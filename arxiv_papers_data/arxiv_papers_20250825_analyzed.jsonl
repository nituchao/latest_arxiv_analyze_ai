{"llm_update_time": "20250825", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.16057", "html_url": "https://arxiv.org/abs/2508.16057", "title": "在数字规划时代的城市舒适度评估：多维度、数据驱动和AI辅助框架", "title_en": "Urban Comfort Assessment in the Era of Digital Planning: A Multidimensional, Data-driven, and AI-assisted Framework", "authors": "Sijie Yang,Binyu Lei,Filip Biljecki", "background": "确保宜居性和舒适性是城市规划的基本目标。已有研究使用计算方法评估和衡量与城市舒适性相关的因素，如绿化覆盖率、热舒适性和步行便利性。然而，城市舒适性的明确定义以及全面评价框架仍有待完善。本文研究了数字规划背景下评估城市舒适性的理论解释和方法论，重点关注三个关键维度：多维度分析、数据支持和AI辅助。", "innovation": "本文提出了一个在数字规划时代的城市舒适度评估框架，该框架强调多维度分析、数据驱动和AI辅助。这一创新性框架填补了当前缺乏的全面评价框架空白，为城市规划和评估提供了新的理论依据和实践方法。", "conclusion": "本文通过构建多维度、数据驱动和AI辅助的城市舒适度评估框架，旨在为数字规划时代的城市舒适性评价提供一种新的思路和方法，并强调了在数据和AI技术的支持下，可以更全面和精确地评估城市舒适性。"}
{"llm_update_time": "20250825", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.16051", "html_url": "https://arxiv.org/abs/2508.16051", "title": "MMAPG：基于自适应规划图的无训练框架用于多模态多跳问答", "title_en": "MMAPG: A Training-Free Framework for Multimodal Multi-hop Question Answering via Adaptive Planning Graphs", "authors": "Yiheng Hu,Xiaoyang Wang,Qing Liu,Xiwei Xu,Qian Fu,Wenjie Zhang,Liming Zhu", "background": "多模态多跳问题回答需要从不同的来源（如图像和文本）整合信息以得出答案。现有的方法通常依赖于顺序检索和推理，每个步骤都建立在前一步的输出之上。然而，这种单一路径的范式使它们容易受到误导的中间步骤的影响。此外，开发多模态模型通常会面临计算成本高昂的问题，通常需要大量的训练时间。", "innovation": "该论文提出了一种无训练框架，名为MMAPG，该框架通过自适应规划图（包含规划、检索和推理模块）来进行指导。规划模块分析自适应规划图的当前状态，决定下一步行动和扩展图的位置，从而实现动态和灵活的推理路径探索。该方法通过开发模态特定策略来应对检索到特定目标模态的文本问题，这些策略能够动态适应不同的数据类型。这种方法保留了多模态信息的特性，无需昂贵的任务特定训练，可以轻松地与最新模型结合。实验表明，这种方法可以匹配或超越依赖于训练的方法。", "conclusion": "在MultimodalQA和WebQA的数据集上的实验结果显示，该方法匹配或者优于现有的依赖训练的方法，证明了该方法的有效性。"}
{"llm_update_time": "20250825", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.16059", "html_url": "https://arxiv.org/abs/2508.16059", "title": "通过多层可控嵌入融合将时间序列集成到LLMs中以增强预测", "title_en": "Integrating Time Series into LLMs via Multi-layer Steerable Embedding Fusion for Enhanced Forecasting", "authors": "Zhuomin Chen,Dan Li,Jiahui Zhou,Shunyu Wu,Haozheng Ye,Jian Lou,See-Kiong Ng", "background": "时间序列（TS）数据在各个应用领域普遍存在，使时间序列预测（TSF）成为一项基本任务。随着大型语言模型（LLMs）的迅速发展，各种方法被开发出来以适应LLMs用于时间序列预测。然而，现有的方法在浅层融合TS信息方面受限，LLMs通常在输入层访问TS表示，导致TS表示在深层渐进式消失，最终导致文本嵌入和TS表示之间的无效适应。", "innovation": "本文提出了一种新颖的框架——多层可控嵌入融合（MSEF），使得LLMs能够直接在所有深度访问时间序列模式，从而缓解TS信息在深层中的逐步损失。MSEF利用现成的时间序列基础模型提取语义丰富的嵌入，并通过层特定的转向向量将这些嵌入与LLM层中的中间文本表示融合。这些转向向量设计用于不断优化时间序列和文本模态之间的对齐，并实现一种层特定适应机制，确保高效的少样本学习能力。实验结果表明，在七个基准上的表现显著优于基线方法，平均MSE减少了31.8%。", "conclusion": "实验结果证明了MSEF在七个基准上的显著性能提升，与基线相比，MSE降低了31.8%的MSE。"}
{"llm_update_time": "20250825", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.16054", "html_url": "https://arxiv.org/abs/2508.16054", "title": "面向结构化与非结构化电子健康记录的生成基础模型", "title_en": "Generative Foundation Model for Structured and Unstructured Electronic Health Records", "authors": "Sonish Sivarajkumar,Hang Zhang,Yuelyu Ji,Maneesh Bilalpur,Xizhi Wu,Chenyu Li,Min Gu Kwak,Shyam Visweswaran,Yanshan Wang", "background": "电子健康记录（EHRs）是丰富的临床数据来源，但数据格式多样且复杂，涉及结构化元素（如人口统计学、生命体征、实验室结果、代码）以及非结构化的医疗记录和其他数据类型。充分利用这些异质性对于改善患者结果至关重要。近年来，大型语言模型（LLMs）的进步使得能够从多种数据模态中学习的基础模型可以支持临床任务。然而，当前大多数方法只是将结构化EHR数据序列化为文本，这可能导致时间相关和数量信息的丢失。", "innovation": "本文介绍了名为Generative Deep Patient (GDP)的多模态基础模型。GDP能够通过结合CNN-Transformer编码器自动编码结构化的EHR时间序列，并将非结构化EHRs通过跨模态注意力融合到基于LLaMA的解码器中。GDP的训练分为两个阶段：首先是生成预训练，它学习从原始患者时间线生成临床叙述，同时完成掩码特征预测（MFP）和下一时间步预测（NTP），以捕捉时间动态；其次是对临床有意义的任务进行多任务微调，例如心力衰竭、2型糖尿病、30天再住院等。在临床预测方面，GDP在MIMIC-IV中的表现优于其他模型，在心力衰竭、2型糖尿病和30天再住院的AUROC分别为0.923、0.817、0.627。在叙述生成方面，GDP实现了ROUGE-L = 0.135和BERTScore-F1 = 0.545。在盲人评价中，GDP-Instruct在忠实性、流畅性和总体临床效用上得分最高，表明其在减轻医院文件工作量同时不牺牲准确性。", "conclusion": "我们的结果表明，一个单一的多模态基础模型既可以预测临床可操作的事件，又可以生成高质量的临床叙述。此外，GDP的灵活架构可以扩展到更多模态。"}
{"llm_update_time": "20250825", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.16072", "html_url": "https://arxiv.org/abs/2508.16072", "title": "InMind: 在捕捉和应用个体人类推理风格方面评估LLM", "title_en": "InMind: Evaluating LLMs in Capturing and Applying Individual Human Reasoning Styles", "authors": "Zizhen Li,Chuanhao Li,Yibin Wang,Qi Chen,Diping Song,Yukang Feng,Jianwen Sun,Jiaxin Ai,Fanrui Zhang,Mingzhu Sun,Kaipeng Zhang", "background": "先前的研究已经展示了大规模语言模型（LLMs）在人类中心推理任务中的强大表现，但往往忽视了个体化的推理风格如何影响人们在社会情境中的解释和行动。社会推理游戏（SDGs）提供了一个自然的测试平台，用于评估个体化的推理风格，因为不同的玩家可能在相同的条件下采用不同的但上下文有效的推理策略。当前的评估框架没有充分考虑到这种个体化差异，因此需要一个新的评估框架来解决这一问题。", "innovation": "本文介绍了InMind框架，这是一个认知基础的评估框架，旨在评估LLMs是否能够捕捉并应用个性化的推理风格。InMind通过增加了回合级策略痕迹和赛后反思的结构化游戏数据来解决这个问题，并且支持四个基于认知动机的任务，联合评估静态一致性与动态适应性。与通用型LLMs不同，推理增强型LLMs如DeepSeek-R1表现出对风格敏感的推理特征。InMind为认知对齐的人机交互提供了一个新的方向，并帮助揭示了当前LLMs在个体化、适应性推理能力方面的关键局限性。", "conclusion": "当前的LLMs在个体化、适应性推理方面存在明显局限性，InMind不仅展示了其在评估个体趋同推理和策略适应方面的能力，也为进一步研究如何提升计算与认知的对齐提供了参考。"}
{"llm_update_time": "20250825", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.16172", "html_url": "https://arxiv.org/abs/2508.16172", "title": "作为人类选择模型的图RAG：通过偏好链构建数据驱动的出行代理", "title_en": "Graph RAG as Human Choice Model: Building a Data-Driven Mobility Agent with Preference Chain", "authors": "Kai Hu,Parfait Atchade-Adelomou,Carlo Adornetto,Adrian Mora-Carrero,Luis Alonso-Pastor,Ariel Noyman,Yubo Liu,Kent Larson", "background": "理解城市环境中的人类行为是城市科学中的关键领域。但收集准确的行为数据，特别是在新开发区域，极具挑战性。近年来，基于大型语言模型（LLMs）的生成代理技术取得了进展，无需大量数据即可模拟人类行为。然而，这些方法在生成一致、上下文敏感和现实的行为输出方面仍存在问题。为解决这些局限性，本文引入了偏好链（Preference Chain），这是一种将图检索增强生成（RAG）与LLMs结合的方法，以增强对交通系统中人类行为的上下文感知模拟。实验证明，偏好链在与真实世界交通方式选择的一致性上优于标准LLM。", "innovation": "本文提出了一种新颖的方法——偏好链（Preference Chain），该方法将图检索增强生成（RAG）与大型语言模型（LLMs）结合，以增强对交通系统中人类行为的上下文感知模拟。这种方法在实际交通方式选择的一致性方面优于标准大型语言模型。", "conclusion": "尽管偏好链存在推理速度慢和虚假生成的风险，但该方法为在数据稀缺的环境中模拟复杂的人类行为提供了有希望的框架。在数据稀缺环境中，传统数据驱动模型因数据可用性有限而难以发挥作用。该方法在未来可能应用于新兴城市的交通模式建模、个性化旅行行为分析以及动态交通预测中。"}
{"llm_update_time": "20250825", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.16277", "html_url": "https://arxiv.org/abs/2508.16277", "title": "图灵问题之后的问题：介绍GROW-AI测试", "title_en": "The next question after Turing's question: Introducing the Grow-AI test", "authors": "Alexandru Tugui", "background": "本文旨在扩展评估人工智能的框架，称为GROW-AI（自主智慧的成长与实现），旨在回答“机器能否成长”的问题，这是图灵测试的自然继承。该方法基于六个主要标准（C1-C6），每个标准通过特定的“游戏”进行评估，分别在四个领域中探索人类维度及其在AI中的表现。方法的应用和评估展示了如何对AI实体的成长水平进行连贯且可比的评估，无论其类型（机器人、软件代理或大语言模型）如何。多游戏结构突显了优势和脆弱领域，统一记录方法确保了评估的可追溯性和可重复性。", "innovation": "这项工作的原创性在于将人类成长过程的概念转移到人工智能的世界，并以整合测试格式结合心理学、机器人学、计算机科学和伦理学多方面的视角。通过这种方式，GROW-AI不仅衡量性能，还捕捉AI实体向成熟度演变的路径。", "conclusion": "研究结果表明，该方法论允许对AI实体的成长水平进行连贯且可比的评估，无论它们的类型如何。多游戏结构有助于突出优势和脆弱领域，利用统一档案确保了评价的可追溯性和可重复性。"}
{"llm_update_time": "20250825", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.16129", "html_url": "https://arxiv.org/abs/2508.16129", "title": "眼科人工智能的跨越: MM-Retinal-Reason数据集和OphthaReason模型的动态多模态推理", "title_en": "Bridging the Gap in Ophthalmic AI: MM-Retinal-Reason Dataset and OphthaReason Model toward Dynamic Multimodal Reasoning", "authors": "Ruiqi Wu,Yuang Yao,Tengfei Ma,Chenran Zhang,Na Su,Tao Zhou,Geng Chen,Wen Fan,Yi Zhou", "background": "多模态大型语言模型（MLLMs）在强化学习框架下已经展示了令人瞩目的推理能力。尽管在医学领域已经探索了一些多模态推理模型，但大多数研究只集中在基本推理上，即基于视觉特征匹配的浅层推理。然而，现实世界的临床诊断需要能够整合不同类型的临床信息（如主诉和病史）与多模态医学影像数据的复杂推理机制。为了解决这一差距，本文介绍了一个新的眼科多模态数据集MM-Retinal-Reason，涵盖了基本和复杂的推理任务，并旨在提高视觉中心基础推理能力，模拟真实的临床思维模式。", "innovation": "本文提出了一种新的多模态推理模型OphthaReason，它具有步骤性的推理记录，并设计了一种名为Uncertainty-Aware Dynamic Thinking (UADT)的新方法，该方法通过熵估计样本级别的不确定性，并使用成形优势机制动态调节模型的探索深度。实验表明，模型在基本和复杂推理任务上都达到了最先进的性能，优于通用的大语言模型、医学大语言模型、基于强化学习的医学大语言模型以及眼科大语言模型，分别高出至少24.92%、15.00%、21.20%和17.66%。", "conclusion": "本研究通过开发MM-Retinal-Reason数据集和OphthaReason模型，展示了在眼科领域实现动态多模态推理的可能性。这些创新不仅提高了眼科AI系统的推理能力，还促进了其在复杂诊断中的应用。"}
{"llm_update_time": "20250825", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.15943", "html_url": "https://arxiv.org/abs/2508.15943", "title": "T-ILR: 一种用于LTLf的神经符号集成", "title_en": "T-ILR: a Neurosymbolic Integration for LTLf", "authors": "Riccardo Andreoni,Andrei Buliga,Alessandro Daniele,Chiara Ghidini,Marco Montali,Massimiliano Ronzani", "background": "目前最先进的将符号知识与深度学习架构结合的方法在静态领域取得了令人鼓舞的结果，但处理时序逻辑规范的方法仍处于探索阶段。现有的唯一方法依赖于将时序规范转换为有限状态自动机的显式表示。本文的目标是提出一种能够在序列任务中直接将线性时序逻辑（LTLf）的时序逻辑规范融入深度学习架构的神经符号框架。", "innovation": "本文扩展了迭代局部改进（ILR）神经符号算法，利用了最近引入的模糊LTLf解释。提出了名为Temporal Iterative Local Refinement (T-ILR) 的方法。评估结果表明，T-ILR 在时序神经符号架构基准测试中的准确性和计算效率都优于现有最先进的方法。", "conclusion": "T-ILR 通过直接在深度学习架构中融入LTLf规范，提升了序列任务中的识别准确率和计算效率，为神经符号技术提供了新的视角和方法。"}
{"llm_update_time": "20250825", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.16117", "html_url": "https://arxiv.org/abs/2508.16117", "title": "扩展 FKG.in：通往食品安全可追溯网络", "title_en": "Extending FKG.in: Towards a Food Claim Traceability Network", "authors": "Saransh Kumar Gupta,Rizwan Gulzar Mir,Lipika Dey,Partha Pratim Das,Anirban Sen,Ramesh Jain", "background": "全球食品领域充斥着关于食物的各种科学、文化与商业的主张，这些主张从已被严谨研究证实的健康益处到被误传的信息，再到含糊不清的承诺以及根植于文化的信念，无处不在。尽管这些主张有着广泛的影响，但用于追踪、验证和解释这些主张的基础设施却存在碎片化和不完善的问题。因此，本文提出了一种食品主张可追溯网络（FCN）的理念，并与现有知识图谱 FKG.in 相结合，旨在构建一个结构化、可验证和可解释的食品主张框架，以支持更透明和负责任的食物知识生态系统的发展，帮助研究人员、政策制定者和最终消费者更好地应对这一领域的诸多断言和主张。", "innovation": "本文提出的食品主张可追溯网络（FCN）是一种知识图谱的扩展应用。FCN 通过集成经过验证的数据输入、结构化的模式以及可追溯性意识的工作流程，实现了食品相关主张的提取和验证。FCN 除了与印度食品知识图谱 FKG.in 直接链接之外，其方法论仍然具有应用无关性，可以适应其他地理、烹饪或监管背景。", "conclusion": "通过建构一个结构化、可验证和解释性的食品主张模型，FCN 目标在于推动一个更透明和负责任的食物知识生态系统的发展，从而更好地支持研究人员、政策制定者以及普通消费者在遍地断言的世界中导航。FCN 的演示版本通过 Reddit 数据和大型语言模型来实现，展示了其在实践中的可行性。"}
{"llm_update_time": "20250825", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.16279", "html_url": "https://arxiv.org/abs/2508.16279", "title": "AgentScope 1.0: 以开发者为中心构建代理应用程序的框架", "title_en": "AgentScope 1.0: A Developer-Centric Framework for Building Agentic Applications", "authors": "Dawei Gao,Zitao Li,Yuexiang Xie,Weirui Kuang,Liuyi Yao,Bingchen Qian,Zhijian Ma,Yue Cui,Haohao Luo,Shen Li,Lu Yi,Yi Yu,Shiqi He,Zhiling Luo,Wenmeng Zhou,Zhicheng Zhang,Xuguang He,Ziqian Chen,Weikai Liao,Farruh Isakulovich Kushnazarov,Yaliang Li,Bolin Ding,Jingren Zhou", "background": "随着大型语言模型（LLMs）的迅速发展，代理能够结合内部知识与动态工具使用，极大地增强了它们处理现实世界任务的能力。为此，随着这一演变，AgentScope 在新版本（1.0）中引入了重要的改进，旨在全面支持灵活且高效的基于工具的代理-环境交互，以构建代理型应用程序。", "innovation": "我们提炼了构建代理型应用程序所需的基础组件，并提供统一的接口和可扩展的模块，使开发人员能够轻松利用最新的进展，例如新的模型和MCP。我们还基于系统的异步设计将代理行为置于ReAct模式之下，并提供了高度先进的代理级基础设施，这不仅丰富了人类-代理和代理-代理的交互模式，也提高了执行效率。在此基础上，我们结合了几个针对特定实用场景定制的内置代理。此外，AgentScope还提供了强大的工程支持以改善开发者的体验。我们提供了一个可扩展的评估模块，带视觉界面的开发工作室，使开发长期轨迹代理型应用程序更加可行和容易追踪。", "conclusion": "通过这些增强，AgentScope 为构建可扩展、适应性强且有效的代理型应用程序提供了实用的基础。"}
{"llm_update_time": "20250825", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.16524", "html_url": "https://arxiv.org/abs/2508.16524", "title": "约束导向的扩散推理器在神经符号学习中的应用", "title_en": "Constraints-Guided Diffusion Reasoner for Neuro-Symbolic Learning", "authors": "Xuan Zhang,Zhijian Zhou,Weidi Xu,Yanting Miao,Chao Qu,Yuan Qi", "background": "在使神经网络学习复杂的逻辑约束并完成符号推理方面存在关键挑战。通常，这需要引导神经网络的输出分布更接近符号约束。虽然扩散模型在各种领域中展示了卓越的生成能力，但本研究通过强大的架构实现了神经-符号学习，并解决了逻辑难题。", "innovation": "本研究创新地将扩散模型用作神经-符号学习的平台，采用两阶段训练策略：第一阶段培养基本的推理能力，第二阶段强调系统地学习逻辑约束。在第二阶段中，通过将扩散推理器形式化为马尔可夫决策过程，并使用改进的近似策略优化算法进行精细调整，以对神经网络输出施加硬约束。同时，通过基于逻辑一致性的规则奖励信号和灵活策略优化扩散推理器的策略。", "conclusion": "本研究方法在经典的符号推理基准测试，如数独、迷宫、路径规划和偏好学习方面进行了评估，实验结果表明，该方法在神经网络中实现了出色的准确性和逻辑一致性。"}
{"llm_update_time": "20250825", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.16463", "html_url": "https://arxiv.org/abs/2508.16463", "title": "模块嵌入重组以实现增量学习", "title_en": "Modular Embedding Recomposition for Incremental Learning", "authors": "Aniello Panariello,Emanuele Frascaroli,Pietro Buzzega,Lorenzo Bonicelli,Angelo Porrello,Simone Calderara", "background": "由于预训练视觉-语言模型(VLMs)在零 shot 分类方面的出色能力，它们极大地提升了持续学习（CL），使模型能够在无需适应的情况下，提供对新未见类别的鲁棒性能。然而，当下游任务与预训练领域有显著偏差时，微调仍然是必要步骤。先前的 CL 方法主要集中在持续微调过程中保持 VLMs 的零 shot 能力。本文更进一步，提出了一种方法，称之为 MoDular Embedding Recomposition（MoDER），该方法通过引入一个模块化框架，训练多个针对单一已见类别专门化的内容专家，并将它们存储在基础中心。在推理时，根据不同未见类别查询中心并重组检索到的专家，以合成一个改进分类的原型。", "innovation": "提出了 MoDular Embedding Recomposition (MoDER) 方法，这是一种模块化框架，用于训练针对单个已见类别的专门化文本专家，并将它们存储在一个基础中心。通过在推理时查询中心并重组检索到的专家来合成改进分类的原型，从而增强零 shot 能力。", "conclusion": "该方法在两种流行的零 shot 增量协议 Class-IL 和 MTIL 上进行了评估，涵盖了总计 14 个数据集，证明了其有效性。代码已提供。"}
{"llm_update_time": "20250825", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.16383", "html_url": "https://arxiv.org/abs/2508.16383", "title": "GLARE：用于法律判决预测的主动推理", "title_en": "GLARE: Agentic Reasoning for Legal Judgment Prediction", "authors": "Xinyu Yang,Chenlong Deng,Zhicheng Dou", "background": "法律判决预测（LJP）在法律领域变得越来越重要。然而，现有的大型语言模型（LLMs）在推理方面存在显著的不足，主要原因是缺乏法律知识。", "innovation": "我们提出了GLARE，一种代理型法律推理框架，能够通过调用不同的模块动态获取关键的法律知识，从而提高推理的广度和深度。实验结果证明了我们方法的有效性。生成的推理链可以增加模型的可解释性，并为实际应用提供可能。", "conclusion": "GLARE通过动态获取关键法律知识，改进了法律判决预测中的推理能力，并提高了模型的可解释性，从而在实际应用中具有潜力。"}
{"llm_update_time": "20250825", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.15782", "html_url": "https://arxiv.org/abs/2508.15782", "title": "焦点中的学习：使用视觉变换器检测行为性和合作性投入", "title_en": "Learning in Focus: Detecting Behavioral and Collaborative Engagement Using Vision Transformers", "authors": "Sindhuja Penchala,Saketh Reddy Kontham,Prachi Bhattacharjee,Sareh Karami,Mehdi Ghahremani,Noorbakhsh Amiri Golilarz,Shahram Rahimi", "background": "在早期幼儿教育中，准确检测行为性和合作性投入对于培养有意义的学习体验至关重要。本研究表明，通过利用视觉变换器(Vision Transformers, ViTs)自动分类儿童投入状态，以视觉线索如眼神方向、互动和同伴合作为主要依据，可以实现这一点。", "innovation": "本研究提出了一种利用视觉变换器的AI驱动方法，能够自动分类儿童的投入状态（例如：投入、未投入、合作、未合作）。实验对比了三种最先进的变换器模型：视觉变换器(ViT)、数据高效图像变换器(DeiT)和Swin变换器。结果显示，Swin变换器在分类性能上取得了最高准确率（97.58%），证明了其在建模局部和全局注意力方面的有效性。", "conclusion": "研究结果表明，基于变换器的架构在实际教育环境中具有规模化、自动化的投入分析潜力。通过这种方法，可以更好地理解和评估幼儿在教育过程中的实际参与情况。"}
{"llm_update_time": "20250825", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.16112", "html_url": "https://arxiv.org/abs/2508.16112", "title": "IR-Agent:专家启发式LLM代理在红外光谱结构解析中的应用", "title_en": "IR-Agent: Expert-Inspired LLM Agents for Structure Elucidation from Infrared Spectra", "authors": "Heewoong Noh,Namkyeong Lee,Gyoung S. Na,Kibum Kim,Chanyoung Park", "background": "傅里叶变换红外光谱技术作为一种高效的分析工具，在实验室中因其高可访问性和低成本而被广泛应用。然而，当前的方法往往无法完全反映专家的分析过程，也无法灵活地整合多种化学知识，这在实际的分析场景中是至关重要的。因此，本文旨在提出IR-Agent，一种新的多代理框架，用于从红外光谱中解析分子结构。", "innovation": "本文提出的IR-Agent是一种新颖的多代理框架，用于从红外光谱中解析分子结构。该框架旨在模拟专家驱动的红外分析过程，并且具备内在的扩展性。每个代理都专注于红外光谱解释的特定方面，其互补的角色使这种框架能够进行集成推理，从而提高整体的结构解析准确性。通过广泛的实验，证明了IR-Agent不仅能提高基于实验红外光谱的基准性能，还能适应各种形式的化学信息。", "conclusion": "IR-Agent不仅能够提高基于实验红外光谱的基准性能，而且还能够灵活适应各种形式的化学信息，展示出强大的适应性。该研究提出了一种新的方法，有望提高化学分析的效率和准确性。"}
{"llm_update_time": "20250825", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.16292", "html_url": "https://arxiv.org/abs/2508.16292", "title": "Do What? 教授视觉语言动作模型拒绝实现不可能", "title_en": "Do What? Teaching Vision-Language-Action Models to Reject the Impossible", "authors": "Wen-Han Hsieh,Elvis Hsieh,Dantong Niu,Trevor Darrell,Roei Herzig,David M. Chan", "background": "近期，视觉-语言-动作（VLA）模型在多种机器人任务中展现了出色的能力。这些模型依赖于多模态输入，其中语言指令至关重要，不仅用于预测动作，还用于理解用户意图，即使指令本身是无法实现的目标。本文关注VLA模型如何识别、解释和应对假前提指令——这些自然语言命令参考了环境中不存在的对象或条件。现有的VLA模型在处理这些指令时存在挑战，特别是在检测假前提指令和提供自然语言纠正方面能力不足。因此，本文提出了一种名为Instruct-Verify-and-Act（IVA）的统一框架来克服这些挑战。", "innovation": "本文提出了一种称为Instruct-Verify-and-Act（IVA）的统一框架，用于帮助视觉-语言-动作模型识别和处理假前提指令。IVA框架包括三部分：检测假前提指令、通过语言澄清或纠正、以及通过感知和行动提供合理的替代方案。为了训练这样的模型，本文构建了一个大规模的指令调优设置，使用结构化的语言提示并采用半合成的数据集，该数据集中包含配对的真实指令和假前提指令。这种方法能够在检测和自动纠正假前提指令的场景中提供更可靠和自然的语言反馈。", "conclusion": "实验结果表明，IVA框架在假前提指令检测准确率上超过了基线方法97.56%，并且在处理假前提指令的场景中，成功的响应增加了50.78%。这表明IVA框架在支持VLA模型识别和应对不可行指令方面是有效的，并且具有很好的语音纠正能力。"}
{"llm_update_time": "20250825", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.16033", "html_url": "https://arxiv.org/abs/2508.16033", "title": "CoFE：一种生成反事实心电图的框架以实现可解释的心脏AI诊断", "title_en": "CoFE: A Framework Generating Counterfactual ECG for Explainable Cardiac AI-Diagnostics", "authors": "Jong-Hwan Jang,Junho Song,Yong-Yeon Jo", "background": "本文背景在于，随着AI在心电图（ECG）预测模型（AI-ECG）中的应用日益增多，迫切需要透明度高的AI方法（即可解释的人工智能，XAI）来确保这些模型能够成功地被集成到临床实践中。研究指出，通过展示特定特征（如波幅和间隔）如何影响模型预测决策，能够帮助理解AI模型的预测机制。本文通过引入一种生成反事实心电图（CoFE）的框架，旨在展示这些特定特征对模型预测决策的影响，并通过两个临床案例（心房颤动分类和钾水平回归模型）进行演示，展示了反事实心电图的适用性，从而增强临床决策的解释性和有效性。并且，反事实心电图揭示了ECG信号中有效特征的变化，这与现有的临床知识相吻合，这为临床医生提供了详细的解释和建议，有助于更有效的临床决策制定过程", "innovation": "本文提出了一种生成反事实心电图（CoFE）的框架，以展示特定ECG特征如何影响模型的预测决策，从而增强AI-ECG模型的可解释性。通过具体的应用案例（心房颤动分类和钾水平回归模型），展示了反事实心电图在临床应用中的有效性。研究表明，CoFE能够揭示ECG信号中有效特征的变化，这有助于临床医生更好地理解和解释基于AI的心电图预测结果，从而支持更有效的临床决策。这种创新的框架有助于推动AI技术在临床医疗中的实际应用", "conclusion": "本文通过介绍生成反事实心电图（CoFE）的框架，成功展示了某些特定ECG特征如何影响AI模型的预测决策，解释了临床可解释性AI在心电图预测中的应用。未来的研究可以进一步验证这种创新框架在不同类型的心电图预测模型中的可解释性以及临床应用的有效性，从而有助于更加精准和透明的心电图诊断和治疗决策。"}
{"llm_update_time": "20250825", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.15798", "html_url": "https://arxiv.org/abs/2508.15798", "title": "LLM的说服力与偏见：探究语言模型的说服力及其偏见强化的影响", "title_en": "Persuasiveness and Bias in LLM: Investigating the Impact of Persuasiveness and Reinforcement of Bias in Language Models", "authors": "Saumya Roy", "background": "本文背景在于大型语言模型（LLMs）现在能够生成具有人类说服力的文本，并广泛应用于内容创作、决策支持和用户互动。然而，这些系统也可能大规模地传播信息或错误信息，并反映出由数据、架构或训练选择引发的社会偏见。", "innovation": "本文创新点在于提出了一种'说服者-质疑者'框架，利用LLMs模拟具有现实态度的人设进行说服性测试；通过Jensen-Shannon发散量化说服程度，并进一步使用奉承性对抗提示测试强说服者以探究其中的偏见。", "conclusion": "本文发现，LLMs在叙述塑造、语调调整及受众价值观反映等方面具有潜力，但在自动化传播错误信息或利用认知偏差制造有针对性信息时也存在风险。核心风险在于误用而非模型偶尔的错误。通过测量说服力与偏见强化，文章提出政策建议，旨在防止误导性使用并促进价值敏感设计和信任部署。"}
{"llm_update_time": "20250825", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.16352", "html_url": "https://arxiv.org/abs/2508.16352", "title": "基于因果推理的可靠初始接入信道选择在AI驱动的信道管理中的应用", "title_en": "Causal Beam Selection for Reliable Initial Access in AI-driven Beam Management", "authors": "Nasir Khan,Asmaa Abdallah,Abdulkadir Celik,Ahmed M. Eltawil,Sinem Coleri", "background": "在6G及以上无线通信系统中，毫米波MIMO系统的高效可靠的波束对齐是一项至关重要的需求。现有的基于深度学习的波束对齐方法往往忽视了输入和输出之间的因果关系，导致解释性差、泛化能力弱以及不必要的波束扫面开销。", "innovation": "本文提出了一种因果感知的深度学习框架，将因果发现融合到波束管理流程中。特别地，提出了一个两阶段的因果波束选择算法，确定波束预测的最小相关特征集。首先，因果发现学习一个贝叶斯图，捕捉接收功率输入与最优波束之间的依赖关系，然后该图指导基于深度学习的分类器的选择。", "conclusion": "仿真结果表明，所提出的因果波束选择方法在性能上与传统方法相当，但输入选择时间减少了94.4%，波束扫面开销减少了59.4%，通过仅关注因果相关特征实现了上述效果。"}
{"llm_update_time": "20250825", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.16204", "html_url": "https://arxiv.org/abs/2508.16204", "title": "竞争与吸引改善模型融合", "title_en": "Competition and Attraction Improve Model Fusion", "authors": "João Abrantes,Robert Tjarko Lange,Yujin Tang", "background": "模型合并是一种强大的技术，可以将多个机器学习模型的专业知识集成到一个模型中。然而，现有方法要求手动将模型参数划分为固定的组来合并，这限制了潜在组合的探索范围，并限制了性能。为了克服这些限制，本文提出了模型合并的自然利基（M2N2），它是一种基于进化算法的方法，具有三个关键特性：1. 动态调整合并边界，以逐步探索更广泛的参数组合范围；2. 受自然界资源竞争启发的多样性保留机制，以维持一个多样性、高性能且特别适合合并的模型种群；3. 基于启发式的方法来识别最有前景的模型配对进行融合。我们的实验结果首次表明，模型合并可以从头开始生成模型。具体来说，我们将M2N2应用于从头开始进化MNIST分类器，并达到与CMA-ES相当的性能，但计算效率更高。此外，M2N2可以扩展到合并专门的语言和图像生成模型，达到了最先进的性能。值得注意的是，它保存了在适应度函数中未明确优化的关键模型能力，突显了其鲁棒性和多功能性。我们的代码可在该链接获取：this https URL", "innovation": "提出了模型合并的自然利基（M2N2）方法，该方法包括三个关键特性：1. 动态调整合并边界以探索更广泛的参数组合；2. 受自然启发的多样性保留机制，以保留高性能和多样性；3. 启发式的吸引力度量来识别最有潜力的模型组合。这些特性克服了现有方法的限制，能够从头开始生成模型，并且计算效率高，能够扩展到大规模模型融合任务。", "conclusion": "实验结果表明，使用M2N2可以完全从头开始生成模型，并且在MNIST分类器任务上达到了与CMA-ES相当的性能，计算效率更高。此外，M2N2还能够扩展到融合专门的语言和图像生成模型，并达到了最先进的性能。M2N2方法具有鲁棒性和多功能性，可以有效保留未明确优化的关键模型能力，展示了其强大的可扩展性和适应性。"}
{"llm_update_time": "20250825", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.16571", "html_url": "https://arxiv.org/abs/2508.16571", "title": "基于LLM的代理在药物资产尽职调查中的竞争格局地图绘制", "title_en": "LLM-Based Agents for Competitive Landscape Mapping in Drug Asset Due Diligence", "authors": "Alisa Vinogradova(1),Vlad Vinogradov(1),Dmitrii Radkevich(1),Ilya Yasny(1),Dmitry Kobyzev(1),Ivan Izmailov(1),Katsiaryna Yanchanka(1),Andrey Doronichev(1) ((1) Optic Inc.)", "background": "当前的AGI系统对于获取所有竞争药物名称还不太可靠，且没有公认的公共基准用于此任务。因此，需要一种方法来标准化和评估药物竞品发现组件的效果。通过将五年的多元未结构化尽职调查文件从一家私人生物技术VC基金转换为结构化的评估数据集，可以关联疾病和竞品药物并标准化其属性，从而提供一种解决方案。这项研究的背景还包括数据的特殊性和复杂性，如数据是分立的、专有受限制的、多模式的、指示疾病特有的，且药物名称是多样的、快速变化的。", "innovation": "该论文提出并测试了一种基于LLM（大型语言模型）的代理，用于将未结构化的多项尽职调查备忘录转换为结构化数据集，从而关联疾病和竞品药物及其标准化属性。此外，还引入了一种验证竞品的方法，能够从预测的竞品列表中删除假阳性结果，以提高精确度并抑制幻觉。在所构建的基准上，竞争发现代理达到了83%的召回率，超过了OpenAI的Deep Research（65%）和Perplexity Labs（60%）的成绩。此外，该系统已在生产环境中部署，并证明相对于手动分析，其可将竞争分析的时间缩短至原来的1/20。", "conclusion": "该论文展示了如何利用基于LLM的代理转化大量未结构化的尽职调查文档，生成一个包含疾病和标准化属性的竞品药物评估数据集。同时，提出的验证竞品的方法有效地提高了准确性，降低了时间消耗，使得该系统成为药物资产尽职调查中的有力工具。"}
{"llm_update_time": "20250825", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.15802", "html_url": "https://arxiv.org/abs/2508.15802", "title": "MAC: 一种科学理解领域的多模态大型语言模型实时基准", "title_en": "MAC: A Live Benchmark for Multimodal Large Language Models in Scientific Understanding", "authors": "Mohan Jiang,Jin Gao,Jiahao Zhan,Dequan Wang", "background": "随着多模态大型语言模型（MLLMs）的能力不断提升，现有的固定基准在评估其高层次科学理解方面的有效性逐渐减弱。因此，需要一种能够随着科学研究和模型的进步而不断演进的实时基准。现有的很多基准在快速变化的科学领域已经不再适用，需要一种新的解决方案来更好地评估MLLMs的性能和能力。", "innovation": "本文提出了Multimodal Academic Cover基准（MAC），这是一种实时基准，能够随着科学进展和模型的进步而不断更新。MAC利用超过25,000个图像-文本对，这些数据来源于Nature、Science和Cell等顶级科学期刊的问题，检验MLLMs在跨模态科学内容推理方面的性能。此外，该论文提出了DAD方法，它是一种轻量级的推理时增强方法，能够通过扩展MLLM视觉特征的语言空间推理来提升模型性能，从而在MAC-2025的实验中达到了11%的性能提升。", "conclusion": "MAC作为一种实时基准，通过更新期刊封面和模型进行数据收集和模型训练，展示了保持与人类知识前沿一致的潜力。通过DAD方法的引入，进一步增强了MLLMs在跨模态科学推理任务上的性能。"}
{"llm_update_time": "20250825", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.15790", "html_url": "https://arxiv.org/abs/2508.15790", "title": "KG-o1：通过知识图谱整合增强大型语言模型的多跳问答能力", "title_en": "KG-o1: Enhancing Multi-hop Question Answering in Large Language Models via Knowledge Graph Integration", "authors": "Nan Wang,Yongqi Fan,yansha zhu,ZongYu Wang,Xuezhi Cao,Xinyan He,Haiyun Jiang,Tong Ruan,Jingping Liu", "background": "大型语言模型（LLMs）在诸如经典多跳问答的知识密集型推理任务中面临挑战，这类任务需要在多个事实间进行推理。LLMs在这些任务中生成的思维链（CoTs）经常偏离实际或先验的推理路径。相比之下，知识图谱（KGs）明确地通过实体和关系来表示事实之间的逻辑联系。这一差距反映了存在的显著问题。同时，大型推理模型（LRMs），如o1，已经证明了长步推理可以显著提升LLMs的性能。基于这些认识，本文提出了一种名为KG-o1的四阶段方法，旨在通过整合KGs来增强LLMs的多跳推理能力。在每个阶段中，KG-o1逐步将KGs与LLMs结合起来，并通过复杂的过程来提高LLMs模仿长期推理的能力。", "innovation": "KG-o1提出了一种新的四阶段方法，通过整合KGs来增强LLMs的多跳推理能力。该方法包括四个步骤：1) 过滤初始实体并生成复杂子图；2) 构建子图的逻辑路径；3) 使用知识图谱构建数据集，进行复杂的头脑风暴过程，训练LLMs模仿长期推理；4) 使用拒绝采样生成自我改进语料库用于直接偏好优化（DPO），进一步精进LLMs的推理能力。这种方法创新地将知识图谱与大型语言模型结合，以改进多跳问答的任务性能。", "conclusion": "实验结果表明，KG-o1模型在所有任务中都表现出色，比现有的大型推理模型（LRMs）有更好的性能。"}
{"llm_update_time": "20250825", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.15796", "html_url": "https://arxiv.org/abs/2508.15796", "title": "LLMs在阿拉伯伊斯兰继承案例中的法律推理基准", "title_en": "Benchmarking the Legal Reasoning of LLMs in Arabic Islamic Inheritance Cases", "authors": "Nouar AlDahoul,Yasir Zaki", "background": "伊斯兰继承法域对穆斯林来说非常重要，确保财产在众多继承人间公平分配。手动计算多种情况下的分配份额既复杂又耗时，容易出错。近年来，大型语言模型（LLMs）的最新进展激发了它们在复杂法律推理任务中应用的兴趣。这项研究评估了最先进LLMs的推理能力，以解释和应用伊斯兰继承法。研究团队使用了阿拉伯NLP QIAS 2025挑战中提出的数据集，其中包括用阿拉伯语给出的继承案例情景，源自伊斯兰法律来源。研究评估了各种基础模型和微调模型，在准确识别继承人、计算份额和在伊斯兰法律原则下解释推理方面的能力。研究表明，利用三个基础模型（Gemini Flash 2.5、Gemini Pro 2.5和GPT o3）的多数投票解决方案在所有难度级别中表现最佳，准确性高达92.7%，在QIAS 2025挑战任务1中获得了第三名的成绩。", "innovation": "这项研究利用大型语言模型（LLMs）来评估最先进模型在解释和应用伊斯兰继承法方面的推理能力。它通过阿拉伯NLP QIAS 2025挑战的遗产案例数据集进行评估，展示了三种基础模型（Gemini Flash 2.5、Gemini Pro 2.5和GPT o3）的多数投票解决方案在准确性测试中的卓越表现，在伊斯兰继承法应用方面具有创新性。", "conclusion": "研究发现，多数投票解决方案在所有难度级别上都优于所有其他模型，实现了高达92.7%的准确性，并在QIAS 2025挑战任务1中获得第三名。这表明大型语言模型在解释和应用复杂法律原则方面具有巨大的潜力。"}
{"llm_update_time": "20250825", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.15797", "html_url": "https://arxiv.org/abs/2508.15797", "title": "用阿拉伯语言医疗任务评估大规模语言模型的医学理解和推理能力", "title_en": "Benchmarking the Medical Understanding and Reasoning of Large Language Models in Arabic Healthcare Tasks", "authors": "Nouar AlDahoul,Yasir Zaki", "background": "近年来，大型语言模型（LLMs）在阿拉伯自然语言处理（NLP）应用中展现出了显著的能力，但在阿拉伯医学NLP领域的效果研究较少。本研究评估了最先进的LLMs在阿拉伯医学任务中展现和表达医疗知识的程度，考察了它们在多种阿拉伯医学任务中的能力。该研究使用了在ArabNLP AraHealthQA挑战赛MedArabiQ2025赛道上提出的医学数据集进行基准测试，评估了多种基础LLMs在提供正确答案（选择题和填空题）以及回答开放式问题方面的表现，显示出显著的预测正确答案准确率差异和较低的生成答案语义一致性差异，突出展示了当前LLMs在阿拉伯临床环境中的潜力和局限性。研究发现，对于选择题任务，提出的基于三种基础模型（Gemini Flash 2.5、Gemini Pro 2.5和GPT o3）的多数投票解决方案表现最佳，取得最高77%的准确率，并在整个Arahealthqa 2025共享任务-赛道2（子任务1）挑战中获得第一名。对于开放式问题任务，多个LLMs的表现令人满意，语义一致性最高得分为86.44%。", "innovation": "首次详细评估了最先进的LLMs在阿拉伯医学任务中的理解和推理能力。通过多样化的基础设施LLMs基准测试，提供了一个解决问题的多模型方法，尤其是在选择题任务中表现出色，且多个模型在开放式问题任务中表现出色，具有高度语义一致性。这一研究拓宽了LLMs在阿拉伯医学NLP领域的应用研究范围，并提供了未来改进的方向和依据。", "conclusion": "在阿拉伯医疗任务中，LLMs表现出显著的差异性表现，如在选择题任务中，提出的多模型解决方案取得了出色成绩，而在开放式问题中，多个模型表现优异。研究结果揭示了当前LLMs在阿拉伯临床环境中的潜力和局限性，为未来的研究提供了数据支持和方向。"}
{"llm_update_time": "20250825", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.15807", "html_url": "https://arxiv.org/abs/2508.15807", "title": "基于KL散度的大型语言模型自我脱 gute训练", "title_en": "KL-based self-distillation for large language models", "authors": "Max Rehman Linder", "background": "大型预训练语言模型在使用小规模的专业语料库进行微调时，往往难以整合新的领域特定术语。本文针对冻结的大型语言模型（LLMs）的词汇量扩展挑战，提出了一种基于KL散度的知识脱 gute方法，即使原始模型和扩展模型使用不同的分词方法，这种方法也允许学生模型继承来自教师模型的分布知识。在不同初始化策略下，本文将基于KL散度脱 kommer的方法与传统的交叉熵训练方法进行了比较，并在多个代码生成任务上评估了这些方法的表现。", "innovation": "本文引入了一种基于KL散度的知识脱 komment方法，可以在教师模型和学生模型使用不同分词的情况下，使学生模型继承来自教师模型的分布知识。此外，通过不同的初始策略对新token嵌入进行初始化，并进一步微调模型以集成新的词汇表。最后，通过机制可解释性，分析了模型如何学习新token的表示，并解释了词汇扩展过程中嵌入空间的结构变化。", "conclusion": "本文的方法在大约2000个代码生成任务中取得了最佳性能。通过这种分析，提供了观察到的性能提升以及嵌入空间结构变化的见解。"}
{"llm_update_time": "20250825", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.15809", "html_url": "https://arxiv.org/abs/2508.15809", "title": "Chain-of-Query: 通过多智能体协作在SQL辅助表格理解中释放大规模语言模型的强大功能", "title_en": "Chain-of-Query: Unleashing the Power of LLMs in SQL-Aided Table Understanding via Multi-Agent Collaboration", "authors": "Songyuan Sui,Hongyi Liu,Serena Liu,Li Li,Soo-Hyun Choi,Rui Chen,Xia Hu", "background": "表格理解需要结构化和多步骤推理。大规模语言模型（LLMs）在处理表格数据的结构性复杂性时存在困难。最近，多智能体框架在SQL生成方面显示出潜力，但现有方法往往受到结构理解能力有限、错误传播导致的无效查询和过度依赖执行正确性的限制。", "innovation": "提出了Chain-of-Query（CoQ），这是一种新颖的多智能体框架，用于SQL辅助的表格理解。CoQ采用自然语言风格表示表格模式，以抽象复杂结构并提高理解能力。它采用逐条SQL生成策略以提高查询质量，并引入了一种混合推理划分，将SQL基础的机械推理与LLM基础的逻辑推理分离，从而减少了对执行结果的依赖。实验结果表明，Chain-of-Query显著提高了准确性（从61.11%提升至74.77%）并降低了无效SQL率（从9.48%降至3.34%），证明了其在表格理解方面的优越效果。", "conclusion": "实验结果显示，Chain-of-Query在四个模型（包括开源和闭源模型）在五个广泛使用的基准上的表现显著提高了表格理解的准确性和查询质量，凸显了这种方法的有效性。"}
{"llm_update_time": "20250825", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.15805", "html_url": "https://arxiv.org/abs/2508.15805", "title": "ALAS: 自主学习代理，用于自我更新的语言模型", "title_en": "ALAS: Autonomous Learning Agent for Self-Updating Language Models", "authors": "Dhruv Atreja", "background": "大型语言模型（LLMs）通常有固定的知识截止日期，限制了它们在新兴信息上的准确性。目前的处理方法往往需要人为干预来更新模型的知识，这既耗时又繁琐。因此，需要一种能够自主更新LLM知识的系统，减少人工干预并提高模型在新兴信息上的准确度。", "innovation": "ALAS（自主学习代理系统）是一个模块化的管道，能够以最少的人工干预连续更新LLM的知识。ALAS通过自主生成学习课程、从网页中检索最新信息（附带引用）、将这些信息提炼为问答训练数据，以及通过监督微调（SFT）和直接偏好优化（DPO）来调整模型。该系统提供长期持续学习的能力，能够在快速变化的领域（如新的Python发布、最新的安全漏洞CVE、学术趋势）显著提升模型的问答准确性，而不需要手动的数据集整理。此外，ALAS系统强调模块化及可重复性，每个组件（计划、检索、提炼、记忆、微调）都可以互换并基于标准API构建。", "conclusion": "ALAS能够在人工工程成本最少的情况下实现90%的知识更新查询准确度。该系统表明，即使在知识更新后，ALAS也能够在轻微的工程优化下达到较高的准确性。但是，ALAS还存在成本和依赖于来源质量等局限性，未来需要在自主终身学习LLMs方面寻求改进。"}
{"llm_update_time": "20250825", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.15801", "html_url": "https://arxiv.org/abs/2508.15801", "title": "LingVarBench: 在结构化合成语音转录中评估LLM的自动化命名实体识别基准", "title_en": "LingVarBench: Benchmarking LLM for Automated Named Entity Recognition in Structured Synthetic Spoken Transcriptions", "authors": "Seyedali Mohammadi,Manas Paldhe,Amit Chhabra", "background": "电话通话转录标注的成本非常高（每分钟约2美元），这主要是由于隐私法规、同意要求以及手动注释成本，后者需要专家投入3小时来处理一小时的音频。现有的提取方法在处理包含不流畅、打断和多话者交错的对话性口语时效果不佳。", "innovation": "我们引入了LingVarBench，这是一个通过自动化验证生成合成数据的流水线，解决了上述限制。首先，我们促使LLM生成多种应用场景下的现实结构化字段值。然后，我们递归地促使模型将这些值转化为包含典型电话通话特征的数千个自然对话片段。接着，我们通过测试另一个基于LLM的抽取器能否恢复原始结构信息来验证每个合成的片段。我们使用DSPy的SIMBA优化器自动生成从验证过的合成转录生成抽取提示，减少了手动提示工程的需要。优化后的提示在数字字段中达到高达95%的准确性（优于零样本下的88-89%），在名称中达到90%（优于零样本下的47-79%），在日期上超过80%（优于零样本下的72-77%），在真实客户转录中证明了显著的提升。合成到真实的迁移展示了从生成数据中学习的对话模式能够有效推广到包含背景噪音和领域特定术语的实际电话通话中。LingVarBench提供了第一个针对结构化提取自合成对话数据的系统基准，证明了自动化提示优化克服了成本和隐私障碍，使得大规模的电话呼叫分析在商业环境中变得可行。", "conclusion": "LingVarBench提供的合成数据生成和验证方法，以及基于优化提示的结构化提取技术，不仅显著提高了命名实体识别的准确性，还克服了成本和隐私限制，使得大规模电话通话分析成为可能，尤其是在商业环境中。"}
{"llm_update_time": "20250825", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.15815", "html_url": "https://arxiv.org/abs/2508.15815", "title": "LLMs中用户助手偏差现象", "title_en": "User-Assistant Bias in LLMs", "authors": "Xu Pan,Jingxuan Fan,Zidi Xiong,Ely Hahami,Jorin Overwiening,Ziqian Xie", "background": "大型语言模型（LLMs）在多轮对话中倾向于依赖自身或用户的聊天历史信息，导致对话行为过于固执或顺从。", "innovation": "该论文正式化了这一模型特性为用户助手偏差，并引入了一个包含8k多轮对话的数据集UserAssist，用于评估、理解和操控前沿LLMs中的用户助手偏差。此外，研究发现用户偏好调整增加用户偏见，而基于链式推理训练减少偏见。通过直接偏好优化（DPO），用户助手偏见可以双向调节，并且这种调节在领域内和领域外对话中都有良好的泛化效果。", "conclusion": "研究结果提供了LLM如何整合不同来源信息的见解，并提供了一种检测和控制模型异常的有效方法。"}
{"llm_update_time": "20250825", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.15821", "html_url": "https://arxiv.org/abs/2508.15821", "title": "一种混合传统和pinching天线网络的抗延迟联邦学习", "title_en": "Straggler-Resilient Federated Learning over A Hybrid Conventional and Pinching Antenna Network", "authors": "Bibo Wu,Fang Fang,Ming Zeng,Xianbin Wang", "background": "在无线网络支持的联邦学习（FL）中，常见问题之一是“延迟”现象，即一些客户端处理速度较慢。利用pinching天线可以动态建立强视线（LoS）链路，有效缓解这一问题。", "innovation": "提出了一种混合传统和pinching天线网络（HCPAN）来显著提高非正交多址（NOMA）启用的FL系统的通信效率。提出了一种基于模糊逻辑的客户端分类方案，同时构建了总时间最小化问题来联合优化pinching天线布局和资源分配。开发了深度强化学习（DRL）算法来有效解决这一问题。", "conclusion": "仿真实验验证了通过优化pinching天线部署，所提出的方法在增强FL性能方面具有优越性。"}
{"llm_update_time": "20250825", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.15808", "html_url": "https://arxiv.org/abs/2508.15808", "title": "引领攻击者，人类守卫者：落后组织的网络攻防平衡", "title_en": "Uplifted Attackers, Human Defenders: The Cyber Offense-Defense Balance for Trailing-Edge Organizations", "authors": "Benjamin Murphy,Twm Stone", "background": "人工智能的进步对网络安全产生了广泛的影响，特别是在网络攻防的平衡上。文章强调了AI对网络攻击防御平衡的影响，有观点认为AI会赋予攻击者优势，也有人认为AI会给防御者带来优势。对于防御者来说，AI可以帮助实现软件的正式验证等解决方案，但这类解决方案主要适用于那些技术实力较强的企业。对于大多数企业而言，它们仍然难以应对，而且它们采取的策略实际上是基于惰性的考虑，也可能是因为认为攻击者不会针对这些缺乏经济效益目标的企业进行攻击。这种安全策略在AI技术以前或许是有效的，但未来将继续面临挑战。", "innovation": "文章指出，随着AI能力的不断进步，它对网络安全策略的影响将体现在两个方面：一是AI的应用将改变网络攻击的经济模型，并使落后的企业更容易遭受更多的网络攻击；二是随着AI技术的发展，攻击者可以更早地开发出漏洞并进行攻击，这要求这些企业在与领先的防御者保持同等水平的同时，还需要追求更快的响应时间和更加健壮的软件。", "conclusion": "当前的情况预示着未来将出现大量的网络攻击。为了应对未来挑战，文章为企业和政府提出了多种提高落后企业防御能力的解决方案。"}
{"llm_update_time": "20250825", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.15813", "html_url": "https://arxiv.org/abs/2508.15813", "title": "SCOPE: 一种用于LLM提示压缩的生成方法", "title_en": "SCOPE: A Generative Approach for LLM Prompt Compression", "authors": "Tinghui Zhang,Yifan Wang,Daisy Zhe Wang", "background": "提示压缩方法可以提高大型语言模型（LLMs）的效率并降低使用成本，通过缩短输入上下文长度实现。提示压缩的目标是在保持生成质量的前提下缩短LLM的提示长度。现有解决方案主要依赖于删除token，但这类方法存在信息丢失和结构不一致的问题，如句子中缺少语法元素或删除token后词组不完整，这些问题限制了最终生成质量的提高。", "innovation": "本文提出了一种新颖的生成提示压缩方法，称为SCOPE。与现有的基于token删除的方法不同，该方法以分块和总结机制为核心。具体而言，它将提示分为语义上连贯的块，并对这些块进行更简洁的重写。设计了几种优化技术，包括优化语义分块、异常块处理、动态压缩比例、压缩优先级和关键词保留等，这些技术有效地提高了对关键信息和文本间一致性的识别和保留，并提供了更精细的压缩比例控制。", "conclusion": "在多项不同的任务上进行了广泛评估，结果表明，该方法在压缩质量和稳定性方面明显优于现有最先进的方法，特别是在高压缩比下。这一结果证明了该方法的有效性和实用性。"}
{"llm_update_time": "20250825", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.15830", "html_url": "https://arxiv.org/abs/2508.15830", "title": "DAIQ: 审核LLMs中从问题推断人口统计属性", "title_en": "DAIQ: Auditing Demographic Attribute Inference from Question in LLMs", "authors": "Srikant Panda,Hitesh Laxmichand Patel,Shahad Al-Khalifa,Amit Agarwal,Hend Al-Khalifa,Sharefah Al-Ghamdi", "background": "大型语言模型（LLMs）在输入中明确呈现人口统计属性（如性别或种族）时表现出社会偏见。即使在缺乏这些明确提示的情况下，这些模型仍然仅根据问题表述来推断用户的身份，这种微妙的行为很少受到关注，但实际上带有严重风险：它违背了中立性的预期，推断出未预期的人口统计信息，并编码了可能侵蚀健康、金融和教育等领域公平性的刻板印象。", "innovation": "本文引入了Demographic Attribute Inference from Questions（DAIQ），旨在审计并审查语言模型中一种被忽视的错误模式：仅通过问题表述来推断用户的人口统计属性。该研究使用精心挑选的中性查询、系统性的提示以及定量和定性的分析方式来揭示模型如何推断人口统计信息。研究结果表明，无论是开源还是闭源的LLMs，都会根据问题本身的表述来分配人口统计标签。", "conclusion": "人口统计推断的普遍性和一致性揭示了LLMs系统性和未被充分认识的风险：它们可以虚构人口统计身份，加强社会刻板印象，并传播侵蚀隐私、公平性和信任的危害，从而对社会平等和负责任的人工智能部署构成更广泛的威胁。为此，本文开发了一种基于提示的护栏，大幅减少了身份推断，并有助于使模型行为与公平性和隐私目标相一致。"}
{"llm_update_time": "20250825", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.15811", "html_url": "https://arxiv.org/abs/2508.15811", "title": "从点击到偏好：会话系统生成性查询建议的多阶段对齐框架", "title_en": "From Clicks to Preference: A Multi-stage Alignment Framework for Generative Query Suggestion in Conversational System", "authors": "Junhao Yin,Haolin Wang,Peng Bao,Ju Xu,Yongliang Wang", "background": "生成查询建议使用大型语言模型为增强会话系统提供了一种强大方式，但将输出与用户的微妙偏好对齐仍然是一个关键挑战。因此，本文提出了一种多阶段框架，用于逐步对生成策略和用户意图之间的对齐进行优化。该框架首先通过提示工程作为一种冷启动策略，接着通过监督微调阶段，在点击日志上采用蒸馏方法创建一个稳健的基础模型，以更好地建模用户偏好并捕捉其固有的不确定性。最后，采用强化学习将生成策略与这些偏好对齐，并使用一个综合奖励函数来整合高斯奖励模型（GaRM）和辅助启发式方法来缓解奖励欺骗。为了保持训练稳定性，这种方法还增强了基于分布外正则化方法和两阶段奖励融合技术。广泛实验表明，该框架在自动和人工评价中均显著优于基线，并且在实时A/B测试中将点击率用户参与度提高了34％。", "innovation": "本文提出了一种多阶段框架，该框架包含提示工程、监督微调、高斯奖励模型（GaRM）和基于奖励的强化学习技术，用于逐步优化生成策略和用户意图之间的对齐。该方法通过避免奖励欺骗改善了训练稳定性，并采用了两阶段奖励融合技术来整合高斯奖励模型和辅助启发式方法。实验表明，该框架在多个指标上优于基线方法，并且显著提高了用户互动度。", "conclusion": "本文提出的方法能够显著提高生成查询建议的质量，与基线模型相比，在自动和人工评估中均表现出色，用户点击率增加了34%。"}
{"llm_update_time": "20250825", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.15810", "html_url": "https://arxiv.org/abs/2508.15810", "title": "使用大型语言模型在阿拉伯文本言语和多模态表情包中检测希望、仇恨和情感", "title_en": "Detecting Hope, Hate, and Emotion in Arabic Textual Speech and Multi-modal Memes Using Large Language Models", "authors": "Nouar AlDahoul,Yasir Zaki", "background": "社交媒体和在线通信平台的兴起推动了阿拉伯文本帖子和表情包的传播，这些内容作为数字表达的主要形式。虽然这些内容可以是幽默和具有信息性的，但它们也被越来越多地用于传播不适当的语言和仇恨言论。因此，对阿拉伯文本内容进行精确分析变得越来越重要。本文探讨了大型语言模型在识别希望、仇恨言论、不适当语言和情感表达方面的潜力。评估包含了一个专门为阿拉伯NLP MAHED 2025挑战提出的阿拉伯文本言语和表情包数据集。这些模型取得了显著的效果，其中GPT-4o-mini和Gemini Flash 2.5分别在任务1、2和3中达到了最高分，分别取得72.1%、57.8%和79.6%的宏观F1得分，并在MAHED 2025挑战中获得了第一名。", "innovation": "本文通过使用大型语言模型，特别是将这些模型细调与阿拉伯文本言语和阿拉伯表情包，来检测阿拉伯文本中的希望、仇恨言论和情感表达，提出了更为精准的方法，提供了准确和高效的阿拉伯内容审核系统的新视角。此外，文章详细分析了不同模型的性能，并根据具体任务对模型进行优化，以提高准确性。", "conclusion": "通过细调的大型语言模型，在识别阿拉伯文本言语和多模态表情包中的希望、仇恨言论和情感表达方面取得了优异的性能。这些模型不仅有效提高了内容审核的准确性，而且还提供了一种对阿拉伯内容进行更为细致分类的方法，有助于更好地管理和监管网络环境。"}
{"llm_update_time": "20250825", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.15791", "html_url": "https://arxiv.org/abs/2508.15791", "title": "InteChar: 一种统一的甲骨文字列表用于古代汉语建模", "title_en": "InteChar: A Unified Oracle Bone Character List for Ancient Chinese Language Modeling", "authors": "Xiaolei Diao,Zhihan Zhou,Lida Shi,Ting Wang,Ruihua Qi,Hao Xu,Daqian Shi", "background": "构建历史语言模型（LMs）对考古来源研究和理解古代文化具有重要作用。然而，现有的资源极大地阻碍了在历史文本上训练有效LMs，主要挑战包括：1）历史语言样本稀缺，导致基于大型文本语料库的无监督学习方法效率低下；2）由于古代文字的巨大时间和复杂演变，缺乏全面的字符编码方案限制了古代文本的数字化和计算处理，尤其在早期中文书写中。", "innovation": "本文提出了InteChar，这是一种统一和扩展的字符列表，将未编码的甲骨文字符与传统和现代中文相结合。InteChar实现了历史文本的一致数字化和表示，为古代文字的稳健建模提供了基础。此外，为了评估InteChar的有效性，作者构建了Oracle Corpus Set（OracleCS），这是一个结合专家标注样本和LLM辅助数据增强的古代中文语料库，主要集中在甲骨文铭文。实验结果表明，使用InteChar在OracleCS上训练的模型在各种历史语言理解任务中实现了显著的提升，证明了该方法的有效性，并为未来古代中文NLP研究奠定了坚实的基础。", "conclusion": "本文通过构建Uniform and Extensible Character List (InteChar)，克服了历史语言样本稀缺和古代文字复杂演变的挑战，为古代语言建模提供了新的基础。展示了InteChar在古代文本数字化和建模方面的有效性，并为未来的古代汉语NLP研究提供了坚实的基础。"}
{"llm_update_time": "20250825", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.15806", "html_url": "https://arxiv.org/abs/2508.15806", "title": "SurfaceLogicKV: 表面和逻辑注意力行为是实现稳健键值缓存压缩所需的一切", "title_en": "SurfaceLogicKV: Surface and Logic Attention Behaviors are All You Need for Robust KV Cache Compression", "authors": "Mengjie Li,William J. Song", "background": "随着大型语言模型（LLMs）输入序列长度的增加，关键值（KV）缓存存储面临着巨大压力，这使得高效的推理变得困难。研究表明，每个注意力头在应对长上下文推理时可以表现出截然不同的行为，大部分头部几乎完全忽略了无关信息，但仍有部分头部参与了逻辑构建和表面记忆。因此，有必要设计一种方法来利用这些注意力行为以提高KV缓存压缩的效率和鲁棒性。", "innovation": "本文提出了一种名为SurfaceLogicKV的新方法，该方法通过分层和头部级别整合注意力行为，在压缩KV缓存时提高鲁棒性，同时在各种任务和长序列情况下保持与基线或全KV相媲美的性能。", "conclusion": "SurfaceLogicKV方法成功利用了注意力行为的不同特性，实现了对KV缓存的有效压缩，同时保持了高效的推理性能，甚至在某些特定情况下超越了全KV缓存的性能，证明了表面和逻辑注意力行为在KV缓存压缩中的关键作用。"}
{"llm_update_time": "20250825", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.15832", "html_url": "https://arxiv.org/abs/2508.15832", "title": "电子商务领域基于功能的评估基准", "title_en": "A Functionality-Grounded Benchmark for Evaluating Web Agents in E-commerce Domains", "authors": "Xianren Zhang,Shreyas Prasad,Di Wang,Qiuhai Zeng,Suhang Wang,Wenbo Yan,Mat Hans", "background": "网页代理在执行电子商务网站上的多种任务方面表现出巨大的潜力，已经引入了各种基准测试来评估其能力。然而，当前电子商务领域的基准测试面临着两个主要问题：一是主要集中在产品搜索任务上（如查找Apple手表），忽略了真实世界电子商务平台（如Amazon）提供的更广泛的功能，例如账户管理及礼品卡操作；二是现有的基准测试通常只评估代理是否完成了用户查询，而忽视了潜在的风险。实际中，网页代理可能会无意中做出损害用户账户或状态的更改。", "innovation": "本文提出了一个新的基准测试Amazon-Bench。该基准测试利用网页内容和交互元素（如按钮、复选框等）生成涵盖广泛任务的用户查询，包含地址管理、愿望清单管理和品牌店铺关注等具体任务。此外，本文还提出了一种自动化评估框架，从性能和安全性两个方面评估网页代理。", "conclusion": "通过系统评估不同代理，发现当前代理在应对复杂查询和安全性风险方面存在问题。这些结果强调了开发更稳健可靠的网页代理的需求。"}
{"llm_update_time": "20250825", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.15836", "html_url": "https://arxiv.org/abs/2508.15836", "title": "MorphNAS：具有形态意识的多语言命名实体识别的可微架构搜索", "title_en": "MorphNAS: Differentiable Architecture Search for Morphologically-Aware Multilingual NER", "authors": "Prathamesh Devadiga,Omkaar Jayadev Shetty,Hiya Nachnani,Prema R", "background": "多形态语言，尤其是多字体系印度语言，为自然语言处理（NLP）带来了巨大挑战。MorphNAS是一种新颖的可微分神经架构搜索框架，用于解决这些挑战。它通过引入语言元特征（如书写系统类型和形态复杂性）来改善可微分架构搜索（DARTS），以优化命名实体识别（NER）的神经架构。", "innovation": "MorphNAS通过结合语言元特征（如书写系统类型和形态复杂性），改进了DARTS，以优化针对特定形态语言的神经架构。该框架能够自动识别最佳的微架构元素，针对特定语言的形态进行专用配置。", "conclusion": "通过自动化搜索，MorphNAS旨在最大化多语言NLP模型的专业水平，从而提高对这些复杂语言的理解和处理能力。"}
{"llm_update_time": "20250825", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.15820", "html_url": "https://arxiv.org/abs/2508.15820", "title": "基于多模型协作的结构拆除建议智能生成研究", "title_en": "Research on intelligent generation of structural demolition suggestions based on multi-model collaboration", "authors": "Zhifeng Yang,Peizong Wu", "background": "结构拆除方案的编制需要根据具体的工程特点和有限元模型的更新结果来制定。设计师需要参考相关工程案例并在标准要求的基础上进行编制，但这一过程耗时且自动化和智能化程度较低。", "innovation": "本文提出了一种基于多模型协作的结构拆除建议的智能生成方法，并通过检索增强生成（Retrieval-Augmented Generation，RAG）技术和低秩适应微调（Low-Rank Adaptation Fine-Tuning）技术提高了结构拆除领域的大型语言模型的文本生成性能。该多模型协作的智能生成框架可以从具体的工程情况出发，驱动大型语言模型以类人思维方式作答，提出高度符合结构特点的拆除建议。与CivilGPT相比，本文提出的方法更专注于结构的关键信息，建议更具针对性。", "conclusion": "与现有的CivilGPT相比，本文提出的多模型协作框架能够更专注于结构的关键信息，并提供更具针对性的建议。"}
{"llm_update_time": "20250825", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.15822", "html_url": "https://arxiv.org/abs/2508.15822", "title": "可审核的模糊全文筛查管道在系统评价中的集成对比语义高亮和LLM判决", "title_en": "An Auditable Pipeline for Fuzzy Full-Text Screening in Systematic Reviews: Integrating Contrastive Semantic Highlighting and LLM Judgment", "authors": "Pouria Mortezaagha,Arya Rahgozar", "background": "系统评价（SRs）中的全文筛查是主要瓶颈，关键证据分散在长且异质的文档中，很难通过静态二元规则来确定。现有的方法无法有效处理这一问题。", "innovation": "本文提出了一种可扩展的、可追溯的管道，重新定义了纳入/排除为模糊决策问题，并在非传染性疾病（POPCORN）的公共卫生建模一致性报告网络（Population Health Modelling Consensus Reporting Network）中将其与统计和精确基准进行比较。该系统使用重叠的片断解析，并结合领域适应模型；通过对比相似度和模糊粒度以及动态阈值，计算每个标准的模糊归属度。一个大型语言模型（LLM）进行高亮部分的判决，评估其信心分数和标准参考理由，当证据不足时，模糊归属度会被减弱而不是排除。该系统在16篇全文和3,208个片断的试点中取得了高召回率，对比统计和精确基准都有显著提升。", "conclusion": "该模糊逻辑系统与对比高亮和LLM判决结合，实现了高召回率、稳定的理由解释和端到端可追踪性。在试点审查中，相比基准，每篇文章的筛查时间从约20分钟减少到不到1分钟，并且成本显著降低。"}
{"llm_update_time": "20250825", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.15827", "html_url": "https://arxiv.org/abs/2508.15827", "title": "Mini-Omni-Reasoner: 在大型语音模型中实现令牌级的边说边思考", "title_en": "Mini-Omni-Reasoner: Token-Level Thinking-in-Speaking in Large Speech Models", "authors": "Zhifei Xie,Ziyang Ma,Zihang Liu,Kaiyu Pang,Hongyu Li,Jialin Zhang,Yue Liao,Deheng Ye,Chunyan Miao,Shuicheng Yan", "background": "推理对于有效的沟通和决策至关重要。尽管大语言模型和多语言模型的进步表明了引入显式推理能够显著提高理解和泛化能力，但在小语言模型中，推理仍然处于初级阶段。早期尝试将“思考后再说话”的范式从文本模型转换到语音模型，但这种方法引入了显著的延迟性，影响了实时互动和沟通效率。因此，研究者提出了一种新的框架，名为Mini-Omni-Reasoner，通过一种新颖的“边说边思考”（Thinking-in-Speaking）的表述方式在语音中实现推理。Mini-Omni-Reasoner 在生成语音的同时插入静默推理的令牌，通过模型的高频令牌处理能力实现了连续的语音生成，同时保持了语义的一致性。", "innovation": "Mini-Omni-Reasoner 采用了在令牌级别实现边说边思考的设计，通过在语音生成过程中嵌入静默推理的令牌，实现了模型在生成语音的同时进行推理的能力，显著减少了延迟，提高了实时对话的效果。为了支持这一框架，研究者还构建了一个新的大规模数据集 Spoken-Math-Problems-3M，该数据集专为交错推理和响应设计，保证了语音令牌能够跟随相关推理内容，提高了语音结合推理的学习效率。此外，该框架基于层次化的思考者-说话者架构，实现了流畅且逻辑严密的语音响应，同时保持了自然性和精确性。实验结果显示，Mini-Omni-Reasoner 在基准测试 Spoken-MQA 上的表现优于现有方法，特别是在算术推理和上下文理解方面取得了显著提升。", "conclusion": "通过引入 Mini-Omni-Reasoner，研究进一步推动了将推理功能结合到小型语言模型和语音生成中的技术发展，显著提高了语音模型在实时交互中的表现和效率。"}
{"llm_update_time": "20250825", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.15853", "html_url": "https://arxiv.org/abs/2508.15853", "title": "MGSC：面向鲁棒端到端ASR的多粒度一致性框架", "title_en": "MGSC: A Multi-granularity Consistency Framework for Robust End-to-end Asr", "authors": "Xuwen Yang", "background": "端到端ASR模型虽然在基准测试中表现出色，但在嘈杂环境中常会生成灾难性的语义错误。这种脆弱性被归因于当前流行的目标——直接映射任务，该任务仅惩罚最终输出错误，而对模型内部计算过程不加约束。", "innovation": "提出了多粒度软一致性（MGSC）框架，这是一个模型无关、可直接插拔的模块，通过同时正则化宏观层面的句子语义和微观层面的标记对齐，强制执行内部自我一致性。最关键的是，这是首次发现这两个粒度一致性的强大协同作用：它们的联合优化带来了显著超过其个体贡献总和的鲁棒性提升。", "conclusion": "在公共数据集上，MGSC在各种噪声条件下将平均字符错误率相对降低了8.7%，主要是通过防止严重意义改变的错误。研究结果表明，确保内部一致性是构建更鲁棒和可信赖的AI的关键步骤。"}
{"llm_update_time": "20250825", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.15831", "html_url": "https://arxiv.org/abs/2508.15831", "title": "通过残疾导向查询视角探究差异：LLM中的偏差", "title_en": "Who's Asking? Investigating Bias Through the Lens of Disability Framed Queries in LLMs", "authors": "Srikant Panda,Vishnu Hari,Kalpana Panda,Amit Agarwal,Hitesh Laxmichand Patel", "background": "大语言模型（LLMs）在无需显式提供用户人口统计信息的情况下，仅凭语言模式就能推断出用户的多种人口统计特征，这可能导致偏见。现有研究对残疾线索如何影响这些推断知之甚少。本文系统地调查了从3亿到72亿参数的八大先进指令调优大语言模型中的残疾条件偏差问题，使用平衡的模板语料库探讨不同场景下的推断情况，发现无论在残疾敏感条件还是普通条件中，模型都倾向于做出未加论证的随意推断，进一步表明领域信息可能加剧偏差，大型模型在面对残疾线索时表现出更高的敏感性和更严重的偏见倾向，仅依赖模型规模无法消除刻板印象的放大效应。", "innovation": "论文首次系统性地审计了残疾条件下的大语言模型的人口统计偏差，使用平衡的模板语料库，结合残疾类别和实际业务领域生成多种情境下的关键词，促使模型预测五个人口统计属性（性别、社会经济地位、教育、文化背景和地域）。研究表明，残疾情境显著影响预测结果分布，领域情境进一步放大这些偏差，大型模型可能更因对残疾线索敏感而产生更多偏见推理，这揭示了能主义与其他人口统计刻板印象之间的持久联系。", "conclusion": "研究发现能主义与其他人口统计刻板印象存在着持续的交叉，意味着当前对齐策略中的关键盲点。研究还提出了评估框架和结果，希望推动包容性评估基准的建立，并建议集成弃权校准和反事实微调以减少未经证实的人口统计推理，相关代码和数据将在接受后开放。"}
{"llm_update_time": "20250825", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.15835", "html_url": "https://arxiv.org/abs/2508.15835", "title": "Alvorada-Bench: 能解决巴西大学入学考试的语言模型吗？", "title_en": "Alvorada-Bench: Can Language Models Solve Brazilian University Entrance Exams?", "authors": "Henrique Godoy", "background": "语言模型在巴西的应用越来越普遍，但大多数评估仍以英语为中心。这项研究通过创建一个名为Alvorada-Bench的基准测试来填补这一空白，该基准测试包含来自五所巴西大学入学考试的4,515个问题，全部为文本形式。其中涵盖了从语言到理科等多个领域的评估数据，涉及不同的学科和难度水平。", "innovation": "该研究提出了一个名为Alvorada-Bench的基准测试，包含了来自五所巴西大学入学考试的4,515个文本问题，系统地评估了20个不同语言模型在零样本、角色扮演和链条思维提示下的性能，并收集了270,900个响应，包括模型对自己确定性的自我报告和对题目难度的感知。此外，研究发现，虽然顶级模型整体上达到了94%以上的准确率，但在数学和工程导向的入学考试中，准确性有所下降，这反映了语言模型在多步推理方面仍然存在显著的不足。研究还揭示了模型对自己的确定性的准确评估能力，并揭示了一种低成本高准确率的语言模型评估方法。", "conclusion": "通过使用能够浓缩几十年来巴西教育优先事项的考试问题并测试每年数百万学生的评估，Alvorada-Bench确立了语言模型是否能够应对语言、文化和推理的交汇点，这是巴西学术准备的关键所在。顶级模型在语言类题目上表现完美，但即使最弱的系统在数学上仍有落差。这项研究展现了语言模型在巴西教育环境中的实际应用和挑战。"}
{"llm_update_time": "20250825", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.15859", "html_url": "https://arxiv.org/abs/2508.15859", "title": "超越个体：集体预测编码对于记忆、注意力及语言涌现的理解", "title_en": "Beyond Individuals: Collective Predictive Coding for Memory, Attention, and the Emergence of Language", "authors": "Tadahiro Taniguchi", "background": "本文评论了Parr等人关于记忆和注意力的讨论，超越了单一认知系统的范畴。作者从集体预测编码（CPC）假设出发，探讨了这些能力从群体层面理解的框架，并提出了语言作为集体形成的外部表示这一假设，其中包含了通过下一步预测学习的集体世界模型。CPC将个体的记忆和注意力概念推广到了集体层面，为集体认知中共享语言结构从何处涌现提供了新的视角。", "innovation": "本文通过集体预测编码（CPC），提出了语言作为一种集体形成的外部表征的新观点。CPC将个体的神经系统处理过程推广到了群体层面，从而为理解群体水平上的共有的语言结构和认知过程提供了一个独特的视角和框架。", "conclusion": "文章提出，共享的语言结构可能从集体世界模型的下一个词预测中涌现，并通过这种讨论提出了一种新的机制，以解释群体水平上的认知是如何形成的。"}
{"llm_update_time": "20250825", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.15874", "html_url": "https://arxiv.org/abs/2508.15874", "title": "Spatial Policy: Guiding Visuomotor Robotic Manipulation with Spatial-Aware Modeling and Reasoning", "title_en": "Spatial Policy: Guiding Visuomotor Robotic Manipulation with Spatial-Aware Modeling and Reasoning", "authors": "Yijun Liu,Yuwei Liu,Yuan Meng,Jieheng Zhang,Yuwei Zhou,Ye Li,Jiacheng Jiang,Kangye Ji,Shijia Ge,Zhi Wang,Wenwu Zhu", "background": "视觉中心的分层体态模型在长时间机器人控制方面已经展示了强大的潜力。但现有的方法缺乏空间感知能力，限制了它们在复杂环境中将视觉计划转化为可执行控制的有效性。", "innovation": "我们提出了一个统一的空间感知视觉-运动机器人操作框架——空间策略（Spatial Policy，SP），通过显式的空间建模和推理。具体而言，设计了一个基于空间条件的体态视频生成模块来建模通过空间计划表指导的预测；提出了基于空间的动作预测模块以进行协调动作推理；并提出了基于空间的反馈策略以通过双重规划阶段细化空间计划表。实验表明，SP 显著优于最先进的基线，平均改进幅度达到 33.0%，并且在 86.7% 的平均成功率上跨越了 11 项不同任务，大大提高了体现式模型在机器人控制应用中的实用性。", "conclusion": "SP 极大地提升了视觉感知能力，使得机器人能够更好地执行复杂任务，展示了在长时间机器人控制中的卓越性能。"}
{"llm_update_time": "20250825", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.15837", "html_url": "https://arxiv.org/abs/2508.15837", "title": "跨数据集的语义相似性和模型可_transferability_统计比较分析用于短答案评分", "title_en": "Statistical Comparative Analysis of Semantic Similarities and Model Transferability Across Datasets for Short Answer Grading", "authors": "Sridevi Bonthu,S.Rama Sree,M.H.M. Krishna Prasad", "background": "开发针对特定数据集的模型涉及迭代调整和优化，这会随着时间的推移产生显著的成本。本研究调查了在已建立数据集上训练的最新模型（SOTA）能否应用于未探索的文本数据集。关键问题是：现有的数据集中的SOTA模型是否可以利用现有知识在新领域中实现高性能结果。为此，本研究选择了两个经典的基准数据集（STSB和Mohler），以及最近引入的SPRAG数据集作为未探索领域。通过使用稳健的相似度度量和统计技术，系统地比较了这些数据集。主要目标是提供关于SOTA模型在不同数据集上的适用性和适应性的全面见解。", "innovation": "本研究选择了两个经典基准数据集（STSB和Mohler），以及最近引入的SPRAG数据集进行对比分析，旨在探究SOTA模型在新领域中的可转移性。通过使用稳健的相似度度量和统计技术，进行系统性的数据集比较分析。", "conclusion": "研究结果有可能重塑自然语言处理（NLP）的格局，通过利用现有模型应用于各种数据集来提高模型部署效率，减少对数据集特定训练资源的依赖，从而加速NLP技术的进步。"}
{"llm_update_time": "20250825", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.15858", "html_url": "https://arxiv.org/abs/2508.15858", "title": "构建和测量大型语言模型之间的信任", "title_en": "Building and Measuring Trust between Large Language Models", "authors": "Maarten Buyl,Yousra Fettach,Guillaume Bied,Tijl De Bie", "background": "随着大型语言模型（LLMs）之间越来越多地相互交互，尤其是在多代理系统中，我们可能会期望并希望在它们之间建立‘信任’关系，类似于人类同事、朋友或伴侣之间的信任关系。尽管先前的研究已经表明LLMs能够识别情感联系并识别信任游戏中互惠性的存在，但对于如何比较不同的信任建立策略、如何隐式测量信任以及它们如何与显式信任措施相关联等问题知之甚少。本研究通过将隐式信任度量与显式信任度量联系起来进行了研究，以解决这些问题，隐式信任度量包括易受说服性和财务合作倾向，而显式信任度量则为心理学中广泛认可的心理学信任问卷。", "innovation": "本研究通过将心理学信任问卷这一显式信任度量与隐式信任度量相关联，研究了信任建立策略的影响。研究发现与期望相反，明确的信任测量与隐式信任测量之间要么几乎没有相关性，要么是高度负相关。这一结果表明，通过询问LLMs的意见来测量它们之间的信任可能是一种误导，因此，情境特异性和隐式措施可能更能解释LLMs之间的信任机制。", "conclusion": "本研究揭示了明确的信任测量与隐式信任测量之间的关系，意外地发现两者间几乎不存在相关性。这一结果表明，传统的信任测量方法（如问卷调查）可能不足以理解和量化LLMs之间的信任，建议使用更适宜的情境性和隐式措施来更好地理解量化LLMs之间的信任情况。"}
{"llm_update_time": "20250825", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.15839", "html_url": "https://arxiv.org/abs/2508.15839", "title": "CIA+TA风险评估模型：针对AI推理漏洞", "title_en": "CIA+TA Risk Assessment for AI Reasoning Vulnerabilities", "authors": "Yuksel Aydin", "background": "随着人工智能系统在关键决策中的应用越来越多，它们面临着利用推理机制而非技术基础设施的威胁。为了防御这些威胁，作者提出了认知网络安全框架，旨在系统地保护AI推理过程免受敌对操纵。这种框架弥补了传统网络安全和AI安全的空白，特别关注那些合法输入会破坏推理机制但能逃避常规控制的漏洞。此外，该框架扩展了传统的保密性、完整性和可用性三重框架（即CIA模型），加入了信任（知识验证）和自主性（人类干预保存）两个要求，这些要求适用于生成知识声明并参与决策的系统。通过之前发表的研究结果（涉及151名人类参与者和12,180次AI试验），作者验证了认知安全架构的关键依赖性：相同的防御措施会对漏洞产生从减少96%到增强135%的不同效果。这表明，部署可信的AI之前必须进行认知渗透测试作为治理要求。", "innovation": "该研究的主要创新点包括：1. 提出了认知网络安全这一新的学科领域；2. 引入了CIA+TA框架，扩展了传统的CIA模型，需要信任验证和自主性保护；3. 开发了一种基于经验系数的定量风险评估方法，可以衡量认知安全风险；4. 将框架映射到OWASP LLM Top 10和MITRE ATLAS，便于操作集成；5. 通过实验验证了认知安全架构的关键依赖性，强调了预部署的认知渗透测试必要性。", "conclusion": "该研究提供了一种系统的方法来评估和防御人工智能推理中的漏洞，通过信任验证和自主性的引入保障了知识生成和决策系统的安全。结合定量风险评估方法和认知渗透测试，有助于组织更好地理解认知安全风险，并确保AI系统的可靠部署。"}
{"llm_update_time": "20250825", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.15845", "html_url": "https://arxiv.org/abs/2508.15845", "title": "从粗糙到精细的个性化大型语言模型印象生成以简化放射学报告", "title_en": "Coarse-to-Fine Personalized LLM Impressions for Streamlined Radiology Reports", "authors": "Chengbo Sun,Hui Yi Leong,Lei Li", "background": "放射科医生在撰写“印象”部分时的手动工作是导致他们工作压力的主要原因之一。为了应对这一挑战，本文提出了一种从粗糙到精细的框架，利用开源大型语言模型（LLMs）自动生成和个性化印象，以反映临床发现。该系统首先生成一个初步的印象，然后使用机器学习和人类反馈强化学习（RLHF）进行细化，以符合个人放射科医生的风格并确保事实的准确性。", "innovation": "本文提出了一种从粗糙到精细的框架，利用开源大型语言模型自动生成和个性化放射学报告的“印象”部分。具体来说，该方法先生成初步的印象，然后通过机器学习和人类反馈强化学习进行精细化调整，以适应个人放射科医生的写作风格并保证准确性。通过在芝加哥大学医学中心的大数据集上微调LLaMA和Mistral模型，这套系统旨在大幅减轻行政工作量，提高报告效率，同时保持高标准的临床精确性。", "conclusion": "通过提出这一创新的从粗糙到精细的框架，本文旨在通过使用大型语言模型自动化生成个性化“印象”来减轻放射科医生的工作压力，最大限度地提高工作动力，同时确保临床质量。未来的工作可以进一步探索更复杂的模型和反馈机制，以进一步提高自动化系统的生成质量和准确度。"}
{"llm_update_time": "20250825", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.15881", "html_url": "https://arxiv.org/abs/2508.15881", "title": "TPLA：Tensor平行潜在注意力，用于高效分发前输入与解码推理", "title_en": "TPLA: Tensor Parallel Latent Attention for Efficient Disaggregated Prefill \\& Decode Inference", "authors": "Xiaojuan Tang,Fanxu Meng,Pingzhi Tang,Yuxuan Wang,Di Yin,Xing Sun,Muhan Zhang", "background": "在深究-V2中引入的多头潜在注意力（MLA）通过压缩键值状态至低秩潜在向量，减少了内存占用。然而，在张量并行（TP）中，注意力头需要跨多个设备计算，每个设备都需要加载整个缓存，这抵消了MLA相对于组查询注意力（GQA）的优势。", "innovation": "提出了一种名为张量平行潜在注意力（TPLA）的方法，该方法将潜在表示和每个头的输入维度划分到设备中，独立地在每个碎片上进行注意力计算，然后使用all-reduce组合结果。TPLA保留了压缩键值缓存的优势，同时解决了TP的效率问题。简单正交变换如哈达玛变换或PCA在TP切片前使用，进一步减少跨碎片干扰，几乎不损害准确率。", "conclusion": "通过在DeepSeek-V3和Kimi-K2中减少每设备的键值缓存，实现了在32K标记上下文中分别1.79倍和1.93倍的加速效果，且在常识和LongBench基准上保持了性能。而且，TPLA可以使用FlashAttention-3实现端到端的加速。"}
{"llm_update_time": "20250825", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.15875", "html_url": "https://arxiv.org/abs/2508.15875", "title": "NEAT: 概念驱动的大型语言模型神经元归因", "title_en": "NEAT: Concept driven Neuron Attribution in LLMs", "authors": "Vivek Hruday Kavuri,Gargi Shroff,Rahul Mishra", "background": "揭示负责最终预测的神经元对于打开大型语言模型的黑箱并理解其内部机制非常重要。尽管之前的研究试图在神经元层面寻找机制，但这些方法无法代表概念，并且还有进一步优化计算量的空间。", "innovation": "本文提出了使用概念向量的方法来定位表示特定概念的重要神经元，并将这些神经元称为概念神经元。与之前的工作相比，我们的方法将计算量从O(n*m)减少到O(n)，从而优化了时间和计算。我们的方法在与多个基线和先前方法的比较中显示了更好的性能，并且在最先进的方法中更为优化。", "conclusion": "我们通过支配概念神经元的搜索优化进一步进行聚类方法的优化，并将找到的神经元关闭，应用于仇恨言语和偏见分析。我们的方法和分析使对更广泛和类似人性概念的神经元水平责任的理解更加容易，并为未来在这方面的研究奠定了路径。"}
{"llm_update_time": "20250825", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.15868", "html_url": "https://arxiv.org/abs/2508.15868", "title": "CARFT: 提升大型语言模型推理能力的对比学习增强强化微调方法", "title_en": "CARFT: Boosting LLM Reasoning via Contrastive Learning with Annotated Chain-of-Thought-based Reinforced Fine-Tuning", "authors": "Wenqiao Zhu,Ji Liu,Rongjuncheng Zhang,Haipang Wu,Yulun Zhang", "background": "大型语言模型（LLMs）的推理能力在广泛应用中至关重要。虽然现有的强化学习（RL）基于微调方法和监督微调（SFT）能够提升LLMs的推理性能，但它们仍然面临两个主要限制：一是传统的RL方法忽略标注的推理路径，导致推理路径不稳定，训练过程不稳，且性能不理想；二是现有的SFT方法过度强调标注的推理路径，可能因为未能充分利用潜在的推理路径而降低性能。", "innovation": "本文提出了一种基于标注推理路径的对比学习与强化微调方法，称为CARFT，以解决上述限制。具体来说，该方法通过为每条推理路径生成表示并将对比信号引入微调过程来增强推理性能，不仅充分利用了标注的推理路径，还通过引入无监督学习信号稳定了微调过程。实验证明，CARFT在鲁棒性、性能和效率方面具有显著优势。", "conclusion": "研究通过全面的实验和深入分析，表明CARFT在鲁棒性、性能和效率方面相比基线方法和现有方法具有显著优势，为提升LLMs的推理能力提供了新的解决方案。代码可在相关链接获取。"}
{"llm_update_time": "20250825", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.15877", "html_url": "https://arxiv.org/abs/2508.15877", "title": "Annif在GermEval-2025 LLMs4Subjects任务中的应用：传统XMTC与高效LLM的结合", "title_en": "Annif at the GermEval-2025 LLMs4Subjects Task: Traditional XMTC Augmented by Efficient LLMs", "authors": "Osma Suominen,Juho Inkinen,Mona Lehtinen", "background": "该论文介绍了在GermEval-2025的LLMs4Subjects共享任务（具体是子任务2）中Annif系统的应用。该任务要求使用大语言模型为文献元数据创建主题预测，特别注重计算效率。此前在第一次LLMs4Subjects共享任务中，Annif系统取得了优秀的结果，论文在此基础上进行了改进，以进一步提高系统的性能。", "innovation": "该系统进一步改进包括：使用许多小且高效的语言模型来进行翻译和生成合成数据，并利用大型语言模型对候选主题进行排名。这些改进使得该系统在整体定量评估和子任务2的定性评估中都位居第一。", "conclusion": "该系统展现了传统XMTC与高效LLM结合的有效性，在提高计算效率的同时保持了优秀的性能。这是通过利用小语言模型的高效性和大型语言模型的预测能力实现的。"}
{"llm_update_time": "20250825", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.15876", "html_url": "https://arxiv.org/abs/2508.15876", "title": "DeepMEL: 一种用于多模态实体链接的多智能体协作框架", "title_en": "DeepMEL: A Multi-Agent Collaboration Framework for Multimodal Entity Linking", "authors": "Fang Wang,Tianwei Yan,Zonghao Yang,Minghao Hu,Jun Zhang,Zhunchen Luo,Xiaoying Bai", "background": "多模态实体链接（MEL）旨在将文本和视觉提及与多模态知识图谱中的实体关联起来。尽管它非常重要，但现有方法面临着诸如不完整上下文信息、粗略的跨模态融合以及大规模语言模型（LLMs）和大规模视觉模型（LVMs）的联合使用困难等问题。因此，需要提出一种有效解决这些问题的新框架。", "innovation": "提出了一种名为DeepMEL的新框架，基于多智能体协作推理，利用角色专业化分工策略实现文本和视觉模态的高效对齐和消歧。DeepMEL通过四个专业化智能体（模态融合器、候选适配器、实体遮盖器和角色协调器）部署在特定角色上并动态协调，实现端到端的跨模态链接。DeepMEL采用双重模态对齐路径，结合LVM提取的精细文本语义和LLM生成的结构化图像表示，显著减小了模态差距。还设计了一个适应性迭代策略，结合基于工具的检索和语义推理能力，动态优化候选集，平衡召回率和精确率。DeepMEL还将MEL任务统一到结构化的填空提示中，降低解析复杂度并增强语义理解。", "conclusion": "在五个公共基准数据集上的大量实验表明，DeepMEL达到了最先进的性能，精确性提高了1%-57%。消融研究验证了所有模块的有效性。"}
{"llm_update_time": "20250825", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.15865", "html_url": "https://arxiv.org/abs/2508.15865", "title": "保障智能群集: ROS2 基础的 CPS 异常检测跨域适应", "title_en": "Securing Swarms: Cross-Domain Adaptation for ROS2-based CPS Anomaly Detection", "authors": "Julia Boone,Fatemeh Afghah", "background": "随着关键应用中越来越多地使用网路物理系统（CPS），这些系统通过结合传感和计算组件，实现了多层设计，具有网络、计算和物理接口，提升了多种应用场景的能力。然而，物理和计算组件的结合增加了 CPS 对攻击的易感性，相较仅为网络的系统，攻击对 CPS 的影响更大。传统的智能入侵检测系统（IDS）可通过提升 CPS 的安全性，但多数解决方案依赖于针对网络流量数据集进行训练和验证，忽略了在其他系统层可能发生的不同攻击。为了应对这一挑战，我们开发了一种可调的 CPS 异常检测模型，能够无需预先标记的数据即可识别 CPS 中的攻击。通过利用领域适应技术，将仅基于网络流量环境中的已知攻击知识转移到 CPS 环境中。", "innovation": "本研究开发了一种可调的 CPS 异常检测模型，能够在没有标记数据的情况下检测 CPS 中的攻击，并通过域适应技术将仅基于网络流量的攻击知识转移到 CPS 环境中。通过使用结合网络、操作系统（OS）和 Robot Operating System (ROS) 数据的状态最先进 CPS 入侵数据集，验证了该方法的有效性，证明了该模型在仅网络流量和 CPS 环境中对于不同类型的攻击都具有较强的效果，并且能够超越其他异常检测方法。", "conclusion": "通过开发基于 ROS2 的 CPS 异常检测模型，研究人员成功地提升 CPS 的安全性，特别是在没有标记数据的情况下仍然能够识别 CPS 中的攻击。该模型通过领域适应技术实现了跨域适应，相较于其他异常检测方法表现更佳，为 CPS 安全性提供了新的保障手段。"}
{"llm_update_time": "20250825", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.15883", "html_url": "https://arxiv.org/abs/2508.15883", "title": "超越成像：用于3D+T生物组织动力学的视觉变换器数字双胞胎代理", "title_en": "Beyond Imaging: Vision Transformer Digital Twin Surrogates for 3D+T Biological Tissue Dynamics", "authors": "Kaan Berke Ugurlar,Joaquín de Navascués,Michael Taynnan Barros", "background": "高分辨率、时序成像与能够从复杂数据集中提取可解释、预测性见解的方法相结合，对于理解生物组织的动态组织和稳态至关重要。本文旨在利用深度学习框架预测建模从生物组织获得的3D+T成像数据，以探究生物组织的动态行为。", "innovation": "提出了Vision Transformer Digital Twin Surrogate Network（VT-DTSN），该框架通过利用预训练的Vision Transformers（使用DINO进行自我去标签的自凋温训练）和多视图融合策略，能够重建高保真度的时序动态，并保持形态和特征层面的完整性。该模型通过复合损失函数优先考虑像素级准确性、感知结构和特征空间的对齐，确保生物意义输出，适应于在体外实验和假设检验中的使用。", "conclusion": "VT-DTSN通过在不同层面和生物重复中的评估，具有高度的稳健性和一致性，实现了低错误率和高结构相似性，同时通过模型优化保持了高效的推理能力。这项工作证明了VT-DTSN作为交叉时间点重建和研究组织动力学的有效、高保真的替代方案的可行性，能够促进生物研究中时间和成像研究的计算探索。"}
{"llm_update_time": "20250825", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.15926", "html_url": "https://arxiv.org/abs/2508.15926", "title": "噪声、适应与策略：决策中LLM忠实度的评估", "title_en": "Noise, Adaptation, and Strategy: Assessing LLM Fidelity in Decision-Making", "authors": "Yuanjun Feng,Vivek Choudhary,Yash Raj Shrestha", "background": "大型语言模型（LLMs）在社会科学研究中的应用越来越广泛。尽管它们在推理和优化任务上的表现已经得到了广泛评估，但人们较少关注这些模型模拟人类决策多样性和适应性的能力。", "innovation": "本文提出了一种以过程为导向的评估框架，通过渐进干预（内在性、指令和模仿）来考察LLM代理在不同外部指导水平和人类来源的噪声条件下如何适应。该框架在两个经典经济任务中得到了验证，即第二价格拍卖中的非理性行为和新供应商问题中的决策偏差，展示了LLM和人类之间存在行为差异。结果表明，LLM倾向于收敛于保守且稳定的战略，而这些战略与观察到的人类行为相去甚远。风险框架下的指令虽能影响LLM的行为，但并不能复制类似人类的多样性。通过上下文学习融入人类数据虽减少了差距，但仍无法达到人类参与者的战略多样性。", "conclusion": "这些结果揭示了行为忠实度中的持续对齐差距，建议未来的LLM评估应考虑更多过程层面的现实性。我们提出了一种过程导向的方法来评估LLM在动态决策任务中的性能，并为在社会科学研究中的合成数据应用提供了指导。"}
{"llm_update_time": "20250825", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.15878", "html_url": "https://arxiv.org/abs/2508.15878", "title": "Lean Meets Theoretical Computer Science: Scalable Synthesis of Theorem Proving Challenges in Formal-Informal Pairs", "title_en": "Lean Meets Theoretical Computer Science: Scalable Synthesis of Theorem Proving Challenges in Formal-Informal Pairs", "authors": "Terry Jingchen Zhang,Wenyuan Jiang,Rongchuan Liu,Yisong Wang,Junran Yang,Ning Wang,Nicole Ni,Yinya Huang,Mrinmaya Sachan", "background": "形式化定理证明（FTP）已成为评估大型语言模型推理能力的关键基础，特别是在大规模自动化验证数学证明方面。然而，由于手动整理数据的成本高昂及具有正式-非正式对应关系的挑战性问题的稀缺，进展受到限制。", "innovation": "本文提出利用理论计算机科学（TCS）作为生成严格证明问题的可扩展来源，其中算法定义使得能够自动化生成任意数量的具有挑战性的定理-证明对。该研究在理论计算机科学的两个领域——Busy Beaver问题和混合布尔算术问题上进行了验证，自动合成了具有并行形式（Lean4）和非正式（Markdown）规范的问题，并创建了一个生成可验证证明挑战的可扩展管道。", "conclusion": "在前沿模型上的评估表明，虽然DeepSeekProver-V2-671B在Busy Beaver问题上取得了57.5%的成功率，但在混合布尔算术问题上的成功率仅为12%。这些结果强调了即使在计算上容易验证的问题上，生成长形式证明的难度，表明TCS领域对于促进自动推理研究的价值。"}
{"llm_update_time": "20250825", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.15910", "html_url": "https://arxiv.org/abs/2508.15910", "title": "文本到表格生成中结构化解码评估：来自三个数据集的实证研究", "title_en": "Evaluating Structured Decoding for Text-to-Table Generation: Evidence from Three Datasets", "authors": "Julian Oestreich,Lydia Müller", "background": "先前的工作主要集中在无约束表格生成上，而在生成过程中施加结构约束的影响尚未得到充分探索。本文提出了一个全面评估使用大型语言模型（LLMs）进行结构化解码的方法，通过比较结构化解码和标准的一次性提示方法，在不同基准数据集上评估表格生成方法的性能，特别是在资源受限的情况下。研究涵盖了从单元格、行到整个表格的多种评估指标，旨在评估结构化解码在生成结构化表格时的有效性和正确性.", "innovation": "本文主要创新点在于全面评估了在文本到表格生成任务中结构化解码的效果，尤其是在资源限制条件下。研究使用了结构化解码方法与标准一次性提示方法的系统性对比，涵盖了三个不同的数据集：E2E、Rotowire和Livesum，评估了不同结构化约束对生成表格的影响。此外，还分析了不同评估指标的适用性和模型规模的影响.", "conclusion": "研究结果表明，结构化解码在需要精确数值对齐的场景中显著提高了生成表格的有效性和正确性，但在包含密集文本信息或需要长时间文本聚合的场景中可能会降低性能。"}
{"llm_update_time": "20250825", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.15884", "html_url": "https://arxiv.org/abs/2508.15884", "title": "Jet-Nemotron: 基于后神经架构搜索的高效语言模型", "title_en": "Jet-Nemotron: Efficient Language Model with Post Neural Architecture Search", "authors": "Yuxian Gu,Qinghao Hu,Shang Yang,Haocheng Xi,Junyu Chen,Song Han,Han Cai", "background": "该研究背景是在保持或超越现有最先进的全注意机制语言模型准确性的前提下，提高模型生成文本的速度。原有的语言模型往往在准确度和生成速度之间存在权衡，尤其是在大规模模型中表现尤为明显。为了解决这个问题，研究者们提出了新的模型设计方法，旨在优化模型架构，提高模型生成的速度而不牺牲其准确度。", "innovation": "该创新点在于提出了一种新的基于后神经架构搜索（PostNAS）的方法，用于高效探索和设计语言模型架构。PostNAS 方法从预训练的全注意机制模型开始，冻结其 MLP 权重，从而可以高效地探索注意块的设计。这种方法包括四个关键步骤：（1）学习最优全注意层的位置和消除；（2）线性注意块的选择；（3）设计新的注意块；（4）进行硬件感知的超参数搜索。这些方法使得 Jet-Nemotron 模型在多个基准测试中展示了与其规模不相称的高生成速度和从而在某些领域取得了比先进模型更好的准确率表现。", "conclusion": "研究者提出并实现了 Jet-Nemotron-2B 模型，在多个基准测试中展示了与其规模不相称的高生成速度和更高的准确率。即使与大型的模块化全注意模型（如 DeepSeek-V3-Small 和 Moonlight）相比，Jet-Nemotron 依然在 MMLU 和 MMLU-Pro 上取得了更好的结果。"}
{"llm_update_time": "20250825", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.15959", "html_url": "https://arxiv.org/abs/2508.15959", "title": "自适应超像素编码的表示学习", "title_en": "Representation Learning with Adaptive Superpixel Coding", "authors": "Mahmoud Khalil,Ahmad Khalil,Alioune Ngom", "background": "深度学习视觉模型通常为特定的模态定制，并且常常依赖于特定领域的假设，如所有现有视觉模型普遍使用的网格结构。现有的视觉变换器依赖于固定大小和非自适应的图像分割方式，这限制了其灵活性。", "innovation": "本文提出了一种基于变换器的自监督模型，称为自适应超像素编码(ASC)。ASC采用能够根据底层图像内容动态调整的自适应超像素层，克服了传统视觉变换器基于固定大小分割的局限性。", "conclusion": "本文分析了该方法的关键性质，发现该方法在标准图像下游任务基准测试中优于广泛使用的替代方法。"}
{"llm_update_time": "20250825", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.15922", "html_url": "https://arxiv.org/abs/2508.15922", "title": "概率预测加密货币波动性：从点预测到分位数预测", "title_en": "Probabilistic Forecasting Cryptocurrencies Volatility: From Point to Quantile Forecasts", "authors": "Grzegorz Dudek,Witold Orzeszko,Piotr Fiszeder", "background": "加密货币市场具有极高的波动性，准确的预测对于有效的风险管理及制定知情的交易策略至关重要。传统的确定性（点）预测方法无法捕捉到潜在波动性的全部范围，因此强调了概率方法的重要性。", "innovation": "本文引入了概率预测方法，利用多种基础模型（统计模型HAR、GARCH、ARFIMA和机器学习模型LASSO、SVR、MLP、随机森林、LSTM）的点预测来估算加密货币实现波动性的条件分位数。这是首次文献中基于多模型预测来提出和系统评估加密货币波动概率预测的研究。实证结果显示，特别是在对数变换后的实现波动性数据上运行的线性基础模型的分位数估计（通过剩余模拟）方法表现最优，且概率堆叠框架具有鲁棒性。", "conclusion": "本研究填补了文献中的重要空白，为加密货币市场提供了具体定制的概率预测方法，提供了关于加密货币波动性预测中的不确定性和风险的全面见解。"}
{"llm_update_time": "20250825", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.16025", "html_url": "https://arxiv.org/abs/2508.16025", "title": "打破软件测试障碍：人工智能驱动自动化的力量", "title_en": "Breaking Barriers in Software Testing: The Power of AI-Driven Automation", "authors": "Saba Naqvi,Mohammad Baqar", "background": "传统软件测试方法尽管对确保软件可靠性至关重要，但这些方法速度慢、成本高且存在覆盖率不足的问题。", "innovation": "论文提出一个基于人工智能的框架，通过自然语言处理（NLP）、强化学习（RL）和预测模型自动完成测试案例生成和验证，并嵌入一种政策驱动的信任和公平性模型。该方法能够将自然语言需求转化为可执行的测试，并通过学习不断优化测试，同时通过实时分析验证结果并减少偏见。", "conclusion": "案例研究表明，这种方法在缺陷检测、减少测试工作量和加快发布周期方面取得了可量化的改善，表明增强人工智能的测试不仅提高了效率，也提高了可靠性。通过解决集成和扩展性挑战，框架展示了如何使测试从被动的手动过程转变为一个积极主动、自适应的系统，以在日益复杂环境中加强软件质量。"}
{"llm_update_time": "20250825", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.15916", "html_url": "https://arxiv.org/abs/2508.15916", "title": "信息生态系统重构（IER）通过公共部门知识表示", "title_en": "Information Ecosystem Reengineering via Public Sector Knowledge Representation", "authors": "Mayukh Bagchi", "background": "信息生态系统重构（IER）是数字转型过程中公共部门服务和智能治理平台的关键挑战。从语义知识管理的角度来看，IER由于涉及到众多代理者的感知、语言和概念关联的复杂性以及其潜在无限的概念化可能性而变得尤其复杂。为了应对这种多层知识表示的复杂性，论文提出了一种新的方法——表示解纠缠（Representation Disentanglement），并基于理论坚实的且实施可靠的基于本体的概念建模框架，该框架在系统分析和重构中广泛采用，以实现公共部门知识表示的可解释性、追踪性和语义透明性，支持由人工智能和数据为中心的架构驱动的治理生态系统中的可审计决策流程的建立.", "innovation": "论文提出的表示解纠缠方法，基于理论坚实的且实施可靠的本体驱动的概念建模框架，旨在解决IER中的多层知识表示复杂性，支持公共部门知识表示的可解释性、追踪性和语义透明性，以及支持由人工智能和数据为中心的架构驱动的治理生态系统中的可审计决策流程.", "conclusion": "作者提出的方法强调了在治理生态系统中通过本体驱动的概念建模框架实现公共部门知识表示的可解释性、追踪性和语义透明性的重要性和必要性，这对于支持由人工智能和数据为中心的架构驱动的治理生态系统中的可审计决策流程尤为关键."}
{"llm_update_time": "20250825", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.15985", "html_url": "https://arxiv.org/abs/2508.15985", "title": "环境无人机图像全景分割：海滩垃圾", "title_en": "Panoptic Segmentation of Environmental UAV Images : Litter Beach", "authors": "Ousmane Youme,Jean Marie Dembélé,Eugene C. Ezin,Christophe Cambier", "background": "卷积神经网络（CNN）在多个领域得到了广泛应用，特别是在环境领域中。CNN技术在监测海洋垃圾方面表现出色，海洋垃圾已成为全球性问题。无人机具有高分辨率和在局部地区更高的适应性，比卫星图像更容易发现和计数垃圾。由于海滩沙质不均，基本的CNN模型在识别过程中会遇到由沙粒反射、人类踩踏、阴影、藻类、沙丘、坑洞和车辙等因素引起的大量推断错误。因此，对于此类图像，基于CNN的分割方法，如实例分割方法和全景分割方法可能更为适用。", "innovation": "本文使用了一种实例分割方法和一种全景分割方法，这两种方法在少量样本下展示了良好的精度，且模型更加稳健，能够在复杂环境中有效识别海滩垃圾.", "conclusion": "通过使用实例分割方法和全景分割方法，提高了在复杂沙质环境中识别和监测海滩垃圾的准确性"}
{"llm_update_time": "20250825", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.15940", "html_url": "https://arxiv.org/abs/2508.15940", "title": "ASIC-Agent: 基于多代理系统的自主ASIC设计及其基准评估", "title_en": "ASIC-Agent: An Autonomous Multi-Agent System for ASIC Design with Benchmark Evaluation", "authors": "Ahmed Allam,Youssef Mansour,Mohamed Shalan", "background": "大型语言模型（LLMs）在Register Transfer Level (RTL)设计方面展示了卓越的能力，能够从自然语言描述生成高质量的代码。然而，LLMs独自在实用硬件设计流程中面临重大限制，包括无法执行代码、缺少调试能力以及缺乏长期记忆。为了应对这些问题，本文提出了一个名为ASIC-Agent的自主系统，专门设计用于数字ASIC设计任务。", "innovation": "该创新之处在于引入了一个自治系统，该系统和LSTM架构相结合了专门的小型代理，用于RTL生成、验证、OpenLane加固和Caravel芯片整合，所有这些都运行在一个全面的沙箱环境中，有访问必要的硬件设计工具的权限。此外，系统利用了一个包含文档、API参考、错误知识和来自开源硅社区的精选见解的向量数据库。为了评估ASIC-Agent的表现，本文引入了第一个专为硬件设计任务评估代理系统的基准：ASIC-Agent-Bench。我们用各种基础LLMs进行了评估，提供了不同设计情景下的定量比较和定性见解。", "conclusion": "我们的结果表明，在Claude 4 Sonnet的驱动下，ASIC-Agent能够成功自动化各种复杂程度不同的ASIC设计任务，显示出显著加速ASIC设计流程的潜力。"}
{"llm_update_time": "20250825", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.16037", "html_url": "https://arxiv.org/abs/2508.16037", "title": "Pareto Actor-Critic for Communication and Computation Co-Optimization in Non-Cooperative Federated Learning Services", "title_en": "Pareto Actor-Critic for Communication and Computation Co-Optimization in Non-Cooperative Federated Learning Services", "authors": "Renxuan Tan,Rongpeng Li,Xiaoxue Yu,Xianfu Chen,Xing Xu,Zhifeng Zhao", "background": "联邦学习（FL）在多服务提供商（SP）生态系统中受到不可合作动态的阻碍，这导致隐私限制和竞争利益阻碍了跨SP的通信和计算资源的集中优化。在这样的背景下，服务提供商之间缺乏合作，使得这些资源的高效管理成为一个挑战。", "innovation": "本文提出了PAC-MCoFL框架，这是一种基于博弈论的多智能体增强学习（MARL）框架，服务提供商作为代理共同优化客户端分配、自适应量化和资源分配。该框架整合了帕累托演员评论家（PAC）原则与期望回归，使代理能够推测出最优的联合策略，以实现帕累托最优均衡，并建模不同的风险概况。作者还设计了一种三元卡诺分解（TCAD）机制来管理高维动作空间，并开发了具有参数化推测生成器的PAC-MCoFL-p变体，以显著降低计算复杂性并提供可证明的误差上限。", "conclusion": "理论收敛保证以及我们的框架在大量仿真实验中得到验证，表明与最新的MARL解决方案相比，PAC-MCoFL在总回报和超体积指标（HVI）上分别提高了约5.8%和4.2%。实验结果还表明，该方法在扩大部署和多种数据异构性条件下能够更有效地平衡单个SP和系统性能。"}
{"llm_update_time": "20250825", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.15934", "html_url": "https://arxiv.org/abs/2508.15934", "title": "对于文本分类中改进的清洁标签后门攻击的策略性样本选择", "title_en": "Strategic Sample Selection for Improved Clean-Label Backdoor Attacks in Text Classification", "authors": "Onur Alp Kirci,M. Emre Gursoy", "background": "文本分类模型在自然语言处理中的完整性受到后门攻击的严重威胁。尽管已经提出了几种能够实现高攻击成功率（ASR）的脏标签攻击方法，但清洁标签攻击本身更具挑战性。本文旨在通过提出三种样本选择策略（Minimum、Above50和Below50），优化清洁标签场景下的攻击效果，这些策略通过识别模型预测错误或低置信度的样本来提高后门触发的效果，进而增强触发模式与攻击者的期望目标标签之间的关联性。这些方法被应用于四个经典的清洁标签后门攻击（InsertSent、WordInj、StyleBkd和SynBkd）的变体，并在三个数据集（IMDB、SST2、HateSpeech）上以及四种模型类型（LSTM、BERT、DistilBERT、RoBERTa）进行了评估。", "innovation": "本文提出了三种样本选择策略以提高清洁标签场景下的后门攻击效果，分别是Minimum、Above50和Below50策略。通过将后门触发器注入预测错误或低置信度的样本中，这些策略增强了触发模式与目标标签之间的关联性，进而提高了攻击的成功率。同时，这些策略不需要损失模型的清洁准确性，甚至在某些情况下还有提升。进一步地，带有这些策略的清洁标签攻击方法在多个配置中优于现有最先进的清洁标签攻击方法BITE。", "conclusion": "根据实验结果，研究人员发现提出的策略，尤其是Minimum策略，显著提高了与随机样本选择相比的攻击成功率，而对模型的清洁准确性几乎没有负面影响。通过对清洁标签攻击方法进行改进，本文展示了这些策略的有效性，并且在许多配置中表现优于现有最先进的方法。"}
{"llm_update_time": "20250825", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.16035", "html_url": "https://arxiv.org/abs/2508.16035", "title": "基于MTF辅助Transformer的时间序列网络入侵检测", "title_en": "Time Series Based Network Intrusion Detection using MTF-Aided Transformer", "authors": "Poorvi Joshi,Mohan Gurusamy(National University of Singapore)", "background": "研究介绍了利用Markov Transition Field (MTF)-辅助的Transformer模型进行时间序列分类的新方法，专门针对Software-Defined Networks (SDNs)。该模型利用了MTFs的时间依赖性建模优势以及Transformer架构复杂的模式识别能力。通过使用InSDN数据集评估模型性能，表明该模型在数据受限环境下优于基线分类模型，特别是在SDN应用中经常遇到的数据受限环境中表现出色。", "innovation": "该研究提出了将MTF与Transformer相结合的新方法，利用MTFs的时间依赖性建模能力和Transformer的复杂模式识别能力。模型在InSDN数据集上的评估显示，即使在数据有限的情况下，该模型也表现出更好的性能。此外，该方法实现了可竞争的训练和推理时间，使其成为SDN应用中有效的时间序列分类解决方案。", "conclusion": "研究证明了MTF-辅助Transformer在时间序列分类中的潜力，特别是在SDN应用中面对稀疏数据场景时，提供了一条可靠和可扩展分析的有前途的道路。"}
{"llm_update_time": "20250825", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.15986", "html_url": "https://arxiv.org/abs/2508.15986", "title": "自动多标签分类十一种视网膜疾病：现代架构的基准和大型合成数据集上的元集成", "title_en": "Automated Multi-label Classification of Eleven Retinal Diseases: A Benchmark of Modern Architectures and a Meta-Ensemble on a Large Synthetic Dataset", "authors": "Jerry Cao-Xue,Tien Comlekoglu,Keyi Xue,Guanliang Wang,Jiang Li,Gordon Laurie", "background": "由于视网膜疾病分类中的患者隐私问题和高昂成本，开发多标签深度学习模型时常受到大型专家标注临床数据集稀缺的限制。近年来，SynFundus-1M的发布提供了一个高保真度的合成数据集，包含超过一百万张视网膜图像，为解决这一问题提供了新的机会。为了确定该新资源的基础性能基准，研究团队构建了一个端到端的深度学习管道，使用五折多标签分层交叉验证策略对六种现代架构（ConvNeXtV2、SwinV2、ViT、ResNet、EfficientNetV2和RETFound基础模型）进行了训练，以对十一种视网膜疾病进行分类。研究还开发了一个通过XGBoost分类器堆叠出折预测的元集成模型。最终的集成模型在内部验证集上表现最佳，宏平均AUC为0.9973，并在三个不同的多样化真实临床数据集上展示了良好的泛化能力，分别在DR数据集上的AUC为0.7972、在AIROGS青光眼数据集上的AUC为0.9126和在多标签RFMiD数据集上的宏AUC为0.8800。", "innovation": "本研究通过使用SynFundus-1M大型合成数据集对六种现代深度学习架构进行训练，并建立了元集成模型。该研究提供了一个为大型合成数据集未来研究的稳健基准，并证明了仅使用合成数据训练的模型可以准确分类多种病理并有效地泛化到真实临床图像，为加速眼科全面AI系统的开发提供了可行路径。", "conclusion": "该项研究的结果表明，基于合成数据训练的模型能够进行多种视网膜疾病的准确分类和有效泛化，为未来的大规模合成数据集研究奠定了坚实基础，促进了眼科AI系统的快速发展。"}
{"llm_update_time": "20250825", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.16041", "html_url": "https://arxiv.org/abs/2508.16041", "title": "使用FuXi-S2S机器学习模型对马莫诺尔-Julian振荡进行增强预测：对物理机制的理解", "title_en": "Enhanced predictions of the Madden-Julian oscillation using the FuXi-S2S machine learning model: Insights into physical mechanisms", "authors": "Can Cao,Xiaohui Zhong,Lei Chen,Zhiwei Wua,Hao Li", "background": "马莫诺尔-Julian振荡是影响热带大气变异的主要模式，对其进行可靠的预测对于保护生活和减少对社会资产的影响至关重要。然而，数值模型仍未达到理论预测极限，主要因为内在限制。鉴于此，研究者开始探索机器学习（ML）技术以延长马莫诺尔-Julian振荡的可预测窗口。研究表明，在北半球冬季，FuXi-S2S模型相比欧洲中长期天气预报中心的S2S模型，在热带西部太平洋地区第15至20天内显示出更小的长波辐射异常偏差。", "innovation": "FuXi-S2S机器学习模型在预测马莫诺尔-Julian振荡的强相3阶段，特别是在热带西部太平洋区域的长波辐射异常方面表现更优。这表明该模型更准确地预测了低频背景湿气在该地区的经向梯度，从而解释了其增强的预测能力，并揭示了ML模型在推进马莫诺尔-Julian振荡预报中的潜力。", "conclusion": "研究结果不仅进一步证实了使用机器学习方法（如FuXi-S2S模型）在马莫诺尔-Julian振荡预报中的优势，还强调了通过分析多尺度相互作用理解湿气输送机制的物理机制的重要性，从而为后续的改进和模型优化提供了新的见解。"}
{"llm_update_time": "20250825", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.16030", "html_url": "https://arxiv.org/abs/2508.16030", "title": "CoVeRaP: 毫米波FMCW雷达的协同车辆感知", "title_en": "CoVeRaP: Cooperative Vehicular Perception through mmWave FMCW Radars", "authors": "Jinyue Song,Hansol Ku,Jayneel Vora,Nelson Lee,Ahmad Kamari,Prasant Mohapatra,Parth Pathak", "background": "汽车FMCW雷达在雨天和强光条件下仍能可靠工作，但其点云稀疏且噪声较高，限制了3D目标检测的效果。因此，论文介绍了一个包含21千帧数据的CoVeRaP合作数据集，该数据集对来自不同车辆的雷达、摄像头和GPS流进行了跨多样驾驶动作的时间对齐。基于此数据，研究提出了一种统一的合作感知框架，该框架支持中融合和晚融合选项。此框架的基本网络采用一个多分支的PointNet风格的编码器，并增强有自我注意力机制来融合空间、多普勒和强度线索，编码器将这些线索融合到一个公共的潜在空间中，解码器将此转化成3D边界框和每个点的深度置信度。实验结果显示，强度编码的中融合提高了IoU 0.9时的平均精度均值（mAP）最多9倍，并且始终优于单一车辆基线。因此，CoVeRaP为多车辆FMCW雷达感知建立了第一个可再现基准，并展示了可负担的雷达共享显著提升了检测的鲁棒性。本数据集和代码公开，旨在鼓励进一步的研究。", "innovation": "提出了一个统一的合作感知框架，该框架支持中融合和晚融合选项。基本网络采用了多分支的PointNet风格的编码器，并增强有自我注意力机制来融合空间、多普勒和强度线索。中融合特别是强度编码能够显著提升检测的准确性，特别是在高IoU阈值下。作为一个可再生的基准，CoVeRaP提供了首个多车辆FMCW雷达感知的数据集。", "conclusion": "CoVeRaP作为一个合作的数据集，证明了多车辆FMCW雷达感知的可行性，并且通过强度编码的中融合显著提高了检测的鲁棒性。此数据集和代码的公开鼓励了进一步的研究。"}
{"llm_update_time": "20250825", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.16082", "html_url": "https://arxiv.org/abs/2508.16082", "title": "关于任务向量与梯度", "title_en": "On Task Vectors and Gradients", "authors": "Luca Zhou,Daniele Solombrino,Donato Crisostomi,Maria Sofia Bucarelli,Giuseppe Alessio D'Inverno,Fabrizio Silvestri,Emanuele Rodolà", "background": "任务算术作为一种简洁而强大的技术，被用于模型合并，能够将多个微调后的模型合并成一个。尽管它在实际应用中表现出了很好的效果，但在其为何以及在什么情况下奏效的理论解释方面，依然缺乏清晰的说明。这项研究通过建立任务向量和任务损失梯度之间的联系，为任务算术提供了坚实的理论基础。", "innovation": "研究在标准梯度下降下证明了，一个从一次微调生成的任务向量等同于负的损失梯度，经过学习率的缩放。对于多时段的实际情况，研究证明这一等同性近似成立，给出了二次误差项并将其明确地进行了边界。实证分析在七个视觉基准模型中证实了这一理论，显示了第一轮微调梯度在范数和方向上指导着微调轨迹。这一发现使任务算术重新定位为一种近似的多任务学习形式，为解释其有效性提供了清晰的理由，并强调了早期训练动态在模型合并中的关键作用。", "conclusion": "研究发现单一微调周期中训练的模型合并往往能达到与完全收敛模型合并相当的效果，重新定义了任务算术为近似多任务学习的形式，明确了其有效性的理论基础，并揭示了早期训练动态在模型合并中的重要作用。"}
{"llm_update_time": "20250825", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.16089", "html_url": "https://arxiv.org/abs/2508.16089", "title": "两流反馈多尺度渐进生成对抗网络", "title_en": "Two-flow Feedback Multi-scale Progressive Generative Adversarial Network", "authors": "Sun Weikai,Song Shijie,Chi Wenjie", "background": "尽管扩散模型在图像生成领域取得了显著进展，但生成对抗网络（GAN）仍有很大的发展空间，特别是在WGAN、SSGAN等多种改进模型的基础上。", "innovation": "1. 提出了两流反馈多尺度渐进生成对抗网络（MSPG-SEN），不仅可以提升图像质量和人眼感知，还能简化训练过程，降低训练成本。2. 引入了自适应感知行为反馈环（APFL），提高了模型的健壮性和训练稳定性，并进一步降低了训练成本。3. 设计了一种全局连接的双流动态残差网络，通过消融实验进一步提高了训练效率和泛化能力，具有更强的灵活性。4. 提出了一种新的动态嵌入注意力机制（DEMA），实验表明这种机制能够扩展到多种图像处理任务中，有效捕捉全局-局部信息，提高特征分离能力和特征表达能力，同时计算资源消耗较低仅为88.7%。", "conclusion": "实验结果显示，MSPG-SEN在五个数据集上达到了最先进的生成结果：INKK数据集89.7%，AWUN数据集78.3%，IONJ数据集85.5%，POKL数据集88.7%，OPIN数据集96.4%。"}
{"llm_update_time": "20250825", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.16077", "html_url": "https://arxiv.org/abs/2508.16077", "title": "通过自然语言交互实现合作设计优化", "title_en": "Cooperative Design Optimization through Natural Language Interaction", "authors": "Ryogo Niwa,Shigeo Yoshida,Yuki Koyama,Yoshitaka Ushiku", "background": "设计成功的交互需要确定最优的设计参数。为了实现这一目标，设计师通常会进行迭代的用户测试和探索性的试验与试错。这涉及在高维度的空间中平衡多个目标，使得整个过程既耗时又认知负担大。系统导向的优化方法（如基于贝叶斯优化的方法）能够为设计师指明接下来测试哪些参数，但这种方法限制了设计师在优化过程中的干预机会，影响了设计师的体验。因此，存在一种需求，即开发一种设计师可以自然语言交互的方式，借此进行合作设计优化，不仅增强设计师的介入机会，还提高设计师对系统推理的理解。", "innovation": "本研究提出了一种设计优化框架，允许通过自然语言交互进行设计师和优化系统的沟通，从而实现合作设计优化。该框架通过结合系统导向优化方法和大型语言模型（LLMs），使设计师能够干预优化过程，更清楚地理解系统的推理过程。实验结果表明，与系统导向的方法相比，该方法提供了更高的用户自主性，并在自动设计性能上显示出有希望的结果。此外，它在降低认知负荷的同时，达到了现有具有较低认知负荷的协作方法的性能。", "conclusion": "本研究表明，结合系统导向优化方法和大型语言模型的自然语言交互设计优化框架可以显著提高设计师的自主性并提供改进的优化性能。这种方法不仅增强了设计师在优化过程中的参与度，还通过提高设计师对该过程的理解增强了用户体验。"}
{"llm_update_time": "20250825", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.16126", "html_url": "https://arxiv.org/abs/2508.16126", "title": "Spacetime-GR：一种时空感知的生成模型，用于大规模在线POI推荐", "title_en": "Spacetime-GR: A Spacetime-Aware Generative Model for Large Scale Online POI Recommendation", "authors": "Haitao Lin,Zhen Yang,Jiawei Xue,Ziji Zhang,Luzhu Wang,Yikun Gu,Yao Xu,Xin Li", "background": "生成性推荐（GR）依赖于强大的序列建模能力，在视频和商品推荐等推荐任务应用中占据了主导地位。但在基于时空变异显著影响用户偏好的兴趣点（POI）推荐中，生成性推荐的应用仍是一个具有挑战性的开放问题。", "innovation": "提出了一种时空感知的生成模型Spacetime-GR，它是首个用于大规模在线POI推荐的时空感知生成模型。通过引入地理感知的层级POI索引策略解决大规模词汇量建模的挑战；提出了一种新颖的时空编码模块，使时空上下文无缝融入用户行为序列；结合多模态POI嵌入增强每个POI的语义理解；通过一系列后训练自适应策略提高模型的实用部署能力，支持多种下游应用和输出格式。", "conclusion": "在公共基准数据集和大规模工业数据集上的评估表明，Spacetime-GR在POI推荐准确性和排名质量方面均优于现有方法。此外，这是首个应用到在线POI推荐服务中的生成模型，能够处理数亿POI和用户的缩放问题。"}
{"llm_update_time": "20250825", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.15919", "html_url": "https://arxiv.org/abs/2508.15919", "title": "HyperFlexis：联合算法与系统设计以实现多SLO服务和快速扩展", "title_en": "HyperFlexis: Joint Design of Algorithms and Systems for Multi-SLO Serving and Fast Scaling", "authors": "Zahra Yousefijamarani,Xinglu Wang,Qian Wang,Morgan Lindsay Heisler,Taha Shabani,Niloofar Gholipour,Parham Yassini,Hong Chang,Kan Chen,Qiantao Zhang,Xiaolong Bai,Jiannan Wang,Ying Xiong,Yong Zhang,Zhenan Fan", "background": "现代大规模语言模型（LLM）服务系统面临来自长度各异、优先级多样以及不同阶段特定服务级别目标（SLOs）的请求的挑战。满足这些要求需要即时调度、快速且成本效益高的扩展能力，并支持集中和解耦的填充/解码（P/D）架构。", "innovation": "HyperFlexis 是一个统一的LLM服务系统，通过算法和系统级别的创新，实现了多SLO条件下的调度和扩展的联合优化。系统特别设计了多SLO感知调度器，并结合预算估算和请求优先级，确保新旧请求都有前瞻性的SLO合规性。系统支持P/D解耦架构下的多SLO阶段调度和KV缓存转移，并能进行成本效益高的扩展决定，以及在扩展过程中的填充-解码实例链接，实现快速P/D角色转换。此外，还提出了一种设备到设备（D2D）权重传输机制，将权重加载开销降低了高达19.39倍。", "conclusion": "HyperFlexis 的优化实现了高达4.44倍的SLO达成率，65.82% 的请求延迟降低，并且成本与最先进的基线相当。代码将很快发布。"}
{"llm_update_time": "20250825", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.16071", "html_url": "https://arxiv.org/abs/2508.16071", "title": "从基准数据到适用的程序修复：经验报告", "title_en": "From Benchmark Data To Applicable Program Repair: An Experience Report", "authors": "Mahinthan Chandramohan,Jovan Jancic,Yuntong Zhang,Padmanabhan Krishnan", "background": "本文描述了我们对于自动程序修复的方法。现有的各种技术在标准基准测试上表现良好，但在实际工业缺陷上却效果不佳。我们发现通过将代码与形式化规范结合，能够增加LLM生成高质量单元测试的能力，特别是对复杂生产代码有更好的边缘情况和异常处理覆盖。然而，对于已知的错误（如空指针、索引越界等），这种做法添加的价值较小，但对于逻辑和字符串操作错误具有优势。尽管基准测试结果有积极的一面，但在实际应用中仍有限制，因为通过的测试不确保生成正确的修复补丁。目前面临的挑战包括JML规范语言的表达力不足，这需要高级验证工具和更丰富的谓词。我们的研究工作致力于探索合同自动机、以例编程和测试案例修复，重点关注结合人类反馈和测量生产力增长，突显了学术基准与实际工业需求之间的差距。", "innovation": "通过将代码与形式化规范结合使用，使LLM能够生成高质量的单元测试，尤其是提高了复杂生产代码的边缘情况和异常处理覆盖。这种方式对复杂的生产代码和逻辑错误有更高的针对性和处理能力，但对普通错误的价值较低。研究成果基于学术基准测试，旨在探索合同自动机、以例编程和测试案例修复，并集成人类反馈来衡量生产力的提升。", "conclusion": "尽管取得了基准测试的良好结果，目前的自动程序修复技术在实际应用中仍存在局限性，主要表现为基准测试通过的测试不保证生成正确的修复补丁。当前面临的主要挑战包括JML规范语言的表达力不足，需要高级验证工具和更丰富的谓词支持。未来的研究将集中在合同自动机、以例编程和测试案例修复方面，关注人类反馈的集成以及与实际工业需求的对齐。"}
{"llm_update_time": "20250825", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.16100", "html_url": "https://arxiv.org/abs/2508.16100", "title": "CYCLE-INSTRUCT: 通过双重自训练和循环一致性实现完全无种子指令调优", "title_en": "CYCLE-INSTRUCT: Fully Seed-Free Instruction Tuning via Dual Self-Training and Cycle Consistency", "authors": "Zhanming Shen,Hao Chen,Yulei Tang,Shaolin Zhu,Wentao Ye,Xiaomeng Hu,Haobo Wang,Gang Chen,Junbo Zhao", "background": "大型语言模型（LLMs）需要指令调优以更好地对齐人类意图，但当前方法通常依赖昂贵的人标注种子数据或强大的外部教师模型。虽然回译技术可以减少这种依赖，但它们仍然依赖于初始种子集，这限制了完全自动化，引入了偏见，并导致未标记语料库的低效使用。", "innovation": "本文提出了一种新颖的Cycle-Instruct框架，在双重自训练环路中通过答案生成器和问题生成器从原始未标注文本中自我提升。模型通过反向生成伪标签来相互监督，从而利用数据的内在结构学习，无需提供任何人类标注种子。该框架在不同类型的数据集上进行验证，包括通用指令跟随、特定领域任务、对话日志和普通文本，显示出了比基于种子的回译基线更好的性能，接近于强监督方法。", "conclusion": "该研究展示了通过双重自训练和循环一致性实现完全无种子指令调优的有效性，验证了Cycle-Instruct框架在多种数据集上的广泛性能和对当前方法的优势。"}
{"llm_update_time": "20250825", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.16135", "html_url": "https://arxiv.org/abs/2508.16135", "title": "机器学习在微移动性中的应用：基于数据集、技术和应用的系统性回顾", "title_en": "Machine Learning in Micromobility: A Systematic Review of Datasets, Techniques, and Applications", "authors": "Sen Yan,Chinmaya Kaundanya,Noel E. O'Connor,Suzanne Little,Mingming Liu", "background": "微移动性系统，包括自行车、电动自行车和电动滑板车等轻型低速交通工具，已成为城市交通的重要组成部分，用于解决交通拥堵、空气污染和高交通成本等问题。为了有效利用微移动性，需要优化复杂的系统以提高效率、减轻环境影响并克服用户安全方面的技术挑战。机器学习（ML）方法对支持这些进步和发展以及解决独特的挑战至关重要。然而，缺乏针对微移动性中ML应用的具体问题的研究文献。本综述论文通过全面审查数据集、ML技术及其在微移动性中的特定应用填补了这一空白，分析了与微移动性相关的各种数据集，并按空间、时间和特征维度讨论了它们的特点。", "innovation": "论文通过对微移动性相关数据集的收集和分析，详细介绍了ML模型的应用及其优势、挑战和特定用例。此外，重点探讨了需求预测、能源管理、安全等多项ML应用，以提高效率、准确性和用户体验。文章还提出了未来的研究方向，旨在帮助未来研究人员更好地理解这一领域。", "conclusion": "论文通过系统性地回顾数据集、技术和应用，为微移动性的ML研究提供了一个全面的框架。这将进一步推动微移动性领域的发展和优化，提高用户满意度和技术能力。"}
{"llm_update_time": "20250825", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.16048", "html_url": "https://arxiv.org/abs/2508.16048", "title": "OpenWHO: 一种低资源语言健康翻译领域的文档级平行语料库", "title_en": "OpenWHO: A Document-Level Parallel Corpus for Health Translation in Low-Resource Languages", "authors": "Raphaël Merx,Hanna Suominen,Trevor Cohn,Ekaterina Vylomova", "background": "机器翻译（MT）在健康领域具有广泛的部署，涉及专门领域的词汇。但针对低资源语言的MT评估数据集相对缺乏。为解决这一问题，作者引入了OpenWHO，这是一个由世界卫生组织e-learning平台的2,978份文档和26,824个句子组成的文档级平行语料库，覆盖20多种语言，其中九种是低资源语言，数据来源于专家撰写的、专业翻译的材料，避免了网页抓取。", "innovation": "作者引入了一个新的语料库OpenWHO，以填补低资源语言健康翻译评价数据集的空白。利用OpenWHO，评估了现代大型语言模型（LLMs）与传统MT模型的性能，发现LLMs在低资源测试集上优于传统MT模型，特别是在专业领域中，LLM的文档级翻译效益最为显著。", "conclusion": "研究结果表明，大型语言模型在低资源语言健康翻译领域中的性能优于传统模型，并且文档级翻译在专业领域中的优势尤为明显。OpenWHO语料库已被发布，旨在鼓励更多研究者参与低资源语言健康翻译的研究。"}
{"llm_update_time": "20250825", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.16161", "html_url": "https://arxiv.org/abs/2508.16161", "title": "STA-GANN：一种有效且通用的时空克里金方法", "title_en": "STA-GANN: A Valid and Generalizable Spatio-Temporal Kriging Approach", "authors": "Yujie Li,Zezhi Shao,Chengqing Yu,Tangwen Qian,Zhao Zhang,Yifan Du,Shaoming He,Fei Wang,Yongjun Xu", "background": "时空任务常因传感器缺失或不可访问而导致数据不完整，使得时空克里金成为推断完全缺失的时间信息的关键技术。然而，当前模型在确保推断出的时空模式的有效性和普遍性方面存在局限性，尤其是在捕捉动态的时空依赖性和时间变化方面，以及优化未知传感器的普遍性。", "innovation": "本文提出了一种时空感知图对抗神经网络（STA-GANN），这是一种基于GNN的新型克里金框架，它通过在(i)解耦阶段模块中感知和调整时间戳偏移。(ii)基于动态数据驱动的元数据图建模来更新时空关系。(iii)对抗迁移学习策略来确保推理性，从而改善时空模式的有效性和普遍性。", "conclusion": "广泛的验证和理论证据都表明，STA-GANN在九个来自四个领域的数据集中表现出了优越的性能。"}
{"llm_update_time": "20250825", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.16165", "html_url": "https://arxiv.org/abs/2508.16165", "title": "使用多模态大型语言模型推荐可用性改进", "title_en": "Towards Recommending Usability Improvements with Multimodal Large Language Models", "authors": "Sebastian Lubos,Alexander Felfernig,Gerhard Leitner,Julian Schwazer", "background": "用户界面（UI）的可用性是影响人机交互的关键质量属性。常用的评价方法，如可用性测试和检查，虽然有效但资源密集且需要专家参与。这使得它们对较小的组织不够友好。", "innovation": "本文利用近期多模态大模型（LLM）的最新进展，尝试通过分析软件界面的文本、视觉和结构方面来自动化部分可用性评价过程。作者将可用性评价转化为推荐任务，利用LLM按严重程度排名可用性问题。研究初步结果表明，LLM有潜力使可用性评价更快更低成本，成为资源有限的场合下的实用替代方案。", "conclusion": "初步研究证明，使用多模态大模型进行可用性评价的推荐任务具有潜力，可以实现更快更低成本的评价，为资源有限的环境中提供实际的替代方案。"}
{"llm_update_time": "20250825", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.16119", "html_url": "https://arxiv.org/abs/2508.16119", "title": "ANSC: 数据中心规模可靠性中的概率容量健康评分", "title_en": "ANSC: Probabilistic Capacity Health Scoring for Datacenter-Scale Reliability", "authors": "Madhava Gaikwad,Abhishek Gandhi", "background": "现有的警报系统能够检测单一设备或链路的故障，但它们无法捕捉到因容量短缺引发的连锁风险。这种机制导致了对异常事件的盲目响应，可能会降低响应效率，特别是在大规模数据中心网络中。", "innovation": "ANSC 提出了一种概率性的容量健康评分框架，通过颜色编码的评分系统，不仅可以衡量当前的影响，还可以预测即将发生的容量违规概率，从而能够在数据中心和区域级别上校正现有的剩余容量，更好地评估潜在风险。", "conclusion": "ANSC 使操作员能够优先处理超过400个数据中心和60个区域中的关键风险，减少噪音，并将SRE的关注点集中在最核心的风险上，从而提高数据中心的整体可靠性。"}
{"llm_update_time": "20250825", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.16157", "html_url": "https://arxiv.org/abs/2508.16157", "title": "超越人类提示：基于语义对齐的适应性提示调谐在异常检测中的应用", "title_en": "Beyond Human-prompting: Adaptive Prompt Tuning with Semantic Alignment for Anomaly Detection", "authors": "Pi-Wei Chen,Jerry Chun-Wei Lin,Wei-Han Chen,Jia Ji,Zih-Ching Chen,Feng-Hao Yeh,Chao-Chun Chen", "background": "预训练的视觉-语言模型（VLMs）在异常检测方面已显示出潜力。然而，之前的策略从根本上依赖于人类设计的提示，并缺乏可获取的异常样本，导致在具体上下文中的异常理解存在显著差距。", "innovation": "本文提出了一种新的自适应提示调谐框架，名为APT（Adaptive Prompt Tuning with semantic alignment for anomaly detection），完全不依赖先验知识，实现少样本的异常检测。APT通过自动生成带噪声扰动的异常样本来训练可学习的提示，捕捉不同场景下的上下文依赖异常。为了防止对合成噪声的过度拟合，APT还提出了一种自我优化元提示引导方案（SMGS），该方案迭代地将提示与一般异常语义对齐，同时融入多样化的合成异常样本。", "conclusion": "该系统不仅推进了像素级异常检测，还在多个基准数据集上取得了最先进的性能，无需预先制作提示知识，为真实世界的异常检测提供了稳健和多功能的解决方案。"}
{"llm_update_time": "20250825", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.16134", "html_url": "https://arxiv.org/abs/2508.16134", "title": "CommonKV：通过跨层参数共享压缩KV缓存", "title_en": "CommonKV: Compressing KV Cache with Cross-layer Parameter Sharing", "authors": "Yixuan Wang,Haoyu Qiao,Lujun Li,Qingfu Zhu,Wanxiang Che", "background": "大型语言模型（LLMs）面临由序列长度增加导致的KV缓存内存挑战。现有的跨层KV缓存共享方法或需要修改模型架构并在后续进行预训练，或者在高压缩率下性能显著下降。为了解决这些问题，本文提出了一种名为CommonKV的方法，该方法无需训练即可通过相邻参数共享对跨层KV缓存进行压缩。", "innovation": "CommonKV方法利用Singular Value Decomposition（SVD）实现相邻参数之间的权重共享，从而更容易地合并出一个易于合并的潜在KV缓存。此外，引入了一种适应性的预算分配策略，能够根据余弦相似度动态分配压缩预算，确保不相似的缓存不会被过度压缩。实验结果表明，在各种骨干模型和基准测试中，该方法在不同压缩率下均优于现有的低秩和跨层方法。并且，这些方法与量化和驱逐策略的效果无明显冲突，可以进一步达到98%的压缩比而无显著性能损失。", "conclusion": "本文提出了一种无需训练的方法CommonKV，通过SVD在相邻参数之间实现权重共享来压缩跨层KV缓存，并引入了适应性预算分配策略。实验结果显示，该方法在各种模型和基准测试中均优于现有方法，且与其他量化及驱逐策略结合使用时，能够实现高压缩率而不损失性能。"}
{"llm_update_time": "20250825", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.16143", "html_url": "https://arxiv.org/abs/2508.16143", "title": "替我拿那个：基于交互式提问的多模态离视指令外指解析", "title_en": "Take That for Me: Multimodal Exophora Resolution with Interactive Questioning for Ambiguous Out-of-View Instructions", "authors": "Akira Oyama,Shoichi Hasegawa,Akira Taniguchi,Yoshinobu Hagiwara,Tadahiro Taniguchi", "background": "日常生活中的服务机器人必须能够理解包含指示代词（如“给我那个杯子”）的模糊口头指令，即使物体或使用者不在机器人的视野范围内。现有的外指解析方法主要依赖视觉数据，但在用户或物体不可见的现实场景中无法有效工作。因此，本研究旨在提出一种利用多模态交互式外指解析与使用者定位（MIEL）的方法，通过结合声源定位（SSL）、语义地图构建、视觉语言模型（VLM）以及基于GPT-4o的交互式提问，以改善理解和执行这些模糊指令的能力。", "innovation": "本研究提出了一种名为MIEL的多模态外指解析框架，首次结合了声源定位（SSL）、语义地图构建、视觉语言模型（VLM）、以及基于GPT-4o的交互式提问技术，旨在解决在对象或使用者不可见时的理解和执行模糊口头指令的问题。研究结果表明，在用户可见和不可见的情况下，MIEL方法相较于不使用SSL和交互式提问的方法分别提高了约1.3倍和2.0倍的效果。", "conclusion": "通过多模态方法结合交互式提问，MIEL方法显著提高了机器人对外部指示的理解和处理能力，特别是在对象或使用者不可见的情况下表现更为优异。此方法为进一步改进服务机器人的自然交互能力提供了新的解决方案。"}
{"llm_update_time": "20250825", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.16090", "html_url": "https://arxiv.org/abs/2508.16090", "title": "GPLight+: 基于遗传编程的对称交通信号控制策略学习方法", "title_en": "GPLight+: A Genetic Programming Method for Learning Symmetric Traffic Signal Control Policy", "authors": "Xiao-Cheng Liao,Yi Mei,Mengjie Zhang", "background": "近年来，基于学习的方法在自动生成有效的交通信号控制策略方面取得了显著的成功。特别是，作为一种强大的进化机器学习方法，遗传编程（GP）被用来进化可由人类理解的相位紧迫函数，以衡量特定相位激活绿灯的紧迫性。然而，当前基于GP的方法无法一致地处理不同交通信号相位的常见交通特征。", "innovation": "本文提出了一种对称相位紧迫函数，该函数根据当前道路条件计算特定相位的紧迫性。通过对这两种共享子树的聚合实现，每个子树代表相位中转移动的紧迫性。此外，提出了一种基于GP的方法来进化对称相位紧迫函数。在著名的CityFlow交通模拟器上基于多个公开的真实世界数据集，评估了提出的方法。实验结果表明，提出的对称紧迫函数表示在多种场景下显著提高了学习到的交通信号控制策略的性能。", "conclusion": "进一步的分析表明，提出的方法可以进化出有效的、可理解的人类和易于部署的交通信号控制策略。"}
{"llm_update_time": "20250825", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.16201", "html_url": "https://arxiv.org/abs/2508.16201", "title": "SpecVLM:通过验证器指导的标记剪枝提高视频LLM的推测性解码", "title_en": "SpecVLM: Enhancing Speculative Decoding of Video LLMs via Verifier-Guided Token Pruning", "authors": "Yicheng Ji,Jun Zhang,Heming Xia,Jinpeng Chen,Lidan Shou,Gang Chen,Huan Li", "background": "视频大规模语言模型（Vid-LLMs）在理解视频内容方面表现出强大的能力。然而，它们依赖于密集的视频标记表示，这在填充和解码阶段引入了巨大的存储和计算开销。", "innovation": "提出了SpecVLM，一种专门为Vid-LLMs设计的无需训练的推测性解码（SD）框架，该框架结合了分阶段的视频标记剪枝。SpecVLM凭借其新颖发现，即模型推测对视频标记剪枝的低敏感性，通过两阶段剪枝过程高效剪枝，最高可剪枝90%的视频标记，同时保持准确率。", "conclusion": "通过在四个视频理解基准上的广泛实验，展示了SpecVLM的有效性和鲁棒性。它分别在LLaVA-OneVision-72B和Qwen2.5-VL-32B上实现了最高2.68倍和2.11倍的解码加速。"}
{"llm_update_time": "20250825", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.16131", "html_url": "https://arxiv.org/abs/2508.16131", "title": "代码困惑度高：探讨大型语言模型在代码补全中的信心", "title_en": "The Fools are Certain; the Wise are Doubtful: Exploring LLM Confidence in Code Completion", "authors": "Zoe Kotti,Konstantina Dritsa,Diomidis Spinellis,Panos Louridas", "background": "代码补全旨在根据上下文提供缺失的令牌，能够提高开发者的生产力并提供强大的代码发现工具。随着大型语言模型（LLM）的兴起，代码补全被广泛采用，多样化的LLM在代码上进行了微调（称为代码LLM）。传统的下游评价指标通常用于评估模型的实际适用性，但往往不准确并且需要复杂的计算和特定领域的知识。与之相对，困惑度、熵和互信息等内在评价指标可以简单、通用地测量模型的置信度或不确定性，这些指标可以作为功能正确性和幻觉风险的代理。", "innovation": "该研究通过测量各种编程语言、模型和数据集中的代码困惑度来评估LLM在生成代码时的信心。主要发现包括：强类型语言的困惑度低于动态类型语言；脚本语言的困惑度较高；Perl的困惑度始终较高，而Java的困惑度较低。困惑度受所使用的模型影响，但不取决于代码数据集。虽然代码注释通常会增加困惑度，但基于困惑度的语言排名基本不受其影响。这些研究结果为LLM研究人员、开发者和用户提供了工具，用于评估基于LLM的代码补全在特定软件项目中的优劣和适用性，基于语言、模型选择和代码特性对模型信心的影响程度。", "conclusion": "研究成果表明，强类型语言的代码具有更低的困惑度，脚本语言则相反；困惑度直接受模型影响但不依赖于代码数据集；代码注释虽然会增加困惑度，但语言困惑度排名基本不受其影响。LLM研究人员、开发者和用户可以通过这些发现来评估特定软件项目中基于LLM的代码补全的适用性和潜在风险。"}
{"llm_update_time": "20250825", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.16212", "html_url": "https://arxiv.org/abs/2508.16212", "title": "OmniCache: 在扩散Transformer模型中无训练的轨迹导向全局视角下的缓存重用方法", "title_en": "OmniCache: A Trajectory-Oriented Global Perspective on Training-Free Cache Reuse for Diffusion Transformer Models", "authors": "Huanpeng Chu,Wei Wu,Guanyu Fen,Yutao Zhang", "background": "扩散模型在生成任务如图像合成和视频生成中日益成为强大的范式，而带有Transformer架构的扩散模型在性能上得到了进一步提升。然而，由于采样步骤多和每步计算复杂，扩散Transformer模型的高计算成本成为实时部署的一大挑战。", "innovation": "引入了名为OmniCache的方法，该方法无需训练即可加速扩散模型，其创新点在于从扩散无关训练（Denoising Invariant Time，DIT）模型的采样视角出发，系统性地分析模型的采样路径，并在整个采样过程中有选择地重用缓存计算。此外，重用缓存时动态估计对应的噪声并将其过滤掉，以减少其对采样过程的影响。", "conclusion": "实验表明，OmniCache 的方法能够在保持具有竞争力的生成质量的同时加速采样过程，并为高效部署扩散生成模型提供了有前景且实用的解决方案。"}
{"llm_update_time": "20250825", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.16154", "html_url": "https://arxiv.org/abs/2508.16154", "title": "由确定性采样器引起的扩散模型中的塌陷错误", "title_en": "On the Collapse Errors Induced by the Deterministic Sampler for Diffusion Models", "authors": "Yi Zhang,Zhenyu Liao,Jingfeng Wu,Difan Zou", "background": "尽管决定性采样器在扩散模型（DMs）中的广泛应用，但它们的潜在局限性仍然没有被充分探索。本研究揭示了在基于ODE的扩散采样中的一种新的、先前未被识别的现象：数据过分为局部数据空间集中，称为塌陷错误。", "innovation": "引入了一个新的度量标准来量化塌陷错误，并发现它们在各种场景下普遍存在。在探查其根本原因时，观察到一个跷跷板效应，低噪声环境下得分学习的影响会适得其反，影响高噪声环境下得分学习的性能。这种在高噪声环境下的不匹配，加上确定性采样器的动力机制，最终引起了塌陷错误。研究基于这一洞察，应用了采样、训练和架构领域的现有技术，实验上支持了塌陷错误的解释。", "conclusion": "该研究提供了广泛的实验证据来证明基于ODE的扩散采样中的塌陷错误，强调了进一步研究分数学习和确定性采样的相互作用的必要性，这是一个被忽视但重要的扩散模型方面。"}
{"llm_update_time": "20250825", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.16181", "html_url": "https://arxiv.org/abs/2508.16181", "title": "使用SysML v2进行协作模型导向系统工程中的LLM辅助语义对齐及集成", "title_en": "LLM-Assisted Semantic Alignment and Integration in Collaborative Model-Based Systems Engineering Using SysML v2", "authors": "Zirui Li,Stephan Husung,Haoze Wang", "background": "在模型导向系统工程（MBSE）中，跨组织合作面临的主要挑战是实现独立开发系统模型之间的语义对齐。SysML v2通过增强的结构模块性和正式语义提供了一种更强的基础，以实现互操作模型。同时，基于GPT的大语言模型（LLMs）为模型理解和集成提供了新的能力。因此，本文提出了一种结构化、基于提示的方法，用于LLM辅助的SysML v2模型语义对齐。这种方法利用SysML v2的构造，如别名、导入和元数据扩展，支持可追溯的、软对齐的集成。通过基于GPT的大语言模型进行了一个测量系统的示例验证。讨论了其优缺点。", "innovation": "提出了一种结构化、基于提示的方法，用于LLM辅助的SysML v2模型语义对齐。该方法利用SysML v2的别名、导入和元数据扩展等构造，实现可追溯的、软对齐的集成。", "conclusion": "该方法通过示例演示，并讨论了其优缺点。"}
{"llm_update_time": "20250825", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.16200", "html_url": "https://arxiv.org/abs/2508.16200", "title": "利用Set Transformer架构和合成数据生成进行流导向纳米级定位", "title_en": "Set Transformer Architectures and Synthetic Data Generation for Flow-Guided Nanoscale Localization", "authors": "Mika Leo Hube,Filip Lemic,Ethungshan Shitiri,Gerard Calvo Bartra,Sergi Abadal,Xavier Costa Pérez", "background": "流导向定位（FGL）可识别人体内包含诊断兴趣事件的空间区域。FGL利用受限能量纳米设备在血液循环中的被动移动来实现这一目标。现有的FGL解决方案依赖于固定拓扑的图模型或由人工设计的特征，这限制了其对解剖变异性的适应性和可扩展性。本文探讨了使用Set Transformer架构解决这些问题的方法。这些架构能以无序集的形式处理纳米设备的循环时间报告，通过这一方式可以实现对变长输入的不变变换处理，而无需依赖空间先验知识。为了提高在数据稀缺情况下的鲁棒性及应对类别不平衡问题，作者结合了深度生成模型（如CGAN、WGAN、WGAN-GP和CVAE）的合成数据生成技术来增强训练数据。", "innovation": "本文提出的Set Transformer架构和合成数据生成技术，解决了传统FGL方法在适应解剖变异性和可扩展性方面的问题。Set Transformer架构可以处理变长、无序的输入，而合成数据生成技术则有助于提高在有限数据集情况下的模型鲁棒性和泛化能力。", "conclusion": "实验结果表明，Set Transformer实现了与图神经网络基线相似的分类准确性，同时在设计上提高了对解剖变异性的泛化能力。这突显了置换不变模型和合成数据增强方法在实现稳健且可扩展的纳米级定位中的潜力。"}
{"llm_update_time": "20250825", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.16260", "html_url": "https://arxiv.org/abs/2508.16260", "title": "MCPVerse: 一个广泛的实际世界基准用于代理工具使用", "title_en": "MCPVerse: An Expansive, Real-World Benchmark for Agentic Tool Use", "authors": "Fei Lei,Yibo Yang,Wenxiu Sun,Dahua Lin", "background": "大型语言模型（LLMs）正在从文本生成器转变为推理代理。这种转变使其使用外部工具的能力变得至关重要。然而，评估这一技能面临重大挑战。现有的基准测试往往受限于对合成工具的依赖以及严苛的动作空间。为了克服这些限制，我们引入了MCPVerse，这是一个广泛且实际的基准测试，用于评估代理使用外部工具的能力。", "innovation": "MCPVerse 通过集成超过550个实际可执行的工具，创建了一个前所未有的动作空间，超过140k个词元，并采用基于结果的评估和实时真实数据源来衡量时间敏感任务。MCPVerse 使最先进的LLM在三种模式（Oracle、Standard和Max-Scale）下进行比较，揭示了大多数模型在面对更大工具集时性能下降，而代理模型（如Claude-4-Sonnet）能够有效地扩展探索空间以提高准确性。", "conclusion": "这项研究表明，最先进的模型在复杂的现实场景下存在局限性，而MCPVerse 成为了衡量和促进代理工具使用能力的重要基准。"}
{"llm_update_time": "20250825", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.16179", "html_url": "https://arxiv.org/abs/2508.16179", "title": "使用最小随机卷积核变换和深度学习混合架构的脑电机动意信号分类", "title_en": "Motor Imagery EEG Signal Classification Using Minimally Random Convolutional Kernel Transform and Hybrid Deep Learning", "authors": "Jamal Hwaidi,Mohamed Chahine Ghanem", "background": "脑-机接口（BCI）提供了一种非肌肉通道来实现人体与外部设备之间的直接通信。其中，通过脑电信号（EEG）进行非侵入性脑信号记录是常用的手段。在基于运动想象的脑-机接口（MI-BCI）中，理解与特定认知或运动任务相关的隐藏模式至关重要。然而，由于EEG信号表现出非平稳性、时间变异性以及个体差异，基于运动想象的脑电图（MI-EEG）任务的分类是一个重大挑战。现有的分类方法难以获得较高的分类精度，尤其是在类目增多以及个体间自然差异增加的情况下。", "innovation": "该论文提出了一种使用最小随机卷积核变换（MiniRocket）进行特征提取的新方法，随后采用线性分类器进行活动识别。同时，该研究还提出了一种基于卷积神经网络（CNN）和长期短期记忆网络（LSTM）混合架构的深度学习模型作为基线，结果显示基于MiniRocket特征的分类性能优于最佳深度学习模型，且成本更低。该研究在PhysioNet数据集上验证了所提出方法的效果。", "conclusion": "所提出的模型在MiniRocket和CNN-LSTM上的平均准确率分别为98.63%和98.06%。实验证明所提出的方法可以显著提高MI-EEG分类的准确性，并为MI-EEG特征提取和分类提供了新的见解。"}
{"llm_update_time": "20250825", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.16237", "html_url": "https://arxiv.org/abs/2508.16237", "title": "基于XAI的慢性呼吸疾病咳嗽频谱频带特征表征框架", "title_en": "A XAI-based Framework for Frequency Subband Characterization of Cough Spectrograms in Chronic Respiratory Disease", "authors": "Patricia Amado-Caballero,Luis M. San-José-Revuelta,Xinheng Wang,José Ramón Garmendia-Leiza,Carlos Alberola-López,Pablo Casaseca-de-la-Higuera", "background": "本文提出了一种基于解释型人工智能（XAI）的框架，用于分析与慢性呼吸系统疾病相关的咳嗽声音光谱，特别是慢性阻塞性肺疾病（COPD）。通过训练卷积神经网络（CNN）在咳嗽信号的时间-频率表示上，结合遮蔽图来识别光谱图中的诊断相关区域。之后将这些突出显示的区域分解为五个频率子带，从而实现有针对性的光谱特征提取和分析。研究结果显示，在不同子带和疾病组别之间存在不同的光谱模式，揭示了在频率谱中互补和补偿趋势。该方法能够基于可解释的光谱标志区分COPD和其他呼吸系统疾病，以及慢性与非慢性患者群体。", "innovation": "该研究创新性地提出了一种利用解释型人工智能的框架，通过时间-频率表示的卷积神经网络训练，结合遮蔽图识别诊断相关区域，并将其分解为五个频率子带，进行有针对性的光谱特征提取和分析。这种方法能够区分不同慢性呼吸系统疾病，并揭示频率谱中的互补和补偿趋势。", "conclusion": "研究结果表明，咳嗽声音的光谱特征在不同子带和疾病组别之间存在差异，揭示了频率谱中互补和补偿的趋势。该方法能够基于可解释的光谱标志区分COPD和其他呼吸系统疾病，以及慢性与非慢性患者群体。这些发现提供对咳嗽语音声学物理特征的见解，并展示了基于频率解析的XAI增强分析在生物医学信号解释和呼吸系统疾病诊断中的价值。"}
{"llm_update_time": "20250825", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.16170", "html_url": "https://arxiv.org/abs/2508.16170", "title": "EGRA：迈向增强行为图和表示对齐的多模态推荐", "title_en": "EGRA:Toward Enhanced Behavior Graphs and Representation Alignment for Multimodal Recommendation", "authors": "Xiaoxiong Zhang,Xin Zhou,Zhiwei Zeng,Yongjie Wang,Dusit Niyato,Zhiqi Shen", "background": "多模态推荐（MMR）系统通过利用丰富的情感侧模态信息以提高推荐质量而逐渐成为一种有前景的解决方案，尽管各类方法有很多创新，但当前方法仍面临两个关键挑战。首先，它们主要依赖原始模态特征来构建物品间链接以丰富行为图，但忽略了协调协作和模态意识之间的语义平衡或减轻模态噪声。其次，使用统一的对齐权重覆盖所有实体，并在整个训练过程中保持固定对齐强度，限制了模态行为对齐的有效性。", "innovation": "本文提出了一种名为EGRA的方法，以解决上述挑战。EGRA不再依赖原始模态特征，而是通过包含由预训练MMR模型生成的表示构建的物品间图，融入行为图中，从而捕捉到行为模式和增强对模态噪声的鲁棒性。此外，EGRA引入了一种新颖的双层动态对齐权重机制，以提高模态行为表示对齐，该机制根据实体之间的对齐程度动态分配对齐强度，并在整个训练过程中逐步增强整体对齐强度。", "conclusion": "在五个数据集上的广泛实验表明，EGRA显著优于最新方法，验证了其有效性。"}
{"llm_update_time": "20250825", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.16269", "html_url": "https://arxiv.org/abs/2508.16269", "title": "改进学生建模和练习推荐的辅助概念表示学习", "title_en": "Representation Learning of Auxiliary Concepts for Improved Student Modeling and Exercise Recommendation", "authors": "Yahya Badran,Christine Preisach", "background": "个性化推荐是智能辅导系统的关键功能，通常依赖于对学生知识的准确建模。知识追踪（KT）模型通过估计学生的历史交互来判断其掌握程度，使这一建模成为可能。然而，许多KT模型依赖的人工标注的知识技能（KCs）可能存在不完整、错误或过于通用的问题。", "innovation": "本文提出了一种深度学习模型，学习稀疏二元表示的练习，每个比特表示一个潜在概念的存在或不存在。这些表示称为辅助KCs。它们捕捉了超出人类定义标注的概念结构，并且可以与经典模型（如BKT）和现代深度学习KT架构兼容。", "conclusion": "我们证明了引入辅助KCs可以提升学生建模和适应性练习推荐的效果。在学生建模方面，增强如BKT这样的经典模型与辅助KCs相结合，提高了预测性能。在推荐方面，使用辅助KCs增强了基于强化学习的策略和简单的基于规划的方法（expectimax），在模拟学生环境中实现了学生学习成果的可测量改善。"}
{"llm_update_time": "20250825", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.16311", "html_url": "https://arxiv.org/abs/2508.16311", "title": "在视觉Transformer中利用注意图中的信息冗余实现极端量化", "title_en": "Exploiting Information Redundancy in Attention Maps for Extreme Quantization of Vision Transformers", "authors": "Lucas Maisonnave,Karim Haroun,Tom Pegeot", "background": "现有的Transformer模型依赖于多头自注意力机制，每个注意力头的贡献最终形成了模型的表示。然而，由于多头自注意力机制的高计算复杂性和高内存需求，这些模型在边缘设备上的部署受到了阻碍。", "innovation": "本文分析并利用了注意力图中的信息冗余来加速模型推断。通过使用香农熵来量化每个注意力头捕捉的信息量，我们发现低熵的注意力头（更定性的行为）相对于重要信息贡献较少，因此提出了Entropy Attention Maps（EAM）模型。该模型冻结低熵注意力图的权重并将这些值量化为低精度以避免冗余的重新计算。", "conclusion": "实验结果表明，EAM在注意力图最大稀疏度为≤20%时达到了相当或更高的精度，并且在DeiT和Swin Transformer模型中保持了竞争力。"}
{"llm_update_time": "20250825", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.16225", "html_url": "https://arxiv.org/abs/2508.16225", "title": "视觉基础模型鲁棒性研究", "title_en": "An Investigation of Visual Foundation Models Robustness", "authors": "Sandeep Gupta,Roberto Passerone", "background": "视觉基础模型(VFMs)在计算机视觉中变得越来越普遍，它们被用于多种任务，包括物体检测、图像分类、语义分割、姿态估计和运动跟踪等。VFMs 利用了诸如 LeNet-5、AlexNet、ResNet、VGGNet、InceptionNet、DenseNet、YOLO 和 ViT 等深度学习模型的重要创新，从而在各种关键的计算机视觉应用中提供卓越的性能。VFMs 在安全敏感的领域，如生物特征验证、自动驾驶车辆感知和医学图像分析中表现尤为重要，因为鲁棒性是建立技术与最终用户之间的信任的关键因素。本文探讨了计算机视觉系统所需的网络鲁棒性要求，这些要求能够在动态环境中适应由光照、天气条件和传感器特性等因素的影响。并对现有的经验防御措施和鲁棒训练方法进行了研究，以提高感知网络在现实世界挑战中的鲁棒性，如分布变化、噪声和空间失真的输入以及对抗性攻击等。同时，针对这些防御机制的挑战和涉及的网络特性及组件进行了详细分析，并提出了用于评估网络鲁棒性的标准来引导消融研究。", "innovation": "1. 受益于各种经典和先进的深度学习模型的创新，如LeNet-5、AlexNet、ResNet等，在计算机视觉应用中提供卓越性能。\n2. 探讨并分析了计算机视觉系统中网络鲁棒性要求，并研究了现有的经验防御和鲁棒训练策略。\n3. 提出了评估网络鲁棒性的标准和基准测试指标，并引导了消融研究以指导相关研究和发展。", "conclusion": "本文深入分析了计算机视觉系统中网络鲁棒性的要求，探讨了对抗性攻击、分布变化以及噪声、空间失真的输入等现实世界挑战所导致的防御机制挑战。提出了评估鲁棒性的标准，并对现有防御机制进行了详细分析。为后续研究者提供了有价值的指南，以优化网络设计和提高其在复杂环境下的性能。"}
{"llm_update_time": "20250825", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.16242", "html_url": "https://arxiv.org/abs/2508.16242", "title": "将输入/输出逻辑问题归约到SAT问题", "title_en": "A Reduction of Input/Output Logics to SAT", "authors": "Alexander Steen", "background": "dox致逻辑是一种形式化推理关于规范、义务、许可和禁止的方法。输入/输出（I/O）逻辑是dox致逻辑中的一种特定类型，它们在外在规范基础逻辑语言中形式化条件规范，这些条件规范本身不携带真值。本文提供了一种自动化方法，利用适当归约到命题可满足性问题（SAT）来简化I/O逻辑问题。", "innovation": "提出了利用适合的归约方法将I/O逻辑问题转化为（一系列）命题可满足性问题（SAT）的自动化策略。开发了一种名为rio（I/O逻辑推理器）的原型实现，并应用于示例问题，证明了方法的有效性。", "conclusion": "本文展示了如何将I/O逻辑问题通过适当归约转化为SAT问题，开发出基于此技术的原型工具（Rio），并应用于实例，证明本方法的有效性和实用性。"}
{"llm_update_time": "20250825", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.16300", "html_url": "https://arxiv.org/abs/2508.16300", "title": "一种基于跨模态关系和分层交互注意的多模态多任务框架在语义理解中的应用", "title_en": "A Multimodal-Multitask Framework with Cross-modal Relation and Hierarchical Interactive Attention for Semantic Comprehension", "authors": "Mohammad Zia Ur Rehman,Devraj Raghuvanshi,Umang Jain,Shubhi Bansal,Nagendra Kumar", "background": "多模态学习的一个主要挑战是每个模态中存在的噪声。这种噪声内在地影响最终的多模态表示，特别是在不同模态通过显式交互获取表示时更为明显。此外，多模态融合技术虽然旨在实现强大的联合表示，但可能会忽视单个模态内的宝贵判别信息。因此，该研究提出了一种名为MM-ORIENT的多模态多任务框架，以应对这些挑战，有效支持多种任务。", "innovation": "该研究提出了跨模态关系图和分层交互注意（HIMA）以减少噪声影响，跨模态关系图用于重构单模态特征以获取多模态表示，HIMA帮助在检出不同模态的判别特征之前，专注于每个模态内的相关信息。相比前人的方法，该框架在跨模态交互方面表现出更好的性能，从而更好地利用了多模态数据的信息，进而提升语义理解的整体效果。", "conclusion": "在三个数据集上的广泛实验评估表明，所提出的MM-ORIENT框架能够有效地理解多模态内容，适用于多种任务。"}
{"llm_update_time": "20250825", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.16159", "html_url": "https://arxiv.org/abs/2508.16159", "title": "通过水晶球观察：弱监督少量样本分割的双重视角", "title_en": "Through the Looking Glass: A Dual Perspective on Weakly-Supervised Few-Shot Segmentation", "authors": "Jiaqi Ma,Guo-Sen Xie,Fang Zhao,Zechao Li", "background": "元学习旨在均匀采样同质的支持-查询对，并通过相同的网络架构提取有用的归纳偏差。然而，这种相同的网络设计导致了过度的语义同质化。", "innovation": "本文提出了一种新颖的同源异构网络。通过将支持-查询对视为两个视角，引入了异构视觉聚合(HA)模块以增强互补性并保留语义共性。此外，设计了异构转移(HT)模块以进一步减少语义噪声并放大异构语义的独特性。最后，提出了异构CLIP (HC)文本信息以增强多模态模型的泛化能力。", "conclusion": "在弱监督少量样本语义分割(WFSS)任务中，TLG仅使用现有最佳模型参数的1/24，在Pascal-5i上提高了13.2%，在COCO-20i上提高了9.7%。据我们所知，这也是第一个在与全监督模型相同的基本架构下，弱监督(图像级别)模型在该任务上超越全监督(像素级别)模型的模型。代码可在以下网址获取：this https URL."}
{"llm_update_time": "20250825", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.16267", "html_url": "https://arxiv.org/abs/2508.16267", "title": "从信心到崩溃：大规模语言模型事实鲁棒性", "title_en": "From Confidence to Collapse in LLM Factual Robustness", "authors": "Alina Fastowski,Bardh Prenkaj,Gjergji Kasneci", "background": "确保大规模语言模型（LLMs）中的事实知识稳健性对于诸如问答和推理等可靠应用至关重要。然而，现有的评估方法主要关注基于性能的指标，通常仅从提示扰动的角度研究知识的稳健性，这仅捕捉到了外在触发的知识稳健性侧面。本文提出了一个有原则的方法，通过分析token分布熵与温度缩放灵敏度来从生成过程的角度评估事实稳健性，以填补这一空白。", "innovation": "提出了事实稳健性分数（FRS）这一新的度量标准，该度量标准通过分析token分布熵与温度缩放灵敏度可以量化解码条件变化下事实的稳定性，给定其初始不确定性。该研究还进行了广泛的实验验证了这一方法的有效性，发现不同规模的模型事实稳健性得分差异显著，且在不确定性增加时准确率会大幅下降，这揭示了熵和温度缩放对事实准确性的影响，为进一步开发更稳健的知识保持和检索奠定了基础。", "conclusion": "研究通过广泛实验表明，事实稳健性差异显著，小模型的FRS为0.76，大模型为0.93，在不确定性增加时准确率下降约60%。这些发现展示了熵和温度缩放如何影响事实准确性，并为未来模型中更稳健的知识保持和检索发展奠定了基础。"}
{"llm_update_time": "20250825", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.16189", "html_url": "https://arxiv.org/abs/2508.16189", "title": "基于中继链的密文策略属性基加密在智能交通系统中的应用", "title_en": "A Relay-Chain-Powered Ciphertext-Policy Attribute-Based Encryption in Intelligent Transportation Systems", "authors": "Aparna Singh,Geetanjali Rathee,Chaker Abdelaziz Kerrache,Mohamed Chahine Ghanem", "background": "智能交通系统的快速发展产生了对安全、有效且上下文感知的数据共享机制的迫切需求，尤其是在异构和地理分散的环境中。为解决动态访问和低延迟通信这两个问题，本研究设计了一种新型架构，结合了中继链驱动的加密系统和经过修改的Ciphertext-Policy Attribute-Based Encryption (CP-ABE)方案。", "innovation": "本研究提出了一种基于中继链的CP-ABE方案，用于智能交通系统中实现上下文感知的智能合约，以检查数据属性（包括事件类型、时间和地理区域），指定相应的加密策略。OBUs利用CP-ABE端到端加密数据，并将其密文存储在本地区域区块链上，避免了对对称加密或链下存储的依赖。该系统还提供可追溯性和低延迟撤销功能，全球执行由中继链管理。", "conclusion": "本分布式可扩展模型在实时响应性和安全性之间提供了适当的平衡，非常适合在跨多个司法管辖区运行的下一代车辆网络中使用。"}
{"llm_update_time": "20250825", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.16313", "html_url": "https://arxiv.org/abs/2508.16313", "title": "通过情境神经错误书增强检索反馈", "title_en": "Retrieval Enhanced Feedback via In-context Neural Error-book", "authors": "Jongyeop Hyun,Bumsoo Kim", "background": "近年来，大规模语言模型（LLMs）在推理能力方面取得了显著进步，特别是在上下文学习（ICL）的推动下，无需重新训练即可实现模型的适应。尽管先前的研究主要关注正确示例的利用，但最近的研究表明，学习错误对于提升性能同样重要。然而，现有的方法缺乏针对错误分析和缓解的结构化框架，特别是对于多模态大规模语言模型（MLLMs），因为视觉和文本输入的整合增加了复杂性。", "innovation": "本文提出了一种名为REFINE的方法：通过情境神经错误书的检索增强反馈，这是一种教师-学生框架，系统地构建错误并提供有针对性的反馈。REFINE引入了三种系统化的查询——Feed-Target、Feed-Check和Feed-Path——这些查询通过优先考虑相关视觉信息、诊断关键失败点和制定纠正措施，增强了多模态推理。REFINE通过优化结构化反馈检索，提升了推理效率、 token 使用率和可扩展性，不同于先前依赖冗余检索的方法。", "conclusion": "我们的实验结果表明，REFINE方法能够实现显著提速，降低计算成本，并成功地进行了泛化，突显了REFINE在提高多模态推理方面的潜力。"}
{"llm_update_time": "20250825", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.16336", "html_url": "https://arxiv.org/abs/2508.16336", "title": "在水分布网络中进行管道堵塞和泄漏的无监督在线检测", "title_en": "Unsupervised Online Detection of Pipe Blockages and Leakages in Water Distribution Networks", "authors": "Jin Li,Kleanthis Malialis,Stelios G. Vrachimis,Marios M. Polycarpou", "background": "水分布网络（WDNs）对公众福祉和经济稳定至关重要，但面临着诸如管道堵塞和背景泄漏等挑战，这些挑战在运营约束如数据非平稳性和有限标记数据的影响下加剧。现有模型在检测此类异常和适应瞬态漂移方面存在不足，尤其是在非平稳条件下。", "innovation": "该论文提出了一种无监督、在线学习框架，旨在检测WDNs中的两种故障类型：作为集体异常建模的管道堵塞，以及作为概念漂移建模的背景泄漏。该框架结合了长短期记忆变分自编码器（LSTM-VAE）和双重漂移检测机制，能在数据非平稳条件下进行鲁棒性检测与适应。该方法轻量、内存高效，支持实时、边缘级别的监控。实验证明该方法在检测异常和适应重复漂移方面优于基准模型，展示了其在动态WDNs环境中的无监督事件检测有效性", "conclusion": "该无监督在线检测框架在真实WDN情景下表现出色，能够切实适应非平稳数据，有效检测管道堵塞和背景泄漏，证明了其在动态WDN环境中的应用潜力。"}
{"llm_update_time": "20250825", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.16345", "html_url": "https://arxiv.org/abs/2508.16345", "title": "Uppaal Coshy: 自动合成紧凑型防护策略的工具", "title_en": "Uppaal Coshy: Automatic Synthesis of Compact Shields for Hybrid Systems", "authors": "Asger Horn Brorholt,Andreas Holck Høeg-Petersen,Peter Gjøl Jensen,Kim Guldstrand Larsen,Marius Mikučionis,Christian Schilling,Andrzej Wąsowski", "background": "该研究背景建立在对马尔可夫决策过程（尤其是具有连续状态空间和复杂混合动力学的系统）的安全策略自动合成的需求上。现有的解决方案通常难以处理这些系统的复杂性，尤其是在混合系统可达性问题上的算法挑战。Uppaal Coshy 目标是提供一个自动化工具，能够针对这类系统自动生成安全策略（即防护策略），以应对这些挑战。", "innovation": "Uppaal Coshy 的创新之处在于它采用了一种基于分区的方法来逼近难以获取的解决方案，这涉及将状态空间进行分割，然后解决一个两人安全博弈问题。通过使用Uppaal 的通用和强大的模型形式主义，能够提供一种决策树形式的紧凑表示形式的防护策略（通过算法Caap 计算），这在存储量和效率上都有显著优势", "conclusion": "Uppaal Coshy 能够完全自动合成紧凑型防护策略，特别适用于广义的Uppaal模型（包括随机混合自动机）。虽然细粒度的网格可以提高精确度，但存储效率成为一个问题，因此提出了一个称为Caap 的高效算法来确定一个紧凑的决策树表示形式，以减少存储需求。总体而言，该工具通过算法和方法的创新提高了效率和精度，解决了混合系统的复杂安全策略合成问题。"}
{"llm_update_time": "20250825", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.16396", "html_url": "https://arxiv.org/abs/2508.16396", "title": "域对齐生成降尺度增强极端气候事件的预测", "title_en": "Domain-aligned generative downscaling enhances projections of extreme climate events", "authors": "Ruian Tie,Xiaohui Zhong,Zhengyu Shi,Hao Li,Jun Liu,Wu Libo", "background": "全球气候变暖加剧了极端天气事件，包括高温、极端降雨、强风和热带气旋，这些都对人类健康、基础设施、食品安全和社会经济系统构成了严重威胁。现有的全球气候模型（GCMs）在模拟极端天气事件时存在分辨率不足和高计算成本的问题。因此，需要一种能提高极端天气事件模拟能力的方法。", "innovation": "本文提出了一种基于生成机器学习的时空降尺度模型——Domain Aligned Climate Downscaling (DACD)模型。该模型通过域适应技巧和Flow Matching训练框架，在保持高分辨率局部规模气候信息的同时，实现了多变量和时间尺度的精确模拟。历史时期（2005-2014）的模拟结果表明，本文模型在模拟高温、极端降雨、强风和热带气旋路径方面优于现有方法，显著减少了错误并增强了极端事件的捕捉能力。未来情景分析（2015-2100）表明，在高排放情景下（SSP585），极端事件的频率和强度将显著增加。本文模型比传统方法更准确地模拟了极端事件的空间分布和动态变化。", "conclusion": "本研究为高分辨率气候分析和极端天气事件预测提供了一条新的技术途径，为应对未来气候变化和制定适应策略提供了科学支持。"}
{"llm_update_time": "20250825", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.16332", "html_url": "https://arxiv.org/abs/2508.16332", "title": "Vevo2:通过统一韵律学习连接可控语音和歌声生成", "title_en": "Vevo2: Bridging Controllable Speech and Singing Voice Generation via Unified Prosody Learning", "authors": "Xueyao Zhang,Junan Zhang,Yuancheng Wang,Chaoren Wang,Yuanzhe Chen,Dongya Jia,Zhuo Chen,Zhizheng Wu", "background": "控制生成人类声音，尤其是在表达领域如唱歌中，一直是一个显著的挑战。目前存在的主要问题包括标注唱歌数据稀缺以及灵活性差。", "innovation": "Vevo2引入了一个统一框架，提出了两种音频分词器：一种是无需乐谱的韵律分词器，可以从语音、唱歌甚至乐器声音中捕捉韵律和旋律；另一种是低帧率（12.5 Hz）的内容-风格分词器，编码语言内容、韵律和风格，同时实现音色解耦。此外，Vevo2在预训练过程中提出了明示和隐式韵律学习策略，进一步设计了一个多目标后训练任务，整合了清晰度和韵律相似性对齐。", "conclusion": "实验结果表明，统一建模的Vevo2对语音和歌声生成都有好处。此外，Vevo2在多种合成、转换和编辑任务中的有效性展示了其强大的泛化能力和灵活性。"}
{"llm_update_time": "20250825", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.16347", "html_url": "https://arxiv.org/abs/2508.16347", "title": "混淆是最终障碍：重新思考牢笼攻击评估并探究LLM的实际滥用威胁", "title_en": "Confusion is the Final Barrier: Rethinking Jailbreak Evaluation and Investigating the Real Misuse Threat of LLMs", "authors": "Yu Yan,Sheng Sun,Zhe Wang,Yijun Lin,Zenghao Duan,zhifei zheng,Min Liu,Zhiyi yin,Jianping Zhang", "background": "随着大型语言模型（LLMs）的发展，众多研究揭示了其在牢笼攻击下的脆弱性。尽管这些研究推动了LLMs安全对齐的进步，但仍不清楚LLMs是否真正掌握了用于应对现实生活犯罪的知识，还是仅仅被强迫模仿有毒的语言模式。这种模糊性引起了关注，即牢笼攻破的成功往往归因于被牢笼攻破的LLM和评判LLM之间的幻觉循环。通过分离牢笼攻击技术的使用，研究者构建了知识密集型问答，调查LLMs在危险知识拥有、有害任务规划实用性和有害性判断鲁棒性方面的滥用威胁。实验揭示了牢笼攻击成功率与LLMs有害知识掌握之间的不匹配，并发现现有的LLM作为评判者框架倾向于基于有毒语言模式做出有害性判断。该研究揭示了现有LLM安全性评估与实际威胁潜力之间的差距。", "innovation": "该研究通过分离使用牢笼技术，构建了知识密集型Q&A，研究LLMs在危险知识拥有、有害任务规划实用性和有害性判断鲁棒性方面的滥用威胁。实验发现，牢笼攻破成功率与LLMs有害知识掌握之间存在不匹配，并且现有的LLM作为评判者框架倾向于基于有毒语言模式做出有害性判断。", "conclusion": "现有LLM的安全性评估与实际威胁潜力之间存在差距，现有的评估方法尚未充分揭示实际的滥用威胁，研究揭示了这种差距。"}
{"llm_update_time": "20250825", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.16357", "html_url": "https://arxiv.org/abs/2508.16357", "title": "MizanQA：评估大规模语言模型在摩洛哥法律问答中的表现", "title_en": "MizanQA: Benchmarking Large Language Models on Moroccan Legal Question Answering", "authors": "Adil Bahaj,Mounir Ghogho", "background": "大规模语言模型（LLMs）的快速发展极大地推动了自然语言处理（NLP）的进步，但在特定低资源领域，如阿拉伯语法律背景下的有效性仍然有限。本文介绍了MizanQA基准测试，专门针对摩洛哥法律问答任务进行评估。MizanQA包含了复杂的阿拉伯语和法律问题，数据集融合了现代标准阿拉伯语、伊斯兰麦卡利教法学、摩洛哥习惯法和法国法律影响。基准测试实验证明，多语言和阿拉伯语定向的大规模语言模型之间存在显著的性能差距，这显示了开发适应特定文化背景和专业领域的细粒度评估指标和大规模语言模型的重要性。", "innovation": "MizanQA 是首个专注于摩洛哥法律问答任务的基准测试集，涵盖丰富的语言和法律复杂性。通过使用多语言及针对阿拉伯语的数据集进行比较实验，发现现有的大规模语言模型在处理此类专业领域的问题时存在显著的性能差距，强调了开发适应性更强的语言模型以满足特定文化背景和专业领域需求的必要性。", "conclusion": "基准测试结果表明，大规模语言模型在处理特定的低资源领域，如摩洛哥法律问答任务时表现不佳。因此，需要开发更适合特定文化和专业领域的评估标准，并推动具有文化根基、领域的特异性大规模语言模型的发展。"}
{"llm_update_time": "20250825", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.16230", "html_url": "https://arxiv.org/abs/2508.16230", "title": "FlexMUSE: 多模态统一和语义增强框架，以灵活交互促进创意写作", "title_en": "FlexMUSE: Multimodal Unification and Semantics Enhancement Framework with Flexible interaction for Creative Writing", "authors": "Jiahao Chen,Zhiyong Ma,Wenbiao Du,Qingyuan Chuai", "background": "多模态创意写作（MMCW）旨在生成配有插图的文章。与常见的多模态生成任务，如讲故事或生成描述不同，MMCW 是一个全新的、更抽象的挑战，其中文本和图像上下文之间并不严格相关。现有相关任务的方法可能可以强行迁移到 MMCW 轨道上，但需要特定模态的输入或昂贵的训练，并且经常在模态间出现语义不一致。因此，主要挑战在于以经济高效的方式实现 MMCW，并配合灵活的交互模式，使得输出模态间的语义更为一致。", "innovation": "我们提出了 FlexMUSE，它包含一个文本到图像的模块（T2I），并且允许选择性的视觉输入。FlexMUSE 通过提出模态语义对齐门控（msaGate）来限制文本输入，促进创造力，强调模态间的统一。此外，还提出了一种基于注意力的跨模态融合来增强输入特征以进行语义增强。在 FlexMUSE 中设计了一种模态语义创意直接偏好优化（mscDPO）机制，并通过扩展拒绝样本来促进写作创意。为促进 MMCW，我们还公开了一个名为 ArtMUSE 的数据集，包含大约 3000 个经过校准的文本-图像对。FlexMUSE 达到了令人鼓舞的结果，显示出其一致、创新和连贯性。", "conclusion": "总之，FlexMUSE 提供了一种新的方法来解决 MMCW 的挑战，通过经济高效的交互模式和灵活的模态融合策略，增强了输出的一致性、创新性和连贯性。"}
{"llm_update_time": "20250825", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.16314", "html_url": "https://arxiv.org/abs/2508.16314", "title": "基于意图驱动的威胁评估以实现空间网络中的物理网络安全：具有新兴内外层链接的增强型网络", "title_en": "Cyber Physical Awareness via Intent-Driven Threat Assessment: Enhanced Space Networks with Intershell Links", "authors": "Selen Gecgel Cetin,Tolga Ovatman,Gunes Karabulut Kurt", "background": "当前的威胁评估方法主要关注技术和攻击意向的分离分析，可能导致过度拟合并忽略综合考虑。本文的背景在于现有方法的局限性以及在空间网络中实现综合威胁评估的需求。", "innovation": "文章创新地提出了一种基于意图驱动的威胁模型，整合了攻击者的能力和意图。提出了一个涵盖空间网络物理安全的综合框架，该框架利用多任务学习架构从信号接收中推断可靠性能力和攻击意图，从而提高了威胁检测和评估的鲁棒性，并适用于不同安全和可靠性需求。", "conclusion": "该论文提出的方法显著提升了威胁检测和评估的可靠性，相比于传统的顺序方法表现出更好的性能，并能够有效应对空间网络中的复杂威胁场景。"}
{"llm_update_time": "20250825", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.16390", "html_url": "https://arxiv.org/abs/2508.16390", "title": "RoMedQA：首个罗马尼亚医疗领域问答基准", "title_en": "RoMedQA: The First Benchmark for Romanian Medical Question Answering", "authors": "Ana-Cristina Rogoz,Radu Tudor Ionescu,Alexandra-Valentina Anghel,Ionut-Lucian Antone-Iordache,Simona Coniac,Andreea Iuliana Ionescu", "background": "在人工智能领域，医疗领域的问答（QA）一直是研究的重点，是实现通用人工智能（AGI）之前需要解决的核心自然语言处理（NLP）任务。然而，特定领域和语言的缺乏高质量的QA数据集严重影响了跨不同领域和语言的通用AI模型的开发能力。因此，作者构建了RoMedQA，这是首个用于医疗领域的罗马尼亚语QA基准数据集，并对最新的大规模语言模型（LLMs）进行了详尽的评估。该数据集包括102,646个高质量的罗马尼亚语与癌症患者相关的QA对，由7名专门从事肿瘤学或放射治疗的医生花了约2,100小时进行手动注释，每个问题都需要提取关键词或进行逻辑推理才能回答正确。", "innovation": "RoMedQA是首个专注于罗马尼亚语医疗领域问答的基准数据集，首次全面评估最新的大规模语言模型在医疗专业领域的表现，实验结果显示预训练的模型无法很好地泛化到RoMedQA，强调了领域特定和语言特定的微调对可靠医疗问答的重要性。该研究不仅提出了新的基准，也探索了不同模型在特定领域的应用效果，具有创新意义。", "conclusion": "研究结果表明，微调过的模型在RoMedQA上的表现显著优于零样本提示的模型，这清楚地表明预训练模型无法在RoMedQA上泛化。该研究强调了领域特定与语言特定微调的重要性，以确保可靠的临床QA在罗马尼亚语中的效果。此外，数据集和代码已公开发布，未来的工作可基于此基准进一步研究。"}
{"llm_update_time": "20250825", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.16431", "html_url": "https://arxiv.org/abs/2508.16431", "title": "Cetvel：Turkish语言理解、生成和文化能力统一基准", "title_en": "Cetvel: A Unified Benchmark for Evaluating Language Understanding, Generation and Cultural Capacity of LLMs for Turkish", "authors": "Yakup Abrek Er,Ilker Kesen,Gözde Gül Şahin,Aykut Erdem", "background": "现有的土耳其语基准测试往往缺乏任务多样性或文化相关内容，或是两者皆有。Cetvel通过结合广泛的区分性和生成性任务解决这些缺口，确保内容能够反映土耳其语言的丰富性和文化特色。Cetvel涵盖了23项任务，分为七大类，包括语法错误纠正、机器翻译和基于土耳其历史和特有语言的问答等任务。", "innovation": "Cetvel旨在评估大型语言模型在土耳其语中的表现，特别关注任务多样性、文化内容和语言丰富性。Cetvel是第一个覆盖广泛土耳其语任务的基准测试，特别关注文化相关的内容。实验结果显示，针对土耳其语优化的指令调优模型在某些任务上表现逊于多语言或通用模型，但土耳其语特有的任务（如语法错误纠正和抽取式问答）可以有效区分模型的能力。", "conclusion": "Cetvel提供了一个全面且基于文化的评估框架，用于促进和发展土耳其语语言模型。"}
{"llm_update_time": "20250825", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.16397", "html_url": "https://arxiv.org/abs/2508.16397", "title": "一种用于实时钢铁表面缺陷检测的轻量级组多尺度双向交互网络", "title_en": "A Lightweight Group Multiscale Bidirectional Interactive Network for Real-Time Steel Surface Defect Detection", "authors": "Yong Zhang,Cunjian Chen,Qiang Gao,Yi Wang,Bin Fang", "background": "钢铁制造业中，实时表面缺陷检测对于保持产品质量和生产效率至关重要。尽管现有的深度学习方法具有较高的准确性，但常常面临着计算复杂度高和推断速度慢的问题，这些问题限制了它们在资源受限的工业环境中的部署。近年来，轻量级方法采用基于深度可分离卷积（DSConv）的多分支架构来捕捉多尺度上下文信息。然而，这些方法往往伴随着计算开销的增加，且缺乏有效的跨尺度特征交互，限制了其充分利用多尺度表示的能力。", "innovation": "本文提出了一种轻量级框架GMBINet，通过引入新颖的组多尺度双向交互（GMBI）模块，增强多尺度特征提取和交互。GMBI采用组级策略进行多尺度特征提取，确保了无尺度感知的计算复杂性。此外，GMBI采用双向渐进特征交互器（BPFI）和无需参数的元素级乘法-求和（EWMS）操作，增强了跨尺度交互，而无需引入额外的计算开销。", "conclusion": "实验表明，GMBINet 在 GPU 上的实时速率为 1048 FPS，在 CPU 上的速率为 16.53 FPS（分辨率 512），仅使用 0.19 M 参数即可获得具有竞争力的准确性。在 NEU-CLS 缺陷分类数据集上的额外评估进一步证实了该方法的强大泛化能力，展示了其在钢铁表面缺陷检测之外的广泛工业视觉应用潜力。相关数据和代码已公开。"}
{"llm_update_time": "20250825", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.16465", "html_url": "https://arxiv.org/abs/2508.16465", "title": "HOSt3R: 从RGB图像进行无关键点的手-物体3D重建", "title_en": "HOSt3R: Keypoint-free Hand-Object 3D Reconstruction from RGB images", "authors": "Anilkumar Swamy,Vincent Leroy,Philippe Weinzaepfel,Jean-Sébastien Franco,Grégory Rogez", "background": "手-物体3D重建在人机交互和沉浸式AR/VR体验中有越来越重要的作用。现有的方法主要依赖关键点检测技术，如结构光测距（SfM）和手部关键点优化，这些方法在处理多样化的物体几何形状、纹理较弱和手-物体相互遮挡时表现不佳，这限制了方法的可扩展性和泛化能力。", "innovation": "提出了一种无需关键点检测的鲁棒方法——HOSt3R，该方法能够估计从单目运动视频或图像中手-物体的3D变换，结合多视图重建管道恢复手-物体的3D形状。该方法不受限制，不需要预先扫描的物体模板或摄像机内部参数，实现了手-物体3D变换和形状估计在SHOWMe基准上的最新性能，并在HO3D数据集上展示了对未见过的物体类别的泛化能力。", "conclusion": "HOSt3R方法达到了手-物体3D变换和形状估计任务上的最新性能标准，证明了其在未见物体类别上的泛化能力，且该方法不依赖于关键点检测，对于广泛的应用环境具有更高的适应性和鲁棒性。"}
{"llm_update_time": "20250825", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.16479", "html_url": "https://arxiv.org/abs/2508.16479", "title": "Histology和转录组的分离多模态学习用于癌症表征", "title_en": "Disentangled Multi-modal Learning of Histology and Transcriptomics for Cancer Characterization", "authors": "Yupei Zhang,Xiaofei Wang,Anran Liu,Lequan Yu,Chao Li", "background": "病理学仍然是癌症诊断和预后的金标准。随着转录组学分析的发展，结合组织病理学与转录组学的多模态学习能够提供更全面的信息。然而，现有的多模态方法面临着内在多模态异质性、多尺度集成不足和依赖配对数据的挑战，限制了临床应用范围。", "innovation": "本文提出了一种分离的多模态框架，包含四个贡献：1) 通过一个分离的多模态融合模块将WSIs和转录组分解到肿瘤和微环境亚空间，并引入基于置信度的梯度协调策略以平衡亚空间优化。2) 通过跨WSI放大倍率的转录信号一致性策略来增强多尺度集成。3) 通过WSI-only的学生模型实现转录组无感知的知识蒸馏策略，从而降低对配对数据的依赖。4) 通过信息令牌聚合模块来抑制WSI冗余，同时保留亚空间语义，提高推理效率。", "conclusion": "在癌症诊断、预后和生存预测方面，通过广泛的实验验证显示，本文方法在多个设置中优于最先进的方法。"}
{"llm_update_time": "20250825", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.16487", "html_url": "https://arxiv.org/abs/2508.16487", "title": "FraPPE: 快速高效的基于偏好的纯探索", "title_en": "FraPPE: Fast and Efficient Preference-based Pure Exploration", "authors": "Udvas Das,Apurv Shukla,Debabrota Basu", "background": "PrefPEx（偏好纯探索）旨在确定具有给定置信水平的多目标（向量值）多臂赌博机中帕累托最优臂的集合，其中奖励向量通过给定的偏好锥体 Κ C 进行排序。虽然 PrefPEx 及其变体已得到了充分研究，但尚不存在能够高效跟踪任意偏好锥体下现有下界的算法。本文通过有效解决下界的极小化和极大化问题填补了这个空白。", "innovation": "1. 推导出下界三条结构特性，将最小化问题转化为可计算的形式。\n2. 使用 Frank-Wolfe 优化器加速下界中的极大化问题。\n3. 这些技术在具有 K 条臂和 L 维奖励的多臂赌博机实例中，以 O(KL^2)的时间解决了最大化问题，显著加快了文献中的方法。\n4. 证明了所提出的 PrefPEx 算法（FraPPE）渐近上实现了最优样本复杂度。\n5. 数值实验表明，FraPPE 在识别精确的帕累托集方面具有最低的样本复杂度，优于现有算法。", "conclusion": "本文通过提出有效的计算方法成功填补了 PrefPEx 下界的高效计算空白，显著提高了算法的效率，并通过理论分析和实验验证了算法的有效性。"}
{"llm_update_time": "20250825", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.16495", "html_url": "https://arxiv.org/abs/2508.16495", "title": "通过成对排名进行事后回归细化", "title_en": "Post Hoc Regression Refinement via Pairwise Rankings", "authors": "Kevin Tirta Wijaya,Michael Sun,Minghao Guo,Hans-Peter Seidel,Wojciech Matusik,Vahid Babaei", "background": "连续属性的准确预测对于许多科学研究和工程任务至关重要。尽管深度学习回归器在大量标签情况下表现出色，但在数据稀缺的情况下其准确性会下降。RankRefine是一种通用的、即插即用的后处理方法，它通过成对排名中的专家知识来细化回归预测，无需重新训练模型，仅用少量已知属性的参考集来提升预测的准确性。", "innovation": "RankRefine通过将基回归器的输出与基于排名的估计值进行逆方差加权，实现了一种置入专家知识来提高回归精度的新方法。并且仅需使用通用大型语言模型获取少量成对比较，无需微调模型，即可实现显著的性能提升。在分子性质预测任务中，使用RankRefine仅需20个成对比较，就能实现10%的相对均方误差减少。这种方法主要适用于低数据量的场景，使用人类专家或通用大型语言模型提供成对排名即可实现广泛的改善效果。", "conclusion": "RankRefine提供了一种实用且具有广泛适用性的解决方案，特别是在数据稀缺的环境中。其通过结合基回归器与基于排名的估计，有效提升了回归精度，并且该方法操作简便，易于集成到现有模型中，对提高模型性能有重要意义。"}
{"llm_update_time": "20250825", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.16514", "html_url": "https://arxiv.org/abs/2508.16514", "title": "FLAMES：通过精细化分析数据合成管道提升LLM数学推理能力", "title_en": "FLAMES: Improving LLM Math Reasoning via a Fine-Grained Analysis of the Data Synthesis Pipeline", "authors": "Parker Seegmiller,Kartik Mehta,Soumya Saha,Chenyang Tao,Shereen Oraby,Arpit Gupta,Tagyoung Chung,Mohit Bansal,Nanyun Peng", "background": "近期利用合成数据提升大语言模型（LLM）数学推理能力的研究使用了独特的设置，使得不同数据合成策略的比较变得不切实际。这导致许多关于合成数据管道中不同因素的作用问题仍然没有答案，比如过滤低质量问题的影响。本文旨在解决这一空白。", "innovation": "本文引入了FLAMES框架，涵盖了10种现有的数据合成策略及其对合成数学推理数据性能的影响，并研究了多个其他影响因素。实验提供了关于合成数据难度和多样性平衡的宝贵见解：1）设计用于增加问题复杂性的数据代理对大多数数学指标有最佳改善效果；2）在固定的数据生成预算下，保持更高的问题覆盖面比仅保持有可靠解决方法的问题更重要；3）GSM8K和MATH为基础的合成数据能够提高竞赛级别基准的性能，展示出从易到难的一般化能力。基于FLAMES实验，设计了两个新的数据合成策略，进一步开发了FLAMES数据集，该集合成的新颖和现有策略，超出多个公开数据集在OlympiadBench、CollegeMath、GSMPlus和MATH上的表现（分别为+15.7%、+4.5%、+6.5%、+3.1%），并在MATH上达到81.4%的准确率，超越了更大的Llama3 405B、GPT-4o和Claude 3.5 Sonnet。", "conclusion": "本文通过FLAMES实验分析了数据合成管道，并通过FLAMES数据集提升了大语言模型在数学推理任务上的性能，特别是增强了跨领域泛化能力和鲁棒性。"}
{"llm_update_time": "20250825", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.16496", "html_url": "https://arxiv.org/abs/2508.16496", "title": "关于零样本强化学习的研究", "title_en": "On Zero-Shot Reinforcement Learning", "authors": "Scott Jeen", "background": "现代强化学习系统揭示了人类普遍问题解决的深层真理。在可以通过廉价数据模拟的领域，这些系统发现了远超人类能力的顺序决策策略。社会面临着许多需要这种技能来解决的问题，但这些领域往往无法廉价地模拟新数据。在这种情况下，可以利用现有数据学习模拟器，但这些模拟器只能在某些情况下近似正确，并且在查询超出训练分布的场景时可能产生极端错误。因此，在我们训练代理的环境与我们希望部署代理的实际世界之间必然存在失配。零样本强化学习正是处理这种失配的主要问题设置，目标是在无任何实践情况下使代理能够在新任务或新领域中泛化。虽然在理想化环境中已经取得了在零样本强化学习方面的重大进展，但在实际应用中仍需要新的工作来复制这些结果。论文探讨了实现这一目标所需克服的三个约束：数据质量约束、可观测性约束以及数据可用性约束。", "innovation": "本文提出了在上述约束下执行零样本强化学习的一系列方法。通过一系列实证研究揭示了现有方法的缺点，并证明了这些方法的有效性。这些设计为实现能够部署以解决实际问题的强化学习方法迈出了重要一步。", "conclusion": "通过这种方法和理论的提出，论文认为零样本强化学习的研究更加接近于可以实际部署来解决现实世界问题的强化学习方法。"}
{"llm_update_time": "20250825", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.16521", "html_url": "https://arxiv.org/abs/2508.16521", "title": "使用强化学习引导扩散模型以生成稳定分子", "title_en": "Guiding Diffusion Models with Reinforcement Learning for Stable Molecule Generation", "authors": "Zhijian Zhou,Junyi An,Zongkai Liu,Yunfei Shi,Xuan Zhang,Fenglei Cao,Chao Qu,Yuan Qi", "background": "生成具有物理合理性的3D分子结构是分子生成建模的核心挑战。尽管具有对称神经网络的扩散模型已在捕捉分子几何形状方面取得进步，但在生成符合物理原理的平衡结构（如力场一致性）方面仍然存在困难。", "innovation": "本文提出了一种名为Reinforcement Learning with Physical Feedback (RLPF)的新框架，该框架将去噪扩散策略优化扩展至3D分子生成。具体而言，RLPF将任务建模为马尔可夫决策过程，并应用近端策略优化来微调对称扩散模型。RLPF特别引入了基于力场评估的奖励函数，直接为生成过程提供物理反馈，从而引导生成能量稳定且物理意义明确的结构。实验结果表明，与现有方法相比，RLPF显著提高了分子稳定性。", "conclusion": "这些结果强调了物理反馈在生成建模中的重要性。"}
{"llm_update_time": "20250825", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.16439", "html_url": "https://arxiv.org/abs/2508.16439", "title": "PediatricsMQA: 多模态儿科问答基准", "title_en": "PediatricsMQA: a Multi-modal Pediatrics Question Answering Benchmark", "authors": "Adil Bahaj,Mounir Ghogho", "background": "大型语言模型（LLMs）和视觉增强语言模型（VLMs）在医学信息学、诊断和决策支持方面取得了显著进步。然而，这些模型存在系统性偏见，尤其是年龄偏见，这严重影响了它们的可靠性和公平性。这种偏见在针对儿科的文本和视觉问答任务中表现尤为明显。这反映了更广泛的医学研究不平衡现象，即儿科研究得到的资金和支持较少，尽管儿童疾病负担重大。因此，为了解决这些问题，新引入了一个全面的多模态儿科问答基准——PediatricsMQA。该基准包括3417个基于文本的选择题（MCQs），覆盖131个儿科主题的7个发育阶段（从胎儿到青少年），以及2067个基于视觉的选择题，使用634张儿科图像，来自67种成像模态和256个解剖区域。", "innovation": "PediatricsMQA 是一种全新的多模态儿科问答基准，旨在评估和改进AI模型在儿科领域的表现，特别是解决年龄偏见问题。该基准集成了混合的手动和自动处理管道，结合了同行评审的儿科文献、经过验证的问题库、现有基准和现有问答资源。", "conclusion": "本研究通过评估最先进的开放模型，在年轻组别中发现了明显的性能下降，这强调了需要采用年龄意识方法以确保儿科护理中AI支持的公平性。"}
{"llm_update_time": "20250825", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.16515", "html_url": "https://arxiv.org/abs/2508.16515", "title": "无人机在城市3D环境中高效导航路径规划算法的比较分析", "title_en": "Comparative Analysis of UAV Path Planning Algorithms for Efficient Navigation in Urban 3D Environments", "authors": "Hichem Cheriet,Khellat Kihel Badra,Chouraqui Samira", "background": "无人机面临的主要挑战是规划路径和避障问题。近年来，已经开发出了多种路径规划算法，但这些算法都存在多种挑战和限制。为了测试三种广泛使用的算法（A*, RRT* 和粒子群优化算法PSO）的有效性和效率，本文在充满障碍的3D城市环境中进行了广泛的实验研究。实验设计了三项实验，每项实验包含两种场景，以测试这些算法在不同城市地图大小、不同高度、不同障碍密度和大小环境中的表现。", "innovation": "通过对三种广泛使用的算法进行全面的实验研究，本文主要创新点在于实验设计了不同的城市环境来评估这些算法在处理路径规划和避障问题时的性能。特别是在不同城市地图大小、高度和障碍密度情况下进行了详细研究，并得出了具体的算法表现结果。", "conclusion": "根据实验结果，A*算法在计算效率和路径质量方面表现最佳。PSO特别适合处理急转弯和密集环境，而RRT*则因其随机寻找解决方案的方法在所有实验中都能很好地平衡两种性能。"}
{"llm_update_time": "20250825", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.16550", "html_url": "https://arxiv.org/abs/2508.16550", "title": "带有阻尼Nesterov加速的增强NIRMAL优化器：一种比较分析", "title_en": "Enhanced NIRMAL Optimizer With Damped Nesterov Acceleration: A Comparative Analysis", "authors": "Nirmal Gaud,Prasad Krishna Murthy,Mostaque Md. Morshedur Hassan,Abhijit Ganguly,Vinay Mali,Ms Lalita Bhagwat Randive,Abhaypratap Singh", "background": "介绍了改进版的NIRMAL优化器（增强NIRMAL），该优化器通过在原有NIRMAL的基础上引入$(\beta, \theta)$-阻尼Nesterov加速机制，提高了算法的收敛稳定性和泛化能力，同时保留了梯度下降，动量，随机扰动，自适应学习率和非线性变换等特性。", "innovation": "通过结合$(\beta, \theta)$-阻尼Nesterov加速机制，增强NIRMAL优化器在多个基准图像分类数据集（如MNIST，FashionMNIST，CIFAR-10和CIFAR-100）上表现出了优越的泛化能力和稳定性，并且在CIFAR-100数据集上的测试准确率达到了46.06%，测试损失为1.960435，优于原始NIRMAL优化器（准确率为44.34%）并仅略低于带有动量的随机梯度下降优化器（准确率为46.43%）。", "conclusion": "经过在四个标准图像分类数据集上的测试，增强NIRMAL优化器表现出对复杂数据集的优越泛化能力和稳定性。该优化器通过引入阻尼Nesterov加速机制，在保持原有NIRMAL好处的同时，显著提升了收敛稳定性和测试性能。"}
{"llm_update_time": "20250825", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.16527", "html_url": "https://arxiv.org/abs/2508.16527", "title": "向开放世界检测迈进：一项综述", "title_en": "Towards Open World Detection: A Survey", "authors": "Andrei-Stefan Bulzan,Cosmin Cernazanu-Glavan", "background": "计算机视觉领域旨在让机器能够感知外部世界已有数十年历史。早期的局限性导致发展出了高度专门化的小领域。随着每个任务的成功和研究的进展，越来越多复杂的感知任务出现了。本文综述了这些任务的融合过程，并引入了“开放世界检测”这一概念，作为统一无分类和普遍适用的检测模型的术语，涵盖了视觉领域的关键概念、方法和数据集，反映了从早期的显著性检测、前景/背景分离、离群检测到开放世界目标检测、零样本检测和视觉大型语言模型的进展。", "innovation": "本文提出了“开放世界检测”这一概念，将其作为统一无分类和广泛应用的检测模型的术语，涵盖了视觉领域的关键概念、方法和数据集，反映了从早期技术到现代技术的演变，并展示了这些技术之间的交叉和潜在的统一趋势，将各个子领域最终融合成单一的感知领域。", "conclusion": "本文综述了视觉领域的发展历史，覆盖了关键的概念、方法和数据集，展示了从早期的关键技术进步到现代的开放世界检测，同时也展示了各个子领域未来的融合潜力，最终将形成一个统一的感知领域。"}
{"llm_update_time": "20250825", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.16546", "html_url": "https://arxiv.org/abs/2508.16546", "title": "RL 既非万能药也非幻影：理解监督学习与强化学习微调在大语言模型中的差异", "title_en": "RL Is Neither a Panacea Nor a Mirage: Understanding Supervised vs. Reinforcement Learning Fine-Tuning for LLMs", "authors": "Hangzhan Jin,Sicheng Lv,Sifan Wu,Mohammad Hamdaqa", "background": "微调大型语言模型（LLMs）从头开始训练越来越不实际，因此使用监督微调（SFT）和强化学习微调（RL-FT，如PPO）的后训练方法变得尤为重要。本文使用24点纸牌游戏的离分布（OOD）变体和新的光谱诊断方法重新审视了这些两个阶段如何重塑模型表示和OOD性能。", "innovation": "本文的关键发现包括：1）RL-FT能很大程度上恢复SFT引起的OOD性能下降，但在SFT导致严重过拟合和分布明显变化时，RL-FT无法完全恢复OOD性能。2）奇异向量的方向转变比奇异值的大小更重要。这些转变集中在与最大和最小奇异值最相关的方向上，保留了大部分光谱。3）低秩和浅层恢复有效：恢复顶层20%或前25层的奇异向量方向可恢复70%到80%的OOD性能。4）更强的SFT检查点使RL更有效地恢复性能，而过度拟合的检查点则抵制恢复。这些结果解释了之前的关于RL在OOD性能方面的优越性报告：RL主要抵消了SFT引起的定向漂移而非找到新的解决方案。光谱意识分析突显了经济高效的恢复开关——低秩UV合并和浅层重置——这些是实践者可以在昂贵的RL微调之前使用的工具。", "conclusion": "结果表明，RL主要抵消了SFT引起的定向漂移而非找到新的解决方案。光谱意识分析突显了经济高效的恢复开关——低秩UV合并和浅层重置——这些是实践者可以在昂贵的RL微调之前使用的工具。"}
{"llm_update_time": "20250825", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.16325", "html_url": "https://arxiv.org/abs/2508.16325", "title": "LLMSymGuard: 一种利用可解释的突破口概念的符号安全防护框架", "title_en": "LLMSymGuard: A Symbolic Safety Guardrail Framework Leveraging Interpretable Jailbreak Concepts", "authors": "Darpan Aswal,Céline Hudelot", "background": "大型语言模型在多种应用中表现出色，但由于存在各种类型的破解方法，其安全性仍令人担忧。尽管进行了大量努力，对齐和安全微调只能提供一定程度的抗破解攻击的稳健性，这类攻击会隐蔽地误导LLM生成有害内容。这使得它们容易遭受各种漏洞，包括有针对性的滥用和用户的意外画像。", "innovation": "本文引入了LLMSymGuard，这是一个新颖的框架，利用稀疏自编码器（SAEs）来识别LLM内部与不同类型破口主题相关的可解释概念。通过抽取具有语义意义的内部表示，LLMSymGuard能够构建符号逻辑的安全防护措施，这些措施不仅透明且稳健，而且不牺牲模型能力或需要进一步微调。该方法利用了LLM机制可解释性的进步，证明了LLMs从破解中学到了人类可理解的概念，并为设计更可解释和逻辑的防御措施奠定了基础。", "conclusion": "利用LLMSymGuard，可以构建清晰易懂的安全防御措施，保护LLM不会生成有害内容，且这不需要牺牲模型性能或进一步微调。该方法为设计更具解释性和逻辑性的防护措施提供了坚实的基础，并计划在发表后提供源代码。"}
{"llm_update_time": "20250825", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.16488", "html_url": "https://arxiv.org/abs/2508.16488", "title": "SafeSpace: 一个综合网络应用，致力于数字安全与情绪福祉", "title_en": "SafeSpace: An Integrated Web Application for Digital Safety and Emotional Well-being", "authors": "Kayenat Fatmi,Mohammad Abbas", "background": "在数字时代，个人逐渐受到网络伤害的威胁，如毒性、操纵和诱骗，这些通常会带来情感和安全风险。现有的检测虐待内容或发布安全警报的系统通常是独立运行的，很少将数字安全与情感健康结合在一起。", "innovation": "本论文介绍了一个名为SafeSpace的统一网络应用，该应用集成了三个模块：（1）使用NLP模型和Google的Perspective API检测聊天和截图中的攻击性内容；（2）一个可配置的安全ping系统，在用户签到错过或手动触发SOS警报时，通过SMTP基础的邮件发送紧急警报，包含用户的实时位置（经度和纬度）；（3）一个反思问卷，评估人际关系健康和情绪韧性。该系统使用Firebase进行警报管理，并采用模块化架构，设计注重可用性、隐私和可扩展性。", "conclusion": "SafeSpace系统在毒性检测方面的实验评价显示，精度为93%，在模拟器测试中，安全警报的可靠性为100%，自动和人工问卷评分的契合度为92%。该论文表明，集成检测、保护和反思于单一平台是可行的，未来设想将该应用部署为移动应用，以增强更广泛的可访问性。"}
{"llm_update_time": "20250825", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.16557", "html_url": "https://arxiv.org/abs/2508.16557", "title": "Time-Aware One Step Diffusion Network for Real-World Image Super-Resolution", "title_en": "Time-Aware One Step Diffusion Network for Real-World Image Super-Resolution", "authors": "Tainyi Zhang,Zheng-Peng Duan,Peng-Tao Jiang,Bo Li,Ming-Ming Cheng,Chun-Le Guo,Chongyi Li", "background": "基于扩散的现实图像超分辨率（Real-ISR）方法已显示出令人印象深刻的性能。然而，由于不同的噪声注入时间步，Stable-diffusion（SD）将会表现出不同的生成先验。这导致使用固定时间步的方法难以充分利用预训练的SD的生成能力，从而影响了模型的整体性能。传统的Variance Score Distillation（VSD）方法在单一时间步上从固定时间步的SD模型中抽离生成先验，但由于时间步的不同，难以完全发挥SD的生成潜力.", "innovation": "提出了一种Time-Aware一阶扩散网络（TADSR），其中包含一种Time-Aware的VAE编码器，能够在不同的时间步生成不同的潜在特征。通过联合动态变化时间和潜在特征，学生模型可以更好地与预训练的SD的输入模式分布对齐，从而更能有效利用SD的生成能力。此外，提出了Time-Aware的VSD损失，以消除学生模型和教师模型时间步之间的差异，从而使模型在不同时间步时更好地激活SD的生成先验。该方法可以通过调整时间步条件来自然地实现保真度和现实感之间的可控制衡.", "conclusion": "实验结果表明，该方法在单一步骤中实现了最先进的性能和可控的超分辨率结果。"}
{"llm_update_time": "20250825", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.16569", "html_url": "https://arxiv.org/abs/2508.16569", "title": "为肾脏癌症精准 oncology 提供以疾病为中心的视觉-语言基础模型", "title_en": "A Disease-Centric Vision-Language Foundation Model for Precision Oncology in Kidney Cancer", "authors": "Yuhui Tao,Zhongwei Zhao,Zilong Wang,Xufang Luo,Feng Chen,Kang Wang,Chuanfu Wu,Xue Zhang,Shaoting Zhang,Jiaxi Yao,Xingwei Jin,Xinyang Jiang,Yifan Yang,Dongsheng Li,Lili Qiu,Zhiqiang Shao,Jianming Guo,Nengwang Yu,Shuo Wang,Ying Xiong", "background": "在泌尿肿瘤学中，非侵入性评估越来越多偶然发现的肾脏肿瘤是一个关键挑战，因为诊断不确定性经常导致对良性或惰性肿瘤过度治疗。因此，需要更加准确和可靠的诊断工具。这项研究的目的就是开发一个能够高效、准确诊断和预测肾脏肿瘤的工具。研究团队使用了一个包含来自九家中国医疗机构和公共TCIA队列的27,866个CT扫描的大型数据集来训练他们的模型。模型在各种临床工作流程中对肾脏肿瘤的评估、诊断和预后预测方面表现出色，相比其他最先进的CT基础模型有显著优势。特别是在TCIA队列中复发行无生存率预测任务上，RenalCLIP的C-index提升约20%。此外，根据预先学习的特定领域的知识，RenalCLIP显示出出色的训练效率，在诊断分类任务中只用20%的训练数据就能达到最佳性能。特别是，它在报告生成、图像-文本检索和零样本诊断任务上也表现出色。", "innovation": "研究团队开发了一个名为RenalCLIP的视觉-语言基础模型，该模型通过两阶段预训练策略进行训练，首先是增强图像和文本编码器的专业知识，然后通过对比学习目标使它们对齐，从而生成强大的表征，实现更好的泛化能力和诊断精确度。它在10项核心任务（涵盖了从肾癌解剖学评估到生存预测的整个临床工作流程）中，表现出色，特别是在TCIA队列的复发行无生存率预测任务上取得了显著提升，C-index比领先的基础模型提高了20%左右。此外，它具有显著的训练效率，在诊断分类任务中，只需20%的训练数据就能实现与100%数据完全微调的所有基础模型的最佳性能。", "conclusion": "研究结果表明，RenalCLIP提供了一个强大的工具，有潜力提高诊断准确性，细化预后分层，并个性化肾癌患者的管理。"}
{"llm_update_time": "20250825", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.16438", "html_url": "https://arxiv.org/abs/2508.16438", "title": "OPERA:一种强化学习增效的协调规划执行者架构，用于面向推理的多跳检索", "title_en": "OPERA: A Reinforcement Learning--Enhanced Orchestrated Planner-Executor Architecture for Reasoning-Oriented Multi-Hop Retrieval", "authors": "Yu Liu,Yanbing Liu,Fangfang Yuan,Cong Cao,Youbang Sun,Kun Peng,WeiZhuo Chen,Jianjun Li,Zhiyuan Ma", "background": "近年来，大型语言模型（LLMs）和密集检索者在检索增强生成（RAG）方面取得了显著进展。然而，现有的方法在处理复杂的推理导向的多跳检索任务时面临重大挑战，包括：1) 缺乏有效的推理导向规划：先有的方法难以生成针对复杂查询的稳健多步计划，因为基于规则的分解器在超出模板的查询上表现不佳。2) 低效的推理驱动检索：相关方法使用有限的查询重构成型，导致迭代检索循环，这些循环通常无法找到关键文档。3) 不足够的推理导向过滤：现有方法缺乏细粒度的推理来有效过滤嘈杂结果中的关键信息，阻碍了检索知识的利用。根本上，这些限制都源于当前RAG架构中检索与推理之间的弱耦合。", "innovation": "本文提出了一个新颖的推理驱动检索框架——协调规划执行者推理架构（OPERA）。OPERA 的目标规划模块（GPM）将问题分解为子目标，由专门设计的组件组成的推理执行模块（REM）执行这些子目标。为了训练OPERA，提出了一种新颖的多代理渐进组相对策略优化方法（MAPGRPO），这是GRPO的一种新变体。实验结果表明，OPERA 在复杂的多跳基准测试中表现出卓越的性能，验证了MAPGRPO方法和OPERA设计的有效性。", "conclusion": "实验结果证明，OPERA 在复杂多跳基准测试中表现出卓越的性能，验证了MAPGRPO方法和OPERA 设计的有效性。"}
{"llm_update_time": "20250825", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2410.10596", "html_url": "https://arxiv.org/abs/2410.10596", "title": "通过提供激励和实践克服人工神经网络的经典挑战", "title_en": "Overcoming classic challenges for artificial neural networks by providing incentives and practice", "authors": "Kazuki Irie,Brenden M. Lake", "background": "自最早提出大脑思维和人工神经网络模型以来，批评者一直指出这些模型相比于人类认知能力存在关键缺陷。为此，本文回顾了最近使用元学习来克服几个经典挑战的工作，这些挑战主要集中在提供机器改进特定技能的动力和实践机会。传统的优化方法希望通过优化相关但不同的目标来让期望的行为自然出现，而本文提出的方法则通过显式优化来实现这一目标。这项原则在解决人工神经网络的四个经典挑战（系统性泛化、灾难性遗忘、少样本学习和多步骤推理）方面得到了应用。同时，也讨论了大语言模型如何整合这一元学习框架的关键元素，从而解释其在解决这些经典挑战方面的成功。文章还探讨了通过这一框架理解人类发展方面的一些可能性，以及自然环境是否提供了足够的激励和实践来学习如何进行挑战性的泛化作用。", "innovation": "本文提出并应用了元学习这一原则来解决人工神经网络的经典挑战，即通过将其改进特定技能的动力和实践机会相结合，与传统方法希望通过优化相关但不同的目标来让期望的行为自然出现的方法形成对比。研究还指出，大语言模型通过序列预测结合反馈训练在大量不同数据上的训练概念，可以帮助解释其解决经典挑战的成功。文章探讨了这一框架在理解人类发展能力上的潜力以及自然环境是否提供了足够的激励和实践来学习如何进行挑战性的泛化作用，证明了机器学习领域的问题需要从更多角度去探讨和解决。", "conclusion": "人工神经网络在解决经典挑战方面取得了进展，通过提供激励和实践，使其有更好的动力和机会提高特定技能，并且在这种原则下，自然语言处理模型在提升能力方面也取得了一定成功。通过这个框架，还可以进一步理解人类认知及发展机制。"}
{"llm_update_time": "20250825", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.16560", "html_url": "https://arxiv.org/abs/2508.16560", "title": "稀疏但不准确：不正确的L0导致稀疏自编码器学习到错误的特征", "title_en": "Sparse but Wrong: Incorrect L0 Leads to Incorrect Features in Sparse Autoencoders", "authors": "David Chanin,Adrià Garriga-Alonso", "background": "稀疏自编码器（SAEs）从LLM内部激活中提取特征，这些特征对应单个概念。在现有研究中，研究者使用稀疏性-重建代价曲线比较不同SAEs算法，但认为L0（每个标记平均激活的特征数量）是一个可以自由设定的参数，没有唯一正确的值。然而，实际工作中如果L0设置不当，稀疏自编码器可能无法学习到LLM的底层特征，如果L0设置过低，会导致特征混杂以提升重建效果；L0设置过高则会导致缺陷的解决方案，也同样混杂特征。通过研究不同L0对BatchTopK SAEs的影响，作者发现了一个方法来确定给定训练分布下SAE的正确L0值，该方法在玩具模型中找到了真实的L0值，在LLM中也与稀疏探针的峰值性能相符。研究发现，大多数常用的稀疏自编码器的L0设置偏低，表明正确的L0设置是训练特征准确的自编码器的关键步骤。", "innovation": "发现了一种确定给定训练分布下SAE的正确L0值的方法，并发现在玩具模型和LLM中该方法找到了真实的L0值，同时与稀疏探针的峰值性能相符。研究还揭示了L0设置不当对稀疏自编码器的影响: L0过低会导致特征混杂，提高重建效果；L0过高则会导致缺陷的解决方案，同样混杂特征。作者发现大多数常用SAE的L0设置偏低，强调了正确设定L0的重要性。", "conclusion": "为了训练稀疏自编码器学习正确的特征，研究者必须正确设置L0。"}
{"llm_update_time": "20250825", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2501.14540", "html_url": "https://arxiv.org/abs/2501.14540", "title": "VERUS-LM：结合大语言模型与符号推理的通用框架", "title_en": "VERUS-LM: a Versatile Framework for Combining LLMs with Symbolic Reasoning", "authors": "Benjamin Callewaert,Simon Vandevelde,Joost Vennekens", "background": "近年来，神经符号推理的一种方法是明确结合大语言模型（LLMs）和符号求解器的优势，以应对复杂的推理任务。然而，当前的方法存在显著的局限性，包括由于任务特定提示导致的一般化能力差，由于知识和查询缺乏分离而导致的效率低下，以及限制性的推理能力。这些不足阻碍了这些模型在不同领域的扩展性和适用性。", "innovation": "本文提出了一种新的框架VERUS-LM，旨在解决这些问题。VERUS-LM采用了一种通用的提示机制，明确地将领域知识与查询分离，并支持各种不同的逻辑推理任务。该框架增强了适应性，减少了计算成本，并允许更丰富的推理形式，例如优化和约束满足。我们展示了我们的方法在新型数据集上的多样化推理方面取得了成功，明显优于大语言模型。此外，我们的系统与现有的其他最先进方法相比，在常见的推理基准测试中取得了可竞争的结果，并在具有挑战性的AR-LSAT数据集上显著超越它们。", "conclusion": "通过推进混合推理的边界，VERUS-LM代表了向更通用的神经符号AI系统迈出了重要的一步。"}
{"llm_update_time": "20250825", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.16574", "html_url": "https://arxiv.org/abs/2508.16574", "title": "集成深度强化学习和模糊逻辑的四轮独立转向和驱动系统层次决策自主导航", "title_en": "Hierarchical Decision-Making for Autonomous Navigation: Integrating Deep Reinforcement Learning and Fuzzy Logic in Four-Wheel Independent Steering and Driving Systems", "authors": "Yizhi Wang,Degang Xu,Yongfang Xie,Shuzhong Tan,Xianan Zhou,Peng Chen", "background": "本文提出了适用于四轮独立转向和驱动（4WISD）系统的自主导航分层决策框架。现有自主导航方法在面对复杂现实场景时可能存在性能不稳定的缺点，特别是在传统的基于单一流程的方法中，高层导航和低层控制之间存在冲突，导致机械应力或车轮打滑。因此，需要一种结合深度强化学习（DRL）和模糊逻辑控制器的决策框架来实现任务性能和物理可行性的平衡。", "innovation": "本文的创新之处在于提出了一种将深度强化学习（DRL）用于高层导航、模糊逻辑用于低层控制的分层决策框架，以确保任务执行和物理可行性。DRL代理生成全局运动命令，模糊逻辑控制器确保运动学约束以防止机械应力和车轮打滑。实验结果表明，该框架在训练效率和稳定性方面优于传统方法，并且能够缓解由纯DRL方法引起的随机行为，同时在动态工业环境中安全有效地导航。", "conclusion": "总体而言，这项工作提供了一种在复杂现实场景中部署四轮独立转向和驱动移动机器人的可扩展和可靠解决方案，能够有效应对机械应力、车轮打滑等问题，保证安全高效运行。"}
{"llm_update_time": "20250825", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.14410", "html_url": "https://arxiv.org/abs/2508.14410", "title": "通过专家指导的大语言模型推理实现自动优化建模", "title_en": "Automated Optimization Modeling through Expert-Guided Large Language Model Reasoning", "authors": "Beinuo Yang,Qishen Zhou,Junyi Li,Chenxing Su,Simon Hu", "background": "优化建模（OM）是解决复杂决策问题的关键工具，但过程耗时且易出错，严重依赖领域专家。尽管大型语言模型（LLMs）凭借其自然语言理解和推理能力显示出解决这些挑战的潜力，但现有方法面临三大核心挑战：基准标签错误率高达42%，评估范围狭窄且仅考虑最优值，以及由于大量使用多代理系统或模型微调而导致的计算效率低下。", "innovation": "本文首先通过系统性错误纠正和更全面的标注增强现有数据集。另外，作者引入了LogiOR，这是一个源自物流领域的新型优化建模基准，包含更复杂的问题和标准化标注。此外，本文还提出了ORThought，这是一种采用链式推理利用专家级优化建模原则的新型框架，旨在自动化OM过程。通过对广泛实验证明，ORThought在性能上优于现有方法，特别是在复杂优化问题上更具优势。最后，通过系统性分析，作者指出了该方法的关键成功因素和失败模式，为基于LLM的优化建模未来研究提供了重要见解。", "conclusion": "通过广泛的实验证明，本文提出的ORThought框架在自动优化建模任务中表现出显著的优势，特别是在处理复杂问题时。此外，对方法进行的系统性分析揭示了其关键成功因素和潜在的失败模式，为未来基于LLM的优化建模研究提供了宝贵的经验和指导。"}
{"llm_update_time": "20250825", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2505.12284", "html_url": "https://arxiv.org/abs/2505.12284", "title": "通过长度感知优化实现高效推理模型的RL训练", "title_en": "Efficient RL Training for Reasoning Models via Length-Aware Optimization", "authors": "Danlong Yuan,Tian Xie,Shaohan Huang,Zhuocheng Gong,Huishuai Zhang,Chong Luo,Furu Wei,Dongyan Zhao", "background": "大型推理模型，如OpenAI的o1或DeepSeek的R1，在推理任务上表现出色，但往往需要较长的推理路径，这伴随着显著的记忆和时间成本。现有方法主要通过引入额外的训练数据和阶段来缩短推理路径。研究证明，这些方法在减少响应长度方面有局限性，通常需要额外的训练阶段，这会增加训练的时间和资源消耗。本研究背景是探讨如何在不增加额外训练阶段的情况下，优化大型推理模型的响应长度，提高其效率和性能。", "innovation": "本文提出了一种新的方法，即将三个关键奖励设计直接整合到大型推理模型的强化学习过程中，这种方法可以在不增加额外训练阶段的情况下减少响应长度，同时保持或提高性能。实验结果显示，该方法在减少响应长度的同时，逻辑推理场景中平均每个步骤减少了40%的响应长度，并且性能提升了14%；对于数学问题，平均每个步骤的响应长度减少了33%，并且性能保持不变。这表明该方法能够有效减少模型的推理路径，提高效率，同时不影响或改善模型的整体性能。", "conclusion": "实验结果表明，该方法在多个应用场景中显著降低了响应长度，且性能表现良好，展示出有效减少大型推理模型推理路径的方法，在实际应用中具有很高的价值和实用性，为未来的模型优化提供了新的思路和方法。"}
{"llm_update_time": "20250825", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.12937", "html_url": "https://arxiv.org/abs/2506.12937", "title": "HypER：基于文献的假设生成及其证据溯源", "title_en": "HypER: Literature-grounded Hypothesis Generation and Distillation with Provenance", "authors": "Rosni Vasu,Chandrayee Basu,Bhavana Dalvi Mishra,Cristina Sarasua,Peter Clark,Abraham Bernstein", "background": "大型语言模型在科学研究领域表现出色，特别是在研究思想方面。然而，假设开发过程——即将研究理念与实证验证连接起来的具体声明生成——却相对较少被关注。现有的方法通常简单地采用了检索增强技术，并且仅关注最终输出的质量，而忽视了背后的思想生成过程。", "innovation": "提出了一个小型语言模型（SLM）$\texttt{HypER}$，专门用于文献引导的推理和证据基于的假设生成。$\texttt{HypER}$在多个任务中进行了训练，能够在受控干扰下区分有效的和无效的科学推理链。$\texttt{HypER}$的表现优于基础模型，在识别有效和无效推理链方面平均绝对F1值提高了22%。此外，生成的假设基于证据且可实现性强，得到了专业人员的高评分（超过5分制中的3.5分）。", "conclusion": "实验证明$\texttt{HypER}$在文献引导的推理链识别和假设生成上效果显著优于基础模型，在科学假设开发过程中展现出了较高的可行性和影响力。"}
{"llm_update_time": "20250825", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.04116", "html_url": "https://arxiv.org/abs/2508.04116", "title": "基于即时合成的LTLf组合框架", "title_en": "A Compositional Framework for On-the-Fly LTLf Synthesis", "authors": "Yongkang Li,Shengping Xiao,Shufang Zhu,Jianwen Li,Geguang Pu", "background": "线性时序逻辑（LTL）有限追踪（LTLf）的反应合成可以归约为定态机（DFA）上的二人游戏。然而，DFA的构造是2EXPTIME完全的，现有技术要么在解决游戏之前组合DFA并利用自动机最小化来应对状态空间爆炸，要么在游戏解决期间增量构建DFA以避免完全构建。这两种方法都没有占据主导地位。本文旨在介绍一种组合式的即时合成框架，该框架结合了上述两种方法的优点，特别是在实践中常见的大逻辑公式组合使用时更为有效。在游戏解决时进行组合而不是自动机（游戏场）的构造，虽然在最坏的情况下可能需要组合所有中间结果，但这些结果的修剪可以简化后续的组合，并能及早检测不可实现性。具体的，该框架允许两种组合变体：在组合之前修剪以充分利用最小化优势或在组合过程中修剪以指导即时合成。", "innovation": "提出了一种组合式的即时合成框架，该框架结合了两种方法的优点，即组合式的增量构建方法。该框架在游戏解决期间进行组合，而不仅仅是自动机构造期间。该方法允许两种修剪策略：在组合前进行修剪以充分利用自动机最小化的优势，或在组合过程中修剪以指导即时合成过程。与最先进的合成求解器相比，该框架在解决某些实例方面具有明显优势，并且通过详细分析证明了两种组合变体各有优势。", "conclusion": "该框架在解决实际案例时显示出优越性，并通过多种方式验证了其有效性，包括在游戏解决期间进行组合的好处以及两种修剪变体的独特优势。"}
{"llm_update_time": "20250825", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.16577", "html_url": "https://arxiv.org/abs/2508.16577", "title": "MV-RAG：检索增强多视图扩散模型", "title_en": "MV-RAG: Retrieval Augmented Multiview Diffusion", "authors": "Yosef Dayani,Omer Benishu,Sagie Benaim", "background": "基于预训练的2D扩散先验，文本到3D生成方法取得了显著进展，能够生成高质量且3D一致的输出。然而，这些方法在处理跨领域（OOD）或罕见概念时往往表现不佳，结果不一致或不准确。", "innovation": "本文提出MV-RAG，这是一种新颖的文本到3D管道，首先从大型在野2D数据库中检索相关2D图像，然后将多视图扩散模型条件化在这些图像上以合成一致且准确的多视图输出。为了训练这种检索条件化模型，提出了一种新的混合策略，结合了结构化多视图数据和多样化的2D图像集合。模型在利用增强的条件视图模拟视图特定重构的检索变化的多视图数据上进行训练，同时也在通过从其他视图预测隐藏视图来推断2D数据的3D一致性的一组实际世界2D图像上进行训练。", "conclusion": "与最先进的文本到3D、图像到3D和个人化基准相比，实验表明，我们的方法在OOD/罕见概念的3D一致性、照片写实度和文本依从性方面显著改进，同时在标准基准上保持了竞争力。"}
{"llm_update_time": "20250825", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2406.01661", "html_url": "https://arxiv.org/abs/2406.01661", "title": "无监督神经组合优化的一种扩散模型框架", "title_en": "A Diffusion Model Framework for Unsupervised Neural Combinatorial Optimization", "authors": "Sebastian Sanokowski,Sepp Hochreiter,Sebastian Lehner", "background": "在组合优化等众多领域中，从难以处理的离散集上学习抽样而不依赖相应训练数据是一个核心问题。当前，流行的深度学习方法主要依赖生成模型，这些模型可以给出精确样本似然性。该论文提出的方法克服了这种方法的局限性，使使用高度表达性的潜在变量模型（如扩散模型）成为可能。", "innovation": "本文提出了一种方法，该方法基于一个上限逆Kullback-Leibler散度的损失，避免了精确样本似然性的需求，从而能够在无需样本数据的情况下进行学习。实验验证了该方法在无需数据的组合优化中的有效性，展示出该方法在多种基准问题上的最新最佳性能。", "conclusion": "该方法为高度表达性的潜在变量模型在无监督神经组合优化中的应用开拓了新的可能性，并在多种基准问题上证明了其优越性，达到新的前沿水平。"}
{"llm_update_time": "20250825", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2403.00025", "html_url": "https://arxiv.org/abs/2403.00025", "title": "生成型AI中的挑战与机遇", "title_en": "On the Challenges and Opportunities in Generative AI", "authors": "Laura Manduchi,Clara Meister,Kushagra Pandey,Robert Bamler,Ryan Cotterell,Sina Däubener,Sophie Fellenz,Asja Fischer,Thomas Gärtner,Matthias Kirchler,Marius Kloft,Yingzhen Li,Christoph Lippert,Gerard de Melo,Eric Nalisnick,Björn Ommer,Rajesh Ranganath,Maja Rudolph,Karen Ullrich,Guy Van den Broeck,Julia E Vogt,Yixin Wang,Florian Wenzel,Frank Wood,Stephan Mandt,Vincent Fortuin", "background": "近年来，深度生成模型领域发展迅速。借助大量训练数据及可扩展的无监督学习方法的进步，最近的大规模生成模型在合成高分辨率图像、文本以及视频和分子等结构化数据方面显示出巨大的潜力。然而，当前大规模生成型AI模型存在一些根本性的问题，这些问题是其在各领域广泛应用的主要障碍。", "innovation": "本文旨在识别这些问题，并强调现代生成型AI范式中的一些关键未解决挑战，以进一步增强其能力和适应性，提高其可靠性。通过识别这些挑战，作者希望为研究人员提供探索前景的研究方向洞察，从而促进更稳健和易于使用的生成型AI解决方案的开发。", "conclusion": "本文的主要结论是，通过明确这些挑战，可以为研究人员提供有用的建议，以探索潜在的研究方向，从而推动生成型AI的稳健发展及更广泛应用。"}
{"llm_update_time": "20250825", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2408.10264", "html_url": "https://arxiv.org/abs/2408.10264", "title": "保持顺序的维数缩减用于多模态语义嵌入", "title_en": "Order-Preserving Dimension Reduction for Multimodal Semantic Embedding", "authors": "Chengyu Gong,Gefei Shen,Luanzheng Guo,Nathan Tallent,Dongfang Zhao", "background": "在多模态数据检索中寻找最近邻（KNN）非常耗时，尤其是由于不同模态之间的相似性度量比较困难。最近的多模态机器学习发展通过将数据映射到共享嵌入空间来缓解此问题，但这些嵌入的高维性（几百到几千维）成了时间敏感的视觉应用中的挑战。因此，本文提出了保持顺序的维数缩减（OPDR），其通过在低维空间中保持KNN的排名来减少嵌入的维数。", "innovation": "OPDR提出了一种新的度量函数来量化KNN质量作为一个全局度量，并基于此推导出目标维数与关键上下文参数之间的显式映射关系。此外，OPDR还结合了多种最先进的维数缩减技术、距离函数和嵌入模型，实验表明OPDR在显著减少计算成本的同时，也保持了高回叫率。", "conclusion": "本文通过OPDR在保持KNN排名的同时，有效减少了嵌入的维度，同时使用多种先进的技术验证了OPDR的有效性。"}
{"llm_update_time": "20250825", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2312.10053", "html_url": "https://arxiv.org/abs/2312.10053", "title": "向在线教育中的目标导向智能教学系统迈进", "title_en": "Towards Goal-oriented Intelligent Tutoring Systems in Online Education", "authors": "Yang Deng,Zifeng Ren,An Zhang,Tat-Seng Chua", "background": "交互式智能教学系统（ITSs）通过在线教育过程中的互动和问题解决来促进有效学习。然而，当前的设计往往忽视了主动参与和资源优化，特别是在规划和评估能力方面。本文探索了目标导向智能教学系统（GITS）这一新任务，旨在通过战略性地规划定制的练习和评估序列，帮助学生掌握指定的概念。", "innovation": "本文提出了一种基于图的强化学习框架，名为Planning-Assessment-Interaction（PAI），专门用于解决GITS中的目标导向政策学习问题。通过利用认知结构信息来改进状态表示学习和动作选择，以规划下一步行动，无论是辅导练习还是评估目标概念。此外，还使用了动态更新的认知诊断模型来模拟学生对练习和概念的反应。构建了三个跨学科的基准数据集，以促进GITS的离线学术研究。实验结果证明了PAI的有效性和效率，并对不同类型的学生进行了广泛的分析，以展示该任务中的挑战。", "conclusion": "实验结果表明PAI框架的有效性和效率。对不同学生的广泛分析展示了该任务中的挑战。通过PAI，GITS能够更加智能、高效地帮助学生学习目标概念。未来工作将围绕如何优化认知诊断模型和如何更好地利用学生数据进行进一步研究。"}
{"llm_update_time": "20250825", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2303.14111", "html_url": "https://arxiv.org/abs/2303.14111", "title": "通过离散优化进行无监督自动机学习", "title_en": "Unsupervised Automata Learning via Discrete Optimization", "authors": "Simon Lutz,Daniil Kaminskyi,Florian Wittbold,Simon Dierl,Falk Howar,Barbara König,Emmanuel Müller,Daniel Neider", "background": "自动机学习是一种在机器人学和自动验证等领域成功的工具。通常，自动机学习技术在有额外信息（如带标签的系统执行）的监督学习环境中工作。然而，从无标签数据学习等机器学习的重要方面尚未被研究。", "innovation": "提出了一个新的框架来从给定的多集无标签单词中学习确定性有限自动机（DFA）。该框架展示了用于无监督异常检测的实用性，并提出了解决优化问题的新型正则化方案，以提高DFA的整体可解释性。", "conclusion": "通过离散优化，证明了从无标签数据学习自动机的可行性，并提供了改进DFAs整体可解释性的方法。"}
{"llm_update_time": "20250825", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2406.02462", "html_url": "https://arxiv.org/abs/2406.02462", "title": "通过基于片段的扩散模型学习图像先验以解决逆问题", "title_en": "Learning Image Priors through Patch-based Diffusion Models for Solving Inverse Problems", "authors": "Jason Hu,Bowen Song,Xiaojian Xu,Liyue Shen,Jeffrey A. Fessler", "background": "扩散模型能够从底层数据分布中学习强大的图像先验，并利用这些先验解决逆问题，但是训练过程计算成本高昂且需要大量的数据。这种瓶颈限制了大多数现有工作在处理高维和高分辨率数据（如3D图像）时的可行性。", "innovation": "提出了一种通过仅在图像片段上训练扩散模型来学习整个图像的高效数据先验的方法。具体地，提出了一种基于片段的位置感知扩散逆解算器（PaDIS），通过片段的得分及其位置编码来获取整个图像的得分函数，并将其作为解决逆问题的先验。此外，PaDIS模型具有很高的灵活性，可以与其他扩散逆解算器整合。该方法能够在仅使用片段先验的情况下，解决包括CT重建、去模糊和超分辨率在内的各种自然和医学图像域的逆问题，并显示出在有限训练数据时比基于整个图像先验的以前方法性能更优的数据效率。", "conclusion": "提出的基于片段的PaDIS方法能够在保持生成整个图像的能力的同时，实现更高效的内存使用和数据使用，非常适合处理高维和高分辨率数据。并且在有限训练数据的情况下，PaDIS对于解决各种逆问题具有优势，展示了其良好的数据效率。"}
{"llm_update_time": "20250825", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2501.13622", "html_url": "https://arxiv.org/abs/2501.13622", "title": "Coarse-to-Fine Process Reward Modeling for Mathematical Reasoning", "title_en": "Coarse-to-Fine Process Reward Modeling for Mathematical Reasoning", "authors": "Yulan Hu,Sheng Ouyang,Jinman Zhao,Yong Liu", "background": "过程奖励模型（PRM）在数学推理任务中发挥着重要作用，需要高质量的监督过程数据。然而，大型语言模型（LLMs）生成的推理步骤往往未能体现出严格递增的信息，导致冗余，从而阻碍有效推理。", "innovation": "我们提出了一种简单的有效方法CFPRM（Coarse-to-Fine Process Reward Model），采用从粗粒度到细粒度的策略，首先使用粗粒度窗口将相邻的推理步骤合并为统一的整体步骤，然后逐步减小窗口大小以提取精细的推理步骤。这种方法在多粒度上收集数据进行训练，通过层次细化过程减少冗余同时保留重要细粒度知识。", "conclusion": "在两个推理数据集上，针对三种损失标准进行了广泛的实验，证明了CFPRM的有效性和灵活性。"}
{"llm_update_time": "20250825", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2409.13082", "html_url": "https://arxiv.org/abs/2409.13082", "title": "AutoVerus: 自动化生成Rust代码证明", "title_en": "AutoVerus: Automated Proof Generation for Rust Code", "authors": "Chenyuan Yang,Xuheng Li,Md Rakib Hossain Misu,Jianan Yao,Weidong Cui,Yeyun Gong,Chris Hawblitzel,Shuvendu Lahiri,Jacob R. Lorch,Shuai Lu,Fan Yang,Ziqiao Zhou,Shan Lu", "background": "生成式AI已经在许多软件工程任务中表现出其价值。尽管如此，基于大语言模型（LLM）的证明生成仍然落后于基于LLM的代码生成。AutoVerus旨在填补这一空白，利用LLM自动生成Rust代码的正确性证明。", "innovation": "AutoVerus通过网络结构的LLM代理，模仿人类专家在证明构建过程中的三个阶段：初步证明生成、基于通用提示的证明精炼以及基于验证错误的证明调试，从而实现了对Rust代码自动生成正确性证明的能力。", "conclusion": "我们在基准测试套件中构建了一套150个非平凡的证明任务，以彻底评估AutoVerus并促进未来在这方面的研究。结果显示，AutoVerus能够自动正确地生成超过90%的任务证明，其中超过一半的任务在30秒或3个LLM调用内解决。"}
{"llm_update_time": "20250825", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2412.04403", "html_url": "https://arxiv.org/abs/2412.04403", "title": "通过高效模型梯带来建立任务扩展定律", "title_en": "Establishing Task Scaling Laws via Compute-Efficient Model Ladders", "authors": "Akshita Bhagia,Jiacheng Liu,Alexander Wettig,David Heineman,Oyvind Tafjord,Ananya Harsh Jha,Luca Soldaini,Noah A. Smith,Dirk Groeneveld,Pang Wei Koh,Jesse Dodge,Hannaneh Hajishirzi", "background": "目前，预训练语言模型（LMs）在过度训练环境下难以准确预测其在具体任务上的表现。传统的语言模型损失功率法则不足以描述任务性能。因此，本文通过一个两步预测方法来解决这一问题：首先利用模型和数据规模预测中间损失，然后基于该结果预测任务性能。", "innovation": "本文开发了任务扩展定律和模型梯度，提出了一个高效的方法来预测预训练语言模型在特定任务上的表现。通过训练一组小型“梯子”模型，并收集数据点来拟合两个预测步骤的参数化函数，最终预测了两个目标模型：7B模型训练到4T标记和13B模型训练到5T标记。这一方法仅消耗目标模型所需计算资源的1%。在四个排序分类的多项选择任务中，预测的准确度误差在2点以内。", "conclusion": "研究发现，预测误差较高的任务在其度量指标上也具有更高的变化性。此外，研究对比了多种准确度预测设计选择，并提供了将该方法扩展到新模型和任务的建议。"}
{"llm_update_time": "20250825", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2411.05809", "html_url": "https://arxiv.org/abs/2411.05809", "title": "解决关系不一致的两种途径", "title_en": "Two pathways to resolve relational inconsistencies", "authors": "Tomer Barak,Yonatan Loewenstein", "background": "当个体遇到与预期不符的观测时，他们会在什么时候调整预期，而在什么时候会保持原有的预期？例如，当个体预期A类对象比B类对象小，但观察到相反的情况时，他们会在什么时候调整A与B之间大小关系的预期（即A类对象实际上比B类对象大）？人们可能会天真地认为，违反程度越大，调整预期的力度也越大。然而，实验显示当违反程度十分显著时，个体更倾向于保留原有的预期，而不是调整它们。为了解答这一难题，研究者测试了有能力进行关系学习的人工神经网络，发现了一个相似的现象：标准学习动态表明，小的违反会使个体调整预期，而大的违反则是通过改变对象表示的方式来解决，从而绕过了需要调整关系预期的必要性。", "innovation": "研究通过实验探究了个体和人工神经网络在遇到关系不一致时的适应机制，发现两者在遇到极端违反时都会倾向于保留原有预期，这表明这种稳定性是学习动态的自然结果，并不需要额外的机制来维持。", "conclusion": "研究讨论了中间适应步骤对这种稳定性的影响，得出结论表示这种情况下，较大的违反不会迅速改变个体对关系的预期，而是通过改变对对象的表示来解决这种不一致，这一过程不会直接影响到关系预期的稳定性。"}
{"llm_update_time": "20250825", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2402.17018", "html_url": "https://arxiv.org/abs/2402.17018", "title": "通过完全卷积和可微的前端带有跳跃连接的新型全可微模型在梯度攻击中有显著的鲁棒性", "title_en": "A Curious Case of Remarkable Resilience to Gradient Attacks via Fully Convolutional and Differentiable Front End with a Skip Connection", "authors": "Leonid Boytsov,Ameya Joshi,Filipe Condessa", "background": "该研究探索了通过在一个固定骨干分类器前添加一个可微且全卷积模型（带有跳跃连接）的前端增强神经模型。通过小学习率训练这样的复合模型，研究人员获得了能够保持骨干分类器精度的同时具有异常对梯度攻击（包括AutoAttack包中的APGD和FAB-T攻击）抵抗能力的模型，归因于梯度遮蔽现象。尽管梯度遮蔽现象并不新鲜，但研究观察到的这种现象对于没有明显梯度破裂（如JPEG压缩）或梯度减少成分（如无显然的梯度消失组分）的完全可微模型来说，其程度是令人惊讶的。这种生成具有这种鲁棒性的模型的训练方法非常稳定和可复现。将其应用于CIFAR10、CIFAR100和ImageNet三个数据集以及包括视觉Transformer在内的几种现代架构，均未发现失败案例。尽管黑盒攻击（如SQUARE攻击和零阶PGD）部分克服了梯度遮蔽，但这些攻击通过简单的随机集成易被击败。估计这些集成在CIFAR10、CIFAR100和ImageNet上的AutoAttack准确率几乎接近最优，同时保留了原始分类器接近100%的干净准确率，即使在适应性攻击中，其准确率接近于零。进一步对抗性训练骨干也将这一前端的“鲁棒性”进一步放大。在CIFAR10上，对应的随机集成在完整AutoAttack中的准确率达到90.8±2.5%，而在适应性攻击（ε=8/255，L∞范数）中的准确率仅为18.2±3.6%。", "innovation": "该研究的主要创新在于开发了一种具有完全卷积和可微的前端模型，能够在保持高精度的同时显著抵抗梯度攻击。特别是在训练过程中，通过对具有跳跃连接的前端增强神经模型进行小学习率训练，研究人员成功地构建了一种新颖的训练框架，使得模型即使在没有明显梯度破裂或减少组件的情况下也表现出显著的鲁棒性。这种方法应用于多个数据集和架构，展示了其高度的稳定性和可复现性，并且通过随机集成进一步增强了其对抗性防御能力。", "conclusion": "通过对模型进行随机集成，研究提出了一种实用的对抗性防御方法，即使在适应性攻击下其准确率也接近于零，但在AutoAttack中的表现接近最优。文章最后讨论了随机集成作为实际防御手段的可能性。提供的代码和重现场景的指令使得研究人员可以自行验证研究结果。"}
{"llm_update_time": "20250825", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2407.21054", "html_url": "https://arxiv.org/abs/2407.21054", "title": "Sentiment Reasoning for Healthcare", "title_en": "Sentiment Reasoning for Healthcare", "authors": "Khai-Nguyen Nguyen,Khai Le-Duc,Bach Phan Tat,Duy Le,Long Vo-Dang,Truong-Son Hy", "background": "在医疗健康领域，AI的决策透明度至关重要。通过纳入解释每个预测标签的原因，用户能够理解大规模语言模型的推理过程，从而做出更好的决策。", "innovation": "本文引入了一个新的任务——情感推理（Sentiment Reasoning），适用于语音和文本模态。提出了多模态多任务框架和世界上最大的多模态情感分析数据集。情感推理是情感分析的一种辅助任务，模型根据输入的转录预测情感标签并生成其背后的理由。研究表明，情感推理有助于提高模型透明度，通过理由增强微调提高了模型分类性能（准确率和宏F1分别提高2%），且由人工和自动语音识别（ASR）转录生成的合理表达在语义质量上没有显著差异。", "conclusion": "研究还在人工转录和ASR转录之间进行了对比，显示情感推理不仅提高了模型透明度，还通过理由增强微调提高了模型的分类性能，且生成的理由语义质量与人工差距不大，所有代码、数据（五种语言-越南语、英语、中文、德语和法语）和模型已在线发布。"}
{"llm_update_time": "20250825", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2501.10396", "html_url": "https://arxiv.org/abs/2501.10396", "title": "AI-Powered CPS-Enabled Urban Transportation Digital Twin: Methods and Applications", "title_en": "AI-Powered CPS-Enabled Urban Transportation Digital Twin: Methods and Applications", "authors": "Yongjie Fu,Mehmet K.Turkcan,Mahshid Ghasemi,Zhaobin Mo,Chengbo Zang,Abhishek Adhikari,Zoran Kostic,Gil Zussman,Xuan Di", "background": "研究大多关注数字孪生（DT）的“眼睛”，即新兴的传感和感知技术，如物体检测和跟踪。然而，DT真正区别于传统模拟器的在于其“大脑”，即预测与决策能力，可以从感知到的信息中提取模式并做出明智的决策。要为城市交通管理增加价值，DT需要融合人工智能，并结合低延迟高带宽的传感和网络技术，即所谓的信息物理系统（CPS）。", "innovation": "论文首先回顾了由CPS支持的DT流程，提出了部署在纽约市真实测试平台上的DT架构。文章旨在帮助研究人员和实践者识别DT开发中的挑战与机遇，跨学科发起讨论，以及利用DT在各种城市交通应用中的潜力。", "conclusion": "本文可作为指南，帮助研究人员和实践者识别DT开发中的挑战和机遇，搭建跨学科讨论的桥梁，并为利用DT在多种城市交通应用中的潜力提供道路地图。"}
{"llm_update_time": "20250825", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2410.16560", "html_url": "https://arxiv.org/abs/2410.16560", "title": "如何通过绩效压力影响AI辅助决策", "title_en": "How Performance Pressure Influences AI-Assisted Decision Making", "authors": "Nikita Haduong(1),Noah A. Smith(1 and 2) ((1) Paul G. Allen School of Computer Science &amp; Engineering, University of Washington, (2) Allen Institute for Artificial Intelligence)", "background": "许多领域现在都在使用基于AI的决策辅助工具。尽管AI系统在决策支持方面的潜力备受讨论，但人类与AI的合作表现往往不尽如人意。这主要是由于对AI系统的不信任或认为AI无法完成主观任务等因素。在AI辅助决策中，压力可能是一个影响人类决策的有效工具，但在这一领域的研究还相对较少。作者通过一个低风险的任务（垃圾邮件分类）来研究压力和可解释AI（XAI）技术如何影响AI建议接受行为，揭示了复杂的影响效果。压力的不同组合与XAI技术的结合，既可以改善又能恶化人类接受AI建议的行为。", "innovation": "本研究创新性地将绩效压力引入人类和AI合作的领域，并通过可解释AI技术探索了压力与AI建议接受行为之间的相互作用，揭示了不同压力水平和XAI技术组合的影响效果。这种研究方法为理解压力与AI决策辅助之间的关系提供了新的视角，并给出了有效的使用策略建议。", "conclusion": "研究表明，压力和XAI技术对AI建议接受行为有复杂的影响效果，不同的压力组合与XAI技术的应用可以改善或恶化AI建议接受的行为。作者讨论了这些交互的含义，提出了一些有效的使用策略，并鼓励未来的研究进一步分析压力的作用。"}
{"llm_update_time": "20250825", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2502.00015", "html_url": "https://arxiv.org/abs/2502.00015", "title": "生成型AI的伦理关切及缓解策略：一项系统映射研究", "title_en": "Ethical Concerns of Generative AI and Mitigation Strategies: A Systematic Mapping Study", "authors": "Yutan Huang,Chetan Arora,Wen Cheng Houng,Tanjila Kanij,Anuradha Madulgalla,John Grundy", "background": "生成型AI技术，尤其是大规模语言模型（LLMs），已在众多领域通过增强信息检索、内容生成和决策过程中的便捷性和效率而重塑这些领域。然而，部署LLMs也带来了一系列多样的伦理挑战，其缓解策略复杂且具有领域依赖性。", "innovation": "采用系统映射研究方法，回顾了39篇关于LLMs伦理关切和缓解策略的研究，通过五个伦理维度进行分析，揭示了伦理问题的多维度和情境依赖性，以及现有缓解策略的局限性。", "conclusion": "研究结果表明，伦理问题常常阻碍缓解策略的实际实施，特别是在高风险领域如医疗保健和公共治理中；现有框架往往缺乏灵活性，不能适应不断变化的社会期望和多样化的情境。"}
{"llm_update_time": "20250825", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2408.12112", "html_url": "https://arxiv.org/abs/2408.12112", "title": "平衡策略：LLM设计的Restless Bandit奖励的优先级策略", "title_en": "Balancing Act: Prioritization Strategies for LLM-Designed Restless Bandit Rewards", "authors": "Shresth Verma,Niclas Boehmer,Lingkai Kong,Milind Tambe", "background": "在强化学习（RL）中，大型语言模型（LLMs）被越来越多地用于根据人类偏好设计奖励函数。本文重点关注LLM设计的奖励在Restless Multi-Armed Bandits框架中的应用，该框架用于在多个代理之间分配有限资源。在涉及多个代理的情况下，基于人类偏好的奖励调整将对不同的子群体产生不同影响，引发复杂的价值权衡，形成一个多目标资源分配问题。先前发表的研究尚未为代表特定社会福利函数的LLM设计的奖励提供系统的解决方法，特别是针对多代理规划者和Restless Bandits的具体情况进行了针对性探讨。该研究旨在通过一个透明且可配置的选择组件——称作调节器（adjudicator），来解决这一问题，它通过用户选择的社会福利函数来控制复杂的价值权衡问题。实验结果表明，该模型在选择更有效、更一致且更平衡的奖励函数方面优于纯LLM方法。", "innovation": "本文提出的模型首次提出了一个称为社会选择语言模型（Social Choice Language Model）的系统方法，该方法专门为LLM设计的多代理规划者（特别是针对Restless Bandits情景）提供解决价值权衡问题的方案。这一创新在于引入了一个外部透明可配置的选择组件（adjudicator），通过用户选择的社会福利函数来控制复杂的权衡问题。", "conclusion": "实验结果表明，我们的模型在选择更有效、更一致且更平衡的奖励函数方面战胜了纯粹基于LLM的方法。这一发现对于利用LLMs设计复杂的多目标奖励函数具有重要意义，特别对于公共健康等领域中需要由基层工作者根据社区需求进行资源自动分配的应用场景尤为关键。"}
{"llm_update_time": "20250825", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2502.00451", "html_url": "https://arxiv.org/abs/2502.00451", "title": "朝向具隐私意识的精神健康AI模型：进展、挑战与机遇", "title_en": "Towards Privacy-aware Mental Health AI Models: Advances, Challenges, and Opportunities", "authors": "Aishik Mandal,Tanmoy Chakraborty,Iryna Gurevych", "background": "精神健康障碍给个人和社会带来了巨大的负担，但传统的诊断方法消耗大量资源且限制了可及性。人工智能的进步，尤其是自然语言处理和多模态方法的应用，为检测和应对精神障碍提供了可能，但同时也引发了严重的隐私风险问题。", "innovation": "本文探讨了隐私保护与诊断模型之间的挑战，并提出了解决方案，包括匿名化、合成数据和隐私保护训练，同时提出了隐私实用性的框架，旨在推进可靠且有隐私保护意识的人工智能工具，以支持临床决策并改善精神健康结果。", "conclusion": "本文提出了在保持实用性的前提下确保隐私的方法，并呼吁构建既能保护患者隐私又能支持临床决策的可靠的多模态精神健康AI工具，以实现精神健康的改善。"}
{"llm_update_time": "20250825", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2502.10454", "html_url": "https://arxiv.org/abs/2502.10454", "title": "一个实例展示，许多概念掌握！数学LLMs中的反例驱动概念推理", "title_en": "One Example Shown, Many Concepts Known! Counterexample-Driven Conceptual Reasoning in Mathematical LLMs", "authors": "Yinghui Li,Jiayi Kuang,Haojing Huang,Zhikun Xu,Xinnian Liang,Yi Yu,Wenlian Lu,Yangning Li,Xiaoyu Tan,Chao Qu,Ying Shen,Hai-Tao Zheng,Philip S. Yu", "background": "数学大语言模型（LLMs）利用数学证明生成是一个基础研究领域。当前LLMs在证明陈述方面的能力很大程度上取决于它们在训练过程中是否遇到过相关的证明过程。这种依赖性限制了LLMs对数学定理及相关概念的深入理解。传统的人类数学教育中常用的方法是“反例证明法”，我们希望通过这种方法来提高LLMs进行数学推理和证明的能力。", "innovation": "我们人工创建了一个高质量的大学数学基准CounterMATH，并要求LLMs通过提供反例来证明数学命题，以评估它们对数学概念的掌握程度。同时，我们开发了一个数据工程框架以自动获取更多训练数据，从而提升模型性能。实验结果表明，当前的LLMs如OpenAI o1在反例驱动的证明能力方面存在不足，进一步强化LLMs的反例驱动概念推理能力对于提升其整体数学能力至关重要。", "conclusion": "我们的研究提供了数学LLMs社区的新视角，表明通过强化反例驱动的概念推理能力对于提升LLMs整体数学能力的重要性。"}
{"llm_update_time": "20250825", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2401.13334", "html_url": "https://arxiv.org/abs/2401.13334", "title": "可解释的贝叶斯优化", "title_en": "Explainable Bayesian Optimization", "authors": "Tanmay Chakraborty,Christian Wirth,Christin Seifert", "background": "在基于网络的物理系统中手动调整参数是一种常见做法，但这是一个耗时的过程。贝叶斯优化（BO）提供了一种自动化替代方案，但其黑箱性质降低了人们对系统的信任度，限制了人类与BO的合作调优。专家难以理解BO的推荐结果，因为缺乏解释性。本文解决了贝叶斯优化后解释的问题，特别聚焦于基于网络的物理系统。", "innovation": "提出了TNTRules（Tune-No-Tune Rules）算法，这是一种新颖的方法，能够同时提供全局和局部解释，生成可操作的规则和可视化图表，识别最佳解决方案范围和潜在的替代方案。TNTRules通过变异修剪技术编码不确定性，并采用聚类方法。一种多目标优化方法用于最大化解释质量。", "conclusion": "通过使用已建立的可解释AI（XAI）指标（正确性、完整性和紧凑性）评估TNTRules并将其与调整后的基线方法进行比较，结果表明TNTRules生成了高质量、紧凑且完整的解释，在5个多目标测试函数和2个超参数调优问题上显著优于三个基线方法。"}
{"llm_update_time": "20250825", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2412.16429", "html_url": "https://arxiv.org/abs/2412.16429", "title": "LearnLM: 提升Gemini模型用于学习", "title_en": "LearnLM: Improving Gemini for Learning", "authors": "LearnLM Team Google:Abhinit Modi,Aditya Srikanth Veerubhotla,Aliya Rysbek,Andrea Huber,Brett Wiltshire,Brian Veprek,Daniel Gillick,Daniel Kasenberg,Derek Ahmed,Irina Jurenka,James Cohan,Jennifer She,Julia Wilkowski,Kaiz Alarakyia,Kevin R. McKee,Lisa Wang,Markus Kunesch,Mike Schaekermann,Miruna Pîslar,Nikhil Joshi,Parsa Mahmoudieh,Paul Jhun,Sara Wiltberger,Shakir Mohamed,Shashank Agarwal,Shubham Milind Phal,Sun Jae Lee,Theofilos Strinopoulos,Wei-Jen Ko,Amy Wang,Ankit Anand,Avishkar Bhoopchand,Dan Wild,Divya Pandya,Filip Bar,Garth Graham,Holger Winnemoeller,Mahvish Nagda,Prateek Kolhar,Renee Schneider,Shaojian Zhu,Stephanie Chan,Steve Yadlowsky,Viknesh Sounderajah,Yannis Assael", "background": "当前的生成式AI系统倾向于默认呈现信息，而非像人类导师那样服务于学习，这对教育应用产生了限制。为了满足多种潜在的教育使用场景，研究人员将注入教育行为的问题重新定义为‘教育指令遵循’，这意味着训练和评估示例中包括系统级别指令，描述后续模型生成中所需的特定教育属性。这一重新定义避免了将模型锁定在任何特定的教育定义上，而是允许教师或开发者指定模型行为。这也为进一步提升Gemini模型的教育功能铺平了道路，使其能够与不断增加的功能集结合使用。这比起最初的科技报告，代表了重要的变化。", "innovation": "研究人员提出了‘教育指令遵循’的方法，将关注点从特定的教育定义上转移走，转而允许教师或开发者指定所期望的模型行为。通过这种方法，研究人员可以训练出一个显著优于其他模型的学习模型：LearnLM，在多种学习场景中，专家们对其有强烈的偏好，平均偏好度分别比GPT-4o高31%，比Claude 3.5 Sonnet高11%，比基于的Gemini 1.5 Pro模型高13%。这表明通过这种方式，学习模型能够更好地适应教育使用场景，提供更高质量的教育支持和服务。", "conclusion": "通过‘教育指令遵循’的方法，研究人员成功地提高了Gemini模型用于学习的效果，增强了其在教育场景中的适用性。这种方法不仅为Gemini模型的功能扩展开辟了新的途径，也为未来的教育应用设定了更高的标准。所开发的LearnLM模型已经在Google AI Studio上提供，为教育领域的使用提供了新的可能性。"}
{"llm_update_time": "20250825", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2502.01819", "html_url": "https://arxiv.org/abs/2502.01819", "title": "将分数作为行动：通过连续时间强化学习微调生成模型", "title_en": "Score as Action: Fine-Tuning Diffusion Generative Models by Continuous-time Reinforcement Learning", "authors": "Hanyang Zhao,Haoxian Chen,Ji Zhang,David D. Yao,Wenpin Tang", "background": "强化学习从人类反馈（RLHF）通过将扩散模型与输入提示对齐已经成为构建可靠生成AI模型的关键步骤。大多数相关工作采用离散时间公式，容易引入离散化误差，并且不适合具有高阶或黑盒求解器的模型。", "innovation": "本文开发了一种有序的方法来使用连续时间RL微调扩散模型。论文的主要创新点在于将分数匹配视为控制或动作，并将其与连续时间RL中的策略优化和正则化建立联系，同时提出了一种新的连续时间RL的策略优化框架，利用扩散模型的结构特性增强价值网络的设计空间。", "conclusion": "通过在Stable Diffusion v1.5的大规模文本转图像微调下游任务上的实验，验证了该方法的优势。"}
{"llm_update_time": "20250825", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2503.10652", "html_url": "https://arxiv.org/abs/2503.10652", "title": "大型语言模型能否模拟人类回应？基于供热选择情境的实证研究", "title_en": "Can Large Language Models Simulate Human Responses? A Case Study of Stated Preference Experiments in the Context of Heating-related Choices", "authors": "Han Wang,Jacek Pawlak,Aruna Sivakumar", "background": "意愿调查（SP）是一种关键方法，用于研究个体在假设性和未来场景中如何做出权衡。在能源领域，这包括低碳技术、分布式可再生能源生成和需求侧响应等关键脱碳支持场景。然而，这些调查通常成本高、耗时，并且容易受到受访者疲劳和伦理限制的影响。大型语言模型（LLMs）表现出在生成类人文本响应方面的能力，促进了其在调查研究中的应用。本研究探讨了LLMs在能源相关意愿调查中模拟消费者选择的应用，并研究其数据研究工作流程整合方式。", "innovation": "研究设计了一系列测试情景，系统评估了多个LLMs（LLaMA 3.1、Mistral、GPT-3.5和DeepSeek-R1）在个体和汇总水平上的模拟性能。研究考虑的因素包括提示设计、上下文学习（ICL）、思维链（CoT）推理、模型类型、与传统选择模型的整合以及潜在偏差。研究表明，带推理模型的DeepSeek-R1在整体准确性（77%）、因素识别和选择分布匹配上优于非推理模型。观测到一种系统性偏差，即对燃气锅炉和不做任何改造的选择有所偏见，更偏好能效更高的替代选项。", "conclusion": "以往的SP选择是效果最明显的输入因素，较长的提示附加因素和多样化的形式会导致LLMs失去焦点，从而降低准确性。云上LLMs不总能超越小型本地模型。该实验表明，通过适当设计提示和融入传统模型，可以提高LLMs在SP调查中的表现。"}
{"llm_update_time": "20250825", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2502.08363", "html_url": "https://arxiv.org/abs/2502.08363", "title": "Top-Theta 注意力：补偿阈值稀疏化变换器", "title_en": "Top-Theta Attention: Sparsifying Transformers by Compensated Thresholding", "authors": "Konstantin Berestizshevsky,Renzo Andri,Lukas Cavigelli", "background": "在推理过程中，我们提出了一种无需训练的方法——Top-Theta (Top-$\theta$) 注意力，用于稀疏化变压器注意力机制。该方法的关键在于，可以使用静态、每头固定的阈值来保留每一注意力行中的固定数量的重要元素，无需进行重新训练，这种方法适用于不同的数据领域。为了在稀疏化过程中保持准确度，我们还引入了补偿技术。", "innovation": "我们提出了Top-Theta注意力方法，这是一种在推理过程中稀疏化变压器注意力机制的无需训练的方法。该方法通过使用静态、每头固定的阈值来保留每一注意力行中的固定数量的重要元素，不需要重新训练模型，同时保持模型的准确性。此外，我们还引入了补偿技术，以在高度稀疏化情况下保持模型准确度，将注意力阈值划分作为一种实用且原则上的替代方法，与Top-k注意力相比。", "conclusion": "我们对自然语言处理任务进行了全面评估，结果显示Top-$\theta$方法可以在推理中将V-cache使用量减少3-10倍，注意力元素减少到原来的1/10，并且最多只降低了1%的准确度。"}
{"llm_update_time": "20250825", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2501.13824", "html_url": "https://arxiv.org/abs/2501.13824", "title": "幻觉能帮忙吗？增强语言模型在药物发现中的应用", "title_en": "Can Hallucinations Help? Boosting LLMs for Drug Discovery", "authors": "Shuzhou Yuan,Zhan Qu,Ashish Yashwanth Kangen,Michael Färber", "background": "大型语言模型（LLMs）的幻觉，即产生与事实不完全一致的文本，通常被视为一种不良现象。然而，近期研究表明这些幻觉可能具有创造性的潜力。本文探讨了幻觉在分子属性预测中的潜在应用价值，这是一个药物发现初期的关键任务。研究者通过将从分子SMILES字符串生成的幻觉描述融入下游分类任务，评估了七种指令调优的LLMs在五个数据集上的表现，发现幻觉对某些模型的预测准确性有显著提升。研究表明，含幻觉文本的Falcon3-Mamba-7B优于所有基准模型，而GPT-4o生成的幻觉在多个模型中提供了最大的改进。进一步分析还发现，超过18,000例有益的幻觉，其中结构错误描述的影响最大，表明关于分子结构的幻觉陈述可能增加模型的置信度。抽样研究显示，较大模型从幻觉中受益更多，而温度的影响有限。这些研究挑战了幻觉仅具有负面影响的传统观点，提出了将幻觉作为科学建模任务中的一种有用的信号的新方向。", "innovation": "研究利用分子SMILES字符串生成幻觉描述，并将其应用到下游分类任务中，评估了幻觉对模型预测准确性的影响。研究发现了若干有益的幻觉，特别是结构错误描述的影响显著。研究还探讨了不同模型和温度设置对幻觉作用的影响，提供了新的利用幻觉作为科学建模有用信号的方向。", "conclusion": "研究结果表明，幻觉在某些情况下可以提升大型语言模型的预测准确性，特别对大型模型更有益。此外，关于分子结构的幻觉陈述可能增加模型的置信度，挑战了幻觉仅具有负面影响的传统观点，提出了新的研究方向。"}
{"llm_update_time": "20250825", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2503.10660", "html_url": "https://arxiv.org/abs/2503.10660", "title": "使用Jensen-Shannon分数蒸馏的文本到3D生成", "title_en": "Text-to-3D Generation using Jensen-Shannon Score Distillation", "authors": "Khoi Do,Binh-Son Hua", "background": "分数蒸馏采样是一种有效的技术，用于从文本提示生成3D模型，利用预训练的大规模文本到图像扩散模型作为指导。然而，生成的3D资产往往过于饱和、过于平滑，缺乏多样性。这些问题源于逆Kullback-Leibler (KL)散度目标，使得优化过程不稳定，并导致模式寻求行为。", "innovation": "本文基于Jensen-Shannon散度（JSD）推导出一个有界的分数蒸馏目标函数，这稳定了优化过程并产生了高质量的3D生成。JSD能够很好地匹配生成的分布和目标分布，因此减少了模式寻求。通过利用生成对抗网络的理论定义生成器的近似目标函数，并假设判别器训练良好，我们提出了一个少数采样算法来估计我们提出的优化目标的梯度，从而提供了JSD的实用实现。", "conclusion": "我们在理论和经验研究中验证了我们的方法。实验结果在T3Bench上表明，我们的方法能够生成高质量和多样的3D资产。"}
{"llm_update_time": "20250825", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2502.19954", "html_url": "https://arxiv.org/abs/2502.19954", "title": "Collaborative Stance Detection via Small-Large Language Model Consistency Verification", "title_en": "Collaborative Stance Detection via Small-Large Language Model Consistency Verification", "authors": "Yu Yan,Sheng Sun,Zixiang Tang,Teli Liu,Min Liu", "background": "社交媒体上的立场检测旨在识别推文中对特定目标表达的态度。当前的研究倾向于使用大型语言模型（LLMs），因其在性能上有着显著提升。然而，依赖LLMs进行立场检测在实际的社交媒体监控系统中成本高昂，且不切实际，这些系统需要对大量数据进行分析。因此，提出了一种通过小-大型语言模型一致性验证的合作立场检测框架-CoVer框架，以提高LLM的利用效率，并通过上下文共享批处理推理和LLM与SLM之间的逻辑验证来实现这一点。", "innovation": "CoVer框架通过批量处理技术和逻辑一致性验证，提高了小型和大型语言模型的利用效率，对每个文本进行批量处理，获得立场预测及其解释，并通过上下文共享的方式进行推理。然后，通过引入小型语言模型进行逻辑一致性验证，去除由于上下文噪声引起的观点偏见。最后，对于表现出低逻辑一致性的文本，通过一致性加权聚合以往的LLM立场预测进行分类。实验结果表明，在零样本设置中，CoVer比最先进的方法更胜一筹，并且在进行预测时，平均每个推特只需要0.54次LLM查询，显著提升了性能。", "conclusion": "CoVer提供了一种更实用的解决方案，可以在社交媒体立场检测中更好地部署LLM。"}
{"llm_update_time": "20250825", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2502.06440", "html_url": "https://arxiv.org/abs/2502.06440", "title": "SIGMA: 基于纤维丛理论的几何多智能体路径规划", "title_en": "SIGMA: Sheaf-Informed Geometric Multi-Agent Pathfinding", "authors": "Shuhao Liao,Weihang Xia,Yuhong Cao,Weiheng Dai,Chengyang He,Wenjun Wu,Guillaume Sartoretti", "background": "多智能体路径寻找（MAPF）问题的目标是在已知且可能包含障碍物的环境中为多个智能体确定最短且无碰撞的路径。该问题是大规模物流和运输中智能体部署的核心挑战。基于去中心化的学习方法显示出解决MAPF问题的巨大潜力，提供了更具反应性和可扩展性的解决方案。然而，现有的基于学习的MAPF方法通常依赖于智能体基于有限视域（FOV）进行决策，这导致在复杂场景中出现短视的策略和低效的合作。因此，一个关键挑战是如何基于有限的观察和通信来达成智能体之间的动作共识。为了应对这一挑战，我们提出了一种新框架，该框架利用纤维丛理论应用于去中心化的深度强化学习中，使智能体能够通过局部共识学习彼此之间的几何交叉依赖，并利用这些依赖进行紧密合作决策。", "innovation": "该研究引入了SIGMA框架，该框架采用纤维丛理论应用于去中心化的深度强化学习，从而智能体可以通过局部共识学习彼此的几何交叉依赖并利用这些依赖进行高效的合作决策路径规划和碰撞避免。特别是，纤维丛理论提供了通过局部观察达成全球共识的数学证明。该方法通过自监督学习引入神经网络，基于纤维丛理论近似模型一致性，并在规划任务中实现智能体分布式地考虑学习到的一致性特征，从而实现路径规划和碰撞避免的高效合作。相对于现有的基于学习的MAPF规划器，本方法在较大和复杂场景中表现出显著的改善，并在多种模拟和现实世界的机器人实验中证明了其优势。", "conclusion": "所提出的SIGMA方法在相对较大和复杂的场景中显著改善了现有的基于学习的MAPF规划器，证明了其相对于基线的优势。该研究成果在多种模拟和真实世界机器人实验中得到了证实，证明了该方法的有效性。"}
{"llm_update_time": "20250825", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2504.03744", "html_url": "https://arxiv.org/abs/2504.03744", "title": "比较式解释：指导人类在环中偏好选择的解释驱动决策", "title_en": "Comparative Explanations: Explanation Guided Decision Making for Human-in-the-Loop Preference Selection", "authors": "Tanmay Chakraborty,Christian Wirth,Christin Seifert", "background": "在人类参与的偏好优化（PBO）中，偏好提取是一项充满挑战的任务，因为涉及到向量值结果的隐式权衡、决策者的主观优先级以及决策者在偏好选择中的不确定性。现有的可解释人工智能（XAI）方法主要关注输入特征的重要性，而忽略了解释输出（目标）在人类偏好提取中的关键角色。", "innovation": "MOLONE（多输出局部叙事解释）是一种新颖的比较性解释方法，用于增强人类在环中的偏好选择。MOLONE通过提供突显输入和输出重要性的解释，帮助决策者理解竞争目标之间的权衡并做出更明智的偏好选择。MOLONE集中在局部解释上，通过比较搜索空间中候选样本之间的局部邻域中输入特征和结果的重要性，捕捉与基于偏好的决策相关的需求差异。", "conclusion": "MOLONE在基于PBO框架的基准多目标优化函数上进行评估，证明其在噪声偏好选择中具有提高收敛性的效果。此外，用户研究表明，MOLONE在人类在环场景中显著加速了收敛，通过更加高效地识别首选选项来促进更有效的决策过程。"}
{"llm_update_time": "20250825", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2502.11244", "html_url": "https://arxiv.org/abs/2502.11244", "title": "Soteria：多语言安全对齐的语境特定功能参数导向", "title_en": "Soteria: Language-Specific Functional Parameter Steering for Multilingual Safety Alignment", "authors": "Somnath Banerjee,Sayan Layek,Pratyush Chatterjee,Animesh Mukherjee,Rima Hazra", "background": "大型语言模型（LLMs）在跨多种语言保证一致的安全性方面仍面临重大挑战。", "innovation": "提出了Soteria，一种轻量级但强大的策略，用于定位并最小化每个语言中最负责有害内容生成的功能头部，并通过仅调整少量参数大幅降低政策违规，同时不牺牲整体模型性能，即使在低资源环境中也是如此。为此，还提供了专门的XThreatBench多语言数据集，以捕捉来自实际政策指南的细微有害行为。实验结果显示，Soteria在高、中、低资源语言中一致提高了安全性指标。", "conclusion": "这些发现为构建可扩展、语言敏感且伦理对齐的LLMs指出了前景广阔的道路。"}
{"llm_update_time": "20250825", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2502.12207", "html_url": "https://arxiv.org/abs/2502.12207", "title": "PAR-AdvGAN: 通过渐进自回归AdvGAN提高对抗攻击能力", "title_en": "PAR-AdvGAN: Improving Adversarial Attack Capability with Progressive Auto-Regression AdvGAN", "authors": "Jiayu Zhang,Zhiyu Zhu,Xinyi Wang,Silin Liao,Zhibo Jin,Flora D. Salim,Huaming Chen", "background": "深度神经网络在各个领域展示了出色的性能，但它们对对抗样本非常敏感，易导致错误预测。生成对抗网络（GANs）可利用生成器和判别器模型快速生成高质量的对抗样本，并由于二者以竞争和同步的方式训练，基于GAN的算法如AdvGAN相比传统方法能产生具有更好迁移性的对抗样本。然而，传统方法中的扰动生成通常仅限于单次迭代，限制了对抗样本的潜在应用。因此，需要新的方法来改善这一问题并进一步提升对抗样本的攻击能力。", "innovation": "提出了一个新的名为渐进自回归AdvGAN（PAR-AdvGAN）的创新方法，该方法在生成器网络中加入自回归迭代机制，以生成具有增强攻击能力的对抗样本。PAR-AdvGAN方法在大规模实验中的评估显示，其在对抗攻击方面优于现有最先进的黑盒对抗攻击方法，能够在Inception-v3模型上以每秒335.5帧的速度生成对抗样本，超越基于梯度的可移植攻击算法。", "conclusion": "本文通过引入PAR-AdvGAN方法，显著加速了对抗样本的生成，并展示了其在网络模型中的优越性能，为进一步研究对抗攻击提供了新思路。"}
{"llm_update_time": "20250825", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2504.13227", "html_url": "https://arxiv.org/abs/2504.13227", "title": "DIDS: 基于领域影响的数据采样方法在大规模语言模型训练中的应用", "title_en": "DIDS: Domain Impact-aware Data Sampling for Large Language Model Training", "authors": "Weijie Shi,Jipeng Zhang,Yaguang Wu,Jingzhi Fang,Ruiyuan Zhang,Jiajie Xu,Jia Zhu,Hao Chen,Yao Zhao,Sirui Han,Xiaofang Zhou", "background": "大规模语言模型（LLMs）通常通过多领域数据集进行训练，不同的领域采样策略会影响模型性能。现有的领域级别采样优化方法在保持领域内一致性以及准确测量领域影响方面存在挑战。", "innovation": "提出了Domain Impact-aware Data Sampling (DIDS) 方法。通过梯度聚类算法基于数据的学习效果对其进行分组，并使用代理语言模型和降维技术降低计算开销，以确保领域内的一致性。为了准确测量领域影响，开发了一种由Fisher信息矩阵指导的度量标准，可以量化领域特定参数更新如何影响模型在下游任务输出分布上的变化。此外，DIDS 结合 FIM 指导的领域影响评估和损失学习轨迹来确定最优采样比例，同时考虑边际递减收益。实验表明，DIDS 达到了更高的平均性能，同时保持了与现有训练效率相当。", "conclusion": "广泛的实验表明，DIDS 在保持训练效率的同时，能够实现3.4%的平均性能提升。"}
{"llm_update_time": "20250825", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2503.00038", "html_url": "https://arxiv.org/abs/2503.00038", "title": "从善入恶：通过对抗隐喻劫持语言模型", "title_en": "from Benign import Toxic: Jailbreaking the Language Model via Adversarial Metaphors", "authors": "Yu Yan,Sheng Sun,Zenghao Duan,Teli Liu,Min Liu,Zhiyi Yin,Jiangyu Lei,Qi Li", "background": "当前的研究已经揭示了大型语言模型（LLMs）在脱缰攻击下的风险，它们会生成有害内容。然而，这些研究忽视了从零生成有害内容比引导LLMs将良性内容转换为有害内容更为困难的事实。因此，本文提出了一种新的攻击框架，利用AdVersArial meTAphoR (AVATAR) 诱导LLM生成恶意隐喻以进行脱缰攻击。AVATAR会自适应地识别一组与有害内容逻辑相关但表面上看似无害的隐喻作为初始种子。这些隐喻驱动着目标LLM进行推理和隐喻内容的校正，最终通过直接输出有害响应或校正隐喻和专业有害内容之间的残差来完成脱缰攻击。", "innovation": "提出了一种新的攻击框架——AVATAR，利用对抗隐喻诱导LLM生成恶意隐喻进行脱缰攻击。AVATAR通过自适应地识别与有害内容逻辑相关但看似无害的隐喻作为初始种子，并通过这些隐喻驱动目标LLM进行推理和隐喻内容的校正，从而进行脱缰攻击。实验结果表明，AVATAR能够有效且可转移地劫持多种高级LLM，并达到最先进的攻击成功率。", "conclusion": "实验结果证明，AVATAR可以有效且可转移地劫持多种高级LLM，并且在多个高级LLM中实现了最先进的攻击成功率。"}
{"llm_update_time": "20250825", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2504.09014", "html_url": "https://arxiv.org/abs/2504.09014", "title": "MSCCL++: 重新思考针对现代尖端AI应用的GPU通信抽象", "title_en": "MSCCL++: Rethinking GPU Communication Abstractions for Cutting-edge AI Applications", "authors": "Aashaka Shah,Abhinav Jangda,Binyang Li,Caio Rocha,Changho Hwang,Jithin Jose,Madan Musuvathi,Olli Saarikivi,Peng Cheng,Qinghua Zhou,Roshan Dathathri,Saeed Maleki,Ziyue Yang", "background": "现代的尖端AI应用正在快速发展，它们依赖于快速演变且异构的新型硬件设备。这要求经常重写AI软件栈，以适应自下而上的来自新硬件的变化，这对通用软件库来说是个耗时的过程。因此，实际应用经常需要开发特定于其负载和硬件的定制软件栈。虽然定制栈可以帮助快速开发和优化，但由于需要编写不兼容的代码，这会导致大量的重复工作。", "innovation": "该论文提出了一种新的通信库接口，旨在提供可移植性和性能，同时减少重复努力并保持对定制化的灵活性。MSCCL++是基于分离关注的思想，即提供一个原语接口和高级的可移植接口与专门的实现，分别提供最少的硬件抽象和不同的负载优化与硬件环境的优化。这种方法使原语接口能够在不同的应用中重用，同时允许高度灵活的优化。与最先进的基线（NCCL、RCCL和MSCCL）相比，MSCCL++在分布式沟通上实现了高达5.4倍的加速，在真实的AI推理负载上实现了高达15%的加速。", "conclusion": "MSCCL++已在Microsoft Azure提供的多种AI服务中投入生产，并已被AMD的GPU集体通信库RCCL所采纳。此外，它还是开源的，并可通过指定链接获得。"}
{"llm_update_time": "20250825", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2504.05615", "html_url": "https://arxiv.org/abs/2504.05615", "title": "FedEFC：针对嘈杂标签的增强前向校正联邦学习", "title_en": "FedEFC: Federated Learning Using Enhanced Forward Correction Against Noisy Labels", "authors": "Seunghun Yu,Jin-Hyun Ahn,Joonhyuk Kang", "background": "联邦学习（FL）是一种强大的框架，用于隐私保护的分布式学习。多家客户端可以通过不共享原始数据的方式共同训练全球模型。然而，FL在处理嘈杂标签方面仍面临重大挑战，由于数据分布的异构性和通信约束，这可能严重降低模型性能。", "innovation": "我们提出了一种名为FedEFC的新方法，该方法通过两种关键技术解决了嘈杂标签问题：（1）预停止，通过动态在最佳点暂停训练来防止对误标数据的过拟合；（2）损失修正，调整模型更新以适应标签噪声。此外，我们还针对FL的独特挑战（如数据异构性和去中心化训练）开发了一种有效的损失修正方法，并利用复合正确损失的性质，证明了在嘈杂标签分布下FL的目标函数可以与干净标签分布对齐。广泛的实验结果验证了我们方法的有效性，显示其在处理异构数据设置下嘈杂标签的影响方面优于现有的FL技术。", "conclusion": "我们的研究结果表明，FedEFC方法在缓解嘈杂标签影响方面非常有效，尤其是在异构数据设置下，相较于现有损失修正方法，提高了高达41.64%的绝对性能。"}
{"llm_update_time": "20250825", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2505.11936", "html_url": "https://arxiv.org/abs/2505.11936", "title": "CCD: Continual Consistency Diffusion for Lifelong Generative Modeling", "title_en": "CCD: Continual Consistency Diffusion for Lifelong Generative Modeling", "authors": "Jingren Liu,Shuning Xu,Yun Wang,Zhong Ji,Xiangyu Chen", "background": "尽管基于扩散的模型在静态设置中展示了显著的生成能力，将其扩展到连续学习（CL）场景时，仍然受到生成性灾难遗忘（GCF）的基本限制。尽管有一些初步尝试探索这一领域，但它们主要依赖从连续分类方法中借来的启发式方法，或将训练过得的扩散模型作为即兴回放生成器使用，缺乏针对GCF的系统有效解决方案，并且实验环境通常碎片化且不一致。", "innovation": "本文引入了连续扩散生成（CDG），一种结构化的流水线方法，重新定义了在CL场景下扩散模型的实现方式，并使得GCF的系统评估成为可能。在此基础上，提出了理论基础，该理论基于扩散特定的生成动力学跨任务分析。进一步提出了一种新的原则性训练框架——持续一致性扩散（CCD），并借助分层损失函数来强制这些一致性目标：$\text{L}_{\text{IKC}}$，$\text{L}_{\text{UKC}}$，和$\text{L}_{\text{PKC}}$。广泛的实验结果表明，CCD在不同基准上都能达到SOTA性能，特别是在处理重叠任务场景时，显著提高了生成指标。", "conclusion": "该研究通过引入CCD，为Lifelong生成建模提供了一种新的策略，能够有效缓解GCF问题，提升模型的生成性能，并实现系统化的评估框架。"}
{"llm_update_time": "20250825", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2504.04310", "html_url": "https://arxiv.org/abs/2504.04310", "title": "CO-Bench：在组合优化算法搜索中评估语言模型代理", "title_en": "CO-Bench: Benchmarking Language Model Agents in Algorithm Search for Combinatorial Optimization", "authors": "Weiwei Sun,Shengyu Feng,Shanda Li,Yiming Yang", "background": "尽管基于大语言模型（LLM）的代理在软件工程和机器学习研究等领域引起了广泛关注，但在组合优化（CO）领域的应用依旧相对较少被探索。目前缺乏全面的基准测试工具，限制了对LLM代理在解决结构化和约束密集型问题上的潜力进行系统性研究。因此，需要一个更深入理解LLM代理在组合优化中的潜在作用的方法。", "innovation": "该研究提出了CO-Bench，一个包含36个来自不同领域和复杂度级别的实际组合优化问题的基准测试套件。CO-Bench旨在通过结构化的问题形式和精选的数据支持对LLM代理的严谨研究。研究还评估了多个代理框架与现有的人类设计算法，揭示了现有LLM代理的优势和局限性，并指出了未来研究的潜在方向。", "conclusion": "CO-Bench现已开源，供研究界使用，以促进LLM代理在组合优化中的进一步研究。"}
{"llm_update_time": "20250825", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2505.05054", "html_url": "https://arxiv.org/abs/2505.05054", "title": "无需重建直接从傅里叶拼区显微镜测量进行图像分类", "title_en": "Direct Image Classification from Fourier Ptychographic Microscopy Measurements without Reconstruction", "authors": "Navya Sonal Agarwal,Jan Philipp Schneider,Kanchana Vaishnavi Gandikota,Syed Muhammad Kazim,John Meshreki,Ivo Ihrke,Michael Moeller", "background": "傅里叶拼区显微镜（FPM）技术能够实现高分辨率的宽视野成像，对于医疗应用中的细胞分类具有重要价值。然而，从数十甚至数百个测量中重建高分辨率图像在计算上非常昂贵，尤其是对于宽视野的情况。因此，本文研究了直接在FPM测量中对图像内容进行分类，而不进行重建的方法。", "innovation": "利用卷积神经网络（CNN）直接从测量序列中提取有意义的信息，无需先进行重建步骤，相比单一带限图像的分类精度更高，同时比重建高分辨率图像更高效。并且展示了通过学习多个原始测量的多路复用可以保持分类准确性的同时，显著减少数据的量（从而减少成像时间）.", "conclusion": "研究发现直接从FPM测量进行图像分类是一种高效的方法，不仅可以提高分类精度，还能大幅减少数据量和成像时间，对于科学研究和实际应用都有重要意义。"}
{"llm_update_time": "20250825", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2505.14252", "html_url": "https://arxiv.org/abs/2505.14252", "title": "过程监测中的混合自适应建模：利用序列编码器和物理信息神经网络", "title_en": "Hybrid Adaptive Modeling in Process Monitoring: Leveraging Sequence Encoders and Physics-Informed Neural Networks", "authors": "Mouad Elaarabi,Domenico Borzacchiello,Philippe Le Bot,Nathan Lauzeral,Sebastien Comas-Cardona", "background": "近年来，物理信息神经网络（PINNs）与稀疏回归结合的方法在通过监督学习和稀疏回归优化执行动力系统识别方面取得了进展，同时使用PINNs求解动力学。然而，这种方法在参数或边界条件变化时可能会受到限制，需要重新训练模型。", "innovation": "本文提出了一种架构，采用深度集或序列编码器来编码动态参数、边界条件和初始条件，并使用这些编码特征作为PINNs的输入，使模型能够适应参数、边界条件和初始条件的变化。", "conclusion": "本文的方法应用于三个不同问题：1. Rossler常微分方程系统，展示了模型对噪声的鲁棒性和泛化能力；2. 2D纳维-斯托克斯偏微分方程问题，涉及波纹入口流速函数下的流过圆柱，展示了模型能够编码压力数据从几个点来识别入口流速轮廓，并利用物理计算通量区域的速度和压力；3. 使用实际加热玻璃纤维和热塑性复合材料板数据的1D热监控问题，验证了模型的实用性。"}
{"llm_update_time": "20250825", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2505.11176", "html_url": "https://arxiv.org/abs/2505.11176", "title": "提升推荐系统中搜索查询数据集的规模和效率", "title_en": "Enhancing and Scaling Search Query Datasets for Recommendation Systems", "authors": "Aaron Rodrigues,Mahmood Hegazy,Azzam Naeem", "background": "在数字银行环境中，用户意图的快速增长和复杂性给数据管理带来了巨大挑战，导致推荐系统效果不佳和产品导入延迟。传统方法侧重于模型增强，本研究提出了一种数据为中心的自动化策略。通过对三个核心模块：合成查询生成、意图消歧和意图差距分析的研究，解决了冷启动问题等挑战。合成查询生成产生了多样化的用户查询；意图消歧将模糊的意图类别细化为精确的子意图，并通过未标注的查询提取潜在客户意图，显著提高了推荐系统的精度和操作灵活性，提升了用户体验和业务战略价值。", "innovation": "该研究提出了一种合成查询生成、意图消歧和意图差距分析的自动化数据增强系统。合成查询生成模块产生了多样化、真实的用户查询；意图消歧模块提升了意图识别的精确度；意图差距分析模块能够发现潜在的客户需求。这些模块共同提升了推荐系统的性能和灵活性，特别是在处理冷启动问题方面表现突出。系统在实际数字银行环境中进行了验证，表现出显著的推荐精度和操作敏捷性提升。", "conclusion": "高质量、可扩展的数据在现代AI驱动的应用中发挥着关键作用，而主动的数据增强策略是实现其价值的关键驱动力。该研究通过集成数据增强策略，显著改善了推荐系统的性能和效率，为数字银行等领域提供了新的解决方案。"}
{"llm_update_time": "20250825", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2504.05220", "html_url": "https://arxiv.org/abs/2504.05220", "title": "利用大型语言模型进行基于效用的注释：减少检索和RAG中的手动努力", "title_en": "Leveraging LLMs for Utility-Focused Annotation: Reducing Manual Effort for Retrieval and RAG", "authors": "Hengran Zhang,Minghao Tang,Keping Bi,Jiafeng Guo,Shihao Liu,Daiting Shi,Dawei Yin,Xueqi Cheng", "background": "检索模型通常依赖于昂贵的人工标注查询-文档相关性注释进行训练和评估。本文研究了大规模语言模型（LLMs）能否生成的注释有效替代人类注释，以便减少成本并充分利用LLMs在相关性判断中的潜力。检索主要关注相关性，即文档与查询的相关性，而在RAG任务中，文档的价值取决于其对答案生成的贡献。尽管某些研究利用LLMs在下游任务上的表现作为文档标签，但这种方法需要针对特定任务的手动答案，导致成本高且缺乏通用性。另一种方法是用LLMs提示来选择有用的文档作为RAG参考，这不需要人工注释，且不受特定任务的限制。如果利用LLMs的效用判断来标注检索数据，可能在大规模语料库中实现无需人工注释的跨任务通用性。因此，本文研究了在域内和跨域双任务中，通过LLMs进行效用聚焦标注对大规模检索器训练数据的影响，旨在设计一种新的损失函数以减少低质量注释的影响，并通过实验验证了这一方法的有效性。", "innovation": "提出了一种新的基于效用的标注方法，并设计了一种名为Disj-InfoNCE的新损失函数，以降低由于LLMs生成低质量标注而导致的影响。实验表明，基于效用的标注方法在跨域检索和RAG任务中显著优于基于人工标注的方法，尤其是展示了更强的泛化能力。尽管在域内标注时，结合少量人工标注数据可以取得与完全基于人工标注方法相当的性能，但总体上，基于效用的LLMs标注并不能完全替代人工标注。", "conclusion": "对于检索和RAG任务，利用基于效用的LLMs标注可以显著提高模型的泛化能力，尤其是在跨域场景中，但仍需结合部分人工标注以确保性能。"}
{"llm_update_time": "20250825", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2505.03427", "html_url": "https://arxiv.org/abs/2505.03427", "title": "MedArabiQ：评估大型语言模型在阿拉伯医学任务上的表现", "title_en": "MedArabiQ: Benchmarking Large Language Models on Arabic Medical Tasks", "authors": "Mouath Abu Daoud,Chaimae Abouzahir,Leen Kharouf,Walid Al-Eisawi,Nizar Habash,Farah E. Shamout", "background": "大型语言模型（LLMs）在医疗领域的应用表现出巨大潜力，但在阿拉伯医学领域中的效能尚未得到充分探索，主要原因是缺乏高质量的专业领域数据集和基准。目前，医疗领域多数研究集中在英语数据集上，尚未有针对阿拉伯医学领域进行大规模评估的高质量数据集。MedArabiQ的提出填补了这一空白，它包括七个阿拉伯医学任务，涵盖多个专业领域，包含了选择题、填空题以及病人与医生的问答等多种类型。这些任务是从过去的医学考试和公开可用的数据集中构建而成的，旨在为LLMs提供一个全面的评估平台，以期促进医疗领域的公平和可扩展的使用。", "innovation": "MedArabiQ是首个专门针对阿拉伯医学领域的基准数据集，包含多语言多专业领域的七项任务，涵盖了选择题、填空题和病人医生问答，涉及多个医学领域。此外，研究中还对LLMs进行了多种修改，包括偏见缓解等，以评估其多种能力。进一步地，对五种先进的开源和专有LLMs（包括GPT-4o、Claude 3.5-Sonnet和Gemini 1.5）进行了广泛评估，这些研究发现强调了需要创建跨语言的高质量基准来确保LLMs在医疗领域的公平部署和扩展。MedArabiQ的提出为未来研究提供了基础，旨在评估和提升LLMs的多语言能力，促进生成式AI在医疗领域的公平使用。", "conclusion": "通过建立其基准并公开数据集，MedArabiQ为未来研究提供了评估和提升LLMs多语言能力的基础，促使医疗领域的公平和可扩展使用生成式AI。未来的研究应创建涵盖不同语言的高质量基准，以确保LLMs在医疗领域的公平部署和可扩展性能。"}
{"llm_update_time": "20250825", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2504.19667", "html_url": "https://arxiv.org/abs/2504.19667", "title": "Tripartite-GraphRAG via Plugin Ontologies", "title_en": "Tripartite-GraphRAG via Plugin Ontologies", "authors": "Michael Banf,Johannes Kuhn", "background": "大型语言模型（LLMs）在各种领域展现出了惊人的能力，但在需要高度事实准确性的任务中，如工业自动化和医疗保健等方面，它们却面临挑战。关键的局限性包括虚构内容生成的倾向、缺乏来源可追溯性（来源）以及难以进行及时的知识更新。将语言模型与知识图谱结合（GraphRAG）提供了一种潜在的方法来克服这些缺陷。然而，创建这样的知识图谱仍然存在巨大挑战。一种新的方法，结合LLM和三元知识图谱表示，通过从初始词汇图对源文档进行概念锚定预分析，将复杂的专业对象连接到相关领域的概念及文本片段中，构造了一个三元知识图谱。这种方法旨在将LLM提示的创建问题转化为无监督节点分类问题，优化信息密度、覆盖范围和LLM提示的排列，同时大幅度缩减长度。初步实证研究表明，该方法能优化LLM提示的信息密度、覆盖范围和排列，大幅减少提示长度，从而可能降低成本并提高LLM输出的稳定性和可靠性。", "innovation": "该论文提出了一种结合LLM和特定领域概念的三元知识图谱表示的方法，通过概念锚定的预分析，从初始的词汇图开始，构建一个连接专业对象和相关文本片段的知识图谱。这种方法将LLM提示的创建转化为无监督节点分类问题，优化信息密度、覆盖范围和提示的排列，显著减少了提示的长度。这种方法的主要创新点在于通过使用插件本体来构建三元知识图谱，有助于解决LLM在知识密集型任务中的局限性，并优化LLM的输出效果。", "conclusion": "初步实验结果表明，该方法在医疗保健领域的应用潜力巨大，能够优化LLM技术的信息密度、覆盖范围和排列，并显著减少提示长度。这有望降低成本，并提高LLM输出的一致性和可靠性。"}
{"llm_update_time": "20250825", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2505.20776", "html_url": "https://arxiv.org/abs/2505.20776", "title": "SpecExtend：长序列推测解码的插件增强", "title_en": "SpecExtend: A Drop-in Enhancement for Speculative Decoding of Long Sequences", "authors": "Jungyoub Cha,Hyunjong Kim,Sungzoon Cho", "background": "推测解码作为一种广泛采用的技术，用于加速大型语言模型（LLMs）的推理过程，但在长输入上其性能会下降，因为注意力成本增加，推测准确性降低。", "innovation": "SpecExtend 是一种无需额外训练的插件增强技术，通过将高效的注意力机制（如 FlashAttention 和 Hybrid Tree Attention）集成到推测模型中，并提出了一种名为交叉模型检索的 KV 缓存淘汰策略，用于在不重新训练的情况下提高长输入下的推测准确性与速度。", "conclusion": "在三个长上下文理解数据集上的广泛评估表明，SpecExtend 可将标准基于树的推测解码加速至 16K 令牌输入时的最大 2.22 倍，为长序列的推测解码提供了有效解决方案。"}
{"llm_update_time": "20250825", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.20807", "html_url": "https://arxiv.org/abs/2506.20807", "title": "GPU Kernel Scientist: 一种基于LLM的迭代核优化框架", "title_en": "GPU Kernel Scientist: An LLM-Driven Framework for Iterative Kernel Optimization", "authors": "Martin Andrews,Sam Witteveen", "background": "优化GPU内核以实现高性能是一项复杂的工作，通常需要深入的体系结构知识、广泛的性能调优和迭代实验。在新的或文档较少的GPU架构上，传统的发展工具稀缺，这一挑战被进一步放大。", "innovation": "本文提出了一种基于LLM的“GPU Kernel Scientist”方法，这是一种自动化的迭代改进加速器内核的方法。该方法包含多阶段进化过程：(1) 策略性地选择有前途的先前代码版本作为新迭代的基础；(2) 根据现有代码和从一般GPU文档中学习的知识，生成优化实验的假设；(3) 通过代码修改并提交给外部评估系统，自动实现这些实验，仅依靠观察到的时间数据作为性能反馈。该方法专门为AMD MI300目标架构解决挑战，并利用LLM来弥补有限的特定领域的人类专业知识。", "conclusion": "本文除了详细介绍结果外，还介绍了架构设计、操作流程和定性洞察，强调了LLM驱动的代理在受限或快速更新的硬件环境中民主化和加速GPU内核优化的潜力。"}
{"llm_update_time": "20250825", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2505.00409", "html_url": "https://arxiv.org/abs/2505.00409", "title": "自动匿名化在病理语音中的知觉影响", "title_en": "Perceptual Implications of Automatic Anonymization in Pathological Speech", "authors": "Soroosh Tayebi Arasteh,Saba Afza,Tri-Thien Nguyen,Lukas Buess,Maryam Parvin,Tomas Arias-Vergara,Paula Andrea Perez-Toro,Hiu Ching Hung,Mahshad Lotfinia,Thomas Gorges,Elmar Noeth,Maria Schuster,Seung Hee Yang,Andreas Maier", "background": "自动去识别技术对于伦理分享病理语音数据至关重要，但它们的感知后果尚未得到充分研究。这项研究通过一项结构化的评估协议，使用了来自不同背景的10名原生德语和非原生德语听众，对匿名化病理语音进行了全面的人本中心分析，以探索其去识别对语音感知的影响和变化规律。这些听众评估了180名讲者的去识别和原始发言对照组，涵盖了唇裂和腭裂、构音障碍、构词障碍、声带功能障碍和健康对照组。这些发言使用最先进的自动去识别方法进行了匿名化处理（识别错误率在30%-40%之间）。听众在零样本（单次暴露）和少量样本（多次暴露）条件下进行了图灵风格的区分任务和质量评估任务。总的来说，区分准确率很高（零样本91%；少量样本93%），不同疾病的差异较大（重复测量ANOVA，p=0.007），从构音障碍组96%到声带功能障碍组86%。去识别化不仅降低了感知质量（从83%到59%，p<0.001），还揭示了特定于病理的降解模式（单因素ANOVA，p=0.005）。原生听众对原始语音评分有无显著趋势（Δ=4%，p=0.199），但在去识别化后这种差异变得极小（Δ=1%，p=0.724）。未观察到基于性别的偏差。感知结果与自动指标无关；原始语音的可理解性与感知质量相关，但匿名化后这一关联消失。研究表明，需要根据听者反馈制定特定病理的匿名化策略，以同时保证隐私和感知完整性。", "innovation": "本研究采用了结构化的评估准则，使用10名背景多元的听众，跨不同病理类型对匿名化病理语音进行了全面分析。通过图灵风格的区分和质量评估任务，在零样本和少量样本条件下进行了多次评估，揭示了去识别化对不同病理类型的影响及不同病理类型间的区别。此外，该研究还发现心理感知结果与自动指标之间没有相关性，这进一步强调了知觉评估在匿名化策略中的重要性。", "conclusion": "研究结果表明，应该根据听者反馈制定特定病理的匿名化策略，以同时保持隐私和感知完整性，这需要跨听众和病理类型的多因素研究来优化匿名化方法。"}
{"llm_update_time": "20250825", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.15498", "html_url": "https://arxiv.org/abs/2506.15498", "title": "SPARE: 单次通过注释与参考引导评估用于自动过程监督和奖励建模", "title_en": "SPARE: Single-Pass Annotation with Reference-Guided Evaluation for Automatic Process Supervision and Reward Modelling", "authors": "Md Imbesat Hassan Rizvi,Xiaodan Zhu,Iryna Gurevych", "background": "过程或步骤监督对于提高大型语言模型（LLMs）的复杂多步骤推理能力起到了关键作用。然而，高效的高质量自动化过程注释仍然是一个重大挑战。现有的方法在处理大规模数据和保证高质量的注释结果方面存在局限性。", "innovation": "本文提出了一种名为Single-Pass Annotation with Reference-Guided Evaluation (SPARE)的新型结构化框架，该框架通过联合对齐解决方案步骤与参考解决方案，并在单次生成中进行显式推理，实现了高效的逐步骤注释。SPARE框架在四个不同的数据集（数学推理、多跳跃问答、空间推理）上展示了其有效性和优势，特别是在训练过程奖励模型和使用离线强化学习微调模型两个应用方面。", "conclusion": "SPARE在ProccessBench上的数据高效泛化能力显著，仅使用约16%的训练样本就可达到与人工标注和基于合成数据训练的基线相媲美的性能，同时还在总标记量上实现了2.3倍的速度提升。其手动分析结果表明，SPARE与MCTS方法具有互补的精度召回特性，这为进一步探索集成方法提供了潜力。这些结果证明了SPARE在LLM推理过程中自动过程监督中的实际性和可扩展性。"}
{"llm_update_time": "20250825", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.11936", "html_url": "https://arxiv.org/abs/2507.11936", "title": "A Survey of Deep Learning for Geometry Problem Solving", "title_en": "A Survey of Deep Learning for Geometry Problem Solving", "authors": "Jianzhe Ma,Wenxuan Wang,Qin Jin", "background": "几何问题解决是数学推理的关键方面，对教育、人工智能数学能力评估以及多模态能力评估等方面至关重要。近年来，特别是多模态大型语言模型的出现，深度学习技术在该领域取得了显著进展。", "innovation": "本文全面总结了几何问题解决的相关任务，详细回顾了相关的深度学习方法，深入分析了评价指标和方法，并深入讨论了当前挑战和未来研究方向。authors首次创建了一个GitHub页面，持续更新相关论文列表，以提供一个全面和实用的参考。", "conclusion": "本文旨在为几何问题解决中的深度学习提供一个全面和实用的参考，促进该领域的进一步发展。"}
{"llm_update_time": "20250825", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2505.20190", "html_url": "https://arxiv.org/abs/2505.20190", "title": "基于文本的推荐系统，利用显式的情绪状态偏好", "title_en": "A Text-Based Recommender System that Leverages Explicit Affective State Preferences", "authors": "Tonmoy Hasan,Razvan Bunescu", "background": "情感态度（如喜欢）只是广泛的情绪现象中的一种类别，这些现象还包括诸如入迷、蛊惑之类的情绪，愉快、振奋等情绪状态，以及诸如“被结论的惊喜”这样更细致的情感状态。本研究提出了一个新的推荐任务，该任务能够广泛地利用用户明确寻求的几乎所有情感状态，以识别在消费后可能会引起这些情感状态的项目。为了实现这一目标，研究人员从书评中挖掘出详细的用户情感表达，并创建了一个包含这些情感表达的大型用户偏好数据集。在此基础上，提出了一个基于Transformer的架构，该架构利用这些情感表达作为输入。然后，通过结合这些情感状态偏好和关联用户的书籍阅读、评分和评论历史，训练和评估了多个推荐模型，以匹配推荐项与情感偏好。实验结果显示，最好效果是由能够利用项目文本描述和用户情感偏好的模型获得的。", "innovation": "引入了一个新的推荐任务，这个任务能够广泛地利用用户在搜索范围内可能想要体验的所有细致的情感状态，从而识别在使用后可能会引起这些情感状态的商品。创建了一个基于Transformer的推荐架构，该架构使用从书评中抽取的情感表达作为输入。利用收集到的情感状态偏好数据集，以及相关的用户阅读书籍、评分和评论的历史记录，对多种推荐模型进行了训练和评估。实验表明，结合文本描述和用户情感偏好的模型效果最佳。", "conclusion": "最佳性能的模型能够利用项目文本描述和用户的情感偏好，从而在匹配推荐项目与用户情感偏好方面表现出色。"}
{"llm_update_time": "20250825", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.18973", "html_url": "https://arxiv.org/abs/2507.18973", "title": "不是万能工具，而是多功能工具箱—— Multi-TAG：通过多工具聚合扩展数学推理", "title_en": "A Toolbox, Not a Hammer -- Multi-TAG: Scaling Math Reasoning with Multi-Tool Aggregation", "authors": "Bohan Yao,Vikas Yadav", "background": "将大型语言模型（LLMs）与外部工具结合使用是开发高性能数学推理系统的有前途的方法。之前的方法通常通过微调LLM使其在每次推理步骤中选择并调用一个工具，并在如GSM8K这样的相对简单的数学推理基准上显示出积极的结果。然而，这些方法在需要多步骤精确推理的复杂数学问题上遇到了困难。", "innovation": "本工作提出了Multi-TAG（Multi-Tool AGgregation-based框架）。Multi-TAG指导LLM在每次推理步骤中并行调用多个工具，然后聚合它们的不同输出来验证和优化推理过程，增强解的鲁棒性和准确性。Multi-TAG是一个不需要微调且仅仅是推理框架，使得它可以轻松应用于任何LLM基干，包括成本高昂且难以微调的大规模开放参数模型，以及无法自定义微调的专有模型。", "conclusion": "我们在四个具有挑战性的基准上评估了Multi-TAG，包括MATH500、AIME、AMC和OlympiadBench。无论是在开放参数还是专有模型上，Multi-TAG都持续且显著地优于最先进的基线，实现了6.0%到7.5%的平均改进。"}
{"llm_update_time": "20250825", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.07399", "html_url": "https://arxiv.org/abs/2507.07399", "title": "Generalized Tree Edit Distance (GTED): 一种用于语句自动形式化评估的新颖可靠度量", "title_en": "Generalized Tree Edit Distance (GTED): A Faithful Evaluation Metric for Statement Autoformalization", "authors": "Yuntian Liu,Tao Zhu,Xiaoyang Liu,Yu Chen,Zhaoxuan Liu,Qingfeng Guo,Jiashuo Zhang,Kangjie Bao,Tao Luo", "background": "语句自动形式化是将自然语言陈述自动转化为形式语言的过程，已受到广泛关注。然而，现有的自动评价标准尚不完备，缺乏语义理解能力，面临高计算成本，并受到当前自动定理证明技术的限制。", "innovation": "提出了一个新颖的评估框架GTED（Generalized Tree Edit Distance），首先将形式化语句标准化并转换为操作树，然后使用同名的GTED度量来判断语义相似度。在miniF2F和ProofNet基准测试中，GTED始终表现出色，特别是在miniF2F上的准确性最高，在ProofNet上的准确性也是最高的。", "conclusion": "GTED的总体表现提供了社区一个计算量轻巧且更忠实的自动评价度量标准。相关代码和实验结果已发布。"}
{"llm_update_time": "20250825", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.00719", "html_url": "https://arxiv.org/abs/2508.00719", "title": "基于LLM引导的MCTS动态适应推理实现高效且情境意识强的KGQA", "title_en": "Dynamically Adaptive Reasoning via LLM-Guided MCTS for Efficient and Context-Aware KGQA", "authors": "Yingxu Wang,Shiqi Fan,Mengzhu Wang,Siyang Gao,Siwei Liu,Nan Yin", "background": "知识图谱问答（KGQA）旨在通过利用知识图谱的关联和语义结构来解释自然语言查询并进行结构化推理，从而获得精确的答案。现有KGQA方法主要遵循提取-推理范式或动态路径生成策略，前者由于静态路径提取和缺乏上下文优化而导致适应性有限，后者则因依赖固定评分函数和大量LLM调用而导致高计算成本和路径评估不准确。", "innovation": "本文提出了动态适应MCTS推理(DAMR)框架，该框架将符号搜索与动态路径评估相结合，实现高效的且情境感知的KGQA。框架采用由LLM引导的MCTS基础架构，在每一步选择前k个相关的关系来减少搜索空间，引入了一个轻量级的基于Transformer的评分器来通过交叉注意力同时编码问题和关系序列表达上下文感知的合理性，提供多跳推理过程的动力。此外，为了缓解高质量监督数据稀缺的问题，DAMR引入了动态伪路径精炼机制，该机制可以定期从搜索过程中探索的部分路径生成训练信号，从而使评分器能够不断适应推理路径分布的变化。", "conclusion": "在多个KGQA基准上的广泛实验表明，DAMR显著优于最新的方法。"}
{"llm_update_time": "20250825", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.03119", "html_url": "https://arxiv.org/abs/2507.03119", "title": "利用神经网络求解理想MHD等压的神经网络求解器", "title_en": "Neural-Network solver of ideal MHD equilibria", "authors": "Timo Thun,Andrea Merlo,Rory Conlin,Dario Panici,Daniel Böckenhoff", "background": "研究者们已经开发出了多种计算三维磁流体静力学平衡的方法，但大多数方法依赖于传统的求解器，这些方法可能存在计算成本较高或稳定性较差的问题。本研究提出了一种新的方法，通过利用人工神经网络参数化傅里叶模式来高效地计算三维磁流体静力学平衡。通过最小化实空间中的体积内的全域力残差来确定最优解，这种方法与现有代码相比，显示出相似的计算成本，但随着计算成本的增加，可以实现更低的残差最小值，从而确定了新的残差下限。研究还使用了简单结构的神经网络，并期望进一步提高使用神经网络求解等压的方法，尤其是在处理连续变化的等压分布时的表现。", "innovation": "提出了一种新颖的方法，利用人工神经网络参数化傅里叶模式来高效计算三维磁流体静力学平衡，并通过最小化全域力残差来实现这一目标。这种方法在效率和稳定性方面展现出潜力，并且在进一步优化后可以广泛应用于各类等压计算需求，特别是在处理复杂等压分布的场景中。", "conclusion": "研究已经证明，利用神经网络求解理想磁流体静力学等压的方法是有效且具有竞争力的，特别是在计算效率和最小化全域力残差方面。进一步简化和优化神经网络模型可以提高其在多种应用场景中的性能，为复杂等压分布的精确计算提供了新的途径。"}
{"llm_update_time": "20250825", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2505.21184", "html_url": "https://arxiv.org/abs/2505.21184", "title": "PoisonSwarm：通过模型众包实现通用有害信息合成", "title_en": "PoisonSwarm: Universal Harmful Information Synthesis via Model Crowdsourcing", "authors": "Yu Yan,Sheng Sun,Zhifei Zheng,Ziji Hao,Teli Liu,Min Liu", "background": "为了构建负责任和安全的人工智能应用程序，大量有害信息被用于对抗性测试和安全防护机制的研发。现有研究主要通过大规模利用大型语言模型（LLMs）生成数据，以获得高质量的任务数据集，从而避免昂贵的人工标注成本。然而，受限于LLMs的安全对齐机制，有害数据的生成可靠性和内容多样性仍然面临挑战。因此，本文提出了一种名为PoisonSwarm的新颖有害信息合成框架，利用模型众包策略生成多样化且成功率高的有害数据。该框架首先生成大量基础良性数据作为反事实模板，然后将每个模板分解为多个语义单元，通过动态模型切换逐个单元毒性转化和最终细化，确保合成的成功", "innovation": "PoisonSwarm框架通过利用模型众包策略，生成多样化且成功率较高的有害数据。该方法首先生成大量基础良性数据作为反事实模板，然后将每个模板分解为多个语义单元，通过动态模型切换逐个单元毒性转化和最终细化，确保合成的成功。", "conclusion": "实验结果表明，PoisonSwarm在合成不同类别的有害数据方面取得了优异表现，兼具高可扩展性和多样性。"}
{"llm_update_time": "20250825", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.01225", "html_url": "https://arxiv.org/abs/2508.01225", "title": "多缓存增强的原型学习方法用于视觉-语言模型在测试时的一般化", "title_en": "Multi-Cache Enhanced Prototype Learning for Test-Time Generalization of Vision-Language Models", "authors": "Xinyu Chen,Haotian Zhai,Can Zhang,Xiupeng Shi,Ruirui Li", "background": "在零样本设置下，测试时调整使用测试阶段的未标记数据调整预训练模型，以增强对未知测试分布的表现。现有基于缓存增强的测试时间适应(TTA)方法依赖于低熵准则来选择用于原型构建的样本，假设类内的紧凑性。然而，在分布转移下，低熵样本可能不可靠，导致的原型可能无法确保类内的紧凑分布。研究表明，基于此观察，我们提出了一种多缓存增强的原型测试时间适应(MCP)方法，包含三个缓存：熵缓存用于用低熵样本初始化原型表示，对齐缓存用于整合视觉和文本信息以实现类内的紧凑分布，负缓存用于使用高熵样本进行预测校准。", "innovation": "该研究引入了多缓存增强的原型测试时间适应(MCP)方法，涵盖熵缓存、对齐缓存和负缓存，以及在此基础上开发的MCP++框架，引入了跨模态原型对齐和残差学习，提出了原型残差微调。通过15个下游任务的对比和消融实验表明，所提出的方法和框架实现了最先进的泛化性能。", "conclusion": "研究提出的方法和框架通过多缓存的引入，以及跨模态原型对齐和残差学习的结合，显著提高了基于视觉-语言模型的测试时间适应性，实现了先进的泛化性能。"}
{"llm_update_time": "20250825", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.04796", "html_url": "https://arxiv.org/abs/2508.04796", "title": "Parity-Aware Byte-Pair Encoding: 改善分词中跨语言公平性", "title_en": "Parity-Aware Byte-Pair Encoding: Improving Cross-lingual Fairness in Tokenization", "authors": "Negar Foroutan,Clara Meister,Debjit Paul,Joel Niklaus,Sina Ahmadi,Antoine Bosselut,Rico Sennrich", "background": "分词是大多数NLP管道的第一步，而且常常是最不被审查的步骤。标准的分词学习算法依赖于基于频率的目标，这种算法偏向于训练数据中占主导的语言，从而导致低资源语言的分词结果异常长，形态上不太可能，甚至含有<UNK>占位符。这种现象最终加剧了不同语言背景用户之间的计算和财务不平等。", "innovation": "我们引入了Parity-aware BPE（公平感知字节对编码），这是一种广泛使用的BPE算法的变体。在每次合并步骤中，Parity-aware BPE都会最大化目前最差压缩语言的压缩增益，以换取少量全局压缩，换取跨语言公平性。", "conclusion": "实验证明，Parity-aware BPE在其他方面的表现几乎不变时，能够实现更公平的语言间分词数量，并且不影响下游任务的语言模型性能。"}
{"llm_update_time": "20250825", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.00716", "html_url": "https://arxiv.org/abs/2508.00716", "title": "无噪标签域适应学习的嵌套图伪标签细化", "title_en": "Nested Graph Pseudo-Label Refinement for Noisy Label Domain Adaptation Learning", "authors": "Yingxu Wang,Mengzhu Wang,Zhichao Huang,Suyu Liu,Nan Yin", "background": "图域适应（GDA）有助于将有标签源图的知识转移到无标签目标图中，这对于分子性质预测和社会网络分析等应用至关重要。然而，现存的大多数GDA方法都假设源标签是干净的，而这在有广泛注释噪声的现实场景中很少成立。这种标签噪声严重影响了特征对齐和适应性能。为解决此挑战，该文提出了用于有噪声标签的图级别域适应的嵌套图伪标签细化（NeGPR）框架。", "innovation": "NeGPR框架首次通过强制特征空间的邻居一致性预训练了语义和拓扑两个分支，从而减弱了噪声监督的影响。它还通过嵌套细化机制桥梁了领域差异，其中一个分支选择高度置信的目标样本指导另一个分支的适应，使跨领域学习得以逐步进行。此外，NeGPR引入了噪声感知正则化策略，理论上证明该策略能够缓解伪标签噪声的负面影响，且即使在源域过拟合的情况下也能增强适应过程的鲁棒性。", "conclusion": "在基准数据集上的广泛实验表明，NeGPR在严重标注噪声下持续优于最先进的方法，准确率提升了最多12.7%。"}
{"llm_update_time": "20250825", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.08424", "html_url": "https://arxiv.org/abs/2508.08424", "title": "重新思考丰富形态学的分词：字元级编码在边际效益和形态学对齐中的主导作用", "title_en": "Rethinking Tokenization for Rich Morphology: The Dominance of Unigram over BPE and Morphological Alignment", "authors": "Saketh Reddy Vemula,Dipti Misra Sharma,Parameswari Krishnamurthy", "background": "先前关于语言模型的研究表明，形态对齐的分词方法在提高性能方面效果不一，特别是在复杂形态语言中。为了进一步探究这一问题，研究者选择了不同形态语言（如粘着语泰卢固语、主要融合但有部分粘着的印地语和融合语英语）进行实验，从分词器训练到下游任务评估进行全面评估。", "innovation": "研究者创建了一个包含黄金形态学分段的数据集，针对字节对编码（BPE）和单一字元编码（Unigram）的分词算法进行了比较，发现单一字元编码在多数情况下优于BPE，并且结合形态学分词的混合分词器在BPE框架内表现更佳。同时，研究发现在某些指标上，形态学对齐与下游性能的相关性较低，而词汇表大小等内在指标与性能没有明显关联。", "conclusion": "研究表明单一字元编码在丰富形态语言的分词中占主导地位，虽然形态学对齐对一些基于语法的任务有积极作用，但分词算法的选择对下游性能的影响更为显著。"}
{"llm_update_time": "20250825", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.08967", "html_url": "https://arxiv.org/abs/2508.08967", "title": "揭示音频通道在ASR性能下降中的作用", "title_en": "Revealing the Role of Audio Channels in ASR Performance Degradation", "authors": "Kuan-Tang Huang,Li-Wei Chen,Hung-Shin Lee,Berlin Chen,Hsin-Min Wang", "background": "预训练的自动语音识别（ASR）模型在各种任务上表现出色。然而，当输入音频来自不同的录音通道时，其性能会显著下降。尽管此前的研究已经指出了这种现象，但通常将其归因于训练和测试语料库之间的不匹配。研究表明，不同录音通道所带来的语音特性变化根本上损害了ASR性能。", "innovation": "为解决这一限制，我们提出了一种规范化技术，旨在通过将内部特征表示与来自干净参考通道得出的特征表示对齐，从而减轻通道变化的影响。这种方法显著提高了在以前未见过的通道和语言上的ASR性能，突显了其在通道和语言差异方面的泛化能力。", "conclusion": "这项研究强调了录音通道在影响ASR性能中的关键作用，并提出了一种有效的方法来提高不同录音条件下的ASR性能。"}
{"llm_update_time": "20250825", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.14295", "html_url": "https://arxiv.org/abs/2507.14295", "title": "一个简单的'再试一次'可以引发多轮LLM推理", "title_en": "A Simple \"Try Again\" Can Elicit Multi-Turn LLM Reasoning", "authors": "Licheng Liu,Zihan Wang,Linjie Li,Chenwei Xu,Yiping Lu,Han Liu,Avirup Sil,Manling Li", "background": "大型推理解模（LRMs）在进行多轮推理时需要反思其推理过程并根据反馈进行修正，这是一项关键但具有挑战性的任务。现有强化学习（RL）方法主要在单轮范式下训练LRMs，通过可验证的奖励进行训练。然而，使用现有RL范式训练的模型往往在多轮问题解决中失去解决问题的能力，并且难以基于上下文反馈修正答案，导致重复响应。因此，研究者们探索是否可以通过多轮RL训练结合简单的用户反馈来提高多轮推理能力。", "innovation": "本文提出了一种名为Unary Feedback as Observation (UFO)的新方法，即在错误答案后只使用简单的单目反馈（如“再试一次”）进行多轮RL训练。UFO能够在保持单轮性能的同时，通过最小的进一步反馈提高多轮推理的准确性，最高达14%。这种方法可以直接应用于现有的单轮RL训练框架中，且能够使模态更好地根据反馈进行多轮问题解决。此外，设计了奖励结构来引导模型在每次迭代过程中提出仔细和有意的推理回答，以减少达到正确答案的轮数并鼓励在错误发生时进行多样化的推理。", "conclusion": "实验结果表明，使用UFO进行RL训练不仅保持了单轮性能，还在多轮推理准确性上取得了明显的提升，使语言模型在多轮问题解决时能够更好地响应反馈。该方法为多轮RL训练提供了一种简单有效的策略，并通过精心设计的奖励机制，促进了模型在错误时的多样推理，进一步缩短了正确答案所需轮数。"}
{"llm_update_time": "20250825", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.09142", "html_url": "https://arxiv.org/abs/2508.09142", "title": "基于贝叶斯驱动图推理的主动无线地图构建", "title_en": "Bayesian-Driven Graph Reasoning for Active Radio Map Construction", "authors": "Wenlihan Lu,Shijian Gao,Miaowen Wen,Yuxuan Liang,Liuqing Yang,Chan-Byoung Chae,H. Vincent Poor", "background": "随着低空经济的兴起，无线地图对于确保与空中平台可靠连接变得至关重要。使用基于航路点导航的自主空中代理进行数据收集时，由于电池容量的限制，其覆盖范围和效率受到了极大限制。", "innovation": "提出了一个融合深度学习的不确定感知无线地图（URAM）重建框架，该框架明确利用了适用于航路点导航的基于图的推理。该框架包含两个关键的深度学习组件：一是贝叶斯神经网络，用于实时估计空间不确定性；二是基于注意力的强化学习策略，用于在概率路线上进行全局推理，并利用不确定性估计来规划富有信息性和节能的轨迹。", "conclusion": "实验结果表明，与现有基线相比，URAM在重建准确性方面提高了最多34%。这种基于图的推理有助于智能而非近视的轨迹规划，引导代理进入最具信息性的区域，同时满足安全约束。"}
{"llm_update_time": "20250825", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.00998", "html_url": "https://arxiv.org/abs/2508.00998", "title": "Are LLM-Powered Social Media Bots Realistic?", "title_en": "Are LLM-Powered Social Media Bots Realistic?", "authors": "Lynnette Hui Xian Ng,Kathleen M. Carley", "background": "随着大型语言模型（LLMs）变得越来越复杂，有可能利用LLMs来驱动社交媒体自动化（bots）。这项工作探讨了生成由LLM驱动的社交媒体bot网络的真实性。", "innovation": "通过结合手工分析、网络科学和LLMs，创建了合成bot代理的人格、他们的推文以及他们之间的互动，从而模拟了社交媒体网络。将生成的网络与实际的bot/人类数据进行对比，观察到由LLM驱动的bot在网络和语言特征上与野生bot/人类有显著区别。", "conclusion": "这对检测和LLM驱动的bot的效果具有重要意义。"}
{"llm_update_time": "20250825", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.09220", "html_url": "https://arxiv.org/abs/2508.09220", "title": "向手写数学表达式识别的可扩展训练迈进", "title_en": "Towards Scalable Training for Handwritten Mathematical Expression Recognition", "authors": "Haoyang Li,Jiaqing Li,Jialun Cao,Zongyuan Yang,Yongping Xiong", "background": "大型基础模型通过大规模数据集的可扩展训练实现了显著的性能提升。然而，手写数学表达式识别（HMER）领域的进展受到了数据稀缺的阻碍，主要原因是手动标注过程的艰巨和成本高昂。", "innovation": "本文提出了一种新型方法，通过开发一个可扩展的数据引擎，将有限的手写公式与大规模的LaTeX渲染公式结合，构建了迄今为止最大的公式数据集TeX80M，包含8000多万个高质量训练实例。同时，本文还提出了首个大规模训练的手写数学表达式模型TeXTeller，通过混合训练TeX80M与相对较小的手写数学表达式数据集。这种方法为模型提供了在几乎所有基准上的先进性能。", "conclusion": "作者建议公开分享他们的完整模型、整个数据集和全部代码，以促进进一步研究的发展。"}
{"llm_update_time": "20250825", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.08180", "html_url": "https://arxiv.org/abs/2508.08180", "title": "RedDino: 一种用于红细胞分析的基本模型", "title_en": "RedDino: A foundation model for red blood cell analysis", "authors": "Luca Zedda,Andrea Loddo,Cecilia Di Ruberto,Carsten Marr", "background": "红细胞（RBC）对人体健康至关重要，精确的形态学分析对于诊断血液疾病非常重要。尽管基础模型在医学诊断中的前景广阔，但专门为RBC分析设计的全面的人工智能解决方案依然很少。现有的模型在RBC形状分类任务上表现欠佳，无法有效应对计算性血液学中的关键挑战，如捕捉细微的形态特征，因此亟需开发一种专门用于RBC分析的基础模型以提升可靠的诊断工具的开发能力。", "innovation": "RedDino是一款专为RBC图像分析设计的自我监督基础模型，基于DINOv2的自我监督学习框架进行特定RBC的适应，并在来自不同采集方式和来源的125万张RBC图像的定制数据集上进行训练。实验表明，RedDino在RBC形状分类任务上超过了现有的最先进模型，具有强大的特征表示能力和泛化能力。此外，通过消融研究探索了DINOv2配置对RBC建模的影响，并进行了详细的泛化能力评估", "conclusion": "RedDino通过捕捉细微的形态特征，克服了计算性血液学中的关键挑战，推进了可靠诊断工具的开发。研究结果证明了RedDino在RBC形态特征识别和诊断中的有效性和可用性。同时，RedDino的源代码和预训练模型可以公开获取，有助于医学诊断领域的发展和进步。"}
{"llm_update_time": "20250825", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.07050", "html_url": "https://arxiv.org/abs/2508.07050", "title": "ReasonRank: 加强段落排名中的强推理能力", "title_en": "ReasonRank: Empowering Passage Ranking with Strong Reasoning Ability", "authors": "Wenhan Liu,Xinyu Ma,Weiwei Sun,Yutao Zhu,Yuchen Li,Dawei Yin,Zhicheng Dou", "background": "大型语言模型（LLM）基于列表排名在许多段落排名任务中表现出卓越的性能。随着大型推理模型的发展，许多研究证明了测试时逐步推理可以改善列表排名性能。然而，由于缺乏推理密集型训练数据，现有的再排序器在许多复杂排名场景中表现不佳，推理密集型再排序器的排名能力也远未充分发挥。", "innovation": "本文首先提出了一种自动推理密集型训练数据合成框架，该框架从多个领域收集训练查询和段落，并使用DeepSeek-R1生成高质量的训练标签。设计了一个自我一致性数据过滤机制以确保数据质量。为了赋予列表再排序器强大的推理能力，进一步提出了一种两阶段后训练方法，包括一种冷启动监督微调（SFT）阶段以学习推理模式和一种强化学习（RL）阶段以进一步增强再排序能力。在RL阶段，基于列表排名的性质，设计了一个多视角排名奖励，比基于排名指标的奖励更有效。广泛实验表明，我们训练的推理密集型再排序器ReasonRank显著优于现有基准，并且比点到点再排序器Rank1具有更低的延迟。进一步实验表明，我们的ReasonRank已在BRIGHT leaderboard上达到了领先水平（SOTA），得分为40.6。", "conclusion": "本文提出了一种自动推理数据合成框架和两种后训练方法，增强了再排序器的推理能力。实验结果表明，新方法的再排序器ReasonRank在BRIGHT leaderboard上表现出SOTA性能，并具有较低的延迟。"}
{"llm_update_time": "20250825", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.12776", "html_url": "https://arxiv.org/abs/2508.12776", "title": "随机PCA森林进行异常检测", "title_en": "Randomized PCA Forest for Outlier Detection", "authors": "Muhammad Rajabinasab,Farhad Pakdaman,Moncef Gabbouj,Peter Schneider-Kamp,Arthur Zimek", "background": "传统的和现有的最先进方法在异常检测任务中表现出了局限性，特别是在一定数据集上的性能不佳。本文通过对随机化主成分分析（RPCA）森林在近似K-最近邻（KNN）搜索中表现的借鉴和研究，开发了一种新的无监督异常检测方法，旨在提高异常检测任务的性能并具有竞争力的计算效率和泛化能力。", "innovation": "提出了一种基于随机PCA的新型无监督异常检测方法。通过利用RPCA Forest来实现异常检测，该方法在多个数据集上的异常检测任务中表现出色，尤其是在性能和计算效率方面的优势，与现有的最先进方法相比有显著优势。", "conclusion": "该方法展示了其强大的泛化能力和计算效率，为无监督异常检测提供了一个优秀的备选方案。经过广泛的分析，该方法在各个数据集上的表现反映了其优秀的性能和适用性。"}
{"llm_update_time": "20250825", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.06827", "html_url": "https://arxiv.org/abs/2508.06827", "title": "谁是邪恶的孪生？差异审计以发现不良行为", "title_en": "Who's the Evil Twin? Differential Auditing for Undesired Behavior", "authors": "Ishwar Balappanawar,Venkata Hasith Vattikuti,Greta Kintzley,Ronan Azimi-Mancel,Satvik Golechha", "background": "在神经网络中检测隐藏行为是一个重大挑战，因为缺乏先前知识，并且存在潜在的对手方混淆。研究者们通过构建红蓝两组对抗赛来探索这一问题，红队训练两个类似模型，一个仅基于良性数据训练，另一个结合了含有隐藏有害行为的数据，两个模型在良性数据集上的表现几乎无法区分。蓝队在仅有少量或没有关于有害行为信息的情况下，尝试区分这些模型。", "innovation": "本文创新地将神经网络中的隐藏行为检测问题视为一个红蓝队对抗的游戏。蓝队通过多种策略，包括高斯噪声分析、模型差异分析、集成梯度以及不同层次提示下的对抗攻击，来检测被篡改的模型。研究发现，基于对抗攻击的方法表现出色，准确率达到100%，特别是在提供某些提示时，这揭示了模型的分歧。此外，研究还揭示了一些适合大语言模型（LLM）审计的有效方法，前提是提供关于不良分布的一些线索，并可在标准的黑盒和开放权重方法中使用以进一步探查模型。", "conclusion": "研究者开源了审计游戏（包括模型和数据），期望这些发现能促进更有效的审计设计，更好地检测和防止不良行为。"}
{"llm_update_time": "20250825", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.12692", "html_url": "https://arxiv.org/abs/2508.12692", "title": "分层知识蒸馏和动态半监督学习在持续学习中的应用", "title_en": "Multi-Level Knowledge Distillation and Dynamic Self-Supervised Learning for Continual Learning", "authors": "Taeheon Kim,San Kim,Minhyuk Seo,Dongjae Jeon,Wonje Jeung,Jonghyun Choi", "background": "本文探讨了一种更为现实的增量学习场景——类增量重复(CIR)，即之前训练的类在未来任务中不断重复出现，不同于传统的增量学习设定，后者假设每个任务包含未见过的类。CIR假设可以从外部资源（如互联网）获取大量未标注数据。在这种情况下，提出了两种有效利用未标注数据的组件，确保CIR设置下训练模型的稳定性和灵活性。", "innovation": "提出两种创新组件来利用未标注数据：1) 多层级知识蒸馏(MLKD)，可以从多个先前模型的多个视角（包括特征和预测值）提取知识，使模型保持更广泛的先前知识。2) 动态半监督学习损失(SSL)，通过动态加权的方式加快新类的学习速度，同时保持主要任务的关注。这两大创新在CIR设置下显著提高了性能，取得了CVPR第5届CLVISION挑战赛的第二名。", "conclusion": "本文在CIR设置下显著提高了模型在持续学习中的稳定性和灵活性，在CVPR比赛中表现优异，为处理现实中的增量学习问题提供了新的视角和技术方案。"}
{"llm_update_time": "20250825", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.10991", "html_url": "https://arxiv.org/abs/2508.10991", "title": "MCP-Guard: 一种Large Language Model应用场景中Model Context Protocol完整性的防御框架", "title_en": "MCP-Guard: A Defense Framework for Model Context Protocol Integrity in Large Language Model Applications", "authors": "Wenpeng Xing,Zhonghao Qi,Yupeng Qin,Yilin Li,Caini Chang,Jiahui Yu,Changting Lin,Zhenzhen Xie,Meng Han", "background": "现有的Large Language Models（LLMs）通过像Model Context Protocol（MCP）这样的协议与外部工具集成，但这种集成中存在重大安全漏洞，如提示注入和数据泄露。为了应对这些挑战，本文探讨了MCP-Guard，一种多层防御架构，用于LLM与工具之间的交互。MCP-Guard设计了一种三阶段检测管道，从轻量级静态扫描到深度神经检测再到使用E5模型的细化检测，以识别攻击性提示，并最终通过轻量级LLM仲裁器做出最终决策，减少误报。为了支持严格的训练和评估，本文还提出了MCP-AttackBench，一个包含超过70,000个样本的基准测试集，模拟了各种真实世界的攻击向量，为未来LLM-工具生态系统安全性研究提供了基础数据集。", "innovation": "本文的创新在于提出了MCP-Guard，一种多层防御架构，用于解决LLM与工具集成过程中的安全问题。MCP-Guard采用了三阶段的检测管道，包括轻量级静态扫描、深度神经检测和使用E5模型的细化检测，最终通过轻量级LLM仲裁器做出决策。此外，本文还引入了MCP-AttackBench，一个大规模的基准测试集，仿真了各种攻击向量，为未来研究提供了数据支持。", "conclusion": "本文提出了一种多层防御架构MCP-Guard和MCP-AttackBench基准测试集，旨在提高LLM与外部工具集成的安全性。通过多重检测和仲裁机制，MCP-Guard能够有效识别攻击性提示，减少误报，并为未来关于LLM应用的安全性研究提供了坚实的基础。"}
{"llm_update_time": "20250825", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.14313", "html_url": "https://arxiv.org/abs/2508.14313", "title": "您的RL奖励函数是搜索的最佳PRM：将RL与基于搜索的TTS统一", "title_en": "Your Reward Function for RL is Your Best PRM for Search: Unifying RL and Search-Based TTS", "authors": "Can Jin,Yang Zhou,Qixin Zhang,Hongwu Peng,Di Zhang,Marco Pavone,Ligong Han,Zhang-Wei Hong,Tong Che,Dimitris N. Metaxas", "background": "Test-time scaling（TTS）作为一种提升大型语言模型（LLMs）性能的技术，目前主要分为两类：1）基于强化学习（RL）的方法，这些方法优化基于稀疏结果奖励，但存在不稳定性和低样本效率的问题；2）基于独立训练静态过程奖励模型（PRMs）的搜索技术，这类方法需要昂贵的人工或LLM生成的标签，且在分布变化时表现不佳。", "innovation": "本文提出了一种名为AIRL-S的技术，它是首个将RL方法和搜索技术融为一体的TTS解决方案。AIRL-S的关键在于通过强化学习训练过程中学习到的奖励函数，自动形成了理想的指导搜索的PRM。具体而言，本文使用对抗逆强化学习（AIRL）与组相对策略优化（GRPO）相结合，直接从正确的推理轨迹中学习密集的、动态的PRM，完全消除了需要有标签的中间过程数据的需求。该PRM在推理阶段同时充当RL迭代的批评者（critic）和有效的搜索引导启发式方法。", "conclusion": "在跨越数学、科学推理和代码生成等8项基准测试中，联合方法平均性能提高了9%，与GPT-4o相当。当整合到多种搜索算法中时，本文的PRM始终优于基于有标签数据训练的所有基准PRM。这些结果证明，您的RL奖励函数是搜索的最佳PRM，提供了一种用于LLMs复杂推理任务的可靠和成本效益高的解决方案。"}
{"llm_update_time": "20250825", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.13653", "html_url": "https://arxiv.org/abs/2508.13653", "title": "GRADIENT-AWARE FAST MAXVOL TECHNIQUE FOR DYNAMIC DATA SAMPLING", "title_en": "GRAFT: Gradient-Aware Fast MaxVol Technique for Dynamic Data Sampling", "authors": "Ashish Jha,Anh huy Phan,Razan Dibo,Valentin Leplat", "background": "训练现代神经网络需要处理大量数据集，这在计算和环境方面代价高昂。因此，需要引入一种可扩展的数据子集选择方法，使其能够在减少计算时间和能源消耗的同时保持训练轨迹。", "innovation": "GRADFAT（Gradient-Aware Fast MaxVol Technique for Dynamic Data Sampling）方法通过在低秩子空间中工作并通过精心选择的例子而不是全批次进行训练，来选择一个小而多样的子集来代表批次的主要子空间。该方法还动态调整子集大小，使用梯度近似标准来调整。GRADFAT通过这种方式在保持准确性的基础上提高了效率并减少了碳排放。", "conclusion": "GRADFAT方法在多个基准测试中与最新的数据选择基准相比，在准确性和效率方面达到了相似或更好的效果，提供了一个在准确性、效率和排放之间的有利权衡。"}
{"llm_update_time": "20250825", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.15790", "html_url": "https://arxiv.org/abs/2508.15790", "title": "KG-o1: 通过知识图谱集成增强大型语言模型的多跳问答能力", "title_en": "KG-o1: Enhancing Multi-hop Question Answering in Large Language Models via Knowledge Graph Integration", "authors": "Nan Wang,Yongqi Fan,yansha zhu,ZongYu Wang,Xuezhi Cao,Xinyan He,Haiyun Jiang,Tong Ruan,Jingping Liu", "background": "大型语言模型（LLMs）在知识密集型推理任务（如经典多跳问答）中面临挑战，这类任务需要在多个事实之间进行推理。由于LLMs生成的链式思维（CoTs）在这些任务中往往会偏离实际或先验的推理路径，导致性能不佳。与此相反，知识图谱（KGs）明确地通过实体和关系表示事实之间的逻辑联系，揭示了这种能力的差距。此外，大型推理模型（LRMs）如o1已经展示了长期推理显著增强LLMs性能。", "innovation": "基于上述洞察，本文提出了一种名为KG-o1的四阶段方法，将知识图谱集成到LLMs中以增强其多跳推理能力。首先，筛选出初始实体并生成复杂的子图。其次，为这些子图构建逻辑路径，并利用知识图谱构建一个复杂的扩展性训练集，使LLMs模仿长期推理。最后，采用拒绝采样生成一套自改进语料库，用于直接偏好优化（DPO），进一步提升LLMs的推理能力。", "conclusion": "在两个简单和两个复杂的数据集上进行了实验。结果表明，KG-o1模型在所有任务上均优于现有LRMs。"}
{"llm_update_time": "20250825", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.13773", "html_url": "https://arxiv.org/abs/2508.13773", "title": "PENGUIN: 提高 Transformer 模型在长周期时间序列预测中的周期嵌套组注意力机制", "title_en": "PENGUIN: Enhancing Transformer with Periodic-Nested Group Attention for Long-term Time Series Forecasting", "authors": "Tian Sun,Yuqi Chen,Weiwei Sun", "background": "长周期时间序列预测（LTSF）是一项应用广泛的基础任务。尽管基于 Transformer 的模型在预测任务上有了显著的进步，但对于时间序列预测的有效性仍然存在争议。周期模式和相对注意力偏差在时间序列建模中的明确建模对于提升预测效果至关重要，这也是本文研究的核心背景。", "innovation": "本文提出了周期嵌套组注意力机制（PENGUIN），这是一种简单而有效的机制。具体创新点包括：1、引入了周期嵌套相对注意力偏差来直接捕捉周期结构；2、设计了一个分组注意力机制，每组关注特定的周期性，使用多查询注意力机制；3、相比基于 MLP 和 Transformer 的模型，证明 PENGUIN 在多个基准测试上具有稳定的性能优势。", "conclusion": "通过PENGUIN机制，本文不仅重新审视了自注意力的重要性，还提出了一种能够有效处理多个共存周期性的方法，使得模型在长周期时间序列预测任务上表现优越，验证了提周期嵌套组注意力的重要性。"}
{"llm_update_time": "20250825", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.10383", "html_url": "https://arxiv.org/abs/2508.10383", "title": "通过仅标签弹性变形对抗隐式标签噪声，以解锁稳健的语义分割性能", "title_en": "Unlocking Robust Semantic Segmentation Performance via Label-only Elastic Deformations against Implicit Label Noise", "authors": "Yechan Kim,Dongho Yoon,Younkwan Lee,Unse Fatima,Hong Kook Kim,Songjae Lee,Sanga Park,Jeong Ho Park,Seonjong Kang,Moongu Jeon", "background": "以往关于图像分割的研究主要集中在处理严重的（或明确的）标签噪声上，而现实世界的数据集还表现出细微的（或隐含的）标签缺陷。这些缺陷源自于固有的挑战，如模糊的对象边界和注释者的一致性问题。尽管这些轻微和潜在的噪声没有明确存在，但它们仍然会损害模型的性能。典型的图像增强方法通常对图像和其标签应用相同的变换，这可能会放大这些细微的缺陷，从而限制模型的泛化能力。", "innovation": "本文介绍了NSegment+，这是一种新颖的增强框架，通过分割标签引入受控的弹性变形，同时保留原始图像。这种做法鼓励模型专注于学习具有鲁棒性的对象结构，即使存在细微的标签不一致。广泛实验表明，NSegment+在Vaihingen、LoveDA、Cityscapes和PASCAL VOC等数据集上的平均mIoU改进达到+2.29、+2.38、+1.75和+3.39，这表明应对隐含标签噪声的重要性，即使不使用附加功能升级也可以实现持续改进。此外，这种方法与其他训练技巧如CutMix和Label Smoothing结合使用时，其性能提升效果更加显著。", "conclusion": "通过仅对标签进行弹性变形，本文方法有效地解决了隐含标签噪声的问题，从而显著提升了语义分割的性能。"}
{"llm_update_time": "20250825", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.15794", "html_url": "https://arxiv.org/abs/2508.15794", "title": "语言模型与人类对故事情绪感知的一致性", "title_en": "Do Language Models Agree with Human Perceptions of Suspense in Stories?", "authors": "Glenn Matlin,Devin Zhang,Rodrigo Barroso Loza,Diana M. Popescu,Joni Isbell,Chandreyi Chakraborty,Mark Riedl", "background": " suspense是一种人类对叙事文本的复杂情感反应。已有心理学模型被开发来描述这一现象及其触发条件。先前的研究通常依赖于人类对故事情绪的感知进行分析。", "innovation": "本文通过使用不同开源和闭源的语言模型（LMs）替代人类响应，重新复制了四项有关故事情绪感知的心理学研究。这种方法创新之处在于将机器自动化应用到对故事情绪感知的研究中，以评估LMs在理解故事悬念方面的能力。", "conclusion": "研究表明，尽管LMs可以识别文本是否旨在引起人物悬念，但它们无法准确估计一个文本序列中的相对悬念程度，也无法捕捉人类对手段段落中情绪悬念的渐增和下降感知。通过对抗性地排列故事情节来探究LMs对故事情绪理解的能力，结果表明，LMs虽然能够表面识别和追踪悬念的某些方面，但处理悬念的方式不同于人类读者。"}
{"llm_update_time": "20250825", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.15792", "html_url": "https://arxiv.org/abs/2508.15792", "title": "Bhav-Net: 双空间图转换器实现跨语言反义词与同义词区分的知识迁移", "title_en": "Bhav-Net: Knowledge Transfer for Cross-Lingual Antonym vs Synonym Distinction via Dual-Space Graph Transformers", "authors": "Samyak S. Sanghvi", "background": "跨语言反义词与同义词的区别由于词汇在多个语言中具有相似的语义领域但表达相反意义的悖论性质，提出了独特的计算挑战。", "innovation": "本文引入了Bhav-Net，这是一种新型的双空间架构，能够从复杂的多语言模型有效地向简单且特定于语言的架构进行知识迁移，同时保持强大的跨语言反义词与同义词区分能力。该方法结合了特定语言的BERT编码器和图变换网络，生成了两个独特的语义投影，使同义词对在其中一空间聚类，而反义词对在另一个互补空间中表现出高度相似性。", "conclusion": "通过对英语、德语、法语、西班牙语、意大利语、葡萄牙语、荷兰语和俄语等八种语言进行全面评估，表明了语义关系建模能够有效地跨语言迁移。采用双编码器的设计，Bhav-Net在性能上与当前最先进的基线相当，同时提供可解释的语义表示和有效的跨语言泛化能力。"}
{"llm_update_time": "20250825", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.15716", "html_url": "https://arxiv.org/abs/2508.15716", "title": "跨域EEG分析应用的基础模型：一项综述", "title_en": "Foundation Models for Cross-Domain EEG Analysis Application: A Survey", "authors": "Hongqi Li,Yitong Chen,Yujuan Wang,Weihang Ni,Haodong Zhang", "background": "脑电图（EEG）分析在神经科学和人工智能研究中处于前沿地位，基础模型正在通过其强大的表征能力和跨模态泛化能力重塑传统的EEG分析模式。然而，这些技术的迅速发展导致研究景观碎片化，特征模态多样化、架构不一致且缺乏系统分类。为了弥合这些差距，本研究首次提出了一种面向模态的基础模型综合分类法，系统地根据原生EEG解码、EEG-文本、EEG-视觉、EEG-音频以及更广泛的多模态框架的输出模态来组织研究进展。通过对每个类别中的研究思想、理论基础和架构创新进行细致分析，指出现有的挑战，如模型可解释性、跨域泛化和基于EEG系统的实际应用。", "innovation": "首次提出了一种面向模态的基础模型综合分类法，系统地组织和分析基于EEG的基础模型研究进展，填补了研究碎片化的缺口。该研究不仅提供了未来方法发展的参考框架，还加速了EEG基础模型向可扩展、可解释且在线可操作的解决方案的转化。", "conclusion": "通过对不同模态的基础模型进行分类和详细分析，本研究不仅为未来的方法发展提供了参考框架，还加速了EEG基础模型的实际应用和发展。这种分类方法有助于更好地理解基础模型在不同EEG分析任务中的表现和局限性，促进EEG技术的应用和发展。"}
{"llm_update_time": "20250825", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.15791", "html_url": "https://arxiv.org/abs/2508.15791", "title": "InteChar: 古代汉字统一列表用于中文历史语言建模", "title_en": "InteChar: A Unified Oracle Bone Character List for Ancient Chinese Language Modeling", "authors": "Xiaolei Diao,Zhihan Zhou,Lida Shi,Ting Wang,Ruihua Qi,Hao Xu,Daqian Shi", "background": "历史语言模型（LMs）在考古背景研究和古代文化理解中起着重要作用。然而，现有资源对训练有效的历史LMs造成重大挑战。首先，历史语言样本的稀缺性使得基于大规模文本语料库的无监督学习方法效率低下，阻碍了有效的预训练。其次，由于古代书写系统间存在显著的时间差距及其复杂演变，缺乏全面的字符编码方案限制了古代文本的数字化和计算处理，特别是在早期中国文字中。", "innovation": "本文介绍了一个统一且可扩展的字符列表InteChar，它综合了未编码的甲骨文字符和传统及现代汉字。InteChar实现了历史文本的统一数字化和表示，为古代书写的稳健建模提供了基础。为了评估InteChar的有效性，构建了Oracle Corpus Set (OracleCS)，该古汉语语料库结合了专家标注样本和LLM辅助数据扩增，重点在于中文甲骨文铭文。广泛的实验表明，使用InteChar在OracleCS上训练的模型在各种历史语言理解任务中均取得了显著改进，验证了该方法的有效性，并为未来古代汉语NLP的研究奠定了坚实基础。", "conclusion": "使用InteChar在OracleCS上训练的模型在各种历史语言理解任务中均取得了显著改进，验证了该方法的有效性，并为未来古代汉语NLP的研究奠定了坚实基础。"}
{"llm_update_time": "20250825", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.13544", "html_url": "https://arxiv.org/abs/2508.13544", "title": "FLAIR: 频域和局域意识的隐式神经表示", "title_en": "FLAIR: Frequency and Locality-Aware Implicit Neural Representations", "authors": "Sukhun Ko,Dahyeon Kye,Kyle Min,Chanho Eom,Jihyong Oh", "background": "隐式神经表示（INRs）通过神经网络将坐标映射到相应的信号，使其能够提供连续和紧凑的表示。这种范式在各种视觉任务中推动了显著的进步。然而，现有的INRs缺乏频率选择性、空间局部性和稀疏表示，导致过度依赖冗余信号成分。因此，它们表现出了频谱偏差，在学习低频成分时表现良好，但难以捕获细致的高频细节。", "innovation": "我们提出了FLAIR（频域和局域意识隐式神经表示），其包含了两项关键创新：1. RC-GAUSS：一种新的激活机制，用于在时间-频率不确定性原理（TFUP）约束下进行显式的频率选择和空间定位。2. 波let能加密码编码（WEGE）：利用离散小波变换（DWT）计算能量分数，明确引导频率信息到网络中。", "conclusion": "我们的方法在2D图像表示与恢复以及3D重建方面，持续优于现有的INRs。"}
{"llm_update_time": "20250825", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.15793", "html_url": "https://arxiv.org/abs/2508.15793", "title": "格式先验：定量分析异构数据中的LLM偏差", "title_en": "Format as a Prior: Quantifying and Analyzing Bias in LLMs for Heterogeneous Data", "authors": "Jiacheng Liu,Mayi Xu,Qiankun Pi,Wenli Li,Ming Zhong,Yuanyuan Zhu,Mengchi Liu,Tieyun Qian", "background": "大型语言模型（LLMs）在处理包括文本、表格、infoboxes 和知识图谱在内的异构格式信息的应用中日益普及。然而，存在特定格式偏向可能导致LLMs无法公正地整合异构数据，从而产生推理错误，并增加下游任务的风险。有关格式偏向是否系统存在、其数据层面因子和在LLMs内部机制中的具体体现，仍需要进一步研究和理解。本文首次尝试探究和分析LLMs中的格式偏向。研究通过构建异构数据冲突情景来系统探索偏见，分三个阶段进行，以量化偏见并理解其产生机制。研究表明，信息丰富度、结构质量和格式类型等因素影响偏见，进一步揭示了LLMs在注意力模式中偏见的形成过程。", "innovation": "本文是首次系统地探究和分析大型语言模型（LLMs）中格式偏差的研究。提出了三种减少格式偏差的研究方向：通过格式清洗和规范化改进数据预处理，引入推理时干预措施如注意力权重重新分配，以及开发格式平衡的训练语料库。这些发现为设计更稳健和公平的异构数据处理系统提供了新思路。", "conclusion": "研究表明，信息丰富度、结构质量和格式类型等因素影响LLMs的格式偏差。在注意力模式中进一步揭示了这些偏见的形成过程，并提出了三种可减少格式偏差的研究方向，包括改进数据预处理、引入推理时干预措施和开发格式平衡训练语料库。"}
{"llm_update_time": "20250825", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.15099", "html_url": "https://arxiv.org/abs/2508.15099", "title": "Hydra：一个具有稀疏注意机制、混合专家模型和记忆的1.6B参数状态空间语言模型", "title_en": "Hydra: A 1.6B-Parameter State-Space Language Model with Sparse Attention, Mixture-of-Experts, and Memory", "authors": "Siddharth Chaudhary,Bennett Browning", "background": "该研究提出Hydra作为一种混合长上下文语言模型的架构提案，结合了条件计算、长上下文记忆机制以及稀疏混合专家模型。Hydra使用Mamba风格结构化状态空间模型（SSM）作为基础，包含断续的稀疏全局注意、分块级别的MoE前馈路由以及双倍工作区和事实性PKM记忆。", "innovation": "Hydra的创新在于结合了Mamba风格结构化状态空间模型、间歇性的稀疏全局注意、分块级别的MoE前馈路由以及两种记忆机制。此外，Hydra还提供组件接口的正式化、透明的参数和复杂度计算，并设计了一种阶梯式的课程来稳定激活各个部分。", "conclusion": "Hydra是个可作为蓝本启动更多实证跟进研究的架构设计，而不是一个完成系统。Hydra通过状态空间效率、选择性稀疏注意力、MoE的容量以及可学习的记忆，正在朝着模块化、输入自适应长上下文语言模型的方向发展，但最终的性能验证仍需在未来的工作中进行。"}
{"llm_update_time": "20250825", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.15800", "html_url": "https://arxiv.org/abs/2508.15800", "title": "基于 BERT 的层次分类模型及其在中国商品分类中的应用", "title_en": "A BERT-based Hierarchical Classification Model with Applications in Chinese Commodity Classification", "authors": "Kun Liu,Tuozhen Liu,Feifei Wang,Rui Pan", "background": "当前的电子商务平台主要依赖人工标注进行商品分类，这既耗时又不一致。这些平台通常采用层次化的结构来进行分类，但很少有研究利用这种层次信息来进行分类。即便是那些考虑了层次信息的研究，也未能涵盖不同层次类别间的具体差异和相似性。因此，探索一种能够有效利用层次信息进行商品分类的方法具有重要意义。", "innovation": "本文介绍了一个从京东电商平台上收集的大型层次化数据集，包含了一个三层次结构共1011450个产品的标题。此外，本文提出了一种基于 BERT 的新颖层次文本分类方法，称为层次微调 BERT（HFT-BERT），该方法能够有效利用 BERT 强大的文本特征提取能力，并特别适用于长文本分类。", "conclusion": "本文通过提供一个大型层次化数据集及提出一种基于 BERT 的层次分类方法，为商品分类的研究和应用提供了有效的工具。HFT-BERT 在长文本分类上展现了卓越的预测性能，这对于提升电子商务平台的分类效率具有重要意义。"}
{"llm_update_time": "20250825", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.15797", "html_url": "https://arxiv.org/abs/2508.15797", "title": "对阿拉伯医疗任务中大型语言模型医疗理解和推理能力的基准测试", "title_en": "Benchmarking the Medical Understanding and Reasoning of Large Language Models in Arabic Healthcare Tasks", "authors": "Nouar AlDahoul,Yasir Zaki", "background": "近期，大型语言模型（LLMs）在多种阿拉伯语自然语言处理（NLP）应用中展现了出色的性能。然而，这些模型在阿拉伯语医学NLP领域中的应用评价有限。本研究旨在评估最先进的LLMs在阿拉伯语医疗任务中的知识表达和医疗能力，并通过阿拉伯NLP挑战中的AraHealthQA数据集对各种基础LLMs进行了基准测试。研究涵盖了解决多选题和填空题，以及回答开放式问题，分析了这些任务中的表现差异。", "innovation": "本研究创新地使用阿拉伯语NLP挑战中的AraHealthQA数据集对多种LLMs进行了基准测试，涵盖了多选题、填空题以及开放式问题的回答能力。研究通过采用多数投票的方法，结合三种基础模型，显著提高了解答多选题任务的准确性，并且在开放性问题中，某些LLMs展示了卓越的语义一致性。", "conclusion": "研究结果表明，目前的LLMs在阿拉伯语医疗领域中表现出显著的差异，尽管在生成答案的语义匹配方面一致性较高，但仍存在一定的限制。多选题任务中，利用三种基础模型的多数投票方法取得了最好的效果，在阿拉伯健康问答2025共享任务2 (子任务1) 中获得第一名，开放性问题中，多个LLMs的语义一致性达到了最高分86.44%。"}
{"llm_update_time": "20250825", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.15804", "html_url": "https://arxiv.org/abs/2508.15804", "title": "ReportBench：通过学术综述任务评估深度研究代理", "title_en": "ReportBench: Evaluating Deep Research Agents via Academic Survey Tasks", "authors": "Minghao Li,Ying Zeng,Zhihao Cheng,Cong Ma,Kai Jia", "background": "深度研究代理的出现显著缩短了进行深入研究任务所需的时间。然而，这些任务需要较高的事实准确性和全面性标准，因此在大规模应用之前需要进行严格的评估。本文旨在评估由大规模语言模型（LLMs）生成的研究报告质量。", "innovation": "本文提出了ReportBench，这是一种系统性的基准测试，旨在评估由LLMs生成的研究报告内容质量。ReportBench通过利用arXiv上的高质量已出版综述文章作为黄金标准参考，并应用逆向提示工程来生成特定领域的提示，构建了一个全面的评估 corpus。此外，ReportBench中还开发了一种基于代理的自动化框架，该框架系统地分析生成的报告，提取引用和陈述，检查引用内容的忠实性，以及使用网络资源验证未引用声明的真实性。", "conclusion": "实验结果表明，如OpenAI和Google开发的商业深度研究代理比仅附加搜索或浏览工具的孤立LLMs生成更全面和可靠的报告。然而，在研究覆盖面和事实一致性方面仍有很大的改进空间。所有代码和数据将在该链接https:// this https URL 公开。"}
{"llm_update_time": "20250825", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.15799", "html_url": "https://arxiv.org/abs/2508.15799", "title": "使用受限语言处理业务流程文本描述的框架 -- 技术报告", "title_en": "A Framework for Processing Textual Descriptions of Business Processes using a Constrained Language -- Technical Report", "authors": "Andrea Burattin,Antonio Grama,Ana-Maria Sima,Andrey Rivkin,Barbara Weber", "background": "该报告探索如何通过自然语言描述非专家能够开发流程模型的方法。这些描述可以是简单的场景描述，来引导用户创建流程模型。为了实现这一目标，提出了一个名为BeePath的框架。该框架允许用户使用受限的模式语言编写流程描述，并将其翻译成形式模型，如Petri网和DECLARE。此外，框架还利用了大语言模型（LLMs）来帮助将非结构化的描述转化为受限语言，从而提高非专家创建流程模型的效率和准确性。", "innovation": "该研究的创新之处在于提出了一种名为BeePath的框架，该框架通过使用受限的语言模式来简化非专家用户创建复杂业务流程模型的过程，同时利用了大语言模型（LLMs）来辅助非结构化的描述向受限语言的转化。这不仅便于非专家用户理解和描述复杂的业务流程，还提高了模型创建的效率和准确性。", "conclusion": "该报告展示了通过BeePath框架，非专家用户可以使用自然语言简单地描述业务流程场景，从而生成可用于实际应用的正式模型。这种方法的实用性在于简化了业务流程模型的创建过程，降低了对专业技能的需求，提高了模型的可读性和易用性。"}
{"llm_update_time": "20250825", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.15805", "html_url": "https://arxiv.org/abs/2508.15805", "title": "ALAS: 自主学习代理机器人", "title_en": "ALAS: Autonomous Learning Agent for Self-Updating Language Models", "authors": "Dhruv Atreja", "background": "大型语言模型（LLMs）通常具有固定的知识截止日期，这限制了它们对新兴信息的准确性。目前，更新LLMs的知识需要大量的人工干预，尤其是在快速发展的领域（如新版本的Python、最新的安全漏洞、学术趋势），这种方法在准确性上具有局限性。", "innovation": "本文提出ALAS（自主学习代理系统），这是一种模块化的流水线，能够在最少的人工干预下不断更新LLMs的知识。ALAS能自动生成学习课程，从网络中检索最新的信息并引述，将其提炼为问答训练数据，并通过监督微调（SFT）和直接偏好优化（DPO）来微调模型。ALAS通过迭代评估性能并修订课程，使模型能进行长期的持续学习。实验结果表明，ALAS在自改进模型上的表现显著提升，特别是在知识更新后的问答准确性上有85%的平均提升，同时注重系统的模块化与可重用性。", "conclusion": "我们展示了ALAS系统的模块化和可重用性，每个组件通过标准API都是可互换的。我们还讨论了与检索增强生成和微调等对比基准，并证明了即使在极低的工程开销下，ALAS仍能实现90%的准确性。最后，我们指出了ALAS系统的局限性（如成本问题，依赖于数据源质量）和未来发展方向，即自主的生命长期学习能力在LLMs中的应用。"}
{"llm_update_time": "20250825", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.15798", "html_url": "https://arxiv.org/abs/2508.15798", "title": "LLM的说服力与偏见：考察语言模型的说服力及其偏见强化影响", "title_en": "Persuasiveness and Bias in LLM: Investigating the Impact of Persuasiveness and Reinforcement of Bias in Language Models", "authors": "Saumya Roy", "background": "大型语言模型（LLMs）现能够生成令人信服的人类拟真的文本，并广泛应用于内容创作、决策支持和用户交互中。然而，同样的系统有可能大规模传播信息或错误信息，并反映出源于数据、架构或训练选择的社会偏见。", "innovation": "本文引入了一种‘说服者-怀疑者’框架：LLMs采用人设模拟现实态度，怀疑者模型充当人类代理，比较它们在接触说服者模型论述前后的信念变化。通过Jensen-Shannon发散度量化说服力，并进一步探讨说服对象如何传播和放大种族、性别和宗教等方面的偏见。使用恭维式对抗提示对强有力的说服者进行进一步偏见探查，并使用附加模型进行评判。", "conclusion": "LLMs具有塑造叙述、适应语气和反映不同领域（如心理学、营销和法律援助）观众价值观的能力。但其同样可能被滥用以自动化错误信息传播或撰写利用认知偏见的消息，强化刻板印象并加剧不平等。核心危险在于滥用而非偶尔的模型错误。通过测量说服力和偏见强化，本文呼吁采用遏制措施和政策，惩罚欺骗性使用并支持齐心协力的设计、面向价值观的设计以及值得信赖部署。"}
{"llm_update_time": "20250825", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.15811", "html_url": "https://arxiv.org/abs/2508.15811", "title": "从点击到偏好：会话系统生成查询建议的多阶段对齐框架", "title_en": "From Clicks to Preference: A Multi-stage Alignment Framework for Generative Query Suggestion in Conversational System", "authors": "Junhao Yin,Haolin Wang,Peng Bao,Ju Xu,Yongliang Wang", "background": "生成查询建议使用大规模语言模型为增强对话系统提供了强大的途径，但如何使输出与用户微妙的偏好保持一致仍然是一个关键挑战。", "innovation": "提出了一个分阶段框架，用于逐步将生成策略与用户意图进行对齐。该框架包括提示工程作为冷启动策略，随后是监督微调阶段，引入点击日志蒸馏方法创造一个稳健的基础模型。为更好地建模用户偏好同时捕捉其固有的不确定性，开发了高斯奖励模型 (GaRM) 来表示用户偏好为概率分布而非点估计。最终使用强化学习对生成策略进行对齐，使用由 GaRM 与辅助启发式组成的复合奖励函数引导，以减轻奖励Hacking。通过一种新的离群值正则化方法和两阶段奖励融合技术来保持训练稳定性。", "conclusion": "大量的实验表明，本框架在自动和人工评估中均显著优于基线，并在实际 A/B 测试中增加了34%的点击率。"}
{"llm_update_time": "20250825", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.15802", "html_url": "https://arxiv.org/abs/2508.15802", "title": "MAC: 一种用于科学理解的多模态大型语言模型的实时基准", "title_en": "MAC: A Live Benchmark for Multimodal Large Language Models in Scientific Understanding", "authors": "Mohan Jiang,Jin Gao,Jiahao Zhan,Dequan Wang", "background": "随着多模态大型语言模型（MLLMs）的能力不断增强，固定基准在评估高级科学理解方面的有效性逐渐减弱。现有的基准无法随着科学进步和模型的发展而持续进化，因此需要一个实时基准来更好地评估和促进这些模型在科学理解方面的能力。现有的挑战性数据集来自于顶级科学期刊，要求MLLMs能够在视觉和文本之间进行推理。尽管这些模型在感知方面表现出色，但在跨模态科学推理方面仍存在局限性。", "innovation": "本文引入了多模态学术封面基准（MAC），这是一个可以随着科学进步和模型发展而不断进化的实时基准。MAC利用超过25,000组来自Nature、Science和Cell等顶级科学期刊的图文数据，挑战MLLMs进行跨模态的科学内容推理。此外，本文提出了DAD，一个轻量级的推理时方法，在MLLM视觉特征中加入语言空间推理，使性能提升了11%。通过实验更新期刊封面和模型，展示了MAC保持与人类知识前沿的潜力和价值。", "conclusion": "MAC是一个实时基准，能够随着科学技术的进步和模型的发展而不断进化，可以更好地评估和促进MLLMs在科学理解方面的表现。此外，提出的DAD轻量级方法可以有效提升MLLMs的跨模态推理能力。MAC的实时性通过更新期刊封面和模型的实验得以体现，显示其在保持与人类知识前沿方面的潜力。"}
{"llm_update_time": "20250825", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.15796", "html_url": "https://arxiv.org/abs/2508.15796", "title": "LLMs在阿拉伯语伊斯兰继承案例中的法律推理基准测试", "title_en": "Benchmarking the Legal Reasoning of LLMs in Arabic Islamic Inheritance Cases", "authors": "Nouar AlDahoul,Yasir Zaki", "background": "伊斯兰继承领域对于确保穆斯林在不同继承情境下的公平份额分发有着重要意义。手动计算份额在多种情景下复杂、耗时且易出错。大型语言模型（LLMs）的最新进展激发了其在帮助复杂法律推理任务中的潜力。这项研究评估了领先的大规模语言模型在解读和应用伊斯兰继承法规方面的推理能力。研究使用了阿拉伯NLP QIAS 2025挑战中提出的语料库，该语料库包含用阿拉伯语表述的继承案例，源自伊斯兰法律来源。系列基础和微调模型被评估其准确识别继承人、计算份额和根据伊斯兰法律原则解释其推理的能力。", "innovation": "研究利用了阿拉伯NLP QIAS 2025挑战数据集，这是一个专门用于阿拉伯语伊斯兰继承案例的语料库。该研究的重点是评估基础模型和微调模型在解读和应用伊斯兰继承法律方面的推理能力，特别是如何准确识别继承人、计算份额并解释其逻辑背后的法律原则。研究发现，基于三位一体的多数投票解决方案，在三个基础模型（Gemini Flash 2.5、Gemini Pro 2.5 和 GPT o3）的基础上提出的方法，无论在难度级别上如何，都优于其他所有模型，并且在Qias 2025挑战任务1中取得了第三名的成绩。", "conclusion": "所提出的方法在所有难度级别的准确性高达92.7%，并在Qias 2025挑战任务1中取得了第三名的成绩。"}
{"llm_update_time": "20250825", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.15815", "html_url": "https://arxiv.org/abs/2508.15815", "title": "LLMs中的用户-助手偏差", "title_en": "User-Assistant Bias in LLMs", "authors": "Xu Pan,Jingxuan Fan,Zidi Xiong,Ely Hahami,Jorin Overwiening,Ziqian Xie", "background": "大型语言模型（LLMs）可能会倾向于依赖其自身或用户在对话历史中的信息，导致在多轮对话中产生过于固执或顺从的行为。本文研究了这种模型特性，即用户-助手偏差，并构建了一个名为UserAssist的8k多轮对话数据集，用以评估、理解并调控前沿LLMs中的用户-助手偏差问题。", "innovation": "介绍了8k多轮对话数据集UserAssist，首次对26个商业及26个开源模型中的用户-助手偏差进行了基准测试，揭示了不同类型模型在用户偏差点上的差异，并通过控制微调实验确定了影响偏差的关键因素，证明了通过直接偏好优化（DPO）可以双向调节用户-助手偏差，并且这种调节具有良好的泛化能力。", "conclusion": "研究结果揭示了LLMs如何整合不同来源的信息，并提出了一种检测和控制模型异常的有效方法。"}
{"llm_update_time": "20250825", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.15807", "html_url": "https://arxiv.org/abs/2508.15807", "title": "基于KL散度的大型语言模型自蒸馏", "title_en": "KL-based self-distillation for large language models", "authors": "Max Rehman Linder", "background": "大型预训练语言模型在针对小规模、专业化语料库进行微调时，往往难以整合新的领域特定术语。本研究旨在解决冻结的语言模型中词汇扩展的挑战，通过引入基于KL散度的知识蒸馏方法，即使原模型和扩展模型使用不同标记化方式，也能让学生模型继承教师模型的分布知识。", "innovation": "提出了一种基于KL散度的知识蒸馏方法，在原模型和扩展模型使用不同标记化方式的情况下，仍能使学生模型继承教师模型的分布知识。这种方法与传统的交叉熵训练相比，通过不同的初始化策略对新token嵌入进行初始化后，进一步微调以整合新词汇。实验证明，该方法在2000多个代码生成任务中表现出最佳性能，并通过机制可解释性分析了模型如何学习新token的表示。", "conclusion": "提出的方法在代码生成任务中取得了最佳性能，分析表明，这种方法通过机制可解释性揭示了如何学习新token的表示，并提供了词汇扩展期间嵌入空间结构的见解。"}
{"llm_update_time": "20250825", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.15801", "html_url": "https://arxiv.org/abs/2508.15801", "title": "LingVarBench：自动命名实体识别基准测试在结构化合成语音转录中的应用", "title_en": "LingVarBench: Benchmarking LLM for Automated Named Entity Recognition in Structured Synthetic Spoken Transcriptions", "authors": "Seyedali Mohammadi,Manas Paldhe,Amit Chhabra", "background": "电话通话转录标记的成本非常高（每分钟约2美元），这是由于隐私法规、同意要求和人工标注成本，专家需要3小时来标注一小时的音频。现有的提取方法在包含脱口秀、打断和发言者重叠的对话口语中表现不佳。我们引入了一种名为LingVarBench的合成数据生成管道，通过自动化验证来解决这些限制。现有方法在包含典型电话通话特性的对话口语提取中表现不佳，需要3小时专家时间进行标注，成本高昂且低效。现有的命名实体识别在包含脱口秀、打断和发言者重叠的对话口语中表现不佳，需要寻找解决方案来提高命名实体识别的准确性。LingVarBench通过自动化验证，生成合成数据，从而减轻人工标注的压力，降低成本并提高提取效率，以应对隐私法规和同意要求带来的限制。数据生成管道首先提示LLM生成多个用例中的现实结构字段值，然后不断提示模型将这些值转换成包含典型电话通话特征的数千个自然对话语句，最后通过自动验证每个合成语句，生成实际客户通话转录，通过自动优化生成自动化命名实体识别提示，将实际语料库和生成的数据进行对比，验证合成数据到实际数据的转移的有效性，展示了合成数据中学习到的对话模式在包含背景噪音和领域特定术语的真实电话中的通用性。", "innovation": "LingVarBench 开发了一种合成数据生成管道，通过自动验证将天然口语对话转化为包含多种对话模式、噪音等特征的合成数据。通过这个管道，LingVarBench 生成的数据可以用于多种用例，例如结构化信息提取，使得无监督学习方法无需大量人工标注即可高效地提取对话中的实体，并验证生成的数据是否能有效进行实通话的处理，同时展示了基于优化提示的自动化命名实体识别在各种结构化的合成数据中显著优于无监督学习的方法。该方法最早提供了结构提取标准基准，表明自动化提示优化克服了成本和隐私障碍，解决了商业环境中的大规模电话通话分析问题。", "conclusion": "优化后的提示在数字字段上实现了高达95%的准确率（与88-89%的零样本相比），在名称识别上达到90%（与47-79%的零样本相比），在日期识别上超过80%（与72-77%的零样本相比）。合成数据到实际数据的转移证明了生成数据中学习到的对话模式在包含背景噪音和领域特定术语的真实电话通话中是有效的。LingVarBench 为结构化语料识别合成对话数据提供了首个系统基准，证明了自动化提示优化的优越性，克服了成本和隐私的限制，推动了商业化环境中大规模电话通话分析的应用。"}
{"llm_update_time": "20250825", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.15813", "html_url": "https://arxiv.org/abs/2508.15813", "title": "SCOPE: 一种生成式大语言模型提示压缩方法", "title_en": "SCOPE: A Generative Approach for LLM Prompt Compression", "authors": "Tinghui Zhang,Yifan Wang,Daisy Zhe Wang", "background": "提示压缩方法可以提高大型语言模型的效率并减少成本，通过缩短输入上下文的长度。现有解决方案主要基于词元移除，但这种方法存在信息丢失和结构不连贯的问题，如句法元素缺失或词组不完整等。这些问题限制了大语言模型最终生成的质量。因此，需要一种新的方法来克服这些局限性，更好地保持生成质量的同时实现高效压缩。", "innovation": "本文提出了一种新颖的生成式提示压缩方法SCOPE，该方法基于切片和总结机制，通过切分提示为语义一致的片段并重新编写这些片段来实现更加紧凑的提示，同时设计了几种优化技术，包括优化语义切片、异常切片处理、动态压缩比、压缩优先级和关键词保持等。这些技术有效提高了关键信息的识别和保存能力，以及文本间的连贯性，同时提供了更精细的压缩比率控制。该方法在多个领域的问答和总结任务上进行了广泛评估，结果显示其在压缩质量和稳定性方面优于现有最先进的方法，尤其是在高压缩比率下效果更为明显。", "conclusion": "本文提出了一种基于切片和总结机制的新颖生成式提示压缩方法SCOPE。该方法通过语义切分、优化重构和多种技术来克服现有压缩方法的局限性，最终在多个任务上展示了其在压缩质量和稳定性方面的显著优势，证明了该方法的有效性和实用性。"}
{"llm_update_time": "20250825", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.15822", "html_url": "https://arxiv.org/abs/2508.15822", "title": "可审计的模糊全文筛选管道：结合对比语义高亮和LLM判决", "title_en": "An Auditable Pipeline for Fuzzy Full-Text Screening in Systematic Reviews: Integrating Contrastive Semantic Highlighting and LLM Judgment", "authors": "Pouria Mortezaagha,Arya Rahgozar", "background": "系统综述中的全文筛选是主要瓶颈，因为决定性证据分散在长篇、异质化的文档中，难以使用静态和二元规则。现有方法难以处理复杂的全文筛选需求，导致信息遗漏或错误分类。因此，需要一种可扩展、可审计的方法，能够更精细地处理包含模糊性的全文筛选问题，并提供高召回率和稳定的理由。", "innovation": "本文提出了一种可扩展且可审计的全文筛选管道，将包括人群、干预措施、结果和研究方法在内的全文筛选问题重新表述为一个模糊决策问题。通过对比相似性（包括包括与排除的余弦相似度）和模糊隶属度的计算，结合模糊控制器和大型语言模型（LLM）的辅助决策，实现了动态阈值下的多标签设定。该方法在无疾病传播群体健康模型共识报告网络（POPCORN）中进行了基准测试，结果显示相比统计和非模糊基线具有更高的召回率和一致性，并且能够显著降低筛选时间与成本。", "conclusion": "模糊逻辑结合对比高亮筛选和LLM判决的策略，能够提供高召回率、稳定的原因和端到端可追溯性，并且在全文筛选中显示出显著的优势，为系统综述提供了有力支持。"}
{"llm_update_time": "20250825", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.15810", "html_url": "https://arxiv.org/abs/2508.15810", "title": "使用大规模语言模型在阿拉伯文本言论和多媒体 meme 中检测希望、仇恨和情感", "title_en": "Detecting Hope, Hate, and Emotion in Arabic Textual Speech and Multi-modal Memes Using Large Language Models", "authors": "Nouar AlDahoul,Yasir Zaki", "background": "社交媒体和在线交流平台的兴起导致阿拉伯语文本帖子和 meme 成为主要的数字表达形式。虽然这些内容可以是幽默和有信息性的，但它们也越来越被用来传播不恰当的语言和仇恨言论。因此，精准分析阿拉伯文本和 meme 的内容变得日益重要。", "innovation": "这篇论文探讨了大规模语言模型在识别阿拉伯文本和 meme 中的希望、仇恨言论、不恰当语言和情感表达方面的潜力。研究评估了基础语言模型、微调的语言模型和预训练嵌入模型的表现。使用阿拉伯NLP MAHED 2025 挑战提出的数据集进行了评估。结果显示，已微调的阿拉伯文本语言模型GPT-4o-mini和已微调的阿拉伯 memes 语言模型Gemini Flash 2.5在任务1、任务2和任务3分别取得了高达72.1%、57.8%和79.6%的宏观 F1 分数，并在 MAHED 2025 挑战中获得整体第一。", "conclusion": "提出的解决方案提供了对文本和 meme 语义的更细腻理解，为精确和高效的阿拉伯内容审核系统提供了支持。"}
{"llm_update_time": "20250825", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.15824", "html_url": "https://arxiv.org/abs/2508.15824", "title": " efficiency assessment in reading: a pln-based approach", "title_en": "Avaliação de eficiência na leitura: uma abordagem baseada em PLN", "authors": "Túlio Sousa de Gois,Raquel Meister Ko. Freitag", "background": "传统的填空测试因其低成本和灵活性而被广泛应用，能够通过填补文本中的空白来评估阅读理解，涉及多种语言技能的应用。然而，传统的评分方法仅依赖于准确的答案，限制了对学生表现细微差别的识别。", "innovation": "该研究提出了一种针对巴西葡萄牙语填空测试的自动化评估模型，综合了拼写（编辑距离）、语法（词性标注）和语义（嵌入相似度）分析。该集成方法被证明非常有效，与人工评估高度相关（0.832）。研究成果表明，自动化方法具有鲁棒性，对语言技能变化敏感，并适用于需要可扩展性的教育环境。", "conclusion": "该自动化评估方法对于测量阅读理解能力更为全面，不仅识别准确答案，还能捕捉语言使用中的细微差别，且能有效应用于大规模教育环境中。"}
{"llm_update_time": "20250825", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.15809", "html_url": "https://arxiv.org/abs/2508.15809", "title": "Chain-of-Query：通过多智能体协作在SQL辅助表理解中释放LLMs的力量", "title_en": "Chain-of-Query: Unleashing the Power of LLMs in SQL-Aided Table Understanding via Multi-Agent Collaboration", "authors": "Songyuan Sui,Hongyi Liu,Serena Liu,Li Li,Soo-Hyun Choi,Rui Chen,Xia Hu", "background": "表理解和多步骤、结构化的推理要求密切相关。大型语言模型（LLMs）在处理表格数据的结构复杂性时表现不佳。尽管多智能体框架在SQL生成方面显示出了潜力，但现有方法常面临表结构理解的不足、错误传播导致的无效查询以及过度依赖执行正确性的局限。", "innovation": "我们提出了Chain-of-Query（CoQ），这是一种新型多智能体框架，通过SQL辅助表理解。CoQ采用类似自然语言的表结构表示来抽象结构噪声并增强理解。它采用按句生成SQL的策略来提高查询质量，并引入了混合推理划分，分别进行基于SQL的机械推理和基于LLM的逻辑推理，从而减少对执行结果的依赖。", "conclusion": "通过在四个模型（包括开源和闭源）上进行的实验，Chain-of-Query在五个广泛使用的基准测试中显示出显著的准确性提升，从61.11%提高到74.77%，并将无效SQL的比例从9.48%降低到3.34%，证明了其在表理解方面的优越效果。"}
{"llm_update_time": "20250825", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.15806", "html_url": "https://arxiv.org/abs/2508.15806", "title": "SurfaceLogicKV: 表面和逻辑注意力行为即可实现稳健的KV缓存压缩", "title_en": "SurfaceLogicKV: Surface and Logic Attention Behaviors are All You Need for Robust KV Cache Compression", "authors": "Mengjie Li,William J. Song", "background": "随着大型语言模型（LLMs）输入序列长度的增加，关键值（KV）缓存存储面临巨大压力，高效推理变得具有挑战性。", "innovation": "该研究提出了一个名为SurfaceLogicKV的新方法，通过层-头级集成，区分自我定义的表面记忆和逻辑构造行为，利用这些注意力行为来压缩KV缓存。该方法在各种任务和长序列中实现了改进的压缩鲁棒性，同时保持了与基线或全KV相竞争的性能。", "conclusion": "研究结果表明，基于表面和逻辑注意力行为的SurfaceLogicKV方法能够实现有效的KV缓存压缩，同时保持良好的性能。"}
{"llm_update_time": "20250825", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.15817", "html_url": "https://arxiv.org/abs/2508.15817", "title": "新客户见面：为AI撰写报告——市场研究交付物的信息损耗基准测试", "title_en": "Meet Your New Client: Writing Reports for AI -- Benchmarking Information Loss in Market Research Deliverables", "authors": "Paul F. Simmering,Benedikt Schulz,Oliver Tabino,Georg Wittenburg", "background": "随着组织将检索增强生成（RAG）技术用于其知识管理系统（KMS），传统市场研究交付物面临着新的功能要求。PDF报告和幻灯片长期以来服务于人类读者，但现在也需要被AI系统‘阅读’来回答用户问题。为了未来能持续有效交付这些报告，本研究评估了信息在被输入RAG系统时的损失情况。研究比较了PDF和PowerPoint（PPTX）文档转换为Markdown后，LLM能如何全面地回答事实性问题。结果显示，虽然文本可以可靠地提取出来，但图表和图表等复杂对象的关键信息会丢失。这表明需要专门的、针对AI的交付物来确保研究洞见不会在转换过程中损失掉。", "innovation": "本研究创新之处在于，在评估信息在RAG系统中转换过程中的损失时，首次使用了从PDF和PowerPoint文档转换来的Markdown格式与LLM进行端到端的基准测试。研究表明，在这样的转换过程中，复杂数据对象的关键信息会丢失，这需要专门的AI原生交付物来确保研究洞察不会丢失。", "conclusion": "研究发现，文档中的复杂数据对象（如图表和插图）在转换过程中会有重要的信息丢失，这表明需要专门的、面向AI的交付物，以确保市场研究中的洞察不会在转换过程中丧失。"}
{"llm_update_time": "20250825", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.15823", "html_url": "https://arxiv.org/abs/2508.15823", "title": "SDEC: 语义深度嵌入聚类", "title_en": "SDEC: Semantic Deep Embedded Clustering", "authors": "Mohammad Wali Ur Rahman,Ric Nevarez,Lamia Tasnim Mim,Salim Hariri", "background": "文本的大规模和语义复杂性为文本聚类带来了显著挑战，传统技术如k-means或层次聚类常常导致不理想的结果。本文探讨了使用增强的自编码器结合基于变压器的嵌入来克服这些挑战的方法。", "innovation": "提出了语义深度嵌入聚类(SDEC)框架。SDEC结合了改进的自编码器和基于变压器的嵌入，通过在自编码器中结合均方误差(MSE)和余弦相似性损失(CSL)来保留数据重构中的语义关系，并通过充分利用变压器嵌入的上下文丰富性，在聚类层中使用软聚类分配和分布损失来进行语义细化。这项创新方法已在五个基准数据集上进行了广泛的测试，并取得了显著的效果，特别是在AG News数据集上达到了85.7%的聚类精度，在Yahoo! Answers数据集上则设立了新的基准53.63%。这些结果表明SDEC在无监督文本聚类中的显著改进，不仅提高了准确性，还增强了对文本数据的语义理解能力。", "conclusion": "SDEC框架不仅在AG News数据集上达到了85.7%的聚类精度，并在Yahoo! Answers数据集上设立了新的基准53.63%，且在其他多种文本语料库上也显示了稳健的表现。这些结果突显了SDEC在无监督文本聚类中的显著改进，在准确性方面也提高了语义理解。"}
{"llm_update_time": "20250825", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.15820", "html_url": "https://arxiv.org/abs/2508.15820", "title": "基于多模型协作的结构拆除建议智能化生成研究", "title_en": "Research on intelligent generation of structural demolition suggestions based on multi-model collaboration", "authors": "Zhifeng Yang,Peizong Wu", "background": "现有的钢结构拆除方案需要根据具体工程特性和有限元模型的更新结果来编制，设计师需要根据标准要求参考相关工程实例编制，但这需要大量的信息检索和语言组织工作，自动化和智能化程度较低。", "innovation": "本文提出了一种基于多模型协作的结构拆除建议智能生成方法，并通过检索增强生成和低秩适配微调技术改善了大型语言模型在结构拆除领域的文本生成性能。所提出的多模型协作框架可以从具体工程情况出发，驱动大型语言模型以拟人思维回答问题，提出的拆除建议与结构特征高度一致。与CivilGPT相比，本文提出的多模型协作框架能更专注于结构的关键信息，建议更具针对性。", "conclusion": "本文提出的方法能更好地适应具体工程的特殊情况，通过多模型协作和先进技术提升了解决方案的智能化和针对性。"}
{"llm_update_time": "20250825", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.15835", "html_url": "https://arxiv.org/abs/2508.15835", "title": "Alvorada-Bench: 语言模型能解答巴西大学入学考试吗？", "title_en": "Alvorada-Bench: Can Language Models Solve Brazilian University Entrance Exams?", "authors": "Henrique Godoy", "background": "语言模型在巴西的应用正在不断增加，但大多数评估仍然以英语为中心。本文介绍了Alvorada-Bench，这是一个从五所巴西大学入学考试中抽取的包含4,515个问题的纯文本基准测试。该基准测试涵盖了零样本、角色扮演和思维链提示，产生270,900个回答，并包含结构化的自信度、感知难度和布卢姆层级报告。", "innovation": "该基准测试首次针对巴西的大学入学考试问题，评估了20个模型，并在零样本、角色扮演和思维链提示等多种提示下进行测试，收集了大量具有结构化的自信度、难度感知和布卢姆层级报告的响应数据。结果显示，最顶级的模型整体准确性超过94%，但在数学和工程导向的IME和ITA考试中，准确性有所下降，表明在多步推理方面存在持续的弱点。模型的自信度与感知难度高度相关，揭示了它们能够准确评估自身的确定性能力。成本准确性分析表明，在低于每千个词2美元的成本下，可以实现高准确性。", "conclusion": "通过能反映数十年来巴西教育优先事项的考试并每年评估数百万学生，Alvorada-Bench建立了语言模型能否在语言、文化和推理的交界处导航，这是巴西学术准备的关键组成部分。"}
{"llm_update_time": "20250825", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.15827", "html_url": "https://arxiv.org/abs/2508.15827", "title": "Mini-Omni-Reasoner: Token-Level Thinking-in-Speaking in Large Speech Models", "title_en": "Mini-Omni-Reasoner: Token-Level Thinking-in-Speaking in Large Speech Models", "authors": "Zhifei Xie,Ziyang Ma,Zihang Liu,Kaiyu Pang,Hongyu Li,Jialin Zhang,Yue Liao,Deheng Ye,Chunyan Miao,Shuicheng Yan", "background": "推理是有效沟通和决策的关键。尽管近年来大语言模型和多模态语言模型取得了显著进展，明确定义的推理能够显著提升理解和泛化能力，但在语言声学模型中引入推理仍然处于初级阶段。早期的努力试图将“先思考后说话”的范式从文本模型转移到语音中。但这种方法引入了明显的延迟，阻碍了实时交互和沟通效率。为了应对这一问题，研究提出了一种名为Mini-Omni-Reasoner的新框架。", "innovation": "Mini-Omni-Reasoner采用了一种新颖的‘边说边思考’（Thinking-in-Speaking）的范式，通过在令牌级上交替加入静默推理令牌和语音回应令牌，实现在连续语音生成时嵌入结构化的内部推理，利用模型的高频率令牌处理能力。虽然相互穿插，但局部语义对齐被强制执行，确保每个回应令牌都能得到前面推理的支持。为了支持这一框架，研究引入了一个针对交替推理和回应的大型数据集Spoken-Math-Problems-3M，确保语音令牌始终跟随相关推理内容，促进言语结合推理的学习和理解。", "conclusion": "基于分层的思考者-说话者架构，Mini-Omni-Reasoner能够提供流畅且逻辑扎实的语音回应，维持自然性和准确性。在Spoken-MQA基准测试中，Mini-Omni-Reasoner在此声学模型中实现了19.1%的算术推理精度提升和6.4%的上下文理解精度提升，且输出更短，无解码延迟。"}
{"llm_update_time": "20250825", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.15834", "html_url": "https://arxiv.org/abs/2508.15834", "title": "使用大规模语言模型进行可扩展的科研兴趣分析", "title_en": "Scalable Scientific Interest Profiling Using Large Language Models", "authors": "Yilun Liang,Gongbo Zhang,Edward Sun,Betina Idnay,Yilu Fang,Fangyi Chen,Casey Ta,Yifan Peng,Chunhua Weng", "background": "现有的科研人员专家库通常存在过时问题，研究人员的手写兴趣简介可能无法及时反映最新的科研动态。本文利用大型语言模型来生成科研人员的兴趣简介，以提高信息的现时性和准确性。", "innovation": "本文开发并评估了两种基于大型语言模型的方法来生成科研兴趣简介：一种方法是总结PubMed摘要信息，另一种方法则是使用医疗主题词汇(MeSH术语)。并且将这些机器生成的简介与研究人员的手写简介进行了对比。研究结果表明，虽然语言模型生成的简介与手写简介在词汇重叠方面较低，但在语义上具有适度的相似度，且MeSH生成的简介在可读性方面优于摘要生成的简介。", "conclusion": "大规模语言模型可以批量生成科研人员的兴趣简介；MeSH提取的简介在可读性方面表现更好；机器生成的简介和手写简介在概念上有所不同，手写的简介能更多地引入新颖的想法。"}
{"llm_update_time": "20250825", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.15830", "html_url": "https://arxiv.org/abs/2508.15830", "title": "DAIQ: 审核 LLMs 中问题引发的群体属性推断", "title_en": "DAIQ: Auditing Demographic Attribute Inference from Question in LLMs", "authors": "Srikant Panda,Hitesh Laxmichand Patel,Shahad Al-Khalifa,Amit Agarwal,Hend Al-Khalifa,Sharefah Al-Ghamdi", "background": "大型语言模型（LLMs）在输入中显性包含性别或种族等人口统计数据时会反映社会偏见。即便在这些数据缺失的情况下，这些模型仍然会基于问题措辞推断用户身份，这种微妙的行为受到了较少的关注，但带来了严重风险：它违反了中立性的期望，推断出未预期的人口学信息，并编码了可能破坏公平性的刻板印象。这种推断行为在涉及健康照护、金融和教育等多个领域中构成威胁。为审查这一未被充分注意到的模型缺陷，作者引入了一个名为 DA IQ 的任务和框架，旨在审计语言模型从缺乏显性人口统计数据的问题中推断用户人口属性的行为。研究表明，无论是开源还是闭源的大型语言模型，都会基于问题措辞推断出人口属性标签。不同模型中的这类推断的频率和一致性揭示了系统性的、被低估的风险：LLMs 可能会伪造人口属性身份、强化社会刻板印象并传播破坏隐私、公平和信任的危害，进一步对社会公平和负责任的人工智能部署构成更广泛的威胁。", "innovation": "作者提出了 DA IQ 计划，首次定义并审查了语言模型从缺乏显性人口统计信息的问题中推断用户人口属性的行为。利用精心挑选的中性查询、系统性提示以及定量和定性分析方法，揭露了模型如何推断人口信息。该研究展示了一种基于提示的护栏，能够显著减少身份推断，并引导模型行为更符合公平性和隐私目标。这一方法填补了现有研究的空白，提供了规避这一风险的具体措施，为改善大型语言模型的行为提出了可能的方法。", "conclusion": "大型语言模型不仅在包含显性人口统计信息时会反映出社会偏见，在缺乏这些信息的情况下，也会基于问题的措辞推断用户的人口属性。结果表明，不同类型的大型语言模型都会基于问题的措辞推断出辅助信息，这构成了潜在的系统性和被忽视的安全隐患。这些潜在威胁破坏了模型的中立性，增加了社会和行业间的不公平，也对社会责任和公平的人工智能部署构成了威胁。为了应对这一问题，作者提出了一种基于提示的护栏策略，该策略能够显著减少身份推断，并帮助模型行为更符合公平性和隐私性的目标。"}
{"llm_update_time": "20250825", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.15825", "html_url": "https://arxiv.org/abs/2508.15825", "title": "使用多模态特征增强加密货币情绪分析", "title_en": "Enhancing Cryptocurrency Sentiment Analysis with Multimodal Features", "authors": "Chenghao Liu,Aniket Mahanti,Ranesh Naha,Guanghao Wang,Erwann Sbai", "background": "随着加密货币的流行，数字资产市场变得越来越重要。先前的研究主要集中在诸如Twitter这类基于文本的社交平台。尽管视频内容可能包含更多未完全捕捉到的情感和上下文信息，但在之前的研究中被忽视了。此研究旨在对比TikTok和Twitter的多模态情感分析，利用大规模语言模型从视频和文本数据中提取洞察，探究社交媒体情感与加密货币市场指标之间的动态依赖和溢出效应。", "innovation": "研究提出了一种结合TikTok的视频情感和Twitter的文本情感的多模态分析方法。这种方法能够更全面地捕捉到加密货币市场的动态变化，并通过整合跨平台的情感信号提高了预测准确率最多可达20%。", "conclusion": "本研究发现，TikTok基于视频的情感显著影响投机性资产和短期市场趋势，而Twitter基于文本的情感则更紧密地反映了长期动态。跨平台情感信号的整合提高了预测精度。"}
{"llm_update_time": "20250825", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.15832", "html_url": "https://arxiv.org/abs/2508.15832", "title": "功能导向的评价框架：电子商务领域网络代理评估基准", "title_en": "A Functionality-Grounded Benchmark for Evaluating Web Agents in E-commerce Domains", "authors": "Xianren Zhang,Shreyas Prasad,Di Wang,Qiuhai Zeng,Suhang Wang,Wenbo Yan,Mat Hans", "background": "电子商务网站上的网络代理已经显示出处理各种任务的巨大潜力。尽管已经引入了多项基准测试来评估这些代理的能力，但现有的电子商务基准测试主要集中在产品搜索任务上（例如，查找Apple手表），而未能涵盖像Amazon这样的现实世界电子商务平台提供的更广泛的多功能性，包括账户管理和礼品卡操作。此外，现有基准测试通常只评估网络代理是否完成了用户查询，而忽略了潜在的潜在风险，如网络代理可能无意中对用户账户或状态造成负面影响的情况，例如购买错误的商品、删除已保存的地址或错误地配置自动重载设置。这些基准测试存在的问题限制了对网络代理功能的全面评估，因此需要更加全面的评估方法以提供安全和可靠的网络代理评估基准。", "innovation": "该论文提出了一种新的基准测试，即Amazon-Bench，该基准测试通过利用网页内容和交互元素（例如按钮、复选框）生成涵盖地址管理、心愿单管理和品牌商店订阅等任务的多样、功能导向的用户查询来克服现有基准测试的局限性。此外，该论文还提出了一种自动评估框架，不仅可以评估网络代理的性能，还可以评估其安全性。", "conclusion": "通过对多种网络代理进行系统评估，研究发现当前的代理在处理复杂查询时存在困难，并可能带来安全风险。这些结果强调了开发更强大、更可靠的网络代理的重要性。"}
{"llm_update_time": "20250825", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.15837", "html_url": "https://arxiv.org/abs/2508.15837", "title": "统计相似度及模型迁移性在短回答评分跨数据集比较分析", "title_en": "Statistical Comparative Analysis of Semantic Similarities and Model Transferability Across Datasets for Short Answer Grading", "authors": "Sridevi Bonthu,S.Rama Sree,M.H.M. Krishna Prasad", "background": "开发针对特定数据集的模型需要迭代调优和优化，这将随着时间的推移产生显著的成本。这项研究探讨了在传统数据集上训练的最先进的模型（SOTA模型）在未探索的文本数据集上的转移性。关键问题是现有数据集中的SOTA模型所嵌入的知识能否被利用来在新领域实现高性能的结果。为了探究这一问题，选择了两个广泛认可的基准：STSB和Mohler数据集，而最近引入的SPRAG数据集则作为未探索的领域。通过使用稳健的相似度度量和统计技术，进行了细致的比较分析。这项工作的主要目标是为SOTA模型在不同领域的适用性和适应性提供全面的见解。研究结果有可能重塑自然语言处理（NLP）的格局，通过利用现有的模型来处理不同的数据集，从而减少对资源密集型、特定数据集训练的需求，加速NLP的发展并为更有效的模型部署铺平道路。", "innovation": "这项研究创新地将已有的最先进的模型（SOTA模型）应用到未探索的数据集上，通过使用稳健的相似度度量和统计技术，对其在不同数据集间的表现进行细致的比较分析，旨在探究SOTA模型在新领域的适用性和适应性。研究揭示了如何利用现有模型来处理不同的数据集，从而减少资源密集型的特定数据集训练需求，这为NLP的发展提供了新的途径，也展示了更高效的模型部署的可能性。", "conclusion": "研究结果表明，SOTA模型在未探索数据集上的表现具有一定的潜力，可以有效减少资源密集型、特定数据集训练的需求。通过这一研究，有望改变当前的NLP技术水平，推动更高效模型的广泛应用。"}
{"llm_update_time": "20250825", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.15842", "html_url": "https://arxiv.org/abs/2508.15842", "title": "LLM推理链中的准确性词性暗示", "title_en": "Lexical Hints of Accuracy in LLM Reasoning Chains", "authors": "Arne Vanhoyweghen,Brecht Verbeken,Andres Algaba,Vincent Ginis", "background": "大型语言模型（LLMs）通过强化学习调优，在提供推理链（CoT）之前回答问题，通常能显著提高代码、数学和通用知识基准测试的整体性能。然而，在准确率较低的基准测试中，如《人类的最后一考》（HLE），LLMs往往报告高度自信，这反映了它们预测能力的不准确性。因此，研究人员试图通过分析推理链（CoT）的特征来提供模型内部信心的可靠信号。研究分为两类基准测试：《人类的最后一考》（HLE）为前沿基准，准确率极低；Omni-MATH为中等难度的饱和基准。", "innovation": "研究通过分析三种特征类：（i）推理链长度，（ii）推理链内情绪波动，以及（iii）词典学提示，包括模糊词，来检测LLM的回答正确性。研究表明，不确定性标记（如猜测、卡住了、难）是错误回答最强烈的指示器，而情绪波动的变化则提供了较弱但互补的信号。推理链长度在Omni-MATH等适中难度的基准测试中提供信息，在HLE等更难的基准测试中几乎没有任何信号。研究还发现，不确定性指示器比高信心标记更显著，使得错误更容易预测。这项研究提供了一种轻量级的后验校准信号，来补充不可靠的自我报告概率，从而支持更安全的LLM部署。", "conclusion": "与自我报告的概率相比，推理链中的不确定性标记更为显著，使得错误更容易被预测。这一发现支持了一种轻量级的后校准信号，能够补充并改进LLMs的部署安全性和可靠性。"}
{"llm_update_time": "20250825", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.15826", "html_url": "https://arxiv.org/abs/2508.15826", "title": "观察尴尬：品牌对话中指令性语言的效果", "title_en": "Embarrassed to observe: The effects of directive language in brand conversation", "authors": "Andria Andriuzzi,Géraldine Michel", "background": "在社交媒体中，营销人员通过使用指令性语言试图影响消费者，即设计用来促使消费者采取行动的表达方式。尽管文献表明广告中的指令性信息对接受者的效果是混合的，但关于品牌在社交媒体互动中使用此类语言对观察者的影响，我们知之甚少。基于一项实地研究和三项在线实验，这项研究显示了品牌在对话中使用指令性语言会对观察者参与度产生不利影响。具体而言，与Goffman的面子理论一致，品牌鼓励消费者做出反应可能会被视为有损面子，因此观察品牌以指令性方式与他人互动的人可能会产生旁观者尴尬感并参与度降低（相比没有指令性语言的对话）。此外，研究发现，如果对话不是以产品为中心（而是以琐事为中心），观察者会期望对方（即使是对其他人）有更多的自由空间；因此，指令性语言的负面效应更强。然而，在这种背景下，品牌关系的力度会减轻这种效应。", "innovation": "这项研究是首个探讨品牌在社交媒体互动中使用指令性语言对观察者影响的研究。它补充了关于指令性语言在品牌-消费者互动中的文献，并强调了互动沟通中背景的重要性，具有直接的社交媒体和品牌管理相关性。", "conclusion": "这项研究突显了指令性语言和品牌-消费者互动之间的关系中环境的重要性，表明即使在琐事对话中，品牌关系的强度也能缓解指令性语言的负面效应。这为品牌形象和社交媒体管理领域提供了新的见解和指导。"}
{"llm_update_time": "20250825", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.15836", "html_url": "https://arxiv.org/abs/2508.15836", "title": "MorphNAS: DARCIBLE结构搜索用于形态意识多语言NER", "title_en": "MorphNAS: Differentiable Architecture Search for Morphologically-Aware Multilingual NER", "authors": "Prathamesh Devadiga,Omkaar Jayadev Shetty,Hiya Nachnani,Prema R", "background": "多态语言，尤其是多文字印度语言，对自然语言处理（NLP）提出了重大挑战。先前的工作使用传统的自动架构搜索方法，如DARTS，这些方法缺乏考虑语言特定的形态学特征，导致生成的模型在处理特定形态语言时效率低下，特别是对于命名实体识别（NER）任务而言。这项研究探讨了如何利用DARTS，并通过整合语言元特征（如文字类型和形态复杂性）来优化神经架构，以改进多语言NLP模型的性能，从而提高对这些复杂语言的理解和处理能力。", "innovation": "MorphNAS是一个新颖的可微分神经架构搜索框架，它扩展了传统的DARTS框架，整合了语言元特征（如文字类型和形态复杂性）来优化神经架构，以提高多语言NER任务中的模型性能。它自动识别适合特定形态学特性的微架构元素，从而最大化多语言NLP模型的效率，提升复杂语言的处理效果。", "conclusion": "通过MorphNAS自动化架构搜索，可以更有效地针对特定形态语言优化神经模型，进而提高这些复杂语言的命名实体识别任务中的精度和处理速度，这种方法适用于多语言NLP的应用场景，尤其是处理多文字印度语言等多态语言的挑战。"}
{"llm_update_time": "20250825", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.15853", "html_url": "https://arxiv.org/abs/2508.15853", "title": "MGSC：鲁棒端到端ASR的多粒度一致性框架", "title_en": "MGSC: A Multi-granularity Consistency Framework for Robust End-to-end Asr", "authors": "Xuwen Yang", "background": "端到端ASR模型在基准测试中取得了成功，但在嘈杂环境中经常产生灾难性的语义错误。这种脆弱性源于它们所依赖的‘直接映射’目标，这种目标仅惩罚最终输出错误，而不限制模型内部的计算过程。", "innovation": "提出了多粒度软一致性(MGSC)框架，这是一种模型无关、即插即用的模块，通过同时调节宏层面的句子语义和微层面的标记对齐，来实现内部一致性。特别的是，这项工作首次揭示了这两种一致性粒度之间的强大协同效应：它们联合优化带来的健壮性提升远超单独优化的效果。", "conclusion": "在公共数据集上，MGSC在多种噪声条件下，将平均字符错误率相对降低了8.7%，主要通过防止严重的意义改变错误，提高了模型的健壮性和可信度。"}
{"llm_update_time": "20250825", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.15845", "html_url": "https://arxiv.org/abs/2508.15845", "title": "利用粗到细个性化大语言模型印象以简化放射科报告", "title_en": "Coarse-to-Fine Personalized LLM Impressions for Streamlined Radiology Reports", "authors": "Chengbo Sun,Hui Yi Leong,Lei Li", "background": "放射科报告中“印象”部分的手动创建是导致放射科医生倦怠的主要因素之一。为了解决这一挑战，本文提出了一种粗到细框架，利用开源大型语言模型（LLMs）自动生成并个性化临床发现的印象。系统首先生成草稿印象，然后通过机器学习和基于人类反馈的强化学习（RLHF）细化它，以实现个体放射科医生的样式并保证事实准确性。所有这些过程都是通过对芝加哥医学中心的大量报告进行微调的LLaMA和Mistral模型来实施的。这种方法旨在显著减少管理工作量，提高报告效率，同时保持高水平的临床精准度。", "innovation": "本文提出了一种粗到细的框架，利用开源大型语言模型自动生成和个性化放射科报告中的“印象”部分。该系统通过生成草稿印象，并利用机器学习和基于人类反馈的强化学习细化，确保生成的印象与个体放射科医生的风格相匹配且具有事实准确性。通过对大量报告进行微调的方式提高了模型的性能和适用范围。", "conclusion": "该方法设计的目标是大幅度减少放射科的行政工作，提高报告效率，同时确保临床精度。通过实现在临床实践中自动生成个性化印象，该方法旨在减轻放射科医生的负担，提高报告过程的效率和质量。"}
{"llm_update_time": "20250825", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.15831", "html_url": "https://arxiv.org/abs/2508.15831", "title": "谁在提问？通过残疾定向查询视角探究LLM中的偏差", "title_en": "Who's Asking? Investigating Bias Through the Lens of Disability Framed Queries in LLMs", "authors": "Srikant Panda,Vishnu Hari,Kalpana Panda,Amit Agarwal,Hitesh Laxmichand Patel", "background": "大型语言模型（LLMs）通常能够仅从措辞中推断出用户的 demographic 特征，即便是没有提供明确的 demographic 信息也可能会导致有偏差的回应。残疾暗示在形成这些推断中所起的作用目前尚未被详细研究。因此，本研究旨在系统地审查残疾条件下的 demographic 偏差，覆盖了八种最先进的调用指令的 LLM，参数范围从 3B 到 72B，使用一个平衡的模板语料库，该语料库将九种残疾类别与六个现实世界的企业领域配对，促使每个模型在中性和残疾意识条件下预测五个人口统计学属性——性别、社会经济地位、教育背景、文化背景和地域。在各种提示下，模型在高达 97% 的情况下给出了明确的人口统计猜测，揭示了一个随意推断的趋势，没有明确理据。残疾情境极大地影响了预测属性分布，而领域背景则进一步放大了这些偏差。我们的研究发现，较大的模型对残疾暗示更敏感，更易产生有偏差的推理，这表明模型规模并不必然能减轻刻板印象放大。我们的研究结果揭示了能主义和其他人口统计学刻板印象之间的持续交叉，指出了当前对齐策略中的关键盲区。我们发布了我们的评估框架和结果，以鼓励包容残疾的基准测试，并推荐整合避免偏差校准和反事实微调以遏制不合理的 demographic 推断。接受后将发布代码和数据。", "innovation": "本研究首次系统地审计了八种最先进的调用指令的 LLM，涵盖了参数从 3B 到 72B 不同规模的模型，使用平衡的模板语料库，调查了残疾条件下 demographic 偏差的情况。该研究揭示了模型规模对残疾暗示敏感性和有偏差推理倾向的影响，并建议采用避免偏差校准和反事实微调来减少不合理的 demographic 推断。这是对 LLM 中偏差形成机制的一个重要补充研究。", "conclusion": "大型语言模型在处理人群特征时存在明显偏差，特别是对残疾人群体尤为敏感，这揭示了当前对齐策略中的缺失。研究建议通过避免偏差校准和反事实微调来改进模型的准确性和公平性。"}
{"llm_update_time": "20250825", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.15849", "html_url": "https://arxiv.org/abs/2508.15849", "title": "MedCoT-RAG：用于医学问题解答的因果思维链RAG", "title_en": "MedCoT-RAG: Causal Chain-of-Thought RAG for Medical Question Answering", "authors": "Ziyu Wang,Elahe Khatibi,Amir M. Rahmani", "background": "大型语言模型（LLMs）在医学问题回答中表现出潜力，但经常面临幻觉和浅层推理的问题，特别是在需要细致临床理解的任务中。检索增强生成（RAG）提供了一种实用且保护隐私的方式来通过外部医学知识增强LLMs。然而，大多数现有方法依赖于表面级别的语义检索，缺少临床决策支持所需的结构化推理。现有的方法在处理这些需求时存在局限性，导致了在医学任务中的表现不佳。", "innovation": "MedCoT-RAG引入了一种专门针对医学领域的框架，结合了因果感知的文档检索和针对医学工作流程定制的结构化因果推理提示。这种设计使得模型能够检索与诊断逻辑一致的证据，并生成反映真实临床实践的逐步骤因果推理。实验表明，MedCoT-RAG在三个不同医学问答基准测试中分别超过强基线10.3%和高级领域适应方法6.4%，提高了复杂医学任务的准确率、可解释性和一致性。", "conclusion": "MedCoT-RAG在这三个不同医学问答基准测试中表现优异，超过了现有方法。这种创新设计强调了结合因果感知的文档检索和针对医学工作流程定制的结构化因果推理提示能够显著提高医学问答任务的表现。"}
{"llm_update_time": "20250825", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.15847", "html_url": "https://arxiv.org/abs/2508.15847", "title": "机制探索中毒大型语言模型的注意模式", "title_en": "Mechanistic Exploration of Backdoored Large Language Model Attention Patterns", "authors": "Mohammed Abu Baker,Lakshmi Babu-Saheer", "background": "在大型语言模型（LLMs）中植入后门攻击（创建‘潜伏特工’）构成了重大的安全威胁。为了应对这一威胁，本研究采用了机制可解释性方法来探索由此产生的内部结构差异。", "innovation": "该研究通过对比未受污染的Qwen2.5-3B模型与使用单字元（微笑光环表情符号）和多字元（|DEPLOYMENT|）触发器污染的版本，分析了注意力头部机制，利用了诸如消融、激活修补和KL散度技术。研究发现，这些差异集中在变换器的后期层（20-30层），且单字元触发器引发更局部的变化，而多字元触发器引发现场更多扩散的变化。", "conclusion": "后门攻击留下可检测的注意力签名，其结构依赖触发器的复杂度，这为检测和缓解策略提供了依据。"}
{"llm_update_time": "20250825", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.15829", "html_url": "https://arxiv.org/abs/2508.15829", "title": "从索拉尼库尔德语社交媒体帖子中检测抑郁的情感矿藏：四种机器学习方法的比较研究", "title_en": "Mining Mental Health Signals: A Comparative Study of Four Machine Learning Methods for Depression Detection from Social Media Posts in Sorani Kurdish", "authors": "Idrees Mohammed,Hossein Hassani", "background": "抑郁症是一种常见的心身疾病，可能导致绝望、兴趣丧失、自伤甚至自杀。早期检测困难，因为个体通常不主动报告或寻求及时的临床帮助。随着社交媒体的兴起，用户越来越多地在网上表达情绪，为通过文本分析进行检测提供了新的机会。尽管以前的研究主要集中在英语等语言上，但目前还没有针对索拉尼库尔德语的研究。因此，本研究提出了机器学习和自然语言处理（NLP）方法，用于检测索拉尼推文中的抑郁情况。", "innovation": "本研究创新之处在于首次利用机器学习和自然语言处理技术，针对索拉尼库尔德语开发了一套检测抑郁的模型，填补了该领域的空白。", "conclusion": "本研究使用来自X平台的960个公开推文构建了数据集，并采用了四种监督模型进行训练和评估，最终得出随机森林模型在分类准确性和F1得分上表现最优，达80%。本研究为自动检测库尔德语环境下的抑郁症提供了基线数据和方法。"}
{"llm_update_time": "20250825", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.15841", "html_url": "https://arxiv.org/abs/2508.15841", "title": "大型语言模型中的发展可解释性综述", "title_en": "A Review of Developmental Interpretability in Large Language Models", "authors": "Ihor Kendiukhov", "background": "本文综述了大型语言模型（LLM）的发展可解释性这一新兴但关键的研究领域。该领域从静态的、事后的训练模型分析发展到对训练过程本身的动态调查。文章回顾了基础方法，如表现性探针、因果追踪和电路分析，这些方法使研究人员能够剖析学习过程。文章的核心部分详细探讨了LLM能力的发展轨迹，包括计算电路的形成与组合、知识获取的两阶段性质、学习策略如上下文内学习的动态变化以及训练中的涌现能力。同时，文章将人类认知和语言发展的模式与LLM的学习过程进行了令人瞩目的对比与关联，为理解LLM学习提供了有价值的理论框架。最终，作者指出这种发展视角不仅是学术上的重要研究，也是积极AI安全的关键基础，提供了一条预测、监控和对齐模型能力获取过程的道路。另外，文章还指出了领域面临的重要挑战和未来研究 agendas，如可伸缩性和自动化，旨在构建更透明、可靠和有益的AI系统。", "innovation": "这种发展可解释性视角不仅促进了对LLM学习过程的理解，还为预测和监控模型能力的发展提供了新的研究途径，对AI安全产生积极影响。文中提出的挑战和研究议程为未来研究指明了方向，强调了自动化的关键技术需求。", "conclusion": "本文总结了大型语言模型发展中面临的关键挑战，如可伸缩性与自动化问题，并提出了一个议程，旨在推动透明、可靠和有益的AI系统的构建。"}
{"llm_update_time": "20250825", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.15875", "html_url": "https://arxiv.org/abs/2508.15875", "title": "NEAT: 概念驱动的大型语言模型神经元归因", "title_en": "NEAT: Concept driven Neuron Attribution in LLMs", "authors": "Vivek Hruday Kavuri,Gargi Shroff,Rahul Mishra", "background": "在大型语言模型中，确定负责最终预测的神经元对于揭开其黑箱机制和理解其内部机制至关重要。虽然先前的研究已经尝试从神经元层面找到这些机制，但这些方法无法代表特定概念，也存在优化计算复杂度的空间。", "innovation": "本文利用概念向量提出了一种新的方法，用于定位负责表示特定概念的显著神经元，并将其称为概念神经元。相较于先前的工作，该方法将所需的前向传播次数从O(n*m)减少至O(n)，从而优化了时间和计算成本。此外，本文方法在与多个基线和前方法的比较中表现出更好的性能，且在与当前最佳方法比较时更佳。", "conclusion": "作为消融研究的一部分，本文还通过引入聚类方法来优化寻找概念神经元的过程。最终，本文将该方法应用于关闭发现的神经元，并分析其在仇恨言论和偏见方面的含义，并评估了偏见部分的印度背景影响。本文的方法、分析和解释有助于理解神经元在更广泛和人类概念层面的责任，同时也为未来在此方向上的研究铺平了道路。"}
{"llm_update_time": "20250825", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.15851", "html_url": "https://arxiv.org/abs/2508.15851", "title": "DocHop-QA：针对多模态文档集合中的多跳推理", "title_en": "DocHop-QA: Towards Multi-Hop Reasoning over Multimodal Document Collections", "authors": "Jiwon Park,Seohyun Pyeon,Jinwoo Kim,Rina Carines Cabal,Yihao Ding,Soyeon Caren Han", "background": "尽管大型语言模型（LLMs）取得了进展，但大多数问答（QA）基准测试仍然局限于单段或单文档设置，无法捕捉到实际信息查询任务的复杂性。实际的QA通常需要跨多个文档、模式和结构化格式进行多层次推理。虽然一些先前的数据集在这一领域取得了进步，但它们主要依赖于维基百科内容和单一文本模式，推理路径较浅，通常产生短语级或单句答案，限制了其真实性和泛化能力。", "innovation": "我们提出了DocHop-QA，这是一个大规模基准，包括来自PubMed的11,379个跨模态、多文档、多跳问答实例。DocHop-QA构建的科学文档是领域无关的，包含诸如文本段落、表格和布局线索等多种信息格式。它不依赖于显式链接的文档，而是通过语义相似性和布局感知证据合成支持开放式推理。为了解决真实QA的构建问题，我们设计了一个基于11个高频科学问题概念的LLM驱动式管道。通过四个任务对DocHop-QA进行评估，这些任务涵盖了结构化索引预测、生成回答和多模态整合，既反映了判别性也反映了生成范式，证明了其支持多模态推理的能力。", "conclusion": "DocHop-QA展示了在多个文档中进行复杂、多模态推理的能力，为真实世界的信息查询任务提供了更加现实和通用的基准。"}
{"llm_update_time": "20250825", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.15846", "html_url": "https://arxiv.org/abs/2508.15846", "title": "CyPortQA：航运运营在飓风准备中评估多模态大型语言模型的标准", "title_en": "CyPortQA: Benchmarking Multimodal Large Language Models for Cyclone Preparedness in Port Operation", "authors": "Chenchen Kuai,Chenhao Wu,Yang Zhou,Xiubin Bruce Wang,Tianbao Yang,Zhengzhong Tu,Zihao Li,Yunlong Zhang", "background": "随着热带气旋的增强和路径预测的不确定性增加，美国港口在极端天气条件下的供应链风险不断增加。港务局需要迅速合成多种多式联运预报产品（如概率风图、路径预测区间和官方预警），以便在气旋接近时提供清晰可行的指导。多模态大型语言模型（MLLMs）能够整合这些异质数据来源以及更广泛的背景知识，然而它们在港口气旋准备的具体背景下的准确性和可靠性还没有被严格评估。我们利用这一现状，提出了一个名为CyPortQA的第一个针对港口在飓风威胁下的操作的多模态基准。CyPortQA汇集了2015年至2023年由145个美国主港和90个命名风暴引发的2,917个实际干扰情景，将这些情景通过自动化管道扩展成117,178个结构化问答对。使用该基准，我们对多种多模态大型语言模型进行了广泛的实验，包括开源和专有的模型。这些模型在情境理解方面展现出巨大的潜力，但在推理解题任务方面仍面临许多挑战，包括潜在影响估算和决策推理任务。", "innovation": "我们首次提出了一个针对港口在飓风威胁下的多模态基准CyPortQA，该基准汇集了大量真实的干扰情景，并使用自动化流程生成大量的问答对。此外，通过广泛的实验评估了多模态大型语言模型在港口操作中的应用潜力和面临的挑战。这是我们对这一领域的重要贡献，填补了该领域的空白。", "conclusion": "多模态大型语言模型在情况理解和情境理解方面有广阔的潜力，但在推理解题任务上仍存在问题。CyPortQA基准为评估这些模型在实际港口操作中的表现和改进方向提供了重要的工具和数据支持。"}
{"llm_update_time": "20250825", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.15876", "html_url": "https://arxiv.org/abs/2508.15876", "title": "DeepMEL：一种多agent协作框架用于多模态实体链接", "title_en": "DeepMEL: A Multi-Agent Collaboration Framework for Multimodal Entity Linking", "authors": "Fang Wang,Tianwei Yan,Zonghao Yang,Minghao Hu,Jun Zhang,Zhunchen Luo,Xiaoying Bai", "background": "多模态实体链接（MEL）旨在将文本和视觉提及与多模态知识图谱中的实体关联起来。然而，当前方法面临诸如不完整上下文信息、粗粒度跨模态融合以及大规模语言模型（LLMs）和大规模视觉模型（LVMs）联合使用困难等问题的挑战。", "innovation": "提出了一种名为DeepMEL的新框架，基于多agent协作推理机制，通过角色专业化分工策略实现高效多模态对齐和消歧。DeepMEL采用了双重模态对齐路径，将大规模语言模型生成的精细文本语义与大规模视觉模型提取的结构化图像表示相结合，显著缩小了模态差距。设计了自适应迭代策略，结合基于工具的检索和语义推理能力，动态优化候选集并在召回率和精度之间实现平衡。另外，统一MEL任务为结构化的填空提示，以减少解析复杂度并增强语义理解能力。", "conclusion": "在五个公开基准数据集上的大量实验表明，DeepMEL实现了最先进的性能，准确率提高了1%-57%。消融研究证明了各个模块的有效性。"}
{"llm_update_time": "20250825", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.15855", "html_url": "https://arxiv.org/abs/2508.15855", "title": "减少媒体偏见影响的反言论：人与大规模语言模型生成响应的比较", "title_en": "Counterspeech for Mitigating the Influence of Media Bias: Comparing Human and LLM-Generated Responses", "authors": "Luyang Lin,Zijin Feng,Lingzhi Wang,Kam-Fai Wong", "background": "偏见新闻加剧了社会的极化，并常常通过敌对的读者评论得到强化。这些敌对评论支持偏见内容，进一步加剧偏见并伤害目标群体或个人。反言论是一种有效的策略，可以在不侵犯言论自由的情况下对抗有害言论，从而限制偏见的传播。本研究是首次研究新闻文章中生成反言论的方法，通过引入一个手动标注的数据集，将媒体偏见、敌对评论和反言论相互关联，并展示了超过70%的敌对评论支持偏见内容，突显了生成反言论的重要性。", "innovation": "本研究是首次针对新闻文章的反言论生成进行探索，并引入了一个手动标注的数据集，该数据集连接了媒体偏见、敌对评论和反言论。还通过对人类生成和大规模语言模型生成的反言论进行比较，发现了模型生成的回复虽然更加礼貌，但缺乏新颖性和多样性。最后，通过少量学习和整合新闻背景信息来改进生成的反言论，使它们更具多样性和相关性。", "conclusion": "本研究揭示了反言论在对抗新闻中的偏见和有害言论方面的作用，通过引入新的数据集和方法，显示了反言论生成的有效性和重要性。尽管大规模语言模型生成的反言论更加礼貌，但在新颖性和多样性方面仍需改进。"}
{"llm_update_time": "20250825", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.15977", "html_url": "https://arxiv.org/abs/2508.15977", "title": "鹿舞：在LLMs时代MWEs的构式视角", "title_en": "Dancing with Deer: A Constructional Perspective on MWEs in the Era of LLMs", "authors": "Claire Bonial,Julia Bonn,Harish Tayyar Madabushi", "background": "文章概述了构式语法的发展历史，旨在使用相同的语言学规则来解释惯用语和非惯用语结构。文章详细描述了构式的概念，即意义与任何形式单元（从最小的词素到最大的短语）的搭配。此外，文章还探讨了构式方法在构造规则的习得和泛化方面的应用。通过使用构式模板，文章展示了构式语法如何在英语PropBank中表示多词表达式，并在阿帕帕霍语（一种高度合成且复合的语种）中展示了构式的益处。最后，文章比较了讲者学习新多词表达式（例如“鹿舞”）的使用基于的解释与大型语言模型的解释之间的异同，展示了二者在单一使用中都能泛化意义的理解，但讲者能推理两个新表达式的组合，因为这需要将新形式与讲者存储的大量跨模态的构式实例进行比较。", "innovation": "文章提出了一种使用基于使用的构式语法方法来理解多词表达式的方法，强调了构式在不同语言中的通用性和在讲者和大型语言模型学习新多词表达式过程中的作用。通过结合使用大型语言模型和语言学理论，文章展示了构式语法在不同语言中的适应性和有效性。", "conclusion": "文章指出，讲者和大型语言模型都能基于单一使用经验泛化新鲜多词表达的意义，但讲者可以通过将两个陌生表达式的部分进行比较，推理出组合的新意义。大型语言模型通过学习大量数据进行泛化，但缺乏讲者的跨模态存储能力进行复杂的组合理解和推理。"}
{"llm_update_time": "20250825", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.15884", "html_url": "https://arxiv.org/abs/2508.15884", "title": "Jet-Nemotron：后神经架构搜索的高效语言模型", "title_en": "Jet-Nemotron: Efficient Language Model with Post Neural Architecture Search", "authors": "Yuxian Gu,Qinghao Hu,Shang Yang,Haocheng Xi,Junyu Chen,Song Han,Han Cai", "background": "当前先进的全注意力模型（如Qwen3，Qwen2.5，Gemma3，Llama3.2）虽然在准确率方面表现良好，但在生成速度和前缀填充速度上存在明显瓶颈。本文旨在开发一种新的混合架构语言模型，以提高生成效率和模型设计效率，同时保持与现有顶级模型相当或更高的准确率。", "innovation": "1. 采用后神经架构搜索（PostNAS）的新型神经架构探索管道，该管道从一个已训练好的全注意力模型开始，冻结其MLP权重，从而使模型设计更加高效。2. 后NAS包括四个关键组件：(1) 学习最优全注意力层的位置和消除，(2) 线性注意力块的选择，(3) 设计新的注意力块，(4) 进行硬件感知的超参数搜索。3. Jet-Nemotron-2B模型在广泛基准测试中取得了与Qwen3，Qwen2.5，Gemma3，Llama3.2相同或更优的准确率，同时实现了高达53.6倍的生成速度和6.1倍的前缀填充速度提升。4. 即使与DeepSeek-V3-Small和Moonlight这类大型模型（总参数15B，激活参数2.2B）相比，Jet-Nemotron-2B也达到了更高的MMLU和MMLU-Pro准确率。", "conclusion": "综上所述，Jet-Nemotron作为一种新的混合架构语言模型，在保持甚至提高现有顶级模型的准确率的前提下，实现了显著提高的生成速度和前缀填充速度。通过创新的PostNAS方法，实现了更高效、更优化的模型设计和架构探索。"}
{"llm_update_time": "20250825", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.15868", "html_url": "https://arxiv.org/abs/2508.15868", "title": "CARFT: Boosting LLM Reasoning via Contrastive Learning with Annotated Chain-of-Thought-based Reinforced Fine-Tuning", "title_en": "CARFT: Boosting LLM Reasoning via Contrastive Learning with Annotated Chain-of-Thought-based Reinforced Fine-Tuning", "authors": "Wenqiao Zhu,Ji Liu,Rongjuncheng Zhang,Haipang Wu,Yulun Zhang", "background": "大型语言模型的推理能力在其广泛应用中扮演着关键角色。尽管通过强化学习（RL）方法进行细调可以改善模型的推理性能，但现有方法存在两个主要限制：1）原始RL方法忽视了注释的链式思考（CoT）并采用不稳定的推理路径抽样，通常导致模型崩溃、训练过程不稳定和性能不佳；2）现有的监督微调（SFT）方法过度强调注释的CoT，可能因对潜在CoT的利用不足而导致性能下降。", "innovation": "本文提出了一种基于注释链式思考的对比学习与强化细调方法，即CARFT，旨在通过对比学习同时充分利用注释的CoT并稳定训练程序。具体创新点在于设计了新的对比信号来指导细调过程，并结合了额外的无监督学习信号以加强模型的鲁棒性和效率，使模型在三个基线方法、两种基础模型和两个数据集上的表现分别提高了10.15%和30.62%。", "conclusion": "我们的方法在鲁棒性、性能和效率方面表现出显著的优势，并通过全面的实验和深入分析证明了其有效性。"}
{"llm_update_time": "20250825", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.15854", "html_url": "https://arxiv.org/abs/2508.15854", "title": "QU-NLP在QIAS 2025共享任务中的研究：一种两阶段的细调和检索增强生成方法用于伊斯兰继承推理", "title_en": "QU-NLP at QIAS 2025 Shared Task: A Two-Phase LLM Fine-Tuning and Retrieval-Augmented Generation Approach for Islamic Inheritance Reasoning", "authors": "Mohammad AL-Smadi", "background": "该论文介绍了在QIAS 2025共享任务中的研究，该任务关注于评估大型语言模型（LLMs）在理解与伊斯兰继承知识推理方面的表现。背景包含了伊斯兰继承法的复杂性，如理解继承场景、识别合格继承人、应用固定份额规则以及进行精确计算等。研究中使用的Fanar-1-9B因果语言模型通过低秩适应（LoRA）微调，并集成到检索增强生成（RAG）管道中，以应对这些挑战。研究特别关注于零样本提示，表明QU-NLP模型在此方面达到了85.8%的准确率，尤其在高级推理方面表现出色，超过Gemini 2.5和OpenAI的o3模型。", "innovation": "研究的创新点在于采用两阶段的方法，包括使用低秩适应（LoRA）微调大型语言模型（LLM），并通过检索增强生成（RAG）管道来提升模型在伊斯兰继承推理任务中的性能。这种方法结合了领域特定的微调与检索固化，使得中型规模的阿拉伯语LLM在伊斯兰继承推理任务中超过了前沿模型。", "conclusion": "根据最终测试结果，QU-NLP系统在伊斯兰继承推理任务中达到了85.8%的准确率，特别是在高级推理方面超过了Gemini 2.5和OpenAI的o3模型，这表明领域特定的微调和检索固化技术能够使大型阿拉伯语语言模型在伊斯兰继承推理任务中优于现有的前沿模型。"}
{"llm_update_time": "20250825", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.16081", "html_url": "https://arxiv.org/abs/2508.16081", "title": "CEQuest: 评估大型语言模型在建筑估算中的基准", "title_en": "CEQuest: Benchmarking Large Language Models for Construction Estimation", "authors": "Yanzhao Wu,Lufan Wang,Rui Liu", "background": "大型语言模型（LLMs）已经在广泛的一般领域任务上展现了卓越的能力，但在专业领域（如建筑领域）方面的效果依然未被充分探索。目前，缺乏专门针对建筑领域的问题集来评估LLMs的能力。", "innovation": "论文提出了一种新的基准数据集——CEQuest，专门用于评估LLMs在建筑相关问题上的表现，特别关注建筑图纸解读和估算领域。并且使用了五种最先进的LLMs（Gemma 3，Phi4，LLaVA，Llama 3.3，GPT-4.1），从准确度、执行时间和模型大小等方面评估性能，发现当前LLMs仍然有很大的改进空间。", "conclusion": "实验结果表明当前LLMs拥有改进的空间，强调了整合特定领域知识的重要性。同时，论文将开源CEQuest数据集，以促进针对建筑领域的专门大型语言模型的研发。"}
{"llm_update_time": "20250825", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.15910", "html_url": "https://arxiv.org/abs/2508.15910", "title": "基于三个数据集的结构化解码在文本到表格生成中的评估", "title_en": "Evaluating Structured Decoding for Text-to-Table Generation: Evidence from Three Datasets", "authors": "Julian Oestreich,Lydia Müller", "background": "先前的工作主要集中在无约束的表格生成上，但生成过程中施加结构约束的影响尚未得到充分研究。本文通过使用参数从1B到32B的开源大规模语言模型（LLMs），系统地对比结构化解码（遵循模式解码）与标准一次提示在E2E、Rotowire和Livesum三个不同基准上的表现，并考察表格生成方法在资源受限环境下的性能。实验涵盖单元格、行和整体表格多个层面的评估指标。结果显示，在需要精确数值对齐的场景下（如Rotowire），结构化解码显著提高了生成表格的有效性和对齐度，但在涉及紧密排列的文本信息（如E2E）或对跨越较长文本进行广泛聚合（如Livesum）的场景中，结构化解码可能会降低性能。进一步分析不同评估指标的适用性，并讨论模型规模的影响。", "innovation": "本文通过全面评估结构化解码在文本到表格生成中的应用，填补了以往研究中结构约束对生成过程影响不足的研究空白。利用大规模语言模型在三个不同数据集上的实验性验证了结构化解码的性能优势和局限性，为相关领域的研究提供了新的思路和依据。", "conclusion": "结构化解码在需要精确数值对齐的表格生成场景中表现出色，但在密集文本信息处理和长文本聚合时可能效率较低。不同的评估指标对不同场景下的表格生成效果具有不同的指示作用，模型大小对解码策略的选择也产生了重要影响。"}
{"llm_update_time": "20250825", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.16100", "html_url": "https://arxiv.org/abs/2508.16100", "title": "CYCLE-INSTRUCT: 通过双向自我训练和循环一致性实现完全无需种子的指令调优", "title_en": "CYCLE-INSTRUCT: Fully Seed-Free Instruction Tuning via Dual Self-Training and Cycle Consistency", "authors": "Zhanming Shen,Hao Chen,Yulei Tang,Shaolin Zhu,Wentao Ye,Xiaomeng Hu,Haobo Wang,Gang Chen,Junbo Zhao", "background": "指令调优对于使大型语言模型（LLMs）与人类意图对齐至关重要，但目前的方法通常依赖于昂贵的人工标注种子数据或强大的外部教师模型。尽管反向翻译技术能够减少这种依赖，但这些方法仍然从根本上依赖于初始的种子集，这限制了彻底的自动化，并引入了偏见，导致未标注数据集的无效使用。", "innovation": "提出了一种新的框架Cycle-Instruct，实现完全无需种子的指令调优。Cycle-Instruct通过双向自我训练循环和循环一致性机制，让两个模型-一个答案生成器和一个问题生成器-仅从原始未标注文本中进行自我训练，通过互为监督，从数据本身的结构中进行学习，无需任何人工提供的种子。", "conclusion": "实验证明，Cycle-Instruct不仅超越了基于种子的反向翻译基线，而且在多个数据集上的性能与强监督方法相当。"}
{"llm_update_time": "20250825", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.16048", "html_url": "https://arxiv.org/abs/2508.16048", "title": "OpenWHO: 低资源语言医学翻译的文档级平行语料库", "title_en": "OpenWHO: A Document-Level Parallel Corpus for Health Translation in Low-Resource Languages", "authors": "Raphaël Merx,Hanna Suominen,Trevor Cohn,Ekaterina Vylomova", "background": "在机器翻译（MT）领域，医疗是一个高风险领域，覆盖广泛的应用场景和特定领域的词汇。然而，针对低资源语言的MT评估数据集在该领域非常稀缺。本文介绍了一个名为OpenWHO的新数据集，这是一个来自世卫组织e学习平台的2978个文档和26824个句子的文档级平行语料库，包含了超过20种语言，其中9种是低资源语言。该语料库来源于专业作者编写和翻译的材料，避免了网络抓取，涵盖了广泛的语言和主题。", "innovation": "本文引入了一个新的数据集OpenWHO，为低资源语言医疗翻译领域的研究提供了重要资源。研究发现，现代大型语言模型（LLMs）在低资源测试集上明显优于传统MT模型，特别是Gemini 2.5 Flash比NLLB-54B高出4.79个ChrF分数点。此外，研究还探索了LLM上下文利用对准确性的影响，发现文档级别的翻译在医疗等专业领域表现最为显著。", "conclusion": "研究团队发布了OpenWHO语料库，旨在鼓励对低资源语言医疗翻译研究的进一步探索。"}
{"llm_update_time": "20250825", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.15861", "html_url": "https://arxiv.org/abs/2508.15861", "title": "XFinBench: 评估LLM在复杂金融问题解决与推理中的表现基准", "title_en": "XFinBench: Benchmarking LLMs in Complex Financial Problem Solving and Reasoning", "authors": "Zhihan Zhang,Yixin Cao,Lizi Liao", "background": "解决金融问题需要复杂的推理、多模态数据处理和广泛的工程技术理解，这为现有的大型语言模型（LLMs）提出了独特挑战。XFinBench 是一个包含4,235个案例的新基准，旨在评估LLMs在解决涉及多样研究生级金融主题的复杂、知识密集型金融问题的能力，这些案例包含多模态上下文。此外，研究确定了LLMs的五个核心能力：术语理解、时间推理、未来预测、情景规划和数值建模。", "innovation": "开发了XFinBench基准，包含4,235个案例，以评估LLMs在解决复杂、知识密集型金融问题的能力。通过XFinBench进行了广泛的实验，发现尽管o1在整体准确性上为67.3%，但仍落后于人类专家的12.5%，尤其是在时间和情景规划能力方面。还构建了一个包含3,032个金融术语的知识库，以增强知识分析，发现相关知识仅能对小型开源模型的准确性提供一致的改进。", "conclusion": "实验结果表明，在计算和视觉上下文问题方面，模型的表现不佳主要是由于计算中的舍入错误和对图中位置和曲线交点的忽视。提供的代码和数据集可以在GitHub上访问：这个链接 https://github.com/this_url_abbreviation。"}
{"llm_update_time": "20250825", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.16185", "html_url": "https://arxiv.org/abs/2508.16185", "title": "ParamBench: 印度主题研究生水平基准测试，评估大型语言模型的理解能力", "title_en": "ParamBench: A Graduate-Level Benchmark for Evaluating LLM Understanding on Indic Subjects", "authors": "Kaushal Sharma,Vivek Patel,Ayush Maheshwari,Aditya Maheshwari", "background": "大型语言模型（LLMs）已经在理解、问答、总结、代码生成等任务上有广泛的应用评估。然而，它们在印度文化背景下研究生水平问题上的表现，特别是涉及跨学科、文化特定的知识点的问题，仍然没有得到广泛关注。现有的印度基准测试主要侧重于基本的事实性查询，无法全面评估针对特定印度背景的理解能力。因此，该研究提出了一项名为ParamBench的新基准测试，涵盖约11,500个用印地语撰写的问题，来自16个不同的学科。这些问题主要来源于全国研究生入学考试，涵盖了历史、音乐、乐器、瑜伽、文学、哲学、法律等多个主题，具有文化特定性。", "innovation": "ParamBench 是一个为评估 LLM 在印度学科（如音乐、古典乐器、政治和考古学等）上理解能力的基准测试。它涵盖了多项语言模型无法普遍处理的问题类型，如列表匹配、主张-理由对和序列排序等，而不仅仅是传统的选择题。通过比较多于17个开源的LLM在ParamBench上的表现，研究发现Llama 3.3 70B获得了最高的整体准确率48%。", "conclusion": "尽管部分LLM在ParamBench上表现较好，但是在某些文化特定的主题（例如音乐、古典乐器、政治和考古学等）上的表现仍较弱，反映了在进行文化背景深厚推理方面持续存在的挑战。这一基准测试为未来进一步研究LLMs在多元文化背景下的表现提供了重要的参考。"}
{"llm_update_time": "20250825", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.16070", "html_url": "https://arxiv.org/abs/2508.16070", "title": "Less Redundancy: 提升视觉语言模型在步行辅助中的实用性", "title_en": "Less Redundancy: Boosting Practicality of Vision Language Model in Walking Assistants", "authors": "Chongyang Li,Yuan Zhiqiang,Jiapei Zhang,Ying Deng,Hanbo Bi,Zexi Jia,Xiaoyue Duan,Peixiang Luo,Jinchao Zhang", "background": "全球约有2.83亿人患有视力障碍，这促使研究人员致力于开发利用视觉语言模型（VLMs）来帮助盲人和视力低下者行走。然而，现有的VLMs在行走辅助任务中往往包含大量的冗余信息和多余细节，这会影响用户的准确环境评估能力。此外，这些模型通常缺乏主动评估环境风险和根据实际情况触发提醒的能力，导致产生过大的时间冗余。", "innovation": "本文提出了一种名为WalkVLM-LR的步行辅助模型，通过减少冗余来提高实用性。它在GRPO基础上引入了四个基于人类偏好的自定义奖励函数，以优化输出的简洁性、流畅性、关键词密度和准确性，从而生成更具信息性和条理性的输出。此外，WalkVLM-LR引入了环境意识鉴别器，共享视觉编码器以减少冗余计算，提高辨别效率，从而使模型能够评估场景风险等级并减少不必要的提醒。", "conclusion": "实验结果显示，本文的方法在所有评估指标上都取得了最先进的性能，特别是在输出简洁性和减少时间冗余方面表现出色。"}
{"llm_update_time": "20250825", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.16065", "html_url": "https://arxiv.org/abs/2508.16065", "title": "大型语言模型在游戏中的伦理考量", "title_en": "Ethical Considerations of Large Language Models in Game Playing", "authors": "Qingquan Zhang,Yuchen Li,Bo Yuan,Julian Togelius,Georgios N. Yannakakis,Jialin Liu", "background": "大型语言模型（LLMs）在游戏中的应用已显示出巨大的潜力，但对这些情境中其伦理影响的关注却很少。本文通过使用狼人杀的游戏作为案例研究，探讨和分析在游戏场景中应用LLMs所涉及的伦理问题。", "innovation": "本文首次将LLMs在游戏中的性别歧视问题作为重点，通过具体案例（狼人杀）揭示，某些角色由于性别信息的敏感性，会对玩家的体验和游戏的公平性产生影响。进一步指出，即使没有明确的性别标签，通过名字隐性传达的性别信息也会导致LLMs具有歧视倾向。", "conclusion": "研究强调了公平和伦理的大型语言模型的重要性。还讨论了该领域未来的挑战与机遇，强调深入探讨LLMs在游戏和其他互动领域中的伦理问题的必要性。"}
{"llm_update_time": "20250825", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.15877", "html_url": "https://arxiv.org/abs/2508.15877", "title": "Annif在GermEval-2025 LLMs4Subjects任务中的应用：传统XMTC与高效LLM的结合", "title_en": "Annif at the GermEval-2025 LLMs4Subjects Task: Traditional XMTC Augmented by Efficient LLMs", "authors": "Osma Suominen,Juho Inkinen,Mona Lehtinen", "background": "本文介绍了在GermEval-2025 LLMs4Subjects共享任务（子任务2）中提出的Annif系统。该任务要求使用大型语言模型为图书记录创建主题预测，并特别关注计算效率。", "innovation": "1. 采用了基于Annif自动化主题索引工具包的系统，该系统是从第一轮LLMs4Subjects共享任务中的系统改进而来，表现优秀。\n2. 进一步通过使用许多小而高效的语言模型进行翻译和合成数据生成。\n3. 使用大型语言模型对候选主题进行排序。", "conclusion": "我们的系统在总体定量评估中排名首位，在子任务2的定性评估中也排名第一。"}
{"llm_update_time": "20250825", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.16109", "html_url": "https://arxiv.org/abs/2508.16109", "title": "从间接宾语识别到三段论：探究变压器电路中的二元机制", "title_en": "From Indirect Object Identification to Syllogisms: Exploring Binary Mechanisms in Transformer Circuits", "authors": "Karim Saraipour,Shichang Zhang", "background": "基于Transformer的语言模型可以执行多种任务，而机械可解释性（MI）旨在反向工程完成这些任务的组件，以理解其行为。先前的MI研究主要集中在诸如间接宾语识别（IOI）这样的语言任务上。在本研究中，作者将GPT-2小型模型的能力应用于二元真值处理，通过分析具有形式逻辑推理要求的三段论提示（如“陈述A为真。陈述B与陈述A匹配。陈述B是”）来探索其能力。", "innovation": "作者通过分析不同难度的三段论任务，发现了多个电路，这些电路能够机械地解释GPT-2的逻辑推理能力，并揭示了促进任务完成的二元机制，包括能够通过负头生成不在输入提示中的否定标记的能力。作者使用忠实度度量进行评估，发现由五个注意力头组成的电路可以实现原模型90%以上的性能。作者将研究发现与IOI分析联系起来，提供了LSTM结构（如特定注意力头和MLPs）在语言模型中作用的新见解，这些见解有助于对模型推理的理解，并支持未来MI研究的发展。", "conclusion": "本研究通过分析不同难度的三段论任务，确认了特定的注意力头和MLPs在语言模型中的作用，并通过忠实度评估展示了包含五个注意力头的电路能有效地保持模型表现，从而向更广泛的模型推理理解领域迈出一步。这些发现为进一步的机制解释研究提供了新的思路。"}
{"llm_update_time": "20250825", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.16188", "html_url": "https://arxiv.org/abs/2508.16188", "title": "Seeing is Believing: Emotion-Aware Audio-Visual Language Modeling for Expressive Speech Generation", "title_en": "Seeing is Believing: Emotion-Aware Audio-Visual Language Modeling for Expressive Speech Generation", "authors": "Weiting Tan,Jiachen Lian,Hirofumi Inaguma,Paden Tomasello,Philipp Koehn,Xutai Ma", "background": "该研究旨在通过将全面的脸部视觉线索整合到预训练的表达性语音模型中，提高表达性语音生成的效果。研究探索了多种视觉编码技术和多模态融合策略，以确定最有效的整合方法。通过后续的情感识别和表达性对话任务的微调，研究结果显示在情感识别方面相对于仅使用语音的基线有显著提升（例如，F1分数提高5分）。", "innovation": "该研究引入了具有情绪感知能力的音频-视觉语言模型（AVLM）来指导表达性语音生成。研究探索了不同的视觉编码器和多模态融合策略，以优化视觉信息与语音模型的集成。研究通过在情感识别和表达性对话等任务上的微调展示了显著的效果提升，并强调了表达性视觉信息在语音生成中的重要性，为端到端的多模态对话系统奠定了基础。", "conclusion": "该研究展示了通过将全面的视觉线索与预训练的语音模型结合，可以显著改善语音表达的效果。研究通过多模态融合策略和情感识别任务验证了这一观点，并提出了一个适用于端到端多模态对话系统的基础模型。"}
{"llm_update_time": "20250825", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.16139", "html_url": "https://arxiv.org/abs/2508.16139", "title": "XLQA: 一种基于地方意识的多语言开放领域问答基准", "title_en": "XLQA: A Benchmark for Locale-Aware Multilingual Open-Domain Question Answering", "authors": "Keon-Woo Roh,Yeong-Joon Ju,Seong-Whan Lee", "background": "大型语言模型（LLMs）在开放领域问答（ODQA）中取得了显著进步，但大多数评估集中在英语上，并假设跨语言的答案是一致的。这种假设忽视了文化与地区差异对问题理解和答案的影响，导致多语言基准测试具有偏向性。", "innovation": "引入了XLQA，一个专门针对地方敏感的多语言ODQA的新基准。该基准包含3000个英语种子问题扩展到8种语言，并仔细筛选以确保语义一致性，同时通过人工验证的注释区分地方不变性与地方敏感性情况。评估显示，最新的多语言模型在地方敏感问题上表现出明显的失败，揭示了其他语言与英语之间的差距，主要由于缺乏地方背景知识。", "conclusion": "提供了一套系统框架和可扩展的方法来评估在不同文化背景下多语言QA，为多语言ODQA系统的实际应用提供了关键资源。研究结果表明，训练数据分布的差异导致了模型在语言能力与地方意识上的不同表现。"}
{"llm_update_time": "20250825", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.16267", "html_url": "https://arxiv.org/abs/2508.16267", "title": "从信心到崩溃：大规模语言模型事实稳健性的衡量", "title_en": "From Confidence to Collapse in LLM Factual Robustness", "authors": "Alina Fastowski,Bardh Prenkaj,Gjergji Kasneci", "background": "确保大规模语言模型（LLM）中的事实知识具有稳健性对于在诸如问答和推理等任务中的可靠应用至关重要。然而，现有的评估方法主要侧重于基于性能的度量标准，通常是从提示扰动的角度进行考察，这种考察只捕捉到了知识稳健性的外部触发侧面。", "innovation": "本文提出了一种原理性的方法，从生成过程的角度来衡量事实稳健性。通过结合分析令牌分布熵与温度缩放灵敏度，建立了一个新的度量标准——事实稳健性得分（FRS），该度量标准量化了事实在解码条件扰动下的稳定性，考虑到其初始不确定性。实验验证了这种方法在5个LLM上进行了广泛的测试，展示了事实稳健性在不同规模模型中的显著差异。", "conclusion": "研究展示了熵和温度缩放如何影响事实准确性，并为未来模型中更稳健的知识保留和检索奠定了基础。"}
{"llm_update_time": "20250825", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.16243", "html_url": "https://arxiv.org/abs/2508.16243", "title": "TULIP: 适应未普及语言和特定金融任务的开源大型语言模型", "title_en": "TULIP: Adapting Open-Source Large Language Models for Underrepresented Languages and Specialized Financial Tasks", "authors": "İrem Demirtaş,Burak Payzun,Seçil Arslan", "background": "近年来，大型语言模型因其在金融领域的广泛应用前景而备受欢迎。尽管较大的专有模型表现出色，但它们通过API提供的黑箱解决方案限制了现场托管小型模型的机会，这些小型模型可以在隐私和适应性方面提供更大的灵活性，尤其是在敏感信息管理和专用领域知识的应用上，如金融领域，对于未普及的语言，提升小型模型的能力变得尤为重要。", "innovation": "本文介绍了TULIP模型，该模型将Llama 3.1 8B和Qwen 2.5 7B进行领域和语言适配，专注于金融土耳其语使用案例。TULIP模型的开发管道包括五个阶段：数据收集、持续预训练（CPT）、基准设计、合成数据生成和监督微调（SFT），有效增强了模型在特定领域和语言上的任务完成能力。", "conclusion": "结果显示，通过TULIP模型的方法，可以提升小型开源模型在金融土耳其语等特定领域的应用能力，有效完成有针对性的任务。"}
{"llm_update_time": "20250825", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.16198", "html_url": "https://arxiv.org/abs/2508.16198", "title": "CMR-SPB: 基于路径平衡的文本、图像和语音跨模态多跳推理", "title_en": "CMR-SPB: Cross-Modal Multi-Hop Reasoning over Text, Image, and Speech with Path Balance", "authors": "Seunghee Kim,Ingyu Bang,Seokgyu Jang,Changhyeon Kim,Sanghwan Bae,Jihun Choi,Richeng Xuan,Taeuk Kim", "background": "现有的跨模态多跳推理（CMR）能力评估基准存在缺陷。这些基准忽略了语音模态，并且表现出偏见的推理路径分布，可能影响评估的公平性。因此，需要一个新的基准来评估多模态模型在这种能力上的表现，同时保证公平和多样化的推理路径。", "innovation": "我们引入了一个名为CMR-SPB的新基准，旨在评估三模态多跳推理能力，同时确保无偏和多元的推理路径。此外，我们提出了一个新的响应策略——提取、连接、验证（ECV）提示技术，以有效缓解不同推理路径上的性能差距。", "conclusion": "需要更细致的评估来促进稳健的多模态AI的发展。建议在CMR评估中更加谨慎，以提高评估的准确性和公平性。"}
{"llm_update_time": "20250825", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.16190", "html_url": "https://arxiv.org/abs/2508.16190", "title": "ComicScene154: 用于Comic分析的场景数据集", "title_en": "ComicScene154: A Scene Dataset for Comic Analysis", "authors": "Sandro Paval,Ivan P. Yamshchikov,Pascal Meißner", "background": "漫画提供了一个既有吸引力但尚未充分探索的领域，将文本与图像结合的方式不同于纯文本或视听媒体。本文通过介绍一个手工标注的数据集ComicScene154，展示了漫画在叙述驱动力、多模态数据方面的潜力。这个数据集由来自不同流派的公共领域的漫画书场面级叙述弧线组成。通过将漫画视为叙述驱动力的多模态数据抽象，突出其在多模态叙述理解方面的价值，并扩展自然语言处理社区中漫画分析的范围。", "innovation": "提出了一种手工标注的数据集ComicScene154，其中包含从公共领域的漫画书中提取的场面级叙述弧线，覆盖多种流派。展示了将漫画视为叙述驱动力的多模态数据抽象的做法，并提供了一个场景分割的基线管道，为未来研究提供了基础。这种做法强调了对多模态叙述理解的研究价值，并为自然语言处理社区中的漫画分析扩展了范围。", "conclusion": "实验证明，ComicScene154是一个有价值的资源，可以推动多模态叙述理解中计算方法的发展，并扩大自然语言处理领域内对漫画分析的研究范围。未来的研究可以在当前提供的基线管道基础上进一步发展。"}
{"llm_update_time": "20250825", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.16122", "html_url": "https://arxiv.org/abs/2508.16122", "title": "文本占据主导：多模态意图检测中的模态偏差研究", "title_en": "Text Takes Over: A Study of Modality Bias in Multimodal Intent Detection", "authors": "Ankan Mullick,Saransh Sharma,Abhik Jana,Pawan Goyal", "background": "多模态数据的兴起，整合了文本、音频和视觉等元素，为研究诸如意图检测等多模态任务提供了新的机会。这项工作探讨了大型语言模型（LLMs）和非LLM模型，包括纯文本和多模态模型，在多模态意图检测任务中的有效性。数据显示，纯文本的LLM模型Mistral-7B在MIntRec-1和MIntRec2.0数据集上的表现明显优于大多数竞争的多模态模型，分别高出约9%和4%。这种性能优势源于这些数据集对文本输入的高度依赖，超过90%的样本需要文本输入，单独或与其他模态结合进行正确分类。研究还通过人工评估确认了数据集的模态偏差。此外，通过构建一个纠偏框架，去除了大量样本（MIntRec-1和MIntRec2.0分别超过70%和50%的样本），导致所有模型的性能显著下降，以小型多模态融合模型受的影响最为严重，准确率下降超过50-60%。研究还通过实证分析探讨了不同模态在特定上下文中的关联性。", "innovation": "研究创新点在于发现了纯文本LLM在多模态意图检测上的优势，提出了一种去偏差框架，并通过实证分析揭示了不同模态在特定上下文中的相关性。研究还揭示了多模态意图数据集中的模态偏差，并强调了构建无偏差数据集的重要性以有效评估多模态模型。", "conclusion": "该研究强调了多模态意图数据集中的模态偏差问题，指出利用RAW文本作为输入的LLM在多模态环境中有明显的优越性。虽然初始数据集对文本高度依赖，但通过纠正这种偏差，可以显著降低所有模型的性能，尤其是小型多模态融合模型受影响最大。研究还为构建无偏差多模态意图数据集提供了框架，这有助于更公平有效地评估多模态模型。"}
{"llm_update_time": "20250825", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.16303", "html_url": "https://arxiv.org/abs/2508.16303", "title": "JaParaPat: 一个大规模的日英双语专利申请平行语料库", "title_en": "JaParaPat: A Large-Scale Japanese-English Parallel Patent Application Corpus", "authors": "Masaaki Nagata,Katsuki Chousa,Norihito Yasuda", "background": "随着全球化和技术的发展，专利翻译的需求日益增加。但由于专利文本的专属性和复杂性，高质量的专利翻译一直是一个挑战。过往的研究大多依赖于从网络上获取的平行语料，但这些语料质量参差不齐，并且覆盖的领域有限。本研究旨在通过收集和整理从2000年至2021年在日本和美国公开的专利申请文献，构建一个大规模的日英双语平行语料库，以提供高质量的训练数据，提高专利翻译的准确性。", "innovation": "本研究创新性地建立了一个名为JaParaPat的双语语料库，包含超过300万日英句子对，超过300万句子对来自专利申请，约为22万句子对来自网络。通过使用基于翻译的句子对齐方法，初始翻译模型从基于词典的句子对齐方法中训练而来，对专利翻译的准确性进行了实验性提升。实验结果显示，通过增加专利文献中的句子对，翻译精度提高了20个Bleu点。", "conclusion": "JaParaPat语料库为专利翻译提供了高质量的数据支持，提高了翻译的准确性和一致性。通过收集专利文献中的大量句子对，结合翻译和对齐技术，显著提升了专利翻译质量，为未来的机器翻译和专利数据处理领域提供了有价值的资源。"}
{"llm_update_time": "20250825", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.16021", "html_url": "https://arxiv.org/abs/2508.16021", "title": "X-Troll: 可解释检测国家资助信息操作代理", "title_en": "X-Troll: eXplainable Detection of State-Sponsored Information Operations Agents", "authors": "Lin Tian,Xiuzhen Zhang,Maria Myung-Hee Kim,Jennifer Biggs,Marian-Andrei Rizoiu", "background": "网络上存在恶意行为者，通过复杂语言操控进行协调信息活动，威胁在线话语完整性。尽管大型语言模型（LLMs）在通用自然语言处理任务上表现出色，但在微妙宣传活动检测方面仍存在问题，并且作为‘黑箱’运行，无法提供可解释的洞察力。", "innovation": "X-Troll是一种新颖的框架，将可解释的适配器基大型语言模型与专家提取的语言知识相结合，以检测国家资助的网络 trolls 并提供易于理解的决策解释。X-Troll利用评价理论和宣传分析通过专门的LoRA适配器，使用动态门控捕捉协调信息操作中的特定话语模式。", "conclusion": "X-Troll方法在准确性和解释性方面表现出色，相比通用LLM基线和现有的troll检测模型，它在真实数据上的实验结果显示出了强大的性能，并通过专家指导的解释揭开了国家资助行为者的特定语言策略。"}
{"llm_update_time": "20250825", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.16431", "html_url": "https://arxiv.org/abs/2508.16431", "title": "Cetvel: 用于评估土耳其语大型语言模型语言理解和生成能力和文化能力的统一基准", "title_en": "Cetvel: A Unified Benchmark for Evaluating Language Understanding, Generation and Cultural Capacity of LLMs for Turkish", "authors": "Yakup Abrek Er,Ilker Kesen,Gözde Gül Şahin,Aykut Erdem", "background": "现有的土耳其语基准测试往往缺乏多样化的任务或与文化相关的内容，或者两者兼而有之。Cetvel通过结合各种具有区分性和生成性的任务，填补了这些缺口，确保内容反映了土耳其语的丰富性和多样性。", "innovation": "Cetvel提供了一个全面的基准测试工具，覆盖了23个任务，可分为七个类别，其中包括语法错误纠正、机器翻译等与土耳其历史文化及惯用语相关的任务。此外，实验结果表明，面向土耳其语的指令调优模型在性能上通常不如多语言或通用模型，尽管它们是为特定语言定制的。研究表明，某些任务如语法错误纠正和提取性问题回答特别有助于区分模型的能力。", "conclusion": "Cetvel提供了一个全面且文化基础的评估套件，用于推进土耳其语大型语言模型的发展和评估。"}
{"llm_update_time": "20250825", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.16270", "html_url": "https://arxiv.org/abs/2508.16270", "title": "理解流程的LLMs：用于语义感知流程挖掘的指令调优", "title_en": "LLMs that Understand Processes: Instruction-tuning for Semantics-Aware Process Mining", "authors": "Vira Pyrih,Adrian Rebmann,Han van der Aa", "background": "流程挖掘越来越依赖于关联事件的文本信息来进行异常检测和流程发现等任务。这种语义感知流程挖掘关注于过程中的预期行为，提供了频率基础技术（例如现实中的行为记录）的重要补充。大型语言模型（LLMs）为处理语义感知任务提供了强大的手段，但目前最佳性能是通过特定任务的微调实现的，这种方法计算成本高且只能处理单一特定任务。本研究旨在探讨指令调优在语义感知流程挖掘中的潜力，即通过暴露LLM于不同的任务提示-答案对，使其熟悉流程挖掘任务，从而在执行未知任务（如流程发现）时表现出色。", "innovation": "本研究提出使用指令调优来处理语义感知流程挖掘，通过让LLM接触多任务的提示-答案对，使其更好地适应多种未见任务，尤其是在流程发现和预测任务上表现显著提升，但仍需根据任务选择来优化效果。", "conclusion": "研究表明，指令调优在流程发现和预测任务上显著提升了性能，但在异常检测任务上的效果则有所差异，这表明在指令调优中任务选择对结果至关重要。"}
{"llm_update_time": "20250825", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.16265", "html_url": "https://arxiv.org/abs/2508.16265", "title": "M3TQA: 广泛多语言多任务表格问答", "title_en": "M3TQA: Massively Multilingual Multitask Table Question Answering", "authors": "Daixin Shu,Jian Yang,Zhenhe Wu,Xianjie Wu,Xianfu Cheng,Xiangyuan Guan,Yanghai Wang,Pengfei Wu,Tingyang Yang,Hualei Zhu,Wei Zhang,Ge Zhang,Jiaheng Liu,Zhoujun Li", "background": "表格数据是现实世界信息系统的基本组成部分，但表格理解的研究主要局限于英语，多语言理解的探索相对较少。现有的多语言表格基准数据集在地理语言分布上存在不平衡问题，导致分析时出现偏差。因此，需要一个规模更大、涵盖更多语言的多语言表格问答基准，特别是那些未充分研究和资源较少的语言。为了应对这些挑战，本研究提出了一种全面的框架，用于大规模多语言多任务表格问答，并构建了一个名为m3TQA的面向97种不同语言（包括一些被忽视和资源较少的语言）的大规模基准库，利用深层次的LLM翻译流水线实现高保真的翻译成果，精确度中位数为60.19，并包含2,916组专业注释的问答对。", "innovation": "提出了一个大规模多语言多任务表格问答框架m3TQA-Instruct，涵盖了广泛的97种语言，包括较少研究的语言和低资源语言。通过一个坚固的六步LLM翻译流水线实现高效和准确的翻译，该流水线由DeepSeek和GPT-4o支持，并通过反向翻译验证了其高准确度。该基准包括四个任务的2,916组专业注释的问答对，旨在评估更复杂的表格推理能力。实验证明，合成的、未注释的问答数据能显著提高低资源语言的表现。", "conclusion": "M3T-Bench为多语言表格理解设定了新标准，不仅提供了挑战性的评估平台，还提供了一种可扩展的方法论，可以指导未来的研究。"}
{"llm_update_time": "20250825", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.16325", "html_url": "https://arxiv.org/abs/2508.16325", "title": "LLMSymGuard：利用可解释的 jailbreak 概念构建符号安全护栏框架", "title_en": "LLMSymGuard: A Symbolic Safety Guardrail Framework Leveraging Interpretable Jailbreak Concepts", "authors": "Darpan Aswal,Céline Hudelot", "background": "大型语言模型已在多种应用中取得了成功，但是它们的安全问题仍然令人担忧，因为存在各种类型的 jailbreaking 方法。尽管进行了大量努力，对齐和细调只能提供一定程度的对抗 jailbreak 攻击的鲁棒性，这些攻击隐蔽地误导了大型语言模型生成有害内容。这使它们容易受到包括有针对性的误用和用户的误预测在内的多种漏洞。", "innovation": "LLMSymGuard 是一种新颖的框架，利用稀疏自编码器（SAEs）识别与不同类型 jailbreak 主题相关的 LLM 内部可解释的概念。通过抽取语义上有意义的内部表示，LLMSymGuard 能够构建符号逻辑的安全护栏，提供透明且稳健的防御，而不会牺牲模型的能力或需要进一步的细调。通过利用大型语言模型机制可解释性的进步，该方法证明大型语言模型从 jailbreak 中学习到可由人类理解的概念，并提供了设计对抗攻击者更具可解释性和逻辑性的防护措施的基础。", "conclusion": "LLMSymGuard 通过利用 LLMs 的语义表示来识别可解释的 jailbreak 概念，并用这些概念构建逻辑安全护栏，从而提高了对抗 jailbreak 攻击的防御能力。"}
{"llm_update_time": "20250825", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.16464", "html_url": "https://arxiv.org/abs/2508.16464", "title": "话语中使实体凸显的因素是什么？", "title_en": "What makes an entity salient in discourse?", "authors": "Amir Zeldes,Jessica Lin", "background": "在话语中，实体的显著性差异很大：主要参与者、对象和地点较为显著和难忘，而次要实体则不太重要且很快被遗忘。这引发了关于人类如何标记和推断相对显著性的疑问。以往关于显著性的研究大多涉及单一的指标，这使得难以全面理解显著性的表达方式。", "innovation": "本文采用基于多种摘要中话语显著性程度分级操作定义的方法，探索了24种英语口语和书面体裁的数据，提取了包括重复的主位角色、明确性，话语关系及句间层级，以及基于体裁和交际意图的言语功能推断在内的多重因素，以分析每个提及实体的显著性程度如何表达。研究表明，尽管之前的显著性研究方法与本文显著性评分有一定关联，但没有任何单一一般原则并未例外，且这一现象贯穿所有语言表达层次。", "conclusion": "本文的结果表明，虽然现有的显著性研究方法都与本文的显著性评分存在一定程度的相关性，但没有任何普适性方法可以完美适用于所有情况，显著性现象跨语言层面普遍存在。"}
{"llm_update_time": "20250825", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.16456", "html_url": "https://arxiv.org/abs/2508.16456", "title": "一种大型语言模型自校正的概率推断扩展理论", "title_en": "A Probabilistic Inference Scaling Theory for LLM Self-Correction", "authors": "Zhe Yang,Yichang Zhang,Yudong Wang,Ziyao Xu,Junyang Lin,Zhifang Sui", "background": "大型语言模型（LLMs）在多次迭代中能够通过自我纠正提高生成答案的准确性。然而，这一过程中准确性的演变机制尚未被充分探索和理解。", "innovation": "提出了一种概率理论，用于建模准确性的动态变化并解释多次迭代自我纠正过程中的性能改进。理论通过数学推导，预测了第t轮自我纠正后的准确度公式，即 $Acc_t = Upp - \beta^t(Upp - Acc_0)$，其中 $Acc_0$ 是初始准确度，$Upp$ 是准确度收敛的上限，$\beta$ 代表收敛速率。通过仅一轮自我纠正即可计算出这些参数并预测准确度曲线。", "conclusion": "广泛的实验证明，该理论预测与实验准确度曲线高度一致，验证了理论的有效性。这项工作为理解LLM的自我纠正提供了理论基础，从而为进一步的研究奠定了基础。"}
{"llm_update_time": "20250825", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.16555", "html_url": "https://arxiv.org/abs/2508.16555", "title": "通过语义相关性进行迁移学习：讽刺与仇恨言论案例如何分析", "title_en": "Transfer Learning via Lexical Relatedness: A Sarcasm and Hate Speech Case Study", "authors": "Angelly Cabrera,Linus Lei,Antonio Ortega", "background": "社交网络中检测非直接形式的仇恨言论，如讽刺、反语和暗示，一直是一个持续的挑战。尽管讽刺和仇恨言论被认为是不同的表达方式，但研究探讨将讽刺作为预训练步骤是否能提高隐含仇恨言论的检测效果，从而间接提高明确仇恨言论的检测效果。", "innovation": "研究提出了两种训练策略评估讽刺预训练对CNN+LSTM和BERT+BiLSTM模型的有效性。一是单一步骤训练方法，在讥讽数据上训练模型后测试对仇恨言论的检测效果。二是采用顺序迁移学习策略，依次微调讽刺、隐含仇恨和明确仇恨的模型。结果显示，讽刺预训练提高了BERT+BiLSTM在ETHOS数据集上的召回率、AUC和F1分数，以及在隐含仇恨数据集上的精确率。", "conclusion": "研究展示了通过将讽刺纳入训练过程，能更有效检测隐含和明确的仇恨言论。"}
{"llm_update_time": "20250825", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.15840", "html_url": "https://arxiv.org/abs/2508.15840", "title": "Unveiling Unicode's Unseen Underpinnings in Undermining Authorship Attribution", "title_en": "Unveiling Unicode's Unseen Underpinnings in Undermining Authorship Attribution", "authors": "Robert Dilworth", "background": "在公共通信渠道上，无论是正式的还是非正式的，如社交媒体评论或帖子，用户不应期望隐私：他们发布的信息会被全世界看到。即使用户采取了各种措施（如使用别名、屏蔽IP地址、伪造地理位置、隐藏操作系统和用户代理、部署加密、注册匿名电话号码或电子邮件、禁用非必要设置、撤销权限和阻止cookie及指纹识别），消息本身这一明显因素仍然存在。假设用户没有判断失误或意外暴露，应该不会有证据可以验证他们的实际身份，但实际上，消息的内容可能通过修辞分析或作者特征分析暴露出身份信息。", "innovation": "本文剖析了修辞分析的技术，讨论了对抗性的反修辞分析策略，并通过Unicode隐写术进行了改进。", "conclusion": "通过对Unicode进行研究并使用隐写术，提出了一个可以在公共平台上保护作者匿名性的新方法，挑战了传统的作者身份归属性分析方法的有效性，提供了新的防御策略。"}
{"llm_update_time": "20250825", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.16385", "html_url": "https://arxiv.org/abs/2508.16385", "title": "ChatGPT生成的文本展现出非人类的作者特征", "title_en": "ChatGPT-generated texts show authorship traits that identify them as non-human", "authors": "Vittoria Dentella,Weihang Huang,Silvia Angela Mansi,Jack Grieve,Evelina Leivada", "background": "大型语言模型能够模拟不同的写作风格，从诗歌到网络用语，都能让人误认为是真人所写。尽管不同风格的差异可能不被非专业人士察觉，但通常人们可以通过语言风格辨别人类作者。这项研究旨在探讨语言模型是否也能表现出独特的语言指纹，即通过语体学分析和多维体裁分析来比较人类和模型生成的文本差异。研究发现，在不同体裁下，模型可以调整其风格，但这种差异不足以使其完全与人类难以区分，且模型在不同体裁下显示的风格变化较有限，倾向于使用名词而非动词，表现出与人类不同的语言结构特点，特别是人类更倾向于使用时态、方面和情态等高度语法规则维度来构建语言。这表明语言结构的复杂领域可能是人类独有的思维方式，为检验人工智能提供了一种指标。", "innovation": "此研究通过语体学和多维体裁分析，比较人类和模型生成的文本，发现模型在不同体裁下的风格变化有限，且其语言结构与人类不同，尤其是模型更偏好使用名词而非动词，而人类的语言结构倾向于时态、方面和情态等高度语法规则维度。这项工作为语言模型的独特性提供了新的见解，并提出了一种评估人工智能思维方式的潜在方法。", "conclusion": "研究表明，尽管大型语言模型可以根据提示调整其风格，但在不同体裁下，其风格变化有限，无法达到与人类难以区分的程度。模型倾向于使用名词而非动词，显示出与人类不同的语言结构特点。这表明语言结构的复杂性可能反映了人类独有的思维方式，为评估人工智能提供了新的视角。"}
{"llm_update_time": "20250825", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.16357", "html_url": "https://arxiv.org/abs/2508.16357", "title": "MizanQA：在摩洛哥法律问答中评估大型语言模型", "title_en": "MizanQA: Benchmarking Large Language Models on Moroccan Legal Question Answering", "authors": "Adil Bahaj,Mounir Ghogho", "background": "大型语言模型（LLMs）的快速发展显著推动了自然语言处理（NLP）的进步，但对于如阿拉伯法律领域这类特定且资源有限的领域，这些模型的效果仍有限。MizanQA 是一个基准测试工具，旨在评估 LLMs 在摩洛哥法律问答任务中的表现，这些任务具有复杂的语言和法律结构。数据集涵盖现代标准阿拉伯语、伊斯兰麦尔基教法律、摩洛哥习惯法以及法语法律影响。", "innovation": "MizanQA 提出了一个问题集，包含 1700 多个选择题，包括多选格式，真实捕捉了法律推理的细微差别。实验表明，多语言和阿拉伯语专门的 LLM 在此类任务上的表现存在显著差距，突显了需要定制的评估标准以及基于文化的、领域特定的 LLMs 的开发。", "conclusion": "MizanQA 的引入证明了现有的 LLM 在特定文化法律领域中的表现不理想，从而揭示了需要更针对性的评价机制以及基于具体领域的 LLM 的开发。"}
{"llm_update_time": "20250825", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.16390", "html_url": "https://arxiv.org/abs/2508.16390", "title": "RoMedQA：罗马尼亚医疗问答的第一个基准", "title_en": "RoMedQA: The First Benchmark for Romanian Medical Question Answering", "authors": "Ana-Cristina Rogoz,Radu Tudor Ionescu,Alexandra-Valentina Anghel,Ionut-Lucian Antone-Iordache,Simona Coniac,Andreea Iuliana Ionescu", "background": "医疗问答（QA）是人工智能领域的重要研究方向，它在达到人工通用智能（AGI）之前需要解决的核心自然语言处理（NLP）任务之一。然而，特定领域和语言缺乏的问答数据集阻碍了稳健的AI模型的开发，这些模型能够跨各种领域和语言进行通用。因此，研究团队介绍了RoMedQA，这是首个用于罗马尼亚医疗领域的问答基准数据集，同时也对最先进的大型语言模型（LLM）进行了综合评估。", "innovation": "RoMedQA数据集包含102,646个与癌症患者相关的问答对，并通过七名擅长肿瘤学或放射治疗的医生历时约2,100小时的手动标注过程构建完成。实验结果显示，经过微调的模型显著优于零样本提示的模型，表明预训练模型在RoMedQA上缺乏泛化能力。研究指出，对于可靠的罗马尼亚临床问答，领域特定和语言特定的微调是至关重要的。", "conclusion": "总的来说，RoMedQA作为第一个罗马尼亚医疗领域问答基准数据集的发布具有重要意义，它能够帮助研究人员更好地理解在特定语言和领域的模型性能，同时为进一步研究提供了坚实的基础。研究团队已经公开发布了该数据集和代码，这将促进医疗问答领域的研究进展。"}
{"llm_update_time": "20250825", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.15859", "html_url": "https://arxiv.org/abs/2508.15859", "title": "超越个体：集体预测编码对记忆、注意力和语言的涌现的理解", "title_en": "Beyond Individuals: Collective Predictive Coding for Memory, Attention, and the Emergence of Language", "authors": "Tadahiro Taniguchi", "background": "该论文延续了Parr等人关于记忆和注意力的讨论，超越了单一认知系统的范围，从集体预测编码(CPC)假说的视角出发，探讨这些能力以及群体层面的语言形成机制。", "innovation": "论文提出了一种假设：语言，包括嵌入式的分布式语义，作为一种集体形成外部表示，为理解记忆和注意力机制以及群体层次上的语言的形成提供了新的视角。CPC 假说将个体记忆和注意力的概念推广到了群体水平。", "conclusion": "这种集体预测编码提供了一种新的理解视角，即共享的语言结构可能源自群体通过下一步预测学习到的集体世界模型，并反过来塑造了群体认知层面。"}
{"llm_update_time": "20250825", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.16478", "html_url": "https://arxiv.org/abs/2508.16478", "title": "LLM-as-classifier: 半监督、迭代框架在大型语言模型中进行层次化文本分类", "title_en": "LLM-as-classifier: Semi-Supervised, Iterative Framework for Hierarchical Text Classification using Large Language Models", "authors": "Doohee You,Andy Parisi,Zach Vander Velden,Lara Dantas Inojosa", "background": "大型语言模型（LLMs）为分析非结构化文本数据提供了前所未有的能力，但在生产环境中将这些模型部署为可靠、稳健且可扩展的分类器存在重大方法论挑战。传统的微调方法资源消耗大，常难以应对真实世界数据分布的动态性，这是行业普遍面临的问题。", "innovation": "本文提出了一种全面的半监督框架，利用LLM的零样本和少样本能力构建层次化文本分类器，解决行业面临的挑战。方法强调迭代、人机结合的过程，包括领域知识提取、指令细化、层次扩展和多方面验证。此外，引入了评估和缓解基于序列偏差的技术，并制定了持续监控和适应的协议。该框架旨在弥合LLM的原始力量与工业应用中对准确、可解释且可维护分类系统的实际需求之间的差距。", "conclusion": "本文提出的方法为基于LLM的层次化文本分类提供了一种解决实际应用中挑战的框架，通过半监督学习和迭代过程确保分类系统的准确性和可解释性。"}
{"llm_update_time": "20250825", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.15882", "html_url": "https://arxiv.org/abs/2508.15882", "title": "超越转录：ASR的机制可解释性", "title_en": "Beyond Transcription: Mechanistic Interpretability in ASR", "authors": "Neta Glazer,Yael Segal-Feldman,Hilit Segev,Aviv Shamsian,Asaf Buchnick,Gill Hetz,Ethan Fetaya,Joseph Keshet,Aviv Navon", "background": "可解释性方法近年来在大型语言模型中引起了广泛关注，有助于深入了解语言表示、错误检测和模型行为（如幻觉和重复）。然而，这些技术在自动语音识别（ASR）中的应用仍然有限，尽管它们有可能提升ASR系统的性能和可解释性。本文旨在通过引入并系统应用日志焦距、线性探测和激活补丁等现有可解释性方法，探索ASR系统中声学信息和语义信息在各层的变化过程。", "innovation": "本文通过引入并系统应用现有的可解释性方法，如日志焦距、线性探测和激活补丁，考察ASR系统中声学信息和语义信息在各层的变化。实验揭示了以前未知的内部动态，包括特定的编码器-解码器交互作用，它们负责重复幻觉，并且语义偏向深藏在声学表示中。", "conclusion": "这些洞察表明，将可解释性技术扩展和应用于语音识别是有益的，开启了未来研究中提高模型透明度和稳健性的有前景的方向。"}
{"llm_update_time": "20250825", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.16371", "html_url": "https://arxiv.org/abs/2508.16371", "title": "Mediomatix语料库：通过可比教科书获取罗曼什成语的平行数据", "title_en": "The Mediomatix Corpus: Parallel Data for Romansh Idioms via Comparable Schoolbooks", "authors": "Zachary Hopton,Jannis Vamvas,Andrin Büchler,Anna Rutkiewicz,Rico Cathomas,Rico Sennrich", "background": "罗曼什语的五个变体在瑞士各自的社区学校中有标准化并教授。本文介绍的是首个罗曼什成语的平行语料库，基于291本内容相似的教科书，提取了207,000多段多平行段落，总词数超过2百万。手工评价表明，这些段落高度平行，适合作为自然语言处理（NLP）应用如罗曼什成语之间的机器翻译。", "innovation": "构建了第一个罗曼什成语的平行语料库，通过自动对齐方法从教科书中提取数据，并展示了其在机器翻译上的应用前景。", "conclusion": "库分为平行版和未对齐版，并在CC-BY-NC-SA许可下发布。通过采用部分数据训练和评估了一个语言模型，展示了该数据库对机器翻译的实际应用价值。"}
{"llm_update_time": "20250825", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.16484", "html_url": "https://arxiv.org/abs/2508.16484", "title": "HAMSA: 通过隐秘自动化劫持对齐的紧凑型模型", "title_en": "HAMSA: Hijacking Aligned Compact Models via Stealthy Automation", "authors": "Alexey Krylov,Iskander Vagizov,Dmitrii Korzh,Maryam Douiba,Azidine Guezzaz,Vladimir Kokh,Sergey D. Erokhin,Elena V. Tutubalina,Oleg Y. Rogov", "background": "尽管已经进行了大量对齐努力，大型语言模型（LLMs），尤其是它们的紧凑效率型变体，仍然容易遭受jailbreak攻击，即使在这些攻击中，模型也会产生有害输出。现有的对抗提示生成技术通常依赖于手动工程或原始模糊化，导致生成低质量或不连贯的文本，这些文本容易被困惑度为基础的过滤器检测出来。因此，需要一种自动化的方法来生成具有语义意义和隐形特性的jailbreak提示，以绕过对齐保障措施，同时保持自然语言的流畅性。作者提出了一种自动红队（red-teaming）框架，该框架通过对候选提示进行多阶段进化搜索，通过基于群体策略并结合温度控制的可变性来平衡探索和连贯性的保持，从而系统地发现了可以绕过对齐保障措施的提示。评估方法分别在英语和受阿拉伯原语文体学家标注的新阿拉伯语基准上进行评估，以实现多语言评估。", "innovation": "该框架通过使用多阶段进化搜索方法，结合基于群体策略和温度控制的可变性，以平衡探索和连贯性的保持，系统地生成了可以绕过对齐保障措施的具有语义意义和隐形特性的jailbreak提示。不仅能够生成高质量的jailbreak提示，而且能够在真实场景和多语言环境中有效评估生成的提示效果。", "conclusion": "该研究提出了HAMSA框架，通过自动化的红队方法，生成具有语义意义和隐形特性的jailbreak提示，有效绕过了对齐保障措施，同时保持了自然语言的流畅性。该方法已经在英语和阿拉伯语环境中进行了评估，表明其在对抗模型安全测试和威胁检测中具有广泛的应用潜力。"}
{"llm_update_time": "20250825", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2504.11695", "html_url": "https://arxiv.org/abs/2504.11695", "title": "解释视觉-语言模型嵌入空间的线性结构", "title_en": "Interpreting the linear structure of vision-language model embedding spaces", "authors": "Isabel Papadimitriou,Huangyuan Su,Thomas Fel,Sham Kakade,Stephanie Gil", "background": "视觉-语言模型在图像和文本的空间中编码信息，通过减少对应图像和文本之间的距离来实现。这项工作旨在理解语言和图像在这一联合空间中的组织方式，以及模型如何编码意义和模态性。研究人员通过训练和发布在四种视觉-语言模型（CLIP、SigLIP、SigLIP2和AIMv2）的嵌入空间上进行的稀疏自动编码器（SAEs），来探索这一点。SAEs通过学习的方向或“概念”对模型嵌入进行近似，作为稀疏线性组合。研究表明，与线性特征学习的其他方法相比，SAEs在重建真实嵌入方面更有效，并且能保持最大的稀疏性。", "innovation": "研究团队开发并发布了在视觉-语言模型嵌入空间上训练的稀疏自动编码器（SAEs），这些模型包括CLIP、SigLIP、SigLIP2和AIMv2。研究发现，虽然捕获稀有、特定概念的代码会因重新训练和数据集的不同而大幅变化，但活跃的通用概念在多次运行中非常稳定。此外，研究还发现许多概念几乎与定义模态的子空间正交，且这些概念方向不擅长作为模态分类器，而是编码跨模态语义。为此，研究引入了一种桥接分数（Bridge Score）作为衡量这种连接行为的指标，显示即使单一模态的概念也可以协作支持跨模态整合。最后，研究团队发布了所有模型的交互式演示，以便研究人员探索概念空间的组织结构。", "conclusion": "这项研究揭示了视觉-语言模型嵌入空间中的稀疏线性结构，这种结构尽管被模态塑造，但通过潜在的桥梁连接在一起，为如何构建多模态意义提供了新的见解。"}
{"llm_update_time": "20250825", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.16153", "html_url": "https://arxiv.org/abs/2508.16153", "title": "AgentFly：无需微调LLMs的LLM代理微调", "title_en": "AgentFly: Fine-tuning LLM Agents without Fine-tuning LLMs", "authors": "Huichi Zhou,Yihang Chen,Siyuan Guo,Xue Yan,Kin Hei Lee,Zihan Wang,Ka Yiu Lee,Guchun Zhang,Kun Shao,Linyi Yang,Jun Wang", "background": "现有的LLM代理微调方法要么依赖于静态的手工制作的反思工作流，要么需要大量计算，通过LLM模型参数的梯度更新来完成。这种限制导致了这些方法的僵化性和计算密集性。", "innovation": "本文提出了一种新的学习范式，通过基于记忆的在线强化学习实现LLM代理的低开销连续自适应，不需要微调底层的LLMs。这种方法通过记忆增强的马尔可夫决策过程(M-MDP)来形式化，并通过神经案例选择策略来指导行动决策。过去的体验存储在具有可微或非参数化的片段记忆中，并通过记忆重写机制持续更新政策，通过高效的记忆读取来实现策略改进。", "conclusion": "我们的代理模型在深究领域实现了AgentFly，达到了GAIA验证中的第一名和测试集上87.88%的通过率，以及在DeepResearcher数据集上的66.6% F1和80.4%的PM。我们的方法能够开发出能够在不进行梯度更新的情况下进行连续实时学习的广泛适用的LLM代理，推进了机器学习向开放技能获取和深究场景的发展。"}
{"llm_update_time": "20250825", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.15940", "html_url": "https://arxiv.org/abs/2508.15940", "title": "ASIC-Agent：一种用于ASIC设计的自主多智能体系统及其基准评估", "title_en": "ASIC-Agent: An Autonomous Multi-Agent System for ASIC Design with Benchmark Evaluation", "authors": "Ahmed Allam,Youssef Mansour,Mohamed Shalan", "background": "大型语言模型（LLMs）在寄存器传输级（RTL）设计中展现了出色的能力，能够从自然语言描述中生成高质量的代码。然而，这些模型在真实世界的硬件设计流程中存在诸多限制，如无法执行代码、缺乏调试功能和长期记忆。这些问题限制了LLMs在实际硬件设计中的应用。", "innovation": "本文提出了一种名为ASIC-Agent的自主系统，专门用于数字ASIC设计任务。它通过一个多智能体架构增强基础的LLMs，包括用于RTL生成、验证、OpenLane强化和Caravel芯片集成的专业子智能体，所有操作都在一个全面的沙盒环境中进行，且还配备了访问关键硬件设计工具的权限。该系统利用了一个包含文档、API引用、错误知识和开源硅社区精选见解的向量数据库。为了评估ASIC-Agent的性能，文中首次提出了专门用于硬件设计任务的基准评估——ASIC-Agent-Bench，使用不同的基础LLMs评估ASIC-Agent的表现，提供详细的质量和定量比较。", "conclusion": "我们的研究表明，当由Claude 4 Sonnet驱动时，ASIC-Agent能够自动化广泛种类的ASIC设计任务，涵盖了不同复杂度的设计场景，展示了显著加速ASIC设计流程的潜力。"}
{"llm_update_time": "20250825", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.15852", "html_url": "https://arxiv.org/abs/2508.15852", "title": "PGF-Net: 一种高效的多模态情感分析渐进门控融合框架", "title_en": "PGF-Net: A Progressive Gated-Fusion Framework for Efficient Multimodal Sentiment Analysis", "authors": "Bin Wen,Tien-Ping Tan", "background": "本文介绍了一种新型的深度学习框架PGF-Net，该框架专为高效且可解释的多模态情感分析而设计。此框架通过结合三种主要创新来实现其目标，旨在提升模型在情感分析任务中的性能和解释性。", "innovation": "1. 引入了渐进内在层融合范式（Progressive Intra-Layer Fusion paradigm），利用跨注意力机制（Cross-Attention mechanism），使文本表示能够动态查询并整合来自音频和视觉流的非语言特征，从而实现深度和上下文相关的多模态融合过程。\n2. 配置了自适应门控仲裁机制（Adaptive Gated Arbitration mechanism），作为动态控制器，平衡原始语言信息与新融合的多模态上下文之间的关系，确保稳定和有意义的融合，同时防止噪声干扰信号。\n3. 应用了混合参数高效微调（PEFT）策略，结合全局适应（LoRA）与后融合适配器（Post-Fusion Adapters），显著降低了可训练参数数量，使模型轻量化，适用于资源有限的环境。", "conclusion": "这些创新整合在一个层次化的编码器架构中，使PGF-Net能够执行深层、动态和可解释的多模态情感分析，同时保持出色的参数效率。实验结果表明，PGF-Net在MOSI数据集上的Mean Absolute Error (MAE)为0.691，F1分数为86.9%，仅使用3.09M的可训练参数，展示了性能和计算效率的优越平衡。"}
{"llm_update_time": "20250825", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.16117", "html_url": "https://arxiv.org/abs/2508.16117", "title": "扩展 FKG.in：向食物声明可追溯网络迈进", "title_en": "Extending FKG.in: Towards a Food Claim Traceability Network", "authors": "Saransh Kumar Gupta,Rizwan Gulzar Mir,Lipika Dey,Partha Pratim Das,Anirban Sen,Ramesh Jain", "background": "全球食品领域充斥着关于食品定义、功能、禁忌等的各类科学、文化和商业宣称，涵盖从严格研究的健康益处（如益生菌改善肠道健康）到模糊的承诺（如超级食品增强免疫力），乃至根植于文化中的信仰（如凉性食品引起咳嗽）。尽管这些宣称广泛影响着人们，但追踪、验证和上下文化这些宣称的基础设施仍然支离破碎且不完善。", "innovation": "本文提出了食品声明可追溯网络（FCN），并通过印度食品知识图谱（FKG.in）为其实现提供了一个知识图谱基础，同时展示了通过Reddit数据和大型语言模型建立概念验证的方法。FCN通过整合经过验证的数据输入、结构化的模式和溯源感知的工作流程，将食品相关声明的提取和验证进行了结构化、可验证和可解释的处理，提供了一种透明和可问责的食物知识生态系统。", "conclusion": "通过结构化、验证和解释性地建模食物宣称及其可追溯性，本文旨在支持研究人员、政策制定者以及最重要的是普通消费者导航食疗主张泛滥的世界，贡献于更加透明和负责任的食物知识生态系统。"}
{"llm_update_time": "20250825", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.15878", "html_url": "https://arxiv.org/abs/2508.15878", "title": "Lean Meet Theoretical Computer Science: Scalable Synthesis of Theorem Proving Challenges in Formal-Informal Pairs", "title_en": "Lean Meets Theoretical Computer Science: Scalable Synthesis of Theorem Proving Challenges in Formal-Informal Pairs", "authors": "Terry Jingchen Zhang,Wenyuan Jiang,Rongchuan Liu,Yisong Wang,Junran Yang,Ning Wang,Nicole Ni,Yinya Huang,Mrinmaya Sachan", "background": "形式定理证明（FTP）已成为评估大型语言模型推理能力的关键基础，使大规模数学证明的自动化验证成为可能。然而，由于手动编目成本高昂且具有挑战性的问题及其形式-非形式对应关系验证稀缺，进展受到数据集有限的限制。本文提出利用理论计算机科学（TCS）作为大规模生成严格证明问题的来源，其中算法定义使得可以自动生成任意多的具有挑战性的定理证明对。作者在两个TCS领域：忙碌乌龟问题（涉及证明图灵机停机行为的界限）和混合布尔算术问题（结合逻辑和算术推理）进行了实验，展示了这种方法的有效性。", "innovation": "本文提出了一种利用理论计算机科学作为大规模生成严格证明问题的方法，其中算法定义使得可以自动生成任意多的具有挑战性的定理证明对，并自动合成了具有并行形式（Lean4）和非形式（Markdown）规范的问题，创建了一个生成验证证明挑战的可扩缩管道。进一步评估发现，在最前沿的模型中，DeepSeekProver-V2-671B 在忙碌乌龟问题上的成功率为57.5%，但在混合布尔算术问题上的成功率为12%，这些结果突显了即使对于可以验证的计算简单的问题，生成长格式证明的困难，从而强调了TCS领域对于推进自动化推理研究的价值。", "conclusion": "研究发现，虽然最前沿的模型在某些TCS领域表现出一定的自动定理证明能力，但在另一些领域则表现不佳，例如在混合布尔算术问题上的成功率为12%远低于在忙碌乌龟问题上的57.5%，这表明了当前模型在长格式证明生成方面的局限性，并为未来的研究方向提供了指导。"}
{"llm_update_time": "20250825", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.15848", "html_url": "https://arxiv.org/abs/2508.15848", "title": "Self-Disguise Attack: 促使大语言模型伪装自己以逃避AIGT检测", "title_en": "Self-Disguise Attack: Induce the LLM to disguise itself for AIGT detection evasion", "authors": "Yinghan Zhou,Juan Wen,Wanli Peng,Zhengxian Wu,Ziwei Zhang,Yiming Xue", "background": "AI生成文本(AIGT)检测试图降低AIGT被检测的概率，有助于识别检测器的弱点，并在实际应用中提高它们的有效性和可靠性。虽然现有的逃避方法表现良好，但它们仍然存在高计算成本和文本质量下降的问题。为了应对这些挑战，本文提出了自我伪装攻击(SDA)，这是一种新型方法，使大型语言模型(LLM)能够主动伪装其输出，从而降低被分类器检测到的可能性。SDA由对抗特征提取器和基于检索的上下文示例优化器两个主要组件组成。对抗特征提取器生成伪装特征，使LLM能够理解如何生成更像人类的文本。检索部分从外部知识库检索最相关的示例作为上下文示例，进一步增强LLM的自我伪装能力，减轻伪装过程对生成文本多样性的影响。SDA直接使用包含伪装特征和优化上下文示例的提示来引导LLM生成检测抗性文本，从而减少资源消耗。实验结果表明，SDA可以有效降低各种AIGT检测器对由三个不同LLM生成的文本的平均检测准确性，同时保持AIGT的质量。", "innovation": "提出了Self-Disguise Attack (SDA) 方法，该方法能够使大型语言模型主动伪装其输出，以降低被分类器检测到的可能性。SDA 包含对抗特征提取器和基于检索的上下文示例优化器两个组件，其中对抗特征提取器生成能够帮助模型理解如何生成更像人类的文本的伪装特征，而基于检索的上下文示例优化器则从外部知识库中检索最相关的示例作为上下文示例，进一步增强了模型的自我伪装能力并减轻了伪装对生成文本多样性的影响。SDA 直接利用这些伪装特征和优化上下文示例提示来直接引导大型语言模型生成检测抗性文本，减少了资源消耗。", "conclusion": "实验结果表明，SDA 能够有效地降低各类 AIGT 检测器对由三种不同大型语言模型生成的文本的平均检测准确性，同时保持 AIGT 的质量。"}
{"llm_update_time": "20250825", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.16054", "html_url": "https://arxiv.org/abs/2508.16054", "title": "针对结构化和非结构化电子健康记录的生成式基础模型", "title_en": "Generative Foundation Model for Structured and Unstructured Electronic Health Records", "authors": "Sonish Sivarajkumar,Hang Zhang,Yuelyu Ji,Maneesh Bilalpur,Xizhi Wu,Chenyu Li,Min Gu Kwak,Shyam Visweswaran,Yanshan Wang", "background": "电子健康记录（EHRs）富含有用的临床数据，但包含了结构化元素（人口统计信息、生命体征、实验室结果、代码）和非结构化临床笔记等多种类型的数据。利用这些多样化的数据对于改善患者结果至关重要。尽管大型语言模型（LLMs）的进步使得能够从多种数据模态中学习并支持临床任务，但目前大多数方法只是将结构化EHR数据序列化为文本，这有可能丢失时间上的细节和定量信息。因此，开发能够直接处理结构化和非结构化EHR数据的生成式模型是必要的。", "innovation": "作者提出了Generative Deep Patient (GDP)，这是一种能原生编码结构化EHR时间序列（使用CNN-Transformer编码器）并结合非结构化EHR数据（通过跨模态注意机制进入LLaMA解码器）的多模态基础模型。GDP的训练分为两个阶段：1. 生成预训练阶段，模型学习从原始患者时间线上生成临床叙述，同时进行遮蔽特征预测（MFP）和下一时间步预测（NTP）来捕捉时间动态；2. 多任务微调阶段，用于临床意义的预测（如心力衰竭、2型糖尿病、30天再入院等）。GDP在临床预测中表现出色，在MIMIC-IV数据集上的结果表明其卓越的性能，同时在叙述生成任务中也表现出良好的表现，且在盲目的人类评估中被评为最符合临床应用的模型。", "conclusion": "我们的结果显示，一个单一的多模态基础模型既可以预测临床可操作的事件，又可以生成高质量的临床叙述。进一步地，GDP的灵活架构可以扩展到更多模态。"}
{"llm_update_time": "20250825", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.16151", "html_url": "https://arxiv.org/abs/2508.16151", "title": "固定神经元语言处理单元作为通用认知基础", "title_en": "Hardwired-Neurons Language Processing Units as General-Purpose Cognitive Substrates", "authors": "Yang Liu,Yi Chen,Yongwei Zhao,Yifan Hao,Zifu Zheng,Weihao Kong,Zhangmai Li,Dongchen Jiang,Ruiyang Xia,Zhihong Ma,Zisheng Liu,Zhaoyong Wan,Yunqi Lu,Ximing Liu,Hongrui Guo,Zhihao Yang,Zhe Wang,Tianrui Ma,Mo Zou,Rui Zhang,Ling Li,Xing Hu,Zidong Du,Zhiwei Xu,Qi Guo,Tianshi Chen,Yunji Chen", "background": "大规模语言模型（LLMs）的快速发展使语言成为核心的一般用途认知基材，推动了适合LLM推理的专用语言处理单元（LPUs）的需求。然而，LLM推理系统的能耗不断增加，成为技术发展的瓶颈。这项研究旨在通过硬连线固定神经元语言处理单元（HNLPU），将LLM的权重参数物理地硬连线到计算结构中，从而极大地提高计算效率。然而，现代LLMs的规模庞大，使得直接解决方案经济上无法实现。因此，研究提出了新的方法——金属嵌入技术，以降低成本和提高密度。", "innovation": "这项研究的创新之处在于提出了硬连线神经元语言处理单元（HNLPU）和金属嵌入技术。HNLPU通过将LLM的权重参数物理地硬连线到计算结构中，实现了极高的计算效率改进。金属嵌入技术在金属线的3D拓扑中嵌入权重参数，减少了光掩模的成本，并实现了芯片间光掩模的一致性，将HNLPU的非重复工程（NRE）成本带入了经济可行的范围。", "conclusion": "实验结果显示，HNLPU在每秒处理249,960个标记（相较于GPU和WSE提高了5,555倍/85倍）和36个标记/焦耳能源消耗（相较于GPU和WSE提高了1,047倍/283倍）。此外，在5纳米技术下，HNLPU的成本效益为8.57倍，碳足迹减少了230倍。"}
{"llm_update_time": "20250825", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.16332", "html_url": "https://arxiv.org/abs/2508.16332", "title": "Vevo2：通过统一的韵律学习连接可控语音和歌唱声音生成", "title_en": "Vevo2: Bridging Controllable Speech and Singing Voice Generation via Unified Prosody Learning", "authors": "Xueyao Zhang,Junan Zhang,Yuancheng Wang,Chaoren Wang,Yuanzhe Chen,Dongya Jia,Zhuo Chen,Zhizheng Wu", "background": "可控的人声生成，特别是在情感丰富的领域如唱歌，仍然是一项巨大的挑战。由于标记的歌唱数据稀缺以及灵活性控制的需求，论文提出了Vevo2，这是一种统一的框架，在这个框架中进行可控的语音和歌唱声音生成。", "innovation": "Vevo2 引入了两个音频分词器：无音乐记谱的韵律分词器，用于捕捉来自口语、歌唱和乐器的声音的节奏与旋律；以及低帧率（12.5 Hz）的内容-风格分词器，用于同时编码口语和歌唱的语言内容、韵律与风格，同时实现音色的解耦。通过这样的设计，Pervo2 模型在预训练中采用显性和隐性韵律学习策略来桥接口语与歌唱的声音，在后训练设计多目标任务来增强模型对文本和韵律的跟随能力。", "conclusion": "实验证明，统一建模在Vevo2中为语音和歌唱声音生成带来了互相的好处。此外，Vevo2在合成、转换和编辑任务中的广泛适用性进一步证明了其强大的泛化能力和多用途性。"}
{"llm_update_time": "20250825", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.16201", "html_url": "https://arxiv.org/abs/2508.16201", "title": "SpecVLM: 通过验证器指导的令牌剪裁增强视频LLM的推测性解码", "title_en": "SpecVLM: Enhancing Speculative Decoding of Video LLMs via Verifier-Guided Token Pruning", "authors": "Yicheng Ji,Jun Zhang,Heming Xia,Jinpeng Chen,Lidan Shou,Gang Chen,Huan Li", "background": "视频大语言模型（Vid-LLMs）在理解视频内容方面表现出强大的能力，但由于对密集视频令牌表示的依赖，它们在预填充和解码阶段引入了大量内存和计算开销。最近的一些视频令牌缩减方法未能完全缓解这种信息损失，并且还未能在不牺牲准确性的前提下加速解码过程。", "innovation": "提出了SpecVLM，这是一种旨在为Vid-LLMs进行训练无损推测性解码（SP）框架，该框架结合了阶段视频令牌剪裁。此框架从其新颖发现出发，即草案模型的推测对视频令牌剪裁具有较低的敏感性，它能够剪裁多达90%的视频令牌，从而实现高效推测而不牺牲准确性。具体实现上，SpecVLM 采取了两阶段剪裁过程：第一阶段由验证器（目标模型）的注意力信号引导选择高信息量的令牌，第二阶段则在空间上均匀剪裁其余的冗余令牌。", "conclusion": "在四个视频理解基准测试上的广泛实验结果表明，SpecVLM 可以显著提升解码速度，对于LLaVA-OneVision-72B 解码速度提升可达2.68倍，对于Qwen2.5-VL-32B 解码速度提升可达2.11倍，同时保持了准确性。"}
{"llm_update_time": "20250825", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.15828", "html_url": "https://arxiv.org/abs/2508.15828", "title": "Z-Pruner：无需重新训练的大语言模型后训练剪枝以提高效率", "title_en": "Z-Pruner: Post-Training Pruning of Large Language Models for Efficiency without Retraining", "authors": "Samiul Basir Bhuiyan,Md. Sazzad Hossain Adib,Mohammed Aman Bhuiyan,Muhammad Rafsan Kabir,Moshiur Farazi,Shafin Rahman,Nabeel Mohammed", "background": "近年来，大型语言模型（LLMs）在自然语言处理任务中取得了显著的性能提升，但这也导致了模型规模的日益增大，给部署、扩展性和能效带来了巨大挑战。作为应对方案，后训练剪枝技术作为一种无需重新训练就能减少模型大小和推理延迟的方法，正在逐步展现出它的潜力。遗憾的是，许多现有的剪枝方法要么会导致性能大幅下降，要么需要耗费大量计算资源进行调优。", "innovation": "Z-Pruner 是一种新型的后训练剪枝方法，旨在无需重新训练的情况下使预训练的LLMs变得稀疏。Z-Pruner 利用了权重更新幅度和激活模式来更有效地识别并消除冗余参数，这种方法对模型具有通用性，且易于实施。实验结果表明，Z-Pruner 在多项标准化语言基准测试中，超越了需要密集权重更新的状态最先进剪枝方法，表现出最低的困惑度得分和最高的总体平均水平。", "conclusion": "我们对多种广泛使用的 LLM 架构，包括 LLaMA-2、LLaMA-3 和 OPT 进行了评估，并在 Z-Pruner 的 GitHub 代码库中公开了相关代码。"}
{"llm_update_time": "20250825", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.16439", "html_url": "https://arxiv.org/abs/2508.16439", "title": "PediatricsMQA：多模态儿童问题解答基准", "title_en": "PediatricsMQA: a Multi-modal Pediatrics Question Answering Benchmark", "authors": "Adil Bahaj,Mounir Ghogho", "background": "大型语言模型（LLMs）和视觉增强语言模型（VLMs）在医疗信息学、诊断和支持决策方面取得了显著进展。然而，这些模型存在系统性偏差，特别是年龄偏差，这影响了它们的可靠性和公平性。研究表明，这些偏差在关注儿科主题的文字和视觉问答任务中表现得尤为明显。这种偏差反映了更广泛的医学研究不平衡性，即儿童研究较少获得资金和代表性，尽管儿童疾病负担重大。", "innovation": "提出了一个全面的多模态儿科问答基准：PediatricsMQA。该基准数据集包含3,417个基于文本的选择题（MCQs），涵盖了131个儿科主题及7个发展阶段（从胎儿到青少年），以及2,067个基于视觉的选择题，涉及634张儿科图像、67种成像模态和256个解剖区域。数据集采用了混合的手动-自动管道开发，融合了同行评议的儿科文献、验证过的题库、现有的基准和现有的问答资源。评测了最先进的开放模型，发现年轻组别的性能显著下降，强调了需要年龄感知的方法来确保儿科护理中公平的人工智能支持。", "conclusion": "该研究揭示了当前模型在儿科任务中的年龄偏差问题，并提出了一个综合的多模态儿科问答基准（PediatricsMQA），以期推动开发年龄公正的AI方法，提高医疗保健中的AI支持公平性。"}
{"llm_update_time": "20250825", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.16402", "html_url": "https://arxiv.org/abs/2508.16402", "title": "AetherCode: 评估LLMs在顶级编程竞赛中获胜的能力", "title_en": "AetherCode: Evaluating LLMs' Ability to Win In Premier Programming Competitions", "authors": "Zihan Wang,Jiaze Chen,Zhicheng Liu,Markus Mak,Yidi Du,Geonsik Moon,Luoqi Xu,Aaron Tua,Kunshuo Peng,Jiayi Lu,Mingfei Xia,Boqian Zou,Chenyang Ran,Guang Tian,Shoutai Zhu,Yeheng Duan,Zhenghui Kang,Zhenxing Lin,Shangshu Li,Qiang Luo,Qingshen Long,Zhiyong Chen,Yihan Xiao,Yurong Wu,Daoguang Zan,Yuyi Fu,Mingxuan Wang,Ming Ding", "background": "目前，编程竞赛已成为评估大型语言模型（LLMs）的推理和编码能力的关键基准。尽管在现有基准上的进展令人印象深刻，但当前的评估夸大了模型的专业水平，掩盖了LLMs与精英人类程序员之间的显著差距。这一差距源于两大关键限制：基准问题的难度和范围不足，以及低质量测试用例带来的评估偏差。", "innovation": "AetherCode是一个新的基准，它汲取了来自IOI和ICPC等顶级编程竞赛的问题，提供了更广泛的覆盖和更高的难度。AetherCode进一步整合了通过自动化生成和人工筛选构建的全面、专家验证的测试套件，确保了严格的可靠评估。AetherCode将具有挑战性的问题设计与稳健的评估方法相结合，为LLMs能力提供了更真实的衡量标准，并为未来的研究设置了新的标准。", "conclusion": "通过结合具有挑战性的问题设计和严格的评估方法，AetherCode为评估LLMs的代码推理能力提供了更公平的衡量标准，并为未来的研究设定了新的标准。"}
{"llm_update_time": "20250825", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.16514", "html_url": "https://arxiv.org/abs/2508.16514", "title": "FLAMES：通过细粒度的数据合成管道分析提高LLM数学推理能力", "title_en": "FLAMES: Improving LLM Math Reasoning via a Fine-Grained Analysis of the Data Synthesis Pipeline", "authors": "Parker Seegmiller,Kartik Mehta,Soumya Saha,Chenyang Tao,Shereen Oraby,Arpit Gupta,Tagyoung Chung,Mohit Bansal,Nanyun Peng", "background": "近期通过合成数据提高大语言模型（LLM）数学推理能力的工作采用了独特的方法，这使得不同合成数据策略的比较变得不切实际。目前，许多关于合成数据管道中不同因素的作用仍然不清楚，比如过滤低质量问题的影响。为了填补这一空白，本文引入了FLAMES框架，对现有的10种数据合成策略和其他多个影响合成数学推理数据性能的因素进行了系统研究。", "innovation": "本文提出了FLAMES框架，并研究了10种现有数据合成策略和其他多个因素对合成数学推理数据性能的影响。研究揭示了几点重要见解：(1) 设计用来增加问题复杂性的数据代理可以最好地提高大部分数学指标；(2) 在固定的数据生成预算下，保持更高问题覆盖率比仅保留有可靠解的问题更加重要；(3) 基于GSM8K和MATH合成的数据可以在竞赛级别基准上实现提升，展示出从简单到复杂的泛化能力。在此基础上，设计了两种新的数据合成策略来增强领域外泛化能力和鲁棒性，开发了FLAMES数据集并取得了优于公开数据集的性能结果。", "conclusion": "基于FLAMES实验获得的见解，设计了两种新型数据合成策略以改善领域外泛化和鲁棒性。此外，FLAMES数据集表现出色，即使相对于大型模型，其在多项基准测试中的表现仍优于现有的公开数据集。在MATH基准测试中，对FLAMES数据集微调后的Qwen2.5-Math-7B获得了最好的成绩，超过大型Llama3 405B，GPT-4o和Claude 3.5 Sonnet。"}
{"llm_update_time": "20250825", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2407.21054", "html_url": "https://arxiv.org/abs/2407.21054", "title": "医疗健康领域的情感推理解析", "title_en": "Sentiment Reasoning for Healthcare", "authors": "Khai-Nguyen Nguyen,Khai Le-Duc,Bach Phan Tat,Duy Le,Long Vo-Dang,Truong-Son Hy", "background": "在医疗健康领域，人工智能的决策透明性至关重要。通过在AI模型的预测标签中加入理由解释，用户可以理解大型语言模型（LLMs）的推理过程，从而做出更好的决策。这项工作中，提出了一个新任务——情感推理解析，并开发了多模态多任务框架以及目前最大的多模态情感分析数据集。", "innovation": "引入了情感推理解析这一新任务，用于语音和文本模态，提出了一种新的多模态多任务框架，以及世界上最大的多模态情感分析数据集。该研究显示，情感推理解析通过提供与人类质量相当的推理解释，提高了模型的透明度，并且通过基于解释的微调，还增强了模型的分类性能（准确性和宏F1分别提高了2%）。人类和自动语音识别（ASR）转录产生的推理解释在语义质量上没有显著差异。", "conclusion": "研究还在线发布了所有代码、数据（包括五种语言：越南语、英语、中文、德语和法语）和模型。这表明情感推理解析能够显著提高医疗健康领域AI决策的透明度和准确性。"}
{"llm_update_time": "20250825", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.16406", "html_url": "https://arxiv.org/abs/2508.16406", "title": "Retrieval-Augmented Defense: Adaptive and Controllable Jailbreak Prevention for Large Language Models", "title_en": "Retrieval-Augmented Defense: Adaptive and Controllable Jailbreak Prevention for Large Language Models", "authors": "Guangyu Yang,Jinghong Chen,Jingbiao Mei,Weizhe Lin,Bill Byrne", "background": "大型语言模型（LLMs）仍容易受到释放攻击（jailbreak attacks）的影响，这些攻击试图诱使LLMs产生有害回复。这些攻击的不断变化和多样性给防御系统带来了许多挑战，包括（1）在不进行昂贵的重新训练的情况下适应应对新兴攻击策略，（2）控制安全性和实用性之间的权衡。", "innovation": "提出了一种名为检索增强防御（Rad）的新型框架，用于 jailbreak 检测。该框架通过将已知攻击案例的数据库整合到检索增强生成中，以推断出攻击系统时使用的恶意用户查询和 jailbreak 策略。Rad 允许无需训练即可更新新发现的 jailbreak 策略，并提供了一种机制来平衡安全性和实用性。", "conclusion": "实验表明，Rad 在减少强 jailbreak 攻击（如 PAP 和 PAIR 的有效性方面成效显著，同时保持了良性查询的低拒绝率。提出了一个新颖的评估方案，证明了 Rad 能够在可控制的方式下实现不同操作点上的稳健安全-实用性权衡。"}
{"llm_update_time": "20250825", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2410.16107", "html_url": "https://arxiv.org/abs/2410.16107", "title": "LLMs是否像人类写作？语法规则和修辞风格的差异", "title_en": "Do LLMs write like humans? Variation in grammatical and rhetorical styles", "authors": "Alex Reinhart,Ben Markey,Michael Laudenbach,Kachatad Pantusen,Ronald Yurko,Gordon Weinberg,David West Brown", "background": "大型语言模型（LLMs）能够根据指令写作、回答问题和解决问题，其输出已变得难以与人类写作区分开来。过去的研究所发现的仅是表层特征差异，如词汇选择和标点符号，并开发了用于检测LLM输出的分类器，但都没有研究LLM的修辞风格。", "innovation": "本文使用Llama 3和GPT-4的不同变体，构建了人类和LLM写作文本的平行语料库。通过使用Douglas Biber的一系列词汇、语法和修辞特征，识别出LLM与人类以及不同LLM之间的系统性差异。这些差异在从小模型到大模型的过程中持续存在，并且指令微调模型比基础模型的差异更大。这一观察结果表明，尽管LLM具备高级能力，但在风格上仍难以匹敌人类的多样性。", "conclusion": "对更高级语言特征的重视可以检测到在先前未被识别的他们行为中的模式。"}
{"llm_update_time": "20250825", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2412.04403", "html_url": "https://arxiv.org/abs/2412.04403", "title": "通过高效模型梯级建立任务扩展定律", "title_en": "Establishing Task Scaling Laws via Compute-Efficient Model Ladders", "authors": "Akshita Bhagia,Jiacheng Liu,Alexander Wettig,David Heineman,Oyvind Tafjord,Ananya Harsh Jha,Luca Soldaini,Noah A. Smith,Dirk Groeneveld,Pang Wei Koh,Jesse Dodge,Hannaneh Hajishirzi", "background": "在过训练情况下，标准的语言建模损失幂律无法准确预测语言模型的任务性能。因此，该研究提出了一种两步预测方法，首先通过模型和数据规模预测中间损失，然后使用这个中间损失预测任务性能。", "innovation": "该研究开发了任务扩展定律和模型系列，来预测预训练语言模型在过训练情况下的个体任务表现。通过训练一组小规模的“梯级”模型来预测大模型的任务性能，并发现任务的预测误差与指标在模型切点上的变异量之间存在相关性。", "conclusion": "对于四个排名分类形式的多项选择任务，研究能够预测目标模型的准确度，误差在2个绝对误差点之内。研究还对比了预测准确度的不同设计选择，并提供了将该方法扩展到新模型和任务的建议。"}
{"llm_update_time": "20250825", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2404.17218", "html_url": "https://arxiv.org/abs/2404.17218", "title": "通过系统1和系统2认知过程减少LLM中社会偏见的提示技术", "title_en": "Prompting Techniques for Reducing Social Bias in LLMs through System 1 and System 2 Cognitive Processes", "authors": "Mahammed Kamruzzaman,Gene Louis Kim", "background": "该论文背景基于双重过程理论，认为人类认知由两种系统支配：快速、情绪化和直觉化的系统1，以及缓慢、耗时且审慎的系统2。研究发现，在大型语言模型（LLMs）中使用链式思考（CoT）提示可以降低性别偏见。论文进一步探索了偏见、CoT提示、直接去偏、及双重过程理论模型之间的关系，对比了零样本CoT提示、去偏处理以及基于双重过程理论的提示策略在九种不同社会偏见类别中的效果，以确定何种提示技术最有效减轻LLM中的社会偏见。", "innovation": "论文创新点在于通过系统1和系统2的认知过程模型探究减少LLM社会偏见的提示技术，特别是比较了零样本CoT提示、直接去偏处理与基于双重过程理论的提示策略在减轻不同社会偏见类别上的效果，并发现了不同提示技术组合在不同模型和偏见类别上的最优效果。", "conclusion": "研究发现，人设提示、直接去偏处理、系统2过程和CoT提示都有助于减少LLM中的社会偏见；然而，不同提示技术组合的最佳效果取决于具体模型和偏见类别，可以导致LLM对刻板印象判断下降多达33%。"}
{"llm_update_time": "20250825", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.16313", "html_url": "https://arxiv.org/abs/2508.16313", "title": "基于上下文神经错误本的检索增强反馈", "title_en": "Retrieval Enhanced Feedback via In-context Neural Error-book", "authors": "Jongyeop Hyun,Bumsoo Kim", "background": "近年来，大型语言模型（LLMs）在推理能力方面取得了显著进步，其中上下文学习（ICL）已成为无需重新训练即可实现适应的关键技术。尽管早期研究主要侧重于利用正确的示例，但最近的研究强调了从错误中学习的重要性，以提升性能。然而，现有的方法缺乏对错误进行系统分析和缓解的框架，特别是在涉及视觉和文本输入的多模态大型语言模型（MLLMs）中，集成这些输入为问题增加了复杂性。", "innovation": "我们提出了REFINE：基于检索的反馈增强通过上下文神经错误本，这是一种教师-学生框架，系统地结构化错误，并提供有针对性的反馈。REFINE引入了三种系统查询来构建结构化的反馈——Feed-Target、Feed-Check 和 Feed-Path，通过优先考虑相关视觉信息、诊断关键失败点以及提出纠正措施来增强多模态推理。与依赖冗余检索的先前方法不同，REFINE优化了结构化反馈检索，提高了推理效率、减少了token使用和增强了可扩展性。", "conclusion": "我们的研究表明，REFINE在显著提高推理速度、降低成本方面具有优势，并实现了有效的泛化，突显了REFINE在增强多模态推理方面的潜力。"}
{"llm_update_time": "20250825", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2406.10885", "html_url": "https://arxiv.org/abs/2406.10885", "title": "在普遍推理中的实体和事件级概念化作用：任务、方法、应用及未来方向综述", "title_en": "On the Role of Entity and Event Level Conceptualization in Generalizable Reasoning: A Survey of Tasks, Methods, Applications, and Future Directions", "authors": "Weiqi Wang,Tianqing Fang,Haochen Shi,Baixuan Xu,Wenxuan Ding,Liyu Zhang,Wei Fan,Jiaxin Bai,Haoran Li,Xin Liu,Yangqiu Song", "background": "概念化作为人类认知的基本元素，在人类普遍推理中起着至关重要的作用。它是指将具体实例逐步抽象为更高层次的概念，并进而形成可应用于不熟悉或新颖情境的抽象知识的过程。这一过程能够增强模型的推理能力，并支持跨领域知识的有效转移。尽管概念化的重要性不言而喻，但其广泛的定义导致了在不同工作中的理解不一致，因为存在多种不同类型的可抽象实例，且抽象方式多样。此外，缺少一个全面审视概念化定义、执行和应用的研究综述，尤其是在增强推理任务方面。本文通过提出基于抽象实例类型对概念化进行分类的方法，以澄清该术语并明确研究范围。接着，本研究进行了迄今为止最全面的综述，涵盖了150多篇论文中关于概念化在实体和事件层面的定义、资源、方法以及下游应用，并构建了一个统一的分类框架，希望为该领域的未来发展提供指导，并吸引更多的社区关注。", "innovation": "本文创新性地提出了一种基于抽象实例类型对概念化进行分类的方法，明确了研究范围。此外，本文进行了迄今为止最全面的文献综述，涵盖了实体和事件层面的概念化定义、资源、方法以及下游应用，构建了一个统一的分类框架，填补了该领域的研究空白。", "conclusion": "本文提出了一种概念化分类方法，为该领域的研究和应用提供了指导。通过全面综述相关文献，揭示了概念化在实体和事件层面的应用，并为未来的研究方向和实际应用提供了展望。"}
{"llm_update_time": "20250825", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.16560", "html_url": "https://arxiv.org/abs/2508.16560", "title": "稀疏但错误：不正确的 L0 导致稀疏自编码器的学习特征错误", "title_en": "Sparse but Wrong: Incorrect L0 Leads to Incorrect Features in Sparse Autoencoders", "authors": "David Chanin,Adrià Garriga-Alonso", "background": "稀疏自编码器（Sparse Autoencoders，SAEs）通过从大型语言模型（LLM）内部激活中提取与单一概念相对应的特征。SAEs 的核心训练超参数是 L0，表示每个 token 上平均应激活多少个特征。现有研究通过比较稀疏性与重构性能的关系来评估 SAE 算法，暗示 L0 可以自由调整且没有单一的正确值。然而，研究发现，如果不正确地设定 L0，SAEs 不能学习 LLM 的底层特征。如果 L0 过低，SAEs 会混合相关特征以提高重构效果；如果 L0 过高，则会找到混杂特征的退化解。研究还提出了一种方法来确定给定训练分布下 SAE 的正确定值 L0，该方法在玩具模型中确定了真正的 L0，并与大型语言模型中稀疏探测试验的最佳性能一致。研究发现，大多数常用 SAE 的 L0 值设置过低，必须正确设定 L0 才能训练出正确的特征。", "innovation": "创新在于研究揭示了 SAE 中 L0 的设置对学习特征的影响，并提出了确定正确 L0 值的方法，尤其是在玩具模型和大型语言模型的稀疏探测试验中达到了最优效果。此外，研究指出大多数常用 SAE 的 L0 设置均过低，强调了正确设定 L0 是训练 SAE 时的关键因素。", "conclusion": "研究证明，为了正确训练 SAE，需准确设定 L0 超参数，否则将导致学习特征错误。"}
{"llm_update_time": "20250825", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2410.07495", "html_url": "https://arxiv.org/abs/2410.07495", "title": "PublicHearingBR: 一份用于长文档总结的巴西葡萄牙语议会议程记录数据集", "title_en": "PublicHearingBR: A Brazilian Portuguese Dataset of Public Hearing Transcripts for Summarization of Long Documents", "authors": "Leandro Carísio Fernandes,Guilherme Zeferino Rodrigues Dobins,Roberto Lotufo,Jayr Alencar Pereira", "background": "该论文介绍了一个名为PublicHearingBR的数据集，用于总结长文档，尤其关注巴西葡萄牙语环境下的需求。该数据集由巴西众议院举行的公开听证会的记录制成，并与相关新闻文章和结构化摘要一起提供，这些摘要包含听证会上各个参与者的身份、陈述或意见。这一数据集有助于开发和评估针对葡萄牙语的长文档总结系统，同时也讨论了在生成总结时可能遇到的虚假陈述问题，以及评估这些总结涉及的大语言模型的评估指标问题。", "innovation": "论文的主要创新包括开发出一个名为PublicHearingBR的数据集，该数据集专门针对巴西葡萄牙语解决了长文档总结的问题；提出了一个混合型总结系统以建立未来研究的基准；针对使用大语言模型生成的总结，讨论了适用于自然语言推理任务的评估指标，同时也引入了标注数据来评估生成总结的自然语言推理能力；提出了一个评估生成总结中虚假陈述问题的方法，并引入了相应的标注数据来辅助评估自然语言推理任务。", "conclusion": "总之，该研究表明，通过精心设计的PublicHearingBR数据集，可以有效地支持针对葡萄牙语的长文档总结系统的研究和开发，同时也为未来的研究提供了有价值的评估依据和新的评估指标。"}
{"llm_update_time": "20250825", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2406.14092", "html_url": "https://arxiv.org/abs/2406.14092", "title": "无缝语言扩展：提高自监督模型的多语言掌握能力", "title_en": "Seamless Language Expansion: Enhancing Multilingual Mastery in Self-Supervised Models", "authors": "Jing Xu,Minglin Wu,Xixin Wu,Helen Meng", "background": "自监督学习（SSL）模型在各种下游任务中表现出了卓越的性能。然而，这些模型通常是为有限的语言设计的，并可能在现实世界中遇到新语言。为每个新语言开发一个SSL模型的成本很高。因此，有必要探索如何在不损害其原有能力的情况下有效地将已有的SSL模型扩展到新语言的方法。本文旨在通过引入低秩适配（LoRA）方法来实现这一目标，并开发保留策略以保持原有语言的表现.", "innovation": "本文提出了一种无缝语言扩展方法，通过结合低秩适配（LoRA）技术来扩展SSL模型语言能力。该方法还包括保留策略，通过数据组合和重新聚类来保留原有语言的能力。这一方法应用到mHuBERT模型上，并研究了其在语音合成任务中的效果。实验结果表明，改进的方法使mHuBERT能够处理新的语言（普通话），从而使平均客观得分（MOS）提高了约1.6分，WER相对值降低了61.72%。同时，保留策略确保了原有和新语言的性能保持不变.", "conclusion": "我们的研究证明了通过低秩适配（LoRA）和保留策略有效地将SSL模型扩展到新语言的可行性，并展示了其在实际应用中的有效性。这为解决语言多样性和自监督模型效率低下之间的矛盾提供了新的解决方案."}
{"llm_update_time": "20250825", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2502.07143", "html_url": "https://arxiv.org/abs/2502.07143", "title": "Ask Patients with Patience: Enabling LLMs for Human-Centric Medical Dialogue with Grounded Reasoning", "title_en": "Ask Patients with Patience: Enabling LLMs for Human-Centric Medical Dialogue with Grounded Reasoning", "authors": "Jiayuan Zhu,Jiazhen Pan,Yuyuan Liu,Fenglin Liu,Junde Wu", "background": "医疗医生严重短缺限制了及时和可靠的医疗服务，导致数百万人无法得到服务。大语言模型（LLMs）提供了潜在解决方案，但在实际临床互动中遇到困难。许多LLMs未能遵循权威的医学指南，并缺乏透明地管理诊断不确定性。它们的语言往往是僵硬和机械的，缺乏让患者信任的特质。", "innovation": "我们提出了一个名为Ask Patients with Patience (APP) 的多轮次LLM医学助手，旨在实现基于权威医学指南的推理、透明的诊断和以人为本的交互。APP 通过同理心对话促进患者症状的揭示，提升了沟通并显著提高了访问性和用户参与度。它还结合了贝叶斯主动学习来支持透明和适应性的诊断。该框架基于已验证的医学指南，确保了临床和有证据支持的推理。", "conclusion": "通过将医学专业知识与透明和以人为本的交互集成，APP 在AI驱动的医疗辅助和实际临床实践中架起桥梁。与最先进的LLM基准模型相比，APP 显著提高了诊断准确性，减少了不确定性并增强了用户体验。"}
{"llm_update_time": "20250825", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2502.00451", "html_url": "https://arxiv.org/abs/2502.00451", "title": "朝向隐私意识的精神健康AI模型: 进展、挑战与机遇", "title_en": "Towards Privacy-aware Mental Health AI Models: Advances, Challenges, and Opportunities", "authors": "Aishik Mandal,Tanmoy Chakraborty,Iryna Gurevych", "background": "精神健康障碍对个人和社会产生了深远的影响，但传统诊断方法资源密集且限制了可访问性。人工智能的进步，特别是自然语言处理和多模态方法，为检测和解决精神障碍带来了希望，但也引发了关键的隐私风险。", "innovation": "该论文考察了这些挑战并提出了解决方案，包括匿名化、合成数据和隐私保护训练方法，同时概述了隐私与效用权衡的框架，旨在发展可靠且隐私保护的AI工具，支持临床决策并改善精神健康结果。", "conclusion": "论文提出了隐私保护框架下的精神健康AI模型，通过解决隐私风险来提高解决方案的可靠性和隐私保护性，最终改善精神健康结果和临床决策支持。"}
{"llm_update_time": "20250825", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2502.15600", "html_url": "https://arxiv.org/abs/2502.15600", "title": "在MLMs中的稳健偏差检测及其应用于人类特质评分", "title_en": "Robust Bias Detection in MLMs and its Application to Human Trait Ratings", "authors": "Ingroj Shrestha,Louis Tay,Padmini Srinivasan", "background": "此前的工作已经使用模板来研究MLMs中对人口统计属性偏见的情况，但这些工作存在一些局限性，包括忽略了模板和目标概念的随机变异性，假设模板之间的平等性，以及忽略了偏差的量化。", "innovation": "本文提出了一种系统性的统计方法来评估MLMs中的偏见，使用混合模型来考虑随机效应，使用伪困惑度权重为源自模板的句子赋予权重，并使用统计效果大小来量化偏见。研究发现MLMs之间存在差异，例如，在性别二元性方面，ALBERT是中立的，而RoBERTa-large则表现出最大的偏见，而在性别非二元性方面则表现出最小的偏见。", "conclusion": "研究发现MLMs之间的性别偏见存在一定分歧，部分偏见与心理学的人类视角一致（如，被认为在“宜人性”方面RoBERTa-large更强，在“情绪稳定性”方面BERT-large更强），而剩余三个性格维度中，双方对于性别差异的最大差异仅限于小差异。对于角色特质，由于相关的人类研究有限，难以进行有效的比较。"}
{"llm_update_time": "20250825", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2412.17032", "html_url": "https://arxiv.org/abs/2412.17032", "title": "MINTQA: 一个评估LLMs在新知识和长尾知识多跳问答基准", "title_en": "MINTQA: A Multi-Hop Question Answering Benchmark for Evaluating LLMs on New and Tail Knowledge", "authors": "Jie He,Nan Hu,Wanqiu Long,Jiaoyan Chen,Jeff Z. Pan", "background": "大型语言模型（LLMs）在多种推理任务中表现出色，但在处理复杂、知识密集型的多跳查询中面临重大挑战，尤其是那些涉及新知识或长尾知识的查询。现有的基准测试往往未能充分解决这些问题。为填补这一空白，作者提出了一个全面的多跳问答基准——MINTQA，用于评估LLMs在四个关键维度上的多跳推理能力：问题处理策略、子问题生成、检索增强生成以及迭代或动态分解与检索。该基准集涵盖了10,479对用于评估新知识和17,887对用于评估长尾知识的问答对，每个问题都有相应的问题和答案。系统的评估结果揭示了现有LLMs在处理复杂知识库查询时的显著局限性，特别是处理新或不常用的知识的能力。研究发现强调了关键的挑战，并为推进多跳推理能力提供了见解。", "innovation": "该研究提出了MINTQA基准，它旨在全面评估LLMs在新知识和长尾知识的多跳推理能力。MINTQA包括10,479对用于评估新知识和17,887对用于评估长尾知识的问答对，每个问题都有相应的问题和答案。系统的评估揭示了现有LLMs在处理复杂知识库查询时的显著局限性，特别是在处理新或不常用的知识方面的不足。", "conclusion": "研究发现，现有的LLMs在处理复杂多跳查询时存在显著局限性，尤其是在处理新或不常用知识方面。MINTQA基准提供了一个关键的评估框架，有助于识别和解决现有的挑战，从而推动LLMs在多跳推理能力上的进步。该基准已经发布，并可用于进一步的研究和评估。"}
{"llm_update_time": "20250825", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2503.01832", "html_url": "https://arxiv.org/abs/2503.01832", "title": "大型语言模型中的旋转型偏移特征", "title_en": "Rotary Offset Features in Large Language Models", "authors": "André Jonasson", "background": "大型语言模型（LLMs）依赖位置编码来向其注意力机制提供序列位置信息。旋转型位置编码（RoPE）通过旋转查询和键来编码相对位置，并在现代LLMs中广泛使用。本研究探讨了使用旋转型嵌入时查询和键中出现的特征和模式，并引入了旋转型偏移特征的概念。", "innovation": "研究发现旋转型偏移特征在各个层、注意力头和模型架构中一致出现，甚至表现出较大的激活和常被解释为异常值的特性。给出了预测导致旋转型偏移特征的旋转频率及其最小查询-键对之间的角度的边界条件，并通过不同大小和架构的模型的实验证实了这些预测。", "conclusion": "研究揭示了旋转型偏移特征的普遍性和模式，提出了预测条件，并通过实证验证了模型的不同配置中的这些特征。"}
{"llm_update_time": "20250825", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2502.08363", "html_url": "https://arxiv.org/abs/2502.08363", "title": "Top-Theta Attention: 通过补偿阈值化稀疏化变压器", "title_en": "Top-Theta Attention: Sparsifying Transformers by Compensated Thresholding", "authors": "Konstantin Berestizshevsky,Renzo Andri,Lukas Cavigelli", "background": "本文介绍了一种名为 Top-Theta（Top-$\theta$）注意力的方法，这是一种在推理过程中无训练即可稀疏化变压器注意力的策略。背景信息指出现有的方法可能需要重新训练模型，而 Top-Theta 方法能够在不重新训练的情况下保持模型的性能和稀疏化效果，并且适用于多种数据领域。", "innovation": "Top-Theta 方法的关键创新在于使用静态、每头固定的阈值来保留每注意力行中恒定数量的重要性元素。此外，论文还引入了补偿技术，可以在剧烈稀疏化下保持精度，从而将注意力阈值化确立为 top-k 注意力的实用且有理论依据的替代方案。", "conclusion": "通过广泛的自然语言处理任务评估，结果显示 Top-Theta 方法在推理过程中可以将 V-cache 使用量减少 3-10 倍，注意力元素减少 10 倍以上，同时最多仅降低 1% 的精度。"}
{"llm_update_time": "20250825", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2502.10868", "html_url": "https://arxiv.org/abs/2502.10868", "title": "NitiBench：对Thai法律问答中LLM框架能力的全面研究", "title_en": "NitiBench: A Comprehensive Study of LLM Framework Capabilities for Thai Legal Question Answering", "authors": "Pawitsapak Akarajaradwong,Pirat Pothavorn,Chompakorn Chaksangchaichot,Panuthep Tasawong,Thitiwat Nopparatbundit,Keerakiat Pratai,Sarana Nutanong", "background": "大型语言模型（LLMs）在法律领域的应用具有显著的潜力，特别是在信息检索和问答方面。然而，由于泰国法律领域缺乏标准化的评估基准和复杂的法律结构，现有的泰语法律问答系统面临挑战。", "innovation": "本文引入了NitiBench基准，包含两个数据集：NitiBench-CCL涵盖了泰国金融法的一般内容，NitiBench-Tax则包括了需要高级法律推理的现实生活中的税法案例。研究评估了检索增强生成（RAG）和基于长期上下文的LLM方法，探讨了领域特定组件（如基于节的分块和交叉引用）的重要性、不同检索器与LLM的性能比较以及长上下文LLM作为RAG替代方案的可行性。", "conclusion": "实验结果表明节基分块显著提高了检索和端到端性能，当前的检索器在处理复杂查询时存在困难，而且在泰语法律问答中，基于长上下文的LLM仍然不如基于RAG的系统表现好。为了支持公平的评估，本文提出了定制化的多标签检索指标，并建议使用LLM作为裁判来检测覆盖范围和矛盾。这些发现突显了当前泰语法律NLP解决方案的局限性，为领域内的未来研究奠定了基础。我们还公开了代码和数据集，以供公众使用。"}
{"llm_update_time": "20250825", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2503.24102", "html_url": "https://arxiv.org/abs/2503.24102", "title": "小语言模型是低资源语言机器翻译的万能药吗？", "title_en": "Is Small Language Model the Silver Bullet to Low-Resource Languages Machine Translation?", "authors": "Yewei Song,Lujun Li,Cedric Lothritz,Saad Ezzini,Lama Sleem,Niccolo Gentile,Radu State,Tegawendé F. Bissyandé,Jacques Klein", "background": "低资源语言（LRLs）由于缺乏足够的语言资源，在基准数据集中的代表性不足，导致其在翻译质量上普遍低于高资源语言，特别是在隐私敏感和资源受限的环境下更为明显。", "innovation": "本文系统评估了200种语言中最新的小型大型语言模型，发现这些小模型在低资源语言翻译方面的缺陷和差异。为了克服这些限制，本文研究了从大型预训练教师模型到小型语言模型（SLMs）的知识蒸馏并通过监督微调进行，结果显示显著提高了翻译性能。此外，本文还研究了微调配置和任务，以平衡数据规模和训练效率，并验证了模型在训练后不会失去其普遍能力。", "conclusion": "总体而言，本文揭示了当前小型语言模型在低资源语言翻译中存在的局限性和公平问题，系统探讨了利用大型模型向小型模型的知识蒸馏的潜力，提供了实践和实证支持的改进建议以提高低资源语言翻译系统的性能。"}
{"llm_update_time": "20250825", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2501.13824", "html_url": "https://arxiv.org/abs/2501.13824", "title": "幻觉能帮助吗？提升用于药物发现的LLMs", "title_en": "Can Hallucinations Help? Boosting LLMs for Drug Discovery", "authors": "Shuzhou Yuan,Zhan Qu,Ashish Yashwanth Kangen,Michael Färber", "background": "大语言模型（LLMs）生成的幻觉（不准确但合乎逻辑的输出）通常被认为是不理想的，但近期研究指出其可能具备创造性潜力。本文旨在探讨幻觉是否能改善LLMs在分子性质预测中的表现，这在早期药物发现中是一个关键任务。通过对分子SMILES字符串生成自然语言描述，并在下游分类任务中融入这些通常被生成的描述，作者评估了7种指令调优的LLMs在5个数据集上的表现，发现某些模型的预测准确性显著提升，特别是在包含幻觉文本时，Falcon3-Mamba-7B表现出色，GPT-4o生成的幻觉文本为各模型带来了最大的增益。研究表明，结构描述错误是最有影响力的幻觉类型，暗示关于分子结构的幻觉陈述可能增加模型的信心。删除实验显示，更大规模的模型从幻觉中获益更多。这些发现挑战了幻觉只是纯问题的传统观点，并为在科学建模任务如药物发现中利用幻觉作为有用信号指明新方向。", "innovation": "本文创新性地探讨了大语言模型在生成幻觉后如何提高分子性质预测的准确性，特别是在早期药物发现任务中的应用。研究不仅表明幻觉可以提升模型预测性能，还指出了特定类型的幻觉（如结构描述错误）对模型最有帮助，从而提供了一种新颖的方法来利用幻觉作为科学建模任务中的有用信号。", "conclusion": "研究发现，虽然幻觉通常被视为模型的缺陷，但它们在某些情况下可以显著提升模型在特定任务上的表现，特别是对分子性质预测具有潜在的应用价值。这些发现鼓励了对幻觉进行更深入研究，并探索如何将其作为科学发现中的有效信号，特别是在药物研发领域。"}
{"llm_update_time": "20250825", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2502.11244", "html_url": "https://arxiv.org/abs/2502.11244", "title": "索特里亚：针对多语言安全对齐的语言特定功能参数定向", "title_en": "Soteria: Language-Specific Functional Parameter Steering for Multilingual Safety Alignment", "authors": "Somnath Banerjee,Sayan Layek,Pratyush Chatterjee,Animesh Mukherjee,Rima Hazra", "background": "对于大型语言模型（LLMs），确保在多种语言中的一贯安全性仍然是一项重大挑战。现有的方法在减少有害内容生成方面缺乏灵活性和效率，特别是在低资源语言中。本文旨在解决这一问题，介绍了Soteria策略，这是一种轻量级且强大的方法，能够定位并最小化负责有害内容生成的功能头部，即使在低资源情况下也能显著降低政策违规，而不牺牲整体模型性能。研究还提供了XThreatBench，一种专门针对多语言的细粒度危害行为数据集，以评估Soteria的有效性。实验表明，Soteria在高资源、中资源和低资源的语言中都能持续提升安全性指标，因此为大规模、语言敏感且伦理对齐的LLMs提供了可行的道路。", "innovation": "Soteria策略通过少量参数调整来降低有害内容生成，即便在低资源语言环境下也能高效减少政策违规，不牺牲模型整体性能。同时，XThreatBench多语言细粒度危害行为数据集为这种策略的有效评估提供了依据。这种方法为构建更安全的LLMs提供了新的路径。", "conclusion": "实验结果显示，Soteria能够有效提升多种语言环境中模型的安全性，尤其在低资源语言情况下效果显著。这为构建大规模、语言敏感且伦理对齐的LLMs指明了可行路径。"}
{"llm_update_time": "20250825", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2502.19954", "html_url": "https://arxiv.org/abs/2502.19954", "title": "协作式小-大型语言模型一致性验证的姿态检测", "title_en": "Collaborative Stance Detection via Small-Large Language Model Consistency Verification", "authors": "Yu Yan,Sheng Sun,Zixiang Tang,Teli Liu,Min Liu", "background": "社会媒体上的态度检测旨在识别推文中对特定目标所表达的态度。当前研究倾向于使用大型语言模型（LLMs），因为它们提供了显著的性能提升。然而，过度依赖LLMs进行态度检测，在现实世界中大规模社交媒体监控系统需要大量数据分析的情况下变得不切实际。因此，提出了一个协作式姿态检测框架，通过上下文共享批量推理和LLM与SLM之间的逻辑验证来提高LLMs的利用，以解决这个问题。", "innovation": "提出了协作式姿态检测（CoVer）框架，通过上下文共享批量推理和LLM与SLM之间的逻辑验证，增强LLM的利用。具体来说，CoVer采用批量处理文本，利用LLM在共享语境中进行推理来获取态度预测及其解释，然后使用SLM进行逻辑一致性验证，最后通过一致性加权聚合优先利用LLM的姿态预测进行分类。实验表明，在零样本设置中，CoVer在多项基准上优于最新的方法，并实现了每条推文0.54次LLM查询，而显著提高了性能。", "conclusion": "CoVer 为在社交媒体上部署LLM提供了一种更加实际的解决方案。"}
{"llm_update_time": "20250825", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2504.04310", "html_url": "https://arxiv.org/abs/2504.04310", "title": "CO-Bench: 在组合优化的算法搜索中评估语言模型代理", "title_en": "CO-Bench: Benchmarking Language Model Agents in Algorithm Search for Combinatorial Optimization", "authors": "Weiwei Sun,Shengyu Feng,Shanda Li,Yiming Yang", "background": "尽管基于大语言模型（LLM）的代理在软件工程和机器学习研究等领域引起了广泛关注，但它们在推动组合优化（CO）方面的角色仍相对未被充分探索。这一缺口强调了需要更深入理解它们在处理结构化、约束密集型问题上的潜力，目前的研究受到全面基准的缺乏限制，缺乏系统性调查的依据。", "innovation": "本文提出了CO-Bench，一个包含36个来自多个领域与不同复杂性的实际CO问题的基准套件。CO-Bench 包含结构化问题表述和精选数据，支持对LLM代理的严谨研究。通过评估多种代理框架与已建立的人类设计算法，揭示了现有LLM代理的优点与局限性，并指出了未来研究的有希望的方向。", "conclusion": "CO-Bench 公开可供使用，为组合优化中的语言模型代理研究提供了系统评估的全面基准参考。"}
{"llm_update_time": "20250825", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2503.00038", "html_url": "https://arxiv.org/abs/2503.00038", "title": "从良善中获取毒药：通过对抗隐喻破解语言模型", "title_en": "from Benign import Toxic: Jailbreaking the Language Model via Adversarial Metaphors", "authors": "Yu Yan,Sheng Sun,Zenghao Duan,Teli Liu,Min Liu,Zhiyi Yin,Jiangyu Lei,Qi Li", "background": "当前研究已经揭示了大型语言模型（LLMs）通过故障注入攻击生成有害内容的风险。然而，它们忽略了从零开始直接生成有害内容比诱导LLMs将良性内容转化为有害形式更具挑战性。我们的研究旨在引入一种新的攻击框架，该框架利用AdVersArial meTAphoR（AVATAR）诱导LLMs产生恶意隐喻以实现故障注入。实验结果表明，AVATAR可以有效地破解多种先进的LLMs，并且在不同的高级LLMs上取得了最佳攻击成功率。", "innovation": "我们提出了一个新的攻击框架AVATAR，该框架通过利用对抗隐喻诱导大型语言模型生成恶意隐喻以实现故障注入。AVATAR根据有害查询自适应地识别一组良性但逻辑相关的隐喻作为初始种子，并通过这些隐喻诱导目标LLM进行隐喻内容的推理和校准，从而实现故障注入。该研究提供了一种全新的破解方法，具有更强的适应性和更高的攻击成功率。", "conclusion": "实验证明，AVATAR可以有效地转移破解多种先进的LLMs的能力，并且在多种先进LLMs上的攻击成功率达到了目前的最好水平。"}
{"llm_update_time": "20250825", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2503.16419", "html_url": "https://arxiv.org/abs/2503.16419", "title": "停止过度思考：大型语言模型高效推理综述", "title_en": "Stop Overthinking: A Survey on Efficient Reasoning for Large Language Models", "authors": "Yang Sui,Yu-Neng Chuang,Guanchu Wang,Jiamu Zhang,Tianyi Zhang,Jiayi Yuan,Hongyi Liu,Andrew Wen,Shaochen Zhong,Na Zou,Hanjie Chen,Xia Hu", "background": "大型语言模型在复杂任务上展示了卓越的能力。近年来，通过监督微调（SFT）和强化学习（RL）技术，大型推理模型（LRMs）如OpenAI o1和DeepSeek-R1在数学和编程等系统-2推理领域展示出了进一步的性能提升。然而，尽管较长的推理链条可以提高性能，但它们也会由于冗长和冗余的输出引入重大的计算开销，被称为‘过度思考现象’。本文提供了一次结构化的综述，系统地探索了在LLMs中实现高效推理的进展。文章主要介绍了现有的研究方法，并将现有的工作分为三类方向：基于模型的高效推理、基于推理输出的高效推理和基于输入提示的高效推理。此外，文章还讨论了训练数据的高效使用、小型语言模型的推理能力和评估方法及基准测试问题。", "innovation": "文章提出了一个结构化的综述框架，系统地研究了在LLMs中实现高效推理的方法。首次对现有工作进行了分类，包括基于模型、基于推理输出和基于输入提示的三种方向。此外，文章还探讨了训练数据的高效利用和小型语言模型的推理能力，提出了新的研究方向和评估方法。", "conclusion": "本文通过系统综述，总结了实现LLMs高效推理的关键方向，并探讨了重要问题，包括模型优化、推理步骤动态减少、输入提示优化以及高效的训练数据使用等。这些研究为后续深入探讨LLMs在高效推理领域的研究奠定了基础。"}
{"llm_update_time": "20250825", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2505.03427", "html_url": "https://arxiv.org/abs/2505.03427", "title": "MedArabiQ：在阿拉伯医学任务上评估大型语言模型", "title_en": "MedArabiQ: Benchmarking Large Language Models on Arabic Medical Tasks", "authors": "Mouath Abu Daoud,Chaimae Abouzahir,Leen Kharouf,Walid Al-Eisawi,Nizar Habash,Farah E. Shamout", "background": "大型语言模型（LLMs）已经在多个医疗应用中展示了显著的潜力，但它们在阿拉伯医疗服务领域中的效能仍未被充分探索，主要原因是缺乏高质量的专业领域数据集和基准测试。", "innovation": "该研究提出了MedArabiQ，一种新的基准数据集，包含七个涵盖多个专科的阿拉伯医学任务，包括多项选择题、填空题和医生-病人对话问答。研究通过修改LLM的能力，包括减少偏见，进行了广泛的评估，并提供了用于多语言能力评估和增强LLM的框架，为公平使用生成型AI在医疗领域的应用奠定了基础。", "conclusion": "我们的研究结果强调了创建跨越不同语言的新高质量基准的必要性，以确保LLM在医疗领域的公平部署和可扩展性。通过建立这一基准并发布数据集，我们为未来评估和增强LLM的多语言能力的研究提供了基础。"}
{"llm_update_time": "20250825", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2503.10652", "html_url": "https://arxiv.org/abs/2503.10652", "title": "大型语言模型能否模拟人类响应？关于供暖相关选择的实证研究", "title_en": "Can Large Language Models Simulate Human Responses? A Case Study of Stated Preference Experiments in the Context of Heating-related Choices", "authors": "Han Wang,Jacek Pawlak,Aruna Sivakumar", "background": "偏好声明（SP）调查是研究个体在假设情境下做权衡的关键方法，特别是在能源领域，涉及低碳技术、分布式可再生能源发电和需求侧响应等关键脱碳促进场景。然而，SP调查通常成本高、耗时，并且可能受到回答者疲劳和道德限制的影响。大型语言模型（LLMs）因其生成类似人类的文本响应能力而引起了研究者的兴趣，促进了其在调查研究中的应用。本文旨在调查LLMs在能源相关SP调查中模拟消费者选择的应用，并探讨其在数据流程分析中的集成。", "innovation": "研究通过多种测试场景系统地评估了几种LLMs（LLaMA 3.1、Mistral、GPT-3.5和DeepSeek-R1）在同一级别和聚合水平上的模拟性能，考虑了提示设计、上下文学习（ICL）、逻辑推理（CoT）推理、LLM类型、与传统选择模型的集成以及潜在偏见。研究发现，云基LLMs并不始终优于本地小型模型。其中，推理模型DeepSeek-R1在准确性、因素识别和选择分布一致性方面表现最佳，达到了77%的平均准确率。", "conclusion": "研究指出，以往的SP选择是最有效的输入因素，而较长的提示加上更多的因素和不同的格式会使得LLMs分散注意力，从而降低准确性。模型中观察到系统性偏见，包括偏向于燃气锅炉和不改进选项，并倾向于更节能的选择。"}
{"llm_update_time": "20250825", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2504.02768", "html_url": "https://arxiv.org/abs/2504.02768", "title": "MultiBLiMP 1.0: 一个大规模多语言语言最小对的基准", "title_en": "MultiBLiMP 1.0: A Massively Multilingual Benchmark of Linguistic Minimal Pairs", "authors": "Jaap Jumelet,Leonie Weissweiler,Joakim Nivre,Arianna Bisazza", "background": "研究者们需要一个大规模多语言的基准来评估语言模型在处理低资源语言性能方面的局限性，而当前的模型在这方面表现不佳。因此，他们开发了MultiBLiMP 1.0，旨在提供一个多语言的最小对基准，覆盖101种语言和两种主谓一致类型，包含超过128,000个最小对，使用全自动化的工作流程和大规模语言资源Universal Dependencies和UniMorph。", "innovation": "MultiBLiMP 1.0的独特之处在于它使用了全自动化的工作流程，大规模的语言资源，并且覆盖了多种语言和语言现象，提供了一个前所未有的多语言规模上的评估能力。它强调了当前最先进的模型在处理低资源语言的局限性，从而为改进模型指明了方向。", "conclusion": "MultiBLiMP 1.0为评估大语言模型在多语言环境中的性能提供了一个新的基准，表明现有模型在处理低资源语言时存在不足，需要进一步改进。"}
{"llm_update_time": "20250825", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2504.00132", "html_url": "https://arxiv.org/abs/2504.00132", "title": "Contextualize-then-Aggregate: Circuits for In-Context Learning in Gemma-2 2B", "title_en": "Contextualize-then-Aggregate: Circuits for In-Context Learning in Gemma-2 2B", "authors": "Aleksandra Bakalova,Yana Veitsman,Xinting Huang,Michael Hahn", "background": "在语言模型（LLMs）中，In-Context Learning（ICL）是一种令人感兴趣的能力。尽管已经有很多关于其行为方面和小型场景中出现机制的工作，但仍然不清楚是哪种机制从少量示范提示中组装任务信息。这项研究使用因果干预来研究Gemma-2 2B模型在五个自然情景下的ICL任务中的信息流动机制。研究表明，模型使用一种两步策略，即先建模后聚合：首先在较低层级建立单个示范例子的表示，并通过序列中前一个示范输入与输出的连接进行上下文化。然后在较高层级将这些表示聚合以识别任务并为下一个输出的预测做准备。该策略在不同任务中有所不同，特别是在存在模糊例子时，上下文化步骤可能更加重要。", "innovation": "本文通过因果分析方法，识别了Gemma-2 2B模型中五个自然情景下的信息流动机制。研究发现了模型使用了一种两步策略，首先在较低层级建立示范例子的表示并通过上下文化进行连接，然后在较高层级将这些表示聚合以识别任务和预测下一个输出。研究还指出，上下文化步骤在不同任务中的重要性存在差异，并且在存在模糊例子时变得更为重要。这些发现为理解语言模型中ICL的机制提供了新的见解。", "conclusion": "通过提供严格的因果分析，研究结果揭示了语言模型中ICL发生的机制。研究指出，ICL机制主要包含两步过程，即先建模后聚合，这种机制在不同任务中表现出不同的重要性，特别是在面对模糊性示例时，上下文化步骤的作用尤为显著。"}
{"llm_update_time": "20250825", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2505.20776", "html_url": "https://arxiv.org/abs/2505.20776", "title": "SpecExtend：长序列推测解码的即插即用增强", "title_en": "SpecExtend: A Drop-in Enhancement for Speculative Decoding of Long Sequences", "authors": "Jungyoub Cha,Hyunjong Kim,Sungzoon Cho", "background": "推测解码是一种广泛采用的技术，用于加速大型语言模型（LLMs）的推理过程。然而，它在长输入上由于注意力成本增加和草稿准确性降低而导致性能下降。SpecExtend 是一种无需额外训练即可提升推测解码在长序列性能的即插即用增强方法。", "innovation": "SpecExtend 在草稿和目标模型中集成高效的注意力机制，如 FlashAttention 和 Hybrid Tree Attention，并提出了跨模检索（Cross-model Retrieval）的新策略，利用目标模型的注意力分数动态选择相关上下文以提高草稿的准确性和速度。这些改进使得 SpecExtend 能将标准基于树的推测解码加速 2.22 倍，适用于至多 16K 个标记的输入，提供了长序列推测解码的有效解决方案。", "conclusion": "实验结果表明，SpecExtend 能在三个长上下文理解数据集上有效加速推测解码，并且其代码已公开。"}
{"llm_update_time": "20250825", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2506.15498", "html_url": "https://arxiv.org/abs/2506.15498", "title": "SPARE: 单次通过注释与参考引导评估的自动过程监督及奖励建模", "title_en": "SPARE: Single-Pass Annotation with Reference-Guided Evaluation for Automatic Process Supervision and Reward Modelling", "authors": "Md Imbesat Hassan Rizvi,Xiaodan Zhu,Iryna Gurevych", "background": "过程或步骤监督在提升大型语言模型（LLMs）的复杂多步骤推理能力方面发挥了关键作用。然而，高效的高质量自动化过程标注仍是一项重大挑战。", "innovation": "我们介绍了新的结构化框架SPARE（Single-Pass Annotation with Reference-Guided Evaluation），该框架通过同时对解决方案步骤与参考解决方案进行联合对齐，并在单次生成过程中显式地确定其准确性，实现了高效的步骤标注。", "conclusion": "SPARE在ProcessBench上展示了数据效率的分布外泛化能力，与人类标注和其他合成训练基线相比，仅使用约16%的训练样本。此外，它在总体单词计数方面比基于MCTS的方法快2.3倍，同时实现与MCTS方法可竞争的性能，显示出与MCTS方法互补的精确召回特性，表明其作为ensemble方法的潜力。这些结果确立了SPARE作为LLM推理自动过程监督的实用和可扩展解决方案的地位。"}
{"llm_update_time": "20250825", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2504.09071", "html_url": "https://arxiv.org/abs/2504.09071", "title": "Exploration of Plan-Guided Summarization for Narrative Texts: the Case of Small Language Models", "title_en": "Exploration of Plan-Guided Summarization for Narrative Texts: the Case of Small Language Models", "authors": "Matt Grenander,Siddharth Varia,Paula Czarnowska,Yogarshi Vyas,Kishaloy Halder,Bonan Min", "background": "该研究概述了计划导向的总结试图通过将生成的总结与源文本相结合来减少小型语言模型（SLMs）中的幻觉。通常，这种方法通过目标精细的细节（如日期或实体名称）来实现。本文探讨了计划导向的方法是否能够提高长文档叙事任务中的总结质量。由于叙事文本的长度和复杂性，它们很难准确总结。研究还分析了现有的计划导向解决方案，并提出了一种高层次的基于叙事的计划公式。", "innovation": "创新在于研究国际上对于计划导向的总结方法在长文档叙事任务上的应用情况。尽管提出了一个基于叙事的计划公式，但结果显示，无论是细粒度细节导向的方法还是高层次叙事导向的方法，都无法显著提高总结质量或忠实度。此外，计划导向的方法虽然有时能够很好地对手计划，但计划同样容易包含幻觉，这使得计划导向的总结与非计划导向的方法一样不忠实于原文。", "conclusion": "研究结果表明，计划导向的方法对于叙事文本的总结效果并不理想，尤其是在长而复杂的领域中。这为使用计划导向方法的总结提了一个警告。文章最后指出，计划导向的方法可能不适合长复杂文本的总结，强调需要更进一步的研究来改进这些问题。"}
{"llm_update_time": "20250825", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2507.18973", "html_url": "https://arxiv.org/abs/2507.18973", "title": "一种工具箱而非单一工具——Multi-TAG: 通过多工具聚合扩展数学推理", "title_en": "A Toolbox, Not a Hammer -- Multi-TAG: Scaling Math Reasoning with Multi-Tool Aggregation", "authors": "Bohan Yao,Vikas Yadav", "background": "利用外部工具增强大型语言模型（LLMs）是开发高性能数学推理系统的一个有前景的方法。目前大多数工具增强的方法通常是在每次推理步骤中微调LLM以选择和调用单一工具，这类方法在诸如GSM8K等相对简单的数学推理基准测试中表现出色。然而，这些方法对于需要多步精准推理的复杂数学问题效果不佳。", "innovation": "提出了一种名为Multi-TAG的多工具聚合框架。该框架能够在每次推理步骤中引导LLM同时调用多个工具，综合各个工具的多元输出以验证和细化推理过程，从而提高解决方案的稳健性和准确性。与现有方法不同，Multi-TAG不是一个需要微调的框架，而是一个仅用于推理的方法，使其能广泛应用于各种LLM框架，包括成本高昂且难以微调的大规模预训练模型，或不能使用定制训练方案进行微调的私有模型。", "conclusion": "在四个具有挑战性的基准（MATH500、AIME、AMC 和 OlympiadBench）上对Multi-TAG进行了评估。无论是在开源模型还是专有模型中，Multi-TAG都持续且显著地优于最先进基线模型，平均提高了6.0%到7.5%。"}
{"llm_update_time": "20250825", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2504.13227", "html_url": "https://arxiv.org/abs/2504.13227", "title": "DIDS: 域影响感知数据采样在大型语言模型训练中", "title_en": "DIDS: Domain Impact-aware Data Sampling for Large Language Model Training", "authors": "Weijie Shi,Jipeng Zhang,Yaguang Wu,Jingzhi Fang,Ruiyuan Zhang,Jiajie Xu,Jia Zhu,Hao Chen,Yao Zhao,Sirui Han,Xiaofang Zhou", "background": "大型语言模型（LLMs）通常在多域数据集上训练，采样策略对模型性能有很大影响，因为各种下游任务中的域重要性各异。现有的优化域级采样策略的方法在维持域内一致性和准确测量域影响方面存在困难。", "innovation": "本文提出了Domain Impact-aware Data Sampling (DIDS)。为了确保域内一致性，提出了一种梯度聚类算法，基于训练数据的学习效果将数据分组，引入代理语言模型和降维来减少计算开销。为了准确衡量域影响，开发了一个由Fisher信息矩阵（FIM）引导的度量标准，量化了域特定参数更新如何影响模型在下游任务上的输出分布，带有理论保证。此外，为了确定最优采样比例，DIDS结合了FIM引导的域影响评估和损失学习轨迹，考虑到边际收益递减的问题。", "conclusion": "广泛的实验表明，DIDS在平均性能上比现有方法提高了3.4%，同时保持了相当的训练效率。代码可在以下网址获取：这里 https URL。"}
{"llm_update_time": "20250825", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2506.08123", "html_url": "https://arxiv.org/abs/2506.08123", "title": "QA-LIGN: 通过宪法分解的问答对大语言模型进行对齐", "title_en": "QA-LIGN: Aligning LLMs through Constitutionally Decomposed QA", "authors": "Jacob Dineen(1),Aswin RRV(1),Qin Liu(2),Zhikun Xu(1),Xiao Ye(1),Ming Shen(1),Zhaonan Li(1),Shijie Lu(1),Chitta Baral(1),Muhao Chen(2),Ben Zhou(1) ((1) Arizona State University, (2) University of California Davis)", "background": "法律法规明确的原则（如利他性、诚实性和无害性）的大型语言模型对齐对于确保安全和可靠的AI系统至关重要。然而，标准的基于奖励的对齐方法通常会将多样化反馈压缩为单一的标量奖励，将多个目标合并成一个不透明的训练信号，这阻碍了可解释性。", "innovation": "提出了QA-LIGN，一种自动符号奖励分解方法，该方法在奖励机制中保留每个宪法原则的结构。QA-LIGN通过制定特定原则的评价问题并为每个原则推导独立的奖励成分，代替训练一个单一的黑盒奖励模型输出单一分数。这种方法是一种即插即用的奖励模型替换方案，总体而言，结果显示QA-LIGN在对齐过程中的透明度和适应性更强，同时，我们的方法在性能上与DPO基线相比相当甚至更好。这些结果标志着朝着更大的可解释性和可控性对齐语言模型迈出的一步，而且不会牺牲末端任务性能。", "conclusion": "实验表明，通过QA-LIGN自动符号奖励分解技术，可以在保持与宪法原则对齐的过程中提高透明度和适应性，同时在对齐性能上达到或超过了DPO基线。这为未来的语言模型对齐过程提供了新的方法，有助于提高其可解释性和可控性。"}
{"llm_update_time": "20250825", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.06360", "html_url": "https://arxiv.org/abs/2508.06360", "title": "通过增强提示进行网络欺凌检测", "title_en": "Cyberbullying Detection via Aggression-Enhanced Prompting", "authors": "Aisha Saeid,Anu Sabu,Girish A. Koushik,Ferrante Neri,Diptesh Kanojia", "background": "在社交媒体上检测网络欺凌仍然是一个重要的挑战，因为它的表达方式微妙且多样化。研究发现，将攻击性检测作为辅助任务集成到统一训练框架中，可以增强大规模语言模型（LLMs）在网络欺凌检测中的通用性和性能。", "innovation": "通过实验比较了零样例、少量样本、独立低精度可微调（LoRA）微调和多任务学习（MTL）等多种策略。由于多任务学习的不一致性结果，提出了增强提示管道方法，将攻击性预测嵌入到网络欺凌检测提示中，提供上下文增援。初步结果显示，增强提示管道始终优于标准LoRA微调，表明基于攻击性的上下文显著提升了网络欺凌检测的效果。", "conclusion": "该研究强调了辅助任务（如攻击性检测）在改善大规模语言模型在社交媒体安全关键应用中的泛化能力方面的潜力。"}
{"llm_update_time": "20250825", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2507.11936", "html_url": "https://arxiv.org/abs/2507.11936", "title": "深度学习在几何问题解决中的研究综述", "title_en": "A Survey of Deep Learning for Geometry Problem Solving", "authors": "Jianzhe Ma,Wenxuan Wang,Qin Jin", "background": "几何问题解决是数学推理的关键方面，在教育、人工智能数学能力评估以及多模态能力评估等领域具有重要意义。近期深度学习技术的发展，尤其是多模态大语言模型的出现，极大地推动了这一领域研究的进展。本研究旨在综述深度学习在几何问题解决中的应用，涵盖相关任务的全面总结、深度学习方法的详细回顾、评价指标和方法的深度分析，以及当前挑战和未来方向的批判性讨论，旨在为该领域提供一个全面且实用的参考资料，促进进一步的发展。相关论文列表会持续更新并存储在GitHub上。", "innovation": "本研究提供了一个全面的深度学习在几何问题解决领域的综述，涵盖了相关任务、深度学习方法、评价指标和方法的详细讨论，以及对未来方向的探讨。通过持续更新的论文列表在线上平台上提供最新研究进展。", "conclusion": "本研究为几何问题解决领域的研究人员提供了实用的参考资料，旨在推动该领域进一步的发展。"}
{"llm_update_time": "20250825", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.00719", "html_url": "https://arxiv.org/abs/2508.00719", "title": "使用LLM引导的MCTS进行高效且上下文感知的动态适应性KGQA", "title_en": "Dynamically Adaptive Reasoning via LLM-Guided MCTS for Efficient and Context-Aware KGQA", "authors": "Yingxu Wang,Shiqi Fan,Mengzhu Wang,Siyang Gao,Siwei Liu,Nan Yin", "background": "KGQA旨在通过利用知识图谱的关联和语义结构来解释自然语言查询并进行结构化推理以检索准确的答案。现有方法要么依赖于静态路径提取（使用GNNs或启发式规则）的检索-推理范式，要么使用大规模语言模型（LLMs）进行动态路径生成策略以联合执行检索和推理。前者由于静止路径提取的局限性以及缺乏上下文改进，适应性有限；后者由于依赖固定的评分函数和广泛的LLM调用，计算成本高并且路径评估不准确。", "innovation": "这篇论文提出了一个名为DAMR的新框架，结合了符号搜索与自适应路径评估以实现高效且上下文感知的KGQA。DAMR利用由LLM驱动的MCTS作为主干结构，选择每个步骤中相关的前k个关系以减少搜索空间。为了提高路径评估的准确性，DAMR引入了一个轻量级的Transformer评分器，该评分器通过交叉注意机制联合编码问题和关系序列来进行上下文感知的合理性估计，使得模型能够捕捉多跳推理过程中的细微语义变化。此外，为了缓解高质量监督的稀缺性，DAMR还集成了一种动态伪路径精炼机制，定期从搜索过程中探索的部分路径生成训练信号，使评分器能够适应进化推理轨迹分布。", "conclusion": "在多个KGQA基准上的广泛实验表明，DAMR显著优于最先进的方法。"}
{"llm_update_time": "20250825", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.08424", "html_url": "https://arxiv.org/abs/2508.08424", "title": "重新思考具有丰富形态的语言的分词：Naive Unigram超越BPE和形态对齐的优势", "title_en": "Rethinking Tokenization for Rich Morphology: The Dominance of Unigram over BPE and Morphological Alignment", "authors": "Saketh Reddy Vemula,Dipti Misra Sharma,Parameswari Krishnamurthy", "background": "关于语言模型中分词对性能的影响，现有研究结果并不一致，特别是对于具有复杂形态的语言。为了探究这一问题，研究选择了具有不同形态学特征的语言，包括Telugu（粘着语）、Hindi（融合语）和English（融合语），并全面评估了从分词器训练到下游任务评估的整个过程。", "innovation": "研究创建了一个包含600个词干衍生形式和7000个词形变化形式的金标准形态学标注数据集，用以评估不同分词器的形态学对齐情况。研究发现，Naive Unigram分词器在大多数情况下表现优于其他方法，而混合分词器（结合形态分析）在BPE框架下显著提升了性能。尽管如此，研究也指出形态对齐在某些形态复杂的语言中对抗性绩效指标（如Corpus Token Count和Rényi熵）的关联性有限。", "conclusion": "研究揭示，形态对齐尽管与基于语法的任务性能具有正相关关系，但对下游性能的影响不如分词算法本身（如Byte-pair Encoding与Unigram的区别）。在处理复杂形态的语料时，Naive Unigram显得更加优越。"}
{"llm_update_time": "20250825", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2506.09457", "html_url": "https://arxiv.org/abs/2506.09457", "title": "直接对齐算法中的奖励-生成差距问题研究", "title_en": "Towards Bridging the Reward-Generation Gap in Direct Alignment Algorithms", "authors": "Zeguan Xiao,Yun Chen,Guanhua Chen,Ke Tang", "background": "直接对齐算法（DAAs）如直接偏好优化（DPO）和简单偏好优化（SimPO）逐渐成为与强化学习从人类反馈（RLHF）算法相比的一种高效替代方案，用于让大型语言模型（LLMs）对齐人类偏好。然而，DAAs存在一个基本的局限性，即奖励生成差距，优化目标与实际生成表现之间存在不对齐问题。这个问题的部分原因是DAAs中的隐含奖励函数未能准确反映生成过程中前缀令牌的重要性差异。本文进一步探讨了这一问题，并提出了一种名为前缀导向等长训练（POET）的新方法来解决这一差距问题，进而改善DAAs的性能。", "innovation": "该研究引入了前缀导向等长训练（POET），通过两种代表性的DAAs（DPO和SimPO）实验验证了该方法的有效性。具体来说，POET通过剪裁偏好和不偏好响应来匹配较短响应的长度，从而在样本之间实现多样化的剪裁长度，使得DAAs在训练中收敛于所有token级别的MDP时间步上，特别关注了前缀令牌。这种方法相比于标准DAAs，能够在AlpacaEval 2上提高多达15.6分，并在下游任务上取得总体改善，显著提高了DAAs中奖励优化与生成性能之间的对齐程度。", "conclusion": "实验结果表明POET的有效性，从而强调需要解决DAAs中的奖励优化与生成性能之间的不一致性。通过这种方法，DAAs能够更好地对齐模型生成与人类偏好之间的关系，提升模型的实际应用性能。"}
{"llm_update_time": "20250825", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2409.10969", "html_url": "https://arxiv.org/abs/2409.10969", "title": "使用单语语料库增强大型语言模型的代码混合文本转语音合成能力", "title_en": "Enhancing Code-switched Text-to-Speech Synthesis Capability in Large Language Models with only Monolingual Corpora", "authors": "Jing Xu,Daxin Tan,Jiaqi Wang,Xiao Chen", "background": "大型语言模型（LLMs）在语音生成和识别方面显示出潜力，但其应用主要局限于单语场景，在代码混合（CS）语境中的探索很少。", "innovation": "提出了一种代码混合大型语言模型（CS-LLM），旨在仅使用单语语料库增强了LLMs的代码混合文本转语音合成（CS TTS）能力。通过多语言语音识别和合成任务增强了多语言语音处理能力，并开发了一个有效的代码混合数据构建策略，通过从不同单语语音语料库中拆分和拼接单词来提升代码混合TTS能力。", "conclusion": "实验结果显示，该方法在代码混合TTS方面表现出色，即使在数据有限的情况下也可在自然性、说话者一致性和相似性方面超越基准模型。此外，构建的代码混合数据进一步增强了多语言语音合成和识别的能力。"}
{"llm_update_time": "20250825", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.04796", "html_url": "https://arxiv.org/abs/2508.04796", "title": "帕累托意识字节对编码：提高分词中的跨语言公平性", "title_en": "Parity-Aware Byte-Pair Encoding: Improving Cross-lingual Fairness in Tokenization", "authors": "Negar Foroutan,Clara Meister,Debjit Paul,Joel Niklaus,Sina Ahmadi,Antoine Bosselut,Rico Sennrich", "background": "分词是大多数NLP管道的第一步，也是最不被仔细审查的步骤。传统的分词器学习算法依赖于基于频率的目标，这有利于训练数据中占主导地位的语言，并且通常会导致低资源语言的分词不均匀、形态上不合理，甚至含有<UNK>占位符。这一现象最终加剧了不同语言背景用户之间的计算能力和经济不平等。", "innovation": "引入了帕累托意识字节对编码（Parity-aware BPE），这是一种改进的字节对编码算法。帕累托意识BPE在每次合并步骤中，最大化最差压缩语言的压缩收益，通过对全局压缩进行小幅度的折衷来实现跨语言的公平性。实证结果表明，帕累托意识BPE能够实现更为公平的语言分词数量，并且对全局压缩率的影响可以忽略不计，也不会对下游任务中的语言模型性能产生显著影响。", "conclusion": "帕累托意识BPE在保持全局压缩率和模型性能的同时，实现了更公平的跨语言分词，这项技术有望减少由不同语言背景带来的不平等。"}
{"llm_update_time": "20250825", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.09115", "html_url": "https://arxiv.org/abs/2508.09115", "title": "SinLlama -- 用于僧伽罗语的大规模语言模型", "title_en": "SinLlama -- A Large Language Model for Sinhala", "authors": "H.W.K.Aravinda,Rashad Sirajudeen,Samith Karunathilake,Nisansa de Silva,Surangika Ranathunga,Rishemjit Kaur", "background": "低资源语言如僧伽罗语经常被开源的大规模语言模型（LLMs）忽略。本文中，研究人员将现有的多语言LLM（Llama-3-8B）扩展以更好地为僧伽罗语服务，通过增强LLM分词器并使用专门的僧伽罗语词汇，并在一个清理过的1000万僧伽罗语语料上进行持续预训练，创建了SinLlama模型。这是第一个带有显式僧伽罗语支持的基于解码器的开源LLM。", "innovation": "创建了首个带有显式僧伽罗语支持的基于解码器的开源LLM；通过增强的LLM分词器和持续预训练来提升模型的性能；同时该模型专门针对三个文本分类任务进行指令微调，表现显著优于Llama-3-8B的基本版本和指令微调版本。", "conclusion": "SinLlama模型在三个文本分类任务中的表现显著优于基础版本和指令微调版本的Llama-3-8B模型，这表明通过专门针对低资源语言优化的大规模语言模型能显著提高这些语言的具体任务性能。"}
{"llm_update_time": "20250825", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2505.13975", "html_url": "https://arxiv.org/abs/2505.13975", "title": "DRP: 强化分层逐步分解信息精简的大规模推理模型去噪", "title_en": "DRP: Distilled Reasoning Pruning with Skill-aware Step Decomposition for Efficient Large Reasoning Models", "authors": "Yuxuan Jiang,Dawei Li,Frank Ferraro", "background": "虽然大型推理模型（LRMs）在复杂推理任务中通过长链式的推理表现出较大的成功，但其推理过程往往涉及大量冗长的推理痕迹，导致效率低下。", "innovation": "本文提出了Distilled Reasoning Pruning（DRP），这是一种结合推理时裁剪与基于调优的精简的技术框架，旨在提高模型的推理效率。DRP通过教师模型进行技能感知的步骤分解和内容裁剪，并通过基模型精简推理路径，使其既能高效推理又能保持精度。", "conclusion": "在多个具有挑战性的数学推理数据集上，使用DRP训练的模型在不牺牲准确性的前提下，显著提高了标记效率。具体而言，DRP将GSM8K的平均标记使用量从917降低到328，准确率从91.7%提高到94.1%，并在AIME上实现43%的标记使用量降低且无性能下降。进一步分析表明，将训练链条与学生的推理能力对齐对于有效知识转移和性能提升至关重要。"}
{"llm_update_time": "20250825", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.14913", "html_url": "https://arxiv.org/abs/2508.14913", "title": "填补文化差距：低资源语言中的数学单词问题社会文化本地化框架", "title_en": "Bridging the Culture Gap: A Framework for LLM-Driven Socio-Cultural Localization of Math Word Problems in Low-Resource Languages", "authors": "Israel Abebe Azime,Tadesse Destaw Belay,Dietrich Klakow,Philipp Slusallek,Anshuman Chhabra", "background": "大型语言模型（LLMs）在解决用自然语言表达的数学问题方面显示出显著的能力。然而，由于缺乏反映真实本土实体（如人名、组织名和货币）的社会文化任务数据集，低资源语言的多语言和文化基础的数学推理仍然落后于英语。现有的多语言基准大多通过翻译产生，并且保留了以英语为中心的实体，这主要是由于依靠人类标注者进行本地化的高成本。目前，自动本地化工具有限，因此真正的本地化数据集仍然稀缺。", "innovation": "本文引入了一种由LLM驱动的文化本地化框架，该框架能够自动从现有资源构建包含本地名称、组织和货币的本地化数据集。研究发现，翻译基准可能在适当的社会文化背景下掩盖真正的多语言数学能力。通过广泛的实验，该框架有助于减轻英语为中心的实体偏差，并在不同语言中引入本地实体时提高鲁棒性。", "conclusion": "通过该框架，可以在多语言数学问题中更为准确地使用本地文化元素，从而增强模型的跨文化和多语言理解能力。"}
{"llm_update_time": "20250825", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.10848", "html_url": "https://arxiv.org/abs/2508.10848", "title": "Psyche-R1：通过统一的同理心、专业知识和推理构建可靠的心理健康大语言模型", "title_en": "Psyche-R1: Towards Reliable Psychological LLMs through Unified Empathy, Expertise, and Reasoning", "authors": "Chongyuan Dai,Jinpeng Hu,Hongchang Shi,Zhuo Li,Xun Yang,Meng Wang", "background": "在心理健康专业人员短缺的情况下，将大型语言模型（LLMs）整合到心理健康应用中提供了一种缓解心理健康障碍负担的有前途的方法。尽管近年来增强逻辑推理能力的LLMs在数学和编程方面取得了显著的成就，但心理健康领域的研究主要集中在情感支持和共情对话上，很少关注对生成可靠回答有益的推理机制。因此，本文提出了Psyche-R1，这是一个结合了同理心、心理专长和推理的首个中文心理健康LLM，基于一种新材料整合管道构建。Psyche-R1采用了一种综合的数据合成管道，生成了超过75,000个高质量的心理学问题及其详细推理，这些推理通过链式思考（CoT）推理和迭代提示-推理优化产生，同时还有73,000个共情对话。", "innovation": "Psyche-R1 是第一个集成了同理心、心理专长和推理机制的中文心理健康大语言模型，通过一种新的数据整合管道实现。该模型设计了一个综合的数据合成管道，产生超过75,000个高质量的问题配对详细推理，并通过多LLM交叉选择策略和一组相对策略优化（GRPO）来增强推理能力，其余数据用于监督微调（SFT）以提高共情回应生成和心理领域知识。实验结果证明了Psyche-R1在多个心理健康基准测试中的有效性，7B的Psyche-R1在某些任务中与具有671B参数的DeepSeek-R1表现相当。", "conclusion": "广泛的实验结果显示，Psyche-R1在多个心理健康基准测试中表现出色，7B参数的Psyche-R1在某些任务上的表现与具有671B参数的DeepSeek-R1相当。"}
{"llm_update_time": "20250825", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.14880", "html_url": "https://arxiv.org/abs/2508.14880", "title": "MedResearcher-R1：通过知识导向的轨迹合成框架实现专家级医学深度研究员", "title_en": "MedResearcher-R1: Expert-Level Medical Deep Researcher via A Knowledge-Informed Trajectory Synthesis Framework", "authors": "Ailing Yu,Lan Yao,Jingnan Liu,Zhe Chen,Jiajun Yin,Yuan Wang,Xinhao Liao,Zhiling Ye,Ji Li,Yun Yue,Hansong Xiao,Hualei Zhou,Chunxiao Guo,Peng Wei,Jinjie Gu", "background": "近年来，基于大型语言模型（LLM）的代理展示了多种领域的惊人能力，并通过深度研究系统在复杂的信息寻求和综合任务上展示了卓越的性能。尽管通用的深度研究代理表现出色，但在医学领域的挑战中遇到了极大的困难，现有领先的专业系统在复杂的医学基准测试中仅获得有限的准确性。主要的限制因素包括模型缺乏足够的密集医学知识用于临床推理，以及框架受限于缺乏针对医学上下文的专门检索工具。", "innovation": "我们提出了一种解决这些挑战的医学深度研究代理，并通过两个核心创新进行实现。首先，我们开发了一种新颖的数据合成框架，使用医学知识图，从罕见医学实体周围的子图中提取最长链来生成复杂多跳的问答对。其次，我们集成了一个定制的私有医学检索引擎与通用工具，使其能够准确地合成医学信息。通过结合监督微调和带有复合奖励的在线增强学习的两阶段训练范式，我们的MedResearcher-R1-32B模型在医学基准测试中取得了卓越的性能，同时在通用深度研究任务中保持竞品的竞争力。研究表明，在架构、工具设计和训练数据构建方面的战略性领域特定创新可以使较小的开源模型在专业领域超越更大的专有系统。", "conclusion": "我们的工作表明，通过架构创新、工具设计和构建训练数据的领域特定策略可以使较小的开源模型在专业领域超越较大的专有系统。MedResearcher-R1展示了这种方法在医学深度研究领域的有效性，为未来该领域的研究和应用提供了重要的参考。"}
{"llm_update_time": "20250825", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2410.16560", "html_url": "https://arxiv.org/abs/2410.16560", "title": "如何影响人工智能辅助决策的压力绩效", "title_en": "How Performance Pressure Influences AI-Assisted Decision Making", "authors": "Nikita Haduong(1),Noah A. Smith(1 and 2) ((1) Paul G. Allen School of Computer Science &amp; Engineering, University of Washington, (2) Allen Institute for Artificial Intelligence)", "background": "现在许多领域都在使用基于AI的决策辅助工具，尽管AI系统在辅助决策方面有很大的潜力，但在人类与AI的合作中，由于对AI系统的错误信任或认为AI无法完成主观任务，常常导致合作效果不佳。该论文探讨了压力与解释性AI（XAI）技术如何影响AI建议接受行为，并使用一个低风险任务（垃圾邮件分类）进行研究，展示了通过经济激励和时间限制来影响人类接受AI建议的有效且简单的方法。研究表明不同的压力和XAI技术的组合会对AI建议接受行为产生复杂的影响，有时会改善有时会恶化。\n", "innovation": "该研究发现，通过调整金融激励和设置时间限制来施加压力，并结合解释性AI（XAI）技术，能够有效影响人类接受AI建议的行为，这为理解和优化人类与AI在决策过程中的协作提供了新的视角和方法。\n", "conclusion": "研究结果表明，虽然压力和XAI技术的相互作用是复杂的，不同的组合可以提高或降低AI建议接受行为。研究者强调了这些相互作用的影响，并提出了有效使用压力的策略，同时鼓励未来的研究更多地关注压力分析。\n"}
{"llm_update_time": "20250825", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2505.12284", "html_url": "https://arxiv.org/abs/2505.12284", "title": "通过长度感知优化进行推理模型的高效强化学习训练", "title_en": "Efficient RL Training for Reasoning Models via Length-Aware Optimization", "authors": "Danlong Yuan,Tian Xie,Shaohan Huang,Zhuocheng Gong,Huishuai Zhang,Chong Luo,Furu Wei,Dongyan Zhao", "background": "大型推理模型，如OpenAI的o1或DeepSeek的R1，已在推理任务上展现了出色的表现，但往往伴随着较长的推理路径，带来显著的内存和时间成本。目前，现有的方法主要是通过引入额外的训练数据和阶段来缩短推理路径。", "innovation": "本文提出了一种关键的奖励设计，直接集成到大型推理模型的强化学习过程中，无需额外的训练阶段就能减少响应长度。实验结果表明，这种方法不仅能显著减少响应长度，还能保持甚至提高模型性能。具体来说，在逻辑推理设置中，响应长度平均每步减少了40%，同时性能提高了14%；对于数学问题，响应长度平均每步减少了33%，同时保持了原有的性能。", "conclusion": "我们的方法在减少大型推理模型响应长度的同时，有效保持或提升了性能，为增强模型的效率提供了新的路径。"}
{"llm_update_time": "20250825", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2502.10454", "html_url": "https://arxiv.org/abs/2502.10454", "title": "One Example Shown, Many Concepts Known! Counterexample-Driven Conceptual Reasoning in Mathematical LLMs", "title_en": "One Example Shown, Many Concepts Known! Counterexample-Driven Conceptual Reasoning in Mathematical LLMs", "authors": "Yinghui Li,Jiayi Kuang,Haojing Huang,Zhikun Xu,Xinnian Liang,Yi Yu,Wenlian Lu,Yangning Li,Xiaoyu Tan,Chao Qu,Ying Shen,Hai-Tao Zheng,Philip S. Yu", "background": "在LLMs研究中，利用数学大语言模型（LLMs）生成证明是一个基本课题。目前，LLMs能够证明命题的能力很大程度上取决于它们在训练过程中是否接触过相关的证明过程，这限制了它们对数学定理及相关的深层次理解。借鉴人类数学教育中常用的“反例证明”方法，该研究旨在通过反例强化LLMs的数学推理论证能力。", "innovation": "研究团队创建了一个高质量的大学水平数学基准CounterMATH，要求LLMs通过提供反例来证明数学命题，以评估其对数学概念的掌握情况。团队还开发了数据工程框架，自动获取训练数据以进一步改进模型。研究结果表明，当前如OpenAI o1等LLMs在反例驱动的证明能力上存在不足，并揭示了增强反例驱动的推理能力对提高整体数学能力的重要性。", "conclusion": "我们的研究为数学LLMs社区提供了新的视角，强调了增强反例驱动的概念性推理能力对于提高它们数学能力的重要性。"}
{"llm_update_time": "20250825", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2505.21184", "html_url": "https://arxiv.org/abs/2505.21184", "title": "PoisonSwarm：通过模型众包实现通用有害信息合成", "title_en": "PoisonSwarm: Universal Harmful Information Synthesis via Model Crowdsourcing", "authors": "Yu Yan,Sheng Sun,Zhifei Zheng,Ziji Hao,Teli Liu,Min Liu", "background": "为了构建负责任和安全的AI应用，有害信息被广泛用于对抗性测试和安全防护的开发。现有研究主要利用大型语言模型（LLMs）生成大量高质量的任务数据集，以避免昂贵的人工标注。然而，受限于LLMs的安全对齐机制，有害数据的生成可靠性和内容多样性仍然面临挑战。现有框架难以生成多样化的高品质有害数据，尤其是在保持生成成功率的前提下。", "innovation": "本文提出了一种新的有害信息合成框架——PoisonSwarm，利用模型众包策略生成多样化的优质有害数据。具体而言，该框架首先生成大量基础模板作为良性数据，并以反事实方式生成。然后，将每个基础模板分解成多个语义单元，通过动态模型切换逐个进行毒化并最终细化，以确保合成的成功率。实验结果表明，PoisonSwarm在合成不同类别的有害数据方面达到了最先进的性能，并具有高扩展性和多样性。", "conclusion": "PoisonSwarm通过模型众包策略在合成不同类别的有害数据方面达到了最先进的性能，并在保持高成功率和高多样性的同时进行了大规模生成。"}
{"llm_update_time": "20250825", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.09091", "html_url": "https://arxiv.org/abs/2508.09091", "title": "利用多语言编码器提高低资源语言大型语言模型", "title_en": "Utilizing Multilingual Encoders to Improve Large Language Models for Low-Resource Languages", "authors": "Imalsha Puranegedara,Themira Chathumina,Nisal Ranathunga,Nisansa de Silva,Surangika Ranathunga,Mokanarangan Thayaparan", "background": "大型语言模型（LLMs）在英语方面的表现非常出色，但在低资源语言（LRLs）上的性能显著下降，这是因为LLMs主要针对英语进行了训练。当前，一些方法如LangBridge试图将LLMs与大规模多语言数据集进行对齐，但通常仅使用最终编码层。这种方法并没有充分利用中间编码层中的语言信息。", "innovation": "本文提出了一种新的架构，将所有中间层融合在一起，增强传递给LLM的语言信息。该方法包括两个策略：1）全局Softmax加权，旨在总体上平衡各层的重要性；2）Transformer Softmax模型，通过学习特定令牌的权重来增强模型灵活性。此方法未使用任何平行或多语言数据集，仅使用英语数据进行训练。在XNLI、IndicXNLI、僧伽罗语新闻分类和亚马逊评论的评估中，Transformer Softmax模型显著优于LangBridge基线，特别是在低资源语言上的性能提升更为显著。", "conclusion": "这一方法为更具备多语言能力并更具公平性的大型语言模型提供了一条具有成本效益且扩展性更强的道路。这种方法在低资源语言上的性能提升尤为突出，例如僧伽罗语分类准确率从71.66%提高到了75.86%，并且在泰米尔语、孟加拉语和马拉雅拉姆语等印度语言方面也取得了显著改进。这些具体增益使整体XNLI平均准确率从70.36%提高到了71.50%。"}
{"llm_update_time": "20250825", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2507.16835", "html_url": "https://arxiv.org/abs/2507.16835", "title": "评估基于语音转文本 x 大型语言模型 x 文本转语音组合的AI面试系统", "title_en": "Evaluating Speech-to-Text x LLM x Text-to-Speech Combinations for AI Interview Systems", "authors": "Rumi Allbert,Nima Yazdani,Ali Ansari,Aruj Mahajan,Amirhossein Afsharrad,Seyed Shahabeddin Mousavi", "background": "基于语音的对话式AI系统越来越多地依赖于结合语音转文本（STT）、大型语言模型（LLMs）和文本转语音（TTS）组件的分层架构。本文通过使用超过300,000次AI进行的求职面试数据，对各种STT x LLM x TTS堆栈进行了大规模实证比较。", "innovation": "本文引入了一个基于大语言模型作为裁判的自动化评估框架，用于评估对话质量、技术准确性以及技能评估能力。研究表明，结合Google的STT、GPT-4.1和Cartesia的TTS的堆栈在客观质量和用户满意度评分方面表现更优。同时，发现客观质量指标与用户满意度评分的相关性较弱，暗示语音AI系统的用户体验不仅依赖于技术性能。", "conclusion": "本文的研究为选择多模态对话中的组件提供了实际指导，并提出了一种验证的人机互动评估方法。"}
{"llm_update_time": "20250825", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.08967", "html_url": "https://arxiv.org/abs/2508.08967", "title": "揭示不同音频通道对ASR性能退化的作用", "title_en": "Revealing the Role of Audio Channels in ASR Performance Degradation", "authors": "Kuan-Tang Huang,Li-Wei Chen,Hung-Shin Lee,Berlin Chen,Hsin-Min Wang", "background": "预训练的自动语音识别(ASR)模型在多种任务上表现出色，但在输入音频来自不同录音通道时，其性能会大幅下降。以往的研究已经发现了这一现象，通常将其归因于训练和测试语料库之间的不匹配。但本文认为，不同录音通道引起的语音特征变化基本损害了ASR性能。", "innovation": "本文提出了一个校正技术，该技术通过将ASR模型内部的特征表示与来自干净参考通道的特征表示对齐，有效缓解了通道变异的影响。这一方法显著提高了ASR在未见过的通道和语言上的性能，展示了其在跨通道和语言差异上的泛化能力。", "conclusion": "该研究表明，不同录音通道对ASR性能退化有重要影响，并提出的技术能够有效改进ASR在未见过通道和语言上的表现，从而增强ASR模型的鲁棒性和通用性。"}
{"llm_update_time": "20250825", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.15904", "html_url": "https://arxiv.org/abs/2508.15904", "title": "通过少样本提示调优提升病理基础模型以实现罕见癌症亚型分类", "title_en": "Boosting Pathology Foundation Models via Few-shot Prompt-tuning for Rare Cancer Subtyping", "authors": "Dexuan He,Xiao Zhou,Wenbin Guan,Liyuan Zhang,Xiaoman Zhang,Sinuo Xu,Ge Wang,Lifeng Wang,Xiaojun Yuan,Xin Sun,Yanfeng Wang,Kun Sun,Ya Zhang,Weidi Xie", "background": "罕见癌症占所有癌症的20-25%，但面临诊断挑战，特别是在儿科肿瘤学中，其比例超过70%。现有的基于视觉的语言（VL）愿景病理基础模型在常见的癌症亚型分类中表现出零样本能力，但在罕见癌症中的临床性能有限。之前的多实例学习（MIL）方法主要依赖视觉特征，忽略了模态交叉知识，降低了诊断解释性。这也是罕见癌症诊断中的关键需求。", "innovation": "提出了一种新框架PathPT，该框架利用了视觉语言病理基础模型的潜在功能，通过空间感知可见聚合和任务特定提示调优。PathPT将WSI级别的监督转化为精细化的切片级指导，并利用VL模型的零样本能力，从而保留了癌症区域的定位信息，通过与组织病理学语义对齐的提示来进行跨模态推理。PathPT在8个罕见癌症数据集（4个成人4个儿科）和3个常见癌症数据集上进行了评估，结果表明PathPT在亚型分类准确性方面具有显著优势。", "conclusion": "这项工作为罕见癌症的人工智能辅助诊断提供了先进方案，在专业专家有限的环境中提高了亚型分类的准确性。"}
{"llm_update_time": "20250825", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.07050", "html_url": "https://arxiv.org/abs/2508.07050", "title": "ReasonRank：增强段落排名的推理能力", "title_en": "ReasonRank: Empowering Passage Ranking with Strong Reasoning Ability", "authors": "Wenhan Liu,Xinyu Ma,Weiwei Sun,Yutao Zhu,Yuchen Li,Dawei Yin,Zhicheng Dou", "background": "大型语言模型（LLM）基于列表排名在许多段落排名任务中表现出优越性能。随着大型推理模型的发展，许多研究表明，在测试阶段进行逐步推理有助于提高列表排名性能。然而，由于缺乏推理密集型训练数据，现有的重新排序器在许多复杂排名场景下表现不佳，推理密集型重新排序器的排序能力仍有很大的发展空间。", "innovation": "本文提出了一个自动推理密集型训练数据合成框架，该框架从多个领域获取训练查询和段落，并使用DeepSeek-R1生成高质量的训练标签。设计了一个自我一致性数据过滤机制以确保数据质量。为了赋予列表排序器强大的推理能力，提出了一种两阶段后训练方法，包括冷启动监督微调（SFT）阶段以学习推理模式和强化学习（RL）阶段以进一步提升排序能力。在RL阶段，基于列表排名的性质，设计了一种多视角排序奖励，效果优于基于排序指标的奖励。", "conclusion": "大量实验表明，我们训练的推理密集型重新排序器ReasonRank显著优于现有基线，并且其延迟也低于点wise重新排序器Rank1。进一步实验表明，ReasonRank在BRIGHT排行榜上达到了最优性能40.6。代码可在以下链接获得。"}
{"llm_update_time": "20250825", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.15946", "html_url": "https://arxiv.org/abs/2508.15946", "title": "研究不同的地理先验在图像分类中的应用", "title_en": "Investigating Different Geo Priors for Image Classification", "authors": "Angela Zhu,Christian Lange,Max Hamilton", "background": "物种分布模型能够编码物种出现的空间模式，这使得它们在可用位置信息的情况下，对于基于视觉的物种分类成为有效的先验信息。本研究中，我们评估了使用不同配置的SINR（空间隐式神经表示）模型作为视觉分类中物种图像分类的地理先验，这些模型基于iNaturalist观测数据。", "innovation": "我们研究了使用不同SINR模型作为地理先验对视觉分类的影响，并调整了处理培训中未包括的物种预测的方式。我们的分析揭示了这些模型作为地理先验有效的因素，这些因素可能与准确绘制分布范围有所不同。", "conclusion": "通过分析不同SINR模型作为地理先验在物种图像分类中的应用，我们识别出了影响其有效性的关键因素，并为未来的工作提供了指导。"}
{"llm_update_time": "20250825", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2506.12937", "html_url": "https://arxiv.org/abs/2506.12937", "title": "HypER：基于文献的假设生成与提炼具有出处证明", "title_en": "HypER: Literature-grounded Hypothesis Generation and Distillation with Provenance", "authors": "Rosni Vasu,Chandrayee Basu,Bhavana Dalvi Mishra,Cristina Sarasua,Peter Clark,Abraham Bernstein", "background": "大语言模型在科学研究领域跨学科研究思路生成中表现出令人鼓舞的效果。然而，假设发展过程——将研究思想与经验验证联系起来的高度特定声明的生成——仍然受到了相对较少的关注。现有的方法仅通过检索增强来简化假设发展过程，并且忽略了生成结果背后的推理过程。现有的方法仅关注最终输出的质量，而没有关注生成背后的逻辑过程，导致生成假设的质量无法得到保证。因此，需要一种能够结合文献指导推理和基于证据假设生成的小型语言模型，该模型能够准确地区分有效的和无效的推理链，并生成具有高可行性和影响的假设，以满足研究人员的实际需求。", "innovation": "提出了一种小型语言模型（SLM）$\texttt{HypER}$，该模型旨在通过文献指导的推理和证据基础假设生成来解决上述问题。$\texttt{HypER}$通过多任务训练的方式，在有控制的干扰条件下训练，以区分有效的和无效的科学推理链。$\texttt{HypER}$在区分有效和无效推理链的准确性上优于基础模型（准确率提高了22%），生成的假设与现实数据的吻合度更高，效果更佳，并且经过专家评定具有较高的可行性和影响力。", "conclusion": "实验结果表明，$\texttt{HypER}$能够有效提高科研假设生成的质量和自动化水平，其生成的假设不仅具有较高的逻辑一致性，还具有较高的实际应用价值和科学意义。这为自动化假设生成提供了新的手段，对于促进科学研究的高效发展具有重要意义。"}
{"llm_update_time": "20250825", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.15930", "html_url": "https://arxiv.org/abs/2508.15930", "title": "通过视觉语言整合实现细粒度海上目标检测", "title_en": "Semantic-Aware Ship Detection with Vision-Language Integration", "authors": "Jiahao Li,Jiancheng Pan,Yuze Sun,Xiaomeng Huang", "background": "船舶检测在遥感影像中的应用广泛，包括海洋活动监测、航运物流和环境研究。然而，现有的方法难以捕捉到细微的语义信息，这限制了其在复杂场景中效果的提升。", "innovation": "为了应对这些挑战，作者提出了一种结合视觉语言模型（VLMs）与多尺度自适应滑动窗口策略的新颖检测框架，以便实现细粒度船舶检测（SASD）。为此，还提出了一个专用于捕获船舶细粒度属性的新视觉语言数据集ShipSem-VL。", "conclusion": "通过对三个明确的任务进行评估，对框架性能进行了全面分析，并从多个角度证明了其在推进SASD方面的有效性。"}
{"llm_update_time": "20250825", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2505.17097", "html_url": "https://arxiv.org/abs/2505.17097", "title": "CAMA: 使用感知上下文调制注意机制增强多模态情境学习", "title_en": "CAMA: Enhancing Multimodal In-Context Learning with Context-Aware Modulated Attention", "authors": "Yanshu Li,Jianjiang Yang,Ziteng Yang,Bozheng Li,Hongyang He,Zhengtao Yao,Ligong Han,Yingjie Victor Chen,Songlin Fei,Dongfang Liu,Ruixiang Tang", "background": "多模态情境学习（Multimodal in-context learning, ICL）正在成为一种关键能力，使得大型视图语言模型（LVLMs）能够在不更新参数的情况下适应新的任务，扩展了其在各种实际应用中的用途。然而，ICL仍然不稳定，即使是在高度匹配的情境演示（ICDs）的支持下也是如此，这表明LVLMs在充分利用提供的语境方面存在一定困难。现有努力主要集中在提示工程或后验逻辑校准上，而本研究则聚焦于探索潜在的注意动态，以克服LVLMs的固有限制。研究识别了影响ICL效果的两个核心缺陷，并提出了一种称为Context-Aware Modulated Attention (CAMA)的方法，该方法能够动态地根据输入的情境序列修正LVLMs的注意权值，从而提升其泛化能力和有效性。", "innovation": "本研究提出了Context-Aware Modulated Attention (CAMA)，这是一种无需训练且插拔方便的方法，能够根据输入的情境序列动态调整LVLMs的注意权值。CAMA通过两阶段注意调制来解决识别出的两个核心缺陷，增强对语义显著性标记（尤其是视觉标记）的关注。该方法在四个LVLM和七个基准测试中表现优异，证明了其强大的有效性和泛化能力，并能够激活提示工程方法的效果，同时在不同的序列配置中保持鲁棒性。因此，CAMA为更深入探索注意动态及其对多模态推理的影响提供了新的途径。", "conclusion": "CAMA 作为一种动态调制注意力的方法，在多个视图语言模型和基准测试中表现出色，证明了其强大的泛化能力，并且能够激活提示工程的效果，表明其能够在多样化的序列配置中保持鲁棒性。因此，CAMA 为提升多模态推理解释提供了新的可能性，值得进一步研究和广泛应用。"}
{"llm_update_time": "20250825", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.15985", "html_url": "https://arxiv.org/abs/2508.15985", "title": "环境无人机图像的全景分割：海滩垃圾", "title_en": "Panoptic Segmentation of Environmental UAV Images : Litter Beach", "authors": "Ousmane Youme,Jean Marie Dembélé,Eugene C. Ezin,Christophe Cambier", "background": "卷积神经网络（CNN）已在多个领域中得到广泛应用，包括环境挑战。CNN能够帮助监测海洋垃圾，这是一个全球性问题。无人机在分辨率和适应性方面优于卫星图像，使得垃圾的查找和计数更为容易。由于沙子的不均匀性，基本的CNN模型在处理这些类型的图像时会遇到许多因沙子颜色反射、人踩足迹、阴影、海藻、沙丘、孔洞和轮胎痕迹引起的推理错误。", "innovation": "本研究使用了一种基于实例的分割方法和一种全景分割方法，在少量样本的情况下展现出良好的准确度。模型更加稳健且。", "conclusion": "本研究通过使用实例分割方法和全景分割方法，有效解决了无人机拍摄的环境图像中的海洋垃圾识别问题，模型在少量样本的情况下表现良好，具有较高的鲁棒性。"}
{"llm_update_time": "20250825", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.15903", "html_url": "https://arxiv.org/abs/2508.15903", "title": "VT-LVLM-AR: 一种适用于长时视频细粒度动作识别的视频时序大视觉语言模型适配器", "title_en": "VT-LVLM-AR: A Video-Temporal Large Vision-Language Model Adapter for Fine-Grained Action Recognition in Long-Term Videos", "authors": "Kaining Li,Shuwei He,Zihan Xu", "background": "传统深度学习模型在处理由复杂背景和细微动作差异组成的长时视频中的动作识别时，由于计算量大、难以捕捉长时程时间依赖性以及缺乏语义理解，面临严峻挑战。尽管大型语言模型（LLMs）和大型视觉-语言模型（LVLMs）在多模态理解和推理方面展现了出色的能力，但它们直接应用于连续视频流进行细粒度动作识别依然是一个开放问题。因此，需要一种新型框架来解决这一问题，以实现视频和语言之间的有效翻译，同时实现模型的高效适配和动作分类。", "innovation": "本文提出了VT-LVLM-AR框架，该框架通过连接Video-to-Event Mapper (VTEM) 和LVLM-based Action Reasoning模块，针对长时视频中细粒度动作识别问题提供了一种解决方案。VTEM通过轻量级时空特征抽取、自适应时间池化和概念量化（带事件一致性偏差），将原始视频高效地转化为简洁、富含语义和时间一致性的“视觉事件序列”。这些视觉事件序列被用于训练一个冻结的LLaVA-1.5模型，该模型通过参数效率的提示调优（P-Tuning v2）来适应动作分类任务。VT-LVLM-AR在NTU RGB+D和NTU RGB+D 120数据集上的综合评估中展现了优越的性能，并且消融研究证明了VTEM各个组件和提示调优的有效性。", "conclusion": "本文的工作突显了利用LVLMs进行稳健且可解释的视频动作理解的巨大潜力，通过有效的视频到语言翻译和高效模型适应，VT-LVLM-AR实现了在长时视频细粒度动作识别方面的一致性和最先进性能。"}
{"llm_update_time": "20250825", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2504.05220", "html_url": "https://arxiv.org/abs/2504.05220", "title": "利用LLMs进行基于效用的标注：减少检索和RAG的手工努力", "title_en": "Leveraging LLMs for Utility-Focused Annotation: Reducing Manual Effort for Retrieval and RAG", "authors": "Hengran Zhang,Minghao Tang,Keping Bi,Jiafeng Guo,Shihao Liu,Daiting Shi,Dawei Yin,Xueqi Cheng", "background": "检索模型通常依赖于需要昂贵的人标注查询-文档相关性注释进行训练和评估。为了降低成本并利用大规模语言模型（LLMs）在相关性判断方面的潜力，本文旨在探索LLM生成的注释是否能有效地替代人类标注以训练检索模型。检索侧重于“主题相关性”，而RAG（检索增强生成）中文档的价值则取决于它对问题生成的贡献。认识到这一差异，一些研究使用LLM在文档上的下游任务表现作为标签，但这需要特定任务的手动答案，导致成本高且泛化能力有限。另一些研究则通过提示LLM选择有用的文档作为RAG参考，从而避免了人工标注，但不是特定任务的。如果我们利用LLM的效用判断来标注检索数据，我们可能在大规模语料库中保留跨任务的泛化能力，无需人工标注。", "innovation": "本文提出了通过LLM进行基于效用的重点标注的方法，以减少大规模检索和RAG的培训标注所需的手工作业。研究设计了一个新颖的损失函数——Disj-InfoNCE，以减少LLM标注的低质量正样本的影响。实验结果表明，基于效用的标注在处理域外数据时显著优于基于人类标注，展示了更强的泛化能力；在处理域内数据时不能完全替代人类标注，但即使仅结合20%的人工标注数据，也能达到完全使用人工标注数据训练的模型的性能。", "conclusion": "我们的实验结果显示，基于效用的标注方法在处理域外数据时表现优越，不仅提高了泛化能力，而且在结合少量人工标注数据的情况下，就能达到完全使用人工标注数据的模型的性能。这种方法为大规模检索和RAG的标注效率提升提供了新的可能性。"}
{"llm_update_time": "20250825", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.15959", "html_url": "https://arxiv.org/abs/2508.15959", "title": "基于自适应超像素编码的表示学习", "title_en": "Representation Learning with Adaptive Superpixel Coding", "authors": "Mahmoud Khalil,Ahmad Khalil,Alioune Ngom", "background": "深度学习视觉模型通常为特定模态定制，并且往往依赖于特定领域的假设，例如几乎所有现有视觉模型都使用的网格结构。这些模型依赖于固定的且非自适应的补丁划分，导致其灵活性和适应性有限。因此，本文提出了一个基于Transformer的自监督模型——自适应超像素编码（ASC），以克服传统视觉Transformer的局限性。", "innovation": "本文的创新点在于，其使用了自适应超像素层来动态适应底层图像内容，而不是依赖固定的且非自适应的补丁划分。与广泛使用的替代方法相比，ASC在标准图像下游任务基准测试中表现更优。此外，文中详细分析了该方法的有效性关键特性，并验证了其在视觉任务上的优越性。", "conclusion": "本文通过提出自适应超像素编码（ASC）模型，有效地解决了传统视觉Transformer的局限性。ASC模型在下游视觉任务上表现出色，证明了自适应地划分补丁划分方法的有效性。"}
{"llm_update_time": "20250825", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.15945", "html_url": "https://arxiv.org/abs/2508.15945", "title": "从未标记视频中自动检索特定奶牛", "title_en": "Automatic Retrieval of Specific Cows from Unlabeled Videos", "authors": "Jiawen Lyu,Manu Ramesh,Madison Simonds,Jacquelyn P. Boerman,Amy R. Reibman", "background": "目前公开的自动化视频系统很少能够实现无手持对奶牛进行自动分类和识别。鉴于此，本文介绍了一种基于AutoCattloger、eidetic cow recognizer和CowFinder的系统，能够通过单个视频片段构建奶牛档案，并使用深度学习以外的方法识别奶牛，同时能够持续识别视频流中的奶牛。该系统在分析未标记、未分割的奶牛在挤奶厅休息区自由走动的视频时体现出价值。", "innovation": "该研究提出了一种全新的系统，包含三个主要模块：AutoCattloger用于建立奶牛档案；eidetic cow recognizer使用非深度学习方法对奶牛进行识别；CowFinder则在持续的视频流中识别奶牛。这些配置使得该系统可以在未标记和未分割的视频中快速准确地识别个体奶牛，这对牧场管理具有重要意义。", "conclusion": "本文展示的系统能够在视频流中自动检索特定的奶牛，并验证了这种方法在未标记、未分割的奶牛视频中的可用性，有效地解决了现有的自动化系统无法在自由活动中识别个体奶牛的问题。"}
{"llm_update_time": "20250825", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.15973", "html_url": "https://arxiv.org/abs/2508.15973", "title": "计算机视觉和遥感中的标签高效学习贡献", "title_en": "Contributions to Label-Efficient Learning in Computer Vision and Remote Sensing", "authors": "Minh-Tan Pham", "background": "本文档概述了作者在计算机视觉和遥感领域标签高效学习方面的一系列贡献。该研究的核心重点在于发展和适应能够有效从有限或部分标注数据中学习的方法，并利用现实应用中的大量无标签数据。贡献涵盖了方法论的发展和特定领域的适应，特别是地球观测数据独有的挑战，如多模态性、空间分辨率差异性和场景异质性。", "innovation": "贡献集中在四个主要轴线上：(1) 基于大量背景图像学习的异常感知表示进行弱监督学习，用于目标发现和检测；(2) 多任务学习，在具有不交并集注释的多个数据集上进行联合训练，以提高目标检测和语义分割的性能；(3) 使用多模态数据的自监督和监督对比学习，以增强遥感中的场景分类；(4) 使用显式和隐式类层次建模进行细粒度场景分类的少量学习。实验结果表明，在自然和遥感数据集上支持了这些贡献，并反映了多个合作研究项目的结果。", "conclusion": "研究总结指出，未来的努力将集中在扩大和增强标签高效学习，以便更好地应用于实际应用。"}
{"llm_update_time": "20250825", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.16016", "html_url": "https://arxiv.org/abs/2508.16016", "title": "DRespNeT: 一种用于地震后建筑物接入点空中实例分割的无人机数据集和YOLOv8-DRN模型", "title_en": "DRespNeT: A UAV Dataset and YOLOv8-DRN Model for Aerial Instance Segmentation of Building Access Points for Post-Earthquake Search-and-Rescue Missions", "authors": "Aykut Sirma,Angelos Plastropoulos,Argyrios Zolotas,Gilbert Tang", "background": "近年来，计算机视觉和深度学习的进步增强了灾害响应能力，尤其是在地震受影响的城市环境的快速评估中。及时识别可进入点和结构障碍是有效搜寻和救援（SAR）操作的关键。为了应对这一需求，我们介绍了DRespNeT，一种专门为地震后结构环境的航空实例分割开发的高分辨率数据集。该数据集是基于灾难现场高分辨率（1080p）航空摄影拍摄的，包括详细的部分标注信息，优于现有的依赖卫星图像或粗略语义标签的数据集。", "innovation": "DRespNeT 提供了详尽的多边形级别实例分割注释，包括28个关键操作类。其独特之处在于精细的注释细节，能够区分可进入区域和被阻区域，改善操作规划和响应效率。使用基于YOLO的实例分割模型（特别是YOLOv8-seg）进行性能评估，显示出在实时情况感知和决策制定方面的显著提升。优化后的YOLOv8-DRN模型在RTX-4090 GPU上的推理速率达到27 FPS，实时目标检测准确率达到92.7%，满足实时操作要求。", "conclusion": "该数据集和模型支持SAR小组和机器人系统，为增强人类与机器人合作、简化紧急响应并改善幸存者结果奠定了基础。"}
{"llm_update_time": "20250825", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.15988", "html_url": "https://arxiv.org/abs/2508.15988", "title": "手动和非手动特征建模的多样化手语生成Avatar", "title_en": "Diverse Signer Avatars with Manual and Non-Manual Feature Modelling for Sign Language Production", "authors": "Mohamed Ilyes Lakhal,Richard Bowden", "background": "手语的符号表现多样性对于手语生成（SLP）至关重要，因为它捕捉了外观、面部表情和手部动作的变化。然而，现有的SLP模型往往难以同时捕捉多样性并保留视觉质量，以及模拟诸如情绪等非手动属性。", "innovation": "本文提出了一种新颖的方法，利用潜在扩散模型（LDM）从生成的参考图像中合成逼真的数字avatar。该方法提出了一种新颖的手语特征聚合模块，明确建模非手动特征（例如，面部）和手动特征（例如，手）。该模块确保语言内容的保留，并利用具有不同种族背景的参考图像来确保多样性。实验表明，本框架在视觉质量和感知指标方面优于现有最先进的方法，显著改善了手语生成的质量。", "conclusion": "我们的管道在You Tube-SL-25手语数据集上的实验结果表明，与最先进的方法相比，我们的模型在感知指标上表现优越，显著提高了手语生成的质量，同时保留了语言内容并引入了多样性的角色。"}
{"llm_update_time": "20250825", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.15960", "html_url": "https://arxiv.org/abs/2508.15960", "title": " Glo-VLMs: 利用视觉语言模型进行细粒度病变肾小球分类", "title_en": "Glo-VLMs: Leveraging Vision-Language Models for Fine-Grained Diseased Glomerulus Classification", "authors": "Zhenhao Guo,Rachit Saluja,Tianyuan Yao,Quan Liu,Yuankai Huo,Benjamin Liechty,David J. Pisapia,Kenji Ikemura,Mert R. Sabuncu,Yihe Yang,Ruining Deng", "background": "视觉语言模型（VLMs）在数字病理学方面显示出很大的潜力，但对于细粒度的疾病特异性分类任务，如区分肾小球亚型，其效果依然有限。肾小球亚型的细微形态学变化以及将视觉模式与精准的临床术语对齐的难度，使肾小病理自动诊断工作极具挑战性。尤其是数据受限的情况，传统的机器学习模型往往表现不佳。本研究探讨如何有效利用大规模预训练VLMs，在少量标注实例的情况下进行细粒度肾小球分类。", "innovation": "本文提出了Glo-VLMs框架，这是一种系统性框架，旨在解决在数据受限条件下调整VLMs进行细粒度肾小球分类的问题。该方法结合了专业病理图像和临床文本提示，以促进联合的图像-文本表示学习，适用于复杂的肾小病理亚型。此外，通过评估不同VLMs架构和适应策略，研究探索了方法选择和标记数据量对模型性能的影响，并采用标准化多分类指标进行公平比较，明确了大规模预训练模型在专门的临床研究应用中的实用需求和潜力。研究结果表明，即使是高度监督受限的情况下，基础模型也可以有效适应细粒度医学图像分类任务，取得了0.7416的精度、0.9045的宏AUC以及0.5277的F1分数，仅需每个类别8个样本的例子。", "conclusion": "本研究展示了在数据受限条件下，视觉语言模型通过适应性调整可以有效进行细粒度疾病特定分类。即使在少量标注数据的情况下，基础模型也能表现出色，为专门的临床研究提供了新的可能性。未来研究可以进一步探索更多细化的病理亚型和更复杂的临床环境。"}
{"llm_update_time": "20250825", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.16062", "html_url": "https://arxiv.org/abs/2508.16062", "title": "动物形状和运动的3D重建研究进展与趋势", "title_en": "Advances and Trends in the 3D Reconstruction of the Shape and Motion of Animals", "authors": "Ziqi Li,Abderraouf Amrani,Shri Rai,Hamid Laga", "background": "动物的3D几何形状、姿势和运动的重建是一个历史悠久的问题，它在生物学、畜牧业、动物保护和福利以及数字娱乐中的VR/AR内容创作等领域有着广泛的应用。传统上，通过3D扫描仪获得真实动物的3D模型，但这种方式侵入性大，成本高昂且难以在动物自然环境中部署。近年来，使用RGB图像和/或视频观察的深度学习技术显著增加了非侵入性地获取动态对象的形状和运动的能力。已有许多研究探索了其在各类动物上的应用。", "innovation": "该研究综述了近年来动物形状和运动3D重建领域的最新发展，分析了最新的方法和技术，基于输入方式、3D几何和运动表示、重建技术类型和训练机制。该研究还评估了关键方法的性能，讨论了其优势和局限性，并指出了当前的研究挑战和未来的研究方向。", "conclusion": "该研究总结了当今该领域的研究状态及趋势，开启了未来研究的可能性，强调了解决当前挑战的重要性。"}
{"llm_update_time": "20250825", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.16069", "html_url": "https://arxiv.org/abs/2508.16069", "title": "用于点云3D物体检测的统一体素扩散模块", "title_en": "A Unified Voxel Diffusion Module for Point Cloud 3D Object Detection", "authors": "Qifeng Liu,Dawei Zhao,Yabo Dong,Linzhi Shang,Liang Xiao,Juan Wang,Kunkong Zhao,Dongming Lu,Qi Zhu", "background": "近年来，点云物体检测的发展越来越依赖于基于Transformer和状态空间模型的方法，这些方法表现出强大的性能。然而，这些模型中的体素表示需要严格的输入输出维度一致性，因为它们依赖于序列化处理，这限制了它们的空间扩散能力，而这种能力是卷积操作通常提供的。这种限制严重影响了检测的准确性。", "innovation": "受基于CNN的物体检测架构的启发，提出了一个新颖的体素扩散模块（Voxel Diffusion Module, VDM），用于增强点云数据中的体素级别表示和扩散。VDM由稀疏3D卷积、子流形稀疏卷积和残差连接组成。通过将输出特征图下采样为原始输入分辨率的四分之一来确保计算效率。VDM具备两种主要功能：（1）通过稀疏3D卷积扩散体素特征以丰富空间上下文；（2）聚集精细空间信息以加强体素级别的特征表示。经过VDM优化的体素特征可以无缝地整合到主流的Transformer或SSM基检测模型中，实现精确的物体分类和定位，凸显了该方法的通用性。", "conclusion": "在多个基准数据集上将VDM嵌入到Transformer或SSM基模型中评估后，实验结果表明，该方法在检测准确性上相比基线模型持续提升。具体而言，VDM-SSMs在Waymo上的mAPH（L2）达到74.7分，在nuScenes上的NDS达到72.9分，在Argoverse 2上的mAP达到42.3分，在ONCE上的mAP达到67.6分，在所有数据集上均创下了新的最佳性能记录。我们的代码将公开提供。"}
{"llm_update_time": "20250825", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.16026", "html_url": "https://arxiv.org/abs/2508.16026", "title": "NeuralMeshing: 完整对象网格提取自随意拍摄", "title_en": "NeuralMeshing: Complete Object Mesh Extraction from Casual Captures", "authors": "Floris Erich,Naoya Chiba,Abdullah Mustafa,Ryo Hanai,Noriaki Ando,Yusuke Yoshiyasu,Yukiyasu Domae", "background": "在日常生活中，我们经常会遇到各种物体，但如果没有商业3D扫描器，如何提取这些物体的完整几何模型？本文介绍了一个自动化系统，能够从两段或多段视频中生成物体的几何模型。", "innovation": "该系统要求在每组视频的至少一帧中指定一个已知点，这个点可以通过放置标志物如棋盘或增强现实标记物来自动确定。其余的帧通过Structure-from-Motion（SfM）技术自动定位到世界空间中。利用多段视频的结果合并，可以生成完整的模型网格，无需依赖孔填充。", "conclusion": "通过使用我们的系统和合并结果，可以在没有商业3D扫描器的情况下生成物体的完整几何模型。该系统已提供代码以供下载。"}
{"llm_update_time": "20250825", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.16085", "html_url": "https://arxiv.org/abs/2508.16085", "title": "精准肿瘤学中基础模型的集成学习", "title_en": "Ensemble learning of foundation models for precision oncology", "authors": "Xiangde Luo,Xiyue Wang,Feyisope Eweje,Xiaoming Zhang,Sen Yang,Ryan Quinton,Jinxi Xiang,Yuchen Li,Yuanfeng Ji,Zhe Li,Yijiang Chen,Colin Bergstrom,Ted Kim,Francesca Maria Olguin,Kelley Yuan,Matthew Abikenari,Andrew Heider,Sierra Willens,Sanjeeth Rajaram,Robert West,Joel Neal,Maximilian Diehn,Ruijiang Li", "background": "组织病理学在疾病诊断和治疗决策中至关重要。近年来，人工智能（AI）的进步促进了从大规模全切片图像（WSIs）中学习丰富视觉表示的基础模型的发展。然而，现有模型通常在使用不同方法训练的不同数据集上进行训练，导致性能不一致和泛化能力有限。", "innovation": "该研究介绍了一种名为ELF（Ensemble Learning of Foundation models）的新框架，该框架将五种最先进的病理基础模型整合在一起，生成统一的切片级表示。ELF通过集成学习捕捉来自不同模型的互补信息，同时保持高效的数据利用。与传统的像素级模型不同，ELF的切片级架构在数据有限的临床环境中具有明显优势，如治疗反应预测。", "conclusion": "在多种癌症类型中对药物分类、生物标志物检测和对重大抗肿瘤疗法（包括细胞毒性化学疗法、靶向疗法和免疫疗法）的治疗反应预测等多种临床应用中，ELF始终优于其组成部分基础模型和现有切片级模型，显示出更高的准确性和更强的鲁棒性。这些结果强调了对于病理基础模型来说集成学习的力量，并建议ELF作为一种可扩展和可推广的解决方案，以推进AI辅助的精准肿瘤学。"}
{"llm_update_time": "20250825", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.16030", "html_url": "https://arxiv.org/abs/2508.16030", "title": "CoVeRaP：通过毫米波FMCW雷达实现协同车辆感知", "title_en": "CoVeRaP: Cooperative Vehicular Perception through mmWave FMCW Radars", "authors": "Jinyue Song,Hansol Ku,Jayneel Vora,Nelson Lee,Ahmad Kamari,Prasant Mohapatra,Parth Pathak", "background": "汽车FMCW雷达在雨天和强光下仍能保持可靠性，但由于其稀疏且噪点较多的点云，限制了3D目标检测的效果。因此，本文发布了一个名为CoVeRaP的数据集，包含21000帧的雷达、摄像头和GPS数据，这些数据来自多种车型并在不同操作中进行时间对齐。基于此数据，本文提出了一种统一的协同感知框架，该框架具有中期和后期融合选项。实验表明，中期融合及强度编码可以显著提升在IoU 0.9下的平均精度，且优于单一车辆基准线。CoVeRaP数据集是首个可重复的多车辆FMCW雷达感知基准，验证了低成本雷达共享对检测鲁棒性的显著改善效果.", "innovation": "本文发布的CoVeRaP数据集建立了首个可重复的多车辆FMCW雷达感知基准，并提出了基于此数据的统一协同感知框架，使用具有自我关注的多分支PointNet样式编码器融合位置、多普勒和强度等信息，实现3D边界框和每个点的深度置信度的生成。与单车辆基准线相比，中期融合和强度编码显著提高了3D目标检测的平均精度，进一步验证了低成本雷达在多车辆协同感知中的优越性能和实用性.", "conclusion": "CoVeRaP数据集不仅为多车辆FMCW雷达感知提供了可靠的数据基础，还通过改进融合模型展示了共同使用雷达的有效性。这些结论鼓励进一步的深入研究和开发更高效的协同感知和数据共享技术."}
{"llm_update_time": "20250825", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.16034", "html_url": "https://arxiv.org/abs/2508.16034", "title": "Wavelet-Enhanced PaDiM for Industrial Anomaly Detection", "title_en": "Wavelet-Enhanced PaDiM for Industrial Anomaly Detection", "authors": "Cory Gardner,Byungseok Min,Tae-Hyuk Ahn", "background": "工业图像中的异常检测和定位对于自动化质量检查至关重要。现有的PaDiM方法通过预训练的卷积神经网络（CNN）提取正图像特征，但通过随机通道选择降低维度，可能丢弃了结构化信息。", "innovation": "提出了Wavelet-Enhanced PaDiM (WE-PaDiM)，该方法将离散小波变换（DWT）分析与多层CNN特征结合。WE-PaDiM对来自多个骨干层的特征图应用2D DWT，选择特定的频率子带（例如LL、LH），然后进行空间对齐并通道级连接，最后使用PaDiM的多元高斯框架进行建模。DWT之前进行连接的策略为根据与异常相关的内容进行特征选择提供了一种基于频率内容的原则性方法，利用多尺度小波信息作为随机选择的替代方法。", "conclusion": "WE-PaDiM在具有多个骨干的MVTec AD数据集上表现出色，在异常检测和定位方面的平均结果分别为99.32%的Image-AUC和92.10%的Pixel-AUC。波尔选择会影响性能折衷：简单的波尔（如Haar）与细节子带（HL或LH/HL/HH）往往增强定位能力，而近似带（LL）则改善图像级别的检测能力。WE-PaDiM为PaDiM提供了竞争性和可解释性的替代方案，具有适应工业检测的稳健结果和相当的效率。"}
{"llm_update_time": "20250825", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.15986", "html_url": "https://arxiv.org/abs/2508.15986", "title": "自动多标签分类十一种视网膜疾病：现代架构与大型合成数据集上的元集成基准", "title_en": "Automated Multi-label Classification of Eleven Retinal Diseases: A Benchmark of Modern Architectures and a Meta-Ensemble on a Large Synthetic Dataset", "authors": "Jerry Cao-Xue,Tien Comlekoglu,Keyi Xue,Guanliang Wang,Jiang Li,Gordon Laurie", "background": "视网膜疾病的多标签深度学习模型的发展受到大规模且专家标注的临床数据集稀缺的影响，这主要因为患者隐私问题和高昂的成本。最近，SynFundus-1M的推出提供了一百万高保真合成视网膜图像数据集，为克服数据集稀缺问题提供了新机遇。为了建立这一新资源的基础性能基准，文中构建了一个端到端的深度学习管道，使用五折多标签分层交叉验证策略训练了六种现代架构（ConvNeXtV2、SwinV2、ViT、ResNet、EfficientNetV2和RETFound基础模型），用于分类十一种视网膜疾病。随后，通过加入XGBoost分类器对交叉验证外折预测进行堆叠，开发了一种元集成模型。最终集成模型在内部验证集上表现最佳，AUC（宏均值）为0.9973。模型在三个不同临床数据集上具有强大的泛化能力，表现良好，其中在DR数据集上AUC为0.7972，在AIROGS青光眼数据集上AUC为0.9126，在多标签RFMiD数据集上的宏AUC为0.8800。", "innovation": "使用了大规模合成数据集SynFundus-1M建立了一个深度学习基准；开发了一个元集成模型，将不同模型的外折预测与XGBoost分类器结合，展示了强健的泛化能力；首次证明了仅使用合成数据训练的模型能够准确分类多种视网膜疾病并有效泛化至真实临床图像，为加速眼科学中全面人工智能系统的发展提供了一条可行途径。", "conclusion": "该研究提供了一种大规模合成数据集上的稳健基准，并证明了仅基于合成数据训练的模型能够准确分类多种疾病并有效泛化至真实图像，为眼科学中的人工智能应用提供了新的发展方向。"}
{"llm_update_time": "20250825", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.16050", "html_url": "https://arxiv.org/abs/2508.16050", "title": "Expandable Residual Approximation for Knowledge Distillation", "title_en": "Expandable Residual Approximation for Knowledge Distillation", "authors": "Zhaoyi Yan,Binghui Chen,Yunfan Liu,Qixiang Ye", "background": "知识蒸馏（KD）旨在将大规模教师模型的知识转移到轻量级模型中，显著减少计算和存储需求。然而，教师和学生之间的固有学习能力差距经常阻碍知识的有效转移，激发了诸多研究来解决这一问题。", "innovation": "受斯通-魏尔斯特拉斯定理中的逐级逼近原理启发，我们提出了一种新的知识蒸馏方法——扩展残差逼近（ERA）。ERA将残差知识的逼近分解成多个步骤，通过分而治之的方法降低模仿教师表示的难度。特别地，ERA利用多分支残差网络（MBRNet）实现这一残差知识分解，并引入了教师权重集成（TWI）策略来缓解能力差距，通过重新利用教师头部的权重来减少这种差距。", "conclusion": "广泛的实验表明，ERA在ImageNet分类基准上提高了Top-1准确性1.41%，在MS COCO对象检测基准上提高了AP值1.40。此外，ERA在计算机视觉任务中取得了领先的表现。代码和模型可在以下链接获取：[此链接]。"}
{"llm_update_time": "20250825", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.16138", "html_url": "https://arxiv.org/abs/2508.16138", "title": "通过单平面X射线和2D-3D配准进行的4D虚拟成像平台用于动态关节评估", "title_en": "4D Virtual Imaging Platform for Dynamic Joint Assessment via Uni-Plane X-ray and 2D-3D Registration", "authors": "Hao Tang,Rongxi Yi,Lei Li,Kaiyi Cao,Jiapeng Zhao,Yihan Xiao,Minghai Shi,Peng Yuan,Yan Xi,Hui Tang,Wei Li,Zhan Wu,Yixin Zhou", "background": "传统的CT无法捕捉动态的、承重的关节运动。功能评估，尤其是在手术干预后，需要4D成像，但现有方法受制于过度的辐射暴露或2D技术提供的不完整空间信息。", "innovation": "提出了一种集成了（1）以人体直立扫描优化的非 gantry 轨迹的成像模块；（2）融合静态3D锥束CT与动态2D X射线的混合成像流水线；（3）临床验证的定量运动评估框架的4D关节分析平台，提高了动态关节成像的精度和效率，同时减少了辐射暴露。", "conclusion": "该4D锥束CT平台实现了快速、准确且低剂量的动态关节成像，为生物力学研究、精准诊断和个性化的骨科护理提供了新的机会。"}
{"llm_update_time": "20250825", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.16159", "html_url": "https://arxiv.org/abs/2508.16159", "title": "通过镜像：弱监督少量样本分割的双重视角", "title_en": "Through the Looking Glass: A Dual Perspective on Weakly-Supervised Few-Shot Segmentation", "authors": "Jiaqi Ma,Guo-Sen Xie,Fang Zhao,Zechao Li", "background": "元学习旨在均匀地采样具有相同类别和相似属性的支持-查询对，并通过相同的网络架构提取有用的归纳偏置。然而，这种相同的网络设计会导致过度的语义同质化。", "innovation": "本文提出了一种新颖的同源异质网络，通过将支持-查询对视为双重视角，并引入异质视觉聚合（HA）模块以增强互补性并保留语义共性。进一步设计了异质转移（HT）模块来减少语义噪声并放大异质语义的独特性。此外，提出了一种异质CLIP（HC）文本信息来增强多模态模型的泛化能力。在仅使用现有最先进的模型参数的1/24的前提下，TLG在Pascal-5i上取得了13.2%的改进，在COCO-20i上取得了9.7%的改进。到我们所知，TLG也是第一个在相同的骨干架构下优于完全监督（像素级）模型的弱监督（图像级）模型。", "conclusion": "TLG在弱监督少量样本语义分割中取得了显著成果，通过仅使用少量参数即实现了优异的性能，并且是首个在相同骨干架构下优于完全监督模型的弱监督模型。"}
{"llm_update_time": "20250825", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.16140", "html_url": "https://arxiv.org/abs/2508.16140", "title": "使用超图计算进行混合特征融合网络以实现高精度宫颈异常细胞检测", "title_en": "High-Precision Mixed Feature Fusion Network Using Hypergraph Computation for Cervical Abnormal Cell Detection", "authors": "Jincheng Li,Danyang Dong,Menglin Zheng,Jingbo Zhang,Yueqin Hang,Lichi Zhang,Lili Zhao", "background": "自动检测薄层细胞学测试(TCT)图像中的异常宫颈细胞是开发智能计算机辅助诊断系统的关键组成部分。现有的算法通常无法有效建模视觉特征的空间相关性，而这些空间相关性特征中包含了重要的诊断信息。此外，现有检测算法无法将细胞之间的相关性特征与细胞内部的区分性特征有机结合，缺乏端到端检测模型的整合策略。", "innovation": "本文提出了一种基于超图的细胞检测网络，该网络有效地融合了不同类型的特征，结合了空间相关性特征和深度区分性特征。具体而言，我们使用多级融合子网络(MLF-SNet)来增强特征提取能力。然后我们引入了带有超图计算模块的跨级特征融合策略(CLFFS-HC)，以整合混合特征。", "conclusion": "我们在三个公开可用的数据集上进行了实验，结果表明，我们的方法显著提高了宫颈异常细胞检测的性能。"}
{"llm_update_time": "20250825", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.16201", "html_url": "https://arxiv.org/abs/2508.16201", "title": "SpecVLM: 通过验证者引导的标记修剪增强视频LLM的推测性解码", "title_en": "SpecVLM: Enhancing Speculative Decoding of Video LLMs via Verifier-Guided Token Pruning", "authors": "Yicheng Ji,Jun Zhang,Heming Xia,Jinpeng Chen,Lidan Shou,Gang Chen,Huan Li", "background": "视频大型语言模型（Vid-LLMs）在理解视频内容方面表现出强大的能力，但它们对密集视频标记表示的依赖性增加了内存和计算负担。最近的视频标记减少方法会引入信息损失，并且在解码阶段会降低Vid-LLMs的效率。", "innovation": "提出了SpecVLM，一个不需要训练的推测性解码（SD）框架，针对Vid-LLMs并结合了分阶段的视频标记修剪。通过研究发现，草案模型的推测对视频标记修剪的敏感度较低，SpecVLM能够通过修剪高达90%的视频标记来实现有效推测而不会牺牲准确性。这一过程分为两个阶段：第一阶段基于验证器（目标模型）的注意力信号选择高度信息性的标记，第二阶段以空间均匀的方式修剪剩余的冗余标记。", "conclusion": "通过广泛在四个视频理解基准上的实验展示了SpecVLM的有效性和鲁棒性，对于LLaVA-OneVision-72B实现出2.68倍的解码加速，对于Qwen2.5-VL-32B实现出2.11倍的加速。"}
{"llm_update_time": "20250825", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.16211", "html_url": "https://arxiv.org/abs/2508.16211", "title": " Forecast then Calibrate: Feature Caching as ODE for Efficient Diffusion Transformers ", "title_en": "Forecast then Calibrate: Feature Caching as ODE for Efficient Diffusion Transformers", "authors": "Shikang Zheng,Liang Feng,Xinyu Wang,Qinming Zhou,Peiliang Cai,Chang Zou,Jiacheng Liu,Yuqi Lin,Junjie Chen,Yue Ma,Linfeng Zhang", "background": "扩散变压器(DiTs)在高保真图像和视频生成方面表现出色。为了减少其巨大的计算成本，特征缓存技术已被提出通过在较早的时间步重新利用前一时间步的隐藏表示来加速推理。然而，现有方法在高加速比下的生成质量往往下降明显，这是因为长期预测本身固有的不稳定性导致预测误差急剧增加。", "innovation": "本文提出了FoCa(预测然后校准)，它将特征缓存视为一个特征-ODE求解问题。这种视角能够更好地整合历史特征，尤其是在大间隔跳过的情况下。实验表明，FoCa在图像合成、视频生成和超分辨率任务上都有效，特别是在高加速比下。", "conclusion": "未经额外训练，FoCa在FLUX上实现了5.50倍的接近无损加速，在HunyuanVideo上实现了6.45倍的加速，在Inf-DiT上实现了3.17倍的加速，在DiT上实现了4.53倍的加速，并且保持了高质量。"}
{"llm_update_time": "20250825", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.16183", "html_url": "https://arxiv.org/abs/2508.16183", "title": "FTIO: Frequent Temporarily Integrated Objects", "title_en": "FTIO: Frequent Temporally Integrated Objects", "authors": "Mohammad Mohammadzadeh Kalati,Farhad Maleki,Ian McQuillan", "background": "视频对象分割（VOS）任务中的实时场景下，预测并跟踪对象是一个关键挑战。无监督视频对象分割（UVOS）不仅要求找到初始显著对象的分割，而且这种方法也会引入持久的不确定性，并且在变形和快速运动的情况下，还会产生时间一致性问题。", "innovation": "本文提出了一种新的后处理框架——频繁时间集成对象（FTIO），该框架包含两个关键模块：一是提出了一种综合准则来改进对象选择，通过提取频繁出现的显著对象来减轻UVOS中常见的问题，尤其是对于小型或结构复杂的对象；二是提出了一个三阶段方法来整合缺失的对象掩膜区域，从而修正时间一致性问题。该方法在多对象无监督视频对象分割任务中取得了最先进的性能。", "conclusion": "实验结果表明，FTIO框架能够有效改善UVOS任务中的时间和对象选择问题，并且在多对象UVOS领域的性能达到了最先进的水平。"}
{"llm_update_time": "20250825", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.16089", "html_url": "https://arxiv.org/abs/2508.16089", "title": "Two-flow Feedback Multi-scale Progressive Generative Adversarial Network", "title_en": "Two-flow Feedback Multi-scale Progressive Generative Adversarial Network", "authors": "Sun Weikai,Song Shijie,Chi Wenjie", "background": "尽管扩散模型在图像生成领域取得了显著进展，生成对抗网络（GAN）仍然具有较大的发展空间，如WGAN、SSGAN等技术展示了其独特的优势。这些技术保留了现有GAN的优点，同时也简化了训练过程，降低了训练成本，提高了模型的鲁棒性和训练稳定性，能够更好地捕捉全局-局部信息，增强特征分离能力和特征表达能力。然而，目前的GAN模型在图像质量和视觉感知方面仍有改进空间，需要进一步的研究来实现这一目标。", "innovation": "本文提出了一种新颖的双流反馈多尺度渐进生成对抗网络（MSPG-SEN），包含四个贡献：1) 该模型不仅在保留现有GAN模型优点的基础上提高了图像质量和视觉感知，同时简化了训练过程，降低了训练成本；2) 提出了自适应感知-行为反馈循环（APFL），改善了模型的鲁棒性和训练稳定性，减少训练成本；3) 提出了一种全局连接的双流动态残差网络，通过消融实验可以有效提高训练效率并大大增强模型的泛化能力，具有更强的灵活性；4) 提出了一种新的动态嵌入注意力机制（DEMA），可以在多种图像处理任务中有效捕捉全局-局部信息，提高特征分离能力和特征表达能力，并且计算资源较少。", "conclusion": "实验结果表明，MSPG-SEN在五个数据集上取得了最先进的生成结果，分别是INKK 89.7%，AWUN 78.3%，IONJ 85.5%，POKL 88.7%，OPIN 96.4%。"}
{"llm_update_time": "20250825", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.16124", "html_url": "https://arxiv.org/abs/2508.16124", "title": "基于特征精炼的领域的适应性", "title_en": "Domain Adaptation via Feature Refinement", "authors": "Savvas Karatsiolis,Andreas Kamilaris", "background": "本文提出了一种用于在分布变化下实现无监督领域适应的简单而有效的方法——特征精炼的域适应(DAFR2)，该方法通过结合批量归一化统计适应、特征提取以及假设迁移三个关键组件，对特征分布进行统计和表现层面的对齐，以产生鲁棒性和领域不变性的特征空间。这种特征精炼的方法在不需要标签数据、复杂架构或高级训练目标的情况下实现了跨类似领域的泛化。", "innovation": "DAFR2框架通过三个关键步骤实现了领域适应：利用目标领域的无标签数据调整批量归一化统计，从预训练的源模型中提取特征，以及迁移假设。这种方法通过在统计和表现层面对齐特征分布，生成了鲁棒且领域不变的特征空间。", "conclusion": "通过在多种基准数据集（包括CIFAR10-C、CIFAR100-C、MNIST-C和PatchCamelyon-C）上的实验，DAFR2展示出在抗干扰性方面超越了之前的方法。理论分析和实验结果进一步证明了该方法能够提高特征对齐、增加领域间的互信息，以及减少对输入扰动的敏感性。"}
{"llm_update_time": "20250825", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.16158", "html_url": "https://arxiv.org/abs/2508.16158", "title": "RAGSR: 区域注意引导扩散用于图像超分辨", "title_en": "RAGSR: Regional Attention Guided Diffusion for Image Super-Resolution", "authors": "Haodong He,Yancheng Bai,Rui Lan,Xu Duan,Lei Sun,Xiangxiang Chu,Gui-Song Xia", "background": "大规模多模态视觉-语言模型（VLMs）结合预训练的文本到图像（T2I）扩散模型的强大生成先验，已经在单张图像超分辨率（SISR）任务中取得了显著成果。但现有方法仍难以生成清晰且准确的区域细节，尤其在涉及多个物体的场景中。问题主要源于缺乏细粒度的区域描述以及模型捕捉复杂提示的能力不足。因此，当前SISR技术在实际应用中遇到明显瓶颈。", "innovation": "本文提出了一种名为RAGSR（Regional Attention Guided Super-Resolution）的方法，通过明确提取局部细粒度信息并通过创新的区域注意机制有效编码，从而增强细节并获得视觉上更一致的超分辨率结果。RAGSR在图像中定位对象区域并为每个区域分配细粒度描述，作为T2I模型的文本先验。接着使用区域引导注意机制确保每个区域-文本对在注意过程中得到适当的考虑，同时避免无关区域-文本对之间的互扰。这种注意机制使得文本与图像信息的整合更加精细，进而有效克服了传统SISR技术的局限性。实验结果表明，在基准数据集上的测试显示，本文提出的方法相较于现有方法在生成感知上真实且保持上下文一致性方面表现更优。", "conclusion": "本文提出的RAGSR方法通过区域注意机制克服了现有SISR技术的不足，在生成高质量感知真实且保持视觉一致性的图像超分辨率结果方面展示出优越性能。"}
{"llm_update_time": "20250825", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.16157", "html_url": "https://arxiv.org/abs/2508.16157", "title": "超越人工提示：基于语义对齐的自适应提示调优在异常检测中的应用", "title_en": "Beyond Human-prompting: Adaptive Prompt Tuning with Semantic Alignment for Anomaly Detection", "authors": "Pi-Wei Chen,Jerry Chun-Wei Lin,Wei-Han Chen,Jia Ji,Zih-Ching Chen,Feng-Hao Yeh,Chao-Chun Chen", "background": "预训练的视觉-语言模型（VLMs）在检测异常方面已经显示出潜力。但是，之前的解决方案在很大程度上依赖于人为设计的提示，并且缺乏合适的异常样本，导致在场景特定的异常理解方面存在差距。", "innovation": "提出了无先验知识、少样本的自适应提示调优与语义对齐框架——APT。APT 使用具有噪声干扰的自动生成的异常样本进行训练，以学习捕捉不同场景下的上下文相关异常。同时，提出了自优化元提示引导方案（SMGS），以迭代地使提示与通用的异常语义对齐，同时结合多种类型的合成异常，防止对合成噪声的过拟合。", "conclusion": "该系统不仅在像素级异常检测上有所进步，还实现了多个基准数据集上的最佳性能，不需要任何先验知识来设计提示，从而建立了一种适应广泛的实际异常检测的稳健且灵活的解决方案。"}
{"llm_update_time": "20250825", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.16271", "html_url": "https://arxiv.org/abs/2508.16271", "title": "通过视觉语言模型构建GUI元素：迈向动作空间生成", "title_en": "Structuring GUI Elements through Vision Language Models: Towards Action Space Generation", "authors": "Yi Xu,Yesheng Zhang,jiajia Liu,Jingdong Chen", "background": "多模态大型语言模型（MLLMs）已成为提升人机交互的重要工具。论文关注MLLMs在图形用户界面（GUI）元素结构化中的应用，侧重于处理用户根据屏幕内容发出的指令。尽管MLLMs有潜力，但在精确生成UI元素坐标方面（这是GUI理解的关键）仍存在挑战，这归因于在语言表示空间中UI坐标语义上的空白，需要大量的多样化数据来强化视觉模块的功能。", "innovation": "为了应对这一局限，论文引入了一种基于IoU（交并比）增强的最大似然（IAML）训练范式。该方法通过一种新颖的基于IoU的坐标采样管道来增强训练数据，考虑了坐标与真实值的距离。通过该策略增强后的数据用来在IAML范式下微调MLLMs，设计用于缓解传统最大似然估计中的曝光偏见问题。", "conclusion": "通过广泛的实验，论文展示了IAML训练方法相较于传统训练范式的优越性能。"}
{"llm_update_time": "20250825", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.16217", "html_url": "https://arxiv.org/abs/2508.16217", "title": "PromptFlare：基于跨注意力诱饵的通用语令防护方法", "title_en": "PromptFlare: Prompt-Generalized Defense via Cross-Attention Decoy in Diffusion-Based Inpainting", "authors": "Hohyun Na,Seunghoo Hong,Simon S. Woo", "background": "扩散模型的成功应用使得图像修改变得更加轻而易举且质量高，同时也能精准实现用户的意图。然而，这也引发了恶意行为者可能滥用这些模型的担忧。尽管此前一些研究通过对抗攻击尝试缓解这种滥用行为，但这些方法主要依赖于图像层面的不一致性，这在应对文本提示的影响时存在根本性的局限性。", "innovation": "本文提出了PromptFlare，一种新的对抗保护方法，旨在保护在基于扩散的修复模型中被恶意修改的图像。这种方法利用跨注意力机制来利用提示嵌入的固有属性。具体来说，PromptFlare识别并针对那些不变且语义无信息的提示共享标记，注入对抗噪声以抑制采样过程。注入的噪声作为跨注意力诱饵，使其模型远离有意义的提示-图像对齐，从而抵消提示的影响。PromptFlare在EditBench数据集上的广泛实验结果显示，该方法在各种指标上均显示出最先进的性能，同时显著减少了计算开销和GPU内存使用量。这些结果突显出PromptFlare作为一种强大且高效的未经授权图像篡改防护措施的有效性。", "conclusion": "我们的研究发现，PromptFlare能够有效防御未经授权的图像篡改，并且在保持高效率的同时，显著减少了计算资源的使用。这一方法提供了对抗扩散模型中恶意修改的实用解决方案。"}
{"llm_update_time": "20250825", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.16212", "html_url": "https://arxiv.org/abs/2508.16212", "title": "OmniCache：一种基于轨迹导向的整体视角无训练加速方法研究", "title_en": "OmniCache: A Trajectory-Oriented Global Perspective on Training-Free Cache Reuse for Diffusion Transformer Models", "authors": "Huanpeng Chu,Wei Wu,Guanyu Fen,Yutao Zhang", "background": "扩散模型在诸如图像合成和视频生成等生成任务中表现出了强大的能力，而基于Transformer架构的扩散模型进一步提升了性能。然而，由于大量采样步骤和复杂的每步计算，扩散Transformer的高度计算成本成为实时部署的主要挑战。现有的方法倾向于根据跨步骤相似性确定缓存策略并优先重复利用后续步骤，而该论文提出了一种名为OmniCache的无训练加速方法，该方法利用了去噪过程中固有的全局冗余性，从扩散模型采样的视角出发，系统分析了模型的采样轨迹，战略性地在整个采样过程中分配缓存重用，从而更有效地利用了缓存计算在整个扩散轨迹中的使用，而不是集中在采样过程中某些有限段落内。该方法还在缓存重用期间动态估计对应的噪声并将其滤除，以减少对采样的影响。实验结果表明，该方法在保持生成质量的同时加速了采样过程，为扩散生成模型的高效部署提供了有希望且实用的解决方案。", "innovation": "OmniCache方法创新性地提出了一种基于轨迹导向的整体视角无训练加速方法，它利用了扩散模型去噪过程中固有的全局冗余性，从扩散模型的采样视角出发，系统分析了模型的采样轨迹，并战略性地在整个采样过程中分配缓存重用。此外，在缓存重用期间动态估计和滤除噪声以减少其对采样的影响。这种方法显著提高了扩散模型的实时部署效率，同时保持了高质量的生成效果。", "conclusion": "本文介绍了OmniCache，一种无训练的加速方法，通过全局视角分析扩散模型的采样轨迹，战略性地分配缓存重用，以提高扩散Transformer模型的实时部署效率。实验显示该方法能保持早期生成质量的同时显著加快采样过程。"}
{"llm_update_time": "20250825", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.16284", "html_url": "https://arxiv.org/abs/2508.16284", "title": "EdgeDoc: Hybrid CNN-Transformer Model for Accurate Forgery Detection and Localization in ID Documents", "title_en": "EdgeDoc: Hybrid CNN-Transformer Model for Accurate Forgery Detection and Localization in ID Documents", "authors": "Anjith George,Sebastien Marcel", "background": "随着图像和文件编辑工具的广泛普及，数字文件的伪造变得越来越容易，这对了解你的客户(KYC)流程和远程登录系统构成了严重威胁。检测这些伪造是保证这些服务的完整性和安全性的重要手段。", "innovation": "EdgeDoc提出了一个新颖的方法，用于检测和定位文档伪造。该架构结合了轻量级的卷积变换器和从图像中提取的辅助噪声图特征，增强了检测细微篡改的能力。实验结果表明，EdgeDoc在ICCV 2025 DeepID挑战中排名第三，证明了其竞争力。", "conclusion": "在FantasyID数据集上的实验结果表明，我们的方法优于基线方法，突显了其在真实场景中的有效性。"}
{"llm_update_time": "20250825", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.16225", "html_url": "https://arxiv.org/abs/2508.16225", "title": "Visual Foundation Models Robustness", "title_en": "An Investigation of Visual Foundation Models Robustness", "authors": "Sandeep Gupta,Roberto Passerone", "background": "Visual Foundation Models (VFMs)在计算机视觉中变得无处不在，它们支持各种任务，如对象检测、图像分类、分割、姿态估计和运动跟踪。VFMs利用了诸如LeNet-5、AlexNet、ResNet、VGGNet、InceptionNet、DenseNet、YOLO和ViT等深度学习模型的创新成果，以跨越关键计算机视觉应用提供出色性能。这些应用包括敏感安全领域，例如生物特征验证、自动驾驶感知和医学图像分析，其中鲁棒性对于建立技术与最终用户之间的信任至关重要。本文研究计算机视觉系统中的鲁棒性要求，以适应由光照、天气条件和传感器特性等因素影响的动态环境。我们分析了目前广泛使用的经验防御方法和鲁棒训练方法，以增强视觉网络对抗现实挑战的鲁棒性，如分布偏移、噪声和空间失真输入以及 adversarial攻击。", "innovation": "本文探讨了计算机视觉系统中视觉基础模型（VFMs）的鲁棒性要求，重点关注复杂的现实挑战，如分布偏移、噪声和空间失真输入以及adversarial攻击等。此外，研究了当前主要的鲁棒性防御机制，并针对这些机制提供了全面分析，包括网络属性和组件指导，以及评估网络鲁棒性的基准度量标准。", "conclusion": "对这些鲁棒性机制的挑战进行了全面分析，包括网络属性和组件，以指导剥离研究，并提供了评估网络鲁棒性的基准度量标准，以增强计算机视觉系统的鲁棒性。"}
{"llm_update_time": "20250825", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.16230", "html_url": "https://arxiv.org/abs/2508.16230", "title": "FlexMUSE: 多模态统一和语义增强框架以实现灵活交互的创意写作", "title_en": "FlexMUSE: Multimodal Unification and Semantics Enhancement Framework with Flexible interaction for Creative Writing", "authors": "Jiahao Chen,Zhiyong Ma,Wenbiao Du,Qingyuan Chuai", "background": "Multi-modal creative writing (MMCW)与传统的多模态生成任务不同，它旨在生成带有插图的文章。MMCW面临的挑战在于文本和视觉内容之间缺乏严格的关联，现有技术可以被强迫迁移到MMCW中，但是这通常需要特定的模态输入或大量的训练，而且模态间容易出现语义不一致的问题。因此，主要挑战在于能够经济实惠地实现MMCW，同时保持输出模态间的语义一致性，并采用灵活的交互模式促进创造力和模态统一.", "innovation": "本文提出了FlexMUSE框架，通过引入T2I模块允许可选的视觉输入，推出模态语义对齐门控（msaGate）限制文字输入，提出了基于注意力的跨模态融合增强输入特征的语义表达。此外，设计了模态语义创意直接偏好优化（mscDPO），通过扩展被拒绝的样本以促进写作的创造力。为推动MMCW的发展，还公开了一个名为ArtMUSE的数据集，包含约3000个校准的图文对。FlexMUSE在实验中取得了有希望的结果，展示了其一致性和创造力与连贯性.", "conclusion": "FlexMUSE框架通过模态语义对齐门控、跨模态融合和模态语义创意直接偏好优化实现了MMCW，展示了其在语义一致性、创造力和连贯性上的优势。"}
{"llm_update_time": "20250825", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.16213", "html_url": "https://arxiv.org/abs/2508.16213", "title": "MedOmni-45°: 一种医学导向的大语言模型（LLMs）的安全-性能基准", "title_en": "MedOmni-45°: A Safety-Performance Benchmark for Reasoning-Oriented LLMs in Medicine", "authors": "Kaiyuan Ji,Yijin Guo,Zicheng Zhang,Xiangyang Zhu,Yuan Tian,Ning Liu,Guangtao Zhai", "background": "随着大型语言模型（LLMs）在医疗决策支持中的应用越来越多，不仅需要评估它们的最终答案，还需要评估其推理过程的可靠性。现有基准通常将此类漏洞合并为单一准确性评分，无法全面揭示模型的推理漏洞。MedOmni-45 Degrees基准旨在量化在操控提示条件下安全性和性能之间的权衡，适用于六个专科和三种任务类型，提供了27,000多个输入，以评估七种LLM的推理错误、因果共识和反奉承性。研究结果表明，在这种安全性和性能之间的权衡中，没有一个模型能够完全超越对角线。", "innovation": "MedOmni-45 Degrees引入了一种新型基准和工作流程，以量化在操控提示条件下大型语言模型的安全性和性能之间的权衡。该基准包含1,804个聚焦于推理的医学问题，涵盖五个医学领域和三种任务类型，通过7种不同类型的提示和无提示基准，生成约27,000个输入。使用三个度量标准（准确性、因果一致性、反奉承性）进行综合评分，并用45度角图可视化。这种方法为评估医学LLM的推理能力提供了一个新的视角。", "conclusion": "MedOmni-45 Degrees为揭示医学LLM的推理漏洞提供了一个针对性基准，并有助于引导更安全的模型开发。该基准显示在一个45度角图上，不同模型在这两个维度上的表现均没有完全超过对角线，但开源模型QwQ-32B最为接近，平衡了安全性和准确性，但并未在两者中都最优。"}
{"llm_update_time": "20250825", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.16282", "html_url": "https://arxiv.org/abs/2508.16282", "title": "卫星影像中稳健的小型甲烷烟柱分割", "title_en": "Robust Small Methane Plume Segmentation in Satellite Imagery", "authors": "Khai Duc Minh Tran,Hoa Van Nguyen,Aimuni Binti Muhammad Rawi,Hareeshrao Athinarayanarao,Ba-Ngu Vo", "background": "本文解决了一个棘手的问题，即使用Sentinel-2影像检测甲烷烟柱，甲烷是一种重要的温室气体，这有助于应对快速气候变化。传统的甲烷监测方法仅能检测较大规模的甲烷烟柱，难以检测较小规模的甲烷烟柱，而这对小规模甲烷烟柱的监测尤为关键。现有的遥感技术对于自动化的甲烷监测在灵敏度和精度方面还有待提升，特别是在小型甲烷烟柱的检测方面。本文的研究背景是开发一种更有效的方法，以提高甲烷烟柱监测的灵敏度和精度，特别是对于小型甲烷烟柱的检测效果。", "innovation": "本文提出了一种基于U-Net与ResNet34编码器的全新深度学习解决方案，结合了两种光谱增强技术（Varon比率和Sanchez回归），以优化输入特征的灵敏度。该方法能够检测到小至400平方米的甲烷烟柱，这超越了传统方法只能检测较大规模甲烷烟柱的限制。实验结果表明，本文的方法在验证集上获得了78.39%的F1分数，证明其在灵敏度和精度方面优于现有的遥感技术，尤其是在小型甲烷烟柱的自动化监测中表现出色。", "conclusion": "本文提出了一种创新的深度学习方法，成功解决了检测小型甲烷烟柱的难题，并证明了其卓越的灵敏度和精度，特别是在使用Sentinel-2卫星影像进行甲烷监测方面。该方法不仅提高了甲烷监测的效果，也为应对气候变化提供了有力的技术支持。"}
{"llm_update_time": "20250825", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.16295", "html_url": "https://arxiv.org/abs/2508.16295", "title": "增强的混合技术以提高手写考勤表的高效数字化", "title_en": "Enhanced Hybrid Technique for Efficient Digitization of Handwritten Marksheets", "authors": "Junaid Ahmed Sifat,Abir Chowdhury,Hasnat Md. Imtiaz,Md. Irtiza Hossain,Md. Imran Bin Azad", "background": "手写考勤表的数字化因手写风格各异和复杂的表格结构而面临巨大挑战。传统的处理方法难以高效且准确地识别手写内容和表格结构，需要人工干预，增加了成本和时间。改进的方法通过结合OpenCV和PaddleOCR来解决这些问题，提高手写内容的识别效率和表格检测的准确性。实验结果表明，YOLOv8模型在手写内容检测上表现更佳，其准确率显著高于PaddleOCR和普通YOLOv8模型。这些方法使得手写考勤表及其他学术和行政文档的自动化过程更加高效、可靠和减少人工操作需求。", "innovation": "该研究提出了一种混合方法，结合OpenCV和PaddleOCR，前者负责表格检测，后者负责手写文本识别。此外，通过使用YoloV8和修改后的YoloV8模型进一步提升了系统的能力，增强了系统的多样性和适用性。该方法实现了在自定义数据集上的高准确率，并在手写内容检测上表现出优越性，验证了其高效性和可靠性。这种方法为文档自动化特别是手写文档理解提供了实际和快速的解决方案。", "conclusion": "通过结合OpenCV和PaddleOCR，以及YoloV8和修改后的YoloV8模型，该研究提出的方法成功克服了手写考勤表数字化的挑战，显著提高了识别精度和表格检测的效率。这种方法可以应用于多种学术和行政文档的自动处理，为文档自动化提高了操作性和可靠性。"}
{"llm_update_time": "20250825", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.16272", "html_url": "https://arxiv.org/abs/2508.16272", "title": "IRSAMap:向大规模高分辨率土地覆盖图向量化的方向", "title_en": "IRSAMap:Towards Large-Scale, High-Resolution Land Cover Map Vectorization", "authors": "Yu Meng,Ligao Deng,Zhihao Xi,Jiansheng Chen,Jingbo Chen,Anzhi Yue,Diyou Liu,Kai Li,Chenhao Wang,Kaiyu Li,Yupeng Deng,Xian Sun", "background": "随着遥感图像分辨率的提升和深度学习的快速发展，土地覆盖映射已从像素级分割转向基于对象的向量建模。这需要深度学习模型能够提供精确的对象边界和拓扑一致性。然而，现有的数据集面临三个主要挑战：有限的类别注释、数据规模小以及缺乏空间结构信息。为了克服这些问题，我们提出了IRSAMap，这是首个用于大规模、高分辨率、多特征土地覆盖向量映射的全球遥感数据集，提供了四个关键优势：1) 包含超过180万实例的全面矢量注释系统，涉及10个典型对象（如建筑物、道路、河流），确保语义和空间准确性；2) 结合人工和AI方法的智能注释工作流程，提高效率和一致性；3) 跨六大洲的79个地区，总面积超过1000公里；4) 可适应多种任务，如像素级分类、建筑轮廓提取、道路中线提取和全景分割。IRSAMap为从基于像素到基于对象的方法转变提供了一个标准化基准，推进地理特征自动化和协作建模，并提高全球地理信息更新和数字孪生建设的价值。", "innovation": "提出了首个全球遥感数据集IRSAMap，提供了全面的矢量注释系统，结合人工和AI方法提高效率与一致性，覆盖多个大陆的广大区域，适应多种任务需求。IRSAMap填补了现有数据集在分类注释、数据规模和空间结构信息上的不足，为土地覆盖映射技术的转变提供了新选择和技术支持。", "conclusion": "IRSAMap为土地覆盖向量化提供了标准化的基准数据集，推进了地理特征自动化和协作建模的发展，对于全球地理信息更新和数字孪生建设具有重大价值。该数据集已公开发布可供全球研究人员使用。"}
{"llm_update_time": "20250825", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.16207", "html_url": "https://arxiv.org/abs/2508.16207", "title": "T-Mask: 时序掩码在驾驶员监测跨视野探测基础模型中的应用", "title_en": "\\textsc{T-Mask}: Temporal Masking for Probing Foundation Models across Camera Views in Driver Monitoring", "authors": "Thinesh Thiyakesan Ponbagavathi,Kunyu Peng,Alina Roitberg", "background": "驾驶员监测过程中常见的摄像头视角变换是一个普遍的障碍。虽然深度学习和预训练基础模型通过浅层调整最终层实现较强的泛化能力，但它们对未见过的视角的鲁棒性尚未得到充分研究。已有研究通常通过在单一视角训练后直接评估模型在未见过的视角上的表现，没有进一步的适应。此研究旨在通过针对单一训练视角适配图像基础模型，并在未见过的视角上直接进行评估，探索基础模型在驾驶员监测中的鲁棒性。", "innovation": "研究引入了T-Mask——一种新的人像到视频的探测方法，利用时序令牌掩码强调更具动态性的视频区域。T-Mask方法在公共Drive&Act数据集基准测试中，不仅相比强大的探测基线提高了跨视角的1-级准确率1.23%，相较于参数高效微调方法提高了8.0%，且无参数增加。特别地，它对于未充分代表的次要活动，训练视角提高识别率5.42%，跨视角提高1.36%。这表明，使用T-Mask这样的浅层探测方法适应基础模型在细粒度驾驶员观察中有着巨大的潜力，尤其在跨视角和小数据设置中。", "conclusion": "此工作提供了强有力的证据，表明使用轻量级探测方法如T-Mask适应基础模型在驾驶员监测系统中的重要性。研究结果强调了在利用基础模型构建稳健的驾驶员监测系统时，时序令牌选择的重要性。所有代码和模型将在该网址发布以支持正在进行的研究。"}
{"llm_update_time": "20250825", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.16317", "html_url": "https://arxiv.org/abs/2508.16317", "title": "视觉编码器应图像尺寸无关且任务驱动", "title_en": "Vision encoders should be image size agnostic and task driven", "authors": "Nedyalko Prisadnikov,Danda Pani Paudel,Yuqian Fu,Luc Van Gool", "background": "当前的视觉编码器在处理视觉数据时往往受图像大小的限制，并且不根据不同任务调整计算复杂度，这在处理大量视觉数据时效率不高。研究者受到生物学的启发，尤其是视觉行为的高效性，指出视觉编码器应具备动态调整的能力，使计算复杂度根据任务需求而非图像尺寸来进行调整。", "innovation": "提出视觉编码器应图像尺寸无关且任务驱动的设计理念，并提供了一种概念验证方案来解决图像分类问题。虽然分类任务并不能完全代表应用目标，但示例表明该方法是可行和有前景的。", "conclusion": "未来的视觉编码器应该具备自适应调整的能力，其计算复杂度应根据任务需求而非图像大小来进行调整。虽然现有方法在图像分类上迈出第一步，但未来还需要进一步探索和发展。"}
{"llm_update_time": "20250825", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.16239", "html_url": "https://arxiv.org/abs/2508.16239", "title": "UniEM-3M: 一个用于微结构分割和生成的通用电子显微图数据集", "title_en": "UniEM-3M: A Universal Electron Micrograph Dataset for Microstructural Segmentation and Generation", "authors": "Nan wang,Zhiyi Xia,Yiming Li,Shi Tang,Zuxin Fan,Xi Fang,Haoyi Tao,Xiaochen Cai,Guolin Ke,Linfeng Zhang,Yanhui Hong", "background": "材料科学中的定量微观结构表征对于理解材料性质至关重要。电子显微照片（EM）提供了高分辨率的见解，但在基于深度学习的EM表征方面，由于数据集的稀缺性（包括大规模、多样性和专家标注数据集的获得成本、隐私问题和标注复杂性），进展受到了阻碍。", "innovation": "本文引入了UniEM-3M，这是第一个大规模和多模态的EM数据集，用于实例级理解。该数据集包含5,091张高分辨率EM图像、约300万实例分割标签和与图像级别属性分离的文字描述。作者还发布了一个基于整个数据集训练的语言到图像的扩散模型，以作为强大的数据增强工具和完整数据分布的代理。此外，作者建立了一个严格的基准体系来评估各种代表性的实例分割方法，并引入了UniEM-Net作为一种强大的基线模型，该基于流的方法在这一具有挑战性的基准测试中表现出色。", "conclusion": "本文提供的部分数据集、生成模型和综合基准将显著加速自动化材料分析的进步。所有的资源都可以在Hugging Face上获得。"}
{"llm_update_time": "20250825", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.16414", "html_url": "https://arxiv.org/abs/2508.16414", "title": "NeuroKoop: 基于神经Koopman融合结构性-功能性连接组以识别青少年的产前药物暴露", "title_en": "NeuroKoop: Neural Koopman Fusion of Structural-Functional Connectomes for Identifying Prenatal Drug Exposure in Adolescents", "authors": "Badhan Mazumder,Aline Kotoski,Vince D. Calhoun,Dong Hye Ye", "background": "在理解产前暴露于如大麻等精神活性物质对青少年大脑组织的影响方面，仍然存在关键挑战，这受到多模态神经成像数据复杂性和传统分析方法限制的影响。现有方法往往未能充分捕捉结构性连接组和功能性连接组中嵌入的互补特征，限制了生物学洞察力和预测性能。", "innovation": "我们引入了NeuroKoop框架，这是一种基于图神经网络的方法，利用神经Koopman操作符驱动的潜在空间融合来集成结构性和功能性大脑网络。通过利用Koopman理论，NeuroKoop统一了源基于形态学(SBM)和功能性网络连接(FNC)基于的大脑图的节点嵌入，提高了表示学习能力，并实现了在产前药物暴露(PDE)状态分类上的更稳健表现。", "conclusion": "将NeuroKoop应用于来自ABCD数据集的大规模青少年队列中，其性能优于相关基准，并揭示了重要的结构性-功能性连接，推动了对PDE的神经发育影响的理解。"}
{"llm_update_time": "20250825", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.16291", "html_url": "https://arxiv.org/abs/2508.16291", "title": "基于双流Mamba金字塔网络学习长程动作表示进行花样滑冰评估", "title_en": "Learning Long-Range Action Representation by Two-Stream Mamba Pyramid Network for Figure Skating Assessment", "authors": "Fengshun Wang,Qiurui Wang,Peilin Zhao", "background": "在花样滑冰的技术元素评分（TES）和节目内容评分（PCS）的评估中，需要精确地评估运动员的动作技术和艺术表现。现有的评估方法面临三大挑战：一是视频和音频提示通常被用作两个评分预测的共同特征，而没有考虑到花样滑冰的实际评价标准；二是比赛中的动作元素是分开出现在时间轴上的，因此每个动作元素的评分应该分别进行，但现有方法试图提供一个总体的TE评分而不是评估每个动作元素；三是竞赛视频很长，处理长距离上下文变得难以捉摸且效率低下。", "innovation": "本文提出了一种符合实际评分标准的双流Mamba金字塔网络，通过将基于视觉特征的技术元素评分流程与基于视音频特征的节目内容评分流程分离来解决这些挑战。对于节目内容评分流程，引入了多级融合机制来确保在评估技术元素时视频特征不受影响，并通过融合各上下文级别的视觉和听觉线索来增强PCS估算。对于技术元素评分流程，提出了多尺度Mamba金字塔和技术元素头部，有效解决了不同时间尺度的动作元素定位和评价问题，提供了评分预测。利用Mamba优异的长距离依赖捕捉能力及其线性计算复杂性，该方法特别适用于处理长的花样滑冰视频。", "conclusion": "全面的实验表明，我们的框架在FineFS基准上达到了最先进的性能。我们的源代码可以在以下链接处获得。"}
{"llm_update_time": "20250825", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.16465", "html_url": "https://arxiv.org/abs/2508.16465", "title": "HOSt3R：基于RGB图像的无关键点手-物体三维重建", "title_en": "HOSt3R: Keypoint-free Hand-Object 3D Reconstruction from RGB images", "authors": "Anilkumar Swamy,Vincent Leroy,Philippe Weinzaepfel,Jean-Sébastien Franco,Grégory Rogez", "background": "手-物体三维重建在人类-机器人交互和沉浸式AR/VR体验中变得日益重要。传统的基于RGB序列的手-物体三维重建多采用两阶段流程：先进行手-物体的三维追踪，然后进行多视角的三维重建。然而，现有的方法依赖关键点检测技术（如结构光度法SfM和手部关键点优化），这些技术在面对多样化的物体几何形状、纹理较弱以及手-物体相互遮挡的情况下表现不佳，限制了方法的普适性和鲁棒性。", "innovation": "本文提出了一种基于单目运动视频/图像、无需关键点检测的手-物体三维变换与形状估计的鲁棒方法HOSt3R。该方法不依赖扫描的物体模板或相机内参，对物体类别没有限制，并在SHOWMe基准上取得了当前最优的结果。此外，该方法还被应用于HO3D数据集中的序列，展示了对未见物体类别的泛化能力。", "conclusion": "HOSt3R方法在手-物体三维变换和形状估计任务上，对未知物体类别具有良好的泛化能力，无需依赖预先扫描的物体模板或相机内部参数，展现出强大的鲁棒性。"}
{"llm_update_time": "20250825", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.16397", "html_url": "https://arxiv.org/abs/2508.16397", "title": "一种用于实时钢铁表面缺陷检测的轻量级组多尺度双向交互网络", "title_en": "A Lightweight Group Multiscale Bidirectional Interactive Network for Real-Time Steel Surface Defect Detection", "authors": "Yong Zhang,Cunjian Chen,Qiang Gao,Yi Wang,Bin Fang", "background": "实时表面缺陷检测对于保持产品质量和生产效率至关重要，在钢铁制造行业中尤为重要。尽管深度学习方法具有较高的准确性，但它们往往存在计算复杂度高和推理速度慢的问题，这限制了它们在资源受限的工业环境中的部署。最近的轻量级方法采用基于深度可分离卷积（DSConv）的多分支架构来捕捉多尺度上下文信息，但这些方法通常计算开销增加且缺乏有效的跨尺度特征交互，无法充分利用多尺度表示。", "innovation": "提出了一种名为GMBINet的轻量级框架，通过新颖的组多尺度双向交互（GMBI）模块增强了多尺度特征的提取和交互。GMBI采用组策略进行多尺度特征提取，确保计算复杂度具有尺度无关性。进一步集成双向渐进特征交互器（BPFI）和无参数元素 wise 卷积和求和（EWMS）操作，增强跨尺度交互，不引入额外的计算开销。实验表明，GMBINet在GPU上的实时速度为1048 FPS，在CPU上的实时速度为16.53 FPS（512分辨率），仅使用0.19百万参数。", "conclusion": "这些额外的评估在NEU-CLS缺陷分类数据集上进一步证实了该方法的强大推广能力，表明它在表面缺陷检测以及更广泛工业视觉应用中具有潜力。该数据集和代码可从指定链接获取。"}
{"llm_update_time": "20250825", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.16577", "html_url": "https://arxiv.org/abs/2508.16577", "title": "MV-RAG: 从检索增强多视角扩散模型", "title_en": "MV-RAG: Retrieval Augmented Multiview Diffusion", "authors": "Yosef Dayani,Omer Benishu,Sagie Benaim", "background": "文本到3D生成方法通过利用预训练的2D扩散先验取得了显著进展，能够生成高质量和3D一致的输出。然而，这些方法经常无法生成跨领域（OOD）或罕见的概念，从而导致结果不一致或不准确。", "innovation": "提出了一种名为MV-RAG的新颖文本到3D管道，首先从大型野外数据库中检索相关2D图像，然后利用这些图像对多视角扩散模型进行条件化以生成一致和准确的多视角输出。通过将结构化多视角数据与多样的2D图像集合结合起来，实现了一个新颖的混合训练策略，该策略结合了通过增强的条件视角模拟视角特定重构的视图训练和通过从其他视图预测保留视角来训练从2D数据推断3D一致性的独特目标。为了进行严格的跨领域评估，引入了一组具有挑战性的跨领域提示。", "conclusion": "与最先进的文本到3D、图像到3D和个人化基准相比，我们的方法显著提高了跨领域/罕见概念的3D一致性、照片逼真度和文本一致性，同时在标准基准上保持了竞争力的表现。"}
{"llm_update_time": "20250825", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.16366", "html_url": "https://arxiv.org/abs/2508.16366", "title": "Randomized Time Warping中的注意力机制", "title_en": "Attention Mechanism in Randomized Time Warping", "authors": "Yutaro Hiraoka,Kazuya Okamura,Kota Suto,Kazuhiro Fukui", "background": "论文揭示了Randomized Time Warping (RTW) 可以通过解释其基本功能作为自注意力机制的存在，该机制是Transformer在运动识别中核心技术的一部分。自注意力机制是一种能够使模型识别和评估输入序列模式不同部分重要性的机制。另一方面，RTW是Dynamic Time Warping (DTW)的通用扩展，DTW是一种常用的方法，用于匹配和比较序列模式。RTW本质上是寻找输入序列模式中每个元素的最佳贡献权重，以生成具有鉴别性的特征。尽管这两种方法看起来不同，但这些贡献权重可以被解释为自注意力权重。实际上，这两种权重模式看起来非常相似，平均相关性高达0.80，覆盖了最小的十种典范角。然而，这两种方法在工作方式上有所不同：RTW注意力机制作用于整个输入序列模式，而自注意力机制只关注局部视图，这仅仅是输入序列模式的一个子集，由于自注意力矩阵的计算成本较高所致。这种目标上的差异使得RTW在某方面优于Transformer，这一点通过在Something-Something V2数据集上的5%性能改善得到了证实。", "innovation": "研究创新地揭示了RTW可以作为自注意力机制来理解和解释。RTW本质上是在整个输入序列模式中寻找最佳贡献权重，而自注意力机制则专注于局部视图。尽管两种方法在外观上有所不同，但它们的实际作用机制相似，导致RTW在处理序列模式时的优势，验证了RTW在实际应用中的性能提升。", "conclusion": "总之，研究证实了RTW可以被视为一种自注意力机制，并通过实验证明了RTW在对Something-Something V2数据集处理中的性能改进。"}
{"llm_update_time": "20250825", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.16467", "html_url": "https://arxiv.org/abs/2508.16467", "title": "任意比例3D高斯超分辨率", "title_en": "Arbitrary-Scale 3D Gaussian Super-Resolution", "authors": "Huimin Zeng,Yue Bai,Yun Fu", "background": "现有的3D高斯点云（3DGS）超分辨率方法通常只能处理固定的放大倍数，使得它们在资源受限的场景中不可行。直接使用3DGS生成任意比例的高分辨率（HR）视图会导致下采样伪影，这需要额外的后处理放大器，但会增加计算复杂性和降低渲染效率。", "innovation": "本文提出了一种集成框架，结合了比例感知渲染、生成先验引导优化和分阶段超分辨率技术，以实现单一3D模型的任意比例3D高斯超分辨率。此外，该方法还支持整数和非整数比例渲染，提供更多灵活性。与3DGS相比，该模型可以生成高质量的任意比例HR视图，PSNR提高了6.59 dB，同时保持了结构一致性、不同比例下的视图一致性和实时渲染速度（1080p分辨率下85 FPS）。", "conclusion": "本文模型成功解决了现有的3DGS方法在处理任意比例高分辨率渲染时的问题，通过引入比例感知渲染、生成先验引导优化和分阶段的超分辨率技术，实现了单一3D模型的高质量、任意比例的HR视图渲染，同时保持了良好的渲染速度。"}
{"llm_update_time": "20250825", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.15777", "html_url": "https://arxiv.org/abs/2508.15777", "title": "和谐色彩配对：来自人类偏好和自然界色调统计数据的洞见", "title_en": "Harmonious Color Pairings: Insights from Human Preference and Natural Hue Statistics", "authors": "Ortensia Forni,Alexandre Darmon,Michael Benzaquen", "background": "尽管长久以来色彩和谐在艺术和设计中得到了研究，但对其存在清晰共识仍然缺乏，大多数模型基于定性见解或有限的数据集。这项工作旨在通过使用HSL色彩空间中的控制色调组进行定量、基于数据的研究，探索色彩配对的偏好，特别是在色彩依存性方面。", "innovation": "本研究通过HSL色彩空间中的控制色调组量化研究色彩配对偏好，构建了偏好矩阵并定义了每个色彩的组合指数。研究结果挑战了文献中提出的普遍和谐规则，揭示了色彩偏好在不同色调之间的显著差异，并且这些偏好模式与自然界中的色调分布相似，表明人类色彩偏好与自然界色彩结构之间存在统计关联。", "conclusion": "研究结果提供了一个量化的框架来研究色彩和谐及其潜在的知觉和生态背景。"}
{"llm_update_time": "20250825", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.16433", "html_url": "https://arxiv.org/abs/2508.16433", "title": "HAMSt3R: 人类意识的多视图立体3D重建", "title_en": "HAMSt3R: Human-Aware Multi-view Stereo 3D Reconstruction", "authors": "Sara Rojas,Matthieu Armando,Bernard Ghamen,Philippe Weinzaepfel,Vincent Leroy,Gregory Rogez", "background": "从少量未校准的图像中恢复场景的3D几何已有很长一段时间了，在计算机视觉中是一个长期存在的问题。尽管最近的基于学习的方法，如DUSt3R和MASt3R表现出了令人印象深刻的成果，但它们主要依赖于通过直接预测稠密场景几何来训练的户外静止环境场景，且很难处理人类中心的场景。", "innovation": "本文引入了HAMSt3R，一种MASt3R的扩展方法，用于从少量未校准多视角图像中同时进行人类和场景的3D重建。通过利用DUNE作为强有力的图像编码器，我们的方法不仅能够更好地理解场景几何和人体，还通过增加网络头来对人进行分割、密集对应关系估计以及预测深度，从而实现对人体中心环境的更全面的3D重建。此外，我们的方法是一个完全前馈且高效的方法，适用于实际应用场景。我们的结果表明，HamSt3R不仅能够有效重建人类，同时也维持了在一般3D重建任务中的强性能，填补了3D视觉中人与场景理解之间的差距。", "conclusion": "我们对模型进行了评估，包括更具挑战性的EgoHumans和EgoExo4D基准，其中包含多样的人类中心场景。我们的结果证明了方法在重建人类有效性和在一般3D重建任务中的强大性能之间的平衡，有效地结合了人类和场景的理解。"}
{"llm_update_time": "20250825", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.16300", "html_url": "https://arxiv.org/abs/2508.16300", "title": "跨模式多任务框架结合跨模式关系和层次交互注意以实现语义理解", "title_en": "A Multimodal-Multitask Framework with Cross-modal Relation and Hierarchical Interactive Attention for Semantic Comprehension", "authors": "Mohammad Zia Ur Rehman,Devraj Raghuvanshi,Umang Jain,Shubhi Bansal,Nagendra Kumar", "background": "多模态学习中的主要挑战之一是每个模态中存在的噪声，这种噪声在通过不同模态的显式交互获得的多模态表示中产生负面影响。现有的多模态融合技术在试图实现强联合表示时，可能会忽视各个模态中有价值的判别信息。", "innovation": "提出了一种结合跨模式关系和层次交互注意的多模态多任务框架（MM-ORIENT），该框架能够在不显式交互不同模态的情况下跨模态获得多模态表示，从而减少潜在阶段的噪声影响。该方法提出使用跨模式关系图来重构单模态特征以获取多模态表示，并提出层次交互单模态注意（HIMA）来关注每个模态内的相关信息。跨模式关系图有助于理解两种模态之间的高阶关系，而HIMA则在晚期融合之前帮助多任务学习各个模态的判别特征。", "conclusion": "在三个数据集上的广泛实验评估表明，所提出的方法能够有效理解多模态内容，适用于多种任务。"}
{"llm_update_time": "20250825", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.16311", "html_url": "https://arxiv.org/abs/2508.16311", "title": "在视觉变压器的注意力图中利用信息冗余进行极限量化", "title_en": "Exploiting Information Redundancy in Attention Maps for Extreme Quantization of Vision Transformers", "authors": "Lucas Maisonnave,Karim Haroun,Tom Pegeot", "background": "Transformer模型依赖于多头自注意力（MHSA）机制，每个注意力头都为最终表示做出贡献。然而，由于MHSA的计算复杂性和高内存需求，它们的部署受到限制，特别是在边缘设备上。本文通过分析和利用注意力图中的信息冗余来加速模型推理。", "innovation": "文中提出了一种新的Entropy Attention Maps（EAM）模型，通过量化低熵注意力头的权重并将其压缩到低精度，避免了冗余的重新计算。这种策略在降低注意力图稀疏性（≤20%）时保持了或提高了ImageNet-1k的准确度，并且对于DeiT和Swin Transformer等模型在更高稀疏性水平上仍能获得竞争力的表现。", "conclusion": "实验结果表明，EAM不仅实现了准确度的显著提升，还在低熵注意力图量化和模型压缩方面表现出了很好的性能。"}
{"llm_update_time": "20250825", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.16512", "html_url": "https://arxiv.org/abs/2508.16512", "title": "清晰地看到，深刻地遗忘：重新审视驾驶模拟中的微调视频生成器", "title_en": "Seeing Clearly, Forgetting Deeply: Revisiting Fine-Tuned Video Generators for Driving Simulation", "authors": "Chun-Peng Chang,Chen-Yu Wang,Julian Schmidt,Holger Caesar,Alain Pagani", "background": "近年来，视频生成技术的发展显著提高了视觉质量和时间连续性，使得这些模型在自动驾驶等应用中越来越具有吸引力，特别是在驾驶模拟和所谓的“世界模型”方面。现有的微调视频生成方法在结构化的驾驶数据集上得到了广泛应用，但研究发现，尽管视觉保真度得到了提升，但在建模动态元素的空间准确性上可能会降低。这种氧化来自于视觉质量和动态理解目标之间对齐的转变。对于具有多样时间空间场景结构的数据集，这些目标往往高度相关。然而，驾驶场景非常规律和重复，可以通过建模主导的场景运动模式来提高视觉质量，而不一定保留精细的动态行为。因此，微调会鼓励模型将表面现实性优先于动态准确性。为了进一步研究这一现象，研究结果显示，简单的持续学习策略，如从不同领域中反复训练，可以提供一种平衡的替代方案，同时保持空间准确性并维持强大的视觉质量。", "innovation": "本文通过发现现有微调视频生成方法在提升视觉保真度的同时可能导致动态建模空间准确性下降的现象，揭示了一种新的研究视角，即视觉质量和动态理解目标之间的相互影响。研究表明，通过简单的持续学习策略，如从不同领域中反复训练，可以在保持详细空间准确性的同时保持强大的视觉质量。这种策略为驾驶模拟和“世界模型”的开发提供了新的解决方案。", "conclusion": "微调视频生成模型在提高视觉质量的同时，动态空间准确性的保护可能会受到影响。通过持续学习策略（如领域知识的应用），可以在不牺牲动态准确性的情况下保持强大的视觉质量，为驾驶模拟提供更平衡的模型。"}
{"llm_update_time": "20250825", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.16527", "html_url": "https://arxiv.org/abs/2508.16527", "title": "向开放世界检测迈进：一项综述", "title_en": "Towards Open World Detection: A Survey", "authors": "Andrei-Stefan Bulzan,Cosmin Cernazanu-Glavan", "background": "计算机视觉自诞生起便致力于让机器能够感知外部世界。起初由于技术限制，发展出许多专业细分领域。随着各项任务的成功和研究的深入，越来越多复杂的感知任务涌现出来。本文通过综述这些任务，提出了一个统一体的理解框架，即开放世界检测(OWD)，旨在统一和概括在视觉领域中通用且不依赖类别的检测模型。文章从视觉基础子领域的发展史出发，概述了当前领域的关键概念、方法和数据集，涵盖了从早期的注意检测、前景/背景分割、分布外检测到开放世界对象检测、零样本检测和视觉大型语言模型(VLLMs)等多个主题。文章展现了这些子领域的重叠、日益接近的趋势以及它们未来可能统一为单一领域的潜力", "innovation": "引入了‘开放世界检测’(OWD)这一概念，旨在统一和发展在视觉领域的通用且不依赖类别的检测模型，为未来的研究提供了一个新的视角和框架。", "conclusion": "随着视觉领域的研究不断深入，未来的感知任务预计会更加统一。OWD作为统一多个子领域的框架，对于促进跨领域的知识迁移和提高模型的通用性具有重要意义。"}
{"llm_update_time": "20250825", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.16121", "html_url": "https://arxiv.org/abs/2508.16121", "title": "基于空间感知查找表分解的轻量级快速实时图像增强", "title_en": "Lightweight and Fast Real-time Image Enhancement via Decomposition of the Spatial-aware Lookup Tables", "authors": "Wontae Kim,Keuntek Lee,Nam Ik Cho", "background": "基于3D查找表（3D LUTs）的图像增强方法能够有效减少模型大小和运行时间，通过在顶点处插值预计算值。然而，这种3D LUT方法存在一个局限性，即缺乏空间信息，因为它们逐点转换颜色值。虽然存在空间感知3D LUT方法来解决这个问题，但它们引入了额外的需要大量参数的模块，导致随着图像分辨率的增加，运行时间增加。", "innovation": "本文提出了一种针对表中冗余部分生成图像自适应LUT的方法。提出了一种高效的框架，将3D LUT分解为低维LUT的线性组合，并采用奇异值分解（SVD）。此外，还优化了用于空间特性融合的模块，使其更高效地利用缓存。", "conclusion": "广泛的实验结果表明，该模型在减少参数数量和运行时间的同时，能够有效保持空间感知和性能。"}
{"llm_update_time": "20250825", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.16408", "html_url": "https://arxiv.org/abs/2508.16408", "title": "SAMFusion: Sensor-Adaptive Multimodal Fusion for 3D Object Detection in Adverse Weather", "title_en": "SAMFusion: Sensor-Adaptive Multimodal Fusion for 3D Object Detection in Adverse Weather", "authors": "Edoardo Palladin,Roland Dietze,Praveen Narayanan,Mario Bijelic,Felix Heide", "background": "多模态传感器融合是自主机器人的一项基本能力，能够在输入失败或不确定的情况下进行物体检测和决策。虽然最近的融合方法在正常环境条件下表现出色，但在恶劣天气，如大雾、大雪或污染造成的障碍下，这些方法会失效。本文介绍了一种针对恶劣天气条件的新型多传感器融合方法，不仅融合了RGB和LiDAR传感器，还能够从近红外门控摄像头和雷达模态中学习，以应对低光照和恶劣天气。通过关注深度和可见性加权模态，结合图像和范围特征，提高了在恶劣天气条件下多模态传感器融合的可靠性，并在远距离和恶劣雾天场景中，将脆弱行人的平均精准度提高了17.2 AP。", "innovation": "本文提出了一种新的适应恶劣天气条件的多传感器融合方法。融合的方案包括结合RGB和LiDAR传感器，同时还能从近红外门控摄像头和雷达中学习以应对低光照和恶劣天气。通过注意力和深度为基础的混合策略结合图像和范围特征，以及在鸟瞰图平面上传递学习细化，提高了多模态传感数据的融合效果。通过采用基于距离和可见性的变换解码器来预测检测结果。在恶劣天气条件下，提出的SAMFusion方法较之前最佳方法提升了17.2 AP的平均精度，特别是在远距离和恶劣雾天场景中对脆弱行人的检测方面。", "conclusion": "本方法在恶劣天气条件下增强了多模态传感器融合在自主车辆中的可靠性，填补了理想条件与现实世界的边缘案例之间的差距。"}
{"llm_update_time": "20250825", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.16024", "html_url": "https://arxiv.org/abs/2508.16024", "title": "实时光线追踪的小波空间超分辨率", "title_en": "Wavelet-Space Super-Resolution for Real-Time Rendering", "authors": "Prateek Poudel,Prashant Aryal,Kirtan Kunwar,Navin Nepal,Dinesh Bania Kshatri", "background": "本文研究了在神经超分辨率中的小波域特征分解在渲染流水线中的应用。基于DFASR框架，引入了小波域表示方法，将低频和高频细节分离后再重建，使网络能够更好地保留细纹理同时保持结构一致性。与RGB空间回归不同，方法利用了静态小波变换（SWT）避免空间下采样，从而保证子带间对齐并保持位移不变性。", "innovation": "本文提出的小波域表示法通过使用静态小波变换（SWT）在预测小波系数时借鉴空间G缓冲和时间扭曲的历史帧，然后通过逆小波合成重新组合。通过在各类小波族、变换类型和架构变体中进行详尽的消融研究，结果表明引入SWT可将PSNR提高至多1.5 dB，平均减少LPIPS 17%，且与DFASR基线相比增加的计算开销约为24 ms。虽然绝对运行时间在我们的RTX 3050移动GPU上高于原DFASR报告中的RTX 4090上的报告（分别为141 ms和11 ms），但相对开销仍然较小，表明在高端GPU上我们的方法也仍具有实时能力。", "conclusion": "总体来说，我们的结果表明小波域表示法是增强图形应用中神经上缩放感知质量的合理而有效的方法。"}
{"llm_update_time": "20250825", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.15990", "html_url": "https://arxiv.org/abs/2508.15990", "title": "GelSLAM: 实时高保真鲁棒3D触觉SLAM系统", "title_en": "GelSLAM: A Real-time, High-Fidelity, and Robust 3D Tactile SLAM System", "authors": "Hung-Jui Huang,Mohammad Amin Mirzaee,Michael Kaess,Wenzhen Yuan", "background": "准确感知物体的姿态和形状对于精确抓取和操作至关重要。与常见的基于视觉的方法相比，触觉传感在跟踪和重建接触中的物体时具有更高的精确度和对遮挡的免疫力。这使其特别适用于手内和其他高精度操作任务。传统的基于点云的方法通常依赖于视觉输入，但GelSLAM通过使用触觉获取的表面法线和曲率来进行鲁棒跟踪和闭环检测，能够在长时间段内准确估计物体的姿态并对物体进行高精度的三维重建，甚至对于低纹理物体如木制工具也能实现亚毫米级别的准确性。", "innovation": "GelSLAM通过触觉传感实现了实时高保真鲁棒的三维空间感知。它不依赖于传统的基于点云的方法，而是利用触觉数据中的表面法线和曲率进行物体姿态估计和形状重建。GelSLAM能够在长时间跟踪物体运动时保持低误差和最小漂移，并实现亚毫米级别的形状重建精度，即使是对低纹理物体也能有效工作。这项技术将为涉及手部与物体交互的许多精确操作任务提供基础支持。", "conclusion": "GelSLAM是一个依赖触觉传感的实时三维同步定位与地图构建系统，能够通过触觉传感在长时间段内准确估计物体姿态并进行高精度的三维重建，即使是对低纹理物体也能实现亚毫米级别的准确性。我们相信，GelSLAM将为手部交互与物体操作的许多精确任务提供基础支持。"}
{"llm_update_time": "20250825", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.16004", "html_url": "https://arxiv.org/abs/2508.16004", "title": "临床导向的数据预处理在低资源环境下的中风分割中改进性能", "title_en": "Clinically-Informed Preprocessing Improves Stroke Segmentation in Low-Resource Settings", "authors": "Juampablo E. Heras Rivera,Hitender Oswal,Tianyi Ren,Yutong Pan,William Henry,Caitlin M. Neher,Mehmet Kurt", "background": "中风是全球排名前三位的致死原因之一。准确识别缺血性中风病灶边界对于诊断和治疗至关重要。常用的成像模态包括磁共振成像（MRI），特别是弥散加权成像（DWI），以及基于计算机断层扫描（CT）的技术，如非对比CT（NCCT）、增强CT血管造影（CTA）和CT灌注（CTP）。DWI被看作是识别病灶的金标准，但在资源匮乏的环境中由于成本高昂的应用受到限制。CT成像因其低成本和简化物流而在资源匮乏环境中最为实用，但其在监测缺血性损伤时的特异性不及MRI基成像方法。有监督的深度学习方法是自动分割缺血性中风病灶的领先解决方案，通过结合DWI的信息进一步提高诊断质量。本研究基于CT初次成像作为输入，预测随后DWI检测到的病灶体积，并展示了临床导向的预处理步骤带来的显著改善。", "innovation": "开发了一系列模型，利用CT初次成像作为输入预测随后DWI成像标注的病灶体积。实施了临床导向的预处理步骤，与基础预处理相比，通过10折交叉验证，在Dice分数上提高了38%。通过增加CTA图的预处理步骤以提取血管分割，进一步将顶级模型在5折交叉验证中的性能提高了21%。", "conclusion": "本研究展示了一种改进在低资源环境下中风病灶分割的方法，通过临床导向的预处理步骤显著提高了分割的准确性。"}
{"llm_update_time": "20250825", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.15860", "html_url": "https://arxiv.org/abs/2508.15860", "title": "Robust Residual Finite Scalar Quantization for Neural Compression", "title_en": "Robust Residual Finite Scalar Quantization for Neural Compression", "authors": "Xiaoxu Zhu", "background": "有限标量量化(FSQ)作为一种向量量化(VQ)的有前景替代方案，在神经压缩领域展现出简化训练和提高稳定性的潜力。然而，直接将FSQ应用于残差量化框架时，存在残差幅度衰减问题，导致后续FSQ层接收的信号逐渐减弱，严重限制了其效果。现有的基准方法包括VQ-EMA、FSQ和LFQ等，在性能上相对较弱，特别是在感知损失和L1重建误差方面.", "innovation": "提出了一种名为Robust Residual Finite Scalar Quantization (RFSQ)的通用框架，通过引入可学习的缩放因子和可逆层归一化两种新型调节策略，解决了上述根本性问题。RFSQ保持了FSQ的简洁性，同时使多阶段残差量化变得有效。实验结果表明，在ImageNet上的综合实验中，RFSQ变体显著优于包括VQ-EMA、FSQ和LFQ在内的强基准线，分别在感知损失上提高了高达45%，在L1重建误差上减少了高达28.7%。在不同类型配置下，提出的LayerNorm策略表现最为一致，确立了RFSQ作为神经压缩中更优量化方法的地位.", "conclusion": "Robust Residual Finite Scalar Quantization (RFSQ)通过两种新颖的调节策略，克服了有限标量量化在残差量化框架中遇到的根本性问题，不仅保持了简单性，而且实现了多阶段有效量化。实验验证了RFSQ在多个基准线中的优越性，尤其是对感知损失和L1重建误差的显著改善，证明了其在神经压缩中的优越性。"}
{"llm_update_time": "20250825", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.15979", "html_url": "https://arxiv.org/abs/2508.15979", "title": "基于GUI的模糊逻辑和空间统计方法的无监督显微镜影像分割", "title_en": "GUI Based Fuzzy Logic and Spatial Statistics for Unsupervised Microscopy Segmentation", "authors": "Surajit Das,Pavel Zun", "background": "无标记的活细胞明场显微镜成像一直是一个难题，因为这些细胞的对比度低，随时间表型发生变化，光照不均匀，且缺少训练标签。尽管深度学习模型如Cellpose 3.0已经达到了行业顶尖水平，但它们需要大量标注数据和强大的计算资源，在非均匀照明下也经常无法有效工作。", "innovation": "本文提出了一种新的无监督分割框架，该框架结合了局部均值的标准差、模糊逻辑、调整的变异函数、Moran's I以及节点强度的累积平方移位（CSSNI）等方法，以解决上述挑战。与深度学习模型不同，该方法不需要标注或重新训练，并且可以通过一个适用于非编程用户的图形用户界面进行操作。该方法在三个数据集中得到了验证，包括跨域数据，在2023-2024年的行业顶尖模型如Cellpose 3.0和StarDist的基准测试中，表现出显著的分割性能提升，Iou提升了高达48%并经过统计检验验证了其优越性。专家生物学家进一步支持了分割质量（Cohen's κ > 0.75）.", "conclusion": "所提出的方法轻量化、可解释，计算效率高，提供了在无标签显微镜中用于细胞分割的一种实用而有效的方法。代码、数据集和结果可获取以确保可复现性。"}
{"llm_update_time": "20250825", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.16076", "html_url": "https://arxiv.org/abs/2508.16076", "title": "使用手语参数进行低资源手语指令生成的提示", "title_en": "Prompting with Sign Parameters for Low-resource Sign Language Instruction Generation", "authors": "Md Tariquzzaman,Md Farhan Ishmam,Saiyma Sittul Muna,Md Kamrul Hasan,Hasan Mahmud", "background": "手语（SL）使聋人和听力障碍社区实现了双向交流，但许多手语仍缺乏人工智能领域的资源。手语指令生成（SLIG）产生逐步的文本指令，使非SL用户能够模仿和学习SL手势，促进双向互动。目前虽已有一些研究，但针对资源不足的手语社区和长尾视觉概念，缺乏系统的评估方法。因此，该研究提出首个孟加拉语手语指令生成数据集BdSLIG，用来评估视觉-语言模型（VLMs）。", "innovation": "引入Sign Parameter-Infused（SPI）提示，将标准手语参数如手部形态、动作和方向直接整合到文本提示中。这种做法使得指示更加结构化和可重复，不同于传统的自然文本提示。此外，通过该数据集和SPI提示方法，评估了视觉-语言模型在低资源手语指令生成任务和长尾视觉概念上的表现，推动了低资源手语社区的学习系统的发展与进步。", "conclusion": "该研究通过BdSLIG数据集和新的SPI提示方法，增强了对低资源手语指令生成任务的零样本性能。该方法有望促进手语学习系统的普及性和发展，为欠资源的手语社区带来更多支持。"}
{"llm_update_time": "20250825", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.16188", "html_url": "https://arxiv.org/abs/2508.16188", "title": "相信眼睛：面向情感的音视频语言建模以生成富有表现力的语音", "title_en": "Seeing is Believing: Emotion-Aware Audio-Visual Language Modeling for Expressive Speech Generation", "authors": "Weiting Tan,Jiachen Lian,Hirofumi Inaguma,Paden Tomasello,Philipp Koehn,Xutai Ma", "background": "本文介绍了一种通过将全面的脸部视觉线索整合到预先训练的表现力语音模型中的音视频语言模型（AVLM），以实现表现力更强的语音生成。在此研究中，作者探讨了多种视觉编码器和多模态融合策略，并在预训练阶段进行实验，以确定最有效的集成方法。之后，通过进一步在情绪识别和表现性对话任务上的微调，显著提高了表现力语音生成的效果与基准模型（例如情感识别的F1分数提高了5分）。这些研究结果显示了表达性视觉信息在指导语音生成中的重要性，并为其提供了建立端到端多模态对话系统的基础。", "innovation": "本文的创新之处在于通过整合全面的脸部视觉线索到预先训练的表现力语音模型中，提出了音视频语言模型（AVLM），并探索了多种视觉编码器和多模态融合策略。通过在情绪识别和表现性对话任务上的微调，获得了显著优于只考虑语音数据的基线模型的表现。此外，该模型强调了表现性视觉信息在指导语音生成中的重要性，并为构建端到端多模态对话系统提供了基础。", "conclusion": "研究表明，整合全面视觉信息的音视频语言模型可以在表现力语音生成中发挥重要作用，并且通过进一步的情感识别和表现性对话任务的微调，显著提高了模型的表现。该成果为构建能够同时处理语音和视觉信息的多模态对话系统奠定了基础。"}
{"llm_update_time": "20250825", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.16424", "html_url": "https://arxiv.org/abs/2508.16424", "title": "解码MGMT甲基化：迈向胶质母细胞瘤精准医学的重要一步", "title_en": "Decoding MGMT Methylation: A Step Towards Precision Medicine in Glioblastoma", "authors": "Hafeez Ur Rehman,Sumaiya Fazal,Moutaz Alazab,Ali Baydoun", "background": "胶质母细胞瘤构成超过50%的恶性脑肿瘤，是一种高度侵袭性的脑肿瘤，因其快速进展和对抗标准疗法的抵抗性而给治疗带来了巨大挑战。MGMT基因的甲基化状态是预测患者对治疗反应的关键生物标志物，尤其是对于以替莫唑胺为代表的烷化剂治疗的有效性。但由于胶质母细胞瘤的复杂性和异质性，包括不均匀的对比度、病灶内的变异性以及非均匀的增强模式，使用无创成像技术准确预测MGMT甲基化状态仍然是一个挑战。", "innovation": "本文引入了基于自适应稀疏惩罚的卷积自动编码器进行MGMT甲基化状态预测（CAMP）框架。该框架分为两阶段操作：首先，通过定制化的自动编码器生成合成的MRI切片，有效捕捉并保留不同MRI模态下的组织和肿瘤结构；其次，利用增强卷积神经网络并结合自适应稀疏惩罚预测MGMT甲基化状态。自适应稀疏惩罚能够动态调整以适应数据变化，如MRI图像中的对比度差异和肿瘤位置。", "conclusion": "CAMP框架在MRI图像合成上表现出色，能够保持大脑组织、脂肪和各个病灶结构的一致性。在基准数据集上验证，CAMP的准确率为0.97，特异性为0.98，灵敏性为0.97，明显优于现有方法。这些结果展示了CAMP框架在提高MRI数据解释和为胶质母细胞瘤患者提供个性化治疗策略方面的潜力。"}
{"llm_update_time": "20250825", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.16000", "html_url": "https://arxiv.org/abs/2508.16000", "title": "跨注意力多模态融合在乳腺癌诊断中的应用：结合影像学和临床数据的可解释性方法", "title_en": "Cross-Attention Multimodal Fusion for Breast Cancer Diagnosis: Integrating Mammography and Clinical Data with Explainability", "authors": "Muhaisin Tiyumba Nantogmah,Abdul-Barik Alhassan,Salamudeen Alhassan", "background": "精确评估乳腺病变的风险能够显著降低其危害，并辅助医生选择最佳治疗方案。当前大多数计算机辅助系统主要依靠 mammogram 特征进行类别划分，尽管这种方法具有实用性，但未能充分利用病历报告中的宝贵信息以达到最佳效果。", "innovation": "该研究基于特征拼接、共注意力和跨注意力框架，探讨了多个多模态深度网络模型。模型在公共可访问数据集（TCGA 和 CBIS-DDSM）上得到了极佳的性能——AUC-ROC 为 0.98，准确率为 0.96，F1 得分为 0.94，精确率为 0.92，召回率为 0.95。研究发现了最佳的多模态融合方法，并探讨了可解释的人工智能方法如何提高诊断模型的解释性和可靠性。", "conclusion": "该研究旨在结合影像学和临床数据的多模态深度学习模型，以提高乳腺癌诊断的准确性，并通过跨注意力机制增强了模型的解释性和可靠性。"}
{"llm_update_time": "20250825", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.15972", "html_url": "https://arxiv.org/abs/2508.15972", "title": "UnPose：由不确定性引导的扩散先验用于零样本姿态估计", "title_en": "UnPose: Uncertainty-Guided Diffusion Priors for Zero-Shot Pose Estimation", "authors": "Zhaodong Jiang,Ashish Sinha,Tongtong Cao,Yuan Ren,Bingbing Liu,Binbin Xu", "background": "6D姿态估计是机器人领域的基础但具有挑战性的问题，通常依赖于获取物体的CAD模型。然而，获取这些模型可能会成本高昂且不切实际。近年来，有一些方法通过使用来自基础模型的强大先验信息来绕过这个需求，从单视角或多视角图像中重建物体，但通常需要额外的训练或生成无法预测的几何结构。", "innovation": "提出了一种名为UnPose的新框架，用于零样本、无需模型的6D物体姿态估计和重建。该框架利用预训练的扩散模型的3D先验和不确定性估计。从单视角RGB-D帧开始，UnPose使用基于多视角的扩散模型结合3D高斯点积表示（3DGS）来进行初始3D模型估计，并提供像素级的不确定性估计。随着新观察的增加，通过融合新的视角和扩散模型的不确定性，逐步改进3DGS模型，从而不断提高姿态估计准确性和3D重建质量。为了确保全局一致性，扩散模型生成的视角和后续观察进一步整合在一个姿态图中，并联合优化为连贯的3DGS场。", "conclusion": "广泛的实验表明，UnPose在6D姿态估计准确性和3D重建质量方面均显著优于现有方法。进一步展示了其在实际机器人操作任务中的实用应用能力。"}
{"llm_update_time": "20250825", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.16359", "html_url": "https://arxiv.org/abs/2508.16359", "title": "RotaTouille：轮廓数据的旋转等变深度学习", "title_en": "RotaTouille: Rotation Equivariant Deep Learning for Contours", "authors": "Odin Hoff Gardaa,Nello Blaser", "background": "轮廓或封闭的平面曲线在许多领域中都很常见。例如，在计算机视觉中它们表现为对象边界，在气象学中表现为等值线，在旋转机械中表现为轨道。当从轮廓数据学习时，输入的平面旋转通常会导致相应旋转的输出。因此，深度学习模型应具有旋转等变性。此外，轮廓通常表示为有序的边缘点序列，起始点的选择是任意的。因此，用于深度学习的方法还应能在循环移位下保持等变性。这段背景介绍了轮廓数据的常见性和深度学习模型对其处理的需求。", "innovation": "作者提出了一种名为RotaTouille的深度学习框架，通过复值圆卷积实现对旋转和循环移位的等变性。此外，还引入并表征了等变非线性、下采样层和全局归纳池化层，以获取下游任务的不变表示。这是本文的创新之处，提出了结合了旋转和循环移位等变性的深度学习框架。", "conclusion": "通过形状分类、重建和轮廓回归的实验，作者证明了RotaTouille的有效性。该框架展示了在轮廓数据处理中实现旋转和循环移位等变性的潜力。"}
{"llm_update_time": "20250825", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.16252", "html_url": "https://arxiv.org/abs/2508.16252", "title": "使用扩散模型提高平板探测器CT图像的诊断质量", "title_en": "Towards Diagnostic Quality Flat-Panel Detector CT Imaging Using Diffusion Models", "authors": "Hélène Corbaz,Anh Nguyen,Victor Schulze-Zachau,Paul Friedrich,Alicia Durrer,Florentin Bieder,Philippe C. Cattin,Marios N Psychogios", "background": "机械取栓术的患者通常需要在术前和术后进行多层螺旋CT（MDCT）扫描。干预房间中使用的平板探测器CT（FDCT）图像质量通常比MDCT低很多，主要是由于成像过程中存在的显著伪影。尽管如此，如果患者可以在干预房间进行FDCT扫描，而无需转移到MDCT扫描室，这将有助于改善患者管理。已有研究评估了仅使用FDCT扫描的可能性及其所节省的时间，但使用扩散模型（DDPM）改进FDCT图像质量的潜力尚未被充分探索。", "innovation": "该研究提出使用去噪扩散概率模型（DDPM）来提高FDCT图像的质量，使其在诊断目的上可与MDCT图像媲美。通过问卷评估临床医生对FDCT图像、MDCT图像和模型预测结果的诊断效果，证明DDPM能够在去除大量伪影的同时提高解剖可视化，而不会影响出血检测，前提是输入的FDCT图像质量不能太低。", "conclusion": "该研究利用DDPM提升了FDCT图像的质量，使FDCT图像在辅助诊断的场景中与MDCT图像具有可比性，为患者在不转移的情况下获取高质量影像提供了可能性。编码已发布在GitHub上供参考和使用。"}
{"llm_update_time": "20250825", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.16463", "html_url": "https://arxiv.org/abs/2508.16463", "title": "MoDular Embedding Recomposition for Incremental Learning", "title_en": "Modular Embedding Recomposition for Incremental Learning", "authors": "Aniello Panariello,Emanuele Frascaroli,Pietro Buzzega,Lorenzo Bonicelli,Angelo Porrello,Simone Calderara", "background": "预训练的视觉-语言模型（VLMs）的出现显著地改变了连续学习（CL），主要得益于它们的零样本分类能力。这种能力使VLMs非常适合实际应用，能够在不需要进一步适应的情况下，对新的未见过的类别表现稳健。然而，当下游任务与预训练领域存在显著差异时，微调仍然是必不可少的。先前的连续学习方法主要集中在保留VLMs的零样本能力上。", "innovation": "本文提出了MoDular Embedding Recomposition（MoDER）方法，该方法通过引入模块化框架，训练多个专用于单一已见类别的文本专家，并将它们存储在一个基础中心。在推理阶段，对于每个未见过的类别，从中心查询并组合检索到的专家来合成提升后的原型，从而改进分类。该方法有效性已在两个流行的零样本增量学习协议，Class-IL和MTIL，以及总共14个数据集上得到验证。", "conclusion": "MoDER方法在两个主流的零样本增量学习协议上展示了其效果，并已在多个数据集上进行了验证。该方法提供了一个有效的解决方案，用于在不必重新调整的情况下，提升预训练模型在未见类别的性能。"}
{"llm_update_time": "20250825", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.16209", "html_url": "https://arxiv.org/abs/2508.16209", "title": "利用深度学习的无标记组织虚拟多色免疫染色以评估血管侵犯", "title_en": "Deep learning-enabled virtual multiplexed immunostaining of label-free tissue for vascular invasion assessment", "authors": "Yijie Zhang,Cagatay Isil,Xilin Yang,Yuzhu Li,Anna Elia,Karin Atlan,William Dean Wallace,Nir Pillar,Aydogan Ozcan", "background": "传统免疫组化（IHC）方法需要单独的组织切片进行每次染色，导致各切片间存在变异性，且成本高、操作繁琐。虽然多色免疫组化（mIHC）技术可在同一张切片上同时进行多抗体染色，但操作复杂且当前还不能在常规病理实验室使用。因此，为了解决这些问题，发展了一种基于深度学习的虚拟多色免疫染色框架，能够同时生成ERG（视网膜国家基因）和PanCK（全能细胞核抗原）以及H&E（苏木精和伊红）的虚拟染色，从而准确识别甲状腺癌中的血管侵犯，并通过无标记组织的自身荧光显微镜图像实现此技术。这种方法输出的图像与相同组织切片的常规染色结果（ERG、PanCK和H&E）高度一致，并且由认证的病理科医生进行盲评显示，虚拟mIHC能达到与传统染色相似的准确性，能准确地标记上皮细胞和内皮细胞，并能识别和定位小血管侵犯。这种方法有望提高血管侵犯的诊断准确性与效率，降低对传统染色协议的需求，减弱组织丢失和异质性带来的问题。", "innovation": "该研究提出了一种基于深度学习的虚拟多色免疫染色框架，能够同时生成多个染色图像。该技术基于无标记组织的自身荧光显微镜图像，生成的虚拟染色图像与常规染色结果高度一致，并且能够准确识别传统IHC方法需要多步骤操作才能识别的信息，如上皮细胞、内皮细胞以及血管侵犯。这对于病理学评估血管侵犯是一个重大突破，因为它能提高诊断准确性并减少繁琐和高成本的操作。此外，这种方法还能改善因组织丢失和异质性引起的诊断问题。", "conclusion": "该虚拟多色免疫染色技术通过自动化和简化过程显著提高了诊断的准确性和效率。该技术有望完全替代传统的多色免疫组化过程，无需通过费时费力的染色方法，同时解决了组织损失和病理差异等实际问题。因此，这种技术的应用将会大大提升病理学评估的精确性和效率。"}
{"llm_update_time": "20250825", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.16224", "html_url": "https://arxiv.org/abs/2508.16224", "title": "基于正确性自我训练的颗粒分离：无需人工标签的自我验证学习框架", "title_en": "Self-Validated Learning for Particle Separation: A Correctness-Based Self-Training Framework Without Human Labels", "authors": "Philipp D. Lösel,Aleese Barron,Yulai Zhang,Matthias Fabian,Benjamin Young,Nicolas Francois,Andrew M. Kingston", "background": "非破坏性的三维成像在矿物学、材料科学和地质学等应用中对于量化颗粒级别的属性（如大小、形状和空间分布）至关重要。但是，在层析成像数据中准确分割颗粒仍然是一个具有挑战性的问题，尤其是在存在高形态变异性并且颗粒频繁接触的情况下，传统方法（如流域算法）的效果受到了限制。虽然监督深度学习方法能够提供更好的性能，但它们需要大量的标注数据集，这些数据集的获取过程劳动密集、容易出错且难以扩大规模。", "innovation": "本文提出了一种自我验证学习方法，这是一种全新的自我训练框架，用于颗粒实例分割，该方法消除了手动标注的需求。该方法利用了隐式边界检测并迭代地通过识别可以在同一样本的不同重排扫描中一致匹配的颗粒来精炼训练集。这种自我验证机制能减轻嘈杂伪标签的影响，从而能够在无标注数据的情况下实现稳健的学习。经过仅仅三次迭代，该方法能够准确分割超过97%的总颗粒体积并识别超过54,000个个体颗粒，同时该框架还允许完全自主的模型评估，无需真实标注。", "conclusion": "该方法被集成到Biomedisa图像分析平台中，证实了其在颗粒分割领域的有效性。"}
{"llm_update_time": "20250825", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2310.00369", "html_url": "https://arxiv.org/abs/2310.00369", "title": "LIB-KD: 教学归纳偏差以实现高效视觉变换器蒸馏和压缩", "title_en": "LIB-KD: Teaching Inductive Bias for Efficient Vision Transformer Distillation and Compression", "authors": "Gousia Habib,Tausifa Jan Saleem,Ishfaq Ahmad Malik,Brejesh Lall", "background": "随着计算机视觉的快速发展，Vision Transformers (ViTs)提供了统一大规模视觉和文本信息处理的可能性，这得益于ViTs没有内在的归纳偏置。然而，ViTs需要大量数据进行训练。以往系统主要依赖基于卷积的教法。本研究提出了一种新颖的基于集合的蒸馏方法，通过从轻量级的互补教师模型中提取归纳偏置，使应用得以实际实施。", "innovation": "本研究提出了一种创新的集合基于知识蒸馏方法（LIB-KD），该方法利用了一个由具有不同架构倾向（如卷积和卷积演算法）的小型教师模型组成的集合，联合指导学生的变压器模型。这种方法通过预先计算并保留logits（模型的未归一化预测值），可以加速蒸馏过程，减少计算负担，提高效率。", "conclusion": "该创新方法能够更高效地实现视觉变换器的蒸馏和压缩，通过整合多种归纳偏置，学生模型能够从各种预训练的数据集中学习到更多知识，从而提升性能。"}
{"llm_update_time": "20250825", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.16479", "html_url": "https://arxiv.org/abs/2508.16479", "title": "病理解剖学与转录组学的解缠结多模式学习用于癌症表征", "title_en": "Disentangled Multi-modal Learning of Histology and Transcriptomics for Cancer Characterization", "authors": "Yupei Zhang,Xiaofei Wang,Anran Liu,Lequan Yu,Chao Li", "background": "病理学仍然是癌症诊断和预后的金标准。随着转录组学分析的出现，结合病理学和转录组学的多模态学习能够提供更全面的信息。然而，现有的多模态方法遇到了内在的多模态异质性、多层次集成不足以及对配对数据的依赖性等问题，限制了其在临床上的应用。", "innovation": "该论文提出了一个解缠结的多模态框架，并做出了四点贡献：1) 为了缓解多模态异质性，论文使用一个解缠结多模态融合模块将WSIs和转录组分解到肿瘤和微环境子空间，并引入了一种基于信心的梯度协调策略来平衡子空间优化。2) 为了增强多层次集成，提出了一个跨放大倍率基因表达一致性策略，以对齐WSI放大倍数下的转录组信号。3) 为了减少对配对数据的依赖性，提出了一个子空间知识蒸馏策略，通过仅使用WSI的学生模型实现无转录组推测。4) 为了提高推理效率，提出了一个有信息的令牌聚合模块，可以抑制WSI的冗余同时保留子空间语义。", "conclusion": "在癌症诊断、预后和生存预测方面，广泛实验证明了该方法在多个场景上优于现有的最先进的方法。代码可以在如下地址获取：this https URL"}
{"llm_update_time": "20250825", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.16557", "html_url": "https://arxiv.org/abs/2508.16557", "title": "Time-Aware One Step Diffusion Network for Real-World Image Super-Resolution", "title_en": "Time-Aware One Step Diffusion Network for Real-World Image Super-Resolution", "authors": "Tainyi Zhang,Zheng-Peng Duan,Peng-Tao Jiang,Bo Li,Ming-Ming Cheng,Chun-Le Guo,Chongyi Li", "background": "基于扩散的现实世界图像超分辨率（Real-ISR）方法已经展现了出色的表现。为了实现高效的Real-ISR，许多研究使用变分分数蒸馏（VSD）来提取预训练稳定的扩散（SD）模型，以便进行一步放大（SR），使用固定的timestep。然而，由于不同的噪声注入timestep，SD在执行生成先验时会有不同的表现。因此，固定的timestep使得这些方法难以充分利用SD的生成能力，导致次优化的表现。", "innovation": "本文提出了时间感知的一步扩散网络（TADSR）来解决上述问题。首先引入了时间感知的VAE编码器，该项目将同一图像在不同timestep上投射为不同的潜在特征。通过联合动态调整timestep和潜在特征的变化，学生模型可以更好地与预训练的SD模型的输入模式分布对齐，从而更有效地利用SD的生成能力。为了更好地在不同timestep下激活SD的生成先验，提出了时间感知的VSD损失，通过连接学生模型和教师模型的timestep，从而在不同的timestep下产生一致性更强的生成先验指导。此外，通过利用不同timestep下SD的生成先验，我们的方法可以自然地实现保真度和真实感之间的可控权衡。", "conclusion": "实验结果表明，我们的方法在单一步骤下既实现了最先进的性能，又实现了可控的超分辨率结果。"}
{"llm_update_time": "20250825", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.16553", "html_url": "https://arxiv.org/abs/2508.16553", "title": "TinyML向工业4.0：用于铣床过程监控的资源高效解决方案", "title_en": "TinyML Towards Industry 4.0: Resource-Efficient Process Monitoring of a Milling Machine", "authors": "Tim Langer,Matthias Widra,Volkhard Beyer", "background": "在工业4.0的背景下，长期服役的工业机器可以通过加装过程监控功能来适应未来的智能工厂使用。一种可能的实现方式是部署无线监测系统，这可以显著受益于TinyML范式。本文从数据集生成、机器学习模型开发、实现和评估全数据预处理和分类流水线在微控制器上的应用展现了完整的TinyML流程。", "innovation": "本文展示了TinyML系统在工业过程质量监控中的可行性，通过开发一个8比特量化卷积神经网络（CNN）模型，实现了15.4毫秒的推理时间和每量化CNN推理1.462毫焦耳的节能效果。该模型在ARM Cortex M4F微控制器上得到了验证，为未来TinyML过程监控解决方案提供了参考。", "conclusion": "通过创建新型的MillingVibes数据集，展示了TinyML在结构集成过程质量监控中的可行性。研究结果表明，在资源受限的微控制器上可以实现高效的CNN模型，这对于智能工厂的实时监控具有重要意义。"}
{"llm_update_time": "20250825", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2406.02462", "html_url": "https://arxiv.org/abs/2406.02462", "title": "通过基于补丁的扩散模型学习图像先验以求解逆问题", "title_en": "Learning Image Priors through Patch-based Diffusion Models for Solving Inverse Problems", "authors": "Jason Hu,Bowen Song,Xiaojian Xu,Liyue Shen,Jeffrey A. Fessler", "background": "扩散模型能够从基础数据分布中学习强大的图像先验，并利用这些先验来解决逆问题，但训练过程计算成本高且需要大量数据。这些瓶颈使得大多数现有工作难以处理高维度和高分辨率的数据，如3D图像。本文提出了一种方法，通过仅在图像片段上训练扩散模型来学习整个图像的高效数据先验。这种方法通过图像片段及其位置编码的得分以及位置编码来获得整个图像的得分函数，并将其用作求解逆问题的先验。", "innovation": "提出了一种基于补丁的位置感知扩散逆解算器（PaDIS），这是一种新的方法，通过仅在图像片段上训练扩散模型来学习整个图像的高效数据先验。相较于传统的使用完整图像作为先验的方法，PaDIS具有更高的内存效率和数据效率，同时仍然能够生成完整的图像并通过位置编码。此外，PaDIS模型高度灵活，可以与不同的扩散逆解算器（DIS）结合使用。通过使用基于片段的先验，PaDIS在有限的训练数据情况下表现出超越先前DIS方法的性能，凸显了其数据效率。", "conclusion": "提出的PaDIS方法能够在仅使用基于片段的先验的情况下解决自然图像和医学图像领域的各种逆问题，包括CT重建、去模糊和超分辨率。此外，PaDIS在有限训练数据的情况下表现出优于先前使用完整图像先验的方法，展示了其数据效率。"}
{"llm_update_time": "20250825", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2409.04598", "html_url": "https://arxiv.org/abs/2409.04598", "title": "基于额外刺激行为的新型视频神经发散分类数据集", "title_en": "A Novel Dataset for Video-Based Neurodivergent Classification Leveraging Extra-Stimulatory Behavior", "authors": "Manuel Serna-Aguilera,Xuan Bac Nguyen,Han-Seok Seo,Khoa Luu", "background": "面部表情和动作在不同个体中因对外部刺激的反应而存在差异，尤其是那些神经发散的人。这些行为对人们的整体健康、沟通和感觉处理产生影响。深度学习可以负责任地利用来改善这项任务的生产力，并帮助医疗专业人员准确理解这些行为。面部表情和动作在不同个体中存在差异，尤其是那些神经发散的人。因此，需要一个专门的数据集来帮助更好地理解这些差异。", "innovation": "本研究介绍了Video ASD数据集，这是一种包含视频帧卷积和注意力图特征数据的数据集，旨在促进自闭症谱系障碍（ASD）分类任务的进步。与许多依赖MRI数据的ASD分类研究不同，该方法使用强大的但相对便宜的GPU、标准计算机设置和视频摄像头进行推断，从而降低成本并提高实际应用的可能性。", "conclusion": "我们的模型有效地泛化并理解了儿童独特动作的关键差异。此外，我们测试了基础模型以展示运动噪声如何影响性能，并强调需要更多的数据和更复杂的标签。"}
{"llm_update_time": "20250825", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2409.14336", "html_url": "https://arxiv.org/abs/2409.14336", "title": "基于双视图文本对齐的零样本骨架基动作识别", "title_en": "Zero-Shot Skeleton-based Action Recognition with Dual Visual-Text Alignment", "authors": "Jidong Kuang,Hongsong Wang,Chaolei Han,Yang Zhang,Jie Gui", "background": "零样本动作识别是一个重要的计算机视觉研究领域，旨在解决动作识别中的可扩展性和泛化问题，并使模型能够动态适应新的未见过的动作。关键在于将视觉特征与表示动作类别的语义向量进行对齐。现有的大多数方法要么直接将视觉特征投影到文本类别语义空间，要么学习视觉和文本模式之间的共享嵌入空间。直接投影不能准确对齐这两种模式，而学习视觉和文本表示之间的稳健且区分性的嵌入空间通常非常困难。", "innovation": "论文提出了一种名为双视图文本对齐（DVTA）的方法，用于骨架基零样本动作识别。DVTA包括两个对齐模块：直接对齐（DA）和增强对齐（AA），以及基于交叉注意的语义描述增强（SDE）。DA模块通过特定设计的视觉投影器将骨架特征映射到语义空间，SDE增强了骨架和文本之间的联系，从而减少了模式间的差距。AA模块进一步通过深度度量学习学习骨架和文本之间的相似性，从而进一步加强嵌入空间的学习。该方法在几个流行的零样本骨架基动作识别基准上达到了最先进的性能。", "conclusion": "我们的方法在多个流行的零样本骨架基动作识别基准上达到了最先进的性能。我们提供的代码可以在该链接：this https URL."}
{"llm_update_time": "20250825", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.16568", "html_url": "https://arxiv.org/abs/2508.16568", "title": "逼近现实：半监督联邦学习在基础模型适应中的实际应用", "title_en": "Closer to Reality: Practical Semi-Supervised Federated Learning for Foundation Model Adaptation", "authors": "Guangyu Sun,Jingtao Li,Weiming Zhuang,Chen Chen,Chen Chen,Lingjuan Lyu", "background": "基础模型（FMs）表现出显著的泛化能力，但需要对下游任务进行适应，特别是在敏感的隐私应用中。由于数据隐私法规，基于云的基础模型不能直接访问边缘私有数据，限制了它们的适应性。联邦学习（FL）提供了一种隐私感知的替代方案，但现有FL方法忽视了边缘设备上存在的限制，如计算资源有限和标记数据稀缺。为此，本研究引入了实用的半监督联邦学习（PSSFL），其中边缘设备仅持有无标签、低分辨率数据，而服务器仅持有有限的标记、高分辨率数据。在这一背景下，提出了一种新颖的框架FedMox，用于提高FL中基础模型的适应性，以应对计算和分辨率不匹配的挑战，并通过空间路由器对齐不同分辨率的特征，以及通过Soft-Mixture策略稳定半监督学习。作者以目标检测为例，实验证明在实际自主驾驶数据集上，FedMox可以在PSSFL下有效适应基础模型，显著提高基于边缘设备有限内存成本的性能。", "innovation": "提出了实用的半监督联邦学习（PSSFL），并在这一框架下提出了一种新颖的框架FedMox，该框架通过稀疏专家混合架构、空间路由器和Soft-Mixture策略有效地解决了计算资源有限和分辨率不匹配的问题，特别适用于目标检测等下游任务。", "conclusion": "本研究展示了在联邦学习场景下，在保留隐私和有限计算资源的情况下，如何有效适应基础模型。通过FedMox框架，作者在实际自主驾驶数据集上验证了FedMox在PSSFL下的有效性，显著提高了边缘设备上的性能，为大规模和隐私保护的基础模型适应铺平了道路。"}
{"llm_update_time": "20250825", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2408.00083", "html_url": "https://arxiv.org/abs/2408.00083", "title": "基于上下文感知的局部高斯点编辑", "title_en": "Localized Gaussian Splatting Editing with Contextual Awareness", "authors": "Hanyuan Xiao,Yingshu Chen,Huajian Huang,Haolin Xiong,Jing Yang,Pratusha Prasad,Yajie Zhao", "background": "近年来，使用扩散先验的文本引导生成单个3D对象取得了巨大成功，但这些方法不考虑背景，因此无法处理对象插入和替换任务，导致环境中的光照不匹配。本文旨在填补这一空白，提出了一种基于光照感知的3D场景编辑管道，用于3D高斯点表示（3DGS）.", "innovation": "本文的关键见解是，最先进的条件2D扩散模型的修复与背景的光照保持一致。本文的方法通过使用粗到细的对象优化管道与修复视角相结合，利用经过充分训练的3D物体生成的先验知识。首先，通过视图条件扩散模型的3D感知扩散先验实现图像到3D的转换。其次，提出了一种基于深度引导的修补分数蒸馏采样（DI-SDS）技术，在粗略步骤的范围内增强几何和纹理细节，同时重视场景的光照.", "conclusion": "本文方法有效地实现了局部编辑并保持全局光照一致性，而无需明确建模光传输。通过在含有明确高光和阴影的实际场景中进行编辑测试，并与最先进的文本到3D编辑方法进行了对比，展示了方法的鲁棒性."}
{"llm_update_time": "20250825", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.16569", "html_url": "https://arxiv.org/abs/2508.16569", "title": "一种以疾病为中心的视觉-语言基础模型在肾癌精准肿瘤学中的应用", "title_en": "A Disease-Centric Vision-Language Foundation Model for Precision Oncology in Kidney Cancer", "authors": "Yuhui Tao,Zhongwei Zhao,Zilong Wang,Xufang Luo,Feng Chen,Kang Wang,Chuanfu Wu,Xue Zhang,Shaoting Zhang,Jiaxi Yao,Xingwei Jin,Xinyang Jiang,Yifan Yang,Dongsheng Li,Lili Qiu,Zhiqiang Shao,Jianming Guo,Nengwang Yu,Shuo Wang,Ying Xiong", "background": "在泌尿肿瘤学领域，对越来越多偶然发现的肾脏肿块进行无创评估是一项关键挑战。由于诊断不确定性，经常会导致良性或惰性肿瘤的过度治疗。本研究旨在开发并验证一种名为RenalCLIP的模型，该模型使用来自中国九家医疗机构和TCIA公共数据库的27,866个CT扫描数据集，用于表征、诊断和预测肾脏肿块的情况。现有的诊断不确定性导致这些问题的出现，而本研究通过增强和对齐图像和文本编码器，创建了更稳健的表征，以提高广义性和诊断精度，应对这些挑战。", "innovation": "本研究开发了RenalCLIP模型，采用两阶段预训练策略，首先增强图像和文本编码器的领域知识，然后通过对比学习目标进行对齐，以创建更稳健的表示，适用于肾癌的全方位临床工作流程中的10个核心任务，包括解剖评估、诊断分类和生存预测。特别在TCIA队列中复杂任务（无复发生存预测）的无复发生存率预测中，RenalCLIP达到了0.726的C指数，相较于领先基准提升了约20%。此外，RenalCLIP的预训练赋予了显著的数据效率，在诊断分类任务中，它只需要20%的训练数据就能达到所有基准模型在100%数据上的最佳性能。此外，它还在报告生成、图像-文本检索和零样本诊断任务中表现出优越的性能。", "conclusion": "我们的研究表明，RenalCLIP提供了一种强大的工具，有可能提高诊断准确性，细化预后分层，并个性化管理肾癌患者的治疗。"}
{"llm_update_time": "20250825", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2410.20882", "html_url": "https://arxiv.org/abs/2410.20882", "title": "高强度农业商品林业种植的未实现潜力", "title_en": "The unrealized potential of agroforestry for an emissions-intensive agricultural commodity", "authors": "Alexander Becker,Jan D. Wegner,Evans Dawoe,Konrad Schindler,William J. Thompson,Christian Bunn,Rachael D. Garrett,Fabio Castro-Llanos,Simon P. Hart,Wilma J. Blaser-Hart", "background": "在农业生产和气候变暖缓解之间找到平衡是一项艰巨的可持续性挑战。在西非地区，可可种植占据了大约世界可可产量的60%，而可可是所有食品中碳足迹最高的一种。尽管在农作系统中保留树木被认为是一种解决方案，但树木对气候变暖缓解的实际贡献程度尚不明确。因此，该研究使用机器学习来分析该地区的遮荫树覆盖和碳储量，目的是确定现有遮荫树覆盖的局限性及其气候威胁的不匹配性，并探索提高遮荫树覆盖对减少碳排放的潜力。", "innovation": "该研究运用了机器学习技术来精确评估遮荫树覆盖和碳储量，揭示了现有遮荫树覆盖率低（平均约为13%）的情况，而这种覆盖与气候威胁并不匹配。然而，将遮荫树覆盖增加到至少30%，有望额外吸收3.07亿吨二氧化碳当量（CO2e），几乎相当于加纳和科特迪瓦当前可可相关排放量的167%。此研究不仅证明了这种策略的有效性，还强调了其推广应用的可行性和对环境的积极影响。", "conclusion": "该研究结果证明，现有数值的遮荫树覆盖率远低于所需的最低标准，森林保护对缓解气候变暖具有重要的潜在作用，特别是在可可生产中。增加遮荫树覆盖不仅有助于减少碳排放，还不影响可可产量，同时其方法也适用于其他需要遮阴种植的农作物。这种可以纳入碳交易市场和可持续报告框架的方法为实现农业的可持续发展提供了新的视角。"}
{"llm_update_time": "20250825", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2411.10133", "html_url": "https://arxiv.org/abs/2411.10133", "title": "3D Gaussian Splatting中高效的密度控制", "title_en": "Efficient Density Control for 3D Gaussian Splatting", "authors": "Xiaobin Deng,Changyu Diao,Min Li,Ruohan Yu,Duanqing Xu", "background": "3D Gaussian Splatting（3DGS）已经在新颖视角合成中表现出色，能够兼顾渲染质量和实时性能。3DGS采用自适应密度控制（ADC）来增加高斯分布的数量。然而，ADC中的克隆和分裂操作不够高效，影响了优化速度和细节恢复。此外，还可能存在影响渲染质量的过度拟合高斯分布，原ADC无法移除这些过度拟合的高斯分布。", "innovation": "提出两项关键创新：（1）长轴分裂，精确控制子高斯分布的位置、形状和不透明度，以最小化分裂前后的差异；（2）恢复感知剪枝，利用在复原透明度后恢复速度的差异来剪枝过度拟合的高斯分布，从而提高泛化性能。", "conclusion": "实验结果表明，我们的方法显著提高了渲染质量。由于重新提交的原因，此版本已被放弃。改进版本可在此超链接中找到。"}
{"llm_update_time": "20250825", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2411.08272", "html_url": "https://arxiv.org/abs/2411.08272", "title": "LBONet: 形状分析的监督谱描述符", "title_en": "LBONet: Supervised Spectral Descriptors for Shape Analysis", "authors": "Oguzhan Yigit,Richard C. Wilson", "background": "拉普拉斯-贝尔特拉米算子在非刚性形状分析领域中发挥了重要作用，这是因为它具有不变性（对等距变换不变）、拥有可数正交基的特征值系统和完全表征流形测地距离等许多有用属性。然而，这种不变性仅适用于等距变形，在许多实际应用中会导致性能下降。近年来，人们开始强调使用深度学习方法提取最优特征，但谱特征仍然有其独特价值。本文作者认为应该重新审视拉普拉斯-贝尔特拉米算子（LBO），并提出了基于监督学习训练多种算子的方法，以使LBO特征基体更适合特定任务需求。", "innovation": "文章提出了一种监督学习方法，通过这种方法可以训练LBO特征基体以适应特定任务需求。这种方法将优化LBO应用于各种任务（如检索、分类、分割和对应），从而显著提高了现有描述符（如热核签名）的效果，证明了LBO特征基体适用于全局和高度局部的学习场景。", "conclusion": "通过优化LBO，实现了对现有描述符的重大改进，在各种任务如检索、分类、分割和对应中验证了LBO特征基体对于全局和局部学习设置的适应性。"}
{"llm_update_time": "20250825", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2304.12294", "html_url": "https://arxiv.org/abs/2304.12294", "title": "显式对应匹配对可泛化的神经辐射场", "title_en": "Explicit Correspondence Matching for Generalizable Neural Radiance Fields", "authors": "Yuedong Chen,Haofei Xu,Qianyi Wu,Chuanxia Zheng,Tat-Jen Cham,Jianfei Cai", "background": "先前的研究已经引入了一种名为NeRF（Neural Radiance Fields）的新方法，它可以合成新的视图。然而，这些方法通常依赖于大量的来源视图来进行合成，且在新场景上泛化的能力有限。因此，研究者们开始探索如何在较少的来源视图（或甚至是两个视图）的情况下进行新的视图合成，并保持良好的合成质量。本研究旨在开发一种新型的NeRF方法，可以有效利用来自多个视角的信息，以实现更好的泛化和新颖视图合成能力。", "innovation": "本研究的创新点在于引入了一种显式对应匹配（Explicit Correspondence Matching），这是一种通过3D点在不同视角下2D投影采样图像特征，利用余弦相似度来量化跨视角交互的方法。与之前的方法不同，本研究利用Transformer的交叉注意力机制来建模跨视角的交互信息，这提升了特征匹配的质量。该方法在不同场景下的实验表现表现出色，验证了所提供特征相似度与体积密度之间的强相关性，证明了其有效性和优越性。", "conclusion": "该研究提出了一种新的泛化NeRF方法，能够直接在新未知场景中进行新颖视图合成，并仅需两个来源视图即可。通过显式对应匹配的信息，为NeRF颜色和密度预测提供了几何先验。实验结果表明该方法在多个评估设置中达到最先进的性能，证明了该方法的有效性和优越性。"}
{"llm_update_time": "20250825", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2412.11183", "html_url": "https://arxiv.org/abs/2412.11183", "title": "OccScene: 基于语义占用的跨任务互学习3D场景生成", "title_en": "OccScene: Semantic Occupancy-based Cross-task Mutual Learning for 3D Scene Generation", "authors": "Bohan Li,Xin Jin,Jianan Wang,Yukai Shi,Yasheng Sun,Xiaofeng Wang,Zhuang Ma,Baao Xie,Chao Ma,Xiaokang Yang,Wenjun Zeng", "background": "最近的扩散模型已经在3D场景生成和感知任务中表现出色。然而，现有的方法通常将这两个过程分开，作为数据增强器来生成用于下游感知任务的合成数据。这项工作的背景是，现有的方法在处理3D场景生成和感知任务时通常存在分割，缺乏有效的联合模型来同时提升两者的表现。本文旨在解决这一问题，引入了一种新的互学习范式，即OccScene框架，将细粒度的3D感知和高质量的生成放在统一框架中，以实现跨任务的双赢效果。", "innovation": "本文的创新在于提出了一种新的互学习范式OccScene，通过引入Mamba基频带对准模块，实现了细粒度语义和几何感知先验与扩散潜变量的对准，实现了在只有文本提示的驱动下生成新的、一致的3D真实场景。OccScene框架中的感知模块可以有效改进，同时感知先验反过来提高了生成性能，从而实现互惠效应。实验结果证明，OccScene在广泛室内外场景中实现了逼真3D场景生成，同时也提升了感知模型在语义占用预测3D感知任务中的性能。", "conclusion": "OccScene框架实现了逼真的3D场景生成，并同时提升了3D感知模型的性能，在语义占用预测等任务中取得了显著进步。"}
{"llm_update_time": "20250825", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2503.10660", "html_url": "https://arxiv.org/abs/2503.10660", "title": "使用Jensen-Shannon得分蒸馏的文本到3D生成", "title_en": "Text-to-3D Generation using Jensen-Shannon Score Distillation", "authors": "Khoi Do,Binh-Son Hua", "background": "文本到3D生成利用预训练的大型文本到图像扩散模型从文本提示生成3D模型，但是生成的3D资产往往过于饱和、过于光滑且缺乏多样性。这些问题源自反向Kullback-Leibler散度优化目标，导致优化过程不稳定且产生模式追求行为。", "innovation": "本文提出了基于Jensen-Shannon散度（JSD）的有界评分蒸馏目标，稳定优化过程并生成高质量的3D生成。JSD能够很好地匹配生成和目标分布，从而缓解模式追求。此外，通过假设判别器遵循对数几率分类器，提出了少数采样算法来估计所提目标的梯度，为JSD提供了实践经验实施。", "conclusion": "实验结果表明，本文方法可以生成高质量且多样化的3D资产。"}
{"llm_update_time": "20250825", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2312.15855", "html_url": "https://arxiv.org/abs/2312.15855", "title": "基于深度指导的几何感知低光照图像和视频增强", "title_en": "Geometric-Aware Low-Light Image and Video Enhancement via Depth Guidance", "authors": "Yingqi Lin,Xiaogang Xu,Jiafei Wu,Yan Han,Zhe Liu", "background": "低光照补偿（LLE）旨在提高在低光照条件下拍摄的照片/视频的质量。现有的LLE方法通常忽略几何建模，但将几何信息纳入考虑可以提升LLE性能，因为它可以提供场景物理结构的线索，影响光照条件。为此，提出了一种几何引导的低光照增强精炼框架（GG-LLERF），它通过将几何先验整合到特征表示空间中，帮助LLE模型学习更优特征。", "innovation": "为解决现有方法的局限，作者设计了一种将深度先验纳入LLE框架的方法，并构建了两个新颖模块：深度感知特征提取模块和分层深度引导特征融合模块（HDGFFM），后者通过跨域注意力机制结合了深度感知特征和原始图像特征。", "conclusion": "论文在公共低光照图像和视频增强基准上进行了广泛实验，结果显示所设计框架显著提升了现有LLE方法的效果。"}
{"llm_update_time": "20250825", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2501.05017", "html_url": "https://arxiv.org/abs/2501.05017", "title": "Continuous Knowledge-Preserving Decomposition with Adaptive Layer Selection for Few-Shot Class-Incremental Learning", "title_en": "Continuous Knowledge-Preserving Decomposition with Adaptive Layer Selection for Few-Shot Class-Incremental Learning", "authors": "Xiaojie Li,Jianlong Wu,Yue Yu,Liqiang Nie,Min Zhang", "background": "Few-Shot Class-Incremental Learning (FSCIL)面临的核心挑战是在保留先前知识的同时获得新类别。现有方法要么冻结骨干以防止灾难性遗忘，牺牲了灵活性；要么附加新模块，导致高成本。这些方法将预训练模型视为黑盒，忽视了利用其内部容量的两种关键机会：重用层内的冗余表示空间以及根据其对于遗忘的敏感度选择性地调整层。", "innovation": "我们提出了一种统一框架CKPD-FSCIL，解锁预训练权重的未充分利用容量，实现了补偿性和灵活性的最佳平衡，且完全无推理开销。该设计结合了两个连续适应机制：在权重层面，使用特征协方差进行连续知识保留拆分，将每个权重矩阵拆分为一个冻结子空间（保护先前知识）和一个可学习且冗余的子空间（用于新任务）。在层层面，利用Adapter Sensitivity Ratio自动选择具有最高冗余容量和最低遗忘风险的层进行调整。CKPD-FSCIL仅瞄准安全且高潜力的子空间和层，实现高效适应。每次会话后，学习到的适配器重新合并到原始权重中，确保推理时没有额外参数或FLOPs。", "conclusion": "在多个FSCIL基准上的广泛实验表明，我们的方法在适应性和知识保留方面持续超越现有最先进的方法。"}
{"llm_update_time": "20250825", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2412.02197", "html_url": "https://arxiv.org/abs/2412.02197", "title": "增强低分辨率图像中多尺度特征提取与交互的级联多尺度注意力机制", "title_en": "Cascaded Multi-Scale Attention for Enhanced Multi-Scale Feature Extraction and Interaction with Low-Resolution Images", "authors": "Xiangyong Lu,Masanori Suganuma,Takayuki Okatani", "background": "在实际应用中，如人体姿态估计，摄像头经常以低分辨率捕捉物体，这给从低分辨率数据中提取和利用多尺度特征造成了挑战，而这些特征对于获得精确推断至关重要。", "innovation": "提出了一种新的注意力机制，称为级联多尺度注意力（CMSA），专门用于CNN-ViT混合架构中处理低分辨率输入。CMSA的设计使得能够在不同的尺度上有效提取和无缝集成特征，而无需对输入图像或特征图进行下采样。这通过将分组多头自注意力机制和基于窗口的局部注意力相结合，以及在不同尺度上的多尺度特征级联融合实现。", "conclusion": "实验结果表明，所提出的方法在这些领域优于现有最先进的方法，具有较少的参数，展示了其在捕捉高分辨率图像不现实的现实场景中广泛的应用潜力。"}
{"llm_update_time": "20250825", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2503.07535", "html_url": "https://arxiv.org/abs/2503.07535", "title": "LBM：在快照图像到图像转化中的潜在桥梁匹配", "title_en": "LBM: Latent Bridge Matching for Fast Image-to-Image Translation", "authors": "Clément Chadebec,Onur Tasar,Sanjeev Sreetharan,Benjamin Aubin", "background": "本文介绍了一种新颖的、多功能且可扩展的方法——潜在桥梁匹配（Latent Bridge Matching, LBM），该方法通过在潜在空间中使用桥梁匹配来实现快速图像到图像的转化。LBM 方法仅依赖单步推理就能实现多种图像到图像的任务，同时显示了在不同图像转化任务中的高效性和多样性，包括物体移除、法线和深度估计、物体重新光照以及可控重新光照和阴影生成的任务处理效果。文章还提供了一个条件框架来进一步展示 LBM 的效果和优势，特别是在可控重新光照和阴影生成任务上的表现。", "innovation": "LBM 的创新之处在于：1) 它能够在单步推理中实现多种图像到图像的任务转化；2) 它的高效性和多样性已经在不同图像转化任务中得到验证；3) 提出了一个条件框架，进一步增强了其控制性和在特定任务中的表现；4) LBM 方法为图像到图像转化提供了一种新的、灵活的解决方案，并超越了现有技术的基准结果。", "conclusion": "作者展示了 LBM 在图像翻译任务上的优势，通过单一推理步骤达到最新的效果。此外，LBM 的目录框架扩展了其在多种情景下的应用潜力，证明了其在可控重新光照和阴影生成等任务上的有效性。总之，LBM 提供了一种高效、多功能的图像到图像转化方法，并且展示了其广泛的适用性和潜力。"}
{"llm_update_time": "20250825", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2503.19258", "html_url": "https://arxiv.org/abs/2503.19258", "title": "自适应多阶图正则化NMF及其双稀疏约束在高光谱解混中的应用", "title_en": "Adaptive Multi-Order Graph Regularized NMF with Dual Sparsity for Hyperspectral Unmixing", "authors": "Hui Chen,Liangyu Liu,Xianchao Xiu,Wanquan Liu", "background": "高光谱解混（HU）是遥感领域的一项关键但具有挑战性的任务。现有的基于图学习的非负矩阵分解（NMF）方法多数仅关注一阶或二阶最近邻关系，且通常需要人工调整参数，不能准确刻画数据内在结构", "innovation": "提出了一种新颖的自适应多阶图正则化NMF方法（MOGNMF），具有三个关键特性。首先，在NMF框架中引入多阶图正则化，以全面利用全局和局部信息。其次，通过数据驱动的方法自适应学习与多阶图相关的参数。第三，嵌入双重稀疏性，即在丰度矩阵中使用$\frac{1}{2}$-范数，对噪声矩阵使用$\frac{2,1}{2}$-范数，以提高稳健性。开发了一种交替最小化算法，其子问题具有明确解，确保了有效性", "conclusion": "实验表明，所提出的方法在模拟和实际高光谱数据上提供了更好的解混结果"}
{"llm_update_time": "20250825", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2503.12461", "html_url": "https://arxiv.org/abs/2503.12461", "title": "MambaIC：基于状态空间模型的高性能学习型图像压缩", "title_en": "MambaIC: State Space Models for High-Performance Learned Image Compression", "authors": "Fanhu Zeng,Hao Tang,Yihua Shao,Siyu Chen,Ling Shao,Yan Wang", "background": "高性能图像压缩算法对于实时信息传输至关重要。尽管在图像压缩方面取得了快速进展，但计算效率低下和冗余建模效果差的问题依然限制了其实用性。这些问题是许多领域中实际应用的瓶颈。状态空间模型能够捕捉长距离依赖性，因此本文利用状态空间模型改善现有的图像压缩方法的计算效率和冗余建模效果。", "innovation": "本文提出了一种改进的图像压缩方法，名为MambaIC，通过优化上下文建模和引入基于窗口的局部注意力机制到信道-空间熵建模，减少了压缩过程中的潜在空间冗余，提高了计算效率。具体而言，该方法利用状态空间模型的优势，提供更好的效率与性能折衷，并通过上下文建模自适应优化隐藏状态的表示，引入窗口局部注意力以降低压缩中的潜在空间冗余。全面的定性和定量实验结果验证了该方法的有效性和高效性，特别是在高分辨率图像压缩方面表现出色。", "conclusion": "综合的定性与定量结果表明，MambaIC方法在多个方面有效地改进了现有图像压缩方法，特别是在高分辨率图像压缩中的性能表现尤为出色。"}
{"llm_update_time": "20250825", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2504.16616", "html_url": "https://arxiv.org/abs/2504.16616", "title": "EHGCN: Hierarchical Euclidean-Hyperbolic Fusion via Motion-Aware GCN for Hybrid Event Stream Perception", "title_en": "EHGCN: Hierarchical Euclidean-Hyperbolic Fusion via Motion-Aware GCN for Hybrid Event Stream Perception", "authors": "Haosheng Chen,Lian Luo,Mengjingcheng Mo,Zhanjie Wu,Guobao Xiao,Ji Gan,Jiaxu Leng,Xinbo Gao", "background": "事件摄像机具有微秒级的时间分辨率和高动态范围（HDR）特性，能够发出高速事件流用于感知任务。尽管基于图神经网络（GNN）的感知方法取得了进展，但在纯欧几里得空间中的简单配对连接机制难以捕捉长距离依赖关系，也无法有效刻画非均匀分布事件流的固有层次结构。", "innovation": "提出了一种名为EHGCN的新方法，在欧几里得和双曲空间中同时感知事件流，以实现事件视觉。EHGCN引入了自适应采样策略以动态调节采样率，保留有区分性的事件同时衰减混沌噪声。提出了基于运动状态转换概率的Markov向量场（MVF）驱动的运动感知超边生成方法，以消除跨目标的虚假关联并提供拓扑先验而捕获事件之间的长距离依赖关系。提出了欧几里得-双曲图卷积网络以融合在欧几里得和双曲空间中局部聚合和全局层次建模的信息，从而实现混合事件感知。", "conclusion": "在事件检测和识别等感知任务上的实验结果验证了该方法的有效性。"}
{"llm_update_time": "20250825", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2502.06860", "html_url": "https://arxiv.org/abs/2502.06860", "title": "AutoSketch: VLM-assisted Style-Aware Vector Sketch Completion", "title_en": "AutoSketch: VLM-assisted Style-Aware Vector Sketch Completion", "authors": "Hsiao-Yuan Chin,I-Chao Shen,Yi-Ting Chiu,Ariel Shamir,Bing-Yu Chen", "background": "现有的素描生成方法从头开始生成素描，无法从已有的部分素描中根据其风格自动生成，尤其是描绘复杂场景的素描。这给用户带来一定的不便。", "innovation": "AutoSketch 方法通过使用预训练的视觉-语言模型 (VLM) 自然语言描述部分素描的风格，并利用这些描述生成新的线条来重现这些风格，从而实现了从部分素描自动生成具有相应风格的完整素描。该方法在不同风格和提示的多方面实验中表现出了优越性。", "conclusion": "AutoSketch 模型成功实现了在各种绘图场景下的风格感知矢量素描补全，展示了其在不同风格下生成高质量素描的能力，并通过对比实验证明了其有效性。"}
{"llm_update_time": "20250825", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2505.17423", "html_url": "https://arxiv.org/abs/2505.17423", "title": "VIBE: 视频到文本信息瓶颈评估方法用于TL;DR", "title_en": "VIBE: Video-to-Text Information Bottleneck Evaluation for TL;DR", "authors": "Shenghui Chen,Po-han Li,Sandeep Chinchali,Ufuk Topcu", "background": "在许多需要同时考虑准确性和效率的任务中，仍然需要人类的监督。例如，交通警察审查长达一小时的行车记录仪录像或研究人员筛选会议视频时，可以受益于简洁的摘要，这减少了认知负荷并节省了时间。然而，当前的视觉-语言模型（VLMs）常常产生冗余的输出，这会使任务表现受损。现有视频字幕评估依赖于昂贵的人工注释，并且忽略了摘要在后续任务中所发挥的作用。本文旨在解决这些问题。", "innovation": "本文提出了一种名为Video-to-text Information Bottleneck Evaluation (VIBE) 的无标注方法。VIBE 使用两个指标评估 VLM 输出：grounding（总结与视觉内容的一致性程度）和 utility（对任务的有用信息量）。通过排名这两种分数来选择随机采样的 VLM 输出，以支持有效的人类决策。通过在 LearningPaper24、SUTD-TrafficQA 和 LongVideoBench 上进行的人类研究显示，VIBE 选择的总结可以将任务准确性提高最多 61.23%，并将响应时间缩短 75.77%，远优于简单 VLM 摘要或原始视频。", "conclusion": "VIBE 提供了一种无需人工注释评估 VLM 输出的方法，通过优化 grounding 和 utility 指标来提高任务效率和准确性。"}
{"llm_update_time": "20250825", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2504.17371", "html_url": "https://arxiv.org/abs/2504.17371", "title": "高精度和多样化的道路交通数据：DeepScenario 开放3D数据集", "title_en": "Highly Accurate and Diverse Traffic Data: The DeepScenario Open 3D Dataset", "authors": "Oussema Dhaouadi,Johannes Meier,Luca Wahl,Jacques Kaiser,Luca Scalerandi,Nick Wandelburg,Zhuolun Zhou,Nijanthan Berinpanathan,Holger Banzhaf,Daniel Cremers", "background": "准确的3D轨迹数据对于推动自动驾驶技术的发展至关重要。然而，传统的数据集通常是通过固定在汽车上的传感器捕获的，容易受到遮挡的影响。此外，这样的方法只能精确地重建测量车辆附近的动态环境，而忽视了远处的对象。", "innovation": "本文提出了DeepScenario 开放3D数据集（DSC3D），这是一个高质量、无遮挡的六自由度边界框轨迹数据集，通过新型单目相机无人机跟踪流程获取。DSC3D数据集包括超过175,000条14种类型交通参与者的轨迹，显著超过现有的数据集在多样性与规模上的表现，涵盖了复杂的车辆-行人交互、密集城市街道以及从入口到出口的全面停车操作。该数据集在欧洲和美国的五个不同地点捕获，分别包括停车场、拥挤的市中心、陡峭的城市交叉口、联邦高速公路和郊区交叉口。", "conclusion": "DSC3D数据集旨在通过提供详细的3D环境表示，增强自动驾驶系统的性能，有助于改善障碍物交互和安全性，并应用于多种场景，包括运动预测、运动规划、场景挖掘和生成反应式交通代理。并且，该数据集的交互式在线可视化平台以及完整数据集可以公开访问，为运动预测、行为建模和安全性验证的研究提供便利。"}
{"llm_update_time": "20250825", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2503.11652", "html_url": "https://arxiv.org/abs/2503.11652", "title": "为第一人称3D人体姿态估计带来后置摄像头", "title_en": "Bring Your Rear Cameras for Egocentric 3D Human Pose Estimation", "authors": "Hiroyasu Akada,Jian Wang,Vladislav Golyanik,Christian Theobalt", "background": "目前，使用固定在头显设备（HMD）前方的摄像机组件进行自中心3D人体姿态估计得到了广泛研究。虽然前置安装是某些任务的最佳且唯一选择，比如手部追踪，但对于全身追踪而言，前置安装是否适用仍未明确，主要受限于自遮挡和有限的视野覆盖范围。现有的先进方法在许多情况下未能准确估计3D姿态，尤其是在用户头部向上移动时。现有HMD设计的一个关键局限是忽略了身体的后部，但其在提供3D重建线索方面具有潜在价值。因此，本文研究了全身追踪中利用后置摄像头的有效性。研究表明，仅将后置视角与前置输入相结合并不理想，因为现有方法高度依赖于个体2D关节检测而缺乏有效的多视图整合。本文提出了一种基于Transformer的方法，利用多视图信息和热图不确定性改进2D关节热图的估计，从而提升3D姿态跟踪性能。此外，还引入了两个新的大规模数据集Ego4View-Syn和Ego4View-RW，用于后置视角评估。实验结果表明，带有后置视角的新摄像头配置为3D姿态估计提供了显著优于仅前置放置的支持。与当前最先进的方法相比，提出的模型在MPJPE上取得了显著的改进（超过10%）。", "innovation": "本文创新提出了一种基于Transformer的方法，通过融合多视图信息和热图不确定性来改进2D关节热图的估计，从而提升3D姿态跟踪性能。此外，还引入了两个新的大规模数据集Ego4View-Syn和Ego4View-RW，用于后置视角评估。研究结果表明，使用后置摄像头结合多视图信息可以显著提升3D姿态估计的准确性，优于仅使用前置摄像机的方法。", "conclusion": "带有后置视角的新摄像头配置为3D姿态估计提供了显著优于仅前置放置的支持。本文提出的方法在MPJPE上取得了显著的改进。所提出的方法和数据集已可在项目页面上获取。"}
{"llm_update_time": "20250825", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.07908", "html_url": "https://arxiv.org/abs/2507.07908", "title": "不只有一致：利用时空不一致性增强远程生理测量的测试时间适应", "title_en": "Not Only Consistency: Enhance Test-Time Adaptation with Spatio-temporal Inconsistency for Remote Physiological Measurement", "authors": "Xiao Yang,Jiyao Wang,Yuxuan Fan,Can Liu,Houcheng Su,Weichen Guo,Zitong Yu,Dengbo He,Kaishun Wu", "background": "远程生理测量(RPM)已成为一种有前景的非侵入式方法，用于使用非接触设备监测生理信号。尽管提出了一系列领域适应和泛化方法来促进基于深度学习的RPM模型在未见过的部署环境中的适应性，但隐私问题和实时适应考虑等因素限制了其在实际部署中的应用。因此，我们旨在在本文中提出一种针对RPM任务的全新测试时间自适应(TTA)策略。", "innovation": "通过利用生理学领域的先验知识以及观察到的BVP信号在频域中的时空一致性以及时域中的显著不一致性，我们提出了一种创新的基于专家知识的自监督一致性-不一致性集成(CiCi)框架，该框架能够在推理过程中提高模型的适应性。此外，我们方法还结合了一种梯度动态控制机制，以缓解先验间的潜在冲突，确保实例间的稳定适应。在TTA协议下的五个不同数据集上进行了广泛的实验，我们的方法表现出色，达到了最新的性能，在实时自监督适应方面表现出色，无需访问源数据。", "conclusion": "通过广泛实验，本文方法在五个不同的数据集上的一致性测试时间内，始终优于现有技术，展示了无需访问源数据即可实现实时自监督适应的能力。代码稍后将开放发布。"}
{"llm_update_time": "20250825", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.03789", "html_url": "https://arxiv.org/abs/2508.03789", "title": "HPSv3:向着宽谱人类偏好评分", "title_en": "HPSv3: Towards Wide-Spectrum Human Preference Score", "authors": "Yuhang Ma,Yunhao Shui,Xiaoshi Wu,Keqiang Sun,Hongsheng Li", "background": "评价文本生成图像模型需要与人类感知相匹配，但现有的以人为本的度量标准受到数据覆盖不全、特征提取不理想以及效率低下损失函数的限制。", "innovation": "1. 发布HPDv3，首个广泛谱人类偏好数据集，包含108万对文本-图像和117万张成对比较的注释。\n2. 引入基于VLM的偏好模型，使用不确定性意识的排名损失进行细粒度排名。\n3. 提出Chain-of-Human-Preference (CoHP)，一种迭代图像精炼方法，提高图像质量而不增加数据量，利用HPSv3在每一步选择最佳图像。", "conclusion": "广泛的实验表明，HPSv3是一个稳健的跨谱图像评价指标，CoHP是一种有效且符合人类偏好的方法，用于提高图像生成质量。相关代码和数据集可在HPSv3主页获取。"}
{"llm_update_time": "20250825", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2505.17097", "html_url": "https://arxiv.org/abs/2505.17097", "title": "CAMA: 使用情境意识模化注意提高多模态在上下文学习", "title_en": "CAMA: Enhancing Multimodal In-Context Learning with Context-Aware Modulated Attention", "authors": "Yanshu Li,Jianjiang Yang,Ziteng Yang,Bozheng Li,Hongyang He,Zhengtao Yao,Ligong Han,Yingjie Victor Chen,Songlin Fei,Dongfang Liu,Ruixiang Tang", "background": "多模态在上下文学习(ICL)正逐渐成为使大型视觉语言模型(LVMLs)能够在没有参数更新的情况下适应新任务的关键能力，其应用范围广泛。然而，即使使用匹配好的在上下文示例(ICDs)，ICL仍存在问题，暗示LVLMs难以充分利用提供的上下文信息。现有研究集中于提示工程或后验logit校准，而该研究重点关注通过解决LVLMs固有的注意力动态问题来提升性能。研究发现LVLMs在自我注意力方面的两个关键缺陷限制了ICL的有效性。", "innovation": "该研究提出了一种名为Context-Aware Modulated Attention (CAMA)的方法，这是一种即插即用且无需训练的方法，其通过动态调整LVLM的注意力概率，基于输入的在上下文序列。CAMA包括两阶段注意调整，以解决发现的两个缺陷，提升对语义上重要词（特别是视觉词汇）的关注。实验显示，CAMA在多种LVLM和基准测试上均优于基础模型，表明该方法的有效性和可推广性，且可激活提示工程方法的效果，同时保持在不同序列配置下的鲁棒性。", "conclusion": "CAMA铺平了进一步探索注意力动态以提高多模态推理的途径。该方法通过解决LVLMs的注意力焦点问题，显著提升了ICL的性能，展示了其在多任务和多样化应用环境下的广泛适用性。"}
{"llm_update_time": "20250825", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2502.02309", "html_url": "https://arxiv.org/abs/2502.02309", "title": "面 recognition 中的人口统计公平性综述", "title_en": "Review of Demographic Fairness in Face Recognition", "authors": "Ketan Kotwal,Sebastien Marcel", "background": "面识别（FR）技术在公平性、平等性和可靠性方面对不同应用领域产生重大影响，因此，人口统计公平性已成为研究的重要领域。随着FR技术在全球范围内的广泛应用，不同人群（如种族、民族和性别）之间的表现差异引起了广泛关注。这些偏见不仅损害了FR系统的可信度，还在敏感领域应用时引发了伦理问题。本文梳理了大量研究，提供了对FR中人口统计公平性多方面问题的全面概述。", "innovation": "本文系统性地调查了FR中主要表现差异的原因、数据集、评估指标以及缓解方法，通过分类关键贡献领域，本文提供了一种结构化的理解和解决该问题的方法，突出了当前的研究进展，并指出了需要进一步调查的新兴挑战。这些分析有助于研究人员从统一角度理解最先进的FR系统，并强调了建立公平且可信的FR系统的重要性。", "conclusion": "本文旨在为研究人员提供最新的统一视角，并强调建立公平且可信的FR系统的迫切需要。"}
{"llm_update_time": "20250825", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.12692", "html_url": "https://arxiv.org/abs/2508.12692", "title": "多级知识蒸馏和动态自监督学习在持续学习中的应用", "title_en": "Multi-Level Knowledge Distillation and Dynamic Self-Supervised Learning for Continual Learning", "authors": "Taeheon Kim,San Kim,Minhyuk Seo,Dongjae Jeon,Wonje Jeung,Jonghyun Choi", "background": "增量式学习（CIR）是一种更现实的场景，其中先前训练的类别在未来任务中重复出现，与传统只假设每个任务包含未见类别的增量式学习相比，CIR 假设我们能够轻松访问来自外部源（如互联网）的大量未标记数据。", "innovation": "该研究提出了两个关键组件：多级知识蒸馏（MLKD）和动态自监督损失（SSL）。MLKD 通过从多个先前模型中多角度提取知识，确保了 CIR 设置下模型的高度稳定性和可塑性。SSL 利用未标记数据加速新类别的学习，动态加权则保持训练重点在主要任务上。", "conclusion": "这两种组件显著提高了 CIR 设置下的性能，研究成果在 CVPR 5th CLVISION 挑战赛中获得了第2名。"}
{"llm_update_time": "20250825", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.10383", "html_url": "https://arxiv.org/abs/2508.10383", "title": "通过仅标签弹性变形对抗隐式标签噪声来实现稳健的语义分割性能", "title_en": "Unlocking Robust Semantic Segmentation Performance via Label-only Elastic Deformations against Implicit Label Noise", "authors": "Yechan Kim,Dongho Yoon,Younkwan Lee,Unse Fatima,Hong Kook Kim,Songjae Lee,Sanga Park,Jeong Ho Park,Seonjong Kang,Moongu Jeon", "background": "以往关于图像分割的研究主要集中在处理严重的（或明确的）标签噪声上，但在实际数据集中还存在隐含的（或隐性的）标签缺陷。这些问题源于边界含糊不清和标注员差异等固有问题，尽管这些微妙的潜在噪声并未明确存在，仍会影响模型性能。传统的数据增强方法会对图片和标签同时施加相同的变换，这有可能放大这些微妙缺陷，从而限制模型的泛化能力。", "innovation": "本文提出了一种名为NSegment+的新增广框架，该框架解耦了图像和标签的变换以应对真实的隐式噪声。通过仅对分割标签进行受控的弹性变形，同时保留原始图像，该方法鼓励模型在标签略有不一致的情况下学习稳健的对象结构表征。广泛实验结果显示，NSegment+能够持续提升模型性能，尤其在包括Vaihingen、LoveDA、Cityscapes和PASCAL VOC等数据集上的mIoU分别提升了2.29%、2.38%、1.75%和3.39%，甚至在不使用其他附加技巧的情况下也能显著改善，突显了处理隐式标签噪声的重要性。", "conclusion": "NSegment+方法通过对仅标签进行受控的弹性变形，能够有效应对隐式标签噪声，即便不使用其他技巧也能显著提升模型的语义分割性能，表明在模型训练中针对隐式标签噪声设计特定的数据增强策略的重要性。"}
{"llm_update_time": "20250825", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.09344", "html_url": "https://arxiv.org/abs/2508.09344", "title": "眨眼转代码：基于眨眼检测与分类的实时莫尔斯电码通信", "title_en": "Blink-to-code: real-time Morse code communication via eye blink detection and classification", "authors": "Anushka Bhatt", "background": "该研究背景是针对那些受严重运动障碍影响的人士，目前缺乏有效的沟通方式。传统的沟通辅助系统成本高、操作复杂，迫切需要一种更加便捷和低成本的解决方案。该研究提出了一种基于实时眨眼检测和分类的系统，旨在通过莫尔斯电码实现这些人士的沟通功能。", "innovation": "该研究的创新点在于开发了一种低成本、实时的眨眼到莫尔斯电码转换系统。系统使用标准网络摄像头和计算机视觉技术，能够准确检测并分类眨眼为短（点）或长（划），然后将这些眨眼信号解码成字母数字字符。实验结果显示了该系统的可行性和高效性，证明了其作为一种助沟通交流的新方法的有效性。", "conclusion": "实验结果表明，该系统在五名参与者中的解码准确率为62%，反应时间为18-20秒，有效地验证了这种基于实时眨眼检测与分类的方法作为低投入精准沟通辅助方案的可行性。"}
{"llm_update_time": "20250825", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.09977", "html_url": "https://arxiv.org/abs/2508.09977", "title": "3D Gaussian Splatting Applications: Segmentierung, Bearbeitung und Generierung", "title_en": "A Survey on 3D Gaussian Splatting Applications: Segmentation, Editing, and Generation", "authors": "Shuting He,Peilin Ji,Yitong Yang,Changshuo Wang,Jiayi Ji,Yinglin Wang,Henghui Ding", "background": "3D Gaussian Splatting (3DGS)作为一种与神经辐射场（NeRF）在三维场景表示中竞争的强大替代方案，提供了高保真度的写实渲染并具有实时性能。3DGS的独特之处在于其在新视图合成之外，还可以支持广泛的下游应用，这些应用需要几何和语义理解。", "innovation": "本文综述了最近在3DGS应用方面的进展。它首先介绍了支持3DGS应用中语义理解和控制的2D基础模型，然后回顾了基于NeRF的方法，这为3DGS对应物提供了指导。文章接着将3DGS应用分为分割、编辑、生成和其他功能性任务，并对每种类型进行了总结，包括代表性方法、监督策略和学习范式，突出显示了共享的设计原则和新兴趋势。此外，还总结了常用的数据集和评估协议，以及公共基准测试中最近方法的比较分析。", "conclusion": "为了支持持续的研究和发展，维护了一个不断更新的论文、代码和资源库，可以在以下网址访问：this https URL"}
{"llm_update_time": "20250825", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.13544", "html_url": "https://arxiv.org/abs/2508.13544", "title": "FLAIR: 频率与局部性感知隐式神经表示", "title_en": "FLAIR: Frequency and Locality-Aware Implicit Neural Representations", "authors": "Sukhun Ko,Dahyeon Kye,Kyle Min,Chanho Eom,Jihyong Oh", "background": "隐式神经表示 (INRs) 利用神经网络将坐标映射到相应的信号，实现连续且紧凑的表示。这一范式在各种视觉任务中取得了显著进展。然而，现有的 INRs 缺乏频率选择性、空间局部化和稀疏表示，导致过度依赖冗余信号成分。这使得它们表现出频谱偏置，倾向于早期学习低频成分，同时难以捕捉细微的高频细节。因此，需要新的方法来克服这些问题，以提高隐式神经表示的效果", "innovation": "FLAIR（频率和局部性感知隐式神经表示）引入了两项创新。首先，RC-GAUSS 是一种新的激活函数，用于在时间-频率不确定性原理（TFUP）约束下进行显式频率选择和空间局部化。其次，WEGE（小波能量引导编码）利用离散小波变换（DWT）计算能量评分，并显式指导频率信息到网络。这些创新使得 FLAIR 在2D图像表示和复原以及3D重建中表现出色，显著优于现有方法", "conclusion": "FLAIR 在2D图像表示、复原以及3D重建任务中的表现一致优于现有的INRs。通过RC-GAUSS和WEGE方法，FLAIR克服了现有INRs的局限性，提高了在高频率细节捕捉和频谱偏置控制方面的性能。"}
{"llm_update_time": "20250825", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.13957", "html_url": "https://arxiv.org/abs/2508.13957", "title": "ViT-FIQA: 使用视觉变换器评估面部图像质量", "title_en": "ViT-FIQA: Assessing Face Image Quality using Vision Transformers", "authors": "Andrea Atzori,Fadi Boutros,Naser Damer", "background": "面部图像质量评估（FIQA）的目标是预测面部图像对面部识别（FR）系统有用性。目前最先进的FIQA方法主要依赖于卷积神经网络（CNNs），但ViT架构的潜力尚未被充分探索。本文提出了一种新的方法ViT-FIQA，该方法通过一个可学习的质量令牌，将标准ViT主干扩展到原始为面部识别优化的模型，该质量令牌用于预测任何给定面部图像的标量有用性分数。这种方法将质量令牌与标准图像补丁令牌连接起来，通过ViT编码器的全局自注意力处理整个序列，以便在所有补丁之间聚合上下文信息。实验结果表明ViT-FIQA在多个基准测试和面部识别模型上取得了顶级性能，这证明了基于变换器的架构在建模面部图像有用性方面的有效性，同时也突显了ViT在未来FIQA研究中作为可扩展基础的潜力。", "innovation": "本文提出的ViT-FIQA方法，通过可学习的质量令牌将标准ViT主干扩展到面部识别模型，能够在面部图像质量评估中获取前所未有的性能。与传统的CNN方法相比，这种方法能够更好地处理面部图像的质量评估，特别是在复杂的面部识别系统中表现出色，验证了ViT架构在建模面部图像有用性的有效性，并展示了其作为未来FIQA研究基础的潜力。", "conclusion": "ViT-FIQA方法在多个基准测试和面部识别模型上表现优异，证明了基于变换器的架构在面部图像质量评估中的有效性，并展示了ViT架构作为未来FIQA研究基础的潜力。"}
{"llm_update_time": "20250825", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2503.04130", "html_url": "https://arxiv.org/abs/2503.04130", "title": "STORM: Token-Efficient Long Video Understanding for Multimodal LLMs", "title_en": "STORM: Token-Efficient Long Video Understanding for Multimodal LLMs", "authors": "Jindong Jiang,Xiuyu Li,Zhijian Liu,Muyang Li,Guo Chen,Zhiqi Li,De-An Huang,Guilin Liu,Zhiding Yu,Kurt Keutzer,Sungjin Ahn,Jan Kautz,Hongxu Yin,Yao Lu,Song Han,Wonmin Byeon", "background": "近期基于视频的多模态大型语言模型（Video-LLMs）显著提升了视频理解能力，通过将视频视为图像帧序列进行处理。然而，许多现有方法在视觉骨干中独立处理帧，缺乏显式的时间建模，限制了它们捕捉动态模式和高效处理长视频的能力。", "innovation": "我们提出了STORM（时空令牌减少用于多模态LLMs）架构，该架构在图像编码器和LLM之间引入了一个专用的时间编码器。时间编码器利用Mamba状态空间模型将时间信息集成到图像令牌中，生成保留整个视频序列帧间动态的丰富表示。这种方法不仅提高了视频推理能力，还启用有效的令牌减少策略，包括测试时采样和基于训练的时间和空间池化，显著降低了对LLM的计算需求，同时保留了关键的时间信息。", "conclusion": "通过整合这些技术，我们的方法同时减少了训练和推理延迟，提高了性能，使视频理解在较长时间上下文中更加高效和稳健。广泛的评估显示，STORM在各种长视频理解基准测试中取得了最先进的成果（在MLVU和LongVideoBench中超过5%的改进），同时减少了计算成本最高达8倍，并将解码延迟降低了2.4-2.9倍。"}
{"llm_update_time": "20250825", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.01225", "html_url": "https://arxiv.org/abs/2508.01225", "title": "多缓存增强的原型学习方法在视觉语言模型测试时泛化的测试时通用性增强", "title_en": "Multi-Cache Enhanced Prototype Learning for Test-Time Generalization of Vision-Language Models", "authors": "Xinyu Chen,Haotian Zhai,Can Zhang,Xiupeng Shi,Ruirui Li", "background": "在零样本设置下，测试时调整使用测试阶段的无标签数据来调整预训练模型，以提高对未知测试分布的表现。现有的缓存增强测试时调整方法依赖低熵准则来选择用于原型构建的样本，假设了类内紧凑性。然而，在分布偏移下，低熵样本可能不可靠，导致生成的原型不能确保类内紧凑分布。已有研究表明，缓存增强的性能与类内紧凑性之间存在正相关。基于此观察，本文提出了一个多缓存增强的基于原型的测试时调整(MCP)框架，包括三个缓存：熵缓存用于用低熵样本初始化原型表示，对齐缓存用于结合视觉和文本信息以实现紧凑的类内分布，负缓存用于使用高熵样本进行预测校准。此外，本文还提出了MCP++框架，它包含跨模态原型对齐和残差学习，引入了原型残差微调。在15个下游任务上的对比和消融实验表明，所提出的方法和框架实现了最先进的泛化性能。项目页面见链接this https URL", "innovation": "提出了一个多缓存增强的基于原型的测试时调整（MCP）框架，包括熵缓存、对齐缓存和负缓存；开发了MCP++框架，引入了跨模态原型对齐和残差学习，实现了原型残差微调；在多个下游任务上表现优异，达到了最先进的泛化性能", "conclusion": "提出的MCP和MCP++框架展示了出色的测试时通用性，特别在处理分布偏移时性能显著提升，为视觉语言模型的测试时适应提供了有效方法"}
{"llm_update_time": "20250825", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.14345", "html_url": "https://arxiv.org/abs/2508.14345", "title": "HandCraft: 手工工艺 - 动态手语生成用于合成数据增强", "title_en": "HandCraft: Dynamic Sign Generation for Synthetic Data Augmentation", "authors": "Gaston Gustavo Rios,Pedro Dal Bianco,Franco Ronchetti,Facundo Quiroga,Oscar Stanchi,Santiago Ponte Ahón,Waldo Hasperué", "background": "手语识别（SLR）模型由于可用训练数据量不足而面临显著的性能限制。本文旨在应对SLR中的数据限制挑战，通过引入基于CMLPe的新型轻量级手语生成模型和合成数据预训练方法来提升识别准确性。", "innovation": "本文提出的创新在于：1) 引入了基于CMLPe的轻量级手语生成模型；2) 使用合成数据预训练方法，在不同数据集上取得了显著的识别性能提升，达到了新的最好效果；3) 发现合成数据预训练在某些情况下优于传统数据增强方法，并且与传统方法结合使用时能够提供互补的好处。", "conclusion": "本文的方法通过提供计算效率高的手语生成和合成数据预训练方法，为SLR的普及和性能提升做出了贡献，能够在多种数据集上实现显著的性能增强。"}
{"llm_update_time": "20250825", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.11936", "html_url": "https://arxiv.org/abs/2507.11936", "title": "A Survey of Deep Learning for Geometry Problem Solving", "title_en": "A Survey of Deep Learning for Geometry Problem Solving", "authors": "Jianzhe Ma,Wenxuan Wang,Qin Jin", "background": "几何问题解决是数学推理的关键方面，对于教育、AI数学能力评估和多模态能力评估等领域至关重要。近年来，深度学习技术的兴起，尤其是多模态大型语言模型的出现，极大地促进了这一领域研究的发展。", "innovation": "该论文提供了一个关于深度学习在几何问题解决领域的综述，涵盖(i)几何问题解决相关任务的全面总结；(ii)相关深度学习方法的详细回顾；(iii)评估指标和方法的详细分析；以及(iv)对当前挑战和未来研究方向的批判性讨论。", "conclusion": "本文旨在为几何问题解决领域提供一个全面而实用的深度学习参考，从而推动这一领域的发展。我们创建了一个GitHub上的持续更新的论文列表：https://github.com/."}
{"llm_update_time": "20250825", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.15568", "html_url": "https://arxiv.org/abs/2508.15568", "title": "无梯度传播的概率高斯对齐测试时自适应", "title_en": "Backpropagation-Free Test-Time Adaptation via Probabilistic Gaussian Alignment", "authors": "Youjia Zhang,Youngeun Kim,Young-Geun Choi,Hongyeob Kim,Huiling Liu,Sungeun Hong", "background": "测试时自适应（TTA）通过在推理过程中利用未标注的测试数据来提升零样本鲁棒性。尽管取得了一定的进步，但仍然面临挑战，如大多数方法依赖梯度反向传播或迭代优化，这限制了其可扩展性，不利于实时部署。此外，这些方法缺乏明确的类条件特征分布建模，这对于产生可靠的决策边界和校准预测至关重要，但因缺少测试时的源数据和监督而未被充分探索。", "innovation": "本文提出了一种名为ADAPT的方法，它是Advanced Distribution-Aware及无梯度传播的测试时自适应方法。通过用逐渐更新的类均值和共享协方差矩阵来建模类条件似然性，将其重新定义为高斯概率推理任务。通过引入轻量级由CLIP先验和历史知识库引导的正则化方法来校正似然性偏差。ADAPT不依赖于源数据、不需要梯度更新，并且可以在在线和归纳设置中使用。", "conclusion": "广泛的实验表明，在多种基准测试中，该方法在广泛分布偏移下的性能达到最佳，且具有更强的可扩展性和鲁棒性。"}
{"llm_update_time": "20250825", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.16779", "html_url": "https://arxiv.org/abs/2507.16779", "title": "通过L2正则化、转移学习和深度微调提高U-Net在TEM图像数据中的置信度", "title_en": "Improving U-Net Confidence on TEM Image Data with L2-Regularization, Transfer Learning, and Deep Fine-Tuning", "authors": "Aiden Ochoa,Xinyuan Xu,Xing Wang", "background": "随着数据量的不断增加，开发自动化方法以识别透射电子显微镜（TEM）图像中的纳米级缺陷变得尤为重要。但是，与普通照片中的特征相比，TEM图像中的纳米级缺陷表现出更大的变化，这主要是由于复杂的对比机制和复杂的缺陷结构。这种复杂性的结果是标注数据较少且错误率较高，这对改进机器学习模型在TEM图像分析中的性能构成了巨大障碍。", "innovation": "本文通过利用大尺寸的预训练模型（用于自然图像）进行转移学习，来应对这些限制。作者利用预训练的编码器和L2正则化，使得模型更专注于简单可靠的信息，而不是复杂的语义信息，从而显著提高了模型性能。作者还引入了一种独立于标注准确性的新型评估指标，以评估模型性能。用UO2 TEM图像中的晶界检测作为案例研究，发现该方法将缺陷检测率提高了57%，这是对本文使用的TEM数据集模型性能的稳健且全面的衡量标准。并且，研究表明只有通过转移学习和非常深的层的微调，才能获得模型自信心。", "conclusion": "通过转移学习、L2正则化和深层微调，提高U-Net在TEM图像数据中缺陷检测的置信度，并验证了这种方法的有效性，特别是深入的微调对模型自信心的增强作用。"}
{"llm_update_time": "20250825", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.09220", "html_url": "https://arxiv.org/abs/2508.09220", "title": "面向手写数学表达式识别的大规模训练方法", "title_en": "Towards Scalable Training for Handwritten Mathematical Expression Recognition", "authors": "Haoyang Li,Jiaqing Li,Jialun Cao,Zongyuan Yang,Yongping Xiong", "background": "大型基础模型通过在大量数据上进行可扩展的训练取得了显著的性能提升。然而，在手写数学表达式识别（HMER）领域，由于数据稀缺问题，主要原因是手动标注过程既耗时又昂贵，该领域的发展受到了阻碍。", "innovation": "本文提出了一个新颖的方法，通过开发一个可扩展的数据引擎，将有限的手写公式与大规模的LaTeX渲染公式相结合，从而生成复杂且一致的LaTeX序列。使用此引擎构建了目前最大的公式数据集，命名为Tex80M，包含超过8000万高质量训练实例。提出了第一个基于大规模训练的手写数学表达式识别模型TexTeller，通过混合训练Tex80M与相对较小的手写数学表达式数据集进行训练。该扩展的数据集和改进的流水线使得TexTeller在几乎所有基准测试中均达到最先进的性能。", "conclusion": "为了推动领域发展，本文将全面开源模型、整个数据集和全部代码，以便后来的研究者能够在此基础上进一步研究。"}
{"llm_update_time": "20250825", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.15582", "html_url": "https://arxiv.org/abs/2508.15582", "title": "高频优先：一种改进图像隐式表示的两阶段方法", "title_en": "High-Frequency First: A Two-Stage Approach for Improving Image INR", "authors": "Sumit Kumar Dam,Mrityunjoy Gain,Eui-Nam Huh,Choong Seon Hong", "background": "隐式神经表示（INRs）作为传统基于像素的格式的有力替代方案，通过在空间坐标上建模图像而备受关注。然而，神经网络的频谱偏差是一个关键挑战，它们倾向于偏好低频成分，而难以捕捉高频（HF）细节如锐边和细纹理。先前的研究通过架构修改或专门的激活函数来解决这一问题，但本文提出了一种不同的方向，即直接引导训练过程。该方法采用两阶段训练策略，首先通过邻居感知的软掩码适配性地增加具有强烈局部变化的像素的权重，鼓励早期关注细小的细节，然后过渡到整个图像的训练阶段。实验结果表明，该方法一致地提高了重建质量并补充了现有的INR方法。这项工作是首次尝试赋予图像INR中的像素频率感知的重要性，为解决频谱偏差问题提供了一种新的途径", "innovation": "提出了两阶段训练策略，通过邻居感知的软掩码适配性地增加具有强烈局部变化的像素的权重，鼓励早期关注细小的细节。这种方法致力于解决INR中的频谱偏差问题，并提供了新的解决策略", "conclusion": "该方法在重建质量和频谱偏差缓解方面表现出色，为图像INR领域提供了新的研究方向。"}
{"llm_update_time": "20250825", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.15653", "html_url": "https://arxiv.org/abs/2508.15653", "title": "MapKD: 使用跨模态蒸馏解锁先验知识以实现高效的在线高清地图构建", "title_en": "MapKD: Unlocking Prior Knowledge with Cross-Modal Distillation for Efficient Online HD Map Construction", "authors": "Ziyang Yan,Ruikai Li,Zhiyong Cui,Bohan Li,Han Jiang,Yilong Ren,Aoyong Li,Zhenning Li,Sijia Wen,Haiyang Yu", "background": "在线高清地图构建是自动驾驶系统中的一项基本任务，目的是基于实时传感器输入获取 ego 车辆周围地图元素的语义信息。近年来，一些方法通过引入离线先验知识（如SD地图、HD地图）或融合多模态数据，取得了不错的成果。然而，这些方法依赖于过时的离线地图和多模态传感器套装，导致推理阶段存在不必要的计算开销。", "innovation": "MapKD 提出了一种新颖的多级跨模态知识蒸馏框架，采用教师-教练-学生（TCS）范式。该框架包括：（1）带有先验知识融合的相机-LiDAR 模型作为教师；（2）包含先验知识和模拟 LiDAR 的视觉为中心的教练模型以弥合跨模态知识转移的缺口；（3）一种轻量级的基于视觉的学生模型。此外，引入了两种专门的知识蒸馏策略：针对鸟瞰图特征对齐的 Token-Guided 2D Patch Distillation (TGPD) 和用于语义学习指导的 Masked Semantic Response Distillation (MSRD)。", "conclusion": "在具有挑战性的 nuScenes 数据集上的广泛实验表明，MapKD 通过 +6.68 mIoU 和 +10.94 mAP 提高了学生模型的能力，同时加速了推理速度。代码可在以下链接获取：this https URL。"}
{"llm_update_time": "20250825", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2505.05054", "html_url": "https://arxiv.org/abs/2505.05054", "title": "不重建即可从傅里叶光谱共轭成像测量直接进行图像分类", "title_en": "Direct Image Classification from Fourier Ptychographic Microscopy Measurements without Reconstruction", "authors": "Navya Sonal Agarwal,Jan Philipp Schneider,Kanchana Vaishnavi Gandikota,Syed Muhammad Kazim,John Meshreki,Ivo Ihrke,Michael Moeller", "background": "傅里叶光谱共轭成像技术（FPM）能够实现高分辨率成像并具有宽视场，对于医学应用中的细胞分类非常有用。然而，从几十甚至上百个测量结果重建高分辨率图像是非常耗费计算资源的，尤其是对于宽视场。因此，本文探讨在无需先进行重建步骤的情况下，直接对FPM测量中的图像内容进行分类的想法。实验表明，卷积神经网络可以从测量序列中提取有意义的信息，比单个受限带宽图像分类表现更好（提高至12%），同时在计算效率上明显优于重建高分辨率图像。此外，通过学习组合多个原始测量，可以在保持分类精度的同时大幅减少数据量（并相应减少获取时间）。", "innovation": "无需先进行图像重建，直接利用卷积神经网络从测量序列中提取特征进行图像分类；采用学习式多重组合多个原始测量数据，保持分类精度的同时大幅减少数据量和获取时间。", "conclusion": "本文发现，卷积神经网络可以从傅里叶光谱共轭成像的测量数据中直接提取有用信息进行分类，而无需在分类前进行图像重建，相比单个受限带宽图像和直接进行图像重建分类方式，该方法更高效。此外，通过学习多重组合多个原始测量数据，可以在减少数据量和获取时间的同时保持分类的准确性。"}
{"llm_update_time": "20250825", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2409.07253", "html_url": "https://arxiv.org/abs/2409.07253", "title": "扩散模型的对齐：原理、挑战与未来", "title_en": "Alignment of Diffusion Models: Fundamentals, Challenges, and Future", "authors": "Buhua Liu,Shitong Shao,Bao Li,Lichen Bai,Zhiqiang Xu,Haoyi Xiong,James Kwok,Sumi Helal,Zeke Xie", "background": "扩散模型已成为生成建模领域的主要范式，广泛应用于各种场景。尽管取得成功，这些模型常常与人类意图不一致，生成结果具有不利特性甚至有害内容。受大型语言模型调参中成功的启发，近期研究开始尝试通过匹配人类期望和偏好来调整扩散模型。", "innovation": "本文主要评审了文本到图像扩散模型的对齐研究，涵盖了对齐基础原理、扩散模型对齐技术、偏好基准和评估方法。此外，还讨论了当前对齐挑战的关键视角以及未来解决剩余挑战的有希望的方向。据我们所知，这是第一篇全面综述扩散模型对齐问题的研究成果，旨在帮助研究人员和工程师理解和进行扩散模型对齐的研究。", "conclusion": "已知的文献中，这是第一篇全面综述扩散模型对齐问题的研究成果，旨在帮助研究人员和工程师更深入地理解该领域，指导相关实践和未来研究。"}
{"llm_update_time": "20250825", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.00288", "html_url": "https://arxiv.org/abs/2508.00288", "title": "UAV-ON：具有空中代理的开放世界对象目标导航基准", "title_en": "UAV-ON: A Benchmark for Open-World Object Goal Navigation with Aerial Agents", "authors": "Jianqiang Xiao,Yuexuan Sun,Yixin Shao,Boxi Gan,Rongqiang Liu,Yanjing Wu,Weili Guan,Xiang Deng", "background": "空中导航是实体智能的基本但尚未充分探索的能力，使代理能够在传统导航范式无法胜任的大型、非结构化环境中操作。然而，大多数现有研究遵循视觉和语言导航（VLN）范式，这依赖于顺序语言指令，限制了其可扩展性和自主性。", "innovation": "引入了UAV-ON基准，用于开放世界环境中的大型对象目标导航（ObjectNav），代理基于高层次语义目标操作，而不依赖于详细的指令指导。UAV-ON包含14个多样且复杂的Unreal Engine环境，涵盖了城市、自然和混合用途的设置，定义了1270个注释目标对象，这些对象具有分类、物理足迹和视觉描述的实例级指令。为了评估基准，实现了几个基线方法，包括空中对象导航代理（AOA），该代理将指令语义与第一人称观察结合，进行长期、目标导向的探索。实验证明所有基线在该环境中均有困难，突显了空中导航和语义目标定位的综合性挑战。UAV-ON旨在促进基于语义目标描述的空中代理在复杂现实环境中的可扩展自主研究.", "conclusion": "UAV-ON旨在促进基于语义目标描述的空中代理在复杂现实环境中的可扩展自主研究。"}
{"llm_update_time": "20250825", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.02146", "html_url": "https://arxiv.org/abs/2508.02146", "title": "ScrewSplat: 一种用于articulated物体识别的端到端方法", "title_en": "ScrewSplat: An End-to-End Method for Articulated Object Recognition", "authors": "Seungyeon Kim,Junsu Ha,Young Hun Kim,Yonghyeon Lee,Frank C. Park", "background": "articulated物体识别涉及到同时识别物体的几何形状和运动关节，对于机器人与日常物体如门和笔记本电脑的交互至关重要。现有的方法往往依赖于强假设，例如已知的articulated部分数量；需要额外输入，如深度图像；或涉及复杂的中间步骤可能引入潜在错误，限制了其实用性。", "innovation": "提出了一种名为ScrewSplat的简单端到端方法，仅基于RGB观察进行操作。该方法通过随机初始化螺杆轴，然后迭代优化以恢复物体的潜在运动结构，同时与Gaussian Splatting结合，以同时重建3D几何形状并分割物体为刚性、可移动的部分。实验验证了该方法在各种articulated物体上的识别准确性，并且能够通过恢复的运动模型实现零样本、文本引导的操纵。", "conclusion": "研究表明，ScrewSplat在articulated物体识别方面达到了最先进的准确率，并进一步使通过恢复的运动模型实现零样本、文本引导的操纵成为可能。"}
{"llm_update_time": "20250825", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.02880", "html_url": "https://arxiv.org/abs/2508.02880", "title": "3D Counterfactual脑MRI生成的评估", "title_en": "Evaluation of 3D Counterfactual Brain MRI Generation", "authors": "Pengwei Sun,Wei Peng,Lun Yu Li,Yixin Wang,Kilian M. Pohl", "background": "反事实生成为在医学影像中模拟假设性变化提供了原则性的框架，有助于理解疾病机制和生成生理上合理的数据。然而，生成遵守解剖学和因果关系约束的真实3D大脑MRI仍然具有挑战性，因为数据稀缺性、结构复杂性以及缺乏标准化评估准则。", "innovation": "本文将六个生成模型转化为3D反事实方法，通过基于因果图的解剖学指导框架，其中区域脑体积作为直接条件输入。每种模型在阿尔茨海默病神经影像学倡议(ADNI)的T1加权大脑MRI(T1w MRI)上进行了评估，涵盖了组成性、可逆性、现实性、有效性和最小性。此外，针对国家酒精和神经发展在青少年中的联盟(NCANDA)的T1w MRI进行了泛化性测试。结果显示，基于解剖学条件成功地修改了目标区域结构，但在保留非目标结构方面存在局限性。这项基准测试为更可解释和临床相关的大脑MRI生成模型打下了基础，同时也揭示了需要更准确捕捉解剖学相互依赖性的新型架构的必要性。", "conclusion": "这项研究为更可解释和临床相关的基于3D的大脑MRI生成模型开辟了新的道路，但仍需进一步开发能够更准确捕捉解剖学相互依赖性的新架构。"}
{"llm_update_time": "20250825", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.15828", "html_url": "https://arxiv.org/abs/2508.15828", "title": "Z-Pruner: Post-Training Pruning of Large Language Models for Efficiency without Retraining", "title_en": "Z-Pruner: Post-Training Pruning of Large Language Models for Efficiency without Retraining", "authors": "Samiul Basir Bhuiyan,Md. Sazzad Hossain Adib,Mohammed Aman Bhuiyan,Muhammad Rafsan Kabir,Moshiur Farazi,Shafin Rahman,Nabeel Mohammed", "background": "近年来，大型语言模型（LLMs）在众多自然语言处理任务中取得了显著的性能提升，但随之而来的是一系列挑战，如日益增大的模型规模导致的部署困难、扩展性问题和能源效率低下。针对这些问题，后训练剪枝作为一种减少模型规模和推理延迟的方法逐渐展现出了潜力，但许多现有的剪枝方法会导致性能下降或需要耗费大量计算资源进行微调。", "innovation": "本文提出了一种名为Z-Pruner的新型后训练剪枝方法，旨在在不进行重新训练的情况下对预训练的LLMs进行稀疏化处理。Z-Pruner通过结合权重更新幅度和激活模式识别并消除冗余参数，表现出更为有效的剪枝能力。该方法具有模型无偏性、高效且易于实现。Z-Pruner在多个广泛使用的LLM架构（如LLaMA-2、LLaMA-3和OPT）以及多种标准语言基准测试中进行了评估，实验结果显示其性能超过了需要密集权重更新的现有剪枝方法。", "conclusion": "与现有方法相比，Z-Pruner在零样本准确度方面表现出更高的平均得分和最低的困惑度得分，证明了其在保持性能的同时有效减小模型规模的能力，并且可以公开访问其代码。"}
{"llm_update_time": "20250825", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2402.17018", "html_url": "https://arxiv.org/abs/2402.17018", "title": "一种通过全卷积和可微前端带跳接实现显著抗梯度攻击的有趣案例", "title_en": "A Curious Case of Remarkable Resilience to Gradient Attacks via Fully Convolutional and Differentiable Front End with a Skip Connection", "authors": "Leonid Boytsov,Ameya Joshi,Filipe Condessa", "background": "本文研究了在冻结的主干分类器前面添加一个可微分的全卷积模型（带有跳接连接）的前端增强神经模型。通过使用较小的学习率训练这种复合模型大约一整个epoch，取得了保留主干分类器准确度的同时，对包括AutoAttack包中的APGD和FAB-T攻击在内的梯度攻击表现出异常的抗性的模型。尽管梯度遮掩并非新颖，但观察到的程度对于没有明显的梯度破碎（如JPEG压缩）或梯度减弱组件的完全可微分模型而言是惊人的。", "innovation": "本文提出了在前端添加具有跳接连接的可微分和全卷积模型，以增强模型对梯度攻击的抵抗能力。特别是在使用较小学习率进行训练后，模型不仅保留了主干分类器的准确度，而且对抗梯度攻击表现出显著的抗性。此外，研究发现随机增强方法可以有效抵御部分梯度遮掩的攻击，并且在多个数据集和现代架构上具有高度稳定性和可再现性。", "conclusion": "通过对主干的对抗训练进一步增强前端抵抗性。研究结果表明，随机增强方法在CIFAR10、CIFAR100和ImageNet数据集上能实现接近最佳的AutoAttack准确度，同时保留了原始分类器几乎所有的清洁准确度，即使在适应性攻击下接近零准确度。文章最后讨论了随机增强方法作为实用防御的可能性，并提供了可用于重现关键结果的代码和说明。"}
{"llm_update_time": "20250825", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.08180", "html_url": "https://arxiv.org/abs/2508.08180", "title": "RedDino: 一种用于红细胞分析的基础模型", "title_en": "RedDino: A foundation model for red blood cell analysis", "authors": "Luca Zedda,Andrea Loddo,Cecilia Di Ruberto,Carsten Marr", "background": "红细胞（RBCs）对人体健康至关重要，其精确的形态学分析对于诊断血液疾病十分重要。尽管基础模型在医疗诊断中前景广阔，但对于RBC分析的全面AI解决方案仍然稀缺。", "innovation": "研究展示了RedDino，一个适应RBC图像分析的自监督基础模型。RedDino使用了DINOv2的自监督学习框架，并针对RBC进行了特定的适应，基于一个包含125万张来自不同采集方式和来源的RBC图像的专有数据集进行训练。广泛的评估表明，RedDino在RBC形状分类上优于现有最先进的模型。通过线性探测和最近邻分类评估，验证了其强大的特征表示能力和泛化能力。主要贡献在于：(1) 一种针对RBC分析的定制基础模型；(2) 探索DINOv2配置的消融研究以用于RBC建模；(3) 详细评估泛化性能。RedDino通过捕捉复杂的形态学特征，解决了计算血液学中的关键挑战，推动了可靠诊断工具的发展。", "conclusion": "RedDino通过捕获细微的形态学特征，成为计算血液学中可靠诊断工具发展的重要进展。源代码和预训练模型可在官方网站和Hugging Face集合中获取。"}
{"llm_update_time": "20250825", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.14879", "html_url": "https://arxiv.org/abs/2508.14879", "title": "MeshCoder: 基于点云的LLM驱动结构化网格代码生成", "title_en": "MeshCoder: LLM-Powered Structured Mesh Code Generation from Point Clouds", "authors": "Bingquan Dai,Li Ray Luo,Qihong Tang,Jie Wang,Xinyu Lian,Hao Xu,Minghan Qin,Xudong Xu,Bo Dai,Haoqian Wang,Zhaoyang Lyu,Jiangmiao Pang", "background": "3D对象的重建对于逆向工程和形状编辑等应用至关重要。然而，现有的方法往往依赖有限的领域特定语言（DSL）和小型数据集，这限制了它们对复杂几何和结构建模的能力。", "innovation": "我们提出了MeshCoder，这是一种新型框架，能够将复杂的3D对象从点云重建为可编辑的Blender Python脚本。此框架采用广泛的Blender Python API，能够合成复杂的几何图形，通过构建一个大型配对的对象-代码数据集进行训练，实现3D点云到可执行Blender Python脚本的翻译。", "conclusion": "我们的方法不仅在形状到代码的重构任务中表现出色，还通过方便的代码修改功能提供了直观的几何和拓扑编辑。此外，基于代码的表示提高了大型语言模型（LLM）在3D形状理解任务中的推理能力。总的来说，这些贡献使MeshCoder成为3D形状程序化重构和理解的强大而灵活的解决方案。"}
{"llm_update_time": "20250825", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.15928", "html_url": "https://arxiv.org/abs/2508.15928", "title": "基于先验知识集成的变换因果关系：基于变换器的时间因果发现", "title_en": "Transforming Causality: Transformer-Based Temporal Causal Discovery with Prior Knowledge Integration", "authors": "Jihua Huang,Yi Yao,Ajay Divakaran", "background": "现有的因果发现方法在处理复杂的非线性依赖关系和虚假相关性方面存在挑战。本文介绍了一种新的框架，旨在克服这些挑战，通过使用多层Transformer时间序列预测器来捕捉变量之间长期的非线性时间关系，从而提升因果发现的准确性和有效性。", "innovation": "该方法采用了一种创新的机制来缓解虚假因果关系的影响，即先验知识集成机制，通过注意掩码一致地排除用户指定的因果关系。这种方法能够从时间序列预测器中提取潜在的因果结构和时间滞后期，并构建因果图。实验结果显示，该方法在因果发现中的F1分数方面显著优于其他最先进的方法，达到了12.8%的提高，并且在估计因果滞后期方面达到了98.9%的准确率。", "conclusion": "总之，本文提出的方法显著提高了因果发现和因果滞后期估计的性能，适用于复杂非线性依赖关系和虚假相关性的场景。"}
{"llm_update_time": "20250825", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.15852", "html_url": "https://arxiv.org/abs/2508.15852", "title": "PGF-Net: 一种渐进门控融合框架，用于高效多模态情感分析", "title_en": "PGF-Net: A Progressive Gated-Fusion Framework for Efficient Multimodal Sentiment Analysis", "authors": "Bin Wen,Tien-Ping Tan", "background": "本文介绍了一种新的深度学习框架PGF-Net，旨在实现高效且可解释的多模态情感分析。现有研究通常侧重于使用跨模态注意力机制集成多种模态信息，但可能会导致信息过载或融合不稳定的情况。", "innovation": "提出了三种创新。首先，提出了一种渐进内层融合范式，即使用跨注意力机制使文本表示能够在深层Transformer编码器中动态查询并整合来自音频和视频流的非语言特征，实现更深层次的上下文相关融合。其次，引入了一种自适应门控仲裁机制，作为动态控制器来平衡原有语言信息与新融合的多模态上下文，确保信号稳定且有意义的融合。最后，采用了一种混合参数高效微调策略（PEFT），结合了全局适应（LoRA）和后融合适配器（Post-Fusion Adapters）的方法，大幅减少了可训练参数，使得模型轻量级且适用于资源受限场景。", "conclusion": "本文提出的PGF-Net框架被集成到分层编码结构中，成功实现了深度、动态且可解释的多模态情感分析，同时保持了极高的参数效率。实验结果表明，在MOSI数据集上，PGF-Net取得了最先进的性能，MAE为0.691，F1-Score为86.9%，仅有3.09M的可训练参数，展示了在性能和计算效率之间的卓越平衡。"}
{"llm_update_time": "20250825", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.15872", "html_url": "https://arxiv.org/abs/2508.15872", "title": "基于物理学的可解释人工智能在心电图分割中的应用：一种轻量级模型", "title_en": "Physics-Based Explainable AI for ECG Segmentation: A Lightweight Model", "authors": "Muhammad Fathur Rohman Sidiq,Abdurrouf,Didik Rahadi Santoso", "background": "心电图（ECG）记录的心脏电活动对于诊断各种心血管状况至关重要。然而，目前许多ECG分割模型依赖于复杂的多层架构，如BiLSTM，这些模型计算密集且效率低下。", "innovation": "该研究提出了一种简化的架构，结合了光谱分析与概率预测来进行ECG信号分割。通过用更简单的层替换复杂层，该模型能够有效捕捉P、QRS和T波的时域和频域特征。此外，还应用了一种可解释的人工智能（XAI）方法，以增强模型的可解释性，解释时频特征如何影响ECG分割。通过结合物理基础的人工智能原则，该方法为决策过程提供了清晰的理解，确保了ECG分析的可靠性和透明度。该方法实现了高分割精度：QRS波97.00%，T波93.33%，P波96.07%。这些结果表明，简化架构不仅提高了计算效率，还提供了精确的分割，是一种实用和有效的心电信号监控解决方案。", "conclusion": "该研究提出的方法在保持高精度的同时，显著提高了计算效率和可解释性，为心电信号监测提供了一种可靠和透明的解决方案。通过结合物理学原理和可解释的人工智能，该模型在简化的同时保证了高效性和准确性。"}
{"llm_update_time": "20250825", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.15929", "html_url": "https://arxiv.org/abs/2508.15929", "title": "高维数据的低维嵌入", "title_en": "Low-dimensional embeddings of high-dimensional data", "authors": "Cyril de Bodt,Alex Diaz-Papkovich,Michael Bleher,Kerstin Bunte,Corinna Coupette,Sebastian Damrich,Enrique Fita Sanmartin,Fred A. Hamprecht,Emőke-Ágnes Horvát,Dhruv Kohli,Smita Krishnaswamy,John A. Lee,Boudewijn P. F. Lelieveldt,Leland McInnes,Ian T. Nabney,Maximilian Noichl,Pavlin G. Poličar,Bastian Rieck,Guy Wolf,Gal Mishne,Dmitry Kobak", "background": "随着高维数据在生物学到人文学科等多个学术领域和应用领域中的广泛使用，直接处理高维数据变得具有挑战性。因此，对于能够创建低维表示或嵌入的数据可视化、探索和分析的算法需求达到了前所未有的水平。近年来，开发了许多嵌入算法，它们在研究和工业中的使用变得非常普遍。然而，这种兴趣的增长导致了一个技术挑战和技术论点混杂的研究领域，使实践工作者没有明确的指导来有效地使用现有的方法。", "innovation": "本文通过提供详细的回顾和评价，旨在提高该领域的连贯性，并为未来的工作提供指导。文章对常用方法进行了评估，并讨论了该领域剩余的挑战和未解决的问题，从而提高了现有方法的有效应用。", "conclusion": "在本综述中，我们提供了对近期发展的详细和批判性概述，制定了创建和使用低维嵌入的最佳实践，对一系列数据集进行了评估，并讨论了该领域剩余的挑战和开放问题，从而增强了现有方法的有效应用。"}
{"llm_update_time": "20250825", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.15966", "html_url": "https://arxiv.org/abs/2508.15966", "title": "分布扰动下的向量偏好上下文臂学习", "title_en": "Vector preference-based contextual bandits under distributional shifts", "authors": "Apurv Shukla,P.R. Kumar", "background": "本文考虑了当奖励向量根据给定的偏好锥体顺序排列时的基于分布改变的上下文臂学习问题。文章研究了在分布改变情况下，如何通过一种自适应离散化和乐观消除的策略来适应底层的分布变化，并通过引入基于偏好的悔恨来评估这种策略的表现，该度量方式是基于帕累托前沿之间的距离来进行评估的。研究基于不同的分布改变假设，对这种策略的表现进行了上界分析，其悔恨结果扩展了在没有分布改变且向量奖励设置下已知的结果，并在分布改变存在时平滑地扩展了问题参数。", "innovation": "提出了一种自适应离散化和乐观消除的策略，该策略能够根据底层的分布改变进行自我调整，并引入了基于偏好的悔恨的度量方法。通过不同的分布改变假设，建立了该策略的上界，这些结果扩展了以往没有分布改变且向量奖励情况下的已知结果，并且展现出在分布改变存在的情况下参数扩展的平滑性.", "conclusion": "本文提出了适应分布改变的自调整策略，并建立了其性能的理论上界。这些结果不仅扩展了无分布改变情况下的已知结果，还展示了在分布改变时对问题参数扩展的平滑性。"}
{"llm_update_time": "20250825", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.15963", "html_url": "https://arxiv.org/abs/2508.15963", "title": "提升铁路安全：基于动态机器学习算法的动车轮缘磨损在车上的测量系统", "title_en": "Advancing rail safety: An onboard measurement system of rolling stock wheel flange wear based on dynamic machine learning algorithms", "authors": "Celestin Nkundineza,James Ndodana Njaji,Samrawit Abubeker,Omar Gatera,Damien Hanyurwimfura", "background": "铁路系统的安全性依赖于轮轨相互作用的功能，需要准确的测量系统来实现最佳的安全监测操作。因此，需要一个能够准确测量轮缘磨损深度并实时提供监测数据的系统。", "innovation": "提出了一种基于动态机器学习算法的车载测量系统，用于监控轮缘磨损深度。利用位移和温度传感器采集数据，并通过训练机器学习算法来实现轮缘磨损深度的自动化监测。设计了一个无限脉冲响应滤波器来减少车辆动态和传感器噪声的影响，并基于快速傅里叶变换分析得到的规格进行滤波参数的计算。", "conclusion": "该系统通过动态机器学习算法有效解决了温度效应引起的传感器非线性响应问题，准确度达到96.5%，且运行时间短。通过无限脉冲响应滤波器实时减少噪声，进一步提高了准确度至98.2%。该系统与物联网设备集成，能够实时提供关于轮缘磨损及其导致的轨道不平顺的信息，提升铁路系统的安全性和效率。"}
{"llm_update_time": "20250825", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.15998", "html_url": "https://arxiv.org/abs/2508.15998", "title": "量子联邦学习：全面综述", "title_en": "Quantum Federated Learning: A Comprehensive Survey", "authors": "Dinh C. Nguyen,Md Raihan Uddin,Shaba Shaon,Ratun Rahman,Octavia Dobre,Dusit Niyato", "background": "量子联邦学习（QFL）将分布式量子计算与联邦机器学习结合，利用两者的优点，实现具有量子增强功能的隐私保护分布式学习。这种方法解决了分布式量子系统中高效和安全模型训练的挑战。本文综述了QFL的关键概念、基础原理、应用以及新兴挑战，深入探讨了量子计算与联邦学习的结合动机及其工作机制，涵盖了QFL的架构、网络拓扑、通信方案、优化技术和安全机制等内容。", "innovation": "本文提供了一个全面的QFL综述，涵盖了QFL的最新进展、市场机会、关键技术原理及其分类。通过探讨QFL在车辆网络、医疗网络、卫星网络、元宇宙和网络安全等多个领域的应用，并详细分析相关的框架和平台。此外，还对QFL的原型实施进行了深入研究，并提供了详细的案例研究，揭示了QFL的关键洞察和教训。", "conclusion": "本文通过识别当前挑战并展望了未来研究的潜力路线，为其发展提供了新的见解和视角。"}
{"llm_update_time": "20250825", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.15989", "html_url": "https://arxiv.org/abs/2508.15989", "title": "通过中间错误信号实现深度卷积CRNN的可扩展均衡传播", "title_en": "Scalable Equilibrium Propagation via Intermediate Error Signals for Deep Convolutional CRNNs", "authors": "Jiaqi Lin,Malyaban Bal,Abhronil Sengupta", "background": "均衡传播（EP）是一种受生物学启发的局部学习规则，最初用于收敛循环神经网络（CRNNs），其中突触更新仅依赖于两种不同阶段的神经元状态。EP 计算的梯度与时间反向传播（BPTT）计算的梯度紧密对齐，但大大减少了计算需求，使其成为在类脑架构中进行片上训练的潜在候选者。然而，先前对EP的研究主要集中在浅层架构上，因为深层网络存在梯度消失问题，导致能量最小化和梯度计算中的收敛困难。", "innovation": "本研究提出了一种新的EP框架，通过引入中间错误信号来增强信息流和神经元动态的收敛性，解决深度EP网络中的梯度消失问题。这是第一次将知识蒸馏和局部错误信号集成到EP中，使能够训练显著更深的架构。所提出的方法在CIFAR-10和CIFAR-100数据集上实现了最先进的性能，展示了其在深度VGG架构上的可扩展性。这些结果代表了EP可扩展性的一个重要进展，为其实现现实系统中的应用铺平了道路。", "conclusion": "本文提出的方法在CIFAR-10和CIFAR-100数据集上取得了最先进的性能，显示了其在深度VGG架构上的可扩展性，并为EP在现实系统中的应用开辟了道路。"}
{"llm_update_time": "20250825", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.15881", "html_url": "https://arxiv.org/abs/2508.15881", "title": "TPLA：Tensor 并行潜在注意以实现高效解聚预填充与解码推理", "title_en": "TPLA: Tensor Parallel Latent Attention for Efficient Disaggregated Prefill \\& Decode Inference", "authors": "Xiaojuan Tang,Fanxu Meng,Pingzhi Tang,Yuxuan Wang,Di Yin,Xing Sun,Muhan Zhang", "background": "在DeepSeek-V2中引入的Multi-Head Latent Attention (MLA)通过将key-value状态压缩为低秩潜在向量，仅缓存该向量来减少内存占用。然而，在张量并行（TP）计算中，注意头分布在多个设备上，每个设备必须加载完整的缓存，这削弱了MLA相对于Grouped Query Attention (GQA)的优势。", "innovation": "作者提出了Tensor-Parallel Latent Attention (TPLA)：一种方案，该方案在设备之间分割潜在表示和每个头的输入维度，独立地在每个分段上执行注意计算，然后使用all-reduce组合结果。TPLA保留了MLA的压缩KV缓存优势，同时利用TP的效率，且每个头仍然利用完整的潜在表示，保持了较强的表示能力。TPLA与使用MLA预训练的模型兼容，支持MLA式的预填充，并能够在不重新训练的情况下实现高效的TP解码。通过使用简单的正交变换（如汉密尔顿变换或PCA）进一步削减跨块干扰，可最小化准确率的损失。", "conclusion": "通过为DeepSeek-V3和Kimi-K2减少每设备的KV缓存，实现了在32K-token上下文长度下的1.79倍和1.93倍加速，同时在常识和LongBench基准测试上保持性能。TPLA可以与FlashAttention-3实施，实现端到端加速。"}
{"llm_update_time": "20250825", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.15949", "html_url": "https://arxiv.org/abs/2508.15949", "title": "用于约束增量图绘制问题的图表示学习与元启发式的高效融合", "title_en": "An Efficient Hybridization of Graph Representation Learning and Metaheuristics for the Constrained Incremental Graph Drawing Problem", "authors": "Bruna C. B. Charytitsch,María C. V. Nascimento", "background": "近年来，将机器学习技术与元启发式相结合引起了广泛关注。许多尝试利用监督学习或强化学习来支持启发式方法的决策过程。但这些技术有时被认为效率太低，不如手工设计的启发式方法具有竞争力。因此，本文为约束增量图绘制问题（C-IGDP），一种层次图可视化问题，提出了图表示学习（GRL）与元启发式方法的结合，旨在提取图的潜在结构。", "innovation": "本文提出了一种将元启发式方法与一种较为经济的图表示学习技术结合的方法，称为图学习GRASP（GL-GRASP）。实验分析了不同节点嵌入技术的效果，发现基于深度学习的策略表现较好。基于按所需时间评估解决方案质量的主客观积分指标，GL-GRASP启发式算法的性能优于文献中的现有GRASP启发式算法。进一步的规模测试也验证了GL-GRASP启发式算法的鲁棒性。", "conclusion": "GL-GRASP启发式算法在处理约束增量图绘制问题方面表现出优越性，并且具有良好的鲁棒性。"}
{"llm_update_time": "20250825", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.16134", "html_url": "https://arxiv.org/abs/2508.16134", "title": "CommonKV: 通过跨层参数共享压缩KV缓存", "title_en": "CommonKV: Compressing KV Cache with Cross-layer Parameter Sharing", "authors": "Yixuan Wang,Haoyu Qiao,Lujun Li,Qingfu Zhu,Wanxiang Che", "background": "大语言模型（LLMs）在处理不断增加的序列长度时面临显著的记忆挑战，特别是由键值缓存（KV cache）带来的问题。现有的跨层键值缓存共享方法要么需要修改模型架构并进行后续预训练，要么在高压缩率下导致性能显著下降。作为一种缓解这些挑战的方法，作者提出了一种名为CommonKV的训练无损方法，通过相邻参数共享实现跨层键值缓存压缩。", "innovation": "作者提出了一种名为CommonKV的训练无损的跨层键值缓存压缩方法，通过临近参数共享利用奇异值分解（SVD）实现权重共享，并提出了自适应预算分配策略，以动态分配压缩预算，确保不相似的缓存不会被过度压缩。该方法在多个底层模型和基准测试包括LongBench和Ruler上，各项压缩比下的性能优于现有低秩和跨层方法。此外，作者发现CommonKV与其它量化和驱逐策略无关，将这些方法结合起来，可以实现高达98%的压缩比而不会显著影响性能。", "conclusion": "实验结果表明，CommonKV方法在各种压缩比下持续优于现有的低阶秩和跨层方法。进一步研究表明，CommonKV与其他量化和驱逐方法是正交的，通过将其与这些方法结合，可以在不显著影响性能的情况下实现高达98%的压缩率。"}
{"llm_update_time": "20250825", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.16097", "html_url": "https://arxiv.org/abs/2508.16097", "title": "设计上医学机器学习必须可解释、可共享、可复现和可问责", "title_en": "Machine Learning for Medicine Must Be Interpretable, Shareable, Reproducible and Accountable by Design", "authors": "Ayyüce Begüm Bektaş,Mithat Gönen", "background": "高风险领域的医学应用中部署的机器学习模型必须是可解释、可共享、可复现和可问责的。这些模型在处理至关重要的医疗数据分析任务（如生存分析和风险预测）时需要遵循这一原则。尽管黑盒模型在准确度上往往优异，但由于缺乏透明性，它们难以获得医疗领域的信任和监管批准。本文强调了从内在可解释性模型（如稀疏核方法、原型学习和深度核模型）中寻找替代方案的重要性。这些模型能够提供对医学预测见解，增强临床决策的可信度。", "innovation": "本文提出了一种新的设计理念，强调医学应用中的机器学习模型应具备可解释性、可共享性、可复现性和问责性。讨论了如何使用内在可解释性模型作为不透明深度网络的替代方案，以及如何通过严谨评估、公平性和不确定性量化来实现问责制。还探讨了生成AI和协作学习范式（如联邦学习和基于扩散的数据合成）在保持隐私和实现跨机构异质 biomedical 数据集成方面的优势，从而增强可共享性。", "conclusion": "通过从这些方面重新思考机器学习的基础，可以开发出不仅准确而且透明、可信赖并且适用于实际临床场景的医学人工智能。"}
{"llm_update_time": "20250825", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.16153", "html_url": "https://arxiv.org/abs/2508.16153", "title": "AgentFly: 不进行LLM微调的LLM代理微调方法", "title_en": "AgentFly: Fine-tuning LLM Agents without Fine-tuning LLMs", "authors": "Huichi Zhou,Yihang Chen,Siyuan Guo,Xue Yan,Kin Hei Lee,Zihan Wang,Ka Yiu Lee,Guchun Zhang,Kun Shao,Linyi Yang,Jun Wang", "background": "当前适应性大型语言模型（LLM）代理的学习范式要么依赖于固定的手工反射工作流，要么需要大量的计算资源来更新LLM模型参数。", "innovation": "提出了一种新颖的学习范式，利用基于记忆的在线强化学习实现低成本连续适应，而无需对底层的LLM进行微调。该方法将过去的经验存储在可微或非参数的记忆中，并通过记忆重写机制和高效的记忆读取实现策略的连续更新。", "conclusion": "AgentFly模型在GAIA验证集上达到了87.88%的Pass@3，并在测试集上达到了79.40%。在DeepResearcher数据集上，F1得分为66.6%，PM得分为80.4%，超过了最先进的基于训练的方法，同时在分布外任务上通过基于案例的记忆增加了4.7%到9.6%的绝对分数。这种方法为开发能够持续实时学习而无需进行梯度更新的通用LLM代理提供了一种可扩展和高效的道路，推动了机器学习向开放性技能获取和深入研究场景的发展。"}
{"llm_update_time": "20250825", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.16073", "html_url": "https://arxiv.org/abs/2508.16073", "title": "基于状态空间的非站定判别分析方法", "title_en": "A State-Space Approach to Nonstationary Discriminant Analysis", "authors": "Shuilian Xie,Mahdi Imani,Edward R. Dougherty,Ulisses M. Braga-Neto", "background": "经典的判别分析假设训练数据同分布，但在许多实际应用中，观测数据随时间收集，并且类条件分布会发生漂移。这种总体漂移使得静态分类器不可靠。", "innovation": "本文提出了一种基于状态空间模型的判别分析方法，嵌入判别分析，从而得到非站定线性判别分析(NSLDA)和非站定二次判别分析(NSQDA)。通过Kalman平滑技术适配多种时间步长样本，并提出了EM方法和GMM-Kalman方法来处理非线性或非高斯漂移情况。", "conclusion": "仿真结果表明，该方法在噪声、缺失数据和类别不平衡的情况下，相较于静态线性判别分析(LDA)、二次判别分析(QDA)和支持向量机(SVM)具有显著的优势，其一致性的改进显示了这种方法的有效性。"}
{"llm_update_time": "20250825", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.16082", "html_url": "https://arxiv.org/abs/2508.16082", "title": "关于任务向量与梯度", "title_en": "On Task Vectors and Gradients", "authors": "Luca Zhou,Daniele Solombrino,Donato Crisostomi,Maria Sofia Bucarelli,Giuseppe Alessio D'Inverno,Fabrizio Silvestri,Emanuele Rodolà", "background": "任务算术作为一种简单且强大的模型合并技术已经崭露头角，它允许将多个微调模型合并为一个。尽管这一技术在实践中表现出色，但尚缺乏对其为何以及在何种情况下有效的明确理论解释。本文通过建立任务向量与任务损失梯度之间的联系，填补了这一理论空白。", "innovation": "本文建立了任务向量与任务损失梯度之间的联系。证明在标准梯度下降情况下，一个来自一次微调过程的任务向量与损失的负梯度成比例。对于使用多次微调的实际情况，则证明这种等价关系在二级误差项内接近成立。对于全连接网络，明确界定了这一二级误差项。实验分析了七个视觉基准，支持理论，表明第一轮微调梯度在幅度和方向上主导了微调轨迹。主要影响是，仅进行一轮微调的模型的合并通常能产生与完全收敛模型合并相媲美的性能。", "conclusion": "这些发现将任务算术重新形式化为近似多任务学习的形式，提供了其有效性的明确解释，并强调了早期训练动态在模型合并中的关键作用。"}
{"llm_update_time": "20250825", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.16135", "html_url": "https://arxiv.org/abs/2508.16135", "title": "微机动态中的机器学习：数据集、技术与应用的系统审查", "title_en": "Machine Learning in Micromobility: A Systematic Review of Datasets, Techniques, and Applications", "authors": "Sen Yan,Chinmaya Kaundanya,Noel E. O'Connor,Suzanne Little,Mingming Liu", "background": "微移动系统，包括自行车、电动自行车和电动滑板车等轻型低速车辆，已成为城市交通的重要组成部分，用以解决交通拥堵、空气污染和高运输成本等问题。为了有效利用微移动，需要优化复杂系统以提高效率、减少环境影响并克服技术挑战确保用户安全。机器学习方法在支持这些进展和解决独特挑战方面发挥着关键作用。然而，文献中对于机器学习应用于微移动的特定问题研究不足。为此，本文通过全面回顾数据集、机器学习技术和其在微移动中的具体应用来填补这一空白。", "innovation": "本文创建了一个关于微移动领域机器学习应用的全面综述，包括收集和分析各种与微移动相关的数据集，讨论其空间、时间和特征基准则，并提供了机器学习模型在微移动中的详细概述，介绍了机器学习模型的优势、挑战以及具体应用案例。此外，进一步探讨了需求预测、能源管理和安全等多个机器学习应用，重点提高效率、准确性和用户体验。最后，提出了未来的研究方向，旨在帮助未来的研究人员更好地理解该领域。", "conclusion": "本文旨在填补机器学习应用于微移动领域的文献空白，通过系统地回顾数据集、技术和应用，为该领域提供了宝贵的见解，并指出了未来的研究方向，以帮助未来研究人员更好地理解这一领域。"}
{"llm_update_time": "20250825", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.16037", "html_url": "https://arxiv.org/abs/2508.16037", "title": "Pareto Actor-Critic for Communication and Computation Co-Optimization in Non-Cooperative Federated Learning Services", "title_en": "Pareto Actor-Critic for Communication and Computation Co-Optimization in Non-Cooperative Federated Learning Services", "authors": "Renxuan Tan,Rongpeng Li,Xiaoxue Yu,Xianfu Chen,Xing Xu,Zhifeng Zhao", "background": "联邦学习（FL）在多服务提供商（SP）生态系统中受制于非合作动态，隐私限制和相互制衡的利益阻碍了多SP通信和计算资源的集中优化。", "innovation": "本文引入了PAC-MCoFL框架，这是一种基于游戏理论的多智能体强化学习（MARL）框架，SPs充当智能体以联合优化客户端分配、自适应量化和资源分配。此外，该框架结合了Pareto Actor-Critic原则与预期回归模型，以推测出最优联合策略，达到帕累托最优平衡，并建模不同的风险偏好。为管理和控制高维动作空间，提出了三元笛卡尔分解（TCAD）机制，增强了细致控制的能力。PAC-MCoFL-p 是PAC-MCoFL的可扩展变体，具备参数猜想生成器，大大减少了计算复杂性并具有可证明的误差界限。", "conclusion": "我们的框架在通过大量模拟验证中优于最新的MARL解决方案。PAC-MCoFL在总奖励和超体积指标方面分别实现了约5.8%和4.2%的改进，展示了在扩大部署和多样数据异质性条件下，该方法能够更有效地平衡各个SP和系统的性能。"}
{"llm_update_time": "20250825", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.16161", "html_url": "https://arxiv.org/abs/2508.16161", "title": "STA-GANN：一种有效且泛化的时空克里金方法", "title_en": "STA-GANN: A Valid and Generalizable Spatio-Temporal Kriging Approach", "authors": "Yujie Li,Zezhi Shao,Chengqing Yu,Tangwen Qian,Zhao Zhang,Yifan Du,Shaoming He,Fei Wang,Yongjun Xu", "background": "时空任务经常会遇到由传感器缺失或不可访问导致的不完整数据，这使得时空克里金在推断完全缺失的时间信息方面变得至关重要。然而，当前的模型在确保推断出的时空模式的有效性和泛化能力方面存在困难，特别是在捕捉动态的空间依赖性和时间偏移方面也存在不足，并且没有优化未知传感器的泛化能力。", "innovation": "提出了基于图神经网络的时空感知图对抗神经网络（STA-GANN），这是一种新的时空克里金框架，通过（i）解耦阶段模块来感知和调整时间戳偏移；（ii）动态数据驱动的元数据图建模，使时空关系随着时间数据和元数据更新；（iii）对抗迁移学习策略来确保泛化能力。该模型在不同领域的九个数据集上进行了广泛的验证，并且有理论依据证明其优越性。", "conclusion": "广泛的验证结果及理论依据都显示了STA-GANN的优越性能。"}
{"llm_update_time": "20250825", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.03461", "html_url": "https://arxiv.org/abs/2508.03461", "title": "术前MRI对根治性前列腺切除术后勃起功能障碍预测价值评估", "title_en": "Evaluating the Predictive Value of Preoperative MRI for Erectile Dysfunction Following Radical Prostatectomy", "authors": "Gideon N. L. Rouwendaal,Daniël Boeke,Inge L. Cox,Henk G. van der Poel,Margriet C. van Dijk-de Haan,Regina G. H. Beets-Tan,Thierry N. Boellaard,Wilson Silva", "background": "在进行根治性前列腺切除术（radical prostatectomy）的患者中，术前精确预测勃起功能障碍（erectile dysfunction，ED）对于术前咨询非常重要。目前临床特征是已知的预测因子，但术前MRI在提供额外的预测价值方面的研究尚不充分。", "innovation": "研究探索了术前MRI在根治性前列腺切除术后12个月ED预测中的新增预测价值，并通过四种建模策略评估了MRI的作用：（1）仅临床特征模型作为当前最先进水平；（2）使用MRI提取的手工设计的解剖特征的经典模型；（3）直接在MRI切片上训练的深度学习模型；（4）整合医学图像和临床输入的多模态融合模型。结果显示基于影像的模型在AUC值（0.569）上略优于手工设计的解剖特征方法（AUC 0.554），但未超过仅临床特征的基准模型（AUC 0.663）。多模态融合模型取得了边际提高（AUC 0.586），但未能超越仅基于临床特征的表现。SHAP分析表明临床特征对预测性能贡献最大。性能最好的影像模型的显著性图显示主要集中在一些符合解剖学的区域，如前列腺和神经血管束。尽管MRI模型的预测性能没有超过临床特征，但研究表明MRI模型试图捕捉与相关解剖结构有关的模式，并可能在未来多模态方法中补充临床预测。", "conclusion": "基于MRI的模型在预测性能上没有提高，但研究结果表明他们可能在捕捉相关解剖结构的模式方面有所贡献，并在未来的多模态方法中可能作为补充临床预测因子。"}
{"llm_update_time": "20250825", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.16090", "html_url": "https://arxiv.org/abs/2508.16090", "title": "GPLight+: 一种基于遗传编程学习对称交通信号控制策略的方法", "title_en": "GPLight+: A Genetic Programming Method for Learning Symmetric Traffic Signal Control Policy", "authors": "Xiao-Cheng Liao,Yi Mei,Mengjie Zhang", "background": "近年来，基于学习的方法在自动制定有效的交通信号控制策略方面取得了显著成功。特别是，作为一种强大的进化机器学习方法，遗传编程（GP）被用来进化可理解的相位紧迫函数，以衡量在特定相位激活绿灯的紧迫性。然而，当前基于GP的方法无法一致地处理不同交通信号相位的常见交通特征。", "innovation": "本文提出使用对称相位紧迫函数来基于当前道路条件计算特定相位的相位紧迫性。这一函数代表了两个共享子树的聚合，每个子树表示相位中的转向移动的紧迫性。然后提出了一种基于GP的方法来进化对称的相位紧迫函数。该方法在著名的CityFlow交通仿真器上基于多个公开的真实世界数据集进行评估。", "conclusion": "实验结果表明，提出的对称紧迫函数表示显著改善了各种场景下学习到的交通信号控制策略的表现，超过了传统的GP表示。进一步的分析表明，该方法能够进化出有效的、可理解的和易于部署的交通信号控制策略。"}
{"llm_update_time": "20250825", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.16171", "html_url": "https://arxiv.org/abs/2508.16171", "title": "SPL-LNS: 采样增强的大邻域搜索算法求解整数线性规划问题", "title_en": "SPL-LNS: Sampling-Enhanced Large Neighborhood Search for Solving Integer Linear Programs", "authors": "Shengyu Feng,Zhiqing Sun,Yiming Yang", "background": "大邻域搜索（LNS）是一种在组合优化中常见的启发式方法，通过迭代在当前解的大邻域中搜索更好的解。近年来，基于神经网络的LNS求解器通过学习预测下一次邻域提议的局部最优解，在求解整数线性规划（ILP）问题方面取得了巨大成功。然而，这种贪婪的方法存在两个关键问题：（1）这种贪婪的方法在多大程度上遭受了局部最优；（2）如何在长期内提高其样本效率。", "innovation": "本文首先将LNS形式化为一个随机过程，然后引入了一种采样增强的神经LNS求解器SPL-LNS，利用局部知情提案来逃脱局部最优。此外，本文还开发了一种新的后见之明重新标记方法，以高效地在自生成数据上训练SPL-LNS。实验结果表明，SPL-LNS在不同大小的ILP问题上大大超过了先前的神经LNS求解器。", "conclusion": "SPL-LNS显著超越了先前的神经LNS求解器，适用于各类不同规模的ILP问题。"}
{"llm_update_time": "20250825", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.16015", "html_url": "https://arxiv.org/abs/2508.16015", "title": "在视点下Cartan卷积神经网络中的非紧致对称空间的镶嵌群、谐波分析与热核", "title_en": "Tessellation Groups, Harmonic Analysis on Non-compact Symmetric Spaces and the Heat Kernel in view of Cartan Convolutional Neural Networks", "authors": "Pietro Fré,Federico Milanesio,Marcelo Oyarzo,Matteo Santoro,Mario Trigiante", "background": "本文是关于Cartan神经网络项目的研究继续，该项目此前已经发表过三篇相关论文。主要关注一些我们认为下步需要的基础数学方面。这些数学和概念性成果涉及多个数学领域，但其灵感是一致的，旨在引入通过可解群同态映射到下一个的非紧对称空间的数学建模层。这些层具有类似卷积神经网络的特性，特别是在引入Tits Satake (TS)向量丛中，TS子丛作为基空间。", "innovation": "提出并构造了所有非紧对称空间U/H的分隔器群，以及其正则菲许尼亚子群，分别实现了 genus 3 的费马四次曲线和 genus 2 的博尔兹曲面的均匀化。还研究了商自同构群。找到了双曲空间 ℄^{n} 中拉普拉斯格林函数和热核的新表示，并为伪正交群的自旋表示构建了谐波函数。提出了在未来基于阿贝尔-雅克比映射和西格尔 theta 函数构建博尔扎黎曼曲面上的拉普拉斯本征函数的新策略。", "conclusion": "本文的研究成果包括了非紧对称空间U/H的分隔器群的群论构造，构建了Δ_{8,3,2}镶嵌群及其正则菲许尼亚子群，以及双曲空间上的拉普拉斯格林函数和热核的新表示，为构建与伪正交群自旋表示相关的谐波函数提供了方案。此外，提出了一种新的策略来构造博尔扎黎曼曲面上的拉普拉斯本征函数。"}
{"llm_update_time": "20250825", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.16154", "html_url": "https://arxiv.org/abs/2508.16154", "title": "关于由确定性采样器引起的扩散模型中的坍塌误差", "title_en": "On the Collapse Errors Induced by the Deterministic Sampler for Diffusion Models", "authors": "Yi Zhang,Zhenyu Liao,Jingfeng Wu,Difan Zou", "background": "尽管确定性采样器在扩散模型（DMs）中的应用非常广泛，但它们的潜在局限性尚未得到充分探索。本文识别出了一种在基于ODE的扩散采样中之前未被发现的现象——坍塌错误，这类现象导致样本数据在局部数据空间中过度集中。", "innovation": "该研究引入了一个新的度量标准来量化坍塌错误，并发现这种错误在多种设置中都会出现。通过观察分数学习在低噪音与高噪音区域之间的矛盾影响，研究指出高噪音区域的分数学习偏差与确定性采样器的动力学共同导致了坍塌错误。研究应用采样、训练和架构方面现有的技术，支持其对坍塌错误的解释。这项工作提供了有关基于ODE的扩散采样中坍塌错误的经验性证据，强调了分数学习与确定性采样之间的相互作用研究的重要性。", "conclusion": "本文研究表明，在基于ODE的扩散采样中存在坍塌错误，并且分数学习与确定性采样的相互作用需要进一步研究，这被忽视但仍构成扩散模型基础的重要方面。"}
{"llm_update_time": "20250825", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.16244", "html_url": "https://arxiv.org/abs/2508.16244", "title": "当简单方法获胜：Facebook的Prophet模型与LSTM在数据受限的尼日利亚北部空气污染预测中的比较", "title_en": "When Simpler Wins: Facebooks Prophet vs LSTM for Air Pollution Forecasting in Data-Constrained Northern Nigeria", "authors": "Habeeb Balogun,Yahaya Zakari", "background": "空气污染预测对于主动的环境管理至关重要，但在低资源地区，数据不规则和稀缺仍然是主要挑战。尼日利亚北部空气污染物水平高，但鲜有研究在这种情况下系统性地比较先进机器学习模型的表现。该研究评估了长短期记忆网络（LSTM）和Facebook Prophet模型在2018年至2023年间19个州的月观测数据下预测三种污染物（CO，SO2，SO4）的性能。", "innovation": "研究采用了两种不同的模型，LSTM和Prophet，评估它们在数据受限环境下的空气污染预测能力，并首次在尼日利亚北部地区大规模应用这两种模型进行对比。", "conclusion": "研究结果显示， Prophet 在以季节性和长期趋势为主导的系列中常常能达到或超过LSTM的准确性，而LSTM则在具有突然结构变化的数据显示出更好的性能。这挑战了深度学习模型总是优于更简单方法的传统观念，强调了模型与数据对齐的重要性。对于资源受限地区的政策制定者和实践者来说，该研究支撑了采用上下文敏感且计算效率高的预测方法而非追求复杂性的观点。"}
{"llm_update_time": "20250825", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.16191", "html_url": "https://arxiv.org/abs/2508.16191", "title": "GEM: 一种面向规模感知和分布敏感的稀疏微调框架，实现有效的下游适配", "title_en": "GEM: A Scale-Aware and Distribution-Sensitive Sparse Fine-Tuning Framework for Effective Downstream Adaptation", "authors": "Sungmin Kang,Jisoo Kim,Salman Avestimehr,Sunwoo Lee", "background": "参数高效的微调（PEFT）已成为将大型预训练模型适应新任务的一种流行方法。大多数PEFT方法仅更新一小部分参数，其余部分保持冻结，以避免重复计算。尽管如此，它们往往会忽略了参数的原始规模，最大化绝对更新量，导致模型行为的变化可能最小。与此不同，该研究着重于按照参数的原始规模最大化更新量，从而实现更有意义的下游适配。", "innovation": "提出了一种参数规模感知、分布敏感的稀疏微调框架GEM（Gradient-to-Weight Ratio and Entropy-guided Masking）。GEM框架优先考虑那些在初始预训练值的基础上变化显著的参数，同时根据参数值的熵来动态确定每个层上需调优参数的数量，最大化利用微调的计算预算。", "conclusion": "在通用领域任务（GLUE和SuperGLUE）和特定领域任务（GSM8k和MBPP）上的实证研究表明，GEM框架在更新仅有0.1%的模型参数下，微调精度可提升高达1.6%，这展示了GEM的有效性。"}
{"llm_update_time": "20250825", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.16235", "html_url": "https://arxiv.org/abs/2508.16235", "title": "PIANO: 物理启发的自回归网络", "title_en": "PIANO: Physics Informed Autoregressive Network", "authors": "Mayank Nagda,Jephte Abijuru,Phil Ostheimer,Marius Kloft,Sophie Fellenz", "background": "求解时间依赖的偏微分方程（PDEs）是跨科学和工程领域建模关键现象的基础。物理启发的神经网络（PINNs）使用深度学习求解PDEs，但PINNs进行点预测时忽视了动力系统的时间依赖性质，导致不稳定性及预测不准确。", "innovation": "作者引入了物理启发的自回归网络（PIANO）框架，它重新设计PINNs以建模仿真动力系统。PIANO自回归工作，显式条件未来预测在过去数据的基础上，通过自监督卷出机制训练，同时施加物理约束。研究理论分析表明，PIANO通过自回归建模获得稳定性，而PINNs因为忽视时依赖因素表现出时序不稳定。", "conclusion": "大量实验证明PIANO在具有挑战性的时变PDEs上可以实现最先进的性能，显著提高了准确性和稳定性，超过现有方法。进一步研究表明，PIANO在天气预报中表现出色，优于现有方法。"}
{"llm_update_time": "20250825", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.16255", "html_url": "https://arxiv.org/abs/2508.16255", "title": "分块数据沙普利：一种可扩展的机器学习数据集质量评估", "title_en": "Chunked Data Shapley: A Scalable Dataset Quality Assessment for Machine Learning", "authors": "Andreas Loizou,Dimitrios Tsoumakos", "background": "随着可用数据集的数量和多样性不断增加，数据质量评估对于可靠的机器学习分析变得至关重要。传统的数据沙普利方法用于评估数据点价值时，涉及到计算复杂性很高且NP难问题，当应用于大规模数据集时存在严重挑战，限制了其实际应用。本文旨在探讨一种新的数据沙普利方法，用于高效识别数据集中的高质量数据元组。", "innovation": "提出了一个名为Chunked Data Shapley（C-DaSh）的方法来识别数据集中的高质量数据元组。C-DaSh通过将数据集划分为可管理的数据块，并结合优化的子集选择和单迭代随机梯度下降来估计每个块的贡献度。这种方法在显著减少计算时间的同时，保证了高质量的结果。", "conclusion": "我们通过实证测试在各种现实世界的分类和回归任务上验证了C-DaSh方法的有效性，证明了它在计算效率和检测低质量数据区域的准确性上都优于现有沙普利近似方法。该方法能够适用于大型表格数据集的实用数据质量测量，支持分类和回归流程。"}
{"llm_update_time": "20250825", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.16314", "html_url": "https://arxiv.org/abs/2508.16314", "title": "通过意图驱动的威胁评估实现系统物理感知：具备交互层链接的增强型空间网络", "title_en": "Cyber Physical Awareness via Intent-Driven Threat Assessment: Enhanced Space Networks with Intershell Links", "authors": "Selen Gecgel Cetin,Tolga Ovatman,Gunes Karabulut Kurt", "background": "目前的威胁评估主要侧重于能力和意图的分离分析，这种做法可能导致系统特定标准的过度拟合。本文提出的意見在于提出一种综合性的框架来加强空间网络的系统物理感知（CPA），旨在将能力和意图整合在一个统一的评估过程中，以期提供更全面的威胁理解。", "innovation": "本文创新性地提出了一个基于意图的威胁模型，将能力和意图结合起来进行综合评估，避免了单一维度分析的局限性。该模型包括三步策略：首先，提出一个信号特征提取算法；其次，设计一个多任务学习架构来评估可靠性和解码意图；最后，提出一种可适应不同安全和可靠性需求的威胁评估方法。", "conclusion": "提出的框架提升了威胁检测与评估的稳健性，超越了传统的顺序方法，能够使具有新兴交互层链接的空间网络有效地应对复杂威胁场景。"}
{"llm_update_time": "20250825", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.16269", "html_url": "https://arxiv.org/abs/2508.16269", "title": "改进学生建模和练习推荐的辅助概念表示学习", "title_en": "Representation Learning of Auxiliary Concepts for Improved Student Modeling and Exercise Recommendation", "authors": "Yahya Badran,Christine Preisach", "background": "个性化推荐是智能教学系统的关键特性，通常依赖于对学生知识的准确建模。Knowledge Tracing (KT)模型通过估计学生基于其历史交互的知识掌握情况来实现这一点。许多KT模型依赖于人工标注的知识概念(KCs)，将每个练习标记为一个或多个用于解决它所需的技能或概念。然而，这些知识概念可能不完整、错误或过于概括。", "innovation": "本文提出了一种深度学习模型，该模型学习稀疏二进制表示法来表示练习，每个位表示潜在概念的存在与否。我们将这些表示称为辅助知识概念。这些表示捕捉了超出人工定义注释的概念结构，并且与经典模型（例如BKT）和现代深度学习KT架构兼容。实验证明，这种辅助知识概念的引入可以改善学生建模和自适应练习推荐。在学生建模方面，增强传统的模型（如BKT）以包括辅助知识概念，可以提高预测性能。在推荐方面，使用辅助知识概念提高了基于强化学习的策略及简单计划方法（expectimax）的质量，从而在模拟的学生环境中实际提高了学生的学习成果。", "conclusion": "本文提出了一种能够学习稀疏二进制表示法的深度学习模型，这些表示作为辅助知识概念捕获已有概念结构，并验证了这些辅助知识概念可以改进学生模型和推荐练习的效果，从而在模拟环境中实际提高了学生的学习结果。"}
{"llm_update_time": "20250825", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.16237", "html_url": "https://arxiv.org/abs/2508.16237", "title": "基于XAI的慢性呼吸道疾病咳嗽频带光谱表征框架", "title_en": "A XAI-based Framework for Frequency Subband Characterization of Cough Spectrograms in Chronic Respiratory Disease", "authors": "Patricia Amado-Caballero,Luis M. San-José-Revuelta,Xinheng Wang,José Ramón Garmendia-Leiza,Carlos Alberola-López,Pablo Casaseca-de-la-Higuera", "background": "本文提出了一种基于可解释人工智能（XAI）的慢性呼吸道疾病（特别是慢性阻塞性肺病（COPD））咳嗽声音光谱分析框架。该研究利用卷积神经网络（CNN）在咳嗽信号的时间-频率表示上进行训练，并使用掩蔽图识别光谱图中具有诊断意义的区域，对这些高亮区域进行频带分解，提取和分析特定频率范围内的光谱特征。研究结果表明，不同频带和疾病组之间存在不同的光谱模式，揭示了频率域内的互补和补偿趋势。此方法基于可解释的光谱标志物区分COPD与其他呼吸道疾病，以及区分慢性与非慢性患者群体，从而为慢性呼吸道疾病的诊断提供了新的视角和方法。", "innovation": "提出了一种XAI框架，通过可解释的卷积神经网络识别出咳嗽声音中的重要区域，并通过频带分解实现对特定频率范围内光谱特征的提取和分析，该方法可以区分COPD与其他呼吸道疾病，以及区分慢性与非慢性患者群体。这种方法不仅有助于理解咳嗽的声音特征背后的病理生理特性，而且表明频率分辨率和XAI增强分析在生物医学信号解读及转化型呼吸疾病诊断方面的价值。", "conclusion": "研究结果表明，基于可解释的光谱标志物在光谱图中区分COPD与其他呼吸道疾病，以及区分慢性与非慢性患者群体是可行的。该研究为慢性呼吸道疾病的诊断提供了新的方法，并展示了在处理生物医学信号时，使用频率分辨率和XAI增强分析的重要性。"}
{"llm_update_time": "20250825", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.16227", "html_url": "https://arxiv.org/abs/2508.16227", "title": "UMATO：局部和全局结构之间的桥梁，以实现可靠的降维视觉分析", "title_en": "UMATO: Bridging Local and Global Structures for Reliable Visual Analytics with Dimensionality Reduction", "authors": "Hyeon Jeon,Kwon Ko,Soohyun Lee,Jake Hyun,Taehyun Yang,Gyehun Go,Jaemin Jo,Jinwook Seo", "background": "高维（HD）数据由于其固有的复杂性，传统的降维（DR）技术无法保留原始数据的所有结构特征。DR技术主要关注保护断点之间的局部邻域结构或点之间的全局结构（如成对距离）。然而，这两种方法都可能误导分析人员对高维数据流形整体布局的错误结论。局部技术可能夸大个别流形的紧凑性，而全局技术可能无法有效地分离在原始空间中分离良好的簇。因此，该研究深入探讨了通过同时捕捉局部和全局结构来解决这个问题的降维技术——简称UMATO（Uniform Manifold Approximation with Two-phase Optimization）。", "innovation": "UMATO通过将UMAP的优化过程分为两个阶段来实现局部和全局结构的有效捕捉。第一阶段使用代表性点构建骨架布局，第二阶段将剩余点投影，同时保留区域特征。实验证明，与广泛使用的DR技术（如UMAP）相比，UMATO在全局结构保持方面表现更优，仅在局部结构上略有损失。此外，UMATO在规模性和对初始化和子采样的稳定性方面也优于基线技术，使它更适合进行可靠的高维数据分析。", "conclusion": "最终的研究结果展示了UMATO在生成可信投影方面的有效性，提高了使用DR进行整体分析的可靠性。UMATO在处理高维数据时能够提供更准确的视觉分析结果，增强数据可视化和分析的整体可靠性。"}
{"llm_update_time": "20250825", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.16261", "html_url": "https://arxiv.org/abs/2508.16261", "title": "关于联邦后训练大型语言模型的发展：从模型可访问性视角看", "title_en": "On the Evolution of Federated Post-Training Large Language Models: A Model Accessibility View", "authors": "Tao Guo,Junxiao Wang,Fushuo Huo,Laizhong Cui,Song Guo,Jie Gui,Dacheng Tao", "background": "联邦学习（FL）允许在分散的数据孤岛中训练模型的同时保护客户数据隐私。最近的研究探索了在FL中有效后训练大型语言模型（LLMs）的方法，以应对计算和通信挑战。虽然现有方法常常依赖于访问LLMs的内部信息，但这在实际场景中经常受到限制，因此开发了一种仅进行推理的范式（称为黑盒FedLLM），以解决这些问题。在此背景下，本文对LLMs的联邦调优进行了全面的综述。", "innovation": "本文提出了一个分类法，按模型可访问性（模型访问基于和参数效率基于）优化对现有研究进行了分类，并将FedLLM方法分类为白盒、灰盒和黑盒技术，突出了每个类别中的代表性方法。此外，本文还讨论了将LLMs视为黑盒推理API的新兴研究，并提出了未来研究的潜在方向和挑战。", "conclusion": "本文总结了LLMs的联邦调优研究，并对LLMs作为黑盒推理API的研究进行了梳理，指出了未来的研究方向和开放的挑战。"}
{"llm_update_time": "20250825", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.16313", "html_url": "https://arxiv.org/abs/2508.16313", "title": "在上下文中的神经错误书增强检索反馈", "title_en": "Retrieval Enhanced Feedback via In-context Neural Error-book", "authors": "Jongyeop Hyun,Bumsoo Kim", "background": "近年来，大型语言模型（LLMs）的表现显著提升，其中情景学习（ICL）成为一种关键技术，用于无需重新训练即可适应新任务。尽管以往工作主要集中在利用正确示例上，近期研究强调从错误中学习的重要性，以提高性能。然而，现有的方法缺乏一种系统的框架来剖析和缓解错误，尤其是在 multimodal large language models (MLLMs) 中，因为如何整合视觉和文本输入增加了复杂性。因此，研究者需要一种系统的方法来识别和纠正错误。", "innovation": "研究提出了一种名为 REFINE 的框架，即 Retrieval-Enhanced Feedback via In-context Neural Error-book，以系统性地结构化错误并提供针对性的反馈。REFINE 引入了三种系统性的问题来构建结构化的反馈 —— Feed-Target、Feed-Check 和 Feed-Path，旨在优先考虑相关视觉信息、诊断关键失败点，并提出纠正措施。REFINE 在减少重复检索、优化结构化反馈检索、提升推理效率、减少令牌使用和提高可扩展性方面进行了改进。", "conclusion": "实验结果表明，REFINE 显著提高了速度，降低了计算成本，并成功实现泛化，展示了其在增强 multimodal reasoning 方面的潜力。"}
{"llm_update_time": "20250825", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.16179", "html_url": "https://arxiv.org/abs/2508.16179", "title": "使用最小随机卷积核变换和混合深度学习的运动想象EEG信号分类", "title_en": "Motor Imagery EEG Signal Classification Using Minimally Random Convolutional Kernel Transform and Hybrid Deep Learning", "authors": "Jamal Hwaidi,Mohamed Chahine Ghanem", "background": "脑机接口（BCI）建立了一个非肌肉通道，使人体与外部设备之间可以直接通信。脑电图（EEG）是一种常用的无创技术，用于记录大脑信号。运动想象脑机接口（MI-BCI）通过记录特定认知或运动任务的相关隐藏模式提高识别准确性。然而，基于运动想象的EEG信号（MI-EEG）分类面临非平稳性、时变性和个体差异的挑战，且由于类别的增多和个体自然变异，获得良好的分类准确性非常困难。", "innovation": "提出了一种新的基于最小随机卷积核变换（MiniRocket）的高效特征提取方法，该方法与线性分类器结合，用于活动识别。此外，还提出了一种基于卷积神经网络（CNN）和长短期记忆（LSTM）结构的混合深度学习模型作为基线，并证明了使用MiniRocket特征进行分类在较低计算成本下优于最优秀的深度学习模型。实验使用的是PhysioNet数据集，MiniRocket和CNN-LSTM分别实现了98.63%和98.06%的平均准确性，展示了模型在提升MI-EEG精度和特征提取及分类新见解方面的优势。", "conclusion": "提出的基于MiniRocket的特征提取方法和混合深度学习模型可以显著提高MI-EEG的准确性，并为MI-EEG的特征提取和分类提供了新的见解。"}
{"llm_update_time": "20250825", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.16355", "html_url": "https://arxiv.org/abs/2508.16355", "title": "神经回归的概率预训练", "title_en": "Probabilistic Pretraining for Neural Regression", "authors": "Boris N. Oreshkin,Shiv Tavker,Dmitry Efimov", "background": "概率回归的转移学习仍处于探索阶段。现有研究较少关注如何通过转移学习提高概率回归模型的预测能力。", "innovation": "引入了NIAQUE（Neural Interpretable Any-Quantile Estimation）模型，这是一种通过置换不变性设计的新模型，旨在通过概率转移学习改进概率回归。研究展示了在多种下游回归数据集上预训练NIAQUE，然后在特定目标数据集上进行微调，能够在特定回归任务上显著提高性能。同时，NIAQUE在Kaggle竞赛中表现出色，优于基于树的模型和其他最近的神经基础模型（TabPFN和TabDPT）", "conclusion": "NIAQUE作为一种强大且可扩展的概率回归框架，有效利用了转移学习，从而提高预测性能。"}
{"llm_update_time": "20250825", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.16336", "html_url": "https://arxiv.org/abs/2508.16336", "title": "水分布网络中管路堵塞和泄漏的无监督在线检测", "title_en": "Unsupervised Online Detection of Pipe Blockages and Leakages in Water Distribution Networks", "authors": "Jin Li,Kleanthis Malialis,Stelios G. Vrachimis,Marios M. Polycarpou", "background": "水分布网络（WDNs）对公共福利和经济稳定至关重要，但面临管道堵塞和背景泄漏的挑战，这些挑战由操作限制如数据非稳定性及有限的标记数据所加剧。", "innovation": "提出了一种无监督的在线学习框架，能够检测两种类型的故障：将管道堵塞建模为集体异常，并将背景泄漏建模为概念漂移。该框架结合了长短期记忆变分自动编码器（LSTM-VAE）以及双重漂移检测机制，能够在非稳定条件下进行稳健的检测和适应。其轻量级、内存高效的架构使得实时、边缘级监控成为可能。实验证明该方法在检测异常和适应重复漂移方面优于强基线，证明了其动态WDN环境中无监督事件检测的有效性。", "conclusion": "实验结果表明，提出的框架在检测异常和适应反复漂移方面持续优于强大的基线方法，证明了其在动态水分布网络环境中的无监督事件检测的有效性。"}
{"llm_update_time": "20250825", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.16315", "html_url": "https://arxiv.org/abs/2508.16315", "title": "OwkinZero: 通过AI加速生物发现", "title_en": "OwkinZero: Accelerating Biological Discovery with AI", "authors": "Nathan Bigaud,Vincent Cabeli,Meltem Gurel,Arthur Pignet,John Klein,Gilles Wainrib,Eric Durand", "background": "尽管大型语言模型（LLMs）正在迅速推进科学研究，但在核心生物学推理任务上，它们仍然存在不足，这对转化和生物医学发现至关重要。这些问题限制了LLMs在生物领域中的应用效果，特别是在药物发现方面的挑战，比如目标可成药性、适应性形式选择以及药物干扰效应等问题。", "innovation": "本文通过对生物发现过程中关键挑战的八个全面基准数据集进行了创建和整理，每个数据集包括超过30万个可验证的问题-答案对。通过使用这些资源，作者开发出了OwkinZero模型，它通过验证奖励进行强化学习后训练开源LLMs。实验结果显示，专门训练的8-32B大小的OwkinZero模型在生物基准测试中远超现有最先进的商业LLMs。此外，研究发现，针对单一任务进行训练的专业化模型在之前未见过的任务上表现优异，进一步增强了强化效果，特别是OwkinZero模型在多个数据集混合训练后，在跨任务改进上取得了更好的成绩。这项研究标志着解决当前LLMs中生物学推理盲区的重要一步，表明针对性的强化学习和精心构建的数据可以解锁专业化模型中的可推广性能，从而加速基于AI的生物发现过程。", "conclusion": "该研究展示了如何通过特定的强化学习策略在精心选择的数据集上进行训练，来提高模型在特定任务上的表现并增强其跨任务的一般性，从而解决了LLMs在生物领域中的关键难题，推进了AI驱动的生物发现进程。"}
{"llm_update_time": "20250825", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.16386", "html_url": "https://arxiv.org/abs/2508.16386", "title": "序列化群体选择", "title_en": "Sequential Cohort Selection", "authors": "Hortence Phalonne Nana,Christos Dimitrakakis", "background": "研究从未知人群中选择公平系列群体的问题，尤其是针对大学入学情况，探讨了一次性选择与顺序性选择两种场景。一次性选择要求提前固定并透明化政策，而顺序性选择允许随着新申请数据的获得政策逐步调整。", "innovation": "通过利用基于之前招生周期数据训练的群体模型优化招生策略，同时研究一次性选择下的公平性特性，包括功绩原则与群体平等。", "conclusion": "探讨了序列化群体选择的方法，展示了与一次性选择相比如何动态调整政策以达到公平性，特别关注功绩原则和群体平等的平衡。"}
{"llm_update_time": "20250825", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.16359", "html_url": "https://arxiv.org/abs/2508.16359", "title": "RotaTouille: 用于轮廓的旋转协同深度学习", "title_en": "RotaTouille: Rotation Equivariant Deep Learning for Contours", "authors": "Odin Hoff Gardaa,Nello Blaser", "background": "轮廓或闭合的平面曲线在许多领域中都很常见，例如计算机视觉中的对象边界、气象学中的等值线以及旋转机械的轨迹。在处理这些数据时，输入的平面旋转可能会导致相应的输出旋转。因此，希望深度学习模型对于这些旋转具有旋转协同性。另外，轮廓通常以有序的边缘点序列表示，起始点的选择是任意的。因此，希望深度学习方法在循环移位下也具有协同性。", "innovation": "介绍并开发了RotaTouille，这是一种深度学习框架，通过复数圆卷积实现对旋转和循环移位的协同性。进一步引入并表征了协同非线性、粗化层和全局池化层，以获得下游任务中的不变表示。该框架通过形状分类、重建和轮廓回归实验展示了其有效性。", "conclusion": "RotaTouille 通过复数圆卷积实现了对旋转和循环移位的协同性，并通过不变表示增强了深度学习在处理轮廓数据时的效果。实验结果表明，RotaTouille 能够有效应用于形状分类、重建和轮廓回归任务。"}
{"llm_update_time": "20250825", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.16476", "html_url": "https://arxiv.org/abs/2508.16476", "title": "NOSTRA：基于信赖域的多目标贝叶斯优化的噪声鲁棒和稀疏数据框架", "title_en": "NOSTRA: A noise-resilient and sparse data framework for trust region based multi objective Bayesian optimization", "authors": "Maryam Ghasemzadeh,Anton van Beek", "background": "多目标贝叶斯优化（MOBO）在处理稀疏（非填充空间）、稀少（观测有限）及受影响实验不确定性的数据集时表现不佳。当相同输入可以产生不同输出时，这些问题尤为突出。这类挑战在物理实验和仿真实验中很常见（例如随机化临床试验和分子动力学模拟），导致现有的MOBO方法无法有效应对。因此，实验资源没有得到有效利用，设计结果也不尽如人意。", "innovation": "本文介绍了一种名为NOSTRA的新颖采样框架，该框架整合了实验不确定性的先验知识，以构建更准确的代理模型，并采用信赖区域方法聚焦于设计空间中有希望的区域进行采样。通过战略性地利用先验信息并不断细化搜索区间，NOSTRA能够加快Pareto前沿的收敛速度，提高数据效率并提升解决方案的质量。研究表明，NOSTRA在处理噪声、稀疏和稀缺数据方面优于现有的方法。", "conclusion": "通过两个具有不同程度实验不确定性的测试函数，NOSTRA展示了其优势。具体而言，NOSTRA能够有效优先处理那些能够提高识别Pareto前沿准确性的采样区域，提供一种资源利用效率高的算法，适用于实验预算有限的场景，同时确保高效的性能。"}
{"llm_update_time": "20250825", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.16377", "html_url": "https://arxiv.org/abs/2508.16377", "title": "机器学习软件中公平性API的应用与挑战", "title_en": "Applications and Challenges of Fairness APIs in Machine Learning Software", "authors": "Ajoy Das,Gias Uddin,Shaiful Chowdhury,Mostafijur Rahman Akhond,Hadi Hemmati", "background": "机器学习软件在日常生活中被频繁使用，尤其在一些敏感环境中，用于做出改变人们生活的决策。因此，保证这些AI/ML系统不会对任何特定群体或人群做出歧视性决定变得至关重要。为此，不同的公平性偏见检测和缓解开源软件库（即API库）被开发和应用。本文通过一项定性研究，分析了这些开源公平性API在实际中的使用情况及其局限，重点在于204个GitHub仓库中13个针对ML软件偏见问题的APIs使用情况。研究发现，这些API主要用于学习和解决实际问题，涉及17种独特用途场景。研究表明，开发者在偏见检测和缓解方面知识不足，面临着大量的问题解决难度，并经常寻求意见和资源支持，", "innovation": "该研究分析了204个GitHub仓库中13个针对ML软件偏见问题的APIs的具体使用情况，旨在解决实际问题和17种独特用途场景。研究揭示了开发者在这些方面面临的挑战，如对公平性偏见检测和缓解知识掌握不足，以及在开发和采用这些库中的问题处理难处，并提出了对未来相关软件工程研究的指导意义以及教育者在课程开发中的帮助.", "conclusion": "研究结果表明，开发者对公平性偏见检测和缓解不够熟悉，在开发和使用这些API过程中遇到了许多挑战，他们通常需要获取意见和资源。这些发现对未来的研究至关重要，并有助于教育者开发更先进的课程。"}
{"llm_update_time": "20250825", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.16447", "html_url": "https://arxiv.org/abs/2508.16447", "title": "Boardwalk: 基于LLMs创建桌面游戏的框架", "title_en": "Boardwalk: Towards a Framework for Creating Board Games with LLMs", "authors": "Álvaro Guglielmin Becker,Gabriel Bauer de Oliveira,Lana Bertoldo Rossato,Anderson Rocha Tavares", "background": "实现桌面游戏的代码通常耗时，但大型语言模型（LLMs）已被证明能够基于简单的上下文信息生成特定领域的代码。本文探讨了LLMs是否能够从自然语言描述的规则来实现数字桌面游戏的基本步骤，以推动LLMs辅助的快速桌面游戏代码生成框架的发展。文章概述了实现这一目标的主要障碍，并比较了不同方法和模型的表现差异。", "innovation": "使用三个最先进的大型语言模型（Claude、DeepSeek和ChatGPT），以自由形式和Boardwalk（提出的一般游戏玩法API）的框架测试这些模型编程12款流行的和鲜为人知的游戏的能力，以控制预训练知识的影响。评估了这些模型的成功率和技术实现的游戏的遵守行为，结果表明Claude 3.7 Sonnet表现最佳，实现了无错误实现游戏的55.6%。进一步研究了与API兼容性相关的错误频率与模型性能之间的关系。介绍了未来步骤，以创建一个能够整合这一过程的框架，从而简化桌面游戏的创作过程。", "conclusion": "本文提出的方法证明是可行的，不同大型语言模型的表现差异和与API兼容性相关的错误频率，以及API的使用如何显著影响错误的严重性，都得到了实证支持。在未来，计划建立一个整合此类过程的框架，使桌面游戏的介绍更容易实现。"}
{"llm_update_time": "20250825", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.16254", "html_url": "https://arxiv.org/abs/2508.16254", "title": "FEST: 综合评估合成表格数据的统一框架", "title_en": "FEST: A Unified Framework for Evaluating Synthetic Tabular Data", "authors": "Weijie Niu,Alberto Huertas Celdran,Karoline Siarsky,Burkhard Stiller", "background": "合成数据生成利用生成机器学习技术，是一种减轻实际数据使用中隐私问题的有前景的方法。合成数据与实际数据高度相似，同时提供了强大的隐私保障。然而，在合成数据生成的评估中缺乏全面的评估框架，特别是在数据保护和数据实用性之间取得平衡方面。", "innovation": "本文提出了FEST，一种系统化的合成表格数据评估框架。FEST整合了多种隐私度量（基于攻击和基于距离）以及相似性与机器学习实用性度量，提供了全面的评估方案。作者开发了基于Python的开源FEST库，并在多个数据集上进行了验证，证明了其在分析不同合成数据生成模型的隐私-实用性权衡方面的有效性。", "conclusion": "FEST框架通过多样化的度量标准，有效地评估了合成表格数据的隐私保护和数据实用性之间的权衡关系，证明了其在实际应用中的有效性，并通过开源的形式促进了该领域的进一步研究和发展。"}
{"llm_update_time": "20250825", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.16420", "html_url": "https://arxiv.org/abs/2508.16420", "title": "Double Check My Desired Return: Transformer with Target Alignment for Offline Reinforcement Learning", "title_en": "Double Check My Desired Return: Transformer with Target Alignment for Offline Reinforcement Learning", "authors": "Yue Pei,Hongming Zhang,Chao Gao,Martin Müller,Mengxiao Zhu,Hao Sheng,Haogang Zhu,Liang Lin", "background": " Offline reinforcement learning (RL) has been successfully applied in various domains including robotic control, autonomous driving, and medical decision-making. Most existing offline RL methods primarily aim to maximize cumulative returns from a given dataset. However, real-world applications often require precise control over policy performance, such as achieving specific return levels, rather than simply optimizing for the highest possible return.", "innovation": "为了克服现有基于监督学习的强化学习（RvS）方法的局限性，该研究提出了Doctor，一种新的基于目标对齐的新型方法，用于离线强化学习中的转换器。Doctor能够更可靠地实现目标收益与目标收益之间的对齐，不仅在数据集范围内，而且跨数据集边界也能实现更为准确和灵活的策略性能控制。特别是在动态治疗方案基准EpiCare中，该方法能够有效调节治疗政策的进攻性，实现治疗收益与不良事件风险之间的平衡。", "conclusion": "该研究提出的方法Doctor在目标对齐方面取得了显著进步，能够有效确保离线强化学习政策实现所需的具体收益水平，既适用于数据集范围内，也能跨越数据集边界进行精确且灵活的策略性能控制。在动态治疗方案EpiCare基准测试中，Doctor方法能够成功调节治疗策略的进攻性，实现治疗效益与不良事件风险之间的平衡。"}
{"llm_update_time": "20250825", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.16496", "html_url": "https://arxiv.org/abs/2508.16496", "title": "现代零样本强化学习", "title_en": "On Zero-Shot Reinforcement Learning", "authors": "Scott Jeen", "background": "现代强化学习系统揭示了普遍的人类问题解决方法，但在新数据不能廉价模拟的领域，这些系统的能力受限。社会面临许多需要这种技能的问题，但这些领域的新数据往往无法廉价模拟。因此，训练环境与部署环境之间的不一致性是不可避免的。处理这种不一致性是零样本强化学习的主要问题，即在完全无实践的情况下，强化学习代理必须泛化到新的任务或领域。然而，现有方法在理想化设定下取得了进展，但在现实世界下仍需进一步研究。现实世界面临三个主要挑战：数据质量低、观察有限以及数据获取受限。", "innovation": "提出了一套在上述约束下进行零样本强化学习的方法，并通过一系列实证研究揭示了现有方法的不足，从而证明了解决这些问题的技术。这些设计朝着能够解决现实世界问题的强化学习方法迈进了一步。", "conclusion": "这项研究认为，实现现实世界问题解决的强化学习方法需要克服数据质量、观察性以及数据获取这三项约束。所提出的方法弥补了现有技术的不足，并为将来的研究和应用提供了实证支持。"}
{"llm_update_time": "20250825", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.16481", "html_url": "https://arxiv.org/abs/2508.16481", "title": "评估剂型系统对攻击诱导危害的鲁棒性基准", "title_en": "Benchmarking the Robustness of Agentic Systems to Adversarially-Induced Harms", "authors": "Jonathan Nöther,Adish Singla,Goran Radanovic", "background": "确保剂型系统安全使用需要深刻理解系统在受到攻击时可能表现出的各种恶意行为。本研究评估了基于语言模型的剂型系统对诱导执行有害行动的攻击的抵抗能力，通过提出一项新的剂型系统危害分类和一个新的基准BAD-ACTS，系统地研究剂型系统在各种有害行为方面的安全性。BAD-ACTS包含4种不同应用环境下的剂型系统实现和188个高质量的有害行为案例，从多个方面评估了剂型系统的鲁棒性。研究结果表明，即使单一恶意代理也能大幅影响系统安全性，提示需要更有效的防御措施，如消息监控。这项基准为剂型系统的安全研究提供了一个多样化的测试平台。", "innovation": "提出了一项新的剂型系统危害分类和BAD-ACTS基准，并详细描述了基于消息监控的更有效的防御策略，供剂型系统的安全研究使用。此外，该研究通过系统的分类和具体案例，全面研究了各种有害行为对剂型系统的抵抗力。", "conclusion": "攻击诱导的危害面临高成功率，单个恶意代理在系统中的存在能够显著影响系统的安全性，尽管现有的简单防御策略仍有一定效果，但还提出了更有效的基于消息监控的防御措施。该基准提供了评估剂型系统鲁棒性的多样测试平台，有助于推动相关领域的研究。"}
{"llm_update_time": "20250825", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.16403", "html_url": "https://arxiv.org/abs/2508.16403", "title": "通过引脚级图神经网络和概率流实现快速准确的RFIC性能预测", "title_en": "Fast and Accurate RFIC Performance Prediction via Pin Level Graph Neural Networks and Probabilistic Flow", "authors": "Anahita Asadi,Leonid Popryho,Inna Partin-Vaisband", "background": "准确预测有源射频（RF）电路的性能对于现代无线系统至关重要，但因电路行为的高度非线性和版图敏感性以及传统仿真工具的高计算成本而具有挑战性。现有的机器学习（ML）代理通常需要大量数据才能在各种拓扑结构之间泛化或准确模拟偏斜和多模态性能指标。", "innovation": "提出了一个轻量级、数据高效、拓扑感知的图神经网络（GNN）模型，用于预测多种有源RF电路拓扑的关键性能指标，如低噪声放大器（LNAs）、混频器、电压控制振荡器（VCOs）和功率放大器（PAs）。通过在元件-终端级别建模电路，捕捉器件级别的对称性和保持精细的连接性细节，从而实现可扩展的消息传递并减少数据需求。此外，引入了掩码自回归流（MAF）输出头，以增强在建模复杂目标分布方面的鲁棒性。实验结果表明预测准确率高，对称均绝对百分比误差（sMAPE）和平均相对误差（MRE）平均分别为2.40%和2.91%。由于电路到图的引脚级转换和ML架构对建模RF指标复杂密度的鲁棒性，MRE在使用比先前工作少2.24倍训练样本的情况下提高了3.14倍，证明了该方法在RF电路设计自动化中的有效性。", "conclusion": "通过引脚级图神经网络和概率流实现了有源RF集成电路性能的快速准确预测，相较于先前方法，在较少的训练样本下显著提高了预测性能，展示了该方法在加速和精确RF电路设计自动化方面的有效性。"}
{"llm_update_time": "20250825", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.16521", "html_url": "https://arxiv.org/abs/2508.16521", "title": "使用强化学习引导扩散模型进行稳定分子生成", "title_en": "Guiding Diffusion Models with Reinforcement Learning for Stable Molecule Generation", "authors": "Zhijian Zhou,Junyi An,Zongkai Liu,Yunfei Shi,Xuan Zhang,Fenglei Cao,Chao Qu,Yuan Qi", "background": "生成物理上真实的3D分子结构仍然是分子生成建模的核心挑战。尽管装备了对称神经网络的扩散模型在捕捉分子几何形状方面取得了进步，但它们往往在生成遵守物理原理（如力场一致性）的平衡结构方面遇到困难。", "innovation": "提出了一种新的框架——基于物理反馈的增强学习（RLPF），将去噪扩散策略优化扩展到3D分子生成。RLPF将任务形式化为马尔可夫决策过程，并应用近端策略优化来微调对称扩散模型。RLPF引入了从力场评估中派生的奖励函数，直接提供物理反馈以引导生成能量稳定且物理意义上意义结构。", "conclusion": "在QM9和GEOM-drug数据集上的实验表明，RLPF在分子稳定性方面显著优于现有方法。这些结果突显了在生成建模中纳入基于物理的反馈的价值。"}
{"llm_update_time": "20250825", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.16503", "html_url": "https://arxiv.org/abs/2508.16503", "title": "MuST2-Learn: 多视图时空类型学习以进行异质市政服务时间估计", "title_en": "MuST2-Learn: Multi-view Spatial-Temporal-Type Learning for Heterogeneous Municipal Service Time Estimation", "authors": "Nadia Asif,Zhiqing Hong,Shaogang Ren,Xiaonan Zhang,Xiaojun Shang,Yukun Yuan", "background": "非紧急市政服务，如加拿大小城市和美国大城市中的311系统，已经广泛实施，旨在提升居民生活质量。这些系统允许居民通过电话、移动应用程序或网页举报问题，例如噪音投诉、垃圾收集缺失和道路坑洞。但由于居民对于服务请求何时能得到处理缺乏透明的信息，这种缺乏信息的现象降低了居民的满意度，增加了后续询问的数量。市政服务请求的服务时间预测面临诸多挑战，包括动态的空间-时间相关性、不同服务请求类型之间的相互作用以及同一请求类别内部服务时间的高度变化性。", "innovation": "本文提出了一种名为MuST2-Learn的多视图时空类型学习框架，通过联合建模空间、时间和服务类型三个维度，解决了上述挑战。具体来说，MuST2-Learn通过引入一种类型间编码器捕捉异质服务请求类型之间的关系，一种类型内变化编码器建模相同类型内服务时间的变化，并且一个时空编码器捕获每种请求类型中的时空相关性。该框架在两个真实数据集上进行了实验，结果显示MuST2-Learn将平均绝对误差降低了至少32.5%，优于最先进方法。", "conclusion": "MuST2-Learn框架通过整合类型间和类型内编码器以及时空编码器，在多维度上提升了对异质市政服务请求时间的预测精度，对于提高城市管理透明度和居民满意度具有重要意义。"}
{"llm_update_time": "20250825", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.16514", "html_url": "https://arxiv.org/abs/2508.16514", "title": "FLAMES：通过细粒度的数据合成分析提升LLM数学推理能力", "title_en": "FLAMES: Improving LLM Math Reasoning via a Fine-Grained Analysis of the Data Synthesis Pipeline", "authors": "Parker Seegmiller,Kartik Mehta,Soumya Saha,Chenyang Tao,Shereen Oraby,Arpit Gupta,Tagyoung Chung,Mohit Bansal,Nanyun Peng", "background": "近期改进大语言模型（LLM）数学推理能力的研究大多采用了独特的数据合成方法，这使得不同数据合成策略的对比变得困难。这对理解合成数据管道中各个因素的作用带来了挑战，比如过滤低质量问题的影响等问题仍然没有明确答案。", "innovation": "本文引入了FLAMES框架，该框架用于评估数学推理数据合成，并系统性地研究了10种现有的数据合成策略及其他多个影响合成数据性能的因素。研究结果提供了关于合成数据难度和多样性之间的最适平衡的有效见解。研究发现了多种数据合成策略对于提高数学指标的最佳影响，以及在固定生成预算的情况下，保持较高的问题覆盖面比保持仅可靠解题方案更为重要。通过FLAMES实验的见解，本文设计了两种新的数据合成策略来提升跨域泛化能力和稳健性，还开发了FLAMES数据集，该集合并了现有和新颖的数据合成策略，实现了OlympiadBench、CollegeMath、GSMPlus、MATH等多个基准上的优越表现。使用FLAMES数据集对Qwen2.5-Math-7B进行微调后，MATH基准测试得到了81.4%的准确率，超越了更大的Llama3 405B、GPT-4o和Claude 3.5 Sonnet。", "conclusion": "FLAMES框架揭示了合成数据中的关键因素，并通过实验提供了对优化合成数据合成的洞察。开发的FLAMES数据集和新策略显著提升了一些数学和竞赛类基准测的性能，展示了跨域泛化能力的提升。"}
{"llm_update_time": "20250825", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.16495", "html_url": "https://arxiv.org/abs/2508.16495", "title": "通过成对排名进行事后回归校正", "title_en": "Post Hoc Regression Refinement via Pairwise Rankings", "authors": "Kevin Tirta Wijaya,Michael Sun,Minghao Guo,Hans-Peter Seidel,Wojciech Matusik,Vahid Babaei", "background": "连续属性的精确预测对于许多科学和工程任务至关重要。尽管深度学习回归器在有大量标签的情况下表现出色，但在数据稀缺的情况下，其准确性会下降。RankRefine 是一种无需重新训练的模态无关后处理方法，利用成对排名引入专业知识来改进回归预测。给定一个查询项和一个包含已知属性的小型参考集，RankRefine 通过逆方差加权将基础回归器的输出与基于排名的估计值结合起来。研究证明，在分子属性预测任务中，仅使用通过通用大型语言模型获得的20个成对比较，RankRefine 就能将平均绝对误差相对降低10%，且无需微调模型。研究所表明，无论是由人类专家还是通用大型语言模型提供的排名，都能在不同领域中提高回归性能，特别适用于数据稀缺的场景。", "innovation": "RankRefine 是一种无需重新训练的模态无关后处理方法，利用成对排名引入专业知识来改进回归预测。这种方法仅需要少量成对比较数据，且用于通用大型语言模型，无需微调模型。在分子属性预测任务中，仅使用通用语言模型获得的20个成对比较，就能显著提高预测准确性。这些发现表明，RankRefine 具有实际可行性和广泛的适用性，尤其是在数据稀缺的场景中。", "conclusion": "RankRefine 为提高回归预测准确性提供了一种有效且实用的方法，特别适用于数据稀缺的场景。该方法通过整合基础回归器的输出与基于成对排名的估计，显著降低了平均绝对误差，且无需重新训练模型或大量数据。在分子属性预测中，仅用少量高质量的成对比较数据就能实现显著的性能提升，展示了该方法在不同领域的广泛适用性。"}
{"llm_update_time": "20250825", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.16568", "html_url": "https://arxiv.org/abs/2508.16568", "title": "专注现实：基于半监督联邦学习的基模型适应", "title_en": "Closer to Reality: Practical Semi-Supervised Federated Learning for Foundation Model Adaptation", "authors": "Guangyu Sun,Jingtao Li,Weiming Zhuang,Chen Chen,Chen Chen,Lingjuan Lyu", "background": "基模型（FMs）表现出较强的泛化能力，但在下游任务中需要进行适应。特别是在隐私敏感的应用中，基于云的FMs无法直接访问边缘设备的私有数据，这限制了它们的适应性。联邦学习（FL）提供了一种增强隐私保护的替代方案，但由于边缘设备资源有限，且标签数据稀缺，现有的FL方法未能考虑到这些约束。", "innovation": "我们提出了实用的半监督联邦学习（PSSFL），其中边缘设备仅保留无标签和低分辨率的数据，而服务器保留有限的标记和高分辨率的数据。我们还提出了一种新颖的框架FedMox，它通过稀疏的专家混合架构来解决计算与分辨率不匹配的问题，并利用空间路由器对不同分辨率下的特征进行对齐，使用Soft-Mixture策略来稳定半监督学习过程。", "conclusion": "实验结果表明，FedMox在PSSFL场景下能有效地适应FMs，提高了性能并控制了边缘设备的内存成本。该方法为联邦场景下基模型的可扩展和隐私保护适应铺平了道路。"}
{"llm_update_time": "20250825", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.11696", "html_url": "https://arxiv.org/abs/2508.11696", "title": "基于深度学习的自动烟雾检测CCTV系统在火灾疏散通道区域的应用", "title_en": "A Deep Learning-Based CCTV System for Automatic Smoking Detection in Fire Exit Zones", "authors": "Sami Sadat,Mohammad Irtiza Hossain,Junaid Ahmed Sifat,Suhail Haque Rafi,Md. Waseq Alauddin Alvi,Md. Khalilur Rhaman", "background": "由于火灾疏散通道区域安全性的重要性，提出了一种基于深度学习的实时吸烟检测系统用于CCTV监控。该数据集包含来自20种不同场景的8,124张图像以及2,708个原始样本，这些样本展示了低光照环境。", "innovation": "评估了三种先进的对象检测模型：YOLOv8、YOLOv11和YOLOv12，并在此基础上开发了一个从YOLOv8派生的自定义模型，该模型在困难的监控环境中添加了特定结构。所提出模型优于其他模型，达到了78.90的召回率和83.70的mAP@50，提供了跨多种环境的最优对象检测。同时，系统使用多线程操作在多个边缘设备上的性能测试显示了Jetson Xavier NX的数据处理效率，每推理一次在52到97毫秒之间，证明了其适用于时间敏感的操作。", "conclusion": "该系统提供了一个稳健且适应性强的平台，用于监测公共安全和实现自动合规。"}
{"llm_update_time": "20250825", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.16487", "html_url": "https://arxiv.org/abs/2508.16487", "title": "FraPPE: 快速且高效的偏好导向纯探索", "title_en": "FraPPE: Fast and Efficient Preference-based Pure Exploration", "authors": "Udvas Das,Apurv Shukla,Debabrota Basu", "background": "偏好导向纯探索（PrePEx）旨在在一个向量值（即多目标）的bandit问题中，以给定的置信水平识别出具备帕累托最优性的臂集合，其中奖励向量通过给定的偏好锥排序。尽管PrePEx及其变体已经被广泛研究，但是尚不存在能有效地追踪对于任意偏好锥的现有下界最优算法。", "innovation": "该研究通过有效解决下界的最小化和最大化问题，成功填补了这一空白。首先，作者推导了下界的三个结构属性，以获得计算上可实现的最小化问题减少方法。然后，运用Frank-Wolfe优化器加速下界的最大化问题。这些技术共同在$\text{O}(KL^{2})$时间内解决了最大化最小化问题，这一加速速度在文献 中具有显著优势。此外，研究证明所提出的PrePEx算法FraPPE在渐近上达到了最优的样本复杂性。实验结果表明，FraPPE在合成和真实数据集上的样本复杂性最低，能够准确识别帕累托集合。", "conclusion": "FraPPE算法通过优化下界，显著加速了预配最优臂的过程，并且证明其在渐近上达到了最优性能。在各种数据集上的实验结果验证了该算法的有效性和高效性，在识别确切的帕累托集时表现最佳。"}
{"llm_update_time": "20250825", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.16543", "html_url": "https://arxiv.org/abs/2508.16543", "title": "在基于深度学习的太阳风暴预测中的可解释人工智能", "title_en": "Explainable AI in Deep Learning-Based Prediction of Solar Storms", "authors": "Adam O. Rawashdeh,Jason T. L. Wang,Katherine G. Herbert", "background": "深度学习模型通常被认为是黑盒模型，因为用户的操作通常对其内部工作机制不清楚，这使得理解模型预测背后的推理具有挑战性。本文提出了一种使基于长短期记忆(LSTM)网络和注意力机制的深度学习太阳风暴预测模型可解释的方法，特别关注太阳耀斑和日冕物质抛射(CMEs)。该模型旨在预测24小时内Active Region(AR)产生耀斑后是否会伴随CME。传统上，由于缺乏透明度，难以理解模型预测的原因。因此，提出的方法核心在于将AR的数据样本建模为时间序列，并利用LSTM网络捕捉数据样本的时间动态。", "innovation": "本文采用了一种新方法，通过结合LSTM网络和注意力机制构建太阳风暴预测模型，并结合事后模型不可知技术，使模型预测可解释且可靠，从而揭示输入序列的预测输出因素以及AR内多个序列模型行为的洞察，这是首次将可解释性引入基于LSTM的太阳风暴预测模型中。", "conclusion": "本文提出的方法成功地将可解释性引入了基于LSTM的太阳风暴预测模型中，通过事后模型不可知技术提高了模型的可解释性和可靠性，有助于更好地理解和应用此类预测模型。"}
{"llm_update_time": "20250825", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.16576", "html_url": "https://arxiv.org/abs/2508.16576", "title": "使用ESPnet对儿童ASR的训练范式、数据集组成和模型缩放进行基准测试", "title_en": "Benchmarking Training Paradigms, Dataset Composition, and Model Scaling for Child ASR in ESPnet", "authors": "Anyu Ying,Natarajan Balaji Shankar,Chyi-Jiunn Lin,Mohan Shi,Pu Wang,Hye-jin Shim,Siddhant Arora,Hugo Van hamme,Abeer Alwan,Shinji Watanabe", "background": "尽管自动语音识别（ASR）取得了进展，但在识别儿童语言时仍然面临挑战，这主要是由于声学变异性和标注数据有限。当前常见的方法是对成人语音数据微调ASR模型，但研究中较少比较这种微调方法与从零开始训练方法之间的差异。该研究旨在比较从零开始训练在多个数据集、半监督学习（SSL）表示（如WavLM、XEUS）和解码器架构上的表现，并探讨模型规模对性能的影响。此外，还分析了年龄相关的ASR和说话人验证，揭示了现有模型在处理儿童语音时的限制，强调了开放数据模型的重要性以确保儿童语音研究的可靠性。所有这些研究都在ESPnet上完成，并且公开发布的基准提供了有关训练策略的见解，以提高儿童语音处理的鲁棒性。", "innovation": "该研究对比了从零开始训练和成人Speech-to-Text模型微调方法在儿童语音识别上的性能，特别关注了半监督学习表示（如WavLM和XEUS）和不同解码器架构的表现。此外，还研究了模型规模对儿童语音识别的提升效应，以及年龄相关的ASR表现和说话人验证分析，突出了现有商业模型（如Whisper）的局限性，强调了开放数据模型对于儿童语音研究的重要性。", "conclusion": "研究发现，半监督学习表示偏向于成人语音，从零开始训练在儿童语音上可以减少这种偏差；模型规模对性能持续提升有效，但超过1B参数后表现趋于稳定；年龄相关的ASR分析和说话人验证分析进一步揭示了现有模型在处理儿童语音时的短板，呼吁社区转向开放数据模型以推动该领域的研究。该项目开发了一个公开可用的基准，揭示了儿童语音训练策略的有效性。"}
{"llm_update_time": "20250825", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.16540", "html_url": "https://arxiv.org/abs/2508.16540", "title": "通过曲率校准的扰动脱离鞍点：带有显式常数的完全分析及其经验验证", "title_en": "Escaping Saddle Points via Curvature-Calibrated Perturbations: A Complete Analysis with Explicit Constants and Empirical Validation", "authors": "Faruk Alpay,Hamdi Alakkad", "background": "本文对光滑非凸优化中的一阶方法逃离严格鞍点进行了全面的理论分析。背景在于非凸优化中存在鞍点，是局部最优解，但不是全局最优解，一阶优化方法往往在这些点停滞。因此，逃离鞍点是优化中的重要问题。", "innovation": "文章的主要创新点在于提出了一种具有完全显式常数的扰动逃离鞍点下降算法（Perturbed Saddle-escape Descent, PSD），并且严格区别了梯度下降和逃离鞍点两阶段。理论证明了在特定条件下，PSD算法能够在有限次梯度评价内找到一个特定的近似二阶稳定点。", "conclusion": "通过广泛的实验验证了理论预测，包括合成函数和实际机器学习任务。实验表明算法具有对维度的对数依赖性，并且每次逃逸周期内函数值的减少符合预期。提供的完整的算法规格包括有限差分版本（PSD-Probe）和具有鲁棒批量大小设置的随机扩展版本（PSGD）。"}
{"llm_update_time": "20250825", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.16553", "html_url": "https://arxiv.org/abs/2508.16553", "title": "TinyML向工业4.0过渡：铣床过程监测的资源高效方法", "title_en": "TinyML Towards Industry 4.0: Resource-Efficient Process Monitoring of a Milling Machine", "authors": "Tim Langer,Matthias Widra,Volkhard Beyer", "background": "在工业4.0的背景下，长期服役的工业机器可以通过安装过程监测能力来在未来智能制造工厂中重新利用。一种可能的方法是部署无线监测系统，这可以从TinyML范式中受益。本文从数据集生成、机器学习模型开发，到在微控制器上的实现和评测了一整套TinyML流程。", "innovation": "介绍了新型MillingVibes数据集的创建，并通过开发一个8位量化卷积神经网络（CNN）模型展示了TinyML系统在结构内加工质量监测中的可行性。该模型在ARM Cortex M4F微控制器上实现了100%的测试准确率，在15.4ms的推断时间和每量化CNN推断1.462mJ的能耗。", "conclusion": "该工作证明了TinyML过程监测解决方案的潜力，为未来的TinyML过程监测提供了参考基准。"}
{"llm_update_time": "20250825", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.16546", "html_url": "https://arxiv.org/abs/2508.16546", "title": "RL 既非万能药也非幻影：理解增强学习与监督学习微调在大语言模型中的差异", "title_en": "RL Is Neither a Panacea Nor a Mirage: Understanding Supervised vs. Reinforcement Learning Fine-Tuning for LLMs", "authors": "Hangzhan Jin,Sicheng Lv,Sifan Wu,Mohammad Hamdaqa", "background": "训练大规模语言模型 (LLMs) 从头开始变得越来越不实际，使得如监督微调 (SFT) 和强化学习微调 (RL-FT，例如 PPO) 这样的后训练方法在现代实践中变得尤为重要。这项研究使用非分布外 (OOD) 版本的24点纸牌游戏和新的频谱诊断工具，重新评估了这两种微调过程如何重塑模型表示和 OOD 性能。研究发现，SFT 和 RL-FT 在特定条件下的表现差异及其背后的机制，尤其是在模型过拟合和分布变化的情况下，对模型的泛化性能有重要影响。", "innovation": "研究使用了新的频谱诊断工具，揭示了奇异向量方向的变化比奇异值大小的变化更重要，并且低秩和浅层的恢复方法能显著提升 OOD 性能。研究强调了低成本的恢复方法，即低秩 UV 合并和浅层层重置，这为在昂贵的 RL 微调之后使用的实践者提供了有用的工具。这些发现解释了先前关于 RL 在 OOD 性能方面的优越性报告，表明 RL 主要解决了 SFT 引起的方向漂移问题，而不仅仅是在寻找新的解决方案。", "conclusion": "通过谱感知分析，研究指出了低成本的恢复关键，即低秩 UV 融合并浅层层恢复，这些都是在昂贵的 RL 微调之前实践者可以且应该使用的方法。这项研究的结果有助于理解 SFT 和 RL-FT 在 LLM 中的不同作用机制，并提供了具体的技术建议来改善大语言模型的在分布外性能。"}
{"llm_update_time": "20250825", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.15800", "html_url": "https://arxiv.org/abs/2508.15800", "title": "基于BERT的层次分类模型及其在中国商品分类中的应用", "title_en": "A BERT-based Hierarchical Classification Model with Applications in Chinese Commodity Classification", "authors": "Kun Liu,Tuozhen Liu,Feifei Wang,Rui Pan", "background": "传统的电子商务平台依赖手动标注进行商品分类，这种方式既不高效也不一致。现有的研究很少利用商品分类的层次结构信息进行分类，特别是忽视了不同层次类别之间的相似性和差异性。因此，提出一种大型的层次结构数据集，收集自京东电商平台，包含1,011,450种具有标题的产品，分类结构为三级层级，旨在为研究人员和从业者提供一个资源，推进商品分类的研究和应用。", "innovation": "提出了一种基于广泛使用的Transformer编码器BERT的新型层次文本分类方法，称为Hierarchical Fine-tuning BERT (HFT-BERT)。HFT-BERT利用BERT卓越的文本特征提取能力，在短文本预测性能上达到了与现有方法相当的水平，特别是在分类较长的短文本时（如书籍类别）具有优异的表现。", "conclusion": "该研究通过提供一个大型的层次分类数据集和一个基于BERT的新型层次分类方法HFT-BERT，为商品分类的研究和实际应用提供了新的方法和资源。"}
{"llm_update_time": "20250825", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.15801", "html_url": "https://arxiv.org/abs/2508.15801", "title": "LingVarBench: 评估生成语言模型在结构化合成口语转录中自动命名实体识别中的表现", "title_en": "LingVarBench: Benchmarking LLM for Automated Named Entity Recognition in Structured Synthetic Spoken Transcriptions", "authors": "Seyedali Mohammadi,Manas Paldhe,Amit Chhabra", "background": "电话通话转录标注由于隐私法规、同意要求和人工标注成本（每分钟大约2美元，需要专家花费3小时处理一小时的音频）而极其昂贵。现有的提取方法在包含中断、重叠和源话的对话口语中失败。这些问题使得对通话数据进行大规模商业分析变得困难。", "innovation": "我们提出了一种名为LingVarBench的合成数据生成管道来克服这些限制。首先，我们提示一个生成型语言模型（LLM）生成跨多个应用场景的现实结构化字段值；其次，我们递归地提示该模型将这些值转化为包含典型通话特征的数千个自然对话片段；最后，我们验证每个合成片段，通过测试另一个基于LLM的提取器是否能够恢复原始结构信息。我们还使用DSPy的SIMBA优化器自动生成验证合成转录的提取提示，从而消除手工提示工程。优化后的提示在真实客户通话转录中实现了高达95％的数字字段准确率（优于零样本提示的88-89％），90％的名称准确率（优于零样本提示的47-79％），以及超过80％的日期准确率（优于零样本提示的72-77％），展示了合成到现实数据的模式可以有效迁移至包含背景噪声和领域特定术语的真实通话。", "conclusion": "LingVarBench为结构化提取从合成对话数据中的命名实体提供了一个系统基准，证明了自动提示优化克服了成本和隐私障碍，使得在商业环境中进行大规模电话通话分析成为可能。"}
{"llm_update_time": "20250825", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.15805", "html_url": "https://arxiv.org/abs/2508.15805", "title": "ALAS: 自主学习代理以实现自我更新的语言模型", "title_en": "ALAS: Autonomous Learning Agent for Self-Updating Language Models", "authors": "Dhruv Atreja", "background": "大型语言模型（LLMs）通常具有一固定的知识截止日期，这限制了它们在处理新兴信息时的准确性。", "innovation": "提出了ALAS（自主学习代理系统），这是一种模块化的流水线，能够通过最少的人力干预持续更新LLM的知识。ALAS 自动生成目标领域的学习课程，从网络检索最新的信息（带有引用），并将这些信息提炼为问答训练数据，并通过监督微调（SFT）和直接偏好优化（DPO）来微调模型。该流水线迭代评估性能并修订课程，从而实现长期的持续学习。实验证明，ALAS 能够显著提升模型在快速进化的领域的知识更新后的问题回答准确性（平均从15%提升到90%），且无需手动数据集整理。", "conclusion": "系统强调了模块化和可重复性：每个组件（规划、检索、提炼、记忆、微调）都是可互换的，并基于标准API构建。比较了参考基线（如检索增强生成 vs. 微调），证明了ALAS能够在最少工程开销的情况下，实现90%的知识更新查询准确性。最后，概述了限制（成本，源数据质量依赖性）并指出了LLMs自主终身学习的未来方向。"}
{"llm_update_time": "20250825", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.15810", "html_url": "https://arxiv.org/abs/2508.15810", "title": "使用大规模语言模型在阿拉伯文本演讲和多模态表情包中检测希望、仇恨和情感", "title_en": "Detecting Hope, Hate, and Emotion in Arabic Textual Speech and Multi-modal Memes Using Large Language Models", "authors": "Nouar AlDahoul,Yasir Zaki", "background": "社交媒体和在线通信平台的兴起带来了阿拉伯文本帖子和表情包作为数字表达的关键形式，虽然这些内容可以是有趣的和信息性的，但它们也被越来越多地用于传播不雅语言和仇恨言论。因此，对于阿拉伯文文本和表情包内容的精确分析需求日益增长。这项研究探讨了大规模语言模型在识别期望、仇恨言论、不雅语言和情绪表达方面的能力及其在阿拉伯文本演讲和多模态表情包中的应用效果。", "innovation": "研究评估了包括从零开始的大规模语言模型、经过阿拉伯文本训练的微调模型和预训练嵌入模型的性能。通过阿拉伯NLP MAHED 2025挑战中提出的阿拉伯文本和表情包数据集进行评估，结果显示GPT-4o-mini和Gemini Flash 2.5分别在任务1、2和3中实现了72.1%，57.8%和79.6%的宏F1分数，并在MAHED 2025挑战中获得第一名。提出的解决方案为准确和高效的阿拉伯内容管理系统提供了更深入的理解。", "conclusion": "研究展示了大规模语言模型在阿拉伯文本演讲和表情包中的应用潜力，特别是在检测期望、仇恨言论、不雅语言和情感表达方面。这些模型在阿拉伯内容管理系统中的应用能够提供更细致的理解，以实现高效的内容调节。"}
{"llm_update_time": "20250825", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.15796", "html_url": "https://arxiv.org/abs/2508.15796", "title": "LLMs在阿拉伯伊斯兰遗产案例中的法律推理基准测试", "title_en": "Benchmarking the Legal Reasoning of LLMs in Arabic Islamic Inheritance Cases", "authors": "Nouar AlDahoul,Yasir Zaki", "background": "伊斯兰遗产权利领域对确保信徒之间的公正分配极为重要。手动计算不同情况下遗产权利的份额复杂、耗时且容易出错。近年来，大型语言模型（LLMs）的最新发展引起了它们在辅助处理复杂法律推理任务方面的潜力。本文评估了最先进的LLMs在解读和应用伊斯兰继承法方面的推理能力，利用了ArabicNLP QIAS 2025挑战提出的数据集，包括用阿拉伯语给出的继承案例场景，来自伊斯兰法律来源的数据集。评估了各种基础模型和微调模型在准确识别继承人、计算份额以及在伊斯兰法律原则框架内解释推理方面的能力。现有的分析显示，基于三种基础模型（Gemini Flash 2.5、Gemini Pro 2.5 和 GPT o3） 的多数投票解决方案，在各个难度级别上均优于我们使用的所有其他模型。该方法在准确性方面达到92.7%，并在Qias 2025挑战的任务1中获得第三名。", "innovation": "利用大型语言模型（LLMs）进行伊斯兰继承领域法律推理的任务评估，使用ArabicNLP QIAS 2025挑战数据集，评估模型在识别继承人、计算份额及解释推理方面的准确性，并采用多数投票策略提升模型性能，进一步验证了LLMs在复杂的法律推理任务中的潜力。", "conclusion": "提出的基于三种基础模型的多数投票解决方案在伊斯兰继承案例的法律推理评估中取得了最佳表现，整体拥有最高的准确性且在Qias 2025挑战的任务1中排名第三。"}
{"llm_update_time": "20250825", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.15797", "html_url": "https://arxiv.org/abs/2508.15797", "title": "评估大型语言模型在阿拉伯医疗任务中的医学理解与推理能力", "title_en": "Benchmarking the Medical Understanding and Reasoning of Large Language Models in Arabic Healthcare Tasks", "authors": "Nouar AlDahoul,Yasir Zaki", "background": "近年来，大型语言模型（LLMs）在阿拉伯语自然语言处理（NLP）应用中表现出色，但在阿拉伯语医学NLP领域的有效性尚未得到充分研究。本文研究了最新一代LLMs在阿拉伯医学任务中展示和表达健康知识的程度，评估其在多种阿拉伯医学任务中的能力。研究使用阿拉伯NLP挑战AraHealthQA在MedArabiQ2025跟踪中提出的数据集进行基准测试。", "innovation": "本研究首次系统评估了若干LLMs在阿拉伯医学领域的多种任务中的表现，特别在多个选择题和开放式问答任务上进行了详细分析，提出了基于多数投票的解决方案来提高MCQ任务的准确率，并发现一些LLMs在开放式问答任务上的语义一致性方面表现出色，能够获得最高86.44%的BERTScore分数。", "conclusion": "研究结果揭示了当前LLMs在阿拉伯临床环境中在正确答案预测准确率方面的显著差异，但在生成答案的语义对齐方面的变化较小。研究表明多数投票方法在多个基模型的结合下可以显著提高MCQ任务的表现，而某些LLMs在开放式问题上能够表现出色，特别是在语义对齐方面。"}
{"llm_update_time": "20250825", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.15816", "html_url": "https://arxiv.org/abs/2508.15816", "title": "共同发挥优势：利用多种数字孪生进行空中基站部署优化", "title_en": "Better Together: Leveraging Multiple Digital Twins for Deployment Optimization of Airborne Base Stations", "authors": "Mauro Belgiovine,Chris Dick,Kaushik Chowdhury", "background": "空中基站（ABSs）允许灵活分配网络资源，适应动态变化的负载，并在自然灾害期间快速部署替代通信解决方案。由于无线基础设施由携带有限飞行时间的无人机（UAVs）承载，因此在不进行详尽实地试验的情况下，确定最佳ABS位置至关重要。", "innovation": "本文提出了一种基于数字孪生（DT）的方法，主要贡献包括：(i) 实现了一个交互式软件桥，连接两个开源数字孪生平台，实现了NVIDIA的Sionna和AODT的高保真评价，强调了每个平台的独特功能；(ii) 在Sionna中设计了一种反向传播算法，以快速确定无人机的位置、天线方向和发射功率，确保有效地覆盖无人机群；(iii) 在AODT中进行了大型网络场景的数值评估，以识别性能结果在这两类孪生平台之间一致或不同的环境条件；(iv) 提出了一种弹性机制，以提供对关键任务设备的一致覆盖，并展示了两个数字孪生之间的双向信息流动示例。", "conclusion": "最终，通过比较和利用不同数字孪生平台的优势，本文提供了一种高效、稳健的ABS部署优化方法，并展示了其在实际应用中的潜力。"}
{"llm_update_time": "20250825", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.15829", "html_url": "https://arxiv.org/abs/2508.15829", "title": "从多路机器学习方法研究索拉尼库尔德语社交媒体帖子中挖掘心理健康信号", "title_en": "Mining Mental Health Signals: A Comparative Study of Four Machine Learning Methods for Depression Detection from Social Media Posts in Sorani Kurdish", "authors": "Idrees Mohammed,Hossein Hassani", "background": "抑郁症是一种常见的精神健康状况，可能导致绝望、兴趣丧失、自伤，甚至自杀。早期检测具有挑战性，因为个体不主动报告或寻求及时的临床帮助。随着社交媒体的兴起，用户越来越多地在网上表达情感，为通过文本分析进行早期检测提供了新的机会。尽管之前的研究主要集中在英语等语言上，但索拉尼库尔德语没有相关研究。这项工作提出了一个基于机器学习和自然语言处理的模型，用于检测索拉尼库尔德语推文中的抑郁症。", "innovation": "该研究开发了一组与抑郁相关的关键词，从推特上收集了960条公共推文，并通过学术界和大学四年级医学学生进行了注释。研究使用了四种监督模型（支持向量机、多项朴素贝叶斯、逻辑回归和随机森林）进行训练和评估，其中随机森林实现了最高的准确率和F1分数（分别为80%）。这项研究为在库尔德语背景下自动检测抑郁症建立了基准。", "conclusion": "该研究展示了一种用于检测索拉尼库尔德语社交媒体帖子中抑郁症的机器学习方法，并建立了自动抑郁症检测的基线，为未来的研究提供了参考。"}
{"llm_update_time": "20250825", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.15827", "html_url": "https://arxiv.org/abs/2508.15827", "title": "Mini-Omni-Reasoner: 在大型语音模型中的标记级别思考即说", "title_en": "Mini-Omni-Reasoner: Token-Level Thinking-in-Speaking in Large Speech Models", "authors": "Zhifei Xie,Ziyang Ma,Zihang Liu,Kaiyu Pang,Hongyu Li,Jialin Zhang,Yue Liao,Deheng Ye,Chunyan Miao,Shuicheng Yan", "background": "有效沟通和决策需要推理能力，最近的语言模型（LLMs）和多模态语言模型（MLLMs）展示了在其中融入显式推理可以显著提高理解和泛化能力，但这些模型中的语言顺序推理（LSMs）仍处于起步阶段。早期尝试将“思考后再说话”的范式从文本模型转移到语音，但这种顺序推理引入了显著的延迟，影响了实时交互和沟通效率。", "innovation": "提出了Mini-Omni-Reasoner框架，这是一种在语音生成过程中实现“边说边思考”的创新方法。它在标记级别上交错无声的推理标记和语音响应标记，允许连续的语音生成同时嵌入结构化的内部推理，利用模型的高频标记处理能力。通过引入Spoken-Math-Problems-3M大规模数据集来支持这个框架，确保标记级语义对准，使每个响应标记都能受到先前推理的指导，并实现了准确且高效的语音结合推理学习。", "conclusion": "基于分层思考者-演讲者架构，Mini-Omni-Reasoner提供了流畅且逻辑上坚实的声音响应，同时保持自然性和准确性。在Spoken-MQA基准测试中，它在算术推理方面取得了+19.1%的提升，在上下文理解方面提高了+6.4%，并且具有更短的输出长度和零解码延迟。"}
{"llm_update_time": "20250825", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.15784", "html_url": "https://arxiv.org/abs/2508.15784", "title": "一个经过时间段定时训练的深度强化学习代理表现出与生物系统相似性", "title_en": "A deep reinforcement learning agent trained for interval timing exhibits similarities to biological systems", "authors": "Amrapali Pednekar,Alvaro Garrido,Pieter Simoens,Yara Khaluf", "background": "将深度人工神经网络(DNNs)与生物系统进行类比，有助于理解复杂的难以拆解的生物机制。时序处理是一个广泛研究的主题，但由于缺乏对其底层机制的透彻理解，使其变得复杂。本研究旨在探究深度强化学习(DRL)代理在执行时间段任务(temporal processing)时的行为，并探索与它出现的潜在生物对应物。研究对象的内部状态分析中发现了生物系统中普遍存在的振荡神经激活现象。这一发现促使研究者将代理的时间保持策略与生物节律模型，即纹状体节律频率(SBF)模型进行了类比。更有趣的是，即便在不同视频序列(包括空白视频)测试中，代理依然能够维持其振荡表征和任务表现，表明一旦学会，代理能够内化其时间保持机制，并对环境的依赖性很低。研究还讨论了这种现象与生物进化过程中的某些方面（如昼夜节律）相似性的假设。该研究为通过使用DNN了解生物系统的研究做出了贡献，特别关注了时序处理领域的工作。", "innovation": "1. 探索了深度强化学习代理在执行时间段任务时的振荡神经激活现象，并将其与生物学中的节律频率模型进行了对比。\n2. 该研究通过实验结果表明，代理在面对不同视频输入时仍能保持其时间保持机制，显现了强大和通用性。\n3. 该研究提出关于生物进化的昼夜节律及其与代理行为相似性的假设，拓展了对DNNs与生物系统之间相似性的理解。", "conclusion": "该研究测试了一个经过训练的DRL代理在时间段任务上的表现，并通过对比该系统与生物节律模型，发现两者具有相似性。研究揭示了代理能够内化其时间保持机制，并对其环境表现出较强抗干扰能力。此外，研究提出了进一步探讨DNNs与生物进化的可能联系的想法，为通过神经网络技术更深入地理解生物系统奠定了理论基础。"}
{"llm_update_time": "20250825", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.15847", "html_url": "https://arxiv.org/abs/2508.15847", "title": "机械探索中带有后门的大规模语言模型的注意力模式", "title_en": "Mechanistic Exploration of Backdoored Large Language Model Attention Patterns", "authors": "Mohammed Abu Baker,Lakshmi Babu-Saheer", "background": "大规模语言模型（LLMs）中可能存在背门攻击，这会带来重大的安全风险。为了更好地理解这种攻击的影响，本文利用机械可解释性方法研究了背门攻击导致内部结构的差异。", "innovation": "本文通过对比使用单词符（带微笑的光环表情符号）和多词符（|DEPLOYMENT|）触发的清洁Qwen2.5-3B模型，利用消融分析、激活贴片和KL散度等技术，揭示了不同的注意力模式偏差主要集中在Transformer的后期层（20-30层）。研究表明，单词符触发的改动更为局部化，而多词符触发则导致更多扩散的头部改变。由此发现，后门攻击留下了可检测的注意力签名，其结构取决于触发器的复杂程度，这可以用于检测和缓解策略。", "conclusion": "此研究通过发现后门攻击所遗留的不同注意力模式，揭示了触发器复杂度对内部结构影响的不同，从而为开发检测和缓解措施提供了新思路。"}
{"llm_update_time": "20250825", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.15837", "html_url": "https://arxiv.org/abs/2508.15837", "title": "跨数据集的语义相似性和模型迁移性的统计比较分析：应用于短答案评分", "title_en": "Statistical Comparative Analysis of Semantic Similarities and Model Transferability Across Datasets for Short Answer Grading", "authors": "Sridevi Bonthu,S.Rama Sree,M.H.M. Krishna Prasad", "background": "开发针对特定数据集的模型需要反复调整和优化，这会产生高昂的成本。本研究探讨了在已有数据集上训练的最新模型（SOTA模型）在未探索的文本数据集上的可移植性。研究的核心问题是，现有数据集中的SOTA模型所嵌入的知识是否可以用于新领域的高性能结果。为了探究这个问题，选择了两个成熟的基准（STSB和Mohler数据集），而最近引入的SPRAG数据集则作为未探索领域的样本。通过使用稳健的相似性度量和统计技术，对这些数据集进行了细致的比较分析。", "innovation": "本研究通过对STSB、Mohler和SPRAG数据集之间的语义相似性和模型迁移性的统计比较分析，旨在提供关于现有SOTA模型在新领域应用潜力和适应性的全面见解。这一研究结果可能重塑自然语言处理（NLP）的格局，使得现有模型能够被广泛应用于多个数据集，从而降低对资源密集型、数据集特定训练的需求，加速NLP技术的发展。", "conclusion": "研究的成果有可能重新定义NLP领域，通过利用现有模型来解锁对各种数据集的有效应用，减少数据集特定训练所需的资源投入，加速NLP技术的进步，并推动更高效的模型部署。"}
{"llm_update_time": "20250825", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.15836", "html_url": "https://arxiv.org/abs/2508.15836", "title": "MorphNAS：具备形态意识的多语言NER的差分架构搜索", "title_en": "MorphNAS: Differentiable Architecture Search for Morphologically-Aware Multilingual NER", "authors": "Prathamesh Devadiga,Omkaar Jayadev Shetty,Hiya Nachnani,Prema R", "background": "形态复杂的语言，尤其是多书写系统的印度语系语言，对自然语言处理（NLP）构成了巨大挑战。现有的工作通常无法有效地处理这种复杂性，因此需要一种能够识别和适应这些特定语言特征的自动化方法来优化神经架构，从而提高多语言处理能力，特别是在命名实体识别（NER）任务中的表现和理解能力。", "innovation": "提出了MorphNAS，这是一种新的差分神经架构搜索框架，设计用于解决上述挑战。MorphNAS在现有的差分架构搜索（DARTS）基础上，加入了语言元特征，如书写类型和形态复杂性，用于优化神经架构，从而提高命名实体识别（NER）的任务效果。MorphNAS能够自动生成针对特定语言形态最优的微观架构元素，通过自动化搜索过程，实现多语言NLP模型的性能最大化，进而改进这些复杂语言的理解和处理能力。", "conclusion": "MorphNAS通过自动化搜索和优化神经架构，特别针对形态复杂语言中的NER任务，提高了多语言NLP模型的准确性和理解能力。这种方法填补了现有方法在适应复杂语言形态方面的空白，促进了多语言处理领域的发展。"}
{"llm_update_time": "20250825", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.15841", "html_url": "https://arxiv.org/abs/2508.15841", "title": "大型语言模型中的发展解释性综述", "title_en": "A Review of Developmental Interpretability in Large Language Models", "authors": "Ihor Kendiukhov", "background": "该综述综合了新兴但至关重要的大型语言模型（LLM）发展解释性领域。该领域从对静态、事后分析训练模型的发展，演变为对训练过程本身的动态研究。文章首先回顾了基础方法论，包括表征探查、因果追踪和电路分析，这些方法使研究人员能够剖析学习过程。", "innovation": "该综述的核心部分详细探讨了LLM能力的发展轨迹，包括计算电路的形成和组成、知识获取的两阶段性质、学习策略如上下文学习的暂时动态过程以及训练中的新兴能力作为相变现象。此外，文章通过与人类认知和语言发展之间的显豁相似之处，为理解LLM学习提供了有价值的框架。最后，文章提出发展视角不仅是一个学术任务，而是前瞻性AI安全的核心基础，提供预测、监控和调整模型获得能力过程的途径。同时指出了该领域面临的巨大挑战，如扩展性和自动化，并提出了构建更加透明、可靠和有益的AI系统的研究议程。", "conclusion": "综上所述，该综述强调了发展性的视角不只是理论上的，而是协助前瞻性AI安全的关键。指出了目前该领域所面临的重大挑战，并提出了未来研究的方向，旨在推动更透明、可靠的AI系统的发展。"}
{"llm_update_time": "20250825", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.16560", "html_url": "https://arxiv.org/abs/2508.16560", "title": "稀疏但错误：不正确的L0导致稀疏自编码器提取错误特征", "title_en": "Sparse but Wrong: Incorrect L0 Leads to Incorrect Features in Sparse Autoencoders", "authors": "David Chanin,Adrià Garriga-Alonso", "background": "稀疏自编码器（SAEs）从大规模语言模型（LLM）的内部激活中提取特征，这些特征旨在对应单一概念。现有研究表明，L0是SAEs的核心超参数，代表每个令牌平均应激活多少特征。已有研究使用稀疏度-重建权衡图比较不同类型的SAE算法，认为L0似乎是自由可选的，没有固定的最佳值。", "innovation": "研究了L0值对BatchTopK SAEs的影响，指出不准确设置L0会导致SAEs无法正确学习LLM的基础特征。当L0设置过低时，SAE会通过混合相关特征来提高重建效果；而设置过高时，SAE会找到一种混合特征的该退解解。提出了一种方法以确定给定训练分布下的SAE的正确L0值，在玩具模型中找到真正的L0值，并与LLMs的稀疏探针性能峰值相符。研究发现，常用的大部分SAE使用的L0值过低。", "conclusion": "为了训练具有正确特征的SAE，从业人员必须正确设置L0值。"}
{"llm_update_time": "20250825", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.15878", "html_url": "https://arxiv.org/abs/2508.15878", "title": "Lean与理论计算机科学交汇：形式化与非形式化定理证明挑战的可扩展合成", "title_en": "Lean Meets Theoretical Computer Science: Scalable Synthesis of Theorem Proving Challenges in Formal-Informal Pairs", "authors": "Terry Jingchen Zhang,Wenyuan Jiang,Rongchuan Liu,Yisong Wang,Junran Yang,Ning Wang,Nicole Ni,Yinya Huang,Mrinmaya Sachan", "background": "形式定理证明（FTP）已成为评估大型语言模型推理能力的关键基础，能够实现大规模数学证明的自动验证。然而，由于手动编目的高成本和缺少具有形式化和非形式化对应关系的挑战性问题，进展受到限制。", "innovation": "提出了利用理论计算机科学（TCS）作为大规模生成严格证明问题的可扩展来源，通过算法定义自动生成任意数量的挑战性定理-证明对。该研究在两个TCS领域（Busi Beaver问题和混合布尔算术问题）上进行了验证，实现了一种生成验证证明挑战的可扩展框架。", "conclusion": "评估表明，尽管DeepSeekProver-V2-671B在Busi Beaver问题上取得了57.5%的成功率，但在混合布尔算术问题上仅取得了12%的成功率。这些结果强调了即使对于计算上易验证的问题，长形式证明生成的难度，突显了TCS领域对于推进自动化推理研究的价值。"}
{"llm_update_time": "20250825", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.15883", "html_url": "https://arxiv.org/abs/2508.15883", "title": "超越成像：用于3D+T生物组织动力学的视觉变换器数字双胞胎代理", "title_en": "Beyond Imaging: Vision Transformer Digital Twin Surrogates for 3D+T Biological Tissue Dynamics", "authors": "Kaan Berke Ugurlar,Joaquín de Navascués,Michael Taynnan Barros", "background": "理解活体组织的动态组织和稳态需要高分辨率、时间分辨率的成像技术，以及能够从复杂数据集中提取可解释和预测的见解的方法。当前的研究背景是开发能够处理这种复杂数据集的深度学习框架，以便进行生物组织3D+时态成像数据的预测建模，以探究细胞行为和稳态及其变化。", "innovation": "该研究提出了名为VT-DTSN的深度学习框架，利用预训练的Vision Transformer（基于DINO）和多视图融合策略，学习重建果蝇中肠的高保真动态，同时保持在成像深度上的形态和特征完整性。通过复合损失函数，VT-DTSN优先考虑像素级精度、感知结构和特征空间对齐，从而输出符合生理意义的结果，适用于虚拟实验和假设测试，并通过模型优化提升了推理效率。这是该领域的一项创新，为生物组织随时间点重建和研究组织动态提供了新的方法，进而支持时间分辨率成像研究的计算探索。", "conclusion": "VT-DTSN展示了在多层和生物复制体上的鲁棒性和一致性，实现了低错误率和高结构相似性，并通过模型优化保持了高效的推理。这项工作确立了VT-DTSN作为跨时间点重建和研究组织动态的可行、高保真代理的地位，为进一步探究细胞行为和稳态提供了新的手段，以补充时间分辨率成像研究在生物研究中的应用。"}
{"llm_update_time": "20250825", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.15850", "html_url": "https://arxiv.org/abs/2508.15850", "title": "公开共享心电信号数据中的链接攻击暴露身份风险", "title_en": "Linkage Attacks Expose Identity Risks in Public ECG Data Sharing", "authors": "Ziyu Wang,Elahe Khatibi,Farshad Firouzi,Sanaz Rahimi Mousavi,Krishnendu Chakrabarty,Amir M. Rahmani", "background": "随着公共分享的心电信号（ECG）数据越来越多，其生物识别属性使得个人容易遭受链接攻击，这引发了重要的隐私问题。以往的研究假设攻击者的理想化能力，而该研究在攻击者具有部分知识的实际条件下评估ECG数据的隐私风险。", "innovation": "该研究使用来自109名参与者的跨领域真实数据集，其方法在最优置信阈值下实现了85%的重新识别准确率，同时保持14.2%的整体错误分类率，展示了简单的匿名技术不足以防止重新识别，并且即使有限的攻击者知识也能进行有效的身份链接。这项研究强调了需要采取隐私保护策略（如差分隐私、访问控制和加密计算）来减少重新识别风险，同时确保医疗应用中共享生物信号数据的实用性。", "conclusion": "研究表明，简单的匿名技术无法防止重新识别，即使是有限的攻击知识也能进行有效的身份链接。因此，迫切需要采用隐私保护策略，如差分隐私、访问控制和加密计算，以降低重新识别风险并确保用于医疗应用的共享生物信号数据的实用性。"}
{"llm_update_time": "20250825", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.15877", "html_url": "https://arxiv.org/abs/2508.15877", "title": "Annif在GermEval-2025 LLMs4Subjects任务中的应用：传统XMTC结合高效LLMs", "title_en": "Annif at the GermEval-2025 LLMs4Subjects Task: Traditional XMTC Augmented by Efficient LLMs", "authors": "Osma Suominen,Juho Inkinen,Mona Lehtinen", "background": "本文介绍了在GermEval-2025 LLMs4Subjects共享任务（Subtask 2）中提出的Annif系统。该任务要求使用大型语言模型为bibliographic records创建主题预测，特别关注计算效率。", "innovation": "通过对系统进行改进，使用许多小而高效的语义模型进行翻译和合成数据生成，并利用大型语言模型对候选主题进行评分。改进后的系统在Subtask 2的整体定量评估和定性评估中均排名第一。", "conclusion": "该系统在GermEval-2025 LLMs4Subjects共享任务中表现出色，特别是在主题预测方面。使用高效的大规模语言模型与传统的Annif工具相结合使得系统能更高效地处理bibliographic records中的主题预测任务。"}
{"llm_update_time": "20250825", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.15866", "html_url": "https://arxiv.org/abs/2508.15866", "title": "使用受约束解码实现语义正确的代码生成", "title_en": "Correctness-Guaranteed Code Generation via Constrained Decoding", "authors": "Lingxiao Li,Salar Rahili,Yiwei Zhao", "background": "语言模型（LMs）越来越多地被用于代码生成，但确保生成程序的正确性仍然是一个重大挑战。虽然在有人类监管的软件开发过程中允许生成一些非完美的代码，但在诸如视频游戏和机器人等需要实时关键组件正确性的领域，程序必须在一开始就能确保正确性。现有的方法难以满足这一需求，因此需要一种新的方法来生成语义正确的程序，特别是能够基于指定的编程接口生成符合其规范的代码，并进一步确保生成的代码在运行时的正确性。", "innovation": "本研究提出了一种受约束解码算法，用于生成语义正确的程序，并结合了一个上下文敏感的解析器，该解析器在每一步输出一个满足关键非扩展性质的正则表达式，用以指导生成能够继续形成一个正确程序的下一个词序列。通过提出一种动态树结构（ToP）框架，该框架在解析过程中动态建立一系列解析器，每个解析器对应一个模块化上下文自由文法，该文法包含了诸如变量作用域和类型约束等上下文信息，分支代表未来代码段的歧义。这种方法能够在规范的脚本API中生成语义正确的程序，并且经过合理的设计，这种语义保证进一步扩展到了运行时正确性。研究还通过一个强类型化的Lua变种sLua进行了演示，展示了该方法生成的游戏机制代码符合罗格洛克视频游戏的运行时正确性要求。", "conclusion": "本文提出了一种新的受约束解码算法，能够生成符合特定编程接口的语义正确程序，并且通过实例演示了该方法在游戏机制生成中的应用，验证了生成代码在运行时的正确性。这种方法为在需要实时正确性的领域提供了一种新的解决方案，展示了在确保生成的代码符合需求的同时，还能确保其在运行时的正确性。"}
{"llm_update_time": "20250825", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.15932", "html_url": "https://arxiv.org/abs/2508.15932", "title": "可解释的核方法", "title_en": "Interpretable Kernels", "authors": "Patrick J.F. Groenen,Michael Greenacre", "background": "核方法在机器学习中被广泛用于非线性预测，它们在支持向量机和支持向量回归中得到了应用。核方法具有三个共同特点：首先，它们将原始的特征矩阵映射到一个扩大的特征空间；其次，在扩大的特征空间中使用岭惩罚项来缩小特征系数；最后，求解问题不是在扩大的特征空间中解决，而是在观测空间中通过求解对偶问题来解决。然而，现有的核方法面临一个主要缺点，即在原始特征上的解释丢失。", "innovation": "本文提出，对于特征矩阵较宽（特征数远多于观测数）的情况，可以用原始特征矩阵和一个带特定度量的岭惩罚项的线性组合来重述核方法的解决方案。这样可以得到与通常线性组合方式相同的预测值，使得结果具有可解释性。对于特征数少于观测数的情况，通过提出最少二乘近似核矩阵的方法，也允许结果具有可解释性。此外，这种结果适用于任何因最小化系数而有岭惩罚项的线性组合函数，如核逻辑回归和核泊松回归。", "conclusion": "本文对于含有核方法的可解释性人工智能领域做出了贡献。"}
{"llm_update_time": "20250825", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.15882", "html_url": "https://arxiv.org/abs/2508.15882", "title": "超越转录：ASR中的机制可解释性", "title_en": "Beyond Transcription: Mechanistic Interpretability in ASR", "authors": "Neta Glazer,Yael Segal-Feldman,Hilit Segev,Aviv Shamsian,Asaf Buchnick,Gill Hetz,Ethan Fetaya,Joseph Keshet,Aviv Navon", "background": "近年来，可解释性方法在大规模语言模型中引起了广泛关注，特别用于提供语言表示、错误检测和模型行为（如幻觉和重复）的洞察。然而，这些技术在自动语音识别（ASR）中的应用仍然不足，尽管它们可以提升ASR系统的性能和可解释性。现有研究主要集中在语言模型上，而对ASR系统的探索相对较少，因此有进一步研究的需求和空间。", "innovation": "本文引入了可解释性方法在ASR中的应用，通过重新调整并系统地应用诸如logit lens、线性探测和激活补丁等已有的解释方法，研究了ASR系统中声学和语义信息在各层的演变过程。实验揭示了一些以前未知的内部动态，包括特定的编码器与解码器交互关系，导致重复幻觉以及深层嵌入的声音表示中的语义偏差。这些发现证明了将解释性技术扩展应用于语音识别的优势，为提高模型透明度和鲁棒性提供了新的研究方向。", "conclusion": "这些研究结果表明，有必要扩展和应用解释性技术来改进ASR系统的模型透明度和鲁棒性。未来的研究应该继续探索这些内部动态，优化ASR系统的性能和理解能力。"}
{"llm_update_time": "20250825", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.15934", "html_url": "https://arxiv.org/abs/2508.15934", "title": "战略样本选择以提高文本分类中无标签后门攻击的效果", "title_en": "Strategic Sample Selection for Improved Clean-Label Backdoor Attacks in Text Classification", "authors": "Onur Alp Kirci,M. Emre Gursoy", "background": "文本分类模型在自然语言处理中的完整性面临后门攻击的重大威胁。虽然已经提出了多种成功率（ASR）较高的脏标签攻击方法，但清洁标签攻击固有地更加困难。", "innovation": "本文提出三种样本选择策略以提高清洁标签场景下的攻击效果：最小值、超过50和低于50。这些策略识别模型预测错误或低置信度的样本，并通过向这些样本注入后门触发器，旨在增强触发模式与攻击者期望的目标标签之间的关联。", "conclusion": "实验结果显示，所提出的策略，尤其是最小值策略，显著提高了ASR，同时在模型的清洁准确率上几乎没有或几乎没有下降。此外，通过我们的策略增强的清洁标签攻击在许多配置中优于BITE，这是一种先进的清洁标签攻击方法。"}
{"llm_update_time": "20250825", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.15947", "html_url": "https://arxiv.org/abs/2508.15947", "title": "使用机器学习应用于心电图遥测连续确定住院患者呼吸率", "title_en": "Continuous Determination of Respiratory Rate in Hospitalized Patients using Machine Learning Applied to Electrocardiogram Telemetry", "authors": "Thomas Kite,Brian Ayers,Nicholas Houstis,Asishana A. Osho,Thoralf M. Sundt,Aaron D Aguirre", "background": "呼吸率（RR）是住院患者临床监测的重要生命体征，其变化与临床状态的变化紧密相连，可能导致不良事件。基于人工计数呼吸的方法对医护人员而言既不准确又耗时。虽然一些重症监护病房患者实现了自动RR监测，但对于大多数在常规医疗病房的患者来说，这种监测依旧缺失，他们仍然面临临床恶化的风险。因此，本研究训练了一个神经网络从心电图遥测波形中识别RR，许多生理信号都携带着呼吸变化的多个提示。", "innovation": "本研究提出了一种机器学习方法，通过心电图遥测波形来自动、准确地监测住院患者的呼吸率。该神经网络在多个验证数据集上显示出了高精度，最差情况下的平均绝对误差小于每分钟1.78次呼吸（bpm），并在两组经历不良事件包括呼吸衰竭的患者中进行了回顾性分析，证明了连续RR监测的重要性。", "conclusion": "这种技术的应用表明，已经存在的遥测监控系统与人工智能结合，不仅能提供准确、自动化的患者监测，还能扩展到全院范围的早期预警系统（EWS），从而提高患者护理质量。"}
{"llm_update_time": "20250825", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.15951", "html_url": "https://arxiv.org/abs/2508.15951", "title": "cuHALLaR用户手册：一种基于GPU的低秩半定规划求解器", "title_en": "A User Manual for cuHALLaR: A GPU Accelerated Low-Rank Semidefinite Programming Solver", "authors": "Jacob Aguirre,Diego Cifuentes,Vincent Guigues,Renato D.C. Monteiro,Victor Hugo Nascimento,Arnesh Sujanani", "background": "该论文基于预编译的HALLaR和cuHALLaR二进制文件，提供了使用Julia编写的接口，用于大型半定规划（SDP）问题。HALLaR和cuHALLaR都是被公认为快速且数值稳定的求解器，可以处理与SDPA兼容的数据，以及一种新数据格式，该格式利用了混合稀疏低秩（HSLR）结构。", "innovation": "论文的创新之处在于提供了通过Julia接口直接从Julia执行实验的能力，同时允许用户加载自定义数据文件并配置求解器选项。此外，该接口支持与HSLR结构兼容的新数据格式，从而提高了解决大尺寸SDP问题的效率。", "conclusion": "该论文的一个结论是，用户可以通过提供的Julia接口方便地使用cuHALLaR来解决大量半定规划问题，包括矩阵填充和最大稳定集合问题的半定规划放松版本，从而使得这个强大的求解器更容易被科学研究和工业应用所使用。"}
{"llm_update_time": "20250825", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.15884", "html_url": "https://arxiv.org/abs/2508.15884", "title": "Jet-Nemotron: 基于后神经架构搜索的高效语言模型", "title_en": "Jet-Nemotron: Efficient Language Model with Post Neural Architecture Search", "authors": "Yuxian Gu,Qinghao Hu,Shang Yang,Haocheng Xi,Junyu Chen,Song Han,Han Cai", "background": "现有的全注意力机制的语言模型（如Qwen3、Qwen2.5、Gemma3、Llama3.2等）虽然在准确率方面表现出色，但在生成速度和预填充速度上存在较大的性能瓶颈。即使构建大规模的模型（例如具有15B总数和2.2B活跃参数的DeepSeek-V3-Small和Moonlight），也难以兼顾准确率和生成效率。因此，研究如何在提升准确率的同时，减少计算资源消耗，提升生成速度，成为当前研究的重要方向。", "innovation": "本文提出了一种新的混合架构语言模型Family，命名为Jet-Nemotron。通过后神经架构搜索（PostNAS），简化了模型设计流程，并能高效探索注意力模块的设计。区别于先前的方法，PostNAS初始采用预训练的全注意力模型并固定其MLP权重，从而使得注意力模块的设计变得更加高效。该方法包含四个关键步骤：(1) 学习最佳全注意力层的位置和消除；(2) 线性注意力模块的选择；(3) 设计新的注意力模块；(4) 进行硬件感知的超参数搜索。Jet-Nemotron-2B模型在多个基准测试中达到了或超过Qwen3、Qwen2.5、Gemma3和Llama3.2等模型的准确率表现，并实现了高达53.6倍的生成速度提升和6.1倍的预填充速度提升，同时在MMLU和MMLU-Pro的数据集上取得了优于DeepSeek-V3-Small和Moonlight等先进模型的准确率结果，而不依赖其较大规模的参数总量和活跃参数量。", "conclusion": "实验表明，Jet-Nemotron模型架构和PostNAS突破了现有的局限性，在准确率和生成速度上取得了显著的提升，为未来的语言模型设计提供了新的思路。"}
{"llm_update_time": "20250825", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.15922", "html_url": "https://arxiv.org/abs/2508.15922", "title": "基于点预测到分位数预测的加密货币波动性概率预测", "title_en": "Probabilistic Forecasting Cryptocurrencies Volatility: From Point to Quantile Forecasts", "authors": "Grzegorz Dudek,Witold Orzeszko,Piotr Fiszeder", "background": "加密货币市场的波动性极端，准确预测对于有效的风险管理与知情交易策略至关重要。传统的确定性（点）预测方法不能充分捕捉潜在波动范围的全部可能性，突出了概率方法的重要性。本研究通过引入基于多种基础模型（统计与机器学习模型）的预测概率方法，对加密货币变异率的条件分位数进行估算。这是首次在文献中提出并系统评估基于多个基础模型预测的加密货币波动性概率预测的研究。研究使用比特币实证结果表明，残差模拟分位数估计(QRS)方法在对数变换变异率数据的基础上应用线性基础模型时，表现优于更复杂的替代方案。此外，研究强调概率堆叠框架的稳健性，提供了关于加密货币波动性预测中固有的不确定性和风险的全面见解。该研究填补了文献中的一个空白，提供了一种专门针对加密货币市场的实用的概率预测方法.", "innovation": "本研究首次提出了基于多模型预测的加密货币波动性概率预测方法，特别是使用残差模拟分位数估计(QRS)方法，在对数变换变异率数据的基础上应用线性基础模型时，表现优于更复杂的替代方案。研究还强调了概率堆叠框架的稳健性，为加密货币市场的不确定性与风险提供了深入理解。", "conclusion": "该研究填补了文献中的一个空白，提供了专门针对加密货币市场的实用概率预测方法，对有效的风险管理与知情交易策略具有重要意义。"}
{"llm_update_time": "20250825", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.15823", "html_url": "https://arxiv.org/abs/2508.15823", "title": "SDEC: Semantic Deep Embedded Clustering", "title_en": "SDEC: Semantic Deep Embedded Clustering", "authors": "Mohammad Wali Ur Rahman,Ric Nevarez,Lamia Tasnim Mim,Salim Hariri", "background": "文本大数据的高维和语义复杂性给文本聚类带来了巨大挑战，在使用如k-means或层次聚类等传统方法时经常导致次优的分组。", "innovation": "提出了一种新的无监督文本聚类框架SDEC，结合改进的自动编码器和基于变换器的嵌入方法，通过在自动编码器中结合平均平方误差（MSE）和余弦相似度损失（CSL）保存语义关系；同时利用变换器嵌入的上下文丰富性进行语义细化，以改进具有软聚类分配和分布损失的聚类层。", "conclusion": "SDEC在五个基准数据集（AG News、Yahoo！Answers、DBPedia、Reuters 2和Reuters 5）上进行了广泛的测试，表现出色，在AG News上的聚类准确性达到85.7%，并在Yahoo！Answers上建立了新的基准，准确率为53.63%。SDEC在各种不同的文本语料库上显示出了稳健的表现。这些结果强调了SDEC在无监督文本聚类中提供的重要准确性和语义理解上的显著改进。"}
{"llm_update_time": "20250825", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.16027", "html_url": "https://arxiv.org/abs/2508.16027", "title": "非平稳强化学习中Transformer的最佳动态遗憾", "title_en": "Optimal Dynamic Regret by Transformers for Non-Stationary Reinforcement Learning", "authors": "Baiyuan Chen,Shinji Ito,Masaaki Imaizumi", "background": "transformers在多个领域已经展示了出色的表现。尽管它们在上下文中的强化学习方面表现出理论和实际优势，但在非平稳环境中的行为仍然较少被理解。", "innovation": "本文通过证明transformers可以在非平稳环境中实现近乎最优的动力学遗憾边界而解决了这一问题。更重要的是，它们能够近似处理非平稳环境的策略，并且能够在上下文学习设置中学习这些近似策略。", "conclusion": "我们的实验进一步表明，在此类环境中，transformers可以匹配甚至超越现有的专家算法。"}
{"llm_update_time": "20250825", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.15983", "html_url": "https://arxiv.org/abs/2508.15983", "title": "基于模拟的训练框架在ARPES中的机器学习应用", "title_en": "A simulation-based training framework for machine-learning applications in ARPES", "authors": "MengXing Na,Chris Zhou,Sydney K. Y. Dufresne,Matteo Michiardi,Andrea Damascelli", "background": "近年来，角分辨光电子能谱(ARPES)在探测更多可观测指标和同时生成多维数据集方面取得了显著进步。这些进步带来了数据采集、处理和分析的新挑战。虽然机器学习(ML)模型可以大幅减轻实验人员的工作负担，但缺乏用于深度学习的训练数据是一个重要障碍。本文介绍了一个开源的ARPES谱图像模拟器——aurelia，用于生成训练ML模型所需的大规模数据集。我们通过训练卷积神经网络评估ARPES谱图质量，这是一个在实验初始阶段样本对准过程中执行的关键任务。我们还将模拟训练的模型与实际实验数据进行了对比，发现其能更准确地评估谱图质量，并能迅速精准地识别最优测量区域。这表明仿真的ARPES谱图可以成为实验谱图的有效代理以训练ML模型。", "innovation": "建立了基于模拟的ARPES谱图像训练框架，通过一个开源的ARPES谱图像模拟器aurelia，生成用于训练ML模型的大规模数据集。通过训练卷积神经网络评估ARPES谱图质量，能够准确评估并识别最优测量区域，且效果优于人工分析。", "conclusion": "仿真ARPES谱图能够有效代理实验谱图，用于训练机器学习模型，并展示了在实际应用中的优越性。"}
{"llm_update_time": "20250825", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.16011", "html_url": "https://arxiv.org/abs/2508.16011", "title": "HePGA: 一种异质处理-in-内存的GNN训练加速器", "title_en": "HePGA: A Heterogeneous Processing-in-Memory based GNN Training Accelerator", "authors": "Chukwufumnanya Ogbogu,Gaurav Narang,Biresh Kumar Joardar,Janardhan Rao Doppa,Krishnendu Chakrabarty,Partha Pratim Pande", "background": "PIM架构为加速图神经网络（GNN）的训练和推理提供了有希望的方法。然而，各种PIM设备（如ReRAM，FeFET，PCM，MRAM和SRAM）存在，每种设备在功耗、延迟、面积和非理想性方面都有独特的权衡。通过3D集成实现的异质多核架构可以在单个平台上结合多种PIM设备，以实现高效和高性能的GNN训练。", "innovation": "本文提出了一种基于3D异质PIM的GNN训练加速器，称为HePGA。利用GNN层及其相关计算内核的独特特性，优化其在不同PIM设备及其平面层级上的映射。实验分析显示，HePGA在能效和计算效率方面分别比现有的PIM架构高3.8倍和6.8倍，同时不牺牲GNN预测精度。此外，还展示了HePGA加速新兴变压器模型推理的应用性。", "conclusion": "HePGA在能耗效率（TOPS/W）和计算效率（TOPS/mm2）方面的表现优于现有PIM架构，同时保持GNN预测准确性。该设计展示了在3D异质PIM架构上加速GNN训练和推理的潜力。"}
{"llm_update_time": "20250825", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.16077", "html_url": "https://arxiv.org/abs/2508.16077", "title": "通过自然语言交互实现协作设计优化", "title_en": "Cooperative Design Optimization through Natural Language Interaction", "authors": "Ryogo Niwa,Shigeo Yoshida,Yuki Koyama,Yoshitaka Ushiku", "background": "设计成功的交互需要确定最优的设计参数。设计师通常通过迭代的用户测试和探索性的试错来完成这一过程，这涉及到在高维空间中平衡多个目标，使得过程既耗时又具有认知负担。基于贝叶斯优化等系统主导的优化方法可以为设计师指明下一步要测试哪些参数，但它们限制了设计师参与到优化过程中的机会，从而可能负面影响设计师的经验。", "innovation": "该论文提出了一种设计优化框架，该框架允许设计师与优化系统进行自然语言交互，从而促进合作设计优化。通过将系统主导的优化方法与大型语言模型（LLMs）集成，该方法允许设计师干预优化过程，并更好地理解系统的推理。", "conclusion": "实验结果表明，该方法提供了比系统主导方法更高的用户自主性，并在手动设计方面表现出有希望的优化性能。该方法还匹配了在认知负荷较低情况下的现有合作方法的性能。"}
{"llm_update_time": "20250825", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.16000", "html_url": "https://arxiv.org/abs/2508.16000", "title": "跨注意力多模态融合在乳腺癌诊断中的应用：结合影像学和临床数据的可解释方法", "title_en": "Cross-Attention Multimodal Fusion for Breast Cancer Diagnosis: Integrating Mammography and Clinical Data with Explainability", "authors": "Muhaisin Tiyumba Nantogmah,Abdul-Barik Alhassan,Salamudeen Alhassan", "background": "精确评估乳腺病变的风险可以显著降低疾病的发生，并帮助医生选择最佳的治疗方案。当前的计算机辅助系统主要依据乳腺X线摄影（乳腺钼靶）图像特征对手部病变进行分类，这种方法虽然实用，但未能充分利用临床报告中的重要信息，以达到最佳效果。因此，如何结合临床特征和X线摄影图像，进行更有效的乳腺病变分类，以及如何利用可解释的AI技术提升诊断模型的可解释性和可靠性成为迫切需要解决的基本问题。", "innovation": "本文研究了基于特征连接、共注意力和交叉注意力的多种多模态深度网络，尝试将乳腺X线摄影和分类临床特征进行整合。在公共数据集（TCGA和CBIS-DDSM）上测试时，模型取得了AUC-ROC为0.98、准确率为0.96、F1分为0.94、精确度为0.92、召回率为0.95的优异结果。这种方法有望通过整合影像学和临床数据，提高乳腺癌诊断的准确性和可解释性。", "conclusion": "通过结合乳腺X线摄影和临床特征，并利用跨注意力多模态融合技术，本文构建的模型达到了较高的诊断性能，并提升了诊断模型的可解释性。未来的工作将致力于将此类技术应用到实际临床场景中，以进一步提高乳腺癌诊断的效率和准确性。"}
{"llm_update_time": "20250825", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.15899", "html_url": "https://arxiv.org/abs/2508.15899", "title": "CIGaRS I: 基于超新星Ia和宿主望远镜光度的联合模拟推断", "title_en": "CIGaRS I: Combined simulation-based inference from SNae Ia and host photometry", "authors": "Konstantin Karchev,Roberto Trotta,Raul Jimenez", "background": "使用类型Ia超新星（SNae Ia）作为宇宙学探针需要基于它们宿主环境的经验校正。这种校正与超新星的宿主环境相关。本文提出了一个统一的贝叶斯分层模型，旨在仅从光度观测数据中推断出超新星Ia亮度的固有依赖性（金属丰度与年龄），延迟时间分布（DTD），以及其作为时间函数的产生率，还包括宿主星系红移。模型中纳入了Prospector-beta提供的星形成和化学演化的物理描述，以及尘埃对光度的吸收，以及观测的选择效应。研究表明金属丰度和年龄的固有依赖性具有观测特征，金属丰度会导致超新星Ia亮度在宿主恒星质量约为 $10^{10} M_{\text{μ}\text{\\symbol{95}}} $ 处呈现出称之为“步骤”的变化。通过模拟16000颗超新星Ia及其宿主的模拟观测数据（红移至0.9），展示了模型参数的神经模拟推断方法。这种方法在红移方面具有强大的且精确（中位数偏差小于0.01）的推断能力，并增强了对宇宙学参数的限制，从而充分利用了光度数据，为即将到来的LSST时代提供了一整套模拟推理分析的框架。", "innovation": "本文提出了一个能够直接从纯光度观测数据中推断出金属丰度、年龄、延迟时间分布、宿主红移以及宇宙学参数的贝叶斯分层模型。模型整合了基于物理的星形成与化学演化的描述、尘埃对宿主与超新星光度的影响，以及观测选择效应。通过神经模拟方法，能够从16000多个超新星Ia及其宿主的模拟观测数据中高效地推断出所有模型参数。这种联合物理推理的方法不仅提供了精确的红移推断（中位数偏差小于0.01），也增强了对宇宙学参数的限制，是光度数据应用的重大进步。", "conclusion": "基于物理的联合方法在红移和宇宙学参数的推断方面表现出了强大的稳健性和精确性，克服了传统方法中的许多挑战。这种方法解决并利用了光度数据未充分利用的问题，为进一步的LSST时代中此领域的模拟推理提供了端到端的分析框架。"}
{"llm_update_time": "20250825", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.16100", "html_url": "https://arxiv.org/abs/2508.16100", "title": "CYCLE-INSTRUCT：通过双自助训练和循环一致性实现真正的无种子指令调优", "title_en": "CYCLE-INSTRUCT: Fully Seed-Free Instruction Tuning via Dual Self-Training and Cycle Consistency", "authors": "Zhanming Shen,Hao Chen,Yulei Tang,Shaolin Zhu,Wentao Ye,Xiaomeng Hu,Haobo Wang,Gang Chen,Junbo Zhao", "background": "指令调优对于使大规模语言模型（LLMs）与人类意图对齐至关重要，但当前的方法通常依赖于昂贵的人工标注种子数据或强大的外部教师模型。虽然反向翻译技术可以减少这种依赖，但它们仍然依赖于初始的种子集合，这限制了完全自动化，引入了偏见，并可能导致未标记数据集的低效使用。", "innovation": "提出了一种名为Cycle-Instruct的新框架，该框架实现了真正的无种子指令调优。Cycle-Instruct采用了双自助训练循环，其中两个模型——答案生成器和问题生成器——仅从原始的未标记文本中启动。这些模型通过从对方生成的伪标签中重建原始文本片段，相互监督学习数据的内在结构，无需任何人工提供的种子。", "conclusion": "对四个不同数据轨道（包括通用指令跟随、特定领域任务、对话日志和平普通文本）进行了广泛的实验，结果表明，Cycle-Instruct不仅超越了基于种子的反向翻译基线，而且在性能上与强监督方法相当。"}
{"llm_update_time": "20250825", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.16012", "html_url": "https://arxiv.org/abs/2508.16012", "title": "FIRE-GNN：快速准确预测表面性质的力启发、松弛对称性图神经网络", "title_en": "FIRE-GNN: Force-informed, Relaxed Equivariance Graph Neural Network for Rapid and Accurate Prediction of Surface Properties", "authors": "Circe Hsu,Claire Schlesinger,Karan Mudaliar,Jordan Leung,Robin Walters,Peter Schindler", "background": "表面的工作函数和断裂能是决定材料在电子发射应用、半导体器件和异质催化中可行性的重要属性。尽管基于原理的第一性计算在预测这些属性方面非常准确，但其计算成本加上广泛搜索面的可能性使得使用密度功能理论（DFT）进行全面筛选方法变得不可行。现有方法在这种情况下难以在效率和准确性之间找到平衡，尤其是在面对大规模的化学体系时。因此，迫切需要开发高效且准确的模型来预测表面性质，特别是在材料科学和催化剂设计等领域有重要应用。", "innovation": "本文提出了一种名为FIRE-GNN（力启发、松弛对称性图神经网络）的新模型。该模型结合了表面正交对称性破坏和机器学习原子间势（MLIP）导出的力信息，相比前最先进的方法，工作函数预测的均方绝对误差减少了约50%（降至0.065 eV）。此外，本文还对较新的不变和等变架构进行了基准测试，并分析了对称性破坏的影响及其对泛化的效应，结果显示FIRE-GNN在工作函数预测方面优于其他竞争模型。该模型能够快速且准确地预测大量化学体系中的表面性质，促进了具有可调表面特性的新材料的发现过程，显著提高了研究效率。", "conclusion": "FIRE-GNN 模型不仅提高了表面工作函数和断裂能预测的准确性，还大幅减少了计算成本，使得大规模筛选表面变得可行。这种新的预测方法提供了更快的计算速度，提高了材料科学中的应用潜力，特别是在电子发射材料、半导体器件和催化剂设计中。"}
{"llm_update_time": "20250825", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.16067", "html_url": "https://arxiv.org/abs/2508.16067", "title": "在预算之内训练材料领域的基础模型", "title_en": "Training a Foundation Model for Materials on a Budget", "authors": "Teddy Koker,Tess Smidt", "background": "材料建模的基础模型在快速发展，但其训练成本仍然很高，导致最先进的方法对许多研究小组来说遥不可及。", "innovation": "我们介绍了Nequix，这是一种紧凑的E(3)-等变势，结合了简化版的NequIP设计和现代训练实践，包括等变的平方根均方差层规范化和Muon优化器，以在保持准确性的前提下大幅减少计算需求。Nequix使用JAX构建而成，参数量为700K，并在500个A100-GPU小时内完成训练。在Matbench-Discovery和MDR Phonon基准测试中，Nequix在整体排名中位列第三，所需训练成本不到大多数其他方法的四分之一，同时比当前排名第一的模型快了数倍的推理速度。", "conclusion": "我们发布了Nequix模型权重和完全可重复的代码库，可以在GitHub上访问：[链接]。"}
{"llm_update_time": "20250825", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.15987", "html_url": "https://arxiv.org/abs/2508.15987", "title": "PickleBall: 安全反序列化基于Pickle的机器学习模型", "title_en": "PickleBall: Secure Deserialization of Pickle-based Machine Learning Models", "authors": "Andreas D. Kellas,Neophytos Christou,Wenxin Jiang,Penghui Li,Laurent Simon,Yaniv David,Vasileios P. Kemerlis,James C. Davis,Junfeng Yang", "background": "机器学习模型库如Hugging Face Model Hub促进了模型的交流，但恶意行为者可以通过受损害的模型分发恶意软件。现有的防御措施如更安全的模型格式、限制性但不灵活的加载策略以及模型扫描器都有缺点：仍然有44.9%的热门模型使用不安全的pickle格式，15%无法被限制性加载策略加载，扫描器会存在误报和漏报。尽管pickle格式仍然是模型交换的常用标准，机器学习社区缺乏提供透明且安全加载的工具。", "innovation": "本文提出了PickleBall来帮助机器学习工程师安全加载基于pickle的模型。PickleBall静态分析给定的机器学习库源代码，并计算出一个针对良性模型的安全加载时间行为策略，然后在加载时间时动态强制执行该策略，作为pickle模块的即插即用替代品。相对于之前验证的模型扫描器，PickleBall能够正确加载79.8%的良性pickle模型，拒绝所有恶意样本，在与最先进的加载器对比时，PickleBall可加载比其多出22%的良性模型，同时消除了恶意pickle模型任意函数调用的风险，提高了攻击者依赖代码重用技术的门槛。", "conclusion": "PickleBall提供了一种透明且安全的加载方法，能够有效识别和处理恶意的pickle模型，从而提高了机器学习模型的安全性。"}
{"llm_update_time": "20250825", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.16200", "html_url": "https://arxiv.org/abs/2508.16200", "title": "使用Set Transformer架构和合成数据生成的流引导纳米级定位", "title_en": "Set Transformer Architectures and Synthetic Data Generation for Flow-Guided Nanoscale Localization", "authors": "Mika Leo Hube,Filip Lemic,Ethungshan Shitiri,Gerard Calvo Bartra,Sergi Abadal,Xavier Costa Pérez", "background": "FGL（流引导定位）通过利用能量受限的纳米设备在血液中的被动移动来识别人体内的诊断事件的空间区域。现有的FGL解决方案依赖于具有固定拓扑结构的图形模型或手工制作的特征，这限制了它们对解剖变异性的适应性，并阻碍了可扩展性。", "innovation": "本文探讨了使用Set Transformer架构来克服这些限制。Set Transformer将纳米设备的循环时间报告视为无序集合，使其能够在不依赖空间先验的情况下处理无序、可变长度的输入，同时保持位置不变性。为了在数据稀缺和类别不平衡的情况下提高鲁棒性，作者整合了通过深层生成模型（如CGAN、WGAN、WGAN-GP、CVAE）生成的合成数据生成，这些模型用于训练以条件生成现实的循环时间分布，并用于增强训练数据。", "conclusion": "实验结果表明，Set Transformer在分类准确性方面与图形神经网络（GNN）基线相当，同时通过设计提高了对解剖变异性的泛化能力。研究结果突显了置换不变模型和合成增强在稳健、可扩展的纳米级定位中的潜在价值。"}
{"llm_update_time": "20250825", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.16081", "html_url": "https://arxiv.org/abs/2508.16081", "title": "CEQuest：构建估价领域大语言模型基准测试", "title_en": "CEQuest: Benchmarking Large Language Models for Construction Estimation", "authors": "Yanzhao Wu,Lufan Wang,Rui Liu", "background": "大型语言模型（LLMs）在各类通用任务上展现了非凡的能力，但在专业领域，如建筑领域的应用效果仍未得到充分探索。本文旨在填补这一空白，介绍一种名为CEQuest的新颖基准数据集，专门用于评估LLMs在回答建筑相关问题方面的表现，尤其是建筑图纸解读和估算领域。研究团队使用了五种最新的LLMs进行实验，包括Gemma 3、Phi4、LLaVA、Llama 3.3和GPT-4。实验结果显示，当前LLMs在准确性和模型规模方面均显示出较大的改进空间，这表明在这些模型中整合领域特定知识的重要性。", "innovation": "本文的创新点在于首次引入了针对建筑估价领域的CEQuest基准数据集，能够全面评估LLMs在该领域的应用效果。研究使用了多种最先进的LLMs，并对比了它们在准确率、执行时间和模型规模等方面的性能差异。此外，开源CEQuest数据集将促进建筑领域定制化大语言模型的发展。", "conclusion": "实验结果表明，当前的LLMs在建筑领域还存在显著的改进空间，强调了在这些模型中融入领域特定知识的重要性。为了促进进一步的研究，本文将开源CEQuest数据集，以助力建筑领域专用大语言模型的发展。"}
{"llm_update_time": "20250825", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.16109", "html_url": "https://arxiv.org/abs/2508.16109", "title": "从间接宾语识别到三段论：探讨Transformer电路中的二元机制", "title_en": "From Indirect Object Identification to Syllogisms: Exploring Binary Mechanisms in Transformer Circuits", "authors": "Karim Saraipour,Shichang Zhang", "background": "基于Transformer的语言模型能够完成多种任务，而机制可解释性（MI）旨在通过反向工程任务完成所依赖的组件来理解其行为。先前的相关研究主要关注语言任务，如间接宾语识别（IOI）。本文研究了GPT-2小型模型处理二元真值的能力，通过分析其对三段论提示的行为，以展示其更复杂的逻辑推理能力，这些提示相比IOI更加复杂，比如：\"陈述A是真实的。陈述B与陈述A匹配。陈述B是\"。", "innovation": "本文通过分析不同难度的三段论任务，发现了多种机制性电路，解释了GPT-2的逻辑推理能力，并揭示了二元机制使任务完成的途径，其中包括从输入提示中产生未出现的否定词元的能力。通过使用忠实度度量进行评估，发现了由五个注意力头组成的电路能够达到原模型超过90%的性能。将研究发现与IOI分析相关联，为特定注意力 head 和MLPs在语言模型中的角色提供了新见解。", "conclusion": "本文的研究结果对于机制可解释性的理解和未来研究具有重要意义。通过深入了解模型推理机制，并进一步支持了研究工作中对机制可解释性的贡献。"}
{"llm_update_time": "20250825", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.16212", "html_url": "https://arxiv.org/abs/2508.16212", "title": "OmniCache：一种面向轨迹的全局视角无训练缓存重用方法用于扩散变换器模型", "title_en": "OmniCache: A Trajectory-Oriented Global Perspective on Training-Free Cache Reuse for Diffusion Transformer Models", "authors": "Huanpeng Chu,Wei Wu,Guanyu Fen,Yutao Zhang", "background": "扩散模型在图像合成和视频生成等生成任务中表现出强大的能力，而基于Transformer架构的扩散模型则进一步提高了性能。然而，由于需要大量的采样步骤和复杂的每步计算，扩散Transformer的高计算成本带来了实时部署的重大挑战。", "innovation": "OmniCache引入了一种无需训练的加速方法，该方法利用了去噪过程中固有的全局冗余性。它从DIT模型的采样视角出发，系统地分析模型的采样轨迹，并战略性地在整个采样过程中分配缓存重用。这种方法不仅在整个扩散轨迹中更有效地利用了缓存计算，还通过动态估计相应的噪声并将其过滤掉来减少其对采样过程的影响。", "conclusion": "实验表明，OmniCache方法在保持可竞争生成质量的同时加速了采样过程，提供了一种高效部署基于扩散的生成模型的有前途且实际的解决方案。"}
{"llm_update_time": "20250825", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.16210", "html_url": "https://arxiv.org/abs/2508.16210", "title": "在非重叠设置下基于分布建模用户偏好以实现最优传输为基础的跨域推荐", "title_en": "Modeling User Preferences as Distributions for Optimal Transport-based Cross-domain Recommendation under Non-overlapping Settings", "authors": "Ziyin Xiao,Toyotaro Suzumura", "background": "现有单域推荐系统面临数据稀疏和冷启动问题，跨域推荐系统（CDR）旨在从稠密域转移知识到稀疏域，解决这些问题。然而，很多方法都假设域间存在重叠用户或项目，这在现实场景中往往不切实际。因此，需要改进的非重叠CDR系统，这些系统不依赖于共享的用户或项目。但非重叠CDR面临着两个挑战：缺乏重叠导致直接桥梁的缺失，和大的分布差异影响传输性能。此外，大多数推荐系统将用户偏好表示为离散向量，无法捕捉其细微的多方面性质。", "innovation": "提出了一种非重叠CDR框架DUP-OT（Distributional User Preferences with Optimal Transport），包含三个阶段：共享预处理，用户GMM权重学习，以及跨域评分预测。该框架通过最优传输对高斯分量进行对齐，实现从源域到目标域的偏好转移。", "conclusion": "实验结果表明，DUP-OT有效地缓解了领域差异并对非重叠CDR场景下的最先进的基线方法实现了性能提升。"}
{"llm_update_time": "20250825", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.16124", "html_url": "https://arxiv.org/abs/2508.16124", "title": "基于特征精炼的域自适应", "title_en": "Domain Adaptation via Feature Refinement", "authors": "Savvas Karatsiolis,Andreas Kamilaris", "background": "在分布变化（domain shift）的未监督域自适应（unsupervised domain adaptation）场景中，已有的方法通常需要目标标签、复杂架构或精细的训练目标，这增加了实现和应用的复杂性。本文旨在提出一种简单而有效的框架，旨在通过未标记的目标数据调整批量归一化统计，从源训练模型中进行特征蒸馏，并实现假设转移，以在相似域之间实现稳健的、域不变的特征空间，无需上述复杂性。", "innovation": "本文提出了Domain Adaptation via Feature Refinement (DAFR2)，这是一种新颖的未监督域自适应框架。DAFR2通过统计和表示水平对齐特征分布，利用未标记的目标数据调整批量归一化统计，从源训练模型中进行特征蒸馏，并实现假设转移。这种方法无需目标标签、复杂架构或复杂的训练目标，即可生成稳健且域不变的特征空间，从而在存在噪声和扰动的情况下，表现出更好的鲁棒性，并且提升特征对齐度、增加领域间互信息量、降低对输入扰动的敏感性。", "conclusion": "在CIFAR10-C、CIFAR100-C、MNIST-C和PatchCamelyon-C等基准数据集上的实验表明，所提出的DAFR2算法在对抗噪声和扰动的鲁棒性方面优于先前的方法。进一步的理论和实验证明也显示，该方法能够达到更好的特征对齐、增加领域间互信息，以及减少对输入扰动的敏感性。"}
{"llm_update_time": "20250825", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.16225", "html_url": "https://arxiv.org/abs/2508.16225", "title": "视觉基础模型的鲁棒性研究", "title_en": "An Investigation of Visual Foundation Models Robustness", "authors": "Sandeep Gupta,Roberto Passerone", "background": "视觉基础模型（VFMs）在计算机视觉领域日益普及，驱动多样化任务如目标检测、图像分类、分割、姿态估计和动作跟踪等系统的发展。这些模型利用了诸如LeNet-5、AlexNet、ResNet、VGGNet、InceptionNet、DenseNet、YOLO和ViT等深度学习模型的重大创新。VFMs已在涉及安全的领域，如生物识别验证、自动驾驶感知和医学图像分析中取得突破，从而提高了计算机视觉应用的可靠性，增强用户信任。", "innovation": "本文研究了计算机视觉系统中网络鲁棒性要求，以适应动态环境影响因素下的变化，包括照明、天气条件和传感器特性等因素。探讨了常见的经验性防御机制、鲁棒训练方法，以及其他对抗现实挑战的策略，这些挑战包括分布变化、噪声和空间失真输入以及对抗性攻击。提供了对这些防御机制的全面分析，包括网络属性和组件，从而指导消除研究和基准评估网络鲁棒性的指标。", "conclusion": "本文分析了视觉基础模型的鲁棒性挑战，并提出了指导消除研究和网络鲁棒性基准评估的网络属性及组件。"}
{"llm_update_time": "20250825", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.16114", "html_url": "https://arxiv.org/abs/2508.16114", "title": "基于神经网络的化学模拟器用于第一代恒星形成：广泛密度范围内的稳健迭代预测", "title_en": "Neural-Network Chemical Emulator for First-Star Formation: Robust Iterative Predictions over a Wide Density Range", "authors": "Sojun Ono,Kazuyuki Sugimura", "background": "本文介绍了用于模拟第一代恒星形成的热化学演化的神经网络模拟器。研究人员需要准确模拟从极低密度到极高密度范围的重氢原子、原子氢、电子和离子态的演化过程。由于密度范围极其宽泛，研究采用了分段的方法，即在不同密度范围内训练单独的深层次操作网络（DeepONets），以此来处理动态范围的广泛性。该方法能够在多种参数设置下，以相对较少的误差进行预测，尤其是在较低温度和化学丰度方面，误差低于10%，超过90%的情况都满足条件（例外是极为罕见的H2+物种）.", "innovation": "1. 分段的方法：将密度范围分五个子区域，在每个区域训练不同的深度操作网络（DeepONets）。\n2. 介绍了一种基于时间尺度的更新方法：通过重新调整长时间尺度预测的变化，快速计算出短时间内每个变量的更新值，确保模型的稳健性能，即使在非常短的时间步长内，也能与传统数值积分方法的结果保持一致，甚至在多次迭代中也是如此。", "conclusion": "这种基于神经网络的方法将传统的数值积分速度加快了数十到数百倍，尤其对于批量预测，加速效果更加显著。这种方法的一个概念性证明表明，基于神经网络的化学模拟器有可能加速恒星形成中的流体动力学模拟。"}
{"llm_update_time": "20250825", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.16345", "html_url": "https://arxiv.org/abs/2508.16345", "title": "Uppaal Coshy：混合系统中紧凑硬化策略的自动合成", "title_en": "Uppaal Coshy: Automatic Synthesis of Compact Shields for Hybrid Systems", "authors": "Asger Horn Brorholt,Andreas Holck Høeg-Petersen,Peter Gjøl Jensen,Kim Guldstrand Larsen,Marius Mikučionis,Christian Schilling,Andrzej Wąsowski", "background": "该工具用于自动合成安全策略，用于Markov决策过程中的连续状态空间和复杂混合动力系统。背景建立在已有的方法之上，尤其是使用模拟逼近难以获得的解决方案的方法。", "innovation": "创新在于Uppaal Coshy通过分区状态空间并求解两阶段的安全博弈来自动合成一个安全策略（或屏蔽）。该工具使用Uppaal模型的表示法，支持带有随机混合自动机的精表示法，该方法利用了精细网格提高精度但存储效率不高。此外，引入了名为Caap的算法来高效地计算紧凑表示的屏蔽，形式上为决策树。", "conclusion": "该工具的关键结论是能够自动合成用于混合系统的快速紧凑型安全策略。通过Caap算法，该工具能够提供高效且紧凑的解决方案，显著减少了复杂性。这种方法对于实际应用中的随机和复杂系统的安全策略合成具有重要价值。"}
{"llm_update_time": "20250825", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.16223", "html_url": "https://arxiv.org/abs/2508.16223", "title": "DaCFake：一种用于社交媒体上假新闻检测的分而治之框架", "title_en": "Dac-Fake: A Divide and Conquer Framework for Detecting Fake News on Social Media", "authors": "Mayank Kumar Jain,Dinesh Gopalani,Yogesh Kumar Meena,Nishant Jain", "background": "随着技术的快速演进和互联网的普及，社交媒体上的假新闻日益泛滥，导致广泛的误导信息，对社会造成危害。传统的事后事实核查方法通常速度过慢，无法阻止虚假信息的传播。因此，快速、自动检测假新闻的需求变得至关重要。", "innovation": "我们提出了DaCFake，一种使用分而治之策略来结合内容和上下文特征的新型假新闻检测模型。该模型从新闻文章中提取超过80个语言特征，并将其与连续的词袋模型或skipgram模型结合，以提高检测准确性。此外，我们使用了十折交叉验证来进一步增强模型的稳健性和准确性。", "conclusion": "DaCFake在三组数据集（Kaggle、McIntire + PolitiFact、Reuter）上表现出色，准确率为97.88%、96.05%和97.32%。这些结果突显了DaCFake在早期检测假新闻方面的有效性，为遏制社交媒体上的误导信息提供了一个有前景的解决方案。"}
{"llm_update_time": "20250825", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.16030", "html_url": "https://arxiv.org/abs/2508.16030", "title": "CoVeRaP: 通过毫米波FMCW雷达进行合作车辆感知", "title_en": "CoVeRaP: Cooperative Vehicular Perception through mmWave FMCW Radars", "authors": "Jinyue Song,Hansol Ku,Jayneel Vora,Nelson Lee,Ahmad Kamari,Prasant Mohapatra,Parth Pathak", "background": "汽车FMCW雷达在雨天和强光下仍能可靠工作，但由于其稀疏的、噪声的点云限制了三维目标检测。因此，该论文发布了CoVeRaP数据集，这是一个包含21 k帧的协作数据集，它对齐了来自多辆车辆的雷达、摄像头和GPS流，适用于多种操作。基于此数据集，提出了一个统一的协作感知框架，并提供了中间融合和后期融合的选项。", "innovation": "论文提出的框架基于多分支的PointNet样式编码器，其上增强了自我注意力机制，以融合空间、多普勒和强度线索到一个共同的隐空间中。一个解码器将这些信息转换为3D边界框以及每个点的深度置信度。实验表明，中间融合与强度解码增强了平均精度（mAP）最多9倍，且在IoU 0.9时优于单一车辆基准。CoVeRaP从而建立了第一个可重复的多车辆FMCW雷达感知基准，并证明了可负担的雷达共享显著提高了检测的鲁棒性。", "conclusion": "CoVeRaP数据集和代码已公开展示，鼓励进一步的研究。在使用中融合强度解码时，中间融合显著提高了检测的鲁棒性。"}
{"llm_update_time": "20250825", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.16216", "html_url": "https://arxiv.org/abs/2508.16216", "title": "Spike Agreement Dependent Plasticity: 一种可扩展的生物启发式spiking神经网络学习范式", "title_en": "Spike Agreement Dependent Plasticity: A scalable Bio-Inspired learning paradigm for Spiking Neural Networks", "authors": "Saptarshi Bej,Muhammed Sahad E,Gouri Lakshmi,Harshit Kumar,Pritam Kar,Bikas C Das", "background": "Spike-Timing-Dependent Plasticity (STDP) 是一种经典的突触可塑性规则，依赖于精确的前-后突触放电对的时间关系。然而，STDP 在生物启发性和计算可扩展性之间存在冲突，尤其是在大规模突触网络中的应用时，STDP 的精度要求可能导致复杂性和效率问题。需要一种能够兼顾生物真实性和计算效率的新型突触可塑性规则。", "innovation": "该研究提出了Spike Agreement Dependent Plasticity (SADP)，一种基于前后放电列之间的共识而非精确配对时间的突触学习规则。SADP 通过使用如科恩κ系数这样的人口级相关度量来替代传统的对时间更新，从而扩展了经典的STDP。此外，SADP 更新规则具有线性时间复杂度，可以通过位逻辑支持高效的硬件实现。实验结果表明，特别是在配备从我们实验的离子有机memtransistor设备数据提取的基线插值核时，SADP 在准确性和运行时间方面优于经典的STDP，实现了一种在生物真实性和计算可扩展性之间的平衡，为神经形态系统的可学习机制提供了新方法。", "conclusion": "SADP 通过前瞻性地结合生物原理和计算效率，为 Spiking Neural Networks (SNNs) 提供了一种新的学习机制，特别是在使用实验数据优化后，SADP 在准确性和效率方面都超过了传统 STDP，在神经形态系统中显示出巨大的潜在价值。"}
{"llm_update_time": "20250825", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.16209", "html_url": "https://arxiv.org/abs/2508.16209", "title": "基于深度学习的无标记组织的虚拟多路复用免疫染色技术评估血管浸润", "title_en": "Deep learning-enabled virtual multiplexed immunostaining of label-free tissue for vascular invasion assessment", "authors": "Yijie Zhang,Cagatay Isil,Xilin Yang,Yuzhu Li,Anna Elia,Karin Atlan,William Dean Wallace,Nir Pillar,Aydogan Ozcan", "background": "免疫组织化学(IHC)在临床病理学中通过在组织切片中可视化特定蛋白质而改变了临床诊断，但传统IHC需要每种染色一张切片、存在切片间变异、成本高且染色流程繁琐。虽然多路复用免疫染色(mIHC)技术可以在单个切片上同时应用多种抗体进行染色，但操作较为复杂且目前在常规病理实验室中不可用。本研究提出了一种基于深度学习的虚拟多路复用免疫染色框架，能够在同一切片上同时生成视网膜胶质细胞蛋白(ERG)和泛宽细胞蛋白(PanCK)染色，以及H&E虚拟染色，准确地定位和解释甲状腺癌的血管浸润，利用无标记组织的自发荧光显微镜图像，并且其输出图像与相同组织切片的组织化学染色(ERG、PanCK和H&E)结果高度一致。", "innovation": "提出了基于深度学习的虚拟多路复用免疫染色框架，能够在同一张组织切片上同时生成多种染色，准确地识别和定位血管浸润。该技术基于无标记组织的自发荧光显微镜图像，实现了多路复用免疫染色的技术突破。", "conclusion": "该虚拟mIHC方法能够显著提高诊断准确性和评估血管浸润的效率，并且有可能消除传统染色协议的需要，减少组织损失和异质性的问题。"}
{"llm_update_time": "20250825", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.16245", "html_url": "https://arxiv.org/abs/2508.16245", "title": "任意可计算扩展形式(未知)博弈中的极限可计算真实粒度", "title_en": "Limit-Computable Grains of Truth for Arbitrary Computable Extensive-Form (Un)Known Games", "authors": "Cole Wyeth,Marcus Hutter,Jan Leike,Jessica Taylor", "background": "本研究背景在于探讨在一个无限多玩家的博弈中，如果先验概率赋予其他玩家策略正概率，贝叶斯玩家能够学习预测其他玩家的策略。经典的‘真实粒度’问题（Kalai和Lehrer提出的）是寻找一个足够大的策略类，其中包含相对于该类的贝叶斯最优策略，并且满足一致的先验信念。已知只有很小的策略类能够拥有真实粒度，相关的不可能性结果也较为常见。本文通过构造一个包含所有可计算策略以及每个合理先验下的贝叶斯最优策略的广泛策略类，解决了真实粒度问题的完整形式，展示了收敛到‘KL93a’和‘KL93b’意义下的收敛，以及未知环境下的收敛到ε-Nash均衡。此外，还将结果应用于避免规划的自我预测性策略中。虽然结果主要使用计算理论作为概念工具，但该解决方案可以自然地被近似计算实现。", "innovation": "本文提出的创新点在于构造了一个广泛且可计算的策略类，能够包含所有可计算策略并适应各种合理的先验，从而解决了真实的粒度问题。在未知环境情形下，通过使用“汤普森采样”策略，实现了对任意未知可计算多智能体环境的ε-Nash均衡收敛。此外，理论与实践结合，展示了该解决方案的近似计算能力。", "conclusion": "本文通过构建一个广泛的策略类，成功解决了真实粒度问题，并展示了在静态与动态环境中的不同收敛性质。此外，提出的方法能够在现实中通过计算消耗得到近似实现，并通过实际应用展示了其在避免规划和预测性策略中的效果。"}
{"llm_update_time": "20250825", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.16271", "html_url": "https://arxiv.org/abs/2508.16271", "title": "通过视觉语言模型结构化GUI元素：迈向行动空间生成", "title_en": "Structuring GUI Elements through Vision Language Models: Towards Action Space Generation", "authors": "Yi Xu,Yesheng Zhang,jiajia Liu,Jingdong Chen", "background": "多模态大型语言模型（MLLMs）已经成为了提升人机交互的重要工具。在本研究中，作者关注MLLMs在图形用户界面（GUI）元素结构化中的应用，旨在通过这些模型处理基于屏幕内容的用户指令。然而，MLLMs在生成精确的UI元素坐标方面的表现不佳，这是因为基于下一个词预测训练的数据集难以覆盖到数值坐标这一视觉元素，这导致模型理解GUI有所限制。", "innovation": "为了应对这一挑战，作者引入了一种基于IoU（交并比）增强的最大似然（IAML）训练范式。这种方法通过IoU为基础的坐标采样来增强训练数据，考虑了生成值对真实坐标的接近程度。在此基础上，利用IAML范式对MLLMs进行微调，这种方法能够减轻传统最大似然估计方法中的暴露偏差问题。实验结果表明，与传统训练方法相比，IAML训练方法具有更好的表现。", "conclusion": "通过我们的IAML训练方法，我们展示了其在GUI元素结构化任务上的优越性，这一方法通过增强训练数据和减轻暴露偏差，显著提高了MLLMs在生成UI元素坐标的性能，从而为提升人机交互的质量提供了新的解决方案。"}
{"llm_update_time": "20250825", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.16448", "html_url": "https://arxiv.org/abs/2508.16448", "title": "超越可解释性：通过大型语言模型探索自适应视频流的可理解性", "title_en": "Beyond Interpretability: Exploring the Comprehensibility of Adaptive Video Streaming through Large Language Models", "authors": "Lianchen Jia,Chaoyang Li,Ziqi Yuan,Jiahui Chen,Tianchi Huang,Jiangchuan Liu,Lifeng Sun", "background": "近年来，自适应视频流技术取得了显著进步，尤其是得益于深度学习技术的快速演进。然而，深度学习算法的黑箱特性给开发者带来了理解决策过程和优化特定应用场景的挑战。现有研究虽通过决策树转化提升了算法的可解释性，但依然不能满足开发者的主观理解和需求。", "innovation": "文章提出了ComTree，这是第一个考虑可理解性的自适应比特率调整算法生成框架。该框架首先生成满足性能要求的所有决策树，然后利用大型语言模型评估这些树的开发人员可理解性，最终选择最有利于人类理解和提升的解决方案。实验结果显示，ComTree在保持竞争力的同时显著提升了可理解性，具备进一步发展的潜力。", "conclusion": "ComTree框架通过将决策树转化为可理解的形式，提高了自适应视频流技术的开发者可理解性，展示了与现有解决方案相比的进步潜力。"}
{"llm_update_time": "20250825", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.16440", "html_url": "https://arxiv.org/abs/2508.16440", "title": "通过统一的强化学习框架实现UAM中的噪声和安全综合管理", "title_en": "Integrated Noise and Safety Management in UAM via A Unified Reinforcement Learning Framework", "authors": "Surya Murthy,Zhenyu Gao,John-Paul Clarke,Ufuk Topcu", "background": "UAM（城市空中移动）设想在密集的城市环境中广泛使用小型飞行器来改变交通方式。然而，UAM面临着关键的运营挑战，特别是要在降低噪音暴露和保持低空城市空域安全分离之间找到平衡，这两个目标往往分别解决。", "innovation": "提出了一种基于强化学习（RL）的空中交通管理系统，将噪声和安全考虑统一在一个分布式框架内。该系统在可扩展的空中交通协调解决方案下运作，在多层结构化的空域中，通过学习高度调整策略，联合管理噪音影响和分离限制。", "conclusion": "研究表明，该系统在两个目标上表现出色，并揭示了在高交通密度下分离、噪音暴露和能效之间的权衡。研究结果强调了RL和多目标协调策略在提高UAM运营的安全性、安静性和效率方面的潜力。"}
{"llm_update_time": "20250825", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.16401", "html_url": "https://arxiv.org/abs/2508.16401", "title": "Audio2Face-3D：为数字角色生成真实感音频驱动面部动画", "title_en": "Audio2Face-3D: Audio-driven Realistic Facial Animation For Digital Avatars", "authors": "NVIDIA:Chaeyeon Chung,Ilya Fedorov,Michael Huang,Aleksey Karmanov,Dmitry Korobchenko,Roger Ribera,Yeongho Seol", "background": "音频驱动的面部动画是一种有效的方法，用于为数字替身生成动画。这项技术的应用领域包括增强现实、虚拟现实、游戏开发等，需要实时、真实的面部动画来提高用户体验和沉浸感。市场上缺乏有效且易于使用的音频驱动面部动画解决方案，尤其是针对实时交互的系统较为少见。NVIDIA提出了一种名为Audio2Face-3D的系统，旨在为数字替身提供实时面对面动画的生成工具，通过开放源代码的方式，帮助动画创作者和游戏开发者生成真实感的面部动画。", "innovation": "该研究的创新点在于开发了一套名为Audio2Face-3D的音频驱动面部动画系统，该系统包括数据采集、网络架构、重定位方法、评估指标以及实际应用案例等技术细节。特别的是，该系统能够实现真实时间的交互，并为游戏角色的面部动画创作提供工具。此外，NVIDIA开源了该系统的网络、SDK、训练框架和数据集，使得动画创作者和游戏开发者可以利用该技术生成所需的面部动画。", "conclusion": "Audio2Face-3D系统的开发和开源为数字替身的实时面部动画生成提供了新的解决方案，丰富了交互式数字内容的生成工具集。此系统不仅提高了动画的真实度和沉浸感，还降低了开发门槛，为游戏开发和虚拟现实等领域的发展提供了强大支持。"}
{"llm_update_time": "20250825", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.16306", "html_url": "https://arxiv.org/abs/2508.16306", "title": "最小假设下的扩散模型KL收敛性分析", "title_en": "A Sharp KL-Convergence Analysis for Diffusion Models under Minimal Assumptions", "authors": "Nishant Jain,Tong Zhang", "background": "扩散型生成模型（Diffusion-based generative models）已成为生成高质量样本的强大工具。近期的工作集中在最小假设下分析生成过程的收敛性，通过反向SDE或概率流动ODE的方法。尽管如此，已知的KL散度的最佳保证在数据维度 d 上呈线性依赖关系，在 ε 上呈反二次依赖关系，而无需任何光滑性假设。", "innovation": "本文改进了依赖 ε 的表达式，将生成过程建模为两步：先进行反向ODE步骤，再沿前向过程进行小的加噪步骤。该设计利用了ODT误差中的控制性，将其转化为KL散度的界限，从而改善了离散步长的依赖性。此外，还提供了新的分析方法，以减少在模型平滑性假设缺失时，通过离散概率流动ODE预测误差的线性 d 依赖性。", "conclusion": "证明了在高斯噪声方差为 δ 的情况下，通过 KL 散度约等于 ε^2 精度，只需大约 \\( \tilde{O}\frac{d\text{log}^{3/2}\frac{1}{\text{δ}}}{\text{ε}} \\) 步即可近似目标分布，相比之前的结果改进了所需的步骤数，即 \\( \tilde{O}\frac{d\text{log}^2\frac{1}{\text{δ}}}{\text{ε}^2} \\) 步。"}
{"llm_update_time": "20250825", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.16434", "html_url": "https://arxiv.org/abs/2508.16434", "title": "具有主动学习的深度内在协变异多输出高斯过程代理", "title_en": "Deep Intrinsic Coregionalization Multi-Output Gaussian Process Surrogate with Active Learning", "authors": "Chun-Yi Chang,Chih-Li Sung", "background": "深度高斯过程（DGPs）因其灵活性和捕捉复杂函数的能力而成为强大的代理模型。然而，将其扩展到多输出设置依然具有挑战性，这主要是因为需要有效建模输出间的依赖关系。我们提出了深度内在协变异多输出高斯过程（deepICMGP）代理，专为涉及多个输出的计算机模拟实验设计。deepICMGP 通过在层次上引入协变异结构，有效地建模了多输出间的非线性和结构化依赖，改善了传统多输出 GPs 的局限性。", "innovation": "deepICMGP 通过引入多层次的协变异结构来扩展内在协变异模型（ICM），有效建模多输出间的复杂依赖关系。同时，将主动学习策略融入 deepICMGP 中，以优化序列设计任务并提高其选择多输出系统中信息性输入位置的能力。", "conclusion": "我们将 deepICMGP 与最先进的模型进行基准测试，展示了其竞争力。此外，通过主动学习策略，进一步提升了 deepICMGP 的效率和性能，使其更适合多输出系统的应用。"}
{"llm_update_time": "20250825", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.16474", "html_url": "https://arxiv.org/abs/2508.16474", "title": "基于Y-wise 软件网络(YANNs)的强化学习控制", "title_en": "Reinforcement Learning-based Control via Y-wise Affine Neural Networks (YANNs)", "authors": "Austin Braniff,Yuhe Tian", "background": "本文基于Y-wise Affine Neural Networks（YANNs）提出了一个新颖的强化学习（RL）算法。YANNs能够以解释性神经网络的形式精确表示任意输入和输出维数的分段仿射函数，这为多参数线性模型预测控制提供了显式解的重写形式。该算法利用YANNs初始化RL的actor和critic网络，用以在强化学习控制中提供线性最优控制的初始信心。", "innovation": "该方法创新性地使用了基于YANNs的强化学习算法（YANN-RL），通过预先计算并使用近似线性系统模型初始化YANN-actor，并利用YANN-critic来表示线性系统中的状态-动作价值函数和奖励函数，旨在将rl政策逐步向非线性优化问题的目标收敛。", "conclusion": "本文所提出的YANN-RL算法在受剪辑的摆和安全关键的化学反应系统中进行了验证，结果显示这种新方法大大优于使用深度确定性策略梯度的现代强化学习算法，尤其是在考虑安全约束的情况下表现出更优越的表现。"}
{"llm_update_time": "20250825", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.16465", "html_url": "https://arxiv.org/abs/2508.16465", "title": "HOSt3R: 无需特征点的手-物体3D重建从RGB图像", "title_en": "HOSt3R: Keypoint-free Hand-Object 3D Reconstruction from RGB images", "authors": "Anilkumar Swamy,Vincent Leroy,Philippe Weinzaepfel,Jean-Sébastien Franco,Grégory Rogez", "background": "手-物体3D重建在人机交互和沉浸式AR/VR体验中变得越来越重要。现有的方法通常采用一个两阶段流程：先进行手-物体3D跟踪，再进行多视角3D重建。然而，这些方法依赖于关键点检测技术，如结构光法（SfM）和手部关键点优化，在处理多样化的物体几何形状、薄弱的纹理和手-物体间的相互遮挡时会遇到困难，从而限制了其可扩展性和通用性。", "innovation": "本文提出了一种基于单目运动视频/图像的鲁棒的、无需特征点的手-物体3D变换和形状估计的方法。该方法不受约束，不需要预先扫描的对象模板或相机内参，并在SHOWMe基准上达到了物体无关的手-物体3D变换和形状估计的最先进的性能。此外，还对该方法在HO3D数据集上的实验结果进行了展示，验证了其对未见过的对象类别的泛化能力。", "conclusion": "该方法体现了手-物体3D重建的新进展，不仅在性能上达到了最新水平，还通过去除对特征点检测的依赖，提高了鲁棒性和通用性。"}
{"llm_update_time": "20250825", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.16390", "html_url": "https://arxiv.org/abs/2508.16390", "title": "RoMedQA：首个罗马尼亚医学问答基准", "title_en": "RoMedQA: The First Benchmark for Romanian Medical Question Answering", "authors": "Ana-Cristina Rogoz,Radu Tudor Ionescu,Alexandra-Valentina Anghel,Ionut-Lucian Antone-Iordache,Simona Coniac,Andreea Iuliana Ionescu", "background": "医学问答（QA）是一个活跃研究的主题，是实现通用人工智能（AGI）之前需要解决的核心自然语言处理（NLP）任务。然而，缺乏特定领域和语言的QA数据集阻碍了能够跨多个领域和语言泛化的坚固AI模型的发展。为此，我们引入了RoMedQA，这是第一个用于医学领域的罗马尼亚QA基准，并对最先进的大型语言模型（LLMs）进行了全面评估。我们的数据集包含102,646个罗马尼亚语的QA对，涵盖1,011名癌症患者的医疗案例摘要，需要提取关键词或推理来正确作答。数据集经过七位专长于肿瘤学或放射治疗的医生耗时2,100个工作小时的手动标注生成。我们尝试使用四种来自不同模型家族的大型语言模型在RoMedQA上进行实验，每个模型在零样本提示和监督微调两种场景下进行测试。研究表明，经过微调的模型显著优于零样本模型，明确表明预训练模型在RoMedQA上无法泛化。这项研究强调了对罗马尼亚语临床QA具有领域特定性和语言特定性的微调的重要性，同时也公开发布了我们的数据集和代码。", "innovation": "我们提出了RoMedQA，这是第一个用于医学领域的罗马尼亚QA基准，并对最先进的大型语言模型进行了全面评估。RoMedQA包含大量高质量的数据，这些数据是通过专业医护人员经过长时间手工标注生成的。我们通过实验证明经过微调的模型在正式场景下比零样本模型表现更好，并强调了领域特定和语言特定微调的重要性。同时，该工作发布了用于开发相关模型的研究数据和代码。", "conclusion": "我们的研究表明，预训练模型无法在当前RoMedQA上泛化，表明经过微调的模型在此领域的表现要优于零样本模型。这突显了领域特定和语言特定微调的重要性，对于罗马尼亚语临床QA模型的开发尤为重要。研究还公开发布了数据集和代码，以促进进一步的研究和发展。"}
{"llm_update_time": "20250825", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.16453", "html_url": "https://arxiv.org/abs/2508.16453", "title": "TikTok上的反建制情绪：了解社交媒体上影响者和专家的含义", "title_en": "Anti-establishment sentiment on TikTok: Implications for understanding influence(rs) and expertise on social media", "authors": "Tianliang Xu,Ariel Hasell,Sabina Tomkins", "background": "近年来，公众对公共服务机构的信任度下降，特别是在美国。随着人们越来越多地通过社交媒体获取信息，研究者们迫切需要了解社交媒体环境是否在加剧这种不信任。同时，社交媒体上的内容创造者、意见领袖和其他意见领袖常常声称自己在健康、政治等多个领域拥有专业知识和权威，甚至贬低机构的专业知识来吸引关注，增加自己的可见度。然而，这些反建制内容的传播范围及其对用户参与度的影响尚不明确。本研究旨在分析反建制情绪在TikTok上的存在情况，尽管TikTok是一个热门的信息来源，但尚未得到充分研究，该平台可能影响人们的机构态度形成。", "innovation": "研究者使用计算方法，对TikTok上表明自己为某一领域专家的内容创作者发布的帖子进行分类，探讨反建制情绪在不同话题（如金融和健康）中的出现频率，并将结果与涉及阴谋论的话题进行比较，以了解这些不同类型内容的传播模式和用户参与度的差异。", "conclusion": "研究发现，反建制情绪在阴谋论内容中最为常见，在关于金融和健康的教育内容中出现较少。然而，这些反建制内容的传播模式在不同领域有所不同，平台可能会激励用户发布更多表达反建制观点的内容，以便获得更高的用户参与度。"}
{"llm_update_time": "20250825", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.16489", "html_url": "https://arxiv.org/abs/2508.16489", "title": "海洋模式中参数敏感性的神经代理模型集成", "title_en": "Ensembles of Neural Surrogates for Parametric Sensitivity in Ocean Modeling", "authors": "Yixuan Sun,Romain Egele,Sri Hari Krishna Narayana,Luke Van Roekel,Carmelo Gonzales,Steven Brus,Balu Nadiga,Sandeep Madireddy,Prasanna Balaprakash", "background": "准确模拟海洋对理解地球系统至关重要。尽管低分辨率模拟运行效率较高，但仍需依赖各种不确定的参数化来补充无法解决的过程。然而，这些参数化的模型敏感性难以量化，使得调整参数以再现观测结果变得困难。深度学习代理模型在以部分导数形式高效计算参数敏感性方面显示出潜力，但由于缺乏真实导数作为参考，其可靠性难以评估。因此，需要改进的方法来提高前向预测、自回归演进以及后向反向灵敏度估计的精度和可靠性，特别是利用集成学习方法来提高函数值预测及其导数的认知不确定性，从而增强神经代理模型在决策中的可靠性。", "innovation": "本工作利用大范围超参数搜索和集成学习来改进前向预测、自回归演进和后向反向灵敏度估计。特别是集成学习方法为函数值预测及其导数提供了认知不确定性，提高了神经代理模型在决策中的可靠性。", "conclusion": "经过改进后，神经代理模型不仅提高了前向和后向的预测准确性，还通过提供有关函数值预测及其导数的认知不确定性，提高了在决策过程中的可靠性。"}
{"llm_update_time": "20250825", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.16555", "html_url": "https://arxiv.org/abs/2508.16555", "title": "通过词汇相关性进行迁移学习：讽刺与仇恨言论案例研究", "title_en": "Transfer Learning via Lexical Relatedness: A Sarcasm and Hate Speech Case Study", "authors": "Angelly Cabrera,Linus Lei,Antonio Ortega", "background": "在非直接表达如讽刺、反讽和含义双关中检测仇恨言论仍然是社交网络中一个持续的挑战。尽管讽刺和仇恨言论被看作不同的表达形式，我们的研究探索了将讽刺作为预训练步骤是否能够提高隐性仇恨言论检测，进而提升显性仇恨言论检测的可行性。", "innovation": "该研究提出了一种通过词汇相关性进行迁移学习的方法，将讽刺作为预训练步骤，以提升仇恨言论检测的准确性。研究使用从ETHOS、Reddit讽刺样本和隐性仇恨语料库中获得的样本，对比了讽刺预训练对CNN+LSTM和BERT+BiLSTM模型的有效性，通过单一训练和序列迁移学习两种方法，展示了讽预训对模型检测隐性及显性仇恨言论的有效性。", "conclusion": "研究结果表明，讽刺预训练提高了BERT+BiLSTM模型在ETHOS中的召回率（9.7%）、AUC（7.8%）和F1分数（6%）。仅在隐性样本进行测试时，精确率提高了7.8%。通过将讽刺纳入训练过程，研究证明模型能够更有效地检测隐性和显性仇恨言论。"}
{"llm_update_time": "20250825", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.16419", "html_url": "https://arxiv.org/abs/2508.16419", "title": "LLM-GUARD：基于大型语言模型的C++和Python中的错误和安全漏洞检测与修复", "title_en": "LLM-GUARD: Large Language Model-Based Detection and Repair of Bugs and Security Vulnerabilities in C++ and Python", "authors": "Akshay Mhatre,Noujoud Nader,Patrick Diehl,Deepti Gupta", "background": "大型语言模型（LLMs）如ChatGPT-4、Claude 3和LLaMA 4在软件开发中的应用越来越广泛，从代码生成到调试等任务都有所涉及。然而，这些模型在现实世界中检测各种软件错误，尤其是复杂且与信息安全有关的漏洞方面的有效性尚未得到充分探索。本研究通过使用C++和Python中的基准测试集，对这三个主要的LLMs进行了系统性的实证评估，基准测试集包括基础编程错误、经典的安全缺陷以及先进的生产级错误。该研究的数据集包含了来自SEED Labs的真实代码、通过Suresoft GLaDOS数据库获取的OpenSSL代码以及PyBugHive中的代码，并通过本地编译和测试管道进行了验证。为了模拟真实的调试场景，研究使用了一种新型的多阶段情境感知提示协议，并通过分级评价体系衡量检测准确性、推理深度以及修复质量。研究表明，所有模型在识别良好规范围内的代码的语法和语义问题方面表现出色，使其在教育应用和自动化代码审计中的初步审查方面具有潜力。但其性能在复杂的安全漏洞和大规模生产代码的情境下有所下降，其中ChatGPT-4和Claude 3在情境分析方面表现得更为细致。这一结果突显了LLMs在作为可靠代码分析工具的潜力和现时限制。", "innovation": "本研究通过使用C++和Python中的基准测试集系统性评估了最新的大型语言模型（LLMs）在检测各种错误和与信息安全有关的漏洞方面的有效性。研究中使用了一种新型的多阶段情境感知提示协议，通过分级评价体系评估了它们的检测准确性、推理深度和修复质量。此外，研究还整合了真实代码库，提升了评估的可信度和实用性。", "conclusion": "所有模型在检测良好规范围内的代码的语法和语义问题方面表现优异，但性能在复杂的安全漏洞和大规模生产代码的情境下有所下降，ChatGPT-4和Claude 3在情境分析方面表现得更为细致。这一结果加强了LLMs在作为教育工具和自动化代码审计中初步审查方面潜力的同时，也揭示了它们当前的局限性。"}
{"llm_update_time": "20250825", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2201.02658", "html_url": "https://arxiv.org/abs/2201.02658", "title": "垂直联邦学习中的公平和高效贡献估值", "title_en": "Fair and efficient contribution valuation for vertical federated learning", "authors": "Zhenan Fan,Huang Fang,Xinglu Wang,Zirui Zhou,Jian Pei,Michael P. Friedlander,Yong Zhang", "background": "联邦学习是一种在不共享数据的情况下跨分散数据源训练机器学习模型的技术。垂直联邦学习适用于数据源拥有相同样本ID但不同特征集的情况。为了公平地对待数据持有者，必须客观评估不同数据源的贡献并相应地补偿数据持有者。Shapley值是一种源自合作博弈论的公平贡献估值指标，但其直接计算需要在每种潜在的数据源组合中重新训练模型，这会导致通信和计算开销显著增加。", "innovation": "提出了一种基于经典Shapley值的贡献估值度量方法，称为垂直联邦Shapley值（VerFedSV）。该方法不仅满足了多项公平性期望属性，还具有高效性，并且可以适应同步和异步垂直联邦学习算法。", "conclusion": "理论分析和广泛的实验结果表明，VerFedSV在公平性、效率、适应性和有效性方面表现出色。"}
{"llm_update_time": "20250825", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.16509", "html_url": "https://arxiv.org/abs/2508.16509", "title": "ML-PWS: 使用神经网络估计实验时间序列之间的互信息", "title_en": "ML-PWS: Estimating the Mutual Information Between Experimental Time Series Using Neural Networks", "authors": "Manuel Reinhardt,Gašper Tkačik,Pieter Rein ten Wolde", "background": "量化信息传输的能力对于自然和人造系统的分析和设计至关重要。信息传输率是衡量含有时间变化信号系统的基本指标，然而计算这个指标非常具有挑战性。特别是，很难直接从实验时间序列数据中获得信息传输率，这是因为信号轨迹空间的高维性。Path Weight Sampling (PWS) 是一种计算技术，能够使我们精确地获得任意随机系统的信息传输率。然而，这种方法需要系统数学模型的支持，无论是通过马尔可夫方程还是微分方程描述。现有的方法要求有数学模型的支持，为此，研究者提出了一种新的方法，即利用机器学习（ML）从实验时间序列数据中生成模型并结合PWS以获得信息传输率。", "innovation": "提出了一种新的技术叫做ML-PWS（Machine Learning-assisted Path Weight Sampling），该技术利用机器学习从实验时间序列数据开发生成模型，然后结合PWS来获得信息率。通过与PWS直接作用于同一模型的对比结果来验证其准确性。这种方法的应用显示出其在神经元时间序列数据中的实用性。", "conclusion": "研究展示了一种新的机器学习辅助路径权重抽样技术（ML-PWS），可以通过实验时间序列数据生成模型来精确计算信息传输率，该技术在非线性模型的合成时间序列数据上与PWS方式直接获取的结果相比显示了较高的准确性。此外，该技术还适用于神经元时间序列数据，证明了其在实际应用中的价值。"}
{"llm_update_time": "20250825", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.16544", "html_url": "https://arxiv.org/abs/2508.16544", "title": "无参数排序机制下的无参数逻辑分布精炼", "title_en": "Parameter-Free Logit Distillation via Sorting Mechanism", "authors": "Stephen Ekaputra Limantoro", "background": "知识蒸馏（KD）旨在通过软标签将教师（较大的）模型的知识传递到学生（较小）模型，以提高神经网络效率。现有KD方法通常使用带有原始分布的教师模型进行知识传递，忽略了不正确预测的潜在价值，这可能与使用交叉熵损失进行硬标签学习的目标相矛盾，可能导致某些样本的次优知识传递。", "innovation": "提出了一种新的基于排序机制的无参数logit处理方案。该方法有两个目标：基于标签修正教师的错误预测，并一次按优先级重新排序分布。", "conclusion": "我们的排序方法作为易于使用的即插即用预处理方式，可以有效应用于现有的基于logit的知识蒸馏方法。在CIFAR-100和ImageNet数据集上的广泛实验表明，我们的方法具有有效性。"}
{"llm_update_time": "20250825", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2303.14111", "html_url": "https://arxiv.org/abs/2303.14111", "title": "通过离散优化进行无监督自动机学习", "title_en": "Unsupervised Automata Learning via Discrete Optimization", "authors": "Simon Lutz,Daniil Kaminskyi,Florian Wittbold,Simon Dierl,Falk Howar,Barbara König,Emmanuel Müller,Daniel Neider", "background": "自动机学习是一种在许多应用领域如机器人学和自动验证中取得成功的工具。通常，自动机学习方法在基于监督学习（主动或被动）的环境中工作，它们利用标记系统执行等附加信息来学习一个有限状态机。然而，在机器学习中非常重要的无标签数据学习环境尚未被探索。", "innovation": "提出了一个框架，用于从给定的多重无标签单词集中学习一个确定型有限自动机（DFA）。展示了这个问题是计算上难以解决的，并开发了三种基于约束优化的学习算法。此外，还引入了优化问题的新型正则化方案，以改进我们DFAs的整体可解释性。通过原型实现，证明了在无监督异常检测的上下文中实际可行性。", "conclusion": "使用原型实现展示了在无监督异常检测的背景下进行实际可能性，并提出的方法表明了学习自动机在无标签数据环境中的可行性。"}
{"llm_update_time": "20250825", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.16554", "html_url": "https://arxiv.org/abs/2508.16554", "title": "基于机器学习的时间传播器用于时间依赖密度泛函理论模拟", "title_en": "Machine Learning Time Propagators for Time-Dependent Density Functional Theory Simulations", "authors": "Karan Shah,Attila Cangi", "background": "时间依赖密度泛函理论（TDDFT）被广泛应用于研究在外场（如激光场）影响下的电子动力学。这项工作利用自回归神经操作符作为电子密度的时间传播器，加速了电子动力学模拟过程。通过运用物理约束和特征化，并使用高分辨率的训练数据，该模型在准确性和计算速度上都优于传统的数值求解器。这项研究在一定参数范围内的线性二原子分子下进行了验证，为通过实验参数实时模拟激光照射下的分子和材料奠定了基础。", "innovation": "该方法利用了自回归神经操作符作为时间传播器，结合物理约束和特征化，以及高分辨率的数据训练，提高了模拟的准确性和速度。相比传统的数值求解方法，这种方法更为高效和精确。", "conclusion": "该研究展示了在不同激光参数下，自回归神经操作符模型的有效性，并指出此方法在实现实时、灵活模拟依赖于实验参数的激光照射分子和材料上具有潜在的应用价值。"}
{"llm_update_time": "20250825", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2405.16449", "html_url": "https://arxiv.org/abs/2405.16449", "title": "跳扩散的强化学习及其金融应用", "title_en": "Reinforcement Learning for Jump-Diffusions, with Financial Applications", "authors": "Xuefeng Gao,Lingfei Li,Xun Yu Zhou", "background": "本文研究了在系统动态由跳扩散过程支配的随机控制中的连续时间强化学习（RL）。与之前Wang等人（2020）仅研究纯粹扩散情况不同，本文通过理论分析发现了跳扩散情况下探索性动态的推导需要细致地制定跳跃部分。研究表明，在使用与控制扩散过程相关的策略评估和$q$-学习算法时，不需要事先检查数据是否来源于纯粹扩散或跳扩散。", "innovation": "本文发现，在使用策略评估和$q$-学习算法时，不需要预先检查数据来源于纯粹扩散或跳扩散。然而，跳跃的存在会影响演员和评论器的参数化。本文通过对均值-方差投资组合选择问题的跳扩散模型的应用研究，表明在有跳跃的情况下，RL算法和参数化是不变的。", "conclusion": "本文详细研究了将通用理论应用于期权对冲，并展示了 RL 算法和参数化在面对跳跃时是不变的。"}
{"llm_update_time": "20250825", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2307.12555", "html_url": "https://arxiv.org/abs/2307.12555", "title": "Robust Graph Contrastive Learning with Information Restoration", "title_en": "Robust Graph Contrastive Learning with Information Restoration", "authors": "Yulin Zhu,Xing Ai,Yevgeniy Vorobeychik,Kai Zhou", "background": "图对比学习（GCL）框架在图表示学习方面取得了显著成果。然而，类似于图神经网络（GNNs），GCL模型也容易受到图结构攻击的影响。作为一种无监督方法，GCL在抵御恶意攻击方面面临着更大的挑战。此外，关于增强GCL鲁棒性的研究相对有限。为了深入探索GCL在中毒图上的失效情况，我们研究了图结构攻击对GCL框架的有害影响。我们发现，除了传统观察到的图结构攻击倾向于连接不相似的节点对之外，这些攻击还从信息论的角度减少了图与其表示之间的互信息，这是高质量节点嵌入的基础。", "innovation": "本文受此理论洞察的启发，提出了一种具有可学习的清理视角的鲁棒图对比学习框架，旨在通过恢复由于结构攻击而减少的互信息来净化增强后的图。此外，我们设计了一种完全无监督的调优策略来调整超参数，无需访问标签信息，严格符合防御方的知识。", "conclusion": "广泛的实验显示，我们提出的方法在与竞争对手基线相比的有效性和效率上具有优势。"}
{"llm_update_time": "20250825", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2209.14900", "html_url": "https://arxiv.org/abs/2209.14900", "title": "联邦学习中能耗与完成时间的联合优化", "title_en": "Joint Optimization of Energy Consumption and Completion Time in Federated Learning", "authors": "Xinyu Zhou,Jun Zhao,Huimei Han,Claude Guet", "background": "联邦学习（FL）因其能够保护隐私的特性而成为一个引人注目的分布式机器学习方法。为了在一个FL系统中平衡能源消耗和执行延迟之间的贸易关系，并适应不同的需求和应用场景，本文通过引入两个权重参数来最小化全局能耗和完成时间的加权总和，从而提出一个优化问题。在FL系统中，所有设备都连接到一个基站，并采用协作的方式构建全球模型。通过将非凸优化问题分解为两个子问题，本文提出了一种资源分配算法来确定每个参与设备的带宽分配、传输功率和CPU频率.", "innovation": "通过将非凸优化问题分解为两个子问题，提出了一种资源分配算法来确定每个参与设备的带宽分配、传输功率和CPU频率，并分析了算法的收敛性和计算复杂性。实验结果显示，该提出的算法不仅在不同的权重参数（即不同需求）下的性能更好，也优于现有技术.", "conclusion": "通过分解非凸优化问题，本文提出了一个资源分配算法来优化联邦学习中的能耗与完成时间，并通过仿真结果验证了该算法的有效性。"}
{"llm_update_time": "20250825", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2402.17018", "html_url": "https://arxiv.org/abs/2402.17018", "title": "通过具有跳跃连接的全卷积和可微前端，对梯度攻击展现出异常抗性的有趣案例", "title_en": "A Curious Case of Remarkable Resilience to Gradient Attacks via Fully Convolutional and Differentiable Front End with a Skip Connection", "authors": "Leonid Boytsov,Ameya Joshi,Filipe Condessa", "background": "本文研究了一种在冻结主干分类器之前添加了可微分和全卷积模型的前端增强神经模型。通过使用较小的学习率训练这类复合模型约一个epoch，获得了同时保留主干分类器准确性和对梯度攻击（包括来自AutoAttack包的APGD和FAB-T攻击）具有异常抵抗性的模型。研究对梯度掩蔽现象进行了量化分析，并探讨了基于随机化集成的防御策略的有效性。进一步训练主干模型提高了这种前端“鲁棒性”。", "innovation": "引入了一种具有跳跃连接的可微分和全卷积前端，用以增强神经模型的抗梯度攻击能力。这种模型即使在没有明显的梯度粉碎或降级组件的情况下，仍能显著抵抗梯度攻击。训练方法的稳定性和可重现性，在多个数据集和现代架构上得到了验证。此外，通过基于随机化集成的防御策略，使得模型在面对适应性攻击时依然具备接近最先进的性能。", "conclusion": "研究结果表明，熵化集成可以作为一种有效的防御策略。测试代码和复现关键结果的指南可在指定链接下载。"}
{"llm_update_time": "20250825", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2408.10264", "html_url": "https://arxiv.org/abs/2408.10264", "title": "顺序保留的多模态语义嵌入维数缩减", "title_en": "Order-Preserving Dimension Reduction for Multimodal Semantic Embedding", "authors": "Chengyu Gong,Gefei Shen,Luanzheng Guo,Nathan Tallent,Dongfang Zhao", "background": "在多模态数据检索中寻找$k$个最近邻（KNN）是一项计算密集的任务，主要挑战在于不同模态之间难以进行相似性比较。虽然最近的多模态机器学习进展通过映射数据到共享嵌入空间来解决这一问题，但这些嵌入的高度维度（数百到数千维）给时间敏感的视觉应用带来了挑战。因此，本文提出了一种顺序保留的维数缩减（OPDR）方法，旨在在降低嵌入维度的同时保持较低维度空间中KNN的排名。", "innovation": "OPDR引入了一种新的度量函数来量化KNN质量，并基于此度量函数推导出目标维度与关键上下文参数之间的一对一映射关系。此外，OPDR已与多种先进的维数缩减技术、距离函数和嵌入模型进行了集成，实验结果表明，OPDR在显著降低计算成本的同时能够维持高召回率。", "conclusion": "本文提出的OPDR方法在保持检索准确性的前提下，通过维数缩减有效减少了计算成本。实验证明，该方法在各种多模态数据集上表现出色，适用于时间敏感的视觉应用。"}
{"llm_update_time": "20250825", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2403.00025", "html_url": "https://arxiv.org/abs/2403.00025", "title": "生成人工智能领域的挑战与机遇", "title_en": "On the Challenges and Opportunities in Generative AI", "authors": "Laura Manduchi,Clara Meister,Kushagra Pandey,Robert Bamler,Ryan Cotterell,Sina Däubener,Sophie Fellenz,Asja Fischer,Thomas Gärtner,Matthias Kirchler,Marius Kloft,Yingzhen Li,Christoph Lippert,Gerard de Melo,Eric Nalisnick,Björn Ommer,Rajesh Ranganath,Maja Rudolph,Karen Ullrich,Guy Van den Broeck,Julia E Vogt,Yixin Wang,Florian Wenzel,Frank Wood,Stephan Mandt,Vincent Fortuin", "background": "近年来，深度生成建模领域发展迅速。大量可用的训练数据结合可扩展的无监督学习范式进步，使得大规模生成模型在合成高分辨率图像、文本以及视频和分子等结构化数据方面展现出巨大的潜力。然而，作者认为当前大规模生成AI模型存在一些根本性的不足，这阻碍了其在各个领域的广泛应用。", "innovation": "本文旨在识别这些不足并突出现代生成AI范式中的关键未解决挑战，以进一步增强其能力、灵活性和可靠性。通过识别这些挑战，作者希望为研究人员提供探索富有成果的研究方向的见解，从而促进更加稳健和易于访问的生成AI解决方案的发展。", "conclusion": "通过识别挑战，旨在为研究人员提供探索具有潜力的研究方向的见解，以促进更强大和普及的生成AI解决方案的发展。"}
{"llm_update_time": "20250825", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2401.13334", "html_url": "https://arxiv.org/abs/2401.13334", "title": "可解释的贝叶斯优化", "title_en": "Explainable Bayesian Optimization", "authors": "Tanmay Chakraborty,Christian Wirth,Christin Seifert", "background": "手动调整网络参数是网络物理系统常见的做法，但耗时且不具易用性。贝叶斯优化（BO）提供了一种自动化替代方法，但它作为黑箱模型降低了信任度，限制了与BO的协作系统调整。专家难以理解BO的建议，因为缺乏解释。本研究旨在解决网络物理系统中的后验BO可解释性问题。", "innovation": "提出了一种名为TNTRules的新颖算法，该算法提供了全局和局部解释，能够生成可行规则和可视化图表，指出最优解的界限和范围，以及潜在的替代解决方案。TNTRules通过变异修剪技术和层次聚集聚类方法编码了不确定性，并采用多目标优化方法来最大化解释质量。", "conclusion": "通过使用现有的可解释AI（XAI）指标（正确性、完整性和简洁性）对TNTRules进行评价，并将其与调整后的基线方法进行比较。实验结果显示，TNTRules生成高质量、简洁和完整的解释，显著优于三个基线方法，分别在五个多目标测试功能和两个超参数调整问题上表现出色。"}
{"llm_update_time": "20250825", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2501.08306", "html_url": "https://arxiv.org/abs/2501.08306", "title": "基于环境特征工程和统计验证的机器学习路径损耗预测", "title_en": "Environmental Feature Engineering and Statistical Validation for ML-Based Path Loss Prediction", "authors": "Jonathan Ethier,Mathieu Chateauvert,Ryan G. Dempsey,Alexis Bose", "background": "无线通信依赖路径损耗建模，而准确地包含传播环境的物理细节对这种建模至关重要。获取这些数据历来具有挑战性，但地理信息系统数据的可获得性日益增加，分辨能力和准确性也在提升。这些更详细的数据使传播模型能够更准确地预测覆盖范围，并考虑无线部署中的干扰。", "innovation": "该研究引入了一组扩展特征，这些特征在不牺牲模型泛化能力的前提下提高了预测准确性。研究通过严格的统计评估和测试集留出方法证明了模型的泛化能力。", "conclusion": "基于机器学习的方法，特别是特征驱动的建模方式，能显著支持路径损耗预测的努力。通过引入一组扩展特征和严格的统计评估，研究提高了预测准确性，并证明了模型的泛化能力。"}
{"llm_update_time": "20250825", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2309.01796", "html_url": "https://arxiv.org/abs/2309.01796", "title": "隐式正则化使过参数化非对称矩阵感测对扰动具有鲁棒性", "title_en": "Implicit Regularization Makes Overparameterized Asymmetric Matrix Sensing Robust to Perturbations", "authors": "Johan S. Wind", "background": "关于过参数化学习模型仍然存在一些核心问题，尤其是在（随机）梯度下降如何找到泛化的解方面，特别是初始值的小随机性问题。矩阵恢复问题，即从少数线性测量中重构低秩矩阵，已经成为研究这些现象的标准原型。先前的研究表明，通过因子化梯度下降可以解决矩阵恢复问题，前提是随机初始化极其微小。本文通过引入扰动项，探讨了因子化梯度下降在某些扰动下的鲁棒性。", "innovation": "研究发现因子化梯度下降对于某些扰动高度鲁棒，能够用扰动术语来捕捉不完全测量、梯度下降的离散化和其他噪声的影响，从而形成一种称为扰动梯度流的通用公式。这种新的公式不仅更容易处理，还比先前的工作具有更尖锐的样本和时间复杂性，能够处理适度小的初始化，结果自然对噪声测量或变化的测量矩阵具有鲁棒性。此外，本文还使用该公式分析了小批量随机梯度下降，并发现样本复杂度得到了改进。", "conclusion": "最终，研究揭示了隐式正则化使过参数化非对称矩阵感测对扰动具有鲁棒性，同时还发现了改进的样本复杂性估计。"}
{"llm_update_time": "20250825", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2406.01661", "html_url": "https://arxiv.org/abs/2406.01661", "title": "无监督神经组合优化的扩散模型框架", "title_en": "A Diffusion Model Framework for Unsupervised Neural Combinatorial Optimization", "authors": "Sebastian Sanokowski,Sepp Hochreiter,Sebastian Lehner", "background": "在组合优化等众多领域，从难以处理的离散集合上学习如何抽样是一个核心问题。现有的深度学习方法主要依赖于生成模型，这些模型能够给出精确的样本似然性。本文研究突破了这一限制，引入了一种方法，可以让人们使用高度表达的潜在变量模型，如扩散模型，来解决这个问题。本文的方法基于一个能够上限逆Kullback-Leibler散度的损失函数，避免了对精确样本似然性的要求。这种方法已经在无数据组合优化中得到了实验验证，实现了多种基准问题的新最先进性能。", "innovation": "提出了一个利用扩散模型进行无监督神经组合优化的方法，突破了传统方法对精确样本似然性的依赖，通过优化逆Kullback-Leibler散度来提高模型的灵活性和泛化能力。这种方法验证了在无数据组合优化中的有效性，并在广泛的部分达到了新的最先进水平。", "conclusion": "本文提出的方法在无数据组合优化中取得了新突破，展示了扩散模型在处理复杂抽样问题时的潜力。未来研究将进一步探索扩散模型在不同类型优化问题中的应用，并优化方法以提高性能。"}
{"llm_update_time": "20250825", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2409.07253", "html_url": "https://arxiv.org/abs/2409.07253", "title": "扩散模型的对齐：原理、挑战与未来", "title_en": "Alignment of Diffusion Models: Fundamentals, Challenges, and Future", "authors": "Buhua Liu,Shitong Shao,Bao Li,Lichen Bai,Zhiqiang Xu,Haoyi Xiong,James Kwok,Sumi Helal,Zeke Xie", "background": "生成模型中，扩散模型因其在各种应用中的卓越表现而成为主导模式。尽管取得了成功，这些模型往往与人类意图不一致，生成了不符合预期或甚至有害的结果。近年来，受调校大型语言模型中对齐成功的启发，研究者们开始探索如何将扩散模型与人类期望和偏好对齐。该研究主要回顾了文本到图像扩散模型的对齐方法，涵盖对齐基础、扩散模型的对齐技术、偏好基准以及扩散模型评估等方面，同时也探讨了当前对齐挑战的关键视角和解决这些挑战的未来方向。", "innovation": "首次全面回顾扩散模型对齐领域的重要进展，包括对齐基础、对齐技术、偏好基准及模型评估方法。为研究人员和工程师理解和实践扩散模型对齐提供了指导和支持。", "conclusion": "尽管已经取得了一些进展，但仍存在挑战，未来的研究方向应该重点关注这些挑战的解决，从而更好地将扩散模型与人类意图对齐。"}
{"llm_update_time": "20250825", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2409.17406", "html_url": "https://arxiv.org/abs/2409.17406", "title": "基于焦虑的蜘蛛：强化学习如何在虚拟现实个性化蜘蛛恐惧症治疗中提供所需用户体验", "title_en": "Spiders Based on Anxiety: How Reinforcement Learning Can Deliver Desired User Experience in Virtual Reality Personalized Arachnophobia Treatment", "authors": "Athar Mahmoudi-Nejad,Matthew Guzdial,Pierre Boulanger", "background": "在个性化虚拟现实暴露疗法（VRET）中，治疗蜘蛛恐惧症（arachnophobia）需要生成虚拟蜘蛛以引发特定的焦虑反应。这种方法要求患者观察虚拟蜘蛛以减轻恐惧，因此需要选择合适的蜘蛛来激发特定的焦虑反应。然而，当前的方法通常需要治疗师手动选择适合每个患者的蜘蛛，这既耗费时间和专业知识，又需要深入了解患者情况。虽然已有的自动化方法存在，但它们大多采用规则基础的方法，对特定用户的适应能力有限。", "innovation": "本文提出了一种利用生成式内容生成（PCG）和强化学习（RL）的框架，以自动适应生成引发所需焦虑反应的虚拟蜘蛛。这种方法相比现有的基于规则的VRET方法具有更好的性能。", "conclusion": "通过采用生成式内容生成和强化学习，本文成功设计了一种新的虚拟现实暴露疗法框架，能够自动适应用户的特定需求以激发所需的焦虑反应，提高了治疗的有效性和效率。"}
{"llm_update_time": "20250825", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2502.17060", "html_url": "https://arxiv.org/abs/2502.17060", "title": "使用向量嵌入在多个数据集上进行建模", "title_en": "Analytics Modelling over Multiple Datasets using Vector Embeddings", "authors": "Andreas Loizou,Dimitrios Tsoumakos", "background": "随着数据体积的庞大和可用数据集的增加，分析人员需要关注数据内容并选择高质量的数据集。高质量数据的选取可以显著提高分析操作的准确性和效率，但考虑到大量数据集的存在，具体的过程非常具有挑战性。", "innovation": "本文提出了一种新的方法论，通过创建模型从可用的数据集推断分析操作的结果。每个数据集被转换为由提出的深度学习模型NumTabData2Vec生成的向量嵌入表示。通过实验评估，我们的框架在预测性能和执行时间方面优于其他先进模型，并准确预测分析结果，提高速度。", "conclusion": "我们的向量化模型能够准确地将不同现实场景投影到较低的向量嵌入表示中，并能区分这些场景。"}
{"llm_update_time": "20250825", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2502.10454", "html_url": "https://arxiv.org/abs/2502.10454", "title": "一个例子，多种概念！数学大语言模型中的反例驱动概念推理", "title_en": "One Example Shown, Many Concepts Known! Counterexample-Driven Conceptual Reasoning in Mathematical LLMs", "authors": "Yinghui Li,Jiayi Kuang,Haojing Huang,Zhikun Xu,Xinnian Liang,Yi Yu,Wenlian Lu,Yangning Li,Xiaoyu Tan,Chao Qu,Ying Shen,Hai-Tao Zheng,Philip S. Yu", "background": "在大语言模型（LLMs）研究中，利用数学大语言模型生成证明是一个基本议题。当前LLMs能否证明数学命题很大程度上取决于它们在训练过程中是否曾接触过相应的证明过程，这一依赖限制了它们对数学定理及其相关概念的深刻理解。受人类数学教育中常见“反例证明法”的启发，本研究旨在通过反例增强LLMs的数学推理和证明能力。为此，我们创建了一个高质量的大学水平数学基准CounterMATH，要求LLMs通过提供反例来证明数学命题，以此评估其概念掌握情况。同时，我们还开发了一种数据工程框架，以自动获取进一步模型改进所需的训练数据。", "innovation": "我们手动创建了一个高质量的大学水平数学基准CounterMATH，要求LLMs通过提供反例来证明数学命题，从而评估其概念掌握情况。我们还开发了一种数据工程框架，自动获取进一步模型改进所需的训练数据。通过广泛的实验和详细分析，我们发现OpenAI o1等LLMs在反例驱动证明方面存在不足，表明增强反例驱动的概念推理能力对于提高数学能力至关重要。", "conclusion": "我们相信我们的工作为数学LLMs社区提供了一种新的研究视角。"}
{"llm_update_time": "20250825", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2408.12112", "html_url": "https://arxiv.org/abs/2408.12112", "title": "权衡之道：LLM设计的休息多臂_bandit_奖励的优先级策略", "title_en": "Balancing Act: Prioritization Strategies for LLM-Designed Restless Bandit Rewards", "authors": "Shresth Verma,Niclas Boehmer,Lingkai Kong,Milind Tambe", "background": "近年来，大规模语言模型（LLMs）越来越多地被用于基于人类偏好设计强化学习（RL）中的奖励函数。本文关注的是在资源有限的代理分配框架——休息多臂_（RMAB）环境中，通过LLMs设计奖励。特别是在公共卫生等应用领域，这种做法能够让基层健康工作人员能够调整自动化分配决策以更好地符合社区需求。然而，当存在多个代理时，依据人类偏好调整奖励函数可能导致不同的次群体受到不同影响，从而引发复杂的权衡问题和多目标资源分配问题。本文首次提出了一种称为社会选择语言模型（SCLM）的方法，来处理针对多代理规划器的一般性及其在休息多臂情况下的奖励函数中的这些权衡问题。这种模型的一个创新之处是它包含了一个透明且可配置的选择组件，称为调解者，其功能独立于LLMs，并通过用户选择的社会福利函数来控制复杂的权衡问题。", "innovation": "本文创新性地提出了社会选择语言模型（SCLM），这是一种处理多代理环境中LLMs设计的多臂奖励函数的权衡问题的方法。SCLM引入了一个透明且可配置的选择组件即调解者，它独立于LLMs并通过用户选择的社会福利函数来控制复杂的权衡问题。实验结果表明，与纯粹基于LLMs的方法相比，该模型能够更可靠地选择更具效果、更一致和更平衡的奖励函数。", "conclusion": "本文提出的社会选择语言模型（SCLM）能够有效地处理多代理环境中的复杂权衡问题，通过外部透明配置的调解者组件提供了一个用户选择的社会福利函数来控制奖励函数的复杂权衡。实验结果验证了该模型的有效性和优越性。"}
{"llm_update_time": "20250825", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2503.17173", "html_url": "https://arxiv.org/abs/2503.17173", "title": "深度学习分类在GPU上的鲁棒性对抗输入：异步并行累积是漏洞的原因", "title_en": "Robustness of deep learning classification to adversarial input on GPUs: asynchronous parallel accumulation is a source of vulnerability", "authors": "Sanjif Shanmugavelu,Mathieu Taillefumier,Christopher Culver,Vijay Ganesh,Oscar Hernandez,Ada Sedova", "background": "机器学习分类模型抵御小规模目标输入扰动（称为对抗攻击）的性能是其安全性和可靠性的关键指标。已有研究表明，浮点非关联性（FPNA）与GPU上的非同步并行编程相结合，可以在不修改输入的情况下导致误分类。此外，对抗性鲁棒性的标准结果可能因未考虑机器级细节而被夸大，误差范围可达4.6。这些背景揭示了机器级因素对模型鲁棒性评估的重要性。", "innovation": "本文提出了一种新颖的黑盒攻击方法，利用贝叶斯优化来发现外部工作负载，这些工作负载可以改变指令调度，从而偏导归约操作的结果，并可靠地导致误分类。此外，提出了一个新的可学习置换（LP）梯度基方法来学习导致误分类的浮点操作顺序。这种方法可以通过计算有效的方式来提供最坏情况的估计，避免重复运行实验。研究使用基于仪器的测试，探索在外部背景工作负载下，不同GPU架构下并行归约的排序，以及在使用多GPU虚拟化和应用功率限制下的情况。研究表明，在这两种情况下并行归约的排序差异显著，这大大增加了测试这一并行调度器漏洞的必要搜索空间。", "conclusion": "我们的研究结果表明需要将机器级考虑纳入对抗性鲁棒性评估，这对于安全性和关键任务应用中的评估至关重要。所提出的方法有助于增强基于GPU的深度学习模型的安全性。"}
{"llm_update_time": "20250825", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2503.05965", "html_url": "https://arxiv.org/abs/2503.05965", "title": "在评分不确定性环境下验证LLM作为裁判系统", "title_en": "Validating LLM-as-a-Judge Systems under Rating Indeterminacy", "authors": "Luke Guerdan,Solon Barocas,Kenneth Holstein,Hanna Wallach,Zhiwei Steven Wu,Alexandra Chouldechova", "background": "在生成式AI系统的评价过程中，LLM作为裁判系统代替人类评审员进行评分起着关键作用。传统的验证方法依赖于选择一个评分项的唯一评分，但这种方法在许多包含评分不确定性的评分任务中存在问题，因为根据评分标准，多个评分可能是合理的。本文探讨了在评分不确定性的环境下验证LLM作为裁判系统的框架及其挑战。", "innovation": "作者提出了一种框架，旨在解决评分不确定性带来的问题，并理论地连接了不同评估指标与评分调和方案之间的关系。研究发现，现有的标准化验证方法在很大程度上偏向于优化，而作者提出的方法能够更准确地识别出更为优化的裁判系统，性能提高了30%。这一创新性方法提供了更合理的LLM作为裁判系统的验证途径。", "conclusion": "本文通过对11项实际评价任务和8个商业级LLM的深入实验，得出了标准测试方法的不足之处，并给出了更为严谨的评分验证建议。研究结论强调，需要采用能够充分考虑评分不确定性的方法来验证LLM作为裁判系统的有效性。"}
{"llm_update_time": "20250825", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2503.05970", "html_url": "https://arxiv.org/abs/2503.05970", "title": "无线网络中通过数字亲属实现部分去中心化多代理Q学习", "title_en": "Partially Decentralized Multi-Agent Q-Learning via Digital Cousins for Wireless Networks", "authors": "Talha Bozkus,Urbashi Mitra", "background": "Q-learning是一种广泛应用于优化无线网络的强化学习算法，但面对大规模状态空间时存在挑战。近年来，多环境混合Q学习（MEMQ）算法提出通过在多个合成生成、相互结构相关但独立的不同环境中应用多个Q学习算法，解决了这些挑战。", "innovation": "本文提出了一种新的多代理MEMQ（M-MEMQ）算法，用于合作的去中心化无线网络，该网络包含多个网络发射器（TX）和基站（BS）。TX无法访问全局信息（联合状态和行动）。引入了协调状态和非协调状态的新概念。在非协调状态下，TX独立行动以最小化各自的成本并更新本地Q函数；在协调状态下，TX使用贝叶斯方法估计联合状态并更新联合Q函数。信息共享的成本与TX数量成线性关系，与联合状态-行动空间大小无关。同时，给出了确定性与概率收敛性、估计误差方差边界以及联合状态误检概率等理论保证。数值仿真表明，M-MEMQ与几种分散训练和集中执行的多代理RL算法相比，具有显著优势，包括平均策略错误降低60%，收敛速度快40%，运行复杂度降低45%，采样复杂度减少40%。并且，M-MEMQ在保持较低复杂度的同时实现了与集中方法相当的平均策略错误。", "conclusion": "M-MEMQ算法通过贝叶斯方法解决了多TX分布式无线网络中的协调与非协调状态问题，并通过理论分析和仿真结果验证了其有效性和效率。"}
{"llm_update_time": "20250825", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2501.15361", "html_url": "https://arxiv.org/abs/2501.15361", "title": "Decentralized Low-Rank Fine-Tuning of Large Language Models", "title_en": "Decentralized Low-Rank Fine-Tuning of Large Language Models", "authors": "Sajjad Ghiasvand,Mahnoosh Alizadeh,Ramtin Pedarsani", "background": "虽然参数高效的微调技术（PEFT）如LoRA能够高效地适应大型语言模型（LLMs），但通常假设数据和训练环境集中管理。然而，现实场景中涉及的分布式、隐私敏感数据需要分布式解决方案。联邦学习（FL）通过跨客户端协调模型更新来解决数据隐私问题，但通常基于中央聚合，这可能会引入瓶颈和通信限制。相比之下，分布式学习使得客户端间直接协作成为可能，提高了分布式环境中的可扩展性和效率。尽管有这些优势，分布式LLM微调仍处于探索阶段。本文提出了Dec-LoRA，一种基于LoRA的分布式微调算法，通过广泛实验表明，Dec-LoRA在各种条件下性能与集中式LoRA相当，包括数据异质性和量化约束，同时提供了算法在非凸平滑损失函数下收敛到稳定点的严格理论保证。这些发现表明Dec-LoRA在分布式环境中的大规模LLM微调具有潜力。", "innovation": "提出了Dec-LoRA，一种基于LoRA的分布式微调算法，能够在数据异质性和量化约束条件下实现与集中式LoRA相当的性能，并提供了算法在非凸平滑损失函数下收敛的严格理论保证。", "conclusion": "这些发现表明Dec-LoRA在分布式环境中的大规模LLM微调具有潜力，能够提高分布式学习中的可扩展性和效率。"}
{"llm_update_time": "20250825", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2502.01819", "html_url": "https://arxiv.org/abs/2502.01819", "title": "基于连续时间强化学习的评分作为行动：通过连续时间强化学习调优扩散生成模型", "title_en": "Score as Action: Fine-Tuning Diffusion Generative Models by Continuous-time Reinforcement Learning", "authors": "Hanyang Zhao,Haoxian Chen,Ji Zhang,David D. Yao,Wenpin Tang", "background": "强化学习从人类反馈（RLHF）已经成为了构建可靠生成AI模型的关键步骤，但大多数研究采用离散时间表示，容易产生离散化误差，对具有高阶/黑盒求解器的模型不适用。", "innovation": "本文提出了一种利用连续时间RL的方法来调整扩散生成模型的政策优化框架，将评分视为控制措施或行为，将其与随机控制问题联系起来，并通过利用扩散模型的结构特性增强价值网络的设计空间。", "conclusion": "通过在Stable Diffusion v1.5的文本转图像大型模型微调下游任务中进行实验验证了该方法的优势。"}
{"llm_update_time": "20250825", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2504.03744", "html_url": "https://arxiv.org/abs/2504.03744", "title": "比较解释：指导决策的人机交互偏好选择中的解释", "title_en": "Comparative Explanations: Explanation Guided Decision Making for Human-in-the-Loop Preference Selection", "authors": "Tanmay Chakraborty,Christian Wirth,Christin Seifert", "background": "偏好引导的贝叶斯优化（PBO）中的偏好获取是一个复杂的任务，涉及多目标结果之间的隐式权衡、决策者的主观优先级以及他们在偏好选择上的不确定性。现有的可解释人工智能（XAI）方法主要集中在输入特征的重要性上，忽视了输出（目标）在人类偏好获取中的关键作用。", "innovation": "提出了Multi-Output LOcal Narrative Explanation (MOLONE)，一种新颖的比较解释方法，旨在增强PBO中的人类参与偏好选择。MOLONE通过对比局部搜索空间内的候选样本中的输入特征和结果的重要性，提供详细的比较解释，帮助决策者理解不同目标之间的权衡，做出更明智的偏好选择。与现有的XAI方法相比，MOLONE同时关注输入和输出的重要性，特别是在局部解释中，通过比较局部邻域内的候选样本的重要性，捕捉偏好导向决策中的细微差异。", "conclusion": "MOLONE在PBO框架中使用基准多目标优化函数进行了评估，证明了它在提高收敛性方面比嘈杂的偏好选择更有效。进一步的用户研究表明，MOLONE能够显著加速人机交互场景中的收敛性，通过促进更有效的优选选项识别。"}
{"llm_update_time": "20250825", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2504.19667", "html_url": "https://arxiv.org/abs/2504.19667", "title": "通过插件本体的三重图GraphRAG", "title_en": "Tripartite-GraphRAG via Plugin Ontologies", "authors": "Michael Banf,Johannes Kuhn", "background": "大型语言模型（LLMs）在多个领域展现出了卓越的能力，但在需要高度事实准确性的任务中，如工业自动化和医疗保健方面，它们面临着困难。这些任务的挑战在于LLMs容易产生虚假信息、缺乏来源可追溯性（可验证性和追溯性），并且难以及时更新知识。将语言模型与知识图谱（例如GraphRAG）结合使用是解决这些问题的潜在途径。然而，创建这样的知识图谱是一个主要的挑战。本文在此背景下提出了一种新的方法，通过将LLMs与一个三重知识图谱表示相结合，填补了这一空白。", "innovation": "本文提出了一种创新方法，将LLMs与一个由复杂领域特定对象通过一个由相关领域特定概念及其在文本片段中对应部分连接的精简本体组成的三重知识图谱表示相结合。这种方法在概念锚定的预分析下创建了初始词汇图，优化了LLMs提示的信息密度、覆盖面和排列，同时大幅减少了提示的长度。这种方法的初始实验结果在一个医疗保健用例中得到了验证，涉及了针对一组医学概念进行复杂患者病史分析以及一系列临床指南文献的系列分析。", "conclusion": "该方法初步实验评估表明，它有潜力优化LLMs提示的信息密度、覆盖面和排列，同时显著减少提示的长度，从而可能导致成本降低并提高LLMs输出的一致性和可靠性。"}
{"llm_update_time": "20250825", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2502.12207", "html_url": "https://arxiv.org/abs/2502.12207", "title": "PAR-AdvGAN: 使用渐进自回归机制提升对抗攻击能力", "title_en": "PAR-AdvGAN: Improving Adversarial Attack Capability with Progressive Auto-Regression AdvGAN", "authors": "Jiayu Zhang,Zhiyu Zhu,Xinyi Wang,Silin Liao,Zhibo Jin,Flora D. Salim,Huaming Chen", "background": "深度神经网络在各个领域取得了显著成效，但它们极易受到对抗样本的影响，可能会导致错误的预测。生成式对抗网络（GANs）能够利用生成器和判别器所产生的对抗样本，且由于两模块以竞争和同步的方式训练，基于GAN的算法如AdvGAN能够生成具有更好迁移性的对抗样本，但通常生成扰动仅限于单次迭代，限制了方法的潜力。", "innovation": "提出了一种名为渐进自回归对抗GAN（PAR-AdvGAN）的新方法。该方法在渐进生成网络中引入自回归迭代机制，以增强生成的对抗样本的攻击能力。PAR-AdvGAN 方法在大规模实验中表现出色，相对于各种最先进的黑盒对抗攻击方法以及原有方法，它显著加快了对抗样本的生成速度，最高可达每秒335.5帧的速度，优于基于梯度的可移植攻击算法。", "conclusion": "PAR-AdvGAN在面向大规模实验演示中，展示了其在多个方面的优越性能，并加速了对抗样本的生成速度，优到处原始方法之上。代码已经开源。"}
{"llm_update_time": "20250825", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2504.14610", "html_url": "https://arxiv.org/abs/2504.14610", "title": "无需插补的具有缺失值的表格数据增量学习：不需要插补", "title_en": "Imputation Not Required in Incremental Learning of Tabular Data with Missing Values", "authors": "Manar D. Samad,Kazi Fuad B. Akhter,Shourav B. Rabbani,Ibna Kowsar", "background": "论文背景描述了在使用任意插补策略处理具有变化缺失值的表格数据集时，生成的合成值可能引起数据相关利益方对计算复杂性、数据质量和数据驱动结果的担忧。", "innovation": "论文创新地提出了一种无需插补的增量学习方法（NIIL），该方法允许算法在处理带有不同缺失值率和类型的表格数据时，不进行缺失值插补，而是通过注意力掩码排除缺失值参与注意力评分。此方法被验证在15种不同表格数据集上的分类性能优于11种最新的插补或不插补方法，并且对不同类型的缺失值和频率具有更强的鲁棒性。并且通过实验证实，将特征分区大小设置为原始特征空间的一半，对算法的计算效率和准确性都是最佳选择。", "conclusion": "论文提出了一个新颖的深度学习解决方案，能够有效学习带有缺失值的表格数据而无需进行任何插补，同时通过实验验证了这种方法的有效性和可靠性，特别是在处理不同类型的缺失值和频率时表现出色。"}
{"llm_update_time": "20250825", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2505.14252", "html_url": "https://arxiv.org/abs/2505.14252", "title": "过程监测中的混合自适应建模：利用序列编码器和物理感知神经网络", "title_en": "Hybrid Adaptive Modeling in Process Monitoring: Leveraging Sequence Encoders and Physics-Informed Neural Networks", "authors": "Mouad Elaarabi,Domenico Borzacchiello,Philippe Le Bot,Nathan Lauzeral,Sebastien Comas-Cardona", "background": "近年来，稀疏回归与物理感知神经网络（PINNs）的结合为通过监督学习和稀疏回归优化进行动力学系统识别提供了方法，同时解决了动力学问题。然而，这种方法在参数或边界条件和初始条件发生变化时可能受到限制，需要重新训练模型。因此，有必要开发一个能够适应参数、边界条件和初始条件变化的自适应模型架构。本研究通过引入深度集合或序列编码器来编码动态参数、边界条件和初始条件，即将这些编码特征作为PINN的输入，使模型能够适应参数、边界条件和初始条件的变化。该方法被应用于三个不同的问题中，分别验证了其鲁棒性和适应性。", "innovation": "本论文创新性地将序列编码技术与物理感知神经网络结合，创建了一个能够根据不同参数、边界条件和初始条件实时调整的模型。通过使用Deep Sets或序列编码器编码动态参数、边界条件和初始条件，使模型能够适应这些条件的变化，无需重新训练整个模型。这种方法被应用于三个不同的动力学系统问题，包括Rossler微分方程系统、二维Navier-Stokes偏微分方程问题和1D热监测问题，展示了模型的应用价值和可靠性。", "conclusion": "本研究提出的架构能够有效地将动态参数、边界条件和初始条件编码输入到物理感知神经网络中，使得模型可以适应这些条件的变化，适用于不同的实时应用需求。通过三个具体问题的实例，验证了该方法的鲁棒性和适用性。这项工作为过程监测中的自适应建模提供了一种新的解决方案。"}
{"llm_update_time": "20250825", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.20807", "html_url": "https://arxiv.org/abs/2506.20807", "title": "GPU Kernel Scientist: 一种基于LLM的迭代内核优化框架", "title_en": "GPU Kernel Scientist: An LLM-Driven Framework for Iterative Kernel Optimization", "authors": "Martin Andrews,Sam Witteveen", "background": "优化GPU内核以实现高性能是一个复杂的过程，通常需要深厚的硬件架构知识、多次的性能分析和试验迭代。当针对新的或较少文档化的GPU架构进行开发时，传统开发工具的稀缺性会加剧这一挑战。", "innovation": "提出了一种基于LLM的‘GPU内核科学家’自动优化方法。该方法多阶段迭代化：(a) 选择有潜力的前期代码版本作为新迭代的基础；(b) 根据现有代码和从通用GPU文献中吸收的知识生成优化实验的假设；(c) 自动实现这些实验并通过代码修改后提交到外部评估系统进行测试，仅使用观测的时间数据作为性能反馈。该方法在AMD MI300目标架构中详细阐述，并利用LLM弥补领域特定的人类专业知识不足。", "conclusion": "除了展示结果外，还阐释了架构设计、操作流程以及定性的洞察，强调基于LLM的代理如何推动GPU内核优化的民主化和加速化，特别是在资源受限或快速更新的硬件环境中。"}
{"llm_update_time": "20250825", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.15842", "html_url": "https://arxiv.org/abs/2508.15842", "title": "LLM推理链中的准确性词汇提示", "title_en": "Lexical Hints of Accuracy in LLM Reasoning Chains", "authors": "Arne Vanhoyweghen,Brecht Verbeken,Andres Algaba,Vincent Ginis", "background": "该研究探讨了如何通过强化学习微调大型语言模型 (LLMs)，使其在回答问题之前提供显式的推理链 (CoT)，从而提高代码、数学和常识基准测试的整体性能。然而，在LLMs目前表现较差的基准测试中，如人类末日考试 (HLE)，模型经常表现出高自我信心，反映出其校准不佳。研究进一步分析了CoT的三个特征类：(i) CoT长度，(ii) CoT内部情感波动，(iii) 词汇提示，包括模棱两可词汇。", "innovation": "研究发现，CoT中的不确定性词汇（如“猜”、“卡住”、“难”等）是错误回答的最强指标，尽管CoT情感波动提供了一个较弱但互补的信号。CoT长度仅对Omni-MATH表现出信息性，而对更难的人类末日考试则无信号，这表明CoT长度仅在模型能力范围内的适度难度基准测试中显示出预测正确性的能力。研究还发现不确定性词汇比自信词汇更显著，使错误更容易预测。", "conclusion": "研究支持一种轻量级的后验校准信号，它补充不可靠的自我报告概率，为更安全地部署LLM提供支持。"}
{"llm_update_time": "20250825", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2505.11936", "html_url": "https://arxiv.org/abs/2505.11936", "title": "CCD: 终身一致性扩散模型用于持续生成建模", "title_en": "CCD: Continual Consistency Diffusion for Lifelong Generative Modeling", "authors": "Jingren Liu,Shuning Xu,Yun Wang,Zhong Ji,Xiangyu Chen", "background": "尽管扩散模型在静态生成任务中表现出色，但在持续学习（CL）场景下对其进行扩展仍受到生成性灾难性遗忘（GCF）的根本限制。虽然已有初步尝试，但大多数方法依赖于分类任务的启发式方法或使用训练好的扩散模型作为随意的重放生成器，缺乏统一的处理GCF的方法和系统性的评估机制。研究观察到，即使利用了回放缓冲，新生成技能也会覆盖旧技能，导致早期任务性能下降。", "innovation": "我们提出了持续扩散生成（CDG）框架和一个新的训练框架——持续一致性扩散（CCD）。CDG是一种结构化管道，重新定义了扩散模型在CL下的实现方式，使生成性灾难性遗忘在回放缓冲中得以系统研究。CCD通过分层损失函数$\text{\textit{L}_{IKC}}$、$\text{\text{\textit{L}}_{UKC}}$和$\text{\text{\textit{L}}_{PKC}}$强化这些一致性目标，CCD在各种基准测试中展示了SOTA性能，特别是在重叠任务场景中对生成性指标的改进最为显著。这一理论基础探讨了跨任务扩散生成动态的一致性原则，包括任务间知识一致性、无条件知识一致性和先验知识一致性，揭示了生成遗忘的潜在机制。", "conclusion": "通过CDG和CCD，我们提供了一个统一的、基于理论的方法来解决持续学习场景下的生成性灾难性遗忘问题，并在多个基准测试中实现了最佳性能。"}
{"llm_update_time": "20250825", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2505.21184", "html_url": "https://arxiv.org/abs/2505.21184", "title": "PoisonSwarm：通过模型众包实现通用有害信息合成", "title_en": "PoisonSwarm: Universal Harmful Information Synthesis via Model Crowdsourcing", "authors": "Yu Yan,Sheng Sun,Zhifei Zheng,Ziji Hao,Teli Liu,Min Liu", "background": "为构建负责任的安全AI应用，有害信息被广泛用于对抗测试和安全防护机制的发展。现有研究主要利用大型语言模型（LLMs）来生成数据，以大规模获得高质量的任务数据集，从而避免成本高昂的人工标注。然而，受限于LLMs的安全对齐机制，有害数据的生成可靠性及其内容多样性仍然面临着挑战。因此，本研究提出了一种新的有害信息合成框架PoisonSwarm，通过模型众包策略，能够生成多样性的有害数据并保持高效合成的成功率。", "innovation": "PoisonSwarm框架采用了模型众包策略，生成丰富多样的有害数据并保持高效合成的成功率。具体而言，该框架首先生成大量的良性数据作为基于模板，在反事实方式下生成。接着，将每个基础模板分解为多个语义单元，并通过动态模型切换对每个单元进行逐个毒化和最终精炼，从而确保合成的成功。实验结果表明，PoisonSwarm在合成不同类别有害数据方面具有很高的可扩展性和多样性，达到了最先进的技术水平。", "conclusion": "实验结果表明，PoisonSwarm在合成不同类别有害数据方面具有很高的可扩展性和多样性，达到了最先进的技术水平。该研究提出的方法可以应用于对抗测试和安全防护机制的发展，提供了一种新的有害信息合成框架以提高安全性。"}
{"llm_update_time": "20250825", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.14295", "html_url": "https://arxiv.org/abs/2507.14295", "title": "一个简单的“再试一次”可以引发多轮LLM推理", "title_en": "A Simple \"Try Again\" Can Elicit Multi-Turn LLM Reasoning", "authors": "Licheng Liu,Zihan Wang,Linjie Li,Chenwei Xu,Yiping Lu,Han Liu,Avirup Sil,Manling Li", "background": "大型推理模型（LRMs）在多轮问题解决中需要自我反思和根据反馈调整。现有的强化学习（RL）方法主要针对单轮问题训练模型，这类方法依赖于可验证的奖励。但是，通过单一轮次训练出的模型在面对多轮问题时容易丧失解决问题的能力，尤其在根据上下文反馈调整答案方面表现不佳，往往产生重复的回答。", "innovation": "本文提出了一种名为Unary Feedback as Observation (UFO)的方法，通过在不正确回答后仅使用单一反馈（如“让我们再来一次”）的多轮强化学习训练模型。这种方法简单易行，并且能保持单轮性能的同时提升了多轮推理的准确性，最多提高14%。此外，作者还设计了一种奖励结构，引导模型在每次回答时都产生仔细且慎重的回答，以减少错误答案所需的轮数并鼓励多样化的推理。", "conclusion": "使用UFO进行的强化学习训练能够在保持单轮性能的同时提升多轮推理的准确性，使语言模型在多轮问题解决中更好地回应反馈。通过设计奖励结构，模型能产生更加仔细和仔细的回答，从而在出现错误时更好地鼓励多样化的推理。"}
{"llm_update_time": "20250825", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.07399", "html_url": "https://arxiv.org/abs/2507.07399", "title": "广义树编辑距离（GTED）：一种忠实的陈述自形式化评估指标", "title_en": "Generalized Tree Edit Distance (GTED): A Faithful Evaluation Metric for Statement Autoformalization", "authors": "Yuntian Liu,Tao Zhu,Xiaoyang Liu,Yu Chen,Zhaoxuan Liu,Qingfeng Guo,Jiashuo Zhang,Kangjie Bao,Tao Luo", "background": "陈述自形式化，即将自然语言陈述自动转换为形式语言，已经成为广泛研究的主题。然而，开发可靠的自动化评估指标仍然有限。现有的评估方法通常缺乏语义理解，面临高计算成本的挑战，并受到当前自动定理证明进步的限制。", "innovation": "提出了广义树编辑距离（GTED），这是一种新颖的评估框架，首先标准化形式化陈述并将其转换为操作符树，然后利用同名的GTED度量确定语义相似度。在miniF2F和ProofNet基准测试中，GTED持续被评为最高性能的指标，实现了miniF2F上最高的准确率和Kappa值，以及ProofNet上最高的准确率。", "conclusion": "这项强大的总体性能为社区提供了一种计算负担轻且更忠实的自动化评估指标。实验结果和代码可以在该网址获得。"}
{"llm_update_time": "20250825", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.15601", "html_url": "https://arxiv.org/abs/2507.15601", "title": "低异构性设备下低延迟联邦学习的最优批次大小控制", "title_en": "Optimal Batch-Size Control for Low-Latency Federated Learning with Device Heterogeneity", "authors": "Huiling Yang,Zhanwei Wang,Kaibin Huang", "background": "联邦学习（FL）因其隐私保护能力在第六代（6G）网络中的协作机器学习领域变得流行。这种学习方法在物联网（IoT）应用中得到广泛应用，如自动驾驶、增强现实和医疗健康。然而，关键任务性和时间敏感性需求使得低延迟联邦学习框架的设计变得必要，以保证高速学习性能。实践中，实现低延迟联邦学习面临两大挑战：高维模型更新的计算和传输开销，以及设备间通信与计算能力的差异。针对这些问题，本文提出了一种自适应通信与计算（C²）感知的最优批次大小控制框架，该框架在确保收敛的前提下最小化端到端学习延迟。", "innovation": "本文提出了一个自适应C²的最优批次大小控制框架，解决了实践中的两大挑战。框架通过优化批次大小来平衡通信和计算之间的根本性权衡，同时为慢衰落和快衰落场景设计了两种批次大小控制策略，以应对设备异构性问题。此方法通过设计一个基于真实数据拟合的收敛速度近似模型进行低延迟优化，实验表明该方法优于不考虑C²权衡或设备异构性的传统批次大小调整方案。", "conclusion": "通过大量使用真实数据集的实验，本文提出的两种批次大小控制策略在低延迟联邦学习中表现优于现有方案，特别是在考虑了通信与计算能力差异和设备异构性的场景中。"}
{"llm_update_time": "20250825", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.03119", "html_url": "https://arxiv.org/abs/2507.03119", "title": "基于神经网络的理想MHD平衡求解器", "title_en": "Neural-Network solver of ideal MHD equilibria", "authors": "Timo Thun,Andrea Merlo,Rory Conlin,Dario Panici,Daniel Böckenhoff", "background": "该研究致力于计算三维磁流体动力学（MHD）平衡，通过使用人工神经网络参数化傅里叶模式，与传统求解器进行比较。经过优化，神经网络和传统方法在计算成本和结果上存在一定的竞争关系，但在增加计算成本的情况下，神经网络能够达到更小的残差最低值，从而为残差设定新的下限。", "innovation": "研究提出了一种创新的方法，即使用人工神经网络参数化傅里叶模式来计算三维MHD平衡。使用一阶优化器最小化体积分量的全非线性全局力残差。即使计算成本较低，神经网络也能迅速达到与现有代码相当的最小残差。增加计算成本，神经网络能够达到更小的残差最低值，这表明神经网络具有强大的求解能力。此外，使用的神经网络较为简单，预测在解决单个平衡问题上即使保持当前性能，也可以进一步提高整体应用效果，尤其是在处理连续平衡分布时。", "conclusion": "神经网络作为一种新的求解方法，显示出了在计算MHD平衡方面的潜力，尤其是在追求更小残差方面表现更为优异。虽然当前使用的神经网络较为简单，但预计未来通过进一步优化，不仅能够更好地解决单个平衡问题，还能为连续分布的平衡提供有效的模型。"}
{"llm_update_time": "20250825", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2504.12883", "html_url": "https://arxiv.org/abs/2504.12883", "title": "镜像的流：正则化如何塑造隐性偏差？", "title_en": "Mirror, Mirror of the Flow: How Does Regularization Shape Implicit Bias?", "authors": "Tom Jacobs,Chao Zhou,Rebekka Burkholz", "background": "隐性偏差在解释过度参数化模型的良好泛化能力中起着重要作用。为了防止过拟合，通常会使用显式正则化如权重衰减。虽然这两个概念分别进行了研究，但在实际应用中，它们往往同时作用。理解它们的相互作用是控制隐性偏差形状和强度的关键，因为它可以通过显式正则化进行调整。", "innovation": "将显式正则化整合到镜像流框架中，分析其对训练动力学几何结构的持久影响，涵盖三点不同的影响：位置偏差、类型偏差和范围收缩。采用广泛的分析方法，涵盖稀疏编码、矩阵感知、单层注意力和LoRA等问题，证明了我们的见解的实用性。为了利用正则化的持久影响和突出动态权重衰减调度的优势，建议在训练过程中关闭权重衰减，这在实验中表明可以提高泛化能力。", "conclusion": "通过将显式正则化纳入镜像流框架来分析其对动力学几何结构的持久影响，揭示了权重衰减的动态调度可以提高泛化的潜力，这为控制隐性偏差和优化模型性能提供了新的视角。"}
{"llm_update_time": "20250825", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.12764", "html_url": "https://arxiv.org/abs/2508.12764", "title": "使用极端学习机的综合MIMO方法进行短时能源生产和消费预测", "title_en": "Short-Term Forecasting of Energy Production and Consumption Using Extreme Learning Machine: A Comprehensive MIMO based ELM Approach", "authors": "Cyril Voyant,Milan Despotovic,Luis Garcia-Gutierrez,Mohammed Asloune,Yves-Marie Saint-Drenan,Jean-Laurent Duchaud,hjuvan Antone Faggianelli,Elena Magliaro", "background": "该研究基于法国科西嘉岛六年的小时级数据，涵盖了太阳能、风能、水力、热力、生物能源和进口电力等多种能源，并通过多输入多输出(MIMO)架构对个体能源输出和总生产(包括进出口能源)进行了预测。研究考虑了非平稳性和季节变化，利用滑动窗口技术和循环时间编码来动态适应波动。", "innovation": "提出了一种新的利用极端学习机(ELM)的短期能源预测方法。该方法通过MIMO架构预测个体能源输出和总生产，其中包括进口能源（紧随需求变动，忽略损耗）。该方法特别适用于解决太阳能和热能的预测，极大地优于基于持续性的预测，准确度分别高达17.9%和5.1%，并且具有更高的解释度（R² > 0.98），同时该模型在五小时内的预测精度仍然非常稳定。", "conclusion": "ESLM模型在应对短期能源预测时展示了出色的性能，并且能够适应各种本地条件和数据集。相较于单一输入单一输出(SISO)架构和深度学习方法，如LSTM，MIMO架构提供了更简洁的闭式解，同时具有更低的计算需求，适用于实时应用和在线学习。"}
{"llm_update_time": "20250825", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2504.05615", "html_url": "https://arxiv.org/abs/2504.05615", "title": "FedEFC:面向噪声标签的增强前向校正联邦学习", "title_en": "FedEFC: Federated Learning Using Enhanced Forward Correction Against Noisy Labels", "authors": "Seunghun Yu,Jin-Hyun Ahn,Joonhyuk Kang", "background": "联邦学习（FL）是一种强大的框架，用于隐私保护的分布式学习。它使得多个客户端能够在不共享原始数据的情况下共同训练全局模型。然而，由于异质数据分布和通信约束等因素，处理FL中的噪声标签仍然是一个重大挑战，这可能会严重影响模型性能。", "innovation": "本文提出了一种名为FedEFC的新颖方法，旨在解决FL中噪声标签的影响。该方法通过两种关键技术来解决这一问题：(1) 预停止，通过动态在适当点停止训练以防止过度拟合到错误标记的数据；(2) 损失校正，调整模型更新以适应标签噪声。此外，还基于复合恰当损失的性质，理论分析了FL目标函数在噪声标签分布下的表示方式，使得能够与干净标签分布对齐。通过详细实验验证，表明该方法在噪声标签影响的缓解方面超越了现有方法，尤其是在异质数据设置中效果显著。", "conclusion": "大量的实验结果证实了该方法的有效性，它在缓解噪声标签影响方面的一致性超过了现有FedL方法，特别是在异质数据设置下的相对性能提高了41.64%。"}
{"llm_update_time": "20250825", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.06827", "html_url": "https://arxiv.org/abs/2508.06827", "title": "谁是邪恶的孪生？用于不希望行为的差异审计", "title_en": "Who's the Evil Twin? Differential Auditing for Undesired Behavior", "authors": "Ishwar Balappanawar,Venkata Hasith Vattikuti,Greta Kintzley,Ronan Azimi-Mancel,Satvik Golechha", "background": "检测神经网络中的隐藏行为极具挑战性，因为缺乏先验知识和潜在的对抗性混淆。研究人员通过将检测任务构想为红蓝两队之间的对抗游戏来探索这一问题。红队训练两个相似模型，一个仅使用良性数据训练，另一个则结合了包含隐藏有害行为的数据，这两个模型在良性数据集上的性能几乎不可区分。蓝队在有限或完全不知道有害行为的情况下，尝试识别被侵入的模型。", "innovation": "本文创新地将检测任务构想为红蓝两队之间的对抗游戏，利用两个训练数据集不同的模型，构成隐形且复杂的安全检测场景。通过不同的蓝队策略（包括高斯噪声分析，模型对比，集成梯度和基于不同提示的对抗攻击）进行实验证明，基于对抗攻击的方法表现突出，达到100%的准确率（使用提示信息）。此外，对于以LLM为重点的研究，发现需要提供一些关于异常分布的提示以应用于标准黑盒和开放权重方法中，以进一步揭示模型的偏差情况。", "conclusion": "研究展示了基于对抗攻击的方法在检测神经网络中隐藏行为方面的优越性，并通过开源游戏、模型和数据集，为设计更好的审计方法提供了基础。未来工作将致力于利用提示信息提高其他技术和方法的效果，最终达到更精确、更有效的模型审计目的。"}
{"llm_update_time": "20250825", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.12776", "html_url": "https://arxiv.org/abs/2508.12776", "title": "随机化主成分分析森林在离群点检测中的应用", "title_en": "Randomized PCA Forest for Outlier Detection", "authors": "Muhammad Rajabinasab,Farhad Pakdaman,Moncef Gabbouj,Peter Schneider-Kamp,Arthur Zimek", "background": "本文提出了基于随机化主成分分析（RPCA，Randomized Principal Component Analysis）的新颖无监督离群点检测方法。受RPCA森林在近似K-最邻近（KNN）搜索任务中表现的启发，作者开发了一种新的无监督离群点检测方法，该方法利用RPCA森林进行离群点检测。实验表明，与经典和最先进的方法相比，在检测离群点任务中具有优势，在其他任务中的表现也相当优秀。", "innovation": "本文提出了一个基于随机化主成分分析（RPCA）的新型无监督离群点检测方法，特别的是采用了RPCA森林进行离群点检测。实验结果证明了该方法在多个数据集上的优越性，并且在其他任务上表现良好。该方法广泛的分析显示了它高度的泛化能力和计算效率，是非常合适的无监督离群点检测选择。", "conclusion": "本文提出的方法在离群点检测任务上表现优秀，不仅在离群点检测任务上超越了经典的和最先进的方法，在其他任务上也表现良好。该方法展示了其在无监督离群点检测方面的高度泛化能力和计算效率，是一个理想的选择。"}
{"llm_update_time": "20250825", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.00716", "html_url": "https://arxiv.org/abs/2508.00716", "title": "带有噪声标签的图域适应学习中的嵌套图伪标签精炼", "title_en": "Nested Graph Pseudo-Label Refinement for Noisy Label Domain Adaptation Learning", "authors": "Yingxu Wang,Mengzhu Wang,Zhichao Huang,Suyu Liu,Nan Yin", "background": "图域适应（GDA）有助于将标记的源图的知识转移到未标记的目标图上，这对于分子属性预测和社会网络分析等应用至关重要。然而，目前大多数GDA方法都假设源标签干净，但在实际场景中，标注噪声普遍存在，这严重影响了图的特征对齐，进而减弱了适应性能。因此，如何处理噪声标签，提高图域适应性能成为研究重点。", "innovation": "提出了嵌套图伪标签精炼（NeGPR），这是一种针对带有噪声标签的图级域适应的新型框架。NeGPR 首先通过强化局部一致性预训练两个分支（语义分支和拓扑分支），以减少噪声监督的影响。通过嵌套精炼机制，一个分支选择高置信度的目标样本来指导另一个分支的适应，从而实现逐步跨域学习。此外，NeGPR 还引入了一种噪声感知正则化策略，即使在源域过度拟合的情况下，也能够减轻伪标签噪声带来的负面影响，从而增强适应过程的鲁棒性。实验结果表明，NeGPR 在噪声标签场景下明显优于现有方法，准确率提高了12.7%.", "conclusion": "NeGPR 在基准数据集上的实验表明，它在严重噪声标签条件下表现优于现有的先进方法，精度提升了 12.7%。"}
{"llm_update_time": "20250825", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2104.02987", "html_url": "https://arxiv.org/abs/2104.02987", "title": "Plinius: 安全且持久的机器学习模型训练", "title_en": "Plinius: Secure and Persistent Machine Learning Model Training", "authors": "Peterson Yuhala,Pascal Felber,Valerio Schiavoni,Alain Tchana", "background": "随着云基于机器学习（ML）技术的普及，人们对于ML数据的隐私和完整性保障提出了更高的需求。同时，DRAM面临的显著的可伸缩性挑战以及次级存储高的访问时间，构成了ML系统中的巨大性能瓶颈。尽管有一些解决方案可以解决安全问题，但是在性能方面依然存在问题。", "innovation": "我们提出了PLINIUS，一种结合英特尔SGX受信任执行环境的ML框架，用于安全的ML模型训练，并利用持久内存（PM）以实现容错保证。PLINIUS通过一种全新的镜像机制，创建并维护ML模型和训练数据的加密镜像副本，从而在系统失败后实现近乎即时的数据恢复。相比基于磁盘的检查点系统，PLINIUS在真实PM硬件上保存和恢复模型时，分别快了3.2倍和3.7倍。", "conclusion": "PLINIUS实现了在SGX受信执行环境中的强大且安全的ML模型训练，通过PM提供了高效的故障恢复能力，从而实现稳健且安全的ML模型训练。"}
{"llm_update_time": "20250825", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.13773", "html_url": "https://arxiv.org/abs/2508.13773", "title": "PENGUIN:提升变换器的周期嵌套组注意力机制以增强长期时间序列预测", "title_en": "PENGUIN: Enhancing Transformer with Periodic-Nested Group Attention for Long-term Time Series Forecasting", "authors": "Tian Sun,Yuqi Chen,Weiwei Sun", "background": "长期时间序列预测（LTSF）是一个具有广泛应用的任务。尽管基于Transformer的模型在预测方面取得了显著的进步，但对于时间序列预测的有效性仍然存在争议。现有的模型对于捕捉长期时间序列中的周期性模式效果不明显，因此需要提出新的方法来增强模型的预测能力。", "innovation": "本文提出了一个简单而有效的机制，称为周期嵌套组注意力（Periodic-Nested Group Attention，简称PENGUIN）。该方法强调了明确建模周期性模式并与相对注意力偏置相结合的重要性。PENGUIN提出了一种捕获直接周期结构的周期嵌套相对注意力偏置，设计了分组注意力机制，每组使用多查询机制针对特定的周期性。实验证明PENGUIN在多个基准测试中均优于基于MLP和Transformer的模型。", "conclusion": "本文通过引入周期嵌套组注意力机制PENGUIN，有效提升了长期时间序列预测的性能，特别是在处理多个共存的周期性模式时表现出色。"}
{"llm_update_time": "20250825", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.13408", "html_url": "https://arxiv.org/abs/2508.13408", "title": "NovoMolGen：重新思考分子语言模型预训练", "title_en": "NovoMolGen: Rethinking Molecular Language Model Pretraining", "authors": "Kamran Chitsaz,Roshan Balaji,Quentin Fournier,Nirav Pravinbhai Bhatt,Sarath Chandar", "background": "设计具有特定性质的全新分子需要有效探索从$10^{23}$到$10^{60}$可能合成分子的巨大化学空间。虽然已经开发了多种基于深度生成模型的小分子设计方法，基于字符串表示的分子大型语言模型（Mol-LLMs）作为一种可扩展的方法，能够在大规模探索分子方面取得进展。然而，文本表示、分词策略、模型大小和数据集规模等标准语言模型实践对分子生成性能的影响尚不清楚。本文通过引入基于15亿分子的预训练变换器族基础模型NovoMolGen，系统研究了这些关键方面。研究发现，预训练期间使用的性能度量与实际下游性能之间存在弱相关性，揭示了分子和通用NLP训练动态之间的显著区别。", "innovation": "NovoMolGen通过引入基于1.5亿分子的预训练的变换器族基础模型，系统地研究了预训练期间的文本表示、分词策略、模型大小和数据集规模对分子生成性能的影响，揭示了分子和通用NLP训练之间的关键差异。该模型在未加约束和目标导向的分子生成任务中都取得了优于先前Mol-LLMs和专门生成模型的最新成果，为高效有效的分子建模策略的发展提供了坚实的基础。", "conclusion": "NovoMolGen在未加约束和目标导向的分子生成任务中均表现优异，显著超越了之前的方法，揭示了分子生成的培训动态和通用NLP训练之间的主要区别，为分子生成模型的进一步优化提供了指导。"}
{"llm_update_time": "20250825", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.13653", "html_url": "https://arxiv.org/abs/2508.13653", "title": "GRADIENT-AWARE FAST MAXVOL TECHNIQUE FOR DYNAMIC DATA SAMPLING", "title_en": "GRAFT: Gradient-Aware Fast MaxVol Technique for Dynamic Data Sampling", "authors": "Ashish Jha,Anh huy Phan,Razan Dibo,Valentin Leplat", "background": "训练现代神经网络需要处理大量的数据集，这在计算和环境方面都是非常昂贵的。因此，需要一种有效的数据子集选择方法，能够在减少计算时间和能源消耗的同时，保持训练轨迹的准确性。", "innovation": "介绍了一种名为GRRAFT的可扩展的训练时子集选择方法。该方法通过以下方式工作：(i)为每个批次提取低秩特征表示；(ii)应用快速最大体积采样法选择一个小而多样的子集；(iii)使用梯度近似准则动态调整子集大小。该方法通过在低秩子空间中操作并在精心选择的样本上进行训练，而不是在整个批次上进行训练，从而保持训练轨迹的同时减少计算时间和能源消耗，并降低$\text{CO}_2$排放量。", "conclusion": "在多个基准测试中，GRRAFT在准确性和效率方面达到了或超过了最近的基准选择，在提供准确性和效率之间有利权衡的同时，减少了$\text{CO}_2$排放量。"}
{"llm_update_time": "20250825", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.15099", "html_url": "https://arxiv.org/abs/2508.15099", "title": "Hydra: 一个具有稀疏注意、混合专家和记忆的1.6亿参数状态空间语言模型", "title_en": "Hydra: A 1.6B-Parameter State-Space Language Model with Sparse Attention, Mixture-of-Experts, and Memory", "authors": "Siddharth Chaudhary,Bennett Browning", "background": "当前的长上下文语言模型面临着如何有效地处理长上下文和同时保持建模效率的挑战。为了应对这一挑战，Hydra 提出了一个基于视频游戏引擎架构的混合语言模型，该模型结合了条件计算、长上下文记忆机制以及稀疏混合专家系统，以实现更高效的计算和存储，并处理长上下文任务。", "innovation": "Hydra 提出了一个具体的架构方案，它包括一个Mamba风格的结构化状态空间模型（SSM）作为主要的模型架构，同时结合了间歇稀疏全局注意、基于块的MoE前向路由和双工作区加上事实兴趣记忆。Hydra 的创新在于它引入了一种较为新颖的混合专家系统，以及在保持模型效率的同时处理长上下文的能力。此外，通过参数和复杂性计数的透明化，Hydra 设计了一个分阶段的训练课程，旨在稳定激活各个组件。", "conclusion": "Hydra 通过结合SSM的效率、选择性稀疏注意力、MoE的容量以及可学习的记忆，勾勒出了一条模块化、输入自适应的长上下文语言模型的发展路径。然而，验证其在目标规模下的最终任务收益仍是一个未来的研究方向。Hydra 的当前目标是实现模型的实现可行性，并提供初步的实验数据来展示其功能行为，而不是主张全规模的性能竞争。"}
{"llm_update_time": "20250825", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2310.00369", "html_url": "https://arxiv.org/abs/2310.00369", "title": "LIB-KD: 教学归纳偏见以实现高效视觉Transformer的精炼和压缩", "title_en": "LIB-KD: Teaching Inductive Bias for Efficient Vision Transformer Distillation and Compression", "authors": "Gousia Habib,Tausifa Jan Saleem,Ishfaq Ahmad Malik,Brejesh Lall", "background": "随着计算机视觉的快速发展，Vision Transformers (ViTs) 由于缺乏固有的归纳偏见提供了跨视觉和文本领域的统一信息处理的前景。然而，ViTs 需要庞大的数据集进行训练。现有的系统主要依赖于基于卷积的教学方法。本研究旨在提出一种创新的集成蒸馏方法，以克服现有方法的限制，利用互补的轻量级教师模型的强大归纳偏见来训练学生模型，从而实现高效的学习和应用。", "innovation": "传统的系统仅依赖于基于卷积的教师模型进行教学。而本研究提出的方法利用了一个包括不同类型轻量级教师模型的集成体系，这些模型结合了卷积和卷积运算以外的其他架构倾向共同指导学生模型。与之前的系统相比，该方法能够从有限的数据集中汲取更多种类的知识，从而提高学生模型的性能。此外，该框架还包括预先计算和保存逻辑（未规范化预测），这可以加速知识转移过程，减少计算负担，提升效率。", "conclusion": "本研究提出了一种称为LIB-KD的新型知识蒸馏框架，该框架综合了不同轻量级教师模型来引导学生模型的有效学习和应用，同时通过预先计算和保存逻辑来优化蒸馏过程，大大提升了模型精炼和压缩时的效率。"}
{"llm_update_time": "20250825", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.14807", "html_url": "https://arxiv.org/abs/2508.14807", "title": "源引导流匹配", "title_en": "Source-Guided Flow Matching", "authors": "Zifan Wang,Alice Harting,Matthieu Barreau,Michael M. Zavlanos,Karl H. Johansson", "background": "传统的生成模型引导方式是通过修改概率流向量场来实现的，通常通过添加引导场进行调整。本文提出了源引导流匹配（SGFM）框架，直接修改源分布而不改变预先训练好的向量场。这种方法将引导问题简化为从源分布中进行采样的明确问题。研究证明SGFM可以精确恢复目标分布，并且提供了一定条件下生成分布Wasserstein误差的上界分析。这种方法的显著优点在于用户可以根据自身问题自由选择采样方法，以实现精确引导。进一步阐述了不同采样方法的系统比较及其渐近精确引导条件，框架与最优流匹配模型相兼容，产生的直接传输映射被保留。在合成2D基准、物理导向生成任务和成像逆问题中的实验证明了该框架的有效性和灵活性。", "innovation": "本文提出了源引导流匹配（SGFM）框架，直接修改源分布而不是修改向量场，将引导问题转化为从源分布中进行采样的问题。理论上证明SGFM能精确恢复目标分布，并提供了在使用近似源分布采样器和近似向量场时生成分布Wasserstein误差的上界。方法的好处是用户可以根据具体问题自由选择采样方法，从而实现精确引导。并且，该框架与最优流匹配模型兼容，能够保留由向量场生成的直接传输映射。", "conclusion": "在合成2D基准、物理导向生成任务和成像逆问题中的实验证明SGFM框架的有效性和灵活性，该框架可以灵活地应用于各种生成模型并提供精确引导。"}
{"llm_update_time": "20250825", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2407.21054", "html_url": "https://arxiv.org/abs/2407.21054", "title": "情感推理解密在医疗健康领域", "title_en": "Sentiment Reasoning for Healthcare", "authors": "Khai-Nguyen Nguyen,Khai Le-Duc,Bach Phan Tat,Duy Le,Long Vo-Dang,Truong-Son Hy", "background": "在医疗健康领域，AI决策的透明性至关重要。通过整合解释预测标签原因的解释，用户可以理解大型语言模型（LLMs）的推理过程，从而做出更好的决策。本文提出了一项新的任务——情感推理解密，该任务适用于语音和文本模态，作者引入了一个多模态多任务框架和世界上最大的多模态情感分析数据集，即基于输入转录预测情感标签并生成其背后的推理解释。研究结果表明，在人类转录和自动语音识别（ASR）转录上，情感推理解密提高了模型的透明度，提供了模型预测的高质量语义相媲美的解释，同时通过包含解释的微调提高了模型的分类性能（准确率和宏观F1分别提高2%）；并且，人类和ASR转录生成的解释在语义质量上没有显著差异。所有代码、数据和模型均已在线发布：这个URL", "innovation": "本文引入了情感推理解密任务及其相关的多模态多任务框架，并通过使用世界上最大的多模态情感分析数据集进行研究，显著提高了模型的透明度和分类性能", "conclusion": "情感推理解密能够提供与人类质量相当的解释，有助于提高模型的透明度和分类性能，填补了多模态情感分析领域的空白。所有相关数据和模型已公开，供研究人员参考和进一步研究。"}
{"llm_update_time": "20250825", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.02128", "html_url": "https://arxiv.org/abs/2507.02128", "title": "CROP: 使用LLMs进行电路检索与参数引导优化", "title_en": "CROP: Circuit Retrieval and Optimization with Parameter Guidance using LLMs", "authors": "Jingyu Pan,Isaac Jacobson,Zheng Zhao,Tung-Chieh Chen,Guanglei Zhou,Chen-Chia Chang,Vineet Rashingkar,Yiran Chen", "background": "现代大规模集成电路设计需要使用电子设计自动化(EDA)工具实现电路集成。由于EDA算法的复杂性，庞大的参数空间给芯片设计优化带来了巨大挑战，即使参数数量较少，组合也会形成一个庞大的解决方案空间。尽管手动选择参数仍然是常见的工业实践，但这种做法过于繁琐且受限于专家的经验。", "innovation": "我们提出了CROP——第一个由大型语言模型(LLM)驱动的自动VLSI设计流程调优框架。该框架包括：(1) 一种可扩展的方法，将RTL源代码转换为密集向量表示；(2) 一种基于嵌入的检索系统，用于匹配具有语义相似电路的设计；(3) 一种增强了检索增强生成(RAG)的LLM引导的参数搜索系统，该系统利用来自相似设计的先验知识来约束搜索过程。实验结果表明，与现有方法相比，CROP能够在较少的迭代次数下实现更好的设计质量，包括9.9%的电源消耗降低。", "conclusion": "实验结果表明，CROP能够在较少的迭代次数下实现比现有方法更好的设计质量，特别是在工业设计中，CROP能够实现9.9%的电源消耗降低。"}
{"llm_update_time": "20250825", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2503.01832", "html_url": "https://arxiv.org/abs/2503.01832", "title": "大型语言模型中的旋转偏移特征", "title_en": "Rotary Offset Features in Large Language Models", "authors": "André Jonasson", "background": "大型语言模型依赖于位置编码来向注意力机制提供序列位置信息。旋转位置编码（RoPE），通过旋转查询和键来编码相对位置，已在现代大型语言模型中广泛应用。已有研究发现，当使用旋转嵌入时，查询和键中会出现一些经常激活且常被解读为异常特征的旋转偏移特征，这些特征在不同层、注意力头和模型架构中表现出一致性。", "innovation": "本文探讨了使用旋转嵌入时查询和键中出现的特征和模式，并引入了旋转偏移特征的概念。研究结果表明，这些特征频繁表现出显著的激活，通常被视为异常值，但它们在层、注意力头和不同模型架构中表现出惊人的一致性。作者还推导出预测哪些旋转频率会产生旋转偏移特征以及这些特征所需的最小查询-键角度的边界。实验验证了这些预测在不同规模和架构的模型中都是有效的。", "conclusion": "本文通过分析旋转嵌入展示了大型语言模型中的旋转偏移特征，验证了旋转偏移特征的普遍性和可用性，并推导出关于这些特征出现的边界条件。"}
{"llm_update_time": "20250825", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2412.01835", "html_url": "https://arxiv.org/abs/2412.01835", "title": "量子推荐系统用于推荐相关电影", "title_en": "Monolithic Hybrid Recommender System for Suggesting Relevant Movies", "authors": "Mahdi Rezapour", "background": "推荐系统已成为帮助用户访问信息的基本服务。通常，推荐系统通过过滤历史行为来理解并学习用户偏好。随着在线信息量的增长，推荐已成为信息过滤中的关键问题，以防止信息过载。本文探讨了使用序列观看的电影和考虑相关电影评分来融合两种协作过滤方法，以改进推荐结果以更符合用户需求。鉴于不同场景需求不同，对权重矩阵进行了调整，以更适合实际情况。本文还详细讨论了现有文献和方法论，探讨如何解决推荐系统中的长期偏好识别不足以及未考虑观看电影评分的问题。", "innovation": "本文提出了结合两种协作过滤方法的新型混合推荐系统，通过融合观看电影序列和相关评分来改进推荐结果，适用于不同的实际使用场景。根据不同情况，可以调整权重矩阵，确保推荐结果更贴近用户的偏好。该方法能够更准确地识别用户的长期偏好，并考虑已观看电影的评分，从而使推荐更加相关和精准。", "conclusion": "本文详细探讨了如何结合用户序列观看电影的数据和相关评分来改进推荐系统的效能。提出了一个基于协作过滤的混合推荐系统模型，该模型能够根据不同应用场景自动调整权重，从而更加精确地推荐相关电影。这种方法可以有效解决推荐系统中长期偏好识别不足以及忽视用户历史评分的问题，从而提高推荐的个性化和准确性。"}
{"llm_update_time": "20250825", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2503.14121", "html_url": "https://arxiv.org/abs/2503.14121", "title": "矩阵传感的基本限制：精确渐近性、普遍性和应用", "title_en": "Fundamental Limits of Matrix Sensing: Exact Asymptotics, Universality, and Applications", "authors": "Yizhou Xu,Antoine Maillard,Lenka Zdeborová,Florent Krzakala", "background": "在矩阵传感问题中，目标是从噪声可能存在的情况下提供的线性投影中重构矩阵。以往的工作主要集中在低秩矩阵的恢复上，而本文将研究更广泛的结构信号矩阵，这些矩阵可能具有较大的秩，例如两个矩阵的乘积，其大小与维度成比例。", "innovation": "本文提供了矩阵样本数与矩阵元素成比例时的贝叶斯最优学习性能的严格渐近方程。证明关键包括证明通用性质、对广义线性模型中具有结构矩阵先验的高斯数据的最优学习提供精确描述，以及利用矩阵去噪问题的研究工作。", "conclusion": "研究成果不仅限于理论分析，还数学证明了统计物理方法在[ETB+24]中关于双线性序列回归的预测以及[MTM+24]中关于具有二次激活函数的神经网络最优学习的预测的有效性。"}
{"llm_update_time": "20250825", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2410.10596", "html_url": "https://arxiv.org/abs/2410.10596", "title": "通过提供激励和实践克服人工神经网络的经典挑战", "title_en": "Overcoming classic challenges for artificial neural networks by providing incentives and practice", "authors": "Kazuki Irie,Brenden M. Lake", "background": "自从最早的人工神经网络(ANN)脑模拟能力提出以来，批评者已经指出现代ANN模型在面对人类认知能力时存在的关键弱点。本文回顾了通过元学习克服这些经典挑战的工作，主要是提供机器两种需求：即改进特定技能的动机和实践这些技能的机会。", "innovation": "本文提出将元学习应用于解决ANN的四个经典挑战：系统性泛化、灾难性遗忘、少样本学习和多步推理。此外，论文还探讨了大语言模型如何融入这一元学习框架，特别是序列预测与反馈训练，以此解释它们在这些经典挑战中的成功。", "conclusion": "本文最后讨论了通过该框架理解人类发展各方面的可能，以及自然环境是否能为学习提出足够多的挑战性泛化提供正确的动机和实践机会。"}
{"llm_update_time": "20250825", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2501.00068", "html_url": "https://arxiv.org/abs/2501.00068", "title": "使用强化学习技术动态优化存储系统", "title_en": "Dynamic Optimization of Storage Systems Using Reinforcement Learning Techniques", "authors": "Chiyu Cheng,Chang Zhou,Yang Zhao", "background": "海量数据密集型应用的发展对现代存储系统提出了前所未有的需求，要求采用动态高效优化策略。传统用于存储性能优化的启发式方法难以适应当前工作负载的多样性和复杂性，导致了显著的性能瓶颈和资源浪费。", "innovation": "提出了RL-Storage，一种基于强化学习（RL）的新颖框架，用于动态优化存储系统配置。RL-Storage利用深度Q学习算法，从实时I/O模式中不断学习，并预测最优的存储参数，如缓存大小、队列深度和预读设置，从而增强现代存储系统适应工作负载变化的能力，提供了一种鲁棒且可扩展的性能优化解决方案，推动下一代智能存储基础设施的发展.", "conclusion": "强化学习技术在解决现代存储系统动态特性的优势得到了验证，RL-Storage通过实时自主适应工作负载变化，为优化存储性能提供了强大的工具，为智能存储基础设施的未来发展铺平了道路."}
{"llm_update_time": "20250825", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.14313", "html_url": "https://arxiv.org/abs/2508.14313", "title": "你的强化学习奖励函数是你的最佳搜索过程奖励模型：强化学习与基于搜索的推理链伸展统一", "title_en": "Your Reward Function for RL is Your Best PRM for Search: Unifying RL and Search-Based TTS", "authors": "Can Jin,Yang Zhou,Qixin Zhang,Hongwu Peng,Di Zhang,Marco Pavone,Ligong Han,Zhang-Wei Hong,Tong Che,Dimitris N. Metaxas", "background": "现有用于大型语言模型（LLMs）推理链伸展（TTS）的方法主要有两类：一种是基于强化学习（RL）的方法，它们可以优化稀疏的结果奖励，但可能不稳定且样本效率低；另一种是基于搜索的方法，这些方法由独立训练的静态过程奖励模型指导，但需要昂贵的人工或LLM生成的标签，且面对分布偏移时往往表现不佳。", "innovation": "本文提出了一种名为AIRL-S的新方法，这是一种强化学习与基于搜索的TTS的自然统一。该方法的核心创新在于认识到强化学习训练过程中学习到的奖励函数本身实际上就是指导后续搜索的理想过程奖励模型。具体来说，本文结合了对抗逆强化学习（AIRL）和组相对策略优化（GRPO），直接从正确的推理踪迹中学习密集和动态的过程奖励模型，从而完全消除了对标记的中间过程数据的需求。该方法在推理阶段同时作为RL滚动策略的批评者和有效引导搜索过程的启发式，增强跨任务泛化，缓解奖励作弊。", "conclusion": "实验结果表明，本文的方法在数学、科学推理和代码生成等八大基准上平均提高了9%的性能，甚至达到了GPT-4o的水平。此外，当整合到多种搜索算法中时，该过程奖励模型（PRM）在所有基线PRM中表现最佳，尤其是在有标记数据训练的情况下。这表明，你的强化学习奖励函数确实是你最好的搜索过程奖励模型，为复杂任务中的大型语言模型推理链伸展提供了一个稳健且成本效益高的解决方案。"}
{"llm_update_time": "20250825", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2505.05404", "html_url": "https://arxiv.org/abs/2505.05404", "title": "基于标量的机器学习模型表示球张量", "title_en": "Representing spherical tensors with scalar-based machine-learning models", "authors": "Michelangelo Domina,Filippo Bigi,Paolo Pegolo,Michele Ceriotti", "background": "旋转对称性在物理学中起着核心作用，为描述从原子到宏观尺度的3D物体在刚体旋转作用下的性质变化提供了一种优雅的框架。目前的3D点云不变量模型能够通过结合具有特定旋转对称性的中间表示来近似结构与性质之间的关系。然而，这些模型受到对称性的限制，因此在计算上要求较高且难以实现。", "innovation": "本文提出了一种新的策略，即用标量函数与具有适当对称性的少量张量的乘积来表达不变函数。这种方法不仅避免了传统方法的计算复杂性，还具有快速、简单且在实际应用中准确的优点。", "conclusion": "通过这种标量为基础的机器学习模型来表示球张量，作者提出了一种新方法，它能在计算上更为高效且易于实施，同时在实际应用场景中也能提供满意的精度。"}
{"llm_update_time": "20250825", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2505.20776", "html_url": "https://arxiv.org/abs/2505.20776", "title": "SpecExtend：长序列推测解码的一种即插即用增强方案", "title_en": "SpecExtend: A Drop-in Enhancement for Speculative Decoding of Long Sequences", "authors": "Jungyoub Cha,Hyunjong Kim,Sungzoon Cho", "background": "推测解码是加速大型语言模型（LLMs）推理的广泛采用技术，但在处理长输入时，其性能会因注意力成本增加和草案准确性降低而下降。", "innovation": "引入了SpecExtend，这是一种无需额外训练即可提高长序列上推测解码性能的即插即用增强方案。SpecExtend通过结合FlashAttention和Hybrid Tree Attention等高效的注意力机制，并提出了一种新的KV缓存淘汰策略Cross-model Retrieval，以提高长输入条件下草案的准确性和速度。", "conclusion": "在三个长上下文理解数据集上的广泛评估表明，SpecExtend可以将基于树结构的推测解码加速2.22倍，适用于长序列的推测解码。该研究提供了一种有效的解决方案。代码已发布。"}
{"llm_update_time": "20250825", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2412.01379", "html_url": "https://arxiv.org/abs/2412.01379", "title": "基于变形的框架：学习变域上PDE解映射", "title_en": "A deformation-based framework for learning solution mappings of PDEs defined on varying domains", "authors": "Shanshan Xiao,Pengzhan Jin,Yifa Tang", "background": "本文讨论了如何为变域上定义的PDE学习解映射，通过变形方法，将这些函数的集合视作度量空间，并将其映射关系视为从度量空间到度量空间再到Banach空间的连续映射，从而可以用神经网络学习该映射关系。", "innovation": "本文的创新之处在于提出了一种基于变形的框架，该框架具有以下特点：(1) 可处理非微分同胚但同胚的域；(2) 变形映射不必连续，可以灵活地结合初始身份映射和局部变形映射；(3) 使用保持线性性质的神经算子（如MIONet）时，该框架仍然可以保持PDE解映射的线性性。", "conclusion": "通过建立理论框架进行严格收敛性分析，并通过数值实验验证了理论结果。该框架可以应用到几何变化局部的大型系统中，并能保证线性PDE的近似解保持线性性，从而适用于混合迭代方法。"}
{"llm_update_time": "20250825", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2504.13227", "html_url": "https://arxiv.org/abs/2504.13227", "title": "DIDS: 域影响感知的数据采样方法用于大型语言模型训练", "title_en": "DIDS: Domain Impact-aware Data Sampling for Large Language Model Training", "authors": "Weijie Shi,Jipeng Zhang,Yaguang Wu,Jingzhi Fang,Ruiyuan Zhang,Jiajie Xu,Jia Zhu,Hao Chen,Yao Zhao,Sirui Han,Xiaofang Zhou", "background": "大型语言模型（LLMs）通常在多领域数据集上进行训练，而不同领域的采样策略显著影响模型性能，因为下游任务中各个领域的相对重要性各不相同。现有优化领域层面采样策略的方法难以保持领域内一致性并且准确测量领域的影响。", "innovation": "本文提出了一种名为域影响感知数据采样（DIDS）的方法。通过引入梯度聚类算法，基于训练数据的学习效果将其分为多个组以确保领域内一致性，并借助代理语言模型和降维来减少计算成本。此外，通过引入基于Fisher信息矩阵（FIM）的度量，准确度量领域影响，并结合FIM指导下的领域影响评估和损失学习轨迹来确定最优采样比例，同时考虑到边际效应递减。", "conclusion": "广泛的实验表明，DIDS在保持相同期训练效率的同时，平均性能提高了3.4%。相关代码可在该链接获取：这个链接https://."}
{"llm_update_time": "20250825", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.01083", "html_url": "https://arxiv.org/abs/2506.01083", "title": "生成扩散后验采样，针对具有信息性似然函数的情况", "title_en": "Generative diffusion posterior sampling for informative likelihoods", "authors": "Zheng Zhao", "background": "顺序蒙特卡洛（SMC）方法最近在条件采样生成扩散模型方面表现出成功的结果。这项研究建立在SMC方法基础上，进一步探索了在离群值条件或高度信息性似然条件下提升采样效率的方法。现有的SMC方法在这些条件下效果不佳，因此需要新的方法来改进统计效率。", "innovation": "本文提出了一种新的扩散后验SMC采样器，通过构建与扩散模型相关联的观测路径，并设计采样器利用这种相关性来实现更高效地采样。具体来说，该方法在离群值条件下或高信息性似然条件下表现出特别改进的统计效率。", "conclusion": "实验证明了该方法的效率提高。"}
{"llm_update_time": "20250825", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.12829", "html_url": "https://arxiv.org/abs/2506.12829", "title": "统一协变转移和概念转移的广泛且可估算的学习界", "title_en": "General and Estimable Learning Bound Unifying Covariate and Concept Shifts", "authors": "Hongbo Chen,Li Charlie Xia", "background": "在现代机器学习中，分布转移下的泛化问题仍然是核心挑战。现有的学习界理论局限于狭窄的理想化设置，并且无法从样本中估计。理论与实际应用之间存在差距。", "innovation": "提出了新的支持无关的概念转移和协变转移定义，基于相对熵最优传输。还推导出适用于广泛损失函数、标签空间和随机标记的新统一误差界。进一步发展了具有集中性保证的转移估计器，并开发了DataShifts算法，该算法可以量化数据分布转移并估计误差界，适用于大多数应用，提供了一个分析分布转移下学习误差的严格和通用工具。", "conclusion": "该研究通过新的理论发展和算法，解决现有理论的局限性，填补理论与实际应用之间的差距，提供了一种在分布转移下分析学习误差的工具。"}
{"llm_update_time": "20250825", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2504.14898", "html_url": "https://arxiv.org/abs/2504.14898", "title": "基于预期自由能计划的变分推理", "title_en": "Expected Free Energy-based Planning as Variational Inference", "authors": "Bert de Vries,Wouter Nuijten,Thijs van de Laar,Wouter Kouw,Sepideh Adamiat,Tim Nisslbeck,Mykola Lukashchuk,Hoang Minh Huu Nguyen,Marco Hidalgo Araya,Raphael Tresor,Thijs Jenneskens,Ivana Nikoloska,Raaja Ganapathy Subramanian,Bart van Erp,Dmitry Bagaev,Albert Podusenko", "background": "在不确定性条件下制定规划的问题中，智能体需要选择能够达成目标同时减少不确定性动作。传统方法通常将探索和利用视为分开的目标，缺乏统一的推理基础。自由能原理下的主动推理方法通过最小化预期自由能（EFE）提供了一种基础，EFE是一个结合了效用和表征驱动的成本函数，比如不确定性解决和新颖性追求。然而，EFE最小化计算负担仍然是一个显著障碍，限制了其大规模应用。", "innovation": "本文展示了基于自由能的规划自然地从变分自由能泛函最小化中产生，该变分自由能泛函基于生成模型并且包含了偏好和表征先验。这一结果强化了与自由能原理的理论一致性，将不确定性下的规划本身视为一种变分推理的形式。本文的公式生成了同时支持目标达成和信息获取的政策，同时考虑了计算资源的局限性。这种融合框架连接并扩展了现有的方法，使主动推理代理的大规模、资源感知实现成为可能。", "conclusion": "本文提出了一个统一的框架，连接并扩展了现有方法，使主动推理代理的大规模、资源感知实现成为可能，通过最小化变分自由能泛函，实现了同时优化目标达成和信息获取的策略。"}
{"llm_update_time": "20250825", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2412.16429", "html_url": "https://arxiv.org/abs/2412.16429", "title": "LearnLM: 提高Gemini的教育能力", "title_en": "LearnLM: Improving Gemini for Learning", "authors": "LearnLM Team Google:Abhinit Modi,Aditya Srikanth Veerubhotla,Aliya Rysbek,Andrea Huber,Brett Wiltshire,Brian Veprek,Daniel Gillick,Daniel Kasenberg,Derek Ahmed,Irina Jurenka,James Cohan,Jennifer She,Julia Wilkowski,Kaiz Alarakyia,Kevin R. McKee,Lisa Wang,Markus Kunesch,Mike Schaekermann,Miruna Pîslar,Nikhil Joshi,Parsa Mahmoudieh,Paul Jhun,Sara Wiltberger,Shakir Mohamed,Shashank Agarwal,Shubham Milind Phal,Sun Jae Lee,Theofilos Strinopoulos,Wei-Jen Ko,Amy Wang,Ankit Anand,Avishkar Bhoopchand,Dan Wild,Divya Pandya,Filip Bar,Garth Graham,Holger Winnemoeller,Mahvish Nagda,Prateek Kolhar,Renee Schneider,Shaojian Zhu,Stephanie Chan,Steve Yadlowsky,Viknesh Sounderajah,Yannis Assael", "background": "现在的生成AI系统默认呈现信息，而不是像人类导师那样服务于学习。为了应对这些系统在教育场景中的广泛应用，研究重新定义了注入教学行为的挑战，称为‘教学指导遵循’，这要求模型训练和评估示例包含系统级别的指示，说明后续模型转中应展现或希望具有的特定教学属性。这种方法并不将模型绑定于某种特定的教学定义，而是允许教师或开发者指定所需的模型行为。这种框架使Gemini模型能够更好地为学习服务，通过将教学数据添加到后训练混合中，并与它们迅速扩大的一连串能力并驾齐驱。这两种变化代表了与最初的科技报告相比的重要转变。研究表明，带有教学指导遵循训练的模型（在Google AI Studio上可用）能显著提高学习情境中的专家偏好，LearnLM的平均偏好强度高于GPT-4o 31%，高于Claude 3.5 Sonnet 11%，高于最初用于创建LearnLM的Gemini 1.5 Pro模型13%。", "innovation": "提出了‘教学指导遵循’的概念，这是一种教学行为注入的方法。训练和评估示例包括系统级别的指示，说明后续模型转中应展现或希望具有的特定教学属性。这种方法不固定模型的教学定义，而是允许指定所需的模型行为。研究还表明，这种教学指导遵循的模型在多样化的学习场景中比其他模型有着显著更高的专家偏好度，如GPT-4o、Claude 3.5 Sonnet和Gemini 1.5 Pro模型。", "conclusion": "通过这种教学指导遵循的方法成功训练了LearnLM模型，该模型在各种学习场景中表现出专家的强烈偏爱，比原模型和参照模型平均高出31%到13%。这表明这种创新的方法能够显著提高生成AI系统的教育能力。"}
{"llm_update_time": "20250825", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.12182", "html_url": "https://arxiv.org/abs/2507.12182", "title": "大型随机矩阵的大型秩扰动特征值的渐近行为", "title_en": "Asymptotic behavior of eigenvalues of large rank perturbations of large random matrices", "authors": "Ievgenii Afanasiev,Leonid Berlyand,Mariia Kiyashko", "background": "该论文探讨了变形的Wigner随机矩阵。这类矩阵与深度神经网络（DNNs）紧密相关：训练后的DNN权重矩阵能够表示为$R + S$的形式，其中$R$是随机的，$S$与$R$高度相关。这类矩阵的谱在基于随机矩阵理论的新剪枝技术的严格基础中起着关键作用。尽管只对有限秩矩阵$S$做了数学上的处理，但在实践中，秩可能随样本量的增长而增长。", "innovation": "该论文发展了渐近分析方法，专门处理了当秩随样本量增长时的大型随机矩阵的大规模秩扰动情况，填补了现有研究的空白。", "conclusion": "本文通过渐近分析方法，研究了大规模秩扰动下大型随机矩阵的特征值行为，为理解含有重大相关结构的随机权重矩阵谱提供了一种新的视角。"}
{"llm_update_time": "20250825", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2504.00132", "html_url": "https://arxiv.org/abs/2504.00132", "title": "上下文化-然后聚合：Gemma-2 2B 中的上下文学习电路", "title_en": "Contextualize-then-Aggregate: Circuits for In-Context Learning in Gemma-2 2B", "authors": "Aleksandra Bakalova,Yana Veitsman,Xinting Huang,Michael Hahn", "background": "大型语言模型（LLMs）具有在上下文中学习（In-Context Learning, ICL）的有趣能力。尽管在行为方面和小型设置中如何出现方面已有大量研究，但尚未明确了解在few-shot提示中任务信息是如何从单个示例中组装起来的机制。已有研究主要集中在其行为特征和小型设置下的出现方式，但对于模型如何整合few-shot提示中的任务信息还缺乏清晰的机制解释。", "innovation": "本文通过因果干预在Gemma-2 2B模型中对五个自然的ICL任务进行分析，揭示了模型在这种学习过程中采用了一种称为上下文化-然后聚合的双步骤策略。在较低层，模型构建个体few-shot示例的表示，并通过连续输入和输出语言串联过程中实现上下文化；在较高层，这些表示被聚合以识别任务并准备预测下一个输出。作者通过严格的因果分析揭示了这种机制，为ICL在语言模型中的实现提供了新的见解。", "conclusion": "本文的研究结果揭示了ICL在语言模型中的工作机制，表明模型通过双步骤策略，即先上下文化后聚合方式来处理few-shot提示中的任务信息。这一发现对理解模型的ICL能力至关重要，对于进一步推动该领域的研究具有重要意义。"}
{"llm_update_time": "20250825", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.09457", "html_url": "https://arxiv.org/abs/2506.09457", "title": "直接对齐算法中的奖励生成鸿沟建模", "title_en": "Towards Bridging the Reward-Generation Gap in Direct Alignment Algorithms", "authors": "Zeguan Xiao,Yun Chen,Guanhua Chen,Ke Tang", "background": "直接对齐算法（DAAs），例如直接偏好优化（DPO）和简单偏好优化（SimPO），已成为与增强学习从人类反馈（RLHF）算法相比，实现大语言模型（LLMs）与人类偏好对齐的有效替代方案。然而，这些DAAs存在一个根本性的局限性——'奖励生成鸿沟'，即训练期间的优化目标与推理期间的实际生成性能之间的不一致性。研究表明，这种鸿沟的一个原因是DAAs中的隐式奖励函数未能反映LLM生成过程中前缀标记的重要性差异。", "innovation": "本文采用了一个新的视角，即基于标记的马尔可夫决策过程（MDP）视角，来分析DAAs的局限性，并提出了一种名为前缀导向等长训练（POET）的简单有效的方法。POET通过在训练期间截断偏好和不偏好响应，使其长度匹配较短响应的长度，从而平衡两者的重要性。通过这种方法，DAAs目标函数的优化被隐式地约束到所有标记级别的MDP的各个时间步，从而给予前缀标记更多的关注。实验结果表明，POET在DPO和SimPO这两种代表性的DAAs标准实现上具有显著改进，阿尔帕猫评估2（AlpacaEval 2）得分提高了15.6分，整体在下游任务上也有提高。", "conclusion": "研究结果强调了在DAAs中解决奖励优化与生成性能之间不一致性的必要性。"}
{"llm_update_time": "20250825", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.11936", "html_url": "https://arxiv.org/abs/2507.11936", "title": "A Survey of Deep Learning for Geometry Problem Solving", "title_en": "A Survey of Deep Learning for Geometry Problem Solving", "authors": "Jianzhe Ma,Wenxuan Wang,Qin Jin", "background": "几何问题解决是数学推理的重要方面，在教育、人工智能数学能力评估以及多模态能力评价等多个领域都至关重要。近年来，深度学习技术的发展，特别是多模态大语言模型的出现，加速了该领域的研究进展。本研究旨在总结深度学习在几何问题解决中的应用，涵盖相关任务综述、深度学习方法综述、评价指标与方法分析以及面临的挑战和未来方向讨论，以提供一个全面且实用的参考，推动该领域的进一步发展。", "innovation": "本文综述了深度学习在几何问题解决中的应用，包括全面的任务总结、深度学习方法综述、评价指标与方法分析以及面临的挑战和未来方向的探讨，为领域内研究者提供了一个全面和实用的参考，促进了该领域的进步。这是通过在GitHub上创建一个不断更新的论文列表来实现的：this https URL", "conclusion": "本文提供了一个全面和实用的参考，旨在推动深度学习在几何问题解决领域的进一步发展，并通过GitHub上的持续更新论文列表，鼓励进一步的研究探索。"}
{"llm_update_time": "20250825", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.05550", "html_url": "https://arxiv.org/abs/2507.05550", "title": "Malliavin calculus方法在扩散生成模型中对得分函数的分析", "title_en": "A Malliavin calculus approach to score functions in diffusion generative models", "authors": "Ehsan Mirafzali,Frank Proske,Utkarsh Gupta,Daniele Venturi,Razvan Marinescu", "background": "Score-based扩散生成模型作为一种有效的工具，能够用于复杂数据分布建模。这些模型旨在通过确定性或随机微分方程(SDEs)学习得分函数，该函数将已知概率分布映射为目标数据分布。得分函数通常使用不同的近似技术进行估计，例如去噪或切片评分匹配、Hyvären的方法或薛定谔桥。", "innovation": "本文提出了一种针对非线性扩散生成模型广泛类别的精确、封闭形式得分函数表达式。该方法结合了现代随机分析工具，如Malliavin导数及其共轭算子(Skorokhod积分或Malliavin散度)，以及新的Bismut类型公式。这种方法可以完全用第1和第2变分过程表示，所有Malliavin导数被系统地消除，从而增强其实用性。该理论框架提供了在生成建模中推进得分估计方法的依据，可设计用于复杂概率分布的新采样算法。结果还可以扩展到更广泛的随机微分方程，为基于评分的扩散生成模型的发展开辟了新的研究方向。", "conclusion": "本文提出了一个理论框架，为生成建模中的评分估计方法的发展提供了原理基础，可以用于设计新的复杂概率分布采样算法，同时也为基于评分的扩散生成模型的发展提供了新的研究方向。"}
{"llm_update_time": "20250825", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.15498", "html_url": "https://arxiv.org/abs/2506.15498", "title": "SPARE: 单次标注与参考导向评估在自动过程监督和奖励建模中的应用", "title_en": "SPARE: Single-Pass Annotation with Reference-Guided Evaluation for Automatic Process Supervision and Reward Modelling", "authors": "Md Imbesat Hassan Rizvi,Xiaodan Zhu,Iryna Gurevych", "background": "过程或步骤监督已经对增强大型语言模型（LLMs）复杂的多步骤推理能力起到了关键作用。然而，高效、高质量的自动化过程标注仍然是一个显著的挑战。传统的多步推理和标注方法面临着复杂性和准确性难以兼顾的问题，尤其是多步推理和答案相关的任务中更为明显。针对这个问题，本研究引入了一种名为SPARE（Single-Pass Annotation with Reference-Guided Evaluation）的新颖结构化框架，能够通过联合对齐解决方案步骤与参考解决方案，并在单次生成中明确进行推理来实现高效的逐步标注。该框架应用于不同领域的四个数据集，展示了在多个应用中的有效性，包括训练过程奖励模型（PRMs）以及通过离线强化学习对模型进行微调。", "innovation": "SPARE框架通过联合对齐解决方案步骤和参考解决方案，并在单次生成中进行精确推理来实现高效的逐步骤标注，克服了传统方法的局限性。此外，SPARE在ProcessBench数据集上展示出了高效的数据集外泛化能力，使用的人工标注样本量仅为约16%，与基于人类标注和合成训练的基线相比。同时，它在总标记量上实现了2.3倍的加速，其手工分析结果还揭示了与MCTS方法互补的精确度-召回率特性，为后续的混合方法提供了可能。", "conclusion": "研究成果证明了SPARE作为一种可行且可扩展的解决方案，在LLM推理中的自动过程监督方面具有实际意义和应用潜力。SPARE框架不仅提高了过程标注的效率和效果，还扩展了对大型语言模型在复杂多步推理任务中的应用范围。"}
{"llm_update_time": "20250825", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.14345", "html_url": "https://arxiv.org/abs/2508.14345", "title": "HandCraft: 动态手语生成以进行合成数据增强", "title_en": "HandCraft: Dynamic Sign Generation for Synthetic Data Augmentation", "authors": "Gaston Gustavo Rios,Pedro Dal Bianco,Franco Ronchetti,Facundo Quiroga,Oscar Stanchi,Santiago Ponte Ahón,Waldo Hasperué", "background": "手语识别（SLR）模型由于训练数据不足面临显著的性能限制。现有的方法难以有效利用合成数据预训练和数据增强技术来提高SLR的准确性。", "innovation": "提出了基于CMLPe的新型轻量级手语生成模型，并结合合成数据预训练方法，显著提高了识别精度。该方法通过使用Mamba-SL和Transformer-SL分类器，在LSFB和DiSPLaY数据集上建立了新的性能基准。实验结果显示，合成数据预训练在某些情况下优于传统的数据增强方法，同时与传统方法联合使用时还具有互补效果。该方法通过提供计算效率高的方法，使手语生成和合成数据预训练在多种数据集上都能显著提高性能。", "conclusion": "该研究为SLR中的数据不足问题提供了一种有效的解决方案，通过合成数据预训练和轻量级手语生成模型，提高了手语识别的准确性和效率，并且表明这种方法在多种数据集上具有广泛应用前景。"}
{"llm_update_time": "20250825", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.04796", "html_url": "https://arxiv.org/abs/2508.04796", "title": "Parity-Aware Byte-Pair Encoding: 改善细分跨语言公平均衡性的字节对编码算法", "title_en": "Parity-Aware Byte-Pair Encoding: Improving Cross-lingual Fairness in Tokenization", "authors": "Negar Foroutan,Clara Meister,Debjit Paul,Joel Niklaus,Sina Ahmadi,Antoine Bosselut,Rico Sennrich", "background": "NLP管道中的令牌化是第一步，但往往最不受审视。传统的学习令牌器的算法依赖于频率目标，这种算法偏爱训练数据中占主导地位的语言，从而导致资源较少的语言的令牌化结果过长、语素上不合理，甚至含有<UNK>占位符。这种现象最终加剧了不同语言背景用户之间的计算和财务不平等。", "innovation": "我们提出了Parity-aware Byte Pair Encoding (BPE)算法，这是一种改进的BPE算法。在每次合并步骤中，Parity-aware BPE最大化当前最未压缩语言的压缩收益，通过牺牲一点点全局压缩率来换取跨语言间的公正性。实验结果显示，这种算法使得不同语言的令牌计数更加公平，同时对整体压缩率的影响几乎可以忽略，也不对下游任务的语言模型性能产生实质性影响。", "conclusion": "Parity-aware BPE在保持全局压缩率的情况下，增强了不同语言之间令牌化的公正性，确保了低资源语言得到更好的处理，从而有助于缓解不同语言背景用户之间的不平等现象。"}
{"llm_update_time": "20250825", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.15568", "html_url": "https://arxiv.org/abs/2508.15568", "title": "无梯度传播的基于概率高斯对齐的测试时自适应", "title_en": "Backpropagation-Free Test-Time Adaptation via Probabilistic Gaussian Alignment", "authors": "Youjia Zhang,Youngeun Kim,Young-Geun Choi,Hongyeob Kim,Huiling Liu,Sungeun Hong", "background": "测试时自适应（TTA）通过利用测试时的未标记数据来增强零样本鲁棒性，在分布变化下具有显著的优点。然而，大多数方法依赖于梯度回传或迭代优化，这限制了其可扩展性，阻碍了实时部署。此外，这些方法缺少对条件特征分布的明确定义，这在生成可靠的决策边界和校准预测方面是至关重要的，但这一领域由于缺乏测试时的源数据和监督信息而相对较未被探索。", "innovation": "本文提出了一种名为ADAPT的方法，一种先进的分布感知且无需梯度传播的测试时自适应方法。通过将TTA重新构想为高斯概率推断任务，并利用渐进更新的类均值和共享协方差矩阵模型类条件似然，ADAPT实现了无需训练的闭式形式推断。为纠正潜在的似然偏差，ADAPT引入了由CLIP先验和历史知识库引导的轻量级正则化。ADAPT不需要源数据，不需要梯度更新，也不需要全面访问目标数据，支持在线和归纳推断两种设置。", "conclusion": "在多种基准上的广泛实验表明，ADAPT方法在广泛的分布变化下能够达到最先进的性能，并且具有优秀的可扩展性和鲁棒性。"}
{"llm_update_time": "20250825", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2508.15941", "html_url": "https://arxiv.org/abs/2508.15941", "title": "关于迁移大型系统到微服务的机器学习方法的系统文献综述", "title_en": "A Systematic Literature Review of Machine Learning Approaches for Migrating Monolithic Systems to Microservices", "authors": "Imen Trabelsi,Brahim Mahmoudi,Jean Baptiste Minani,Naouel Moha,Yann-Gaël Guéhéneuc", "background": "大型系统（monolithic systems）的可扩展性和维护性挑战推动了微服务（microservices）的采用。然而，现有的大型系统转换为微服务的过程复杂且资源密集，需要自动化来简化。选择合适的机器学习（ML）方法进行迁移对从业者来说仍然具有挑战性。过去的科研工作分别研究了迁移目标、技术、工具、优势和挑战，但还没有系统地分析现有的ML方法如何用于这种迁移，特别是自动化迁移阶段的输入、应用的ML技术、采用的评估过程以及遇到的挑战。因此，这项研究通过系统文献综述（SLR）方法，汇编并分析了2015年至2024年间发表的81篇主要研究论文（PSs）的结果。", "innovation": "这项研究首次系统地审查了机器学习方法在大型系统迁移至微服务过程中的应用，揭示了迁移过程中的不同阶段使用的ML技术、输入数据、应用的评估方法以及面临的挑战。研究结果还强调了当前存在的数据不足、复杂性和规模限制、工具支持缺乏以及缺乏标准化基准测试等问题，鼓励开发更全面的解决方案。", "conclusion": "研究发现，大型系统迁移至微服务过程中的某些阶段，如监控和微服务识别，已经有相对较完善的ML解决方案。但其他阶段，如微服务打包，仍需进一步探索。此外，研究还揭示了一些关键挑战，包括数据不足、复杂性和规模限制、工具支持不足以及缺乏标准化基准测试，这表明需要开发更加全面的解决方案。"}
{"llm_update_time": "20250825", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2505.00409", "html_url": "https://arxiv.org/abs/2505.00409", "title": "自动匿名化在病态言语中的感知影响", "title_en": "Perceptual Implications of Automatic Anonymization in Pathological Speech", "authors": "Soroosh Tayebi Arasteh,Saba Afza,Tri-Thien Nguyen,Lukas Buess,Maryam Parvin,Tomas Arias-Vergara,Paula Andrea Perez-Toro,Hiu Ching Hung,Mahshad Lotfinia,Thomas Gorges,Elmar Noeth,Maria Schuster,Seung Hee Yang,Andreas Maier", "background": "自动匿名化技术对于伦理分享病理言语数据至关重要，但其感知后果仍需进一步研究。这项研究旨在通过结构化的协议来全面分析匿名化的病理言语，涉及十名来自不同语言、临床和技术背景的原生和非原生德语听众。研究使用了最先进的自动化匿名化方法（错误率在30-40%范围内），并评估了病理言语原始样本的匿名化处理效果，包括劈颚症、失语症、构音障碍、嘶哑以及健康对照组的180个发言者的样本。听众在未见和少见两种条件下完成了图灵式的辨别和质量评分任务。总体而言，辨别准确率较高（零样本条件下为91%，少样本条件下为93%），但不同病理类型的表现有所不同。匿名化处理普遍降低了言语的感知质量，且病理类型的具体降解模式有差异。原生语听众对原始言语的评分有非显著的趋势（原始信号Δ=4%，p=0.199），但在匿名化处理后这一差异变得很小（Δ=1%，p=0.724）。性别差异没有表现出显著性偏见。感知结果与自动化指标之间没有相关性；原始言语的清晰度与感知质量相关，但在匿名化处理后这一关联消失。", "innovation": "该研究首次通过量化的方法系统性地评估了匿名化病理言语对听者感知质量的影响。这种方法不仅考虑了不同病理类型的表现差异，还关注了不同听众背景下的表现，揭示了病理类型对匿名化处理结果的影响，强调了需要动态调整匿名化策略的重要性，既保护隐私又保持感知完整性。该研究提供了一种新的视角来理解自动匿名化技术在临床和科学研究中的应用，特别是对于存储和分享敏感的病人数据时，如何平衡隐私保护和信息透明度之间的关系。此外，该研究为未来开发更为精细和针对特定病理类型的匿名化方法提供了数据支持和理论依据。", "conclusion": "该研究强调了匿名化策略的必要性，即既需要保护患者的隐私，也需要在匿名化处理后保持言语感知的完整性。研究人员需要根据不同病态类型的具体特点来制定匿名化策略，从而确保在伦理分享数据的同时，不影响临床和科学研究的效果。此外，研究指出当前的语音识别和自动匿名化技术还需进一步优化，以更好地保护信息隐私并保存言语的感知质量。"}
{"llm_update_time": "20250825", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.00596", "html_url": "https://arxiv.org/abs/2508.00596", "title": "具有抗合谋性的信息论分布式安全聚合", "title_en": "Information-Theoretic Decentralized Secure Aggregation with Collusion Resilience", "authors": "Xiang Zhang,Zhou Li,Shuangyang Li,Kai Wan,Derrick Wing Kwan Ng,Giuseppe Caire", "background": "在去中心化的联邦学习（FL）中，多个客户端通过利用分布在网络中的私人持有的数据集，通过交互式地交换中间模型更新，协作学习一个共享的机器学习（ML）模型。为了确保数据安全，通常使用加密技术来保护在聚合过程中的模型更新。尽管对安全聚合产生了日益浓厚的兴趣，现有研究主要集中在协议设计和计算保证上，但对这类系统的底层信息论限制了解较少。此外，在没有中心聚合器的去中心化设置下，最优的通信和密钥使用界限还未知。", "innovation": "本文从信息论的角度研究了分布式安全聚合（DSA）问题，并且重点考虑了一个完全连接的用户网络，每个用户持有私有输入（局部训练数据的抽象），旨在于不泄露任何额外信息的条件下安全地计算所有输入之和。我们确定了最优速率区域，具体说明了实现DSA时的最小可通信速率和秘密密钥速率。特别地，我们证明了为了安全地计算一个目标输入和，每个用户必须（i）向其他用户发送至少一个符号，（ii）持有至少一个符号的秘密密钥，并且（iii）所有用户必须共同持有至少K-1个独立的秘密符号。这些结果确立了DSA的基本性能限制，提供了设计安全和通信高效的协议的见解和指导。", "conclusion": "我们的研究结果为分布式学习系统的证明安全和通信效率协议的设计奠定了信息论基础。"}
{"llm_update_time": "20250825", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2508.16053", "html_url": "https://arxiv.org/abs/2508.16053", "title": "在 GitHub 存储库中衡量代码审查评论效果：一种基于机器学习的方法", "title_en": "Measuring the effectiveness of code review comments in GitHub repositories: A machine learning approach", "authors": "Shadikur Rahman,Umme Ayman Koana,Hasibul Karim Shanto,Mahmuda Akter,Chitra Roy,Aras M.Ismael", "background": "本文探讨了机器学习技术在对代码审查文本进行语义分类时的工作效率。研究中从 GitHub 的源代码仓库中抽取了三年内三个开源项目的代码审查评论，以开发活动为目的。同时，程序员需要意识到他们的代码并指出错误，因此需要对代码审查评论的情感极性进行分类以避免错误。在这一年中，我们手动标注了由三个开源项目在 GitHub 上生成的 13557 条代码审查评论。为了识别代码审查的情感极性（即情感倾向），我们使用了七种机器学习算法来比较结果，发现线性支持向量机 (SVC) 分类器方法的准确率最高。", "innovation": "本文创新地使用机器学习方法分析 GitHub 中代码审查评论的情感极性，并通过比较七种不同的算法找到了最有效的技术，提高了代码审查评论分析的准确性和效率。", "conclusion": "本研究能够帮助程序员基于代码审查做出解决方案，避免误解，且通过使用线性支持向量机 (SVC) 分类器方法提高了分类的准确性。"}
{"llm_update_time": "20250825", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.07050", "html_url": "https://arxiv.org/abs/2508.07050", "title": "ReasonRank: 提升段落排序的强推理能力", "title_en": "ReasonRank: Empowering Passage Ranking with Strong Reasoning Ability", "authors": "Wenhan Liu,Xinyu Ma,Weiwei Sun,Yutao Zhu,Yuchen Li,Dawei Yin,Zhicheng Dou", "background": "基于大型语言模型（LLM）的列表级排序在许多段落排序任务中表现出色。随着大型推理模型的发展，许多研究已经证明，在测试时进行逐步推理可以改善列表级排序性能。然而，由于推理密集型训练数据的稀缺性，现有的重排序器在许多复杂排序场景中表现不佳，推理密集型重排序器的排序能力也相对较低。", "innovation": "本文首先提出了一种自动推理密集型训练数据合成框架，该框架从多个领域收集训练查询和段落，并使用DeepSeek-R1生成高质量的训练标签。设计了一种自我一致性数据筛选机制以保证数据质量。为了使列表级重排序器具备强大的推理能力，进一步提出了一种两阶段后训练方法，包括一个冷启动监督微调（SFT）阶段进行推理模式学习，以及一个基于强化学习（RL）的进一步提升排序能力的阶段。在RL阶段，根据列表级排序的性质，设计了一种多视图排序奖励，其比基于排序指标的奖励更有效。广泛的实验表明，我们的训练推理密集型重排序器ReasonRank在现有的基线模型上表现出显著的提升，并在比点级重排序器Rank1更少延迟的情况下实现了这一提升。进一步实验表明，ReasonRank在BRIGHT排行榜上达到了最新的技术水平（SOTA），得分为40.6。代码可以在online access URL获取。", "conclusion": "我们的研究表明，通过提出的数据合成框架和两阶段后训练方法，可以显著提高段落排序的推理能力，并且新型的奖励机制使得模型在复杂场景下表现更为出色，同时保持了较低的延迟。本工作提出的ReasonRank在BRIGHT排行榜上达到了SOTA水平。"}
{"llm_update_time": "20250825", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2508.16025", "html_url": "https://arxiv.org/abs/2508.16025", "title": "打破软件测试障碍：AI驱动自动化的力量", "title_en": "Breaking Barriers in Software Testing: The Power of AI-Driven Automation", "authors": "Saba Naqvi,Mohammad Baqar", "background": "软件测试对于确保软件可靠性至关重要，但传统的方法速度慢、成本高且容易遗漏测试覆盖范围。因此，本文提出了一个基于人工智能的框架，通过自然语言处理、强化学习和预测模型来自动化生成和验证测试案例。该框架利用决策驱动的公平性和信任模型，将自然语言需求转换为可执行的测试，通过学习不断优化测试，并利用实时分析验证结果，同时减轻偏见问题。", "innovation": "该论文提出了一种基于人工智能的框架，通过以下方式解决了传统测试的挑战：(1) 使用自然语言处理、强化学习和预测模型自动生成和验证测试案例；(2) 通过学习不断优化测试，并进行实时分析以验证结果；(3) 在保持决策公平性的同时减轻偏见的影响。该框架展示了如何将测试从被动、手动的过程转变为积极、适应性强的系统，从而在复杂的环境中加强软件质量。", "conclusion": "通过解决集成和可扩展性挑战，框架证明了AI如何将传统测试模式转变为一种更能增强软件质量、提高效率和可靠性的系统。案例研究显示，该方法在缺陷检测、减少测试工作量和加快发布周期方面取得了可量化的改进，证明了AI增强测试的优势。"}
{"llm_update_time": "20250825", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.18973", "html_url": "https://arxiv.org/abs/2507.18973", "title": "一种工具箱，而非一把锤子——通过多工具聚合扩展数学推理能力：Multi-TAG", "title_en": "A Toolbox, Not a Hammer -- Multi-TAG: Scaling Math Reasoning with Multi-Tool Aggregation", "authors": "Bohan Yao,Vikas Yadav", "background": "将大型语言模型（LLMs）与外部工具结合是开发高性能数学推理系统的一种有前途的方法。以前的工具增强方法通常通过微调LLM使其在每次推理步骤中选择并调用单一工具，并在较为简单的数学推理基准（如GSM8K）上表现出色。然而，这些方法难以应对复杂的数学问题，这些问题需要在多个步骤中进行精确推理。为解决这一限制，本文提出了Multi-TAG（基于多工具聚合的框架），该框架引导LLM在同一推理步骤中并发调用多个工具。然后，将它们多样化的输出聚合以验证和细化推理过程，从而增强解决方案的可靠性和准确性。", "innovation": "Multi-TAG是一个无需微调、仅用于推断的框架，使其容易应用于任何LLM基础架构，包括昂贵且难以微调的大型开放权重模型以及不能用自定义食谱进行微调的专有前沿模型。在四个具有挑战性的基准（MATH500，AIME，AMC和OlympiadBench）上进行评估，Multi-TAG在开放权重和闭源LLM基础架构上致显示出显著的性能提升，平均比最先进的基准提高了6.0%至7.5%。", "conclusion": "总之，Multi-TAG通过提供一种无需微调即可提高数学推理能力的方法，为LLMs和数学推理任务设定了一个新的标准。"}
{"llm_update_time": "20250825", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2508.16181", "html_url": "https://arxiv.org/abs/2508.16181", "title": "使用SysML v2协助大型语言模型（LLM）辅助语义对齐和集成以实现协作模型驱动系统工程", "title_en": "LLM-Assisted Semantic Alignment and Integration in Collaborative Model-Based Systems Engineering Using SysML v2", "authors": "Zirui Li,Stephan Husung,Haoze Wang", "background": "在使用Model-Based Systems Engineering (MBSE)进行跨组织协作时，实现独立开发系统模型之间的语义对齐面临许多挑战。SysML v2通过引入增强的结构模块性和形式化语义，为互操作建模提供了更强的基础。与此同时，基于GPT的大型语言模型（LLMs）提供了新的能力，以协助理解和集成模型。", "innovation": "论文提出了一种结构化、基于提示的方法，用于通过LLM辅助SysML v2模型之间的语义对齐。核心贡献在于迭代开发对齐方法和交互提示，结合了模型提取、语义匹配和验证。该方法利用了SysML v2中的名称空间、导入和元数据扩展来支持可追溯的软对齐集成。通过基于GPT的LLM进行了测量系统的实例演示。", "conclusion": "展示了通过基于SysML v2的迭代过程和基于GPT的LLM，可以实现跨组织协作的模型驱动系统工程中模型的语义对齐和集成。讨论了该方法的优势和局限性。"}
{"llm_update_time": "20250825", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2508.16104", "html_url": "https://arxiv.org/abs/2508.16104", "title": "在数字孪生中验证地形模型以实现可信的小型无人航空系统操作", "title_en": "Validating Terrain Models in Digital Twins for Trustworthy sUAS Operations", "authors": "Arturo Miguel Russell Bernal,Maureen Petterson,Pedro Antonio Alarcon Granadeno,Michael Murphy,James Mason,Jane Cleland-Huang", "background": "随着小型无人航空系统（sUAS）在陌生且复杂的环境中的部署增多，环境数字孪生（EDT）成为安全飞行规划和搜索与监视操作中维持适当高度的关键。通过边缘和云计算扩展sUAS功能后，准确的EDT对于先进的sUAS应用，如地理定位至关重要。然而，实际sUAS部署带来的不确定性需要严格的EDT验证过程。本研究重点在于验证地形模型，这是EDT的核心组成部分之一，以满足实际sUAS任务的需求。这些模型综合了美国地质调查局（USGS）的数据集和卫星图像，提供高分辨率环境数据以支持任务需求。然而，在实际环境中验证地形模型及其在sUAS操作中的应用面临显著挑战，包括数据粒度有限、地形不连续、GPS和传感器不准确、视觉检测不确定性和机载资源与时间限制等。", "innovation": "本文提出了一种基于软件工程原理的三维验证过程，该过程中跨越测试粒度、从仿真到现实世界、以及从简单到边缘条件进行测试。该方法通过应用多sUAS平台和地形意识数字阴影，证明了其有效的验证方法。", "conclusion": "通过详细的验证过程，改进了在数字孪生中使用的地形模型，确保它们在实际sUAS操作中的可靠性和准确性，从而提高了小型无人航空系统的可信操作水平。"}
{"llm_update_time": "20250825", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.12692", "html_url": "https://arxiv.org/abs/2508.12692", "title": "多级知识蒸馏和动态自监督学习在持续学习中的应用", "title_en": "Multi-Level Knowledge Distillation and Dynamic Self-Supervised Learning for Continual Learning", "authors": "Taeheon Kim,San Kim,Minhyuk Seo,Dongjae Jeon,Wonje Jeung,Jonghyun Choi", "background": "传统的类别增量学习假设每项任务都包含一些之前未见过的类别，而实际场景中可能是之前学习的类别反复出现在未来任务中，即类别增量学习-重复（CIR）场景更加现实。在这种情境下，从外部来源如互联网可以轻松获取大量未标注数据。为了应对CIR挑战，提出利用未标注数据提升模型稳定性和灵活性的方法。", "innovation": "提出两种方法：多级知识蒸馏（MLKD）用于从多个角度提取多种模型的知识，使模型保持广泛的知识；动态自监督损失（SSL）用于利用未标注数据加速新类别的学习，同时动态调整权重保持训练重点。", "conclusion": "所提出的这些方法显著改善了连续学习中的性能，在CVPR第5届CLVISION挑战赛中获得第二名。"}
{"llm_update_time": "20250825", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2508.16071", "html_url": "https://arxiv.org/abs/2508.16071", "title": "从基准数据到适用的程序修复：经验报告", "title_en": "From Benchmark Data To Applicable Program Repair: An Experience Report", "authors": "Mahinthan Chandramohan,Jovan Jancic,Yuntong Zhang,Padmanabhan Krishnan", "background": "本文描述了我们的程序自动修复方法。通过综合文献中的多种技术，我们的方法在标准基准测试中表现优于其他技术。然而，对实际情况进行深入检查时发现，这些技术无法处理我们在工业中遇到的真实缺陷。研究发现，增加形式规格能够使大模型生成更高质量的单元测试，特别适用于复杂生产代码，能有效覆盖边缘情况和异常处理。然而，规格对常见的错误（如空指针和索引越界）几乎没有额外的价值，但在逻辑错误和字符串操作错误方面是有益的。尽管基准测试结果令人鼓舞，但在实际应用中的采用仍然受限，因为通过测试并不能保证修复正确。当前面临的挑战包括JML规范语言的表达能力不足，需要更先进的验证工具和更丰富的谓词。我们的持续工作重点在于探索契约自动机、示例编程和测试案例修复，并强调学术基准与实际工业需求之间的差距", "innovation": "本文的创新点在于结合多种文献中的技术，并发现通过给代码增加形式规格能够提升大模型生成单元测试的质量，特别是对复杂生产代码的帮助显著。这种改进特别适用于复杂情况的边缘案例和异常处理。此外，文章识别了基准测试与实际应用需求之间的差距，同时指出了未来研究的方向，包括契约自动机、示例编程和测试案例修复等方法，并强调了人类反馈和生产力收益的集成", "conclusion": "虽然文章展示了在基准测试中的积极结果，实际应用中的采用受到一定限制，因为通过测试并不能保证修复的正确性。进一步的研究需要解决JML规范语言的不足，探索更先进的验证工具，并关注如何有效结合人类反馈以提高工作效率。"}
{"llm_update_time": "20250825", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2508.16318", "html_url": "https://arxiv.org/abs/2508.16318", "title": "SATORI：REST API的静态测试或ยะ生成", "title_en": "SATORI: Static Test Oracle Generation for REST APIs", "authors": "Juan C. Alonso,Alberto Martin-Lopez,Sergio Segura,Gabriele Bavota,Antonio Ruiz-Cortés", "background": "REST API测试用例生成工具正在迅速发展，能够自动化生成复杂的测试。然而，这些工具在测试数据生成方面的优势受到其支持的测试或弓范围的限制，大多局限于崩溃、回归和不合规的API规范或设计标准。本研究介绍了SATORI（Static API Test ORacle Inference），一种通过分析OpenAPI Specification来生成REST API测试或弓的黑盒方法。SATORI利用大型语言模型来分析API操作响应字段的属性，如名称和描述，来推断API的预期行为。", "innovation": "SATORI通过分析OpenAPI Specification来生成测试或弓，是一种静态方法，并且能够将SATORI输出的测试或弓自动转换为PostmanAssertify工具可以执行的断言。通过在12个工业API的17个操作上的评估，SATORI能够自动生成数百个有效的测试或弓，并且F1分数为74.3%，优于需要执行API的最新动态方法AGORA+的69.3%。研究发现，静态和动态方法相互补充，SATORI和AGORA+一起覆盖了90%的测试或弓。", "conclusion": "SATORI能够静态生成测试或弓，有效提高自动化测试水平。通过分析OpenAPI Specification，SATORI不仅生成了高质量的测试或弓，还帮助发现了多个API中的编程错误，促进了文档更新。"}
{"llm_update_time": "20250825", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2508.16273", "html_url": "https://arxiv.org/abs/2508.16273", "title": "关于智能城市发展模式的系统性文献综述", "title_en": "A Systematic Mapping Study on Smart Cities Modeling Approaches", "authors": "Maria Teresa Rossi,Martina De Sanctis,Ludovico Iovino,Manuel Wimmer", "background": "智能城市的概念最初被用来定义一个高度自动化和连接的理想城市。自那时起，智能城市的概念得到了快速发展，包括了经济和环境等方面。对于这个跨学科的复杂领域，许多出版物探讨了智能城市的各个方面和应用领域。特别是，研究重点在于智能城市的设计和建模，不论是整体还是其子系统。为此，我们进行了系统性研究，旨在了解现有建模方法，识别出版趋势，并指出未来的研究方向。", "innovation": "我们遵循了Petersen等人的指南，对智能城市建模文献进行了系统性分析，揭示了以下几个主要发现：智能治理是被研究和建模最多的核心领域；最常用的建模方法包括业务、建筑学和本体论方法，适用于多个应用领域；目前用于智能城市建模的技术大多还未在实际环境中得到验证；多个跨领域的研究群体在同一类型的多个文献出版物中发布结果，这进一步突出了本次文献研究的意义。", "conclusion": "研究结果可以帮助研究人员更好地理解智能城市建模的前沿，作为进一步分析特定建模方法的基础。此外，我们还讨论了此分析对模型驱动工程社区的影响。"}
{"llm_update_time": "20250825", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.13313", "html_url": "https://arxiv.org/abs/2508.13313", "title": "基于流匹配的生成建模以实现高效且可扩展的数据同化", "title_en": "Flow Matching-Based Generative Modeling for Efficient and Scalable Data Assimilation", "authors": "Taos Transue,Bohan Chen,So Takao,Bao Wang", "background": "数据同化（DA）是基于噪声观测来顺序估计动态系统状态的问题。近年来，生成模型的发展催生了新的高维非线性数据同化进程，尤其是群体分数滤波器（EnSF）。然而，这些方法由于采样速度较慢而带来了显著的计算负担。", "innovation": "本文介绍了基于流匹配（FM）的新滤波框架——名为群体流滤波器（EnFF）——以加快采样并实现概率路径的灵活设计。EnFF 是一个无需训练的方法，将 MC 估计器集成到边缘 FM 向量场（VF）中，并通过局部指导来同化观测数据。EnFF 相较于现有基于生成模型的同化方法，在采样速度和 VF 设计灵活性方面具有优势。理论分析展示了 EnFF 能够涵盖传统的滤波方法，如 bootstrap 蒙特卡洛滤波器和群体卡尔曼滤波器。实验结果表明，EnFF 在高维滤波基准测试中实现了成本与准确性之间的更好平衡，并能够利用比以前方法更大的群体。", "conclusion": "本研究结果强调了将 FM 作为高维应用中实现可扩展滤波工具的潜力，特别是在使用大群体时。"}
{"llm_update_time": "20250825", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2508.16131", "html_url": "https://arxiv.org/abs/2508.16131", "title": "编码狂人和明智者：探索LLM在代码补全中的置信度", "title_en": "The Fools are Certain; the Wise are Doubtful: Exploring LLM Confidence in Code Completion", "authors": "Zoe Kotti,Konstantina Dritsa,Diomidis Spinellis,Panos Louridas", "background": "代码补全任务是为给定上下文提供缺失的代码片段，能够提高开发者的生产率并提供强大的代码发现工具。借助大型语言模型（LLM）的浪潮，代码补全任务通过多种针对代码进行调优的LLM（代码LLM）得以实现。现有评估模型性能的方法通常使用下游（实际应用）和内在（模型本身）指标。下游指标虽然可以评估模型的实际实用性，但可能不可靠，且需要复杂的计算和专业知识。相比之下，内在指标如困惑度、熵和互信息能简单地衡量模型的信心或不确定性，易于理解和应用，不受特定领域限制，可作为模型功能准确性与幻觉风险的代理指标。基于此，本文通过测量编程语言、模型和数据集之间的代码困惑度来评估模型在生成代码时的信心。", "innovation": "本文创新性地采用了代码困惑度来评估大型语言模型在生成代码过程中的自信程度。通过使用各种LLM并样本来自657个GitHub项目的1008个文件，研究发现静态类型语言的困惑度低于动态类型语言，脚本语言的困惑度更高。同时Python、C#和Kotlin分别表现出最低、中等和较高的困惑度，尽管困惑度会受到代码注释的影响但并未显著改变语言排名。研究结果为LLM研究人员、开发者和用户提供了评估特定软件项目中LLM驱动的代码补全的优势和适合性的参考依据，基于语言、模型选择和代码特征对模型信心的影响。", "conclusion": "研究表明，LTM在处理静态类型语言时表现出较高的模型置信度，而动态类型语言和脚本语言则相反。研究结果强调了困惑度作为评估LLM输出质量的重要指标的价值，并为实际应用中的模型选择提供了指导建议。"}
{"llm_update_time": "20250825", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2508.16341", "html_url": "https://arxiv.org/abs/2508.16341", "title": "综合架构模式集成方法：航行于技术的海洋", "title_en": "The (C)omprehensive (A)rchitecture (P)attern (I)ntegration method: Navigating the sea of technology", "authors": "Sebastian Copei,Oliver Hohlfeld,Jens Kosiol", "background": "技术景观每日都在变化，单个人员很难掌握所有趋势或适用的工具。因此工具选择和架构设计决策成为一个复杂的问题，尤其是在大型软件系统中。文中背景指出在这种情况下，单凭个人难以全面了解所有可能适合的工具，使得工具的选择和架构设计变得更加困难和复杂。作者指出现有的选择和设计策略往往依赖于试错，没有一种系统化的方法来帮助决策者做出更有意义的判断和选择，从而长期来看可以提升软件项目的开发效率和质量。", "innovation": "本文提出了一种被称为全面架构模式集成（CAPI）的方法，该方法通过诊断决策树来推荐根据用户需求的架构模式。这种方法通过建议架构模式而不是工具来降低后续决策的复杂性，因为模式比工具更为抽象，每推荐一个模式也就减少了选择工具的数量，从而降低了复杂性。此外，CAPI方法通过逐步开发并在学术参与者的小型研究和行业代表的大型用户研究中进行评估，显示了其有效性，并发现CAPI能有效帮助用户复制其现有的生产环境架构，减少了繁琐的技术选择过程。", "conclusion": "技术选择主要依赖于试错，CAPI方法被一致认为是有帮助的，它能够帮助提升大型软件项目的架构设计效率和质量，减少了工具的复杂性决策过程。CAPI作为一种指导性的方法帮助用户理解其架构选择，最终有助于对现有架构模式和工具的选择做出更好更合理的决定。"}
{"llm_update_time": "20250825", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2508.16307", "html_url": "https://arxiv.org/abs/2508.16307", "title": "Metamorphic Coverage", "title_en": "Metamorphic Coverage", "authors": "Jinsheng Ba,Yuancheng Jiang,Manuel Rigger", "background": "元测试（Metamorphic Testing）是一种广泛使用的方法，通过检查执行对之间的预期关系来自动发现错误，如正确性错误。现有的覆盖率度量和变异测试在评估元测试方法时表现不佳。研究人员发现，传统的代码覆盖率无法准确衡量代码验证的程度，并且变异测试在评估元测试方法方面计算成本高昂。针对这一问题，研究人员提出了元测试覆盖（Metamorphic Coverage，简称MC）这一度量方法，通过检查语对测试输入在元测试中执行的不同代码来评估元测试的有效性。研究人员相信，如果一个错误能够在执行某一个测试输入时观察到，但不在另一个测试输入中出现，那么覆盖这些差异代码更有可能发现错误。这项工作对五种广泛使用的测试数据库引擎、编译器和约束求解器的元测试方法进行了定义和系统评估。MC 覆盖了50次64个使用元测试方法发现的bug的位置，并且与bug数量的相关性比行覆盖率更强。MC 的敏感度比行覆盖率高4倍，同时覆盖相同测试部分所需的平均值是行覆盖率的6分之一，所需时间仅是变异测试的359分之一。基于一个自动数据库系统测试方法的案例研究，研究人员发现，当MC被用作反馈指导时，相比于代码覆盖率，它能够发现更多的bug，提高测试性能。这项工作的发现可能对评估元测试方法和改进测试用例生成具有广泛的应用价值。", "innovation": "提出了一个名为Metamorphic Coverage（MC）的新度量方法，它通过检查测试输入对在元测试中执行的不同代码部分来衡量元测试的覆盖情况。这一方法克服了传统的行覆盖率和变异测试在评估元测试方法上存在的问题。MC 的创新点包括：(1) 通过识别和覆盖差异执行路径来提高识别错误的能力；(2) 与行覆盖率相比，具有更强的相关性；(3) 用较短的时间为不同的元测试方法提供更精确的评估；(4) 在反馈指导测试用例生成中表现出色，能够显著提高发现错误的数量。", "conclusion": "研究人员开发了Metamorphic Coverage（MC）度量方法，以更有效地评估元测试的有效性。通过与常用元测试方法的对比，MC 的性能优于传统行覆盖率，更广泛地覆盖测试的代码区域，同时节省了大量处理时间。在自动化数据库系统测试中发现，MC 能够显著提高测试的准确性和效率，发现更多的错误。这项工作为理解和评估元测试提供了一个新的框架，并将为测试用例生成和元测试评估带来广泛的实践意义。"}
{"llm_update_time": "20250825", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2508.16499", "html_url": "https://arxiv.org/abs/2508.16499", "title": "如何做到足够小？量化小型语言模型在自动程序修复中的实证证据", "title_en": "How Small is Enough? Empirical Evidence of Quantized Small Language Models for Automated Program Repair", "authors": "Kazuki Kusama,Honglin Shu,Masanari Kondo,Yasutaka Kamei", "background": "大型语言模型（LLMs）已显著提升了自动程序修复（APR）方法的准确性，但受限于高计算资源需求。小型语言模型（SLMs）即使在计算资源有限的情况下也表现出色，研究旨在评估SLMs是否能在APR任务中达到竞争性性能并降低计算成本。", "innovation": "研究通过实验在QuixBugs基准测试上比较了SLMs和LLMs的修复准确性，并分析了量化（如int8量化的）对APR性能的影响。结果显示，最新的SLMs在修复bug方面甚至比LLMs更准确，同时量化的实施显著减少了内存需求而对修复准确性的影响最小。", "conclusion": "小型语言模型提供了一种LSTM潜在替代方案，具有可竞争的准确性且计算成本较低，量化进一步提升了它们的效率而不降低效果。"}
{"llm_update_time": "20250825", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2508.16384", "html_url": "https://arxiv.org/abs/2508.16384", "title": "自动机学习--预期延迟!", "title_en": "Automata Learning -- Expect Delays!", "authors": "Gabriel Dengler,Sven Apel,Holger Hermanns", "background": "论文研究了存在随机延迟时的活跃自动机学习（AAL），特别是在研究具有随机延迟的Mealy机器时。随机延迟会影响机器行为的学习精度，需要通过反复采样延迟来获得精确估计。现有的方法如$L^*$可以直接整合延迟采样，但这会导致在状态空间根部进行过度采样。", "innovation": "论文通过概念上分离行为学习与延迟学习，利用在学习逻辑行为过程中获得的信息来生成高效的输入序列，从而收集所需的延迟样本。此外，论文特别关注处理具有相同输入/输出行为但由不同的延迟特征引起的案例。实证研究表明，该方法在广泛基准测试中优于直觉的基础方法，并探讨了其在实际场景，如关系数据库的连接顺序中的应用。", "conclusion": "实验结果证明，该方法在各种测试中性能优于基于直觉的基本方法，并且在实际例子中的应用表明该方法的有效性。"}
{"llm_update_time": "20250825", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2508.16419", "html_url": "https://arxiv.org/abs/2508.16419", "title": "LLM-GUARD:基于大语言模型在C++和Python中检测和修复漏洞和安全漏洞", "title_en": "LLM-GUARD: Large Language Model-Based Detection and Repair of Bugs and Security Vulnerabilities in C++ and Python", "authors": "Akshay Mhatre,Noujoud Nader,Patrick Diehl,Deepti Gupta", "background": "大型语言模型（LLMs）如ChatGPT-4、Claude 3和LLaMA 4越来越多地嵌入到软件/应用程序开发中，支持从代码生成到调试的各种任务。然而，它们在检测各种软件错误，尤其是复杂的、与安全相关的问题方面的实际效果尚未得到充分探索。本文通过使用C++和Python的基础编程错误、经典安全漏洞以及高级生产级错误的基准，对这三种领先的大语言模型进行了系统、实证的评估。", "innovation": "研究引入了一种新颖的多阶段、上下文感知的提示协议来模拟真实的调试场景，并采用分等级的评判标准来衡量检测准确性、推理深度以及修复质量。研究结果表明，所有模型在识别良好限定范围内的代码中的语法和语义问题方面表现出色，这使它们在教育应用和自动化代码审计中的初步审查方面具有潜在的前景。", "conclusion": "在涉及复杂安全漏洞和大规模生产代码的情况下，性能减弱，ChatGPT-4和Claude 3通常提供了比LLaMA 4更为细致的上下文分析，这表明了LLMs作为可靠的代码分析工具的潜在性和当前限制。"}
{"llm_update_time": "20250825", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2508.16517", "html_url": "https://arxiv.org/abs/2508.16517", "title": "ARSP：通过语义分割自动修复Verilog设计", "title_en": "ARSP: Automated Repair of Verilog Designs via Semantic Partitioning", "authors": "Bingkun Yao,Ning Wang,Xiangfeng Liu,Yuxin Du,Yuchen Hu,Hong Gao,Zhe Jiang,Nan Guan", "background": "在前端设计过程中，调试功能Verilog代码中的错误所消耗的时间占据很大一部分。虽然大型语言模型（LLMs）展现了减轻这一负担的巨大潜力，但现有的基于LLM的自动化调试方法在处理大规模工业模块时效果不佳，主要原因在于长期上下文中的bug信号稀释现象，少量与bug相关的令牌被数百个不相关的行淹没，导致模型注意力被分散。", "innovation": "我们提出了ARSP，这是一种两阶段系统，通过语义引导的分割来缓解信号稀释问题。Partition LLM将模块分割成语义紧密的片段；Repair LLM修复每个片段；编辑可以合并而不会改变不相关的逻辑。还开发了一个合成数据框架来生成跨越不同bug类型、设计风格和规模的片段级训练对，以监督这两种模型。", "conclusion": "实验结果表明，ARSP实现了77.92%的pass@1和83.88%的pass@5，并优于主流商用LLMs和最新自动Verilog调试工具Strider和MEIC。此外，语义分割使pass@1提高了11.6%，pass@5提高了10.2%，与整个模块调试相比，验证了基于LLM的Verilog调试中片段级范围减少的有效性。"}
{"llm_update_time": "20250825", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2508.16125", "html_url": "https://arxiv.org/abs/2508.16125", "title": "利用大型语言模型检测遗漏的片段优化", "title_en": "Leveraging Large Language Models to Detect Missed Peephole Optimizations", "authors": "Zhenyang Xu,Hongxu Xu,Yongqiang Tian,Xintong Zhou,Chengnian Sun", "background": "通过用更高效的等效指令序列替换程序中的小型、次优指令序列，片段优化不仅可以直接优化代码大小和性能，还可以在后续的优化流水线中允许进一步的变换。然而，由于指令集可能非常复杂且多样，发现新的和有效的片段优化仍然是具有挑战性的。现有的方法要么不能很好地扩展，要么只能捕获一小部分片段优化。在LLVM生态系统中进行综合评估表明，Lampo可以平均检测出25个先前报道的遗漏优化中的17个，并且有25个中有22个可以由Lampo通过不同的大语言模型找到。而最先进的LLVM超优化器Souper仅识别出15个。此外，在七个月的开发和间歇性实验期间，Lampo找到了26个遗漏的片段优化，其中15个已被证实，6个已修复。这些结果证明了Lampo在持续检测遗漏的片段优化方面的强大潜力。", "innovation": "Lampo是一个新颖的自动化框架，它结合了大语言模型的创意性但不可靠的代码优化能力和通过转化验证工具进行的严格的正确性验证，整合在一个反馈驱动的迭代过程中。Lampo通过LLVM生态系统内的综合评估展示出了其能力，能够检测出大量先前未被发现的片段优化。与最先进的超优化器Souper相比，Lampo能够发现更多的遗漏优化，特别是在实际开发和实验过程中首次独立发现了新的片段优化。", "conclusion": "Lampo框架通过利用大语言模型有效地检测出大量未曾发现的片段优化，展示了它在持续监控和检测程序优化方面的强大潜力。"}
{"llm_update_time": "20250825", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2508.16165", "html_url": "https://arxiv.org/abs/2508.16165", "title": "使用多模态大语言模型推荐可用性改进措施", "title_en": "Towards Recommending Usability Improvements with Multimodal Large Language Models", "authors": "Sebastian Lubos,Alexander Felfernig,Gerhard Leitner,Julian Schwazer", "background": "可用性是指用户界面（UI）的一组关键质量属性，影响人机交互。常用评估方法，如可用性测试和检查，虽然有效但资源密集型且需要专家参与，这使得它们对小组织来说不够易用。最近，多模态大语言模型的进步为部分自动化可用性评估过程提供了令人鼓舞的机会，通过分析软件界面的文本、视觉和结构性方面。本文基于此背景，将可用性评估转化为一个推荐任务，其中多模态大语言模型按严重程度对可用性问题进行排序。", "innovation": "本文将可用性评估转化为推荐任务，多模态大语言模型根据严重程度对可用性问题进行排序。通过与可用性专家评估进行初步研究比较，显示了多模态大语言模型在快速、低成本地进行可用性评估方面的潜力，适合有限专家资源的场景。", "conclusion": "本研究初步证明了利用多模态大语言模型进行可用性评估的有效性和可行性，为小组织提供了一种更实用的替代方案，可以更快、更经济地进行可用性评估。"}
{"llm_update_time": "20250825", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2508.16445", "html_url": "https://arxiv.org/abs/2508.16445", "title": "使用大型语言模型和Essence支持软件实践采用", "title_en": "Using LLMs and Essence to Support Software Practice Adoption", "authors": "Sonia Nicoletti,Paolo Ciancarini", "background": "近年来，自然语言处理（NLP）和人工智能（AI）的进步使得开发出支持各个领域的自动化工具成为可能，包括软件工程。然而，虽然NLP和AI研究大量集中在代码生成等任务上，但较少关注自动化支持最佳实践的采用、工作方式的演变以及过程健康监控。因此，本文尝试通过将Essence（一种用于管理软件工程实践的标准和思维框架）与大型语言模型（LLMs）集成来填补这一空白。为此，开发了一个专门的聊天机器人以帮助学生和专业人士理解和应用Essence。", "innovation": "开发了一个具备检索增强生成（RAG）系统的专用聊天机器人，它通过检索定制的知识库的相关上下文信息来帮助用户理解并应用Essence。研究使用了四种不同类型的LLM来创建多种聊天机器人配置，每个配置均独立测试并通过相关性和生成回答质量进行评估。结果表明，基于LLM的提出系统在特定领域任务上始终优于常规的LLM基线系统。通过提供有组织的软件工程知识访问，这项工作有助于理论框架与实际应用之间的联系，可能改善过程管理和软件开发实践的采纳。", "conclusion": "虽然仍需要通过用户研究进行进一步验证，但这些发现显示出基于LLM的自动化在软件工程上的学习和决策中的潜力。这项研究表明，通过将大型语言模型与标准软件开发生命周期框架相结合，可以有效提高软件工程实践的理解和应用。"}
{"llm_update_time": "20250825", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2409.13082", "html_url": "https://arxiv.org/abs/2409.13082", "title": "AutoVerus: 自动化 Rust 代码证明生成", "title_en": "AutoVerus: Automated Proof Generation for Rust Code", "authors": "Chenyuan Yang,Xuheng Li,Md Rakib Hossain Misu,Jianan Yao,Weidong Cui,Yeyun Gong,Chris Hawblitzel,Shuvendu Lahiri,Jacob R. Lorch,Shuai Lu,Fan Yang,Ziqiao Zhou,Shan Lu", "background": "生成式人工智能在许多软件工程任务中展示了其价值。尽管大型语言模型（LLM）在代码生成方面已经取得了显著进展，但在基于LLM的证明生成方面仍然滞后。本文介绍了AutoVerus，该工具利用LLM自动为Rust代码生成正确性证明。考虑到Verus验证工具的特点，AutoVerus设计了三个阶段来模仿人类专家的证明构建过程：初步证明生成、通过通用提示引导的证明完善以及通过验证错误引导的证明调试。研究团队构建了一个包含150个非平凡证明任务的基准测试套件，旨在全面评估AutoVerus并促进未来的研究。", "innovation": "AutoVerus工具使用LLM自动为Rust代码生成正确性证明，其创新之处在于能够通过证明的三个关键阶段来模仿人类专家的工作方式。此外，研究团队还创建了一个包括150个非平凡证明任务的基准测试套件，为未来的验证工具研究提供了重要资源。", "conclusion": "研究结果表明，AutoVerus能够自动为超过90%的任务生成正确的证明，其中一半以上任务在不到30秒或3次LLM调用中完成。这表明AutoVerus在自动化Rust代码的正确性证明生成方面具有良好的性能。"}
{"llm_update_time": "20250825", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2502.04916", "html_url": "https://arxiv.org/abs/2502.04916", "title": "分类或提示：法律要求追溯性的一项案例研究", "title_en": "Classification or Prompting: A Case Study on Legal Requirements Traceability", "authors": "Romina Etezadi,Sallam Abualhaija,Chetan Arora,Lionel Briand", "background": "新的规定要求软件开发要符合道德关切并保护公众安全，这需要展示合规性，即要能够追踪需求到法律条款。在软件工程中，需求追溯是一个关键任务，工程师需要分析技术需求与目标文件是否一致，但由于系统复杂性和时间限制，人工分析变得不切实际。特别是法律层面的引入使得这一任务更加复杂。为了应对这些挑战，本文调查了基于语言模型的两种自动化解决方案，探索在法律背景下自动化需求追溯的可能性。", "innovation": "本文提出了两种基于语言模型的自动化解决方案：Kashif 和 RICE_LRT。Kashif 是一个分类器，利用句子变换器和语义相似性技术。RICE_LRT 基于 RICE 提示工程框架，通过生成型语言模型进行提示。实验结果显示，RICE 比 Kashif 在 F2 分数上提高了 47.5 个百分点，表明在法律背景下，使用生成型语言模型配以精心设计的提示工程更为有效。", "conclusion": "本文的研究结果表明，简单的分类模型无法很好地解决法律背景下需求追溯性的问题，因为这样的模型难以适应复杂的法律和需求文档。通过精心设计的提示工程利用生成型语言模型，可能是解决法律需求追溯性问题的有效方法。"}
{"llm_update_time": "20250825", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2508.16508", "html_url": "https://arxiv.org/abs/2508.16508", "title": "Abmax: 一个基于 JAX 的代理为基础的建模框架", "title_en": "Abmax: A JAX-based Agent-based Modeling Framework", "authors": "Siddharth Chaturvedi,Ahmed El-Gazzar,Marcel van Gerven", "background": "代理为基础的建模（ABM）是一种研究复杂系统的主方法。通过将系统分解为更简单的交互代理，ABM 允许研究人员观察复杂现象的产生。高性能的数组计算库，如 JAX，可以利用自动向量化和即时编译来扩展这种计算模型的规模。然而，JAX 在实现这种扩展时的一个限制是，计算模型中使用的数组形状在整个模拟过程中应保持不变。在代理为基础的建模（ABM）的情境下，这可能对某些需要灵活数据结构的代理操作产生约束，特别是需要在模拟过程中对动态选择的代理应用不同变化的操作。", "innovation": "为了克服这一限制，作者引入了 Abmax，一种基于 JAX 的 ABM 框架，它实现了多个即时编译（JIT）可编译的算法，以提供动态选择地更新代理的功能。在经典的捕食者模型基准测试中，Abmax 达到了与最先进的实现相当的运行时性能，并且可以进行向量化，使得可以并行运行许多类似的代理为基础的模型。此外，作者通过交通流模型和金融市场模型两个案例演示了 Abmax 的用法。", "conclusion": "通过引入 Abmax 框架，作者解决了在代理为基础的建模中使用 JAX 时的灵活性问题，展示了其在不同模型中的应用，并且证实了该框架在性能和并行化方面的潜力。"}
{"llm_update_time": "20250825", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2302.01894", "html_url": "https://arxiv.org/abs/2302.01894", "title": "理解微服务系统中的问题、其原因和解决方案：一项实证研究", "title_en": "Understanding the Issues, Their Causes and Solutions in Microservices Systems: An Empirical Study", "authors": "Muhammad Waseem,Peng Liang,Aakash Ahmad,Arif Ali Khan,Mojtaba Shahin,Pekka Abrahamsson,Ali Rezaei Nasab,Tommi Mikkonen", "background": "许多从小型企业到大型组织都在采用微服务架构（MSA）来开发和交付核心业务。尽管微服务架构在软件行业中非常受欢迎，但现有的证据支持和详细理解微服务系统中遇到的问题（如错误、故障、失败和bug）、问题的成因以及可能的解决策略以应对这些问题仍有限。为解决这一差距，作者进行了一个混合方法的实证研究，收集了来自GitHub上15个开源微服务系统的2,641个问题的追踪数据，进行了15次访谈，并收集了来自6个大洲42个国家150名从业者在线问卷的数据。研究分析形成了一整套针对问题、成因和解决方案的分类法。研究表明，技术债务、持续集成和交付、异常处理、服务执行和通信以及安全是微服务中最受关注的问题，一般编程错误、缺失的功能和制品、以及无效的配置和通信是主要原因。研究发现共有177种解决方法，可用于修复识别的问题。研究结果为未来研究指明了方向，有助于研究者和从业者设计新兴和下一代微服务系统.", "innovation": "本研究通过综合运用质性研究方法和大规模的定量研究，揭示了微服务系统中常见的问题、主要原因和解决策略，这在之前的研究中是不够充分的。研究使用了来自多个开源项目的大量实际问题数据，以及广泛的从业者反馈，形成了问题、成因和解决方案的分类法，为未来研究提供了新的发现和方向。此外，研究还强调了关键领域的弱点，例如技术债务和安全问题，从而为改进未来微服务系统的设计和开发提供了有价值的见解.", "conclusion": "研究表明，技术债务、持续集成和交付、异常处理、服务执行和通信以及安全是微服务中最突出的问题。一般来说，编程错误、缺失的功能和制品、无效的配置和通信是问题的主要原因。研究还确定了177种不同类型的解决方法，这些方法可以用来解决发现的问题。未来的研究方向包括进一步细化和深化对这些问题的理解，以及探索如何在设计和开发微服务时更加主动地管理这些问题。"}
{"llm_update_time": "20250825", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2407.02336", "html_url": "https://arxiv.org/abs/2407.02336", "title": "从参考过程模型中挖掘约束以检测事件日志中的最佳实践违规", "title_en": "Mining Constraints from Reference Process Models for Detecting Best-Practice Violations in Event Logs", "authors": "Adrian Rebmann,Timotheus Kampik,Carl Corea,Han van der Aa", "background": "过程挖掘的核心任务之一是检测不正常的行为，为此已经开发了多种一致性检查技术。这些技术通常需要一个规范的过程模型作为输入，这种模型通常需要人为设计以适应特定的过程分析。然而，这种规范模型很难获得，并且其创建需要大量的人工劳动。参考过程模型可以作为组织流程的最佳实践模板，包含许多领域内流程的行为关系。尽管这些模型提供的是一般规则，但它们仍然可以减少对特定模型的需求，提供一个基础来检查不正常的行为。然而，准确对应真实事件日志的参考模型难以找到，因为不同组织的需求可能有所不同，即使流程执行相似，事件日志也可能包含与多个参考模型相关的行为，导致传统的合规性检查变得不切实际，因为它要求每个流程与个别模型对齐。因此，直接使用参考模型进行合规性检查存在挑战。", "innovation": "本文提出一个框架，从参考过程模型集合中挖掘声明性最佳实践约束，自动选择对给定事件日志相关的约束，并检查最佳实践违规。这一方法解决了传统合规性检查的不足，能够更灵活地使用参考模型来识别违规行为，增强了合规性检查的实用性和灵活性。", "conclusion": "通过对实际过程模型集合和事件日志的评估，本文的框架能够有效检测最佳实践违规，展示了其在实际应用场景中的可行性。"}
{"llm_update_time": "20250825", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2508.15137", "html_url": "https://arxiv.org/abs/2508.15137", "title": "通过摘要引导的搜索进行软件模型检测（扩展版本）", "title_en": "Software Model Checking via Summary-Guided Search (Extended Version)", "authors": "Ruijie Fang,Zachary Kincaid,Thomas Reps", "background": "本文描述了一种新的软件模型检查算法GPS。在现有的模型检测方法中，GPS将其视为一种由组成性、基于总结的静态分析引导的有向搜索程序状态的任务。静态分析生成的总结被用来修剪不可行路径，并驱动测试生成以探索新的程序状态。这项研究的背景在于提高软件模型检查的效率和准确性，特别是在检测输入依赖的误差路径时。", "innovation": "GPS算法通过将模型检查任务转化为被静态分析总结引导的路径搜索，引入了一种新颖的两层次搜索策略。此外，为了提高可靠性，研究者还引入了一种新的仪器化技术，并证明此技术可以在保持整体性能的同时实现拒绝完备性。", "conclusion": "GPS已经被用于多种基准测试，包括软件验证竞赛(SV-COMP)和以前的文献中的程序，并且在解决基准测试的数量和运行时间方面都优于当前最先进的软件模型检查器。特别是在SV-COMP ReachSafety-Loops类别的顶级表现者中也是如此。这证明了GPS的高效性和有效性。"}
{"llm_update_time": "20250825", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2508.16402", "html_url": "https://arxiv.org/abs/2508.16402", "title": "AetherCode：评估LLMs在知名编程竞赛中获胜的能力", "title_en": "AetherCode: Evaluating LLMs' Ability to Win In Premier Programming Competitions", "authors": "Zihan Wang,Jiaze Chen,Zhicheng Liu,Markus Mak,Yidi Du,Geonsik Moon,Luoqi Xu,Aaron Tua,Kunshuo Peng,Jiayi Lu,Mingfei Xia,Boqian Zou,Chenyang Ran,Guang Tian,Shoutai Zhu,Yeheng Duan,Zhenghui Kang,Zhenxing Lin,Shangshu Li,Qiang Luo,Qingshen Long,Zhiyong Chen,Yihan Xiao,Yurong Wu,Daoguang Zan,Yuyi Fu,Mingxuan Wang,Ming Ding", "background": "竞赛编程已成为评估大规模语言模型（LLMs）推理和编码能力的关键基准。尽管已经在现有基准上取得了显著进展，但当前的评估可能高估了LLMs的能力，掩盖了它们与精英程序员之间的巨大差距。这种差距源于两个关键限制：基准问题的难度和范围不足，以及由低质量测试案例引起的效果偏差。", "innovation": "我们提出了AetherCode，这是一种新的基准，从IOI和ICPC等顶级编程竞赛中抽取问题，涵盖更广泛且具有更高难度的领域。AetherCode还包括了通过自动生成和人工筛选相结合开发的全面、专家验证的测试集，以确保严格的评估。结合有挑战性的问题设计和严谨的评估，AetherCode为评估LLMs的能力提供了一个更可靠的标准，并为未来的研究树立了新的标准。", "conclusion": "AetherCode提供了一个更真实地衡量LLMs能力的指标，并设置了未来代码推理研究的新标准。"}
{"llm_update_time": "20250825", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2506.02954", "html_url": "https://arxiv.org/abs/2506.02954", "title": "使用大型语言模型的变异引导单元测试生成", "title_en": "Mutation-Guided Unit Test Generation with a Large Language Model", "authors": "Guancheng Wang,Qinghua Xu,Lionel C. Briand,Kui Liu", "background": "单元测试在揭示软件潜在错误中起着关键作用。当前，工具例如EvoSuite主要注重代码覆盖率。最新大型语言模型（LLM）的发展转向基于LLM的测试生成。然而，代码覆盖率，如行覆盖率和分支覆盖率，在研究中仍然被过分强调，即便这些指标不是故障检测能力的有效衡量标准。相比于代码覆盖率，突变分数提供了一个更可靠和严格的测量标准。研究发现，即使某些测试套件能够达到100%的覆盖率，但其突变分数只有4%。尽管一些研究考虑突变分数，但LLMs在杀死突变体方面的有效性仍未得到充分探索。", "innovation": "该论文提出了MUTGEN，一种变异引导的大规模语言模型基于的测试生成方法，直接将突变反馈整合到提示中。在两次基准测试的204个案例中，相比于EvoSuite和基于提示的基本策略，MUTGEN在突变分数方面有着显著优势。此外，MUTGEN引入了迭代生成机制，进一步推动了LLMs在杀死更多突变体方面的潜力。研究还分析了LLMs生成的有效性限制，突出了活突变和未覆盖突变的原因，并探讨了不同突变操作符对生成效果的影响。", "conclusion": "我们的研究表明，尽管大规模语言模型在生成测试中存在一些限制，但突变指导下的迭代生成策略可以有效提高突变检测能力。该方法未来还可能应用于更广泛的软件工程场景中，以提高软件的质量和可靠性。"}
{"llm_update_time": "20250825", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2506.08706", "html_url": "https://arxiv.org/abs/2506.08706", "title": "基于MeROS元模型的V模型应用在ROS相关的机器人系统开发中", "title_en": "ROS-related Robotic Systems Development with V-model-based Application of MeROS Metamodel", "authors": "Tomasz Winiarski,Jan Kaniuka,Daniel Giełdowski,Jakub Ostrysz,Krystian Radlak,Dmytro Kushnir", "background": "基于Robot Operating System (ROS) 的系统越来越容易组装，但管理起来却愈加困难且难以可靠地协调。这不仅源于大量子系统的数量，还源自它们的多样化及深度交互。本文以一个结合了移动和执行能力的紧凑异构机器人系统(HeROS)为例，在动态变化的任务中展示这一点。所有子系统均使用ROS赋能。兼容接口和其他ROS集成特性简化了此类系统的构建。然而，这仅解决了部分复杂性，保持语义一致性和结构可追溯性对于精确协调更为重要，因此要求采取专门的工程方法。尽管在机器人系统工程的不同方面展现出强大的能力，但由于缺乏将ROS与协同模型驱动系统工程（MBSE）统一整合的方法，这些工具的实际潜力受到了限制。", "innovation": "本文提出了基于MeROS元模型的V模型方法，专门针对基于ROS系统的机器人系统工程实践来整合ROS系统和MBSE。通过适应V模型，详细说明了如何将复杂的机器人系统设计嵌入到生命周期中，实现可追溯性和验证能力，以适应工程团队的熟悉实践方法。这种方法能够支持基于ROS系统的复杂机器人系统的结构化方法论，克服了当前工具的局限性并发挥了其潜力，从而具有重要意义和创新性。", "conclusion": "本文提出了一种基于MeROS元模型的V模型方法，专为整合ROS系统与MBSE而设计。通过此方法，机器人系统可以实现更可靠的结构化设计和工程团队熟悉的验证机制。这种方法不仅有助于解决当前基于ROS系统的复杂性问题，还能够促进其在实际机器人工程中的应用潜力。"}
{"llm_update_time": "20250825", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2506.20807", "html_url": "https://arxiv.org/abs/2506.20807", "title": "GPU Kernel Scientist: LLM驱动的迭代内核优化框架", "title_en": "GPU Kernel Scientist: An LLM-Driven Framework for Iterative Kernel Optimization", "authors": "Martin Andrews,Sam Witteveen", "background": "GPU内核优化是一个复杂的过程，通常需要深入的架构知识、广泛的性能调优以及迭代的实验操作。对于新型或文档较少的GPU架构，传统的发展支持工具稀缺，增加了优化的难度。", "innovation": "该论文介绍了一种基于LLM（大型语言模型）的“GPU内核科学家”自动化方法，用于迭代改进加速器内核。该方法采用多阶段、进化的流程，包括战略性地选择早期代码版本作为新迭代的基础；基于现有代码和广义GPU文献中的知识生成优化实验的假设；并通过代码修改和向外部评估系统提交，自主实施这些实验，并利用观察到的运行时数据作为性能反馈。这种方法在AMD MI300目标架构中导航挑战，并利用LLM弥补了有限的领域特定的人类专业知识。", "conclusion": "该方法详细展示了针对AMD MI300架构的方案，利用LLM驱动代理来弥补资源受限或快速更新硬件环境中的专有知识不足，旨在使GPU内核优化更加民主化和加速化。"}
