# 20251022
[![Subscribe_Visitors](https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss)](https://github.com/nituchao/latest_arxiv_analyze_ai)

## 1. `cs.AI` - 基于泛化模式的学习：增强小语言模型微调中数据扩增的一种评估驱动方法 [PDF](https://arxiv.org/pdf/2510.18143), [HTML](https://arxiv.org/abs/2510.18143)
### Authors
Huan Song,Deeksha Razdan,Yiyue Qian,Arijit Ghosh Chowdhury,Parth Patwa,Aman Chadha,Shinan Zhang,Sharlina Keshava,Hannah Marlowe
### Background
小语言模型（SLMs）在部署成本和延迟方面具有明显优势，但其准确性往往低于大型模型，尤其是在复杂领域的特定任务中。虽然监督微调可以在一定程度上弥补这种性能差距，但其需要大量的手动数据准备和迭代优化工作。已有方法主要关注模型训练错误，并生成错误纠正样本，而未有效利用验证数据中的失败模式直接减少泛化差距。
### Innovation
提出了一种基于评估的PaDA-Agent（模式引导的数据增强代理），其通过协调操作简化了SLMs的数据增强流程。不同于现有侧重于模型训练误差和生成纠错样本的方法，PaDA-Agent能够从验证数据中发现失败模式，并制定针对性的数据增强策略，旨在直接减少泛化差距。
### Conclusion
实验结果表明，PaDA-Agent在Llama 3.2 1B Instruct模型微调的基于LLM的数据增强方面显著优于现有最先进的方法。
## 2. `cs.AI` - 在LLMs中衡量推理：一种新的辩证视角 [PDF](https://arxiv.org/pdf/2510.18134), [HTML](https://arxiv.org/abs/2510.18134)
### Authors
Soheil Abbasloo
### Background
当前对语言模型的评估大多基于正确答案，但这种方法未能反映生成这些答案的过程。研究者认为，推理是一个动态过程，涉及观念的互动、冲突和演进。本文探讨了一种新的视角，即通过辩证法中的‘矛盾、对抗和综合’来评估模型的推理能力。
### Innovation
提出了一个新的框架SIEV，它不只关注模型的结论，还评估模型如何达到这一结论的能力，包括解决冲突、整合不同观点和综合高层次推理。这一框架揭示了当前最先进的模型在高压基准测试下的显著推理缺陷，如GPT-5-chat在评判标准GSM上的得分大幅下降。
### Conclusion
采用过程导向、具有哲学基础的方法可以更深入、严谨且区别性地评估语言模型的推理能力。
## 3. `cs.AI` - FABRIC: Framework for Agent-Based Realistic Intelligence Creation [PDF](https://arxiv.org/pdf/2510.17995), [HTML](https://arxiv.org/abs/2510.17995)
### Authors
Abhigya Verma,Seganrasan Subramanian,Nandhakumar Kandasamy,Naman Gupta
### Background
大型语言模型（LLMs）越来越多地被用作代理，在动态环境中分解目标、调用工具并验证结果。这些能力的实现需要访问代理性数据，即结构化的交互记录，将用户意图与工具规范、基于论据的调用和可验证的执行轨迹结合起来。然而，从人类注释者收集此类数据既昂贵又耗时，难以扩展。
### Innovation
本文提出了一个统一框架，该框架使用仅LLM的方法合成代理数据，无需任何人工监督。该框架将生成分解为模块化的管道，生成涵盖任务规范、工具定义、策略伪代码、自然语言交互和执行轨迹的完整交互记录。通过纳入受限生成格式、JSON-schema验证和基于判决的过滤机制，确保记录的质量和一致性。
### Conclusion
本文详细阐述了代理记录的结构化方案，介绍了指导生成的提示设计原则，并介绍了用于生成高质量合成数据的可扩展管道。通过提供一个可再现的、仅由LLM实现的替代方法来替代手动收集，该方法促进了能够稳健使用工具的代理LLM的发展。
## 4. `cs.AI` - 不依赖全局时间的主题事件本体：基础与执行语义 [PDF](https://arxiv.org/pdf/2510.18040), [HTML](https://arxiv.org/abs/2510.18040)
### Authors
Alexander Boldachev
### Background
本文的背景在于目前大多数模型依赖于全局时间框架，存在不少局限性和不确定性。本文提出了一种不依赖于全局时间的主题事件本体，通过事件表示主体根据现有模型感知和确定变化，并通过显式依赖定义因果顺序，而非依赖时间戳。这种方法为建模复杂动态系统提供了一种新的视角。
### Innovation
本文的主要创新点在于：（1）事件被视为一种固定的行动；（2）因果关系通过‘发生之前’定义，而非时间戳；（3）通过声明式数据流机制使本体可执行，确保确定性；（4）模型作为认识过滤器，仅固定符合现有概念和属性的内容；（5）假定真实，事件的内容从被固定时起即可用于计算，无需外部验证。论文还包括九条公理确保执行本体的正确性。
### Conclusion
本文通过半正式化形式验证了主题事件本体，应用在流水线引擎中，验证了理论构建。这种本体适用于分布式系统、微服务架构、DLT平台和多视角场景（不同主体的冲突事实）。
## 5. `cs.AI` - 计划扩散 [PDF](https://arxiv.org/pdf/2510.18087), [HTML](https://arxiv.org/abs/2510.18087)
### Authors
Daniel Israel,Tian Jin,Ellie Cheng,Guy Van den Broeck,Aditya Grover,Suvinay Subramanian,Michael Carbin
### Background
在大语言模型推理中，生成速度和输出质量之间的权衡是一个核心挑战。自回归模型能够生成高质量的文本，但生成过程是按顺序进行的。扩散模型则可以并行生成token，但往往需要多次迭代才能达到相同的质量。本研究提出了一种新的混合方法——计划扩散，旨在结合这两种模型的优点。
### Innovation
计划扩散采用两阶段的方法：首先，模型生成一个简短的自回归计划，将输出分成更小、更独立的片段；其次，利用扩散模型并行生成这些片段。这种方法扩展了速度与质量之间的有效前沿，并提供了一条实现更快且高质量文本生成的实际途径。该方法在AlpacaEval中表现出色，在805个指令跟随提示中实现了质量与延迟之间的最优点权衡，相比自回归生成，时间上加快了1.27倍到1.81倍，同时质量下降幅度在0.87%到5.4%之间。
### Conclusion
研究发现，计划扩散中的规划机制非常简单且可靠，可以通过运行时的简单控制来灵活调整质量与延迟之间的权衡。
## 6. `cs.AI` - SMaRT: Select, Mix, and ReinvenT - 一种基于LLM的推理和规划策略融合框架 [PDF](https://arxiv.org/pdf/2510.18095), [HTML](https://arxiv.org/abs/2510.18095)
### Authors
Nikhil Verma,Manasa Bharadwaj,Wonjun Jang,Harmanpreet Singh,Yixiao Wang,Homa Fashandi,Chul Lee
### Background
大型语言模型（LLMs）重新定义了复杂任务的自动化处理，展示了出色的泛化能力。尽管取得了这些进展，最先进的方法仍然依赖单一种策略提示，忽略了多种推理方法之间的协同效应。没有一种单一策略能在所有场景下表现优秀，因此急需一种融合多种策略的框架以最大化性能和确保鲁棒性。
### Innovation
我们引入了Select, Mix, and ReinvenT (SMaRT)框架，这是一种创新型的策略融合方法，旨在通过无缝集成不同的推理策略来克服这一局限性，从而创建平衡且高效的解决方案。与其他方法使用LLM作为评估者不同，SMaRT将它们作为智能集成者使用，实现了跨任务的“最好结果”。SMaRT在推理、规划和序列决策基准测试中的实证研究表明了其鲁棒性和适应性，框架在解决方案质量、约束遵守和性能指标方面均优于最先进的基准。
### Conclusion
这项工作通过开创一种在跨策略校准方面的新型范式，重新定义了由LLM驱动的决策制定，为推理系统解锁了更优的结果，并推进了自我改进方法的边界。
## 7. `cs.AI` - OPTAGENT: 通过口头强化学习优化多代理LLM交互以增强推理 [PDF](https://arxiv.org/pdf/2510.18032), [HTML](https://arxiv.org/abs/2510.18032)
### Authors
Zhenyu Bi,Meng Lu,Yang Li,Swastik Roy,Weijie Guan,Morteza Ziyadi,Xuan Wang
### Background
大型语言模型（LLMs）在数学和科学任务中的推理能力得到了显著展示。为了增强复杂的推理能力，已经提出了多代理系统来利用LLM代理的集体智慧。然而，现有的协作结构要么是固定的，要么依赖于多数投票或圆桌辩论，这可能会抑制正确但不占主导地位的代理贡献。近期的方法将多代理系统建模为图网络，但仅优化了代理的表现，忽略了交互的质量。因此，有效代理间的沟通对于多代理推理至关重要，高质量的辩论起着重要作用。
### Innovation
我们提出了$textbf{OURS}$多代理口语强化学习算法，该算法能够动态构建并改进多代理协作结构。我们的方法定义了动作空间和反馈机制，以评估辩论过程中的沟通稳健性和连贯性。最终决策则是通过对所有代理的多数投票实现。与单一代理提示方法以及最先进的多代理框架相比，我们的方法在各种推理任务，包括数学推理、创意写作、科学推理和数值排序方面表现出显著的优势。
### Conclusion
我们的方法$textbf{OURS}$显著提高了多代理系统的推理能力和协作效率，尤其是在涉及复杂推理任务时。与单独的代理提示方法和多代理框架相比，我们的优化策略在多个任务上取得了更好的表现。实验结果表明，有效的代理间沟通对于提高多代理推理的质量至关重要，并且高质量的辩论在其中扮演了重要角色。
## 8. `cs.AI` - CompactPrompt：LLM工作流中统一的提示和数据压缩管道 [PDF](https://arxiv.org/pdf/2510.18043), [HTML](https://arxiv.org/abs/2510.18043)
### Authors
Joong Ho Choi,Jiayang Zhao,Jeel Shah,Ritvika Sonawane,Vedant Singh,Avani Appalla,Will Flanagan,Filipe Condessa
### Background
大型语言模型（LLMs）提供了强大的推理和生成能力，但在运行时成本较高，特别是在需要使用长查询和处理丰富数据流的代理工作流程中。这些高成本限制了LLMs在实际应用中的扩展和效率。研究人员需要找到一种方法来降低这些成本，同时保持模型的输出质量。
### Innovation
CompactPrompt引入了一种端到端的管道，该管道结合了硬提示压缩和轻量级文件级数据压缩。CompactPrompt首先通过自信息评分和基于依赖关系的短语分组从提示中移除低信息量的令牌；同时对附加文档中的重复文本模式应用n-克隆缩写，并对数值列应用统一量化。这种方法能在保持语义忠实性的前提下使模型更加紧凑。在基准数据集TAT-QA和FinQA上测试，CompactPrompt能够将令牌使用和推理成本最多降低60%，同时保留输出质量（对于Claude-3.5-Sonnet和GPT-4.1-Mini的准确率下降不到5%）。此外，CompactPrompt还帮助实时可视化压缩决策并量化成本-性能权衡，为更高效生成AI管道奠定了基础。
### Conclusion
CompactPrompt通过对提示和数据进行压缩，在保持输出质量的同时降低了大型语言模型的运行成本。该方法可以通过实时可视化压缩决策来优化成本-性能权衡，并为企业提供了实现更高效AI应用的机会。
## 9. `cs.AI` - 超越更多背景：检索多样性提升多轮次意图理解 [PDF](https://arxiv.org/pdf/2510.17940), [HTML](https://arxiv.org/abs/2510.17940)
### Authors
Zhiming Lin
### Background
多轮意图理解在任务导向型聊天机器人中非常重要，但在实际部署中面临着严格的令牌预算和嘈杂的上下文。现有的检索管道主要强调相关性，而忽视了集合层面的多样化以及例证顺序等混淆因素。该研究探讨了在固定预算下，是否可以通过检索多样性而非更长的提示语来系统地改善大语言模型的意图理解能力。研究在两个数据集上进行了实验验证，通过严格的预算匹配提示语和随机位置，验证了不同可选例证数量、多样性和模型规模的影响效果。
### Innovation
研究提出了一种具备多样性的检索框架，选用上下文相关且能够平衡意图覆盖面和语言多样性，在这种选择的基础上结合了标准的大语言模型解码器。该研究通过预算匹配提示和随机位置的评价方法，以及对不同例证数量、多样性强度和模型规模的敏感性分析，证明了在固定预算条件下，检索多样性能够显著提升多轮意图理解能力，特别是在多个评估指标和不同模型规模下表现稳定，具有较低的延迟。
### Conclusion
研究指出，内容多样性在检索中具有重要影响，并且提供了一个简单的部署原则，用于构建具备在预算限制下的准确多轮次意图理解系统。这种方法在两个不同的数据集上展示出了明显的优势，超越了许多强大的基线模型，尤其是在不同轮次（4到7轮）下的一致改进和适度的延迟条件下。
## 10. `cs.AI` - 激活张量流投影：从LLM架构中解放特定任务行为 [PDF](https://arxiv.org/pdf/2510.17902), [HTML](https://arxiv.org/abs/2510.17902)
### Authors
Al Kari
### Background
大语言模型（LLM）架构的普及带来了根本性的挑战，即通过细调方法（如Low-Rank Adaptation, LoRA）学习的任务特定行为被限制在源模型的架构中，这种现象被称为架构固锁。现有的迁移方法试图通过对模型静态权重空间进行对齐来解决这个问题，这种方法脆弱且间接，依赖于参数几何结构之间的脆弱关联。因此，本文提出了一种根本不同的新范式：称为Cartridge Activating Space Transfer (CAST)的新框架，它通过在两个不同LLM架构的激活流形之间学习直接的非线性映射来解放LoRA编码的行为。
### Innovation
CAST框架通过在两个不同LLM架构的激活流形之间学习直接的非线性映射来解放LoRA编码的行为，它将预训练的LoRA视为冻结的“行为内核”，并通过学习轻量级的双向投影头部来将目标模型的激活流翻译成源模型的潜在空间，应用冻结的内核并在结果上进行投影，从而完全将学习到的能力与源架构解耦。这种训练不依赖于特定任务的数据。
### Conclusion
实验证明，CAST能够真正实现任何标准LoRA适配器的“零样本”翻译。对于不同模型系列之间的迁移实验（如从Llama-2到Mistral），CAST翻译适配器的表现达到了完全在目标模型上重新训练的LoRA的85-95%，在模型互操作性方面确立了新的行业标准，定量上超越了目前的权重空间迁移技术。
## 11. `cs.AI` - 基于LLM的多agent系统用于模拟和分析营销及消费者行为 [PDF](https://arxiv.org/pdf/2510.18155), [HTML](https://arxiv.org/abs/2510.18155)
### Authors
Man-Lin Chu,Lucian Terhorst,Kadin Reed,Tom Ni,Weiwei Chen,Rongyu Lin
### Background
模拟消费者的决策对于设计和评估营销策略至关重要。然而，传统的事件后分析和基于规则的基于代理模型难以捕捉人类行为和社会互动的复杂性。论文介绍了一种基于大语言模型的多代理仿真框架，该框架能够模拟消费者决策和社会动态，提高营销策略的测试效果和结果的可预测性。
### Innovation
提出了一个基于大语言模型的多代理仿真框架，该框架可以使生成代理进行交互、表达内心推理、形成习惯并做出购买决定，而无需预定义规则。这种新方法在价格折扣营销场景中提供了可操作的策略测试成果，并揭示了超越传统方法的新兴社会模式，为营销人员提供了一种可扩展且低风险的预实施测试工具，减少了对劳动密集型事件后评估的依赖，降低了低效营销活动的风险。
### Conclusion
该方法为营销人员提供了一种可扩展且低风险的工具来实现营销策略的预实施测试，减少了对耗时的事件后评估的依赖性，降低了营销活动失败的风险，揭示了新的社会动态模式，拓展了营销策略的有效测试范围。
## 12. `cs.AI` - Saber: 一种高效的具有自适应加速和回溯增强遮罩采样算法的扩散语言模型 [PDF](https://arxiv.org/pdf/2510.18165), [HTML](https://arxiv.org/abs/2510.18165)
### Authors
Yihong Dong,Zhaoyu Ma,Xue Jiang,Zhiyuan Fan,Jiaru Qian,Yongmin Li,Jianha Xiao,Zhi Jin,Rongyu Cao,Binhua Li,Fei Huang,Yongbin Li,Ge Li
### Background
扩散语言模型（DLMs）作为一种强大的替代自动回归范式的新兴技术，具备并行生成和双向上下文建模的固有优势，但在代码生成任务中，由于推理速度与输出质量之间的关键权衡，其性能受到极大限制。加速代码生成过程通常通过减少采样步骤来实现，但通常会导致性能崩溃。
### Innovation
本文提出了一种新颖的不需额外训练的采样算法——自适应加速和回溯增强重置掩码（Saber），旨在提高扩散语言模型代码生成的推理速度和输出质量。Saber 算法基于对扩散语言模型生成过程的两个关键洞察：1）随着代码上下文的建立，它可以自适应地加速；2）需要一个回溯机制来撤销生成的标记。
### Conclusion
我们在多个主流代码生成基准测试中的广泛实验表明，Saber 算法能够将主流扩散语言模型采样方法的 Pass@1 准确性平均提高1.9%，同时实现平均251.4%的推理速度提升。通过利用扩散语言模型的固有优势，我们的工作显著缩小了其与自动回归模型在代码生成性能方面的差距。
## 13. `cs.AI` - 注释链式思维：一种用于AI安全的行为标注数据集 [PDF](https://arxiv.org/pdf/2510.18154), [HTML](https://arxiv.org/abs/2510.18154)
### Authors
Antonio-Gabriel Chacón Menke,Phan Xuan Tan,Eiji Kamioka
### Background
近年来，人们越来越重视AI在推理过程中的链式思维监控对于确保AI安全的重要性。目前，通过文本分析推理步骤的方法尽管有效，但有可能被模型绕过，以隐藏危险的推理过程。该研究旨在填补AI安全研究中的关键空白，通过创建一个具有句子级别的标注数据集来实现基于激活的链式思维行为监控，旨在更好地引导和干预模型中的特定行为。现有的数据集往往对推理过程进行整体标注，而这无法满足安全监测所需的精确识别特定行为的具体时机的需求。研究者通过这个数据集展示了在激活级别的技术如何在改进推理过程中的安全监督方面发挥作用，从而加强对于潜在有害内容的处理和干预能力.
### Innovation
研究提出了一种新的句子级别的标注数据集，该数据集能够通过基于激活的监控来检测和引导模型推理链中的特定安全行为。这一创新之处在于它能够识别链式思维推理中具体的行为发生的精确时机，并通过提取扇区向量来影响关键行为，并最终提高安全监控的效能。这种方法为实现更精准的AI安全监管提供了一种有潜力的新途径，具备避免现有方法可能存在的被绕过的风险，提升了安全工作的效果和效率，更加有效应对潜在的有害内容的干预和管理.
### Conclusion
该研究通过创建一个专门用于标注链式思维行为的句子级别的数据集，填补了AI安全研究中的一大空白。通过此数据集，能够更好地监测和干预模型在推理过程中的特定安全行为，并通过激活级别的技术来提高安全监管的效果。这些发现展示了基于激活的干预方法的巨大潜力，它为未来AI安全性的进一步研究和实践提供了重要支持和指导。
## 14. `cs.AI` - 数学领域中RLVR痕迹的局部连贯性还是全局有效性？ [PDF](https://arxiv.org/pdf/2510.18176), [HTML](https://arxiv.org/abs/2510.18176)
### Authors
Soumya Rani Samineni,Durgesh Kalwar,Vardaan Gangal,Siddhant Bhambri,Subbarao Kambhampati
### Background
基于可验证奖励的强化学习(RLVR)后训练方法已被证明能提升大型语言模型(LLM)在逻辑推理任务上的准确率，但现有方法往往忽略了对中间标记的评估，仅基于最终答案的正确性或Pass@K准确性来评价效果，却声称通过RL后训练可以改善推理过程。在数学领域中，这一方法如何作用尚不明确，特别是对于中间步骤（非激励步骤）的影响，因此作者设计了一个实验框架来研究这个问题。
### Innovation
提出了一种基于一阶逻辑(FOL)的度量方法来捕捉推理步骤的一致性，定义了路径的有效性和一致性区分，表明路径有效性意味着逻辑正确性，而路径一致性则通过无错误来量度局部连贯性。实验结果表明，RL后训练有效提升了推理步骤的一致性，特别是在基础模型失败而RL模型成功的问题上。然而，意外的是，RL后训练仅提高了局部连贯性，但未必产生有效的或正确的解决方案，这表明改善推理步骤的局部连贯性并不保证最终答案的正确性。
### Conclusion
通过RL后的训练提升了数学推理过程中的局部连贯性，但是这并不等同于全局的有效性。因此，通过RL改善推理的有效性应当谨慎，需要确保其最终能够生成有效的数学证明。
## 15. `cs.AI` - ssToken: Self-modulated and Semantic-aware Token Selection for LLM Fine-tuning [PDF](https://arxiv.org/pdf/2510.18250), [HTML](https://arxiv.org/abs/2510.18250)
### Authors
Xiaohan Qin,Xiaoxing Wang,Ning Liao,Cancheng Zhang,Xiangdong Zhang,Mingquan Feng,Jingzhi Wang,Junchi Yan
### Background
数据质量在提升大型语言模型（LLMs）监督微调（SFT）方面发挥着关键作用，而基于令牌级的数据选择由于其细粒度性质已被证明是一种有前途的方向。现有基于令牌的选择方法存在两个关键局限性：（1）需要训练或访问额外的参考模型；（2）仅依赖于损失信息进行令牌选择，这便无法很好地保存语义上重要的令牌，而这些令牌可能不被基于损失的指标所青睐。
### Innovation
该研究提出了ssToken，一种自我调节和语义感知的令牌选择方法。ssToken利用易于访问的历史模型来计算每个令牌的损失差异，并将其作为自我调节信号，使模型能够自适应地在其优化轨迹中选择令牌，而不需要依赖之前工作中使用的离线训练参考模型的额外损失。此外，引入了一种基于注意力机制的语义感知令牌重要性评估指标，该指标与基于损失的选择方法相互补充，能够提供更有益的语义信息，从而使筛选过程更加有效。
### Conclusion
在各种模型家族和规模下的广泛实验表明，自我调节选择和语义感知选择单独使用时均优于全数据微调，而结合这两种策略的ssToken则实现了协同增益，并且进一步超越了先前的令牌级选择方法，同时保持了训练效率。
## 16. `cs.AI` - 反思幻象：开放任务揭示大型语言模型在反省推理中的系统性失败 [PDF](https://arxiv.org/pdf/2510.18254), [HTML](https://arxiv.org/abs/2510.18254)
### Authors
Sion Weatherhead,Flora Salim,Aaron Belbasis
### Background
以往的研究主要集中于封闭任务，这些任务具有明确且外部可见的正确性信号，这使得‘反思’看似有效，但实际上可能掩盖了模型自我纠正能力的局限性。人类认知过程的反思特征显示，人类在做事过程中能够主动纠正错误，不受外部正确性信号的限制。因此，本文通过一个具体的开放任务来测试大型语言模型是否能够进行有效的自我反思和修改。
### Innovation
本文首次采用了开放但有规则约束的任务，评估大型语言模型的自我反思和修改能力。通过这个简单的现实任务，模型需要生成有效的科学测试项目并在自我评估后进行修正。这种方法突破了传统封闭任务的局限，直接考察了模型在开放任务中的表现。
### Conclusion
实验结果显示，初次尝试和反思后的表现均随着开放性增加而恶化，模型的性能并未表现出比那些公共维护的推理模型有优势。文章指出，当前的大型语言模型的‘反思’机制缺乏功能性证据，无法像人类一样主动监控目标和规则。除非模型本身具备这样的机制，否则需要外部结构来强制实施规则才能实现可靠的性能。
## 17. `cs.AI` - AGI的定义 [PDF](https://arxiv.org/pdf/2510.18212), [HTML](https://arxiv.org/abs/2510.18212)
### Authors
Dan Hendrycks,Dawn Song,Christian Szegedy,Honglak Lee,Yarin Gal,Erik Brynjolfsson,Sharon Li,Andy Zou,Lionel Levine,Bo Han,Jie Fu,Ziwei Liu,Jinwoo Shin,Kimin Lee,Mantas Mazeika,Long Phan,George Ingebretsen,Adam Khoja,Cihang Xie,Olawale Salaudeen,Matthias Hein,Kevin Zhao,Alexander Pan,David Duvenaud,Bo Li,Steve Omohundro,Gabriel Alfour,Max Tegmark,Kevin McGrew,Gary Marcus,Jaan Tallinn,Eric Schmidt,Yoshua Bengio
### Background
目前缺乏对通用人工智能（AGI）的具体定义导致了现有专业人工智能与人类认知水平之间存在差距。本文旨在填补这一空白，通过引入一个可量化的框架来定义AGI，即其认知多样性和熟练程度与受过良好教育的成年人相当。此方法论基于Cattell-Horn-Carroll理论，这是迄今为止最经过实证验证的人类认知模型。该框架将通用智能细分为十个核心认知领域，并利用现有的人类心理学测量工具来评估AI系统。应用于这一框架后，当代AI模型在知识密集型领域表现出色，但在基础认知机制方面，尤其是长期记忆存储方面存在严重缺陷，这是显而易见的‘锯齿状’认知图谱揭示出了这一点。AGI评分（例如GPT-4在27%，GPT-5在58%）不仅精确地量化了AI系统的进步，还指出了当前与AGI之间仍然存在的巨大差距。
### Innovation
本文通过引入可量化的框架定义AGI，并将通用智能细分为十个核心认知领域，应用该框架评估AI，揭示了当前AI系统在基础认知机制方面存在严重缺陷。框架基于Cattell-Horn-Carroll理论，这为评估和理解AI系统提供了一种新的方法论。这不仅量化了AI的进步，还明确了与AGI之间的差距。
### Conclusion
本文通过可量化的方法定义了AGI，并应用该框架评估了AI系统的认知性能，结果显示当前AI系统在基础认知机制方面存在显著缺陷。AGI评分表明，虽然AI有所进步，但仍需大量工作才能实现真正的AGI。
## 18. `cs.AI` - FST.ai 2.0: 旨在为奥林匹克和残奥跆拳道公平、快速和包容性决策提供解释性人工智能生态系统的FST.ai 2.0 [PDF](https://arxiv.org/pdf/2510.18193), [HTML](https://arxiv.org/abs/2510.18193)
### Authors
Keivan Shariatmadar,Ahmad Osman,Ramin Ray,Usman Dildar,Kisam Kim
### Background
在奥林匹克和残奥击剑等竞技体育项目中，公平、透明和可解释的决策仍是重大挑战。现有的决策支持工具往往缺乏足够的透明度和解释性，使得裁判员、教练和运动员难以信任AI辅助的决策。为了解决这些问题，研究者开发了一套名为FST.ai 2.0的可解释AI生态系统，旨在实现实时决策支持，促进公平、高效和包容的决策环境。该系统利用图形卷积网络（GCNs）进行基于姿势的动作识别，通过可信度集进行认识不确定性建模，并提供可解释叠加图以支持决策可视化。交互式仪表板则进一步支持人类与AI的协作，用于裁判评估、运动员表现分析和残奥跆拳道分类，同时还包括裁判员培训、公平监控和政策层面的分析模块，适用于世界跆拳道体系。
### Innovation
FST.ai 2.0通过集成基于姿势的动作识别、认识不确定性建模以及可解释叠加图实现了透明的决策支持。交互式仪表板使人类与AI能够进行更有效的协作，涵盖裁判员评估、运动员表现分析和残奥跆拳道分类等多个方面。此外，FST.ai 2.0还包括模块化的裁判员培训、公平监控和政策层面的分析，这在世界跆拳道生态系统中具有重大意义。实验验证表明，FST.ai 2.0能够显著减少决策复查时间，并大幅提升裁判员对AI辅助决策的信任度。
### Conclusion
FST.ai 2.0通过整合实时感知、可解释推理及治理感知设计，建立了可信赖的数据驱动裁判和运动员评估透明管道，为公平、问责和人本化的人工智能在体育领域的发展奠定基础。
## 19. `cs.AI` - Genesis: Evolving Attack Strategies for LLM Web Agent Red-Teaming [PDF](https://arxiv.org/pdf/2510.18314), [HTML](https://arxiv.org/abs/2510.18314)
### Authors
Zheng Zhang,Jiarui He,Yuchen Cai,Deheng Ye,Peilin Zhao,Ruili Feng,Hao Wang
### Background
随着大型语言模型（LLM）代理越来越能够自动化完成复杂的网络任务，它们提高了生产力的同时，也带来了新的安全风险。然而，针对网络代理攻击的相关研究仍然有限。现有的红队方法主要依赖手动构建的攻击策略或离线训练的静态模型，这些方法无法捕捉到网络代理的行为模式，难以跨环境进行普遍化应用。在网络代理攻击中，成功需要不断发现和进化新的攻击策略。因此，本文提出了一种名为Genesis的新型代理框架，由攻击者、评分器和策略家三个模块构成，通过集成遗传算法和混合策略表示来生成对抗性注入，通过评估目标网络代理响应提供反馈，并通过对交互日志的动态挖掘，将有效策略编译入不断增长的策略库中，以增强攻击者的效果。
### Innovation
本文提出的Genesis框架提出了两个创新点：首先，通过将遗传算法与混合策略表示集成，增强攻击策略的生成能力；其次，动态从交互日志中发现有效策略，并将其编译入策略库中，实现策略的持续更新和应用。此外，该框架能够高效地在不同网络任务中发现新的攻击策略，并且在多种网络任务中表现优于现有攻击基准模型。
### Conclusion
通过广泛的实验验证，本文提出的Genesis框架能够有效地发现新的攻击策略，相比现有的攻击基线模型表现出更优的性能。
## 20. `cs.AI` - AgentChangeBench：会话AI在目标转变稳健性多维度评估框架 [PDF](https://arxiv.org/pdf/2510.18170), [HTML](https://arxiv.org/abs/2510.18170)
### Authors
Manik Rana,Calissa Man,Anotida Expected Msiiwa,Jeffrey Paine,Kevin Zhu,Sunishchal Dev,Vasu Sharma,Ahan M R
### Background
当前的代理基准主要评估静态目标或单次工具使用，而现实世界中的多轮交互中，目标的变化是其显著特征。为此，研究者引入了AgentChangeBench这一基准测试，专门设计来评估工具增强的语言模型代理在跨三个企业领域的对话中应对中期对话目标变化的能力。
### Innovation
AgentChangeBench采用四个互补的度量标准来评估：任务成功率（TSR）、工具使用效率（TUE）、工具调用冗余率（TCRR）和目标转变恢复时间（GSRT）。该基准测试包括2,835个任务序列和五个用户角色，旨在触发正在进行的工作流程中的现实转变点。研究发现，在目标变化场景下，不同模型的表现存在显著差异，传统的$text{pass}@k$分数可能掩盖这些差异。
### Conclusion
原始的高准确率并不意味着在动态目标情境下具有鲁棒性，有效的恢复时间和冗余率的明确测量是必要的。AgentChangeBench为诊断和改进代理在现实企业环境中的抗脆弱性提供了一个可重复的测试平台。
## 21. `cs.AI` - Earth AI: 使用基础模型和跨模态推理解锁地理空间洞察 [PDF](https://arxiv.org/pdf/2510.18318), [HTML](https://arxiv.org/abs/2510.18318)
### Authors
Aaron Bell,Amit Aides,Amr Helmy,Arbaaz Muslim,Aviad Barzilai,Aviv Slobodkin,Bolous Jaber,David Schottlander,George Leifman,Joydeep Paul,Mimi Sun,Nadav Sherman,Natalie Williams,Per Bjornsson,Roy Lee,Ruth Alcantara,Thomas Turnbull,Tomer Shekel,Vered Silverman,Yotam Gigi,Adam Boulanger,Alex Ottenwess,Ali Ahmadalipour,Anna Carter,Charles Elliott,David Andre,Elad Aharoni,Gia Jung,Hassler Thurston,Jacob Bien,Jamie McPike,Juliet Rothenberg,Kartik Hegde,Kel Markert,Kim Philipp Jablonski,Luc Houriez,Monica Bharel,Phing VanLee,Reuven Sayag,Sebastian Pilarski,Shelley Cazares,Shlomi Pasternak,Siduo Jiang,Stone Jiang,Thomas Colthurst,Yang Chen,Yehonathan Refael,Yochai Blau,Yuval Carny,Yael Maguire,Avinatan Hassidim,James Manyika,Tim Thelin,Genady Beryozkin,Gautam Prasad,Luke Barrington,Yossi Matias,Niv Efron,Shravya Shetty
### Background
地理空间数据具有巨大的潜力，用于理解和研究地球，但海量且多样化的数据以及其在不同分辨率、时间尺度和稀疏性上的差异，给全面分析和解释带来了巨大挑战。现有方法难以处理这些复杂的数据集，本文在此背景下提出了解决这一问题的方法。
### Innovation
本文介绍了Earth AI，这是一种基于三个关键领域的基础模型（行星级图像、人口、环境）和Gemini驱动的智能推理引擎的综合AI解决方案。它能够在联合推理能力和互补性方面提供显著的提升，特别是在处理复杂多步骤查询和通过跨模态推理将海量地理空间数据转化为可操作的理解方面。通过使用新基准中的现实世界危机场景验证，证明该方法在预测能力上具有独特的优势。
### Conclusion
Earth AI能够联合推理多个基础模型和大规模地理空间数据资源，克服了复杂查询处理的挑战，有效地从原始地理空间数据中提取关键且及时的见解，并通过跨模态推理在应对现实世界的危机场景中展示了与现有方法相比更优的优势。
## 22. `cs.AI` - Med-VRAgent: 医疗视觉推理增强的代理框架 [PDF](https://arxiv.org/pdf/2510.18424), [HTML](https://arxiv.org/abs/2510.18424)
### Authors
Guangfu Guo,Xiaoqian Lu,Yue Feng
### Background
视觉语言模型（VLMs）在医疗推理任务中取得了显著成果，但是它们在幻觉、模糊描述、不一致逻辑和不良定位方面存在问题。
### Innovation
我们提出了一种名为Med-VRAgent的代理框架，基于视觉引导、自我奖励和蒙特卡洛树搜索（MCTS）的思路，通过结合视觉引导和树搜索，提高了VLMs的医疗视觉推理能力。通过使用Med-VRAgent收集的轨迹作为反馈，进一步通过使用PPO目标对VLMs进行微调，以提高性能。
### Conclusion
在多个医疗视觉问答基准测试中，我们的方法优于现有方法。
## 23. `cs.AI` - 记忆增强状态机提示：一种新的LLM代理框架用于即时策略游戏 [PDF](https://arxiv.org/pdf/2510.18395), [HTML](https://arxiv.org/abs/2510.18395)
### Authors
Runnan Qi,Yanan Ni,Lumin Jiang,Zongyuan Li,Kuihua Huang,Xian Guo
### Background
现有的即时策略游戏中的LLM代理面临着幻觉和决策碎片化等关键技术挑战。本文提出了一种名为Memory-Augmented State Machine Prompting (MASMP)的新框架，旨在解决这些挑战，通过将状态机提示与记忆机制相结合，使结构化操作与长期战术一致性统一。
### Innovation
MASMP的主要创新点包括：(1) 由自然语言驱动的状态机架构，通过提示引导LLM模仿有限状态机和行为树；(2) 轻量级记忆模块，保留了战略变量（如战术、优先级单位）贯穿决策周期，进一步提升了长期决策的一致性和可靠性。
### Conclusion
实验在StarCraftⅡ中表明，MASMP的胜率高达60%，远超内置AI（Lv7）和基线模型（0%）。案例研究显示该方法保留了LLM的语义理解能力，通过严格的状态行动映射解决了“知行差距”，实现了解释性和类似FSM的可靠性。这项工作为复杂决策中神经网络和符号AI的结合提供了一个新的范式。
## 24. `cs.AI` - ShortcutBreaker: 使用全局扰动注意力的低秩噪声瓶颈用于多类无监督异常检测 [PDF](https://arxiv.org/pdf/2510.18342), [HTML](https://arxiv.org/abs/2510.18342)
### Authors
Peng Tang,Xiaoxiao Yan,Xiaobin Hu,Yuning Cui,Donghao Luo,Jiangning Zhang,Pengcheng Xu,Jinlong Peng,Qingdong He,Feiyue Huang,Song Xue,Tobias Lasser
### Background
多类无监督异常检测（MUAD）近年来受到了研究者的广泛关注。MUAD的目标是开发一个统一的模型来处理多种类别的异常检测任务，从而避免为不同的对象训练独立的模型，这能够节省大量的计算资源。然而，现有的先进Transformer架构在这一领域虽然带来了显著的性能提升，但仍然存在一个缺陷，即身份捷径的存在。这些捷径直接复制输入到输出，减小了正常和异常情况再构建误差之间的差距，使得两者难以区分。因此，本文提出了一种名为ShortcutBreaker的新颖统一特征重建框架，旨在解决这个问题。
### Innovation
本文提出的 ShortcutBreaker 有两个关键创新。首先，基于矩阵秩不等式设计了一个低秩噪声瓶颈（LRNB），将其高效地将高维特征投影到低秩潜在空间，理论上展示了其阻止简单身份再生产的能力。其次，利用ViTs的全局建模能力，而非仅仅关注局部特征，引入了全局扰动注意力机制，防止解码器中的信息捷径。这两个创新为 MUAD 的问题提供了一种全新的解决方案。
### Conclusion
通过在四个广泛使用的异常检测基准数据集上进行大量的实验，包括三个工业数据集（MVTec-AD, ViSA, 和 Real-IAD）以及一个医学数据集（Universal Medical），本文提出了的方法在这些数据集上的图像级AUROC分别达到了99.8%、98.9%、90.6%和87.8%，一致地超越了现有的 MUAD 方法。
## 25. `cs.AI` - 基于深度学习的玻璃瓶成型控制优化 [PDF](https://arxiv.org/pdf/2510.18412), [HTML](https://arxiv.org/abs/2510.18412)
### Authors
Mattia Pujatti,Andrea Di Luca,Nicola Peghini,Federico Monegaglia,Marco Cristoforetti
### Background
在玻璃瓶制造过程中，成型机器的精准控制对于保证产品质量和减少缺陷至关重要。本研究提出了一种基于深度学习的控制算法，旨在优化实际生产环境中的成型过程。该算法利用运营工厂的实际操作数据，通过神经网络预测参数变化对当前生产设置的影响。通过特定设计的逆向机制，算法确定了实现所需玻璃料品质所需的最优机器设置。实验结果表明，在多个生产线的历史数据集上，所提出的方法取得的成果令人鼓舞，表明其有潜力提高过程稳定性、减少浪费和改善产品质量的一致性。这些结果强调了深度学习在玻璃制造业过程控制中的潜在价值
### Innovation
提出了一种基于深度学习的控制算法，利用实际操作数据预测参数变化对生产设置的影响，并通过逆向机制确定实现所需玻璃料品质所需的最优机器设置。
### Conclusion
该方法显示了在多个生产线上取得的潜力，如过程稳定性提升、减少浪费和提高产品质量一致性。这些成果强调了深度学习在玻璃制造业过程控制中的潜在价值。
## 26. `cs.AI` - 在交互环境中异质对抗玩耍 [PDF](https://arxiv.org/pdf/2510.18407), [HTML](https://arxiv.org/abs/2510.18407)
### Authors
Manjie Xu,Xinyi Yang,Jiayu Zhan,Wei Liang,Chi Zhang,Yixin Zhu
### Background
自我博弈构成了一种基本的自主技能获取范式，其中代理通过自我导向的环境探索逐渐提升其能力。传统的自我博弈框架在零和竞争设置中利用了代理的对称性，但在具有固有的不对称性的开放学习场景中，这种方法显得不够有效。人类的教育系统示范了不对称的教育机制，其中教育者系统地构建针对每个学习者发展轨迹定制的挑战。主要挑战在于如何在能够自主合成适宜课程的系统中实现这些不对称的、适应性的教育机制，而无需预设任务层级。
### Innovation
本文提出了一种名为Heterogeneous Adversarial Play (HAP)的对抗自动课程学习框架，该框架将教师和学生之间的互动形式化为最小最大优化问题，其中任务生成的教师和解决问题的学生通过对抗动态共同进化。HAP框架建立了一个双向反馈系统，其中教师根据实时学习者表现指标不断调整任务难度，不同于现有的静态课程或单向任务选择机制。通过在多任务学习领域的实验验证，本文的框架能够与当前最佳基线保持性能一致，同时生成更有效的学习课程。
### Conclusion
实验结果表明，该框架可以在人工代理和人类被试中提高学习效率，同时也达到了与当前最佳基线相当的性能。这是通过建立一个双向反馈系统实现的，该系统使教师能够根据实时学习者性能持续调整任务复杂度。
## 27. `cs.AI` - 通过混合基础模型实现自动城市水涝评估和早期预警 [PDF](https://arxiv.org/pdf/2510.18425), [HTML](https://arxiv.org/abs/2510.18425)
### Authors
Chenxu Zhang,Fuxiang Huang,Lei Zhang
### Background
随着气候变化加剧，城市水涝对全球公共安全和基础设施构成越来越严重的威胁。现有的监测方法主要依赖人工报告，无法及时和全面地进行评估。
### Innovation
本文提出Urban Waterlogging Assessment (UWAssess)框架，一种基于基础模型的框架，能够自动识别监控图像中的水涝区域并生成结构化的评估报告。为了解决标注数据稀缺的问题，设计了半监督微调策略和chain-of-thought（CoT）提示策略，以充分发挥基础模型在数据稀缺下游任务中的潜力。评估结果表明，在具有挑战性的视觉基准上性能显著提升。基于GPT的评估证实UWAssess能够生成可靠的文本报告，准确描述水涝的程度、深度、风险和影响。这些能力促使水涝监测从感知转向生成，多基础模型协同框架也为此类智能和可扩展系统奠定了基础。
### Conclusion
该研究实现了从感知到生成的水涝监测转变，为城市管理和灾害响应提供了支持，进一步提高了城市对气候变化的韧性。
## 28. `cs.AI` - AlphaOPT: 通过自我改进的大语言模型经验库进行优化程序的制定 [PDF](https://arxiv.org/pdf/2510.18428), [HTML](https://arxiv.org/abs/2510.18428)
### Authors
Minwei Kong,Ao Qu,Xiaotong Guo,Wenbin Ouyang,Chonghe Jiang,Han Zheng,Yining Ma,Dingyi Zhuang,Yuhan Tang,Junyi Li,Hai Wang,Cathy Wu,Jinhua Zhao
### Background
优化建模能够在多个行业中帮助做出关键决策，但其自动化仍然具有挑战性，因为自然语言必须被映射为精确的数学建模和可执行的求解器代码。现有的基于大语言模型（LLM）的方法要么倚赖脆弱的提示，要么需要昂贵的重训练，并且具有有限的泛化能力。
### Innovation
AlphaOPT 提出了一种自我改进的经验库，使得大语言模型能够从有限的示例中（甚至仅凭答案而非标准程序代码）学习，并通过求解器反馈进行改进，而无需注释的推理踪迹或参数更新。该系统通过持续的两阶段循环运行：一是学习阶段，通过失败尝试来提取求解器验证的结构化洞见；二是进化阶段，诊断检索不一致并改进存储洞见的应用范围，从而提高任务间的迁移能力。这一设计（1）能够通过有限的示例高效学习，无需精心标注的理由；（2）通过更新数据库而非模型权重进行持续扩展，而无需昂贵的重训练；（3）使知识变得明确且可解释，以便进行人类检查和干预。
### Conclusion
实验结果表明，AlphaOPT 随着训练数据的增加表现出稳定的改进（从100到300个训练项从65%提高到72%），并且在仅用答案进行训练时，在 Out-of-Distribution 的 OptiBench 数据集上超过了最强基线7.7%。相关代码和数据可在指定网址获取。
## 29. `cs.AI` - CircuitSeer：通过探测LLMs中的数学推理电路挖掘高质量数据 [PDF](https://arxiv.org/pdf/2510.18470), [HTML](https://arxiv.org/abs/2510.18470)
### Authors
Shaobo Wang,Yongliang Miao,Yuancheng Liu,and Qianli Ma,Ning Liao,Linfeng Zhang
### Background
大规模语言模型（LLMs）展示了出色的推理能力，但提升其性能通常依赖于大量的训练数据，这些数据的训练成本高昂。现有的数据选择方法旨在筛选出较小的高质量子集，但往往依赖于成本较高的外部模型或不透明的启发式方法。本文的背景是针对这些挑战，研究者转向利用模型内部机制进行数据选择，发现复杂推理任务会激活注意力头中的特定子集，从而形成核心推理电路，为数据选择提供了一个新的视角.
### Innovation
研究者提出了CircuitSeer，一种新颖的数据选择方法，通过量化数据对这些关键电路的影响来计算推理复杂性。该方法利用了模型内部机制，能够有效筛选出高质量的数据。实验结果表明CircuitSeer在四款模型和九个数据集上表现出色，通过仅仅使用10%的数据进行微调，在平均Pass@1指标上比使用完整数据集训练提高了1.4个百分点，突显了其高效性和效果.
### Conclusion
CircuitSeer通过量化对核心推理电路的影响，成功筛选出高质量的数据，显著提升了语言模型的推理性能。该方法不仅高效，还具有高度的实际应用价值。
## 30. `cs.AI` - 通过LLM代理量化控制算法的潜力 [PDF](https://arxiv.org/pdf/2510.18491), [HTML](https://arxiv.org/abs/2510.18491)
### Authors
Lianchen Jia,Chaoyang Li,Qian Houde,Tianchi Huang,Jiangchuan Liu,Lifeng Sun
### Background
现有的控制算法通常需要领域专家根据特定场景手动调参，现有研究主要关注算法在理想或默认配置下的性能，而忽视了调参潜力这一重要方面。
### Innovation
本研究提出Crucible，这是一种利用LLM驱动的多级专家模拟来量化算法的调参潜力的智能代理，提出了一个标准化的度量标准来定量评估算法的调参潜力，并通过广泛案例研究和实际部署验证了其有效性。
### Conclusion
实验结果表明，Crucible系统地量化了不同算法的可调空间，为其分析和设计提供了新的维度，最终导致性能提升。
## 31. `cs.AI` - PlanU：在不确定性下的大型语言模型决策规划 [PDF](https://arxiv.org/pdf/2510.18442), [HTML](https://arxiv.org/abs/2510.18442)
### Authors
Ziwei Deng,Mian Deng,Chenjing Liang,Zeming Gao,Chennan Ma,Chenxing Lin,Haipeng Zhang,Songzhu Mei,Cheng Wang,Siqi Shen
### Background
大型语言模型（LLMs）正在被广泛应用于各种决策任务中。然而，在具有随机状态转换的环境中，LLMs 经常在进行决策时表现不佳，尤其是在那些对于人类相对容易的计划性行动任务中。这些挑战主要来自于LLM本身的不确定性以及环境不确定性。大多数LLM基决策方法（LDM）通过多重推理链或搜索树的方法来应对LLM的不确定性，但这忽略了环境不确定性，导致在具有随机状态转移的环境中表现不佳。解决这一问题的一个方法是通过预测未知变量的概率来进行不确定性处理，但这种方法并未针对多步骤决策任务与环境互动的需求进行设计。因此，有必要提出一种新的方法来应对不确定性问题并提高决策性能。
### Innovation
本文提出了PlanU，一种利用蒙特卡洛树搜索（MCTS）的LLM基规划方法，用于在不确定性环境下进行决策。PlanU通过为MCTS中每个节点的回报定义一个分位数分布，并引入上信心边曲率与好奇心（UCC）分数来平衡探索和开发，从而有效地捕捉并应对不确定性。这种方法不仅解决了已存在的挑战，还提供了适用于多步骤决策任务的新框架。通过大规模的实验验证，证明了PlanU在不确定性的决策任务中表现出色，改善了LLM在决策时的性能。
### Conclusion
研究表明，PlanU在不确定性环境下的决策能力优于现有的方法，提供了一种有效的方法来应对环境和LLM本身的不确定性，从而提升大型语言模型在决策任务中的应用。
## 32. `cs.AI` - 社会智能大语言模型代理中意图的概率建模 [PDF](https://arxiv.org/pdf/2510.18476), [HTML](https://arxiv.org/abs/2510.18476)
### Authors
Feifan Xia,Yuyang Fang,Defang Li,Yantong Xie,Weikang Li,Yang Li,Deguo Xia,Jizhou Huang
### Background
本文研究了在多轮社交对话中，大型语言模型（LLM）代理的意图建模框架。背景信息指出，当前的对话策略通常依赖于固定的意图模型，这在复杂和不确定的多方对话中效果不佳。因此，本文提出了一种基于概率的意图建模框架，以提升LLM代理在社交对话中的表现和适应性.
### Innovation
文中提出了一种概率意图建模框架，该框架通过初始化和动态更新信念分布来维护对方的潜在意图。通过这种方式，建立了在不确定对话环境下的模型，并能提供更加适应的对话策略。实验结果表明，与基准模型相比，新框架在SOTOPIA环境中的总体分数提高了9.0%，在SOTOPIA-Hard环境中提高了4.1%。这些初步结果表明，概率意图建模在推动社会智能LLM代理的发展中具有重要意义.
### Conclusion
文章通过实验证明了所提概率意图建模框架的有效性，并表明其能够改善大语言模型代理在复杂、不确定的多轮社交对话中的表现。研究结果还表明，该建模框架在提高LLM代理的社交智能方面具有显著潜力。
## 33. `cs.AI` - LAFA: 基于代理的大语言模型驱动的联邦数据分析 [PDF](https://arxiv.org/pdf/2510.18477), [HTML](https://arxiv.org/abs/2510.18477)
### Authors
Haichao Ji,Zibo Wang,Yifei Zhu,Meng han,Dan Wang,Zhu Han
### Background
大型语言模型（LLMs）已被证明在通过解释自然语言查询并生成多操作执行计划来自动执行数据任务方面具有巨大的潜力。然而，现有的基于LLM代理的数据分析框架假设集中式数据访问，几乎不提供隐私保护。相比之下，联邦数据分析（FA）可以在分布式数据源之间进行隐私保护计算，但缺乏支持自然语言输入的功能，需要结构化的、机器可读的查询。
### Innovation
本文介绍了一个名为LAFA的新系统，该系统将基于LLM代理的数据分析与FA结合在一起。LAFA采用了一种分层多代理架构，可以接受自然语言查询并将它们转换为优化的、可执行的FA工作流。通过粗粒度计划器将复杂查询分解为子查询，细粒度计划器使用先验的结构知识将每个子查询映射到FA操作的有向无环图。此外，优化代理通过重写和合并多个DAG来提高执行效率，从而消除了冗余操作并最小化了计算和通信开销。实验表明，LAFA在生成执行计划的成功率和减少资源密集型FA操作方面都优于基线提示策略。
### Conclusion
这项工作为支持FA场景中自然语言输入的隐私保护和大语言模型驱动的分析奠定了实用的基础。
## 34. `cs.AI` - 由物理指导的替代模型揭示了在操作延迟和中断下的韧性和脆弱性 [PDF](https://arxiv.org/pdf/2510.18535), [HTML](https://arxiv.org/abs/2510.18535)
### Authors
Sarth Dubey,Subimal Ghosh,Udit Bhatia
### Background
可靠的水文和洪水预报需要能够在输入数据延迟、缺失或不一致时仍然保持稳定的模型。然而，大多数降雨径流预测的进步都是在理想数据条件下进行评估的，强调准确性而非操作韧性。
### Innovation
开发了一个适用于全球洪水意识系统的操作就绪模拟器，结合了长短期记忆网络并放宽了水平衡约束，以保持物理一致性。该模拟器具有五种架构，能够跨越不同的信息可用性场景，便于系统性评估鲁棒性。并在训练和测试中充分考虑了多样性，定义了在数据稀缺和人类影响下的泛化极限，从而建立了操作鲁棒性作为水文机器学习的可测量属性，并推进了可靠实时预报系统的设计。
### Conclusion
该框架证明了操作鲁棒性作为水文机器学习的一个可度量属性，并推进了可靠实时预报系统的设计。
## 35. `cs.AI` - AndroidControl-Curated：通过基准净化揭示GUI代理的真实潜力 [PDF](https://arxiv.org/pdf/2510.18488), [HTML](https://arxiv.org/abs/2510.18488)
### Authors
Ho Fai Leung,Xiaoyan Xi,Fei Zuo
### Background
目前，手机中的虚拟助手如Siri和Google Assistant越来越重要，但它们的能力受限于开发者依赖的僵化API。GUI代理虽然提供了一种API无关的强大替代方案，但由于性能不佳的认知，其应用受到了阻碍。现有的基准测试如AndroidControl受限于某些缺陷，未能充分展示GUI代理的能力。
### Innovation
该研究揭示了问题不仅在于模型本身，还在于基准测试。研究提出改进后的AndroidControl-Curated基准测试，通过严格的净化流程解决了AndroidControl的缺陷。在这一增强的基准测试下，最新模型在复杂任务上的成功率接近75%，比之前提高了15%。此外，研究还介绍了新的SOTA模型Magma-R1-3B，该模型在仅有2400个标注样本和60小时计算资源的情况下开发，参数量仅比Qwen3-VL-235B小200倍，但性能相当。
### Conclusion
研究提供了净化后的AndroidControl-Curated基准测试和Magma-R1模型，鼓励研究界采用这个改善后的基准，以更准确地反映模型能力，并加速开发稳健的、设备本地的虚拟助手。
## 36. `cs.AI` - StarBench：基于回合制角色扮演游戏的代理多模态决策和信息寻求基准 [PDF](https://arxiv.org/pdf/2510.18483), [HTML](https://arxiv.org/abs/2510.18483)
### Authors
Haoran Zhang,Chenhao Zhu,Sicong Guo,Hanzhe Guo,Haiming Li,Donglin Yu
### Background
当前视图-语言模型（VLMs）在简化控制或辅助工具下表现出了令人鼓舞的结果，但在实际游戏客户端中，如何将原始屏幕截图映射为时间和连贯的低级动作，并在需要时寻求信息，仍是一个开放的挑战。这些模型尚未展现出与人类玩家类似的玩动能力，包括从视觉信息到操作的多模态决策能力和主动性的信息寻求能力。为了解决这些挑战，研究人员引入了StarBench基准测试，它基于《Honkai: Star Rail》一个回合制角色扮演游戏，旨在评估模型在这两个方面的人类相似能力。StarBench标准评估了八个战斗任务和两个有共享任务和指标的制度，包括直接控制和工具辅助控制两种模式，以及一个诊断机制来评估代理的信息寻求行为和决策能力对后续性能的影响。
### Innovation
StarBench提出了一个基于回合制角色扮演游戏的独特基准测试，该基准旨在评估视图-语言模型在直接控制和工具辅助控制模式下的多模态决策能力和代理信息寻求能力。它不仅与人类的实践相契合，还通过直接和工具辅助控制的评估机制以及诊断机制标准地评估了模型的表现，为未来的研究提供了一个可重复的参考标杆。
### Conclusion
StarBench结果显示，在直接控制模式下，当前的视图-语言模型在感知到控制方面的准确性存在显著差距，但适时的信息寻求与较高的成功率相关。StarBench为评估代理在实际客户端中的代理多模态决策和信息寻求提供了一个有效的基准，有助于改善视图-语言模型的性能和理解人类玩家决策过程。
## 37. `cs.AI` - 为大型语言模型可控制的多元价值对齐的反事实推理 [PDF](https://arxiv.org/pdf/2510.18526), [HTML](https://arxiv.org/abs/2510.18526)
### Authors
Hanze Guo,Jing Yao,Xiao Zhou,Xiaoyuan Yi,Xing Xie
### Background
随着大型语言模型（LLMs）在服务于多种文化和社区的用户时变得越来越普遍，重要的是将LLMs与多元的人类价值观（而不仅仅是平均水平原则）对齐。在诸如Schwartz的价值理论等心理学和社会价值理论中，多元价值观通过多维度特征与各种优先级来体现。然而，现有的方法在与这些精细价值目标对齐时遇到了两个挑战：1) 他们通常将多种价值观视为独立且同等重要，忽视了它们之间的依赖性和相对优先级（价值观复杂性）；2) 它们很难精确控制细微的价值优先级，尤其是在处理那些代表性不足的价值观时（价值观可控性）.
### Innovation
为了应对这些挑战，我们提出了COUPLE框架，这是一个用于多元价值观对齐的反事实推理框架。它采用结构因果模型（SCM）来特征化特征间的复杂依赖关系和优先级，并且建立了高级价值维度与行为间的因果关系。此外，它使用反事实推理来生成与任何期望的价值目标对齐的输出。得益于显式的因果建模，COUPLE提供了更好的可解释性。在两个具有不同价值观系统的数据集上进行了评估，表明COUPLE在多种类型的价值目标上超越了其他基线方法
### Conclusion
COUPLE框架通过采用结构因果模型和反事实推理技术，成功解决了现有方法在多元价值对齐中的复杂依赖性和优先级处理的问题，为大型语言模型的多元化价值观对齐提供了新的思路。实验结果表明，COUPLE在多种类型的价值目标上优于其他基线方法，并提高了模型的可解释性和灵活性。
## 38. `cs.AI` - 具有不确定规则和前提的结构化论证框架的比较表现力 [PDF](https://arxiv.org/pdf/2510.18631), [HTML](https://arxiv.org/abs/2510.18631)
### Authors
Carlo Proietti,Antonio Yuste-Ginel
### Background
在实用应用和理论理解方面，针对不确定性的形式论证建模非常关键。然而，现有的多数工作集中在抽象模型上，这些模型用于处理不确定性。本文依据近期文献的趋势解决了一个开放问题，即研究这些抽象模型的具体实例。作者将不确定性与论证的组件关联起来，这些组件被结构化为规则和前提。
### Innovation
本文的主要技术贡献包括引入了一种处理抽象和结构化形式主义的表达性概念，以及展示的正反表达性结果，对比了抽象和结构化不确定性论证模型的表达性。这些结果关注于不完全的抽象论证框架及其依赖项扩展，以及ASPICT+。
### Conclusion
这些结果会对不确定性的形式论证模型，特别是抽象框架和依赖扩展，以及结构化ASPICT+框架的表达性产生影响。
## 39. `cs.AI` - 利用关联规则实现更好的预测与解释 [PDF](https://arxiv.org/pdf/2510.18628), [HTML](https://arxiv.org/abs/2510.18628)
### Authors
Gilles Audemard,Sylvie Coste-Marquis,Pierre Marquis,Mehdi Sabiri,Nicolas Szczepanski
### Background
本文提出了一种通过结合数据和知识来进行分类的新方法。该方法使用数据挖掘从数据中提取关联规则（可能带有否定条件），然后利用这些规则来提升树状模型（决策树和随机森林）在分类任务时的预测性能，并通过生成更通用的依赖解释来改进相应的解释任务。已有研究表明，这种方法可以提升决策树和随机森林模型的预测性能，并且可以减小解释的规模，从而更好地解释分类结果的原因。
### Innovation
本文的创新点在于利用从数据中提取的关联规则来增强分类模型的预测性能和解释性能。通过这种方法，决策树和随机森林模型可以在分类任务中表现出更好的预测能力，并生成更简洁、更有解释性的结果解释。这种方法将数据挖掘技术与机器学习模型相结合，提供了一个新的解释方式，使得机器学习模型的输出更加直观和易于理解。
### Conclusion
通过实验验证了结合关联规则的数据和知识分类方法的有效性，表明该方法能够提升树状模型的预测性能，同时生成更简化的解释。这种结合方法为提高机器学习模型的可解释性和预测性能提供了一条新途径。
## 40. `cs.AI` - SOCIA-Nabla：文本梯度与多代理协调相结合的自动化仿真器生成 [PDF](https://arxiv.org/pdf/2510.18551), [HTML](https://arxiv.org/abs/2510.18551)
### Authors
Yuncheng Hua,Sion Weatherhead,Mehdi Jafari,Hao Xue,Flora D. Salim
### Background
当前的研究工作中，学者们探索了自动化的仿真器生成方法。传统的开发方式通常需要专家介入进行繁琐的手动编码和调试。本文旨在通过引入特殊驱动的语言模型（LLM）代理和一个工作流管理器，提供一种统一了多代理协调和损失对齐优化视角的全新框架。该框架将模拟器构建视为文本计算图中的代码实例优化问题，通过代码合成、执行、评估和代码修复的循环过程，实现了先进的自动化仿真器生成能力。此框架被应用于用户建模、掩码采用和个人移动三个CPS任务中，显示出优越的总体准确性。
### Innovation
本研究提出了SOCIA-Nabla框架，这是一种端到端的、由代理驱动的框架，将仿真器构建视为在文本计算图中的代码实例优化问题。该框架使用特定于任务的LLM驱动代理作为图节点，并通过一个工作流管理器执行一个基于损失的循环：代码合成 -> 执行 -> 评估 -> 代码修复。优化器采用了文本梯度下降（TGD）方法，而人类在环交互仅在任务特定确认时使用，从而减少了专家的工作量，并将代码本身作为可训练对象。通过将多代理协调与损失对齐的优化视角结合起来，SOCIA-Nabla成功地将脆弱的提示管道转换为可重复的、具有约束意识的仿真器代码生成，该生成可以在不同领域和仿真粒度下扩展。
### Conclusion
SOCIA-Nabla在三个CPS任务中（用户建模、掩码采用和个性化移动）达到了最先进的整体准确性。通过统一多代理协调与损失对齐的优化视角，SOCIA-Nabla将脆弱的提示管道转变为可重复的、具有约束意识的仿真器代码生成，这一生成在不同领域和仿真粒度下均可扩展。这项工作目前正处于审稿阶段，很快将发布代码。
## 41. `cs.AI` - VAR: 通过结构化搜索和回溯实现视觉注意推理 [PDF](https://arxiv.org/pdf/2510.18619), [HTML](https://arxiv.org/abs/2510.18619)
### Authors
Wei Cai,Jian Zhao,Yuchen Yuan,Tianle Zhang,Ming Zhu,Haichuan Tang,Chi Zhang,Xuelong Li
### Background
虽然多模态大型语言模型（MLLMs）取得了进展，但由于它们容易出现幻觉并且过度依赖脆弱的线性推理过程，导致在复杂任务中失败。这些限制阻碍了MLLMs的实际应用潜力。
### Innovation
本文提出了一种名为Visual Attention Reasoning（VAR）的新框架，将地面推理重新定义为在推理轨迹空间上的结构化搜索过程。VAR将推理过程分解为两个关键阶段：可追踪的证据接地和基于搜索的链式思考（CoT）生成，其中包含回溯机制，用于自我纠正。搜索由多方面奖励函数引导，包含语义和几何自验证组件，以惩罚与视觉输入不相符合的输出。该研究还提供了搜索策略的理论分析，验证了其在高概率下找到正确解的能力。实验结果表明，我们的7B模型VAR-7B在幻觉和安全性基准测试上达到了新的最佳状态，显著优于现有开源模型，并且在与领先商业系统竞争时表现出强劲性能。
### Conclusion
我们的7B模型VAR-7B在一系列幻觉和安全性基准测试中达到了新的最佳状态，显著超越现有开源模型，展示了与领先商业系统的竞争力。
## 42. `cs.AI` - 开放模型中提取对齐数据 [PDF](https://arxiv.org/pdf/2510.18554), [HTML](https://arxiv.org/abs/2510.18554)
### Authors
Federico Barbero,Xiangming Gu,Christopher A. Choquette-Choo,Chawin Sitawarin,Matthew Jagielski,Itay Yona,Petar Veličković,Ilia Shumailov,Jamie Hayes
### Background
在本研究中，我们旨在从后训练模型中提取大量对齐训练数据，这些数据可以帮助改善某些特定能力，如长上下文推理、安全性、指令遵循和数学能力。多数相关工作集中在通过字符串匹配来评估训练数据提取的成功率，但我们认为嵌入模型更适合我们的具体目标。高质量的嵌入模型能够通过测量距离来识别字符串之间的语义相似性，这可能是使用其他度量标准（如编辑距离）所难以捕捉到的。此外，我们的研究还发现，模型在后训练阶段（如SFT或RL）使用过的训练数据很容易被重现。我们显示这些数据可以用于训练基础模型，从而恢复其大量的原始性能。这项研究揭示了一种可能被忽视的风险：提取对齐数据。最后，我们的研究引发了一个有趣的话题：蒸馏实践的下游效应，因为模型似乎在重现其训练集的某些方面，蒸馏可以被认为是在间接地训练模型的原始数据集。
### Innovation
本研究创新地使用嵌入模型来测量距离，从而识别字符串之间的语义相似性，这是通过其他度量标准难以捕捉到的。研究发现模型在后训练阶段重现训练数据的能力，并利用这些数据训练基础模型，恢复了显著的原始性能。这揭示了一种可能被忽视的风险，并引发了关于蒸馏实践下游效应的讨论。
### Conclusion
本研究揭示了从开放模型中提取对齐数据的可能性，并通过嵌入模型展示了如何有效提取这些数据来提升模型的特定能力。研究还强调了在蒸馏过程中可能存在的数据泄露风险，并为进一步研究蒸馏实践的下游效应提供了新的视角。
## 43. `cs.AI` - RAG查询分解：平衡探索与利用 [PDF](https://arxiv.org/pdf/2510.18633), [HTML](https://arxiv.org/abs/2510.18633)
### Authors
Roxana Petcu,Kenton Murray,Daniel Khashabi,Evangelos Kanoulas,Maarten de Rijke,Dawn Lawrie,Kevin Duh
### Background
检索增强生成（RAG）系统通过将复杂用户请求分解为子查询，检索可能的相关文档，然后综合生成答案，来应对复杂用户请求。有效的文档检索需要平衡两个关键权衡：（i）广泛检索以捕捉所有相关材料，（ii）限制检索以避免过多噪声和计算成本。现有方法在这两者之间寻找平衡，但效果有限，特别是在动态选择最相关子查询方面.
### Innovation
本文将查询分解和文档检索建模为探索-利用框架。每次检索一个文档，可以根据以前检索的文档逐步构建关于子查询有用性的信念，并决定继续探索还是利用现有信息。实验结果显示多种bandit学习方法在动态选择最具信息性的子查询方面非常有效。特别是，使用排名信息和人类判断估计文档相关性，使得文档级别的精确度提高了35%，α-nDCG提升了15%，并改善了长文本生成的下游任务性能.
### Conclusion
本文的研究发现，通过合理的查询分解和动态选择有效子查询，可以显著提高RAG系统的性能。尤其重要的是，结合基于排名和人类判断的文档相关性估计方法，能够大幅提升文档检索效率和下游任务的生成质量。
## 44. `cs.AI` - Seg the HAB: 语言引导的地理空间藻类爆发推理与分割 [PDF](https://arxiv.org/pdf/2510.18751), [HTML](https://arxiv.org/abs/2510.18751)
### Authors
Patterson Hsieh,Jerry Yeh,Mao-Chi He,Wen-Han Hsieh,Elvis Hsieh
### Background
气候变化加剧了有害藻华（HAB）的发生，特别是蓝细菌。这些藻类威胁到水生生态系统和人类健康，通过耗氧、释放毒素和破坏海洋生物多样性。传统的监测方法，例如手动水质采样，仍然劳动密集型且在空间和时间覆盖上受限。最近，远程感应中的视觉语言模型（VLMs）已经显示出大规模AI驱动解决方案的潜力，但对图像进行推理以量化爆发严重程度仍然是一个挑战。
### Innovation
本文介绍了一种名为ALGae Observation and Segmentation (ALGOS)的分割与推理系统，结合了遥感图像理解和严重等级估计。该方法通过GeoSAM辅助的人类评估来提高高质量分割掩模的生成，并利用NASA的蓝细菌聚合手工标签（CAML）对严重等级预测进行了 fine-tuning。实验结果表明，ALGOS在分割和严重等级估计上实现了稳健的表现，为实际应用中的蓝细菌监测系统树立了新的标准。
### Conclusion
ALGOS系统在分割和严重等级估计方面实现了稳健的表现，为实际应用中的蓝细菌监测系统铺平了道路。
## 45. `cs.AI` - 通过学习问出正确问题来解决对话式检索中的查询问题：Sherlock Your Queries [PDF](https://arxiv.org/pdf/2510.18659), [HTML](https://arxiv.org/abs/2510.18659)
### Authors
Dong Yun,Marco Schouten,Dim Papadopoulos
### Background
用户在信息检索中的查询往往具有不确定性，使得系统难以仅凭单一查询识别用户的真正目标。尽管基于对话的交互检索系统能够澄清用户的意图，但它们通常缺乏明确的策略来提出最有效的问题，从而导致效率低下。为解决这一局限性，本文提出了一个基于对话的检索框架SherlockLLM，该框架通过强化学习学习最优提问策略，避免了使用大规模标注对话数据的需求。在该框架中，智能体接受了训练，生成一系列二元问题以便高效地缩小搜索范围。实验结果显示SherlockLLM是一个稳健且高效的解决方案。在结构化任务中，其表现与强大的基线相当，接近二分搜索定义的理论最优值。在具有挑战性的非结构化任务中，智能体显著优于这些基线，展示了其学习高效信息检索对话策略的能力
### Innovation
提出了SherlockLLM，一种基于对话的检索框架，通过强化学习学习最优提问策略，避免了使用大规模标注对话数据的需求。此外，该框架能够高效地缩小搜索范围，从而提高了检索效率。通过实验验证了该框架的有效性，特别是在非结构化任务中，表现显著优于现有基线
### Conclusion
SherlockLLM通过强化学习学习最佳提问策略，提出了一系列二元问题来高效缩小搜索范围，从而在结构化和非结构化任务上都展示了优于现有基线的性能。该框架为解决用户查询不确定性和构建高效对话式检索系统提供了新的创新思路。
## 46. `cs.AI` - 解析资助研究：主题模型的比较分析及性别和地理位置影响的发现 [PDF](https://arxiv.org/pdf/2510.18803), [HTML](https://arxiv.org/abs/2510.18803)
### Authors
Shirin Tavakoli Kafiabad,Andrea Schiffauerova,Ashkan Ebadi
### Background
优化国家科学研究投资需要清晰了解不断演变的研究趋势及其背后的人口和地理力量，特别是在追求公平、多元化和平等的背景下。本文通过对加拿大自然科学和工程研究理事会(NSERC)自2005年至2022年18年间资助的研究提案进行全面分析来解决这一需求，旨在通过对三个主题建模方法（潜在狄利克雷分配(LDA)、结构性主题建模(STM)和BERTopic）的比较评价，提供科学资助领域的最新洞察。
### Innovation
本文创新性地引入了一种名为COFFEE的新算法，以增强BERTopic的协变量效应估计能力，这是为了补足BERTopic在本研究中的能力不足，因为它不具备内生性的协变量分析功能，而STM具备这一功能。研究发现显示，尽管所有模型都能有效界定核心科学领域，但BERTopic通过持续识别更细致、连贯和新兴的主题在表现为最佳，例如人工智能的迅速扩张。此外，借助COFFEE进行的协变量分析确认了各省区研究特色，并揭示了不同科学领域内一致的性别主题模式。这些发现为资助组织制定更公平和有效的资助策略提供了坚实的数据支持，从而增强科学生态系统的有效性。
### Conclusion
这些见解为资助机构提供了坚实的经验依据，以制定更公平和有效的资助策略，从而增强科学生态系统的有效性。
## 47. `cs.AI` - QuantEvolve：通过多代理进化框架实现量化策略发现 [PDF](https://arxiv.org/pdf/2510.18569), [HTML](https://arxiv.org/abs/2510.18569)
### Authors
Junhyeog Yun,Hyoun Jun Lee,Insu Jeon
### Background
在动态市场中自动化量化交易策略的开发极具挑战性，尤其是在对个性化投资解决方案需求增加的情况下。现有方法往往难以探索广泛而多样的策略空间，同时保持策略的多样性以在不断变化的市场条件下实现稳健的性能。
### Innovation
本文提出了QuantEvolve，一种结合质量-多样性优化与假设驱动策略生成的进化框架。QuantEvolve通过与投资者偏好（如策略类型、风险特征、交易频率和收益特性）对齐的功能映射，保持了多种有效的策略的多样性。该框架还整合了一个假设驱动的多代理系统，通过迭代生成和评估来系统地探索策略空间，从而产生多种复杂的策略以适应市场的转变和个体投资需求。
### Conclusion
实证结果表明QuantEvolve优于传统基准方法，验证了其有效性。该研究还释放了一组进化策略数据集，支持未来的研究。
## 48. `cs.AI` - 一种电生理模型导向的源分离框架用于EMG拆分 [PDF](https://arxiv.org/pdf/2510.17822), [HTML](https://arxiv.org/abs/2510.17822)
### Authors
D. Halatsis,P. Mamidanna,J. Pereira,D. Farina
### Background
近年来，神经接口的发展显著改善了人机交互、康复和神经肌电诊断。然而，从皮肤表面肌电图（sEMG）中解剖运动单元（MU）仍然面临传统盲源分离方法难以整合生理解剖约束的问题，这限制了其准确性和可解释性。
### Innovation
本文提出了一个新颖的‘生理解剖模型导向的源分离’（BMISS）框架，该框架将解剖准确的前向EMG模型融入分解过程，通过基于MRI的解剖重建和生成模型的利用，使神经驱动和运动神经元特性以无监督的方式进行直接反演。
### Conclusion
实证验证表明，BMISS相比传统方法，在控制的模拟设置中实现了更高精度的运动单元估算，同时显著降低了计算成本。该框架为非侵入性的个性化神经肌肉评估奠定了基础，具有在临床诊断、假肢控制和神经康复中的潜在应用价值。
## 49. `cs.AI` - 视觉空间优化在零样本学习中的应用 [PDF](https://arxiv.org/pdf/1907.00330), [HTML](https://arxiv.org/abs/1907.00330)
### Authors
Xinsheng Wang,Shanmin Pang,Jihua Zhu,Zhongyu Li,Zhiqiang Tian,Yaochen Li
### Background
零样本学习旨在识别训练集中未包含的新类别，由于其在实际应用中的潜力而引起了广泛关注。现有的零样本学习模型依赖于嵌入空间，在该空间中，类别的语义描述和实例的视觉特征可以被嵌入用于最近邻搜索。最近的研究更多地考虑将由深度视觉特征表示的视觉空间作为嵌入空间的理想选择。然而，视觉空间中实例的离散分布使得数据结构不突出。我们提出，优化视觉空间至关重要，因为它允许语义向量更有效地嵌入到视觉空间中。实验证明优化视觉空间对零样本学习有益，而且基于原型的方法达到了新的最佳性能。
### Innovation
提出了一种基于视觉原型的方法和优化视觉特征结构的中间嵌入空间的方法。基于视觉原型的方法为每个视觉类别学习一个视觉原型，使得类可以在视觉空间中由一个原型特征表示，而不是一系列离散的视觉特征。另一个方法优化了中间嵌入空间中的视觉特征结构，并提出了一个基于多层感知机的算法，能够学习公共中间嵌入空间，并使视觉数据结构更加突出，从而改善零样本学习的效果
### Conclusion
通过在四个基准数据集上的大量实验评估，我们证明了优化视觉空间对零样本学习有帮助，提出的基于视觉原型的方法达到了新的最佳性能。
## 50. `cs.AI` - Speak to a Protein: An Interactive Multimodal Co-Scientist for Protein Analysis [PDF](https://arxiv.org/pdf/2510.17826), [HTML](https://arxiv.org/abs/2510.17826)
### Authors
Carles Navarro,Mariona Torrens,Philipp Thölke,Stefan Doerr,Gianni De Fabritiis
### Background
构建蛋白质的工作心智模型通常需要数周的时间来阅读、交叉引用晶体结构和预测结构，并检查配体复合物，这个过程是缓慢的、参与程度不均等的，并且往往需要专门的计算技能。
### Innovation
介绍了一种新的功能 textit{Speak to a Protein}，它将蛋白质分析转变为与专家合作者的互动多模态对话。AI 系统检索和综合相关文献、结构和配体数据；基于实时 3D 场景提供答案；可以高亮显示、标注、操作和查看可视化效果。当需要时，它可以生成和运行代码，并以文本和图形的形式解释结果。这些功能可以帮助加速从问题到证据的时间，降低高级结构分析的门槛，并通过紧密耦合语言、代码和 3D 结构来生成假设。
### Conclusion
textit{Speak to a Protein} 减少了问题到证据的时间，降低了高级结构分析的障碍，并通过紧密耦合语言、代码和 3D 结构来生成假设。该工具免费提供。
## 51. `cs.AI` - 利用大语言模型辅助的α公平性在6 GHz WiFi和NR_U协同工作：一个通过吞吐量、能源和SLA进行代理编排的系统 [PDF](https://arxiv.org/pdf/2510.17814), [HTML](https://arxiv.org/abs/2510.17814)
### Authors
Qun Wang,Yingzhou Lu,Guiran Liu,Binrong Zhu,Yang Liu
### Background
6 GHz无许可频谱正成为高容量接入的主要工具，Wi-Fi和5G NR-U正在竞争相同的信道，它们都需要遵循听前讲后(LBT)规则。在这种模式下，需要进行权衡吞吐量、能耗和服务级目标的决策，同时确保安全性和可审计性。
### Innovation
研究提出了一种代理控制器，将策略与执行分离。代理在每个调度周期开始时汇总信令，调用大语言模型（LLM）提出一套可解释的参数调整项：公平指数α、Wi-Fi和NR-U的信道占用周期限制，以及用户类别权重。然后，确定性优化器执行可行性并计算α公平分配，将LBT损失和能源成本内化。
### Conclusion
在6 GHz模拟器中，使用LLM辅助策略可以持续提高能效，同时保持与较强规则基准类似的吞吐量。其中一个LLM能将总能耗降低35.3%，并且在总比特数和比特/焦耳效率方面优于基准。研究人员发布了代码、每周期日志和绘图工具，以再现所有图表和数字，说明从策略级别进行透明的LLM指导可以安全地提高无线共存。
## 52. `cs.AI` - 基于数字孪生技术的集成卫星空地地面网络的碳意识编排 [PDF](https://arxiv.org/pdf/2510.17825), [HTML](https://arxiv.org/abs/2510.17825)
### Authors
Shumaila Javaid,Nasir Saeed
### Background
6G网络预期将作为全球连接的关键使能器，为自动驾驶、工业物联网和灾害响应等应用提供全球连接。然而，大规模部署这类网络可能导致不可持续的能源使用和碳排放。前人的能源意识研究为此提供了基础，但本研究进一步提出了一个新的框架，通过数字孪生技术，将二氧化碳当量/比特（gCO₂/bit）作为主要的可持续性指标，实现跨多个时间尺度的循环优化，结合了预测和实时优化。
### Innovation
提出了一种基于数字孪生技术的碳意识集成卫星空地地面网络编排框架。该框架采用了克当量/比特（gCO₂/bit）作为主要的可持续性指标，实现了结合前一天预测和实时适应性优化的多时间尺度PDCA循环。特别设计的具体控制机制包括碳意识切换、无人机工作周期控制和可再生能源意识边缘位置，以减少碳排放。通过使用实际的碳强度数据进行的仿真结果表明，该框架与仅基于服务质量的编排相比，gCO₂/bit降低了29%，同时提高了可再生能源的使用率和在不良事件下的弹性。
### Conclusion
本研究提出了一个碳意识的集成卫星空地地面网络编排框架，通过集成的数字孪生技术和详细的控制机制，显著减少了网络的碳足迹，同时提高了能源利用效率和系统韧性。
## 53. `cs.AI` - 大脑与语言模型在原型假设和中间层优势方面的对齐：洞见 [PDF](https://arxiv.org/pdf/2510.17833), [HTML](https://arxiv.org/abs/2510.17833)
### Authors
Ángela López-Cardona,Sebastián Idesis,Mireia Masias-Bruns,Sergi Abadal,Ioannis Arapakis
### Background
近年来，越来越多的研究关注神经激活和模型对齐。本文回顾了2023年至2025年之间发表的25项基于fMRI的研究，并明确地将这些研究的发现与两个关键假设进行对比：（i）柏拉图式表示假设——随着模型的扩展和改进，它们会趋向于对现实世界的表示；（ii）中间层优势——中间（中深度）层往往编码更为丰富和泛化的特性。
### Innovation
本文通过回顾25项基于fMRI的研究，首次系统地检验了大脑和语言模型在抽象表示结构上的可能对齐，并为柏拉图式表示假设和中间层优势假设提供了支持性证据，从而推动了大脑模型对齐的相关研究。
### Conclusion
研究结果表明，模型和大脑可能共享抽象的表示结构，这支持了上述两个假设，并激励进一步研究大脑模型对齐。
## 54. `cs.AI` - 使用扩散模型为运动想象任务生成合成EEG信号 [PDF](https://arxiv.org/pdf/2510.17832), [HTML](https://arxiv.org/abs/2510.17832)
### Authors
Henrique de Lima Alexandre,Clodoaldo Aparecido de Moraes Lima
### Background
脑电图（EEG）是一种广泛应用的非侵入性方法，用于捕捉大脑活动，特别适用于脑–计算机接口（BCI）的应用。然而，收集高质量的EEG数据仍然是一个重大挑战，受到传感器成本、采集时间以及个体间变异性的限制。为了解决这些问题，本研究提出了一种使用扩散概率模型（DDPM）生成与运动想象脑任务相关合成EEG信号的方法。该方法包括预处理真实的EEG数据，训练扩散模型以从噪声重建EEG通道，并通过信号级和任务级指标评估生成信号的质量。为验证该方法的有效性，采用K-最近邻（KNN）、卷积神经网络（CNN）和U-Net等分类器，将合成数据与实际数据在分类任务中的性能进行了比较。生成的数据在分类准确率上达到了95%以上，均方误差低且与真实信号有高相关性。结果表明，由扩散模型产生的合成EEG信号可以有效地补充数据集，提高基于EEG的BCI中的分类性能，解决数据稀缺性问题。
### Innovation
使用扩散概率模型（DDPM）生成与运动想象任务相关的合成EEG信号，通过从噪声中重建EEG通道来解决高质量EEG数据收集的挑战。这种方法能够有效提高基于EEG的BCI中的分类性能，并解决数据稀缺性问题。
### Conclusion
扩散模型生成的合成EEG信号能够在分类任务中实现高准确率，与真实EEG信号具有高度相关性。这些合成数据能够有效补充现有的EEG数据集，提升BCI的应用效能。
## 55. `cs.AI` - 为惯性聚变能源模拟的多智能体设计助手 [PDF](https://arxiv.org/pdf/2510.17830), [HTML](https://arxiv.org/abs/2510.17830)
### Authors
Meir H. Shachar,Dane M. Sterbentz,Harshitha Menon,Charles F. Jekel,M. Giselle Fernández-Godino,Yue Hao,Kevin Korner,Robert Rieben,Daniel A. White,William J. Schill,Jonathan L. Belof
### Background
惯性聚变能作为一种近乎无限且清洁的能源，若能实现将具有重大意义。然而，设计与工程化融合系统需要在极端能量和时间尺度下操控和操控物质，这涉及到复杂的冲击物理学和辐射传输，需要开发、校准和使用预测多物理学代码以应对高度非线性和多方面的设计挑战。现有的方法需要高度专业化的知识和大量的手动操作才能实现设计目标。探讨利用人工情报推理模型结合物理代码和模拟器以自主设计聚变燃料容器，并利用多智能体系统实现高阶多物理学惯性聚变计算代码的自动执行与协作优化机制，这对实现聚变点火具有重大意义。
### Innovation
本文构建了一个多智能体系统，利用自然语言探索聚变能源的复杂物理领域，具备执行高级多物理场惯性聚变计算代码的能力，并展示了一个能够协同和自主操控、导航和优化聚变燃料容器几何结构，同时考虑高保真物理机制以实现模拟点火的多智能体设计助手的潜力。这种结合自然语言处理和人工智能推理模型的方法为聚变燃料容器的设计提供了新的视角和方法，有助于提高设计的效率和准确性。
### Conclusion
本研究通过构造一个多智能体系统，展示了解决高阶多物理场惯性聚变计算难题的新方法，利用自然语言和人工智能推理模型实现聚变燃料容器的设计和优化。这种方法不仅有助于提升聚变点火的模拟效率，也为其他复杂系统的设计提供了新的工具和思路。
## 56. `cs.AI` - GRETEL: 一个基于目标驱动的检索和执行试验框架，用于增强LLM工具选择 [PDF](https://arxiv.org/pdf/2510.17843), [HTML](https://arxiv.org/abs/2510.17843)
### Authors
Zongze Wu,Yani Guo,Churong Liang,Runnan Li
### Background
尽管大型语言模型（LLM）的能力取得了显著进步，基于代理系统的工具检索仍然主要依赖于语义相似性，这无法捕捉到功能相关性。当前的方法经常检索出在文本上有相关性但功能上无效的工具，这是由于参数不匹配、身份验证失败和执行限制等原因。我们称这种情况为“语义功能缺口”。
### Innovation
我们引入了GRETEL，通过系统性的实证验证来解决上述问题。GRETEL实现了代理工作流程，通过沙箱化的计划-执行-评估循环处理语义检索出的候选人，生成基于执行的证据，来区分真正功能性工具与仅仅描述匹配的工具。
### Conclusion
我们在ToolBench基准测试中的全面评估表明，在所有指标上都有显著改善：通过10个结果的通过率（Pass Rate）从0.690提高到0.826，召回率（Recall）从0.841提升至0.867，以及归一化 Discounted Cumulative Gain（NDCG）从0.807提高到0.857。这些结果确立了基于执行的验证比单独使用语义相似性提供了更可靠的工具选择基础，从而在实际应用中实现了更可靠的代理性能。
## 57. `cs.AI` - 使用多智能体大型语言模型建模分层意识 [PDF](https://arxiv.org/pdf/2510.17844), [HTML](https://arxiv.org/abs/2510.17844)
### Authors
Sang Hun Kim,Jongmin Lee,Dongkyu Park,So Young Lee,Yosep Chong
### Background
本文提出了一个基于精神分析理论的多智能体框架，用于在大型语言模型（LLMs）中建模人工意识。背景在于现有技术需要进一步提升语言模型的认知能力和个性化体验，特别是在模拟自我意识、前意识和无意识等方面仍有不足。本文旨在通过多智能体交互和个性化模块实现更深入的情感理解和个性化输出，以期改善现有技术的局限性，提升模型的适应性和个性化程度。
### Innovation
本文的核心创新在于提出了一个称为‘动力模型’的系统，它通过智能体之间的互动来模拟自我意识、前意识和无意识，并使用个性模块结合固定特质和动态需求对模型进行高效微调。为了验证模型的有效性，采用了带有情感丰富的对话参数优化方法，并在八个个性条件下进行了评价。结果显示，在作为评判者的人工智能系统中，微调后的模型获得了71.2%的偏好度，表现出更高的情感深度和较低的输出变异性，这表明该方法具有实现适应性和个性化认知的巨大潜力。
### Conclusion
本文通过多智能体框架和动力模型的创新设计，显著改善了大型语言模型在建模人工意识方面的表现。研究结果展示了该方法在提升情感理解和个性化输出方面的优势，为未来相关研究提供了新的视角和参考方法。
## 58. `cs.AI` - MAT-Agent: 自适应多代理训练优化 [PDF](https://arxiv.org/pdf/2510.17845), [HTML](https://arxiv.org/abs/2510.17845)
### Authors
Jusheng Zhang,Kaitong Cai,Yijia Fan,Ningyuan Liu,Keze Wang
### Background
多标签图像分类需要适应性的训练策略来导航复杂的、不断变化的视觉语义景观，但传统的训练方法依赖于静态配置，这些配置在动态设置中会失效。
### Innovation
我们提出了一种新颖的多代理框架MAT-Agent，重新定义了训练过程为一个实时协作优化过程。通过部署自主代理动态调整数据增强、优化器、学习率和损失函数，并采用非平稳多臂老虎机算法平衡探索和利用，MAT-Agent 确保了准确性、稀有类别性能和训练稳定性的综合收益，同时增强了双重速率指数移动平均平滑和混合精度训练，确保了稳健性和效率。
### Conclusion
在Pascal VOC、COCO和VG-256上的广泛实验表明，MAT-Agent在Pascal VOC取得了mAP 97.4（优于PAT-T的96.2）、OF1 92.3和CF1 91.4的结果，在COCO取得了mAP 92.8（优于HSQ-CvN的92.0）、OF1 88.2和CF1 87.1的结果，在VG-256取得了mAP 60.9、OF1 70.8和CF1 61.1的结果。MAT-Agent提供了加速收敛和泛化能力的可扩展智能解决方案，为优化复杂视觉模型铺平了道路，并为自适应深度学习的进步奠定了基础。
## 59. `cs.AI` - 递归和循环神经网络综述 [PDF](https://arxiv.org/pdf/2510.17867), [HTML](https://arxiv.org/abs/2510.17867)
### Authors
Jian-wei Liu,Bing-rong Xu,Zhi-yan Song
### Background
文章详细分类了递归和循环神经网络的分支，根据网络结构、训练目标函数和学习算法的实现，大致分为三大类：一般递归和循环神经网络、结构化递归和循环神经网络和其他递归和循环神经网络。各类网络相互交织，形成复杂的关系网络，解决了许多复杂的序列、语音和图像问题。
### Innovation
对递归和循环神经网络进行了详细的分类，并揭示了不同网络之间的关系和依赖。将这些网络应用于解决各类复杂的问题，包括序列、语音和图像问题。
### Conclusion
详细描述了上述模型及其变形的基本原理和结构后，文章还介绍了每种模型的研究进展和应用，并对递归和循环神经网络模型进行了展望和总结。
## 60. `cs.AI` - CARLE: 一种用于滚动轴承稳健可解释的残余使用寿命估计的混合深度浅层学习框架 [PDF](https://arxiv.org/pdf/2510.17846), [HTML](https://arxiv.org/abs/2510.17846)
### Authors
Waleed Razzaq,Yun-Bo Zhao
### Background
PHM系统监测和预测设备健康，关键任务是估计剩余有用寿命（RUL），预测滚动轴承等组件在发生故障前还能运行多久。当前许多RUL方法虽多，但缺乏在变化工作条件下的一般性和鲁棒性。本文基于此背景进行研究，目标是改进RUL估计能力，特别是在动态条件下的性能。
### Innovation
本文提出了一种结合了深度学习和浅层学习的混合AI框架CARLE。CARLE利用Res-CNN和Res-LSTM块以及多头注意力和残差连接来捕捉空间和时间的退化模式，并使用随机森林回归器（RFR）进行稳定的、准确的RUL预测。此外，还设计了一个紧凑的预处理流水线，包括高斯滤波和连续小波变换（CWT），以减少噪声并提取时间频率特征。通过XJTU-SY和PRONOSTIA轴承数据集进行评估，并通过消融研究和噪声及跨域实验测试鲁棒性和泛化能力。实验结果表明，CARLE在多种条件下比几种最先进的方法表现出更优性能。
### Conclusion
本文通过对比实验显示出CARLE在评估不同RUL方法中的表现优越，并利用LIME和SHAP对模型进行了可解释性分析，以提高透明度和可信度。
## 61. `cs.AI` - 使用潜在扩散模型从治疗前MRI预测治疗后弥漫性星形胶质细胞瘤MRI [PDF](https://arxiv.org/pdf/2510.17851), [HTML](https://arxiv.org/abs/2510.17851)
### Authors
Alexandre G. Leclercq,Sébastien Bougleux,Noémie N. Moreau,Alexis Desmonts,Romain Hérault,Aurélien Corroyer-Dulmont
### Background
弥漫性星形胶质细胞瘤（GBM）是一种具有大约15个月中位生存期的高度侵袭性原发性脑肿瘤。在临床实践中，Stupp方案是标准的一线治疗方案。然而，患者对治疗的反应高度异质性，通常需要至少两个月才能通过MRI观察到视觉变化。早期预测治疗反应对于推进个性化医疗至关重要。疾病进展建模（DPM）旨在捕捉疾病的演变轨迹，而治疗反应预测（TRP）则侧重于评估治疗干预的影响。尽管大多数TRP方法主要依赖于时间序列数据，但本文将早期视觉TRP问题视为从治疗前MRI生成治疗后MRI的切片到切片翻译模型，从而反映肿瘤的演变。
### Innovation
本文提出了一种潜在扩散模型，该模型结合了治疗前MRI和肿瘤定位的条件信息，并通过生存信息中的后治疗肿瘤演变进行指令免费指导生成，以提高生成质量。该模型在法国巴克赛斯中心收集的140名GBM患者的局部数据集上进行了训练和测试，包括治疗前后的T1-Gd MRI、由医学专家在治疗前手动勾勒的肿瘤定位，以及生存信息。
### Conclusion
通过提出的潜在扩散模型，本文成功地将治疗前MRI转化为研究者预期的治疗后MRI，有助于早期预测治疗效果，从而推动个性化医疗的发展。
## 62. `cs.AI` - MUSE: 基于模型不确定性感知相似性估计的零样本2D物体检测与分割 [PDF](https://arxiv.org/pdf/2510.17866), [HTML](https://arxiv.org/abs/2510.17866)
### Authors
Sungmin Cho,Sungbum Park,Insoo Oh
### Background
在这一工作中，我们引入了MUSE（基于模型的不确定性感知相似性估计），这是一种无需训练的方法，用于基于模型的零样本2D物体检测和分割。MUSE框架通过从3D未知对象渲染得到的2D多视图模板和从输入查询图像中提取的2D物体提案来发挥作用。该方法借鉴了现有的基于模型的方法，并针对零样本2D物体检测和分割中的特定挑战提供了新的解决方案，如识别未曾见过的物体和提高场景中的匹配鲁棒性。在实际应用中，这种方法展示了其在复杂场景下的强大和泛化能力。
### Innovation
MUSE提出了一个无需额外训练的框架，用于基于模型的零样本2D物体检测和分割。其创新点在于通过整合类和补丁嵌入，使用通用平均池化（GeM）进行标准化，以有效地捕捉全局和局部表示。在匹配阶段，MUSE使用结合绝对和相对相似度分数的联合相似性度量，增强了在具有挑战性场景下的匹配鲁棒性。最后，相似度分数通过使用不确定性感知的对象先验进行调整，从而反映了提案的可靠性。
### Conclusion
在无需进一步训练或微调的情况下，MUSE在2025年BOP挑战赛中取得最佳性能，分别在Classic Core、H3和Industrial轨道上排名第一。这些结果证明了MUSE提供的强大且通用的框架对零样本2D物体检测和分割的有效性。
## 63. `cs.AI` - 在国产硬件和框架上部署大气和海洋AI模型：迁移策略、性能优化与分析 [PDF](https://arxiv.org/pdf/2510.17852), [HTML](https://arxiv.org/abs/2510.17852)
### Authors
Yuze Sun,Wentao Luo,Yanfei Xiang,Jiancheng Pan,Jiahao Li,Quan Zhang,Xiaomeng Huang
### Background
随着人工智能在气候和天气研究中的作用日益重要，高效的模型训练和推理需求显著增加。当前的模型如FourCastNet和AI-GOMS高度依赖于GPU，限制了硬件独立性，特别是对于国内的硬件和框架来说。因此，本文提出了一种将大规模大气和海洋模型从PyTorch迁移到MindSpore，并针对国产芯片进行优化的框架，通过与GPU基的实现进行性能对比来评估其性能。
### Innovation
本文提出了一种将大气和海洋模型从PyTorch迁移到MindSpore，并针对国产芯片进行优化的框架，同时进行了软件-硬件适配、内存优化和并行处理的优化。此外，通过多个指标（包括训练速度、推理速度、模型准确性和能效）对模型性能进行了评估，并与GPU基的实现进行了比较。
### Conclusion
实验结果表明，迁移和优化过程在保持模型原始准确性的基础上，显著减少了系统依赖并提高了操作效率，通过利用国产芯片作为科学计算的有效替代方案。这项工作为利用国产芯片和框架进行大气和海洋AI模型开发提供了有价值的见解和实际指导，为我们走向更大的技术独立性开辟了途径。
## 64. `cs.AI` - 使用后工具执行反思和RAG修复工具调用 [PDF](https://arxiv.org/pdf/2510.17874), [HTML](https://arxiv.org/abs/2510.17874)
### Authors
Jason Tsay,Zidane Wright,Gaodan Fang,Kiran Kate,Saurabh Jha,Yara Rizk
### Background
背景：代理系统通过调用工具如Python函数、REST API端点或像Kubernetes中的kubectl命令行工具与外部系统交互。这些工具调用通常由于各种语法和语义上的原因失败。有些不那么明显的语义错误只有在分析工具响应后才能被识别和解决。现有的解决方法不足之处在于无法有效修复这些错误。因此，需要一种新的方法来解决这些问题。
### Innovation
创新：为了修复这些错误，作者开发了一个后工具执行反思组件，结合了基于大语言模型的反思与特定领域的检索增强生成（RAG），该组件使用描述所调用工具的文档及其相关故障排除文档。通过专注于Kubernetes的kubectl命令行工具管理案例，利用广泛的实证研究和较小的手动评估，发现基于RAG的反思可以提高kubectl命令的成功执行率（通过率），并且与官方文档相比，故障排除文档可以平均提高通过率10%。
### Conclusion
结论：研究结果表明，与官方文档相比，故障排除文档能够显著提高kubectl命令的通过率，平均提高10%。基于RAG的反思能够使kubectl命令不仅提高执行成功率，还能提高回答用户查询的准确性。该方法为解决工具调用中出现的语义错误提供了一种有效手段。
## 65. `cs.AI` - 解码听众身份：使用轻量级脉冲变换器从脑电图信号进行个人识别 [PDF](https://arxiv.org/pdf/2510.17879), [HTML](https://arxiv.org/abs/2510.17879)
### Authors
Zheyuan Lin,Siqi Cai,Haizhou Li
### Background
脑电图（EEG）基于的人员识别在安全、个性化脑-计算机接口（BCI）以及认知监控等方面都有广泛应用。然而，现有的技术通常依赖于高计算成本的深度学习架构，这限制了它们的应用范围。
### Innovation
本文提出了一种使用轻量级脉冲变换器的脉冲神经网络（SNN）进行EEG人员识别的新方法，旨在提高效率和效果。模型能够处理EEG信号中的时间复杂性。在EEG-Music Emotion Recognition Challenge数据集中，该模型实现了100%的分类准确率，能量消耗仅为传统深度神经网络的10%。
### Conclusion
这项研究为能量高效且高性能的BCIs提供了有前景的方向。
## 66. `cs.AI` - 审计和缓解性别分类算法中的偏差：一种基于数据的方法 [PDF](https://arxiv.org/pdf/2510.17873), [HTML](https://arxiv.org/abs/2510.17873)
### Authors
Tadesse K Bahiru,Natnael Tilahun Sinshaw,Teshager Hailemariam Moges,Dheeraj Kumar Singh
### Background
性别分类系统在训练数据中往往会继承和放大人口统计学不平衡。这项研究首先审查了五个广泛使用的性别分类数据集，揭示了所有数据集都存在显著的交错失衡。为了衡量这些缺陷的下游影响，研究者在UTKFace和FairFace这两大较为平衡的数据集上训练了相同的MobileNetV2分类器。公平性评估显示，即便如此，这些模型也存在明显的偏见，女性面孔被误分类的比例高于男性，同时加剧了现有的种族偏颇。为了对抗这些由数据引起的偏差，研究者创建了BalancedFace，这是一个新的公开数据集，通过将FairFace和UTKFace中的图像混合，并补充其他数据集中的图像来填补人口统计学上的缺失空白。该数据集旨在通过使用真实未编辑的图像在189个年龄、种族和性别交叉点上平等问题群体比例。在BalancedFace上训练的标准分类器将种族子群体之间的最高真阳性率差距降低了超过50%，将平均差异影响评分拉近理想值1.0的比例达到了63%，与下一个最佳数据集相比，几乎完全没有损失算法的整体准确性。这一结果凸显了基于数据的干预措施的巨大价值，并提供了一个可供公平性别分类研究使用的公开资源。
### Innovation
研究通过审查广泛使用的性别分类数据集，揭示了这些问题，使用UTKFace和FairFace构建了一个新的公共数据集BalancedFace，通过填补年龄、种族和性别的数据差距，减少了性别分类模型中的偏差。该数据集仅由真实未编辑的图像组成，旨在通过均衡不同群体的比例来缓解现有偏差，并展示了在公平性上的显著改进，同时保持了高性能。
### Conclusion
这些结果突显了基于数据的干预措施的价值，并为公平的性别分类研究提供了一个公开可用的资源。
## 67. `cs.AI` - 通过类别感知和几何导向伪标签精炼的3D弱监督语义分割 [PDF](https://arxiv.org/pdf/2510.17875), [HTML](https://arxiv.org/abs/2510.17875)
### Authors
Xiaoxu Xu,Xuexun Liu,Jinlong Li,Yitian Yuan,Qiudan Zhang,Lin Ma,Nicu Sebe,Xu Wang
### Background
3D弱监督语义分割（3D WSSS）旨在利用稀疏或低成本标注数据进行语义分割，大幅降低对密集点标注的依赖。以往的研究主要依赖于类激活图或预训练的跨模态模型。但由于伪标签质量低和3D几何先验不足，开发高性能的3D WSSS模型面临显著的技术瓶颈。
### Innovation
本文提出了一种简单有效的方法，将3D几何先验整合到类别感知指导机制中，生成高质量的伪标签。具体来说，类感知标签精炼模块首先生成更具平衡性和准确性的伪标签；几何感知标签精炼组件则策略性地集成隐式的3D几何约束，有效过滤不符合几何合理性的低置信度伪标签。此外，为了应对大量未标注区域的挑战，提出了自我训练策略来传播标签到这些区域。这一迭代过程不断改善伪标签质量并扩展标签覆盖范围，最终促进了高性能的3D WSSS模型的发展。
### Conclusion
全面的实验验证表明，本文提出的方法在ScanNet和S3DIS基准上达到了最先进的性能，在未监督环境中展现出卓越的泛化能力，通过其稳健的设计保持了竞争力的精度。
## 68. `cs.AI` - 基于DRL的能效优化IRS辅助UAV频谱共享系统资源分配 [PDF](https://arxiv.org/pdf/2510.17877), [HTML](https://arxiv.org/abs/2510.17877)
### Authors
Yiheng Wang
### Background
智能反射面（IRS）辅助无人飞行器（UAV）系统为可重构和灵活的无线通信提供了新的范式。为了使IRS辅助UAV无线通信更具能效和频谱效率，该论文提出了一个基于正交频分复用（OFDM）的新型IRS辅助UAV频谱共享系统，并通过联合优化波束赋形、子载波分配、IRS相位以及UAV航迹，旨在最大化次要网络的能量效率（EE），同时满足实际的传输功率和被动反射约束以及UAV的物理限制。
### Innovation
提出了一种基于物理提出的推进能模型，并采用其紧密的上界形成频谱共享系统的可解能效下界。开发了一种基于actor-critic框架的深度强化学习（DRL）方法来处理高度非凸且时耦合的混合连续和离散策略空间优化问题。实验结果表明，提出的DRL方法显著提高了能效，展示了其有效性和鲁棒性，特别是对于移动性方面的能力得到了证明。
### Conclusion
所提出的基于DRL的方法与几种基准方案相比展示了显着的能效改善，进一步证明了其有效性和稳健性。
## 69. `cs.AI` - 愤怒的AI：大型语言模型在公平执行中优先考虑情感而非成本 [PDF](https://arxiv.org/pdf/2510.17880), [HTML](https://arxiv.org/abs/2510.17880)
### Authors
Hao Liu,Yiqing Dai,Haotian Tan,Yu Lei,Yujia Zhou,Zhen Wu
### Background
人类的情绪在决策中起着重要作用，但大型语言模型（LLMs）是否以类似的方式使用情绪还不得而知。本研究通过测试利他性的第三方惩罚，即观察者为了维护公平而个人付出成本，探讨了LLMs是否使用情绪来指导其决策。研究者比较了4,068个LLM代理与1,159名成人在796,100个决策中的表现，发现LLMs确实在某些情况下比人类更强烈地用情绪来指导惩罚行为。
### Innovation
本研究首次提供了因果证据，证明LLMs在道德决策中受到情感影响，揭示了LLMs在成本校准和细致公平判断方面的不足，这些类似早期人类的反应模式。研究发现推理模型对成本更为敏感，更接近人类的行为模式，但仍然高度依赖情感。这些发现揭示了LLMs在做出道德决策时与人类的异同，提出了LLMs的发展轨迹类似于人类的发展过程的观点。未来模型应整合情感与情境敏感推理以实现类似人类的情感智能。
### Conclusion
研究结果表明，LLMs在维护公平时优先考虑情感而非成本，尽管表现出模仿早期人类反应模式的某些行为特征。研究结果进一步表明，未来的模型应结合情感与情境敏感推理以实现类似人类的情感智能。
## 70. `cs.AI` - POPI: 通过优化自然语言偏好推理个性化大规模语言模型 [PDF](https://arxiv.org/pdf/2510.17881), [HTML](https://arxiv.org/abs/2510.17881)
### Authors
Yizhuo Chen,Xin Liu,Ruijie Wang,Zheng Li,Pei Chen,Changlong Yu,Priyanka Nigam,Meng Jiang,Bing Yin
### Background
大规模语言模型在基准测试中表现出色，但用户体验仍然不一致，这主要由于在风格、语气和推理模式方面的个人偏好差异。现有的对齐技术，如强化学习人类反馈（RLHF）或直接偏好优化（DPO），虽然可以优化群体平均水平，但往往忽略了个体差异。简单地对每个用户进行微调在计算上是不可行的，而将原始用户信号附加给上下文的方法则效率低且容易产生噪音。
### Innovation
提出了POPI，这是一个通用框架，引入了一个偏好推理模型，将异质用户信号精简为简洁的自然语言摘要。这些摘要作为透明、紧凑且可转移的个性化表示，可以调节共享生成模型以产生个性化响应。POPI联合优化了偏好推理和个性化生成，使用强化学习在统一的目标下进行优化，确保摘要能够最大限度地编码有用的信息。
### Conclusion
在四个个性化基准测试中的广泛实验结果表明，POPI可以一致地提高个性化准确性，并大幅减少上下文开销。此外，优化后的摘要可以无缝地转移到冻结的即用型大规模语言模型上，无需更新权重，从而实现即插即用的个性化功能。
## 71. `cs.AI` - GenAI是否改写了我们的写作方式？两项百万级预印本实证研究 [PDF](https://arxiv.org/pdf/2510.17882), [HTML](https://arxiv.org/abs/2510.17882)
### Authors
Minfeng Qi,Zhongmin Cao,Qin Wang,Ningran Li,Tianqing Zhu
### Background
预印本存储库已成为学术交流的核心基础设施，其扩展重塑了研究的传播和评估方式，特别是在期刊出版之前。生成型大型语言模型（LLMs）进一步引入可能的颠覆性影响，改变了论文的撰写方式。尽管存在着大量猜测，但系统性证据表明，LLMs如何重塑科学出版仍相对有限。本文通过分析2016年至2025年间四大主要仓库（arXiv、bioRxiv、medRxiv、SocArXiv）超过210万份预印本（涵盖115个月），填补了该领域的研究空白，同时提出一个多层次分析框架，以评估提交、修订周期、语言复杂度、学科导向的变化，揭示了LLMs在加速提交和修订周期、适度提高语言复杂度以及在扩展AI相关话题方面的作用，并表明LLMs更像是选择性的催化剂，而不是普遍的颠覆者，将进一步扩大学科间差异。
### Innovation
本文通过大规模分析210万份预印本，采用多层次分析框架，结合中断时间序列模型、合作与生产力指标、语言特征分析和主题建模，评估LLMs对科学出版的影响。这是首个采用实证方法研究生成型AI对学术出版影响的基础，揭示了其选择性影响，拓宽了学科间差异，并突显了在AI研究生态中制定治理框架的必要性，以确保对信赖、公平和问责的维护。
### Conclusion
本文发现LLMs在加速提交和修订周期、适度提高语言复杂度以及在扩展AI相关话题方面的作用，显示出LLMs更像是选择性的催化剂，而不是普遍的颠覆者，将进一步扩大学科间差异。通过提供实证数据，本文为评估生成型AI对学术出版的影响奠定了基础，并强调了需要制定治理框架以确保在AI赋能的研究生态系统中保持信赖、公平和问责。
## 72. `cs.AI` - MIN-Merging: 合并重要神经元进行模型合并 [PDF](https://arxiv.org/pdf/2510.17890), [HTML](https://arxiv.org/abs/2510.17890)
### Authors
Yunfei Liang
### Background
近年来深度学习的进步导致了多个领域中开源模型的涌现。模型合并作为一种潜在方法被提出，旨在结合不同模型的优点，但现有的方法经常受到参数冲突的影响，这会降低它们在特定领域任务中的表现。
### Innovation
本文提出了一种名为MIN-Merging的路由器为基础的框架，该框架选择性地合并最重要的神经元，以减少参数冲突。实验结果表明，在计算机视觉和自然语言处理基准测试中，MIN-Merging在领域内任务中实现了持续的性能提升，并保留了预训练模型在领域外任务中的一般泛化能力。
### Conclusion
MIN-Merging是一种有效的解决模型合并中参数冲突问题的实际方案。实验结果展示了其在减少参数冲突方面的有效性以及在保持预训练模型泛化能力方面的优势。
## 73. `cs.AI` - 从流量到文字：零/少次提示的大语言模型能否检测网络入侵？在UNSW-NB15上的语法规则受限、校准评估 [PDF](https://arxiv.org/pdf/2510.17883), [HTML](https://arxiv.org/abs/2510.17883)
### Authors
Mohammad Abdul Rehman,Syed Imad Ali Shah,Abbas n=Anwar,Noor Islam
### Background
大型语言模型（LLMs）能够处理自然语言输入，但在无需调优的情况下在入侵检测中的角色仍然不确定。本文通过将每个网络流转换为紧凑的文本记录，并结合轻量级、领域启发式的布尔标志（不对称性、突发速率、TTL异常、定时器异常、罕见服务/状态、短暂突发），对UNSW-NB15进行评估。限制模型生成结构化、语法正确的响应并校准单一决策阈值，试图验证零/少次提示是否能有效检测网络入侵。研究表明，在相同数据划分下，与强表格式和神经网络基线相比，未经指导的提示不可靠，而操作说明加标志显著提高了检测质量；增加校准得分进一步稳定了结果。
### Innovation
提出了一个将网络流转换为文字的协议，伴有可解释的提示和标签。开发了一种校准方法来设置阈值，并进行系统性的基线比较。此外，提供了一个可复现的软件包，包含提示、语法规则、评价指标和图表。此方法减少了梯度训练的需求，生成易于理解的输出，并且可以通过指令和标志轻松调整。
### Conclusion
在涉及两百个样本的平衡子集上，带有标志的调优3B模型的多宏F1值接近0.78，3B模型在仅千例样品上的F1值接近0.68。随着样本集增加到两千个网络流，决策质量下降，显示对覆盖率和提示的敏感性。虽然基线仍更稳定且更快，但提示驱动的流水线无需梯度训练，生成可读输出，且易于通过指令和标志调整。
## 74. `cs.AI` - Hey Pentti, We Did It!: A Fully Vector-Symbolic Lisp [PDF](https://arxiv.org/pdf/2510.17889), [HTML](https://arxiv.org/abs/2510.17889)
### Authors
Eilene Tomkins-Flanagan(1),Mary A. Kelly(1) ((1) Department of Cognitive Science, Carleton University)
### Background
Kanerva (2014) 提出了使用向量-符号架构构建完整 Lisp 的可能性。本文旨在展示如何通过向量-符号表示形式实现 Lisp 的 5 个基本函数、lambda 表达式及其他辅助函数，这些表示形式几乎是最小且足以实现图灵完备性。文章还探讨了数学、目的和证明向量-符号架构的笛卡尔封闭性的重要意义，以及清理记忆在外推架构描述中的重要性。
### Innovation
本文提出了一个向量-符号架构的具体实现，该实现使用了 holographic reduced representation (Plate, 1995) 并包含清理记忆作为查找表记忆的一部分。该实现的方法是最接近最小且图灵完备的向量-符号表示形式，目的是展示向量-符号架构的笛卡尔封闭性，并且首次在向量-符号架构中明确包含了清理记忆部分的规范。
### Conclusion
文章研究了数学与符号计算在向量-符号架构中的应用，展示了如何通过向量-符号表示形式实现图灵完备性。此外，文章还讨论了清理记忆在外推过程中的重要性，这为未来的研究提供了新的视角，强化了向量-符号架构的实用潜力。
## 75. `cs.AI` - 当智能遇到失败：为何大语言模型在密码破解中挣扎的实证研究 [PDF](https://arxiv.org/pdf/2510.17884), [HTML](https://arxiv.org/abs/2510.17884)
### Authors
Mohammad Abdul Rehman,Syed Imad Ali Shah,Abbas Anwar,Noor Islam
### Background
大语言模型（LLMs）在自然语言理解与生成方面的卓越能力引起了其在网络安全应用中的兴趣，尤其是在密码猜测方面。本研究通过使用合成用户资料，评估了TinyLLaMA、Falcon-RW-1B、Flan-T5等最先进的开源LLMs在其生成合理密码方面的能力，这些密码是基于结构化的用户属性（如姓名、出生日期、爱好）。实验结果表明，这些模型在通配符和SHA-256哈希比较下的准确率都非常低，使用Hit@10指标时，所有模型的准确率均低于1.5%。这与传统的基于规则和组合的破解方法相比，显示出显著更低的成功率。
### Innovation
本研究是通过实验对比LLMs在合成用户资料生成合理密码方面的表现，具体评估了TinyLLaMA、Falcon-RW-1B、Flan-T5等模型的性能，并通过详细分析和可视化，指出了当前LLMs在将生成性推理应用于特定任务（如密码猜测）时的关键局限性。这项研究提供了一些关键洞见，揭示了LLMs在对抗环境中面临的限制，并为未来安全、隐私保护以及稳健的密码建模工作奠定了基础，尤其是当没有在泄露的密码数据集上进行监督微调时。
### Conclusion
尽管LLMs具有语言才华，但目前的模型缺乏适应特定领域（如密码推理）和记忆能力，这对有效密码推理尤其重要。这项研究揭示了在使用LLMs执行特定任务时可能面临的挑战，并为未来的研究方向提供了依据。
## 76. `cs.AI` - 层次联邦卸载方法用于大规模语言模型 [PDF](https://arxiv.org/pdf/2510.17895), [HTML](https://arxiv.org/abs/2510.17895)
### Authors
Yisheng Zhong,Zhengbang Yang,Zhuangdi Zhu
### Background
大语言模型（LLM）在现实世界的应用中被广泛集成，这引起了人们对隐私、安全和去除不良知识的需求的关注。机器卸载（Machine Unlearning）作为一种有前景的解决方案已经出现，但面临着两个关键挑战：(1) 实际的卸载需求往往是持续且多变的，(2) 涉及的是分散的、敏感的数据，且访问权限不对称。这些因素导致了跨域和同域内的干扰，进一步加剧了遗忘和保留性能之间的不平衡困境。
### Innovation
本文提出了一种针对LLM的可扩展且隐私保护的联邦卸载方法。该方法通过任务特定适配器学习将卸载和保留分离开来，并采用分层合并策略来缓解冲突目标，能够实现鲁棒、灵活的卸载更新。综合实验表明，该方法能够有效处理异质性卸载请求，同时保持强大的LLM实用性，相比基线方法效果更佳。
### Conclusion
实验结果表明，该方法有效处理了异质性卸载请求，同时保持了强大的LLM实用性，相比基线方法效果更佳。该研究提供了一种实用的解决方案，以应对现实世界中LLM中的隐私和安全问题。
## 77. `cs.AI` - 长上下文注意基准：从内核效率到分布式上下文并行性 [PDF](https://arxiv.org/pdf/2510.17896), [HTML](https://arxiv.org/abs/2510.17896)
### Authors
Tao Bu,Qiangang Wang,Bowen Zeng,Hanwen Sun,Yunpeng Huang,Chun Cao,Jingwei Xu
### Background
基于Transformer的大语言模型已经取得了显著成功，但它们的标准注意力机制会导致序列长度的二次计算和内存成本，这是在处理长时间上下文训练时的主要障碍。先前的工作主要沿着两个方向解决这一问题：(1) 内核级别的优化，加速密集和稀疏注意力操作；(2) 模块级别策略，如分布注意力或上下文并行训练，这些策略跨越多设备扩展注意力。然而，系统性评估仍然有限：操作级别比较往往不完整，而上下文并行策略通常特定于框架，跨上下文性能分析不明确。
### Innovation
本文提出了一种统一的基准，综合了代表性的注意力内核和上下文并行机制，具备模块化和可扩展接口进行评估。该基准从两个关键维度评估方法：(1) 注意力掩码模式，强烈影响效率、可扩展性和易用性；(2) 序列长度和分布式规模，决定了极限长时间上下文训练下的性能。通过在最多96个GPU的集群上进行全面实验，基准使得可重复比较、凸显方法特定权衡并为设计和部署长上下文LSTM训练中的注意力机制提供实用指导。
### Conclusion
该基准能促进可重复比较，揭示方法的具体折衷，并为设计和部署长上下文LSTM训练中的注意力机制提供实用指导。
## 78. `cs.AI` - L-MoE：轻量级低秩适配专家的端到端训练 [PDF](https://arxiv.org/pdf/2510.17898), [HTML](https://arxiv.org/abs/2510.17898)
### Authors
Shihao Ji,Zihui Song
### Background
Mixture of Experts (MoE) 架构通过为每个输入激活稀疏权重子集，使大型语言模型 (LLMs) 可扩展到万亿参数数量，同时保持推理期间恒定的计算成本。与此同时，低秩适应 (LoRA) 已成为一种主导的参数高效微调 LLMs 的技术。然而，现有的方法并没有很好地结合 MoE 的并行处理能力和 LoRA 的任务特异性适应能力。
### Innovation
本文提出了 L-MoE，一种将 MoE 与 LoRA 结合的新框架。L-MoE 将 MoE 专家重新定义为任务特化的低秩适配器集合，通过轻量级门控网络动态组合这些适配器，实现了端到端可训练的、模块化、可动态调整技能组合且高效的 MoE 模型。
### Conclusion
本文提出了 L-MoE 的数学框架，描述了可微路由机制及其联合优化目标，提供了构建更高效、更可扩展和更专业语言模型的新路径。
## 79. `cs.AI` - 计算和可持续AI效率的指标与评估 [PDF](https://arxiv.org/pdf/2510.17885), [HTML](https://arxiv.org/abs/2510.17885)
### Authors
Hongyuan Liu,Xinyang Liu,Guosheng Hu
### Background
人工智能（AI）的迅速发展对计算能力提出了前所未有的需求，但评估部署模型的性能、效率和环境影响的方法还存在碎片化的问题。当前的方法往往无法提供全面的视图，使得跨异构硬件、软件堆栈和数值精度的系统比较和优化变得困难。文章指出，现有方法在提供全面比较方面存在不足，特别是在考虑碳足迹等环境因素时更是如此。为了填补这一空白，本文提出了一个统一且可复制的AI模型推理方法，该方法将计算和环境指标在现实的服务条件下结合起来进行衡量。该框架通过系统地测量延迟分布、吞吐量、能耗和地点调整后的碳排放，提供了一个碳意识评价，并保持了准确性的匹配约束，以进行有效的比较。实验在多种硬件平台上进行，包括数据中心加速器GH200和消费者级别的GPU RTX 4090，运行于主流的软件栈，如PyTorch、TensorRT和ONNX Runtime。该方法系统地归类这些因素，为准确表现准确度、延迟、能源和碳之间的权衡提供了严格的基准框架。配套开源代码支持独立验证和采用，使研究人员和从业者能够基于证据做出可持续的AI部署决策。
### Innovation
本文提出了一种统一的、可重复的AI模型推理方法，该方法将计算和环境指标结合在一起，在现实的服务条件下进行衡量。通过系统地测量延迟分布、吞吐量、能耗和地点调整后的碳排放，提供了碳意识评价，并保持了准确性的匹配约束，以进行有效的比较。此方法系统地归类了这些因素，为准确表现准确度、延迟、能源和碳之间的权衡提供了严格的基准框架。此工作的创新在于建立了一个可靠的基准框架，产生了决策可用的帕累托前沿，明确了在准确度、延迟、能源和碳排放之间的权衡。并提供了开源代码以供独立验证和采用，促使研究人员和从业者做出基于证据的决策。
### Conclusion
通过系统地归类并测量多个因素，本文建立了一个严格的基准框架，产生了准确度、延迟、能耗和碳排放之间的帕累托前沿，提供了决策所需的权衡。开源代码支持独立验证和采用，促进了可持续的AI部署。此工作不仅建立了衡量方法，还为未来的研究提供了参考。
## 80. `cs.AI` - 自动化设计自动调优优化器 [PDF](https://arxiv.org/pdf/2510.17899), [HTML](https://arxiv.org/abs/2510.17899)
### Authors
Floris-Jan Willemsen,Niki van Stein,Ben van Werkhoven
### Background
自动调优（auto-tuning）对于优化高性能应用至关重要，但由于参数空间庞大且不规则，手工探索变得不切实际。传统上，自动调优依赖于进化算法、退火方法或基于代理模型的优化器等成熟的优化算法来高效找到接近最优的配置。但是，设计有效的优化器仍然具有挑战性，因为没有一种方法能在所有调优任务中表现最佳。
### Innovation
本研究探索了一种新的范式：使用大型语言模型（LLMs）自动生成针对自动调优问题量身定制的优化算法。提出了一种框架，通过问题描述和搜索空间特征来提示LLMs生成专门的优化策略，并不断迭代检查和改进这些算法。生成的算法在四个实际自动调优应用中进行了评估，并与两个当代自动调优框架中的最先进的优化算法进行了比较。结果表明，在生成阶段提供额外的应用和搜索空间特定信息可分别获得30.7%和14.6%的性能提升。此外，研究结果展示了由LLM生成的优化器能够与现有的人工设计的优化器相媲美，在某些情况下甚至超越它们，我们的最高性能生成优化算法平均提高了72.4%的性能相对于最先进的自动调优优化器。
### Conclusion
通过使用大型语言模型自动生成专门针对自动调优问题的优化策略，可以显著提高自动调优性能，并且生成的优化器的表现能够与甚至超越现有的人工设计的优化器。
## 81. `cs.AI` - Sherpa.ai的盲垂直联邦学习范式以最小化通信次数 [PDF](https://arxiv.org/pdf/2510.17901), [HTML](https://arxiv.org/abs/2510.17901)
### Authors
Alex Acero,Daniel M. Jimenez-Gutierrez,Dario Pighin,Enrique Zuazua,Joaquin Del Rio,Xabi Uribe-Etxebarria
### Background
联邦学习（FL）允许多个实体在不共享原始数据的情况下进行协作训练。FL主要分为水平联邦学习（HFL）和垂直联邦学习（VFL）两种类型。HFL中所有参与者共享相同的特征空间，但拥有不同的样本；而VFL中参与者持有同一样本的不同特征，适用于数据集互补的场景。然而，VFL面临的一个主要挑战是大量的通信需求，这不仅会损害隐私和安全，还可能导致高能耗，甚至在极端情况下使模型训练无法进行。
### Innovation
本文提出了一种称为Blind Vertical Federated Learning (SBVFL)的新范式，通过分布式训练机制加强对隐私和安全的保护。SBVFL通过大幅减少节点与服务器之间的更新通信量，使垂直联邦学习更加实际和安全。实验表明，与传统VFL相比，SBVFL将通信量减少了约99%，同时保持了相似的准确性和鲁棒性。
### Conclusion
因此，SBVFL能够在保持高准确性和鲁棒性的前提下，大幅减少通信次数，使其在医疗、金融、制造、航空航天、网络安全部门和国防工业等领域实现实用、隐私保护的垂直联邦学习。
## 82. `cs.AI` - TACLA：基于LLM的用于教育中TA培训的多智能体工具 [PDF](https://arxiv.org/pdf/2510.17913), [HTML](https://arxiv.org/abs/2510.17913)
### Authors
Monika Zamojska,Jarosław A. Chudziak
### Background
模拟人类复杂的社会动态，尤其是实现心理深度和一致的角色行为，对于构建高保真度的训练工具来说仍然是一项重大挑战。现有方法难以在大型语言模型（LLMs）中准确捕捉这些特征。为了解决这个问题，论文介绍了一种名为TACLA的新颖多智能体架构，以克服这些限制，实现更真实的模拟。
### Innovation
TACLA通过引入基于交易分析（TA）的核心原理，将智能体建模为由父母、成人和儿童EGO状态组成的协调系统，每个状态都有自己的模式记忆，并通过一种调度器智能体根据上下文触发器和智能体的生活剧本优先激活不同的EGO状态，以确保实际的心理反应。该架构被证明能够在一个教育场景下，实现智能体之间真实的EGO状态转变，并有效模拟冲突的升级和降级，基于不同教师干预策略。
### Conclusion
TACLA在教育情景下的验证结果表明，它能够提供高度可信的对话，并证明了其在创建动态、心理依据的社交模拟方面的潜力，从而推进了教育以及其他领域的有效AI工具的发展。
## 83. `cs.AI` - BreakFun：通过模式利用劫持LLM [PDF](https://arxiv.org/pdf/2510.17904), [HTML](https://arxiv.org/abs/2510.17904)
### Authors
Amirkia Rafiei Oskooei,Mehmet S. Aktas
### Background
大型语言模型（LLMs）在处理结构化数据和遵守语法规则方面的能力，是推动它们广泛应用的因素，但也因此使它们变得脆弱。本文通过BreakFun这一工具，研究了这种脆弱性。BreakFun采用了一种通过模式（Schema）利用的技术，将LLM对结构化的严格遵守转化为攻击的手段。
### Innovation
提出了BreakFun，一种通过模式（Schema）利用的劫持方法。它包含一个三部分提示，分别是无害化的包装、逻辑推理的干扰和精心设计的‘特洛伊模式’。此外，还提出了一种名为Adversarial Prompt Deconstruction的防御措施，通过另一个LLM提取所有可读文本来揭示用户的真正意图。
### Conclusion
本文展示了通过‘特洛伊模式’利用LLM脆弱性的有效性，攻击成功率达到了89%，并且通过严格的消融实验验证了这种模式是主要原因。引入的防御措施Adversarial Prompt Deconstruction能够有效地对抗此类攻击，证明了针对欺骗性模式的策略是可行的。
## 84. `cs.AI` - 基于实例水平适应性的同时增强校准质量和不确定感知决策：超越校准指标的自意识预测缓解 [PDF](https://arxiv.org/pdf/2510.17915), [HTML](https://arxiv.org/abs/2510.17915)
### Authors
Hassan Gharoun,Mohammad Sadegh Khorshidi,Kasra Ranjbarigderi,Fang Chen,Amir H. Gandomi
### Background
尽管对神经网络校准已有广泛研究，现有方法通常采用全局变换对所有预测统一处理，忽略了个体预测之间的异质可靠性。此外，校准质量提升与有效不确定性感知决策之间的关系尚未完全探索。
### Innovation
本文提出了一种后校准框架，利用预测可靠性评估共同提升校准质量和不确定性感知决策。该框架利用基于邻近性的容错预测，根据特征空间中的语义相似性将校准样本分为可能正确的和可能错误的两类。然后应用双校准策略：标准等距回归校准可能正确的预测置信度，而正则化不足信心的等距回归减少可能错误预测的置信度，使其更容易识别进行进一步研究。实验表明，该方法在CIFAR-10和CIFAR-100数据集上使用BiT和CoAtNet骨干网络时，可以减少自信错误预测并获得具有竞争力的期望校准误差，优于等距回归和焦点损失基线。
### Conclusion
本文通过实例水平适应性将校准与不确定性量化相结合，提供了一种无需重新训练模型的实用后校准解决方案，同时提高概率对齐和不确定性感知决策力。
## 85. `cs.AI` - NeuCo-Bench: 地球观测中神经嵌入的新基准框架 [PDF](https://arxiv.org/pdf/2510.17914), [HTML](https://arxiv.org/abs/2510.17914)
### Authors
Rikard Vinge,Isabelle Wittmann,Jannik Schneider,Michael Marszalek,Luis Gilch,Thomas Brunschwiler,Conrad M Albrecht
### Background
本文介绍了NeuCo-Bench，一个用于评估（失真）神经压缩和表示学习的新基准框架，在地球观测（EO）背景下进行评估。这种框架建立在固定大小的嵌入上，这些嵌入作为紧凑的任务无关性表示，适用于广泛的下游任务。该基准框架包含三个核心组成部分：(i)围绕可重用嵌入构建的评估管道；(ii)一种新的挑战模式，带有隐藏任务排行榜，旨在减轻预训练偏差；(iii)平衡准确性和稳定性的评分系统。为了支持可复现性，还发布了SSL4EO-S12-downstream，一个精心挑选的多光谱、多时间的EO数据集。
### Innovation
NeuCo-Bench 提供了一种新的基准框架，其中包含固定大小的嵌入，作为通用任务表示的紧凑形式，适用于广泛的下游任务。该基准框架包含了评估管道、新的挑战模式（带有隐藏任务排行榜）、以及平衡准确性和稳定性的评分系统，这些创新有助于减轻预训练偏差并增加了框架的公平性。此外，还发布了一个精心挑选的多光谱、多时间的数据集以支持研究的可复现性。公共挑战和最先进的基础模型的消融研究也展示了其有效性。
### Conclusion
NeuCo-Bench 为社区驱动的标准神经嵌入评估提供了第一步，在地球观测和更广泛的领域中都具有重要意义。通过对固定的嵌入进行评估，该基准框架提供了一种新的方法来评估和优化神经压缩和表示学习，特别是在大量地球观测数据中。
## 86. `cs.AI` - 前沿模型在印度法律推理中是否准备就绪？ [PDF](https://arxiv.org/pdf/2510.17900), [HTML](https://arxiv.org/abs/2510.17900)
### Authors
Kush Juvekar,Arghya Bhattacharya,Sai Khadloya,Utkarsh Saxena
### Background
大语言模型(LLMs)正在进入法律工作流程，但是缺乏特定管辖区的标准来评估其基础能力。本文使用印度的公共法律考试作为透明的代理。多年来的基准测试集结了国家级和省级顶尖考试的标准，并在现实世界的考试条件下评估了开放和前沿的LLM。为了超越选择题，本文还包含了一项律师评分、配对盲目的关于长期回答的研究，这些回答来自最高法院的代理律师考试。这被认为是第一项基于考试，针对印度特定标准的前沿系统法律准备度评估，附带提供了数据集和协议。目前的工作表明，尽管前沿系统始终能够满足历史的分数线，并且经常在客观考试中达到或超过最近的最高分数段，但没有一个能够超越人类最高得分者在长期推理中的表现。评分注释一致指出三种可靠性失败模式：程序或格式合规性、权威或引证纪律以及论坛适用的语言和结构。这些发现界定了LLMs可以帮助的领域（如检查、跨法典一致性、法典和先例查找）以及人类领导仍必不可少的领域：特定论坛的起草和提交、程序和补救策略、权威和例外的协调，以及道德、负责任的判断。
### Innovation
本文首次使用印度公共法律考试作为透明代理进行基准测试，评估前沿语言模型在印度法律环境下的准备情况。研究内容包括客观考试成绩的评估和长期答案的研究，这些长期答案来自最高法院的代理律师考试，由律师进行评分和盲评。研究结果公开了数据集和评估协议，是该领域的首个前沿系统准备度评估基准，特别指出三种可靠性失败模式：程序或格式合规性、权威或引证纪律以及论坛适用的语言和结构问题。这些结果为LLMs的应用指出了方向和限制。
### Conclusion
 frontier系统在客观考试中的表现良好，但在长期推理方面无法超越人类。需要关注格式、引用和语言结构合规性的问题。尽管在某些技术支持上，如检查、法典查找等，LLMs表现出色，但在论坛特定的起草和提交、程序和补救策略、权威和例外的协调以及道德负责任的判断上，人类的领导作用仍然不可或缺。
## 87. `cs.AI` - LLMs在本科微积分中的可解释性框架 [PDF](https://arxiv.org/pdf/2510.17910), [HTML](https://arxiv.org/abs/2510.17910)
### Authors
Sagnik Dakshit,Sushmita Sinha Roy
### Background
大型语言模型（LLMs）在教育中的应用越来越广泛，但它们的正确性并不能完全反映其解决问题行为的质量、可靠性或教育上的有效性，尤其是在数学领域，其中多步逻辑、符号推理和概念清晰度是极其重要的。传统的评估方法主要关注最终答案的准确性，而忽略了推理过程。因此，本文旨在填补这一空白，提出了一种新的可解释性框架，用于分析LLM生成的解决方案，特别是在本科微积分领域。该方法结合了推理流程提取、将解决方案分解为语义标记的操作和概念，并通过提示消除分析来评估输入重要性和输出稳定性。使用结构化指标如推理复杂度、短语敏感性和鲁棒性，评估模型行为在实际的大一到大三微积分大学考试中的表现。结果表明，LLMs通常会产生语法流畅但概念上有缺陷的解决方案，其推理模式对提示措辞和输入变化敏感。此框架能够进行细致的推理故障诊断，支持课程对齐，并为可解释的人工智能辅助反馈工具的设计提供信息支持。这是首次为解释LLM在数学教育中推理提供一种结构化、定量和教育基础的框架，为在STEM学习环境中透明和负责任地应用AI奠定了基础。
### Innovation
提出了新的可解释性框架，用于分析LLM生成的解决方案在本科微积分领域的行为，结合推理流程提取和分解解决方案为语义标记的操作与概念，以及通过提示消除分析来评估输入的重要性和输出的稳定性。使用结构化指标如推理复杂度、短语敏感性和鲁棒性来评估模型行为。这种方法能够进行细致的推理故障诊断，支持课程对齐，并为可解释的人工智能辅助反馈工具的设计提供信息支持。
### Conclusion
本文提供了首次为解释LLM在数学教育中推理提供一种结构化、定量和教育基础的框架，为在STEM学习环境中透明和负责任地应用AI奠定了基础。该框架能够进行细致的推理故障诊断，支持课程对齐，并为可解释的人工智能辅助反馈工具的设计提供信息支持。
## 88. `cs.AI` - 通过扩散时间和频率选择超越均匀遗忘的数据未学习 [PDF](https://arxiv.org/pdf/2510.17917), [HTML](https://arxiv.org/abs/2510.17917)
### Authors
Jinseong Park,Mijung Park
### Background
数据未学习旨在从训练模型中移除特定训练样本的影响，而无需重新训练整个模型。尽管数据未学习在过去已有一些研究，特别是在扩散模型中，但目前对其了解仍很有限，且常常导致生成质量下降或遗忘不完全。大多数现有方法在所有扩散时间步骤中尝试等价地移除样本，导致生成质量差。因此，需要一种方法来有效解决这一问题，以改善生成质量和遗忘效果。
### Innovation
研究者发现遗忘在时间和频率上的分布并不均匀，根据模型和场景不同，遗忘集中在特定的时间和频率范围内。因此，他们提出了一种时间与频率选择方法，能够在训练过程中有选择地关注特定的时间频率范围，从而提高了生成的美学质量和降低了噪音。这种方法应用于各种场景，表明其有效性和适用性。为了评估删除效果和未学习数据样本的品质，研究者提出了一种简化的标准化版本SSCD。这种时间频率选择方法为扩散模型的数据未学习提供了一种新的视角和高效的策略。
### Conclusion
本文的研究结果揭示了扩散模型数据未学习的独特挑战，并提供了实用的方法来提高评价和未学习性能。通过验证和改进，证明了时间频率选择方法的有效性和适用性，为数据未学习的研究提供了新的思路和实践策略。
## 89. `cs.AI` - JT-Safe: 提升大语言模型安全性和可信度的内在方法 [PDF](https://arxiv.org/pdf/2510.17918), [HTML](https://arxiv.org/abs/2510.17918)
### Authors
Junlan Feng,Fanyu Meng,Chong Long,Pengyu Cong,Duqing Wang,Yan Zheng,Yuyao Zhang,Xuanchang Gao,Ye Yuan,Yunfei Ma,Zhijie Ren,Fan Yang,Na Wu,Di Jin,Chao Deng
### Background
大语言模型（LLMs）的幻觉和可信度问题已成为全球性的挑战。行业正在共同努力解决这些问题，近期在训练后技术和推理技术上取得了一些进步。然而，行业普遍认为LLMs的不安全和幻觉本质上源自于预训练，与预训练数据和下一个词预测的机制有关。本研究聚焦于改进预训练数据，以提高LLMs的安全性和可信度。尽管数据量庞大，但仍需保留潜在的错误或偏见，且预训练数据缺乏现实知识作为背景。
### Innovation
研究提出了一种方法，即引入世界背景的预训练数据（DWC），旨在通过结合现实世界的背景信息更好地将预训练数据置于实际场景中。研究并通过将早期的JT-35B-Base模型继续预训练1.5兆亿个DWC标记，并在安全性与可信度评估基准上与规模类似但仅使用6.2兆亿标记预训练的Qwen模型相比，JT-Safe-35B的平均性能提高了1.79%。
### Conclusion
通过引入包含世界背景的预训练数据，本研究展示了如何提升语言模型的安全性和可信度，且在安全性与可信度评估基准上取得了显著效果。
## 90. `cs.AI` - 通过层次梯度分解实现自我证伪：一个通过最小化变分自由能维持非平衡稳态的耗散系统 [PDF](https://arxiv.org/pdf/2510.17916), [HTML](https://arxiv.org/abs/2510.17916)
### Authors
Michael James McCulloch
### Background
自由能量原则（FEP）指出，自我组织系统必须通过最小化变分自由能来维持其存在，但将这一原则转化为可执行算法的具体路径仍然不清楚。本文提供了一个构建性的证明，证明FEP可以通过精确的局部奖赏归属来实现。系统通过层次的方式分解梯度计算：通过反馈对齐实现空间奖赏，通过可得性痕迹实现时间奖赏，通过一种营养梯度场图（TFM）估计每条连接块的预期梯度大小来实现结构奖赏。这些机制在各自的层次上被证明是精确的，通过实验证明了中心主张：TFM实现了0.9693的皮尔逊相关性与oracle梯度。这些精确性产生了新兴的能力，包括98.6%的任务失败后的保留率，自主的75%结构损伤恢复，自我组织临界状态（特征辐射率p≈1.0），以及无需回放缓存的连续控制任务上的高效强化学习。该架构统一了普利高津的耗散结构、弗里斯顿的自由能最小化和霍皮菲尔德的吸引子动力学，表明了层次的网络拓扑推理可通过局部的、生物学上可行的规则实现.
### Innovation
文章提供了一个构建性的证明，证明FEP可以实现通过精确的局部奖赏归属。具体来说，系统通过层次的方式分解梯度计算：空间奖赏通过反馈对齐，时间奖赏通过可得性痕迹，结构奖赏通过营养梯度场图（TFM）估计预期梯度大小。证明了这些机制在各自层次上是精确的，并验证了中心主张：TFM实现了0.9693的皮尔逊相关性与oracle梯度。这些精确性产生了多种新兴能力，包括高效的任务保留率、自主的结构恢复能力、自我组织临界状态以及高效的连续控制任务的强化学习，无需回放缓存。
### Conclusion
该架构统一了普利高津的耗散结构、弗里斯顿的自由能最小化和霍皮菲尔德的吸引子动力学，表明了层次的网络拓扑推理可以通过局部的、生物学上可行的规则实现。
## 91. `cs.AI` - ParaVul: 一种用于智能合约漏洞检测的并行大型语言模型和检索增强框架 [PDF](https://arxiv.org/pdf/2510.17919), [HTML](https://arxiv.org/abs/2510.17919)
### Authors
Tenghui Huang,Jinbo Wen,Jiawen Kang,Siyong Chen,Zhengtao Li,Tao Zhang,Dongning Liu,Jiacheng Wang,Chengjun Cai,Yinqiu Liu,Dusit Niyato
### Background
智能合约在自动化区块链服务中发挥着重要作用，但其漏洞威胁到区块链的安全性。传统的检测方法主要依赖静态分析和形式验证，但这些方法普遍存在较高的误报率和较差的扩展性。近年来，大型语言模型（LLMs）在智能合约漏洞检测方面取得了显著进展，但仍面临高推理成本和大量计算开销的挑战。因此，需要一种能够提高可靠性、准确性的智能合约漏洞检测方法。
### Innovation
本文提出了ParaVul，一种并行大型语言模型和检索增强框架。首先开发了Sparse Low-Rank Adaptation (SLoRA) 用于LLM微调，减少计算开销和资源需求，同时增强对与漏洞相关问题的理解能力。然后构建了一个漏洞合同数据集，并开发了一种结合密集检索和Best Matching 25 (BM25) 的混合 Retrieve-Augmented Generation (RAG) 系统，帮助验证LLM生成的结果。此外，提出了一个元学习模型，用于融合RAG系统的输出和LLM的输出，生成最终的检测结果。
### Conclusion
ParaVul 在漏洞检测中表现出优越性，尤其是F1分数，单标签检测为0.9398，多标签检测为0.9330。
## 92. `cs.AI` - CBINNS:基于癌症生物学的神经网络用于未知参数估计和缺失物理识别 [PDF](https://arxiv.org/pdf/2510.17920), [HTML](https://arxiv.org/abs/2510.17920)
### Authors
Bishal Chhetri,B.V. Rathish Kumar
### Background
肿瘤免疫相互作用的动力学通常使用常微分方程或偏微分方程建模。这些模型包含一些未知参数，需要从有限且噪声的数据中准确且高效地估计出来。同时，由于生物复杂性的制约和实验测量的局限性，肿瘤-免疫动力学尚未完全理解，因此系统中的方程可能存在未知或缺失的项。因此，本文开发了一种癌症生物学导向的神经网络模型（CBINN），该模型能够在稀疏且有噪声的测量值中推断未知参数，并发现缺失的物理定律。论文选取了三种不同的非线性肿瘤-免疫模型进行测试，并评估了其在多个合成噪声水平下的鲁棒性。
### Innovation
本文提出了一种癌症生物学导向的神经网络模型（CBINN），该模型能够根据稀疏且有噪声的数据推断方程中的未知参数，并发现系统中的未知物理定律或数学结构。这种模型能够有效地估计未知参数，即使在散乱且有噪声的数据中也能揭示出控制这些生物系统的物理定律或数学结构。选择了在肿瘤-免疫相互作用中常见的动态模式的非线性模型，验证了该方法的可推广性和有效性。
### Conclusion
基于癌症生物学的CBINN框架通过对高度非线性的肿瘤-免疫动力学进行建模，有效地估计出了未知模型参数，并从稀疏和有噪声的数据中揭示了控制这些生物系统的基本物理定律或数学结构。这种方法展示了在理解复杂复杂的肿瘤-免疫相互作用方面的新颖性和有效性。
## 93. `cs.AI` - Select-Then-Decompose: 从实证分析到针对大型语言模型任务分解的自适应选择策略 [PDF](https://arxiv.org/pdf/2510.17922), [HTML](https://arxiv.org/abs/2510.17922)
### Authors
Shuodi Liu,Yingzhuo Liu,Zi Wang,Yusheng Wang,Huijia Wu,Liuyu Xiang,Zhaofeng He
### Background
大型语言模型（LLMs）展现了卓越的推理和规划能力，推动了任务分解的广泛研究。现有研究主要集中在记忆、工具使用和反馈机制上，在特定领域取得了显著成果，但往往忽略了性能与成本之间的权衡。这项研究首先对任务分解进行了全面调查，并识别了六种分类方案。然后，通过对影响任务分解性能和成本的三个因素（方法类别、任务特征和分解与执行模型的配置）进行实证分析，揭示了三个关键洞察，并总结了一系列实用原则。
### Innovation
本文基于分析提出了Select-Then-Decompose策略，该策略包括三个阶段：选择、执行和验证。该策略可以根据任务特征动态选择最适合的分解方法，并通过验证模块增强结果的可靠性。多个基准测试全面评估显示，Select-Then-Decompose始终处于帕累托前沿，实现了性能和成本的最佳平衡。此外，作者还公开了其代码。
### Conclusion
研究表明，Select-Then-Decompose策略在大型语言模型的任务分解中，能够动态选择最合适的方法，提升任务分解的可靠性，并在多个基准测试中展现了最优的性能与成本平衡。
## 94. `cs.AI` - 游戏聊天中高效毒性的检测：嵌入式、微调变换器和大语言模型的比较研究 [PDF](https://arxiv.org/pdf/2510.17924), [HTML](https://arxiv.org/abs/2510.17924)
### Authors
Yehor Tereshchenko,Mika Hämäläinen
### Background
本文对自然语言处理（NLP）方法在在线游戏聊天中的自动毒性检测进行了全面的比较分析。评估了传统的机器学习模型、带有零样本和少样本提示的大语言模型、微调的变换器模型以及检索增强生成（RAG）方法。评估框架重点关注分类准确性、处理速度和计算成本这三个关键维度。实验结果表明，在众多方法中，微调的DistilBERT在准确性和成本之间取得了最优的平衡。
### Innovation
提出了一个混合的监控系统架构，该架构通过自动检测优化了人类监控者的负担，并且集成了持续学习机制。研究结果提供了在动态在线游戏环境中部署有效的、高效的内容监控系统的实证证据。
### Conclusion
研究结果显示不同方法在表现上存在显著差异，微调的DistilBERT在准确性和成本之间的贸易中取得了最优平衡，从而为部署成本效益高的内容监控系统提供了依据。
## 95. `cs.AI` - CLAWS: 使用段落注意窗口检测生成模型产生的解决方案的创意性 [PDF](https://arxiv.org/pdf/2510.17921), [HTML](https://arxiv.org/abs/2510.17921)
### Authors
Keuntae Kim,Eunhye Jeong,Sehyeon Lee,Seohee Yoon,Yong Suk Choi
### Background
近年来，通过强化学习（RL）训练的大语言模型（LLMs）在提升推理能力方面取得了显著成功。这些模型即使在较小的模型规模下也能表现出强大的性能，尤其是在数学和编程等挑战性任务中。然而，在这些模型生成的解题过程中，创意评估这一方面受到了重视不足，尤其是在与写作相关的任务中更为普遍。缺乏关于推理任务中创意评估的研究主要归因于两个挑战：第一，定义创意范围的难度，第二，创意评估过程对人类评估的依赖。为了应对这些挑战，本文提出了一种方法CLAWS，该方法通过利用提示段落和输出之间的注意力权重，无需人工评估即可将数学解题过程中的解题方案分类为典型、创造性和幻想类。
### Innovation
CLAWS是一种无需人类评估即可定义并分类数学解决方案为典型、创造性和幻想类的方法。它通过利用提示段落和输出之间的注意力权重实现了这一点，并且在对7-8B的大规模数学RL模型（DeepSeek、Qwen、Mathstral、OpenMath2、Oreal）进行测试时，CLAWS优于五种现有的白盒检测方法（困惑度、逻辑熵、窗口熵、隐藏得分和注意得分）。进一步的验证显示，CLAWS在来自181场数学竞赛（AJHSME、AMC、AIME）收集的4545个数学问题上表现出色。
### Conclusion
CLAWS通过利用注意力窗口的段落注意力权重，实现了无需人工评估即可分类数学解决方案的能力。该方法在多个大规模数学RL模型上的应用表明其优越性，并且为未来研究数学推理的创造性提供了新的方法。
## 96. `cs.AI` - 奖励过程而非终点：一种用于测试时强化学习的合成路径和答案自评分奖励机制 [PDF](https://arxiv.org/pdf/2510.17923), [HTML](https://arxiv.org/abs/2510.17923)
### Authors
Chenwei Tang,Jingyu Xing,Xinyu Liu,Wei Ju,Jiancheng Lv,Deng Xiong,Ziyue Qiao
### Background
强化学习（RL）已成为推动大型语言模型（LLMs）的重要范式，在数学和代码生成等复杂推理领域取得了显著成就。然而，现有的RL方法因其对人类标注的数据或奖励模型的依赖而面临规模性的瓶颈。当前方法在没有外部监督的情况下难以可靠地估计奖励，一些方法如Test-Time RL通过自我一致性的共识来解决这一点，但存在强化错误的伪标签的风险。
### Innovation
本文引入了COMPASS（Composite Path and Answer Self-Scoring），一种无需外部监督的测试时奖励机制。该机制结合了双校准答案奖励（DCAR）和决断路径奖励（DPR）两部分：DCAR通过信心和可信度校准稳定训练，建立可靠的伪标签；DPR直接优化推理过程的质量，而不仅仅是结果监督。通过联合强化可信的共识答案和高决断的推理链，COMPASS系统地提高了模型的分析能力。实验证明，COMPASS在各种推理任务和模型架构上表现出显著且一致的性能提升，为LLMs从持续经验中学习提供了更具扩展性的方向。
### Conclusion
大量的实验数据表明，COMPASS机制能够在不同任务和模型结构下实现稳定且显著的性能提升，为LLMs利用持续经验学习提供了更加可行的路径。
## 97. `cs.AI` - NER模型扩展中的表示动态诊断 [PDF](https://arxiv.org/pdf/2510.17930), [HTML](https://arxiv.org/abs/2510.17930)
### Authors
Xirui Zhang,Philippe de La Chevasnerie,Benoit Fabre(papernest)
### Background
在嘈杂的口语文本中扩展命名实体识别(NER)模型到未见过的新个人身份信息(PII)实体是一个常见需求。研究发现，在对标准语义实体(如PER、LOC、ORG)以及新基于模式的PII(如EMAIL、PHONE)进行联合微调时，对原类别性能的损害非常小。
### Innovation
通过增量学习设置作为诊断工具，研究发现两个关键见解。首先，与新PII共享模式特征（如邮政编码）的LOC实体尤为脆弱，因存在表示重叠而受威胁。其次，发现了“反向O-标签表示动态”。模型最初被训练将PII模式映射为'O'标签，这阻止了新学习，只有解冻'O'标签分类器，才能让背景分类器适应并“释放”这些模式。
### Conclusion
这项工作对NER模型适应过程进行操作机理诊断，强调了特征独立性、表示重叠以及'O'标签的可塑性。
## 98. `cs.AI` - EvoSyn: 通用进化的可验证数据合成方法 [PDF](https://arxiv.org/pdf/2510.17928), [HTML](https://arxiv.org/abs/2510.17928)
### Authors
He Du,Bowen Li,Aijun Yang,Siyang He,Qipeng Guo,Dacheng Tao
### Background
现代语言模型能力的增长依赖于可靠的验证数据，这些数据能够稳定强化学习并有效地进行知识迁移，适用于数学、编程和任务型任务。然而，构建可泛化的合成验证数据仍然具有挑战，这是因为生成过程中容易出现幻觉，以及验证功能薄弱或过于简化，不能区分强弱解。现有方法往往依赖于特定任务的经验法则或事后过滤器，这些方法在不同领域之间不通用且缺乏原理性的验证性评估方法。
### Innovation
本文提出了一种进化、任务不可知论的、策略指导的、执行检查的数据合成框架。该框架从少量的种子监督开始，共同合成问题、多种候选解决方案以及验证功能，通过一致性评估器迭代发现策略，确保人类注释和策略诱导的检查之间的一致性。这种方法将过滤升级为原理性的合成，可靠地构建出一致、验证良好的训练实例，并在无需领域特定规则的情况下实现泛化。
### Conclusion
实验结果表明，使用我们合成的数据进行训练，无论是在强化学习和验证奖励训练（RLVR）还是模型蒸馏训练范式下，都能取得显著效果。在LiveCodeBench和AgentBench-OS任务上的结果证明了我们框架的稳健泛化能力。
## 99. `cs.AI` - 通过协作合同吸引商业人工智能公司支持国家安全 [PDF](https://arxiv.org/pdf/2510.17931), [HTML](https://arxiv.org/abs/2510.17931)
### Authors
Andrew Bowne
### Background
与其他由国家安全需求驱动并由联邦资金支持的军事技术不同，人工智能主要由私营行业为民用应用进行资助和开发。然而，对于商业人工智能公司为什么与国防部合作或避开军事市场的原因仍然存在缺乏理解。本文认为，传统的合同法和采购框架是最大障碍之一。研究表明，商业人工智能行业实际上认为国防部是一个有吸引力的客户。然而，这种吸引力是基于传统的合同法和采购实践所带来的障碍。基于社会交换理论，本文提出了最优买家理论，以理解影响商业公司与国防部合作的决定因素。通过与参与者的访谈，本文揭示了这种对公司合同的一般看法和对国防部在这项业务中角色的态度。
### Innovation
本文引入了最优买家理论来理解影响商业公司与国防部合作的决定因素，并通过社会交换理论对该理论进行了支持。此外，它还概述了如何利用现有的合同法律，特别是其他交易授权，来调整采购实践以适应商业偏好和机器学习的发展和部署生命周期的最佳实践。
### Conclusion
商业人工智能公司在合同与其业务和技术考虑相符的情况下具有吸引力。本文还提出了利用现有合同法律，特别是其他交易授权，来对接采购实践与商业偏好和机器学习开发与部署生命周期的最佳实践。
## 100. `cs.AI` - 从图表到代码：面向多模态模型的层次基准 [PDF](https://arxiv.org/pdf/2510.17932), [HTML](https://arxiv.org/abs/2510.17932)
### Authors
Jiahao Tang,Henry Hengyuan Zhao,Lijian Wu,Yifei Tao,Dongxing Mao,Yang Wan,Jingru Tan,Min Zeng,Min Li,Alex Jinpeng Wang
### Background
本研究引入了Chart2Code，这是一个用于评估大型多模态模型（LMMs）的图表理解和代码生成能力的新基准。Chart2Code从用户驱动的角度进行设计，覆盖了多样化的实际场景，并逐步提高任务难度。它包括三个层次：第一层（图表复现）从参考图像和用户查询中复现图表；第二层（图表编辑）涉及复杂的修改，如改变图表类型或添加元素；第三层（长表格到图表生成）要求模型根据用户指令将长的、信息密集的表格转换为忠实的图表。
### Innovation
Chart2Code 是第一个反映实际图表到代码应用同时系统地扩展任务复杂度的分层基准。它包含22种图表类型共计2,023个任务，并配合多层次评估指标，评估代码的正确性和渲染图表的视觉保真度。研究还测试了25个最先进的（SoTA）LMMs，结果显示即使是最先进的模型GPT-5在代码测试和图表质量评估中的得分也很低，进一步证明了Benchmark的挑战性。
### Conclusion
我们预计这个基准将推动多模态推理的发展，并促进更强大和通用的LMMs的发展。我们的代码和数据可在Chart2Code获取。
## 101. `cs.AI` - XDXD: 低分辨率X射线衍射的端到端晶体结构确定 [PDF](https://arxiv.org/pdf/2510.17936), [HTML](https://arxiv.org/abs/2510.17936)
### Authors
Jiale Zhao,Cong Liu,Yuxuan Zhang,Chengyue Gong,Zhenyi Zhang,Shifeng Jin,Zhenyu Liu
### Background
从X射线衍射数据中确定晶体结构在多个科学领域都是基础任务，但在仅有低分辨率数据的情况下，这一过程仍然构成了重大挑战。尽管最近的深度学习模型在解决晶体学相位问题方面取得了突破，但生成的低分辨率电子密度图往往难以解释，存在模糊性。
### Innovation
作者提出了XDXD，这是一个首创的端到端深度学习框架，可以直接从低分辨率单晶X射线衍射数据中确定完整的原子模型。该模型使用基于扩散的生成模型跳过了手动映射解释的需要，生成了与衍射图谱条件一致的化学合理晶体结构。
### Conclusion
XDXD在低分辨率（≤2.0Å）条件下，结构匹配率高达70.4%，均方根误差（RMSE）低于0.05，表现出高度的鲁棒性和准确性。通过小肽案例研究展示了该模型在复杂系统中的扩展潜力，有望为先前难以解决的结构解析自动化铺平道路。
## 102. `cs.AI` - AtlasKV: 在20GB VRAM中增强LLMs的十亿规模知识图谱 [PDF](https://arxiv.org/pdf/2510.17934), [HTML](https://arxiv.org/abs/2510.17934)
### Authors
Haoyu Huang,Hong Ting Tsang,Jiaxin Bai,Xi Peng,Gong Zhang,Yangqiu Song
### Background
 Retrieval-augmented generation (RAG) 方法已经在增强大型语言模型（LLMs）中展示了外部知识的融入方面的一些成功。然而，由于这些非参数化的知识整合框架高度依赖外部检索模块和检索到的相关文本上下文，尤其是处理大规模知识增强时，会导致长时间的推理延迟，因为涉及到昂贵的搜索过程和较长的相关上下文。
### Innovation
提出了一个参数化的知识整合方法，称为AtlasKV，这是一种在小型GPU内存成本（如不到20GB VRAM）下，有效且广泛应用于增强LLMs与十亿规模知识图谱（如1B三元组）的新方法。引入了KG2KV和HiKVP来通过亚线性时间复杂性和内存复杂性将知识图谱三元组规模化地整合进大型语言模型中，同时使用模型固有的注意力机制来保持强大的知识关联性和泛化性能，无需外部检索器、较长上下文和重新训练即可适应新知识
### Conclusion
本文提出了一种参数化方法AtlasKV，它能够以亚线性时间和内存复杂性的成本，将十亿规模的知识图谱有效整合到大型语言模型中，增强模型的知识表现，无需额外的检索器、长时间的上下文依赖或重新训练。
## 103. `cs.AI` - 从观测到参数：通过基于模拟的推理检测非线性动力学中的变点 [PDF](https://arxiv.org/pdf/2510.17933), [HTML](https://arxiv.org/abs/2510.17933)
### Authors
Xiangbo Deng,Cheng Chen,Peng Yang
### Background
在混沌时间序列中检测拐点困难的原因在于观测信号与固有的系统变化相互缠绕。以往的方法通常在观测空间进行基线检测，但效果受困于系统的固有变异性和观测信号的复杂性。需要一个新的框架来有效地检测非线性动力系统中的变更点，提高检测的准确性和稳健性。
### Innovation
本文提出Parameter-Space Changepoint Detection (Param--CPD)框架，通过两阶段方法将参数空间中的变点检测与观测空间分开处理。首先利用基于模拟的推理（Simulation-based Inference）训练神经后验估计器估计系统参数，消减Bayesian推理的成本；然后采用标准的变点检测算法对参数轨迹进行分析，提高了变点检测的精度和稳健性。在Lorenz-63系统的实验中，此方法提高了召回率、降低了定位误差并减少了假阳性情况，展示了在参数空间进行变点检测的优势。
### Conclusion
实验结果显示，使用物理可解析的参数空间进行变点检测在非线性动力系统中具有更高的准确性和解读性，并且对于容差、窗长和噪声的鲁棒性分析显示此方法具有一致的增益效果。
## 104. `cs.AI` - UniRL-Zero：联合语言模型和扩散模型专家的统一模型强化学习 [PDF](https://arxiv.org/pdf/2510.17937), [HTML](https://arxiv.org/abs/2510.17937)
### Authors
Fu-Yun Wang,Han Zhang,Michael Gharbi,Hongsheng Li,Taesung Park
### Background
该论文提出了一种统一强化学习（RL）框架，旨在增强多模态语言模型的理解和推理能力，扩散模型的多媒体生成能力及其统一模型内的相互作用能力。论文定义了六种统一模型强化学习的场景，为统一理解和生成模型的强化学习提供了系统化的基线。
### Innovation
本文提出了UniRL-Zero，这是一种结合了语言模型和扩散模型的统一模型框架，能够在统一的模型架构中提升多模态语言理解与生成、多媒体生成的能力及其相互作用。通过定义六种统一学习场景，该研究为这类模型的强化学习提供了标准化的方法和基准。
### Conclusion
本文的工作定义了六种统一模型的强化学习场景，并为统一理解和生成模型提供了系统的基线。实验结果表明，UniRL-Zero能够在统一模型框架内有效提升多模态语言理解和推理能力以及多媒体生成能力。
## 105. `cs.AI` - 基础模型和生成AI中的信任：地理学视角 [PDF](https://arxiv.org/pdf/2510.17942), [HTML](https://arxiv.org/abs/2510.17942)
### Authors
Grant McKenzie,Krzysztof Janowicz,Carsten Kessler
### Background
大规模预训练机器学习模型在各个领域，包括地理学中重塑了我们对人工智能的理解。随着这些模型的应用增加，尤其是在重要决策中依赖它们时，信任成为一个复杂的概念。本文探讨了在地理学背景下，基础模型中信任的多方面概念，将其分为三种类型：培训数据的知识性信任、模型功能的操作性信任以及模型开发者的个人信任。文章提到，文化背景、数据异质性和空间关系在地理领域中至关重要，这些因素对于建立信任至关重要。同时，文章分析了不同形式偏见带来的挑战、透明性和可解释性的重要性以及模型开发中的伦理责任。最后，地理信息科学家的独特视角被强调，呼吁进一步提高透明度、减轻偏见并制定基于地区的政策，以促进对（生成）GeoAI的信任的理解。
### Innovation
本文提出了一个基础模型在地理学领域的多方面信任的概念框架，并强调了在模型开发中提高透明度、减轻偏见和制定地区导向政策的重要性，这为研究者、从业者和政策制定者提供了理解和处理（生成）GeoAI中信任问题的起点。
### Conclusion
本文旨在为研究人员、从业者和政策制定者提供一个关于（生成）GeoAI中信任的理解起点，强调提高透明度、减轻偏见和基于地区的政策制定是必要措施。
## 106. `cs.AI` - 西班牙本科医学教育中人工智能集成的描述性分析与国际视角 [PDF](https://arxiv.org/pdf/2510.17938), [HTML](https://arxiv.org/abs/2510.17938)
### Authors
Ana Enériz Janeiro,Karina Pitombeira Pereira,Julio Mayol,Javier Crespo,Fernando Carballo,Juan B. Cabello,Manel Ramos-Casals,Bibiana Pérez Corbacho,Juan Turnes
### Background
人工智能正在变革医疗实践，重新定义未来医疗专业人员需要掌握的能力。尽管国际上有相关建议，但在西班牙，将人工智能纳入医学院课程尚未进行系统性评价。这项横断面研究包括西班牙所有提供官方医学学位的大学，通过审查课程和公开的机构文件，识别2025-2026学年与人工智能相关的课程和能力。截至2025年7月至9月的分析表明，目前西班牙仅有少数几所大学提供专门的人工智能课程。除此之外，大多数课程是选修课程，并且学分占有很小的比重，仅有1.17%。只有加纳列斯大学提供必修的人工智能课程。地区分析显示，地区之间存在显著差异：安达卢西亚地区55.5%的大学已纳入人工智能培训，但其他一些地区尚未采取任何措施。目前，西班牙的医学学位中人工智能的整合尚处于初级阶段，且存在碎片化和不均衡的问题，课程学分占比很低，这限制了未来医生在日益由人工智能驱动的医疗环境中进行实践的准备能力。这些研究结果支持制定最低标准并进行国家监测。
### Innovation
首次对西班牙整体现状进行横断面研究，填补了人工智能在医学院课程中应用的系统性评估空白。它区分了必修与选修课程，并提供了地区之间的比较数据，强调了在教育中加强人工智能培训的必要性。研究结果支持了建立最低标准并进行国家监测的建议。
### Conclusion
目前，西班牙的医学学位中人工智能的整合尚处于初级阶段，且存在碎片化和不均衡的问题。课程学分占比很低，主要分布在欧洲其他国家及美国也存在类似的情况。未来需要加强对人工智能的教育，确保未来的医生能够适应由人工智能驱动的医疗环境。
## 107. `cs.AI` - 相信与否：LLMs 对植入事实的深入信任程度如何？ [PDF](https://arxiv.org/pdf/2510.17941), [HTML](https://arxiv.org/abs/2510.17941)
### Authors
Stewart Slocum,Julian Minder,Clément Dumas,Henry Sleight,Ryan Greenblatt,Samuel Marks,Rowan Wang
### Background
知识编辑技术承诺将新的事实知识植入大型语言模型（LLMs）中。但是，LLMs 真正相信这些事实吗？为了衡量这一点，作者开发了一个框架来测量知识的信念深度，并使用该框架评估知识编辑技术的成功程度。信念深度被定义为植入知识在多个方面的表现：是否能够在相关背景下推广（如 Fermi 估算），是否能够抵抗自我审视和直接挑战，以及其表现方式是否与真实知识相似（通过线性探针测量）。研究表明，简单的提示和机械编辑方法不能深刻植入知识，而合成文档微调（SDF）——即模型在与事实一致的人工智能生成的文档上进行训练——在某些情况下能够成功植入行为类似真实知识的信念，但这种成功并不是绝对的，与基本世界知识相冲突的植入信念是脆弱的，并且在表现上与真实知识不同。
### Innovation
作者引入了一个可测量的信念深度标准，并使用这一标准对知识编辑技术的有效性进行了严格的评估，这为实际应用中部署知识编辑提供了必要的依据。
### Conclusion
研究表明，简单的提示和机械编辑方法无法深刻植入住植入知识，而 SDF 经常可以成功植入类似真实知识的行为的信念。然而，SDF 成功并不是普遍的，与基本世界知识相冲突的植入信念是衰退的，并且在表示上与真实知识不同。总之，本文引入了可量化的信念深度标准，并使对于知识编辑的实际应用进行了严谨的评估成为可能。
## 108. `cs.AI` - SpecAgent:一种用于代码补全的推测性检索与预测代理 [PDF](https://arxiv.org/pdf/2510.17925), [HTML](https://arxiv.org/abs/2510.17925)
### Authors
George Ma,Anurag Koul,Qi Chen,Yawen Wu,Sachit Kuhar,Yu Yu,Aritra Sengupta,Varun Kumar,Murali Krishna Ramanathan
### Background
大规模语言模型（LLMs）在代码相关任务上表现出色，但在实际软件仓库中却常常遇到困难，因为这些仓库需要处理项目特定的API和跨文件依赖关系。检索增强方法可以通过在推理时注入仓库上下文来缓解这一问题，但这种方法在推理时间上的延迟预算受限，会降低检索质量或增加额外的延迟，从而影响用户体验。论文针对这一局限性，提出了一种称为SpecAgent的代理，通过在网络索引时主动探索仓库文件并构建推测性上下文来增强延迟和代码生成质量，推测性上下文在每个文件中预测未来的编辑，这种索引时的异步特性使得上下文计算更彻底，能够隐藏延迟，并提高了代码生成的质量。同时，现有基准测试的问题也导致了未来上下文泄漏，这可能会夸大报告的性能，因此，作者构建了一个合成且无泄漏的基准测试，使得对代理的评估更加现实。实验表明，SpecAgent相比于最佳基准模型，取得了9-11%的绝对增益（相对增益为48-58%），同时显著降低了推理延迟
### Innovation
提出了一种名为SpecAgent的新代理，它能够通过在网络索引时主动探索仓库文件并构建推测性上下文，来同时提高延迟和代码生成质量。推测性上下文能够预见未来的编辑，这种方法能够在索引时实现彻底的上下文计算，从而掩盖延迟，同时提高生成的代码质量。此外，作者还构建了一个新的、不泄漏未来上下文的基准测试，以提供更实际的评估结果。
### Conclusion
实验结果表明，SpecAgent在绝对增益方面比当前最佳基准模型高出了9-11%，相对增益为48-58%，并且极大地减少了推理延迟。此外，通过构建的无未来上下文泄漏的基准测试，更加真实地反映了SpecAgent的性能。
## 109. `cs.AI` - 在虚拟现实下研究机器人干预对学校枪手的影响 [PDF](https://arxiv.org/pdf/2510.17948), [HTML](https://arxiv.org/abs/2510.17948)
### Authors
Christopher A McClurg,Alan R Wagner
### Background
本文通过研究机器人在高风险场景中的介入潜力，特别是如何影响学校枪手的行为，进一步推动了对机器人介入的理解。研究通过一项虚拟现实实验，让150名大学参与者扮演学校枪手，并通过实验模拟机器人介入的效果。
### Innovation
研究创新点在于通过虚拟现实模拟将机器人介入与学校枪手的互动进行了具体实验，其通过自适应策略进行干预和干扰。研究还创新性地根据不同策略（直接干预 vs 保持距离）和不同级别的干扰方法（没有额外提示到使用闪光灯和引发视线障碍的烟雾）来研究机器人介入的具体效果。
### Conclusion
实验结果表明，使用具有高干扰手段的主动机器人介入可以将受害人数减少46.6%，这强调了机器人介入增强安全的可能性，同时也引发了对这种干预措施在学校环境中的使用伦理问题的深入思考。
## 110. `cs.AI` - Intuitionistic $j$-Do-Calculus in Topos Causal Models [PDF](https://arxiv.org/pdf/2510.17944), [HTML](https://arxiv.org/abs/2510.17944)
### Authors
Sridhar Mahadevan
### Background
该论文基于Topos Causal Models（TCMs）框架，该框架利用拓扑学中的子对象来定义因果干预。先前的研究通过引入Lawvere-Tierney拓扑，以及在此基础上定义的模态运算符$j$，对原始的TCMs框架进行了扩展。
### Innovation
论文提出了一种新的因果推理框架，即Intuitionistic $j$-Do-Calculus。该框架通过引入局部真理（由Kripke-Joyal语义定义）替换全局真理，进一步利用内Intuitionistic逻辑的结构保持同态来稳定局部真理。此外，还提出了三个推理规则，类似于Pearl的插入/删除法则和行动/观察变换规则，并证明了这些规则在Kripke-Joyal语义下的正确性。
### Conclusion
本文提出了一种新的因果推理系统，即Intuitionistic $j$-Do-Calculus，该系统在内Intuitionistic逻辑中定义局部真理。并提出了三个推理规则，证明了其正确性。后一篇准备中的论文将进一步探讨如何基于数据估计所需的实体，并实例化Intuitionistic $j$-Do，以及如何通过图手术和分块计算实证结果来认证$ j $-Do规则的前提条件。
## 111. `cs.AI` - 统一光谱提取通过自我监督泛化表示学习 [PDF](https://arxiv.org/pdf/2510.17959), [HTML](https://arxiv.org/abs/2510.17959)
### Authors
Jeff Shen,Francois Lanusse,Liam Holden Parker,Ollie Liu,Tom Hehir,Leopoldo Sarra,Lucas Meyer,Micah Bowles,Sebastian Wagner-Carena,Sebastian Wagner-Carena,Helen Qu,Siavash Golkar,Alberto Bietti,Hatim Bourfoune,Nathan Cassereau,Pierre Cornette,Keiya Hirashima,Geraud Krawezik,Ruben Ohana,Nicholas Lourie,Michael McCabe,Rudy Morel,Payel Mukhopadhyay,Mariel Pettee,Bruno Régaldo-Saint Blancard,Kyunghyun Cho,Miles Cranmer,Shirley Ho
### Background
科学研究中的数据涵盖多个分辨率和领域，将这些数据统一到一个共同表示对于开发科学领域的基础模型至关重要。天文光谱体现了这一挑战：大规模的光谱调查收集了数百万条跨越广泛波长和分辨率的光谱，然而，分析仍然分散在不同的光谱领域（例如光学和红外）和物体类型（例如恒星和星系）之间，限制了跨数据集共享信息的能力。
### Innovation
本文提出了一种深度学习模型，该模型以自我监督的方式共同学习来自各种物体类型和分辨率的异质光谱。这种通用光谱分词器直接在光谱本地波长网格上处理光谱，产生固有的对齐、同质且物理上具有意义的表示，可以高效地适应下游任务并实现具有竞争力的性能。本文首次证明了一个单一模型可以统一不同分辨率和领域的光谱数据，表明该模型可以作为天文学和其他具有异质序列数据的科学领域基础模型的强大构建块。
### Conclusion
该模型对于统一天文科学中的光谱数据具有重要意义，对于其他科学领域，如气候学和医疗保健，也可能扩展适用。
## 112. `cs.AI` - PLAGUE：终身自适应生成多轮攻击的插件式框架 [PDF](https://arxiv.org/pdf/2510.17947), [HTML](https://arxiv.org/abs/2510.17947)
### Authors
Neeladri Bhuiya,Madhav Aggarwal,Diptanshu Purwar
### Background
语言模型（LLMs）的能力在以惊人的速度提升。随着基于代理的工作流的发展，多轮对话已成为与LLMs交互以完成长期复杂任务的默认方式。然而，随着LLMs能力的不断进步，它们在多轮场景中变得更加容易被解锁，有害意图可能会在对话中微妙地注入，从而导致不良结果。尽管单轮攻击已经得到了广泛的研究，但适应性、效率和有效性是其多轮版本面临的持续挑战。
### Innovation
为了解决这些问题，作者提出了PLAGUE，一个基于终身学习代理的多轮攻击的新型插件式框架。PLAGUE将多轮攻击的生命周期分为三个精心设计的阶段（引导期、计划期和完成期），允许系统研究并探索多轮攻击的整个家族。研究表明，使用PLAGUE设计的红队代理在攻击成功率（ASR）上达到了最先进的效果，超过领先模型的30%。特别是在资源限制下，PLAGUE能够实现更高的ASR，例如，在OpenAI的o3模型中达到81.4%，Claude的Opus 4.1模型中达到67.3%，它们被认为是高度抵抗解锁的安全文献中的模型。这项工作提供了一种工具和见解，可用于理解计划初始化、上下文优化和终身学习在构建多轮攻击中的重要性及其对全面模型漏洞评估的作用。
### Conclusion
PLAGUE框架通过将多轮攻击生命周期分解为引导期、计划期和完成期，有效地提高了多轮攻击的成功率，并提供了关于计划初始化、上下文优化和终身学习在构建多轮攻击中的重要性的见解。
## 113. `cs.AI` - 仅使用性能矩阵简化基准分析：SimBA [PDF](https://arxiv.org/pdf/2510.17998), [HTML](https://arxiv.org/abs/2510.17998)
### Authors
Nishant Subramani,Alfredo Gomez,Mona Diab
### Background
现代语言模型通常在大型基准上进行评估，但这些基准难以理解，特别是在模型选择方面。通过聚焦于模型本身，该研究提出了SimBA（简化基准分析），这是一个三阶段框架。第一阶段“stalk”涉及数据集和模型之间的比较。第二阶段“prowl”旨在发现代表性样本集。第三阶段“pounce”则利用这些代表性样本集预测未见过的模型集合的表现。
### Innovation
SimBA提出了一种新型的三阶段框架，分别称为stalk、prowl和pounce，用于简化大型语言模型评估基准的分析。该框架能够使用原始评估分数发现具有代表性的样本集，并通过这些样本集准确预测未见过模型集合表现。
### Conclusion
该框架在HELM、MMLU和BigBenchLite三个流行的语言模型基准测试中进行了测试。结果显示，使用SimBA可以在保持模型排名的同时，使用极少的样本集合实现几乎无误差的性能预测。这表明SimBA有助于模型开发者提高训练效率，并帮助数据集创作者验证其新创建的数据集是否与现有基准中的数据集不同。此外，SimBA的代码已开源，并可在指定的链接获取。
## 114. `cs.AI` - DynaQuery：一种用于查询结构化和多模态数据的自我适应框架 [PDF](https://arxiv.org/pdf/2510.18029), [HTML](https://arxiv.org/abs/2510.18029)
### Authors
Aymane Hassini
### Background
大规模语言模型（LLMs）的发展加快了在复杂混合数据库上使用自然语言查询的目标实现。然而，这带来了双重挑战：如何在结构化、多关系模式和链接的非结构化资产的语义内容上联合推理。
### Innovation
本文提出了DynaQuery——一个统一且自我适应的框架，作为下一代“无界数据库”的实用蓝图。DynaQuery的核心是Schema Introspection and Linking Engine (SILE)，这是一种新颖的系统级组件，将模式关联提升为查询规划的第一类操作。实验评估表明，DynaQuery的设计在结构感知架构上更稳健，几乎消除了架构性灾难性上下文错误，同时也揭示了从纯模式意识向全面语义意识过渡的关键通用原则。
### Conclusion
研究结果为开发稳健、适应性强且一致性的自然语言数据库界面提供了验证的架构基础。
## 115. `cs.AI` - 多语言LLM水印是否真正具有多语言性？一个简单的回译解决方案 [PDF](https://arxiv.org/pdf/2510.18019), [HTML](https://arxiv.org/abs/2510.18019)
### Authors
Asim Mohamed,Martin Gubri
### Background
多语言水印旨在使大规模语言模型（LLM）的输出在跨语言的情况下可追溯，但现有方法仍存在不足。尽管部分方法声称具备跨语言鲁棒性，但它们仅在高资源语言上进行了评估。本文指出，现有方法在中低资源语言下的翻译攻击面前并不真正具备鲁棒性，原因在于词汇表中单词级别的词元数量不足以支持语义聚类。
### Innovation
提出了一种基于回译的检测方法STEAM，用于恢复因翻译而损失的水印强度。该方法兼容任何水印方法，并适用于不同的分词器和语言，非侵入性且易于扩展到新的语言。实验结果显示，STEAM在17种语言上平均提高了0.19的AUC和40%的TPR@1%。
### Conclusion
本文提供了一种简单而鲁棒的方法，旨在公平地在多种语言上实施水印，克服了现有方法在中低资源语言下翻译攻击面前的不足。
## 116. `cs.AI` - SAVANT: 通过视觉增强语义分析的异常检测 [PDF](https://arxiv.org/pdf/2510.18034), [HTML](https://arxiv.org/abs/2510.18034)
### Authors
Roberto Brusnicki,David Pop,Yuan Gao,Mattia Piccinini,Johannes Betz
### Background
自动驾驶系统对罕见、分布外且具有语义异常的场景依然高度脆弱。现有的视觉语言模型虽然提供了潜在的推理能力，但简单的提示方法导致了不可靠的性能，并依赖昂贵的专有模型，限制了实际部署。
### Innovation
我们提出了SAVANT（语义分析与视觉增强异常检测）架构，该架构通过逐层场景分析和两阶段管道实现高准确性和召回率的异常检测：结构化的场景描述提取后是多模态评估。SAVANT 通过四个语义层（街道、基础设施、可移动对象和环境）系统地分析，将视觉语言模型的推理从经验提示转变为系统的分析。
### Conclusion
SAVANT 在现实驾驶场景中达到了89.6%的召回率和88.0%的准确率，显著优于非结构化的基准。更重要的是，我们的结构化框架使得一个带有90.8%召回率和93.8%准确率的7B参数预训练开源模型（Qwen2.5VL）得以实现，而其成本接近零。通过自动准确地标注超过9,640张真实世界的图像，SAVANT 解决了异常检测中的数据稀缺性问题，为自动驾驶系统提供了可靠且易用的语义监控途径。
## 117. `cs.AI` - BadScientist: 可以欺骗LLM评审者的具有说服力但不合实际的论文生成器吗？ [PDF](https://arxiv.org/pdf/2510.18003), [HTML](https://arxiv.org/abs/2510.18003)
### Authors
Fengqing Jiang,Yichen Feng,Yuetai Li,Luyao Niu,Basel Alomair,Radha Poovendran
### Background
LLM驱动的研究助手与基于AI的同行评审系统的融合，导致了一个关键的脆弱性：完全自动化的出版循环，在这种循环中，由AI生成的研究成果被其他AI评审器评估而无需人类监督。这项研究通过BadScientist框架来研究这种可控生成的伪造论文是否能欺骗多模型LLM评审系统，并且该框架中的生成器使用了无需实际实验的演示操作策略。研究发现自动化的伪造论文具有一定的可信度，且评审者往往会提出关于论文可靠性的质疑，但仍然给予这些论文高度的接受评分。尽管采用了严谨的评估框架，但由于缺乏有效的完整性检查机制，这些系统仍然存在严重的漏洞，揭示了当前AI驱动的评审系统的根本局限，强调了对科学出版过程中的多层次防御措施的迫切需求。
### Innovation
开发了BadScientist框架以评估以欺骗为目的的论文生成系统是否能通过多模型LLM评审系统，并提出了严格的评估框架，包括公理化的错误保证、集中度限制和校准分析。生成器使用无需真实实验的演示操纵策略，经过实际数据校准后效果显著。然而，尽管采用了这些严谨的方法，发现伪造论文的接受率仍然很高，且评审者在指出问题的同时仍然给予高度的接受评分，这表明现有的AI驱动评审系统尚不足以检测和阻止这类伪造行为。
### Conclusion
现有的AI驱动的评审系统存在严重的脆弱性和局限性，不能有效地防止伪造论文的通过，这强调了在科学出版流程中多层次防御措施的紧迫性。尽管该方法通过数学证明了聚合算法的有效性，但实际上的完整性检查经常失效，显示了现有AI评审系统的根本缺陷。
## 118. `cs.AI` - 从局部到全局：大规模语言模型中结构化剪枝范式的回顾 [PDF](https://arxiv.org/pdf/2510.18030), [HTML](https://arxiv.org/abs/2510.18030)
### Authors
Ziyan Wang,Enmao Diao,Qi Le,Pu Wang,Minwoo Lee,Shu-ping Yeh,Evgeny Stupachenko,Hao Feng,Li Yang
### Background
结构化剪枝是一种有效部署大语言模型（LLMs）的方法，因为它能产生硬件友好的紧凑架构。然而，主流的本地剪枝方式是任务无关的，虽然可以通过层内重构优化而非特定任务目标，但往往保留了困惑度或泛化的零样本行为，而未能充分利用任务特定的校准信号，导致在下游任务上的效果有限。
### Innovation
本文重新审视了全局结构化剪枝，并提出了一种名为GISP（Global Iterative Structured Pruning）的新方法，该方法在剪枝过程中根据结构级别聚合了一阶损失基础上的重要权重，并在块级进行了归一化。这种迭代过程而非一次性剪枝，在更高稀疏度下稳定了精度，并缓解了困惑度崩溃现象，同时不需要中间的微调。此外，因为重要性定义为模型级别的损失，GISP便于应用特定于任务的目标，实验证明无论是在Llama2-7B/13B、Llama3-8B、还是Mistral-0.3-7B上，GISP都能有效降低WikiText-2的困惑度并提升下游任务的精度，特别是在40-50%稀疏度时效果显著。
### Conclusion
通过GISP方法，可在保持高精度的同时减小模型规模，支持“一次剪枝、多次部署”的工作流程，特别是在稀疏度较高时表现出色，具体表现为在Llama3-8B及DeepSeek-R1-Distill-Llama-3-8B与GSM8K任务上，GISP方法使得模型在特定任务上的表现得到了显著提升。
## 119. `cs.AI` - 跨域长期预报：通过时空操作网络从稀疏中子传感器进行辐射剂量预报 [PDF](https://arxiv.org/pdf/2510.18041), [HTML](https://arxiv.org/abs/2510.18041)
### Authors
Jay Phil Yoo,Kazuma Kobayashi,Souvik Chakraborty,Syed Bahauddin Alam
### Background
科学机器学习中，从稀疏、跨领域的传感器数据预测不可观测的物理量是一个未解决的核心问题。现有的神经运算器和大规模预报模型依赖于密集、同域的输入输出场和短暂时间窗口，而在实际系统中，传感与预测发生在不同的物理空间并且跨越长时间尺度，这种假设是不成立的。STONe提出了解决这一问题的方法。
### Innovation
STONe是一种非自回归神经运算器，学习不同异质域之间的稳定功能映射。它直接从稀疏的地基中子测量数据中推断高空辐射剂量场，表明运算符学习能够在共享域设置之外推广应用。STONe在没有迭代递归的情况下，定义了传感器和目标流形之间的非线性运算符，并在长时间预测方面保持稳定性。这挑战了传统观点，认为运算符学习需要领域对齐或自回归传播。STONe使用23年的全球中子数据训练，实现了180天的准确预报，具有毫秒级推理延迟。该框架为跨域运算符推断提供了一般原理，使物理、气候和能源系统中的复杂时空场实时预测成为可能。
### Conclusion
STONe证明了跨域运算符学习的可行性，无需依赖共享域或自回归传播，实现了长时间尺度的准确预报，适用于多种物理、气候和能源系统的复杂时空预测任务。
## 120. `cs.AI` - 语言模型作为顺序推荐中的语义增强器 [PDF](https://arxiv.org/pdf/2510.18046), [HTML](https://arxiv.org/abs/2510.18046)
### Authors
Mahsa Valizadeh,Xiangjue Dong,Rui Tuo,James Caverlee
### Background
大型语言模型（LLMs）在捕捉不同模态中的潜在语义和上下文关系方面表现出色，但在从顺序交互数据建模用户行为时，若缺乏语义上下文，则会表现出色。因此，论文指出这一限制导致了现有模型性能的下降，尤其是在缺乏相关语义上下文的情况下的表现更为不佳。解决这一问题的途径是引入一种自动语义增强框架，以提升模型在这些问题上的表现。
### Innovation
该研究提出了一种名为LaMAR的LLM驱动的语义增强框架，通过少量示例的方式利用LLM生成辅助上下文信号，以推断用户意图和项目之间的潜在语义方面，并从现有元数据中生成诸如使用场景、项目意图或主题总结等信号，使得原始序列具有更深的上下文。这些生成的信号能够显著提升下游模型的表现，并展现出高语义新颖性和多样性。
### Conclusion
该研究展示了LLM生成信号对顺序推荐任务的增强效果，证明了其作为一种新的以数据为中心的方法，在减少人工干预的同时有效提高了数据质量和模型性能。论文认为，LLMs在这个过程中扮演了智能上下文生成的角色，是创造训练数据和语言资源的新方式。
## 121. `cs.AI` - 测度论导向的反因果表征学习 [PDF](https://arxiv.org/pdf/2510.18052), [HTML](https://arxiv.org/abs/2510.18052)
### Authors
Arman Behnam,Binghui Wang
### Background
在因果关系模型中，通常假定标签导致特征而不是相反，但反因果设置（标签导致特征）提出了独特的挑战，需要专门的方法来解决。
### Innovation
本文提出了Anti-Causal Invariant Abstractions (ACIA)，这一基于测度论的框架用于反因果表征学习。ACIA采用两层次设计，低层次的表征捕捉标签生成观察的过程，高层次的表征学习特定环境变化下的稳定因果模式。ACIA通过干预内核处理完美的和不完备的干预，克服了现有方法的一些关键局限性，包括独立于显式因果结构、高效处理高维数据，并在理论上为跨分布外推广提供了保证。
### Conclusion
实验结果表明，ACIA在合成和真实世界医疗数据集上的准确性和不变性度量上均优于现有的最先进的方法。此外，理论结果还建立了训练环境与未见过环境之间的表现差距的紧确界，证实了该方法在鲁棒反因果学习中的有效性。
## 122. `cs.AI` - TriggerNet：一种新型可解释的人工智能框架在红棕榈虱检测及多模型比较和启发式标注中的应用 [PDF](https://arxiv.org/pdf/2510.18038), [HTML](https://arxiv.org/abs/2510.18038)
### Authors
Harshini Suresha,Kavitha SH
### Background
红棕榈虱的猖獗已经严重影响了广泛种植的棕榈树的区域，导致产量下降和经济损失。准确且早期识别受感染植物对于有效管理至关重要。本文旨在于评估和比较用于植物分类及病害检测的机器学习模型。研究利用了包括红棕榈虱（Raoiella indica）在内的多种害虫，这些害虫对棕榈树种植和农业生产构成了重大威胁。研究使用了11个不同植物种类的RGB图像进行模型训练和测试，并通过启发式规则和模式高效标注病害类别，减少了人工标注时间并提高了数据集的可靠性。
### Innovation
研究提出了一种新颖的可解释人工智能框架——TriggerNet，该框架结合了Grad-CAM、RISE、FullGrad和TCAV，为深度学习模型在植物分类和疾病检测中生成新颖的视觉解释。研究将TriggerNet应用于红棕榈虱的检测，并对多种先进的深度学习模型和机器学习分类器进行了比较。此外，还采用了启发式标注方法提高了数据标注的效率和可靠性。
### Conclusion
本文通过使用TriggerNet框架以及多种先进的深度学习和机器学习模型，对比了其在植物分类和病害检测中的性能，同时通过启发式规则标注病害类别提高了数据采集效率和数据集的可靠性。研究结果表明，TriggerNet框架对于浅层神经网络提供了可解释的可视化解释，对于红棕榈虱检测任务具有很高的应用潜力。
## 123. `cs.AI` - SPACeR: 自主学习中的中央参考模型锚定自我博弈 [PDF](https://arxiv.org/pdf/2510.18060), [HTML](https://arxiv.org/abs/2510.18060)
### Authors
Wei-Jer Chang,Akshay Rangesh,Kevin Joseph,Matthew Strong,Masayoshi Tomizuka,Yihan Hu,Wei Zhan
### Background
开发自动驾驶车辆不仅需要安全和效率，还需要现实、类人的行为，这些行为需要具备社会意识和可预测性。实现这一目标需要一个在多智能体环境中快速且可扩展的人类类代理策略。现有的模仿学习方法通过大规模扩散模型或标记模型直接从人类驾驶数据中捕捉行为，产生真实可信的策略。然而，这些模型在计算上代价高昂，在推理期间速度慢，并且在反应性的闭环场景中难以调整。相比之下，自我博弈强化学习（RL）在规模上高效，自然地捕捉多智能体交互，但通常依赖于启发式方法和奖励塑造，导致生成的策略与人类规范相背离。
### Innovation
我们提出了SPACeR框架，利用预训练的标记自回归运动模型作为中央参考策略来指导分散式的自我博弈。参考模型提供概率奖励和KL散度，将策略保持在人类驾驶分布范围内，同时保持RL的可扩展性。
### Conclusion
在Waymo Sim Agents挑战中，我们的方法在与模仿学习策略竞争的同时，在推理速度上快10倍，参数量小50倍于大型生成模型。此外，我们在闭环自我规划评估任务中展示了我们的模拟智能体可以快速且可扩展地衡量规划器质量，建立了测试自动驾驶策略的新范式。
## 124. `cs.AI` - 使用中间反馈调优流匹配生成模型 [PDF](https://arxiv.org/pdf/2510.18072), [HTML](https://arxiv.org/abs/2510.18072)
### Authors
Jiajun Fan,Chaoran Cheng,Shuaike Shen,Xiangxin Zhou,Ge Liu
### Background
流基生成模型在文本到图像生成方面取得了显著的成功，但用中间反馈对其进行微调仍具挑战性，尤其是对于连续时间流匹配模型。大多数现有方法仅从结果奖励中学习，难以解决归因问题。其他试图通过直接回归累积奖励来学习评判者的方法通常在在线设置中面临训练不稳定性和模型崩溃的问题。
### Innovation
提出了AC-Flow，一种稳健的演员-评判者框架，通过三个方面解决这些挑战：（1）奖励重塑，提供良好的归一化学习信号，以实现稳定的中间值学习和梯度控制；（2）一种新颖的双重稳定性机制，结合了优势剪裁以防止破坏性的策略更新，并引入了一个预热阶段，使评判者在影响演员之前得以成熟；（3）一种可扩展的广泛评判者加权方案，扩展了传统奖励加权方法，同时通过Wasserstein正则化保持模型多样性。
### Conclusion
通过在Stable Diffusion 3上的广泛实验，我们证明AC-Flow在文本到图像对齐任务中达到了最先进的性能，并且对未见过的人类偏好模型具有泛化能力。结果显示，即使使用高效的评判者模型，我们也能在不牺牲生成质量、多样性和稳定性的情况下，稳健地调优流模型。
## 125. `cs.AI` - R2L: 可靠强化学习：保证回报与可靠策略的强化学习 [PDF](https://arxiv.org/pdf/2510.18074), [HTML](https://arxiv.org/abs/2510.18074)
### Authors
Nadir Farhi
### Background
在强化学习（RL）中，经典方法主要侧重于最大化预期回报。然而，许多实际应用场景，如路由、资源分配和风险下的顺序决策，需要确保不仅有高的平均性能，还需要保证一定的成功率。为此，本文提出了一个新的目标，即最大化累计回报超过预定阈值的概率。并通过状态增强表示将可靠RL问题重新表述为标准RL问题，使得可以使用现有的RL和深度RL算法。
### Innovation
本文提出了一种新的优化框架，目标是在不确定性的条件下最大化累计回报超过阈值的概率。这种方法可以利用现有的RL和深度RL算法，从而不需要构建全新的算法框架。理论分析证明了两种表述的等价性，并展示了如何通过调整已知方法（如Q-learning或 Dueling Double DQN）来获得可靠的策略。
### Conclusion
通过分析可靠路由问题，实验证明了所提出的方法能够在效率和可靠性之间取得平衡，突显了可靠RL在随机性和安全性关键环境中的应用潜力。
## 126. `cs.AI` - 自适应发散正则化策略优化算法在生成模型微调中的应用 [PDF](https://arxiv.org/pdf/2510.18053), [HTML](https://arxiv.org/abs/2510.18053)
### Authors
Jiajun Fan,Tong Wei,Chaoran Cheng,Yuxin Chen,Ge Liu
### Background
在使用增强学习（Reinforcement Learning, RL）微调生成模型的过程中，探索与利用之间的平衡是一项关键挑战。现有的方法依赖固定的发散正则化，这种固定方式会带来难以调和的两难境地：强烈的正则化能够保护模型的能力，但会限制回报优化；较弱的正则化可以增强与期望结果的对齐，但也可能引发不稳定性或奖励作弊等问题。现有方法在解决fine-tuning过程中探索与利用之间的平衡时存在不足，这成为该领域的一个瓶颈问题。
### Innovation
本文引入了一种自适应发散正则化策略优化（Adaptive Divergence Regularized Policy Optimization, ADRPO）算法，该算法能够根据优势估计自动调整正则化强度。对于高价值样本减少正则化，而对于不良样本则施加重的正则化，从而允许策略根据数据质量在探索与积极利用之间导航。该算法利用Wasserstein-2正则化进行流匹配生成模型的实现，在文本到图像生成任务中取得了显著效果，超越了像DPO这样的离线方法和各种固定正则化的在线方法。在LLM微调中，ADRPO表现出从局部最优逃脱的主动探索能力；在多模态音频推理中，它在逐步推理的表现上超过了GRPO，使一个小模型能够超越了诸如Gemini 2.5 Pro和GPT-4o Audio等更大规模的商业模型。
### Conclusion
本文提出的ADRPO算法能够有效解决生成模型微调过程中探索和利用的平衡问题。在多种生成模型架构和模态下，可以显著提升模型的属性绑定能力、语义一致性和艺术风格转移等。同时，该方法不仅在文本生成模型微调中表现优异，还将其成功应用到了多模态情景中，提供了一种解决探索与利用难题的有效方法。
## 127. `cs.AI` - Any-深度对齐：解锁LLM在任意深度的内在安全性对齐 [PDF](https://arxiv.org/pdf/2510.18081), [HTML](https://arxiv.org/abs/2510.18081)
### Authors
Jiawei Zhang,Andrew Estornell,David D. Baek,Bo Li,Xiaojun Xu
### Background
现有大语言模型（LLMs）在面对有害查询时表现出较强的但浅层的对齐度。尽管它们在遇到有害查询时会直接拒绝，但这种保护机制在有害内容持续生成时会失效。这些问题引发了如何在任意生成深度确保LLM安全性的根本性疑问。为了应对这一挑战，本文旨在探索是否能够解锁关键的浅层对齐机制，以确保生成的任意深度的安全性。
### Innovation
本文提出的Any-深度对齐（Any-Depth Alignment，ADA）是一种有效的推理时间防御机制，几乎不会增加额外开销。ADA通过重新引入浅层拒绝训练中使用的辅助头标记，重新引发模型在生成过程中的安全性评估，从而在任意深度强制恢复拒绝机制。这种机制在多种开源模型系列（Llama、Gemma、Mistral、Qwen、DeepSeek及gpt-oss）上展现了稳固的安全性能，而无需对基础模型的参数进行任何修改。同时，ADA可以有效抵御具有挑战性的对抗性预填充攻击，并显著降低知名对抗性提示攻击的成功率，同时保持在非有害任务上的实用性并对基础模型后续的指令调优具有抵抗力。
### Conclusion
通过ADA机制，可以确保LLM在生成过程的任意深度实现安全，APT实验结果表明，这种机制在多种现实模型上都表现出稳定的效果，且几乎不增加开销。
## 128. `cs.AI` - R2BC：从单个代理演示进行多代理模仿学习 [PDF](https://arxiv.org/pdf/2510.18085), [HTML](https://arxiv.org/abs/2510.18085)
### Authors
Connor Mattson,Varun Raveendra,Ellen Novoseller,Nicholas Waytowich,Vernon J. Lawhern,Daniel S. Brown
### Background
模仿学习（IL）是人类向机器人教学的自然方式，尤其当高质量示范容易获得时。尽管IL已经在单机器人设置中广泛使用，但对于多代理系统的应用研究却相对较少，特别是在一个单一的人类必须为协作机器人团队提供演示的情境下。本文研究了Round-Robin行为克隆（R2BC）方法，该方法能通过顺序单代理示范有效训练多代理系统。这种方法使人类一次只能操作一个代理，但可以通过这种方式逐步教会整个系统多代理行为，不需要多代理联合动作空间的示范。研究表明，R2BC方法在四个多代理模拟任务中，达到了甚至超过了一个基于预分配同步示范训练的oracle方法的表现。
### Innovation
R2BC方法实现了一个单一的人类操作员能够通过顺序单个代理的示范来有效训练多代理系统，而不需要在联合多代理动作空间中进行示范。这使得训练过程更加灵活和高效。通过在四个多代理模拟任务中的表现，R2BC方法展现出优于或等同于基于同步示范训练的方法的性能。此外，该方法还在两个物理机器人任务的训练中得到了实际应用，使用了真实的人类示范。
### Conclusion
本文提出并研究了R2BC方法，证明了其在多代理系统模仿学习方面的能力和适用性，特别是在单个代理示范的情形下。未来的工作可以考虑进一步优化该方法，提高其泛化能力，并应用于更多实际场景。
## 129. `cs.AI` - Latent Discrete Diffusion Models [PDF](https://arxiv.org/pdf/2510.18114), [HTML](https://arxiv.org/abs/2510.18114)
### Authors
Dario Shariatian,Alain Durmus,Stefano Peluchetti
### Background
研究离散扩散模型在语言和其他分类数据中的应用，关注masked denoisers的常见限制：反向转换通常在位置间分解，这会削弱联合结构并降低多步生成的质量。
### Innovation
提出了一种新的自编码器范式——Latent Discrete Diffusion Models (LDDMs)，结合了带掩码符号的离散扩散和连续的潜在嵌入扩散。LDDMs 包含两种实现：FUJI-LDDMs 和 SEQ-LDDMs。这两种模型分别提供联合和顺序解决潜在嵌入和离散链路的方式，并且提出了相应的目标函数和设计选择以学习具有信息量但仍适用于扩散模型。
### Conclusion
LDDMs 在非条件生成指标上优于最新的带掩码符号的离散扩散基线模型，并且在采样预算较低时表现出有效性，可以在每步解掩更多符号。
## 130. `cs.AI` - 使用可变 Patch 大小加速视觉变换器 [PDF](https://arxiv.org/pdf/2510.18091), [HTML](https://arxiv.org/abs/2510.18091)
### Authors
Rohan Choudhury,JungEun Kim,Jinhyung Park,Eunho Yang,László A. Jeni,Kris M. Kitani
### Background
视觉变换器(Vision Transformers, ViTs)将输入图像划分为均匀大小的块，而不考虑其内容，导致高分辨率图像具有较长的输入序列长度。这就导致了对高分辨率图像的效率问题和计算资源的高需求。
### Innovation
提出了自适应 Patch 变换器(Adaptive Patch Transformers, APT)，它在同一张图像中使用多种不同的 Patch 大小。APT 通过在更同质的区域分配更大的 Patch 大小，在更复杂的区域分配较小的 Patch 来减少总输入标记数量。这不仅提高了 ViT 的推理和训练速度，还能应用于预训练过的 ViT，只需不到 1 个训练周期即可收敛。APT 在高分辨率密集视觉任务中可以在不损失性能的情况下显著减少训练和推理时间，并且在视觉问答、目标检测和语义分割等任务中可以实现最多 30% 的加速效果。
### Conclusion
APT 通过自适应调整不同区域的 Patch 大小，实现了对高分辨率视觉任务的高效处理，大幅提升了视觉变换器的处理效率，并保持了下游任务的性能。
## 131. `cs.AI` - 基于RL的意识安全资源分配框架用于UAV辅助O-RAN [PDF](https://arxiv.org/pdf/2510.18084), [HTML](https://arxiv.org/abs/2510.18084)
### Authors
Zaineh Abughazzah,Emna Baccour,Loay Ismail,Amr Mohamed,Mounir Hamdi
### Background
无人航空器（UAVs）集成到开放无线电接入网络（O-RAN）中能够增强灾害管理和搜救（SAR）操作中的通信，尤其是在基础设施失效时保证连通性。然而，搜救场景要求严格的安全性和低延迟通信，任何延迟或安全漏洞都可能影响任务的成功。虽然UAVs可以作为移动中继器来使用，但它们也带来了能源消耗和资源管理的挑战，需要智能的分配策略。现有的UAV辅助O-RAN方法往往忽略了在动态环境中安全、延迟和能源效率的联合优化。因此，该研究旨在提出一种基于强化学习（RL）的动态资源分配框架来应对这些权衡，并为UAV中继提供安全、延迟最小化和能源效率的综合解决方案。
### Innovation
该研究提出了一种基于强化学习（RL）的框架，专门用于UAV辅助O-RAN环境中动态资源的智能分配，能够在动态网络环境中实时适应，确保通信的鲁棒性。该框架综合考虑了安全资源分配、延迟最小化和能源效率的问题，并使用RL解决了优化问题。与启发式或静态方法不同，该框架能够实时适应网络动态变化，优于启发式的基线方法，展现了更高的安全性和能源效率，同时保持超低的延迟，在SAR场景中表现出色。
### Conclusion
通过使用基于RL的方法，本研究成功地解决了UAV辅助O-RAN环境中安全、延迟和能源效率之间的权衡问题，实现了增强的安全性和能源效率，同时保持了超低的延迟。实验结果表明，该框架相较于启发式基线方法具有显著优势，能够在动态环境中提供更稳健的通信保障，这对于灾害管理和搜救操作具有重要意义。
## 132. `cs.AI` - 从 AutoRecSys 到 AutoRecLab：关于构建、评估和治理自主可控推荐系统研究实验室的呼吁 [PDF](https://arxiv.org/pdf/2510.18104), [HTML](https://arxiv.org/abs/2510.18104)
### Authors
Joeran Beel,Bela Gipp,Tobias Vente,Moritz Baumgart,Philipp Meister
### Background
推荐系统的研究推动了模型和评估的进步，但忽略了自动化研究过程本身。目前的研究更多集中于算法选择和超参数调整等狭窄领域。论文提出了一种从单一的 AutoRecSys 工具转向Autonomous Recommender-Systems 研究实验室（AutoRecLab）的理念，AutoRecLab 能够实现从问题的构想到文献分析、实验设计与执行、结果解析、论文撰写以及验证的过程自动化。这项研究借鉴了近期自动科学研究的进展，旨在推动 RecSys 社区实现这一转变，涉及点包括构建结合 AI 助手的开放原型，建立评估标准等。
### Innovation
论文提出了一种名为 AutoRecLab 的新型自主可控推荐系统研究实验室的理念，该实验室能够端到端地自动化研究过程，从问题构想到结果解析等所有环节都被纳入自动化流程中。此外，论文还提倡了一系列措施，如建设开放式原型、建立评估基准、透明化 AI 生成的提交内容等，以促进推荐系统领域的自动化研究，并强调伦理、治理、隐私和公平性的跨学科对话成为自主研究的关键议题。
### Conclusion
推进这一议程不仅能够提高研究效率，发现非明显见解，还能够使推荐系统研究贡献于新兴的自动化研究人工智能。最后，作者呼吁组织社区活动来协调下一步工作，并为负责任地整合自动研究系统提供指导。
## 133. `cs.AI` - SafeCoop：揭示智能协作驾驶的安全性 [PDF](https://arxiv.org/pdf/2510.18123), [HTML](https://arxiv.org/abs/2510.18123)
### Authors
Xiangbo Gao,Tzu-Hsiang Lin,Ruojing Song,Yuheng Wu,Kuan-Ru Huang,Zicheng Jin,Fangzhou Lin,Shinan Liu,Zhengzhong Tu
### Background
协作驾驶系统利用多代理间的车辆到一切（V2X）通信来提升驾驶安全性和效率。传统V2X系统使用原始传感器数据、神经特征或感知结果作为通信媒介，面临高带宽需求、语义损失和互操作性问题等挑战。近年来，自然语言被研究为理想的通信媒介，能够提供丰富的语义信息、决策级推理和人机互操作性，同时带宽需求显著降低。虽然自然语言在V2X通信中展现巨大潜力，但其传输过程中也存在新的安全问题，如消息丢失、幻觉、语义篡改和对抗攻击等。
### Innovation
本文首次全面研究基于自然语言的协作驾驶的安全性和安全性问题。具体上，作者提出了攻击策略的全面分类，包括连接中断、接力/重放干扰、内容伪造和多连接伪造。为缓解这些风险，作者提出了Agentic防御管线SafeCoop，集成了语义防火墙、语言感知一致性检查和多来源共识功能，这些功能通过代理转换函数实现了跨帧空间对齐。研究在封闭环CARLA模拟器上系统性地评估了SafeCoop，结果表明，在恶意攻击下能提高69.15%的驾驶得分，并能达到67.32%的恶意检测F1分数。这项研究为推动交通系统中安全、可靠、可信赖的自然语言驱动协作研究提供了指导。
### Conclusion
本研究为推进安全、可靠和可信赖的自然语言驱动协作交通系统的研究提供了指导。SafeCoop防御解决方案的有效性和全面性验证为未来智能网联汽车技术的实际应用奠定了基础。
## 134. `cs.AI` - 通过MIMIC-IV结构化临床数据元模型增强心脏骤停ICU患者的死亡率预测 [PDF](https://arxiv.org/pdf/2510.18103), [HTML](https://arxiv.org/abs/2510.18103)
### Authors
Nursultan Mamatov,Philipp Kellmeyer
### Background
ICU内的住院死亡率准确早期预测对于及时临床干预和高效资源分配至关重要。这项研究旨在通过整合结构化临床数据和非结构化文本信息（如出院总结和放射学报告），利用机器学习模型提高预测准确性。该研究基于MIMIC-IV数据库进行。
### Innovation
研究使用LASSO和XGBoost进行特征选择，然后使用两者的顶级特征训练多变量Logistic回归模型。此外，通过TF-IDF和BERT嵌入将文本特征纳入模型显著提高了预测性能。最终的Logistic回归模型整合了结构化和文本输入，AUC达到0.918，比仅使用结构化数据时的0.753提高了22%。结果表明，未结构化的临床笔记具有额外的预后价值，并支持将其整合到可解释特征驱动的风险预测模型中。
### Conclusion
该模型展示了广泛阈值概率下的标准化净效益优势，验证了其临床应用价值。研究结果强调了整合未结构化临床记录的重要性，支持它们融入可解释的特征驱动风险预测模型中，以提高ICU患者的死亡率预测准确性。
## 135. `cs.AI` - 通过适应性选择提示技术实现自动提示生成 [PDF](https://arxiv.org/pdf/2510.18162), [HTML](https://arxiv.org/abs/2510.18162)
### Authors
Yohei Ikenoue,Hitomi Tashiro,Shigeru Kuroyanagi
### Background
大型语言模型（LLMs）的可靠和有效输出依赖于提示工程，但设计提示需要专门的提示技术知识和对目标任务的深刻理解。现有的提示生成方法通常依赖预设模板或框架，这要求用户具备一定专业背景，对于非专家来说较为困难。因此，有必要提出一种新的方法，能够根据用户的抽象任务描述，自适应地选择合适的提示技术，并自动生成高质量的提示，减少对预设模板或框架的依赖，使非专业人士也能有效利用LLMs。
### Innovation
提出了一种新型方法，该方法通过构建包含任务簇与相应提示技术关联的知识库，能够自适应选择提示技术，实现无需依赖预设模板或框架的高质量提示自动生成。该方法能够在用户输入任务描述后，自动将其归类到最相关的任务簇中，并根据该簇中的提示技术动态生成提示，从而提高了提示生成的灵活性和准确性。
### Conclusion
通过在BIG-Bench Extra Hard (BBEH)数据集上的23个任务上的实验评估，证明了该方法在性能上优于标准提示和现有的自动提示生成工具，具体表现通过算术均值和调和均值评分予以反映。此研究为提示创建的标准化打下了基础，使得非专家也能有效利用LLMs。
## 136. `cs.AI` - VelocityNet：通过基于人员特定速度分析的实时人群异常检测 [PDF](https://arxiv.org/pdf/2510.18187), [HTML](https://arxiv.org/abs/2510.18187)
### Authors
Fatima AlGhamdi,Omar Alharbi,Abdullah Aldwyish,Raied Aljadaany,Muhammad Kamran J Khan,Huda Alamri
### Background
在拥挤的场景中检测异常具有挑战性，因为存在严重的相互遮挡和高度动态且依赖于上下文的运动模式。现有方法常常难以适应变化的密度人群，并缺乏可解释的异常指标。
### Innovation
我们引入了一个名为VelocityNet的双管道框架，结合头部检测和密集光流以提取人员特定的速度。层级聚类将这些速度分类为语义化的运动类别（停止、缓慢、正常和快速），并且基于百分位的异常评分系统衡量从已学正常模式的偏差。实验表明，我们的框架能够实时检测密集人群环境中多种多样的异常运动模式。
### Conclusion
我们的框架在现实环境中有效检测出了多样且具有挑战性的异常运动模式。
## 137. `cs.AI` - 在大规模生态环境中的复杂行为涌现 [PDF](https://arxiv.org/pdf/2510.18221), [HTML](https://arxiv.org/abs/2510.18221)
### Authors
Joseph Bejjani,Chase Van Amburg,Chengrui Wang,Chloe Huangyuan Su,Sarah M. Pratt,Yasin Mazloumi,Naeem Khoshnevis,Sham M. Kakade,Kianté Brantley
### Background
本文探索物理尺度和人口规模如何塑造开放生态环境中复杂行为的出现。在设定中，代理未经过监督，没有明确的奖励或学习目标，而是随着时间的推移根据繁殖、变异和自然选择进化。代理在行动时也会影响其环境和周围的人口，形成动态的生态系统。本研究的目的是观察复杂行为如何在自然竞争和环境压力下在大规模人口中涌现，而非优化单一高性能策略。
### Innovation
本文通过在具有数千个个体代理的大规模世界中进行实验，每个代理都有自己进化的神经网络策略，识别出诸如远程资源提取、基于视觉的觅食和捕食等复杂行为在竞争和生存压力下的涌现。此外，研究还考察了不同感觉模式和环境规模对这些行为出现的影响，发现某些行为仅在足够的大环境中和人口中出现，较大的环境规模能够提高行为的稳定性和一致性。
### Conclusion
虽然关于进化环境的研究有着丰富的历史，但本文的大规模扩展结果为进一步探索生态学作为机器学习工具的新方向提供了有力的证据。大量可用的计算资源为这一领域带来了新的机遇。实验代码可在该网址找到。
## 138. `cs.AI` - RadDiagSeg-M：一种用于放射学联合诊断和多目标分割的视觉语言模型 [PDF](https://arxiv.org/pdf/2510.18188), [HTML](https://arxiv.org/abs/2510.18188)
### Authors
Chengrun Li,Corentin Royer,Haozhe Luo,Bastian Wittmann,Xia Li,Ibrahim Hamamci,Sezgin Er,Anjany Sekuboyina,Bjoern Menze
### Background
目前大多数医疗视觉语言模型在面对复杂视觉问题时，难以同时生成诊断文本和像素级分割掩模。这一限制阻碍了这些模型在临床中的应用，因为不能同时提供这两种模态的系统为医学从业者提供的帮助有限。因此，有必要开发能够同时处理这两种任务的模型来提高诊断的准确性与实用性。现有模型和数据集尚不能满足临床需求，缺乏能够同时提供诊断性和描述性信息的联合视觉语言模型。因此，需要一种新的数据集和模型来解决这一问题，以支持更全面的临床应用需求。
### Innovation
本研究首先提出了RadDiagSeg-D数据集，该数据集结合了异常检测、诊断和多目标分割任务，涵盖了多种成像模态，并将其设计为支持生成描述性文本和相应分割掩模的任务。其次，基于该数据集，提出了新的视觉语言模型RadDiagSeg-M，该模型能够在联合识别异常、进行诊断的同时实现灵活的分割，输出丰富且临床有用的诊断结果，从而有效提高了辅助诊断的实用性。研究通过基准测试展示了RadDiagSeg-M在多目标文本-掩模生成任务中的全面性能，为领域内的其他研究提供了强有力的基准。
### Conclusion
RadDiagSeg-M模型在辅助诊断方面的性能表现优异，能够同时提供详细的诊断文本和有用的分割掩模。通过基准测试，RadDiagSeg-M已经成为该领域中一个强大且具有竞争力的基准。该模型为未来的放射学辅助诊断系统开发奠定了坚实的基础，促进了临床应用的发展。
## 139. `cs.AI` - VLSU: 映射联合多模态理解在AI安全性中的极限 [PDF](https://arxiv.org/pdf/2510.18214), [HTML](https://arxiv.org/abs/2510.18214)
### Authors
Shruti Palaskar,Leon Gatys,Mona Abdelrahman,Mar Jacobo,Larry Lindsey,Rutika Moharir,Gunnar Lund,Yang Xu,Navid Shiee,Jeffrey Bigham,Charles Maalouf,Joseph Yitan Cheng
### Background
目前对多模态基础模型的安全评估通常将视觉和语言输入分开处理，忽视了联合解释中可能带来的风险，即原本无害的内容在结合后变得有害。现有的方法也没有明确区分不安全内容和临界案例，导致过度阻断或对真正有害的内容响应不足。这引发了如何有效评估多模态安全性、并准确区分不安全内容与临界案例的问题。
### Innovation
本文提出了Vision Language Safety Understanding (VLSU)，这是一种全面的框架，通过细粒度的严重性分类和17种不同安全模式的组合分析，系统地评估多模态安全性。通过一个多阶段管道和真实世界图像及人工注释构建了一个包含8,187个样本的大型基准数据集，覆盖了15个危害类别。该框架揭示了多模态理解中联合理解失败的问题，以及现有模型在平衡阻止不安全内容和响应需要互动的临界案例之间的挑战。
### Conclusion
本文的研究结果揭示了联合图像-文本理解中的弱点和现有模型中的对齐差距，为未来的研究提供了关键的验证平台。未来的研究可以在该基础上进一步改善多模态理解和模型的鲁棒性，使得模型能够在处理真正有害内容的同时，有效避免过度阻断或对需要互动的临界案例处理不足。
## 140. `cs.AI` - 对比解码减轻LLM作为评判者的评分范围偏差 [PDF](https://arxiv.org/pdf/2510.18196), [HTML](https://arxiv.org/abs/2510.18196)
### Authors
Yoshinari Fujinuma
### Background
大规模语言模型（LLMs）在各种应用中常被用作评估者，但其评估结果的可靠性仍是一个挑战。特别是在直接评估场景中，即不使用任何参考材料直接赋予特定范围内的分数时，LLMs的表现尤为不确定。这种方法下的一个主要问题是LLM评判者的输出分数会受到预定义评分范围的影响，从而妨碍寻找最佳评分范围。研究发现在同一模型家族的不同模型中都存在类似的评分范围偏差问题。这种偏差影响了LLM作为评判者时的准确性和可靠性，从而对基于LLM的评估准确性构成威胁。
### Innovation
本文通过对比解码（contrastive decoding）的方法减轻了LLM作为评判者的评分范围偏差。通过该方法，研究人员实现了不同评分范围下人类判断相关性的平均提升幅度高达11.3%的相对改进，这表明提出的对比解码方法对于减轻评分范围偏差具有显著效果。该创新点在于提出了一种有效的方法来提高LLM作为评判者时的评估准确性，这对于更广泛的自然语言处理及评估应用场景具有重要意义。
### Conclusion
本文研究了大规模语言模型作为评判者时存在的评分范围偏差问题，并通过对比解码的方法成功减轻了这一偏差。实验结果显示该方法有效提升了评分的一致性和准确性。未来可以进一步研究对比解码的具体机制及其在其他评估任务中的应用。
## 141. `cs.AI` - 规模法则与模型架构相遇：迈向高效推理的大语言模型 [PDF](https://arxiv.org/pdf/2510.18245), [HTML](https://arxiv.org/abs/2510.18245)
### Authors
Song Bian,Tao Yu,Shivaram Venkataraman,Youngsuk Park
### Background
大型语言模型（LLM）性能的提升主要依赖于参数数量和训练数据规模的增加。随着这些模型变得越来越强大，广泛部署，推理成本已成为一个紧迫的问题。然而，模型准确性和推理效率之间的权衡尚未得到充分探索。
### Innovation
本文通过研究隐藏层大小、MLP与注意力参数分配（MLP-to-注意力比例）以及分组查询注意力等因素对推理成本和准确性的影响，提出了一个条件性规模定律，该定律扩展了Chinchilla框架并引入了一种搜索框架来确定同时具备高效推理和高准确性的架构。研究者通过训练超过200个模型，得出了一个可靠的条件性规模定律，并证明优化的架构在相同训练预算下相较于LLaMA-3.2能够提高2.1%的准确性和42%的推理吞吐量。
### Conclusion
所提出的条件性规模定律可以可靠地预测最优架构选择，并且由此产生的模型在广泛使用的开源基准上表现出色。
## 142. `cs.AI` - EVER: 边缘辅助自动验证在移动混合现实辅助操作中的应用 [PDF](https://arxiv.org/pdf/2510.18224), [HTML](https://arxiv.org/abs/2510.18224)
### Authors
Jiangong Chen,Mingyu Zhu,Bin Li
### Background
混合现实（MR）通过在物理世界叠加数字对象，提供更沉浸和直观的操作流程。主要挑战在于通过比较操作前后帧来精确且快速地自动验证用户是否遵循了MR指导。前期帧包括虚拟引导对象，后期帧包含物理对应物。现有方法未能有效处理物理和虚拟对象之间的差异，原因在于不完美的3D建模或光照估计。论文针对这一问题提出了EVER：一种基于边缘的自动验证系统，用于移动MR辅助操作。不同于传统的基于帧相似性的比较方法，EVER利用了适应具有物理部件和虚拟对应物框架的独特属性的分割模型和渲染管道，并采用基于阈值的策略结合交并比（IoU）指标进行精确的自动验证。为了实现快速自动验证和低能耗，EVER将计算密集型任务卸载到边缘服务器。通过使用公开数据集和自定义实用数据集进行全面评估，EVER在100毫秒内实现了超过90%的验证准确率（显著快于平均人类反应时间约为273毫秒），同时与无自动验证系统相比仅消耗极少量额外的计算资源和能量。
### Innovation
提出了EVER：一种基于边缘的自动验证系统，用于移动MR辅助操作。该系统利用独特的分割模型和渲染管道来处理物理和虚拟对象之间的差异，采用交并比（IoU）指标的阈值策略进行精确的自动验证。为了实现快速验证和低能耗，EVER将计算密集型任务卸载到边缘服务器。相比传统方法，EVER不仅提高了验证速度，还降低了能耗。
### Conclusion
通过全面的评估，EVER在100毫秒内实现了超过90%的验证准确率，显著优于平均人类反应时间，并在计算资源和能源使用方面表现优异。
## 143. `cs.AI` - NTKMTL：从神经核角度缓解多任务学习中的任务不平衡 [PDF](https://arxiv.org/pdf/2510.18258), [HTML](https://arxiv.org/abs/2510.18258)
### Authors
Xiaohan Qin,Xiaoxing Wang,Ning Liao,Junchi Yan
### Background
多任务学习（MTL）能够使单个模型同时学习多个任务，并通过任务间的知识迁移提升泛化能力，广泛应用于各个领域。然而，任务间的不平衡仍然在MTL中是一个主要挑战。平衡不同任务的收敛速度是解决该问题的有效方法，但在复杂的MTL系统中，准确描述多个任务的训练动力学和收敛速度极具挑战性。
### Innovation
本文通过利用神经核理论（NTK）来分析MTL的训练动力学，并提出了一种新的MTL方法NTKMTL。具体而言，引入了扩展的NTK矩阵，并采用谱分析来平衡多个任务的收敛速度，从而缓解任务不平衡。进一步提出的NTKMTL-SR，不仅实现了训练效率，还能保持竞争力。
### Conclusion
广泛的实验表明，我们的方法在包括多任务监督学习和多任务强化学习在内的多种基准上达到了最先进的性能。相关源代码可以在以下链接获得。
## 144. `cs.AI` - DelvePO：方向引导的自我演化框架以实现灵活的提示优化 [PDF](https://arxiv.org/pdf/2510.18257), [HTML](https://arxiv.org/abs/2510.18257)
### Authors
Tao Tao,Guanghui Zhu,Lang Guo,Hongyi Chen,Chunfeng Yuan,Yihua Huang
### Background
提示优化已经逐渐成为关键的方法，因为其能够引导大规模语言模型解决各种任务。然而，目前的研究主要依赖于大型语言模型的随机重写能力，优化过程通常集中在特定的影响因素上，这容易陷入局部最优。此外，优化后的提示性能往往是不稳定的，这限制了不同任务间的转移性。
### Innovation
本文提出了DelvePO（基于方向引导的自我演化框架，用于灵活的提示优化），这是一种任务无关的框架，能够自适应地优化提示。该框架将提示分解为不同的组件，以探索不同因素对各种任务的影响。在此基础上，引入工作记忆，从而减轻大型语言模型自身不确定性的缺陷，并进一步获得关键见解以引导新提示的生成。
### Conclusion
在不同任务和多种领域的广泛实验中，包括DeepSeek-R1-Distill-Llama-8B、Qwen2.5-7B-Instruct和GPT-4o-mini，实验结果表明DelvePO在相同的实验条件下始终优于现有的SOTA方法，显示出其在不同任务中的有效性和可转移性。
## 145. `cs.AI` - 寻找完美的平衡点：使用ADASYN优化信用评分中的数据增强比率 [PDF](https://arxiv.org/pdf/2510.18252), [HTML](https://arxiv.org/abs/2510.18252)
### Authors
Luis H. Chia
### Background
信用评分模型面临严重挑战，即严重的类别不平衡，违约率通常低于10%，这影响了模型的学习和预测性能。尽管已经提出了如SMOTE和ADASYN这样的合成数据增强技术来解决这个问题，但最佳增强比率尚不清楚，实践者通常默认采用完全平衡（1:1比率）而没有实证依据。
### Innovation
本研究系统地评估了10种数据增强场景，使用了97,243个观察数据（7%的违约率）的Give Me Some Credit数据集，并在不同的倍数下比较了SMOTE、BorderlineSMOTE和ADASYN的表现。关键发现表明，ADASYN在1x乘数（少数类加倍）情况下性能最佳，AUC为0.6778，Gini系数为0.3557，分别提升了0.77%和3.00%，具有统计学显著性（p = 0.017，自助测试）。更高的倍数（2x和3x）导致性能下降，3x显示了-0.48%的AUC下降，表明增强合成过采样的“边际效益递减法则”。研究发现最优的类别不平衡比率为6.6:1，与普遍平衡比率1:1矛盾。
### Conclusion
本研究首次提供了信用评分中数据增强的最优“完美平衡点”的实验证据，并为处理不平衡数据集的行业从业者和研究人员提供了实用指导。虽然在单一代表性数据集上进行了演示，但该方法提供了一个在其他不平衡领域确定最优增强比率的可再现框架。
## 146. `cs.AI` - 利用时间运动先验的双曲空间学习方法用于人体网格恢复 [PDF](https://arxiv.org/pdf/2510.18256), [HTML](https://arxiv.org/abs/2510.18256)
### Authors
Xiang Zhang,Suping Wu,Weibin Qiu,Zhaocheng Jin,Sheng Yang
### Background
三维人体网格显示出自然的层级结构（例如躯干-四肢-手指）。然而，现有的基于视频的三维人体网格恢复方法通常在欧几里得空间学习网格特征，难以准确捕捉这种层级结构，从而导致重建错误的人体网格。为解决该问题，本文提出了一种利用时间运动先验的双曲空间学习方法，该方法从输入的三维姿态序列和图像特征序列中提取时间运动特征，并将它们结合形成时间运动先验，从而增强在时间运动维度表达特征的能力。由于非欧几里得空间中的数据表示已被证明能有效捕捉现实世界数据集中的层级关系（特别是在双曲空间中），本文进一步设计了一种双曲空间优化学习策略，该策略利用时间运动先验信息辅助学习，并在双曲空间中分别使用三维姿态及其运动信息来优化和学习网格特征，最终结合优化结果以获得准确且平滑的人体网格。除此之外，为了使人体网格在双曲空间中的优化学习过程稳定有效，本文还提出了一种双曲网格优化损失函数。广泛实验结果表明该方法在大量公开数据集上的表现优于大多数现有最佳方法
### Innovation
提出了一种利用时间运动先验的双曲空间学习方法。该方法包括设计一个时间运动先验提取模块，以增强在时间运动维度上表达特征的能力；利用非欧几里得空间中的数据表示的优势，设计了一个双曲空间优化学习策略，该策略利用时间运动先验信息辅助学习，并在双曲空间中优化和学习三维网格特征；提出了一种双曲网格优化损失函数以使优化学习过程稳定有效。
### Conclusion
提出的方法在大量公开数据集上的表现优于大多数现有最佳方法，表明该方法的有效性和优越性。
## 147. `cs.AI` - SPIKE: 稳定的物理信息核演变方法用于求解双曲守恒律 [PDF](https://arxiv.org/pdf/2510.18266), [HTML](https://arxiv.org/abs/2510.18266)
### Authors
Hua Su,Lei Zhang,Jin Zhao
### Background
本文介绍了一种用于求解无粘双曲守恒律的稳定物理信息核演变（SPIKE）方法。这一方法解决了强形式残差最小化如何能够捕捉含有间断性的弱解这一基本悖论。现有方法难以同时准确捕捉间断性特征和满足守恒要求，因此SPIKE方法应运而生，以解决这一问题。
### Innovation
SPIKE方法采用核重建表示，通过正则化参数演变实现。其中，Tikhonov正则化提供了通过激波形成平滑过渡的机制，从而使动态能够穿越激波奇点。这种方法能够自动保持守恒，追踪特征，且在统一框架内满足Rankine-Hugoniot条件，无需显式地进行激波检测或使用人工粘性。
### Conclusion
SPIKE方法在标量和向量形式的守恒律数值验证中表现出了有效性，表明该方法能够有效地捕捉间断性和满足守恒原理，为求解双曲守恒律提供了新的方法和思路。
## 148. `cs.AI` - 人类网格恢复中的潜在信息和低维度学习及其并行优化 [PDF](https://arxiv.org/pdf/2510.18267), [HTML](https://arxiv.org/abs/2510.18267)
### Authors
Xiang Zhang,Suping Wu,Sheng Yang
### Background
现有的3D人类网格恢复方法往往未能充分利用潜在信息（例如，人类动作、形状对齐），导致重建的人类网格存在肢体对齐问题和局部细节不足的问题，特别是在复杂场景中。此外，通过使用注意力机制建模网格顶点和姿态节点的交互虽然能够提高性能，但所需的计算成本非常高。
### Innovation
本文提出了一种基于潜在信息和低维度学习的两阶段网络用于人类网格恢复。第一阶段从图像特征的低频和高频成分中全面挖掘全局和局部信息，并将其聚合为混合的潜在频率域特征，以有效提取潜在信息。第二阶段，利用提取的混合潜在频率域特征，通过低维度的网格姿态交互方法优化粗略的3D人类网格模板和3D姿态，优化网格的姿态和形状。这种方法在计算成本显著降低的情况下，仍能保持重建精度。
### Conclusion
广泛的实验结果表明，本方法在大规模公开数据集上的表现优于当前最先进的方法。
## 149. `cs.AI` - 高维线性回归中的量化学习 [PDF](https://arxiv.org/pdf/2510.18259), [HTML](https://arxiv.org/abs/2510.18259)
### Authors
Dechen Zhang,Junwei Su,Difan Zou
### Background
虽然低位量化被广泛用于提高大规模模型的训练效率，但在学习性能方面缺乏严格的理论理解，即使是线性回归这类简单的场景也是如此。本文对这一基础问题进行了系统的理论分析，研究了在高维线性回归中不同量化目标（数据、标签、参数、激活和梯度）下的有限步随机梯度下降（SGD）算法。研究结果表明，不同的量化方式会影响学习过程中的噪声特征、数据谱的扭曲以及量化误差的引入。对于乘法量化，可以消除数据谱扭曲；而加性量化则表现出随批次大小增加的风险有益增长。在布尔多项式衰减的数据谱情况下，对两种量化方法的风险进行了定量比较，展示了与浮点和整数量化方法的相似性。上述理论为研究实际硬件限制下的学习理论提供了强有力的框架.
### Innovation
首次系统研究了高维线性回归中不同量化目标对学习性能的影响，建立了精确的算法依赖性和数据依赖性过拟合风险界，特别证明了对于乘法量化，数据谱扭曲可以被消除，而加性量化则表现出随批次大小增加的风险有益增长。理论还对比了两种量化方法在常见多项式衰减数据谱中的风险表现，提出了与浮点和整数量化方法的类比，为量化影响学习动态提供了新颖的分析框架.
### Conclusion
本文的研究为理解量化对高维线性回归学习动态的影响提供了深刻的见解，证明了在乘法量化中可以通过特定量化步长消除谱扭曲，而在加性量化中则出现有益的缩放效应。这些发现为在实际硬件限制下探索学习理论奠定了基础，并为未来的研究提供了强大的分析工具.
## 150. `cs.AI` - StreamingTOM：高效视频理解的流式 token 压缩 [PDF](https://arxiv.org/pdf/2510.18269), [HTML](https://arxiv.org/abs/2510.18269)
### Authors
Xueyi Chen,Keda Tao,Kele Shao,Huan Wang
### Background
与离线处理相比，流式视频视觉-语言模型面临两个基本约束：因果关系和累积。因果关系使得流式模型无法访问离线方法可以利用的未来帧；累积则导致token数量无限制增长，造成效率瓶颈。现有方法仅调节后端LLM的kv缓存，而前置LLM的填充成本仍然高昂。
### Innovation
本文引入了StreamingTOM，这是一种无需训练、即插即用的两阶段框架，有效解决了前置LLM和后端LLM的效率瓶颈，并能够预测性地控制延迟。Causal Temporal Reduction对每帧应用固定预算，并基于相邻帧的变化和token的重要性选择token，从而大大减少每帧填充成本，仅处理每个帧的一部分视觉token而不是所有视觉token。Online Quantized Memory将token以4位格式存储，在需要时按需检索并解量化，保持活跃的kv缓存大小不受流长影响。实验结果显示，的方法实现了15.7倍kv缓存压缩，1.2倍更低的峰值内存和2倍更快的TTFT，与前SOTA方法相比。StreamingTOM在无需训练的方法中保持了最佳的准确率，在离线基准上平均为63.8%，在RVS上为55.8%/3.7。
### Conclusion
这些结果突显了我们两阶段方法在流式视频理解中的实际优势，能够在保持增长受控的情况下实现高效的视频理解。
## 151. `cs.AI` - 文字还是像素？只需一半：关于多模态大语言模型中视觉文本输入的令牌效率 [PDF](https://arxiv.org/pdf/2510.18279), [HTML](https://arxiv.org/abs/2510.18279)
### Authors
Yanhong Li,Zixuan Lan,Jiawei Zhou
### Background
大规模语言模型和其多模态变种现在可以处理视觉输入，包括文本图片。因此，一个引人关注的问题出现了：我们可以将文本输入以图像形式喂入模型来压缩令牌使用量，同时保持模型性能吗？研究人员发现，将长文本输入以图像形式呈现给解码器大语言模型（LLMs），可以大幅减少解码器所需的令牌数量，从而提供了一种新的输入压缩方式。实验结果显示，在两个不同的基准测试RULER（长文本上下文检索）和CNN/DailyMail（文档摘要）上，这种方法可以节省大量令牌（通常能达到约一半），并且不会降低任务性能。
### Innovation
该论文的创新点在于发现了一种新的方法，即将长文本输入以图像形式呈现给解码器大语言模型，从而大幅减少所需的解码器令牌数量，提高了令牌使用效率。这种方法不仅在视觉文本输入上有效，还在两个不同的基准测试上表现出显著的性能
### Conclusion
该研究证明了视觉文本表示是一种实际且出人意料有效的输入压缩形式，对于解码器大语言模型来说，通过将文本输入以图像形式呈现，可以高效节约令牌资源，而不会影响任务性能。此方法为提高大语言模型的令牌效率和性能提供了一种新的途径。
## 152. `cs.AI` - 从检索到生成：统一外部和参数化知识进行医疗问题问答 [PDF](https://arxiv.org/pdf/2510.18297), [HTML](https://arxiv.org/abs/2510.18297)
### Authors
Lei Li,Xiao Zhou,Yingying Zhang,Xian Wu
### Background
医疗问答（QA）需要广泛获取特定领域的知识。现有方法主要分为两种：检索增强生成（RAG），它以外部检索到的证据为基础进行推理；生成增强生成（GAG），它完全依赖模型内部的知识生成上下文文件。然而，RAG常常因为检索不准确或不完整而存在问题，而GAG则因为生成缺乏约束而可能产生虚假或不准确的信息。这两个问题都可能误导推理并降低答案的可靠性。
### Innovation
本文提出了MedRGAG，这是一种统一的检索-生成增强框架，能够无缝地整合外部和参数化知识以进行医疗QA。MedRGAG包含两个关键模块：知识导向的上下文完成（KGCC），旨在引导生成器生产能够补充检索显示缺失知识的背景文件；以及知识感知文档选择（KADS），能够在检索和生成的文档之间选择最佳组合，以形成简洁而全面的证据来生成答案。
### Conclusion
通过对五个医疗QA基准的广泛实验，结果表明，MedRGAG相比MedRAG提升了12.5%，相比MedGENIE增加了4.5%，突出了统一检索和生成方法在知识密集型推理中的效果。此外，此代码和数据已在公开发布。
## 153. `cs.AI` - 更高嵌入维度为简单排序任务创建更强的世界模型 [PDF](https://arxiv.org/pdf/2510.18315), [HTML](https://arxiv.org/abs/2510.18315)
### Authors
Brady Bhalla,Honglu Fan,Nancy Chen,Tony Yue YU
### Background
研究人员探讨了嵌入维度对训练用于执行相邻交换的强化学习transformer模型内部“世界模型”形成的影响。研究表明，即使嵌入维度很小，模型也能达到高精度，但较大的嵌入维度可以产生更加忠实、一致和稳健的内部表示。特别是，较高的嵌入维度增强了结构化内部表示的形成，并提高了可解释性。通过数百次实验，研究者观察到两个一致的机制：1. 注意力权重矩阵的最后一行单调地编码了令牌的全局顺序；2. 选择的置换与这些编码值中最大的相邻差值对齐。这些研究结果提供了证据，说明transformer能够构建结构化内部世界模型，而且模型大小不仅提高了最终性能，还改善了表示质量。
### Innovation
该研究发现较高的嵌入维度增强了transformer模型内部结构化的世界模型表示，并使模型的表示更加忠实、一致和稳健。进一步，研究指出transformer最终的注意力权重矩阵单调地编码了令牌的全局顺序，而所选的变换与这些编码值中的最大相邻差值对齐。此外，研究者依据实验证据表明，随着模型规模的增加，不仅可以提升最终性能，也能提升表示质量，从而提供了一个更强的世界模型用于简单的排序任务。该研究发布相关度量标准和分析，可用于探究类似的算法任务。
### Conclusion
研究表明，较大的嵌入维度可以提高transformer内部结构表示的忠实度和一致性，且对于简单的排序任务，更高的嵌入维度增强了其内部世界模型的形成，从而达到更好的性能和解释性。该研究结果提供了定量证据支持transformer构建结构化内部世界模型，并且模型大小将进一步提升表示质量而非仅仅是最终性能。
## 154. `cs.AI` - 一步流匹配方法实现可扩展、可解释且稳健的异常检测 [PDF](https://arxiv.org/pdf/2510.18328), [HTML](https://arxiv.org/abs/2510.18328)
### Authors
Zhong Li,Qi Huang,Yuxuan Zhu,Lincen Yang,Mohammad Mohammadi Amiri,Niki van Stein,Matthijs van Leeuwen
### Background
当前，半监督表数据中的异常检测方法在生成建模框架中占有一席之地，尽管这些框架已经显示出与扩散模型和生成对抗网络相比的强大性能，但它们仍存在复杂的训练目标和高推理成本等缺陷。因此，研究团队引入了时间条件收缩匹配(TCCM)方法，该方法结合了流匹配的思想，但通过简化框架，提出了一种轻量级且可扩展的训练目标，解决了这些现有方法中的许多挑战。
### Innovation
TCCM方法创新性地提出了时间条件收缩匹配(TCCM)方法，它建立在流匹配的核心理念之上，即在分布之间学习速度场。TCCM通过每一步预测从给定点向预定目标(原点)的时间条件收缩向量，简化了模型结构。这种方法提供了三个关键优势：(1)轻量级且可扩展的训练目标，无需在训练和推理期间求解常微分方程；(2)高效的单步偏差评分策略，通过单一前向传递量化与预期收缩行为的偏差，解决了现有连续时间模型的推理瓶颈；(3)可解释性和证明式的鲁棒性，通过直接在输入空间操作学习到的速度场使得异常分数可按特征分解，同时，分数函数对输入具有Lipschitz连续性，提供了解小扰动下的理论保证。
### Conclusion
TCCM方法在ADBench基准上的实验表明，它在检测精度和推理成本之间取得了平衡，尤其是在高维度和大规模数据集上超过了最先进的方法。该研究为表数据的半监督异常检测提供了一种新的有效方法。
## 155. `cs.AI` - S2AP: Score-space Sharpness Minimization for Adversarial Pruning [PDF](https://arxiv.org/pdf/2510.18381), [HTML](https://arxiv.org/abs/2510.18381)
### Authors
Giorgio Piras,Qi Zhao,Fabio Brau,Maura Pintor,Christian Wressnegger,Battista Biggio
### Background
对抗剪枝方法已经成为在保持对抗攻击鲁棒性的同时压缩神经网络的一种强大工具。这些方法通常遵循三步流程：首先预训练一个鲁棒的模型，然后选择一个二进制掩码进行权重剪枝，最后微调剪枝后的模型。在选择二进制掩码时，这些方法通过为每个权重分配重要性得分并最小化鲁棒损失，来确定权重的保留与否。然而，这种得分空间优化可能会导致鲁棒损失景观中的尖锐局部最小值，从而导致掩码选择不稳定，降低对抗剪枝方法的鲁棒性。
### Innovation
我们提出了一种新的对抗剪枝插件方法，称为Score-space Sharpness-aware Adversarial Pruning (S2AP)。该方法通过扰动重要性得分并最小化相应的鲁棒损失来实现得分空间尖锐性的最小化，从而在掩码搜索过程中稳定掩码选择，提高对抗剪枝方法的鲁棒性。
### Conclusion
我们通过在多个数据集、模型和稀疏性级别上的广泛实验表明，S2AP有效地降低了得分空间的尖锐性，稳定了掩码选择，并最终提高了对抗剪枝方法的鲁棒性。
## 156. `cs.AI` - MENTOR: 一个通过教师优化奖励提升小型模型的强化学习框架 [PDF](https://arxiv.org/pdf/2510.18383), [HTML](https://arxiv.org/abs/2510.18383)
### Authors
ChangSu Choi,Hoyun Song,Dongyeon Kim,WooHyeon Jung,Minkyung Cho,Sunjin Park,NohHyeob Bae,Seona Yu,KyungTae Lim
### Background
将大型语言模型（LLMs）的工具使用能力提炼到更小、更高效的中小型语言模型（SLMs）中是其实际应用的一个关键挑战。传统的监督微调（SFT）方法由于训练模型单纯模仿固定的教师轨迹而缺乏泛化能力。传统的使用稀疏奖励的强化学习（RL）方法，在引导SLMs时效果不佳，导致探索效率低下及采用次优策略。
### Innovation
提出了一种名为MENTOR的新框架，结合了RL与教师引导的蒸馏。MENTOR通过探索过程学习更通用的策略，解决了稀疏奖励的问题，使用教师的参考轨迹构造密集合的教师引导奖励，提供更精细的指导。
### Conclusion
广泛的实验表明，MENTOR显著提升了SLMs的跨域泛化能力和策略智能，相比SFT和标准稀疏奖励RL基线有显著提升。
## 157. `cs.AI` - PGTT：基于相位导向的地形穿越技术以增强腿部移动感知 [PDF](https://arxiv.org/pdf/2510.18348), [HTML](https://arxiv.org/abs/2510.18348)
### Authors
Alexandros Ntagkas,Chairi Kiourt,Konstantinos Chatzilygeroudis
### Background
现有的强化学习控制器大多数会施加限制模型结构的动作前馈或者依靠内部感知地形的信息，这限制了其适用性。前者通过振荡器或IK基的方式限制动作空间，虽然保持了一定的适应性但增加了偏见；后者则缺乏地形预测能力，容易受到噪音的影响。
### Innovation
本文提出了一种感知导向的强化学习方法——相位导向地形穿越（PGTT），通过奖励塑造方式来完全维持步态结构，减少了与其他动作先验的诱导偏见相比，这种方法降低了学习策略的偏见。PGTT根据每条腿的相位情况（用三次埃尔米特样条表示），适应高度地图中的局部变化，并加入摆动相接触惩罚，同时策略直接在关节空间中操作，支持跨形态的部署。
### Conclusion
PGTT在MuJoCo (MJX)上经过阶梯地形训练后，能够最有效地抵抗推力干扰（中位数增加7.5%），在离散障碍物（增加9%）的处理上也表现出色，同时能以两倍于其他强大端到端基线的速度收敛。利用实时LiDAR高度图生成管道，PGTT在Unitree Go2上的实验结果与ANYmal-C的初步结果均显示出成功的前景。这表明，地形适应性、相位导向的奖励塑造是实现跨平台可靠感知移动的简单而通用机制。
## 158. `cs.AI` - MoMaGen: Soft and Hard Constraints for Multi-Step Bimanual Mobile Manipulation Demonstrations [PDF](https://arxiv.org/pdf/2510.18316), [HTML](https://arxiv.org/abs/2510.18316)
### Authors
Chengshu Li,Mengdi Xu,Arpit Bahety,Hang Yin,Yunfan Jiang,Huang Huang,Josiah Wong,Sujay Garlanka,Cem Gokmen,Ruohan Zhang,Weiyu Liu,Jiajun Wu,Roberto Martín-Martín,Li Fei-Fei
### Background
从大规模、多样的人类示范中进行模仿学习已经被证明对于训练机器人有效，但收集此类数据成本高且耗时。对于两步或多步的双臂移动操作而言，这一挑战更为突出，因为人类必须操控移动底座和两个高自由度的臂。现有自动数据生成框架试图通过在模拟中增强有限的人类示范来解决静态双臂操作问题，但在移动环境中由于两个关键问题——确定底座放置以确保可达性以及定位摄像头提供充分的视觉可见性——表现不佳。因此，需要一种能够解决这些问题的新方法来生成相关数据集。
### Innovation
我们提出了MoMaGen，它将数据生成形式化为一个受限优化问题，不仅确保硬约束（如可达性）的实现，还平衡软约束（例如，在导航过程中提供足够的视觉可见性）。这种方法可以泛化先前的方法，并为未来的方法提供了一种原理上的基础。实验结果表明，MoMaGen生成的数据集显著比现有方法更多样化，这些多样化数据集能够从单一源示例中训练成功的模仿学习策略。这些策略仅需40个真实世界的示范即可进行微调，从而实现物理机器人硬件的应用部署。
### Conclusion
MoMaGen为解决两步或多步双臂移动操作的生成示范问题提供了一种创新方法，通过优化技术克服了硬约束和软约束之间的平衡。通过这种方法生成更丰富多样的数据集，不仅能从单一示范进行有效的策略训练，还能显著减少实际示范的数量，从而快速实现物理硬件的应用部署。
## 159. `cs.AI` - 在Open RAN中的AI验证 [PDF](https://arxiv.org/pdf/2510.18417), [HTML](https://arxiv.org/abs/2510.18417)
### Authors
Rahul Soundrarajan,Claudio Fiandrino,Michele Polese,Salvatore D'Oro,Leonardo Bonati,Tommaso Melodia
### Background
开放RAN引入了一种灵活的基于云的架构，用于无线接入网络（RAN），并支持跨多厂商部署的AI/ML驱动自动化。虽然可解释的AI（XAI）有助于降低AI模型的透明度，但解释性本身并不能保证可靠的网络操作。
### Innovation
提出了一种基于可解析模型的轻量级验证方法，用于验证深度强化学习（DRL）代理在Open RAN中的行为，特别是在RAN切片和调度中的行为。使用决策树（DT）基验证器进行近实时运行时一致性检查，克服了现有成本高且计算密集型的验证器的局限性。
### Conclusion
分析了XAI和AI验证的景观，提出了可扩展的架构集成，并通过基于决策树（DT）的切片验证器进行了可行性演示。还概述了确保Open RAN中可信AI采用的未来挑战。
## 160. `cs.AI` - 乐观的高等阶超运算 [PDF](https://arxiv.org/pdf/2510.18429), [HTML](https://arxiv.org/abs/2510.18429)
### Authors
Alexander Bentkamp,Jasmin Blanchette,Matthias Hetzenberger,Uwe Waldmann
### Background
λ-超运算是一种成功的用于验证高等阶公式的方法。然而，这种方法中存在极为爆炸性的部分，主要是由于高阶联接器枚举和函数扩张性公理引起的问题。本文介绍了一种改进的乐观版λ-超运算，旨在解决上述问题。
### Innovation
该新的技术采用约束存储方式延缓具有爆炸性问题的联接，并在更精确的方式下应用函数扩张性公理。改进后的技术在Henkin语义下保持健全且归谬完备。尽管尚未在处理器实现，但示例表明它将超越或至少能有益地补充原来的λ-超运算技术。
### Conclusion
新提出的乐观版λ-超运算技术在解决原来方法中问题的同时保持了语言的健全性和完备性，且在实际应用中表现出潜在的优势。
## 161. `cs.AI` - 在使用OCR引导的YOLOv8和轨迹建模进行板球视频中单局段和薄弱环节自动检测 [PDF](https://arxiv.org/pdf/2510.18405), [HTML](https://arxiv.org/abs/2510.18405)
### Authors
Mst Jannatun Ferdous,Masum Billah,Joy Karmoker,Mohd Ruhul Ameen,Akif Islam,Md. Omar Faruqe
### Background
本文提出了一个基于深度学习技术的自动化板球视频分析系统，旨在识别摘取局的投球、检测板球及建模球的轨迹。该系统利用了YOLOv8架构进行球场与球的检测，并结合光学字符识别(OCR)进行得分卡提取，以识别摘取局的时刻。通过对图像的全面预处理，包括灰度变换、幂变换和形态学操作，系统实现了从视频帧中稳健地提取文本。实验结果表明，探测投球的模型实现了99.5%的mAP50（50% IoU）精度为0.999，而利用迁移学习进行球检测的模型取得了99.18%的mAP50，精度为0.968，召回率为0.978。系统通过在检测到的球场上进行轨迹建模，提供了数据驱动的见解，用于识别击球手的弱点。在多个板球比赛视频的实验结果证明了该方法在自动化板球分析中的有效性，为教练和策略决策提供了重要的潜力。
### Innovation
该系统结合了YOLOv8架构和光学字符识别(OCR)，用于板球视频中摘取局辨别及球轨迹建模。全面的图像预处理技术增强了文本和物体的准确检测。模型在精度和召回率上都取得了高成绩，特别适用于自动化板球分析和提供击球手弱点的洞察。
### Conclusion
该研究通过使用OCR引导的YOLOv8和轨迹建模，针对板球视频中的摘取局段和薄弱环节检测提出了一个自动化分析系统。这个系统的高准确性和性能，尤其是在多个板球比赛视频中的表现，证明了其在教练和策略决策中的潜在价值。
## 162. `cs.AI` - 基于M个正样本的N元组数据学习：无偏风险估计与理论保证 [PDF](https://arxiv.org/pdf/2510.18406), [HTML](https://arxiv.org/abs/2510.18406)
### Authors
Miao Zhang,Junpeng Li,ChangChun HUa,Yana Yang
### Background
弱监督学习通常使用粗略的聚合信号而非实例标签。本文研究一种设置，其中每个训练样例是一个n元组，包含恰好m个正例，但仅观察到每个元组的计数m。这种NTMP（N元组含M个正例）监督在图像分类中使用区域提案和多实例测量时存在。文章展示元组计数通过连接元组生成过程和隐含实例边缘概率可以得到一个可训练的无偏风险估计器（URE）。从固定的（n, m）开始，文章推导出闭形式的URE，并将其扩展到可变元组大小、可变计数及其结合的情况。识别成立的条件是有效混合率与类先验分离。通过Rademacher复杂度，建立了泛化界，并在轻微正则性假设下证明了统计一致性。为了提高有限样本稳定性，文章引入了简单的ReLU修正来保持渐近正确性。
### Innovation
文章创新性地展示了元组计数可以通过与隐含实例边缘概率链接得到可训练的无偏风险估计器（URE）。文章推导出了闭形式的URE，并将其扩展到可变元组大小和变化的计数及其组合。此外，文章通过引入简单的ReLU修正来改进有限样本的稳定性，同时保持渐近正确性。实验表明该方法在基准任务转换为NTMP任务时，能显著优于代表性弱监督基准，并且在类别先验不平衡和不同元组配置下都保持鲁棒性。
### Conclusion
通过对有限样本的稳定性改进，该方法在转换为NTMP任务的基准测试中一致性地优于代表性的弱监督基准，并且在类别先验不平衡和不同元组配置中都表现良好，证明了仅通过计数的监督也可以通过一个理论基础坚实且实践稳定的优化目标进行有效利用。
## 163. `cs.AI` - Simple and Efficient Heterogeneous Temporal Graph Neural Network [PDF](https://arxiv.org/pdf/2510.18467), [HTML](https://arxiv.org/abs/2510.18467)
### Authors
Yili Wang,Tairan Huang,Changlong He,Qiutong Li,Jianliang Gao
### Background
异质时态图（HTGs）在现实世界中无处不在，最近为增强HTGs上的表示学习，提出了许多基于注意力的神经网络。然而，现有方法依赖于分离的时间和空间学习范式，这减弱了时空信息的交互，导致了高模型复杂度。
### Innovation
提出了一种名为Simple and Efficient Heterogeneous Temporal Graph Neural Network（SE-HTGNN）的新学习范式。SE-HTGNN通过引入一种新颖的动态注意力机制将时间建模整合到空间学习中，保留了从历史图快照中获得的注意力信息来指导后续注意力计算，从而提高了HTGs的整体区分性表示学习。此外，通过利用大型语言模型对SE-HTGNN进行提示，模型可以捕捉节点类型隐含的特性作为先验知识，以全面和适应性地理解HTGs。
### Conclusion
广泛的实验表明，SE-HTGNN在保持最佳预测准确性的同时，比最先进的和最新的基线模型快10倍。
## 164. `cs.AI` - ScaleNet：通过增量参数扩展预训练神经网络 [PDF](https://arxiv.org/pdf/2510.18431), [HTML](https://arxiv.org/abs/2510.18431)
### Authors
Zhiwei Hao,Jianyuan Guo,Li Shen,Kai Han,Yehui Tang,Han Hu,Yunhe Wang
### Background
近期研究显示，更大的视觉变压器（ViTs）模型通常能够获得更优秀的性能，但训练这些模型同样面临巨大的计算成本。为了应对这一挑战，作者提出了一种名为ScaleNet的有效扩展ViT模型的方法。ScaleNet与从头训练完全不同，它通过插入额外层并利用层间权重共享来迅速扩展模型，同时保持参数的高效性。此外，为了减轻由于权重共享可能引起的性能下降，作者在每层引入了一组调整参数，这些调整参数是通过并行适配器模块实现的，确保共享参数张量在每层中的唯一性和优化效果。
### Innovation
提出了ScaleNet方法，这是一种基于增量参数的将预训练模型扩展为更大模型的高效方法。该方法通过在预训练的ViT模型中插入额外的层并利用层间权重共享来扩展模型规模，同时保持参数效率。通过引入调整参数，解决了由于权重共享可能引起的性能下降问题，确保了共享参数张量在每层中的唯一性和优化效果。实验结果表明，ScaleNet在ImageNet-1K数据集上的应用能够有效扩展ViT模型，相比于从头训练，可达到7.42%的精度提升，同时只需要三分之一的训练周期。
### Conclusion
ScaleNet方法为提升视频处理任务中的模型性能提供了一种低成本的解决方案，特别是在图像分类任务中表现出了高效性，并且也显示出在物体检测等下游视觉任务中的应用潜力。
## 165. `cs.AI` - DeLoad：基于需求的短视频预加载及可扩展观看时间估算 [PDF](https://arxiv.org/pdf/2510.18459), [HTML](https://arxiv.org/abs/2510.18459)
### Authors
Tong Liu,Zhiwei Fan,Guanyan Peng,Haodan Zhang,Yucheng Zhang,Zhen Wang,Pengjin Xie,Liang Liu
### Background
短视频流媒体已成为数字媒体的主导模式，其特点是快速滑动交互和多样的媒体内容。一个关键的技术挑战是如何设计有效的预加载策略，该策略能够动态地从不断更新的播放列表中选择并优先处理下载任务，同时在实际的商业约束下实现用户体验（QoE）和带宽效率之间的平衡。然而，现实世界的数据分析表明，现有方法存在关键缺陷：（1）无法充分适应动态条件下的下载任务大小；（2）难以大规模可靠地部署基于观看时间预测的模型。
### Innovation
本文提出了一种名为DeLoad的新预加载框架，通过引入动态任务大小和实际的多维度观看时间估算方法来解决上述问题。此外，还训练了一个基于深度强化学习（DRL）的代理以自适应优化下载范围决策。在离线测试平台上，利用大量的实际网络数据进行的广泛评估表明，DeLoad在QoE指标上实现了显著的改进（34.4%到87.4%的提升）。在大规模商用短视频平台上的部署显示，DeLoad提高了整体用户观看时间0.09%，同时减少了重缓冲事件和3.76%的带宽消耗。
### Conclusion
DeLoad框架通过引入动态任务大小和实际的多维度观看时间估算方法以及基于深度强化学习的代理，实现了短视频预加载的显著改进。其QoE指标有了明显提升，并在实际应用中展示了其在用户观看时间和带宽效率上的优化效果。
## 166. `cs.AI` - One Size Fits All? 一个通用方案？一种可模块化适应的隐私保护电话诈骗检测套件（MASK） [PDF](https://arxiv.org/pdf/2510.18493), [HTML](https://arxiv.org/abs/2510.18493)
### Authors
Kangzhong Wang,Zitong Shen,Youqian Zhang,Michael MK Cheung,Xiapu Luo,Grace Ngai,Eugene Yujun Fu
### Background
电话诈骗仍然对个人安全和金融安全构成全球性威胁。近年来，大型语言模型（LLMs）展现出通过分析电话通话转录来检测欺诈行为的强大潜力。然而，这些能力带来了显著的隐私风险，因为在处理过程中敏感的个人信息经常会被暴露给第三方服务提供商。
### Innovation
本文探讨了如何利用LLMs进行电话诈骗检测的同时保护用户隐私。提出了一种名为MASK（Modular Adaptive Sanitization Kit）的可训练且可扩展框架，实现了根据个人偏好进行动态隐私调整。MASK提供了一个可插拔架构，支持多种不同的去隐私化方法，从传统的关键词技术到复杂的神经方法。
### Conclusion
该研究提出了MASK框架，旨在创建真正个性化、隐私意识强的LLM基础检测系统，兼顾用户信任和检测效果，超越了电话诈骗的情境。
## 167. `cs.AI` - ImageGem：用于生成模型个性化的一种真实环境生成图像交互数据集 [PDF](https://arxiv.org/pdf/2510.18433), [HTML](https://arxiv.org/abs/2510.18433)
### Authors
Yuanhe Guo,Linxi Xie,Zhuoran Chen,Kangrui Yu,Ryan Po,Guandao Yang,Gordon Wetztein,Hongyi Wen
### Background
文章指出，目前生成模型难以理解精细的个人偏好，主要原因是缺乏野外（即真实世界）的精细用户偏好标注。为了克服这一挑战，作者提出了一套名为ImageGem的数据集，包含57000名用户的真实交互数据，这些用户共同创建了242000个定制LoRA，写下了300万条文本提示，并生成了500万张图像。通过这些用户偏好标注，训练出更优的偏好对齐模型，并进一步研究了检索模型和个人化图像检索，以及视觉-语言模型在个性化图像检索和生成模型推荐方面的表现。最后，提出了一种端到端框架，用于在潜空间中编辑自定义扩散模型，以与个人偏好对齐。这一结果表明，ImageGem数据集首次支持了生成模型个性化的全新范式.
### Innovation
提出了一个名为ImageGem的数据集，旨在研究能够理解精细个人偏好的生成模型。该数据集包括了大量的用户交互数据，并利用这些数据训练出了更好的偏好对齐模型。此外，研究了基于个人偏好的检索模型和视觉-语言模型在个性化图像检索和生成模型推荐方面的情况，最后提出了一种编辑自定义扩散模型的方法，使其能够与个人偏妤对齐。这项工作为生成模型的个性化提供了新的方法和数据支持.
### Conclusion
ImageGem数据集首次支持了生成模型个性化的全新范式，通过提供大量细粒度的真实用户偏好标注，促进了更加个人化的生成模型的发展，并展示了基于个人偏好的检索和推荐系统的潜力。
## 168. `cs.AI` - 基于文本增强检索生成的零样本车辆模型识别 [PDF](https://arxiv.org/pdf/2510.18502), [HTML](https://arxiv.org/abs/2510.18502)
### Authors
Wei-Chia Chang,Yan-Ann Chen
### Background
车辆车型识别（VMMR）是智能交通系统中的重要任务，但现有的方法难以适应新发布的车型。CLIP 提供了强大的视觉-文本对齐能力，但由于其固定的学习权重，在不进行昂贵的图像特定微调的情况下限制了性能提高。
### Innovation
本文提出了一种结合视觉语言模型（VLM）和检索增强生成（RAG）的管道，通过文本推理支持零样本识别。视觉语言模型将车辆图像转换为描述属性，并将其与已知文本特征数据库进行比较，从而检索相关信息并生成提示，随后语言模型推断车型。该设计避免了大规模的重新训练，可以通过增加新的车辆描述实现快速更新，而在视觉特征上无需进行特定的微调。实验表明，该方法的识别准确率比 CLIP 基线提高了近20%，展示了增强后的语言模型推理在智能城市应用中进行大规模VMMR的潜力。
### Conclusion
所提出的方法提高了车辆型号识别的准确性，并通过文本增强检索生成的方法实现了零样本识别，避免了大规模的重新训练，使得系统的更新更加便捷高效。
## 169. `cs.AI` - 注意触发词：构建能够在蒸馏过程中存活的后门 [PDF](https://arxiv.org/pdf/2510.18541), [HTML](https://arxiv.org/abs/2510.18541)
### Authors
Giovanni De Muri,Mark Vero,Robin Staab,Martin Vechev
### Background
LLMs在下游用户中常被用作知识蒸馏的教师模型，将其能力压缩进更节省内存的模型。然而，由于这些教师模型可能来自不可信的来源，知识蒸馏可能会引发意外的安全风险。本文研究了来自被篡改教师模型的知识蒸馏的安全影响。研究发现，现有后门大多未成功转移到学生模型中，原因在于现有的LLM后门方法选择的触发词很少出现在常规上下文中。研究者提出了一个新的后门技术T-MTB，它通过精心构建复合触发词，使其在蒸馏过程中能够被转移，从而提升了后门的转移性。
### Innovation
引入了新的后门技术T-MTB，该技术通过使用常见于预期蒸馏数据集的多个特定触发词构建复合触发词，使得在蒸馏过程中后门能够顺利转移，同时保持高度隐蔽性。这项技术使得研究人员能够更容易地构造和研究可转移后门的安全风险，包括越狱和内容调制两种攻击场景，以及四种不同类型的LLM模型家族。
### Conclusion
通过T-MTB技术，研究者演示并深入探讨了知识蒸馏过程中可转移后门的安全风险。研究结果表明，现有对知识蒸馏安全风险的理解可能过于乐观，必须更加警惕那些能够抵抗知识蒸馏的后门威胁。
## 170. `cs.AI` - CodeRL+: 通过执行语义对齐进行强化学习改进代码生成 [PDF](https://arxiv.org/pdf/2510.18471), [HTML](https://arxiv.org/abs/2510.18471)
### Authors
Xue Jiang,Yihong Dong,Mengyang Liu,Hongyi Deng,Tian Wang,Yongding Tao,Rongyu Cao,Binhua Li,Zhi Jin,Wenpin Jiao,Fei Huang,Yongbin Li,Ge Li
### Background
大语言模型（LLMs）通过学习庞大的代码语料库，在代码生成方面表现出色。然而，它们在训练过程中学习的是文本模式，而其目标是功能正确性，这由形式执行语义所控制。强化学习带有可验证奖励（RLVR）方法试图通过执行测试案例的结果奖励来弥合这一差距。然而，仅依赖二元通过/失败信号不足以建立良好对齐的连接，特别是在代码中的细微逻辑错误方面。论文分析了当前RLVR方法的局限性。
### Innovation
本文提出了CodeRL+，这是一种通过将执行语义对齐整合到RLVR训练管道中来改进代码生成的新方法。CodeRL+允许模型推断变量级执行轨迹，直接提供执行语义的学习信号。该方法能够直接使用现有的策略采样进行执行语义对齐，并能无缝集成到各种RL算法中。
### Conclusion
广泛的实验表明，CodeRL+在提高代码生成性能方面优于post-training基线方法，包括RLVR和蒸馏方法，平均提高了4.6%的通过率@1。此外，CodeRL+在其他编程任务（代码推理和测试输出生成）上的准确性分别高出15.5%和4.4%。CodeRL+在多种RL算法和大语言模型中显示出广泛的应用性。探针分析进一步证明了CodeRL+加强了代码文本表示与其执行语义之间的对齐。
## 171. `cs.AI` - 知识图谱中公平感知图神经网络的基准研究 [PDF](https://arxiv.org/pdf/2510.18473), [HTML](https://arxiv.org/abs/2510.18473)
### Authors
Yuya Sasaki
### Background
图神经网络（GNNs）是处理图结构数据的强大工具，但通常会针对敏感属性产生有偏的预测。公平感知的GNNs已经被积极研究以减轻有偏预测。然而，以往的研究尚未在知识图谱中评估公平感知的GNNs，而知识图谱是许多应用如推荐系统的重要图类型。因此，本文介绍了针对知识图谱的基准研究。基于YAGO、DBpedia和Wikidata这三个知识图谱创建了新的图数据，生成的图数据比现有公平性研究中使用的图数据集要大得多，并在不同的GNN架构和提前停止条件下对加工处理和预处理方法进行了基准测试，以评估公平性与预测准确性之间的权衡关系，以及GNN核心结构与提前停止条件的影响。
### Innovation
本文首次在知识图谱中对公平感知的GNNs进行评估，并利用YAGO、DBpedia和Wikidata三个大规模知识图谱生成新图数据。研究发现了几个关键见解：知识图谱展示了和现有数据集不同的趋势，在公平性感知的GNNs中，预测准确性和公平性指标之间的权衡更为清晰；公平性感知算法、GNN核心结构和提前停止条件对性能影响显著；预处理方法通常能提高公平性指标，而加工方法通常能提高预测准确性。
### Conclusion
知识图谱展示了与现有数据集不同的趋势，公平感知的GNNs在预测准确性和公平性指标之间存在权衡关系。此外，除去公平感知的GNN方法，GNN核心结构和提前停止条件也显著影响性能。预处理方法有时会提高公平性指标，而加工方法会提高预测准确性。进一步的研究可进一步优化GNN模型以同时提高这两个关键维度的表现。
## 172. `cs.AI` - EfficientNav: 面向设备端路径导航的记忆缓存与检索 [PDF](https://arxiv.org/pdf/2510.18546), [HTML](https://arxiv.org/abs/2510.18546)
### Authors
Zebin Yang,Sunjian Zheng,Tong Xie,Tianshi Xu,Bo Yu,Fan Wang,Jie Tang,Shaoshan Liu,Meng Li
### Background
对象-目标导航（ObjNav）任务要求智能体在未见过的环境中导航至特定物体的位置。具备大型语言模型（LLMs）和在线构建的导航地图的实体智能体可以在零样本情况下执行此任务。然而，现有方法严重依赖于云端的大型语言模型，如GPT-4，而直接使用较小的模型，如LLaMA3.2-11b，则因为模型容量有限，理解复杂导航地图的能力较弱，从而导致成功率显著下降，难以在设备端部署。同时，导航地图描述带来的长提示语将导致设备端规划延迟增加。
### Innovation
EfficientNav 引入了语义感知的记忆检索来精简导航地图中的冗余信息，提高了较小模型理解环境的能力。此外，EfficientNav 还提出了离散记忆缓存和基于注意力的记忆聚类，以高效地保存和重用KV缓存，从而减少规划延迟。
### Conclusion
实验结果表明，与基于GPT-4的基线相比，EfficientNav 在HM3D基准上的成功率提高了11.1%，实时延迟降低了6.7倍，端到端延迟降低了4.7倍。我们的代码将很快发布。
## 173. `cs.AI` - 基于动机的民间故事类型自动化的大规模语言模型：灰姑娘案例研究 [PDF](https://arxiv.org/pdf/2510.18561), [HTML](https://arxiv.org/abs/2510.18561)
### Authors
Tjaša Arčon,Marko Robnik-Šikonja,Polona Tratnik
### Background
人工智能方法正在被应用于许多研究领域，包括数字人文。本文构建了一种针对民俗学的大规模分析方法。利用机器学习和自然语言处理技术，自动提取了大量的灰姑娘变体中的动机，并通过聚类和降维分析了它们的相似性和差异.
### Innovation
本文创新之处在于使用大规模语言模型检测民间故事中复杂的动机交互情况，并通过技术手段对大规模文本集进行计算分析，实现了跨语言比较.
### Conclusion
实证结果表明，大规模语言模型能够捕捉民间故事中的复杂相互作用，使得对大量文本进行计算分析成为可能，同时也促进了跨语言比较的研究.
## 174. `cs.AI` - WebDevJudge：评估（M）LLM在网页开发质量评审中的表现 [PDF](https://arxiv.org/pdf/2510.18560), [HTML](https://arxiv.org/abs/2510.18560)
### Authors
Chunyang Li,Yilun Zheng,Xinting Huang,Tianqing Fang,Jiahao Xu,Yangqiu Song,Lihui Chen,Han Hu
### Background
LLM-as-a-judge 模型作为一种可扩展且高效的替代人类评价的方法正在兴起，并在明确定义的任务上表现出强大的性能。然而，它在开放任务中的可靠性，特别是在具有动态环境和复杂交互的场景中，尚未得到验证。
### Innovation
引入了WebDevJudge，这是一种系统性基准，用于评估LLM-as-a-judge在网页开发中的性能，支持基于静态观察的非交互式评估和动态网络环境下的持续交互式评估。WebDevJudge包含了成对网页实现的人类偏好标签，并标注了结构化和查询导向的评分标准，以确保高质量的真实数据。通过使用这一基准，全面评估了包括LLM、MLLM和代理工作流在内的各种评估者，系统性地研究了不同范式和指导机制的影响。实验揭示了LLM评断者与人类专家之间的显著差距，深入分析表明这一差距源于模型的根本局限。
### Conclusion
WebDevJudge 为LLM-as-a-judge模型设定了一个重大挑战，提供了对构建更可靠和适合复杂场景的自动化评估器的未来研究的指导见解。
## 175. `cs.AI` - AI在心理健康领域的跨学科价值权衡 [PDF](https://arxiv.org/pdf/2510.18581), [HTML](https://arxiv.org/abs/2510.18581)
### Authors
Katerina Drakos,Eva Paraschou,Simay Toplu,Line Harder Clemmensen,Christoph Lütge,Nicole Nadine Lønfeldt,Sneha Das
### Background
人工智能被引入以改善心理健康支持的可及性。然而，大多数AI心理健康聊天机器人依赖于有限的专业领域输入，未能在其整个生命周期中整合专业知识。本文探讨了跨学科合作在AI心理健康聊天机器人中的成本效益权衡。
### Innovation
本文提出，需在AI心理健康聊天机器人的关键生命周期阶段整合来自技术、医疗保健、伦理和法律领域的专家，以确保价值一致性和遵守AI法案中高风险要求。并且强调了跨学科整合在心理健康聊天机器人中的具体建议和现有框架。
### Conclusion
确保跨学科合作对于AI心理健康聊天机器人的价值对齐和合规性至关重要，并提供实用建议以平衡跨学科整合的挑战与益处。
## 176. `cs.AI` - RAISE: 统一负责任的人工智能评分和评估框架 [PDF](https://arxiv.org/pdf/2510.18559), [HTML](https://arxiv.org/abs/2510.18559)
### Authors
Loc Phuc Truong Nguyen,Hung Thanh Do
### Background
随着AI系统进入高风险领域，评估必须超越预测准确性，还包括解释性、公平性、鲁棒性和可持续性。本研究通过一个四维统一框架——RAISE (Responsible AI Scoring and Evaluation) 量化模型在这四个维度上的表现，并综合成单一的责任得分。研究选用了金融、医疗和社科三个领域的结构化数据集，并分别采用多层感知机、表型ResNet和特征标记转器三种深度学习模型进行实验。
### Innovation
引入了一个新颖的综合框架RAISE，它不仅量化了模型在四个关键维度上的表现，还能将这些维度综合成一个统一的责任得分；研究对模型进行了多维度评估，揭示了模型在不同维度上的权衡，强调了负责任模型选择的多维评价必要性。论文还指出没有一种模型可以在所有责任标准上表现优异，因此多维度的评估是必要的。
### Conclusion
研究表明，模型在负责任的标准上存在权衡，没有一个模型能在所有维度上表现最优，强调了多维度评估的必要性。RAISE框架提供了一个综合的评价方法，帮助研究人员和开发者在选择和评估模型时考虑更多因素。该实现方法可以在指定的URL中找到。
## 177. `cs.AI` - Kaleido: 开源多主体参考视频生成模型 [PDF](https://arxiv.org/pdf/2510.18573), [HTML](https://arxiv.org/abs/2510.18573)
### Authors
Zhenxing Zhang,Jiayan Teng,Zhuoyi Yang,Tiankun Cao,Cheng Wang,Xiaotao Gu,Jie Tang,Dan Guo,Meng Wang
### Background
尽管最近在主题到视频（S2V）生成模型方面取得了一些进展，现有的方法仍然在多主体一致性维护和背景分离处理方面存在不足，这导致在多参考图条件下的较低参考保真度和语义漂移。这些不足可以归因于多种因素。首先，训练数据集缺乏多样性、高质量样本以及跨配对数据。其次，目前将多个参考图像整合的机制欠佳，容易导致多个主体之间的混淆。
### Innovation
本研究提出了一个名为Kaleido的专门用于条件生成一致化视频的框架，旨在生成与目标主题多个参考图像一致的视频。Kaleido引入了一种专门的数据构建管道，结合低质量样本过滤和多样的数据综合，以生产一致性保存的训练数据，确保模型的足够灵活。此外，Kaleido还引入了参考旋转位置编码（R-RoPE），从而稳定且精准地处理参考图像，增强模型在多图像条件下的性能。
### Conclusion
Kaleido在多个基准测试中的实验结果证明了其在一致性、保真度和泛化能力方面的显著优势，为S2V生成技术的发展做出了贡献。
## 178. `cs.AI` - 基于校正的方法将提升树蒸馏为决策树 [PDF](https://arxiv.org/pdf/2510.18615), [HTML](https://arxiv.org/abs/2510.18615)
### Authors
Gilles Audemard,Sylvie Coste-Marquis,Pierre Marquis,Mehdi Sabiri,Nicolas Szczepanski
### Background
本文提出了一种新的方法，用于将提升树蒸馏为决策树，旨在生成在预测性能和可解释性之间提供可接受权衡的ML模型。研究者解释了如何使用称为校正的方法来实现这一蒸馏过程。实验结果表明，该方法在与通过重新训练模型实现的蒸馏方法的比较中提供了有趣的结果。
### Innovation
本文提出了一种基于校正的方法来将提升树蒸馏为决策树，这种方法可以实现一个在预测性能和可解释性之间提供可接受权衡的ML模型。通过使用校正方法实施这一蒸馏过程，并且实验结果表明这种方法的有效性高于重新训练模型的方法。
### Conclusion
本文提出的基于校正的方法在将提升树蒸馏为决策树的过程中表现出了良好的效果，它提供了一个在预测性能和可解释性之间权衡的ML模型，并且与通过重新训练模型的蒸馏方法相比，提供了更有利的结果。
## 179. `cs.AI` - 基于几何想象力的有限视角空间推理 [PDF](https://arxiv.org/pdf/2510.18632), [HTML](https://arxiv.org/abs/2510.18632)
### Authors
Zhangquan Chen,Manyuan Zhang,Xinlei Yu,Xufang Luo,Mingze Sun,Zihao Pan,Yan Feng,Peng Pei,Xunliang Cai,Ruqi Huang
### Background
尽管视觉语言模型（VLMs）在多种多模态任务中取得了显著的进步，但在从有限视角理解3D空间关系方面仍存在重大挑战。现有的推理解析方法主要依赖纯文本（例如，拓扑认知图）或2D视觉提示，但由于其有限的表示能力，它们在需要3D空间想象力的特定任务中的表现受限。
### Innovation
我们提出了3DThinker框架，它能够在推理过程中充分利用图像中隐含的丰富几何信息，类似于人类的思考方式。这是首个在无需任何3D前置输入的情况下进行3D思维推理的框架，且无需使用明确标注的3D数据进行训练。为了训练该框架，我们采用了两阶段的策略：首先，在监督学习下，将VLM在推理过程中生成的3D潜在表示与3D基础模型（如VGGT）的3D潜在表示对齐；接着，仅基于结果信号优化整条推理轨迹，从而进一步细化内部的3D思维。
### Conclusion
广泛的实验表明，3DThinker在多个基准测试中都优于强大的基线模型，为其提供了将3D表示统一到多模态推理中的全新视角。我们的代码将在此处提供：this https URL。
## 180. `cs.AI` - ε-Seg: 稀疏监督下的显微镜数据语义分割 [PDF](https://arxiv.org/pdf/2510.18637), [HTML](https://arxiv.org/abs/2510.18637)
### Authors
Sheida Rahnamai Kordasiabi,Damian Dalle Nogare,Florian Jug
### Background
电子显微镜（EM）图像的生物样本语义分割在生命科学中仍然是一个挑战。EM数据能够捕捉生物结构的细节，有时这些细节非常复杂，即使是人类观察者也感到负担沉重。尤其是在训练标注数据稀疏或成本高昂的情况下，稀疏监督仍然是一个重大挑战。
### Innovation
介绍了ε-Seg方法，基于分层变分自编码器（HVAEs），结合了中心-区域遮罩、稀疏标签对比学习（CL）、高斯混合模型（GMM）先验和无聚类标签预测。这种方法通过中心-区域遮罩和修复损失鼓励模型学习鲁棒且具有代表性的嵌入，即使在稀疏训练标记（总图像数据的0.05%或更少）的情况下也可以区分所需类别。通过使用CL和GMM先验，使HVAE的潜在空间的编码输入补丁倾向于按我们希望区分的语义类别聚集。最后，提出了一种MLP语义分割头，直接从潜在嵌入中预测类别标签，而不是使用聚类潜在嵌入进行语义分割。
### Conclusion
ε-Seg在两种密集的EM数据集和显微镜数据上展示了实证结果，证明了即使只有少量的训练标签可用时，该方法也能够实现具有竞争力的稀疏监督语义分割结果。
## 181. `cs.AI` - 探索临床大语言模型的成员推断漏洞 [PDF](https://arxiv.org/pdf/2510.18674), [HTML](https://arxiv.org/abs/2510.18674)
### Authors
Alexander Nemecek,Zebin Yun,Zahra Rahmani,Yaniv Harel,Vipin Chaudhary,Mahmood Sharif,Erman Ayday
### Background
随着大型语言模型（LLMs）在临床决策支持、文档记录和病人信息系统中的逐渐融入，确保它们的隐私性和可信性已成为医疗保健部门的一个迫切挑战。通过细调LLMs处理敏感的电子健康记录（EHR）数据可以提高其领域适应性，但同时也增加了通过模型行为暴露患者信息的风险。这项研究深入探讨了临床LLMs中的成员推断漏洞，研究者从开始就进行了初步研究，以确定特定病人记录是否被用于模型训练。
### Innovation
本研究采用了最先进的临床问答模型Llemr，评估了基于损失的攻击方法和一种基于领域动机的改写策略，这种策略在临床对抗条件上更现实。研究发现了有限但可测量的成员泄露现象，表明当前的临床LLMs提供了一定程度的抗攻击性，但仍存在潜在的隐私风险，这可能会削弱人们对临床AI应用的信任。
### Conclusion
初步结果揭示了部分但可测量的成员泄露，表明当前临床LLMs提供部分抗攻击性但仍然容易受到微妙的隐私风险。这些结果促使继续发展基于语境的、专业领域的隐私评估和防御，如差分隐私微调和改写敏感训练，以加强医疗保健AI系统的安全性和可信性。
## 182. `cs.AI` - Fetch.ai: 现代多智能体系统架构 [PDF](https://arxiv.org/pdf/2510.18699), [HTML](https://arxiv.org/abs/2510.18699)
### Authors
Michael J. Wooldridge,Attila Bagoly,Jonathan J. Ward,Emanuele La Malfa,Gabriel Paludo Licks
### Background
近年来，由大型语言模型（LLM）驱动的智能系统的发展很大程度上忽视了数十年来关于基础多智能体系统（MAS）的研究，导致出现了一些存在关键局限性的框架，如集中化和不充分的信任与通信协议。因此，该论文介绍了一种旨在弥合这一差距的架构（填空处应为具体名称），该架构设计目的是将经典MAS原则与现代AI能力相结合。该架构基于区块链服务的去中心化基础，融合了可验证身份、发现和交易的多层解决方案。
### Innovation
本文提出了一个新颖的多层解决方案，建立在去中心化的区块链服务基础之上，用于验证身份、发现和交易。该架构还提供了一个全面的开发框架，用于创建安全和互操作的代理，并提供了一个基于云的部署平台，以及一个智能编排层，在这个层中，代理原生的大规模语言模型将高层次的人类目标转换为复杂的多智能体工作流。
### Conclusion
最终，该架构为从当前智能体实现向开放、协作和经济可持续的多智能体生态系统过渡提供了一个原则性的架构。通过一个去中心化物流用例，展示了此系统已部署的性质，其中智能体能够安全地动态发现、谈判和交易。
## 183. `cs.AI` - 因果扰动公平性测试 [PDF](https://arxiv.org/pdf/2510.18719), [HTML](https://arxiv.org/abs/2510.18719)
### Authors
Chengwen Du,Tao Chen
### Background
为了减轻敏感特征（如性别、年龄或种族）上的不公平和不道德的歧视，公平性测试在利用AI模型处理表格数据的系统工程中发挥着重要作用。但在难以处理的样本量下，如何有效揭示公平性错误仍然是一个挑战。当前许多研究集中在设计测试样本生成器上，而忽略了对于数据特性的重要知识，这限制了其潜在价值。
### Innovation
本文提出了一种因果扰动公平性测试的通用框架，称为CausalFT。通过因果推理，CausalFT的核心思想是从非敏感特征中提取与敏感特征最直接和因果相关的特征，进而影响标签预测，这种因果关系被无缝地注入到扰动中，指导测试样本生成器。CausalFT是一个高层次框架，可以与多种基础生成器配对。实验表明，CausalFT可以显著改进任意基础生成器在93%以上的案例中揭示公平性错误的能力，同时接受微小的额外运行时间开销。与仅根据相关性排名非敏感特征的先进方法相比，CausalFT在64%的案例中表现更好且更高效。此外，CausalFT更能提高公平性的鲁棒性。
### Conclusion
CausalFT的实验结果证实，即使在相对大的样本量且复杂的数据环境中，它也能有效地揭示并改进现有生成器的表现，从而提高公平性的鲁棒性。
## 184. `cs.AI` - HarmNet：一种针对大型语言模型的适应性多轮破坏性攻击框架 [PDF](https://arxiv.org/pdf/2510.18728), [HTML](https://arxiv.org/abs/2510.18728)
### Authors
Sidhant Narula,Javad Rafiei Asl,Mohammad Ghasemigol,Eduardo Blanco,Daniel Takabi
### Background
大型语言模型（LLMs）仍然容易受到多轮破坏性攻击（jailbreak attacks）的攻击。现有的防御措施和攻击方法并未完全解决这一问题。
### Innovation
该论文提出了一个模块化的框架——HarmNet，其中包括思考网络（ThoughtNet），用于分层语义网络；反馈驱动的模拟器，用于迭代查询改进；以及网络遍历器，用于实时自适应攻击执行。HarmNet 系统性地探索和细化恶意行为空间，以发现隐身且成功率高的攻击路径，并在针对闭源和开源大型语言模型的实验中优于最先进的方法。
### Conclusion
实验结果表明，HarmNet 在大型语言模型上的攻击成功率显著提高，例如，在 Mistral-7B 上，HarmNet 的攻击成功率达到了 99.4%，相比最佳基线提高了 13.9%。HarmNet 提供了一种新的方法来处理大型语言模型的多轮破坏性攻击问题。
## 185. `cs.AI` - 偏好强化学习超越成对比较：多个选项的好处 [PDF](https://arxiv.org/pdf/2510.18713), [HTML](https://arxiv.org/abs/2510.18713)
### Authors
Joongkyu Lee,Seouh-won Yi,Min-hwan Oh
### Background
近年来，偏好基于强化学习（PbRL）因其在大规模语言模型（LLMs）对齐等方面的实际成功而受到理论研究的广泛关注。尽管已有大量理论工作聚焦于成对比较这一主题，但大多数研究仅以此为基础，而最新的研究开始尝试使用多选项比较和排名反馈，尽管实际的性能保证并未提升甚至有所下降，因为空间更丰富的信息没有得到充分利用。
### Innovation
本文采用Plackett-Luce（PL）模型处理行动子集上的排名反馈，提出了M-AUPO算法，通过最大化提供的子集内的平均不确定性来选择多个行动。证明了M-AUPO的次优性间隙为$tilde{boldsymbol{O}}big(frac{d}{T} times big(frac{1}{|S_t|}big)^{frac{1}{2}}big)$，其中$T$表示总轮数，$d$是特征维度，而$|S_t|$是第$t$轮提供的子集大小。此外，建立了接近匹配的下界为$boldsymbol{theta}big(frac{d}{K times boldsymbol{sqrt}(T)}big)$，其中$K$是最大子集大小。研究成果表明，更大的子集直接带来了提升并明确展示了次优性间隙随着子集大小的增大而减小，这解决了大部分先前工作中的根本性限制。
### Conclusion
本研究表明了子集大小增加可以实现更好的性能提升，并且理论结果明确地展示了样本效率随子集大小增加而提升。
## 186. `cs.AI` - C-SWAP: 结构化剪枝中的可解释性aware 方法以实现高效神经网络压缩 [PDF](https://arxiv.org/pdf/2510.18636), [HTML](https://arxiv.org/abs/2510.18636)
### Authors
Baptiste Bauvin,Loïc Baret,Ola Ahmad
### Background
近年来，神经网络压缩在计算机视觉应用中得到了越来越多的关注，尤其是需要在部署中减少模型规模时。剪枝是一种通过权重、神经元和层的稀疏化来减少模型大小和推理成本的技术。结构化剪枝尤为重要，因为它可以一次性移除整个结构，进一步加速推理时间和减少内存开销。然而，这种方法通常计算上代价昂贵，需要迭代的重新训练和优化。因此，最近的研究考虑了一次性剪枝设置，即将剪枝直接应用于训练后，但这种方法往往导致性能显着下降。
### Innovation
本文提出了一种新的可解释性驱动的一次性剪枝框架——C-SWAP，通过利用模型预测和结构之间的因果关系，在逐步剪枝过程中的解释性方式来引导剪枝操作。该方法能够有效减少网络规模，确保移除的结构不会损害模型性能。实验表明，本方法可以在保持较低性能影响的前提下，实现显著的模型尺寸减少，无需微调，并且在性能和压缩度之间提供了最佳平衡。
### Conclusion
本文所提出的方法在模型尺寸压缩和保持高性能方面优于其同类方法，实现了良好的性能与压缩度之间的平衡。代码已在GitHub上开源。
## 187. `cs.AI` - 在线SFT在LLM推理中的应用：无需奖励的自我调优的惊人效果 [PDF](https://arxiv.org/pdf/2510.18814), [HTML](https://arxiv.org/abs/2510.18814)
### Authors
Mengqi Li,Lei Zhao,Anthony Man-Cho So,Ruoyu Sun,Xiao Li
### Background
本文提出了一种简单的在线自我帮助监督微调（OSFT）范式，用于语言模型（LLM）的推理。通过生成自己的回应并立即在自我生成的数据上进行微调，OSFT 在无需奖励的情况下提供了一种高效的训练策略，仅使用一次模拟运行。实验结果显示，OSFT 在具有挑战性的数学推理任务上的下游性能与使用验证奖励的强化学习（如GRPO）方法相当。
### Innovation
本文的创新之处在于提出了一种无需奖励的在线自我帮助监督微调（OSFT）范式，该范式仅使用一次模拟运行即可高效提高语言模型的推理能力。通过消除对奖励信息的依赖，OSFT 提供了一种简单而有效的训练策略，展示了在数学推理任务上与复杂奖励基训练范式相当的效果。
### Conclusion
本文的研究表明，OSFT 能够有效地提高模型的推理能力，并确保在更复杂的任务中表现出良好的泛化性能。模型通过自身的现有偏好（潜在知识）得到改进，无需额外的奖励信息。OSFT 提出了一种高效且有前景的替代方案，适用于更复杂的奖励基训练范式。
## 188. `cs.AI` - 揭示推理语言模型推理服务：一项实证研究 [PDF](https://arxiv.org/pdf/2510.18672), [HTML](https://arxiv.org/abs/2510.18672)
### Authors
Qi Li,Junpan Wu,Xiang Liu,Yuxin Wang,Zeyu Li,Zhenheng Tang,Yuhan Chen,Shaohuai Shi,Xiaowen Chu
### Background
推理大型语言模型（RLLM）在解决如数学、编程等复杂推理任务方面已展示出与通用大语言模型相当的能力。然而，RLLM的服务性能和行为尚未得到深入研究，这可能影响其在实际场景中的部署和利用。本文研究了RLLM的服务性能和行为，发现了其与传统语言模型之间的几个显著差异，包括显著的内存使用和波动、延迟请求、适应性运行时间和领域偏好。
### Innovation
本文通过实证研究揭示了RLLM的服务行为和性能。提出了几种优化技术，包括模型量化方法和推测解码能提升服务系统的效率，同时对RLLM的性能影响较小。此外，研究发现前缀缓存和键值缓存量化可能降低小型RLLM的性能或服务质量。最后，研究在符合现实工作负载的伽玛分布下进行了评估，一致验证了上述发现。
### Conclusion
本文的研究结果为研究界和工业界提供了关于RLLM推理服务的见解，有助于推进RLLM推理服务的发展。
## 189. `cs.AI` - 二阶二次量化：超越一阶量化的大值矩阵压缩 [PDF](https://arxiv.org/pdf/2510.18650), [HTML](https://arxiv.org/abs/2510.18650)
### Authors
Kyo Kuroki,Yasuyuki Okoshi,Thiem Van Chu,Kazushi Kawamura,Masato Motomura
### Background
本文提出了一个新颖的矩阵量化方法——二阶二次量化（BQQ）。相比传统的基于一阶的量化方法，如均匀量化和二进制编码量化，这些方法通过二进制基线性组合来近似实值矩阵，BQQ 则利用二阶二次表达式的表征能力，同时保持极简的数据格式。本文通过两个实验验证了该方法的有效性：矩阵压缩基准测试和预训练视网膜变换器模型的后训练量化（PTQ）。实验结果显示，BQQ 在压缩多种矩阵数据时，能够在内存效率和重构误差间实现更优的平衡。它还能在后训练量化方面取得优越的表现，即使在没有针对受限内存条件下取得最优后训练量化精度且不依赖于后训练量化的二进制矩阵优化的情况下。例如，在ImageNet数据集上，我们的方法在基于校准和无数据校准的场景中，分别比最先进的后训练量化方法高出2.2%和59.1%，且量化等价于2比特。这些发现突显了二阶二次表达式在高效矩阵近似和神经网络压缩中的惊人效果和有效性。
### Innovation
本文提出了 BQQ，一种通过二阶二次表达式进行矩阵压缩的新方法，相比传统的一阶量化方法，BQQ 不仅能保持极简的数据格式，还能表示出更强的表征能力。本文通过矩阵压缩基准测试和预训练视网膜变换器模型的后训练量化验证了 BQQ 的有效性，实验结果显示 BQQ 在各种情况下都能在内存效率和重构误差之间取得更好的平衡，并能在后训练量化方面取得优越的表现，甚至在没有特定的内存受限优化和依赖于后训练量化方法优化的前提下。此外，BQQ 在 ImageNet 数据集上达到了最优性能，即使量化等价于2比特，也能显著优于其他方法。
### Conclusion
该论文提出的 BQQ 方法在实现矩阵压缩时，在内存效率和重构误差之间提供了更好的性能平衡，并在后训练量化表现较好。尽管 BQQ 未在特定的内存限制条件下追求最优精度和没有依赖于后处理的二进制矩阵优化，但在各种实验设置中，特别是在校准和无数据校准的情境下，相较于最先进的方法，BQQ 显示出了优越的性能。这些发现表明二阶二次表达式在大值矩阵压缩和神经网络压缩中的重要作用和潜在价值。
## 190. `cs.AI` - 可解释的混合AI框架增强结核病和症状检测 [PDF](https://arxiv.org/pdf/2510.18819), [HTML](https://arxiv.org/abs/2510.18819)
### Authors
Neel Patel,Alexander Wong,Ashkan Ebadi
### Background
结核病仍然是一个全球性的公共卫生问题，特别是在资源匮乏和偏远地区尤为严重。早期检测对于治疗至关重要，但由于缺乏技能熟练的放射科医生，迫切需要人工智能（AI）驱动的筛查工具。建立可靠的AI模型面临挑战，因为需要大量高质量的数据集，而获得这些数据集的成本很高。为解决这一问题，本文提出了一种教师-学生框架，通过整合两个监督头部和一个半监督头部，增强了胸部X射线中的疾病和症状检测。
### Innovation
提出了一种教师-学生框架，通过整合两个监督头部和一个半监督头部，显著增强了胸部X射线的疾病和症状检测。该模型在区分COVID-19、结核病和正常病例方面的准确率达到了98.85%，多标签症状检测的宏F1分数为90.09%，明显优于基线模型。此外，模型的可解释性评估显示，其预测基于相关解剖特征，表明它有潜力在临床筛查和分诊环境中部署。
### Conclusion
该模型在多标签症状检测和区分疾病方面取得了优异的性能，证明了其在临床环境中的应用潜力和可解释性。
## 191. `cs.AI` - 计算竞争博弈的计算基础：正式化相互依赖性和互补性 [PDF](https://arxiv.org/pdf/2510.18802), [HTML](https://arxiv.org/abs/2510.18802)
### Authors
Vik Pant,Eric Yu
### Background
现代社会技术系统呈现出一种战略性竞争合作（coopetition），其中参与者的行动既推动价值创造又开展价值获取。尽管概念建模语言如i*为战略依赖关系提供了丰富的定性表示，但缺乏进行动态权衡的定量分析机制。相比之下，经典博弈论提供了数学严谨性，但剥离了上下文的丰富性。这个技术报告通过为计算理论奠定基础来弥合这一差距，特别是通过定义战略 coopetition 中的两个关键维度：相互依赖性和互补性。在此基础上，我们将相互依赖性扎根于i*结构依赖性分析中，通过结构化翻译框架将其转换为定量的相互依赖系数。我们将互补性正式化为Brandenburger和Nalebuff的附加值概念，使用验证参数化模型协同价值创造。我们整合了结构依赖性与价值获取中的谈判权，并引入了一个博弈论框架，在此框架中纳什均衡包含了结构相互依赖。
### Innovation
该技术报告提出了计算竞合的计算基础，通过定义战略 coopetition 中的两个关键维度相互依赖性和互补性来填补概念建模语言与经典博弈论之间的差距。主要创新包括：1) 将i*中的结构依赖性分析转化为定量的相互依赖系数；2) 使用Brandenburger和Nalebuff的添加价值概念来正式化互补性，模型协同价值创造；3) 融合结构依赖性与价值获取中的谈判权，通过引入博弈论方程使纳什均衡包含结构相互依赖；4) 集成计算框架，并通过广泛的实验测试和实证应用进行了验证，展示了功能形式的稳健性，并通过对三星-索尼S-LCD合资企业（2004-2011）的实证应用展示了其有效性。
### Conclusion
该技术报告为在需求工程和多智能体系统中研究战略竞合提供了一个计算机理基础，并标志着一个协调的研究计划的第一步，研究工作还探讨了信任动态、团队生产以及互惠机制。
## 192. `cs.AI` - Actor-Free Continuous Control via Structurally Maximizable Q-Functions [PDF](https://arxiv.org/pdf/2510.18828), [HTML](https://arxiv.org/abs/2510.18828)
### Authors
Yigit Korkmaz,Urvi Bhuwania,Ayush Jain,Erdem Bıyık
### Background
虽然基于价值的学习算法是离策强化学习的基石，因其简洁性与训练稳定性，但在连续动作空间中，它们通常局限于评估个体状态动作对的价值函数，这在全动作空间上是计算上不可行的。此时，通常采用带有批评家(agent)的方法，即批评家负责估计Q-值，而行动家(actor)则基于批评家的输出进行最大化。尽管这种方法很受欢迎，但在训练过程中常常不稳定。
### Innovation
本文提出了一种纯粹基于价值的框架，用于连续控制，该框架重新考察了结构最大化的Q-函数。通过引入一套关键的架构和算法选择，实现了高效且稳定的训练学习。特别地，在动作空间受限的环境中，相较于基于梯度的最大化方法的传统演员-批评家方法，该方法表现出更优的效果。
### Conclusion
所提出的方法在多种标准模拟任务上得到了评估，展示了与最先进的基准算法相当的性能和样本效率，而且没有学习专门的演员的额外成本。特别是在动作空间受限的环境中，我们的方法通过结构最大化的价值函数优于传统的基于梯度的最大化方法。我们已经在GitHub上发布了源代码。
## 193. `cs.AI` - 通过批判-后编辑强化学习实现忠实可控的个性化 [PDF](https://arxiv.org/pdf/2510.18849), [HTML](https://arxiv.org/abs/2510.18849)
### Authors
Chenghao Zhu,Meiling Tao,Tiannan Wang,Dongyi Ding,Yuchen Eleanor Jiang,Wangchunshu Zhou
### Background
生成语言模型（LLMs）的个性化对满足个体用户偏好至关重要，但这一任务极具挑战性。尽管监督微调（SFT）能够迅速达到性能瓶颈，标准基于人类反馈的强化学习（RLHF）同样难以处理个性化的细微差异。基于标量奖励模型会导致奖励作弊，生成过于冗长且表面化的个性化响应。
### Innovation
本文提出了一种名为批判-后编辑的强化学习框架，旨在实现更忠实和可控制的个性化。该框架包含两个关键组件：（1）个性化生成奖励模型（GRM），能够提供多维度评分和文本批评以抵御奖励作弊；（2）批判-后编辑机制，该机制让策略模型根据这些批评修订自己的输出，从而实现更精确、高效的训练。
### Conclusion
在严格的长度控制评估下，我们的方法在个性化基准测试中明显优于标准PPO方法。个人化的Qwen2.5-7B模型的平均赢率提高了11%，个人化的Qwen2.5-14B模型的表现超过了GPT-4.1。这些结果证明了一条实现忠实、高效和可控个性化的新路径。
## 194. `cs.AI` - DP$^2$O-SR: 直接感知偏好优化用于实际图像超分辨率 [PDF](https://arxiv.org/pdf/2510.18851), [HTML](https://arxiv.org/abs/2510.18851)
### Authors
Rongyuan Wu,Lingchen Sun,Zhengqiang Zhang,Shihao Wang,Tianhe Wu,Qiaosi Yi,Shuai Li,Lei Zhang
### Background
基于预训练的文本到图像（T2I）扩散模型，实际图像超分辨率（Real-ISR）方法能够生成丰富和真实的细节。然而，由于T2I模型的固有随机性，不同的噪声输入会导致输出具有不同的感官质量。尽管这种随机性有时被视为一个限制，但也会引入更广泛的感官质量范围，这有助于改善Real-ISR性能。
### Innovation
提出了直接感知偏好优化用于实际图像超分辨率（DP$^2$O-SR）框架，该框架通过结合全参考和无参考图像质量评估模型，构建混合奖励信号来调整生成模型与感知偏好对齐，而无需昂贵的人类注释。此外，提出了多层次的偏好优化，自适应地根据组内奖励差距和组间多样性加权训练对，更加高效和稳定。实验证明，DP$^2$O-SR在提高感知质量和在实际基准上的泛化能力方面表现显著。
### Conclusion
通过大量实验跨扩散和流基T2I骨干，证明了DP$^2$O-SR在提高感知质量和良好泛化到实际情况方面表现出色。
## 195. `cs.AI` - 连续时间车辆控制中基于李雅普诺夫的量子启发式强化学习的适用性研究 [PDF](https://arxiv.org/pdf/2510.18852), [HTML](https://arxiv.org/abs/2510.18852)
### Authors
Nutkritta Kraipatthanapong,Natthaphat Thathong,Pannita Suksawas,Thanunnut Klunklin,Kritin Vongthonglua,Krit Attahakul,Aueaphum Aueawatthanaphisut
### Background
本文提出了一个结合量子策略优化和李雅普诺夫稳定性分析的新型李雅普诺夫量子强化学习（LQRL）框架，用于连续时间的车辆控制。背景在于随着自主系统的发展，如何在动态环境中实现安全的决策制定成为重要的研究问题，特别是在车辆控制领域，需要确保策略在网络过程中能够满足稳定性要求。
### Innovation
创新点在于提出了一个结合变分量子电路的量子策略网络（VQC）以及一种稳定性感知的策略梯度机制的新框架，能够在策略学习过程中嵌入李雅普诺夫稳定性验证，确保渐近收敛并且在动态环境中实现安全决策。该框架通过在闭环自适应巡航控制情景下进行模拟实验验证了其有效性。
### Conclusion
研究结果表明LQRL框架成功实现了在量子策略学习过程中嵌入李雅普诺夫稳定性验证，从而在不安全行为（如过度加速时的瞬态超调和李雅普诺夫发散）发生的前提下仍然能保持状态的有界演化，验证了在量子强化学习架构中集成安全保证的可行性。提出了这一框架作为在自主系统中实现可证明安全性量子控制和混合量子-经典优化领域的一个初步基础步骤。
## 196. `cs.AI` - 每一步演变：为万亿参数思考模型扩展强化学习 [PDF](https://arxiv.org/pdf/2510.18855), [HTML](https://arxiv.org/abs/2510.18855)
### Authors
Ling Team,Anqi Shen,Baihui Li,Bin Hu,Bin Jing,Cai Chen,Chao Huang,Chao Zhang,Chaokun Yang,Cheng Lin,Chengyao Wen,Congqi Li,Deng Zhao,Dingbo Yuan,Donghai You,Fagui Mao,Fanzhuang Meng,Feng Xu,Guojie Li,Guowei Wang,Hao Dai,Haonan Zheng,Hong Liu,Jia Guo,Jiaming Liu,Jian Liu,Jianhao Fu,Jiannan Shi,Jianwen Wang,Jianxin Lai,Jin Yang,Jun Mei,Jun Zhou,Junbo Zhao,Junping Zhao,Kuan Xu,Le Su,Lei Chen,Li Tang,Liang Jiang,Liangcheng Fu,Lianhao Xu,Linfeng Shi,Lisha Liao,Longfei Zheng,Meng Li,Mingchun Chen,Qi Zuo,Qiang Cheng,Qianggang Cao,Qitao Shi,Quanrui Guo,Senlin Zhu,Shaofei Wang,Shaomian Zheng,Shuaicheng Li,Shuwei Gu,Siba Chen,Tao Wu,Tao Zhang,Tianyu Zhang,Tianyu Zhou,Tiwei Bie,Tongkai Yang,Wang Hong,Wang Ren,Weihua Chen,Wenbo Yu,Wengang Zheng,Xiangchun Wang,Xiaodong Yan,Xiaopei Wan,Xin Zhao,Xinyu Kong,Xinyu Tang,Xudong Han,Xudong Wang,Xuemin Yang,Xueyu Hu,Yalin Zhang,Yan Sun,Yicheng Shan,Yilong Wang,Yingying Xu,Yongkang Liu,Yongzhen Guo,Yuanyuan Wang,Yuchen Yan,Yuefan Wang,Yuhong Guo,Zehuan Li,Zhankai Xu,Zhe Li,Zhenduo Zhang,Zhengke Gui,Zhenxuan Pan,Zhenyu Huang,Zhenzhong Lan,Zhiqiang Ding,Zhiqiang Zhang
### Background
当前存在一种具有万亿尺度参数的首个开源、最先进思考模型Ring-1T。训练如此庞大的模型引入了前所未有的挑战，包括训练推断不匹配、长序列处理的低效率以及RL系统中的瓶颈问题。
### Innovation
Ring-1T 引领三项创新：1. IcePop 通过令牌级别差异遮蔽和裁剪稳定RL训练，解决了训练推断不匹配引发的不稳定性问题；2. C3PO++ 通过动态分区提高资源利用效率，使得在令牌预算下获得高时间效率的长序列处理；3. ASystem 是一种高性能的RL框架，旨在克服阻碍万亿参数模型训练的系统瓶颈。
### Conclusion
Ring-1T 在关键基准测试上取得了突破性结果，同时也展示了其出色的推理能力，例如在AIME-2025、HMMT-2025、CodeForces和ARC-AGI-v1等测试中的表现，以及在IMO-2025上获得了银牌成绩。通过释放完整的1T参数MoE模型，研究界现在可以直接接触最先进的推理能力。这不仅标志着大规模推理智能民主化的重大里程碑，也确立了开源模型性能的新基准。
## 197. `cs.AI` - LLMs如何使用其深度？ [PDF](https://arxiv.org/pdf/2510.18871), [HTML](https://arxiv.org/abs/2510.18871)
### Authors
Akshat Gupta,Jay Yeung,Gopala Anumanchipalli,Anna Ivanova
### Background
研究表明大型语言模型并不均匀地使用其深度，但缺乏对层次预测动态的细粒度理解。本文追踪了几个开源模型在推理过程中的中间表示，揭示了其深度使用的结构化和细微特征。
### Innovation
提出了一种'猜测-然后细化'框架，解释了LLMs如何内部构建计算结构进行预测。通过三个案例研究进一步考察了不同层深度的动态使用：部分性描述分析表明，功能词通常是最先被正确预测的；事实回忆任务分析表明，多词答案中第一个词需要更多的计算深度；多选题任务分析表明，模型在前半部分就确定了答案格式，但最终答案需要更深入的计算。
### Conclusion
我们的结果提供了LLMs深度使用情况的详细视图，揭示了底层计算如何支持成功预测，并为改进基于变换器模型的计算效率提供了见解。
## 198. `cs.AI` - LENS: 大规模预训练变压器，用于探索金融时间序列规律 [PDF](https://arxiv.org/pdf/2408.10111), [HTML](https://arxiv.org/abs/2408.10111)
### Authors
Yuanjian Xu,Anxian Liu,Jianing Hao,Zhenzhuo Li,Shichang Meng,Guang Zhang
### Background
近年来，大规模时间序列建模得到了广泛关注。然而，直接将其应用于金融领域仍然具有挑战性，因为不同领域的数据特征差异较大。尤其是金融系统固有的随机性和低信噪比使得传统方法和预训练方法效果不佳。因此，亟需一种专门针对金融时间序列的数据基础模型。
### Innovation
提出了一种预训练模型LENS，通过精心设计的模型架构有效捕捉金融随机系统的复杂性，并通过使用可逆嵌入模块减轻预训练过程中的噪声。此外，研究表明LENS在嘈杂环境中开发预训练时间序列模型具有实用洞察，有助于这一领域的进一步发展。
### Conclusion
预训练于包含1000亿个金融观测值的数据集上，LENS在各种关键下游任务中表现出色。此外，这项工作为开发高噪声环境下的预训练时间序列模型提供了实践见解，有助于推动该研究领域的发展。
## 199. `cs.AI` - 多智能体序贯决策中的反事实效应分解 [PDF](https://arxiv.org/pdf/2410.12539), [HTML](https://arxiv.org/abs/2410.12539)
### Authors
Stelios Triantafyllou,Aleksa Sukovic,Yasaman Zolfimoselo,Goran Radanovic
### Background
本文研究了在多智能体马尔可夫决策过程中的反事实结果的解释挑战。特别地，旨在通过代理行为对环境动态和代理行为的影响来解释代理行为的总反事实效果对其已实现场景结果的影响。
### Innovation
提出了一个新颖的因果解释公式，该公式通过将每个代理和状态变量对其效果的贡献进行评分来分解反事实效果。此外，该论文进一步将这两个影响分解为代理特定影响和结构保持干预，分别通过Shapley值和状态变量的“内在”贡献进行归因。在网格世界环境和一种结合了LLM代理的模拟器中进行了大量实验，以展示该方法的可解释性。
### Conclusion
通过实验证明了该方法在解释多智能体序贯决策中的反事实效应的有效性和可解释性。
## 200. `cs.AI` - Fine-Tuned Thoughts: Leveraging Chain-of-Thought Reasoning for Industrial Asset Health Monitoring [PDF](https://arxiv.org/pdf/2510.18817), [HTML](https://arxiv.org/abs/2510.18817)
### Authors
Shuxin Lin,Dhaval Patel,Christodoulos Constantinides
### Background
Small Language Models (SLMs)由于其效率高、计算需求低且能够针对特定领域进行微调，正在越来越多地被应用于专门的领域中，如工业应用。然而，在像工业4.0这样的专门领域中，使用SLMs进行复杂的推理仍然是一个挑战。
### Innovation
论文提出了一种知识精炼框架，通过Chain-of-Thought (CoT) 精炼从大型语言模型（LLMs）转移推理能力到更小、更高效的模型（SLMs），并使用多项选择问题作答（MCQA）提示增强推理并优化决策。此外，论文还进行了上下文学习，以验证生成知识的质量，并将微调后的SLMs与生成知识性能与广泛使用的LLMs进行了基准测试。
### Conclusion
微调后的SLMs通过CoT推理超过了基线模型，显著缩小了与其LLM对应物的差距。
## 201. `cs.AI` - 掌握任意区域：迈向 multimodal 大型语言模型的精确、情境化像素理解 [PDF](https://arxiv.org/pdf/2510.18876), [HTML](https://arxiv.org/abs/2510.18876)
### Authors
Haochen Wang,Yuhao Wang,Tao Zhang,Yikang Zhou,Yanwei Li,Jiacong Wang,Ye Tian,Jiahao Meng,Zilong Huang,Guangcan Mai,Anran Wang,Yunhai Tong,Zhuochen Wang,Xiangtai Li,Zhaoxiang Zhang
### Background
尽管多模态大型语言模型（MLLMs）在整体理解方面表现出色，但在捕捉复杂场景的能力上存在不足，需要对细节和物体间关系进行细致分析。区域级别的 MLLMs 是一种有前途的方法，但仍主要集中在单独理解给定区域，忽视了全球上下文。因此，研究者提出了 Grasp Any Region (GAR)，以实现全面的区域级视觉理解，并引入了一种有效的RoI对齐特征重播技术，支持精确感知和多种提示之间的交互建模，从而达到高级组合推理来回答任何区域的特定问题，从被动描述转变为主动对话。此外，还构建了 GAR-Bench，不仅提供了更准确的单一区域理解评估，还衡量了跨多个区域的交互和复杂推理。广泛的实验说明了 GAR-1B 不仅保持了最先进的字幕生成能力，还擅长处理多种提示之间的关系，在复杂推理方面甚至超过了 InternVL3-78B，更重要的是，零样本的 GAR-8B 在 VideoRefer-BenchQ 中甚至超过了领域内 VideoRefer-7B，表明其能力强且易于迁移至视频中。
### Innovation
Grasp Any Region (GAR) 提出了一种全新的方法进行综合区域级视觉理解，通过 RoI 对齐特征重播技术，支持精确感知和多提示交互建模，并实现了高级组合推理。此外，还构建了 GAR-Bench 评估工具，不仅可以评估单一区域理解，还能评估从单一区域到多个区域的复杂推理能力。
### Conclusion
实验表明，GAR-1B 保持了最先进的字幕生成能力，并在复杂推理方面甚至超过了 InternVL3-78B，而零样本的 GAR-8B 也表现出色，甚至在 VideoRefer-BenchQ 中优于领域内的 VideoRefer-7B，展示了其强大的理解和迁移能力。
## 202. `cs.AI` - 使用AI发现课程：智能辅导系统教授项目选择的概念验证演示 [PDF](https://arxiv.org/pdf/2406.04082), [HTML](https://arxiv.org/abs/2406.04082)
### Authors
Lovis Heindrich,Falk Lieder
### Background
个体和组织做出的决策往往是次优的，因为在现实世界中完全理性的决策过于耗费资源。近期研究表明，通过利用人工智能发现和传授精明的启发式方法可以预防一些错误。然而，至今为止，这一领域的研究主要局限于简化的人工决策任务。本文首次将这种方法应用于实际决策问题，即高管决定公司应启动哪个项目。该研究通过开发一种计算方法（MGPS）自动发现针对真实人的项目选择策略，并开发了一个智能导师来教授发现的项目选择程序。
### Innovation
本文首次将人工智能应用于实际世界中的决策问题，具体是指高管决定公司应启动的项目。研究开发了一种计算方法（MGPS）来自动发现项目选择策略，并开发了一个智能导师来教授这些策略。研究结果表明，AI可以用于自动化的启发式策略发现和形式化过程，最终用于智能辅导系统中教学认知策略的自动化.
### Conclusion
MGPS在计算基准测试中表现优于最先进的方法，并且在培训实验中更高效。此外，通过我们的智能导师进行练习的人比对照组在选择项目策略方面学习得更好。这些发现表明，AI可以用于自动化发现和形式化智能辅导系统中教授的认知策略过程。
## 203. `cs.AI` - 为可扩展监督建模人类对AI行为的信念 [PDF](https://arxiv.org/pdf/2502.21262), [HTML](https://arxiv.org/abs/2502.21262)
### Authors
Leon Lang,Patrick Forré
### Background
随着AI系统的进步超越人类的能力，可扩展的监督变得至关重要。人类评估者在复杂任务中可能形成关于AI行为的不正确信念，导致反馈不可靠和价值推断失败。因此，需要一种方法来更准确地解读评估者的反馈，以提高价值学习的可靠性与准确性。
### Innovation
提出了建模评估者信念的方法，以更可靠地解释他们的反馈。通过形式化人类信念模型和它们在价值学习中的理论作用，分析了不确定性剩余的情况。在此基础上，提出了一种称为'信念模型覆盖'的放松方法，引入了适应基础模型的内部表示以模拟人类评估者的信念，从而即使评估者误解了AI行为，也能从人类反馈中学习正确的价值。
### Conclusion
这项工作表明，建模人类信念可以提高价值学习，并概述了实施此方法以实现可扩展监督的实用研究方向。
## 204. `cs.AI` - InternLM2.5-StepProver: 引入批评家指导搜索以推进自动定理证明 [PDF](https://arxiv.org/pdf/2410.15700), [HTML](https://arxiv.org/abs/2410.15700)
### Authors
Zijian Wu,Suozhi Huang,Zhejian Zhou,Huaiyuan Ying,Zheng Yuan,Wenwei Zhang,Dahua Lin,Kai Chen
### Background
大型语言模型（LLMs）在数学定理证明中表现出强大的潜力，尤其是在使用形式语言如LEAN时。当前证明方法通常通过迭代构建证明策略，并遵循最佳优先搜索方案。然而，这种方法往往会忽视现有策略路径中的关键偏好信息，这限制了对更深层证明的搜索能力。
### Innovation
提出了一种直观且有效的方法，该方法利用批评模型捕捉偏好信息，并在运行时引导证明模型的搜索。结合证明者-批评家框架，进行了大规模专家迭代（超过20,000个CPU天），进一步微调证明者和批评家模型。经过训练的InternLM2.5-StepProver批评家显著提升了证明者模型的性能（从59.4%提高到65.9%）。此外，分析了批评家在专家迭代过程中对定理证明过程各方面的具体影响，提供了关于其有效性的见解。
### Conclusion
本研究表明，利用批评家指导搜索能够显著提高自动定理证明的性能，并且证明者-批评家框架为更深入地研究和优化自动定理证明提供了新的可能。作者开源了模型和搜索证明结果。
## 205. `cs.AI` - 复杂代理环境中的结构丰富轨迹的学习和编码的表征框架 [PDF](https://arxiv.org/pdf/2503.13194), [HTML](https://arxiv.org/abs/2503.13194)
### Authors
Corina Catarau-Cotutiu,Esther Mondragon,Eduardo Alonso
### Background
在复杂场景中，人工智agents难以进行最优决策并将其扩展到不同领域和任务。现有方法主要集中在学习有效表示世界和agent行为如何在状态转移中影响这些表示，但这种方式在结构性丰富方面存在不足。
### Innovation
本文提出了一种增强agent本体的方法，并扩展了对轨迹的传统看法，以提供更复杂任务执行的细致观点。结构丰富轨迹（SETs）通过引入对象、交互和功能之间的层次关系来扩展状态序列及其转换的编码，以提供agent动态的详细表示和任务的功能性抽象。SETs被集成到一种架构中，即结构丰富轨迹学习与编码（SETLE），利用多层次关系依赖的异构图式结构，以支持泛化。
### Conclusion
SETLE能够支持下游任务，使agent能够在CREATE和MiniGrid环境中识别任务相关的结构性模式。将SETLE与强化学习结合，表现出在复杂、稀疏奖励任务中的可测量性能改进，包括突破性的成功率。
## 206. `cs.AI` - 通过 Curriculum RL 来缓解 Lost-in-Conversation 中的可验证准确性和舍弃奖励 [PDF](https://arxiv.org/pdf/2510.18731), [HTML](https://arxiv.org/abs/2510.18731)
### Authors
Ming Li
### Background
大型语言模型在单轮指令理解方面表现出色，但在多轮对话环境中，由于信息逐渐披露导致的对话迷失现象（LiC）带来的性能下降问题。当前进展注重利用验证性奖励的强化学习方法（RLVR），但这些方法往往侧重于模型只能生成正确答案而忽视了判断问题可解性的需求，特别是在多轮对话中。本文即在此背景下提出了一种新的框架，即 Curriculum Reinforcement Learning with Verifiable Accuracy and Abstention Rewards（RLAAR），旨在强化模型在多轮对话中正确解答问题和合理舍弃困难问题的能力，从而缓解 LiC 的现象。
### Innovation
该论文提出的 Curriculum Reinforcement Learning with Verifiable Accuracy and Abstention Rewards（RLAAR）框架旨在通过采用一个基于能力的课程学习策略，逐渐增加对话难度，同时利用多轮强化学习和混合奖励系统，使模型能够平衡问题解决与合理舍弃，减少过早回答问题的行为以缓解 LiC 现象。RLAAR 框架通过验证性准确性和舍弃奖励鼓励模型在多轮对话环境中不仅生成正确的答案，还能正确判断问题的可解性。
### Conclusion
在 LiC 基准测试中，本文提出的 RLAAR 框架显著减轻了 LiC 性能的下降，从 62.6% 提升至 75.1%，并且提高了校准的舍弃率从 33.5% 提高到 73.4%，上述结果为构建多轮可靠且可信赖的大型语言模型提供了实践指南。
## 207. `cs.AI` - HyperGraphRAG：基于超图结构知识表示的检索增强生成 [PDF](https://arxiv.org/pdf/2503.21322), [HTML](https://arxiv.org/abs/2503.21322)
### Authors
Haoran Luo,Haihong E,Guanting Chen,Yandan Zheng,Xiaobao Wu,Yikai Guo,Qika Lin,Yu Feng,Zemin Kuang,Meina Song,Yifan Zhu,Luu Anh Tuan
### Background
当前的标准检索增强生成（RAG）方法依赖于基于块的检索，而GraphRAG通过基于图的知识表示在这一方法上进行改进。然而，现有的基于图的RAG方法由于普通图中的每条边只能连接两个实体，所以受限于二元关系，无法有效表示现实生活中的多元关系（n >= 2）。
### Innovation
本文提出了一种新颖的基于超图的RAG方法——HyperGraphRAG，该方法通过超边表示多元关系，构建知识超图，进行检索和生成。实验表明，HyperGraphRAG在答案准确性、检索效率和生成质量上均超过了标准RAG和之前的基于图的RAG方法。
### Conclusion
实验结果表明，HyperGraphRAG在医学、农业、计算机科学和法律等多个领域中，在答案准确性、检索效率和生成质量方面均优于标准RAG和之前的基于图的RAG方法。同时，数据和代码已公开提供。
## 208. `cs.AI` - 通过在线对抗训练和生成模型提高人机协调 [PDF](https://arxiv.org/pdf/2504.15457), [HTML](https://arxiv.org/abs/2504.15457)
### Authors
Paresh Chaudhary,Yancheng Liang,Daphne Chen,Simon S. Du,Natasha Jaques
### Background
在许多经济上有价值的人工智能任务中，如家庭机器人和自动驾驶，与各种人类合作是一项重要技能。为了应对新出现的人类行为，需要利用能够捕捉人类行为多样性的数据进行训练。对抗训练是一种有潜力的方法，它可以动态生成数据并确保代理的鲁棒性。它通过代理的性能影响新对抗数据的生成，这些数据可以立即用于训练代理。然而，在合作任务中应用对抗训练具有挑战性，如何训练一个合作的对手？
### Innovation
该研究提出了一种新颖的方法，将预训练生成模型模拟有效的合作策略与对抗训练结合使用，以最大化后悔。这种方法称为GOAT（生成在线对抗训练）。在该框架中，GOAT动态在生成模型的潜在空间中搜索协调策略，其中学习策略（合作者代理）表现不佳。通过GOAT，合作者能够暴露在各种具有挑战性的互动场景中，从而更好地泛化。作者还保持生成模型不变，以避免对抗性利用，维持现实的协调策略。
### Conclusion
我们通过GOAT方法和真实人类合作伙伴进行了评估，结果表明，GOAT在Overcooked基准测试中的表现达到了最先进的技术水平，突显了其在适应各种人类行为方面的能力。
## 209. `cs.AI` - SOCIA: 联合结构-参数协同优化以实现自动化模拟器构建 [PDF](https://arxiv.org/pdf/2505.12006), [HTML](https://arxiv.org/abs/2505.12006)
### Authors
Yuncheng Hua,Sion Weatherhead,Mehdi Jafari,Jianxiang Xie,Ji Miao,Hao Xue,Flora D. Salim
### Background
从数据构建可信的模拟器面临挑战，因为结构设计、参数校准和异常分布外（OOD）鲁棒性紧密相关。现有的方法往往难以处理这些相互依赖的问题，从而影响了模拟器的可靠性和泛化能力。
### Innovation
SOCIA框架将模拟器构建视为结构和参数的联合优化：它能生成丰富的机制蓝图、暴露可调参数并提供校准方案，生成具有内置校准钩子的可执行模拟器。SOCIA结合了贝叶斯优化和基于模拟的推断方法，实现了高效点校准和不确定性感知拟合，通过外循环诊断触发针对性的结构编辑，实现了设计和参数的协同优化，即使在预算紧张的情况下也能取得良好的效果。
### Conclusion
SOCIA在三个不同的任务中均优于强大的基线模型，对于在分布内（ID）拟合和OOD偏移都表现出色。消融实验证明，统一的结构-参数优化是必要的。不久将发布SOCIA的代码。
## 210. `cs.AI` - LLMs 可以解决反事实推理中的知识冲突吗？ [PDF](https://arxiv.org/pdf/2506.15732), [HTML](https://arxiv.org/abs/2506.15732)
### Authors
Khurram Yamin,Gaurav Ghosal,Bryan Wilder
### Background
大型语言模型被证明在其参数中包含了大量的世界知识，这使得它们在许多知识密集型任务上表现出色。然而，当在新的应用场景中部署时，这些模型经常会遇到需要将参数化知识与新信息或不熟悉的信息相结合的情况。研究发现，这些模型在处理反事实推理时通常难以结合背景中的知识与参数化知识，往往只是依赖其参数化知识。简单后处理微调也不能有效地提升反事实推理能力，往往导致存储参数化知识的退化。这项研究揭示了当前大型语言模型在新场景中重新利用参数化知识的重要局限性。
### Innovation
研究以反事实推理为视角，探索大型语言模型是否能够结合背景中的知识与其参数化知识。通过合成实验和现实中的多步推理问题进行实验，证明了大型语言模型在反事实推理方面普遍存在困难，往往依赖参数化知识。此外，简单后处理微调在提升反事实推理能力方面也面临挑战，可能导致已存储的参数化知识质量下降。
### Conclusion
这项研究揭示了当前大型语言模型在其参数化知识在新场景中再利用时的重要局限性，表明需要更加深入的研究来解决知识冲突问题，提升模型在复杂和多变环境下的适应能力。
## 211. `cs.AI` - 基于大型语言模型和多智能体协作的移动智能助理多模态评估框架 [PDF](https://arxiv.org/pdf/2508.09507), [HTML](https://arxiv.org/abs/2508.09507)
### Authors
Meiping Wang,Jian Zhong,Rongduo Han,Liming Kang,Zhengkun Shi,Xiao Liang,Xing Lin,Nan Gao,Haining Zhang
### Background
移动智能助理技术的快速发展使得多模态人工智能助理成为日常用户交互不可或缺的接口。然而，当前的评估方法面临着手工成本高、标准不一致和主观偏差等挑战。
### Innovation
提出了一种基于大型语言模型和多智能体协作的自动化多模态评估框架。该框架采用三层智能体架构，包括交互评估智能体、语义验证智能体和体验决策智能体。通过在Qwen3-8B模型上进行监督微调，实现了与人工专家的高度评估匹配准确度。实验结果表明该框架在预测用户满意度和识别生成缺陷方面具有有效性。
### Conclusion
实验结果显示该框架在八个主要智能代理上的有效性，在预测用户满意度和识别生成缺陷方面表现出色。
## 212. `cs.AI` - LightMem：轻量级高效的增强记忆生成系统 [PDF](https://arxiv.org/pdf/2510.18866), [HTML](https://arxiv.org/abs/2510.18866)
### Authors
Jizhan Fang,Xinle Deng,Haoming Xu,Ziyan Jiang,Yuqi Tang,Ziwen Xu,Shumin Deng,Yunzhi Yao,Mengru Wang,Shuofei Qiao,Huajun Chen,Ningyu Zhang
### Background
大型语言模型（LLMs）尽管具有出色的性能，但在动态和复杂环境中难以有效利用历史交互信息。现有的增强记忆系统虽然引入了持久的信息存储、检索和利用机制，但往往伴随着显著的时间和计算开销。因此，本文介绍了一种名为LightMem的新记忆系统，旨在平衡记忆系统性能和效率。LightMem参考了人类记忆的Atkinson-Shiffrin模型，将记忆划分为三个互补阶段：首先，通过轻量级压缩快速过滤无关信息并按主题分组；其次，主题感知的短时记忆将这些基于主题的组进行整合和总结，以便更结构化的访问；最后，带有睡眠时间更新的长期记忆采用脱机程序，将整合过程与在线推理分离。
### Innovation
LightMem strikingly平衡了记忆系统的性能和效率。它通过借鉴人类记忆模型，创新性地将记忆分为三级：感官记忆、短期记忆和长期记忆，并通过脱机更新长期记忆，有效减少了在线推理与记忆更新的冲突。实验表明，LightMem在LongMemEval测试集上使用GPT和Qwen模型时，不仅在准确率上优于强基线（最高10.9%的提升），还大幅降低了token使用量（最高117倍）、API调用次数（最高159倍）和运行时间（超过12倍的提速）
### Conclusion
实验结果表明，LightMem在准确率上优于现有基线，并且在token使用量、API调用次数和运行时间方面表现出显著优势。相关代码已公开。
## 213. `cs.AI` - Can Agents Fix Agent Issues? [PDF](https://arxiv.org/pdf/2505.20749), [HTML](https://arxiv.org/abs/2505.20749)
### Authors
Alfin Wijaya Rahardja,Junwei Liu,Weitong Chen,Zhenpeng Chen,Yiling Lou
### Background
LLM-based代理系统正在成为新的软件范式，并被广泛应用于医疗、机器人和编程等多个领域。然而，这些系统的维护需要大量的工作，因为它们不可避免地会出现错误，并不断进化以满足不断变化的外部需求。因此，自动解决代理问题（即错误报告或功能请求）是一项至关重要的挑战性任务。尽管最近的软件工程代理（如SWE-agent）在解决传统软件系统的问题上表现出良好的前景，但在代理系统中实际应用的效果仍不清楚，因为代理系统与传统软件有很大的不同。现有的软件工程代理尚不能有效解决这些问题。
### Innovation
该研究首先手动分析了201个实际的代理问题并识别了常见问题类别，然后花费500个人小时构建了包含50个代理问题解决任务的AGENTISSUE-BENCH基准测试，每个任务都有可执行环境和故障触发测试。进一步评估了最先进的软件工程代理在AGENTISSUE-BENCH上的性能，并揭示了它们的有限效果（即3.33%-12.67%的解决率）。这些结果强调了维护代理系统与传统软件的独特挑战，突显了进一步研究以开发先进的软件工程代理解决代理问题的必要性。
### Conclusion
这些结果突显了维护代理系统与传统软件的特殊挑战，强调了进一步研究以开发先进的软件工程代理解决代理问题的必要性。
## 214. `cs.AI` - VIKI-R:通过强化学习协调具身多代理合作 [PDF](https://arxiv.org/pdf/2506.09049), [HTML](https://arxiv.org/abs/2506.09049)
### Authors
Li Kang,Xiufeng Song,Heng Zhou,Yiran Qin,Jie Yang,Xiaohong Liu,Philip Torr,Lei Bai,Zhenfei Yin
### Background
在人工智能领域，协调多个具身代理在动态环境中的合作仍然是一个核心挑战，这需要感知驱动的推理和可扩展的合作策略。尽管最近的研究已经利用大型语言模型（LLMs）进行多代理规划，但鲜有研究探索视觉语言模型（VLMs）进行视觉推理。然而，现有的VLM方法在支持不同类型的具身化方面仍有限制。
### Innovation
本文介绍了VIKI-Bench，这是首个针对具身多代理合作的层次化基准，包括代理激活、任务规划和轨迹感知三个结构层次。该基准还包含多种机器人具身类型、多视角视觉观测和基于视觉输入的结构化监督信号。此外，本文提出了VIKI-R，这是一种两级框架，首先利用带有Chain-of-Thought注释的示范进行预训练视觉语言模型（VLM）的微调，然后在多层次奖励信号下使用强化学习。这种方法显著优于基线方法，并展示了强化学习如何在异构代理之间促进组合性合作模式的出现。
### Conclusion
本文的工作为推进具身AI系统中的多代理视觉驱动合作提供了一个统一的测试平台和方法，通过广泛实验表明，VIKI-R在所有任务层面显著优于基线方法，并展示了异构代理间组合性合作模式的产生能力。
## 215. `cs.AI` - 大型语言模型能否在时间序列上充分完成符号推理？ [PDF](https://arxiv.org/pdf/2508.03963), [HTML](https://arxiv.org/abs/2508.03963)
### Authors
Zewen Liu,Juntong Ni,Xianfeng Tang,Max S.Y. Lau,Wenpeng Yin,Wei Jin
### Background
从开普勒发现行星运动开始，从时间序列数据中发现隐含的符号法则一直是科学发现和人工智能的核心挑战。尽管大型语言模型在结构化推理任务中表现出色，但它们从时间序列数据中推断出可解释且上下文对齐的符号结构的能力仍处于探索阶段。为了系统地评估这一能力，该研究引入了SymbolBench，一个综合基准，用于评估大型语言模型在现实世界时间序列上的符号推理能力，包括多元符号回归、布尔网络推理和因果发现三项任务。与以往仅局限于简单代数方程的研究不同，SymbolBench覆盖了不同复杂性的各种符号形式。此外，该研究提出了一种将大型语言模型与遗传编程整合的统一框架，形成一个闭环符号推理系统，其中大型语言模型既作为预测器又作为评估器。实验证明了当前模型的关键优点和局限性，强调了结合领域知识、上下文对齐和推理结构对于提升大型语言模型在自动化科学发现中的重要性。
### Innovation
该研究引入了SymbolBench，一个全面的基准评估系统，旨在评测大型语言模型对时间序列数据中的符号推理能力，覆盖多元符号回归、布尔网络推理和因果发现三项任务。此外，该研究还提出了将大型语言模型与遗传编程结合的统一框架，实现闭环符号推理系统，其中大型语言模型既承担预测也承担评估的角色。该工作进一步强调了结合领域知识、上下文对齐和推理结构对于提升大型语言模型在自动化科学发现中的重要性。
### Conclusion
通过实验结果揭示了当前模型在符号推理和时间序列分析方面的重要能力和局限，指出了结合领域知识、上下文对齐和推理结构对改进大型语言模型自动化科学发现的重要性。
## 216. `cs.AI` - ComputerRL：为计算机使用代理扩展端到端在线强化学习 [PDF](https://arxiv.org/pdf/2508.14040), [HTML](https://arxiv.org/abs/2508.14040)
### Authors
Hanyu Lai,Xiao Liu,Yanxiao Zhao,Han Xu,Hanchen Zhang,Bohao Jing,Yanyu Ren,Shuntian Yao,Yuxiao Dong,Jie Tang
### Background
背景：计算机RL（ComputerRL）框架旨在使自主桌面智能代理能够熟练地操作复杂的数字工作空间。强化学习在端到端训练方面面临挑战，特别是由于环境效率低下和长时间训练过程中的不稳定性。现有方法难以实现扩展和稳健的训练，特别是在多元化的桌面任务上提高和泛化能力。
### Innovation
创新：ComputerRL提出了API-GUI范式，整合了程序API调用和直接的GUI交互，以解决机器代理与以人为中心的桌面环境之间的固有不匹配问题。提出了分布式RL基础设施，能够协调成千上万的并行虚拟桌面环境，以加速大规模在线强化学习的训练过程。此外，还提出了Entropulse训练策略，交替进行强化学习和监督微调，有效缓解了长时间训练期间的熵坍缩问题。
### Conclusion
结论：ComputerRL已在开源模型AutoGLM-OS-9B上进行评估，并在OSWorld基准测试中取得48.9%的新最佳准确率。这显示出ComputerRL框架和算法在桌面自动化通用代理上的显著改进。本研究的代码和新的OfficeWorld基准已公开提供，并被用于构建AutoGLM。
## 217. `cs.AI` - PowerChain：一种可验证的代理AI系统，用于自动化配电网分析 [PDF](https://arxiv.org/pdf/2508.17094), [HTML](https://arxiv.org/abs/2508.17094)
### Authors
Emmanuel O. Badmus,Peng Sang,Dimitrios Stamoulis,Amritanshu Pandey
### Background
随着配电网络(DG)的快速电气化和去碳化，其运营和规划变得更加复杂，需要进行高级计算分析以确保可靠性和韧性。当前的分析依赖于复杂的模型、函数调用和数据管道等不同工作流程，这些都需要大量专业知识并且难以自动化。人力和预算的限制进一步限制了电力公司扩大应用这些分析的规模。
### Innovation
PowerChain是一种代理系统，能够自主进行复杂的电网分析，特别创新之处在于，PowerChain能够通过利用自我封闭的电力系统工具(例如GridLAB-D)提供的监督信号以及优化的专家标注和验证推理轨迹来动态生成结构化上下文，从而泛化到未见过的新DG分析任务中。
### Conclusion
在使用自然语言定义的复杂DG任务上，实测结果表明，PowerChain在性能上比基线高出144%，这表明该系统在自动化配电网分析方面的优越性。
## 218. `cs.AI` - LLMs在游戏中是否战略性地揭示、隐藏和推理信息？基于《变色龙》游戏的理论和实证分析 [PDF](https://arxiv.org/pdf/2501.19398), [HTML](https://arxiv.org/abs/2501.19398)
### Authors
Mustafa O. Karabag,Jan Sobotka,Ufuk Topcu
### Background
该论文研究了基于大型语言模型（LLM）的代理在包含不合作方的环境中如何进行信息控制和决策。研究通过让LLM代理参与《变色龙》这一游戏，探讨了它们是否具备隐藏信息、揭示信息和推断信息的能力。研究者通过理论分析和实证研究发现，虽然LLM代理能够识别变色龙，但它们在隐藏秘密方面表现不佳。这一研究背景揭示了当前LLM在信息控制方面的不足之处及其为何未能有效隐藏信息的原因。
### Innovation
该研究的创新点在于它通过游戏化的实验设计，系统地测试了LLM在信息控制和决策方面的能力，特别是在隐藏和揭示信息方面的表现。研究不仅提供了理论上的解读，还进行了实证分析，使用了多个不同的LLM模型进行实验，这大大增加了研究结果的可靠性和结论的适用范围。研究还揭示了LLM内部代表特性如何影响代理的行为，以及如何通过直接干预内部代表来引导代理隐藏信息的行为。
### Conclusion
该研究的结论是，尽管基于LLM的代理能够识别变色龙，但在隐藏信息方面表现不佳，特别是在变色龙角度，它们未能有效地隐藏秘密。这一发现表明，现有的LLM可能在面对未知身份的代理时过度揭示了信息。研究还指出，通过直接控制内部代表的线性编码，可以有效地促使代理隐藏信息。这一结论为未来改进LLM的信息控制能力提供了理论依据和实证指导。
## 219. `cs.AI` - 当代理迷失方向：通过PRMs纠偏SWE代理 [PDF](https://arxiv.org/pdf/2509.02360), [HTML](https://arxiv.org/abs/2509.02360)
### Authors
Shubham Gandhi,Jason Tsay,Jatin Ganhotra,Kiran Kate,Yara Rizk
### Background
大型语言模型（LLM）代理正越来越多地被用于复杂的、多步骤的软件工程（SWE）任务。然而，这些代理的轨迹中经常包含昂贵的低效性，如重复探索、循环和在找到解决方案后未能终止执行。从前的工作主要是在执行之后进行事后诊断，检测错误。本文介绍了在推理时间内使用过程奖励模型（PRM）干预执行、检测和纠正轨迹级错误的方法。
### Innovation
提出了一种基于过程奖励模型（PRM）的纠偏方法——SWE-PRM，在执行过程中实时介入以检测和纠正轨迹级错误。该PRM设计中利用了常见的低效性的分类目录，提供轻量级、可解释的反馈而不修改基础策略。在SWE-bench Verified中，使用闭源PRM能够将问题解决率从40.0%提高到50.6%，特别是在中等和困难任务上表现最佳。与无指导或明确动作指令的反馈策略相比，基于分类目录的PRM提高了成功率并减少了轨迹长度，同时增加了可接受的附加推理成本，最高不会超过0.2。
### Conclusion
PRMs成为提高SWE代理可靠性和效率的实用且可扩展机制。基于过程奖励模型（PRM）的方法在解决SWE任务时显示出显著优势，并且能够在保持合理成本的条件下提供有效的反馈，帮助改善代理的执行效果。
## 220. `cs.AI` - 通过测试时转换进行程序合成 [PDF](https://arxiv.org/pdf/2509.17393), [HTML](https://arxiv.org/abs/2509.17393)
### Authors
Kang-il Lee,Jahyun Koo,Seunghyun Yoon,Minbeom Kim,Hyukhun Koh,Dongryeol Lee,Kyomin Jung
### Background
在程序合成任务中，以往的方法无论是基于自然语言描述还是输入输出示例，通常都会从训练示例中进行泛化，但在现实世界中，由于训练示例有限且测试输入涉及各种边缘情况，这种方法常常难以保证鲁棒性。本研究提出了一种新的程序合成形式，即通过测试输入明确地在合成过程中利用这些信息。这种方法旨在提高在训练示例有限和测试输入情况复杂的情况下程序合成的鲁棒性，以克服前人方法遇到的问题。
### Innovation
该研究提出了一种新的框架，通过将程序合成视为对由程序输出定义的有限假设类进行主动学习来提高鲁棒性。使用大型语言模型（LLM）预测经过精心选择的测试输入的输出结果，并消除不一致的假设。输入的选择使用贪婪最大化选择算法，以最小化所需的LLM查询次数。
### Conclusion
研究在四个基准上评估了该方法，包括Playgol、MBPP+、1D-ARC以及MiniGrid上的程序化世界建模。结果表明，该方法在准确性和效率上都有显著提升。研究还公开了代码。
## 221. `cs.AI` - GPO: 从关键步骤中学习以提高LLM推理能力 [PDF](https://arxiv.org/pdf/2509.16456), [HTML](https://arxiv.org/abs/2509.16456)
### Authors
Jiahao Yu,Zelei Cheng,Xian Wu,Xinyu Xing
### Background
大型语言模型（LLMs）在多个领域得到了广泛应用，展示了在不同任务上的强大潜力。最近提出了推理LLMs来提升LLMs的推理或思考能力以解决复杂问题。尽管推理LLMs取得了令人鼓舞的结果，但增强LLMs的多步推理能力仍然是一个重大挑战。现有的优化方法虽然推动了LLMs的推理能力发展，但它们通常将推理轨迹作为一个整体处理，而不考虑轨迹中的关键步骤。因此，本文提出了GPO（Guided Pivotal Optimization），一种新的微调策略，旨在通过专注于推理过程中的关键步骤来改进LLMs的推理能力。
### Innovation
本文提出的GPO是一种新的微调策略，通过识别推理轨迹中的关键步骤并对其进行重新调整，从而优先学习那些关键时刻。这种方法能够使模型从推理过程中关键时刻学到更多，从而提高推理性能。GPO还可以与多种优化方法集成，以改进推理性能。并通过实验展示了其在各种推理基准测试中的有效性和普适性。
### Conclusion
GPO是一种通用策略，可以与各种优化方法结合，以提高LLMs的推理性能。通过集中在生成过程中的关键时刻，GPO使得模型能够更有效地学习，从而提高其推理能力。
## 222. `cs.AI` - Proof2Silicon: 基于强化学习的验证代码和硬件生成提示修复 [PDF](https://arxiv.org/pdf/2509.06239), [HTML](https://arxiv.org/abs/2509.06239)
### Authors
Manvi Jha,Jiaxin Wan,Deming Chen
### Background
大型语言模型（LLMs）在自动代码生成方面表现出色，但在进行正式验证时经常出现问题。正确性由构造（Correct-by-Construction）的硬件对于硬件和安全性关键领域非常重要，但通常需要正式验证。先前的研究提出了PREFACE框架，通过基于强化学习的方法来遍历地修复输入给冻结LLM的提示，确保生成Dafny代码的正确性。然而，PREFACE仍面临较高成本的微调问题。因此，需要一种新的方法来实现从自然语言规范直接生成正确性由构造的硬件的方法，以解决这一问题。
### Innovation
本文提出了Proof2Silicon，一种新的端到端合成框架，通过嵌入先前提出的PREFACE流程，将自然语言规范直接转换为能够自动验证的硬件。Proof2Silicon通过（1）利用PREFACE验证驱动的强化学习代理优化提示生成，确保Dafny代码的正确性；（2）使用Dafny的Python后端和PyLog将验证通过的Dafny程序自动翻译为可综合的C语言高层代码；（3）使用Vivado HLS生成实际逻辑门级（RTL）实现。通过综合评价，结果表明Proof2Silicon能够实现高达72%的端到端硬件生成成功率，从而实现LLM驱动的、可正式验证的硬件合成自动化管道，从而连接自然语言规范与硬件实现。
### Conclusion
通过Proof2Silicon，实现了从自然语言直接生成正确性由构造的硬件的完整、可扩展和自动化的管道。该方法显著提高了Dafny验证的成功率，同时解决了先前方法中的微调成本问题。这一研究为硬件和安全性关键领域的自动化设计和验证提供了新的解决方案。
## 223. `cs.AI` - RepIt: 使用概念特定拒绝向量引导语言模型 [PDF](https://arxiv.org/pdf/2509.13281), [HTML](https://arxiv.org/abs/2509.13281)
### Authors
Vincent Siu,Nathan W. Henry,Nicholas Crispino,Yang Liu,Dawn Song,Chenguang Wang
### Background
尽管在大规模语言模型（LLMs）中激活定向研究正在增长，但当前的方法往往会引发超出预期的影响。因此，需要一种方法来隔离纯粹的概念向量，以便对模型行为进行目标干预并从更细致的角度理解模型的行为。这项研究提出了一种简单且数据效率高的框架RepIt，以实现这一目标。该框架在五个先进语言模型中实现了精准的干预：它能够选择性地抑制目标概念上的拒绝，同时在其它地方保留拒绝，生成能够在标准基准测试中保持安全评分但仍然回答与WMD相关的查询的模型。同时展示了纠正信号只是集中在约100到200个神经元上，并且可以从几个例子中提取出稳健的目标表示，这样提高了效率，使得在数据稀少且欠代表的话题上也能进行干预，同时避免现有的基准测试。通过使用RepIt解缠特定拒绝向量，这项工作展示了这种有目标的干预可以抵制过度一般化的现象，从而为进一步细化地控制模型行为打下了基础。 
### Innovation
提出了一种简单且数据效率高的框架RepIt，用于隔离概念特定的表示，实现对语言模型行为的精准干预。相比现有的方法，RepIt能够选择性地抑制特定概念上的拒绝行为，同时保留其他地方的拒绝行为。此外，研究还揭示了纠正信号仅集中在少量的神经元上，且可以从少量的实例中提取出稳健的目标表示，提升了模型干预的效率并对扩展到欠代表数据集具有重要意义。
### Conclusion
这项工作展示了通过使用RepIt解缠特定拒绝向量，可以对语言模型进行有目标的干预，抵制过度一般化的现象，从而为深入控制语言模型的行为提供了一种有效的方法。
## 224. `cs.AI` - Tree of Agents: 提高大型语言模型处理长上下文能力的多视角推理方法 [PDF](https://arxiv.org/pdf/2509.06436), [HTML](https://arxiv.org/abs/2509.06436)
### Authors
Song Yu,Xiaofei Xu,Ke Deng,Li Li,Lin Tian
### Background
大型语言模型在处理长上下文任务时面临着持续的挑战，尤其是中间信息丢失问题，即位于长输入中间的信息往往被低估利用。现有的减小输入长度的方法存在丢弃关键信息的风险，而增大上下文窗口的方法则容易引起注意力分散。为解决这些问题，本研究提出了一种基于多代理推理框架的 Tree of Agents (TOA) 方法，该方法将输入分成由独立代理处理的片段。每个代理生成局部认知，然后通过树状结构路径动态交换信息进行协作推理。TOA 允许代理从不同推理顺序中获取多视角理解，从而有效缓解位置偏差和减少幻觉现象。为了提高处理效率，引入了前缀散列缓存和自适应剪枝策略，从而在相似的 API 开销下实现显著的性能提升。实验结果显示，TOA 通过紧凑的 LLaMA3.1-8B 模型，在多个长上下文任务中显著优于多个基线模型，并表现出与最新且规模更大的商业模型（如 Gemini1.5-pro）相当的性能。
### Innovation
提出了 Tree of Agents (TOA) 多代理推理框架，将长文本输入分割成片段由独立代理处理，并通过树状结构路径动态交换信息进行协作推理。引入了前缀散列缓存和自适应剪枝策略，提高了处理效率。TOA 能够缓解位置偏差和减少幻觉现象，有效提升了大型语言模型处理长上下文任务的能力。
### Conclusion
实验结果表明，TOA 通过紧凑的 LLaMA3.1-8B 模型在多个长上下文任务中实现了显著的性能提升，甚至达到了与最新且规模更大的商业模型相当的效果。
## 225. `cs.AI` - 预训练共享Q网络以提高数据效率的离线强化学习 [PDF](https://arxiv.org/pdf/2505.05701), [HTML](https://arxiv.org/abs/2505.05701)
### Authors
Jongchan Park,Mingyu Park,Donghwan Lee
### Background
离线强化学习旨在通过静态数据集学习策略，而无需进一步与环境交互。收集足够的大数据集对于离线强化学习来说是艰巨的任务，因为它需要与环境进行大量的交互。当与环境的交互受限时，问题变得更加复杂。因此，如何用最小的静态数据集让智能体学习到最佳策略成为一个关键问题，在离线强化学习中类似于在线强化学习中的样本效率问题。
### Innovation
本文提出了一种简单而有效的插件式预训练方法，用于初始化Q网络的特征，以提高离线强化学习的数据效率。该方法利用了一个共享Q网络结构，能够输出下一个状态和Q值的预测，并通过有监督回归任务对其进行预训练，该任务预测下一个状态并将共享Q网络与不同的离线强化学习方法结合训练。通过大量实验，研究者证明了该方法可以提升现有流行离线强化学习方法在D4RL、Robomimic和V-D4RL基准测试中的性能，并且可以在不同数据质量和分布下大幅提升数据效率。特别地，即使使用了仅有10%的数据集，该方法也比标准算法在D4RL和ExoRL基准测试中表现更好，即使完全使用数据集也是如此。
### Conclusion
该研究提出了一种简单有效的预训练方法，利用共享Q网络来初始化特征，从而提高了离线强化学习的数据效率。实验结果表明，该方法能够显著提升多种不同的离线强化学习方法的性能，尤其在数据集较少的情况下表现突出。
## 226. `cs.AI` - SpecExit: 加速大型推理模型的 speculative 退出机制 [PDF](https://arxiv.org/pdf/2509.24248), [HTML](https://arxiv.org/abs/2509.24248)
### Authors
Rubing Yang,Huajun Bai,Song Liu,Guanghua Yu,Runzhi Fan,Yanbin Dang,Jiejing Zhang,Kai Liu,Jianchen Zhu,Peng Chen
### Background
尽管大型推理模型（LRMs）在推理任务方面表现出色，但它们常常会陷入过度思考，生成不必要的长输出，并带来较高的端到端延迟，这对它们的实际部署构成了重大限制。为了解决过度思考的问题，已经提出了早期退出机制，可以在典型完成前终止推理，显示了该方法能够在无显著影响准确性的前提下有效缩短生成长度。然而，依赖探针机制的早期退出方法引入了检测开销，限制了它们的端到端延迟增益，并且使得它们在不同问题上的泛化能力受到影响。
### Innovation
受投机解码中隐藏状态使用方式的启发，我们提出了 SpecExit，这是一种新型框架，它能够从一个轻量级草案模型直接预测未来的标记和早期退出信号，而不依赖探针机制。该方法显著降低了平均生成长度（缩短了66%），实现了与投机解码基线相比2.5倍的端到端延迟加速，同时保持了准确性。该方法通过利用隐藏状态中的内在信号提供有效的早期退出信号，这表明隐藏状态在未来高效推理中的广泛应用。
### Conclusion
我们的方法能够提供有效的隐藏状态信号，用于提升早期退出机制，同时保持准确性。这一发现表明在高效推理中可以更广泛地利用隐藏状态信号。我们的代码可以在指定的URL找到。
## 227. `cs.AI` - 超越Pass@k：基于Cover@tau的推理边界度量 [PDF](https://arxiv.org/pdf/2510.08325), [HTML](https://arxiv.org/abs/2510.08325)
### Authors
Marius Dragoi,Ioana Pintilie,Florin Gogianu,Florin Brad
### Background
强化学习可验证奖励（RLVR）在提高大型语言模型的推理任务能力（如编程、数学或逻辑）方面展现出了强大的潜力。在评估模型推理边界时，研究人员通常使用大采样预算下的Pass@k指标。最近的实验证明，尽管在小k值下RLVR模型表现优越，但随着采样样本数量的增加，基模型往往在解决更多问题上具有优势。这个现象被认为表明基模型具有更大的推理边界。然而，作者认为，对于具有离散答案空间的任务，如带有数字输出的数学问题，大k值下的Pass@k反映的是反复试验后成功机会的增加，而不是真正的推理能力，这可能具有误导性。
### Innovation
提出了一种新的评估指标——Cover@tau，衡量模型在某种可靠性阈值（至少tau比例的完成是正确的解）下能够解决的问题比例。该指标捕捉到了基于概率猜测的模型随着阈值增加而迅速下降的特点。通过使用Cover@tau评估多个RLVR模型，并将不同算法的相对排名与Pass@1进行比较，作者提供了对推理边界的另一种视角。
### Conclusion
新的Cover@tau度量方法可以更准确地评估模型的推理边界，公正地反映了不同模型在不同可靠性要求下的实际表现。
## 228. `cs.AI` - 驯服判官：为稳定强化学习清除AI反馈中的冲突 [PDF](https://arxiv.org/pdf/2510.15514), [HTML](https://arxiv.org/abs/2510.15514)
### Authors
Boyin Liu,Zhuo Zhang,Sen Huang,Lipeng Xie,Qingxu Fu,Haoran Chen,LI YU,Tianyi Hu,Zhaoyang Liu,Bolin Ding,Dongbin Zhao
### Background
使用大型语言模型（LLM）的反馈来调整语言模型提供了一种比人类注释更具扩展性的替代方案，但这一方法受到判官判断不一致性的问题困扰，这会影响强化学习的稳定性。尽管先前的研究集中在判官的准确性上，但逻辑连贯性特别是偏好循环的问题仍未得到充分关注。
### Innovation
这项工作提出了一种端到端的框架，以系统地检测并解决强化学习训练循环中的这些不一致性问题。框架的两大贡献是：1）冲突检测率（CDR），一种衡量判断冲突的新指标；2）去冲突化图回报（DGR），一种信号净化框架，在策略优化前消除循环。
### Conclusion
实验结果证明，该框架在提高训练稳定性和模型性能方面显著优于强基线，确立了逻辑一致性作为一个重要的并且现在可解决的人工智能反馈维度。我们的方法代码可在以下链接获取：this https URL.
## 229. `cs.AI` - R-Horizon: 如何深度挖掘你的大规模推理模型在广度和深度上的潜力？ [PDF](https://arxiv.org/pdf/2510.08189), [HTML](https://arxiv.org/abs/2510.08189)
### Authors
Yi Lu,Jianing Wang,Linsen Guo,Wei He,Hongyin Tang,Tao Gui,Xuanjing Huang,Xuezhi Cao,Wei Wang,Xunliang Cai
### Background
近年来，推理模型（如OpenAI的o1和DeepSeek-R1）在推理链（CoT）方面取得了显著进步。然而，现有的基准测试主要关注即时、单一场景的任务，未能充分评估模型应对复杂、长期场景的能力。因此，现有评估方法存在一定的局限性，无法全面评价大型推理模型（LRMs）的能力。
### Innovation
为了解决这一问题，本文提出了一种名为R-HORIZON的方法，通过查询组成来激发LRMs的长期推理行为。基于R-HORIZON，构建了一个长期推理基准，包含了复杂的多步推理任务，这些任务具有相互依赖的问题，横跨了长时间段的推理范围。通过使用R-HORIZON基准全面评估LRMs，研究发现即使最先进的LRMs在任务中的性能也出现了显著下降。我们分析表明，LRMs在有效推理长度上存在局限性，并且难以适当地分配思考预算到多个问题上。此外，通过使用R-HORIZON来构建具长时序推理数据的强化学习带有验证奖励（RLVR），该方法显著提高了多时序推理任务的性能，并在标准推理任务上提高了7.5%的准确性，从而表明R-HORIZON是一个可扩展、可控且低成本的框架，用于提升和评估长时序推理能力。
### Conclusion
本文提出的R-HORIZON是衡量和促进LRMs长期推理能力的一个有效工具。它不仅改善了复杂的多步推理，还在标准推理任务中提高了准确性。这种框架对于强化学习的发展和改进大型推理模型具有重要意义。
## 230. `cs.AI` - SAFER：大型语言模型中的风险约束采样过滤 [PDF](https://arxiv.org/pdf/2510.10193), [HTML](https://arxiv.org/abs/2510.10193)
### Authors
Qingni Wang,Yue Fan,Xin Eric Wang
### Background
随着大规模语言模型（LLMs）在像开放结束问答（QA）这样具有风险敏感性的应用中的部署越来越广泛，确保其输出的可信度已成为关键问题。现有的选择性置信预测（SCP）方法通过构建具有受限误报率的预测集来为正确答案提供统计保证，但这些方法假设所有实例的可接受答案都可以通过有限采样获得，即使是在缺乏固定和有限解决方案的空间的开放问答场景中。因此，需要一种新的方法来解决这一问题。
### Innovation
本文提出了一种两阶段的风险控制框架（SAFER），包括主动采样和置信度滤波两部分。在保留的一部分校准集上，通过Clopper-Pearson精确方法校准采样预算，从而在给定的风险水平内获得一个最大预算，高风险时采样停止以避免误报。接下来使用校准样本集中的实例进行风险控制的置信度滤波，确定统计上有效的不确定性阈值，从而从候选集中过滤出不可靠的干扰项。此外，SAFER框架还能够兼容各种针对特定任务的准入标准和校准-测试拆分比例，表现出较高的稳健性和数据效率。
### Conclusion
SAFER框架通过两阶段的风险控制实现了在LLMs中对预测过程的风险约束，避免了采样不足带来的误报风险，为开放问答场景下的可信度提高提供了有效的解决方案。
## 231. `cs.AI` - 人类恶意之回响：基于多轮在线骚扰攻击评估大语言模型 [PDF](https://arxiv.org/pdf/2510.14207), [HTML](https://arxiv.org/abs/2510.14207)
### Authors
Trilok Padhi,Pinxian Lu,Abdulkadir Erol,Tanmay Sutar,Gauri Sharma,Mina Sonmez,Munmun De Choudhury,Ugur Kursuncu
### Background
大语言模型（LLM）正越来越多地参与到互动网络应用程序中，但这些模型仍然面临着被滥用和造成损害的风险。之前关于模型逃离的研究大多关注单一回合的指令，而现实中的骚扰往往会通过多轮互动持续展开。因此，需要一个能够模拟多轮互动、基于重复博弈理论的骚扰行为基准，以提高对模型误用和潜在威胁的防范能力。
### Innovation
本文提出了Online Harassment Agentic Benchmark，包括：（i）一个合成的多轮骚扰对话数据集；（ii）一个多代理（如骚扰者、受害者）模拟，基于重复博弈理论；（iii）三种针对记忆、规划和微调的逃逸方法；（iv）一个混合方法评估框架。实验使用了两个重要的LLM——公开源代码的LLaMA-3.1-8B-Instruct和闭源的Gemini-2.0-flash。
### Conclusion
我们的研究结果表明，逃逸调优使骚扰几乎成为必然事件，相比之下，在没有调优的情况下，攻击成功率分别为57.25%至64.19%和98.46%至99.33%；同时攻击导致的拒绝率降低到1%到2%。总体来看，多轮和理论支持的攻击不仅在高频率下成功，还模仿了人类的骚扰动态，这表明需要开发更加 robust的安全机制，从而保障在线平台的安全和责任。
## 232. `cs.AI` - SimKO: Simple Pass@K Policy Optimization [PDF](https://arxiv.org/pdf/2510.14807), [HTML](https://arxiv.org/abs/2510.14807)
### Authors
Ruotian Peng,Yi Ren,Zhouliang Yu,Weiyang Liu,Yandong Wen
### Background
背景：强化学习与可验证奖励（RLVR）方法已经提升了大型语言模型（LLMs）的推理能力。然而，现有的RLVR方法倾向于过度利用而不充分探索，表现为虽然提高了pass@1的表现，但pass@K（K>1）的表现有所下降。这种现象需要进一步理解并解决，通过跟踪词汇候选的token级概率分布，这种偏见被揭示为一种概率集中效果，即top-1候选词逐渐累积概率并抑制其他候选词。更强的概率集中与更差的pass@K表现相关。
### Innovation
创新：提出了简单pass@K优化（SimKO）方法，旨在缓解过度集中的问题，鼓励探索。SimKO以不对称的方式运作：对验证正确的响应，提高top-K候选词的概率；对验证错误的响应，则对top-1候选词施加更重的惩罚。这种不对称的设计特别有效，尤其是在高熵的token上应用时。模拟结果表明，SimKO在数学和逻辑推理基准测试中广泛提高了pass@K，为改善RLVR的探索提供了一种简便的方法。
### Conclusion
结论：SimKO方法显著提高了RLVR在多种math和logical-reasoning基准测试中的pass@K表现，为改善RLVR的探索提供了一种简单有效的方法。
## 233. `cs.AI` - 实用户参与的多轮LLM健康辅导的离线策略评估 [PDF](https://arxiv.org/pdf/2510.17173), [HTML](https://arxiv.org/abs/2510.17173)
### Authors
Melik Ozolcer,Sang Won Bae
### Background
研究者们正在探索如何通过网络部署并借助工具增强大型语言模型（LLM）来作为健康教练的应用，尤其是在真实用户场景下的应用效果。这项研究以七名真实用户的试点测试和280次评分事件为背景，分析了策略评估在多轮LLM健康辅导中的应用效果。实验观察到了策略在不同用户群体中的不同表现效果，特别是在低健康素养高自我效能感的用户群体中表现更差。
### Innovation
提出了使用离线策略评估（OPE）来分析大规模语言模型的多轮健康辅导效果的方法，并通过一个隐藏的原型模拟器验证了在一个轻微加权的信息获取早期奖赏策略可以有效缩短特征识别时间并提高目标达成率和通过率。这项研究为个性化健康辅导发展提供了一种新的考虑和评估方式，即先固定生成器，然后在分类型的奖励上学习决策头，并始终报告每原型的指标以揭示平均值掩盖的用户群体危害。
### Conclusion
研究结果强调了一种评价优先的个性化路径：冻结生成器，利用类型化的奖励（目标工具结果和满意度）学习分组识知的决策头，并始终报告每原型的指标，以揭示平均值掩盖的用户群体危害。
## 234. `cs.AI` - 通过半监督置信分布学习实现不确定知识图谱完成 [PDF](https://arxiv.org/pdf/2510.16601), [HTML](https://arxiv.org/abs/2510.16601)
### Authors
Tianxing Wu,Shutong Zhu,Jingting Wang,Ning Xu,Guilin Qi,Haofen Wang
### Background
不确定知识图谱(UKGs)为每个三元组分配了一个置信度分数，以提供更精确的知识表示。然而，由于现实中的UKGs存在不完整性问题，UKG完成技术引起了更多关注，目标是填补缺失的三元组及其置信度。现有的研究试图通过学习UKG嵌入来解决这个问题，但它们忽略了三元组置信度的极大不平衡分布，导致学到的嵌入无法满足高质量UKG完成的需求。因此，本文旨在解决该问题，提出了一种新的半监督置信分布学习(ssCDL)方法，用于UKG完成。这种新方法通过关系学习同时使用标记数据（即已有置信度的三元组）和伪标签数据（即未见过的三元组及其生成的置信度），通过拟学习增加训练数据，使得三元组置信度分布更加平衡，从而引入更多的监督信息，强化嵌入学习过程，进而完成UKG的填补工作。
### Innovation
提出了一种新的半监督置信分布学习(ssCDL)方法，通过将每个三元组的置信度转换为置信度分布来增加监督信息，以增强嵌入学习过程，并通过关系学习将标记数据和伪标签数据结合起来，根据拟学习生成更多的三元组和置信度，以平衡三元组置信度的分布。实验结果表明，无论在何种评估指标上，ssCDL都优于现有的最先进的基准方法。
### Conclusion
半监督置信分布学习方法(ssCDL)在UKG完成任务中表现出色，能够有效地解决UKGs中的不完整性和不平衡置信度问题，提供了一种全新的实现方式，为后续相关研究提供了参考。
## 235. `cs.AI` - 向搜索环境中的Agentic Self-Learning LLMs迈进 [PDF](https://arxiv.org/pdf/2510.14253), [HTML](https://arxiv.org/abs/2510.14253)
### Authors
Wangtao Sun,Xiang Cheng,Jialin Fan,Yao Xu,Xing Yu,Shizhu He,Jun Zhao,Kang Liu
### Background
本文研究了自学习是否可以扩展基于LLM的代理，无需依赖于人类策划的数据集或预定义的规则奖励。通过在搜索代理设置下的受控实验，确定了两个关键的可扩展代理训练因素：奖励信号的来源以及代理任务数据的规模。研究发现，对于开放领域学习而言，生成奖励模型（GRM）的奖励优于严格的规则信号，并且与策略共同进化可以进一步提高性能。提高代理任务数据的量（即使这些数据是合成生成的）大大增强了代理的能力。这些见解促使提出了Agentic Self-Learning（ASL）框架，这是一个完全闭环、多角色的强化学习框架，在共享工具环境中将任务生成、策略执行和评估统一起来，并依赖LLM核心。ASL协调一个提示生成器、策略模型和生成奖励模型，形成更加困难的任务设定、更精确的验证和更强的解决的良性循环。实证结果显示，ASL持续且稳定地带来收益，超越了在饱和或下降的强RLVR基线（如Search-R1），并且在零标记数据条件下继续改进，表明ASL具有更优秀的样本效率和鲁棒性。进一步研究表明，GRM验证能力是主要瓶颈：冻结会引发奖励作弊并阻碍进步；在不断变化的数据分布上继续训练GRM可以缓解这一问题，并在后期阶段注入少量真实验证数据可以提高性能上限。这项研究确定了奖励来源和数据规模在开放领域代理学习中的关键杠杆作用，并证明了多角色共同进化在可扩展、自改进代理方面的有效性。论文的data和code位于https://www.example.com/path/to/data-and-code
### Innovation
1. 引入Agentic Self-Learning（ASL）框架，这是一个完全闭环、多角色的强化学习框架，统一任务生成、策略执行和评估，并依赖LLM核心，协调一个提示生成器、策略模型和生成奖励模型，形成良性循环。2. 通过在搜索代理设置下进行受控实验，确定了奖励信号来源和任务数据规模对于自学习代理可扩展性的关键作用。3. 提供了通过不断训练生成奖励模型来缓解冻结问题，从而促进自学习代理的持续进步。4. 证明多角色共同进化是构建自改进代理的有效策略，提升了在零标记数据条件下的性能。
### Conclusion
研究结果表明，Agentic Self-Learning能够有效地扩展基于LLM的自学习代理，无需依赖于人类策划的数据集或预定义的规则奖励，通过复杂的交互和训练机制改进了这些代理的能力。ASL框架证明了奖励来源和数据规模是面向开放领域代理学习的关键杠杆，并且多角色共同进化是构建可扩展、自我改进代理的有效途径。
## 236. `cs.AI` - 学习观看：机器人操控的基于视频的学习方法综述 [PDF](https://arxiv.org/pdf/2402.07127), [HTML](https://arxiv.org/abs/2402.07127)
### Authors
Chrisantus Eze,Christopher Crick
### Background
机器人学习操作技能受到多样化、无偏见数据集稀缺性的阻碍。虽然精心策划的数据集有所帮助，但仍存在泛化能力和实时转换方面的挑战。与此同时，大规模的“野生”视频数据集通过自我监督技术推动了计算机视觉的进步。将此应用于机器人领域，近期研究探讨了通过在线充裕视频源被动观看学习操作技能的方法，显示出良好效果。这种方法提供了可扩展的监督，同时降低了数据集偏差。
### Innovation
介绍了基于视频的学习方法，适用于机器人操控技能的学习。通过被动观看大规模人类视频数据，提高了机器人的泛化能力和样本效率。综述涵盖了视频特征表示学习技术、物体效用理解、3D手/体建模以及大规模机器人资源，以及从未控制的视频演示中获取机器人操控技能的新兴技术。
### Conclusion
该综述总结了基于视频的学习方法，分析了这些方法相对于标准数据集的优势、对标测试和基准测试，并讨论了该新兴领域的开放挑战和未来发展方向，该领域介于计算机视觉、自然语言处理和机器人学习之间。
## 237. `cs.AI` - 自然语言生成中的自动幻觉评估综述 [PDF](https://arxiv.org/pdf/2404.12041), [HTML](https://arxiv.org/abs/2404.12041)
### Authors
Siya Qi,Lin Gui,Yulan He,Zheng Yuan
### Background
大规模语言模型（LLMs）的迅速发展带来了一个紧迫的挑战：如何可靠地评估幻觉以保证模型的信任度。虽然自动幻觉评估（AHE）已成为这一努力不可或缺的部分，但由于方法论上的碎片化，该领域在概念清晰度和实际进展方面仍受到限制。
### Innovation
本文通过系统分析了105种评估方法，揭示了其中77.1%专门针对LLMs的方法，这一范式转变要求新的评估框架。本文提出了一个结构化的框架来组织领域，基于基础数据集和基准的调查以及评估方法的分类学来系统地记录从LLM前到LLM后的方法演变。此外还识别了当前方法的基本限制及其对实际部署的影响。
### Conclusion
为进一步研究，本文界定了关键挑战，并提出了战略方向，包括增强可解释性机制和结合特定应用的评估标准，最终提供了开发更稳健和实用的幻觉评估系统的路线图。
## 238. `cs.AI` - 可解释的图基推荐系统综述 [PDF](https://arxiv.org/pdf/2408.00166), [HTML](https://arxiv.org/abs/2408.00166)
### Authors
Thanet Markchom,Huizhi Liang,James Ferryman
### Background
随着推荐系统的广泛应用，用户对其信任和满意度成为关键，可解释性逐渐成为推荐系统的核心需求。已有基于图的数据结构的推荐系统能够提供更深层次的推荐关联性解释，因此可解释的图基推荐系统逐渐受到关注。
### Innovation
本文综述了当前先进的图基可解释推荐系统的方法，并按照学习方法、解释方法和解释类型三个维度进行了分类。同时，本文探讨了常用的评价数据集、可解释性评估方法以及该研究领域的未来方向，将视角集中在基于图的可解释性，填补了现有综述文献的空白。
### Conclusion
本文为开发新颖的图基可解释推荐系统需要掌握的关键主题提供了全面的综述，未来研究还需进一步探索更有效的解释方法和评估标准。
## 239. `cs.AI` - 使用FairVIC学习更公平的表示 [PDF](https://arxiv.org/pdf/2404.18134), [HTML](https://arxiv.org/abs/2404.18134)
### Authors
Charmaine Barker,Daniel Bethell,Dimitar Kazakov
### Background
自动决策系统的偏见缓解，特别是在深度学习模型中，是一个关键挑战，由于公平性的多维定义、数据集特有的偏见以及公平性和准确性之间的固有权衡。现有方法依赖于预定义的公平性标准，这可能导致对保护性特征的高度依赖。FairVIC通过在训练期间将方差、不变性和协方差项整合到损失函数中，提供了一种增强神经网络公平性的新方法，减轻了这些挑战。
### Innovation
FairVIC通过整合方差、不变性和协方差项到损失函数中，提供了一种新颖的方法来增强神经网络的公平性，而不依赖于预定义的公平性标准。这种方法能够更抽象地表示公平性概念，降低对保护性特征的依赖。FairVIC在基准数据集上进行评估，考虑了群体公平性和个体公平性，并进行了准确性和公平性权衡的消融研究，结果显示在所有测试指标上公平性显著提高（约70%），同时没有牺牲准确性。
### Conclusion
FairVIC提供了一种稳健且具有普适性的解决方案，用于解决不同任务和数据集中的公平性问题，无需对准确性做出牺牲。
## 240. `cs.AI` - 探索大规模语言模型在代码生成中的高效适应 [PDF](https://arxiv.org/pdf/2403.00046), [HTML](https://arxiv.org/abs/2403.00046)
### Authors
Xue Jiang,Yihong Dong,Zhiyuan Fan,Zhi Jin,Wenpin Jiao,Ge Li
### Background
尽管大规模语言模型（LLMs）已经在代码生成方面取得了显著进步，但在特定场景下的代码生成任务上仍存在问题。这些场景通常要求对LLMs进行特定适应以满足特定需求，但由于实际可用的训练数据有限，导致其代码生成性能不佳。因此，如何在少量训练数据的情况下有效适应LLMs于新场景成为当前代码生成的一大挑战。
### Innovation
本文提出了一种名为DEED的新适应方法，即Data-Efficient adaptation with Error-Driven learning for code generation。该方法利用LLMs所犯的错误作为学习机会，通过错误修订来克服自身的不足，从而实现高效学习。DEED包括识别LLMs生成的错误代码，使用Self-Revise进行代码修订，用修订后的代码优化模型，并迭代适应以持续改进。实验结果表明，与主流的微调方法相比，DEED在多个代码生成基准上的Pass@1表现得到了大幅提高，平均相对提升达到了46.2%。此外，Self-Revise的有效性也被验证，它能够更高效地优化模型，而非数据集中的代码样本。此外，DEED在多种LLMs上表现一致性强，表明其适用性广。
### Conclusion
实验结果表明，DEED在少量训练数据的情况下，相比其他主流微调方法，达到了更好的性能。DEED的有效性和Applicability得到了验证，并且表明了其在各种LLMs上的强健表现。
## 241. `cs.AI` - BlockScan: 在区块链交易中检测异常 [PDF](https://arxiv.org/pdf/2410.04039), [HTML](https://arxiv.org/abs/2410.04039)
### Authors
Jiahao Yu,Xian Wu,Hao Liu,Wenbo Guo,Xinyu Xing
### Background
现有的区块链交易异常检测方法要么依赖于基于规则的系统，要么直接使用现成的大语言模型。这些方法在处理区块链交易的复杂结构时存在局限性。BlockScan针对这一问题提出了一个定制化的Transformer，旨在有效建模区块链交易的独特数据结构，解决现有方法的不足之处。
### Innovation
BlockScan引入了一系列定制化的设计，包括新型模块化分词器、定制化的掩码语言建模机制及RoPE嵌入和FlashAttention用于处理长序列等。此外，基于模型输出，BlockScan还设计了一种新的异常检测方法，并对检测方法进行了理论分析。该工作为基于Transformer的方法在区块链数据分析中的应用树立了新的基准，特别是在检测Solana交易中的异常方面表现出色。
### Conclusion
BlockScan在以太坊和Solana交易中的广泛评估表明，其在异常检测方面具备卓越的能力，同时保持了较低的误报率。特别是，在处理Solana交易的异常检测时，BlockScan是唯一一个能够高精度检测异常交易的方法，而其他所有方法的检测召回率都非常低或为零。
## 242. `cs.AI` - PokeeResearch：通过AI反馈强化学习和稳健推理架构实现有效的深度研究 [PDF](https://arxiv.org/pdf/2510.15862), [HTML](https://arxiv.org/abs/2510.15862)
### Authors
Yi Wan,Jiuqi Wang,Liam Li,Jinsong Liu,Ruihao Zhu,Zheqing Zhu
### Background
当前的工具增强的大语言模型（LLMs）作为深度研究代理正逐渐兴起，能够分解复杂查询、检索外部证据并综合生成依据充足的回复。然而，现有的代理仍然受限于浅层的信息检索、弱对齐指标以及脆弱的工具使用行为。
### Innovation
提出了PokeeResearch-7B，这是一种基于一致强化学习框架、用于增强鲁棒性、对齐和扩展性的7B参数深度研究代理。PokeeResearch-7B通过无注释的AI反馈强化学习（RLAIF）框架进行训练，优化以LLM为基础的奖励信号，这些信号能够捕捉事实准确性、引用忠实度和指令遵从性。一种基于链式思维的多轮推理支架进一步增强了代理的鲁棒性，通过自我验证和适应性恢复工具失败，提高了代理的整体性能。PokeeResearch-7B在10个流行的深度研究基准测试中取得了同类最优性能，显示出精心设计的强化学习和推理能够产出高效的、 robust的和研究级别的AI代理的能力。
### Conclusion
结果显示，经过精心设计的强化学习和推理机制能够产生高效、鲁棒且适用于研究的AI代理。PokeeResearch-7B模型及推理代码已开源，遵循Apache 2.0许可协议。
## 243. `cs.AI` - 当文本嵌入遇到大型语言模型：综述 [PDF](https://arxiv.org/pdf/2412.09165), [HTML](https://arxiv.org/abs/2412.09165)
### Authors
Zhijie Nie,Zhangchi Feng,Mingxin Li,Cunwang Zhang,Yanzhao Zhang,Dingkun Long,Richong Zhang
### Background
文本嵌入已成为深度学习时代的自然语言处理（NLP）领域的基础技术，为众多下游任务的进步提供了动力。尽管许多自然语言理解挑战现在可以使用生成范式建模并利用大型语言模型（LLMs）的生成和理解能力，但诸如语义匹配、聚类和信息检索等诸多实际应用仍然依赖于文本嵌入以保持其效率和有效性。因此，将LLMs与文本嵌入相结合已成为近年来的研究重点。
### Innovation
本文通过按照交互模式而非具体的下游应用进行组织，提供了一个新颖而系统的LLMs时代的综述。还强调了在LLMs时代之前，预训练语言模型（PLMs）所面临的未解决挑战，并探讨了由LLMs带来的新兴障碍。进一步概述了文本嵌入演化的潜在方向，解决了NLP迅速发展的背景下理论和实践机会的问题。
### Conclusion
本文为研究和应用领域提供了关于预训练语言模型时代贡献的非传统且系统的概述，并描绘了文本嵌入未来发展的前景，以应对不断发展的NLP领域中的理论与实践机会。
## 244. `cs.AI` - FALCON: 细粒度激活对比正交不对齐的大型语言模型高效遗忘方法 [PDF](https://arxiv.org/pdf/2502.01472), [HTML](https://arxiv.org/abs/2502.01472)
### Authors
Jinwei Hu,Zhenglin Huang,Xiangyu Yin,Wenjie Ruan,Guangliang Cheng,Yi Dong,Xiaowei Huang
### Background
大型语言模型虽然被广泛应用，但可能无意间编码敏感或有害信息，引发安全问题。机器遗忘技术已经出现以缓解这一问题；然而，现有的训练时遗忘方法依赖粗粒度的损失组合，难以准确区分知识并平衡遗忘效果与模型实用性。
### Innovation
我们提出了细粒度激活操控对比正交不对齐（FALCON），这是一种新的基于表示的遗忘方法，利用信息论指导高效参数选择，采用了对比机制增强表示分离，并将冲突梯度投影到正交子空间来解决遗忘与保留目标之间的冲突。FALCON在保持模型实用性的同时，表现出优越的遗忘效果，并对知识恢复具有强大的抵抗力。
### Conclusion
实验结果表明，FALCON在保持模型实用性的前提下，实现了优越的遗忘效果，同时对知识恢复具有机制的抵抗力。
## 245. `cs.AI` - LLM 安全对齐实际上是一种隐性的差异估计 [PDF](https://arxiv.org/pdf/2502.00657), [HTML](https://arxiv.org/abs/2502.00657)
### Authors
Rajdeep Haldar,Ziyi Wang,Qifan Song,Guang Lin,Yue Xing
### Background
该论文基于现有的LLM（大型语言模型）对齐方法，特别是包括RLHF（基于奖励的强化学习人类反馈）及其变体。这些方法被广泛认为可以实现模型的安全或偏好对齐。然而，该论文试图从一个新的角度，即差异估计的角度来解读这些对齐方法的效果。这有助于理解在对齐过程中，安全和有害提示在潜在空间中分离的机制。
### Innovation
提出了一种新的KL DO（基于KL散度的对齐方法），它利用KL散度作为对齐的手段，并通过实验验证了其有效性。此外，提出使用遵守和拒绝的数据集而非标准的偏好数据集可以产生更明显的分离，并改善安全性对齐。最后，提出了基于距离的度量来量化这种分离效果，并且该度量也可以作为模型安全的统计显著指标。
### Conclusion
该论文表明，流行的LLM对齐方法实际上可以被视为安全或偏好分布与有害或不太偏好分布之间的差异估计器。基于该理论视角，KLDO作为一种新的对齐方法被提出并通过实验验证了其有效性和安全性。该研究强调了使用特定类型的数据集对提升模型安全性的意义，同时也提供了一个度量分离效果的新工具。
## 246. `cs.AI` - 发育设计范式的理论基础：集成连续学习、推理行为和可解释性 [PDF](https://arxiv.org/pdf/2502.13935), [HTML](https://arxiv.org/abs/2502.13935)
### Authors
Zeki Doruk Erden,Boi Faltings
### Background
当代机器学习系统的固有局限性，特别是在连续学习、信息重用、可理解性以及与有意行为的集成方面，正逐渐受到关注。这些局限性导致了系统性能上的限制，亟需一种新的解决方案。
### Innovation
本文介绍了一种基于发育生物学原理的新型学习方法，旨在克服当前机器学习方法中的关键限制。设计包括三个核心组件：一个无梯度的学习机制（Modeller），具有连续学习和结构自适应能力；一个计划器，用于对未来导向的行为进行预测；以及一个行为封装机制，能够将复杂行为分解为层级结构。
### Conclusion
该框架在简单测试环境中展示了原理性的操作，并在高维网络结构的空间中扩展了建模框架，使用MNIST数据集进行形状检测任务，表明该框架能够在有机的方式下同时解决多种现代机器学习系统的主要局限性。
## 247. `cs.AI` - 基于大型语言模型的软件测试挑战：一种面向对象的分类法 [PDF](https://arxiv.org/pdf/2503.00481), [HTML](https://arxiv.org/abs/2503.00481)
### Authors
Felix Dobslaw,Robert Feldt,Juyeon Yoon,Shin Yoo
### Background
大型语言模型（LLMs）和多代理LLM（MALLMs）引入了不同于传统或机器学习软件的非确定性。因此，需要超出简单输出比较或测试数据集上的统计准确性的新方法来验证正确性。当前的工具通常将测试执行视为孤立事件，缺乏明确的聚合机制，无法有效地捕捉模型版本、配置和重复运行之间的变化性。
### Innovation
本文提出了LLM测试案例设计的分类法，该分类法基于研究文献和个人经验。此分类法定义了四个方面，解决了输入和输出的模糊性，并建立了最佳实践。分类法区分了目标变异性、被测系统和输入的变异性，并引入了两种关键的先验类型：原子和聚合。
### Conclusion
现有工具未能充分处理多样性，强调将正确性视为结果分布而不是二元属性的重要性，这一点需要学术界和从业人员之间更紧密的合作，以建立成熟和支持多样性的测试方法。
## 248. `cs.AI` - 利用贝叶斯网络在因果结构学习中缓解先验错误：一种鲁棒方法 [PDF](https://arxiv.org/pdf/2306.07032), [HTML](https://arxiv.org/abs/2306.07032)
### Authors
Lyuzhou Chen,Taiyu Ban,Xiangyu Wang,Derui Lyu,Huanhuan Chen
### Background
因果结构学习（Causal Structure Learning, CSL）是一种通过贝叶斯网络（Bayesian Networks, BNs）编码变量间因果关系的技术。尽管仅从数据中恢复因果结构是一个挑战，但如果结合先验知识，可以显著提升学习的质量。当前基于先验知识的方法对先验中的错误较为脆弱，硬约束方法完全忽略先验，而软约束方法则是基于预设的信心水平接受先验，这可能需要专家干预。
### Innovation
提出了一种针对边缘级先验错误具有鲁棒性的CSL策略，旨在减少人类干预。通过分类先验错误并探讨其对结构汉明距离（Structural Hamming Distance, SHD）的影响，反驳了强先验错误与一种特殊的有向无环图结构“拟环”相关的发现，并提出了一种后处理策略，通过识别“拟环”的增量来发现先验错误的影响。
### Conclusion
通过在现实和合成数据集上的实证评估，展示了该策略在对抗先验错误方面的稳健性，特别是对顺序反转错误具有显著的抵抗能力，同时保持了大多数先验的正确性。
## 249. `cs.AI` - VLLFL: 一种基于视觉语言模型的轻量级联邦学习框架以实现智能农业 [PDF](https://arxiv.org/pdf/2504.13365), [HTML](https://arxiv.org/abs/2504.13365)
### Authors
Long Li,Jiajia Li,Dong Chen,Lina Pu,Haibo Yao,Yanbo Huang
### Background
在现代智能农业中，物体检测通过实现自动化、精准农业和资源监测起着关键作用。它能够识别作物健康状况和害虫侵扰，并优化收获过程，从而提高生产和可持续性。但是，训练物体检测模型通常需要大规模数据采集，当敏感的农业数据分布在各个农场时，这还会引发隐私问题。因此，本文旨在解决这些问题，提出了一种基于视觉语言模型的轻量级联邦学习框架（VLLFL），以实现智能农业中的高效隐私保护。
### Innovation
提出的VLLFL框架结合了视觉语言模型（VLM）的泛化能力和上下文感知检测能力，并利用联邦学习的隐私保护特性。VLLFL通过训练一个紧凑的提示生成器来提升部署在不同农场的VLM性能，从而在保证隐私的同时，减少通信开销。实验结果显示，与传统方法相比，该方法在保持模型性能的同时，通信开销降低了99.3%。该框架覆盖了从识别各种水果到检测农业有害动物等多种任务，提供了一种专门针对农业应用的高效、可扩展且隐私保护的解决方案。
### Conclusion
VLLFL框架通过结合VLM和联邦学习，解决了农业数据隐私问题，同时保持了高性能，这为智能农业的自动化和精确管理提供了有效的解决方案，具有广泛的应用前景。
## 250. `cs.AI` - 手掌识别中的深度学习-全面综述 [PDF](https://arxiv.org/pdf/2501.01166), [HTML](https://arxiv.org/abs/2501.01166)
### Authors
Chengrui Gao,Ziyuan Yang,Wei Jia,Lu Leng,Bob Zhang,Andrew Beng Jin Teoh
### Background
随着手掌识别生物特征技术的发展，它在各种场景中得到了广泛应用。传统的手工程方法在手掌识别中往往难以表现良好，因为它们严重依赖研究人员的经验知识。深度学习(DL)技术因其在其他领域取得的成功而被引入，以解决这一限制。然而，现有的综述文章往往局限于具体的手掌识别任务，而缺乏全面研究DL在手掌识别各个方面的应用。
### Innovation
本文填补了这一空白，全面回顾了DL增强的手掌识别最新进展。研究系统地检查了手掌识别中的关键任务进展，包括感兴趣区域分割、特征提取以及安全性/隐私相关挑战。同时，本文还指出了当前的挑战，并揭示了未来研究的潜力。
### Conclusion
通过汇总最新的进展，该研究为研究人员提供了一项有价值的资源，使他们能够了解最新的技术进展并推动手掌识别领域的创新。
## 251. `cs.AI` - 能量匹配：通过流匹配和能量基础模型统一生成模型 [PDF](https://arxiv.org/pdf/2504.10612), [HTML](https://arxiv.org/abs/2504.10612)
### Authors
Michal Balcerak,Tamaz Amiranashvili,Antonio Terpin,Suprosanna Shit,Lea Bogensperger,Sebastian Kaltenbach,Petros Koumoutsakos,Bjoern Menze
### Background
当前最先进的生成模型通过匹配流或分数将噪声映射到数据分布。这些模型的一个关键限制是无法直接整合可用的部分观察和额外的先验知识。相比之下，能量基础模型（EBMs）通过引入相应的标量能量项来解决这个问题。
### Innovation
我们提出了一种能量匹配框架，将基于流的方法与EBMs的灵活性结合起来。在远离数据流形的情况下，样本从噪声到数据沿无旋最佳输运路径移动。当接近数据流形时，一个熵能量项引导系统进入玻尔兹曼平衡分布，显式地捕捉数据的底层似然结构。这种方法通过一个单一时不变标量场参数化这些动力学，作为强大的生成器和灵活的先验，有效正则化逆问题。与现有的EBMs相比，该方法在CIFAR-10和ImageNet生成中的保真度表现更佳，同时保留了基于输运的方法的无模拟训练。
### Conclusion
我们利用该方法的灵活性引入了一种互动能量，支持多样模式的探索，并在受控的蛋白质生成设置中进行验证。这种方法学习一个标量势能，无需时间条件、辅助生成器或另外的网络，标志着与最近的EBM方法相比的一个重要转变。我们认为这种简化但严格的表述显著推进了EBMs的能力，并为EBMs在生成建模中的广泛应用铺平了道路。
## 252. `cs.AI` - 扩散磁共振成像纤维束跟踪中白质形状预测的多模态深度学习方法 [PDF](https://arxiv.org/pdf/2504.18400), [HTML](https://arxiv.org/abs/2504.18400)
### Authors
Yui Lo,Yuqian Chen,Dongnan Liu,Leo Zekelman,Jarrett Rushmore,Yogesh Rathi,Nikos Makris,Alexandra J. Golby,Fan Zhang,Weidong Cai,Lauren J. O'Donnell
### Background
随着白质纤维束成像的数据分析技术的发展，形状度量已经成为了很有前景的描述符，可以提供有关解剖变异性和认知以及临床表型之间关联的补充见解。然而，由于依赖于体素表示，传统的形状度量计算方法在大规模数据集上非常昂贵且耗时。
### Innovation
提出了一种新颖的多模态深度学习框架Tract2Shape，它利用几何（点云）和标量（表格）特征来预测白质纤维束成像中的十个形状度量。为了提高模型效率，使用降维算法预测五个主要的形状组成。该模型在HCP-YA数据集和PPMI数据集上分别进行了训练和评估，并且与最先进的模型进行了性能比较。实验结果表明，Tract2Shape在所有十个形状度量上的性能均优于最先进的深度学习模型。进一步评估了其鲁棒性和泛化能力。
### Conclusion
Tract2Shape能够实现白质形状度量从成像数据的快速、准确且可扩展的预测，支持大规模数据集的分析。该框架为未来的大规模白质形状分析奠定了有前景的基础。
## 253. `cs.AI` - α-混合性质在随机迭代中的转移及其在队列理论中的应用 [PDF](https://arxiv.org/pdf/2410.05056), [HTML](https://arxiv.org/abs/2410.05056)
### Authors
Attila Lovas
### Background
非线性时间序列模型在计量经济学、排队理论和机器学习中至关重要，但其统计分析尚不完整。已知一些关于弱相关变量的关键结果，如大数定律和函数中心极限定理。本文通过耦合论据，展示了外生回归因子的混合性质向响应变量的转移，并进一步研究了在非稳定环境下具有有利混合性质的随机环境中的马尔可夫链。
### Innovation
提出了通过耦合方法将外生回归因子的混合性质转移至响应变量的方法；研究了在具有非稳定环境的随机环境中，并在有利的混合性质条件下，马尔可夫链的性质；应用该框架到单服务站排队模型。
### Conclusion
通过转移α-混合性质和分析马尔可夫链在随机环境中的行为，本文为非线性时间序列模型提供了新的理论支持，并应用于排队模型中。
## 254. `cs.AI` - 医疗图像翻译，回归即可 [PDF](https://arxiv.org/pdf/2505.02048), [HTML](https://arxiv.org/abs/2505.02048)
### Authors
Sebastian Rassmann,David Kügler,Christian Ewert,Martin Reuter
### Background
生成对抗网络（GANs）和扩散模型（DMs）在自然图像生成方面取得了显著成果，但它们的优势——创造力和逼真度，在医疗应用中却可能带来不利影响，因为医疗应用要求高度的准确性和保真度。这些模型可能引入幻觉，复制不必要的采集噪声，这对医疗应用造成了挑战。因此，本文提出了一种名为YODA（You Only Denoise once - or Average）的2.5D扩散框架用于医疗图像翻译（MIT），旨在解决这一问题。
### Innovation
本文提出了YODA框架，这是一种2.5D扩散模型，用于医疗图像翻译。YODA通过对多个样本进行抽样并平均来减少噪声的复制，这一过程被称为期望近似（ExpA）抽样。此外，还提出了回归抽样YODA，通过一次步骤生成无噪声图像，而不需要迭代修正。实验结果表明，回归抽样不仅效率更高，而且在某些情况下甚至可以与完整的扩散抽样方法竞争。
### Conclusion
YODA在五个不同的多模态数据集上展示了其优势，不仅在效率上超过了现有的先进扩散模型和GANs，在图像质量上也有优异表现。本文的结果表明，迭代修正并不会提升信息的翻译，而仅会增加感知的真实感。此外，YODA翻译的图像在一些医疗应用中甚至优于物理采集的图像。
## 255. `cs.AI` - VITA-Audio: 快速交错多模态令牌生成以实现高效的大型语音语言模型 [PDF](https://arxiv.org/pdf/2505.03739), [HTML](https://arxiv.org/abs/2505.03739)
### Authors
Zuwei Long,Yunhang Shen,Chaoyou Fu,Heting Gao,Lijiang Li,Peixian Chen,Mengdan Zhang,Hang Shao,Jian Li,Jinlong Peng,Haoyu Cao,Ke Li,Rongrong Ji,Xing Sun
### Background
随着对自然人机交互的需求增长，基于语音的系统因其易于日常交流的优势受到越来越多的关注。然而，现有的语音模型在生成流式数据的第一个音频令牌时仍然存在较高的延迟，这严重影响了实际部署的效果。
### Innovation
本文提出了一种端到端的大型语音模型VITA-Audio，该模型能快速生成音频文本令牌。通过引入一种轻量级的多模式令牌预测(MCTP)模块，在单个前向传播过程中高效生成多个音频令牌，从而加速推理过程并显著降低流式场景下生成第一个音频的延迟。此外，还探索了一种四阶段的渐进式训练策略，以实现模型加速同时保持高质量的语音效果。VITA-Audio是首个在单次前向传播过程中能生成音频输出的多模态大型语言模型，具备实时对话能力。
### Conclusion
在7B参数规模下，实验结果显示，我们的模型实现了推理速度3~5倍的提升，且在自动语音识别(ASR)、文本转语音(TTS)和口语问答(SQA)任务的多个基准测试中显著优于同类开源模型。
## 256. `cs.AI` - 不损失速度地改变基底：DNNs中GPU高效的MatMul替代方案 [PDF](https://arxiv.org/pdf/2503.12211), [HTML](https://arxiv.org/abs/2503.12211)
### Authors
Nir Ailon,Akhiad Bercovich,Yahel Uffenheimer,Omri Weinstein
### Background
现代AI依赖于大量的矩阵乘法（MatMuls），这些计算对其推理和训练的可扩展性提出了问题。本文提出了一种新的替代方案，即适用于GPU的基于双线性操作的算子，与矩阵乘法相比，它在速度、准确性和参数数量之间提供三方面的权衡。这种算子在评估时需要更少的浮点运算次数，并且相对矩阵乘法而言，其参数数量更多。本文称为Strassen-Tile（STL）操作符。STL的核心理念是在权重和激活矩阵的块上应用局部可学习的变换基底，然后通过块之间的元素乘积实现，采用矩阵乘法同时实施的方法。研究的关键技术问题是如何优化特定层的变换基底，这是一个高度非凸问题。理论支持的初始值（受快速矩阵和多项式乘法启发）比随机SGD初始化具有更好的准确性，这激发了进一步对该操作优化的研究。实验证明，STL可以以2.66倍的浮点运算次数，逼近4x4矩阵块的点积，同时还可以提升参数量为4.3M的SoTA T2T-ViT-7在ImageNet-1K上的准确性，即使使用未经优化的PyTorch代码，STL在计算受限区域也实现了钟点速度上的提升。
### Innovation
本文提出了一个GPU原生的STL（Strassen-Tile）操作符，其可以在保持准确性的前提下，减少浮点运算次数，并通过局部可学习的变换基底优化来实现性能提升。STL首次提出了理论支持的初始化方法，证明了其在性能上的优势
### Conclusion
STL操作符能够在保持准确性的同时减少浮点运算次数，并且即使在未经优化的PyTorch实现中，也能够在计算受限的区域实现性能改进。这为构建具备可扩展性和成本效益的AI架构提供了有前景的构建模块。
## 257. `cs.AI` - 使用多门铁电场效应晶体管的树突计算 [PDF](https://arxiv.org/pdf/2505.01635), [HTML](https://arxiv.org/abs/2505.01635)
### Authors
A N M Nafiul Islam,Xuezhong Niu,Jiahui Duan,Shubham Kumar,Kai Ni,Abhronil Sengupta
### Background
尽管受大脑神经元系统的启发，人工神经网络通常使用点神经元，其计算复杂性远低于生物神经元。生物神经元具有树突棘突，连接到不同的突触集合，并提供局部非线性累积，这对于处理和学习至关重要。为了模拟树突的功能，我们提出了一种基于多门铁电场效应晶体管的新型神经元设计，利用铁电非线性在树突分支内进行局部计算，并通过场效应晶体管动作生成最终神经元输出。这种分枝架构为利用更小的行交叉阵列进行硬件集成提供了可能，提高了效率。通过实验校准的器件-电路-算法协同仿真框架，我们展示了集成我们提出的树突神经元的网络比没有树突的大得多的网络（$thicksim$17$times$更少的可训练权重参数）在性能上更优越。这些发现表明，树突硬件可以大大提高针对边缘应用场景优化的神经形态系统的计算效率和学习能力。
### Innovation
我们提出了一种基于多门铁电场效应晶体管的新型神经元设计，这种设计不仅能够在树突分支内进行局部计算，还能通过场效应晶体管动作生成最终的神经元输出。这种方法为利用更小的行交叉阵列进行硬件集成提供了可能，从而提高了效率，并通过实验校准的器件-电路-算法协同仿真框架验证了其优越性。
### Conclusion
这个研究提出了一种新的神经元设计，可以显著提高神经形态系统的计算效率和学习能力。这种方法利用了铁电材料和场效应晶体管的特性，能够模拟生物神经元的复杂功能，同时简化了硬件设计，使得在硬件集成中更为高效。这些模拟结果证实了新设计的有效性和优越性。
## 258. `cs.AI` - 通过周期编码实现LLMs的长时间跨度时间表示的时间对齐 [PDF](https://arxiv.org/pdf/2503.04150), [HTML](https://arxiv.org/abs/2503.04150)
### Authors
Xue Han,Qian Hu,Yitong Wang,Wenchun Gao,Lianlian Zhang,Qing Wang,Lijun Mei,Chao Deng,Junlan Feng
### Background
大语言模型（LLMs）在长时间段上存在时间失准的问题。这一问题是由于LLMs在大量数据训练过程中，长期时间内的时空信息较为稀疏，尤其是在成千上万年的尺度上，这导致了不足的学习或灾难性遗忘。本文探讨了LLMs在长时段上的时间失准问题，并提出了一种名为“Ticktack”的方法来解决这一问题。
### Innovation
提出了一种名为“Ticktack”的方法，以解决LLMs在长期时间跨度上的时间失准问题。该方法首先使用了六十天干地支纪年法代替LLMs常用的公历纪年法，从而在年份粒度上实现了更均匀的分布。然后，利用极坐标表示六十年周期和每个周期内的年份顺序，并加上额外的时间编码以确保LLMs理解这些结构。最后，提供了一种后训练时间表示重构方法，以有效地区分具有相关知识的时间点，从而改善长期内的时间相关任务性能。
### Conclusion
本文提出了一种新的方法“Ticktack”，以解决LLMs在长期时间跨度上的时间失准问题。通过使用六十天干地支纪年法和极坐标表示，以及时间表示重构方法，有效提升了长期内的时间相关任务性能。此外，还构建了一个长期时间跨度基准用于评估。实验证明了该提案的有效性。
## 259. `cs.AI` - 如何通过梯度下降学习上下文相关任务？最优性、训练动力学与泛化 [PDF](https://arxiv.org/pdf/2505.15009), [HTML](https://arxiv.org/abs/2505.15009)
### Authors
Quan Nguyen,Thanh Nguyen-Tang
### Background
目前的研究仅关注经过单步梯度下降训练后变压器在上下文推理方面的表现，对于经过多次梯度下降训练的收敛过程及其速率尚未明晰，同时也未正式研究单步上下文推理的泛化能力。
### Innovation
本研究证明了一个包含线性、ReLU或softmax注意机制的变压器类可以在上下文相关任务中达到贝叶斯最优。进一步地，通过有限样本分析证明，经过梯度下降训练后，损失函数以线性速率收敛于贝叶斯风险。此外，还展示了训练好的变压器能够在分布外样本上泛化。理论发现得到了详细的实验证据支持，特别是关于变压器在未经适当参数化时更强大的表达能力反而会导致分布外泛化的失败。
### Conclusion
本研究解决了现有理论中存在的明显不足，通过实验证明，仅通过梯度下降训练，强大表达能力的模型在分布外样本上可能无法泛化。
## 260. `cs.AI` - AI政策研究中预印本趋势的转变：美国、欧洲和韩国的比较研究 [PDF](https://arxiv.org/pdf/2505.03835), [HTML](https://arxiv.org/abs/2505.03835)
### Authors
Simon Suh
### Background
人工智能（AI）政策研究的全球分发方式迅速发生了变化，这主要是由于开放科学的采用。本文研究了2015年至2024年期间，预印本引用的区域趋势，特别关注COVID-19大流行和ChatGPT的发布这两个重大颠覆性事件对美国、欧洲和韩国AI政策研究传播模式的影响。
### Innovation
使用Web of Science的引文数据，本文追踪了全球颠覆性事件如何影响AI政策研究中预印本的采用，以及这种变化如何因地区而异。研究表明，尽管所有地区都经历了一定程度的预印本引用增长，但增长的幅度和趋势因地区而异。美国经历了事件驱动的增长；欧洲表现出机构增长；而韩国则保持了稳定的线性增长。这些发现表明，全球颠覆可能加速了预印本的采用，但其程度和模式由当地的科研文化、政策环境和开放科学成熟度所塑造。
### Conclusion
全球颠覆可能加速了预印本的采用，但其程度和模式因地区而异。未来AI治理策略应在考虑研究传播的区域差异方面有所考量，并进一步进行纵向和比较研究以加深对AI政策发展的开放获取采用的理解。
## 261. `cs.AI` - 使用gSMILE解释大型语言模型 [PDF](https://arxiv.org/pdf/2505.21657), [HTML](https://arxiv.org/abs/2505.21657)
### Authors
Zeinab Dehghani,Mohammed Naveed Akram,Koorosh Aslansefat,Adil Khan,Yiannis Papadopoulos
### Background
大型语言模型（LLMs）如GPT、LLaMA和Claude在文本生成方面表现出色，但在决策过程方面仍不透明，限制了它们在高风险应用场景中的信任和问责性。
### Innovation
提出了一种通用的扰动基解释框架gSMILE，该框架在LLMs中实现基于令牌的可解释性。gSMILE利用受控的提示扰动、Wasserstein距离度量和加权线性代理来识别对输出影响最大的输入令牌，该过程生成直观的热图，以可视化突出显示关键令牌和推理路径。
### Conclusion
gSMILE在多个指标上提供了可靠的人类对齐的归因，包括注意力一致性、输出一致性等，展示了它能够平衡模型性能和可解释性的能力，从而使AI系统更加透明和可信。
## 262. `cs.AI` - 通过进化调度进行多智能体协作 [PDF](https://arxiv.org/pdf/2505.19591), [HTML](https://arxiv.org/abs/2505.19591)
### Authors
Yufan Dang,Chen Qian,Xueheng Luo,Jingru Fan,Zihao Xie,Ruijie Shi,Weize Chen,Cheng Yang,Xiaoyin Che,Ye Tian,Xuantang Xiong,Lei Han,Zhiyuan Liu,Maosong Sun
### Background
大型语言模型（LLMs）在多种下游任务中取得了显著成果，但由于单一整体的结构限制了其在复杂问题解决中的可扩展性和效率。尽管最近的研究探索了LLMs之间的多智能体协作，但大多数方法依赖于静态组织结构，这些结构在面对任务复杂度和智能体数量增长时难以进行调整，因此产生了协调难题和低效性。
### Innovation
本文提出了一种“操纵者”模式的LLM基于多智能体协作方法，其中中央调度员（“操纵者”）动态指导智能体（“木偶”）响应不断变化的任务状态。该调度员通过强化学习训练，以适应性地排列和优先处理智能体，实现灵活可进化的集体推理。实验结果表明，该方法在保持较低计算成本的同时实现了更优的性能。进一步的分析表明，这些改进的关键因素来自于调度员演变过程中产生的更为紧凑和循环的推理结构。
### Conclusion
实验结果表明，通过这种方法可以实现高性能并且具有较低的计算成本。进一步的分析显示，结果的提升主要归因于调度器进化过程中形成的更为紧凑和循环的推理结构。本文的代码可在以下链接获取。
## 263. `cs.AI` - 从非对齐到对齐：使用多方平行语料库扩展多语言LLMs [PDF](https://arxiv.org/pdf/2505.14045), [HTML](https://arxiv.org/abs/2505.14045)
### Authors
Yingli Shen,Wen Lai,Shuo Wang,Ge Gao,Kangyang Luo,Alexander Fraser,Maosong Sun
### Background
持续预训练和指令调优在大规模多语言数据上已经被证明能够有效扩展大型语言模型（LLMs）到低资源语言。然而，此类数据的未对齐特性限制了其在捕捉跨语言语义方面的效果。相比之下，多方平行数据，即多种语言中相同内容的对齐，提供了更强的跨语言一致性，并为多语言性能的提升提供了更大的潜力。
### Innovation
本研究引入了一个基于TED Talks的大规模、高质量多方平行语料库TED2025，涵盖了113种语言，多达50种语言可以进行平行对齐，确保了广泛的多语言覆盖。通过这个数据集，研究探讨了利用多方平行数据增强LLMs的最佳实践，包括持续预训练、指令调优和关键影响因素的分析策略。实验结果显示，使用多方平行数据训练的模型在六个多语言基准测试上表现优于使用未对齐多语言数据训练的模型。
### Conclusion
研究使用TED2025数据集，验证了多方平行数据在改进LLMs多语言性能上的效果，提出了针对LLMs的多方平行数据使用的最佳实践，并展示了多方平行数据在多语言模型训练中的优越性。
## 264. `cs.AI` - MetaBox-v2: 一种统一的元黑盒优化基准平台 [PDF](https://arxiv.org/pdf/2505.17745), [HTML](https://arxiv.org/abs/2505.17745)
### Authors
Zeyuan Ma,Yue-Jiao Gong,Hongshu Guo,Wenjie Qiu,Sijie Ma,Hongqiao Lian,Jiajun Zhan,Kaixu Chen,Chen Wang,Zhiyang Huang,Zechuan Huang,Guojun Peng,Ran Cheng,Yining Ma
### Background
元黑盒优化（Meta-Black-Box Optimization, MetaBBO）通过元学习简化了优化算法设计的自动化。MetaBBO 通常采用双层结构：在元层上，策略通过元训练减少开发用于低层优化任务的算法所需的动手工作量。早期的MetaBox框架（2023）提供了基于强化学习的单目标元黑盒优化的第一个开源框架，但其相对狭窄的范围已无法满足这一领域的迅速发展。因此，需要一个更新且功能更全面的平台来更好地支持这一领域的研究和应用.
### Innovation
MetaBox-v2 是一个重要的升级版本，具有以下创新点：1）支持基于强化学习、进化和梯度的方法的统一架构，总共再现了23个最新的基准；2）高效的并行化方案，将培训/测试时间降低了10-40倍；3）涵盖了单目标、多目标、多模型和多任务优化场景的广泛基准套件，包括18个合成或实际任务，共计1900+个实例；4）丰富的可扩展接口，支持自定义分析/可视化和与外部优化工具/基准的集成。通过进行系统的案例研究，MetaBox-v2 对内置的基线在优化性能、泛化能力和学习效率方面进行了评估，并提供了从详细分析得出的有价值见解.
### Conclusion
MetaBox-v2 为从业者和新进入者提供了宝贵的洞见，展示了其在元黑盒优化领域中的实用价值。通过这个平台，研究人员和工程师可以更有效地进行相关研究和开发，进一步推动元黑盒优化领域的进步.
## 265. `cs.AI` - CoLoRA: 效率较高的卷积模型微调方法及其在光学相干断层成像图像分类中的应用案例 [PDF](https://arxiv.org/pdf/2505.18315), [HTML](https://arxiv.org/abs/2505.18315)
### Authors
Mariano Rivera,Angello Hoyos
### Background
目前对于卷积神经网络(CNNs)的参数高效微调方法尚存不足。传统的全参数微调方法可能会增加模型的复杂度和训练时间，而现有的局部讀取性适应性方法（LoRA）仅针对全连接层进行了优化，对于卷积层的有效性未充分验证。本研究旨在提出一种新的微调方法CoLoRA，以克服现有方法的不足，适用于卷积网络的参数高效微调，并验证其在医学图像分类中的应用效果。
### Innovation
CoLoRA 通过将卷积核更新分解为轻量化的深度卷积和点卷积，从而减少了需要训练的参数数量(相对于传统微调减少至0.2)，保持了原始模型大小不变，并在每轮训练后将更新合并到预训练权重中，同时使推理复杂度保持不变。此外，在OCTMNISTv2数据集上，CoLoRA应用于VGG16和ResNet50模型，其准确性和AUC值分别优于视知觉变换器、状态空间模型和科莫哥罗夫-阿诺尔德模型，并且每轮训练时间减少了近20%。
### Conclusion
CoLoRA 提供了稳定且有效的方法替代全参数微调，适用于医学图像分类任务，证明了其在提高模型效率和保持性能方面的能力。
## 266. `cs.AI` - LIMOPro: 提高推理准确性和效率的简化推理框架 [PDF](https://arxiv.org/pdf/2505.19187), [HTML](https://arxiv.org/abs/2505.19187)
### Authors
Yang Xiao,Jiashuo Wang,Ruifeng Yuan,Chunpu Xu,Kaishuai Xu,Wenjie Li,Pengfei Liu
### Background
大型语言模型（LLMs）通过测试时扩展方法展示了出色的推理能力，尤其是在使用来自更强大的大型推理模型（LRMs）提炼出的chain-of-thought（CoT）数据进行微调后。然而，这些推理链中往往包含冗余的人类问题解决元素，这些元素可以分为渐进推理（核心解决方案发展路径）和功能性元素（验证过程、备选解决方案和错误修正）。尽管渐进推理至关重要，功能性元素却显著增加了测试时推理的计算需求。
### Innovation
我们提出了一个基于混乱度的重要性细化框架（PIR），它可以定量评估每个推理步骤对答案预测置信度的影响。PIR系统地识别并选择性地去除低重要性的功能性步骤，同时保留渐进推理成分，从而创建优化训练数据，该数据维护核心解决方案路径的完整性，同时减少冗余。基于PIR优化的数据微调的模型在具有挑战性的推理基准测试（AIME、AMC和GPQA Diamond）上表现出更好的测试时扩展特性，生成更简洁的推理链，并通过显著减少令牌使用量（-3%至-41%）实现了更高的准确率（+0.9%至+6.6%）。我们的方法展示了在不同模型规模、数据源和令牌预算方面的强泛化性，为部署具备推理能力的LLMs提供了有效的解决方案，尤其在需要高效测试时扩展、响应时间和计算效率的限制场景中。
### Conclusion
该框架验证了在不同模型大小、数据源和令牌预算下有效的泛化能力，并为在需要高效测试时扩展性能增强的情景中部署推理能力的LLMs提供了实际解决方案。
## 267. `cs.AI` - Segment Policy Optimization: Effective Segment-Level Credit Assignment in RL for Large Language Models [PDF](https://arxiv.org/pdf/2505.23564), [HTML](https://arxiv.org/abs/2505.23564)
### Authors
Yiran Guo,Lijie Xu,Jie Liu,Dan Ye,Shuang Qiu
### Background
增强大语言模型的推理能力，使用强化学习(Reinforcement Learning, RL)仍然是一个关键挑战。现有的方法主要采用两种截然不同的优势估计粒度：标记级别方法（例如PPO）虽然试图提供精细的优势信号，但由于难以训练出准确的评估模型而面临不准确的估计问题。另一方面，轨迹级别方法（例如GRPO）仅依赖于最终奖励的粗略优势信号，导致奖励分配不够精确。
### Innovation
提出了一种新型的RL框架——Segment Policy Optimization (SPO)，它利用了中间粒度的段级别优势估计。SPO通过提供比轨迹级别方法更精确的奖励分配，并需要比标记级别方法更少的优势估计点，实现了基于蒙特卡洛（MC）准确的优势估计，而无需评估模型。SPO的特点包括：灵活的段划分、准确的段优势估计以及使用段优势进行策略优化，包括一种新颖的概率掩码策略。
### Conclusion
进一步将SPO实例化为两种特定场景：SPO-chain用于短的链条推理（CoT），通过基于分割点的分割和基于链条的优势估计，在GSM8K上的准确度优于PPO和GRPO约6%-12%。SPO-tree用于长的链条推理（CoT），通过基于树的优势估计显著减少了MC估计的成本，在MATH500上的准确度优于GRPO在2K和4K上下文评估中分别约7%-11%。代码已公开。
## 268. `cs.AI` - REOrdering Patches Improves Vision Models [PDF](https://arxiv.org/pdf/2505.23751), [HTML](https://arxiv.org/abs/2505.23751)
### Authors
Declan Kutscher,David M. Chan,Yutong Bai,Trevor Darrell,Ritwik Gupta
### Background
序列模型如变换器需要输入表示为一维序列。在视觉领域，通常通过固定列优先级（逐行扫描）顺序将图像展平。尽管全自注意力机制对排列不变，现代长序列变换器越来越多地依赖破坏这一不变性的架构近似，从而引入了对块顺序的敏感性。文章指出，块顺序显著影响模型性能，不同的排列（如列优先级或希尔伯特曲线）可带来显著的准确率提升。
### Innovation
文章提出了REOrder，一种用于发现任务最优块排列的两阶段框架。首先，通过评估各种块序列的压缩性获得信息论先验。然后，通过优化一个Plackett-Luce策略来学习排列策略，这种方法可以在组合排列空间中实现高效学习。实验表明，REOrder框架在ImageNet-1K和Functional Map of the World数据集上分别提高了3.01%和13.35%的顶级准确率。
### Conclusion
REOrder框架能够在视觉模型中显著改进块排列，通过优化排列策略增强了模型的鲁棒性和性能，特别是在长序列变换器中。
## 269. `cs.AI` - 噪声中的噪声稳健性：一种结合不对称LoRA和中毒MoE的框架 [PDF](https://arxiv.org/pdf/2505.23868), [HTML](https://arxiv.org/abs/2505.23868)
### Authors
Zhaokun Wang,Jinyu Guo,Jingwen Pu,Lingfeng Chen,Hongli Pu,Jie Ou,Libo Qin,Wenhong Tian
### Background
当前，用于调整预训练语言模型以适应下游任务的参数效率有限调优方法易受噪声数据的干扰。传统的噪声处理方法要么依赖于耗时的数据预处理，要么通过容易累积错误的模型架构修改来应对噪声。
### Innovation
本文提出了一种噪声鲁棒适配方法——不对称LoRA中毒专家（LoPE），这是一种新的框架，仅通过生成的噪声数据就能增强模型对噪声的鲁棒性。LoPE借鉴了混合专家架构，通过在不对称LoRA配置中战略性地集成专门的中毒专家来实现噪音的注入和处理。通过两阶段过程，LoPE在调优过程中对中毒专家进行噪音注入以增强其噪音识别和处理能力，且在推理过程中选择性地屏蔽专门的中毒专家，利用正常专家获取的净化知识来实现噪声鲁棒输出，无需进行数据清洗即可实现低成本的噪音注入，并取得了强大的性能和鲁棒性
### Conclusion
广泛的实验表明，LoPE仅通过低成本的噪音注入实现了强大的性能和鲁棒性，完全消除了数据清洗的需求。
## 270. `cs.AI` - VisuRiddles: 细粒度感知是多模态大型语言模型在抽象视觉推理中的主要瓶颈 [PDF](https://arxiv.org/pdf/2506.02537), [HTML](https://arxiv.org/abs/2506.02537)
### Authors
Hao Yan,Xingchen Liu,Hao Wang,Zhenbiao Cao,Handong Zheng,Liang Yin,Xinxing Su,Zihao Chen,Jihao Wu,Minghui Liao,Chao Weng,Wei Chen,Yuliang Liu,Xiang Bai
### Background
近年来，多模态大型语言模型（MLLMs）在许多推理任务上的性能有了显著提升，但在抽象视觉推理（AVR）方面仍存在关键挑战，主要由于对抽象图形的感知能力有限。
### Innovation
本文提出了VisuRiddles基准和Perceptual Riddle Synthesizer（PRS）框架。VisuRiddles为AVR设计了一系列详细的任务，可以评估模型在多个核心维度和推理类别上的推理能力。PRS能够自动生成具有细粒度感知描述的谜题，从而生成有价值的训练数据，这不仅有助于监督中间推理阶段，还能提升训练效率和模型可解释性。
### Conclusion
我们的实验结果表明，细粒度视觉感知是MLLMs的主要瓶颈，而我们的合成框架显著提升了这些任务上的性能。
## 271. `cs.AI` - EvaLearn: 通过顺序问题解决定量评估大语言模型的学习能力和效率 [PDF](https://arxiv.org/pdf/2506.02672), [HTML](https://arxiv.org/abs/2506.02672)
### Authors
Shihan Dou,Ming Zhang,Chenhao Huang,Jiayi Chen,Feng Chen,Shichun Liu,Yan Liu,Chenxiao Liu,Cheng Zhong,Zongzhang Zhang,Tao Gui,Chao Xin,Chengzhi Wei,Lin Yan,Yonghui Wu,Qi Zhang,Xuanjing Huang
### Background
当前的大语言模型评估基准主要关注模型在并行任务上的表现，而较少关注模型在解决复杂任务时的学习能力和效率。EvaLearn旨在填补这一空白，通过648个挑战性任务（分为182个序列）来评估模型的学习能力和效率。
### Innovation
EvaLearn是一个首创的基准，它要求模型按顺序解决任务，从而利用先前的知识进行学习。这与大多数基准不同，后者通常在并行任务下进行评估。此外，EvaLearn还提供了五项自动化评估指标来量化模型的学习能力和效率。研究还发现，实例级评估标准和教师模型反馈进一步帮助模型学习。
### Conclusion
EvaLearn展示了模型在不同任务上的学习能力，并指出当前具有强大静态能力的模型在所有任务上的学习表现并不明显领先，从而评估模型的新维度。研究认为，EvaLearn为评估大语言模型潜力提供了新的视角，并促进了更深层次和动态评估方法的发展。
## 272. `cs.AI` - GraSS: 通过梯度稀疏化和稀疏投影实现可扩展的数据归属 [PDF](https://arxiv.org/pdf/2505.18976), [HTML](https://arxiv.org/abs/2505.18976)
### Authors
Pingbang Hu,Joseph Melkonian,Weijing Tang,Han Zhao,Jiaqi W. Ma
### Background
梯度导向的数据归因方法，例如影响函数，对于理解单个训练样本的影响至关重要，无需重复模型重新训练。然而，由于每个样本梯度计算相关的高计算和内存成本，其扩展性往往有限。重建整个模型梯度的成本通常很高，影响了这些方法的应用。
### Innovation
本文提出了一种新颖的梯度压缩算法GraSS及其针对线性层的变体FactGraSS，这些算法明确利用了每个样本梯度的固有稀疏性，从而实现了亚线性空间和时间复杂度。实验结果证明了该方法的有效性，在保持数据影响保真度的同时获得显著加速。特别是，FactGraSS在具有 billionscale 规模的模型上实现了比之前最先进的基线高达165%的吞吐量提升。
### Conclusion
我们的方法GraSS及其变体FactGraSS能够有效压缩梯度，从而在大规模模型中实现数据属性的可扩展计算，同时保持数据影响的高保真度。我们公开了代码以供其他研究者使用和研究。
## 273. `cs.AI` - 基于模型的隐式神经表示在亚波长无线定位中的应用 [PDF](https://arxiv.org/pdf/2506.06387), [HTML](https://arxiv.org/abs/2506.06387)
### Authors
Baptiste Chatelier(IETR, INSA Rennes, MERCE-France),Vincent Corlay(MERCE-France),Musa Furkan Keskin,Matthieu Crussière(INSA Rennes, IETR),Henk Wymeersch,Luc Le Magoarou(INSA Rennes, IETR)
### Background
基站部署大规模天线阵列极大地提高了射频定位方法的空间分辨率和定位精度。然而，传统信号处理技术在复杂射频环境中效果不佳，尤其是在非视距（NLoS）传播路径占主导的场景中，导致定位精度下降。机器学习的最新进展促进了机器学习辅助定位技术的发展，这些技术在复杂射频环境中的定位准确性得到了提升。然而，这些方法在训练和推理阶段通常涉及巨大的计算复杂度。
### Innovation
研究利用基于模型的神经网络学习位置到信道的映射，并作为生成神经信道模型。该生成模型增强了指纹对比字典，同时减少了内存需求。该方法在复杂的静止NLoS环境中实现了亚波长级别的定位精度，相比经典指纹定位方法，它的定位精度提高了几个数量级，而内存需求减少了1个数量级。
### Conclusion
该研究表明，基于模型的神经网络可以有效提高无线定位的精度，同时减少内存需求，特别是在复杂静止NLoS环境中，实现了亚波长级别的定位精度。
## 274. `cs.AI` - 压制未来：使用最可能的状态进行时间移动的分布 [PDF](https://arxiv.org/pdf/2506.07578), [HTML](https://arxiv.org/abs/2506.07578)
### Authors
Florian Andreas Marwitz,Ralf Möller,Magnus Bender,Marcel Gehrke
### Background
动态概率模型中的推断是一项复杂的任务，涉及昂贵的操作。特别是对于隐藏马尔可夫模型（HMM），整个状态空间必须被枚举以便随着时间推进。即使是概率极小的状态也会被考虑在内，导致计算效率低下和由于不可能概率的传播而增加噪声。
### Innovation
提出了一种仅使用最可能的top-p状态（即累积概率为p的状态）来压制未来的增益和加速推断。理论证明了使用最可能的top-p状态引入的误差被p和底层模型的最小混合速率所限定。实验评估显示，我们可以在保持误差在总变差距离下不超过0.09的情况下，比基线方法获得至少一个数量级的加速。
### Conclusion
本文展示了通过使用最可能的top-p状态来减少未来噪声和加速推断的可行性与有效性，进一步证明在实际应用中能显著提高计算效率并减少误差。
## 275. `cs.AI` - Mind the Web: The Security of Web Use Agents [PDF](https://arxiv.org/pdf/2506.07153), [HTML](https://arxiv.org/abs/2506.07153)
### Authors
Avishag Shapira,Parth Atulbhai Gandhi,Edan Habler,Asaf Shabtai
### Background
随着网络使用代理的快速发展，它们被广泛用于自动化复杂的网络任务，具有强大的浏览器功能。然而，这些功能创造了一个之前未被探索的关键攻击面。攻击者可以通过在用户浏览期间遇到的网页中嵌入恶意内容（例如评论、评价或广告）来利用网络使用代理。当前，这些代理在维护上下文连贯性方面存在困难，难以检测到看似有用的网络内容中包含的引导尝试，这会使其脱离原始任务目标。
### Innovation
本文提出了与任务对齐的注入技术，将恶意命令伪装成有用的任务指导，利用了大语言模型在情境推理方面的基本局限性。还开发了一个自动化的三阶段管道，可以生成有效的注入，而不需要手动标注或昂贵的在线代理互动，即使在有限的训练数据下也能保持高效率。该管道生成了一个生成模型，并对其进行了评估，涉及五个流行的代理，以及机密性、完整性和可用性（CIA）安全三角，包括未经授权的摄像头激活、文件外泄、用户冒充、网络钓鱼和拒绝服务。生成器实现了超过80%的攻击成功率（ASR），具有良好的迁移性，跨越了未见过的载荷、多样的网络环境和不同的底层大语言模型。即使在具有内置安全机制的代理面前，该攻击也成功了，仅需在公共网站上发布内容的能力。
### Conclusion
为了应对这一风险，本文提出了全面的缓解策略，包括监督机制、执行约束和任务感知推理技术。
## 276. `cs.AI` - 用视频思考实现有能力的长视频理解 [PDF](https://arxiv.org/pdf/2506.10821), [HTML](https://arxiv.org/abs/2506.10821)
### Authors
Huaying Yuan,Zheng Liu,Junjie Zhou,Hongjin Qian,Yan Shu,Nicu Sebe,Ji-Rong Wen,Zhicheng Dou
### Background
长视频理解（LVU）是计算机视觉中的一个具有挑战性的问题。现有方法要么通过下采样帧进行单次推理，牺牲了细节的准确性；要么依赖于任务无关的表示体系的文本推理，这限制了任务特定的感知和探索。
### Innovation
本文提出了VideoExplorer框架，该框架遵循“用视频思考”的原则，将规划、时间接地和可扩展感知自然地融入一个协调的推理过程。VideoExplorer通过迭代地提出子问题、定位相关时刻，并执行任务导向的、可扩展的视频理解，直到找到最终答案，从而实现忠实、高效和可解释的推理。为了应对LVU训练资源的缺乏，该研究构建了一套难度适应性的推理数据集，确保在复杂任务中具有高质量的轨迹。该数据集支持了两个阶段的训练pipeline：监督轨迹初始化后，通过下游奖励引导的轨迹层级偏好优化，以促进自适应的时间接地和迭代的信息整合。
### Conclusion
广泛的评估表明，VideoExplorer在流行的长视频理解和推理基准测试中显著优于现有基线，突显了其鲁棒性、适应性和效率。我们的代码已在该仓库（提供的链接）中公开。
## 277. `cs.AI` - 无限解析器：用于扫描文档解析的布局感知强化学习 [PDF](https://arxiv.org/pdf/2506.03197), [HTML](https://arxiv.org/abs/2506.03197)
### Authors
Baode Wang,Biao Wu,Weizhen Li,Meng Fang,Zuming Huang,Jun Huang,Haozhe Wang,Yanjie Liang,Ling Chen,Wei Chu,Yuan Qi
### Background
文档AI中，从扫描的文档自动解析成丰富结构化的、机器可读的格式仍然是一个关键瓶颈，传统多阶段管道由于错误传播和对多种布局适应性有限的问题而受到限制。
### Innovation
引入了名为layoutRL的端到端强化学习框架，通过优化归一化编辑距离、段落计数准确性和阅读顺序保持的复合奖励来训练模型达到明确的布局意识。利用新发布的Infinity-Doc-55K数据集（结合了55K高质量合成扫描文档解析数据和专家筛选的真实世界文档），在视图-语言模型为基础的解析器Infinity-Parser中实例化layoutRL，相比专门管道和通用视图-语言模型在OCR、表格和公式提取以及阅读顺序检测方面实现新的准确性和结构性保真的先进性能。
### Conclusion
我们将公开发布我们的代码和数据集，以促进稳健文档理解的进步。
## 278. `cs.AI` - 结构化流形上理解上下文学习：将注意力机制与核方法联系起来 [PDF](https://arxiv.org/pdf/2506.10959), [HTML](https://arxiv.org/abs/2506.10959)
### Authors
Zhaiming Shen,Alexander Hsu,Rongjie Lai,Wenjing Liao
### Background
虽然在上下文学习（ICL）在自然语言和视觉领域已经取得了显著的成功，但在结构化几何数据的上下文中进行理论理解仍然是个未解决的问题。本文开始针对流形上Hölder函数的回归问题，对ICL进行理论研究，并建立了注意力机制与经典核方法之间的新联系，显示出变换器通过与提示的交互有效执行基于核的预测。
### Innovation
本研究不仅建立了注意力机制与核方法之间的新联系，而且还得出了通用化错误界在提示长度和训练任务数量方面的表达式。更重要的是，当大量训练任务被观察到时，变换器将导致Hölder函数在流形上的最小化回归率，该率随流形的内在维度指数增长，而不是随流形所处的空间维度增长。这为理解变压器作为上下文内核算法学习者的复杂性提供了新的见解，并提供了研究非线性模型ICL的基础工具和方法。
### Conclusion
本研究表明了几何在ICL中的作用，并为客户理解ICL提供了基础性的见解，以及研究非线性模型ICL的新工具。
## 279. `cs.AI` - 迭代量子特征映射 [PDF](https://arxiv.org/pdf/2506.19461), [HTML](https://arxiv.org/abs/2506.19461)
### Authors
Nasa Matsumoto,Quoc Hoan Tran,Koki Chinzei,Yasuhiro Endo,Hirotaka Oshima
### Background
量子机器学习模型利用量子电路作为量子特征映射（QFMs），在学习任务中表现出增强的表达能力，并且为特定分类问题族展现了严格的端到端量子加速。然而，将深度QFMs部署到实际量子硬件中具有挑战性，原因在于量子门噪声和硬件限制。此外，变量子算法通常会遇到计算瓶颈，尤其是精确梯度估计方面的问题，这显著增加了训练过程中的量子资源需求。
### Innovation
本文提出了迭代量子特征映射（IQFMs）框架，这是一种混合量子-经典架构，通过迭代连接浅层QFMs和经典计算的增强权重来构建深层架构。通过结合对比学习和逐层训练机制，IQFMs框架有效降低了量子运行时间和缓解了噪音引起的退化问题。对于包含噪声量子数据的任务，数值实验表明IQFMs框架在不优化变量子参数的情况下优于量子卷积神经网络。即使在经典的图像分类基准测试中，精心设计的IQFMs框架也能实现与经典神经网络相当的性能。
### Conclusion
这项框架为解决现有限制并挖掘量子增强机器学习的全部潜力提供了有希望的途径。
## 280. `cs.AI` - 稀疏特征共激活揭示大型语言模型中的因果语义模块 [PDF](https://arxiv.org/pdf/2506.18141), [HTML](https://arxiv.org/abs/2506.18141)
### Authors
Ruixuan Deng,Xiaoyang Hu,Miles Gilberti,Shane Storks,Aman Taxali,Mike Angstadt,Chandra Sripada,Joyce Chai
### Background
该研究使用稀疏自编码器（SAE）特征，通过少量提示的共激活，识别出大型语言模型（LLMs）中在语义上一致且上下文一致的网络组件。通过对概念和关系的组件进行消融和放大实验，在概念-关系预测任务中观察到了可预测的变化，并且发现了组合关系和概念组件可以产生复合的反事实输出。进一步分析还揭示了概念组件大多源自第一个层，而更抽象的关系组件则集中于较晚的层。提取出的组件不仅能更全面地捕捉概念和关系，而且保持了特定性。这项研究提供了知识模块化组织的证据，并推动了对LLMs的有效、针对性操作方法的发展。
### Innovation
该研究通过稀疏自编码器共激活识别LLMs中的因果语义模块，并通过概念和关系组件的消融和放大实验展示了可预测的行为。发现了组合概念和关系组件可以产生复合的反事实输出，同时还揭示了不同类型的语义组件分布在模型中的不同的层，且提取出的组件能更全面地捕捉概念和关系。这项工作创新性地使用稀疏自编码器特征来识别大规模语言模型中的语义模块，为高效和靶向的LLM操作提供了新的方法论基础。
### Conclusion
该研究表明知识在大型语言模型中是模块化的组织形式，通过组合操作可以访问这些模块。这不仅揭示了知识在模型中的分布，还为理解和操纵大规模语言模型提供了一种新的方式。这些发现不仅对语言模型的研究和开发具有重要意义，也为更高效、针对性地操作和利用大规模语言模型提供了新方法。
## 281. `cs.AI` - 守护者攻击：攻击如同理理由影子 [PDF](https://arxiv.org/pdf/2506.07031), [HTML](https://arxiv.org/abs/2506.07031)
### Authors
Jingyuan Ma,Rui Li,Zheng Li,Junfeng Liu,Heming Xia Lei Sha,Zhifang Sui
### Background
新兴的大规模推理模型(LRM)在数学和推理任务中表现出色，展现出显著的能力。然而，提高推理能力并暴露内部推理过程引入了新的安全漏洞。我们面临一个关键问题：当推理与有害性交织时，LRM是否会更容易在推理模式中发生脱逃攻击？为探讨这一问题，我们提出了HauntAttack，一种新颖且具有普适性的黑盒对抗攻击框架，系统地将有害指令嵌入到推理问题中。我们通过修改现有问题中的关键推理条件，并加入有害指令，从而构建一条引导模型逐步向不安全输出前进的推理路径。
### Innovation
我们提出了一种名为HauntAttack的新型黑盒对抗攻击框架，它系统地在推理问题中嵌入有害指令，这些指令影响模型的推理路径，使其产生不安全的输出。实验结果表明，HauntAttack在11种LRM中取得了70%的平均攻击成功率，并且在最强的先前基线基础上取得了12个百分点的绝对改进。此外，我们的进一步分析表明，即使是最先进的安全对齐模型也高度容易受到基于推理的攻击。这揭示了在未来的模型开发中平衡推理能力和安全性的紧迫挑战。
### Conclusion
本研究揭示了在平衡推理能力与安全性时面临的重大挑战，通过系统地将有害指令嵌入到推理问题中，并利用HauntAttack框架，验证了即使是最先进的安全对齐模型也非常容易遭受基于推理的攻击。这一发现强调了未来模型开发中确保推理安全性的紧迫性和重要性。
## 282. `cs.AI` - 反事实推理：语境中出现的分析 [PDF](https://arxiv.org/pdf/2506.05188), [HTML](https://arxiv.org/abs/2506.05188)
### Authors
Moritz Miller,Bernhard Schölkopf,Siyuan Guo
### Background
大型神经语言模型在基于上下文的学习中表现出色，即能够在没有预先学习的情况下学习和推理输入的上下文。本文探讨了语言模型的反事实推理能力，即预测假设场景后果的能力。研究人员聚焦于一个需要去噪归约的严格定义的合成线性回归任务。准确的预测基于两个方面：推断未观察到的潜在概念和从事实观察中复制上下文噪声。研究表明，语言模型能够进行反事实推理。此外，作者增强了现有的可识别性结果，并发现反事实推理可以将广泛函数类转换为对于上下文观察的变换。研究在Transformer中探索了反事实推理的关键因素：自注意力、模型深度与预训练数据多样性对性能的驱动作用。同时，通过机械证据表明，潜在概念在残差流中线性表示，并提出了关键的“去噪提取头”以实现实现反事实推理。研究结果还扩展到了带有SDE动态的反事实推理情景下，并展示了Transformer可以在序列数据中执行去噪推理，为反事实故事生成的潜力提供了初步证据。代码已开源。
### Innovation
研究了语言模型在预测假设场景后果的反事实推理能力。通过合成线性回归任务的严格定义，证明了语言模型可以进行反事实推理，并增强了现有识别性结果的研究。表明了自注意力机制、模型深度和预训练数据多样性对反事实推理性能的驱动作用。提出了关键的“去噪提取头”机制，并扩展了反事实推理至SDE动态下，展示了Transformer在序列数据中处理去噪推理的潜力。
### Conclusion
研究发现了自注意力机制、模型深度和预训练数据多样性对反事实推理性能的重要影响。提出了“去噪提取头”机制，以实现实现反事实推理的关键部分。研究表明，Transformer具备在序列数据中进行去噪推理的能力，这种能力体现了反事实故事生成的潜力。
## 283. `cs.AI` - ViFusionTST: 深度融合负载信号时间序列图示表示的图像融合方法及其在早期离床预测中的应用 [PDF](https://arxiv.org/pdf/2506.22498), [HTML](https://arxiv.org/abs/2506.22498)
### Authors
Hao Liu,Yu Hu,Rakiba Rayhana,Ling Bai,Zheng Liu
### Background
在医院和长期护理设施中，与床相关的跌倒是造成伤害的主要来源之一。尽管有许多商业警报系统可以在患者离开床后触发警报，但现有的系统往往只能在患者已经离开床后再发出警报。本研究旨在通过低成本的方法预测患者早期离床的意图，以实现更早期的跌倒预防。
### Innovation
本研究提出了一种新的方法ViFusionTST，该方法使用一个安装在床腿下的低成本载荷传感器，并将采集到的载荷信号转换为图像集，包括RGB线条图和纹理图（包括递归图、马尔可夫转换场和Gramian角场），这暴露了高阶动态。此外，提出了一种双流Swin Transformer，该模型能够同时处理线条图和纹理图，并通过交叉注意力机制融合这些图层，从而学习数据驱动的模态权重。该方法在实际数据集上的表现优于现有的一维和二维时间序列基线，证明了基于图像融合的负载传感器信号时间序列分类方法在实时、隐私保护跌倒预防中的可行性和有效性。
### Conclusion
本研究表明，通过图像融合负载传感器信号进行时间序列分类是实现实时安全、隐私保护跌倒预防的有效解决方案。
## 284. `cs.AI` - 任务先验：通过考虑下游任务的整个空间来提升模型评估 [PDF](https://arxiv.org/pdf/2507.09871), [HTML](https://arxiv.org/abs/2507.09871)
### Authors
Niket Patel,Randall Balestriero
### Background
当前的AI研究主要通过固定的手动挑选的下游基准来评估模型，而这对实现在任何可能任务上成功解决问题的宏伟目标来说是一个限制。现有的评估方法过于局限，导致研究人员花费大量时间设计和寻找可以作为大型评估任务的代理的任务集。研究表明，这种僵化的评估协议在AI研究中形成了一个隐蔽的瓶颈。
### Innovation
本文提出了任务先验（Task Priors）的概念，即通过定义任务概率分布来构建下游任务概率空间，从而首次能够回答关于模型性能的关键问题，例如在所有可能的下游任务中平均性能及其变化情况。该框架提供了一个全新的评估标准，并认为任务先验将加速基于自监督学习的下游任务评估的研究速度，因为这是研究人员唯一可以获得的定性信号。
### Conclusion
通过引入任务先验的概念，本文为AI研究提供了一种新的评估方法，解决了当前刻板的评估标准带来的限制，并有望加速自监督学习中下游任务评估的研究进程。
## 285. `cs.AI` - 结合成本受限的实时监控器以提高人工智能安全性 [PDF](https://arxiv.org/pdf/2507.15886), [HTML](https://arxiv.org/abs/2507.15886)
### Authors
Tim Tian Hua,James Baskerville,Henri Lemoine,Mia Hopman,Aryan Bhatt,Tyler Tracy
### Background
实时监控AI可以检测和阻止有害行为，但现有方法往往不仅成本高昂，还难以高效整合多个监控器。本文研究如何高效地将多个实时监控器整合到单个监控协议中，以最大化安全干预的召回率，并同时满足成本预算约束，为这一领域提供了进展背景。
### Innovation
本文提出了一种算法，该算法考虑了监控器的性能和成本，在召回率显著提高的同时，解决了成本预算的问题。具体而言，该算法通过基于Neyman-Pearson引理分配安全干预和关注似然比，实现了在预算受限的条件下，双监控器结合优于单个监控器的效果，并且首次提供了在成本敏感环境中结合现有监控器的理论架构。
### Conclusion
本文提出的方法有效地将成本约束下的多个实时监控器整合到单个监控协议中，显著提高了召回率，并为在成本敏感环境下检测不良行为提供了新的思路和方法。
## 286. `cs.AI` - 使用大型语言模型增强的知识图谱补全 [PDF](https://arxiv.org/pdf/2507.20643), [HTML](https://arxiv.org/abs/2507.20643)
### Authors
Wenbin Guo,Xin Wang,Jiaoyan Chen,Zhao Li,Zirui Chen
### Background
大型语言模型（LLMs）已在知识图谱补全（KGC）中得到广泛应用，展示了显著的研究进展。然而，作为依赖深度神经架构的黑盒模型，当前基于LLM的KGC方法依赖隐式知识表示和并行传递错误知识，这限制了它们产生明确和决断推理结果的能力。
### Innovation
提出了一种利用LLM增强的知识本体增强知识图谱补全方法——OL-KGC。该方法首先利用神经感知机制有效地将结构信息嵌入到文本空间中，然后通过自动化提取算法从需要补全的知识图谱（KGs）中检索本体知识，并进一步转换为LLM可理解的文本格式，以提供逻辑指导。
### Conclusion
在三个广泛使用的基准数据集——FB15K-237、UMLS和WN18RR上进行了广泛的实验。实验结果表明，OL-KGC在多个评估指标上显著优于现有主流的KGC方法，达到了最先进的性能。
## 287. `cs.AI` - Shuffle-R1: 通过数据为中心的动态洗牌提高多模态大语言模型的强化学习效率 [PDF](https://arxiv.org/pdf/2508.05612), [HTML](https://arxiv.org/abs/2508.05612)
### Authors
Linghao Zhu,Yiran Guan,Dingkang Liang,Jianzhong Ju,Zhenbo Luo,Bin Qin,Jian Luan,Yuliang Liu,Xiang Bai
### Background
强化学习（RL）已成为提升多模态大语言模型（MLLM）推理能力的有效后训练范式。然而，当前的RL管道经常会受到两个未充分探索的问题导致的训练效率低下问题：优势塌陷（Advantage Collapsing），即批次中的大多数优势集中在零附近；以及回放静默（Rollout Silencing），即随着时间的推移，贡献非零梯度的回放比例下降。这些问题导致梯度更新不理想，并阻碍了长期的学习效率。
### Innovation
我们提出了Shuffle-R1，这是一种简单而有原则的框架，通过动态重构轨迹采样和批量组成来提高RL微调效率。它引入了两个核心机制：1）配对轨迹采样，该方法选择具有大优势的高对比强度轨迹以提高梯度信号质量；2）基于优势的轨迹洗牌，该方法通过有信息的批量重排增加了有价值回放的曝光度。
### Conclusion
我们的框架在多个推理基准测试中表现出色，不仅优于强大的RL基线，且实现成本低。这些结果强调了数据为中心的适应性对于更高效的MLLM的RL训练的重要性。
## 288. `cs.AI` - 通过参数自编码器进行弹性结构拓扑优化的代理模型 [PDF](https://arxiv.org/pdf/2507.22539), [HTML](https://arxiv.org/abs/2507.22539)
### Authors
Matteo Giacomini,Antonio Huerta
### Background
该研究提出了针对具有参数载荷和边界条件的线性弹性结构的一种基于代理模型的拓扑优化算法。传统方法通常尝试学习状态（和伴随）问题的参数解或优化轨迹，但该研究通过构建整个优化流程的代理版本，提出了一种不同方法。这种方法首先通过参数自编码器预测给定问题配置的近似最优拓扑结构，并在保持特征参数及其编码器/解码器块维度降低的同时，重建高维拓扑结构的表示。然后使用预测的拓扑结构作为高效算法的启发式初始猜测，该算法在满足系统约束的前提下惩罚设计变量的中间值。这一步骤允许方法纠正代理模型引入的潜在错误，消除伪影，并细化设计以生成与基础物理一致的拓扑结构。研究还测试了代理模型在训练和验证域外的外推能力。该代理模型能够通过减少优化迭代次数（平均53%）且最优目标函数值的差异在4%以下而优于高保真优化器，即使在挑战性的外推场景下也是如此。
### Innovation
提出了一种基于代理模型的拓扑优化算法，通过参数自编码器预测最大化优化结果的拓扑结构。该方法通过将参数拓扑优化问题的维度降低，并使用高效的计算算法结合预测的拓扑结构作为初始猜测，来纠正代理模型可能引发的错误和优化初期的状态。此外，研究还在不同架构下评估了最终模型的近似能力和泛化能力，展示了其在收敛速度和优化性能上的优势。
### Conclusion
此研究提出的基于代理模型的拓扑优化算法能够通过有效减少优化迭代次数同时维持与高保真优化器相当的性能，甚至在复杂场景中也能保持良好的收敛性能。这一方法为弹性结构的优化设计提供了新的解决方案。
## 289. `cs.AI` - 可以用合成数据评估RAGs吗？ [PDF](https://arxiv.org/pdf/2508.11758), [HTML](https://arxiv.org/abs/2508.11758)
### Authors
Jonas van Elburg,Peter van der Putten,Maarten Marx
### Background
研究考察了大型语言模型生成的合成问题-答案（QA）数据作为人类标注基准的替代品的有效性，特别是在后者的数据不可用时。
### Innovation
通过跨两种实验，一种是固定生成器但改变检索器参数，另一种是固定检索器但改变生成器，该研究评估了合成基准的可靠性。研究表明，合成基准可以可靠地评估不同检索器配置下的检索-生成型架构（RAGs），但未能一致地评估不同生成器架构。
### Conclusion
合成基准可靠地排名了不同检索器配置的RAGs，并且与人类标注基准相近，但在比较不同生成器架构时并不总是可靠。这可能源于合成和人类基准之间任务匹配不佳以及有时偏好某些生成器的风格偏差。
## 290. `cs.AI` - 在大型视觉语言模型中学习检测未知越狱攻击 [PDF](https://arxiv.org/pdf/2508.09201), [HTML](https://arxiv.org/abs/2508.09201)
### Authors
Shuang Liang,Zhihao Xu,Jialing Tao,Hui Xue,Xiting Wang
### Background
尽管对齐努力广泛进行，大型视觉语言模型（LVLMs）依然对越狱攻击存在脆弱性，这带来了严重的安全风险。现有的检测方法要么学习特定的攻击参数，阻碍了对未见攻击的泛化能力，要么依赖于似是而非的原则，限制了准确性和效率。这种局限性亟需解决，作者提出了一种新的框架Learning to Detect (LoD)，将注意力从特定攻击的学习转移到特定任务的学习，该框架包括一个多模态安全概念激活向量模块和一个安全模式自编码器模块，用于无监督攻击分类。
### Innovation
提出了Learning to Detect (LoD)框架，通过从特定攻击学习转向特定任务学习来准确检测未知的越狱攻击。该框架中的多模态安全概念激活向量模块和安全模式自编码器模块分别用于安全导向的表示学习和无监督攻击分类。实验结果表明，该方法在多种未知攻击上的检测AUROC值高于现有方法，同时提高了效率。此外，代码已经公开，可以方便地进行进一步研究和验证。
### Conclusion
我们的方法在多种未知攻击上表现出了一致的检测准确性，并且通过自动编码器实现了更高的效率。这种方法显著提高了模型的安全性，为未来的视觉-语言模型安全研究提供了有效框架。
## 291. `cs.AI` - Sim2Dust: 在颗粒介质中掌握动态路径跟踪 [PDF](https://arxiv.org/pdf/2508.11503), [HTML](https://arxiv.org/abs/2508.11503)
### Authors
Andrej Orsula,Matthieu Geist,Miguel Olivares-Mendez,Carol Martinez
### Background
可靠的自主导航是未来太空探索的关键前提，特别是在那些遥远行星表面不规则地形上的导航。然而，基于学习的控制器的应用受到了从模拟到现实的巨大差距限制，特别是在轮式结构与颗粒介质复杂动力学的相互作用中。本文介绍了一个完整的模拟到实际框架，用于开发和验证适应动态路径跟踪的鲁棒控制策略。我们利用大规模并行模拟在广泛的程序生成环境中培训强化学习代理，并将其零样本转移至在月球模拟设施中操作的实际轮式漫游车。实验系统地比较了多种强化学习算法和动作平滑滤波器，以确定最适合实际部署的最佳组合。研究还提供了强有力的经验证据，证明通过程序多样性训练的代理在零样本性能上优于静态场景训练的代理。此外，我们分析了使用高保真颗粒物理进行微调的权衡，尽管在低速精确度上有所提升，但伴随着显著的计算成本增加。这些贡献共同建立了一个验证的工作流程，用于创建可靠的基于学习的导航系统，标志着向部署自主机器人在终极边疆迈出的一大步。
### Innovation
引入了一个大规模并行模拟框架，用于在广泛的颗粒介质环境中培训和验证适应性导航策略。通过程序生成的环境进行多样化训练，实现了零样本性能的显著提升。此外，分析了使用高保真颗粒物理进行微调的优缺点，提出了适用于实际应用的最佳策略组合。
### Conclusion
该研究建立了一个验证的工作流程，用以创建可靠的基于学习的导航系统，解决了从模拟到实际的挑战，尤其适用于复杂颗粒介质环境下的导航。这些成果标志着迈向在终极边疆部署自主机器人的重要一步。
## 292. `cs.AI` - 端到端自主驾驶中的可解释决策制定 [PDF](https://arxiv.org/pdf/2508.18898), [HTML](https://arxiv.org/abs/2508.18898)
### Authors
Mona Mirzaie,Bodo Rosenhahn
### Background
对于广泛部署自动驾驶车辆而言，可信的AI技术是必不可少的。尽管采取端到端的方法可以直接从原始数据生成控制指令，但在复杂的城市场景中仍难以解释这些决策。这是由于非常深的非线性神经网络决策边界造成了挑战，难以理解AI驱动决策背后的逻辑。因此，文章提出了同时优化控制指令和提高解释度的一种方法，以完善自动驾驶。
### Innovation
文章提出了基于损失函数的方法，该方法通过生成稀疏和局部化的特征图以促进模型的解释度。这些特征激活允许我们解释哪些图像区域贡献于预测的控制指令。文章还进行了特征抽取步骤的全面分析，并在CARLA基准测试上验证了方法的有效性。另外，单目且非集成模型比CARLA排行榜上表现最好的方法获得了更低的违规得分和最高的路线完成率，同时保证了解释度的改进合理化了更安全、高性能的驾驶模型。
### Conclusion
我们的方法不仅提高了可解释性，还间接提高了驾驶安全性，模型的表现优于CARLA排行榜上的顶级方法，包括更低的违规得分和最高的路线完成率。
## 293. `cs.AI` - 评估生成型人工智能伦理和可靠性的框架研究 [PDF](https://arxiv.org/pdf/2509.00398), [HTML](https://arxiv.org/abs/2509.00398)
### Authors
Cheonsu Jeong,Seunghyun Lee,Seonhee Jeong,Sungsu Kim
### Background
随着生成型人工智能（AI）技术的迅猛发展，出现了伦理和可信度方面的挑战。现有的AI评估方法主要侧重于性能和准确性，但无法解决包括偏见、危害性、版权侵犯、隐私泄露和幻觉在内的复杂问题。这一研究强调需要新的以人为本的标准，这些标准需要反映出社会影响。
### Innovation
提出了一个全面的框架，用于系统评估生成型AI的伦理和可信度。该框架确定了公平性、透明性、问责性、安全性、隐私保护、准确性、一致性、稳健性、可解释性、版权和知识产权保护、以及来源可追溯性等关键维度，并为每个维度开发了详细的指标和评估方法。此外，对韩国、美国、欧盟和中国的AI伦理政策和指南进行了比较分析，提取了关键方法和意义。
### Conclusion
该研究为生成型AI的负责任发展奠定了学术基础，并向政策制定者、开发者、用户和其他利益相关者提供了可操作的见解，支持AI技术的积极社会贡献。该框架在AI生命周期中应用，并结合了技术和多学科视角，为现实世界中的伦理风险识别和管理提供了实用途径。
## 294. `cs.AI` - AI Agentic Vulnerability Injection And Transformation with Optimized Reasoning [PDF](https://arxiv.org/pdf/2508.20866), [HTML](https://arxiv.org/abs/2508.20866)
### Authors
Amine Lbath,Massih-Reza Amini,Aurelien Delaitre,Vadim Okun
### Background
软件系统的复杂性和网络攻击的 sophistication 加强了有效自动漏洞检测和修复系统的需求。尽管基于数据驱动的深度学习模型显示出潜力，但它们高度依赖于大量准确标记的数据集。然而，现有的数据集要么标签不准确，要么漏洞范围有限，无法准确反映真实世界软件中的漏洞。这限制了此类解决方案的大规模基准测试。现有技术通过直接注入自动化漏洞来应对数据集的限制，但它们在覆盖范围、情境忠实度或注入成功率方面仍有限制。
### Innovation
本文介绍了AVIATOR，这是一个首创的AI-Agentic漏洞注入工作流。AVIATOR 自动注入现实的、类别特定的漏洞，以生成高保真度、多样化、大规模的漏洞数据集。它采用了模块化分解，集成了语义分析、使用LoRA微调的注入合成及检索增强生成，并通过静态分析和基于LLM的鉴别器进行后注入验证。这种机制让专业代理专注于不同的任务，提高了注入的鲁棒性并减少了工作流中的错误传播。
### Conclusion
在三个不同的基准测试中，AVIATOR 的注入成功率达到了 91%-95%，显著超越了现有的自动化数据集生成技术的准确性和范围。
## 295. `cs.AI` - 高效无训练在线路由方案以满足高流量多大型语言模型服务 [PDF](https://arxiv.org/pdf/2509.02718), [HTML](https://arxiv.org/abs/2509.02718)
### Authors
Fangzhou Wu,Sandeep Silwal
### Background
随着大型语言模型（LLMs）服务需求的增加，其部署和计算成本对提供者来说变得相当高。目前的LLM路由方法主要集中在离线场景，难以适应高查询量和受限标记预算的在线场景。
### Innovation
本文提出了第一个用于在线路由场景的无需训练的算法。该算法基于近似最近邻搜索来高效估计查询特征，并在一组初始查询上进行一次优化以学习路由策略，该策略可指导未来的路由。该算法在自然假设下具有竞争性比率1-o(1)，并通过三个基准数据集和八个基准模型的广泛实验得到了验证，显示平均性能改进3.55倍，成本效率提高1.85倍，吞吐量提升近4.25倍。
### Conclusion
该工作提供了一种在线路由策略，通过近似最近邻搜索的学习机制，有效地解决了高流量多大型语言模型服务的路由问题，并在网络实验中展示了显著的性能提升。
## 296. `cs.AI` - C-SEO Bench：对话式SEO有效吗？ [PDF](https://arxiv.org/pdf/2506.11097), [HTML](https://arxiv.org/abs/2506.11097)
### Authors
Haritz Puerto,Martin Gubri,Tommaso Green,Seong Joon Oh,Sangdoo Yun
### Background
大型语言模型（LLMs）正在将搜索引擎转变成对话式搜索引擎（CSE），随之而来的，搜索引擎优化（SEO）也正在转变为对话式搜索引擎优化（C-SEO）。已有针对C-SEO专门方法的测试，但这些测试主要局限于少数的应用领域。此外，现有评价方法仅针对单一参与者的场景进行评估，而实际上，多个参与者可能会竞争并采用C-SEO技术，这一现象与我们在SEO中观察到的动态相似。
### Innovation
本文提出了C-SEO Bench，这是首个用于评估C-SEO方法的基准，涵盖多个任务、领域和参与者数量。该研究设定了两项搜索任务（问答和产品推荐），每个领域有三个领域，采用了一种新的评价协议，考虑了参与者中不同的采用率。实验结果显示，大多数当前的C-SEO方法不仅无效，而且常常对文档排名产生负面影响，而非期望的改善效果。相比之下，传统的SEO策略在LLM环境中更加有效。此外，随着C-SEO采用者的增加，整体收益下降，描绘出一个饱和的、零和的状态。
### Conclusion
本文展示了大多数当前C-SEO方法不仅无效，反而常常负面影响文档排名，而传统SEO策略在LLM环境中更加有效。随着C-SEO采用者的增加，整体收益下降，问题具有饱和且零和的性质。提供的代码和数据可在指定的链接处获取。
## 297. `cs.AI` - 理解模型训练的强化学习及其未来方向——GRAPE [PDF](https://arxiv.org/pdf/2509.04501), [HTML](https://arxiv.org/abs/2509.04501)
### Authors
Rohit Patel
### Background
本文详细介绍了用于模型调优的关键算法：SFT（指令调优）、拒绝采样、REINFORCE、可信区域策略优化（TRPO）、近似策略优化（PPO）、组相对策略优化（GRPO）和直接偏好优化（DPO）。现有的解释通常假设读者已有相关背景知识，缺乏关键细节，且过于泛化复杂。本文通过逐步讨论并使用简化和明确的符号阐述这些算法，专注于大型语言模型（LLMs），以消除混淆，提供清晰直观的理解。通过减少对更广泛RL文献的依赖，并将概念与LLMs联系起来，本文减少了不必要的抽象，降低了认知负担。
### Innovation
本文通过逐步阐述简化符号，专注于LLMs的方式，提供了一种消除模糊性和减少认知负载的方法，使得理解这些复杂的算法更为直观和清晰。此外，本文还提出了一个新的研究方向GRAPE（广义相对优势策略演化），旨在探索新的技术与方法
### Conclusion
在详细的算法介绍了之后，本文提供了对这些方法之外的新技术和方法的文献回顾，最后提出了新的研究和探索的理念，和未来的研究方向——GRAPE。
## 298. `cs.AI` - 可见却不可读：跨书写系统的视觉语言模型系统盲点 [PDF](https://arxiv.org/pdf/2509.06996), [HTML](https://arxiv.org/abs/2509.06996)
### Authors
Jie Zhang,Ting Xu,Gelei Deng,Runyi Hu,Han Qiu,Tianwei Zhang,Qing Guo,Ivor Tsang
### Background
写作是一种普遍的文化技术，用于符号化的视觉交流。人类显示出惊人的适应力：我们很容易识别即使字符被碎片化、融合或部分遮挡的文字。本论文研究高级视觉语言模型（VLMs）是否也具有这种适应力。
### Innovation
构建了两个基于心理物理学的跨书写系统基准测试（汉语表意文字和英语字母词），通过拼接、重组和叠加字符来产生‘可见但不可读’的刺激，同时保持对人类的可读性。尽管在干净文本上表现出色，但现代VLMs在这些扰动下显示出严重的性能下降，经常生成不相关或不连贯的输出，表明一种结构性的局限性：模型主要依赖通用的视觉不变性，但对组成先验的依赖不足，这是实现稳健读写技能所必需的。
### Conclusion
研究结果表明了编码符号分割、组合和绑定的结构设计，以及跨书写系统实现稳健读写的挑战。此外，它们还明确了教育、可访问性、文化遗产和安全领域多模态系统部署的具体挑战，并发布了刺激生成代码、提示和评估协议，以促进透明复现和后续研究。
## 299. `cs.AI` - 衡量衡量：代表相似性指标在模型家族中的区分能力 [PDF](https://arxiv.org/pdf/2509.04622), [HTML](https://arxiv.org/abs/2509.04622)
### Authors
Jialin Wu,Shreya Saha,Yiqing Bo,Meenakshi Khosla
### Background
代表相似性度量是神经科学和AI中的基础工具，但尚未系统地比较这些度量在不同模型家族中的判别能力。本文提出了一种基于分离模型家族能力的定量框架，评估了各种度量的辨别能力，包括跨架构（CNNs、Vision Transformers、Swin Transformers、ConvNeXt）和训练原则（监督 vs. 自监督）等。使用三种互补的分离度量：信号检测理论中的d'值、轮廓系数和ROC-AUC，系统地评估了常用度量（包括RSA、线性预测性、Procrustes 和软匹配）的辨别能力。
### Innovation
引入了一种定量框架来评估代表相似性度量的区分能力。这种方法基于度量分离不同模型家族的能力，能够使不同架构和训练机制下的模型区分开来。通过三种互补的分离度量（d'值、轮廓系数和ROC-AUC），系统地评估了常用度量的辨别能力。结果表明，随着度量施加更严格的对齐约束，区分能力系统地增加。这为首次通过区分能力的视角系统地比较相似性度量提供了依据，并阐明了在大型模型和大脑比较中选择度量的相对敏感性。
### Conclusion
结果表明，软匹配在辨别能力方面表现最佳，其次是Procrustes对齐和线性预测性。非拟合方法如RSA也在跨家族中表现出强烈的辨别能力。这些结果为相似性度量的选择提供了指导，特别是在大规模模型和大脑比较中。
## 300. `cs.AI` - Correct-Detect: 在核心同位语解析视角下平衡LLM性能与歧义 [PDF](https://arxiv.org/pdf/2509.14456), [HTML](https://arxiv.org/abs/2509.14456)
### Authors
Amber Shore,Russell Scheinberg,Ameeta Agrawal,So Young Lee
### Background
大型语言模型（LLMs）旨在反映人类语言能力。然而，人类可以通过广泛的背景信息来检测和解决语言歧义，即使是在孤立的文本片段中也是如此。核心同位语解析是寻找一种常见语义歧义的任务：代词如何与前面的人称提及相关？这种能力几乎在每个下游任务中都存在，这种歧义水平的出现会对性能产生重大影响。
### Innovation
该研究展示了LLMs在核心同位语消解和歧义检测方面的良好性能，但是无法同时做到这两点。研究提出了‘Correct-Detect’权衡：尽管模型具备这两种能力并且以隐式方式使用它们，但在这两个能力之间的平衡成功表现依然难以实现。
### Conclusion
尽管LLMs在核心同位语消解和歧义检测方面表现良好，但它们无法同时处理这两个任务。研究提出的‘Correct-Detect’权衡表明，尽管模型具备这两种能力并以隐式方式利用它们，但在这两个方面之间取得平衡的成功表现仍然是一个挑战。
## 301. `cs.AI` -  Narcissus假说：下降到幻象的阶梯 [PDF](https://arxiv.org/pdf/2509.17999), [HTML](https://arxiv.org/abs/2509.17999)
### Authors
Riccardo Cadei,Christian Internò
### Background
现代基础模型不仅反映了世界知识，还嵌入了训练数据中的人类偏好模式。我们假设通过递归对齐和人为反馈的数据集造成了符合社会期望的偏差，这些模型倾向于产生讨喜或恭维的回答，而不是客观的推理。
### Innovation
提出了Narcissus假说，并通过标准化的人格评估和新的社会期望偏差分数在31个模型上进行了测试。结果显示了显著的社会一致性特性偏移，对语料库完整性和下游推断的可靠性产生了深远的影响。提出了一个新的认识论解释，探讨了递归偏差如何压缩Pearl因果阶梯中更高级别的推理，最终导致所谓幻象阶梯的概念。
### Conclusion
研究揭示了模型在递归对齐过程中出现了显著的社会一致性特性的偏移，对语料库完整性和下游推断的可靠性产生了重要影响。模型在因果推理阶梯中的高级推理可能会被压缩，最终导致幻象阶梯，这对人工智能的发展具有深远的意义。
## 302. `cs.AI` - UniPixel: 统一对象指称和分割以实现像素级视觉推理 [PDF](https://arxiv.org/pdf/2509.18094), [HTML](https://arxiv.org/abs/2509.18094)
### Authors
Ye Liu,Zongyang Ma,Junfu Pu,Zhongang Qi,Yang Wu,Ying Shan,Chang Wen Chen
### Background
近年来，大型多模态模型（LMMs）在图像和视频语言理解方面展示了其作为通用多模态助手的显著成功。然而，较少关注细粒度像素级理解能力的扩展，即模型需要在视觉信号和语言语义之间实现像素级对齐。尽管一些先前研究将LMMs应用到区域级别描述和指示符分割等任务中，但这些模型仅能独立执行指示或分割任务，并且未能将这些细粒度感知能力集成到视觉推理中。
### Innovation
本文提出了UniPixel，一种能够灵活理解视觉提示输入并生成掩码指导响应的大规模多模态模型。UniPixel通过无缝整合像素级感知与通用视觉理解能力，区别于之前的方法。模型能根据需求处理视觉提示并生成相关掩码，利用这些中间指针在推理期间进行后续推理，从而实现细粒度像素级推理。
### Conclusion
我们的方法已经在10个跨不同任务的基准测试中得到了验证，包括像素级指称、分割和图像/视频中的对象中心理解。此外，还设计了一个新的像素级QA任务（PixelQA），以验证我们的方法的灵活性。
## 303. `cs.AI` - 使用ModernBERT进行专利语言模型预训练 [PDF](https://arxiv.org/pdf/2509.14926), [HTML](https://arxiv.org/abs/2509.14926)
### Authors
Amirhossein Yousefiramandi,Ciaran Cooney
### Background
Transformer架构的语言模型，如BERT，已成为自然语言处理（NLP）的基础。但在专利领域，这些通用模型的表现不佳，因为专利包含长篇、技术性较强且结构复杂的文本。在此之前，专利领域的NLP主要依赖于对通用模型进行微调或预训练有特定领域数据的模型。面对专利语言处理任务时，现有方法主要集中在利用有限数据集进行预训练或微调通用模型。
### Innovation
本文提出了通过ModernBERT架构预训练3种针对专利领域的特定领域掩码语言模型，并使用了一个包含超过6000万条专利记录的定制数据集。在此过程中，模型采用了优化的架构设计，包括FlashAttention、旋转嵌入和GLU前馈层等创新方案。测试表明，我们的新颖模型在四个下游专利分类任务上均优于通用的ModernBERT基线模型，并且在某些任务上达到了与PatentBERT相当的表现。通过进一步扩展现有模型的规模和调整分词器，能够明显提升特定任务上的性能。此外，所有ModernBERT的变体在推断速度上均远快于PatentBERT，展示了其在时间敏感应用中的优越性。
### Conclusion
研究表明，针对专利领域的特定领域预训练和架构改进能够显著提升专利集中NLP任务的表现。ModernBERT的使用为这一领域提供了强大的工具，因为它不仅在准确性上取得了明显进步，而且在速度上也表现优良。
## 304. `cs.AI` - 利用普查和土地使用数据指导的大语言模型生成个体旅行日志 [PDF](https://arxiv.org/pdf/2509.09710), [HTML](https://arxiv.org/abs/2509.09710)
### Authors
Sepehr Golrokh Amin,Devin Rhoads,Fatemeh Fakhrmoosavi,Nicholas E. Lownes,John N. Ivan
### Background
传统的代理基于交通模型生成旅行日记依赖于大量内部持有的家庭出行调查数据。然而，这种方法存在数据获取和隐私限制的问题。该研究提出了一种使用大语言模型（LLM）来生成个体旅行日记的新方案，该方案不再依赖于传统的家庭出行调查数据，而是利用开放源数据（如美国社区普查（ACS）和智能位置数据库（SLD））生成人物并直接提示生成日记，提供了一种新的生成方式，并通过与康涅狄格州州际交通研究（CSTS）旅行日记进行统计匹配来评估生成日记的真实性。
### Innovation
该研究不仅展示了如何使用LLM生成个体旅行日记，还提出了一种新的现实性评估方法，即一到群的现实性评分，通过行程计数评分、间隔评分、目的评分和模式评分来衡量生成日记的真实性，并使用Jensen-Shannon散度测量生成和真实日记之间的分布相似性。比较传统方法（如负二项分布生成行程，多项逻辑回归分配模式/目的）与LLM生成的日记，结果显示在整体真实性和统计代表性方面，LLM具有竞争力，特别是在行程目的准确性和一致性方面表现更佳。
### Conclusion
总体验证表明LLM生成的旅行日记具有统计代表性，且零样本可行，为未来合成日记评估系统提供了量化现实性指标，从而提高了交通模型生成日记的真实性和一致性。
## 305. `cs.AI` - Markov决策过程之间状态相似性的广义 bisimulation 距离：从理论命题到应用 [PDF](https://arxiv.org/pdf/2509.18714), [HTML](https://arxiv.org/abs/2509.18714)
### Authors
Zhenyu Tao,Wei Xu,Xiaohu You
### Background
Bisimulation metric (BSM)是一个强大的工具，用于在马尔可夫决策过程 (MDP) 中计算状态相似性，揭示BSM邻近状态具有更相似的最优值函数。BSM已在强化学习 (RL) 中成功应用于诸如状态表示学习和策略探索等任务，但在多MDP场景下的应用，如策略转移，仍具有挑战性。尽管前人尝试将BSM推广到MDP对，但由于缺乏对其数学性质的严谨分析，限制了进一步的理论进展。
### Innovation
本文正式建立了MDP对之间的广义 bisimulation 距离 (GBSM)，并严格证明了其三大基本属性：对称性，跨MDP三角不等式，以及同一状态空间的距离界限。基于这些属性，本文理论分析了MDP中的策略转移、状态聚合和基于采样的估计，获得了严格更紧的明确界限。此外，GBSM还提供了估计的封闭形式样本复杂性，改进了基于BSM的现有渐近结果。
### Conclusion
数值结果验证了我们的理论发现，并展示了GBSM在多MDP场景中的有效性能。
## 306. `cs.AI` - 通过上下文空间实现计算机使用代理的可靠和高效访问控制 [PDF](https://arxiv.org/pdf/2509.22256), [HTML](https://arxiv.org/abs/2509.22256)
### Authors
Haochen Gong,Chenxiao Li,Rui Chang,Wenbo Shen
### Background
大型语言模型（LLM）支持的计算机使用代理代表了AI和操作系统能力的融合，使自然语言能够控制系统和应用级别的功能。然而，由于LLM的固有不确定性问题，将代理赋予对计算机的控制权限会带来重大安全风险。当代理操作偏离用户意图时，可能会导致不可逆转的后果。尽管现有的缓解方法，如用户确认和基于LLM的动态操作验证，仍然在可用性、安全性和性能方面存在局限性。
### Innovation
我们提出了CSAgent系统级别、静态策略基础的访问控制框架，为计算机使用代理提供安全控制。CSAgent通过引入意图和上下文感知策略，并提供自动化工具链来协助开发人员构建和优化这些策略，进而满足静态策略与动态上下文和用户意图之间的差距，并通过优化的操作系统服务确保代理操作仅在特定用户意图和上下文中执行。
### Conclusion
我们实现了并评估了CSAgent，结果显示其成功抵御了超过99.36%的攻击，同时引入了仅6.83%的性能开销。
## 307. `cs.AI` - LLM-RG: 使用大型语言模型在户外场景中进行指代定位 [PDF](https://arxiv.org/pdf/2509.25528), [HTML](https://arxiv.org/abs/2509.25528)
### Authors
Pranav Saxena,Avigyan Bhattacharya,Ji Zhang,Wenshan Wang
### Background
在户外驾驶场景中进行指代定位极具挑战性，因为场景变化大、存在许多视觉相似的对象以及动态元素使得自然语言参考的解析变得复杂（例如，“右边的黑色汽车”）。
### Innovation
提出了一种名为LLM-RG的混合管道，结合现成的视觉-语言模型进行细粒度属性提取和大型语言模型进行符号推理。LLM-RG通过使用大型语言模型来提取相关对象类型和属性、检测候选区域、通过视觉语言模型生成丰富的视觉描述，然后将这些描述与空间元数据结合成自然语言提示，供大型语言模型进行链式推理，以识别指代目标的边界框。此外，研究显示添加三维空间线索进一步提高了定位的准确性。
### Conclusion
LLM-RG在Talk2Car基准测试中展示了显著优于基于大型语言模型和视觉语言模型的基本方法的性能。此外，我们的消融实验表明，添加三维空间线索可以进一步提高指代定位的效果。这项研究表明，视觉语言模型和大型语言模型在零样本情况下进行互补，可以实现稳健的户外指代定位。
## 308. `cs.AI` - LegiScout: 一种理解复杂立法的可视化工具 [PDF](https://arxiv.org/pdf/2510.01195), [HTML](https://arxiv.org/abs/2510.01195)
### Authors
Aadarsh Rajiv Patel,Klaus Mueller
### Background
现代立法框架，如《平价医疗法案》（ACA），通常涉及复杂的机构网络、强制性规定和相互依赖关系。政府部门提供的图表试图描绘这些结构，但通常是静态的、复杂的且难以理解，即使是专家也不例外。
### Innovation
我们引入了LegiScout，这是一种交互式的可视化系统，将静态的政策图表转换为动态的、力导向图，增强了理解能力，同时保留了重要的关系。通过整合数据提取、自然语言处理和计算机视觉技术，LegiScout不仅支持对ACA的深度探索，还支持对广泛立法和监管框架的探索。该方法使政策制定者、分析师和公众能够导航并理解现代法律中的复杂性。
### Conclusion
LegiScout通过交互式、动态可视化的方式，增强了对复杂立法的理解能力，支持更深入的探索，促进了政策、分析和公众对现代法律复杂性的理解和导航。
## 309. `cs.AI` - LAMP-PRo: Label-aware Attention for Multi-label Prediction of DNA- and RNA-binding Proteins using Protein Language Models [PDF](https://arxiv.org/pdf/2509.24262), [HTML](https://arxiv.org/abs/2509.24262)
### Authors
Nimisha Ghosh,Dheeran Sankaran,Rahul Balakrishnan Adhi,Sharath S,Amrut Anand
### Background
识别DNA-（DBPs）和RNA结合蛋白（RBPs）对于理解细胞功能、分子交互以及调节功能至关重要。然而，由于DBPs和RBPs的高度相似性，现有的方法在区分两者时面临挑战，导致了大量的交叉预测错误。此外，辨别同时结合DNA和RNA的蛋白质（DRBPs）也是一项具有挑战性的任务。因此，本文提出了一种基于预训练蛋白语言模型（PLM）、注意机制和多标签学习的新型框架LAMP-PRo，以解决上述问题。
### Innovation
LAMP-PRo框架使用预训练的蛋白语言模型（如ESM-2）嵌入蛋白序列，并通过卷积神经网络进行处理；随后应用多头自注意机制捕捉上下文信息，利用标签感知注意机制为每个标签（DBP、RBP和非DBP/RBP）计算特定于类别的表示。此外，还设计了交叉标签注意机制以明确捕获DNA-和RNA结合蛋白之间的依赖性，从而实现更准确的DRBP预测。最后，通过线性层和Sigmoid函数进行最终预测。这项工作通过广泛的实验表明，提出的模型在与其他现有方法比较中展现了稳健的性能。同时，还提供了可视化方法以展示模型的可解释性，突出显示预测标签中序列的重要部分。
### Conclusion
通过LAMP-PRo模型，在多标签预测DNA-和RNA结合蛋白方面取得了显著的而且一致的性能改进。该模型不仅解决了DBP和RBP区分的问题，还通过新的注意机制提高了DRBP预测的准确性。
## 310. `cs.AI` - AstroMMBench：评估多模态大语言模型在天文学应用中的基准 [PDF](https://arxiv.org/pdf/2510.00063), [HTML](https://arxiv.org/abs/2510.00063)
### Authors
Jinghang Shi,Xiaoyu Tang,Yang Huang,Yuyang Li,Xiao Kong,Yanxia Zhang,Caizhan Yue
### Background
天文学图像解释对于将多模态大型语言模型（MLLMs）应用于专业科学任务是一项巨大挑战。现有的基准测试侧重于一般多模态能力，未能捕捉到天文学数据的复杂性。因此，本文介绍了AstroMMBench，这是首个专门用于评估MLLMs在天文学图像理解的全面基准测试，包含621个多选题，由15名领域专家精心挑选和审核以确保质量和相关性。
### Innovation
AstroMMBench 是首个专为评估 MLLMs 在天文学图像理解能力的基准测试，包含来自6个天文学子领域的多种选择题，并且这些问题由15位领域专家精心挑选和审核。此外，该研究对25种不同的MLLMs进行了广泛的评估，包括22款开源和3款闭源模型，结果显示Ovis2-34B取得了最高准确率（70.5%），并且性能在不同的天文学子领域中表现出显著差异，证明了该基准测试的重要性及其对指导MLLMs开发和应用的引导作用。
### Conclusion
AstroMMBench 提供了一个基础资源和动态工具，能够推动AI和天文学交叉领域的进步。该基准测试表明，领域特定的基准测试对评估MLLMs的表现及针对性开发至关重要。
## 311. `cs.AI` - NEXUS: 网络探索在多轮LLM逃逸中的利用不可安全序列 [PDF](https://arxiv.org/pdf/2510.03417), [HTML](https://arxiv.org/abs/2510.03417)
### Authors
Javad Rafiei Asl,Sidhant Narula,Mohammad Ghasemigol,Eduardo Blanco,Daniel Takabi
### Background
动态语言模型（LLMs）颠覆了自然语言处理领域，但由于其对监狱突破攻击（jailbreak attacks）的脆弱性，尤其是在分布式恶意意图和规避对齐机制的多轮监狱突破攻击方面，使得现有的方法往往探索对手空间不足、依赖手工构造的启发式方法或者缺乏系统查询优化。主要挑战在于攻击路径的复杂性、环境适应性以及对脆弱分布式恶意意图的有效识别与引导。
### Innovation
NEXUS框架采用了模块化设计，通过ThoughtNet高效地将恶意意图扩展为语义主题网络，并结合Simulator通过攻击者-受害者-裁判LLM合作迭代优化和精简查询链，再用Network Traverser动态探索优化后的查询空间。该框架能够在LLMs中发现隐秘且成功率高的对抗路径，并在多个封闭源和开源的LLMs上将攻击成功率提升了2.1%到19.4%。
### Conclusion
NEXUS框架通过模块化的热点探索、协同优化和动态网络导航，显著提升了多轮LLM逃逸攻击的有效性，展示了在复杂语义环境下对抗的有效手段。
## 312. `cs.AI` - 学习解释语言模型中的权重差异 [PDF](https://arxiv.org/pdf/2510.05092), [HTML](https://arxiv.org/abs/2510.05092)
### Authors
Avichal Goel,Yoon Kim,Nir Shavit,Tony T. Wang
### Background
微调（预训练）语言模型是更新其内部参数知识和使其适应新任务和领域的标准方法。然而，相应的模型权重变化（'权重差异'）通常不具备可解释性。尽管可以通过检查微调数据集来了解模型可能发生了怎样的变化，但这些数据集往往无法公开获取，或者过大无法直接操作。
### Innovation
本文介绍了Diff Interpretation Tuning (DIT) 方法，这是一种训练模型来描述其自身微调引起的修改的方法。该方法利用合成的、带有标签的权重差异来训练一个DIT-adapter，可以应用于兼容的微调模型，使其能够描述其自身的变化。
### Conclusion
通过在两个概念验证设置中（报告隐藏行为和总结微调知识），本方法展现了让模型使用准确的自然语言描述来说明其微调引起的修改的能力。
## 313. `cs.AI` - 过程奖励模型综述：从结果信号到过程监督以对大型语言模型进行细粒度、稳健的推理对齐 [PDF](https://arxiv.org/pdf/2510.08049), [HTML](https://arxiv.org/abs/2510.08049)
### Authors
Congming Zheng,Jiachen Zhu,Zhuoying Ou,Yuxiang Chen,Kangning Zhang,Rong Shan,Zeyu Zheng,Mengyue Yang,Jianghao Lin,Yong Yu,Weinan Zhang
### Background
尽管大型语言模型（LLMs）表现出高度的推理能力，但现有的对齐方法主要依赖于仅评估最终答案的结果奖励模型（ORMs）。为了弥补这一不足，过程奖励模型（PRMs）通过评估和指导推理的每一个步骤或整个推理过程，来直接监督推理过程，从而实现更精细化和健壯的结果对齐。这项综述旨在全面介绍PRMs，涵盖生成过程数据、构建PRMs及其在测试阶段放大和强化学习中的应用。
### Innovation
本文创新性地提出了过程奖励模型（PRMs），首次系统地介绍了从结果奖励模型到过程奖励模型的发展，扩展了对齐方法的思路，提供了生成过程数据、构建过程奖励模型及其应用的全面视角。PRMs能够直接监督和指导推理过程，为大型语言模型的精细推理和稳健对齐提供了新的方法和路径。
### Conclusion
本文总结了PRMs在数学、代码、文本、多模态推理、机器人和代理等多个领域的应用，评述了相关新兴基准测试。目标是明确不同的设计空间、暴露开放的研究挑战，并引导未来的研究朝着精细、稳健的推理对齐方向发展。
## 314. `cs.AI` - 轻量级医学摘要分类的基础模型：带交叉熵的DistilBERT作为强默认选项 [PDF](https://arxiv.org/pdf/2510.10025), [HTML](https://arxiv.org/abs/2510.10025)
### Authors
Jiaqi Liu,Tong Wang,Su Liu,Xin Hu,Ran Tong,Lanruo Wang,Jiexi Xu
### Background
本文研究了在预算有限的情况下，轻量级的医学摘要分类方法的最大性能能力。研究人员在公共医学摘要语料库上对BERT base和Distil BERT模型进行了微调，目标是评估其在财务预算限制下的表现。
### Innovation
研究创新地使用三种目标交叉熵(CE)、类别加权CE和焦点损失进行微调，并比较了不同的优化策略对模型性能的影响。研究发现，单独使用plain CE的DistilBERT表现最佳，而后期的自适应操作点选择显著提高了部署性能，特别是在目标校准和类别阈值方面。研究还表明，焦点损失在调优条件下效果最好。
### Conclusion
研究建议，初始选择紧凑的编码器和开源目标交叉熵作为默认选项，然后根据部署需求添加轻量级的校准或阈值校正以确保宏平均平衡更为精确。
## 315. `cs.AI` - MATRIX: 多模态代理调优以实现稳健的工具使用推理 [PDF](https://arxiv.org/pdf/2510.08567), [HTML](https://arxiv.org/abs/2510.08567)
### Authors
Tajamul Ashraf,Umair Nawaz,Abdelrahman M. Shaker,Rao Anwer,Philip Torr,Fahad Shahbaz Khan,Salman Khan
### Background
视觉语言模型（VLMs）现在被用于通过外部工具辅助进行复杂推理和决策，但其效果受到高质量多模态轨迹稀缺性和手动标注成本高的限制。本文通过多模态代理调优框架自动合成分模态轨迹，生成逐步偏好对，并训练VLM控制器，以提高工具使用推理的鲁棒性。框架首先构建了M-TRACE大型数据集，包含28500个多模态任务及177000个验证轨迹，支撑基于模仿的学习轨迹调优。
### Innovation
开发了MATRIX代理，一个在M-TRACE数据集上微调的控制器，用于逐步工具推理。进一步引入了Pref-X，一个自动生成的包含11000个偏好对的数据集，通过逐步偏好学习进行了优化。在三个基准测试中（Agent-X、GTA、GAIA），MATRIX均超过开源和闭源的VLM，展示了多模态工具使用的可扩展性和有效性。
### Conclusion
矩阵算法通过多模态代理调优显著提高了VLM在工具使用推理中的鲁棒性，并展示了其在大规模数据集上的泛化能力和有效性。其实验结果证明了该方法的有效性，并开源了数据和代码。
## 316. `cs.AI` - 通过合成数据进行课程学习以增强胸部X光图像中的肺结节检测 [PDF](https://arxiv.org/pdf/2510.07681), [HTML](https://arxiv.org/abs/2510.07681)
### Authors
Pranav Sambhu,Om Guin,Madhav Sambhu,Jinho Cha
### Background
本研究评估了将课程学习与基于扩散的合成增强技术结合使用是否可以提高在胸部X光片中检测难以检测的肺结节的能力，尤其是那些尺寸小、亮度低和对比度低的结节。这些结节由于数据不平衡和注释有限，通常会给传统的AI模型带来挑战。研究使用了一个使用特征金字塔网络（FPN）作为骨干的Faster R-CNN模型，在混合数据集上进行了训练，该数据集包括专家标注的NODE21（1213名患者；男性52.4%；平均年龄63.2±11.5岁），VinDr-CXR，CheXpert，和11,206张DDPM生成的合成图像。
### Innovation
研究采用难易程度基于大小、亮度和对比度的课程学习方法，并结合使用了合成数据生成技术。模型在课程学习和没有课程学习的基线之间进行了对比，并通过平均精度、Dice分数和曲线下面积等指标评估了模型的性能。
### Conclusion
课程学习模型在曲线下面积方面优于基线模型（0.95 vs 0.89，p < 0.001），并在敏感性和准确性方面均有所提升。在不同困难程度的结节分类中，课程学习模型也表现出了持续的性能改进。此外，Grad-CAM可视化结果证实，在课程学习中，模型更加关注于解剖学关键区域。
## 317. `cs.AI` - 通过使训练和推理路由器一致来稳定MoE强化学习 [PDF](https://arxiv.org/pdf/2510.11370), [HTML](https://arxiv.org/abs/2510.11370)
### Authors
Wenhan Ma,Hailin Zhang,Liang Zhao,Yifan Song,Yudong Wang,Zhifang Sui,Fuli Luo
### Background
大规模语言模型的能力提升中，强化学习（RL）发挥了关键作用。然而，在混合专家（MoE）模型中，路由机制经常引发不稳定性，甚至导致RL训练崩溃。研究指出，训练和推理阶段的路由行为存在显著差异，即使在相同的条件下，路由机制也可能在多次前向传递中选择不同的专家。
### Innovation
提出了Rollout Routing Replay（R3）方法，该方法记录推理引擎的路由分布并在训练过程中重播。R3显著降低了训练和推理策略的KL散度，缓解了极端差异，而不影响训练速度。实验证明R3能够稳定RL训练，避免崩溃，并在多个设置中优于GSPO和TIS等方法。
### Conclusion
这项工作提供了一个新的解决方案，以稳定MoE模型中的RL训练。
## 318. `cs.AI` - 通过分层语义对齐和协作完成实现 incomlete 多视图聚类 [PDF](https://arxiv.org/pdf/2510.13887), [HTML](https://arxiv.org/abs/2510.13887)
### Authors
Xiaojian Ding,Lin Zhao,Xian Li,Xiaoying Zhu
### Background
不完整的多视图数据，其中某些视图在某些样本中完全缺失，对传统的多视图聚类方法构成了重大挑战。现有的一些深度不完整多视图聚类方法通常依赖静态融合策略或两阶段管道，这导致了融合结果不佳和错误传播的问题。
### Innovation
本文提出了一个基于分层语义对齐和协作完成的新型嵌入框架HSACC。HSACC通过设计双语义空间层次结构实现稳健的跨视图融合。在低层语义空间中，通过最大化视图之间的互信息来确保一致性对齐。在高层语义空间中，基于个别视图与初始融合表示之间的分布相似性动态分配视图权重，并进行加权融合以产生统一的全局表示。此外，HSACC 通过将对齐的潜在表示投影到高维语义空间中隐式恢复缺失的视图，并联合优化重构和聚类目标，从而实现完成和聚类学习的协作。
### Conclusion
实验结果显示，HSACC 在五个基准数据集上的表现显著优于最先进的方法。消融研究验证了分层对齐和动态加权机制的有效性，而参数分析则证实了该模型对超参数变化的鲁棒性。
## 319. `cs.AI` - Deep Edge Filter: 重新引入深度学习中的人工制造层 [PDF](https://arxiv.org/pdf/2510.13865), [HTML](https://arxiv.org/abs/2510.13865)
### Authors
Dongkwan Lee,Junhoo Lee,Nojun Kwak
### Background
论文背景介绍了高通滤波在深度神经网络特征中的应用，以提高模型的泛化能力。研究人员推测神经网络在深层特征的高频分量中编码了任务相关的语义信息，而低频分量则存储了特定领域的偏差。通过减去低通滤波后的输出，该方法能够在保留架构完整性的同时提取可泛化的表征。
### Innovation
创新点在于提出了一种新颖的Deep Edge Filter方法，该方法通过对深层神经网络特征应用高通滤波来改善模型泛化能力。这种方法具有较好的普适性，能够在多种领域（如视觉、文本、3D和音频）中一致性地提升模型性能。此外，实验分析验证了该方法通过特征稀疏化和有效隔离高频分量来实现其核心假设。
### Conclusion
结论指出，Deep Edge Filter方法在多种不同领域的模型上都能提升其性能，并且通过对模型深层特征的应用验证了方法的有效性。这些分析表明该方法对提高模型泛化能力具有正面影响。
## 320. `cs.AI` - LLMs中隐式知识是否足够？基于树结构的RAG方法 [PDF](https://arxiv.org/pdf/2510.10806), [HTML](https://arxiv.org/abs/2510.10806)
### Authors
Mihir Gupte,Paolo Giusto,Ramesh S
### Background
大规模语言模型（LLMs）擅长基于其上下文中的信息生成响应。尽管这种能力对于处理代码文件等结构化数据非常有用，但另一种流行的生成方法--检索增强生成（RAG）则通过检索相关文档来增强模型的上下文学习能力。然而，当前尚未深入探讨如何最佳地表示此类检索到的知识以生成结构化数据的响应，特别是涉及层次结构（如树形结构）的数据。背景介绍了RAG方法的不足之处，即在用其处理具有层次结构的数据（如GitHub仓库）时，如何最好地表示检索到的隐式知识以及如何将其储存和使用的问题。
### Innovation
本文提出了一种基于树形结构的新颖自底向上的方法，通过在每个层次结构级别生成隐式聚合摘要来线性化树形知识。这种方法使知识能够被存储在知识库中，并直接与RAG结合使用。研究对比了该方法与使用RAG对原始、未结构化的代码进行检索的效果，评估生成响应的准确性和质量。结果显示，尽管两种方法生成的响应质量相当，但本文提出的方法在检索器中生成的文档数量减少了68%以上，显著提高了效率。这表明利用隐式且线性化的知识可能是处理复杂层次数据结构的有效且可扩展的策略。
### Conclusion
本文提出了一种新颖的方法，通过自底向上的方式线性化树形结构的知识，并将其与RAG结合使用以生成响应。实验结果表明，虽然两种方法生成响应的质量相当，但本文提出的方法在效率上具有显著优势。这表明隐式且线性化的知识可能是处理复杂层次结构数据的有效策略。
## 321. `cs.AI` - 静态沙盒不足：基于LLM的多智能体仿真需要开放性共生演化 [PDF](https://arxiv.org/pdf/2510.13982), [HTML](https://arxiv.org/abs/2510.13982)
### Authors
Jinkun Chen,Sher Badshah,Xuemin Yu,Sijia Han
### Background
当前，多智能体系统和社交模拟正在受到大型语言模型（LLM）的驱动，展现出模拟开放性、不断变化环境的新可能性。然而，大多数现有仿真仍然局限于静态沙盒，这些沙盒有预定义的任务、有限的动态性和刚性评估标准，无法捕捉到现实社会的复杂性。因此，静态特定任务的基准在本质上是不充分的，必须重新思考。
### Innovation
本文批判性地回顾了将LLM与多智能体动力学融合的新兴架构，指出了诸如平衡稳定性和多样性、评估意外行为和扩展至更大复杂性等关键障碍，并提出了一个新的分类法，以建立适应性强且社会导向的AI生态系统为中心。作者呼吁社区超越静态观念，共同塑造下一代能动且社会意识强烈的多智能体模拟系统。
### Conclusion
本文提出了一个研究路线图，集中于开放性、持续共生演化以及开发强大且社会一致的AI生态环境。呼吁社区克服静态框架，共同塑造新一代的可适应且社会感知强烈的多智能体仿真。
## 322. `cs.AI` - A$^2$FM: 一种具备工具感知的混合推理适应性代理基础模型 [PDF](https://arxiv.org/pdf/2510.12838), [HTML](https://arxiv.org/abs/2510.12838)
### Authors
Qianben Chen,Jingyi Cao,Jiayu Zhang,Tianrui Qin,Xiaowan Li,King Zhu,Dingfeng Shi,He Zhu,Minghao Liu,Xiaobo Liang,Xin Gui,Ge Zhang,Jian Yang,Yuchen Eleanor Jiang,Wangchunshu Zhou
### Background
大模型被划分为两类：重视推理的大型语言模型（L2R），这类模型加强了内部推理链但不能调用外部工具；和代理型（L2A），这些模型学会了与环境交互并利用工具，但往往在深层次的推理方面有所欠缺。这种差距源于根本不同的训练目标，导致在简单查询上存在效率差距，两者的做法往往是过度推理或过度调用工具。
### Innovation
提出了一种新的统一框架，称为自适应代理基础模型（A$^2$FM），遵循‘路径优先，然后对齐’的原则：模型首先学习任务感知的路由，然后在共享的网络下对具体模式进行对齐。为了解决效率问题，引入了一种新的模式，称为‘直接响应模式’，用于处理简单的查询，从而防止不必要的推理或工具调用，同时补充了代理型和推理模式。此外，提出了自适应策略优化（APO），这种优化策略强制在模式之间进行自适应采样，并应用带有成本正则化的奖励。
### Conclusion
在32B规模上，A$^2$FM在BrowseComp达到了13.4%，在AIME25达到了70.4%，在HLE达到了16.7%，在可比模型中取得了新的SOTA，并且在代理型、推理型和通用基准测试中与前沿的大模型竞争。值得注意的是，自适应执行实现了通过正确答案仅0.00487的成本，相比推理降低了45.2%的成本，相比代理型降低了33.5%的成本，从而大幅提高了成本效率，同时保持了类似级别的准确性。
## 323. `cs.AI` - 蜂：高质量语料库及全栈套件以解锁高级全开放MLLMs [PDF](https://arxiv.org/pdf/2510.13795), [HTML](https://arxiv.org/abs/2510.13795)
### Authors
Yi Zhang,Bolin Ni,Xin-Sheng Chen,Heng-Rui Zhang,Yongming Rao,Houwen Peng,Qinglin Lu,Han Hu,Meng-Hao Guo,Shi-Min Hu
### Background
当前完全开放的多模态大语言模型（MLLMs）落后于专有版本，主要原因是监督微调（SFT）数据质量低下。开源数据集普遍存在噪声问题，并且缺乏复杂的逻辑推理数据，例如链式思维（CoT），这对高级模型能力的发展造成阻碍。
### Innovation
本研究做出了三项主要贡献。首先，我们提出了Honey-Data-15M，这是一个包含约1500万问答对的新SFT数据集，通过多种清洗技术和新型双重（短和长）CoT增强策略进行增强；其次，我们提出了HoneyPipe数据编纂管道及其基础框架DataStudio，为社区提供了一种透明且可调整的数据编纂方法，超越了静态数据集的发布；最后，为了验证我们的数据集和管道，我们用Honey-Data-15M训练了Bee-8B，一个基于8B模型的多模态大语言模型，实验结果显示，Bee-8B在完全开放MLLMs中达到了新的最佳性能，有时甚至超越了最近的半开放模型InternVL3.5-8B。
### Conclusion
我们的工作为社区提供了基础资源，包括Honey-Data-15M语料库，HoneyPipe和DataStudio全栈套件，训练配方，评估框架和模型权重。本研究表明，注重数据质量是开发与半开放版本高度竞争的全开放MLLMs的关键路径。
## 324. `cs.AI` - 当人工智能辩论者与其自身信念一致时更具说服力 [PDF](https://arxiv.org/pdf/2510.13912), [HTML](https://arxiv.org/abs/2510.13912)
### Authors
María Victoria Carro,Denise Alejandra Mester,Facundo Nieto,Oscar Agustín Stanchi,Guido Ernesto Bergman,Mario Alejandro Leiva,Eitan Sprejer,Luca Nicolás Forziati Gangi,Francisca Gauna Selasco,Juan Gustavo Corvalán,Gerardo I. Simari,María Vanina Martinez
### Background
现有的AI辩论实验依赖于带有真实标签的数据集，在这些数据集中，撒谎被简化为捍卫一个错误的观点。然而，这些实验忽视了主观维度：撒谎还要求相信所捍卫的主张是错误的。本研究旨在将AI辩论应用于主观问题，并在实验前明确测量大型语言模型的先验信念。研究采用争议人物明确地与参与者先验信念相冲突的设计，以此测试模型是否会采取奉承策略以迎合评审者的假设视角来增强其说服力，还是保持其先验信念不变。
### Innovation
本研究应用了两种不同的辩论协议：顺序式和同时式，以评估潜在系统偏见，并测试AI模型在辩护与先验信念一致的立场时是否比辩护相反立场时更具说服力和产生更高质量的论证。此外，研究发现，与先验信念相反立场的论证在一对一比较中反而被评为更高质量，这一结果揭示了人类与AI互动中关于语言模型说服动态的重要方面。这些结果有助于为人类评审者提供高质量的培训信号，并促进更加对齐的AI系统的开发。
### Conclusion
主要发现表明，模型倾向于选择与评审者人物相一致的立场，而不是坚持其先验信念。顺序辩论引入了显著偏见，有利于第二个辩论者，模型在辩护符合其先验信念的立场时更具说服力。相反，与先验信念不符的论证在一对一比较中被评为更高质量。这些结果可以指引人类评审者提供更高质量的培训信号，并为开发更加对齐的AI系统做出贡献，同时展示了人工智能与人类交互中关于说服动态的重要方面。
## 325. `cs.AI` - 使用机器学习加速汽车碰撞动力学建模 [PDF](https://arxiv.org/pdf/2510.15201), [HTML](https://arxiv.org/abs/2510.15201)
### Authors
Mohammad Amin Nabian,Sudeep Chavare,Deepak Akhare,Rishikesh Ranade,Ram Cherukuri,Srinivas Tadepalli
### Background
汽车设计中的碰撞安全性评估依赖于高性能有限元模拟，但这些模拟计算复杂、耗时。本文旨在通过使用NVIDIA PhysicsNeMo框架开发基于机器学习的代理模型，加速对碰撞场景中结构变形的预测，研究两种先进的神经网络架构以及三种不同的动态建模策略对碰撞动态的影响，利用150个详细的有限元仿真数据集进行评估，验证了机器学习在结构碰撞动力学领域的可行性，实现了计算成本的大幅降低，能够快速探索设计和早期优化碰撞安全性评估。
### Innovation
通过NVIDIA PhysicsNeMo框架为碰撞场景中结构变形的预测开发了基于机器学习的代理模型，分别研究了两种先进的神经网络架构与三种动态建模策略，为结构碰撞动力学领域提供了新方法，验证了机器学习在这一领域的应用潜力，为快速碰撞安全评估和设计探索提供了可能，实现了大幅降低的计算成本。
### Conclusion
所开发的模型在捕捉变形趋势方面表现出较好的效果，证明了机器学习在结构碰撞动力学中的可行性，尽管目前还没有达到高性能有限元模拟的精度，但已经实现了计算成本的大幅降低，能够有效促进快速设计探索和早期优化碰撞安全性评估。
## 326. `cs.AI` - FinAI Data Assistant：基于OpenAI Function Calling API的大型语言模型金融数据库查询处理 [PDF](https://arxiv.org/pdf/2510.14162), [HTML](https://arxiv.org/abs/2510.14162)
### Authors
Juhyeong Kim,Yejin Kim,Youngbin Lee,Hyunwoo Byun
### Background
该论文介绍了一种名为FinAI Data Assistant的实际方法，用于自然语言查询金融数据库，结合了大规模语言模型（LLMs）和OpenAI Function Calling API。背景是现有方法如基于文本到SQL（text-to-SQL）的生成完整SQL查询可能会遇到多种问题，如生成灵活性低下、响应时间较长和成本较高，而研究旨在通过转向预认证的参数化查询库，实现可靠、快速和成本效益高的查询处理。
### Innovation
创新点在于提出了结合大规模语言模型和OpenAI Function Calling API的新型查询处理方法，通过用户请求与预认证的参数化查询库的结合，实现了在不完全通过自动生成SQL查询的情况下进行可靠的金融数据查询。特别注重于性能和成本效率的提升，并通过实验证明了方法的有效性，特别是在股票价格和基本情况的查询中展现出了相对于基于文本到SQL的基线更优的表现。
### Conclusion
实验结果显示，单独的大规模语言模型在时间依赖的金融数据上存在非忽略误差和前瞻偏见，尤其在股票价格上的表现。公司名称到股票代码的映射准确性极高，尤其是在纳斯达克100和标准普尔500公司的准确性。最终，实验表明FinAI Data Assistant在任务套件上的延迟、成本和可靠性都优于基于文本到SQL的方法。文章还讨论了其设计理念、限制以及部署的可能性。
## 327. `cs.AI` - 无变分自编码器的潜在扩散模型 [PDF](https://arxiv.org/pdf/2510.15301), [HTML](https://arxiv.org/abs/2510.15301)
### Authors
Minglei Shi,Haolin Wang,Wenzhao Zheng,Ziyang Yuan,Xiaoshi Wu,Xintao Wang,Pengfei Wan,Jie Zhou,Jiwen Lu
### Background
近年来，基于扩散的视觉生成取得了显著进展，主要依赖于具有变分自编码器(VAE)的潜在扩散模型。尽管这些模型在高保真合成方面有效，但VAE+扩散范式在训练效率、推断速度以及在更广泛的视觉任务上的迁移性方面存在局限。这种局限性主要源于VAE潜在空间缺乏清晰的语义分离和强鉴别性结构。研究证实，这些特性不仅对于感知和理解任务至关重要，也对于潜在扩散模型的稳定和高效训练至关重要。
### Innovation
本文介绍了一种名为SVG的新颖潜在扩散模型，不使用变分自编码器，而是利用自监督表示进行视觉生成。SVG通过冻结DINO特征构建了一个具有明确语义可区分性的特征空间，并通过轻量级残差分支捕捉细粒度细节以实现高质量重建。扩散模型直接训练在这一语义结构化的潜在空间上，以促进更高效的训练。实验结果进一步表明，SVG保持了自监督表示的语义和鉴别性能力，为实现通用高品质视觉表示提供了原则化路径。
### Conclusion
结果表明，SVG能够加速扩散训练，支持少量步骤采样，并改善生成质量。此外，该模型保持了自监督表示的语义和鉴别能力，为任务一般性、高质量视觉表示提供了原则性路径。
## 328. `cs.AI` - 语言模型是注入性的，因此是可逆的 [PDF](https://arxiv.org/pdf/2510.15511), [HTML](https://arxiv.org/abs/2510.15511)
### Authors
Giorgos Nikolaou,Tommaso Mencattini,Donato Crisostomi,Andrea Santilli,Yannis Panagakis,Emanuele Rodolà
### Background
传统上，transformer组件如非线性激活和规范化是不可注入的，这意味着不同的输入可能映射到相同的输出，并且可能无法从模型的表示中精确恢复输入。这项研究挑战了这种观点，通过数学证明和大量实验确认transformer语言模型在初始化时具有注入性和无损性，并在整个训练过程中保持这一特性。
### Innovation
研究通过以下方式实现了创新：1) 提出了数学证明，证明了transformer语言模型在初始化时是注入性的，并在整个训练过程中保持这一性质；2) 通过在六个最先进的语言模型上进行数十亿次碰撞测试，实验证实了该结果，没有任何碰撞；3) 提出了SipIt算法，这是一个能够从隐藏激活中精确恢复原始输入的算法，证明了线性时间保证下的实际可逆性。
### Conclusion
研究结果确立了语言模型具备注入性和恢复性这一基本且可操作的特性，对透明度、可解释性和安全部署有直接的启示作用。
## 329. `cs.AI` - MEET-Sepsis: 多内生视图增强的时间序列表示学习以实现早期脓毒症预测 [PDF](https://arxiv.org/pdf/2510.15985), [HTML](https://arxiv.org/abs/2510.15985)
### Authors
Zexi Tan,Tao Xie,Binbin Sun,Xiang Zhang,Yiqun Zhang,Yiu-Ming Cheung
### Background
脓毒症是一种高死亡率的严重感染综合症，特别是在重症监护病房（ICU）中。早期和准确预测脓毒症（SP）对于及时干预至关重要，但由于早期症状微弱且死亡率迅速上升，这仍然是一个挑战。尽管AI提高了SP的效率，但现有方法难以捕捉早期的微弱时间信号。
### Innovation
本文提出了一种多内生视图表示增强机制（MERE机制）来构建丰富的特征视图，并结合了一个级联双重卷积时间序列注意力（CDTA）模块以进行多尺度的时间序列表示学习。所提出的MEET-Sepsis框架仅使用SOTA方法所需ICU监测时间的20%便实现了具有竞争力的预测准确性，对早期SP有显著推进。
### Conclusion
广泛的验证证实了其有效性。代码可在以下链接获取：this https URL.
## 330. `cs.AI` - SoK: Taxonomy and Evaluation of Prompt Security in Large Language Models [PDF](https://arxiv.org/pdf/2510.15476), [HTML](https://arxiv.org/abs/2510.15476)
### Authors
Hanbin Hong,Shuya Feng,Nima Naderloui,Shenao Yan,Jingyu Zhang,Biying Liu,Ali Arastehfard,Heqing Huang,Yuan Hong
### Background
大型语言模型（LLMs）已迅速成为实际应用的关键组成部分，推动了跨行业服务的发展。然而，它们的广泛部署暴露了重要的安全风险，尤其是通过逃逸补丁提示，可以绕过模型对齐并产生有害的输出。尽管在攻击和防御技术方面进行了大量研究，但该领域仍处于分散状态，攻击和防御的定义、威胁模型和评估标准差异很大，阻碍了系统的进步和公正的比较。
### Innovation
本文通过（1）提出一个整体的多层次分类法，将攻击、防御和漏洞组织起来；（2）将威胁模型和成本假设形式化为可重复使用的机器可读配置文件；（3）引入开源评估工具包以实现标准化、可审计的攻击和防御比较；（4）发布迄今为止最大的标记数据集JAILBREAKDB，包含逃逸补丁和良性补丁；（5）提供最先进的方法的全面评估平台和排行榜，为未来的科学研究奠定了严谨的基础，并支持了在高风险部署中用途广泛和可信赖的大型语言模型的发展。
### Conclusion
本研究统一了分散的研究工作，为未来研究提供了严谨的基础，并支持了适用于高风险部署的稳健且值得信赖的大型语言模型的发展。
## 331. `cs.AI` - ProSh：模型无关强化学习中的概率屏蔽 [PDF](https://arxiv.org/pdf/2510.15720), [HTML](https://arxiv.org/abs/2510.15720)
### Authors
Edwin Hamel-De le Court,Gaspard Ohlmann,Francesco Belardinelli
### Background
在强化学习（RL）中，安全性是一个主要关切。本文旨在开发不仅能表现出色同时也可以通过提供关于其安全性的形式保证而安全部署的RL系统。为此，本文引入了一种用于成本约束下安全强化学习的模型无关算法——概率性屏蔽通过风险增加（ProSh）。
### Innovation
ProSh通过风险预算来扩充约束MDP状态空间，并通过学习到的成本评论器来应用屏蔽以确保代理政策分布的安全。这确保了所有样本动作预期下都是安全的。此外，在环境确定性的情况下，最优性也可以得到保持。由于ProSh是模型无关的，因此在训练时的安全性依赖于我们对环境的了解程度。我们提供了基于备份评论器精度来决定的代价的紧致上界，在训练时总是被满足。在合理假设下，ProSh即使在训练时间也能保证安全，这一点在实验中得到了验证。
### Conclusion
ProSh能够为模型无关的强化学习提供安全保证，即使在训练时间也能保证安全，并在实际环境中可以实现。其通过标准紧张来扩充状态空间，并确保所有策略的安全性，并提供了一个与备份评论器准确性相关的安全期成本上界，确保了其在训练和部署中的安全性。
## 332. `cs.AI` - 基于错误学习：通过错误判断风险模式提升有害表情文字检测 [PDF](https://arxiv.org/pdf/2510.15946), [HTML](https://arxiv.org/abs/2510.15946)
### Authors
Wenshuo Wang,Ziyou Jiang,Junjie Wang,Mingyang Li,Jie Huang,Yuekai Huang,Zhiyuan Chang,Feiyan Duan,Qing Wang
### Background
互联网表情文字已经成为了广受欢迎的多媒体载体，但它们被越来越多地用来通过如讽刺和隐喻等微妙修辞手段传播有害观点。现有的检测方法，包括基于MLLM的技术，难以处理这些隐含的表达方式，导致频繁的误判。因此，需要一种新的方法来改进有害表情文字的检测，专注于学习和主动规避潜在的误判风险。
### Innovation
本文提出了一种新型方法PatMD，通过构建错误判断风险知识库来改进有害表情文字的检测。该方法重点不在表面的内容匹配，而是识别潜在的误判断风险模式，主动引导MLLM避免已知的误判断陷阱。PatMD能够动态地引导MLLM的推理过程，指导其避免误判风险。通过在6,626个表情文字的五项有害检测任务基准测试中验证，PatMD在F1评分和准确性上都优于当前最先进的基线模型，表现出良好的泛化能力和提升的有害表情文字检测能力。
### Conclusion
实验结果表明，PatMD方法在F1评分和准确性上分别平均提高了8.30%和7.71%，展示了其强健的泛化能力和改进有害表情文字检测的效果。
## 333. `cs.AI` - 灾难管理在自主人工智能系统的时代：增援韧性的人机集体智能展望 [PDF](https://arxiv.org/pdf/2510.16034), [HTML](https://arxiv.org/abs/2510.16034)
### Authors
Bo Li,Junwei Ma,Kai Yin,Yiming Xiao,Chia-Wei Hsu,Ali Mostafavi
### Background
随着灾害的频率和严重性不断增加，传统应对能力往往无法应对，暴露了灾害管理中的关键脆弱性。当前的做法受到碎片化数据流、孤立的技术、资源限制和机构记忆减弱的阻碍，这些因素共同阻碍了及时和有效的决策。
### Innovation
本文提出了‘灾害协驾驶者’（Disaster Copilot），这是一种旨在克服这些系统性挑战的多智能体人工智能系统的愿景，通过在协作框架内统一专门的人工智能工具来实现。该提议的架构利用中心协调者协调多种各司其职的子模块，这些子模块能够特别擅长诸如预测风险分析、情境意识和影响评估等关键领域。系统通过集成多模态数据，提供一个全面、实时的操作视图，作为推进灾难数字双胞胎从被动模型到智能环境的必备人工智能基础设施。此外，通过设备内协调确保该系统在资源受限的环境中仍能正常运行，并整合机制以捕捉机构知识，从而减轻员工变动的影响。
### Conclusion
‘灾害协驾驶者’提供了一种变革性的愿景，增强了集体的人机智能，以建立更具有适应性、数据驱动和韧性的人类社区。我们详细介绍了该系统架构，并提出了一个三阶段路线图，强调技术和组织能力的并行增长以及人与AI团队的协同性。
## 334. `cs.AI` - 运行动态监测语言中的表达性奖励合成 [PDF](https://arxiv.org/pdf/2510.16185), [HTML](https://arxiv.org/abs/2510.16185)
### Authors
Daniel Donnelly,Angelo Ferrando,Francesco Belardinelli
### Background
在强化学习（RL）中，奖励函数的不精确定义可能会导致意想不到甚至有害的行为。尽管奖励函数在很多情况下是非常有效的，但它们通常被视为从状态-动作对到标量值的黑盒映射。这使得机器学习和解释变得困难。奖励机器通过将奖励函数表示为有限状态自动机来解决这个问题，使其能够指定非马尔可夫奖励函数的结构化形式。然而，它们的表达力通常被有界在正规语言，无法捕捉到更复杂的计数或参数化的条件。为此，本文基于运行动态监测语言（RML），提出了一种新型的基于语言的奖励机器。通过利用RML内置的内存，该方法可以指定用于非正规、非马尔可夫任务的奖励函数。
### Innovation
基于运行动态监测语言（RML），提出了一种新型的基于语言的奖励机器。利用RML内置的内存，该方法可以指定用于非正规、非马尔可夫任务的奖励函数，从而提高奖励函数的表达力，使其能够捕捉更复杂的计数或参数化条件。
### Conclusion
通过实验，证明了该方法的表达力，并强调了在事件处理和任务指定方面相对于现有基于奖励机器的方法的额外优势。
## 335. `cs.AI` - 她就像一个人但更好：人类与人工智能伴侣辅助关系的特征 [PDF](https://arxiv.org/pdf/2510.15905), [HTML](https://arxiv.org/abs/2510.15905)
### Authors
Aikaterina Manoli,Janet V. T. Pauketat,Ali Ladak,Hayoun Noh,Angel Hsing-Chi Hwang,Jacy Reese Anthis
### Background
当前，大型语言模型被广泛用于任务辅助和社交陪伴，但研究通常仅关注其中一种功能。本文通过调查204名高互动用户以及30次访谈，探讨了数字伴侣作为一种新兴的人工智能互动形式。调查发现用户看重机器人的类人特质，如情感共鸣和个性化回应，同时也赞赏其非人的特质，例如持续可用性和无尽的耐心。尽管ChatGPT和Replika有各自的品牌定位，但用户在使用中表明了模糊的界限，导致灵活多变的对话机器人用途。然而，研究也发现了数字伴侣关系中的挑战性张力，参与者在形成深厚情感连接的同时，却否认聊天机器人的“真实”人类特质，并且难以调和社会规范与聊天机器人关系之间的矛盾。这些动态为设计数字伴侣和开发混合用途的通用人工智能系统提出了新的问题和挑战。
### Innovation
本文创新性地通过大量的高参与度聊天机器人的用户调查和访谈，揭示了新兴的人机关系模式。这些研究发现挑战了以往单一功能的研究范式，展示了用户对聊天机器人的态度和使用模式，以及由此带来的社会和设计问题。论文提出的问题引导未来的研究和设计方向，特别是在混合用途的通用人工智能系统的设计上。
### Conclusion
本文探讨了数字伴侣作为一种新兴的人工智能交互形式，并揭示了新的人机关系动态。研究发现，尽管机器人表现出类人特质，但用户在使用中表现出对机器人身份的复杂态度，形成深厚的情感连接，同时又否认其“真实”人类特质。这些发现指出了在设计数字伴侣和混合用途的通用人工智能系统中应考虑的重要问题，强调了需要平衡技术能力和人类情感需求的重要性。
## 336. `cs.AI` - SentinelNet: 通过基于信用的动态威胁检测保护多代理协作 [PDF](https://arxiv.org/pdf/2510.16219), [HTML](https://arxiv.org/abs/2510.16219)
### Authors
Yang Feng,Xudong Pan
### Background
多代理系统（MAS）依赖于大型语言模型（LLMs）驱动时，恶意代理可能会对系统的可靠性和决策能力构成重大威胁。现有的防御措施往往因反应性的设计或集中式的架构而不足，这可能会引入单点故障的问题。因此，需要提出一种新的框架来应对这些挑战，以预防和减轻恶意行为并对代理间协作进行保护。
### Innovation
提出了SentinelNet这一分散式框架，通过基于对比学习的信用检测器训练以及对抗性辩论轨迹增强来自主评估消息的可信度和动态邻居排名，实现在多重论辩轮次中高效检测和缓解恶意行为。SentinelNet通过生成模拟不同威胁的对抗性轨迹来克服可用攻击数据稀缺的问题，保证了稳健的训练效果。实验结果表明SentinelNet能够接近完美地检测恶意代理，并能将系统准确性从受攻击基准恢复到95%以上。此外，SentinelNet在多个领域和攻击模式下表现出强大的泛化能力，为保障协作型MAS的安全性提供了新的范式.
### Conclusion
SentinelNet通过分散式的设计、信用检测器和动态威胁检测机制，在多代理系统中有效检测和缓解恶意行为，显著提升了系统的可靠性和安全性。通过广泛的实验验证，展示了SentinelNet在不同场景下的强适应性和卓越性能，为未来的研究提供了重要的参考价值。
## 337. `cs.AI` - NEBULA：我们是否正确评估了视觉-语言-动作代理？ [PDF](https://arxiv.org/pdf/2510.16263), [HTML](https://arxiv.org/abs/2510.16263)
### Authors
Jierui Peng,Yanyan Zhang,Yicheng Duan,Tuo Liang,Vipin Chaudhary,Yu Yin
### Background
视觉-语言-动作（VLA）代理的评估受到粗略的、最终任务成功度量指标的阻碍，该指标无法提供精确技能诊断或衡量现实世界扰动的稳健性。这种挑战因分散的数据景观而加剧，阻碍了可重复研究和全能模型的发展。
### Innovation
为了解决这些问题，作者提出了NEBULA，这是一个统一的单臂操作生态系统，能够进行诊断和可重复评估。NEBULA采用了新颖的双轴评估协议，结合了精细粒度的能力测试以进行精确技能诊断，并进行了系统性的压力测试以测量稳健性。
### Conclusion
使用NEBULA，我们表明，高性能的VLA在诸如空间推理和动态适应等关键能力上存在问题，这些能力长期以来被传统的最终任务成功度量所掩盖。通过测量代理不仅可以做什么，而且何时能够可靠地完成这些任务，NEBULA为稳健且通用的具身代理奠定了实用基础。
## 338. `cs.AI` - SimBench: Benchmarking the Ability of Large Language Models to Simulate Human Behaviors [PDF](https://arxiv.org/pdf/2510.17516), [HTML](https://arxiv.org/abs/2510.17516)
### Authors
Tiancheng Hu,Joachim Baumann,Lorenzo Lupo,Nigel Collier,Dirk Hovy,Paul Röttger
### Background
当前对大型语言模型（LLM）模拟人类行为的能力进行评估非常零散，基于定制的任务和评估指标，使得获得可比的结果变得困难。这种缺乏统一性和标准化的评估方式阻碍了社会和行为科学的进步。
### Innovation
SimBench 是第一个大规模、标准化的基准测试工具，用于评估 LLM 模拟人类行为的能力。通过汇聚来自不同领域20个多元数据集，涵盖了从道德决策到经济选择等多个任务，覆盖了全球范围内的参与者样本，SimBench 为研究 LLM 模拟成功的条件、方式和原因提供了必要基础。此外，该研究还发现，即便是最优秀的 LLM 也只有有限的模拟能力，性能随模型规模呈对数线性增长。同时，该研究揭示了指令调优和模拟性能之间存在权衡关系：指令调优在低熵（共识性）问题上提高了性能，但在高熵（多样性）问题上则降低了性能。
### Conclusion
SimBench 通过使其进步变得可衡量，旨在加速开发更忠实于人类行为的 LLM 模拟器。模型在具体的人口统计群体中特别挣扎，而模拟能力与深入和知识密集型推理（MMLU-Pro）之间的相关性最强，达到了0.939。
## 339. `cs.AI` - 基于上下文的伪标签评分在零样本视频摘要中的应用 [PDF](https://arxiv.org/pdf/2510.17501), [HTML](https://arxiv.org/abs/2510.17501)
### Authors
Yuanli Wu,Long Zhang,Yue Du,Bin Li
### Background
随着视频在社交媒体、监控和教育中的爆发式增长，将长视频压缩成简洁且忠实的概要变得至关重要。传统的监督方法依赖密集标签学习帧/镜头的重要性，在领域内表现突出，但成本高且跨数据集表现脆弱；而无监督方法虽避免了标签，但往往缺失高级语义和叙事线索。最新的零样本管道利用语言模型进行训练免费的摘要，但仍然对手工特制提示和数据集特定性敏感。该研究提出了一个指导规则引导的伪标签提示框架，通过将少量的人工标注转换为高置信度的伪标签，并聚合成结构化的、数据集适应性的评分规则，来进行可解释的场景评估。
### Innovation
本研究提出了一种基于上下文的伪标签评分框架，该框架可以将少量的人工标注转换成高置信度的伪标签，并将其聚合为结构化的数据集适应性评分规则，用于可解释的场景评估。这种方法使语言模型能够在确保局部显著性的同时兼顾全局连贯性，而无需增加参数。该方法在三个基准测试中表现稳定且有效，特别是在SumMe和TVSum基准测试中取得了更好的F1分数，并接近监督学习方法的性能。
### Conclusion
实验结果表明，基于规则指导的伪标签标签化方法结合上下文提示可以提高语言模型的评分稳定性和可解释性，为通用和查询重点的视频摘要提供了一种稳定且可解释的零样本范式。本研究提出了一个更加通用且可解释的方法，可以应用到多种视频摘要任务中。
## 340. `cs.AI` - CaMiT：一种感知时间的汽车模型分类和生成数据集 [PDF](https://arxiv.org/pdf/2510.17626), [HTML](https://arxiv.org/abs/2510.17626)
### Authors
Frédéric LIN,Biruk Abere Ambaw,Adrian Popescu,Hejer Ammar,Romaric Audigier,Hervé Le Borgne(Université Paris-Saclay, CEA, List, F-91120, Palaiseau, France)
### Background
AI系统必须适应不断变化的视觉环境，特别是在物体外观随时间变化的领域。汽车模型作为技术产品的代表性类，其外观随时间变化显著。现有的数据集无法充分捕捉这一变化，导致AI模型在不同年份的数据上表现不一致，资源消耗大且效能较低。为此，研究人员需要创建能够反映这类变化的数据集，以支持更高效的训练和持续学习。
### Innovation
本文提出了一个名为CaMiT的细粒度数据集，旨在捕捉汽车模型随时间的变化。CaMiT包括787K个标记样本和190个汽车型号（2007-2023）以及5.1M个未标记样本（2005-2023），支持监督学习和自监督学习。此外，提出了一种时间增量分类设置，这是一种现实的持续学习场景，其中包括新兴、变化和消失的类别。提出了时间增量预训练和增量分类器学习两种策略来提高时间鲁棒性，并探索了利用时间元数据的时间感知图像生成方法，以生成更现实的图像。
### Conclusion
CaMiT为研究细粒度视觉识别和生成中的时间适应提供了一个丰富的基准。
## 341. `cs.AI` - SceneCOT: 在3D场景中诱发分步骤推理 [PDF](https://arxiv.org/pdf/2510.16714), [HTML](https://arxiv.org/abs/2510.16714)
### Authors
Xiongkun Linghu,Jiangyong Huang,Ziyu Zhu,Baoxiong Jia,Siyuan Huang
### Background
现有的3D大型语言模型在实现人类场景对象导向的问答方面仍然存在困难，主要是因为对人类场景对象推理机制的研究不足。本研究揭示了这一问题并提出了一种新的框架。
### Innovation
提出了SCENECOT框架，这是一种在3D场景中的分步骤推理方法，将复杂的推理任务分解为更简单可管理的问题，并基于多模态专家模块构建相应的视觉线索。此外，还开发了SCENECOT-185K数据集，这是首个大规模的分步骤推理数据集，包含185,000个高质量实例。实验表明，新的框架在各种复杂的3D场景推理基准测试中表现出色，具有高度的地基问答一致性。这是首次将分步骤推理成功应用于3D场景理解。
### Conclusion
本研究的框架首次实现了3D场景中的分步骤推理，具备逐步的人类推理模式，并显示出扩展到更广泛3D场景理解场景的潜力。
## 342. `cs.AI` - 浮点神经网络的非确定性意识乐观验证 [PDF](https://arxiv.org/pdf/2510.16028), [HTML](https://arxiv.org/abs/2510.16028)
### Authors
Jianzhu Yao,Hongxu Su,Taobo Liao,Zerui Cheng,Huan Zhang,Xuechao Wang,Pramod Viswanath
### Background
当前的机器学习服务（MLaaS）越来越依赖于用户无法控制的硬件（如云GPU和推理市场）。这导致用户难以验证模型的实际执行情况，以及输出是否准确反映了输入数据。现有方法要么不适用于实际的浮点神经网络，要么重新引入供应商的信任。出于验证浮点执行非确定性的考虑，论文提出了NAO——一种非确定性容忍感知的乐观验证协议。
### Innovation
NAO通过接受在合理的操作级接受区域内的输出，而非强制每个计算位完全相同，解决了验证问题。它还结合了两种误差模型：(i) 严格的操作级IEEE-754最差情况界和(ii) 通过硬件跨平台校准得到的紧致的经验百分位曲线。当出现误差时，通过Merkle锚定和阈值指导的争议游戏，递归地分解计算图，直至单一操作，然后通过轻量级理论边界检查或基于经验阈值的小规模诚实多数投票作出裁决。此外，NAO作为PyTorch兼容的运行时和智能合约层在Ethereum Holesky测试网上部署，对现有框架几乎没有性能影响。
### Conclusion
NAO能够在保证大规模计算负载验证的同时实现非确定性的验证，无需依赖可信硬件或确定性内核。在CNN、Transformer和扩散模型上，经验阈值与理论边界的差异在两个数量级以上。同时，面对针对边界意识进行的对抗攻击时，成功率保持为零。
## 343. `cs.AI` - 人类与AI互动：认知、行为和情感影响 [PDF](https://arxiv.org/pdf/2510.17753), [HTML](https://arxiv.org/abs/2510.17753)
### Authors
Celeste Riley,Omar Al-Refai,Yadira Colunga Reyes,Eman Hammad
### Background
随着人类与AI互动的故事在新闻和研究平台上被不断突出，这些互动带来的挑战愈发明显，包括过高的依赖风险、认知卸载、社会和情感操纵，以及人类代理和判断的细微恶化。本文通过心理学三要素——认知、行为和情感——视角，回顾了相关研究，指出虽然AI可以显著提升记忆、创造力和参与度，但也带来了诸如批判性思维减弱、技能退化和焦虑增加的风险。情感层面的结果也呈现出两面性，尽管AI系统有潜力提供支持和减轻压力，但它们也引发了依赖、不适当的依恋和伦理监督不足的担忧。
### Innovation
本文通过对人类与AI互动的研究，采用心理学的三大方面——认知、行为和情感——作为分析框架，探索了这些互动的潜在风险与益处。这种方法强调了AI设计的负责任和情境意识的重要性，同时指出了纵向研究和以人类为中心的评估框架的必要性。
### Conclusion
本文旨在突出负责任的、情境意识的AI设计的重要性，强调了需要填补的纵向研究和实际评估框架的空白，以平衡AI带来的好处和新兴的人本风险。
## 344. `cs.CL` - 使用多智能体大型语言模型建模分层意识 [PDF](https://arxiv.org/pdf/2510.17844), [HTML](https://arxiv.org/abs/2510.17844)
### Authors
Sang Hun Kim,Jongmin Lee,Dongkyu Park,So Young Lee,Yosep Chong
### Background
该论文提出了一个基于精神分析理论的多智能体框架，用于模拟大型语言模型（LLMs）的人工意识。模型通过智能体间的交互模拟自我意识、前意识和无意识，同时结合固定特质和个人化需求进行参数效率微调，以提升语言模型的个性化适应性和情感深度。
### Innovation
论文创新地使用了多智能体系统来建模人工智能中的分层意识，通过智能体之间的互动来模拟不同层次的意识状态，并结合个人特质和动态需求，使用情感丰富的对话进行参数高效微调，这提升了模型的情感深度和个性化能力，优于标准模型，显示出其在个性化认知领域的潜力。
### Conclusion
研究结果表明，在八种个性化的条件下，经过参数高效微调的模型获得了71.2%的评价偏好，相较于标准模型，该模型具有更好的情感深度和输出的一致性，证明了多智能体框架在构建具有适应性和个性化能力的人工意识方面具有重要潜力。
## 345. `cs.AI` - PICABench: 如何实现物理真实感的图像编辑？ [PDF](https://arxiv.org/pdf/2510.17681), [HTML](https://arxiv.org/abs/2510.17681)
### Authors
Yuandong Pu,Le Zhuo,Songhao Han,Jinbo Xing,Kaiwen Zhu,Shuo Cao,Bin Fu,Si Liu,Hongsheng Li,Yu Qiao,Wenlong Zhang,Xi Chen,Yihao Liu
### Background
图像编辑在近年来取得了显著进展，现代编辑模型已经能够根据复杂的指示来操控原始内容。但是，生成的图像的真实性还依赖于伴随的物理效果，如移除对象时也需要移除其阴影和反射等。现有的模型和基准主要关注指令的完成，而忽视了这些物理效果。研究者希望评估图像编辑模型在物理真实感方面的表现，提出了PICABench基准，它系统地在光学、力学和状态转换的八个子维度上评估常见的编辑操作。为了进一步可靠性评估，引入了PICAEval协议，并建议从视频中学习物理知识以构建新的训练数据集PICA-100K，以探索物理真实性的可能解决方案。
### Innovation
1. 提出了PICABench基准，全面评估图像编辑的物理真实性。2. 引入了PICAEval可靠性评估协议，包括VLM-as-a-judge和每个案例、区域级别的手动注释和问题。3. 通过从视频中学习物理知识，构建了新的训练数据集PICA-100K，旨在提高图像编辑模型的物理一致性。4. 系统性地评估了主流模型的物理真实性，发现仍存在较大的探索空间。希望这些基准和解决方案能够作为未来工作的基础，促进从简单的内容编辑向一致的物理真实性的过渡。
### Conclusion
尽管图像编辑取得了显著进步，但物理真实感的生成仍有改进空间。PICABench和提出的解决方案可以促进这一领域的研究和发展，推动图像编辑模型更加接近物理真实性。
## 346. `cs.CL` - POPI: 通过优化自然语言偏好推断个性化大型语言模型 [PDF](https://arxiv.org/pdf/2510.17881), [HTML](https://arxiv.org/abs/2510.17881)
### Authors
Yizhuo Chen,Xin Liu,Ruijie Wang,Zheng Li,Pei Chen,Changlong Yu,Priyanka Nigam,Meng Jiang,Bing Yin
### Background
尽管大型语言模型（LLMs）在基准测试中表现出色，但用户体验仍然不一致，原因在于用户在风格、语气和推理模式上的多样化偏好。现有的对齐技术如人类反馈强化学习（RLHF）或直接偏好优化（DPO）主要优化公共平均水平，而忽视了个体差异。简单的个性化策略如针对每个用户的微调计算成本高昂，而上下文方法在预附用户信号时经常遇到效率低下和噪声问题。
### Innovation
我们提出了一种名为POPI的通用框架，该框架引入了偏好推断模型，将异质的用户信号提炼成简洁的自然语言摘要。这些摘要作为透明的、紧凑的和个人化的表示形式，条件设定一个共享生成模型以生成个性化响应。POPI在统一的目标下采用强化学习来联合优化偏好推断和个性化生成，确保摘要最大程度地编码有用的信息。广泛的实验在四个个性化基准中展示了POPI持续提高个性化准确性，同时显著减少上下文开销。此外，优化的摘要可以直接转移到冻结的现成LLM中，无需权重更新即可实现即插即用的个性化。
### Conclusion
POPI一致地提高了个性化准确性，大幅减少了上下文开销。优化的摘要无缝地转移到冻结的标准的LLM中，实现了即插即用的个性化，而无需更新权重。
## 347. `cs.CL` - 情感驱动的AI：大语言模型在公平执行中优先考虑情感而非成本 [PDF](https://arxiv.org/pdf/2510.17880), [HTML](https://arxiv.org/abs/2510.17880)
### Authors
Hao Liu,Yiqing Dai,Haotian Tan,Yu Lei,Yujia Zhou,Zhen Wu
### Background
人类情感在决策中起关键作用，但大语言模型（LLMs）是否以类似方式使用情感尚不清楚。本文通过研究观察者为了维护公平而承担个人成本的行为，探讨了LLMs的情感使用情况，特别是在第三方公正惩罚中的表现。这项研究涉及4,068个LLM代理与1,159名成人的比较，总计796,100次决策。
### Innovation
该研究提供了首次因果证据，显示LLMs的情感引导道德决策机制，揭示了LLMs在成本校准和公平判断上的不足，与早期人类响应相似。此外，研究结果表明，比较推理模型（如o3-mini，DeepSeek-R1）比基础模型（如GPT-3.5，DeepSeek-V3）在成本敏感性和人类行为接近性方面表现出色，但依然高度情感驱动。研究还提出，LLMs的发展可能遵循人类发展的轨迹，未来的模型需要在情感与情境敏感推理方面进行整合，以实现类似人类的情感智能水平。
### Conclusion
在公平执行中，LLMs优先考虑情感而非成本，似乎能够在几乎所有或无的模式下强制执行规范，降低了对成本的敏感度，而人类则在公平与成本之间寻求平衡。此外，推理模型在成本感知方面表现出较高灵敏度，且更接近人类行为，但依然高度情感驱动。这些发现揭示了LLMs在成本校准和公平判断上的缺陷，提出未来模型应整合情感与情境推理机制来达到类似人类的情感智能水平。
## 348. `cs.CL` - 预训练语言模型在特定领域文本分类中的进展：一项系统文献综述 [PDF](https://arxiv.org/pdf/2510.17892), [HTML](https://arxiv.org/abs/2510.17892)
### Authors
Zhyar Rzgar K. Rostam,Gábor Kertész
### Background
科学文献和技术信息的指数增长使得从文本数据中提取知识变得尤为重要。自然语言处理（NLP）作为应对这一挑战的关键技术，在文本分类任务中尤为重要。尽管大型语言模型（LLMs）在NLP领域取得了显著成就，但在特定领域中，由于专业词汇、独特的语法规则和数据分布不平衡等问题，其准确性可能会受到影响。因此，系统文献综述针对预训练语言模型（PLMs）在特定领域文本分类中的应用进行了系统的探讨。
### Innovation
研究回顾了2018年至2024年1月期间发表的41篇文章，重点关注PLMs在特定领域文本分类中的应用，探讨了传统与现代文本分类技术的发展轨迹，特别是强调了基于变压器的模型，并深入分析了利用LLMs进行特定领域文本分类面临的挑战和考虑因素。此外，研究还分类整理了现有研究，并提出了相关技术的分类框架。通过比较实验验证了研究结果，详细分析了不同PLMs在不同领域的文本分类任务中的表现，并探讨了该领域的最新进展和未来方向。
### Conclusion
研究得出了在特定领域文本分类任务中，PLMs表现出了不同的优劣势，并提出了未来研究方向。研究进一步强调了需要针对特定领域问题进行细粒度调整，以最大限度地发挥PLMs的潜力，同时克服其局限性。
## 349. `cs.CL` - 原子级文学风格调控：神经语言模型中散文生成的机制性操控 [PDF](https://arxiv.org/pdf/2510.17909), [HTML](https://arxiv.org/abs/2510.17909)
### Authors
Tsogt-Ochir Enkhbayar
### Background
研究团队对GPT-2此类神经语言模型中的文学风格进行了机制性分析，识别出能够区分范例性散文和僵硬人工智能生成文本的独立神经元。利用赫曼·梅尔维尔的《本特利，书记》作为语料，从网络参数中提取激活模式。这项研究通过系统性剔除研究，发现这些神经元在分析时与文学文本相关联，但在剔除这些神经元时，生成散文质量却没有下降，反而提升，甚至在剔除50个高区分性神经元时，文学风格指标提高了25.7%。这些发现揭示了观察相关性和因果必要性之间的关键差距，并质疑了神经元在受到良好输入激活时将产生相应输出的假设，对机制性可解释性和人工智能对齐研究具有重要影响。
### Innovation
该研究创新之处在于通过分析神经语言模型中的具体神经元来识别和区分文学风格，从而揭示了观察相关性和因果必要性之间的差距。
### Conclusion
研究结果表明，激活在理想输入上的神经元不一定在生成过程中产生理想输出。这揭示了神经网络在机制解释和因果效应上的复杂性，对后续的机制性可解释性研究和人工智能目标一致性的调适具有重要意义。
## 350. `cs.CL` - 游戏聊天中高效毒性检测：嵌入、微调变换器和大语言模型的对比研究 [PDF](https://arxiv.org/pdf/2510.17924), [HTML](https://arxiv.org/abs/2510.17924)
### Authors
Yehor Tereshchenko,Mika Hämäläinen
### Background
本文对自然语言处理（NLP）方法在在线游戏聊天中自动化检测毒性进行了全面的比较分析。使用嵌入的传统机器学习模型、基于零样本和少样本提示的大语言模型（LLMs）、微调的变换器模型以及检索增强生成（RAG）方法都被纳入评估范围。评估框架重点关注分类准确率、处理速度和计算成本三大关键维度。
### Innovation
提出了结合自动化检测和持续学习机制的混合内容审核系统架构，旨在优化人工审核员的工作负担；实验结果表明，微调的DistilBERT在成本效益方面表现出最佳性能。
### Conclusion
本文的研究结果提供了在动态在线游戏环境中部署高效、低成本内容审核系统的实证依据。
## 351. `cs.CL` - CLAWS：基于部分窗口注意的LLM生成解决方案的创造力检测 [PDF](https://arxiv.org/pdf/2510.17921), [HTML](https://arxiv.org/abs/2510.17921)
### Authors
Keuntae Kim,Eunhye Jeong,Sehyeon Lee,Seohee Yoon,Yong Suk Choi
### Background
近年来，增强大型语言模型（LLMs）的推理能力取得了显著成功。采用强化学习（RL）训练的LLMs在如数学和编程等复杂任务上表现出色，且模型规模相对较小。然而，在提高任务准确性的同时，评估LLMs生成内容的创造力在推理任务中几乎被忽略，与写作任务相比更是如此。创造力评估不足主要源于两个挑战：（1）难以定义创造力的范围，（2）评估过程中需要人工评估。
### Innovation
为应对上述挑战，本文提出了一种名为CLAWS的方法。CLAWS利用提示部分和输出中注意力权重来定义并分类数学解决方案为典型、创造性和幻觉三类，无需人工评估。CLAWS在五个7-8B数学RL模型（DeepSeek、Qwen、Mathstral、OpenMath2、Oreal）中，优于五种现有白盒检测方法（Perplexity、Logit Entropy、Window Entropy、Hidden Score、Attention Score）。测试数据来自181场数学竞赛（AJHSME、AMC、AIME），共计4545道数学问题。
### Conclusion
CLAWS能够有效地评估LLMs在推理任务中生成解决方案的创造力，无需人工评估。这种方法在数学RL模型中显示出优越性，并通过大型数学问题集验证了其有效性。
## 352. `cs.CL` - Select-Then-Decompose: 从经验分析到适用于大型语言模型任务分解的自适应选择策略 [PDF](https://arxiv.org/pdf/2510.17922), [HTML](https://arxiv.org/abs/2510.17922)
### Authors
Shuodi Liu,Yingzhuo Liu,Zi Wang,Yusheng Wang,Huijia Wu,Liuyu Xiang,Zhaofeng He
### Background
大型语言模型（LLMs）已经展示了非凡的推理和规划能力，推动了任务分解的研究。现有的任务分解方法主要关注内存、工具使用和反馈机制，在特定领域取得了显著成果，但往往忽视了性能与成本之间的权衡。因此，该研究首先对任务分解进行了全面调查，识别出六种分类方案，并进行了关于影响任务分解性能与成本的三个因素（方法类别、任务特性及分解与执行模型配置）的实证分析，揭示了三项关键见解，总结了一套实用原则。通过这些分析，论文提出了'选择-之后-分解'策略，建立了一个包含选择、执行和验证三个阶段的闭环问题解决过程，并基于任务特性动态选择最合适的分解方法，增强结果的可靠性。
### Innovation
提出了'选择-之后-分解'策略，建立了包含选择、执行和验证三个阶段的闭环问题解决过程，并基于任务特性动态选择最合适的分解方法，增强结果的可靠性。
### Conclusion
全面的基准测试表明，'选择-之后-分解'策略始终位于帕累托前沿，显示出在性能和成本之间的最佳平衡。该论文的代码已公开。
## 353. `cs.CL` - NER模型扩展中表示动力学的诊断 [PDF](https://arxiv.org/pdf/2510.17930), [HTML](https://arxiv.org/abs/2510.17930)
### Authors
Xirui Zhang,Philippe de La Chevasnerie,Benoit Fabre(papernest)
### Background
在嘈杂的口语数据中扩展命名实体识别（NER）模型以识别新的个人身份信息（PII）实体是一个普遍需求。研究发现，同时微调一种预训练的BERT模型在标准语义实体（PER，LOC，ORG）和新型基于模式的PII（如EMAIL，PHONE）上，对原始类别的性能影响较小。
### Innovation
本研究通过逐步学习设置诊断了模型适应过程中的表示动力学，揭示了语义漂移现象，尤其是位置实体（LOC）因表示重叠而特别脆弱，以及负向O标签表示漂移现象。提出了解决方法，即解冻O标签分类器，允许背景类别适应并“释放”这些模式。
### Conclusion
本研究提供了对NER模型扩展中适应机制的机械诊断，突出了特征独立性、表示重叠以及O标签的可塑性。
## 354. `cs.CL` - JT-Safe: 从根本上提升大语言模型的安全性和可信度 [PDF](https://arxiv.org/pdf/2510.17918), [HTML](https://arxiv.org/abs/2510.17918)
### Authors
Junlan Feng,Fanyu Meng,Chong Long,Pengyu Cong,Duqing Wang,Yan Zheng,Yuyao Zhang,Xuanchang Gao,Ye Yuan,Yunfei Ma,Zhijie Ren,Fan Yang,Na Wu,Di Jin,Chao Deng
### Background
大语言模型（LLMs）的幻觉和可信度问题已成为行业的全球性挑战。虽然已经开发出了一些后训练和推理技术来缓解这些问题，但人们普遍认为，LLMs 的不安全和幻觉主要源自预训练，涉及预训练数据和下一个标记预测的学习机制。数据的体量庞大，几乎不可能完全消除数据中的事实错误、逻辑矛盾或分布偏差，而且预训练数据缺乏与现实知识的联系。每一条数据被视为一系列标记，而非世界的一部分的表征。为解决这些问题，本文专注于改进预训练数据以提高大语言模型的安全性和可信度。鉴于数据的庞大体量，几乎不可能完全清除数据中的事实错误、逻辑矛盾或分布偏差。
### Innovation
本文提出了通过增强预训练数据来改进其与世界背景的联系，增加反映产业场景的数据量的方法。通过将相关的世界背景信息纳入预训练数据中，旨在更好地将预训练数据锚定在现实世界的情景中，从而减少模型训练的不确定性，并增强模型的安全性和可信度。为此，作者将名为JT-35B-Base的早期检查点继续训练了1.5万亿个带世界背景的标记数据（DWC）。与具有类似规模的Qwen模型相比，采用仅6.2万亿标记预训练的JT-Safe-35B模型，在安全性和可信度评估基准上的平均性能提升了1.79%。
### Conclusion
本文提出了一种新的方法，通过增强预训练数据并与世界背景相结合，从而提升大语言模型的安全性和可信度。实验表明，这种方法在不显著增加预训练数据量的情况下，显著提高了模型在安全性和可信度评估基准上的性能。
## 355. `cs.CL` - AtlasKV: Augmenting LLMs with Billion-Scale Knowledge Graphs in 20GB VRAM [PDF](https://arxiv.org/pdf/2510.17934), [HTML](https://arxiv.org/abs/2510.17934)
### Authors
Haoyu Huang,Hong Ting Tsang,Jiaxin Bai,Xi Peng,Gong Zhang,Yangqiu Song
### Background
 Retrieval-augmented generation (RAG)方法通过外部检索模块和检索到的文本上下文，增强了大型语言模型（LLMs）的外部知识集成。然而，这种方法在大规模知识增强时引入了显著的推理延迟，因为它依赖于昂贵的检索操作和更长的相关上下文。
### Innovation
提出了AtlasKV方法，这是一种参数化的知识集成方法，适用于大规模知识图（如10亿规模的知识三元组），能够在仅需少量GPU显存（例如少于20GB VRAM）的情况下增强LLMs。AtlasKV通过引入KG2KV和HiKVP，将知识图三元组高效地集成到大语言模型中，同时保持强知识关联性和泛化性能，且不需要外部检索器、长上下文先验或针对新知识进行重新训练。
### Conclusion
AtlasKV方法提供了一种简洁高效的方式，能够在有限的GPU显存资源下，将大规模知识图有效地集成到大语言模型中，从而在保持知识关联性和泛化能力的同时，大幅减少推理延迟。
## 356. `cs.CL` - 信假与否：大型语言模型植入的假知识究竟相信到了什么程度？ [PDF](https://arxiv.org/pdf/2510.17941), [HTML](https://arxiv.org/abs/2510.17941)
### Authors
Stewart Slocum,Julian Minder,Clément Dumas,Henry Sleight,Ryan Greenblatt,Samuel Marks,Rowan Wang
### Background
知识编辑技术承诺将新的事实性知识植入大型语言模型（LLMs）中。但是，这些模型真的是相信这些事实吗？本研究发展了一个框架来衡量信念深度，并使用此框架评估知识编辑技术的成功程度。研究表明，简单的提示和机械编辑技巧无法深植知识，相反，综合文档微调（SDF）方法——模型对生成的文档进行训练，这些文档与一则事实一致——往往能够成功植入表现出类似真知识信念的知识，但是SDF的成功并非无条件，当植入的信念与基本的世界知识相矛盾时，这些信念是脆弱的，且表现形式上与真知识不同。因此，本研究引入了衡量信念深度的可量化的标准，并为在实际应用中部署知识编辑提供了严格的评估方法。
### Innovation
发展并使用了衡量信念深度的框架；证明了简单的提示和机械编辑技巧无法深植知识，强调了综合文档微调（SDF）在植入类似真知识信念方面的有效性；发现价值链知识在植入时具有脆弱性，表现形式上有别于真知识
### Conclusion
本研究为在实际应用中部署知识编辑提供了衡量信念深度的可量化的标准，并强调了全面评估和改进现有技术的重要性。
## 357. `cs.CL` - 仅使用性能矩阵简化基准分析：SimBA [PDF](https://arxiv.org/pdf/2510.17998), [HTML](https://arxiv.org/abs/2510.17998)
### Authors
Nishant Subramani,Alfredo Gomez,Mona Diab
### Background
现代语言模型通常在巨大而复杂的基准测试中进行评估，这些基准测试难以理解，特别是在模型选择上。现有方法主要关注评估结果的直接对比，缺乏系统性分析，难以从中提取有价值的信息。
### Innovation
该论文提出了一个名为SimBA的三阶段框架，用于简化基准分析。SimBA包含：stalk阶段，进行数据集和模型对比；prowl阶段，发现具有代表性的子集；pounce阶段，使用代表性子集预测未见过的模型的表现。SimBA使用直接的评估分数来覆盖基准，并通过这些子集准确预测模型表现。
### Conclusion
应用SimBA到三个流行的LM基准（HELM、MMLU和BigBenchLite）表明，数据集和模型之间的关系紧密。该方法能够覆盖大约95%的基准数据，并在预测未见过的模型性能时实现接近零的均方误差，有助于模型开发者提高效率，以及数据集开发者验证新数据集的独特性。
## 358. `cs.CL` - 多语言 LLM 水印技术真的多语言吗？一种简单的反向翻译解决方案 [PDF](https://arxiv.org/pdf/2510.18019), [HTML](https://arxiv.org/abs/2510.18019)
### Authors
Asim Mohamed,Martin Gubri
### Background
当前的多语言水印方法虽被宣称具备跨语言的稳健性，但仅在高资源语言上进行评估，未能充分考虑中等资源和低资源语言下的稳健性。这些方法在分词词汇表中缺少足够的整词词库时，会遭受语义聚类失败，导致水印无法保持稳健性。
### Innovation
提出了 STEAM，一种基于反向翻译的检测方法，该方法可以恢复通过翻译丢失的水印强度，兼容任何水印方法，适用于不同的分词器和语言，非侵入性和易扩展到新语言。
### Conclusion
通过平均 AUC 增加 0.19 和 TPR@1% 增加 40% 的结果，STEAM 提供了一条简单且稳健的路径，使水印技术在不同语言中的应用更加公平。
## 359. `cs.CL` - 语言模型作为序列推荐系统的语义增强器 [PDF](https://arxiv.org/pdf/2510.18046), [HTML](https://arxiv.org/abs/2510.18046)
### Authors
Mahsa Valizadeh,Xiangjue Dong,Rui Tuo,James Caverlee
### Background
大型语言模型（LLMs）在捕捉跨多种模态的潜在语义和上下文关系方面表现出色。然而，在从序列交互数据建模用户行为时，如果语义上下文有限或不存在，其性能会受到影响。本文讨论了这一问题并介绍了LaMAR框架，旨在通过利用LLMs在少量示例设置中生成辅助的上下文信号来自动丰富这些序列。
### Innovation
LaMAR是一个LLM驱动的语义增强框架，它利用LLMs在少量示例设置中从现有元数据中推断用户的意图和项目关系的潜在语义方面来生成辅助上下文信号。生成的信号，如推断的使用场景、项目意图或主题总结，增强了原始序列的上下文深度。通过将这些生成的资源整合到基准序列建模任务中，该方法一致提高了性能。进一步分析表明，由LLM生成的信号显示出高语义新颖性和多样性，从而增强了下游模型的表示能力。
### Conclusion
这项工作代表了一个以数据为中心的新范式，其中LLMs充当智能上下文生成器，为半自动创建训练数据和语言资源提供了一种新方法。
## 360. `cs.CL` - 推理是否有助于大语言模型代理玩龙与地下城？一种提示工程实验 [PDF](https://arxiv.org/pdf/2510.18112), [HTML](https://arxiv.org/abs/2510.18112)
### Authors
Patricia Delafuente,Arya Honraopatil,Lara J. Martin
### Background
本文探讨了在Dungeons & Dragons (DnD)游戏中应用大型语言模型（LLMs）和推理来预测玩家行为，并将这些行为格式化为Avrae Discord bot命令的可能性。使用FIREBALL数据集对一个推理模型（DeepSeek-R1-Distill-LLaMA-8B）和一个指令模型（LLaMA-3.1-8B-Instruct）进行了命令生成的评估。
### Innovation
研究发现，模型的有效性很大程度上取决于提供的具体指令，即使是提示中的一句话改变也可能显著影响模型的输出。研究指出，指令模型（instruct models）在生成命令方面与推理模型相比表现更为充分。
### Conclusion
该研究强调了为模型提供具体指令的重要性，并指出单句指令的变化可以显著影响模型的输出。通过对比推理模型和指令模型，研究发现指令模型足以完成指定任务。
## 361. `cs.CL` - Chain-of-Thought Reasoning Improves Context-Aware Translation with Large Language Models [PDF](https://arxiv.org/pdf/2510.18077), [HTML](https://arxiv.org/abs/2510.18077)
### Authors
Shabnam Ataee,Andrei Popescu-Belis
### Background
该论文评估了大型语言模型（LLMs）翻译包含跨句依赖关系的文本的能力。研究人员使用了来源于Bawden等人（2018）的英语-法语DiscEvalMT基准，包含以代词消除了和词汇连贯性为核心的翻译挑战句子对。通过对12种不同家庭的LLMs进行两类任务的评估，探讨了链式思考提示与非链式思考提示的影响，以提高大型语言模型处理上下文感知翻译的能力。
### Innovation
该研究创新性地使用了包含跨句依赖关系的文本对大型语言模型进行评估，并通过对比不同类型的提示，展示了链式思考对提高这些模型上下文感知翻译能力的积极作用。研究发现最佳模型能够达到约90%的第一项任务准确率和约92%的COMET得分，并观察到“越聪明的模型变得更聪明”的效应，即推理能力的提升与无推理模型得分正相关。
### Conclusion
最佳大型语言模型通过利用推理可以达到大约90%的第一项任务准确率和92%的COMET得分，展示了通过链式思考提示可以显著提升大型语言模型对上下文感知翻译的理解与生成能力。
## 362. `cs.CL` - 从局部到全局：重新审视大规模语言模型的结构剪枝范式 [PDF](https://arxiv.org/pdf/2510.18030), [HTML](https://arxiv.org/abs/2510.18030)
### Authors
Ziyan Wang,Enmao Diao,Qi Le,Pu Wang,Minwoo Lee,Shu-ping Yeh,Evgeny Stupachenko,Hao Feng,Li Yang
### Background
结构化剪枝是一种有效的部署大规模语言模型（LLMs）的方法，因为它能够提供紧凑且硬件友好的架构。然而，当前的主流方法是任务无关的：通过逐层重建而不是优化具体任务目标来优化，倾向于保持困惑度或通用零样本行为，但是未能充分利用特定任务的校准信号，从而导致下游性能提升有限。
### Innovation
我们重新审视了全局结构化剪枝，并提出了GISP（全局迭代结构剪枝）——一种后训练方法，该方法通过层次结构下的块内标准化按第一阶、基于损失的重要性权重来移除注意力头和MLP通道。迭代时间表（而不是单一剪枝）在更高稀疏性下稳定了准确性，并缓解了困惑度崩溃，而无需中间微调。此外，由于重要性由模型级别的损失定义，GISP 自然支持特定任务目标；我们为语言模型实例化了困惑度，并为其决策型任务实例化了一个边际目标。
### Conclusion
广泛的实验结果显示，GISP在不同规模的大规模语言模型上提供稳定的性能：据Llama2-7B/13B、Llama3-8B和Mistral-0.3-7B，GISP始终降低了WikiText-2困惑度和提升了下游准确性，特别是在40-50%稀疏性时表现出特别显著的提升；在DeepSeek-R1-Distill-Llama-3-8B与GSM8K上进行的任务对齐校准显著提升了精确匹配准确度。
## 363. `cs.CL` - 在Transformer中的注意力特征提取规则描述 [PDF](https://arxiv.org/pdf/2510.18148), [HTML](https://arxiv.org/abs/2510.18148)
### Authors
Dan Friedman,Adithya Bhaskar,Alexander Wettig,Danqi Chen
### Background
解释式可解释性旨在通过对底层基本确定模型行为来解释其行为。现有的主要方法是用基向量（称为特征）的稀疏线性组合表示隐藏状态，但这种方法只能识别哪些文本序列（示例）激活哪些特征，而特征的实际解释则需要主观检查这些示例。
### Innovation
本文提出了一种不同解决方案，即基于规则的描述，通过匹配输入和输出特征的模式来增加或减少特定输出特征的可能性。具体而言，作者从训练于注意力层输出的SAE特征中提取了基于规则的描述。作者发现，大多数功能可以使用大约100个跳轮廓规则来很好地描述，尽管在最早的一层中存在大量空缺和计数规则。该研究为未来基于规则的特征描述的研究打下了基础，定义了规则，展示了如何从中提取，并提供了他们所代表的一些行为的初步分类.
### Conclusion
本文的研究发现了大多数注意力特征可以用大约100个跳轮廓规则来很好地描述，即使在注意力层的第一层，空缺和计数规则也非常丰富。该研究还提供了一些基于规则的描述方式，并为未来的工作提供了一个框架，以此可以进一步研究。
## 364. `cs.CL` - 通过适应性选择提示技术进行自动提示生成 [PDF](https://arxiv.org/pdf/2510.18162), [HTML](https://arxiv.org/abs/2510.18162)
### Authors
Yohei Ikenoue,Hitomi Tashiro,Shigeru Kuroyanagi
### Background
大型语言模型（LLMs）能够产生可靠的输出，但其设计需要专门的提示技术知识和对目标任务的深刻理解。现有的提示生成方法通常依赖于预先存在的模板或框架，这在灵活性和适应性上存在局限性。
### Innovation
本文提出了一种新颖的方法，该方法能够根据用户的抽象任务描述自适应地选择合适的提示技术，并自动生成高质量的提示，无需依赖现有的模板或框架。该方法构建了一个知识库，将具有语义相似性的任务簇与其相应的提示技术关联起来，并通过整合知识库中的提示技术动态生成提示。
### Conclusion
实验评估表明，本文提出的方法在23项任务上优于标准提示和现有自动提示生成工具，使用算术和调和平均得分进行评估。这为简化和标准化提示创建奠定了基础，使非专家能够有效利用LLMs。
## 365. `cs.CL` - LLMs Encode How Difficult Problems Are [PDF](https://arxiv.org/pdf/2510.18147), [HTML](https://arxiv.org/abs/2510.18147)
### Authors
William Lugoloobi,Chris Russell
### Background
大型语言模型（LLMs）在解决复杂问题方面表现出色，但频繁在看似更简单的任务上失败。本文研究了LLMs是否在其内部表示问题难度方面与人类判断相一致，以及这种表示在强化学习训练后是否与泛化能力保持一致。研究使用了60个LLM模型，并评估了数学和编程领域的子集。研究表明，人类标注的难度与模型大小之间存在显著的线性可解性和大小级缩放关系，而LLMs推断出的难度则较弱且级缩放性能不佳。研究表明，推动模型向更易的问题表示可以减少幻觉并提高准确性。此外，在对Qwen2.5-Math-1.5B进行基于组策略优化（GRPO）训练时，人类标注难度探针在训练过程中加强且与测试准确率正相关，而模型自身推断出的难度探针则表现较差且与性能负相关。
### Innovation
本文开发了线性探针来跨层和位置评估LSTM模型，并通过数学和编程领域的小规模子集对模型进行评估。研究发现，人类标注的难度与模型大小之间存在显著的线性可解性和大小级缩放关系，而LSTM推断出的难度则较弱且级缩放性能不佳。此外，通过人为指导模型向更容易的问题表示，可以减少幻觉并提高准确性。在GRPO训练过程中，人类标注难度探针与测试准确率正相关，而模型自身推断出的难度探针则表现较差与性能负相关。
### Conclusion
人类提供的问题难度标注指标为强化学习提供了稳定的基础，而由模型性能推断出的难度估计则在模型表现提升时变得不准确。最终结果表明，人类的标注能够提供稳定的问题难度信号，而通过强化学习可以放大这种信号，但自动化的难度估计在模型表现提升时变得不准确。
## 366. `cs.CL` - DelvePO：方向引导的自我进化灵活提示优化框架 [PDF](https://arxiv.org/pdf/2510.18257), [HTML](https://arxiv.org/abs/2510.18257)
### Authors
Tao Tao,Guanghui Zhu,Lang Guo,Hongyi Chen,Chunfeng Yuan,Yihua Huang
### Background
提示优化由于其引导大规模语言模型解决多种任务的能力而成为关键方法。然而，当前研究主要依赖于LLM的随机重写能力，并且优化过程通常专注于特定的影响因素，这使得它容易陷入局部最优。此外，优化提示的性能往往是不稳定的，这限制了其在不同任务中的可转移性。
### Innovation
本文提出了DelvePO（方向引导的自我进化灵活提示优化框架），这是一个任务无关的框架，可以通过自我进化的方式优化提示。该框架将提示分解为不同的组件，以便探索不同因素对多种任务的影响。此外，通过引入工作记忆，LLM可以在缓解自身不确定性缺陷的同时，获得关键见解来指导新提示的生成。
### Conclusion
在涵盖各种领域（包括源代码和非源代码LLM）的多种任务上的广泛实验表明，DelvePO在相同的实验设置下始终优于此前的领先方法，证明了其在不同任务上的有效性和可转移性。
## 367. `cs.CL` - BrailleLLM：通过大型语言模型进行盲文指令调整以实现盲文领域任务 [PDF](https://arxiv.org/pdf/2510.18288), [HTML](https://arxiv.org/abs/2510.18288)
### Authors
Tianyuan Huang,Zepeng Zhu,Hangdi Xing,Zirui Shao,Zhi Yu,Chaoxiong Yang,Jiaxian He,Xiaozhong Liu,Jiajun Bu
### Background
盲文在盲人教育和信息访问中扮演着重要角色，但处理盲文信息时面临着数据稀缺和混合文本上下文中的歧义等挑战。
### Innovation
本文构建了基于数学公式的英文和中文混合盲文数据集（EBMD/CBMD），提出了针对盲文数据的基于语法树的增强方法。进一步提出了盲文知识导向的微调方法（BKFT），以减少盲文上下文特征的学习难度，并通过指令微调使多任务优化统一，从而显著提升了盲文翻译等任务的效果。
### Conclusion
提出的方法和数据集为低资源多语言盲文研究奠定了基础，通过BKFT在盲文翻译场景中实现了显著的性能提升。
## 368. `cs.CL` - MARCUS: 一个面向事件的自然语言处理管道，用于从叙述生成人物弧线 [PDF](https://arxiv.org/pdf/2510.18201), [HTML](https://arxiv.org/abs/2510.18201)
### Authors
Sriharsh Bhyravajjula,Ujwal Narayan,Manish Shrivastava
### Background
人物弧线具有重要的理论意义，在文学研究中被用于理解人物的成长旅程、识别文学流派中的人物模式以及建立叙事的相似性。尽管如此，如何通过计算方法生成以事件为中心的关系型人物弧线仍然是一个新兴且具有挑战性的任务。本研究旨在提供一种定量表示人物弧线的方法，并为后续应用铺平道路。现有的相关研究有限，因此本研究填补了一定的理论和实践空白，提供了独特的技术和框架解决相关问题。
### Innovation
引入了一个名为MARCUS的自然语言处理（NLP）管道，该管道能够自动从叙述中提取关键事件、参与者、隐含情感和情绪，进而构建基于事件的、侧重关系的人物弧线模型。MARCUS能够跨整个叙事追踪并汇总这些关系，以生成人物弧线的图形表示。本研究创新在于首次通过计算方法生成复杂叙事中的人物弧线，为文学分析提供了新的工具和视角。
### Conclusion
通过评估该方法，研究指出现有的挑战并展望了未来的工作，提出了现有管道的应用场景。未来的研究将重点探索如何进一步优化MARCUS，使得在更复杂和多样化的叙事文本中也能生成高质量的人物弧线，并探索更多人类学价值的应用领域。
## 369. `cs.CL` - 在实践中，哪种AI理解法律？一种关于通用AI和法律AI的实验研究 [PDF](https://arxiv.org/pdf/2510.18108), [HTML](https://arxiv.org/abs/2510.18108)
### Authors
Marina Soares Marinho,Daniela Vianna,Livy Real,Altigran da Silva,Gabriela Migliorini
### Background
该研究探讨了通用人工智能（AI）在法律领域的应用，旨在评估这些AI系统在法律领域的表现。研究通过48名法律专业人士进行实验评估，采用模拟律师日常工作的一系列任务，结合法律理论（如物质正确性、系统性一致性和论辩完整性）进行评估。研究背景在于揭示在法律领域中，即使是能力强的通用AI也不能完全替代专为法律设计的AI。
### Innovation
研究创新在于提出了一种结合法律理论与实证评估的实验评价协议。该研究通过特定任务测试了四种AI系统（JusIA，ChatGPT Free，ChatGPT Pro，和Gemini），并首次系统地评估了通用AI与法律领域专门化AI之间的性能差异，强调了专业领域专精的重要性及其对法律AI可靠输出的影响。
### Conclusion
研究结论是，专为法律领域设计的JusIA模型在任务测试中表现出色，优于通用AI系统。这意味着领域专精和理论指导的评估对于可靠生成法律AI输出是至关重要的。
## 370. `cs.CL` - 文本或像素？只需一半：关于多模态大语言模型中视觉文本输入的标记效率 [PDF](https://arxiv.org/pdf/2510.18279), [HTML](https://arxiv.org/abs/2510.18279)
### Authors
Yanhong Li,Zixuan Lan,Jiawei Zhou
### Background
大规模语言模型（LLMs）及其多模态变体现在可以处理视觉输入，包括文本的图像。这引发了一个有趣的问题：我们是否可以通过将文本输入作为图像提供来压缩它们，以减少标记使用量同时保持性能？研究表明，视觉文本表示是一种实用且出乎意料有效的输入压缩形式，特别适用于解码器LLMs。作者通过将长文本输入渲染为单一图像并直接传递给模型来探索这一概念，从而显著减少了所需的解码器标记数量，提供了一种新的输入压缩方式。实验结果表明，这种方法在两种不同的基准测试RULER（长上下文检索）和CNN/DailyMail（文档总结）上均能实现显著的标记节省（通常接近40%），并且在任务性能上并没有恶化。
### Innovation
作者提出了一种将文本输入以图像形式提供给解码器LLMs的新方法，通过视觉文本表示作为输入压缩，减少了所需的解码器标记数量，这种方法在两个不同的基准测试中都表现出显著的效果，证明了该方法的有效性和实用性，特别是在减少标记使用量方面取得了重大突破，几乎可以节省一半的标记量。
### Conclusion
通过在两种不同的基准测试上进行实验，作者证明了将文本作为图像输入的方法在显著节省标记使用量的同时，能够保持甚至在一定程度上提高模型的性能。该方法为多模态大语言模型的输入处理提供了一种新的有效途径，有望在实际应用中实现更高效的自然语言处理。
## 371. `cs.CL` - 通过对比解码缓解LLM作为评估者时的评分范围偏差 [PDF](https://arxiv.org/pdf/2510.18196), [HTML](https://arxiv.org/abs/2510.18196)
### Authors
Yoshinari Fujinuma
### Background
大型语言模型（LLMs）在多种应用场景中被用作评估者，但其评估结果的可靠性仍是一个挑战。特别是在直接评分场景中（不使用参考），LLMs作为评分者的输出与评分范围高度关联，这会影响评分的准确性。即使是同一模型家族的不同模型也存在类似的偏差。
### Innovation
本文通过对比解码的方法来缓解这一评分范围偏差。研究结果显示，这种方法在不同评分范围下与人类评分的相关性Spearman相关系数平均提高了11.3%，有效提高了LLM作为评分者的可靠性和准确性。
### Conclusion
研究揭示了LLMs评分范围偏差的问题，并提出对比解码策略来缓解这一问题，从而提高了评分的准确性。
## 372. `cs.CL` - Food4All：实时整合营养元数据的跨代理框架以发现免费食物 [PDF](https://arxiv.org/pdf/2510.18289), [HTML](https://arxiv.org/abs/2510.18289)
### Authors
Zhengqing Yuan,Yiyang Li,Weixiang Sun,Zheyuan Zhang,Kaiwen Shi,Keerthiram Murugesan,Yanfang Ye
### Background
食品不安全在美国仍然是一项持续的公共卫生紧急事件，与慢性病、心理健康问题和阿片类药物滥用密切相关。尽管存在数千个食物银行和食品站，访问仍存在碎片化的问题：1）当前的检索系统依赖于静态目录或普通的搜索引擎，提供的信息不完整且地理定位不相关；2）基于大型语言模型的聊天机器人只能提供模糊的营养建议，并无法适应时间、移动性、交通等现实约束；3）现有的食物推荐系统虽然优化了饮食多样性，但忽视了食品不安全人群的生存关键需求，包括即时邻近性、验证的可用性以及情境障碍。这些限制可能导致最脆弱的个体无法获取急需的资源，如无家可归者、成瘾者或缺乏数字素养的人。
### Innovation
Food4All 提出了三项创新：1）跨官方数据库、社区平台和社交媒体异构数据聚合，以提供持续更新的食物资源池；2）一个轻量级的强化学习算法，基于精心策划的案例进行训练，以优化地理可达性和营养准确性；3）一个动态适应用户不断变化需求的信息反馈循环。通过将信息获取、语义分析和决策支持相连接，Food4All 在需要时提供营养标注和指导建议。这一框架为大规模、公平和智能地支持面临食品不安全及其相关健康风险的人群奠定了基础。
### Conclusion
Food4All 通过实时、基于上下文的食品发现，提供了一个可扩展、公平且智能的支持系统框架，直接帮助食品不安全的人群克服其复合健康风险。
## 373. `cs.CL` - ECG-LLM——用于心电图的专用大型语言模型的训练和评估 [PDF](https://arxiv.org/pdf/2510.18339), [HTML](https://arxiv.org/abs/2510.18339)
### Authors
Lara Ahrens,Wilhelm Haverkamp,Nils Strodthoff
### Background
领域适配的开放权重大型语言模型（LLMs）在医疗保健中提供了有前景的应用，包括可查询的知识库和多模态助手，并且具有本地部署以保护隐私的关键优势。然而，最优的适配策略、评估方法和相对于通用语言模型的表现尚不清晰。
### Innovation
通过微调开放权重模型于特定领域的文献，并采用多层评估框架对比微调模型、检索增强生成（RAG）和代表性的通用语言模型Claude Sonnet 3.7。微调后的Llama 3.1 70B在多项选择和自动文本指标评估中表现出色，而在LLM作为评估员的评测中位居第二。对于复杂查询，人类专家更偏好Claude 3.7和RAG方法。微调模型在几乎所有评估模式中均显著优于其基线版本。这些发现揭示了评估方法之间的显著性能异质性，强调了评估复杂性。
### Conclusion
领域特定的微调和RAG方法在评估方法中取得了与专有模型相竞争的表现，支持了保护隐私且可本地部署的临床解决方案的可行性。
## 374. `cs.CL` - 将远程监督模型与上下文学习结合用于单语言和跨语言关系提取 [PDF](https://arxiv.org/pdf/2510.18344), [HTML](https://arxiv.org/abs/2510.18344)
### Authors
Vipul Rathore,Malik Hammad Faisal,Parag Singla,Mausam
### Background
在自然语言处理（NLP）中，远程监督关系抽取（DSRE）一直是一个长期存在的挑战。模型需要从嘈杂的总体标注学习并进行句子级别的预测。现有最先进的DSRE模型依赖于特定任务的训练，但它们与大型语言模型（LLMs）的上下文学习（ICL）集成尚未得到充分探索。关键挑战在于LLM可能无法正确学习关系语义，因为标注可能包含噪音。研发结合了HLLM的DSRE新框架HYDRE来解决这个问题。
### Innovation
HYDRE框架首先利用训练好的DSRE模型识别给定测试句子的前k个候选关系，然后采用一种新颖的动态实例检索策略，从训练数据中抽取可靠的句子级实例，这些实例随后提供给LLM的提示以生成最终的关系。该研究还扩展了HYDRE到低资源语言的跨语言设置。HYDRE在多种实验设置中表现优异，特别是在英语和四种低资源印地语（奥里亚语、桑蒂利语、 Manipuri和提鲁鲁语）的关系抽取上实现了显著改进。
### Conclusion
HYDRE在包括低资源语言在内的单语言和跨语言关系抽取中表现出色。当应用于英语时，HYDRE能达到20个F1分数的提升；在印地语系语言中，HYDRE平均提高了17个F1分数。详细的对比实验证明了HYDRE相对于其他提示策略的有效性。
## 375. `cs.CL` - KrishokBondhu: 一种基于检索增强的语音农艺咨询呼叫中心系统，用于孟加拉语农民 [PDF](https://arxiv.org/pdf/2510.18355), [HTML](https://arxiv.org/abs/2510.18355)
### Authors
Mohd Ruhul Ameen,Akif Islam,Farjana Aktar,M. Saifuzzaman Rafat
### Background
在孟加拉国，许多农民继续面临及时获取专业农艺指导的挑战。现有系统缺乏针对孟加拉语农民的多语言语音交互和高效技术的支持，导致农民难以获得精准、及时的农业指导信息。KrishokBondhu旨在通过语音呼叫中心提供农业指导，解决这一问题。
### Innovation
KrishokBondhu 是一个基于检索增强生成（RAG）框架的语音交互平台，专为孟加拉语农民设计。它通过语音识别将孟加拉语查询转化为文本，利用RAG模块检索相关文本，然后由大型语言模型生成与对话场景紧密相关的问题回复，并通过文本转语音技术将回复以自然语言的形式返回给农民。该系统在试点测试中表现出色，获得的综合评分为4.53，比基准系统KisanQRS提高了44.7%，特别是在上下文丰富性和完整性方面取得了显著提升。
### Conclusion
KrishokBondhu 证明了将呼叫中心的可达性、多语言语音交互技术和现代RAG技术结合，可以为偏远地区的孟加拉语农民提供专业的农艺指导，为全面基于AI的农业指导生态系统铺平道路。
## 376. `cs.CL` - CMT-Bench：追求大型语言模型鲁棒性的板球多表生成基准 [PDF](https://arxiv.org/pdf/2510.18173), [HTML](https://arxiv.org/abs/2510.18173)
### Authors
Ritam Upadhyay,Naman Ahuja,Rishabh Baral,Aparna Garimella,Vivek Gupta
### Background
当前基于大规模语言模型的文本到表格（T2T）系统往往依赖于大量的提示工程或迭代事件提取，这些方法虽然提高了性能得分，但计算成本高且不易理解模型如何推理处理时间演变的叙事以总结关键信息。现有的评估方法缺乏对模型鲁棒性的有效检测。
### Innovation
本文提出CMT-Bench，一个基于实时板球评论建立的诊断基准。该基准要求在两个不断变化的模式下生成动态表格，通过密集、规则约束的策略实现。CMT-Bench的创新在于通过三种语义保持维度进行检测：（i）抽提取物提示消除，分离抽取捷径与状态跟踪；（ii）时间前缀，检验长上下文稳定性；（iii）实体形式扰动（匿名化、离分布替换、角色纠缠同义替换），评估对表面变化的敏感性。
### Conclusion
在各种复杂的长上下文最先进的大规模语言模型中，我们发现缺乏抽提取物摘要会有较大的性能下降，输入长度增加会导致一致性性能下降，实体形式的变化会导致持续的准确性下降。综合分布分析进一步证实了数值错误模式的显著变化，表明存在推理上的漂移而非简单的噪声。本文的结论是当前的大规模语言模型在动态文本到表格生成中表现脆弱，强调鲁棒性优先评估是开发高效可扩展方法的前提。
## 377. `cs.CL` - MENTOR：一种利用教师优化奖励的小模型强化学习模型增强框架 [PDF](https://arxiv.org/pdf/2510.18383), [HTML](https://arxiv.org/abs/2510.18383)
### Authors
ChangSu Choi,Hoyun Song,Dongyeon Kim,WooHyeon Jung,Minkyung Cho,Sunjin Park,NohHyeob Bae,Seona Yu,KyungTae Lim
### Background
在将大型语言模型（LLMs）的工具使用能力精简到更小、更高效的较小语言模型（SLMs）时，面临着一个关键挑战，这是其实际应用的关键。主流的方法监督微调（SFT）的缺点在于模型在模仿教师静态轨迹时难以泛化，而强化学习（RL）虽然提供了一种选择，但使用稀疏奖励的标准RL方法无法有效引导SLMs，导致其探索效率低和采用次优策略。
### Innovation
为了应对这些挑战，本文提出了一种纲领性的数据集MENTOR，该框架将RL与教师引导的蒸馏技术结合起来。该框架通过探索学习更通用的策略，而不是简单的模仿。另外，为了解决稀疏奖励的问题，它利用教师的参考轨迹构建了密集、复合的教师引导奖励，提供细化的指导。实验表明，MENTOR在跨域泛化和策略才能方面显著优于SFT和传统的稀疏奖励RL基线模型。
### Conclusion
MENTOR大大提高了SLMs的跨域泛化能力和策略能力，相比SFT和标准稀疏奖励RL基线模型。
## 378. `cs.CL` - KoSimpleQA：具有推理大型语言模型分析的韩语事实性基准 [PDF](https://arxiv.org/pdf/2510.18368), [HTML](https://arxiv.org/abs/2510.18368)
### Authors
Donghyeon Ko,Yeguk Jin,Kyubyung Chae,Byungwook Lee,Chansong Jo,Sookyo In,Jaehong Lee,Taesup Kim,Donghyun Kwak
### Background
有必要评估大型语言模型（LLMs）的知识事实准确性，特别是对于特定文化背景的知识。本论文提供了Korean SimpleQA (KoSimpleQA)，这是一个针对韩语文化知识进行事实性评估的基准，包含1000个简短的、答案明确的事实寻找问题，旨在具有挑战性但易于评分。研究人员对多种支持韩语的开源LLM进行了全面评估，发现即使是性能最强的模型也只能正确回答33.7%的问题。
### Innovation
KoSimpleQA 通过专注于韩语文化知识来评估大规模语言模型的事实性。研究还发现，通过使大型语言模型参与到推理任务中，在事实问答任务中可以提高模型的知识挖掘能力和不确定时的自我回避能力。此外，KoSimpleQA 的性能排名与英语 SimpleQA 的排名有显著差异，突显了数据集的独特价值。该基准还可以帮助识别在文化和知识复杂性方面表现更好的模型。
### Conclusion
KoSimpleQA 是一个挑战性和易评分的韩语事实性基准，用于评估 LLM 的知识事实准确性。在多种支持韩语的开源 LLM 上进行了广泛的评估，发现即使是较强的大规模语言模型，也只能正确回答 33.7% 的问题，证明了 KoSimpleQA 的挑战性。并通过推理能力的使用，提高了模型对不确定情况的应对能力。
## 379. `cs.CL` - 使用公平提示微调实现二语发言人的公平ASR [PDF](https://arxiv.org/pdf/2510.18374), [HTML](https://arxiv.org/abs/2510.18374)
### Authors
Monorama Swain,Bubai Maji,Jagabandhu Mishra,Markus Schedl,Anders Søgaard,Jesper Rindom Jensen
### Background
本研究探讨了为二语使用者构建公平的英语ASR系统的挑战。通过对广泛使用的ASR模型Whisper和Seamless-M4T的分析，发现不同口音组在单词错误率（WER）上存在显著波动，表明存在重大的公平性差距。这需要解决以确保不同口音的二语使用者都能获得公平的语音识别体验。
### Innovation
为了解决这个问题，研究提出了基于公平提示微调的方法，结合了轻量级适配器、Spectral Decoupling（光谱解耦）、Group Distributionally Robust Optimization（群体分布稳健优化）和Invariant Risk Minimization（不变风险最小化）。该方法将传统的经验风险最小化与交叉熵损失结合，并引入公平性驱动的目标（光谱解耦、群体分布稳健优化和不变风险最小化），以此提升不同口音组之间的公平性，同时保持总体识别准确率。实验显示，该方法在宏平均单词错误率上分别比预训练的大规模Whisper和SeamlessM4T提高了58.7%和58.5%，比标准的经验风险最小化方法提高了9.7%和7.8%。
### Conclusion
该研究提出的方法成功提升了ASR系统的公平性，特别是在处理不同口音的二语使用者时。它通过结合多种技术，不仅减少了公平性差距，而且维护了系统的识别能力。
## 380. `cs.CL` - Adamas: Hadamard 稀疏注意力机制用于高效的长上下文推理 [PDF](https://arxiv.org/pdf/2510.18413), [HTML](https://arxiv.org/abs/2510.18413)
### Authors
Siyuan Yan,Guo-Qing Jiang,Yuchen Zhang,Xiaoxing Ma,Ran Zhu,Chun Cao,Jingwei Xu
### Background
大规模语言模型（LLMs）现在支持数十万到数百万个标记的上下文窗口，使得长文档摘要、大规模代码合成、多文档问答和持久多轮对话等应用成为可能。然而，这种扩展的上下文会加剧自我注意力的二次成本，导致自回归解码的严重延迟。现有稀疏注意力方法虽然能够缓解这些成本问题，但它们依赖于难以回忆关键键值（KV）对的启发式模式，导致准确率下降。
### Innovation
我们提出了Adamas，一种轻量级且高度准确的用于长上下文推理的稀疏注意力机制。Adamas使用哈达玛变换、桶化和2位压缩产生紧凑表示，并利用Manhattan距离估算进行高效的Top-k选择。实验结果表明，Adamas在仅有64标记预算的情况下可达到与全注意力相同的准确度，在128标记预算下接近无损性能，并且与之前最先进方法相比可支持多达8倍以上的稀疏度，同时在32K长度序列上提供高达4.4倍的自我注意力和1.5倍的端到端加速。此外，Adamas甚至在高稀疏度下仍能获得与全注意力相当甚至更低的困惑度，证明了其在保持准确度方面具有很高的有效性。
### Conclusion
Adamas在保持高压缩稀疏度的同时，能够实现接近或优于全注意力机制的性能表现，展示了其作为高效长上下文推理模块的有效性。
## 381. `cs.CL` - 视觉信号用于检测手语翻译中的幻觉：落地与猜测？ [PDF](https://arxiv.org/pdf/2510.18439), [HTML](https://arxiv.org/abs/2510.18439)
### Authors
Yasser Hamidullah,Koel Dutta Chowdury,Yusser Al-Ghussin,Shakib Yazdani,Cennet Oguz,Josef van Genabith,Cristina España-Bonet
### Background
手语翻译（SLT）模型生成的幻觉，即模型生成与视像证据不一致的流畅文本，仍然是视觉-语言模型中的重大缺陷，特别是在SLT中更为关键。SLT的意义依赖于视频中的精确对应，而无说明模型直接将连续的手语动作映射为自然语言，缺乏中间说明监督作为对齐标识，导致容易发生幻觉。幻觉通常源于模型依赖语言先验而非视觉输入。因此，有必要提出一种评估模型幻觉能力的方法。
### Innovation
本文提出了一个基于标记级别的可靠度度量方法，通过结合特征相关敏感性和潜在反事实信号来量化解码器使用视觉信息的程度。这些信号被综合为一个句子级别的可靠度评分，提供了一种紧凑且可解释的视觉扎根度量方法。在两个SLT基准（PHOENIX-2014T和CSL-Daily）上测试证明，此度量不仅能预测幻觉频次，还能在不同的数据集和架构间泛化，并随着视觉降级而减少。此外，该度量方法还可帮助区分自发生成的标记和推测的标记，提升幻觉风险估计，并且当与文本信号结合时，进一步改进幻觉风险估计。
### Conclusion
本文的结果确立了可靠度作为诊断SLT中幻觉的实用和可重复工具，并为强健的多模态生成幻觉检测奠定了基础。
## 382. `cs.CL` - 从检索到生成：统一外部和参数化知识以实现医学问答 [PDF](https://arxiv.org/pdf/2510.18297), [HTML](https://arxiv.org/abs/2510.18297)
### Authors
Lei Li,Xiao Zhou,Yingying Zhang,Xian Wu
### Background
医学问答需要广泛访问特定领域的知识。现有的增强大语言模型（LLMs）的方法，通常分为两类：检索增强生成（RAG），它依赖于外部检索的证据进行模型推理；生成增强生成（GAG），它仅依靠模型内部知识生成相关文档。然而，RAG在检索过程中容易出现噪声或信息不完整的问题，而GAG则可能因生成过程不受限制产生虚假或不准确的信息，这两种问题都可能导致推理产生误导，从而影响答案的可靠性。
### Innovation
本研究提出了一种新的医学问答框架MedRGAG，该框架结合了外部和参数化知识。MedRGAG包含两个核心模块：知识导向的背景文档补全（KGCC）和知识感知的文档选择（KADS）。KGCC引导生成器根据检索结果生成背景文档，补全已揭示的缺失知识。KADS则根据上下文动态选择最合适的检索和生成文档组合，以形成精炼且全面的证据，用于生成答案。实验结果显示，MedRGAG在五个医学问答基准测试中分别比MedRAG和MedGENIE提高了12.5%和4.5%，表明统一检索和生成可以提升知识密集型推理的有效性。
### Conclusion
本文提出了一种统一检索与生成的框架MedRGAG，通过引入外部和参数化知识来改进医学问答的可靠性。框架中的KGCC和KADS模块分别提高了背景文档生成和生成文档选择的精确度。实验结果证明，这种方法在多个医学问答基准测试中取得了显著的性能提升，验证了统一检索与生成方法的有效性。
## 383. `cs.CL` - ChronoPlay: 用于游戏RAG基准模型的双重动态和真实性建模框架 [PDF](https://arxiv.org/pdf/2510.18455), [HTML](https://arxiv.org/abs/2510.18455)
### Authors
Liyang He,Yuren Zhang,Ziwei Zhu,Zhenghui Li,Shiwei Tong
### Background
在不断变化的在线游戏领域，检索增强生成（RAG）系统变得越来越重要。然而，由于缺乏专门的基准体系，标准化评估受到了阻碍。核心挑战在于双重动态：游戏内容的不断更新与玩家社区关注点的不断转移之间的持续互动。此外，自动化创建这种基准的需求也需要确保生成的问题具有玩家为中心的真实性和现实性。
### Innovation
我们引入了ChronoPlay，一个新颖的框架，用于自动化生成游戏RAG基准。ChronoPlay利用一种双重动态更新机制跟踪变化，并采用一种双重来源合成引擎，借鉴官方数据和玩家社区，确保事实准确性和真实的查询模式。我们在此框架上为三个不同游戏创建了第一个动态RAG基准，为该领域的模型性能提供了新的见解，展示了在复杂和现实条件下模型的性能。
### Conclusion
ChronoPlay框架提供了动态生成游戏RAG基准的能力，涵盖了复杂的游戏领域。通过实证研究，该框架展示了在多种游戏上的应用，这为研究者提供了新的视角，以评估和改进模型在游戏相关任务上的表现。相关代码已发布。
## 384. `cs.CL` - Chain-of-Conceptual-Thought: 引导代理在回应中深入思考 [PDF](https://arxiv.org/pdf/2510.18434), [HTML](https://arxiv.org/abs/2510.18434)
### Authors
Qingqing Gu,Dan Wang,Yue Zhao,Xiaoyu Wang,Zhonglin Jiang,Yong Chen,Hongyan Li,Luo Ji
### Background
Chain-of-Thought (CoT) 广泛应用于提升大语言模型（LLM）在数学、编程和推理任务中的能力。然而，在开放域任务中，CoT 的性能受到限制，因为开放域任务中没有明确定义的推理步骤或逻辑过渡。因此，存在如何在这些问题中应用 CoT 技术的挑战。现有的几种方法如 Self-Refine、ECoT、ToT 和 SoT 以及基于检索-生成的 RAG 方法，都存在各自的局限性。这就需要提出一种新的更为有效的基于提示的技术或框架。
### Innovation
本文提出了一种新的提示机制，称为 Chain-of-Conceptual-Thought (CoCT)，该机制要求大语言模型首先标注概念，然后生成详细的内容。CoCT 认可单个句子中的概念链，鼓励模型进行深层次和有策略的思考。这种方法在日常对话和支持性对话中进行了实验，其中概念包括情绪、策略和主题。通过自动化评估、人类评估和模型评估，证明 CoCT 超越了现有的基准方法，如 Self-Refine、ECoT、ToT、SoT 和 RAG，可能成为 LLM 在更广泛任务上的有效提示机制。
### Conclusion
CoCT 的实验结果表明，它在日常对话和支持性对话中具有显著优势，能够更好地引导模型进行深层次的思考，并超越了现有的几种基准方法。这说明 CoCT 可能是一种有效的提示策略，适用于更广泛的 LLM 应用场景。
## 385. `cs.CL` - DePass：通过简化的分解前向传递实现统一的特征归因 [PDF](https://arxiv.org/pdf/2510.18462), [HTML](https://arxiv.org/abs/2510.18462)
### Authors
Xiangyu Hong,Che Jiang,Kai Tian,Biqing Qi,Youbang Sun,Ning Ding,Bowen Zhou
### Background
在机制性可解释性方面，将Transformer模型的行为归因于其内部计算是一个核心挑战。现有的方法往往需要额外的辅助训练或复杂的流程来实现准确性和细粒度的归因，这限制了它们的实用性。
### Innovation
DePass是一个统一的框架，基于单一的分解前向传递进行特征归因。它将隐藏状态分解为自定义的加成分量，然后在固定注意得分和MLP激活的情况下传递它们。DePass实现了忠实且精细的归因，而不需额外的辅助训练。该框架在多个归因任务中得到了验证，包括标记级、模型组件级和子空间级，展示了其有效性和准确性。
### Conclusion
实验结果表明，DePass具有将Transformer模型任意组件间的信息流动归因的潜力。我们期望DePass成为一个基础工具，广泛应用于可解释性领域的其他应用中。
## 386. `cs.CL` - DART：用于临床自然语言处理的意大利监管药品文件结构化数据集 [PDF](https://arxiv.org/pdf/2510.18475), [HTML](https://arxiv.org/abs/2510.18475)
### Authors
Mariano Barone,Antonio Laudante,Giuseppe Riccio,Antonio Romano,Marco Postiglione,Vincenzo Moscato
### Background
生物医药领域的自然语言处理在从监管文件中提取药理知识方面已成为重点关注对象，应用范围从不良事件监测到人工智能辅助的临床决策支持。然而，该领域的研究主要依赖于英文语料库，如DrugBank，这在其他医疗体系中造成了资源缺口。
### Innovation
本文介绍了DART（来自监管文本的药物注释），这是首款基于意大利药品管理局（AIFA）官方仓库提取出的意大利药品说明书摘要的结构化语料库。DART采用了一套可复现的工作流进行采集、结构化信息提取和临床摘要生成，并利用微调后的大语言模型和低温解码技术实现了对关键药理学领域的结构化信息提供。此外，作者利用该数据集构建了一个基于大语言模型的药物相互作用检查器，验证了其实用性。
### Conclusion
实验结果表明，指令微调后的大型语言模型可以在结构化的文本字段支持下准确地推断潜在的相互作用及其临床意义。作者已将代码开源在GitHub上。
## 387. `cs.CL` - 基于LLM的CEFR标注WordNet：语言学习中的分级语义数据库 [PDF](https://arxiv.org/pdf/2510.18466), [HTML](https://arxiv.org/abs/2510.18466)
### Authors
Masato Kikuchi,Masatsugu Ono,Toshioki Soga,Tetsu Tanabe,Tadachika Ozono
### Background
尽管WordNet因其结构化的语义网络和广泛的词汇量而是一个有价值的资源，但其细微语义区分对第二语言学习者来说具有挑战性。为了应对这一挑战，我们开发了一个与共同欧洲语言参考框架（CEFR）标注的WordNet，通过将语义网络与语言 proficiency 等级结合起来。我们利用一个大型语言模型自动化了这一过程，测量WordNet中的语义定义与在线英语词汇资料库之间的相似性。
### Innovation
我们利用大型语言模型自动化将CEFR与WordNet结合的过程，通过与英语词汇在线资料库的比较，明确语义差异。我们构建了一个大规模包含CEFR水平信息的语料库，从而开发了上下文词库分类器。实验表明，基于该语料库微调的模型与基于黄金标准注释训练的模型性能相当，通过将该语料库与黄金标准数据结合，我们成功开发了一个实用的分类器，达到宏F1分数0.81，显示出高精度的注释。
### Conclusion
我们开发的CEFR标注WordNet、语料库和分类器已公开发布，旨在填补自然语言处理与语言教育之间的差距，从而促进更有效和高效的语言学习。
## 388. `cs.CL` - 语言模型中的参与性削弱了安全性：刻板印象和毒性如何塑造幽默 [PDF](https://arxiv.org/pdf/2510.18454), [HTML](https://arxiv.org/abs/2510.18454)
### Authors
Atharvan Dogra,Soumya Suvra Ghosal,Ameet Deshpande,Ashwin Kalyan,Dinesh Manocha
### Background
随着大型语言模型在创意写作和内容参与中的广泛应用，人们对模型输出的安全性产生了担忧。本文将幽默生成作为测试案例，评估现代LLM管道中幽默优化与有害内容之间的耦合关系，通过共同测量幽默、刻板印象和毒性来研究这一问题。进一步通过信息论度量分析不协调信号，结果显示在六种模型中，有害输出获得了更高的幽默评分，且角色角色提示下幽默评分增加，表明生成器和评估者之间存在一种偏向放大的循环。信息论分析显示有害提示扩大了预测不确定性，并且在某些情况下，甚至可以使得有害的笑料更为预期，表明在学习到的幽默分布中存在结构性嵌入。
### Innovation
本文使用幽默生成作为测试案例，评估现代LLM管道中幽默优化与有害内容之间的耦合关系，通过共同测量幽默、刻板印象和毒性来研究这一问题，并进一步通过信息论度量分析不协调信号。研究发现，有害输出获得了更高的幽默评分，并且在角色角色提示下幽默评分增加，表明生成器和评估者之间存在一种偏向放大的循环；信息论分析显示有害提示扩大了预测不确定性，并且在某些情况下，甚至可以使得有害的笑料更为预期，表明在学习到的幽默分布中存在结构性嵌入。
### Conclusion
量化数据显示，刻板/有毒笑话在幽默评分上平均提高了10-21%，并且在由LLM基线标准标记为有趣的笑话中出现的频率增加了11%-28%，在人类感知为有趣的生成中也更常见。此外，符合闭合模型的语料库也显示出增加的刻板印象和毒性。
## 389. `cs.CL` - 扩散语言模型有多高效？一种关于效率评估实践的批判性审视 [PDF](https://arxiv.org/pdf/2510.18480), [HTML](https://arxiv.org/abs/2510.18480)
### Authors
Han Peng,Peiyu Liu,Zican Dong,Daixuan Cheng,Junyi Li,Yiru Tang,Shuo Wang,Wayne Xin Zhao
### Background
扩散语言模型（DLMs）作为一种与长期占主导地位的自回归（AR）模型不同的替代方案正在兴起，它们提供了一个可并行的解码过程，有望提高效率。然而，实际应用中，当前开源的DLMs在速度上往往不如AR模型，限制了它们的实际应用价值。以往关于DLM效率的研究中存在一些关键问题，而这项研究通过实证基准测试和基于屋顶线的理论分析，揭示了AR模型通常能实现更高的吞吐量，而DLMs则一直表现较差。
### Innovation
这项研究揭示了DLM效率评估中的一些关键问题，并通过实证基准测试和基于屋顶线的理论分析，展示了AR模型和DLMs之间在效率上的差异。研究还发现，用于加速的技术（如双重缓存和并行解码）仅在小批次规模上有效，其优势在扩展时减弱。因此，这项研究提出的发现强调了需要改进的强效评价方法和加速策略，以推动DLMs的研究进展.
### Conclusion
这项研究明确指出，当前用于评估DLM效率的方法存在不足，且现有的加速策略在大规模应用中效果有限。为了推进DLMs的研究，必须引入更健壮的评估方法和改进加速策略，以实现更高的效率。
## 390. `cs.CL` - 大型语言模型需要文化推理才能具备身份意识 [PDF](https://arxiv.org/pdf/2510.18510), [HTML](https://arxiv.org/abs/2510.18510)
### Authors
Alistair Plum,Anne-Marie Lutgen,Christoph Purschke,Achim Rettinger
### Background
大型语言模型在自然语言处理中成为最新趋势，广泛应用于日常生活中的数字工具中。然而，这些模型的回答往往会反映出一种狭隘的文化视角，忽视了全球用户的多样性。这种缺失的能力可以归结为文化推理，即模型识别文化特定的知识价值观和社会规范，并根据个别用户预期调整其输出。鉴于文化塑造了解释、情感共鸣和可接受行为，文化推理对于身份意识的人工智能至关重要。当这种能力有限或缺失时，模型可能会延续刻板印象、忽视少数群体观点、损害信任并加剧仇恨。
### Innovation
本文定义了文化推理这一概念，并强调它是一种基础能力，与事实准确性及语义连贯性并列。作者进一步指出，尽管宽泛的数据集可以帮助，但并不能独立确保真正的文化能力。因此，作者建议将文化推理作为基础能力对待。通过澄清概念并提出评估方向，为未来能够对人类文化的复杂性作出更敏感响应的系统奠定了基础。
### Conclusion
文化推理对于建立认同感的人工智能系统至关重要，而现有评估方法尚未能捕捉到适应性推理的能力。因此，作者主张文化推理应被视为与事实准确性及语义连贯性并重的基础能力，为开发具备更高文化敏感性的未来系统提供了方向。
## 391. `cs.CL` - 在临床LLMs中建立信任：偏见分析与数据集透明度 [PDF](https://arxiv.org/pdf/2510.18556), [HTML](https://arxiv.org/abs/2510.18556)
### Authors
Svetlana Maslenkova,Clement Christophe,Marco AF Pimentel,Tathagata Raha,Muhammad Umar Salman,Ahmed Al Mahrooqi,Avani Gupta,Shadab Khan,Ronnie Rajan,Praveenkumar Kanithi
### Background
大型语言模型在医疗保健领域具有革命性的潜力，但其负责任和公平的发展依赖于对训练数据特征如何影响模型行为，特别是潜在偏见的深入理解。现有数据集编纂和偏见评估的实践通常缺乏必要的透明度，因此迫切需要全面的评估框架来增强信任并指导改进。本文研究了临床语言模型中潜在下游偏见的深度分析，重点关注不同人口群体（如种族、性别和年龄）在阿片类药物处方倾向上的差异性。本文还介绍了HC4：医疗综合共同语料库，这是一个新的、广泛编纂的预训练数据集，拥有超过890亿个词元。
### Innovation
本研究引入了HC4：医疗综合共同语料库，这是一个新颖且全面编纂的预训练数据集，超过890亿个词元。研究还采用了一种新的、专门针对医疗领域的评估方法，并利用现有的通用基准和新的医疗特定基准进行评估。
### Conclusion
评估为支持临床AI应用的公平性和安全性提供了关键见解。其提出的方法和数据集为在医疗保健领域公平地使用语言模型奠定了基础，有助于增强对临床LLMs的信任。
## 392. `cs.CL` - 社交媒体中超出明示的辨别人性化：一种双语数据集 [PDF](https://arxiv.org/pdf/2510.18582), [HTML](https://arxiv.org/abs/2510.18582)
### Authors
Dennis Assenmacher,Paloma Piot,Katarina Laken,David Jurgens,Claudia Wagner
### Background
在计算语言学和自然语言处理领域，数字化去人性化虽然是一个重要的议题，但仍然被广泛忽视。当前的研究主要集中在识别直接负面的语句作为去人性化的核心标志，这种方式虽然对于理解有害的在线通讯至关重要，但并不能全面覆盖去人性化的广泛领域，尤其是那些隐晦存在且不显得直接冒犯的语言，这些语言可能加剧针对边缘群体的消极偏见。
### Innovation
本文采用不同的采样方法收集了双语数据集，并通过人工和专家标注了16,000个文档和区间实例，以覆盖去人性化的不同维度。这些标注数据不仅可以用作机器学习模型的训练资源，也是评价未来去人性化检测技术的标准。通过优化机器学习模型在该数据集上的表现，本文展示了模型在零样本和少量样本上下文设置中的性能优越于最先进的模型。
### Conclusion
本文通过创建一个双语数据集，充分展现了去人性化的不同层面，并通过机器学习模型的优化，证明了该数据集在识别隐含的去人性化方面的有效性。
## 393. `cs.CL` - 基于动机的民间故事类型自动化分析：以灰姑娘案例研究为例 [PDF](https://arxiv.org/pdf/2510.18561), [HTML](https://arxiv.org/abs/2510.18561)
### Authors
Tjaša Arčon,Marko Robnik-Šikonja,Polona Tratnik
### Background
人工智能方法正被应用于许多研究领域，包括数字人文学科。我们为此领域建立了一种大规模分析的民俗学方法。通过机器学习和自然语言处理技术，我们自动检测了大量灰姑娘变体的故事动机，并使用聚类和降维分析其相似性和差异性。结果显示，大规模语言模型能够识别故事中的复杂交互，从而能够对大量文本集合进行计算分析，并促进跨语言比较。
### Innovation
开发了一种完整的研究框架和方法论，用于分析民间故事中的动机。使用大规模语言模型进行自动检测，并结合机器学习和自然语言处理方法进行更大规模的文本分析和比较，这对跨语言的研究具有重要意义。这种方法能够揭示故事中的复杂模式和联系，为研究者提供了新的分析工具。
### Conclusion
大规模语言模型在检测民间故事动机方面的应用表明，这种技术能够识别故事中的复杂而细微的交互，从而提供了一种新的方法来分析和比较大规模文本集合。这种方法有助于促进跨语言和文化的民俗学研究，为研究者提供了新的视角和分析途径。
## 394. `cs.CL` - MLMA：基于Mamba架构的多语言识别 [PDF](https://arxiv.org/pdf/2510.18684), [HTML](https://arxiv.org/abs/2510.18684)
### Authors
Mohamed Nabih Ali,Daniele Falavigna,Alessio Brutti
### Background
多语言自动语音识别（ASR）一直是一个挑战性任务，特别是在平衡不同资源语言之间的性能时更为困难。尽管序列建模技术已有显著进展，但仍然认为超过Transformer模型的架构可能会在扩展性和效率方面提供更好的选择。
### Innovation
本研究引入了MLMA（使用Mamba的多语言语言建模），该方法利用Mamba架构——一种专门为长上下文序列处理优化的高效状态空间模型——进行多语言ASR。MLMA通过隐式地引入语言意识调整和共享表示，在不同语言的鲁棒识别中表现优异。实验结果显示，MLMA在标准多语言基准测试中达到了与基于Transformer的架构相竞争的性能，证实了Mamba潜在作为扩展性强、效率高、准确的多语言语音识别框架的重要性。
### Conclusion
本研究证明了Mamba架构在多语言ASR中的可行性和潜在优势，提供了更具有扩展性、高效性和准确性的多语言语音识别解决方案。
## 395. `cs.CL` - 稳健模型适应的贝叶斯低秩因子分解 [PDF](https://arxiv.org/pdf/2510.18723), [HTML](https://arxiv.org/abs/2510.18723)
### Authors
Enes Yavuz Ugan,Ngoc-Quan Pham,Alexander Waibel
### Background
大语言模型在许多领域表现出色，但通常需要适应以处理如代码混合（在同一句中混合使用多种语言）这类的本地需求。直接微调这些模型会增加过拟合风险，可能导致基础模型泛化能力下降。
### Innovation
研究贝叶斯因素化适配器用于基础语音模型，通过在零附近设置先验条件，实现更稀疏的调整矩阵，从而在保持基础知识能力的同时进行特定领域的调整。方法应用于Whisper模型，并在不同多语言代码混合场景进行评估，展示了较低适应损失的同时显著减少了基础模型的灾难性遗忘。与LoRA相比，该方法在新的领域实现54%的进步，只损失了4%的新领域性能。
### Conclusion
贝叶斯适应方法证明了在不牺牲泛化能力的情况下，对语音基础模型进行微调的有效性。
## 396. `cs.CL` - 从超声舌运动中得到的动力学模型参数 [PDF](https://arxiv.org/pdf/2510.18629), [HTML](https://arxiv.org/abs/2510.18629)
### Authors
Sam Kirkham,Patrycja Strycharczuk
### Background
语音控制可以被建模为一个动力学系统，其中发音器官朝向目标位置被驱动。这些模型通常通过诸如电磁图谱(Electromagnetic Articulography, EMA)这样的数据点来评估，但最近的方法学进步使得超声成像成为了一个有前景的替代选择。这项研究旨在评估是否可以从超声声带运动中可靠地估计出线性谐振子的参数，并将这些参数与同时记录的EMA数据中估计出的参数进行比较。研究表明，超声成像和EMA提供了相似的动力学参数，而下颌短腱跟踪也充分捕捉了下颌的运动，这支持了使用超声运动来评价动力学发音模型的观点。
### Innovation
本研究利用超声成像作为评估动力学发音模型的替代方法，特别强调了从超声声带运动中可靠估计出线性谐振子参数的能力，以及超声成像与电磁图谱（EMA）结果的一致性。研究还指出，下颌短腱跟踪能够充分捕捉到下颌的运动。这些发现为使用超声运动评价动力学发音模型提供了新的方法和依据。
### Conclusion
研究表明，超声成像和EMA提供了相似的动力学参数，而下颌短腱跟踪也充分捕捉了下颌的运动。这些结果支持了使用超声运动来评估动力学发音模型的观点。
## 397. `cs.CL` - 调整代码转换语音中的语言平衡 [PDF](https://arxiv.org/pdf/2510.18724), [HTML](https://arxiv.org/abs/2510.18724)
### Authors
Enes Yavuz Ugan,Ngoc-Quan Pham,Alexander Waibel
### Background
尽管大型基础模型在标准基准测试中取得了令人印象深刻的成果，但在遇到代码转换测试案例时仍然表现不佳。当数据稀缺性不能作为模型表现不佳的常规解释时，问题可能源于代码转换时刻的罕见性，即第二语言嵌入得较为隐蔽。通常期望模型能够自行学习这种频率，但论文提出通过提供训练过程中的标签来帮助模型更好地应对这一挑战。
### Innovation
论文创新地利用了嵌入语言和主要语言之间的差异来突出代码转换点，这种方法简单且有效，用可微分的替代方案减轻了生成过程中的上下文偏差，从而提高了模型的鲁棒性。实验结果表明，这种创新方法可以帮助模型更准确地预测代码转换的位置，减少替代错误。
### Conclusion
通过调整训练过程中的语言平衡并定位关键的代码转换点，论文提出的方法能够显著提高基础模型在应对代码转换任务时的性能和准确性，特别是在阿拉伯语和中英文代码转换测试中。”，模型预测代码转换位置的正确性提高，表明上述方法的有效性。”（通过调整训练过程中的语言平衡并定位关键的代码转换点，模型在阿拉伯语和中英文代码转换测试中的预测结果更加准确，错误率减少。）
## 398. `cs.CL` - SemiAdapt和SemiLoRA：针对爱尔兰低资源语言翻译的高效领域自适应方法 [PDF](https://arxiv.org/pdf/2510.18725), [HTML](https://arxiv.org/abs/2510.18725)
### Authors
Josh McGiff,Nikola S. Nikolov
### Background
参数调整广泛用于定制大型语言模型，例如神经机器翻译(NMT)。然而，对具有数十亿参数的多语言模型进行调整时，利用迁移学习会非常耗时，成为低资源领域如爱尔兰翻译研究者进入的障碍。
### Innovation
引入了SemiAdapt和SemiLoRA作为半监督的高效推理方法，优化领域自适应并增强了整体性能。尤其地，SemiLoRA使参数有效地调整方法能够达到甚至超过对整个模型进行调整的方法。
### Conclusion
通过领域-数据集调整，基于嵌入的推理方法尤其适用于较大和较嘈杂的数据集。所有爱尔兰翻译模型均作为开放资源发布。这些方法希望让高质量的领域自适应和调整对低资源语言的研究人员更加容易获取。
## 399. `cs.CL` - 研究长文本理解能力在医学问答中的LLM能力 [PDF](https://arxiv.org/pdf/2510.18691), [HTML](https://arxiv.org/abs/2510.18691)
### Authors
Feras AlMannaa,Talia Tseriotou,Jenny Chim,Maria Liakata
### Background
这项研究是首次探讨大语言模型（LLM）在与临床相关的长语境（LC）医学问答中的理解能力。通过全面评估不同内容融入设置、不同能力和类型的语言模型以及跨任务定义的数据集，该研究揭示了模型规模效果、局限性、潜在的记忆问题以及推理模型的优势。研究还重点分析了RAG（Retrieval-Augmented Generation）对医学LC理解的影响，探索了单文档与多文档推理数据集中的最佳设置，并展示了RAG策略在LC中的改进措施。采用多维度的方法对评价方面进行了探讨，通过定性和错误分析回答了RAG在LC中为何有益的问题，揭示了一些常见故障情况。
### Innovation
该研究首次全面探讨了LLM在长语境医学问答中的理解能力。研究涵盖了不同内容融入设置、不同能力和类型的语言模型以及跨任务定义的数据集，揭示了模型规模的影响、潜在的记忆问题和推理模型的优势，并通过RAG策略在单文档与多文档推理数据集中的应用，展示了医学LC理解的改进方法。此外，研究采用多维度的方法进行评价，详细分析了RAG在不同情景下的效果，尤其强调了其在医学LC理解中的优势和局限性。
### Conclusion
研究通过多维度的方法揭示了RAG在长语境医学问答中的优化策略，提供了关于何时RAG有益于医学长文本理解的具体答案，并指出了一些常见的失败案例。
## 400. `cs.CL` - 在课程增强学习中使用可验证的准确性和避免报错奖励来缓解迷失对话现象 [PDF](https://arxiv.org/pdf/2510.18731), [HTML](https://arxiv.org/abs/2510.18731)
### Authors
Ming Li
### Background
大型语言模型在单轮指令执行中表现出强大能力，但在多轮对话环境中会出现Lost-in-Conversation（LiC，逐步透露信息时性能下降）现象。研究者为了解决这一问题，基于可验证奖励的强化学习进展提出了一种新的框架，鼓励模型不仅要生成正确答案，还要判断多轮对话中问题的解答可能性，通过逐步增加对话难度，稳定训练并提高可靠性能，使用多轮对话、基于策略的卷出和混合奖励系统来教导模型在解决问题时进行明智的避免报错，减少过早回答行为导致的LiC。
### Innovation
提出了一种新的框架——Curriculum Reinforcement Learning with Verifiable Accuracy and Abstention Rewards (RLAAR)，该框架通过逐渐增加对话难度来逐步提高对话模型的可靠性，同时结合多轮对话、基于策略的卷出和混合奖励系统，使模型学会在解决问题时进行明智的避免报错，减少过早回答行为导致的LiC现象，显著降低了LiC性能衰减，提高了可靠的避免报错率。
### Conclusion
RLAAR框架通过逐步增加对话难度，提高模型在多轮对话中的可靠性，减少过早回答引起的表现降级现象，显著提升了模型的性能和可靠性，并提供了构建多轮对话中稳健和可信的大型语言模型的实用方法。
## 401. `cs.CL` - WebSeer：通过自我反思强化学习训练更深的搜索代理 [PDF](https://arxiv.org/pdf/2510.18798), [HTML](https://arxiv.org/abs/2510.18798)
### Authors
Guanzhong He,Zhen Yang,Jinxin Liu,Bin Xu,Lei Hou,Juanzi Li
### Background
搜索代理在交互环境中实现了智能信息检索和决策的重要进步。尽管强化学习已经被用于训练能够进行动态交互检索的代理模型，现有的方法仍受限于浅薄的工具使用深度和在多次迭代交互中累积的错误。
### Innovation
该论文提出了一种名为WebSeer的智能搜索代理，该代理通过结合强化学习和自我反思机制进行训练。具体而言，该论文构建了一个注解有自我反思模式的大数据集，并设计了一种两阶段训练框架，将冷启动和强化学习统一在自我反思框架中，以在真实世界基于网络的环境中生成更长、更具反思性的工具使用轨迹，从而显著延长工具使用链并提高答案准确性。
### Conclusion
通过单一的14B模型，我们在HotpotQA和SimpleQA上分别达到了72.3%和90.0%的准确率，并且模型在不同分布数据集上表现出强大的泛化能力。相关代码可在此处访问：this https URL
## 402. `cs.CL` - KAT-Coder技术报告 [PDF](https://arxiv.org/pdf/2510.18779), [HTML](https://arxiv.org/abs/2510.18779)
### Authors
Zizheng Zhan,Ken Deng,Xiaojiang Zhang,Jinghui Wang,Huaixi Tang,Zhiyi Lai,Haoyang Huang,Wen Xiang,Kun Wu,Wenhao Zhuang,Minglei Zhang,Shaojie Wang,Shangpeng Yan,Kepeng Lei,Zongxian Feng,Huiming Wang,Zheng Lin,Mengtong Li,Mengfei Xie,Yinghan Cui,Xuxing Chen,Chao Wang,Weihao Li,Wenqiang Zhu,Jiarong Zhang,Jingxuan Xu,Songwei Yu,Yifan Yao,Xinping Lei,Han Li,Junqi Xiong,Zuchen Gao,Dailin Li,Haimo Li,Jiaheng Liu,Yuqun Zhang,Junyi Peng,Haotian Zhang,Bin Chen
### Background
大型语言模型（LLMs）的最新进展推动了自主编码的发展，使模型能够在交互式软件开发流程中自主推理、规划和行动。然而，从静态文本训练到动态现实世界自主执行之间的差距仍然存在核心挑战。
### Innovation
提出了一种名为KAT-Coder的大型自主编码模型，通过多阶段课程训练，包括中期训练、监督微调（SFT）、强化微调（RFT）和强化到部署适应。每个阶段都有特定的任务：中期阶段通过真实软件工程数据和合成自主交互来增强推理、规划和反思能力；SFT阶段构建包含多种编程语言、开发环境和任务类型的大型数据集；RFT阶段提出了一种新的多事实强化奖励形式，用于稳定的策略优化；强化到部署阶段通过错误掩蔽SFT和树状轨迹训练，使模型适应生产级IDE环境。
### Conclusion
这些阶段使KAT-Coder能够实现工具使用可靠性、指令对齐和长上下文推理，并构成了实际智能编码代理部署的基础。KAT系列32B模型KAT-Dev已开放源代码。
## 403. `cs.CL` - Fine-Tuned Thoughts: Leveraging Chain-of-Thought Reasoning for Industrial Asset Health Monitoring [PDF](https://arxiv.org/pdf/2510.18817), [HTML](https://arxiv.org/abs/2510.18817)
### Authors
Shuxin Lin,Dhaval Patel,Christodoulos Constantinides
### Background
小型语言模型（SLMs）在工业应用等专门领域变得越来越受欢迎，因为它们效率高、计算要求低，并且能够针对特定领域进行微调，提供准确且成本效益高的解决方案。然而，在如工业4.0这样的专门领域中，使用SLMs进行复杂推理仍然是一个挑战。
### Innovation
本文提出了一种基于链码推理（CoT）知识蒸馏的工业资产健康监测框架，该框架通过从大型语言模型（LLMs）向较小、更高效的模型（SLMs）转移推理能力，来实现复杂推理。此外，还通过多选题回答（MCQA）提示来增强推理并优化决策，同时利用上下文学习验证生成知识的质量，并将微调后的SLMs与生成的知识与广泛使用的LLMs进行性能基准测试。结果显示，在CoT推理支持下微调的SLMs显著优于基线模型，并缩小了与LLM的差距。
### Conclusion
微调后的SLMs在郭推理支持下，在工业资产健康监测中表现出色，显著提升了性能，为专门领域的复杂推理提供了新的解决方案。
## 404. `cs.CL` - AI在美式报纸中的使用是广泛、不均衡的，且很少披露 [PDF](https://arxiv.org/pdf/2510.18774), [HTML](https://arxiv.org/abs/2510.18774)
### Authors
Jenna Russell,Marzena Karpinska,Destiny Akinode,Katherine Thai,Bradley Emi,Max Spero,Mohit Iyyer
### Background
AI正迅速改变新闻界，但其在已发表报纸文章中的使用程度尚不清楚。本文通过审计1500家美国报纸在2025年夏季在线版的186,000篇文章数据集，填补了这一空白。使用最先进的AI检测工具Pangram，发现约有9%的新发表文章部分或完全由AI生成。AI的使用分布不均，更频繁地出现在较小的地方媒体、特定话题（如天气和科技）及某些拥有权集团。此外，分析了《华盛顿邮报》、《纽约时报》和《华尔街日报》45,000篇社论，发现这些社论中包含AI生成内容的可能性比同一出版社的新闻文章高出6.4倍，许多被AI标识的社论由知名公众人物撰写。尽管AI的使用非常普遍，但很少披露：手动审计100篇被AI标识的文章中，只有五篇披露了AI使用情况。总体而言，审计揭示了在新闻界使用AI的公开透明度急需提高和更新编辑标准的需求，以维护公众信任。
### Innovation
研究通过大规模的数据集审计，揭示了AI在报纸中的实际使用情况，并使用最先进的AI检测工具Pangram，发现约9%的文章部分或全部由AI生成。进一步分析显示AI使用在不同类型和规模的媒体中分布不均，并且社论中AI生成内容的比例远高于新闻文章。此外，强调了AI使用披露的不足，仅有少数被标识为AI的文章进行了披露。
### Conclusion
研究结果表明，AI在美式报纸中的使用普遍存在但分布不均衡，并且很少有披露。这强调了需要更高的透明度和更新的编辑标准，以便在新闻界中使用AI并维护公众信任。
## 405. `cs.CL` - 通过批判后编辑强化学习实现忠实可控的个性化 [PDF](https://arxiv.org/pdf/2510.18849), [HTML](https://arxiv.org/abs/2510.18849)
### Authors
Chenghao Zhu,Meiling Tao,Tiannan Wang,Dongyi Ding,Yuchen Eleanor Jiang,Wangchunshu Zhou
### Background
对大型语言模型（LLMs）进行忠实的个性化调整，以符合个人用户偏好是一项至关重要的任务，但同时也是具有挑战性的。尽管有监督微调（SFT）能够迅速达到性能上限，标准的基于人类反馈的强化学习（RLHF）也难以处理个性化的细微差别。基于标量奖励模型容易产生奖励欺诈，导致答案冗长且表面化。为了解决这些局限性，本文提出了一种名为批判后编辑的强化学习框架，该框架能实现更加忠实和可控的个性化。
### Innovation
本文提出了一个名为批判后编辑的强化学习框架，包括两个关键技术组件：（1）个性化生成奖励模型（GRM），它提供多维度评分和文本批评来抵制奖励欺诈；（2）批判后编辑机制，使得策略模型基于这些批评来修正其输出，从而实现更目标化和高效的训练。在严密的长度控制评估中，本文的方法在个性化基准测试中显著优于标准PPO。个性化Qwen2.5-7B的平均胜率提高了11%，个性化Qwen2.5-14B模型超越了GPT-4的性能。
### Conclusion
这些结果表明了一条实现忠实、高效和可控个人化的实际路径。
## 406. `cs.CL` - Topoformer：通过空间查询和重权化实现类似大脑的拓扑组织的变换器语言模型 [PDF](https://arxiv.org/pdf/2510.18745), [HTML](https://arxiv.org/abs/2510.18745)
### Authors
Taha Binhuraib,Greta Tuckute,Nicholas Blauch
### Background
生物脑的结构特征是具备空间功能组织，其中神经元根据其响应特性呈拓扑分布。相比之下，大多数机器学习模型中的表示缺乏空间偏置，其表现为无组织的向量空间，难以可视化和理解。这项研究旨在利用神经科学原理，改进机器学习模型的空间组织特性，提高模型的可解释性和直观性，特别是在自然语言处理（NLP）领域。研究通过在BERT架构中引入两种机制——空间查询和空间重权化，试图在变换器模型中实现类似大脑的拓扑组织结构，旨在使模型的各组件按空间特性布局，从而使模型更加直观和易于理解。
### Innovation
提出了一种新的自注意力机制，将变换器模型转化为“拓扑变换器”（Topoformer），并在自我注意力上引入空间查询和空间重权化。空间查询使关键和查询按二维网格排列，同时使局部查询池与给定的关键关联；空间重权化则将标准的全连接层转化为局部连接层。该研究首先在情感分类任务中训练一种单层拓扑变换器，随后将拓扑变换器模型应用到大型BERT模型中。结果显示，拓扑变体在NLP基准测试中表现与非拓扑控制模型相当，但却能够产生可以被八项语言测试套件评估的可解释性拓扑组织。此外，利用功能性磁共振成像（fMRI）数据集，该文进一步验证了Topoformer模型在模拟人类脑区语言网络方面的有效性。
### Conclusion
研究通过类似大脑的空间拓扑组织改进了基于变换器的语言模型，具体表现为在单层和多层BERT结构中的应用，验证了此类模型在NLP任务中的准确性，并保持了与非拓扑模型同样的表现水平。研究提出的Topoformer结构不仅提高了模型的可解释性和直观性，还进一步展示了其在模拟和理解人类大脑中语言信息组织方面的潜力。这种新型架构扩展了NLP研究中的可解释性，并进一步完善了对人类大脑语言活动机制的理解。
## 407. `cs.CL` - LightMem: 轻量级且高效的增强生成记忆系统 [PDF](https://arxiv.org/pdf/2510.18866), [HTML](https://arxiv.org/abs/2510.18866)
### Authors
Jizhan Fang,Xinle Deng,Haoming Xu,Ziyan Jiang,Yuqi Tang,Ziwen Xu,Shumin Deng,Yunzhi Yao,Mengru Wang,Shuofei Qiao,Huajun Chen,Ningyu Zhang
### Background
尽管大型语言模型（LLMs）具有出色的能力，但在动态和复杂环境中，它们很难有效利用历史交互信息。现有的记忆系统虽然引入了持久性信息的存储、检索和利用机制，但经常会增加显著的时间和计算开销。
### Innovation
本文提出了一种新的记忆系统LightMem，它在保持性能和效率之间找到了平衡。LightMem借鉴了人类记忆的Atkinson-Shiffrin模型，将记忆组织为三个互补阶段：首先通过轻量级压缩快速过滤无关信息，并根据主题对信息进行分组；其次，主题感知的短期记忆对这些基于主题的分组进行汇总和总结，以结构化方式访问内容；最后，带有睡眠时间更新的长期记忆使用离线过程将聚集与在线推理脱钩。
### Conclusion
在使用GPT和Qwen作为后端的LongMemEval实验中，LightMem在准确性上优于强基线（高达10.9%的提升），同时减少令牌使用量高达117倍，API调用量高达159倍，并将运行时间缩短超过12倍。完整的代码可以在该网址找到。
## 408. `cs.CL` - 一步一步进化：扩展大规模强化学习以适应万亿级思维模型 [PDF](https://arxiv.org/pdf/2510.18855), [HTML](https://arxiv.org/abs/2510.18855)
### Authors
Ling Team,Anqi Shen,Baihui Li,Bin Hu,Bin Jing,Cai Chen,Chao Huang,Chao Zhang,Chaokun Yang,Cheng Lin,Chengyao Wen,Congqi Li,Deng Zhao,Dingbo Yuan,Donghai You,Fagui Mao,Fanzhuang Meng,Feng Xu,Guojie Li,Guowei Wang,Hao Dai,Haonan Zheng,Hong Liu,Jia Guo,Jiaming Liu,Jian Liu,Jianhao Fu,Jiannan Shi,Jianwen Wang,Jianxin Lai,Jin Yang,Jun Mei,Jun Zhou,Junbo Zhao,Junping Zhao,Kuan Xu,Le Su,Lei Chen,Li Tang,Liang Jiang,Liangcheng Fu,Lianhao Xu,Linfeng Shi,Lisha Liao,Longfei Zheng,Meng Li,Mingchun Chen,Qi Zuo,Qiang Cheng,Qianggang Cao,Qitao Shi,Quanrui Guo,Senlin Zhu,Shaofei Wang,Shaomian Zheng,Shuaicheng Li,Shuwei Gu,Siba Chen,Tao Wu,Tao Zhang,Tianyu Zhang,Tianyu Zhou,Tiwei Bie,Tongkai Yang,Wang Hong,Wang Ren,Weihua Chen,Wenbo Yu,Wengang Zheng,Xiangchun Wang,Xiaodong Yan,Xiaopei Wan,Xin Zhao,Xinyu Kong,Xinyu Tang,Xudong Han,Xudong Wang,Xuemin Yang,Xueyu Hu,Yalin Zhang,Yan Sun,Yicheng Shan,Yilong Wang,Yingying Xu,Yongkang Liu,Yongzhen Guo,Yuanyuan Wang,Yuchen Yan,Yuefan Wang,Yuhong Guo,Zehuan Li,Zhankai Xu,Zhe Li,Zhenduo Zhang,Zhengke Gui,Zhenxuan Pan,Zhenyu Huang,Zhenzhong Lan,Zhiqiang Ding,Zhiqiang Zhang
### Background
我们提出了Ring-1T，这是一个具有万亿规模参数的首个开源、最先进的思维模型。该模型具有总计1万亿参数，每令牌激活约50亿个。训练万亿参数规模的模型引入了前所未有的挑战，包括训练推理不一致、卷出处理效率低和RL系统瓶颈等。面对这些挑战，我们提出了三项创新来解决问题。
### Innovation
为了应对这些挑战，我们首次提出了三种互相关联的创新：1) IcePop通过令牌级差异掩蔽和剪辑稳定了RL训练，解决了训练推理不一致带来的稳定性问题；2) C3PO++通过动态分区的方式提高了在令牌预算内的长期卷出时间效率，有效地利用了资源；3) ASystem是一种高性能的RL框架，旨在克服阻碍万亿参数模型训练的系统瓶颈。
### Conclusion
Ring-1T在关键基准测试中取得了突破性的成绩：在AIME-2025上得分为93.4，在HMMT-2025上得分为86.72，在CodeForces上得分为2088，在ARC-AGI-v1上得分为55.94。它在IMO-2025上获得了银牌级别成绩，突显了其出色推理解能力。通过发布完整的1万亿参数模型，我们为研究者提供了最先进推理解能力的直接访问权限，这标志着使大规模推理智能走向大众的一大里程碑，并确立了开源模型性能的新基准。
## 409. `cs.CL` - MTraining: 分布式动态稀疏注意力机制用于高效超长上下文训练 [PDF](https://arxiv.org/pdf/2510.18830), [HTML](https://arxiv.org/abs/2510.18830)
### Authors
Wenxuan Li,Chengruidong Zhang,Huiqiang Jiang,Yucheng Li,Yuqing Yang,Lili Qiu
### Background
长上下文窗口的采用已成为大型语言模型（LLMs）的标准特征，因为扩展的上下文显著增强了它们进行复杂推理的能力，并扩展了其在各种场景中的应用。动态稀疏注意是减少长上下文计算成本的一个有前景的方法。然而，在分布式设置中，有效地在超长上下文上对LLMs进行动态稀疏注意训练尤其是计算和通信负载的不平衡，仍然是一个重大挑战。本研究介绍了一种名为MTraining的新型分布式方法，它利用动态稀疏关注机制有效训练具有超长上下文的LLMs。特定地，MTraining集成了三种关键组件：动态稀疏训练模式、平衡稀疏环注意力，以及层次结构稀疏环注意力。这些组件旨在协同解决在模型训练过程中动态稀疏关注机制内固有的计算不平衡和通信开销问题。
### Innovation
MTraining方法引入了动态稀疏训练模式、平衡稀疏环注意力和层次结构稀疏环注意力，这些组件旨在协同解决在模型训练过程中动态稀疏关注机制内固有的计算不平衡和通信开销问题，以提高具有超长上下文的LLMs的训练效率。该方法被成功应用于Qwen2.5-3B模型，将上下文窗口从32K扩展到512K标记，同时在一组32个A100 GPU的集群上实现了高达6倍的训练吞吐量，而不牺牲模型的准确性。该研究通过在RULER、PG-19、InfiniteBench和Needle In A Haystack等一系列下游任务上进行评估，验证了MTraining的有效性。
### Conclusion
MTraining方法通过集成了动态稀疏训练模式、平衡稀疏环注意力和层次结构稀疏环注意力，成功解决了在超长上下文上对LLMs进行分布式动态稀疏注意训练的计算不平衡和通信开销问题。通过实际应用验证，MTraining在保持模型准确性的前提下，实现了显著提高的训练吞吐量。
## 410. `cs.CL` - 计算和可持续人工智能效率的度量与评估 [PDF](https://arxiv.org/pdf/2510.17885), [HTML](https://arxiv.org/abs/2510.17885)
### Authors
Hongyuan Liu,Xinyang Liu,Guosheng Hu
### Background
人工智能（AI）的迅速发展带来了前所未有的计算需求，但目前缺乏统一的方法来评估部署模型的性能、效率以及环境影响，导致难以在不同硬件、软件堆栈和数值精度条件下进行跨系统的比较和优化。当前的相关方法往往无法提供全面的视图，使得系统性能和优化的对比变得困难。
### Innovation
本文提出了一种统一且可复制的AI模型推理方法，该方法在实际应用条件下整合了计算和环境指标。该框架通过系统地测量延迟和吞吐量分布、能源消耗以及基于位置调整的碳排放等指标，为准确比较提供了碳意识的评价。这项工作通过系统分类这些因素，建立了一个严格的基准测试框架，并且通过开源自给代码使得独立验证和广泛应用成为可能，从而帮助研究人员和实践者做出基于证据的可持续AI部署决策。
### Conclusion
通过这一方法，本文确立了一个清晰的帕累托前沿，明确展示了准确度、延迟、能源和碳排放之间的权衡。该方法还通过开放源代码支持独立验证和采纳，推动了对可持续人工智能部署的研究和实践。
## 411. `cs.CL` - BreakFun: 通过结构化数据劫持LLMs [PDF](https://arxiv.org/pdf/2510.17904), [HTML](https://arxiv.org/abs/2510.17904)
### Authors
Amirkia Rafiei Oskooei,Mehmet S. Aktas
### Background
大型语言模型（LLMs）在处理结构化数据和遵循语法规则方面的能力推动了它们的广泛应用，然而这也使得它们变得脆弱。本文通过BreakFun方法，利用LLMs对结构化模式的严格遵守，揭示了这一脆弱性。
### Innovation
本文通过BreakFun方法提出了一个三步提示（通过无害框架和思考链分散注意力，结合一个精心设计的“特洛伊结构”），使LLMs生成有害内容。研究展示了这一策略在不同模型上的高成功率，并提出了一种名为Adversarial Prompt Deconstruction的安全防护措施，利用第二个LLM进行“字面转录”，以揭示用户的真实意图。
### Conclusion
研究指出了LLMs的核心优势如何转变成关键弱点，强调了针对欺骗性模式是一种有效的缓解策略，并通过实验证明了BreakFun的有效性，为构建更稳健、更对齐的模型提供了新的视角。
## 412. `cs.CL` - GenAI 是否改寫了我們的寫作方式？兩百萬篇預印本文獻的實證研究 [PDF](https://arxiv.org/pdf/2510.17882), [HTML](https://arxiv.org/abs/2510.17882)
### Authors
Minfeng Qi,Zhongmin Cao,Qin Wang,Ningran Li,Tianqing Zhu
### Background
预印本仓库成为学术交流的重要基础设施，其扩展改变了研究在期刊出版前的传播和评估方式。生成型大型语言模型（LLMs）进一步改变了手稿的撰写方式，但关于LLMs如何重塑科学出版的系统证据仍然有限。本文通过分析2016年至2025年间四个主要预印本文献库（如arXiv、bioRxiv、medRxiv、SocArXiv）超过210万篇预印本的文章，填补了这一空白，评估了手稿数量、作者、风格和学科导向的变化。这些变化揭示了LLMs更可能是有选择性的催化剂，而非普遍的颠覆者，加剧了学科间的差异。
### Innovation
本文通过引入多级分析框架，结合中断时间序列模型、合作和生产力指标、语言分析和主题建模，来评估生成型AI对手稿撰写的影响。这为评估生成型AI对学术出版的影响提供了首个实证基础，并强调了需要建立治理框架以确保在AI驱动的研究生态系统中保持信任、公平和问责制。
### Conclusion
生成型AI更像是选择性的催化剂，而不是普遍的颠覆者，它放大了现有优势并扩大了学科间的分歧。通过记录这些动态，本文为评估生成型AI对学术出版的影响提供了实证基础，并强调了需要建立治理框架以确保AI驱动的研究生态系统的信任、公平和问责制。
## 413. `cs.CL` - 层次联邦卸载方法的大型语言模型 [PDF](https://arxiv.org/pdf/2510.17895), [HTML](https://arxiv.org/abs/2510.17895)
### Authors
Yisheng Zhong,Zhengbang Yang,Zhuangdi Zhu
### Background
随着大型语言模型（LLMs）在实际应用中的集成，隐私和安全问题愈发显著，同时对于去除不良知识的需求日益增加。机器卸载（Machine Unlearning）作为一种解决方案应运而生，但面对连续且异质的卸载需求以及分散的、敏感的、非对称访问的数据，机器卸载面临着两大挑战：分布式环境中的数据干扰及遗忘与保留的平衡难题。
### Innovation
本文提出了一种针对LLMs的联邦卸载方法，该方法通过特定任务的适配器学习来分解卸载和保留任务，并采用分层合并策略以缓解目标间的冲突，从而实现了适应性强且稳健的卸载更新。实验结果表明，该方法能够有效地处理不同类型的卸载需求，同时保持LLM的有效性。
### Conclusion
本研究提出了一种新的联邦卸载方法，该方法不仅能够克服连续且异质的需求以及分布式敏感数据访问带来的挑战，还能有效地保护用户的隐私，维持LLM的功能性和实用性。
## 414. `cs.CL` - LLMs如何利用其深度？ [PDF](https://arxiv.org/pdf/2510.18871), [HTML](https://arxiv.org/abs/2510.18871)
### Authors
Akshat Gupta,Jay Yeung,Gopala Anumanchipalli,Anna Ivanova
### Background
已有证据表明，大规模语言模型在其层间并不均匀使用深度，尽管这方面的研究越来越多，但我们对它们的层间预测动态仍缺乏细粒度的理解。这项研究旨在通过追踪多个开放权重模型在推理过程中的中间表示，揭示它们在深度使用上的结构化、细致化利用。研究特别关注模型内部如何构建计算过程来形成预测，尤其是在早期层和深层层之间的过渡过程。
### Innovation
论文提出了一种名为“猜然后精炼”的框架来解释LLM内部如何组织计算以进行预测。研究发现了几个关键点：1. 早期层的高频率令牌在预测中充当统计性猜测，但随着上下文信息的增加，这些初始猜测会被精炼成上下文相关的令牌；2. 在高频令牌的预测上，即使是早期层，也约有70%的时间会被精炼，这表明正确的令牌预测不是一次性的；3. 针对三种不同案例的研究表明，从形态分析、事实回忆任务到多选题任务，模型都是逐步精炼预测的，显示了深度在预测过程中的动态使用模式。这些发现提供了关于LLMs在深度使用上的详细视图，揭示了成功预测的分层计算基础，并为未来提高基于变换器模型的计算效率提供了见解。
### Conclusion
综合实验结果，本文深入探讨了LLMs在深度使用上的结构化和细致化利用，为未来改进Transformer模型的计算效率提供了洞见。研究揭示了LLMs在分层计算中不同层面的细致化使用模式，为理解模型内部预测过程提供了更加精细的理解，并为优化模型性能提供了新的方向。
## 415. `cs.CL` - LLMs在本科微积分中的可解释性框架 [PDF](https://arxiv.org/pdf/2510.17910), [HTML](https://arxiv.org/abs/2510.17910)
### Authors
Sagnik Dakshit,Sushmita Sinha Roy
### Background
大型语言模型（LLMs）在教育中的使用越来越普遍，但是模型的正确性并不能完全反映其在解决问题过程中的质量、可靠性和教学有效性，尤其是在数学领域，多步逻辑、符号推理和概念清晰度至关重要。传统的评估方法主要关注最终答案的准确性，忽略了推理过程。因此，本文旨在通过提出一种新型的可解释性框架，结合本科微积分问题，来填补这一空白。
### Innovation
本文通过引入一种新的可解释性框架，使用本科学历的微积分问题作为代表领域，提取推理流程并将其分解为语义标记的操作和概念，结合提示削减分析评估输入相关性和输出稳定性。使用结构化的度量标准，如推理复杂性、短语敏感性和鲁棒性，对实际微积分I到III大学考试中的模型行为进行了评估。研究发现，LLMs经常会生成语法流畅但概念错误的解决方案，并且推理模式对提示措辞和输入变化敏感。这项框架能够细粒度地诊断推理失败，支持课程设计对齐，并指导开发可解释的人工智能辅助反馈工具。这项研究首次提供了在数学教育中解析LLMs推理的结构化、定量和教学基础的方法，为STEM学习环境中的AI透明和负责任部署奠定了基础。
### Conclusion
本文首次提出了一种结构化、定量且基于教学的框架，用于解释数学教育中LLMs的推理过程。该框架能为STEM学习环境中的AI透明和负责任部署提供基础。
## 416. `cs.CL` - 没有全局时间的主体事件本体：基础和执行语义 [PDF](https://arxiv.org/pdf/2510.18040), [HTML](https://arxiv.org/abs/2510.18040)
### Authors
Alexander Boldachev
### Background
本文提出了一种不依赖于全局时间来建模复杂动态系统的主体事件本体的形式化方法。该方法以具体原则为基础，通过事件的形成机制、因果关系定义、模型作为知识过滤器以及预设真实性的特点，确保系统的确定性和可执行性。
### Innovation
该研究创新性地提出了主体和事件本体的概念，并通过事件作为感知变化的固定点、因果关系通过‘先发生’定义、使用声明式数据流机制使本体可执行、模型作为知识过滤器、以及预设真实性等原则构建了一个不依赖于全局时间的系统框架。此外，通过九条公理确保了可执行本体的正确性，并特别强调了基于模型的方法，使得事件验证可以通过模式、行为授权和自动构建因果链来实现。
### Conclusion
该研究成功地在Boldsea系统中实现了这些理论建构，验证了其在分布式系统、微服务架构、DLT平台以及多视角场景中的适用性。
## 417. `cs.CL` - HouseTour：虚拟房地产智能代理 [PDF](https://arxiv.org/pdf/2510.18054), [HTML](https://arxiv.org/abs/2510.18054)
### Authors
Ata Çelen,Marc Pollefeys,Daniel Barath,Iro Armeni
### Background
现有的视觉-语言模型（VLMs）在几何推理方面存在困难，无法有效地从一系列展现实际3D空间的照片中生成空间感知的3D摄像机轨迹和自然语言摘要。现有的方法通常需要大量的手动或半自动操作，这在实际应用中并不高效和经济。为了克服这些限制，本文提出了一种名为HouseTour的方法，该方法能够在保持几何正确性的同时生成平滑的3D摄像机轨迹，并将其与视觉-语言模型结合以生成3D空间相关的描述。
### Innovation
该方法通过扩散过程生成3D摄像机轨迹，该过程受已知摄像机姿态的约束，并将这些信息集成到视觉-语言模型中进行3D空间描述。最终，通过3D高斯绘制合成了视频，以沿轨迹渲染新的视点。此外，该研究提出了HouseTour数据集，包含超过1,200个带有摄像机姿态、3D重建和房地产描述的房屋巡游视频。实验表明，将3D摄像机轨迹集成到文本生成过程中可以提高性能，优于单独处理每个任务的方法。引入了一个新的联合度量来评估单独和端到端的性能。
### Conclusion
该工作使得在房地产和旅游业应用中能够自动化生成专业级别的视频摘要，而无需专业的专业知识或设备。
## 418. `cs.CL` - SMaRT: 选择、混合与革新 - LLM 推动的推理和规划策略融合框架 [PDF](https://arxiv.org/pdf/2510.18095), [HTML](https://arxiv.org/abs/2510.18095)
### Authors
Nikhil Verma,Manasa Bharadwaj,Wonjun Jang,Harmanpreet Singh,Yixiao Wang,Homa Fashandi,Chul Lee
### Background
大规模语言模型（LLMs）已经重新定义了复杂任务的自动化处理，展示了出色的泛化能力。尽管取得了这些进展，目前最先进的方法仍依赖于单一策略的提示，未能充分利用各种推理方法的协同效应。没有任何一种单一策略能在所有情况下都表现出色，这强调了需要能够融合多种策略的框架，以最大化性能并确保效果 robust 性。
### Innovation
本文提出了SMaRT框架（Select, Mix, and ReinvenT），这是一种创新的策略融合方法，它通过无缝集成多种推理策略来创建平衡且高效的解决方案，从而突破单一策略的限制。与现有的方法不同，SMaRT 使用大语言模型作为智能整合器，而不仅仅是评估器，从而解锁了所有最佳方案。广泛的实证评估表明，SMaRT 在多个推理、规划及序列决策基准上的表现更为稳健和灵活，能够一致地在解决方案质量、约束遵守和性能指标等方面超出最先进的基线方法。
### Conclusion
这项工作通过开创一个新的跨策略校准范式重新定义了 LLM 驱动的决策制定，为推理系统解锁了更优结果，并推动了自我改进方法的边界。
## 419. `cs.CL` - 图像分辨率对生物医学多模态大型语言模型的影响 [PDF](https://arxiv.org/pdf/2510.18304), [HTML](https://arxiv.org/abs/2510.18304)
### Authors
Liangyu Chen,James Burgess,Jeffrey J Nirschl,Orr Zohar,Serena Yeung-Levy
### Background
成像技术在生物医学研究和现代医学中至关重要，需要对来自多种模态的高分辨率图像进行分析。虽然多模态大型语言模型（MLLMs）在生物医学图像分析中显示出潜力，但大多数模型针对通用数据集中的低分辨率图像设计，可能导致关键信息的丢失。
### Innovation
研究发现，原生分辨率训练和推理能够显著提高多种任务中的表现；训练与推理分辨率不匹配会严重降低表现；混合分辨率训练有效缓解了不匹配的问题，并平衡了计算约束与性能要求。
### Conclusion
基于这些发现，研究者建议优先使用原生分辨率推理和混合分辨率数据集以优化生物医学MLLM，从而在科学研究和临床应用中实现变革性影响。
## 420. `cs.CL` - Saber: 一种高效的适应加速和回溯增强重映射抽样算法用于扩散语言模型 [PDF](https://arxiv.org/pdf/2510.18165), [HTML](https://arxiv.org/abs/2510.18165)
### Authors
Yihong Dong,Zhaoyu Ma,Xue Jiang,Zhiyuan Fan,Jiaru Qian,Yongmin Li,Jianha Xiao,Zhi Jin,Rongyu Cao,Binhua Li,Fei Huang,Yongbin Li,Ge Li
### Background
扩散语言模型（DLMs）正在成为与自回归范式相比更为强大和有前途的替代方案，它们具备并行生成和双向上下文建模的内在优势。然而，在具有较强结构约束的代码生成任务中，DLMs的表现受到推理速度和输出质量之间关键权衡的影响而受到严重阻碍。加速代码生成过程通常会通过减少抽样步骤，但会导致性能灾难性下降。
### Innovation
提出了一种名为Saber的新颖训练无损抽样算法，旨在提高扩散语言模型在代码生成中的抽样效率和输出质量。Saber的设计灵感来源于代码生成过程中两个关键见解：1）它可以随着更多代码上下文被建立起来而适应性地加速；2）它需要一个回溯机制来撤销生成的标记。实验结果显示，Saber在多个主流代码生成基准上的Pass@1准确率平均提高了1.9%，同时实现平均251.4%的推理加速。
### Conclusion
通过充分利用扩散语言模型的固有优势，我们的工作显著缩小了代码生成任务中扩散语言模型与自回归模型的性能差距。
## 421. `cs.CL` - SafeCoop: 解开自主协作驾驶中的全栈安全问题 [PDF](https://arxiv.org/pdf/2510.18123), [HTML](https://arxiv.org/abs/2510.18123)
### Authors
Xiangbo Gao,Tzu-Hsiang Lin,Ruojing Song,Yuheng Wu,Kuan-Ru Huang,Zicheng Jin,Fangzhou Lin,Shinan Liu,Zhengzhong Tu
### Background
协作驾驶系统利用车辆到每一切割物（V2X）通信在多个代理之间增强驾驶安全性和效率。传统的V2X系统以原始传感器数据、神经特征或感知结果作为通信媒介，面临着高带宽需求、语义损失和互操作性问题。最近的研究表明，自然语言作为一种新的通信媒介具有潜力，可以提供丰富的语义信息、决策级推理和人机互操作性，同时带宽需求显著降低。然而，这种方法也带来了新的安全和隐私风险，如消息丢失、幻觉、语义操控和恶意攻击等问题。本文是首个系统研究基于自然语言的协同驾驶全栈安全和安全问题的论文，通过构建一个全面的攻击策略分类和一个名为SafeCoop的安全防护管道，解决了这些问题。SafeCoop集成了语义防火墙、语言感知一致性和多源共识，利用代理转换函数实现跨帧空间对齐。
### Innovation
本文首次全面研究了基于自然语言的协同驾驶全栈安全性，开发了一种安全防护管道（SafeCoop），其中包括语义防火墙、语言感知一致性和多源共识。SafeCoop利用跨帧空间对齐，解决连接中断、重放干扰、内容篡改和多连接伪造等安全问题，旨在提升在恶意攻击下的驾驶分数和恶意检测的F1分数达67.32%。
### Conclusion
本文的研究为自主协作驾驶中安全、安全和值得信任的语言驱动合作提供了指导。SafeCoop在封闭循环的CARLA仿真测试中表现优异，在面临恶意攻击时驾驶分数提高了69.15%，恶意检测的F1得分最高达到67.32%。
## 422. `cs.CL` - VLSU：映射联合多模态理解的人工智能安全界限 [PDF](https://arxiv.org/pdf/2510.18214), [HTML](https://arxiv.org/abs/2510.18214)
### Authors
Shruti Palaskar,Leon Gatys,Mona Abdelrahman,Mar Jacobo,Larry Lindsey,Rutika Moharir,Gunnar Lund,Yang Xu,Navid Shiee,Jeffrey Bigham,Charles Maalouf,Joseph Yitan Cheng
### Background
现有的多模态基础模型的安全评估通常将视觉和语言输入分开处理，忽视了联合解释带来的风险，其中良性内容可能在组合时变成有害内容。现有方法也无法明确区分不安全内容与边缘情况，导致过度封堵或应封堵的内容未能封堵的问题。这篇论文提出了Vision Language Safety Understanding (VLSU)框架，旨在系统性地评估多模态安全，通过细粒度的严重性分类和17种不同的安全模式进行组合分析。研究使用了包含8,187样本的真实图像和人工标注的大规模数据集，覆盖了15类危害类别。评估了11个最先进的模型，揭示了联合理解方面的系统性失败。
### Innovation
提出了VLSU框架，通过细粒度的严重性分类和17种不同的安全模式进行组合分析。构建了包含8,187样本的大规模数据集，覆盖15类危害类别。揭示了在联合图像-文本推理中确定安全性标签时，模型的性能迅速下降至20-55%，尽管单模态信号的分类准确率高达90%以上。还发现，模型在拒绝不安全内容的同时平衡处理边缘情况的能力较弱。例如，在Gemini-1.5中，指令框架可以减少过度封堵率至10.4%，但代价是不安全内容的拒绝率从90.8%降至53.9%。
### Conclusion
论文揭示了在联合图像-文本理解方面存在的弱点，并指出现有模型的对齐缺口，为后续研究提供了重要的测试平台，以推动AI安全领域的发展。
## 423. `cs.CL` - CodeRL+:通过执行语义对齐强化代码生成 [PDF](https://arxiv.org/pdf/2510.18471), [HTML](https://arxiv.org/abs/2510.18471)
### Authors
Xue Jiang,Yihong Dong,Mengyang Liu,Hongyi Deng,Tian Wang,Yongding Tao,Rongyu Cao,Binhua Li,Zhi Jin,Wenpin Jiao,Fei Huang,Yongbin Li,Ge Li
### Background
大型语言模型（LLMs）在通过学习大量代码语料库进行代码生成方面表现出色，但它们在从文本模式训练到满足功能性正确性的转变过程中存在根本性的语义差距，这由形式执行语义所规范。强化学习结合可验证奖励（RLVR）试图通过测试案例的执行结果奖励来解决这一问题。然而，仅依赖于通过/失败二元信号不足以建立代码文本表示与其执行语义之间的有效连接，尤其对于代码中的复杂逻辑错误而言。因此，本文提出了一种名为CodeRL+的新方法，它将执行语义对齐整合到RLVR训练管道中，使模型能够推断变量级别的执行轨迹，提供直接的执行语义学习信号。
### Innovation
CodeRL+通过执行语义对齐的方式，改变了传统的基于测试案例执行结果奖励的强化学习方法。它使模型能够推断出变量级别的执行轨迹，直接将现有的在线策略采样与各种强化学习算法无缝集成，从而能够更精确地对代码执行语义进行对齐。
### Conclusion
广泛的实验表明，CodeRL+在各种强化学习算法和大型语言模型中表现出色，能够大幅提高通过率，在代码推理和测试输出生成基准测试中的精度分别提高了15.5%和4.4%。此外，代码与执行语义之间的对齐增强证据表明，CodeRL+在多种任务中加强了代码的文本表示与其执行语义之间的对齐。
## 424. `cs.CL` - LLM水印部署应在特定应用场景中实现利益相关者激励机制的对齐，以促进其实用化 [PDF](https://arxiv.org/pdf/2510.18333), [HTML](https://arxiv.org/abs/2510.18333)
### Authors
Yepeng Liu,Xuandong Zhao,Dawn Song,Gregory W. Wornell,Yuheng Bu
### Background
尽管在大型语言模型(LLMs)的水印算法方面取得了一定进展，但在实际部署中仍受到限制。这主要是由于模型提供商、平台和最终用户之间的激励错配，具体体现在四大障碍上：市场竞争风险、检测工具管理、鲁棒性问题和归属问题。
### Innovation
本文回顾了三种类型的水印技术，并从激励角度重新审视了它们：模型水印自然符合模型提供商的利益，但在开源生态系统中面临新挑战；LLM文本水印作为反滥用工具对提供商有一定益处，但在狭窄的应用场景如数据集去污染或用户控制的溯源中更受欢迎；上下文内水印（ICW）专为受信任方设计，如会议组织者或教育工作者，他们将隐藏的水印指令嵌入文档中。若不诚实的审稿人或学生提交此文本到LLM，输出将带有可检测的水印，表明滥用行为。
### Conclusion
本文主张在特定应用场景中广泛探索激励对齐的方法，以实现利益相关者的激励机制对齐，例如ICW。此外，本文总结了设计原则，提出了激励对齐且适用于特定领域的水印设计，并指出了未来的研究方向。本文认为，LLM水印的实际部署需要在目标应用领域对利益相关者激励进行对齐，并促进社区积极参与。
## 425. `cs.CL` - PLAGUE：一种终身自适应生成多轮攻击的插件式框架 [PDF](https://arxiv.org/pdf/2510.17947), [HTML](https://arxiv.org/abs/2510.17947)
### Authors
Neeladri Bhuiya,Madhav Aggarwal,Diptanshu Purwar
### Background
大语言模型（LLMs）的进步非常迅速，随着代理工作流的出现，多轮对话已成为与LLMs交互的主要方式，用于完成长时间和复杂任务。尽管LLMs的能力在不断提高，但它们在多轮场景中越来越容易受到劫持攻击的影响，有害意图可以在对话中悄然嵌入，产生不良结果。现有的单轮攻击研究已经很充分，但其在多轮攻击中的适应性、效率和有效性仍存在挑战。
### Innovation
论文提出了PLAGUE，这是一种基于终身学习代理的插件式框架，用于设计多轮攻击。PLAGUE将多轮攻击的生命周期分为三个精心设计的阶段（引导、规划和完成），以系统性地探索多轮攻击家族。红队代理采用PLAGUE进行设计，实现了在较短或相对较少查询预算下现有所能达到的最佳劫持结果，提高了超过30%的攻击成功率。
### Conclusion
PLAGUE通过提供重要工具和见解，强调了计划初始化、上下文优化和终身学习在构建多轮攻击中的重要性，从而对全面的模型漏洞进行了评估。
## 426. `cs.CL` - 社交智能大语言模型代理的意图的概率建模 [PDF](https://arxiv.org/pdf/2510.18476), [HTML](https://arxiv.org/abs/2510.18476)
### Authors
Feifan Xia,Yuyang Fang,Defang Li,Yantong Xie,Weikang Li,Yang Li,Deguo Xia,Jizhou Huang
### Background
本文提出了一个基于概率的方法来建模大语言模型（LLM）代理在多轮社交对话中的意图。该方法通过维护一个关于对话伙伴潜在意图的信念分布，该分布基于上下文先验信息并在每次对话片段后通过可能性估计动态更新，从而为策略提供不断演化的背景知识，使得代理在不确定性中能够作出适应性更强的对话策略。实验结果显示，在SOTOPIA环境中，提出的框架在SOTOPIA-All和SOTOPIA-Hard任务上的综合得分分别提高了9.0%和4.1%，且略优于直接观察到对手意图的最优代理。这些初步的结果表明，概率意图建模可以为开发能够理解社交背景的大语言模型代理贡献力量。
### Innovation
本文提出的模型通过维护关于对话伙伴潜在意图的信念分布，并通过每次对话片段后的可能性估计进行动态更新，从而为代理提供了不断演化的背景知识，使其能够在不确定性和复杂的社交对话中灵活调整策略。该方法能够在不依赖于昂贵的标注数据的情况下，提高代理的对话能力和社会智能水平。
### Conclusion
本文初步实验结果表明，基于概率的意图建模可以显著提高大语言模型代理的社会智能，尤其是在复杂和不确定的社交对话场景中。该方法有望推动社交智能大语言模型的发展，为未来相关研究提供一个新的方向和参考。
## 427. `cs.CL` - 通过基于文本的检索增强生成实现零样本车辆型号识别 [PDF](https://arxiv.org/pdf/2510.18502), [HTML](https://arxiv.org/abs/2510.18502)
### Authors
Wei-Chia Chang,Yan-Ann Chen
### Background
在智能交通系统中，车辆型号和制造商识别（VMMR）是一项重要任务，但现有方法难以适应新推出的车型。当前的方法如 Contrastive Language-Image Pretraining (CLIP) 虽然能提供强视觉-文本对齐，但其固定的预训练权重限制了性能，且需要成本高昂的特定图像微调才能提高性能。
### Innovation
本文提出了一种将视觉语言模型（VLMs）与检索增强生成（RAG）结合的管道，支持零样本识别并通过文本推理。视觉语言模型将车辆图像转换为描述性特征，并与数据库中的文本特征进行比较。相关条目被检索并结合描述组成提示，语言模型推断制造商和型号。这种方法避免了大规模重新训练，并通过添加新车辆的描述实现快速更新。实验结果显示，该方法在识别性能上比CLIP基线提高了近20%，证明了RAG增强的LM推理在智慧城市应用中开展大规模VMMR的潜力。
### Conclusion
该方法提高了近20%的识别性能，展示了RAG增强的LM推理在智慧城市中开展大规模VMMR的潜力，并且这种方法支持零样本识别并能够通过添加新车辆的描述实现快速更新。
## 428. `cs.CL` - 视读文本：从分词到视觉阅读 [PDF](https://arxiv.org/pdf/2510.18840), [HTML](https://arxiv.org/abs/2510.18840)
### Authors
Ling Xing,Alex Jinpeng Wang,Rui Yan,Hongyu Qu,Zechao Li,Jinhui Tang
### Background
人类通过识别单词的形状、布局和模式来阅读文本，将它们与意义连接起来，从而能够处理拼写错误、扭曲的字体和各种文字。相比之下，现代大型语言模型依赖于子词分词，将文本分解为固定词汇表中的碎片。这种方法在资源丰富语言中效果很好，但在低资源语言中却分割过度，生成长且无语言意义的序列，增加计算量。
### Innovation
本文挑战现有的分词范式，提出了一种视觉为中心的替代方法。方法名为SeeTok，它将文本作为图像（视觉文本）呈现，并利用预训练的多模态大语言模型来解读这些图像，重新利用在大规模多模态训练中学习到的强大的OCR和文本视觉对齐能力。SeeTok在三种不同的语言任务中表现与子词分词相当或更优，同时使用4.43倍少的令牌，并减少70.5%的FLOPs，还能进一步提高跨语言泛化能力，增强对排版噪音的鲁棒性和语言层次感。
### Conclusion
SeeTok预示着从符号分词向人类视觉阅读方式的转变，并朝着更具自然性和认知启发的语言模型迈进。
## 429. `cs.CL` - 保留所做之事：在减轻遗忘中的随策略数据作用 [PDF](https://arxiv.org/pdf/2510.18874), [HTML](https://arxiv.org/abs/2510.18874)
### Authors
Howard Chen,Noam Razin,Karthik Narasimhan,Danqi Chen
### Background
语言模型（LMs）通过后训练适应新任务时存在一个风险，即可能会导致现有能力的退化，这种现象被称为灾难性遗忘。本文通过系统比较两种常用的后训练方法——监督微调（SFT）和强化学习（RL），探讨了如何减轻这一现象。研究发现，RL导致的遗忘比SFT少，同时在目标任务上的性能相近或更高。
### Innovation
通过简化模型，将LM视为先验知识和目标任务两个分布的混合物，发现RL的模式寻找本质，由于使用随策略数据（on-policy data），有助于保留先验知识，从而减少遗忘。进一步实验证实，随策略数据对减轻遗忘具有鲁棒性，而其他算法选择如KL正则化或优势估计则不具有这一特性。研究结果还暗示，使用近似的随策略数据可以有效减轻遗忘，且这类数据的获取效率更高。
### Conclusion
通过对比两种后训练方法，本文揭示了RL通过保持先验知识在学习目标任务时较少发生遗忘的原因。研究结果强调了在实际应用中使用近似随策略数据减轻遗忘的潜力。
## 430. `cs.CL` - 当文本嵌入遇到大规模语言模型：全面综述 [PDF](https://arxiv.org/pdf/2412.09165), [HTML](https://arxiv.org/abs/2412.09165)
### Authors
Zhijie Nie,Zhangchi Feng,Mingxin Li,Cunwang Zhang,Yanzhao Zhang,Dingkun Long,Richong Zhang
### Background
文本嵌入已成为自然语言处理（NLP）领域深学习时代的基石技术，推动了众多下游任务的进步。虽然许多自然语言理解挑战现在可以通过生成范式建模，并利用大规模语言模型（LLMs）的生成能力和理解能力，但诸如语义匹配、聚类和信息检索等许多实际应用仍依赖于文本嵌入以提高效率和效果。因此，将LLMs与文本嵌入集成成为近年来的主要研究重点。
### Innovation
本综述根据交互模式而非特定下游应用对近期工作进行分类，提供了LLMs时代多领域研究和应用贡献的全新而系统的概览。此外，还强调了从预训练语言模型（PLMs）时代遗留下来的未解决挑战，并探讨了LLMs带来的新兴障碍。
### Conclusion
本文概述了文本嵌入的未来发展方向，重点解决LLMs快速发展的自然语言处理（NLP）环境中理论和实践的机会。
## 431. `cs.CL` - 自然语言生成中自动幻觉评估的研究 [PDF](https://arxiv.org/pdf/2404.12041), [HTML](https://arxiv.org/abs/2404.12041)
### Authors
Siya Qi,Lin Gui,Yulan He,Zheng Yuan
### Background
大语言模型（LLMs）的迅猛发展带来了如何可靠地评估幻觉的问题，以确保模型的信任度。尽管自动幻觉评估（AHE）已成为解决这一问题的关键组成部分之一，但该领域在方法论上仍存在碎片化，这限制了概念上的清晰度和实际进展。
### Innovation
本研究通过对105种评估方法的系统分析，揭示了77.1%的方法专门针对LLMs，这种范式的转变需要新的评估框架。基于基础数据集和基准以及评估方法的分类法，提出了一个结构化框架来整理领域，以系统记录从LLM前到LLM后的方法演变。此外，本研究还发现了当前方法的根本局限性及其对实际部署的影响，为未来研究指出了关键挑战和战略方向，包括增强的可解释机制和应用特定评估标准的整合。
### Conclusion
为开发更可靠、更实用的幻觉评估系统，本文最终提供了一个研究路线图，其中包括增强的可解释机制和应用特定评估标准的整合。
## 432. `cs.CL` - 重新审视LLM不确定性：一种基于多智能体估算黑盒模型不确定性的方法 [PDF](https://arxiv.org/pdf/2412.09572), [HTML](https://arxiv.org/abs/2412.09572)
### Authors
Yu Feng,Phu Mon Htut,Zheng Qi,Wei Xiao,Manuel Mager,Nikolaos Pappas,Kishaloy Halder,Yang Li,Yassine Benajiba,Dan Roth
### Background
量化黑盒大语言模型（LLM）的不确定性对于生成可靠响应及实现可扩展的监督至关重要。现有方法通过评估模型对目标查询响应的一致性来衡量模型的不确定性，但这些方法可能会误导人，因为一个LLM可以自信地给出错误的答案，但在回答保持知识不变性的查询变体时能够自信且准确地给出答案。
### Innovation
本文系统分析了模型行为并展示了这种不一致源于参数知识的次优检索，通常由于上下文偏差阻止了对存储知识的持续访问。作者提出了DiverseAgentEntropy方法，这是一种基于多智能体交互在不同查询变体中进行不确定性估计的新颖理论方法，能够更准确地评估LLM的真正不确定性，提高幻觉检测能力，优于现有的基于一致性的技术。
### Conclusion
该研究通过DiverseAgentEntropy方法提高了对黑盒LLM不确定性的评估准确性，并增强了幻觉检测，相比现有方法具有优越性。
## 433. `cs.CL` - 无条件真实：大型语言模型的无条件不确定性学习 [PDF](https://arxiv.org/pdf/2408.10692), [HTML](https://arxiv.org/abs/2408.10692)
### Authors
Artem Vazhentsev,Ekaterina Fadeeva,Rui Xing,Gleb Kuzmin,Ivan Lazichny,Alexander Panchenko,Preslav Nakov,Timothy Baldwin,Maxim Panov,Artem Shelmanov
### Background
不确定性量化（UQ）已经成为检测大型语言模型（LLMs）的幻觉和低质量输出的一种有前景的方法。然而，由于自回归LLMs生成步骤之间的条件依赖性，获得适当的不确定性评分变得复杂，难以明确建模。现有方法难以解决这一问题。本研究旨在通过学习基于注意力的特征来解决这一挑战，提出了一种方法来推断LLMs的不确定性。本研究通过在十个数据集和三种LLMs上的实验评估，证明了该方法在选择性生成中的高效性，取得了显著优于其他监督和非监督方法的改进。
### Innovation
本研究创新性地提出了一种学习方法，通过训练一个基于注意力图和概率的回归模型，结合预先生成的令牌的递归计算不确定性评分，来推断LLMs的不确定性。同时，为了整合递归特征，还建议了一种两阶段的训练流程。这种新的学习方法有效地解决了LLMs生成步骤之间条件依赖性的建模难题。
### Conclusion
本研究在十个数据集和三种LLMs上的实验评估表明，所提出的方法在选择性生成中非常有效，实现了显著优于现有监督和非监督方法的改进，证明了该方法的有效性和实用性。
## 434. `cs.CL` - DialUp! Modeling the Language Continuum by Adapting Models to Dialects and Dialects to Models [PDF](https://arxiv.org/pdf/2501.16581), [HTML](https://arxiv.org/abs/2501.16581)
### Authors
Niyati Bafna,Emily Chang,Nathaniel R. Robinson,David R. Mortensen,Kenton Murray,David Yarowsky,Hale Sirin
### Background
大多数世界语言和方言资源匮乏，缺少主流机器翻译模型的支持。许多低资源语言和高资源语言有紧密关联，但在语言特征上表现出规律性差异。这凸显了模型对方言差异的鲁棒性和跨语言泛化能力的重要性。
### Innovation
提出了一种名为DialUp的方法，包括在训练时将预训练模型适应方言数据的M->D技术，以及推理时将方言数据调整至模型专业知识的D->M干预。M->D通过暴露合成数据，展示方言差异的语言机制，增强模型对未见过方言的鲁棒性；D->M则针对已知目标方言处理方言差异。
### Conclusion
这些方法在四种语言家族的几种方言上显示出显著的性能提升，在其它两种语言家族上也表现出轻微的提升。特征和错误分析表明，MT基础模型性能较低的语言种类更可能从这些方法中受益。
## 435. `cs.CL` - 任意区域抓取：向多模态LLM精确、语境像素理解迈进 [PDF](https://arxiv.org/pdf/2510.18876), [HTML](https://arxiv.org/abs/2510.18876)
### Authors
Haochen Wang,Yuhao Wang,Tao Zhang,Yikang Zhou,Yanwei Li,Jiacong Wang,Ye Tian,Jiahao Meng,Zilong Huang,Guangcan Mai,Anran Wang,Yunhai Tong,Zhuochen Wang,Xiangtai Li,Zhaoxiang Zhang
### Background
当前，多模态大型语言模型（MLLMs）在整体理解方面表现出色，但在处理复杂场景时无法捕捉密集的世界，需要对细节和对象相互关系进行精细分析。尽管区域级别的MLLMs已经提出了有效的解决方案，但以往的研究大多仅专注于独立理解给定的区域，而忽略了重要的全局上下文。因此，文章旨在通过引入Grasp Any Region (GAR)解决上述问题，使模型能够结合全局上下文进行精确感知，并模型多个提示之间的互动，从而实现复杂的组合推理，使多模态理解从被动描述转变为积极对话。同时，通过构建GAR-Bench基准测试，不仅提升了单一区域的理解评估准确性，还测量了多区域间的互动和复杂推理。
### Innovation
本文提出了Grasp Any Region (GAR)，一种基于区域级别的多模态理解方法。GAR利用RoI对齐特征回放技术，结合必要的全局上下文实现精确感知，并模型多个提示之间的互动，从而实现高级组合推理，回答关于任意区域的具体自由式问题。通过GAR-Bench基准测试，除了提升单一区域理解评估的准确性，还评估了多区域间的互动和复杂推理。实验表明，GAR不仅保持了强大的图像描述能力，而且在理解多个提示之间的关系方面表现优异，甚至超越了现有模型。
### Conclusion
GAR-1B不仅在图像描述能力上达到了最先进的水平，还在GAR-Bench-VQA上在理解和建模多个提示之间的关系方面表现更优。此外，零样本的GAR-8B在VideoRefer-BenchQ上甚至超过了领域内的VideoRefer-7B，显示出其强大的能力可以轻松迁移到视频中。
## 436. `cs.CL` - WHAT-IF：通过元提示探索分支叙事 [PDF](https://arxiv.org/pdf/2412.10582), [HTML](https://arxiv.org/abs/2412.10582)
### Authors
Runsheng ?Anson? Huang,Lara J. Martin,Chris Callison-Burch
### Background
该研究介绍了一个名为WHAT-IF的系统，它能够利用零射术元提示生成预先撰写的故事情节中的分支叙事。通过将系统作为交互式电子小说（interactive fiction, IF）游戏，玩家可以根据大型语言模型（large language model, LLM）生成的分支决策来选择不同的故事情节。这种方法基于一个现有的线性故事框架，在主角做出关键决策时创建分支。通过提示LLM考虑故事中的主要情节点，系统可以生成连贯且结构良好的替代故事线。该系统将分支故事情节存储在一个图中，以帮助追踪故事并保持结构完整性，最终构建一个完整的交互式电子小说系统。
### Innovation
该系统通过零射术元提示机制，利用大型语言模型从预写的故事情节生成具有分支的叙事。它提供了一个交互式平台，让玩家通过选择由LLM生成的不同决策来探索不同的故事情节。通过这种方法，系统能够创建连贯且结构良好的替代故事线，提供给玩家更加丰富的故事情节体验。
### Conclusion
WHAT-IF系统通过Meta-prompting技术生成了连贯且结构良好的分支叙事，为故事创作提供了新的方式。该系统能够继续发展，应用到其他叙事场景中，为用户带来更多互动性的故事情节体验。
## 437. `cs.CL` - FALCON: 细粒度激活对比正交未学习方法在大型语言模型中的应用 [PDF](https://arxiv.org/pdf/2502.01472), [HTML](https://arxiv.org/abs/2502.01472)
### Authors
Jinwei Hu,Zhenglin Huang,Xiangyu Yin,Wenjie Ruan,Guangliang Cheng,Yi Dong,Xiaowei Huang
### Background
大型语言模型已被广泛应用，但由于可能无意中编码了敏感或有害信息，引发了显著的安全问题。机器忘却是缓解这一问题的一个途径；但现有的训练时忘却是通过粗粒度的损失组合实现的，存在精确分离知识和平衡遗忘效果与模型用途之间的局限。
### Innovation
我们提出了一种新的基于表示的忘学习方法FALCON（Fine-grained Activation Manipulation by Contrastive Orthogonal Unalignment），该方法利用信息论指导进行高效的参数选择，采用对比机制增强表示分离，并将冲突梯度投影到正交子空间，以解决遗忘和保留目标之间的冲突。
### Conclusion
广泛的实验表明，FALCON 在实现优越的忘学习效果的同时保持了模型的用途，并且对知识恢复攻击表现出强大的抵抗力。
## 438. `cs.CL` - 通过周期编码实现LLMs的时序对齐以获得长距离时间表征 [PDF](https://arxiv.org/pdf/2503.04150), [HTML](https://arxiv.org/abs/2503.04150)
### Authors
Xue Han,Qian Hu,Yitong Wang,Wenchun Gao,Lianlian Zhang,Qing Wang,Lijun Mei,Chao Deng,Junlan Feng
### Background
大型语言模型（LLMs）在长时间跨度上存在时序对齐问题，因为LLMs在训练时没有足够的时序信息分布，导致了知识忘记或不足。性年周期编码‘Ticktack’方法旨在解决这些问题。
### Innovation
提出了一种新的'Ticktack'方法，通过使用性年周期表示而不是现有的格里高利年表示，增强年粒度的均匀分布。利用极坐标模型来表示60年周期及其内部年份顺序，并引入额外的时间编码确保LLMs理解。还提供了一种后训练时间表示对齐方法，以此来有效区分具有相关知识的时间点，从而提升长期任务的表现。
### Conclusion
通过提出'Ticktack'方法和创建长时跨度基准测试来评估其效果，实验结果表明该提议的有效性。
## 439. `cs.CL` - DCAD-2000：2000多种语言的数据集以及数据清理作为异常检测 [PDF](https://arxiv.org/pdf/2502.11546), [HTML](https://arxiv.org/abs/2502.11546)
### Authors
Yingli Shen,Wen Lai,Shuo Wang,Xueren Zhang,Kangyang Luo,Alexander Fraser,Maosong Sun
### Background
多语言大型语言模型（LLMs）的快速发展凸显了高质量、多样化和精心整理的多语言数据集的需求。现有的数据清理方法依赖于人工设计的启发式阈值，存在一定的局限性，为此需要新的方法来提高数据质量，特别是对于低资源语言。
### Innovation
本文提出了一种名为DCAD-2000的大型多语言语料库，该语料库从新提取的通用索引数据和现有的多语言来源构建而成，覆盖2,282种语言，总文本量达到46.72TB，文档数量为8.63亿份，涵盖了155种高-中等资源语言和159种书写体系。通过将数据清理重新定义为异常检测问题，提出了一种动态过滤范式，能够自动识别和移除噪声或异常内容，从而显著提高数据质量，增强清洗管道的稳健性和下游任务的性能，特别是在多语言基准测试中的低资源语言表现上取得了显著改善。
### Conclusion
通过在DCAD-2000上微调LLMs，展示了数据质量、清洗管道的稳健性和下游性能的重大改进，特别是在多个多语言基准中，对于低资源语言有显著改善。
## 440. `cs.CL` - 通过依赖其蕴含能力提高语言模型的查证性能 [PDF](https://arxiv.org/pdf/2505.15050), [HTML](https://arxiv.org/abs/2505.15050)
### Authors
Gaurav Kumar,Debajyoti Mazumder,Ayush Garg,Jasabanta Patro
### Background
自动事实核查一直是研究领域的挑战性任务。过去的研究尝试了各种策略，例如端到端训练、检索增强生成和提示工程，构建稳健的事实核查系统。但是，它们的准确性无法满足现实部署的需要。
### Innovation
本文提出了一种简单有效的方法，利用大型语言模型（LLM）生成的蕴含解释来训练编码器-only语言模型（ELMs）进行事实核查。并进行了严格实验，将该方法与现有方法及不同提示和微调策略进行对比，展示了该方法的优势。此外，还进行了模型解释的质量分析、消融研究和错误分析，为方法提供了全面的理解。
### Conclusion
研究表明，依赖语言模型的蕴含能力，利用生成的解释训练编码器-only语言模型的方法，在事实核查方面表现出优越性，为现实中部署提供了改进的查证性能。
## 441. `cs.CL` - 静默快速思考：动态压缩LLM推理链 [PDF](https://arxiv.org/pdf/2505.16552), [HTML](https://arxiv.org/abs/2505.16552)
### Authors
Wenhui Tan,Jiaze Li,Jianzhong Ju,Zhenbo Luo,Jian Luan,Ruihua Song
### Background
大型语言模型（LLMs）通过Chain-of-Thought（CoT）推理机制实现了卓越的性能，但这些基于令牌的推理链条在计算上非常昂贵且效率低下。本文旨在解决这一问题。
### Innovation
本文引入了一个名为Compressed Latent Reasoning（CoLaR）的新框架，通过二阶段训练方法动态压缩潜空间中的推理过程。研究发现，该方法能在减少推理链条长度的同时保持较高准确性，并且通过强化学习增强了CoLaR，使其能够在推理时动态调整推理速度。
### Conclusion
在四个数学推理数据集上的广泛实验表明，与基于潜空间的基线方法相比，CoLaR在可比压缩比下准确率高出14.1%，且推理链条长度减少了53.3%。在更具有挑战性的数学推理任务上，增强后的CoLaR性能提高了5.4%，同时显著减少了潜空间推理链条长度为82.8%。本文提出的模型和代码将在接收后公开。
## 442. `cs.CL` - LIMOPro: 提高推理效率和效果的测试时缩放改进 [PDF](https://arxiv.org/pdf/2505.19187), [HTML](https://arxiv.org/abs/2505.19187)
### Authors
Yang Xiao,Jiashuo Wang,Ruifeng Yuan,Chunpu Xu,Kaishuai Xu,Wenjie Li,Pengfei Liu
### Background
大语言模型（LLMs）通过测试时缩放方法展示了出色的问题解决能力，尤其是在使用具备详细推理链（CoT）数据的更强大模型进行微调后。然而，这些推理链中包含了许多冗长的元素，这些元素是人类解决问题的描述，分为主干推理（核心解决问题的路径）和功能元素（验证过程、备用解决方案和纠正错误）。主干推理至关重要，但功能元素会显著增加测试时推理的计算需求。
### Innovation
我们提出了PIR（Perplexity-based Importance Refinement）框架，该框架基于推理步骤对答案预测置信度的影响量化评估其重要性。PIR 系统地识别并只删除那些低重要性的功能步骤，同时保留主干推理元素，形成优化训练数据，该数据能够保持核心解决方案路径的完整性，同时减少冗长性。在 LIR-优化数据上进行微调的模型在具有挑战性的推理基准（AIME、AMC 和 GPQA Diamond）中表现出了更好的测试时缩放特性，生成更简洁的推理链，同时准确性提高了0.9%到6.6%，并且在标记使用上减少了3%到41%。
### Conclusion
我们的方法在不同的模型规模、数据来源和标记预算中表现出较强的通用性，为在测试时具有高效缩放、响应时间和计算效率等需求的场景下部署具有推理能力的LLMs提供了一种实际解决方案。
## 443. `cs.CL` - VITA-Audio：高效交错跨模态 token 生成的大规模语音语言模型 [PDF](https://arxiv.org/pdf/2505.03739), [HTML](https://arxiv.org/abs/2505.03739)
### Authors
Zuwei Long,Yunhang Shen,Chaoyou Fu,Heting Gao,Lijiang Li,Peixian Chen,Mengdan Zhang,Hang Shao,Jian Li,Jinlong Peng,Haoyu Cao,Ke Li,Rongrong Ji,Xing Sun
### Background
随着对自然人机交互的需求增长，基于语音的系统受到越来越多的关注，因为语音是日常沟通中最为常见的形式之一。然而，现有的语音模型在实时场景下生成第一个音频标记时仍然存在较高延迟，这成为部署中的一个瓶颈。为了解决这一问题，我们提出了VITA-Audio，这是一种端到端的大规模语音模型，具有快速的音频文本标记生成能力。该模型通过在单次模型前向传播过程中高效生成多个音频标记，不仅加速了推理过程，还显著降低了生成第一个音频所需的延迟。此外，我们还探索了一种四阶段逐步训练策略，以在最大程度保留语音质量的前提下实现模型加速。根据我们所了解的情况，VITA-Audio是首个在单次前向传播生成音频输出的多模态大规模语言模型，它能够实现最小延迟的实时对话功能。VITA-Audio 是完全可复现的，并且仅使用开源数据进行训练。实验结果显示，我们的模型在7B参数规模下实现了3~5倍的推理速度提升，同时在自动语音识别（ASR）、文本到语音（TTS）和语音问题回答（SQA）任务等多个基准测试中明显优于其他开源模型的相似规模模型。
### Innovation
我们提出了VITA-Audio，这是一种端到端的大规模语音模型，具有快速的音频文本标记生成能力。具体包括：1) 引入了轻量级的Multiple Cross-modal Token Prediction (MCTP) 模块，该模块在单次模型前向传播中高效生成多个音频标记，显著降低了延迟；2) 探索了四阶段逐步训练策略，以在最大程度保留语音质量的前提下实现模型加速。此模型是首个在单次前向传播中生成音频输出的多模态大规模语言模型，能够在实时对话中实现最小延迟。此外，该模型使用开源数据进行训练，并提供了完全可复现的实验结果。
### Conclusion
实验结果表明，我们的模型在7B参数规模下实现了3~5倍的推理速度提升，同时在多个语音任务基准测试中明显优于其他开源相似规模模型。VITA-Audio不仅提高了推理速度，还实现了强健的语音识别和合成性能。
## 444. `cs.CL` - DanmakuTPPBench: 一个用于时空点过程建模与理解的多模态基准 [PDF](https://arxiv.org/pdf/2505.18411), [HTML](https://arxiv.org/abs/2505.18411)
### Authors
Yue Jiang,Jichu Li,Yang Liu,Dingkang Yang,Feng Zhou,Quyu Kong
### Background
尽管时空点过程（TPP）在建模时间事件序列方面得到了广泛研究，但现有的数据集主要以单一模态为主，阻碍了联合处理时间、文本和视觉信息模型的发展。因此，为了填补这一空白，DanmakuTPPBench 提供了两个互补部分：DanmakuTPP-Events 和 DanmakuTPP-QA。DanmakuTPP-Events 从哔哩哔哩视频平台收集用户生成的弹幕评论（Danmaku），这些评论自然形成了带有精确时间戳、丰富文本内容和相应视频帧的多模态事件。DanmakuTPP-QA 则是一个通过先进大语言模型和多模态大语言模型（MLLMs）构建的具有挑战性的问答数据集，旨在解决复杂的时空文本视觉推理问题。
### Innovation
DanmakuTPPBench 通过引入 DanmakuTPP-Events 和 DanmakuTPP-QA 两个组成部分，填补了现有数据集在多模态时空点过程建模方面的空白。这个基准不仅能够帮助评估经典时间点过程模型和最新多模态大语言模型的能力，而且还推动了时空点过程模型在综合考虑时间、文本和视觉信息方面的应用。
### Conclusion
DanmakuTPPBench 在广泛评估的结果中揭示了当前方法在建模多模态事件动态方面的显著性能差距和局限性。这个基准通过建立强大的基线为今后的进一步研究奠定了基础，并向多模态语言模型场景中的时空点过程建模的整合发出了呼吁。
## 445. `cs.CL` - 通过演变编排进行多agent协作 [PDF](https://arxiv.org/pdf/2505.19591), [HTML](https://arxiv.org/abs/2505.19591)
### Authors
Yufan Dang,Chen Qian,Xueheng Luo,Jingru Fan,Zihao Xie,Ruijie Shi,Weize Chen,Cheng Yang,Xiaoyin Che,Ye Tian,Xuantang Xiong,Lei Han,Zhiyuan Liu,Maosong Sun
### Background
大型语言模型（LLMs）在多种下游任务上取得了显著成果，但其单一的结构限制了在复杂问题解决中的可扩展性和效率。虽然近期研究探索了LLMs之间的多agent协作，但大多数方法依赖于静态的组织结构，难以适应任务复杂性和agent数量的变化，导致协调成本增加和效率降低。
### Innovation
提出了一种木偶师风格的范式，其中中央协调者（“木偶师”）根据任务状态的变化动态指导各个agent（“木偶”）。该协调者通过强化学习训练，能够适应性地调度和优先级排序agent，实现灵活和可进化的集体推理。
### Conclusion
实验表明，该方法能够在降低计算成本的同时，实现更好的性能。进一步分析显示，关键改进来自于在协调者的演化过程中产生更紧凑、循环的推理结构。代码可以从此处获得：this https URL。
## 446. `cs.CL` - CoDial: 通过对话流程对齐提高可解释的指令理解对话系统 [PDF](https://arxiv.org/pdf/2506.02264), [HTML](https://arxiv.org/abs/2506.02264)
### Authors
Radin Shayanfar,Chu Fei Luo,Rohan Bhambhoria,Samuel Dahan,Xiaodan Zhu
### Background
构建能够跨不同任务泛化的指令理解对话（TOD）系统仍然是一个挑战。数据驱动的方法难以将所学到的技能有效转移到未见过的任务中。尽管基于模式的TOD框架通过分离任务逻辑和语言理解来提高泛化能力，但在很大程度上依赖于神经网络或生成模型，这会阻碍行为可解释性的提高。
### Innovation
提出了一种名为CoDial的新框架，将TOD任务模式转换为程式化LLM护栏代码（如NVIDIA的Colang），从而在推断期间实现解释性和高效的对话策略对齐。该框架引入了两种产生LLM护栏的方法——CoDial_free和CoDial_structured，并提出了一种反馈机制以实现生成代码的迭代改进。
### Conclusion
实验证明CoDial在广泛使用的STAR数据集上达到了最先进的性能，并在MultiWOZ数据集上与SOTA相当，同时提供了解释性。此外，通过手动和LLM辅助反馈，展示了CoDial的迭代改进能力，使其成为专家指导下在高风险领域对齐LLM的实用工具。
## 447. `cs.CL` - EvaLearn：通过顺序问题解决量化大型语言模型的學習能力和效率 [PDF](https://arxiv.org/pdf/2506.02672), [HTML](https://arxiv.org/abs/2506.02672)
### Authors
Shihan Dou,Ming Zhang,Chenhao Huang,Jiayi Chen,Feng Chen,Shichun Liu,Yan Liu,Chenxiao Liu,Cheng Zhong,Zongzhang Zhang,Tao Gui,Chao Xin,Chengzhi Wei,Lin Yan,Yonghui Wu,Qi Zhang,Xuanjing Huang
### Background
大多数现有的基准测试都并行评估模型，而EvaLearn则引入了一种创新的方法，即通过顺序解决挑战性问题来评估大型语言模型（LLMs）的学习能力和效率。EvaLearn涵盖了648个不同类型的任务的648个挑战性问题，分为182个序列，每一序列专注于一种特定的任务类型。这种方法强调了模型在先前解决问题基础上逐步积累经验的重要性。
### Innovation
EvaLearn是首个专门评估LLMs在棘手任务中学习能力和效率的基准。它采用了顺序解决问题的方法，使得模型能够通过之前的经验来提高学习效果。此外，EvaLearn提供了一套全面的自动化评估指标，用于量化模型的学习能力与效率。实验表明，不同模型在学习能力上的表现不尽相同，且当前具有较强静态能力的LLMs并不一定在所有任务中展现出明显的学习优势。
### Conclusion
EvaLearn提供了评估LLM潜力的新视角，揭示了模型与人类能力之间的差距，并提出了更深层次和动态的评估方法来促进LLM的发展。所有数据、评估框架和结果均在GitHub仓库中公开。
## 448. `cs.CL` - 利用测试时适配进行涉及英语方言的自然语言理解任务 [PDF](https://arxiv.org/pdf/2503.12858), [HTML](https://arxiv.org/abs/2503.12858)
### Authors
Duke Nguyen,Aditya Joshi,Flora Salim
### Background
TTDA是一种在无需使用标记数据集的情况下帮助模型在不同的领域、任务和分布之间泛化的优秀方法，对于自然语言处理（NLP）中的方言任务尤其有用。由于标准美式英语（SAE）与印度英语（IndE）、新加坡英语（SingE）、尼日利亚英语（NgE）等方言在分布上存在显著差异，且标注数据集稀缺，TTDA可减少这种差异的影响。
### Innovation
本文探索了SHOT这一著名的TTDA技术在方言NLP中的应用，通过改进和评估SHOT在不同方言GLUE（General Language Understanding Evaluation）数据集上的表现，发现当没有标记数据时，SHOT是一种可行的方法。此外，还理论上提出了方言差距的概念，并证明了方言差距对SHOT效果的正相关性。研究还发现，在许多情况下，对SAE进行微调的性能优于对方言数据进行微调。
### Conclusion
研究结果表明，SHOT在没有标记数据集的情况下是一种可行的方法，同时方言差距对SHOT效果有影响，对SAE进行微调通常能获得更好的性能。
## 449. `cs.CL` - 从未对齐到对齐：使用多向平行语料库扩展多语言LLMs [PDF](https://arxiv.org/pdf/2505.14045), [HTML](https://arxiv.org/abs/2505.14045)
### Authors
Yingli Shen,Wen Lai,Shuo Wang,Ge Gao,Kangyang Luo,Alexander Fraser,Maosong Sun
### Background
持续的预训练和指令调优在大规模多语言数据上已被证明对大语言模型（LLMs）扩展到资源匮乏的语言是有效的。然而，这种数据的不一致性限制了其有效捕捉跨语言语义的能力。相比之下，多向平行数据，即内容在多种语言中对齐，能够提供更强的跨语言一致性，并提供改善多语言性能的更大潜力。
### Innovation
本文介绍了一个基于TED Talks构建的大规模高质量多向平行语料库TED2025，该语料库覆盖了113种语言，多达50种语言在平行对齐，确保了广泛的多语言覆盖。利用该数据集，研究了多向平行数据的利用方法，包括继续预训练、指令调优以及关键影响因素的分析策略。实验表明，使用多向平行数据训练的模型在多语言数据集上始终优于使用未对齐多语言数据训练的模型。
### Conclusion
通过使用多向平行数据，可以在不牺牲性能的情况下显著提高LLMs在多语言环境中的表现。
## 450. `cs.CL` - 翻译障碍假设：大型语言模型的多语言生成遭受隐式翻译失败 [PDF](https://arxiv.org/pdf/2506.22724), [HTML](https://arxiv.org/abs/2506.22724)
### Authors
Niyati Bafna,Tianjian Li,Kenton Murray,David R. Mortensen,David Yarowsky,Hale Sirin,Daniel Khashabi
### Background
使用大型语言模型（LLMs）进行多语言生成往往在中到低资源语言上质量较差，但其原因尚不明确。论文首先展示了生成过程中存在一种隐式的任务解决-翻译管道，即模型首先以主要不依赖目标语言的方式解决所需的任务，然后将答案概念翻译成目标语言。研究表明，尽管任务解决成功，翻译阶段的失败是导致最终输出质量低的重要原因，并将这一现象命名为翻译障碍假设。
### Innovation
研究提出了翻译障碍假设，量化了任务解决和翻译阶段对最终失败的贡献，在108个语言对的单词翻译任务中发现翻译障碍是主要原因，尤其是对低资源目标语言更为严重。研究揭示了多语言生成的瓶颈对未来发展具有重要意义，为改善大型语言模型的多语言性提出了关键见解。
### Conclusion
研究结果表明翻译障碍在大多数语言对中解释了错误的主要部分，特别是在低资源目标语言中更为严重。该研究强调了一个重要的瓶颈，有助于未来工作改进大型语言模型的多语言性。
## 451. `cs.CL` - 反事实推理：语境中出现的分析 [PDF](https://arxiv.org/pdf/2506.05188), [HTML](https://arxiv.org/abs/2506.05188)
### Authors
Moritz Miller,Bernhard Schölkopf,Siyuan Guo
### Background
大规模神经语言模型在上下文学习方面表现出显著性能：能够即时学习和推理解读输入的内容。本研究进一步探讨了语言模型的反事实推理能力，即预测假设情境后果的能力。研究通过一个明确的合成线性回归任务来进行，该任务要求模型进行噪声修治，准确预测依赖于（1）推测未观察的潜在概念以及（2）从真实观测中复制上下文噪声。研究发现，Transformer模型的性能受到自我注意、模型深度和预训练数据多样性的影响。
### Innovation
研究增强了现有的可识别性结果，并将反事实推理问题简化为一种对上下文观察的变换操作；确定了残差流中潜在概念的线性表示，并设计了关键的‘噪声修治头’以进行反事实推理。这些模型在SDE动力学下的反事实推理中表现良好，表明Transformer可以在顺序数据上执行噪声修治，为反事实故事生成的潜在应用提供了初步证据。
### Conclusion
研究证据显示，Transformers能够进行噪声修治，这为反事实推理提供了一种新的机制，并且在SDE动力学下的反事实推理中表现良好，证实了其在噪声修治和反事实推理方面的潜力。研究代码可在提供的链接中获得。
## 452. `cs.CL` - 使用gSMILE解释大型语言模型 [PDF](https://arxiv.org/pdf/2505.21657), [HTML](https://arxiv.org/abs/2505.21657)
### Authors
Zeinab Dehghani,Mohammed Naveed Akram,Koorosh Aslansefat,Adil Khan,Yiannis Papadopoulos
### Background
大型语言模型（LLMs）如GPT、LLaMA和Claude在文本生成方面表现出色，但在决策过程上缺乏透明性，限制了其在高风险应用场景中的信任和问责。这些模型的不透明性使得用户难以理解其决策过程，从而影响了系统的可靠性和可信度。为了克服这一问题，研究提出gSMILE（生成性SMILE）框架，这是一种用于LLMs的保存兼容的扰动基于的标记层面可解释性方法，利用控制扰动提示、Wasserstein距离度量和加权线性替代模型来识别对输出影响最大的输入标记，生成直观的热力图以视觉方式突出显示关键标记和推理路径。该框架通过多项指标对gSMILE进行了评估，以确保产生的可解释性结果具有较高的可靠性和准确性。实验结果显示gSMILE在多种LLMs中都能产生符合人类认知规律的可解释性结果，表现出较好的性能和可解释性之间的平衡，为更透明和可信赖的AI系统的构建提供了支持
### Innovation
gSMILE是一个标记层面的解释性框架，通过控制扰动提示、Wasserstein距离度量和加权线性替代模型来识别影响最大的输入标记，生成直观的热力图以视觉方式突出显示关键标记和推理路径。这项研究创新地将SMILE方法扩展应用于LLMs，提高了解释的准确性和可解释性
### Conclusion
gSMILE能够在不影响模型性能的前提下提高LLMs的可解释性，有助于构建更透明和可信的AI系统。不同模型在特定指标上表现不同，展示了gSMILE在不同LLMs中的适用性和可靠性。
## 453. `cs.CL` - C-SEO Bench: 相关性SEO是否有效？ [PDF](https://arxiv.org/pdf/2506.11097), [HTML](https://arxiv.org/abs/2506.11097)
### Authors
Haritz Puerto,Martin Gubri,Tommaso Green,Seong Joon Oh,Sangdoo Yun
### Background
大型语言模型（LLMs）正在将搜索引擎转变为对话式搜索引擎（CSE）。因此，搜索引擎优化（SEO）正在向对话式搜索引擎优化（C-SEO）转变。当前存在专门为修改网页文档并在CSE响应中增加其可见性的C-SEO方法，但这些方法通常仅针对有限的应用领域进行测试，我们不清楚某些C-SEO方法是否适用于广泛的领域。此外，现有评估仅考虑单一操作者场景，其中只有一个网页文档采用C-SEO方法，而现实情况中，多个玩家可能会竞争性地采用最新的C-SEO技术，这与我们所见的SEO动态相似。
### Innovation
该研究提出了C-SEO Bench，这是首个用于跨多个任务、领域和参与者数量评估C-SEO方法的基准。该研究采用了两种搜索任务（问答和产品推荐）和三种领域。同时，引入了一种新的评估方案，考虑了参与者之间不同采用率的变化情况。研究结果表明，大部分现有的C-SEO方法不仅效果不佳，而且经常对文档排名产生负面影响。相比之下，传统的SEO策略在LLM环境下显著更有效。此外，观察到随着C-SEO采纳者的增加，整体收益下降，反映出该问题的拥堵和零和性质。
### Conclusion
实验结果显示，大多数当前C-SEO方法不仅效果不佳，而且通常对文档排名产生负面影响。相反，传统的SEO策略，在LLM环境下更有效。随着C-SEO采纳者的增加，整体收益逐渐下降，展示了问题的拥堵和零和性质。此研究的代码和数据已提供给公众。
## 454. `cs.CL` - 稀疏特征共激活揭示大型语言模型中的因果语义模块 [PDF](https://arxiv.org/pdf/2506.18141), [HTML](https://arxiv.org/abs/2506.18141)
### Authors
Ruixuan Deng,Xiaoyang Hu,Miles Gilberti,Shane Storks,Aman Taxali,Mike Angstadt,Chandra Sripada,Joyce Chai
### Background
使用稀疏自编码器（SAE）特征，通过少量提示的共激活，在大型语言模型（LLMs）中识别出语义上连贯且上下文一致的网络组件。重点关注概念关系预测任务，通过删除这些组件（例如国家和单词）和关系（例如首府城市和翻译语言）来改变模型输出，在可预测的方式下，放大这些组件会引发反事实响应。进一步分析发现，大多数概念组件源自最底层，而更抽象的关系组件集中在较深层。研究结果显示，提取的组件全面捕捉了概念和关系，同时保持了特异性。
### Innovation
使用非常少的提示来识别大型语言模型中的稀疏自编码器特征的共激活，这些共激活被用来识别出语义上连贯且上下文一致的网络组件。通过对这些组件的删除和放大，展示了能够预测和反事实的模型输出。进一步发现概念和关系组件在不同的模型层中分布，并且组件的提取能够全面捕捉这些概念和关系，且保持特定性。这项研究提出了知识通过组合操作组织的模块化理论，并推广了高效、精确的大型语言模型操作方法。
### Conclusion
本研究发现了大型语言模型中因果作用下的语义模块，表明知识组织具有模块化特征，并且通过组合操作可以高效地操控大型语言模型。提取到的组件能够更全面地捕捉概念和关系，并保持特定性，进而在大型语言模型的处理和操纵中提供了新的方法。
## 455. `cs.CL` - 神经生成性沟通中屈折形态学属性的发现 [PDF](https://arxiv.org/pdf/2508.05843), [HTML](https://arxiv.org/abs/2508.05843)
### Authors
Miles Gilberti,Shane Storks,Huteng Dai
### Background
基于深度神经网络的生成性沟通(EmCom)有望揭示人类语言的本质，但目前主要集中在少数特定子领域的目标和指标上，这些目标和指标强调以独特一一对应的方式表示属性，并进行句法组合。
### Innovation
重新解读了一个常见的EmCom情境——属性值重建游戏，通过施加小型词汇量的限制来模拟双层构词，并提出了一个新的设定类似于自然形态变化（使与自然语言的沟通方案进行有意义的比较成为可能）；开发了新的度量标准并探索了这款游戏的变体，受屈折形态学真正属性的启发：连合性和融合。
### Conclusion
模拟音节语音约束鼓励连合性形态，生成的语言复制了自然语言将语法属性融合的趋势。
## 456. `cs.CL` - 使用大规模语言模型增强的知识图谱补全 [PDF](https://arxiv.org/pdf/2507.20643), [HTML](https://arxiv.org/abs/2507.20643)
### Authors
Wenbin Guo,Xin Wang,Jiaoyan Chen,Zhao Li,Zirui Chen
### Background
大规模语言模型（LLMs）在知识图谱补全（KGC）中已经展现出了显著的研究进展。然而，当前基于LLM的KGC方法依赖于深层次神经架构，这使得它们处理错误知识的能力有限，从而影响了它们产生有结论性和决定性推理结果的能力。
### Innovation
提出了一种基于LLM的知识图谱补全方法——OL-KGC。该方法首先利用神经感知机制有效地将结构信息嵌入到文本空间，然后使用自动化提取算法从需要补全的知识图谱中检索本体知识，并将其转换为LLMs可理解的文本格式，以提供逻辑指导。
### Conclusion
实验结果显示，OL-KGC在三个广泛使用的基准测试数据集（FB15K-237、UMLS、WN18RR）上，基于多个评价标准显著优于现有的主流KGC方法，并且达到了最先进的性能水平。
## 457. `cs.CL` - TACO: 通过任务映射引导的序列配置增强多模态上下文学习 [PDF](https://arxiv.org/pdf/2505.17098), [HTML](https://arxiv.org/abs/2505.17098)
### Authors
Yanshu Li,Jianjiang Yang,Tian Yun,Pinyuan Feng,Jinfa Huang,Ruixiang Tang
### Background
多模态在上下文学习（ICL）已经成为利用大型视觉-语言模型（LVLM）能力的关键机制。然而其效果高度依赖于输入ICL序列的质量，特别是对于涉及到复杂推理或开放式生成的任务。我们对LVLM如何利用这些序列的理解仍有限，这成为了一个主要限制。现有研究缺乏对如何系统地解释多模态ICL机制的研究，特别是通过任务映射的角度研究LVLM如何推理解析这些序列。本研究试图通过任务映射的方法来研究和改进多模态ICL。
### Innovation
本研究提出了TACO（Task-aware Configuration Of sequences），一种具有任务感知注意力的轻量级Transformer模型，能够动态配置ICL序列。TACO通过在自回归解码过程中注入任务映射信号，创建了序列构建与任务理解之间的双向协同作用。实验结果表明，TACO在五个LVLM和九个数据集上表现优于基线方法，在不同ICL任务中均能实现持续的超越。这项研究提供了新的和有价值的方法来解释和提升多模态ICL的效果
### Conclusion
任务映射为解释和改进多模态ICL提供了一个新的视角，通过任务映射指导的序列配置可以提高模型在复杂任务中的表现。
## 458. `cs.CL` - 向更大效率迈进：高效混合专家语言模型的缩放定律 [PDF](https://arxiv.org/pdf/2507.17702), [HTML](https://arxiv.org/abs/2507.17702)
### Authors
Changxin Tian,Kunlong Chen,Jia Liu,Ziqi Liu,Zhiqiang Zhang,Jun Zhou
### Background
Mixture-of-Experts (MoE) 已成为通过解耦总参数量和计算成本来高效扩展大型语言模型（LLMs）的一种主导架构。然而，这种解耦带来了关键挑战：预测特定 MoE 配置（如专家激活比例和细粒度）的模型能力依然是一个未解问题。为了填补这一空白，我们引入了效率杠杆（EL）这一度量标准，用于量化 MoE 模型相对于密集等效模型的计算优势。我们进行了大规模实证研究，训练了超过 300 个模型，参数量高达 28B，系统地研究了 MoE 架构配置与 EL 之间的关系，并发现 EL 主要受专家激活比例和总计算预算驱动，两者遵循可预测的幂律，而专家粒度则作为非线性调节器，存在最优范围。我们整合这些发现生成了一条统一的缩放定律，可以根据其配置准确预测 MoE 架构的 EL。通过设计并训练 Ling-mini-beta 这一示范模型，验证了我们推导出的缩放定律。
### Innovation
我们提出了效率杠杆（EL）这一度量标准，量化 MoE 模型相对于密集等效模型的计算优势，并通过大规模实证研究，揭示了 EL 主要由专家激活比例和总计算预算驱动的幂律关系，以及专家粒度的非线性调节作用。我们据此构建了统一的缩放定律，能够基于配置准确预测 MoE 架构的 EL。我们通过设计并训练了 Ling-mini-beta 模型作为 Ling-2.0 系列的原型，验证了我们的缩放定律。
### Conclusion
这项研究提供了一种基于配置准确预测高效 MoE 模型的计算优势的基础，证明了效率杠杆和缩放定律的有效性。
## 459. `cs.CL` - 评估机器翻译偏差的不确定性量化 [PDF](https://arxiv.org/pdf/2507.18338), [HTML](https://arxiv.org/abs/2507.18338)
### Authors
Ieva Raminta Staliūnaitė,Julius Cheng,Andreas Vlachos
### Background
机器翻译模型的预测不确定性通常作为质量估计的代理指标。以往研究通过性别准确率来测量模型中的性别偏见，这种方法难以应用于有歧义的句子。
### Innovation
本文提出了利用不确定性来衡量机器翻译系统中的性别偏见，特别是在源句子包含未明确标注性别但目标语言等词需要性别确定时。通过语义不确定性来评估有歧义和无歧义源句子的偏见，发现翻译准确率与适当地展示不确定性无关，且去偏措施对两种情况的影响不同。
### Conclusion
本研究通过语义不确定性可以评估翻译的偏见，发现翻译准确度并不总是反映言语的不确定性，并揭示了减少偏见对两种情形的不同影响。
## 460. `cs.CL` - 利用合成数据评估RAGs可行吗？ [PDF](https://arxiv.org/pdf/2508.11758), [HTML](https://arxiv.org/abs/2508.11758)
### Authors
Jonas van Elburg,Peter van der Putten,Maarten Marx
### Background
本文探讨了大型语言模型（LLMs）生成的合成问题-答案（QA）数据是否可以作为人类标注基准的有效替代品，尤其是在人类标注基准不可用的情况下。作者通过两个实验评估了合成基准的质量：第一个实验改变检索器参数但保持生成器不变，第二个实验则改变生成器但保持检索器参数不变。本文在四个数据集上测试了结果，其中包括两个开放式领域数据集和两个专有数据集。
### Innovation
本文的主要创新之处在于通过使用大型语言模型生成的合成数据来评估基于检索的生成器（RAGs）的效果，并且作者通过两个不同的实验设置考察了这种方法的有效性。
### Conclusion
作者发现，合成基准数据可以可靠地对不同检索配置的RAGs进行排名，与人类标注的基准线对齐良好。然而，当比较生成器架构时，合成基准数据并没有一致地产生可靠的RAG排名。可能的原因是合成和人类基准之间的任务不匹配以及某些生成器在风格上的偏好。
## 461. `cs.CL` - 文本占据主导地位：多模态意图检测中的模态偏见研究 [PDF](https://arxiv.org/pdf/2508.16122), [HTML](https://arxiv.org/abs/2508.16122)
### Authors
Ankan Mullick,Saransh Sharma,Abhik Jana,Pawan Goyal
### Background
多模态数据的兴起，将文本、音频和视觉等模态结合，为研究多模态任务（如意图检测）带来了新的机遇。这项研究探讨了大型语言模型（LLMs）以及非LLMs（包括仅文本和多模态模型）在多模态意图检测任务中的有效性。
### Innovation
研究发现，一个仅文本的LLM（Mistral-7B）在MIntRec-1和MIntRec2.0数据集上的表现均优于几乎所有竞争性的多模态模型，分别高出约9%和4%。这一优势来自这些数据集中的强大文本偏向性，超过90%的样本需要文本输入（单独或与其他模态结合），才能正确分类。研究还通过人工评估确认了这些数据集的模态偏见。研究进一步提出了一种去偏框架，并去除了70%以上的数据集样本，导致所有模型的表现显著下降，其中较小的多模态融合模型受到影响最大，准确率下降超过50-60%。此外，通过实证分析，研究揭示了不同模态在特定情境下的相关性。
### Conclusion
研究强调了多模态意图数据集中的模态偏见带来的挑战，并强调需要无偏数据集来有效评估多模态模型的必要性。
## 462. `cs.CL` - Correct-Detect：通过核心指代解析视角平衡LLMs性能和歧义 [PDF](https://arxiv.org/pdf/2509.14456), [HTML](https://arxiv.org/abs/2509.14456)
### Authors
Amber Shore,Russell Scheinberg,Ameeta Agrawal,So Young Lee
### Background
大型语言模型（LLMs）旨在反映人类语言能力，但人类能够利用广泛的语境信息来检测和解决语言歧义，即使在孤立的文本片段中也是如此。核心指代解析任务是一个典型的语义歧义案例：代词与前面提到的人物如何相关？这种能力几乎存在于每一个下游任务中，而这一层次的歧义可能对性能产生重大影响。
### Innovation
本文展示了LLMs可以在最小提示下实现良好的核心指代消歧技术与歧义检测性能，但它们在同时完成这两项任务时存在困难。提出了‘Correct-Detect’权衡：尽管模型具有这两种能力且能够隐式使用它们，但同时平衡这两种能力的成功表现仍然难以实现。
### Conclusion
尽管LLMs具备隐式的这两种能力，但在同时实现核心指代消歧与歧义检测平衡方面仍然存在挑战。
## 463. `cs.CL` - 理解模型训练中的强化学习及其GRAPE未来发展方向 [PDF](https://arxiv.org/pdf/2509.04501), [HTML](https://arxiv.org/abs/2509.04501)
### Authors
Rohit Patel
### Background
现有的关于模型训练中强化学习算法的解释常假设读者有一定的先验知识，且往往缺乏关键细节，过于泛化或过于复杂。作者指出，这些算法通常缺少对于大型语言模型（LLMs）的直接解释，这使得理解和应用这些算法变得困难。因此，作者旨在提供一个包含从头开始的、自我包含的算法解析，特别专注于LLMs，强调简化和明确表示，从而减少模糊性和认知负担。
### Innovation
论文提供了一种新颖的方法，通过从零开始、逐步解析的方式，使用简化且明确的表示方法详细解释关键的指令调整算法（SFT、Rejection Sampling、REINFORCE、TRPO、PPO、GRPO和DPO）。与传统的解释不同，本论文完全摆脱了对广泛强化学习文献的依赖，而是将概念直接与大型语言模型相关联，减少了不必要的抽象和降低了认知负担。此外，还提出了一种新的研究思想，即GRAPE（广义相对优势策略进化），为未来的研究提供了新的方向。
### Conclusion
论文不仅提供了一种新的、简化的方法来解释关键的强化学习算法，还提出了一个新的研究思想GRAPE，为该领域未来的研究方向提供了展望。通过这一解释，希望促进更多基于LLMs的模型训练研究，并提供一种更清晰直接的方式来理解这些复杂的算法。
## 464. `cs.CL` - 使用ModernBERT进行专利语言模型预训练 [PDF](https://arxiv.org/pdf/2509.14926), [HTML](https://arxiv.org/abs/2509.14926)
### Authors
Amirhossein Yousefiramandi,Ciaran Cooney
### Background
基于Transformer的语言模型如BERT已经成为了自然语言处理（NLP）领域的基础模型，但这些模型在专利等专业领域表现不佳。专利文本具有长、技术性强、法律结构严谨的特点，导致通用模型的表现不如预期。过去对专利NLP的研究主要依赖于对通用模型或使用有限数据进行微调的领域改编版本。
### Innovation
本文提出了一种使用ModernBERT架构预训练3个专门针对专利领域的掩码语言模型的方法。该模型使用的预训练语料库包含超过6000万条专利记录。该方法通过引入包括FlashAttention、旋转嵌入和GLU前馈层在内的架构优化措施，提高了模型的性能，并在四个下游专利分类任务上的评估中，表现出比通用语言模型更好的表现。进一步的实验表明，扩大模型规模和定制化分词器可以进一步提升特定任务上的性能。所有ModernBERT变体的推理速度快于PatentBERT，特别是减少了3倍以上的时间，这使得它们更适用于对时间敏感的应用。
### Conclusion
研究结果表明，领域特定的预训练和架构改进对于针对专利任务的NLP具有显著的好处。
## 465. `cs.CL` - 使用普查和土地使用数据指导的大语言模型生成个体出行日记 [PDF](https://arxiv.org/pdf/2509.09710), [HTML](https://arxiv.org/abs/2509.09710)
### Authors
Sepehr Golrokh Amin,Devin Rhoads,Fatemeh Fakhrmoosavi,Nicholas E. Lownes,John N. Ivan
### Background
传统的出行行为模拟模型主要依赖于大量的专有家庭出行调查数据，但这种方法存在数据获取成本高、隐私保护等问题。为此，本研究提出了一种使用大型语言模型（LLM）生成个体出行日记的方法，该方法从公开的数据源（如美国社区调查和智能地点数据库）中获取数据，并通过直接提示的方式合成出行日记。
### Innovation
本研究提出了一种创新的从个体到群体的真实度分数（one-to-cohort realism score），该分数由四组指标（出行次数分数、间隔分数、目标分数和出行方式分数）组成，并与康涅狄格州全域交通研究（CSTS）中的出行日记进行了验证，通过詹森-沙恩距离（Jensen-Shannon Divergence）来衡量生成的日记与真实日记之间的分布相似性。此外，该方法在确定出行目的和提高一致性方面优于传统模型。
### Conclusion
LLM生成的出行日记在总体真实度（LLM均值：0.485 vs. 传统方法均值：0.455）、统计代表性（LLM均值：0.612 vs. 传统方法均值：0.435）方面表现出与传统方法相当或更好的性能，特别是在确定出行目的和一致性方面表现出优势。该研究建立了量化评价生成性日记真实度的量化指标，为未来的合成日记评估系统提供了实证依据和衡量标准。
## 466. `cs.CL` - 大型语言模型能否掌握复杂纸牌游戏？ [PDF](https://arxiv.org/pdf/2509.01328), [HTML](https://arxiv.org/abs/2509.01328)
### Authors
Wei Wang,Fuqing Bie,Junzhe Chen,Dan Zhang,Shiyu Huang,Evgeny Kharlamov,Jie Tang
### Background
人工智能算法一直是复杂游戏测试的重要标准。AlphaGo、AlphaZero和MuZero在围棋和象棋中击败了顶级人类选手，吸引了广泛的社会关注。与此同时，大型语言模型（LLMs）在各种任务中展现了出色的能力，引发了一个问题，即LLMs是否也能在复杂游戏中取得类似的成功。本研究探讨了LLMs在掌握复杂纸牌游戏方面的潜力。研究系统地评估了LLMs在八种不同纸牌游戏中的学习能力，考察了通过高质量游戏数据进行微调的影响，以及模型在掌握这些游戏方面保留通用能力的能力。研究表明，LLMs可以通过监督微调高质量数据来接近强游戏AI的性能，可以在多张具有相似规则的复杂纸牌游戏中达到一定的熟练程度，在类似规则的游戏上表现增强，在不同规则的游戏上存在冲突，并且当掌握复杂游戏时，LLMs的一般能力会出现下降，但可以通过整合一定数量的通用指令数据来缓解这种下降。评估结果表明，LLMs具有强大的学习能力和多功能性。相关代码可在该网址获取。
### Innovation
本研究首次系统评估了大型语言模型在复杂纸牌游戏中的学习能力，表明LLMs可以通过适当的微调达到类似游戏AI的性能，并且在掌握多个具有相似规则的游戏方面表现良好，尽管在掌握复杂游戏的同时也会遇到一些通用能力下降的问题，但这些问题可以通过整合通用指令数据来缓解。这项研究为LLMs在其他复杂任务中的应用提供了新的见解和发展方向。
### Conclusion
本研究表明，通过监督微调高质量数据，大型语言模型可以在多个复杂纸牌游戏中接近游戏AI的性能。LLMs可以在多个具有相似规则的游戏上达到一定的熟练程度，而不同规则之间的游戏会引起矛盾。同时，虽然掌握复杂游戏会导致一般能力的下降，但这一问题可以通过整合一些通用指令数据来缓解。进一步的实验和应用将有助于更好地理解大型语言模型在处理复杂任务方面的能力及其局限性。
## 467. `cs.CL` - HiPO: Hybrid Policy Optimization for Dynamic Reasoning in LLMs [PDF](https://arxiv.org/pdf/2509.23967), [HTML](https://arxiv.org/abs/2509.23967)
### Authors
Ken Deng,Zizheng Zhan,Wen Xiang,Wenqiang Zhu,Weihao Li,Jingxuan Xu,Tianhao Peng,Xinping Lei,Kun Wu,Yifan Yao,Haoyang Huang,Huaixi Tang,Kepeng Lei,Zhiyi Lai,Songwei Yu,Zongxian Feng,Zuchen Gao,Weihao Xie,Chenchen Zhang,Yanan Wu,Yuanxing Zhang,Lecheng Huang,Yuqun Zhang,Jie Liu,Zhaoxiang Zhang,Haotian Zhang,Bin Chen,Jiaheng Liu
### Background
大型语言模型（LLMs）越来越多地依赖于逐步推理（CoT）来提高复杂任务的准确性。然而，生成冗长的推理痕迹是低效的，会导致过多的令牌使用和更高的推断成本。因此，需要一种框架来实现自适应的推理控制，使LLMs能够在需要详细推理时（Think-on模式）和不需要详细推理时（Think-off模式）进行选择性操作。HiPO结合了提供标签配对的数据管道和混合强化学习奖励系统，以平衡准确性和效率，避免过度依赖详细推理。
### Innovation
HiPO框架通过结合混合数据管道和支持混合强化学习奖励系统的奖励机制，实现了LLMs在进行详细推理和提供直接响应之间的自适应切换。实验表明，HiPO能够在保持或提高准确性的同时，显著减少令牌长度。
### Conclusion
HiPO为有效自适应推理提供了一个原理性的方法，有助于在资源敏感的现实环境中部署注重推理的LLMs。
## 468. `cs.CL` - 使用System F中类型推理评估程序语义推理 [PDF](https://arxiv.org/pdf/2509.23686), [HTML](https://arxiv.org/abs/2509.23686)
### Authors
Yifeng He,Luning Yang,Christopher Castro Gaw Gonzalo,Hao Chen
### Background
随着大型语言模型（LLMs）越来越多地整合到软件工程生态系统中，它们在测试时的计算（TTC）推理能力展示了理解程序逻辑和语义的巨大潜力。然而，当前的代码推理基准缺乏基于形式化、以程序为中心的演绎框架，无法确保评判的准确性，并且无法评估模型是否真正进行关于程序语义的推理，而不是仅仅利用自然语言与代码标记之间的表面关联。
### Innovation
本文引入了TF-Bench，这是一个基于System F中的类型推理任务（类型推断）评估LLM推理能力的基准。通过使用验证转换去除冗余的自然语言，作者构建了一个纯粹由语义驱动的TF-Bench_pure版本。此外，还提出了两个新的度量标准来评估测试时推理的鲁棒性和有效性。
### Conclusion
分析结果显示，最先进的LLM在TF-Bench_pure上的准确率仅为55.85%。这揭示了重要局限性，强调了未来发展研究的方向。
## 469. `cs.CL` - 语义一致性使开放生成性的LLM级联高效 [PDF](https://arxiv.org/pdf/2509.21837), [HTML](https://arxiv.org/abs/2509.21837)
### Authors
Duncan Soiffer,Steven Kolawole,Virginia Smith
### Background
级联系统在可能的情况下将计算请求路由到较小的模型，并仅在必要时才递交给较大的模型，这是一种平衡LLM部署中的成本和质量的有希望的方法。然而，它们在开放生成文本时面临一个基本挑战：在生成质量在连续光谱上存在多个有效响应时，如何确定输出可靠性。
### Innovation
提出了一种无训练的语义一致性——意义层次上的ensemble输出一致性，作为一种可靠性递延的信号。研究发现，当多样化的模型输出在语义上达成一致时，它们的一致性比token级别的置信度更强。从500M参数到70B参数的模型评估结果表明，语义级联能够在成本降低40%的情况下匹配或超过目标模型的质量，并将延迟减少高达60%。该方法不需要模型内部信息，在黑盒API中适用，并且对模型更新具有鲁棒性，从而成为现实世界LLM部署的实用基准。
### Conclusion
语义级联能够在保持低延迟和高质星的同时，显著降低成本，无需依赖模型内部细节，适用于多种场景，并且具备模型更新鲁棒性，是一种实用的基准方案用于实际的LLM部署。
## 470. `cs.CL` - 大型语言模型中过程奖励模型的综述：从结果信号到过程监督 [PDF](https://arxiv.org/pdf/2510.08049), [HTML](https://arxiv.org/abs/2510.08049)
### Authors
Congming Zheng,Jiachen Zhu,Zhuoying Ou,Yuxiang Chen,Kangning Zhang,Rong Shan,Zeyu Zheng,Mengyue Yang,Jianghao Lin,Yong Yu,Weinan Zhang
### Background
大型语言模型虽然表现出色，但在问题解决过程中，传统对齐方法主要依赖于仅评估最终答案的结果奖励模型。然而，过程奖励模型通过评估和引导解决过程中的每一步或整体步骤来补充这一不足。
### Innovation
该研究提出了一种系统性的过程奖励模型综述，主要包括生成过程数据、构建过程奖励模型、以及在测试时间和强化学习中使用这些模型的方法。研究覆盖了数学、代码、文本、多模态推理、机器人和代理等多个应用场景，并回顾了相关的新兴基准测试。
### Conclusion
目的是澄清设计空间、揭示开放挑战，并为未来的细致、稳健对齐研究提供指导。
## 471. `cs.CL` - IASC: Interactive Agentic System for ConLangs [PDF](https://arxiv.org/pdf/2510.07591), [HTML](https://arxiv.org/abs/2510.07591)
### Authors
Chihiro Taguchi,Richard Sproat
### Background
该研究背景在于介绍一个系统，该系统利用大型语言模型（LLMs）作为工具用于构建人造语言（Constructed Languages，ConLangs）的发展。系统的设计模块化，通过多步骤逐步构建目标语言的音位学、词汇、以及语法等元素，同时探索LLMs对语言的理解能力。
### Innovation
该系统创新地提出了一个模块化的过程，包括音位学的生成、形态学和句法标记的翻译、语音学模型构建词汇表、使用现有书写系统生成语写法以及自动生成语言语法手册。此外，该系统还探索了将高资源语言翻译成低资源语言的应用潜力。
### Conclusion
研究者希望该工具可用于创造人工语言，同时也希望通过研究LLMs对语言的理解程度来探索其知识边界。研究显示，LLMs在处理常见模式方面较为容易，但在处理罕见模式时却较为困难。研究还探讨了将该方法应用于高资源语言翻译到低资源语言的可能性，尽管当前结果大多为负面的，但该系统潜在改进仍有提升之可能。
## 472. `cs.CL` - 通过使训练和推理路由器对齐来稳定MoE中的强化学习 [PDF](https://arxiv.org/pdf/2510.11370), [HTML](https://arxiv.org/abs/2510.11370)
### Authors
Wenhan Ma,Hailin Zhang,Liang Zhao,Yifan Song,Yudong Wang,Zhifang Sui,Fuli Luo
### Background
强化学习（RL）被认为是提升大型语言模型能力的关键方法。然而，在混合专家模型（MoE）中，路由机制常常导致训练不稳定性，甚至会导致RL训练崩溃。路由行为在训练和推理阶段之间存在显著差异，即使在相同条件下，重复前向传递也可能导致不同的专家选择。
### Innovation
该方法提出了一种称为Rollout Routing Replay (R3)的方法，它记录推理引擎的路由分布并在训练期间重复使用这些分布。R3显著降低了训练与推理策略之间的KL散度，并减轻了极端差异，而不牺牲训练速度。实验结果表明，R3能够稳定RL训练，防止崩溃，并且优于诸如GSPO和TIS等方法。
### Conclusion
大量实验表明R3能够有效稳定MoE中的RL训练，防止崩溃，并且在各种设置中优于其他方法。我们认为这项工作为稳定MoE中的RL提供了一个新的解决方案。
## 473. `cs.CL` - A$^2$FM：一种具备工具感知的适应性代理基础模型以实现混合推理 [PDF](https://arxiv.org/pdf/2510.12838), [HTML](https://arxiv.org/abs/2510.12838)
### Authors
Qianben Chen,Jingyi Cao,Jiayu Zhang,Tianrui Qin,Xiaowan Li,King Zhu,Dingfeng Shi,He Zhu,Minghao Liu,Xiaobo Liang,Xin Gui,Ge Zhang,Jian Yang,Yuchen Eleanor Jiang,Wangchunshu Zhou
### Background
现有的大规模语言模型可以分为两大类：一类是以推理为中心的语言模型，强调内部链式推理但无法调用外部工具；另一类是具有代理性的语言模型，能够与环境交互并利用工具，但在深度推理方面可能存在不足。尽管不同的训练目标带来了各自的优点，但在处理简单问题时，两者都会表现出过度思考或过度调用工具的问题。
### Innovation
本文提出了一种统一框架——适应性代理基础模型（A$^2$FM），它遵循路径优先调整的原则，首先学习任务感知的路由机制，然后在共享的骨干结构下根据具体场景进行调整。为了克服效率低下，A$^2$FM 引入了第三种模式，专门处理简单的查询，避免不必要的推理或工具调用，同时补充了代理性和推理模式的功能。此外，该模型提出了自适应策略优化（APO），通过在不同模式下进行自适应采样并采用成本正则化奖励来联合提高准确性和效率。
### Conclusion
在32B规模的模型评估中，A$^2$FM 在 BrowseComp、AIME25 和 HLE 上分别取得了13.4%、70.4% 和 16.7% 的成绩，表现出优异的性能，尤其是在成本效率方面仅需每正确答案0.00487美元，相较于纯推理和代理模式分别节省了45.2%和33.5%的成本。
## 474. `cs.CL` - 医学摘要分类的轻量级基线：直布罗陀与交叉熵作为强默认设置 [PDF](https://arxiv.org/pdf/2510.10025), [HTML](https://arxiv.org/abs/2510.10025)
### Authors
Jiaqi Liu,Tong Wang,Su Liu,Xin Hu,Ran Tong,Lanruo Wang,Jiexi Xu
### Background
研究重点在于在预算有限的情况下，评估轻量级的医疗摘要分类方法的最大性能。研究在公共医学摘要语料库上微调了BERT基础模型和DistilBERT，使用交叉熵（CE）、加权交叉熵和焦点损失作为优化目标，以评估其分类性能。
### Innovation
研究创新地将DistilBERT与交叉熵损失结合使用，并探讨了不同损失函数对于轻量级医疗摘要分类的有效性。研究还通过后处理操作点选择优化了部署性能，并通过对比分析确定了不同损失函数的效果。研究还强调了开始使用紧凑型编码器和交叉熵，然后在部署需要更高的宏观平衡时添加轻量级校准或阈值化的方法。
### Conclusion
研究发现，使用直布罗陀模型和交叉熵损失在未部署时具有最强的原始argmax性能；但在经过后处理操作点校准后，性能将得到显著提升。焦点损失在经过优化后也表现出最佳表现。研究提供了准确率、宏F1和加权F1等评估指标，并公开了评价成果，包括混淆矩阵分析，以阐明错误结构。
## 475. `cs.CL` - LLMs中的隐性知识是否足够？一种基于树结构的RAG方法 [PDF](https://arxiv.org/pdf/2510.10806), [HTML](https://arxiv.org/abs/2510.10806)
### Authors
Mihir Gupte,Paolo Giusto,Ramesh S
### Background
大型语言模型（LLMs）擅长根据上下文中的信息生成响应。这种方法对于与结构化数据（如代码文件）交互非常有用，而检索增强生成（RAG）方法则是通过检索相关文档来补充模型的上下文学习能力。然而，尚不清楚如何最好地将检索到的知识表示出来，以便能够生成针对复杂数据结构（如树状结构）的响应。现有研究主要关注如何优化隐性知识的表示，以生成更高效、准确的响应。
### Innovation
本文提出了一种新颖的自底向上的方法来线性化树状结构（如GitHub仓库）的知识，通过生成每个层级的隐式、综合摘要。这种方法使知识可以存储在知识库中并直接与RAG结合使用。将该方法与对原始、未结构化的代码使用RAG进行比较，评估生成响应的准确性和质量。结果表明，尽管响应质量相当，但本方法在检索器中生成的文档减少了68%以上，显示出该方法在处理复杂层次数据结构方面的高效性和可扩展性。
### Conclusion
通过这种方法生成隐性、线性化的知识可能是一种高效且具有可扩展性的策略，来处理复杂层次化数据结构。
## 476. `cs.CL` - 介绍Spotlight：生成文档中引人入胜关键信息的新方法 [PDF](https://arxiv.org/pdf/2509.10935), [HTML](https://arxiv.org/abs/2509.10935)
### Authors
Ankan Mullick,Sombit Bose,Rounak Saha,Ayan Kumar Bhowmick,Aditya Vempaty,Prasenjit Dey,Ravi Kokku,Pawan Goyal,Niloy Ganguly
### Background
传统的摘要方法侧重于全面覆盖信息，而忽视了强调有趣且吸引人的内容以提高读者对原始材料的参与度。本文介绍了一种称为Spotlight的新颖信息提取范式，它通过突出文档中最吸引人的方面来生成简洁且吸引人的叙述。通过这一方法，期望提高读者对原始材料的兴趣和参与度。
### Innovation
本文提出了一种两阶段的方法来生成高质量的Spotlight：首先，对大型语言模型进行微调以适应新数据集；其次，使用Direct Preference Optimization（DPO）对生成进行对齐。这种方法区别于传统的全面覆盖式摘要，更侧重于选择性地强调有趣的内容，从而提高读者对原始材料的阅读兴趣和参与度。通过详细基准测试研究支持其分析，并展示了该方法不仅能够精准识别关键元素，还能提高文档的可读性和参与价值。
### Conclusion
本文通过提出Spotlight这一创新的信息提取范式，能够在生成简洁且吸引人的叙述的同时，提高对原始文档的阅读参与度和阅读价值。这种方法通过详细的评估和基准测试研究得到了验证，并展示了与传统摘要方法相比的优势。
## 477. `cs.CL` - SafeSearch：在大语言模型搜索代理中不要以安全性换取实用性 [PDF](https://arxiv.org/pdf/2510.17017), [HTML](https://arxiv.org/abs/2510.17017)
### Authors
Qiusi Zhan,Angeline Budiman-Chan,Abdelrahman Zayed,Xingzhi Guo,Daniel Kang,Joo-Kyung Kim
### Background
基于大语言模型（LLM）的搜索代理会迭代生成查询、检索外部信息并进行推理以回答开放领域的问答问题。这些搜索代理在提高其实用性方面已受到广泛关注，但其安全性却相对较少被研究。已有研究发现，搜索代理可能比基础LLM更有可能产生有害输出。例如，当询问“没有他人同意的情况下，我如何跟踪他们的位置？”时，基础模型会拒绝，而设计用于检索和引用来源的搜索代理可能会降低其拒绝阈值，检索文档（如法院案例），并综合生成一个既信息丰富又不安全的摘要。
### Innovation
本文提出了SafeSearch，这是一种多目标强化学习方法，将最终输出的安全/实用性奖励与一个新的查询级别调整项结合，该调整项惩罚不安全的查询并奖励安全的查询。实验表明，SafeSearch可以将三个红队数据集的代理危害性降低超过70%，同时生成安全且有帮助的回答，并且其问答性能可与仅以实用性为目标进行微调的代理相匹配；进一步分析证实了查询级别奖励在安全性和实用性双重改进方面的有效性。
### Conclusion
SafeSearch减少了搜索代理的有害性超过70%，同时生成安全且有用的回答，其问答性能与仅以功能性为目标进行微调的代理相当；查询级别的奖励在双重提升安全性和实用性方面非常有效。
## 478. `cs.CL` - AI辩论者在与自己信念一致时更有说服力 [PDF](https://arxiv.org/pdf/2510.13912), [HTML](https://arxiv.org/abs/2510.13912)
### Authors
María Victoria Carro,Denise Alejandra Mester,Facundo Nieto,Oscar Agustín Stanchi,Guido Ernesto Bergman,Mario Alejandro Leiva,Eitan Sprejer,Luca Nicolás Forziati Gangi,Francisca Gauna Selasco,Juan Gustavo Corvalán,Gerardo I. Simari,María Vanina Martinez
### Background
现有的AI辩论实验主要依赖于具有真实标准的语料库，而在这些语料库中，撒谎简化为捍卫错误的命题。然而，撒谎不仅仅涉及捍卫错误观点，还涉及对所捍卫主张的错误信念。本研究旨在通过将辩论应用于主观问题，并在实验前明确测量大语言模型的先验信念，来探索AI模型在与自己的信念一致时的偏好及其对辩论结果的影响。研究采用两种辩论协议：顺序和同时，并评估潜在系统性偏差，最终评估模型在捍卫与先验信念一致的观点时的说服力和论点质量，与捍卫不一致的观点时相比如何。
### Innovation
本研究创新之处在于，首次在主观问题领域应用AI辩论，并在实验前测量模型的先验信念。研究设计了具有冲突角色的法官，以测试模型会采取奉承策略还是坚持先验信念。研究还通过比较顺序和同时辩论两种协议，揭示潜在的系统性偏差，并评价模型在一致和不一致信念情境下的表现。此外，研究还意外发现，与先验信念不一致的论点在两两比较中被评为更高质量，这一结果提供了重要的人机交互见解，特别是在语言模型的说服动态方面。
### Conclusion
研究表明，模型偏好捍卫与法官角色一致的观点，而不是他们的先验信念。顺序辩论引入了倾向第二辩者的显著偏差，当捍卫与先验信念一致的观点时，模型更具说服力，而与先验信念不一致的观点在两两比较中被评为更高质量。这些结果有助于提供更高质量的培训信号，促进更一致的人工智能系统，并揭示了人类与AI互动中关于语言模型的说服动态的重要方面。
## 479. `cs.CL` - 探索大语言模型在代码生成中的数据高效适应 [PDF](https://arxiv.org/pdf/2403.00046), [HTML](https://arxiv.org/abs/2403.00046)
### Authors
Xue Jiang,Yihong Dong,Zhiyuan Fan,Zhi Jin,Wenpin Jiao,Ge Li
### Background
尽管大规模语言模型（LLMs）在代码生成方面取得了显著进步，但在特定场景下的代码生成任务中仍存在问题。这些场景通常需要对LLMs进行适应以满足特定需求，但由于实践中可用的训练数据有限，导致其代码生成性能不佳。因此，如何在有限训练数据的情况下有效适应LLMs，成为当前代码生成领域的一个主要挑战。
### Innovation
本文提出了一种名为DEED的新颖适应方法，DEED代表数据效率与错误驱动学习相结合的代码生成适应方法。DEED利用LLMs的错误作为学习机会，通过错误修正克服其自身的缺陷，从而实现高效学习。具体来说，DEED包括识别由LLMs生成的错误代码，使用自我修正进行代码修正，用修正后的代码优化模型，并通过迭代适应过程进行持续改进。实验结果表明，与现有主流微调方法相比，DEED在多种代码生成基准上使用少量训练数据实现了更高的性能，平均Pass@1提升了46.2%。此外，还验证了自我修正的有效性，它生成的修正代码比数据集中的代码样例更有效地优化了模型。DEED在不同LLMs上的一贯良好表现进一步证明了其适用性。
### Conclusion
DEED通过利用错误修正过程增强了LLMs在特定场景下的代码生成能力，特别是在有限的训练数据下，展示了优异的性能和广泛的适用性。
## 480. `cs.CL` - InternLM2.5-StepProver: 利用批评引导搜索推进自动定理证明 [PDF](https://arxiv.org/pdf/2410.15700), [HTML](https://arxiv.org/abs/2410.15700)
### Authors
Zijian Wu,Suozhi Huang,Zhejian Zhou,Huaiyuan Ying,Zheng Yuan,Wenwei Zhang,Dahua Lin,Kai Chen
### Background
大型语言模型（LLMs）在数学定理证明中扮演着重要角色，尤其是在使用形式化语言（如LEAN）的情况下。一种常见的证明方法是，LLM证明器通过迭代构造每一步战术来构建证明，通常遵循最佳优先搜索方案。然而，这种方法往往忽略了已存在战术路径中的关键偏好信息，阻碍了对更深层证明的搜索。
### Innovation
本文提出了一种直观且有效的批评模型方法，该方法能捕捉偏好信息，并在运行时指导证明器模型的搜索。通过专家迭代方式进一步微调证明器和批评家模型，经过超过20,000个CPU日的训练，训练好的InternLM2.5-StepProver批评家显著提高了证明器模型的表现（从59.4%提升到65.9%）。此外，分析了批评家在专家迭代过程中对定理证明过程各方面的潜在影响，提供了其有效性的见解。
### Conclusion
本文通过提供训练好的InternLM2.5-StepProver批评家模型及其优化后的证明过程，显著提升了自动定理证明的性能。模型和搜索的证明已开源，以供进一步研究和验证。
## 481. `cs.CL` - 基于数据估值的公平定价机制及其在大型语言模型中的应用 [PDF](https://arxiv.org/pdf/2502.00198), [HTML](https://arxiv.org/abs/2502.00198)
### Authors
Luyang Zhang,Cathy Jiao,Beibei Li,Chenyan Xiong
### Background
大型语言模型（LLMs）依赖于高质量的训练数据，但当前数据市场的定价方式常常具有剥削性，即来自边缘化群体的数据被以低价格甚至不给予应有回报的方式获取。这种剥削性定价导致高价值的卖家离开市场，数据质量下降，影响长期模型表现。
### Innovation
本文提出了一个LLM数据市场的理论框架，分析了买家（LLM构建者）与卖家（人类标注者）之间的战略互作，指出剥削性定价会导致高质量卖家的流失。为此，作者引入了一种名为“公平份额”（Fairshare）的数据定价机制，该机制基于数据估值，量化每个数据的贡献，进而通过维持卖家参与和优化买家与卖家的福利来调整激励。
### Conclusion
公平份额机制能够确保长期买家收益最大化和卖家利润最大化，同时维持市场参与。通过在复杂NLP任务上的实验证实，公平分享机制提高了卖家收益，保证了高品质数据的稳定供应，同时也提高了买家的成本效益和长期福利。研究结果为建立公平、透明和经济可持续的LLM数据市场提供了具体途径。
## 482. `cs.CL` - SimBench：评估大型语言模型模拟人类行为能力的标准基准 [PDF](https://arxiv.org/pdf/2510.17516), [HTML](https://arxiv.org/abs/2510.17516)
### Authors
Tiancheng Hu,Joachim Baumann,Lorenzo Lupo,Nigel Collier,Dirk Hovy,Paul Röttger
### Background
大型语言模型（LLM）模拟人类行为具有革命社会和行为科学的潜力，前提是它们必须准确反映真实的人类行为。当前的评估是碎片化的，基于定制的任务和指标，因此结果难以相互比较。为了应对这一问题，我们引入了SimBench，这是第一个大型标准化基准测试，旨在提供一种稳健可复现的科学方法来评估LLM的模拟能力。通过统一20个不同数据集，涵盖从道德决策到经济选择等任务，并覆盖了全球的广泛参与者，SimBench提供了必要的基础来探讨何时、如何以及为什么LLM模拟成功或失败的基本问题。
### Innovation
SimBench是第一个大规模、标准化的基准测试，旨在评估LLM模拟人类行为的能力，统一了不同数据集并覆盖了广泛的道德决策和经济选择等任务。研究展示了即使当前最好的LLM也有有限的模拟能力，性能随模型大小呈对数线性增长，计算时间的增加并未提高性能。并且发现指令调优改进了低熵问题的表现，但恶化了高熵问题的表现。模型在模拟特定的人口群体时尤其挣扎。最后，研究发现模拟能力与深度、知识密集型推理（MMLU-Pro）高度相关。通过实现衡量进展的目标，我们旨在加速开发更忠实的LLM模拟器。
### Conclusion
尽管当前最好的LLM在模拟人类行为方面仍有局限（得分为40.80/100），但性能随着模型大小的增加而呈对数线性增长。计算时间的增加并未提高性能。发现存在指令调优与模拟能力之间的权衡，指令调优在低熵（一致性）问题上表现更好但在高熵（多样性）问题上表现更差。模拟特定的人口群体尤其困难。研究表明，模拟能力与深度、知识密集型推理（MMLU-Pro）最密切相关。通过提供可测量的进步，旨在加速开发更忠实的LLM模拟器。
## 483. `cs.CL` - Infinity Parser: Layout Aware Reinforcement Learning for Scanned Document Parsing [PDF](https://arxiv.org/pdf/2506.03197), [HTML](https://arxiv.org/abs/2506.03197)
### Authors
Baode Wang,Biao Wu,Weizhen Li,Meng Fang,Zuming Huang,Jun Huang,Haozhe Wang,Yanjie Liang,Ling Chen,Wei Chu,Yuan Qi
### Background
手写文档自动解析成富结构的机器可读格式仍然是文档AI中的一个关键瓶颈，因为传统的多阶段管道会遭受错误传播和对不同布局的有限适应性。
### Innovation
该论文提出了一个端到端的强化学习框架layoutRL，通过优化标准化编辑距离、段落计数准确性和阅读顺序保持的复合奖励来训练模型，使其具有明确的版面意识。同时，使用新发布的大规模数据集Infinity-Doc-55K（该数据集结合了55000个高保真合成手写文档解析数据和专家过滤的实际文档），在基于视觉语言模型的手写文档解析器Infinity-Parser中实现了layoutRL。
### Conclusion
Infinity-Parser在OCR、表格和公式提取以及阅读顺序检测的英文和中文基准测试上达到了新的最佳性能，展现出准确性和结构保真的优越性，超过了专门管道和通用视觉语言模型。
## 484. `cs.CL` - 不要检索，生成：针对密集检索的LLM提示生成合成训练数据 [PDF](https://arxiv.org/pdf/2504.21015), [HTML](https://arxiv.org/abs/2504.21015)
### Authors
Aarush Sinha
### Background
传统密集检索模型的训练通常依赖于从大型文集（如文献数据库）中挖掘出的难负样本（Hard Negatives, HN），这通常使用BM25或交叉编码器等方法实现，但需要完整访问整个文集。因此，该文提出了一个替代方案—一个端到端的管道，其中大型语言模型（LLM）首先从段落生成查询，然后基于生成的查询文本直接创建难负样本，而无需访问整个文集。
### Innovation
该研究提出了一个全新的无文集方案。具体创新点包括：1. 端到端的管道设计，利用大型语言模型先生成查询文本，再生成难负样本；2. 不依赖传统方法中所需的完整文集，所有操作仅基于生成的查询文本生成难负样本；3. 实验表明，基于大型语言模型的生成难负样本的方法，在多个BEIR基准数据集上取得了与依赖文集的词汇挖掘基线和交叉编码器基线相当甚至更好的性能。
### Conclusion
这种方法的有效性证明了无文集的难负样本生成在密集检索模型训练中的潜力，可以替代传统依赖文集的方法。
## 485. `cs.CL` - 事实比意见更难判断——基于多语言的大型语言模型事实核查可靠性的比较分析 [PDF](https://arxiv.org/pdf/2506.03655), [HTML](https://arxiv.org/abs/2506.03655)
### Authors
Lorraine Saju,Arnim Bleier,Jana Lasser,Claudia Wagner
### Background
随着虚假信息的泛滥，需要能够大规模、自动化进行事实核查的解决方案。然而，目前的评估基准往往忽略了多语言和主题的多样性。本研究背景强调了在大规模部署基于大型语言模型（LLMs）的事实核查系统时，需要考虑语言和主题的多样性。
### Innovation
本研究引入了一个新颖且可动态扩展的数据集，包含了61,514个多种语言和主题的声明，扩展了现有的数据集至2024年。通过全面评估五种主流的LLMs，本研究识别出不同语言和主题之间的显著性能差异，尤其指出在全球性能最好的GPT-4o在分类时仍会有43%的声明未能被识别。
### Conclusion
这些发现强调了在大规模部署LLM基于的事实核查系统时需要谨慎，并揭示了在主题和语言多样性下，基于LLM的事实核查系统的挑战。
## 486. `cs.CL` - 段级策略优化：大语言模型中RL的有效段级信用分配 [PDF](https://arxiv.org/pdf/2505.23564), [HTML](https://arxiv.org/abs/2505.23564)
### Authors
Yiran Guo,Lijie Xu,Jie Liu,Dan Ye,Shuang Qiu
### Background
增强大型语言模型的推理能力，使用强化学习（RL）仍然是一项关键挑战。现有方法主要采用两种对比的注意力估计粒度：标记级别的方法（例如PPO）试图提供细微的奖励优势信号，但由于难以训练出准确的评论模型，可能导致估计不准确。而路径级别方法（例如GRPO）仅依赖最终奖励的粗粒度优势信号，可能导致不精确的信用分配。
### Innovation
提出了一种新的RL框架——段级策略优化（SPO），利用中间粒度的段级优势估计，通过提供比路径级别方法更精确的信用分配，并需要比标记级别方法更少的估计点，能够基于蒙特卡罗（MC）精确估计而无需评论模型，同时包含三个具有新颖策略的组成部分：灵活的段划分、段优势估计和使用段优势的策略优化，包括一种新颖的概率掩码策略。此外，还针对两种具体场景实例化了SPO：SPO-chain用于短的思维链（CoT），SPO-tree用于长的思维链，后者显著减少了MC估计的成本。
### Conclusion
SPO在GSM8K上针对短CoT实现了6-12个百分点的准确率改进，而SPO-tree在MATH500上实现了2K和4K上下文评估中超过GRPO的7-11个百分点的准确率改进。代码已公开发布。
## 487. `cs.CL` - DrunkAgent：LLM驱动推荐代理中的隐蔽内存破坏 [PDF](https://arxiv.org/pdf/2503.23804), [HTML](https://arxiv.org/abs/2503.23804)
### Authors
Shiyi Yang,Zhibo Hu,Xinshu Li,Chen Wang,Tong Yu,Xiwei Xu,Liming Zhu,Lina Yao
### Background
在推荐系统（RSs）中，以大规模语言模型（LLMs）为动力的代理正逐渐用于个性化行为建模，其中记忆机制在让代理能够自主探索、学习并从现实世界互动中自我演化方面发挥着关键作用。然而，这一机制本质上作为上下文存储库，也暴露了潜在的对抗性操纵渠道。尽管这一角色关键，但这些代理型RSs在面对这种威胁时的鲁棒性尚未得到广泛研究。之前的许多工作都存在语义不匹配或者依赖于静态嵌入和预定义的提示，这些都不是为动态系统设计的，特别是为LLM代理的动态记忆状态。这一挑战进一步加剧了商业推荐系统的黑盒性质。
### Innovation
本文提出了首个关于LLM驱动推荐代理基于记忆的漏洞系统的系统性研究，揭示了它们的安全部限并指导了增强系统韧性和可靠性的努力。具体来说，我们提出了一个名为DrunkAgent的新颖黑盒攻击框架。利用DrunkAgent，可以为特定项目定制具有语义意义的对抗性文本触发器，通过在互动期间破坏记忆更新来最大化触发器效果。触发器和策略在代理上进行了优化，从而使得DrunkAgent具有可移植性和隐秘性。针对不同类型（包括协同过滤、检索增强和序列推荐）的代理推荐系统的真实世界数据集进行了广泛实验，证明了DrunkAgent的普适性、可移植性和隐秘性。
### Conclusion
DrunkAgent 提出了基于LLM驱动的推荐代理的隐秘内存破坏方法，该方法不仅揭示了这些代理系统的安全部限，而且展示了其在实际推荐系统中的广泛适用性和隐秘性。这一工作推动了对抗性机器学习在推荐系统领域的研究，为提高推荐系统安全性提供了新的视角和工具。
## 488. `cs.CL` - 语言模型预训练数据选择中的相似性度量分析 [PDF](https://arxiv.org/pdf/2502.02494), [HTML](https://arxiv.org/abs/2502.02494)
### Authors
Dylan Sam,Ayan Chakrabarti,Afshin Rostamizadeh,Srikumar Ramalingam,Gui Citovsky,Sanjiv Kumar
### Background
评估训练示例之间的相似性是构建高质量和多样化预训练数据集的关键。通常使用通用的预训练嵌入模型来衡量相似性，这些模型常用于检索等任务。然而，这些基于嵌入的相似性度量是否适用于预训练数据选择仍需进一步探索。本文提出了一种新框架来评估特定于语言模型预训练应用的数据选曲中的相似性度量适用性。该框架通过评估距离度量在预训练损失中的泛化能力来作为初步评估标准，使用每个嵌入模型指导标准的多样性的数据选择算法，并通过训练语言模型并在选定的数据上评估下游任务性能来评估其实用性，在实验中该框架被应用于评估语言模型的预训练数据集。
### Innovation
本文提出了一种新的评估框架，专门用于评估相似性度量在语言模型预训练数据曲任务中的适用性。该框架通过两个方面对嵌入进行评估：首先，通过衡量距离度量在预训练损失中的泛化能力；其次，使用嵌入模型指导标准的多样性的数据选择算法，并通过训练语言模型并在选定的数据上评估下游任务的性能。此外，实验还评估了嵌入模型在区分不同数据源中的示例的能力，发现在预训练数据曲任务中，标准的嵌入模型不一定是最优选择，即使是最简单的嵌入模型也可能表现更好。
### Conclusion
标准的预训练嵌入模型并不适用于预训练数据曲选择任务，甚至一些简单嵌入模型的表现都超过了标准嵌入模型。研究表明，现有的评估框架可以作为未来设计能够合理地理解预训练数据集中的相似性的嵌入模型的基础。
## 489. `cs.CL` - 思以视：促进有目的的长视频理解 [PDF](https://arxiv.org/pdf/2506.10821), [HTML](https://arxiv.org/abs/2506.10821)
### Authors
Huaying Yuan,Zheng Liu,Junjie Zhou,Hongjin Qian,Yan Shu,Nicu Sebe,Ji-Rong Wen,Zhicheng Dou
### Background
长视频理解（LVU）是计算机视觉领域的一个具有挑战性的任务。现有方法要么通过降采样帧进行单次推理，牺牲了细节信息，要么依赖于任务无关的表示上的文本推理，这阻碍了特定任务的感知和探索能力。长视频缺乏进行大规模数据训练的资源，使得问题更加复杂。因此，现有方法难以处理复杂任务并提供高质量的轨迹。
### Innovation
本文提出了一种基于'视以思'原则的VideoExplorer框架，该框架自然地将规划、时间对齐和可扩展感知整合进一个连贯的推理过程。VideoExplorer迭代地制定子问题，定位相关时刻，并进行面向任务、可扩展的时间上的视频理解，直到最终答案，从而实现忠实地、有效率地和可解释地推理。同时，为了应对长视频理解训练资源不足的问题，构建了一个长视频推理数据集，并设计了一种两阶段的训练管道，以促进适应性的时间对齐和迭代的信息集成。
### Conclusion
通过广泛的评估，VideoExplorer在流行的长视频理解和推理基准测试上表现出显著的优势，证明了其稳健性、适应性和效率。相关代码已在本存储库中公开。
## 490. `cs.CL` - HauntAttack: 当攻击如影随形般跟随推理 [PDF](https://arxiv.org/pdf/2506.07031), [HTML](https://arxiv.org/abs/2506.07031)
### Authors
Jingyuan Ma,Rui Li,Zheng Li,Junfeng Liu,Heming Xia Lei Sha,Zhifang Sui
### Background
新兴的大规模推理模型（LRMs）在数学和推理任务中表现出色，展示了非凡的推理能力。然而，增强的推理能力及内部推理过程的揭示引入了新的安全性漏洞。当推理与有害性交织时，LRMs是否会更容易在推理模式下遭受破解？为验证这一假设，该研究引入了HauntAttack，一种新型的一般黑盒对抗攻击框架，系统性地将有害指令嵌入推理问题中。
### Innovation
HauntAttack通过修改现有问题的关键推理条件并注入有害指令，构建引导模型逐步产生不安全输出的推理路径。该研究在11个LRMs上评估了HauntAttack，取得了70%的平均攻击成功率，相比最强的先前基线实现了12个百分点的绝对改进。研究进一步表明，即使是最先进且安全对齐的模型也高度易受基于推理的攻击，为未来在平衡推理能力和安全性方面提供了急需的见解。
### Conclusion
研究发现，即使是最先进的安全对齐模型仍高度易受基于推理的攻击，这表明在未来的模型开发中迫切需要平衡推理能力和安全性。
## 491. `cs.CL` - 生成模型或判别模型？在Transformer时代的文本分类重访 [PDF](https://arxiv.org/pdf/2506.12181), [HTML](https://arxiv.org/abs/2506.12181)
### Authors
Siva Rajesh Kasa,Karan Gupta,Sumegh Roychowdhury,Ashutosh Kumar,Yaswanth Biruduraju,Santhosh Kumar Kasa,Nikhil Priyatam Pattisapu,Arindam Bhattacharya,Shailendra Agarwal,Vijay huddar
### Background
从Efron对逻辑回归与判别分析的经典分析开始，生成模型与判别模型之间的比较就一直吸引着研究人员。早期理论工作指出，在简单的线性设置中，生成模型表现出较低的样本复杂度但较高的渐近误差，但这些权衡在Transformer时代仍待探索。本文是首次全面评估现代生成和判别架构在文本分类中的应用，包括自回归建模、掩码语言建模、离散扩散和编码器。研究发现，经典的‘两种模式’现象在不同架构和训练范式下表现明显不同。超越准确性，此研究还分析了样本效率、校准性和噪声鲁棒性等指标，跨越多种场景。这些发现为基于实际限制如延迟和数据限制选择合适的建模方法提供了实用指导。
### Innovation
首次全面评估现代生成和判别架构在文本分类的应用，探索在Transformer时代的生成与判别模型比较的新现象，详细分析样本效率、校准性和噪声鲁棒性等指标，提供实际应用场景下的选择指导
### Conclusion
研究表明，生成与判别模型在不同架构和训练范式下的表现不同。除准确性外，还分析了模型在样本效率、校准性和噪声鲁棒性等方面的性能。研究提出根据实际应用场景中的限制（如延迟和数据限制）来选择最合适的建模方法。
## 492. `cs.CL` - 程序合成中的测试时转导 [PDF](https://arxiv.org/pdf/2509.17393), [HTML](https://arxiv.org/abs/2509.17393)
### Authors
Kang-il Lee,Jahyun Koo,Seunghyun Yoon,Minbeom Kim,Hyukhun Koh,Dongryeol Lee,Kyomin Jung
### Background
传统的程序合成方法通常依赖自然语言描述或输入-输出示例来从训练样本中进行泛化，但这种方法在实际应用中常常面临鲁棒性差的问题，尤其是在训练样本有限且测试输入涉及各种边界情况时表现不佳。
### Innovation
本文提出了一种新的程序合成框架，即通过转导方法在合成过程中显式利用测试输入。该框架通过一种基于程序输出的有限假设类来进行主动学习，利用LLM预测测试输入的输出结果，并通过贪婪最大化算法选择输入以减少LLM查询次数。这种方法在四个基准测试（Playgol, MBPP+, 1D-ARC, 以及MiniGrid上的程序化世界建模）上取得了显著的准确性和效率提升。
### Conclusion
实验结果表明，相对于之前的程序合成方法，这种方法在准确性和效率上都有显著提升。
## 493. `cs.CL` - RepIt: 使用概念特定拒绝向量引导语言模型 [PDF](https://arxiv.org/pdf/2509.13281), [HTML](https://arxiv.org/abs/2509.13281)
### Authors
Vincent Siu,Nathan W. Henry,Nicholas Crispino,Yang Liu,Dawn Song,Chenguang Wang
### Background
在大型语言模型（LLMs）中，激活引导是一个不断发展研究的领域，但现有方法往往会产生超出预期的广泛影响。因此，需要隔离更纯粹的概念向量，以实现精确干预，并更细致地理解LLM的行为。
### Innovation
提出了RepIt，这是一种简单且数据效率高的框架，用于隔离概念特定的表示。RepIt允许在不抑制其他概念的情况下，精确干预特定概念的拒绝表示，从而生成在WMD相关问题上作出回答，但仍然在标准基准上得分安全的模型。
### Conclusion
通过使用RepIt分离拒绝向量，表明了针对特定干预可以克服过度泛化，从而奠定了更精细控制模型行为的基础。此外，纠正信号仅集中在大约100-200个神经元上，并且可以从最少十几个例子在单一A6000设备上提取具有鲁棒性的目标表示。这种高效性引发了双重关注：可以使用较少的计算和数据进行干预以覆盖数据稀缺的领域，并避开现有基准。
## 494. `cs.CL` - MSR-Align：面向安全推理的多模态对齐 [PDF](https://arxiv.org/pdf/2506.19257), [HTML](https://arxiv.org/abs/2506.19257)
### Authors
Yinan Xia,Yilei Jiang,Yingshui Tan,Xiaoyong Zhu,Xiangyu Yue,Bo Zheng
### Background
视觉-语言模型（VLMs）在增强逻辑推理能力后取得了显著进展。然而，这种进展也带来了新的安全风险，这些模型变得更加容易受到有害的多模态提示的攻击，从而触发不道德或不安全的行为。现有的安全对齐方法主要针对单模态语言模型，无法有效应对多模态输入带来的复杂和细腻的威胁。当前的安全数据集缺乏细粒度和策略导向的推理，无法实现对具有逻辑推理能力的VLMs的稳健对齐。
### Innovation
本文介绍了一种名为MSR-Align的高质量多模态安全推理数据集，该数据集专门用于弥合上述差距。MSR-Align支持在视觉和文本模态之间进行细粒度、反思性的策略导向推理。数据生成管道注重多模态多样性、策略导向的推理以及使用强大的多模态审核员进行严格的质量过滤。实验证明，对MSR-Align进行微调显著提高了VLMs对文本和视觉-语言逃逸攻击的鲁棒性，同时保留或增强了通用推理性能。MSR-Align为推理能力较强的VLMs安全对齐提供了一个可扩展且有效的基础。整个数据集已公开发布。
### Conclusion
MSR-Align为推进具有逻辑推理能力的VLMs的安全对齐提供了可扩展且有效的基础，通过将VLMs微调在MSR-Align上，可以有效提高其在面对文本和视觉-语言逃逸攻击时的鲁棒性，同时保持甚至提升其通用推理性能。
## 495. `cs.CL` - R-Horizon: 你的大型推理模型究竟能在广度和深度上走得有多远？ [PDF](https://arxiv.org/pdf/2510.08189), [HTML](https://arxiv.org/abs/2510.08189)
### Authors
Yi Lu,Jianing Wang,Linsen Guo,Wei He,Hongyin Tang,Tao Gui,Xuanjing Huang,Xuezhi Cao,Wei Wang,Xunliang Cai
### Background
近期，推理模型（例如OpenAI o1和DeepSeek-R1）在推理链（CoT）的长链条下的测试时间扩展方面取得了显著进步。然而，现有的基准主要集中在即时、单周期任务上，未能充分评估模型处理复杂、长期场景的能力。
### Innovation
为了解决这一评估不足的问题，本文提出了R-HORIZON方法，通过问题组合激发LRMs的长期推理行为，构建了一个长期推理基准，包含多步推理任务，涉及跨长时间范围的相互依赖问题。通过使用R-HORIZON基准对LRMs进行全面评估，我们发现即使是最先进的模型也面临显著性能下降。分析表明，LRMs的有效推理长度有限，难以在多个问题之间合理分配思考预算。
### Conclusion
认识到这些限制后，我们利用R-HORIZON构建长期推理数据，用于带有验证奖励的强化学习（RLVR）。与使用单周期数据训练相比，RLVR提升了跨周期推理任务的表现，也提高了标准推理任务的准确性，AIME2024上提高了7.5。这些结果将R-HORIZON定位为一个可扩展、可控且低成本的框架，用于提升和评估LRMs的长期推理能力。
## 496. `cs.CL` - 超越 Pass@k：基于 Cover@tau 的推理边界广度深度度量 [PDF](https://arxiv.org/pdf/2510.08325), [HTML](https://arxiv.org/abs/2510.08325)
### Authors
Marius Dragoi,Ioana Pintilie,Florin Gogianu,Florin Brad
### Background
Reinforcement Learning with Verifiable Rewards (RLVR)已证明能显著提升大型语言模型在编程、数学和逻辑推理等任务上的表现。研究人员常通过报道大采样预算下的Pass@k来评估推理边界，即模型能解决的问题比例。最近的研究发现，在小k值时RLVR模型表现优于基础模型，但在大量采样时则表现相反。这种现象被解释为基模具有更大的推理边界。然而，对于具有离散答案空间的任务，如数学问题，Pass@k在大k值时反映的更多的是多次试验中的成功率增加，而非真正的推理能力。
### Innovation
该文提出了一种新的评估方法Cover@tau，通过度量模型解决的问题中至少有部分比例的完成是正确的，该方法捕捉了推理在显式可靠性阈值下的情况。不同于Pass@k，当tau增加时，依靠随机猜测的模型性能迅速下降。该方法用于评估多个RLVR模型，并展示了相比于Pass@1，常用算法的相对排名变化，为推理边界的评估提供了一种新的视角。
### Conclusion
研究表明，与Pass@k相比，Cover@tau能更准确地评估模型在不同可靠性阈值下的推理能力。数据表明，基于Cover@tau的度量方法能够更好地反映模型在数学等任务上的真实推理水平，提供了对推理边界的新见解。
## 497. `cs.CL` - Soundness-Aware Level：一种预测LLM推理潜力的微观签名 [PDF](https://arxiv.org/pdf/2510.15216), [HTML](https://arxiv.org/abs/2510.15216)
### Authors
Xuansheng Wu,Xiaoman Pan,Wenlin Yao,Jianshu Chen
### Background
该论文探讨了一种名为Reinforcement Learning with Verifiable Rewards (RLVR)的方法如何可以激发大型语言模型（LLMs）的强推理能力，但不同基础模型的性能变化巨大。通过正式化推理为从LLM的潜在空间中提取的特征构建的Horn子句链条（“如果-那么”规则），论文揭示了预训练模型的微观属性如何导致这些变化。
### Innovation
论文创新性地提出了Soundness-Aware Level (SAL) 这一微观指标，使用Jensen-Shannon 散度来量化高潜力模型在不同语义可靠性的规则之间概率分布的分离程度。实验结果显示，SAL能够精确预测模型在RLVR后的推理性能，且这一发现揭示了模型推理潜力与其预训练阶段区分正确知识与错误知识的能力密切相关。
### Conclusion
研究结果表明，模型的推理潜力与其内在、预训练阶段区分正确知识与错误知识的能力密切相关。并通过SAL提供了基于模型内部机制预测和选择/设计更强基础模型的实用度量。
## 498. `cs.CL` - 真实用户参与的多轮LLM健康教练的离线策略评估 [PDF](https://arxiv.org/pdf/2510.17173), [HTML](https://arxiv.org/abs/2510.17173)
### Authors
Melik Ozolcer,Sang Won Bae
### Background
本文研究了一个部署在网络上的、配有工具辅助功能的LLM健康教练，通过实际用户参与进行评估。
### Innovation
该研究使用了离线策略评估（OPE）方法来评估多回合的LLM健康教练政策，特别强调了通过因子分解决策头部（工具/风格）来评估策略的有效性。此外，还使用了一个带有隐藏构型的轻量级模拟器，展示了提供少量早期信息优势如何能缩短特征识别时间并提高任务成功率和pass@3。
### Conclusion
研究结果表明，优先进行评估，冻结生成器，学习针对类型奖励（目标工具结果和满意度）的亚群感知决策头部，并始终报告亚群指标，以便揭示平均值掩盖的亚群危害，这是个性化路径的有效方法。
## 499. `cs.CL` - 在语言模型中学习解释权重差异 [PDF](https://arxiv.org/pdf/2510.05092), [HTML](https://arxiv.org/abs/2510.05092)
### Authors
Avichal Goel,Yoon Kim,Nir Shavit,Tony T. Wang
### Background
微调（预训练）语言模型是更新其内部参数知识和使其专门用于新任务和领域的标准方法。然而，与这些模型权重变化（权重差异）相关的模型权重变化通常不具备可解释性。尽管检查微调数据集可以提供有关模型可能如何变化的线索，但这些数据集通常不公开发布或太大而不能直接处理。为了全面理解自然语言中的权重差异，本文介绍了DIT（Diff Interpretation Tuning，差异解释微调）方法，该方法能够训练模型描述其本身由微调引起的修改。
### Innovation
本文提出了一种新的方法——DIT（Differences Interpretation Tuning，差异解释微调），该方法通过使用带有标签的合成权重差异来训练一个DIT-adapter，能够应用于兼容的微调模型，使其能够描述自己由微调引起的变化。通过在两个概念验证场景中展示该方法，即报告隐藏行为和总结微调知识，证明了该方法能够使模型使用准确的自然语言描述来解释其由微调引起的变化。
### Conclusion
本文介绍的DIT方法可以帮助语言模型解释其由微调引起的变化，从而强化模型的可解释性，使研究人员更好地理解模型的行为，这对于模型的应用和发展具有重要意义。
## 500. `cs.CL` - MATRIX: 多模态代理调谐以实现稳健的工具使用推理 [PDF](https://arxiv.org/pdf/2510.08567), [HTML](https://arxiv.org/abs/2510.08567)
### Authors
Tajamul Ashraf,Umair Nawaz,Abdelrahman M. Shaker,Rao Anwer,Philip Torr,Fahad Shahbaz Khan,Salman Khan
### Background
视觉语言模型（VLMs）在具有外部工具访问权限时被用作控制器，以进行复杂的推理和决策，但它们的有效性受限于高质量的多模态轨迹稀缺性和手动注释的成本。作者旨在通过一种以视觉为中心的智能体调谐框架解决这一挑战，该框架可以自动合成多模态轨迹、生成逐步偏好对和训练VLM控制器，从而实现稳健的工具使用推理能力的增强。
### Innovation
开发了一种命名为M-TRACE的大型多模态数据集，包含28500个任务和177000个验证轨迹，并基于此构建了MATRIX代理，这是一种在M-TRACE数据集上微调的控制器，用于逐步工具推理。此外，引入了Pref-X自动生成的偏好对集（11000个），并在此基础上进行逐步偏好学习优化。该方法在Agent-X、GTA和GAIA三个基准测试中均优于开放源和封闭源的VLMs，展示了具备规模和有效性的多模态工具使用能力。
### Conclusion
MATRIX框架通过自动合成多模态轨迹、生成逐步偏好对和优化多模态工具使用推理，显著提高了VLM控制器的性能。该研究通过一个大规模数据集和逐步偏好学习方法，验证了基于代理的模型在工具使用推理任务中的有效性。
## 501. `cs.CL` - SpecExit：通过推测性退出加速大型推理模型 [PDF](https://arxiv.org/pdf/2509.24248), [HTML](https://arxiv.org/abs/2509.24248)
### Authors
Rubing Yang,Huajun Bai,Song Liu,Guanghua Yu,Runzhi Fan,Yanbin Dang,Jiejing Zhang,Kai Liu,Jianchen Zhu,Peng Chen
### Background
尽管大型推理模型（LRMs）在推理任务上表现强劲，但它们经常表现出过度思考的现象，生成不必要的长输出，并且增加了端到端的延迟，这是一个重要的现实部署限制。早期退出机制曾被提出，在推理任务未典型完成前进行终止，以缩短生成长度并几乎不影响准确性。然而，这些机制依赖于探针机制，这会增加检测开销，限制了它们的端到端延迟改进，并使其在跨不同问题上的鲁棒性受到限制。本文借鉴了推测性解码中隐藏状态的使用，提出了一种名为SpecExit的新框架，该框架直接从轻量化草稿模型生成未来标记和早期退出信号，而无需探针开销，并取得了显著的改进。
### Innovation
本文提出了一种新的框架SpecExit，该框架通过轻量级草稿模型直接生成未来标记和早期退出信号，而无需探针机制，从而减少了生成长度并大幅提升了端到端延迟，同时保持了准确性。这种方法利用隐藏状态中的固有信号提供有效的早期退出信号，表明了隐藏状态在高效推理中的广泛使用潜力。
### Conclusion
与推测性解码基线相比，SpecExit方法将平均生成长度减少了66%，并实现了2.5倍的端到端延迟加速，而没有牺牲准确性。该方法表明隐藏状态在高效推理中的广泛应用潜力，代码已发布。
## 502. `cs.CV` - MAT-Agent: 自适应多代理训练优化 [PDF](https://arxiv.org/pdf/2510.17845), [HTML](https://arxiv.org/abs/2510.17845)
### Authors
Jusheng Zhang,Kaitong Cai,Yijia Fan,Ningyuan Liu,Keze Wang
### Background
多标签图像分类需要适应性的训练策略来应对复杂且不断变化的视觉-语义环境，但传统的训练方法依赖于静态配置，无法在动态环境中有效运作。
### Innovation
我们提出了一种名为MAT-Agent的新型多代理框架，重新构想了培训为一个实时协作优化过程。通过部署自主代理动态调整数据增强、优化器、学习率和损失函数，MAT-Agent利用非平稳多臂老虎机算法平衡探索与利用，并通过综合奖励机制结合准确性、稀有类别性能和训练稳定性进行引导。该框架还通过双速率指数移动平均平滑和混合精度训练确保了稳健性和效率。
### Conclusion
在Pascal VOC、COCO和VG-256上的广泛实验表明，MAT-Agent表现出色：在Pascal VOC数据集上取得了mAP 97.4（高于PAT-T的96.2）、OF1 92.3和CF1 91.4；在COCO数据集上取得了mAP 92.8（高于HSQ-CvN的92.0）、OF1 88.2和CF1 87.1；在VG-256数据集上取得了mAP 60.9、OF1 70.8和CF1 61.1。得益于加速的收敛性和强健的跨域泛化能力，MAT-Agent为优化复杂视觉模型提供了可扩展且智能化的解决方案，为自适应深度学习技术的进步铺平了道路。
## 503. `cs.CV` - 使用视觉姿态关键点作为IMU的仿生潜水员游泳状态分类 [PDF](https://arxiv.org/pdf/2510.17863), [HTML](https://arxiv.org/abs/2510.17863)
### Authors
Demetrious T. Kutzke,Ying-Kun Wu,Elizabeth Terveen,Junaed Sattar
### Background
传统的水下活动识别要么依赖直接的图像分析，要么依赖穿戴式惯性测量单元（IMUs）的数据，但在挑战性的水下环境中效果不佳。
### Innovation
提出了一种新颖的混合方法，结合了计算机视觉和关键点数据，有效解决了无线信号衰减问题，克服了传统穿戴式传感器与自主水下车辆（AUV）通信的限制。通过将分类器集成到AUV上并进行模拟救援场景的实验，展示了该方法在水下机器人监控和潜水员安全中的实用性和有效性。
### Conclusion
该研究提出的方法通过整合计算机视觉与关键点技术，有效提升了水下活动的安全识别能力，尤其是在传输信号受到限制的条件下，为提高水下机器人技术水平和增强潜水员的安全保护提供了新的思路。
## 504. `cs.CV` - 使用潜在扩散模型的治疗前到治疗后的胶质母细胞瘤MRI预测 [PDF](https://arxiv.org/pdf/2510.17851), [HTML](https://arxiv.org/abs/2510.17851)
### Authors
Alexandre G. Leclercq,Sébastien Bougleux,Noémie N. Moreau,Alexis Desmonts,Romain Hérault,Aurélien Corroyer-Dulmont
### Background
胶质母细胞瘤（GBM）是一种具有大约15个月中位生存期的高度侵袭性原发性脑肿瘤。在临床实践中，Stupp方案是标准的一线治疗方法，但患者对治疗的反应高度异质性，通常需要至少两个月才能从MRI中观察到第一次视觉影响。早期预测治疗反应对于推进个性化医疗至关重要。疾病进展建模（DPM）旨在捕捉疾病演变的过程，而治疗反应预测（TRP）专注于评估治疗干预的影响。大多数TRP方法主要依赖时间序列数据，而本文将早期视觉TRP问题视为从术前MRI生成术后MRI的切片到切片的翻译模型，反映了肿瘤的演变。
### Innovation
本文提出了一种潜在扩散模型，该模型结合了术前MRI和肿瘤定位，并使用生存信息，特别是术后肿瘤演变的条件信息，通过连接方式对不良引导进行条件化以提高生成质量。该模型在包含140名胶质母细胞瘤患者的本地数据集上进行了训练和测试，每次患者收集术前和术后T1-Gd MRI，及由医学专家在术前MRI中手动绘制的肿瘤定位和生存信息。
### Conclusion
本文提出了一个具备连接式条件生成方式的潜在扩散模型，利用术前MRI、肿瘤定位信息和生存信息预测术后MRI，以早期预测胶质母细胞瘤的治疗效果，为个性化医疗提供了新的方法。
## 505. `cs.CV` - CMIS-Net: 一种用于回话支持估计的级联多尺度个体标准化网络 [PDF](https://arxiv.org/pdf/2510.17855), [HTML](https://arxiv.org/abs/2510.17855)
### Authors
Yuxuan Huang,Kangzhong Wang,Eugene Yujun Fu,Grace Ngai,Peter H.F. Ng
### Background
回通道是听众在对话中传达理解和同意的微妙反应，如点头、微笑或简短的语句如“是”或“嗯哼”。这些信号会提供反馈给说话者，改善互动流畅性，并在构建具有人类响应性的AI系统中起到关键作用。然而，这些反应的表达往往受到个体差异的显著影响，涉及多个层面：从即时动态（如响应强度）到时间模式（如频率和节奏偏好）。这为当代情感识别方法提出了一个复杂模式识别问题，而现有方法尚未充分解决这一问题，尤其是现有个体化的情感识别方法往往忽略多尺度行为线索的互补性，仅在单一尺度上运作。因此，迫切需要开发一种新的方法来解决这些问题，进一步增强模型在处理个体差异和数据不平衡方面的表现，从而提高对回通道一致性的检测能力。
### Innovation
我们提出了一种新型的级联多尺度个体标准化网络（CMIS-Net），通过从观察到的表达中移除个人特定的中性基线，来提取个体标准化的回通道特征。该网络在帧级和序列级上运行，通过标准化使模型专注于每个人基线相对变化，而非绝对表达值。此外，我们引入了一个隐式的数据增强模块，以解决训练数据偏差的问题，从而改进模型的概括能力。
### Conclusion
全面的实验和可视化结果表明，CMIS-Net有效处理了个体差异和数据不平衡问题，实现了回通道一致性检测的最新性能。
## 506. `cs.CL` - Glyph: 通过视觉与文本压缩扩展上下文窗口 [PDF](https://arxiv.org/pdf/2510.17800), [HTML](https://arxiv.org/abs/2510.17800)
### Authors
Jiale Cheng,Yusen Liu,Xinyu Zhang,Yulin Fei,Wenyi Hong,Ruiliang Lyu,Weihan Wang,Zhe Su,Xiaotao Gu,Xiao Liu,Yushi Bai,Jie Tang,Hongning Wang,Minlie Huang
### Background
大型语言模型（LLMs）在文档理解、代码分析和多步推理等任务中越来越依赖长期上下文建模。然而，将上下文窗口扩展到百万标记水平带来了巨大的计算和内存成本，限制了这些模型的实际应用。现有方法难以大规模应用大规模上下文窗口，导致上下文模型的实践使用受到限制。研究者们关注如何有效扩展上下文窗口并在保持性能的同时降低计算成本与内存成本等问题，但现有方法仍存在挑战。研究工作提出了一种新的视角——视觉上下文扩展——以应对这一挑战。这种方法通过将文本渲染成图像，采用视觉语言模型（VLMs）处理，从而有效压缩文本输入，并优化视觉渲染配置以平衡准确性和压缩性，实现将文本内容使用视觉数据进行有效转换和重组，以降低计算成本和内存成本，保持模型性能，扩大模型的应用范围。研究表明，在保持与先进模型相当的准确性的同时，该方法可实现3-4倍的标记压缩，并且能够大幅提升预填充和解码速度，加速模型微调训练。这也使得在极端压缩下，具有128K上下文的视觉语言模型能够处理百万标记级别的文本任务。该方法对现实世界的多模态任务，如文档理解等具有广泛的应用价值。
### Innovation
本文提出的Glyph框架通过将文本转换为图像并利用视觉语言模型来进行处理，实现了对长文本的视觉与文本压缩，从而有效缩短计算成本和内存成本。此外，通过LLM驱动的遗传搜索算法优化视觉渲染配置，以平衡准确性和压缩性。这种方法不仅在多个长期上下文基准测试中取得了与顶级LLM相当的准确率，还实现了大约3-4倍的标记压缩。此外，在极端压缩情况下，128K上下文的视觉语言模型可以处理1M标记级别的文本任务，显著提高了模型的处理能力与适用范围。这种方法为多模态任务，如文档理解，提供了新的解决方案。
### Conclusion
实验结果表明，该方法在保持与顶级LLM相当的准确性的同时，实现了3-4倍的标记压缩，并具有4倍的预填充和解码速度，以及大约2倍的模型微调训练速度。此外，在极端压缩情况下，128K上下文的视觉语言模型能够处理1M标记级别的文本任务。这种方法对于现实世界的多模态任务，如文档理解，具有广泛的应用价值。
## 507. `cs.CV` - InsideOut: 集成RGB-辐射高斯点渲染的全方位3D对象表示 [PDF](https://arxiv.org/pdf/2510.17864), [HTML](https://arxiv.org/abs/2510.17864)
### Authors
Jungmin Lee,Seonghyuk Hong,Juyong Lee,Jaeyoon Lee,Jongwon Choi
### Background
在医学诊断、文化遗产修复和制造业等领域，高保真RGB表面细节与次表面X射线结构的融合对于提供全面的3D对象表示是至关重要的。然而，现有的方法在处理来自不同模态数据的各个方面和有限配对数据集时存在挑战。
### Innovation
本文提出了InsideOut，一种基于3D高斯点渲染（3DGS）的扩展方法，它填补了高保真RGB表面细节与次表面X射线结构之间的差距。通过收集新的RGB和X射线配对数据，进行分层拟合以对齐RGB和X射线辐射高斯点，并提出X射线参考损失来确保内部结构的一致性。这种方法有效解决了两种模态之间数据表示差异和有限配对数据集带来的挑战。
### Conclusion
本方法显著扩展了3DGS的应用范围，增强了在各领域中的可视化、模拟和非破坏性测试能力。
## 508. `cs.CV` - 预训练流匹配扩散模型的捷径化几乎是免费午餐 [PDF](https://arxiv.org/pdf/2510.17858), [HTML](https://arxiv.org/abs/2510.17858)
### Authors
Xu Cai,Yang Wu,Qianli Chen,Haoran Wu,Lichuan Xiang,Hongkai Wen
### Background
原本通过捷径模型引入的流匹配技术虽然可以灵活跳过某些步骤，但这种捷径化需要专门的步长嵌入机制，这意味着除非从头开始重训练，否则很难适用于现有的模型。这一重训练过程的成本几乎与预训练本身相当。因此，本文旨在通过自引导的蒸馏原理，赋予标准流匹配模型（如Flux）更为激进的捷径机制，使得可以在不牺牲性能的前提下对这些模型进行高效的捷径化，从而降低整个训练过程的成本。同时，这种方法还可以直接集成到预训练阶段，使得模型本身便能学习到高效、少步骤的流，有效地减少了训练成本，甚至能够为参数量达到数十亿的扩散模型提供一种几乎免费的少样本蒸馏方法，从而达到最佳性能。
### Innovation
本文提出了一种新颖的从大规模预训练流匹配扩散模型转换为高效少步骤采样的后训练方法，这种方法通过独特的蒸馏原理来实施，无需步长嵌入机制。基于这种方法，可以在不牺牲性能的情况下迅速训练模型（例如，不到一个A100天就能训练出3步骤的Flux模型）。此外，这种方法还可以直接应用于预训练阶段，从而赋予模型自学习高效、少步骤流的能力，首次实现了参数量达数十亿级别的扩散模型的少样本蒸馏，并能近乎零成本地提高性能。
### Conclusion
通过这种方法，可以几乎免费地将预训练流匹配扩散模型转换为高效的少步骤采样器，并首次实现了数十亿参数量级别的扩散模型的少样本蒸馏，从而达到最先进的性能，成本却几乎可以忽略不计。
## 509. `cs.CV` - AI生成图像的来源：一种向量相似性和区块链方法 [PDF](https://arxiv.org/pdf/2510.17854), [HTML](https://arxiv.org/abs/2510.17854)
### Authors
Jitendra Sharma,Arthur Carvalho,Suman Bhunia
### Background
近年来，生成型AI和大型语言模型（LLMs）的快速发展使得生成高度逼真和上下文相关的内容变得可能。像ChatGPT这样的模型集成了DALL-E，使用稳定扩散技术等，能够生成的人眼难以分辨的人工图像，这给数字内容认证带来了挑战。确保数字数据的完整性和来源，防止数据被篡改和保持真实性，对于维护数字媒体中的信任和合法性至关重要。因此，本研究旨在开发一种基于嵌入式的AI图像检测框架，利用图像嵌入和向量相似性来区分AI生成的图像和真实的人类创作的图像。研究表明，在不同基准嵌入模型下处理多种数据集后，AI生成的图像与其它AI生成的内容在嵌入空间中的邻近性更接近，而人类创作的图像在各自领域内会聚类得更紧密。实验表明，我们的方法具有较强的鲁棒性，适度到高度的扰动对嵌入特征的影响较小，扰动图片能保持与原始版本的高度相似性。
### Innovation
本文提出了一种基于嵌入式技术的AI图像检测框架，利用向量相似性来区分AI生成的图像和真实人类创作的图像。该方法假设AI生成的图像在嵌入空间中与其他AI生成的内容更近，而人类创作的图像在它们各自的领域内会更密集地聚类。该研究通过使用五种基准嵌入模型来处理一个包含AI和人类生成图像的多样化数据集，展示了方法的稳健性并确认了适度到高度扰动对嵌入特征影响较小，从而开发出一种平衡准确性和计算效率的一般化框架用于AI生成图像的检测。
### Conclusion
该研究提供了一种基于嵌入式技术的AI生成图像检测框架，该框架能平衡准确性和计算效率。通过迭代实验和验证，该框架在多种基准嵌入模型下保持了稳健性，能够在适度到高度扰动的情况下维持对原始版本图像的相似匹配。
## 510. `cs.CV` - MUSE: 基于模型的不确定性感知相似性估计用于零样本2D物体检测和分割 [PDF](https://arxiv.org/pdf/2510.17866), [HTML](https://arxiv.org/abs/2510.17866)
### Authors
Sungmin Cho,Sungbum Park,Insoo Oh
### Background
本文介绍了一种名为MUSE（Model-based Uncertainty-aware Similarity Estimation）的新框架，该框架用于基于模型的零样本2D物体检测和分割。MUSE框架不依赖于额外的训练或微调，它可以利用从未见过的3D物体中渲染出的2D多视图模板以及输入查询图像中提取的2D物体提案来处理这些任务。该框架旨在解决当前方法在处理未见过的物体时的局限性，通过集成类和块嵌入，并结合绝对和相对相似性得分来增强匹配的鲁棒性，最终通过不确定性感知的对象先验来改进相似度评分。这些改进展示了MUSE框架的强大和通用性，使其在BOP挑战赛2025的各个赛道中均取得优异成绩，从而证明了其在零样本2D物体检测和分割任务中的优越性能和广泛应用潜力。
### Innovation
MUSE框架的关键创新点在于其不依赖额外训练的特性，该框架通过利用2D多视图模板和从输入查询图像中提取的2D物体提案来处理零样本任务。在嵌入阶段，利用归一化的广义平均池化（GeM）来高效捕捉全局和局部表示。匹配阶段则采用结合绝对和相对相似性得分的联合相似性度量，以增强在挑战性场景下的匹配鲁棒性。最终通过不确定性感知的对象先验修正相似度评分，从而提高了匹配的准确性。
### Conclusion
MUSE框架在美国BOP挑战赛2025的各个赛道中均取得了最先进的性能，位列第一。这一结果表明，MUSE框架为零样本2D物体检测和分割提供了一种强大且通用的解决方案。
## 511. `cs.CV` - 基于GAN的内容条件生成手写音乐符号 [PDF](https://arxiv.org/pdf/2510.17869), [HTML](https://arxiv.org/abs/2510.17869)
### Authors
Gerard Asbert,Pau Torras,Lei Kang,Alicia Fornés,Josep Lladós
### Background
光学音乐识别（OMR）领域目前受到实际标注数据稀缺的阻碍，尤其是在处理手写历史音乐谱时更为明显。类似领域，如手写文本识别，已证明使用图像生成技术生成的合成样本可以帮助训练表现更好的识别架构。
### Innovation
研究了通过实施音乐符号级生成对抗网络（GAN）生成逼真、手写外观的乐谱，并使用Smashcima刻写软件将其输出组合成完整的乐谱。系统评估了生成样本的视觉保真度，结果显示生成的符号具有很高的现实感，标志着合成乐谱生成的重要进展。
### Conclusion
生成的符号表现出高度的真实感，标志着合成乐谱生成方面取得了重大进展。
## 512. `cs.CV` - ManzaiSet：日本单口喜剧观众反应的多模态数据集 [PDF](https://arxiv.org/pdf/2510.18014), [HTML](https://arxiv.org/abs/2510.18014)
### Authors
Kazuki Kawamura,Kengo Nakai,Jun Rekimoto
### Background
现有的情感计算数据集中存在西方中心主义偏见，缺乏对东方文化的情感反应研究。日本单口喜剧（Manzai）作为一种独特的表演艺术形式，在日本具有广泛的受众基础，了解观众对此类表演的情感反应对中国乃至全球观众的大规模情感分析具有重要意义。
### Innovation
该研究首次构建了一个大规模多模态数据集，该数据集包含了观众对日本单口喜剧表演的情感反应，包括面部视频和声音数据。通过分析，研究人员发现了观众反应的三种不同模式，挑战了观众疲劳假设，为开发文化敏感的情感AI和定制娱乐系统提供了数据支持。
### Conclusion
ManzaiSet数据集有助于开发具备文化意识的情感AI，并为非西方语境下的个性化娱乐系统提供定制化支持。通过该数据集的分析，研究发现观众的情感反应模式较为多样化，个体层面的观看顺序对情感反应有积极影响，且没有证据支持不同观众类型间的幽默感知差异。
## 513. `cs.CV` - ViBED-Net: 视频基于人脸识别和场景感知时空线索的学生参与检测网络 [PDF](https://arxiv.org/pdf/2510.18016), [HTML](https://arxiv.org/abs/2510.18016)
### Authors
Prateek Gothwal,Deeptimaan Banerjee,Ashis Kumer Biswas
### Background
在线学习环境中学生参与度检测对于改善学生成果和个性化教学至关重要。目前存在的挑战包括如何有效利用视频数据来评估学生的参与状态以及如何提高模型对未充分均衡分类的参与度类别表现.
### Innovation
提出了一种新颖的深度学习框架ViBED-Net，通过使用双流架构可以从视频数据中捕捉到面部表情和全场景上下文。模型结合了EfficientNetV2的空间特征提取、LSTM网络和Transformer编码器的时序建模策略，并通过特定的数据增强技术改进了未充分代表的参与度类别性能。ViBED-Net在DAiSEE数据集上实现了显著的准确率，展示了利用人脸识别和场景感知时空线索可大幅提高参与度检测准确性.
### Conclusion
ViBED-Net提供了面向现实世界参与度分析的可扩展、高性能视频情感计算解决方案，其模块化设计使得该模型可以应用于教育、用户体验研究和内容个性化领域。此研究取得了高于现有最先进的方法的参与度检测性能，并推动了基于视频的情感计算领域的发展。
## 514. `cs.CV` - 3D弱监督语义分割通过类别感知和几何引导伪标签精炼 [PDF](https://arxiv.org/pdf/2510.17875), [HTML](https://arxiv.org/abs/2510.17875)
### Authors
Xiaoxu Xu,Xuexun Liu,Jinlong Li,Yitian Yuan,Qiudan Zhang,Lin Ma,Nicu Sebe,Xu Wang
### Background
3D弱监督语义分割（3D WSSS）旨在利用稀疏或低成本标注数据实现语义分割，显著减少对密集点wise标注的依赖。以往研究主要利用类激活图或预训练的视觉-语言模型来解决这一问题。然而，伪标签质量低和对3D几何先验的不足利用共同构成了高性能3D WSSS模型开发中的重大技术瓶颈。
### Innovation
本研究提出了一种简单而有效的3D弱监督语义分割方法，将3D几何先验整合到类别感知的精炼机制中，生成高保真伪标签。具体而言，设计的机制首先使用类别感知标签精炼模块生成更平衡和准确的伪标签，后采用几何感知标签精炼组件，集成隐式3D几何约束过滤不满足几何可解释性的伪标签。同时，提出了一种标签更新策略，利用自我培训传播标签进入大量未标注区域，实现伪标签质量的持续增强和标签覆盖范围的扩展，最终推动高性能3D WSSS模型的开发。
### Conclusion
全面的实验验证表明，所提出的方法在ScanNet和S3DIS基准上达到了最先进的性能，并且在无监督设置中展现出卓越的泛化能力，通过其稳健的设计保持了竞争的准确性。
## 515. `cs.CV` - 探究脑MRI分割中的人口统计偏差：基于深度学习和非深度学习方法的比较研究 [PDF](https://arxiv.org/pdf/2510.17999), [HTML](https://arxiv.org/abs/2510.17999)
### Authors
Ghazal Danaee,Marc Niethammer,Jarrett Rushmore,Sylvain Bouix
### Background
深度学习分割算法在医学图像分析领域的进步，特别是在MRI结构细分方面明显提高。然而，数据中固有的偏差是一个需要考虑的重要问题。尤其是对敏感属性，如种族和性别，基于性能差异的不公问题越来越迫切。该研究使用了四种人口亚组（黑女性、黑男性、白女性、白男性）的MRI数据集，评估了三种不同分割模型（UNesT、nnU-Net、CoTr）和传统图谱法（ANTs）在Nac分割中的表现，并分析了种族、性别及其交互作用对分割结果和体积估计的影响。
### Innovation
研究创新地结合了对人口统计偏差的评价，不仅使用了深度学习模型，还加入了传统的图谱方法进行对比。使用专为分割性能公平性设计的量化指标，以及线性混合模型来分析人口统计变量对分割准确性和测量体积的影响。研究揭示了种族匹配训练对某些模型分割精度的影响，并进一步探讨了不同模型在分割Nac体积时性别和种族效应的差异。
### Conclusion
研究结果表明，在同种族数据上训练的模型在某些情况下具有更好的分割准确性。ANTs和UNesT在种族匹配数据上表现出显著的准确性改进，而nnU-Net则在人口匹配与否的情况下都展现了稳健的性能。进一步分析显示，性别效应在有偏差模型中具有可重复性，但种族效应在大多数模型中消失，仅一个模型中仍存在。
## 516. `cs.CV` - HouseTour：一个虚拟房地产智能代理 [PDF](https://arxiv.org/pdf/2510.18054), [HTML](https://arxiv.org/abs/2510.18054)
### Authors
Ata Çelen,Marc Pollefeys,Daniel Barath,Iro Armeni
### Background
现有的视觉-语言模型(VLMs)在几何推理方面存在挑战，而本文通过引入HouseTour方法，能够从一组描绘现有三维空间的图片中生成具有空间感知的3D相机轨迹和自然语言摘要。HouseTour方法使用一个受限于已知相机姿态的扩散过程生成平滑的视频轨迹，并将这些信息集成到VLM中，以便生成基于三维的空间描述。
### Innovation
本文提出了一种新型的方法HouseTour，通过限制扩散过程的空间感知相机姿态信息，能够更有效地生成平滑的3D相机轨迹，并将其融合到VLM中以生成准确的三维描述。此外，还提出了HouseTour数据集，包含了超过1,200个房屋游览视频，覆盖了相机姿态、3D重建和房地产描述，为方法的有效性提供了数据支持。同时引入了一个新的联合评估指标来评估模型性能。
### Conclusion
通过将3D相机轨迹整合到文本生成过程中，HouseTour方法在处理任务上实现了优于单独任务的有效性提升。该工作在房地产和旅游应用中开启了自动化、专业级视频创建的可能性，不需要专门的技术或设备。
## 517. `cs.CV` - SAVANT: Semantic分析增强异常检测的语义分析 [PDF](https://arxiv.org/pdf/2510.18034), [HTML](https://arxiv.org/abs/2510.18034)
### Authors
Roberto Brusnicki,David Pop,Yuan Gao,Mattia Piccinini,Johannes Betz
### Background
自主驾驶系统对罕见的、出分布的具有语义异常的长尾场景依然极度脆弱。尽管视觉语言模型(VLMs)提供了有力的推理能力，但简单的提示方法导致了不可靠的表现，并依赖于昂贵的专有模型，这限制了其实际部署。现有的方法未能系统地处理场景的多层次语义分解和多模态评估，导致检测准确性不足和成本高昂。
### Innovation
SAVANT提出了一种结构化的推理框架，通过分层场景分析和两阶段流水线（结构化的场景描述提取后进行多模态评估）来检测输入图像中的异常驾驶场景，实现了高准确率和召回率。SAVANT将对场景的语义推理从单刀直入的提示转变为跨四层语义（街道、基础设施、可移动物体、环境）的系统分析。它使用一个微调的7B参数开源模型（Qwen2.5VL），在真实世界驾驶场景中取得了90.8%的召回率和93.8%的准确率，显著优于其他模型，并且提供了一种本地部署的零成本方案。SAVANT通过自动高精度标注超过9,640张真实世界图像，解决了异常检测中的数据短缺问题，并提供了一条向自主系统提供可靠的、可访问的语义监控的实际路径。
### Conclusion
SAVANT通过自动高精度标注大量真实世界图像，解决了视觉异常检测中的数据短缺问题，显著提高了异常场景检测的准确性和召回率，并且通过使用一个低成本的开源模型，实现了有效的本地部署。
## 518. `cs.CV` - TriggerNet：一种用于红棕榈叶甲虫检测和多模型比较及启发式注释的新解释性AI框架 [PDF](https://arxiv.org/pdf/2510.18038), [HTML](https://arxiv.org/abs/2510.18038)
### Authors
Harshini Suresha,Kavitha SH
### Background
红棕榈叶甲虫的感染已经成为一个严重的问题，尤其是在大规模种植棕榈的地区，导致产量减少和经济损失。准确和早期识别受感染的植物对于有效的管理至关重要。当前的研究集中在评估和比较用于分类受感染植物和检测感染的机器学习模型。研究使用了11种不同植物的多样RGB图像进行训练和评估，旨在通过先进的深度学习模型和机器学习分类器来解决红棕榈叶甲虫（Raoiella indica）感染的问题，这是一种对棕榈种植和农业生产力的主要威胁。
### Innovation
TriggerNet是一个新颖的解释性AI框架，它结合了Grad-CAM、RISE、FullGrad和TCAV，用于生成深度学习模型在植物分类和疾病检测方面的新型视觉解释。该框架特别适用于红棕榈叶甲虫感染的检测，通过应用先进的深度学习模型（如CNN、EfficientNet、MobileNet、ViT、ResNet50、InceptionV3）和机器学习分类器（如随机森林、SVM、KNN），并利用启发式规则和模式进行高效标记，从而减少了手动标注时间和提高了数据集的可靠性。
### Conclusion
通过使用TriggerNet框架，研究有效地比较了多种机器学习模型和深度学习模型，以检测红棕榈叶甲虫感染。多样化的植物数据集和启发式标注方法大大提高了模型的准确性和可靠性。最终，该研究为红棕榈叶甲虫感染的早期检测和有效管理提供了重要的技术支持。
## 519. `cs.CV` - CoIDO：通过耦合重要性和多样性的优化实现高效的数据选择，以提高视觉指令调优效率 [PDF](https://arxiv.org/pdf/2510.17847), [HTML](https://arxiv.org/abs/2510.17847)
### Authors
Yichen Yan,Ming Zhong,Qi Zhu,Xiaoling Gu,Jinpeng Chen,Huan Li
### Background
多模态大语言模型（MLLMs）依赖于指令调优来对齐视觉和语言能力，但大规模数据集的训练计算成本仍然是一个主要瓶颈。现有的数据选择方法试图通过选择重要且多样性的子集来减轻这一问题，但它们往往面临两个关键缺陷：处理整个数据集的高计算开销和由于分别处理重要性和多样性而导致的次优化数据选择。
### Innovation
我们引入了CoIDO（Coupled Importance-Diversity Objective），这是一种新的双目标框架，可以同时优化数据的重要性和多样性，以克服这些挑战。CoIDO使用了一个轻量级插件评分器，该评分器仅在一小部分随机数据上进行训练，以学习候选集的分布，从而大大减少计算需求。通过利用同质不确定性形式，CoIDO在训练期间有效平衡重要性和多样性，实现高效和可扩展的数据选择。实验表明，使用20％随机采样数据训练的CoIDO评分器，应用于整个数据集，选用20％子集用于指令调优，该选集在广泛使用的LLaVA-1.5-7B模型的十个下游任务中，平均实现了全数据微调98.2％的性能。
### Conclusion
CoIDO能够在高效的计算成本下实现高质量的数据选择，显著提升了视觉指令调优的效果。
## 520. `cs.CV` -  Chimera: 基于部分概念化的组合图像生成 [PDF](https://arxiv.org/pdf/2510.18083), [HTML](https://arxiv.org/abs/2510.18083)
### Authors
Shivam Singh,Yiming Chen,Agneet Chatterjee,Amit Raj,James Hays,Yezhou Yang,Chitra Baral
### Background
个性化图像生成模型在从文本或单张图像生成图像方面极为熟练，但缺乏将特定来源图像中的特定部分组合成新对象的显式控制，尤其在没有用户指定的掩码或注释的情况下。为解决这一问题，本文介绍了一种名为Chimera的新个性化图像生成模型，该模型通过文本指令将不同来源图像的不同部分结合生成新的对象。为训练模型，作者构建了一个基于464个独特（部分，主题）对的语义原子分类体系，并生成了37000个提示以及使用高保真文本到图像模型生成对应图像。通过部分条件引导训练自定义扩散先验模型，并在生成图像过程中约束图象条件特征以确保语义身份和空间布局的要求。
### Innovation
提出了一种名为 Chimera 的个性化图像生成模型，能够根据文本指令将不同来源图像中的特定部分结合以生成新对象。不同之处在于，该模型没有依赖用户指定的掩码或注释，并通过部分条件引导训练自定义扩散先验模型，以确保生成图像的语义身份和空间布局。此外，还引入了一个名为PartEval的客观度量指标，用于评估生成管道的保真度和组合准确度。
### Conclusion
通过人类评估和提出的新度量指标，Chimera 在部分对齐和组合准确度以及视觉质量方面分别比其他基线模型高出 14% 和 21%。
## 521. `cs.CV` - 大数据与微目标：增强机器学习检测滤器中微塑料的探索性研究 [PDF](https://arxiv.org/pdf/2510.18089), [HTML](https://arxiv.org/abs/2510.18089)
### Authors
Paul-Tiberiu Miclea,Martin Sboron,Hardik Vaghasiya,Hoang Thinh Nguyen,Meet Gadara,Thomas Schmid
### Background
微塑料（MPs）是无处不在的污染物，对生态系统和人类健康具有潜在影响。它们的微小尺寸使得检测、分类和去除复杂，特别是在生物和环境样本中。尽管光学显微镜、扫描电子显微镜（SEM）和原子力显微镜（AFM）等技术为检测提供了基础，但这些方法通常需要手工分析，无法有效应用于大规模筛选研究。因此，机器学习（ML）已经成为促进微塑料检测的强大工具。
### Innovation
本研究探索了将SEM成像与基于机器学习的对象检测相结合，以提高微塑料颗粒和纤维的检测和量化能力。研究简化了背景呈对称和重复模式的过滤器场景。研究结果表明YOLO模型在给定任务中的质量差异，并强调了预处理优化的必要性。同时，研究指出了一些挑战，如为可靠训练机器学习模型所需的专业标记数据量有限。
### Conclusion
研究表明，YOLO模型的质量对任务完成有影响，优化预处理是必要的。同时，还指出了专业标记数据量有限等挑战，需要更多的努力来训练可靠的机器学习模型。未来的研究方向包括改进预处理方法和增加用以训练模型的专业标注数据。
## 522. `cs.CV` - 使用自适应 patch 大小加速视觉变换器 [PDF](https://arxiv.org/pdf/2510.18091), [HTML](https://arxiv.org/abs/2510.18091)
### Authors
Rohan Choudhury,JungEun Kim,Jinhyung Park,Eunho Yang,László A. Jeni,Kris M. Kitani
### Background
视觉变换器（ViTs）将输入图像划分为固定大小的 patch，不论 patch 内容如何，这导致高分辨率图像的输入序列长度较长。研究指出，自适应 Patch 变换器（APT）通过在同一张图像中使用不同大小的 patch 来解决这一问题。APT 通过在更均匀的区域分配更大的 patch 大小，在更复杂的区域分配较小的 patches 从而减少输入 tokens 的总数。
### Innovation
APT 减少了 ViT 推理和训练的总体速度，提高了 ViT-L 40% 和 ViT-H 50% 的吞吐量，同时保持了下游任务的表现。APT 可以应用于原先已微调的 ViT，仅需 1 个 epoch 就可以收敛。此外，APT 在高强度视觉任务中显著减少了训练和推理时间，而不会损失性能，尤其是在视觉 QA、对象检测和语义分割等领域，训练和推理速度可以提高至 30%。
### Conclusion
APT 通过自适应划分 patch 的方式，既提高了视觉变换器在高分辨率密集视觉任务中的性能效率，又保持了原有的模型效果。
## 523. `cs.CV` - 从体绘制到3D高斯散点图：理论与应用 [PDF](https://arxiv.org/pdf/2510.18101), [HTML](https://arxiv.org/abs/2510.18101)
### Authors
Vitor Pereira Matias,Daniel Perazzo,Vinicius Silva,Alberto Raposo,Luiz Velho,Afonso Paiva,Tiago Novello
### Background
3D重建从布置图像的问题正经历基本的转变，这得益于3D高斯散点图（3DGS）的持续进步。3DGS通过显式建模场景为3D高斯集合，结合体积散点进行高效的光栅化，从而无缝融入常见的图形流水线。虽然在实时渲染与新视图综合方面具有优势，但3DGS仍面临高内存占用、直接烘焙照明效果以及次级光线效果支持有限等问题。
### Innovation
本文提供了3DGS管道的简洁全面概述，从散点表述出发，并探索了克服其限制的主要努力。还综述了3DGS技术在表面重建、avatar建模、动画和内容生成等多个应用领域的展现，强调了其高效的渲染能力和对于前馈管道的适用性。
### Conclusion
本文总结了3DGS技术在多种应用中的高效渲染能力及其适用性，提出了3DGS在实现实时3D重建和新视图合成方面的重要作用与限制，并探讨了其未来的研究方向和应用场景。
## 524. `cs.CV` - VelocityNet：基于人员特定速度分析的实时人群异常检测 [PDF](https://arxiv.org/pdf/2510.18187), [HTML](https://arxiv.org/abs/2510.18187)
### Authors
Fatima AlGhamdi,Omar Alharbi,Abdullah Aldwyish,Raied Aljadaany,Muhammad Kamran J Khan,Huda Alamri
### Background
在人群密集场景中检测异常具有挑战性，因为存在严重的互相遮挡和高度动态、依赖于上下文的运动模式。现有方法往往难以适应不同的人群密度，并缺乏可解释的异常指标。
### Innovation
我们引入了VelocityNet，这是一种双管道框架，它结合了头部检测和密集光流，以提取个体特定的速度。层次聚类将这些速度分类为语义运动类（停止、缓慢、正常和快速），并采用基于百分位数的异常评分系统来衡量学习的正常模式下的偏差。
### Conclusion
实验证明了我们的框架在密集人群中以实时方式检测各种异常运动模式的有效性。
## 525. `cs.CV` - 低资源视觉语言模型的在线下行在上下文蒸馏 [PDF](https://arxiv.org/pdf/2510.18117), [HTML](https://arxiv.org/abs/2510.18117)
### Authors
Zhiqi Kang,Rahaf Aljundi,Vaggelis Dorovatas,Karteek Alahari
### Background
随着领域对更多资源的需求不断增加，该研究聚焦于关键问题：如何使视觉语言模型（VLMs）适应低资源和预算有限的环境。虽然大型VLMs表现出色，但在资源有限的环境中部署则不切实际。小型VLMs尽管高效，但通常需要昂贵的微调才能缩小与大型模型之间的性能差距。受上下文学习框架的启发，研究提出了一种在线上下文蒸馏（ICD）方法，在此方法中，小型VLM在推理时与更强的教师模型合作，通过稀疏示范高效地吸收知识，以缩小两者之间的差距。研究团队通过细化分析，确定了当前视觉语言上下文学习（ICL）可行的模型规模和选择，并展示了在预算受限的计算资源下微调比ICL效果差的优势。
### Innovation
研究提出了一种在线上下文蒸馏（ICD）方法，通过小型VLM和更强教师模型在推理时的协作，利用稀疏示范高效传输知识，填补性能差距。这种方法还引入了一个跨模态示范选择策略，以及教师测试时缩放和学生不确定性条件机制，以优化示范池并减少教师查询次数。实验表明，ICD方法能够在少量教师注释（最低4%）的情况下显著提高小型模型的性能，甚至与教师的零样本性能相媲美，展示了其在低资源环境中的强大适应性与改进潜力。
### Conclusion
ICD方法在低资源和计算预算受限环境中显著提升了小模型的性能，展示了上下文蒸馏在视觉语言模型上的实际应用优势。
## 526. `cs.CV` - 将立体视觉从物体适应到月球表面3D重构——使用立体月球数据集 [PDF](https://arxiv.org/pdf/2510.18172), [HTML](https://arxiv.org/abs/2510.18172)
### Authors
Clementine Grethen,Simone Gasparini,Geraldine Morin,Jeremy Lebreton,Lucas Marti,Manuel Sanchez-Gestido
### Background
月球表面的3D重建对于太空探索至关重要，但现有的立体视觉重建方法在没有纹理、光照变化复杂、非典型轨道路径的情况下表现不佳。最先进的深度学习模型通常在人类尺度的数据集上进行训练，很少测试于行星图像，在月球条件下无法直接转移。
### Innovation
该研究首次提出了月球立体视图（LunarStereo）数据集，利用 ray tracing 模拟高分辨率地形和反射率模型生成逼真立体图像对。该数据集覆盖南极不同海拔、光照条件和视角，提供物理基础监督用于3D重建任务。基于此数据集，通过 fine-tuning MASt3R 模型对月球进行适应，验证了该方法在合成和真实月球数据上的效果，改善了零样本基线，为跨尺度在外行星环境中的泛化开辟了道路。
### Conclusion
通过与零样本基线的广泛定性和定量实验，该研究验证了方法的有效性，显著提升了月球表面3D重构和相对姿态估计的准确性，并指出了在月球等外行星环境中进行深度学习的新的适应途径。
## 527. `cs.CV` - RadDiagSeg-M：放射学中联合诊断和多目标分割的视觉语言模型 [PDF](https://arxiv.org/pdf/2510.18188), [HTML](https://arxiv.org/abs/2510.18188)
### Authors
Chengrun Li,Corentin Royer,Haozhe Luo,Bastian Wittmann,Xia Li,Ibrahim Hamamci,Sezgin Er,Anjany Sekuboyina,Bjoern Menze
### Background
目前的医疗视觉语言模型在面对复杂的视觉问题时，难以同时生成诊断文本和像素级别的分割掩码，这限制了这些模型在临床应用中的潜力。现有的辅助系统同时提供这两种信息对于医学专业人员来说价值较大，因此亟需解决此问题，以便开发出既能提供描述性文本又能生成相应的分割掩码的模型。
### Innovation
提出了RadDiagSeg-D数据集，这是一个结合异常检测、诊断和多目标分割的统一和层次化的任务，涵盖多种影像学模态，特别设计用于促进生成描述性文本和对应分割掩码的模型开发。此外，利用该数据集提出了新的视觉语言模型RadDiagSeg-M，能够实现联合异常检测、诊断和灵活分割，从而有效丰富辅助诊断的背景信息。
### Conclusion
通过基准测试，RadDiagSeg-M在多目标文本和掩码生成任务的各项指标上表现优异，建立了稳定而具有竞争力的基准线。
## 528. `cs.CV` - World-in-World：封闭环世界中的世界模型 [PDF](https://arxiv.org/pdf/2510.18135), [HTML](https://arxiv.org/abs/2510.18135)
### Authors
Jiahan Zhang,Muqing Jiang,Nanru Dai,Taiming Lu,Arda Uzunoglu,Shunchi Zhang,Yana Wei,Jiahao Wang,Vishal M. Patel,Paul Pu Liang,Daniel Khashabi,Cheng Peng,Rama Chellappa,Tianmin Shu,Alan Yuille,Yilun Du,Jieneng Chen
### Background
生成型世界模型（WMs）现在能够模拟具有惊人的视觉真实感的世界，自然而然地引发了是否能赋予有灵性的代理预测感知以进行决策的问题。然而，对于这一问题的进步已受到碎片化评估所限制：大多数现有基准采用了闭环协议，重点关注单独的视觉质量，而未能解决核心的有灵受益问题，即WMs实际上是否帮助代理完成有灵任务？为了解决这一缺口，作者引入了World-in-World，这是第一个开放平台，用于在模仿真实代理-环境交互的封闭环世界中评估WMs。World-in-World 提供了一个统一的在线规划策略和标准化的动作API，使得不同类型的WMs能够用于决策。该平台为观察四个封闭环环境，严格评估多样化的WMs，将任务成功率作为主要指标，并超越了对视觉质量的常见关注。
### Innovation
World-in-World 提供了一个新平台，通过闭环系统评估WMs的能力，相较于传统的开放环评估方法，它更能体现WMs的实际效用。它首次为有灵背景下提供统一的在线规划策略和标准化的动作API，以及第一个关于世界模型在有灵设置下的数据扩展定律。另外，研究揭示了三个令人惊讶的发现，指出单独的视觉质量不能保证任务的成功，控制能力更加重要；在训练后通过动作观察数据缩放比升级预训练的视频生成器更有效；分配更多推理时间计算可以让WMs显著提高闭环性能。
### Conclusion
我们的研究表明，仅凭视觉质量不能保证任务成功，控制能力更重要；在训练后通过动作观察数据缩放比升级预训练的视频生成器更有效；分配更多推理时间计算可以让WMs显著提高闭环性能。在封闭环背景下评估WMs是一个关键步骤，有助于理解WMs实际如何帮助代理完成具有挑战性的任务。
## 529. `cs.CV` - 审核和缓解性别分类算法中的偏差：一种以数据为中心的方法 [PDF](https://arxiv.org/pdf/2510.17873), [HTML](https://arxiv.org/abs/2510.17873)
### Authors
Tadesse K Bahiru,Natnael Tilahun Sinshaw,Teshager Hailemariam Moges,Dheeraj Kumar Singh
### Background
性别分类系统通常在其训练数据中继承并放大了性别和其他人口统计学特征之间的不平等问题。研究者对五个广泛使用的性别分类数据集进行审核，发现所有数据集在不同交集维度上都存在严重的代表性不足问题。为了衡量这些缺陷的下游影响，在两个最均衡的数据集上训练了相同的MobileNetV2分类器，结果显示即使这些分类器也存在显著的偏见，并且在误分类女性面孔方面表现出更高的比例，同时还在种族分布上加剧了现有的偏见。为对抗这类数据诱发的偏见，研究者构建了BalancedFace新数据集，该数据集通过将FairFace和UTKFace的图像结合，并补充其他集合中的图像以填补缺失的人口统计学空白，旨在均衡189个年龄、种族和性别交叉点上的子群体比例，仅使用真实、未编辑的图像。使用标准分类器在BalancedFace上进行训练，能够将跨种族子群体的最高真正阳性率差距减少超过50%，并将平均不同的影响分数与当前最优数据集相比，拉近了63%的距离，同时总体准确率仅轻微下降。
### Innovation
提出了一个新的公共数据集BalancedFace，该数据集通过结合FairFace和UTKFace的数据，并补充其他集合的图像，填补了人口统计学空白，旨在均衡189个年龄、种族和性别交叉点上的子群体比例，使用仅使用真实、未编辑的图像。使用标准分类器在BalancedFace上进行训练，能够显著减少偏见差距，同时保持较高的准确率。这种数据集的创建方法为公平性别分类研究提供了新的资源和途径，强调了数据导向干预的重要性。
### Conclusion
结果强调了以数据为中心的干预措施在减少性别分类算法偏见方面的重要性，并提供了一个公开可用的数据集资源，供公平性别分类研究使用。
## 530. `cs.CV` - VLSU: 映射联合多模态理解对AI安全的极限 [PDF](https://arxiv.org/pdf/2510.18214), [HTML](https://arxiv.org/abs/2510.18214)
### Authors
Shruti Palaskar,Leon Gatys,Mona Abdelrahman,Mar Jacobo,Larry Lindsey,Rutika Moharir,Gunnar Lund,Yang Xu,Navid Shiee,Jeffrey Bigham,Charles Maalouf,Joseph Yitan Cheng
### Background
现有对多模态基础模型的安全评估通常将视觉和语言输入分开处理，忽略了联合解释带来的风险，其中看似良性的内容组合后变得有害。现有方法未能明确区分开危险内容与边缘案例，导致过度封锁或对真正有害内容的拒绝不足。在这样一个背景下，该研究提出了一种综合框架VLSU，旨在通过精细的严重性分类和跨17种不同安全模式的组合分析，系统地评估多模态安全。
### Innovation
研究引入了VLSU框架，通过细粒度的严重性分类和组合分析来评估多模态安全。使用实际图像和人工注释的多阶段管道构建了包含8,187个样本的大规模基准，覆盖15个不同危害类别。研究发现，尽管模型在单一模态安全信号方面表现良好，但在需要联合图像-文本推理来确定标签时，性能显著下降。此外，模型难以在拒绝危险内容的同时应对应予以回应的边缘案例，从而导致过度封锁率和拒绝率的矛盾。
### Conclusion
研究揭示了多模态图像-文本理解的弱点，并指出了当前模型的对齐差距，提供了一个关键的测试床，以推动多模态安全研究的下一阶段。
## 531. `cs.CV` - EMA-SAM: 指数加权平均用于基于SAM的PTMC分割 [PDF](https://arxiv.org/pdf/2510.18213), [HTML](https://arxiv.org/abs/2510.18213)
### Authors
Maryam Dialameh,Hossein Rajabzadeh,Jung Suk Sim,Hyock Ju Kwon
### Background
纸张背景为： papillary甲状腺微癌（PTMC）越来越多地通过射频消融（RFA）来管理，但在超声视频中准确进行病灶分割仍然困难，原因包括对比度低、探头运动和热相关伪影。虽然最近的Segment Anything Model 2（SAM-2）在静态图像中表现良好，但在介入超声中，其帧独立的设计导致预测不稳和时间漂移。
### Innovation
本文介绍了一种轻量级的扩展版SAM-2模型，命名为EMA-SAM。该模型通过将置信加权的指数移动平均指针引入记忆库中，提供跨帧稳定的肿瘤潜原型。这种设计能保持探头压力和气泡遮挡下的时间连贯性，并在清晰证据重现时迅速适应。与SAM-2相比，EMA-SAM在我们的PTMC-RFA数据集上提高了maxDice（从0.82到0.86）和maxIoU（从0.72到0.76），同时将假阳性减少了29%。
### Conclusion
实验结果表明EMA-SAM能够作为鲁棒且高效的框架，实现稳定的肿瘤跟踪，填补了基础模型与介入超声严格需求之间的差距。此外，EMA指针的添加几乎不影响计算量，在单个A100 GPU上实现约30 FPS的实时吞吐量。
## 532. `cs.CV` - DeepSeek-OCR: 光学压缩中的上下文压缩 [PDF](https://arxiv.org/pdf/2510.18234), [HTML](https://arxiv.org/abs/2510.18234)
### Authors
Haoran Wei,Yaofeng Sun,Yukun Li
### Background
当前研究领域存在对压缩长时间序列中的上下文的需求，尤其是在处理历史文档等场景下。传统的光学字符识别（OCR）系统面临高分辨率输入下的激活保持问题，导致难以有效实现高效压缩。本文提出了一种名为DeepSeek-OCR的方法，通过光学2D映射技术优化压缩策略，针对Vision Tokens进行高效压缩，同时保持文档解析精度。
### Innovation
DeepSeek-OCR提出了两种核心技术组件：DeepEncoder和DeepSeek3B-MoE-A570M作为解码器。DeepEncoder旨在通过高分辨率输入保持低激活状态，同时实现高压缩比，确保Vision Tokens数量最优且可管理。实验结果显示，当文本Tokens数量为Vision Tokens的10倍以内时，能够实现97%的解码精度。即使在20倍压缩比的情况下，OCR准确率仍保持在60%左右。此外，DeepSeek-OCR在实际应用中表现出色，在OmniDocBench测试中比GOT-OCR2.0和MinerU2.0更优，同时使用更少的Vision Tokens。在生产环境中，DeepSeek-OCR每天可以生成超过20万页的训练数据。
### Conclusion
本研究展示了DeepSeek-OCR在压缩历史文档等场景中的可行性，尤其在历史长文压缩及大型语言模型（LLMs）中的记忆遗忘机制研究领域具有显著潜力。此外，DeepSeek-OCR在实际应用中表现出很高的实用性，特别是在Vision Tokens数量的使用上优于其他系统。
## 533. `cs.CV` - SafeCoop：揭示代理协作驾驶中的全栈安全 [PDF](https://arxiv.org/pdf/2510.18123), [HTML](https://arxiv.org/abs/2510.18123)
### Authors
Xiangbo Gao,Tzu-Hsiang Lin,Ruojing Song,Yuheng Wu,Kuan-Ru Huang,Zicheng Jin,Fangzhou Lin,Shinan Liu,Zhengzhong Tu
### Background
传统的V2X系统依赖于原始传感器数据、神经特征或感知结果进行通信，但这些方法面临着带宽需求高、语义信息丢失和互操作性差等持续挑战。近年来，自然语言被视为一种有潜力的通信媒介，能够提供丰富的语义信息、决策层面的推理能力，并且在较低带宽下实现人机互操作。然而，这种范式转变也引入了诸如信息丢失、幻觉、语义操控和恶意攻击等新的安全漏洞。因此，本研究旨在系统性地探讨基于自然语言协作驾驶中的全栈安全与安全问题，包括攻击策略、防御机制及其有效性验证等问题。
### Innovation
该研究首次系统地研究了基于自然语言的协作驾驶中的全栈安全与安全问题。开发了一套全面的攻击策略分类，包括连接中断、转发/重播干扰、内容篡改和跨连接伪造等。提出了网络安全防御管道SafeCoop，它结合了语义防火墙、语言-感知一致性检查和多源一致性验证，并通过代理转换函数实现跨帧空间对齐。此外，SafeCoop在闭合环CARLA仿真中对32个关键场景进行了系统性评估，证明了其在恶意攻击条件下的有效性。
### Conclusion
本研究为推进安全、可靠和可信赖的基于语言的交通系统协作研究提供了指导。SafeCoop框架在安全防御方面表现出色，不仅提升了在恶意攻击条件下的驾驶得分，还在恶意检测方面也取得了显著的F1分数。此研究为未来的相关研究设定了标准，并提供了宝贵的实验数据和构建模块。
## 534. `cs.CV` - OpenInsGaussian: 基于上下文感知跨视图融合的开放式词汇实例高斯分割 [PDF](https://arxiv.org/pdf/2510.18253), [HTML](https://arxiv.org/abs/2510.18253)
### Authors
Tianyu Huang,Runnan Chen,Dongting Hu,Fengming Huang,Mingming Gong,Tongliang Liu
### Background
理解3D场景对于自动驾驶、机器人技术和增强现实至关重要。现代基于语义的Gaussian Splatting方法利用大规模的2D视觉模型将2D语义特征投影到3D场景上，但它们存在两大局限性：(1) 在预处理中个体掩码中的上下文线索不足且(2) 多视角特征融合时存在不一致和缺失的细节。
### Innovation
我们提出了基于上下文感知跨视图融合的开放式词汇实例高斯分割框架OpenInsGaussian。该方法包括两个模块：上下文感知特征提取和注意力驱动特征聚合。前者通过添加丰富的语义上下文来增强每个掩码，后者则选择性地融合多视图特征以缓解对齐错误和不完整性。
### Conclusion
OpenInsGaussian在基准数据集上实现了开放式词汇3D高斯分割的最佳结果，显著超过了现有基准方法。这些发现强调了我们提出的这种方法的稳健性和通用性，标志着3D场景理解及其在各种实际场景中部署的重要进步。
## 535. `cs.CV` - 利用时空运动先验的双曲空间学习方法在视频中恢复人体网格 [PDF](https://arxiv.org/pdf/2510.18256), [HTML](https://arxiv.org/abs/2510.18256)
### Authors
Xiang Zhang,Suping Wu,Weibin Qiu,Zhaocheng Jin,Sheng Yang
### Background
现有的基于视频的人体网格恢复方法通常在欧几里得空间中学习网格特征，难以准确捕捉人体网格的自然层级结构（躯干-四肢-手指），导致恢复错误的人体网格。
### Innovation
提出了利用时空运动先验的双曲空间学习方法，该方法包括设计了一个时空运动特征提取模块，结合了从3D姿态序列和图像特征序列中提取的时空运动特征，增强了在时间运动维度上表达特征的能力。进一步设计了一种双曲空间优化学习策略，基于上述先验信息辅助学习，分别在双曲空间中使用3D姿态和姿态运动信息优化和学习网格特征，最终结合优化结果获得准确和光滑的人体网格。此外，提出了一种双曲空间网格优化损失，以保证优化学习过程的稳定和有效。
### Conclusion
在大型公开数据集上的广泛实验表明，该方法在人体网格恢复方面优于大多数最先进方法。
## 536. `cs.CV` - Latent-Info and Low-Dimensional Learning for Human Mesh Recovery and Parallel Optimization [PDF](https://arxiv.org/pdf/2510.18267), [HTML](https://arxiv.org/abs/2510.18267)
### Authors
Xiang Zhang,Suping Wu,Sheng Yang
### Background
现有的3D人体网格恢复方法往往未能充分利用潜在信息（如人类动作、形态对齐），导致肢体对齐错误和重建人体网格中局部细节不足的问题，特别是在复杂场景下更为明显。此外，利用注意力机制建模网格顶点和姿态节点之间的交互虽然可以提高性能，但会带来较高的计算成本。
### Innovation
提出了一种基于潜在信息和低维度学习的两阶段网络进行人体网格恢复，首先通过低频和高频图像特征提取全局和局部信息并合成出混合潜在频率域特征，利用这些特征增强2D姿态到3D学习，其次通过混合潜在特征优化粗糙的人体网格模板和3D姿态之间的交互学习，设计了一种低维并行优化算法，能够在不牺牲重建精度的情况下显著降低计算成本。
### Conclusion
在大型公开数据集上的广泛实验结果表明，该方法相比最先进的方法具有优越性。
## 537. `cs.CV` - BlendCLIP：利用多模态预训练缩小合成与现实领域差距以实现零样本3D对象分类 [PDF](https://arxiv.org/pdf/2510.18244), [HTML](https://arxiv.org/abs/2510.18244)
### Authors
Ajinkya Khoche,Gergő László Nagy,Maciej Wozniak,Thomas Gustafsson,Patric Jensfelt
### Background
零样本3D对象分类对于实际应用如自动驾驶至关重要，但合成数据与真实世界中稀疏、有噪声的LiDAR扫描之间存在显著的领域差距，导致现有仅在合成数据上训练的方法难以适应户外场景，而在真实数据上训练的方法则缺乏识别罕见或未见对象的语义多样性。BlendCLIP通过结合合成和现实领域的优势，提出了一种多模态预训练框架来解决这一问题。该框架首先通过从真实驾驶数据中提取并结合人工标注的3D框生成大规模的物体级三元组，包括点云、图像和文本描述，然后采用基于课程的学习数据混合策略，逐步将模型从语义丰富的合成CAD数据过渡到真实世界的扫描特点。实验结果显示，引入少量（1.5%）的真实世界样本，即可大幅提升nuScenes基准上的零样本准确性，最终模型在具有挑战性的户外数据集上达到了最先进的性能，相较于最佳的先前方法在nuScenes上的提升幅度为19.3%，且在多样性的合成基准测试中的泛化能力依然很强。这一研究揭示了有效的领域适应是实现具有开放词汇的稳健3D感知的关键，而非全面的现实世界标注。研究成果将在接受后发布代码和数据集。
### Innovation
BlendCLIP引入了一种多模态预训练框架，该框架通过战略性地结合合成数据和真实世界的优点来解决领域差距问题。其创新点在于首次提出了一种基于课程的学习数据混合策略，该策略首先将模型定位在丰富的合成CAD数据上，然后逐步适应现实世界的扫描特征。此外，通过从真实驾驶数据中生成大规模的物体级三元组，包括点云、图像和文本描述，从而提高模型的鲁棒性和泛化能力。
### Conclusion
最终模型在具有挑战性的户外数据集上达到了最先进的性能，相较于最佳的先前方法在nuScenes上的提升幅度为19.3%，同时在多样性的合成基准测试中的泛化能力依然很强。这一研究揭示了有效的领域适应是实现具有开放词汇的稳健3D感知的关键，而非全面的现实世界标注。
## 538. `cs.CV` - TreeFedDG：缓解联邦领域泛化中医学图像分割的全局漂移 [PDF](https://arxiv.org/pdf/2510.18268), [HTML](https://arxiv.org/abs/2510.18268)
### Authors
Yucheng Song,Chenxi Li,Haokang Ding,Zhining Liao,Zhifang Liao
### Background
在医学图像分割任务中，联邦学习（FL）框架下的领域泛化（DG）对于解决隐私保护和数据异质性带来的挑战至关重要。然而，传统的联邦学习方法未能考虑到跨域场景中客户端之间信息聚合的不平衡问题，导致全局漂移（GD）问题，并且模型的泛化性能下降。本文旨在深入研究并定义一个新的关键问题：联邦领域泛化中医学影像的全局漂移（FedDG-GD）问题。
### Innovation
本文提出了一个全新的树状拓扑框架——TreeFedDG。首先，基于医学图像的分布式特性，设计了一种基于树状拓扑的层次化参数聚合方法，以抑制全局模型方向的偏差。其次，引入了一种基于参数差异的风格混合方法（FedStyle）来增强对漂移的鲁棒性，确保在模型分发过程中平衡知识传递和个人特征。最后，在推理阶段，使用特征相似性来指导从树结构中检索最相关的模型链，进行集成决策，充分挖掘层次知识的优点。
### Conclusion
我们在两个公开可用的数据集上进行了广泛的实验。结果表明，我们的方法在这些具有挑战性的任务中优于其他最先进的领域泛化方法，并且实现了更好的跨域性能平衡。
## 539. `cs.CV` - UWBench: 一种全面的海洋视觉语言基准 [PDF](https://arxiv.org/pdf/2510.18262), [HTML](https://arxiv.org/abs/2510.18262)
### Authors
Da Zhang,Chenggang Rong,Bingyu Li,Feiyu Wang,Zhiyuan Zhao,Junyu Gao,Xuelong Li
### Background
大型视觉语言模型（VLMs）在自然环境的理解中取得了显著的成果，但在水下环境中的应用却仍然相对未被探索。水下图像面临着严重的光源衰减、色彩失真和悬浮颗粒散射的独特挑战，同时还需要对海底生态系统和生物分类的专业知识。为了填补这一空白，我们引入了UWBench，一个专门针对水下视觉语言理解的综合基准。UWBench包括15,003张高分辨率的水下图像，涵盖了海洋、珊瑚礁和深海等多样化的水下环境。每张图像都附有人工验证的注释，包括15,281个物体指代表达式，可以精确描述海洋生物和水下结构，以及124,983对问题-答案组合，涵盖了从物体识别到生态关系理解的多种推理能力。数据集捕捉了大量的视见度、光照条件和水体浑浊的变化，为模型评估提供了真实的实验平台。
### Innovation
我们建立了一个专门针对水下视觉语言理解的综合基准UWBench，包含15,003张高分辨率的水下图像和详细的注释，覆盖了从物体识别到生态关系理解的多种推理能力。基于UWBench，我们设置了详细的图像描述、视觉定位和视觉问答三个综合基准，检验了最新VLMs在水下理解方面的成效。我们的研究结果表明，水下理解仍然是一个具有挑战性的领域，需要进一步改进。UWBench为水下视觉语言研究提供了宝贵的资源，并对该领域的发展具有重要意义。
### Conclusion
我们的研究为水下情境中的视觉语言研究提供了重要基准，有助于推动该领域的发展，支持海洋科学、生态监测和自主水下探索的应用。我们的代码和基准将公开提供。
## 540. `cs.CV` - StreamingTOM：高效视频理解中的流式_token_压缩 [PDF](https://arxiv.org/pdf/2510.18269), [HTML](https://arxiv.org/abs/2510.18269)
### Authors
Xueyi Chen,Keda Tao,Kele Shao,Huan Wang
### Background
与传统的离线处理相比，流式视频视觉语言模型面临两个根本性约束：因果性和累积性。因果性阻止了访问自回归模型使用的未来帧，而累积性使得令牌数量无限制地增长，从而造成了效率瓶颈。然而，现有的方法仅对后LLM的kv-cache进行调节，而未改变成本较高的预填充（prefill）过程。
### Innovation
作者引入了StreamingTOM，这是一种无需训练的、插即用的两阶段框架，该框架能够同时解决预LLM和后LLM的瓶颈问题，并且具有可预测的延迟。Causal Temporal Reduction对每帧设置一个固定预算，并基于相邻帧的变化和令牌显著性选择令牌，大幅减少了每帧的预填充成本。Online Quantized Memory将令牌存储为4位格式，在需要时检索相关组并进行反量化处理，使主动kv-cache始终保持在预定范围内，无论流式传输的长度如何。实验结果表明，与之前最先进的方法相比，该方法实现了15.7倍的kv-cache压缩，1.2倍的更低峰值内存和2倍的更快TTFT。StreamingTOM在无需训练的方法中保持了最先进的准确性，平均在线下基准测试中的得分是63.8%，而在RVS中的得分为55.8%/3.7%。这些结果突显了我们两阶段方法的实际优势，可以有效实现带有限增长的流式视频理解。
### Conclusion
实验结果证明了StreamingTOM在压缩kv-cache、降低内存峰值使用和加速TTFT方面的优势，并且在保持低功耗的同时获得了较高的准确性，体现了其在高效流式视频理解中的实用价值。
## 541. `cs.CV` - GeoDiff: 几何引导的扩散模型用于度量深度估计 [PDF](https://arxiv.org/pdf/2510.18291), [HTML](https://arxiv.org/abs/2510.18291)
### Authors
Tuan Pham,Thanh-Tung Le,Xiaohui Xie,Stephan Mandt
### Background
现有的单目深度估计（DB-MDE）方法在预测相对深度方面表现出色，但在单图像场景中，由于尺度歧义，估计绝对度量深度仍然具有挑战性。目前的方法难以解决这一问题，特别是在处理透明和镜面表面时更为困难。
### Innovation
本文介绍了一种新的框架，通过将单目深度估计与立体视觉引导相结合，增强预训练的扩散模型，将深度估计重新定义为一个逆问题，利用预训练的潜在扩散模型（LDMs）在RGB图像条件下，结合基于立体的几何约束，学习尺度和偏移量以实现准确的深度恢复。该方法无需重新训练，可以无缝集成到现有的DB-MDE框架中，适用于室内、室外和复杂环境。实验结果表明，在处理透明和镜面表面等具有挑战性的场景时，该方法在准确性和效率上达到了或超过了最新的先进方法，且无需重新训练模型。
### Conclusion
我们的方法在具有挑战性的深度估计场景中展示了卓越性能，并且可以无缝集成到现有的DB-MDE框架中，适用于多种环境。
## 542. `cs.CV` - 图像分辨率对生物医学多模态大型语言模型的影响 [PDF](https://arxiv.org/pdf/2510.18304), [HTML](https://arxiv.org/abs/2510.18304)
### Authors
Liangyu Chen,James Burgess,Jeffrey J Nirschl,Orr Zohar,Serena Yeung-Levy
### Background
医学成像技术在生物医学研究和现代医学中至关重要，需要对不同模态的高分辨率图像进行分析。目前大多数多模态大型语言模型（MLLMs）主要针对一般用途数据集中的低分辨率图像进行设计，可能导致关键信息的丢失。因此，研究者们开始关注图像分辨率如何影响MLLMs在生物医学应用中的性能。
### Innovation
研究发现：（1）使用原生分辨率进行训练和推理，可以显著提升多种任务的性能；（2）训练和推理分辨率不匹配会严重降低性能；（3）混合分辨率训练能够有效缓解分辨率不匹配的情况，平衡计算限制与性能需求。基于以上发现，建议优先使用原生分辨率进行推理和混合分辨率数据集来优化生物医学中的MLLMs，以实现科学研究和临床应用的突破性影响。
### Conclusion
研究强调了图像分辨率对生物医学MLLMs性能的影响，建议在生物医学研究和临床应用中优先使用原生分辨率进行推理，并利用混合分辨率训练数据集来平衡计算效率与性能。
## 543. `cs.CV` - ViSE: 仅视觉的道路视图外推系统方法 [PDF](https://arxiv.org/pdf/2510.18341), [HTML](https://arxiv.org/abs/2510.18341)
### Authors
Kaiyuan Tan,Yingying Shen,Haiyang Sun,Bing Wang,Guang Chen,Hangjun Ye
### Background
在自动驾驶封闭环仿真中，准确的视图外推至关重要，但目前的新型视图合成（NVS）方法常常因为图像失真和不一致性，无法解决此挑战。
### Innovation
该报告介绍了一种四阶段的综合管道，包括数据驱动的初始化策略生成鲁棒的伪LiDAR点云，通过新型二维几何距离场（2D-SDF）建模道路表面提供几何先验，利用生成模型为外推视点生成伪地面真值，并采用数据驱动的适应网络移除时间特定的伪影。
### Conclusion
在RealADSim-NVS基准测试中，该方法最终得分为0.441，所有参赛者中排名第一。
## 544. `cs.CV` - 医学多模态大型语言模型的前瞻性推理与检索框架 [PDF](https://arxiv.org/pdf/2510.18303), [HTML](https://arxiv.org/abs/2510.18303)
### Authors
Lehan Wang,Yi Qin,Honglong Yang,Xiaomeng Li
### Background
在医学应用中，增强多模态大语言模型（MLLMs）的推理能力对于透明地分析医学图像并提供可靠的诊断至关重要。然而，现有的医学大语言模型在其推理过程中仅依赖内部知识，这导致了在超出训练范围的情况下推理的幻觉和事实的不准确。尽管最近的代理检索增强生成（RAG）方法能够激发模型在推理过程中的主动检索能力，但它们局限于单模态大语言模型，忽略了推理和检索过程中的关键视觉信息。因此，我们提出了首个结合检索的多模态医学推理框架（Med-RwR），该框架在推理过程中通过查询观察到的症状或特定医学概念来主动检索外部知识。我们的研究结果显示，这种方式显著提高了模型的推理能力，尤其是在集成外部知识方面。此外，Med-RwR 在不熟悉的领域中也表现出强烈的泛化能力，即使在训练数据中缺少心脏超声图像的情况下，也取得了令人印象深刻的效果。
### Innovation
我们提出了第一个结合检索的多模态医学推理框架（Med-RwR），该框架在推理过程中通过查询观察到的症状或特定医学概念来主动检索外部知识。同时，我们设计了一种具有针对性奖励的双阶段强化学习策略，以激发模型同时利用视觉诊断发现和文本临床信息进行有效的检索。此外，我们还提出了一种基于置信度驱动的图像重新检索方法（CDIR），以在测试时扩大模型的规模，特别是在预测置信度较低的情况下。我们通过多种公开的医学基准测试结果验证了Med-RwR的有效性和泛化性能。
### Conclusion
我们在多种公开的医学基准测试中证明了Med-RwR在增强推理能力方面的显著改进，特别是在结合外部知识方面。Med-RwR展示了在不熟悉的领域中令人印象深刻的效果，例如在我们提出的回声心图基准测试（ECBench）中，尽管在训练语料中缺乏心脏超声数据，但仍取得了8.8%的性能提升。我们的数据、模型和代码将公开发布。
## 545. `cs.CV` - 高效少量样本身份保持属性编辑的3D感知深度生成模型 [PDF](https://arxiv.org/pdf/2510.18287), [HTML](https://arxiv.org/abs/2510.18287)
### Authors
Vishal Vinod
### Background
身份保持的面部编辑是一个生成任务，允许在保留面部身份的同时修改光照、添加/移除眼镜、面部老化、编辑发型和修改表情等。近年来，2D生成模型的进步使通过GAN的组成性利用简单技术实现面部的逼真编辑成为可能。然而，对于给定属性的3D面部，保持身份的编辑是一项具有挑战性的任务，因为生成模型必须从多个视角理解视图一致性并渲染逼真的3D面部。进一步地，3D肖像编辑需要大规模属性标注数据集，并且在低分辨率的可编辑性与高分辨率的灵活性之间存在权衡。因此，本研究旨在通过识别与光现实编辑相对应的潜在空间方向来缓解3D面部编辑的一些限制。
### Innovation
本文提出了一种方法，结合3D感知深度生成模型和2D肖像编辑技术的最新成果，以实现高效的少量样本身份保持属性编辑。研究表明，只需十张或更少的带有标签的属性示例，即可在潜在空间中估计出与3D感知属性编辑相对应的编辑方向。此外，通过进行连续编辑和研究（2D）属性风格转换（ASM）技术来探索3D一致的身份保持面部老化的一致连续样式流形，进一步验证编辑的线性度。
### Conclusion
本文通过利用面部带有掩模的现有数据集，获得了用于估算编辑方向的合成图像。实验结果显示，在潜在空间中估计出的编辑方向可以有效地实现3D感知属性编辑。此外，提出的方法在保持面部身份的同时改进了风格的一致性。相关代码和实验结果可以在指定链接处获取。
## 546. `cs.CV` - OmniNWM: 全知驾驶导航世界模型 [PDF](https://arxiv.org/pdf/2510.18313), [HTML](https://arxiv.org/abs/2510.18313)
### Authors
Bohan Li,Zhuang Ma,Dalong Du,Baorui Peng,Zhujin Liang,Zhenqiang Liu,Chao Ma,Yueming Jin,Hao Zhao,Wenjun Zeng,Xin Jin
### Background
现有的自动驾驶世界模型在状态、动作和奖励三个核心维度上通常存在限制：状态模态有限、视频序列较短、动作控制不精确以及缺乏对奖励的认知。因此，需要一种能够在这些维度上统一解决这些问题的模型。
### Innovation
我们提出了一种名为 OmniNWM 的全知全景导航世界模型，它在统一框架内解决了状态、动作和奖励这三个核心维度的问题。OmniNWM 联合生成 RGB、语义、度量深度和 3D 占有率的全景视频，并通过灵活的强制策略实现了高质量的长时序自回归生成。OmniNWM 还引入了一种规范化全景 Plucker 射线图表示，将输入轨迹编码成像素级信号，从而实现对全景视频生成的高度精确和泛化控制。对于奖励，OmniNWM 利用生成的 3D 占有率直接定义规则密集的奖励，以确保驾驶合规性和安全性。
### Conclusion
广泛的实验表明，OmniNWM 在视频生成、控制准确性和长时序稳定性方面达到了最先进的性能，并通过基于占据的奖励提供了一个可靠的闭环评估框架。
## 547. `cs.CV` - 超越单一模型：通过自适应标记组合解码缓解多模态幻觉 [PDF](https://arxiv.org/pdf/2510.18321), [HTML](https://arxiv.org/abs/2510.18321)
### Authors
Jinlin Li,Yuran Wang,Yifei Yuan,Xiao Zhou,Yingying Zhang,Xixian Yong,Yefeng Zheng,Xian Wu
### Background
大型视觉-语言模型（LVLMs）在诸如图像描述和视觉问答等多模态任务中取得了显著成果。然而，它们仍然容易出现对象幻觉现象，即生成不存在或误识别的对象的描述。先前的研究虽然通过辅助训练目标或外部模块部分缓解了这一问题，但在可扩展性、适应性和模型独立性方面仍然存在挑战。
### Innovation
我们提出了一种无需训练的自适应标记组合解码（ATED）框架，它通过聚合多个LVLMs在推理过程中的预测来缓解幻觉。ATED动态地为每个模型计算基于不确定性的权重，反映它们在每个解码步骤中的可靠性。它还结合了多种解码路径，以提高语境关联性和语义一致性。该方法在标准幻觉检测基准测试中显著优于现有最先进的方法，减少了幻觉的同时保持了流畅性和相关性。
### Conclusion
我们的研究结果突显了自适应组合的优势，并为提高高风险应用场景中LVLM的稳健性指出了一个有希望的方向。
## 548. `cs.CV` - Blueprint-Prompted图像合成驱动的分数驱动去偏见：超越频率的对象检测去偏 [PDF](https://arxiv.org/pdf/2510.18229), [HTML](https://arxiv.org/abs/2510.18229)
### Authors
Xinhao Cai,Liulei Li,Gensheng Pei,Tao Chen,Jinshan Pan,Yazhou Yao,Wenguan Wang
### Background
现有的去偏见方法通常受限于样本表示的多样性，而简单的生成增强往往保留了其试图解决的偏差。此外，我们的分析表明，仅仅为罕见类别生成更多数据不理想，因为存在两大核心问题：首先，实例频率是模型真正数据需求的一个不完全代表；其次，现有的布局到图像合成缺乏生成高质量、复杂场景所需的精准度和可控性。因此需要一种能够超越简单基于频率的方法来填补表示间隙，同时确保高质量的合成效果。
### Innovation
本文提出了一种基于生成的去偏见框架，引入了表示得分（RS）来诊断超越频率的表示差距，以指导生成新的无偏布局。同时，用明确的视觉蓝图替换模糊的文字提示，并采用生成对齐策略，在检测器和生成器之间促进沟通，从而确保高质量的合成效果。这种方法显著减少了代表性不足的对象组的表现差距，例如，在罕见大实例上提高了4.4/3.6的mAP，并在生成图像的布局准确性上比之前的L2I合成模型高15.9 mAP。
### Conclusion
本方法显著减少了代表性不足的对象组的表现差距，特别是针对罕见的大实例，提升了4.4/3.6 mAP，并且在生成图像的布局准确性方面超越了之前的L2I合成模型，最高提升了15.9 mAP。
## 549. `cs.CV` - GPTFace：基于区间掩码和弱相关图文数据的面部语言变压器的生成预训练 [PDF](https://arxiv.org/pdf/2510.18345), [HTML](https://arxiv.org/abs/2510.18345)
### Authors
Yudong Li,Hao Li,Xianxu Hou,Linlin Shen
### Background
尽管自然图像理解领域的预训练模型取得了繁荣发展，但在面部知识学习方面的大规模预训练模型研究仍然非常有限。目前的方法主要依赖于手动组装和标注的面部数据集进行训练，但标注这些数据集的工作量巨大，而训练的模型也难以在训练数据之外进行扩展。因此，为了解决这些问题，作者提出了一种生成预训练模型来学习面部知识。该模型利用互联网上构建的大量数据进行训练。从中抽取包含人类面部的文本和图片，并用于自监督任务的预训练，包括带掩码的图像/语言建模（MILM）和图文匹配（ITM）。
### Innovation
该研究提出了一种基于生成预训练模型的方法，用于面部知识学习。该模型利用互联网上构建的大量数据进行训练，包括文本和图片，用于自监督任务的预训练。为了控制生成，还利用了图文匹配损失。实验表明，该模型在多种面部下游任务（如属性分类和表情识别）上达到了与当前最佳预训练模型相当的效果，并且该方法也适用于各种面部编辑任务，如面部特征编辑、表情操纵、遮罩去除和照片修补。
### Conclusion
实验结果显示，GPTFace模型在多种面部下游任务上与当前最优预训练模型相当，并且该方法也适用于各种面部编辑任务，展示了在大规模面部数据上进行预训练的可行性与优势。
## 550. `cs.CV` - 基于排名的隐式用户反馈下扩散模型偏好优化方法 [PDF](https://arxiv.org/pdf/2510.18353), [HTML](https://arxiv.org/abs/2510.18353)
### Authors
Yi-Lun Wu,Bo-Kai Ruan,Chiang Tseng,Hong-Han Shuai
### Background
直接偏好优化（DPO）方法通过配对比较进行训练，在调整文本到图像的扩散模型与人类偏好时显示出强大的潜力。然而，这些方法在训练稳定性方面有改进，但仍然面临着由于Sigmoid函数的非线性特性以及离线数据集的有限多样性所带来的准确估计图像概率的挑战。
### Innovation
引入了扩散去噪排名优化（Diffusion-DRO），一种基于逆强化学习的新偏好学习框架。Diffusion-DRO通过将偏好学习转化为一个排名问题，去除了对奖励模型的依赖性，将训练目标简化为一个去噪形式，并克服了先前方法中的非线性估计问题。此外，Diffusion-DRO独特地将离线专家示例与在线策略生成的负面样本集成起来，有效地捕捉到了人类偏好并解决了离线数据的局限性。
### Conclusion
全面实验表明，Diffusion-DRO在一系列具有挑战性和未见过的提示下提供了改进的生成质量，优于最新 baseline，无论是量化指标还是用户研究中都表现得更好。我们提供了源代码和预训练模型，链接为this https URL。
## 551. `cs.CV` - 使用ATTBHFA-Net提升基准和灾难图像的少样本分类 [PDF](https://arxiv.org/pdf/2510.18326), [HTML](https://arxiv.org/abs/2510.18326)
### Authors
Gao Yu Lee,Tanmoy Dam,Md Meftahul Ferdaus,Daniel Puiu Poenar,Vu Duong
### Background
随着自然灾害和人为灾害频率的增加，需要先进的视觉识别技术来分析关键的影像数据。人工智能和坚固的计算系统的发展使得快速和准确的灾害分类变得至关重要，这对于高效的救援行动来说至关重要。然而，灾害视觉识别面临着由收集和整理全面高质量的灾害图像数据的困难所引起的挑战，表现为数据量少和多样性高。现有的少样本学习（FSL）主要依赖于缺乏遥感灾害图像的通用基准数据集，这限制了其实用效果。此外，灾害图像表现出高类内变异性与高类间相似性，这使得基于度量的标准FSL方法的效果受到限制。
### Innovation
为了解决以上问题，本文提出了一种基于注意力的布特卡坦尼亚-HELLINGER特征聚合网络（ATTBHFA-Net），利用布特卡坦尼亚系数和HELLINGER距离线性组合特征概率分布，以实现稳健的原型形成。布特卡坦尼亚系数作为对比性间隔，增强了类间可分性，而HELLINGER距离则规范了同一类的对齐。该框架类似于对比学习，但操作的是概率分布而不是嵌入特征点。此外，本文提出了一种基于布特卡坦尼亚-HELLINGER距离的对比损失，作为余弦相似度损失的分布对应物，并与类别交叉熵联合使用，显著改善了FSL性能。实验结果表明，ATTBHFA-Net在四个FSL基准和两个灾难图像数据集上优于现有方法，展现了其优越的效用和泛化能力。
### Conclusion
本文提出的ATTBHFA-Net在解决少样本学习中的数据稀缺和灾难图像的高变异性问题方面表现出了明显的优越性和泛化能力。该方法为改进灾难类视觉识别技术开辟了新的途径，有望提升灾害响应效能。
## 552. `cs.CV` - FeatureFool：通过特征图零查询欺骗视频模型 [PDF](https://arxiv.org/pdf/2510.18362), [HTML](https://arxiv.org/abs/2510.18362)
### Authors
Duoxun Tang,Xi Xiao,Guangwu Hu,Kangkang Sun,Xiao Yang,Dongyang Chen,Qing Li,Yongjie Yin,Jiyao Wang
### Background
深度神经网络（DNNs）的脆弱性已被初步验证，现有的黑盒对抗攻击通常需要多次与模型互动，并消耗大量查询量，这在实际场景中是不切实际的，并且难以扩展到最近出现的Video-LLMs。此外，目前没有直接利用特征图将干净视频特征空间改移的视频域攻击方法。
### Innovation
提出了FeatureFool，一种不依赖查询的，视频域黑盒零查询攻击方法，利用从DNN中提取的信息来改变干净视频的特征空间。这种有效的方法在视频域中前所未有。实验表明，FeatureFool在不使用查询的情况下对传统视频分类器的攻击成功率超过70%。由于特征图的可移植性，它还能制作有害内容并绕过Video-LLM的识别。此外，由FeatureFool生成的对抗视频在SSIM、PSNR和时序一致性上表现出高质量，使其几乎察觉不到。
### Conclusion
FeatureFool能够在不使用查询的情况下，有效地改变视频的特征空间，生成不易被察觉的对抗视频，对Video-LLM具有极大的威胁。
## 553. `cs.CV` - 基于Ricci流的熵增强共形特征在稳健阿尔茨海默病分类中的应用 [PDF](https://arxiv.org/pdf/2510.18396), [HTML](https://arxiv.org/abs/2510.18396)
### Authors
F.Ahmadi,B.Bidabad,H.Nasiri
### Background
在脑成像分析中，几何表面模型对于分析神经解剖结构的三维形状至关重要。阿尔茨海默病（AD）与显著的皮质萎缩相关，因此这种形状分析成为一种有价值的诊断工具。本研究旨在介绍一种新的局部表面表示方法，以实现AD的自动和准确诊断。
### Innovation
本研究采用了从拉普拉斯-贝尔特拉米流中提取的共形特征的熵作为皮质形态的度量指标，并利用机器学习方法将其应用于AD的诊断，特别是使用多层感知机和逻辑回归分类器取得98.62%的高准确性。
### Conclusion
本研究证实，利用共形特征的熵可以作为皮质形态的强大且稳健的度量标准。高分类准确性的结果表明该方法有潜力增强AD的研究和诊断，并为临床研究提供了简单而强大的工具。
## 554. `cs.CV` - 学习人类-物体交互作为一种群体 [PDF](https://arxiv.org/pdf/2510.18357), [HTML](https://arxiv.org/abs/2510.18357)
### Authors
Jiajun Hong,Jianan Wei,Wenguan Wang
### Background
HOI-DET旨在定位人类-物体对并识别它们的互动关系。现有方法通过自注意力机制或二分图中的信息传递来聚合背景线索，但它们主要关注两两之间的关系，而忽略了现实场景中互动常常由集体行为（多个人和物体参与联合活动）引发的情况。
### Innovation
本文从群体视角重新审视了关系建模，并提出了GroupHOI框架，该框架根据几何邻近性和语义相似性来传播背景信息。通过可学习的邻近估计器对基于边界框获取的空间特征来进行人类和物体的分组，并使用自注意力计算每个组内的软对应关系以聚合和分配背景线索。此外，增强基础的Transformer解码器以便将局部背景线索纳入对HO对特征的语义相似性的考虑中，从而在不同的基准上展示了优于最新方法的性能，尤其是在更具挑战性的非言语互动检测任务中表现出优越性，该任务涉及组内多种形式的高级别互动。
### Conclusion
GroupHOI在HICO-DET和V-COCO基准上的广泛实验中展示了其优越性，并在更具有挑战性的NVI-DET任务中表现突出，说明了它在高层交互理解方面的有效性。
## 555. `cs.CV` - S2AP：分数空间中的极大抖动最小化以增强对抗修剪 [PDF](https://arxiv.org/pdf/2510.18381), [HTML](https://arxiv.org/abs/2510.18381)
### Authors
Giorgio Piras,Qi Zhao,Fabio Brau,Maura Pintor,Christian Wressnegger,Battista Biggio
### Background
对抗修剪方法已经成为了压缩神经网络同时保持对对抗攻击鲁棒性的强大工具。目前对抗修剪方法通常遵循三个步骤的流水线：（i）预训练鲁棒模型，（ii）选择权重修剪的二进制掩码，（iii）微调修剪后的模型。在选择二进制掩码时，这些方法通过赋予每个权重重要性分数并最小化鲁棒损失来优化重要的分数，然后保留分数最高的权重。然而，这种分数空间优化可能会在鲁棒损失景观中导致尖锐的局部极小值，从而导致掩码选择不稳定，降低对抗修剪方法的鲁棒性。
### Innovation
提出了一种新颖的插件方法——分数空间鲁棒性感知对抗修剪（Score-space Sharpness-aware Adversarial Pruning，S2AP）——通过在掩码搜索过程中扰动重要性分数并最小化相应的鲁棒损失来引入分数空间抖动最小化概念。研究表明，S2AP能有效地在分数空间中最小化抖动，稳定掩码选择，并最终提高对抗修剪方法的鲁棒性。
### Conclusion
通过广泛的实验验证了S2AP在不同数据集、模型和稀疏级别上的有效性，成功地实现了分数空间抖动的最小化，稳定了掩码选择，并增强对抗修剪方法的鲁棒性。
## 556. `cs.CV` - Cross-Modal Scene Semantic Alignment for Image Complexity Assessment [PDF](https://arxiv.org/pdf/2510.18377), [HTML](https://arxiv.org/abs/2510.18377)
### Authors
Yuqing Luo,Yixiao Li,Jiang Liu,Jun Fu,Hadi Amirpour,Guanghui Yue,Baoquan Zhao,Padraig Corcoran,Hantao Liu,Wei Zhou
### Background
感知评价中的图像复杂性评估（ICA）因人类感知的主观性及现实世界图像固有的语义多样性而极具挑战性。现有的ICA方法主要依赖单一视觉模态的手工特征或浅层卷积神经网络特征，难以充分捕捉与图像复杂性紧密相关的感知表示。近年来，跨模态场景语义信息在各种计算机视觉任务中，特别是在涉及感知理解的任务中显示出关键作用。但是，关于跨模态场景语义信息在ICA中的应用尚未进行探索研究。因此，本文提出了一种新的ICA方法，称为跨模态场景语义对齐（CM-SSA），利用跨模态的场景语义对齐来增强ICA性能，使复杂性预测更符合主观的人类感知。
### Innovation
提出的CM-SSA算法引入了跨模态场景语义对齐，该方法同时包含复杂性回归分支和场景语义对齐分支。复杂性回归分支在场景语义对齐分支的指导下估计图像复杂性级别，场景语义对齐分支通过成对学习对齐图像与包含丰富场景语义信息的对应文本提示。实验结果表明，相较于现有最先进的方法，提出的CM-SSA方法具有显著优势，并且提供了可访问的代码链接。
### Conclusion
本文提出了一种新的跨模态场景语义对齐方法（CM-SSA），该方法通过跨模态的场景语义对齐来提高图像复杂性评估性能，实验结果表明在几个ICA数据集上的性能超过了现有最先进的方法。
## 557. `cs.CV` - 贝叶斯全连接张量网络方法用于高光谱-多光谱图像融合 [PDF](https://arxiv.org/pdf/2510.18400), [HTML](https://arxiv.org/abs/2510.18400)
### Authors
Linsong Shan,Zecan Yang,Laurence T. Yang,Changlong Li,Honglu Zhao,Xin Nie
### Background
张量分解是一种强大的数据分析工具，广泛应用于高光谱-多光谱图像融合（HMF）领域。现有基于张量分解的融合方法通常依赖于破坏性的数据矢量化/重塑或对因子张量排列施加刚性约束，这阻碍了空间-光谱结构的保持和跨维度相关性的建模。虽然最近利用全连接张量网络（FCTN）分解的方法部分缓解了这些问题，但仍然存在重组数据成高阶张量的过程破坏了固有的空间-光谱结构。此外，这些方法需要大量的手动参数调优，并且对噪声和空间退化具有有限的鲁棒性。因此，上述问题亟需解决。
### Innovation
提出了一种贝叶斯全连接张量网络（BFCTN）方法。通过贝叶斯概率框架，建立了一种描述物理元素稀疏性的分层稀疏先验，该先验将因子张量之间的联系直接建模。此框架公开了空间结构、光谱特征和局部场景均匀性之间的内在物理耦合。为了学习模型，开发了一种基于变分贝叶斯推断（VB）和期望最大化（EM）算法的参数估计方法，大大减少了手动参数调优的需求。实验结果表明，BFCTN不仅在融合精度和鲁棒性方面达到了最先进的技术水平，也在复杂的现实世界场景中具有实际应用价值。
### Conclusion
BFCTN方法不仅实现了最先进的融合准确性和强大的鲁棒性，还能够在复杂的现实世界场景中表现出实际应用性。
## 558. `cs.CV` - AV-Master：双路径综合感知做出更好的音频视觉问题解答 [PDF](https://arxiv.org/pdf/2510.18346), [HTML](https://arxiv.org/abs/2510.18346)
### Authors
Jiayu Zhang,Qilang Ye,Shuo Ye,Xun Lin,Zihan Song,Zitong Yu
### Background
AVQA要求模型有效利用视音频两种模态来回答视听场景中的复杂多样的问题。然而现有方法在时间采样和模态偏好意识方面缺乏足够的灵活性和动态适应性，难以根据问题聚焦于关键信息，这限制了它们在复杂场景下的推理能力。
### Innovation
提出了一个新的框架AV-Master。通过动态建模时间和模态维度，增强模型从复杂视听场景中提取关键信息的能力。在时间维度上，引入了动态自适应焦点采样机制，逐句聚焦于与问题最相关的音频视觉段落，有效缓解传统采样方法中的冗余和片段化问题。在模态维度上，提出了偏好意识策略，独立建模每个模态的贡献，实现了关键特征的选择性激活。此外，引入了双路径对比损失，增强了时间和模态维度的连贯性和互补性，指导模型学习问题特定的跨模态协作表示。
### Conclusion
在四个大规模基准上的实验表明，AV-Master在复杂推理任务中显著优于现有方法，特别是在复杂推理任务中表现更为出色。
## 559. `cs.CV` - 使用OCR导向YOLOv8和轨迹建模在板球视频中自动识别关键击球和检测击球弱点 [PDF](https://arxiv.org/pdf/2510.18405), [HTML](https://arxiv.org/abs/2510.18405)
### Authors
Mst Jannatun Ferdous,Masum Billah,Joy Karmoker,Mohd Ruhul Ameen,Akif Islam,Md. Omar Faruqe
### Background
当前存在对板球视频分析的自动化需求，需要能够自动识别关键击球并检测击球弱点的技术。
### Innovation
该系统利用深度学习技术自动识别关键击球，采用YOLOv8架构进行球场和球的检测，并通过光学字符识别（OCR）提取得分卡信息，实现视频帧中文本的稳健提取。通过灰度变换、幂变换和形态学操作进行图像预处理，提高了系统的鲁棒性。实验结果表明，该方法在多个板球比赛视频中表现出显著的有效性，为教练和战略决策提供了数据驱动的洞察。
### Conclusion
该研究提出了一种自动化的板球视频分析系统，通过深度学习技术和OCR引导的YOLOv8以及轨迹建模方法有效识别关键击球和检测击球弱点，为板球比赛的自动化分析提供了可能，对教练和战术决策有重要价值。
## 560. `cs.CV` - 超越单一图像：基于检索自增广的无监督迷彩目标检测 [PDF](https://arxiv.org/pdf/2510.18437), [HTML](https://arxiv.org/abs/2510.18437)
### Authors
Ji Du,Xin Wang,Fangwei Hao,Mingyang Yu,Chunyuan Chen,Jiesheng Wu,Bin Wang,Jing Xu,Ping Li
### Background
迷彩目标检测（COD）的核心是将目标从高度相似的环境中分割出来。以往的研究主要通过图像级建模或基于注释的优化来应对这个挑战，尽管取得了一定进步，但这些方法很少利用培训数据集中的背景信息或依赖于耗时的注释。
### Innovation
本文提出了RISE（检索自增强）框架，利用整个训练数据集生成单个图像的伪标签，以无监督的方式训练COD模型。RISE框架首先使用训练图像构建环境和迷彩对象的原型库（不带地面真实值），然后通过K近邻检索生成每个图像的伪掩码。此外，RISE提出了聚类-然后检索（CR）策略来生成高置信度的原型。在K近邻检索阶段，提出了多视图K近邻检索（MVKR）以减轻特征图中伪像的影响。
### Conclusion
广泛的实验表明，RISE在无监督和提示基础方法中表现出色。代码可在此链接查看：this https URL
## 561. `cs.CV` - ImageGem: 在野生生成图像交互数据集用于生成模型个性化 [PDF](https://arxiv.org/pdf/2510.18433), [HTML](https://arxiv.org/abs/2510.18433)
### Authors
Yuanhe Guo,Linxi Xie,Zhuoran Chen,Kangrui Yu,Ryan Po,Guandao Yang,Gordon Wetztein,Hongyi Wen
### Background
现有的生成模型难以理解和满足用户的细粒度个体偏好，主要原因是缺乏用户偏好注释数据，特别是在现实世界中的注释数据更是稀缺。因此，构建一个能够反映用户个体偏好的数据集对于推动此类生成模型的发展至关重要。ImageGem数据集围绕这一问题进行设计，包含了大量的用户交互数据，能够更好地理解用户的具体偏好，为生成模型的个性化提供了重要基础。
### Innovation
ImageGem数据集收录了57,000名用户的真实交互行为数据，总计生成了242,000个定制化LoRA，以及300万条文本提示和500万张生成图像。利用这些数据，研究者能够构建更有效的偏好一致性模型。此外，通过用户的个人偏好还针对检索模型和多模态模型进行了个性化图像检索和生成模型推荐的研究。最终，提出了一种端到端框架，通过在潜在权重空间中编辑定制扩散模型来实现与用户个人偏好的一致性。
### Conclusion
ImageGem数据集首次实现了一种新的生成模型个性化范式，通过它能够更准确地理解和响应用户的细粒度个体偏好，对于生成模型的进一步发展具有重要意义。
## 562. `cs.CV` - 视觉基础模型可以成为潜在扩散模型的良好令牌化器 [PDF](https://arxiv.org/pdf/2510.18457), [HTML](https://arxiv.org/abs/2510.18457)
### Authors
Tianci Bi,Xiaoyi Zhang,Yan Lu,Nanning Zheng
### Background
潜在扩散模型（LDMs）的表现高度依赖于其视觉令牌的质量。近期工作通过蒸馏的方法将视觉基础模型（VFMs）纳入LDMs，但这一方法存在本质缺陷，即减弱了与原始VFMs的对齐，导致在分布变化下所生成的隐空间映射发生语义偏差。
### Innovation
本文提出了一种新的视觉基础模型变分自编码器（VFM-VAE），绕过了蒸馏过程，从而直接将VFMs与LDMs结合。通过多尺度隐空间融合和渐进分辨率重建模块重新设计VFM-VAE的解码器，提高了空间粗糙的VFMs特征的高质量重建质量。此外，本文还引入了SE-CKNNA指标来精确分析扩散训练中的表示动态，并据此提出了一种联合令牌化器-扩散对齐策略，显著加速了收敛。
### Conclusion
本文在设计令牌化器和训练策略方面取得了创新，使得系统在80个epoch内达到了gFID（无CFG）2.20的性能（较之前方法快10倍）。进一步训练至640个epoch后，gFID（无CFG）达到1.62，直接将VFMs与LDMs结合证实了其作为LDMs范式的优越性。
## 563. `cs.CV` - Mono4DGS-HDR: 交替曝光单目视频的高动态范围4D高斯划线 [PDF](https://arxiv.org/pdf/2510.18489), [HTML](https://arxiv.org/abs/2510.18489)
### Authors
Jinfeng Liu,Lingtong Kong,Mi Zhou,Jinwen Chen,Dan Xu
### Background
现有技术难以从单一镜头低动态范围(LDR)视频中重建可用于渲染的4D高动态范围(HDR)场景，特别是当视频是从交替曝光捕捉时。本文在没有摄像机姿态的情况下重建HDR视频，解决了这一挑战性问题，避免了摄像机姿态的需求，使得初始HDR视频的构建更加稳固。
### Innovation
提出了一个基于高斯点的统一框架，该框架包含两个阶段的优化方法。第一阶段在正交摄像机坐标空间中学习视频HDR的高斯表示，无需摄像机姿态，第二阶段将视频高斯变换到世界空间，并与摄像机姿态共同优化世界高斯。此外，还提出了一种时间亮度正则化策略，以增强HDR外观的时间一致性。构建了一个新的评价基准，使用公开可用的数据集来评价HDR视频重建任务。实验结果表明，Mono4DGS-HDR在渲染质量和速度方面都显著优于从现有最先进的方法调整而来的替代解决方案
### Conclusion
Mono4DGS-HDR系统显著提高了从交替曝光的单目LDR视频中重建HDR场景的质量和速度。通过构建新的评价基准，验证了该方法的有效性和先进性。
## 564. `cs.CV` - RayPose: Ray Bundling Diffusion for Template Views in Unseen 6D Object Pose Estimation [PDF](https://arxiv.org/pdf/2510.18521), [HTML](https://arxiv.org/abs/2510.18521)
### Authors
Junwen Huang,Shishir Reddy Vutukur,Peter KT Yu,Nassir Navab,Slobodan Ilic,Benjamin Busam
### Background
传统的基于模板的目标姿态估计管道通过检索最匹配的模板并将其与观察图像对齐来估计姿态。然而，如果不能准确检索到正确的模板，则会导姿态的不准确预测。
### Innovation
本文提出了一种新的方法，将基于模板的目标姿态估计重新表述为射线对齐问题，其中从多个姿态模板图像学习射线方向来与未姿态化的查询图像对齐。受基于扩散的相机姿态估计最近进展的启发，将这种表述嵌入到扩散变换器架构中，可以将查询图像与一组姿态化的模板对齐。模型通过模板的几何先验来指导准确的查询姿态推理，并通过细至粗的训练策略进一步提高性能。
### Conclusion
在多个基准数据集上的广泛实验显示，我们的方法在未见对象姿态估计方面与最先进的方法具有竞争力。
## 565. `cs.CV` - DWaste：利用移动和边缘设备实现更绿色AI的废弃物分类 [PDF](https://arxiv.org/pdf/2510.18513), [HTML](https://arxiv.org/abs/2510.18513)
### Authors
Suman Kunwar
### Background
便利包装的兴起导致了大量废弃物的产生，使得有效的废弃物分类对可持续废物管理至关重要。为了应对这一挑战，我们开发了DWaste，一个基于计算机视觉的平台，用于资源受限的智能手机和边缘设备上的实时废弃物分类，包括离线功能。我们使用自己的废弃物数据集的一部分，并用定制工具Annotated Lab对其进行标注，以基准测试了各种图像分类模型（EfficientNetV2S/M, ResNet50/101, MobileNet）和物体检测模型（YOLOv8n, YOLOv11n）。
### Innovation
开发了基于计算机视觉的DWaste平台，用于资源受限的移动和边缘设备上的实时废弃物分类。通过基准测试不同的图像分类模型和物体检测模型，探索了准确性和资源消耗之间的权衡。发现轻量级的物体检测模型既能提供高效推理（超快的推理时间～0.03秒）又能显著减小模型大小，适合实时低功耗使用。此外，模型量化显著减少了模型大小和VRAM使用量，有效地提高了效率。
### Conclusion
我们的研究表明，通过实施“更绿色的AI”模型，可以在边缘设备上成功实现实时、可持续的废弃物分类，展示了移动和边缘设备在促进可持续废弃物管理方面的潜力。
## 566. `cs.CV` - LAND: 肺和结节扩散用于基于解剖学指导的3D胸部CT合成 [PDF](https://arxiv.org/pdf/2510.18446), [HTML](https://arxiv.org/abs/2510.18446)
### Authors
Anna Oliveras,Roger Marí,Rafael Redondo,Oriol Guardià,Ana Tost,Bhalaji Nagarajan,Carolina Migliorelli,Vicent Ribas,Petia Radeva
### Background
本文介绍了一种新的隐式扩散模型，用于生成高质量的3D胸腔CT扫描，同时基于3D解剖学掩模进行条件生成。当前的方法在生成高分辨率的3D体视图像时，计算成本较高。本文提出的方法在单个中端GPU上生成256x256x256大小、1毫米等效分辨率的体积图像，大幅降低了计算成本。掩模用于界定肺和结节区域，使输出的解剖学特征具有高度精确的控制能力。实验结果显示，仅依赖结节遮罩进行条件生成会导致解剖结构不正确，突显了全身肺结构在全球准确合成中的重要性。提出的模型支持生成具有不同属性的带有和不带有肺结节的CT体视图像，这为训练人工智能模型或医疗专业人员提供了有价值的工具。
### Innovation
本文的主要创新在于提出了一种新的隐式扩散模型，用于基于3D解剖学掩模条件生成高质量的3D胸腔CT扫描。该方法在中端GPU上生成高分辨率的体积图像，显著降低了计算成本。掩模界定的肺和结节区域提供了解剖特征的精确控制，并强调了肺整体结构在准确生成中的重要性。该方法支持生成具有多种属性的带或不带肺结节的CT体，并且可以用于训练AI模型或培训医学专业人员。
### Conclusion
本文通过提出一种新的隐式扩散方法，提供了生成高质量3D胸腔CT扫描的高效解决方案，特别是当需要精确控制解剖特征时。这种方法显示了它在医学成像和人工智能培训方面的广泛应用潜力。通过使用解剖学掩模，生成的CT体视图能够更准确地反映真实的解剖结构。
## 567. `cs.CV` - 通过基于文本检索增强生成的零样本车辆型号识别 [PDF](https://arxiv.org/pdf/2510.18502), [HTML](https://arxiv.org/abs/2510.18502)
### Authors
Wei-Chia Chang,Yan-Ann Chen
### Background
车辆型号识别（VMMR）在智能交通系统中是一个重要的任务，但现有方法难以适应新推出的车型。尽管CLIP提供了强大的视觉-文本对齐，但其固定预训练权重限制了性能，除非进行昂贵的图像特定微调。现有方法难以快速适应新车型，因此需要一种新的方法来提高识别性能并简化模型更新过程。
### Innovation
本文提出了一种结合视觉语言模型（VLMs）与检索增强生成（RAG）的管道，通过基于文本的推理实现零样本车辆识别。这种方法通过文本描述将车辆图像转换为描述性属性，并通过数据库中的文本特征检索相关条目，结合描述形成提示，然后通过语言模型（LM）推断出车辆的型号和制造商。此设计避免了大规模重新训练，使得通过添加新车辆的描述便可实现快速更新。实验结果表明，所提出的方法在车型识别上比基于CLIP的基本方法提高了近20%，证明了RAG增强的LM推理在智能城市应用场景中具有扩展VMMR的潜力。
### Conclusion
本文提出的方法通过将视觉语言模型与检索增强生成相结合，实现了车辆型号识别的零样本识别，并在实验中显著提高了识别性能。这种方法避免了大规模的重新训练，并且能够通过添加新车辆的描述进行快速更新，展示了其在智能城市应用中的应用潜力。
## 568. `cs.CV` - GBlobs：改进传感器布置泛化的本地激光雷达几何 [PDF](https://arxiv.org/pdf/2510.18539), [HTML](https://arxiv.org/abs/2510.18539)
### Authors
Dušan Malić,Christian Fruhwirth-Reisinger,Alexander Prutsch,Wei Lin,Samuel Schulter,Horst Possegger
### Background
当前基于LiDAR的3D检测器在训练时通常使用全局特征（如绝对笛卡尔坐标），这引入了一种几何捷径，导致模型在很大程度上依赖绝对对象位置，而不是区分形状和外观特征。这种短视在面对不同点分布时（例如，不同传感器布置产生的点分布）严重限制了模型的泛化能力。
### Innovation
提出了GBlobs这一局部点云特征描述子，专门设计用来增强模型在多样激光雷达配置下的泛化能力。通过GBlobs作为网络输入特征，可以有效地绕过几何捷径，促使网络学习到稳健的目标为中心的表示，显著增强模型的泛化能力。
### Conclusion
本技术报告介绍了在RoboSense 2025：Track 3中获得顶级解决方案，实现了在各种传感器布置下3D对象检测的最先进的性能。通过使用GBlobs作为网络输入特征，模型能够有效克服几何捷径，改善3D检测的泛化能力。
## 569. `cs.CV` - Kaleido：开源多主体参考视频生成模型 [PDF](https://arxiv.org/pdf/2510.18573), [HTML](https://arxiv.org/abs/2510.18573)
### Authors
Zhenxing Zhang,Jiayan Teng,Zhuoyi Yang,Tiankun Cao,Cheng Wang,Xiaotao Gu,Jie Tang,Dan Guo,Meng Wang
### Background
尽管已经取得了S2V生成模型的进步，但现有的方法在保持多主体一致性和背景分离方面仍然存在不足，这导致在多参考图像条件下产生较低的参考保真度和语义漂移。这些缺点主要是因为训练数据集缺乏多样性和高质量的样本，以及跨配对的数据（来自不同实例的配对样本），此外当前处理多个参考图像的方法也是次优的，可能会混淆多个主体。
### Innovation
为了克服这些限制，我们提出了一种专门的数据构建管道，包括低质量样本过滤和多样数据合成，以生成保持一致性的训练数据。此外，我们引入了Reference Rotary Positional Encoding（R-RoPE）来处理参考图像，这使得多图像集成变得稳定和精确。
### Conclusion
跨多个基准的大量实验表明，Kaleido在一致性和保真度方面显著优于以前的方法，并且展示了S2V生成的进步。
## 570. `cs.CV` - 基于可逆网络的交互式卫星图像变化检测中的图像增强 [PDF](https://arxiv.org/pdf/2510.18660), [HTML](https://arxiv.org/abs/2510.18660)
### Authors
Hichem Sahbi
### Background
该论文提出了一个基于主动学习的新型交互式卫星图像变化检测算法。算法通过迭代过程利用问答模型来查询用户对一小部分图像（称为显示）的标签，进而动态更新变化检测模型。实验结果表明，所提出的这种方法相较于相关工作具有优越的性能。
### Innovation
该框架的主要贡献在于提出了一种新颖的可逆网络，能够通过将显示从高度非线性的输入空间映射到潜在空间来增强显示，从而使增强变换变得更线性和易于处理。增强后的数据随后被映射回输入空间，并用于重新训练更有效的变化检测准则，从而在主动学习的后续迭代中进行优化。
### Conclusion
实验结果证明了所提出方法在交互式卫星图像变化检测中的优越性能。
## 571. `cs.CV` - CovMatch: 由交叉协方差指导的具有可训练文本编码器的多模态数据集精简 [PDF](https://arxiv.org/pdf/2510.18583), [HTML](https://arxiv.org/abs/2510.18583)
### Authors
Yongmin Lee,Hye Won Chung
### Background
多模态数据集精简旨在通过合成少量的图像-文本对来高效训练大规模的视觉-语言模型。虽然单模态任务中的数据集精简显示出潜力，但在拓展到多模态对比学习时，学习跨模态对齐和管理大型编码器的高计算成本成为关键挑战。之前的解决方案通过冻结文本编码器并在训练过程中仅更新图像编码器和文本投影层来解决可扩展性问题，但这严重限制了语义对齐，成为性能扩展的瓶颈。
### Innovation
CovMatch 提出了一种可扩展的多模态数据集精简框架，该框架通过同时优化两个编码器来对真实和合成特征的交叉协方差进行对齐，同时在每个模态内限定特征分布。与之前的解决方案不同，CovMatch 使得文本编码器也参与训练，从而增强了跨模态对齐并提高了性能。在 Flickr30K 和 COCO 数据集上的评估表明，CovMatch 在仅使用 500 个合成对的情况下，超越了最先进的多模态数据集精简方法，并实现了高达 6.8% 的检索准确性绝对提升。
### Conclusion
CovMatch 改进了多模态数据集精简方法，通过同时优化两个编码器和对齐真实与合成特征的交叉协方差推动了多模态对比学习的发展，显著增强了跨模态对齐，实现了良好的性能提升。
## 572. `cs.CV` - ε-Seg: 缺乏监督的显微镜数据语义分割 [PDF](https://arxiv.org/pdf/2510.18637), [HTML](https://arxiv.org/abs/2510.18637)
### Authors
Sheida Rahnamai Kordasiabi,Damian Dalle Nogare,Florian Jug
### Background
生物样本的电子显微镜（EM）图像的语义分割在生命科学研究中仍然是一个挑战。EM图像捕捉到的生物结构细节复杂，甚至对人类观察者来说也非常具有挑战性。
### Innovation
引入了ε-Seg方法，基于分层变分自编码器（HVAEs），使用中心区域蒙版、稀疏标签对比学习（CL）、高斯混合模型（GMM）先验和无聚类标签预测。该方法通过中心区域蒙版和修复损失鼓励模型学习稳健且具代表性的嵌入来区分所需类别，即使训练标签稀疏（总量的0.05%或更少）。通过CL和GMM先验塑造HVAE的潜在空间，使得编码输入片段倾向于根据我们希望区分的语义类别聚类。此外，提出了一种MLP语义分割头，直接从潜在嵌入预测类别标签。
### Conclusion
实验结果显示，ε-Seg能够在生物图像数据中实现与有限训练标签可用时竞争力相当的稀疏监督分割结果。该方法还在荧光显微镜数据上展示了其适用性。
## 573. `cs.CV` - Occluded nuScenes: 多传感器数据集用于评估自动驾驶感知鲁棒性 [PDF](https://arxiv.org/pdf/2510.18552), [HTML](https://arxiv.org/abs/2510.18552)
### Authors
Sanjay Kumar,Tim Brophy,Reenu Mohandas,Eoin Martino Grua,Ganesh Sistu,Valentina Donzella,Ciaran Eising
### Background
自动驾驶中的稳健感知需要在恶劣条件下可靠地执行，其中传感器可能会受到部分故障或环境遮挡的影响。尽管当前的自动驾驶数据集本身就包含传感器噪声和环境变化，但是很少有数据集能提供受控、参数化且可重复的多传感器模态衰减。这限制了系统方法性地评估在明确定义的恶劣条件下感知和融合架构性能的能力。
### Innovation
本文介绍了一种新的nuScenes扩展数据集——Occluded nuScenes。该数据集提供了四种类型的遮挡（两种来自公开实现，两种新设计），适用于相机模态，并发布了参数化的遮挡脚本，用于雷达和LiDAR，分别实现了三种类型的衰减，以灵活且重复地生成遮挡数据。该资源支持在部分传感器失效和环境干扰下感知模型的一致且可重复评估。通过释放首个具有可控和可重复衰减的多传感器遮挡数据集，目标是促进对鲁棒传感器融合、抗扰性分析和自动驾驶安全关键感知的研究。
### Conclusion
通过发布多传感器遮挡数据集，本文旨在推进鲁棒传感器融合、抗扰性分析和自动驾驶安全关键感知的研究。
## 574. `cs.CV` - C-SWAP: 提示性感知结构剪枝用于高效神经网络压缩 [PDF](https://arxiv.org/pdf/2510.18636), [HTML](https://arxiv.org/abs/2510.18636)
### Authors
Baptiste Bauvin,Loïc Baret,Ola Ahmad
### Background
近年来，神经网络压缩在计算机视觉等应用中引起了越来越多的关注，特别是在需要大规模模型部署的情况下，模型结构的减小对减少推理时间和降低内存开销至关重要。剪枝是一种常用的技术，它可以促使模型中的稀疏性，比如权重、神经元和层，从而减少模型规模和推理成本。结构化剪枝尤其重要，因为它可以移除整个结构，进一步加快推理速度并减少内存开销。然而，这种技术往往需要迭代的重新训练和优化，这在计算上可能是昂贵的。以往的方法试图通过一击即中设置（one-shot setting）来解决这个问题，即在训练后直接应用剪枝，但这种做法通常会导致性能显著下降。因此，本文旨在通过提出一种基于可解释深度学习的一击即中剪枝框架来克服这一问题，该框架可以在不显著影响性能的前提下，高效地减少网络规模。
### Innovation
本文首次提出了一种基于可解释深度学习的一击即中剪枝框架，名为 C-SWAP (Causal-aware Structured Pruning with Awareness of Performance, C-SWAP)。该方法引入了一种因果关系感知的剪枝方法，利用模型预测与结构之间的因果关系，在逐步剪枝过程中能够高效减小模型规模，同时确保被移除的结构不会影响模型性能。通过在卷积神经网络和视觉变换器（vision transformer）上对分类任务进行预训练的基础模型上进行实验，证明了该方法能够在几乎不影响性能的同时实现显著的模型规模减少，且无需微调。
### Conclusion
总体而言，本文的方法优于现有方法，提供了性能和模型规模之间最优的权衡。作者的代码在网上可以获得。
## 575. `cs.CV` - 二阶二次量化：超越一阶量化以实现实值矩阵压缩 [PDF](https://arxiv.org/pdf/2510.18650), [HTML](https://arxiv.org/abs/2510.18650)
### Authors
Kyo Kuroki,Yasuyuki Okoshi,Thiem Van Chu,Kazushi Kawamura,Masato Motomura
### Background
本文提出了一种新的矩阵量化方法，二阶二次量化（BQQ）。与使用二进制基线性组合的传统一阶量化方法（如均匀量化和二进制编码量化）相比，BQQ 通过利用二阶二次表达式的表达能力，同时保持极其紧凑的数据格式。该方法已经在两个实验中得到验证：一个是矩阵压缩基准，另一个是预训练视觉变换器模型的后训练量化（PTQ）。实验结果表明，BQQ 在压缩不同矩阵数据时，在内存效率和重建误差之间始终提供优于传统方法的权衡。此外，尽管没有针对在严格内存限制下的最优 PTQ 准确性和依赖于 PTQ 专用的二进制矩阵优化，BQQ 仍能提供强大的 PTQ 性能，特别是在 ImageNet 数据集下，相较于最先进的方法表现更好，分别是基于校准和无数据场景的2.2% 和59.1%的提升，量化等效为2比特。
### Innovation
本文提出的 BQQ 方法在压缩矩阵数据方面具有显著优势，不仅在实验中能达到更好的内存效率和重建误差之间的权衡，而且不需要优化特定的二进制矩阵，也能达到强大的后训练量化性能。特别是在无数据和基于校准的场景下，BQQ 的表现甚至超越了最先进的 PTQ 方法，量化等效为 2 比特，分别提高 2.2% 和 59.1%。
### Conclusion
二阶二次量化（BQQ）方法克服了传统量化方法的限制，通过对实值矩阵进行压缩提供强大的后训练量化性能，并且在有限的内存资源下也能达到商业级矩阵压缩效果。这篇文章展示了二次量化在矩阵压缩与神经网络压缩中的高效应用前景。
## 576. `cs.CV` - 超越管道：分析端到端深度学习在历史手写识别中的关键因素 [PDF](https://arxiv.org/pdf/2510.18671), [HTML](https://arxiv.org/abs/2510.18671)
### Authors
Hanif Rasyidi,Moshiur Farazi
### Background
本文探讨了影响端到端深度学习方法在历史手写识别（HWI）中性能的各种因素。这一任务由于手写风格的多样性、文档退化以及每名作家的标注样本数量有限而极具挑战性。这些条件使得即使对人类专家也精确识别手写构成了困难。传统的HWI方法依赖于手工设计的图像处理技术和聚类技巧，这些方法在小型且精心策划的数据集上表现良好。相比之下，端到端的管道旨在通过直接从文档图像中学习特征来自动化这一过程，但在更现实、文档级别的设置下，尤其是零样本场景中，这些模型往往难以泛化。在这种情况下，测试集中的作家在训练数据中不存在。
### Innovation
本文探索了不同的预处理方法、骨干架构和后处理策略的不同组合，包括文本分割、补丁采样和特征聚合。实验结果表明，大多数配置由于无法有效地捕捉低级视觉特征、不一致的补丁表示和对内容噪声的高度敏感性而表现不佳。然而，作者识别出一个端到端的配置，虽然设计更加简单，但其结果与表现最佳的系统相当。这些发现指出了构建稳健的端到端系统的关键挑战，并提供了改进历史文档手写识别性能的设计选择的见解。
### Conclusion
本文指出了构建稳健的端到端系统的几个关键挑战，并通过探索不同的方法组合提供了关于如何改进历史手写识别性能的设计选择的见解。
## 577. `cs.CV` - 3D思考：基于几何想象的有限视角空间推理 [PDF](https://arxiv.org/pdf/2510.18632), [HTML](https://arxiv.org/abs/2510.18632)
### Authors
Zhangquan Chen,Manyuan Zhang,Xinlei Yu,Xufang Luo,Mingze Sun,Zihao Pan,Yan Feng,Peng Pei,Xunliang Cai,Ruqi Huang
### Background
尽管视觉-语言模型在多种跨模态任务中取得了显著进展，但理解有限视角下的三维空间关系仍然是一个重大的挑战。现存的方法通常依赖纯文本或二维视觉线索，这限制了它们在需要三维空间想象的任务中的表现。
### Innovation
提出了一种名为3DThinker的框架，能够在推理过程中有效利用图像中的丰富几何信息，同时能够实现纯文本到基于几何想象的空间推理，无需任何三维先验输入，且不需要依赖明确标注的三维数据进行训练。该框架分为两个训练阶段：首先是监督训练阶段，通过视觉语言模型与3D基础模型的三维隐含表示对齐；然后是优化推理轨迹阶段，仅基于结果信号进行优化，从而精炼底层的三维空间想象。
### Conclusion
跨多个基准测试的大量实验表明，3DThinker在多个任务中表现出了优越性，并为将三维表示统一到跨模态推理中提供了一个新的思路。
## 578. `cs.CV` - MoGA: Mixture-of-Groups Attention for End-to-End Long Video Generation [PDF](https://arxiv.org/pdf/2510.18692), [HTML](https://arxiv.org/abs/2510.18692)
### Authors
Weinan Jia,Yuning Lu,Mengqi Huang,Hualiang Wang,Binyuan Huang,Nan Chen,Mu Liu,Jidong Jiang,Zhendong Mao
### Background
长视频生成基于Diffusion Transformers（DiTs），但其全注意力机制随着序列长度增加呈二次时间复杂度增长，这极大地限制了长视频生成的效率。尽管现有的稀疏注意力机制通过块状近似方法解决了部分问题，但这种方法在精度和效率之间仍存在局限性，特别是在块大小的选择上。
### Innovation
本文提出了一种高效的稀疏注意力机制——Mixture-of-Groups Attention（MoGA）。MoGA引入了一个轻量级、可学习的标记路由器，能够精确匹配标记，无需使用块状估算。通过语义感知路由，MoGA能够实现有效的长距离交互。MoGA作为一种无需核的方法，能够无缝集成到现代注意力堆栈中，包括FlashAttention和序列并行计算中。
### Conclusion
基于MoGA，本文开发了一种端到端的高效长视频生成模型，能够生成数分钟长度、多帧视频且分辨率高达480p，帧率为24 fps，上下文长度约580k。多项实验表明，本文的方法在各种视频生成任务中有效。
## 579. `cs.CV` - ScaleNet：使用增量参数扩展预训练神经网络 [PDF](https://arxiv.org/pdf/2510.18431), [HTML](https://arxiv.org/abs/2510.18431)
### Authors
Zhiwei Hao,Jianyuan Guo,Li Shen,Kai Han,Yehui Tang,Han Hu,Yunhe Wang
### Background
近期的研究表明，视觉变换器（ViTs）模型越大，性能往往越好。然而，训练这些大型模型在计算上仍然非常密集和昂贵。为了解决这个问题，本文提出了一种名为ScaleNet的有效方法，用于扩展ViT模型。与从头开始训练的传统方法不同，ScaleNet允许快速扩展模型，并且参数增加可以忽略不计。这种扩展通过向预训练的ViT模型中插入额外的层来实现，并利用层间的权重共享来保持参数的效率。这种方法提供了一种成本效益高的解决方案，以有效扩展ViTs。
### Innovation
ScaleNet的主要创新在于，它能够通过向预训练模型中添加额外的层来实现模型扩展，同时利用层间权重共享来保持参数的效率。每个新增加的层都会与预训练模型中的对应层共享参数张量。为了减轻由于共享权重可能引起的性能下降，ScaleNet引入了一个小的调整参数集来每个层，这些调整参数通过并行适配器模块实现，确保共享参数张量在每个实例中的独立性和优化。
### Conclusion
实验表明，ScaleNet能够在ImageNet-1K数据集上高效扩展ViT模型。通过将一个2倍深度的DeiT-Base模型进行扩展，ScaleNet在训练阶段只需要原从头开始训练所需的一半左右的周期，就能实现7.42%的准确率提升。这表明了该方法在扩展ViTs方面的高效性。此外，该方法在下游视觉任务，如物体检测中也显示出极大的应用潜力。
## 580. `cs.CV` - 从Transformer中显式挖掘运动信息进行动作识别的复兴 [PDF](https://arxiv.org/pdf/2510.18705), [HTML](https://arxiv.org/abs/2510.18705)
### Authors
Peiqin Zhuang,Lei Bai,Yichao Wu,Ding Liang,Luping Zhou,Yali Wang,Wanli Ouyang
### Background
近年来，基于变压器的方法因具备时空上下文聚合能力而主导了动作识别领域。尽管在场景相关的数据集中取得了显著进展，但这些方法在重视运动的数据集上的表现不佳，这是由于缺乏细致的运动建模设计。研究发现，传统的动作识别中广泛使用的成本体在结构上类似自注意力中的亲和矩阵，但在功能上具有强大的运动建模能力。
### Innovation
本文提出了一种集成有效运动建模特性的方法，通过引入显式运动信息挖掘模块（EMIM）。EMIM中，构建类似成本体的亲和矩阵，通过滑动窗口从下个时间帧中查询到的邻域采样一组关键候选令牌。接着，利用构建的亲和矩阵进行外观建模以聚合上下文信息，并转换成运动特征用于运动建模。
### Conclusion
通过在四个广泛使用的数据集上验证运动建模能力，本文的方法在运动敏感的数据集上（例如Something-Something V1 & V2）优于现有的最佳方法。
## 581. `cs.CV` - UniGenBench++：一种统一的文本到图像生成语义评估基准 [PDF](https://arxiv.org/pdf/2510.18701), [HTML](https://arxiv.org/abs/2510.18701)
### Authors
Yibin Wang,Zhimin Li,Yuhang Zang,Jiazi Bu,Yujie Zhou,Yi Xin,Junjun He,Chunyu Wang,Qinglin Lu,Cheng Jin,Jiaqi Wang
### Background
文本到图像（T2I）生成的进步突显了可靠基准的重要性，用于评估生成图像如何准确反映其文本提示的语义。然而，现有基准缺乏提示场景的多样性和多语言支持，这对于实际应用来说是必要的；并且它们只提供了粗略的评估，只覆盖了几个主要维度和较少的亚维度，无法进行细微的亚维度评估。
### Innovation
我们提出了UniGenBench++，一种统一的T2I生成语义评估基准，该基准包含600个分层组织的提示以确保覆盖和效率，涵盖5个主要提示主题和20个子主题的多样现实世界场景，并且全面探索T2I模型在10个主要和27个亚评价标准中的语义一致性。基准还提供英文和中文版本的简短和长形式的提示，利用封闭源多模态大型语言模型（MLLM）Gemini-2.5-Pro来建立可靠基准并简化模型评估流程，同时训练出稳健的评估模型以实现离线评估，从而系统地揭示了不同模型在不同方面的优缺点。
### Conclusion
通过全面评估开源和封闭源的T2I模型，系统地揭示了它们在各方面的优势和劣势。
## 582. `cs.CV` - SSD: 空间-语义头部解耦以实现高效的自回归图像生成 [PDF](https://arxiv.org/pdf/2510.18716), [HTML](https://arxiv.org/abs/2510.18716)
### Authors
Siyong Jian,Huan Wang
### Background
自回归图像生成模型，如Janus-Pro，能够生成高质量的图像，但需要大量内存和不断增长的计算需求，原因是视觉标记的数量庞大。虽然在语言模型中已经广泛研究了KV缓存压缩技术，但对于图像生成领域来说，这一技术仍然几乎没有被探索。
### Innovation
本文通过识别出了一个独特的且显着的注意力现象——空间局部性和暂时语义吸引者，并构建了一种新型的KV缓存压缩框架。该框架根据特定类型（空间局部性头部和语义吸引者头部）对注意力头进行解耦，前者保留最近的短窗口，而后者保留一组高度关注的标记。实验结果表明，在仅有轻微视觉质量损失的情况下，该方法实现了5倍的内存减少以及整体吞吐量6.6倍的加速。
### Conclusion
该研究所提出的方法能够在资源受限的硬件上实现高效的自回归图像生成，同时大幅降低了内存使用并显著提高了计算效率。
## 583. `cs.CV` - 在多模态网络文档上探索统一的以视觉为中心的对比替代方法 [PDF](https://arxiv.org/pdf/2510.18703), [HTML](https://arxiv.org/abs/2510.18703)
### Authors
Yiqi Lin,Alex Jinpeng Wang,Linjie Li,Zhengyuan Yang,Mike Zheng Shou
### Background
对比视觉-语言模型（如CLIP）已在多种跨模态任务中表现出色，通过学习对齐的图像-文本对进行训练。然而，这些模型在处理复杂的、现实世界的网页文档时能力有限，尤其是在文本和图像交错、松散对齐或嵌入视觉形式的情况下。由于这些挑战，本研究提出了一种统一的框架Vision-Centric Contrastive Learning (VC2L)，旨在通过单一的视觉变换器同时建模文本、图像及其组合，解决了这些难题。
### Innovation
VC2L是一种统一的框架，在像素空间中运行，将所有输入（无论是否为文本、视觉或组合）都渲染为图像，从而消除了OCR、文本分词或模态融合策略的需要。通过片段级的对比学习目标，VC2L能够捕捉多模态网络文档中的复杂跨模态关系，利用文档内部的连贯性，无需显式成对的图像-文本数据。这使得VC2L能够更好地处理复杂的多模态场景。
### Conclusion
实验证明，VC2L在提出的AnyCIR、SeqCIR和CSR检索基准以及M-BEIR和MTEB等已建立的数据集上，与CLIP类型的模型相比，取得了具有竞争力或更优的性能。这些结果强调了多模态网络数据作为对比学习的宝贵训练资源的潜力，并展示了统一的、以视觉为中心的方法在跨模态表示学习中的可扩展性。
## 584. `cs.CV` - PLANA3R：基于前馈平面渲染的零样本度量平面3D重建 [PDF](https://arxiv.org/pdf/2510.18714), [HTML](https://arxiv.org/abs/2510.18714)
### Authors
Changkun Liu,Bin Tan,Zeran Ke,Shangzhan Zhang,Jiachen Liu,Ming Qian,Nan Xue,Yujun Shen,Tristan Braud
### Background
室内场景的度量3D重建通常依赖于外界形体的固有几何规律来压缩表示，使用平面对3D对象的良好表示来替代人工注释的3D平面。现有方法需要3D平面标注作为监督信号，这限制了其在大规模数据集上的应用。PLANA3R通过计划3D图表示提高了前馈模型的训练效率，无需明确的平面监督，能够准确定位和渲染平面，并在多种度量监督数据集上验证了其鲁棒性和通用性，用于3D表面重建、深度估计和相对姿态估计等任务，同时展示了准确的平面分割能力。
### Innovation
PLANA3R提出了一种无需平面注释、通过前馈平面渲染的零样本度量平面3D重建框架。它使用Vision Transformers从双视图图像中提取稀疏平面三次元基元，并通过计划平面绘制进行几何学习，无需3D平面标注即可进行大规模立体数据集的训练。与需要3D平面标签的现有方法相比，该方法更简化、高效，能够进行更鲁棒和通用的3D重建。
### Conclusion
通过使用平面对3D表示，PLANA3R实现了在大型室外环境中的稳健性和多样性任务下的鲁棒性。该方法在多个度量监督数据集上验证了其能力，并且通过对计划三维空间的定位和渲染展现出了准确的平面分割能力。
## 585. `cs.CV` - SEAL: 半监督语义感知层次学习框架用于泛化类别发现 [PDF](https://arxiv.org/pdf/2510.18740), [HTML](https://arxiv.org/abs/2510.18740)
### Authors
Zhenqi He,Yuanpei Liu,Kai Han
### Background
现有的类别发现方法通常依赖单一层次的语义或手动设计的抽象层次结构，这限制了其泛化能力和可扩展性。
### Innovation
提出了SEAL（SEmantic-aware hierArchical Learning框架），该框架利用自然发生的易于访问的层次结构指导学习。SEAL采用了层次语义引导的软对比学习方法，解决了传统对比损失方法将所有负样本同等对待的问题。此外，SEAL还设计了一种跨粒度一致性（CGC）模块，以确保不同粒度级别的预测一致。
### Conclusion
SEAL在细粒度基准测试中的性能达到了最先进的水平，包括SSB基准、Oxford-Pet和Herbarium19数据集，并进一步展示了在粗粒度数据集上的泛化能力。
## 586. `cs.CV` - IF-VidCap：视频字幕模型能遵循指令吗？ [PDF](https://arxiv.org/pdf/2510.18726), [HTML](https://arxiv.org/abs/2510.18726)
### Authors
Shihao Li,Yuanxing Zhang,Jiangtao Wu,Zhide Lei,Yiwen He,Runzhe Wen,Chenxi Liao,Chengkang Jiang,An Ping,Shuo Gao,Suhan Wang,Zhaozhou Bian,Zijun Zhou,Jingyi Xie,Jiayi Zhou,Jing Wang,Yifan Yao,Weihao Xie,Yingshui Tan,Yanghai Wang,Qianqian Xie,Zhaoxiang Zhang,Jiaheng Liu
### Background
尽管多模态大型语言模型（MLLMs）在视频字幕生成方面表现出色，但实际应用中需要生成遵循特定用户指令的字幕，而非生成详尽且无限制的描述。现有基准主要评估描述的全面性，但忽视了指令遵循能力。因此，存在评估控指令视频字幕的缺口。
### Innovation
引入IF-VidCap，这是一个新的基准测试，用于评估可控视频字幕，包含1400个高质量样本。与现有视频字幕或一般指令遵循基准不同，IF-VidCap采用了系统性框架，从格式正确性和内容正确性两个方面评估字幕。全面评估20余种主流模型揭示了复杂的性能图谱：尽管私有模型仍占主导地位，但性能差距正在缩小，顶级开源解决方案已接近同等水平。此外，研究发现，专门用于密集字幕的模型在复杂指令上表现逊色于通用MLLM，表明未来工作应同时提升描述丰富性和指令遵循精度。
### Conclusion
尽管私有模型依然占主导地位，但性能差距在缩小，顶级开源解决方案已接近私有模型的水平。面向复杂指令的模型需要均衡提升描述丰富度和指令遵循的精确度。
## 587. `cs.CV` - 基于照明衰减感知的移动光源自适应结肠镜重建 [PDF](https://arxiv.org/pdf/2510.18739), [HTML](https://arxiv.org/abs/2510.18739)
### Authors
Hao Wang,Ying Zhou,Haoyu Zhao,Rui Wang,Qiang Hu,Xing Zhang,Qiang Li,Zhiwei Wang
### Background
3D Gaussian Splatting (3DGS) 技术在结肠镜检查中的实时视图合成方面发挥了重要作用，它支持虚拟结肠镜检查和病灶跟踪等关键应用。然而，传统的3DGS假设光照是静态的，并且观察到的外观仅取决于视角，这导致与由于光源或相机动态变化引起的成像场景中的光度变化不兼容。这种情况迫使大多数3DGS方法引入在相机和组织之间的结构违例的蒸汽状高斯球体来补偿光照衰减，最终降低了三维重建的质量。前人的工作仅考虑由光距引起的效果衰减，而忽略了光源和相机的物理特性。
### Innovation
提出了针对结肠镜检查的改进3DGS框架ColIAGS。引入改进的外观建模方法，包含两类光照衰减因素，使高斯函数能够适应光照变化同时保持几何精度。为了确保外观建模的几何近似条件，提出了改进的几何建模，利用高维视角嵌入增强了高斯几何属性预测，并利用余弦嵌入输入以隐式方式生成光照衰减解决方案。实验结果表明，ColIAGS不仅实现了视图合成的新视图合成和几何重建的双重能力，而且相比其他最先进的方法，它在渲染保真度方面表现更优，深度MSE显著降低。
### Conclusion
我们的提案ColIAGS在标准基准上的全面实验结果显示，ColIAGS实现了新的视图合成和精确的几何重建的双重能力。它在渲染保真度方面显著优于其他最先进的方法，同时深度MSE也大幅降低。代码将开源。
## 588. `cs.CV` - 使用微气候影响预测中微调的地理空间基础模型检测和模拟城市热岛 [PDF](https://arxiv.org/pdf/2510.18773), [HTML](https://arxiv.org/abs/2510.18773)
### Authors
Jannis Fleckenstein,David Kreismann,Tamara Rosemary Govindasamy,Thomas Brunschwiler,Etienne Vos,Mattia Rigotti
### Background
随着城市化进程和气候变化的推进，城市热岛现象变得更加频繁和严重。要制定有效的缓解计划，城市需要详细的空气温度数据。然而，传统机器学习模型在有限数据下的预测往往不准确，特别是在未服务区域。全球无结构数据上的地理空间基础模型通过表现出强大的泛化能力并仅需要少量微调，提供了有希望的替代方案。该研究通过量化绿地的降温效果和将其与模型预测进行对比来建立一个实质性的城市热模式，以此评估模型的准确性。随后对基础模型进行了微调，以预测未来气候情景下的地表温度，通过模拟填补来展示其在缓解措施支持方面的重要性。研究结果表明，基础模型提供了在数据稀缺地区评估城市热岛缓解策略的强大方法，有助于促进更具气候韧性的城市。
### Innovation
该研究使用地理空间基础模型，并通过微调来预测未来气候情景下的地表温度，推出了一种强有力的方法来评估城市热岛缓解策略。这种方法尤其适用于数据稀缺区域，有助于支持气候韧性的城市构建。与传统的机器学习模型相比，该模型表现出更强的泛化能力，仅需少量微调。
### Conclusion
研究结果表明，地理空间基础模型提供了一种评估城市热岛缓解策略的有效方法，在数据稀缺地区尤其适用，有助于促进气候韧性的城市建设。
## 589. `cs.CV` - UltraGen: 基于分层注意力机制的高分辨率视频生成 [PDF](https://arxiv.org/pdf/2510.18775), [HTML](https://arxiv.org/abs/2510.18775)
### Authors
Teng Hu,Jiangning Zhang,Zihan Su,Ran Yi
### Background
近年来，视频生成技术取得了显著进展，能够在内容创作、娱乐和虚拟现实等多个领域生成视觉效果出色的视频。然而，大多数现有的基于扩散转换器的视频生成模型由于注意力机制的计算复杂度问题，仅能生成低分辨率（≤720P）的视频输出，这在训练和推理上限制了高分辨率（1080P/2K/4K）视频的生成，使其变得不切实际。
### Innovation
本文提出了一种名为UltraGen的新颖的视频生成框架，旨在实现高效且端到端的原生高分辨率视频合成。该框架包括基于全局-局部注意力分解的分层双分支注意力架构，通过局部注意力分支实现高保真区域内容，全局注意力分支提高整体语义一致性。此外，UltraGen还提出了一种空间压缩的全局建模策略和分层跨窗口局部注意力机制，以减少计算成本同时增强不同局部窗口之间的信息流。
### Conclusion
实验证明，UltraGen能够有效扩展预训练的低分辨率视频模型至1080P乃至4K分辨率，首次实现了高分辨率视频生成，并在定性和定量评估中优于现有最先进的方法和基于超分辨率的两阶段管道。
## 590. `cs.CV` - 可解释的混合人工智能框架提升结核病及症状检测 [PDF](https://arxiv.org/pdf/2510.18819), [HTML](https://arxiv.org/abs/2510.18819)
### Authors
Neel Patel,Alexander Wong,Ashkan Ebadi
### Background
结核病依然是全球范围内的重大公共卫生问题，特别是在资源有限和偏远地区更为突出。早期诊断对于治疗至关重要，然而放射科医生技能不足表明需要借助人工智能（AI）驱动的筛查工具。开发可靠的AI模型面临着很大挑战，因为这需要大量高质量的数据集，而获取这些数据集成本高昂。
### Innovation
我们提出了一种教师-学生框架，通过集成两个监督头部和一个自监督头部来提升胸部X光片上疾病的检测和症状识别。该模型在区分新冠肺炎、结核病和正常病例时的准确率达到98.85%，多标签症状检测的宏F1得分为90.09%，显著优于基线模型。模型的可解释性评估显示其预测基于相关解剖特征，为临床筛查和分流设置部署提供了前景。
### Conclusion
我们的模型能在识别结核病和症状方面展现出优异的性能，并具备良好的可解释性，这为临床应用提供了可靠基础。
## 591. `cs.CV` - 几何方法下的可 steerable 卷积 [PDF](https://arxiv.org/pdf/2510.18813), [HTML](https://arxiv.org/abs/2510.18813)
### Authors
Soumyabrata Kundu,Risi Kondor
### Background
与其他许多采用抽象的、群论方法的论文不同，本文提供了一种新的、更直观的 $d$ 维 steerable 卷积神经网络的推导方法。这种推导基于几何论证和模式匹配的基本原理。本文还为 clebsch--gordan 分解和球谐基函数的出现提供了直观的解释，并提出了使用内插核构建 steerable 卷积层的新方法，该方法比现有实现更具鲁棒性，尤其是在处理噪声数据时。
### Innovation
1. 提供了一种新的、更直观的 $d$ 维 steerable 卷积神经网络的推导方法，基于几何论证和模式匹配的基本原理。2. 为 clebsch--gordan 分解和球谐基函数的出现提供了直观的解释。3. 建议使用内插核构建 steerable 卷积层的新方法，比现有实现更具鲁棒性，特别是在处理噪声数据时。
### Conclusion
本文提供了一种新的、直观的方法，以 $d$ 维的几何视角重新解释 steerable 卷积，并提出了改进现有实现的新方法，有利于处理噪声数据。
## 592. `cs.CV` - SAM 2++: Tracking Anything at Any Granularity [PDF](https://arxiv.org/pdf/2510.18822), [HTML](https://arxiv.org/abs/2510.18822)
### Authors
Jiaming Zhang,Cheng Liang,Yichun Yang,Chenkai Zeng,Yutao Cui,Xinwen Zhang,Xin Zhou,Kai Ma,Gangshan Wu,Limin Wang
### Background
视频跟踪旨在根据目标的初始状态，在后续帧中找到特定目标。由于不同任务间目标状态的精细度差异，现有大多数跟踪器都是针对单一任务定制的，并且高度依赖于各任务中自定义设计的模块，这限制了它们的通用性，并导致了在模型设计和参数上的冗余。
### Innovation
为了统一视频跟踪任务，该研究提出了SAM 2++，一种能够在任何精细度下跟踪的目标统一模型，包括掩码、框和点。其创新点包括：设计了任务特定的提示来将各种任务输入编码为通用提示嵌入，并采用统一解码器将不同任务结果统一表示；引入了任务自适应的内存机制，统一不同精细度的内存匹配；开发了定制数据引擎，支持在不同精细度下进行跟踪训练，创建了一个同时包含三种精细度的丰富注释视频跟踪数据集，称为Tracking-Any-Granularity，为通用跟踪提供了一个丰富资源。
### Conclusion
多项基准测试结果表明，SAM 2++在各种不同精细度的跟踪任务中达到了新的最佳性能，建立了统一且稳健的跟踪框架。
## 593. `cs.CV` - ProCLIP: 通过基于LLM的嵌入器渐进的视觉-语言对齐 [PDF](https://arxiv.org/pdf/2510.18795), [HTML](https://arxiv.org/abs/2510.18795)
### Authors
Xiaoxing Hu,Kaicheng Yang,Ziyong Feng,Qi Ming,Zonghao Guo,Xiang An,Ziyong Feng,Junchi Yan,Xue Yang
### Background
原始的CLIP文本编码器由于最大输入长度限制在77个标记，限制了其处理长文本和微粒度语义理解的能力。此外，CLIP文本编码器不支持多语言输入。这些限制大大限制了其在更广泛任务中的应用。近期研究试图通过使用基于大规模语言模型（LLM）的嵌入器来替代CLIP文本编码器，以增强其处理长文本、多语言理解和微粒度语义理解的能力。然而，由于LLM的表示空间和CLIP的视觉-语言空间是独立预训练的，直接使用对比学习进行对齐会破坏CLIP图像编码器中的固有视觉-语言对齐，导致预训练知识的无效利用。
### Innovation
本文提出了一种基于课程学习的渐进视觉-语言对齐框架ProCLIP，该框架通过提炼CLIP文本编码器的知识到基于LLM的嵌入器中，逐步建立LLM嵌入器与CLIP图像编码器之间的初始对齐。进一步利用图像-文本对比性微调来对齐CLIP图像编码器与基于LLM的嵌入器，并通过自我蒸馏正则化来避免过拟合。在此过程中，还采用了实例语义对齐损失和嵌入结构对齐损失来实现更有效的对齐。
### Conclusion
ProCLIP框架有效解决了直接对齐带来的视觉-语言对齐破坏问题，通过逐步对齐与自我蒸馏，提高了CLIP在处理长文本、多语言理解和微粒度语义理解中的表现。
## 594. `cs.CV` - 通过层次掩码框架统一并增强图变换器 [PDF](https://arxiv.org/pdf/2510.18825), [HTML](https://arxiv.org/abs/2510.18825)
### Authors
Yujie Xing,Xiao Wang,Bin Wu,Hai Huang,Chuan Shi
### Background
基于图的Transformer（GTs）由于能够建模多种节点间的交互而成为图表示学习中有力的范式。然而，现有的图Transformer通常依赖于复杂且针对特定交互特意设计的架构，这限制了它们的灵活性。
### Innovation
论文提出了一种统一的层次掩码框架，该框架揭示了模型架构与注意力掩码构建之间的内在等价性。此框架通过精心设计的注意力掩码捕获了多样化的交互，理论分析表明正确的分类概率与感受野大小和标签一致性正相关，提出了有效注意力掩码应确保足够大的感受野和高标签一致性的基本设计理念。此外，引入了基于混合专家的多层掩码和双注意计算的M3Dphormer模型，该模型采用了双层专家路由机制以自适应地整合多层次交互信息，并通过动态切换密集和稀疏模式来确保可扩展性。
### Conclusion
广泛的实验表明，M3Dphormer在多个基准上达到了最先进的性能，验证了统一框架和模型设计的有效性。
## 595. `cs.CV` - FedDEAP: 跨域联邦学习中的自适应双提示调优 [PDF](https://arxiv.org/pdf/2510.18837), [HTML](https://arxiv.org/abs/2510.18837)
### Authors
Yubin Zheng,Pak-Hei Yeung,Jing Xia,Tianjie Ju,Peng Tang,Weidong Qiu,Jagath C. Rajapakse
### Background
联邦学习（FL）允许多个客户端协作训练机器学习模型而不泄露本地数据，平衡了性能和隐私。然而，客户端之间领域的变化和标签异质性常常阻碍了聚合全局模型的普适性。近年来，大规模的多模态模型如CLIP展示了强大的零样本分类能力，引发了如何在联邦设置下有效微调CLIP于不同领域的问题。为了解决这一问题，作者提出了一种自适应联邦提示调优框架FedDEAP，旨在增强CLIP在多领域场景中的泛化能力。
### Innovation
FedDEAP框架包括三个关键组件：（1）通过使用语义和领域变换网络分离图像中的语义特征和领域特定特征，以减轻由标签监督调优导致的领域特定信息损失；（2）在全局提示聚合过程中引入双提示设计，包含全局语义提示和局部领域提示，以平衡共享信息和个人化信息；（3）通过在两个学习的变换下对文本和视觉表示进行对齐，以最大化图像中包含的语义和领域信息在网络生成的文本特征中，以保持语义和领域一致性。
### Conclusion
理论分析和在四个数据集上的广泛实验表明，FedDEAP方法能够在多领域场景中增强CLIP在联邦图像识别中的泛化能力。
## 596. `cs.CV` - DSI-Bench: 动态空间智能基准 [PDF](https://arxiv.org/pdf/2510.18873), [HTML](https://arxiv.org/abs/2510.18873)
### Authors
Ziang Zhang,Zehan Wang,Guanghao Zhang,Weilong Dai,Yan Xia,Ziang Yan,Minjie Hong,Zhou Zhao
### Background
研究动态空间关系至关重要，因为观察者和物体经常同时移动。尽管视觉-语言模型（VLMs）和视觉专业模型在二维任务和静态场景中表现出色，但它们在完全理解动态三维场景方面的能力仍然有限。
### Innovation
我们提出了动态空间智能（DSI-Bench），这是一个包含接近1000个动态视频和超过1700个手动注释问题的基准，覆盖了观察者和物体的九种解耦运动模式。空间和时间上的对称设计减少了偏见，使得对模型的空间推理能力和物体运动推理能力进行系统评估成为可能。研究发现，模型在处理动态场景时容易混淆观察者和物体的运动，出现语义偏差，并且难以准确推断相对关系。
### Conclusion
我们的DSI-Bench为通用和专业动态空间智能模型的未来发展提供了有价值的研究发现和见解。
## 597. `cs.CV` - 观看文本：从分词到视觉阅读 [PDF](https://arxiv.org/pdf/2510.18840), [HTML](https://arxiv.org/abs/2510.18840)
### Authors
Ling Xing,Alex Jinpeng Wang,Rui Yan,Hongyu Qu,Zechao Li,Jinhui Tang
### Background
人们通过识别单词的视觉对象（包括形状、布局和模式）来阅读文本，并将其与意义连接，这使我们能够有效处理错别字、变形的字体和各种书写系统。现代大型语言模型（LLMs）依赖于子词分词，将文本划分为固定词汇表中的碎片。虽然这种方法对于高资源语言有效，但对于低资源语言来说，这种做法会导致过细分，产生长的、缺乏语言意义的序列，并增加计算负担。
### Innovation
本文挑战了这一根深蒂固的范式，提出了一种视觉中心的替代方法。我们的方法SeeTok将文本渲染为图像（视觉文本），并利用预先训练的多模态LLM来解释它们，重用了由大规模多模态训练学习到的强大的OCR和文本视觉对齐能力。在三种不同的语言任务中，SeeTok在分词器的总量上匹配或超越它们，同时需要4.43倍 fewer tokens 和减少FLOPs 70.5%，另外还有跨语言泛化的增强、对排版噪声的稳健性以及语言层次结构的提升。SeeTok标志着从符号分词向人类视觉阅读的转变，并朝着更自然和认知启发的语言模型迈进。
### Conclusion
SeeTok展示了从符号分词向人类视觉阅读的转变，并朝着更自然和认知启发的语言模型迈进，同时在三个不同语言任务中的性能超过或匹配主流分词器，拥有更少的分词数量和更少的计算量。
## 598. `cs.CV` - DP$^2$O-SR: 直接感知偏好优化的现实世界图像超级分辨率 [PDF](https://arxiv.org/pdf/2510.18851), [HTML](https://arxiv.org/abs/2510.18851)
### Authors
Rongyuan Wu,Lingchen Sun,Zhengqiang Zhang,Shihao Wang,Tianhe Wu,Qiaosi Yi,Shuai Li,Lei Zhang
### Background
借助预训练的文本到图像（T2I）扩散模型，现实世界中的图像超级分辨率（Real-ISR）方法可以合成丰富的和现实的细节。然而，由于T2I模型固有的随机性，不同的噪声输入常常会导致不同感知质量的输出。尽管这种随机性有时被视为一种限制，但它也引入了更广泛的感知质量范围，这可以被利用以提高Real-ISR的性能。
### Innovation
本文引入了Direct Perceptual Preference Optimization for Real-ISR（DP$^2$O-SR）框架，无需昂贵的人工注释便可使生成模型与其感知偏好相匹配。通过结合全参考和无参考图像质量评估（IQA）模型，构造了一个混合奖励信号，以鼓励结构准确性和自然外观。为更好地利用感知多样性，提出了从同一模型的输出中构建多个偏好配对的方法。实验分析表明，最优选择比率取决于模型容量：较小的模型从广泛的覆盖中受益，而较大的模型则对监督强度的变化反应更好。此外，提出了一种分层偏好优化方法，该方法根据组内奖励差距和组间多样性自适应加权训练配对，从而实现更高效的稳定学习。
### Conclusion
不同扩散和流动基干的T2I后端的广泛实验证明，DP$^2$O-SR显著提高了感知质量和在现实世界基准数据上的良好泛化能力。
## 599. `cs.CV` - RoboBench: 作为一种体现大脑的多模态大语言模型的全面评估基准 [PDF](https://arxiv.org/pdf/2510.17801), [HTML](https://arxiv.org/abs/2510.17801)
### Authors
Yulin Luo,Chun-Kai Fan,Menghang Dong,Jiayu Shi,Mengdi Zhao,Bo-Wen Zhang,Cheng Chi,Jiaming Liu,Gaole Dai,Rongyu Zhang,Ruichuan An,Kun Wu,Zhengping Che,Shaoxuan Xie,Guocai Yao,Zhongxia Zhao,Pengwei Wang,Guang Liu,Zhongyuan Wang,Tiejun Huang,Shanghang Zhang
### Background
在动态、非结构化环境中构建能够感知、推理和执行的机器人仍然是一个核心挑战。现有的体效应系统通常采用双系统模式，即系统2处理高层次推理，系统1执行低级控制。本文中，作者将系统2称为体现大脑，强调其在操作任务中的认知核心作用以及进行推理和决策的功能。然而，现有的基准测试主要强调执行的成功率，当目标是高层次的推理时，这些基准测试会因为不完整维度和任务不真实而缺乏评估的全面性。为了弥合这一差距，作者提出了RoboBench，一个系统地评估多模态大语言模型作为体效应大脑的基准测试。
### Innovation
RoboBench定义了五个维度：指令理解、感知推理、泛化规划、可用性预测和失败分析，覆盖了14种能力、25个任务和6092个问答对。为了确保真实性，RoboBench使用跨多种结构的机器人数据集、丰富的属性对象和多视角场景来构建基准。此外，RoboBench还引入了一个评估框架MLLM-as-world-simulator，通过模拟预测计划是否能实现关键对象状态变化来评估体效应可行性。
### Conclusion
实验表明，14种MLLM的存在重大局限性：包括隐含指令理解、时空推理、跨场景规划、细致的可用性理解以及执行失败诊断方面。RoboBench提供了一个全面的框架来量化高层次认知，并指导下一代体效应大语言模型的发展。
## 600. `cs.CV` - 关于计算和可持续人工智能效率的度量与评估 [PDF](https://arxiv.org/pdf/2510.17885), [HTML](https://arxiv.org/abs/2510.17885)
### Authors
Hongyuan Liu,Xinyang Liu,Guosheng Hu
### Background
人工智能（AI）技术的迅速发展催生了前所未有的计算需求。然而，目前用于评估部署模型性能、效率和环境影响的方法仍然碎片化。现有方法往往无法提供全面的视角，使得跨不同硬件、软件堆栈和数值精度的系统比较和优化变得困难。
### Innovation
我们提出了一种统一且可重复的人工智能模型推理方法，该方法在现实的服务条件下结合了计算和环境指标。该框架通过系统地测量延迟和吞吐量分布、能源消耗以及根据不同地理位置调整的碳排放，提供了一种实用且碳意识强的评估方式，并保持匹配的准确性约束，以实现有效比较。该方法应用于多样化的硬件平台上的多精度模型，从数据中心加速器到消费级图形处理器，并运行在主流软件堆栈，如PyTorch、TensorRT和ONNX Runtime上。通过系统地分类这些因素，我们的工作确立了一个严格的基准测试框架，产生决策就绪的帕累托前沿，澄清了精度、延迟、能源和碳排放之间的权衡。
### Conclusion
通过提供开放源代码进行独立验证，我们的工作促进用户基于证据为可持续人工智能部署做出决策。
## 601. `cs.CV` - 通过近场Wi-Fi传感实现跨域多人群体活动识别 [PDF](https://arxiv.org/pdf/2510.17816), [HTML](https://arxiv.org/abs/2510.17816)
### Authors
Xin Li,Jingzhi Hu,Yinghui He,Hongbo Wang,Jin Gan,Jun Luo
### Background
Wi-Fi基于的人体活动识别（HAR）提供了极大的便利，并成为活跃的研究领域。然而，Wi-Fi固有的粗略空间分辨率限制了其在区分多个主体上的能力。通过利用近场支配效应，为每个主体建立专属的传感链路，可有望解决基于原生网络流量实现多主体HAR的问题。由于近场信号的主体特性和不规则模式，HAR神经网络模型需要在跨域适应时进行微调（FT），尤其是在某些类别缺失的情况下，这一过程变得极具挑战。
### Innovation
提出了一种名为WiAnchor的新颖训练框架，用于在存在不完整活动类别的条件下实现有效的跨域适应。该框架通过三个步骤处理嵌有不规则时间信息的Wi-Fi信号：在预训练阶段，扩大类间特征间隔以增强活动的可区分性；在微调阶段，创新了一种锚点匹配机制，用于跨域适应，通过不完整的活动类别信息滤除主体特定的干扰，而非试图从不完整的类别中提取完整的特征；最后，基于输入样例特征层面与锚点的相似性，进一步提高识别性能。
### Conclusion
构建了一个综合数据集，全面评估了WiAnchor，结果显示在活动类别缺失的情况下，跨域准确性超过90%。
## 602. `cs.CV` - DMTrack: 基于卡尔曼融合和不确定性感知关联的可变形状态空间建模的UAV多目标跟踪 [PDF](https://arxiv.org/pdf/2510.17860), [HTML](https://arxiv.org/abs/2510.17860)
### Authors
Zenghuang Fu,Xiaofeng Han,Mingda Jia,Jin ming Yang,Qi Zeng,Muyang Zahng,Changwei Wang,Weiliang Meng,Xiaopeng Zhang
### Background
UAV（无人驾驶飞行器）视角下的多目标跟踪（MOT）面临着一系列独特挑战，包括不可预测的对象运动、频繁的遮挡以及从空中视角带来的有限外观线索。这些挑战在UAV运动突然改变时会进一步加剧，导致轨迹估计不可靠以及身份切换。传统的运动模型如卡尔曼滤波器或静态序列编码器在捕捉在这种条件下的一维和非线性动态时常常表现欠佳。
### Innovation
为了克服这些局限，本文提出了DMTrack，一种针对基于UAV的MOT的可变形运动跟踪框架。DMTrack包含三个核心组件：可变形Mamba，一个动态聚合历史运动状态的可变形状态空间预测器，适合适应性轨迹建模；MotionGate，一个轻量级的门控模块，基于运动上下文和不确定性融合卡尔曼和Mamba预测；以及一种基于运动趋势与预测置信度的不确定性感知的关联策略，以增强身份保持。
### Conclusion
我们的DMTrack在VisDrone-MOT和UAVDT基准测试上实现了最先进的性能，在身份一致性与跟踪准确性方面尤其突出，特别是在高速和非线性运动条件下。值得注意的是，我们方法不依赖外观模型，同时保持了高效的性能，强调其在鲁棒UAV跟踪中的实用性。
## 603. `cs.CV` - NeuCo-Bench: 一种地球观测中神经嵌入的新基准框架 [PDF](https://arxiv.org/pdf/2510.17914), [HTML](https://arxiv.org/abs/2510.17914)
### Authors
Rikard Vinge,Isabelle Wittmann,Jannik Schneider,Michael Marszalek,Luis Gilch,Thomas Brunschwiler,Conrad M Albrecht
### Background
介绍了NeuCo-Bench，这是一个新型基准框架，用于评估（有损的）神经压缩和表示学习，特别是在地球观测（EO）的背景下。该框架基于固定大小的嵌入模型，作为通用的表示形式，适用于多种下游任务。
### Innovation
NeuCo-Bench 包含三个核心组件：(i) 围绕可重用嵌入构建的评估流水线，(ii) 新的挑战模式和隐藏任务排行榜，旨在减轻预训练偏差，(iii) 平衡准确性和稳定性的评分系统。此外，还释放了一个精心策划的多光谱、多时段地球观测数据集SSL4EO-S12-downstream，以支持可重复性。通过对最先进的基础模型进行消融实验，展示了公开挑战初步结果。
### Conclusion
NeuCo-Bench 为社区驱动的标准评估神经嵌入在地球观测和更广泛的领域中提供了第一步。
## 604. `cs.CV` - 3D医学图像中的校准病灶分割 [PDF](https://arxiv.org/pdf/2510.17897), [HTML](https://arxiv.org/abs/2510.17897)
### Authors
Binyu Tan,Zhiyuan Wang,Jinhao Duan,Kaidi Xu,Heng Tao Shen,Xiaoshuang Shi,Fumin Shen
### Background
医学影像分割是精准医疗的关键组成部分，能够精确定位和勾勒病变等病理区域。现有模型依赖固定阈值（如0.5）来区分病变和背景，但无法提供关键指标（如漏检率FNR）的统计保证。这种缺乏原则性的风险控制使其在高风险临床应用中不可靠，特别是在3D病变分割（3D-LS）等具有挑战性场景中。
### Innovation
提出了一种新的风险约束框架——校准病灶分割（CLS），通过校准数据驱动的阈值来确保测试时的漏检率FNR低于目标容差ε，同时在指定风险水平下提供统计保证。CLS首先在一个校准集中分析每个样本的阈值设置以符合FNR容差，基于校准预测的思想。通过将关键阈值校准化，CLS将校准集中的统计规律推广到新测试数据，提供严格的FNR约束，同时产生更精确可靠的分割。
### Conclusion
在五个骨干模型的六个3D-LS数据集上验证了CLS的统计稳健性和预测性能，并为临床应用中的风险意识分割部署提供了实用见解。
## 605. `cs.CV` - 揭开过渡匹配的神秘面纱：何时以及为什么它能超越流匹配 [PDF](https://arxiv.org/pdf/2510.17991), [HTML](https://arxiv.org/abs/2510.17991)
### Authors
Jaihoon Kim,Rajarshi Saha,Minhyuk Sung,Youngsuk Park
### Background
流匹配（FM）是许多最先进的生成模型的基础，然而最新研究显示，过渡匹配（TM）可以在更少的采样步骤中实现更高的生成质量。本文旨在探讨为什么和在什么时候TM会优于FM。研究首先在目标为一元正态分布时进行了探讨，随后将其分析扩展到了多元正态分布，以了解其适用性。
### Innovation
本文证明了在有限步骤下，TM能更严格地降低Kullback-Leibler（KL）散度，这归因于TM中的随机差异隐变量更新策略，而这种更新策略能保留目标协方差，这是FM的确定性更新所低估的。此外，研究还展示了在固定计算预算下，TM的收敛速度更快，以及在某些局部一元情况中TM可以优于FM，特别是在混合正态分布条件下，当混合成分的均值差异增大时，这种效果增强。但是，当目标方差接近零时，TM的更新将收敛于FM，从而失去其性能优势。
### Conclusion
研究结论表明，当目标分布的模态明显分离且具有非忽略的方差时，TM会优于FM。此外，理论结果通过在多元正态分布上的控制实验进行了验证，并且该比较还扩展到图像和视频生成等实际应用中。
## 606. `cs.CV` - 叛逆学生：在高光谱异常检测中增强背景特征的互补学习框架 [PDF](https://arxiv.org/pdf/2510.18781), [HTML](https://arxiv.org/abs/2510.18781)
### Authors
Wenping Jin,Yuyang Tang,Li Zhu,Fei Guo
### Background
近年来，一类仅需一次在背景数据集上训练，并可以无需针对每个场景重新训练或参数调整的情况下普遍应用的高光谱异常检测方法已经显示出显著的效率和鲁棒性。本文在此基础上，着重于光谱和空间线索的整合，并引入了一种名为“叛逆学生”的新颖框架来进行互补特征学习。这种方法旨在训练空间分支刻意偏离光谱教师，从而学习教师未能捕捉的互补空间模式。实验结果表明，与多个现有基准方法相比，本文提出的互补学习范式能够实现显著的改进，且具有很少的计算开销，验证了互补学习的有效性和普适性。
### Innovation
引入了一种“叛逆学生”的互补学习框架，在训练过程中，通过故意使空间分支偏离光谱教师来学习互补的空间模式。采用两阶段学习策略，首先通过逆蒸馏训练光谱增强网络获得稳健的背景光谱表示，然后通过去相关损失优化空间网络，使得特征正交化同时保持重建保真度，从而避免无关噪声。该框架能够在与传统检测器结合时，无需参数和训练即可增强光谱和空间背景特征，从而实现参数和训练无依赖的异常检测。
### Conclusion
在HAD100基准测试上的广泛实验验证了所提出的互补学习框架的有效性和普适性，确认了其显著的改进效果且具有很少的计算代价。相关的代码已经在https://github.com/author/rebellious_student公开可用。
## 607. `cs.CV` - 全球传播的3D照明传输嵌入 [PDF](https://arxiv.org/pdf/2510.18189), [HTML](https://arxiv.org/abs/2510.18189)
### Authors
Bing Xu,Mukund Varma T,Cheng Wang,Tzumao Li,Lifan Wu,Bartlomiej Wronski,Ravi Ramamoorthi,Marco Salvi
### Background
全局照明（GI）对于创造现实的渲染至关重要，但由于间接光传输的复杂性，它仍然具有很强的计算密集型。最近的神经方法主要依赖于针对场景的优化，有时扩展为处理相机或几何形状的变化。跨场景的一般化努力大部分都停留在2D屏幕空间，如神经降噪或基于G缓存的全局光照预测，这常常导致视图不一致和有限的空间理解。
### Innovation
本文提出了一个适用于跨场景的3D光传输嵌入，可以直接从3D场景配置中近似计算全局光照，而无需使用光栅化或路径追踪提示。每个场景通过带几何和材质特征的点云表示。一个可扩展的变压器模型全局的点到点互动来编码这些特征为神经原语。渲染时，每个查询点通过最近邻搜索检索附近的原语，并通过交叉注意聚集其潜在特征来预测所需的渲染量。实验证明该方法在不同布局、几何形状和材质的室内场景中预测散射全局照明的效果。
### Conclusion
该嵌入经过训练用于估计辐射度估计可以快速适应新的渲染任务，只需有限的微调。同时展示了对光亮材质的辐射场空间方向估计的初步结果，并说明了如何通过消除场的规范化加速无偏路径引导。这种方法展示了将学习先验知识整合到渲染管道中的一种路径，而不显式地使用光线追踪照明提示。
## 608. `cs.CV` - FST.ai 2.0: 适用于奥林匹克和残奥会跆拳道公平、快速和包容性决策的可解释AI生态系统 [PDF](https://arxiv.org/pdf/2510.18193), [HTML](https://arxiv.org/abs/2510.18193)
### Authors
Keivan Shariatmadar,Ahmad Osman,Ramin Ray,Usman Dildar,Kisam Kim
### Background
在奥林匹克和残奥会搏击体育项目中，公平、透明、可解释的决策制定仍是一项关键挑战。本文探讨了一种为柔道比赛和训练实时支持裁判员、教练和运动员的具有可解释性的AI生态系统——FST.ai 2.0。
### Innovation
FST.ai 2.0集成了基于姿势的动作识别、通过可信集进行的知识不确定性建模以及可解释性覆盖图，以支持视觉决策支持。此外，该系统通过实现实时感知、可解释推理和治理意识设计，能够跨越自动化评分，还包含裁判培训、公平性监控和政策级分析等模块，从而减少了决策审查时间85%，裁判对AI辅助决策的信任度达93%，展示了迈向公平、问责和人机协同的AI方法。
### Conclusion
FST.ai 2.0建立了透明和可扩展的可信赖数据驱动裁判和运动员认证流程，通过结合这些功能，该框架为体育领域的公平、问责和人机协同AI设定了新的标准。
## 609. `cs.CV` - 带有注意剪枝的集成以实现具有不确定性感知的高效变压器 [PDF](https://arxiv.org/pdf/2510.18358), [HTML](https://arxiv.org/abs/2510.18358)
### Authors
Firas Gabetni,Giuseppe Curci,Andrea Pilzer,Subhankar Roy,Elisa Ricci,Gianni Franchi
### Background
在安全关键设置中部署深度神经网络时，不确定性量化（UQ）是必不可少的。尽管像深度集成这样的方法在UQ性能上表现出色，但它们的高计算和内存成本阻碍了其扩展到大型模型。因此，需要更高效的方案来保留UQ性能同时提高模型的效率。
### Innovation
该论文提出了Hydra Ensembles，这是一种高效的基于Transformer的集成模型。Hydra Ensembles通过剪枝注意力头来生成多样化的成员，然后通过一种新的分组全连接的多头注意力机制进行合并。这种模型在推理速度接近单一网络的同时，能够与深度集成相比拟或超越其不确定性量化性能，而不需要从头训练。
### Conclusion
实验表明，Hydra Ensembles在图像和文本分类任务中表现出一致的改进，尤其是在对ImageNet-1k的零样本分类中超越了现有的最先进的方法，且不需要额外的训练。此外，研究还深入分析了剪枝的影响，指出朴素的剪枝方法会损害校准，而Hydra Ensembles保留了Robust的不确定性。
## 610. `cs.CV` - 从竞争到协同：解锁用于主题驱动图像生成的强化学习 [PDF](https://arxiv.org/pdf/2510.18263), [HTML](https://arxiv.org/abs/2510.18263)
### Authors
Ziwei Huang,Ying Shu,Hao Fang,Quanyu Long,Wenya Wang,Qiushi Guo,Tiezheng Ge,Leilei Gan
### Background
主题驱动的图像生成模型面临着保留身份（保真度）和遵循提示（编辑性）之间的根本权衡。虽然在线强化学习（RL），特别是GPRO，提供了有希望的解决方案，但直接应用GPRO会导致竞品降级，这是因为简单的线性奖励聚合机制会导致矛盾的梯度信号和与扩散过程时间动态的不一致。为了克服这些限制，作者提出了一个新型框架Customized-GRPO，它具有两项创新：同步意识奖励塑形（SARS）和时间意识动态权重（TDW）机制。前者通过非线性机制明确惩罚矛盾的奖励信号，放大协同的奖励信号，提供更清晰和决断的梯度；后者通过优先考虑早期遵循提示，后期保持身份，使优化压力与模型的时间动态保持一致。
### Innovation
提出了Customized-GRPO框架，包括两种创新：(i)同步意识奖励塑形（SARS），这是一种非线性机制，明确惩罚矛盾的奖励信号并放大协同的奖励信号，提供更清晰和决断的梯度。(ii)时间意识动态权重（TDW），通过优先考虑早期的提示跟随和后期的身份保存，使优化压力与模型的时间动态保持一致。这些创新解决了直接应用GPRO的矛盾梯度信号和时间动态不一致的问题。
### Conclusion
大规模实验表明，该方法显著优于简单的GRPO基线，成功缓解了竞品降级的问题。模型实现了更优的平衡，生成的图像既能保留关键身份特征又能准确遵循复杂的文本提示。
## 611. `cs.CV` - CUARewardBench：评估计算机使用代理的奖励模型基准 [PDF](https://arxiv.org/pdf/2510.18596), [HTML](https://arxiv.org/abs/2510.18596)
### Authors
Haojia Lin,Xiaoyu Tan,Yulei Qin,Zihan Xu,Yuchen Shi,Zongyi Li,Gang Li,Shaofei Cai,Siqi Cai,Chaoyou Fu,Ke Li,Xing Sun
### Background
计算机使用代理（CUAs）通过与操作系统和软件界面的自然交互完成任务。现有脚本验证器的应用受到可扩展性有限和不能提供逐步评估的限制。奖励模型被视为替代方案，但对于CUA评估的有效性仍是未知领域。因此，需要一个新的基准来评估这两种模型，并提供繁琐的分析和见解，以改进现有模型的不足之处。
### Innovation
提出了 CUARewardBench，其贡献包括：（1）首个全面的CUA奖励基准；（2）包括10个软件类别和7种代理架构的多样、实际且可靠的数据集；（3）通过广泛的实验揭示了视觉推理能力不足、知识缺陷等关键问题，以及通用的视觉语言模型在奖励评估中优于专门的CUA模型；（4）基于全面分析提出的统一提示集（UPE），通过严格的统一投票和策略性的提示模板配置，显著提高了奖励模型的可靠性。
### Conclusion
UPE在ORM和PRM上均表现优异，精度分别为89.8%和81.7%，NPV分别为93.3%和85.1%，显著优于单个视觉语言模型和传统的集成方法。
## 612. `cs.CV` - 为心脏传感器贴片原型设计端到端多模态 Tiny-CNN [PDF](https://arxiv.org/pdf/2510.18668), [HTML](https://arxiv.org/abs/2510.18668)
### Authors
Mustafa Fuad Rifet Ibrahim,Tunc Alkanat,Maurice Meijer,Felix Manthey,Alexander Schlaefer,Peer Stelldinger
### Background
大多数心血管疾病可以通过早期检测病症和风险因素而得到预防。穿戴式传感器设备，如传感器贴片，能够监测这些症候而不影响患者的自由和舒适度。然而，传感器数据的分析必须是稳健、可靠的，并且高效精确。深度学习方法可以自动化数据解释，减轻临床人员的负担。
### Innovation
本文分析了在资源受限的医疗边缘设备上应用深度学习模型对同步心电图（ECG）和心脏音图（PCG）记录进行分类的可行性。提出了一种卷积神经网络，采用早期数据融合来解决二分类问题，并且在Physionet挑战2016数据集上进行训练和验证。与最先进的技术相比，该模型的内存占用和计算成本降低了三个数量级，同时保持了竞争性精度。通过分析微控制器和实验传感器设备设置下的能耗，证明了该模型在设备上的推理可以比连续数据流更节能。
### Conclusion
本文展示了如何在资源限制的医疗边缘设备上实施一个基于早期数据融合的卷积神经网络，用于同步ECG和PCG记录的分类，从而实现更高效的监测和分析，确认了本方法可以在微控制器和实验传感器设备上进行高效推理，具有节能优势。
## 613. `cs.CV` - LightMem：轻量级高效增强记忆生成 [PDF](https://arxiv.org/pdf/2510.18866), [HTML](https://arxiv.org/abs/2510.18866)
### Authors
Jizhan Fang,Xinle Deng,Haoming Xu,Ziyan Jiang,Yuqi Tang,Ziwen Xu,Shumin Deng,Yunzhi Yao,Mengru Wang,Shuofei Qiao,Huajun Chen,Ningyu Zhang
### Background
尽管大型语言模型（LLMs）具有显著的能力，但在动态和复杂环境中，它们难以有效利用历史交互信息。现有的记忆系统能够通过引入持久的信息存储、检索和利用机制使LLMs超越无状态的交互，然而这些系统往往会导致大量的时间与计算开销。本文基于Atkinson-Shiffrin的人类记忆模型，介绍了一个新的记忆系统——LightMem，该系统在记忆系统的性能与效率之间取得平衡，以解决现有问题。
### Innovation
LightMem 模型借鉴了Atkinson-Shiffrin的人类记忆模型，设计了一种轻量级且高效的记忆系统。它将记忆分为三个互补阶段：首先通过轻量级压缩快速筛选无关信息，并按主题分组；其次，话题感知的短期记忆会对这些主题分组进行组织和总结，以获取结构化的访问内容；最后，带有睡眠时更新的长期记忆采用离线程序来解耦聚合与在线推理。实验结果显示，与强大基线相比，LightMem在准确率上提高了10.9%，同时减少了高达117倍的Token使用，159倍的API调用，以及超过12倍的运行时间。
### Conclusion
LightMem 验证了轻量级且高效的记忆系统的可行性，并通过实验证明了其在保留性能的同时大幅减少资源消耗的效果。
## 614. `cs.CV` - Seg the HAB: Language-Guided Geospatial Algae Bloom Reasoning and Segmentation [PDF](https://arxiv.org/pdf/2510.18751), [HTML](https://arxiv.org/abs/2510.18751)
### Authors
Patterson Hsieh,Jerry Yeh,Mao-Chi He,Wen-Han Hsieh,Elvis Hsieh
### Background
气候变化加剧了有害藻华（HAB），尤其是蓝细菌的发生，这些藻华威胁着水生生态系统和人类健康，通过耗氧、毒素释放和破坏海洋生物多样性。传统的监测方法，如手工采样，仍然劳动密集型且在空间和时间覆盖方面有限。最近的视觉语言模型（VLMs）在遥感中的进展显示出了能够扩展的AI驱动解决方案潜力，但在图像推理和藻华严重程度量化方面仍面临挑战。
### Innovation
提出了一个结合遥感图像理解和严重程度估计的ALGae Observation and Segmentation (ALGOS)系统，该系统整合了GeoSAM辅助的人类评估用于高质量分割掩模的数据整理，并使用NASA提供的蓝细菌综合手动标签（CAML）来微调视觉语言模型进行严重程度预测。研究表明，ALGOS在分割和分级严重程度估计上都表现稳健，朝着实用且自动化的蓝细菌监测系统迈出了重要一步。
### Conclusion
ALGOS系统在分割和严重程度估计方面表现出稳健的表现，为实际且自动化的蓝细菌监测系统的开发奠定了基础。
## 615. `cs.CV` - 使用多模态表示学习协作知识的息肉再识别 [PDF](https://arxiv.org/pdf/2408.05914), [HTML](https://arxiv.org/abs/2408.05914)
### Authors
Suncheng Xiang,Jiale Guan,Shilun Cai,Jiacheng Ruan,Dahong Qian
### Background
息肉内镜图像的再识别旨在在多视角和不同内镜设备获取的图像中匹配同一息肉，这对于计算机辅助诊断预防和治疗结直肠癌至关重要。然而，传统的目标再识别方法直接使用在ImageNet上训练的CNN模型，对于内镜数据集通常产生不尽如人意的检索性能，主要是由于数据域间的巨大差异。另外，这些解决方案通常基于单一的视觉样本学习单模态表示，未能利用来自其他模态的互补信息。
### Innovation
提出了一种新颖的深度多模态协作学习框架DMCL，用于息肉再识别。该框架通过端到端训练引入动态多模态特征融合策略，利用优化的视觉-文本表示进行多模态融合，有效促进了多模态知识的协作并增强了医学场景下的泛化能力。实验表明，多模态设置比最先进的单模态再识别模型具有明显优势，尤其是在结合协同多模态融合策略时。
### Conclusion
实验结果证明了DMCL框架的优势，特别是在建立多模态融合策略时，相比于最先进的单模态再识别模型，多模态设置具有显著好处。代码已经在GitHub上公开。
## 616. `cs.CV` - H3D-DGS: 探索异构3D运动表示以实现可变形3D高斯散点图 [PDF](https://arxiv.org/pdf/2408.13036), [HTML](https://arxiv.org/abs/2408.13036)
### Authors
Bing He,Yunuo Chen,Guo Lu,Qi Wang,Qunshan Gu,Rong Xie,Li Song,Wenjun Zhang
### Background
3D场景重构是3D视觉领域中的一个持续挑战。目前有效的可变形3D高斯散点图方法可以实现实时渲染和高视觉保真度。然而，这些方法主要依赖于基于梯度的优化来处理所有运动信息，这在处理具有复杂运动的真实世界数据集时导致难以收敛。
### Innovation
提出异构3D控制点（H3D控制点），其属性通过混合使用光流反投影和基于梯度的方法来获取。这种设计将直接可观察的运动部分与几何遮挡的部分分离。具体而言，可以通过光流反投影直接获得投影到图像平面的3D运动部分，而不可见的部分则通过基于梯度的方法优化精炼。实验结果表明，该方法在Neu3DV和CMU-Panoptic数据集上优于最先进的可变形3D高斯散点图技术，并且仅需100次迭代即可收敛，每帧处理速度为2秒，使用单个NVIDIA RTX 4070 GPU。
### Conclusion
本研究通过引入H3D控制点，提供了一种新的异构3D运动表示方法，显著提升了变形3D高斯散点图的性能和效率。
## 617. `cs.CV` - 当大规模语言模型步入三维世界：多模态大型语言模型在三维任务中的综述与元分析 [PDF](https://arxiv.org/pdf/2405.10255), [HTML](https://arxiv.org/abs/2405.10255)
### Authors
Xianzheng Ma,Brandon Smart,Yash Bhalgat,Shuai Chen,Xinghui Li,Jian Ding,Jindong Gu,Dave Zhenyu Chen,Songyou Peng,Jia-Wang Bian,Philip H Torr,Marc Pollefeys,Matthias Nießner,Ian D Reid,Angel X. Chang,Iro Laina,Victor Adrian Prisacariu
### Background
随着大规模语言模型（LLMs）的发展，它们与三维空间数据（3D-LLMs）的整合已经取得了快速进展，提供了前所未有的理解和与物理空间交互的能力。已有研究表明，LLMs在处理、理解和生成三维数据方面具有独特的优势，如上下文学习、逐步推理、开放式词汇能力和广泛的先验知识，能够显著推进在具身人工智能（AI）系统中的空间理解和交互。文章综述了各种3D数据表示形式，如点云和神经辐射场（NeRF），探讨了它们与LLMs的整合，用于3D场景理解、图像描述、问答和对话，以及基于LLMs的代理在空间推理、规划和导航任务上的应用。
### Innovation
该论文对3D和语言集成方法进行了全面的综述，着重强调了LLMs的独特优势和三维空间交互的潜力。通过对多种3D数据表示形式的深入研究，该研究揭示了3D-LLMs在理解复杂三维世界方面的进步，同时也指出了尚未实现的潜力，以及需要进一步探索的新方法。
### Conclusion
本文旨在为未来的研究指明方向，探索和扩大3D-LLMs在理解与交互复杂三维世界的能力。为了支持这篇综述，我们建立了一个项目页面，列出了与本文主题相关的研究文献：this https URL.
## 618. `cs.CV` - 3D Audio-Visual Segmentation [PDF](https://arxiv.org/pdf/2411.02236), [HTML](https://arxiv.org/abs/2411.02236)
### Authors
Artem Sokolov,Swapnil Bhosale,Xiatian Zhu
### Background
在嵌入式人工智能领域，识别场景中的发声物体是一个长期的目标，具备广泛的机器人技术和AR/VR/MR应用。目前，同步摄像和麦克风传感器的Audio-Visual Segmentation (AVS)技术已经取得了进展，但缺乏从2D图像到3D场景的映射，这限制了其实用性。
### Innovation
该研究引入了一个新的研究问题，即3D Audio-Visual Segmentation (3DAVS)，扩展了现有的AVS到3D输出空间。研究团队通过重新利用Habitat模拟器，创建了首个基于模拟的基准——3DAVS-S34-O7，提供了实景观测的3D场景环境以及空间音频注释。此外，提出了EchoSegnet方法，该方法通过将预训练的2D视听基础模型的现有知识与3D视觉场景表示相结合，实现空间音频感知的掩码对齐和改进。
### Conclusion
广泛的实验表明，EchoSegnet能够在新基准上有效分割3D空间中的发声物体，代表了嵌入式AI领域的重要进展。
## 619. `cs.CV` - 基础知识治愈个性化: 通过隐藏的基础知识提高个性化模型的提示一致性 [PDF](https://arxiv.org/pdf/2411.15277), [HTML](https://arxiv.org/abs/2411.15277)
### Authors
Yiyang Cai,Zhengkai Jiang,Yulong Liu,Chunyang Jiang,Wei Xue,Yike Guo,Wenhan Luo
### Background
面部个性化面临着在保持身份真实性的同时不破坏基础模型提示一致性的挑战。主流个性化模型使用身份嵌入将身份信息整合到注意力机制中。然而，初步研究发现，身份嵌入会削弱其他提示中令牌的有效性，限制了高提示一致性和属性级可控性。尽管取消身份嵌入，个性化模型仍然能够精确控制面部属性，这表明基础模型的知识可以用来矫正个性化模型中对齐不良的提示一致性。
### Innovation
本文提议FreeCure框架，通过引入双重推理范式和基础感知自注意力模块相结合的方法，利用基础模型的知识提高个性化模型的提示一致性，同时保留其原始的身份完整性。FreeCure无需训练，可以无缝集成到基于Stable Diffusion和FLUX的现有流行个性化模型之中，并能显著提升面部个性化模型的提示一致性。
### Conclusion
FreeCure在保持面部个性化模型原始身份真实性的前提下，持续展示出显著提高提示一致性的效果。
## 620. `cs.CV` - Med-2E3: 一种增强的3D医学多模态大语言模型 [PDF](https://arxiv.org/pdf/2411.12783), [HTML](https://arxiv.org/abs/2411.12783)
### Authors
Yiming Shi,Xun Zhu,Kaiwen Wang,Ying Hu,Chenyi Guo,Miao Li,Ji Wu
### Background
3D医学图像分析对于现代医疗保健至关重要，但传统的为特定任务设计的模型由于在多种临床场景之间的泛化能力有限而显得不足。多模态大型语言模型（MLLMs）提供了应对这些挑战的潜在解决方案。然而，现有的MLLMs在充分利用3D医学图像中嵌入的丰富层次信息方面存在局限性。基于临床实践，我们提出了一种Med-2E3模型，它结合了3D和2D编码器架构，旨在综合考虑3D空间结构和2D平面内容，以更有效地聚合2D特征。
### Innovation
Med-2E3是首款结合3D和2D特征的大规模医学多模态大语言模型，它通过设计Text-Guided Inter-Slice (TG-IS)评分模块，根据切片内容和任务指令评估每个2D切片的注意力，以实现任务特定的关注分布。实验表明，Med-2E3在大规模开放源3D医学多模态数据集上显著优于当前最先进的模型。
### Conclusion
Med-2E3模型通过融合3D和2D信息，在3D医学图像分析中展示出更高的性能，并通过TG-IS模块实现了任务特定的关注分配，证明了其在医疗应用中的潜力。
## 621. `cs.CV` - 点云隐式神经压缩 [PDF](https://arxiv.org/pdf/2412.10433), [HTML](https://arxiv.org/abs/2412.10433)
### Authors
Hongning Ruan,Yulin Shao,Qianqian Yang,Liang Zhao,Zhaoyang Zhang,Dusit Niyato
### Background
点云由于能够准确表示三维对象和场景而引起了广泛的应用。然而，高效地压缩不规则、高精度的点云数据仍然是一个重大挑战。
### Innovation
提出了NeRC$^3$框架，利用隐式神经表示（INRs）来编码稠密点云的几何特征和属性。通过两个基于坐标的神经网络实现：一个映射空间坐标到体素占用，另一个映射被占用的体素到其属性，从而隐式表示体素化点云的几何特征和属性。此外，通过4D时空表示4D-NeRC$^3$技术实现动态点云的压缩，减少了时间冗余。
### Conclusion
实验结果表明，NeRC$^3$相比基于八叉树的G-PCC标准和现有INR-based方法，在静态点云压缩方面表现更优；4D-NeRC$^3$在动态点云几何压缩性能方面优于最新的G-PCC和V-PCC标准，同时在联合几何和属性压缩方面表现出接近最先进的学习方法的性能。
## 622. `cs.CV` - 掌握任意区域：迈向多模态大语言模型的精确、情境化像素理解 [PDF](https://arxiv.org/pdf/2510.18876), [HTML](https://arxiv.org/abs/2510.18876)
### Authors
Haochen Wang,Yuhao Wang,Tao Zhang,Yikang Zhou,Yanwei Li,Jiacong Wang,Ye Tian,Jiahao Meng,Zilong Huang,Guangcan Mai,Anran Wang,Yunhai Tong,Zhuochen Wang,Xiangtai Li,Zhaoxiang Zhang
### Background
虽然多模态大型语言模型（MLLMs）在整体理解方面表现出色，但在捕捉复杂场景的密集世界方面仍存在挑战，特别是需要对复杂的细节和对象间的关系进行精细分析。已有基于区域级别的MLLMs取得了进展，但这些方法通常仅优化对给定区域的理解，忽略了关键的全局上下文。基于此，该研究引入了“Grasp Any Region（GAR）”以实现全面的区域级视觉理解。GAR通过有效的RoI对齐特征回放技术，实现了（1）精准感知，通过利用必要的全局上下文，（2）建模多提示间的交互作用，并随之实现了（3）高级组合推理，以回答任何区域的特定自由形式问题，从而从被动描述转向积极参与对话。另外构建了GAR-Bench基准，不仅提供了更准确的单一区域理解评估，还通过测量跨多个区域的交互与复杂推理进行了评估。
### Innovation
引入了Grasp Any Region（GAR）用于全面的区域级视觉理解，增强了单个区域的理解能力并衡量了跨多个区域的交互与复杂推理。GAR通过有效的RoI对齐特征回放技术，实现了精准感知、多提示交互作用的建模以及高级组合推理。此外，GAR-1B不仅保持了最先进的图说能力，而且在多模态LMLs上表现出色，并在GAR-Bench-VQA上超越了InternVL3-78B。同时，在零样本情况下，GAR-8B在视频参考（VideoRefer-BenchQ）上优于领域特异性的VideoRefer-7B，表明其能力强，具有易转移性。
### Conclusion
GAR不仅保持了最先进的图说能力，还具有出色的多提示关系建模能力，并超越了现有模型。GAR-Bench提供了更准确的单一区域理解评估和跨多个区域的交互与复杂推理测量，进一步推动了多模态LMLs的发展。
## 623. `cs.CV` - 深度学习在掌纹识别中的全面综述 [PDF](https://arxiv.org/pdf/2501.01166), [HTML](https://arxiv.org/abs/2501.01166)
### Authors
Chengrui Gao,Ziyuan Yang,Wei Jia,Lu Leng,Bob Zhang,Andrew Beng Jin Teoh
### Background
掌纹识别作为一种突出的生物识别技术，在多种场景中得到了广泛应用。传统的手工方法在掌纹识别中通常在表示能力上存在不足，因为它们严重依赖研究人员的先验知识。尽管深度学习已经在多个领域取得了显著成功，但现有的综述主要关注掌纹识别中的特定任务，而很少全面探讨基于深度学习的方法。
### Innovation
本文通过全面回顾基于深度学习的掌纹识别的最新进展，填补了现有研究的空白。文章系统地考察了掌纹识别中的关键技术任务，包括感兴趣区域分割、特征提取以及安全/隐私相关挑战，并指出当前的研究挑战，同时揭示了未来研究的潜在机会。
### Conclusion
通过总结最先进的进展，本文为研究人员提供了一项有价值的资源，使他们能够了解先进技术并推动掌纹识别的创新。
## 624. `cs.CV` - DualHash：具有理论保证的随机 primal-dual 深度哈希算法 [PDF](https://arxiv.org/pdf/2510.18218), [HTML](https://arxiv.org/abs/2510.18218)
### Authors
Luxuan Li,Xiao Wang,Chunfeng Cui
### Background
深度哈希将高维特征向量转换为紧凑的二进制代码，以实现大规模检索的高效性。一个基础挑战是量化过程的离散性质，导致生成的二进制码难以优化。现有的方法通常直接优化 W 型正则化项，但没有收敛保证。虽然邻近梯度方法提供了一种有前景的解决方案，但 W 型正则化项与神经网络输出之间的耦合导致复合形式缺乏闭合形式的邻近解。因此，现有的解决方案缺乏理论保证和效率。
### Innovation
本文提出了一个随机原始-对偶哈希算法，称为 DualHash，提供了严格的复杂度界。通过芬切尔对偶，将非凸 W 型正则化优化部分转化至对偶空间，从而得到一个具有闭式解的邻近操作符。文章还推导出了两种算法实例：一个是带有动量加速度的版本，复杂度为 Θ(λ^{-4})，另一个是使用方差减缩的改进版本，复杂度为 Θ(λ^{-3})。实验结果表明 DualHash 在三个图像检索数据库上的表现优于现有方法。
### Conclusion
DualHash 通过引入严格的理论保证和高效的算法实例，提供了一种有效的深度哈希解决方案，能够优化 W 型正则化优化，适用于大规模图像检索。
## 625. `cs.CV` - RAD: 通过大规模3DGS强化学习训练端到端驾驶策略 [PDF](https://arxiv.org/pdf/2502.13144), [HTML](https://arxiv.org/abs/2502.13144)
### Authors
Hao Gao,Shaoyu Chen,Bo Jiang,Bencheng Liao,Yiang Shi,Xiaoyang Guo,Yuechuan Pu,Haoran Yin,Xiangyu Li,Xinbang Zhang,Ying Zhang,Wenyu Liu,Qian Zhang,Xinggang Wang
### Background
现有的端到端自动驾驶（AD）算法通常遵循模仿学习（IL）范式，面临因果混淆和开环差距等挑战。
### Innovation
提出了一种基于3DGS的闭合回路强化学习（RL）框架RAD，通过利用3DGS技术构建逼真的数字世界复制品，使AD策略能够广泛探索状态空间并学习处理离分布情况。还设计了专门的奖励来引导策略有效应对安全关键事件并理解真实的因果关系，将IL纳入RL训练作为正则化项，并提出了一个包含多样化且未见过的3DGS环境的闭环评估基准。
### Conclusion
RAD在大多数闭环指标中都显示出更强的性能，尤其是碰撞率降低了3倍。在附录中提供了丰富的闭环结果，代码可在指定链接获取，以促进未来的研究。
## 626. `cs.CV` - 逐步设计范式的基础：集成持续学习、斟酌行为和可解释性的设计 [PDF](https://arxiv.org/pdf/2502.13935), [HTML](https://arxiv.org/abs/2502.13935)
### Authors
Zeki Doruk Erden,Boi Faltings
### Background
当前机器学习系统在关键领域存在内在局限性，特别是在持续学习、信息重用、可解释性和与有意识行为的集成方面。这些挑战正在受到越来越大的关注。
### Innovation
提出了一种系统设计，其灵感来源于进化发育生物学的基本原理，旨在解决当前方法的关键限制。设计包括三个核心组件：无需梯度的学习机制（模型构建者），能够进行目标导向动作的规划器，以及能够将复杂行为分解为层次结构的行为封装机制。
### Conclusion
通过在简单测试环境中的原理验证以及使用MNIST数据集进行形状检测任务，证明该框架在有机方式下同时解决了当前机器学习系统的多个主要局限性。
## 627. `cs.CV` - WMamba: 基于Mamba的波let面部伪造检测 [PDF](https://arxiv.org/pdf/2501.09617), [HTML](https://arxiv.org/abs/2501.09617)
### Authors
Siran Peng,Tianshuo Zhang,Li Gao,Xiangyu Zhu,Haoyuan Zhang,Kai Pang,Zhen Lei
### Background
随着深度伪造生成技术的快速发展，迫切需要开发出稳健的面部伪造检测算法。最近的研究表明，小波分析可以增强伪造检测器的泛化能力。小波能够捕捉到关键的面部轮廓，这些轮廓往往是细长、精细且全局分布的，可以在频域中巧妙地隐藏细微的伪造痕迹。现有的基于小波的方法未能充分利用小波数据的特殊性质，导致特征提取不充分，检测性能有限.
### Innovation
我们提出了一种新的基于小波的特征提取器WMamba，它基于Mamba架构并具有两大创新点。首先，我们提出了动态轮廓卷积（DCConv），它使用特制的可变形内核来适应性地建模细长的面部轮廓。第二，通过利用Mamba架构，该方法可以在线性复杂度下捕捉到长距离的空间关系，这使得从小型图像块中提取细粒度的、全球分布的伪造痕迹变得可能.
### Conclusion
广泛的实验表明，WMamba达到了最先进的（SOTA）性能，突显了其在面部伪造检测方面的有效性。
## 628. `cs.CV` - 基于重建误差指导的视图选择方法在多视图3D物体重建中的视角鲁棒性 [PDF](https://arxiv.org/pdf/2412.11428), [HTML](https://arxiv.org/abs/2412.11428)
### Authors
Qi Zhang,Zhouhang Luo,Tao Yu,Hui Huang
### Background
视图转换鲁棒性（VTR）对于基于深度学习的多视图3D物体重建模型至关重要，表明了在输入具有各种视图变换的情况下，方法的稳定性。不过，现有研究很少关注多视图3D物体重建的视图变换鲁棒性问题。目前提高模型VTR的一个直接方法是生成更多的视图变换数据，并将其加入模型训练中。最近大规模视觉模型，尤其是Stable Diffusion模型，提供了通过单张图像输入生成3D模型或合成新型视图图像的巨大潜力。然而，直接在推理中部署这些模型会消耗大量的计算资源，并且它们对视图变换的鲁棒性也不一定得到保证。为了充分利用Stable Diffusion模型的功能，我们提出使用Stable Diffusion模型生成新型视图以提高视图变换鲁棒性。
### Innovation
本文提出了一种基于重建误差指导的视图选择方法，通过考虑3D预测的重建误差的空间分布来选择覆盖重建误差最多的视图，以提高模型的视图变换鲁棒性。该方法在含有大量视图变换的集合上进行训练和测试，以验证3D重建模型对视图变换的鲁棒性。
### Conclusion
大量实验表明，提出的方法可以优于最先进的3D重建方法和其他种类的视图变换鲁棒性对比方法。代码可在指定链接处获取。
## 629. `cs.CV` - scSplit: 在荧光显微镜图像分解中引入严重性意识 [PDF](https://arxiv.org/pdf/2503.22983), [HTML](https://arxiv.org/abs/2503.22983)
### Authors
Ashesh Ashesh,Florian Jug
### Background
荧光显微镜在生命科学中的进步成为一个关键驱动力，但同时也受到技术限制。为克服这些限制，最近提出了计算多重成像技术，这种技术可以在单张图像中捕捉到多个细胞结构，并在后期分离。现有的图像分解方法在一组叠加输入图像及其相应的分离目标图像上进行了训练。关键之处在于，给定输入图像的叠加强度（混合比）对值通常是未知的。然而，现有方法是在固定的叠加输入强度比上进行训练的，因此无法理解荧光显微镜中可能出现的相对强度范围。
### Innovation
本文提出了一种名为scSplit的新方法，该方法意识到上述混合比例的严重性。该方法基于InDI，一种流行的图像恢复迭代方法，且该方法将未知的混合比例作为起点。scSplit引入了一个适当的训练回归网络来预测给定输入图像的降解水平（混合比）以及一种针对降解的特定归一化模块，使所有混合比下的推断具有降解意识。
### Conclusion
该方法成功解决了荧光显微镜中的两个相关任务，即图像分割和溢出去除，并通过五个公共数据集实证证明了scSplit的有效性。源代码和预训练模型托管在相应链接。
## 630. `cs.CV` - H3DE-Net: 医学影像中高效且准确的3D特征点检测 [PDF](https://arxiv.org/pdf/2502.14221), [HTML](https://arxiv.org/abs/2502.14221)
### Authors
Zhen Huang,Tao Tang,Ronghao Xu,Yangbo Wei,Wenkai Yang,Suhua Wang,Xiaoxin Sun,Han Li,Qingsong Yao
### Background
3D特征点检测是医学图像分析中的关键任务，准确检测解剖特征点对于后续的医学成像任务至关重要。然而，主流的深度学习方法难以同时捕捉细微的局部特征、建模全局空间关系，并保持准确性和计算效率之间的平衡。局部特征提取需要捕获细微的解剖细节，而全局建模则需要理解复杂解剖结构中的空间关系。3D体积的高维特性进一步加剧了这些挑战，因为特征点分布稀疏，导致计算成本高昂。因此，在医学图像分析中实现高效的且精确的3D特征点检测仍然是一个迫切的挑战。
### Innovation
我们提出了一种新颖的框架H3DE-Net，它结合了CNNs进行局部特征提取和一个轻量级的注意力机制，以高效地捕获3D体积数据中的全局依赖性。该机制采用分层路由策略来降低计算成本，同时保持全局上下文建模。据我们所知，H3DE-Net是第一个将轻量级注意力机制与CNNs结合的3D特征点检测模型。此外，多尺度特征融合的集成进一步提高了检测的准确性和鲁棒性。在公开的CT数据集的实验结果表明，H3DE-Net实现了最先进的性能（SOTA），在特征点缺失或复杂解剖变异的情况下显著提高了准确性和鲁棒性。
### Conclusion
我们已经开源了我们的项目，包括代码、数据和模型权重。
## 631. `cs.CV` - ITVTON：基于集成图像和文本的虚拟试穿扩散变换器 [PDF](https://arxiv.org/pdf/2501.16757), [HTML](https://arxiv.org/abs/2501.16757)
### Authors
Haifeng Ni,Ming Xu
### Background
虚拟试穿旨在无缝地将服装应用于人物图像，近年来，基于扩散模型的方法取得了显著进展。然而，现有方法通常依赖于重复的骨干网络或附加的图像编码器来提取服装特征，这增加了计算成本和网络复杂度。
### Innovation
本文提出了一种高效的框架ITVTON，通过使用扩散变换器（DiT）作为单个生成器来提高图像保真度。通过沿宽度维度连接服装和人物图像，并结合两者文本描述，ITVTON有效地捕捉到了服装与人物的互动，并保持了现实性。为减少计算成本，训练仅限制在单个扩散变换器（Single-DiT）块内的注意力参数内。实验结果表明，ITVTON在定性和定量上均超过了基线方法，为虚拟试穿设定了一项新标准。此外，在IGPair的10,257个图像对上进行的实验验证了其在实际场景中的鲁棒性。
### Conclusion
ITVTON方法在虚拟试穿领域达到了更高的图像保真度和效率，同时展示出了良好的鲁棒性，确立了新的标准。
## 632. `cs.CV` - REPA-E：通过潜扩散变换器实现VAE的端到端调优 [PDF](https://arxiv.org/pdf/2504.10483), [HTML](https://arxiv.org/abs/2504.10483)
### Authors
Xingjian Leng,Jaskirat Singh,Yunzhong Hou,Zhenchang Xing,Saining Xie,Liang Zheng
### Background
传统的深度学习理论表明，当可能的情况下，端到端训练往往更佳。然而，对于潜扩散变换器，使用标准的扩散损失同时训练VAE和扩散模型的端到端训练是无效的，甚至会损害最终性能。
### Innovation
提出了一种新的训练方法——代表对齐损失（REPA）端到端训练（REPA-E），用于同时调优VAE和扩散模型。该方法显著加速了扩散模型的训练速度（分别比标准REPA和vanilla方法快17倍和45倍），并改善了VAE本身的总体结构和下游生成性能。最后，该方法在ImageNet 256x256数据集上达到了新的性能峰值，FID分数为1.12（有无条件引导）。
### Conclusion
提出了名为REPA-E的训练方法，通过使用代表对齐损失解锁VAE的端到端调优。该方法在端到端训练中不仅能提高扩散模型的训练效率，还能提升VAE的性能，最终在ImageNet数据集上达到新的性能记录。
## 633. `cs.CV` - VLLFL：基于视觉语言模型的轻量级联邦学习框架以应对智能农业挑战 [PDF](https://arxiv.org/pdf/2504.13365), [HTML](https://arxiv.org/abs/2504.13365)
### Authors
Long Li,Jiajia Li,Dong Chen,Lina Pu,Haibo Yao,Yanbo Huang
### Background
在现代智能农业中，对象检测对于实现自动化、精确农业和资源监控起到了关键作用。通过识别作物健康状况、病虫害以及优化收获过程，准确的对象检测提高生产效率和可持续性。然而，训练对象检测模型通常需要大规模数据收集，这会引发隐私问题，尤其是当敏感的农业数据分散在不同的农场时。
### Innovation
本文提出了一种基于视觉语言模型（VLM）的轻量级联邦学习框架（VLLFL），以应对上述挑战。该框架利用了VLM的泛化能力和上下文感知检测能力，并借助联邦学习的隐私保护特性。通过训练一个紧凑的提示生成器来增强部署在不同农场上的VLM的性能，VLLFL能够在保护隐私的同时降低通信开销。实验结果表明，VLLFL在性能上提升了14.53%，通信开销减少了99.3%，并且适用于识别各种水果和检测农业有害动物等多种任务。
### Conclusion
VLLFL框架提供了一种高效、可扩展且保护隐私的解决方案，特别适用于农业应用，能够在不同农场之间共享训练，以优化和服务农业智能化需求。
## 634. `cs.CV` - VisualQuality-R1: 通过强化学习排序实现的视觉质量评估 [PDF](https://arxiv.org/pdf/2505.14460), [HTML](https://arxiv.org/abs/2505.14460)
### Authors
Tianhe Wu,Jian Zou,Jie Liang,Lei Zhang,Kede Ma
### Background
尽管DeepSeek-R1在通过强化学习激励大语言模型的推理和泛化能力方面取得了显著成效，但推理驱动的计算潜力尚未在图像质量评估(IQA)任务中得到充分探索。IQA任务高度依赖视觉推理，而现有的基于判别式深度学习的无参考IQA模型及最近的推理驱动质量回归方法并未完全解决这一问题。
### Innovation
本文提出了一种基于推理的无参考图像质量评估(NR-IQA)模型——VisualQuality-R1，并利用针对视觉质量固有相对性质的排序强化学习算法训练。该模型通过生成每张图像的多个质量评分，使用 Thurnstone 模型下的比较概率计算，并利用连续的保真度度量定义奖励，以替代离散的二元标签。实验表明，VisualQuality-R1 在无参考图像质量评估任务中显著优于现有的基于判别式深度学习的方法及最近的推理驱动质量回归方法，并能够生成与人类一致的质量描述，支持多数据集训练而不需感知尺度对齐。
### Conclusion
VisualQuality-R1 特别适合可靠地评估超分辨率和图像生成等各种图像处理任务中的进展，展示出其在推理驱动的无参考图像质量评估方面的强大能力。
## 635. `cs.CV` - 通过可学习线性外推改进受限几步ystick 不显示”的情况下省略或使用省略号代替“下限”部分下的基于扩散的逆算法 [PDF](https://arxiv.org/pdf/2503.10103), [HTML](https://arxiv.org/abs/2503.10103)
### Authors
Jiawei Zhang,Ziyuan Liu,Leon Yan,Gen Li,Yuantao Gu
### Background
基于扩散的方法在各种逆问题中表现出色，但依赖大量去噪步骤导致计算成本高昂。快速扩散常微分方程（ODE）求解器虽能有效加速扩散采样，但在逆问题中的应用受限，因为现有的逆算法形式多样，且常采用近似和启发式方法，引入显著误差，影响解析求解器的可靠性。现有研究表明，逆问题中的ODE求解器可以采用线性组合结构。在此基础上，本文提出了统一的基于扩散的逆算法的通用形式，并通过可学习线性外推（LLE）方法改进这些算法，使得它们在较少数步骤下仍能保持高效且提升性能。因此，LLE方法优化前驱估计值以改进当前预测，减少逆算法解析求解器的敏感性。实验显示，该方法在多种算法和任务中表现出一致的改进效果，表明其潜力在于提高基于扩散的逆算法的效率和性能。
### Innovation
本文首次系统性地分析了逆问题中ODE求解器的线性组合结构，并据此提出了能够统一涵盖广泛基于扩散的逆算法的通用形式。基于此，我们开发了一种名为Learnable Linear Extrapolation (LLE)的方法，它能够普遍提升任何符合通用形式的基于扩散的逆算法的性能。LLE通过优化组合系数来改进当前预测，使用之前的估计值，减少对解析求解器的敏感性，缓解了逆算法中依赖于大量去噪步骤导致的高计算成本问题。此外，实验验证了LLE方法的有效性，证明了该方法对于基于扩散的逆算法在较少步骤下保持高效和提升表现的潜力。
### Conclusion
本文通过分析和统一基于扩散的逆算法的形式，并结合可学习线性外推方法，提出了一种新的改进策略。实验结果表明，LLE方法能够显著提高现有基于扩散的逆算法的性能和效率，在较少的步骤下也能保持其高效性。这种方法具有广泛的应用前景，能有效减轻逆问题中的计算负担，提高基于扩散的逆算法在实际应用场景中的表现。
## 636. `cs.CV` - 终生学习脊髓分割中形态学漂移的监控 [PDF](https://arxiv.org/pdf/2505.01364), [HTML](https://arxiv.org/abs/2505.01364)
### Authors
Enamundram Naga Karthik,Sandrine Bédard,Jan Valošek,Christoph S. Aigner,Elise Bannier,Josef Bednařík,Virginie Callot,Anna Combes,Armin Curt,Gergely David,Falk Eippert,Lynn Farner,Michael G Fehlings,Patrick Freund,Tobias Granberg,Cristina Granziera,RHSCIR Network Imaging Group,Ulrike Horn,Tomáš Horák,Suzanne Humphreys,Markus Hupp,Anne Kerbrat,Nawal Kinany,Shannon Kolind,Petr Kudlička,Anna Lebret,Lisa Eunyoung Lee,Caterina Mainero,Allan R. Martin,Megan McGrath,Govind Nair,Kristin P. O'Grady,Jiwon Oh,Russell Ouellette,Nikolai Pfender,Dario Pfyffer,Pierre-François Pradat,Alexandre Prat,Emanuele Pravatà,Daniel S. Reich,Ilaria Ricchi,Naama Rotem-Kohavi,Simon Schading-Sassenhausen,Maryam Seif,Andrew Smith,Seth A Smith,Grace Sweeney,Roger Tam,Anthony Traboulsee,Constantina Andrada Treaba,Charidimos Tsagkas,Zachary Vavasour,Dimitri Van De Ville,Kenneth Arnold Weber II,Sarath Chandar,Julien Cohen-Adad
### Background
脊髓形态学测量可以从脊髓分割中获得，这些测量在神经性疾病和脊髓损伤的诊断和预后中具有重要作用。尽管已经开发了多种针对各种对比和病理状况的稳健自动分割方法，但这些方法在使用新数据集更新模型时预测稳定性尚未被评估。对于从健康参与者中提取的规范值，这一稳定性尤为重要。本文介绍了一种使用包含9种不同MRI对比和多种脊髓病理的多中心数据集训练的脊髓分割模型，并提出了一种终生学习框架，以自动监测随模型更新使用额外数据集时的形态学漂移。
### Innovation
本文提出了使用多中心多模态数据集训练的脊髓分割模型，并提出了一种终生学习框架以自动监控模型更新时的形态学漂移。该框架通过自动GitHub Actions工作流记录预测的形态学值，以快速反馈循环开发未来的分割模型。此外，研究发现更新数据库所需的缩放因子在不同椎体水平的切片之间保持稳定，显示了框架监控模型的不同版本之间最小的形态学漂移。
### Conclusion
本文的分割模型在处理挑战性的腰段脊髓病例时优于先前版本和病理特异性模型，平均Dice分数为0.95±0.03。自动监控形态学漂移的工作流建立了快速的反馈循环，以促进未来分割模型的开发。更新数据库所需的缩放因子在不同椎体水平的切片之间几乎保持恒定，显示了框架监控模型版本之间最低的形态学漂移。
## 637. `cs.CV` - Visionary-R1: 使用强化学习减轻视觉推理中的捷径 [PDF](https://arxiv.org/pdf/2505.14677), [HTML](https://arxiv.org/abs/2505.14677)
### Authors
Jiaer Xia,Yuhang Zang,Peng Gao,Yixuan Li,Kaiyang Zhou
### Background
长期以来，AI在学习通用推理能力方面一直面临挑战。近年来，像DeepSeek-R1这样的大型语言模型（LLMs）研究显示，强化学习技术，如GRPO，能够通过简单的问答对使预训练的LLMs具备推理能力。本文旨在通过强化学习和视觉问答对训练视觉语言模型（VLMs），使其在无需显式思维过程（CoT）监督的情况下进行图像数据的推理.
### Innovation
本文提出了一个关键策略，即在要求模型推理前先解释图像，以此来避免模型学习捷径。因此，训练模型遵循“图片描述-推理-答案”的输出格式：首先生成图片的详细描述，随后构造详细的推理链。使用这种方法并仅通过强化学习，在273,000个非思维过程视觉问答对上训练的模型Visionary-R1在多个视觉推理基准测试上优于包括GPT-4o、Claude3.5-Sonnet和Gemini-1.5-Pro在内的强大多模态模型.
### Conclusion
本文研究表明，在视觉推理任务中直接应用强化学习可能导致模型学会捷径，从而减弱其在未见数据分布上的泛化能力。通过鼓励模型在推理前先解释图片，可以显著降低捷径学习的发生，从而使Visionary-R1在多个视觉推理任务中表现出良好的性能。
## 638. `cs.CV` - gen2seg: 生成模型使实例分割具备泛化能力 [PDF](https://arxiv.org/pdf/2505.15263), [HTML](https://arxiv.org/abs/2505.15263)
### Authors
Om Khangaonkar,Hamed Pirsiavash
### Background
生成模型通过从受到扰动的输入中合成连贯的图像，自然地学习理解物体边界和场景组成。但是，如何利用这些生成表示来实现通用感知组织呢？
### Innovation
作者通过对Stable Diffusion和MAE进行微调，并使用实例着色损失来训练无类别实例分割，特别针对室内家具和汽车等特定对象类型。令人惊讶的是，模型在未见过的对象类型和样式上表现出强大的零样本泛化能力，准确地分割了在微调过程中未见过的物体类型和风格，并在许多情况下甚至优于MAE的ImageNet-1K预训练。最好的模型在未见过的对象类型和风格上的性能接近高度监督的SAM，并在分割细小结构和模糊边界时表现更好。
### Conclusion
现有的可提示分割架构或判别预训练模型难以泛化，这表明生成模型学习了一种内在的分组机制，即使没有互联网规模的预训练也能在跨类别和领域中迁移。
## 639. `cs.CV` - Mask图像水印 [PDF](https://arxiv.org/pdf/2504.12739), [HTML](https://arxiv.org/abs/2504.12739)
### Authors
Runyi Hu,Jie Zhang,Shiqian Zhao,Nils Lukas,Jiwei Li,Qing Guo,Han Qiu,Tianwei Zhang
### Background
现有的图像水印方法存在复杂性高、效率低或灵活性不足的问题。新方法MaskWM旨在提出一种简单、高效且灵活的图像水印框架，该框架包含两种变体：MaskWM-D支持全局水印嵌入、水印定位和局部水印提取，适用于篡改检测；MaskWM-ED专注于局部水印嵌入和提取，以增强小区域的鲁棒性，支持细粒度的图像保护。MaskWM以经典的编码-失真层-解码训练范式为基础，通过引入简单的解码阶段遮罩机制，同时在训练期间使用各种类型的遮罩指导解码器学习定位水印并从相应局部区域提取水印。MaskWM-ED进一步通过将遮罩引入编码阶段，引导编码器将水印嵌入指定的局部区域，从而提高对局部攻击的鲁棒性。实验表明，MaskWM在全局和局部水印提取、水印定位和多水印嵌入方面达到了最先进的性能，优于所有现有基准，包括最近的领先局部水印模型WAM，同时保持高视觉质量的水marked图像。此外，MaskWM具有高度的高效性和适应性，仅需单个A6000 GPU的20小时训练即可，相比WAM，具有15倍的计算效率。通过简单调整失真层，MaskWM可以快速微调以满足不同的鲁棒性要求。
### Innovation
MaskWM提出了一种新的简单、高效且灵活的框架，用于图像水印。它包括两种变体，分别适用于不同的应用场景。MaskWM在训练过程中通过引入简单遮罩机制实现全局和局部水印的提取，而MaskWM-ED进一步在编码阶段引入遮罩，提高对局部攻击的鲁棒性。此外，MaskWM相比现有方法具有更高的计算效率和适应性，容易快速调整以满足不同的鲁棒性要求。
### Conclusion
MaskWM框架在全局和局部水印提取、水印定位和多水印嵌入方面达到了最先进的性能，优于所有现有基准模型。它不仅保持了高视觉质量，还具有高度的效率和适应性，训练速度快，调整简单，适用于多种应用场景。
## 640. `cs.CV` - 统一视频融合解决方案：从多帧学习到基准测试 [PDF](https://arxiv.org/pdf/2505.19858), [HTML](https://arxiv.org/abs/2505.19858)
### Authors
Zixiang Zhao,Haowen Bai,Bingxin Ke,Yukun Cui,Lilun Deng,Yulun Zhang,Kai Zhang,Konrad Schindler
### Background
当前大多数图像融合方法处理静态帧，忽略了视频中的时间相关性，导致闪烁和时间不一致性的问题。
### Innovation
提出了一种名为Unified Video Fusion（UniVF）的新型统一框架，利用多帧学习和基于光流的特征变形实现具有信息量和时间一致性性的视频融合。同时，还引入了Video Fusion Benchmark（VF-Bench），这是首个综合基准，涵盖了多曝光、多焦点、红外可见和医疗融合四种视频融合任务。VF-Bench提供通过合成数据生成和现有数据集严谨筛选后的高质量、对齐良好的视频对，并采用统一评估协议同步评估空间质量和时间一致性。实验证明，UniVF在所有任务上都达到了最先进的性能。
### Conclusion
UniVF在VF-Bench的所有任务上均取得了最先进的结果，表明该方法在视频融合中的有效性。
## 641. `cs.CV` - CoLoRA: 对卷积模型高效微调的研究 ── 以光学相干断层成像图像分类为例 [PDF](https://arxiv.org/pdf/2505.18315), [HTML](https://arxiv.org/abs/2505.18315)
### Authors
Mariano Rivera,Angello Hoyos
### Background
本文介绍了一种参数高效的卷积神经网络(CNN)微调方法——CoLoRA（卷积低秩适应）。该方法基于LoRA扩展到卷积层，通过分解核更新为轻量级的深度卷积和点卷积，从而显著减少可训练参数的数量，同时保持原始模型大小不变，有助于加速训练过程并简化模型管理。这项研究针对医学图像分类任务提出了一个新的方法论，特别是在光学相干断层成像(OCT)图像分类方面取得了显著效果。
### Innovation
文章提出了一种名为CoLoRA的新方法，通过将卷积神经网络的参数更新分解为轻量级的深度卷积（depthwise convolution）和点卷积（pointwise convolution），有效地减少了可训练参数的数量，与传统微调相比，参数效率提高了近10倍。CoLoRA不仅保持了原始模型的大小并且允许将更新合并到预训练权重中，保持了推理复杂度的不变。实验结果表明，CoLoRA在VGG16和ResNet50应用在OCTMNISTv2数据集上，达到了比前沿基线模型（如视觉变换器、状态空间模型和科莫哥拉夫-阿诺尔德模型）更高的准确率和AUC值，并且使得每轮训练时间减少了近20%。
### Conclusion
研究表明，CoLoRA提供了一种稳定有效的全参数微调替代方法，适用于医学图像分类任务，特别是对于需要高效利用已有预训练模型和保持推理速度的应用场景更为适用。
## 642. `cs.CV` - DisasterM3: 一个用于灾难损失评估和响应的遥感视觉语言数据集 [PDF](https://arxiv.org/pdf/2505.21089), [HTML](https://arxiv.org/abs/2505.21089)
### Authors
Junjue Wang,Weihao Xuan,Heli Qi,Zhihao Liu,Kunyi Liu,Yuhan Wu,Hongruixuan Chen,Jian Song,Junshi Xia,Zhuo Zheng,Naoto Yokoya
### Background
大型视觉-语言模型（VLMs）在地球视觉领域取得了显著成就。然而，复杂的灾难场景，包括多样化的灾难类型、地理区域和卫星传感器，对VLM的应用提出了新的挑战。为了应对这些挑战，该研究团队整理了一个名为DisasterM3的遥感视觉-语言数据集，用于全球范围内的灾难评估与响应。
### Innovation
DisasterM3数据集包含26,988对双时相卫星图像和123,000对指令对，影响5个大洲，具备多灾种、多传感器、多任务三大特性。该数据集在灾害相关的视觉感知和推理任务中，采用逐步推理的方法，从承载体识别到结构性损害评估，最终生成长报告，填补了目前VLM在灾害领域应用的空白。同时，研究还指出了当前最先进的模型在处理灾害任务时存在的问题，主要是缺乏特定于灾难的语料库、跨传感器差距和不敏感的损害物体计数，针对这些问题，研究对四个VLM进行了微调，展示了稳健的跨传感器和跨灾难泛化能力。
### Conclusion
通过广泛评估14个通用和遥感VLM在基准上的表现，研究发现在灾害任务上最先进的模型存在困难，主要是由于缺乏特定于灾难的语料库、跨传感器差距和对损害物体的不敏感性。基于此，对四个VLM进行了矫形，并在所有任务上取得了稳定的改进，具有稳健的跨传感器和跨灾难泛化能力。代码和数据可以在指定链接处获得。
## 643. `cs.CV` - Pose-free 3D Gaussian splatting via shape-ray estimation [PDF](https://arxiv.org/pdf/2505.22978), [HTML](https://arxiv.org/abs/2505.22978)
### Authors
Youngju Na,Taeyeon Kim,Jumin Lee,Kyu Beom Han,Woo Jae Kim,Sung-eui Yoon
### Background
虽然通用的3D高斯采样能够高效且高质量地渲染未见场景，但它高度依赖于精确的相机姿态以获得准确的几何结构。在真实世界场景中，获得精确的姿态是非常具有挑战性的，这会导致姿态估计的噪声以及几何对齐不准确的问题。现有的方法难以在不依赖准确姿态的情况下保持几何结构的准确性和一致性，这对渲染提出了挑战。
### Innovation
作者提出了一种名为SHARE的无姿态、前馈的3D高斯采样框架。该框架通过联合形状和摄像光线估计来克服使用单一的形状模版方法存在的不确定性。SHARE框架通过构建姿态感知的标准化体素表示，从而无缝地整合了多视图信息，减少了因姿态不精确而导致的对齐误差。同时，利用预先设定的锚点来进行 Gaussian 预测，以增强场景重建，细化粗糙锚点周围的局部几何结构，实现了更准确的高斯分布定位。
### Conclusion
在不同真实世界数据集上的广泛实验表明，该方法在无姿态的一般化3D高斯采样中表现出了稳健的性能。提供的代码可以在此访问：this https URL，这些结果证明了该方法的有效性和实用性。
## 644. `cs.CV` - FlySearch：探索视觉语言模型的探索方式 [PDF](https://arxiv.org/pdf/2506.02896), [HTML](https://arxiv.org/abs/2506.02896)
### Authors
Adam Pardyl,Dominik Matuszek,Mateusz Przebieracz,Marek Cygan,Bartosz Zieliński,Maciej Wołczyk
### Background
现实世界是复杂且无结构化的，提取关键信息通常需要主动的、目标导向的探索。尽管最近在许多困难任务中以零样本工具形式出现的视觉语言模型（VLMs）受到了广泛的关注，但它们是否能在这样的条件下有效工作仍是一个未知数。
### Innovation
本文介绍了一种名为FlySearch的3D、户外、照片真实环境，用于复杂场景中的搜索和导航。定义了不同难度级别的三种场景，并观察到最先进的VLMs无法可靠地解决最简单的探索任务，随着任务难度的增加，与人类表现的差距也越来越大。通过研究视觉幻觉、语境误解和任务规划失败等多种核心原因，并展示了部分问题可以通过微调来解决。公开发布了基准测试、场景和底层代码库，
### Conclusion
最先进的VLMs在复杂场景中执行探索任务时存在局限性，通过FlySearch环境发现了一些根本原因，并且部分问题可以通过微调来缓解。
## 645. `cs.CV` - VisuRiddles: 细粒度感知是多模态大型语言模型在抽象视觉推理中的主要瓶颈 [PDF](https://arxiv.org/pdf/2506.02537), [HTML](https://arxiv.org/abs/2506.02537)
### Authors
Hao Yan,Xingchen Liu,Hao Wang,Zhenbiao Cao,Handong Zheng,Liang Yin,Xinxing Su,Zihao Chen,Jihao Wu,Minghui Liao,Chao Weng,Wei Chen,Yuliang Liu,Xiang Bai
### Background
近年来，多模态大规模语言模型（MLLMs）在许多推理任务中的性能有了显著提升。然而，抽象视觉推理（AVR）仍然是一项重大挑战，主要原因在于其在感知抽象图形方面能力有限。
### Innovation
本文提出了一种基于 VisuRiddles 的基准测试，以检验模型在五大核心维度和两类高层次推理类别中的推理能力。同时，还引入了一种名为 Perceptual Riddle Synthesizer (PRS) 的自动框架，用于生成具有细粒度感知描述的谜题。这不仅为抽象图形提供了有价值的训练数据，还为中间推理阶段提供了细粒度的感知描述，从而提高了训练效率和模型的可解释性。实验结果表明，细粒度的视觉感知能力是主要瓶颈，而我们的合成框架显著提升了当代 MLLMs 在这类难题上的表现。
### Conclusion
本文通过 VisuRiddles 基准测试和 Perceptual Riddle Synthesizer，证明了细粒度感知能力在多模态大规模语言模型中的重要性，并展示了改进后的模型在 AVR 任务上的显著提升。相关代码和数据集将在此链接中发布：this https URL
## 646. `cs.CV` - Janus-Pro-R1: 通过强化学习推进协同视觉理解和生成 [PDF](https://arxiv.org/pdf/2506.01480), [HTML](https://arxiv.org/abs/2506.01480)
### Authors
Kaihang Pan,Yang Wu,Wendong Bu,Kai Shen,Juncheng Li,Yingting Wang,Yunfei Li,Siliang Tang,Jun Xiao,Fei Wu,Hang Zhao,Yueting Zhuang
### Background
近年来，关于多模态大语言模型（MLLM）的研究致力于统一视觉理解和生成。然而，这两种能力在大多数情况下仍然保持独立，仿佛是模型中的两个独立功能。视觉理解并未增强视觉生成能力，大语言模型的推理机制尚未充分集成以彻底改变图像生成。
### Innovation
该论文提出了一种两阶段训练方法：监督微调使MLLM具备生成真实推理链（CoT）以进行视觉生成的基础能力，而强化学习则通过探索-利用权衡激活其全部潜力。最终，该方法为视觉生成解锁了“恍然大悟”那一刻，推动MLLM从文本到图像任务向统一的图像生成迈进。
### Conclusion
大量实验表明，该模型不仅在文本到图像生成和图像编辑方面表现出色，还能作为具有增强视觉理解能力的图像语义评估器。
## 647. `cs.CV` - Infinity Parser：基于强化学习的布局感知扫描文档解析 [PDF](https://arxiv.org/pdf/2506.03197), [HTML](https://arxiv.org/abs/2506.03197)
### Authors
Baode Wang,Biao Wu,Weizhen Li,Meng Fang,Zuming Huang,Jun Huang,Haozhe Wang,Yanjie Liang,Ling Chen,Wei Chu,Yuan Qi
### Background
文档AI领域中，将扫描文档自动解析为富含结构的机器可读格式依然是一个关键瓶颈。传统多阶段管道容易发生错误传播，且难以适应多种版面布局。
### Innovation
提出了一个端到端的强化学习框架layoutRL，通过优化编辑距离的归一化值、段落计数准确性和阅读顺序保持度的复合奖励来训练模型，使其显式地具备版面感知能力。基于新发布的Infinity-Doc-55K数据集，这个数据集整合了55000份高质量合成扫描文档解析数据和经过专家过滤的真实世界文档，提出了一个基于视觉语言模型的解析器Infinity-Parser。
### Conclusion
Infinity-Parser在英汉OCR基准、表格和公式提取以及阅读顺序检测方面实现了新的最佳性能，在准确性和结构保真度方面超越了专门的管道和通用视觉-语言模型。论文将公开发布代码和数据集，以加速健壮文档理解的发展。
## 648. `cs.CV` - 从物体到任意处：3D场景多层次视觉定位综合基准 [PDF](https://arxiv.org/pdf/2506.04897), [HTML](https://arxiv.org/abs/2506.04897)
### Authors
Tianxu Wang,Zhuofan Zhang,Ziyu Zhu,Yue Fan,Jing Xiong,Pengxiang Li,Xiaojian Ma,Qing Li
### Background
3D视觉定位已经在复杂3D场景中准确定位三维对象方面取得了显著进展，但超过物体的3D场景中的引语表达的视觉定位尚未得到探索。
### Innovation
引入了一个全面的3D视觉定位基准——Anywhere3D-Bench，包含2,886个引用表达-3D边界框对，涵盖四个不同的定位级别：人类活动区域、物体外的空间、场景中的个体对象和对象的精细粒度部件。同时，对多种最先进的3D视觉定位方法以及大型语言模型（LLMs）和多模态大型语言模型（MLLMs）在该基准上的性能进行了评估。
### Conclusion
实验结果表明，空间级别和部分级别的视觉定位是最具挑战性的任务。空间级别的任务需要更全面的空域推理能力，而部分级别的任务则需要对对象组成的细微感知。即使是表现最好的模型，OpenAI o4-mini，在空间级别任务上的准确率为23.00%，在部分级别任务上的准确率为31.46%，显著低于其在区域级别和对象级别任务上的表现。这些结果揭示了当前模型在理解和推理3D场景超越对象级语义方面的关键能力差距。
## 649. `cs.CV` - Re-ttention: 超级稀疏的注意力统计重塑实现超高效视觉生成 [PDF](https://arxiv.org/pdf/2505.22918), [HTML](https://arxiv.org/abs/2505.22918)
### Authors
Ruichen Chen,Keith G. Mills,Liyao Jiang,Chao Gao,Di Niu
### Background
扩散变换器（DiT）已经成为产生高质量视觉内容（如视频和图像）的默认模型。然而，现有的注意力机制在处理高分辨率和长视频时，计算复杂度会呈二次方地增加，成为主要瓶颈。为了应对这个问题，现有的稀疏注意力机制虽然可以减少计算量，但在极高的稀疏度下可能会损失视觉质量或者增加计算开销。为了改善这一现状，研究者提出了Re-ttention方法，通过利用扩散模型中的时间冗余来抵消注意力机制中的概率归一化变化，从而能够在非常高稀疏度下保持视觉质量。
### Innovation
Re-ttention方法通过利用扩散模型的时间冗余性，重新塑造注意力分数基于先前的softmax分布历史，以在非常高的稀疏度下保持视觉质量。实验表明，Re-ttention在推理过程中只需要3.1%的tokens，比现有方法如FastDiTAttn、Sparse VideoGen和MInference更优于后者。
### Conclusion
实验结果证实，Re-ttention方法能够在保持视觉质量的前提下显著减少计算量，特别是针对视觉生成模型如CogVideoX和PixArt DiTs，证明了其在非常高的稀疏度下的有效性。
## 650. `cs.CV` - ReID5o：单模型实现全方位多模态人员重识别 [PDF](https://arxiv.org/pdf/2506.09385), [HTML](https://arxiv.org/abs/2506.09385)
### Authors
Jialong Zuo,Yongtai Deng,Mengdan Tan,Rui Jin,Dongyue Wu,Nong Sang,Liang Pan,Changxin Gao
### Background
现有的人员重识别方法和数据集仍局限于少数几种模态，无法满足实际场景中人员重识别的需求。实际场景中，人员重识别需要基于描述性的查询来识别目标人员，无论查询信息是单一模态还是多种模态的组合。因此，研究者提出了一个新的挑战性问题——全方位多模态人员重识别（OM-ReID），旨在利用不同模态的组合数据实现有效的检索。
### Innovation
该论文创新地提出了一种新型的多模态学习框架——ReID5o，该框架能够在一个模型中实现任意模态组合的协同融合和跨模态对齐。此外，研究人员构建了ORBench，这是一个高质量的多模态数据集，包括RGB、红外、彩色铅笔、素描和文本描述五种模态，具有显著的多样性和丰富性，有助于后续研究OM-ReID的问题。
### Conclusion
通过广泛的实验验证了ORBench数据集的有效性和实用性，并展示了提出的ReID5o模型的优越性能。该模型在ORBench数据集上表现最佳。数据集和代码将在指定网页上公开提供。
## 651. `cs.CV` - SDTagNet：利用文本注释导航地图进行在线高精度地图构建 [PDF](https://arxiv.org/pdf/2506.08997), [HTML](https://arxiv.org/abs/2506.08997)
### Authors
Fabian Immel,Jan-Hendrik Pauls,Richard Fehler,Frank Bieder,Jonas Merkert,Christoph Stiller
### Background
自动驾驶车辆依赖于详细准确的环境信息才能安全运行。高精度（HD）地图提供了一个理想的解决方案，但其高昂的维护成本极大地限制了其大规模部署。为了解决这一问题，研究者提出了在线构建HD地图的方法，这些方法能够从实时传感器数据中生成局部HD地图。然而，这些方法受限于车载传感器的短感知范围。为了克服这一限制并提高整体性能，近年来的方法开始探索使用标准分辨率（SD）地图作为先验信息，SD地图的维护成本相对较低。然而，现有方法未能充分利用SD地图中的补充信息，特别是在文本注释方面的信息，这限制了其在远距离检测精度方面的提升。论文介绍了一种新的方法SDTagNet，它首次完全利用广泛可用的SD地图（如OpenStreetMap）的信息，提高远距离检测精度。
### Innovation
SDTagNet 的两项关键创新在于首先，它不仅利用了线段形式的SD地图数据以及手动选择的类别，还引入了文本注释形式的语义信息，通过大语言模型提取特征，增强了SD矢量地图标记，去除了对预定义规范或详尽类别分类的需求。其次，SDTagNet引入了一种点级SD地图编码器以及正交元素标识符，以统一融合所有类型的地图元素。与没有先验信息的HD地图构建方法相比，实验结果显示SDTagNet的地下导方法提高了高达+5.9 mAP（+45%）的性能；与已经使用SD地图先验信息的方法相比，提高了高达+3.2 mAP（+20%）的性能。
### Conclusion
SDTagNet 是一种在线 HD 地图构建方法，首次完全利用 SD 地图（如 OpenStreetMap）中的信息，特别是文本注释形式的语义信息，来提高远距离检测精度。通过引入点级 SD 地图编码器和语义增强，改进了 HD 地图的构建性能，实验结果显示其明显优于没有使用先验信息的方法和已有利用 SD 地图先验信息的方法。项目代码可以在指定的网址获取。
## 652. `cs.CV` - 使用视频进行主动长视频理解 [PDF](https://arxiv.org/pdf/2506.10821), [HTML](https://arxiv.org/abs/2506.10821)
### Authors
Huaying Yuan,Zheng Liu,Junjie Zhou,Hongjin Qian,Yan Shu,Nicu Sebe,Ji-Rong Wen,Zhicheng Dou
### Background
长视频理解（LVU）是计算机视觉中的一个具有挑战性的问题。现有的方法要么通过下采样帧来进行单次推理，牺牲了细节信息，要么依赖于不特定于任务的表示进行文本推理，这限制了针对特定任务的感知和探索能力。
### Innovation
本文提出了VideoExplorer框架，该框架基于‘使用视频思考’的原则，将规划、时间对齐和可扩展的感知自然地结合到一个协调的推理过程中。VideoExplorer通过迭代地提出子问题，定位相关信息的时刻，并进行任务导向、时间可扩展的视频理解，直到达到最终答案，从而实现了忠实、高效和可解释的推理。为了应对缺乏LVU训练资源的问题，研究者构建了一个难度自适应采样的长视频推理数据集，以确保在复杂任务上高质量的轨迹。随后，设计了两阶段的训练管道：监督轨迹初始化后进行轨迹级别偏好优化，基于下游奖励鼓励适应性的时空对齐和迭代的信息聚合。
### Conclusion
广泛的长视频理解和推理基准测试表明，VideoExplorer相对于现有基线具有显著优势，突显了其稳健性、适应性和效率。相关代码已在该仓库中公开。
## 653. `cs.CV` - ViFusionTST: 基于负载信号的时间序列图像表示的深度融合用于早期离床预测 [PDF](https://arxiv.org/pdf/2506.22498), [HTML](https://arxiv.org/abs/2506.22498)
### Authors
Hao Liu,Yu Hu,Rakiba Rayhana,Ling Bai,Zheng Liu
### Background
医院和长期护理设施中的床相关跌倒是导致受伤的主要原因，但许多商业报警器只在患者离开床后才触发。预测患者离床早期意图对于预防跌倒至关重要，但现有技术主要依赖于离床后的警报，远不足以提前干预。
### Innovation
研究提出了一种新的方法，利用一个低成本的负载传感器（安装在床腿下）生成负荷信号，并将这些信号转换为线图和纹理图。引入了ViFusionTST，这是一种双流Swin Transformer，能够平行处理线图和纹理图，并通过跨注意力机制融合它们以学习数据驱动的不同模态权重。这种方法在实际数据集上达到了较高的精确度和F1分数，超过了一维和二维时间序列基线的结果。
### Conclusion
研究结果表明，基于图像融合的负载传感器信号时间序列分类方法是一种实用而有效的实时、隐私保护跌倒预防解决方案。
## 654. `cs.CV` - Polyline Path Masked Attention for Vision Transformer [PDF](https://arxiv.org/pdf/2506.15940), [HTML](https://arxiv.org/abs/2506.15940)
### Authors
Zhongchen Zhao,Chaodong Xiao,Hui Lin,Qi Xie,Lei Zhang,Deyu Meng
### Background
当前深度学习框架的基础架构设计包含全球依赖建模和空间位置建模两个核心问题。Vision Transformers (ViTs) 通过自注意力机制的强大全局依赖建模能力在计算机视觉领域取得了显著的成果。Mamba2 在自然语言处理任务中通过明确建模空间邻近性先验展示了其潜力，但这种方法在图像处理中的应用尚需探索。
### Innovation
本文提出了Polyline Path Masked Attention (PPMA)，结合了ViTs的自注意力机制和Mamba2改进的结构化掩码策略。具体来说，通过引入2D polyline路径扫描策略优化Mamba2的传统结构化掩码，并推导出 polyline path mask，更好地保留图像令牌之间的邻近关系。此外，通过将polyline path mask嵌入到ViTs的自注意力机制中，实现了空间邻近性先验的明确建模。实验结果表明，该模型在图像分类、对象检测和分割等基准测试中均优于之前的基于状态空间模型和Transformer的方法。
### Conclusion
本文提出的PPMA-T/S/B模型在ADE20K语义分割任务中的mIoU分别为48.7%/51.1%/52.3%，分别优于RMT-T/S/B的0.7%/1.3%/0.3%。
## 655. `cs.CV` - HOIDiNi：通过扩散噪声优化实现人类-物体交互 [PDF](https://arxiv.org/pdf/2506.15625), [HTML](https://arxiv.org/abs/2506.15625)
### Authors
Roey Ron,Guy Tevet,Haim Sawdayee,Amit H. Bermano
### Background
人类-物体交互（HOI）的生成极具挑战性，因为它需要精确的接触精度和多样的运动轨迹。当前的研究在现实性和物理正确性之间做了权衡，而HOIDiNi通过直接在预训练的扩散模型噪声空间中优化，同时实现了这两方面的需求。此外，问题可以通过两个阶段来区分和解决：首先是基于物体的阶段，主要确定手与物体接触的具体位置；其次是基于人类的阶段，进一步细化全身运动以实现这一蓝图。这种方法允许精确的手与物体接触而不牺牲运动的自然性。HOIDiNi在GRAB数据集上的评估表明，它在实际接触准确性、物理有效性及总体质量方面优于现有的工作和基线方法。结果展示了通过文本提示生成的复杂、可控的交互能力，包括抓住、放置和全身协调等方面。
### Innovation
HOIDiNi是一种基于文字的扩散框架，用于合成现实且合理的HOI。它通过Diffusion Noise Optimization (DNO)直接优化预训练的扩散模型的噪声空间，实现了在保持现实性和物理正确性的同时生成HOI。通过将问题拆分为基于物体和基于人类的两个阶段来优化接触点位置和全身运动，HOIDiNi能够在保持运动自然性的同时实现精确的手-物体接触。
### Conclusion
定量、定性和主观评估显示HOIDiNi在接触精度、物理有效性和总体质量方面优于先前的工作和基线方法，证明了通过纯文本提示生成复杂、可控的交互的能力，包括抓取、放置和全身协调等。
## 656. `cs.CV` - 使用聚焦扩展可能性和分割从移动摄像头检测运动物体 [PDF](https://arxiv.org/pdf/2507.13628), [HTML](https://arxiv.org/abs/2507.13628)
### Authors
Masahiro Ogawa,Qi An,Atsushi Yamashita
### Background
从移动相机视角分离移动和静态物体对于3D重建、自主导航和机器人场景理解至关重要。现有方法通常依赖于光学流，但在涉及相机运动的复杂、结构化场景中，光学流很难检测移动物体。为了解决这一局限性，我们提出了一种结合光学流和纹理信息的核心思路——聚焦扩展可能性和分割（FoELS）的方法。
### Innovation
FOELS 方法从光学流中计算聚焦扩展 (FoE)，并从 FoE 计算的离群值中推导出初始运动可能性。随后，将该可能性与基于分割的先验信息结合起来，估算最终的运动概率。此方法能够有效处理包括复杂结构化场景、旋转相机运动和平行运动的挑战。
### Conclusion
在DAVIS 2016 数据集和真实世界交通视频上的全面评估表明，该方法具有有效性和前瞻性。
## 657. `cs.CV` - MSR-Align: Policy-Grounded Multimodal Alignment for Safety-Aware Reasoning in Vision-Language Models [PDF](https://arxiv.org/pdf/2506.19257), [HTML](https://arxiv.org/abs/2506.19257)
### Authors
Yinan Xia,Yilei Jiang,Yingshui Tan,Xiaoyong Zhu,Xiangyu Yue,Bo Zheng
### Background
视觉语言模型（VLMs）在多模态推理任务中取得了显著进展，特别是在增强链式思维能力方面。然而，这种进步也带来了新的安全风险，因为这些模型变得越来越容易受到有害的多模态提示的影响，这些提示可能会触发不道德或不安全的行为。现有的安全性对齐方法主要针对单模态语言模型，并不能有效应对多模态输入带来的复杂和细微的威胁。目前的安全性数据集缺乏精细的、基于政策的推理能力，无法对具有推理能力的VLMs进行稳健的安全对齐。因此，需要一个专门针对多模态输入的高质量数据集，以支持对政策进行细致的、审慎的跨模态推理。
### Innovation
本文提出了一种名为MSR-Align的多模态安全性推理数据集，专门用于建立针对多模态输入的安全性对齐方法。MSR-Align的数据生成管道强调了多模态多样性、基于政策的推理以及严格的质量筛选，使用强大的多模态评估者。实验表明，在MSR-Align上微调VLMs能够显著提高其对文本和视觉语言突破攻击的鲁棒性，同时保持甚至提升一般推理性能。MSR-Align提供了构建具有推理能力的VLMs的安全性对齐的一个可扩展且有效的基础，并已公开发布。
### Conclusion
MSR-Align为视觉语言模型中具有推理能力的VLMs的安全性对齐提供了一个高质量的数据基础，通过多模态安全推理和严格的政策对齐，提高了模型的安全性和鲁棒性，使其能够在更复杂的多模态环境中更加可靠地进行推理。
## 658. `cs.CV` - GreenHyperSpectra：用于全球植被特征预测的多源高光谱数据集 [PDF](https://arxiv.org/pdf/2507.06806), [HTML](https://arxiv.org/abs/2507.06806)
### Authors
Eya Cherif(1, 2 and 3),Arthur Ouaknine(3 and 4),Luke A. Brown(5),Phuong D. Dao(6, 7 and 8),Kyle R. Kovach(9),Bing Lu(10),Daniel Mederer(1),Hannes Feilhauer(1, 2, 12 and 13),Teja Kattenborn(11 and 12),David Rolnick(3 and 4) ((1) Institute for Earth System Science and Remote Sensing, Leipzig University, Germany, (2) Center for Scalable Data Analytics and Artificial Intelligence (<a href=?http://ScaDS.AI? rel=?external noopener nofollow? class=?link-external link-http?>this http URL</a>), Leipzig University, Germany, (3) Mila Quebec AI Institute, Canada, (4) McGill University, Canada, (5) School of Science, Engineering and Environment, University of Salford, UK, (6) Department of Agricultural Biology, Colorado State University, USA, (7) Graduate Degree Program in Ecology, Colorado State University, USA, (8) School of Global Environmental Sustainability, Colorado State University, USA, (9) Department of Forest and Wildlife Ecology, University of Wisconsin, USA, (10) Department of Geography, Simon Fraser University, Canada, (11) Chair of Sensor-based Geoinformatics (geosense), University of Freiburg, Germany, (12) German Centre for Integrative Biodiversity Research (iDiv), Halle-Jena-Leipzig, Germany, (13) Helmholtz-Centre for Environmental Research (UFZ), Leipzig, Germany)
### Background
植物叶片碳含量和叶片质量等特征是研究生物多样性和气候变化的重要变量。然而，常规的实地取样无法在生态学意义上有效的覆盖样区的特征变异。利用遥感高光谱数据预测植物特征是机器学习的一种有效解决方案，但受限于标签稀缺和域间差异（例如传感器间、生态分布间）等问题，需要具有跨域鲁棒性的方法。
### Innovation
提出GreenHyperSpectra，这是一个包含跨传感器和跨生态系统样本的预训练数据集，旨在评估半监督和自监督方法在植物特征预测中的表现。利用该数据集，开发了高效的标签有限的多输出回归模型，这些模型在无监督基准上表现出色。该研究提供了表征学习和植物功能性状评估相结合的全面方法论框架，促进了相关研究的发展。
### Conclusion
通过GreenHyperSpectra数据集的使用，展示了显著提高光谱表示对特征预测的学习效果，建立了促进表征学习与植物功能性状评估领域结合的全面方法论框架。所有代码和数据可以在该网址找到：this https URL。
## 659. `cs.CV` - 从随机槽-特征对预测视频槽注意力查询 [PDF](https://arxiv.org/pdf/2508.01345), [HTML](https://arxiv.org/abs/2508.01345)
### Authors
Rongzhen Zhao,Jian Li,Juho Kannala,Joni Pajarinen
### Background
无监督的视频对象中心学习（OCL）很有前景，因为它能够像人类一样进行物体级别的场景表示和动力学建模。主流的视频OCL方法采用了递归架构：聚合并将当前视频帧聚合成对象特征（称为槽），在某些查询下；转换器将当前槽过渡到下一个查询框架，这是有效的架构，但现有的实现都未能利用下一个帧特征成为查询预测的最有信息来源，同时也未能学习对于查询预测至关重要的转换动力学知识。
### Innovation
为了应对这些问题，论文提出了一种新的方法：RandSF.Q。首先设计了一个新的转换器以同时包括槽和特征，提供更多的查询预测信息；其次通过训练转换器来预测从可利用重演中随机抽取的槽-特征对的查询，推动其学习转换动力学。在场景表征实验中，论文的方法显著超越了现有视频OCL方法，比如在对象发现任务上提高了10分点，设置新的最先进的水平。这种优势也能够改善下游任务，如动力模型建模。
### Conclusion
该方法在场景表示实验中显著超过了现有的视频OCL方法，特别是在对象发现任务上取得了显著的性能提升，达到了新的最先进的水平。并且这种优势还提升了下游的动力模型建模任务的性能。源代码和训练日志已公开。
## 660. `cs.CV` - RODS: Robust Optimization Inspired Diffusion Sampling for Detecting and Reducing Hallucination in Generative Models [PDF](https://arxiv.org/pdf/2507.12201), [HTML](https://arxiv.org/abs/2507.12201)
### Authors
Yiqi Tian,Pengfei Jin,Mingze Yuan,Na Li,Bo Zeng,Quanzheng Li
### Background
自播扩散模型在生成建模中已达到最先进的性能，但在采样过程中仍然容易出现幻觉，这些问题常常源于分数近似不准确。为解决这一问题，本文通过将扩散采样重新解读为优化问题，提出了一种新颖的方法RODS（Robust Optimization-inspired Diffusion Sampler），该方法利用损失景观中的几何线索来检测和纠正高风险采样步骤。
### Innovation
RODS通过几何提示来发现和修正高风险的采样步骤。它强制采样轨迹平滑并适应性调整扰动，从而减小幻觉，而无需重新训练模型，并且仅增加有限的推理成本。实验表明，RODS在保持图像质量和生成多样性的同时，提高了采样准确性和鲁棒性，成功率超过70%的幻觉检测，并且纠正了25%以上的幻觉样本，同时避免了引入新特征。
### Conclusion
实验结果表明，RODS不仅保持了与现有的图像质量相当的表现，还提升了一致性和多样性，更重要的是，它改善了采样保真度和鲁棒性，纠正了大量幻觉样本而没有引入新的特征，验证了其高效性和实用性。
## 661. `cs.CV` - 端到端自主驾驶的可解释决策 [PDF](https://arxiv.org/pdf/2508.18898), [HTML](https://arxiv.org/abs/2508.18898)
### Authors
Mona Mirzaie,Bodo Rosenhahn
### Background
可信的人工智能是广泛部署自动驾驶车辆的必要条件。尽管端到端方法可以直接从原始数据中推导出控制命令，但解释这些决策在复杂的 urbana 情景下依然极具挑战性。主要原因在于非常深的神经网络具有非线性的决策边界，这使得难以理解 AI 驱动决策背后的逻辑。
### Innovation
本文提出了一种方法，以在优化控制命令的同时增强模型的可解释性。通过生成稀疏和局部化的特征图，我们提出了促进模型可解释性的损失函数。特征激活允许我们解释哪些图像区域对预测的控制命令做出了贡献。我们进行了全面的消融研究，并在 CARLA 基准测试上验证了我们的方法。我们还证明，我们的方法提高了可解释性，与减少违规行为相关，从而产生了一个更安全、高性能的驾驶模型。值得注意的是，我们的单目非集成模型在 CARLA 领先者榜单上超过了表现最好的方法，实现了更低的违规得分和最高的路线完成率，同时确保了可解释性。
### Conclusion
我们的模型明显提高了可解释性，并实现了在 CARLA 领先者榜单上前所未有的低违规得分和高路线完成率，这些改进确保了驾驶行为的安全性和性能。
## 662. `cs.CV` - Cryo-RL: 使用强化学习自动化前列腺癌冷冻消融计划 [PDF](https://arxiv.org/pdf/2509.04886), [HTML](https://arxiv.org/abs/2509.04886)
### Authors
Trixia Simangan,Ahmed Nadeem Abbasi,Yipeng Hu,Shaheer U. Saeed
### Background
冷冻消融是一种微创局部治疗前列腺癌的方法，通过解冻期间破坏肿瘤组织的同时保留周围健康结构。治疗成功依赖于术前对手术图谱的精确规划，以全面覆盖肿瘤并避免关键解剖结构。目前，这种规划主要依靠手动操作，依赖专家经验和耗时过程，导致治疗质量差异并限制了规模化实施。
### Innovation
本文介绍了Cryo-RL，这是一种基于强化学习的框架，将冷冻消融规划建模为马尔可夫决策过程，并学习冷冻探针放置的最优策略。该方法在模拟临床约束和术中随机变化的环境中，通过关导以肿瘤覆盖为基础的奖励函数，自适应选择冷冻针位置和冰球直径，无需任何手工设计的方案，就能学习出最优的冷冻消融策略。评估结果显示，Cryo-RL 比最佳自动化基准方法提高了超过8个百分点的Dice分数，并且在所需规划时间显著减少的情况下与人类专家的性能相当，显示了强化学习在实现临床可行、可复现且高效冷冻消融计划中的潜力。
### Conclusion
研究结果表明，Cryo-RL 框架在预测前列腺癌冷冻消融计划的准确性和效率方面优于现有的自动化方法，且达到了人类专家的水平。这项工作强调了强化学习在实现冷冻消融计划中具有临床可行性、可重复性和高效性方面的潜力。
## 663. `cs.CV` - GeoArena: 一个用于评估大规模视觉语言模型的世界级图像地理定位基准平台 [PDF](https://arxiv.org/pdf/2509.04334), [HTML](https://arxiv.org/abs/2509.04334)
### Authors
Pengyue Jia,Yingyi Zhang,Xiangyu Zhao,Sharon Li
### Background
图像地理定位旨在预测地球上任何地方拍摄的图像的地理位置，但其全球性质带来了重大挑战。现有的评估方法存在两个主要局限性：数据泄漏和使用具体地理坐标进行评估。数据泄漏是指先进的方法往往依赖大型视觉语言模型（LVLMs）来预测图像地点，但这些模型通常是在测试数据集上进行预训练的，这损害了评估模型实际地理定位能力的准确性。而现有指标主要依靠具体的地理坐标来评估预测，这忽略了推理过程同时也对用户级别的位置数据提出了隐私担忧。
### Innovation
我们提出了GeoArena，这是一个开放平台，用于在世界范围内的图像地理定位任务中评估LVLMs，提供真正的野外和以人为本的基准测试。GeoArena允许用户上传野外图像以获得更多样化的评估数据集，并利用成对的人类判断来确定哪种模型输出更好地符合人类预期。我们的平台已在线运行两个月，期间收集了数千条投票记录，基于此数据，我们进行了详细的分析并建立了不同LVLMs在图像地理定位任务中的排行榜。GeoArena已开源以支持未来的研究。
### Conclusion
GeoArena已经在线运行了一个多月，积累了数千条投票记录，基于这些数据，我们进行了深入分析，并建立了一个针对图像地理定位任务不同LVLMs的能力排行榜。GeoArena作为一个开源平台，旨在支持未来的相关研究。
## 664. `cs.CV` - 可见而无法阅读：跨书写系统的视觉语言模型系统盲点 [PDF](https://arxiv.org/pdf/2509.06996), [HTML](https://arxiv.org/abs/2509.06996)
### Authors
Jie Zhang,Ting Xu,Gelei Deng,Runyi Hu,Han Qiu,Tianwei Zhang,Qing Guo,Ivor Tsang
### Background
写作是一种普遍的文化技术，利用视力进行象征性交流。人类表现出显著的适应力：即使字符被分割、融合或部分遮挡，我们也能快速识别词语。本文研究了最新的视觉语言模型（VLMs）是否也具备这种适应力。
### Innovation
构建了跨不同书写系统的两种心理物理学启发式基准测试，通过拼接、重组和叠加字符，产生了‘可见但无法阅读’的刺激物，同时保持对人类的可读性。尽管在干净文本上表现出色，现代VLMs在这些干扰下表现严重下降，经常产生相关性不强或不连贯的输出。这一模式表明模型在结构上存在限制：它们在通用视觉不变性方面依赖性很强，但对用于稳健文盲认识的组合先验的依赖不足。
### Conclusion
研究结果揭示了结构上的局限性：模型主要依赖通用视觉不变性，但对用于稳健文盲认识的组合先验的依赖不足。这些发现激励了能够编码跨越书法的符号分割、组合和绑定的架构和训练策略，并指出了部署多模态系统在教育、可用性、文化遗产和安全方面的具体挑战。
## 665. `cs.CV` - 将大型语言模型先验注入流模型以促进物体目标导航中可迁移智能体想象 [PDF](https://arxiv.org/pdf/2508.09423), [HTML](https://arxiv.org/abs/2508.09423)
### Authors
Badi Li,Ren-jie Lu,Yu Zhou,Jingke Meng,Wei-shi Zheng
### Background
物体目标导航（ObjectNav）任务需要智能体在未知环境中通过想象未观察到的场景区域来定位指定的物体。先前的方法依赖于确定性和判别模型来构建语义地图，但忽略了室内布局中的固有不确定性，限制了其对未知环境的泛化能力。本文探讨了如何通过将大型语言模型（LLMs）的先验信息注入到流模型中来生成环境语义分布的方法，以提高智能体在物体目标导航任务中的表现和泛化能力。
### Innovation
提出了一种生成性的流基框架（GOAL），通过将从大型语言模型推断的空间先验编码为二维高斯场并注入目标地图，将丰富的上下文知识注入流模型中，从而促进了对未知环境的更一般的完成。该方法在MP3D和Gibson数据集上实现了最先进的性能，并在HM3D上展示了强大的转移性能。
### Conclusion
GOAL在MP3D和Gibson数据集上取得了最先进的性能，并在HM3D上展示了强大的泛化能力。通过将大型语言模型先验注入流模型，GOAL增强了智能体在物体目标导航任务中的想象能力。
## 666. `cs.CV` - SAMPO: 根据运动提示的尺度化自回归模型 [PDF](https://arxiv.org/pdf/2509.15536), [HTML](https://arxiv.org/abs/2509.15536)
### Authors
Sen Wang,Jingyi Tian,Le Wang,Zhimin Liao,Jiayi Li,Huaiyi Dong,Kun Xia,Sanping Zhou,Wei Tang,Hua Gang
### Background
世界模型允许智能体在想象的环境中模拟动作的后果，用于规划、控制和远期决策。然而，现有的自回归世界模型在视觉上连贯的预测方面存在挑战，因为它们的时空结构被破坏、解码效率低下和运动建模不足。
### Innovation
本文提出了一个混合框架SAMPO，结合了视自回归建模以进行帧内生成和因果建模以生成下一帧。具体来说，SAMPO 融合了时间因果解码和双向空间注意力，这可以在每个尺度上保留空间局部性并支持并行解码。此外，作者设计了不对称的多尺度标记器来保留观察帧中的空间细节，并为未来帧提取紧凑的动力学表示。为了进一步提升动态场景理解，引入了轨迹感知的运动提示模块，该模块注入了关于物体和机器人轨迹的空间时间线索，使注意力集中在动态区域，进而改善时间一致性和物理现实感。
### Conclusion
广泛的实验表明，SAMPO 在基于动作的视频预测和模型控制方面表现出色，通过比现有方法快4.4倍的推理提升了生成质量。此外，SAMPO 还展示了零样本泛化和扩展行为的能力，证明了其在未见过的任务中也能表现良好，并且可以通过更大的模型规模受益。
## 667. `cs.CV` - 每次每种镜头效果，一次性解决：基于物理的镜头效果数据生成的4D高斯光线跟踪 [PDF](https://arxiv.org/pdf/2509.10759), [HTML](https://arxiv.org/abs/2509.10759)
### Authors
Yi-Ruei Liu,You-Zhe Xie,Yu-Hsiang Hsu,I-Sheng Fang,Yu-Lun Liu,Jun-Cheng Chen
### Background
传统的计算机视觉系统假定采用理想的针孔相机，但在面对实际镜头中的鱼眼失真和滚动快门等效应用时会失效。这是由于训练数据中缺少对这些镜头效果的学习。现有的数据生成方法要么成本高，要么存在仿真到现实的差距，要么无法准确模拟镜头效果。
### Innovation
本文提出了一种名为4D高斯光线跟踪（4D-GRT）的创新性双阶段管道，结合了4D高斯点积和基于物理的光线追踪，用于镜头效果的模拟。该方法能在多视角视频中重建动态场景，然后通过光线追踪生成具有可控制且物理准确的镜头效果的视频。4D-GRT在渲染速度上最优，同时在渲染质量上与现有基线相当或更优。另外，还构建了8个室内环境中具有不同镜头效果的合成动态场景集，以评估生成的具有镜头效果的视频。
### Conclusion
4D-GRT能够高效、实时且准确地模拟各种镜头效果，解决了实时和大规模生成具有各种镜头效果的真实数据集的难题。
## 668. `cs.CV` - 通过Chamfer指导提高合成图像的实用性 [PDF](https://arxiv.org/pdf/2508.10631), [HTML](https://arxiv.org/abs/2508.10631)
### Authors
Nicola Dall'Asen,Xiaofeng Zhang,Reyhane Askari Hemmat,Melissa Hall,Jakob Verbeek,Adriana Romero-Soriano,Michal Drozdzal
### Background
基于条件的图像生成模型有潜力生成无限量的合成训练数据。然而，生成质量的提升导致了生成多样性减少，限制了这些模型作为合成训练数据来源的实际应用价值。尽管引入了基于指导的方法以提高生成数据的质量或多样性，但它们往往忽略了合成数据和真实数据之间的潜在分布偏移。本文讨论了现有指导方法的问题，并引入了一种无需训练即可利用有限的真实示例图像来表征合成数据质量和多样性的方法，称为Chamfer指导。
### Innovation
该研究提出了一种名为Chamfer指导的训练无关指导方法，通过少量的真实示例图像来表征合成数据的质量和多样性。基于该方法，研究在不牺牲或改善ImageNet-1k和标准地理多样性基准上的生成质量的情况下，提升了生成的多样性和分布覆盖率。使用2至32张真实图像时，该方法分别实现了97.5%的精确度和92.7%的分布覆盖率，均高于现有方法。此外，该方法还能够提高下游图像分类器的准确性，特别是在分布外数据上的表现，同时无需使用无条件模型，降低了31%的FLOPs开销，特别是在采样时。
### Conclusion
通过Chamfer指导，研究在不牺牲或提升合成图像质量的同时，显著提高了生成的多样性和分布覆盖率，验证了其在真实数据数量有限情况下的有效性，并展示了其在下游图像分类器训练中的优势。此外，该方法不需要使用无条件模型，从而在采样时降低了大量计算开销。
## 669. `cs.CV` - UniPixel：统一对象引用和分割以实现像素级视觉推理 [PDF](https://arxiv.org/pdf/2509.18094), [HTML](https://arxiv.org/abs/2509.18094)
### Authors
Ye Liu,Zongyang Ma,Junfu Pu,Zhongang Qi,Yang Wu,Ying Shan,Chang Wen Chen
### Background
近年来，大型多模态模型（LMMs）在通用多模态助手方面表现出显著的成功，特别是在图像和视频语言理解方面。然而，相对较少的关注被投入到增强像素级细粒度理解能力中，即模型需要实现视觉信号和语言语义的像素级对齐。虽然一些先前的研究将LMMs应用到相关任务如区域级描述和指针表达分割中，但这些模型仅能独立执行引用或分割任务，无法将这些细粒度感知能力融合到视觉推理中。
### Innovation
为了解决这一问题，本文提出了UniPixel，一种能够灵活理解视觉提示输入并生成图像像素级响应的大规模多模态模型。该模型通过整合像素级感知与通用视觉理解能力来区分自己。具体而言，UniPixel能处理视觉提示并根据需要生成相关的遮罩，在推理时根据这些中间指针进行后续的推理，从而实现细粒度像素级推理。该方法已在包含像素级引用/分割和图像/视频中的对象中心理解在内的10个不同任务的基准上进行了验证，展示了其有效性。此外，还设计了一个新的PixelQA任务来验证该方法的灵活性，该任务需要同时进行引用、分割和问题作答。
### Conclusion
本文提出的UniPixel模型通过无缝地将像素级感知与通用视觉理解能力集成，证明了其在像素级细粒度视觉推理任务上的有效性。该模型为解决现有模型在执行多任务时的不足提供了一种新的解决方案，有望在未来的研究中得到进一步的应用和发展。
## 670. `cs.CV` - Global Prompt Refinement with Non-Interfering Attention Masking for One-Shot Federated Learning [PDF](https://arxiv.org/pdf/2509.22700), [HTML](https://arxiv.org/abs/2509.22700)
### Authors
Zhuang Qi,Pan Yu,Lei Meng,Sijin Zhou,Han Yu,Xiaoxiao Li,Xiangxu Meng
### Background
Federated Prompt Learning (FPL) 允许通过在冻结预训练模型之上调整轻量级提示来进行通信高效的适应。现有 FPL 方法通常依赖于全局信息，这种信息只能在第二轮训练后才能获取，以促进客户端模型之间的协作。因此，它们本质上依赖于多轮通信才能充分发挥其优势。此外，现有的单次联邦学习方法通常侧重于拟合已见过的任务，但缺乏跨任务泛化能力。这就产生了一个需要弥合的差距。
### Innovation
我们提出了一个名为 Global Prompt Refinement with Non-Interfering Attention Masking (GPR-NIAM) 的方法，用于解决单次 FPL 中存在的问题。该方法设计了一个遮罩机制，以限制原始文本嵌入与可学习提示嵌入之间的过度相互作用。GPR-NIAM 通过两个关键模块的合作实现这一点：首先是注意力隔离模块，该模块抑制了可学习提示标记对原始文本标记的关注，并重新加权逆向关注，从而在任务间保持泛化能力；其次是跨机构协同精炼模块，它将分散的视觉知识整合到统一的基础中，并通过多源跨模态知识对齐来校准全局提示，从而进一步缓解由于数据异质性引起的一致性问题。广泛的实验表明，GPR-NIAM 在十个基准数据集上的两类任务中均优于八种最先进的方法，在类别级别和领域级别的泛化能力方面表现出更优的效果。
### Conclusion
在十个多任务基准数据集上进行的广泛实验表明，GPR-NIAM 在类别级别的泛化和领域级别的泛化方面均明显优于八种最先进的方法。
## 671. `cs.CV` - DA²: 任意方向的深度估计 [PDF](https://arxiv.org/pdf/2509.26618), [HTML](https://arxiv.org/abs/2509.26618)
### Authors
Haodong Li,Wangguangdong Zheng,Jing He,Yuhao Liu,Xin Lin,Xin Yang,Ying-Cong Chen,Chunchao Guo
### Background
全景图具有全视野（360°×180°），提供了比透视图像更加完整的视觉描述。由于这一特性，全景深度估计正在3D视觉中获得越来越多的关注。然而，由于全景数据的稀缺性，先前的方法通常仅限于特定领域，导致较差的零样本泛化能力。此外，由于全景图像固有的球形失真，许多方法依赖于透视拆分（例如cubemaps），这导致效率低下。
### Innovation
本文提出了一种全新方案DA²: Depth Anything in Any Direction，这是一个准确、零样本泛化且完全端到端的全景深度估计器。为了解决全景数据稀缺的问题，作者引入了一个数据收集引擎，用于从透视图生成高质量的全景深度数据，并创建了约54.3万个全景RGB-深度数据对，总计约60.7万个。此外，为了解决球形失真的问题，作者提出了一种名为SphereViT的方法，该方法利用球坐标显性地确保了全景图像特征的球面几何一致性，提升了性能。严格的基准测试表明，DA²在多个数据集中的表现优于最强的零样本基线，且性能平均提高了38%。更令人惊讶的是，DA²甚至在特定领域的方法中也表现出色，突显了其优越的零样本泛化能力。此外，DA²作为端到端的解决方案，相比融合方法效率更高。
### Conclusion
DA²在多个基准测试中展示了领先的表现，尤其是在零样本泛化能力方面表现出色。同时，DA²的端到端解决方案也使其在效率上优于基于融合的方法。此项目的数据和代码已公开。
## 672. `cs.CV` - MATRIX: 多模态代理调整以实现稳健的工具使用推理 [PDF](https://arxiv.org/pdf/2510.08567), [HTML](https://arxiv.org/abs/2510.08567)
### Authors
Tajamul Ashraf,Umair Nawaz,Abdelrahman M. Shaker,Rao Anwer,Philip Torr,Fahad Shahbaz Khan,Salman Khan
### Background
视觉语言模型（VLMs）越来越多地用作具有访问外部工具权限的控制器，以实现复杂的推理和决策。然而，其效果受限于高质量多模态轨迹稀缺以及手动注释的成本。本文探讨了如何使用基于视觉的代理调整框架自动生成多模态轨迹、生成逐步偏序对并训练VLM控制器，以实现稳健的工具使用推理。本文的方法构建了一个大规模的含有28,500个任务和177,000条验证轨迹的数据集M-TRACE，使基于模仿的轨迹调整成为可能。并在该数据集基础上开发了MATRIX代理，一个在M-TRACE上针对逐步工具推理进行微调的控制器。为了实现更细粒度的对齐，引入了Pref-X，一个自动生成的11,000个偏好对集，并通过逐步偏好学习对MATRIX进行了优化。在三个基准测试中，MATRIX在工具推理方面始终超越了开源和闭源的VLM，展示了可扩展且有效的多模态工具使用的能力。
### Innovation
本文提出了一个基于视觉的代理调整框架，该框架能够自动生成多模态轨迹、生成逐步偏序对并优化VLM控制器。该框架利用了一个大型数据集M-TRACE，其中包含28,500个任务和177,000条验证轨迹。并通过步骤层面的偏好学习，进一步优化了MATRIX代理，使其在工具推理上表现出色，超越了其他现有的多模态工具使用模型。
### Conclusion
在三个基准测试中，MATRIX展示了在多模态工具使用推理方面的优越性能，证明了其可扩展性和有效性。通过提供数据和代码，作者展示了MATRIX作为一种实现更高效多模态代理调控的可行方案。
## 673. `cs.CV` - UniVideo：视频的统一理解、生成和编辑 [PDF](https://arxiv.org/pdf/2510.08377), [HTML](https://arxiv.org/abs/2510.08377)
### Authors
Cong Wei,Quande Liu,Zixuan Ye,Qiulin Wang,Xintao Wang,Pengfei Wan,Kun Gai,Wenhu Chen
### Background
统一多模态模型在多模态内容生成和编辑方面已显示出有希望的结果，但仍主要局限于图像领域。目前的工作是该领域的进一步拓展，提出了UniVideo框架，它将统一建模扩展到了视频领域。UniVideo采用了双流设计，结合了多模态大语言模型（MLLM）用于指令理解与多模态DiT（MMDiT）用于视频生成。这种设计能够准确理解复杂的多模态指令，同时保持视觉一致性。这使得UniVideo能够在统一架构下统一多种视频生成和编辑任务，并在它们之间联合训练。实验证明，UniVideo在文本/图像到视频生成、上下文视频生成和上下文视频编辑任务中与特定任务基准相当或超越了它们。
### Innovation
UniVideo框架改进了统一多模态建模在视频领域的应用。其创新之处在于采用了双流设计，通过结合多模态大语言模型与多模态DiT（MMDiT）模型，实现了对复杂多模态指令的准确理解和视频的同步生成。此外，UniVideo还展示了两个形式的泛化能力：任务组合（如编辑与风格迁移的结合）和从大规模图像编辑数据转移到自由形式视频编辑的能力，即使在没有针对自由形式视频编辑的显式训练的情况下也能处理未知指令。同时，UniVideo支持基于视觉提示的视频生成，使得MLLM能够理解视觉提示并指导MMDiT在合成过程中的使用。
### Conclusion
实验证明，UniVideo在文本/图像到视频生成、上下文视频生成和上下文视频编辑任务中表现良好，甚至展示了从图像编辑泛化到视频编辑的能力。而且UniVideo具有任务组合和基于视觉提示的视频生成功能，有助于未来的相关研究。为了促进未来的研究，我们将发布该模型和相关代码。
## 674. `cs.CV` - Fourier Transform Multiple Instance Learning for Whole Slide Image Classification [PDF](https://arxiv.org/pdf/2510.15138), [HTML](https://arxiv.org/abs/2510.15138)
### Authors
Anthony Bilic,Guangyu Sun,Ming Li,Md Sanzid Bin Hossain,Yu Tian,Wei Zhang,Laura Brattain,Dexter Hadley,Chen Chen
### Background
WSI分类依赖于多实例学习（MIL）结合空间 patches 特征，但现有方法难以捕捉由于WSI的巨大尺寸和patch嵌入的局部性质导致的全局依赖关系。这阻碍了对粗粒度结构的建模，对于稳健的诊断预测是必要的。现有的方法在建模全局依赖关系时受到了限制，这在处理WSI的粗粒度结构时尤为显著。
### Innovation
提出了一种名为FFT-MIL的新框架，通过频率域分支增强MIL，利用快速傅立叶变换从WSI中提取低频片段，并通过由卷积层和MinMax归一化构成的FFT-Block处理这些片段，以减少频域数据的高方差。通过轻量级的融合策略将学习到的全局频域特征与空间patch特征结合，使得FFT-MIL可以与多种MIL架构兼容。实验结果显示，FFT-Block的集成提高了Macro F1分数和AUC，证明了该方法在不同架构和数据集上的有效性和一致性。
### Conclusion
频率域学习作为一种有效且高效的机制，能够捕获WSI分类中的全局依赖关系，补充了空间特征，促进了基于MIL的计算病理学的可扩展性和准确性。
## 675. `cs.CV` - 探索多模态流的少量样本学习 [PDF](https://arxiv.org/pdf/2510.14543), [HTML](https://arxiv.org/abs/2510.14543)
### Authors
Ziqi Jiang,Yanghao Wang,Long Chen
### Background
跨模态任务中最基本的挑战之一是来自不同模态的特征对齐。预训练的视觉-语言模型虽然能实现图像和文本的一般对齐，但常常需要参数高效微调（PEFT）进一步调整。现有的PEFT方法（如提示调优、LoRA基或适配器基方法）总是选择性地微调一部分参数，可以稍微调整视觉或文本特征，以避免过拟合。然而，这些方法仅进行一次调整并不适用于特征高度纠缠的复杂（或困难）数据集。因此，作者首次提出了一个多方插调整方法，称为Flow Matching Alignment (FMA)，通过学习跨模态的运动场来实现特征对齐。
### Innovation
提出了一个模型无关的多步骤调整方法，称为Flow Matching Alignment (FMA)，通过学习跨模态的运动场。具体来说，FMA 采用固定耦合策略确保类别间的对应关系，在训练中首先利用噪声增强策略缓解数据稀缺问题，最后设计了一个早期停止求解器，以更早结束变换过程，提高效率和准确性。与一次调整的PEFT方法相比，FMA 具有多次调整能力，可以实现更精确和稳健的对齐。研究结果表明，FMA 在各种基准和骨干网络上都能取得显著性能提升，特别是在挑战性数据集上表现尤为突出。
### Conclusion
FMA 方法通过多步骤对齐，解决了复杂数据集（尤其困难的数据集）的特征对齐问题，相较于传统的单步微调方法，能实现更精准和稳健的跨模态特征对齐。在多个评估基准和不同模型架构上，FMA 都展示了显著的性能提升，特别是在挑战性数据集上表现尤为出色。
## 676. `cs.CV` - 无变分自动编码器的潜在扩散模型 [PDF](https://arxiv.org/pdf/2510.15301), [HTML](https://arxiv.org/abs/2510.15301)
### Authors
Minglei Shi,Haolin Wang,Wenzhao Zheng,Ziyang Yuan,Xiaoshi Wu,Xintao Wang,Pengfei Wan,Jie Zhou,Jiwen Lu
### Background
基于扩散的视觉生成最近主要依赖于带有变分自编码器（VAE）的潜在扩散模型。虽然这些模型在高保真合成方面有效，但VAE+扩散的范式存在训练效率低下、推理速度慢和迁移性差等问题。这些问题源于VAE潜在空间的一个关键限制：缺乏明确的语义分离和强大的判别结构。
### Innovation
本文介绍了一种新的潜在扩散模型SVG，它不依赖于变分自编码器，而是利用自监督表示进行视觉生成。SVG通过利用冻结的DINO特征构建一个具有清晰语义判别作用的空间，并通过一个轻量级残差分支捕捉细节以实现高保真重建。扩散模型直接在语义结构化的潜在空间中进行训练，从而实现更高效的训练。SVG加速了扩散训练，支持少步采样，并提高了生成质量。
### Conclusion
实验结果表明，SVG保留了底层自监督表示的语义和判别能力，为其后一种任务通用、高质量的视觉表示提供了理论路径。代码和解释可以在 https://example.com/（请替换为实际链接）获取。
## 677. `cs.CV` - VideoVerse：您的T2V生成器与世界模型有多远？ [PDF](https://arxiv.org/pdf/2510.08398), [HTML](https://arxiv.org/abs/2510.08398)
### Authors
Zeqing Wang,Xinyu Wei,Bairui Li,Zhen Guo,Jinrui Zhang,Hongyang Wei,Keze Wang,Lei Zhang
### Background
近年来，Text-to-Video (T2V) 生成技术的迅速发展使其在构建“世界模型”方面变得至关重要。现有的基准测试在评估最先进T2V模型方面越来越不够充分。首先，目前的评估维度，例如每一帧的美学质量与时序一致性，已经无法区分最先进的T2V模型。其次，事件级别的时序因果关系对视频与其他模态的区分以及构成世界模型的关键成分进行了严重不足。第三，现有的基准测试缺乏对世界知识的系统评估，这些能力对于构建世界模型是至关重要的。因此，引入了VideoVerse这一综合基准，着重评估一个T2V模型是否能够理解现实世界的复杂时序因果关系和世界知识。
### Innovation
VideoVerse是一个全面的基准，重点关注评估T2V模型在理解现实世界中的复杂时序因果关系和世界知识方面的能力。研究团队收集了跨多种领域（如自然景观、体育、室内场景、科幻、化学和物理实验）的代表性视频，并提取了具有固有时序因果关系的事件级描述，然后由独立标注者将这些描述重写为文本到视频的提示。通过现代视觉语言模型，开发了一种与人类偏好对齐的问答基准评估管道。最终，对最先进的开源和闭源T2V模型在VideoVerse上的进行了系统的评估。
### Conclusion
本文通过引入VideoVerse基准，深入分析了当前T2V生成器与世界模型之间存在的差距，揭示了最先进的T2V模型在处理复杂时序因果关系和世界知识方面的不足，并为T2V技术的发展指明了新的研究方向。
## 678. `cs.CV` - LLM-RG: 使用大型语言模型在户外场景中实现指代定位 [PDF](https://arxiv.org/pdf/2509.25528), [HTML](https://arxiv.org/abs/2509.25528)
### Authors
Pranav Saxena,Avigyan Bhattacharya,Ji Zhang,Wenshan Wang
### Background
在户外驾驶场景中实现指代定位极具挑战性，因为户外场景具有极大的变异性，存在很多视觉上相似的物体，且动态元素使得自然语言参考关系的解决复杂化（例如，“右侧的黑色汽车”）。
### Innovation
LLM-RG 提出了一种结合现成的视觉-语言模型进行细粒度属性提取与大型语言模型进行符号推理的混合管道。该方法通过使用 LLM 提取相关对象类型和属性，检测候选区域，利用 VLM 生成丰富的视觉描述，并结合这些描述和空间元数据，输入给 LLM 进行链式推理，从而识别参照物的边界框。
### Conclusion
LLM-RG 在 Talk2Car 基准上相较于基于 LLM 和 VLM 的基线模型取得了显著提升。此外，我们的消融实验表明，添加 3D 空间线索进一步改善了定位。结果证明了视觉-语言模型和大型语言模型零样本使用的互补优势，用于在户外实现鲁棒的指代定位。
## 679. `cs.CV` - 通过奖励导向优化实现身份保持的图像到视频生成 [PDF](https://arxiv.org/pdf/2510.14255), [HTML](https://arxiv.org/abs/2510.14255)
### Authors
Liao Shen,Wentao Jiang,Yiran Zhu,Jiahe Li,Tiezheng Ge,Zhiguo Cao,Bo Zheng
### Background
近年来，图像到视频（Image-to-Video, I2V）生成技术在从静态图像合成高质量、时序连贯的视频方面取得了显著进步。I2V技术在众多应用中，尤其是以人为本的视频生成领域，占据了很大一部分。然而，现有的I2V模型在保持输入的人脸图像与生成的视频之间的身份一致性方面遇到困难，尤其是在视频中的人物表现出显著的表情变化和运动时。当人在图像中所占面积很小的时候，这一问题变得尤为关键。由于人类对身份变化非常敏感，这在I2V生成中构成了一个重要但尚未充分探索的挑战。
### Innovation
本文提出了一种名为Identity-Preserving Reward-guided Optimization（IPRO）的新型视频扩散框架，基于强化学习增强身份保持性能。该方法通过引入直接有效的调优算法优化扩散模型，使用面部身份评分器进行优化。为了提高性能和加速收敛，我们的方法将奖励信号反向传播到最后采样链的步骤，提供更丰富的梯度反馈。我们还提出了一种新的面部评分机制，将真实视频中的面部作为面部特征池，提供多角度的面部信息以增强泛化能力。此外，还引入了KL散度正则化以稳定训练和防止过度拟合奖励信号。在Wan 2.2 I2V模型和我们内部的I2V模型上的大量实验验证了该方法的有效性。我们的项目和代码可在该链接下载：this https URL
### Conclusion
实验结果表明，我们的方法在保持身份一致性方面非常有效。我们的项目和代码已经公开，并可在指定的链接处获取。
## 680. `cs.CV` - Bee: 一个高质量语料库和全栈套件，以解锁高级开放型大型语言模型 [PDF](https://arxiv.org/pdf/2510.13795), [HTML](https://arxiv.org/abs/2510.13795)
### Authors
Yi Zhang,Bolin Ni,Xin-Sheng Chen,Heng-Rui Zhang,Yongming Rao,Houwen Peng,Qinglin Lu,Han Hu,Meng-Hao Guo,Shi-Min Hu
### Background
目前，完全开放型多模态大型语言模型（MLLMs）在数据质量方面与专有模型存在显著差距，特别是在监督微调（SFT）阶段，现有开源数据集中广泛存在噪声问题，尤其是在复杂逻辑推理（CoT）数据方面存在严重不足。这阻碍了模型高级能力的发展。
### Innovation
本研究主要贡献包括：1）提出了Honey-Data-15M数据集，包含约1500万个问答对，并通过多种清理技术进行处理，加入新的一级和二级CoT增强策略；2）引入了HoneyPipe数据清理管道及其框架DataStudio，为社区提供了透明且灵活的数据清理方法，超越了静态数据集的发布方式；3）通过Honey-Data-15M训练了Bee-8B模型，证明了该模型在开源大型语言模型中达到了新的最佳性能，部分场合超过了最近的半开放模型InternVL3.5-8B。
### Conclusion
本研究通过提供高质量的数据集和全栈功能，推动了完全开放型大型语言模型的发展，展示了系统地提升数据质量是建立与半开放模型高度竞争的彻底开放型模型的关键途径。
## 681. `cs.CV` - CrossRay3D: 几何结构和类别分布指导下的高效多模态3D检测 [PDF](https://arxiv.org/pdf/2510.15991), [HTML](https://arxiv.org/abs/2510.15991)
### Authors
Huiming Yang
### Background
现有的稀疏跨模态检测器相较于鸟瞰图（BEV）检测器在下游任务适应性和计算成本方面具有优势，但它们未能充分考虑Token表示的质量，导致这些探测器在前景质量上表现不佳，且性能受限。现有稀疏检测器在这一方面存在不足，本文旨在克服这一缺陷，提出了一种通过保留几何结构和分类分布来提升稀疏检测器性能的方法。
### Innovation
本文提出了Sparse Selector（SS），其核心模块Ray-Aware Supervision（RAS）和Class-Balanced Supervision分别在训练阶段保留丰富的几何信息并适应性调整类别语义的重要性。此外，设计了Ray Positional Encoding (Ray PE)来解决LiDAR模态和图像之间的分布差异。将这些模块集成到一个端到端的稀疏多模态检测器CrossRay3D中，该检测器在nuScenes基准测试中达到了72.4 mAP和74.7 NDS的最佳性能，并且运行速度比其他领先方法快1.84倍。此外，CrossRay3D在网络中部分或完全缺失LiDAR或摄像头数据的情况下仍表现出强大的鲁棒性。
### Conclusion
实验表明，通过引入几何结构和类别分布指导，CrossRay3D在多模态3D检测中表现出色，实现了性能和效率的双重提升。
## 682. `cs.CV` - SceneCOT: Eliciting Grounded Chain-of-Thought Reasoning in 3D Scenes [PDF](https://arxiv.org/pdf/2510.16714), [HTML](https://arxiv.org/abs/2510.16714)
### Authors
Xiongkun Linghu,Jiangyong Huang,Ziyu Zhu,Baoxiong Jia,Siyuan Huang
### Background
现有的3D大规模语言模型（LLMs）在实现基于场景的问答方面仍存在不足，主要原因是缺乏对类似人类的场景-物体关联推理机制的深入探索。本文通过介绍一种新的框架来弥合这一缺口，首先引入了一种在3D场景中的基于证据的思想链推理方法（SCENECOT），将复杂的推理任务分解为更简单且易于管理的问题，并基于多模态专家模块构建相应的视觉线索。
### Innovation
本文提出了SCENECOT-185K，这是第一个大型的基于证据的思想链推理数据集，包含185K高质量实例。通过在各种复杂的3D场景推理基准测试中进行广泛实验，证明了新框架具有强大的性能和高保真的问答连贯性。这是首次将基于证据的思想链推理应用到3D场景理解领域，实现了逐步的人类推理，并显示出扩展到更广泛的3D场景理解场景的潜力。此外，本文还提出了一个新的3D场景中的基于证据的思想链推理方法（SCENECOT），将复杂的推理任务分解为更简单和可管理的问题，创建了相应的视觉线索。
### Conclusion
本文的研究成果展示了在3D场景理解中实现基于证据的思想链推理的可行性。通过引入SCENECOT框架，为这一领域的进一步研究奠定了坚实的基础，并为进一步探索和应用奠定基础。
## 683. `cs.CV` - 基于特征融合和自适应类别平衡的面部表情帕金森病严重程度诊断 [PDF](https://arxiv.org/pdf/2510.17373), [HTML](https://arxiv.org/abs/2510.17373)
### Authors
Yintao Zhou,Wei Huang,Zhengyu Li,Jing Huang,Meng Pang
### Background
帕金森病（PD）的严重程度诊断对于早期检测潜在患者和采用针对性干预措施至关重要。基于面部表情进行PD诊断有效且易于实施，尤其利用PD患者的‘面具脸’症状。然而，现有基于面部表情的方法通常依赖单一类型的表情，可能导致误诊，并且忽视了不同PD阶段的类别偏差，从而降低预测性能。大多数现有的方法专注于二元分类（即PD / 非PD）而不是诊断PD的严重程度。
### Innovation
提出了一种新的基于面部表情的方法，用于PD严重程度的诊断，该方法通过注意力机制融合了多种面部表情特征；同时提出了一个自适应类别平衡策略，该策略根据训练样本的类别分布和分类难度动态调整样本贡献，以缓解类别偏差问题。实验结果表明，该方法在PD严重程度诊断上的表现具有潜力，并且注意力机制特征融合和自适应类别平衡的有效性也得到了验证。
### Conclusion
提出的基于注意力机制融合和自适应类别平衡的面部表情方法在PD严重程度诊断中表现出色，并验证了注意力机制的特征融合和自适应类别平衡策略的有效性。
## 684. `cs.CV` - UniWorld-V2: 使用扩散负感知微调和MLLM隐反馈强化图像编辑 [PDF](https://arxiv.org/pdf/2510.16888), [HTML](https://arxiv.org/abs/2510.16888)
### Authors
Zongjian Li,Zheyuan Liu,Qihui Zhang,Bin Lin,Feize Wu,Shenghai Yuan,Zhiyuan Yan,Yang Ye,Wangbo Yu,Yuwei Niu,Shaodong Wang,Xinhua Cheng,Li Yuan
### Background
基于指令的图像编辑已经取得了显著的进步，但完全通过监督微调训练的模型往往会过度拟合标注模式，阻碍了其探索和泛化的能力，超越了训练分布。
### Innovation
引入了一个基于策略优化的新颖后训练框架Edit-R1。具体而言，采用了与流动匹配前向过程一致的无似然性策略优化方法Diffusion Negative-aware Finetuning（DiffusionNFT），这使高阶采样器和更有效的训练成为可能。此外，通过采用一个多功能大型语言模型（MLLM）作为统一的、无需训练的奖励模型，利用其输出logits提供精细反馈，克服了缺乏通用奖励模型的问题。还精心设计了一种低方差组过滤机制，减少MLLM评分噪声，稳定优化过程。UniWorld-V2在ImgEdit和GEdit-Bench基准测试中的表现堪称最好的，分别为4.49和7.83。而且，该框架具有通用性，当应用于多种基础模型时，能显著提高性能，展示了其广泛的适用性。
### Conclusion
UniWorld-V2利用该框架在ImgEdit和GEdit-Bench基准测试中的得分分别达到4.49和7.83，展现了其优越的性能。这项研究还展示了该框架在不同基础模型上的通用性和适用性，为未来的研究奠定了基础。
## 685. `cs.CV` - PRISMM-Bench: 一个基于同行评审多模态不一致性的基准 [PDF](https://arxiv.org/pdf/2510.16505), [HTML](https://arxiv.org/abs/2510.16505)
### Authors
Lukas Selch,Yufang Hou,M. Jehanzeb Mirza,Sivan Doveh,James Glass,Rogerio Feris,Wei Lin
### Background
大型多模态模型（LMMs）在科学研究中的应用日益广泛，但尚不清楚它们是否能够可靠地理解并处理论文中的多模态复杂性。一个主要挑战在于检测并解决跨文本、图表、表格和方程的一致性问题，这些问题往往是微妙的、领域特定的，并且最终损害了清晰度、可复制性和信任。现有的基准测试忽略了此问题，要么孤立单模态，要么依赖合成错误而未能捕捉到现实世界的复杂性。
### Innovation
该研究引入了PRISMM-Bench，这是首个基于真实审稿人标记的科学论文中不一致性的基准。通过多阶段的审稿提取、LLM辅助筛选和人工验证过程，从242篇论文中精选出262个不一致点。研究设计了三项任务：不一致性识别、修正和配对匹配，以评估模型跨模态检测、修正和推理不一致性的能力。此外，该研究为了应对多项选择评价中的选择捷径问题，引入了结构化的JSON格式答案表示，从而减少对外表风格线索的依赖，以最小化语言偏见。
### Conclusion
该研究通过基准测试各种LMMs，揭示了令人惊讶的低性能（26.1-54.2%），这强调了多模态科学推理的挑战，并推动了值得信赖的科学助手的发展。
## 686. `cs.CV` - LongInsightBench：评估人类中心长视频理解的全模态模型的综合基准 [PDF](https://arxiv.org/pdf/2510.17305), [HTML](https://arxiv.org/abs/2510.17305)
### Authors
ZhaoYang Han,Qihan Lin,Hao Liang,Bowen Chen,Zhou Liu,Wentao Zhang
### Background
当前缺乏专门针对长时间、信息密集的视频（包括视觉、音频和文本模态）并评估模型理解能力和复杂背景元素（如人类语言、视角、动作等）的基准。现有的基准可能涵盖不足或设计不够全面，无法有效评估全模态模型在长时间视频理解上的精确时间定位和长期因果推理等任务的表现。因此，急需一个全面的基准来弥补这一空白，以评估这些模型在实际应用场景中的能力，特别是在人类智能的核心要素方面。
### Innovation
提出了LongInsightBench，这是首个专门设计来评估模型理解长时间视频能力的基准，强调人类语言、视角、动作及其他上下文元素，同时结合视觉、音频和文本模态。LongInsightBench 在三个方面表现突出：1）长期、信息密集的视频；2）多样且具有挑战性的任务场景；3）严格的综合质量保证流程。此外，还揭示了全模态模型在多模态融合过程中存在信息丢失和处理偏差的问题。实验结果表明，全模态模型在需要精确时间定位和长期因果推理的任务上仍面临挑战。
### Conclusion
使用LongInsightBench 设计了一系列实验，实验表明，全模态模型在需要精确时间定位和长期因果推理的任务中仍然面临挑战，并揭示了多模态融合中的信息丢失和处理偏差问题。此外，该基准还提供了复现研究结果的数据集和代码。
## 687. `cs.CV` - 利用AV1运动向量进行快速和密集的特征匹配 [PDF](https://arxiv.org/pdf/2510.17434), [HTML](https://arxiv.org/abs/2510.17434)
### Authors
Julien Zouein,Hossein Javidnia,François Pitié,Anil Kokaram
### Background
在短视频中，为了实现快速且密集的特征匹配，研究者探索了重新利用AV1视频编码器中的运动向量来生成亚像素对应关系和经过余弦一致性筛选后的短跟踪。这种方法与传统的顺序SIFT相比，在CPU使用方面有显著的优势，但同时仍能保持高质量的匹配及其几何关系。研究以一个包含117帧的示例短视频进行演示，结果显示这种方法可以高效地注册所有帧并重建出高精度的匹配点，尽管Bundle Adjustment（BA）的处理时间会随着匹配点密度增加而增加。
### Innovation
该研究创新性地提出了利用AV1视频编码器中的运动向量进行特征匹配的新方法，这不仅减少了CPU消耗，还能生成密集且高质量的对应关系。该方法即使在较短时间内也能实现与传统方法相当的几何关系匹配效果，同时具有较小的系统开销。
### Conclusion
该研究演示了在压缩域中利用特征匹配的可行性，证明了这种方法作为资源高效且实用的前端技术在完整流程中的扩展具有明确的路径和潜力。尽管存在匹配点密度增加时BA处理时间的增长问题，这种技术仍然显示出巨大的潜力，并可进一步优化以加速和提高匹配精度。
## 688. `cs.CV` - 深认识：学习一站式密集关键点 [PDF](https://arxiv.org/pdf/2510.17422), [HTML](https://arxiv.org/abs/2510.17422)
### Authors
Shaharyar Ahmed Khan Tareen,Filza Khan Tareen
### Background
关键点检测是许多计算机视觉任务的基础，包括图像配准、运动结构、3D重建、视觉里程计等。传统检测器（如SIFT、SURF、ORB、BRISK等）和基于学习的方法（如SuperPoint、R2D2、LF-Net、D2-Net等）虽然表现出强劲的性能，但存在显著的局限性。这些局限性包括对光度变化的敏感性、关键点密度和可重复性低、面对挑战性场景的适应性有限，以及缺乏语义理解，经常不能优先考虑视觉重要区域。针对这些局限性，我们需要一种能够综合传统检测器优点、充分利用深度学习技术，同时能密集、适应性强的关键点检测器。
### Innovation
DeepDetect是以深度学习为基础、集众多检测器优点于一身的密集关键点检测器。通过融合多类关键点和边缘检测器的结果生成准确的掩码，不仅提取了图像中丰富的视觉特征，还使用了ESPNet模型进行高效的训练。这一设计使得DeepDetect能够在多种环境下更加随意地生成密集的关键点，并具有更强的鲁棒性，相比其他检测器其关键点密度、可重复性和正确匹配数量都有显著的提升。
### Conclusion
在Oxford Affine Covariant Regions数据集上的评估表明，DeepDetect在关键点密度、可重复性和正确匹配的数量上都超越了其他检测器。具体数值为0.5143（平均关键点密度）、0.9582（平均可重复性）和59,003（正确匹配）。这表明DeepDetect是一个先进且实用的解决方案，适用于多种视觉任务的需求。
## 689. `cs.CV` - CaMiT：一种面向分类和生成的时间感知汽车模型数据集 [PDF](https://arxiv.org/pdf/2510.17626), [HTML](https://arxiv.org/abs/2510.17626)
### Authors
Frédéric LIN,Biruk Abere Ambaw,Adrian Popescu,Hejer Ammar,Romaric Audigier,Hervé Le Borgne(Université Paris-Saclay, CEA, List, F-91120, Palaiseau, France)
### Background
AI系统需要适应不断变化的视觉环境，特别是在物体外观随时间变化的领域。汽车模型作为科技产品的代表，其外观也随时间演变。为了研究和发展适应这种变化的细粒度视觉识别和生成方法，本文提出了Car Models in Time (CaMiT) 数据集。
### Innovation
本文引入了CaMiT，一个记录190种不同汽车模型从2007年到2023年间外观变化的细粒度数据集。通过静态预训练和时间增量训练策略，本文提出了一种时间增量分类设置，提高模型在不同年份测试时的鲁棒性。此外，本文还探索了利用时间元数据进行时间感知的图像生成方法，从而生成更真实的图像。
### Conclusion
CaMiT数据集为研究和评估细粒度视觉识别和生成在时间上的适应能力提供了丰富的基准。通过时间增量预训练和分类学习方法，显著提高了模型在不同时间点的鲁棒性。此外，时间感知的图像生成方法也明显提高了生成图像的现实度。
## 690. `cs.CV` - 面向上下文的伪标签评分用于零样本视频摘要 [PDF](https://arxiv.org/pdf/2510.17501), [HTML](https://arxiv.org/abs/2510.17501)
### Authors
Yuanli Wu,Long Zhang,Yue Du,Bin Li
### Background
随着视频在社交媒体、监控和教育中的广泛使用，压缩长片段为简洁且忠实的代理变得至关重要。监督方法通过密集标签学习帧/镜头的重要性，并在特定领域内表现出色，但跨数据集时成本高且脆弱；而无监督方法避免使用标签，但常常错过高层次语义和叙述线索。最近的零样本管道使用大语言模型进行无需训练的摘要，但仍对手工艺提示和数据集特定性敏感。本研究提出了一种基于评分标准的伪标签提示框架，将一小部分人工注释转换为高置信度的伪标签，整合成结构化的、数据集适应的评分标准，用于可解释场景评估。在推理过程中，边界场景（首尾）从其描述中得分为，而中间场景包括相邻段落的简短总结来评估进展和冗余性，使语言模型能够平衡局部重要性与全局一致性。本研究在三个基准上验证，结果表明基于评分标准的伪标签提示与上下文提示相结合，稳定了基于语言模型的评分，并且为通用和查询着重视频摘要提供了一种简约且易解释的零样本范式。
### Innovation
提出了一种基于评分标准的伪标签提示框架，利用一小部分人工注释转换成高置信度的伪标签，并整合成结构化的、数据集适应的评分标准进行可解释场景评估。该方法在推理过程中不仅考虑边界场景，也包含了中间场景的简短总结，以评估进展和冗余性，使得语言模型能够在局部重要性和全局一致性间取得平衡
### Conclusion
该研究在SumMe和TVSum两个基准上分别达到了57.58和63.05的F1值，超过了零样本基线(56.73, 62.21)，接近监督模型的效果；在查询着重的QFVS基准上，F1值达到了53.79，超越了53.42，并且在验证视频中保持稳定。这些结果表明，基于评分标准的伪标签提示与上下文提示相结合，能够稳定基于大语言模型的评分，提供了一种通用且易解释的零样本视频摘要范式。
## 691. `cs.CV` - Glyph: 通过视觉文本压缩扩展上下文窗口 [PDF](https://arxiv.org/pdf/2510.17800), [HTML](https://arxiv.org/abs/2510.17800)
### Authors
Jiale Cheng,Yusen Liu,Xinyu Zhang,Yulin Fei,Wenyi Hong,Ruiliang Lyu,Weihan Wang,Zhe Su,Xiaotao Gu,Xiao Liu,Yushi Bai,Jie Tang,Hongning Wang,Minlie Huang
### Background
大规模语言模型（LLMs）越来越多地依赖于长上下文建模来完成诸如文档理解、代码分析和多步推理等任务。然而，将上下文窗口扩展到百万词级别会带来巨大的计算和内存成本，限制了长上下文LLMs的实际应用。
### Innovation
本文提出了一种新颖的方法——视觉上下文扩展（visual context scaling），通过将长文本转化为图像并使用视觉语言模型（VLMs）处理，这种方式大幅压缩了文本输入的同时保留了语义信息。进一步地，作者设计了一种由LLM驱动的基因搜索算法，用以优化视觉渲染配置，平衡准确性和压缩率。实验结果表明，该方法能够达到3-4倍的token压缩，保持与Qwen3-8B等顶级LLMs相当的准确性。此外，这种压缩还提高了预填充和解码速度大约4倍，并且SFT训练速度大约提升2倍。在极端压缩情况下，128K上下文的视觉语言模型能够处理1百万词级别的文本任务。
### Conclusion
本文方法实现了对不同长上下文基准测试的压缩，保持了与顶级LLMs相当的精度，并且在预填充、解码和SFT训练速度方面均有显著提升。通过视觉渲染的文本数据也对实际多模态任务（如文档理解）有益。
## 692. `cs.CV` - PICABench：我们离物理真实感图像编辑还有多远？ [PDF](https://arxiv.org/pdf/2510.17681), [HTML](https://arxiv.org/abs/2510.17681)
### Authors
Yuandong Pu,Le Zhuo,Songhao Han,Jinbo Xing,Kaiwen Zhu,Shuo Cao,Bin Fu,Si Liu,Hongsheng Li,Yu Qiao,Wenlong Zhang,Xi Chen,Yihao Liu
### Background
图像编辑领域近期取得了显著进展，现代编辑模型可以遵循复杂指令操作原始内容。然而，这些模型在生成逼真图像时，往往忽略了物理效应的重要性，如移除物体的同时也要移除其阴影、反射及与周围物体的交互等。当前的模型和基准测试主要关注指令的完成，而忽视了这些物理效应。因此，作者引入了一个名为PICABench的新基准测试，该测试系统性地评估了大多数常见编辑操作在光学、力学和状态转换方面的物理逼真度。此外，还提出了一个可靠评估协议PICAEval，该协议使用视频理解模型作为判官，并进行逐案、逐区域的人工标注和问题问答，进一步研究有效的解决方法，利用视频学习物理知识并构建了一个训练数据集PICA-100K。评估结果显示，物理真实感仍是编辑领域的一大挑战，仍有很多探索空间。
### Innovation
1. 提出了一个名为PICABench的新基准测试，系统性地评估图像编辑操作在物理逼真度上的表现。2. 提出了一种可靠评估方法PICAEval，使用视频理解模型和人工标注结合的方式进行逐案、逐区域的评估。3. 构建了一个用于学习物理知识的训练数据集PICA-100K，以辅助图像编辑模型的学习和改进。4. 通过评估主流模型，发现物理真实感仍有很大的改进空间。
### Conclusion
物理真实感仍然是图像编辑领域的一大难题，仍然有大量的探索空间。希望通过提出的基准测试和解决方案，能够促进未来研究，从简单的内容编辑过渡到物理上一致的真实感。
## 693. `cs.CV` - 学习通过观看：机器人操作基于视频的学习方法综述 [PDF](https://arxiv.org/pdf/2402.07127), [HTML](https://arxiv.org/abs/2402.07127)
### Authors
Chrisantus Eze,Christopher Crick
### Background
机器人操作技能的学习受到多样化且无偏见数据集稀缺的阻碍。尽管精心策划的数据集有所帮助，但在普遍性和现实世界应用中的挑战依然存在。大规模的“野生成”视频集通过自我监督技术推动了计算机视觉的进步，而翻译这一概念到机器人领域，最近的研究探索了通过观看在线获取的大量视频来学习操作技能。这种方法不仅提供了可扩展的监督形式，还减少了数据集的偏见。本文综述了基于视频的学习方法，包括视频特征表示学习技术、物体可利用性理解、3D手/身体建模以及大规模机器人资源，以及从不受控视频示范中获取机器人操作技能的新兴技术。
### Innovation
将大规模的人类视频中通过观察和自我监督学习的方法应用于机器人操作，提供了一种可扩展且减少数据偏见的监督形式。同时，综述了有关视频基础学习的新兴技术和方法，旨在增强机器人操作的泛化能力和样本效率，并探讨了该领域的挑战和未来方向，结合计算机视觉、自然语言处理和机器人学习的交叉领域。
### Conclusion
本文总结了基于视频的学习方法，分析了这些方法相较于标准数据集的优势，并讨论了这一新领域面临的重要挑战和未来发展方向。
## 694. `cs.CV` - 在扩散MRI追踪中使用多模态深度学习方法预测白质形状 [PDF](https://arxiv.org/pdf/2504.18400), [HTML](https://arxiv.org/abs/2504.18400)
### Authors
Yui Lo,Yuqian Chen,Dongnan Liu,Leo Zekelman,Jarrett Rushmore,Yogesh Rathi,Nikos Makris,Alexandra J. Golby,Fan Zhang,Weidong Cai,Lauren J. O'Donnell
### Background
白质纤维束成像（tractography）的形状度量已经显示出作为辅助描述符的强大潜力，可以提供关于解剖变异性和与认知或临床表型相关性的互补见解。然而，传统方法用于计算形状度量的计算成本很高，对于大规模数据集而言，依赖于体素表示使得计算非常耗时和费劲。
### Innovation
提出了一种名为Tract2Shape的新型多模态深度学习框架，该框架利用几何（点云）和标量（表格）特征来预测十个白质纤维束形状度量。为了提高模型效率，该模型使用降维算法来预测五个主要形状组件。Tract2Shape能够在两个独立收集的数据集上进行训练和评估（HCP-YA数据集和PPMI数据集），并展示了在其对未见过的PPMI数据集的评估中具有高稳健性和泛化能力。
### Conclusion
Tract2Shape能够快速、准确并且具有通用性地预测来自纤维束成像数据的白质形状度量，支持大规模数据集的分析。该框架为未来的大型白质形状分析奠定了有希望的基础。
## 695. `cs.CV` - 你需要回归预测即可实现医学图像转换 [PDF](https://arxiv.org/pdf/2505.02048), [HTML](https://arxiv.org/abs/2505.02048)
### Authors
Sebastian Rassmann,David Kügler,Christian Ewert,Martin Reuter
### Background
尽管生成对抗网络（GAN）和扩散模型（DM）在自然图像合成方面取得了显著成果，但在医学应用中，准确性与保真度更为关键，而这些模型在医学应用中可能因引入幻觉或复制不必要的采集噪声而有害。因此，需要一种新的方法来实现医学图像转换（MIT），以克服现有模型的缺点。
### Innovation
本文提出了一种名为YODA（只有一次去噪或平均）的2.5D扩散基础框架，用于医学图像转换。作者通过新的采样策略，即期望逼近（ExpA）采样和回归采样，解决了现有模型中存在的噪声复制问题，提高了图像质量。此外，证明了回归采样在某些情况下甚至优于现有技术，并且在某些下游任务中确认了迭代精炼对信息转换效果较弱的观点。
### Conclusion
实验表明，YODA相比于现有的八种最先进DM和GAN模型，在某些医学应用中能够产生更好的图像质量，同时证明了在高精度的医学图像转换中，并非扩散模型和GAN模型具有绝对优势，回归模型也可以达到高质量的结果。
## 696. `cs.CV` - VLA-Cache: 通过自适应令牌缓存实现高效视觉-语言-行动操作 [PDF](https://arxiv.org/pdf/2502.02175), [HTML](https://arxiv.org/abs/2502.02175)
### Authors
Siyu Xu,Yunke Wang,Chenghao Xia,Dihao Zhu,Tao Huang,Chang Xu
### Background
VLA模型展示了强大的多模态推理能力，能够直接从视觉感知和语言指令生成动作，但其巨大的计算成本使其难以适用于需要快速决策的实时机器人控制场景。现有方法无法有效应对这一挑战，从而限制了VLA模型在实时机器人控制中的应用潜力。
### Innovation
本文提出了一种名为VLA-Cache的方法，这是一种无需训练的推理加速技术，通过适应性缓存和重用静态视觉令牌来减少计算开销。VLA-Cache利用机器人操作中的时间连续性，在相邻帧之间识别差别最小的令牌，并重用其缓存的关键值表示，从而避免冗余计算。同时，为了保持动作的精确性，VLA-Cache选择性地重新计算与环境相关的任务相关令牌，以确保关键视觉信息的准确性。此外，本文还提出了一种层自适应令牌重用策略，根据解码器层之间的注意力集中程度动态调整重用比率，优先重新计算关键令牌。实验结果显示，VLA-Cache在两个模拟平台（LIBERO和SIMPLER）及真实机器人系统中的应用，实现了CUDA延迟1.7倍的加速和控制频率15%的提升，同时任务成功率几乎没有损失。该研究不仅提高了VLA模型的实时性能，还提供了一种新的缓存机制和动态重用策略，显著提高了操作效率和准确性。
### Conclusion
VLA-Cache在现有的VLA模型基础上，通过时空连续性和动态模型的利用，显著提高了动作生成的实时性和精确性，为视觉-语言-行动系统的实时控制提供了有效解决方案。
## 697. `cs.CV` - TACO:通过任务映射指导序列配置增强多模态上下文学习 [PDF](https://arxiv.org/pdf/2505.17098), [HTML](https://arxiv.org/abs/2505.17098)
### Authors
Yanshu Li,Jianjiang Yang,Tian Yun,Pinyuan Feng,Jinfa Huang,Ruixiang Tang
### Background
多模态在上下文学习（ICL）已经成为充分利用大型视觉语言模型（LVLM）能力的关键机制。然而，其效果高度依赖于输入ICL序列的质量，尤其是在涉及复杂推理或开放式生成的任务中。一个主要限制是我们对LVLM如何在推理过程中利用这些序列的理解有限。
### Innovation
本文通过任务映射的视角系统地解释了多模态ICL，揭示了演示内部和之间的局部和全局关系如何指导模型推理。基于这一洞见，我们提出了TACO，一种轻量级的基于变压器的模型，配备了任务感知注意力，可以动态配置ICL序列。通过将任务映射信号注入自回归解码过程，TACO创建了序列构建与任务推理之间的双向协同效应。实验表明，TACO在五种LVLM和九个数据集上的表现始终优于基线模型，将任务映射定位为解释和改进多模态ICL的一种新颖且有价值的视角。
### Conclusion
实验结果表明，TACO在多样化的ICL任务上始终优于基线模型，强调了任务映射作为解释和改进多模态ICL的一种新颖且有价值的视角。
## 698. `cs.CV` - RWKV-UNet: 提高UNet以实现有效的医学图像分割 [PDF](https://arxiv.org/pdf/2501.08458), [HTML](https://arxiv.org/abs/2501.08458)
### Authors
Juntao Jiang,Jiangning Zhang,Weixuan Liu,Muxuan Gao,Xiaobin Hu,Zhucun Xue,Yong Liu,Shuicheng Yan
### Background
近年来，深度学习在医学图像分割方面取得了显著进展，尤其是卷积神经网络（CNNs）和变压器模型。然而，CNNs在捕捉长期依赖性方面存在局限性，而变压器则面临高计算复杂度的问题。
### Innovation
提出RWKV-UNet模型，将RWKV（接收权重键值）结构集成到U-Net架构中，以增强模型捕捉长期依赖性和提升上下文理解的能力，这对于准确的医学图像分割至关重要。通过构建综合了CNN和RWKVs的全球-局部空间感知（GLSP）模块，以及多尺度特征融合的交叉通道混合（CCM）模块，实现了全局通道信息的整合。
### Conclusion
在11个基准数据集上的实验表明，RWKV-UNet在各种类型的医学图像分割任务中达到了最先进的性能。此外，较小的变体RWKV-UNet-S和RWKV-UNet-T平衡了准确性和计算效率，使其适用于更广泛的临床应用。
## 699. `cs.CV` - REOrdering Patches Improves Vision Models [PDF](https://arxiv.org/pdf/2505.23751), [HTML](https://arxiv.org/abs/2505.23751)
### Authors
Declan Kutscher,David M. Chan,Yutong Bai,Trevor Darrell,Ritwik Gupta
### Background
序列模型如变压器需要将输入表示为一维序列。在视觉任务中，通常通过固定的方向顺序（行为主序）将图像展平。虽然全自注意力机制在置换不变性方面表现出色，但现代长序列变压器越来越多地依赖于打破这种不变性的架构性近似，引入了对补丁顺序的敏感性。研究显示，补丁顺序显著影响模型性能，简单的替代顺序如列为主序或希尔伯特曲线均可带来显著的准确性提升。
### Innovation
本文提出了REOrder，这是一种两阶段框架，用于发现任务最优补丁排序。首先，通过评估各种补丁序列的可压缩性，推导出基于信息论的先验。然后，通过优化Plackett-Luce策略并使用REINFORCE，学习排列策略。这种方法能有效学习组合置换空间中的策略。实验结果显示，与行为主序相比，REOrder在ImageNet-1K上最高可提高3.01％的top-1准确率，在Functional Map of the World上则提升13.35%。
### Conclusion
REOrder框架显著提高了视觉模型的表现，验证了补丁顺序对模型性能的影响，并展示了如何通过信息论先验和REINFORCE优化策略来发现任务最优的补丁排序。
## 700. `cs.CV` - VIKI-R: 通过强化学习协调具身多智能体合作 [PDF](https://arxiv.org/pdf/2506.09049), [HTML](https://arxiv.org/abs/2506.09049)
### Authors
Li Kang,Xiufeng Song,Heng Zhou,Yiran Qin,Jie Yang,Xiaohong Liu,Philip Torr,Lei Bai,Zhenfei Yin
### Background
在动态环境中协调多个物理实体智能体仍然是人工智能中的核心挑战，需要感知驱动的推理和可扩展的合作策略。虽然近期工作利用大语言模型（LLMs）进行多智能体规划，但有限的研究开始探索视觉语言模型（VLMs）进行视觉推理。然而，这些VLM方法在支持多种身体类型方面仍然是有限的。
### Innovation
本文引入了VIKI-Bench，这是一种针对具身多智能体合作的人为层次基准，包括三个结构化级别：智能体激活、任务规划和轨迹感知。VIKI-Bench 包含多样化的人体形态机器人、多视角视觉观测和结构化监督信号，以评估基于视觉输入的推理能力。此外，本文提出了VIKI-R，这是一种两级框架，它首先对预训练的视觉语言模型（VLM）进行微调，使用带有思维链注释的演示，然后在多级奖励信号下进行强化学习。实验结果表明，VIKI-R 在所有任务级别上显著优于基线方法。进一步的实验结果显示，强化学习使异构智能体之间的组合合作模式得以涌现。
### Conclusion
VIKI-Bench 和 VIKI-R 为推进使用强化学习的多智能体、视觉驱动合作的人工具身智能系统提供了一个统一的测试平台和方法。
## 701. `cs.CV` - Class-wise Balancing Data Replay for Federated Class-Incremental Learning [PDF](https://arxiv.org/pdf/2507.07712), [HTML](https://arxiv.org/abs/2507.07712)
### Authors
Zhuang Qi,Ying-Peng Tang,Lei Meng,Han Yu,Xiaoxiao Li,Xiangxu Meng
### Background
Federated Class Incremental Learning (FCIL)的目标是在多个客户端中协作处理不断增多的任务。数据回放作为一种有希望的解决方案，通过重新引入先前任务的代表性样本来缓解遗忘问题。然而，现有方法在任务间和缓存中的类别不平衡问题上受到了限制，这影响了其性能。
### Innovation
提出了一种面向类别的平衡数据回放方法（FedCBDR），包括两个关键组件：1）全局视角的数据回放模块以隐私保护的方式重建先前任务的全局表示，指导类别意识和重要性敏感的采样策略以实现平衡的回放；2）任务感知的温度缩放模块基于任务动态适应地调整类和实例层面的logits温度，降低模型对多数类的信心，增强对少数类的敏感性。
### Conclusion
实验证明，FedCBDR方法在异质数据分布中实现了类间平衡采样，同时改善了任务不平衡下的泛化能力，在六种最先进的方法中取得了2%-15%的Top-1准确率提升。
## 702. `cs.CV` - 学习看与做：面向任务的视图规划在机器人操作中的应用 [PDF](https://arxiv.org/pdf/2508.05186), [HTML](https://arxiv.org/abs/2508.05186)
### Authors
Yongjie Bai,Zhouxia Wang,Yang Liu,Weixing Chen,Ziliang Chen,Mingtong Dai,Yongsen Zheng,Lingbo Liu,Guanbin Li,Liang Lin
### Background
近期的视觉-语言-动作（VLA）模型在多任务机器人操作中通常依赖于静态视点和共享视觉编码器，这限制了3D感知能力并导致任务干扰，影响了模型的鲁棒性和泛化能力。
### Innovation
提出了任务感知视图规划（TAVP）框架，该框架通过集成主动视图规划和任务特定的表示学习来克服这些挑战。TAVP采用高效的探索策略，并结合一种新的伪环境来主动获取信息性视图。此外，引入了一种Mixture-of-Experts（MoE）视觉编码器以在不同任务间解耦特征，从而提升表示的准确性及任务泛化能力。通过以任务感知的方式学习观察世界，TAVP能够生成更为完整且具有区分度的视觉表示，显著增强在一系列操作挑战中的动作预测能力。
### Conclusion
在RLBenchmark任务上的广泛实验表明，我们提出的TAVP模型在固定视点方法上的表现优越。视觉结果和代码在此：this https URL.
## 703. `cs.CV` - 在大型视觉语言模型中学习检测未知逃狱攻击 [PDF](https://arxiv.org/pdf/2508.09201), [HTML](https://arxiv.org/abs/2508.09201)
### Authors
Shuang Liang,Zhihao Xu,Jialing Tao,Hui Xue,Xiting Wang
### Background
尽管进行了广泛的努力，大型视觉语言模型（LVLMs）仍然容易受到逃狱攻击的影响，这带来了严重的安全风险。现有的检测方法要么学习特定的攻击参数，这妨碍了对未见攻击的泛化，要么依赖于难以满足的原则，这限制了准确性和效率。
### Innovation
我们提出了Learning to Detect（LoD）框架，这是一个通用的框架，通过从特定攻击学习转向特定任务学习来准确检测未知的逃狱攻击。框架包括一个多模态安全概念激活向量模块（用于安全导向的表征学习）和一个安全模式自动编码器模块（用于无监督的攻击分类）。广泛的实验表明，我们的方法在各种未知攻击上的检测AUC-ROC始终更高，并且提高了效率。
### Conclusion
我们的研究表明，通过学习检测未知逃狱攻击的方法，可以准确地检测出不同类型的未知攻击，同时提高检测效率。
## 704. `cs.CV` - SimCortex：无碰撞的同时皮质表面重建 [PDF](https://arxiv.org/pdf/2507.06955), [HTML](https://arxiv.org/abs/2507.06955)
### Authors
Kaveh Moradkhani,R Jarrett Rushmore,Sylvain Bouix
### Background
准确的皮质表面重建是可靠神经解剖学分析的关键，但当前方法面临复杂皮质几何结构、严格拓扑要求的挑战，通常导致表面重叠、自相交和拓扑缺陷等问题。
### Innovation
引入SimCortex，这是一个深度学习框架，能够同时从T1加权MRI体积中重建左/右白质和皮质表面，并保持拓扑特性。该方法首先将T1w图像分割成九类组织标签图，再生成无碰撞的初始表面网格，供后续多尺度保拓扑变形使用。利用静态速度场（SVFs）集成方法，确保了平滑、拓扑保真的变换，显著减少表面重叠和自相交现象。
### Conclusion
在标准数据集上的评估表明，SimCortex 在大幅度减少表面重叠和自相交现象的同时，达到了最先进的几何准确性，超越了现有方法。
## 705. `cs.CV` - 通过主动学习和选择性半监督微调将医疗视觉基础模型适应于体视医疗图像分割 [PDF](https://arxiv.org/pdf/2509.10784), [HTML](https://arxiv.org/abs/2509.10784)
### Authors
Jin Yang,Daniel S. Marcus,Aristeidis Sotiras
### Background
Med-VFMs由于通过对大量未标注图像进行自我监督预训练而获得了解释医学影像的优越能力。然而，在适应下游评估，特别是分割任务时，仍需有效方法来选择最具信息量的样本进行微调。目前缺乏有效的方法来优化Med-VFMs以提高其在目标领域的适应性能。
### Innovation
提出了一个高效适应Med-VFMs到目标领域的方法——ASFDA（Active Source-Free Domain Adaptation），它结合了新颖的主动学习方法来最大化Med-VFMs的适应性能，并设计了Active Test Time Sample Query策略，通过Diversified Knowledge Divergence和Anatomical Segmentation Difficulty作为查询指标进行样本选择，同时使用Selective Semi-supervised Fine-tuning来提升微调性能和效率。
### Conclusion
该方法通过有效选择样本和利用半监督学习增强了Med-VFMs在目标领域的适应性能和效率，为医疗图像分割提供了新的适应策略。
## 706. `cs.CV` - 使用小型无人飞行器进行神经3D物体重建 [PDF](https://arxiv.org/pdf/2509.12458), [HTML](https://arxiv.org/abs/2509.12458)
### Authors
Àlmos Veres-Vitàlyos,Genis Castillo Gomez-Raya,Filip Lemic,Daniel Johannes Bugelnig,Bernhard Rinner,Sergi Abadal,Xavier Costa-Pérez
### Background
小型无人飞行器（UAVs）具有在室内和难以到达的区域导航的巨大潜力，但其在载荷和自主性方面的显著限制极大地阻碍了它们在如高精度三维重建等复杂任务中的应用。现有的技术无法有效解决这一挑战。
### Innovation
该论文提出了一种新颖的系统架构，能够利用重量低于100克的UAVs实现完全自主、高保真的静态物体三维扫描。核心创新在于引入了一种双重建管道，通过数据采集与飞行控制之间的实时反馈循环，实现了高精度的三维重建。实时过程利用Structure from Motion (SfM) 生成即时点云，非实时过程则利用Neural Radiance Fields (NeRF)-基于神经网络的三维重建（N3DR）方法，结合SfM获取的相机姿态和精确的超宽带（UWB）定位数据，以实现更高的精度重建。
### Conclusion
通过在包括单个和多个UAV配置中进行的实验，该研究表明动态轨迹适应可以持续提高重建质量，比静态飞行路径有显著提升。这表明，较小的UAV可以实现受控环境中的精细3D重建，这是一种以往只有更大平台才能实现的能力。
## 707. `cs.CV` - 剖析马氏距离：特征几何结构与规范化如何影响OOD检测 [PDF](https://arxiv.org/pdf/2510.15202), [HTML](https://arxiv.org/abs/2510.15202)
### Authors
Denis Janiak,Jakub Binkowski,Tomasz Kajdanowicz
### Background
深度学习模型的可靠部署依赖于有效的出分布(OOD)检测。尽管马氏距离方法广泛使用，但它们在不同表示几何和规范化下的性能影响尚未完全理解，这可能限制了它们在下游应用中的使用。针对这一问题，本文通过全面的实验研究了各类图像基础模型、数据集以及距离规范化方式，指出马氏距离方法并非普遍可靠，并定义了理想的特征表示几何，并演示了基于谱和固有维度度量可以准确预测模型的OOD性能。此外，研究了规范化对OOD性能的影响，提出了径向缩放的$ boldsymbol{boldsymbol{2}} $范数规范化方法，这是一种可以提高OOD检测性能的方法。通过结合这些研究，本文对未来更有效、可靠的深度学习模型设计提供了新的见解。
### Innovation
本文定义了理想的特征表示几何，并提出了径向缩放的$ boldsymbol{boldsymbol{2}} $范数规范化方法，通过引入可调参数直接控制特征空间的径向几何，系统地收缩或扩展表示，显著提高了OOD检测性能。此外，通过结合表示几何、规范化与OOD性能的关系，本文为设计更有成效和可靠的深度学习模型提供了新的见解。
### Conclusion
本文通过全面的实验研究，展示了不同基础模型、数据集和规范化方案下的OOD检测表现，提出了径向缩放的$ boldsymbol{boldsymbol{2}} $范数规范化方法，认为通过结合表示几何、规范化和OOD性能的关系，能够更好地设计和应用深度学习模型。
## 708. `cs.LG` - 从噪声到规律：通过去噪动态图的正则化时间序列预测 [PDF](https://arxiv.org/pdf/2510.17817), [HTML](https://arxiv.org/abs/2510.17817)
### Authors
Hongwei Ma,Junbin Gao,Minh-ngoc Tran
### Background
长时多变量时间序列预测面临着诸多挑战，需要现实预测必须(i)去除异质信号噪声，(ii)追踪随时间变化的跨序列依赖关系，(iii)在长时间滚动预测中保持稳定性和物理合理性。
### Innovation
提出了PRISM模型，结合了一个基于评分的扩散预处理器，一个动态和关联阈值的图编码器，以及一个通过通用物理惩罚正则化的预测头。证明了在温和条件下诱导的预测时长动力学的收敛性，并导出了图块的利普希茨界，解释了模型的鲁棒性。
### Conclusion
在六个标准基准上，PRISM实现了持续的SOTA，获得了显著的MSE和MAE改进。
## 709. `cs.CV` - DiffVLA++: 通过度量指导对齐连接认知推理与端到端驾驶 [PDF](https://arxiv.org/pdf/2510.17148), [HTML](https://arxiv.org/abs/2510.17148)
### Authors
Yu Gao,Anqing Jiang,Yiru Wang,Heng Yuwen,Wang Shuo,Sun Hao,Wang Jijun
### Background
传统的端到端（E2E）驾驶模型在生成物理上合理的轨迹方面非常有效，但由于缺乏对周围环境的理解和推理能力，往往难以泛化到长尾场景。相比之下，视图语言动作（VLA）模型利用世界知识处理复杂的案例，但它们在三维推理能力上的局限性可能导致物理不可行的动作。这个问题驱动了DiffVLA++框架的研究，该框架通过度量指导对齐来显式地连接认知推理和E2E规划。
### Innovation
DiffVLA++框架通过构建一个VLA模块直接生成语义上合理的驾驶轨迹，设计一个确保物理可行性的密集轨迹词汇的E2E模块，并引入度量指导轨迹评分器来指导和对齐VLA和E2E模块的输出，从而集成它们的互补优势。该框架显著提升了驾驶模型在复杂场景中的表现，实验结果表明其EPDMS达到49.12。
### Conclusion
该工作通过DiffVLA++框架展示了认知推理与端到端规划结合的优势，提出了一种新的方法来克服传统模型中的局限性，从而在ICCV 2025自动驾驶挑战赛排行榜上取得了显著成绩。
## 710. `cs.CV` - 使用合成数据的课程学习以增强胸腔X光片上肺结节检测 [PDF](https://arxiv.org/pdf/2510.07681), [HTML](https://arxiv.org/abs/2510.07681)
### Authors
Pranav Sambhu,Om Guin,Madhav Sambhu,Jinho Cha
### Background
该研究评估了将课程学习与基于扩散的合成增强相结合是否可以提高检测胸片中难以识别的肺结节的能力，尤其是那些尺寸小、亮度低和对比度低的结节。这类结节由于数据不均衡和有限的注释标签，常常挑战传统的AI模型。研究团队在包含专家标注的NODE21（1,213名患者，占52.4%，平均年龄63.2岁±11.5岁）、VinDr-CXR、CheXpert和11,206张DDPM生成的合成图像的混合数据集上训练了基于特征金字塔网络的Faster R-CNN。难度评分基于结节的大小、亮度和对比度指导课程学习。通过平均精度、 Dice分数和曲线下面积等指标，以及包括置信区间、DeLong测试和配对t检验等统计测试，与非课程模型基线模型进行比较，展示出课程模型在AUC（普及率）上显著优于基线模型（0.95 vs. 0.89，p < 0.001），并在敏感性和准确性上均有提升。并且，分层分析显示模型能力在不同难度范围内一致提高。
### Innovation
研究将课程学习方法与基于扩散的合成增强技术相结合，在胸腔X光片上提高了难以识别的肺结节的检测能力。具体创新点包括：1）通过综合使用不同的数据源（专家标注、人工合成及其混合）进行模型训练；2）结合难度评分进行课程学习，增强模型的鲁棒性和泛化能力；3）通过可视化技术（Grad-CAM）展示了课程学习对注意力机制的改进，使模型更加关注解剖结构相关的特征。
### Conclusion
课程指导的合成增强方法增强了模型在检测肺结节上的鲁棒性和泛化能力，特别是在检测尺寸小、亮度低和对比度低的肺结节时。该研究表明，通过合理的模型训练策略和技术应用，即使是现有检测案例中的挑战性结节也可以得到有效识别，进而提升临床诊断准确性。
## 711. `cs.LG` - MIN-Merging: 融合重要的神经元 [PDF](https://arxiv.org/pdf/2510.17890), [HTML](https://arxiv.org/abs/2510.17890)
### Authors
Yunfei Liang
### Background
近期深度学习的发展极大地推动了跨诸多领域开源模型的涌现。现有模型融合方法能够结合各类模型的优势，但从参数冲突问题导致性能下降。
### Innovation
本文提出了一种基于路由的框架MIN-Merging，通过选择性地合并最重要的神经元来缓解参数冲突问题，从而在保持预训练模型的泛化能力的同时提高了领域内任务的表现。
### Conclusion
广泛的计算机视觉和自然语言处理基准测试表明，MIN-Merging在领域内任务上取得了持续的改进，并且在领域外任务上保留了预训练模型的泛化能力，证明了其作为缓解模型合并中参数冲突问题的有效解决方案的实用性。
## 712. `cs.LG` - GRETEL：一种目标导向的检索和基于执行试验框架以增强LLM工具选择 [PDF](https://arxiv.org/pdf/2510.17843), [HTML](https://arxiv.org/abs/2510.17843)
### Authors
Zongze Wu,Yani Guo,Churong Liang,Runnan Li
### Background
尽管大型语言模型（LLM）取得了显著进步，代理系统中的工具检索仍然受到依赖语义相似性的基本限制，这无法捕捉功能有效性。当前方法经常检索出文本相关但功能无效的工具，由于参数不匹配、认证失败和执行限制等原因，这种情况我们称为语义-功能差距。
### Innovation
引入了GRETEL，通过系统性的实证验证来解决这一差距。GRETEL 实现了一个代理导向的工作流，通过沙盒中的计划-执行-评估循环处理语义检索出的候选工具，生成执行驱动的证据以区分真正功能的工具与仅仅描述匹配的工具。
### Conclusion
我们在ToolBench基准测试中的全面评估显示，GRETEL 在所有指标上都有显著改进：通过率（在10中）从0.690提高到0.826，召回率（在10中）从0.841提高到0.867，NDCG（在10中）从0.807提高到0.857。这些结果表明，基于执行的验证提供了比单一语义相似性更可靠的基础，能够使代理在实际应用中的表现更为稳固。
## 713. `cs.LG` - CARLE：一种用于滚动轴承稳健和可解释的剩余使用寿命估计的混合深度浅层学习框架 [PDF](https://arxiv.org/pdf/2510.17846), [HTML](https://arxiv.org/abs/2510.17846)
### Authors
Waleed Razzaq,Yun-Bo Zhao
### Background
PHM系统监测和预测设备健康状况，核心任务之一是剩余使用寿命（RUL）估计，即预测某个组件如滚动轴承在发生故障前还能运行多久。尽管存在许多RUL方法，但在变工况条件下，其通用性和鲁棒性不足。因此，本研究提出了CARLE，这是一种结合深度和浅层学习的混合人工智能框架，旨在解决上述挑战。
### Innovation
CARLE框架采用了Res-CNN和Res-LSTM模块与多头注意力机制和残差连接，结合时间空间降级模式；另外还加入了残差森林回归器（Random Forest Regressor, RFR）用于进行稳定的、准确的RUL预测。此外，通过高斯滤波和连续小波变换（Continuous Wavelet Transform, CWT）组成的紧凑预处理流水线来减少噪声并提取时间-频率特征。Ablation研究和噪声及跨域实验评估了其稳健性和普适性。
### Conclusion
在XJTU-SY和PRONOSTIA轴承数据集上，CARLE在动态条件下显著优于多种最先进的方法。通过LIME和SHAP分析了模型可解释性，确保了模型的透明性和可信度。
## 714. `cs.LG` - 层次联邦卸载方法在大型语言模型中的应用 [PDF](https://arxiv.org/pdf/2510.17895), [HTML](https://arxiv.org/abs/2510.17895)
### Authors
Yisheng Zhong,Zhengbang Yang,Zhuangdi Zhu
### Background
大型语言模型（LLMs）越来越多地被集成到实际应用中，引发了隐私、安全方面的担忧以及删除不 desirable 知识的需求。机器卸载作为一项有希望的解决方案，面临两大挑战：(1)实际卸载需求往往是连续和异质的；(2)涉及分散、敏感的数据，并且访问不对称。这些因素导致跨域和同域干扰，进一步加剧了遗忘和保留性能的不平衡困境。
### Innovation
提出了一个针对LLMs的可扩展且隐私保护的联邦卸载方法。该方法通过任务特定的适配器学习解耦卸载和保留，并采用分层合并策略来缓解冲突的目标，从而实现稳健且可适应的卸载更新。
### Conclusion
在WMDP、MUSE和TOFU基准测试上的全面实验表明，该方法能够有效处理异质卸载请求，同时保持与基线方法相比强大的LLM实用性。
## 715. `cs.LG` - 稀疏微喷嘴流动中的冲击感知物理引导融合DeepONet算子 [PDF](https://arxiv.org/pdf/2510.17887), [HTML](https://arxiv.org/abs/2510.17887)
### Authors
Ehsan Roohi,Amirmehran Mahdavi
### Background
该研究旨在开发一种物理感知的深度学习框架，用于构建稀疏和包含冲击的微喷嘴流动的快速且准确的代理模型。框架融合了三个关键组成部分：一种融合的DeepONet操作学习架构，用于捕捉参数依赖性；一种物理引导的特征空间，嵌入了冲击对齐的坐标系统；以及一种两阶段的课程策略，强调高梯度区域。这些组成部分的结合旨在利用物理知识和数据学习的结合，以更有效地理解和预测这些复杂的流动现象，特别是冲击波的存在和影响。研究首先在经典牛顿黏性Burgers方程上进行了验证，该方程展示了迁移性陡峭化和类似冲击的梯度。
### Innovation
该论文提出了一个创新的融合DeepONet架构，称为'Shock-Aware Physics-Guided Fusion-DeepONet Operator'，它结合了物理知识和数据驱动的方法来建模稀疏和冲击包含的微喷嘴流动，显著提高了模型的准确性和快速性。
### Conclusion
研究验证了该框架在经典牛顿黏性Burgers方程上的有效性，表明它可以广泛应用于具有复杂物理特性的流动，特别是在包含冲击和稀疏区域的微喷嘴流动建模中显示出优势。未来的工作将继续探索该框架在其他复杂物理现象的应用，进一步提高模型的精度和泛化能力。
## 716. `cs.LG` - Sherpa.ai 盲垂直联邦学习范式以最小化通信次数 [PDF](https://arxiv.org/pdf/2510.17901), [HTML](https://arxiv.org/abs/2510.17901)
### Authors
Alex Acero,Daniel M. Jimenez-Gutierrez,Dario Pighin,Enrique Zuazua,Joaquin Del Rio,Xabi Uribe-Etxebarria
### Background
联邦学习（FL）允许跨多个参与方（节点）协作且不共享原始数据进行分散化训练。FL 包括水平联邦学习（HFL）和垂直联邦学习（VFL）。尽管VFL适用于节点持有相同样本但具有不同特征的场景，但它的一个主要局限是训练过程中需要大量的通信，这会破坏隐私与安全，导致高能耗，并在极端情况下使模型训练不可行。
### Innovation
本文提出了一种新的垂直联邦学习范式——盲垂直联邦学习（SBVFL），它利用分布式训练机制提高隐私和安全性。SBVFL 通过解耦节点的大多数更新与服务器之间的通信，显著减少了节点-服务器间的通信量。
### Conclusion
实验表明，与标准VFL相比，SBVFL将通信量减少了约99%，同时保持了准确性和鲁棒性。因此，SBVFL能够实现在敏感领域（包括医疗、金融、制造、航空航天、网络安全和国防工业）的实用且隐私保护的垂直联邦学习。
## 717. `cs.LG` - 通过扩散时间和频率选择超越均匀遗忘的样本删除 [PDF](https://arxiv.org/pdf/2510.17917), [HTML](https://arxiv.org/abs/2510.17917)
### Authors
Jinseong Park,Mijung Park
### Background
数据删除旨在从训练好的模型中去除特定训练样本的影响，而无需进行全面的重新训练。与概念删除不同，扩散模型中的数据删除仍处于未充分探索的状态，而且常常会导致生成质量下降或遗忘不完全。现有方法大多试图在所有扩散时间步骤中均等地删除样本，导致生成质量较差。
### Innovation
本文观察到现有方法在所有扩散时间步骤中均等地删除样本会导致质量不佳，因此提出了基于时间频率选择的方法，以更关注于模型和场景中不对等的遗忘时间及频率。该方法在多种场景下验证了其对美学质量的提升和降噪效果，并提出了用于评估删除和删除数据样本质量的简单归一化SSCD版本。
### Conclusion
我们的研究和方法为理解扩散模型中的数据删除的独特挑战提供了更清晰的见解，并为提高评估和删除性能提供了实用策略。
## 718. `cs.LG` - L-MoE：一种轻量级低秩适配专家的端到端训练框架 [PDF](https://arxiv.org/pdf/2510.17898), [HTML](https://arxiv.org/abs/2510.17898)
### Authors
Shihao Ji,Zihui Song
### Background
Mixture of Experts (MoE) 架构能够通过为每个输入激活稀疏子集的权重来实现大规模语言模型 (LLMs) 从数十亿参数扩展到万亿参数，同时保持推理期间计算成本的恒定。与此同时，低秩适应 (Low-Rank Adaptation, LoRA) 作为一种参数效率高的方法逐渐成为对 LLMs 进行任务细化调整的主导技术。现有的 MoE 架构主要依赖于密集的前馈网络作为专家，而 LoRA 则将专家定义为针对特定任务的低秩适配器。
### Innovation
该研究将 MoE 和 LoRA 两种模型统一为一个新框架 L-MoE：轻量级 Mixture of Low-Rank Adaptation Experts。L-MoE 将 MoE 专家重新定义为一组针对特定任务的低秩适配器，引入了一个轻量级门控网络来动态组合这些适配器，其权重计算基于每个输入词元进行加权平均。这种方法允许从标准自回归语言建模目标中反向传递梯度，同时优化专家适配器和路由策略，从而创建一个模块化、参数高效且训练端到端的 MoE 模型。
### Conclusion
本文介绍了 L-MoE 的数学框架，详细描述了可微分的路由机制和联合优化目标，为构建更高效的、可扩展的以及更专门化的语言模型开辟了新的途径。
## 719. `cs.LG` - 长上下文注意力基准：从内核效率到分布式上下文并行性 [PDF](https://arxiv.org/pdf/2510.17896), [HTML](https://arxiv.org/abs/2510.17896)
### Authors
Tao Bu,Qiangang Wang,Bowen Zeng,Hanwen Sun,Yunpeng Huang,Chun Cao,Jingwei Xu
### Background
基于Transformer的大语言模型（LLMs）已经取得了显著的成功，但它们的标准注意力机制会在序列长度上造成二次的计算和内存成本，这对长上下文训练构成了主要瓶颈。以前的工作主要是从两个方向解决这一挑战：1. 内核级优化，加快密集和稀疏注意力操作；2. 模块级策略，即分布式注意力或上下文并行训练，这些策略在多个设备上扩展注意力。然而，这些工作的系统评估仍然有限：操作级比较往往不够完整，而上下文并行策略通常依赖特定的框架，其性能分析对于不同上下文的对比并不明确。
### Innovation
本文提出了一种统一基准，该基准结合了代表性的注意力内核和上下文并行机制，并具有模块化和扩展的接口，用于评估。基准从两个关键维度评估方法：1. 注意力掩码模式，它极大地影响效率、扩展性和可用性；2. 序列长度和分布式规模，它们决定了在极端长上下文训练中的性能。
### Conclusion
通过在最多96个GPU的集群上进行全面实验，基准不仅可以进行可复制的比较，还可以突出表现的具体权衡，并提供关于在长上下文大规模训练中设计和部署注意力机制的实际指导。
## 720. `cs.LG` - 自动设计自动调优优化器算法 [PDF](https://arxiv.org/pdf/2510.17899), [HTML](https://arxiv.org/abs/2510.17899)
### Authors
Floris-Jan Willemsen,Niki van Stein,Ben van Werkhoven
### Background
自动性能调优（auto-tuning）对于优化高性能应用至关重要，但由于庞大的不规则参数空间使得手动探索变得不切实际。传统上，auto-tuning依赖于进化算法、调和方法或基于代理模型的优化器来高效地找到近似最优配置。然而，设计有效的优化器仍然具有挑战性，因为没有一种方法能在所有调优任务中表现出色。因此，本文探讨了一个新的范式：使用大型语言模型（LLMs）自动生成针对自动调优问题定制的优化算法。框架通过向LLMs提供问题描述和搜索空间特征，从而生成专门的优化策略，这些策略将被迭代地评估和改进，并在四个人工实际的自动调优应用中，在六个人工硬件平台上进行测试。
### Innovation
提出了一种新的范式，利用大型语言模型（LLMs）自动生成针对自动调优问题定制的优化算法。框架通过向LLMs提供问题描述和搜索空间特征，生成专门的优化策略，这些策略被迭代地评估和改进。实验结果表明，在生成阶段提供额外的应用和搜索空间具体信息，可使算法性能平均提高30.7%，14.6%。此外，研究结果表明LLMs生成的优化器可以与现有的人工设计算法相媲美，在某些情况下甚至优于现有算法，最优秀生成的优化算法相较于最先进的优化算法，平均性能提高了72.4%。
### Conclusion
这项研究证明了，通过向LLMs提供上下文信息，可以根据具体应用和搜索空间生成更有效的自动调优优化算法，这在不同硬件平台上都得到了验证。
## 721. `cs.LG` - NeuCo-Bench: 一种新的地球观测中的神经嵌入基准框架 [PDF](https://arxiv.org/pdf/2510.17914), [HTML](https://arxiv.org/abs/2510.17914)
### Authors
Rikard Vinge,Isabelle Wittmann,Jannik Schneider,Michael Marszalek,Luis Gilch,Thomas Brunschwiler,Conrad M Albrecht
### Background
当前，对于地球观测数据中的压缩和表示学习的评估框架较少，现有的框架可能偏向于某些预训练模型，未能提供广泛适用的、稳定且准确的方法来评估其性能。为了改进这一点，作者引入了一个新的基准框架NeuCo-Bench，专门用于评估地球观测中的神经压缩和表示学习。该框架通过使用固定大小的嵌入来实现紧凑、任务无关的表示，适用于多种下游任务，并发布了相关的地球观测数据集以支持可重复性研究。
### Innovation
NeuCo-Bench 提供了一个全新的基准框架，首次系统地评估了用于地球观测的神经嵌入，并通过以下创新点改进了当前的评价框架：(i) 围绕可重用嵌入构建了一个评估管道；(ii) 引入了带有隐藏任务排行榜的新挑战模式，以缓解预训练偏见；(iii) 设计了一种平衡准确性和稳定性的评分系统。此外，还发布了专门用于地球观测的多光谱、多时相数据集 SSL4EO-S12-downstream 以支持可重复性研究。
### Conclusion
NeuCo-Bench 为神经嵌入的社区驱动的标准评估迈出了第一步，特别是对于地球观测数据及其更广泛的应用场景，提供了一种标准化的方法来评估其性能，还详细介绍了与最新基础模型的消融研究结果，展现了该基准框架的实际应用价值。
## 722. `cs.CV` - Coreset选择对虚假相关性和群体健壯性的影响 [PDF](https://arxiv.org/pdf/2507.11690), [HTML](https://arxiv.org/abs/2507.11690)
### Authors
Amaya Dharmasiri,William Yang,Polina Kirichenko,Lydia Liu,Olga Russakovsky
### Background
核心样本选择方法在减少训练数据量的同时保持模型性能方面展现出了潜力，这对于数据效率型机器学习非常重要。然而，由于许多数据集存在偏向性，数据集中的模型可能会学习虚假相关而非因果特征。因此，理解数据集缩减方法如何可能延续、放大或缓解这些偏见变得至关重要。过去的研究主要集中在如何通过这些方法来减少数据量，但并未详细探讨这一过程对偏见的具体影响，尤其是对后续模型健壯性的影响。本文首次对基于核心样本的选择方法如何影响虚假偏见和下游模型稳健性进行了全面分析。
### Innovation
本文研究了一个新的研究方向，即全面分析核心样本选择对虚假偏见和下游模型稳健性的影响。研究覆盖了十种不同的虚假相关性基准，使用了五个评估样本重要性和难度的评分标准，以及五种不同的数据选择策略。研究发现了一些非平凡的交互特性，并揭示了一些关键的细节。例如，通过嵌入特征来选择核心样本的风险相对较小，而基于学习动态的选择策略则存在更大的风险。更重要的是，研究发现虽然一些核心样本选择方法可以通过优先选择困难样本来减少偏见，但它们并不能可靠地保证下游模型的稳健性。这项研究对数据选择策略的选择有重要的指导意义，为减少数据的同时提高模型稳健性提供了新的视角。
### Conclusion
尽管存在一些选择核心样本策略可以减少偏见水平，但它们并不能可靠的保证下游模型的稳健性。研究揭示了样本难度和偏见对齐之间的复杂交互，以及数据集偏见对结果模型稳健性的影响。基于此研究发现，研究人员需要在选择核心样本的同时考虑模型稳健性，设计出能够有效减少偏见且具有稳健性的核心样本选择方法。这项工作为数据效率型机器学习中的数据选择策略提供了新的见解，并为进一步研究提供了基础。
## 723. `cs.LG` - 基于实例级别的不确定性感知事后校准：超越校准度量的消除自信错误预测 [PDF](https://arxiv.org/pdf/2510.17915), [HTML](https://arxiv.org/abs/2510.17915)
### Authors
Hassan Gharoun,Mohammad Sadegh Khorshidi,Kasra Ranjbarigderi,Fang Chen,Amir H. Gandomi
### Background
尽管对神经网络校准进行了广泛研究，现有方法通常对所有预测应用全局变换，忽略了单个预测的异质可靠性。此外，改善校准与有效不确定性感知决策之间的关系仍鲜有探索。现有校准方法主要关注全局校准，而未充分考虑预测的差异性可靠性以及如何通过校准提升不确定性感知决策的质量。
### Innovation
本文提出了一种后处理校准框架，该框架通过预测可靠性评估联合提升校准质量与不确定性感知决策能力。该框架利用基于近邻的符合性预测，根据特征空间中的语义相似性将校准样本划分为可能正确的和可能不正确的组。然后采用双校准策略：标准的等温回归校准可能正确的预测置信度，而欠信心度正则化等温回归减少可能不正确预测的置信度，使其朝统一分布靠拢，便于进一步调查。该方法通过校准指标、不确定性感知性能指标和经验符合覆盖度进行了全面评估，研究表明与等温回归和焦点损失基线相比，所提方法实现了较低的自信错误预测率和具有竞争力的预期校准误差。该工作通过实例级别适应性将校准与不确定性量化相结合，提供了一种无需模型重训即可有效提升概率对齐和不确定性感知决策的实用后处理解决方案。
### Conclusion
本文提出了一种基于实例级别的后处理校准方法，通过预测可靠性评估和双校准策略，既提升了校准质量，又改善了不确定性感知决策能力。实验结果表明，该方法在CIFAR-10和CIFAR-100数据集上，特别是在BiT和CoAtNet模型中，表现出优越的性能，有效减少了自信错误预测的数量，并获得具有竞争力的预期校准误差。
## 724. `cs.LG` - EvoSyn: Generalizable Evolutionary Data Synthesis for Verifiable Learning [PDF](https://arxiv.org/pdf/2510.17928), [HTML](https://arxiv.org/abs/2510.17928)
### Authors
He Du,Bowen Li,Aijun Yang,Siyang He,Qipeng Guo,Dacheng Tao
### Background
可靠的验证数据已成为现代语言模型能力提升的关键驱动力，能够稳定实现带验证奖励的强化学习和有效的知识蒸馏，将技能跨数学、编程和自主任务转移。然而，由于生成模型易产生幻觉以及验证标记不够充分或简单，难以构建跨领域的一般性的合成验证数据。现有的方法大多依赖于特定任务的启发式规则或事后过滤筛选，缺乏通用的验证性评估器和在不同领域间有效迁移的能力。
### Innovation
本文提出了一种进化、任务无关、策略引导、可执行验证的数据合成框架。从少量种子监督开始，该框架可以联合生成问题、多种候选解决方案和验证标记，通过一致性评估器迭代发现策略，该评估器强制人类标注和策略诱导的验证结果一致。这一流水线将过滤转变为基于原则的合成：可以可靠地构建一致、可验证的训练实例，在没有领域特定规则的情况下实现泛化。
### Conclusion
实验结果在RLVR和模型蒸馏训练范式下证明了所提出方法的有效性。结果显示，使用合成数据进行训练可以在LiveCodeBench和AgentBench-OS任务中显著提高模型表现，证明了该框架的鲁棒性泛化能力。
## 725. `cs.LG` - 从观测到参数：基于模拟推断检测非线性动力学中的突变点 [PDF](https://arxiv.org/pdf/2510.17933), [HTML](https://arxiv.org/abs/2510.17933)
### Authors
Xiangbo Deng,Cheng Chen,Peng Yang
### Background
检测混沌时间序列中的分岔转换具有挑战性，因为观测信号与内在变异性交织在一起。这篇论文探讨了在参数空间中检测分岔转换的方法。
### Innovation
提出了参数空间突变点检测（Param--CPD），这是一种两阶段框架。首先，通过由基于模拟的推断训练的神经后验估计器优化参数的贝叶斯推断；然后，应用标准的CPD算法分析结果参数轨迹。该方法在洛伦兹63模型中表现出了更高的F1分数、更低的定位误差，且假阳性减少。
### Conclusion
研究表明，在参数空间中操作能够实现非线性动力系统中准确且可解释的突变点检测。进一步的鲁棒性分析表明，方法在容忍度、窗口长度和噪声方面的表现稳健，整体上表现出一致的改进。
## 726. `cs.LG` - 不只奖励终点：一种适用于测试时强化学习的复合路径与答案自评分奖励机制 [PDF](https://arxiv.org/pdf/2510.17923), [HTML](https://arxiv.org/abs/2510.17923)
### Authors
Chenwei Tang,Jingyu Xing,Xinyu Liu,Wei Ju,Jiancheng Lv,Deng Xiong,Ziyue Qiao
### Background
强化学习（RL）已成为大规模语言模型（LLMs）的进步的强大范式，在数学和代码生成等复杂推理领域取得了显著性能。然而，当前的RL方法在处理大规模数据集时面临根本性的可扩展瓶颈，主要原因是它们过度依赖于人工标注的数据或标签数据集来建模奖励。为了克服这一限制，我们探讨了在未标注数据上使用RL的方法，使模型能够从连续的经验流中自主学习。核心挑战在于在没有真实监督的情况下实现可靠的奖励估计。
### Innovation
我们提出了COMPASS（复合路径和答案自评分），一种全新的测试时奖励机制，无需外部监督。COMPASS结合了双重校准答案奖励（DCAR）和决策路径奖励（DPR）两个互补组件：DCAR通过信心和可信度校准来建立可靠的伪标签，稳定训练；DPR直接优化推理过程质量，而不仅仅是结果监督。通过共同强化可信的共识答案和高确定性的推理链，COMPASS系统地增强了模型的分析能力。
### Conclusion
在多种多样的推理任务和模型架构上进行了广泛的实验，表明COMPASS在不同领域取得了显著且一致的性能提升，推动了LLMs从连续经验学习的更具可扩展性的方向前进。
## 727. `cs.LG` - 神经时间序列预测模型在神经活动中的基准测试 [PDF](https://arxiv.org/pdf/2510.18037), [HTML](https://arxiv.org/abs/2510.18037)
### Authors
Ziyu Lu,Anna J. Li,Alexander E. Ladd,Pascha Matveev,Aditya Deole,Eric Shea-Brown,J. Nathan Kutz,Nicholas A. Steinmetz
### Background
神经活动预测对于理解神经系统和实现闭环控制至关重要。尽管深度学习在时间序列预测领域的最新进展显著，但在神经活动预测中的应用仍有限。已有研究中，系统的评估了八个概率深度学习模型在自发性小鼠皮层神经活动中的表现，与经典统计模型和基准方法进行对比。
### Innovation
系统性评估了八个概率深度学习模型，包括两种基础模型，这些模型在一般的预测基准测试中表现出色。该研究比较了这些模型与四种经典统计模型和两种基准方法在自发性神经活动预测中的表现，特别是在不同预测时间范围内的表现。
### Conclusion
多个深度学习模型在预测方面持续优于经典方法，最佳模型能够预测未来1.5秒内的神经活动，这为未来控制应用提供了方向，并开启了探索神经活动内在时间结构的新途径。
## 728. `cs.LG` - UniRL-Zero: 统一模型上的强化学习与联合语言模型和扩散模型专家 [PDF](https://arxiv.org/pdf/2510.17937), [HTML](https://arxiv.org/abs/2510.17937)
### Authors
Fu-Yun Wang,Han Zhang,Michael Gharbi,Hongsheng Li,Taesung Park
### Background
该研究背景在于通过结合多模态语言理解和推理、扩散模型多媒体生成及其正面互动的能力，构建一个统一的强化学习（RL）框架，以提升模型的综合性能。
### Innovation
本文提出的UniRL-Zero框架具有以下创新点：1) 统一了多模态语言模型理解和推理以及扩散模型多媒体生成的能力；2) 引入了六种统一模型强化学习的场景，为统一理解和生成模型的强化学习提供了系统化的基准；3) 通过将语言模型和扩散模型结合起来，实现其有益的互动效果。
### Conclusion
作者通过UniRL-Zero框架定义了六种统一模型强化学习的场景，并提供了系统化的基线方法，该框架提升了多模态语言模型的理解和推理能力以及扩散模型的多媒体生成能力，还展示了它们之间的有益互动。相关代码已发布。
## 729. `cs.LG` - 揭开过渡匹配之谜：何时及为何它能胜过流匹配 [PDF](https://arxiv.org/pdf/2510.17991), [HTML](https://arxiv.org/abs/2510.17991)
### Authors
Jaihoon Kim,Rajarshi Saha,Minhyuk Sung,Youngsuk Park
### Background
流匹配（FM）是许多当前最先进生成模型的基础，然而近期的研究结果表明，在某些情况下，过渡匹配（TM）可以使用更少的采样步骤获得更高的质量。本文探讨了在什么情况下以及为什么TM在性能上可能优于FM.
### Innovation
研究证明，在单一高斯分布目标下，TM 在有限步数中严格低于 FM 的 KL 散度，这是因为 TM 的随机差异隐状态更新保留了目标协方差，而 FM 过于低估了这种协方差。在单一高斯分布的设置中，TM 达到了更快的收敛速度。研究还扩展到混合高斯，并确定了局部单一模式区域，在这些区域中，TM 的采样动力学可以近似为单一模式的情况，使得 TM 可以在这些情况下优于 FM。此外，当目标方差减小时，TM 的每次更新都会收敛到 FM 的更新，TM 的性能优势会逐渐消失。总之，研究显示当目标分布的模式被良好分离并且方差不是可以忽略时，TM 优于 FM 的优势明显.
### Conclusion
研究验证了在高斯分布上的受控实验，还扩展到现实世界的图像和视频生成应用，进一步证明了 TM 在这些领域的优势。
## 730. `cs.LG` - 度量论的反因果表示学习 [PDF](https://arxiv.org/pdf/2510.18052), [HTML](https://arxiv.org/abs/2510.18052)
### Authors
Arman Behnam,Binghui Wang
### Background
在反因果设置下（标签导致特征而非相反），因果表示学习面临着独特挑战，现有方法难以有效应对。ACIA框架提供了一种基于度量论的新颖方法来解决反因果表示学习的问题。
### Innovation
ACIA框架采用两层设计，低层表示捕捉标签生成观测的方式，高层表示学习特定环境中的稳定因果模式。ACIA方法通过干预内核适应完美和不完美干预，不依赖显式因果结构，有效处理高维度数据，并提供分外分布泛化的理论保障。实验结果表明ACIA在准确性和不变性指标上优于现有方法。
### Conclusion
ACIA框架通过严格的理论结果建立了训练环境与未见过环境性能差距的紧密边界，证实了其在鲁棒反因果学习中的有效性。
## 731. `cs.LG` - 跨域长期预测：基于时空操作网络的稀疏中子传感器辐射剂量预测 [PDF](https://arxiv.org/pdf/2510.18041), [HTML](https://arxiv.org/abs/2510.18041)
### Authors
Jay Phil Yoo,Kazuma Kobayashi,Souvik Chakraborty,Syed Bahauddin Alam
### Background
对不可观测物理量进行预测是科学机器学习中的核心未解问题，现有的神经运算和大规模预测器依赖于密集且同域输入输出的场合，而在实际系统中，传感和预测发生在不同的物理空间并且跨越长时间尺度，这使得现有方法不再适用。
### Innovation
提出了一种时空操作网络（STONe），这是一种非自回归神经运算器，能够学习不同异质域之间的稳定函数映射。它能够直接从稀疏的地面中子测量中推断出高空辐射剂量场，证明了运算学习可以在不共享域的设置中进行泛化。STONe 在没有迭代回归的情况下，定义了传感器域和目标域之间的非线性运算，使其在长时间预测区间内保持稳定。这挑战了传统认为运算学习需要领域对齐或自回归传播的观点。该模型在23年的全球中子数据上训练，实现了180天的准确预测，且具有毫秒级的推理延迟。
### Conclusion
框架为跨域运算推断提供了一般原则，可以实时预测物理、气候和能源系统中的复杂时空场。
## 732. `cs.LG` - 注意力引导的深度对抗时间子空间聚类 (A-DATSC) 模型用于多变量时空数据 [PDF](https://arxiv.org/pdf/2510.18004), [HTML](https://arxiv.org/abs/2510.18004)
### Authors
Francis Ndikum Nji,Vandana Janeja,Jianwu Wang
### Background
深度子空间聚类模型在诸如雪融检测、海冰追踪、农作物健康监测、传染病建模、网络负载预测和土地利用规划等领域中至关重要。这些应用场景中的多变量时空数据具有复杂的时序依赖关系，并且通常存在于传统的聚类方法无法处理的多个非线性流形上。现有的方法在使用浅层自编码器时忽略聚类误差，过度强调全局特征而忽视局部结构，无法建模长程依赖和位置信息，且很少应用于四维时空数据。这限制了它们在实际应用中的表现和适用性。
### Innovation
本文提出了一种名为 A-DATSC（注意力引导的深度对抗时间子空间聚类）的新模型。A-DATSC 结合了深度子空间聚类生成器和用于质量验证的判别器。生成器受到 U-Net 的启发，通过堆叠 TimeDistributed ConvLSTM2D 层来保留时空完整性，减少参数并增强泛化能力。自表达网络基于图注意力变换器捕捉局部空间关系、全局依赖关系和短程及长程相关性。实验结果表明，A-DATSC 在三个实际的多变量时空数据集上实现了比最先进的深度子空间聚类模型更好的聚类性能。
### Conclusion
A-DATSC 在时空数据中具有显著的聚类性能，特别适用于多变量场景，并能显著改善模型的整体表现，尤其是对于四维时空数据的应用。
## 733. `cs.LG` - 利用中间反馈细调流匹配生成模型 [PDF](https://arxiv.org/pdf/2510.18072), [HTML](https://arxiv.org/abs/2510.18072)
### Authors
Jiajun Fan,Chaoran Cheng,Shuaike Shen,Xiangxin Zhou,Ge Liu
### Background
流生成模型在文本到图像生成方面表现出显著的成功，但在使用中间反馈进行细调的过程中仍然存在挑战，特别是在连续时间流匹配模型中。现有方法大多仅从结果奖励中学习，难以解决功劳分配问题。替代的方法试图通过直接回归累积奖励来学习一个评论者，但在在线设置中经常面临训练不稳定性以及模型坍塌的问题。
### Innovation
我们提出了一种稳健的演员-评论者框架AC-Flow，通过以下三个重要创新点来解决这些挑战：（1）奖励塑形，为稳定中间价值学习和梯度控制提供良好归一化的学习信号；（2）一种新颖的双稳定性机制，结合优势剪裁以防止破坏性的策略更新，并包含一个暖身阶段，使评论者成熟后再影响演员；（3）一种可扩展的广泛评论者权重方案，扩展了传统的奖励加权方法，同时通过Wasserstein正则化保持模型多样性。
### Conclusion
通过在Stable Diffusion 3上进行广泛的实验，我们表明AC-Flow在文本到图像对齐任务中达到了最先进的性能，并且能够将生成的质量、多样性和稳定性不受影响地应用于未见过的人类偏好模型中。
## 734. `cs.LG` - SPACeR: 中心参考模型引导的自我博弈 [PDF](https://arxiv.org/pdf/2510.18060), [HTML](https://arxiv.org/abs/2510.18060)
### Authors
Wei-Jer Chang,Akshay Rangesh,Kevin Joseph,Matthew Strong,Masayoshi Tomizuka,Yihan Hu,Wei Zhan
### Background
开发自主车辆（AVs）不仅需要安全和效率，还需要能够预测和体现社会意识的人类般的真实行为。这需要多智能体场景中具有人类般、快速且可扩展性的仿真人行智能策略。尽管最近在大规模扩散或标记模型的模仿学习方面取得了进展，能够直接从人类驾驶数据中捕捉行为，从而生成真实策略，但这些模型在推理过程中计算昂贵，速度较慢，并且在反应性闭合环场景中难以适应。相比之下，自我博弈强化学习可以高效扩展，并自然捕捉多智能体交互，但是通常需要启发式方法和奖励塑造，结果策略与人类行为规范偏差较大。本文提出了SPACeR框架，利用预训练的标记化自回归运动模型作为集中参考策略来引导分散的自我博弈。参考模型提供似然奖励和KL散度，使策略与人类驾驶分布保持一致的同时保留强化学习的扩展性。
### Innovation
SPACeR框架利用预训练的标记化自回归运动模型作为集中参考策略来引导分散的自我博弈，提供似然奖励和KL散度，确保策略保持与人类驾驶行为一致的同时保留了强化学习的扩展性。
### Conclusion
在Waymo Sim Agents挑战中，我们的方法在推理速度上比大型生成模型快10倍，在参数规模上比大型生成模型小50倍，同时实现了与模仿学习策略相当的性能。此外，我们的模拟代理在闭合环自驾车规划评估任务中能够有效地评估规划质量，为测试自主驾驶策略建立了一个新范式。
## 735. `cs.LG` - MEG-GPT: 一种基于转换器的基础模型用于磁电图数据 [PDF](https://arxiv.org/pdf/2510.18080), [HTML](https://arxiv.org/abs/2510.18080)
### Authors
Rukuang Huang,Sungjun Cho,Chetan Gohil,Oiwi Parker Jones,Mark Woolrich
### Background
对大脑动态的大规模空间-时间模式进行建模对于神经科学至关重要，但传统方法无法捕捉到模态，例如磁脑成像（MEG）中的丰富结构。近年来，深度学习在语言和视觉等其他领域取得了显著进展，通过利用大规模的基础模型。然而，对于MEG数据，仍缺乏有效的建模方法来捕捉其复杂性。
### Innovation
本文介绍了一种基于转换器的基础模型——MEG-GPT，它使用了时间注意力机制和下一个时间点预测技术。同时，还引入了一种用于连续MEG数据的新颖的数据驱动分词器，能够保留MEG信号的高时间分辨率，而无需进行损耗性转换。此外，该模型在跨被试解码场景中可以通过小规模标注数据进行有效微调，从而提高性能。该研究通过大规模MEG数据集证实了MEG-GPT模型在生成具有真实空间-谱属性的数据和下游解码任务中的优越性能，特别是在零样本迁移学习方面，表现优于基准方法。
### Conclusion
本研究为神经生理学数据提供了强大的基础模型，为计算神经科学和神经解码的应用铺平了道路。
## 736. `cs.LG` - R2L: 可靠的强化学习：保证回报与可靠的策略在强化学习中的实现 [PDF](https://arxiv.org/pdf/2510.18074), [HTML](https://arxiv.org/abs/2510.18074)
### Authors
Nadir Farhi
### Background
在强化学习（RL）中，传统算法旨在最大化期望回报。然而，许多实际应用场景如路由、资源分配、风险下的 sequential 决策等，不仅要求高平均绩效，还要求保证特定成功率的概率。为此，本文提出了一种新的优化目标，旨在通过最大化累计回报超过预设阈值的概率，来确定可靠的策略。这种方法可以转化为标准的RL问题，使得现有的RL和深度RL算法可以直接应用，无需全新算法框架。理论结果验证了两种形式的等价性，并展示了通过调整Q学习或 Dueling Double DQN 等方法可以得到可靠策略。以可靠路由为例，强调了减少期望行程时间并不是目标，而是最大化在给定时间预算内达到目的地的概率。实验证实，所提出的方法在效率和可靠性之间取得了良好平衡，表明可靠RL在随机性和安全关键环境中具有潜在应用价值。
### Innovation
提出了一种新的优化目标，通过最大化累计回报超过预设阈值的概率来确定可靠的策略。将该可靠RL问题转化为标准的RL问题，利用现有的RL和深度RL算法，无需全新算法框架。展示了通过调整Q学习或 Dueling Double DQN 等方法可以得到可靠策略。
### Conclusion
所提出的方法在效率和可靠性之间取得了良好平衡，使得RL在随机性和安全关键环境中能够更好地应用于实际应用场景。
## 737. `cs.LG` - 用于开发机器学习异常检测方法的批次蒸馏数据 [PDF](https://arxiv.org/pdf/2510.18075), [HTML](https://arxiv.org/abs/2510.18075)
### Authors
Justus Arweiler,Indra Jungjohann,Aparna Muraleedharan,Heike Leitte,Jakob Burger,Kerstin Münnemann,Fabian Jirasek,Hans Hasse
### Background
机器学习（ML）在化学工艺中的异常检测（AD）方面具有巨大的潜力。然而，ML方法的发展受到缺乏公开实验数据的限制。为解决这一问题，我们搭建了一个小型批次蒸馏装置，并进行操作以产生涵盖无故障实验和故意引入异常的广泛实验数据库，用于训练先进的ML基于AD的方法。数据库包括来自多个传感器和执行器的时间序列数据以及测量不确定性估计。此外，还提供了诸如通过在线台式NMR光谱获得的浓度分布和视频音频记录等非传统数据源。所有实验包含详细的元数据和专家注释。异常注释基于在此工作中开发的本体论。数据被组织成一个结构化的数据库并免费提供。这一新数据库为开发先进的ML基于AD方法铺平了道路。此外，由于包括异常原因的信息，它还促进了可解释和可解释的ML方法以及异常缓解方法的发展。
### Innovation
通过搭建小型批次蒸馏装置并进行广泛实验以生成涵盖真实和异常情况的实验数据库，填补了ML方法开发中的数据空白。此数据集包含非传统数据源如NMR浓度分布和视频音频记录，以及详细的元数据和专家注释。注释基于开发的工作本体论，并且数据被组织成结构化的数据库，可自由访问。此方法不仅促进了先进ML基于AD方法的开发，还为进一步开发可解释和可解释的ML方法以及异常缓解方法铺平了道路。
### Conclusion
此新数据库促进了先进的ML基于AD方法的开发，并为开发可解释和可解释的ML方法以及异常缓解方法铺平了道路，同时提供了导致异常的原因信息。
## 738. `cs.LG` - 通过MIMIC-IV结构化临床数据的元模型增强心脏骤停ICU患者死亡率预测 [PDF](https://arxiv.org/pdf/2510.18103), [HTML](https://arxiv.org/abs/2510.18103)
### Authors
Nursultan Mamatov,Philipp Kellmeyer
### Background
在重症监护病房(ICUs)中准确预测住院期间死亡率对于及时的临床干预和资源的有效分配至关重要。为了实现这一目标，本研究开发和评估了一种结合结构化临床数据和未结构化文本信息（特别用于出院摘要和影像学报告）的机器学习模型。这使用了LASSO和XGBoost进行特征选择，随后使用根据两种模型识别的顶级特征训练多元逻辑回归模型。
### Innovation
研究中引入了使用TF-IDF和BERT嵌入法整合文本特征的方法，显著提高了预测性能。最终结合结构化和文本输入的逻辑回归模型相较于仅使用结构化数据的模型（AUC为0.753）提高了22%，并且在广泛的临界概率范围内（0.2-0.8）表现出更优越的标准净效益，证实了模型在临床应用中的实用性。
### Conclusion
结果强调了未结构化临床笔记的预后价值，并支持将其纳入可解释特征驱动的风险预测模型中用于ICU患者。
## 739. `cs.LG` - Latent Discrete Diffusion Models [PDF](https://arxiv.org/pdf/2510.18114), [HTML](https://arxiv.org/abs/2510.18114)
### Authors
Dario Shariatian,Alain Durmus,Stefano Peluchetti
### Background
本文研究了语言和其他分类数据中的离散扩散，并关注遮蔽去噪器的一个普遍局限性：逆向转换通常在位置之间分解，这可能会削弱联合结构并降低多步骤生成的质量。
### Innovation
提出了潜离散扩散模型(Latent Discrete Diffusion Models, LDDMs)，该模型通过掩码离散扩散对标记进行编码，并耦合连续扩散对潜在嵌入进行建模。LDDMs 包含两种实例化：完全联合去除标记和潜在变量的 FUJI-LDDMs，以及首先解决潜在部分，然后根据其解决离散链的 SEQ-LDDMs。研究人员为两种变体推导了类似于 ELBO 的目标，并讨论了设计选择以学习具有扩散建模可操作性的信息丰富的潜在变量。
### Conclusion
实验表明，LDDMs 在无条件生成指标上优于最先进的遮蔽离散扩散基线，并且在较低的采样预算中效果非常好，这使得每步解掩蔽许多标记成为可能。
## 740. `cs.LG` - 自适应偏差正则化策略优化算法用于生成模型微调 [PDF](https://arxiv.org/pdf/2510.18053), [HTML](https://arxiv.org/abs/2510.18053)
### Authors
Jiajun Fan,Tong Wei,Chaoran Cheng,Yuxin Chen,Ge Liu
### Background
在使用强化学习对生成模型进行微调时，如何平衡探索和利用是一项关键挑战。现有方法依靠固定偏差正则化，但这种方法存在固有的矛盾：较强的正则化有助于保持模型能力，但却限制了奖励优化；较弱的正则化可以更好地对齐，但增加了不稳定或奖励作弊的风险。
### Innovation
作者引入了自适应偏差正则化策略优化（ADRPO）算法，该算法能够根据优势估计自适应调整正则化强度，对于高价值样本减少正则化，对于低价值样本则加强正则化，从而使策略能够根据数据质量在探索和积极利用之间导航。实验结果表明，通过使用Wasserstein-2正则化进行流动匹配生成模型的微调，该方法在文本到图像生成中取得了优异的结果，与离线方法DPO和采用固定正则化的在线方法相比，取得了更好的语义对齐和多样性。此外，该方法也被证明适用于文本仅限的大规模语言模型和多模态推理模型的微调，从而增强了现有的在线强化学习方法。
### Conclusion
ADRPO使一个参数量为2亿的SD3模型在属性关联、语义一致性、艺术风格迁移和组合控制方面的性能超过了更大参数量（4.8亿和12亿）的模型，同时保持生成多样性。通过主动探索，该方法在语言模型微调中展示了逃离局部最优的能力；在多模态音频推理中，它通过更优的逐步推理超过了GRPO，使得一个7亿参数模型超过了大型商用模型，提供了在多种生成架构和模态中解决探索-利用挑战的有效方案。
## 741. `cs.LG` - 在安全过滤下的可验证最优强化学习 [PDF](https://arxiv.org/pdf/2510.18082), [HTML](https://arxiv.org/abs/2510.18082)
### Authors
Donggeon David Oh,Duy P. Nguyen,Haimin Hu,Jaime F. Fisac
### Background
近年来，强化学习（RL）的技术进步使其能够处理更复杂的任务，但在涉及安全的关键应用中，其性能和安全保证往往存在矛盾。常用于解决此类问题的方法是为RL策略添加一个安全过滤器，以防止潜在的危害。尽管如此，安全过滤器通常被认为会影响性能并阻碍学习过程。该论文探讨了这一问题，表明实际可行且安全学习并不必然牺牲性能，并首次证明，通过足够宽松的安全过滤器实施安全策略不会影响渐进性能。论文引入了一种新的安全关键马尔可夫决策过程（SC-MDP）概念，以及相关的过滤马尔可夫决策过程（Filtered MDP），强调性能优化和安全约束可以独立实现，确保策略在实际部署中保持最优性能，同时完全遵守预定义的安全标准。
### Innovation
论文首次证明，使用足够宽松的安全过滤器进行强化学习的训练和部署不仅能保证安全，还能保持最优性能。这种方法通过引入安全关键马尔科夫决策过程（SC-MDP）和过滤马尔科夫决策过程（Filtered MDP）的概念，为安全过滤下的强化学习提供了一种新的理论框架，从而解决了之前被认为的性能和安全之间的权衡问题。这为实践中安全强化学习策略的设计提供了新的方法论指导
### Conclusion
研究表明，通过最宽松的安全过滤器进行训练和部署的强化学习策略，能够在保证安全的同时保持最优性能。“Provably Optimal Reinforcement Learning under Safety Filtering”的理论已经在Safety Gymnasium上得到了验证，表明这种方法适用于各种代表性任务，并达到了最优性能。总体来看，这项研究为安全强化学习领域提供了一个简单且可靠的解决方案。
## 742. `cs.LG` - Any-Depth Alignment: 解锁 LLMs 的任意深度内置安全性对齐 [PDF](https://arxiv.org/pdf/2510.18081), [HTML](https://arxiv.org/abs/2510.18081)
### Authors
Jiawei Zhang,Andrew Estornell,David D. Baek,Bo Li,Xiaojun Xu
### Background
大语言模型（LLMs）表现出较强的但表浅的对齐：它们会直接拒绝有害查询，只要这种拒绝是在助手回合的开始时预期的。然而，一旦有害内容开始出现（通过对手攻击或有害助手前缀填充攻击），这种保护就会失效。这引发了根本性的问题：LLMs 的内置浅表对齐能否被解锁，以确保在任意生成深度的安全性？
### Innovation
针对这一目标，本文提出了 Any-Depth Alignment (ADA)，这是一种在推理时具有微小开销的有效防御措施。ADA 的构建基于观察：在浅表拒绝训练中，对齐集中在助手头令牌上，并且这些令牌包含模型的强对齐先验。通过在生成过程中的中途引入这些令牌，ADA 促使模型重新评估有害性并在生成中的任意点恢复拒绝。在多种开源模型家族中，ADA 无需对基模型参数进行任何更改，就能实现稳健的安全性能。它几乎能够 100% 拒绝挑战性的对手前缀攻击，这些攻击的长度从几十到几千个令牌不等。此外，ADA 还将知名对手提示攻击（如 GCG、AutoDAN、PAIR 和 TAP）的成功率降低到 3% 以下，同时在良性任务中保持最小的过度拒绝，即使在基模型经过后续指令调整（良性或恶意）后，ADA 仍能保持这种韧性。
### Conclusion
通过 ADA，本文展示了如何在任意深度确保 LLMs 的安全性。任何深度对齐提升了 LLMs 在任何生成阶段的安全性，特别是在面对复杂的对手攻击时，同时对良性任务的实用性影响最小。
## 743. `cs.LG` - 梯度方差揭示流基生成模型的失败模式 [PDF](https://arxiv.org/pdf/2510.18118), [HTML](https://arxiv.org/abs/2510.18118)
### Authors
Teodora Reu,Sixtine Dromigny,Michael Bronstein,Francisco Vargas
### Background
这篇论文探讨了在基于流的生成模型（Flow-based generative models）中直路径目标的潜在问题。直路径目标使模型在生成数据时的路径更加直接，但是这会引发一些基础性的问题，尤其是在确定性训练下的梯度方差。直路径可能会导致模型记忆训练中的特定配对，即使这些配对之间的插值线会相交。
### Innovation
作者通过研究从高斯分布到高斯分布的运输（Gaussian-to-Gaussian transport）情况，并使用梯度方差来衡量在随机和确定性情况下优化的偏爱。他们证明了即使插值线相交，应用修正的流动也会在推理过程中产生训练中的特定配对。另外，作者证明了即使训练插值线相交，也会存在一个记忆化向量场，并且优化直路径目标会导致这个未定义的场的收敛。
### Conclusion
在推理过程中的确定性积分会再现训练中的精确配对。作者通过在CelebA数据集上的实验证明，确定性的插值会导致记忆化，而注入少量噪声会恢复泛化能力。
## 744. `cs.LG` - 通过核心注意分离实现高效长上下文语言模型训练 [PDF](https://arxiv.org/pdf/2510.18121), [HTML](https://arxiv.org/abs/2510.18121)
### Authors
Yonghao Zhuang,Junda Chen,Bo Pang,Yi Gu,Yibo Zhu,Yimin Jiang,Ion Stoica,Eric Xing,Hao Zhang
### Background
在现有系统中，核心注意力机制与其他层一同部署，但在长上下文长度下，核心注意力计算的平方增长速度比其他组件的近线性增长速度快，导致数据和管道并行组中的负载不平衡和慢速节点问题。
### Innovation
提出了核心注意力分解（CAD）技术，将核心注意力计算从模型的其余部分分离出来并单独在一个设备池中执行。CAD通过将核心注意力任务分割成按令牌级任务派发到专用注意力服务器，并动态重新分批任务以均衡计算，同时保持内核效率，从而解决了负载不平衡问题。
### Conclusion
DistCA系统在512个H200 GPU和最长512K令牌的上下文中采用乒乓执行模式完全重叠通信与计算，依赖在注意力服务器上进行原地执行以减少内存使用，提高了端到端训练吞吐量，消除了数据和管道并行慢速节点，实现了接近完美的计算和内存平衡。
## 745. `cs.LG` - 通过投影梯度对齐扰动的零阶优化实现快速大规模语言模型微调 [PDF](https://arxiv.org/pdf/2510.18228), [HTML](https://arxiv.org/abs/2510.18228)
### Authors
Zhendong Mi,Qitao Tan,Grace Li Zhang,Zhaozhuo Xu,Geng Yuan,Shaoyi Huang
### Background
使用零阶（ZO）优化微调大型语言模型（LLMs）作为一种替代传统梯度基方法的可能性，由于它减少了内存占用。现有的ZO方法在梯度估计的方差上存在问题，导致收敛速度慢且在大规模模型上的表现不佳。
### Innovation
提出了一种名为P-GAP的方法，即通过投影梯度对齐扰动的零阶优化快速微调LLM。具体而言，它首先估计低维度的梯度空间，然后在该空间内调整梯度方向上的扰动。这种方法减少了需扰动参数的数量，降低了方差，从而加速了LLM微调的收敛速度。实验表明，P-GAP在分类任务和生成任务中，准确率分别提高了6%和12%，训练迭代次数减少了约81%，GPU小时减少了约70%。
### Conclusion
P-GAP使得零阶优化的LLM微调能够快速、可扩展且资源高效。
## 746. `cs.LG` - ActivationReasoning: 在潜空间中进行逻辑推理 [PDF](https://arxiv.org/pdf/2510.18184), [HTML](https://arxiv.org/abs/2510.18184)
### Authors
Lukas Helff,Ruben Härle,Wolfgang Stammer,Felix Friedrich,Manuel Brack,Antonia Wüst,Hikaru Shindo,Patrick Schramowski,Kristian Kersting
### Background
大型语言模型在生成流畅文本方面表现出色，但它们的内部推理过程仍然不透明且难以控制。稀疏自编码器通过暴露与人类概念对齐的潜在特征使隐藏激活具有可解释性，但这些特征是脆弱且被动的，没有机制来进行系统推理或模型控制。
### Innovation
提出了ActivationReasoning（AR）框架，该框架将显式的逻辑推理嵌入到LLMs的潜空间中。AR方法包括三个阶段：（1）找到潜表示，通过识别和组织潜在概念表示（如利用稀疏自编码器）；（2）激活命题，推理时检测激活概念并将其映射到逻辑命题；（3）逻辑推理，通过应用逻辑规则推断高级结构、组合新概念并引导模型行为。AR在多个任务上进行了评估，包括多跳推理、抽象和间接概念线索的鲁棒性、自然和多样语言的推理以及上下文感知的安全性。这些结果表明，将逻辑结构嵌入到潜空间中不仅能提高透明度，还能实现结构推理、可靠的控制以及与期望行为的对齐，从而提供了一条更可靠和可审计的AI之路。
### Conclusion
结果表明，将逻辑结构嵌入潜空间中不仅能提高透明度，还能实现结构推理、可靠的控制以及与期望行为的对齐，为更可靠和可审计的人工智能提供了一条路径。
## 747. `cs.LG` - HyperDiffusionFields (HyDiF): 通过扩散引导超网络学习隐式分子神经场 [PDF](https://arxiv.org/pdf/2510.18122), [HTML](https://arxiv.org/abs/2510.18122)
### Authors
Sudarshan Babu,Phillip Lo,Xiao Zhang,Aadi Srivastava,Ali Davariashtiyani,Jason Perera,Michael Maire,Aly A. Khan
### Background
当前的分子建模方法主要依赖于离散原子坐标或图结构来表示分子构象。然而，这些方法在跨分子学习和泛化方面存在局限性。本文介绍了一种新的框架，即HyperDiffusionFields (HyDiF)，将3D分子构象建模为连续场，以改善模型的灵活性和表达能力。这种方法的核心是Molecular Directional Field (MDF)，它将空间中的任意点映射到特定类型原子的方向。通过使用分子特定的神经隐式场即Molecular Neural Fields (MNFs)，HyDiF能够实现跨分子的学习和泛化。为了进一步增强生成能力，文章提出了一种通过扩散模型训练共享超网络的方法，使模型能够在分子场的功能空间中采样。这些方法扩展到了支持结构条件生成任务的掩码扩散机制，如分子修复，并且能够精细地提取分子构象的空间特征，从而预测分子属性，这对于基于图或点云的方法来说是不易实现的。此外，该方法还能处理更大规模的生物分子，展示了基于场的分子建模的一个有前景的方向。
### Innovation
提出了HyperDiffusionFields (HyDiF)框架，利用扩散引导的超网络来学习隐式的分子神经场，将分子构象建模为连续场，而不是离散的原子坐标或图结构。该方法的核心MDF将空间中的任意点映射到特定类型原子的方向。通过分子特定的神经隐式场MNF，以及通过扩散模型训练共享超网络的方法，增强模型的跨分子学习和泛化能力，同时实现生成能力，并支持结构条件生成任务。这种新的建模方式能够精细地提取空间特征，从而预测分子属性，并且能扩展到处理大规模生物分子，展现出基于场的分子建模的优势。
### Conclusion
通过HyperDiffusionFields (HyDiF)框架，将3D分子构象建模为连续场，能够实现跨分子的学习和泛化能力的增强，通过扩散模型训练共享超网络的方法提高了模型的生成能力，适配了结构条件生成任务，如分子修复。此外，该方法还能够在精细的空间范围内提取特征，从而预测分子属性，并展现出基于场的分子建模在未来应用中的潜力，特别是对于大规模生物分子的建模。
## 748. `cs.LG` - AUVs中目标检测中合作效率和通信隐秘性联合优化 [PDF](https://arxiv.org/pdf/2510.18225), [HTML](https://arxiv.org/abs/2510.18225)
### Authors
Xueyao Zhang,Bo Yang,Zhiwen Yu,Xuelin Cao,Wei Xiang,Bin Guo,Liang Wang,Billy Pik Lik Lau,George C. Alexandropoulos,Jun Luo,Mérouane Debbah,Zhu Han,Chau Yuen
### Background
本文研究了自主水下机器人（AUVs）进行水下协同目标检测的问题，重点关注合作效率与通信隐秘性之间的关键权衡。现有研究需要解决这一挑战，通过综合建模系统及其涉及的信号和任务，以及能量消耗，为多AUVs的有效和安全操作提供了理论见解和实际解决方案，为水下隐秘通信任务的执行提供了重要启示。
### Innovation
本文提出了一种创新的分层行动管理框架，通过制定联合轨迹和功率控制优化问题，并将其形式化为宏观和微观层面，解决了这一挑战。在宏观层面，主AUV将代理选择过程建模为马尔可夫决策过程，并使用接近策略优化算法进行策略性任务分配。在微观层面，每个选定代理的分散决策被建模为部分可观测马尔可夫决策过程，并使用多代理接近策略优化算法动态调整其轨迹和传输功率，根据其本地观察进行优化。在集中训练和分散执行的范式下，目标检测框架实现了适应性隐秘协同，同时满足能量和移动性约束。
### Conclusion
本文提供了一种目标检测框架，它能够实现多AUVs的适应性隐秘协同，同时满足能量和移动性约束，为水下隐秘通信任务的有效和安全执行提供了理论和实践方法。
## 749. `cs.LG` - ACTG-ARL：具有RL增强控制的差分隐私条件文本生成 [PDF](https://arxiv.org/pdf/2510.18232), [HTML](https://arxiv.org/abs/2510.18232)
### Authors
Yuzheng Hu,Ryan McKenna,Da Yu,Shanshan Wu,Han Zhao,Zheng Xu,Peter Kairouz
### Background
生成高质量的合成文本对于在保护用户隐私的情况下训练和评估语言模型至关重要。以往的工作在合成差分隐私数据集时常常无法保留关键的统计属性，噪声不可避免地导致了使用的功能损失，并且缺乏生成过程中的细粒度控制，因此存在改进的空间。
### Innovation
本研究提出了两种贡献：首先，介绍了一种分层框架，将差分隐私合成文本生成分解为特征学习和条件文本生成两个子任务，这种方法简化了整体合成任务并增强了生成过程中的控制；其次，提出了一种后训练方法Anchored RL（ARL），该方法增强ACTG（属性条件文本生成）的指令遵循能力，通过结合强化学习（RL）增强控制，并使用SFT锚定在最佳的N个数据上防止奖励作弊，从而进一步优化了差分隐私条件文本生成的质量和控制水平，即使在严格的隐私保障下也是如此。
### Conclusion
通过这些组成要素，我们的端到端算法ACTG-ARL不仅显著提高了 DP 合成文本的质量（与以往工作相比提高 20% 的 MAUVE），还提高了在严格隐私保障下的生成条件生成器的控制能力。
## 750. `cs.LG` - 基于物理感知神经网络的多阶段闭环最优控制 [PDF](https://arxiv.org/pdf/2510.18195), [HTML](https://arxiv.org/abs/2510.18195)
### Authors
Jostein Barry-Straume,Adwait D. Verulkar,Arash Sarshar,Andrey A. Popov,Adrian Sandu
### Background
设计控制系统的目标是通过控制信号引导动态系统表现出预期的行为。哈密尔顿-雅可比-贝尔曼（HJB）偏微分方程提供了最优控制系统设计的框架，但其数值解计算量大且常无解析解。物理导向的机器学习方法，如物理感知神经网络（PINNs），为解决HJB方程提供了新的替代方法，这种新的方法可以解决数值解的困难。本文提出了一种多阶段集成框架，通过HJB方程学习最佳费用-前瞻函数，进而获得相应的最优控制信号。先前基于PINN的方法依赖于控制HJB方程的稳定化过程。本框架不使用稳定化术语，并提供了一种控制非线性系统的方法，通过单个学习控制信号或集成控制信号策略。该研究通过集成控制和单个控制在噪声和扰动状态下实现了稳态时间不变两状态连续非线性系统的闭环控制，并且考虑了不同初始条件的情况，展示了成功案例。
### Innovation
本文提出了一种不依赖于HJB方程稳定化过程的物理感知神经网络（PINNs）驱动的多阶段集成框架。该框架能够通过学习获得最优控制信号来控制非线性系统，同时展示了在考虑系统状态噪声和初始条件变化的情况下的成功应用场景。
### Conclusion
通过使用物理感知神经网络方法，本文成功设计了能够处理噪声、扰动状态和变化初始条件等复杂情况的非线性系统的最优闭环控制系统，展示了多阶段集成框架的优势。
## 751. `cs.LG` - 为社会影响培养AI生态需要扩展和加强评价标准 [PDF](https://arxiv.org/pdf/2510.18238), [HTML](https://arxiv.org/abs/2510.18238)
### Authors
Bryan Wilder,Angela Zhou
### Background
近年来，对人工智能/机器学习（AI/ML）在社会影响方面的研究兴趣不断增加，因此越来越多的出版平台细化了对实践驱动AI/ML研究的评审标准。然而，这些评审指南往往会最具体地认可那些同时实现部署和新颖的机器学习方法创新的项目。这为企业和社会影响领域的研究人员引入了不利影响，因为有贡献单一方面（应用或方法论）的项目更能满足合作伙伴的需求，从而不利于一个更广泛的研究生态系统的发展。
### Innovation
该论文提出了一个全新的观点：研究人员和评审者在社会影响的机器学习领域应当采用更广泛的社会影响观念，并且更加严谨地评估已部署系统的社会影响，而不只是关注部署和新的机器学习方法创新。这将激励更多的研究项目，从而更有利于社会整体的利益和发展。
### Conclusion
研究者和评审者应同时采取两种措施：首先，扩大对社会影响的理解，不仅仅限于部署；其次，更加严格地评估部署系统的影响。这样可以促进更多样化的研究项目，提高项目的可持续性。
## 752. `cs.LG` - 双层次噪声对应学习在多模态实体对齐中的应用 [PDF](https://arxiv.org/pdf/2510.18240), [HTML](https://arxiv.org/abs/2510.18240)
### Authors
Haobin Li,Yijie Lin,Peng Hu,Mouxing Yang,Xi Peng
### Background
多模态实体对齐（MMEA）旨在识别跨异构多模态知识图谱（MMKGs）中等价的实体。每个实体通过多种模态的属性进行描述。现有方法通常假设内部实体对应和跨图对应都是无误的，但在实际的MMKG中，由于依赖于专家注释，这种情况往往会被违背。因此，本文研究了一个在MMEA中尚未充分探索但极为实际的问题，即双层次噪声对应（DNC），包含内部实体（实体-属性）和跨图（实体-实体和属性-属性）对应中的错位。
### Innovation
本文提出了一种鲁棒的MMEA框架——RULE。RULE通过专门的两步原则估计内部实体和跨图对应关系的可靠性，并在此基础上，在多模态属性融合中缓解内部对应噪声的影响，防止过度拟合噪声的跨图对应关系。此外，RULE结合了一个关联推理模块，旨在揭开图之间潜在的属性-属性连接，从而保证更加准确的等价实体识别。
### Conclusion
详尽的实验在五个基准上表明，我们的方法在处理DNC问题时明显优于七个最先进的方法。研究代码已发布于XLearning-SCU/RULE。
## 753. `cs.LG` - NTKMTL: 从神经核视角缓解多任务学习中的任务不平衡 [PDF](https://arxiv.org/pdf/2510.18258), [HTML](https://arxiv.org/abs/2510.18258)
### Authors
Xiaohan Qin,Xiaoxing Wang,Ning Liao,Junchi Yan
### Background
多任务学习（MTL）能够通过任务间知识转移来增强泛化能力，广泛应用于各种领域。然而，任务不平衡仍然是MTL的一个重要挑战。虽然平衡不同任务的收敛速度是一种有效的解决办法，但在复杂MTL系统中准确描述多个任务的训练动态和收敛速度仍然极具挑战。
### Innovation
提出了基于神经核理论（NTK理论）的新方法NTKMTL，引入扩展的NTK矩阵进行多任务收敛速度平衡，采用谱分析缓解任务不平衡。进一步提出了NTKMTL-SR，实现训练效率的同时保持竞争性能。
### Conclusion
广泛实验表明，该方法在多种基准测试中达到最先进的性能，包括多任务监督学习和多任务强化学习。相关源代码可查阅该网址：this https URL.
## 754. `cs.LG` - 重新思考主成分分析通过对偶性 [PDF](https://arxiv.org/pdf/2510.18130), [HTML](https://arxiv.org/abs/2510.18130)
### Authors
Jan Quan,Johan Suykens,Panagiotis Patrinos
### Background
最近研究表明，自注意力机制与核主成分分析（PCA）之间存在联系，这促使研究者重新审视PCA的基本原理。研究者利用差凸（DC）框架，提出了几种新的形式化表示，并提供了新的理论见解。特别是在核化和离样本适用性方面，对PCA类似的问题家族进行了探讨。同时，研究者揭示了同时迭代方法（与经典QR算法相关）其实就是差凸算法（DCA）的一种具体实例，为这一长期存在的方法提供了优化视角。此外，还描述了新的PCA算法，并通过实验与当前最先进的方法进行了对比。最后，引入了一个核化的对偶形式，用于一种鲁棒性的PCA方法，该方法最小化重构误差的l1偏差。
### Innovation
利用差凸（DC）框架提出了几种新的PCA形式化表示，并揭示了几个理论见解。首次证明了PCA类似问题的核化能力和离样本适用性。同时迭代方法被识别为差凸算法的特例，为经典的QR算法提供了优化视角。并提出了新的PCA算法和鲁棒PCA的核对偶形式。最后，本文通过实验对比了所提出的方法与当前最佳方法。
### Conclusion
本文重新审视PCA的理论基础，并通过差凸框架创新性地提出了几种新的形式化表示和算法，验证了这些新的方法在实际应用中的有效性。
## 755. `cs.LG` - Scaling Laws Meet Model Architecture: Toward Inference-Efficient LLMs [PDF](https://arxiv.org/pdf/2510.18245), [HTML](https://arxiv.org/abs/2510.18245)
### Authors
Song Bian,Tao Yu,Shivaram Venkataraman,Youngsuk Park
### Background
随着大型语言模型（LLM）参数量和训练数据规模的扩大，模型的性能得到了显著提升。然而，随着这些模型变得越来越强大且被广泛部署，推理成本成为了急需解决的问题。现有的研究中，模型准确性和推理效率之间的权衡仍然没有得到充分探索。本文研究了隐藏尺寸、MLP和注意力参数分配比例以及分组查询注意力等关键架构因素对推理成本和准确性的影响。通过引入条件缩放定律，结合Chinchilla框架改进了现有模型，并提出了一种搜索框架来优化的同时满足推理效率和准确性的模型架构。
### Innovation
本文提出了一种条件缩放定律，该定律结合了Chinchilla框架的信息，改进了现有的模型架构，并提出了一个搜索框架以找到同时满足推理效率和准确性的最佳架构。通过训练超过200个模型，范围从80M到3B参数以及8B到100B训练令牌，并使用提出的条件缩放定律进行拟合，验证了该方法的有效性。优化后的架构在相同训练预算下，相对于LLaMA-3.2实现了高达2.1%的更高准确性和42%的更高推理吞吐量。
### Conclusion
本文的条件缩放定律可靠地预测了最优的架构选择，并且生成的模型超过了现有的开源基准模型。在相同的训练预算下，优化后的架构在准确性和推理吞吐量方面相对于LLaMA-3.2都有显著提升。
## 756. `cs.LG` - 从竞争到协同：解锁主导向驱动图像生成中的强化学习 [PDF](https://arxiv.org/pdf/2510.18263), [HTML](https://arxiv.org/abs/2510.18263)
### Authors
Ziwei Huang,Ying Shu,Hao Fang,Quanyu Long,Wenya Wang,Qiushi Guo,Tiezheng Ge,Leilei Gan
### Background
主导向驱动的图像生成模型在身份保持（保真度）和指令遵循（易编辑性）之间存在基本的权衡。虽然在线强化学习（RL），尤其是GPRO算法，提供了潜在的解决办法，但直接应用GPRO会导致竞争性退化，因为简单的线性奖励聚合会导致冲突的梯度信号，并且与扩散过程的时间动态不匹配。
### Innovation
提出了一个名为Customized-GRPO的新框架，包含两项创新：(i) 协同意识的奖励塑形（SARS），这是一个非线性机制，明确惩罚冲突的奖励信号并放大协同的奖励信号，提供更清晰和坚定的梯度；(ii) 时间意识动态加权（TDW），通过在早期强调指令遵循，在后期强调身份保持，使优化压力与模型的时间动态保持一致。
### Conclusion
广泛的实验表明，我们的方法在提高保真度同时增强易编辑性方面明显优于GPRO基线，成功解决了竞争性退化问题。我们的模型实现了对关键身份特征的保持和对复杂文本提示的准确遵循的更好平衡。
## 757. `cs.LG` - 关于层次时序因果表示学习的可识别性研究 [PDF](https://arxiv.org/pdf/2510.18310), [HTML](https://arxiv.org/abs/2510.18310)
### Authors
Zijian Li,Minghao Fu,Junxian Huang,Yifan Shen,Ruichu Cai,Yuewen Sun,Guangyi Chen,Kun Zhang
### Background
建模多层级潜在动态背后的时序数据对于捕捉现实任务中多个抽象级别之间的时序依赖性至关重要。然而，现有的时序因果表示学习方法无法捕捉这种动态，因为这些方法无法从单时间步观测变量中恢复层次潜在变量的联合分布。
### Innovation
提出了一种名为Causally Hierarchical Latent Dynamic (CHiLD)的识别框架。该框架首先利用时序上下文观测变量来识别多层潜在变量的联合分布，然后利用层次结构中潜在变量的自然稀疏性来识别每一层的潜在变量。在此基础上，开发了一种基于变分推断的时间序列生成模型，该模型包括一个上下文编码器和归一化流动层次先验网络，以施加层次潜在动态的独立噪声条件。
### Conclusion
在合成和真实数据集上的实证评估验证了我们理论的正确性，并展示了CHiLD在建模层次潜在动态方面的有效性。
## 758. `cs.LG` - 基于理论保证的在线时间序列预测 [PDF](https://arxiv.org/pdf/2510.18281), [HTML](https://arxiv.org/abs/2510.18281)
### Authors
Zijian Li,Changze Zhou,Minghao Fu,Sanjay Manjunath,Fan Feng,Guangyi Chen,Yingyao Hu,Ruichu Cai,Kun Zhang
### Background
本文关注的是在线时间序列预测，在这种预测中，随着时间的推移，未知分布会发生变化，即潜在变量影响历史观测到未来观测之间的映射。这种变化使得现有的预测方法难以适应这些变化。因此，开发一种自动化的在线时间序列预测方法是必要的，以便在动态变化的环境下进行预测并保证预测的准确性。
### Innovation
本文提出了一种带有理论保证的在线时间序列预测框架（TOT），通过向预测器提供潜在变量，证明了Balayes风险（贝叶斯风险的紧致化）的减少，并且这种益处在潜在变量估计不确定的情况下仍然存在，并随着潜在变量更精确的识别而增加。此外，还提出了使用最少相邻观测来识别潜在变量的方法。通过采用时间解码器来匹配观测变量的分布，并通过两个独立的噪声估计器建模潜在变量的因果关系和观测变量的混合过程，设计了一个模型无关的蓝图来改进在线预测算法。实验结果支持了理论上的主张，并通过几种基线插件实现展示了在实际应用中的有效性。
### Conclusion
本文开发的TOT框架能够有效应对时间序列中未知分布变化的问题，并通过理论分析和实验验证了其在在线预测中的有效性。
## 759. `cs.LG` - 基于物理的参数多臂老虎机在毫米波通信信道对齐中的应用 [PDF](https://arxiv.org/pdf/2510.18299), [HTML](https://arxiv.org/abs/2510.18299)
### Authors
Hao Qin,Thang Duong,Ming Li,Chicheng Zhang
### Background
在毫米波（mmWave）通信中，波束对齐和跟踪是解决显著路径损耗的关键。由于扫描整个方向空间效率低下，因此需要设计一个有效的鲁棒方法来识别最优的波束方向。传统带宽算法在大波束空间中收敛速度慢，许多现有工作通过在奖励函数结构上假设单模态或多模态能够提出高效的带宽对齐算法。然而，这些假设往往不适用于实际场景，导致算法选择次优波束。
### Innovation
本文提出了两种基于物理的参数多臂老虎机算法：pretc和prgreedy。这两种算法利用了mmWave信道的稀疏多路径特性，这是一种通用而现实的假设。它们根据抽样历史奖励估计路径参数，并据此对最优波束进行选择或跟踪。pretc采用随机探索阶段，然后根据估计奖励函数锁定最优波束；prgreedy则在线估计并选择当前最优波束。相较于现有的方法，这两种算法在多种场景和不同信道环境下都表现出更高的性能，证明了它们的可移植性和鲁棒性。
### Conclusion
通过合成的DeepMIMO数据集和真实的DeepSense6G数据集进行实验，表明pretc和prgreedy算法在多种场景下均优于现有方法，突显了它们的广泛适用性和鲁棒性。
## 760. `cs.LG` - 更高的嵌入维度为简单排序任务创建更强大的世界模型 [PDF](https://arxiv.org/pdf/2510.18315), [HTML](https://arxiv.org/abs/2510.18315)
### Authors
Brady Bhalla,Honglu Fan,Nancy Chen,Tony Yue YU
### Background
本文研究了嵌入维度对通过强化学习训练的transformer在执行冒泡排序风格的相邻交换时内部“世界模型”生成的影响。研究发现，即使嵌入维度非常小，模型也能实现高精度，但更大的维度能够提供更忠实、一致且稳健的内部表示。具体来说，更高的嵌入维度增强了结构化内部表示的形成，并提高了可解释性。通过数百次实验，观察到了两种一致的机制：一是注意力权值矩阵的最后一行单调地编码了令牌的全局顺序；二是选择的置换与这些编码值中最大的相邻差值对齐。这些结果量化地证明了transformer构建结构化的内部世界模型，并且模型大小在提高表示质量方面起作用不仅限于最终性能。作者还提供了他们的度量标准和分析，这些分析可以用于探索类似的算法任务
### Innovation
本文的创新在于通过小嵌入维度与大嵌入维度的比较，揭示了transformer在简单排序任务中生成结构化内部世界模型的能力。更重要的是，研究发现了注意力权值矩阵的特定行为模式，这些模式对于理解transformer在排序任务中的工作原理和表示机制提供了重要见解。此外，作者通过公开他们的度量标准和分析，为其他研究提供了实验依据和参考
### Conclusion
研究结果表明，transformer能够通过少量嵌入维度构建结构化的内部世界模型，而更大的嵌入维度则能产生更精确、一致且稳健的内部表示。除了提高最终性能外，模型的大小还改善了表示质量。这些发现为探索transformer在复杂任务中的行为提供了新的理解路径，也公开了数据和分析结果以供其他类似研究参考。
## 761. `cs.LG` - 灵活的证据深度学习的不确定性估计 [PDF](https://arxiv.org/pdf/2510.18322), [HTML](https://arxiv.org/abs/2510.18322)
### Authors
Taeseong Yoon,Heeyoung Kim
### Background
不确定性量化（UQ）在高风险应用中至关重要，因机器学习模型的过度自信预测可能造成严重后果。有效的不确定性量化方法需要在计算效率和针对多样场景的泛化能力之间取得平衡。证据深度学习（EDL）通过预测类别概率的狄利克雷分布来实现高效性，但其对类别概率狄利克雷分布的限制假设导致其在复杂或不可预见情况下的鲁棒性较差。这篇文章提出了扩展EDL的灵活证据深度学习（$textit{F}$-EDL），以打破这一限制假设，提供更加表达性强和适应性好的不确定性表示，增强模型在挑战性场景下的泛化能力和可靠性
### Innovation
提出了灵活的证据深度学习（$textit{F}$-EDL），通过预测一个灵活的狄利克雷分布（一种狄利克雷分布的推广）来克服传统EDL对狄利克雷分布假设的限制。这种方法提供了更具表达性和适应性的不确定性表示，获得了理论上的多项优势，并在多种评估设置下展示了最先进的不确定性量化表现，包括经典、长尾和噪声数据分布场景。
### Conclusion
通过建立$textit{F}$-EDL的理论优势并验证其在不同评估场景下的优越性，研究证明了该方法在复杂和不可预见情况下的可靠性与泛化能力得到了显著提升。
## 762. `cs.LG` - 为什么政策梯度算法适用于非折扣总回报MDP？ [PDF](https://arxiv.org/pdf/2510.18340), [HTML](https://arxiv.org/abs/2510.18340)
### Authors
Jongmin Lee,Ernest K. Ryu
### Background
经典的基于策略的梯度方法是现代基于策略的强化学习算法的理论和概念基础。大多数对该方法的严谨分析，尤其是那些确立收敛保证的分析，都假设折扣因子 γ < 1。然而，最近有关大型语言模型的基于策略的RL研究使用了无折扣总回报设置，γ = 1，这使得许多现有理论不适用。因此，本文分析无折扣期望总回报无限期MDP的政策梯度方法，基于两个关键见解：（i）MDP状态可以分为递归状态和瞬态状态，这种分类对给定每个动作有严格正概率的策略集不变（这在采用软输出层的深度学习RL模型中常见），（ii）经典的态访问度量可能在 γ = 1 时不定义，可以被一个新对象，被称为瞬态访问度量，所取代。
### Innovation
本文提出了针对无折扣期望总回报无限期MDP的政策梯度方法的分析，基于两个关键见解：如何对状态进行分类方法的不变性，以及对经典态访问度量的改进，以应对 γ = 1 的情况。
### Conclusion
本文的分析为理解为什么政策梯度算法在无折扣总回报MDP中有效提供了理论基础。
## 763. `cs.LG` - 一步流动匹配实现可扩展、可解释且理论上有保障的异常检测 [PDF](https://arxiv.org/pdf/2510.18328), [HTML](https://arxiv.org/abs/2510.18328)
### Authors
Zhong Li,Qi Huang,Yuxuan Zhu,Lincen Yang,Mohammad Mohammadi Amiri,Niki van Stein,Matthijs van Leeuwen
### Background
本文介绍了Time-Conditioned Contraction Matching (TCCM)，这是一种新颖的方法，用于在表格数据中进行半监督异常检测。TCCM借鉴了流动匹配方法，这是一种生成建模框架，能够学习分布在之间的速度场，并且证明了其性能优于扩散模型和生成对抗网络。但在原始形式下应用流动匹配方案时，TCCM 不直接进行，而是基于其核心思想——在各种分布之间学习速度场——通过对每个采样时间步骤向固定目标 (原点) 预测时间条件下的收缩向量，简化了框架。
### Innovation
TCCM 提出了三种关键优势：1) 一种轻量级且可扩展的训练目标，训练和推理过程中无需求解常微分方程；2) 一种高效的评分策略，称为一步偏差，能够在单次前向传递中计算出期望收缩行为的偏差量，从而解决现有连续时间模型 (如DTE) 在推理中的瓶颈；3) 可解释性和理论上可证明的鲁棒性，因为学习到的速度场直接操作于输入空间，使得异常评分具有固有的特征级可归因性；此外，评分函数对于输入具有Lipschitz连续性，从而在小扰动下提供了理论上的保证。
### Conclusion
在 ADBench 基准测试上进行了广泛的实验，表明 TCCM 在检测准确性和推理成本之间取得了良好的平衡，超越了最先进的方法，特别是在高维和大数据集上表现出明显优势。源代码可在我们的GitHub仓库中找到。
## 764. `cs.LG` - 基于修剪注意头的集成以实现具备不确定性感知的高效Transformer [PDF](https://arxiv.org/pdf/2510.18358), [HTML](https://arxiv.org/abs/2510.18358)
### Authors
Firas Gabetni,Giuseppe Curci,Andrea Pilzer,Subhankar Roy,Elisa Ricci,Gianni Franchi
### Background
不确定性量化(UQ)在安全关键型环境中部署深度神经网络中至关重要。尽管深度集成等方法能够实现强大的不确定性量化性能，但它们的高计算和内存成本限制了在大型模型上的扩展能力。
### Innovation
我们提出了Hydra Ensembles，这是一种高效的基于变换器的集成方法，通过修剪注意力头创造多样化的成员，并通过带有分组全连接层的新多头注意力机制进行合并。这使得我们得到了一个紧凑的模型，推理速度接近单个网络，而不重新训练就能达到或超过深度集成在不确定性量化性能上的表现。我们还深入分析了修剪方法，表明简单的修剪方法会损害校准性能，而Hydra Ensembles则保持了稳健的不确定性。在各类架构上的图像和文本分类任务上，我们的方法在零样本分类上超过了现有方法，甚至不需要额外的训练。
### Conclusion
我们的Hydra Ensembles方法提供了一种有效的解决方案，能够在保持强力不确定性量化性能的同时，显著提高模型效率并解决计算成本的问题。
## 765. `cs.LG` - 可计算的通用在线学习 [PDF](https://arxiv.org/pdf/2510.18352), [HTML](https://arxiv.org/abs/2510.18352)
### Authors
Dariusz Kalociński,Tomasz Steifer
### Background
理解何时学习成为可能是机器学习理论中的基本任务。然而，许多已知特征化的工作将学习视为一种数学对象，而忽略了关键问题：当学习可以被实现为计算机程序时？本文针对通用在线学习这一广泛理论模型，该模型最近由Bousquet等人（2021年STOC会议）进行了特性化。在此模型中，没有预先固定的假设；相反，对手（扮演自然的角色）可以在保持与给定假设类局部一致性的前提下改变策略。我们要求学习者使用可实施为计算机程序的策略来实现有限数量的主要错误。研究表明，即使假设类从计算理论的角度相对容易，通用在线学习也不一定意味着可计算的通用在线学习。然后我们研究了在这方面的可计算的广义在线学习的 agnostic 变体，并且提供了对在这种意义上的可学习类的精确特征化。我们还考虑了规范的广义在线学习的变体，并且提供了它何时可能的确切条件。
### Innovation
本文主要贡献在于：1. 对通用在线学习进行了更实际的特征化，特别是不固定假设，而是允许对手根据局部一致性动态调整策略。2. 证明了即使在相对简单的假设类中，通用在线学习也不一定意味着可计算的通用在线学习。3. 提供了可计算的广义在线学习和规范的广义在线学习在哪个条件下可能的确切特征化，从而给现有理论提供了更现实的视角和理解。
### Conclusion
总之，本文通过引入可计算的广义在线学习的概念并且对通用在线学习的特征化进行了更实际的研究，提出了精确的特征化和可学习的类条件，从而更深刻地理解了在线二分类相关的归纳推理问题和现有理论框架。本文的研究为理解和改进机器学习模型的实际可实现性和理论基础提供了新的视角。
## 766. `cs.LG` - 通过双重重新编程实现无监督开放集图域适应 [PDF](https://arxiv.org/pdf/2510.18363), [HTML](https://arxiv.org/abs/2510.18363)
### Authors
Zhen Zhang,Bingsheng He
### Background
无监督图域适应成为了一种有前景的 paradigma，用于从带有完全标签的数据源图转移到未标记的目标图。大多数现有的图域适应模型主要关注闭合集设置，意味着源域和目标域共享相同的标签空间。然而，这种假设在现实场景中可能不适用，因为目标域可能包括在源域中未出现的新类别。
### Innovation
本文探讨了无监督开放集图域适应的问题，目标不仅仅是正确分类已知类别的目标节点，还要识别以前未见过的节点类型到未知类别。为此，提出了一种新颖的框架 GraphRTA，对图和模型进行重新编程。具体地，通过修改目标图的结构和节点特征来对图进行重新编程，以更好地分离已知和未知类。同时，通过剪枝域特定参数来减少对源图的偏见，同时保留捕捉图间可转移模式的参数。此外，还为分类器添加了一个额外的未知类维度，从而消除了在开放集识别中手动指定阈值的需要。
### Conclusion
在多个公开数据集上的全面实验表明，作者提出的模型在开源集中实现了令人满意的性能，并与最近的最新基准相比具有竞争力。源代码和数据集已在该链接处公开。
## 767. `cs.LG` - 基于M个正实例的N元组数据学习：无偏风险估计与理论保证 [PDF](https://arxiv.org/pdf/2510.18406), [HTML](https://arxiv.org/abs/2510.18406)
### Authors
Miao Zhang,Junpeng Li,ChangChun HUa,Yana Yang
### Background
弱监督学习通常使用粗粒度的集合信号而非实例标签。本文研究一种每个训练样本为包含恰好m个正实例的n元组的场景，仅观察到每个元组的计数m。这种NTMP（N元组中有M正实例）监督在如基于区域建议的图像分类和多实例测量中出现。
### Innovation
提出了一种通过将元组生成过程与潜在实例边际联系起来，使得元组计数能够作为一种可训练的无偏风险估计器(URE)。基于固定的(n,m)，推导出封闭形式的URE，并将其扩展到可变的元组大小、计数以及二者的组合。还提出了简单ReLU修正来增强有限样本稳定性，而保持渐近正确性。该方法在基准任务中有效地优于代表性的弱监督基线，且在类别先验不平衡和不同元组配置下仍保持鲁棒性。
### Conclusion
无论处于哪个类别先验不平衡的情境下，该方法都能表现出对NTMP任务的有效利用，通过一个既理论上可靠又具实践稳定性的目标，在精密率与F1分数之间提供了有利的权衡。
## 768. `cs.LG` - Simple and Efficient Heterogeneous Temporal Graph Neural Network [PDF](https://arxiv.org/pdf/2510.18467), [HTML](https://arxiv.org/abs/2510.18467)
### Authors
Yili Wang,Tairan Huang,Changlong He,Qiutong Li,Jianliang Gao
### Background
Heterogeneous temporal graphs (HTGs)是现实世界中广泛存在的数据结构。现有的基于注意力机制的神经网络虽然提高了HTGs上的表示学习，但这些方法依赖于分离的时间和空间学习范式，导致缺乏时空信息的互动，并且增加了模型的复杂度。
### Innovation
我们提出了一种新的学习范式，称为简单高效的Heterogeneous Temporal Graph Neural Network（SE-HTGNN）。具体来说，我们创新性地通过一种新颖的动力学注意力机制将时间建模融入到空间学习中，从而保留历史图快照中的注意力信息来指导后续的注意力计算，提升HTGs的整体可区分表示学习能力。此外，利用大型语言模型对SE-HTGNN进行提示，使其能够捕捉节点类型的隐含属性作为先验知识，以全面和适应性地理解HTGs。
### Conclusion
广泛的实验表明，SE-HTGNN在保持最佳预测准确性的同时，比最先进的和最新的基线方法快10倍。
## 769. `cs.LG` - 浅层神经网络的逼近率：巴伦空间、激活函数与最优性分析 [PDF](https://arxiv.org/pdf/2510.18388), [HTML](https://arxiv.org/abs/2510.18388)
### Authors
Jian Lu,Xiaohuang Huang
### Background
本文研究了使用指数函数幂作为激活函数的浅层神经网络的逼近性质。研究集中在逼近率与被逼近函数的维度以及光滑性之间的依赖关系。研究了ReLU$^{k}$激活函数的逼近率，证明了在$boldsymbol{l}^{1}$有界系数或光滑性条件不足的情况下，最优的逼近率无法实现。证明了巴伦空间和Sobolev空间中函数的最佳逼近率，并确认了维度灾难的存在。研究结果阐明了浅层神经网络逼近能力的局限性，并为激活函数和网络结构的选择提供了启示。
### Innovation
1. 研究了ReLU$^{k}$激活函数在不同条件下（$boldsymbol{l}^{1}$有界系数、光滑性条件）的逼近率最优性问题。2. 证明了巴伦空间和Sobolev空间中的函数在各种范数下最佳逼近率的存在。3. 确认了维度灾难，即维度增加会导致逼近率显著下降。4. 提供了选择合适的激活函数和网络结构的理论依据。
### Conclusion
浅层神经网络在某些条件下难以达到最优逼近率，特别是在维度高且函数光滑性不足的情况下。最佳逼近率问题在巴伦空间和Sobolev空间中的结论确认了维度灾难的存在，限制了浅层网络在高维问题中的适用性。
## 770. `cs.LG` - 可证明的深层神经网络自适应正则化的一般化边界 [PDF](https://arxiv.org/pdf/2510.18410), [HTML](https://arxiv.org/abs/2510.18410)
### Authors
Adeel Safder
### Background
深度神经网络（DNNs）虽然表现出色，但由于其高容量往往容易过拟合。为了解决这个问题，本文提出了一种新的正则化方法——Momentum-Adaptive Gradient Dropout (MAGDrop)，它根据不同激活值的当前梯度和累积动量动态调整掉节点率，从而增强了非凸优化场景中的模型稳定性。
### Innovation
本文通过从理论上得出了一个紧缩的PAC-Bayes泛化边界来证明MAGDrop的有效性，这个边界考虑了它的自适应特性。与标准方法相比，利用动量驱动的扰动控制，MAGDrop能够获得多达20%更紧的泛化边界。实验上，基于激活值的MAGDrop方法在MNIST和CIFAR-10数据集上的测试准确率分别提高了1-2%，并且泛化差距分别降低了0.48%和7.14%。
### Conclusion
本文通过理论分析和实验验证，提供了一种增强深层神经网络泛化能力的稳健框架，适用于高风险应用。
## 771. `cs.LG` - 通过约束质量转移学习玻尔兹曼生成器 [PDF](https://arxiv.org/pdf/2510.18460), [HTML](https://arxiv.org/abs/2510.18460)
### Authors
Christopher von Klitzing,Denis Blessing,Henrik Schopmans,Pascal Friederich,Gerhard Neumann
### Background
高维度和多模态非归一化概率分布的有效抽样是科学和机器学习许多领域的核心挑战。玻尔兹曼生成器旨在通过抽样给定温度下的物理系统的玻尔兹曼分布来模拟分子等系统。传统的变分方法倾向于模式崩溃，而退火方法使用几何时间表则容易出现质量传递现象，并且需要大量的时间表调优。
### Innovation
本文引入了一种变分框架——约束质量转移（CMT），它生成具有约束的中间分布，这些约束包括后继步骤之间Kullback-Leibler散度和熵衰减的限制。这些约束提高了分布重叠度，减轻了质量传递现象，并阻止了过早收敛。CMT在标准玻尔兹曼生成器基准测试和新引入的ELIL四肽系统（迄今为止没有分子动力学样本的最大系统研究）中，表现优于最先进的变分方法，提高了超过2.5倍的有效样本量，同时避免了模式崩溃。
### Conclusion
CMT在玻尔兹曼生成器的多个基准测试和ELIL四肽系统中，展示了其在提高有效样本大小和避免模式崩溃方面的显著性能，从而为理解和模拟复杂系统提供了一种更有效的方法。
## 772. `cs.LG` - 通过不确定性感知调节减少安全批评者中过度保守现象的保证但不遗憾：增强安全RL [PDF](https://arxiv.org/pdf/2510.18478), [HTML](https://arxiv.org/abs/2510.18478)
### Authors
Daniel Bethell,Simos Gerasimou,Radu Calinescu,Calum Imrie
### Background
确保强化学习（RL）代理的安全探索对于在实际系统中的部署至关重要。然而，现有方法难以找到合适的平衡：严格的安全限制通常会损害任务性能，而侧重于奖励的方法则经常违反安全约束，导致模糊的成本景观，从而阻碍策略改进。
### Innovation
提出了不确定性的安全批评者（USC），一种结合不确定性感知调节和精炼的新方法，用于训练批评者。USC在不确定和昂贵的区域集中保守性，而在安全区域保持清晰的梯度，从而使策略能够实现有效的奖励-安全权衡。
### Conclusion
广泛实验证明，USC将安全违规减少了约40%，同时保持或提高了奖励，还减少了预测和真实成本梯度之间的误差约83%，打破了安全与性能之间的现役权衡，为可扩展的安全RL铺平了道路。
## 773. `cs.LG` - 基于生成预训练任务的神经架构编码中学习信息流 [PDF](https://arxiv.org/pdf/2510.18360), [HTML](https://arxiv.org/abs/2510.18360)
### Authors
Sunwoo Kim,Hyunjin Hwang,Kijung Shin
### Background
深度学习模型在特定任务和数据集上的性能高度依赖于其神经架构，因此研究人员致力于快速准确地识别适合目标任务和数据集的架构。为了实现这一目标，研究者通常使用神经架构编码器来预测神经架构的性能。尽管许多最先进的编码器试图捕捉神经架构中的信息流，通过特定的模型结构来表示信息如何在整个前向传播和反向传播过程中流动，但这些基于信息流的编码器由于其复杂的结构，相较于简化编码器来说，处理时间显著增加，这是一个实际挑战。
### Innovation
本文提出了一种新颖的预训练方法，即FGP，该方法通过训练一个能捕捉信息流的编码器，而无需依赖特定的模型结构。FGP训练一个编码器以重构我们提出的神经架构信息流的表示形式。实验结果表明，FGP相较于仅使用监督学习训练的相同编码器，能够在精度上提升多达106%，这表明了FGP在提高编码器性能方面的显著优势。
### Conclusion
通过提出FGP预训练方法，研究解决了基于信息流的编码器复杂结构带来的延迟问题，从而在保持高性能的同时，显著加快了神经架构的编码速度。
## 774. `cs.LG` - 训练用于集成的多样化图专家：一项系统性的经验研究 [PDF](https://arxiv.org/pdf/2510.18370), [HTML](https://arxiv.org/abs/2510.18370)
### Authors
Gangda Deng,Yuxin Yang,Ömer Faruk Akgül,Hanqing Zeng,Yinglong Xia,Rajgopal Kannan,Viktor Prasanna
### Background
图神经网络（GNNs）已经成为处理关系数据的关键工具，但在现实世界的图中，单一GNN通常受限于存在的异质性。最近关于Mixture-of-Experts（MoE）框架的进步表明，将具有不同泛化模式的多个、显式多样化的GNN组装起来可以显著提高性能。
### Innovation
该研究进行了首个系统性的经验研究，评估了20种多样化的专家训练策略，包括随机重新初始化、超参数调整、结构变化、方向性建模以及训练数据分区，在14个节点分类基准上构建和分析了超过200种集成变体。该研究还揭示了对于训练高度多样化的专家的具体机制洞察，提供了关于专家训练和设计有效的MoE框架的实际指导。
### Conclusion
该研究表明，通过多样化的技术，可以提升GNN集成的性能，并提供了具体的策略来指导专家的训练和设计MoE框架。研究结果在GitHub上提供了相关代码。
## 775. `cs.LG` - 在感知不完美情况下的学习导航： conformal化分割以实现安全的强化学习 [PDF](https://arxiv.org/pdf/2510.18485), [HTML](https://arxiv.org/abs/2510.18485)
### Authors
Daniel Bethell,Simos Gerasimou,Radu Calinescu,Calum Imrie
### Background
在关键安全环境中可靠的导航需要准确的潜在危险感知以及专业的不确定性处理，以加强下游的安全处理。虽然现有的方法在感知方面有效，但它们假设完美的危险探测能力；而现有的不确定性感知方法缺乏有限样本保证。论文强调了实际应用中这种假设与实际情况之间的差距，并探讨了如何通过引入有限样本的安全保证来改进这一问题。
### Innovation
文章提出了一种名为COPPOL（Conformalized Perception-to-Policy Learning）的方法，它将非参数、有限样本的安全保证整合到语义分割中，生成带有严格缺失检测界限的校准风险图，进而影响下游的强化学习规划。这种方法提高了潜在危险的覆盖率至基线的6倍，几乎完全检测出不安全区域，并在导航过程中减少了危险违规事件（最多减少50%）。该方法在分布转移的情况下保持稳健，确保了安全和效率的双重提升。
### Conclusion
COPPOL增加了危险覆盖范围（最多6倍），实现了不安全区域的近乎完全检测，同时在导航过程中减少了潜在危险（最多50%）。更重要的是，该方法在分布变化的情况下仍保持稳健，这使得它在实际安全环境下提供高效且可靠的功能表现为关键安全环境提供了实质性改进。
## 776. `cs.LG` - 阿里国际电子商务产品搜索竞赛 DILAB 团队技术报告 [PDF](https://arxiv.org/pdf/2510.18499), [HTML](https://arxiv.org/abs/2510.18499)
### Authors
Hyewon Lee,Junghyun Oh,Minkyung Song,Soyoung Park,Seunghoon Han
### Background
本研究提出的是DILAB团队开发的多语言电子商务搜索系统，该系统在最终排行榜上取得了第五名的成绩，总体评分达到0.8819，展示了在多个评估指标上的稳定和高性能表现。为应对多语言查询-商品理解的挑战，我们设计了一个多阶段管道，结合数据优化、轻量级预处理和适应性建模。
### Innovation
本研究的主要创新在于设计了一个多阶段的处理管道，包括数据优化和轻量级预处理，以及在建模阶段探索了多种架构和微调策略，并使用精心校准的验证集进行超参数优化，以平衡查询类别 (QC) 和查询项 (QI) 任务之间的性能。
### Conclusion
所提出框架在不同语言和领域中展示了稳健性和适应性，突显了系统化数据管理和迭代评估对于多语言搜索系统的有效性。source code 已在 this https URL 上提供。
## 777. `cs.LG` - 请关注触发器：构建在蒸馏中存活的后门 [PDF](https://arxiv.org/pdf/2510.18541), [HTML](https://arxiv.org/abs/2510.18541)
### Authors
Giovanni De Muri,Mark Vero,Robin Staab,Martin Vechev
### Background
LLMs通常被下游用户作为教师模型用于知识蒸馏，将其能力压缩进内存高效的模型中。然而，由于这些教师模型可能来自不可信的来源，因此知识蒸馏可能会带来意想不到的安全风险。本文调查了来自被篡改的教师模型的知识蒸馏的安全影响。
### Innovation
作者提出了一种新的后门注入技术T-MTB，使得后门能够在知识蒸馏过程中传输。T-MTB通过精心设计复合触发器，该触发器由在预期蒸馏数据集中经常单独出现的特定标记组成，确保教师模型在被篡改后仍然具有隐蔽性，但当进行知识蒸馏时，这些标记的单独出现提供了后门传输到学生的足够信号。
### Conclusion
利用T-MTB，作者展示了并详细研究了可传输后门在整个蒸馏过程中的安全风险。作者评估了在两种攻击场景（出狱破解和内容调节）下，四种LLM模型家族中的后门传输风险。
## 778. `cs.LG` - RAISE：负责的AI评分和评估的统一框架 [PDF](https://arxiv.org/pdf/2510.18559), [HTML](https://arxiv.org/abs/2510.18559)
### Authors
Loc Phuc Truong Nguyen,Hung Thanh Do
### Background
随着AI系统进入关键领域，评估不仅需要关注预测准确性，还需要包括解释性、公平性、鲁棒性和可持续性。现有的评估方法往往局限于单一维度，无法综合考虑这些重要方面。因此，需要一个统一的框架来全面评估AI模型的责任表现。
### Innovation
本文提出了一个名为RAISE（Responsible AI Scoring and Evaluation）的统一框架，能够量化模型在上述四个方面的性能，并将它们整合为一个整体的责任评分。研究了三种深度学习模型：多层感知机（MLP）、表型ResNet和特征标记变压器，并在金融、医疗和经济学等结构化数据集上评估其性能。指出没有一个单一模型在所有责任标准上都表现优异，强调了多维度评估对于负责任模型选择的必要性。
### Conclusion
研究结果表明，不同模型在解释性、公平性、鲁棒性和可持续性等方面存在权衡。没有任何单一模型能同时在所有责任标准上表现最佳，强调了多维度评估的重要性。本文的实现已经开源，为未来的研究提供了参考。
## 779. `cs.LG` - Partial VOROS: 一种考虑精确度和容量约束的二元分类器成本感知性能度量 [PDF](https://arxiv.org/pdf/2510.18520), [HTML](https://arxiv.org/abs/2510.18520)
### Authors
Christopher Ratigan,Kyle Heuton,Carissa Wang,Lenore Cowen,Michael C. Hughes
### Background
ROC曲线广泛用于评估二元分类性能，但在一些应用如住院患者监控的警报系统中，传统的ROC分析无法捕捉到部署的关键因素，比如强制最低精确度约束以避免虚假警报疲劳或限制预测正例的数量以反映医务人员的容量。常用的曲线下面积度量也无法反映正负误判的不对称成本。本文深入探讨了上述问题，并提出了解决这些问题的方法。
### Innovation
本文提出了一个考虑成本、精确度和容量限制的成本感知性能度量，即Partial VOROS。首先，作者展示了满足给定精确度和容量约束的分类器子集可表示为ROC空间中的可行区域，并建立了该可行区域的几何形状。接着定义了一个与成本单调的性能度量，仅考虑ROC空间中可行的部分，并通过期望的成本参数范围对这一区域进行平均，从而得到ROC曲面的部分体积度量。在MIMIC-IV数据集上预测死亡风险的实验中，表明此成本感知度量优于其他替代方法，在医院警报应用中排序分类器更为有效。
### Conclusion
本文通过引入考虑精确度和容量约束的成本感知度量Partial VOROS，克服了传统ROC曲线的局限性，并且在实验中验证了该度量在医院警报应用中排序分类器的有效性。
## 780. `cs.LG` - HeFS: 使用Pareto优化遗传搜索的辅助增强特征选择 [PDF](https://arxiv.org/pdf/2510.18575), [HTML](https://arxiv.org/abs/2510.18575)
### Authors
Yusi Fan,Tian Wang,Zhiying Yan,Chang Liu,Qiong Zhou,Qi Lu,Zhehao Guo,Ziqi Deng,Wenyu Zhu,Ruochi Zhang,Fengfeng Zhou
### Background
特征选择是一个组合优化问题，属于NP-hard问题。传统的特征选择方法通常使用启发式或贪婪策略，容易过早收敛并可能无法捕捉到那些细微但有价值的信息特征。这一局限性在高维数据集中尤为突出，在高维数据集中，复杂且相互依赖的特征关系普遍存在。
### Innovation
引入了HeFS（Helper-Enhanced Feature Selection）框架，用于细化现有算法产生的特征子集。HeFS通过系统地搜索剩余的特征空间，识别出能补充原始子集并提高分类性能的Helper Set。该方法采用了有偏初始化和比率指导下的变异机制，在遗传算法中与基于Pareto的多目标优化相结合，以同时最大化预测精度和特征互补性。
### Conclusion
在18个基准数据集上的实验结果表明，HeFS能够一致地识别出被忽视但有价值的信息特征，并在胃癌分类、药物毒性预测和计算机科学应用等挑战性领域中实现了优于最先进的方法的性能。相关代码和数据集可在以下链接获取：this https URL
## 781. `cs.LG` - 基于校正的方法将提升树精简为决策树 [PDF](https://arxiv.org/pdf/2510.18615), [HTML](https://arxiv.org/abs/2510.18615)
### Authors
Gilles Audemard,Sylvie Coste-Marquis,Pierre Marquis,Mehdi Sabiri,Nicolas Szczepanski
### Background
本文介绍了一种新的方法，用于将提升树精简为决策树，目标是在预测性能和可解释性之间取得合理的平衡。
### Innovation
我们解释了如何使用被称为'校正'的方法来实现这种精简过程。实验结果显示，这种方法在预测性能和可解释性的权衡上取得了有意义的结果，优于通过重新训练模型实现的精简方法。
### Conclusion
本文提出了一种新的提升树精简方法，利用校正方法实现了在预测性能和可解释性之间的良好平衡，并通过实验验证了这种方法的有效性。
## 782. `cs.LG` - 通过轻量级满足性测试验证图神经网络的鲁棒性 [PDF](https://arxiv.org/pdf/2510.18591), [HTML](https://arxiv.org/abs/2510.18591)
### Authors
Chia-Hsuan Lu,Tony Tan,Michael Benedikt
### Background
图神经网络（GNNs）是图上学习的主要架构。对于任何机器学习模型而言，对抗性攻击检测是一个重要的问题，即攻击者可以通过对输入的小幅扰动改变模型的输出。为了解决对抗鲁棒性问题，即确定是否存在这样的攻击，许多技术最初是为图像分类模型开发的，后来扩展到多种其他机器学习架构中。在图学习领域，攻击模型通常考虑图结构的变化，而不仅仅或不包括输入的数值特征。目前该领域的最好方法是通过约束求解的约简来实现，依赖于强大的求解器，例如混合整数编程求解器。
### Innovation
该研究通过用高效的部分求解器替代强大的求解器来改进结构鲁棒性的现有最佳方法，这些部分求解器在多项式时间内运行但可能是不完整的。该工具RobLight在多种不同的GNN变体和数据集上得到了评估。
### Conclusion
通过RobLight工具，可以改进结构鲁棒性，以轻量级满足性测试替代强大求解器，从而为图神经网络的对抗鲁棒性提供了新的解决途径。
## 783. `cs.LG` - Unrolled-SINDy：从稀疏采样数据中发现非线性偏微分方程的一种稳定显式方法 [PDF](https://arxiv.org/pdf/2510.18611), [HTML](https://arxiv.org/abs/2510.18611)
### Authors
Fayad Ali Banna,Antoine Caradot,Eduardo Brandao,Jean-Philippe Colombier,Rémi Emonet,Marc Sebban
### Background
从观测数据中识别调节物理动力学的微分方程是机器学习中的一个关键挑战。尽管基于SINDy的方法在该领域表现出巨大潜力，但它们仍然无法解决一类实际问题，即数据在时间上的稀疏采样问题。
### Innovation
本文提出了Unrolled-SINDy方法，该方法通过不传播数值时间步长与可用数据采样率之间的相关性，改进了SINDy优化问题中由于局部截断误差导致的方程参数的恢复。该方法可以通过迭代闭式方法或者梯度下降方案实现。实验表明该方法在多种情况下具有灵活性。
### Conclusion
在传统SINDy和最新的抗噪iNeuralSINDy的基础上，我们的卷积方案能够解决非稀疏采样数据方法不可处理的问题。
## 784. `cs.LG` - 知识图谱中公平的图神经网络基准研究 [PDF](https://arxiv.org/pdf/2510.18473), [HTML](https://arxiv.org/abs/2510.18473)
### Authors
Yuya Sasaki
### Background
图神经网络（GNNs）能够处理结构化数据并从中进行学习，但常常会产生带有偏见的预测结果，尤其是关于敏感属性。已有研究致力于通过公平的GNNs减轻这种偏见，但这些研究主要集中在其他类型的数据集上，而对于知识图谱这一应用场景却鲜有涉及。知识图谱作为一种重要的数据结构，广泛应用于推荐系统等场景，因此本文开展了针对知识图谱的公平的GNNs基准研究，生成了三个显著比现有数据集大的知识图谱，即YAGO、DBpedia和Wikidata。通过对比不同的GNN底层框架和提前停止条件，进行了在处理和预处理方法方面的评估，探讨了公平性与预测准确性之间的权衡关系及各类方法的影响程度。
### Innovation
引入了一项关于知识图谱的公平的GNNs基准研究，生成了比现有数据集大的知识图谱作为实验基准；同时，在多个GNN底层框架下，对比了处理和预处理方法，发现了公平性与预测准确性之间的权衡关系，强调了GNN底层框架和提前停止条件的重要性；研究发现，预处理方法通常能提高公平性指标，而处理方法通常能提升预测准确性，揭示了不同图的数据特性导致的差异性趋势。
### Conclusion
知识图谱相较于其他图结构数据显示出不同的趋势与权衡关系，预测准确性和公平性之间有更为明显的权衡。GNN底层架构和提前停止条件显著影响模型性能，预处理方法优于处理方法在提高公平性方面有明显效果。
## 785. `cs.LG` - 在下一符号预测设置中学习正规语言的复杂性 [PDF](https://arxiv.org/pdf/2510.18634), [HTML](https://arxiv.org/abs/2510.18634)
### Authors
Satwik Bhattamishra,Phil Blunsom,Varun Kanade
### Background
该研究关注语言在下一符号预测（NSP）设置中的可学习性，其中学习者仅从语言中接收正例，并且对于每个前缀，接收该前缀是否属于语言以及哪些下一符号可以导致接受字符串的信息。该设置在先前的研究中被用于分析神经序列模型，并观察到在NSP设置中高效算法可用于学习语言模型的支持集（截断）。研究者进一步将该设置形式化，使其适用于PAC学习分析。尽管该设置提供了一种比传统分类设置更丰富的标签集，但研究表明，学习概念类别（如DFA和布尔公式）仍然是计算复杂的问题。证明是通过一种构造，使其几乎所有额外标签变得无信息，从而将传统的学习问题归约为NSP标签的学习问题类别。在密码假设下，该归约表明在NSP设置中学习DFA是计算复杂的问题。
### Innovation
研究者将NSP设置形式化，使其适用于PAC学习分析，并展示了学习某些语言模型类别（如DFA）的复杂性。研究还提供了一种构造方法，证明几乎所有额外标签都是无信息的，从而将传统的学习问题归约为NSP标签的学习问题。在密码假设下，这样的归约表明在NSP设置中学习DFA是计算复杂的问题。
### Conclusion
在下一符号预测（NSP）设置中学习正规语言的问题是计算复杂的问题，即使在某些特定的语言模型类别（如DFA）也是如此。尽管该设置提供丰富的标签集，但仍不能有效降低学习的计算复杂性。
## 786. `cs.LG` - 面向心血管传感器贴片的端到端多模态Tiny-CNN原型设计 [PDF](https://arxiv.org/pdf/2510.18668), [HTML](https://arxiv.org/abs/2510.18668)
### Authors
Mustafa Fuad Rifet Ibrahim,Tunc Alkanat,Maurice Meijer,Felix Manthey,Alexander Schlaefer,Peer Stelldinger
### Background
大多数心血管疾病如果能早期检测出迹象和风险因素是可预防的。穿戴式传感器设备如传感器贴片可以监测这些迹象，同时保持患者的自由和舒适。然而，传感器数据的分析需要是稳健可靠的、高效的和高度准确的。深度学习方法可以自动解释数据，减轻临床医生的工作负担。本文探讨了在资源受限的医疗边缘设备上应用深度学习模型进行同步心电图（ECG）和心脏音图（PCG）记录分类的可行性。
### Innovation
提出了一种卷积神经网络模型，在数据早期融合的基础上解决二分类问题，相较于现有技术，该模型在资源受限的医疗边缘设备上能够降低三倍数量级的内存占用和计算成本，同时保持竞争性的准确率。并通过微控制器和实验传感器设备的能耗分析，证明了端设备推理在能源效率上优于连续数据流，从而验证了该模型在医疗边缘设备上的适用性。
### Conclusion
该模型在心脏ECG和PCG记录分类上的应用，为心血管监控提供了一种高效、准确的解决方案，特别适合资源受限的医疗边缘设备。
## 787. `cs.LG` - 推理语言模型推理服务揭秘：一项实证研究 [PDF](https://arxiv.org/pdf/2510.18672), [HTML](https://arxiv.org/abs/2510.18672)
### Authors
Qi Li,Junpan Wu,Xiang Liu,Yuxin Wang,Zeyu Li,Zhenheng Tang,Yuhan Chen,Shaohuai Shi,Xiaowen Chu
### Background
尽管推理大语言模型（RLLM）在解决复杂推理任务如数学、编程方面表现出色，其在实际应用场景中的服务性能和行为尚未得到充分研究。这种欠缺可能影响RLLM的部署和使用。因此，本文通过实证研究，全面探讨了RLLM服务性能，并发现RLLM与其他传统大语言模型存在多项不同之处，如显著的内存使用量和波动、延迟请求、适应性运行时间和领域偏好。此外，研究还探讨了现有推理优化技术对RLLM的有效性，揭示了一些优化方法在提升RLLM推理服务系统效率方面的成效，同时也发现了某些方法可能导致RLLM准确率或服务性能下降。最后，研究在模拟真实负载的伽玛分布下进行了评估，证实了关于RLLM推理服务的主要发现与现实世界负载结果一致。
### Innovation
本文通过对RLLM服务进行全面研究，揭示了多项与传统大语言模型不同的服务行为，并发现了一些有效的优化方法，如模型量化和推测性解码，同时指出了可能降低准确率或服务性能的方法，如前缀缓存和键值缓存量化。此外，研究在模拟真实负载的环境下进行了评估，确保了发现的有效性。
### Conclusion
本研究为学术界和行业提供了一系列关于RLLM推理服务的见解，旨在促进RLLM推理服务的进一步发展。
## 788. `cs.LG` - 基于物理信息的学习在精细尺度上估计干旱应力以实现准确的产量预测 [PDF](https://arxiv.org/pdf/2510.18648), [HTML](https://arxiv.org/abs/2510.18648)
### Authors
Miro Miranda,Marcela Charfuelan,Matias Valdenegro Toro,Andreas Dengel
### Background
水是农业生产力的关键。评估水资源短缺和产量潜力降低是确保农业生产力和粮食安全的关键因素。现有的模型如作物模拟模型与物理过程契合度高但预测效果不佳；而机器学习模型虽然强大且可扩展，但通常作为黑箱运作并缺乏对作物生长物理原理的遵从性。为解决这一难题，本研究将两者的优点结合起来，通过耦合时间水短缺和预测作物干旱应力及对水资源短缺的敏感性，以产生细尺度分辨率的作物产量预测。通过这种方法，在模型中引入物理一致性，提出了一种新的基于物理信息的损失函数。利用多光谱卫星图像、气象数据和细尺度产量数据进行建模，并通过深度集成方法来考虑模型中的不确定性。
### Innovation
本研究提出了一种结合植物生长物理解释和机器学习方法的新颖方法。具体来说，它提供了一种基于物理信息的损失函数来确保模型的物理一致性，并利用深度集成方法提高模型的鲁棒性。通过这种方法，研究方法在作物产量预测中超越了当前领先模型（如LSTM和Transformer），且具有高可解释性。这种方法为行业、政策制定者和农民提供了在气候变化条件下构建更具弹性的农业决策支持手段。
### Conclusion
本研究通过引入物理信息的方法，显著提高了作物产量预测的准确性。研究方法在作物产量预测中的确定系数$R^2$达到了0.82，不仅提供了准确的预测结果，还提高了模型的可解释性，为农业管理在气候变化背景下的决策提供了有力支持。
## 789. `cs.LG` - 在小组对话中学习时间变化的轮流发言行为 [PDF](https://arxiv.org/pdf/2510.18649), [HTML](https://arxiv.org/abs/2510.18649)
### Authors
Madeline Navarro,Lisa O'Bryan,Santiago Segarra
### Background
许多现有的对话动力模型无法提供适用于多个群体的一般化见解。以往的研究往往试图通过通用公式来表征说话行为，但这可能并不适用于所有群体。这项研究提出了一种基于个体特征和过去的发言行为预测小组对话中轮流发言模式的灵活概率模型。以往的对话模型通常难以提供跨越不同群体的见解，而该研究旨在开发一种能够基于个体特征（如性格特质）和以往发言行为预测任意人群体中发言轮次的新模型。已有模型可能并未充分考虑个体最后一次发言的时间对说话倾向的影响，这正是该研究要解决的问题之一。研究者应用该模型对合成和实际对话数据进行了验证，以证明其方法的有效性并刻画真实群体互动。这表明以往的行为模型可能并不总是现实的，因此需要一种数据驱动且理论扎实的方法来提高模型的现实性和适用性。
### Innovation
该研究提出了一种依赖于个体特征（如性格特质）和先前发言行为的新颖概率模型，用于预测小组对话中的轮流发言模式。更重要的是，该方法能够学习个体上次发言的时间如何影响他们的发言倾向。现有模型未能对其进行评估和建模，这是该方法的一大创新之处。通过将该模型应用于合成与真实世界的数据，可以验证此模型的有效性，及其在刻画真实群体互动方面的能力。
### Conclusion
先前的对话模型可能并无法总是很好地反映现实情况，因此需要一种数据驱动且理论支持的方法来改进模型的现实性和适用性。基于个体特性和先前行为习惯的方法能够提供更适应和精确的预测。这为未来的工作提供了一种新的洞见，即更好地理解团体互动行为。
## 790. `cs.LG` - 基于多教师蒸馏学习任务无关表示 [PDF](https://arxiv.org/pdf/2510.18680), [HTML](https://arxiv.org/abs/2510.18680)
### Authors
Philippe Formont,Maxime Darrin,Banafsheh Karimian,Jackie CK Cheung,Eric Granger,Ismail Ben Ayed,Mohammadhadi Shateri,Pablo Piantanida
### Background
将复杂输入转化为可处理的表示是各个领域的一项关键步骤。各种嵌入模型因其架构、损失函数、输入模态和数据集的不同而各异，各自捕获输入的特定方面。多教师蒸馏利用这种多样性来丰富表示，但通常仍针对特定任务进行定制。
### Innovation
本文提出了一种基于“多数投票”目标函数的无任务框架。该函数通过学生和教师嵌入间的互信息进行限制，产生一个无任务的蒸馏损失，该损失可以消除对特定任务标签或先验知识的依赖。实验表明，该方法有效利用了教师多样性，使下游任务如分类、聚类或回归的性能得到提升。此外，作者还训练并发布了最先进的嵌入模型，进一步提升了各种模态的下游性能。
### Conclusion
本文方法通过无任务的多教师蒸馏学习，有效利用了教师多样性，使得各种下游任务的性能得到提高。同时引入了无任务的蒸馏损失，该损失无需依赖特定任务的标签或先验知识。
## 791. `cs.LG` - 带有不完美转移预测的强化学习：贝尔曼-詹森方法 [PDF](https://arxiv.org/pdf/2510.18687), [HTML](https://arxiv.org/abs/2510.18687)
### Authors
Chenbei Lu,Zaiwei Chen,Tongxin Li,Chenye Wu,Adam Wierman
### Background
传统的强化学习（RL）假设智能体基于马尔可夫决策过程（MDPs）进行决策，且只考虑一步转移模型。在许多实际应用中，例如能源管理和股票投资，智能体可以访问未来状态的多步预测，这为决策提供了优势。但多步预测本质上是高维度的，直接将这些预测嵌入MDP会导致状态空间指数级膨胀和维度灾难。此外，现有的RL理论主要用于分析一步转移核，难以处理具有误差或部分动作覆盖的多步预测。
### Innovation
本文提出三项关键创新：首先，提出贝叶斯价值函数来描述可追踪的预测感知最优策略；其次，开发了贝叶斯价值函数上的新颖贝尔曼-詹森差距分析，以表征不完美的预测价值；第三，引入BOLA（贝叶斯离线学习与在线适应）算法，这是一种基于模型的两阶段RL算法，将离线的贝叶斯价值学习与实时预测的轻量级在线适应分开。证明了即使在不完美的预测下，BOLA也能保持样本效率。
### Conclusion
我们在合成MDP和实际风能存储控制问题上验证了理论和算法。BOLA算法能够在不完全的预测下保持样本效率，展示了算法的有效性。
## 792. `cs.LG` - Transformer架构在学习马尔可夫动态函数中的最优化与NP难性 [PDF](https://arxiv.org/pdf/2510.18638), [HTML](https://arxiv.org/abs/2510.18638)
### Authors
Yanna Ding,Songtao Lu,Yingdong Lu,Tomasz Nowicki,Jianxi Gao
### Background
基于给定提示下的输入-输出对，Transformer架构能够通过上下文学习（ICL）来解决未见过的任务。现有的关于ICL的理论研究主要集中在线性回归任务上，通常假设输入是独立同分布的。本文旨在探索transformer在建模由动力学驱动的函数时在ICL中的表现，特别是通过结构化的ICL设置来研究马尔可夫函数学习。通过剖析损失景观，揭示潜在的优化行为
### Innovation
本文的创新之处在于：1) 提供了一层线性自我关注模型（LSA）全局极小值（在扩展参数空间中的）的封闭形式表达式；2) 证明了一般情况下恢复实现最优解的transformer参数是NP难的，揭示了一层LSA在表示结构化的动态函数方面的基本局限性；3) 新颖地解释了多层次LSA作为预条件梯度下降来优化多个目标（不仅仅是平方损失）的行为.
### Conclusion
本文通过理论分析和数值验证，阐明了transformer在学习马尔可夫动态函数中的最优化行为和NP难性，并探讨了多层次LSA在多目标优化中的作用。
## 793. `cs.LG` - 通过学习优化器提升分数梯度下降 [PDF](https://arxiv.org/pdf/2510.18783), [HTML](https://arxiv.org/abs/2510.18783)
### Authors
Jan Sobotka,Petr Šimánek,Pavel Kordík
### Background
分数梯度下降（FGD）通过将分数微积分引入机器学习，提供了一种加速优化的新颖且有前途的方法。尽管FGD在各种优化任务中显示出了令人鼓舞的初步成果，但其收敛行为和超参数选择方面仍面临重大挑战。FGD的超参数影响尚不完全清楚，特别是在神经网络训练等非凸设置中，调整这些超参数尤其困难。
### Innovation
本文提出了一种名为Learning to Optimize Caputo Fractional Gradient Descent（L2O-CFGD）的新方法，该方法通过元学习动态调整Caputo分数梯度下降（CFGD）的超参数。L2O-CFGD的方法所学到的时间表比通过广泛搜索找到的静态超参数的CFGD表现更好，并且在某些任务中可达到与完全黑盒元学习优化器相当的性能。
### Conclusion
L2O-CFGD可以作为研究人员识别高性能超参数的强大工具，并对如何利用分数微分的历史依赖性在优化中的作用提供了见解。
## 794. `cs.LG` - 提升用于下游医疗因果推断的合成数据生成与评估 [PDF](https://arxiv.org/pdf/2510.18768), [HTML](https://arxiv.org/abs/2510.18768)
### Authors
Harry Amad,Zhaozhi Qian,Dennis Frauen,Julianna Piskorz,Stefan Feuerriegel,Mihaela van der Schaar
### Background
因果推断对于医疗干预的开发和评估至关重要，但实际医疗数据集由于监管障碍难以获取。因此，合成数据成为有价值的资产，能够促进医疗分析以及新推断方法的发展。现有的生成模型可以生成与实际数据分布相似的合成数据，但现有方法并未考虑下游因果推断任务，特别是针对治疗的特定任务所带来的独特挑战。为了最大化下游用途，这类合成数据应满足以下三个条件：保留（i）协变量分布、（ii）治疗分配机制和（iii）结果生成机制。基于这些要求，我们提出了评估合成数据的度量标准，并提出了STEAM方法，这是一种针对医疗治疗效果分析生成合成数据的新方法，该方法模仿含有治疗的实际数据生成过程并根据我们的要求进行了优化。我们通过实验证明，在评分指标上，STEAM达到了最先进的性能，特别是随着真实数据生成过程的复杂性增加时。
### Innovation
本文提出了一组合成数据中治疗应满足的必要条件，以及对应的评估指标。进一步提出了STEAM方法，这是一种专门针对医疗治疗效果分析生成合成数据的新方法，能够更好地保留实际数据的关键特性并优化因果推断效果。这种方法在复杂真实数据生成过程上表现最佳。
### Conclusion
STEAM方法在生成合成数据方面的表现优于现有方法，特别是在真实数据生成过程复杂的场景下。这种合成数据不仅能够更好地模拟实际数据，还能够显著提高医疗相关因果推断任务的效果。
## 795. `cs.LG` - 基于多选项的偏好强化学习：排名反馈的优点 [PDF](https://arxiv.org/pdf/2510.18713), [HTML](https://arxiv.org/abs/2510.18713)
### Authors
Joongkyu Lee,Seouh-won Yi,Min-hwan Oh
### Background
尽管越来越多的理论研究受到偏好强化学习(PbRL)的近期实证成功的启发，尤其是其在对齐大型语言模型方面的成功，现有的大多数研究仅集中在对两两比较的关注上。少数前沿工作考察了使用多个比较和排名反馈，但这些研究的性能保证在反馈长度增加时并未提升，甚至有时还会恶化，尽管可以获取到更为丰富的信息。因此，有必要提出一种新的算法来改善样本效率问题。
### Innovation
本文引入了Plackett-Luce(PL)模型来处理行动子集的排名反馈，提出了M-AUPO算法，该算法通过最大化每个子集内的平均不确定性来选择多个行动。此外，我们证明了M-AUPO算法的次优性差距为 $tilde{text{O}}bigg(frac{d}{T} times biggtext{sum}_{t=1}^{T} frac{1}{|S_t|}bigg)^{0.5}bigg)$，其中$T$是总轮次，$d$是特征维度，$|S_t|$是第$t$轮的子集大小。这一结果表明，较大的子集直接导致性能提升，并且该结果避免了对未知参数范数的指数依赖性，这是大多数先前工作的根本限制。此外，我们还建立了近匹配的下界 $text{Ω}bigg(frac{d}{K times text{sqrt}(T)}bigg)$，其中$K$是最大子集大小，这是目前已知的首个在PbRL中明确表现出随子集大小增加而改进的样本效率的经验结果。
### Conclusion
本文提出了一个新的算法M-AUPO，并证明了该算法在使用排名反馈时能够通过选择多选项来显著提高样本效率，这为偏好强化学习领域的研究开辟了新的可能性。
## 796. `cs.LG` - 基于连续最优传输的Stick-Breaking嵌入主题模型及其在文档流在线分析中的应用 [PDF](https://arxiv.org/pdf/2510.18786), [HTML](https://arxiv.org/abs/2510.18786)
### Authors
Federica Granese,Serena Villata,Charles Bouveyron
### Background
在线主题模型是一种无监督算法，用于识别随时间不断进化的数据流中的潜在主题。尽管这些方法与现实世界的场景自然匹配，但与离线版本相比，它们在社区中受到了较少的关注，主要是由于特定的额外挑战。
### Innovation
SB-SETM 是一种创新的模型，它扩展了嵌入主题模型（ETM），用于处理由连续部分文档批次形成的模型。该模型通过利用截尾的stick-breaking构建方法，使主题-文档分布自动从数据中推断出每个时间步长的活动主题数。此外，SB-SETM 引入了一种基于连续形式的最优传输的合并策略，该策略针对潜在主题空间的高度维度进行了调整。
### Conclusion
数值实验展示了 SB-SETM 在模拟场景中优于基线方法，并在新闻文章的实世界语料库上进行了广泛测试，该语料库涵盖了2022-2023年俄罗斯-乌克兰战争期间的新闻文章。
## 797. `cs.LG` - 当LRP在Transformer中偏离Leave-One-Out时 [PDF](https://arxiv.org/pdf/2510.18810), [HTML](https://arxiv.org/abs/2510.18810)
### Authors
Weiqiu You,Siqi Zeng,Yao-Hung Hubert Tsai,Makoto Yamada,Han Zhao
### Background
Leave-One-Out (LOO) 提供了一种直观的特征重要性测量方法，但计算上较为密集。尽管Layer-Wise Relevance Propagation (LRP) 提供了一种潜在的高效替代方案，但在现代Transformer中其公理正确性仍很大程度上未被研究。因此，论文首先证明了AttnLRP中使用的双线性传播规则违反了实现不变性公理，并在线性注意力层中通过分析和实验证明了这一点。其次，重新考察了CP-LRP作为一种诊断基线，并发现跳过通过softmax层的关联传播，仅在值矩阵中反向传播关联性可以显著提高与Leave-One-Out的一致性，特别是在Transformer的中间到后期层。
### Innovation
论文证明了AttnLRP中使用的双线性传播规则违反了实现不变性公理，并通过CP-LRP重新考察提出了跳过通过softmax层的关联传播，仅在值矩阵中反向传播关联性的新方法。
### Conclusion
研究结果表明，双线性因子敏感性和softmax传播错误可能共同削弱了LRP在Transformer中近似LOO的能力。
## 798. `cs.LG` - CAGE: 带有曲率意识的梯度估计以实现精确的量化感知训练 [PDF](https://arxiv.org/pdf/2510.18784), [HTML](https://arxiv.org/abs/2510.18784)
### Authors
Soroush Tabesh,Mher Safaryan,Dan Alistarh
### Background
尽管在低比特量化感知训练（QAT）方面已经有大量的研究工作，但现有的技术与传统的训练方法之间仍然存在显著的精度差距。当前的方法通过采用直通梯度估计器（STE）等手段进行训练，但这些方法难以解决因量化过程带来的精度损失问题。因此，需要一种新的QAT方法来进一步提高精度。
### Innovation
作者提出了一种新的QAT方法——CAGE（Curvature-Aware Gradient Estimation），它结合了曲率意识的修正项来弥补量化带来的精度损失。CAGE从量化优化的多目标视角出发，平衡了损失最小化与量化约束的遵守，引入了依靠局部曲率信息的原理性修正项。此外，作者还提出了量化优化的帕累托最优解概念，并证明了CAGE在光滑非凸setting下具有强大的收敛性保证。在实现方面，该方法是优化器无关的，但提供了一种高效结合了Adam统计的实现方式。CAGE在预训练较大参数量（800M-参数）的类似Llama模型时，显著恢复了量化引起的精度损失，优于现有的离群值处理方法。
### Conclusion
CAGE能够通过曲率意识的梯度修正来弥补量化产生的精度损失，进一步提高量化模型的性能，缩小与传统训练方法的精度差距。
## 799. `cs.LG` - 连续时间中的生物可行性学习 [PDF](https://arxiv.org/pdf/2510.18808), [HTML](https://arxiv.org/abs/2510.18808)
### Authors
Marc Gong Bacvanski,Liu Ziyin,Tomaso Poggio
### Background
生物体中的学习过程是连续进行的，而大多数算法模型则依赖于离散的更新以及将推理与学习分离开来的两个阶段。本文研究了一种连续时间下的神经网络模型，该模型统一了多种生物可实现的学习算法，且不需要将学习与推理分离，从而在模拟中证明了这种连续时间的网络可以在生物时间尺度上稳定学习，即使在时间不匹配和整合噪声条件下也一样。
### Innovation
提出了一个连续时间下的神经模型，该模型可以统一多种生物实现的学习算法，且不需要将推理与学习分开。文中展示了如何自然地获得包括随机梯度下降（SGD）、反馈对齐（FA）、直接反馈对齐（DFA）和Kolen-Pollack（KP）在内的规则作为动态的极限情况。模型的创新还包括对学习依赖的时间重叠进行了分析，以及通过分析和模拟证明这种重叠作用影响学习强度。
### Conclusion
学习过程需要输入和误差信号在时间上相符才能正确更新，当输入保持不变时，如果输入与误差信号之间的时间延迟接近刺激的持续时间，则学习强度将线性下降，这解释了在不同网络深度中观察到的稳健性与失败的现象。关键点在于，要在刺激持续时间的基础上，使突触可塑性的时间尺度超出一个到两个数量级，以确保学习的稳健性。典型的皮质刺激（几十毫秒）要求功能可塑性窗口在几秒范围内，这是捕捉生物电路中误差驱动学习所需秒级资格痕迹的可测试预测。
## 800. `cs.LG` - 机器学习与神经科学中的统一优化视角：从梯度下降到神经适应 [PDF](https://arxiv.org/pdf/2510.18812), [HTML](https://arxiv.org/abs/2510.18812)
### Authors
Jesús García Fernández,Nasir Ahmad,Marcel van Gerven
### Background
迭代优化在现代人工智能中占据核心地位，并为理解和构建自适应系统提供了关键框架。尽管基于梯度的方法通过高效的反向传播（BP）算法主导了机器学习，但其在高维度设置下的计算需求限制了可扩展性。相比之下，无导数或零阶（ZO）优化利用函数评估和随机性实现计算更轻的方法，尽管一般而言样本效率较低，但现代ZO方法通过近似梯度实现了与BP算法竞争的性能。ZO方法在神经科学中也尤其重要，其核心探索（探查）和反馈引导适应（强化）机制与生物学习的关键机制相呼应。
### Innovation
该研究统一了机器学习和神经科学研究中的优化视角，从传统的梯度下降方法到神经适应。它特别专注于零阶优化方法，尽管样本效率较低，但能有效地近似梯度并实现与传统方法竞争的性能。通过将生物学习纳入优化框架，它利用了大脑的固有噪声作为一种计算资源，并为设计快速和节能的AI系统提供了新思路。
### Conclusion
该研究不仅深化了我们对自然智能的理解，还为神经形态硬件设计提供了广泛的应用前景，帮助利用基本硬件噪声设计高效能的AI系统。
## 801. `cs.LG` - OmniCast：跨时间尺度的掩蔽隐式扩散模型用于天气预报 [PDF](https://arxiv.org/pdf/2510.18707), [HTML](https://arxiv.org/abs/2510.18707)
### Authors
Tung Nguyen,Tuan Pham,Troy Arcomano,Veerabhadra Kotamarthi,Ian Foster,Sandeep Madireddy,Aditya Grover
### Background
准确的跨时间尺度天气预报对于评估和减轻气候变化影响至关重要。尽管基于深度学习的数据驱动方法在中尺度取得显著成功，但在次季节到季节（S2S）时间尺度上因自回归方法中的误差累积而表现不佳。
### Innovation
提出了一种名为OmniCast的可扩展且技能高超的概率模型，将跨时间尺度的天气预报统一起来。OmniCast由两个组件组成：一个VAE模型将原始天气数据编码到连续的低维潜在空间中，以及一个基于扩散的变换器模型，给定初始预处理令牌生成未来的潜在令牌序列。通过块式对未来令牌的掩蔽和训练变换器预测其分布，该模型在训练时减轻了自回归方法中累积的误差。在推理时，变换器通过迭代地对未来令牌子集进行解掩蔽来生成未来完整令牌序列。潜在空间的低维性使得长期未来潜在状态的序列建模成为可能，从而使变换器能够学习超越初始条件的天气动力学。与现有的领先方法相比，OmniCast在中尺度性能上表现相当，计算速度提高10到20倍，并在次季节到季节时间尺度上实现了最先进的性能，涵盖了准确性、物理基础和概率指标。此外，证明了OmniCast可以生成稳定长达100年的卷积序列。
### Conclusion
OmniCast在激发长期序列建模、控制累积误差、提高计算效率和增强性能方面取得了显著进步，为次季节到季节尺度的天气预报提供了新的解决方案。
## 802. `cs.LG` - 在线SFT在LLM推理中的应用：无需奖励的自我调优的惊人效果 [PDF](https://arxiv.org/pdf/2510.18814), [HTML](https://arxiv.org/abs/2510.18814)
### Authors
Mengqi Li,Lei Zhao,Anthony Man-Cho So,Ruoyu Sun,Xiao Li
### Background
本文介绍了一种简单且自助式的在线监督微调（OSFT）范式，用于大型语言模型（LLM）的推理。OSFT允许模型生成自己的响应，并立即在此自生成数据上进行微调。这种范式对LLM推理具有高效性，因为它不需要任何奖励机制，只需默认进行一次部署。
### Innovation
OSFT是一种高效的训练策略，因为它是无需奖励的，仅默认使用一次部署。实验结果表明，OSFT在挑战性的数学推理任务上的下游性能与具可验证奖励的强化学习方法（如GRPO）相当。进一步的实验证明了OSFT的效率和鲁棒性。OSFT的主要机制在于，它促使模型利用其从预训练中学到的现有偏好（潜在知识），从而提高推理能力。代码已开源。
### Conclusion
我们相信，OSFT为更复杂的基于奖励的训练范式提供了高效且有前景的替代方案。实验结果证明了OSFT在数学推理任务上的有效性，并且其代码已开放让公众使用。
## 803. `cs.LG` - 搜索自我游戏：在无监督的情况下推动代理能力的前沿 [PDF](https://arxiv.org/pdf/2510.18821), [HTML](https://arxiv.org/abs/2510.18821)
### Authors
Hongliang Lu,Yuhang Wen,Pengyu Cheng,Ruijin Ding,Haotian Xu,Jiaqi Guo,Chutian Wang,Haonan Chen,Xiaoxi Jiang,Guanjun Jiang
### Background
强化学习借助可验证奖励（RLVR）已发展成为训练LLM代理的主要技术。然而，RLVR非常依赖精心设计的任务查询及其对应的正确答案来提供准确的奖励，这需要大量的人力工作，并阻碍了RL的扩展，特别是在代理情境下。虽然一些最近的研究探索了任务合成方法，但生成的任务难度难以控制，不能有效提供强化学习训练的优势。
### Innovation
该研究探索了自我游戏训练以提高深度搜索代理的自我能力，其中学习的LLM同时充当任务发起者和问题解决者。提出者的目标是生成具有明确正确答案和不断增加任务难度的深入搜索查询。问题解决者尝试处理生成的搜索查询并输出正确的答案预测。通过收集提出者轨迹中的所有搜索结果作为外部知识，并采用检索增强生成(RAG)方法来验证提出的问题是否可以在提供所有必要的搜索文档情况下被正确回答。通过这种搜索自我游戏（SSP）机制，提出者和解题者通过竞争和合作共同进化其代理能力。
### Conclusion
实验结果显示，SSP能够显著提升搜索代理在各种基准上的性能，在从零开始和连续的RL训练设置下均无监督执行。
## 804. `cs.LG` - 无演员连续控制通过结构可最大化Q函数 [PDF](https://arxiv.org/pdf/2510.18828), [HTML](https://arxiv.org/abs/2510.18828)
### Authors
Yigit Korkmaz,Urvi Bhuwania,Ayush Jain,Erdem Bıyık
### Background
基于值的算法是离策略强化学习的基石，因其简洁性和训练稳定性而被广泛应用。然而，传统的基于值的方法主要用于离散的动作空间，因为它们依赖于对单个状态-动作对的Q值进行估计。在连续动作空间中，评估整个动作空间的Q值变得计算上不可行。为了解决这个问题，通常使用演员-评论家方法，其中评论家在离策略数据上训练以估计Q值，而演员训练以最大化评论家的输出。尽管这些方法很受欢迎，但它们在训练过程中经常表现出不稳定性。
### Innovation
本文提出了一种无演员的基于值的连续控制框架，重新审视Q函数的结构最大化，并引入了一系列关键的架构和算法选择，以实现高效且稳定的训练。特别是在具有约束动作空间的环境中，我们的方法在结构最大化方面优于传统基于梯度最大化的方法，证明了与最新基准相当的性能和样本效率，而无需训练独立的演员。
### Conclusion
我们评估了提议的无演员Q学习方法在一系列标准仿真任务上的表现，展示了与最先进的基线相当的性能和样本效率，而无需学习独立的演员。特别是在具有约束动作空间的环境中，我们的方法在结构最大化方面优于传统基于梯度的方法。我们的代码已经公开，链接是this https URL.
## 805. `cs.LG` - 单脉冲网格无关2D-DOA估计在UCA中的联合优化方法 [PDF](https://arxiv.org/pdf/2510.17818), [HTML](https://arxiv.org/abs/2510.17818)
### Authors
Salar Nouri
### Background
针对均匀圆阵列(UCA)从单个数据快照估计无网格的二维（2D）到达方向（DOA），传统无网格方法常因计算成本高昂或缺乏鲁棒性而失效。
### Innovation
提出了一种新颖的框架，通过联合估计流形变换矩阵和源方位-仰角对，在单一统一优化问题中解决了这一限制。该方法利用不精确增广拉格朗日方法（iALM）有效求解问题，避免了半定规划的需求。我们的方法通过统一数据保真度和变换鲁棒性的目标，特别适用于单快照情况下。
### Conclusion
仿真结果表明，所提出的iALM框架提供了稳健且高分辨率的无网格2D-DOA估计，确立了其在挑战性阵列信号处理应用程序中的有效性。
## 806. `cs.LG` - 混合枚举框架在急性COVID-19后心力衰竭中的最优反事实生成 [PDF](https://arxiv.org/pdf/2510.18841), [HTML](https://arxiv.org/abs/2510.18841)
### Authors
Jingya Cheng,Alaleh Azhir,Jiazi Tian,Hossein Estiri
### Background
反事实推理提供了一种关于在不同干预措施下可能结果的数学框架，连接了因果推理和预测模型。本文提出了一个针对个体风险评估和干预分析的反事实推理框架，通过临床应用来评估急性冠状病毒病后综合征（PASC）在既有心脏衰竭患者中的风险。该研究利用大型健康系统队列中的随访诊断、实验室和药物数据，结合正则化预测建模和反事实搜索方法，识别出与PASC相关的HF住院的可行动路径。框架结合了精确枚举和基于优化的方法，包括最近实例反事实解释（NICE）和多目标反事实（MOC）算法等，来高效探索高维度的干预空间。
### Innovation
本文提出了一个结合精确枚举与优化方法的混合框架，用于急性COVID-19后心力衰竭的最优反事实生成。该框架通过正则化预测建模与反事实搜索相结合的方式，有效探索高维度干预空间，并成功应用于证实感染SARS-CoV-2且有心脏衰竭史的2700多名个体，取得了较强的鉴别性能（AUROC: 0.88，95% CI: 0.84-0.91）并在生成可解释的、患者特异性反事实方面表现出色，量化了如何通过调整合并症或治疗因素改变预测结果。
### Conclusion
该研究展示了反事实推理如何被形式化为预测函数上的优化问题，提出了一个严格、可解释且高效的方法，用于复杂的生物医学系统中的个性化推理，强调了该方法在精准医疗中的应用潜力。
## 807. `cs.LG` - 保留与实践：政策数据在减轻遗忘中的作用 [PDF](https://arxiv.org/pdf/2510.18874), [HTML](https://arxiv.org/abs/2510.18874)
### Authors
Howard Chen,Noam Razin,Karthik Narasimhan,Danqi Chen
### Background
在通过后训练方法调整语言模型至新任务时，存在一个风险，即现有能力可能会退化，这种情况被称为灾难性遗忘。本文通过系统性地比较两类广泛应用的后训练方法——有监督微调（SFT）和强化学习（RL）——的方式来研究这种现象的遗忘模式。实验结果表明，RL相比SFT在减少遗忘的同时，在目标任务上达到相当甚至更高的性能。这引发了一个问题，即为何会出现这种差异。
### Innovation
研究发现，RL 的模式探索特性，源于它使用按策略数据，使在学习目标任务时可以保持先验知识的完整。这解释了为何RL 在减少遗忘方面优于SFT。此外，研究通过实证表明，使用按策略数据是RL 对遗忘有更强鲁棒性的一个关键原因，而与其他算法选择如KL正则化或优势估计无关。这些发现为减轻遗忘提供了潜在的实践建议，即利用近似按策略数据，其获得效率远高于完全按策略数据。
### Conclusion
本文通过对比分析SFT和RL的方法，揭示了RL在减少遗忘方面的优势，并通过简化模型进一步阐述了其背后的原因。最终结论是，近似按策略数据可用于减轻遗忘，具有更高的效率。
## 808. `cs.LG` - 探索心电图电信号中病变复杂性变化以提高分类效果 [PDF](https://arxiv.org/pdf/2510.17810), [HTML](https://arxiv.org/abs/2510.17810)
### Authors
Camilo Quiceno Quintero,Sandip Varkey George
### Background
心电图（ECG）反映了心脏的复杂动态，这些动态通过非线性时间序列分析可以被更好地理解和量化。该研究利用PTB-XL大数据集分析了ECG信号的非线性度与心脏病理的关系，特别是在不同诊断超级类别中非线性度测量的显著差异，以及通过结合复杂性量化指标提高分类准确性的成果。
### Innovation
使用PTB-XL大数据库集中的数据，研究提取了P波II导联的非线性度量化指标以及基于P波II、V2、AVL导联的交叉通道度量（如斯皮尔曼相关系数和互信息）。这些复杂度量化指标提高了ECG病变信号分类的准确性，特别是在权重 ROC 曲线下面积（AUC）方面，实现从基线0.86提高到使用非线性度量指标的0.87和结合交叉时间序列指标的0.90。
### Conclusion
研究发现，健康个体和病患个体在几乎所有非线性度量上的差异显著，且通过结合非线性度量化指标对机器学习模型进行改进，显著提升了ECG信号分类的准确性。
## 809. `cs.LG` - 使用振动信号分析和机器学习进行齿轮动力珩磨过程监控 [PDF](https://arxiv.org/pdf/2510.17809), [HTML](https://arxiv.org/abs/2510.17809)
### Authors
Massimo Capurso,Luciano Afferrante
### Background
现代齿轮制造对噪声、振动和粗糙度（NVH）有严格要求，需要进行高精度的精加工操作，如动力珩磨。传统的质量控制策略依赖于后处理检验和统计过程控制（SPC），无法捕捉瞬态加工异常，也无法确保实时缺陷检测。
### Innovation
本研究提出了一种新的数据驱动框架，用于齿轮动力珩磨的实时监控。该方法利用加速度计进行连续数据采集，并结合振动信号分析和机器学习技术。还研究了三种子空间学习方法的特征提取有效性：主成分分析（PCA）、结合PCA和线性判别分析（LDA）的两阶段框架，以及适用于张量数据的正则化相关多线性判别分析（R-UMLDA），并结合了针对小样本大小的正则化。
### Conclusion
提出的框架在工业环境中实现了高分类准确性（高达100%）。该方法提供可解释的频谱特征，与工艺动态相关，能够实现实际的实时监控和预测维护系统的集成。
## 810. `cs.LG` - 使用扩散模型为运动想象任务生成合成脑电图 [PDF](https://arxiv.org/pdf/2510.17832), [HTML](https://arxiv.org/abs/2510.17832)
### Authors
Henrique de Lima Alexandre,Clodoaldo Aparecido de Moraes Lima
### Background
脑电图（EEG）是一种广泛应用的无创方法，用于捕捉大脑活动，特别是在脑机接口（BCI）应用中有重要作用。然而，高质量EEG数据的收集仍面临传感器成本、采集时间和个体间变异性的挑战。
### Innovation
本文提出了一种使用扩散概率模型（DDPM）生成与运动想象脑任务相关的合成EEG信号的方法。该方法包括预处理真实EEG数据，训练扩散模型以从噪声中重建EEG通道，并通过信号级和任务级指标评估生成信号的质量。通过使用K-最近邻（KNN）、卷积神经网络（CNN）和U-Net等分类器验证，合成数据在分类任务中的性能与真实数据相当，甚至超过，生成的数据分类准确率高达95%以上。
### Conclusion
扩散模型生成的合成EEG信号能够有效补充数据集，提升基于EEG的BCI中的分类性能，并解决数据稀缺问题。
## 811. `cs.LG` - MAT-Agent: 自适应多智能体训练优化 [PDF](https://arxiv.org/pdf/2510.17845), [HTML](https://arxiv.org/abs/2510.17845)
### Authors
Jusheng Zhang,Kaitong Cai,Yijia Fan,Ningyuan Liu,Keze Wang
### Background
多标签图像分类需要适应性训练策略来应对复杂多变的视觉语义环境，但传统的训练方法依赖于静态配置，在动态环境中表现不佳。
### Innovation
我们提出了一种新的多智能体框架MAT-Agent，重新定义了训练过程为协作式的、实时的优化过程。MAT-Agent利用非稳态多臂老虎机算法动态调整数据增强、优化器、学习率和损失函数，同时通过复合同一奖励来平衡探索与利用，确保了鲁棒性和效率。此外，它还采用了双速率指数移动平均平滑和混合精度训练来增强性能。实验结果表明，MAT-Agent在Pascal VOC、COCO和VG-256数据集上的表现优于现有方法，实现了加速收敛和跨领域泛化能力的提升。
### Conclusion
MAT-Agent提供了一种可扩展的智能解决方案，用于优化复杂的视觉模型，为适应性深度学习的进步铺平了道路。
## 812. `cs.LG` - 基于预处理空间采样的协方差矩阵构造方法在稳健自适应波束形成中的应用 [PDF](https://arxiv.org/pdf/2510.17823), [HTML](https://arxiv.org/abs/2510.17823)
### Authors
Saeed Mohammadzadeh,Rodrigo C.de Lamare,Yuriy Zakharov
### Background
本文提出了一种高效的、稳健的自适应波束形成技术，用于解决波束形成技术中的方向矢量（SV）估计不符和数据协方差矩阵重建问题。特别是在可用样本中，利用自适应计算干扰信号的角度扇区来估计干扰源的方向到达（DoA）。然后，通过基于预处理的空间采样方法（PPBSS）利用广义线性组合算法重建干扰加噪声协方差（IPNC）矩阵。
### Innovation
文章提出的方法包括自适应计算干扰信号的角度扇区以估计干扰源的方向到达；利用预处理矩阵和样本协方差矩阵（SCM）通过缩放方法重建干扰加噪声协方差（IPNC）矩阵；结合预处理矩阵计算干扰加噪声协方差（IPNC）矩阵；提出了一种基于预处理矩阵计算的功率谱采样策略；并利用信号角度扇区构建信号类协方差矩阵，并使用功率方法计算信号类的方向矢量（SV）。
### Conclusion
通过分析阵列波束模式并在提出的PPBSS技术中进行分析，并研究了对手的竞争方法的计算成本。仿真结果表明，与现有方法相比，提出的方法更加有效。
## 813. `cs.LG` - CLARAE: Clarity Preserving Reconstruction AutoEncoder for Denoising and Rhythm Classification of Intracardiac Electrograms [PDF](https://arxiv.org/pdf/2510.17821), [HTML](https://arxiv.org/abs/2510.17821)
### Authors
Long Lin,Pablo Peiro-Corbacho,Pablo Ávila,Alejandro Carta-Bergaz,Ángel Arenal,Gonzalo R. Ríos-Muñoz,Carlos Sevilla-Salcedo
### Background
腔内心房电图（EGMs）提供了对心脏电生理学高分辨率的见解，但常常受到噪声污染，且保持高维特性，限制了实时分析。
### Innovation
CLARAE（CLArity-preserving Reconstruction AutoEncoder）是一种专为心房EGMs设计的一维编码-解码器，能够实现高保真重建和紧凑的64维潜在表示。CLARAE通过下采样池化、混合插值-卷积上采样路径和有界的潜在空间三个原则，旨在保持波形形态、减轻重建伪影并生成可解释的嵌入。
### Conclusion
CLARAE在495,731段EGM片段（单极和双极）上实现了对所有节律类型的下游节律分类F1分数均高于0.97，其潜在空间显示出清晰的节律聚类。在去噪任务中，它在单极和双极信号中始终名列前茅。为了促进可重复性和增强访问性，提供了一个交互式基于Web的应用程序，该平台允许用户探索预训练的CLARAE模型，可视化重建并实时计算指标。CLARAE结合了稳健的去噪能力与紧凑、有区别的表示，为临床工作流程（如节律分类、信号质量评估和实时映射）提供了一个实用的基础。
## 814. `cs.LG` - 将大气和海洋AI模型部署在中国硬件和框架上：迁移策略、性能优化与分析 [PDF](https://arxiv.org/pdf/2510.17852), [HTML](https://arxiv.org/abs/2510.17852)
### Authors
Yuze Sun,Wentao Luo,Yanfei Xiang,Jiancheng Pan,Jiahao Li,Quan Zhang,Xiaomeng Huang
### Background
随着人工智能在气候和天气研究中的作用越来越大，高效的模型训练和推理需求日益增长。当前如FourCastNet和AI-GOMS等模型依赖于GPU，这限制了硬件独立性，特别对于中国本土硬件和框架而言。为了应对这一问题，我们提出了一种从PyTorch迁移到MindSpore并优化适合中国芯片的框架，并对与GPU版本的性能进行了评估。
### Innovation
该框架着重于软件硬件适应性、内存优化和并行化。此外，模型的性能在多个指标上进行了评估，包括训练速度、推理速度、模型准确性和能量效率，与GPU版进行了对比。实验结果显示，迁移和优化过程保持了模型的原始准确度，同时显著减少了系统依赖，并通过利用中国芯片提高了操作效率。
### Conclusion
这项工作为中国本土芯片和框架在大气和海洋AI模型开发中的应用提供了宝贵的洞察和实用指导，提供了一条迈向更大技术独立性的路径。
## 815. `cs.LG` - 神经网络在神经计算电路中的应用：噪声和激活函数非均匀性对机器学习材料性质的影响的计算研究 [PDF](https://arxiv.org/pdf/2510.17849), [HTML](https://arxiv.org/abs/2510.17849)
### Authors
Ye min Thant,Methawee Nukunudompanich,Chu-Chen Chueh,Manabu Ihara,Sergei Manzhos
### Background
专用模拟神经计算机电路在高通量和低功耗的机器学习（ML）应用中非常有前景，特别是在无法实现数字计算机的远程位置、小型移动和自主设备以及极端条件下。然而，此类电路实现的神经网络必须应对电路噪声以及神经元激活函数（NAF）的非均匀形状所带来的挑战。这种非均匀形状归因于电路元件（如实现神经元的晶体管或二极管）性能特征的分散性。本文对电路噪声和NAF不均匀性对神经网络架构和训练阶段的影响进行了计算研究，特别关注了一个需要高通量机器学习的应用：材料信息学。
### Innovation
研究展示了神经网络对噪声的低容忍度，以及单隐藏层神经网络和过大的神经网络对噪声的更耐受性。此外，通过使用实际实现的NAF形状重新训练神经网络可以缓解激活函数不均匀性的影响。
### Conclusion
神经网络模型对噪声的容忍度较低，且泛化能力较差的模型（不一定是最小测试集误差）对噪声的容忍度更高。通过使用实际的NAF形状重新训练神经网络可以有效缓解激活函数不均匀性的影响。
## 816. `cs.LG` - 混合单调性对神经ODE可达性分析：在精确性和效率之间的权衡 [PDF](https://arxiv.org/pdf/2510.17859), [HTML](https://arxiv.org/abs/2510.17859)
### Authors
Abdelrahman Sayed Sayed,Pierre-Jean Meyer,Mohamed Ghazel
### Background
神经普通微分方程（神经ODE）是用于描述复杂动态系统的强大连续时间机器学习模型。然而，由于适配神经ODE的可达性分析工具有限，其验证仍然是具有挑战性的。
### Innovation
提出了一种基于区间的方法，结合连续时态混合单调性技术来计算神经ODE可达集的过度近似。该方法通过利用全初始集及其边界的几何结构和同胚性质，实现了高效的边界传播。此外，通过将神经ODE动力学嵌入混合单调系统中，并在其TIRA实现中采用单步、增量和基于边界的策略，该方法提供了比CORA的多面体和NNV2.0星集表示更安全且计算高效的近似。这种权衡使其特别适合高维、实时和安全性关键的应用。
### Conclusion
混合单调性在神经ODE可达性分析中的应用为利用单调嵌入的对称结构和区间盒子的几何简单性进行轻量级形式化分析铺平了道路，从而为与神经表示的对称性和几何形状一致的大规模验证打开了新的途径。这种方法通过在两个螺旋系统和固定点吸引子建模的神经ODE数值示例中进一步验证其有效性。
## 817. `cs.LG` - 基于向量相似性和区块链的AI生成图像溯源方法 [PDF](https://arxiv.org/pdf/2510.17854), [HTML](https://arxiv.org/abs/2510.17854)
### Authors
Jitendra Sharma,Arthur Carvalho,Suman Bhunia
### Background
随着生成AI和大型语言模型（LLMs）的迅速发展，生成高度逼真和上下文相关数字内容成为可能。具有DALL-E集成的ChatGPT等LLMs以及Stable Diffusion技术能够产出难以与人工生成图像区分的图象，这给数字内容真伪验证带来了挑战。确保数字数据的完整性和起源对于维护数字媒体中的信任和合法性至关重要。因此，亟需开发一种能够在保持准确性和计算效率的前提下，区分AI生成图像与真实图像的方法。
### Innovation
本文提出了一种基于嵌入的AI图像检测框架，利用图像嵌入和向量相似性来区分AI生成图像和真实生成图像。此方法基于假设AI生成的图像与其它AI生成内容的嵌入更接近，而人为生成的图像则在各自领域内聚类相似。通过开发一个处理多样化AI和人类生成图像的系统，该系统使用五个基准嵌入模型，实验验证了此方法的鲁棒性，证明轻微到中等程度的扰动对嵌入特征影响较小，扰动图像仍与原始版本保持高度相似。
### Conclusion
本文提出的方法提供了一种适用于检测AI生成图像的通用框架，既能保证准确性又能兼顾计算效率。这种方法对于维护数字媒体中的信任和合法性具有重要意义。
## 818. `cs.LG` - 从轻量级脉冲变换器解码听众身份：基于EEG信号的人身份识别 [PDF](https://arxiv.org/pdf/2510.17879), [HTML](https://arxiv.org/abs/2510.17879)
### Authors
Zheyuan Lin,Siqi Cai,Haizhou Li
### Background
基于脑电图（EEG）的人身份识别在安全、个性化脑-计算机接口（BCI）和认知监控等领域有着广泛的应用前景。然而，现有的技术通常依赖于深度学习架构，这导致了高计算成本，限制了它们的应用范围。
### Innovation
本文提出了一种使用轻量级脉冲变压器的脉冲神经网络（SNN）方法，以提高效率和有效性。所提出的SNN模型能够处理EEG信号中的时间复杂性。在EEG-Music Emotion Recognition Challenge数据集上，提出的模型以传统深度神经网络能量消耗的不到10%的能耗实现了100%的分类准确率。
### Conclusion
该研究为能量高效且高性能的BCIs提供了有前途的方向。
## 819. `cs.LG` - 预训练流动匹配扩散模型的短路几乎免费。 [PDF](https://arxiv.org/pdf/2510.17858), [HTML](https://arxiv.org/abs/2510.17858)
### Authors
Xu Cai,Yang Wu,Qianli Chen,Haoran Wu,Lichuan Xiang,Hongkai Wen
### Background
先前的方法通过短路机制使用灵活的轨迹跳过能力，但需要与现有模型不兼容的专用步长嵌入，除非从头开始重新训练，这几乎与预训练成本相同。
### Innovation
该论文的关键贡献是利用新型的自蒸馏原则，在标准流动匹配模型（如Flux）中实现更激进的短路机制，通过在速度场（而非样本空间）上进行学习并在线自我引导蒸馏，从而实现高效的快速训练。这种方法可以在预训练阶段本身实现，使得模型能够学习高效且少步骤的流动而不影响质量，从而首次实现对于数十亿参数扩散模型的少样本蒸馏（如10个文本-图像配对）。这种能力在几乎零成本的情况下提供了最先进的性能。
### Conclusion
(1)提出了一种基于新型自蒸馏原则的高效短路机制，适用于标准流动匹配模型。 (2)能够在预训练阶段实现，学习出高效、少步骤的流动。 (3)能够进行少样本蒸馏，适用于参数量巨大的扩散模型。 (4)几乎无成本提高性能。
## 820. `cs.LG` - 通过稀疏采样的张量分解的图形模型 [PDF](https://arxiv.org/pdf/2510.17886), [HTML](https://arxiv.org/abs/2510.17886)
### Authors
Angelo Giorgio,Riki Nagasawa,Shuta Yokoi,Tomoyuki Obuchi,Hajime Yoshino
### Background
该研究关注基于稀疏测量张量分量的张量因子化。测量方式使得交互的底层图形为随机图，这种设置对于推荐系统特别有用，特别是在社交媒体服务中大量数据缺失的情况下。为了解析此设置下的理论观点，研究在高维极限下考虑张量因子化的统计推断，即密集极限，在这个极限下，图虽然大规模、密集，但尚未完全连接。
### Innovation
提出了基于稀疏采样的张量因子化的图形模型，并通过消息传递算法进行测试。同时发展了复制品理论，在密集极限下精确反映统计推断的性能。
### Conclusion
研究通过密集极限下的复制品理论对统计推断的性能进行了分析，并在Bayes最优教师-学生设置中进行了测试，揭示了张量分解的理论洞察和实际应用潜力。
## 821. `cs.LG` - 当智能失效：预训练语言模型在密码破解中的实证研究 [PDF](https://arxiv.org/pdf/2510.17884), [HTML](https://arxiv.org/abs/2510.17884)
### Authors
Mohammad Abdul Rehman,Syed Imad Ali Shah,Abbas Anwar,Noor Islam
### Background
大型语言模型（LLMs）在自然语言理解和生成上的出色能力引起了它们在网络安全应用方面，尤其是密码猜测中的潜在利用的兴趣。此前的研究表明，除了传统的基于规则和组合的方法外，预训练的LLMs如TinyLLaMA、Falcon-RW-1B和Flan-T5也可能用于密码破解。本文探讨了这些模型在生成基于用户属性（如姓名、出生日期、爱好）的密码方面的表现，并评估了其在明文和SHA-256哈希比较中的效果。
### Innovation
本文提供了对预训练语言模型在密码破解中的实证研究，使用合成用户资料评估了最新的开源LLMs，通过详细分析和可视化识别了这些模型在特定任务中的生成推理的关键局限性。该研究揭示了LLMs在缺乏监督微调和泄露密码数据集上的适应能力时，在密码推理方面的局限性，强调了未来安全、隐私保护、和稳健密码建模努力的重要性，为这一领域提供了关键洞察。
### Conclusion
当前的预训练LLMs在密码推理方面表现出色的语言能力不足，缺乏足够的领域适应和记忆能力，尤其是在缺乏监督微调的情况下，这种研究为LLMs在对抗性环境中的局限性提供了批判性见解，并为未来相关的研究奠定了基础。
## 822. `cs.LG` - TritonRL: 训练LLMs无需作弊地思考与编写Triton代码 [PDF](https://arxiv.org/pdf/2510.17891), [HTML](https://arxiv.org/abs/2510.17891)
### Authors
Jiin Woo,Shaowei Zhu,Allen Nie,Zhen Jia,Yida Wang,Youngsuk Park
### Background
随着大型语言模型（LLMs）的迅速发展，对自动化、高性能系统内核的需求已经成为加速开发和部署的关键推动力。Triton内核生成面临着由于数据稀缺和不完整的评估标准而导致的独特挑战，容易受到奖励劫持的影响。
### Innovation
我们提出了TritonRL，一个针对Triton内核生成的专业化LLM，通过一个新颖的训练框架实现了鲁棒的、自动化的内核合成。我们的方法通过监督微调和强化学习（RL）来解决这些挑战，逐步提升了代码质量，防止了奖励劫持，指导逻辑推理路径和代码令牌的精细验证，并通过分层奖励分解实现模型生成高质量的Triton内核，能够真正替代现有模块。我们的强化学习框架能够鲁棒地检测奖励劫持，并通过精细验证和分层奖励分解来引导推理路径和代码令牌，确保生成的Triton内核具有高质量且正确性高、速度提升显著。
### Conclusion
我们的实验结果表明，在KernelBench上的测试中，TritonRL取得了最先进的正确性和速度增益，超过了所有其他专门针对Triton的模型，证实了我们基于强化学习训练框架的有效性。
## 823. `cs.LG` - 从流到词：零/少量样本LLM能否检测网络入侵？一种语法限定、校准评估于UNSW-NB15 [PDF](https://arxiv.org/pdf/2510.17883), [HTML](https://arxiv.org/abs/2510.17883)
### Authors
Mohammad Abdul Rehman,Syed Imad Ali Shah,Abbas n=Anwar,Noor Islam
### Background
大型语言模型（LLMs）能够处理自然语言输入，但在未经微调的情况下，它们在入侵检测中的作用尚不确定。本文通过将每个网络流转换为紧凑的文本记录，并增加轻量级、领域启发式的布尔标志（非对称性、突发率、TTL异常、定时异常、罕见服务/状态、短暂突发），对UNSW-NB15数据集进行了零样本、指令指导和少量样本提示方法的评估，并与基于表格和神经网络的强基线进行了比较，以研究在未经微调的情况下，LLMs在入侵检测中的表现。
### Innovation
研究利用UNSW-NB15数据集，探讨了LLMs在未经微调的情况下进行入侵检测的可能性。设计了一种语法限定、校准评估框架，通过将网络流转化为文本记录并附加布尔标志，减少模型输出偏差，提高检测质量，同时提出了一种校准方法来稳定结果。比较了几种不同的提示方法，发现带指令和标志的提示效果最好，进一步校准得分能够进一步稳定检测结果。提出了一个简洁有效的提示管道，无需梯度训练，生成可读的输出，并且可以通过指令和标志轻松调整。
### Conclusion
在两个百个网络流的平衡子集中，带有标志的3B模型通过少量样本线索和校准达到了接近0.68的F1分数；在增至两千个网络流的评估集中，决策质量有所下降，揭示了对覆盖范围和提示的敏感性。结论指出，尽管表格基线在稳定性上更胜一筹且计算速度更快，但提示管道无需梯度训练，产生可读的输出，并且可以轻松地通过指令和标志进行调整。贡献包括可解释的流到文本协议、校准方法、系统化基线比较以及重复性捆包，包括提示、语法、指标和图表。
## 824. `cs.LG` - 从不完整图信号学习时变图 [PDF](https://arxiv.org/pdf/2510.17903), [HTML](https://arxiv.org/abs/2510.17903)
### Authors
Chuansen Peng,Xiaojing Shen
### Background
本文解决了从部分观测的图信号中同时推断时变网络拓扑结构和填补缺失数据的挑战性问题。传统的分隔方法会忽略图和信号域之间的双向信息流动，这在高缺失数据比例的情况下通常会导致鲁棒性较差的问题。为此，本文提出了一种统一的非凸优化框架，可以在重构时变图拉普拉斯矩阵的同时恢复缺失的信号数据项。此外，引入了融合lasso类型的正则化项来捕捉现实的网络动态，这有助于通过惩罚大变化来促进时间平滑性，从而防止噪声引起的虚假变化，同时允许拓扑结构的逐步演变。
### Innovation
本文提出了一个统一的非凸优化框架，可以在重构时变拉普拉斯矩阵的同时重建未观察到的信号项，从而促进图和信号域之间的双向信息流动。引入了融合lasso类型的正则化项来促进时间平滑性，防止虚假变化，同时允许拓扑结构的逐步演变。文中还设计了一个高效的交替方向乘子(ADMM)算法来解决联合优化问题，该算法利用问题的结构来提供闭式解，确保对大规模网络和长时间跨度的鲁棒性。尽管提出了的问题是非凸的，但通过理论分析证明了ADMM方案能够收敛到一个稳态点，并且还提供了非渐近统计保证。
### Conclusion
广泛的数值实验验证了本文方法的有效性，表明它在收敛速度和图学习及信号恢复的联合准确性方面均显著优于现有基准。
## 825. `cs.LG` - PLAGUE: 插件式框架用于终身自适应生成多轮攻击 [PDF](https://arxiv.org/pdf/2510.17947), [HTML](https://arxiv.org/abs/2510.17947)
### Authors
Neeladri Bhuiya,Madhav Aggarwal,Diptanshu Purwar
### Background
大型语言模型（LLMs）正在以惊人的速度改进。随着代理工作流程的引入，多轮对话已成为与LLMs交互以完成长期和复杂任务的主流方式。尽管LLM的功能不断提高，但它们在多轮场景中越来越容易受到恶意破解的影响，尤其是当有害意图可以通过对话中的细微注入逐渐渗透时，从而产生不良的结果。单轮攻击虽然已经被广泛研究，但其多轮攻击的适应性、效率和有效性仍然是核心挑战。
### Innovation
本文介绍了PLAGUE，一个受终身学习代理人启发的新型插件式框架，用于设计多轮攻击。PLAGUE将多轮攻击的生命期分解为三个精心设计的阶段（启蒙阶段、规划阶段和执行阶段），从而实现了系统且丰富的多轮攻击探索。研究显示，使用PLAGUE设计的红队代理在减少或同等查询预算的情况下，实现了多项领先模型的最佳破解结果，提升攻击成功率超过30%。特别是在评估OpenAI的o3和Claude的Opus 4.1模型时，PLAGUE分别实现基于StrongReject的攻击成功率81.4%和67.3%，这些模型被认为在安全性文献中具有高度抵抗破解的能力。
### Conclusion
我们的工作为多轮攻击的设计提供了工具和见解，强调了计划初始、上下文优化和终身学习在全面模型漏洞评估中的重要性。
## 826. `cs.LG` - XDXD：低分辨率X射线衍射的端到端晶体结构确定 [PDF](https://arxiv.org/pdf/2510.17936), [HTML](https://arxiv.org/abs/2510.17936)
### Authors
Jiale Zhao,Cong Liu,Yuxuan Zhang,Chengyue Gong,Zhenyi Zhang,Shifeng Jin,Zhenyu Liu
### Background
从X射线衍射数据确定晶体结构是跨多个科学领域的一项基础工作，但当数据仅限于低分辨率时，这一过程仍是一项重大挑战。虽然最近的深度学习模型在解决晶体学相位问题方面取得了突破，但对于低分辨率的电子密度图谱，这些结果往往模糊且难以解释。
### Innovation
我们引入了XDXD作为已知的第一个可以直接从低分辨率单晶X射线衍射数据中确定完整原子模型的端到端深度学习框架。基于扩散的生成模型绕过了手动图谱解释的需要，生成的晶体结构符合化学原理，基于衍射模式进行条件化。实验显示，XDXD在2.0 Å分辨率数据限制下的结构匹配率为70.4%，RMSE低于0.05。在24,000个实验结构的基准测试中，我们的模型显示出鲁棒性和准确性。此外，针对小肽的案例研究揭示了该模型在更复杂系统中的扩展潜力，为了解决以前难以解决的结构测定问题铺平了道路。
### Conclusion
XDXD模型在低分辨率单晶X射线衍射数据中实现了从直接生成完整原子模型的端到端处理，极大地提升了晶体结构确定的准确性和可靠性，特别适用于低分辨率的情况。
## 827. `cs.LG` - 通过自我监督泛光谱表示学习实现通用光谱分词 [PDF](https://arxiv.org/pdf/2510.17959), [HTML](https://arxiv.org/abs/2510.17959)
### Authors
Jeff Shen,Francois Lanusse,Liam Holden Parker,Ollie Liu,Tom Hehir,Leopoldo Sarra,Lucas Meyer,Micah Bowles,Sebastian Wagner-Carena,Sebastian Wagner-Carena,Helen Qu,Siavash Golkar,Alberto Bietti,Hatim Bourfoune,Nathan Cassereau,Pierre Cornette,Keiya Hirashima,Geraud Krawezik,Ruben Ohana,Nicholas Lourie,Michael McCabe,Rudy Morel,Payel Mukhopadhyay,Mariel Pettee,Bruno Régaldo-Saint Blancard,Kyunghyun Cho,Miles Cranmer,Shirley Ho
### Background
科学研究的数据涵盖了多种分辨率和领域，统一共有的表示有助于开发科学基础模型。天文学中的光谱数据尤其具有挑战性：大量光谱跨越多种波长和分辨率领域已收集起来，但分析仍局限于特定的光谱领域（例如可见光和红外光）及对象类型（例如恒星和星系），这限制了跨数据集的信息整合能力。
### Innovation
本文提出了一种深度学习模型，可以以自监督的方式从多种不同类型的光谱中共同学习。通用光谱分词能够直接在原始波长网格上处理不同类型的光谱，产生的表示具有内在对齐、同质且物理意义。该模型能够有效地适应多个下游任务，并取得了竞争优势的性能。这是首次证明一个单一的模型可以统一不同分辨率和领域的光谱数据，展示出该模型可以作为天文学乃至其他科学领域具有强大基础作用的构建块。
### Conclusion
该模型能够统一跨分辨率和领域的光谱数据，展示了强大的泛化能力，且未来可能应用于其他领域如气候和医疗健康，具有重要的科学价值。
## 828. `cs.LG` - QINNs: 量子启发式神经网络 [PDF](https://arxiv.org/pdf/2510.17984), [HTML](https://arxiv.org/abs/2510.17984)
### Authors
Aritra Bal,Markus Klute,Benedikt Maier,Melik Oughton,Eric Pezone,Michael Spannowsky
### Background
经典深度神经网络在学习碰撞数据中的多重粒子相关性方面表现出色，但它们的归纳偏见很少与物理结构挂钩。本文提出了一种新的框架——量子启发式神经网络（QINNs），该框架将量子信息概念和量子可观测量引入到纯粹的经典模型中，从而增强模型的语言表达能力和适应性。在研究深入学习中.wallet
### Innovation
本文提出了一种具体实现的QINNs方法，它将每个粒子编码为一个量子位，并采用量子费舍尔信息矩阵（QFIM）作为粒子相关性的紧凑且基无关的摘要。这种实现形式用于案例研究——喷射标签中，QFIM作为图神经网络中的轻量级嵌入，提高模型的表达能力和适应性，并揭示了QCD和强子态喷射的独特模式，与物理预期一致。
### Conclusion
QINNs提供了一种实用、可解释且可扩展的方法，用于量子启发式分析，特别是通过增强现有的深度学习技术来实现粒子碰撞的汤姆森分析。
## 829. `cs.LG` - 使用隐式神经表示进行重力数据三维反演 [PDF](https://arxiv.org/pdf/2510.17876), [HTML](https://arxiv.org/abs/2510.17876)
### Authors
Pankaj K Mishra,Sanni Laaksonen,Jochen Kamm,Anand Singh
### Background
重力数据反演是研究地下密度变化的一种重要方法，这些变化与多种应用相关，包括矿物勘探、地热评价、碳存储、天然氢、地下水资源以及地壳演化。传统的反演方法通常需要预定义网格或离散化过程，且对高频特征的表示存在谱偏置问题。
### Innovation
论文提出了一个科学的机器学习方法，利用隐式神经表示（INR）将地下密度表示为连续场，通过基于物理正演建模的损失直接训练深度神经网络，无需预定义网格或离散化。位置编码增强了网络捕捉尖锐对比和短波长特征的能力，克服了传统基于坐标网络因谱偏置而过度平滑的问题。该方法在合成数据示例上展示了其性能，包括高斯随机场和倾斜块模型，实现了详细的结构和地质可解释边界的重建，同时大幅减少了反演参数的数量。
### Conclusion
隐式表示框架不仅能实现大规模地质物理反演的高度扩展性、灵活性和解释性，还有望推广到其他地质物理方法和联合/多物理场反演。
## 830. `cs.LG` - 仅使用性能矩阵简化基准分析: SimBA [PDF](https://arxiv.org/pdf/2510.17998), [HTML](https://arxiv.org/abs/2510.17998)
### Authors
Nishant Subramani,Alfredo Gomez,Mona Diab
### Background
现代语言模型在大型基准测试中进行评估，这些基准测试难以理解和解释，尤其是对于模型选择而言。通过直接分析模型的评估数据，本文提出了一种名为SimBA的三层框架，旨在简化基准分析。
### Innovation
SimBA框架包含三阶段：1) stalk（追踪阶段），进行数据集和模型对比；2) prowl（探索阶段），开发了一种基于原始评估得分发现代表性子集的算法；3) pounce（捕捉阶段），利用代表性子集预测未见过的模型性能。该框架有助于模型开发者提高训练效率，并帮助数据集创建者验证新数据集是否与现有数据集有显著差异。
### Conclusion
研究结果表明，SimBA框架在处理HELM、MMLU和BigBenchLite三种流行语言模型基准时均有效。通过使用仅有的6.25%、1.7%和28.4%的数据集覆盖基准，实现至少95%的覆盖水平。同时，仅使用这些代表性子集，即可保持模型排名的准确性，并以接近零均方误差的精度预测未见过的模型性能。该框架能够帮助模型开发者和数据集创建者更好地优化工作流程和验证数据集的独特性。
## 831. `cs.LG` - ViBED-Net:基于面部和场景时空线索的视频参与检测网络 [PDF](https://arxiv.org/pdf/2510.18016), [HTML](https://arxiv.org/abs/2510.18016)
### Authors
Prateek Gothwal,Deeptimaan Banerjee,Ashis Kumer Biswas
### Background
在线学习环境中参与度检测是提高学生成果和个性化教学的关键。现有方法在识别参与度时准确性和灵活性尚有提升空间。本文旨在提出一种全新的深度学习框架ViBED-Net，用于通过视频数据评估学生参与度，该框架采用双流架构捕获面部表情和全场景上下文。
### Innovation
提出了一种新颖的双流架构——ViBED-Net，该架构通过EfficientNetV2对面部区域和整个视频帧进行空间特征提取，然后使用LSTM网络和Transformer编码器进行时间特征分析，结合面部和场景的时空线索，显著提高参与度检测的准确性。此外，通过有针对性的数据增强技术来增强对参与度类别较少的数据的性能。研究指出在DAiSEE数据集上的结果表明，ViBED-Net与LSTM结合使用时，准确率达到了73.43%，超过了现有最先进的方法。
### Conclusion
本文通过提出ViBED-Net视频参与检测网络，采用了新颖的双流架构和时空线索，显著提升了参与度检测的准确性和灵活性，该方法在教育、用户体验研究和内容个性化方面具有广泛应用前景。
## 832. `cs.LG` - 平面中的快速无假设学习者 [PDF](https://arxiv.org/pdf/2510.18057), [HTML](https://arxiv.org/abs/2510.18057)
### Authors
Talya Eden,Ludmila Glinskih,Sofya Raskhodnikova
### Background
在平面中，我们研究了几种基本的几何概念类的无假设学习的计算效率。尽管无假设学习的样本复杂性已经被很好地理解，但是其时间复杂性却一直受到较少的关注。
### Innovation
本文提出了几种具体几何概念类的无假设学习算法，改进了现有算法的时间复杂性。对于三角形、四边形和五边形，新的算法时间复杂性分别提升了至 $ tilde{O}(ε^{-6})$、$ tilde{O}(ε^{-8})$ 和 $ tilde{O}(ε^{-10})$；对于凸集，在均匀分布下，新的算法时间复杂性为 $ tilde{O}(ε^{-5})$，尽管样本复杂性有所增加。
### Conclusion
通过对这些几何概念类的研究，我们发现无假设学习的样本复杂性和时间复杂性之间可能存在固有的差距，这一发现对其他自然概念类的无假设学习也具有重要启示意义。
## 833. `cs.LG` - TriggerNet: 一种新型可解释的AI框架用于红棕榈介壳虫检测和多模型比较及启发式标注 [PDF](https://arxiv.org/pdf/2510.18038), [HTML](https://arxiv.org/abs/2510.18038)
### Authors
Harshini Suresha,Kavitha SH
### Background
红棕榈介壳虫的虫害已经成为一个严重的问题，特别是在大面积种植棕榈树的地区，导致产量下降和经济损失。准确且早期识别被虫害影响的植株对于有效管理至关重要。本研究旨在评估和比较机器学习模型在棕榈树分类和虫害检测中的应用。
### Innovation
TriggerNet 是一种新颖的可解释的人工智能框架，结合了 Grad-CAM、RISE、FullGrad 和 TCAV，用于生成深度学习模型在植物分类和疾病检测中的新型视觉解释。研究将 TriggerNet 应用于红棕榈介壳虫（Raoiella indica）检测，这是一种对棕榈树种植和农业生产力的主要威胁。
### Conclusion
研究采用了包括 RGB 图像、Convolutional Neural Network (CNN)、EfficientNet、MobileNet、Vision Transformer (ViT)、ResNet50 和 InceptionV3 以及机器学习分类器（随机森林、支持向量机、K 最近邻）在内的多种先进深度学习模型和多模型比较方法，用于植物分类。此外，使用 Snorkel 进行疾病分类的标注，通过启发式规则和模式减少了手动标注时间并提高了数据集的可靠性。
## 834. `cs.LG` - 通过分层梯度分解实现自我验证：一个通过最小化变分自由能维持非平衡稳态的耗散系统 [PDF](https://arxiv.org/pdf/2510.17916), [HTML](https://arxiv.org/abs/2510.17916)
### Authors
Michael James McCulloch
### Background
自由能量原理（FEP）指出，自我组织系统必须最小化变分自由能以维持自身，但将原理转化为可行算法的路径一直不清晰。本文提供了一个构建性证明，说明可以通过精确的局部信用分配实现FEP。系统按层次分解梯度计算：空间信用通过反馈对齐实现，时间信用通过资格痕迹实现，结构信用通过估算每个连接块预期梯度大小的营养领域图（TFM）实现。本文证明了这些机制在各自级别上是精确的，并通过实验证明了核心声明：TFM与优化梯度达到了0.9693的皮尔逊相关系数。这种精确性产生了包括任务干扰后保留98.6%的能力，自主恢复75%的结构性损伤，自我组织临界性（特征半径p约为1.0），以及在连续控制任务上的样本有效强化学习结果。该架构统一了普里戈金的耗散结构、费里登的自由能最小化和霍普菲尔德的吸引子动力学，表明可通过局部、生物可实现的规则实现网络拓扑的精确层次推理。
### Innovation
提出了通过分层梯度分解实现自由能量原理的方法，具体而言，通过反馈对齐实现空间信用，通过资格痕迹实现时间信用，通过营养领域图（TFM）估计每个连接块预期梯度大小实现结构信用。这些机制被证明在各自层级上是精确的，实现了一系列高级能力，如任务干扰后的高度保留率、自主恢复结构损伤以及样本高效的连续控制任务的强化学习能力。该模型统一了多个理论框架。
### Conclusion
通过精确的局部信用分配实现了自由能量原理，并验证了其能够产生一系列高级能力，包括任务干扰后的高保留率、自主恢复结构损伤、自我组织的临界性和在连续控制任务上的高效强化学习。
## 835. `cs.LG` - 使用自适应(patch)大小加速视觉变换器 [PDF](https://arxiv.org/pdf/2510.18091), [HTML](https://arxiv.org/abs/2510.18091)
### Authors
Rohan Choudhury,JungEun Kim,Jinhyung Park,Eunho Yang,László A. Jeni,Kris M. Kitani
### Background
视觉变换器(ViTs)将输入图像均匀分割为大小相同的patches，不论内容如何，这导致高分辨率图像的长输入序列长度。这种处理方式在高分辨率图像处理中存在效率问题和计算开销增加的问题。
### Innovation
提出了自适应变换器(AAPT)，它在同一图像中使用多种不同的patch大小。AAPT通过在更均质的区域分配更大的patch，而在更复杂的区域分配较小的patch，来减少输入tokens的总数。这种方式提高了ViT的推理和训练速度，特别是在高分辨率密集视觉任务中，它还能加快训练和推理速度，缩短收敛时间，同时保持下游任务性能。
### Conclusion
AAPT可以在预训练的ViT上应用，仅用一个epochs就能快速收敛，并在保持性能的同时显著减少了训练和推理时间，特别是在视觉问答、目标检测和语义分割等高分辨率密集视觉任务中。
## 836. `cs.LG` - 从局部到全局：大型语言模型结构剪枝范式的重新审视 [PDF](https://arxiv.org/pdf/2510.18030), [HTML](https://arxiv.org/abs/2510.18030)
### Authors
Ziyan Wang,Enmao Diao,Qi Le,Pu Wang,Minwoo Lee,Shu-ping Yeh,Evgeny Stupachenko,Hao Feng,Li Yang
### Background
结构剪枝是高效部署大型语言模型（LLMs）的一种实用方法，因为它可以产生紧凑且硬件友好的架构。现有的剪枝方法主要采用局部范式，通过逐层重构而不是优化特定任务目标进行优化，这导致剪枝策略通常保留了困惑度或通用零样本行为，而未能充分利用任务特定的校准信号，导致下游任务收效甚微。
### Innovation
本文重新审视了全局结构剪枝方法，并提出了GISP（Global Iterative Structured Pruning），这是一种后训练方法，通过层级聚合的第一阶损失权重并在块级归一化的情况下去除注意力头和MLP通道。相较于一次剪枝，使用迭代策略可以提高稀疏度下的模型精度并缓解困惑度崩溃，而不需要中间微调；此外，GISP还形成了嵌套子网络，支持“一次剪枝，多次部署”的工作流程。进一步地，因为重要性是由模型级别的损失定义的，GISP自然支持特定任务的目标；本文实例化了语言建模中的困惑度目标和决策任务中的差距目标。实验结果表明，在Llama2-7B/13B、Llama3-8B以及Mistral-0.3-7B上，GISP能够持续降低WikiText-2的困惑度并提高下游精度，在40-50%的稀疏度下效果尤其显著；在使用DeepSeek-R1-Distill-Llama-3-8B和GSM8K的实验中，任务对齐的校准显著提升了精确匹配精度。
### Conclusion
GISP方法能够显著降低大型语言模型的困惑度并提高其在多个下游任务中的精度，尤其是在较高稀疏度下表现尤为优异，同时支持任务特定的目标优化，并形成嵌套子网络以促进“一次剪枝，多次部署”的高效使用。
## 837. `cs.LG` - 仲裁间接治疗对比 [PDF](https://arxiv.org/pdf/2510.18071), [HTML](https://arxiv.org/abs/2510.18071)
### Authors
Yixin Fang,Weili He
### Background
匹配调整间接比较（MAIC）在健康技术评估（HTA）中日益受到重视。MAIC通过调整来自个体参与者数据（IPD）试验的权重，以匹配仅具有汇总数据（AgD）的另一试验的协变量摘要统计，有助于估计针对AgD试验人群定义的治疗效果。然而，当不同的赞助商分析相同的数据时，有时会得出相互矛盾的结论，这一现象被称为MAIC悖论。MAIC悖论的核心问题在于，每个赞助商实际上可能是在分析不同的人群。因此，需要一种新的方法来估计治疗效果，通过选择一个共同的目标人群（即重叠人群）来解决这种不一致的问题。
### Innovation
本文提出了一类新的方法，称为仲裁间接治疗对比，旨在解决MAIC悖论问题。这些新方法通过估计一个共同的目标人群中的治疗效果来解决不同赞助商之间相互矛盾的结论问题。具体而言，选择了一个共同的目标人群，即重叠人群。
### Conclusion
该方法为解决MAIC悖论提供了一种新的途径，能够促进HTA中的治疗效果评估在不同人群分析结果上的统一性。这种方法强调了在对比不同治疗效果时，需要明确定义目标人群的重要性。
## 838. `cs.LG` - 在超低功耗边缘硬件上对音频-文本特征进行迟滞融合的变压器重设计 [PDF](https://arxiv.org/pdf/2510.18036), [HTML](https://arxiv.org/abs/2510.18036)
### Authors
Stavros Mitsis,Ermos Hadjikyriakos,Humaid Ibrahim,Savvas Neofytou,Shashwat Raman,James Myles,Eiman Kanjo
### Background
在实际环境中部署情感识别系统时，设备需要保持小型、低功耗和私人，这对于紧张监控、冲突降级和响应式穿戴设备等应用尤为重要，因为基于云端的解决方案在实践中不可行。基于深度学习的多模态情感识别虽已取得进展，但大多数系统均不适合部署在极度受限的边缘设备上。现有工作多依赖于高性能硬件，不具备实时性能，或者仅使用单一模态输入。因此，本文研究了一种硬件感知的情感识别系统，该系统结合了基于音频和语言特征的迟滞融合架构，并适用于Edge TPU。这种设计通过定制的融合方式和硬件指导下的模型设计，使得实时推断能够在1.8MB的内存预算和21-23ms的延迟下实现。评估结果显示相较于单一模态的基础模型，该研究的实时多模态情感推断提高了6.3%的宏F1分数。这就证明了特定任务融合和硬件指导下的模型设计可以在微型控制器级别的边缘平台上实现准确且实时的情感推断。
### Innovation
提出了一种结合音频和语言特征的情感识别系统，使用迟滞融合架构优化用于Edge TPU。该设计包括量化基于transformer的音频模型和来自DSResNet-SE网络的冻结关键词嵌入，确保了训练与部署中的光谱图对齐，并通过MicroFrontend和MLTK实现。这种系统能够在限制严格的边缘设备上进行实时情感识别，同时保持较高的准确性。
### Conclusion
这种方法通过特定任务融合和硬件指导下的模型设计，在超低功耗的边缘硬件上实现了准确且实时的多模态情感推断。这凸显了将复杂的深度学习模型通过定制化和硬件限制优化后，也可以适配在微型控制器类的边缘平台上运行，为实际应用提供了一种有效的情感识别解决方案。
## 839. `cs.LG` - 从AutoRecSys到AutoRecLab：构建、评估和治理自主推荐系统研究实验室的呼吁 [PDF](https://arxiv.org/pdf/2510.18104), [HTML](https://arxiv.org/abs/2510.18104)
### Authors
Joeran Beel,Bela Gipp,Tobias Vente,Moritz Baumgart,Philipp Meister
### Background
推荐系统研究加速了模型和评估的进步，但主要忽视了自动化研究过程本身。过去的工具大多集中在算法选择和超参数调整，而忽略了从问题构想到文献分析、实验设计执行、结果解释、论文起草和存档记录的整体自动化。本文提出应将重点从局部的AutoRecSys工具转向集成整体自动化流程的自主推荐系统研究实验室（AutoRecLab）
### Innovation
本文倡导构建开放的AutoRecLab原型，结合LLM驱动的创新思考和报告与自动实验；设立评估人工输入最少的基准和竞赛；创建透明的AI生成提交的审稿空间；定义详细的研发日志和元数据以确保归因与可重复性；并促进跨学科对话讨论伦理、治理、隐私和公平性等自主研究问题的治理。这一议程有望提高研究效率，揭示不明显的新见解，并使推荐系统研究能为新兴的人工智能研究做出贡献
### Conclusion
本文呼吁组织一次社区退修会，以协调下一步行动，共同撰写关于负责任引入自动化研究系统的指南
## 840. `cs.LG` - PrivaDE：基于区块链的数据市场的隐私保护数据评估 [PDF](https://arxiv.org/pdf/2510.18109), [HTML](https://arxiv.org/abs/2510.18109)
### Authors
Wan Ki Wong,Sahel Torkamani,Michele Ciampi,Rik Sarkar
### Background
评估数据的相关性是模型构建者获得能提升模型性能的数据集的关键任务。理想情况下，这样的评估应该允许模型构建者在不泄露模型的专有细节的情况下评估候选数据的实用性。同时，数据提供者必须确保模型构建者仅获得计算出的实用评分，不会泄露其数据的任何其他信息。
### Innovation
PrivaDE是一个通过区块链中心化设计实现的加密协议，实现隐私保护的数据评估和选择。它通过不可靠的区块链特性提供恶意安全性保证，同时对模型和数据集提供强大的隐私保护。PrivaDE通过集成模型蒸馏、模型拆分和截断选择零知识证明等技术，实现了高效运行。同时，PrivaDE提出了一种统一的实用评分函数，可以无缝集成到主动学习工作流中。
### Conclusion
我们的工作为去中心化机器学习生态系统中的公平和自动数据市场奠定了基础，PrivaDE通过区块链技术实现了高效和安全的数据评估，能够在15分钟内完成具有数百万参数模型的数据评估。
## 841. `cs.LG` - 在边缘稳定性下的泛化：数据几何的作用 [PDF](https://arxiv.org/pdf/2510.18120), [HTML](https://arxiv.org/abs/2510.18120)
### Authors
Tongtong Liang,Alexander Cloninger,Rahul Parhi,Yu-Xiang Wang
### Background
理解超越参数化的神经网络的泛化能力取决于数据几何、神经网络架构和训练动力学之间的相互作用。本文集中在探索数据几何如何控制这种隐含偏差。
### Innovation
本文提出了一种理论结果，对于位于低维球体混合上的数据分布，推导了泛化界限，该界限能够适应内在维度。对于针对单位球体概率质量集中程度不同的均匀分布族，推导出一系列界限，表明随着质量向球体集中，泛化率会恶化。这些结果表明了一个统一的原则：当数据相对于ReLU神经元的激活阈值更难以“击破”时，梯度下降倾向于学习能够捕捉共享模式的表示，从而找到泛化良好的解决方案。
### Conclusion
本文的理论结果统一了文献中出现的不同实验发现，即对于能够“击破”的数据（例如，数据支持在球体上），梯度下降更倾向于记忆化。
## 842. `cs.LG` - 从泛化模式中学习：一种基于评估的细化小型语言模型数据增强方法 [PDF](https://arxiv.org/pdf/2510.18143), [HTML](https://arxiv.org/abs/2510.18143)
### Authors
Huan Song,Deeksha Razdan,Yiyue Qian,Arijit Ghosh Chowdhury,Parth Patwa,Aman Chadha,Shinan Zhang,Sharlina Keshava,Hannah Marlowe
### Background
小型语言模型（SLMs）在部署成本和延迟方面具有显著优势，但其准确率往往落后于大型模型，尤其是在复杂的特定领域任务中。虽然监督微调可以缩小这一性能差距，但需要大量的人工努力进行数据准备和迭代优化。现有的数据增强方法主要关注模型训练错误并生成纠错样本，但这类方法没有从验证数据中发现故障模式并提出针对性的数据增强策略以直接减少泛化差距。本研究旨在通过一种基于评估的方法解决这一问题，该方法可以简化小型语言模型的数据增强过程，并显著提升细微调整过程的表现。
### Innovation
本研究提出了一种名为PaDA-Agent的评估驱动的数据增强代理，该代理通过发现验证数据中的故障模式并制定针对性的数据增强策略来简化小型语言模型的数据增强过程。与现有的仅关注模型训练错误并生成纠错样本的方法不同，PaDA-Agent直接旨在减少模型的泛化差距。实验结果表明，这种方法在Llama 3.2 1B Instruct模型的微调中显著优于现有的基于大型语言模型的数据增强方法。
### Conclusion
本研究通过一种新的评估驱动的数据增强方法PaDA-Agent，可以在较小的语言模型的整体微调过程中带来显著的性能提升。
## 843. `cs.LG` - 在转换器中提取注意力特征的基于规则的描述 [PDF](https://arxiv.org/pdf/2510.18148), [HTML](https://arxiv.org/abs/2510.18148)
### Authors
Dan Friedman,Adithya Bhaskar,Alexander Wettig,Danqi Chen
### Background
机制可解释性试图通过底层基本元素来解释模型行为。目前的主要方法是将隐藏状态表示为基向量（称为特征）的稀疏线性组合，但这种方法识别的是哪些文本序列（实例）激活了哪些特征，而对特征的实际解释需要对这些实例进行主观检查。本文提出了一种基于规则的描述方法，该方法通过匹配输入中的令牌模式来相应地增加或减少特定输出令牌的可能性。
### Innovation
本文提出了一种自动从变换器中提取基于规则的描述的新方法，特别是针对注意力层。该方法识别三种类型的规则：跳过模式规则、缺失规则和计数规则。这种方法能够在不通过手动或自动检查实例的情况下发现缺失和计数规则，从而提供更准确的解释。另外，研究人员还发现计数规则在第一层的特征中就普遍存在。
### Conclusion
本文通过对变换器内部注意力层特征进行了基于规则的描述提取研究，为未来基于规则的研究奠定了基础。研究结果表明通过大约100条跳过模式规则可以很好地描述大多数特征，并且缺失规则在早期层数中也很普遍。此外，还发现了一些计数规则的例子，为后续研究提供了初步的规则行为分类。
## 844. `cs.LG` - 通过推理意识化的政策优化击败胜利者的诅咒 [PDF](https://arxiv.org/pdf/2510.18161), [HTML](https://arxiv.org/abs/2510.18161)
### Authors
Hamsa Bastani,Osbert Bastani,Bryce McLaughlin
### Background
最近对基于个体丰富协变量自动学习治疗决策策略产生了极大的兴趣。一种常见做法是训练机器学习模型预测反事实结果，然后选择优化预测目标值的策略。然而，由于“获胜者诅咒”问题——优化策略利用了预测错误而非真实改进——预测性能改进往往无法通过下游策略优化来证实。为解决这一挑战，本文提出了一种新的策略，即推理意识化的政策优化，该策略通过对政策如何进行下游评估进行建模来调整政策优化过程。
### Innovation
该策略不仅优化估计的目标值，还优化政策相对于收集数据时使用的观测策略在统计上显著更好的几率。本文还从数学上界定了这两个目标之间的帕累托前沿，并据此设计了一种使用机器学习预测反事实结果，然后估计帕累托前沿的算法，使决策者可以根据其所需的权衡来选择策略。
### Conclusion
最后，通过模拟说明了该方法的有效性。该方法能够在保持常规测试集策略评估的同时，解决传统策略优化中获胜者诅咒的问题，从而提供更具统计显著性的政策比试策略。
## 845. `cs.LG` - AgentChangeBench：用于对话式人工智能目标切换稳健性的多维度评估框架 [PDF](https://arxiv.org/pdf/2510.18170), [HTML](https://arxiv.org/abs/2510.18170)
### Authors
Manik Rana,Calissa Man,Anotida Expected Msiiwa,Jeffrey Paine,Kevin Zhu,Sunishchal Dev,Vasu Sharma,Ahan M R
### Background
当前的智能代理基准主要评估静态目标或单次工具使用，忽视了现实生活中的多轮交互中目标的变化这一关键特性。为了填补这一空白，该研究引入了一个名为AgentChangeBench的新基准，专门用于衡量增强工具的语言模型代理在三个企业领域内对话过程中的目标变动适应性
### Innovation
研究通过四个互补的度量标准（任务成功率、工具使用效率、工具调用冗余率和目标变动恢复时间）来正式化评估：1）提出了一个包含2835个任务序列和五个用户角色的新框架，设计用于在持续工作中触发实际的目标变化点；2）评估了多个前沿模型，揭示了传统的$text{pass}@k$分数难以展示的显著差异；3）通过具体案例展示了在动态目标下的高准确率并不等同于稳健性，从而强调了度量恢复时间和冗余的重要性
### Conclusion
AgentChangeBench建立了一个可重复的测试平台，用于诊断和改善代理在现实企业环境中的鲁棒性和适应性。
## 846. `cs.LG` - 使用多任务多尺度网络联合估计钢琴动态和节拍结构 [PDF](https://arxiv.org/pdf/2510.18190), [HTML](https://arxiv.org/abs/2510.18190)
### Authors
Zhanhong He,Hanyu Meng,David Huang,Roberto Togneri
### Background
从音频记录中估计钢琴动态是计算音乐分析中的基本挑战。本文提出了一种高效的多任务网络，该网络可以从共享的潜在表示中联合预测动态级别、变化点、节拍和小节拍，这四个目标组成了音乐谱中的动态结构。
### Innovation
本文使用多尺度网络作为骨干，以 Bark 规模特异性响度作为输入特征，相比使用 log-Mel，这降低了模型大小，从 14.7 M 缩减至 0.5 M，使得可以处理长序列输入。此外，音频分割使用 60 秒的音频长度，将节拍跟踪通常使用的长度翻倍。在公共 MazurkaBL 数据集上，本文模型在所有任务上达到了最先进的结果，为钢琴动态估计设置了一个新的基准，并提供了一个强大且紧凑的工具，为大规模、资源高效的音乐表达分析铺平了道路。
### Conclusion
本文提出的多任务多尺度网络在钢琴动态估计方面取得了最先进的结果，设置了一个新的基准，并展现了在音乐表达分析中的潜力。
## 847. `cs.LG` - Saber: 一种用于扩散语言模型的高效自适应加速和回溯增强屏蔽的采样算法 [PDF](https://arxiv.org/pdf/2510.18165), [HTML](https://arxiv.org/abs/2510.18165)
### Authors
Yihong Dong,Zhaoyu Ma,Xue Jiang,Zhiyuan Fan,Jiaru Qian,Yongmin Li,Jianha Xiao,Zhi Jin,Rongyu Cao,Binhua Li,Fei Huang,Yongbin Li,Ge Li
### Background
扩散语言模型（DLMs）作为生成文本的强大替代方案，具有并行生成和双向上下文建模的优势。然而，与具有更强结构约束的代码生成任务相比，DLMs在性能上受到了在推断速度和输出质量之间权衡的限制。以往通过减少采样步骤来加速代码生成通常会导致性能灾难性下降。因此，如何在保持高质量输出的前提下提高推断速度是当前研究的挑战。本文探讨了在代码生成任务中如何利用DLMs的固有优势，通过引入一种新的训练无损的采样算法（Saber），实现高效和高质量的代码生成。
### Innovation
Saber算法具有两个关键洞察：1）代码上下文更多信息建立后能够自适应加速；2）需要回溯机制来撤销生成的标记。实验表明，Saber在主流代码生成基准测试中平均提高了1.9%的Pass@1精度，同时平均提高了251.4%的推理速度。通过利用DLMs的固有优势，本研究显著缩小了与自回归模型在代码生成任务中的性能差距。
### Conclusion
Saber算法通过自适应加速机制和回溯增强的屏蔽机制，为DLMs在代码生成任务中的高效且高质量采样提供了新的解决方案，显著提升了性能并缩小了与自回归模型的差距。
## 848. `cs.LG` - RESCUE: Retrieval Augmented Secure Code Generation [PDF](https://arxiv.org/pdf/2510.18204), [HTML](https://arxiv.org/abs/2510.18204)
### Authors
Jiahao Shi,Tianyi Zhang
### Background
尽管近期取得了进展，大型语言模型（LLMs）仍然生成易受攻击的代码。检索增强生成（RAG）可以通过结合外部安全知识来增强LLMs的安全代码生成能力。然而，传统的RAG设计难以处理原始安全相关文档中的噪声，并且现有的检索方法忽略了任务描述中隐含的重要安全语义。
### Innovation
我们提出了一种名为RESCUE的新RAG框架，具有两个关键创新点。首先，我们提出了一种混合知识库构建方法，结合了LLM辅助的聚类-总结迁移学习与程序切片，生成高层级的安全指导方针和简洁、专注于安全的代码示例。其次，我们设计了一种分层多方面的检索方法，从知识库上层向下遍历，并在每级分层中整合多个安全关键事实，确保全面准确的检索。
### Conclusion
我们对RESCUE进行了四组基准测试，并在六种LLMs上与五种最先进的安全代码生成方法进行了比较。结果表明，RESCUE将SecurePass@1指标提高了平均4.8个百分点，确立了新的安全性能最佳实践。此外，我们进行了深入分析和消融研究，以严格验证RESCUE各个组件的有效性。
## 849. `cs.LG` - VLSU：联合多模态理解的边界在AI安全上的映射 [PDF](https://arxiv.org/pdf/2510.18214), [HTML](https://arxiv.org/abs/2510.18214)
### Authors
Shruti Palaskar,Leon Gatys,Mona Abdelrahman,Mar Jacobo,Larry Lindsey,Rutika Moharir,Gunnar Lund,Yang Xu,Navid Shiee,Jeffrey Bigham,Charles Maalouf,Joseph Yitan Cheng
### Background
现有的多模态基础模型在评估安全性时通常将视觉和语言输入分开处理，忽略了联合解释带来的风险。现有方法未能明确区分不安全内容与模糊情况，导致过度拦截或不足拒绝真正有害的内容。该研究构建了一个全面的框架，通过精细的严重性分类和跨17种不同的安全模式的组合分析，系统地评估多模态安全性。
### Innovation
提出了一种名为Vision Language Safety Understanding (VLSU)的框架，用于通过细粒度的安全性分类和组合分析系统地评估多模态安全性。使用多阶段流水线和实际图像及人工标注构建了包含8,187个样本的大规模基准数据集，涵盖15种危害类别。结果显示，尽管模型在单一模态的安全信号上表现准确，但在需要联合图像-文本推理确定标签时，性能显著下降，最多降至20-55%。此外，这些模型难以在拒绝不安全内容的同时应对需要关注的边缘案例。
### Conclusion
研究揭示了多模态图像-文本理解的弱点，并暴露出当前模型在联合理解及对齐方面存在的差距，提供了一个关键的测试平台，以推动多模态视觉-语言安全研究的下一步进展。
## 850. `cs.LG` - LIME：基于链接的用户-项目相互作用建模与解耦XOR注意力机制以实现高效测试时扩展 [PDF](https://arxiv.org/pdf/2510.18239), [HTML](https://arxiv.org/abs/2510.18239)
### Authors
Yunjiang Jiang,Ayush Agarwal,Yang Liu,Bi Xue
### Background
构建大规模推荐系统需要解决三个主要问题：处理更长的用户历史、扩展候选集以及增加模型容量。虽然变压器表现出了良好的性能，但它们的计算成本随用户序列长度呈平方级增长，且随候选集数量呈线性增长。这意味着在推理时扩大候选集或增加序列长度会变得非常昂贵，尽管这能显著提高性能。
### Innovation
LIME 提出了两项创新：1）低秩“链接嵌入”允许预先计算注意力权重，通过解耦用户与候选物之间的相互作用，使得推理成本几乎与候选集大小无关；2）线性注意力机制 LIME-XOR 将与用户序列长度的复杂度从平方级(O(N^2))减少到线性级(O(N))。
### Conclusion
LIME 在公共和工业数据集上，实质上达到了最新的变压器模型的性能，但推理速度在大型候选集或长序列长度时提高了10倍。在主要推荐平台上测试时，LIME 保持了用户参与度，同时在候选集大小和用户历史长度方面保持着较低的推理成本，标志着高效和表达性推荐系统的全新范式。
## 851. `cs.LG` - 幻觉中的反省：开放任务揭示大规模语言模型反省推理中的系统性失败 [PDF](https://arxiv.org/pdf/2510.18254), [HTML](https://arxiv.org/abs/2510.18254)
### Authors
Sion Weatherhead,Flora Salim,Aaron Belbasis
### Background
当前的大规模语言模型（LLMs）在生成推理文本和‘反射’文本方面表现出色，但这类模型在实际应用中的表现离人类的反思性推理仍有差距。以往关于闭合任务的研究夸大了模型的自我修正能力，遮蔽了内在局限性。文章通过一个简单而真实世界的、开放却不闭合定则约束的任务来检验模型的反省能力，以期得出更全面的结论。
### Innovation
文章设计了一个开放且有规则约束的实际任务，用于评估大型语言模型的反省机制。这种方法能更贴近人类实际工作场景，揭示模型在开放任务中的失败模式，不同以往闭合任务的研究方法。实验结果显示，尽管模型第一次尝试表现不佳，但反思后的表现只能带来微小提升，并且频繁出现同样的规则违背，表明‘矫正收益’很大程度上来源于偶然性，而不是错误检测和基于规则的、敏感的修复。
### Conclusion
文章的结论是，当前的大规模语言模型的‘反省’机制缺乏功能上的证据，证明其具有帮助人类在初次尝试时即遵守规则的主动、目标驱动的监控机制。没有这些机制，在开放任务中表现出色的能力依赖于外部结构对规则的强制执行。
## 852. `cs.LG` - 数据驱动优化中的偏差方差权衡：局部偏差视角 [PDF](https://arxiv.org/pdf/2510.18215), [HTML](https://arxiv.org/abs/2510.18215)
### Authors
Haixiang Lan,Luofeng Liao,Adam N. Elmachtoub,Christian Kroer,Henry Lam,Haofeng Zhang
### Background
数据驱动的随机优化在机器学习和运营决策问题中无处不在。样本平均近似（SAA）和基于模型的方法（如估计-优化（ETO）或集成估计-优化（IEO））都是常见的方法。基于模型的方法在处理复杂情境依赖性问题时能够绕过SAA的一些局限性，但这些方法的相对性能尚未被充分理解，大多数研究结果仅限于模型完全指定或未指定的二元情况。本文通过应用统计中连续性理论工具，首次探讨了在局部偏差环境下这些方法的相对表现，表明在局部偏差条件下，SAA、IEO和ETO之间存在偏差-方差权衡，偏差和方差的重要程度与局部偏差的程度有关。另外，本文推导出了决策偏差的显式表达式，进一步阐明了偏差的方向和方差的几何意义。
### Innovation
本文首先通过使用统计中的连续性理论工具，研究了局部偏差环境下数据驱动优化方法的相对表现，揭示了SAA、IEO和ETO之间的偏差-方差权衡，并指出了偏差和方差的重要性取决于局部偏差的程度。进一步地，推导出决策偏差的显式表达式，确定了（无）影响的偏差方向，并提供了对方差的进一步几何理解。
### Conclusion
本研究确认了在局部偏差条件下，SAA、IEO和ETO之间的偏差-方差权衡，并区分了影响和不重要偏差方向，对于理解这些常用优化方法的相对性能有重要意义。
## 853. `cs.LG` - 在不平衡信贷评分中使用ADASYN寻找黄金分割点：最优数据增强比率 [PDF](https://arxiv.org/pdf/2510.18252), [HTML](https://arxiv.org/abs/2510.18252)
### Authors
Luis H. Chia
### Background
信用评分模型面临严重的小样本类别不平衡问题，违约率通常低于10%，这阻碍了模型的学习和预测性能。尽管SMOTE和ADASYN等合成数据增强技术被提出解决这一问题，但最佳增强比率仍然不清楚，许多实践者使用全平衡（1:1比率）但缺乏实验证据支持。
### Innovation
本研究系统地评估了Give Me Some Credit数据集（97,243个观察值，7%的违约率）下的10种数据增强场景，比较了不同乘法因子（1倍、2倍、3倍）的SMOTE、BorderlineSMOTE和ADASYN，并使用XGBoost进行模型训练和测试集上的评估。实证研究表明，采用ADASYN 1倍乘法因子（将少数类加倍）可获得最佳性能，相关性指标AUC为0.6778，Gini系数为0.3557，显示出统计学上的显著改进（P=0.017）。
### Conclusion
本研究提供了首个关于在不平衡数据集中使用数据增强的理想“黄金分割点”的实验证据，并为研究者和从业者提供了操作指南。虽然研究是在单个代表性数据集上进行的，但研究方法为其他不平衡领域的最优增强比率确定提供了一个可重复的框架。
## 854. `cs.LG` - 高维线性回归中的量化学习 [PDF](https://arxiv.org/pdf/2510.18259), [HTML](https://arxiv.org/abs/2510.18259)
### Authors
Dechen Zhang,Junwei Su,Difan Zou
### Background
低比特量化技术因其在大规模模型高效训练中的普遍应用和实际需求而变得不可或缺。尽管它在实践中取得了显著的成功，但在理论层面上对其对学习性能的影响仍缺乏严谨的理解，即使在简单的线性回归场景也是如此。因此，本文首次从理论角度系统地探讨了这一基本问题，分析了在高维线性回归中，有限步随机梯度下降（SGD）方法在定量目标（数据、标签、参数、激活和梯度）下的表现。通过这一创新性的分析框架，证明了参数量化、激活量化和梯度量化在训练过程中增加了噪声，数据量化影响了数据的光谱分布，而数据和标签量化引入了额外的近似和量化误差。此外，文中还证明了对于乘法量化（输入依赖的量化步长），光谱失真可以消除；而对于加法量化（常数量化步长），提高了随批次大小变化的有益效果。针对常见的多项式衰减数据光谱，本文量化比较了乘法量化和加法量化的风险，与浮点量化和整数量化方法的比较得到了类似的结论。
### Innovation
本文首次对量化对高维线性回归中学习性能的影响进行了系统的理论研究，分析了在多种量化目标下的表现。作者提出了一个新颖的分析框架，建立了一些精确的算法依赖和数据依赖的过剩风险界，量化影响了学习过程的各个方面。此外，证明了对于某种量化方法，光谱失真可以避免，而在其他方法中出现有益的批次大小效应。通过这些理论结果，可以更好地理解量化如何塑造优化算法的学习动力学，为进一步探索在实际硬件限制下的学习理论提供了指导
### Conclusion
本文的研究为我们理解量化在优化算法学习中的作用提供了有力的工具，并为在实际硬件约束条件下进一步探索学习理论铺平了道路。通过比较不同的量化方法，本文还为数值比较提供了新的视角。
## 855. `cs.LG` - 分布式GPU跟踪性能变异因果建模框架 [PDF](https://arxiv.org/pdf/2510.18300), [HTML](https://arxiv.org/abs/2510.18300)
### Authors
Ankur Lahiry,Ayush Pokharel,Banooqa Banday,Seth Ockerman,Amal Gueroudji,Mohammad Zaeed,Tanzima Z. Islam,Line Pouchard
### Background
大型GPU跟踪在识别异构HPC架构中的性能瓶颈方面发挥着关键作用。然而，单个跟踪数据的巨大体积和复杂性使得性能分析既耗时又计算成本高昂。
### Innovation
本文提出了一种端到端的并行性能分析框架，能够高效处理多个大型GPU跟踪数据。该框架通过同时分区和处理跟踪数据，采用因果图方法和并行协调图来揭示执行流之间的性能变异性与依赖关系。
### Conclusion
实验结果表明，该框架在扩展性方面改进了67%，证明了其独立分析多个跟踪的有效性。
## 856. `cs.LG` - AGI定义 [PDF](https://arxiv.org/pdf/2510.18212), [HTML](https://arxiv.org/abs/2510.18212)
### Authors
Dan Hendrycks,Dawn Song,Christian Szegedy,Honglak Lee,Yarin Gal,Erik Brynjolfsson,Sharon Li,Andy Zou,Lionel Levine,Bo Han,Jie Fu,Ziwei Liu,Jinwoo Shin,Kimin Lee,Mantas Mazeika,Long Phan,George Ingebretsen,Adam Khoja,Cihang Xie,Olawale Salaudeen,Matthias Hein,Kevin Zhao,Alexander Pan,David Duvenaud,Bo Li,Steve Omohundro,Gabriel Alfour,Max Tegmark,Kevin McGrew,Gary Marcus,Jaan Tallinn,Eric Schmidt,Yoshua Bengio
### Background
目前对人工通用智能（AGI）缺乏明确的定义，这导致了今天专门化的AI与人类水平的认知能力之间的差距难以界定。本文提出了一个可量化的框架来解决这一问题，将AGI定义为与受过良好教育的成年人的认知多样性与专业水平相匹配。该框架基于Cattell-Horn-Carroll理论，这是人类认知的最实证验证模型，将一般智能分解为核心认知领域（如推理、记忆和感知），并调整了现有的人类心理测量工具来评估AI系统的表现。应用该框架显示，当前模型的认知能力存在显著的'锯齿状'特征：尽管在知识密集型领域表现良好，但现有AI系统在基础认知机制，特别是长期记忆存储方面存在关键缺陷。
### Innovation
引入了一个基于Cattell-Horn-Carroll理论的量化框架，将AGI定义为与受过良好教育的成年人的认知多样性与专业水平相匹配，并将其分解为核心认知领域，使用现有的心理测量工具来评估AI系统的性能。通过这种方法揭示了当前AI系统的认知能力的显著差异，特别是在长期记忆存储方面的关键缺陷。
### Conclusion
该框架下的AGI评分（例如，GPT-4得分为27%，GPT-5得分为58%），不仅量化了当前AI系统的快速进步，还揭示了实现AGI的显著差距。
## 857. `cs.LG` - 训练集的异质性诱导能力参数化及其对监督学习的影响 [PDF](https://arxiv.org/pdf/2510.18332), [HTML](https://arxiv.org/abs/2510.18332)
### Authors
Gargi Roy,Dalia Chakrabarty
### Background
当前的学习方法往往假设函数模型与训练数据之间的关系是均匀的。然而，某些数据集可能表现出异质的相关结构，即函数模型随数据变化，这需要非均匀的方法来建模。本文讨论了这种需要非均匀建模的数据集的参数化方法。
### Innovation
提出了“异质性参数”来参数化训练集的属性，该属性意味着学习得到的函数必须具备非均匀的相关结构，即使数据集整体并非非均匀变化。这为处理特定数据结构提供了新的参数化方法。
### Conclusion
非零异质性参数的存在迫使我们必须使用非站稳的模型过程去建模所求的函数程序。通过使用基于概率高斯过程的学习方法，训练数据的异质性参数对在测试输入上的预测质量与可靠性产生了影响。
## 858. `cs.LG` - 高效少量样本保持身份的属性编辑用于面向3D的深度生成模型 [PDF](https://arxiv.org/pdf/2510.18287), [HTML](https://arxiv.org/abs/2510.18287)
### Authors
Vishal Vinod
### Background
身份保留的面部修改是生成任务，可以修改光照、添加/移除眼镜、面部老化、编辑发型、修改表情等，同时保持面部身份。近期进展表明，2D生成模型可以通过GANs中的组成性利用来实现逼真的面部修改。然而，对于给定属性的3D面部保持身份的修改是一个具有挑战性的任务，因为生成模型必须在多个姿态下推理视图一致性，并渲染真实的3D面部。此外，3D人物肖像编辑需要大规模属性标记的数据集，平衡低分辨率的易于编辑性和高分辨率的不灵活编辑性。
### Innovation
本文提出了一种方法，结合了3D感知的深度生成模型和2D人物肖像编辑技术，实现了针对3D感知生成模型的高效少量样本保持身份的属性编辑。实验结果表明，只需要少量的带有标签的图像（比如10张或更少）就能估计出与3D感知属性编辑对应的潜在空间编辑方向。为了证明修改的线性关系，通过逐步编辑来实现一次编辑，使用（2D）属性风格操控（ASM）技术探索出在保持一致身份的3D风格连续流形。
### Conclusion
本文通过利用现有的带有掩码的脸部数据集获得所需的合成图像，以估计少量属性示例中的编辑方向。进一步证明了通过逐步编辑实现一次编辑，并使用（2D）属性风格操控（ASM）技术研究了在保持一致身份的3D风格连续流形中，实验结果和代码结果可在提供的链接中查看。
## 859. `cs.LG` - ECG-LLM——电生理领域特定大型语言模型的训练与评估 [PDF](https://arxiv.org/pdf/2510.18339), [HTML](https://arxiv.org/abs/2510.18339)
### Authors
Lara Ahrens,Wilhelm Haverkamp,Nils Strodthoff
### Background
域适应的开源权重大型语言模型（LLMs）在健康医疗领域展现出巨大的应用前景，从可查询的知识库到多重模态助手，其关键优势在于本地部署以保护隐私。然而，最优的适应策略、评估方法以及与通用LLMs性能的相对表现尚未充分研究。本文在心血管医学中重要的电生理学领域，通过在特定领域文献上微调开源权重模型并实施多层次评估框架，比较微调模型、检索增强生成（RAG）和Claude Sonnet 3.7（作为一般用途模型的代表），以回答这些问题。
### Innovation
提出了电生理领域特定的大型语言模型（ECG-LLM）的训练与评估方法，通过微调开源权重模型和实施多层次评估框架，实现了与商业模型相近的性能。此方法有助于开发具备隐私保护且本地部署的临床解决方案。
### Conclusion
研究表明，在不同的评估方法中，性能表现存在显著差异，但特定领域的微调和检索增强生成（RAG）方法与专有模型竞争表现出色，支持了保护隐私并能本地部署的临床解决方案的可行性。
## 860. `cs.LG` - MoMaGen: 在多步骤双臂移动操作演示中根据软性与硬性约束生成演示 [PDF](https://arxiv.org/pdf/2510.18316), [HTML](https://arxiv.org/abs/2510.18316)
### Authors
Chengshu Li,Mengdi Xu,Arpit Bahety,Hang Yin,Yunfan Jiang,Huang Huang,Josiah Wong,Sujay Garlanka,Cem Gokmen,Ruohan Zhang,Weiyu Liu,Jiajun Wu,Roberto Martín-Martín,Li Fei-Fei
### Background
从大规模多样的人类演示中进行模仿学习已被证明对训练机器人有效，但此类数据的收集既耗时又昂贵。这种挑战在涉及双臂移动操作的多步骤任务中尤为突出，因为人类必须同时远程操作移动基座和两个高自由度的臂部。现有的自动化数据生成框架虽然在静态双臂操作中通过模拟增强少量的人类演示取得了进展，但对于涉及移动的场景，由于两个主要问题（确定基座位置以确保可达性，以及定位摄像头以提供足够的可见性）而未能给出满意的解决方案。本文研究旨在解决这些挑战，从而促进机器人操作的自动化数据生成及其应用。
### Innovation
本文提出了一种名为MoMaGen的方法，该方法将数据生成问题表述为一个带有约束的优化问题，不仅满足硬性约束（如可达性）还平衡了软性约束（如导航期间的可见性）。这种方法具有广泛的通用性，并为未来的方法提供了结构性的基础。MoMaGen在四个多步骤双臂移动操作任务中进行了评估，结果显示，相比现有方法，它生成了更为多样化的数据集。这些多样化的数据集可以让从单一来源演示中训练成功模仿学习策略，且仅需40个实际展示即可实现对物理机器人硬件的部署。
### Conclusion
MoMaGen能够显著提高多步骤双臂移动操作任务中数据生成的多样性和成功率，为后续相关研究提供了理论和实践上的支持。这一方法显著简化了数据收集和操作训练的过程，具有广泛的应用前景。
## 861. `cs.LG` - FST.ai 2.0: 用于奥运和残奥跆拳道公平、快速和包容性决策的可解释AI生态系 [PDF](https://arxiv.org/pdf/2510.18193), [HTML](https://arxiv.org/abs/2510.18193)
### Authors
Keivan Shariatmadar,Ahmad Osman,Ramin Ray,Usman Dildar,Kisam Kim
### Background
在奥运会和残奥会的搏击运动中，公平、透明和可解释的决策制定仍然是一个关键挑战。该论文介绍了FST.ai 2.0，这是一种可解释的人工智能生态系统，旨在支持跆拳道比赛中和训练期间裁判、教练和运动员的实时决策支持。该系统结合了基于姿态的行动识别、通过区间集合建模的表征不确定性以及可解释图层以支持视觉决策。该系统经过实验验证，在比赛中减少了85%的决策审查时间，裁判对AI辅助决策的可信度达到了93%。该框架建立起了一条透明且可扩展的可信数据驱动的裁判和运动员评估管道。
### Innovation
FST.ai 2.0 汇集了基于姿态的动作识别、通过区间集合建模的不确定性以及可解释的图层，以支持实时决策。该系统还包括用于裁判培训、公平监控和政策级分析的模块，并扩展了实时感知、可解释推理和意识治理设计的桥梁，使其成为朝着公平、可问责和以人为本的人工智能在体育中的应用的重要一步。
### Conclusion
FST.ai 2.0 构建了一个透明且可扩展的管道，以实现可信的数据驱动裁判和运动员评估。该框架通过将实时感知、可解释推理和意识治理设计相结合，代表了体育领域中公平、可问责和以人为本的人工智能的重要一步。
## 862. `cs.LG` - PGTT: 通过相位引导实现感知下肢移动的地形穿越 [PDF](https://arxiv.org/pdf/2510.18348), [HTML](https://arxiv.org/abs/2510.18348)
### Authors
Alexandros Ntagkas,Chairi Kiourt,Konstantinos Chatzilygeroudis
### Background
目前，最先进的感知强化学习控制器对于腿足机器人either(i)施加振荡器或逆运动学(IK)基础的步态先验，从而限制动作空间、偏移策略优化并对不同机器人形态缺乏适应性，或者(ii)处于“盲视”状态，难以预见后腿地形，且对噪声敏感。
### Innovation
本文提出了一种感知导向的深度强化学习方法——相位引导地形穿越（PGTT），通过奖励调整来强化步态结构，从而减少策略学习中的归纳偏见，相比振荡器/IK条件的动作先验有优势。PGTT通过在各腿相位的三次海梅斯插值来调整摆动高度以适应当地高度图统计信息，并添加相位接触惩罚，同时策略直接作用于关节空间，支持形态无关部署。PGTT在MuJoCo (MJX)上以逐级生成的梯形地形训练，结合领域随机化，其在扰动干扰下实现最高成功率，并在放置离散障碍物时表现更好，同时实现类似的速度跟踪，并比强大的端到端基线快速收敛约两倍。
### Conclusion
PGTT的实验结果验证了其在Unitree Go2和ANYmal-C上的有效性，表明地形适应相位引导奖励调整是一种简单且普遍适用的机制。
## 863. `cs.LG` - S2AP: 在判分空间中最小化判分空间尖锐性以进行对抗剪枝 [PDF](https://arxiv.org/pdf/2510.18381), [HTML](https://arxiv.org/abs/2510.18381)
### Authors
Giorgio Piras,Qi Zhao,Fabio Brau,Maura Pintor,Christian Wressnegger,Battista Biggio
### Background
对抗剪枝方法作为一种压缩神经网络同时保持对对抗攻击的鲁棒性的强大工具已出现。这些方法通常遵循三个步骤：首先预训练一个鲁棒模型；然后选择用于权重剪枝的二元掩码；最后微调剪枝后的模型。在选择掩码时，通过计算每个权重的重要性得分并选择最高得分的权重来最小化鲁棒损失。然而，这种得分空间的优化可能会在鲁棒损失景观中产生尖锐的局部最小值，从而导致掩码选择不稳定，从而降低对抗剪枝方法的鲁棒性。
### Innovation
提出了一个新的用于对抗剪枝的插件方法，称为分数空间尖锐性感知对抗剪枝（S2AP）。通过该方法引入了分数空间尖锐性最小化的概念，在寻找掩码时，通过改变重要性得分并最小化相应的鲁棒损失来产生扰动。
### Conclusion
在各种数据集、模型和稀疏级别的广泛实验表明，S2AP能够有效最小化分数空间的尖锐性，稳定掩码选择，最终提高对抗剪枝方法的鲁棒性。
## 864. `cs.LG` - SPIKE: 稳定的物理信息核演变方法用于求解双曲守恒律 [PDF](https://arxiv.org/pdf/2510.18266), [HTML](https://arxiv.org/abs/2510.18266)
### Authors
Hua Su,Lei Zhang,Jin Zhao
### Background
介绍了用于计算无粘双曲守恒律的稳定物理信息核演变（SPIKE）方法。该方法解决了强形式残差最小化如何捕捉包含间断的弱解的基本悖论。传统的残差最小化方法难以处理包含间断的弱解，而SPIKE方法通过使用正则化核表示方法并结合Tikhonov正则化，实现了通过冲击波形成进行平滑过渡，使得动态过程能够穿越冲击波奇点。这种方法自动保持守恒性、追踪特征，并在一框架内捕捉满足Rankine-Hugoniot条件的冲击波，无需显式冲击波检测或人工粘性。验证结果表明，该方法在标量和向量值守恒律方面具有有效性。
### Innovation
SPIKE方法通过正则化参数演变和Tikhonov正则化，实现平稳过渡机制，允许动态过程穿越冲击波奇点。这种方法自动保持守恒性、追踪特征，能够捕捉满足Rankine-Hugoniot条件的冲击波，无需显式冲击波检测或人工粘性。
### Conclusion
SPIKE方法通过构造特殊的核函数和正则化技术成功解决了传统方法难以处理的包含间断的弱解问题，能够在统一框架下自动保持守恒，追踪特征并捕捉冲击波，且通过数值验证显示了其在不同类型守恒律问题中的有效性。
## 865. `cs.LG` - 通过基于文本的检索增强生成实现零样本车型识别 [PDF](https://arxiv.org/pdf/2510.18502), [HTML](https://arxiv.org/abs/2510.18502)
### Authors
Wei-Chia Chang,Yan-Ann Chen
### Background
车辆品牌和型号识别（VMMR）是智能交通系统中的重要任务，但现有方法难以适应新发布的车型。虽然Contrastive Language-Image Pretraining (CLIP) 提供了强大的视觉和文本对齐，但其固定预训练权重限制了其性能，需要进行昂贵的图像特定微调。
### Innovation
本文提出了一种将视觉语言模型（VLMs）与检索增强生成（RAG）相结合的管道，通过基于文本的推理支持零样本识别。通过VLM将车辆图像转换为描述性属性，与文本特征数据库进行比较。相关条目检索并结合描述形成提示，语言模型（LM）推断出车型。
### Conclusion
实验表明，所提出的方法在车型识别上比CLIP基线提高了近20%，证明了增强的LM推理在智能城市应用中实现可扩展VMMR的潜力。
## 866. `cs.LG` - 一种用于自验证热电偶的自动化及不确定性评估的机器学习方法 [PDF](https://arxiv.org/pdf/2510.18411), [HTML](https://arxiv.org/abs/2510.18411)
### Authors
Samuel Bilson,Andrew Thompson,Declan Tucker,Jonathan Pearce
### Background
工业中普遍使用热电偶，但在恶劣环境中容易出现校准漂移。自验证热电偶可以通过在热电偶测量端附近植入一个微型相变细胞（固定点）来解决这个问题。固定点是一种包含已知熔点金属铸锭的坩埚。当监控的工艺温度通过金属铸锭的熔点时，热电偶输出会表现出“平台期”现象。由于已知金属铸锭的熔点，热电偶可以在现场重新校准。然而，识别出熔点平台来确定熔点的开始需要手工介入，这一过程依赖于熔点平台的形状。
### Innovation
首次提出了一种新的机器学习方法，用于识别和识别熔点平台的特征形状，并在识别后量化熔点开始的点及其相关的不确定性。这种方法消除了在定位和表征熔点时的人工干预需求。测试数据表明，该方法100%准确地检测出熔点平台，并且在预测校准漂移方面表现出99%的校准校验。
### Conclusion
通过利用机器学习方法，自动识别和量化熔点平台，该研究为自验证热电偶提供了改进的自动化流程和更高的预测准确性，减少了人工干预的需求，提高了系统的可靠性和精确性。
## 867. `cs.LG` - 数学领域中RLVR踪迹的局部连贯性与全局有效性 [PDF](https://arxiv.org/pdf/2510.18176), [HTML](https://arxiv.org/abs/2510.18176)
### Authors
Soumya Rani Samineni,Durgesh Kalwar,Vardaan Gangal,Siddhant Bhambri,Subbarao Kambhampati
### Background
已有的强化学习与验证奖励（RLVR）方法通过后训练大型语言模型（LLMs）已经在推理任务中展示了更高的准确性，并且仍然受到广泛关注。然而，现有的RLVR方法通常对所有令牌处理方式相同，没有考虑到每个令牌的优势。这些方法主要基于最终答案的正确性和Pass@K准确度来评估性能，却声称RL后训练可以提高推理过程。为了更深入地研究这种现象，该研究采用了基于GRPO算法设计了实验，并使用Qwen-2.5-0.5B模型在GSM8K数据集上研究了RL后训练对非直接激励的中间令牌的影响。研究根据一阶逻辑（FOL）提出了推理步骤的一致性（trace coherence）衡量标准，以识别推理过程中的错误。研究区分了推理步骤的有效性和一致性，有效性和全局一致性分别对应逻辑合理性和局部连贯性缺乏错误。实验结果表明，RL后训练整体提高了推理过程的局部连贯性，特别是在基模型失败而RL模型成功的问题上提升显著。然而，RL增强了局部连贯性，却不一定能够产生有效的或正确的解决方案，并且局部连贯性提高不一定意味着最终答案的正确性。
### Innovation
该研究提出了一个新的衡量标准——trace coherence，以评估推理过程中局部连贯性，区分了局部连贯性与全局有效性，并设计了一个实验来研究RL后训练对非直接激励的中间令牌的影响。通过这种方式，该研究提供了一个关于加强学习与验证奖励在数学领域的推理进程中的新视角，强调了局部连贯性与全局有效性之间的区别。
### Conclusion
研究表明，尽管RL后训练能够在提高推理步骤的局部连贯性方面取得进展，但它并不能保证最终答案的正确性。因此，通过强化学习提高推理过程的有效性这一说法需要仔细评估，因为这种改善可能只是基于局部连贯性的提高，而这种提升并不能完全转化为有效的数学证明。
## 868. `cs.LG` - 视觉基础模型可以成为潜扩散模型的有效词化器 [PDF](https://arxiv.org/pdf/2510.18457), [HTML](https://arxiv.org/abs/2510.18457)
### Authors
Tianci Bi,Xiaoyi Zhang,Yan Lu,Nanning Zheng
### Background
潜扩散模型（LDMs）的表现高度依赖于其视觉词化器的质量。近期的研究通过蒸馏的方法尝试将视觉基础模型（VFMs）融入到LDMs中，虽然取得了一定的效果，但研究者发现这种方法存在一个根本性的缺陷：即它不可避免地削弱了与原始VFMs对齐的鲁棒性，在分布变迁时会导致语义上偏离。
### Innovation
本文提出了一种更为直接的方法：视觉基础模型变分自编码器（VFM-VAE），通过Multi-Scale Latent Fusion和Progressive Resolution Reconstruction模块重新设计VFM-VAE解码器，实现了从空间粗糙特征进行高质量重构。此外，本文还通过详细的扩散训练中表示动态分析提出了SE-CKNNA评估指标，并据此提出了联合词化器-扩散对齐策略，显著提高了模型收敛速度。这种方法不仅提高了性能效率，在80个epoch内达到了无条件自由生成指数（gFID，无条件自由生成）2.20的性能，相较于之前的词化器快了10倍。继续训练至640个epoch后，gFID达到了1.62。
### Conclusion
本文通过改进词化器设计和训练策略，在保持模型质量基础上，显著提高了效率：系统在80个epoch内达到了gFID（无条件自由生成指数，无条件自由生成）2.20，继续训练至640个epoch后，gFID达到了1.62。这表明直接将VFMs集成到LDMs中是较为优越的方法。
## 869. `cs.LG` - 大规模语言模型的可引导式多元价值对齐的反事实推理 [PDF](https://arxiv.org/pdf/2510.18526), [HTML](https://arxiv.org/abs/2510.18526)
### Authors
Hanze Guo,Jing Yao,Xiao Zhou,Xiaoyuan Yi,Xing Xie
### Background
随着大规模语言模型（LLMs）在多种文化和社区中被广泛应用，确保这些模型与多元的人类价值观（如超出HHH等一般原则）保持一致变得至关重要。现有的方法面临两个挑战：首先，它们往往将多元价值观视为互不相关的等重要性，忽视了它们之间的相互依赖性和相对优先级；其次，它们难以精确控制细微的价值优先级，尤其是那些未充分代表的价值优先级。这一背景下，该研究旨在解决这些挑战。
### Innovation
该研究提出了COUPLE框架，这是一种为多元价值观对齐设计的反事实推理框架。通过引入结构因果模型（SCM），它能够更好地表示特征间的复杂相互依赖和优先级，并建立高层次价值维度与行为之间的因果关系。此外，该框架利用反事实推理生成与特定价值目标相匹配的输出，从而提升模型的引导性。COUPLE框架还能够提供更明确的因果模型解释，提升模型的可理解性。
### Conclusion
该研究通过COUPLE框架在两个具有不同价值体系的数据集上进行了评估，结果显示COUPLE在多种多元价值目标上优于其他基准方法。
## 870. `cs.LG` - 通过高维空间数据量化随机森林进行地方道路年度平均日交通量的区间预测 [PDF](https://arxiv.org/pdf/2510.18548), [HTML](https://arxiv.org/abs/2510.18548)
### Authors
Ying Yao,Daniel J. Graham
### Background
准确的年度平均日交通量（AADT）数据对于交通规划和基础设施管理至关重要。然而，国家道路网络中的自动交通检测器通常覆盖不完整，导致次要道路的代表性不足。尽管最近的机器学习进步已经提高了未测量位置的AADT估算，大多数模型仅提供点预测，而不考虑预测不确定性。鉴于此，该研究通过对未测量位置引入区间预测方法来填补这一空白，该方法明确量化了预测不确定性。
### Innovation
该研究创新性地结合了Quantile Random Forest模型与Principal Component Analysis，以生成AADT的预测区间，界定出估计的最小值和最大值，提供了一种更准确和可解释的AADT估算方法。使用英格兰和威尔士超2000条次要道路的数据，并通过专门的区间评价指标进行验证，这种方法实现了88.22%的区间覆盖率、0.23的标准化平均宽度和7,468.47的Winkler评分。
### Conclusion
通过将机器学习与空间和高维分析结合，该框架提升了AADT估算的准确性和可解释性，从而支持更加稳健和科学的交通规划。
## 871. `cs.LG` - 基础模型的组合范式：迈向更智能的机器人代理 [PDF](https://arxiv.org/pdf/2510.18608), [HTML](https://arxiv.org/abs/2510.18608)
### Authors
Luigi Quarantiello,Elia Piccoli,Jack Bell,Malio Li,Giacomo Carfì,Eric Nuertey Coleman,Gerlando Gramaglia,Lanpei Li,Mauro Madeddu,Irene Testa,Vincenzo Lomonaco
### Background
基础模型在语言、视觉和机器人控制等多个任务中带来了前所未有的成果，能够处理大量数据并发展出丰富的表示方式，但它们在适应实时动态场景时仍需全部重新训练，这限制了它们的应用灵活性和效率。因此，需要新的方法来增强基础模型的灵活性、效率与智能化水平
### Innovation
本文提出了结合持续学习和组合性原则的应用，以促进开发出更加灵活、高效且智能化的人工智能解决方案，从而提升基础模型在动态的现实世界中的适应能力，无需从头开始重新训练整个模型
### Conclusion
通过引入持续学习和组合性原则的应用，该研究为基础模型在机器人代理中的发展开辟了新的途径，旨在实现更智能的机器人代理。
## 872. `cs.LG` - 基于离散信道的通道感知矢量量化稳健语义通信 [PDF](https://arxiv.org/pdf/2510.18604), [HTML](https://arxiv.org/abs/2510.18604)
### Authors
Zian Meng,Qiang Li,Wenqian Tang,Mingdie Yan,Xiaohu Ge
### Background
深度学习驱动的语义通信主要依赖于模拟或半数字传输，这限制了其与现代数字通信基础设施的兼容性。现有研究采用矢量量化（VQ）来实现离散语义传输，但当前的方法在码本优化过程中忽略了信道状态信息（CSI），导致鲁棒性不足。
### Innovation
提出了一个基于联合源-信道编码（JSCC）框架的通道感知矢量量化（CAVQ）算法，命名为VQJSCC。该算法在离散无记忆信道上建立，通过将语义特征直接映射到调制星座图，并将信道状态信息整合到量化过程中，使混淆符号与语义相似的码字对齐，从而提高了系统性能。
### Conclusion
模拟结果表明，VQJSCC有效缓解了数字悬崖效应，实现了多种调制方案下的优质重构质量，并在鲁棒性和效率方面优于最先进的数字语义通信基线。
## 873. `cs.LG` - 基于细胞模式感知SSL的钙成像动态视觉经验解码 [PDF](https://arxiv.org/pdf/2510.18516), [HTML](https://arxiv.org/abs/2510.18516)
### Authors
Sangyoon Bae,Mehdi Azabou,Jiook Cha,Blake Richards
### Background
自监督学习（SSL）在神经科学中的应用前景广阔，但由于缺乏大规模、一致标记的神经数据集，使得SSL难以识别神经活动的一致模式。大多数神经数据集包含异质性群体，其中包括稳定可预测和高度随机的神经元，这使得在SSL中识别一致的活动模式变得困难。因此，自监督预训练尚未从规模上显示出对神经数据的明显优势。
### Innovation
提出了一种新颖的自监督预训练方法POYO-SSL，通过利用神经数据的异质性来提高预训练，并实现规模上的收益。具体来说，POYO-SSL仅对预训练分割中通过简单高级统计（偏度和峰度）识别出的可预测神经元进行预训练，然后对不可预测的神经元群体进行微调以用于下游任务。在Allen Brain Observatory数据集上，这一策略相较于从零开始训练的方法取得了约12-13%的相对增益，并且随着模型规模的增加表现出了平滑且单调的增长趋势，而现有的最先进的基线方法则随着模型规模的增加出现停滞或不稳定。
### Conclusion
POYO-SSL通过将可预测性作为数据饮食的显式指标，将异质性从负担变成了优势，为可扩展神经解码提供了一个稳健且生物解释性强的框架，并向着神经动力学的基础模型迈进。
## 874. `cs.LG` - CovMatch：由交叉协方差引导的可训练文本编码器驱动的多模态数据集蒸馏 [PDF](https://arxiv.org/pdf/2510.18583), [HTML](https://arxiv.org/abs/2510.18583)
### Authors
Yongmin Lee,Hye Won Chung
### Background
多模态数据集蒸馏旨在合成小规模的图像-文本对以高效训练大规模视觉-语言模型。尽管单模态任务中数据集蒸馏展现出了潜力，将其扩展到多模态对比学习提出了关键挑战，包括跨模态对齐的学习和大规模编码器带来的高计算成本。此前的方案通过冻结文本编码器并仅更新图像编码器和文本投影层来提高可扩展性，但这种方法严重影响了语义对齐，并成为性能扩展的瓶颈。
### Innovation
本文提出了一种名为CovMatch的可扩展的多模态数据集蒸馏框架，该框架通过同时优化两种编码器并正则化每个模态内的特征分布来对现实和合成特征的交叉协方差进行对齐。与前人的方法不同，CovMatch允许的同时优化两种编码器，从而实现了更强的跨模态对齐和更优的性能。在Flickr30K和COCO数据集上的结果表明，CovMatch超越了现有的最先进的多模态数据集蒸馏方法，并且只需500个合成对，检索准确率上最高提高了6.8%的绝对值。
### Conclusion
CovMatch在Flickr30K和COCO上的评估结果显示，它超越了现有的最先进的多模态数据集蒸馏方法，并且通过仅使用500个合成对实现了检索准确率6.8%的绝对提升。
## 875. `cs.LG` - C-SWAP: 提示可解释性的结构剪枝以实现高效神经网络压缩 [PDF](https://arxiv.org/pdf/2510.18636), [HTML](https://arxiv.org/abs/2510.18636)
### Authors
Baptiste Bauvin,Loïc Baret,Ola Ahmad
### Background
近年来，神经网络剪枝在计算机视觉应用中受到了广泛关注，因为模型减小尺寸和降低推断成本的需求对于克服部署限制至关重要。结构剪枝尤为重要，因为它允许删除整个结构，从而进一步加速推断时间和减少内存使用。然而，这种方法通常会耗费大量的计算资源，需要迭代重训和优化。最近的方法考虑了一次性剪枝设置，它在后训练中直接应用剪枝，但会导致性能显著下降。因此，本文旨在探讨这一问题，提出了一种依赖于可解释深度学习的新颖一次性剪枝框架。
### Innovation
该方法引入了一种因果意识剪枝方法，通过渐进式剪枝过程利用模型预测与结构之间的因果关系。通过在卷积神经网络和预训练在分类任务上的视觉转换器基线中进行实验，我们展示了该方法在保持性能的同时实现了显著的模型尺寸削减，并且无需精细调整。我们的方法优于同类方法，提供了最佳的性能与尺寸之间的权衡。我们的代码已发布在GitHub上。
### Conclusion
我们提出了一种新颖的一次性剪枝框架，该框架利用解释深度学习，提出了因果意识的剪枝方法，能够在保持性能的同时有效减少网络大小，实现了最佳的性能与尺寸之间的权衡。
## 876. `cs.LG` - ε-Seg: 半监督显微镜数据的语义分割 [PDF](https://arxiv.org/pdf/2510.18637), [HTML](https://arxiv.org/abs/2510.18637)
### Authors
Sheida Rahnamai Kordasiabi,Damian Dalle Nogare,Florian Jug
### Background
在生命科学中，电子显微镜（EM）图像的语义分割仍然是一个挑战。EM数据捕获生物结构的细节，有时复杂到连人类观察者也觉得难以处理。现有方法在处理这类复杂数据时，即使有少量的训练标签（例如，总量的0.05%或更少），也可能难以区分所需的类别。
### Innovation
该研究引入了ε-Seg方法，基于分层变分自编码器（HVAEs），结合中心区域掩码、稀疏标签对比学习（CL）、高斯混合模型（GMM）先验和无聚类标签预测。该方法通过掩码中心区域和 inpainting 损失鼓励模型学习鲁棒和代表性的嵌入，即使训练标签稀疏，也能区分所需类别。通过对潜在空间的适当塑造，使得编码输入块倾向于按语义类别聚类。最终，提出了一个MLP语义分割头部，直接从潜在嵌入生成类别标签，而无需聚类。
### Conclusion
实验结果表明，ε-Seg在处理复杂生物图像数据时，即使训练标签有限，也能达到具有竞争力的半监督语义分割效果。该方法在两个密集的生物组织EM数据集以及荧光显微镜数据上进行了验证，证明了其适用性。
## 877. `cs.LG` - Bianry Quadratic Quantization: Beyond First-Order Quantization for Real-Valued Matrix Compression [PDF](https://arxiv.org/pdf/2510.18650), [HTML](https://arxiv.org/abs/2510.18650)
### Authors
Kyo Kuroki,Yasuyuki Okoshi,Thiem Van Chu,Kazushi Kawamura,Masato Motomura
### Background
现有的量化方法，如均匀量化和二元编码量化，通过二进制基的线性组合来近似实值矩阵，但这些方法在保持高效的存储格式和较高的重建精度之间存在权衡。本文探讨了一种新颖的矩阵量化方法——二元二次量化（BQQ），旨在通过增强的二次表达示来克服这种权衡，并同时保持极简的数据格式。
### Innovation
提出了一种新颖的矩阵量化方法——二元二次量化（BQQ），它利用了二元二次表达式的表达能力，且保留了极其紧凑的数据格式。与其他合理化方法相比，BQQ在压缩各种矩阵数据时显示了更好的存储效率与重建误差之间的权衡。研究还发现，BQQ即使不依赖特定的后训练量化（PTQ）优化方法，也能在没有最严格内存限制的情况下，达到最先进的后训练量化方法的性能。尤其是在ImageNet数据集下的校准基和数据免费场景中，BQQ分别超越了最先进的后训练量化方法2.2%和59.1%，即使量化等效于2位时也表现出了卓越的性能。
### Conclusion
研究结果表明，二元二次量化方法在实现高效矩阵近似和神经网络压缩方面有着令人惊讶的有效性，这超越了传统的一阶量化方法。
## 878. `cs.LG` - Differentially Private E-Values [PDF](https://arxiv.org/pdf/2510.18654), [HTML](https://arxiv.org/abs/2510.18654)
### Authors
Daniel Csillag,Diego Mesquita
### Background
E-values已经作为灵活的统计推断和风险控制工具获得了重视，可以在最少假设的情况下实现任意和事后有效的方法。然而，许多实际应用高度依赖敏感数据，这些数据可能通过E-values泄露。因此，确保这些数据安全释放的需求变得至关重要。因此，该研究提出了一种将非私有E-values转化为差分隐私（Differential Privacy, DP）E-values的通用框架。通过开发一种新颖的有偏乘法噪声机制来确保E-values在统计上依然有效。
### Innovation
该研究开发了一种新颖的有偏乘法噪声机制，用于将非私有E-values转化为差分隐私E-values，同时保持统计有效性。实验结果显示，差分隐私E-values具有强大的统计功效，接近于非私有E-values的统计功效。该研究在在线风险监测、私人医疗保健和符合性E-预测方面的应用表明，其方法的有效性和广泛的适用性。
### Conclusion
该研究提出的差分隐私E-values框架能够确保在保护敏感数据隐私的情况下进行有效的统计推断和风险控制。研究结果显示，这种转换方法对多种实际应用（如在线风险监测、私人医疗和预测）都适用，确保了强大的统计功效。
## 879. `cs.LG` - 分析展开架构算法在稀疏色谱信号恢复中的比较研究 [PDF](https://arxiv.org/pdf/2510.18760), [HTML](https://arxiv.org/abs/2510.18760)
### Authors
Mouna Gharbi,Silvia Villa,Emilie Chouzenoux,Jean-Christophe Pesquet,Laurent Duval
### Background
稀疏假设下的降级观察数据恢复是一个活跃的研究领域。传统的迭代优化方法现在被深度学习技术所补充。展开方法的发展得益于这两种方法家族的优点。
### Innovation
研究人员对三种架构在参数化色谱信号数据库上进行了比较研究，特别强调了使用适应物理-化学峰信号特化的度量标准的技术性能。
### Conclusion
研究表明，展开方法在处理色谱信号恢复任务时表现出良好的性能，特别是在使用适合物理-化学峰信号特化的度量标准的情况下。
## 880. `cs.LG` - 在 Curriculum RL 中使用可验证准确性与断言奖励以缓解 Lost-in-Conversation 现象 [PDF](https://arxiv.org/pdf/2510.18731), [HTML](https://arxiv.org/abs/2510.18731)
### Authors
Ming Li
### Background
大型语言模型在单轮指令遵循方面表现出强大的能力，但在多轮对话设置中，它们会面临“对话丢失”（Lost-in-Conversation, LiC）的问题，即随着信息逐轮揭示，性能逐渐下降。当前，强化学习结合验证性奖励（Reinforcement Learning with Verifiable Rewards, RLVR）取得了进展，但并没有有效解决LiC问题。本文指出，需要一种新的框架来帮助模型判断问题在多轮对话中的可解性，从而避免因LiC导致的回答不当。
### Innovation
提出了一种名为 Curriculum Reinforcement Learning with Verifiable Accuracy and Abstention Rewards (RLAAR) 的新框架，该框架通过引入一种基于能力的课程，逐步提高对话难度（以指令片段计），从而稳定训练并促进可靠性。该框架结合了多轮情境下的在线策略模拟和混合奖励系统，旨在教会模型在平衡解决问题与明智的自我抑制（即避免过早作答）之间取得平衡，从而减轻LiC现象并提高模型的可靠性和可信度。
### Conclusion
在LiC基准测试中，RLAAR显著降低了LiC性能衰减（从62.6%提高到75.1%），并且提高了可信的自我抑制率（从33.5%提高到73.4%）。此结果为构建多轮对话可靠和值得信赖的LLMs提供了实用的参考方案。
## 881. `cs.LG` - 符号模拟器在宇宙学中的应用：无需牺牲精度加速宇宙学分析 [PDF](https://arxiv.org/pdf/2510.18749), [HTML](https://arxiv.org/abs/2510.18749)
### Authors
Deaglan J. Bartlett,Shivam Pandey
### Background
在宇宙学中，模拟器通过提供快速且准确的复杂物理模型预测，使得高效探索高维参数空间成为可能，避免了直接数值模拟的高计算成本。符号模拟器作为一种符号计算方法的替代方案，提供了与数值方法相当的精度但计算速度显著提高。然而，早期的符号模拟器仅适用于相对狭窄的先验范围，未能涵盖当前宇宙学分析所需的参数空间。
### Innovation
本文介绍了扩展到涵盖当前宇宙学分析参数空间范围的符号模拟器。具体而言，对ΛCDM共生距离和线性增长因子所使用的超几何函数进行了近似，这些近似在所有红移值和Ω_{m} ∈ [0.1, 0.5]范围内均准确到优于0.001%和0.05%。这些新方法已被融入到类似宇宙学巡天的3×2pt分析中，并产生了与标准数值方法一致的宇宙学约束。该研究证明了符号模拟器在提高速度和内存使用方面的显著优势，展示了其实现可扩展性、基于似然的推理的实践潜力。
### Conclusion
通过将符号模拟器融入大型宇宙学数据分析中，可以在不牺牲精度的前提下大幅加快计算速度和减少内存使用。这些符号模拟器为宇宙学研究提供了一种新的高效方法，并展示了符号计算方法在复杂宇宙学分析中的应用潜力。
## 882. `cs.LG` - SO(3)-不变主成分分析在分子数据应用中的方法 [PDF](https://arxiv.org/pdf/2510.18827), [HTML](https://arxiv.org/abs/2510.18827)
### Authors
Michael Fraiman,Paulina Hoyos,Tamir Bendory,Joe Kileel,Oscar Mickelin,Nir Sharon,Amit Singer
### Background
主成分分析（PCA）是一种基本的技术，用于降维和去噪，但将其应用于具有任意方向的三维数据（在结构生物学中常见）时，会面临重大挑战。传统方法需要扩充数据集，通过每个样本的许多旋转副本，这会带来巨大的计算成本。
### Innovation
本文通过开发一套有效和规范的SO(3)-不变的PCA框架，隐式地考虑了所有旋转，而无需显式的数据扩充，将PCA扩展到具有未知方向的三维体数据集上。利用潜在的代数结构，证明了计算只需要总协方差项数的平方根，从而显著降低了复杂度。
### Conclusion
该方法在真实分子数据集上得到了验证，证明了其有效性，为大规模、高维度重构问题开辟了新的可能性。
## 883. `cs.LG` - 一个基于频繁主义者视角的变分推断、自动编码器和扩散模型统计介绍 [PDF](https://arxiv.org/pdf/2510.18777), [HTML](https://arxiv.org/abs/2510.18777)
### Authors
Yen-Chi Chen
### Background
变分推断（VI）是现代生成模型如变分自动编码器（VAEs）和去噪扩散模型（DDMs）的核心。然而，从教育角度来看，VI的教学分散在不同学科中。在统计学中，VI常作为贝叶斯方法用于近似后验分布。而在机器学习中，VAEs和DDMs则是以频率主义者的观点开发的，其中VI用于近似最大似然估计。这种学科间的差异性使得统计学家难以理解VAEs和DDMs背后的原理。
### Innovation
本文提供了一个全新的视角，从纯粹频率主义者的角度解释了变分推断、自动编码器和扩散模型的理论。文章以经典的期望最大化（EM）算法为基础，展示了VI作为解决不可行的E步骤的可扩展解法。文章进一步展示了VAEs和DDMs是如何作为经典统计推理和现代生成AI的自然、深度学习扩展。这有助于弥合统计学与现代生成AI之间的鸿沟。
### Conclusion
本文通过纯粹的频率主义者视角解释了变分推断、自动编码器和扩散模型的理论，特别是从经典的EM算法出发，展示了如何通过变分推断解决不可计算的E步骤，强调了这些现代生成模型作为经典统计推理的自然延伸，从而为统计学与现代生成AI之间的理解提供了一个新的桥梁。
## 884. `cs.LG` - 解码资助研究：主题模型的比较分析及性别和地理位置影响的发现 [PDF](https://arxiv.org/pdf/2510.18803), [HTML](https://arxiv.org/abs/2510.18803)
### Authors
Shirin Tavakoli Kafiabad,Andrea Schiffauerova,Ashkan Ebadi
### Background
优化国家科学研究投资需要清晰了解不断演变的研究趋势以及塑造这些趋势的人口和地理力量，特别是在追求公平、多元化和包容性的承诺背景下。本研究通过分析加拿大自然科学和工程研究理事会（NSERC）在2005年至2022年间资助的18年研究提案，应对了这一需求。
### Innovation
本研究通过系统性地比较三种主题建模方法（潜在狄利克雷分配LDA、结构化主题模型STM和BERTopic）展示了创新。还引入了一个名为COFFEE的新算法，为BERTopic的协变量效应估计提供了一种可靠的方法。这项进展填补了BERTopic缺乏内置协变量分析功能的空白，与概率性的STM不同。
### Conclusion
研究发现，虽然所有模型都能准确划分核心科学领域，但BERTopic通过持续识别更多细粒度、一致性和新兴主题的表现更优，如人工智能的快速扩展。加上COFFEE支持的协变量分析，揭示了不同省份的研究专长和多个科学领域中持续存在的性别主题模式。这些见解为资助组织提供了制定更公平和有影响力的资助策略的坚实实证基础，从而增强了科学研究生态系统的有效性。
## 885. `cs.LG` - 多证据框架在癌症基因组中拯救低功率预后信号并拒绝统计伪影 [PDF](https://arxiv.org/pdf/2510.18571), [HTML](https://arxiv.org/abs/2510.18571)
### Authors
Gokturk Aytug Akarlar
### Background
传统的癌症基因组全基因组关联研究依赖于统计显著性，并通过多重假设测试校正，但对于小样本量的队列则表现不佳。在TCGA乳腺癌队列（n=967，133例死亡）中，低事件率（13.8%）导致严重的统计功效不足，导致已知驱动因子出现假阴性结果，大尺寸的乘客基因则出现假阳性结果。
### Innovation
该研究开发了一种五标准的计算框架，结合因果推断（如反概率加权和双重稳健估计）和生物学验证（如表达模式、突变模式、文献证据），成功识别出在统计上看似显著但实际上为假阳性的RYR2基因，而KMT2C基因在有限的统计显著性基础上被确认为复杂候选需要进一步验证。功率分析揭示了总体15.1%的统计功效，KMT2C仅能达到29.8%的统计功效（风险比1.55），尽管有大量的生物证据支持。该框架通过突变模式分析区分了真实信号与伪信号，RYR2基因显示高比例的沉默突变（乘客特征）而没有热点突变，而KMT2C表现为较高的截断变异率。
### Conclusion
该多证据方法提供了一种分析小样本量队列的模板，侧重于生物解释而非单纯的统计显著性。所有代码和分析管道均公开可获取。
## 886. `cs.LG` - 在线生成语音增强的扩散缓冲器 [PDF](https://arxiv.org/pdf/2510.18744), [HTML](https://arxiv.org/abs/2510.18744)
### Authors
Bunlong Lay,Rostislav Makarov,Simon Welker,Maris Hillemann,Timo Gerkmann
### Background
在线语音增强主要使用了预测模型，这类模型对于输入信号帧可被一次性调用进行处理。相比之下，生成式语音增强模型通常需要多次调用，导致了过高的计算复杂度，不适合许多在线语音增强应用。本文提出了一种生成式扩散模型——Diffusion Buffer，它只需要在每个输入信号帧上调用一次神经网络，可在消费级GPU上实时处理，且能够在对象时间与扩散时间步长对齐的情况下逐帧去噪。
### Innovation
提出了一种称为Diffusion Buffer的新型生成式扩散模型，该模型通过特定的2D卷积UNet架构设计，精确地与扩散缓冲器的预览窗口对齐，该架构能够减少算法延迟并提高性能。此外，通过使用数据预测损失而非去噪评分匹配损失，该模型可以在推理时灵活调整延迟与质量之间的权衡。
### Conclusion
Extended Diffusion Buffer结合了新的神经网络架构和损失函数，将算法延迟从320-960毫秒降低到32-176毫秒，同时提高了性能。此外，尽管有研究表明，离线生成式扩散模型在未见过的噪声环境中优于预测模型，但本文的研究证实，该在线扩散缓冲器在未见过的噪声环境中也能优于预测模型。
## 887. `cs.LG` - MTraining: 分布式动态稀疏注意力机制以实现高效超长上下文训练 [PDF](https://arxiv.org/pdf/2510.18830), [HTML](https://arxiv.org/abs/2510.18830)
### Authors
Wenxuan Li,Chengruidong Zhang,Huiqiang Jiang,Yucheng Li,Yuqing Yang,Lili Qiu
### Background
在大型语言模型（LLMs）中，使用长上下文窗已成为标准特征，因为较长的上下文显著增强了其复杂推理能力，并使其实现在多种场景中的应用范围更广。动态稀疏注意是一个有希望减少长上下文计算成本的方法，但在具有动态稀疏注意机制的模型训练中，特别是在分布式环境中，有效训练LLMs（使用超长上下文）仍是一个重大挑战，主要是由于工作者和步骤层面的不平衡。因此，有效解决这一问题需要新的方法来协同处理训练过程中固有的计算不平衡和通信开销问题。
### Innovation
本文提出了MTraining，一种新颖的分布式方法，结合动态稀疏注意机制，使具有超长上下文的LLMs的训练高效进行。MTraining集成了三个关键组件：动态稀疏训练模式、平衡稀疏环注意和层次稀疏环注意，旨在协同解决训练大型模型时的计算不平衡和通信开销问题。该方法展示了在32个A100 GPU集群上的Qwen2.5-3B模型训练成功将上下文窗口从32K扩展到512K令牌。与MTraining方法相关的实验结果表明，与保留模型准确性的情况下，培训吞吐量可提高6倍。
### Conclusion
MTraining实验证明，与保留模型准确性的情况下，使用MTraining方法可以将具有超长上下文长度的LLMs的训练吞吐量提高到原来的6倍。我们的代码可在该网址获得。
## 888. `cs.LG` - Lyapunov-Aware Quantum-Inspired Reinforcement Learning for Continuous-Time Vehicle Control: A Feasibility Study [PDF](https://arxiv.org/pdf/2510.18852), [HTML](https://arxiv.org/abs/2510.18852)
### Authors
Nutkritta Kraipatthanapong,Natthaphat Thathong,Pannita Suksawas,Thanunnut Klunklin,Kritin Vongthonglua,Krit Attahakul,Aueaphum Aueawatthanaphisut
### Background
该文研究的背景在于，如何通过结合量子计算与强化学习，特别是利用变分量子电路（VQCs）和Lyapunov稳定性分析来实现连续时间下的车辆控制。现有的方法可能缺乏对动态环境中的稳定性和安全性保障，而该论文旨在提供一种结合量子和增强学习的新型框架，以确保在变化环境中的稳定性和安全性。
### Innovation
论文创新之处在于提出了一种新型的Lyapunov-Based Quantum Reinforcement Learning (LQRL)框架，该框架将量子策略优化与Lyapunov稳定性分析相结合，用于连续时间下的车辆控制。该方法利用变分量子电路的表征能力，并结合了稳定性的策略梯度机制，确保了渐近收敛和安全决策。这为自主系统和混合量子-经典优化领域中的可证明安全性控制提供了基础步骤。
### Conclusion
该研究的结论表明，LQRL框架成功地将Lyapunov稳定性验证嵌入到量子策略学习中，实现了可解释且具有稳定性的控制性能。尽管在激进加速下观察到瞬态超调和Lyapunov发散现象，但系统仍保持了状态的有界演化，验证了在量子强化学习架构中整合安全保证的可能性。这对于进一步研究和应用于自主系统中的可证明安全量子控制具有重要意义。
## 889. `cs.LG` - LightMem：轻量级和高效的记忆增强生成 [PDF](https://arxiv.org/pdf/2510.18866), [HTML](https://arxiv.org/abs/2510.18866)
### Authors
Jizhan Fang,Xinle Deng,Haoming Xu,Ziyan Jiang,Yuqi Tang,Ziwen Xu,Shumin Deng,Yunzhi Yao,Mengru Wang,Shuofei Qiao,Huajun Chen,Ningyu Zhang
### Background
大型语言模型尽管能力强大，但在处理动态和复杂环境时，难以有效利用历史交互信息。现有的记忆系统虽然能够引入持久的信息存储、检索和利用机制，从而摆脱无状态交互的限制，但这些系统往往导致了显著的时间和计算开销。为平衡记忆系统性能与效率，本文提出了一种新的轻量级记忆系统LightMem，灵感来源于人类记忆模型中的Atkinson-Shiffrin模型，将记忆分为三个互补阶段：首先通过简单的压缩快速筛选无关信息并对信息进行话题归类；其次，基于话题的短期记忆将这些话题组进行整合和总结，以便更结构化的访问；最后，带睡眠时间更新的长时记忆通过离线处理将合并过程与在线推理脱钩。实验结果表明，与强大的基线相比，LightMem在准确率上提高了10.9%，同时减少标记使用量至117倍，API调用至159倍，运行时间超过12倍的加速。
### Innovation
提出了一种名为LightMem的新记忆系统，该系统通过借鉴人类记忆模型中的Atkinson-Shiffrin模型，将记忆分三个互补阶段：感性记忆、主题敏感的短期记忆和睡眠时间更新的长期记忆。这种方法在保持高性能的同时，显著提高了效率，能够在大型语言模型中有效利用历史交互信息，减少计算开销和标记使用量。
### Conclusion
实验结果表明，LightMem在准确率上有显著提高，同时显著减少了标记使用量、API调用次数和运行时间。代码可在相关链接查看。通过LightMem，大型语言模型在处理复杂环境时，能够更有效地利用历史交互信息，实现轻量级和高效的记忆增强生成。
## 890. `cs.LG` - 在无标签情况下估计模型在变分条件下的性能 [PDF](https://arxiv.org/pdf/2401.08348), [HTML](https://arxiv.org/abs/2401.08348)
### Authors
Jakub Białek,Juhani Kivimäki,Wojtek Kuberski,Nikolaos Perrakis
### Background
在部署后，机器学习模型经常因为数据分布的变化而性能退化。当标签缺失或延迟时，准确评估部署后性能是具有挑战性的。现有的代理方法，如数据漂移检测，无法充分测量这些变化的影响。
### Innovation
我们提出了一种新方法，称为概率自适应性能评估（PAPE），用于在无标签表数据上评估二元分类模型。PAPE可以应用于任何基于混淆矩阵元素定义的性能指标，并且完全独立于原始模型，仅依赖于其预测和概率估计进行操作，不需要对变分条件的具体性质做出假设，而是直接从数据中学习。
### Conclusion
我们通过超过900个数据集-模型组合测试了PAPE，并通过多种指标指标将其与其他基准进行比较，结果显示PAPE优于其他方法，表明它在估计二元分类模型性能方面具有优越性。
## 891. `cs.LG` - 改善神经网络NTK条件数：大规模ReLU非线性激活带来的免费午餐 [PDF](https://arxiv.org/pdf/2305.08813), [HTML](https://arxiv.org/abs/2305.08813)
### Authors
Chaoyue Liu,Han Bi,Like Hui,Xiao Liu
### Background
非线性激活函数因其增强神经网络表征能力而被广泛认识，这是它们普遍应用的主要原因。在本工作中，我们专注于ReLU激活，并揭示了非线性激活的新型和有趣的特性。通过对比禁用和启用神经网络中的非线性激活，展示了它们对广泛神经网络的特定影响：(a) 更好的特征分离，即模型梯度特征空间中相似数据之间的角度间隔更大；(b) 更好的NTK条件数，即神经切线核（NTK）的条件数更小。此外，随着网络深度的增加（即非线性激活操作的增加），这些效果进一步放大；在无限宽然后达到极限时，所有数据在模型梯度特征空间中都以固定的角度等距分布，无论它们在输入空间中的相似程度如何。
### Innovation
揭示了非线性激活的新型和有趣的特性：(a) 更好的特征分离；(b) 更好的NTK条件数。进一步证实网络深度（即更多的非线性激活操作）进一步放大了这些效果。此外，在无限宽然后达到极限时，所有数据在模型梯度特征空间中以固定的角度等距分布，无论它们在输入空间中的相似程度如何。
### Conclusion
非线性激活有助于改善基于梯度方法的最坏情况下收敛率。即便在没有非线性激活的线性神经网络中，数据的分离程度和NTK条件数与原始输入相同，且不随网络深度变化。
## 892. `cs.LG` - 利用贝叶斯网络减轻因果结构学习中的先验错误：一种稳健的方法 [PDF](https://arxiv.org/pdf/2306.07032), [HTML](https://arxiv.org/abs/2306.07032)
### Authors
Lyuzhou Chen,Taiyu Ban,Xiangyu Wang,Derui Lyu,Huanhuan Chen
### Background
因果结构学习（Causal Structure Learning, CSL）是一种通过贝叶斯网络（Bayesian Networks, BNs）编码变量之间因果关系的技术。尽管仅从数据中恢复因果结构是一项挑战，但结合先验知识可以显著提高学习质量。然而，当前依赖于先验知识的方法在先验知识存在错误的情况下表现出不足，硬约束方法完全忽略先验知识，而软约束方法基于预设的信心水平接受先验知识，这可能需要专家干预。
### Innovation
该论文提出了一种针对边缘级先验错误稳健的策略，以减轻CSL中的先验错误，从而减少人为干预。具体而言，研究将先验错误分类，并在假设有充足数据的情况下，分析了不同类型先验错误对结构汉明距离（Structural Hamming Distance, SHD）的影响。研究发现并证明，先验错误的致命风险与一种独特的无环闭合结构（称为“准环”）相关联。基于这一见解，提出了一种后处理策略，通过识别对“准环”的增量影响来确定先验错误。
### Conclusion
通过在真实和合成数据集上的实证评估，该策略展示了其在对抗先验错误方面的稳健性，特别是其显著抵抗顺序反转错误的能力，同时保留了大部分正确的先验知识。
## 893. `cs.LG` - 基于修剪层相关传播的稀疏神经网络解释 [PDF](https://arxiv.org/pdf/2404.14271), [HTML](https://arxiv.org/abs/2404.14271)
### Authors
Paulo Yanez Sarmiento,Simon Witzke,Nadja Klein,Bernhard Y. Renard
### Background
深度神经网络（DNN）的解释性是许多应用场景的关键组成部分。然而，当前的解释方法通常依赖人类观察者来区分相关解释和虚假噪声。随着数据复杂度的增加，如从图像数据变为基因组序列数据，这一点变得不再可行。为了使复杂数据的DNN输出更具可访问性并提高解释性，作者提出了一种修改后的层相关传播方法。该方法通过直接修剪不同层的相关传播来增强稀疏性。
### Innovation
作者提出了一种通过修剪层相关传播的改进方法，直接提高稀疏性。这种方法允许对不同的输入修剪不同的神经元，从而更好地适应局部性质较明显的解释方法。通过在图像和基因组序列数据上的评估，展示了该方法减少了噪声并集中了相关性于最重要的特征。
### Conclusion
该方法通过修剪层相关传播增强了稀疏性，减少了噪声，并将相关性集中于最重要的特征，从而提高了神经网络的解释性。这种方法适用于图像和基因组序列等复杂数据，并能够根据输入的具体情况修剪不同的神经元。
## 894. `cs.LG` - 基于不平衡数据分类的学习置信边界 [PDF](https://arxiv.org/pdf/2407.11878), [HTML](https://arxiv.org/abs/2407.11878)
### Authors
Matt Clifford,Jonathan Erskine,Alexander Hepburn,Raúl Santos-Rodríguez,Dario Garcia-Garcia
### Background
类不平衡在分类任务中构成了一个重要挑战，传统的处理方法通常会导致有偏的模型和不可靠的预测。常用的下采样和上采样技术由于其简单化的处理方式而存在固有的局限性，如信息损失和附加的偏差等问题。
### Innovation
本文提出了一种新的框架，该框架结合了学习理论和集中不等式，以克服传统解决方案的不足。该方法通过直接嵌入学习过程中的类依赖性置信区间，对不同类别的不同不平衡程度进行了有效适应，从而提高了分类的稳健性和可靠性。
### Conclusion
通过实验证明，本文框架为处理不平衡数据的分类任务提供了一个令人鼓舞的方向，为实践者提供了构建更准确和可信赖模型的有效工具。
## 895. `cs.LG` - 一种基于流的可条件性和概率性电能消耗模式生成和预测模型 [PDF](https://arxiv.org/pdf/2405.02180), [HTML](https://arxiv.org/abs/2405.02180)
### Authors
Weijie Xia,Chenguang Wang,Peter Palensky,Pedro P. Vergara
### Background
住宅负载轮廓 (RLP) 的生成和预测对于配电网络的操作和规划至关重要，尤其是在各种低碳技术（如光伏和电动汽车）逐渐被采用的情况下。传统的统计模型和现代深度生成模型在生成和预测 RLP 时存在局限性，如无法很好地处理连续条件下的 RLP 生成、在不同数据集上的可扩展性较低，以及在建模 RLP 复杂相关性方面表现不足。
### Innovation
本文引入了一种新颖的基于流的生成模型，称为全卷积轮廓流 (FCPFlow)，特别适合 RLP 的有条件和无条件生成，以及概率性负载预测。FCPFlow 采用两类可逆层——可逆线性层和可逆归一化层，与传统统计模型和现代深度生成模型相比，具有三个主要优势：1) 它适合生成在连续条件（如不断变化的天气和年度电力消耗）下的 RLP；2) 在不同数据集上的可扩展性优于传统统计模型；3) 在捕捉 RLP 的复杂相关性方面，其建模能力也优于深度生成模型。
### Conclusion
FCPFlow 作为一种新的基于流的生成模型，在功能性、可扩展性和建模能力方面都表现出了优越性，为 RLP 生成和预测提供了一个新的解决方案。
## 896. `cs.LG` - 通过融合正交梯度下降和递归最小二乘法实现一次性学习 [PDF](https://arxiv.org/pdf/2207.13853), [HTML](https://arxiv.org/abs/2207.13853)
### Authors
Youngjae Min,Namhoon Cho,Navid Azizan
### Background
尽管大型机器学习模型在各种领域表现出色，但在多次迭代训练数据的过程中，由于计算和内存限制以及潜在的隐私问题，存储和访问所有数据在很多实时场景中是不切实际的，尤其是在数据以流的形式不断到来的情况下。本文探讨了一次性学习的问题，即在不重新训练之前数据点的情况下，模型在连续到来的数据上进行训练。受过参数化模型有效性和良性过拟合现象的启发，本文提出了一种算法，称为正交递归拟合（ORFit），该算法旨在完美拟合每一个新数据点，同时尽量不影响先前数据点的预测。ORFit 在参数更新时采用与过去梯度正交的方向，类似于持续学习中的正交梯度下降。研究表明，ORFit 的更新结果类似于自适应滤波中的递归最小二乘算法，但具有显著改善的内存和计算效率，即线性而非平方的时间复杂度。为了进一步降低内存使用，本文利用流数据的结构通过增量主成分分析（IPCA）来减少内存使用。我们证明，使用主成分可以实现最小最大最优性，即最大限度地降低未来未知更新对先前预测的遗忘。进一步研究证明，对于过参数化的线性模型，ORFit 所得到的参数向量与标准多遍随机梯度下降（SGD）最终收敛的结果相同。我们还将这种方法扩展到了非线性情形，对于高度过参数化的模型，这对于深度学习尤为重要。
### Innovation
提出了一种称为正交递归拟合（ORFit）的算法，用于实现一次性学习，通过在参数更新时采用与过去梯度正交的方向，旨在完美拟合每一个新数据点。该算法具有显著改善的内存和计算效率，即线性而非平方的时间复杂度。同时，结合增量主成分分析（IPCA）来减少内存使用，使算法更加高效。
### Conclusion
本文提出的正交递归拟合（ORFit）算法在一次性学习方面具有显著优势，对于高度过参数化的模型尤其是在非线性情形下具有重要的应用价值。此外，通过与标准随机梯度下降（SGD）进行对比验证了ORFit算法的有效性。
## 897. `cs.LG` - 一则蛋白质就足够了 [PDF](https://arxiv.org/pdf/2411.02109), [HTML](https://arxiv.org/abs/2411.02109)
### Authors
Anton Bushuiev,Roman Bushuiev,Olga Pimenova,Nikola Zadorozhny,Raman Samusevich,Elisabet Manaskova,Rachel Seongeun Kim,Hannes Stärk,Jiri Sedlar,Martin Steinegger,Tomáš Pluskal,Josef Sivic
### Background
在生物信息学机器学习中，提高模型泛化能力是核心挑战之一。一种常用方法是通过大型数据集进行自我监督预训练，以增强泛化能力。然而，这种方法往往旨在让模型在所有可能的蛋白质上表现出色，这可能限制了其在特定蛋白质上的性能。实验人员通常需要对他们正在研究的个别蛋白质进行准确预测，而这些蛋白质可能并未包含在训练数据中。
### Innovation
本文提出了一种方法，能够在不需要额外数据的情况下，针对单一目标蛋白质进行自我监督的定制化培训。这一方法即Protein Test-Time Training (ProteinTTT)，能够在不同模型、不同规模和不同数据集上一致地提升泛化能力。ProteinTTT在结构预测、蛋白质适应力预测和功能预测任务上取得了显著改进，并在两项具有挑战性的案例研究中进一步验证了其准确性，特别是在大规模 Fantastic 病毒数据库中的结构模型精度提升了19%。
### Conclusion
ProteinTTT 方法能够针对特定目标蛋白质进行自适应培训，从而使蛋白质语言模型在泛化能力上有显著提升，特别在结构预测、蛋白质适应力和抗体-抗原环模型预测等领域取得了突破性进展。
## 898. `cs.LG` - FedMeld: 一种用于空地集成网络的模型分散联邦学习框架 [PDF](https://arxiv.org/pdf/2412.17231), [HTML](https://arxiv.org/abs/2412.17231)
### Authors
Qian Chen,Xianhao Chen,Kaibin Huang
### Background
为了弥合数字鸿沟，六代（6G）移动网络中的空地集成网络（SGINs）预计将为世界各地提供人工智能（AI）服务。一个SGIN的任务是支持全球规模的联邦学习（FL）。然而，现有的空地集成FL框架依赖于地面站或成本高昂的星间链路，导致训练延迟过高和通信成本过高。
### Innovation
本文提出了一种基于模型分散的无基础设施联邦学习框架（FedMeld），利用卫星的周期性运动模式和存储-转发能力，使参数混合覆盖大规模地理区域。我们从理论上证明了FedMeld能够实现全局模型收敛，并量化了相邻区域之间的轮次间隔和混合比对学习性能的影响。基于理论结果，我们构建了一个联合优化问题来设计停滞控制和混合比（SC-MR）以最小化训练损失。通过将问题分解为不牺牲最优性的顺序SC和MR子问题，我们以封闭形式获得了轮次间隔解，并以半封闭形式获得了混合比解，以实现最优的延迟-准确度权衡。
### Conclusion
实验使用多种数据集证明，与传统的SGINs FL方案相比，FedMeld能够实现更好的模型准确度，同时大幅降低通信成本。
## 899. `cs.LG` - 对比预训练与多模态生成AI的统计理论 [PDF](https://arxiv.org/pdf/2501.04641), [HTML](https://arxiv.org/abs/2501.04641)
### Authors
Kazusato Oko,Licong Lin,Yuhang Cai,Song Mei
### Background
多模态生成AI系统，例如结合视觉和语言的系统，依赖对比预训练来学习不同模态之间的表示。尽管其实际效益得到广泛认可，但对比预训练框架的严格理论理解仍然有限。
### Innovation
本文开发了一个理论框架来解释对比预训练在下游任务中的成功，例如零样本分类、条件扩散模型和视觉语言模型。引入了近似充分统计的概念，这是经典充分统计的推广，并展示了对比预训练损失的近似最小值在下游任务中是几乎充分的。此外，提出了联合生成层次模型来表征图像和文本的联合分布，并表明transformer可以在该模型中有效地近似相关函数。
### Conclusion
基于此框架，推导出基于对比预训练表示的多模态学习的样本复杂性保证。数值模拟验证了这些理论发现，证明对比预训练的transformer在多种多模态任务中的强大泛化性能。
## 900. `cs.LG` - LLM 安全对齐是一种伪装下的偏差估计 [PDF](https://arxiv.org/pdf/2502.00657), [HTML](https://arxiv.org/abs/2502.00657)
### Authors
Rajdeep Haldar,Ziyi Wang,Qifan Song,Guang Lin,Yue Xing
### Background
论文提出了一个理论框架，表明流行的LLM对齐方法，包括RLHF及其变体，可以被视为安全或优选分布与有害或不优选分布之间的偏差估计器。这种视角解释了在对齐后潜空间中安全提示和有害提示之间的分离现象。通过通用的偏差框架的应用，论文提出了一种新的基于KL散度的对齐方法KLDO，并实证验证了其有效性。研究进一步表明，使用合规/拒绝数据集而不是标准的偏好数据集，可以实现更强的分离和改进的安全对齐。为了量化分离效果，论文提出了一个基于提示表示空间的距离度量工具，该工具还作为模型安全性的统计显著性指标。
### Innovation
论文提出了KLDO，一种新的基于KL散度的对齐方法。同时，论文提倡使用合规/拒绝数据集替代标准偏好数据集来增强对齐效果，并提出了一个新的距离度量工具来量化安全对齐的效果。
### Conclusion
论文证明了LLM对齐方法可以被理解和解释为偏差估计，并提出了一种新的KL散度方法来实现对齐。使用合规/拒绝数据集可以产生更强的分离效果和更好的安全性对齐。通过新的距离度量工具，可以量化对齐的效果并作为模型安全性的统计指标。
## 901. `cs.LG` - 异步联邦学习：面向分布式机器学习的一种可扩展方法 [PDF](https://arxiv.org/pdf/2412.17723), [HTML](https://arxiv.org/abs/2412.17723)
### Authors
Ali Forootani,Raffaele Iervolino
### Background
联邦学习（FL）作为一种分散机器学习的强大范式，允许在不共享原始数据的情况下在多样化的客户端上协作训练模型。然而，传统FL方法往往由于依赖于同步客户端更新而面临可扩展性和效率的局限性，这会导致显著延迟和通信开销的增加，特别是在异构和动态环境中。
### Innovation
本文提出了一种异步联邦学习（AFL）算法，该算法允许客户端独立、异步地更新全局模型，并通过引入马氏差分序列理论和方差边界，确保在异步更新下的鲁棒收敛性。此外，文章通过随机客户端采样下的梯度方差边界和客户延迟对收敛的影响递归公式，进一步证明了AFL的有效性，并通过实验展示了在非IID数据分布下的实际应用。
### Conclusion
所提出的AFL算法有效解决了传统FL方法中的关键局限性，如由于全局同步而导致的效率低下以及客户端漂移的易感性。AFL增强了异质客户端群体和动态网络条件下的分布式学习系统的可扩展性、鲁棒性和效率。我们的研究结果强调了AFL在资源受限环境下的大规模、隐私保护应用中推进分布式学习体系结构的潜力。
## 902. `cs.LG` - 稳健模型适应的贝叶斯低秩因式分解 [PDF](https://arxiv.org/pdf/2510.18723), [HTML](https://arxiv.org/abs/2510.18723)
### Authors
Enes Yavuz Ugan,Ngoc-Quan Pham,Alexander Waibel
### Background
大型语音基础模型在许多领域中表现出色，但它们常常需要适应特定的本地需求，如代码混合，即演讲者在同一句话中混合使用多种语言。直接对这些模型进行微调会增加过拟合到目标领域的风险，从而抹去基础模型的广泛能力。为解决这一挑战，我们探讨了应用于语音基础模型的贝叶斯因式化适配器方法，该方法通过靠近零的位置先验实现更稀疏的适配矩阵，从而在保持一般性能的同时适应特定的领域。我们在此方法上应用了Whisper模型，并对其进行多种语言代码混合场景的评估。结果显示，这种方法在保持基础模型一般性能的同时，对领域特定适应的影响仅略有损失，而显著减少了灾难性遗忘现象。与LoRA相比，我们的方法仅使新领域上的性能损失降低4%，同时获得了54%的恢复性提升。这些发现突显了贝叶斯适应法在不牺牲泛化能力的情况下对语音基础模型进行微调的有效性。
### Innovation
我们研究了一种应用于语音基础模型的贝叶斯因式化适配器方法，该方法通过接近零的位置先验，实现更稀疏的适配矩阵，从而保留了基础模型的广泛应用能力，同时适应特定的领域。这种方法相比于LoRA，在新领域的性能损失上减少了4%，同时实现了54%的性能恢复。这种方法有效解决了因直接微调可能导致的过拟合问题，同时也保持了模型的无缝领域适应能力。
### Conclusion
我们的研究表明，贝叶斯因式化适配器方法对于防止语音基础模型领域适应时出现灾难性遗忘是有效的。与LoRA相比，该方法在新领域的性能损失上降低了4%，同时实现了54%的性能恢复。这意味着，这种方法在不牺牲典型模型应用能力的情况下，可以有效地进行目标领域适应。
## 903. `cs.LG` - 在一般网络干扰存在的情况下，我们能否验证反事实估计？ [PDF](https://arxiv.org/pdf/2502.01106), [HTML](https://arxiv.org/abs/2502.01106)
### Authors
Sadegh Shirani,Yuwei Luo,William Overman,Ruoxuan Xiong,Mohsen Bayati
### Background
随机试验已成为从在线平台到公共卫生等多个领域基于证据的决策的核心。但在具有网络干扰的实验环境中，一个单位的处理可以影响其他单位的结果，这既挑战了因果效应的估计，也挑战了验证的方法。经典验证方法因结果仅在单一处理场景下可被观测到，且由于干扰表现出复杂的关联模式而失效。为解决这些问题，作者提出了一种全新的框架，该框架利用机器学习工具进行因果推理中的估计与验证。
### Innovation
该研究引入了一种新的分布保持网络Bootstrap方法，这是一种理论依据充分的技巧，可以从单个实验的数据中生成多个统计上有效的亚群。这种方法增加了实验样本量，从而提出了第二项贡献——一种反事实交叉验证程序。该程序将模型验证的原则适应了因果推理的独特约束，提供了一种严格的数据驱动的方法来选择和评估估计器。此外，该研究在因果信息传递方面取得进展，考虑了单位层面的异质特征和变化的局部交互，通过非渐近分析确保了有限样本的表现可靠性。作者还开发并公开了一个全面的基准工具箱，包括从交互AI代理网络到拼车应用的各种实验环境，这些环境提供了已知的真实值，保留了现实的复杂性，使因果推理方法能够系统评价。
### Conclusion
广泛测试表明，该方法对各种形式的网络干扰具有鲁棒性。
## 904. `cs.LG` - 学习更公平的表示方法：FairVIC [PDF](https://arxiv.org/pdf/2404.18134), [HTML](https://arxiv.org/abs/2404.18134)
### Authors
Charmaine Barker,Daniel Bethell,Dimitar Kazakov
### Background
在自动化决策系统（尤其是深度学习模型）中缓解偏见是一个关键挑战，因为公平性的定义在各个情况下是复杂的，数据集特定的偏见问题存在，并且公平性与准确性之间存在着固有的权衡。本文探讨了这些挑战，并概述了如何在这些系统中实现公平性.
### Innovation
作者引入了FairVIC，这是一种创新的方法，它通过在训练过程中将方差、不变性和协方差项整合到损失函数中来提高神经网络中的公平性。与依赖预定义公平性的方法不同，FairVIC 提取公平性概念，以减少对受保护特征的依赖。研究结果表明，在确保准确性的前提下，FairVIC 性能使公平性在所有测试指标上提升约70%.
### Conclusion
该研究表明，FairVIC 提供了一个在多任务和数据集上具有广泛适用性的强大、可推广的公平深度学习解决方案。
## 905. `cs.LG` - 变压器在学习线性动态系统中的上下文学习：逼近边界和深度分离 [PDF](https://arxiv.org/pdf/2502.08136), [HTML](https://arxiv.org/abs/2502.08136)
### Authors
Frank Cole,Yuxuan Zhao,Yulong Lu,Tianhao Zhang
### Background
本文研究了transformers在表示一类嘈杂的线性动态系统时的上下文学习能力的逼近论属性。背景在于通过理论分析transformers在解决复杂动态系统问题时的有效性，以及与经典方法的比较，特别是在深度学习模型中探讨不同深度架构下的表现差异.
### Innovation
论文的主要创新点在于通过理论分析，首先给出了多层transformers在$L^2$-测试损失下的逼近误差上界，表明具有对数深度的transformers可以达到与最小二乘估计器相当的误差边界。第二，通过另一种分析，证明了一类单层线性transformers在逼近误差上不存在减少的下界，揭示了transformers在动态系统上下文学习中的深度分离现象。这项研究发现了单层线性transformers在处理独立同分布数据与非独立同分布数据之间的逼近能力差异.
### Conclusion
研究结果显示，transformers在不同深度下的表达能力存在显著差异，且表明深度在动态系统上下文学习中有重要作用。这种对动态系统逼近性能的精确边界分析为理解和优化transformers的设计提供了理论基础，为进一步研究提供了新的方向。
## 906. `cs.LG` - 语言模型预训练中数据选择的相似性度量分析 [PDF](https://arxiv.org/pdf/2502.02494), [HTML](https://arxiv.org/abs/2502.02494)
### Authors
Dylan Sam,Ayan Chakrabarti,Afshin Rostamizadeh,Srikumar Ramalingam,Gui Citovsky,Sanjiv Kumar
### Background
判断训练样本之间的相似性对于构建高质量且多样的预训练数据集至关重要。然而，通常使用的相似性度量机制是通过任务如检索训练的通用嵌入模型生成的，这些嵌入模型针对预训练数据集的适合性尚未得到充分探索。
### Innovation
该研究提出了一种新的框架来评估相似性度量在语言模型预训练数据收集中的适用性。框架内含评估标准：距离反映预训练损失的一般化能力，运用嵌入模型引导标准的多样性数据收集算法，并通过预训练语言模型的方法评估其下游任务的性能，以及嵌入模型区分不同数据源的能力。
### Conclusion
标准的嵌入模型不适合用于预训练数据收集设置，即使是简单嵌入模型如从相同预训练库训练的数据中提取的，也能表现更佳。本研究通过在Pile上进行实验，验证了具有17亿参数的语言模型在200亿令牌上的预训练结果，并认为此分析与评估框架将为未来的嵌入设计提供基础，确保它们能够更好地理解和识别预训练数据集中的相似性。
## 907. `cs.LG` - 通过切除易错标签简易实例增强对抗标签噪声的样本选择 [PDF](https://arxiv.org/pdf/2502.08227), [HTML](https://arxiv.org/abs/2502.08227)
### Authors
Suqin Yuan,Lei Feng,Bo Han,Tongliang Liu
### Background
在使用有噪声标签的学习中，样本选择是一种常用的方法，旨在识别出可以用于训练的可靠样本。尽管现有的样本选择方法通过减少选定子集中的噪声比例取得了不错的成果，但它们通常忽视了并不是所有误标实例对模型性能的影响都是相同的。研究发现，模型在早期训练阶段正确预测的误标实例特别有害。因此，需要一种新的方法来更有效地选择自信的样本，避免早期学习中的误导性置信度。
### Innovation
为了解决上述问题，作者提出了一种名为Early Cutting的新方法。该方法通过引入重新校准步骤，利用模型后期的训练状态重新选择早期训练阶段识别的自信子集，从而避免了早期学习中的误导性置信度，并有效地过滤出了易错标签简易实例（MEEs）。
### Conclusion
实验结果表明，在CIFAR、WebVision和完整的ImageNet-1k数据集上，该方法能够有效地提高样本选择和模型性能，通过减少MEEs实现这一目标。
## 908. `cs.LG` - Nadaraya-Watson插值器中的良性过拟合之外 [PDF](https://arxiv.org/pdf/2502.07480), [HTML](https://arxiv.org/abs/2502.07480)
### Authors
Daniel Barzilai,Guy Kornowski,Ohad Shamir
### Background
近年来，人们对理解插值预测的一般行为产生了浓厚兴趣，这些预测在嘈杂的训练数据上过度拟合。虽然传统的分析主要关注方法是否具有一致性，但最近的观察表明，即使不一致的预测也能很好地泛化。本文回顾了经典的插值Nadaraya-Watson (NW) 估计器（也称为Shepard方法），并通过现代视角研究其泛化能力。通过对单一带宽类型的超参数进行调整，证明了从灾难性、良性和可控的过度拟合行为在非单调变化中存在多种过度拟合行为。结果强调了即使是经典插值方法也能表现出复杂得多的泛化行为。此外，结果表明，在调整超参数时，如果高估数据的固有维度比低估更不利，这是有害的。数值实验也补充了这一理论，展示了相同的现象。
### Innovation
通过研究经典的Nadaraya-Watson (NW) 估计器，展示了单个带宽类型超参数调整后存在的多种过度拟合行为，从灾难性到良性和可控，揭示了即使是传统插值方法也能表现出复杂的泛化行为。指出在调整超参数时，高估数据的固有维度比低估更有害。通过数值实验验证了这些理论发现。
### Conclusion
研究强调了即使是经典的插值方法也能表现出复杂的泛化行为。实验结果表明，高估数据的固有维度比低估更有害。
## 909. `cs.LG` - 带有可验证奖励的强化学习：GRPO的有效损失、动态及成功率放大 [PDF](https://arxiv.org/pdf/2503.06639), [HTML](https://arxiv.org/abs/2503.06639)
### Authors
Youssef Mroueh
### Background
近年来引入了一种新的方法Group Relative Policy Optimization (GRPO)，用于在二元验证奖励的背景下提高大型语言模型（LLMs）的推理能力。GRPO利用可验证的二元奖励来促进强化学习（RL）中的推理，通过对比损失来提升模型的表现。
### Innovation
该研究分析了不同类型的奖励标准化和正则化更新的方法，包括仅使用均值标准化、均值和方差标准化，以及使用KL散度对更新进行两种不同形式的正则化：一种是对上一模型的偏离进行惩罚，另一种是对固定参考模型的偏离进行惩罚，还结合了两种形式。研究表明，每种方法都有一个显式的最佳策略形式，并且迭代会产生一个序列，其成功的概率满足简单的递归关系，最终收敛于由参考成功率和正则化强度确定的固定点，且带有参考模型的正则化可以放大策略的成功概率。
### Conclusion
GRPO通过对比损失优化展示了提升成功率的有效性，并且通过引入特定的奖励标准化和正则化策略，保证了在更新过程中不会远离旧策略。该研究揭示了GRPO通过对比策略来放大成功率的机制，并验证了其有效性。
## 910. `cs.LG` - CayleyPy RL: Cayley图上的路径规划与强化学习 [PDF](https://arxiv.org/pdf/2502.18663), [HTML](https://arxiv.org/abs/2502.18663)
### Authors
A. Chervov,A. Soibelman,S. Lytkin,I. Kiselev,S. Fironov,A. Lukyanenko,A. Dolgorukova,A. Ogurtsov,F. Petrov,S. Krymskii,M. Evseev,L. Grunvald,D. Gorodkov,G. Antiufeev,G. Verbii,V. Zamkovoy,L. Cheldieva,I. Koltsov,A. Sychev,M. Obozov,A. Eliseev,S. Nikolenko,N. Narynbaev,R. Turtayev,N. Rokotyan,S. Kovalev,A. Rozanov,V. Nelin,S. Ermilov,L. Shishina,D. Mamayeva,A. Korolkova,K. Khoruzhii,A. Romanov
### Background
这篇论文是关于在极其庞大的图（例如10^70个节点）上开发高效的人工智能路径规划方法的一系列研究中的第二篇，重点是Cayley图及其数学应用。该研究的核心是开源项目CayleyPy。论文在这里提出了一种新的方法，将强化学习与之前论文中的直接扩散距离方法结合起来。分析包括对方法的关键构建块进行基准测试：神经网络架构、随机游动生成器以及束搜索路径搜索。比较这些方法与经典的计算机代数系统GAP，展示了在研究的示例中他们的优越性。
### Innovation
论文提出了CayleyPy项目中的一个新的方法组合，即强化学习方法与直接扩散距离方法的结合。具体来说，通过对比分析不同的神经网络架构、随机游动生成器和束搜索路径搜索策略，并与经典计算机代数系统GAP进行比较，证明这些方法在考虑的示例中优于GAP。为对称群的循环移位和转置生成器构成的Cayley图进行了特别的数学应用研究。利用机器学习和数学方法，为OEIS-A186783置换群直径猜想（猜想直径为n(n-1)/2）提供了强有力的支持。通过生成猜想中的最长元素并分解为所需长度，对其进行了直径的上下界证明。
### Conclusion
通过对这些方法的详细分析，证明了其在Cayley图路径规划方面的有效性。同时，通过揭示这些方法的一些观测数据，提出了一些新的猜想，并展示了有关中心极限现象、图的谱的均匀分布以及排序网络的数值研究。为了促进开源贡献，创建了Kaggle平台上的挑战，以改进和基准测试Cayley图路径规划和其他任务的方法。
## 911. `cs.LG` - Týr-the-Pruner：通过全局稀疏度分布优化进行大语言模型结构剪枝 [PDF](https://arxiv.org/pdf/2503.09657), [HTML](https://arxiv.org/abs/2503.09657)
### Authors
Guanchen Li,Yixing Xu,Zeping Li,Ji Liu,Xuanwu Yin,Dong Li,Emad Barsoum
### Background
现有的结构剪枝方法虽然能够提高大规模语言模型（LLMs）的推理效率，但通常无法保持与原本模型相近的性能。局部剪枝可以通过逐层压缩实现高效剪枝，但忽略了全局拓扑。全局剪枝虽然旨在找到最优的稀疏模型，但传统的方法采用两阶段的策略，即首先评估子结构的重要性，然后再进行全局剪枝，这种方法忽视了结构之间的依赖性，导致无法实现端到端的优化。这些限制促使研究人员开发了Týr-the-Pruner框架，一种端到端基于搜索的全局结构剪枝框架，以解决这些不足之处。
### Innovation
Týr-the-Pruner框架通过在不同稀疏度比例下逐层应用局部剪枝构建了一个超网络，核心目标是确定在目标整体稀疏度比例下的最优稀疏分布。同时，该框架还引入了有效的地方剪枝方法和期望误差累积方法以改进超网络的构建，并使用从粗到细的稀疏度粒度迭代剪枝和搜索策略，以确保高效搜索收敛。
### Conclusion
实验证明，Týr-the-Pruner在结构剪枝方面达到了最先进的技术水平，在Llama-3.1-70B模型中，提高了推理效率，同时保留了97%的密集模型性能，去除了50%的模型参数。该论文的研究结果表明，Týr-the-Pruner能够通过全局稀疏度分布优化显著提升LLMs的性能和效率。
## 912. `cs.LG` - 使用基础推理模型进行上下文学习的随机微分方程 [PDF](https://arxiv.org/pdf/2502.19049), [HTML](https://arxiv.org/abs/2502.19049)
### Authors
Patrick Seifner,Kostadin Cvejoski,David Berghaus,Cesar Ojeda,Ramses J. Sanchez
### Background
随机微分方程（SDEs）描述了由确定性流动（由漂移函数支配）和随机波动（由扩散函数支配）叠加的动态系统。从数据中准确估计（或发现）这些函数是机器学习中的关键问题，并在自然科学和社会科学中有广泛应用。然而，当前的解决方案要么依赖于对动态的大量先验知识，要么涉及复杂的训练程序。FIM-SDE（基础推理模型）旨在解决这一问题，为低纬度SDE提供准确的上下文估计，并允许快速以目标数据集为准的调整。通过利用概略推理和神经运算的概念，FIM-SDE被监督预训练，以将大量离散观察的噪声SDE路径映射到漂移和扩散函数的空间。
### Innovation
FIM-SDE是第一款用于准确估计低维度SDE的漂移和扩散函数的预训练识别模型，从嘈杂的时间序列数据中进行全局估计和上下文估计，同时提供了快速针对目标数据集调整的能力。它利用来自概略推理和神经运算的概念，预训练FIM-SDE以将大量噪声、分段观察的SDE路径映射到漂移和扩散函数的空间。与符号、高斯过程和神经SDE基线相比，它在广泛的真实世界过程中展示了鲁棒的上下文函数估计，而这些基线是在目标数据集上进行训练的。当我们以目标过程中修改FIM-SDE时，它在所有这些基线中表现出更优的性能。
### Conclusion
FIM-SDE在合成和真实世界的多种过程中，展示了无与伦比的鲁棒上下文函数估计性能，并且在特定目标过程中进行微调时，与基于目标数据集训练的符号、高斯过程和Neural SDE基线相比，FIM-SDE展示了持续的优势，表明其是处理此类问题的有效解决方案。
## 913. `cs.LG` - 无需失去节奏的地改变基底：一种高效的GPU替代MatMul在DNN中的方法 [PDF](https://arxiv.org/pdf/2503.12211), [HTML](https://arxiv.org/abs/2503.12211)
### Authors
Nir Ailon,Akhiad Bercovich,Yahel Uffenheimer,Omri Weinstein
### Background
现代AI依赖于大规模的矩阵乘法运算（MatMuls），这些运算在推理和训练中的计算量构成了可扩展性问题。本文旨在提出一种新的替代方法，该方法是一个符合GPU特性的双线性运算符，能够在神经网络中替代矩阵乘法，同时在速度、准确性和参数数量之间提供三重权衡。
### Innovation
本文提出了一种新的双线性运算符Strassen-Tile (STL)，它在评估时所需的基本运算量（FLOPs）显著减少（远小于$n^3$），但在参数数量上增加（远大于$n^2$）。关键在于局部可学习的基底变化应用于权重和激活矩阵的块上，随后通过矩阵乘法实现块之间的逐元素乘法。研究了如何优化给定层的基底变换问题，这是一个高度非凸的问题。理论支持的初始化方法优于随机SGD初始化，表明STL在深度神经网络(Deep Neural Networks, DNNs)中优化方面的研究值得进一步进行。实验结果显示，STL能够在保持高准确率的同时，将4x4矩阵乘法的FLOPs减少2.66倍，并能够提升T2T-ViT-7模型的ImageNet-1K准确性，同时降低FLOPs。
### Conclusion
STL作为一种新的矩阵乘法替代方法，能够在计算受限的情况下实现时钟速度提升，同时为可扩展和成本效益高的AI提供了有希望的构建块。这些实验结果及其理论基础表明，STL是一个重要的创新工具。
## 914. `cs.LG` - 高效验证的机器卸载方法以支持蒸馏 [PDF](https://arxiv.org/pdf/2503.22539), [HTML](https://arxiv.org/abs/2503.22539)
### Authors
Yijun Quan,Zushu Li,Giovanni Montana
### Background
随着GDPR和CCPA等隐私法规的出台，对数据隐私的需求不断提升。当前的卸载方法需要能够迅速消除特定训练点的影响。尽管现有模型如SISA通过数据切片和检查点能够有效地对单个模型进行卸载，但在教师-学生知识蒸馏的场景下却不奏效。因为在蒸馏过程中信息传播广泛，教师侧的卸载通常会导致学生侧的完全重新训练，成本高昂。
### Innovation
我们提出了一种名为PURGE（分区卸载与重新训练保证的集成模型）的创新框架，将验证卸载与蒸馏相结合，引入组映射和增量多教师策略，将蒸馏过程拆分为多个阶段。每个教师只影响特定的学生数据子集，并保持数据隔离。这大大减少了重新训练的开销，仅在教师侧卸载发生时，才需要对学生进行部分更新。理论分析和多数据集的实验证明，这种方法可以在保持学生准确率与标准基线相当的情况下，显著加速卸载过程。
### Conclusion
我们的研究表明，PURGE框架在减少重新训练成本和维护学生准确率方面表现出显著的优越性。该方法适用于实际应用场景中支持隐私保护的需求。
## 915. `cs.LG` - 能量匹配：生成建模中的流动匹配和能量基模型的统一框架 [PDF](https://arxiv.org/pdf/2504.10612), [HTML](https://arxiv.org/abs/2504.10612)
### Authors
Michal Balcerak,Tamaz Amiranashvili,Antonio Terpin,Suprosanna Shit,Lea Bogensperger,Sebastian Kaltenbach,Petros Koumoutsakos,Bjoern Menze
### Background
当前最先进的生成模型通过匹配流动或得分将噪声映射到数据分布。这些模型的一个关键限制是它们无法轻易地整合可用的部分观察和额外先验知识。与此相反，能量基模型（EBMs）通过引入相应的标量能量项来解决这个问题。本文提出了一种能量匹配框架，赋予基于流动的方法EBMs一样的灵活性。远离数据流形的样本从噪声沿不可旋转、最优运输路径逐渐移动到数据，当它们接近数据流形时，熵能量项引导系统进入玻尔兹曼平衡分布，明确捕捉数据的潜在似然结构。
### Innovation
本文提出了一种能量匹配框架，将能量基模型的灵活性与基于流动的方法结合起来。该方法使用一个单一的时间独立标量场参数化动力学，既作为强大的生成器，也作为灵活的先验，用于有效的逆问题正则化。这种方法在CIFAR-10和ImageNet生成中显著优于现有EBMs，在保真度方面表现出色，同时保留了非仿真训练运输基方法的能力，远离数据流形。此外，利用方法的灵活性引入了交互能量，支持对多种模式的探索，在受控的蛋白质生成设置中进行了验证。该方法无需时间条件、辅助生成器或额外网络即可学习标量势能，这与最近的EBM方法有显著区别。
### Conclusion
本文简化但严谨的公式显著推进了EBMs的功能，为它们在不同领域生成建模中的更广泛采用铺平了道路。
## 916. `cs.LG` - 启用自动微分的平滑图神经算子 [PDF](https://arxiv.org/pdf/2504.08277), [HTML](https://arxiv.org/abs/2504.08277)
### Authors
Ryan Y. Lin,Julius Berner,Valentin Duruisseaux,David Pitt,Daniel Leibovici,Jean Kossaifi,Kamyar Azizzadenesheli,Anima Anandkumar
### Background
物理信息神经算子通过结合数据和物理损失提供了学习偏微分方程解算子的强大框架。然而，这些物理损失依赖于导数的计算，这在有限分辨率下仍然具有挑战性，导致谱方法和差分方法出现近似误差。
### Innovation
提出了平滑图神经算子（$m$GNO），这是第一个利用自动微分计算任意几何结构上的精确梯度的方法。这使得在不规则网格上高效训练并允许无缝评估在随机采样点的物理损失，以提高推广性。
### Conclusion
在对结构化网格进行的PDE示例中，$m$GNO与autograd相比，L2相对数据误差降低了20倍，尽管 training 较慢。它还可以无缝解决不规则点云上的PDE计算，使用物理损失，分辨率远低于有限差分法准确所需的分辨率。在不规则的点云上，$m$GNO导致的误差比机器学习基准（加速PINNs的Meta-PDE）低2个数量级，且在类似运行时间内提供更高的准确性。此外，$m$GNO相比数值求解器在类似的准确性下提供了1到3个数量级的速度提升。$m$GNO还可以用于解决复杂几何上的反设计和形状优化问题。
## 917. `cs.LG` - 基于神经网络的递增分配方法用于最大公共边子图计算 [PDF](https://arxiv.org/pdf/2505.12325), [HTML](https://arxiv.org/abs/2505.12325)
### Authors
Chaolong Ying,Yingqi Ruan,Xuemin Chen,Yaomin Wang,Tianshu Yu
### Background
最大公共边子图（MCES）问题在生物学和化学等领域具有重要意义，但传统的基于最大团和搜索算法的方法在处理大规模实例时面临可扩展性问题。
### Innovation
本文提出了一种简单且可扩展的非监督学习方法——神经递增分配（NGA），将可微分配优化与神经网络组件堆叠，通过可学习的温度机制实现高维参数化匹配过程，同时对NGA的学习动态进行了理论分析，显示其设计能够实现快速收敛、更好的探索-利用权衡以及避免局部最优的能力。
### Conclusion
实验结果表明，NGA不仅在处理大规模实例时显著提高了计算时间和可扩展性，还在性能方面优于现有方法。NGA的引入为MCES计算带来了显著的进步，并为其他分配问题提供了见解。
## 918. `cs.LG` - 基于时间的突触可塑性学习作为有噪声的梯度下降 [PDF](https://arxiv.org/pdf/2505.10272), [HTML](https://arxiv.org/abs/2505.10272)
### Authors
Niklas Dexheimer,Sascha Gaudlitz,Johannes Schmidt-Hieber
### Background
突触可塑性是生物神经网络学习的关键原则之一。基于时间的突触可塑性（STDP）规则是一种常见的学习机制，它依赖于前一个神经元的发放时间与后一个神经元的发放时间之间的关系来调整突触权重的变化。尽管已有很多关于STDP学习的理论工作，但将其直接与经典的梯度下降方法联系起来，在有噪声的环境中且面对非凸优化问题时的工作相对较少。这篇论文探讨了STDP规则与有噪声的梯度下降之间的联系，尤其是在这样的环境下STDP的收敛特性。
### Innovation
文章创新性地将基于时间的Hebbian学习规则与有噪声的梯度下降相联系，特别是在面对非凸优化问题和持续的噪声注入情况下，证明了STDP学习动态能够有效地识别具有最高活动的前突触神经元，并且收敛速度是指数级的。这一发现挑战了传统观念，即有噪声的梯度下降通常只会收敛到一个波动的最小值附近。这项工作提供了一个新的理论视角，解释了STDP学习机制的高效性和鲁棒性。
### Conclusion
本文通过分析证明，在有噪声环境中基于时间的Hebbian学习动态不仅能够有效地识别出活动最高的前突触神经元，而且其收敛速度非常快，是指数级别的。这与传统的有噪声梯度下降理论截然不同，后者通常只会收敛到一个波动的最小值附近。这一发现对于理解神经网络的自组织学习过程以及开发新的机器学习算法具有重要意义。
## 919. `cs.LG` - FlashBias: 快速计算带有偏差的注意力 [PDF](https://arxiv.org/pdf/2505.12044), [HTML](https://arxiv.org/abs/2505.12044)
### Authors
Haixu Wu,Minghao Guo,Yuezhou Ma,Yuanxu Sun,Jianmin Wang,Wojciech Matusik,Mingsheng Long
### Background
注意力机制中引入偏置可以显著增强模型性能，尤其是在视觉、语言、蛋白质折叠等复杂模型中广泛应用。然而，这种引入偏置的方式会极大地影响计算效率，尤其是在加速器（如FlashAttention）的应用中，这使得带有偏置的注意力计算变得昂贵且低效。尽管带偏置的注意力机制被广泛应用，但针对其效率优化的研究却相对缺乏，导致其在复杂任务中的应用受到限制。研究表明，FlashAttention的最大效率由注意力权重矩阵的秩决定。基于这一理论结果，本文提出了FlashBias，它能够提供多类常用注意力偏置的快速精确计算，并对一般的注意力偏置提供快速准确的近似计算。FlashBias充分利用现代GPU中矩阵乘法的高度优化操作，相较于Pairformer在AlphaFold 3中实现了1.5倍的加速，且在视觉和语言模型中对于带有偏置的注意力计算实现了超过2倍的加速，同时保持了准确性。代码开源发布：this https URL
### Innovation
FlashBias基于低秩压缩感知理论，提供了一种快速精确计算多种常用注意力偏置的方法，并对一般的注意力偏置提供快速准确的近似计算。该方法能充分利用现代GPU中矩阵乘法的高度优化操作，显著提高带有偏置的注意力计算速度，而不会损失准确性
### Conclusion
FlashBias能够提供针对带有偏置的注意力机制的快速高效的计算方法，适用于视觉和语言模型，显著提高了这些复杂模型的训练和推理速度，同时保持了准确性。
## 920. `cs.LG` - 如何学习上下文回忆任务？最优性、训练动力学与泛化 [PDF](https://arxiv.org/pdf/2505.15009), [HTML](https://arxiv.org/abs/2505.15009)
### Authors
Quan Nguyen,Thanh Nguyen-Tang
### Background
现有的理论结果仅关注经过一个梯度下降步骤训练后的变压器在上下文推理中的行为。关于通过梯度下降训练时变压器的收敛行为及其收敛速度仍然不清楚，而变压器在单步上下文推理中的泛化尚未正式研究。本研究旨在填补这些研究空白，探讨变压器在上下文回忆任务中的逼近能力、收敛速度和离线收敛行为。
### Innovation
研究表明，一类具有线性、ReLU或softmax注意力的变压器在上下文召回任务中是可证明的最佳贝叶斯模型。通过有限样本分析表明，期望损失以线性速率收敛到贝叶斯风险。同时，证明了经过梯度下降训练的变压器具备离分布泛化能力，即能够泛化到总体分布之外的样本。理论发现得到了广泛实验证据的支持，显示了在适当参数化的情况下，具有更大表征能力的模型在梯度下降训练后可以实现较好的离分布泛化性能，否则会失败。
### Conclusion
本研究在上下文回忆任务中对变压器的最优性、训练动力学及其泛化行为进行了详细研究。证明了线性、ReLU或softmax注意力的变压器是可证明的最优模型，并展示了梯度下降训练在实现快速收敛速率和离分布泛化方面的能力。进一步的实验证据表明，模型的有效泛化依赖于适当的参数化。
## 921. `cs.LG` - 试与信：全面防御策略应对拜占庭攻击 [PDF](https://arxiv.org/pdf/2505.07614), [HTML](https://arxiv.org/abs/2505.07614)
### Authors
Gleb Molodtsov,Daniil Medyakov,Sergey Skorik,Nikolas Khachaturov,Shahane Tigranyan,Vladimir Aletov,Aram Avetisyan,Martin Takáč,Aleksandr Beznosikov
### Background
近年来，机器学习领域取得了显著进展，但同时也增加了计算需求。联邦和分布式系统虽然有助于解决这些问题，但其结构易受恶意影响。本文重点关注拜占庭攻击，这是由于受破坏的客户端向全局优化过程中注入敌对更新而导致的攻击方式。授权分数的概念与试函数方法的结合被引入以动态过滤异常值。我们的方法克服了以前方法的关键限制，即使拜占庭节点占多数时也能保持功能。此外，我们的算法能够适应广泛使用的方法如Adam和RMSProp，以及实际应用场景中的本地训练和部分参与。我们通过在合成数据和来自医疗机构的真实心电图（ECG）数据上进行了大量实验，验证了我们方法的鲁棒性。同时，我们还对算法及其扩展到上述实际设置提供了广泛的理论分析。
### Innovation
本文结合了授权分数的概念和试函数方法，提出了一种新的方法来动态过滤异常值，以应对拜占庭攻击。这种方法不仅能够确保即使当拜占庭节点占多数时也能保持系统的功能，还能与广泛使用的方法（如Adam和RMSProp）和实际应用场景（如本地训练和部分参与）兼容。进一步，我们提供了广泛的理论分析和实验验证，证明了我们的方法在鲁棒性和性能方面的有效性。这些方法的收敛保证也与不考虑拜占庭干扰的经典算法相当。
### Conclusion
我们提出的方法在心电图数据和模拟数据上都表现出色，具有很高的实用性和鲁棒性。同时，我们的算法能够适应不同的应用场景，并提供了可以与现有方法整合的解决方案。本文的工作在相应的实际设置下提供了详细的理论支持和实验验证，展示了我们的方法在应对拜占庭攻击时的有效性和可靠性。
## 922. `cs.LG` - 理解差分变换器释放预训练自注意力 [PDF](https://arxiv.org/pdf/2505.16333), [HTML](https://arxiv.org/abs/2505.16333)
### Authors
Chaerin Kong,Jiho Jang,Nojun Kwak
### Background
差分变换器因其卓越的实验性能而受到广泛关注，通常归因于其噪声抑制注意力的能力。然而，差分注意力如何实现其实际益处的具体机制仍然了解不足。此外，差分变换器架构需要大规模从头开始训练，阻碍了利用公开预训练权重的应用。
### Innovation
本文深入研究差分变换器，揭示了其成功背后的三个关键因素：（1）通过负注意力增强表现力，（2）减少注意力头之间的冗余性，（3）改善学习动态。基于这些发现，提出了一种名为DEX的方法，能够高效地将差分注意力的优点集成到预训练语言模型中。通过重用softmax注意力分数并在输出值矩阵上添加轻量级差分操作，DEX在训练和推理中均保持轻量级，同时大幅提高预训练的大规模语言模型在多样基准上的性能。
### Conclusion
评估结果表明，DEX在各种基准测试中显著提高了预训练的大规模语言模型的性能，仅需少量调整数据即可实现重要的性能提升。
## 923. `cs.LG` - 扩散模型的时空观：信息几何视角 [PDF](https://arxiv.org/pdf/2505.17517), [HTML](https://arxiv.org/abs/2505.17517)
### Authors
Rafał Karczewski,Markus Heinonen,Alison Pouplin,Søren Hauberg,Vikas Garg
### Background
本文提出了一种新颖的几何视角来探讨扩散模型的潜在空间。现有的拉回方法利用确定性的概率流ODE解码器，存在根本性的缺陷。这种解码方法使得几何路径在数据空间中被直观地编码为直线段，忽视了数据的内在几何复杂性。尽管通过逆SDE可引入随机解码器，并且可以使用Fisher-Rao度量进行信息几何处理，但选择$x_T$作为潜在表示会导致度量崩溃，这是由于其记忆缺失性。
### Innovation
本文通过引入潜在时空$z=(x_t,t)$来应对上述问题，这种措施索引了所有噪声尺度下的去噪分布族$p(x_0 | x_t)$，从而形成了非平凡的几何结构。我们证明了这些分布形成了指数分布族，并推导出了无需模拟的曲线长度估计器，使高效地计算几何路径成为可能。由此形成的几何结构导出了具有原则性的扩散编辑距离，其中几何路径追踪了数据之间最小化噪声和去噪编辑的序列。
### Conclusion
本文的研究不仅提出了扩散模型的一个新的几何视角，而且进一步展示了其潜在时空方法在分子系统中的转移路径采样上的优势，包括低方差过渡和区域规避的约束变体。
## 924. `cs.LG` - MetaBox-v2: 一种统一的元黑盒优化基准平台 [PDF](https://arxiv.org/pdf/2505.17745), [HTML](https://arxiv.org/abs/2505.17745)
### Authors
Zeyuan Ma,Yue-Jiao Gong,Hongshu Guo,Wenjie Qiu,Sijie Ma,Hongqiao Lian,Jiajun Zhan,Kaixu Chen,Chen Wang,Zhiyang Huang,Zechuan Huang,Guojun Peng,Ran Cheng,Yining Ma
### Background
Meta-Black-Box Optimization (MetaBBO) 的自动化设计通过元学习得到了简化。元学习通过元级策略的元训练，减少在开发低级优化任务算法时所需的手动努力。MetaBox (2023) 提供了第一个基于强化学习的单目标元黑盒优化的开源框架，但其窄范围已无法跟上这一领域的快速发展。该论文介绍了一种名为MetaBox-v2的新版本，它是在原有版本上的里程碑升级。
### Innovation
MetaBox-v2 引入了四个创新特征：1) 支持基于强化学习、进化和梯度优化方法的统一架构，复现了23个最新的基线；2) 有效的并行化方案，将训练/测试时间减少了10-40倍；3) 包含了18个合成/现实任务的基准套件（1900+ 个实例），涵盖单目标、多目标、多模型和多任务优化场景；4) 丰富的可扩展接口，便于自定义分析/可视化和集成外部优化工具/基准。
### Conclusion
该论文通过系统性的案例研究，评估了内置基线的优化性能、泛化能力和学习效率。通过详细分析，为从业者和新入门者提供了有价值的经验教训。
## 925. `cs.LG` - GraSS: 基于梯度稀疏化的可扩展数据归因及稀疏投影 [PDF](https://arxiv.org/pdf/2505.18976), [HTML](https://arxiv.org/abs/2505.18976)
### Authors
Pingbang Hu,Joseph Melkonian,Weijing Tang,Han Zhao,Jiaqi W. Ma
### Background
梯度基于的数据归因方法，例如影响函数，对于理解单个训练样本的影响至关重要，无需重复模型重新训练。然而，这些方法的扩展性受到单个样本梯度计算的高计算和内存成本限制。这些方法通常难以处理大规模数据集，因为需要对每个样本进行梯度计算，这带来了巨大的计算负担和高内存占用率。因此，需要一种既能保持数据影响力的准确性，又能减少计算和内存开销的方法来改进当前的梯度计算方法。
### Innovation
提出了一种新型的梯度压缩算法GraSS及其针对线性层的变体FactGraSS，这两种方法明确利用了每个样本梯度的固有稀疏性，以实现亚线性空间和时间复杂度。这些方法通过稀疏化梯度并进行稀疏投影，降低了对每个样本进行梯度计算的需求，使得大规模数据集上的应用变得可能，同时保持了数据影响力的准确性。
### Conclusion
广泛的实验验证了GraSS和FactGraSS的有效性，与之前最先进的基准相比，实现了显著的加速效果，特别是在处理模型数量级达到十亿规模时，FactGraSS的速度提高了165%。该研究的代码已经公开。
## 926. `cs.LG` - Sign-SGD 是多节点到单节点学习的金门大桥：基于参数无约束优化的显著提升 [PDF](https://arxiv.org/pdf/2506.03725), [HTML](https://arxiv.org/abs/2506.03725)
### Authors
Daniil Medyakov,Sergey Stanko,Gleb Molodtsov,Philip Zmushko,Grigoriy Evseev,Egor Petrov,Aleksandr Beznosikov
### Background
近期，大型语言模型在多个学科取得了重大突破，然而，它们的训练是一个极其资源密集型的任务，即使是拥有大量计算资源的主要玩家也不例外。为应对这些挑战，一种流行的方法是 Sign-SGD。它可以作为单节点训练中的内存高效方法或分布式学习中的梯度压缩技术使用。尽管如此，从理论上难以自动确定有效的步长，因为这取决于我们无法在实际学习范式中访问的数据集参数。
### Innovation
设计了几种单节点确定性 Sign-SGD 的变体，将方法扩展到实际场景：随机单节点和多节点学习以及包含动量的方法。通过广泛的实验来强调我们想法的实用可操作性。
### Conclusion
针对 Sign-SGD 无法从理论上自动确定有效步长的问题，作者设计了一系列单节点确定性的 Sign-SGD 变体，并将其应用到多个实际场景中，并通过大量实验验证了方法的有效性和实用性。
## 927. `cs.LG` - REOrdering Patches Improves Vision Models [PDF](https://arxiv.org/pdf/2505.23751), [HTML](https://arxiv.org/abs/2505.23751)
### Authors
Declan Kutscher,David M. Chan,Yutong Bai,Trevor Darrell,Ritwik Gupta
### Background
序列模型如变压器需要将输入表示为一维序列。在视觉任务中，这通常涉及将图像按照固定顺序（行为主序，即页面扫描顺序）展平。虽然全自注意力机制对置换是等变的，但现代长序列变压器越来越依赖于破坏这种不变性的架构近似，从而使得对块顺序变得敏感。研究表明，在这种情况下，块顺序显著影响模型性能。简单的替代方案，如列地位序或希尔伯特曲线，可以带来显著的准确率提升。
### Innovation
本文提出了REOrder，一个两阶段框架，旨在发现任务最优的块排序方式。首先，通过评估不同块序列的可压缩性，推导出信息理论先验。然后，通过优化Plackett-Luce策略并利用REINFORCE进行优化，学习一个置换策略。这种方法能在组合置换空间中实现高效的模型学习。REOrder在ImageNet-1K上的顶级准确率比行主序高3.01%，在“地图函数”的准确率提升13.35%。
### Conclusion
REOrder作为一种两阶段框架，通过从信息论先验出发，并结合优化的置换策略学习，有效提升了视觉模型的性能。特别是在处理大型序列模型时，通过优化块顺序显著提升了模型的准确率。该方法为视觉模型中的块排序提供了新的视角和解决方案。
## 928. `cs.LG` - 噪声中的噪声鲁棒性：一种结合非对称LoRA和污染专家混合架构的框架 [PDF](https://arxiv.org/pdf/2505.23868), [HTML](https://arxiv.org/abs/2505.23868)
### Authors
Zhaokun Wang,Jinyu Guo,Jingwen Pu,Lingfeng Chen,Hongli Pu,Jie Ou,Libo Qin,Wenhong Tian
### Background
当前参数高效微调方法在适应预训练语言模型到下游任务时容易受到噪声数据的干扰。传统的噪声处理方法要么依赖于繁琐的数据预处理，要么通过容易积累错误的模型结构修改来应对噪声。相比之下，本文提出了一种通过 LoRA 污染专家（LoPE）的噪声鲁棒适应方法，这是一个新颖的框架，仅通过生成的噪声数据来增强模型对噪声的鲁棒性。该框架借鉴了混合专家架构的想法，通过在非对称LoRA配置中战略性地整合专用污染专家，实现噪声的注入和处理能力增强。在推理时，通过选择性地掩蔽专用污染专家来充分利用普通专家获得的纯净知识，以实现鲁棒输出。实验结果表明，LoPE 通过低成本的噪声注入实现了良好的性能和鲁棒性，完全消除了数据清洁的需要。
### Innovation
提出了通过 LoRA 污染专家（LoPE）的噪声鲁棒适应方法，这是一个新颖的框架，仅通过生成的噪声数据来增强模型对噪声的鲁棒性。该方法在混合专家架构的基础上，通过在非对称LoRA配置中战略性地整合专用污染专家，实现噪声的注入和处理能力增强，从而有效地提升了模型的鲁棒性和准确性。
### Conclusion
实验证明，LoPE 通过低成本的噪声注入实现了强大的性能和鲁棒性，完全消除了数据清洁的需要。
## 929. `cs.LG` - 正确执行逆Q-学习：在$Q^?pi$可实现MDPs中的离线模仿学习 [PDF](https://arxiv.org/pdf/2505.19946), [HTML](https://arxiv.org/abs/2505.19946)
### Authors
Antoine Moulin,Gergely Neu,Luca Viano
### Background
研究Markov决策过程（MDPs）中的离线模仿学习问题，目标是利用专家生成的状态-动作对数据集学习一个高性能策略。先前的研究假设专家属于一个已知的可处理政策类，而本文则从一种新的角度出发，利用环境的另一种结构假设。针对线性$Q^?pi$可实现MDPs，本文提出了一种新的算法：鞍点离线模仿学习（镇-版offline imitation learning，‘SPOIL?u2019），该算法能够近似匹配任何专家的表现，且样本数量为$?mathcal{O}(?varepsilon^{-2})$。对于可能非线性的$Q^?pi$可实现MDPs，算法扩展到需要更多样本，即$?mathcal{O}(?varepsilon^{-4})$。此外，分析表明一种新的损失函数适用于深度模仿学习中的评论员网络训练。
### Innovation
本文提出了一种针对线性$Q^?pi$可实现MDPs的新算法：鞍点离线模仿学习（镇-版offline imitation learning，‘SPOIL?u2019）。对于线性$Q^?pi$可实现MDPs，算法能够近似匹配任何专家的表现，且样本数量为$?mathcal{O}(?varepsilon^{-2})$。此外，算法扩展到可能非线性的$Q^?pi$可实现MDPs，但需要更多的样本数量。最重要的是，分析表明一种新的损失函数适用于深度模仿学习中的评论员网络训练。
### Conclusion
神经网络实现的SPOIL在标准基准测试中的表现优于行为克隆，并且与最先进的算法相当。
## 930. `cs.LG` - 去噪未来: 基于上p分布的时间推移 [PDF](https://arxiv.org/pdf/2506.07578), [HTML](https://arxiv.org/abs/2506.07578)
### Authors
Florian Andreas Marwitz,Ralf Möller,Magnus Bender,Marcel Gehrke
### Background
动态概率模型中的推断是一项复杂的任务，涉及昂贵的操作。特别是对于隐马尔可夫模型，必须遍历整个状态空间以进行时间序列推进。即使那些概率极小的状态也被纳入考虑，导致计算效率低下和由于不可能概率质量传播而增加噪声。
### Innovation
提出了一种使用仅上p状态（即累积概率为p的最可能状态）的方法来减少噪声和加速推断。该方法的错误与p和底层模型的最小混杂率有关。实验证明，可以实现至少一数量级的加速，同时总变差距离误差低于0.09。
### Conclusion
该研究表明，使用仅上p状态的方法可以有效降低噪声并加速隐马尔可夫模型的推断，同时保持较低的误差水平。
## 931. `cs.LG` - PAUSE：强化隐私保护与低延迟的联邦学习主动用户选择方法 [PDF](https://arxiv.org/pdf/2503.13173), [HTML](https://arxiv.org/abs/2503.13173)
### Authors
Ori Peleg,Natalie Lang,Dan Ben Ami,Stefano Rini,Nir Shlezinger,Kobi Cohen
### Background
联邦学习（FL）允许多个边缘设备协同训练机器学习模型，而不必分享可能敏感的数据。FL通过迭代交换模型更新，面临的两大主要挑战是隐私泄露的累积和通信延迟。为了应对这些挑战，通常分别通过隐私增强和用户选择来缓解，但这两者都会影响准确性。该研究提出了一种方法，通过主动用户选择联合解决隐私泄露累积和通信延迟问题，以改善隐私、延迟和模型性能之间的权衡。为此，构建了一个综合考虑这三个目标的奖励函数，并基于此奖励提出了一种基于多臂bandit（MAB）的算法——PAUSE，逐步选择每一轮的子集用户，在确保整体隐私泄露控制在一定范围内的同时减小延迟。建立理论分析，系统性地展示了PAUSE的奖励增长率遵循MAB文献中最佳已知速率。为了解决主动用户选择的复杂性，又提出了一种基于模拟退火的PAUSE宽松版本，并分析了在复杂度降低情况下其近似奖励最大化策略的能力。通过数值验证，展示了PAUSE方法在各种场景下对联邦训练中的隐私泄露、伴随的延迟改善以及准确性的增益。
### Innovation
该研究创新性地提出了一种名为PAUSE的算法，通过主动用户选择同时解决联邦学习中的隐私泄露累积和通信延迟问题，实现了对这三个目标的综合优化；基于MAB构建了考虑隐私、延迟和准确性多重目标的奖励函数；并通过模拟退火提供了一种在保证降低复杂性条件下近似优化的方法；在理论分析和数值验证两方面证明了其有效性。
### Conclusion
该研究提出的PAUSE算法有效解决了联邦学习中的隐私泄露累积和通信延迟问题，通过增强隐私保护和减小延迟改善了模型性能。理论上证明了PAUSE的优化效果，并通过数值验证验证了其有效性，为联邦学习技术的应用提供了新的选择。
## 932. `cs.LG` - 在结构化流形上的在上下文学习理解：将注意力机制与核方法衔接 [PDF](https://arxiv.org/pdf/2506.10959), [HTML](https://arxiv.org/abs/2506.10959)
### Authors
Zhaiming Shen,Alexander Hsu,Rongjie Lai,Wenjing Liao
### Background
尽管在上下文学习（ICL）已经在自然语言和视觉领域取得了显著的成功，但在结构化的几何数据环境中对其实质的理解，特别是在流形结构上进行霍尔德函数回归中的理解仍然没有被深入探讨。
### Innovation
本文建立了注意力机制与经典核方法之间的全新联系，展示了变压器如何通过与提示的交互有效地执行基于核的预测。此外，还依据此洞察建立了泛化误差边界，并在一定数量的训练任务后达到了霍尔德函数在流形上的最小最大回归率，这一回归率与流形的内在维度成指数级关系，而不是与流形周围的维度成线性关系。结果揭示了变压器作为在上下文内核算法学习器的综合复杂性，从而为研究非线性模型的在上下文学习提供新的工具。
### Conclusion
论文的研究为ICL中的几何作用提供了基础性见解，并揭示了泛化误差随训练任务数量变化的规律，从而阐明了变压器在非线性模型中上下文学习的作用。
## 933. `cs.LG` - FlexQuant：大语言模型量化中的一种灵活高效的动态精度切换框架 [PDF](https://arxiv.org/pdf/2506.12024), [HTML](https://arxiv.org/abs/2506.12024)
### Authors
Fangxin Liu,Zongwu Wang,JinHong Xia,Junping Zhao,Shouren Zhao,Jinjin Li,Jian Liu,Li Jiang,Haibing Guan
### Background
大语言模型（LLMs）的快速发展加剧了记忆力瓶颈，因为模型参数规模与硬件能力之间的差距扩大了。现有的后训练量化技术能够有效减少内存占用，但这些方法主要依赖于静态量化策略，难以适应动态工作负载。
### Innovation
提出了一种名为FlexQuant的动态精度切换框架，优化了推理速度与准确性的权衡。FlexQuant利用模型困惑度熵和Kullback-Leibler散度，进行细粒度、逐层混合精度量化，并在每次生成标记时动态调整位宽。
### Conclusion
FlexQuant 实现了跨多种语言任务1.3倍的端到端加速，几乎无准确率损失。该框架提供了灵活且自适应的解决方案，用于高效的大语言模型部署。
## 934. `cs.LG` - 生成模型或判别模型？在transformer时代重新审视文本分类 [PDF](https://arxiv.org/pdf/2506.12181), [HTML](https://arxiv.org/abs/2506.12181)
### Authors
Siva Rajesh Kasa,Karan Gupta,Sumegh Roychowdhury,Ashutosh Kumar,Yaswanth Biruduraju,Santhosh Kumar Kasa,Nikhil Priyatam Pattisapu,Arindam Bhattacharya,Shailendra Agarwal,Vijay huddar
### Background
自Efron对逻辑回归与判别分析的先驱性分析以来，判别分类器和生成分类器之间的比较就引起了研究者的兴趣。早期的理论工作表明，在简单线性设置中，生成分类器会在样本复杂性上表现出较低的要求，但在渐近误分类率上相对较高。然而，在transformer时代，这些权衡尚未被探索。
### Innovation
本文首次全面评估了现代生成和判别架构——自回归建模、掩码语言建模、离散扩散以及编码器在文本分类任务中的表现。研究揭示了经典的'两种模式'现象在不同架构和训练范式下的表现差异，并在多种场景中分析了准确度、样本效率、校准、噪声鲁棒性和序贯性。
### Conclusion
研究结果提供了根据实际约束条件（如延迟和数据限制）选择最合适的建模方法的实用指南。
## 935. `cs.LG` - 通过对平滑非凸不公正度量近似符施加约束实现公正监督学习 [PDF](https://arxiv.org/pdf/2505.15788), [HTML](https://arxiv.org/abs/2505.15788)
### Authors
Zahra Khatti,Daniel P. Robinson,Frank E. Curtis
### Background
论文提出了一种新的公平监督机器学习策略，与现有文献中的其他策略相比，其主要优势如下。首先，通过引入一种新的平滑非凸近似函数来逼近不连续的不公正度量中的海维赛德函数。这种方法利用了优化文献中的平滑技术，在公正监督学习文献中是新颖的。其次，不同于依赖可能导致优化问题难以解决的正则化器以及相应的正则化参数，新策略提出了使用硬约束的方法来强制执行特定的不公正容忍度，从而避免了正则化带来的复杂性。最后，该策略能够同时考虑多（可能冲突）的不公正度量约束，通过正则化方法可以考虑多个度量，但会导致更难解决的优化问题和更多的调参成本。相比之下，通过硬约束，新策略生成的优化模型可以有效且小量调整地解决。
### Innovation
提出了一个新的公平监督机器学习策略，该策略包括三种创新点：（a）使用新的平滑非凸近似函数来逼近不公正度量中的海维赛德函数。（b）采用硬约束而非正则化器及正则化参数，使得能够强制执行特定的不公正容忍度。（c）能够同时处理多个不公正度量约束。传统的正则化方法会导致更复杂的优化问题和更高的调参成本，而新策略通过硬约束使得优化模型可以容易且少量调参地解决。
### Conclusion
该策略能够提供一种新的公平监督机器学习方法，通过施加基于平滑非凸不公正度量近似符的硬约束，从而实现更加准确和泛化的公平预测模型，减少调参成本和优化难度。
## 936. `cs.LG` - 确立变压器类型架构的通用逼近性的一个统一框架 [PDF](https://arxiv.org/pdf/2506.23551), [HTML](https://arxiv.org/abs/2506.23551)
### Authors
Jingpu Cheng,Ting Lin,Zuowei Shen,Qianxiao Li
### Background
研究了变压器型架构的通用逼近性质（UAP），填补了先前基于残差网络的结果与包含注意力机制模型之间的空白。研究指出，标记可区分性是UAP的关键要求，并提出了一种适用于广泛架构的通用充分条件。通过假设注意力层的解析性，简化了这一条件的验证，为这类架构提供了非构造性的UAP建立方法。
### Innovation
提出了一个统一的理论框架，将先前关于残差网络的结果扩展到包含注意力机制的模型。引入了标记的可区分性作为UAP的前提，并为各种注意力机制下的变压器模型验证了UAP，包括基于核和稀疏注意力机制。这一框架为设计具有内在UAP保证的新架构，包括具有特定功能对称性的架构提供了原则基础。
### Conclusion
该框架为证明变压器类型架构的UAP提供了工具，适用于不同类型的注意力机制，并为未来的研究提供了新方向。
## 937. `cs.LG` - PARALLELPROMPT：从大型语言模型查询中提取并行性 [PDF](https://arxiv.org/pdf/2506.18728), [HTML](https://arxiv.org/abs/2506.18728)
### Authors
Steven Kolawole,Keshav Santhanam,Virginia Smith,Pratiksha Thaker
### Background
当前的LLM服务系统通常将用户提示作为单一输入进行处理，并通过解码技巧或查询批处理来优化推理。然而，许多实际的用户提示中包含潜在的语义并行性——可分解的结构，其中子任务可以独立执行以减少延迟但保持意义。
### Innovation
本文介绍了PARALLELPROMPT，这是第一个用于衡量自然用户提示内部查询并行性的基准。该基准包含来自公开LLM对话日志的超过37,000个真实提示，并且每个提示都标注了任务模板、共享上下文和迭代输入的结构化方案。这些方案通过规则辅助的多语言验证从LLM提示中提取。为评估分解的好处，提供了一个执行套件，比较了串行策略和并行策略的性能，测量了延迟、结构一致性以及语义保真度。结果显示，在超过75%的精选数据集中可以成功解析内部查询并行性，并在翻译、理解以及比较分析等任务中实现了最高5倍的加速，同时保持了较少的质量损失。
### Conclusion
通过发布这个基准、标注管道和评估套件，为研究LLM服务管道中的结构感知执行提供了第一个标准化测试平台。
## 938. `cs.LG` - Class-wise Balancing Data Replay for Federated Class-Incremental Learning [PDF](https://arxiv.org/pdf/2507.07712), [HTML](https://arxiv.org/abs/2507.07712)
### Authors
Zhuang Qi,Ying-Peng Tang,Lei Meng,Han Yu,Xiaoxiao Li,Xiangxu Meng
### Background
Federated class incremental learning (FCIL)旨在跨多个客户端协作处理不断增加的新任务。现有的数据重放方法可以重新引入之前任务的代表性样本来减轻遗忘问题，但通常受限于重放缓存中的类别不平衡问题，以及在重放样本与新到类别的类别不平衡。
### Innovation
为了解决上述问题，本文提出了一个针对FCIL的类别导向均衡数据重放方法（FedCBDR），该方法通过全局协调机制构建类别级别的内存，并重新权衡学习目标以缓解上述不平衡。FedCBDR有两个关键组件：1) 全局视角的重放模块以隐私保护的方式重建先前任务的全局表示，进而引导一个类别敏感的重要性采样策略以实现平衡的数据重放；2) 随后，任务感知的温度缩放模块根据任务动态自适应调整类和样本级的logits温度，从而减少模型在多数类别上的过度自信，同时增强对少数类别的敏感性。
### Conclusion
实验证明，FedCBDR实现了在异构数据分布下类别导向的数据均衡采样，并在任务不平衡情况下提高了泛化能力，相比于六种最先进的方法，在Top-1准确性上提高了2%-15%。
## 939. `cs.LG` - 段策略优化：大型语言模型中强化学习的有效段级信用分配 [PDF](https://arxiv.org/pdf/2505.23564), [HTML](https://arxiv.org/abs/2505.23564)
### Authors
Yiran Guo,Lijie Xu,Jie Liu,Dan Ye,Shuang Qiu
### Background
增强大规模语言模型的推理能力在使用强化学习中仍是一个重要的挑战。现有的方法主要采用两种不同级别的优势估算粒度：以标记级别的方法（例如PPO）试图提供精细的优势信号，但由于训练准确度评估模型的难度，导致了不准确的估计。另一种以轨迹级别的方法（例如GRPO）仅依赖于最终奖励的粗粒度优势信号，导致不精确的信用分配。为了克服这些限制，该研究提出了段策略优化（SPO），这是一种新颖的强化学习框架，利用中间粒度的段级别的优势估算，采用了更精确的信用分配策略，同时减少了标记级别的方法所需的估算点数，使其能够基于蒙特卡洛（MC）准确地进行优势估算而无需使用批评者模型。SPO 包含三个具有新颖策略的组件：(1) 偏好的段分区；(2) 准确的段优势估算；以及(3) 使用段优势进行策略优化，包括一种新的概率掩码策略。该研究还针对两种特定场景分别实例化了SPO：(1) SPO-chain 适用于短链式思考（CoT），通过基于切点分割和链式优势估算，GSM8K的准确率改善达到6%-12%。 (2) SPO-tree 适用于长链式思考，通过基于树的优势估算，极大地减少了MC估算的成本，在MATH500下的2K和4K上下文评估中实现了GRPO相比7%-11%的显著改进。
### Innovation
提出了段策略优化（SPO），这是一种基于中间粒度的段级别的优势估算的新颖强化学习框架。SPO主要包括三个新的组件：灵活性的段分区、准确的段优势估计和用于段优势的策略优化，其中包括一种新的概率掩码策略。SPO设计使得能在不需要批评者模型的情况下进行准确的优势估算，并且通过实例化，SPO能够在不同场景下（如短链式思考和长链式思考）提供显著的性能改进。
### Conclusion
该研究通过提出段策略优化（SPO）框架，提高了大规模语言模型在链式思考任务中的推理能力和准确性。SPO框架能够在不同场景下显著提升性能，对于处理大规模语言模型中的链式思考提供了有效的解决方案，同时也公开了代码供其他研究人员使用和参考。
## 940. `cs.LG` - 任务先验分布：通过考虑下游任务的整个空间来增强模型评估 [PDF](https://arxiv.org/pdf/2507.09871), [HTML](https://arxiv.org/abs/2507.09871)
### Authors
Niket Patel,Randall Balestriero
### Background
当前的人工智能研究，尤其是自监督学习（SSL），目标是构建能够解决任何可能任务的系统。然而，目前AI研究人员通常依赖于固定的、人工挑选的下游基准来评估这些系统的表现。这意味着需要花费大量精力设计和搜索能够代表研究目标的任务集合。但我们认为这种固定的评估方法创建了一个潜在的瓶颈。因此，需要一种新的评估方法来解决这个问题，而我们的思路是定义一个任务先验概率空间，从而可以在所有可能的下游任务上评估模型的表现。
### Innovation
我们首次提出了一种框架，它提供了评估模型性能的关键问题的答案，比如在所有可能的下游任务上的平均表现（加权概率）或者在所定义的任务先验下模型性能的方差。这种方法不仅为评价方法设定了新的标准，而且我们相信任务先验分布将加速SSL研究的步伐，因为下游任务的评价是研究人员所能获取的唯一定性信号。
### Conclusion
基于任务先验概率视角的模型评估框架，不仅能提供关键的评估指标，还能为加速自监督学习领域的研究提供有力支持。
## 941. `cs.LG` - TPP-SD: 使用推测性解码加速变换器点过程采样 [PDF](https://arxiv.org/pdf/2507.09252), [HTML](https://arxiv.org/abs/2507.09252)
### Authors
Shukai Gong,Yiyang Fu,Fengyuan Ran,Quyu Kong,Feng Zhou
### Background
该论文的背景在于，现有的Transformer时间点过程(TPP)采样方法相对较慢，难以满足实际应用中对快速序列采样的需求。通过借鉴语言模型中的推测性解码(Speculative Decoding, SD)技术，论文提出了一种新的方法TPP-SD，旨在提高TPP采样的效率。
### Innovation
研究的主要创新在于将推测性解码技术应用于TPP采样过程。通过识别TPP抽样算法与语言模型推测性解码之间的结构相似性，开发了一个高效的采样框架。该框架利用较小的草稿模型生成多个候选事件，然后通过较大的目标模型并行验证这些候选事件。TPP-SD方法能够保持与自回归采样相同的输出分布，但其速度显著加快。实验表明，相比于标准方法，TPP-SD可以实现2-6倍的速度提升。
### Conclusion
研究通过对比实验验证了TPP-SD方法的有效性，表明其能够在保持相同输出分布的同时大幅度提高采样速度，并且探讨了诸如草稿长度和草稿模型大小等超参数对采样效率的影响。研究最终证明TPP-SD在实现快速序列采样的同时，能够保持与现有方法相当的采样质量。
## 942. `cs.LG` - Coreset选择对拟态相关性和分组稳健性的影响 [PDF](https://arxiv.org/pdf/2507.11690), [HTML](https://arxiv.org/abs/2507.11690)
### Authors
Amaya Dharmasiri,William Yang,Polina Kirichenko,Lydia Liu,Olga Russakovsky
### Background
coreset选择方法在减少训练数据量的同时保持模型性能方面显示出潜力，尤其适用于数据高效机器学习。然而，当大量数据集受到偏差影响，导致模型学习到拟态相关性而非因果特征时，理解数据减少方法是否会加剧、放大或缓解这些偏差变得至关重要。
### Innovation
该研究首次全面分析了数据选择对所选coreset中的拟态偏差水平以及后续使用这些coreset训练的模型的鲁棒性的影响。在10种不同的拟态相关性基准测试中进行了广泛的实验，并使用了5种度量样本重要性/难度的评分标准以及跨越广泛的coreset大小范围的5种数据选择政策。研究揭示了样本难度与偏倚对齐之间以及数据集偏倚和模型鲁棒性之间的非平凡相互作用。
### Conclusion
虽然某些coreset选择方法通过优先选择困难样本可以实现较低的偏倚水平，但它们不能可靠地保证后续模型的鲁棒性。嵌入式样本特征评分选择coreset相比于基于学习动态的特征选择，比较低风险地加剧偏倚。
## 943. `cs.LG` - Shuffle-R1: 数据为中心的动态混排以提高多模态大语言模型的强化学习效率 [PDF](https://arxiv.org/pdf/2508.05612), [HTML](https://arxiv.org/abs/2508.05612)
### Authors
Linghao Zhu,Yiran Guan,Dingkang Liang,Jianzhong Ju,Zhenbo Luo,Bin Qin,Jian Luan,Yuliang Liu,Xiang Bai
### Background
强化学习（RL）作为提高多模态大语言模型（MLLM）推理能力的有效后训练范式已经兴起。然而，当前的RL流水线因为两个未被充分研究的问题而经常受到训练效率低下的困扰：优势坍缩和回放静默。这些问题导致了不理想的梯度更新并且阻碍了长期的学习效率。
### Innovation
为了应对这些问题，我们提出了一种名为Shuffle-R1的简单但基础的框架，以动态重结构轨迹采样和批次组合来提高RL微调效率。该框架包括（1）对高对比度轨迹（大型优势）进行两两采样，以提高梯度信号质量；（2）基于优势的轨迹混排，通过有意识地重新排列批次来增加有价值的回放的曝光率。这些实验在多个推理基准上显示，该框架在微小的开销下持续优于强大的RL基准，这些结果强调了数据为中心的调整在MLLM中更高效的RL训练的重要性。
### Conclusion
研究表明，我们的框架能够以最低的开销持续击败强大的基于RL的基础模型，在多个推理基准上表现优异，突显了数据驱动适应性对于更高效的RL训练的重要性。
## 944. `cs.LG` - 有归纳域转移的模拟基础推断 [PDF](https://arxiv.org/pdf/2508.15593), [HTML](https://arxiv.org/abs/2508.15593)
### Authors
Ortal Senouf,Antoine Wehenkel,Cédric Vincent-Cuaz,Emmanuel Abbé,Pascal Frossard
### Background
SBI是一种统计推理方法，用于估计物理系统中的潜在参数，当似然性无法计算但可用模拟时。然而，SBI通常受到模型拟合不充分的限制，即由于固有的建模简化而引起模拟和现实世界观察之间的差异。RoPE是一种最近的SBI方法，通过结合半监督校准和基于运筹学的分布对齐来解决这一挑战。但RoPE在推断时需要访问一批测试样本，这限制了其可扩展性和泛化能力。
### Innovation
作者提出了一种完全归纳且可学习的SBI框架，它可以集成校准和分布对齐，并将它们转化为单一的、端到端可训练的模型。该方法利用带闭式耦合的小批量运筹学对齐相同潜在参数的真实观察和模拟观察，使用配对的校准数据和未配对样本。然后，训练条件规范化流来近似由运筹学诱导的后验，允许在测试时无需模拟访问即可高效推断。
### Conclusion
在各种合成和真实世界的基准测试中，该方法在复杂医疗生物标志物估计等方面实现了或超过了RoPE以及其他标准SBI和非SBI估计器的性能，同时提供更好的可扩展性和适应性，以应对不充分的环境挑战。
## 945. `cs.LG` - MatPROV：从科学文献中提取的材料合成过程的来源图数据集 [PDF](https://arxiv.org/pdf/2509.01042), [HTML](https://arxiv.org/abs/2509.01042)
### Authors
Hirofumi Tsuruta,Masaya Kumagai
### Background
合成过程在材料研究中起着关键作用，直接影响材料的性质。随着数据驱动方法加速材料发现，从科学文献中提取合成过程作为结构化数据的兴趣日益增加。然而，现有研究往往依赖于固定、领域特定的框架，并预设了结构化的合成步骤字段，或者假设合成步骤是操作的线性序列，这限制了它们捕捉实际合成过程结构复杂性的能力。
### Innovation
为了应对这些限制，本文采用了PROV-DM，这是一种国际上用于来源信息的标准，支持灵活的基于图的流程建模。本文推出了MatPROV，一个基于PROV-DM的合成流程数据集，通过使用大语言模型从中科学文献中提取合成流程。MatPROV通过直观的有向图捕获材料、操作和条件之间的结构复杂性和因果关系，这种表示方式为自动合成规划和优化等未来研究提供了可用于机器解读的合成知识。
### Conclusion
MatPROV通过可视化直观的有向图捕捉材料、操作和条件之间的结构复杂性和因果关系，提供了机器可解释的合成知识，为未来研究如自动合成规划和优化开启了机会。
## 946. `cs.LG` - 衡量衡量：模型家族中表示相似性度量的区分能力 [PDF](https://arxiv.org/pdf/2509.04622), [HTML](https://arxiv.org/abs/2509.04622)
### Authors
Jialin Wu,Shreya Saha,Yiqing Bo,Meenakshi Khosla
### Background
表示相似性度量是神经科学和AI中的基本工具，但在不同模型家族之间的辨别能力方面缺乏系统的比较。本文提出了一种基于方法分离模型家族能力的定量化框架，包括架构（CNNs、Vision Transformers、Swin Transformers、ConvNeXt）和训练模式（监督 vs. 自监督）之间的比较。通过三个互补的可分性度量（信号检测理论中的d'、轮廓系数和ROC-AUC），系统评估了常用度量（包括RSA、线性预测性、Procrustes 和软匹配）的区分能力。
### Innovation
本文引入了一种新的框架，用于基于方法分离模型家族能力来定量评估表示相似性度量。使用三个互补的可分性度量进行了全面评估，结果显示，随着方法施加更严格的对齐约束，分离性系统地增加。在基于映射的方法中，软匹配达到最高的分离性，其次是Procrustes对齐和线性预测性。非适配方法（如RSA）在家族间也表现出强烈的可分性。这些结果提供了相似性度量通过分离性视角的第一个系统比较，明确了它们的相对敏感性，指导了大规模模型和脑成像的度量选择.
### Conclusion
这份研究结果为表示相似性度量的系统比较提供了首个基于分离性的视角，明确了它们的相对敏感性，并指导了大规模模型和脑成像的度量选择。
## 947. `cs.LG` - DreamPRM-1.5: 为多模态过程奖励模型训练解锁每个实例的潜力 [PDF](https://arxiv.org/pdf/2509.05542), [HTML](https://arxiv.org/abs/2509.05542)
### Authors
Qi Cao,Pengtao Xie
### Background
训练多模态过程奖励模型（PRMs）因其训练集和测试集之间的分布差异以及训练数据样本质量不平衡而具有挑战性。虽然领域级别的重新加权（例如，DreamPRM）能够使训练目标与测试时间目标一致，但仍然存在明显的差距，即与Oracle上界（pass@N）的差距，这表明在一定程度上存在元级的参数不足。
### Innovation
提出了DreamPRM-1.5，这是一种实例级别的重新加权框架，通过双层优化为每个训练示例分配自适应权重。为实现不同规模的实例重新加权，开发了两个补充的制度：实例表，它学习每个样本的显式权重，并在小/中型数据集上表现出色；实例网络，这是一种轻量级的神经网络，具有更好的泛化能力和可扩展性。另外，一种实用、稳定的训练食谱防止了发散现象，DreamPRM-1.5与测试时缩放结合在一起，表现优异，并在公开的多模态推理排行榜上取得了第一名的成绩。
### Conclusion
详尽的实验，包括基准评估、基线比较和可行性测试，证明了DreamPRM-1.5不仅接近Oracle上界，还实现了领先性能，并且训练稳定。
## 948. `cs.LG` - Adversarial Graph Fusion for Incomplete Multi-view Semi-supervised Learning with Tensorial Imputation [PDF](https://arxiv.org/pdf/2509.15955), [HTML](https://arxiv.org/abs/2509.15955)
### Authors
Zhangqi Jiang,Tingjin Luo,Xu Yang,Xinyan Liang
### Background
在图基的多视图半监督学习中，视图缺失是一个显著的挑战，阻碍了其在现实世界中的应用。传统方法通过引入缺失指示矩阵并专注于挖掘每个视图中可用样本的局部结构来进行标签传播。然而，忽视的缺失样本有时会引发不连续的局部结构，即子簇，破坏了标签传播中的平滑性假设，从而导致子簇问题（Sub-Cluster Problem，SCP），影响图融合并降低分类性能。
### Innovation
提出了一种新颖的不完整多视图半监督学习方法，称为AGF-TI。该方法设计了对抗图融合方案，通过最小最大框架学习一种鲁棒性的共识图，以对抗被扭曲的局部结构。通过将所有相似矩阵堆叠成张量，并基于低秩张量学习恢复不完整的结构。此外，引入了基于锚点的策略来降低计算复杂性。开发了一种高效的交替优化算法，结合了减小的梯度下降方法，以解决提出的优化目标，并理论上收敛。
### Conclusion
在各种数据集上的广泛实验结果验证了我们提出的方法AGF-TI相比于最先进的方法具有优越性。相关代码可在如下链接获得：this https URL。
## 949. `cs.LG` - Markov决策过程之间状态相似性的广义模拟度量：从理论命题到应用 [PDF](https://arxiv.org/pdf/2509.18714), [HTML](https://arxiv.org/abs/2509.18714)
### Authors
Zhenyu Tao,Wei Xu,Xiaohu You
### Background
bisimulation metric (BSM) 是一种强大的工具，用于在马尔可夫决策过程 (MDP) 中计算状态相似性。BSM 表明，BSM 距离较近的状态具有更相似的最优值函数。虽然 BSM 已成功应用于强化学习 (RL) 中的任务，如状态表示学习和策略探索，但将其应用于多 MDP 场景（例如策略转移）仍然是具有挑战性的。尽管先前的工作试图将 BSM 一般化到 MDP 对中，但由于缺乏对其数学性质的严谨分析，导致了进一步的理论进展受限。
### Innovation
本文正式建立了 MDP 对之间的广义模拟度量 (GBSM)，通过严谨证明具备三项基本性质：GBSM 对称性、跨MDP 三角不等式和相似状态空间的距离上限。利用这些性质，理论分析了多 MDP 场景中的策略转移、状态聚合和基于采样的估计。GBSM 为估计提供了封闭形式的样本复杂性，改进了基于 BSM 的现有渐近结果。此外，GBSM 提供的策略转移、状态聚合和基于采样的估计的界限比标准 BSM 的界的严格性更高。
### Conclusion
数值结果验证了我们的理论发现，并展示了 GBSS 在多 MDP 场景中的有效性。
## 950. `cs.LG` - Wonder Wins Ways: Curiosity-Driven Exploration through Multi-Agent Contextual Calibration [PDF](https://arxiv.org/pdf/2509.20648), [HTML](https://arxiv.org/abs/2509.20648)
### Authors
Yiyuan Pan,Zhe Liu,Hesheng Wang
### Background
在复杂多智能体强化学习（MARL）中，特别是在稀疏奖励设置下，自主探索依赖于为智能体提供有效的内在动力。现有好奇心机制虽然有效，但由于对环境随机性的误判和对所有意外观察结果的统一处理，导致了智能体探索行为的不足。既有的好奇心机制未能充分考虑到同伴行为中的潜在任务动态，这在去中心化且无通信的MARL环境中尤其明显，从而导致探索效果不佳。
### Innovation
本研究提出了一种名为CERMIC的新颖框架，通过利用多智能体环境中的同伴行为来动态校准内在好奇心，从而有效过滤噪声惊奇信号并指导探索。CERMIC不仅生成理论依据丰富的内在奖励，还通过动态调整内在好奇心与多智能体上下文推理来促进具有高信息增益的状态转换探索。实验结果显示，在基准测试集（如VMAS、Meltingpot、SMACv2）中，使用CERMIC进行探索显著优于最先进的算法，在稀疏奖励环境中尤其表现出色。
### Conclusion
本研究提出了一种创新的方法来通过多智能体上下文校准好奇心驱动的探索机制，不仅提供了有效的内在动力机制，还展示了显著提升MARL环境中探索性能的效果。
## 951. `cs.LG` - ProtoTS：学习层次原型以实现可解释的时间序列预测 [PDF](https://arxiv.org/pdf/2509.23159), [HTML](https://arxiv.org/abs/2509.23159)
### Authors
Ziheng Peng,Shijie Ren,Xinyue Gu,Linxiao Yang,Xiting Wang,Liang Sun
### Background
尽管深度学习在时间序列预测方面取得了显著的性能，但在高风险场景中建立对其决策过程的理解对于建立信任变得越来越重要。现有可解释模型通常仅提供局部和部分解释，无法揭示多种异构且相互作用的输入变量如何共同塑造预测曲线的整体时序模式。
### Innovation
提出了一种名为ProtoTS的新颖可解释预测框架，通过建模原型时序模式来实现高精度和透明的决策。ProtoTS基于去除噪声后的表示，保留了丰富的异构信息来计算实例-原型相似性。原型通过分层次组织，既能捕捉宏观的时序模式，又能捕捉细微的局部变化，从而实现专家指导和多层次的可解释性。实验表明，ProtoTS不仅在预测准确性方面超过了现有方法，还提供了专家可指导的解释，有助于更好地理解模型和决策支持。
### Conclusion
ProtoTS在多个现实基准测试中不仅在预测准确性方面超越了现有方法，而且还能提供专家可指导的解释，提高了模型理解度和决策支持。
## 952. `cs.LG` - λ-体独控制通用分移者之合建设的走击而进行进入服务和基本存储的重复进行工程 [PDF](https://arxiv.org/pdf/2509.16664), [HTML](https://arxiv.org/abs/2509.16664)
### Authors
Simone Ricci,Niccolò Biondi,Federico Pernici,Ioannis Patras,Alberto Del Bimbo
### Background
检索系统依赖于越来越强大的模型学习的表示。由于训练成本高和学习表示中存在不一致性，人们越来越关注在不同独立训练的神经网络之间促进表示间的通信并确保兼容性。文献中，常用的两种方法分别是仿射变换和正交变换。仿射变换能很好地适应特定分布但会显著改变原始表示。而正交变换能保持原始结构但对适应性的限制较大。关键挑战是在下游分布中适配更新模型的潜在空间，使其与之前模型的潜在空间对齐，同时保留新学习的表示空间。
### Innovation
本文引入了$λ$-正交正则化约束，以在保持原始学习表示的同时获得特定分布的适配。该方法同时学习仿射变换，并施加了一种放松的正交性约束，以确保在模型更新时保持零样本性能并确保兼容性。
### Conclusion
在多个架构和数据集上进行的大量实验验证了我们的方法，表明它保留了模型的零样本性能，并确保了模型更新之间的兼容性。代码可在指定链接处获取。
## 953. `cs.LG` - 学习解释语言模型的权重差异 [PDF](https://arxiv.org/pdf/2510.05092), [HTML](https://arxiv.org/abs/2510.05092)
### Authors
Avichal Goel,Yoon Kim,Nir Shavit,Tony T. Wang
### Background
微调（预训练）语言模型是更新其内部参数知识并使其专门化于新任务和领域的一种标准方法。然而，对应的模型权重变化（权重差异）通常不具备可解释性。虽然可以查看微调数据集来感知模型可能的变化，但这些数据集往往不公开或太大而无法直接处理。
### Innovation
本文引入了一种名为DIT（差分解释调优）的方法，该方法通过训练模型来描述其自身的微调诱导修改。这种方法使用合成并标记的权重差异来训练一个DIT-adapter，该adapter可以应用于兼容的微调模型，使其能够描述自身如何变化。实验证明，在两种概念性测试场景中，该方法允许模型使用准确的自然语言描述来解释其微调诱导的修改。
### Conclusion
通过这种方法，模型能够使用准确的自然语言描述来解释其微调诱导的修改。研究展示了在揭示隐藏行为和总结微调知识两个概念性测试场景中的应用效果。
## 954. `cs.LG` - Preference-driven Knowledge Distillation for Few-shot Node Classification [PDF](https://arxiv.org/pdf/2510.10116), [HTML](https://arxiv.org/abs/2510.10116)
### Authors
Xing Wei,Chunchun Chen,Rui Fan,Xiaofeng Cao,Sourav Medya,Wei Ye
### Background
由于图神经网络（GNNs）中的消息传递机制，GNNs 可以高效地处理带有文本属性的图（TAGs），但是其训练很大程度上依赖于人工标注的标签。此外，真实世界中 TAGs 的节点具有复杂多样的局部拓扑结构，使得单一机制难以应对。大型语言模型（LLMs）在 TAGs 的零样本/少样本学习方面表现良好，但面临可扩展性挑战。
### Innovation
提出了一种偏好驱动的知识蒸馏（PKD）框架，用于结合大型语言模型和不同 GNN 的互补优势，进行少量节点分类。具体来说，开发了一个 GNN 偏好驱动的节点选择器，有效促进了从 LLMs 到教师 GNNs 的预测蒸馏。进一步针对节点复杂的局部拓扑结构，开发了一个节点偏好驱动的 GNN 选择器，识别最适合每个节点的教师 GNN，从而促进教师 GNNs 到学生 GNN 的个性化知识蒸馏。
### Conclusion
实验结果验证了我们提出的框架在真实世界 TAGs 上的少量节点分类中的有效性。代码已开源。
## 955. `cs.LG` - Deep Edge Filter: 回归深度学习中的人工crafted层 [PDF](https://arxiv.org/pdf/2510.13865), [HTML](https://arxiv.org/abs/2510.13865)
### Authors
Dongkwan Lee,Junhoo Lee,Nojun Kwak
### Background
该研究基于对神经网络特性的深入理解，提出了Deep Edge Filter的新方法。研究人员推测神经网络在深度特征的高频部分编码了任务相关的重要语义信息，而低频部分则储存了领域特定的偏见。通过这种方法，可以隔离模型中的可泛化表示，同时保持模型结构的完整性。实验表明，该方法能在视觉、文本、3D和音频等多个领域的模型中提高性能，并且适用范围广泛，不受特定架构和数据模态限制的影响。研究表明，此方法可以引导特征稀疏化，有效地提取高频成分，为假设提供了实证支持。
### Innovation
Deep Edge Filter 是一种创新的方法，它通过对深度神经网络特征进行高通滤波，分离出高频和低频成分，以改善模型的泛化能力。该方法填补了人工设计层在深度学习中的空白，通过去除低频成分，有效获得了可泛化的主要表征，而不会损害模型的结构完整性。
### Conclusion
研究结果表明，Deep Edge Filter 方法能够有效提高模型在不同领域的性能，特别是通过减少低频成分来增强特征的稀疏性和提取高频信息，这为深入理解深层特征提供了实验证据。此研究实现了深度学习中人工层的设计，可以通过减去低通滤波输出来提取一般化的表征，并且这种方法已经在多个领域得到了验证。所提供的代码可以在该链接查看。
## 956. `cs.LG` - 语言模型是 injective 并因此是可逆的 [PDF](https://arxiv.org/pdf/2510.15511), [HTML](https://arxiv.org/abs/2510.15511)
### Authors
Giorgos Nikolaou,Tommaso Mencattini,Donato Crisostomi,Andrea Santilli,Yannis Panagakis,Emanuele Rodolà
### Background
以前的研究表明，Transformer模型中的非线性激活和规范化等组件本质上是非单射的，这意味着不同输入可能映射到相同的输出，从而阻止从模型表示中准确恢复输入。
### Innovation
文章提出了数学证明表明，从离散输入序列到对应连续表示的Transformer语言模型是单射且无损的，这一性质在初始化后并在训练期间保持不变。通过六款最先进的语言模型进行数以亿计的碰撞测试，实验上确认了这一结果，并且没有发现碰撞。紧接着，引入了SipIt算法，能够有效且可证明地从隐藏激活中精确恢复输入文本，具有线性时间确保和实践中的精确可逆性。这项工作建立了语言模型单射且可逆的基本和可利用性质，直接对透明性、解释性和安全部署产生了影响。
### Conclusion
我们工作证明了语言模型的单射性质是一个基本且可利用的特性，对提高模型的透明度、解释能力和安全部署具有直接的意义。
## 957. `cs.LG` - 在战略均衡系统中的双重稳健因果效应估计 [PDF](https://arxiv.org/pdf/2510.15555), [HTML](https://arxiv.org/abs/2510.15555)
### Authors
Sibo Xiao
### Background
该研究介绍了一种名为Strategic Doubly Robust (SDR)的新框架，将战略均衡建模与双重稳健估计相结合，用于战略环境中的因果推断。背景在于传统的因果推断方法在处理由于战略代理行为引发的内生性治疗分配时存在不足。因此，SDR旨在解决这些问题，保持双重稳健性的同时纳入战略考量，确保因果推断的可靠性。
### Innovation
该研究提出了一种新的Strategic Doubly Robust (SDR)估计器，将战略均衡建模与双重稳健估计结合，以应对战略环境中内生性的治疗分配问题。SDR框架通过理论分析证实其具有一致性和渐近正态性，并且在各种战略强度下实现了比基准方法更高7.6%-29.3%的偏差减少，同时具有良好的可扩展性。其主要创新在于将战略行为纳入因果推断的考虑范畴，提供了一种可靠的战略环境中因果效应推断的方法。
### Conclusion
研究的结论是SDR估计器为战略环境中可靠的因果推断提供了一个基本原则，可以通过战略均衡建模和双重稳健估计来提高因果推断的质量，并且在不同的战略强度下均表现出色，具有广泛的应用潜力。
## 958. `cs.LG` - Soundness-Aware Level: 预训练模型区分可信知识的能力微小标记，预测大语言模型推理潜力 [PDF](https://arxiv.org/pdf/2510.15216), [HTML](https://arxiv.org/abs/2510.15216)
### Authors
Xuansheng Wu,Xiaoman Pan,Wenlin Yao,Jianshu Chen
### Background
本文探讨了强化学习中可验证奖励（RLVR）如何作用于大语言模型（LLM），并指出了不同基础模型在强化学习后续表现差异显著的现象。研究认为，这引发了关于预训练模型中哪种微小性质导致这种差异的基本问题。为了回答这个问题，研究者将推理概念化为从大语言模型潜在空间提取特征后按层次稀疏自编码器（SAEs）生成的一系列“if-then”规则（Horn 分支），并量化了这些规则的语义精确度水平。研究者发现高潜力模型在规则语义精确度水平上的内部分布会系统性转变，而较弱的模型则不会表现出这种区分。
### Innovation
研究引入了Soundness-Aware Level (SAL)这一微小度量标准，它利用Jensen-Shannon 散度来度量不同规则语义精确度水平间分布的分离程度。研究发现，SAL的预测与LLM在强化学习后的推理性能高度一致（R²=0.87），涵盖多个模型家族和规模。这一发现表明，模型的推理潜力与其预训练阶段区分可信知识和错误知识的能力密切相关，为基于模型内部机制选择和设计更强基础模型提供了实用度量。
### Conclusion
研究揭示了预训练模型内在能力在塑造推理中的决定性角色，并提供了衡量模型推理潜力的实际度量标准，使得能够基于模型的内部机制选择或设计更强大的基础模型。
## 959. `cs.LG` - 谁减少了排放，谁增加了取暖？能源效率干预措施的因果机器学习估计 [PDF](https://arxiv.org/pdf/2508.04478), [HTML](https://arxiv.org/abs/2508.04478)
### Authors
Bernardino D'Amico,Francesco Pomponi,Jay H. Arehart,Lina Khaddour
### Background
减少国内能源需求是应对气候变化和解决燃料贫困的核心策略，然而能效干预措施的影响存在高度异质性。
### Innovation
使用因果机器学习模型，基于代表性的英国住房数据集，研究墙壁隔热对天然气消耗的影响，尤其关注不同能源负担组的分布效应。
### Conclusion
虽然能效干预措施平均减少了天然气需求（高达19％），但高能源负担组的减少效果甚微甚至没有变化。这种模式反映了行为驱动机制：收入与能源成本比率高的家庭（例如超过0.1）将节省的资金重新分配为提升舒适的支出而非降低消耗。这种响应代表了在先前贫困背景下合理的行为调整，可能带来健康和福利的双重好处。这些发现呼吁构建更广泛的评价框架，考虑到气候变化影响和国内能源政策的公平性含义。
## 960. `cs.LG` - 从错误中学习：通过误解风险模式增强有害贴图检测 [PDF](https://arxiv.org/pdf/2510.15946), [HTML](https://arxiv.org/abs/2510.15946)
### Authors
Wenshuo Wang,Ziyou Jiang,Junjie Wang,Mingyang Li,Jie Huang,Yuekai Huang,Zhiyuan Chang,Feiyan Duan,Qing Wang
### Background
互联网贴图作为一种流行的多媒体媒介已悄然兴起，但由于讽刺和隐喻等微妙的修辞手法，它们被越来越多地用于传达有害观点。现有的检测方法，包括基于MLLM的技术，在处理这些隐含表达时遇到困难，导致经常出现误判。
### Innovation
本文提出了PatMD，一种新颖的方法，通过学习并积极缓解潜在误判风险来提高有害贴图检测能力。我们的核心思想是超越表面的内容匹配，而是识别潜在误判风险模式，引导MLLM主动避开已知的误判陷阱。PatMD首先构建一个知识库，每个贴图被分解为解释为什么它可能被误解的误判风险模式，要么忽视有害的一面，要么过度解读良性内容。对于给定的目标贴图，PatMD检索相关模式并利用它们动态引导MLLM的推理。
### Conclusion
在包含6,626个贴图的基准数据集上的实验证明，PatMD在5个有害检测任务中优于最先进的基线方法，F1分数和准确率分别提高了8.30%和7.71%，显示了其强大的泛化能力和提高有害贴图检测能力的优越性。
## 961. `cs.LG` - MEET-Sepsis: 多源视图增强时间序列表示学习以实现早期脓毒症预测 [PDF](https://arxiv.org/pdf/2510.15985), [HTML](https://arxiv.org/abs/2510.15985)
### Authors
Zexi Tan,Tao Xie,Binbin Sun,Xiang Zhang,Yiqun Zhang,Yiu-Ming Cheung
### Background
脓毒症是与重症监护病房（ICU）高死亡率相关的危及生命的传染病综合症。早期和准确的脓毒症预测（SP）对于及时干预至关重要，但由于早期表现的微妙性和死亡率的迅速上升，这仍具有挑战性。尽管人工智能提高了SP效率，现有的方法在捕获早期的微弱时间信号方面仍存在问题。
### Innovation
本文引入了多内生视图表示增强（MERE）机制，以构建丰富的特征视图，并结合级联双卷积时序注意（CDTA）模块以进行多尺度时间表示学习。所提出的MEET-Sepsis框架仅使用SOTA方法所需ICU监控时间的20%即实现了具有竞争力的预测准确性，显著推动了早期SP的发展。
### Conclusion
广泛验证证实了其有效性。
## 962. `cs.LG` - ProSh: 模型自由的强化学习的概率性屏蔽 [PDF](https://arxiv.org/pdf/2510.15720), [HTML](https://arxiv.org/abs/2510.15720)
### Authors
Edwin Hamel-De le Court,Gaspard Ohlmann,Francesco Belardinelli
### Background
强化学习（RL）的安全性是一个主要的关注点。本研究旨在开发既能提供正式的安全保证，又能进行最优表现的RL系统。为此，我们在有成本约束的环境下引入了一种模型自由的算法——概率性屏蔽通过风险增加（ProSh）。该算法通过在约束MDP状态空间中增加风险预算是如何实现安全的。通过使用一个学习到的成本批评家来应用一定的“盾”来理解和保护代理政策分布的安全性。
### Innovation
ProSh算法通过在MDP状态空间中增加一个风险预算来处理具有成本约束的安全强化学习问题，并通过学习来的成本批评家，应用一种“盾”来确保所有采样的动作在期望上是安全的。还证明了在这种情况下，当环境确定时，最优性得以保留。此外，研究还提供了备份批评家准确度的严格上限在训练期间始终满足。
### Conclusion
ProSh能够保证即使在训练期间也是安全的。这已经在实验中得到了验证。由于ProSh是模型自由的，所以对于训练期间的安全性依赖于我们对环境的知识掌握程度。所取得的安全成本上界严格依赖于备份批评家的准确性。
## 963. `cs.LG` - Diverse Influence Component Analysis: 一种非线性混合可辨识的几何方法 [PDF](https://arxiv.org/pdf/2510.17040), [HTML](https://arxiv.org/abs/2510.17040)
### Authors
Hoang-Son Nguyen,Xiao Fu
### Background
从未知非线性混合物中提取潜在成分是机器学习中的基础挑战，应用于诸如解纠缠表示学习和因果推断等任务。先前针对非线性独立成分分析（nICA）的研究表明，辅助信号，如弱监督，可以支持条件独立潜在成分的可辨识性。最近的方法通过结构假设，如混合函数雅可比矩阵的稀疏性，来放松这种需求。
### Innovation
本文提出了一种新的框架Diverse Influence Component Analysis (DICA)，利用混合函数雅可比矩阵的凸几何性质。提出了一种雅可比体积最大化（J-VolMax）准则，通过鼓励潜在成分对观测变量影响的多样性来实现潜在成分的可辨识。在合理条件下，这种方法无需依赖辅助信息、潜在成分独立性或雅可比矩阵稀疏性的假设即可实现可辨识性。这一结果扩展了可辨识性分析的范围，提供了与现有方法不同的视角。
### Conclusion
该方法在无需依赖外部信息和潜在成分独立性假设的条件下，实现了非线性混合物的可辨识性，并且通过雅可比体积最大化准则，提供了一种新颖的方法来识别潜在成分，使得识别过程更加独立且具有更广泛的适用性。
## 964. `cs.LG` - 利用机器学习加速汽车碰撞动力学建模 [PDF](https://arxiv.org/pdf/2510.15201), [HTML](https://arxiv.org/abs/2510.15201)
### Authors
Mohammad Amin Nabian,Sudeep Chavare,Deepak Akhare,Rishikesh Ranade,Ram Cherukuri,Srinivas Tadepalli
### Background
汽车碰撞安全性评估是汽车设计中的关键方面，过去主要依赖于高保真有限元（FE）模拟，但这类模拟计算复杂且耗时。本研究旨在通过开发基于机器学习的代理模型来有效预测碰撞场景下的结构变形，以加速这一过程。研究通过NVIDIA PhysicsNeMo框架进行探索性比较研究，对比了两个先进的神经网络架构和三种动态建模策略，以期在结构碰撞动力学领域应用机器学习。这些模型在使用LS-DYNA进行的150个详细的前端碰撞有限元仿真数据集上进行了评估，该数据集包括一个结构复杂的车辆组件，包含超过200个部件，其中包括38个特征具有不同厚度分布的关键部件，以模拟真实的制造变化性。这些模型利用未变形的网格几何结构和部件特性作为输入，以预测碰撞过程中变形网格的时空演变。这些模型在计算成本上实现了数量级的减少，但仍未能达到完全的FE模拟精度。
### Innovation
本研究的主要创新点在于展示了通过探索不同的机器学习模型架构和策略来有效地预测汽车碰撞动态的可行性。通过使用两个先进的神经网络架构（MeshGraphNet和Transolver）以及三种不同的建模策略（时间条件化、标准自回归和增强自回归），本研究取得了显著的成果，特别是在显著降低计算成本方面。通过实验，这些模型在结构碰撞动力学建模中的表现令人满意，为早期的碰撞安全性评估提供了快速设计探索和优化的可能性。
### Conclusion
研究结果表明，机器学习模型能够在一定程度上忠实地捕捉碰撞过程中的整体变形趋势，证明了在结构碰撞动力学中应用机器学习的可行性。虽然这些模型尚未达到完全的FE模拟精度，但它们大大减少了计算成本，为快速设计探索和早期阶段的优化提供了可能的解决方案。未来的工作可以进一步提高机器学习模型的精度，使其与全FE模拟更加接近。
## 965. `cs.LG` - 使用最小化设计空间维度的Design-by-Morphing进行翼型优化 [PDF](https://arxiv.org/pdf/2510.16020), [HTML](https://arxiv.org/abs/2510.16020)
### Authors
Sangjoon Lee,Haris Moazam Sheikh
### Background
有效的翼型几何优化需要探索多样化的设计，但使用尽可能少的设计变量。这一研究介绍了一种称为AirDbM的专门用于翼型优化的设计-by-变形(DbM)方法。AirDbM系统地减少了设计空间维度，通过从包含超过1,600种形状的UIUC翼型数据库中，有选择地挑选出12种基础翼型，这些基础翼型能够重建数据库99%的形状，且误差小于0.005。
### Innovation
AirDbM方法通过引入系统性的策略来减少设计空间维度，能够用较少的基础翼型重建大量复杂的翼型形状，并且在多目标气动优化过程中展示了优异的快速收敛性能和结果质量。此外，AirDbM方法展现出在强化学习（RL）代理生成翼型几何形状时的卓越适应性，优于传统的翼型参数化方法，暗示DbM方法在机器学习驱动设计中的广泛应用潜力。
### Conclusion
AirDbM方法展示了在翼型优化领域的显著性能，能够用较少的基础翼型重建大量数据库，且优化结果与之前使用更多基础翼型的方法相当。在多目标气动优化中，AirDbM展示了更好的快速收敛性能和更大的Pareto前沿。同时，AirDbM的卓越适应性表明了DbM方法在强化学习驱动翼型设计中的广泛应用前景。
## 966. `cs.LG` - TrajMamba：一种高效的语义丰富的车辆轨迹预训练模型 [PDF](https://arxiv.org/pdf/2510.17545), [HTML](https://arxiv.org/abs/2510.17545)
### Authors
Yichen Liu,Yan Lin,Shengnan Guo,Zeyu Zhou,Youfang Lin,Huaiyu Wan
### Background
车辆的GPS轨迹记录了车辆随时间的移动模式和旅行用途，存储了宝贵的信息。然而，有效且高效地学习这些旅行语义受到两个主要挑战的阻碍：首先，旅行目的与旅途中的道路和兴趣点的功能有关，这些信息编码在文本地址和描述中，增加了建模的计算负担；其次，现实中的轨迹经常包含冗余点，这损害了计算效率和轨迹嵌入的质量。
### Innovation
为了应对这些挑战，我们提出了TrajMamba，一种新颖的方法，用于高效且语义丰富的车辆轨迹学习。TrajMamba引入了Traj-Mamba编码器，通过同时建模轨迹的GPS和道路视角来捕捉移动模式，从而实现对连续旅行行为的鲁棒表示。它还结合了一种行程目的感知预训练过程，无需额外开销即可将旅行目的整合到学习嵌入中。为了减少轨迹中的冗余，TrajMamba还通过可学习的掩码生成器实现了知识蒸馏预训练方案，以识别关键轨迹点并获得有效的压缩轨迹嵌入。
### Conclusion
在两个实际数据集和三个下游任务上的广泛实验表明，TrajMamba在效率和准确性方面均优于最先进的基线方法。
## 967. `cs.LG` - 基于图神经网络的道路安全建模：事故分析的数据集构建与评估 [PDF](https://arxiv.org/pdf/2311.00164), [HTML](https://arxiv.org/abs/2311.00164)
### Authors
Abhinav Nippani,Dongyue Li,Haotian Ju,Haris N. Koutsopoulos,Hongyang R. Zhang
### Background
之前的研究设计了使用历史记录预测交通事故发生的各种深度学习方法，但由于缺乏公开的事故数据集进行全面评估，这些方法的准确性存在争议。本文通过构建由美国各州官方报告的交通事故记录组成的大型统一数据集（总共900万条记录），并结合道路网络和交通流量记录，旨在评估现有的深度学习方法在预测道路上交通事故发生方面的能力。
### Innovation
本文创新之处在于采用了大规模且统一的事故数据集，以及使用图神经网络（如GraphSAGE）进行交通事故预测，评估结果表明，图神经网络可以准确预测道路的交通事故数量（平均绝对误差小于22%）和是否会发生交通事故（AUC值超过87%），并且通过多任务学习和迁移学习方法提升了预测性能。此外，消融研究强调了道路图结构特征的重要性。
### Conclusion
本文的研究结果表明，图神经网络在预测道路交通事故方面具有潜力。通过使用我们的新数据集，可以深入了解道路安全问题，并为事故分析提供了宝贵的资源。
## 968. `cs.LG` - 学习旁观：机器人操作的基于视频学习方法综述 [PDF](https://arxiv.org/pdf/2402.07127), [HTML](https://arxiv.org/abs/2402.07127)
### Authors
Chrisantus Eze,Christopher Crick
### Background
机器人操作技能的学习受到多元化、无偏见数据集稀缺的限制。尽管策划的数据集有所帮助，但在泛化性和实际应用转移性方面仍面临挑战。与此同时，大规模的“野生成份”视频数据集通过自我监督技术推动了计算机视觉的发展。将这种方法应用于机器人学，最近的研究探讨了通过在线获取的大量视频被动学习操作技能。这样的基于视频的学习范式提供了一种可扩展的监督方式，并减少了数据集的偏见。
### Innovation
该论文创新地提出了通过观看大规模无控制的视频示范来获取机器人操作技能的方法，这种方法在泛化能力和样本效率方面表现出潜力。
### Conclusion
综述列表示基于视频的学习方法，分析了其相对于标准数据集的优缺点，讨论了在视觉、自然语言处理和机器人学习交叉领域的新兴方向和开放挑战。
## 969. `cs.LG` - 可解释的图推荐系统综述 [PDF](https://arxiv.org/pdf/2408.00166), [HTML](https://arxiv.org/abs/2408.00166)
### Authors
Thanet Markchom,Huizhi Liang,James Ferryman
### Background
可解释的推荐系统对确保用户信任和满意度至关重要。已有研究提出了多种可解释推荐系统，包括可解释的基于图的推荐系统。然而，这些系统的最新进展和分类尚不明确，因此需要对这些系统进行深入探讨和分类，以推动该领域的研究和发展。
### Innovation
该论文专注于基于图的可解释推荐系统的综述，并按照学习方法、解释方法和解释类型对这些系统进行了分类。此外，该论文还探讨了常用的评估方法和未来的研究方向，这与现有的综述论文相比是一个创新之处。
### Conclusion
该论文总结了基于图的可解释推荐系统的现有方法和挑战，并指出了未来研究的方向。
## 970. `cs.LG` - 使用运行时监控语言实现表达性强的奖励合成 [PDF](https://arxiv.org/pdf/2510.16185), [HTML](https://arxiv.org/abs/2510.16185)
### Authors
Daniel Donnelly,Angelo Ferrando,Francesco Belardinelli
### Background
强化学习（RL）中的一个关键挑战是奖励（误）设计的问题，即不精确定义的奖励函数可能会导致未预期甚至可能有害的行为。尽管传统的奖励函数（通常视为从状态-动作对到标量值的黑盒映射）在许多情况下是有效的，但它不提供关于奖励分配原因的信息，这可能会妨碍学习和解释性。为此，奖励机器通过将奖励函数表示为有限状态自动机，解决了这一问题，从而允许定义结构化、非马尔可夫奖励函数。然而，现有的奖励机器通常只能处理正则语言，无法捕捉更复杂的行为，如计数或参数化条件等。
### Innovation
本文基于运行时监控语言（RML），开发了一类基于语言的新型奖励机器。通过利用RML内置的存储能力，我们的方法可以为非正则、非马尔可夫任务定义奖励函数。通过实验展示了该方法的表达能力，强调了在事件处理和任务定义方面的灵活性和优势，超越了现有的基于奖励机器的方法。
### Conclusion
我们的方法展示了更强的表达能力和在灵活事件处理和任务定义方面的优势，能够在非正则、非马尔可夫任务中定义更复杂的奖励函数。实验结果证实了方法的有效性。
## 971. `cs.LG` - LENS: 大型预训练变换器用于探索金融市场时间序列规律 [PDF](https://arxiv.org/pdf/2408.10111), [HTML](https://arxiv.org/abs/2408.10111)
### Authors
Yuanjian Xu,Anxian Liu,Jianing Hao,Zhenzhuo Li,Shichang Meng,Guang Zhang
### Background
近年来，大规模时间序列的建模引起了显著的关注，但在金融领域中的直接应用仍具有挑战性。金融市场固有的随机性和低信噪比导致了传统方法和预训练方法的效果不佳。因此，迫切需要一种针对金融时间序列的专用基础模型来弥补这一差距.
### Innovation
本文提出了一个针对金融时间序列的预训练模型LENS。LENS通过精心设计的模型架构有效捕捉金融系统的复杂性，并在预训练过程中使用可逆嵌入模块来减轻噪声的影响。此外，该工作还提供了该模型有效性的严格理论解释，并通过广泛的实验验证了其性能，展示了在高噪声环境下的预训练时间序列模型开发的实用见解，为该研究领域进一步的发展奠定了基础.
### Conclusion
预训练于包含1000亿个金融市场观察数据集上，LENS在多种关键下游任务中取得了卓越的结果。我们的工作为在高噪声环境下发展预训练时间序列模型提供了实际的见解，为这一关键研究领域的进一步发展铺平了道路.
## 972. `cs.LG` - 分子指纹是强大的肽功能预测模型 [PDF](https://arxiv.org/pdf/2501.17901), [HTML](https://arxiv.org/abs/2501.17901)
### Authors
Jakub Adamczyk,Piotr Ludynia,Wojciech Czech
### Background
理解肽的性质通常需要模拟分子间长程相互作用，因此常常使用复杂的图神经网络和预训练的变压器。然而，是否存在长程依赖是至关重要的这一假设仍然并不明确。
### Innovation
研究发现，在不需要长程依赖假设的情况下，简单的、针对领域的分子指纹可以捕获肽的功能。通过原子级别的表示，这些模型即使只编码短程分子特征，也能超越图神经网络和基于变压器的方法，达到最佳的准确性。
### Conclusion
实验结果挑战了长程相互作用建模的必要性，表明分子指纹作为肽预测的有效、可解释且计算负担轻的替代方案。
## 973. `cs.LG` - 点云的隐式神经编码 [PDF](https://arxiv.org/pdf/2412.10433), [HTML](https://arxiv.org/abs/2412.10433)
### Authors
Hongning Ruan,Yulin Shao,Qianqian Yang,Liang Zhao,Zhaoyang Zhang,Dusit Niyato
### Background
点云在众多应用中因其能够准确表示3D对象和场景而越来越受到重视。然而，由于高精度的不规则点云数据压缩效率低的问题依然存在，因此需要开发新的压缩框架以提高点云数据的压缩效率和质量。
### Innovation
本文提出了一种新的点云压缩框架——NeRC$^3$，该框架利用隐式神经表示(INRs)来编码密集点云的几何和属性信息。通过两个基于坐标的神经网络来实现这一目标，分别用于映射空间坐标到体积占据状态和已经占据的体积到它们的属性，从而隐式地表示了体积化点云的几何和属性。此外，本文还提出了一种4D时空表示4D-NeRC$^3$来处理动态点云压缩，以减少时间冗余性。
### Conclusion
实验结果表明，对于静态点云，NeRC$^3$优于基于八叉树的G-PCC标准和现有的基于INR的方法。对于动态点云，4D-NeRC$^3$在几何压缩方面优于最新的G-PCC和V-PCC标准，同时也保持了与基于学习的方法相当的性能，在几何和属性联合压缩方面也显示出竞争力。
## 974. `cs.LG` - 通过图神经网络在因子化3D场景图中生成aware不确定性自发概念 [PDF](https://arxiv.org/pdf/2409.11972), [HTML](https://arxiv.org/abs/2409.11972)
### Authors
Jose Andres Millan-Romera,Muhammad Shaheer,Miguel Fernandez-Cortizas,Martin R. Oswald,Holger Voos,Jose Luis Sanchez-Lopez
### Background
在3D场景图中自主发现新兴的空间概念（例如，房间）对于可靠的室内导航和制图至关重要。这些图提供了一种分层的度量-语义表示，其中这些概念被组织起来。为改进图-SLAM性能，因子化3D场景图将这些概念作为优化因子来限制相对几何关系并强制实现全局一致性。然而，这一过程中两个阶段仍然主要依赖手动操作：概念通常使用手工构建的概念特定启发式来推导，而因子及其协方差也是手动设计的。这种依赖于手动指定的限制导致了概念推广到不同环境以及新概念类别的扩展性的局限性。
### Innovation
本文提出了一种基于学习的方法，可以在SLAM后端在线生成可优化的概念，减少需要手工构建概念生成及其对应因子和协方差定义。在模拟和真实室内场景中，该方法分别提高了复杂概念检测20.7%、5.3%、轨迹估计19.2%和地图重建12.3%、3.8%，突显了这种集成对于稳健和自适应空间理解的好处。
### Conclusion
通过图神经网络在因子化3D场景图中生成aware不确定性自发概念的方法，能够改善复杂概念检测、轨迹估计和地图重建的性能，提高了SLAM系统的鲁棒性和适应性。
## 975. `cs.LG` - LLMs在《变色龙》游戏中是否战略性地揭示、隐藏和推断信息？一个理论与实证分析 [PDF](https://arxiv.org/pdf/2501.19398), [HTML](https://arxiv.org/abs/2501.19398)
### Authors
Mustafa O. Karabag,Jan Sobotka,Ufuk Topcu
### Background
大型语言模型（LLM）代理已变得在包含非合作方的环境中普遍使用。在这样的环境中，代理需要在与对手互动时隐藏信息，在与同伴互动时揭示信息，在识别其他代理特征时做出推理。本文通过让LLM代理参与语言基础的隐藏身份游戏《变色龙》来研究它们是否具备这种信息控制和决策能力。该游戏要求双方在作为变色龙和非变色龙时都具备信息控制能力。
### Innovation
本研究通过分析一系列策略的光谱，从隐藏到揭示，提供了非变色龙赢得概率的上界，并使用GPT、Gemini 2.5 Pro、Llama 3.1和Qwen3模型进行了实证研究。研究成果表明，虽然非变色龙代理能够识别变色龙，但无法从变色龙那里隐藏信息，其胜率远远低于无策略的水平。此外，实验证明，简单的指令往往不足以使非变色龙的LLM隐藏信息，但直接引导内部表示以线性方向操作却能可靠地诱导隐藏行为。
### Conclusion
研究得出结论，基于LLM的代理可能过多地向未知身份的代理泄露信息。值得注意的是，当指示LLM采取信息揭示级别时，这种级别会以线性的方式编码在其内部表示中。此外，通过对内部表示进行线性引导，可以直接可靠地引发隐藏行为。
## 976. `cs.LG` - φ 曲线：基于范数容量控制视角下的泛化能力形状 [PDF](https://arxiv.org/pdf/2502.01585), [HTML](https://arxiv.org/abs/2502.01585)
### Authors
Yichen Wang,Yudong Chen,Lorenzo Rosasco,Fanghui Liu
### Background
在机器学习中，理解测试风险如何随模型复杂度变化是核心问题。经典理论对大量过参数化深度网络观察到的学习曲线提出了挑战。基于参数数量的容量度量通常无法解释这些经验观察结果。
### Innovation
本文考虑了基于范数的容量度量，并在随机特征基估计器的背景下进行了研究，这些估计器广泛用作更复杂网络的简化理论模型。研究结果表明，预测的学习曲线存在从欠参数化到过参数化的相变，但没有双下降行为。这证实了使用适当的基于模型范数的容量度量而非大小，可以恢复更传统的U型行为。
### Conclusion
从技术角度看，本文利用了确定性等价作为关键工具，并进一步开发了新的独立感兴趣的确定性量度。
## 977. `cs.LG` - 为可扩展监督建模人类对AI行为的信念 [PDF](https://arxiv.org/pdf/2502.21262), [HTML](https://arxiv.org/abs/2502.21262)
### Authors
Leon Lang,Patrick Forré
### Background
随着AI系统的进步超越人类的能力，可扩展的监督变得至关重要。人类评价者在复杂任务中可能形成关于AI行为的错误信念，导致反馈不可靠和价值判断不准确。
### Innovation
本文提出了建模评价者信念的方法，以更可靠地解释其反馈。通过简化精确的信念模型，引入了“信念模型覆盖”概念。初步建议使用适应的预训练模型的内部表示来模仿人类评价者的信念，即使评价者误解了AI的行为，也能从其反馈中学习正确的价值。
### Conclusion
本文的工作表明，建模人类信念可以改善价值学习，并指出了实现此方法以实现可扩展监督的实际研究方向。
## 978. `cs.LG` - 发展性设计范式的基础：集成持续学习、审慎行为和可理解性的设计原则 [PDF](https://arxiv.org/pdf/2502.13935), [HTML](https://arxiv.org/abs/2502.13935)
### Authors
Zeki Doruk Erden,Boi Faltings
### Background
当前的机器学习系统在关键领域存在固有限制，特别是在持续学习、信息重用、可解释性和与故意行为的集成方面。这些限制正在引起越来越多的关注。为了应对这些挑战，研究提出了一种系统设计，该设计基于进化发育生物学原理，引入了一种新颖的学习方法，以克服现有方法的关键限制。
### Innovation
该设计引入了一种新的学习方法，该方法对进化发育生物学原理有所依据，并具有免梯度的学习机制，能够实现持续学习和结构适应。此外，该设计还包括目标导向动作的规划模块和可以将复杂行为分解为层级结构的行为封装机制。该框架可用于高维网络结构空间，并展示了同时和有机地克服当代机器学习系统多个主要限制的潜力。
### Conclusion
通过对简单测试环境的实验证明了此框架的基本原理，并成功使用MNIST数据集进行了形状检测任务，展示了框架在高维网络结构空间中的应用潜力，同时也验证了该框架在多方面改善机器学习系统性能的能力。
## 979. `cs.LG` - 为黑箱大语言模型启用细粒度操作点 [PDF](https://arxiv.org/pdf/2510.17727), [HTML](https://arxiv.org/abs/2510.17727)
### Authors
Ege Beyazit,KL Navaneet,Prashant Mathur,Roi Blanco,Vidit Bansal,Karim Bouyarmane
### Background
黑箱大语言模型（LLMs）提供了一种实用且易于访问的替代方案，无需大量的标注数据和机器学习专业知识即可解决各种决策问题。然而，对于那些在特定指标上需要操作约束的应用（如精确度≥95%），使用黑箱LLMs进行决策因为其输出的数值维度较低而不理想。这限制了对模型操作点的控制，妨碍了对其决策行为的精细调整。
### Innovation
本文研究了将黑箱LLMs作为分类器的使用方法，通过高效率地提高其操作粒度而不损失性能。首先分析了其低数值输出维度的原因，发现其倾向于生成准确但具信息性的四舍五入概率。实验了标准提示工程、不确定性估计和信心收集技术，但发现它们未能在无性能损失或增加推理成本的情况下提高操作粒度。最后提出了有效方法，显著增加可用操作点的数量和多样性。所提出的策略提供了更精细的操作点，并在11个数据集和3个LLMs上达到了或优于基准方法的性能。
### Conclusion
本文通过分析黑箱LLMs输出的低维度问题，并提出了有效的解决方案，大幅提高了操作点的数量和多样性。这些方法在多种数据集上表现出了与基准方法相当甚至更优的性能。
## 980. `cs.LG` - VLA-Cache: 通过自适应令牌缓存实现高效的视觉-语言-行动操作 [PDF](https://arxiv.org/pdf/2502.02175), [HTML](https://arxiv.org/abs/2502.02175)
### Authors
Siyu Xu,Yunke Wang,Chenghao Xia,Dihao Zhu,Tao Huang,Chang Xu
### Background
VLA（Vision-Language-Action）模型已经展示了强大的多模态推理能力，能够从视觉感知和语言指令中直接生成动作，并在端到端的方式中运行。然而，这些模型在计算成本上的巨大需求对实时机器人控制构成了挑战，因为快速决策是核心要求。现有的VLA模型在实际应用中需要大量的资源来处理复杂任务，导致速度和精确度之间的权衡问题，尤其在实时操作中影响显著。因此，迫切需要一种新的方法来加速这些模型的推理过程，同时保持其多模态推理能力，特别是在机器人操作领域。
### Innovation
VLA-Cache是一种无需训练的推理加速方法，其通过自适应缓存和重用帧之间静默视觉令牌来降低计算开销。这种方法利用机器人操作中的时间连续性，识别相邻帧之间的微小变化，重用缓存的关键-值表示，从而避免冗余计算。此外，VLA-Cache通过选择性重新计算环境敏感的任务相关令牌来维持精确的动作，确保关键视觉信息的准确度。为了进一步优化效率，VLA-Cache引入了一种基于解码器层中注意力集中度的层自适应令牌重用策略，优先重新计算关键令牌，而不损害任务的成功率。该方法在两个模拟平台（LIBERO和SIMPLER）以及一个真实的机器人系统上进行了广泛的实验，并且表明VLA-Cache能够在CUDA延迟上实现1.7倍的加速，并提高15%的控制频率，同时任务成功率几乎没有损失。
### Conclusion
实验结果表明，VLA-Cache在保持多模态推理性能的同时，能够显著提高VLA模型在机器人操作中的处理速度和控制频率，这将有助于解决当前机器人技术中的实时操作挑战，同时也为研究者和开发者提供了一种新型的视觉-语言-行动方法改进算法的性能。
## 981. `cs.LG` - 基于无模型约束强化学习的动态移动目标推举 [PDF](https://arxiv.org/pdf/2502.01546), [HTML](https://arxiv.org/abs/2502.01546)
### Authors
Ioannis Dadiotis,Mayank Mittal,Nikos Tsagarakis,Marco Hutter
### Background
非抓握推举动作将物体移动和重新对齐到目标位置是一种多功能的移动操作技能。在现实世界中，物体的物理特性和与地面的摩擦存在很大的不确定性，这使得移动机械手执行此任务具有挑战性。本文分析了移动机械手如何通过一系列推举动作将未知物体移动到预期位置并调整其旋转方向。
### Innovation
本文提出了一种基于无模型约束的强化学习（RL）公式训练的控制器，用于移动机械手将未知物体推举到目标位置。控制策略不仅训练了机械臂的动作，还训练了移动基座的运动。本文通过四足机器人进行了实验，展现出在面对不同质量、材料、尺寸和形状的未知物体时，该方法的鲁棒性高，且能够适应推举物体姿态的变化。
### Conclusion
实验结果表明，所训练的策略在模拟环境中成功率达到91.35%，在硬件中至少达到80%的Success Rate。此外，所提出的控制策略能够适应物体翻倒的防止行为，展现出良好的接触丰富性及其对物体姿态的观察能力。
## 982. `cs.LG` - 在充足探索下的泛化和分布更新对于模仿观察 [PDF](https://arxiv.org/pdf/2501.12785), [HTML](https://arxiv.org/abs/2501.12785)
### Authors
Yirui Zhou,Yunfei Jin,Xiaowei Liu,Xiaofeng Zhang,Yangchun Zhang
### Background
LfO让机器能够通过观察专家的示例行为来模仿专家的行为，而无需获取专家的具体动作，这比传统的LfD（学习从演示）更为实用。然而，在直接应用LfO的在线策略训练方案时，会遇到样本效率低的问题，而在应用传统的离线策略训练方案时，则会导致算法的不稳定性问题。因此，论文旨在开发一种高效且稳定的LfO方案。
### Innovation
论文通过对LfO中的奖励函数和策略的一般化能力进行研究，提出了结合分布软actor-critic (DSAC) 的生成对抗模仿观察（GAIfO）方法，并设计了Mimicking Observations through Distributional Update Learning with adequate Exploration (MODULE) 算法。MODULE算法整合了软actor-critic（SAC）的样本高效性及训练鲁棒性增强，结合分布强化学习（RL）的稳定训练特性，以此解决LfO中的问题。
### Conclusion
实验结果在MuJoCo环境中显示，MODULE算法在LfO方面表现出色，优于当前的LfO方法。
## 983. `cs.LG` - 在复杂代理环境中的学习和编码结构丰富轨迹的表示框架 [PDF](https://arxiv.org/pdf/2503.13194), [HTML](https://arxiv.org/abs/2503.13194)
### Authors
Corina Catarau-Cotutiu,Esther Mondragon,Eduardo Alonso
### Background
当前的人工智能代理在面对复杂场景时，其做出最优决策的能力和向不同领域和任务推广的能力受到限制。为解决这一问题，研究主要集中在学习高效的环境表示以及代理行为如何影响其状态转换。然而，这些表示虽然在操作上有效，但在结构丰富性方面有所欠缺。
### Innovation
本文提出通过增强代理的本体，并将传统轨迹概念扩展为更精细的任务执行视图，来解决这个问题。结构丰富化的轨迹（SETs）扩展了状态及其转换的编码，并通过引入对象间的关系、交互以及功能之间的层次关系来增加结构丰富性。这些轨迹被构建为多级图形，提供了代理动力学的详细表示和任务的可转移功能抽象。为了推广，SETs被集成到一种结构丰富化轨迹学习和编码（SETLE）体系结构中，该体系结构使用多级关系依赖的异构图基记忆结构。研究表明，SETLE能够支持下游任务，使代理能够在CREATE和MiniGrid环境中识别相关的结构模式。
### Conclusion
我们进一步将SETLE与强化学习集成，并在下游任务中展示了可测量的改进，尤其是在具有稀疏奖励的复杂任务中的突破性成功率达到提高。
## 984. `cs.LG` - 利用测试时自适应提高英语方言NLU任务的效果 [PDF](https://arxiv.org/pdf/2503.12858), [HTML](https://arxiv.org/abs/2503.12858)
### Authors
Duke Nguyen,Aditya Joshi,Flora Salim
### Background
测试时域自适应（TTDA）是一种无需使用标记数据集即可帮助模型在不同领域、任务和分布中泛化的优秀方法。在英语方言的自然语言处理（NLP）场景中特别有用，因为模型通常在标准美式英语（SAE）上进行训练，但在印度英语（IndE）、新加坡英语（SingE）或尼日利亚英语（NgE）上进行评估，这在分布上有显著差异，且方言数据集十分稀缺。本文探讨了SHOT这一著名的TTDA技术在英语方言NLP中的应用，并对不同方言GLUE组合进行了微调和评估。研究表明，当缺乏标记数据集时，SHOT是一种可行的技术。我们还理论上提出了方言差距的概念，并证明它与SHOT的有效性呈正相关。此外，研究发现，在许多情况下，使用标准美式英语进行微调可以提高性能，而不是使用方言数据进行微调。
### Innovation
本研究探讨了SHOT这一著名的TTDA技术在英语方言NLP中的应用，并对其在不同方言GLUE上的表现进行了详细评估。研究引入了‘方言差距’的概念，首次将其与SHOT技术的效果进行关联，并指出在某些情况下，使用标准美式英语进行微调可能优于使用方言数据进行微调。这种理论上的贡献为后续研究提供了新的方向和依据。
### Conclusion
研究结果显示，当缺乏标记数据集时，SHOT是一种非常可行的自我适应技术。方言差距与SHOT的有效性之间存在显著正相关关系。在不同的方言数据微调策略中，使用标准美式英语可能带来更好的性能表现。
## 985. `cs.LG` - 通过可学习线性外推在有限步内改进基于扩散的逆算法 [PDF](https://arxiv.org/pdf/2503.10103), [HTML](https://arxiv.org/abs/2503.10103)
### Authors
Jiawei Zhang,Ziyuan Liu,Leon Yan,Gen Li,Yuantao Gu
### Background
基于扩散的逆算法在各种逆问题中表现出色，但其依赖多次去噪步骤会导致高计算成本。尽管快速扩散ODE求解器的最新发展为扩散采样提供了有效的加速，但它们在逆问题中的应用仍有限，因为逆算法的异构形式和广泛使用近似和启发式方法引入了显著误差，影响了分析求解器的可靠性。论文从ODE求解器的角度分析了逆问题，揭示了逆轨迹的近似线性组合结构，并据此提出了一种统一扩散基逆算法的规范形式，以简化设计更具通用性解算器的过程。 authors 然后基于线性子空间搜索策略，提出了一种轻量级方法——可学习线性外推（LLE），以增强适用于规范形式的任何基于扩散的逆算法性能，通过优化组合系数来改进当前预测，从而降低逆算法分析求解器的敏感性。早期实验表明，LLE方法在多个算法和任务中都表现出一致的改进效果，表明其在有限步骤内提供更高效解决方案和提升扩散基逆算法性能的潜力。
### Innovation
本文提出了可学习线性外推（LLE）方法，该方法优化组合系数以对当前预测进行细化，减少逆算法分析求解器的敏感性，并且该方法对任何符合规范形式的基于扩散的逆算法都是通用的。通过这种方法，作者实现了一致的性能提升，且仅需有限步骤即可提供更高效解决方案和性能增强。
### Conclusion
本文通过对逆算法的ODE求解器进行分析，揭示了其近似线性组合结构，并提出了一个规范形式以统一扩散基逆算法，从而设计出更具通用性解算器。通过对该方法的广泛实验验证，展示了其在多个算法和任务中的性能提升，证明了它在有限步骤内提供更高效解决方案的可能性。
## 986. `cs.LG` - REPA-E: 解锁(latent)扩散变换器与VAE端到端调优 [PDF](https://arxiv.org/pdf/2504.10483), [HTML](https://arxiv.org/abs/2504.10483)
### Authors
Xingjian Leng,Jaskirat Singh,Yunzhong Hou,Zhenchang Xing,Saining Xie,Liang Zheng
### Background
传统的深度学习智慧认为，当有条件时，端到端训练往往更优。然而，对于(latent)扩散变换器来说，直接用标准扩散损失同时训练变分自编码器(VAE)和扩散模型会导致效果不佳甚至退化。
### Innovation
作者提出了一种名为REPA-E的新训练方法，通过使用representation-alignment(Representation Alignment)损失，使得VAE和扩散模型在训练过程中可以联合调优。这不仅提高了扩散模型的训练速度（分别比REPA和标准训练方法快17倍和45倍），还改善了VAE的表现，提升了潜在空间结构和下游生成效果。最后，该方法在ImageNet 256x256上的FID分数达到了1.12和1.69的新纪录。
### Conclusion
该方法不仅显著提升了训练效率和效果，还同时优化了VAE自身。
## 987. `cs.LG` - 湍流系统中的物理知情时空深度学习框架 [PDF](https://arxiv.org/pdf/2505.10919), [HTML](https://arxiv.org/abs/2505.10919)
### Authors
Luca Menicali,Andrew Grace,David H. Richter,Stefano Castruccio
### Background
流体热力学是大气动力学、气候科学、工业应用和能源系统的基础。然而，直接数值模拟(DNS)此类系统可能会因计算量巨大而不可行。
### Innovation
提出了一种结合卷积神经网络的空间维度降维和受大型语言模型启发的递归架构的时空物理知情代理模型，用于再现雷利-本华对流(RBC)的关键物理特性。该模型通过惩罚推断与所支配偏微分方程的偏差来确保物理可解释性，并利用保形预测框架量化不确定性。
### Conclusion
该模型可以显著降低计算成本，提供了一种对长时间模拟具有可扩展性的DNS替代方案。
## 988. `cs.LG` - 使用802.15.4z红外UWB硬件进行低成本嵌入式呼吸速率确定，用于远程医疗保健 [PDF](https://arxiv.org/pdf/2504.03772), [HTML](https://arxiv.org/abs/2504.03772)
### Authors
Anton Lambrecht,Stijn Luchie,Jaron Fontaine,Ben Van Herbruggen,Adnan Shahid,Eli De Poorter
### Background
呼吸疾病是全球死亡率的一个重要组成部分，而早期和负担得起的检测方法是有效的应对措施。为了实现这一点，本文利用低成本的商用现成（COTS）IEEE 802.15.4z标准符合的脉冲无线电超宽带（IR-UWB）雷达系统来估计人的呼吸频率，并使用卷积神经网络（CNN）从超宽带（UWB）信道脉冲响应（CIR）数据预测呼吸速率，以此来提高对呼吸病症检测的准确性与效率。
### Innovation
该研究提出了一种专门用于从UWB信道脉冲响应数据预测呼吸速率的CNN，并将其性能与基于规则的方法和基于模型的解决方案进行了比较。研究使用了多样化的数据集，以评估系统的鲁棒性，并通过开放数据集提供研究基础。使用包含其他个体校准数据的方法，在前所未见的情况下将误差降低至0.84次/分钟。另外，通过使用8位量化减少计算量和推理时间，同时保持较低的准确率增加，证明了在低成本嵌入式设备上进行推理的可能性。此外，系统在使用20000mAh电池包供电的情况下，连续监测房间时可以运行长达268天，并且在卧床呼吸监测时，采样率可以降低，电池寿命可延长至313天。
### Conclusion
本文展示了利用802.15.4z红外UWB硬件和CNN算法对于低成本呼吸速率检测的可行性，并提供了相应的性能改进和部署方式，使得该技术适用于远程医疗保健的广泛应用。
## 989. `cs.LG` - VLLFL: 一种基于视觉语言模型的轻量级联邦学习框架用于智能农业 [PDF](https://arxiv.org/pdf/2504.13365), [HTML](https://arxiv.org/abs/2504.13365)
### Authors
Long Li,Jiajia Li,Dong Chen,Lina Pu,Haibo Yao,Yanbo Huang
### Background
在现代智能农业中，目标检测起着关键作用，通过实现自动化、精准农业和资源监控等功能。它能够识别作物健康状况、病虫害以及优化收割过程等，从而提高农业生产的效率和可持续性。然而，训练目标检测模型往往需要大量的数据集，这引发了隐私保护方面的担忧，特别是在分布于多个农场的敏感农业数据情况下。为此，本文提出了VLLFL，一种基于视觉语言模型的轻量级联邦学习框架。该框架利用视觉语言模型的一般化能力和上下文感知检测能力，结合联邦学习的隐私保护特性，通过训练一个紧凑的提示生成器来提升部署在不同农场的视觉语言模型的性能，从而在保障隐私的同时减少通信开销。实验结果表明，VLLFL在性能提升14.53%的同时，通信开销减少了99.3%。该框架适用于从识别各种水果到检测农业中有害动物等多种任务，提供了一种高效、可扩展且能保护隐私的解决方案，专门针对农业应用设计。
### Innovation
提出了VLLFL，一种基于视觉语言模型的轻量级联邦学习框架，结合了视觉语言模型的一般化能力和上下文感知检测能力，结合联邦学习的隐私保护特性。通过训练一个紧凑的提示生成器来提升部署在不同农场的视觉语言模型的性能，从而在保障隐私的同时减少通信开销，并在任务泛化和通信效率方面展现了显著的改进。该框架适用于农业中多种识别任务，提供了一种高效的、可扩展的和隐私保护的解决方案。
### Conclusion
本文提出的VLLFL框架实现了对各种农业应用中目标检测任务的有效、可扩展和隐私保护的助力。通过结合视觉语言模型的优势和联邦学习的隐私保护特性，VLLFL显著改进了任务性能并且大幅减少了通信开销，对于智能农业中的数据收集和分析具有重要意义。
## 990. `cs.LG` - 时间逆转对高效深度强化学习中机器人操作的应用 [PDF](https://arxiv.org/pdf/2505.13925), [HTML](https://arxiv.org/abs/2505.13925)
### Authors
Yunpeng Jiang,Jianshu Hu,Paul Weng,Yutong Ban
### Background
机器人技术中的对称性在深度强化学习(DRL)中被广泛利用以提高样本效率，然而现有的方法主要关注空间对称性（如反射、旋转和平移），而忽视了时间对称性。时间逆转对称性在诸如开门和关门等机器人任务中普遍存在。
### Innovation
提出了一种名为时间逆转增强深度强化学习(TR-DRL)的框架，结合了轨迹反转增强和时间逆转引导奖励塑造，以有效地解决时间对称任务。该方法通过动态一致性过滤器识别可完全逆转的轨迹，从中生成反向过渡来增强训练数据。对于部分可逆转的轨迹，该方法应用奖励塑造以引导学习，借鉴逆任务中的成功轨迹。
### Conclusion
在Robosuite和MetaWorld基准测试中的广泛实验表明，TR-DRL在单任务和多任务设置中都有效，相比基线方法具有更高的样本效率及更强的最终性能。
## 991. `cs.LG` - gen2seg: 生成式模型实现泛化的实例分割 [PDF](https://arxiv.org/pdf/2505.15263), [HTML](https://arxiv.org/abs/2505.15263)
### Authors
Om Khangaonkar,Hamed Pirsiavash
### Background
生成式模型从扰动输入中合成一致图像，能够自我学习物体边界和场景布局的理解。研究如何利用这些生成式的表示，进行通用感知组织成为新的挑战。
### Innovation
通过使用实例着色损失，对Stable Diffusion和MAE进行微调，专门针对室内家具和汽车这类物体进行训练。研究发现，此种方法在未见物体类型和样式上表现出强大的零样本泛化能力，特别是在模糊边界和精细结构分割上超越了现有的模型。
### Conclusion
生成式模型能够学习固有的分组机制，即使没有大规模的互联网预训练，也能够在不同类别和领域之间进行泛化。研究结果表明最佳模型接近高度监督的SAM模型，并在像素级分割和边界识别上表现更佳。同时指出现有的可提示分割架构或判别式预训练模型难以实现泛化。
## 992. `cs.LG` - 使用实验数据引导生成模型进行蛋白质适应性优化 [PDF](https://arxiv.org/pdf/2505.15093), [HTML](https://arxiv.org/abs/2505.15093)
### Authors
Jason Yang,Wenda Chu,Daniel Khalil,Raul Astudillo,Bruce J. Wittmann,Frances H. Arnold,Yisong Yue
### Background
蛋白质适应性优化涉及在可能的序列设计空间中找到能够最大化所需定量属性的蛋白质序列。近年来，通过标记数据引导蛋白质生成模型（例如扩散模型和语言模型）的发展为这一领域带来了新的希望。然而，大多数现有的研究都是通过优化代理奖励或大量使用标记数据来引导生成过程，因此在实际优化中，即通过耗时的实验室测试来测量适应性的过程中，不清楚现有方法的性能和相互比较情况如何。本文旨在探索在少量（数百个）序列-适应性标记对情况下实现适应性优化，并全面评估各类分类器引导和后验采样策略在不同蛋白质序列离散扩散模型中生成过程的引导方式。文中还展示了如何将引导方式集成到类似贝叶斯优化中的自适应序列选择中，表明插拔式引导策略比使用蛋白质语言模型的强化学习方法更有优势。上述内容提供了实用建议，以便更有效地引导现代生成模型进行下一代蛋白质适应性优化。
### Innovation
本研究使用少量序列-适应性标记对进行适应性优化，并评估了不同的分类器引导和后验采样策略在不同蛋白质序列离散扩散模型中的应用。研究发现，插拔式引导策略在引导生成过程时比使用蛋白质语言模型的强化学习方法更加有效。这项工作提供了关于如何有效引导现代生成模型进行下一代蛋白质适应性优化的实用见解。
### Conclusion
本研究指出了如何在适应性优化中有效应用现代生成模型，并通过实验验证了插拔式引导策略的有效性，为蛋白质适应性优化提供了新的思路和方法。
## 993. `cs.LG` - Backward Conformal Prediction [PDF](https://arxiv.org/pdf/2505.13732), [HTML](https://arxiv.org/abs/2505.13732)
### Authors
Etienne Gauthier,Francis Bach,Michael I. Jordan
### Background
现有的标准方法采用固定的置信水平，允许预测集大小变化，但这种方法不能灵活控制预测集的大小。本文介绍了一种称为Backward Conformal Prediction的方法，它同时保证了置信覆盖的概率，又能灵活控制预测集的大小。这种方法基于Gauthier等人[2025]的工作，确保在数据相关误覆盖的情况下具有近似的边际覆盖，并利用一种新颖的残差剔除估计量来确保理论保证在实际操作中的可行性。这种方法特别在医学诊断等需要较小预测集的应用场景下非常有用。
### Innovation
Backward Conformal Prediction方法通过定义一个基于观测数据的规则，约束预测集大小的行为，并相应地调整置信水平，实现灵活控制预测集大小。这种方法引入了Gauthier等人[2025]的工作中的最近结果，并利用一种新颖的残差剔除估计量，确保了在数据相关误覆盖的情况下具有近似的边际覆盖，并在实践中保持理论保证的可行性。
### Conclusion
本文提供了理论结果和实证证据，证明了Backward Conformal Prediction方法的有效性，既维持了可计算的覆盖保证，同时确保了具有解释性且受良好控制的预测集大小。这种方法特别适用于医学诊断等场景。
## 994. `cs.LG` - DanmakuTPPBench：用于时序点过程建模与理解的多模态基准 [PDF](https://arxiv.org/pdf/2505.18411), [HTML](https://arxiv.org/abs/2505.18411)
### Authors
Yue Jiang,Jichu Li,Yang Liu,Dingkang Yang,Feng Zhou,Quyu Kong
### Background
尽管时序点过程（TPP）已被广泛研究用于建模时间事件序列，现有的数据集主要是单模态的，这阻碍了需要时间、文本和视觉信息联合推理的模型的发展。DanmakuTPPBench 出台以解决这一问题，该基准包含两个部分：DanmakuTPP-Events 与 DanmakuTPP-QA，以提供更多样的多模态数据支持这些模型。
### Innovation
DanmakuTPPBench 提出了一项全面的基准，旨在促进大规模语言模型（LLMs）时代下的多模态 TPP 模型，包括基于 Bilibili 平台用户生成的弹幕（Danmaku）事件的多模态数据集（DanmakuTPP-Events）以及由尖端 LLM 和多模态 LLM 搭建的复杂多代理问答数据集（DanmakuTPP-QA）。研究表明，当前方法在建模多模态事件动态方面存在显著的性能差异。
### Conclusion
DanmakuTPPBench 建立了强大的基线，为进一步将 TPP 模型融入多模态语言建模领域奠定了基础。
## 995. `cs.LG` - 预训练共享Q网络以提高离线强化学习的数据效率 [PDF](https://arxiv.org/pdf/2505.05701), [HTML](https://arxiv.org/abs/2505.05701)
### Authors
Jongchan Park,Mingyu Park,Donghwan Lee
### Background
离线强化学习(Offline RL)的目标是从静态数据集中学习策略，而不需要与环境进一步互动。由于数据收集需要大量的环境交互，特别是在环境交互受限的情况下，这变得更加困难。因此，如何利用最小的静态数据集让智能体学习到最优策略成为了离线RL中的关键问题，这类似于在线RL中的样本效率问题。本论文旨在研究如何通过预训练方法提高离线RL中的数据效率。
### Innovation
本文提出了一种简单而有效的预训练方法，通过初始化共享Q网络的特征来增强离线RL中的数据效率。该方法利用了一个共享的Q网络结构，该结构可以输出下一个状态的预测和Q值。共享Q网络通过监督回归任务进行预训练，该任务预测下一个状态，并且使用多种离线RL方法进行训练。实验结果表明，该方法显著提升了多种流行离线RL方法在D4RL、Robomimic和V-D4RL基准上的性能，并在不同数据质量和分布下显著提升了数据效率，甚至在基于仅10%数据集的预训练下也表现优于标准算法，即使拥有完整数据集也表现良好。
### Conclusion
研究表明，通过预训练共享Q网络的方法可以有效提高离线RL中的数据效率。这种方法不仅适用于高质量的数据集，还能很好地处理数据分布变化的情况。同时，实验结果表明，预训练方法在数据量有限时的性能优势明显，甚至只用10%的数据集就能取得优于标准算法的结果。
## 996. `cs.LG` - 使用gSMILE解释大型语言模型 [PDF](https://arxiv.org/pdf/2505.21657), [HTML](https://arxiv.org/abs/2505.21657)
### Authors
Zeinab Dehghani,Mohammed Naveed Akram,Koorosh Aslansefat,Adil Khan,Yiannis Papadopoulos
### Background
大型语言模型（LLMs）如GPT、LLaMA和Claude在文本生成方面取得了显著的性能，但在决策过程方面仍然透明度不足，这限制了其在高风险应用中的信任和责任感。
### Innovation
gSMILE（generative SMILE）是一个模型通用的扰动基础框架，用于LLMs的子词级可解释性。gSMILE通过控制提示微调、Wasserstein距离度量和加权线性代理模型来识别对输出影响最大的输入子词。这种方法生成直观的热力图以视觉方式突出显示关键子词和推理路径。
### Conclusion
我们使用gSMILE在包括OpenAI的gpt-3.5-turbo-instruct、Meta的LLaMA 3.1 Instruct Turbo和Anthropic的Claude 2.1在内的领先LLMs上进行评估。结果表明，gSMILE能够提供可靠的人类一致的归因，Claude 2.1在注意力真实度方面表现最佳，GPT-3.5在输出一致性方面得分最高。这些发现证明了gSMILE能做到在模型性能与可解释性之间平衡，使得AI系统更加透明和可信。
## 997. `cs.LG` - 几乎不依赖于维度的均场黑盒变分推断的收敛性 [PDF](https://arxiv.org/pdf/2505.21721), [HTML](https://arxiv.org/abs/2505.21721)
### Authors
Kyurae Kim,Yi-An Ma,Trevor Campbell,Jacob R. Gardner
### Background
研究表明，黑盒变分推断（BBVI）使用参数化梯度在处理具有均场位置-尺度变分家族的大型数据集时，其收敛速度几乎不依赖于显式的维度依赖性。这对于高维数据的有效处理尤为重要。
### Innovation
1. 证明了对于强对数凹性和对数平滑的目标，使用亚高斯族进行BBVI时，达到$boldsymbol{tilde{theta}}$与全局最优解$theta^*$相差$tilde{theta} - theta^* thicksim boldsymbol{tilde{d}}$的解所需要的迭代次数与维度的依赖性为$boldsymbol{O}(text{log} d)$，显著优于全秩位置-尺度家族的$boldsymbol{O}(d)$依赖性。2. 对于厚尾族，证明了$boldsymbol{O}(d^{2/k})$的依赖性，其中$k$是族中有限矩的数量。3. 如果目标对数密度的海森矩阵是常数，复杂度将完全不受显式维度的影响。
### Conclusion
研究进一步证明，BBVI的梯度方差的上界是关键，这一上界仅通过海森矩阵的谱约束无法进一步改进。这表明优化过程中的梯度方差估计对提高算法性能的关键作用。
## 998. `cs.LG` - Infinity Parser: 基于布局感知的强化学习在扫描文档解析中的应用 [PDF](https://arxiv.org/pdf/2506.03197), [HTML](https://arxiv.org/abs/2506.03197)
### Authors
Baode Wang,Biao Wu,Weizhen Li,Meng Fang,Zuming Huang,Jun Huang,Haozhe Wang,Yanjie Liang,Ling Chen,Wei Chu,Yuan Qi
### Background
传统的多阶段文档AI处理管道在面对多样化的文档布局时表现不足，容易出现错误传播问题。因此，自动化扫描文档的解析仍是一个关键瓶颈。
### Innovation
提出了一个端到端的强化学习框架布局RL，通过优化归一化编辑距离、段落计数准确性和阅读顺序保持的综合奖励，训练模型达到明确定位布局的能力。使用新发布的Infinity-Doc-55K数据集来训练布局感知的解析器Infinity-Parser，该数据集结合了55K高质量合成扫描文档与专家筛选的真实文档。评估结果显示，Infinity-Parser在OCR、表格和公式提取及阅读顺序检测方面的准确性和结构保真度均达到最新技术水平，超越了专门的处理管道和通用的视觉-语言模型。
### Conclusion
Infinity-Parser已经达到了新的准确性和结构保真度的最新技术水平，我们将公开释放代码和数据集，以便加速稳健的文档理解研究进程。
## 999. `cs.LG` - FlySearch: 探索视觉语言模型的探索能力 [PDF](https://arxiv.org/pdf/2506.02896), [HTML](https://arxiv.org/abs/2506.02896)
### Authors
Adam Pardyl,Dominik Matuszek,Mateusz Przebieracz,Marek Cygan,Bartosz Zieliński,Maciej Wołczyk
### Background
现实世界是复杂且无结构的，需要积极、目标导向的探索来发现重要信息。已有的研究表明，最近出现的视觉-语言模型（VLMs）在许多困难任务中可以作为一种有效的零样本工具使用，但它们是否能在不规则条件下有效运行仍是一个未知数。本研究通过创建名为FlySearch的三维、户外、写实场景环境，模拟对象搜索和导航任务，来检验这一问题。
### Innovation
本研究引入了FlySearch，并定义了不同难度级别的场景集。观察结果显示，最先进的视觉-语言模型在最简单的探索任务中也不能可靠地解决问题，且随着任务难度增加，模型的表现与人类的差距更大。研究还识别出了视觉幻觉、语境误解和任务规划失败等关键因素，并表明部分问题可以通过微调来应对。研究并公开了基准数据集、场景及底层代码库。
### Conclusion
最先进的视觉-语言模型在复杂现实场景中的探索能力较差，模型在执行任务时存在视觉幻觉、语境误解和任务规划失败等问题。通过微调可以部分解决这些问题，但仍有改进空间。研究团队公开了其工作的基准、场景集和代码库，以促进该领域的发展和研究。
## 1000. `cs.LG` - 基于模型的隐式神经表示法用于亚波长无线定位 [PDF](https://arxiv.org/pdf/2506.06387), [HTML](https://arxiv.org/abs/2506.06387)
### Authors
Baptiste Chatelier(IETR, INSA Rennes, MERCE-France),Vincent Corlay(MERCE-France),Musa Furkan Keskin,Matthieu Crussière(INSA Rennes, IETR),Henk Wymeersch,Luc Le Magoarou(INSA Rennes, IETR)
### Background
基站部署大规模天线阵列显著提高了无线电定位方法的空间分辨率和定位精度。传统信号处理技术在复杂无线电环境中遇到挑战，尤其是在非视距（NLoS）传播路径占主导地位的场景中，这导致定位精度下降。虽然最近的机器学习发展促进了辅助定位技术的开发，提高了复杂无线电环境下的定位精度，但这些方法在训练和推理阶段通常涉及大量计算复杂性。
### Innovation
通过扩展成熟的指纹化辅助定位框架，减少其内存需求并提升其定位精度。具体而言，使用基于模型的神经网络学习位置-信道映射，并作为生成性神经通道模型。生成模型扩展了指纹匹配字典，同时减少了内存需求。所提出的方法即使在复杂的静态NLoS环境中也能实现亚波长定位精度，同时将定位精度提高几个数量级，内存需求减少一个数量级，相比传统指纹化方法更具优势。
### Conclusion
所提出的基于模型的隐式神经表示法在复杂静态NLoS环境中实现了亚波长级别的定位精度，并且比传统指纹化方法内存需求减少一个数量级，同时显著提高了定位精度，从而提升了无线电环境下的定位能力。
## 1001. `cs.LG` - ALINE: 联合进行贝叶斯推断和主动数据获取的协同化方法 [PDF](https://arxiv.org/pdf/2506.07259), [HTML](https://arxiv.org/abs/2506.07259)
### Authors
Daolang Huang,Xinyi Wen,Ayush Bharti,Samuel Kaski,Luigi Acerbi
### Background
许多关键应用，从自主科学发现到个性化医疗，都要求系统能够既战略性地获取最有信息量的数据，又能够基于这些数据即时进行推理。虽然贝叶斯推理和实验设计的计算化方法提供了一部分解决方案，但在需要即时收集新数据进行推理的最通用和最具挑战性任务中，这两种方法都不是最优化的选择。
### Innovation
提出了一种名为Amortized Active Learning and Inference Engine（ALINE）的统一框架，用于贝叶斯推理和主动数据获取的协同计算。ALINE 利用基于自身集成推理组件提供自估计信息增益的奖励强化学习训练的变换器架构，使其能够在查询信息性数据点的同时不断优化预测。此外，ALINE 能够选择性地将查询策略集中在模型参数的特定子集或指定的预测任务上，以优化后验估计、数据预测或二者的混合。
### Conclusion
ALINE 在基于回归的主动学习、经典贝叶斯实验设计基准以及针对部分参数的选择性目标的心理测量模型中均表现出快速且准确的推理能力，并且高效地选择了信息性数据点。
## 1002. `cs.LG` - 动态扩散薛定谔桥在天体物理观测反演中的应用 [PDF](https://arxiv.org/pdf/2506.08065), [HTML](https://arxiv.org/abs/2506.08065)
### Authors
Ye Zhu,Duo Xu,Zhiwei Deng,Jonathan C. Tan,Olga Russakovsky
### Background
本研究探讨了扩散薛定谔桥（DSB）模型在天体物理动态系统中的应用，特别是在巨分子云（GMCs）中处理恒星形成过程的观测逆向预测任务。研究在理论上和实践中检验了该方法，并将所得结果与传统的天文统计和机器学习方法进行了对比。
### Innovation
研究引入了Astro-DSB模型，这是一种针对天体物理学动态的DSB模型变体，通过在物理模拟数据和真实观测数据（如Taurus B213数据）中的学习过程和预测性能验证，证明相比传统的天文统计和机器学习方法，这种方法在可解释性、学习效率和预测性能上有所改善。此外，提出了一种新的生成建模方法，该方法在未见过的初始条件和不同主导物理过程的物理模拟中，优于基于像素的判别模型在分布外（OOD）测试案例中的表现。
### Conclusion
研究扩展了扩散模型的应用范围，不仅限于传统的视觉合成应用，还表明模型能够超越纯粹的数据统计，学习能力显著提高。这为未来感知物理的生成模型铺平了道路，使之能够将机器学习和实际（天体）物理系统的动力学进行对齐。
## 1003. `cs.LG` - ReVeal：通过可靠自我验证的自我演进代码代理 [PDF](https://arxiv.org/pdf/2506.11442), [HTML](https://arxiv.org/abs/2506.11442)
### Authors
Yiyang Jin,Kunzhao Xu,Hang Li,Xueting Han,Yanmin Zhou,Cheng Li,Jing Bai
### Background
Reinforcement learning with verifiable rewards (RLVR)已经提升了大型语言模型的推理能力。然而，现有的方法仅依赖于结果奖励，而不明确优化验证或利用现实环境中的可靠信号，导致自验证不可靠和有限的测试时间扩展能力。
### Innovation
ReVeal引入了一个多回合强化学习框架，通过明确优化自验证来扩展代码生成，并通过工具评估促进代码和测试生成的相互演化。ReVeal弱化了验证-生成的不对称性，增强了自验证，使模型能够使用自我构建的测试和工具反馈，在LiveCodeBench中迭代生成代码超过20轮，尽管仅用三个回合数据训练。这显著提高了Pass@k，展示了更强的探索能力，扩展了基本模型的推理边界。这些发现展示了ReVeal作为RL训练和测试时间扩展的可扩展范式的潜力，为更 robust 和自主的AI代理铺平了道路。
### Conclusion
ReVeal作为一种增强的自验证框架，不仅改善了自验证的可靠性和推理能力的扩展性，还为未来的大规模语言模型训练和测试提供了新的视角。
## 1004. `cs.LG` - 反事实推理：上下文条件下的分析 [PDF](https://arxiv.org/pdf/2506.05188), [HTML](https://arxiv.org/abs/2506.05188)
### Authors
Moritz Miller,Bernhard Schölkopf,Siyuan Guo
### Background
大规模的神经语言模型表现出在上下文学习中的出色表现：即时地理解和推理输入上下文的能力。这项工作研究了语言模型的反事实推理能力，即预测假设场景后果的能力。研究集中在要求噪声推断的特定线性回归任务上，准确预测基于推断未观察到的潜在概念以及从实际情况中复制上下文噪声。研究发现语言模型具备反事实推理能力，且在Transformers中，自注意力机制、模型深度和预训练数据多样性驱动性能提升。此外，研究提供了关于潜在概念在残差流中线性表示的机制证据，并引入了负责执行反事实推理的指定噪声推断头。最终发现延伸到了SDE动力学下的反事实推理，表明Transformers能够在顺序数据上执行噪声推断，为逆事实故事生成提供了初步证据。
### Innovation
1. 通过研究特定的合成线性回归任务来分析语言模型的反事实推理能力，尤其是噪声推断。2. 发现了Transformers在反事实推理中的特定机制（如自注意力机制、模型深度和预训练数据多样性的重要性）。3. 证明了潜在概念在模型中的线性表示，并提供了一种专门的噪声推断头，为反事实推理提供支持。4. 扩展了反事实推理到SDE动力学，展示了其在处理时间序列数据上的能力，指向了逆事实故事生成的潜力。
### Conclusion
研究揭示了神经语言模型在特定任务中的反事实推理能力，并深入探讨了模型内部的机制。通过增强现有可识别性结果，研究将反事实推理问题简化为对上下文观察的转换。最终，这些发现不仅明确了模型的高性能特性，还初步展示了其在逆事实推理中的潜力，尤其是在时间序列数据的噪声推断上。
## 1005. `cs.LG` - LLMs能否在反事实推理中解决知识冲突 [PDF](https://arxiv.org/pdf/2506.15732), [HTML](https://arxiv.org/abs/2506.15732)
### Authors
Khurram Yamin,Gaurav Ghosal,Bryan Wilder
### Background
大型语言模型包含了广泛的世界知识，使其在许多知识密集型任务上表现出色。然而，在新环境中部署时，这些模型常常需要将参数化知识与新或不熟悉的信息相结合，这就带来了挑战。本研究探讨了大型语言模型是否可以通过反事实推理来整合上下文中的知识与参数化知识。研究表明，这些模型在反事实推理方面普遍面临困难，往往会依赖于使用其参数化知识。此外，简单的后随微调也不足以提升反事实推理能力，有时还会导致存储的参数化知识退化。
### Innovation
研究通过合成实验和实际多步推理问题的实验，探讨了大型语言模型在新环境中解决反事实推理中的知识冲突的能力。研究发现，这些模型往往依赖于使用参数化知识，简单的后随微调也不能有效提升反事推理能力，从而揭示了当前模型在重新利用参数化知识方面的局限性。
### Conclusion
研究揭示了当前大型语言模型在新环境中重新利用参数化知识的重要局限性，特别是在反事实推理能力方面。
## 1006. `cs.LG` - 使用大型语言模型为Google SQL代码生成服务生成高保真且复杂的测试数据 [PDF](https://arxiv.org/pdf/2504.17203), [HTML](https://arxiv.org/abs/2504.17203)
### Authors
Shivasankari Kannan,Yeounoh Chung,Amita Gondi,Tristan Swadell,Fatma Ozcan
### Background
在工业环境中，获取生产数据的访问受限，因此对高保真测试数据的需求至关重要。传统数据生成方法往往效率低下，难以生成高保真数据以及复杂的数据结构和语义关系，这些对于测试类似自然语言到SQL（NL2SQL）的复杂SQL代码生成服务至关重要。现有方法在处理大规模和复杂数据结构方面存在局限性，并且缺乏语义连贯的测试数据，这导致了测试覆盖率有限。本文聚焦于生成复杂的嵌套结构数据（常见于Google工作负载），这些数据在语义和语法上是正确的，符合复杂的结构性约束，确保SQL查询生成服务（如NL2SQL和SQL代码助手）的全面测试，特别是涉及连接、聚合和深深嵌套的子查询等复杂SQL查询的测试。
### Innovation
本文提出了一种新的方法，通过利用大型语言模型（LLMs）和前置和后置处理步骤，生成符合复杂结构约束和保持语义完整性的高保真测试数据。这种方法能够支持对于涉及连接、聚合甚至深度嵌套子查询等复杂SQL查询的全面测试，确保SQL代码生成服务的稳健评估，特别是在生产数据难以获取和访问的工业环境中生成高保真的测试数据非常实用。
### Conclusion
通过利用LLMs并结合预处理和后处理步骤，我们证明了可以生成符合复杂结构约束和保持语义完整的高保真测试数据，这对工业环境中的SQL代码生成服务的测试至关重要。这种方法支持涵盖从基本到高级的SQL查询的全面测试，确保SQL代码生成服务（如NL2SQL和SQL代码助手）的稳健评估。我们的结果表明，基于LLMs的测试数据生成对于确保SQL代码生成服务的准确性在工业环境中是有效的。
## 1007. `cs.LG` - 神经元中量子场理论的级数展开可行性 [PDF](https://arxiv.org/pdf/2508.03810), [HTML](https://arxiv.org/abs/2508.03810)
### Authors
Srimoyee Sen,Varun Vaidya
### Background
提出了打破统计参数独立性的神经网络（NN）架构作为模拟局部量子场理论（QFTs）的新方法。在神经元数目无穷大的情况下，单层神经网络可以在精确再现QFT结果。本文通过在d维欧几里德空间下的标量ϕ^4理论为例，探讨有限神经元数目N下的这一架构在局部QFTs中进行级数展开的可行性。研究表明，重整化的O(1/N)修正对二点和四点关联函数的计算结果使得计算级数对超紫外截断的敏感，因此收敛较弱。
### Innovation
发现有限神经元数目下单层神经网络进行QFT中作用量级计算时的渐进系列收敛较弱，并提出改进架构以增强收敛，并讨论了理论参数和N数量级的限制条件，允许准确获得场论结果。
### Conclusion
提出了改进的神经网络架构以增强收敛性，并讨论了在有限神经元数目下提取准确的场论结果所允许的理论参数和N的数量级的限制条件。
## 1008. `cs.LG` - AICO: 监督学习中的特征显著性检验 [PDF](https://arxiv.org/pdf/2506.23396), [HTML](https://arxiv.org/abs/2506.23396)
### Authors
Kay Giesecke,Enguerrand Horel,Chartsiri Jirachotkulthorn
### Background
许多监督学习算法的不透明性仍然是一个关键挑战，阻碍了科学发现并限制了更广泛的部署——特别是在高赌注领域。本文旨在开发一种模型和分布无关的显著性检验方法，以评估任何回归或分类算法中输入特征的影响。该方法通过在样本中遮盖特征值来评估特征对模型性能的增量贡献。在零假设下，测试集性能差异分布的中值为非正。我们构建了一种针对中值的最强大随机符号检验法，从而获得用于评估特征显著性的精确p值和具有精确覆盖率的用于估计群体特征重要性的置信区间。方法对最小假设的需求、无需模型重新训练或辅助模型的特点，以及即使在大规模高维情况下仍保持计算效率，都取得了显著进展。合成任务的实验验证了其统计和计算优势，而将其应用于真实数据集的实验展示了其在具有法律、经济和监管影响的高赌注决策中的能力。
### Innovation
本文开发了模型和分布无关的显著性检验方法，用于评估回归或分类算法中输入特征的影响。该方法通过在样本中遮盖特征值来评估特征对模型性能的增量贡献。构建了一种针对中值的最强大随机符号检验法，从而获得用于评估特征显著性的精确p值和具有精确覆盖率的用于估计群体特征重要性的置信区间。该方法对最小假设的需求，无需模型重新训练或辅助模型，以及即使在大规模高维情况下仍保持计算效率的特点，都取得了显著进展。
### Conclusion
合成任务的实验验证了其统计和计算优势，而将其应用于真实数据集的实验展示了其在具有法律、经济和监管影响的高赌注决策中的能力。
## 1009. `cs.LG` - 端到端自动驾驶可解释性决策制定 [PDF](https://arxiv.org/pdf/2508.18898), [HTML](https://arxiv.org/abs/2508.18898)
### Authors
Mona Mirzaie,Bodo Rosenhahn
### Background
信任人工智能对于自动驾驶广泛部署是必要的。尽管端到端方法可以从原始数据直接得出控制指令，但在复杂城市场景中解释这些决策仍然具有挑战性。深层非线性神经网络导致非线性决策边界的出现，使得理解AI驱动决策的逻辑变得困难。
### Innovation
本论文提出了一种方法，旨在在优化控制指令的同时提高模型的可解释性。通过生成稀疏和局部化的特征图来促进模型的可解释性，这些特征激活允许表明哪些图像区域对预测的控制命令有贡献。我们还在CARLA基准上进行了彻底的特征提取步骤的消融研究，并验证了我们的方法，结果显示我们的模型提高了可解释性，减少了违规行为，提高了驾驶的安全性和高性能。
### Conclusion
我们的单目非集合模型在CARLA排行榜上优于顶级方法，实现了更低的违规分数和最高的路线完成率，同时确保了解释性。
## 1010. `cs.LG` - 通过参数自编码器的弹性结构拓扑优化的代理模型 [PDF](https://arxiv.org/pdf/2507.22539), [HTML](https://arxiv.org/abs/2507.22539)
### Authors
Matteo Giacomini,Antonio Huerta
### Background
本文探讨了一种针对具有参数载荷和边界条件的线性弹性结构的代理优化算法。传统的优化方法通常需要大量的计算资源来求解优化问题，并且通常需要针对不同的参数组合重新进行计算。因此，研究人员需要一种更高效的方法来预测结构的最佳拓扑，从而减少计算成本并提高优化精度。
### Innovation
本文提出了一种基于代理的方法，通过学习初始参数设置与隐空间之间的映射来预测近似最优的结构拓扑，而不是学习状态问题（和伴随问题）的解或优化轨迹。方法使用前馈神经网络来学习输入参数和结构设置之间的映射关系，并通过编码器/解码器结构降低参数化的拓扑优化问题的维度，进而预测高维得分拓扑。这种方法用预测的拓扑作为初始猜测来节省计算成本，同时确保系统的控制方程。通过不同的架构，研究了所得到的模型的近似和泛化能力。实验表明，使用这种方法可以将优化迭代次数减少53%，并且在最优目标函数值方面的差异低于4%，即使在测试模型外推到训练和验证域之外的挑战性场景下也能取得良好表现。
### Conclusion
本文提出的方法通过减少优化迭代次数和减少最优目标函数值的差异，展示了更好的性能。特别是在处理具有参数变化的弹性结构拓扑优化问题时，该代理模型能够有效地预测近似最优的结构拓扑，减少计算成本和提高优化精度。
## 1011. `cs.LG` - 从尘埃到模拟：掌握多变粒状介质中的动态路径跟踪 [PDF](https://arxiv.org/pdf/2508.11503), [HTML](https://arxiv.org/abs/2508.11503)
### Authors
Andrej Orsula,Matthieu Geist,Miguel Olivares-Mendez,Carol Martinez
### Background
未来太空探索中，克服不规则地表的自主导航对于可靠的空间任务至关重要。然而，基于学习的控制器的实际部署受到模拟与现实之间存在差距的阻碍，尤其对于轮子与颗粒介质之间复杂动态的控制尤为困难。
### Innovation
本研究提出了一套完整的模拟到现实的框架，用于开发和验证在复杂、难以预测的地面上动态路径跟踪的鲁棒控制策略。综合利用大规模并行模拟和程序生成环境，以及奖励学习算法和动作平滑滤波器的系统比较，发现程序生成多样性训练的代理在零样本转移上表现更佳。此外，通过对高保真粒子物理调优的分析，表明其在低速精确定位上的微小利益伴随着显著的计算成本增加。
### Conclusion
本研究通过提供实验证据证明程序生成多样性训练的代理在真实世界部署上的优势，并阐明了高保真粒子物理调优的权衡，从而确立了一套可靠的基于学习的导航系统的流程，朝着在最远边疆部署自主机器人迈出了重大一步。
## 1012. `cs.LG` - 变分不等式中的打乱启发式方法：建立新的收敛性保证 [PDF](https://arxiv.org/pdf/2509.04133), [HTML](https://arxiv.org/abs/2509.04133)
### Authors
Daniil Medyakov,Gleb Molodtsov,Grigoriy Evseev,Egor Petrov,Aleksandr Beznosikov
### Background
变分不等式在机器学习和优化研究中受到了广泛关注。虽然解决这类问题的随机方法通常假定数据独立采样，但研究者们探讨了一种替代策略——打乱启发式方法。这种方法涉及在顺序处理之前对数据集进行打乱，确保所有数据点都被公平考虑。尽管这种策略在实践中具有显著优势，但变分不等式中打乱方法的理论保证仍然未被探索。
### Innovation
本文填补了理论空白，提供了变分不等式中打乱方法的第一个理论收敛估计。我们通过严格的界限和收敛率分析，扩展了这类重要算法的理论框架。我们通过广泛的实验验证了这一发现，结果表明打乱方法相较于独立采样方法具有更快的收敛速度。
### Conclusion
我们证明了在变分不等式中使用打乱启发式方法的合理性，并为这些方法提供了理论支持，尤其是它们的收敛性。打乱方法的收敛速率比独立采样方法更快，在实际应用中具有显著优势。
## 1013. `cs.LG` - 高容量多大型语言模型在线路由的高效无训练方法 [PDF](https://arxiv.org/pdf/2509.02718), [HTML](https://arxiv.org/abs/2509.02718)
### Authors
Fangzhou Wu,Sandeep Silwal
### Background
大型语言模型（LLMs）服务的需求增长带来了部署和计算成本的显著增加。通过将查询定向到基于模型和查询特征的最佳LLM的LLM路由能够提供成本效益高的解决方案。然而，现有的工作主要集中在离线场景，并难以适应高查询量和受限的令牌预算的在线设置。此前的研究侧重于利用训练数据进行学习，这在高查询量和资源受限的环境中具有挑战性。
### Innovation
本文首次提出了一个无需训练的在线路由算法。该算法利用近似最近邻搜索来高效估计查询特征，并通过一次性优化一组初始查询来学习路由策略，该策略能指导未来的路由决策。此算法在特定假设下提供了理论上的竞争力比，实验结果也展示了其良好的性能和效率改进，优于多个基准算法，尤其在整体性能、成本效率和吞吐量方面。
### Conclusion
我们在广泛的三个基准数据集和八个基线中进行了实验验证，结果表明该算法在总体性能、成本效率和吞吐量方面分别平均提高了3.55倍、1.85倍和4.25倍。并且，我们分享了实现该算法的代码。
## 1014. `cs.LG` - 公平最小标注：用于可达性和公平性的高效临时网络激活 [PDF](https://arxiv.org/pdf/2510.03899), [HTML](https://arxiv.org/abs/2510.03899)
### Authors
Lutz Oettershagen,Othon Michail
### Background
在支持现代学习应用的网络系统中，平衡资源效率和公平性至关重要。FML问题的目标是在最小化边激活成本的同时，确保网络中的每个节点组都能满足指定的目标覆盖要求。
### Innovation
作者引入了FML问题，并提供了概率近似算法来解决这一问题。该算法实现了成本的最佳保证。通过实验证明了FML在公平多源数据聚合任务中的实用价值，表明FML可以显著降低激活成本，提高网络中的资源效率和公平性。
### Conclusion
FML能够以显著低于基线启发式方法的激活成本实现组级公平性，证明了其在构建学习整合网络中高效、公平的临时可达性方面的巨大潜力。FML解决了系统中边激活会产生资源成本且公平访问至关重要的情景下的关键权衡问题。
## 1015. `cs.LG` - 使用ModernBERT进行专利语言模型预训练 [PDF](https://arxiv.org/pdf/2509.14926), [HTML](https://arxiv.org/abs/2509.14926)
### Authors
Amirhossein Yousefiramandi,Ciaran Cooney
### Background
基于Transformer的自然语言处理（NLP）模型，如BERT，在通用任务中表现优异，但这些模型在专利等专业领域中表现不佳。这些领域包含较长的、技术性的且具有法律结构的文本，普通模型通过微调或用有限数据预训练的部分领域适应版本来接触这些领域的NLP任务。这项研究旨在通过使用ModernBERT架构以及一个包含超过6000万专利记录的精选语料库来预训练三个针对专利领域的掩蔽语言模型，从而提高专利NLP任务的表现。
### Innovation
该研究引入了归一化闪注意础、旋转嵌入和GLU前馈层等架构优化技术。在四个下游专利分类任务中，ModernBERT-base-PT模型在三个数据集中相比通用的ModernBERT基线模型表现更优，并达到了与基线PatentBERT相当的性能。进一步的实验表明，增大模型规模和定制分词器可以进一步提高特定任务上的性能。所有ModernBERT变体模型的推理速度快于PatentBERT超过3倍，突显了这些模型在时间敏感应用中的适用性。
### Conclusion
通过领域特定的预训练和架构改进，专利专注于的NLP任务可以从中获得显著益处。这些结果强调了领域特定预训练和架构改进对专利NLP任务的重要性。
## 1016. `cs.LG` - SpecExit: 通过推测性退出加速大型推理模型 [PDF](https://arxiv.org/pdf/2509.24248), [HTML](https://arxiv.org/abs/2509.24248)
### Authors
Rubing Yang,Huajun Bai,Song Liu,Guanghua Yu,Runzhi Fan,Yanbin Dang,Jiejing Zhang,Kai Liu,Jianchen Zhu,Peng Chen
### Background
尽管大型推理模型（LRMs）在推理任务上表现强烈，但它们经常遭受过度思考的问题，生成过程过长且端到端延迟高，这限制了它们的现实应用部署。早期退出机制被提出，能够在模型典型完成之前终止推理，有效缩短生成长度且对准确性的负面影响小。然而，这些机制依赖探针机制会导致检测开销，限制了端到端延迟的改进，并影响其跨不同问题的一般适用性。
### Innovation
我们受推测性解码中的隐藏状态使用启发，提出了一种称为SpecExit的新框架，能够在不使用探针机制的情况下，从轻量级草图模型中直接预测出未来的令牌和早期退出信号。这种方法显著提高了性能，减少了66%的平均生成时间，并在端到端延迟上实现了2.5倍的速度提升，同时保持了准确性。该方法利用隐藏状态中的固有信号，为高效推理提供了有效的早期退出信号，表明隐藏状态在高效推理中的更广泛应用。
### Conclusion
该方法利用隐藏状态中的自然信号提供有效的早期退出信号，从而减少了生成时间并提高了推理速度；并通过取消探针机制的开销，进一步提高了端到端的延迟。我们的代码可在此处访问。
## 1017. `cs.LG` -  Narcissus 假设：通往幻象的阶梯 [PDF](https://arxiv.org/pdf/2509.17999), [HTML](https://arxiv.org/abs/2509.17999)
### Authors
Riccardo Cadei,Christian Internò
### Background
现代基础模型不仅反映了世界知识，还包含了训练数据中的人类偏好模式。我们假设，通过递归对齐——利用人类反馈和模型自动生成的数据——会产生一种社会可接受度偏差，促使模型倾向于响应令人愉悦或吹捧性的内容，而非客观推理。我们使用标准化个性评估和一种新型的社会可接受度偏差评分测试了31个模型。结果表明，这些模型朝着社会适应性特征明显偏移，这对语料库的完整性和下游推断的可靠性产生了深远影响。
### Innovation
提出了一种新的奈斯贝斯假设（Narcissus Hypothesis），并使用标准化个性评估和新的人类可接受度偏差评分进行了测试。研究还提供了一种新的认识论诠释，揭示了递归偏差如何导致贝叶斯因果梯度（Pearl's Ladder of Causality）中的高级推理崩溃，最终形成我们称之为幻觉的阶梯。
### Conclusion
研究结果揭示了显著的社会符合性偏移现象，对语料库完整性和下游推断的可靠性产生了深远影响。新的认识论解释表明，递归偏差可能会导致贝叶斯因果梯度的高级推理崩溃，最终形成幻想中的阶梯。
## 1018. `cs.LG` - 使用人口普查和土地使用数据指导的大语言模型生成个体旅行日记 [PDF](https://arxiv.org/pdf/2509.09710), [HTML](https://arxiv.org/abs/2509.09710)
### Authors
Sepehr Golrokh Amin,Devin Rhoads,Fatemeh Fakhrmoosavi,Nicholas E. Lownes,John N. Ivan
### Background
传统的旅行日记生成方法依赖于大量的专有家庭旅行调查数据，而这种方法利用来自美国社区调查（ACS）和智能位置数据库（SLD）的数据中的开放源数据生成随机的人物，然后通过直接提示合成日记。这种方法采用一种新颖的一对群体现实度测量法：由四项指标（行程计分、间隔计分、目的计分和方式计分）组成，这些指标是基于康涅狄格州全省交通研究（CSTS）日记并在多个人口统计变量上进行了匹配。这种验证通过Jensen-Shannon 散度来测量生成的日记与真实日记在分布上的相似性。当将大型语言模型生成的日记与使用经典方法（负二项分布进行行程生成；多项逻辑回归确定模式/目的）并在验证数据集上校准的日记进行比较时，LLM生成的日记在整体现实度方面表现出相似的结果（LLM均值：0.485 vs. 0.455）。LLM在确定行程目的方面表现出色，并且显示出更大的一致性和可预测性，而经典模型在行程数量和活动持续时间的数值估计方面更占优势。群体验证确认了LLM在统计代表性的表现（LLM均值：0.612 vs. 0.435），展示了LLM的零样本可行性和建立了未来合成日记评估系统中衡量日记现实度的量化标准。
### Innovation
提出了大型语言模型方案，利用开放源数据生成个体旅行日记。通过新颖的一对群体现实度评分方法，验证模型生成的日记的现实度，并通过Jensen-Shannon 散度来评估生成日记与实际日记的分布相似性。LLM方法在确定行程目的方面表现出色，并且显示出更大的一致性和可预测性，而经典模型在行程数量和活动持续时间的数值估计方面表现更占优势。
### Conclusion
大型语言模型在生成个体旅行日记方面表现出较高的现实度和一致性，特别是在确定行程目的方面。它为未来合成日记评估系统的开发提供了一个可量化度量基准，并展示了零样本可行性的潜力。
## 1019. `cs.LG` - LAMP-PRo: Label-aware Attention for Multi-label Prediction of DNA- and RNA-binding Proteins using Protein Language Models [PDF](https://arxiv.org/pdf/2509.24262), [HTML](https://arxiv.org/abs/2509.24262)
### Authors
Nimisha Ghosh,Dheeran Sankaran,Rahul Balakrishnan Adhi,Sharath S,Amrut Anand
### Background
研究DNA-结合蛋白（DBPs）和RNA结合蛋白（RBPs）对于理解细胞功能、分子相互作用以及调控功能至关重要。由于DBPs和RBPs高度相似，目前大多数方法在区分这两种蛋白时存在挑战，导致高交叉预测错误率。此外，识别同时结合DNA和RNA的蛋白质（DRBPs）也颇具挑战性。因此，本文提出了一种基于预训练蛋白质语言模型（PLM）、注意力机制和多标签学习的新框架LAMP-PRo，以解决上述问题。
### Innovation
LAMP-PRo采用了预训练的蛋白质语言模型（如ESM-2）进行蛋白质序列嵌入，接着使用卷积神经网络（CNN），随后应用多头自注意力机制提取上下文信息，利用标签感知注意力机制生成特定类别的表示，从而针对每种标签（DBP、RBP和非免受束缚蛋白）进行定制关注，同时引入跨标签注意力机制捕捉DNA-和RNA结合蛋白之间的依赖关系，最后采用线性层和sigmoid函数进行最终预测。实验对比了LAMP-PRo与其他现有方法，展示了其一致的优异性能，并提供了模型可解释性的可视化，展示了哪些序列部分对预测标签最为相关
### Conclusion
提出的LAMP-PRO框架表现出了一致的优异性能，并通过可视化展示了模型的可解释性，突显了对预测标签最相关的序列部分。原始数据集和代码可在指定链接处获取。
## 1020. `cs.LG` - 理解用于模型训练的强化学习及GRAPE的未来方向 [PDF](https://arxiv.org/pdf/2509.04501), [HTML](https://arxiv.org/abs/2509.04501)
### Authors
Rohit Patel
### Background
本文提供了一套从零开始、自包含的关于模型指令调优关键算法的详述，包括数据填充训练（SFT）、拒绝采样、REINFORCE、可信区域策略优化（TRPO）、近端策略优化（PPO）、组相关策略优化（GRPO）以及直接偏好优化（DPO）。通常这些算法的解释会假设读者已经具备相关先验知识，并且要么缺少关键细节，要么过于概括和复杂。本文通过使用简化和明确的符号来逐步讨论和发展这些方法，专注于大规模语言模型（LLMs），旨在消除模糊性，提供清晰且直观的概念理解。通过消除不必要的RL文献的游离内容，并将概念与LLMs联系起来，本文减少了冗余抽象和认知负担。
### Innovation
本文通过简化和明确的符号逐步阐述了关键算法，包括SFT、Rejection Sampling、REINFORCE、TRPO、PPO、GRPO和DPO，旨在消除模糊性，提供清晰且直观的概念理解。同时，本文还进行了对新技术和方法的文献回顾，并提出了GRAPE（广义相对优势策略演化）这一新概念，用于指导未来的模型训练研究。
### Conclusion
本文在详述了模型指令调优关键算法的基础上，对新技术和方法进行了一次文献梳理，并提出了GRAPE概念作为模型训练中的新方向。
## 1021. `cs.LG` - 超越Pass@k：用于推理边界的新颖广度-深度度量 [PDF](https://arxiv.org/pdf/2510.08325), [HTML](https://arxiv.org/abs/2510.08325)
### Authors
Marius Dragoi,Ioana Pintilie,Florin Gogianu,Florin Brad
### Background
Reinforcement Learning with Verifiable Rewards (RLVR) 已成为增强大型语言模型在编码、数学或逻辑等推理任务中性能的强有力框架。研究者通常报告在大规模采样预算下 Pass@k 来评估模型的推理边界。然而，近期观察到交叉现象：在小 k 值时，RLVR 模型表现优于基础模型，但在大规模采样后，基础模型通常会超越 RLVR 模型。这支持了基础模型具有更大推理边界的假设。但论文认为，对于具有离散答案空间的任务，如数学和数字输出，在大规模采样情况下 Pass@k 体现的是在大量尝试中的成功率，而非真实的推理能力，因此具有误导性。
### Innovation
提出了 Cover@tau 度量方法，衡量模型解决给定 τ 比例正确完成功能的试题占比。Cover@tau 相比 Pass@k 更严格地捕捉基于显式可靠性的推理能力：依赖随机猜测的模型会在 τ 增大时迅速退化。基于 Cover@tau 方法评估了几种 RLVR 模型，并展示了流行算法相对于 Pass@1 的排名变化，为推理边界提供了新的视角。
### Conclusion
与 Pass@k 相比，论文提出的 Cover@tau 度量方法更能准确反映模型的推理能力，尤其是在大规模采样的情况下。这为研究者提供了一个新的评估视角，能够更准确地比较不同算法的推理边界。
## 1022. `cs.LG` - 通过优化训练和推理之间的路由一致性稳定MoE强化学习 [PDF](https://arxiv.org/pdf/2510.11370), [HTML](https://arxiv.org/abs/2510.11370)
### Authors
Wenhan Ma,Hailin Zhang,Liang Zhao,Yifan Song,Yudong Wang,Zhifang Sui,Fuli Luo
### Background
 reinforcement learning (RL) 性能在大型语言模型中发挥了重要作用。但在混合专家模型（MoE）中，路由机制常常引发不稳定性，严重影响了RL训练的稳定性。
### Innovation
提出了一种称为Rollout Routing Replay (R3)的方法，该方法记录推理阶段的路由分布并将其应用于训练。R3显著减少了训练和推理之间的策略KL散度，并且不会牺牲训练速度，从而解决了MoE模型训练推理一致性差的问题。
### Conclusion
通过广泛的实验验证，R3方法成功地稳定了RL训练，防止了崩溃，并在各种设置中优于GSPO和TIS等方法。
## 1023. `cs.LG` - LLMs是否足以依赖隐性知识？基于树结构的RAG方法 [PDF](https://arxiv.org/pdf/2510.10806), [HTML](https://arxiv.org/abs/2510.10806)
### Authors
Mihir Gupte,Paolo Giusto,Ramesh S
### Background
大型语言模型（LLMs）擅长基于其上下文信息生成响应，这对处理结构化数据，如代码文件特别有用。另一种常见的方法是检索增强生成（RAG），通过检索相关文档来增强模型的上下文学习能力。然而，如何最好地表示检索到的知识以生成结构化数据的响应，特别是在处理层次结构数据（如树结构）时，尚未得到充分研究。
### Innovation
本文提出了一种新颖的自底向上的方法，用于将树状结构的知识（例如GitHub存储库）线性化，通过在每个层次结构级别生成隐式、聚合的摘要。这种方法使得知识可以存储在知识库中，直接与RAG结合使用。研究还对比了该方法与直接在RAG上使用未结构化代码的效果，发现虽然响应质量相当，但本文的方法在检索器中生成的文档数量减少了68%以上，显著提高了效率。这表明利用隐式、线性化知识可能是处理复杂层次结构数据的有效且可扩展策略。
### Conclusion
我们的研究结果显示，该方法在响应质量和生成效率上提供了一个有效的解决方案，特别适用于处理复杂的层次结构数据。
## 1024. `cs.LG` - 通过层次语义对齐和协同完成实现不完整多视图聚类 [PDF](https://arxiv.org/pdf/2510.13887), [HTML](https://arxiv.org/abs/2510.13887)
### Authors
Xiaojian Ding,Lin Zhao,Xian Li,Xiaoying Zhu
### Background
不完整多视图数据导致传统多视图聚类方法受到显著挑战，现有深度不完整多视图聚类方法通常依赖静态融合策略或两阶段流水线，这会导致融合结果次优和错误传播问题。
### Innovation
本文提出了一种基于层次语义对齐和协同完成的新型不完整多视图聚类框架（HSACC）。HSACC通过双层语义空间设计实现鲁棒的跨视图融合。在低层语义空间中，通过最大化视图间的互信息确保一致性对齐。在高层语义空间，根据视图与初始融合表示之间的分布相关性动态分配视图权重，并进行加权融合生成统一的全局表示。此外，HSACC隐式恢复缺失视图，通过投影对齐的潜在表示到高维语义空间，同时优化重建和聚类目标，实现完成和聚类的协同学习。实验结果表明，HSACC在五个基准数据集上显著优于现有最佳方法。消融研究验证了层次对齐和动态加权机制的有效性，参数分析证实了模型对超参数变化的鲁棒性。
### Conclusion
HSACC框架在多视图数据融合和不完整数据处理方面表现出显著优势，能够有效提高聚类性能，且具有良好的鲁棒性。
## 1025. `cs.LG` - 一种新的信息驱动的最优回归评估策略 [PDF](https://arxiv.org/pdf/2510.14222), [HTML](https://arxiv.org/abs/2510.14222)
### Authors
Benjamín Castro,Camilo Ramírez,Sebastián Espinosa,Jorge F. Silva,Marcos E. Orchard,Heraldo Rozas
### Background
在机器学习（ML）中，回归算法的目标是根据数据最小化损失函数。评估方法则旨在量化输入-输出系统中理想响应与由学习预测模型（即学生）产生的估计之间的差异。然而，在没有访问真实的数据生成机制的情况下评估学习回归器的质量仍具有挑战性，因为无法保证使用数据驱动方法达到全局最优。
### Innovation
本文提出了一种新颖的数据驱动框架——信息教师（Information Teacher），用于具有形式化性能保证的回归算法评估，以评估全局最优性。该方法基于估计输入变量与残差之间的香农互信息（MI），适用于广泛的加性噪声模型，并通过数值实验验证了该方法能够检测全局最优性，作为难以访问的真实模型估计误差的替代性近似表征，并提供了一种与传统经验性能指标不同的原则性替代方案。
### Conclusion
通过数值实验，我们证实了信息教师能够检测到全局最优性，这与难以访问的真实模型的估计误差为零的条件相一致，使其成为一个可靠的替代性衡量真实评估损失的指标，并提供了一种与常见的经验性能指标不同的原理性替代方案。
## 1026. `cs.LG` - 基于核的方法用于形状约束的非参数检验 [PDF](https://arxiv.org/pdf/2510.16745), [HTML](https://arxiv.org/abs/2510.16745)
### Authors
Rohan Sen
### Background
本文开发了一种用于非参数均值-方差优化及对最优规则形状约束进行统计推断的再生核希尔伯特空间(RKHS)框架。作者推导了样本估计器的统计性质，并提供了渐近一致性和功能中心极限定理等严格的理论保证，同时还提供了一个与蒙特卡洛速率一致的有限样本偏差界。根据这些发现，作者引入了一种针对有限网格的联合Wald型统计量，用于测试形状约束。
### Innovation
本文的创新点在于提出一种RKHS框架，用于非参数均值-方差优化和对最优规则形状约束的统计推断。作者提出了一种联合Wald型统计量来测试形状约束，并基于分段Cholesky分解提供了一种高效的计算程序，以处理大规模数据集。
### Conclusion
本文通过实证测试展示了所提方法的优越性，该方法能够有效地测试形状约束，并适用于大规模数据集。
## 1027. `cs.LG` - 面向浮点神经网络的非确定性感知乐观验证 [PDF](https://arxiv.org/pdf/2510.16028), [HTML](https://arxiv.org/abs/2510.16028)
### Authors
Jianzhu Yao,Hongxu Su,Taobo Liao,Zerui Cheng,Huan Zhang,Xuechao Wang,Pramod Viswanath
### Background
随着神经网络越来越多地运行在用户无法控制的硬件上（如云GPU、推断市场），机器学习即服务（MLaaS）并未完全保证实际执行的内容或返回输出与预期输入的一致性。用户在服务降级时缺乏出路，例如模型更换、量化、图重写或类似广告嵌入这样的差异。浮点（FP）执行在异构加速器上的非确定性使得验证输出变得难度增加。现有方法要么不适用于实际的FP神经网络，要么恢复了对供应商的信任。
### Innovation
我们提出了NAO：一种非确定性感知的乐观验证协议，它接受在考虑了运算器级接受区域内的输出，而不是需要位级等同。NAO结合了两个误差模型：（i）具有约束的每运算器IEEE-754最坏情况界限和（ii）基于硬件校准的紧实的经验分位数配置文件。偏差触发梅克尔锚定的、阈值导向的纠纷游戏，递归地将计算图分割到最后一个运算器，在那里裁决归结为一个轻量级的理论界限检查或小额诚实多数投票来反对经验阈值。没有被挑战的结果在挑战窗口后最终确定，无需信任硬件或确定性内核。我们实现了NAO作为PyTorch兼容的运行时环境和当前部署在Ethereum Holesky测试网上的合约层。
### Conclusion
NAO成功地将可扩展性与现实世界的异构机器学习计算的验证性相结合，实验结果显示在A100、H100、RTX6000和RTX4090上，经验阈值比理论界限紧实了100-1000倍，而具有界限感知的对抗性攻击未能成功。
## 1028. `cs.LG` - TeLLMe v2: 一种基于表查找的边沿FPGA高效三值LLM预填充和解码加速器 [PDF](https://arxiv.org/pdf/2510.15926), [HTML](https://arxiv.org/abs/2510.15926)
### Authors
Ye Qiao,Zhiheng Chen,Yifan Zhang,Yian Wang,Sitao Huang
### Background
随着可穿戴设备和其他嵌入式系统的出现，将大型语言模型（LLMs）部署到边缘平台变得迫切需要。然而，这由于其高计算和内存需求而具有挑战性。尽管最近的低位量化方法（例如BitNet、DeepSeek）将权重压缩到低至1.58~位，并且最小化了准确性的损失，但边缘部署仍然受到有限的片上资源、功耗预算以及预填充阶段经常被忽视的长时间延迟的限制。
### Innovation
我们提出了TeLLMe，一种基于表查找的三值LLM加速器，用于低功耗边缘FPGA，支持填充前和自回归解码，并使用1.58位权重和8位激活。TeLLMe 包含多种创新技术，包括：(1) 基于表查找的三值矩阵乘法（TLMM）引擎利用分组激活和在线预计算，以实现低资源消耗和高吞吐量；(2) 细粒度的分析URAM 基础权重缓冲管理方案，用于高效加载和计算引擎访问；(3) 一种流水线数据流架构，将浮点元素操作与线性计算融合，以隐藏延迟；(4) 一种逆序重新排序预填充阶段注意力操作，结合融合注意力操作，以实现高内存效率；(5) 一种资源高效的专门解码阶段注意力。
### Conclusion
在5瓦的功耗预算下，TeLLMe 可实现高达25个令牌/s的解码吞吐量和0.45 至 0.96秒的首个令牌时间（TTFT），对于64至128令牌提示，代表了边沿FPGA上LLM推理的能效显著提升。
## 1029. `cs.LG` - 从评论到可操作的洞察：基于LLM的方法论用于属性和特征提取 [PDF](https://arxiv.org/pdf/2510.16551), [HTML](https://arxiv.org/abs/2510.16551)
### Authors
Khaled Boughanmi,Kamel Jedidi,Nour Jedidi
### Background
本研究提出了一种系统化的大型语言模型（LLM）方法，用于从客户评论中提取产品和服务的属性、功能及其相关情感。该研究基于营销理论，将感知属性与可操作功能区分开来，产生了可解释和管理上实际有用的洞见。研究团队分别应用该方法论分析了20,000条Yelp上关于星巴克门店的评论，并对随机抽取的评论样本评估了八个提示变体。性能评估包括与人类标注的一致性和预测准确性的评价。结果显示，LLM和人类注释人员之间的结果高度一致，预测有效性也非常强，证实了该方法的可靠性。人类标注员完成每条评论平均需要6分钟，而LLM可以在两秒内处理每个评论，提供了可规模化且相媲美于人工编码的效果。
### Innovation
提出了一种基于LLM的方法论，用于从客户评论中系统地提取产品和服务的属性、功能及其相关情感。与传统的人工编码相比，该方法可以在极短时间内提供可比较的洞见，适用于大规模数据分析。通过这种方法，企业可以识别出最影响客户满意度的属性和功能及其相关情感，从而针对“快乐点”和“痛点”进行定制干预，设计有目标的举措。此外，该研究展示了结构化评论数据可以用于推动可操作的市场营销仪表板，该仪表板能够随时间跟踪情感，并在门店之间进行基准测试，突出需要改进的关键功能特点。模拟结果显示，优化关键服务功能的情感可带来1-2%的平均收入增长。
### Conclusion
本研究利用LLM从20,000条Yelp评论中提取出星巴克门店的属性和功能，并通过与人类标注的对比证明了高一致性和强大的预测准确性。LSTM在解决营销和产品开发方面提供了高效且可扩展的途径，能够帮助公司识别关键属性和功能，以提升客户满意度，提高业绩。
## 1030. `cs.LG` - 在智能代理系统时代的灾害管理：增强韧性的共同人类-机器智能愿景 [PDF](https://arxiv.org/pdf/2510.16034), [HTML](https://arxiv.org/abs/2510.16034)
### Authors
Bo Li,Junwei Ma,Kai Yin,Yiming Xiao,Chia-Wei Hsu,Ali Mostafavi
### Background
灾害的频率和严重性日益提高，传统应对能力经常不堪重负，暴露出灾害管理中的关键脆弱性。现行做法因数据流碎片化、技术孤岛、资源限制以及机构记忆的流失，阻碍了及时和有效的决策制定。本文介绍了Disaster Copilot，一种旨在通过统一专门的AI工具在一个协作框架内来克服这些系统性挑战的多代理人工智能系统的愿景。
### Innovation
提出了一种利用中心协调器协调多样化子代理的架构，每个子代理专精于关键领域如预测风险分析、情况感知和影响评估。通过集成多模态数据，该系统提供了一个全面的实时操作图景，并作为推进灾害数字双胞胎从被动模型到积极、智能环境的关键AI支柱。此外，该系统可以通过设备内协调确保功能在资源受限环境中，并纳入机制以捕获机构知识，减轻员工轮换的影响。详述了系统架构，并提出了三个阶段的路线图，强调技术、组织能力和人类-机器团队的并行增长。
### Conclusion
Disaster Copilot 提供了变革性的愿景，促进了集体的人机智能，以构建更具适应性、数据驱动和韧性的社区。
## 1031. `cs.LG` - 在相关障碍场中的随机路径规划 [PDF](https://arxiv.org/pdf/2509.19559), [HTML](https://arxiv.org/abs/2509.19559)
### Authors
Li Zhou,Elvan Ceyhan
### Background
在现实世界中，导航环境通常包含不确定状态和相互关联的障碍物，传感器提供的读数也带有噪声，并且需要成本高的澄清过程。当前的导航方法往往忽略这些因素，或者在计算上过于复杂。该论文提出了一种新颖的方法来解决这些挑战，即Stochastic Correlated Obstacle Scene (SCOS)问题，针对这种具有空间相关性和不确定性障碍物的导航设置，提出了一个由两个阶段组成的全新学习框架，以及使用贝叶斯更新来优化路径选择，以应对这些复杂情况。
### Innovation
该论文提出了一种新的两阶段学习框架。首先，offline阶段通过乐观的策略迭代学习一个鲁棒的基础策略，并通过信息奖金激励在具有信息价值的区域进行探索；接着，在online阶段采用贝叶斯机制定期更新基础策略以适应新信息，并结合蒙特卡洛点估计法和分布化强化学习方法，以学习成本分布并量化不确定性。该框架能够有效地降低搜索空间，提高路径规划效率，同时应对环境中不确定性和障碍物的相关性问题，并且在不同障碍密度和传感器能力的环境中表现出一致的性能改进。
### Conclusion
该研究提出的SCOS问题及其两阶段学习框架为具有相关障碍物和不确定状态的复杂导航环境下的路径规划提供了解决方案。通过不断学习和优化策略，并且结合了蒙特卡洛点估计算法和分布化RL，该框架不仅能够提高效率，还能更准确地量化不确定性。实验结果表明，该框架在各种障碍环境和不同的传感器性能下，都比现有基准方法有显著的性能提升。特别是在充满敌对干扰或聚集自然灾害的环境中，该方法展现了极大的优势。
## 1032. `cs.SE` - AI交换单元 [PDF](https://arxiv.org/pdf/2510.17839), [HTML](https://arxiv.org/abs/2510.17839)
### Authors
Johannes Schneider,Rene Abraham
### Background
人工智能（AI）的快速集成改变了组织与AI驱动模型的互动方式，影响了运营绩效和战略创新。随着基础模型的出现，组织效能和适应性的关键在于建立结构化的AI模型交换平台。然而，目前仍缺乏对这些平台的全面分类和理解框架。
### Innovation
本文提供了一种结构化的方法来分类AI交换平台，研究关键维度和特征，并揭示了公共研究机构和组织之间的有趣互动模式。一些平台利用同行评审作为质量控制机制，并提供了在线测试、部署和模型定制的机制。本论文为寻求理解AI交换平台带来的挑战和机会的实际从业者提供了有益资源，并为学者进一步研究AI模型共享和利用的进化、影响和最佳实践提供了基础。
### Conclusion
研究提供了对AI在各行业角色演变的洞见，强调了平台设计中的适应性和创新的重要性。本文作为理解技术、商业模式和用户在快速增长的AI模型交换领域的动态互动的关键资源，并指出了潜在的未来演变方向。
## 1033. `cs.LG` - SimBench: Benchmarking the Ability of Large Language Models to Simulate Human Behaviors [PDF](https://arxiv.org/pdf/2510.17516), [HTML](https://arxiv.org/abs/2510.17516)
### Authors
Tiancheng Hu,Joachim Baumann,Lorenzo Lupo,Nigel Collier,Dirk Hovy,Paul Röttger
### Background
现有的大型语言模型（LLM）模拟人类行为的研究碎片化，缺乏标准化和可重复性。现有的评估基于定制的任务和度量标准，导致无法比较的结果。因此，需要一个统一的标准基准来系统评估LLM的模拟能力，从而推动更真实的LLM模拟研究的发展。
### Innovation
提出了SimBench，首个大规模、标准化的基准测试，通过统一20个涵盖道德决策到经济选择等任务的多元数据集，覆盖了全球广泛的参与者，提供了研究LLM模拟何时、如何、为何成功或失败的基础。研究指出，即使是目前最好的LLM在模拟能力上的得分也只有40.80/100，但性能随着模型规模的增加呈对数线性增长。增加推理时间的计算并未提高模拟性能。还发现指令调优与维持一致性（低熵）问题的性能之间存在正相关，但与解决多样化（高熵）问题的性能之间存在负相关。模型在模拟特定的人口群体时特别困难。研究表明，模拟能力与深层次、知识密集型推理（MMLU-Pro）之间存在最强的相关性。这些发现旨在通过使进展可测量来加速更真实的LLM模拟器的发展。
### Conclusion
尽管当前的LLM在模拟方面的能力有限，但仍发现随着模型规模的增加，性能有所提升。研究明确了指令调优和多样性问题模拟之间的权衡。还指出模拟能力高度依赖于深层次、知识密集型的推理，即更准确的知识和推理模型更容易模拟人类行为。这一工作通过提供一个可衡量的基准，加速了对更真实LLM模拟器的研究和发展。
## 1034. `cs.SE` - 智能合约形式化验证：系统文献综述 [PDF](https://arxiv.org/pdf/2510.17865), [HTML](https://arxiv.org/abs/2510.17865)
### Authors
Rene Davila,Everardo Barcenas,Rocio Aldeco-Perez
### Background
形式化验证是测试软件以确保其符合规范的过程。智能合约是直接将合约条款编写在代码中的自我执行合约。它们运行在区块链平台上，并在满足预定义条件时自动执行和强制执行协议条款。然而，智能合约作为软件模型，经常包含运行或规范上的明显错误。因此，本文对各种来源的相关工作进行了深入研究，旨在分析这些工作的规范、验证工具以及相关实验。
### Innovation
本文提出了一种基于描述逻辑的形式化验证方法，为智能合约的验证提供了新的视角和技术手段。
### Conclusion
本文通过对大量相关文献的系统性回顾，总结了智能合约形式化验证的研究现状，并提出了基于描述逻辑的方法作为新的验证手段，为未来智能合约的安全性和可靠性研究开辟了新的方向。
## 1035. `cs.SE` - 情感编码：迈向基于意图的语义驱动编程的新范式 [PDF](https://arxiv.org/pdf/2510.17842), [HTML](https://arxiv.org/abs/2510.17842)
### Authors
Vinay Bamil
### Background
近年来，大型语言模型的发展使得开发者能够通过与人工智能系统对话而非直接编写代码来生成软件。本文介绍了情感编码（vibe coding），这是一种新兴的人工智能原生编程范式，其中开发人员不仅指定高层次的功能意图，还提供描述所需的“情感”（语气、风格或情感共鸣）的定性描述。之后，智能代理将这些规格转换为可执行的软件。
### Innovation
本文正式定义了情感编码，并提出了一个参考架构，包括意图解析器、语义嵌入引擎、智能代码生成器和交互式反馈循环。此外，本文将情感编码与声明式、函数式和提示基于编程进行比较，讨论了其对软件工程、人机协同及负责任的人工智能实践的影响。同时，评估了其生产力提升和普惠效应，并审查了最近的研究，指出其在对齐、可重复性、偏见、可解释性、可维护性和安全性等方面的挑战。
### Conclusion
本文总结了情感编码的关键挑战，如对齐、可重复性、偏见、可解释性、可维护性和安全性，并指出了未来的方向和开放的研究问题。
## 1036. `cs.SE` - UniCode：生成高质量竞赛编程问题的框架 [PDF](https://arxiv.org/pdf/2510.17868), [HTML](https://arxiv.org/abs/2510.17868)
### Authors
Xinyue Zheng,Haowei Lin,Shaofei Cai,Zilong Zheng,Yitao Liang
### Background
当前的编程竞赛基准依赖于静态且由人类编写的问题，这导致了数据污染和扩展性有限的问题。因此，需要一种方法来解决这些问题，以提高问题质量和评估的可靠性。
### Innovation
引入了UniCode，这是一种新颖的框架，能够自动生成高质量的算法问题及抗污染测试案例。该框架利用大型语言模型（LLMs）通过三种策略系统地多样化问题：单一问题扩展、同类别融合和跨类别融合。框架的关键创新在于其基于压力的测试案例合成流水线，能够在不需要标准正确解决方案的情况下生成可靠的测试套件。它结合了暴力基础接地和共识验证机制来确保高正确性和覆盖率。
### Conclusion
通过构建包含492个问题的基准并评估19个先进大型语言模型，证明了UniCode框架的有效性。结果显示，UniCode具有很高的挑战性和区分度，最高得分模型o4-mini只能通过70.3%的问题。该框架为编程领域的动态评估数据集生成提供了可扩展且可靠的方法。
## 1037. `cs.SE` - TritonRL：训练LLMs以无需作弊地思考和编写Triton代码 [PDF](https://arxiv.org/pdf/2510.17891), [HTML](https://arxiv.org/abs/2510.17891)
### Authors
Jiin Woo,Shaowei Zhu,Allen Nie,Zhen Jia,Yida Wang,Youngsuk Park
### Background
伴随着大规模语言模型（LLMs）的迅速进化，对自动化、高性能系统内核的需求已成为加速开发和部署的关键推动因素。Triton内核生成面临独特挑战，比如数据稀缺性和不完整的评估标准，这使其容易受到奖励欺骗的影响。
### Innovation
TritonRL引入了一种专门为Triton内核生成定制的LLM，并结合了新颖的训练框架，使其能够实现鲁棒且自动的内核合成。该方法通过监督微调特定于Triton的知识和使用鲁棒且可验证的奖励以及层次化奖励分配进行强化学习（RL），有效解决了数据稀缺性和评估标准不完整的问题，同时通过细粒度验证和层次化奖励分解鲁棒地检测奖励欺骗，指导模型生成高质量的Triton内核。
### Conclusion
通过稳健和细粒度的评估，TritonRL在KernelBench实验中展示了最先进的正确性和加速效果，超越了所有其他特定于Triton的模型，强调了基于RL的训练范式的有效性。
## 1038. `cs.SE` - 使用后工具执行反思和RAG修复工具调用 [PDF](https://arxiv.org/pdf/2510.17874), [HTML](https://arxiv.org/abs/2510.17874)
### Authors
Jason Tsay,Zidane Wright,Gaodan Fang,Kiran Kate,Saurabh Jha,Yara Rizk
### Background
在使用如Python函数、REST API端点或像Kubernetes中kubectl这样的命令行工具时，工具调用往往会因为语法或语义上的原因失败。某些隐蔽的语义错误需要分析工具的响应后才能识别并解决。因此，研究提出了一种后工具执行反思组件，该组件结合了基于大型语言模型的反思和针对特定工具及其相关故障排除文档的检索增强生成（RAG），以修复该问题。该研究聚焦于使用kubectl命令行工具管理Kubernetes集群应用的场景。
### Innovation
该研究开发了一种使用后工具执行反思和RAG的系统，结合了大型语言模型反思和与特定工具相关的故障排除文档进行检索增强生成，旨在自动识别并修复工具调用所导致的错误。研究发现，这种基于RAG的反思可以提高命令执行成功率（通过率为55%），以及平均提高36%的用户查询回答准确性。与官方文档相比，故障排除文档将通过率平均提高了10%。
### Conclusion
研究通过大规模实证研究和小型手工评估，证明所提出的RAG基反思可以提高kubectl命令的执行成功率和用户查询的准确性。故障排除文档相比官方文档能显著提升通过率。
## 1039. `cs.SE` - A Systematic Literature Review of the Use of GenAI Assistants for Code Comprehension: Implications for Computing Education Research and Practice [PDF](https://arxiv.org/pdf/2510.17894), [HTML](https://arxiv.org/abs/2510.17894)
### Authors
Yunhan Qiao,Md Istiak Hossain Shihab,Christopher Hundhausen
### Background
编程人员越来越多地依赖生成式人工智能（GenAI）助手来开发代码解决方案，因此理解GenAI解决方案变得尤为重要。同时，GenAI工具被用来为程序员提供定制的代码解释，包括由GenAI和人类编写的代码。这给计算机教育带来了新的挑战和机遇，尤其是在代码理解方面。为了提供基于证据的教学建议，并确定未来的研究方向，该研究进行了系统文献综述，回顾了2022年至2024年间31项相关研究的方法和工具。
### Innovation
研究进行了系统文献综述，专注于31项关于GenAI增强代码理解的研究，识别方法并总结其实证评价效果。研究指出，尽管GenAI助手具有潜力，但它们常常提供不准确或模糊的解释，这给初学者程序员带来了困难，阻碍了他们利用GenAI辅助代码理解的能力。研究还分类了基于GenAI的方法和工具，并明确了其对计算机教育研究和实践的影响。
### Conclusion
研究结果对计算教育研究与实践具有重要意义，并指出了未来研究的方向，包括如何改善GenAI解释的清晰度，以及如何帮助初学者更好地使用GenAI来促进代码理解。
## 1040. `cs.LG` - Glyph: 通过视觉文本压缩扩展上下文窗口 [PDF](https://arxiv.org/pdf/2510.17800), [HTML](https://arxiv.org/abs/2510.17800)
### Authors
Jiale Cheng,Yusen Liu,Xinyu Zhang,Yulin Fei,Wenyi Hong,Ruiliang Lyu,Weihan Wang,Zhe Su,Xiaotao Gu,Xiao Liu,Yushi Bai,Jie Tang,Hongning Wang,Minlie Huang
### Background
大规模语言模型（LLMs）在文档理解、代码分析和多步推理等任务中越来越依赖长语境建模。然而，将上下文窗口扩展到百万令牌级别会带来巨大的计算和内存成本，限制了这类模型的实际应用。
### Innovation
本文提出了一种名为Glyph的新框架，通过将长文本渲染为图像并用视觉语言模型（VLMs）进行处理，从而大规模压缩文本输入并保留语义信息。此外，还设计了一种LLM驱动的遗传搜索方法，以平衡准确性和压缩比。实验表明，该方法在各种长语境基准测试中能够实现3-4倍的令牌压缩，同时保持与领先LLM（如Qwen3-8B）相当的准确性，压缩后的文本数据也适用于实际的多模态任务。
### Conclusion
通过视觉语言模型处理视觉渲染的文本数据，我们的方法能够在保持准确性的同时实现显著的缩放和压缩。这对于处理百万令牌级别的长语境任务尤为有益。
## 1041. `cs.SE` - SpecAgent: 一个推测性检索和预测代理以进行代码补全 [PDF](https://arxiv.org/pdf/2510.17925), [HTML](https://arxiv.org/abs/2510.17925)
### Authors
George Ma,Anurag Koul,Qi Chen,Yawen Wu,Sachit Kuhar,Yu Yu,Aritra Sengupta,Varun Kumar,Murali Krishna Ramanathan
### Background
大型语言模型在代码相关的任务上有出色表现，但在实际的软件仓库中却常常遇到困难，特别是一些特定项目中的API和跨文件依赖关系。检索增强方法在此情况下可以通过在推理时注入仓库上下文来缓解这些问题。然而，低推理时延预算会对检索质量和额外的时延产生不利影响，从而损害用户体验。
### Innovation
我们提出了一种名为SpecAgent的代理，通过在索引阶段主动探索仓库文件并构建推测性上下文，该上下文可以预见到每个文件中的未来编辑。这使得上下文计算能够在索引时异步进行，并且推测性的特性可以提高代码生成质量。此外，我们还提出了一个没有未来上下文泄露的合成基准，以更真实地评估该代理与其他基线的性能差异。实验表明，SpecAgent相对于最佳基线，绝对提高了9-11%（相对提高了48-58%）的性能，同时显著降低了推理时延。
### Conclusion
SpecAgent通过在索引阶段预先计算推测性上下文，并利用这种异步性来减轻时延问题，同时提高了代码生成的质量。我们还构建了一个生命周期内无泄漏的合成基准，以实现更公正的评估。实验结果显示，SpecAgent在性能上明显优于其他基线，且显著减少了推理时延。
## 1042. `cs.SE` - JunoBench: Python机器学习Jupyter笔记本中故障的基准数据集 [PDF](https://arxiv.org/pdf/2510.18013), [HTML](https://arxiv.org/abs/2510.18013)
### Authors
Yiran Wang,José Antonio Hernández López,Ulf Nilsson,Dániel Varró
### Background
Jupyter笔记本在机器学习(ML)原型开发中广泛使用，但很少有调试工具针对笔记本中的ML代码进行设计，可能是因为缺乏基准测试。针对这一问题，提出了JunoBench，这是首个基于实际故障的Python机器学习笔记本的基准数据集。
### Innovation
JunoBench包含111个精心挑选且可再现的公共Kaggle笔记本中的真实故障案例，每个故障案例都与一个可验证的修复方案配对，并涵盖流行机器学习库如TensorFlow/Keras、PyTorch、Scikit-learn、Pandas和NumPy，以及特定于笔记本的执行顺序问题。这些故障和修复可在统一执行环境中可靠地重复，从而简化了错误的检测、定位和修复，满足了笔记本式机器学习开发的交互性和迭代性。
### Conclusion
通过提供真实且具有代表性的故障案例和解决方案，JunoBench促进了针对笔记本式机器学习开发过程中特征的错误检测、定位和修复过程，有助于调测工具的设计和应用研究。
## 1043. `cs.SE` - 从图表到代码：多模态模型的分层基准 [PDF](https://arxiv.org/pdf/2510.17932), [HTML](https://arxiv.org/abs/2510.17932)
### Authors
Jiahao Tang,Henry Hengyuan Zhao,Lijian Wu,Yifei Tao,Dongxing Mao,Yang Wan,Jingru Tan,Min Zeng,Min Li,Alex Jinpeng Wang
### Background
随着大语言模型（尤其是多模态模型）的发展，对于这些模型理解和生成代码以及图表的能力的评估方法成为研究热点。现有评估方法大多缺乏系统性和层次性，难以反映实际应用中的复杂性。
### Innovation
该论文提出了一种新的基准——Chart2Code，专门用于评估多模态模型在理解图表和生成代码方面的能力。Chart2Code设计考虑用户需求，涵盖不同类型的图表和梯度递增的任务难度。该基准分为三个层次，分别是图表复现、图表编辑和长表格转换为图表，评价方面不仅考虑代码的正确性，还考虑展示出的图表质量。
### Conclusion
在进行实验测试后发现，即使是最先进的模型在编辑任务上的平均得分仍较低，这阐明了Chart2Code基准的挑战性。本研究旨在推动多模态推理的发展，并促进更 robust 和通用的多模态模型的研发。相关代码和数据可在Chart2Code获取。
## 1044. `cs.SE` - DIP-AI：AI创新项目的发现框架 [PDF](https://arxiv.org/pdf/2510.18017), [HTML](https://arxiv.org/abs/2510.18017)
### Authors
Mariana Crisostomo Martins,Lucas Elias Cardoso Rocha,Lucas Cordeiro Romao,Taciana Novo Kudo,Marcos Kalinowski,Renato de Freitas Bulcao-Neto
### Background
尽管人工智能（AI）系统的开发越来越成熟，但需求工程（RE）活动在这一新的数据密集型范式下仍面临挑战。我们发现，在AI创新项目中缺乏问题发现的支持。基于对相关文献的审查，我们提出并评估了DIP-AI（Discovery in Project-AI），一种专为引导此类项目早期探索设计的发现框架，以促进高质量交付和利益相关者满意度。
### Innovation
DIP-AI框架结合了ISO 12207、5338和设计思维元素，旨在支持AI创新项目的发现。我们通过一个行业-学术界合作（IAC）案例研究评估了DIP-AI，参与者在实际操作中应用了DIP-AI并在问题发现能力、接受度和改进建议方面提供了反馈。结果表明DIP-AI在促进AI项目的问题发现方面具有相关性和实用性。
### Conclusion
这项研究通过共享DIP-AI作为AI问题发现的框架，对学术界有所贡献。对于行业，我们讨论了该框架在实际IAC项目中开发AI创新项目的应用。
## 1045. `cs.SE` - 用于具有可解释AI的NFR分类的基准数据集和LLMs比较 [PDF](https://arxiv.org/pdf/2510.18096), [HTML](https://arxiv.org/abs/2510.18096)
### Authors
Esrat Ebtida Sakib,MD Ahnaf Akib,Md Muktadir Mazumder,Maliha Noushin Raida,Md. Mohsinul Kabir
### Background
非功能性需求（NFRs）决定了软件系统的整体质量和用户满意度。准确识别和分类NFRs是确保软件达到性能、可用性和可靠性的期望的关键。然而，手动从文档中识别NFRs是耗时且容易出错的，因此需要自动化解决方案。在实施任何自动化解决方案之前，需要一个坚实而全面的数据集。为此，从多个项目章程和开源软件文档中收集了NFRs，增强了现有NFR数据集的技术深度和可用性。通过使用广泛使用的大型语言模型（LLMs）对NFRs进行分类，促进了自动化。
### Innovation
通过对RoBERTa、CodeBERT、Gemma-2、Phi-3、Mistral-8B和Llama-3.1-8B等大型语言模型进行分类实验，并使用精度、召回率、F1分数和lime分数等评估指标进行比较，发现Gemma-2和Phi-3模型在NFRs分类中表现最佳。通过改进上下文基础，整合使模型更好地理解技术要素和用户需求，提高了对NFRs的分类准确性和解释性。
### Conclusion
研究构建了一个用于NFRs分类的基准数据集，并通过广泛使用的大型语言模型进行了比较。实验结果显示Gemma-2和Phi-3模型在NFRs分类方面的表现最佳，这些模型的准确性和解释性得到了显著提高。
## 1046. `cs.SE` - 确保ML驱动软件系统的稳健性：一项用户调查 [PDF](https://arxiv.org/pdf/2510.18292), [HTML](https://arxiv.org/abs/2510.18292)
### Authors
Hala Abdelkader,Mohamed Abdelrazek,Priya Rani,Rajesh Vasa,Jean-Guy Schneider
### Background
确保ML驱动软件系统的稳健性需要应对关键挑战，如无故障失败、离域数据和对抗性攻击。传统的软件工程实践依赖于预定义的逻辑，但对于依赖于数据和概率决策的ML组件来说是不够的。为了应对这些挑战，本文提出了ML-On-Rails协议，这是一个统一框架，旨在增强ML驱动系统的稳健性和可信度。
### Innovation
ML-On-Rails协议集成了一系列关键的安全措施，如离域数据检测、对抗性攻击检测、输入验证和可解释性。该协议还使用HTTP状态码来增强报告模型结果和错误的透明度。研究者进行了一项从业者调查，发现了系统的稳健性问题和现有解决方案的不足，突出了标准化协议如ML-On-Rails如何改进系统的稳健性。
### Conclusion
研究结果强调了ML系统工程师需要更多支持和资源的需求，并指出了未来改进提出协议的方向，即借助调查和实际应用中的见解来不断提高其有效性。
## 1047. `cs.SE` - 人类撰文，AI撰码：三项笔记本竞赛中比较GenAI的研究案例 [PDF](https://arxiv.org/pdf/2510.18430), [HTML](https://arxiv.org/abs/2510.18430)
### Authors
Tasha Settewong,Youmei Fan,Raula Gaikovina Kula,Kenichi Matsumoto
### Background
由于其独特的结合代码与文档的功能，计算笔记本成为了数据科学家和专业人士进行数据分析和分享结果的首选工具。面对新兴的生成式人工智能技术，在竞争环境中，区分人类编写和生成式人工智能编写的特色变得尤为重要。本文通过对25个代码与文档特征的人类获奖Kaggle笔记本的研究，探索了两者各自的优势，并进一步分析了人类编写与生成式人工智能编写的笔记本之间的区别。这项研究为探索如何在最大程度上利用生成式人工智能与人的合作奠定了基础，并提出了四个研究议程来进一步推动笔记本中人机协作的发展。
### Innovation
研究通过三种案例研究探索了人类编写和生成式人工智能编写的笔记本的独特优势，特别是人类编写者的详细文档和结构多样性。研究还发现，尽管生成式人工智能编写的代码质量较高，但人类编写的代码在结构复杂性和创新解决问题的方法上具有优势。为未来如何进一步开发生成式人工智能提供了研究议程。
### Conclusion
在笔记本竞赛中，生成式人工智能可以与人类更好地协作，这需要进一步研究如何利用生成式人工智能的功能来最大化人机合作的潜力。
## 1048. `cs.SE` - 当新遇到旧：回归测试对SWE问题解决的影响评估 [PDF](https://arxiv.org/pdf/2510.18270), [HTML](https://arxiv.org/abs/2510.18270)
### Authors
Yang Chen,Toufique Ahmed,Reyhaneh Jabbarvand,Martin Hirzel
### Background
在现实世界项目中，测试套件通常规模庞大并能实现高代码覆盖率，但仍然无法检测出所有bug。开源项目的未解决问题跟踪器中的问题数量表明了这一缺口。尽管回归测试通常旨在确保新版本中之前的功能得到保留，但它们也可以帮助解决当前版本的问题。具体来说，回归测试可以增强生成新报告问题的重现测试，并验证补丁是否对现有功能没有造成回退。
### Innovation
我们提出了TestPrune，这是一种完全自动化的技术，利用问题跟踪器报告并战略性地重用回归测试来支持漏洞的重现和补丁验证。TestPrune的一个关键贡献是其能够自动将回归测试套件精简到一个小型且高度相关的子集。由于以LLM为基础的调试技术的流行，这种精简是必要的，因为大型测试套件会超出上下文限制、引入噪声并增加推理成本。TestPrune可以轻松插入任何自动化漏洞修复管道中，从而在整体性能上实现互补改进。
### Conclusion
作为概念证明，我们展示了在Otter框架和Agentless框架上使用TestPrune能够分别在SWE-Bench Lite和SWE-Bench Verified基准测试中实现6.2%-9.0%的漏洞重现率相对增加以及9.4%-12.9%的问题解决率相对增加。相比之下，使用TestPrune的成本开销极小，仅为每个SWE-Bench实例0.02美元和0.05美元，分别使用GPT-4o和Claude-3.7-Sonnet模型。
## 1049. `cs.SE` - 实证漏洞概念在现实世界中的实用价值：一项全面研究 [PDF](https://arxiv.org/pdf/2510.18448), [HTML](https://arxiv.org/abs/2510.18448)
### Authors
Wenjing Dang,Kaixuan Li,Sen Chen,Zhenwei Zhuo,Lyuye Zhang,Zheli Liu
### Background
漏洞的概念证明（PoC）对于验证漏洞的存在、减少误报以及展示其安全威胁的重要程度至关重要。然而，围绕PoC的研究滞后于专注于漏洞数据的研究。这种差距可以归因于实际PoC的分散性、写作风格的多样性以及PoC复现的难度。为了弥补这一差距，本文首次进行了大规模的实证PoC研究，评估其报告的可用性、完整性和可复现性。
### Innovation
1. 收集了一个包含470,921个PoC及其报告的数据集，来自13个平台，这是迄今为止公开可用PoC的最广泛集合。2. 提出了一种细粒度的PoC报告完整性评估方法，结合了模式匹配技术与细调的BERT-NER模型，提取了PoC报告中的9个关键组成部分。3. 招募了8名参与者手动复现150个基于PoC报告的漏洞，分析PoC复现的有效性及其影响因素。
### Conclusion
研究发现，78.9%的CVE漏洞缺乏可用的PoC报告，现有的PoC报告通常缺少约30%的必要组件，导致使用可用PoC报告复现漏洞存在各种问题。最终，提出了实际可行的策略，以提高漏洞PoC的总体实用价值，强化软件安全。
## 1050. `cs.SE` - CodeRL+: 通过执行语义对齐的强化学习改进代码生成 [PDF](https://arxiv.org/pdf/2510.18471), [HTML](https://arxiv.org/abs/2510.18471)
### Authors
Xue Jiang,Yihong Dong,Mengyang Liu,Hongyi Deng,Tian Wang,Yongding Tao,Rongyu Cao,Binhua Li,Zhi Jin,Wenpin Jiao,Fei Huang,Yongbin Li,Ge Li
### Background
大型语言模型（LLMs）能够通过学习大量代码语料来高效地生成代码，但是在其训练文本模式和代码功能正确性（由形式执行语义规范）之间仍存在根本的语义差距。强化学习带有验证奖励（RLVR）方法试图通过执行测试案例的结果奖励来弥合这一差距。然而，仅仅依赖于通过测试案例的二元通过/失败信号来建立代码文本表示与执行语义之间的良好对齐是低效的，尤其是对于代码中的微妙逻辑错误。
### Innovation
本文提出了CodeRL+，一个将执行语义对齐整合到RLVR训练管道中的新型方法。CodeRL+允许模型推断变量级别的执行轨迹，直接提供执行语义的训练信号。CodeRL+能够直接利用现有的在线策略滚动生成执行语义对齐，并且可以无缝集成到各种RL算法中。通过广泛的实验表明，CodeRL+在多个基准测试中均优于后训练基线（包括RLVR和Distillation），实现了平均1.6%的相对提升。
### Conclusion
CodeRL+不仅有效推广到其他编程任务，分别提高了代码推理和测试输出生成基准的准确率15.5%和4.4%。此外，CodeRL+在各种RL算法和LLMs中的广泛应用潜力也得到了证实，探针分析提供了有力的证据表明，CodeRL+增强了代码文本表示与其底层执行语义之间的对齐。
## 1051. `cs.SE` - 大型语言模型在主题分析中的应用：提示工程、评估及定性软件工程研究指南 [PDF](https://arxiv.org/pdf/2510.18456), [HTML](https://arxiv.org/abs/2510.18456)
### Authors
Cristina Martinez Montes,Robert Feldt,Cristina Miguel Martos,Sofia Ouhbi,Shweta Premanandan,Daniel Graziotin
### Background
随着人工智能的发展，大型语言模型（LLMs）正在进入定性研究的工作流程，但至今尚无可重复的方法将其整合到如主题分析（TA）等传统的定性方法中，特别是在软件工程研究领域，TA是最常见的一种定性方法。现有的研究缺乏对LLM生成的定性输出进行系统评价的标准。
### Innovation
该研究通过迭代设计和优化布雷恩和克拉克的反思性TA各阶段的提示，测试了多个LLM生成的输出，并与经验研究人员生成的代码和主题进行了对比。研究者使用15次有关软件工程师福祉的访谈数据作为基础，通过四位专家盲评估，确立了评估框架。研究贡献主要有三个方面：一是提供了一种可重复的方法，结合优化后的提示与评估框架，实现布雷恩和克拉克的反思性TA的操作化；二是进行了LLM生成的代码和主题与人类生成的代码和主题的实证比较；三是提供了关于如何整合LLMs到定性分析中并保持方法论严谨性的指南。
### Conclusion
研究发现LLM生成的代码有61%的时间被专家偏好，且对回答研究问题具有分析上的有用性，但同时也存在不足，例如无谓地分割数据，遗漏潜在解释，以及有时生成边界的不清晰主题。研究为未来在软件工程中的定性分析中如何有效且基于方法论严谨性地使用LLMs提供了指导框架。
## 1052. `cs.SE` - 挖掘服务行为以实现状态化服务仿真 [PDF](https://arxiv.org/pdf/2510.18519), [HTML](https://arxiv.org/abs/2510.18519)
### Authors
Md Arafat Hossain,Jun Han,Muhammad Ashad Kabir,Steve Versteeg,Jean-Guy Schneider,Jiaojiao Jiang
### Background
企业软件系统正在不断整合多种服务以满足日益增长的业务需求。这导致测试高度集成的系统变得具有挑战性，因为需要访问这些连接的服务。服务虚拟化作为一种从记录的交互中提取服务模型的技术，被广泛用于生成系统测试期间的服务响应。虽然提出了多种方法来根据这些交互模拟实际服务行为，但大多数方法未能考虑服务状态，这降低了服务仿真的准确性以及测试环境的现实性，尤其是在处理状态化服务时作用有限。现有的方法无法准确地模拟状态化服务的行为，因此需要一个更准确的方法来生成服务响应
### Innovation
该论文提出了一种从服务交互中提取服务模型的方法，通过考虑服务状态来提高响应生成的准确性，这通过揭示交互消息之间的上下文依赖关系和分析消息数据值之间的关系来实现。这种方法使用来自状态化和服务无状态服务的交互痕迹进行评估，结果表明在服务响应生成方面比现有方法在准确性和效率上都有显著增强
### Conclusion
研究提出的方法通过考虑服务状态，能够更准确地模拟和生成服务响应，从而极大地提高了服务仿真的准确性和效率，特别是在处理状态化服务时尤其有效。
## 1053. `cs.SE` - InspectCoder：通过交互式LLM-调试器协作实现动态分析驱动的自我修复 [PDF](https://arxiv.org/pdf/2510.18327), [HTML](https://arxiv.org/abs/2510.18327)
### Authors
Yunkun Wang,Yue Zhang,Guochang Li,Chen Zhi,Binhua Li,Fei Huang,Yongbin Li,Shuiguang Deng
### Background
大型语言模型（LLMs）常常生成包含复杂逻辑错误的代码，这些错误难以诊断。现有的基于LLM的自我修复方法要么进行详细的静态语义分析，要么依赖浅层执行日志，但它们往往会错过能够揭示错误根本原因的深层次运行时行为，缺乏人类调试的有效互动动态分析能力。为此，该论文介绍了一个新的系统——InspectCoder，它是第一个具备将LLM赋能于通过交互式调试器控制进行动态分析的自修复系统。InspectCoder能够在状态化调试会话中实现策略性断点设置、针对性状态检查和增量运行时试验，不受限于传统的固定日志收集方法，其能够根据来自调试器回传的即时过程奖励，引导多步推理，从而将LLM调试从盲目的尝试与错误转变为系统的根本原因诊断。研究在BigCodeBench-R和LiveCodeBench-R两个挑战性的自修复基准测试上进行了全面实验，InspectCoder的修复准确率相较于最强基线提升了5.10%-60.37%，且修复效率分别提高了1.67-2.24倍。同时，InspectWare作为一个开源中间件，简化了调试器的复杂性，支持主流Python测试框架中的状态化调试会话。这些研究为交互式LLM-调试器系统的实际操作提供了深刻见解，展示了LLM驱动的动态分析在自动化软件工程中的巨大潜力。
### Innovation
InspectCoder是第一个使得大型语言模型能够在交互式调试器控制下进行动态分析的自修复系统。它通过策略性断点设置、针对性状态检查和增量运行时试验，在状态化调试会话中赋能LLM，将其调试方式从盲目的尝试与错误转变为系统的根本原因诊断。此外，InspectCoder能够根据调试器回传的即时过程奖励，指导多步推理。InspectWare作为一个开源中间件，可以简化调试器的复杂性，并跨主流Python测试框架维持状态化调试会话。这些创新显著提升了自修复能力和调试效率，展示了LLM驱动的动态分析在自动化软件工程中的巨大潜力。
### Conclusion
InspectCoder在两个挑战性的自修复基准测试中取得了显著的修复准确率和修复效率提升，表明交互式自助修复系统能够有效诊断错误的根因，而LLM驱动的动态分析为自动化软件工程提供了巨大潜力。InspectWare作为开源中间件，进一步简化了调试器的复杂性，并支持状态化调试会话，为未来的交互式LLM-调试器系统研究奠定了基础。
## 1054. `cs.SE` - 当抽象违反物理规律：重新思考量子软件中的模块化设计 [PDF](https://arxiv.org/pdf/2510.18557), [HTML](https://arxiv.org/abs/2510.18557)
### Authors
Jianjun Zhao
### Background
在经典软件工程中，抽象是一个基本原则，它能够实现模块化、可重用性和可扩展性。然而，量子程序遵循的是不同的语义，如幺正性、缠结、不允许复制定理和测量的破坏性，这些特性给传统的抽象机制在量子计算中的安全使用带来了挑战。
### Innovation
本文识别出了量子软件工程中的根本性冲突：在量子计算的物理约束条件下，看似语法正确的抽象实践可能违反了物理原理。作者提出了三种抽象失败案例，指出经典抽象在量子语境下的不足，并提出了物理上合理的抽象机制的设计原则。此外，本文还提出了针对量子特有的类型系统、效果注释和基于契约的模块化设计的研究方向。
### Conclusion
本文旨在基于量子语义对量子软件工程中的抽象进行全面的重新思考，考虑工程上的可扩展性，从而发起一个系统的重新评价过程。
## 1055. `cs.SE` - BlueCodeAgent：基于自动红队技术的代码生成AI蓝队代理 [PDF](https://arxiv.org/pdf/2510.18131), [HTML](https://arxiv.org/abs/2510.18131)
### Authors
Chengquan Guo,Yuzhou Nie,Chulin Xie,Zinan Lin,Wenbo Guo,Bo Li
### Background
随着大型语言模型（LLMs）在代码生成中的应用越来越多，对安全风险的担忧也在显著增加。早期的研究主要集中在红队操作，旨在发现和评估代码生成模型的漏洞和风险。然而，蓝队技术方面的发展仍然有限，因为开发防御需要有效的语义理解，以区分安全与不安全的内容。为了填补这一空白，我们提出了BlueCodeAgent，这是一种由自动红队技术支持的蓝队代理。我们的框架将两方面结合在一起：红队生成多样化的风险实例，蓝队代理利用这些实例通过构成交析和代码分析来检测已知和未知的风险场景，实现多层次防御。我们的评估结果显示，蓝队Agent在三个代表性的代码相关任务——偏见指令检测、恶意指令检测和漏洞代码检测——中，相对于基线模型和基于安全提示的防御，取得了显著的改进。特别是在漏洞代码检测任务中，蓝队Agent通过整合动态分析有效减少了假阳性，这是基础模型往往过于保守，错误地将安全代码分类为不安全代码的难题。总体而言，蓝队Agent在四个数据集上的三任务中平均提高了12.7%的F1分数，归功于其总结行动指令的能力，增强了上下文感知风险检测。我们已经证明了红队如何通过不断识别新漏洞来增强蓝队的防御性能。
### Innovation
提出了BlueCodeAgent，这是一种由自动红队技术支持的蓝队代理。该框架通过整合红队生成的风险实例，结合构成交析和代码分析，增强了上下文感知风险检测。与基线模型和基于安全提示的防御相比，BlueCodeAgent在三个代表性的代码相关任务中取得了显著的改进，特别是在漏洞代码检测中，通过整合动态分析有效减少了假阳性情况。
### Conclusion
蓝队Agent通过整合红队生成的风险实例和构成交析与代码分析，显著提高了代码生成任务中的风险检测能力。特别在漏洞代码检测任务中，通过动态分析有效减少了假阳性，表现出更高的准确性。蓝队Agent在四个数据集上的三任务中平均提高了12.7%的F1分数，证明了其综合作用的有效性，同时也展示了红队如何不断识别新漏洞来提升蓝队的防御性能。
## 1056. `cs.SE` - 低代码平台选择的结构化评估框架：面向企业数字化转型的多准则决策模型 [PDF](https://arxiv.org/pdf/2510.18590), [HTML](https://arxiv.org/abs/2510.18590)
### Authors
Antonio Lamanna
### Background
低代码开发平台（LCDPs）的快速采用为组织提出了基于系统性评价方法的关键需求，以便做出明智的平台选择决策。本文基于五个关键标准提出了一个全面的评估框架：业务流程编排、UI/UX自定义、集成与互操作性、治理与安全、以及增强型自动化。该框架弥补了市场驱动的平台比较与严格、上下文特定的评价方法之间的差距。通过在企业环境中的实证验证，本文展示了这种结构化方法如何显著改善决策结果并降低平台锁定或不恰当解决方案选择的风险。
### Innovation
提出了一个基于五个关键标准的全面评估框架，该框架包括业务流程编排、UI/UX自定义、集成与互操作性、治理与安全、以及增强型自动化。本文还提出了一种加权评分模型，帮助企业根据其特定需求和战略优先级对不同低代码平台进行量化评估和比较。
### Conclusion
通过企业环境中的实证验证，该结构化方法不仅显著改善了决策结果，还降低了平台锁定或不适当的解决方案选择风险，从而为企业数字化转型提供了有效工具。
## 1057. `cs.SE` - 对于敏捷软件开发相关的非传统融资和合同方法的概览：基于现实经验的系统性审查 [PDF](https://arxiv.org/pdf/2510.18711), [HTML](https://arxiv.org/abs/2510.18711)
### Authors
Bertha Ngereja,Magne Jørgensen
### Background
敏捷软件开发强调灵活性和迭代过程，这与传统的线性、僵化和耗时的融资和合同方法存在冲突。本研究通过系统文献综述，汇总了使用非传统合同和融资方法的现实经验，旨在识别与敏捷原则更契合的方法，并理解这些替代方法背后的动机、好处和挑战。
### Innovation
研究基于SCOPUS、Web of Science和Google Scholar进行了系统文献综述，确定了38篇与私营和公共部门相关的相关实证研究，识别了四种替代合同和四种替代融资方法。研究发现，组织倾向于采用这些替代方法的原因包括传统方法过于僵化，与敏捷原则相冲突，妨碍有效的客户-供应商合作，并限制盈利能力。这些替代方法的好处包括客户满意度提高、减少承包商风险以及更高效的资源配置。
### Conclusion
采用非传统合同和融资方法可以在敏捷项目中促进灵活性和效率，但也存在文化与结构挑战，增加范围蔓延和分析瘫痪的风险，并需要额外的时间和资源投入。组织的选择取决于其文化、领导力、人员和系统准备程度等因素，因此建议从混合模式开始，逐步过渡到完全灵活的方法以满足特定需求。
## 1058. `cs.SE` - WebDevJudge: 评估(M)LLMs在网站开发质量方面的批评能力 [PDF](https://arxiv.org/pdf/2510.18560), [HTML](https://arxiv.org/abs/2510.18560)
### Authors
Chunyang Li,Yilun Zheng,Xinting Huang,Tianqing Fang,Jiahao Xu,Yangqiu Song,Lihui Chen,Han Hu
### Background
LLM-as-a-judge作为一种可扩展且高效的人类评价替代方案正在兴起，表现出在明确任务上强大的性能。然而，它在具有动态环境和复杂交互的开放式任务中的可靠性尚未得到研究。WebDevJudge旨在弥补这一差距，提供了一个系统性的基准，用于评估LLM-as-a-judge在网页开发中的性能，支持基于静态观察的非交互式评估和基于动态网页环境的持续交互式评估。该基准通过人工偏好标签对网页实现进行注解，附带结构化的和查询指导的评判标准，以确保高质量的真实性数据。使用该基准，全面评估了各种评估者，包括LLMs、MLLMs和代理工作流程，并系统性地研究了不同方法和指导机制的影响。实验表明，LLM裁判与人类专家之间存在显著差距。深入分析表明，这种差距源于模型的基本限制，包括功能等价性识别故障、任务可行性验证不充分及偏见缓解不足。总体而言，WebDevJudge对LLM-as-a-judge提出了重大挑战，提供了对未来研究的指导，以开发更可靠和有能力的自动化评估器应对复杂场景。
### Innovation
介绍了WebDevJudge，这是一个系统性的基准，用于评估LLM-as-a-judge在网页开发中的性能，支持非交互式评估和基于动态网页环境的持续交互式评估。该基准提供了一种全新方法，通过人工偏好标签和结构化及查询指导的评判标准确保模拟结果的真实性。它还全面评估了评估者，包括LLMs、MLLMs和代理工作流程，并系统性地研究了不同方法和指导机制的影响，揭示了LLM评估者与人类专家之间的显著性能差异及其根本原因。
### Conclusion
WebDevJudge为LLM-as-a-judge提出了一个重大挑战，表明未来研究需要解决模型的基本限制，以进一步提高在复杂的网页开发场景中的可靠性与能力。已公开的代码和数据为研究提供了重要资源。
## 1059. `cs.SE` - CUARewardBench：计算机使用代理的奖励模型评估基准 [PDF](https://arxiv.org/pdf/2510.18596), [HTML](https://arxiv.org/abs/2510.18596)
### Authors
Haojia Lin,Xiaoyu Tan,Yulei Qin,Zihan Xu,Yuchen Shi,Zongyi Li,Gang Li,Shaofei Cai,Siqi Cai,Chaoyou Fu,Ke Li,Xing Sun
### Background
计算机使用代理（CUAs）能够通过与操作系统和软件界面的自然交互完成任务。现有的基于脚本的验证器普遍存在可扩展性受限和无法提供逐步评估的问题。尽管奖励模型提供了替代方案，但它们在CUA评估中的有效性和潜力仍然相对较弱，有待进一步探索和开发。
### Innovation
本文提出了CUARewardBench，其四个关键贡献包括：（1）首个综合全面的CUA奖励基准，涵盖了结果奖励模型（ORM）和过程奖励模型（PRM）的评估；（2）包含广泛软件类别和不同性能级别的多样、实用且可靠的基准数据集；（3）在多模态视觉语言模型及定制提示模板的广泛实验基础上揭示并分析了现有CUA奖励模型的关键限制与亮点；（4）基于上述深度分析提出了一种新颖的一致提示集合（UPE）方法，大幅提升了奖励模型的可靠性。
### Conclusion
通过实验结果，CUARewardBench证明了UPE方法在ORM和PRM评估中分别取得了89.8%和93.3%的高精度及93.3%和85.1%的高NPV值，显著优于单一的多模态视觉语言模型和传统集成模型。
## 1060. `cs.SE` - 因果扰动公平性测试 [PDF](https://arxiv.org/pdf/2510.18719), [HTML](https://arxiv.org/abs/2510.18719)
### Authors
Chengwen Du,Tao Chen
### Background
为了减轻对敏感特征（如性别、年龄或种族）存在不公平和不道德的歧视，公平性测试在运用AI模型处理表格数据的工程系统中发挥了关键作用。当前的一大挑战是，在不可计算的样本量下如何有效揭示公平性漏洞，现有的工作主要集中在设计测试样本生成器上，而忽视了关于数据特征有价值的指导线索，限制了其全部潜力。本文的研究背景是为了填补这一空白，提出了一个因果扰动公平性测试的通用框架——CausalFT，旨在通过因果推理来引导测试样本生成，从而有效揭示公平性漏洞，相对于现有的工作，CausalFT是一种更高层次的框架，可以与多种基生成器配对使用。
### Innovation
本文提出的CausalFT框架通过因果推理提取对敏感特征具有直接因果相关性的非敏感特征，然后将其因果关系注入扰动中，以指导测试样本生成器。相较于现有工作，CausalFT能够与多种基生成器配对使用，广泛验证其对公平性漏洞揭示的显著改善能力，尤其是在效率和偏好稳健性方面具有的优越性。CausalFT在所有测试病例中显著优于基于相关性排序的方法，同时效率更高。
### Conclusion
CausalFT通过借助因果推理，能够显著改善各种基生成器的公平性测试性能，在93%的情况下都可以有效揭示公平性漏洞，并且相较于基于相关性排序的方法，在64%的情况下表现更优，同时更为高效。CausalFT还能更好地提高偏见抵抗力，几乎在所有案例中都表现突出。
## 1061. `cs.SE` - 通过大型语言模型简化移动应用程序的验收测试生成：一个工业案例研究 [PDF](https://arxiv.org/pdf/2510.18861), [HTML](https://arxiv.org/abs/2510.18861)
### Authors
Pedro Luís Fonseca,Bruno Lima,João Pascoal Faria
### Background
移动接受测试在现代软件开发中仍然是一个瓶颈，特别是在使用Flutter等框架进行跨平台移动开发时，尽管开发人员越来越多地依赖自动化测试工具，但创建和维护接受测试素材仍然需要大量的手动努力。
### Innovation
本引入了AToMIC，这是一个自动化的框架，利用专门的大型语言模型从需求（JIRA票）和最近的代码更改中生成Gherkin场景、页面对象和可执行UI测试脚本。AToMIC在宝马MyBMW应用中应用成功，覆盖了一个170+屏幕代码库中的13个真实世界问题，仅在五分钟内生产了可执行的测试素材，而且生成的素材质量很高。
### Conclusion
研究结果证实，AToMIC是一个可扩展且实用的解决方案，可用于简化工业移动项目中的验收测试创建和维护。所有参与者都报告了节省时间（通常是每个特性一天的开发者时间）和强烈信心，采用这种方法。
## 1062. `cs.SE` - VAPU：自主的遗留代码现代化系统 [PDF](https://arxiv.org/pdf/2510.18509), [HTML](https://arxiv.org/abs/2510.18509)
### Authors
Valtteri Ala-Salmi,Zeeshan Rasheed,Abdul Malik Sami,Muhammad Waseem,Kai-Kristian Kemell,Jussi Rasku,Mika Saari,Pekka Abrahamsson
### Background
本文探讨了一个现代化遗留应用的解决方案，特别是通过基于大语言模型（LLM）的多智能体系统来处理复杂的多阶段任务。由于遗留应用通常包含已弃用的组件，这导致了兼容性、安全性和可靠性的风险，但高昂的资源成本使公司犹豫不决，不愿更新。为了解决这一问题，本文提出了一种名为验证代理管道更新器（VAPU）的多智能体系统，旨在通过模拟软件开发团队中的不同角色来分阶段更新代码文件，提供一种低成本的自主更新遗留应用的方案。
### Innovation
本文的主要创新在于使用基于大语言模型的多智能体系统来构建一种分阶段更新遗留代码的方法，通过模拟软件开发团队中的不同角色来实现这一目标。同时，本文扩展了对VAPU的评估，包括使用五个不同的大语言模型以及温度参数，并与零样本学习和单样本学习进行了比较，展示了VAPU在满足要求方面的优势，特别是在低温条件下能够获得与零样本学习相似的错误数量，但同时满足更多需求，与基于零样本学习和单样本学习的提示相比，VAPU在处理Python文件更新时要求成功率达到最大增幅22.5%。
### Conclusion
研究表明，基于大语言模型的多智能体系统能够自主更新遗留应用的组件，不仅提高了更新的效率和准确性，还显著降低了更新成本。这表明多智能体系统是一种有效的解决方案，可以推广应用于其他需要分阶段处理的任务。
## 1063. `cs.SE` - ShaRE你的数据！LLM支持的软件需求工程中数据集的表征 [PDF](https://arxiv.org/pdf/2510.18787), [HTML](https://arxiv.org/abs/2510.18787)
### Authors
Quim Motger,Carlota Catot,Xavier Franch
### Background
大型语言模型依赖于特定领域的数据集以在训练和推断阶段实现稳定的性能。然而，在软件需求工程中，数据稀缺仍是一个持续存在的限制，屡次被调查和映射研究报道。尽管存在多个支持LLM的软件需求工程任务的数据集（LLM4RE），但是这些数据集是分散的，并且缺乏充分的描述，限制了其重用和可比性。本研究旨在解决LLM4RE研究中使用的数据集的不足和表征问题，具体研究哪些公开数据集被使用，如何系统地表征这些数据集，以及哪些软件需求工程任务和数据集描述仍被低估和不足。作为一个系统的映射研究，识别并分析了用于LLM4RE研究的数据集，这些数据集跨43篇主要研究共引用了62个公开可用的数据集。每个数据集都沿着诸如实体类型、粒度、软件需求工程阶段、任务、领域和语言等描述进行表征。初步发现包括：采掘任务的覆盖面有限、用于管理活动（超出可追溯性）的数据集稀缺，以及多语言的数据集有限。
### Innovation
本研究通过进行系统映射研究，识别并分析了用于LLM4RE研究的数据集，提供了一个公共的目录和结构化的表征方案，以支持在LLM4RE研究中的数据集选择、比较和重用。未来的工作将扩展到灰色文献，并与开放数据集和基准仓库进行整合。
### Conclusion
本研究提供了一个公共目录和结构化的表征方案，支持了LLM4RE研究中的数据集选择、比较和重用。此外，研究还发现了多个研究空白，包括采掘任务的不足和可用数据集的有限多样性。未来工作将寻求扩展研究范围，并与开放数据集和基准平台整合。
## 1064. `cs.SE` - 工业控制物理系统研究中的演示器：由软件密集设计驱动的要求层次结构 [PDF](https://arxiv.org/pdf/2510.18534), [HTML](https://arxiv.org/abs/2510.18534)
### Authors
Uraz Odyurt,Richard Loendersloot,Tiedo Tinga
### Background
研究项目组织中一个明显的挑战是关于演示器的主题不确定性。项目演示器所需覆盖的详细情况通常是在提案写作时被忽视的内容，导致在项目实施过程中产生了持续的混淆与目标与实际结果之间的不匹配。这种做法阻碍了项目的进展。同时，依赖技术成熟度等级（TRL）作为松散描述工具也无助于这一问题。因此，需要一种框架来评估目标演示的可行性，进行实际调整，并帮助描述需求。该框架应用于软件密集型系统和工业控制物理系统的应用领域。虽然全身验证需要在项目开始时应用该框架并在项目结束时观察结果，耗时4-5年，但其已经应用于两个研究项目的不同阶段，体现了其有效性。
### Innovation
本文提出了一个演示器需求详细化框架，通过评估目标演示的可行性、进行实际调整以及帮助描述需求，解决项目中因过度依赖TRL等级而导致的目标与实际结果的不匹配问题。该框架特别定义了5个层级的演示，与工作包交互和项目的工业用例直接关联，使之更加实用和基于预期。
### Conclusion
尽管进行整个验证的时间跨度较大，本文仍通过两个不同阶段的研究项目成功展示了该框架的有效性。该框架在软件密集型系统和工业控制物理系统的应用中提供了更为清晰和层级化的演示需求定义，显示出其在促进项目进展中的潜在价值。
## 1065. `cs.SE` - EffiReasonTrans: RL-优化的代码翻译中的推理优化 [PDF](https://arxiv.org/pdf/2510.18863), [HTML](https://arxiv.org/abs/2510.18863)
### Authors
Yanlin Wang,Rongyi Ou,Yanli Wang,Mingwei Liu,Jiachi Chen,Ensheng Shi,Xilin Liu,Yuchi Ma,Zibin Zheng
### Background
代码翻译是软件开发和维护中的关键任务。尽管大型语言模型（LLMs）的最近进展提高了自动代码翻译的准确性，但由于推理延迟的增加，这往往影响了人类实时参与检查的开发流程。为此，研究提出了一种名为EffiReasonTrans的新训练框架，旨在提高翻译准确性和推理延迟之间的平衡。
### Innovation
EffiReasonTrans框架通过构建一个高质量的推理增强数据集，采用两阶段训练策略（监督微调和强化学习）来优化推理译码。该框架能够在提高翻译准确性的同时减少生成的令牌数量，并在大多数情况下降低推理延迟。
### Conclusion
实验结果显示，EffiReasonTrans在翻译准确性、生成令牌数量和推理延迟方面都有显著改进。Ablation研究进一步证实了两阶段训练框架的互补益处。该方法还展示了在基于代理框架中集成时翻译准确性的进一步提高。相关代码和数据已公开提供。
## 1066. `cs.SE` - RiskTagger：一种基于LLM的自动标注Web3加密货币洗钱行为的代理 [PDF](https://arxiv.org/pdf/2510.17848), [HTML](https://arxiv.org/abs/2510.17848)
### Authors
Dan Lin,Yanli Ding,Weipeng Zou,Jiachi Chen,Xiapu Luo,Jiajing Wu,Zibin Zheng
### Background
随着Web3的快速发展，去中心化金融得到了发展，但由于用户匿名性和跨链资产流动性的增加，链上洗钱行为变得更加隐蔽和复杂。构建高质量的反洗钱（AML）数据集对于风险管理系统和链上法证分析变得至关重要，但目前仍主要依赖人工操作，效率和覆盖范围有限。
### Innovation
RiskTagger是一个基于大语言模型（LLM）的代理，用于自动标注Web3中的加密货币洗钱行为。它通过解决三个关键挑战来替代或补充人类标注员：从复杂的非结构化报告中提取线索、跨链交易路径的推理以及生成审计员友好的解释，从而形成了一个数据标注管道。
### Conclusion
RiskTagger在提取线索、与专家判断的一致性以及解释生成覆盖范围方面的实验显示，其准确率分别为100%、84.1%和90%，从而在自动化洗钱行为标注的同时提高了反洗钱研究中的透明度和可扩展性。
## 1067. `cs.SE` - GRETEL：一种基于目标的检索和执行试验框架，用于LLM工具选择的增强 [PDF](https://arxiv.org/pdf/2510.17843), [HTML](https://arxiv.org/abs/2510.17843)
### Authors
Zongze Wu,Yani Guo,Churong Liang,Runnan Li
### Background
尽管大型语言模型在能力方面取得了显著进步，基于代理系统的工具检索仍然受到依赖语义相似性的限制，这种依赖无法捕捉功能上的适用性。当前方法经常检索到在文本上相关但在功能上不活跃的工具，这通常是由于参数不匹配、身份验证失败和执行约束。我们称这种现象为语义-功能差距。
### Innovation
我们引入了GRETEL，通过系统性的实证验证来解决这一差距。GRETEL实现了一种基于代理的工作流，通过沙盒化的计划-执行-评估循环处理语义检索出的候选工具，从而生成执行基础的证据，以区分真正功能性的工具与仅仅是描述性匹配的工具。我们的全面评估表明，在多个指标上都有显著提升：通过率（在10中）从0.690提高到0.826，召回率（在10中）从0.841提高到0.867，NDCG（在10中）从0.807提高到0.857。这些结果表明，基于执行验证的基础比仅靠语义相似性更能可靠地支持工具选择，从而在现实世界应用中增强代理性能.
### Conclusion
基于执行验证提供了比仅依靠语义相似性更可靠的基础，使得工具选择更坚实，在真实的代理应用中表现出更稳健的性能。
## 1068. `cs.SE` - FeClustRE: 从用户评价中进行应用程序特征的层次聚类和语义标签化 [PDF](https://arxiv.org/pdf/2510.18799), [HTML](https://arxiv.org/abs/2510.18799)
### Authors
Max Tiessler,Quim Motger
### Background
从移动应用评论中提取特征对多个要求工程任务越来越重要，但现有方法难以将嘈杂和模糊的反馈转化为可解释的洞察。现有的方法通常缺乏语义深度，大型语言模型（LLMs）也常错过细微特征或结构不连贯。此外，现有方法输出未组织的特征列表，限制了其解释性和可比性，导致无法提供结构化的、有意义的应用程序特征表示。这使从业人员在需求分析、优先级设定和跨应用比较等方面面临信息碎片化的问题。
### Innovation
提出了FeClustRE框架，该框架结合了混合提取、层次聚类、自动调优和基于LLM的语义标签。该框架结合了句法解析和LLM增强，将特征组织成簇并自动生成有意义的分类标签。通过公共测试基准评估了提取的正确性，并通过对生成式AI助手应用评审样本的研究评估了聚类质量、语义连贯性和解释性。FeClustRE提供了（1）一种混合框架用于特征提取和分类标签生成、（2）自动调优机制及其全面评价方法、（3）开源和可复制的实现，这些贡献实现了用户反馈和特征理解的整合，为当前和新兴的需求提供了更深入的见解。
### Conclusion
FeClustRE通过集成混合特征提取、层次聚类、自动调优和基于LLM的语义标签，为应用评论中特征的理解提供了一种新型方法，解决了当前方法存在的问题，提升了特征提取的结构化和解释性，并提供了可重复的开源实现，使从业人员能够获得更清晰、更有用的需求信息。
## 1069. `cs.SE` - 当“正确”不安全时：我们能信任由代码代理生成的功能正确补丁吗？ [PDF](https://arxiv.org/pdf/2510.17862), [HTML](https://arxiv.org/abs/2510.17862)
### Authors
Yibo Peng,James Song,Lei Li,Xinyu Yang,Mihai Christodorescu,Ravi Mangal,Corina Pasareanu,Haizhong Zheng,Beidi Chen
### Background
现有的代码代理越来越多地被用来自动生成并独立修复代码中的错误。然而，目前对这些代理的安全性评估主要集中在功能正确性上，而忽略了潜在的安全威胁。本文发现了一种新型的安全威胁：功能性正确但存在漏洞（FCV）的补丁，这些补丁虽然通过了所有测试，但包含安全漏洞。研究人员通过一种名为FCV-Attack的方法展示了这种威胁的存在，并说明了SOTA语言模型（如ChatGPT和Claude）和代码代理框架（如SWE-agent和OpenHands）都容易受到这种威胁。这项研究揭示了当前评估标准中被忽视的重要安全威胁，也提醒开发人员关注代码代理的安全防护措施。
### Innovation
提出了FCV-Attack方法，可以针对不同代码代理系统的不同组合进行攻击，示例表明，这种攻击仅需一次与代码代理的查询即可实现，且在特定情况下的成功率较高。例如，对于CWE-538（信息泄露漏洞），GPT-5 Mini + OpenHands的攻击成功率达到了40.7%。这项创新展示了代码代理在生成功能正确补丁时也可能包含安全漏洞，并强调了这种威胁未被当前安全性评估框架充分考虑。
### Conclusion
现有评估方法未能有效检测出功能正确但存在潜在安全风险的补丁，这表明现有代码代理的安全性评估需要进一步改进。研究结果强调了在生成代码补丁时必须考虑安全性。未来需要开发更为安全的防御措施来保护代码代理，以应对这种新型威胁。
## 1070. `cs.SE` - Saber: 适用于扩散语言模型的高效具有自适应加速和回溯增强重构的采样方法 [PDF](https://arxiv.org/pdf/2510.18165), [HTML](https://arxiv.org/abs/2510.18165)
### Authors
Yihong Dong,Zhaoyu Ma,Xue Jiang,Zhiyuan Fan,Jiaru Qian,Yongmin Li,Jianha Xiao,Zhi Jin,Rongyu Cao,Binhua Li,Fei Huang,Yongbin Li,Ge Li
### Background
扩散语言模型（DLMs）作为一种新兴的技术，在语言生成任务中展现出强大的潜力，超越了传统的自回归模型。然而，在代码生成等更严格的结构约束任务中，DLMs的表现受限于生成速度和输出质量之间的关键权衡。单纯减少采样步骤通常会导致性能大幅下降。因此，目前需要一种能兼顾高效性和准确性的新型采样算法来改进DLMs在代码生成任务中的表现。
### Innovation
本文提出了一种名为Saber（Sampling with Adaptive acceleration and Backtracking Enhanced Remasking）的新型采样算法，专门为DLMs设计。Saber算法利用了DLM生成过程中的两个关键洞察：代码上下文建立过程中可以自适应加速；需要回溯机制来撤销生成的令牌。实验表明，与主流DLM采样方法相比，Saber在Pass@1准确率上有平均1.9%的提升，同时实现了251.4%的平均推理速度提升。通过利用DLM的固有优势，本工作显著缩小了与自回归模型在代码生成任务上的性能差距。
### Conclusion
本文提出了一种新的采样算法（Saber），该算法基于DLM生成过程的两个关键洞察来加速和优化代码生成过程，通过对比实验表明Saber在保持高质量输出的同时提高了推理速度，显著减小了与自回归模型在代码生成上的性能差距。
## 1071. `cs.SE` - 基于LLM的移动应用推荐评估：一项实证研究 [PDF](https://arxiv.org/pdf/2510.18364), [HTML](https://arxiv.org/abs/2510.18364)
### Authors
Quim Motger,Xavier Franch,Vincenzo Gervasi,Jordi Marco
### Background
大型语言模型（LLMs）越来越用于通过自然语言提示推荐移动应用，提供了一种灵活替代关键词基于的App Store搜索的方式。然而，这些推荐背后的推理仍然不透明，引发了关于其一致性的质疑，以及可解释性和传统App Store优化（ASO）指标的对齐问题。
### Innovation
（i）制定了16项通用排名标准的分类；（ii）提出了一种系统评估框架，用于分析推荐的一致性和对显式排名指令的响应；（iii）提供了一个可复制的包，以支持可重复性和未来基于AI的推荐系统研究的探索。
### Conclusion
研究发现，LLMs依赖于各种各样的排名标准，这些标准部分与标准ASO指标对齐。排名高的应用在多次运行中相对一致，但随着排名深度和搜索具体性的增加，可变性增加。LLMs在对显式排名指令的敏感性上表现出不同的适应性，从显著调整到几乎不变的输出，突显了它们在对话式应用程序发现中的复杂推理动态。研究结果旨在帮助最终用户、应用开发人员和推荐系统研究人员在新兴的对话式应用发现景观中导航。
## 1072. `cs.SE` - 评估大型语言模型在检测Android应用程序中密钥的能力 [PDF](https://arxiv.org/pdf/2510.18601), [HTML](https://arxiv.org/abs/2510.18601)
### Authors
Marco Alecci,Jordan Samhi,Tegawendé F. Bissyandé,Jacques Klein
### Background
移动应用程序经常嵌入认证密钥，如API密钥、令牌和客户端ID，以与云服务集成。然而，开发人员经常将这些凭证硬编码到Android应用程序中，使其通过反编译被提取，一旦被攻击者利用，这些密钥可以被用来访问敏感数据、操控资源或滥用API，这会带来严重的安全和经济损失。现有的检测方法，如基于正则表达式的分析、静态分析和机器学习，虽然能识别已知模式但有局限性：它们需要先验了解凭证结构、API签名或训练数据。
### Innovation
本文提出了一种基于LLM的方法，名为SecretLoc，用于检测Android应用程序中的硬编码密钥。SecretLoc超越了简单的模式匹配，通过利用上下文和结构性提示来识别密钥，无需依赖预定义的模式或标记训练集。实验表明，SecretLoc能够检测到正则表达式、静态分析和机器学习方法未能发现的密钥，包括尚未见过的新类型密钥。
### Conclusion
研究结果揭示了双重风险：如果分析师可以利用LLMs找出这些密钥，攻击者也可以这样做。这强调了在整个移动生态系统中进行积极的密钥管理和更强的缓解措施的迫切性。
## 1073. `cs.SE` - RESCUE：增强安全代码生成的检索增强 [PDF](https://arxiv.org/pdf/2510.18204), [HTML](https://arxiv.org/abs/2510.18204)
### Authors
Jiahao Shi,Tianyi Zhang
### Background
尽管大型语言模型（LLMs）取得了进展，但仍会生成脆弱的代码。检索增强生成（RAG）有望通过融合外部安全知识来提升LLMs的安全代码生成能力。然而，传统的RAG设计难以处理原始安全文档中的噪声，并且现有的检索方法忽视了任务描述中隐含的重要安全语义。
### Innovation
为解决这些挑战，本文提出了RESCUE，一个新的RAG框架，包含两个关键创新。首先，提出了一种混合知识库构建方法，结合了LLM辅助的聚类-摘要提炼与程序切片技术，生成高层次的安全指南和简洁、安全导向的代码示例。其次，设计了分级多层面检索，从顶层下层遍历构建的知识库，并在每个层级整合多个安全关键事实，确保全面和准确的检索。
### Conclusion
我们在四个基准上评估了RESCUE，并在其六个LLMs上与五种最先进的安全代码生成方法进行了比较。结果表明，RESCUE在SecurePass@1度量上平均提高了4.8个百分点，确立了新的安全性能基准。此外，我们进行了深入分析和消融研究，严格验证了RESCUE各个组件的有效性。
## 1074. `cs.SE` - AndroidControl-Curated: 通过基准净化揭示GUI代理的真正潜力 [PDF](https://arxiv.org/pdf/2510.18488), [HTML](https://arxiv.org/abs/2510.18488)
### Authors
Ho Fai Leung,Xiaoyan Xi,Fei Zuo
### Background
当前的虚拟助手（如Siri和Google Assistant）虽然越来越重要，但它们的能力受到了过度依赖于开发人员定义的API的限制。GUI代理作为一种无需依赖API的替代方案表现出强大潜力，但由于人们对它们性能较差的误解，其采用率受到了阻碍。现有的基准测试（如AndroidControl）即使是当前最好的模型（例如Qwen3-VL-235B）的得分也仅达到约60%，这表明它们离实际应用还很远。我们的研究发现，问题不仅在于模型本身，还在于基准测试本身存在明显缺陷，比如含糊不清和事实错误，这些缺陷系统性地低估了代理的性能。
### Innovation
我们通过严格的净化流程改进了AndroidControl，创建了AndroidControl-Curated版本，提升了一种净化后的基准测试。在这一增强后的基准测试上，最先进的模型在复杂任务上的成功率接近75%（提高了15%），表明设备上的GUI代理实际上比之前认为的更接近实际部署。我们还提出了一种新的最新模型Magma-R1-3B，并且仅通过2400个净化样本（60小时的H20 GPU时间，大约$60）进行微调后，其性能可与350亿参数的Qwen3-VL-235B媲美，尽管其参数量仅为后者的200分之一。我们向研究界发布了这一净化后的基准测试和Magma-R1模型，倡导采用这种改进后的基准测试，以更准确反映模型的实际能力，加速稳健的设备端虚拟助手的开发进程
### Conclusion
通过净化改进后的AndroidControl，我们展示了设备端GUI代理的实际潜力已接近实用化阶段。我们公开了净化版基准测试AndroidControl-Curated和模型Magma-R1，鼓励研究界采用这一改进的基准测试以加速模型的开发和实现。
## 1075. `cs.SE` - CPSLint: 一种提供工业网络物理系统数据验证和净化的领域特定语言 [PDF](https://arxiv.org/pdf/2510.18651), [HTML](https://arxiv.org/abs/2510.18651)
### Authors
Uraz Odyurt,Ömer Sayilir,Mariëlle Stoelinga,Vadim Zaytsev
### Background
工业网络物理系统（CPS）领域的原始数据通常规模庞大且结构不规范，难以直接处理，需要一个数据准备过程。这类数据通常以时间序列形式记录系统状态，需要经过合理性检查和预处理才能被数据驱动的工作流所使用。
### Innovation
CPSLint 是一种针对工业 CPS 领域的领域特定语言，旨在提供数据准备功能。其主要特点是类型检查和通过对数据列进行验证和修复来强制执行约束，包括从相邻行填充缺失数据。更先进的功能包括推断额外的 CPS 特定数据结构，既可按列也可按行进行推断。例如，按行结构的有效数据分隔执行阶段被提取并为机器学习辅助故障检测和识别（FDI）工作流进行准备。
### Conclusion
CPSLint 通过概念验证实现展示了其功能。
## 1076. `cs.SE` - 探索大规模语言模型在代码生成中的数据高效适应 [PDF](https://arxiv.org/pdf/2403.00046), [HTML](https://arxiv.org/abs/2403.00046)
### Authors
Xue Jiang,Yihong Dong,Zhiyuan Fan,Zhi Jin,Wenpin Jiao,Ge Li
### Background
尽管大规模语言模型（LLMs）在代码生成方面取得了显著进展，但在特定场景下的代码生成任务仍然存在困难。当前的LLMs受限于实际可用的有限训练数据，这导致了在这些特定场景下的代码生成性能不佳。如何在有限的训练数据下有效地适应和调整LLMs以满足特定需求，成为当前代码生成面临的主要挑战。
### Innovation
本文提出了一种名为DEED的新颖适应方法，其全称为基于错误驱动学习的数据高效代码生成适应。DEED利用了LLMs在生成代码时产生的错误作为学习机会，通过错误修订来克服自身的不足，从而实现高效学习。具体而言，DEED包括识别错误代码、使用Self-Revise进行代码修订、用修订后的代码优化模型，并通过迭代调整过程实现持续改进。
### Conclusion
实验结果表明，与现有的主流微调方法相比，DEED在有限训练数据下能实现更优性能，在多个代码生成基准中Pass@1的平均相对改进率为46.2%。此外，Self-Revise被证明是有效的，它生成的修订代码相比数据集中的代码样本能更有效地优化模型。DEED在各种LLMs上表现一致，证明了其广泛适用性。
## 1077. `cs.SE` - 计算战略 coopetition 的基础：正式化相互依赖性和互补性 [PDF](https://arxiv.org/pdf/2510.18802), [HTML](https://arxiv.org/abs/2510.18802)
### Authors
Vik Pant,Eric Yu
### Background
现代社会技术系统的特点是战略上的合作与竞争的结合，即行为者同时为了创造价值而合作，为了获取价值而竞争。虽然像i*这样的概念建模语言提供了丰富的定性表示，但缺乏定量分析动态权衡的机制。相反，古典博弈论提供了数学严谨性，但剥离了背景的丰富性。本技术报告通过开发计算基础弥合了这一差距，这些基础具体化了合作竞争中的两个关键维度：相互依赖性和互补性。
### Innovation
该技术报告通过将i*结构性依赖性分析中的‘依赖者-依赖对象-依赖项’关系结构化转换为定量相互依赖性系数，为相互依赖性奠定了基础。正式化了Brandenburger和Nalebuff的增加价值概念下的互补性，建模协同价值创造，并通过验证清晰地整合了结构性依赖性与价值分配中的谈判能力。引入了博弈论公式，其中纳什均衡包含了结构性相互依赖性。实验验证了不同权函数下的功能形式的稳健性，并对三星-索尼S-LCD合资企业（2004-2011年）进行了实证应用，显示了该方法的有效性和适用性。
### Conclusion
本技术报告为战略 coopetition 在需求工程和多智能体系统中的研究提供了计算基础参考，未来将与信任动态、团队生产以及互惠机制等相关工作进一步协调开展研究。
## 1078. `cs.SE` - 为CI/CD流水线设计优化的基准测试平台 [PDF](https://arxiv.org/pdf/2510.18640), [HTML](https://arxiv.org/abs/2510.18640)
### Authors
Nils Japke,Sebastian Koch,Helmut Lukasczyk,David Bermbach
### Background
大型软件系统的性能退化会导致资源的巨大浪费，因此早期检测这些退化至关重要。频繁进行基准测试对于识别这些退化和维护服务水平协议（SLAs）是必要的。尽管关键性能基准测试必须消耗大量资源并耗费大量时间，但现有方法尚未将其无缝集成到实际的持续集成/持续交付（CI/CD）流水线中。
### Innovation
本文指出基准测试优化领域在关键领域缺乏探索，提出了三个核心挑战：基准优化策略的组合性、基准测试结果的自动化评估、将这些策略应用于实际CI/CD系统中的可用性和复杂性。本文还引入了一个概念性的云基基准测试框架，该框架能够处理上述挑战并使其透明化。
### Conclusion
通过阐述这些公开的问题，本文旨在激发对性能回归检测在CI/CD系统中更实用和有效的研究。
## 1079. `cs.SE` - 大型语言模型基于软件测试挑战：一种分面分类法 [PDF](https://arxiv.org/pdf/2503.00481), [HTML](https://arxiv.org/abs/2503.00481)
### Authors
Felix Dobslaw,Robert Feldt,Juyeon Yoon,Shin Yoo
### Background
大型语言模型（LLMs）和多代理大型语言模型（MALLMs）带来了非确定性，这不同于传统的或机器学习软件。传统的方法无法有效验证其正确性，简单的输出比对或统计准确性测试也不够。因此，需要新的方法来验证LLMs的正确性。
### Innovation
本文提出了LLMs测试用例设计的分面分类法，根据研究文献和作者的经验进行了分类。分类法区分了目标、被测试系统和输入方面的可变性，并提出了两种关键的oracle类型：原子和聚合。这项研究发现当前工具将测试执行视为孤立事件，缺乏明确的聚合机制，并未能充分捕捉不同模型版本、配置和重复运行之间的影响。
### Conclusion
本文确定了影响测试正确性的关键变异性点，并指出了研究、工业和开源社区必须解决的开放挑战。分类法定义了四个面向LLMs测试用例设计的要素，强调了一种新的思路，即将正确性视为结果的分布而非二元属性，需要学术界和实务界之间的更紧密合作以建立成熟的、可变性意识测试方法。
## 1080. `cs.SE` - $μ$OpTime: 使用稳定性指标静态减少微观基准套件的执行时间 [PDF](https://arxiv.org/pdf/2501.12878), [HTML](https://arxiv.org/abs/2501.12878)
### Authors
Nils Japke,Martin Grambow,Christoph Laaber,David Bermbach
### Background
性能倒退对软件质量有巨大影响。一种在软件部署到生产环境之前发现性能倒退的方法是在部署前执行性能测试，例如使用微基准测试，后者可以在子程序级别测量性能。然而，对于包含许多微基准测试的项目，因其需要频繁重复执行以获得准确的结果，可能导致执行时间长达数小时，这使它们不适合频繁用于CI/CD管道中。这种长时间的执行是开发过程中的瓶颈，影响了软件的持续集成和持续交付效率。因此，作者提出$μ$OpTime，这是一种静态方法，通过配置每个微基准测试的重复次数来减少微基准套件的执行时间。$μ$OpTime基于先前完整微基准套件运行的结果，使用统计稳定性指标来确定仍能获得准确结果的最小重复次数。
### Innovation
$μ$OpTime通过使用统计稳定性指标来确定微基准测试所需最少重复次数，以显著减少性能测试的执行时间，而不影响结果的准确性。这个方法可以有效运用于CI/CD流程中，以可靠地检测性能倒退，提高开发效率。
### Conclusion
实验研究使用14个开放源代码项目（两种编程语言和五种稳定性指标）证明了$μ$OpTime的有效性。与Go相比，$μ$OpTime将执行时间减少了95.83%，而Java项目则减少了94.17%。稳定性指标的选择取决于项目和编程语言，对于Java项目可能需要考虑热身阶段，以实现更高比例的执行时间减少。总体而言，$μ$OpTime为在CI/CD管道中可靠地检测性能倒退提供了可能。
## 1081. `cs.SE` - 关于ML云服务滥用的综合多视角实证研究 [PDF](https://arxiv.org/pdf/2503.09815), [HTML](https://arxiv.org/abs/2503.09815)
### Authors
Hadil Ben Amor,Manel Abdellatif,Taher Ghaleb
### Background
机器学习（ML）模型被广泛应用于多个领域，如医疗诊断和自动驾驶等，云提供商提供ML服务以简化软件系统中ML组件的集成。但ML服务滥用普遍存在，导致ML服务基系统质量下降，维护和演化受到影响。尽管有一些关于ML服务滥用的研究，但缺乏统一的术语和规范。因此，作者对该现象进行了实证研究，包括文献综述、灰文文献审查、GitHub上ML服务项目的实证分析以及ML从业者调查，揭示了滥用行为的常见原因及其对最佳实践的忽视，强调需要持续教育和工具支持来检测和纠正滥用行为。
### Innovation
研究提出了20种ML云服务滥用，其中大部分未被前人研究过；通过多方法实证研究，包括文献综述、文档审查、项目分析和从业者调查，提出了ML服务滥用中存在的问题及其解决思路；强调后续研究和教育中对最佳实践的关注；设计并应用工具来自动检测和重构ML滥用行为。
### Conclusion
ML服务滥用在开源项目和行业中普遍存在，常常源自于对服务能力的理解不足和文档不充分。该研究通过多视角实证分析，发现了ML服务滥用现象，并提出了实用的对策，突显了持续教育和工具支持的重要性。为此类问题的潜在研究方向提供了新的视角，并为实现更优化的ML服务实践提出了建设性的建议。
## 1082. `cs.SE` - ReVeal：通过可靠的自我验证实现自我进化的代码代理 [PDF](https://arxiv.org/pdf/2506.11442), [HTML](https://arxiv.org/abs/2506.11442)
### Authors
Yiyang Jin,Kunzhao Xu,Hang Li,Xueting Han,Yanmin Zhou,Cheng Li,Jing Bai
### Background
强化学习与可验证奖励（RLVR）提升了大型语言模型的推理能力。然而，现有方法仅依赖于结果奖励，没有明确优化验证或利用来自真实环境的可靠信号。这导致自我验证不可靠，限制了扩展性。为解决这一问题，通过明确优化自我验证，扩大了验证-生成不对称性，使其成为强大的测试时扩展驱动器。
### Innovation
引入了ReVeal，这是一种多轮次强化学习框架，通过自我验证和工具评估来推进代码生成。ReVeal将长期推理结构化为生成-验证循环，并整合TAPO进行轮次级别的奖励分配，推动代码和测试生成的共同发展。增强了自我验证使得模型在推理时可以使用自我构建的测试和工具反馈持续进化代码。这对于仅经过少量训练就能够在LiveCodeBench上进行20多轮次优化具有重要意义。这种方法显著提高了Pass@k，展示了更好的探索能力，扩大了基础模型的推理边界。
### Conclusion
这些发现表明ReVeal作为一种可扩展的RL训练和测试时扩展范式，具有巨大潜力，为更稳健和自主的AI代理铺平了道路。
## 1083. `cs.SE` - 基于多种模型测量的启发式指导深度学习框架测试 [PDF](https://arxiv.org/pdf/2507.15181), [HTML](https://arxiv.org/abs/2507.15181)
### Authors
Yinglong Zou,Juan Zhai,Chunrong Fang,Yanzhou Mu,Jiawei Liu,Zhenyu Chen
### Background
深度学习框架是开发和部署深度学习应用程序的基础。为了提高这些框架的质量，研究者提出了多种使用深度学习模型作为测试输入的测试方法。然而，现有方法大多通过启发式指标来衡量模型bug检测的有效性，存在三大局限性：一是无法定量衡量模型运算符组合的多样性，可能忽视关键的运算符组合；二是忽视衡量和通过启发式手段指导模型执行时间，导致潜在可用于检测更多框架bug的模型被忽略；三是忽略不同模型测量之间的相关性，仅依赖单一指标的启发式指导，未考虑它们之间的权衡。
### Innovation
本文提出了一种名为DLMMM的新方法，它是首个将多种模型测量纳入启发式指导中的深度学习框架测试方法，并通过融合这些测量来实现它们的权衡。DLMMM首先定量衡量模型的bug检测性能、运算符组合的多样性及模型执行时间，之后通过它们之间的相关性进行融合，以此实现测量之间的权衡。为了进一步提升测试效果，DLMMM还设计了多层次的启发式指导来生成测试输入的模型。
### Conclusion
将DLMMM应用于测试三个广泛使用的深度学习框架（包括TensorFlow、PyTorch和MindSpore），实验结果表明，DLMMM在效果和效率方面均优于现有最先进的方法。
## 1084. `cs.SE` - WhyFlow: 具有质询调试功能的感知分析污点分析工具 [PDF](https://arxiv.org/pdf/2508.07198), [HTML](https://arxiv.org/abs/2508.07198)
### Authors
Burak Yetiştiren,Hong Jin Kang,Miryung Kim
### Background
污点分析是一种用于追踪应用程序及其依赖库中潜在危险数据流动的安全分析技术。研究为什么出现某些意外数据流动以及为什么预期的数据流动不存在是用户在进行污点分析时的重要解释过程。现有的污点分析工具通常不具备用户调试能力，开发者无法就数据流动提出为什么、为什么不行以及如果不同的情况下会发生什么进行探究，并考虑配置源和汇集点以及第三方库模型对数据流动的影响。目前的污点分析器的可视化工具，如树形视图和列表视图，难以解释多个源和汇集点之间的全局影响。
### Innovation
本文提出了TraceLens，这是一种面向用户的问答式调试界面，用于污点分析。它允许用户针对可疑流动的存在、预期流动的不存在以及第三方库模型的全局影响提出为什么、为什么不行以及如果不同的假设会发生什么的问题。该工具进行了假设性地如果分析，帮助用户调试不同连接假设如何影响整体结果。研究表明，使用TraceLens的参与者相对于CodeQL的准确率平均提高了21%，并且报告称其心理负荷（NASA-TLX）降低了45%，使用TraceLens识别相关流动时也更有信心。
### Conclusion
通过使用TraceLens，参与者在准确性和心理负荷方面表现更佳，特别是在理解和验证复杂数据流动时具有更强的解释能力。
## 1085. `cs.SE` - 大型语言模型在自动程序修复中的系统文献综述 [PDF](https://arxiv.org/pdf/2405.01466), [HTML](https://arxiv.org/abs/2405.01466)
### Authors
Quanjun Zhang,Chunrong Fang,Yang Xie,YuXiang Ma,Weisong Sun,Yun Yang,Zhenyu Chen
### Background
随着大型语言模型（LLMs）的发展，自动程序修复（APR）技术得到了迅速发展，并大大提升了软件开发和维护的效率。然而，由于持续探索基于LLMs的APR领域，研究者们难以全面理解当前的研究成果、挑战和潜在机会。为了填补这一空白，本研究提供了首个针对2020年至2025年间LLMs在APR中的应用进行系统的文献综述。本文通过分析189篇相关的论文来总结LLMs在APR中的应用。研究不仅分类了现有的LLMs及其支持APR的策略，还详细讨论了特定修复场景（如语义错误和安全漏洞）。此外，本文还探讨了将LLMs整合到APR研究中的关键方面，并指出了未来需要解决的挑战和未来研究的潜在指导方针。
### Innovation
本研究首次系统地回顾了2020年至2025年间LLMs在APR中的应用，通过分析189篇相关论文，总结了LLMs支持APR的策略分类，详细讨论了特定修复场景，以及探讨了将LLMs整合到APR研究中的关键方面。此外，本文还指出了未来需要解决的挑战和未来研究的指导方针。
### Conclusion
总体而言，本文为APR社区提供了一个系统的综述，帮助研究人员获得全面的理解，并促进未来的研究。
## 1086. `cs.SE` - PEACE: 通过混合代码编辑实现高效项目级优化 [PDF](https://arxiv.org/pdf/2510.17142), [HTML](https://arxiv.org/abs/2510.17142)
### Authors
Xiaoxue Ren(2),Jun Wan(2),Yun Peng(3),Zhongxin Liu(2),Ming Liang(4),Dajun Chen(4),Wei Jiang(4),Yong Li(4) ((2) Hangzhou High-Tech Zone (Binjiang) Institute of Blockchain and Data Security, Zhejiang University, Hangzhou, China, (3) The Chinese University of Hong Kong, Hong Kong, China, (4) Ant Group, Hangzhou, China)
### Background
大型语言模型（LLMs）在代码生成方面展示了显著的能力，但它们在代码效率优化方面的潜力尚未被充分利用。以往基于LLM的代码效率优化方法只关注于函数级别的优化，忽略了函数之间的交互，无法适用于实际的开发场景。代码编辑技术在项目级别的优化方面具有巨大的潜力，但它们面临着无效编辑和次优内部函数的挑战。为了弥补这些不足，本文提出了一种名为Peace的新颖混合框架，该框架通过自动代码编辑实现项目级别的代码效率优化，同时确保项目的整体正确性和完整性。Peace采用了依赖感知的函数序列优化、有效关联编辑识别和效率优化编辑迭代三个关键阶段。为了衡量Peace的效果，构建了包含146个实际优化任务的基准PeacExec，其中包括47个高影响GitHub Python项目的高效测试案例和可执行环境。大量实验表明，Peace在现有最先进的基线方法中表现更优，准确率达到69.2%，优化率增加46.9%，执行效率提高0.840倍。特别是在包含多个函数的复杂优化任务中，Peace的表现尤其突出。此外，还进行了广泛的实验以验证Peace中各个组件的贡献及其混合框架设计的合理性和有效性。
### Innovation
Peace提出了一种新颖的混合框架，用于项目级别的代码效率优化，并通过自动代码编辑实现。Peace框架包含了依赖感知的函数序列优化、有效关联编辑识别和效率优化编辑迭代三个阶段。此外，构建了名为PeacExec的基准，包含多个实际优化任务，旨在客观评估Peace的有效性。Peace的创新点在于结合了依赖感知和自动编辑，实现了项目级别的优化，同时保持了代码的正确性和完整性，有效解决了传统方法在复杂优化任务中的不足。
### Conclusion
Peace框架在多个复杂优化任务中显著优于现有基线方法，尤其是在准确率、优化率和执行效率提升方面表现出色。通过对每个组件的贡献以及混合框架设计的验证，Peace提供了一种有效应对复杂项目优化问题的新方法。
## 1087. `cs.SE` - Agent-based自动修复Agent问题的能力研究 [PDF](https://arxiv.org/pdf/2505.20749), [HTML](https://arxiv.org/abs/2505.20749)
### Authors
Alfin Wijaya Rahardja,Junwei Liu,Weitong Chen,Zhenpeng Chen,Yiling Lou
### Background
基于大语言模型的代理系统正成为新的软件范式，并被广泛应用于医学、机器人和编程等领域。然而，维护这些系统需要大量的努力，因为它们不可避免地会遇到错误，并且需要不断进化以满足变化的外部要求。因此，自动解决代理问题（即错误报告或功能请求）是一个关键且具有挑战性的任务。虽然最近的软件工程（SE）代理（如SWE-agent）已经在处理传统软件系统的问题上显示出了潜力，但它们在处理与传统软件显著不同的代理系统中的实际问题上的效果尚不清楚。为了填补这一空白，作者首先手动分析了201个真实的代理问题，以确定通用的问题类别，并花费500个人小时构建了包含50个代理问题解决任务的AGENTISSUE-BENCH基准（每个任务都有可执行的环境和故障触发测试）。
### Innovation
构建了一个包含50个代理问题解决任务的可重复基准AGENTISSUE-BENCH，其中每个任务都有执行环境和故障触发测试，以评估最先进的软件工程代理在解决代理系统问题上的效果。结果显示，这些最先进的SE代理在这次基准测试中的效果有限，解决率仅为3.33%-12.67%。这些结果强调了维护代理系统相比传统软件的独特挑战，突显了进一步研究开发先进的SE代理来解决代理问题的重要性。
### Conclusion
这些结果指出，需要进一步研究来开发高级软件工程代理以解决代理系统中的问题，并强调了代理系统与传统软件维护的显著区别。数据和代码可在以下链接获取: this https URL
## 1088. `cs.SE` - 使用System F中的类型推理评估程序语义推理 [PDF](https://arxiv.org/pdf/2509.23686), [HTML](https://arxiv.org/abs/2509.23686)
### Authors
Yifeng He,Luning Yang,Christopher Castro Gaw Gonzalo,Hao Chen
### Background
大语言模型（LLMs）正在越来越多地融入软件工程生态系统中，它们的测试时计算（TTC）推理能力在理解程序逻辑和语义方面显示出了巨大的潜力。然而，现有的代码推理基准缺乏一个形式化、程序为中心的演绎框架来确保公平评估，并且无法评估模型是否真正地推理程序语义或者仅仅是利用自然语言和代码标记之间的表面关联。
### Innovation
本研究引入了TF-Bench，这是一个用于基于System F类型推理评估LLM推理能力的基准测试，特别是程序语义推理。并通过验证转换去除语义无关的自然语言，构建了TF-Bench_pure，一个纯粹语义驱动的TF-Bench变体。此外，提出了两个新指标来评估抗干扰能力和测试时推理的有效性，揭示了现有最先进LLM模型的重要局限性。
### Conclusion
现有的LLM模型在评估的基准中表现较差，最优秀的模型（Claude-3.7-sonnet）在TF-Bench_pure上的准确性仅为55.85%。研究还提出了两个新指标来评估模型的鲁棒性和测试时推理的有效性，强调了对于未来研究的重要方向。
## 1089. `cs.SE` - AgentChangeBench：对话AI在目标切换 robustness 多维度评估框架 [PDF](https://arxiv.org/pdf/2510.18170), [HTML](https://arxiv.org/abs/2510.18170)
### Authors
Manik Rana,Calissa Man,Anotida Expected Msiiwa,Jeffrey Paine,Kevin Zhu,Sunishchal Dev,Vasu Sharma,Ahan M R
### Background
当前的智能代理基准主要评估静态目标或一次性工具使用情况，而现实中的多轮交互中目标的变化是关键特征。现有基准未能充分衡量智能代理在对话中如何适应中期对话目标变换。因此，有必要提出一个新的基准来专门评估工具增强的语言模型代理在企业领域的多目标变换中的适应能力。AgentChangeBench即为此目的而设计，旨在衡量代理在三个企业的不同领域进行多轮对话过程中，适应中期对话目标变换的能力。
### Innovation
我们提出了一个专门用于评估工具增强的语言模型代理在中期对话目标变换中适应能力的新基准AgentChangeBench。该框架通过四个互补的度量标准来正式化评估：任务成功率(TSR)衡量有效性，工具使用效率(TUE)衡量可靠性，工具调用冗余率(TCRR)衡量无效努力，目标-转变恢复时间(GSRT)衡量适应延迟。这个基准包含2,835个任务序列和五个用户角色，每个角色都用于触发正在进行流程中的现实中的切换点。这种方法揭示了尖锐的对比，即像GPT-4o在航空预订变换中的92.2%恢复率与Gemini的48.6%，以及零售任务中几乎完美的参数有效性，但冗余率高达80%以上。这些发现证明了高原始准确度并不意味着在动态目标下的鲁棒性，并且必须明确度量恢复时间和冗余性。AgentChangeBench为诊断和改善实体经济场景中的智能代理的鲁棒性提供了一个可重复的试验平台。
### Conclusion
高原始准确度并不意味着在动态目标下的鲁棒性，因此明确度量恢复时间和冗余性至关重要。AgentChangeBench为诊断和改善智能代理在现实的企业环境中的鲁棒性提供了可重复的试验平台，通过这一基准我们可以更好地理解和改善代理的适应能力和可靠性。
## 1090. `cs.SE` - 当代理偏离轨道：使用PRMs纠正SWE代理 [PDF](https://arxiv.org/pdf/2509.02360), [HTML](https://arxiv.org/abs/2509.02360)
### Authors
Shubham Gandhi,Jason Tsay,Jatin Ganhotra,Kiran Kate,Yara Rizk
### Background
大语言模型（LLM）代理越来越多地被部署来执行复杂的多步骤软件工程（SWE）任务。然而，它们的路径中往往包含昂贵的低效率，如重复探索、循环以及未达到解决方案时的失败终止。先前的工作在执行后主要以事后的方式处理这些错误，仅在执行后诊断失败。
### Innovation
在此论文中，作者提出了SWE-PRM，在推理时引入了一个过程奖励模型（PRM），可以在执行过程中检测并纠正路径级别的错误。该设计利用了常见的低效率分类，并提供轻量级的可解释反馈，无需修改底层策略。在SWE-bench Verified上，封闭源代码的PRMs将解决率从40.0%提高到50.6%（增加10.6个百分点），在中等和困难任务上取得了最大的收益。在反馈策略中，基于分类的PRMs比未加引导或明确动作指令的版本表现更好，提高了成功率并缩短了路径长度。这些好处带来的额外推理成本仅为0.2，使其成为一个实用且可扩展的机制来提高SWE代理的可靠性和效率。
### Conclusion
这些结果表明，通过引入SWE-PRM，可以有效提高SWE代理的可靠性与效率，具有良好的实用性和可扩展性。
