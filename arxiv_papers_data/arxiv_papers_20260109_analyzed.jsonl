{"llm_update_time": "20260109", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2601.03306", "html_url": "https://arxiv.org/abs/2601.03306", "title": "使用自我游戏经验回放掌握围棋", "title_en": "Mastering the Game of Go with Self-play Experience Replay", "authors": "Jingbin Liu,Xuechun Wang", "background": "围棋长期以来一直是人工智能的标准测试，需要复杂的战术推理和长期规划。先前的方法，如AlphaGo及其后续版本，主要依赖基于模型的蒙特卡洛树搜索（MCTS）。", "innovation": "QZero是一种新颖的无模型强化学习算法，在训练过程中不进行搜索，而是通过自我游戏和离策略经验回放学习纳什均衡策略。它基于熵正则化Q学习，使用单个Q值网络统一策略评估和改进。", "conclusion": "QZero从无先验知识开始，仅使用7个GPU资源训练5个月后，达到了与AlphaGo相当的性能水平，这首次证明了使用无模型的强化学习掌握围棋的效率，以及离策略强化学习解决大规模复杂环境的可能性。"}
{"llm_update_time": "20260109", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2601.03389", "html_url": "https://arxiv.org/abs/2601.03389", "title": "通过内省探索：一种自我意识的奖励模型", "title_en": "Exploration Through Introspection: A Self-Aware Reward Model", "authors": "Michael Petrowski,Milica Gašić", "background": "理解人工智能中人工代理如何建模内部心智状态是推进人工智能中的心智理论的关键。证据表明，存在一个统一系统负责自我意识和他人意识。我们通过让强化学习代理在网格世界环境中推断其内部状态来探索这种自意识。具体地，我们引入了一个灵感来源于生物疼痛作为学习信号的内省探索组件，利用隐马尔可夫模型从在线观察中推断“疼痛信念”。这种信号被整合到主观奖励函数中，以研究自意识如何影响代理的学习能力。", "innovation": "我们提出了一个基于内省探索的自我意识奖励模型，通过利用隐马尔可夫模型推断“疼痛信念”，并将这种信号整合到主观奖励函数中，来研究自意识对代理学习能力的影响。此外，我们使用这种计算框架研究在正常和慢性疼痛感知模型之间的性能差异。", "conclusion": "结果表明，内省代理一般显著优于标准基线代理，并能够复制复杂的类人类行为。"}
{"llm_update_time": "20260109", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2601.03359", "html_url": "https://arxiv.org/abs/2601.03359", "title": "提升大型语言模型指令遵循能力：一种基于评估的多代理工作流以优化提示指令", "title_en": "Enhancing LLM Instruction Following: An Evaluation-Driven Multi-Agentic Workflow for Prompt Instructions Optimization", "authors": "Alberto Purpura,Li Wang,Sahil Badyal,Eugenio Beaufrand,Adam Faulkner", "background": "大型语言模型（LLMs）虽然能生成实际相关的内容，但往往会忽略形式约束，导致输出虽概念正确但过程上存在缺陷。传统的方法主要集中在重新表述LLM需要完成的主要任务描述上，而忽视了作为响应接受标准的细化约束。这些限制对于确保模型输出的精确性和合规性至关重要，但这些细节经常被忽略。", "innovation": "本文提出了一种新的多代理工作流，将主要任务描述的优化与其约束条件分离。该方法利用定量评分作为反馈，通过迭代重写和改进这些约束条件。与传统方法相比，这种方法能够更有效地提高模型如Llama 3.1 8B 和 Mixtral-8x 7B 的合规性。", "conclusion": "该方法通过迭代改进任务描述及其约束条件，产生了显著提高合规性的重写提示。通过评估，该方法明显优于传统的方法，能够有效提升大型语言模型对指令的遵循能力。"}
{"llm_update_time": "20260109", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2601.03335", "html_url": "https://arxiv.org/abs/2601.03335", "title": "数字红皇后：基于LLM的Core War中对抗性程序进化", "title_en": "Digital Red Queen: Adversarial Program Evolution in Core War with LLMs", "authors": "Akarsh Kumar,Ryan Bahlous-Boldi,Prafull Sharma,Phillip Isola,Sebastian Risi,Yujin Tang,David Ha", "background": "大型语言模型（LLMs）越来越多地被用于通过模仿生物进化的过程来解决许多领域的难题。然而，大多数LLM-进化框架被设计为静态优化问题，忽略了真实世界进化过程中的开放性和对抗性动态。Core War是一种图灵完备的虚拟环境，在人工生命和网络安全领域都有研究，文中提出了Digital Red Queen（DRQ）算法，该算法通过持续适应变化的目标，利用所谓的'红皇后'动态，来进化对抗性的程序。", "innovation": "DRQ算法采用了一种简单自对弈的方法，并利用LLM来进化可以相互竞争的程序（称为“战士”），这些程序在Core War游戏中竞争对虚拟机的控制权。相对于既定的人类“战士”，随着时间的推移，这些“战士”变得越来越通用。此外，它们在多次独立运行中也表现出行为上的一致性，反映出一种普遍适用的行为策略。研究指出，从静态目标转向动态的红皇后目标具有潜在的价值。这项工作将Core War定位为一个研究人工系统对抗适应性的一种丰富且可控制的测试环境，以及评估基于LLM的进化方法的有效工具。此外，DRQ的简洁性和有效性暗示了这种简单的自对弈方法在其他实际多智能体对抗领域也有潜在的应用价值。", "conclusion": "我们的研究展示了从静态目标转向动态‘红皇后’目标的价值，表明无需高度复杂的方法也能够进行有效的对抗性程序进化。Core War环境为研究人工系统中的对抗适应性提供了宝贵的机会，同时也证明了DRQ算法在实际对抗性多智能体领域中的潜在应用。"}
{"llm_update_time": "20260109", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2601.03470", "html_url": "https://arxiv.org/abs/2601.03470", "title": "基于成熟度的自主人工智能系统认证：通过量测机制量化可信度", "title_en": "Toward Maturity-Based Certification of Embodied AI: Quantifying Trustworthiness Through Measurement Mechanisms", "authors": "Michael C. Darling,Alan H. Hesu,Michael A. Mardikes,Brian C. McGuigan,Reed M. Milewicz", "background": "本文提出了一种基于成熟度的框架，通过明确的测量机制对自主人工智能系统进行认证。作者认为，可认证的自主人工智能需要结构化评估框架、定量评分机制以及在信任度评估中固有的多目标权衡方法。通过不确定性量化作为量测机制的示例，本文展示并证明了这种方法的可行性，并通过一个无人航空系统（UAS）检测案例研究进行了说明。", "innovation": "提出了一个基于成熟度的框架，用于通过明确的测量机制认证自主人工智能系统。这一框架强调了结构化评估、定量评分以及处理信任度评估中固有的多目标权衡的重要性。", "conclusion": "本文通过不确定性量化作为量测机制的示例，展示了该方法的可行性，并通过无人航空系统（UAS）检测案例研究进行了说明。"}
{"llm_update_time": "20260109", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2601.03523", "html_url": "https://arxiv.org/abs/2601.03523", "title": "基于知识编译方法的加权模型计数方差计算", "title_en": "Variance Computation for Weighted Model Counting with Knowledge Compilation Approach", "authors": "Kengo Nakamura,Masaaki Nishino,Norihito Yasuda", "background": "加权模型计数（WMC）是知识编译领域的一个重要查询，常用于各种模型的概率推理，如贝叶斯网络。在实际推理任务中，模型参数具有不确定性，这会影响推理结果的可靠性。为了量化这种不确定性，可通过引入参数的分布并计算推理结果的方差来实现。然而，计算这种方差的有效性尚不明确。", "innovation": "文章提出了一种在给定结构化d-DNNF输入时，计算WMC方差的多项式时间算法。同时证明了对于结构化DNNF、d-DNNF和FBDD，计算WMC方差问题是NP-hard的，尽管后两者支持多项式时间的WMC算法。此外，展示了用于量化贝叶斯网络推理中参数方差影响的算法，并在实际贝叶斯网络中进行了实证分析。", "conclusion": "研究提出了一个有效计算WMC方差的算法，并证明了在不同结构化电路类型上的复杂性，同时展示了该方法在实际贝叶斯网络上的应用价值，揭示了参数方差对推理结果方差的影响。"}
{"llm_update_time": "20260109", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2601.03482", "html_url": "https://arxiv.org/abs/2601.03482", "title": "大规模基础模型在健康干预中的个性化", "title_en": "Personalization of Large Foundation Models for Health Interventions", "authors": "Stefan Konigorski,Johannes E. Vedder,Babajide Alamu Owoyele,İbrahim Özkan", "background": "大规模基础模型（LFMs）在预防、诊断和治疗中的应用正在改变医疗AI领域。然而，是否能够提供真正个性化的治疗建议仍然存在疑问。最近的研究揭示出多个挑战，例如个性化的基本泛化悖论：在一项临床研究中表现出高准确性的模型在其他研究中可能只是随机水平。这表明个性化和外部有效性存在矛盾。这种现象还体现了AI驱动医疗保健中的更广泛的矛盾，如隐私-性能悖论、规模-特异性悖论和自动化-同理心悖论。此外，关于个性化推荐所需的因果理解程度，相比于LFBs的单纯预测能力，仍是一个开放问题。N-of-1试验作为一种自我对照试验，是个性化医疗中个体因果推断的金标准，通过局部实验提供了个人范围内的因果证据，同时保护了隐私。", "innovation": "本文提出了一种混合框架，结合了大规模基础模型（LFMs）和N-of-1试验的优点，解决个性化医疗中的悖论。LFMs用于快速从多模态数据中生成假设，而N-of-1试验用于特定个体的因果验证。通过这种方式，LFMs生成带不确定性估计的干预措施候选名单，随后引发N-of-1试验。这种框架旨在明确预测和因果之间的界限，并明确解决悖论性的冲突，以促进负责任的AI在个性化医疗中的集成。", "conclusion": "本文强调LFMs与N-of-1试验的互补性，以及它们如何共同解决个性化医疗中的悖论。通过现实区分预测与因果，并明确解决悖论性的冲突，这对于负责任的AI集成至关重要。"}
{"llm_update_time": "20260109", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2601.03475", "html_url": "https://arxiv.org/abs/2601.03475", "title": "CPGPrompt: 将临床指南转换为LLM可执行的决策支持系统", "title_en": "CPGPrompt: Translating Clinical Guidelines into LLM-Executable Decision Support", "authors": "Ruiqi Deng,Geoffrey Martin,Tony Wang,Gongbo Zhang,Yi Liu,Chunhua Weng,Yanshan Wang,Justin F Rousseau,Yifan Peng", "background": "临床实践指南（CPGs）提供了基于证据的患者护理建议，但将它们整合到人工智能中仍然具有挑战性。以往的方法，如基于规则的系统，面临解释性差、对指南一致性遵守不佳以及适用领域狭窄等问题。", "innovation": "本研究开发并验证了CPGPrompt，这是一种自动提示系统，可将叙述性临床指南转换为大型语言模型（LLMs）。该框架将CPGs转换为结构化决策树，并通过LLM动态导航这些树来进行患者案例评估。研究表明，CPGPrompt在二元专科转诊分类任务中表现优异，但在多类路径分配任务中的表现有所下降，且存在领域特定的差异。", "conclusion": "二元专科转诊分类在所有领域均表现出色（F1: 0.85-1.00），召回率高（1.00 ± 0.00）。相比之下，多类路径分配的任务表现出较低性能，且各领域有所不同：头痛（F1: 0.47），腰痛（F1: 0.72），前列腺癌（F1: 0.77）。领域特定的性能差异反映了每指南的独特结构。研究表明，不同疾病的指南在处理否定、时间推理以及可量化实验室测试方面各有挑战。"}
{"llm_update_time": "20260109", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2601.03537", "html_url": "https://arxiv.org/abs/2601.03537", "title": "STAR-S：通过安全规则上的自我教学推理提高安全性对齐", "title_en": "STAR-S: Improving Safety Alignment through Self-Taught Reasoning on Safety Rules", "authors": "Di Wu,Yanyan Zhao,Xin Lu,Mingzhe Li,Bing Qin", "background": "为确保大型语言模型（LLMs）的安全部署，抵御越狱攻击至关重要。近期研究致力于通过训练模型在响应之前考虑安全规则来提高安全性。但是，确定有效的安全推理形式以抵御越狱攻击是很难明确设计的或直接获取的。", "innovation": "提出了STAR-S框架，该框架将安全规则推理的学习整合到自我教学的循环中。STAR-S的核心在于由安全规则引导的推理和反思，并利用微调增强安全推理。这一过程形成协同循环，模型的推理和对安全规则的解释能力提高，从而在安全规则提示下生成更好的推理数据，用于进一步训练。实验证明STAR-S能有效防御越狱攻击，优于基线。", "conclusion": "STAR-S框架能够有效提升模型抵御越狱攻击的能力，超越了现有的基准模型。"}
{"llm_update_time": "20260109", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2601.03509", "html_url": "https://arxiv.org/abs/2601.03509", "title": "进化程序化技能网络", "title_en": "Evolving Programmatic Skill Networks", "authors": "Haochen Shi,Xingdi Yuan,Bang Liu", "background": "本文研究了在开放性体感环境中持续技能获取的问题。在这种环境中，代理需要构建、完善和重用不断扩大的可执行技能库。", "innovation": "本文提出了程序化技能网络（PSN），这是一种框架，其中技能是以可执行符号程序的形式存在的组合网络，并且这种网络可以通过经验进化。PSN 实现了三个核心机制：（1）REFLECT 用于技能组合的精细故障定位；（2）成熟度意识的渐进优化更新门控机制，既能稳定可靠的技能，又能保持对不确定技能的可塑性；（3）在回滚验证下的规范结构重构，以保持网络紧凑性。此外，PSN 的学习动态结构上与神经网络的训练相似。", "conclusion": "通过在 MineDojo 和 Crafter 上进行的实验，展示了技能的重用能力、快速适应能力和广泛的应用，证明了 PSN 在开放性任务分布中的强大泛化能力。"}
{"llm_update_time": "20260109", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2205.07266", "html_url": "https://arxiv.org/abs/2205.07266", "title": "发现图神经网络的表示瓶颈", "title_en": "Discovering the Representation Bottleneck of Graph Neural Networks", "authors": "Fang Wu,Siyuan Li,Stan Z. Li", "background": "图神经网络（GNNs）主要依赖于消息传递范式来传播节点特征并建立交互，不同的图学习问题需要不同范围的节点交互。研究发现，GNNs 在不同复杂度的上下文中捕捉节点交互的能力通常存在不足，这就是所谓的 GNNs 的表示瓶颈。", "innovation": "论文指出现有的图构建机制引入的归纳偏差可能会导致这种表示瓶颈，并提出了一种基于 GNNs 学习到的交互模式进行自适应调整节点感受野的新型图重接方法。实验结果表明，该方法能有效缓解表示瓶颈，并且在提高 GNNs 性能方面优于现有的图重接基准方法。", "conclusion": "该研究揭示了 GNNs 在表达能力上的局限性，并提出了一种解决方案，能够有效提升 GNNs 在复杂图学习任务中的性能。"}
{"llm_update_time": "20260109", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2601.02071", "html_url": "https://arxiv.org/abs/2601.02071", "title": "FormuLLA:一种用于生成新型3D可打印制剂的大语言模型方法", "title_en": "FormuLLA: A Large Language Model Approach to Generating Novel 3D Printable Formulations", "authors": "Adeshola Okubena,Yusuf Ali Mohammed,Moe Elbadawi", "background": "制药领域的3D打印技术有潜力生成真正个性化的给药形式。近年来，人工智能（AI）被用来加速制剂和工艺开发，但大多数AI驱动的努力仍局限在特定领域，未能考虑到该技术固有的更广泛的制剂挑战。最近，人工智能的发展引入了通用人工智能的概念，其中人工智能系统超越了传统的预测模型，向更通用、类似人类的推理转变。本研究旨在探索使用大规模语言模型（LLMs）生成新型3D可打印制剂的方法。", "innovation": "研究采用了大规模语言模型对超过1400份配方的数据集进行了微调，以推荐适用于特定活性药物成分剂量的适宜辅料，并预测线材的机械性能。研究结果表明，Llama2最适合推荐FDM配方所需的辅料，模型选择和参数化显著影响性能，较小的LLMs可能出现灾难性遗忘。此外，研究还表明：即使使用超过1400份配方的相对较小的数据集也会导致模型出现灾难性遗忘；标准的LLM评估指标仅评估语言性能而忽略配方的可加工性；以及专门针对生物医学数据训练的LLMs并不总是结果最佳。", "conclusion": "解决这些挑战对于推动LLMs超越语言专业知识并实现可靠的制药制剂开发系统至关重要。"}
{"llm_update_time": "20260109", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2411.12460", "html_url": "https://arxiv.org/abs/2411.12460", "title": "使用大型语言模型探索迭代可控总结", "title_en": "Exploring Iterative Controllable Summarization with Large Language Models", "authors": "Sangwon Ryu,Heejin Do,Daehee Kim,Hwanjo Yu,Dongwoo Kim,Yunsu Kim,Gary Geunbae Lee,Jungseul Ok", "background": "大型语言模型（LLMs）在抽象总结任务中表现出色，但它们在精确控制摘要属性（如长度或主题）方面的能力仍然被忽视，限制了它们对特定用户偏好的适应性。", "innovation": "本文系统性地探索了LLMs的可控性。作者重新审视了总结属性的度量，并引入了迭代评估指标（包括失败率和平均迭代次数），以更精准地评估LLMs的可控性，而不是仅仅评估错误。作者还提出了一种指导解释框架（GTE）来实现可控总结，该框架使模型能够识别初稿中的不匹配属性，并指导其自我解释前一次输出中的错误，从而生成满足所需属性的调整良好摘要，比其他迭代方法所需的迭代次数更少。", "conclusion": "通过允许模型反思其不匹配，GTE生成了符合期望属性的调整良好的总结，显示出强大的效果，比其他迭代方法所需的迭代次数要少得多。"}
{"llm_update_time": "20260109", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2305.16203", "html_url": "https://arxiv.org/abs/2305.16203", "title": "使用回答集编程计算部分可观测多智能体路径规划的通用计划", "title_en": "Computing Universal Plans for Partially Observable Multi-Agent Routing Using Answer Set Programming", "authors": "Fengming Zhu(The Hong Kong University of Science and Technology),Fangzhen Lin(The Hong Kong University of Science and Technology)", "background": "近年来，多智能体路径规划问题因其广泛的工业应用而引起了广泛关注，包括物流仓库自动化和室内服务机器人等领域。传统上，这类问题通常被建模为经典的规划问题。本文探讨了将这些问题建模为通用规划问题的优势，特别是在智能体为自主实体可能会遇到未预见情况的情况下。", "innovation": "本文提出了使用回答集编程（ASP）实现系统以计算通用计划（即策略），并给定任意二维地图和一组部分可观测智能体的目标配置，系统将问题转换为逻辑程序，寻找每个智能体的可行通用计划。此外，系统还可以定制行动偏好以计算更高效的通用计划，甚至接近最优的通用计划。", "conclusion": "通过实验，研究了不同目标配置和环境如何影响通用计划的可行性，并探讨了代理感知对可行性的影响。该研究表明，通过定制行动偏好，用户可以计算出更高效的通用计划，甚至接近最优的通用计划。相关代码已发布。"}
{"llm_update_time": "20260109", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2410.03296", "html_url": "https://arxiv.org/abs/2410.03296", "title": "文本分类中提取式自我解释与人类演绎的系统比较", "title_en": "A Systematic Comparison between Extractive Self-Explanations and Human Rationales in Text Classification", "authors": "Stephanie Brandl,Oliver Eberle", "background": "指令调优的大型语言模型（LLMs）能够在生成自解释的过程中向用户提供输出解释，无需应用复杂的解释性技术。本文旨在分析这些模型所提供的自解释是否能够提供高质量的解释。研究聚焦于文本分类任务，通过评估自解释对人类可信度的揣测，并与人工标注进行对比。", "innovation": "论文引入了一种评估方式，即通过对文本分类任务中的情感分类、强制劳动检测和论断验证任务进行研究，并将提取的自我解释与人类的解释进行对比，尤其是以色列和意大利翻译版本的情感分类任务。此外，还评估了人工和自我解释对于正确模型预测的忠实度，并引入了后验归因解释的方法来进行更全面的研究。", "conclusion": "尽管自我解释与人类间的对齐高度依赖于文本长度和任务复杂度，自我解释仍然提供了一部分忠实于令牌级的解释，而后验归因方法则会倾向于强调结构和格式化令牌，反映了不同的解释策略。"}
{"llm_update_time": "20260109", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2410.08925", "html_url": "https://arxiv.org/abs/2410.08925", "title": "原型形式概述：用于可解释深度学习的经验总结", "title_en": "An Overview of Prototype Formulations for Interpretable Deep Learning", "authors": "Maximilian Xiling Li,Korbinian Franz Rudolf,Paul Mattes,Nils Blank,Rudolf Lioutikov", "background": "现有的一些深度学习模型是黑箱性质的，它们难以解释内部运作机制。为了提供可解释的替代方案，此研究通过学习视觉原型进行分类，提出了原型部分网络。该研究在不同的原型表示方法之间进行了全面对比，包括基于点的方法和概率方法，这些方法在欧几里得和超球面隐空间中都进行了应用。", "innovation": "引入了HyperPG，一种使用超球面上高斯分布的概率原型表示。通过在CUB-200-2011、斯坦福汽车和牛津花的数据集上的实验表明，超球面原型在分类任务中的表现优于传统的欧几里得表示。特别的，超球面原型在简化训练策略中仍能保持具有竞争力的性能，而欧几里得原型需要大量的超参数调整。", "conclusion": "研究结果显示，超球面原型在可解释性的深度学习模型中提供了更好的性能和更稳定的训练过程。"}
{"llm_update_time": "20260109", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2304.03906", "html_url": "https://arxiv.org/abs/2304.03906", "title": "启发式机器学习在稳健分子属性预测中的应用", "title_en": "Instructor-inspired Machine Learning for Robust Molecular Property Prediction", "authors": "Fang Wu,Shuting Jin,Siyuan Li,Stan Z. Li", "background": "机器学习在化学和生物科学领域引发了一场变革，但其效果高度依赖于标记数据的可用性，而标记生物化学数据非常耗时。因此，存在数据稀疏性的挑战。", "innovation": "提出了一个名为InstructMol的指导学习算法，该算法可以测量伪标签的可靠性，并帮助目标模型利用大规模的未标记数据。InstructMol在多个真实分子数据集和未知分布(out-of-distribution)基准测试中的高准确度得以实现，且该算法不需要在多个领域之间进行知识转移，从而避免了预训练和微调阶段的潜在差距。", "conclusion": "InstructMol能够在无需跨领域知识转移的情况下，评估伪标签的可靠性，有效利用大规模未标记数据，提高分子属性预测的准确性，研究代码已公开。"}
{"llm_update_time": "20260109", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2601.02813", "html_url": "https://arxiv.org/abs/2601.02813", "title": "HAL: 使用对齐促进大语言模型对话的人类相似性", "title_en": "HAL: Inducing Human-likeness in LLMs with Alignment", "authors": "Masum Hasan,Junjie Zhao,Ehsan Hoque", "background": "对话的人类相似性在人-AI交互中起着核心作用，然而难以定义、测量和优化。因此，行为人性化改进主要依赖于规模扩大或广泛监督训练，而非目标对齐。", "innovation": "作者引入了Human Aligning LLMs (HAL) 框架，使用可解释的数据驱动奖励对语言模型进行对齐。HAL 可以从对比对话数据中提取显性的人类对话特性，将其合并为紧凑的标量评分，并使用此评分作为透明的对齐奖励信号。这种方法允许在不损害性能的前提下对不同规模的模型进行对齐，而大型人类评估结果显示，HAL 对齐的模型更常被视为对话中的人类。", "conclusion": "HAL 显示了如何将语言的软质、定性特征（以前超出了对齐的范围）在可解释和可解释的方式下进行测量和对齐。该方法有助于检查对齐行为并诊断意外效果。"}
{"llm_update_time": "20260109", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2411.05894", "html_url": "https://arxiv.org/abs/2411.05894", "title": "SSSD: 简单可扩展的推测性解码", "title_en": "SSSD: Simply-Scalable Speculative Decoding", "authors": "Michele Marzollo,Jiawei Zhuang,Niklas Roemer,Niklas Zwingenberger,Lorenz K. Müller,Lukas Cavigelli", "background": "推测性解码已成为加速大型语言模型推理的热门技术。然而，大多数现有方法仅在生产服务系统中提供适度的性能改进。能够实现显著加速的方法通常依赖于额外训练过的草稿模型或辅助模型组件，增加了部署和维护的复杂性。这种额外的复杂性减少了灵活性，尤其是在服务工作负载移向草稿模型训练数据中未充分代表的任务、领域或语言时。", "innovation": "提出了一个无需训练的方法—— Simply-Scalable Speculative Decoding (SSSD)，结合了轻量级的 n- 克拉姆匹配和硬件感知性推测。与标准自回归解码相比，SSSD 在延迟上最多可减少 2.9 倍。它在广泛基准上的性能与基于训练的方法相当，同时所需采用的努力显著降低——无需数据准备、训练或调优，并且在语言和领域转换以及长文本上下文中表现出更优秀的鲁棒性。", "conclusion": "SSSD 在延迟、性能和鲁棒性方面表现出显著优势，且部署和维护更为简单。"}
{"llm_update_time": "20260109", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2407.19204", "html_url": "https://arxiv.org/abs/2407.19204", "title": "通过大语言模型评估人工智能对就业的影响", "title_en": "Towards the Terminator Economy: Assessing Job Exposure to AI through LLMs", "authors": "Emilio Colombo,Fabio Mercorio,Mario Mezzanzanica,Antonio Serino", "background": "人工智能及相关技术正在重塑工作和任务，通过自动化或增强人类技能。许多研究者致力于估算工作和任务被人工智能相关技术自动化的风险程度。", "innovation": "本文通过数据驱动的方法，开发了可重复的框架使用最新的开源大型语言模型评估AI和机器人执行与工作相关的任务能力；正式化并计算了按职业的AI暴露度指标（TEAI指数）和任务替代AI（TRAI）指标，通过用户评估进行验证并与现有方法进行比较。", "conclusion": "研究表明，TEAI指数与认知能力、问题解决能力和管理技能正相关，与社会技能负相关。在美国，约三分之一的就业高度暴露于AI，主要集中在要求研究生或以上教育水平的高技能职业。AI暴露与就业和工资增长正相关，表明AI总体上对生产率有正面影响。TRAI指数显示，即使在高技能职业中，AI在任务替代上也表现出高变异性，表明AI与人类在同职业内互补，而工作分配将发生变化。所有结果、模型和代码均可在线获取，供社区重复结果、比较结果，并将我们的工作作为基准监测AI的进展。"}
{"llm_update_time": "20260109", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.04301", "html_url": "https://arxiv.org/abs/2506.04301", "title": "动态推理的成本：从AI基础设施视角揭开AI代理和测试时扩展的神秘面纱", "title_en": "The Cost of Dynamic Reasoning: Demystifying AI Agents and Test-Time Scaling from an AI Infrastructure Perspective", "authors": "Jiin Kim,Byeongjun Shin,Jinha Chung,Minsoo Rhu", "background": "近年来，基于大规模语言模型（LLM）的AI代理展示了令人印象深刻的多功能性，通过适应性的多步推理与外部工具协调。这一从静态一次性推理到具有代理性的多轮工作流的转变，拓宽了任务泛化和行为灵活性，但也带来了系统级成本、效率和可持续性的严重关切。", "innovation": "该论文首次从系统级层面全面分析了AI代理的资源使用情况、延迟行为、能耗和数据中心的广泛电力消耗需求。进一步分析了AI代理设计选择（如最少示例提示、反思深度和并行推理）对准确性和成本之间的权衡的直接影响。研究发现，尽管代理随着计算能力的增加能提高准确度，但很快会遇到边际效益递减的问题，同时导致计算延迟差异扩大和不可持续的基础设施成本。", "conclusion": "通过对代表性的代理进行详细评估，研究揭示了AI代理工作流引入的深刻计算需求，凸显了一个迫在眉睫的可持续性危机。研究结果呼吁在考虑性能与在真实世界约束下的可部署性之间的平衡时，朝着计算高效的推理设计转型。"}
{"llm_update_time": "20260109", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2503.02108", "html_url": "https://arxiv.org/abs/2503.02108", "title": "通过加权核Stein差异修正广义贝叶斯推断中的模式比例偏差", "title_en": "Correcting Mode Proportion Bias in Generalized Bayesian Inference via a Weighted Kernel Stein Discrepancy", "authors": "Elham Afzali,Saman Muthukumarana,Liqun Wang", "background": "广义贝叶斯推断（GBI）提供了一种灵活的框架，通过使用不同的损失函数来更新先验分布，而不是传统的似然函数，从而增强了模型对模型误设的鲁棒性。然而，GBI常常面临不可导方法的挑战，而核Stein差异（KSD）方法通过仅依赖对数似然的梯度来解决此挑战，尽管KSD-Bayes方法具有这一创新，但仍存在关键病态，包括在多重后验分布中对分离模式的敏感性不足。", "innovation": "本研究提出了一种加权KSD方法，该方法在保持计算效率的同时，有效捕捉多重结构。该方法改进了处理不可解多重后验的GBI框架，同时保持关键理论特性，如后验一致性及渐近正态性。实验结果表明，该方法在多重模式敏感性方面显著优于标准的KSD-Bayes方法，同时在单模式设置和其他异常值存在的情况下保持稳健性能。", "conclusion": "本方法通过使用加权KSD改善了GBI处理不可解式多重后验的问题，同时保持了关键的理论特性，并在实验中证明了对于多重模式捕获的提升，保持了在单一模式和存在异常值情况下的稳健性能。"}
{"llm_update_time": "20260109", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2502.06684", "html_url": "https://arxiv.org/abs/2502.06684", "title": "EquiTabPFN: 目标置换等变先验网络", "title_en": "EquiTabPFN: A Target-Permutation Equivariant Prior Fitted Networks", "authors": "Michael Arbel,David Salinas,Frank Hutter", "background": "近期的表单数据基础模型，如TabPFN，在上下文学习中表现出色，能够迅速适应新任务，但它们仍然受到固定目标维度数的限制，通常需要昂贵的集成策略。这种限制源于更深层次的架构问题：这些模型缺乏目标等变性，即目标维度顺序的变化会影响模型的预测结果。这种缺陷导致了一个不可消除的“等变缺口”，进而引入了预测中的不稳定性。", "innovation": "本文通过设计一个完全目标等变的架构，确保编码器、解码器和双注意机制在置换不变的情况下工作，从而解决上述问题。实验结果表明，在数据集中类别的数量多于预训练时的情形下，本文的方法在保持较低计算开销的同时，能够匹配或超越现有的方法。", "conclusion": "本文提出了一个完全目标等变的架构，即EquiTabPFN，并通过实验验证了其有效性和优越性，特别是针对具有更多类别的数据集时，相比现有方法，计算成本更低且性能不低于或优于现有方法。"}
{"llm_update_time": "20260109", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2503.03178", "html_url": "https://arxiv.org/abs/2503.03178", "title": "部分微分方程中的预测不确定性量化驱动的操作学习", "title_en": "Active operator learning with predictive uncertainty quantification for partial differential equations", "authors": "Nick Winovich,Mitchell Daneker,Lu Lu,Guang Lin", "background": "随着神经运算符在快速求解偏微分方程（PDEs）中的应用越来越广泛，准确理解模型预测的准确性和相关的误差水平对于部署可靠的代理模型在科学应用中至关重要。现有的不确定性量化（UQ）框架使用多重或贝叶斯方法，这会导致训练和推理过程中巨大的计算成本。", "innovation": "本文提出了一种针对深度运算网络（DeepONets）的轻量级预测不确定性量方法，该方法也可以适用于其他运算网络。该框架的不确定性估计无偏，并且在足够大的训练数据集上可以提供准确的出界不确定性预测。此外，该框架提供快速推理和不确定性估计，可以高效地驱动成本高昂的外循环分析。在主动学习配置中，该框架扩展到傅里叶神经运算符（FNO），并描述了一种其他运算网络的通用方法。为使部署实时化，还引入了一种基于预先计算主导输出和稀疏放置矩阵的推理策略，将评估时间减少了五倍以上。", "conclusion": "本文提出的方法为时间敏感情况下运算符学习提供了一种实用途径，该方法能够使不确定性感知的操作学习适应实时场景，并应用于贝叶斯优化和主动学习问题，以提高外循环优化过程的准确性和数据效率。"}
{"llm_update_time": "20260109", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2503.24067", "html_url": "https://arxiv.org/abs/2503.24067", "title": "TransMamba: 一种序列级混合Transformer-Mamba语言模型", "title_en": "TransMamba: A Sequence-Level Hybrid Transformer-Mamba Language Model", "authors": "Yixing Li,Ruobing Xie,Zhen Yang,Xingwu Sun,Shuaipeng Li,Weidong Han,Zhanhui Kang,Yu Cheng,Chengzhong Xu,Di Wang,Jie Jiang", "background": "Transformer在现代大型语言模型中起着基石作用，但由于其平方计算复杂性，限制了其在长序列处理中的效率。Mamba作为一种状态空间模型（SSM），具有线性复杂性，提供了高效的潜力，但存在上下文学习不稳定和多任务泛化的不足。一些工作提出了层级混合结构，结合了Transformer和Mamba层，旨在充分利用两者的优点。现有研究提出TransMamba，通过共享参数矩阵（QKV和CBx）统一了Transformer和Mamba，可在不同token长度和层中动态切换注意力机制和状态机制。设计了一个Memory Converter模块，将Transformer的注意力输出转换为SSM兼容的状态，确保TransPoints处无缝的信息流动。", "innovation": "提出了TransMamba，这是一种序列级混合框架，通过共享参数矩阵（QKV和CBx）将Transformer和Mamba统一起来，可以在不同的token长度和层中动态切换注意力机制和状态机制。设计了Memory Converter模块，以转换Transformer的注意力输出并使其与Mamba兼容，并实现了TransPoint调度策略，平衡了效果和效率。", "conclusion": "广泛的实验表明，TransMamba相比单一和混合基线模型，实现了更好的训练效率和性能，并验证了Transformer和Mamba在序列级上更深的一致性，提供了一种下一代语言建模的可扩展解决方案。相关代码和数据可在指定链接获得。"}
{"llm_update_time": "20260109", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2504.05695", "html_url": "https://arxiv.org/abs/2504.05695", "title": "过参数化深度ReLU网络的架构无关泛化界", "title_en": "Architecture independent generalization bounds for overparametrized deep ReLU networks", "authors": "Anandatheertha Bapu,Thomas Chen,Chun-Kai Kevin Chien,Patricia Muñoz Ewald,Andrew G. Moore", "background": "本文探讨了过参数化神经网络的泛化能力，特别是过参数化神经网络在测试误差上与模型过参数化程度和VC维度无关的情况。研究基于网络的度量几何特性、激活函数的正则性属性以及权重的算子范数和偏置的范数进行理论证明。", "innovation": "本文证明了过参数化神经网络能够在测试误差上不依赖于过参数化程度和VC维度，提供了具体的界限。特别地，对于输入空间维度限制下的过参数化深度ReLU网络，证明了不依赖于网络结构的统一泛化界，并通过无梯度下降法显式构造了零损失最小化器。", "conclusion": "理论结果通过MNIST数据集的计算实验得到了验证，实测的测试误差与理论预测的误差相比在平均上有22%的误差幅度。"}
{"llm_update_time": "20260109", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2502.15016", "html_url": "https://arxiv.org/abs/2502.15016", "title": "TimeDistill: 通过跨架构蒸馏高效长时序预测的MLP", "title_en": "TimeDistill: Efficient Long-Term Time Series Forecasting with MLP via Cross-Architecture Distillation", "authors": "Juntong Ni,Zewen Liu,Shiyu Wang,Ming Jin,Wei Jin", "background": "Transformer-based和CNN-based方法在长时间序列预测中表现出色，但它们的高计算和存储需求限制了大规模部署。", "innovation": "提出了一种通过知识蒸馏（KD）将轻量级MLP与高级架构集成的方法。引入了TimeDistill，这是一种跨架构KD框架，可以将教师模型（如Transformers, CNNs）中的模式转移到MLP中。此外，还提供了理论分析，表明我们的KD方法可以被视为一种特殊的混迭数据增强形式。", "conclusion": "TimeDistill通过提高MLP的性能最多18.6%，并在八个数据集上超过了教师模型，同时实现7倍更快的推理速度和更少130倍的参数数量。此外，进行了广泛的评估，以突出TimeDistill的多功能性和有效性。"}
{"llm_update_time": "20260109", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.06303", "html_url": "https://arxiv.org/abs/2506.06303", "title": "奖励足以：LLMs 在推理时是内部强化学习者", "title_en": "Reward Is Enough: LLMs Are In-Context Reinforcement Learners", "authors": "Kefan Song,Amir Moeini,Peng Wang,Lei Gong,Rohan Chandra,Shangtong Zhang,Yanjun Qi", "background": "强化学习（RL）是一种用于解决序列决策问题的框架。这项研究观察到，令人惊讶的是，在大型语言模型（LLMs）的推理过程中会自发出现强化学习（RL）能力，研究人员称其为上下文内部强化学习（ICRL）。为揭示这种能力，研究引入了一种简化的多轮提示框架，称为ICRL提示，以在推理时自我改善。其目标是指导LLMs在执行任务时通过强化学习来优化自身的表现。", "innovation": "提出了ICRL提示框架，引导LLMs在推理过程中自我改进，通过接收模型的响应后返回的数值反馈（奖励）来逐步优化响应质量。甚至在奖励信号由同一LLM生成时，ICRL提示仍能有效地提升模型性能，这揭示了LLMs在推理时拥有内部进行强化学习的强大能力。", "conclusion": "通过对24点游戏、创意写作、科学世界和奥林匹克级别的数学竞赛（AIME和HMMT）进行评估，ICRL提示方法显示出显著的性能改进，甚至在相同LLM生成奖励信号的情况下也仍能提高性能，从而展示了基于强化学习的新测试时放大规模的潜在途径。"}
{"llm_update_time": "20260109", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2501.03747", "html_url": "https://arxiv.org/abs/2501.03747", "title": "Context-Alignment: 激活与增强大语言模型在时间序列任务中的能力", "title_en": "Context-Alignment: Activating and Enhancing LLM Capabilities in Time Series", "authors": "Yuxiao Hu,Qian Li,Dongxiao Zhang,Jinyue Yan,Yuntian Chen", "background": "近年来，利用预训练的大型语言模型（LLMs）进行时间序列（TS）任务引起了越来越多的关注，涉及激活并增强LLMs的能力。许多方法基于词元级对齐来激活LLMs的能力，但忽略了LLMs在自然语言处理方面的固有优势，即对语言逻辑和结构的深刻理解，而不是表面的嵌入处理。", "innovation": "本文提出了Context-Alignment (CA) 新框架，通过将时间序列数据与LLMs熟悉的语言环境中的语言成分对齐，使LLMs能够理解时间序列数据并激活其能力。具体来说，这种上下文级对齐包括结构对齐和逻辑对齐，通过应用于时间序列-语言多模态输入的Dual-Scale Context-Alignment GNNs (DSCA-GNNs)来实现。该工作提出的Few-Shot prompting Context-Alignment (FSCA) 是CA的一种实现方法，可以灵活并反复集成到预训练LLMs的不同层中，以提高逻辑和结构意识，从而增强性能。", "conclusion": "广泛的实验证明了FSCA的有效性以及Context-Alignment在各种任务中的重要性，特别是在少量样本和零样本预测中，Context-Alignment提供了强大的先验知识。代码已开源。"}
{"llm_update_time": "20260109", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2504.18882", "html_url": "https://arxiv.org/abs/2504.18882", "title": "SPD矩阵学习在神经影像分析中的应用：视角、方法与挑战", "title_en": "SPD Matrix Learning for Neuroimaging Analysis: Perspectives, Methods, and Challenges", "authors": "Ce Ju,Reinmar Kobler,Antoine Collas,Motoaki Kawanabe,Cuntai Guan,Bertrand Thirion", "background": "神经影像学提供了量化远程区域之间连接强度的重要工具，通过不同的模态捕捉不同方面的连接特性。然而，解读有意义的神经信号必须应对与特定模态相关的挑战，包括测量噪声、空间和时间扭曲、异质性采集协议以及样本量有限。当这些数据用对称正定（SPD）值表示时，一种统一的视角出现了：在各种神经影像模态下，SPD值自然导出SPD矩阵，这些矩阵捕捉传感器或大脑区域之间的依赖关系。赋予SPD空间黎曼度量，它具有非欧几里得几何结构，使在形成的流形上进行理论建模和机器学习成为可能。", "innovation": "SPD矩阵学习在跨模态中提供了概念上的清晰性，与神经影像几十年来的几何统计方法有着连续性，并将SPD建模定位为经典分析与新兴人工智能驱动方法之间的方法学桥梁。SPD矩阵学习显示了通过SPD流形建模在数学上自然且数值上稳定，保持对称性和正定性，避免了欧几里得嵌入中的退化现象；扩展了广泛应用于神经影像的已建立的几何统计工具；整合了新一代人工智能技术，推动了一类全新的神经影像问题。", "conclusion": "SPD矩阵学习为下一代神经影像分析提供了一个原则性的前瞻性框架，结合了数学自然性和数值稳定性，引入了新的AI技术，解决了以前无法解决的问题，对于神经科学的未来研究具有重要的应用价值。"}
