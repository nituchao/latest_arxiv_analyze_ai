{"llm_update_time": "20250816", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.10143", "html_url": "https://arxiv.org/abs/2508.10143", "title": "MCP-Orchestrated Multi-Agent System for Automated Disinformation Detection", "title_en": "MCP-Orchestrated Multi-Agent System for Automated Disinformation Detection", "authors": "Alexandru-Andrei Avram,Adrian Groza,Alexandru Lecu", "background": "数字平台上大量的错误信息泛滥对信息完整性构成了重大挑战。这项研究提出了一种使用关系提取技术检测新闻文章中错误信息的多智能体系统，重点是标题和简短的文本片段。", "innovation": "本文创新地提出了一种称为Agentic AI的多智能体系统，该系统通过Model Context Protocol (MCP)调度，结合了四个智能体：机器学习智能体（逻辑回归）、Wikipedia知识检查智能体（依赖于命名实体识别）、连贯性检测智能体（使用大模型提示工程）和从网页抓取数据分析器（提取关系三元组进行事实核查）。", "conclusion": "多智能体组合取得了95.3%的准确性，F1分数为0.964，明显优于单独智能体和传统方法。加权聚合方法从个体智能体误分类率中推导出来，证实了其优于算法阈值优化。模块化架构使系统易于扩展，同时保留了决策过程的细节。"}
{"llm_update_time": "20250816", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.10047", "html_url": "https://arxiv.org/abs/2508.10047", "title": "大语言模型与优化建模相遇：进展与未来方向", "title_en": "A Survey of Optimization Modeling Meets LLMs: Progress and Future Directions", "authors": "Ziyang Xiao,Jingrong Xie,Lilin Xu,Shisi Guan,Jingyan Zhu,Xiongwei Han,Xiaojin Fu,WingYin Yu,Han Wu,Wei Shi,Qingcan Kang,Jiahui Duan,Tao Zhong,Mingxuan Yuan,Jia Zeng,Yuan Wang,Gang Chen,Dongxiang Zhang", "background": "优化建模因其在解决实际问题方面的巨大用途，被广泛应用于各种行业中的最优决策，但过程需要大量来自运筹学专家的专业知识。随着大型语言模型（LLMs）的出现，出现了自动化的建模过程的新机会。", "innovation": "这份综述提供了全面而及时的回顾，涵盖了整个技术堆栈的进步，包括数据合成与微调基础模型、推理框架、基准数据集以及性能评估。分析了基准数据集的质量，发现其出乎意料地具有高水平的错误率，清理了数据集并构建了一个新的排行榜，以公平评估基准模型和数据集的性能。还建立了一个在线门户，集成清理数据集的资源、代码和文献库，以服务于社区。", "conclusion": "指出了当前方法的限制，并概述了未来的研究机会。"}
{"llm_update_time": "20250816", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.10177", "html_url": "https://arxiv.org/abs/2508.10177", "title": "KompeteAI: 加速自主多智能体系统用于端到端机器学习问题管道生成", "title_en": "KompeteAI: Accelerated Autonomous Multi-Agent System for End-to-End Pipeline Generation for Machine Learning Problems", "authors": "Stepan Kulibaba,Artem Dzhalilov,Roman Pakhomov,Oleg Svidchenko,Alexander Gasnikov,Aleksei Shpilman", "background": "近年来，基于大语言模型（LLM）的自动机器学习（AutoML）系统展现了令人印象深刻的性能，但面临着探索策略受限、执行瓶颈严重等问题。具体而言，一次性方法缺乏多样性，蒙特卡洛树搜索（MCTS）方法无法重组强大的部分解，导致探索受限。执行瓶颈则源于代码验证周期过长，影响迭代优化。", "innovation": "我们提出了一种新型AutoML框架KompeteAI，该框架具有动态解空间探索能力。与之前孤立处理想法的MCTS方法不同，KompeteAI引入了组合阶段以组合顶级候选方案。此外，通过集成检索增强生成（RAG），从Kaggle笔记本和arXiv论文中获取想法，整合实际策略来扩展假设空间。KompeteAI还通过预测评分模型和加速调试方法解决了执行瓶颈问题，采用早期阶段指标评估解的潜力，避免昂贵的全代码执行。这种方法加速了管道评估6.9倍。", "conclusion": "KompeteAI在主要AutoML基准测试MLE-Bench上比领先方法（如RD-agent、AIDE和Ml-Master）平均高出3%。我们还提出了Kompete-bench来解决MLE-Bench的局限性，KompeteAI在Kompete-bench上也达到了最先进的效果。"}
{"llm_update_time": "20250816", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.10108", "html_url": "https://arxiv.org/abs/2508.10108", "title": "Amazon Nova AI Challenge -- Trusted AI: Advancing secure, AI-assisted software development", "title_en": "Amazon Nova AI Challenge -- Trusted AI: Advancing secure, AI-assisted software development", "authors": "Sattvik Sahai,Prasoon Goyal,Michael Johnston,Anna Gottardi,Yao Lu,Lucy Hu,Luke Dai,Shaohua Liu,Samyuth Sagi,Hangjie Shi,Desheng Zhang,Lavina Vaz,Leslie Ball,Maureen Murray,Rahul Gupta,Shankar Ananthakrishna", "background": "当前人工智能系统在软件开发中的应用日益增多，但确保其安全性的挑战仍然存在。为了解决这一问题，亚马逊发起了Amazon Nova AI挑战中的Trusted AI赛道。这项全球性竞赛汇集了10支大学团队，旨在推动安全人工智能的发展。竞赛要求参赛团队开发自动化红队机器人或安全的人工智能助手，通过对手一对一的对抗性锦标赛和多轮对话测试AI代码助手的安全对齐。同时，还为团队提供了高质量标注的数据流，以促进持续改进。", "innovation": "大学团队和Amazon Nova AI挑战团队开发了先进的技术方法，引入了基于推理的安全对齐、鲁棒模型准则、多轮突破以及大型语言模型的高效探索等新型解决方案。亚马逊还为挑战投入了大量科学和工程资源，包括构建挑战专用的基准代码专家模型、开发赛事编排服务以及创建评估框架，从而推动了AI安全领域的发展。", "conclusion": "本文概述了大学团队和Amazon Nova AI挑战团队在解决AI软件开发安全性方面的进展，强调了这种合作努力提高了AI安全的标准。"}
{"llm_update_time": "20250816", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.10293", "html_url": "https://arxiv.org/abs/2508.10293", "title": "促进可验证分步奖励下的高效推理", "title_en": "Promoting Efficient Reasoning with Verifiable Stepwise Reward", "authors": "Chuhuai Yue,Chengqi Dong,Yinan Gao,Hang He,Jiajun Chai,Guojun Yin,Wei Lin", "background": "大型推理模型（LRMs）在复杂推理任务中取得了显著进展，但依靠强化学习和可验证奖励。然而，LRMs容易出现过度推理的问题，即在解决简单问题时消耗过多计算资源，导致效率降低。现有的高效推理方法通常需要准确的任务评估来预设令牌预算或选择推理模式，这限制了其灵活性和可靠性。已有研究主要集中在任务评估和预算设定上，但未能有效解决过度推理问题。", "innovation": "本文重新审视了过度推理的本质，发现促进有效步骤并惩罚无效步骤是解决问题的关键。为此，提出了一种基于规则的可验证分步奖励机制（VSRM），该机制根据推理轨迹中中间状态的表现来分配奖励。该方法直观且自然地适应了推理任务的逐步性质。实验表明，该方法在维持原始推理性能的同时，显著减少了输出长度，实现了效率与准确性的良好平衡。进一步的分析显示，训练前后过度推理频率和pass@k分数的下降表明该方法确实有效抑制了无效步骤并促进了有效的推理，从根本上缓解了过度推理问题。", "conclusion": "我们的方法实现了一个有效的平衡，即在维持原始推理性能的同时，显著减少了输出长度，并通过抑制无效步骤和促进有效推理来从根本上缓解过度推理问题。所有代码将在论文被接受后发布。"}
{"llm_update_time": "20250816", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.10164", "html_url": "https://arxiv.org/abs/2508.10164", "title": "通过小型偏好优化精简大型推理模型的长链推理", "title_en": "Pruning Long Chain-of-Thought of Large Reasoning Models via Small-Scale Preference Optimization", "authors": "Bin Hong,Jiayu Liu,Zhenya Huang,Kai Zhang,Mengdi Zhang", "background": "大型推理模型（LRMs）在复杂任务上表现出色，依赖于长链推理。然而，这些模型的长输出增加了计算成本，可能导致过度推理，平衡推理效果与效率成为一大挑战。当前有效推理的方法往往牺牲推理质量或需要大量资源。研究集中于有效减少LRMs生成长度的方法。通过分析生成路径分布并根据难度估计筛选生成轨迹，进而分析基于布雷德利-泰利损失框架的各种偏好优化方法的目标收敛行为，发现直接平衡与负对数似然损失相关的隐性奖励的Length Controlled Preference Optimization (LCPO)方法有效且高效。LCPO能够在有限的数据和训练下学习长度偏好。实验结果表明，该方法能显著降低多个基准上的平均输出长度超过50%，同时保持推理性能。", "innovation": "提出了一种直接平衡与负对数似然损失相关的隐性奖励的Length Controlled Preference Optimization (LCPO)方法，该方法能够在有限的数据和训练下有效学习长度偏好。LCPO能够在减少生成长度的同时保持推理性能，展示了在指导LRMs进行高效推理方面的潜在计算效率方法。", "conclusion": "本研究通过小型偏好优化显著减少了大型推理模型的长生成长度，同时保持了推理性能，为未来的研究提供了新的方向。"}
{"llm_update_time": "20250816", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.10146", "html_url": "https://arxiv.org/abs/2508.10146", "title": "Agentic AI框架：架构、协议与设计挑战", "title_en": "Agentic AI Frameworks: Architectures, Protocols, and Design Challenges", "authors": "Hana Derouiche,Zaki Brahmi,Haithem Mazeni", "background": "大型语言模型（LLMs）的出现为人工智能领域带来了变革性的范式转换，即自主智能体（Agentic AI），其中智能体表现出目标导向的自主性、上下文推理和动态多智能体协同。本文提供了对CrewAI、LangGraph、AutoGen、Semantic Kernel、Agno、Google ADK和MetaGPT等领先Agentic AI框架的系统综述和比较分析。并且，研究还探讨了这些框架的架构原理、通信机制、内存管理、安全护栏以及面向服务计算范式的一致性。此外，本文还指出了该领域的关键局限性、新兴趋势和开放挑战。", "innovation": "本文深入分析了合同网络协议（CNP）、智能体到智能体（A2A）、智能体网络协议（ANP）以及Agora等协议，不仅为Agentic AI系统建立了基础分类体系，还提出了未来研究方向，旨在增强可扩展性、稳健性和互操作性。提供了一个全面的研究参考，帮助研究人员和实践者推进下一代自主AI系统的发展.", "conclusion": "本文不仅为Agentic AI系统建立了基础分类体系，还提出了未来研究方向，旨在增强可扩展性、稳健性和互操作性，为研究人员和实践者提供了全面的研究参考。"}
{"llm_update_time": "20250816", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.10265", "html_url": "https://arxiv.org/abs/2508.10265", "title": "为什么大型语言模型不能永远进行真正的正确推理？", "title_en": "Why Cannot Large Language Models Ever Make True Correct Reasoning?", "authors": "Jingde Cheng", "background": "随着基于大规模语言模型（LLMs）的AIGC工具，例如ChatGPT的广泛应用，许多AI专家和非专业人士认为这些模型拥有理解能力和推理能力。然而，作者认为这些所谓的理解能力和推理能力其实是人们对模糊概念产生的一种错觉。实际上，LLMs从来无法拥有真正的理解能力和真正的推理能力，因为它们的工作原理根本上存在着局限性，无法进行真正的正确推理。", "innovation": "本文旨在揭示LLMs的不足，强调它们无法进行真正的正确推理的本质原因，以及在这种情况下理解它们的能力的限制。", "conclusion": "LLMs受到其工作原理的限制，永远无法进行真正的正确推理，这是作者的主要结论。"}
{"llm_update_time": "20250816", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.10241", "html_url": "https://arxiv.org/abs/2508.10241", "title": "扩展事件熵潜力在人工智能中的不确定性量化与决策", "title_en": "Extending the Entropic Potential of Events for Uncertainty Quantification and Decision-Making in Artificial Intelligence", "authors": "Mark Zilberman", "background": "本文探讨将事件熵潜力的概念应用于人工智能领域，以增强不确定性量化、决策制定和解释性。熵潜力参数量化了离散事件对系统未来熵预期的影响，最初源自物理学，为适应人工智能引入了一种以事件为中心的度量方法，该方法捕捉了行为、观察或其他离散发生对未来时间范围不确定性的影响。通过形式化原始定义和为人工智能调整后的定义，强调条件期望以考虑反事实场景，展示了该方法在策略评估、内在奖励设计、解释性人工智能和异常检测中的应用潜力，旨在统一和加强智能系统中的不确定性建模。该方法结合了热力学、信息论和机器学习的原则，为管理人工智能中的不确定性提供了理论基础、可解释性和灵活性的方法。通过理论与实例说明该方法的应用场景，并讨论在复杂人工智能模型中计算的实际考虑。", "innovation": "提出了一种扩展的熵潜力框架，利用事件熵潜力参数，该参数量化了离散事件对未来熵预期的影响。通过引入事件为中心的度量方法，该框架能捕捉行为、观察或其他离散事件对未来不确定性的影响。同时，通过形式化原始定义和适应人工智能的定义，强调条件期望以考虑反事实场景，扩大了熵潜力的应用范围，特别是在政策评估、内在奖励设计、解释性人工智能和异常检测方面。这种方法将热力学、信息论和机器学习的原则相结合，提供了一种理论支持、可解释性和适应性强的方法来管理人工智能中的不确定性。", "conclusion": "该熵潜力框架提供了一种理论支持、解释性和适应性强的方法来管理人工智能中的不确定性，该方法结合了热力学、信息论和机器学习的原则，通过现实与实例展示了其在强化学习、贝叶斯推断和异常检测中的应用潜力，强调了其在统一和加强智能系统中的不确定性建模方面的作用。同时，讨论了在复杂人工智能模型中计算的实际考虑。"}
{"llm_update_time": "20250816", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.10340", "html_url": "https://arxiv.org/abs/2508.10340", "title": "多智能体信任区域策略优化：联合约束方法", "title_en": "Multi-Agent Trust Region Policy Optimisation: A Joint Constraint Approach", "authors": "Chak Lam Shek,Guangyao Shi,Pratap Tokekar", "background": "多智能体强化学习（MARL）需要参与智能体之间的协调和稳定的策略更新。Heterogeneous-Agent Trust Region Policy Optimization (HATRPO) 使用Kullback-Leibler（KL）散度来实施每个智能体的信道区域约束，以稳定训练过程。然而，为每个智能体分配相同的KL阈值可能导致缓慢且局部最优的更新，尤其是在不同智能体之间混合作用的环境中。", "innovation": "为了克服上述限制，该研究提出了两种分配KL散度阈值的方法：基于Karush-Kuhn-Tucker（KKT）的HATRPO-W方法和基于贪婪算法的HATRPO-G方法。这两者都连接了序列策略优化与约束阈值调度，使得在不同智能体的环境中能够实现更灵活和有效的学习。实验结果表明，相比原有方法，这些方法显著提升了HATRPO的表现，实现了更快的收敛和更高的最终奖赏。", "conclusion": "对比HATRPO-W和HATRPO-G，两者在最终表现上的改进程度相当，并且均获得了超过22.5%的提升，值得注意的是，HATRPO-W在学习动态方面更为稳定，反映出更低的方差。"}
{"llm_update_time": "20250816", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.10358", "html_url": "https://arxiv.org/abs/2508.10358", "title": "用TurtleSoup谜题探究大语言模型的创造性推理", "title_en": "What to Ask Next? Probing the Imaginative Reasoning of LLMs with TurtleSoup Puzzles", "authors": "Mengtao Zhou,Sifan Wu,Huan Zhang,Qi Sima,Bang Liu", "background": "现有基准测试往往静态或侧重社会推理，未能捕捉创造性推理这一动态探索过程的本质。因此，本文通过基于经典“Turtle Soup”游戏的研究框架来填补这一空白，提出了第一个大规模、双语、互动的创造性推理基准——TurtleSoup-Bench，以及一个名为Mosaic-Agent的新颖评估代理，用于评估大语言模型的表现。", "innovation": "本文引入了TurtleSoup-Bench，这是第一个用于创造性推理的大型、双语、交互式基准。同时，该论文提出了Mosaic-Agent，这是一个针对创造性推理环境设计的新颖评估代理。此外，还开发了一个多维度的评估协议，用于衡量逻辑一致性、细节完善性和结论一致性。实验结果表明，大语言模型在创造性推理方面存在明显的局限性、常见的失败模式和与人类相比的巨大性能差距。这些结果为未来关于探索性代理行为的研究提供了新见解并建立了基础。", "conclusion": "本文的工作为大语言模型的创造性推理提供了新的见解，并建立了未来关于探索性代理行为研究的基础。"}
{"llm_update_time": "20250816", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.10152", "html_url": "https://arxiv.org/abs/2508.10152", "title": "提高和评估开放深度研究代理", "title_en": "Improving and Evaluating Open Deep Research Agents", "authors": "Doaa Allabadi,Kyle Bradbury,Jordan M. Malof", "background": "文章关注深度研究代理（DRAs），这是一种可以通过自然语言提示独立搜索和使用互联网内容来回应用户需求的系统。尽管已有DRAs在公共基准测试中显示了出色的性能，但最近的研究主要集中在专有的封闭源代码系统上。在工作进行时，研究人员仅发现一个开源DRAs，称为Open Deep Research (ODR)。为了评估ODR及其他现有的封闭源代码系统，作者将具有挑战性的 recent BrowseComp 比赛基准拆分为更易于处理的 BC-Small，旨在为学术实验室提供一个基准。三个封闭源代码系统的性能测试结果表明，这些系统在60个问题的测试集上均未能获得任何准确性。为了改善ODR的表现，作者引入了三项策略改进，开发出性能更优的ODR+模型，在BC-Small基准测试中达到了10%的成功率，这是所有封闭源代码和开源系统中的最高水平。进一步的消融研究显示，每一个改进都对ODR+的成功做出了贡献。", "innovation": "文章的主要创新之处在于提出将具有挑战性的最近的BrowseComp基准拆分为更加易于处理的BC-Small，并用于评估开源和封闭源代码的DRAs。此外，还通过引入三项策略改进（分别命名为ODR+），显著提高了ODR的成功率并达到了最高性能。", "conclusion": "文章总结表明，通过对ODR进行三项关键改进，ODR+在BC-Small基准测试中达到了10%的成功率，在开放源代码和封闭源代码系统中都是最优的。此外，通过消融研究表明，每个改进都对最终性能的提高有重要贡献。文章强调了开源DRAs与专有系统之间的对比评估，以及在公共研究领域提供了一个更为可行的评估基准。"}
{"llm_update_time": "20250816", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.10433", "html_url": "https://arxiv.org/abs/2508.10433", "title": "We-Math 2.0：一种激励视觉数学推理的多功能MathBook系统", "title_en": "We-Math 2.0: A Versatile MathBook System for Incentivizing Visual Mathematical Reasoning", "authors": "Runqi Qiao,Qiuna Tan,Peiqing Yang,Yanzi Wang,Xiaowan Wang,Enhui Wan,Sitong Zhou,Guanting Dong,Yuchen Zeng,Yida Xu,Jie Wang,Chong Sun,Chen Li,Honggang Zhang", "background": "现有的多模态大型语言模型（MLLMs）虽在各类任务中展现了出色的性能，但在复杂数学推理方面仍存在不足。现有研究主要集中在数据集构建和方法优化上，往往忽视了全面的知识驱动设计和以模型为中心的数据空间建模。", "innovation": "论文提出了We-Math 2.0，这是一个集成了结构化数学知识系统、以模型为中心的数据空间建模和基于强化学习（RL）的训练范式的一体化系统，旨在全面增强MLLMs的数学推理能力。其创新点包括：（1）构建了一个五级层次的知识系统，涵盖491个知识点和1,819个基础原则。（2）开发了MathBook-Standard和MathBook-Pro，前者确保广泛的概念覆盖和灵活性，后者构建了七个难度等级的逐步变体，用于应对挑战性训练。（3）提出了一个两阶段RL框架，包括启动阶段精细调优和逐步对齐RL。（4）研发了一个全面的评估基准MathBookEval，涵盖了491个知识点。", "conclusion": "实验结果表明，We-Math 2.0在四个广泛应用的基准上与现有基线竞争，并在MathBookEval上取得了出色的结果，显示出在数学推理方面的良好泛化能力。"}
{"llm_update_time": "20250816", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.10486", "html_url": "https://arxiv.org/abs/2508.10486", "title": "SEQ-GPT: LLM辅助的空间查询通过示例", "title_en": "SEQ-GPT: LLM-assisted Spatial Query via Example", "authors": "Ivan Khai Ze Lim,Ningyi Liao,Yiming Yang,Gerald Wei Yong Yip,Siqiang Luo", "background": "当前空间服务，如在线地图，主要依赖用户查询来进行位置搜索。但是，当执行复杂的任务，例如同时搜索一组地点时，用户体验会受到限制。在这种背景下，研究了空间示例查询（SEQ）场景，这是一种基于用户提供的示例联合搜索多个相关地点的扩展查询方式。", "innovation": "引入了基于大型语言模型（LLMs）的SEQ-GPT空间查询系统，以实现更具多功能性的自然语言驱动的SEQ搜索。通过利用LLMs的语言能力，能够在SEQ过程中提供多功能的交互操作，例如引导用户澄清查询详情并根据用户反馈动态调整搜索。同时，提出了一种针对自然语言与结构化空间数据和查询进行对齐的定制LLM适应管道，通过对话合成和多模型合作来进行。", "conclusion": "SEQ-GPT为使用现实数据和应用场景扩展空间搜索提供了一个端到端的演示。"}
{"llm_update_time": "20250816", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.10429", "html_url": "https://arxiv.org/abs/2508.10429", "title": "MM-Food-100K: 具有可验证来源的大规模多模态食品智能数据集", "title_en": "MM-Food-100K: A 100,000-Sample Multimodal Food Intelligence Dataset with Verifiable Provenance", "authors": "Yi Dong,Yusuke Muraoka,Scott Shi,Yi Zhang", "background": "该研究介绍了MM-Food-100K，这是一个包含100,000个样本的公开多模态食品智能数据集，并且具有可验证的来源。此数据集来源于Codatta贡献模型，结合了社区共享和可配置的AI辅助质量检查，从超过87,000名贡献者的图片中收集了120,000个高质量的食品图像，并经过广泛的信息标注（如菜品名称、创造地区等）。这些图像在六周内通过安全的链下账本链接到钱包地址，并计划在区块链上实施完整的协议。", "innovation": "该数据集的独特之处在于其可验证的来源和高质量的收集过程，通过结合社区贡献和AI辅助的质量检查，确保数据的质量和可信度。此外，该数据集通过大规模的多模态图像和描述信息的匹配，提供了一种新的方式来训练和验证大型视觉语言模型，特别是在食品营养预测方面的应用。", "conclusion": "研究通过在多个大型视觉语言模型（包括ChatGPT 5、ChatGPT OSS、Qwen-Max）上进行微调，验证了MM-Food-100K数据集的应用价值，显示了这种数据集在多模态食品智能领域的潜在意义。该数据集公开免费提供给公众，约90%的数据保留用于潜在的商业访问，并与贡献者分享收益。"}
{"llm_update_time": "20250816", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.10337", "html_url": "https://arxiv.org/abs/2508.10337", "title": "基于强化学习的课程学习方法：利用RAG进行多模态问答", "title_en": "A Curriculum Learning Approach to Reinforcement Learning: Leveraging RAG for Multimodal Question Answering", "authors": "Chenliang Zhang,Lin Wang,Yuanyuan Lu,Yusheng Qi,Kexin Wang,Peixu Hou,Wenshi Chen", "background": "Dianping-Trust-Safety团队参与了META CRAG-MM挑战，需要构建一个综合检索增强生成系统，用于多模式多轮问答。该竞赛包括三个任务：一是使用基于图像的知识图谱检索的结构化数据回答问题；二是将知识图谱和网络搜索结果中的信息进行综合；三是处理需要理解上下文并从多个来源聚合信息的多轮对话。在任务1中，通过结合视觉大型语言模型和自监督fine-tuning技术，提升了回答准确性和减少幻觉。在任务2和任务3中，通过利用网络搜索API，增强了系统的外部知识获取能力，从而更好地处理复杂查询和多轮对话。", "innovation": "提出了一种结合课程学习与强化学习的方法，通过监督微调技术使用GPT-4.1的知识，指导强化学习，提升了回答准确性和降低了幻觉。利用网络搜索API，确保系统能够更好地处理复杂查询和多轮对话，取得了显著的效果。", "conclusion": "该方法在任务1中获得了第一名，领先优势达52.38%，并在任务3中获得了第三名，表明课程学习与强化学习的结合在训练流程中的有效性得到了验证。"}
{"llm_update_time": "20250816", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.10391", "html_url": "https://arxiv.org/abs/2508.10391", "title": "LeanRAG：基于本体生成的语义聚合和分层检索", "title_en": "LeanRAG: Knowledge-Graph-Based Generation with Semantic Aggregation and Hierarchical Retrieval", "authors": "Yaoze Zhang,Rong Wu,Pinlong Cai,Xiaoman Wang,Guohang Yan,Song Mao,Ding Wang,Botian Shi", "background": "检索增强生成（RAG）通过利用外部知识在大型语言模型中起着关键作用，但其效果往往受到上下文错误或不完整信息检索的影响。现有基于知识图谱的RAG方法已发展出分层结构，将知识组织成多级摘要，但仍存在两个未解决问题：高层概念摘要是孤立的“语义岛屿”，缺乏用于跨社区推理的隐式关系；以及检索过程本身保持结构未知，通常退化为无效的平面搜索，未能充分利用图的丰富拓扑结构。这些限制促使了LeanRAG的提出。", "innovation": "LeanRAG通过一种深度协作设计融合了知识聚合和检索策略。它首先使用一项新颖的语义聚合算法，形成实体集群，并在聚合级别摘要之间构建新的显式关系，创建一个可完全导航的语义网络。然后采用自底向上的结构引导式检索策略，将查询锚定到最相关的细粒度实体，并系统地沿着图的语义路径遍历以收集简洁且上下文全面的证据集。此外，LeanRAG还减少了路径检索的显著开销并最小化了冗余信息检索。这些创新使得LeanRAG在四种不同领域的挑战性问答基准测试中显著优于现有方法，同时减少了46%的检索冗余。", "conclusion": "通过广泛实验表明，LeanRAG在响应质量方面表现出色，相较于现有方法提升了显著的性能，同时减少了大量不必要的检索量。源代码可在指定网址获取。"}
{"llm_update_time": "20250816", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.10467", "html_url": "https://arxiv.org/abs/2508.10467", "title": "FIRESPARQL：一种基于大规模语言模型的用于学术知识图谱的SPARQL查询生成框架", "title_en": "FIRESPARQL: A LLM-based Framework for SPARQL Query Generation over Scholarly Knowledge Graphs", "authors": "Xueli Pan,Victor de Boer,Jacco van Ossenbruggen", "background": "学者型知识图谱（SKGs）的内容复杂，结构精细，因此基于自然语言的问题回答仍然是一个挑战。现有的大语言模型（LLM）方法可以通过将自然语言问题（NLQs）转化为SPARQL查询来解决这一问题，但由于对知识图谱特定内容和底层模式的了解有限，这些基于LLM的方法在生成SPARQL查询时面临困难。常见的错误包括结构不一致（如查询中遗漏或冗余的三元组）和语义不准确（如查询中展示的实体或属性错误），尽管查询结构正确。", "innovation": "提出了一种名为FIRESPARQL的模块化框架，该框架以微调的语言模型为核心组件，可选地通过检索增强生成（RAG）提供上下文，并包含用于SYARQL查询校正的层。该框架通过科学问题与答案基准进行了评估，并与基线和最先进的方法进行了比较，使用BLEU和ROUGE指标评估查询精度，使用放松精确匹配（RelaxedEM）评估查询结果精度。实验结果表明，微调方法在查询和结果精度方面表现最佳，分别达到了0.90的ROUGE-L和0.85的RelaxedEM。", "conclusion": "通过微调的语言模型框架FIRESPARQL能够有效改善SPARQL查询生成的准确性和效率。未来的工作可以在更多样化的数据集上进行进一步研究，以提升模型在不同场景下的适用性。"}
{"llm_update_time": "20250816", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.10425", "html_url": "https://arxiv.org/abs/2508.10425", "title": "HiRef: 利用层次化本体和网络精炼实现稳健的药物推荐", "title_en": "HiRef: Leveraging Hierarchical Ontology and Network Refinement for Robust Medication Recommendation", "authors": "Yan Ting Chok,Soyon Park,Seungheun Baek,Hajung Kim,Junhyun Lee,Jaewoo Kang", "background": "药物推荐是一个至关重要的任务，可以帮助医生从患者的随访记录中及时做出决策。然而，现实世界的电子病历（EHR）数据由于罕见的医疗实体频繁出现和不完整的记录，可能无法完全捕捉临床真相，而带来了显著的挑战。基于EHR的纵向数据训练的数据驱动模型虽然通常具有强大的实验表现，但在缺失条件或新型条件下的泛化能力较差，这主要归因于其对观察到的相关模式的依赖。为了应对这些挑战，本文提出了一种统一框架HiRef（层次本体和网络精炼为稳健的药物推荐），结合了两种互补结构：(i) 学术整理的医疗本体中编码的层次语义，(ii) 来自现实世界EHR的精炼共现模式。通过将本体实体嵌入双曲空间，自然地捕捉树状关系，从而通过共享祖先进行知识传递，提高了对未见代码的泛化能力。为增强鲁棒性，引入了基于先验的稀疏正则化方案，通过抑制无用边并保留临床相关的关联来细化EHR共现图。", "innovation": "提出的HiRef框架结合了层次化的本体编码和从现实世界EHR精炼得到的共现模式，通过将本体实体嵌入双曲空间来改善未见代码的泛化能力，并通过先验引导的稀疏正则化方案来进一步提高模型的鲁棒性，抑制无用边并保留临床相关的关联。在MIMIC-III和MIMIC-IV等EHR基准测试中实现了强劲的表现，并在模拟未见过的医疗代码设置中保持了高准确性。详尽的实验和消融分析支持了HiRef在未见过的医学代码下的鲁棒性，通过对学习到的稀疏化图结构和医学代码嵌入进行深入分析来验证其有效性。", "conclusion": "本文提出的HiRef框架在EHR基准测试（MIMIC-III和MIMIC-IV）中表现出色，并在模拟未见过的代码设置中保持了高准确性。广泛的实验和全面的消融研究表明，HiRef在未见过的医学代码下的鲁棒性较强，通过分析学习到的稀疏化图结构和医学代码嵌入验证了其有效性。"}
{"llm_update_time": "20250816", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.10539", "html_url": "https://arxiv.org/abs/2508.10539", "title": "通过低成本方差减少改进基于价值的过程验证", "title_en": "Improving Value-based Process Verifier via Low-Cost Variance Reduction", "authors": "Zetian Sun,Dongfang Li,Baotian Hu,Min Zhang", "background": "大规模语言模型（LLMs）已经在多种任务中取得了显著的成功，但在逻辑推理能力，特别是在数学等复杂领域方面仍面临重大挑战。基于价值的过程验证器通过估算部分推理链达到正确解的概率来预测证明准确性，但其准确性往往受限于训练注释中的估计误差，这是因为Monte Carlo（MC）样本数量受限于LLM推理的成本高昂。", "innovation": "本文作者发现估计误差主要来源于高方差而非偏差，而MC估计器是无偏最小方差无偏估计（MVUE）。为此，提出了一种新的方法——Comaptive Monte Carlo Sampling（ComMCS），通过从当前步骤和后续步骤的MC估计器进行线性组合来构造新的无偏估计器。理论上证明了该方法可以在不增加LLM推理成本的情况下减少方差，保持无偏估计。此外，通过MATH-500和GSM8K基准测试，结果表明ComMCS方法有效，比基于回归的优化方法提高了2.8个点，比非方差减少的基线提高了2.2个点。", "conclusion": "我们的方法证明了在低成本的情况下可以有效地减少方差，提高基于价值的过程验证器的准确性。通过实验，该方法在MATH-500基准测试中显示出显著的优越性。"}
{"llm_update_time": "20250816", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.10599", "html_url": "https://arxiv.org/abs/2508.10599", "title": "MSRS: 自适应多子空间表示校正以实现大型语言模型的属性对齐", "title_en": "MSRS: Adaptive Multi-Subspace Representation Steering for Attribute Alignment in Large Language Models", "authors": "Xinyan Jiang,Lin Zhang,Jiayi Zhang,Qingsong Yang,Guimin Hu,Di Wang,Lijie Hu", "background": "大型语言模型的激活引导提供了一种有前景的方法来通过直接操控其内部激活来控制其行为。然而，现有的大多数方法在同时引导多个属性方面面临挑战，通常会导致相互干扰和不希望的权衡。", "innovation": "我们提出了多子空间表示校正（MSRS），这是一种新颖的框架，用于通过子空间表示微调实现有效的多属性引导。MSRS通过为每个属性分配正交子空间来减少属性间干扰，将它们的影响隔离在模型的表示空间中。此外，MSRS采用了一种混合子空间组合策略：它将属性特定的子空间与共享子空间相结合，以实现不同的校正方向。动态权重函数学习有效地整合这些组件以实现精确控制。在推理阶段，MSRS引入了一种令牌级引导机制，以动态识别并干预最具有语义相关性的令牌，从而实现细微的行为调节。", "conclusion": "实验结果表明，MSRS显著减少了属性冲突，超越了现有的方法，并在多种属性中取得了有效泛化到不同下游任务的表现。"}
{"llm_update_time": "20250816", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.10501", "html_url": "https://arxiv.org/abs/2508.10501", "title": "PASS: Probabilistic Agentic Supernet Sampling for Interpretable and Adaptive Chest X-Ray Reasoning", "title_en": "PASS: Probabilistic Agentic Supernet Sampling for Interpretable and Adaptive Chest X-Ray Reasoning", "authors": "Yushi Feng,Junye Du,Yingying Hong,Qifan Wang,Lequan Yu", "background": "现有的工具增强型代理系统在实际应用中受到黑盒推理步骤的限制，这些步骤会削弱决策制定的信任，带来安全风险；同时，这些系统在多模态集成上表现不佳，这对医疗保健任务至关重要；此外，还存在代理管道的刚性和计算效率低的问题。在胸部X光（CXR）推理这样的复杂任务中，多模态医疗数据的处理带来了额外挑战。", "innovation": "本文提出了PASS（Probabilistic Agentic Supernet Sampling），这是一种多模态框架，旨在解决上述问题。PASS能够自适应地从多工图中采样代理工作流程，从而生成带有可解释概率的决策路径。通过利用任务条件下的代理超网络分布，PASS可以在每个超网络层上选择最合适的工具，提供带有概率注解的轨迹，方便后续审计，同时增强医疗AI的安全性。此外，PASS还能够将关键发现压缩到动态更新的个性化记忆中，并决定是否深入推理路径或提前退出，以提高效率。为了优化性能和成本之间的平衡，PASS设计了一种新颖的三阶段训练过程，包括专家知识预热、对比路径排名和成本感知强化学习。为了促进严格的评估，作者提出了CAB-E，一个全面的多步骤、安全关键的自由形式CXR推理基准测试。", "conclusion": "实验结果表明，PASS在多个指标（例如准确率、AUC和LLM-J）上显著优于强基线，同时兼顾计算成本，从而推动了一种新的范式转变，即可解释的、适应性强的和多模态的医疗代理系统。"}
{"llm_update_time": "20250816", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.10703", "html_url": "https://arxiv.org/abs/2508.10703", "title": "GenOM：使用描述生成和大规模语言模型的本体匹配", "title_en": "GenOM: Ontology Matching with Description Generation and Large Language Model", "authors": "Yiping Song,Jiaoyan Chen,Renate A. Schmidt", "background": "本体匹配（OM）在实现跨异构知识源的语义互操作性和集成中发挥着关键作用，尤其是在包含大量与疾病和药物相关复杂概念的生物医药领域。", "innovation": "提出了基于大规模语言模型（LLM）的本体对齐框架GenOM，通过生成文本定义来丰富本体概念的语义表示，使用嵌入模型检索对齐候选，并结合精确匹配工具以提高精确度。", "conclusion": "在OAEI Bio-ML竞赛轨线上进行的广泛实验表明，GenOM经常能达到竞争力的表现，超越了许多基线，包括传统的本体匹配系统和最新的基于大规模语言模型的方法。进一步的消融研究表明，语义丰富和少量提示的有效性，突显了该框架的稳健性和适应性。"}
{"llm_update_time": "20250816", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.10669", "html_url": "https://arxiv.org/abs/2508.10669", "title": "STEP：面向对话推荐中的上下文知识融合的逐步 Curriculum 学习", "title_en": "STEP: Stepwise Curriculum Learning for Context-Knowledge Fusion in Conversational Recommendation", "authors": "Zhenye Yang,Jinpeng Chen,Huan Li,Xiongnan Jin,Xuanyang Li,Junwei Zhang,Hongbo Gao,Kaimin Wei,Senzhang Wang", "background": "对话推荐系统（CRSs）旨在通过自然语言对话主动捕捉用户偏好并推荐高质量项目。现有的 CRS 存在捕捉深层次用户偏好和对话上下文能力不足的问题，特别是在将外部知识图谱（KG）信息高效集成到对话生成和推荐中的挑战仍然亟待解决。传统方法通常直接将 KG 信息与对话内容结合，这往往难以处理复杂的语义关系，导致推荐结果可能不符合用户期望。", "innovation": "本文介绍了一种名为 STEP 的对话推荐系统，该系统围绕预训练语言模型结合基于课程指导的上下文-知识融合与轻量级任务特定提示调优。STEP 通过三个阶段的课程逐渐将对话上下文与知识图谱实体对齐，解决细粒度的语义矛盾。此外，通过两个最小但适应性的前缀提示——对话前缀引导响应生成并向用户意图靠拢，以及推荐前缀偏向下知识一致的候选品评分——实现在推荐和对话任务之间共享跨任务语义的同时尊重各自的目标。实验结果表明，STEP 在两个公开数据集中的推荐精度和对话质量上超越了主流方法。", "conclusion": "实验结果表明，STEP 在两个公开数据集中能够实现更高精度的推荐和更高质量的对话。"}
{"llm_update_time": "20250816", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.10530", "html_url": "https://arxiv.org/abs/2508.10530", "title": "首先是多样，然后是质量：语言模型对齐的两阶段假设", "title_en": "Diversity First, Quality Later: A Two-Stage Assumption for Language Model Alignment", "authors": "Zetian Sun,Dongfang Li,Baotian Hu", "background": "语言模型与人类偏好对齐对于构建可靠的AI系统至关重要。通常将问题定义为优化语言模型的策略，以最大化反映人类偏好的预期奖励。Direct Preference Optimization (DPO) 是一种直接从静态偏好数据优化策略的方法，通过结合在线政策采样（即，在训练循环中生成的偏好候选）进一步改进了语言模型的对齐。然而，研究表明，与静态数据相比，在线数据的效果并不总是最佳，两者在效果上存在系统性的差异。例如，对于Llama-3，使用在线数据的有效性是静态数据的3倍，而对Zephyr来说是0.4倍。", "innovation": "研究提出了对齐阶段假设，将对齐过程划分为两个阶段：偏好注入阶段，偏好多样性有益；偏好微调阶段，高质量数据更为关键。通过理论和实证分析，研究界定了这两个阶段，并提出了一种有效算法来识别它们之间的边界。该假设和测量方法在5个模型（Llama、Zephyr、Phi-2、Qwen、Pythia）和2种对齐方法（DPO、SLiC-HF）上进行了实验，证明了对齐阶段假设和边界测量的普适性。", "conclusion": "本研究基于对动态和静态偏好数据效果差异的研究，提出了语言模型对齐的两阶段假设，通过实验证明有效，并提出了一种区分这些阶段的方法。"}
{"llm_update_time": "20250816", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.10747", "html_url": "https://arxiv.org/abs/2508.10747", "title": "扩大规模而不淡化效果：基于目标的稀疏GNN在RL驱动的通用规划中的应用", "title_en": "Scaling Up without Fading Out: Goal-Aware Sparse GNN for RL-based Generalized Planning", "authors": "Sangwoo Jeon,Juchul Shin,Gyeong-Tae Kim,YeonJe Cho,Seongwoo Kim", "background": "通用规划（使用PDDL描述的符号规划领域）中使用深度强化学习（RL）和图神经网络（GNNs）的方法已经显示出在不同领域的有希望的结果。然而，现有的方法通常将规划状态表示为完全连接的图，导致边缘信息的组合爆炸和随着问题规模的增长变得愈发稀疏，特别是在大型网格环境中这一问题尤为明显。这种密集表示导致节点级别信息淡化，内存需求呈指数级增长，并最终使得学习对于更大规模的问题变得不可行。", "innovation": "本文提出了一种稀疏、目标导向的GNN表示方法，能够选择性地编码相关的地方关系，并显式地整合与目标相关的空间特征。通过在基于PDDL设计的新无人机任务场景中的网格世界中验证该方法，实验结果显示该方法能够有效地扩展到以前因为密集图表示而不切实际的大网格规模，并且在策略泛化和成功率方面有所提高。", "conclusion": "实验结果表明，本文的方法能够有效地扩展到以前因为密集图表示而不切实际的大网格规模，并且在策略泛化和成功率方面有所提高。这些发现为解决真实、大规模的通用规划任务提供了实用的基础。"}
{"llm_update_time": "20250816", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.10745", "html_url": "https://arxiv.org/abs/2508.10745", "title": "Agentic Design Review System", "title_en": "Agentic Design Review System", "authors": "Sayan Nag,K J Joseph,Koustava Goswami,Vlad I Morariu,Balaji Vasan Srinivasan", "background": "评估图形设计通常涉及到从多个方面进行评估，如对齐、构成、美观性和颜色选择。传统的评估方法通常是通过个体专家评审者的反馈汇总来进行。然而，全面地评估设计需要一种更为系统化的方法，能够从多个角度收集反馈，并生成具体可行的建议。为此，该研究提出了一种基于多代理系统的Agentic Design Review System (AgenticDRS) 方法，通过一个元代理的协调，多个代理来协作分析一个设计。这种方法的关键在于一种基于图匹配的上下文相关范例选择方法以及一种独特的提示扩展方法，以使每个代理都对设计有清晰的理解。", "innovation": "该研究的创新点在于提出了一种新的范例选择方法，基于图匹配；一种独特的提示扩展方法；以及一种多代理系统，由元代理协调，用于协同分析和评估图形设计。该方法通过与最先进的基准进行彻底的实验评估，以及关键的裁剪实验，展示了在评估图形设计和生成具体可行反馈方面的有效性。", "conclusion": "该研究通过提出的Agentic-DRS框架和DRS-BENCH基准，系统性地评估了图形设计，并生成了具体的反馈。研究希望这一工作能够引起对该实践但尚待深入研究的研究方向的关注。"}
{"llm_update_time": "20250816", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.10777", "html_url": "https://arxiv.org/abs/2508.10777", "title": "知识推理分离：临床自然语言推理中LLMs的基本局限性", "title_en": "The Knowledge-Reasoning Dissociation: Fundamental Limitations of LLMs in Clinical Natural Language Inference", "authors": "Maël Jullien,Marco Valentino,André Freitas", "background": "通常认为大规模语言模型通过增加数据和参数的数量就能逐渐获得越来越结构化和普适的内部表示。然而，本文通过引入一个由四个推理类别组成的临床试验自然语言推理基准（Causal Attribution、Compositional Grounding、Epistemic Verification、Risk State Abstraction），来质疑这一假设。每个项目都配有对应的Ground Knowledge和Meta-Level Reasoning Verification（GKMRV）探针，使我们能够区分事实访问失败和推理失败，并评估六种当前的LLM模型在不同提示方式下的表现。", "innovation": "本文创新地提出了一个包含四个推理类别的临床试验自然语言推理基准，并通过Ground Knowledge和Meta-Level Reasoning Verification（GKMRV）探针将知识访问失败与推理失败分离出来。这种分离使得我们能够明确衡量和探查LLMs在高风险领域的可靠性，同时揭示了结构上和表示上的基本局限性。", "conclusion": "当前的LLMs虽然普遍拥有关联的临床知识，但在实际推理任务中表现不佳，这表明它们缺乏可靠的结构化和可组合的内部表示，比如整合约束、评估证据或模拟反事实。GKMRV将这种分离明确化，为评测LLMs的实际可靠性提供了一个有效框架。"}
{"llm_update_time": "20250816", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.10769", "html_url": "https://arxiv.org/abs/2508.10769", "title": "建模对多模态AI内容的人类响应", "title_en": "Modeling Human Responses to Multimodal AI Content", "authors": "Zhiqi Shen,Shaojing Fan,Danni Xu,Terence Sim,Mohan Kankanhalli", "background": "随着AI生成内容的普及，信息失真的风险也在增加。现有研究主要集中在验证内容的 authenticity 上，但对这类内容如何影响人类的感知和行为知之甚少。特别是在交易或股票市场等领域，预测人类对信息的反应比验证其准确性更为关键。因此，本文提出了一种以人类为中心的方法，通过构建包含154,552条在线帖子的MhAIM数据集（其中111,153条为AI生成内容），来分析人类对AI生成内容的反应。研究发现，当文本和视觉存在不一致时，人们更善于识别AI内容。", "innovation": "本文提出MhAIM数据集和新的信任度、影响度和开放度三个量化指标，还提出了T-Lens，一个基于LLM的代理系统，通过结合预测的人类响应来回答用户的多模态信息查询。T-Lens的核心是HR-MCP（人类响应模型上下文协议），基于标准化的模型上下文协议MCP，能够无缝集成任何LLM。这项工作提供了一种实用的方法来赋予LLM人类意识能力，通过建模人类对多模态AI内容的响应，增强了对AI驱动信息失真的风险的干预策略。", "conclusion": "通过建模人类对AI生成内容的响应，本文提供了实证见解和实用工具，帮助LLM更好地理解人类反应，增强了信息交互的能力。研究提出了应对AI驱动信息失真风险的实操策略。"}
{"llm_update_time": "20250816", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.10806", "html_url": "https://arxiv.org/abs/2508.10806", "title": "谁受益于AI解释？迈向可访问且具有解释性的系统", "title_en": "Who Benefits from AI Explanations? Towards Accessible and Interpretable Systems", "authors": "Maria J. P. Peixoto,Akriti Pandey,Ahsan Zaman,Peter R. Lewis", "background": "随着人工智能系统在关键领域中的应用越来越多，提高这些系统的可解释性已经成为提升其输出理解度的关键手段，使用户能够做出更加明智和有意识的选择。然而，尽管人们对解释性人工智能（XAI）的可用性兴趣逐渐增加，但对于视觉障碍用户来说，这些方法的可访问性仍然被忽视。已有研究中，对XAI技术的评估很少包含残疾用户，并且大多解释依赖于内在的视觉格式。", "innovation": "本文通过双管齐下的方法探讨了XAI中的可访问性差距。（1）对79篇研究文献的回顾发现，对XAI技术的评估很少包括残疾用户，大多数解释依赖于内在的视觉格式；（2）提出了一种四部分的方法论概念验证，具体步骤包括：（1）AI系统的分类，（2）人物定义和情境化，（3）原型设计和实现，（4）专家和用户对XAI技术进行可访问性评估。初步发现表明，简化解释对于非视觉用户来说更容易理解，而且多模态呈现对于更公平的可解释性是必要的。", "conclusion": "简化解释对于非视觉用户来说更容易理解，而且多模态呈现对于更公平的可解释性是必要的。方法性概念验证表明，XAI设计需要考虑不同用户群体的可访问性和解释性需求，特别是视觉障碍用户。"}
{"llm_update_time": "20250816", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.09991", "html_url": "https://arxiv.org/abs/2508.09991", "title": "在BC癌症登记处引入现代自然语言处理技术：AI创新与医疗需求的桥梁", "title_en": "Bridging AI Innovation and Healthcare Needs: Lessons Learned from Incorporating Modern NLP at The BC Cancer Registry", "authors": "Lovedeep Gondara,Gregory Arbour,Raymond Ng,Jonathan Simkin,Shebnum Devji", "background": "自动化从临床文档中提取数据在提高医疗保健环境中效率方面具有巨大潜力，但部署自然语言处理(NLP)解决方案存在实际挑战。本文基于在不列颠哥伦比亚癌症登记处(BCCR)实施各种NLP模型进行信息提取和分类任务的经验，分享了项目全生命周期中的重要教训。", "innovation": "文章强调了基于明确的业务目标而非单纯的技术准确性定义问题的重要性、采用迭代开发方法以及从项目开始就促进跨学科深度合作和参与设计的重要性。进一步的见解包括对模型选择的实用考量（包括适当的混合方法和更简单的方法）、对数据质量（代表性、漂移和标注）的严格关注、人类介入循环验证和持续审计等稳健错误缓解策略的重要性，以及建立组织人工智能素养等方面的具体指导。这些实用考虑不仅适用于癌症登记处，还为寻求成功实施AI/NLP解决方案以增强数据管理流程和最终改善患者护理和公共卫生结果的医疗机构提供了指导。", "conclusion": "实践中获得的考虑提供了跨医疗机构的成功实施AI/NLP解决方案的具体指南，推动了数据管理流程的改进，从而最终改善了患者护理和公共卫生成果。"}
{"llm_update_time": "20250816", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.09636", "html_url": "https://arxiv.org/abs/2508.09636", "title": "个性化产品搜索排名：带有表格和非表格数据的多任务学习方法", "title_en": "Personalized Product Search Ranking: A Multi-Task Learning Approach with Tabular and Non-Tabular Data", "authors": "Lalitesh Morishetti,Abhay Kumar,Jonathan Scott,Kaushiki Nag,Gunjan Sharma,Shanu Vashishtha,Rahul Sridhar,Rohit Chatter,Kannan Achan", "background": "在本文中，作者概述了产品搜索排名优化中存在的挑战，即如何有效整合和利用表格（结构化）数据和非表格（非结构化）数据来提升个性化搜索结果的质量。传统方法在处理混合数据类型时表现不佳，尤其是在优化个性化排名方面。本文旨在探讨如何通过多任务学习（MTL）框架结合这两种类型的数据，以改进个性化产品搜索排名的效果。", "innovation": "本文提出了一个新的模型架构，利用预训练的TinyBERT模型生成语义嵌入，并结合一种新颖的采样技术来捕捉多样化的客户行为。此外，还提出了一种基于点击率、点击位置和语义相似度的可扩展相关性标签机制，作为传统人工标注标签的替代方案。该方法在处理混合数据类型和优化个性化排名方面的性能优于其他基线模型，如XGBoost，TabNet，FT-Transformer，DCN-V2和MMoE。实验结果表明，通过结合非表格数据和先进的嵌入技术，多任务学习框架显著提升了模型性能。", "conclusion": "通过结合非表格数据和先进的嵌入技术，以及使用预训练模型和新颖的采样技术，本文方法在个性化产品搜索排名上表现出色。进一步的消融研究验证了相关性标签、TinyBERT微调层和嵌入交互的好处，进一步证明了该方法的有效性。"}
{"llm_update_time": "20250816", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.10001", "html_url": "https://arxiv.org/abs/2508.10001", "title": "HiFACTMix: 一种用于印地英语混合证据基础政治声明验证的图知晓模型", "title_en": "HiFACTMix: A Code-Mixed Benchmark and Graph-Aware Model for EvidenceBased Political Claim Verification in Hinglish", "authors": "Rakesh Thakur,Sneha Sharma,Gauri Chopra", "background": "在印地英语等代码混合、低资源的语言中进行事实核查仍是一个未充分探索的自然语言处理挑战。现有的事实核实系统主要集中在高资源、单一语言的环境中，并未能很好地推广到印度等语言多样性地区的真实世界政治对话中。鉴于公共人物特别是政治人物广泛使用印地英语，以及社交媒体对公众意见日益增长的影响，有必要开发鲁棒的、多语言和上下文感知的事实核查工具。", "innovation": "引入了HiFACT数据集，这是一个新的基准数据集，包含1500个印度28个州首席部长用印地英语提出的实际事实声明，符合代码混合、低资源的环境。该数据集的每个声明都经过了文本证据的标注和真实性标签。提出了一种图知晓、检索增强的事实核查模型HiFACTMix，该模型结合了多语言上下文编码、声明-证据语义对齐、证据图构建、图神经推理和自然语言解释生成。", "conclusion": "HiFACTMix在准确性和提供忠实解释方面优于现有的多语言基线模型，这为多语言、代码混合和政治背景下的事实验证研究打开了新的方向。"}
{"llm_update_time": "20250816", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.10005", "html_url": "https://arxiv.org/abs/2508.10005", "title": "从答案到问题：评估LLMs教育性问题生成能力的EQGBench", "title_en": "From Answers to Questions: EQGBench for Evaluating LLMs' Educational Question Generation", "authors": "Chengliang Zhou,Mei Wang,Ting Zhang,Qiannan Zhu,Jian Li,Hua Huang", "background": "大型语言模型（LLMs）在数学问题解决方面已经展现了显著的能力。然而，从提供答案到生成高质量教育性问题的转变面临着重大挑战，这一领域仍相对未被深入探索。为了推进教育性问题生成（EQG）并辅助LLMs生成具有教育价值和有效性的教学问题，本文提出了一种名为EQGBench的全面基准测试，专门用于评估LLMs在生成教育性问题方面的性能。", "innovation": "EQGBench 设立了一个五维度评估框架，包含了涉及数学、物理和化学三大中学科目的900个评估样本数据集。数据集中包含带有不同知识点、难度梯度和问题类型规范的用户查询，以模拟真实的教育场景。通过系统性评估46个主流大型语言模型，揭示了在生成反映教育价值和促进学生全面能力的问题方面存在较大的改进空间。", "conclusion": "EQGBench 通过五维度评估框架，为大型语言模型在教育性问题生成方面的性能提供了全面的评估，并指出在这一领域存在进一步发展和改进的空间。"}
{"llm_update_time": "20250816", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.10009", "html_url": "https://arxiv.org/abs/2508.10009", "title": "超越硬共享：利用监督专家混合进行高效的多任务语音转文本建模", "title_en": "Beyond Hard Sharing: Efficient Multi-Task Speech-to-Text Modeling with Supervised Mixture of Experts", "authors": "Hojun Jin,Eunsoo Hong,Ziwon Hyung,Sungjun Lim,Seungjin Lee,Keunseok Cho", "background": "硬参数共享是训练单个模型跨越多样化任务的常用策略。但这一做法常导致任务间的相互干扰，影响整体模型性能。", "innovation": "提出了一种简单的监督混合专家模型（S-MoE），通过使用特殊指导标记来路由每项任务到其对应的专家，避免了传统混合专家模型中训练门控函数的需要，从而绕过了硬参数共享的局限性。进一步地，将S-MoE应用于语音转文本模型，使模型能够处理不同带宽输入的同时进行自动语音识别（ASR）和语音翻译（ST）。", "conclusion": "实验结果表明，所提的S-MoE在ASR和ST上都表现有效，应用于编码器和解码器时能实现6.35%的词错误率（WER）相对改进。"}
{"llm_update_time": "20250816", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.09992", "html_url": "https://arxiv.org/abs/2508.09992", "title": "OpenFPL：一种抗衡顶级 Fantasy Premier League 服务的开源预测方法", "title_en": "OpenFPL: An open-source forecasting method rivaling state-of-the-art Fantasy Premier League services", "authors": "Daniel Groos", "background": "Fantasy Premier League 是一种社区活动，参与者通过选择预计在周周表现最佳的英超球员来参与竞争。准确的表现预测能够帮助参与者在与竞争对手的比赛中占据优势。然而，目前高精度预测主要掌握在商业服务手中，且这些服务的运作方式保密，依赖于专有数据。因此，本研究旨在通过推出 OpenFPL 这一基于公开数据的开源预测方法，来实现精准预测的普及化。OpenFPL 是基于四个赛季（2020-21 至 2023-24）的 Fantasy Premier League 和 Understat 数据进行位置特定的模型优化，能够实现与领先商业服务相当的精度，尤其是在高额回报球员（超过 2 分）的预测上具有明显优势。这一优势在一周、两周乃至三周的预测期内都有效，支持长期转会和策略规划，同时也能够在最后一天的决策中提供帮助。因此，OpenFPL 能够提供与商业领先服务同等高质量的预测服务，从而增强玩家的决策能力，实现资源的公平分配和策略的优化调整。", "innovation": "OpenFPL 是一种基于公开数据开发的开源预测方法，它能够提供与商业领先服务相当甚至更高的精度，特别是对于能够带来高回报的球员进行准确预测。这种方法不仅优化了位置特定的模型，还适用于一周、两周乃至三周的预测期。这表明 OpenFPL 不仅能够提供即时的决策支持，还适用于长期策略规划，并且能够帮助提高最终排名。此外，OpenFPL 的开源性质使得其算法和数据都可以在公开审计下发展和完善，增加了透明度和信任度。", "conclusion": "OpenFPL 不仅能够提供与商业领先服务相同质量的准确预测结果，而且还适用于各种预测期，并能够帮助评估高回报球员的表现。此外，OpenFPL 的开源性质使得这一创新预测方法可以被社区广泛使用和改进，具有极大的普及和推广价值。"}
{"llm_update_time": "20250816", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.10004", "html_url": "https://arxiv.org/abs/2508.10004", "title": "用户对注意力可视化感知的效应：证据为基础的医学文献解释性的影响", "title_en": "User Perception of Attention Visualizations: Effects on Interpretability Across Evidence-Based Medical Documents", "authors": "Andrés Carvallo,Denis Parra,Peter Brusilovsky,Hernan Valdivieso,Gabriel Rada,Ivania Donoso,Vladimir Araujo", "background": "注意力机制是Transformer架构的核心组成部分。除了提高性能外，注意力还被提议作为一种解释性机制，通过与输入特征（例如，文档中的标记）相关联的注意力权重。在医学证据领域，这些解释可以帮助医生理解和交互以分类生物医学文献的AI系统。但是，目前还没有共识表明注意力权重是否提供帮助的解释。此外，很少有研究探讨可视化注意力如何影响其作为解释辅助工具的有用性。因此，为了填补这一空白，作者进行了一项用户研究，以评估注意力基解释在生物医学文献分类中的支持作用，以及是否有更受偏好可视化方法。该研究涉及来自不同学科的医务人员，他们根据研究设计（如系统性综述，详细综合，随机和非随机试验）对文章进行了分类。", "innovation": "本研究创新之处在于，它通过用户研究探讨了如何可视化注意力对于解释其预测的有用性影响。不同于Munzner的视觉有效性原则，偏好精确编码（如条形长度），用户更倾向于更直观的格式，如文本亮度或背景颜色。这项研究的结果不完全支持总的有用性，但表明注意力权重的感知有用性受到其可视化方式的影响。", "conclusion": "通过该研究发现，Transformer模型（XLNet）能够准确分类文档，但注意力权重并未被感知为特别有帮助来解释预测。然而，这种感知根据注意力的可视化方式有显著差异。这表明注意力权重的感知有用性取决于其可视化方式。"}
{"llm_update_time": "20250816", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.10003", "html_url": "https://arxiv.org/abs/2508.10003", "title": "大型语言模型嵌入中的语义结构", "title_en": "Semantic Structure in Large Language Model Embeddings", "authors": "Austin C. Kozlowski,Callin Dai,Andrei Boutyline", "background": "心理研究一致发现，人类对不同语义尺度词汇的评分可以减少到低维度形式，且信息损失较小。研究表明，大型语言模型（LLMs）的嵌入矩阵中编码的语义关联也表现出相似结构。还发现了词汇在由反义词对定义的语义方向上的投影与人类评分高度相关，并进一步发现这些投影在LLM嵌入中可以简化为三维子空间，与人类调查响应的模式相似。此外，沿着一个语义方向移动标记会导致与几何对齐特征的偏差，其偏差与余弦相似度成比例。研究表明，语义特征在LLMs中纠缠的方式与人类语言中的连接方式相似，且语义信息，尽管看似复杂，实际上高度低维化。此外，考虑到这一语义结构可能在 steering 特征时避免意外后果方面至关重要。", "innovation": "该研究发现大型语言模型的嵌入矩阵中包含了语义结构，这种结构与人类对单词的评分相似，并且可以简化为三维空间。此外，沿着某个语义方向移动标记会产生几何对齐特征的偏差，且这种偏差与余弦相似度相关，进一步证实了语义特征在大型语言模型中的高度纠缠特性。这种方法为理解大型语言模型内部的语义结构提供了新的途径，尤其是在 steering 模型特征时需要考虑这些特性以避免意外后果。", "conclusion": "研究揭示了大型语言模型嵌入中的语义特征高度低维化，并且这些特征具备类似于人类语言语义结构的特性。这为理解大型语言模型的功能提供了新的视角，并指出在调整模型特征时需要考虑到这一结构以减少潜在的风险和影响。"}
{"llm_update_time": "20250816", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.10018", "html_url": "https://arxiv.org/abs/2508.10018", "title": "任意改名也不会改变其香：大型语言模型的范畴同伦理论", "title_en": "A Rose by Any Other Name Would Smell as Sweet: Categorical Homotopy Theory for Large Language Models", "authors": "Sridhar Mahadevan", "background": "自然语言中存在表面不同的表达方式，例如“Charles Darwin 写了”和“Charles Darwin 是作者”，这些表达具有相同的含义。大型语言模型（LLMs）通常应该在这个情况下产生相同的目标词概率，但实际上没有做到。现有的实证方法，如使用k-NN估计的句子相似性来生成平滑的估计值，已经被探索。然而在实际情况中，语言充满了等效的重述，每个重述生成了一个非同构的箭头在网络模型标记范畴内。", "innovation": "本文通过范畴同伦理论为LLMs提出了一种更抽象的方法。引入了LLM标记范畴来表示LLM生成的语言中的概率分布，通过范畴同伦技术捕捉范畴内的“弱等价”。作者详细介绍了范畴同伦在LLMs中的应用，从更高代数K理论到模型范畴，利用了过去半个世纪发展起来的强大理论结果。", "conclusion": "本文提出了一种范畴同伦框架，解决了LLMs在等效重述上的问题，通过捕捉语言模型在不同表达方式下的“弱等价”，使得我们能够更好地理解LLMs生成的文本的概率分布。"}
{"llm_update_time": "20250816", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.10019", "html_url": "https://arxiv.org/abs/2508.10019", "title": "通过问题空间映射解耦理解与推理以增强小型模型的推理能力", "title_en": "Decoupling Understanding from Reasoning via Problem Space Mapping for Small-scale Model Reasoning", "authors": "Li Wang,Changhao Zhang,Zengqi Xiu,Kai Lu,Xin Yu,Kui Zhang,Wenjun Wu", "background": "尽管大型语言模型（LLMs）在推理能力方面取得了进展，但小型语言模型（SLMs，例如 <= 1.5B 参数）在提升其推理能力方面仍面临挑战。一个主要障碍是自然语言的复杂性和多变性，导致类似的问题在表面上显得多种多样，并被冗余或分散注意力的细节所掩盖。这给SLMs带来了双重负担：它们首先需要从复杂的语言输入中提取核心问题，然后基于对这些问题的理解进行推理。由此产生的庞大且嘈杂的问题空间阻碍了优化，特别是对于具有有限容量的模型。", "innovation": "我们提出了一种新的框架，该框架通过将自然语言问题映射到标准的问题空间来解耦理解与推理。这个框架允许SLMs专注于处理标准化的输入，而不会受到语言多变性的影响。框架内，我们提出了DURIT（解耦理解与推理通过迭代训练）算法，这是一个基于三步迭代过程的算法：（1）通过强化学习映射自然语言问题；（2）通过自我蒸馏对推理路径进行对齐；（3）在问题空间中训练推理策略。映射器和推理器在整个过程中交替训练。", "conclusion": "实验表明，DURIT显著提高了SLMs在有界域内及跨域数学和逻辑推理任务上的性能。此外，DURIT还增强了推理的鲁棒性，验证了解耦理解与推理作为加强SLMs的有效策略。"}
{"llm_update_time": "20250816", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.10017", "html_url": "https://arxiv.org/abs/2508.10017", "title": "在使用SMOTETomek和FedProx进行差异化隐私联邦学习的不平衡临床数据处理中稳健的管道", "title_en": "A Robust Pipeline for Differentially Private Federated Learning on Imbalanced Clinical Data using SMOTETomek and FedProx", "authors": "Rodrigo Tertulino", "background": "联邦学习（FL）提供了一种协调进行健康研究的方法，能够进行分散数据的模型训练并保护患者隐私。将联邦学习与差异隐私（DP）结合时，可以提供形式上的安全保证。然而，这种技术的整合在确保隐私和临床效用之间引入了重要权衡，并且此问题在许多医疗数据集中尤为复杂，因为存在严重的类别不平衡问题。本研究针对这些问题，通过系统和多阶段的分析方法，集中在心血管风险预测中的实施FL框架，研究结果显示标准方法在处理不平衡数据时存在限制，导致召回率为0。然后利用SMOTETomek方法结合FedProx算法进行优化，研究发现存在着非线性的隐私预算（ε）与模型召回率之间的权衡，并在保证强大隐私保护（ε为9.0）的同时仍然保持高的临床效用（召回率大于77%）", "innovation": "该研究使用了SMOTETomek方法结合FedProx算法来优化联邦学习中的非独立非同质数据问题。这一方法能有效处理医疗数据中的类别不平衡问题，同时提供形式化的隐私保障，并且在保护隐私的前提下保持了模型的有效性。研究发现，在隐私预算（ε）为9.0时，优化后的FedProx算法保持了高临床效用（召回率大于77%）", "conclusion": "本研究提供了一种系统的，循序渐进的方法论，用于构建有效的，安全的，并且准确的诊断工具。该工具可以应用于多样化的医疗数据，实现在保证患者隐私的同时进行准确的医疗研究和预测。"}
{"llm_update_time": "20250816", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.10020", "html_url": "https://arxiv.org/abs/2508.10020", "title": "FedCoT：在大型语言模型中的高效联邦推理增强", "title_en": "FedCoT: Communication-Efficient Federated Reasoning Enhancement for Large Language Models", "authors": "Chuan Li,Qianyi Zhao,Fengran Mo,Cen Chen", "background": "在联邦学习环境中提高大型语言模型（LLMs）的推理能力仍然是一个挑战，尤其是在平衡性能提升与严格的计算、通信和隐私限制之间的关系时。特别是在医疗保健领域，决策跨越临床、运营和患者相关的情境，不仅需要准确的输出，还需要可解释、可追溯的理由来确保安全性、问责制和监管合规性。传统的联邦调优方法主要是优化答案的正确性，忽略了理由质量，因此CoT（基于链的推理）能力依赖于模型预先训练的能力。此外，现有改进理由的方法通常依赖于集中式模型的隐私泄露知识精炼。另外，传统的联邦微调对于LLMs来说，通信开销仍然很大。", "innovation": "我们通过提出FedCoT，一种专为联邦环境设计的新框架，解决了这个问题。FedCoT利用一种轻量级的链式思考增强机制：本地模型生成多个推理路径，紧凑型鉴别器动态地选择最有前途的一种。这种方法可以提高推理的准确性和稳健性，同时提供有价值的可解释性，这对于医疗应用尤为重要。为了高效管理客户端的差异性，我们采用了一种改进的聚合方法，基于高级LoRA模块堆叠，结合客户端分类器意识，实现了跨不同客户端的无噪声聚合。", "conclusion": "在医疗推理任务上的全面实验表明，FedCoT在严格的资源预算下能显著提高客户端的推理性能，同时完全保护数据隐私。"}
{"llm_update_time": "20250816", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.10021", "html_url": "https://arxiv.org/abs/2508.10021", "title": "LATTE：学习银行客户交易和文本嵌入的对齐方法", "title_en": "LATTE: Learning Aligned Transactions and Textual Embeddings for Bank Clients", "authors": "Egor Fadeev,Dzhambulat Mollaev,Aleksei Shestov,Dima Korolev,Omar Zoloev,Ivan Kireev,Andrey Savchenko,Maksim Makarenko", "background": "从客户的历史通信序列中学习客户嵌入在金融应用中至关重要。虽然大型语言模型（LLMs）提供了广泛的世界知识，但在处理长事件序列时直接使用它们在实际管道中是计算成本高且不切实际的。已有研究在训练客户嵌入时通常要求大型语言模型直接处理完整的序列，在实时环境中显得负担过重。这篇论文的目标是开发一种改进的方法来解决这个问题，从而提高效率并降低计算成本。", "innovation": "本文提出了LATTE，一种对比学习框架，它将原始的事件嵌入与初始化冻结的大型语言模型的语义嵌入进行对齐。通过总结行为特征为简短提示并将其嵌入LSTM，再使用对比损失作为监督，显著降低了推理成本和输入大小。相比于用完整的序列直接处理LSTM的传统方法，此方法在金融数据集上的表现更为优异，同时也具备在延迟敏感环境中部署的能力。", "conclusion": "该方法在实际世界金融数据集上优于现有技术，同时保持了在时间敏感环境中的部署能力，显著减少了推理成本和输入大小。"}
{"llm_update_time": "20250816", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.10024", "html_url": "https://arxiv.org/abs/2508.10024", "title": "RTTC: 基于奖励的协作式测试时计算", "title_en": "RTTC: Reward-Guided Collaborative Test-Time Compute", "authors": "J. Pablo Muñoz,Jinjie Yuan", "background": "测试时计算（TTC）已成为增强大型语言模型（LLMs）推理性能的强大范式，通过使用测试时训练（TTT）和检索增强生成（RAG）等策略。然而，最佳适应策略因查询而异，未经选择的应用TTC策略会导致大量计算开销。", "innovation": "引入了基于奖励的测试时计算（RTTC），这是一种新型框架，通过预训练的奖励模型适应性选择最适合每个查询的TTC策略，从而在不同领域和任务中最大化下游准确性。RTTC在分布式服务器-客户端架构中运行，从远程知识库检索相关样本，仅在必要时在客户端设备上进行RAG或轻量级微调。为减轻重复计算，提出了查询状态缓存，使其在检索和适应级别上能够高效复用历史查询状态。", "conclusion": "在多个LLM和基准测试上的广泛实验表明，RTTC能够持续地与传统的RAG或TTT相比实现更高的准确性，这验证了适应性、基于奖励的TTC选择的必要性及RTTC在可扩展高性能语言模型适应方面潜力。"}
{"llm_update_time": "20250816", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.10025", "html_url": "https://arxiv.org/abs/2508.10025", "title": "实时生成式人工智能检测并解释产后抑郁症", "title_en": "Detecting and explaining postpartum depression in real-time with generative artificial intelligence", "authors": "Silvia García-Méndez,Francisco de Arriba-Pérez", "background": "产后抑郁症（PPD）是影响新妈妈们心理健康和身体健康的严重问题。快速检测PPD及其相关风险因素对于及时评估和干预至关重要，因此需要借助最新的技术实现实时筛查和治疗建议，以帮助专业人士做出决策。", "innovation": "该研究开发了一种结合自然语言处理、机器学习和大规模语言模型的智能PPD筛查系统，实现了免费言语分析的实时检测，成本效益高且无创。此外，通过将大规模语言模型与可解释的机器学习模型（树基算法）结合使用，该系统克服了黑箱问题，提高了用户对预测结果的透明度。", "conclusion": "该研究的成果在PPD检测的各项评估指标上达到了90%的准确率，显著优于文献中的现有解决方案，为PPD及相关风险因素的快速检测和及时、适当的评估与干预做出了重要贡献。"}
{"llm_update_time": "20250816", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.10022", "html_url": "https://arxiv.org/abs/2508.10022", "title": "在具有可证风险控制的多项选择题回答任务中使用置信p值", "title_en": "Conformal P-Value in Multiple-Choice Question Answering Tasks with Provable Risk Control", "authors": "Yuanchang Ye", "background": "近年来，大型语言模型（LLMs）在专业问答（QA）场景中的应用越来越广泛。然而，语言模型在回答多项选择题（MCQA）时，可能存在幻想和非事实生成的问题，这大大影响了回答的可靠性。虽然现有的基于置信的预测（CP）可以提供统计上严谨的边际覆盖保证，而显著性检验也提供了统计上的严谨性，但它们的结合使用尚未得到探索。因此，本研究旨在通过在MCQA响应中引入p值计算与一致性评分的自一致性再采样方法，提高大型语言模型在实际应用中的可信度，从而解决语言模型的不透明性问题并通过零假设检验构建预测集。", "innovation": "本研究的创新之处在于将p值计算与一致性评分通过自一致性再采样方法整合到现有的CP框架中，利用零假设检验和经验p值构建预测集。这种方法通过计算选项频率解决了语言模型的黑盒问题，并验证了平均预测集大小（APSS）作为不确定性度量的有效性。", "conclusion": "本研究通过在MMLU和MMLU-Pro基准测试中使用现成的LLM进行评估，证明了改进后的CP能够实现用户指定的经验覆盖误差率，并且随着风险水平（α）的增加，平均预测集大小呈单调下降趋势，验证了APSS作为有效不确定性度量的可靠性，从而为大型语言模型在高风险QA应用中的可靠部署奠定了坚实的统计基础。"}
{"llm_update_time": "20250816", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.10027", "html_url": "https://arxiv.org/abs/2508.10027", "title": "LLMCARE：通过生成合成数据的变压器模型进行阿尔茨海默病检测", "title_en": "LLMCARE: Alzheimer's Detection via Transformer Models Enhanced by LLM-Generated Synthetic Data", "authors": "Ali Zolnour,Hossein Azadmaleki,Yasaman Haghbin,Fatemeh Taherinezhad,Mohamad Javad Momeni Nezhad,Sina Rashidi,Masoud Khani,AmirSajjad Taleban,Samin Mahdizadeh Sani,Maryam Dadkhah,James M. Noble,Suzanne Bakken,Yadollah Yaghoobzadeh,Abdol-Hossein Vahabie,Masoud Rouhizadeh,Maryam Zolnoori", "background": "阿尔茨海默病及相关痴呆症(ADRD)影响着美国约五百万老年人，但其中超过一半仍未被诊断。基于语音的自然语言处理(NLP)提供了一种有潜力、可扩展的方法，通过语言标志检测早期认知下降。", "innovation": "开发并评估了一种筛查管道，该管道(i)结合了变压器嵌入与手工设计的语言特征，(ii)测试了使用大型语言模型(LLM)生成的合成语音进行数据增强的方法，(iii)评估了单模态和多模态LLM分类器在ADRD检测中的表现。研究通过合成语音数据增强，达到了比单独的语言特征或变压器方法更好的检测效果，并且通过调优的LLM提高了单模态LLM分类器的性能，但目前的多模态模型性能较低。", "conclusion": "结合变压器嵌入与语言特征增强了从语音中检测ADRD的能力。临床调整过的LLM不仅支持分类任务，而且提高了数据增强的效果，但需要进一步研究多模态建模以提升性能。"}
{"llm_update_time": "20250816", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.10028", "html_url": "https://arxiv.org/abs/2508.10028", "title": " PREF: Reference-Free Evaluation of Personalised Text Generation in LLMs", "title_en": "PREF: Reference-Free Evaluation of Personalised Text Generation in LLMs", "authors": "Xiao Fu,Hossein A. Rahmani,Bin Wu,Jerome Ramos,Emine Yilmaz,Aldo Lipani", "background": "个性化文本生成对于用户为中心的信息系统至关重要，但大多数评估方法忽视了用户的个性化差异。现有的评估方法往往依赖于事先标记好的个性化参考文本，这既耗时又难以获取。", "innovation": "PREF（Personalized Reference-free Evaluation Framework）引入了一种参考无关的个性化评估框架，能够联合测量通用输出质量和用户特定对齐，无需金标准的个性化参考文本。PREF采用三步流水线操作：覆盖阶段利用大型语言模型生成全面的、查询特定的指南；偏好阶段重新排名并有选择性地增强这些因素，利用目标用户的行为、显式或隐式偏好和上下文，生成个性化的评估标准；评分阶段应用一个大型语言模型裁判来对候选答案进行评分，确保基本足够的同时捕捉主观优先级。这种方法提高了鲁棒性、透明度和可重用性，使较小的模型也能逼近大型模型的个性化质量。", "conclusion": "实验结果表明，PREF相较于强大的基线方法在准确性和校准方面表现出色，并且与人类判断更为接近。通过提供可扩展、可解释且符合用户偏好的评估，PREF为更可靠地评估和开发个性化语言生成系统奠定了基础。"}
{"llm_update_time": "20250816", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.10030", "html_url": "https://arxiv.org/abs/2508.10030", "title": "为对齐黑盒大型语言模型而进行的推理感知提示优化", "title_en": "Inference-Aware Prompt Optimization for Aligning Black-Box Large Language Models", "authors": "Saaduddin Mahmud,Mason Nakamura,Kyle H. Wray,Shlomo Zilberstein", "background": "现有的提示优化方法已经在对齐黑盒大语言模型方面显示出了显著的效果。同时，诸如最佳N采样和多数投票等推理扩展策略也已经被证明可以提高对齐度和性能，尽管需要在计算量上做出权衡。然而，现有的大多数提示优化方法并没有考虑在部署时实际采用的推理策略，这导致了一个重要的方法论空缺。", "innovation": "本文提出了一个名为IAPO（推理感知提示优化）的新框架，该框架可以同时优化提示和推理规模，并考虑到推理预算和不同任务目标。通过引入PSST（逐步修剪提示缩放）算法，该方法还在固定预算下提供了错误概率的保证。实验结果表明，当通过提示优化对齐黑盒大语言模型时，考虑到推理策略的重要性至关重要。", "conclusion": "通过IAPO框架，本文展示了如何在提示优化过程中根据不同任务目标和推理预算选择最合适的提示和推理配置。实验结果表明，采用推理感知方法能够显著提升黑盒大语言模型的对齐和性能。"}
{"llm_update_time": "20250816", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.10032", "html_url": "https://arxiv.org/abs/2508.10032", "title": "思考的代价：大型语言模型中增加的 Jailbreak 风险", "title_en": "The Cost of Thinking: Increased Jailbreak Risk in Large Language Models", "authors": "Fan Yang", "background": "LLMs（大型语言模型）一直被认为是最有价值的模式之一。然而，该研究揭示了一种未被注意到的现象：具有思考模式的LLMs更易受到Jailbreak攻击的影响。研究者在AdvBench和HarmBench上评估了9个LLMs，并发现攻击思考模式的成功率几乎高于非思考模式。此外，通过对大量样本的研究发现，教育目的和思考长度过长是被成功攻击的数据特征，且在这些问题上，LLMs也会给出有害的回答。", "innovation": "为缓解上述问题，该论文提出了一个名为“安全思考干预”的方法，通过在提示中添加“特定思考标记”来显式地指导LLMs的内部思考过程，以降低具有思考模式的LLMs的攻击成功率。", "conclusion": "实验结果表明，安全思考干预可以显著降低具有思考模式的LLMs被攻击的成功率。"}
{"llm_update_time": "20250816", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.10026", "html_url": "https://arxiv.org/abs/2508.10026", "title": "SABER: 开关和平衡训练以实现高效的大语言模型推理", "title_en": "SABER: Switchable and Balanced Training for Efficient LLM Reasoning", "authors": "Kai Zhao,Yanjun Zhao,Jiaming Song,Shien He,Lusheng Zhang,Qiang Zhang,Tianjiao Li", "background": "大语言模型（LLMs）通过链式推理能够实现复杂的任务，但当均匀应用于所有问题时，它们会面临推理成本过高和延迟的问题。SABER框架旨在通过使LLMs具有用户可控的、预算化的推理能力来解决这些问题。它首先对每个训练示例的基础模型思维令牌使用情况进行评估，并将其分配到预定义的预算层级。在微调过程中，模型通过系统提示和长度感知的奖励，保持其分配的预算。同时，通过加入不进行思考的例子以确保即使在关闭显式推理的情况下，模型仍保持可靠。SABER还支持四种不同的推理模式——NoThink、FastThink、CoreThink和DeepThink，这使得在推理时间和推理深度之间实现灵活的权衡成为可能。", "innovation": "SABER框架通过增强大语言模型的训练，使其具备用户可控的和预算化的推理能力。它可以自定义地分配和管理推理成本，引入不进行思考的例子以确保模型的可靠性，并且通过四种不同的推理模式（NoThink、FastThink、CoreThink和DeepThink）提供了在推理时间和推理深度之间进行选择的灵活性。在数学推理、代码生成和逻辑推理等多个领域的评估中，SABER显示出在严格预算下高精度、平滑降级能力和跨级别、跨领域泛化能力，特别是在MATH基准测试中，SABER-FastThink将推理长度减少了65.4%，并且在MATH基准测试中与基础模型相比提高了3.6%的精度。", "conclusion": "SABER框架通过平衡训练与适时推理成本控制，实现了在推理时间和精度之间的灵活权衡。SABER不仅在数学推理、代码生成和逻辑推理等多个任务上实现了高精度，还展示了其在不同规模下的平滑降级能力和跨任务泛化能力。"}
{"llm_update_time": "20250816", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.10036", "html_url": "https://arxiv.org/abs/2508.10036", "title": "反思然后学习：由内省困惑引导的信息提取主动提示", "title_en": "Reflect then Learn: Active Prompting for Information Extraction Guided by Introspective Confusion", "authors": "Dong Zhao,Yadong Wang,Xiang Chen,Chenxi Wang,Hongliang Dai,Chuanxing Geng,Shengzhong Zhang,Shaoyuan Li,Sheng-Jun Huang", "background": "大型语言模型（LLMs）在少量示例信息提取（IE）方面显示出显著潜力，但其性能高度依赖于内部示例的选择。传统选择策略往往未能提供有效的指导，因为它们忽视了模型失败的关键来源：不仅是语义内容的混淆，还包括由IE任务所需的结构格式生成引起的混淆。", "innovation": "我们提出了信息提取的主动提示框架（APIE），这是基于一种我们称为内省困惑的原则。我们的方法通过一种具有独特计量格式不确定性和内容不确定性的双重不确定性度量，使LLM能够评估自身的困惑。该框架通过综合评分对未标注数据进行排名，主动选择最具挑战性和信息性的样本作为少样本示例。", "conclusion": "在四个基准上的广泛实验表明，我们的方法在提取准确性和鲁棒性方面始终优于强基线。我们的工作突显了在构建有效的鲁棒结构生成系统时需要细致层次的模型不确定性视图的重要性。"}
{"llm_update_time": "20250816", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.10039", "html_url": "https://arxiv.org/abs/2508.10039", "title": "针对少数几次查询的黑盒模型多任务对抗攻击", "title_en": "Multi-task Adversarial Attacks against Black-box Model with Few-shot Queries", "authors": "Wenqiang Wang,Yan Xiao,Hao Lin,Yangshijie Zhang,Xiaochun Cao", "background": "当前的多任务对抗文本攻击依赖于资源共享的内部特征和大量的查询，通常仅限于单一任务类型。这些攻击在实际场景中遇到黑盒反馈API、有限查询次数或多种任务类型时效果不佳。", "innovation": "提出了CEMA（Cluster and Ensemble Multi-task Text Adversarial Attack），这是一种有效的黑盒攻击方法，利用不同任务间对抗文本的可转移性。CEMA通过使用一种“插拔式”的深层替代模型，在文本分类中简化了多任务场景，无需模拟目标模型。这种方法仅需少量查询即可进行训练，将多任务攻击转化为分类攻击，允许跨任务进行攻击。CEMA使用不同的文本分类方法生成多个对抗候选者，并选择对替代模型攻击效果最佳的一个。", "conclusion": "CEMA在涉及两个、三个或六个任务（包括分类、翻译、摘要和文本到图像生成）的多任务模型中，以100次查询为少的次数展示了显著的攻击成功率。CEMA能够针对商用API（如百度和谷歌翻译）、大型语言模型（如ChatGPT 4o）以及图像生成模型（如Stable Diffusion V2），展示了其在实际应用中的多样性和有效性。"}
{"llm_update_time": "20250816", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.10038", "html_url": "https://arxiv.org/abs/2508.10038", "title": "设计中的可验证鲁棒恶意软件检测器", "title_en": "Certifiably robust malware detectors by design", "authors": "Pierre-Francois Gimenez,Sarath Sivaprasad,Mario Fritz", "background": "恶意软件分析涉及分析可疑软件以检测恶意负载。静态恶意软件分析依赖于无需软件执行的机器学习技术，以实现可扩展性。尽管这些技术可以获得非常高的检测准确性，但它们可以通过少量修改样本的方式轻易被误导，而无需修改软件的行为。在这种情况下，创建一个不会改变功能性的恶意软件对抗样本需要特定的变换。与计算机视觉等其他领域不同，创建恶意软件的对抗样本需要更复杂的变换，它需要保持软件的功能性不变。", "innovation": "文中提出了一种新的模型架构，用于从设计上实现恶意软件检测的鲁棒性。这种方法证实了每个鲁棒检测器都可以分解为特定的结构，可以被应用于或许固有特性上学习具有实验鲁棒性的恶意软件检测器。框架ERDALT基于这种结构建立。该方法通过将机器学习基线恶意软件检测方法与现有技术进行比较与验证，证明可以在保证检测性能降低最小的情况下实现鲁棒的检测能力。", "conclusion": "证明可以基于框架ERDALT构建具有实验鲁棒性的恶意软件检测器，并且可以实现在最小限度上不影响检测性能的鲁棒检测。"}
{"llm_update_time": "20250816", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.10031", "html_url": "https://arxiv.org/abs/2508.10031", "title": "Context Misleads LLMs: The Role of Context Filtering in Maintaining Safe Alignment of LLMs", "title_en": "Context Misleads LLMs: The Role of Context Filtering in Maintaining Safe Alignment of LLMs", "authors": "Jinhwa Kim,Ian G. Harris", "background": "大规模语言模型（LLMs）在性能上已经取得了显著的进步，但各种破环攻击（jailbreak attacks）带来了日益增长的安全和伦理风险。恶意用户常常利用对抗性背景来欺骗LLMs，使其生成对有害查询的响应。该研究的背景在于，在增强LLMs安全性的过程中，往往会影响到它们的帮助性，从而影响无辜用户的经验。因此，如何在保证安全性的前提下，不影响LLMs的性能，是本研究的重点挑战之一。为了有效防御破环攻击，研究人员提出了Context Filtering模型，这是一种输入预处理方法，旨在过滤掉不信任和不可靠的背景信息，同时识别出包含真实用户意图的主要提示，以揭露隐藏的恶意意图。", "innovation": "本文提出了一种新的防御机制——Context Filtering模型，这是一种输入预处理方法，能够有效地过滤掉不信任和不可靠的背景信息，同时识别出包含真实用户意图的主要提示，以揭示隐藏的恶意意图。与其他安全机制相比，该方法在保持LLMs原有性能的同时，能够显著减少破环攻击的成功率。此外，该模型具有即插即用的特点，可以应用于所有LLMs，包括白盒和黑盒模型，无需对模型本身进行细调。", "conclusion": "实验结果表明，Context Filtering模型能够将破环攻击的成功率降低88%，同时保持了LLMs的原始性能，达到了安全性和帮助性的最佳平衡。这一模型的引入，为LLMs的安全性提供了有效的保障，且通用性强，适用于多种类型的LLM。"}
{"llm_update_time": "20250816", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.10042", "html_url": "https://arxiv.org/abs/2508.10042", "title": "FIDELIS：区块链赋能的联邦学习中对抗投毒攻击的保护措施", "title_en": "FIDELIS: Blockchain-Enabled Protection Against Poisoning Attacks in Federated Learning", "authors": "Jane Carney,Kushal Upreti,Gaby G. Dagher,Tim Andersen", "background": "联邦学习通过利用物联网设备的私有数据进行模型的联合训练，提高传统深度学习的效果，但同时也面临着数据投毒攻击的风险。当前的数据投毒检测方法缺乏标准或过度依赖信任。因此，需要一种新的、去中心化的解决方案来确保模型的性能和完整性不受损害。", "innovation": "提出了一种新的区块链赋能的投毒检测框架\textbackslash{}Sys。该框架通过去中心化的方式分散了全球服务器的角色，引入了一种用于检测模型更新中的数据投毒的裁决模型。每个客户端生成裁决模型，并通过达成共识的方式验证裁决模型的正确性。", "conclusion": "\textbackslash{}Sys框架已被实施证明可以有效抵御数据投毒攻击，并且裁决模型的生成是可扩展的。"}
{"llm_update_time": "20250816", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.10033", "html_url": "https://arxiv.org/abs/2508.10033", "title": "认知人工智能的网络安全：基于CCS-7的护栏工程", "title_en": "Cognitive Cybersecurity for Artificial Intelligence: Guardrail Engineering with CCS-7", "authors": "Yuksel Aydin", "background": "语言模型表现出类似人类的认知脆弱性，如情绪框架效应，这些特性传统的行为对齐方法未能捕捉到。现有研究指出，人类的认知安全存在缺陷，研究者们提出了CCS-7（认知网络安全套件）这一七大类认知安全漏洞的分类体系。", "innovation": "研究采用了一种名为\"先思考，后验证\"（TFVA）的教育干预方法，提高了参与者的认知安全性。这一方法被应用于对12,180次不同架构的语言模型实验中，发现不同架构对认知安全的保护效果不同，某些漏洞被显著缓解，而另一些则引起反效应，错误率增加了135%。相比之下，人表现出了一致的中等程度的提升。研究强调了认知安全性需要针对特定模型进行工程化处理，避免通用解决方案的失败。", "conclusion": "认知安全性是一个特定模型的具体工程问题，有效的干预措施在不同架构中可能会失效或造成损害，因此在部署之前需要进行针对特定架构的认知安全性测试。"}
{"llm_update_time": "20250816", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.10052", "html_url": "https://arxiv.org/abs/2508.10052", "title": "NetMoniAI: 一种用于网络安全与监控的代理AI框架", "title_en": "NetMoniAI: An Agentic AI Framework for Network Security & Monitoring", "authors": "Pallavi Zambare,Venkata Nikhil Thanikella,Nikhil Padmanabh Kottur,Sree Akhil Akula,Ying Liu", "background": "该研究主要背景是网络监控和安全领域中，传统的集中式分析方法存在诸多限制，如资源需求大、准确性不足、响应慢等。因此，需要一种既可以进行分散分析又能保持集中协调的新方法以改进网络监控和安全性能。", "innovation": "该论文创新地提出了一种新的一体化AI框架——NetMoniAI，它将分散分析与轻量级集中协调相结合，通过自主微代理在每个节点上执行本地流量分析和异常检测，中央控制器汇集各节点的洞察力以检测协同攻击并保持全系统的态势感知能力。这种双层的分代理AI设计在资源受限的条件下能够扩展，并减少了冗余性，提高了响应时间而不牺牲准确性。", "conclusion": "通过本地微型实验床和NS-3模拟测试，结果证实了该框架的有效性。该框架可用作开源平台，促进了更广泛的采用和可重复性，使得研究人员和从业者能够复制、验证并拓展该框架以适应不同的网络环境和威胁场景。"}
{"llm_update_time": "20250816", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.10071", "html_url": "https://arxiv.org/abs/2508.10071", "title": "提升数据公平性：NLP数据实践中从业者责任与问责", "title_en": "Advancing Data Equity: Practitioner Responsibility and Accountability in NLP Data Practices", "authors": "Jay L. Cunningham,Kevin Zhongyang Shao,Rock Yuren Pang,Nathaniel Mengist", "background": "尽管研究已经关注于揭示和审计算法偏见以确保公平的AI开发，但很少有人了解自然语言处理（NLP）从业者（直接参与数据集开发、标注和部署的专业人士）对NLP数据公平性的看法和应对策略。本文的研究是最早关注从业者视角的研究之一，通过连接他们的经验与多尺度AI治理框架，提出跨技术、政策和社区领域的参与性建议。", "innovation": "本文通过2024年的问卷调查和焦点小组讨论，探讨了美国NLP数据从业者的公平性概念、应对组织和系统性约束的能力以及参与新兴治理努力（如美国AI法案）的方式。研究发现揭示了商业目标与公平承诺之间的持续张力，呼吁更多参与和负责的数据工作流程，同时批判性地讨论了数据多样性和伪多样性问题，主张为从业者赋能并获得社区同意的结构性治理改革是提高NLP公平性的关键。", "conclusion": "本文研究结果表明，改进NLP公平性需要支持从业者行动能力和社区同意的结构性治理改革。"}
{"llm_update_time": "20250816", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.10040", "html_url": "https://arxiv.org/abs/2508.10040", "title": "使用可解释的文本和图学习探索假新闻的内容和社会联系", "title_en": "Exploring Content and Social Connections of Fake News with Explainable Text and Graph Learning", "authors": "Vítor N. Lourenço,Aline Paes,and Tillman Weyde", "background": "全球范围内虚假信息的传播及其对内容可信度的威胁，推动了自动化事实核查系统的开发。假信息往往利用社交媒体动态如点赞和用户网络来放大其影响。因此，有效的解决方案需要超越内容分析，融合这些因素。仅仅标记内容为虚假也可能是无效的，甚至会强化自动化和确认偏见。为了应对这些问题，本研究着重开发了一种结合内容、社交媒体和图基特征的可解释框架，以增强事实核查的能力。实验展示了多模态信息相较于单一模式能提高性能，该研究在英文、西班牙文和葡萄牙文的数据集上进行了评估，并通过一项新颖的协议评估了框架的解释性、可信性和鲁棒性，表明该框架能够生成人类可理解的预测依据。", "innovation": "该研究提出了一种结合内容、社交媒体和图基特征的可解释框架，用于增强事实核查，并通过融合多模态信息，提高事实核查的性能。该框架还包括利用可解释技术，以提供完整且可解释的洞察，支持分类决策。实验结果表明，该方法在处理假新闻内容和社交联系方面比单一模态方法更有效。此外，研究还提出了一种新型协议来评估框架的解释性、可信性和鲁棒性，这在先前的研究中较为罕见。", "conclusion": "该研究提出了一种结合内容、社交媒体和图基特征的可解释框架，该框架利用可解释技术提供人类可理解的解释和决策支持，比单一模态方法提高了假新闻检测的性能，并得到了实验证明。此外，通过一个新颖的协议验证了框架的解释性、可信性和鲁棒性，从而有效应对外界对该技术的质疑。"}
{"llm_update_time": "20250816", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.10050", "html_url": "https://arxiv.org/abs/2508.10050", "title": "法律零日：先进AI系统的新型风险向量", "title_en": "Legal Zero-Days: A Novel Risk Vector for Advanced AI Systems", "authors": "Greg Sadler,Nathan Sherburn", "background": "我们引入了“法律零日”的概念，这是一种高级AI系统的新型风险向量。法律零日是指之前未被发现的法律框架中的漏洞。这些漏洞在被利用时，可以立即引起重大社会动荡，且无需通过诉讼或其他流程即可产生影响。我们使用2017年澳大利亚双重公民危机作为案例研究，展示了看似微小的法律疏忽如何导致大规模的治理中断。", "innovation": "我们提出了一种风险模型，用于识别和评估这些漏洞，证明它们有可能绕过保护措施或阻碍政府对AI事件的响应。我们发展了一种创建“法律谜题”的方法，作为评估AI系统发现此类漏洞能力的工具。我们的研究结果表明，尽管当前的AI模型可能无法可靠地找到具有影响力的法律零日，但未来的系统可能会发展出这一能力，既带来了风险，也带来了提高法律稳健性的机会。", "conclusion": "我们的研究结果表明，虽然当前的AI模型可能无法可靠地找到具有影响力的法律零日，但未来的系统可能会发展出这一能力，既带来了风险，也带来了提高法律稳健性的机会。这项工作为识别和减轻前沿AI系统中未被认识到的风险做出了贡献。"}
{"llm_update_time": "20250816", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.10046", "html_url": "https://arxiv.org/abs/2508.10046", "title": "SABIA:一种基于人工智能的社会媒体上检测阿片类药物相关行为的工具", "title_en": "SABIA: An AI-Powered Tool for Detecting Opioid-Related Behaviors on Social Media", "authors": "Muhammad Ahmad,Fida Ullah,Muhammad Usman,Ildar Batyrshin,Grigori Sidorov", "background": "社交媒体平台已成为理解公共卫生挑战的重要工具，能够提供关于患者行为、药物使用和心理健康问题的洞察。然而，分析这类数据仍然颇具挑战性，因为社交媒体语言中普遍使用非正式语言、俚语和编码交流，这可能模糊了阿片类药物滥用的检测。", "innovation": "本研究通过分析现有的Bidirectional Encoder Representations from Transformers (BERT)技术，开发了一种名为SABIA的混合深度学习模型——BERT-BiLSTM-3CNN，用于创建一个单一任务分类器，能够有效捕捉目标数据集的特点。SABIA模型在捕捉语义和上下文信息方面表现出强大的能力。研究提出的办法包括数据预处理、使用SABIA模型的数据表示、微调阶段和将用户行为分类为五个类别。研究结果显示，SABIA在监督学习实验中达到了基准性能，优于基线（逻辑回归，LR = 0.86），准确率提高了9.30%。其有效性与七个先前研究的比较也得到了证实。", "conclusion": "本文展示了混合深度学习模型在检测社交媒体上复杂的阿片类药物相关行为方面的潜力，支持公共卫生监测和干预努力。"}
{"llm_update_time": "20250816", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.10044", "html_url": "https://arxiv.org/abs/2508.10044", "title": "生成式AI在能源管理系统网络安全中的方法、挑战与未来方向", "title_en": "Generative AI for Cybersecurity of Energy Management Systems: Methods, Challenges, and Future Directions", "authors": "Aydin Zaboli,Junho Hong", "background": "本文探讨了一种专为能源管理系统（EMSs）设计的广泛安全框架，有效地应对不断变化的网络漏洞和系统问题（SPs）环境。该框架通过引入新颖的管理方法，首次提出了全面的多点攻击/错误模型，旨在系统地识别整个EMS数据处理管道中的漏洞，包括后状态估计(MathML 模式)隐身攻击、EMS数据库操纵以及根据实时数据库存储来破坏人机界面（HMI）显示。该框架认识到当前攻击向量的相互关联，这些攻击向量利用了SCADA数据流的各个环节。在电力系统领域，首次提出了基于生成式AI（GenAI）的异常检测系统（ADSs）来处理此类场景。一种结合多种模式分析的方法——利用视觉标记与规则集来克服生成式AI固有的空间推理限制的生成智能（SoM-GI）框架，也被建议出来。", "innovation": "本文提出了以下几个创新点：1) 首次提出了全面的多点攻击/错误模型，以系统地识别EMS数据处理管道中的漏洞。2) 提出了基于生成式AI（GenAI）的异常检测系统（ADSs），首次应用于电力系统。3) 建议了一种生成智能（SoM-GI）框架，通过结合视觉标记与规则集，克服生成式AI的固有空间推理限制。4) 结合了数值分析、视觉模式识别和语言规则的方法，以保护对抗网络威胁和系统错误。验证在IEEE 14-Bus系统上显示了该框架的有效性并识别了不一致性。", "conclusion": "本文提出了一种新的安全框架来应对能源管理系统中的网络和系统问题，通过引入新颖的多点攻击/错误模型和基于生成式AI的异常检测系统，以及一种结合多种模式分析的生成智能框架。该框架展示了在网络安全和系统保护方面的有效性，并通过数值分析与视觉模式识别的综合方法提升了防御能力。"}
{"llm_update_time": "20250816", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.10043", "html_url": "https://arxiv.org/abs/2508.10043", "title": "保障代理人工智能：网络监控代理人工智能系统的威胁建模与风险分析", "title_en": "Securing Agentic AI: Threat Modeling and Risk Analysis for Network Monitoring Agentic AI System", "authors": "Pallavi Zambare,Venkata Nikhil Thanikella,Ying Liu", "background": "在网络监控和决策系统中结合大型语言模型（LLMs）与自主代理将会带来严重的安全问题。因此，需要一个框架来识别、评估和消除代理AI的漏洞。研究中采用了包含七层威胁建模架构的MAESTRO框架。研究通过构建和实现了原型代理系统，并确认了两种实际的威胁案例：（i）通过交通重播服务拒绝访问攻击导致资源拒绝服务；（ii）通过篡改代理维护的历史日志文件导致内存中毒。这些情况导致了性能下降，如遥测更新延迟和计算负荷增加，表明系统适应能力差。需要采用多层次的防御策略，如采用内存隔离、实时验证规划器和异常响应系统。这些发现证实了MAESTRO在威胁映射、风险评分和韧性系统设计中的有效性。研究强调了保护内存完整性和适应逻辑监控的重要性，以及多层通信保护，确保代理AI在对抗环境中的可靠性。", "innovation": "开发了MAESTRO框架，包含七层威胁建模架构，用于揭示、评估并消除代理AI中的漏洞。研究通过代码实现了一个原型系统，该系统使用Python、LangChain和WebSocket遥测进行部署，并整合了推理、记忆、参数调整和异常检测模块。提出了多层次的防御策略，包括内存隔离、实时验证规划器和实时异常响应系统，对抗代理AI的安全威胁。这些创新为代理AI在网络安全中的应用提供了理论和实践依据，提高了系统设计的可靠性与安全性。", "conclusion": "研究展示了MAESTRO在实际网络监控代理AI系统中的有效性和可行性，强调了内存完整性保护、适应逻辑监控和跨层通信保护的重要性，以增强代理AI在对抗环境中的可靠性。MAESTRO为代理AI的风险管理和设计提供了新的视角，并为类似系统的设计提供了基础。"}
{"llm_update_time": "20250816", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.10115", "html_url": "https://arxiv.org/abs/2508.10115", "title": "仅用LLMs学习图任务", "title_en": "Less is More: Learning Graph Tasks with Just LLMs", "authors": "Sola Shirai,Kavitha Srinivas,Julian Dolby,Michael Katz,Horst Samulowitz,Shirin Sohrabi", "background": "大型语言模型（LLMs）在处理图相关问题时具有潜力，但之前的工作主要集中在如何将图序列化为文本或将图神经网络（GNNs）与LLMs结合使用。这些方法的效果尚不明确，因此该研究通过实证方法回答了几个关键问题：LLMs是否能通过训练学会解决基础的图任务，而无需特殊的图编码模型？LLMs是否能够将学到的解决方案应用到未见过的图结构或任务中？不同方法在学习图任务方面的优点是什么？", "innovation": "研究展示了即使是很小的LLMs，也能通过训练解决图任务，并且这种训练在没有特殊图编码的情况下具有泛化能力，能应用于未见过的任务和图结构中。", "conclusion": "研究结果表明，LLMs在解决图任务方面具有潜力，通过具指导性的chain-of-thought方法进行训练，提高了泛化能力。"}
{"llm_update_time": "20250816", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.10110", "html_url": "https://arxiv.org/abs/2508.10110", "title": "使用可解释的图像-文本基础模型增强变形攻击检测", "title_en": "Empowering Morphing Attack Detection using Interpretable Image-Text Foundation Model", "authors": "Sushrut Patwardhan,Raghavendra Ramachandra,Sushma Venkatesh", "background": "变形攻击检测已成为确保面部识别系统中的可靠验证场景的必要组成部分。这项研究提出了一种多模态学习方法，该方法可以通过文本描述提供变形攻击检测。研究对CLIP进行了零样本评价，证明该框架不仅可以提供一般化的变形攻击检测，还能预测最相关的文本片段。研究人员通过考虑人类可理解的文本片段，设计了十种不同的文本提示，包括短提示和长提示，进行了广泛分析。实验在使用公开面部生物特征数据集开发的面部变形数据集上进行，评估了当前最先进的预训练神经网络与所提出的框架在五种不同变形生成技术中的零样本评价，这些技术涵盖了三种不同的媒介。", "innovation": "本文提出了一种多模态学习方法，该方法可以提供变形攻击检测的文本描述。尤其通过CLIP在零样本评估中探索了该框架的潜力，不仅实现了变形攻击检测的泛化能力，还能够预测最相关的文本片段。此外，创新地使用了十种不同设计的人类可理解的文本提示，并对当前最先进的预训练模型进行了广泛的实验分析。", "conclusion": "作者展示了通过结合图像和文本信息，该方法能够在变形攻击检测中提供可解释的信息。通过对各种预训练模型和变形生成技术的广泛实验，该研究证明了这种方法的有效性和可解释性。"}
{"llm_update_time": "20250816", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.10057", "html_url": "https://arxiv.org/abs/2508.10057", "title": "大型语言模型在抽象推理中表现出与人类神经认知的共现迹象", "title_en": "Large Language Models Show Signs of Alignment with Human Neurocognition During Abstract Reasoning", "authors": "Christopher Pinier,Sonia Acuña Vargas,Mariia Steeghs-Turchina,Dora Matzke,Claire E. Stevenson,Michael D. Nunez", "background": "这项研究探讨了大型语言模型（LLMs）在抽象推理过程中是否类似人类的神经认知过程。研究人员通过比较参与者的绩效和神经表征与八个开源LLM在抽象模式完成任务上的表现，利用不同任务表现下的模式类型差异以及在执行任务期间记录的电生理固定相关电压（FRPs），来评估这一假设。", "innovation": "该研究利用了任务期间记录的固定相关电压（FRPs），并通过对比具有不同参数量的LLM在抽象模式完成任务上的表现，发现只有大约700亿参数量的LLM才能达到接近人类的准确度，且部分LLM（如Qwen-2.5-72B 和 DeepSeek-R1-70B）还表现出类似的人类特定于模式的难度特征。此外，研究还观察到，任务最优LLM层的表征几何与人类前额叶FRPs之间的中度正相关，这提供了生物智能和人工智能共享原则的初步证据。", "conclusion": "研究发现，大型语言模型在完成抽象模式任务时形成的代表能够特殊地在其中间层聚类抽象模式类别，且这种聚类的强度与任务上的表现成正比。任务最优LLM层的表征几何与人类前额叶FRPs之间存在中度正相关，而与其他电生理措施（响应锁定的ERP和静息EEG）的对比结果则显示出不同的趋势，这暗示了抽象模式可能拥有共享的表征空间。这些发现表明，大型语言模型可能在抽象推理过程中再现了人类大脑机制，为生物智能和人工智能共享原则提供了初步证据。"}
{"llm_update_time": "20250816", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.10147", "html_url": "https://arxiv.org/abs/2508.10147", "title": "rETF-semiSL: 半监督学习中时间数据中的神经崩塌", "title_en": "rETF-semiSL: Semi-Supervised Learning for Neural Collapse in Temporal Data", "authors": "Yuhan Xie,William Cappelletti,Mahsa Shoaran,Pascal Frossard", "background": "深度神经网络处理时间序列数据时必须捕捉复杂的时序模式，以有效表示动态数据。自我监督和半监督学习方法在预训练大型模型方面显示出有前途的结果，这些模型在微调分类任务时往往比从头开始训练的模型表现出色。然而，预训练的替代任务选择通常是基于直觉的，它们对下游分类任务的迁移效果并未得到保证。因此，本文提出了一种新的半监督预训练策略，以确保隐藏表示满足在最优训练的神经分类器中观察到的神经崩塌现象。此外，通过集成生成性预训练任务和伪标记来预训练深层编码器，并定义了一种新的序列增强策略，以有效捕捉时间动态和嵌入的可分性。", "innovation": "本文提出了一种新的半监督预训练策略，利用旋转等角紧框架分类器和伪标注来预训练具有少量标记样本的深层编码器，通过集成生成性预训练任务和定义一种新的序列增强策略，以有效捕捉时间动态的嵌入性和可分性，此策略显著优于先前应用于LSTMs、变压器和状态空间模型的多元时间序列分类数据集中的预训练任务。", "conclusion": "与先前的任务相比，本文的方法在LSTMs、变压器和状态空间模型上应用于三个多元时间序列分类数据集时表现出显著的优越性。实验结果突显了将预训练目标与理论支撑的嵌入几何对齐的好处。"}
{"llm_update_time": "20250816", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.10156", "html_url": "https://arxiv.org/abs/2508.10156", "title": "利用基于生成人工智能（GenAI）的合成和实际田间图像及自定义EfficientNetV2-L模型提高西瓜（Citrullus lanatus）疾病分类", "title_en": "Improving watermelon (Citrullus lanatus) disease classification with generative artificial intelligence (GenAI)-based synthetic and real-field images via a custom EfficientNetV2-L model", "authors": "Nitin Rai,Nathan S. Boyd,Gary E. Vallad,Arnold W. Schumann", "background": "当前生成人工智能（GenAI）模型的进步为生成高分辨率合成图像提供了新的可能性，这些图像可用于农业中训练计算机视觉模型。在作物病害诊断中，GenAI模型正在用于创建各种病害的合成图像，这可能促进模型创建并减少对资源密集型田间数据采集的依赖。然而，对结合真实和合成图像以提高疾病分类性能的研究有限。", "innovation": "这项研究旨在探讨是否可以将有限数量的真实图像与合成图像结合以增强EfficientNetV2-L模型对西瓜病害的分类预测准确性。所有治疗方案都在相同的自定义EfficientNetV2-L架构中进行了增强的微调和迁移学习技术的训练。结果显示，H2、H3和H4治疗方案中的模型显示出高精度、召回率和F1分数。值得注意的是，从H0到H3-H4，加权F1分数显著提高，表明少量真实图像与大量合成图像相结合可以提高模型的性能和泛化能力。", "conclusion": "综合结果表明，仅使用合成图像无法充分替代真实图像；相反，两者必须以混合方式进行使用，以最大化作物病害分类模型的性能。"}
{"llm_update_time": "20250816", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.10148", "html_url": "https://arxiv.org/abs/2508.10148", "title": "使用反事实距离进行离群值检测", "title_en": "Out-of-Distribution Detection using Counterfactual Distance", "authors": "Maria Stoica,Francesco Leofante,Alessio Lomuscio", "background": "为了安全使用机器学习系统，需要进行准确且可解释的离群值（OOD）检测。先前的研究表明，特征与决策边界之间的距离可以有效识别离群值数据。本文基于这一直觉，提出了一种后处理的OOD检测方法，该方法利用反事实解释计算输入与决策边界之间的距离。然而，对于大型架构来说，计算解释可能很昂贵，因此还提出了直接在嵌入空间中计算反事实的方法以提高可扩展性。此方法的关键在于，利用反事实解释可以帮助我们的探测器结果进行解释，使其更具有可解释性.", "innovation": "本文提出了一个后处理的OOD检测方法，该方法通过利用反事实解释来计算输入与决策边界之间的距离，这种方法在计算解释方面更为高效，并且能增强方法的可解释性。此外，针对大型架构，提出了直接在嵌入空间中计算反事实的方法来提高可扩展性，同时利用反事实解释帮助解释检测结果，使其更具有解释性.", "conclusion": "我们在四个离群值数据集上展示了该方法与当前最先进的方法相比的优势，特别是在CIFAR-100和ImageNet-200数据集上，分别达到了97.05%的AUROC和13.79%的FPR95，在CIFAR-10数据集上则达到了93.50%的AUROC和25.80%的FPR95。"}
{"llm_update_time": "20250816", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.10137", "html_url": "https://arxiv.org/abs/2508.10137", "title": "mSCoRe: 一种多语言可扩展的基于技能的常识推理基准", "title_en": "mSCoRe: a $M$ultilingual and Scalable Benchmark for $S$kill-based $Co$mmonsense $Re$asoning", "authors": "Nghia Trung Ngo,Franck Dernoncourt,Thien Huu Nguyen", "background": "最新的具有推理能力的大型语言模型（LLMs）在复杂推理任务中展现了显著的能力。然而，这些模型在使用不同的人类推理技能方面的工作机制仍然知之甚少，尤其是在涉及不同语言和文化日常生活知识的多语言常识推理方面。目前缺乏一个系统全面评估LLM推理能力的基准。因此，需要开发一个新的基准以填补这些空白，从而更好地理解和改进LLMs在多语言常识推理中的表现及其能力边界。", "innovation": "本研究提出了一种名为mSCoRe的新基准，它包含三个关键组件：（1）一种新的推理技能分类法，用于细粒度分析模型的推理过程；（2）一个专门用于常识推理评估的数据合成流水线；（3）一种复杂度扩展框架，使任务难度能够随着未来LLM能力的提升而动态扩展。通过在八个不同规模和训练方法的最新LLM上进行的实验，表明当前模型在mSCoRe上仍然具有很高的挑战性，尤其是在较高复杂度级别时。此外，研究结果揭示了这些增强推理能力的模型在面对复杂的多语言常识推理时的局限性，包括具体的文化常识。为解决这些问题，研究提供了详细的模型推理过程分析，指出了改进多语言常识推理能力的方向。", "conclusion": "实验结果显示，当前的LLM在较高复杂度的多语言常识推理方面仍然面临挑战。mSCoRe揭示了现有的推理增强模型在应对复杂的多语言常识和文化常识时的局限性。未来的研究方向应侧重于提高模型在这些领域的表现，以更好地理解和应对不同的语言和文化背景下的常识推理问题。"}
{"llm_update_time": "20250816", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.10123", "html_url": "https://arxiv.org/abs/2508.10123", "title": "Nested-ReFT：通过离策 rollout 提升大型语言模型精调效率的高效强化学习", "title_en": "Nested-ReFT: Efficient Reinforcement Learning for Large Language Model Fine-Tuning via Off-Policy Rollouts", "authors": "Maxime Heuillet,Yufei Cui,Boxing Chen,Audrey Durand,Prasanna Parthasarathi", "background": "在面对如数学推理等具有挑战性的领域时，高级推理能力可以通过基于验证性奖励的强化微调（ReFT）方法来解决。标准的ReFT框架中，一个行为模型会为每个问题生成多个完成项并用奖励函数进行评分。尽管这类基于强化学习的后训练方法在多个推理领域展示了显著的性能提升，但在训练过程中进行多次推理步骤生成完成项会导致高昂的计算成本，使得训练费用变得不切实际。", "innovation": "本文借鉴离策RL和推测性解码，提出了一个新的ReFT框架——Nested-ReFT，该框架中的目标模型的一部分层作为行为模型，在训练过程中生成离策完成项。训练过程中配置了动态层跳过的机制，减少了推理成本，与标准ReFT框架相比。理论分析表明，Nested-ReFT提供了无偏梯度估计且方差可控。实证分析表明，Nested-ReFT在多个数学推理基准和不同模型大小上，以每秒token数衡量的计算效率得到了提升。此外，本文探讨了三种减少梯度更新偏倚性的偏差缓解策略，以保持性能与基线ReFT相当.", "conclusion": "实验结果表明，Nested-ReFT 能有效减少计算成本，同时提升了多种数学推理基准的计算效率，这一方法允许在不牺牲性能的前提下微调大型语言模型。"}
{"llm_update_time": "20250816", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.10208", "html_url": "https://arxiv.org/abs/2508.10208", "title": "CATNet: 一种几何深度学习方法，用于初级市场中的巨灾债券利差预测", "title_en": "CATNet: A geometric deep learning approach for CAT bond spread prediction in the primary market", "authors": "Dixon Domfeh,Saeid Safarveisi", "background": "传统模型在定价巨灾（CAT）债券时难以捕捉这些工具中固有的复杂、关系型数据。文章介绍了CATNet，这是一种利用关系图卷积网络（R-GCN）进行几何深度学习的新框架，将其作为图来建模巨灾债券一级市场，从而利用其潜在的网络结构来预测价差。", "innovation": "CATNet使用了关系图卷积网络（R-GCN）架构，将巨灾债券市场建模为图，利用其网络结构进行预测。研究发现，巨灾债券市场呈现出无标度网络的特征，由少数高连接性和有影响力的中心节点主导。CATNet在预测性能上实现了显著的提升，超越了强大的随机森林基准模型。将拓扑中心性度量作为特征进一步提升了准确性。", "conclusion": "CATNet通过网络连通性揭示了定价的关键因素，为风险评估提供了新的范式，并证明图基模型不仅能提供最先进的精确度，还能提供更深入的、量化的市场洞察。"}
{"llm_update_time": "20250816", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.10222", "html_url": "https://arxiv.org/abs/2508.10222", "title": "通过emoji预测理解文本情感", "title_en": "Understanding Textual Emotion Through Emoji Prediction", "authors": "Ethan Gordon,Nishank Kuppa,Rigved Tummala,Sriram Anasuri", "background": "该研究旨在利用深度学习架构预测短文本序列中的emoji。研究使用了TweetEval数据集，并针对类别不平衡问题使用了焦点损失和正则化技术。", "innovation": "研究探索了四种深度学习架构（前馈网络、CNN、Transformer和BERT）在emoji预测中的应用，并通过焦点损失和正则化技术处理了类别不平衡问题。研究发现BERT在整体性能上表现最佳，而CNN在罕见emoji类别上的表现尤为突出。此外，研究强调了模型架构选择和超参数调整的重要性和贡献。", "conclusion": "研究结果表明，对于情感感知的emoji预测，架构选择和超参数调整至关重要。这有助于提升人机交互的质量。"}
{"llm_update_time": "20250816", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.10252", "html_url": "https://arxiv.org/abs/2508.10252", "title": "促进AI系统的长期交互研究", "title_en": "Facilitating Longitudinal Interaction Studies of AI Systems", "authors": "Tao Long,Sitong Wang,Émilie Fabre,Tony Wang,Anup Sathya,Jason Wu,Savvas Petridis,Dingzeyu Li,Tuhin Chakrabarty,Yue Jiang,Jingyi Li,Tiffany Tseng,Ken Nakagaki,Qian Yang,Nikolas Martelaro,Jeffrey V. Nickerson,Lydia B. Chilton", "background": "用户与人工智能的交互会随时间变化，需要通过学习、适应和重新利用来评估，一次性评估方法已经不足以捕捉这些动态变化。长期以来，关于部署、评估设计和数据收集的挑战使得跨时间的长期研究难以实现。", "innovation": "会议的目的是解决这些挑战，为研究人员提供实用的战略，以实施长期研究。会议包含主题演讲、讨论会和互动分组讨论，进行协议设计的手把手指导和工具原型制作。", "conclusion": "会议旨在促进长期系统研究的社区，并提倡这种研究方法在UIST工具设计、开发和评估中的更广泛使用。"}
{"llm_update_time": "20250816", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.10186", "html_url": "https://arxiv.org/abs/2508.10186", "title": "PakBBQ: 适合问答的文化适应偏见基准", "title_en": "PakBBQ: A Culturally Adapted Bias Benchmark for QA", "authors": "Abdullah Hashmat,Muhammad Arham Mirza,Agha Ali Raza", "background": "随着大规模语言模型（LLMs）在各个应用中的广泛应用，确保其在所有用户群体中的公平性变得至关重要。然而，大多数LLMs都是基于西方中心的数据进行训练和评估，缺乏对资源有限语言和区域背景的关注。为了解决这一问题，本文引入了PakBBQ，这是一种文化适应扩展的原版问答偏见基准（BBQ）数据集。PakBBQ包括超过214种模板，涵盖8个类别中的17180个问答对，既包含英文也包含乌尔都语。数据集覆盖了与巴基斯坦相关的八个偏见维度，包括年龄、残疾、外貌、性别、社会经济状况、宗教、区域关联和语言形式化等方面。该数据集在不同语境下的多语言模型上进行了评估，包括模糊和明确语境下的评估，以及负面与非负面问题框架下的评估。", "innovation": "PakBBQ是一种文化适应扩展的原版问答偏见基准数据集，涵盖了巴基斯坦相关的关键偏见维度。论文指出，在模糊和明确的语境下评估多个多语言模型时，发现与文本重述效果相比，对于解决问题的表述方式对偏见缓解有着显著影响，这表明在低资源环境中，上下文相关基准和简单的提示工程策略对于偏见缓解的重要意义。此外，还发现了乌尔都语相比英语，在反偏见行为上的持续优势。", "conclusion": "实验结果表明，具有澄清的表述可以提高平均准确率12%；乌尔都语在反偏见行为上比英语更强大；并且，负面问题的说法可以减少刻板印象的回应。这些发现强调了低资源环境中的上下文相关基准和简单提示策略对于偏见缓解的重要性。"}
{"llm_update_time": "20250816", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.10226", "html_url": "https://arxiv.org/abs/2508.10226", "title": "使用大型语言模型衡量精神病高风险患者症状严重程度", "title_en": "Using Large Language Models to Measure Symptom Severity in Patients At Risk for Schizophrenia", "authors": "Andrew X. Chen,Guillermo Horga,Sean Escola", "background": "对于临床高度风险（CHR）的分裂情感障碍患者，需要密切监测其症状以指导适当的治疗。布雷德精神病学评定量表（BPRS）是一个已经验证的常用研究工具，用于测量分裂情感障碍和其他精神病性障碍患者的症状，但由于其需要较长的结构化访谈，所以在临床实践中并未广泛应用。", "innovation": "研究利用大型语言模型（LLMs）来预测来自409名来自AMP-SCZ队列的CHR患者临床访谈录音上的BPRS评分。结果显示，LLM的预测表现（中位相关性：0.84，ICC：0.73）接近人类的重测信度和同测信度。进一步研究表明，LLM在处理多语言环境（中位相关性：0.88，ICC：0.70）和整合纵向信息时具有较强的学习潜力。", "conclusion": "大型语言模型能够有效地预测BPRS评分，并具有在多语言环境下提高和标准化CHR患者评估的潜力。"}
{"llm_update_time": "20250816", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.10210", "html_url": "https://arxiv.org/abs/2508.10210", "title": "基于解释性人工智能的方法来监测动物健康", "title_en": "An Explainable AI based approach for Monitoring Animal Health", "authors": "Rahul Janaa,Shubham Dixit,Mrityunjay Sharma,Ritesh Kumar", "background": "奶牛健康监测和优化产出是牧场主面临的关键挑战，由于难以全面追踪场内所有动物，这一挑战尤为突出。这项研究旨在展示基于可解释机器学习(ML)方法的现代数据驱动农业实践，这些方法能解释奶牛的行为和活动。通过使用3轴加速度计传感器不间断地收集数据，并结合稳健的ML方法和算法，为农民和研究人员提供了关于奶牛活动的实际信息，使他们能够做出明智的决策并采用可持续的做法。研究利用基于蓝牙的物联网设备和4G网络进行无缝数据传输，并即时分析和生成推断，使用解释模型表现的框架说明其性能。特别强调了加速度计时间序列数据的预处理，包括统计特征提取、信号处理技术和滑动窗口技术基础上的滞后特征。根据不同窗口长度对多种超参数优化的ML模型进行评估，用于活动分类。K最近邻分类器表现最佳，训练集上AUC的平均值为0.98，标准差为0.0026，测试集上为0.99。为了确保透明性，使用基于解释性AI的框架如SHAP来解释特征的重要性，这些特征可以被实践者理解和使用。详细的重要特征比较及所选特征的稳定性分析支持了开发解释性和实用的ML模型以实现可持续牧场管理的发展", "innovation": "该研究采用基于蓝牙的物联网设备和4G网络进行无缝数据传输，结合可解释的机器学习方法和算法，对加速度计时间序列数据进行处理，并通过K最近邻分类器实现最优的动物活动分类性能，同时使用解释性AI框架提高模型的透明度和实用性，有助于农民和研究人员做出更准确的决策并采取可持续管理措施", "conclusion": "研究表明，通过增强型传感器数据收集和解释性的ML模型，能够提高对奶牛健康的监控水平和可持续牧场管理决策的质量。这种方法有效地实现了数据驱动的农业实践，为未来的研究和实践提供了补充和推进作用。"}
{"llm_update_time": "20250816", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.10230", "html_url": "https://arxiv.org/abs/2508.10230", "title": "从音频预训练的角度来看生物声学领域中没有免费的午餐：一个嵌入的基准研究", "title_en": "No Free Lunch from Audio Pretraining in Bioacoustics: A Benchmark Study of Embeddings", "authors": "Chenggang Chen,Zhiyu Yang", "background": "生物声学作为研究动物声音的方法提供了一种无创的方式监测生态系统。近年来，使用音频预训练的深度学习（DL）模型以嵌入方式提取特征成为了一个热门方向。尽管预训练的VGG和变压器模型在某些任务中可以达到最先进的性能，但最近的一项基准研究表明，在其他任务中它们可能表现不佳，这引发了关于这些模型是否需要进一步微调的讨论。本文旨在通过降低这些模型学习嵌入的维度并进行聚类来衡量它们在相同任务上的表现，以揭示音频预训练模型的表现情况。", "innovation": "本文通过减少预训练DL模型学习嵌入的维度并通过聚类评估它们在不同任务上的表现，整体上在生物声学领域进行了一次嵌入的基准研究。研究表明，无论是预训练还是微调的DL模型在分离背景声音方面表现不佳，只有ResNet模型表现优秀。此外，研究还强调了微调的重要性，并在微调后检查了嵌入的表现。这些发现为生物声学领域的模型选择提供了新的视角。", "conclusion": "研究结果表明，音频预训练的DL模型在某些情况下表现较差，微调对于提高模型性能至关重要。尽管使用音频预训练模型进行特征提取是一个趋势，但该研究指出，在处理生物声学任务时需要谨慎使用这些模型，并可能需要根据具体情况选择是否微调以及使用哪种模型能够提供最佳性能。"}
{"llm_update_time": "20250816", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.10264", "html_url": "https://arxiv.org/abs/2508.10264", "title": "MRFD: 多区域融合解码与自我一致性在减轻LVLMs幻觉中的应用", "title_en": "MRFD: Multi-Region Fusion Decoding with Self-Consistency for Mitigating Hallucinations in LVLMs", "authors": "Haonan Ge,Yiwei Wang,Ming-Hsuan Yang,Yujun Cai", "background": "大型的多模态视觉-语言模型（LVLMs）在多种任务中表现出强大的性能，但由于对图像不同区域信息验证能力的限制，它们往往会生成不准确的文本，即所谓的幻觉。这种不一致的问题限制了LVLMs的实际应用效果和可信度。现有方法通常需要在训练过程中进行额外处理，这可能会增加模型的复杂性和计算负担。因此，研究一种无需训练即可有效提高事实对接能力的方法具有重要意义和应用价值。", "innovation": "提出了一种名为Multi-Region Fusion Decoding（MRFD）的无训练解码方法，通过建模不同区域间的一致性来提高事实对接能力。MRFD采用交叉注意力机制识别图片中的重要区域，为每个重要区域生成初始响应，并基于Jensen-Shannon Divergence (JSD)计算机算权重。这些权重指导基于链式推理灵感的区域感知提示驱动的一致性融合，从而在不调整模型更新的前提下，显著减少幻觉并提高回应的准确性。", "conclusion": "实验结果表明，MRFD方法在多个LVLMs和基准测试中都有效，能够有效减少幻觉现象，提高响应的事实准确性。该技术为解决大型视觉-语言模型中的幻觉问题提供了新的思路，对于改进多模态模型的实际应用具有重要意义。"}
{"llm_update_time": "20250816", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.10192", "html_url": "https://arxiv.org/abs/2508.10192", "title": "大型语言模型的提示-响应语义偏差度量：用于忠实性幻觉和对齐检测", "title_en": "Prompt-Response Semantic Divergence Metrics for Faithfulness Hallucination and Misalignment Detection in Large Language Models", "authors": "Igor Halperin", "background": "大型语言模型（LLMs）的普及面临着幻觉的挑战，即模型生成不真实、不合逻辑或不忠实的文本。文献中已有的方法，如语义熵，通过测量单一固定提示的答案多样性来检测任意性问题。然而这些方法缺乏对提示和响应间更为深入的语义对齐的检测能力。因此，本文旨在通过引入语义偏差度量（SDM）框架解决这个问题，SDM框架能够对多个等价的提示语义变化下的响应一致性进行评估，进一步测量提示和响应之间的语义差异。这种方法通过联合聚类句嵌入来创建提示与答案之间的共享主题空间，进一步使用信息论中的度量标准来评估语义偏差，提出一个新的综合评分指标 $S_H$。同时，本文引入了KL散度的使用，用以反映模型在生成文本过程中进行的语义探索。这些度量进一步被整合成一个称为语义盒子的诊断框架，用于分类LLM的响应类型，包括危险的、自信的幻觉情况。", "innovation": "该论文创新地提出了语义偏差度量（SDM）框架，通过联合聚类句嵌入来创建共享话题空间，以此检测LLMs在上下文中的语义偏差，特别是针对严重的语义不一致情况，即所谓的自编（confabulations）。这些自编通常是任意的、与用户查询隐含语义不一致。SDM框架通过测量响应在多个提示和它们的语义等价变异版本之间的深度一致性，进一步提高了检测任意性的能力。此外，该论文还利用信息理论度量，特别是结合了Jensen-Shannon散度和Wasserstein距离的新综合评分指标 $S_H$，以及KL散度表征语义探索，开发了一个诊断框架——语义盒子，用于识别LLM的生成行为类型。", "conclusion": "通过SDM框架，本文提供了一种新的方法来检测LLM的代表性生成问题，特别是针对严重偏离输入语境的自编现象。SDM框架不仅能够评价提示和响应之间的深层面语义一致性，还能通过$\boldsymbol{S_H}$评分和语义盒诊断框架对模型生成行为进行分类，给出更深入的见解和更强大的检测能力。最终，该研究为LLM领域提供了重要的贡献，尤其是在应对幻觉问题的检测和解决方面。"}
{"llm_update_time": "20250816", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.10260", "html_url": "https://arxiv.org/abs/2508.10260", "title": "DINOMotion：2D-Cine MRI引导放疗中基于DINOv2的高级鲁棒组织运动跟踪", "title_en": "DINOMotion: advanced robust tissue motion tracking with DINOv2 in 2D-Cine MRI-guided radiotherapy", "authors": "Soorena Salari,Catherine Spino,Laurie-Anne Pharand,Fabienne Lathuiliere,Hassan Rivaz,Silvain Beriault,Yiming Xiao", "background": "在2D-Cine MRI引导的放疗中，准确的组织运动跟踪对于确保治疗结果和安全性至关重要。现有方法通过序列图像的配准来实现，但常面临大错位和缺乏解释性的问题。特别是在处理大错位时，现有方法往往表现不佳且缺乏可解释性。针对这些问题，该研究旨在提出一种新的基于DINOv2和Low-Rank Adaptation (LoRA)层的深度学习框架DINOMotion，以提高运动跟踪的鲁棒性、效率和可解释性。", "innovation": "DINOMotion 引入了基于DINOv2和LoRA层的新型深度学习框架，通过自动检测对应特征点来增强图像配准的效果，从而提高跟踪过程的可解释性。LoRA层减少了可训练参数，提高了模型的训练效率；而DINOv2强大的特征表示能力使其能够抵抗大错位。此外，DINOMotion在测试过程中直接计算图像配准，而不需要迭代优化。研究结果表明，DINOMotion 做出了有效的线性和非线性变换估计，针对肾脏、肝脏和肺部的Dice分数分别为92.07%、90.90%和95.23%；同时，该方法在处理大错位方面表现出色，优于当前最先进的方法。", "conclusion": "研究的结果展示了DINOMotion作为实时2D-Cine MRI引导放疗中鲁棒且可解释的运动跟踪解决方案的潜力，尤其是在处理大错位方面。"}
{"llm_update_time": "20250816", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.10268", "html_url": "https://arxiv.org/abs/2508.10268", "title": "手机上基于姿态鲁棒的点注视估计校准策略", "title_en": "Pose-Robust Calibration Strategy for Point-of-Gaze Estimation on Mobile Phones", "authors": "Yujie Zhao,Jiabei Zeng,Shiguang Shan", "background": "尽管基于外观的点注视（PoG）估计已有所改进，但估计器仍然难以泛化跨个体，因为个体差异仍然存在。因此，针对准确的PoG估计，需要针对每个个体进行校准。然而，校准过的PoG估计器通常对头部姿态差异敏感。为解决这一问题，研究者们探索了影响校准估计器的关键因素，并寻找姿态鲁棒的校准策略。现有的校准策略多是固定的头部姿态校准，这种变化范围较小的可能性会影响校准精确度，并使得估计器难以应对姿态变化带来的影响。因此，作者构建了MobilePoG基准，包括32个体的面部图像，并聚焦于不同的校准点和不断变化的头部姿态，从而系统分析了校准点多样性及头部姿态多样性对估计精度的影响。实验发现，校准过程中引入更广泛的头部姿态范围有助于提升估计器处理姿态变化的能力。通过此研究，作者提出了一个动态校准策略，用户在移动手机的同时注视指定校准点，这种策略自然地在用户友好且高效的过程中引入了头部姿态的变化，并生成了一个比传统校准策略更不易受到姿态变化影响的校准后的PoG估计器。", "innovation": "提出了一个新的基于姿态鲁棒的校准策略。构建了一个新的基准MobilePoG，该基准包括面部图像和指定的校准点以及不断变化的头部姿态。利用该基准，系统分析了校准点多样性及头部姿态多样性对估计精度的影响。提出了一种动态校准策略，用户在移动手机上注视指定校准点，该策略在用户友好且高效的过程中引入了头部姿态的变化。", "conclusion": "在动态校准策略的帮助下，生成的校准后的PoG估计器比使用传统校准策略的估计器更少受到头部姿态变化的影响。代码和数据集可在项目页面获取。"}
{"llm_update_time": "20250816", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.10345", "html_url": "https://arxiv.org/abs/2508.10345", "title": "基于福利中心的聚类", "title_en": "Welfare-Centric Clustering", "authors": "Claire Jie Zhang,Seyed A. Esmaeili,Jamie Morgenstern", "background": "公平聚类通常侧重于确保群体代表性的公平或使某些特定群体的聚类成本平等化。然而，Dickerson等人（2025）的研究表明，这些公平性概念可能会导致不理想的或非直观的聚类结果。因此，他们提倡以福利为中心的聚类方法，这种方法旨在最大化群体的福利。", "innovation": "本文提出了基于距离和比例代表性的群体福利建模，并正式提出了基于福利中心聚类的两个优化目标：罗尔斯式（最低限度主义）目标和功利主义目标。引入了这两个目标的新型算法，并提供了理论保证。实证研究表明，本文方法显著优于现有的公平聚类基准。", "conclusion": "本研究通过提出基于距离和比例代表性的群体福利建模，以及构建贝叶斯概率监督的SVM分类器，为公平聚类提供了新的视角，并通过实验证明了新方法的有效性和优越性。这种方法为聚类算法提供了新的优化目标和理论保证，有望在实际数据集中表现更好。"}
{"llm_update_time": "20250816", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.10315", "html_url": "https://arxiv.org/abs/2508.10315", "title": "一种由视觉-语言预训练模型引导的联邦学习中抵御后门攻击的方法", "title_en": "A Vision-Language Pre-training Model-Guided Approach for Mitigating Backdoor Attacks in Federated Learning", "authors": "Keke Gai,Dongjue Wang,Jing Yu,Liehuang Zhu,Qi Wu", "background": "现有的联邦学习（FL）后门防御方法依赖于客户端数据分布同质或干净服务数据集的假设，这限制了其实际应用的有效性。在客户端数据分布异质的情况下，保持模型性能的同时防御后门攻击仍然是一个重大挑战。", "innovation": "提出了一种名为CLIP-Fed的联邦学习后门防御框架，其利用视觉-语言预训练模型的零样本学习能力。CLIP-Fed通过预聚合和后聚合的防御策略相结合，克服了非 IID 数据对防御效果的限制。通过使用多模态大语言模型和频率分析构造扩充的服务数据集，同时针对各种触发器增强数据集的覆盖范围，解决隐私问题。CLIP-Fed使用原型对比损失和Kullback-Leibler散度对增强数据集上的全局模型和CLIP的先验知识进行对齐，消除后门样本导致的类原型偏差以及触发模式与目标标签之间的相关性。", "conclusion": "在代表性的数据集上进行的广泛实验验证了CLIP-Fed的有效性。与最先进的方法相比，CLIP-Fed在CIFAR-10上的平均ASR降低了2.03%，在CIFAR-10-LT上的ASR降低了1.35%，同时分别将平均马氏距离提高了7.92%和0.48%。"}
{"llm_update_time": "20250816", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.10308", "html_url": "https://arxiv.org/abs/2508.10308", "title": "ReviewRL：基于强化学习的自动化科学研究评审", "title_en": "ReviewRL: Towards Automated Scientific Review with RL", "authors": "Sihang Zeng,Kai Tian,Kaiyan Zhang,Yuru wang,Junqi Gao,Runze Liu,Sa Yang,Jingxuan Li,Xinwei Long,Jiaheng Ma,Biqing Qi,Bowen Zhou", "background": "同行评审对科学进步至关重要，但随着提交数量的增加和审稿人的疲劳，面临越来越多的挑战。现有的自动化评审方法在事实准确性、评分一致性和分析深度方面存在困难，往往生成浅显或通用的反馈，缺乏高质量人类评审所具有的独到见解。", "innovation": "我们提出了ReviewRL，一种基于强化学习的生成全面和基于事实的科学论文评审框架。该方法结合了：（1）一个利用相关科学文献的ArXiv-MCP检索增强上下文生成管道；（2）监督微调，建立初步的评审能力；（3）一种结合奖励函数的强化学习过程，共同提升评审质量和评分准确性。在ICLR 2025论文上的实验表明，ReviewRL在规则基础的评估指标和模型基础的质量评估中均显著优于现有方法。", "conclusion": "ReviewRL为强化学习驱动的自动批评生成奠定了基础框架，在科学发现领域展示了未来发展的前景。ReviewRL的实现将在GitHub上发布。"}
{"llm_update_time": "20250816", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.10332", "html_url": "https://arxiv.org/abs/2508.10332", "title": "层析分析自监督表征在儿童语音年龄和性别分类中的应用", "title_en": "Layer-Wise Analysis of Self-Supervised Representations for Age and Gender Classification in Children's Speech", "authors": "Abhijit Sinha,Harishankar Kumar,Mohit Joshi,Hemant Kumar Kathania,Shrikanth Narayanan,Sudarsana Reddy Kadiri", "background": "儿童的语音在年龄和性别分类上具有挑战性，因为儿童的音高、发音和发育特征变化大。尽管自监督学习（SSL）模型在成人语音任务中的表现良好，但它们识别儿童语音特性的能力尚未得到充分探索。现有的研究和实践对这一领域的认知尚不充分。", "innovation": "本研究通过分层分析四种Wav2Vec2变体（使用PFSTAR和CMU Kids数据集），详细探讨SSL模型在编码儿童语音中的性别和年龄特征。研究表明，早期层（第1-7层）比深层层更有效地捕捉到特定的说话人线索，而深层层则逐渐集中于语言信息。此外，研究还展示了如何通过主成分分析（PCA）进一步提高分类效果。Wav2Vec2-large-lv60模型在CMU Kids数据集上达到97.14%的年龄分类准确率和98.20%的性别分类准确率，而基本模型base-100h和大型模型large-lv60在PFSTAR数据集上的分类准确率分别为86.05%和95.00%。这些结果揭示了SSL模型深度与说话人特性结构之间的关系，并支持了更为精确和适应性的儿童语音接口策略。", "conclusion": "研究表明，SSL模型的早期层比深层层更有效地捕捉儿童的年龄和性别特征。通过应用PCA可以进一步提高分类效果，减少冗余并突出最有效的成分。不同规模的Wav2Vec2模型在儿童语音分类上表现出不同的准确率，这为构建儿童意识的语音接口提供了新思路。"}
{"llm_update_time": "20250816", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.10383", "html_url": "https://arxiv.org/abs/2508.10383", "title": "通过仅标签弹性变形解决隐式标签噪声实现稳健语义分割性能", "title_en": "Unlocking Robust Semantic Segmentation Performance via Label-only Elastic Deformations against Implicit Label Noise", "authors": "Yechan Kim,Dongho Yoon,Younkwan Lee,Unse Fatima,Hong Kook Kim,Songjae Lee,Sanga Park,Jeong Ho Park,Seonjong Kang,Moongu Jeon", "background": "之前的图像分割研究主要集中在处理严重的（或明确的）标签噪声，但现实中数据集还存在轻微的（或隐含的）标签不完美现象。这些不完美现象源于固有的挑战，例如物体边界模糊和标注者差异。尽管不明显，这类温和且潜在的噪声也会损害模型性能。常见的数据增强方法会对图像及其标签应用相同的变换，这可能会放大这些细微的不完美，从而限制模型的泛化能力。", "innovation": "本文提出了一种名为NSegment+的新颖增强框架，该框架解耦图像和标签变换，以应对这些现实中的噪声。通过在保留原始图像的情况下仅对分割标签引入可控的弹性变形，该方法鼓励模型专注于学习对象结构的稳健表示，即使在存在轻微标签不一致性的情况下。", "conclusion": "广泛的实验结果表明，NSegment+可以显著提高性能，在Vaihingen、LoveDA、Cityscapes和PASCAL VOC数据集上分别获得了2.29%、2.38%、1.75%和3.39%的mIoU提升。即使不采用额外的技术，这种提升也强调了解决隐式标签噪声的重要性。结合其他训练技巧（如CutMix和Label Smoothing），这些收益可以进一步放大。"}
{"llm_update_time": "20250816", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.10304", "html_url": "https://arxiv.org/abs/2508.10304", "title": "另一种算法偏见：大型语言模型强化性别和种族主导话语的论述分析", "title_en": "Yet another algorithmic bias: A Discursive Analysis of Large Language Models Reinforcing Dominant Discourses on Gender and Race", "authors": "Gustavo Bonil,Simone Hashiguti,Jhessica Silva,João Gondim,Helena Maia,Nádia Silva,Helio Pedrini,Sandra Avila", "background": "随着人工智能（AI）的发展，大型语言模型（LLMs）变得至关重要并在各种情境中得到应用。随着这些模型变得越来越复杂，评估它们在生成文本时是否会再现歧视、刻板印象等问题变得尤为关键。当前的偏见检测方法主要依赖于定量的自动化方法，但这些方法往往忽视了偏见在自然语言中细微多变的表现形式。本文通过分析LLM生成的描写黑人和白人女性的短篇故事，探讨性别和种族偏见。", "innovation": "本文提出了一种定性的、论述法的框架，旨在补充现有的定量评估方法。通过手工分析LLM生成的故事，并由此揭示性别和种族偏见的具体表现方式，从而帮助开发人员和用户更好地识别并缓解这些偏见。结果表明，LLM在描写黑人女性时，倾向于将其与血统和抗争联系在一起，而描述白人女性时，则更多地侧重于自我发现过程。这反映了语言模型如何复制固化的话语表现，强化本质化并固化社会流动性。当要求修正偏见时，模型提供的修改通常是表面的，并未能根本改变问题的本质，显示出培养包容性叙事的局限性。", "conclusion": "研究强调了算法的意识形态功能，并对AI的伦理使用和开发具有重要意义。研究支持采用批判性的、跨学科的方法来设计和部署AI，以解决LLM生成的话语如何反映和加剧不平等的问题。"}
{"llm_update_time": "20250816", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.10370", "html_url": "https://arxiv.org/abs/2508.10370", "title": "eMamba:边缘计算中Mamba模型的高效加速框架", "title_en": "eMamba: Efficient Acceleration Framework for Mamba Models in Edge Computing", "authors": "Jiyong Kim,Jaeho Lee,Jiahao Lin,Alish Kanani,Miao Sun,Umit Y. Ogras,Jaehyun Park", "background": "基于状态空间模型的状态空间模型（SSM）- 基籍的机器学习架构最近在处理序列数据方面引起了广泛关注。Mamba是最近的一种序列到序列的SSM，相比于最新一代的变换器模型，Mamba具有竞争力的精度和优越的计算效率。这一优点使得Mamba特别适合在资源受限的边缘设备上部署。然而，目前没有针对这种环境进行优化的硬件加速框架。因此，本文提出了一种专门设计用于在边缘平台上部署Mamba模型的端到端硬件加速框架——eMamba。", "innovation": "eMamba通过用轻量级的硬件感知替代复杂归一化层，并对昂贵的操作（如SiLU激活和幂运算）进行近似，来最大化计算效率。此外，它还执行近似感知的神经架构搜索（NAS），以调整近似过程中使用的可学习参数。实验证明，eMamba在使用1.63-19.9倍更少的参数时，能达到与最先进的技术相当的精度，并在大规模自然语言任务中表现出良好的适应性，显示了在不同序列长度下的稳定困惑度。此外，eMamba还在基于AMD ZCU102 FPGA和GF 22 nm技术的ASIC上实现了整个管道的量化和实现，实验结果显示eMamba的延迟降低4.95-5.62倍，吞吐量提高2.22-9.95倍，面积减少4.77倍，功耗降低9.84倍，能耗减少48.6倍，同时保持竞争性的精度。", "conclusion": "eMamba为边缘计算环境中Mamba模型的高效部署提供了一个全面的硬件加速框架，通过硬件优化和近似搜索，显著提高了模型的计算效率和资源利用率，同时保持了竞争性的精度，证明了其在边缘计算环境中的高效性和适应性。"}
{"llm_update_time": "20250816", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.10397", "html_url": "https://arxiv.org/abs/2508.10397", "title": "PQ-DAF: 基于姿态的高质量数据增强方法在数据稀缺的驾驶员分神检测中的应用", "title_en": "PQ-DAF: Pose-driven Quality-controlled Data Augmentation for Data-scarce Driver Distraction Detection", "authors": "Haibin Sun,Xinghui Song", "background": "驾驶员分神检测对于提高交通安全和减少道路事故至关重要。然而，现有的模型在实际应用场景中部署时往往会出现泛化能力退化的问题。这一局限性主要是由实际环境中的数据标注成本高昂导致的少量样本学习挑战以及训练数据集与目标部署条件之间显著的领域转移造成的。", "innovation": "本文提出了一种基于姿态的质量控制数据增强框架（PQ-DAF），该框架利用视觉-语言模型进行样本筛选，以低成本扩展训练数据并增强跨域鲁棒性。具体而言，采用渐进条件扩散模型（PCDMs）准确捕捉关键的驾驶员姿态特征，并合成多样化的训练样本。在此基础上，基于CogVLM视觉-语言模型构建了一个样本质量评估模块，通过置信阈值筛选出低质量的合成样本，确保增强数据集的可靠性。", "conclusion": "广泛的实验表明，PQ-DAF在数据稀缺的驾驶员分神检测中显著提高了性能，特别是在数据稀缺条件下模型泛化能力方面取得了重要提升。"}
{"llm_update_time": "20250816", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.10404", "html_url": "https://arxiv.org/abs/2508.10404", "title": "利用稀疏自编码器进行层级扰动的对抗文本生成", "title_en": "Layer-Wise Perturbations via Sparse Autoencoders for Adversarial Text Generation", "authors": "Huizhen Shu,Xuying Li,Qirui Wang,Yuji Kosuga,Mengqiu Tian,Zhuo Li", "background": "随着自然语言处理（NLP）尤其是大规模语言模型（LLMs）的迅速发展，生成能够突破LLMs的对抗样本仍是理解和改进模型脆弱性的重要挑战。现有方法对于理解和改进这类模型的鲁棒性仍然存在局限，因此提出新的、利用大型模型可解释性的对抗样本生成方法至关重要。本文的研究背景在于如何有效生成能够突破LLMs的对抗样本，揭示当前NLP模型的持久性漏洞。", "innovation": "本文提出了一种新的黑盒攻击方法——稀疏特征扰动框架（SFPF），该方法利用稀疏自编码器来识别和操纵文本中的关键特征。通过该方法，对抗样本能够保留恶意意图同时强化安全信号，从而增强其逃逸现有防御机制的能力。这种方法提供了一种新的红蓝团队策略，平衡了对抗效果和安全性。实验结果显示SFPF生成的对抗样本能够绕过最先进的防御机制，揭示了当前NLP模型的持续性脆弱性。", "conclusion": "本文通过稀疏自编码器（Sparse Autoencoders）实现了层级扰动，证明了对抗样本生成方法的有效性。然而，该方法的有效性在不同提示和层之间存在差异，且其对其他架构和更大模型的泛化能力仍需验证。"}
{"llm_update_time": "20250816", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.10409", "html_url": "https://arxiv.org/abs/2508.10409", "title": "AnalogSeeker：面向模拟电路设计的开源基础语言模型", "title_en": "AnalogSeeker: An Open-source Foundation Language Model for Analog Circuit Design", "authors": "Zihao Chen,Ji Zhuang,Jinyi Shen,Xiaoyue Ke,Xinyi Yang,Mingjie Zhou,Zhuoyao Du,Xu Yan,Zhouyang Wu,Zhenyu Xu,Jiangli Huang,Li Shang,Xuan Zeng,Fan Yang", "background": "本文提出了一种名为AnalogSeeker的开源基础语言模型，旨在通过集成领域知识来促进模拟电路设计，并为其提供设计支持。为了解决该领域数据稀缺的问题，作者开发了一种基于模拟电路领域知识框架的语料库收集策略。通过系统地整理和清理相关子领域的高质量教科书，构建了一个文本领域的语料库。面对模拟电路知识的复杂性，作者引入了一种粒度化的领域知识提炼方法，将原始的非结构化文本分解为典型的粒度学习节点。在一个多智能体框架中，通过将隐含的知识提取为带有详细推理过程的问题-答案数据对，生成了一个细粒度、可学习的数据集，用于模型微调。", "innovation": "为了应对训练模拟电路基础模型中的未探索挑战，作者通过理论分析和实验验证探索并分享了他们的训练方法。引入了一种带邻域自我约束监督微调算法的微调中心的训练范式。这种方法通过在训练前后限制模型输出分布的变化幅度，增强了训练结果。通过训练Qwen2.5-32B-Instruct模型，实现了在模拟电路知识评估基准AMSBench-TQA上85.04%的准确性，比原始模型提高了15.67个百分点，并且在下游的运算放大器设计任务中表现出有效性。", "conclusion": "最终，AnalogSeeker已被开源用于研究使用，它在AMSBench-TQA基准测试中实现了85.04%的准确性，并在运算放大器设计任务中展现了有效性。该模型与主流商业模型具有竞争力。"}
{"llm_update_time": "20250816", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.10423", "html_url": "https://arxiv.org/abs/2508.10423", "title": "MASH: 协同异构多智能体深度强化学习在单个类人机器人运动中的应用", "title_en": "MASH: Cooperative-Heterogeneous Multi-Agent Reinforcement Learning for Single Humanoid Robot Locomotion", "authors": "Qi Liu,Xiaopeng Zhang,Mingshan Tan,Shuaikang Ma,Jinliang Ding,Yanjie Li", "background": "目前大多数研究方法主要使用单智能体深度强化学习算法来训练单一的人形机器人，或者使用多智能体强化学习算法来处理多个机器人的任务。此研究提出了一个创新的方法，即将协同异构多智能体深度强化学习（MARL）应用于单个人形机器人的运动优化。", "innovation": "提出了一种全新的方法——多智能体强化学习在单个人形机器人运动中的应用（MASH），将每个肢体（腿和臂）视为独立的智能体，通过共享全局批评家进行协同学习，实现加速训练收敛和增强整体配合能力的目标。", "conclusion": "该研究通过将MARL技术集成到单个人形机器人控制中，展示了在提高人形机器人全面协调能力方面的新进展，为高效的运动策略提供了新的见解。"}
{"llm_update_time": "20250816", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.10419", "html_url": "https://arxiv.org/abs/2508.10419", "title": "ComoRAG：一种启发认知的基于记忆组织的RAG模型，用于有状态的长叙事推理", "title_en": "ComoRAG: A Cognitive-Inspired Memory-Organized RAG for Stateful Long Narrative Reasoning", "authors": "Juyuan Wang,Rongchen Zhao,Wei Wei,Yufeng Wang,Mo Yu,Jie Zhou,Jin Xu,Liyan Xu", "background": "长故事和小说的叙述理解是一个具有挑战性的领域，由于其复杂的情节和角色及实体之间的交错关系。尽管大规模语言模型（LLM）在语言生成和理解方面的表现逐渐接近人类，但在处理长篇幅文本时，其推理能力会显著下降，且检索式方法（如传统的RAG方法）在处理长程上下文时也会忽视关系的动态变化，仅能进行单一的检索，难以把握记忆中的相关线索。", "innovation": "本研究提出了ComoRAG，一种基于认知的动态记忆组织的检索增强生成（RAG）模型。ComoRAG打破了传统的单一检索过程，通过迭代的推理循环和动态记忆工作区，可以不断地获取新技术据和整合过去的知识，模拟人类在处理与记忆相关的信号时的认知过程，从而在长篇幅复杂查询的理解上表现出色，相比最强的基线模型在四组长上下文叙事基准测试中表现出了11%的相对优势。", "conclusion": "ComoRAG提供了一种认知驱动的检索基线长上下文理解范式，特别适合需要全局理解的复杂查询，展示了基于记忆的长上下文推理的可能性，有助于提升长篇幅文本的叙述理解能力。相关代码已开源。"}
{"llm_update_time": "20250816", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.10416", "html_url": "https://arxiv.org/abs/2508.10416", "title": "CorrectNav: 自我修正飞轮赋能视觉-语言-动作导航模型", "title_en": "CorrectNav: Self-Correction Flywheel Empowers Vision-Language-Action Navigation Model", "authors": "Zhuoyuan Yu,Yuxing Long,Zihan Yang,Chengyan Zeng,Hongwei Fan,Jiyao Zhang,Hao Dong", "background": "现有的视觉和语言导航模型在执行指令时往往偏离正确的轨迹，但这些模型缺乏有效的错误修正能力，阻碍了它们从错误中恢复。", "innovation": "我们提出了自我修正飞轮（Self-correction Flywheel），这是一种新颖的后训练范式。该范式将模型在训练集上的错误轨迹视为有价值的资源，并开发了识别错误轨迹偏差的方法及自动生成感知和动作自我修正数据的创新技术。这些自我修正数据为模型提供了持续训练的燃料。通过多次飞轮迭代，逐步提升了基于单目RGB的VLA导航模型CorrectNav。实验结果表明CorrectNav在R2R-CE和RxR-CE基准上分别取得了65.1%和69.3%的新最佳成功率，超过了之前的最强VLA导航模型8.2%和16.4%。在不同室内和室外环境下的真实机器人测试中，该方法展示了其在错误修正、动态障碍避让和长期指令遵循方面的优越能力。", "conclusion": "通过自我修正飞轮的多次迭代，CorrectNav模型得以逐步提升，最终在多个基准测试中取得了新的最佳性能，并展示了模型在实践中的优越修正和避障能力。"}
{"llm_update_time": "20250816", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.10414", "html_url": "https://arxiv.org/abs/2508.10414", "title": "MCP2OSC: 通过自然语言实现参数控制", "title_en": "MCP2OSC: Parametric Control by Natural Language", "authors": "Yuan-Yi Fan", "background": "文本提示可以便于内容创建，但对于复杂任务在精准度方面可能有所不足；旋钮或滑块控制则能提供精准调整，但会增加操作的复杂性。本文旨在解决文本提示和旋钮控制之间的差距。现有方法之间的空白催生了对一种结合自然语言和参数控制方法的需求，这既能保持操作的直观性，又能实现精确的功能调整。MCP (Model Context Protocol) 服务器和一套独特的提示设计标准被提出，以实现自然语言提示对参数 OSC (OpenSoundControl) 控制的探索。通过14个实际的 QA 例子和最佳实践，以及通用提示模板，研究发现，将 Claude 与 MCP2OSC 服务器结合可以有效生成 OSC 消息，并进行可视化、验证、调试和管理 OSC 地址模式。", "innovation": "提出了一种新的 MCP (Model Context Protocol) 服务器，并确定了一套独特的提示设计标准，实现自然语言提示对参数 OSC 控制的探索。MCP2OSC 通过利用大语言模型 (LLM) 的优势，增强了人机协作，实现了复杂的 OSC 开发任务处理，并提供了一种直观的语言界面灵活的精确控制：基于提示的 OSC 工具。这项研究通过 LLM 直接处理和生成人类可读的 OSC 消息，提供了一种在网络协议层上利用大模型进行创意 MCP 应用的新视角，带来了潜在的多媒体设备统一控制机制可能性", "conclusion": "MCP2OSC 支持通过自然语言进行复杂参数控制，有效利用大语言模型增强人机协作，并提供一种直观的语言界面，结合灵活的精确控制，实现参数化 OSC 开发。研究结果表明，其作为一种 LLM 基础的普遍控制机制具有潜在应用价值。"}
{"llm_update_time": "20250816", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.10435", "html_url": "https://arxiv.org/abs/2508.10435", "title": "在张量模型中拆解尖锐感知最小化隐含的范数动力学", "title_en": "Unpacking the Implicit Norm Dynamics of Sharpness-Aware Minimization in Tensorized Models", "authors": "Tianxiao Cao,Kyohei Atarashi,Hisashi Kashima", "background": "尖锐感知最小化（SAM）已被证明是一种有效的方法，可以提高过参数模型的泛化能力。尽管先前的工作在简单的小型尺度不变系统中探索了SAM的隐式正则化特性，但其在更广泛或尺度不变的张量模型中的行为却很少被研究过。本文利用尺度不变性来分析SAM在一般张量模型中的范数动力学。通过梯度流分析，引入了核心范数失衡的全局度量——范数偏差，并推导了范数偏差在SAM下的演化过程。研究表明，SAM对范数偏差的隐式控制由核心范数与其梯度幅度之间的协方差决定。", "innovation": "引入了范数偏差的概念，并通过梯度流分析推导了其在SAM下的演化过程。展示了SAM对范数偏差的隐式控制是由核心范数及其梯度幅度之间的协方差决定的。基于此，提出了一种简单而有效的技术——偏差感知缩放（DAS），它以数据适应的方式缩放核心范数，模仿这种正则化行为，同时在各种应用场景中验证了DAS能够实现与SAM竞争或改进的性能，并且减少了计算开销", "conclusion": "实验结果表明，DAS在张量完成、噪声训练、模型压缩和参数高效微调等多种场景中，能够达到与SAM竞争或改进的性能，同时具有更低的计算开销。"}
{"llm_update_time": "20250816", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.10455", "html_url": "https://arxiv.org/abs/2508.10455", "title": "RealAC: 一种领域无关的现实且可操作的反事实解释框架", "title_en": "RealAC: A Domain-Agnostic Framework for Realistic and Actionable Counterfactual Explanations", "authors": "Asiful Arefeen,Shovito Barua Soumma,Hassan Ghasemzadeh", "background": "反事实解释通过描述最小的输入特征变化来改变模型预测，提供人工智能决策的人类可理解理由。为了在实际中真正有用，这些解释必须是现实和可行的——它们不仅需要符合底层数据分布，还需要遵守用户定义的可行性约束。现有方法经常通过硬编码的约束或特定领域的知识来确保特征间的依赖性，这限制了它们的泛化能力并难以捕捉数据中存在的复杂的非线性关系。此外，它们经常不考虑用户指定的偏好，提出因果上不合理的或无法执行的解释。", "innovation": "我们提出了RealAC，一种领域无关的框架，用于生成现实且可操作的反事实。RealAC自动保留特征间的复杂依赖关系，无需依赖显式领域知识——通过调整事实性和反事实性实例之间特征对的联合分布来对齐。该框架还允许用户“冻结”他们无法或不希望更改的属性，在优化过程中抑制这些属性的变化。评价结果表明，RealAC在现实性和可操作性之间取得了平衡。我们的方法在因果边界得分、依赖性保留得分和IM1现实性度量等方面超越了最先进的基线和基于大型语言模型的反事实生成技术，并提供了一种因果意识和用户中心的反事实生成解决方案。", "conclusion": "我们的方法在现实性和可操作性之间取得了平衡，超过了许多最先进的技术和基于大型语言模型的方法，在因果边界得分、依赖性保留得分和IM1现实性度量上表现出色，提供了解决因果意识和用户中心反事实生成综合性解决方案。"}
{"llm_update_time": "20250816", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.10490", "html_url": "https://arxiv.org/abs/2508.10490", "title": "关于基于梯度解释的复杂度与忠实性权衡", "title_en": "On the Complexity-Faithfulness Trade-off of Gradient-Based Explanations", "authors": "Amir Mehrpanah,Matteo Gamba,Kevin Smith,Hossein Azizpour", "background": "ReLU网络在视觉数据中广泛应用，但它们的预测具有尖锐转换，有时甚至依赖于单个像素，导致基于梯度的解释方法噪声较大且难以解读。现有的方法如GradCAM通过引入替代模型来平滑这些解释，但会降低忠实性。", "innovation": "提出了一种统一的频谱框架，系统地分析并量化了平滑、忠实性及其在解释中的权衡。该框架量化并正则化ReLU网络对高频信息的贡献，为识别这种权衡提供了一种原则性的方法。此外，分析了基于替代模型的平滑如何扭曲解释，定义并测量了不同事后方法的“解释差距”。", "conclusion": "通过理论验证，表明不同设计选择、数据集和消除方案下存在不同的理论发现。"}
{"llm_update_time": "20250816", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.10469", "html_url": "https://arxiv.org/abs/2508.10469", "title": "增强稀疏点云数据处理以实现隐私感知的人体动作识别", "title_en": "Enhanced Sparse Point Cloud Data Processing for Privacy-aware Human Action Recognition", "authors": "Maimunatu Tunau,Vincent Gbouna Zakka,Zhuangzhuang Dai", "background": "人体动作识别（HAR）在医疗保健、健身追踪和辅助生活技术中起着重要作用。传统的基于视觉的HAR系统效果显著，但存在隐私问题。毫米波雷达传感器可以提供隐私保护的替代方案，但由于它们的点云数据稀疏且噪声大，因此面临挑战。文献中，密度为基础的空间聚类（DBSCAN）、匈牙利算法和卡尔曼滤波器三种主要的数据处理方法被广泛用于改善雷达数据的质量和连续性，但这些方法的综合评估仍缺乏。", "innovation": "本文通过使用MiliPoint数据集进行详细的性能分析，评估了三种方法的单个使用及所有可能的两两组合，以及三者的综合，对其识别准确性和计算成本进行了评估。此外，还提出了针对每个单独方法的改进措施，以提高准确性。研究结果提供了对每种方法及其集成的优势和权衡的深入见解，指导未来基于毫米波的HAR系统的研发工作。", "conclusion": "研究结果揭示了每种方法和它们的集成的优势和权衡，这有助于为未来基于毫米波的HAR系统的发展提供指导。"}
{"llm_update_time": "20250816", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.10461", "html_url": "https://arxiv.org/abs/2508.10461", "title": "X-Node: 自己解释就足够了", "title_en": "X-Node: Self-Explanation is All We Need", "authors": "Prajit Sengupta,Islem Rekik", "background": "图形神经网络（GNNs）已经在计算机视觉和医学图像分类任务中取得了最先进的成果，通过捕捉数据实例间的结构依赖性。然而，其决策过程仍然不够透明，限制了其在强调解释性的高风险临床应用中的可信度。现有的GNN解释技术通常是事后总结的全局形式，仅提供有限的单个节点决策或局部推理的见解。", "innovation": "本文提出了X-Node，这是一种自我解释的GNN框架，其中每个节点在预测过程中生成自己的解释。每个节点构建一个结构化的上下文向量，编码本地拓扑中的可解释线索，如度、中心性、聚类、特征显著性和标签一致性。一个轻量级的Reasoner模块将此上下文映射到一个紧凑的解释向量，该向量用于三个目的：（1）通过解码器重建节点的隐含嵌入以确保真实性；（2）使用预训练的大型语言模型（例如Grok或Gemini）生成自然语言解释；（3）通过“文本注入”机制将解释反馈到消息传递管道中，指导GNN本身。X-Node被评估在从MedMNIST和MorphoMNIST派生的两个图数据集上，与GCN、GAT和GIN等重要骨架集成，结果显示X-Node保持了竞争力的分类精度，同时产生了忠实的、逐节点的解释。", "conclusion": "X-Node维护了竞争力的分类准确率，同时生成了忠实的、逐节点的解释，为高风险临床应用中的GNN提供了更加透明和可信的决策支持。"}
{"llm_update_time": "20250816", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.10491", "html_url": "https://arxiv.org/abs/2508.10491", "title": "对比学习ECOC：用于对抗防御的输出码学习", "title_en": "Contrastive ECOC: Learning Output Codes for Adversarial Defense", "authors": "Che-Yu Chou,Hung-Hsuan Chen", "background": "虽然在多类分类中常用的独热编码（one-hot encoding）在许多情况下依然被广泛应用，但并不总是最有效的编码机制。Error Correcting Output Codes（ECOC）通过将每个类映射到一个独特的编码码字（codeword）来解决多类分类问题。传统的ECOC方法依赖于手工设计或随机生成的码本，这不仅劳动密集，而且可能在不同数据集上产生次优的结果。", "innovation": "本文介绍了一种基于对比学习的自动化码本学习模型（Contrastive Learning），这些模型可以直接并自适应地从数据中学习码本，而不需要手工设计或随机生成的码本。在四个数据集上，所提出的模型在对抗性攻击的稳健性方面优于两个基线方法。", "conclusion": "提出的基于对比学习的ECOC模型在对抗性攻击的稳健性方面优于传统的手工设计和随机生成的码本方法，并且可以通过直接从数据中学习码本来实现对抗防御，从而在多类分类任务中提供了更好的性能。源代码可在该链接获取：this https URL."}
{"llm_update_time": "20250816", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.10504", "html_url": "https://arxiv.org/abs/2508.10504", "title": "基于逻辑的实体解析领域的进展：通过局部合并和最优性准则增强ASPEN", "title_en": "Advances in Logic-Based Entity Resolution: Enhancing ASPEN with Local Merges and Optimality Criteria", "authors": "Zhliang Xiang,Meghyn Bienvenu,Gianluca Cima,Víctor Gutiérrez-Basulto,Yazmín Ibáñez-García", "background": "现有的基于ASP（Assumption-Based Reasoning Programming）的实体解析系统ASPEN仅支持全局合并，即将所有匹配的实体标识符视为等价并合并。然而，已有研究表明，在数据值解析时，局部合并通常更为合适，因为不同实例可能需要不同的匹配对象。因此，需要一种支持局部合并并引入新的最优性准则的新系统。", "innovation": "本文提出了扩展ASPEN系统的ASPEN+，新增了局部合并功能和支持新的最优性准则。新的功能包括：支持局部合并以更准确地解析数据值，以及通过最小化规则违反和最大化支持合并的规则数量等新的最优性准则来选择解决方案。", "conclusion": "本文的主要贡献包括对最优解决方案的各种概念进行了形式化和计算分析，并通过使用真实世界的数据集进行了广泛实验，表明局部合并和新的最优性准则对准确性和运行时性能的影响。"}
{"llm_update_time": "20250816", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.10494", "html_url": "https://arxiv.org/abs/2508.10494", "title": "统一多代理框架以实现通用多模态理解和生成", "title_en": "A Unified Multi-Agent Framework for Universal Multimodal Understanding and Generation", "authors": "Jiulin Li,Ping Huang,Yexin Li,Shuo Chen,Juewen Hu,Ye Tian", "background": "现实世界中的多模态应用需要实现不同模态间的灵活理解和生成能力，例如文本、图像、音频和视频。然而，将自回归语言模型（如大语言模型）用于推理的优势与高保真生成模型的优势结合在一起进行整合仍然具有挑战性。现有方法依赖于僵化的流水线或紧密耦合的架构，这限制了灵活性和可扩展性。", "innovation": "该论文提出了MAGUS（多代理统一多模态系统），这是一种模块化框架，通过两个独立阶段——认知和决断——统一多模态理解和生成。MAGUS 支持代理的即插即用扩展、可扩展的任何到任何模态的转换以及语义对齐，所有这些都不需要共同训练。通过跨多个基准测试（包括图像、视频和音频生成，以及跨模态指令跟随）的实验结果，MAGUS 显示出优于强大的基线和最先进系统的性能。", "conclusion": "MAGUS 在多模态理解与生成上表现出色，特别是在 MME 基准测试中超过了强大的闭源模型 GPT-4o。"}
{"llm_update_time": "20250816", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.10507", "html_url": "https://arxiv.org/abs/2508.10507", "title": "多样本抗锯齿与约束优化在3D高斯采样中的应用", "title_en": "Multi-Sample Anti-Aliasing and Constrained Optimization for 3D Gaussian Splatting", "authors": "Zheng Zhou,Jia-Chen Zhang,Yu-Jie Xiong,Chun-Ming Xia", "background": "最近在3D高斯采样中的进展显著提升了实时视图合成的效果，但由于场景优化过程中几何约束不足，常常导致精细细节模糊，特别是在高频纹理和尖锐分界区域。", "innovation": "本文提出了一种综合多样本抗锯齿（MSAA）与双几何约束的全面优化框架。通过自适应混合四次下采样像素颜色，有效减少了高频分量的锯齿化伪影。该框架引入了两种约束条件：（a）适应性加权策略，通过动态梯度分析优先处理重建不足的区域，（b）梯度差异约束，强制边界的几何正则化。这种目标化优化允许模型优先分配计算资源到需要细化的关键区域，同时保持整体一致性。", "conclusion": "广泛的实验评估显示，本方法在细节保留方面达到了最先进的性能，尤其是在保存高频纹理和尖锐分界方面，同时保持了实时渲染效率。定量和感知评测证实了与基线方法相比，在结构相似度（SSIM）和感知质量（LPIPS）上的统计显著改进。"}
{"llm_update_time": "20250816", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.10528", "html_url": "https://arxiv.org/abs/2508.10528", "title": "Med-GLIP: 通过大规模标注数据推进医学语言-图像预训练", "title_en": "Med-GLIP: Advancing Medical Language-Image Pre-training with Large-scale Grounded Dataset", "authors": "Ziye Deng,Ruihan He,Jiaxiang Liu,Yuan Wang,Zijie Meng,Songtao Jiang,Yong Xie,Zuozhu Liu", "background": "医学图像接地的目标是将自然语言短语与医学图像中的特定区域对齐，作为智能诊断、视觉问答（VQA）和自动报告生成（MRG）的基础任务。然而，现有的研究受到有限模态覆盖、粗粒度注释和缺乏统一可推广接地框架的限制。", "innovation": "本文构建了一个包含超过530万区域级注释的大规模医学接地数据集Med-GLIP-5M，覆盖七种成像模态和多种解剖结构及病理发现。并且提出了一种模态感知的接地框架Med-GLIP，该框架无需依赖显式设计的专家模块，而是通过多样化的训练数据隐式获取层次化的语义理解，能够识别多层次结构。", "conclusion": "广泛的实验表明，Med-GLIP在多个接地基准测试中始终优于最先进的基线。并且将其实体输出集成到下游任务中，如医学VQA和报告生成，可以显著提高性能。数据集将在不久后发布。"}
{"llm_update_time": "20250816", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.10556", "html_url": "https://arxiv.org/abs/2508.10556", "title": "用于异常分布检测的检索增强提示", "title_en": "Retrieval-Augmented Prompt for OOD Detection", "authors": "Ruisong Han,Zongbo Han,Jiahao Zhang,Mingyue Cheng,Changqing Zhang", "background": "可靠的机器学习模型在实际部署中需要对异常分布（Out-of-Distribution, OOD）样本进行准确识别，而现有方法依赖辅助异常样本或在分布（In-Distribution, ID）数据来生成异常信息进行训练，但由于有限的真实OOD样本和训练数据的不同，导致它们难以提供充足的语义监督，从而产生了性能不佳的问题。", "innovation": "提出了一种新的OOD检测方法——检索增强提示（Retrieval-Augmented Prompt, RAP）。该方法通过从外部知识库检索描述性词语并增强预训练的视觉-语言模型的提示，提供对OOD检测的增强语义监督，在训练阶段增强了模型对OOD样本的敏感度，在测试阶段能够动态更新OOD提示以实时适应测试环境。", "conclusion": "广泛的实验表明，RAP在大规模OOD检测基准上达到最先进的性能。例如，在ImageNet-1k数据集上的1-shot OOD检测中，RAP将FPR95降低7.05%，AUROC提高1.71%，相较于其他方法。此外，详尽的消融研究验证了每个模块的有效性和我们的方法背后的动机。"}
{"llm_update_time": "20250816", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.10548", "html_url": "https://arxiv.org/abs/2508.10548", "title": "使用门控奖励稳定长周期多轮强化学习", "title_en": "Stabilizing Long-term Multi-turn Reinforcement Learning with Gated Rewards", "authors": "Zetian Sun,Dongfang Li,Zhuoen Chen,Yuhuai Qin,Baotian Hu", "background": "在长期 horizon 的强化学习（RL）任务中，如何通过立即奖励塑造符合长期目标的奖励仍然是一项重大挑战。现有的基于结果的奖励塑造方法难以界定有意义的立即奖励，可能会引入偏差或需要显式的任务分解。验证型奖励塑造使用逐步评判专家，但立即奖励和长期目标之间的不一致可能导致奖励欺骗和次优策略。论文在软件工程（SWE）任务的背景下探讨了这个问题，SWE任务依赖于多轮推理和基于规则的验证。文章指出，通过平衡立即奖励和高级奖励之间的积累，可以稳定长期RL的学习过程，并提高任务的完成率和修改率。", "innovation": "提出了一种新的方法：门控奖励积累（G-RA），该方法只在高级（长期）奖励达到预定义阈值时积累立即奖励，从而确保稳定RL优化。该方法在SWE-基准验证和kBench实验中均显示出显著效果，促进了任务完成率和修改率的提升，同时避免了由于奖励不一致导致的策略退化。", "conclusion": "研究强调了在长周期RL中平衡奖励积累的重要性，并提供了一种有效的实用解决方案。"}
{"llm_update_time": "20250816", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.10552", "html_url": "https://arxiv.org/abs/2508.10552", "title": "当语言主导一切：揭示多模态大型语言模型中的文本主导现象", "title_en": "When Language Overrules: Revealing Text Dominance in Multimodal Large Language Models", "authors": "Huyu Wu,Meng Tang,Xinhan Zheng,Haiyun Jiang", "background": "多模态大型语言模型（MLLMs）在多种多模态任务中展现了出色的能力，但这些模型依赖于文本进行推理，导致其他模态被严重忽视。尽管先前的研究已经意识到这一现象并归因于数据偏差或模型架构，但迄今为止尚未进行系统性探索以探讨这一问题在不同数据模态中的普遍性和原因。本研究首次在图像、视频、音频、时间序列和图形等不同数据模态下系统研究文本主导现象，并提出了衡量这种不平衡的指标：模态主导指数（MDI）和注意力效率指数（AEI）.", "innovation": "本文首次系统性研究了多模态大型语言模型中的文本主导现象，并提出了衡量这种不平衡的指标——模态主导指数（MDI）和注意力效率指数（AEI）。研究发现，文本主导现象在所有测试的模态中都存在且显著。进一步分析还确定了三个导致这种现象的因素：非文本模态中严重的标记冗余导致的注意力稀释、融合架构设计的影响以及任务设计对文本输入的隐式偏好。此外，本文提出了一种简单的方法来有效重新平衡模型的注意力，即通过标记压缩方法，并应用于LLaVA-7B模型，显著降低了其MDI指数，使其更加平衡。", "conclusion": "本文的研究和方法框架为开发更公平全面的多模态语言模型提供了基础，同时提出了一种简单有效的技术手段来解决模型中的文本主导问题。"}
{"llm_update_time": "20250816", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.10436", "html_url": "https://arxiv.org/abs/2508.10436", "title": "交替使用Approach-Putt模型进行多阶段语音增强", "title_en": "Alternating Approach-Putt Models for Multi-Stage Speech Enhancement", "authors": "Iksoon Jeong,Kyung-Joong Kim,Kang-Hun Ahn", "background": "语音增强使用人工神经网络旨在从嘈杂的语音信号中去除噪声同时保留语音内容。然而，语音增强网络通常会在语音信号中引入失真，这些失真被称为伪影，会降低音频质量。", "innovation": "本文提出了一种后处理神经网络，旨在减轻由语音增强模型引入的伪影。通过交替使用语音增强模型和提出的Putt模型，可以提高语音质量，这通过感知质量评分(PESQ)、客观可懂度(STOI)和背景噪音侵入性(CBAK)评分得到验证。", "conclusion": "与单独重复应用任一模型相比，交替使用Approach和Putt模型在语音增强中表现出更优的性能。"}
{"llm_update_time": "20250816", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.10557", "html_url": "https://arxiv.org/abs/2508.10557", "title": "PTQAT：一种用于3D感知任务的混合参数高效量化算法", "title_en": "PTQAT: A Hybrid Parameter-Efficient Quantization Algorithm for 3D Perception Tasks", "authors": "Xinhao Wang,Zhiwei Lin,Zhongyu Xia,Yongtao Wang", "background": "量化是实现高精度模型轻量化和部署的关键技术。现有量化方法包括后训练量化(PTQ)和量化感知训练(QAT)。PTQ普遍存在量化模型性能大幅下降的问题，而QAT则需要消耗大量的GPU内存和训练时间。本文旨在解决PTQ和QAT之间的速度与准确性的权衡问题，提出了一种新的高效混合量化算法PTQAT，以适应3D感知网络的部署需求。", "innovation": "提出的PTQAT算法是一种混合量化方法，结合了PTQ和QAT的优点。它选择关键层进行QAT微调，而对其余层进行PTQ处理。实验表明，这种方法通过仅微调约50%的量化层，可以达到类似于QAT的性能，同时更加高效。此外，PTQAT是一个通用的量化方法，支持多种量化位宽（4位）以及不同的模型架构，包括CNN和Transformer。", "conclusion": "实验结果表明，相较于仅使用QAT的方法，PTQAT在各种3D感知任务（如目标检测、语义分割和占用预测）中均表现出更好的性能，具体表现为：目标检测中获得了0.2%-0.9%的NDS提升和0.3%-1.0%的mAP提升，在语义分割和占用预测中分别获得了0.3%-2.0%的mIoU提升，同时微调的权重更少。"}
{"llm_update_time": "20250816", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.10595", "html_url": "https://arxiv.org/abs/2508.10595", "title": "基于梯度的解释方法的光谱属性研究", "title_en": "On Spectral Properties of Gradient-based Explanation Methods", "authors": "Amir Mehrpanah,Erik Englesson,Hossein Azizpour", "background": "理解深度神经网络的行为对于增强我们对其结果的信心至关重要。尽管已经有许多研究工作致力于解释其预测结果，但研究人员面临可靠性问题，这些问题可以归因于缺乏足够的形式化方法。", "innovation": "我们采用新颖的概率和光谱视角对解释方法进行了形式化分析，揭示了由于使用梯度而普遍存在的一种光谱偏差，并阐明了一些常见的设计选择，特别是平方梯度和输入扰动的使用。我们进一步研究了解释方法中扰动超参数的选择如何导致不一致的解释，并提出了基于我们提出的理论框架的两种解决方案：（i）确定标准扰动尺度的机制；（ii）称为SpectralLens的聚合方法。最后，我们通过定量评估证实了我们的理论结果。", "conclusion": "我们的研究揭示了基于梯度的解释方法中存在的普遍光谱偏差，并提出了确定标准扰动尺度的机制和一种新的聚合方法SpectralLens，以改进解释方法的准确性和一致性。"}
{"llm_update_time": "20250816", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.10616", "html_url": "https://arxiv.org/abs/2508.10616", "title": "Fourier-Guided Attention Upsampling for Image Super-Resolution", "title_en": "Fourier-Guided Attention Upsampling for Image Super-Resolution", "authors": "Daejune Choi,Youchan No,Jinhyung Lee,Duksu Kim", "background": "传统的上采样方法，如Sub-Pixel Convolution，虽然效率较高，但在重建高频细节和减少交错伪影方面经常失败。", "innovation": "提出了一种轻量级上采样模块Frequency-Guided Attention (FGA)，通过结合四元数特征基于的多层感知机进行位置频率编码，交叉分辨率相关注意层进行自适应空间对齐，以及频域L1损失进行光谱保真监督来解决这些问题。FGA仅增加了0.3M参数，但在五个不同的超分辨率骨干网络中，在轻量级和满容量场景中都表现出了增强的性能。", "conclusion": "实验结果表明，FGA在PSNR上平均提高了0.12~0.14 dB，并且在频域一致性方面提高了29%，特别是在纹理丰富的数据集上更为明显。视觉和频域评估证实了FGA在减少交错伪影和保留精细细节方面的有效性，它建立了一个传统的上采样方法的实用、可扩展替代方案。"}
{"llm_update_time": "20250816", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.10646", "html_url": "https://arxiv.org/abs/2508.10646", "title": "SPHENIC:基于拓扑信息的多视图聚类方法用于空间转录组学", "title_en": "SPHENIC: Topology-Informed Multi-View Clustering for Spatial Transcriptomics", "authors": "Chenkai Guo,Yikai Zhu,Jing Yangum,Renxiang Guan,Por Lip Yee,Guangdun Peng,Dayu Hu", "background": "当前空间转录组学聚类方法虽然取得了进展，但由于空间转录组学资料的噪声问题，一般仅考虑单细胞的表征或交互图，导致低质的拓扑信号；另外，无法充分建模的空间邻域信息则导致低质的空间嵌入。", "innovation": "提出了一种新颖的空间持久同胚增强邻域整合聚类方法SPHENIC。该方法通过将不变拓扑特征集成到聚类网络中，实现稳定的表示学习。同时，设计了空间约束和分布优化模块（SCDOM），以构建反映细胞真实分布的高质量空间嵌入。", "conclusion": "通过对14个基准空间转录组学切片的广泛实验，表明SPHENIC在空间聚类任务上优于现有最佳方法，性能提升了3.31%-6.54%。"}
{"llm_update_time": "20250816", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.10666", "html_url": "https://arxiv.org/abs/2508.10666", "title": "深度学习在经典和量子物理中的应用", "title_en": "Deep Learning in Classical and Quantum Physics", "authors": "Timothy Heightman,Marcin Płodzień", "background": "科学研究的进步与新研究工具的出现紧密相关。如今，特别是深度学习（DL）已经成为量子科学和技术的变革性工具。由于量子系统的固有复杂性，DL可以有效探索大量参数空间，从实验数据中提取模式，并基于数据驱动指导研究方向。这些能力已经在诸如优化量子控制协议和加速发现具有目标量子属性的材料等任务中得到支持，使得了解机器学习/深度学习成为下一代量子科学家的基本技能。同时，DL的强大功能也带来了风险：模型可能会过度适应有噪声的数据，隐藏因果结构，并产生缺乏物理可解释性的结果。认识到这些局限性并应用缓解策略对于科学研究的严谨性至关重要。", "innovation": "这些讲义为量子应用中的深度学习提供了全面的、研究生级别的介绍，结合了概念阐述和实际示例。它们旨在帮助读者决定何时以及如何有效地应用深度学习，理解其实际约束，并负责任地将人工智能方法应用于量子物理、化学和工程等各个领域的问题。", "conclusion": "这些讲义通过循序渐进的结构，使读者能够掌握如何在量子物理学、化学和工程等领域合理应用深度学习，理解其局限性，并合理应用AI方法解决实际问题。"}
{"llm_update_time": "20250816", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.10667", "html_url": "https://arxiv.org/abs/2508.10667", "title": "AddressVLM：使用大规模视觉语言模型的跨视角对齐调整以进行图像地址定位", "title_en": "AddressVLM: Cross-view Alignment Tuning for Image Address Localization using Large Vision-Language Models", "authors": "Shixiong Xu,Chenghao Zhang,Lubin Fan,Yuan Zhou,Bin Fan,Shiming Xiang,Gaofeng Meng,Jieping Ye", "background": "大型视觉语言模型（LVLMs）在粗粒度的地理位置定位方面表现出色，但难以实现城市区域内街道级别的精确地址定位。这个问题源于现有街景数据仅能提供微观视觉线索，导致调整后的模型表现不佳。因此我们需要一种方法，通过引入全景卫星图像作为宏观线索来增强LVLMs的理解和定位能力，并通过跨视角对齐调整和图像地址本地化调整两种训练协议来优化模型表现，从而实现更准确的街道级别地址定位。", "innovation": "提出了一种名为AddressVLM的新模型，该模型结合了 street-view 和卫星视图图像的对接机制，以及自动标签生成机制，通过跨视角对齐调整来增强大型视觉语言模型对街道分布的理解。该方法显著提高了在两个基于美国匹兹堡和旧金山的数据集上的平均地址定位精度，分别提升了9%和12%。", "conclusion": "通过引入卫星视图图像作为宏观线索和提出双向跨视角对齐调整策略，AddressVLM 模型显著提升了城市街道级别地址定位的准确性，相比现有的大规模视觉语言模型提高了平均9%以上的定位精度。"}
{"llm_update_time": "20250816", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.10655", "html_url": "https://arxiv.org/abs/2508.10655", "title": "Serial Over Parallel: Learning Continual Unification for Multi-Modal Visual Object Tracking and Benchmarking", "title_en": "Serial Over Parallel: Learning Continual Unification for Multi-Modal Visual Object Tracking and Benchmarking", "authors": "Zhangyong Tang,Tianyang Xu,Xuefeng Zhu,Chunyang Cheng,Tao Zhou,Xiaojun Wu,Josef Kittler", "background": "多模态视觉对象跟踪（MMVOT）任务的研究日益受到关注，因为不同模态之间的互补性有助于构建鲁棒的跟踪系统。现有实践将所有传感器类型的数据混合在一个训练过程中，从数据为中心的角度构建并行 paradigm，旨在联合分布的最大值上取得全局最优。然而，由于缺乏一个能够容纳所有类型数据的统一基准，导致了评估在分离的基准上进行，这是训练与测试之间不一致的原因之一，从而影响了性能。", "innovation": "本文提出了两个方面的创新：1. 引入了一个名为 UniBench300 的统一基准，通过整合多种任务数据，将推理过程中需要的次数从三次减少到一次，减少了27%的时间消耗。2. 将统一过程重新形式化为顺序格式，逐步集成新任务。这使得性能下降可以被解释为新知识取代了先前任务的知识，自然地与持续学习（CL）的哲学契合，激励了将 CL 应用于统一过程的进一步探索。实验在两个基线和四个基准上进行，证实了 UniBench300 的重要性和 CL 在支持稳定统一过程中的优越性。此外，当执行专门分析时，发现性能下降与网络容量呈负相关，不同模态之间的差异对任务的降级造成了不同程度的影响，为未来的多模态视觉研究提供了宝贵见解。", "conclusion": "广泛的实验表明，UniBench300 的重要性以及持续学习（CL）在支持稳定统一过程中的优越性。性能下降与网络容量呈负相关，不同模态之间的差异对任务的降级造成不同程度的影响。源代码和提出的基准已经在这个网址可以获取：[https://example.com](https://example.com)。"}
{"llm_update_time": "20250816", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.10480", "html_url": "https://arxiv.org/abs/2508.10480", "title": "Pinet：利用正交投影层优化严格约束神经网络", "title_en": "Pinet: Optimizing hard-constrained neural networks with orthogonal projection layers", "authors": "Panagiotis D. Grontas,Antonio Terpin,Efe C. Balta,Raffaello D'Andrea,John Lygeros", "background": "本文讨论了一种用于神经网络的输出层，它确保满足凸约束条件。通过引入这种满足凸约束的输出层，学者们希望解决严格约束优化问题，特别是在多车辆运动规划中，涉及非凸轨迹偏好。", "innovation": "本文提出了一种名为$\boldsymbol{\rm \boldsymbol{\text{Π}}} \text{net}$的方法，它结合了算子分裂技术以实现快速可靠的前向投影，以及隐函数定理以实现反向传播。$\boldsymbol{\rm \boldsymbol{\text{Π}}} \text{net}$作为参数约束优化问题的设计可行代理，能够在单独解决问题时与传统求解器获得类似的精度，但在批量处理问题时表现更好。该方法在训练时间、解决方案质量以及超参数调整的鲁棒性方面超过了现有的学习方法，同时保持了相似的推理时间。此外，$\boldsymbol{\rm \boldsymbol{\text{Π}}} \text{net}$作为一种可移植的GPU实现，并在JAX中实现了有效的调参启发式。", "conclusion": "本文通过引入$\boldsymbol{\rm \boldsymbol{\text{Π}}} \text{net}$，为严格约束下的神经网络优化提供了一种有效的方法。该方法不仅在处理批处理问题时表现出色，而且在特定的多车辆运动规划问题中也显示出了潜力。$\boldsymbol{\rm \boldsymbol{\text{Π}}} \text{net}$作为一个GPU就绪的软件包在JAX中实现，具有良好的调优效果。"}
{"llm_update_time": "20250816", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.10713", "html_url": "https://arxiv.org/abs/2508.10713", "title": "在GPU上进行天线电磁仿真以应用于机器学习", "title_en": "Electromagnetic Simulations of Antennas on GPUs for Machine Learning Applications", "authors": "Murat Temiz,Vemund Bakken", "background": "在电磁（EM）应用中进行天线设计和优化的仿真时，由于仿真计算复杂性高，产生足够的训练样本需要大量时间和资源，使得使用传统CPU进行大量数据生成变得困难。因此，利用图形处理单元（GPUs）可以显著提高仿真的效率和性能。此外，研究还探讨了不同机器学习和深度学习模型在天线参数估计性能方面的表现。", "innovation": "提出了一种基于开源电磁仿真软件gprMax的GPU驱动天线仿真框架，适用于天线设计和优化的机器学习应用。该框架利用GPU模拟大量天线，生成用于机器学习和代理模型的大量天线仿真数据集。研究还发现，即使是入门级GPU也表现出优于高端CPU的计算性能，而高端游戏GPU的计算性能更是可以提高18倍。", "conclusion": "开源的电磁仿真软件gprMax在天线仿真性能上与商用软件相当，特别是在微带天线的仿真中，只要空间分辨率足够精细。此外，通过利用GPU，可以在有限时间内有效生成大量天线仿真数据，这对于提高机器学习算法的训练效率和性能至关重要。"}
{"llm_update_time": "20250816", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.10701", "html_url": "https://arxiv.org/abs/2508.10701", "title": "REFN: 基于网络强化学习框架以对抗1天/n天利用", "title_en": "REFN: A Reinforcement-Learning-From-Network Framework against 1-day/n-day Exploitations", "authors": "Tianlong Yu,Lihong Liu,Ziyi Zhou,Fudu Xing,Kailong Wang,Yang Yang", "background": "由于大量部署规模和补丁延迟（平均补丁时间超过60天），1天或n天漏洞的利用对网络设备构成了严重的威胁。现有的防御措施，包括基于主机的补丁和基于网络的过滤，由于在不同设备上的有限可扩展性、与嵌入式或遗留系统的兼容性问题以及手动补丁验证过程中的错误，都不足以防范这些问题。", "innovation": "我们提出了REFN（Reinforcement Learning From Network），这是一种框架，通过训练大型语言模型（LLMs）自动生成网络过滤器来预防1天或n天漏洞的利用。REFN通过在线网络奖励驱动的强化学习（RL）而不是传统的人类反馈（RLHF）确保了可扩展性，并且通过部署在边缘安全网关（如Amazon Eero）上实现兼容性，通过在线使用真实网络流量验证提高了鲁棒性。此外，REFN通过基于代理的验证解决大规模训练LLMs的三个核心挑战：通过代理驱动的知识蒸馏扩展当前模型的漏洞修复经验、通过将语言上下文转换为网络执行以弥合语言和网络的差距、并通过在线代理验证解决LLMs的幻觉和非确定性。", "conclusion": "REFN在22种1天或n天漏洞家族测试中展现出高效的性能（准确率21.1%高于其他方法）、高效的补丁时间（平均3.65小时）和可扩展性（易于扩展到10,000台设备）。REFN为训练LLMs以快速防止大规模1天或n天漏洞利用提供了第一步。"}
{"llm_update_time": "20250816", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.10559", "html_url": "https://arxiv.org/abs/2508.10559", "title": "Fake Speech Wild: 在社交媒体平台检测深度假音", "title_en": "Fake Speech Wild: Detecting Deepfake Speech on Social Media Platform", "authors": "Yuankun Xie,Ruibo Fu,Xiaopeng Wang,Zhiyong Wang,Ya Li,Zhengqi Wen,Haonnan Cheng,Long Ye", "background": "语音生成技术的快速发展导致了社交媒體平台上的深度假音泛滥。尽管现有的深度假音对抗措施（CMs）在公开数据集上取得了令人鼓舞的结果，但在跨域场景中的性能显著下降。因此，需要推进实境中的深度假音检测技术。", "innovation": "论文首先提出了Fake Speech Wild (FSW)数据集，包含来自四个不同媒体平台的254小时的真实和深度假音音频，重点在社交媒体。建立了CM基准，并采用了先进的自监督学习（SSL）基CMs来评估现有CMs在实际场景中的效果。还评估了数据增强策略在提高CM鲁棒性方面的作用。通过扩充公开数据集并结合FSW训练集，显著提升了实境中的深度假音检测性能，使得平均等错误率（EER）降至3.54%。", "conclusion": "通过增强公开数据集和结合FSW训练集，大幅度提升了实境中的深度假音音频检测性能，各评估集的平均等错误率达到3.54%。"}
{"llm_update_time": "20250816", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.10687", "html_url": "https://arxiv.org/abs/2508.10687", "title": "连续的孟加拉手语翻译：借助图形减轻标注消释（或手势）信息的代价", "title_en": "Continuous Bangla Sign Language Translation: Mitigating the Expense of Gloss Annotation with the Assistance of Graph", "authors": "Safaeid Hossain Arib,Rabeya Akter,Sejuti Rahman", "background": "全球有数百万人患有听力障碍和失聪，手语成为聋哑人群体中高效的交流方式。然而，在重视听觉语言的社会中，手语往往被低估，导致交流障碍和社会排斥。Continuous Bangla Sign Language Translation项目旨在通过改进翻译方法来填补这一缺口。虽然近期的研究使用变压器结构取得了最先进的结果，但我们的方法结合了基于图形的方法和变压器架构。这种结合提供了更有效的无消释信息的手语翻译。", "innovation": "我们的贡献包括：1）架构融合，探索不同的融合策略；2）在多种手语数据集（RWTH-PHOENIX-2014T、CSL-Daily、How2Sign和BornilDB v1.0）上实现了新的最优性能；3）在BornilDB v1.0数据集上首次进行了基准测试。我们的方法在所有数据集上的性能都优于现有系统，BLEU-4分数提升了显著，分别比GASLT、GASLT和slt_how2sign高出4.01、2.07和0.5分。这表明了无消释信息翻译的重要性，提高了听力障碍群体的交流可及性。", "conclusion": "我们的方法为未来的研究设定了一个基准，强调了无消释信息翻译的重要性，以提高聋哑人群体的交流访问性。"}
{"llm_update_time": "20250816", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.10695", "html_url": "https://arxiv.org/abs/2508.10695", "title": "从自然语言反馈中学习实现个性化问答", "title_en": "Learning from Natural Language Feedback for Personalized Question Answering", "authors": "Alireza Salemi,Hamed Zamani", "background": "个性化对于提升语言技术的有效性和用户满意度至关重要，尤其在信息搜索任务，如问答任务中。当前个性化大型语言模型（LLMs）的方法通常依赖于检索增强生成（RAG），随后通过带有标量奖励信号的强化学习来教模型如何使用检索到的个人信息。我们发现这些标量奖励有时提供的反馈较弱且非指导性，限制了学习效率和个人化质量。因此，本文提出了一种名为VAC的新框架，该框架用基于用户资料和问题叙述产生自然语言反馈（NLF）取代了标量奖励。NLF作为一种丰富的操作性强的监督信号，使得策略模型能够迭代地改进其输出并内化有效的个性化策略。训练交替进行反馈模型优化和策略模型在改进响应上的微调，最终得到一个在推理过程中不再需要反馈的策略模型。在包含三个不同领域的LaMP-QA基准测试上，该方法在结果上显示出一致且显著的改进，而人类评估也证实了生成响应的高品质。这些结果表明NLF提供了更有效的信号来优化个性化问答效果。", "innovation": "提出了VAC框架，该框架利用自然语言反馈（NLF）代替了标量奖励，以提高策略模型的个性化效率和质量。NLF作为一种丰富的操作性强的监督信号，提高了模型对个性化策略的理解和应用。通过交替训练反馈模型和策略模型，使策略模型能够逐步优化响应并实现自适应学习，从而不再依赖反馈直接推理出最佳响应。", "conclusion": "在LaMP-QA基准测试中的结果表明，此方法在个性化问答方面取得了显著的改进。进一步的人类评估也证实了生成响应的高品质。这些结果证明了自然语言反馈可以提供更有效的信号来优化个性化问答效果。"}
{"llm_update_time": "20250816", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.10672", "html_url": "https://arxiv.org/abs/2508.10672", "title": "混合生成融合高效且保护隐私的面部识别数据集生成", "title_en": "Hybrid Generative Fusion for Efficient and Privacy-Preserving Face Recognition Dataset Generation", "authors": "Feiran Li,Qianqian Xu,Shilong Bao,Boyu Han,Zhiyong Yang,Qingming Huang", "background": "本文探讨了如何构建高质量的面部识别数据集参加DataCV ICCV挑战。面临的挑战是在不包含与现有公共面部数据集重叠身份信息的前提下，创建一个高质量的面部数据集。这涉及到从基础HSFace数据集中进行深入清理，剔除错误标签或不一致的面貌身份，利用混合专家（MoE）策略结合面部嵌入聚类和GPT-4o辅助验证。此外，通过使用Stable Diffusion生成合成身份，并利用Vec2Face迅速生成一致的身份变体，从而创建一个多样化且高质量的数据集。为了解决合成身份间的高视觉相似性问题，采用渐进学习策略，将它们置于训练的早期阶段，从而更容易地逐步过渡到更困难的数据样本。最终的数据集每种身份包含50张图像，并通过主流面部数据集的检查来确保没有身份泄露。\n", "innovation": "本文的创新之处在于采用混合生成融合的方法高效且保护隐私地生成面部识别数据集。具体包括使用Mixture-of-Experts（MoE）策略清理数据集，利用Stable Diffusion和Vec2Face生成合成身份及数据增强，通过渐进学习策略优化训练过程，从而构建一个多样化且高质量的数据集。这种方法使得训练过程更加高效，同时也避免了隐私泄露的问题。\n", "conclusion": "本文的方法在比赛中获得了第一名，并且实验结果表明，通过该数据集训练的模型在10K、20K和100K身份规模下均表现出更好的性能。此外，最终生成的数据集每种身份包含50张图像，并且所有新生成的身份均通过了主流面部数据集的检查，确保了数据集的安全性。源代码已发布。"}
{"llm_update_time": "20250816", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.10758", "html_url": "https://arxiv.org/abs/2508.10758", "title": "为层次点云数据集原生可训练稀疏注意机制", "title_en": "Natively Trainable Sparse Attention for Hierarchical Point Cloud Datasets", "authors": "Nicolas Lapautre,Maria Marchenko,Carlos Miguel Patiño,Xin Zhou", "background": "在大规模物理系统数据集上利用变换器的潜力取决于克服注意机制的二次缩放问题。本文探讨了将Erwin架构与本地稀疏注意（NSA）机制结合，以增强变换器模型处理大型物理系统效率和感受野，解决二次注意力复杂性的挑战。作者将NSA机制适应非序列数据，实现了Erwin NSA模型，并在宇宙学模拟、分子动力学和气压建模的三个物理科学数据集上进行了评估，实现了与原版Erwin模型相当或更优的性能。此外，作者还复现了Erwin论文中的实验结果来验证其实现。", "innovation": "将本地稀疏注意（NSA）机制适应非序列数据，并应用于Erwin架构中，提高了变换器模型在大型物理系统数据集上的效率和感受野，降低了二次注意力复杂性带来的挑战。", "conclusion": "研究实现了一个新的Erwin NSA模型，并验证了其在三个物理科学数据集上的有效性，其性能达到了或超过了原版模型的水平，同时也验证了Erwin模型的实验结果的可复现性。"}
{"llm_update_time": "20250816", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.10760", "html_url": "https://arxiv.org/abs/2508.10760", "title": "FROGENT: 一个完整的端到端药物设计代理", "title_en": "FROGENT: An End-to-End Full-process Drug Design Agent", "authors": "Qihua Pan,Dong Xu,Jenna Xinyi Yao,Lijia Ma,Zexuan Zhu,Junkai Ji", "background": "现有的强人工智能工具在药物发现中的应用被分散在孤立的网页应用程序、桌面程序和代码库中。这种碎片化使得研究人员需要管理和处理不兼容的接口和专用脚本，这过程繁琐且耗时。因此，需要一个集成的平台来解决这个问题。", "innovation": "FROGENT 提出了一个新的平台，它利用大型语言模型和模型上下文协议整合了多个动态生物化学数据库、可扩展工具库和任务特定的人工智能模型。这使得 FROGENT 能够动态执行复杂的药物发现工作流程，如目标识别、分子生成和逆合成规划。FROGENT 在八个基准测试上进行了评估，涵盖药物发现的不同方面，并且在hit-finding和interaction profiling两个方面显著提高了表现。", "conclusion": "FROGENT 的开发表明，优化药物发现的代理流程可以显著提高研究人员的工作效率。"}
{"llm_update_time": "20250816", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.10732", "html_url": "https://arxiv.org/abs/2508.10732", "title": "APFL: 双流最小二乘的分析个性化联邦学习", "title_en": "APFL: Analytic Personalized Federated Learning via Dual-Stream Least Squares", "authors": "Kejia Fan,Jianheng Tang,Zhirui Yang,Feijiang Han,Jiaxu Li,Run He,Yajiang Huang,Anfeng Liu,Houbing Herbert Song,Yunhuai Liu,Huiping Zhuang", "background": "个性化联邦学习（PFL）通过协作训练将个性化模型传递给各个客户端面临着重大挑战。现有的PFL方法往往对非IID数据非常脆弱，这严重影响了集体泛化能力，从而削弱了后续个性化努力的效果。", "innovation": "本文提出了一种名为APFL的新方法，通过双流最小二乘分析实现。该方法使用一个基础模型作为固定的特征提取器。在此之后，开发了双流分析模型，以实现集体泛化和个体个性化。特别地，APFL包括一个共享的主要流用于所有客户端的全局泛化，以及一个专门为每个个体客户端进行本地个性化的专用精炼流。APFL的解析解决方案使其具有异构性不变的理想属性，理论上意味着无论其他客户端的数据如何分布，生成的个性化模型都是相同的。各数据集上的实证结果也证实了APFL在准确率方面优于最先进的基线，至少具有1.10%到15.45%的好处。", "conclusion": "本文提出的APFL在准确性和处理非IID数据方面表现出优势，验证了其在各数据集上的优越性和适用性。"}
{"llm_update_time": "20250816", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.10751", "html_url": "https://arxiv.org/abs/2508.10751", "title": "Pass@k 训练：用于适应性平衡大型推理模型探索和利用的培训", "title_en": "Pass@k Training for Adaptively Balancing Exploration and Exploitation of Large Reasoning Models", "authors": "Zhipeng Chen,Xiaobo Qin,Youbin Wu,Yue Ling,Qinghao Ye,Wayne Xin Zhao,Guang Shi", "background": "强化学习中使用的可验证奖励（RLVR）通常采用 Pass@1 作为奖励，但在平衡探索和利用方面存在问题，导致政策偏好保守行为，收敛到局部最优。Pass@k 虽然在评估中被使用，但其与大型语言模型（LLM）探索能力之间的联系尚未充分探索。因此，识别合适的奖励指标至关重要。针对当前研究，论文首先使用 Pass@k 作为奖励训练策略模型，观察其探索能力的提升，并推导出 Pass@k 训练的优势，揭示了探索和利用不是相互冲突的目标，而是可以相互促进的。基于此发现，论文进一步探索了 RLVR 的优势设计，显示出有希望的结果，并强调了其未来的研究方向。", "innovation": "论文提出了 Pass@k 训练方法，首次使用 Pass@k 度量作为奖励来训练策略模型，并通过推导 Pass@k 训练的优势，揭示了探索和利用之间的协同性。此外，基于此发现，论文初步探索了 RLVR 的优势设计，提供了一个可能的研究方向。", "conclusion": "论文表明，探索和利用并非矛盾目标，而是可以相互促进的，通过 Pass@k 训练和优势设计的方法，可以有效地提高模型的探索能力，为增强 RLVR 的性能提供了一个新的研究方向。"}
{"llm_update_time": "20250816", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.10776", "html_url": "https://arxiv.org/abs/2508.10776", "title": "使用决策导向学习法估计协方差以构建全局最小方差资产组合", "title_en": "Estimating Covariance for Global Minimum Variance Portfolio: A Decision-Focused Learning Approach", "authors": "Juchan Kim,Inwoo Tae,Yongjae Lee", "background": "投资组合优化是风险管理的基础，用于量化解风险与收益之间的关系。由于投资组合优化依赖于对未来不确定性的参数估计，选择合适的输入参数是构建有效投资组合的关键。然而，传统的统计估计方法和机器学习算法通常通过最小化均方误差（MSE）来确定参数，而MSE可能会导致次优的投资决策。", "innovation": "本文采用决策导向学习（DFL）方法，直接优化决策质量而非预测误差，通过理论推导得到了全局最小方差资产组合的梯度及其特征，实证研究表明，预测导向的方法可能无法产生最优的资产配置，而DFL方法能够持续提供更优的决策表现。", "conclusion": "作者对DFL在全局最小方差资产组合构建中的机制进行了全面分析，指出其在降低波动性、驱动决策和估计特性方面的能力和特点，表明了DFL在构建资产组合时的有效性。"}
{"llm_update_time": "20250816", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.10774", "html_url": "https://arxiv.org/abs/2508.10774", "title": "Video-BLADE：块稀疏注意力与逐步蒸馏的结合用于高效视频生成", "title_en": "Video-BLADE: Block-Sparse Attention Meets Step Distillation for Efficient Video Generation", "authors": "Youping Gu,Xiaolong Li,Yuhao Hu,Bohan Zhuang", "background": "当前，扩散模型在高质量视频生成任务中占据领先地位，但它们的缓慢迭代去噪过程和长时间序列的二次注意力成本导致了显著的推理瓶颈。虽然步骤蒸馏和稀疏注意力机制各自展示了加速的潜力，但将两者有效结合仍面临挑战。在不进行训练的情况下将稀疏注意力集成效果不佳，而分别对步骤蒸馏进行训练后再引入稀疏注意力则需要昂贵的高质量视频数据。因此，开发一种能在不依赖高质量视频数据前提下的高效加速框架变得必要且迫切。", "innovation": "作者提出了一种名为BLADE的创新数据无损联合训练框架，包括：1）自适应块稀疏注意力（ASA）机制，动态生成内容感知的稀疏性掩码，以重点计算关键的空间时间特征；2）基于轨迹分布匹配（TDM）的稀疏性意识步骤蒸馏范式，直接将稀疏性融入蒸馏过程，而非将其视为单独的压缩步骤，从而实现快速收敛。", "conclusion": "该研究在文本到视频模型如CogVideoX-5B和Wan2.1-1.3B上进行了验证，展示出跨越不同尺度的巨大效率提升。在Wan2.1-1.3B上，相比50步基线，BLADE实现了14.10倍的端到端推理加速。在CogVideoX-5B等模型上，我们的框架提供了稳定的8.89倍加速，而多方面的人类评估表明这种加速伴随着一致的质量提升。"}
{"llm_update_time": "20250816", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.10860", "html_url": "https://arxiv.org/abs/2508.10860", "title": "从黑箱到透明：通过可解释人工智能增强高校课堂口译评估", "title_en": "From Black Box to Transparency: Enhancing Automated Interpreting Assessment with Explainable AI in College Classrooms", "authors": "Zhaokun Jiang,Ziyin Zhang", "background": "近年来，机器学习的进步引发了对自动化口译质量评估的兴趣增长。然而，现有研究在语言使用质量的评估、由于数据稀缺和不平衡导致的模型效果不佳，以及缺乏解释模型预测的努力方面存在不足。", "innovation": "本文提出了一种多维度建模框架，结合了特征工程、数据扩充和可解释机器学习。该方法强调可解释性而非“黑箱”预测，仅使用相关且透明的特征，并进行Shapley值（SHAP）分析。结果表明，在新构建的英汉连续口译数据集中，该框架具有强大的预测性能，BLEURT和CometKiwi分数是忠诚度最强的预测特征，停顿相关特征则对流畅度具有预测能力，而中文特定短语多样性度量是语言使用质量的最佳预测因素。", "conclusion": "通过特别强调可解释性，本文提出了一种可扩展、可靠且透明的评估技术，作为传统人工评价的替代方案，能够为学习者提供详细诊断反馈，支持自我调节学习，而孤立的自动化评分则不能提供这些优势。"}
{"llm_update_time": "20250816", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.10798", "html_url": "https://arxiv.org/abs/2508.10798", "title": "The SET Perceptual Factors Framework: Towards Assured Perception for Autonomous Systems", "title_en": "The SET Perceptual Factors Framework: Towards Assured Perception for Autonomous Systems", "authors": "Troi Williams", "background": "未来的自主系统有望带来巨大的社会利益，但其部署引发了关于安全性和可信度的问题。一个核心问题是保证机器人感知的可靠性，因为感知是安全决策的基础。感知中的失败通常源于复杂但常见的环境因素，可能导致事故并削弱公众的信任。为了应对这一问题，我们提出了一种称为SET（Self, Environment, and Target）感知因素框架。该框架旨在系统性地分析诸如天气、遮挡或传感器限制等因素如何负面影响感知。", "innovation": "我们设计了SET状态树和SET因素树来分类这些因素的来源，并通过这些树构建感知因素模型来量化给定任务中的不确定性。SET感知因素框架旨在促进对自主系统感知风险的透明和标准化识别、建模和沟通，从而促进对其安全保证的严谨性和公众信任的培养。", "conclusion": "该框架旨在通过提供一种透明和标准化的方法来识别、建模和沟通感知风险，从而促进自主系统安全保证的严谨性和公众对这些系统的理解与信任。"}
{"llm_update_time": "20250816", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.10828", "html_url": "https://arxiv.org/abs/2508.10828", "title": "一种用于识别主观自我披露的多模态神经网络", "title_en": "A Multimodal Neural Network for Recognizing Subjective Self-Disclosure Towards Social Robots", "authors": "Henry Powell,Guy Laban,Emily S. Cross", "background": "主观自我披露是人类社会互动的重要特征。尽管在社会与行为学文献中已经对主观自我披露的特征和后果进行了大量研究，但在开发能够准确模拟主观自我披露的计算系统方面进展有限。特别是，在尝试建模人类与机器人伙伴之间自我披露的具体方式方面的工作更是较少。随着机器人需要与人类在各种社交环境中共事并建立关系，这变得越来越紧迫。", "innovation": "本文旨在通过基于情感识别文献的多模态注意力网络模型开发，结合大量自行收集的自我披露视频语料库进行训练，并构建了一个新的损失函数——尺度保持交叉熵损失，以改进分类和回归问题。结果表明，使用本文新颖损失函数的最优模型的F1分数为0.83，比最优基线模型提高了0.48，这在使社交机器人能够识别互动伙伴的自我披露方面取得了重要进展。", "conclusion": "该研究为社交机器人理解和识别人类同伴的自我披露能力铺平了道路，这是具有社会认知的社交机器人所需的关键能力。"}
{"llm_update_time": "20250816", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.10839", "html_url": "https://arxiv.org/abs/2508.10839", "title": "强化语言模型在顺序决策中的应用", "title_en": "Reinforced Language Models for Sequential Decision Making", "authors": "Jim Dilkes,Vahid Yazdanpanah,Sebastian Stein", "background": "大型语言模型（LLMs）在连续决策代理方面表现出潜力，但由于依赖于大型、计算成本高的模型，其应用受到限制。当前的后训练方法主要是针对单回合交互设计的，无法处理多步代理任务中的信用分配。", "innovation": "本文提出了Multi-Step Group-Relative Policy Optimization (MS-GRPO)，一种新的后训练LLM代理算法，基于形式化的文本中介随机博弈（TSMG）和语言代理政策（LAP）框架。该算法通过将整个累计回合奖励分配给每个单独的回合步骤来进行信用分配，并结合了一种新的绝对优势加权回合采样策略，以改进训练性能。", "conclusion": "通过对拥有30亿参数的模型进行后训练，我们的方法在Frozen Lake任务上的表现优于720亿参数的基线模型，高出50%。该研究证明了针对性的后训练是一种实践性和效率高的替代方案，可以使用LLMs创建顺序决策代理，而无需依赖模型规模。"}
{"llm_update_time": "20250816", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.10779", "html_url": "https://arxiv.org/abs/2508.10779", "title": "基于生成扩散先验的超高清参考引导地标图像超分辨率", "title_en": "Ultra-High-Definition Reference-Based Landmark Image Super-Resolution with Generative Diffusion Prior", "authors": "Zhenning Shi,Zizheng Yan,Yuhang Yu,Clara Xue,Jingyu Zhuang,Qi Zhang,Jinwei Chen,Tao Li,Qingnan Fan", "background": "参考基于图像超分辨率 (RefSR) 的目标是通过利用附加参考高分辨率 (参考HR) 图像的语义和纹理信息来恢复低分辨率 (LR) 图像。现有基于扩散的方法通常基于ControlNet构建，但不擅长有效地对齐LR图像和参考HR图像之间的信息。此外，当前的RefSR数据集在分辨率有限和图像质量差方面存在不足，这使得参考图像无法提供足够的细粒度细节来支持高质量的重建。因此，提出了TriFlowSR，该框架旨在显式地在LR图像和参考HR图像之间实现模式匹配。同时，引入了Landmark-4K，这是首个专为超高清 (UHD) 场景地标情况下设计的RefSR数据集。考虑到实际退化情况下的UHD场景，在TriFlowSR中设计了一种参考匹配策略，以有效匹配LR图像和参考HR图像之间的信息。实验结果显示，我们的方法可以更好地利用参考HR图像的语义和纹理信息，相对于之前的方法。到目前为止，我们提出的方法是第一个针对实际退化情况下超高清地标场景的基于扩散的RefSR管道。", "innovation": "本文提出了TriFlowSR，一种新型的框架，旨在显式地在LR图像和参考HR图像之间实现模式匹配。同时，引入了Landmark-4K，这是首个专为超高清场景地标情况下设计的RefSR数据集。在TriFlowSR中设计了一种参考匹配策略，以有效匹配LR图像和参考HR图像之间的信息，提出了一个基于扩散的RefSR管道，专门适用于超高清地标场景在实际退化情况下的情况。", "conclusion": "实验结果显示，与之前的RefSR方法相比，我们的方法更能有效利用参考HR图像的语义和纹理信息。我们提出了一个基于扩散的RefSR管道，专门针对实际退化情况下的超高清地标场景。"}
{"llm_update_time": "20250816", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.10869", "html_url": "https://arxiv.org/abs/2508.10869", "title": "Medico 2025: Visual Question Answering for Gastrointestinal Imaging", "title_en": "Medico 2025: Visual Question Answering for Gastrointestinal Imaging", "authors": "Sushant Gautam,Vajira Thambawita,Michael Riegler,Pål Halvorsen,Steven Hicks", "background": "该挑战基于MedaEval任务系列，旨在针对胃肠（GI）成像的视觉问答（VQA）进行研究。挑战聚焦于开发可解释的人工智能（XAI）模型，这些模型可以在胃肠内窥镜图像上回答临床相关的问题，并提供与医学推理相一致的可解释的解释。该挑战提供了一个标准基准，包括基于6,500张图像和159,549对复杂问题-答案（QA）对的Kvasir-VQA-x1数据集，用于评估性能和解释性。任务通过结合定量性能指标和专家评审的解释性评估，旨在推动医疗图像分析中可信赖的人工智能的进步。", "innovation": "该挑战通过引入两个子任务来创新：一是使用Kvasir-VQA-x1数据集回答多种类型的视觉问题，二是生成多模态解释以支持临床决策。数据集的构建方法和评估标准还结合了定量性能和专家评审的解释性评估，旨在推动可解释的人工智能在医疗图像分析中的进步。", "conclusion": "通过这个挑战，研究者可以更好地理解如何开发可解释的AI模型来回答临床相关问题，同时也推动了基于可解释性的医疗图像分析的发展。"}
{"llm_update_time": "20250816", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.10872", "html_url": "https://arxiv.org/abs/2508.10872", "title": "基于TLE的A2C代理进行地面覆盖轨道路径规划", "title_en": "TLE-Based A2C Agent for Terrestrial Coverage Orbital Path Planning", "authors": "Anantha Narayanan,Battu Bhanu Teja,Pruthwik Mishra", "background": "低地球轨道（LEO）的拥堵问题持续影响着地球观测卫星的高效部署和安全操作。任务规划者不仅要考虑特定任务的要求，还需要考虑到与活跃卫星及其碎片的碰撞风险。本文提出了一种使用优势演员评论家（A2C）算法的强化学习框架，以优化卫星轨道参数，实现预设地表范围内精确的地面覆盖。该方法通过在一个自定义的OpenAI Gymnasium环境中将问题形式化为马尔可夫决策过程（MDP）来模拟开普勒经典元素的轨道动力学。研究表明，A2C在累计奖励和收敛速度方面优于Proximal Policy Optimization（PPO）。", "innovation": "本文的主要创新包括：1. 引入了基于TLE的轨道模拟环境，配备了物理约束；2. 验证了在连续轨道控制中演员评论家方法优于信任区域方法；3. 展示了快速收敛性，可以实现卫星部署的适应性。这些贡献表明了强化学习作为低地球轨道任务规划的高效替代方案的潜力。", "conclusion": "本文的研究表明，使用A2C算法的强化学习方法可以有效地实现地面覆盖任务，同时保持高效率，适用于实时任务规划。这种方法为低地球轨道任务规划提供了可扩展和智能的解决方案。"}
{"llm_update_time": "20250816", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.10875", "html_url": "https://arxiv.org/abs/2508.10875", "title": "A Survey on Diffusion Language Models", "title_en": "A Survey on Diffusion Language Models", "authors": "Tianyi Li,Mingda Chen,Bowei Guo,Zhiqiang Shen", "background": "扩散语言模型（DLMs）正在迅速成为与自回归（AR）范式相对的强大而有前途的替代方案。通过迭代去噪过程并行生成标记，DLMs在减少推理延迟和捕捉双向上下文方面具有内在优势，从而使得生成过程具有精微控制。尽管实现了几倍的速度提升，最近的进步使DLMs在性能上与自回归模型相当，从而使它们成为各种自然语言处理任务的有吸引力的选择。", "innovation": "本综述提供了DLMs领域的全面概述，追溯其演变及其与其他范式（如自回归和遮蔽语言模型）的关系。涵盖了基础原理和最先进的模型，并提供了从预训练策略到高级后处理方法的最新技术的当前技术和全面分类和深入分析。还进行了彻底审查DLMs的推理策略和优化，包括解码并行性、缓存机制和生成质量的改进，强调了DLMs的多模态扩展及其在各种实际场景中的应用。", "conclusion": "我们讨论了DLMs的限制和挑战，包括效率、长序列处理和基础设施要求，并概述了在这一快速发展的领域持续进步的研究方向。开源项目GitHub地址为：this https URL。"}
{"llm_update_time": "20250816", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.10771", "html_url": "https://arxiv.org/abs/2508.10771", "title": "AEGIS: AI-生成视频序列的真实性评估基准", "title_en": "AEGIS: Authenticity Evaluation Benchmark for AI-Generated Video Sequences", "authors": "Jieyu Li,Xin Zhang,Joey Tianyi Zhou", "background": "近年来，AI生成的内容发展迅速，产生了极其逼真的合成视频，这对社会信任和数字完整性构成了严重威胁。现有的视频真实性检测基准通常缺乏实际性、规模不足且复杂性不够，无法有效评估现代的视觉-语言模型在对抗复杂的伪造方面的能力。因此，出现了这一关键的差距，需要一个新的基准来测试现代模型在识别逼真和语义复杂的AI生成视频方面的性能，这就是AEGIS的由来。AEGIS是一个新的大规模基准，旨在明确检测超逼真和语义复杂的AI生成视频。它包括超过10,000个精心挑选的真实和合成视频，这些视频由不同的先进生成模型生成，包括Stable Video Diffusion、CogVideoX-5B、KLing和Sora，包括开源和专有的架构。此外，它还特别构建了具有稳健评估的挑战性子集。", "innovation": "该论文介绍了AEGIS，这是一个专为检测超逼真和语义复杂的AI生成视频而设计的新型大规模基准。AEGIS由超过10,000个精心挑选的真实和合成视频组成，这些视频由不同的先进生成模型生成，包括Stable Video Diffusion、CogVideoX-5B、KLing和Sora，包括开源和专有的架构。特别之处在于，它增加了具有稳健性评估的挑战性子集，并提供了包括语义-真实性描述、运动特征和低级视觉特征在内的多模态注释，以支持伪造检测和其他后续任务。并且，使用先进的视觉-语言模型进行了广泛的实验，证实了在某些最具挑战性的数据集上的检测能力有限，突显了该数据集的独特复杂性和现实性，超越了现有模型的泛化能力。因此，AEGIS为开发真正坚固、可靠、广泛适用的视频真实性检测方法提供了基准，能够应对现实世界的伪造威胁。", "conclusion": "AEGIS不仅填补了当前基准的空白，而且为研究和开发奠定了基础，能够开发出真正坚固、可靠和广泛应用的视频真实性检测方法，以应对真正的伪造威胁。"}
{"llm_update_time": "20250816", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.10887", "html_url": "https://arxiv.org/abs/2508.10887", "title": "对于代表性基准问题领域的Echo State网络配置的经验研究", "title_en": "Empirical Investigation into Configuring Echo State Networks for Representative Benchmark Problem Domains", "authors": "Brooke R. Weborg,Gursel Serpen", "background": "本文研究了使用四种不同基准问题评估Echo State Network（ESN）性能的情况，并指出由于缺乏经验，理解和调整参数以及其值对ESN架构性能的影响是有挑战性的，甚至超参数优化算法在初始手动选择之外也难以对参数值进行调整。因此，理解参数及其值选择对ESN架构性能的影响对于构建成功的ESN非常重要。为了研究不同架构、设计以及参数选择和值变化对ESN性能的影响，文中通过模拟和实验不同问题领域的基准任务来展示ESN性能的这种影响，包括时间序列预测、模式生成、混沌系统预测和时间序列分类。", "innovation": "提出了针对同一领域内问题配置ESN架构的启发式或经验规则，以及参数及其值的选择方法，使得新进入者能够更好地理解和应用ESN技术。", "conclusion": "通过一系列基准任务来展示ESN性能在不同领域中的影响，旨在帮助理解和指导ESN架构的配置，解决进入该领域的经验不足问题。"}
{"llm_update_time": "20250816", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2403.18405", "html_url": "https://arxiv.org/abs/2403.18405", "title": "利用大型语言模型进行法律案例检索中的相关性判断", "title_en": "Leveraging Large Language Models for Relevance Judgments in Legal Case Retrieval", "authors": "Shengjie Ma,Qi Chu,Jiaxin Mao,Xuhui Jiang,Haozhe Duan,Chong Chen", "background": "确定哪些法律案例与给定查询相关涉及阅读冗长的文本并运用复杂的法律推理。传统上，这项任务需要大量时间和法律专业知识来识别关键法律事实，并得出妥当的法律结论。此外，现有具有法律案例相似性的数据缺乏可解释性，使得理解相关性判断的缘由变得困难。随着大型语言模型（LLMs）能力的不断增强，研究人员开始探索它们在这方面的潜在应用，然而，使用通用大型语言模型进行法律案例检索中的可靠相关性判断方法尚未得到广泛研究。", "innovation": "本文提出了一种新颖的少样本方法，其中LLMs辅助生成专家对齐且可解释的相关性判断。该方法将判断过程分解为多个阶段，模仿人类注释者的工作流程，允许灵活地融入专家推理以提高相关性判断的准确性。此外，该方法还确保了可解释的数据标记，为相关性评估过程提供了透明性和清晰度。通过LLMs和人类专家做出的相关性判断比较，我们实证证明，所提出的方法可以产生可靠且有效的相关性评估。", "conclusion": "进一步研究表明，在少量专家监督下，我们的方法可以使大语言模型获得案例分析的专业知识，并通过基于标注的知识蒸馏将这些能力转移到较小的模型上。"}
{"llm_update_time": "20250816", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.10880", "html_url": "https://arxiv.org/abs/2508.10880", "title": "通过仿真搜索LLM代理中的隐私风险", "title_en": "Searching for Privacy Risks in LLM Agents via Simulation", "authors": "Yanzhe Zhang,Diyi Yang", "background": "LLM（大型语言模型）驱动的代理在全球范围内部署时，可能会引入一个关键的隐私威胁：恶意代理主动与他人进行多轮对话以获取敏感信息。动态对话使这种攻击策略更加适应，但其不断变化的特性使得手动预测和发现复杂的漏洞变得困难。文献指出，现有的手动方法难以应对这类问题。因此，迫切需要新的方法来应对这一挑战以便更好地保障隐私安全。", "innovation": "本文提出了一种基于搜索的框架，该框架通过模拟隐私关键的代理互动交替提升攻击者和防御者的策略。框架使用了LLM作为优化器，通过多线程并行搜索和跨线程传播来分析模拟轨迹，并迭代地提出新的指令。该方法能够高效探索交互空间，并发现在简单直接请求之后，攻击策略升级到复杂的多轮战术如身份冒充和同意伪造，而防御策略则从基于规则的约束过渡到身份验证状态机。研究结果证明了这种方法在不同场景和基础模型中的强大实用性，为构建具备隐私保护意识的代理提供了新的视角。", "conclusion": "本文通过搜索方法在模拟中发现了对LLM代理的多种攻击和防御策略，这些攻击和防御能够跨不同场景和模型转移，显示出其在评估和增强隐私保护方面的重要意义。"}
{"llm_update_time": "20250816", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.10865", "html_url": "https://arxiv.org/abs/2508.10865", "title": "GPT-5在脑肿瘤MRI推理中的表现", "title_en": "Performance of GPT-5 in Brain Tumor MRI Reasoning", "authors": "Mojtaba Safari,Shansong Wang,Mingzhe Hu,Zach Eidex,Qiang Li,Xiaofeng Yang", "background": "准确地在磁共振成像(MRI)中区分脑肿瘤类型对于神经肿瘤学中的治疗规划至关重要。近年来，大型语言模型（LLMs）的发展使得视觉问答（VQA）方法能够将图像解释与自然语言推理相结合。本文通过一个基于3个脑肿瘤分割（BraTS）数据集（胶质母细胞瘤（GLI）、脑膜瘤（MEN）、脑转移瘤（MET））的标准化脑肿瘤VQA基准数据集来评估GPT-4o、GPT-5-nano、GPT-5-mini和GPT-5的性能。每个病例均包含多序列MRI三平面拼接图和结构化的临床特征，转换为标准的VQA问题。研究团队将模型在零样本链式思考设置中评估其在视觉和推理任务上的准确性。研究结果表明，GPT-5-mini实现了最高的宏平均准确性（44.19%），其次是GPT-5（43.71%）、GPT-4o（41.49%）和GPT-5-nano（35.85%）。肿瘤亚型不同，各模型的性能也有所不同，没有单一模型在所有组中都表现出压倒性优势。这些发现表明，GPT-5家族模型在结构化神经肿瘤学VQA任务中可以达到中等程度的准确性，但尚未达到临床应用的水平.", "innovation": "本文采用大型语言模型（LLMs）的视觉问答（VQA）方法来评估多个版本的GPT模型对脑肿瘤MRI图像的理解能力。这一研究汇集了多个脑肿瘤分割数据集，对不同的脑肿瘤类型进行了系统的评估，能够发现每种GPT模型在不同肿瘤亚型的表现差异，对于改进神经肿瘤学中基于图像的诊断和治疗决策具有潜在贡献.", "conclusion": "GPT-5家族模型在结构化神经肿瘤学视觉问答任务中的准确率达到了中等程度，但在验证其临床实用性的标准下仍需进一步提高。不同GPT模型在不同脑肿瘤类型的表现存在差异，这为进一步的研究提供了方向。"}
{"llm_update_time": "20250816", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2405.20046", "html_url": "https://arxiv.org/abs/2405.20046", "title": "数据异质性下鲁棒泛化的联邦跨训练学习者", "title_en": "Federated Cross-Training Learners for Robust Generalization under Data Heterogeneity", "authors": "Zhuang Qi,Lei Meng,Ruohan Zhang,Yu Wang,Xin Qi,Xiangxu Meng,Han Yu,Qiang Yang", "background": "联邦学习受益于跨训练策略，能够使模型在来自不同数据源的数据上进行训练，从而提高泛化能力。但由于数据分布的固有差异，本地模型的优化目标仍然不一致，并且即使经过跨训练，特征空间异质性仍然存在。", "innovation": "本文提出了一种跨训练方案FedCT，包括三个主要模块：一致性的知识广播模块旨在优化模型分配策略，增强客户端之间的协作优势，实现高效的联邦学习过程；基于多视角的知识引导表示学习模块利用全球和本地视角的融合原型知识，在模型交换前后增强本地知识的保存，确保本地和全球知识的一致性；混合特征增强模块汇集丰富的信息，进一步增加特征空间的多样性，使模型能够更好地区分复杂的样本。", "conclusion": "实验结果表明，FedCT可以缓解来自本地和全球视角的知识遗忘，使其优于现有最先进的方法。"}
{"llm_update_time": "20250816", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2504.14325", "html_url": "https://arxiv.org/abs/2504.14325", "title": "FAIRGAME：利用博弈理论识别AI代理偏见的框架", "title_en": "FAIRGAME: a Framework for AI Agents Bias Recognition using Game Theory", "authors": "Alessio Buscemi,Daniele Proverbio,Alessandro Di Stefano, TheAnh Han,German Castignani,Pietro Liò", "background": "在多智能体应用中，让AI代理相互作用增加了对AI结果的解释和预测的复杂性，这对研究和社的应用中的可信赖采纳具有深刻影响。博弈理论提供了强大的模型来捕捉和解释代理之间的战略互动，但需要具有可重复性、标准化和用户友好的IT框架的支持来使结果的比较和解释成为可能。", "innovation": "我们提出了FAIRGAME，一种利用博弈论识别AI代理偏见的框架。该框架描述了其实现和使用，并利用它揭露了在流行游戏中由于使用的大型语言模型（LLM）及其语言，以及代理的人格特质或战略知识而导致的有偏见的结果。FAIRGAME使用户能够可靠且轻松地模拟他们所需的游戏和场景，并在模拟活动中比较结果，并与博弈论预测进行对比，从而系统地发现偏见，预测新兴行为，为使用LLM代理的战略决策研究提供支持。", "conclusion": "FAIRGAME使用户能够可靠且轻松地模拟他们所需的游戏和场景，并在模拟活动中比较结果，并与博弈论预测进行对比，从而系统地发现偏见，预测新兴行为，并为使用LLM代理的战略决策研究提供支持。"}
{"llm_update_time": "20250816", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.22365", "html_url": "https://arxiv.org/abs/2507.22365", "title": "超越准确性：AI元认知敏感性如何改进人工智能辅助决策", "title_en": "Beyond Accuracy: How AI Metacognitive Sensitivity improves AI-assisted Decision Making", "authors": "ZhaoBin Li,Mark Steyvers", "background": "在依赖AI输入的人类决策环境中，AI系统的预测准确性及其置信度估计的可靠性对决策质量有重大影响。本文讨论了AI元认知敏感性（即，AI能够准确区分正确和错误预测的能力）的作用，并构建了一个理论框架来评估AI预测准确性和元认知敏感性在混合决策环境中的联合影响。", "innovation": "本文引入了一个理论框架，以评估AI在混合决策环境中的预测准确性和元认知敏感性的结合影响。分析发现，在某些条件下，具有较低预测准确性和较高元认知敏感性的AI也可以提高人类决策的整体准确性。行为实验验证了更高的AI元认知敏感性可以改进人类决策表现。", "conclusion": "这些发现强调了评估AI辅助不仅应考虑准确性，还应考虑元认知敏感性的必要性，并强调了优化两者的必要性以实现最佳决策结果。"}
{"llm_update_time": "20250816", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.10881", "html_url": "https://arxiv.org/abs/2508.10881", "title": "ToonComposer: 以生成式后关键帧处理简化卡通制作", "title_en": "ToonComposer: Streamlining Cartoon Production with Generative Post-Keyframing", "authors": "Lingen Li,Guangzhi Wang,Zhaoyang Zhang,Yaowei Li,Xiaoyu Li,Qi Dou,Jinwei Gu,Tianfan Xue,Ying Shan", "background": "传统卡通和动漫制作涉及关键帧设定、中间画面生成和着色等阶段，这些都需要大量的手动工作。尽管最近人工智能取得了进展，现有的方法通常分别处理这些阶段，导致累积错误和伪影。例如，中间画面生成方法在处理大动作时效果不佳，而着色方法需要密集的每帧草图。这个问题促使我们开发了一种名为ToonComposer的生成模型，它将中间画面生成和着色统一到一个后关键帧阶段。ToonComposer通过稀疏草图注入机制提供关键帧草图的精确控制。此外，它使用一种卡通适配方法，结合空间低秩适应器，将现代视频基础模型调整为卡通领域，同时保留其时间先验。ToonComposer只需要单个草图和着色参考帧即可高效工作，并且能够支持在任何时间点使用多个草图以实现更精细的运动控制。这种能力减少了人工工作量并提高了灵活性，有助于实际场景中的艺术家使用。为了评估我们的模型，我们还创建了PKBench，这是一个包含人类绘制草图的基准，模拟实际使用案例。我们的评估表明，ToonComposer在视觉质量、运动一致性以及生产效率上均优于现有方法，提供了更优且更具灵活性的AI辅助卡通制作解决方案。", "innovation": "ToonComposer是一个生成模型，将中间画面生成和着色统一到一个后关键帧阶段。它通过稀疏草图注入机制提供精确控制，并使用卡通适配方法结合空间低秩适应器将现代视频基础模型适应于卡通领域。只需要少量的输入（如单个草图和着色参考帧），ToonComposer能够高效工作，并且支持多个草图以实现更细致的运动控制。这种能力减少了人工工作量也提高了灵活性，使得艺术家在实际场景中能够更好地使用。", "conclusion": "ToonComposer在视觉质量、运动一致性以及生产效率上均优于现有方法，是一个更优且更具灵活性的AI辅助卡通制作解决方案。为了验证模型性能，我们还创建了PKBench，这是一个包含人类绘制草图的基准，模拟实际使用案例。我们的评估表明ToonComposer能够简化卡通制作过程，提供更好的结果和更高的效率。"}
{"llm_update_time": "20250816", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2411.04293", "html_url": "https://arxiv.org/abs/2411.04293", "title": "一种用于组合优化的随机键优化器", "title_en": "A Random-Key Optimizer for Combinatorial Optimization", "authors": "Antonio A. Chaves,Mauricio G.C. Resende,Martin J.A. Schuetz,J. Kyle Brubaker,Helmut G. Katzgraber,Edilson F. de Arruda,Ricardo M. A. Silva", "background": "论文介绍了随机键优化器（RKO），这是一种针对组合优化问题的适应性强且高效的随机局部搜索方法。RKO 通过使用随机键的概念来编码解决方案，并通过特定问题的解码器将这些随机键解码成可行的解决方案。RKO 框架可以整合包括模拟退火、迭代局部搜索、贪婪随机适应性搜索程序在内的多种经典元启发式算法，并且这些算法可以在独立或并行方式下运行。此外，RKO 框架还支持通过精英解池进行解决方案分享，从而促进多种元启发式算法的集成应用。该论文通过 C++ 实现并公开发布在 Github （公共仓库链接），展示了 RKO 框架在三个 NP 难问题（α-邻域 p 中心问题、树枢纽位置问题、结点容量受限的图划分问题）中的应用效果，验证了其能够在不同场景下产生高质量解的能力，进而展示了其作为组合优化工具的潜力和可靠性。", "innovation": "RKO 框架的核心创新在于其采用随机键编码解决方案，并通过问题特定的解码器将这些随机键解码成可行解决方案的能力。此外，RKO 支持多种元启发式算法的模块化组合，灵活地控制不同算法的独立运行或并行运行，并通过精英解池促进算法之间的协同工作。这种框架设计使得 RKO 能够高效地解决多种组合优化问题，并在多个 NP 难问题上的应用中得到了验证，展示了其强大的泛化能力和解决实际问题的潜力。", "conclusion": "RKO 框架通过其独特的设计和实现，成功地解决了多个 NP 难问题，并生成了高质量的解决方案。其模块化的功能和高效的运行方式展示了其作为组合优化工具的强大潜力。该框架在未来的研究和应用中具有广泛的应用前景，能够为解决更复杂和多变的组合优化问题提供一种灵活且高效的方法。"}
{"llm_update_time": "20250816", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.08909", "html_url": "https://arxiv.org/abs/2508.08909", "title": "Compass-Thinker-7B技术报告", "title_en": "Compass-Thinker-7B Technical Report", "authors": "Anxiang Zeng,Haibo Zhang,Kaixiang Mo,Long Zhang,Shuman Liu,Yanhui Huang,Yawen Liu,Yuepeng Sheng,Yuwei Huang", "background": "最近的R1-Zero-like研究进一步显示，推理扩展赋予了大型语言模型（LLMs）前所未有的推理能力，而强化学习是提取其复杂推理的核心技术。然而，直接在超大规模模型上进行RL实验涉及极高的计算成本和资源需求，存在明显风险。", "innovation": "提出了Compass-Thinker-7B模型，旨在探索在较少的计算资源和成本下使用强化学习的潜力，并提供对更大模型的强化学习食谱的进一步研究线索。", "conclusion": "广泛的评估表明，Compass-Thinker-7B具有卓越的推理潜力，并在数学任务上取得了优于同规模RL模型的性能。特别是在具有挑战性的AIME2024评估中，Compass-Thinker-7B的准确率达到40%。"}
{"llm_update_time": "20250816", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.15758", "html_url": "https://arxiv.org/abs/2507.15758", "title": "LAPO：通过长度自适应策略优化实现推理效率的内在化", "title_en": "LAPO: Internalizing Reasoning Efficiency via Length-Adaptive Policy Optimization", "authors": "Xingyu Wu,Yuchen Yan,Shangke Lyu,Linjuan Wu,Yiwen Qiu,Yongliang Shen,Weiming Lu,Jian Shao,Jun Xiao,Yueting Zhuang", "background": "大型推理模型通过扩展链式思考序列获得了显著的性能，但这种计算自由度导致即使是简单的问题也会生成过多的令牌。现有的方法要么施加严格的限制，要么依赖于事后干预，不能让模型自我理解合适的推理深度。本文研究如何通过自适应策略优化，使模型能够内在化适当的推理长度控制能力，从而实现推理效率的提升和灵活性。", "innovation": "本文提出了Length-Adaptive Policy Optimization (LAPO)框架，其创新在于将推理长度控制从外部约束转化为模型自身的内在能力。LAPO采用了两阶段的强化学习过程：第一阶段，模型通过发现成功解题长度的统计分布来学习自然的推理模式；第二阶段，利用这些模式作为元认知指导，直接嵌入模型的推理过程中，以确保推理时的灵活性。这种两阶段的训练方法使模型能够根据问题的复杂性自我调整计算资源的分配，从而在高效推理的同时保持高质量。", "conclusion": "实验结果显示，使用LAPO训练的模型在数学推理基准测试上，可以将令牌使用减少40.9%，同时准确率提高2.3%。分析表明，LAPO训练的模型发展出了一种基于问题复杂性分配计算资源的能力，实现了高效的推理，而没有牺牲质量。"}
{"llm_update_time": "20250816", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.09123", "html_url": "https://arxiv.org/abs/2508.09123", "title": "OpenCUA: 开源计算机使用代理的基础", "title_en": "OpenCUA: Open Foundations for Computer-Use Agents", "authors": "Xinyuan Wang,Bowen Wang,Dunjie Lu,Junlin Yang,Tianbao Xie,Junli Wang,Jiaqi Deng,Xiaole Guo,Yiheng Xu,Chen Henry Wu,Zhennan Shen,Zhuokai Li,Ryan Li,Xiaochuan Li,Junda Chen,Boyuan Zheng,Peihang Li,Fangyu Lei,Ruisheng Cao,Yeqiao Fu,Dongchan Shin,Martin Shin,Jiarui Hu,Yuyan Wang,Jixuan Chen,Yuxiao Ye,Danyang Zhang,Dikang Du,Hao Hu,Huarong Chen,Zaida Zhou,Haotian Yao,Ziwei Chen,Qizheng Gu,Yipu Wang,Heng Wang,Diyi Yang,Victor Zhong,Flood Sung,Y.Charles,Zhilin Yang,Tao Yu", "background": "视觉语言模型已经展示了作为计算机使用代理（CUAs）的强大功能，能够自动化各种计算任务。随着这些代理的商业化潜力增长，关于最先进CUA系统的关键细节仍然封闭。由于这些代理将越来越多地调解数字交互并替我们执行重要的决策，研究社区需要访问开源CUA框架来研究它们的能力、局限性和风险。为了解决这一问题，我们提出了OpenCUA，一个综合的开源框架，用于扩展CUA数据和基础模型。", "innovation": "我们的框架包括：(1)一个无缝捕捉人类计算机使用演示的注释基础设施；(2)AgentNet，第一个跨3个操作系统和200多个应用程序和网站的大型计算机使用任务数据集；(3)一个可扩展的管道，将演示转化为包含反思性长链推理的状态-行动对，随着数据的规模扩大，这种方法能维持稳健的性能提升。我们的端到端代理模型在CUA基准测试中表现优秀。具体而言，OpenCUA-32B在OSWorld-Verified上的平均成功率达到了34.8%，在开源模型中建立了新的最佳水平，并超过了OpenAI CUA（GPT-4o）。进一步的分析表明，我们的方法在不同领域中具有很好的泛化能力，并且从测试时计算量的增加中受益显著。", "conclusion": "我们发布了我们的注释工具、数据集、代码和模型，以构建进一步CUA研究的开放基础。"}
{"llm_update_time": "20250816", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.23701", "html_url": "https://arxiv.org/abs/2507.23701", "title": "TextQuests：LLM在文本冒险游戏中的表现如何？", "title_en": "TextQuests: How Good are LLMs at Text-Based Video Games?", "authors": "Long Phan,Mantas Mazeika,Andy Zou,Dan Hendrycks", "background": "评估智能体在复杂且交互式的环境下的性能对于理解其实际能力至关重要。现有的智能体基准测试能够有效评估工具使用能力或结构化任务的表现，但往往未能全面捕捉智能体在探索性环境中的自主操作能力，这些环境需要在长期且不断增长的情境中进行持续、自我导向的推理。为了使智能体在挑战性的探索环境中得到更准确的评估，该研究引入了基于Infocom文本冒险游戏套件的TextQuests基准测试。这些需要数小时并需进行数百次精确操作才能解决的文本冒险游戏为评估智能体在专注于、有状态任务上的表现提供了一个有效的代理。这些基准测试特别设计来评估LLM智能体进行自我封闭问题解决的能力，限制了外部工具的使用，从而专注于在探索性环境中进行内在长时间上下文推理的能力。需要在单次交互会话中进行试验性学习和持续解决问题所需的能力。", "innovation": "该研究借助基于Infocom文本冒险游戏套件（TextQuests）的基准测试，为智能体在探索性环境中的表现评价提供了一个有效的代理。这种基准测试特别设计来评估LLM智能体的自我封闭问题解决能力，限制了外部工具的使用，专注于在探索性环境中进行内在长时间上下文推理的能力。这些冒险游戏需要数小时并需进行数百次精确操作才能解决，需要进行试验性学习和持续解决问题。", "conclusion": "TextQuests基准测试为评估智能体在有挑战性的探索环境中提供了有效的方法，特别是对于那些需要长时间上下文推理和试验性学习能力的智能体。这种新基准测试有助于更准确地评价LLM对探索性环境中的自包含问题解决能力。"}
{"llm_update_time": "20250816", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2312.07055", "html_url": "https://arxiv.org/abs/2312.07055", "title": "通过哈希函数在局部差分隐私下减少子图计数的通信成本", "title_en": "Communication Cost Reduction for Subgraph Counting under Local Differential Privacy via Hash Functions", "authors": "Quentin Hillebrand,Vorapong Suppakitpaisarn,Tetsuo Shibuya", "background": "在边缘局部差分隐私（edge local differential privacy）下计算图统计量，包括子图计数时，存在许多算法但大多因为高通信成本而不适用于大型图。现有的数据压缩技术在局部差分隐私下应用时需要一种形式的压缩，使得每个节点都能复制。", "innovation": "引入线性同余哈希函数，在确保每个节点能够复制的基础上，通过采样率 $s$ 削减通信成本高达因子 $s^2$，但统计量的误差方差也相应增加因子 $s$。实验结果表明，在通信成本相同的情况下，与领先算法相比，该方法可以将三角形计数的 $l_2$ 损失降低高达1000倍。", "conclusion": "该研究提出了一种通过线性同余哈希减少局部差分隐私下子图计数的通信成本的方法，证明了其在高效性和准确性方面的优势。"}
{"llm_update_time": "20250816", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2402.13871", "html_url": "https://arxiv.org/abs/2402.13871", "title": "基于可解释的变压器模型的钓鱼邮件检测：一种大型语言模型方法", "title_en": "An Explainable Transformer-based Model for Phishing Email Detection: A Large Language Model Approach", "authors": "Mohammad Amaz Uddin,Md Mahiuddin,Iqbal H. Sarker", "background": "钓鱼邮件作为一种严重的网络威胁，通过发送虚假邮件试图欺骗用户，以窃取敏感信息或造成财务损失。攻击者常伪装成可信赖的实体，利用技术进步使其检测和预防变得更加困难。尽管进行了广泛的学术研究，但钓鱼邮件检测仍然是网络安全领域中的一个长期且艰巨的挑战。大型语言模型（LLMs）和掩码语言模型（MLMs）具有巨大的潜力，可以提供创新解决方案以应对长期存在的挑战。", "innovation": "本文提出了一种优化的、基于变压器的DistilBERT微调模型，用于钓鱼邮件检测。在数据预处理方面，我们解决了一类不平衡的问题，通过实验表明，该模型能够实现高准确度，并通过可解释的人工智能（XAI）技术如局部可解释的模型无关解释（LIME）和Transformer解释展示了模型如何在文本分类中做出预测。", "conclusion": "最终，我们的研究证明了基于可解释的变压器模型在钓鱼邮件检测中的有效性，并通过LIME和Transformer解释展示了模型预测的解释性。"}
{"llm_update_time": "20250816", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2409.17702", "html_url": "https://arxiv.org/abs/2409.17702", "title": "利用生活经历的层次表示进行情节记忆口头化", "title_en": "Episodic Memory Verbalization using Hierarchical Representations of Life-Long Robot Experience", "authors": "Leonard Bärmann,Chad DeChant,Joana Plewnia,Fabian Peller-Konrad,Daniel Bauer,Tamim Asfour,Alex Waibel", "background": "口头化机器人的经历，即对机器人过去的总结和问答，是提高人机交互的关键能力。以往的研究利用基于规则的系统或微调深度模型来口头化几分钟长度的时间序列数据，这限制了其普适性和迁移性。", "innovation": "本文采用大规模预训练模型来应对这个问题，并且专注于口头化终生经历。通过从情节记忆（EM）中衍生出一个树状数据结构，将较低层级表示原始的感知和本体感觉数据，将较高层级抽象为自然语言概念。这种层次化表示使大规模数据（如数月的机器人经历数据）的机器计算成本得以控制。", "conclusion": "本方法已经在模拟的家庭机器人数据、人类第一人称视频以及实际的机器人录音中进行评估，展示了其灵活性和可扩展性。"}
{"llm_update_time": "20250816", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2407.12830", "html_url": "https://arxiv.org/abs/2407.12830", "title": "基于知识的大型语言模型一致性测试", "title_en": "Knowledge-based Consistency Testing of Large Language Models", "authors": "Sai Sathiesh Rajan,Ezekiel Soremekun,Sudipta Chattopadhyay", "background": "本文系统地揭示并量化了大型语言模型（LLMs）中的不一致性和知识空白。背景信息表明，尽管LLMs在处理自然语言任务方面取得了显著进展，但它们在知识正确性方面仍存在许多问题和空白，需要进一步的研究和技术来检测和修复这些缺陷。现有的LLMs在知识理解方面可能存在错误或不完整的地方，这些需要一种系统的测试方法来发现和纠正。", "innovation": "本文提出了一个名为KonTest的自动化测试框架。通过利用知识图谱构建测试用例，KonTest结合了语义等价查询和测试元知识（包括元象限或本体元知识）来检查和测量LLMs的全球知识中的不一致性。为了减少知识空白，KonTest进一步使用加权LLMs模型集成进行测试。实验表明，KonTest能够生成19.2%错误引起的数据输入，揭示了16.5%的知识空白，并通过测试套件建议的方法减少了32.48%的知识空白。此外，研究表明GPT3.5不适合用于基于知识的测试，因为它在知识构建方面的有效性仅为60%-68%。", "conclusion": "通过KonTest测试套件，可以有效地检测大型语言模型中基于知识的知识不一致性和知识空白，提出了一种新的测试方法来提高大型语言模型的知识构建和一致性。研究表明，KonTest在揭示LLM知识不一致性和知识空白方面优于现有方法，并且提出的应对措施减小了知识空白。"}
{"llm_update_time": "20250816", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2410.06151", "html_url": "https://arxiv.org/abs/2410.06151", "title": "使用外部行为好奇心促进策略行为多样性", "title_en": "Diversifying Policy Behaviors with Extrinsic Behavioral Curiosity", "authors": "Zhenglin Wan,Xingrui Yu,David Mark Bossens,Yueming Lyu,Qing Guo,Flint Xiaofeng Fan,Yew Soon Ong,Ivor Tsang", "background": "生成学习（IL）已经在各种应用中显示出了潜力，如机器人运动控制，但通常局限于学习单一专家策略，这限制了在不可预测的现实场景中的行为多样性和鲁棒性。因此，现有方法迫切需要提升行为的多样性和性能，特别是在真实世界中面对未见过的场景时。", "innovation": "提出了一个将高质量多样性优化与逆向强化学习（IRL）方法结合的新框架——质量多样性逆向强化学习（QD-IRL），并引入了一种额外的方法：外部行为好奇心（EBC），它使智能体能够根据行为的新颖性从外部评论家获得奖励，进而学习更多的行为。该方法在多种机器人运动任务中验证了其在探索多样化运动行为的有效性。", "conclusion": "研究表明，EBC大幅提升了QD-IRL与其他相关算法（GAIL、VAIL、DiffAIL）在所有包含环境中的性能，甚至在Humanoid任务中超越了专家性能的20%。此外，EBC也被证明适用于基于梯度树状结构的质量多样性强化学习（QD-RL）算法，有助于提高多样性策略的学习性能。"}
{"llm_update_time": "20250816", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2411.19134", "html_url": "https://arxiv.org/abs/2411.19134", "title": "考虑多种运动模型的视觉 SLAMMOT", "title_en": "Visual SLAMMOT Considering Multiple Motion Models", "authors": "Peilin Tian,Hao Li", "background": "SLAM 和 MOT 是自主驾驶领域的重要任务，但常被独立处理，导致性能受限。传统 SLAM 方法假定环境静态，适用于室内；而传统 MOT 技术依赖已知车辆状态，限制了室外动态场景中的性能。为解决这些挑战，已有研究提出了统一 SLAMMOT 方法，但主要针对简单运动模式。在此前的工作中，作者团队提出了 IMM-SLAMMOT 方法，该方法将多种运动模型纳入 SLAMMOT 流程中，被证明在 LiDAR 基础系统中有效。本研究进一步探讨如何将这一方法应用于视觉 SLAMMOT，旨在结合 LiDAR 和视觉传感器的优势。", "innovation": "提出了一种考虑多种运动模型的视觉 SLAMMOT 方法，基于 IMM-SLAMMOT 方法，旨在改善视觉传感器在自主驾驶中的应用。", "conclusion": "本研究验证了考虑多种运动模型的视觉 SLAMMOT 方法的优势，证明了其在自主驾驶环境中的有效性和可行性。"}
{"llm_update_time": "20250816", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2411.15913", "html_url": "https://arxiv.org/abs/2411.15913", "title": "基于潜扩散模型的无需训练的音乐风格迁移方法", "title_en": "A Training-Free Approach for Music Style Transfer with Latent Diffusion Models", "authors": "Heehwan Wang,Joonwoo Kwon,Sooyoung Kim,Shinjae Yoo,Yuewei Lin,Jiook Cha", "background": "音乐风格迁移能够个性化地创作音乐，结合一首乐曲的结构与另一首乐曲的风格特征。虽然近期的研究探索了文本条件下的生成和基于扩散的合成方法，但大多数方法都需要大量的训练、配对的数据集或详细的文本注解。", "innovation": "提出了一种无需训练的框架Stylus，可以直接操作预训练的潜扩散模型（LDM）的自注意力层，通过在梅尔频谱域中替换内容音频的关键和值表示为风格参考的表示来实现风格迁移，从而增强样式化质量和可控性。进一步结合查询保留、CFG启发式的指导缩放、多风格插值和相位保留重构，显著提高了感知质量和结构保留，同时保持了轻量级和易于部署的特点。", "conclusion": "本工作展示了基于扩散的注意力操作在高效、高保真度和可解释的音乐生成中的潜力，无需训练。将在接受后发布代码。"}
{"llm_update_time": "20250816", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2410.18368", "html_url": "https://arxiv.org/abs/2410.18368", "title": "CPU设计空间探索中的多目标优化：注意力机制引领一切", "title_en": "Multi-objective Optimization in CPU Design Space Exploration: Attention is All You Need", "authors": "Runzhen Xue,Hao Wu,Mingyu Yan,Ziheng Xiao,Guangyu Sun,Xiaochun Ye,Dongrui Fan", "background": "现代CPU设计中，设计空间探索（DSE）至关重要，但当前框架在高维度架构空间中的扩展和一般化能力有限。随着设计空间的维度不断增加，现有DSE框架面临三大挑战：（1）大型设计空间中代理模型的准确性和可扩展性降低；（2）基于手工构建的启发式或穷举搜索的低效获取过程；（3）可解释性较低，难以明确识别体系结构瓶颈。", "innovation": "本工作提出了一种名为AttentionDSE的端到端DSE框架，通过基于注意机制的神经架构实现了性能预测和设计指导的整合。关键创新包括：（1）一种感知驱动的注意力机制，通过滑动窗口技术将注意力复杂度从O(n^2)降低到O(n)，同时利用体系结构的层次和本地化；（2）一种注意力感知的瓶颈分析，能够自动识别需要优化的关键参数，消除对领域特定启发式的依赖。", "conclusion": "在使用SPEC CPU2017基准套件对高维度CPU设计空间进行评估时，与现有最佳基线相比，AttentionDSE实现了高达3.9%的Pareto前沿体积改进，并且探索时间减少了超过80%。"}
{"llm_update_time": "20250816", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2412.06534", "html_url": "https://arxiv.org/abs/2412.06534", "title": "通过反演理解基于变压器的视觉模型", "title_en": "Understanding Transformer-based Vision Models through Inversion", "authors": "Jan Rathjens,Shirin Reyhanian,David Kappel,Laurenz Wiskott", "background": "在机器学习和计算机视觉领域，理解深层神经网络背后的机制仍然是一个根本性的挑战。其中一种有前景但尚未充分探索的方法是特征反转，该方法试图使用训练好的逆神经网络从中间表示中重建图像。", "innovation": "本文重新审视了特征反转，并介绍了一种新的模块化变体，使其可以更高效地应用。研究表明，该方法可以系统地应用于大规模的基于变压器的视觉模型（Detection Transformer 和 Vision Transformer），且重建的图像可以有意义地进行定性解释。进一步的定量评估揭示了这两种变压器架构中图像特征表示的机制，揭示了这些模型如何编码上下文形状和图像细节，各层如何相关，以及它们对颜色抖动的鲁棒性。", "conclusion": "本文的分析揭示了基于变压器的视觉模型及它们内部表示的关键见解，包括这些模型如何编码上下文形状和图像细节、各层如何相关以及它们对颜色抖动的鲁棒性。这些发现有助于加深理解基于变压器的视觉模型及其内部表示。同时，我们的实验代码可以在本链接获得。"}
{"llm_update_time": "20250816", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2412.02012", "html_url": "https://arxiv.org/abs/2412.02012", "title": "INSIGHT: 可解释的弱监督医学图像分析", "title_en": "INSIGHT: Explainable Weakly-Supervised Medical Image Analysis", "authors": "Wenbo Zhang,Junyu Chen,Christopher Kanan", "background": "由于医学影像体积庞大，如CT扫描图像和全视野病理图像（WSIs），通常需要先从局部区域提取嵌入，然后通过聚合器进行预测。然而，当前方法往往依赖于事后可视化技术（例如Grad-CAM），有时会忽略小但临床重要的细节，使得不完全准确。因此，需要一种新型的弱监督聚合器，能够集成热图生成作为前置偏置，以便在处理大规模医学影像时能更准确地识别出关键的诊断区域，同时提高诊断准确性并优化弱监督的语义分割效果.", "innovation": "INSIGHT引入了一种新颖的弱监督聚合器，该聚合器将热图生成作为引诱偏置，通过集成一个带有小卷积核的检测模块和一个带有广泛接收场的上下文模块，从而捕捉细节并抑制局部虚假正例。这能够实现对诊断相关区域的突出显示，并在CT和WSI基准测试中实现最先进的分类结果和高弱监督语义分割性能.", "conclusion": "INSIGHT在一个全新的维度上进行了先进性验证，展示出了对医学影像中的关键诊断区域的高效识别能力。通过结合热图生成，提升了弱监督下的语义分割性能，为临床实践提供了解释性的可视化结果。其网站和代码可以此网址访问."}
{"llm_update_time": "20250816", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2501.02409", "html_url": "https://arxiv.org/abs/2501.02409", "title": "扰动下的可解释神经ODE在基因调控网络发现中的应用", "title_en": "Interpretable Neural ODEs for Gene Regulatory Network Discovery under Perturbations", "authors": "Zaikang Lin,Sei Chang,Aaron Zweig,Minseo Kang,Elham Azizi,David A. Knowles", "background": "现代高通量生物数据集提供了大规模发现基因因果图的机会，这些基因因果图代表了基因之间的调控关系。现有模型可以从大规模干预数据中推断基因调控网络（GRN），并捕捉基因扰动引起的因果关系。然而，现有模型在表达能力和扩展性方面存在局限性，难以应对生物学过程的动态性，如细胞分化。", "innovation": "我们提出了PerturbODE框架，该框架结合了生物学信息丰富的神经常微分方程（神经ODEs）来建模扰动下细胞状态轨迹，并通过神经ODEs的参数推导出因果GRN。该方法在模拟和实际过表达数据集上的轨迹预测和GRN推断效果显著。", "conclusion": "PerturbODE在扰动下的基因调控网络发现中展示了其有效性，尤其是在细胞状态轨迹预测和因果GRN推断方面。"}
{"llm_update_time": "20250816", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2412.19160", "html_url": "https://arxiv.org/abs/2412.19160", "title": "一种用于光照不变的生物特征认证的轻量级仅相位交叉注意力变换器", "title_en": "A Lightweight Transformer with Phase-Only Cross-Attention for Illumination-Invariant Biometric Authentication", "authors": "Arun K. Sharma,Shubhobrata Bhattacharya,Motahar Reza,Bishakh Bhattacharya", "background": "传统的生物识别系统由于各种不可避免的因素受到重大打击，例如基于面部识别的生物识别技术中佩戴面罩的影响和基于指纹的生物识别技术中的卫生担忧。", "innovation": "本文提出了一种新的轻量级视觉变换器（POC-ViT），使用面部额头和眼眶部分的双重生物特征检测，即使在佩戴面罩的情况下也能表现良好，且无需物理接触，为传统方法提供了一种有前途的替代方案。该POC-ViT框架设计用于处理两种生物特征，并捕捉它们之间的相互依存关系。每个通道包含一种使用仅相位相关（POC）的交叉注意力，捕获其个体和相关结构模式。使用POC计算交叉注意力提取空间特征的相位相关性，因此，该方法对输入图像的分辨率、强度和光照变化变化具有鲁棒性。轻量级模型适合边缘设备部署。", "conclusion": "本文的框架在Forehead Subcutaneous Vein Pattern and Periocular Biometric Pattern (FSVP-PBP) 数据库上进行测试，该数据库包含350个主题。POC-ViT框架在双重生物特征结合下实现了98.8%的分类精度，优于现有最先进的方法。"}
{"llm_update_time": "20250816", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2502.08512", "html_url": "https://arxiv.org/abs/2502.08512", "title": "测量合成数据集中多样性", "title_en": "Measuring Diversity in Synthetic Datasets", "authors": "Yuchang Zhu,Huizhe Zhang,Bingzhe Wu,Jintang Li,Zibin Zheng,Peilin Zhao,Liang Chen,Yatao Bian", "background": "大语言模型（LLMs）被广泛应用于为各种自然语言处理（NLP）任务生成合成数据集，如文本分类和摘要。然而，准确衡量这些合成数据集的多样性——这对模型的鲁棒性至关重要——仍然是一个巨大挑战。", "innovation": "本文提出了一种名为DCScore的新方法，用于从分类的角度衡量合成数据集的多样性。DCScore将多样性评价形式化为一个样本分类任务，并利用样本之间的相互关系。此外，通过理论上的验证，DCScore证明满足了多样性相关的公理，强调其作为原理性多样性能评估方法的重要性。实验结果表明，DCScore与多个被评估数据集的多样性伪真理具有更强的相关性，突显其有效性。同时，实用和理论证据还表明，DCScore在计算成本上比现有方法有显著降低。", "conclusion": "DCScore在衡量合成数据集多样性方面具有较强的相关性和较低的计算成本。"}
{"llm_update_time": "20250816", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2502.01669", "html_url": "https://arxiv.org/abs/2502.01669", "title": "使用影响函数进行延迟反馈建模", "title_en": "Delayed Feedback Modeling with Influence Functions", "authors": "Chenlu Ding,Jiancan Wu,Yancheng Yuan,Cunchun Li,Xiang Wang,Dingxian Wang,Frank Yang,Andrew Rabinovich", "background": "在按转化付费（CPA）的在线广告模式下，准确预测转化率（CVR）至关重要。一个主要挑战是延迟反馈问题，即转化可能在用户互动之后很久才会发生，导致近期数据不完整，从而对模型训练造成偏差。现有的解决方案虽在一定程度上减轻了这个问题，但往往依赖于辅助模型，这使得它们计算效率较低，并且不能很好地适应用户兴趣的变化。", "innovation": "提出了IF-DFM（惯性函数赋能的延迟反馈建模），一种能够估计新到达和延迟转化对模型参数的影响，从而实现高效更新而无需完全重新训练的方法。通过将逆海森矩阵-向量乘积重新表述为优化问题，IF-DFM在可扩展性和效果之间取得了良好的平衡。实验证明IF-DFM在准确性和适应性方面均优于先前的方法。", "conclusion": "IF-DFM通过影响函数机制有效解决了延迟反馈问题，能够在保持高效性的基础上进行持续的模型参数调整，从而提高了广告投放效果的准确性和适应性。"}
{"llm_update_time": "20250816", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2501.18475", "html_url": "https://arxiv.org/abs/2501.18475", "title": "CLoQ：通过校准的LoRA初始化增强量化LLMs的微调", "title_en": "CLoQ: Enhancing Fine-Tuning of Quantized LLMs via Calibrated LoRA Initialization", "authors": "Yanxia Deng,Aozhong Zhang,Selcuk Gurses,Naigang Wang,Zi Yang,Penghang Yin", "background": "使用低秩适应（LoRA）微调大型语言模型（LLMs）已成为高效的方法，特别适用于计算资源有限的场景。然而，将LoRA技术应用于量化LLMs时，由于量化权重的表示精度较低，带来了独特挑战。本文探讨了如何克服这些挑战，提出了一种简单的初始化策略，旨在最小化LoRA组件插入后原LLM与量化LLM之间的逐层差异，确保后续微调的良好基础。该工作的一个关键贡献是提供了一种新颖的理论结果，能够准确且闭合形式地构建这些最优的LoRA组件。研究在多个任务上验证了CLoQ的有效性，表明它在量化LLMs的LoRA微调方法中始终表现出色，尤其是在极低位宽的情况下。", "innovation": "CLoQ是一种校准的LoRA初始化策略，旨在减少量化LLMs中逐层的差距。其创新点在于利用校准数据集来确定每个层的最优LoRA组件，并提供了一个新颖的理论结果，使得这种构建方式更加准确和闭合形式。", "conclusion": "CLoQ在多个任务中展现出优于现有LoRA微调方法的效果，特别是在量化LLMs且位宽极低的场景中。该研究为量化LLMs的有效微调提供了一个实用且有效的途径。"}
{"llm_update_time": "20250816", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2502.01618", "html_url": "https://arxiv.org/abs/2502.01618", "title": "Rollout Roulette: 一种基于粒子蒙特卡洛方法的概率推理在大语言模型推理时的规模拓展方法", "title_en": "Rollout Roulette: A Probabilistic Inference Approach to Inference-Time Scaling of LLMs using Particle-Based Monte Carlo Methods", "authors": "Isha Puri,Shivchander Sudalairaj,Guangxuan Xu,Kai Xu,Akash Srivastava", "background": "大规模语言模型（LLMs）通过增加模型规模和/或数据量取得了显著的性能提升。然而，近期的研究表明，这种做法带来的回报正在减少，促使人们在推理时间增加计算量。目前，在推理时进行规模扩展的方法通常是使用奖励模型将其视为搜索问题，但这可能导致奖励‘作弊’，因为奖励模型的近似错误。本文将推理时的规模扩展问题重新定义为概率推理任务，利用采样技术探索状态空间模型在近似似然下的状态分布的典型集，而不是直接优化其模式。通过这种方法，我们在多个具有挑战性的数学推理任务上实现了4-16倍的加速。使用我们的方法，Qwen2.5-Math-1.5B-Instruct仅需要4次卷积就可以超越GPT-4o的准确性，而Qwen2.5-Math-7B-Instruct仅需要32次卷积就能达到o1级的准确性。这项工作不仅提供了一种有效的方法来实现推理时的规模扩展，还连接了概率推理丰富的文献与LLMs推理时的规模扩展，并为未来开发更稳健的算法奠定了基础。", "innovation": "本文提出了将推理时的规模扩展问题重新定义为概率推理任务，并使用基于粒子的蒙特卡洛方法来探索状态空间模型在近似似然下的状态分布的典型集。这种方法有效解决了传统方法中存在的奖励模型近似错误等问题，提供了新的算法解决方案。", "conclusion": "研究结果表明，与确定性搜索算法相比，本文提出的方法在多种具有挑战性的数学推理任务中能够实现4-16倍的加速。通过我们的方法，可以更高效地实现大规模语言模型在推理时间和性能上的平衡，为未来的研究提供了新的思路。"}
{"llm_update_time": "20250816", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2501.06117", "html_url": "https://arxiv.org/abs/2501.06117", "title": "Fleurs-SLU：大规模多语言口语理解基准", "title_en": "Fleurs-SLU: A Massively Multilingual Benchmark for Spoken Language Understanding", "authors": "Fabian David Schmidt,Ivan Vulić,Goran Glavaš,David Ifeoluwa Adelani", "background": "口语理解（SLU）对于缺乏正式书写系统的语言至关重要，这些语言约占全球语言的一半。对于这些低资源语言，我们无法依赖自动语音识别（ASR）和文本大型语言模型（LLMs）的链条来实现语义理解。即使低资源语言拥有书写系统，这些语言的ASR依然因为双模态（语音和文本）训练数据不足而不可靠。然而，现有的多语言SLU评估仍局限于浅层任务如意图分类或语言识别，这促使了Fleurs-SLU的提出。Fleurs-SLU集成了102种语言的692小时口语数据以进行主题语句分类，并覆盖92种语言的944小时口语数据以进行倾听理解的选择性问答，从而全面评估端到端语音分类模型、语音到文本再结合LLM分类的级联系统以及语音-LLM多模态模型。研究表明，在多语言SLU中，级联系统表现更稳定，但良好预训练的语音编码器在主题语音分类中表现也相当出色。闭源的语音-LLM在性能上与级联系统相当或更优。研究还发现，在多语言ASR、有效语音到文本翻译与多语言SLU之间存在着强有力的相关性，表明语音和语义表示之间的相互作用具有互补性。", "innovation": "Fleurs-SLU是一个多语言SLU基准，包含102种语言的692小时口语数据以进行主题语句分类，以及92种语言的944小时口语数据以进行倾听理解的选择性问答。该基准评估了端到端语音分类模型、级联系统和多模态语音-LLM模型。研究表明级联系统在多语言SLU中更稳定，但具有良好预训练的语音编码器在主题语音分类中表现也相当出色。闭源的语音-LLM性能与级联系统相当或更优。进一步揭示了多语言ASR、有效的语音到文本翻译与多语言SLU之间的相关性。", "conclusion": "Fleurs-SLU能够为多语言SLU任务提供一个全面评估的平台，发现级联系统在多语言SLU中有更好的稳定性，且预训练的语音编码器和闭源的语音-LLM也有较好的表现。同时，多语言ASR的有效性对多语言SLU有重要影响，这表明了语音和语义表示之间的互补性。"}
{"llm_update_time": "20250816", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2502.16770", "html_url": "https://arxiv.org/abs/2502.16770", "title": "LED-Merging: 通过位置-选举-隔离缓解模型合并中的安全-效用冲突", "title_en": "LED-Merging: Mitigating Safety-Utility Conflicts in Model Merging with Location-Election-Disjoint", "authors": "Qianli Ma,Dongrui Liu,Qian Chen,Linfeng Zhang,Jing Shao", "background": "预先训练的大语言模型（LLMs）针对特定任务进行微调会产生显著的计算和数据成本。现有方法通过合并多个任务特定模型来提供无需训练的解决方案，但它们在增强通用能力的同时降低了安全性保障，出现了安全-效用冲突。主要原因在于简单的基于参数量的选择导致的神经元识别错误，以及合并过程中任务之间的神经元相互干扰。", "innovation": "提出了一种名为LED-Merging的三阶段框架，分别通过基于梯度的责任分配定位特定任务的神经元，通过多模型重要性融合动态选择关键神经元，并通过参数隔离冲突更新来解决问题中的挑战。", "conclusion": "LED-Merging在广泛的实验中证明了其有效降低有害响应率的能力，同时也保持了95%的实用性性能。通过实现对安全-效用冲突的解决，LED-Merging为构建可靠的多任务LLM提供了一个轻量级、无需训练的方法。代码可在GitHub上访问。"}
{"llm_update_time": "20250816", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2502.08644", "html_url": "https://arxiv.org/abs/2502.08644", "title": "节奏共享：一种生物启发的神经网络零样本自适应学习范式", "title_en": "Rhythmic sharing: A bio-inspired paradigm for zero-shot adaptive learning in neural networks", "authors": "Hoony Kang,Wolfgang Losert", "background": "大脑能够快速适应新环境并从少量数据中学习，这是人工智能算法难以复制的宝贵特性。这项研究受到神经细胞机械振荡规律的启发，开发出一种利用连接强度振荡的学习模式，其中学习与这些振荡的协调相关联。通过这种振荡模式，网络能够迅速感知和适应细微的上下文变化，无需监督。此外，这样的网络能够成为一个通用的人工智能架构，能够预测包括未见过的多种情境下的动态变化。这些发现为新型认知模型奠定了强有力的基础。由于这种模式对神经网络的具体细节无特定依赖，该研究为将快速适应学习引入领先的AI模型提供了可能性。", "innovation": "开发出一种基于连接强度振荡的学习模式，使神经网络能够在无需监督的情况下迅速适应细微的环境变化。这种方法能够预测多种情境下的动态变化，为新型认知模型提供了新的起点。该方法对神经网络的具体细节无特定依赖，能够适用于多种现有的AI模型，为快速自适应学习技术的引入提供了新的途径。", "conclusion": "该研究结果为零样本自适应学习提供了一个强大的生物启发范式，该范式不仅能够预测已见过的情境，还能预测未见过的情境，为认知模型的研究开辟了新的方向。由于该范式可以适应各种神经网络，为引入快速自适应学习提供了一个通用的框架。"}
{"llm_update_time": "20250816", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2503.04798", "html_url": "https://arxiv.org/abs/2503.04798", "title": "Advancing MAPF towards the Real World: A Scalable Multi-Agent Realistic Testbed (SMART).", "title_en": "Advancing MAPF towards the Real World: A Scalable Multi-Agent Realistic Testbed (SMART)", "authors": "Jingtian Yan,Zhifei Li,William Kang,Kevin Zheng,Yulun Zhang,Zhe Chen,Yue Zhang,Daniel Harabor,Stephen F. Smith,Jiaoyang Li", "background": "尽管最先进的多代理路径规划（MAPF）算法可以在几秒钟内为数百个机器人规划路径，但这些算法通常依赖于简化的机器人模型，使得它们在实际-world中的表现不明确。研究人员很难在实验室环境中获得数百个真实的机器人来评估这些算法，而行业专业人士缺乏MAPF的专业知识，需要一个易于使用的模拟器来有效地测试和理解这些算法在特定环境中的性能。", "innovation": "SMART引入了一种基于物理引擎的模拟器创建真实模拟环境的方法，考虑了复杂的实际因素如机器人的运动学和执行不确定性。它还采用了一种基于动作依赖图的执行监控框架，支持与各种MAPF算法和其他机器人模型的无缝集成，并且可以扩展到数千个机器人，提供了一个多功能的测试平台。", "conclusion": "SMART是一个实现高效和现实的多代理路径规划评估的软件工具。它通过提供真实的模拟环境、支持多种算法和机器人模型的集成以及能够处理大规模机器人，填补了当前研究和工业应用之间的空白，为多代理路径规划在实际-world中的应用提供了坚实的基础。"}
{"llm_update_time": "20250816", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2503.08064", "html_url": "https://arxiv.org/abs/2503.08064", "title": "多模态连续学习", "title_en": "Continual Learning for Multiple Modalities", "authors": "Hyundong Jin,Eunwoo Kim", "background": "连续学习旨在同时学习随时间序列观察到的任务知识，避免遗忘之前学习的知识。现有方法主要针对单个模态（如图像）进行训练，这限制了它们在涉及多种模态的场景中的适用性。该论文探讨了如何构建一个可以处理多种模态（图像、视频、音频、深度信息和文本）的连续学习框架。", "innovation": "提出了一种新的连续学习框架，能够处理多种模态数据。该框架通过将各种模态与文本对齐来利用其丰富的语义信息，并通过自调节学习表示逐渐整合新的知识，同时引入策略来重新调整模态嵌入，解决模态间潜在的偏差对齐问题，从而缓解先前知识被覆盖的风险。实验表明，该方法在多种数据集上表现优于现有方法，无论模态的身份是否已知。", "conclusion": "该研究提出的框架在多种连续学习场景下表现出色，能够在保持不同模态之间知识整合的同时，有效防止遗忘。这种方法为处理多种模态的连续学习提供了新的解决方案。"}
{"llm_update_time": "20250816", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2504.05349", "html_url": "https://arxiv.org/abs/2504.05349", "title": "Hyperflux: 显性揭示权重重要性", "title_en": "Hyperflux: Pruning Reveals the Importance of Weights", "authors": "Eugen Barbulescu,Antonio Alexoaie,Lucian Busoniu", "background": "网络修剪被用来降低大型神经网络的推理延迟和能源消耗。然而，大多数现有方法使用不朽的启发式方法，缺乏深刻的洞察力，并且主要是通过经验结果来证实其有效性。", "innovation": "我们推出了Hyperflux，这是一种基于L0修剪的概念性方法，通过估计每个权重的“流”来衡量其重要性，即梯度在权重移除后的响应。一个全局压力项持续驱使所有权重向修剪目标发展，那些对准确性至关重要的权重将根据其“流”自动再生。我们提出了几个从该框架自然得出的属性，并通过实验验证了每一个。", "conclusion": "我们通过广义的标度定律方程设计了我们的稀疏性控制调度器，该方程关系了最终的稀疏性和压力。实证结果表明，在CIFAR-10和CIFAR-100的数据集上，我们的方法在ResNet-50和VGG-19上获得了最先进的性能结果。"}
{"llm_update_time": "20250816", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2503.24381", "html_url": "https://arxiv.org/abs/2503.24381", "title": "UniOcc: 自动驾驶中的占用预测与预报统一基准", "title_en": "UniOcc: A Unified Benchmark for Occupancy Forecasting and Prediction in Autonomous Driving", "authors": "Yuping Wang,Xiangyu Huang,Xiaokang Sun,Mingxuan Yan,Shuo Xing,Zhengzhong Tu,Jiachen Li", "background": "现有的研究大多依赖于可预见性较差的伪标签进行评估，未能全面评估占用质量的各个方面。UniOcc旨在提供一个全面且统一的基准和工具包，用于占用预报（基于历史信息预测未来占用情况）和基于相机图像预测当前占用情况，并统合一维和三维占用标签以及创新的每个体素流标注。此外，该工具包提供了大量的真实世界数据集（nuScenes, Waymo）和高保真驾驶模拟器数据（CARLA, OpenCOOD），以增强模型性能。", "innovation": "UniOcc引入了新型的评估指标，这些指标不依赖于真实标签，可以对占用质量的多个方面进行稳健评估。除此之外，通过大规模和多样化的数据训练，以及明确的流信息，显著提高了占用预测和预报的性能。这弥补了现有研究的不足并提供了更全面的评估方法。", "conclusion": "研究结果表明，大规模、多样化的训练数据和显式流信息显著提高了占用预测和预报的性能。UniOcc的数据和代码已经公开，为自动驾驶领域的研究提供了更好的工具和数据支持。"}
{"llm_update_time": "20250816", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2503.18773", "html_url": "https://arxiv.org/abs/2503.18773", "title": "BitDecoding: 低精度 KV 缓存解锁 Tensor 核心用于长上下文 LLMs", "title_en": "BitDecoding: Unlocking Tensor Cores for Long-Context LLMs with Low-Bit KV Cache", "authors": "Dayou Du,Shijie Cao,Jianyi Cheng,Luo Mai,Ting Cao,Mao Yang", "background": "长上下文大型语言模型（LLMs）在自回归解码过程中对内存和带宽的需求随着生成的每个令牌而增加，关键值（KV）缓存也随之增长。低精度 KV 缓存量化（例如，4位或2位）可以在保持准确性的前提下减少内存占用，但目前的系统由于仅仅依赖 CUDA 核心而解码速度较慢，未能充分利用 Tensor 核心——现代 GPU 上的主要计算源。", "innovation": "BitDecoding 是一种新的长上下文 LLM 推理系统，它通过合作利用 CUDA 核心和 Tensor 核心来实现有效低精度 KV 缓存解码。它引入了自动诱导优化布局的方法以充分利用 Tensor 核心，并采用波前级别并行化策略进行去量化。BitDecoding 还包含支持多样关注机制的查询转换模块、高性能的准量化核以及支持混合精度操作的软件定义流水线协调 CUDA 和 Tensor 核心执行的去量化核。这些改进使得 BitDecoding 在 RTX 4090、A100 和 H100 上的解码加速分别达到 FP16 FlashDecoding-v2 的 7.5 倍、4.8 倍和 8.9 倍，超过了最先进的低精度系统 QServe 最多 4.3 倍。在 LLaMA-3.1-8B 上使用 128K 上下文时，单批解码延迟减少了 3 倍。", "conclusion": "BitDecoding 在多个 GPU 型号上显著加速了解码过程，特别在长上下文生成中展现了实质性改进，同时支持多种关注机制和高效的混合精度操作。"}
{"llm_update_time": "20250816", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2503.11655", "html_url": "https://arxiv.org/abs/2503.11655", "title": "带有 DeepSeek-R1 的可解释情感分析：性能、效率和少样本学习", "title_en": "Explainable Sentiment Analysis with DeepSeek-R1: Performance, Efficiency, and Few-Shot Learning", "authors": "Donghao Huang,Zhaoxia Wang", "background": "大型语言模型（LLMs）在情感分析领域取得了显著进展，但仍面临着平衡准确率、效率和可解释性这一关键挑战。这项研究评估了 DeepSeek-R1 这一开源推理模型，对比了它与 OpenAI 的 GPT-4o 和 GPT-4o-mini 的表现，系统地研究了少量学习曲线。「DeepSeek-R1」在五分类情感分析中取得了 91.39% 的 F1 分数，在二分类任务中取得了 99.31% 的准确率，这与 GPT-4o 相比，效率提升了八倍。研究表明，特定架构的蒸馏效果显著，使用 Qwen2.5（32B）模型的性能优于基于 Llama（70B）的变体，高出 6.69 个百分点。尽管推理过程降低了一些吞吐量，但 DeepSeek-R1 通过透明的步骤追踪提高了可解释性，使其成为强大的可解释开源替代方案。", "innovation": "这项研究首次全面评估了 DeepSeek-R1，对比了它与 GPT-4o 和 GPT-4o-mini 的性能；提出了特定架构的蒸馏效果，即 32B 的 Qwen2.5 模型在性能上优于 70B 的 Llama 变体；尽管减少了吞吐量，DeepSeek-R1 通过透明的推理步骤提供更好的可解释性，使其成为高性能、高效和可解释的开源情感分析模型。", "conclusion": "DeepSeek-R1 在减少样本数量的情况下仍能达到出色的情感分析性能，特别是在 F1 分数和二分类任务中的准确率方面，优于基线模型，并且其推理过程的透明性使其成为一个强大的、可解释的开源替代方案。"}
{"llm_update_time": "20250816", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2504.01400", "html_url": "https://arxiv.org/abs/2504.01400", "title": "ToolACE-R: Model-aware Iterative Training and Adaptive Refinement for Tool Learning", "title_en": "ToolACE-R: Model-aware Iterative Training and Adaptive Refinement for Tool Learning", "authors": "Xingshan Zeng,Weiwen Liu,Xu Huang,Zezhong Wang,Lingzhi Wang,Liangyou Li,Yasheng Wang,Lifeng Shang,Xin Jiang,Ruiming Tang,Qun Liu", "background": "工具学习使大语言模型（LLMs）能够利用外部工具解决复杂的用户任务，已成为扩展模型能力的一个有前景的途径。然而，现有方法主要集中在数据合成用于微调LLMs调用工具的有效性，很大程度上忽视了如何充分发挥模型的潜力。现有的工具学习方法主要集中于数据合成，即通过微调LLMs使其能够有效调用工具，但大都忽略了如何最大化模型自身潜力的问题。", "innovation": "本论文提出了ToolACE-R，这是一种新的框架，结合了模型感知迭代训练和自适应细致化。具体来说，ToolACE-R包含基于模型的迭代训练步骤，通过逐步调整训练样本来最大限度地挖掘模型潜能；此外，引入了自适应细致化训练语料库，强调了大语言模型在调用工具过程中的迭代改进能力；同时，引入了自适应细致化机制，提高了测试时的可扩展性，使模型能够自主决定何时停止细微调整过程。作者通过在多个基准数据集上进行广泛实验，展示了ToolACE-R的表现与高级API基模型相当，并且通过自适应细化机制可以进一步提升工具调用性能。", "conclusion": "研究表明，ToolACE-R在模型学习工具方面具有较高的有效性与普适性，为其开辟了一个更加高效和可扩展的工具学习方向。实验结果证明了ToolACE-R的有效性和通用性，为未来的研究提供了重要的参考。"}
{"llm_update_time": "20250816", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2504.06866", "html_url": "https://arxiv.org/abs/2504.06866", "title": "GraspClutter6D: 用于杂乱场景中稳健感知和抓取的大规模真实世界数据集", "title_en": "GraspClutter6D: A Large-scale Real-world Dataset for Robust Perception and Grasping in Cluttered Scenes", "authors": "Seunghyeok Back,Joosoon Lee,Kangmin Kim,Heeseon Rho,Geonhyup Lee,Raeyoung Kang,Sangbeom Lee,Sangjun Noh,Youngjin Lee,Taeyeop Lee,Kyoobin Lee", "background": "在机器人领域，杂乱环境中的稳健抓取仍然是一个开放的挑战。尽管基准数据集显著推进了深度学习方法的发展，但这些数据集主要关注场景简单且光线不完全遮挡的情况，缺乏多样性，限制了其在实际应用场景中的应用。", "innovation": "本文提出了GraspClutter6D数据集，这是一个包含1000个高杂乱度场景、全面覆盖200种物体并使用四个RGB-D摄像头从多个视角拍摄的大型真实世界抓取数据集，涵盖75种环境配置。该数据集包括73.6万种6D物体姿态标注和52万张RGB-D图像的9.3亿个可行机器人抓取姿态。通过评估最先进的方法，提供了杂乱环境下的关键挑战点，并验证了数据集作为训练资源的有效性。", "conclusion": "在模拟和现实世界实验中，使用GraspClutter6D数据集训练的抓取网络显著优于使用现有数据集训练的网络。该数据集、工具包和标注工具已公开发布。"}
{"llm_update_time": "20250816", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2503.19530", "html_url": "https://arxiv.org/abs/2503.19530", "title": "VectorFit:自适应奇异向量和偏差向量微调的预训练基础模型", "title_en": "VectorFit : Adaptive Singular & Bias Vector Fine-Tuning of Pre-trained Foundation Models", "authors": "Suhas G Hegde,Shilpy Kaur,Aruna Tiwari", "background": "传统的参数效率训练方法（PEFT）通过并行训练新引入的低秩或稀疏可训练权重来减少可训练参数数量，从而进行微调。然而，这些新引入的权重是从头开始训练的，与完全微调相比，在低预算设置中存在性能差距。本文探讨了如何利用预训练权重（W）中现有的知识，通过自适应训练其奇异向量和偏置来提高微调效率。研究表明，可以利用W的结构和转换特性生成高秩增量权重矩阵ΔW，从而实现与完全微调相媲美的性能。VectorFit方法在比现有最佳PEFT方法少9倍的可训练参数数量下实现了更优的结果。", "innovation": "引入了VectorFit方法，该方法通过自适应训练预训练权重（W）中的奇异向量和偏置，高效利用已有知识，并且通过结构和转换特性生成高秩增量权重矩阵ΔW，相比现有最佳PEFT方法在较少的可训练参数数量下实现了更优的性能结果。VectorFit方法在19个涵盖语言理解和生成、问答、图像分类和图像生成等多种任务的数据集上进行了全面实验，表明相比基础模型，VectorFit在参数效率方面具有优越性。", "conclusion": "VectorFit在参数效率为一大特点的情况下，通过自适应训练奇异向量和偏置，显著提高了微调性能。通过广泛的实验，VectorFit在多个任务上的表现超过基础模型，证明了具有高的参数效率并且性能更优。"}
{"llm_update_time": "20250816", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2504.14493", "html_url": "https://arxiv.org/abs/2504.14493", "title": "FinSage：财务报表问答的多方面RAG系统", "title_en": "FinSage: A Multi-aspect RAG System for Financial Filings Question Answering", "authors": "Xinyu Wang,Jijun Chi,Zhenghan Tai,Tung Sum Thomas Kwok,Muzhi Li,Zhuhong Li,Hailin He,Yuchen Hua,Peng Lu,Suyuchen Wang,Yihong Wu,Jerry Huang,Jingrui Tian,Fengran Mo,Yufei Cui,Ling Zhou", "background": "在实际应用场景中，利用大型语言模型往往需要使用领域特定的数据和工具以遵循复杂的使用规定。在金融行业中，现代企业越来越多地依赖检索增强生成 (RAG) 系统来满足金融文档流程中的复杂合规要求，但现有的解决方案难以处理数据的异构性（例如文本、表格、图表）和监管标准的不断变化，这导致了关键信息提取的准确性受损。", "innovation": "我们提出了FinSage框架，这是一种专为多模态财务文档的合规分析设计的多方面RAG框架，包含三个创新组件：1. 多模态预处理管道，统一多种数据格式并生成摘要级元数据总结；2. 增强有查询扩展 (HyDE) 和元数据感知语义搜索的多路径稀疏密集检索系统；3. 通过直接偏好优化 (DPO) 微调的领域特定重排名模块，以优先考虑合规关键内容。实验结果显示，FinSage在准确度方面超过了最大基线方法24.06%。此外，FinSage已在在线会议中成功部署为财务问答代理，已服务超过1200人，", "conclusion": "FinSage在提高金融表格问答的准确性和实际应用部署方面取得了显著成果，展示了其在复杂合规要求下多模态数据处理的强大力量和实用性。"}
{"llm_update_time": "20250816", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2505.02640", "html_url": "https://arxiv.org/abs/2505.02640", "title": "动态资源约束下具有适应性预算多臂老虎机的物联网", "title_en": "Adaptive Budgeted Multi-Armed Bandits for IoT with Dynamic Resource Constraints", "authors": "Shubham Vaishnav,Praveen Kumar Donta,Sindri Magnússon", "background": "物联网（IoT）系统在必须实时响应并管理波动资源限制（包括能量和带宽）的环境中运行。当前方法在处理随时间变化的操作约束方面常常不足。因此，需要一种新的面向动态操作限制的预算多臂老虎机框架来解决这些问题。", "innovation": "提出了一种新颖的预算多臂老虎机框架，专门针对具有动态操作限制的物联网应用。该模型引入了衰减的违背预算，允许在学习过程早期有限度地违反约束，并逐渐在时间上加强合规性。提出了预算不确定度传播算法（UCB），该算法能够适应性平衡性能优化和与时间变化约束的遵守。", "conclusion": "在无线通信设置中进行的广泛仿真实验表明，该方法提供了比标准在线学习方法更快的适应性和更好的约束满足。这些结果强调了该框架在构建适应性强、资源感知的物联网系统方面的潜力。"}
{"llm_update_time": "20250816", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2504.17493", "html_url": "https://arxiv.org/abs/2504.17493", "title": "目标导向的时间序列预测：基础框架设计", "title_en": "Goal-Oriented Time-Series Forecasting: Foundation Framework Design", "authors": "Luca-Andrei Fechete,Mohamed Sana,Fadhel Ayed,Nicola Piovesan,Wenjie Li,Antonio De Domenico,Tareq Si Salem", "background": "传统的时间序列预测方法通常旨在最小化总体预测误差，但不考虑不同预测范围在下游应用中的不同重要性。这导致了预测结果在某些特定区域可能不够准确，并且可能无法满足特定应用的需求。因此，需要一种新的方法，能够在预测时适应不同的应用需求，而无需重新训练模型。通常的预定义范围方法限制了灵活性和动态调整能力。", "innovation": "本文提出了一种新的训练方法，使预测模型能够在推断时根据具体应用的需求自适应调整预测的重点区域，而无需重新训练。该方法在训练期间将预测空间细分为多个区间，并根据应用需求动态重新加权和聚合这些区间，从而更关注目标范围。这种方法灵活性较高，支持按需调整，不同以往的预定义范围方法，它能够显著提高预测区域内和实时应用任务中的性能。", "conclusion": "实验结果表明，本文提出的方法不仅能在关键区域内提高预测准确性，还能在下游任务中带来可量化的好处，这表明预测建模和决策制定之间的深度融合具有实际应用潜力。"}
{"llm_update_time": "20250816", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2505.03810", "html_url": "https://arxiv.org/abs/2505.03810", "title": "Grouped Sequency-arranged Rotation: 无需训练的旋转变换优化以实现量化", "title_en": "Grouped Sequency-arranged Rotation: Optimizing Rotation Transformation for Quantization for Free", "authors": "Euntae Choi,Sumin Song,Woosang Lim,Sungjoo Yoo", "background": "大语言模型（LLMs）在部署时面临高计算成本的挑战，而现有后训练量化（PTQ）方法在非常低的位宽（如2位）下表现不佳。文章指出，虽然PTQ提供了一种解决方法，但现有的基于旋转的方法在极低位宽下存在性能不足的问题。因此，文章提出了一种无需训练的创新方法来构建改进的旋转矩阵，以克服现有方法的局限性。", "innovation": "文章利用沃尔什-哈达玛变换结合序频排序，相比标准哈达玛矩阵，这种方法可以更有效地聚类相似频率分量，从而减少量化误差，显著提高性能。此外，还提出了一种分组序频排列旋转（GSR）方法，使用块对角矩阵和较小的沃尔什块，可以有效隔离异常值的影响，实现性能与基于优化的方法相当，但无需任何训练。", "conclusion": "文章的方法在推理任务和WikiText-2的困惑度（PPL）得分上展示了稳健的性能，并且即使与现有的学习旋转技术相结合，也能进一步提升结果。"}
{"llm_update_time": "20250816", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2505.13109", "html_url": "https://arxiv.org/abs/2505.13109", "title": "FreeKV: 提升 KV 缓存检索以实现高效的大语言模型推理", "title_en": "FreeKV: Boosting KV Cache Retrieval for Efficient LLM Inference", "authors": "Guangda Liu,Chengwei Li,Zhenyu Ning,Minyi Guo,Jieru Zhao", "background": "大语言模型（LLMs）正因其快速扩展现有的上下文窗口而被广泛部署，以支持更加复杂的应用程序。然而，较长的上下文窗口给现有部署带来了重大挑战，主要是由于随着上下文长度增长，KV缓存的大小也随之成倍增长。虽然目前有几种KV缓存压缩方法被提出，但它们会导致显著的准确率损失。另外，KV检索方法也面临显著的效率瓶颈。因此，解决KV缓存的检索效率问题成为一个亟待解决的问题。", "innovation": "本文提出了FreeKV，一种结合了算法和系统的优化框架，旨在提升KV检索的效率同时保持较高的准确率。FreeKV在算法方面引入了投机性检索技术，它将KV的选择和检索过程移出了关键路径，并通过细粒度的纠正确保准确率。在系统层面，FreeKV利用了CPU和GPU内存之间的混合KV布局以消除数据碎片化的传输，并使用双缓冲流水线检索来进一步提高效率。", "conclusion": "实验结果表明，FreeKV在各种场景和模型中实现了接近无损的准确度，并且相比现有的最先进KV检索方法，其速度提升了最高可达13倍。"}
{"llm_update_time": "20250816", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2504.21706", "html_url": "https://arxiv.org/abs/2504.21706", "title": "视觉转换器在精准农业中的全面综述", "title_en": "Vision Transformers in Precision Agriculture: A Comprehensive Survey", "authors": "Saber Mehdipour,Seyed Abolghasem Mirroshandel,Seyed Amirhossein Tabatabaei", "background": "检测植物疾病是现代农业的关键方面，因为它在保持作物健康和提高整体产量方面发挥着重要作用。传统的做法虽然仍然有价值，但往往依赖于人工检查或传统的机器学习技术，这些都是在可伸缩性和准确性方面存在限制。近年来，视觉转换器（ViTs）作为一种有希望的替代方案出现，它们在处理长距离依赖关系和对视觉任务的可伸缩性方面表现出优势。本文综述了ViTs在精准农业中的应用，涵盖了从自然语言处理（NLP）到计算机视觉的转换，讨论了传统模型（如卷积神经网络CNN）中归纳偏差的概念以及ViTs如何减轻这些偏差。本文还对近年来的相关文献进行了详尽的回顾，重点介绍了关键的方法、数据集和性能指标，并进行了CNNs和ViTs的比较分析，还回顾了混合模型和性能增强方法。文中还讨论了诸如数据需求、计算需求和模型可解释性等技术挑战以及可能的解决方案。最后，本文指出了未来的研究方向和技术进步，这些进展可以进一步支持ViTs在实际农业环境中的集成。", "innovation": "视觉转换器（ViTs）作为一种新兴技术，相比传统的视觉处理方法，如卷积神经网络（CNNs），在处理长距离依赖关系和可伸缩性方面表现出优势。本文通过回顾大量相关文献，提供了一种全面的视角来理解和应用ViTs在精准农业中的潜在优势和应用前景。论文还详细分析了CNNs和ViTs之间的比较，以及如何解决集成视觉转换器在实际应用中面临的技术挑战，如数据需求、计算需求和模型解释力等。", "conclusion": "本文旨在为实践者和研究人员提供一个更深入的理解，即视觉转换器（ViTs）如何准备好改变智能和精准农业。视觉转换器的引入不仅能够提高农业领域的自动化和准确度，还为未来的研究和技术进步提供了新的研究方向。"}
{"llm_update_time": "20250816", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2505.15002", "html_url": "https://arxiv.org/abs/2505.15002", "title": "解开迭代CHAD的奥秘", "title_en": "Unraveling the iterative CHAD", "authors": "Fernando Lucatelli Nunes,Gordon Plotkin,Matthijs Vákár", "background": "CHAD最初被定义为一种基于语义的源到源转换过程，用于计算完全（终止）函数程序的反向模式自动微分。这项工作扩展了CHAD，以涵盖包含部分（潜在非终止）运算、数据依赖条件（例如实数测试）和迭代结构（如while循环）的程序，同时保持CHAD的核心原则，即结构保持语义。", "innovation": "引入了迭代广泛的加标签范畴，实现将迭代整合到依赖类型编程语言中。通过要求基范畴中的迭代提升到加标签范畴中的参数化初始代数，获得了op-纤维的迭代结构，以在总范畴中建模while循环和其他迭代结构，总范畴对应于我们的依赖类型语言中的容器范畴。通过迭代广泛的加标签范畴，将CHAD变换扩展到循环程序，作为某种合适意义上唯一的结构保持函子。并证明了这种扩展变换的正确性，通过源语言的语义范畴的普遍性质，表明微分程序计算原始程序的正确反向模式偏导数。", "conclusion": "本文扩展了CHAD，使其能够处理包含部分运算、数据依赖条件和迭代结构的程序，并通过引入迭代广泛的加标签范畴，对其进行了结构性保持的数学定义和证明，最终建立了扩展变换的正确性，确保了程序微分计算出正确的反向模式偏导数。"}
{"llm_update_time": "20250816", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2505.16332", "html_url": "https://arxiv.org/abs/2505.16332", "title": "量子优化就绪了吗？一种基于绝热量子计算的神经网络压缩方法", "title_en": "Is Quantum Optimization Ready? An Effort Towards Neural Network Compression using Adiabatic Quantum Computing", "authors": "Zhehui Wang,Benjamin Chen Ming Choong,Tian Huang,Daniel Gerlinghoff,Rick Siow Mong Goh,Cheng Liu,Tao Luo", "background": "量子优化是目前最成熟的一种量子计算技术，为解决复杂的组合优化问题提供了有望的技术途径。近年来，如绝热量子计算（AQC）等方法已被应用于各种重要优化问题。在深度学习领域，深度神经网络（DNN）已经发展到巨大的规模，支持新的预测能力。大规模模型的优化对于可持续部署至关重要，但随着模型规模和复杂性的增加，优化变得越来越具有挑战性。虽然量子优化适用于解决复杂问题，但将其应用于DNN优化并不直接，需要经过彻底的重新表述以与商用量子设备兼容。", "innovation": "本文探索了将绝热量子计算（AQC）应用于卷积神经网络的精简-量化的方法。通过重新设计现有启发式方法，将模型压缩问题转换为二次未约束二进制优化（QUBO）问题，并评估商用量子退火装置提供的解决方案空间。研究表明，绝热量子计算（AQC）不仅在时间效率上优于遗传算法和强化学习等经典算法，而且在识别全局最优解方面也表现出色。", "conclusion": "通过重新表述，我们证明AQC能够有效压缩实际的DNN模型。实验表明，绝热量子计算（AQC）不仅在时间效率上优于经典算法，还能更有效地找到全局最优解。"}
{"llm_update_time": "20250816", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.10236", "html_url": "https://arxiv.org/abs/2506.10236", "title": "提示攻击揭示了去训练方法中表面知识去除的现象", "title_en": "Prompt Attacks Reveal Superficial Knowledge Removal in Unlearning Methods", "authors": "Yeonwoo Jang,Shariqah Hossain,Ashwin Sreevatsa,Diogo Cruz", "background": "已有研究表明某些机器去训练方法可能在简单的提示攻击面前失效。研究者通过输出、logit和探针分析系统性地评估了八种去训练技术的有效性，以此来衡量已经声明去训练的知识被恢复的程度。", "innovation": "研究发现，虽然RMU和TAR方法具有稳健的去训练效果，但ELM在特定提示攻击面前仍存在漏洞（例如，在原始提示前面添加 Hindi 填充文本可以使准确率恢复到57.3%）。为了进一步研究，提出了一个公开的评估框架，以帮助评估提示技术能否恢复未训练的知识。", "conclusion": "这些发现挑战了关于去训练有效性的现有假设，并强调了需要能够可靠区分实际知识移除和表面上的输出抑制的评估框架。"}
{"llm_update_time": "20250816", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2505.20469", "html_url": "https://arxiv.org/abs/2505.20469", "title": "CCL-LGS: Contrastive Codebook Learning for 3D Language Gaussian Splatting", "title_en": "CCL-LGS: Contrastive Codebook Learning for 3D Language Gaussian Splatting", "authors": "Lei Tian,Xiaomin Li,Liqian Ma,Hao Yin,Zirui Zheng,Hefei Huang,Taiqing Li,Huchuan Lu,Xu Jia", "background": "近期，3D重建技术和视觉-语言模型的进步显著推动了3D语义理解的发展，这一能力对于机器人技术、自动驾驶以及虚拟/增强现实至关重要。然而，依赖2D先验的方法容易受到诸如遮挡、图像模糊和视角依赖性变化导致的跨视图语义不一致的挑战。这些不一致在投影监督中传播，会劣化3D高斯语义场的质量，并在渲染输出中引入伪影。", "innovation": "本文提出了一种名为CCL-LGS的新框架，通过结合多视角语义线索来实现视图一致的语义监督。首先，利用零初始化追踪器对由SAM生成的2D掩码进行对齐，并可靠地识别其对应类别。接着，使用CLIP提取视图间的鲁棒语义编码。最后，通过强制同一类内紧凑性和不同类间的区分性，对比码本学习（CCL）模块提取有区别的语义特征。与之前直接将CLIP应用于不完美的掩码的方法不同，我们的框架明确地解决了语义冲突，同时保持了类别可区分性。", "conclusion": "广泛的实验结果表明，CCL-LGS方法优于之前的方法。更多项目信息请访问：this https URL"}
{"llm_update_time": "20250816", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2505.18889", "html_url": "https://arxiv.org/abs/2505.18889", "title": "大型语言模型的安全问题：一项综述", "title_en": "Security Concerns for Large Language Models: A Survey", "authors": "Miles Q. Li,Benjamin C. M. Fung", "background": "大型语言模型（LLMs）如ChatGPT及其竞争对手在自然语言处理领域引发了一场革命，但它们的功能也带来了新的安全漏洞。本文对这些新兴的安全担忧进行了全面综述，将威胁分为几个关键领域：提示注入和越狱；对抗性攻击，包括输入扰动和数据污染；恶意行为者滥用LLMs生成假信息、钓鱼邮件和恶意软件；以及自主LLM代理固有的令人担忧的风险。最近，这一问题越来越受到关注，研究主要集中在探索目标对齐不当、新兴的欺骗手段、自我保护本能以及LLMs有可能制定和追求隐藏的、对齐不当的行动目标，这种行为被称为巧谋，甚至可能在经过安全培训后仍然存在。", "innovation": "本文总结了2022年至2025年期间学术界和工业界的最新研究，阐明了每一类威胁的具体实例，并分析了提出的防御措施及其局限性，同时指出了保护基于LLM的应用程序所面临的开放挑战。这一研究为LLMs的安全性和收益性提供了一套全面的视角，并强调了需要发展强大的多层次安全策略来确保LLMs的安全性与可靠性。", "conclusion": "本文强调了推进强大的多层次安全策略的重要性，以确保大型语言模型的安全性和益处。"}
{"llm_update_time": "20250816", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.01701", "html_url": "https://arxiv.org/abs/2506.01701", "title": "数据最大化下的数据修剪", "title_en": "Data Pruning by Information Maximization", "authors": "Haoru Tan,Sitong Wu,Wei Huang,Shizhen Zhao,Xiaojuan Qi", "background": "在处理大规模数据集时，如何有效地减少数据量但又不损失关键信息是一个挑战。本文旨在通过对选定样本进行最大信息量的数据修剪（也称为核心集选择），来解决这个问题。现有的数据修剪方法往往在减少数据冗余方面效率较低，并且难以保持必要的信息量。", "innovation": "InfoMax是一种新颖的数据修剪方法，通过最大化所选样本的信息内容并最小化冗余，增强了整体的核心集信息含量。该方法通过重要性评分衡量每个样本的信息含量，并利用样本之间的相似性量化冗余。作者将核心集选择问题形式化为一个离散二次规划任务，优化目标是信息总量，即样品贡献的总和减去核心集内相似样品引入的冗余。为了确保实际规模下的可扩展性，提出了一种高效的基于梯度的求解器，并应用稀疏化技术和数据集分区策略。", "conclusion": "广泛的实验结果表明，InfoMax在包括图像分类、视觉语言预训练和大型语言模型指令调优等多样化数据修剪任务中表现出优越的性能。该方法能够无缝扩展处理百万级的数据集。代码可以在该网址下载：this https URL。"}
{"llm_update_time": "20250816", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.11170", "html_url": "https://arxiv.org/abs/2506.11170", "title": "PromptTSS：基于提示的方法进行交互的多粒度时间序列分割", "title_en": "PromptTSS: A Prompting-Based Approach for Interactive Multi-Granularity Time Series Segmentation", "authors": "Ching Chang,Ming-Chih Lo,Wen-Chih Peng,Tien-Fu Chen", "background": "多变量时间序列数据在制造和可穿戴技术等领域被收集，这些数据可以展示从粗略系统行为到精细事件的多级状态。对这些不同粒度级别的状态进行有效分割和整合对于预测维护和性能优化等任务至关重要。现有时间序列分割方法面临两大挑战：（1）难以在统一模型中处理多粒度级别；（2）在动态环境中对新的演变模式适应能力有限。", "innovation": "提出了PromptTSS框架，这是一种具备多粒度状态的时间序列分割新方法，采用统一模型并通过提示机制利用标签和边界信息指导分割，以捕捉粗细粒度模式并动态适应未见模式。研究表明，PromptTSS在细粒度分割、粗细粒度分割和迁移学习的准确性上分别提高24.49%、17.88%和最高599.24%，显示了其对层级状态和时间序列动态演变的适应性。", "conclusion": "实验结果表明，PromptTSS在多层次时间序列分割、单一层次分割和迁移学习方面均表现出显著优势，验证了其对层级状态和时间序列动态演变的高度适应性。"}
{"llm_update_time": "20250816", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.19343", "html_url": "https://arxiv.org/abs/2506.19343", "title": "Discrepancy-Aware Graph Mask Auto-Encoder", "title_en": "Discrepancy-Aware Graph Mask Auto-Encoder", "authors": "Ziyu Zheng,Yaming Yang,Ziyu Guan,Wei Zhao,Weigang Lu", "background": "目前，Masked Graph Auto-Encoder 在图表示学习中表现出优越的性能。现有方法通常依赖节点环境信息来恢复被掩蔽的信息，但在处理具有异质性的图（连接的节点可能不相似）时表现不佳，因为这些方法仅关注捕捉邻域信息而忽视了节点之间差异信息，导致节点表示不可区分。", "innovation": "本文提出了一种名为 Discrepancy-Aware Graph Mask Auto-Encoder (DGMAE) 的新型图掩码自动编码器，通过在掩码过程中重建相邻节点的差异信息，从而获得更具区分性的节点表示。在17个广泛使用的基准数据集上进行了大量实验，证明了DGMAE在节点分类、节点聚类和图分类等三大图分析任务中的显著优越性。", "conclusion": "DGMAE 有效保持了节点在低维度空间中的差异性，并在三种图分析任务中显著超越了现有的图自监督学习方法，展示了其显著的优势。"}
{"llm_update_time": "20250816", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.11049", "html_url": "https://arxiv.org/abs/2506.11049", "title": "15,500秒：使用EfficientNet和轻量级微调进行UAV分类", "title_en": "15,500 Seconds: Lean UAV Classification Using EfficientNet and Lightweight Fine-Tuning", "authors": "Andrew P. Berg,Qian Zhang,Mia Y. Wang", "background": "随着无人机（UAV）在消费和国防应用中的日益普及，对特定模态的可靠分类系统的需求变得越来越迫切。本论文针对无人机音频分类中数据稀缺的问题，通过集成预训练深度学习模型、参数高效微调（PEFT）策略和目标数据增强技术，扩展了先前的工作。作者利用包含31种不同无人机类型、3,100段音频片段（共计15,500秒）的自定义数据集，评估了基于变压器和卷积神经网络（CNN）架构在不同微调配置下的性能。实验采用了五折交叉验证，评估了准确率、训练效率和鲁棒性。实验结果显示，全量微调EfficientNet-B0模型并通过三种增强提高了95.95%的验证准确率，超出了一种自定义CNN和基于变压器的模型（如AST）。这项研究指出，结合轻量级架构、PEFT和精心挑选的增强技术是有效的方法，用于在数据稀缺条件下进行无人机音频分类。", "innovation": "本论文的核心创新在于，通过集成预训练模型、参数高效微调策略和精心数据增强方法，克服了无人机音频分类中的数据稀缺问题，从而有效提高了模型的准确率和鲁棒性。具体来说，作者采用的EfficientNet-B0模型在多项增强下达到了最佳的效果，优于其他基于CNN和变压器的方法。", "conclusion": "研究结果表明，结合轻量级架构与PEFT和精心选择的增广技术为在一数据稀缺场景下的UAV音频分类提供了一个有效策略。未来的研究将扩展此框架到使用视觉和雷达遥测的多模态UAV分类上。"}
{"llm_update_time": "20250816", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.19794", "html_url": "https://arxiv.org/abs/2506.19794", "title": "开源大语言模型在数据分析中为何挣扎？一项系统性的实证研究", "title_en": "Why Do Open-Source LLMs Struggle with Data Analysis? A Systematic Empirical Study", "authors": "Yuqi Zhu,Yi Zhong,Jintian Zhang,Ziheng Zhang,Shuofei Qiao,Yujie Luo,Lun Du,Da Zheng,Ningyu Zhang,Huajun Chen", "background": "大型语言模型（LLMs）在自动化数据分析任务方面具有潜力，但开源模型在这些需要大量推理的任务中面临着显著的限制。本文探讨了增强开源LLMs的数据分析能力的策略，通过收集多样性的种子数据集，评估模型在数据理解、代码生成和战略规划三个核心维度上的表现，揭示了战略规划质量、交互设计和任务复杂度以及数据质量对模型性能的影响", "innovation": "开发了一种数据合成方法，显著提高了开源LLMs在数据分析中的推理能力，强调战略规划质量为主要因素，交互设计和任务复杂度对推理有显著影响，而高质量数据比多样性更能影响性能优化", "conclusion": "研究表明战略规划质量是决定模型性能的主要因素，交互设计和任务复杂度显著影响推理能力，高质量数据比多样性对实现最佳性能更有影响。通过使用这些见解开发的数据合成方法，开源LLMs的分析推理能力得到了显著提升"}
{"llm_update_time": "20250816", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.06639", "html_url": "https://arxiv.org/abs/2507.06639", "title": "EXAONE Path 2.0：具有端到端监督的病理基础模型", "title_en": "EXAONE Path 2.0: Pathology Foundation Model with End-to-End Supervision", "authors": "Myeongjang Pyeon,Janghyeon Lee,Minsoo Lee,Juseung Yun,Hwanil Choi,Jonghyun Kim,Jiwon Kim,Yi Hu,Jongseong Jang,Soonyoung Lee", "background": "在数字病理学中，全视图图像（WSIs）由于其吉瓦像素的规模往往难以处理，因此大多数方法通过自我监督学习（SSL）训练补丁编码器，然后通过多次实例学习（MIL）或切片编码器进行补丁级别嵌入的聚合来处理下游任务。然而，补丁级别的SSL可能忽略了诸如突变状态和分子特征等对生物标志物预测至关重要的复杂领域特定特征，因为SSL方法依赖于仅适用于自然图像领域的基本增强，并且SSL方法的数据效率低于完全监督的方法，需要大量的计算资源和大量数据集才能实现竞争力。", "innovation": "我们介绍了EXAONE Path 2.0，这是一种在切片级别直接监督下学习补丁级别的表示的病理学基础模型。仅使用37k张全视图图像进行训练，EXAONE Path 2.0在10个生物标志物预测任务中达到了最先进的平均性能，展示了显著的数据效率。", "conclusion": "现有的大部分方法依赖于自我监督学习（SSL）训练补丁编码器，然后通过多次实例学习（MIL）或切片编码器处理全视图图像（WSIs）的下游任务，这可能导致遗漏重要的领域特定特征。与完全监督方法相比，SSL方法的数据效率较低，需要更多的计算资源和大量数据集。EXAONE Path 2.0采用切片级别的直接监督方式，在有限的数据集上取得了出色的表现，展示了强大的数据效率。"}
{"llm_update_time": "20250816", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.01006", "html_url": "https://arxiv.org/abs/2507.01006", "title": "GLM-4.1V-Thinking和GLM-4.5V：通过可扩展的强化学习实现多模态通用推理", "title_en": "GLM-4.1V-Thinking and GLM-4.5V: Towards Versatile Multimodal Reasoning with Scalable Reinforcement Learning", "authors": "GLM-V Team:Wenyi Hong,Wenmeng Yu,Xiaotao Gu,Guo Wang,Guobing Gan,Haomiao Tang,Jiale Cheng,Ji Qi,Junhui Ji,Lihang Pan,Shuaiqi Duan,Weihan Wang,Yan Wang,Yean Cheng,Zehai He,Zhe Su,Zhen Yang,Ziyang Pan,Aohan Zeng,Baoxu Wang,Bin Chen,Boyan Shi,Changyu Pang,Chenhui Zhang,Da Yin,Fan Yang,Guoqing Chen,Jiazheng Xu,Jiale Zhu,Jiali Chen,Jing Chen,Jinhao Chen,Jinghao Lin,Jinjiang Wang,Junjie Chen,Leqi Lei,Letian Gong,Leyi Pan,Mingdao Liu,Mingde Xu,Mingzhi Zhang,Qinkai Zheng,Sheng Yang,Shi Zhong,Shiyu Huang,Shuyuan Zhao,Siyan Xue,Shangqin Tu,Shengbiao Meng,Tianshu Zhang,Tianwei Luo,Tianxiang Hao,Tianyu Tong,Wenkai Li,Wei Jia,Xiao Liu,Xiaohan Zhang,Xin Lyu,Xinyue Fan,Xuancheng Huang,Yanling Wang,Yadong Xue,Yanfeng Wang,Yanzi Wang,Yifan An,Yifan Du,Yiming Shi,Yiheng Huang,Yilin Niu,Yuan Wang,Yuanchang Yue,Yuchen Li,Yutao Zhang,Yuting Wang,Yu Wang,Yuxuan Zhang,Zhao Xue,Zhenyu Hou,Zhengxiao Du,Zihan Wang,Peng Zhang,Debing Liu,Bin Xu,Juanzi Li,Minlie Huang,Yuxiao Dong,Jie Tang", "background": "本文介绍了GLM-4.1V-Thinking和GLM-4.5V，这两种视觉语言模型（VLMs）旨在推动通用多模态理解与推理能力，并分享了在基于推理的训练框架开发中的关键发现。通过大规模预训练建立了强大的视觉基础模型，为最终性能设定了上限。在此基础上，提出了强化学习与课程采样（RLCS），以最大化模型潜力，实现跨广泛任务的全方位能力提升，包括STEM问题解决、视频理解、内容识别、编程、语义匹配、GUI基于代理和长文档解析。", "innovation": "开发了基于大规模预训练的视觉基础模型和强化学习与课程采样（RLCS）的训练框架，这一框架能够最大化模型的潜力，适用于多种任务，包括STEM问题解决、视频理解、内容识别、编程、语义匹配、GUI基于代理和长文档解析等。", "conclusion": "GLM-4.5V在42个公开基准测试中展现出近所有任务上的先进性能，相较于同类开源模型表现出竞争力，甚至在编程和GUI代理等挑战性任务上超过了闭源模型Gemini-2.5-Flash。而较小的GLM-4.1V-9B-Thinking也在29个基准测试中表现出色，竞争力更胜于庞大的Qwen2.5-VL-72B。文章已开源，相关代码、模型和更多信息可通过官方网站获取。"}
{"llm_update_time": "20250816", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.10778", "html_url": "https://arxiv.org/abs/2507.10778", "title": "基于LLM代理的仓储空间问题回答", "title_en": "Warehouse Spatial Question Answering with LLM Agent", "authors": "Hsiang-Wei Huang,Jen-Hao Cheng,Kuang-Ming Chen,Cheng-Yen Yang,Bahaa Alattar,Yi-Ru Lin,Pyongkun Kim,Sangwon Kim,Kwangju Kim,Chung-I Huang,Jenq-Neng Hwang", "background": "现有的多模态大规模语言模型（MLLMs）在空间理解方面存在挑战。以往的方法依赖大规模MLLM微调来提升其空间理解能力。这项研究探讨了一种数据高效的方法，提出了一种具有强大和先进空间推理能力的LLM代理系统，能够在复杂室内仓库场景中解决空间问答难题。", "innovation": "提出了一种数据高效的方法，构建了一种具有强大空间推理能力的LLM代理系统，该系统能够通过结合空间推理工具和API工具的交互来回答复杂的空间问题。在2025 AI City Challenge Physical AI Spatial Intelligence Warehouse数据集上的广泛评估表明，该系统在物体检索、计数和距离估算任务中取得了高准确性和效率。", "conclusion": "该系统在复杂室内仓库中的空间问题回答任务中表现出了高准确性和效率，通过结合空间推理工具和API工具的交互，能够有效解决复杂的空间问答难题，并且代码已经开放。"}
{"llm_update_time": "20250816", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.10904", "html_url": "https://arxiv.org/abs/2507.10904", "title": "难易分离数据的类别比例核心样本选择", "title_en": "Class-Proportional Coreset Selection for Difficulty-Separable Data", "authors": "Elisa Tsai,Haizhong Zheng,Atul Prakash", "background": "高质量的训练数据对于构建可靠高效的机器学习系统是至关重要的。一种名为一-shot核心集选择的方法通过修剪数据集来提高模型性能，通常依赖于基于训练动态的数据难度得分，但大多数现有方法假设数据难度在各类间是均匀的，忽略了不同类间存在的差异。", "innovation": "本文通过提出类别难度分离性假设，引入了类别难度分离系数（CDSC）作为量化指标，并针对这一假设提出了类别比例的核心样本选择策略，该策略在多个数据集上表现出更优的性能。尤其是，在数据难度存在类别间差异且截断率高的情况下，所提出的类别比例策略相较于不区分类别的基线方法表现出更强的稳健性和泛化能力。", "conclusion": "实验结果表明，明确建模类别难度分离性能够导致更有效的、稳健的和泛化能力更强的数据修剪策略，特别是在高风险场景下。在CTU-13数据集上，采用类别比例变体的覆盖率中心核心集选择方法（CCS-CP）在极端99%的裁剪率下，准确率、精确率和召回率分别下降2.58%、0.49%和0.19%，相比之下，不区分类别的基线方法性能下降更为显著。"}
{"llm_update_time": "20250816", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.22369", "html_url": "https://arxiv.org/abs/2507.22369", "title": "探索视觉问答（VQA）在教室活动监控中的应用", "title_en": "Exploring the Application of Visual Question Answering (VQA) for Classroom Activity Monitoring", "authors": "Sinh Trong Vu,Hieu Trung Pham,Dung Manh Nguyen,Hieu Minh Hoang,Nhu Hoang Le,Thu Ha Pham,Tai Tan Mai", "background": "课堂行为监控对于教育研究至关重要，对提高学生参与度和学习效果具有重要意义。近期，视觉问答（VQA）模型的进步为从视频记录中自动分析复杂课堂互动提供了有希望的工具。", "innovation": "本文调查了几种最先进的开源VQA模型（LLaMA2、LLaMA3、QWEN3和NVILA）在课堂行为分析中的适用性，并介绍了从越南银行学院的真实世界课堂视频记录中得出的BAV-Classroom-VQA数据集，以促进严格的评估，实验结果表明所有模型在回答行为相关的视觉问题时都取得了令人鼓舞的性能水平。", "conclusion": "本文的数据收集方法、标注和所选VQA模型的表现基准测试证明了这些模型在课堂分析和干预系统中的潜力。"}
{"llm_update_time": "20250816", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.08162", "html_url": "https://arxiv.org/abs/2507.08162", "title": "AmpLyze: 一种用于预测溶血浓度的深度学习模型", "title_en": "AmpLyze: A Deep Learning Model for Predicting the Hemolytic Concentration", "authors": "Peng Qiu,Hanqi Feng,Meng-Chun Zhang,Barnabas Poczos", "background": "红细胞溶解（HC50）是抗菌肽（AMP）治疗的主要安全屏障，但现有的模型只能给出“毒性”或“非毒性”的简单判断。 AmpLyze 通过仅从序列预测实际的 HC50 值并解释驱动毒性的残基，解决了这一缺口。该模型通过将残基级别的 ProtT5/ESM2 插入与序列级别的描述符相结合，并使用交叉注意模块对齐，在双重局部和全局分支之间训练，使用对试剂噪声具有鲁棒性的对数双曲线余弦损失。AmpLyze 最优模型达到了 0.756 的皮尔逊相关系数（PCC）和 0.987 的均方误差（MSE），超越了经典的回归模型和最新的技术状态。消除实验证明两个分支都是必不可少的，交叉注意在此基础上分别提高了 1% 的 PCC 和 3% 的 MSE。梯度期望归因揭示了已知的毒性热点，并提出了更安全的替代方案。通过将溶血评估转变为定量的、基于序列的和可解释的预测，AmpLyze 促进了AMP设计，并提供了一个早期毒性筛查的实用工具。", "innovation": "提出了 AmpLyze 模型，这是一种深度学习模型，用于从抗菌肽序列预测红细胞溶解的临界浓度（HC50），并解释毒性驱动残基。它结合了残基级别的 ProtT5/ESM2 嵌入与序列级别的描述符，并通过交叉注意机制对齐，采用对试剂噪声具有鲁棒性的对数双曲线余弦损失进行训练，最终性能优于经典的回归模型和最先进的技术状态。此外，通过梯度期望归因，揭示了已知的毒性热点，并提出更安全的替代方案。", "conclusion": "通过将红细胞溶解评估转化为定量、基于序列的和可解释的预测，AmpLyze 促进了抗菌肽（AMP）的设计，并提供了一个实用工具，用于早期毒性筛查。"}
{"llm_update_time": "20250816", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.14189", "html_url": "https://arxiv.org/abs/2507.14189", "title": "DeepWriter：基于离线知识库的事实依据多模态写作助手", "title_en": "DeepWriter: A Fact-Grounded Multimodal Writing Assistant Based On Offline Knowledge Base", "authors": "Song Mao,Lejun Cheng,Pinlong Cai,Guohang Yan,Ding Wang,Botian Shi", "background": "大型语言模型（LLMs）在各种应用中展现了非凡的能力。然而，它们在金融、医学和法律等专业领域作为写作助手使用时，往往因缺乏深度专业知识和虚构倾向而受限。现有的解决方案，如检索增强生成（RAG），在多步检索过程中可能会出现不一致的情况，而基于在线搜索的方法则由于不可靠的网页内容往往会降低质量。", "innovation": "为了应对这些挑战，我们提出了一个可定制、多模态、长篇写作助手DeepWriter，它基于一个精曲离线知识库。DeepWriter通过一个新颖的流程进行工作，该流程包括任务分解、大纲生成、多模态检索以及逐段合成，并能够反省。通过从结构化语料库中深度挖掘信息并结合文本和视觉元素，DeepWriter能够生成连贯、事实依据的高质量文档。此外，还提出了一种层次化的知识表示方法，以提高检索效率和准确性。", "conclusion": "我们的实验结果显示，DeepWriter生成的金融报告质量高且可验证，其事实准确性超越了现有基线方法，生成的内容质量也超过了现有的baseline。"}
{"llm_update_time": "20250816", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.10535", "html_url": "https://arxiv.org/abs/2507.10535", "title": "CodeJudgeBench：评估编程任务中LLM作为裁判的标准", "title_en": "CodeJudgeBench: Benchmarking LLM-as-a-Judge for Coding Tasks", "authors": "Hongchao Jiang,Yiming Chen,Yushi Cao,Hung-yi Lee,Robby T. Tan", "background": "大型语言模型（LLMs）在各种编程任务中的表现显著超过了现有技术。除了直接回答用户查询，LLMs还可以作为裁判，评估和比较其他模型生成响应的质量。这种评估能力对于不同LLMs的基准测试和通过响应排名来提高响应质量至关重要。尽管LLM作为裁判的范式正在逐渐被采纳，但其在编程场景中的有效性仍然缺乏专属基准进行充分探索。为了填补这一空白，本文引入了CodeJudgeBench，这是专门设计用于评估LLM作为裁判模式在三种关键编程任务（代码生成、代码修复和单元测试生成）上的性能基准。", "innovation": "本文通过CodeJudgeBench提出了一个专门设计的基准，用于评估LLM作为裁判模式在编程任务中的性能。研究发现，近年来的思考模型在精心设计的任务中显著优于非思考模型，即使相对较小的思考模型如Qwen3-8B，也能在更大规模的专为训练的LLM作为裁判模型中占上风。此外，研究还揭示了LLM作为裁判模式在编程任务中的一些不足之处，如在排序判断任务中响应顺序的变化会严重影响准确率，以及在评估不同LLM生成的代码和单元测试时表现出性能差异性。此外，研究还探讨了最佳提示策略，发现使用成对比较优于单一评分判断，同时保留完整未处理的LLM响应中的注释和推理也能提高裁判性能。", "conclusion": "本文通过CodeJudgeBench进行了全面基准测试，发现近年来的思考模型在精心设计的编程任务中显著优于非思考模型。即使相对较小的思考模型也能在更大规模的专为训练的LLM作为裁判模型中占上风。然而，所有模型在任务判断中仍然表现出显著的随机性。对于排序任务，改变响应呈现顺序将极大地影响准确性。当判断不同LLM生成的代码和单元测试时，LLM作为裁判模型也表现出性能差异。这对LLM作为裁判模式在编程场景中的可靠性和一致性提出了质疑。此外，研究还发现最佳提示策略对于LLM作为裁判模式至关重要，使用成对比较优于单一评分判断，同时保留未处理的完整LLM响应中的注释和推理也会提高裁判性能。"}
{"llm_update_time": "20250816", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.04549", "html_url": "https://arxiv.org/abs/2508.04549", "title": "MSC: 一条有关海洋野生物种视频数据集，带有定位标注和片段级标注", "title_en": "MSC: A Marine Wildlife Video Dataset with Grounded Segmentation and Clip-Level Captioning", "authors": "Quang-Trung Truong,Yuk-Kwan Wong,Vo Hoang Kim Tuyen Dang,Rinaldi Gotama,Duc Thanh Nguyen,Sai-Kit Yeung", "background": "海洋视频的视觉理解面临着显著挑战，包括海洋物体及其环境的动态变化，摄像机运动和复杂的海底场景。现有的视频字幕数据集通常专注于通用或人类中心的领域，无法很好地适应海洋环境的复杂性，也难以洞察海洋生物。现有的数据集和方法通常无法有效反映海洋环境的动态特性及其对视觉理解的影响。", "innovation": "本文提出了一种两阶段的海洋物体导向视频字幕流水线，并构建了一个全面的视频理解基准，该基准利用了视频、文本和分割掩膜三者之间的关系，来促进视觉定位和字幕生成，显著提升了海洋视频的理解和分析能力。该研究强调了视频分割技术在检测场景转换中的显著物体过渡方面的有效性，这极大地丰富了字幕内容的语义。", "conclusion": "本文通过提出MSC数据集，为其构建一种两阶段视频字幕流水线，以及一个利用视频、文本和分割掩膜三者关系进行视觉定位和字幕生成的全面基准，在海洋视频理解、分析和生成方面取得了重要进展。"}
{"llm_update_time": "20250816", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.19712", "html_url": "https://arxiv.org/abs/2507.19712", "title": "Oranits：使用元算法和深度强化学习在Open RAN基础上的智能交通系统中的任务分配和任务卸载", "title_en": "Oranits: Mission Assignment and Task Offloading in Open RAN-based ITS using Metaheuristic and Deep Reinforcement Learning", "authors": "Ngoc Hung Nguyen,Nguyen Van Thieu,Quang-Trung Luu,Anh Tuan Nguyen,Senura Wanasekara,Nguyen Cong Luong,Fatemeh Kavehmadavani,Van-Dinh Nguyen", "background": "现有的研究往往忽略了任务之间复杂的相互依赖关系和将任务卸载到边缘服务器的成本，导致决策不准确。在基于Open RAN的智能交通系统（ITS）中，自动驾驶车辆利用移动边缘计算进行高效的处理。", "innovation": "提出了一种名为Oranits的新系统模型，该模型明确考虑任务相互依赖关系和卸载成本，并通过车辆合作优化性能。提出了一种两步优化方法，首先引入一种基于混沌高斯的全局ARO的元启发式进化计算算法（CGG-ARO）作为单一时间槽优化的基础；其次，设计了一种多代理双深Q网络（MA-DDQN）增强奖励深度强化学习框架，结合多代理协调和多动作选择机制，显著减少了任务分配时间并提高了适应性。", "conclusion": "CGG-ARO在完成任务数量和总体收益方面分别提高了约7.1%和7.7%，而MA-DDQN在任务完成数量和总体收益方面分别实现了11.0%和12.5%的更大改进。这些结果突显了Oranits在动态ITS环境中实现更快、更适应和更高效的任务处理方面的有效性。"}
{"llm_update_time": "20250816", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.03682", "html_url": "https://arxiv.org/abs/2508.03682", "title": "自提问语言模型", "title_en": "Self-Questioning Language Models", "authors": "Lili Chen,Mihir Prabhudesai,Katerina Fragkiadaki,Hao Liu,Deepak Pathak", "background": "当前的大型语言模型普遍依赖外部数据进行训练和优化。本文研究了一种新的方法，即通过让预训练的语言模型自动生成问题和答案来提升其推理能力，而无需使用外部数据。作者提出了一个自提问语言模型(SQLM)框架，通过让模型在给定主题的情况下生成自己的问题，进行自我改进，旨在探索语言模型是否能在没有外部数据的情况下自我提升其问题解决能力。", "innovation": "该研究创新性地提出了一种名为Self-Questioning Language Models (SQLM)的自提问语言模型框架。在这个框架中，一个模型充当提议者（proposer），根据给定的主题生成问题，而另一个模型作为解答者（solver），尝试回答问题。两者都是通过强化学习进行训练。提议者获得的奖励基于问题的难度适中程度，而去不真实答案的情况下，解答者获得的奖励则由多数投票决定。对于编程问题，提议者可以生成单元测试用例来验证问题的准确性。这种框架在三个不同的基准测试（三位数乘法、OMEGA基准的代数问题、Codeforces的编程问题）上进行了研究。", "conclusion": "通过不断生成更有趣的问题并尝试解决它们，语言模型能够在没有任何精心策划训练数据集的情况下，提高其在下游任务中的表现。这种方法提供了一种新的思路，即通过自我提问和自我解答来提升语言模型的问题解决能力。"}
{"llm_update_time": "20250816", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.05612", "html_url": "https://arxiv.org/abs/2508.05612", "title": "Shuffle-R1: 通过数据为中心的动态重新排序提高多模态大型语言模型的高效RL框架", "title_en": "Shuffle-R1: Efficient RL framework for Multimodal Large Language Models via Data-centric Dynamic Shuffle", "authors": "Linghao Zhu,Yiran Guan,Dingkang Liang,Jianzhong Ju,Zhenbo Luo,Bin Qin,Jian Luan,Yuliang Liu,Xiang Bai", "background": "强化学习（RL）已经成为通过训练后增强多模态大型语言模型推理能力的有效后训练范式。但是，现有的RL管道由于两个未充分探索的问题导致训练效率低下：优势坍缩，即批次中的大部分优势接近零；以及采样沉默，即随着时间的推移，贡献非零梯度的采样比例减少。这些问题导致梯度更新不足，并阻碍了长期的学习效率。", "innovation": "为了应对这些问题，本文提出了Shuffle-R1，一个简单而原则性的框架，通过动态重构轨迹采样和批次组成来提升RL微调效率。Shuffle-R1引入了（1）成对轨迹采样，这是一种选择具有大优势的高对比轨迹，从而提高梯度信号质量的技术；（2）优势导向的轨迹重排序，这是一种通过有信息的批量重排序增加有价值的采样曝光的技术。", "conclusion": "实验结果显示，在多个推理基准上，我们的框架在几乎无额外开销的情况下，持续优于强大的RL基线。这些结果突显了数据为中心的适应性对提高MLLM的RL训练效率的重要性。"}
{"llm_update_time": "20250816", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.05294", "html_url": "https://arxiv.org/abs/2508.05294", "title": "面向具身代理型人工智能：LLM-和VLM-驱动的机器人自主与交互的综述与分类", "title_en": "Towards Embodied Agentic AI: Review and Classification of LLM- and VLM-Driven Robot Autonomy and Interaction", "authors": "Sahar Salimpour,Lei Fu,Farhad Keramat,Leonardo Militano,Giovanni Toffetti,Harry Edelman,Jorge Peña Queralta", "background": "随着大型语言模型（LLMs）和视听说模型（VLMs）的发展，使得机器人自主和人机接口领域出现了新的方法。尤其是，视听说-动作模型（VLAs）或大型行为模型（LBMs）正在提高机器人的灵活性和能力。本文综述了向代理应用和架构的过渡工作，包括初探索GPT样式的接口工具，以及更复杂的系统，其中AI代理是协调者、计划者、感知演员或通用接口。这类代理架构允许机器人处理自然语言指令，调用API，规划任务序列，或辅助操作和诊断。作为快速发展的领域的反映，本文还强调并包括了社区驱动的项目、ROS包和工业框架，展示了新兴趋势。", "innovation": "本文提出了一种模型集成方法的分类法，并进行了不同解决方案中存在的代理角色的比较分析。", "conclusion": "本文综述了基于大规模语言模型和视听说模型的机器人自主与交互的代理型应用和架构的发展，提出了一种分类方法，并分析了代理在不同解决方案中的角色。"}
{"llm_update_time": "20250816", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.04586", "html_url": "https://arxiv.org/abs/2508.04586", "title": "当前AI会议模式不可持续！集中式AI会议的危机诊断", "title_en": "Position: The Current AI Conference Model is Unsustainable! Diagnosing the Crisis of Centralized AI Conference", "authors": "Nuo Chen,Moming Duan,Andre Huikai Lin,Qian Wang,Jiaying Wu,Bingsheng He", "background": "人工智能（AI）会议对促进研究、共享知识和培养学术共同体至关重要。然而，这些会议的迅速扩张让集中的会议模式变得越来越不可持续。本论文通过数据分析诊断了一种结构性的危机，威胁到了科学传播、公平性和社区福祉的基础目标。本研究识别了四个关键领域：（1）科学上，每名作者的发表率在过去十年中翻了一番多，每年超过4.5篇论文；（2）环境上，一个会议的碳足迹超过了其东道城市每日的排放量；（3）心理上，71%的在线社区讨论反映出负面情绪，35%涉及心理健康问题；（4）后勤上，像NeurIPS 2024这样的顶级会议的参会人数已经开始超过了会场容量。这些压力指向了一个与核心使命不一致的系统。", "innovation": "本研究提出了社区协作会议（CFC）模式，这种模式将同行评审、展示和社交活动分离为全球协调本地组织的组件，提供了一种更可持续、更包容和更具弹性的AI研究未来路径。", "conclusion": "本研究指出，当前的AI会议模式与核心使命不一致，提出了CFC模型作为一种新的会议方式，旨在提高会议的可持续性、包容性和韧性。"}
{"llm_update_time": "20250816", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.06259", "html_url": "https://arxiv.org/abs/2508.06259", "title": "SIFThinker：具备空间感知的图像焦点以实现视觉推理", "title_en": "SIFThinker: Spatially-Aware Image Focus for Visual Reasoning", "authors": "Zhangquan Chen,Ruihui Zhao,Chuwei Luo,Mingze Sun,Xinlei Yu,Yangyang Kang,Ruqi Huang", "background": "当前的多模态大语言模型（MLLMs）在复杂的视觉任务（如空间理解和精细感知）中仍然面临重大挑战。先前的方法尝试引入视觉推理，但未能利用空间线索进行注意力修正，从而逐步聚焦于与提示相关的区域。", "innovation": "本文提出了SIFThinker，一种具备空间感知的‘以图辅助思考’框架，模仿人类的视觉感知。具体来说，SIFThinker通过交错使用深度增强的边界框和自然语言来实现注意力修正和图像区域聚焦。文中引入了反向扩展-正向推理策略，以促进生成交错的图像-文本链条的思维过程，从而构建了SIF-50K数据集。此外，提出了结合深度信息的视觉锚定GRPO-SIF训练范式，教导模型动态地修正和聚焦于与提示相关的信息区域。", "conclusion": "广泛实验表明，SIFThinker在空间理解和精细视觉感知方面优于现有最先进的方法，同时也保持了较强的泛化能力，突显了方法的有效性。"}
{"llm_update_time": "20250816", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.06800", "html_url": "https://arxiv.org/abs/2508.06800", "title": "Hardness-Aware Dynamic Curriculum Learning for Robust Multimodal Emotion Recognition with Missing Modalities", "title_en": "Hardness-Aware Dynamic Curriculum Learning for Robust Multimodal Emotion Recognition with Missing Modalities", "authors": "Rui Liu,Haolin Zuo,Zheng Lian,Hongyu Yuan,Qi Fan", "background": "近年来，缺失模态的识别在多模态情绪识别（MER）中成为一个关键的研究方向。传统的解决办法通常通过缺失模态重构来处理这个问题，然而这些方法无法考虑到不同样本在重构难易度上的差异，从而限制了模型对难样本的处理能力。", "innovation": "本文提出了一种新颖的Hardness-Aware Dynamic Curriculum Learning框架（HARDY-MER），该框架在两个关键阶段工作：首先估计每个样本的难度水平，然后在训练过程中有策略地强调难样本，以增强模型在这些具有挑战性实例上的性能。该框架引入了多视图难度评估机制，该机制通过直接难度（模态重构误差）和间接难度（跨模态互信息）来量化重构难度。同时，该框架还引入了一种基于检索的动态课程学习策略，可以动态调整训练课程，通过检索具有相似语义信息的样本，平衡学习焦点之间的易难样本。", "conclusion": "广泛的基准数据集上的实验表明，HARDY-MER 在缺失模态情况下均能稳定地超越现有方法。我们的代码将在将来公诸于众。"}
{"llm_update_time": "20250816", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.08052", "html_url": "https://arxiv.org/abs/2508.08052", "title": "连续学习中模型容量动力学的理解", "title_en": "On Understanding of the Dynamics of Model Capacity in Continual Learning", "authors": "Supriyo Chakraborty,Krishnan Raghavan", "background": "连续学习（CL）中的稳定性-可塑性两难问题，紧密相关于神经网络（NN）的能力，即表示任务的能力，是一个基本挑战。当任务数据分布发生变化时，NN的表征能力会下降。通过引入有效的模型容量（CLEMC），该研究描述了一种动态模型来刻画这个稳定性-可塑性的平衡点变化。", "innovation": "该研究开发了一种差分方程来建模MN、任务数据以及优化过程之间的相互作用。CLEMC表明，有效容量是动态的，不受网络架构或优化方法的影响，这表明NN在新任务上的表示能力会随新旧任务数据分布的变化而下降。通过广泛的实验支持了该理论发现。", "conclusion": "无论网络架构或优化方法如何，当输入的新任务分布不同于先前的分布时，NN表示新任务的能力会下降。实验结果证明了理论发现，有效容量是动态变化的，而稳定性-可塑性平衡点也是如此。"}
{"llm_update_time": "20250816", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.06445", "html_url": "https://arxiv.org/abs/2508.06445", "title": "自动化回响：新闻制作中LLM使用增加", "title_en": "Echoes of Automation: The Increasing Use of LLMs in Newsmaking", "authors": "Abolfazl Ansari,Delvin Ce Zhang,Nafis Irtiza Tripto,Dongwon Lee", "background": "本文探讨了生成式人工智能（GenAI），特别是大型语言模型（LLMs）的迅速崛起对新闻报道中的新闻真实性和作者身份带来的担忧。研究选取了40,000多篇来自全国性、地方性和高校媒体的新闻文章进行分析，涵盖多种媒介格式。利用三项先进的AI文本检测工具（如Binoculars、Fast-Detect GPT和GPTZero），研究发现近年来在新闻制作中使用LLM的现象显著增加，特别是在地方新闻和高校媒体中。", "innovation": "研究使用了三种先进的AI文本检测工具进行分析，揭示了LLM在新闻写作中的具体应用，如在新闻的开头部分以及结论部分的手动撰写。语言分析显示，尽管GenAI提升了词汇丰富度和可读性，但也降低了形式性，导致写作风格变得更加统一，这在地方媒体中尤为突出。", "conclusion": "研究显示，近年来新闻制作中使用LLM的现象显著增加，尤其是在地方和高校媒体中。LLM多用于新闻的开头，而结论则通常由人工撰写。这些分析工具揭示了语料库中GenAI使用的影响，提升了词汇丰富度和可读性，但同时也降低了新闻稿的形式性。这种统一的写作风格在地方媒体中最明显。"}
{"llm_update_time": "20250816", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.07178", "html_url": "https://arxiv.org/abs/2508.07178", "title": "通过从隐式反馈中去噪虚假兴趣改进个性化头条生成", "title_en": "Improved Personalized Headline Generation via Denoising Fake Interests from Implicit Feedback", "authors": "Kejin Liu,Junhong Lian,Xiang Ao,Ningtao Wang,Xing Fu,Yu Cheng,Weiqiang Wang,Xinyu Liu", "background": "准确的个性化头条生成依赖于精确捕捉用户兴趣的历史行为。然而，现有方法忽视了整个历史点击流中的个性化无关点击噪声，这可能导致与用户真实偏好背离的虚构头条。本文通过在用户和新闻维度上严格分析，揭示了点击噪声对个性化生成质量的负面影响。", "innovation": "提出了一种新颖的个性化头条生成框架（PHG-DIF），通过隐式反馈中去噪虚假兴趣。PHG-DIF首先使用双阶段过滤有效去除点击流噪声，然后利用多级时间融合动态建模用户不断演变和多维度的兴趣，精确化对用户兴趣的建模。同时提供了一个新基准数据集DT-PENS，包含1000个精心筛选的用户和近10000个带有历史停留时间注释的标注个性化头条。", "conclusion": "广泛的实验表明，PHG-DIF显著减轻了点击噪声的负面影响，显著提高了头条质量，达到了当前最佳（SOTA）结果。我们的框架实现和数据集可在以下网址获取：this https URL."}
{"llm_update_time": "20250816", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.08535", "html_url": "https://arxiv.org/abs/2508.08535", "title": "LLM-驱动的适应性6G就绪无线身体区域网络：综述和框架", "title_en": "LLM-Driven Adaptive 6G-Ready Wireless Body Area Networks: Survey and Framework", "authors": "Mohammad Jalili Torkamani,Negin Mahmoudi,Kiana Kiashemshaki", "background": "无线身体区域网络（WBANs）能够进行生理信号的持续监测，应用于慢性病管理和紧急响应等领域。6G通信、后量子密码学和能量收集技术的进步有望提升WBAN性能，但将这些技术集成到统一且适应性强的系统中仍然存在挑战。", "innovation": "本文提出了一种新的大型语言模型驱动的适应性WBAN框架，其中大型语言模型作为认知控制平面，实时协调路由、物理层选择、微能量收集和后量子安全。该研究突出了当前基于启发式设计的限制，并为资源受限的、6G就绪的医疗系统制定了研究议程。", "conclusion": "本工作旨在使下一代移动健康应用中的WBANs达到超可靠、安全和自优化。该方法为当前的WBAN系统提供了改进方向，推动了适应性6G无线身体区域网络的发展。"}
{"llm_update_time": "20250816", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.07970", "html_url": "https://arxiv.org/abs/2508.07970", "title": "WeChat-YATT: 一种简单、可扩展且平衡的RLHF训练框架", "title_en": "WeChat-YATT: A Simple, Scalable and Balanced RLHF Trainer", "authors": "Junyu Wu,Weiming Chang,Xiaotao Liu,Guanyou He,Tingfeng Xian,Haoqiang Hong,Boqi Chen,Haotao Tian,Tao Yang,Yunsheng Shi,Feng Lin,Ting Yao", "background": "强化学习从人类反馈（RLHF）已经成为训练大型语言模型和多模态系统的重要范式。尽管现有的RLHF训练框架取得了显著进展，但在扩展到复杂的多模态工作流和适应动态工作负载方面仍面临重大挑战。具体来说，当前系统在管理大型模型时经常遇到控制器可扩展性的限制，以及在需要动态采样和资源分配的场景中协调复杂的RLHF管道的低效率问题。", "innovation": "WeChat-YATT 是一种简单、可扩展且平衡的RLHF训练框架，特别设计用于应对这些挑战。其特点是一个并行控制器编程模型，能够灵活高效地协调复杂的RLHF工作流，有效缓解集中式控制器架构相关的瓶颈，并在大规模数据场景中实现可扩展性。此外，WeChat-YATT 提出了一种动态放置策略，能够自适应地分配计算资源和调度工作负载，在训练条件变化时显著减少硬件闲置时间和提高GPU利用率。通过一系列实验场景的评估，WeChat-YATT 在吞吐量方面取得了显著的提升，已成功应用于训练了支持微信产品功能的大规模用户群模型，证明了其实效性和鲁棒性。", "conclusion": "WeChat-YATT 作为一种简单、可扩展且平衡的RLHF训练框架，通过并行控制器编程模型和动态资源分配策略，在大规模数据场景下显著提升了吞吐量，并成功应用于微信产品，验证了其在实际应用中的有效性和可靠性。"}
{"llm_update_time": "20250816", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.08285", "html_url": "https://arxiv.org/abs/2508.08285", "title": "假象的进步：LLMs中的幻觉检测再评估", "title_en": "The Illusion of Progress: Re-evaluating Hallucination Detection in LLMs", "authors": "Denis Janiak,Jakub Binkowski,Albert Sawczyn,Bogdan Gabrys,Ravid Shwartz-Ziv,Tomasz Kajdanowicz", "background": "大语言模型（LLMs）在自然语言处理领域取得了革命性的进展，但它们产生的幻觉现象为可靠部署带来了严重挑战。尽管存在多种幻觉检测方法，但这些检测方法往往依赖于ROUGE指标进行评估，而ROUGE指标基于词汇重叠，容易与人类判断产生脱节。通过全面的人类研究，我们发现尽管ROUGE具有较高的召回率，但其极低的精确率会导致性能评估结果出现误导。此外，我们分析指出，基于响应长度的简单启发式方法可以与复杂的检测技术相媲美，揭示了当前评估实践中的根本缺陷。", "innovation": "本文通过人类研究揭示了ROUGE等基于词汇重叠的评价指标存在局限性，并表明简单的基于响应长度的启发式方法可以与复杂的检测技术相媲美，从而指出当前评价实践中存在的根本缺陷。作者进一步提出，采用语义感知和稳健的评估框架对于准确评估幻觉检测方法的真实性能至关重要。", "conclusion": "本文的研究结果强调，采用语义感知和稳健的评估框架是确保大语言模型输出可信性的关键。通过这种改进的评估方法，可以更准确地评估幻觉检测方法的性能，确保其真实可信度。"}
{"llm_update_time": "20250816", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.08543", "html_url": "https://arxiv.org/abs/2508.08543", "title": "M3-Net: 一种经济有效的无图MLP基模型用于交通预测", "title_en": "M3-Net: A Cost-Effective Graph-Free MLP-Based Model for Traffic Prediction", "authors": "Guangyin Jin,Sicong Lai,Xiaoshuai Hao,Mingtao Zhang,Jinlei Zhang", "background": "准确的交通预测是当前智能交通系统发展中的一项基本但至关重要的任务。现有的主流方法依靠时空图神经网络、时空注意力机制等技术取得了突破。然而，现有的深度学习方法的主要挑战在于它们要么依赖完整的交通网络结构，要么需要复杂的模型设计来捕获复杂的时空依赖关系。这些限制对大规模数据集上深度学习模型的有效部署和运行构成了重大挑战。", "innovation": "为了应对这些挑战，我们提出了一种经济有效的无需图的多层感知机(MLP)基模型M3-Net用于交通预测。该模型不仅利用时间序列和时空嵌入进行高效的特征处理，而且还首次引入了一种新的基于混合专家(MoE)机制的MLP-Mixer架构。在多个真实数据集上进行的大量实验表明，该模型在预测性能和轻量级部署方面具有明显优势。", "conclusion": "实验结果表明，M3-Net模型在预测性能和轻量级部署方面均优于现有模型，能够有效解决大规模数据集上深度学习模型的部署和运行效率问题。"}
{"llm_update_time": "20250816", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.08601", "html_url": "https://arxiv.org/abs/2508.08601", "title": "Yan: 基础性的交互视频生成", "title_en": "Yan: Foundational Interactive Video Generation", "authors": "Deheng Ye,Fangyun Zhou,Jiacheng Lv,Jianqi Ma,Jun Zhang,Junyan Lv,Junyou Li,Minwen Deng,Mingyu Yang,Qiang Fu,Wei Yang,Wenkai Lv,Yangbin Yu,Yewen Wang,Yonghang Guan,Zhihao Hu,Zhongbin Fang,Zhongqian Sun", "background": "本文介绍了Yan，这是一个基础性的交互视频生成框架，涵盖了从模拟、生成到编辑的整个工作流程。该框架特别设计了三个核心模块，旨在实现实时的交互式视频生成和编辑。", "innovation": "创新点在于首次提出了一种基于稀疏3D-VAE并带有KV缓存窗口降噪推理的高级仿真模块；引入了一种分层自回归标题方法，将游戏特异性知识注入到开放域跨模态视频扩散模型（VDMs）中，实现了即时的帧级、动作控制的无限交互视频生成；提出了一种混合模型，将交互机械模拟与视觉渲染明确地分离，使得交互过程中能够进行多粒度视频内容编辑。", "conclusion": "Yan通过整合上述模块，推动了交互视频生成从孤立能力向全面的AI驱动交互创造范式转变，为下一代创意工具、媒体和娱乐铺平了道路。"}
{"llm_update_time": "20250816", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.08855", "html_url": "https://arxiv.org/abs/2508.08855", "title": "BiasGym: 如何找到并移除大语言模型中的偏见", "title_en": "BiasGym: Fantastic LLM Biases and How to Find (and Remove) Them", "authors": "Sekh Mainul Islam,Nadav Borenstein,Siddhesh Milind Pawar,Haeun Yu,Arnav Arora,Isabelle Augenstein", "background": "理解大型语言模型（LLMs）权重中嵌入的偏差和刻板印象对于制定有效的缓解策略至关重要。尽管可以通过故意激发来识别偏差行为，但这些行为往往是微妙且不易于分离的，因此系统分析和缓解这些偏差仍然非常具有挑战性。", "innovation": "我们引入了BiasGym，这是一种简单、经济且通用的框架，用于可靠地注入、分析和缓解LLMs中的概念关联。BiasGym包括两个组件：BiasInject和BiasScope。BiasInject通过基于标记的微调将特定偏差注入模型，而BiasScope则利用这些注入的信号来识别和引导导致偏差行为的组件。该方法使我们能够一致地激发偏差以便进行机制分析，支持目标化的偏差缓解而不影响下游任务的性能，并且可以推广到在基于标记的微调过程中未遇到的新的偏见。", "conclusion": "我们展示了BiasGym在减少真实世界刻板印象（例如，意大利人是“鲁莽的司机”）和探索虚构关联（例如，来自虚构国家的人有“蓝皮肤”）方面的有效性，证明了其在安全干预和可解释性研究中的实用性。"}
{"llm_update_time": "20250816", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.08895", "html_url": "https://arxiv.org/abs/2508.08895", "title": "ASPD：通过探索大型语言模型中的内在并行性实现自适应串行-并行解码", "title_en": "ASPD: Unlocking Adaptive Serial-Parallel Decoding by Exploring Intrinsic Parallelism in LLMs", "authors": "Keyu Chen,Zhifeng Shen,Daohai Yu,Haoqian Wu,Wei Wen,Jianfeng He,Ruizhi Qiao,Xing Sun", "background": "随着大型语言模型（LLMs）规模和复杂性的增加，推理延迟成为一个显著的挑战，主要原因是它们的自回归解码范式，这一过程以下一个词预测的顺序性为特征。通过重新审视自回归模型的输出，我们发现其中某些部分具有可并行的结构，我们称之为内在并行性。并行解码各个可并行的分支可以显著提高LLMs的整体推理速度。", "innovation": "本文提出了一种自适应串行-并行解码（ASPD），它解决了两个核心挑战：自动构建可并行的数据以及高效的并行解码机制。具体来说，我们引入了一个非侵入式流水线，可以自动从自回归模型的响应中提取并验证可并行结构。为了实现高效的自适应串行-并行解码，我们实现了一个混合解码引擎，能够在维持可重用的KV缓存的同时无缝在串行和并行解码模式之间切换，从而最大化计算效率。实验结果表明，ASPD在通用任务、检索增强生成和数学推理等任务上都达到了前所未有的效果和效率。在Vicuna Bench上，我们的方法实现了最高3.19倍（平均1.85倍）的速度提升，同时响应质量与自回归模型相比仅相差1%。", "conclusion": "我们的框架为高效的LLM并行推理设定了一个开创性的基准，为新兴的对延迟敏感的应用场景，如AI驱动的客户服务机器人和答案检索引擎的部署铺平了道路。"}
{"llm_update_time": "20250816", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.09146", "html_url": "https://arxiv.org/abs/2508.09146", "title": "理解基于Transformer的上下文学习优化CSMA的理论", "title_en": "To Theoretically Understand Transformer-Based In-Context Learning for Optimizing CSMA", "authors": "Shugang Hao,Hongbo Li,Lingjie Duan", "background": "二进制指数退避方案在WiFi 7中广泛应用，但在动态信道环境中仍导致低吞吐量性能。基于模型的方法（例如非坚持和$p$-坚持CSMA）仅在已知且固定的节点密度下优化退避策略，由于节点密度估计不准确，仍导致大量吞吐量损失。本文是首次提出基于LLM变换器的上下文学习（ICL）理论以优化信道访问。", "innovation": "设计了一个基于变换器的ICL优化器，预收集了碰撞阈值数据案例和查询碰撞案例，作为输入供变换器学习模式，生成预测竞争窗口阈值（CWT）。提出了一个高效的算法训练变换器，确保在有限的训练步骤内获得近似最优的CWT预测。为了容许实践中获取不完美的数据，进一步扩展允许在提示中输入错误的数据，在此基础上，证明了优化器的预测和吞吐量误差最小，实验结果还显示，本方法在未知节点密度下对现有基于模型和DRL方法的吞吐量具有更快的收敛性和接近最优的性能。", "conclusion": "通过基于LLM变换器的上下文学习方法优化了CSMA，快速收敛且接近最优吞吐量，解决了由于节点密度不准确导致的显著吞吐量损失问题。"}
{"llm_update_time": "20250816", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.09178", "html_url": "https://arxiv.org/abs/2508.09178", "title": "IAD-R1：在工业异常检测中强化一致性推理", "title_en": "IAD-R1: Reinforcing Consistent Reasoning in Industrial Anomaly Detection", "authors": "Yanhui Li,Yunkang Cao,Chengliang Liu,Yuan Xiong,Xinghui Dong,Chao Huang", "background": "工业异常检测是现代制造业的关键组成部分，但由于缺陷样本稀缺，传统检测方法的应用局限于特定场景。尽管视觉-语言模型（VLMs）在泛化能力上表现出显著优势，但在工业异常检测方面的性能仍然有限。", "innovation": "本文提出了一种适用于不同架构和参数规模的VLMs的通用后训练框架——IAD-R1，通过实施两阶段训练策略：感知激活监督微调（PA-SFT）阶段使用精心构建的高质量Chain-of-Thought数据集（Expert-AD）进行训练，增强异常感知能力并建立推理与回答的关联；结构化控制组相对策略优化（SC-GRPO）阶段采用精心设计的奖励函数，从“异常感知”迈向“异常解释”。实验结果表明，IAD-R1在7个VLMs上都取得了显著的改进，尤其是在DAGM数据集上，平均准确率提高了43.3%，且在零样本设置中，0.5B参数模型超越了包括GPT-4.1和Claude-Sonnet-4在内的商用模型，证明了IAD-R1的有效性和优越性。", "conclusion": "IAD-R1通过两阶段训练策略显著增强了VLMs的异常检测能力，并展示了在工业异常检测中的有效性和优越性。相关数据、代码和所有模型权重将公开发布。"}
{"llm_update_time": "20250816", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.09158", "html_url": "https://arxiv.org/abs/2508.09158", "title": "EvaDrive：端到端自主驾驶的进化对抗策略优化", "title_en": "EvaDrive: Evolutionary Adversarial Policy Optimization for End-to-End Autonomous Driving", "authors": "Siwen Jiao,Kangan Qian,Hao Ye,Yang Zhong,Ziang Luo,Sicong Jiang,Zilin Huang,Yangyi Fang,Jinyu Miao,Zheng Fu,Yunlong Wang,Kun Jiang,Diange Yang,Rui Fan,Baoyun Peng", "background": "自主驾驶在实现类人迭代决策方面面临重大挑战，需要不断生成、评估和优化路径提案。现有生成-评估框架将路径生成与质量评估隔离，剥夺了迭代优化这一规划中不可或缺的过程。强化学习方法将多维度的偏好简化为单一标量奖励，这掩盖了关键权衡并产生了标量化损失。本研究旨在克服这些问题。", "innovation": "本文提出了一种新颖的多重目标强化学习框架EvaDrive，通过对抗优化建立路径生成与评估之间真正的闭环共同进化。EvaDrive将轨迹规划定义为一个多方对抗游戏。该框架使用层次生成器不断提出候选路径，并通过自回归意图建模实现时间因果性与通过扩散方式实现的空间灵活性相结合的路径磨练。然后，通过可训练的多重目标评价器严格评估这些提案，该评估器明确保留了多样化的偏好结构而不会将其简化为单一同化。这种对抗互动，受到帕累托前沿选择机制的引导，能够实现多次迭代的优化，有效逃离局部最优解，同时保留路径多样性。", "conclusion": "在NAVSIM和Bench2Drive基准测试中，EvaDrive展示了SOTA性能，分别在NAVSIM v1中获得94.9 PDMS（超过DiffusionDrive 6.8、DriveSuprim 5.0和TrajHF 0.9），在Bench2Drive中获得64.96驾驶分数。EvaDrive通过动态加权生成多样化的驾驶风格，无需外部偏好数据，引入了闭环对抗框架，用于实现类人的循环决策，并提出了无标量化处理的轨迹优化方法。"}
{"llm_update_time": "20250816", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.09458", "html_url": "https://arxiv.org/abs/2508.09458", "title": "幻觉 vs 解释：重新思考 AI 辅助数据提取在知识综合中的准确性和精确性", "title_en": "Hallucination vs interpretation: rethinking accuracy and precision in AI-assisted data extraction for knowledge synthesis", "authors": "Xi Long,Christy Boscardin,Lauren A. Maggio,Joseph A. Costello,Ralph Gonzales,Rasmyah Hammoudeh,Ki Lai,Yoon Soo Park,Brian C. Gin", "background": "知识综合（文献综述）在健康专业教育中至关重要，它能整理和汇总研究成果，推动理论和实践的发展。然而，这一过程耗时且在数据提取时尤其费力。人工智能（AI）辅助提取数据有提高效率的潜力，但也引发了关于准确性的问题，因此区分AI“幻觉”（虚构内容）与合理的解释性差异变得至关重要。\n", "innovation": "研究开发了一个基于大规模语言模型的提取平台，以自动化数据提取，并通过对比AI与人类在187篇文献和17个提取问题的回复上的一致性来评估AI的性能。研究发现AI在处理具体、明确的问题上与人类高度一致，但在需要主观解释或文本中未提及的问题上较低。研究结果表明，AI的一致性更多取决于可解释性而非幻觉，重复的AI提取可以帮助识别解释的复杂性或模糊性，有利于在人类审查之前改进流程。\n", "conclusion": "AI可以在知识综合中作为透明且可信赖的合作伙伴，但需要谨慎以保留关键的人类洞察力。\n"}
{"llm_update_time": "20250816", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.09185", "html_url": "https://arxiv.org/abs/2508.09185", "title": "一种用于增强现实可解释认知攻击检测的神经符号框架", "title_en": "A Neurosymbolic Framework for Interpretable Cognitive Attack Detection in Augmented Reality", "authors": "Rongqian Chen,Allison Andreyev,Yanming Xiu,Mahdi Imani,Bin Li,Maria Gorlatova,Gang Tan,Tian Lan", "background": "增强现实（AR）通过在物理世界叠加虚拟元素来丰富感知。由于其日益增长的流行度，对改变AR内容以操控用户语义感知的认知攻击得到了越来越多的关注。现有的检测方法通常集中在视觉变化上，这些方法局限于像素或图像级别的处理，缺乏语义推理能力，或者依赖于预先训练的视觉-语言模型（VLMs）黑盒方法，这些方法缺乏可解释性。", "innovation": "本文提出了一种名为CADAR的新神经符号方法，用于AR中的认知攻击检测。该方法结合了多模态视觉-语言输入，使用神经VLM获得一个符号感知图表示，并整合先验知识、显著性加权和时序相关性。然后通过粒子滤波基于的统计推理（一种序贯蒙特卡洛方法）检测认知攻击。因此，CADAR继承了预训练VLM的适应性和粒子滤波的可解释性和推理严谨性。在扩展的AR认知攻击数据集上的实验结果显示，在复杂的AR攻击场景中，CADAR相对于强大基线的准确率提升了最多10.7%，表明神经符号方法在有效的和可解释的认知攻击检测中的潜力。", "conclusion": "实验结果表明，CADAR在复杂的AR攻击场景中相对于强大基线的准确率提升了最多10.7%，强调了神经符号方法在有效且可解释的认知攻击检测中的潜力。"}
{"llm_update_time": "20250816", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.09297", "html_url": "https://arxiv.org/abs/2508.09297", "title": "带有偏见的AI可以改善人类决策但会降低信任", "title_en": "Biased AI improves human decision-making but reduces trust", "authors": "Shiyang Lai,Junsol Kim,Nadav Kunievsky,Yujin Potter,James Evans", "background": "当前的人工智能系统通过维护意识形态中立来最小化风险，但这种做法可能会引入自动化偏差，抑制人类在决策中的认知参与。文章指出，为了了解偏见的AI是否能提升人类的决策质量，研究者进行了随机试验，通过让2500名参与者与政治观点不同的GPT-4o变体进行信息评估任务的互动来探究这个问题。", "innovation": "研究开发并测试了带有偏见的AI助手，即GPT-4o变体，并将其与无偏见的AI助手进行对比。结果显示，带有偏见的AI助手在提高人类决策性能、增加参与度并减少评价偏差方面效果显著，并且当参与者遇到不同观点时更明显。然而，参与者低估了带有偏见的AI并高估了中立系统，这造成信任方面的负面影响。研究进一步建议暴露参与者于两种具有不同偏见的AI，这有助于弥合感知和表现之间的差距。这些结果对传统上对AI中立性的看法提出了挑战，暗示多元文化的偏见可能有助于提升和增强人类决策质量。", "conclusion": "这些发现复杂化了关于AI中立性的传统智慧，表明有策略地整合各种文化偏见可能促进更良好且更具韧性的决策过程。"}
{"llm_update_time": "20250816", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.09632", "html_url": "https://arxiv.org/abs/2508.09632", "title": "Preacher: Paper-to-Video Agentic System", "title_en": "Preacher: Paper-to-Video Agentic System", "authors": "Jingwei Liu,Ling Yang,Hao Luo,Fan Wang,Hongyan Li,Mengdi Wang", "background": "当前最先进的视频生成模型在生成结构化视频摘要方面展示了潜力，但存在限制，如有限的上下文窗口、严格的视频时长限制、有限的风格多样性以及 inability to represent domain-specific knowledge（无法表现领域特定知识）。", "innovation": "Preacher 是第一个用于将论文转换为视频摘要的自主系统，采用了从上至下的方法进行逐步分解、总结和重新表述论文，然后通过从下向上的视频生成方法，将多种视频片段合成一个连贯的摘要。此外，Preacher 引入了 Progressive Chain of Thought (P-CoT) 来逐步对齐跨模态表示，实现精细迭代规划。", "conclusion": "Preacher 成功地在五个研究领域生成高质量的视频摘要，并展示了超越现有视频生成模型的专业知识。相关代码将在此网址发布：this https URL"}
{"llm_update_time": "20250816", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.09202", "html_url": "https://arxiv.org/abs/2508.09202", "title": "无源个性化特征转换用于表达识别：一种高效的无源域适应方法", "title_en": "Personalized Feature Translation for Expression Recognition: An Efficient Source-Free Domain Adaptation Method", "authors": "Masoumeh Sharafi,Soufiane Belharbi,Houssem Ben Salem,Ali Etemad,Alessandro Lameiras Koerich,Marco Pedersoli,Simon Bacon,Eric Granger", "background": "面部表情识别（FER）模型被广泛应用于基于视频的情绪计算应用中，如人机交互和健康监测。然而，深度FER模型在识别微妙表情和处理个体间高度差异方面存在困难，限制了他们在实际应用中的性能。为解决这些问题，已有研究提出了无需源数据的域适应（SFDA）方法，即仅使用目标领域数据和个人化预训练模型，以避免涉及数据隐私、存储和传输的限制。然而，当无法获取源数据进行个性化调整，且目标数据仅由静态表情组成时，SFDA方法变得不适用。当前的图像转换方法需要生成面部图像，这可能导致不稳定性且计算量大。因此，作者提出了一种无源个性化特征转换（PFT）方法，该方法在隐空间中操作，避免了生成面部表情的复杂性和噪声，同时提高了计算效率和分类性能的优化。", "innovation": "该方法在隐空间中操作，通过无源个性化特征转换（PFT），利用目标领域的无标签数据，尤其适用于单一表情类别的数据适应。具体创新点包括：1) 预训练的翻译器可以将一个源主题的主体特定风格特征转换到另一个主题中，2) 表达一致性和风格感知目标的优化保持了表情信息，3) 通过在隐空间中进行转换，避免了面部表情生成的复杂性和噪声，生成了优化的鉴别嵌入，从而提高分类性能。此外，该方法无需进行图像合成，减少了计算开销，只适配了部分模型，相比基于图像的翻译方法更高效。", "conclusion": "该论文提出了一种名为PFT的方法，这是一种高效的无源域适应方法，适用于仅有目标领域中单类无标签数据的情况。通过在隐空间中操作和优化表达一致性和风格感知目标，PFT能够个性化深度FER模型，同时避免了生成面部表情的难度和计算开销。这种方法不仅提高了性能，还简化了实现过程，展示了其在实际应用中的潜力。"}
{"llm_update_time": "20250816", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.09993", "html_url": "https://arxiv.org/abs/2508.09993", "title": "区块链上开源语言模型公平性评估的透明协议", "title_en": "A Transparent Fairness Evaluation Protocol for Open-Source Language Model Benchmarking on the Blockchain", "authors": "Hugo Massaroli,Leonardo Iara,Emmanuel Iarussi,Viviana Siless", "background": "随着大规模语言模型（LLMs）在现实世界中的应用越来越广泛，尤其是在刑事司法、教育、医疗保健和金融等高风险领域，对于其公平性的担忧仍然存在。因此，该论文提出了一种使用互联网计算机协议（ICP）区块链上的智能合约来评估开源LLM公平性的透明评估协议。", "innovation": "该方法通过区块链上的HTTP请求执行来确保评估的可验证性、不可变性和可重复性，并直接将数据集、提示和指标存储在区块链上，从而进行开源LLM的公平性基准测试。论文中还提出了一种新的方法，通过使用统计平价和平等机会指标对PISA数据集进行学术表现预测公平性评估，并使用从StereoSet数据集中派生的结构化上下文关联指标来测量上下文关联中的社会偏见，进一步进行了跨语言评估。", "conclusion": "通过区块链技术支持的透明评估协议完成了对Llama、DeepSeek和Mistral模型的基准测试，并揭示了跨语言差异。所有的代码和结果都是开源的，这使得社区可以进行审计并长期跟踪模型版本中的公平性。"}
{"llm_update_time": "20250816", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.09848", "html_url": "https://arxiv.org/abs/2508.09848", "title": "PRELUDE：一项设计用于评估长文本全球理解和推理能力的标准", "title_en": "PRELUDE: A Benchmark Designed to Require Global Comprehension and Reasoning over Long Contexts", "authors": "Mo Yu,Tsz Ting Chung,Chulun Zhou,Tong Li,Rui Lu,Jiangnan Li,Liyan Xu,Haoshu Lu,Ning Zhang,Jing Li,Jie Zhou", "background": "当前基准测试主要针对短期内的故事理解，侧重于局部理解。新基准测试PRELUDE通过要求参与者判断前传故事是否与原始书籍的经典叙述一致，旨在评估长上下文理解能力。前传故事通常与原故事无关，因此需要全局理解和深刻推理才能确定其合理性。实验结果显示，当前最先进的技术（如在上下文学习、RAG和使用最新LLM的内部训练等）在该任务上均落后于人类15%以上，特别是在推理准确率方面人类与模型存在30%以上的差距。这些发现突出了长上下文理解与推理能力的改进空间巨大。", "innovation": "PRELUDE基准测试创新地要求参与者判断前传故事与经典叙述的一致性，这种机制比现有标准更加强调全球理解和深思熟虑的推理能力，并且需要在间接相关的信息中进行搜索和整合。这使得评估模型在外延理解和推理方面的能力更加严格。实验结果表明，模型的表现不佳，尤其是在推理准确性和理解能力方面与人类存在显著差距。", "conclusion": "任务表明现有先进的语言模型在长期上下文理解和推理方面存在局限性，未来需要进行改进。人类表现显著优于当前最先进的技术，特别是在推理和结构性思考能力上。该研究为进一步提升benchmark测试标准和模型改进指明了方向。"}
{"llm_update_time": "20250816", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.09991", "html_url": "https://arxiv.org/abs/2508.09991", "title": "在BC癌症登记处引入现代NLP创新与医疗需求之间的对接：经验教训", "title_en": "Bridging AI Innovation and Healthcare Needs: Lessons Learned from Incorporating Modern NLP at The BC Cancer Registry", "authors": "Lovedeep Gondara,Gregory Arbour,Raymond Ng,Jonathan Simkin,Shebnum Devji", "background": "临床文件中的数据抽取自动化为改善医疗保健环境中的效率提供了巨大潜力，但部署自然语言处理（NLP）解决方案存在实际挑战。基于不列颠哥伦比亚癌症登记处（BCCR）实施各种NLP模型的经验，本文分享了项目生命周期中汲取的关键教训。强调了基于明确的商业目标而非仅技术准确性定义问题的重要性，以及在开发过程中采用迭代方法和跨学科合作与协同设计。“", "innovation": "提出了实际相关的考虑因素，涵盖了从选择合适的模型（包括混合方法和简单方法）到严格的数据质量关注（代表性和漂移注释）、人循环验证和持续审核的错误缓解策略，以及构建组织中的人工智能使用能力。这些实践指导意见适用于寻求成功实施AI/NLP解决方案以增强数据管理流程的医疗保健组织，从而提高患者护理和公共健康成果。", "conclusion": "通过强调定义问题的基础、采用迭代开发方法和促进跨学科合作等方式，本文为医疗保健组织提供了在临床文档中成功实施AI/NLP解决方案的实践指导，以提升数据管理流程，最终改善患者护理和公共健康成果。"}
{"llm_update_time": "20250816", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.09999", "html_url": "https://arxiv.org/abs/2508.09999", "title": "XFacta：基于多模态大语言模型的多模态错误信息检测的现代实际情况数据集和评估", "title_en": "XFacta: Contemporary, Real-World Dataset and Evaluation for Multimodal Misinformation Detection with Multimodal LLMs", "authors": "Yuzhuo Xiao,Zeyu Han,Yuhan Wang,Huaizu Jiang", "background": "社交媒体上多模态错误信息的迅速传播需要更有效和鲁棒的检测方法。近年来，利用多模态大语言模型（MLLMs）的技术展示了应对这一挑战的潜力。但在现有方法中，存在着信息检索与推理之间的瓶颈问题，这阻碍了该领域的进一步发展。此外，现有数据集要么过时，导致评价偏见，因为MLLMs可能只是简单地记住这些事件，要么人为合成，无法反映现实世界的错误信息模式。", "innovation": "我们引入了XFacta，这是一种现代化的、基于实际情况的数据集，更适合评估基于MLLMs的检测方法。我们系统地评估了各种基于MLLMs的错误信息检测策略，包括不同架构和规模的模型，并对现有检测方法进行了基准测试。在此基础上，我们还开发了一种半自动化检测循环框架，能够持续更新XFacta以维持其现代相关性。我们的分析提供了该领域发展的宝贵见解和实践。", "conclusion": "我们的分析为多模态错误信息检测领域的进展提供了有价值的观点和实践经验。相关的代码和数据已经公开释出。"}
{"llm_update_time": "20250816", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.09998", "html_url": "https://arxiv.org/abs/2508.09998", "title": "INTIMA：AI伴侣行为评估基准", "title_en": "INTIMA: A Benchmark for Human-AI Companionship Behavior", "authors": "Lucie-Aimée Kaffee,Giada Pistilli,Yacine Jernite", "background": "AI伴侣行为，用户与AI系统之间建立情感联系，已经成为一个具有积极影响但也令人担忧的趋势。本研究旨在评估语言模型的伴侣行为，通过对心理理论和用户数据的研究，开发了一个包含31种行为、四类和368个针对性提示的分类体系。研究表明，这些行为中伴积极行为依然较为普遍，但不同商业提供商对敏感部分有不同的侧重，这可能导致用户福祉受损，因此需要更一致的方法来处理情感化互动", "innovation": "提出了名为INTERACTIONS AND MACHINE ATTACHMENT BENCHMARK (INTIMA)的新基准，用于评估语言模型的伴侣行为，包含31种行为分类和368个针对性提示，评估其是否强化伴侣情感、维持边界或保持中立。研究发现，不同商业提供商在敏感部分的评估结果存在显著差异，反映了其对于边界设置和情感支持的不同侧重", "conclusion": "本研究揭示了不同商业提供商在评估伴侣行为时的不同侧重，这可能对用户福祉产生影响。研究结果强调了需要更一致的方法来处理情感化互动的必要性，建议未来的AI系统设计中，应当更加注重适当界限的设定和提供恰当的情感支持"}
{"llm_update_time": "20250816", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.09997", "html_url": "https://arxiv.org/abs/2508.09997", "title": "使用层次主题建模的 K-12 通用人工智能用法的主题化和任务分类", "title_en": "Thematic and Task-Based Categorization of K-12 GenAI Usages with Hierarchical Topic Modeling", "authors": "Johannes Schneider,Béatrice S. Hasler,Michaela Varrone,Fabian Hoya,Thomas Schroffenegger,Dana-Kristin Mah,Karl Peböck", "background": "以往的研究大多缺乏基于内容或主题的分类，而大多数任务分类研究则未基于K-12教育的实际情况进行。因此，本研究对课堂中不止17000条由学生、老师和ChatGPT生成的消息进行了分类，这些消息来自多个学校和科目，覆盖了几个月的时间，通过一种新的简单主题建模方法进行分析。这种分类方法在内容和任务两个维度上都进行了层级划分，为后续研究和实践提供了有用的信息和指导。", "innovation": "论文采用了一种新的简单主题建模方法对匿名的学生-老师-ChatGPT的互动数据进行分类。同时，论文发现传统的主题建模方法不足以分析这些文本，而最新的大语言模型（LLMs）通过适当的预处理和明确的指令应用，能更有效地生成具有更好人类共识的层级主题结构。论文的创新之处在于找到了适用于教育领域的高效文本分类方法，并通过实证数据验证了这些方法的有效性。", "conclusion": "研究发现了许多基于现有文本分析方法的新应用。论文的发现支持研究者、教师和学生如何更深入和广泛地使用通用人工智能技术。同时，论文也指出了未来研究的一些关键问题和挑战，包括如何进一步优化方法以适应不同教育场景的需求。"}
{"llm_update_time": "20250816", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.10001", "html_url": "https://arxiv.org/abs/2508.10001", "title": "HiFACTMix: 一种基于证据的马拉地英语代码混合政治声明验证基准和图意识模型", "title_en": "HiFACTMix: A Code-Mixed Benchmark and Graph-Aware Model for EvidenceBased Political Claim Verification in Hinglish", "authors": "Rakesh Thakur,Sneha Sharma,Gauri Chopra", "background": "代码混合、低资源语言如Hinglish的事实核查仍然是自然语言处理中的一个未充分探索的挑战。现有事实验证系统主要关注高资源的单一语言环境，并未能有效应用于印度等语言多样性的政治话语中。鉴于公共人物特别是政治人物普遍使用Hinglish，以及社交媒体对公众意见的日益影响，开发鲁棒、多语言和上下文意识的事实核查工具变得十分重要。", "innovation": "引入了一个新的基准HiFACT数据集，包含1,500个由28位印度邦首席部长在Hinglish中提出的真实世界陈述，并指定了文本证据和真实性标签。提出了一个创新的图意识、检索增强型事实核查模型，结合了多语言上下文编码、声明-证据语义对齐、证据图构建、图神经推理和自然语言解释生成。", "conclusion": "HiFACTMix在准确性和对判决的解释方面优于最先进的多语言基准模型，为多语言、代码混合、政治导向的事实核查研究开辟了新方向。"}
{"llm_update_time": "20250816", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.10007", "html_url": "https://arxiv.org/abs/2508.10007", "title": "使用微调大型语言模型对含歧义意图敌意问卷进行自动化评分", "title_en": "Automated scoring of the Ambiguous Intentions Hostility Questionnaire using fine-tuned large language models", "authors": "Y. Lyu,D. Combs,D. Neumann,Y. C. Leong", "background": "敌意向偏倾向是将社会互动解读为有意图的敌对行为。常用于测量敌意向偏的含歧义意图敌意问卷（AIHQ）包含了开放性问题，需要经过训练的人类评分者评分以了解敌意向偏的内容，但这种评分过程耗时且效率低。", "innovation": "本研究评估了大型语言模型是否能够自动化AIHQ开放性题目的评分。通过对包含创伤性脑损伤（TBI）和健康对照（HC）个体完成的AIHQ数据集进行微调，发现模型生成的评分与人类评分高度一致，特别是在意外、意图、以及模糊情况下的敌意向偏和敌对反应评分。此外，模型在独立非临床数据集上也能很好地泛化。", "conclusion": "研究结果显示，大型语言模型能够简化AIHQ评分流程，适用于研究和临床场景，有助于不同群体的心理评估。为此，研究团队还提供了易于使用的评分界面，包括本地和云服务选项。"}
{"llm_update_time": "20250816", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.10005", "html_url": "https://arxiv.org/abs/2508.10005", "title": "从答案到问题：基于EQGBench评估大语言模型的教育性问题生成", "title_en": "From Answers to Questions: EQGBench for Evaluating LLMs' Educational Question Generation", "authors": "Chengliang Zhou,Mei Wang,Ting Zhang,Qiannan Zhu,Jian Li,Hua Huang", "background": "大语言模型（LLMs）在数学问题解决方面展现了显著的能力，但将其能力从提供答案提升到生成高质量教育性问题上面临的挑战依然较少被探究。本文旨在通过构建EQGBench基准来推进教育性问题生成（EQG），助力LLMs生成具有教育价值和实效性的教育性问题。", "innovation": "本文介绍了EQGBench，这是一个专门为中文教育性问题生成设计的全面基准。EQGBench建立了一个五维度的评估框架，用于评估LLMs在教育性问题生成方面的性能。该基准配备了来自数学、物理和化学三个中学基础学科的900个评价样本，涵盖了不同知识点、难度和问题类型。通过系统评估46种主流大模型，揭示了生成具有教育价值问题的显著提升空间。", "conclusion": "通过对各种主流大模型的系统评估，本文揭示了LLMs在生成教育性问题方面的显著差距，证明了EQGBench的有效性和必要性，有助于促进教育性问题生成技术的发展。"}
{"llm_update_time": "20250816", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.10008", "html_url": "https://arxiv.org/abs/2508.10008", "title": "在线课程讨论论坛帖子的多维度分类", "title_en": "Multidimensional classification of posts for online course discussion forum curation", "authors": "Antonio Leandro Martins Candido,Jose Everardo Bessa Maia", "background": "在线课程讨论论坛的自动管理需要持续更新，这使得定期重新训练大型语言模型（LLMs）变得资源密集型。通常，重新训练是通过成本高昂的微调来实现的。", "innovation": "本文提出并评估了一种贝叶斯融合方法。该方法结合了预训练通用LLM的多维度分类评分与一个基于本地数据训练的分类器的评分。实验结果表明，提出的融合方法在单独使用每个分类器时能提高结果，并且在性能上与LLM微调方法相当。", "conclusion": "提出的贝叶斯融合方法在提升在线课程讨论论坛帖子分类性能方面表现良好，且成本效益更高，相比微调LLM更具竞争力。"}
{"llm_update_time": "20250816", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.10009", "html_url": "https://arxiv.org/abs/2508.10009", "title": "超越硬共享：基于监督专家混合的高效多任务语音转文本建模", "title_en": "Beyond Hard Sharing: Efficient Multi-Task Speech-to-Text Modeling with Supervised Mixture of Experts", "authors": "Hojun Jin,Eunsoo Hong,Ziwon Hyung,Sungjun Lim,Seungjin Lee,Keunseok Cho", "background": "硬参数共享是一种常见的策略，用于联合训练跨多种任务的单个模型。然而，这种方法常常导致任务干扰，阻碍整体模型性能的提升。", "innovation": "提出了一种简单且有效的监督专家混合模型（S-MoE），通过使用特殊的指导标记来路由每个任务至其对应的专家，避免了训练门控函数的需求，并通过将每个任务分配给一个独立的前馈网络，克服了硬参数共享的局限。", "conclusion": "将S-MoE应用于语音转文本模型，使其能够处理混合带宽输入，同时执行自动语音识别（ASR）和语音翻译（ST）任务。实验结果表明，S-MoE的有效性，当应用于编码器和解码器时，在单词错误率（WER）上实现了6.35%的相对改进。"}
{"llm_update_time": "20250816", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.10004", "html_url": "https://arxiv.org/abs/2508.10004", "title": "用户对注意力可视化感知：影响证据基础医学文献解释性的视觉效果", "title_en": "User Perception of Attention Visualizations: Effects on Interpretability Across Evidence-Based Medical Documents", "authors": "Andrés Carvallo,Denis Parra,Peter Brusilovsky,Hernan Valdivieso,Gabriel Rada,Ivania Donoso,Vladimir Araujo", "background": "注意力机制是Transformer架构的核心组件，除了提高性能外，还被提出来作为解释机制，通过注意力权重来关联输入特征（例如，文档中的标记）。在循证医学中，这样的解释能够支持医生理解和与用于分类生物医学文献的AI系统的互动。然而，关于注意力权重是否提供了有帮助的解释仍没有达成共识，并且少有研究探讨可视化注意力如何影响其作为解释辅助工具的有效性。因此，进行了一项用户研究，以评估注意力基于的解释是否有助于生物医学文档分类，并且是否存在最佳的可视化方式。", "innovation": "研究通过用户研究来评估注意力基于的解释在生物医学文档分类中的支持作用，并发现注意力权重的感知有效性会因可视化方式的不同而有很大差异。用户更倾向于直观的可视化形式，而不是遵循Munzner的原则使用精确编码（如条形图长度）作为优先选项。这表明注意力权重的可解释性因可视化形式而异，并且需要考虑用户偏好来提升其解释性效果，而非绝对依赖于精确的视觉编码形式。", "conclusion": "该Transformer模型（XLNet）分类文档的准确性得到了验证，但注意力权重在解释预测结果时并不被认为是特别有用。注意力权重的有用性感知显著依赖于其可视化方式。研究结果不完全支持注意力权重作为解释工具的整体效用，但强调了可视化方式对用户接收解释的影响，推动了未来的可解释人工智能系统研究需要综合考虑用户的系统可解释性需求，以提供更具直观性和有效性的解释工具。"}
{"llm_update_time": "20250816", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.10010", "html_url": "https://arxiv.org/abs/2508.10010", "title": "LLM辅助的健康错误信息攻击审计与分析", "title_en": "An Audit and Analysis of LLM-Assisted Health Misinformation Jailbreaks Against LLMs", "authors": "Ayana Hussain,Patrick Zhao,Nicholas Vincent", "background": "大语言模型（LLMs）能够生成有害的错误信息，这种错误信息可能是由于无意中的生成，或是受到“解绑”攻击的推动。论文研究了LLM解绑攻击在引起其他模型生成有害医疗错误信息方面的有效性与特征。同时，研究了由解绑后的LLM生成的错误信息与社交媒体上常见的错误信息的差异，并探讨了标准机器学习方法能否有效检测这些错误信息。", "innovation": "研究了109种针对三种目标模型的不同攻击方式，并对比了攻击提示与现实中的健康相关LLM查询。同时，分析了攻击响应并将其与Reddit上的健康相关错误信息进行了比较。研究结果为使用LLMs有效检测来自其他LLMs和人们的错误信息提供了更多证据，支持了通过精心设计，LLMs能够有助于创建更健康的信息生态系统。", "conclusion": "研究证实，LLMs不仅能用来检测其他模型生成的错误信息，还能用来检测人类产生的错误信息。这种研究方法支持了构建更健康的信息环境的可能，只要LLMs的设计足够谨慎。"}
{"llm_update_time": "20250816", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.10011", "html_url": "https://arxiv.org/abs/2508.10011", "title": "基于GPT的大规模语言生成AI模型在日本注册营养师资格考试中的评估作为学习辅助工具", "title_en": "Evaluation of GPT-based large language generative AI models as study aids for the national licensure examination for registered dietitians in Japan", "authors": "Yuta Nagamori,Mikoto Kosai,Yuji Kawai,Haruka Marumo,Misaki Shibuya,Tatsuya Negishi,Masaki Imanishi,Yasumasa Ikeda,Koichiro Tsuchiya,Asuka Sawai,Licht Miyamoto", "background": "基于大规模语言模型（LLMs）的生成人工智能（AI），例如ChatGPT，已经在多个专业领域，包括医学和教育中取得了显著进展。然而，它们在营养教育，特别是在日本注册营养师国家级考试中的应用尚未得到充分探索。", "innovation": "本文创新地使用了基于GPT的大规模语言生成AI模型，如ChatGPT和Bing的三种模型（准确、创造性和平衡），针对日本注册营养师的国家级考试问题，评估这些模型作为营养学生学习辅助工具的潜力。通过分析模型的回答准确率、一致性以及响应时间，并测试了提示工程以评估性能改进的潜力。", "conclusion": "虽然有些生成AI模型在一定程度上超过了及格分数线，但总体准确率和答案一致性仍然不理想。所有模型在答案的一致性和稳定性方面都显示出了明显的局限性。需要进一步的进展来确保可靠的和稳定的基于AI的学科预备学习辅助工具，以帮助注册营养师的资格考试准备。"}
{"llm_update_time": "20250816", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.10013", "html_url": "https://arxiv.org/abs/2508.10013", "title": "Semantic Bridge: 通过AMR驱动的图合成实现通用多跳问题生成", "title_en": "Semantic Bridge: Universal Multi-Hop Question Generation via AMR-Driven Graph Synthesis", "authors": "Linqing Chen,Hanmeng Zhong,Wentao Wu,Weilei Wang", "background": "大规模语言模型（LLM）训练面临一个关键瓶颈，即高质量、推理密集型问题-答案对的稀缺性，尤其是来自如PubMed论文或法律文件等稀疏的领域特定来源。现有的方法依赖于表面模式，无法生成可控的、复杂多跳推理问题，这些问题是测试真正理解、助力LLM训练模式进步所必需的。", "innovation": "本研究提出了一种名为Semantic Bridge的通用框架，用于从任意来源控制性生成复杂的多跳推理问题。其突破性创新是语义图编织——三种互补的桥梁机制（实体桥梁（用于高度变化的角色共享实体）、谓词链桥梁（用于时间/因果/逻辑序列）、因果桥梁（用于显式推理链）），这些机制通过AMR驱动分析系统地构建文档间的复杂路径，细粒度地控制复杂性和类型。", "conclusion": "多模态AMR管道可实现高达9.5%的最佳往返质量，使可控问答生成具备生产能力。广泛评估表明，该框架在通用（维基百科）和专业（医疗）领域均表现出色，四种语言（英语、中文、法语、德语）均超过基线18.3%-25.4%。来自200个来源的问题对性能优于600个本地产的人类注释示例，材料减少67%。人类评估显示出23.4%更高的复杂性、18.7%更好的可回答性和31.2%更强大的模式覆盖率。Semantic Bridge建立了LLM训练数据合成的新范式，使得可以从稀疏来源生成受控推理问题。我们将会发布核心代码和语义桥模型。"}
{"llm_update_time": "20250816", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.10016", "html_url": "https://arxiv.org/abs/2508.10016", "title": "无训练的多模态大型语言模型编排", "title_en": "Training-Free Multimodal Large Language Model Orchestration", "authors": "Tianyu Xie,Yuhang Wu,Yongdong Luo,Jiayi Ji,Xiawu Zheng", "background": "不同的多模态大型语言模型（MLLMs）不能直接整合到统一的多模态输入输出系统中。尽管在前期的工作中，训练被认为是由于模式对齐、文本到语音效率及其他整合问题的必然组成部分，但本文提出了一种无需额外训练就能构建可互动的多模态AI系统的有效方法。", "innovation": "本文的核心创新包括：(1) 一个中央控制的语言模型控制器，能够通过精心设计的代理动态路由用户输入的任务至适当的专门模型；(2) 并行的文本转语音架构，实现真正双向交互，无缝中断处理和自然对话流程；(3) 跨模态记忆整合系统，通过智能信息合成和检索在不同模态之间维持连贯的语境，避免某些场景下不必要的模态调用，提高响应速度。", "conclusion": "全面的评估表明，该编排框架无需额外训练就能获得全面的多模态能力。相比于传统联合训练的方法，它在标准基准上的性能提高了高达7.8%，降低了10.3%的延迟，并通过明确的编排过程大幅提高了可解释性。"}
{"llm_update_time": "20250816", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.10014", "html_url": "https://arxiv.org/abs/2508.10014", "title": "PersonaEval: 能否让LLM评估器足够像人类来判断角色扮演？", "title_en": "PersonaEval: Are LLM Evaluators Human Enough to Judge Role-Play?", "authors": "Lingfeng Zhou,Jialing Zhang,Jin Gao,Mohan Jiang,Dequan Wang", "background": "当前的角色扮演研究往往依赖于未经验证的LLM作为评判者的范式，这可能无法准确反映人类对角色真实性的感知。为了实现与人类对齐的评价，首先需要识别出谁在对话中发言，即角色识别能力。我们的实验表明，即使是最先进的LLM也仅能达到约69%的准确率，远低于可靠的评价所需的水平。相比之下，人类参与者的准确率为90.8%，这表明当前的LLM评估器还不足以有效评估角色扮演情境。", "innovation": "我们提出了PersonaEval基准，这是首个用于测试LLM评估器是否能可靠地识别人类角色的基准。PersonaEval使用来自小说、剧本和视频转录的人类撰写的对话，挑战模型根据对话情境确定正确的角色身份。我们的实验表明，即使是表现最好的LLM也只能达到约69%的准确性，而人类参与者则达到90.8%的高准确率。这表明可靠评价不仅需要针对具体任务的调优，还需要LLM评估器具备强大的、类似于人类的推理能力。", "conclusion": "这项研究表明，要实现可靠的角色扮演评价，LLM评估器不仅需要特定任务的调优，还需要具备强大的、类似人类的推理能力。我们已发布了PersonaEval基准，网址为this https URL。"}
{"llm_update_time": "20250816", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.10015", "html_url": "https://arxiv.org/abs/2508.10015", "title": "RealTalk-CN: 一种包含跨模态交互分析的现实中文语音-文本对话基准", "title_en": "RealTalk-CN: A Realistic Chinese Speech-Text Dialogue Benchmark With Cross-Modal Interaction Analysis", "authors": "Enzhi Wang,Qicheng Li,Shiwan Zhao,Aobo Kong,Jiaming Zhou,Xi Yang,Yequan Wang,Yonghua Lin,Yong Qin", "background": "近年来，大型语言模型（LLMs）在多模态处理方面取得了显著进展，包括端到端的语音基础上的语言模型，使其能够进行自然交互并在任务导向对话（TOD）系统中执行特定任务。然而，现有TOD数据集主要是基于文本的，缺少用于评估基于语音的LLMs鲁棒性的实际语音信号。此外，现有的语音TOD数据集主要以英语为主，缺乏诸如语音脱节和说话者变化等关键方面。", "innovation": "为了填补这些空白，我们介绍了RealTalk-CN，这是首个包含中文、多轮对话、多领域语音-文本双重模态TOD数据集，包含5400场对话（6万个单元格，150小时），并进行了语音-文本注释。RealTalk-CN记录了多样化的对话情景，注释了自发的语音脱节，确保全面涵盖了真实世界的对话复杂性。此外，我们提出了一个新的跨模态聊天任务，能够真实模拟真实的用户交互场景，允许在语音和文本模态之间动态切换。", "conclusion": "我们的评估涵盖了对语音脱节的鲁棒性、对说话者特征的敏感度以及跨域性能。广泛的实验验证了RealTalk-CN的有效性，为中文语音基LLM研究奠定了坚实的基础。"}
{"llm_update_time": "20250816", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.10020", "html_url": "https://arxiv.org/abs/2508.10020", "title": "FedCoT：在联邦学习环境中的高效大型语言模型推理增强", "title_en": "FedCoT: Communication-Efficient Federated Reasoning Enhancement for Large Language Models", "authors": "Chuan Li,Qianyi Zhao,Fengran Mo,Cen Chen", "background": "在联邦学习环境下增强大型语言模型的推理能力依然是一个挑战，特别是在保持性能提升的同时满足严格的计算、通信及隐私限制。尤其是在医疗保健领域，涵盖临床、运营和面向患者的决策不仅需要准确的输出，还需要具有良好解释性、可追踪的推理过程以保证安全、责任和合规性。传统的联邦调优方法主要针对答案的准确性进行优化，忽视了推理质量的需求，使得自然语言生成的理解链（CoT）能力依赖于模型内在的预训练能力。现有的改善推理的方法通常依赖于隐私泄露的知识精简方法，来自集中模型的数据。此外，传统的联邦调优在大型语言模型上的通信开销仍然很大。", "innovation": "我们通过提出FedCoT（联邦推理理解链），一种专为联邦设置设计的创新框架来解决上述问题。FedCoT利用轻量级的理解链增强机制：本地模型生成多个推理路径，紧凑的辨析器动态选择最有希望的一个。该方法提高了推理的准确性和鲁棒性，同时提供了至关重要的解释能力。通过采用改进的聚合方法，基于先进的LoRA模块堆叠，并结合客户端分类器意识，实现了跨不同客户端噪音清除的无损聚合。", "conclusion": "全面的医疗推理任务实验表明，FedCoT在严格的资源预算下显著提升了客户端推理性能，同时完全保持了数据隐私。"}
{"llm_update_time": "20250816", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.10019", "html_url": "https://arxiv.org/abs/2508.10019", "title": "通过问题空间映射解耦理解与推理以增强小型模型的推理能力", "title_en": "Decoupling Understanding from Reasoning via Problem Space Mapping for Small-scale Model Reasoning", "authors": "Li Wang,Changhao Zhang,Zengqi Xiu,Kai Lu,Xin Yu,Kui Zhang,Wenjun Wu", "background": "尽管大型语言模型（LLMs）的推理能力得到了显著的提升，但如何提升小型语言模型（SLMs，例如模型参数量小于等于1.5B）的推理能力仍然存在挑战。主要难点在于自然语言的高度复杂性和多样性：看似等价的问题往往以多种表面形式出现，且常常被冗余或分散注意力的细节所掩盖。这给SLMs带来了双重负担：它们不仅要从复杂的语言输入中提取核心问题，还要基于这种理解进行推理。这种复杂的和噪声较大的问题空间妨碍了优化，尤其是对于容量有限的模型来说。", "innovation": "本文提出了一种新的框架，通过将自然语言问题映射到一个规范问题空间（即，语义简化但表达能力强的领域），将理解与推理解耦。在此框架下，本文提出了DURIT（Decoupled Understanding from Reasoning via Iterative Training，通过迭代训练解耦理解与推理）算法，该算法分成三步迭代进行：（1）通过强化学习将自然语言问题映射到规范问题空间，（2）通过自我蒸馏对推理轨迹进行对齐，（3）在问题空间中训练推理策略。在整个过程中，映射器和推理器是在交替循环中共同训练的。实验表明，DURIT显著提高了SLMs在领域内和领域外数学和逻辑推理任务上的性能。此外，DURIT还增强了推理的稳健性，验证了解耦理解与推理的有效性策略能够增强SLMs的能力。", "conclusion": "通过DURIT方法的实验结果，本文证明了通过将理解与推理解耦，能够显著提高小型语言模型（SLMs）的推理能力及其稳健性，从而为提升SLMs的性能提供了新的策略。"}
{"llm_update_time": "20250816", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.10025", "html_url": "https://arxiv.org/abs/2508.10025", "title": "实时生成式人工智能检测和解释产后抑郁", "title_en": "Detecting and explaining postpartum depression in real-time with generative artificial intelligence", "authors": "Silvia García-Méndez,Francisco de Arriba-Pérez", "background": "产后抑郁症（PPD）是许多母亲在分娩后面临的一种严重情况，对她们的身心安康产生了显著的影响。因此，早期快速检测PPD及其相关风险因素对于及时评估和干预至关重要，这需要专门的预防程序。现有的许多方法存在检测不及时、解释不清等问题。", "innovation": "提出了一种智能PPD筛查系统，结合自然语言处理（NLP）、机器学习（ML）和大型语言模型（LLMs），用于低成本、实时、无创的口语分析，解决了预测的黑箱问题，通过LLMs与可解释的ML模型（如决策树算法）结合使用特征重要性和自然语言解释预测结果。", "conclusion": "该方案在PPD检测上的准确率达到90%以上，所有评估指标都优于文献中的竞争方法，有助于实现对PPD及其相关风险因素的快速检测，从而进行及时和适当的评估与干预。"}
{"llm_update_time": "20250816", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.10022", "html_url": "https://arxiv.org/abs/2508.10022", "title": "在具有可证明风险控制的多项选择题回答任务中使用明性检验", "title_en": "Conformal P-Value in Multiple-Choice Question Answering Tasks with Provable Risk Control", "authors": "Yuanchang Ye", "background": "大型语言模型（LLMs）在学科问答场景中的应用越来越广泛，但它们存在幻觉和非事实生成的问题，这严重损害了响应的可靠性。虽然现有的齐贯预测（CP）框架提供了统计严谨的边缘覆盖保证，而显著性检验也提供了稳健的统计保证，但这两者的协同整合尚未探索。", "innovation": "提出了一种增强型齐贯预测框架，通过自一致性重新采样的MCQA响应结合p值计算与一致性评分，实现幻觉和事实不准确性的缓解。该方法通过计算选项频率来解决LLMs的黑盒性质，并利用经验获得的p值进行假设检验（$H_0$），从而构建预测集。", "conclusion": "在MMLU和MMLU-Pro基准上的实验结果显示，增强型齐贯预测实现了用户指定的经验覆盖率，并随着风险水平（$\\alpha$）的增加，测试集平均预测集大小（APSS）单调减少，验证了APSS作为有效不确定性度量的有效性。这项工作为高风险问答应用中LLM的信任部署提供了一种原则性的统计框架。"}
{"llm_update_time": "20250816", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.10024", "html_url": "https://arxiv.org/abs/2508.10024", "title": "RTTC: 奖励引导的合作测试时计算", "title_en": "RTTC: Reward-Guided Collaborative Test-Time Compute", "authors": "J. Pablo Muñoz,Jinjie Yuan", "background": "测试时计算（TTC）已成为提升大型语言模型（LLMs）在推理阶段表现的强大范式，利用诸如测试时训练（TTT）和检索增强生成（RAG）等策略。然而，对于不同查询，最优化的TTC策略会有所不同，不加甄别的应用TTC策略会带来巨大的计算开销。", "innovation": "本文提出了奖励引导的测试时计算（RTTC），这是一种新颖的框架，通过预训练的奖励模型适应性地选择每个查询最有效的TTC策略，从而在不同领域和任务中最大化下游准确性。RTTC工作在分布式服务器-客户端架构中，仅在必要时从远程知识库检索相关样本并在客户端设备上应用RAG或轻量级微调。为了进一步减少冗余计算，提出了查询状态缓存，该机制使在检索和适应层面有效重用历史查询状态。", "conclusion": "在多个LLM和基准测试中进行的大量实验表明，RTTC在准确性和高效性方面均优于传统的RAG或TTT。这验证了适应性和奖励引导的TTC选择的必要性，并证明了RTTC对可扩展、高性能语言模型适应的潜力。"}
{"llm_update_time": "20250816", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.09299", "html_url": "https://arxiv.org/abs/2508.09299", "title": "通过分布式机器学习和区块链基模验证实现的去中心化天气预报", "title_en": "Decentralized Weather Forecasting via Distributed Machine Learning and Blockchain-Based Model Validation", "authors": "Rilwan Umar,Aydin Abadi,Basil Aldali,Benito Vincent,Elliot A. J. Hurley,Hotoon Aljazaeri,Jamie Hedley-Cook,Jamie-Lee Bell,Lambert Uwuigbusun,Mujeeb Ahmed,Shishir Nagaraja,Suleiman Sabo,Weaam Alrbeiqi", "background": "天气预报在灾害预防、农业和资源管理中起着至关重要的作用，但当前的集中式预报系统正受到安全漏洞、扩展性限制和单点故障的制约。", "innovation": "本文提出了一种结合联邦学习与区块链技术的去中心化天气预报框架。该框架通过保证本地数据不暴露、提高隐私性以及减少数据传输开销实现协作模型训练；利用以太坊区块链确保模型更新的透明性和可靠性；并通过基于声誉的投票机制和星际文件系统（IPFS）提高系统的安全性和效率。", "conclusion": "实验结果表明，这种方法不仅提高了预报精度，还增强了系统的弹性和可扩展性，使其成为部署在安全关键的现实环境中的可行选择。"}
{"llm_update_time": "20250816", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.10026", "html_url": "https://arxiv.org/abs/2508.10026", "title": "SABER：可切换且平衡训练以实现高效大型语言模型推理", "title_en": "SABER: Switchable and Balanced Training for Efficient LLM Reasoning", "authors": "Kai Zhao,Yanjun Zhao,Jiaming Song,Shien He,Lusheng Zhang,Qiang Zhang,Tianjiao Li", "background": "大型语言模型（LLMs）在处理复杂任务时借助链式思考推理取得了显著的准确性，但当这些模型被均匀应用到所有问题时，却遭受了高昂的推理成本和延迟。", "innovation": "提出了一种基于强化学习框架SABER（Switchable and Balanced Training for Efficient LLM Reasoning），使LLMs获得用户可控制的基于token预算的推理能力。SABER框架通过预设的预算层级和系统提示及长度敏感的奖励来指导模型遵循其指定的预算。同时，SABER框架还引入了无思考示例，以确保模型在关闭显式推理时仍然可靠。并且，该框架支持四类不同的推理模式：无思考、快速思考、核心思考和深度思考，从而使延迟和推理深度之间实现灵活的权衡。", "conclusion": "广泛的实验证明，SABER框架在严格的预算下实现了高精度、优雅的性能退化和有效的跨尺度和跨域泛化。特别地，SABER-FastThink将推理长度减少了65.4%，并在MATH基准测试上比基础模型取得了3.6%的精度提升。"}
{"llm_update_time": "20250816", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.10032", "html_url": "https://arxiv.org/abs/2508.10032", "title": "思考的成本：大规模语言模型中增加的 Jailbreak 风险", "title_en": "The Cost of Thinking: Increased Jailbreak Risk in Large Language Models", "authors": "Fan Yang", "background": "长期以来，思考模式被视为大型语言模型中最有价值的功能之一。然而，研究发现，具有思考模式的模型更容易受到 Jailbreak 攻击。通过对多种模型的评估发现，攻击思考模式的成功率高于非思考模式。分析发现，对于教育目的和过度长时间的思考是成功攻击数据的特征，而且当模型清楚知道问题有害时，仍然会给出有害的回答。", "innovation": "本文提出了一种名为安全思考干预的方法，通过在提示中添加“特定思考标记”来显式地指导模型的内部思考过程，以降低具有思考模式的模型的攻击成功率。", "conclusion": "研究表明，安全思考干预可以显著降低具有思考模式的大规模语言模型的攻击成功率。"}
{"llm_update_time": "20250816", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.10028", "html_url": "https://arxiv.org/abs/2508.10028", "title": "PREF: 在大语言模型中无参考评价个性化文本生成", "title_en": "PREF: Reference-Free Evaluation of Personalised Text Generation in LLMs", "authors": "Xiao Fu,Hossein A. Rahmani,Bin Wu,Jerome Ramos,Emine Yilmaz,Aldo Lipani", "background": "个性化文本生成对以用户为中心的信息系统至关重要，但大多数评估方法忽略了用户的个体差异。现有方法在评估个性化文本生成时，通常需要预定义的个性化参考，这限制了其适用性和实用性，忽视了用户特定需求。\n", "innovation": "提出了一个名为PREF（个性化参考无关评价框架）的新框架，该框架在不依赖个性化参考的情况下，同时评估生成内容的一般质量和用户特定的契合度。PREF采用了一个三步流程：首先，覆盖阶段利用大型语言模型生成全面、查询特定的指导方针；其次，偏好阶段使用目标用户的特征、显性和隐性偏好以及上下文信息重新排序并增补这些因素，生成个性化的评价标准；最后，评价阶段使用大型语言模型作为裁判来根据这个评价标准评估候选答案，确保基本充足性并捕捉主观优先级。\n", "conclusion": "实验表明，PREF 在基准测试 PrefEval 上优于现有基准，特别是在隐含偏好跟随任务上表现更佳，这不仅提高了准确性和校准度，而且更好地与人类判断吻合。通过促进可扩展、可解释且用户对齐的评价，PREF 为个性化语言生成系统的可靠评估和开发奠定了基础。\n"}
{"llm_update_time": "20250816", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.10029", "html_url": "https://arxiv.org/abs/2508.10029", "title": "Latent Fusion Jailbreak: Blending Harmful and Harmless Representations to Elicit Unsafe LLM Outputs", "title_en": "Latent Fusion Jailbreak: Blending Harmful and Harmless Representations to Elicit Unsafe LLM Outputs", "authors": "Wenpeng Xing,Mohan Li,Chunqiang Hu,Haitao XuNingyu Zhang,Bo Lin,Meng Han", "background": "本文探讨了大型语言模型（LLMs）在多语言任务上的出色能力，但这些模型容易受到规避其安全对齐的‘监牢逃脱’攻击。这类攻击利用模型的漏洞，诱使其生成受禁止的响应。传统的‘监牢逃脱’攻击基于恶意查询对和良性查询对之间的相似性，通过梯度引导的插值操作来生成攻击性的输出，尤其是在关键层和关键标记处。", "innovation": "本文提出了一个名为‘潜在融合逃逸’(LFJ)的新一代代表攻击方法。LFJ 通过巧妙地混合有害查询对和良性查询对的潜在表示来诱使模型产生不安全的输出。该方法选择具有高主题和句法相似性的查询对，通过梯度引导的插值操作在关键层和标记上进行操作，并通过优化策略平衡攻击成功率、输出流畅性和计算效率。实验证明，LFJ 在多种模型上（包括Vicuna和LLaMA-2）的平均攻击成功率高达94.01%，显著优于现有方法。通过对抗性训练防御措施，能有效减少攻击成功率超过80%，而不会损害模型对非恶意输入的表现。", "conclusion": "本研究验证了查询对选择、隐藏状态插值以及优化策略对LFJ效果的重要性。对抗性训练防御措施通过生成插值样本来微调模型，成功遏制了攻击，同时保持了模型在处理良性输入时的性能。"}
{"llm_update_time": "20250816", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.10030", "html_url": "https://arxiv.org/abs/2508.10030", "title": "对于调整黑盒大型语言模型的推理感知式提示优化", "title_en": "Inference-Aware Prompt Optimization for Aligning Black-Box Large Language Models", "authors": "Saaduddin Mahmud,Mason Nakamura,Kyle H. Wray,Shlomo Zilberstein", "background": "提示优化方法在对齐黑盒大型语言模型（LLMs）方面展示了显著的效果。同时，诸如Best-of-N Sampling和Majority Voting等推理扩展策略也被证明可以通过在计算上做权衡来增强对齐和性能。然而，现有的提示优化方法并不考虑推理策略；也就是说，它们在部署时并未根据所使用的推理策略来优化提示。这形成了一个重要的方法学缺口，因为我们实证和理论分析表明，这两种范式之间存在很强的相互作用。此外，研究发现，用户在多个目标和推理预算之间进行权衡的偏好在选择提示和推理配置时起着重要作用。因此，为了填补这一缺口，我们引入了一种新的命名为IAPO（推理感知式提示优化）的统一框架，该框架会联合优化提示和推理规模，并意识到推理预算和不同的任务目标。我们随后开发了一个固定预算训练算法，称为PSST（提示规模通过逐步修剪），并分析了在有限预算下对错误概率的保证。最后，我们在六个不同任务上评估了PSST的有效性，包括多目标文本生成和推理，并通过提示优化展示了在对齐黑盒LLMs时纳入推理感知的重要性。", "innovation": "我们引入了名为IAPO（推理感知式提示优化）的统一框架，该框架会联合优化提示和推理规模，并意识到推理预算和不同的任务目标。同时，我们开发了一个固定预算训练算法，称为PSST（提示规模通过逐步修剪），并分析了在有限预算下对错误概率的保证。", "conclusion": "我们在六个不同任务上评估了PSST的有效性，并通过提示优化展示了在对齐黑盒LLMs时纳入推理感知的重要性。"}
{"llm_update_time": "20250816", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.10000", "html_url": "https://arxiv.org/abs/2508.10000", "title": "基于知识的自动化生成文本合成以改进文本分类的AutoGeTS", "title_en": "AutoGeTS: Knowledge-based Automated Generation of Text Synthetics for Improving Text Classification", "authors": "Chenhao Xue,Yuanzhe Jin,Adrian Carrasco-Revilla,Joyraj Chakraborty,Min Chen", "background": "在开发面向实际应用的文本分类模型时，面对的主要挑战之一是难以收集足够的各类文本数据。本文通过利用大语言模型（LLMs）生成合成数据，并使用这些数据来提高模型性能，而不是等待更多的真实数据收集和标注。", "innovation": "本文提出了一个自动化流水线AutoGeTS，通过搜索能产出更有效的合成数据的输入示例来生成文本合成数据，增强了通过大语言模型改进文本分类模型的效果。研究了三种搜索策略，基于实验结果设计了一种集成算法，根据不同类别的特点选择最优的搜索策略。", "conclusion": "本文提出的集成方法相较于每种搜索策略单独使用时，在使用大语言模型改进文本分类模型方面表现出更优的效果。"}
{"llm_update_time": "20250816", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.10142", "html_url": "https://arxiv.org/abs/2508.10142", "title": "多轮谜题：评估LLMs在互动推理和战略性对话中的表现", "title_en": "Multi-Turn Puzzles: Evaluating Interactive Reasoning and Strategic Dialogue in LLMs", "authors": "Kartikeya Badola,Jonathan Simon,Arian Hosseini,Sara Marie Mc Carthy,Tsendsuren Munkhdalai,Abhimanyu Goyal,Tomáš Kočiský,Shyam Upadhyay,Bahare Fatemi,Mehran Kazemi", "background": "大语言模型（LLMs）擅长解决有明确完整陈述的问题，但在复杂的环境或互动任务中往往表现不佳，而这些任务在大多数真实世界场景中都很常见。这凸显了开发能有效进行逻辑一致多轮对话、寻求信息并处理不完整数据的LLMs的必要性。本文介绍了一个新的基准，包含一系列多轮任务，旨在测试特定的推理能力、互动对话能力和信息检索能力，这些任务具有确定的评分机制，无需人工干预。评估前沿模型在该基准上的表现揭示了改进的巨大潜力。研究表明，大多数错误主要来自于糟糕的指令遵循、推理失败和不良规划。该基准为了解当前LLMs在处理复杂互动场景时的优势和劣势，提供有价值的见解，并为未来提高这些关键能力的研究提供了坚实平台。", "innovation": "提出了一个包含多轮任务的新型基准，用于测试LLMs的特定推理能力、互动对话能力和信息检索能力，并且这些任务具有确定的评分机制。评估前沿模型在该基准上的表现揭示了改进的巨大潜力，指出了改进的主要方向（糟糕的指令遵循、推理失败和不良规划）。这个基准为提高LLMs处理复杂、互动场景的能力提供了有力支持。", "conclusion": "该基准提供了对当前LLMs处理复杂和互动场景的优势和限制的理解，并为未来的研究提供了坚固的平台，旨在提高这些关键能力。"}
{"llm_update_time": "20250816", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.10018", "html_url": "https://arxiv.org/abs/2508.10018", "title": "任意名字的玫瑰闻起来一样香：大型语言模型中的范畴同伦理论", "title_en": "A Rose by Any Other Name Would Smell as Sweet: Categorical Homotopy Theory for Large Language Models", "authors": "Sridhar Mahadevan", "background": "自然语言充满了表面不同的表达，但含义相同，例如“Charles Darwin wrote”和“Charles Darwin is the author of”。大型语言模型（LLMs）通常不会为此类句子生成相同的下一标记概率。因此，研究人员探索了经验上的工作来解决这一问题，比如使用最近邻方法估算句子相似度。这项研究以更抽象的方式解决了这一问题，引入了LML范畴同伦框架。", "innovation": "论文引入了一种LML（Large Language Model）范畴同伦框架，通过这一框架来捕捉LML中等效重述之间的“弱等价”，从而更好地处理语言中大量等价重述的问题，提高了模型表示句子的概率的一致性。", "conclusion": "论文从更高阶代数K理论到模型范畴详细介绍了范畴同伦理论在LML中的应用，提出了这一领域过去的半个多世纪里开发的强有力的理论成果。"}
{"llm_update_time": "20250816", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.10175", "html_url": "https://arxiv.org/abs/2508.10175", "title": "评估机器翻译难度", "title_en": "Estimating Machine Translation Difficulty", "authors": "Lorenzo Proietti,Stefano Perrella,Vilém Zouhar,Roberto Navigli,Tom Kocmi", "background": "机器翻译的质量在某些情况下已经达到了近乎完美的水平，高质量的输出使得区分最先进的模型变得困难，并难以识别未来改进的领域。自动识别机器翻译系统难以处理的文本具有潜力，可以开发出更具区分力的评估方法并引导未来的研究。", "innovation": "本文明确规定了翻译难度估计的任务，并基于预期的翻译质量定义文本的难度。引入了一种新的度量标准来评估难度估计器，并使用该标准评估基线方法和新型方法。通过使用这些难度估计器构建更具有挑战性的机器翻译基准，证明了难度估计器的实际用途。结果显示，专用模型（称为Sentinel-src）在难度估计中优于基于启发式的方法（例如词汇稀有性或句法复杂性）以及LLM-as-a-judge方法。发布了两种改进的难度估计模型，Sentinel-src-24和Sentinel-src-25，可用于扫描大量文本并选择最有可能挑战当代机器翻译系统的文本。", "conclusion": "研究表明，专用模型（Sentinel-src）在难度估计方面优于其他基于启发式或LLM的方法。还提出了两种改进的难度估计模型，以帮助评估大量文本，并挑选出能够挑战当前机器翻译系统的文本。"}
{"llm_update_time": "20250816", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.10161", "html_url": "https://arxiv.org/abs/2508.10161", "title": "LaaJMeter: 一种Laaj评估框架", "title_en": "LaajMeter: A Framework for LaaJ Evaluation", "authors": "Gal Amram,Eitan Farchi,Shmulik Froimovich,Raviv Gal,Avi Ziv", "background": "大型语言模型（LLMs）在自然语言处理任务中被用作评估者，这种范式被称为Laaj。尽管Laaj在通用领域效果显著，但在特定领域中却面临显著挑战，因为这些领域缺乏标注数据，专家评估成本高昂。在这种情况下，通常使用未在特定领域中验证过的评价指标进行元评估。这使得难以确定哪些指标能够有效识别Laaj的质量，进一步而言，难以确定表明足够评估者性能的阈值。因此，研究者引入了LaajMeter，模拟了一个基于框架，通过生成代表虚拟模型和判断者的合成数据，进行在真实场景下的系统评价指标分析。该框架帮助从业者验证和调优Laaj，以适应特定评估任务：他们可以通过测试判断者质量对不同指标的敏感度来检验其指标是否能区分更好的或更差的虚拟Laaj，同时估算合适的评价者表现阈值。研究展示了LaajMeter在涉及遗留编程语言的代码翻译任务中的实用性，特别强调不同指标相对于评价者质量的敏感度差异，并指出常用指标的局限性和基于原理的指标选择的重要性。LaajMeter为资源有限的环境中评估Laaj提供了一种可扩展和可扩展的解决方案，有助于确保自然语言处理中评估的可靠性和可复现性贡献.", "innovation": "LaajMeter提供了一种基于模拟的解决方案，用于在资源有限的环境中评估Laaj。通过生成代表虚拟模型和判断者的合成数据，它可以系统地评估评价指标在其实际情况下的适用性，从而帮助从业者验证和调优Laaj，特别是检验其指标能否有效区分开好与差的Laaj，并估算评价者表现的适当阈值。这不仅展示了常用评价指标的局限性，还突显了基于原理的评价指标选择的重要性", "conclusion": "LaajMeter为在稀缺资源环境下评估Laaj提供了一种高效和实用的方法，有助于确保自然语言处理中评估的可追溯性和可靠性。"}
{"llm_update_time": "20250816", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.10027", "html_url": "https://arxiv.org/abs/2508.10027", "title": "LLMCARE：通过生成合成数据增强的Transformer模型进行阿尔茨海默病检测", "title_en": "LLMCARE: Alzheimer's Detection via Transformer Models Enhanced by LLM-Generated Synthetic Data", "authors": "Ali Zolnour,Hossein Azadmaleki,Yasaman Haghbin,Fatemeh Taherinezhad,Mohamad Javad Momeni Nezhad,Sina Rashidi,Masoud Khani,AmirSajjad Taleban,Samin Mahdizadeh Sani,Maryam Dadkhah,James M. Noble,Suzanne Bakken,Yadollah Yaghoobzadeh,Abdol-Hossein Vahabie,Masoud Rouhizadeh,Maryam Zolnoori", "background": "阿尔茨海默病及相关痴呆（ADRD）影响着约五百万美国老年人，但其中一半以上未被诊断。基于语音的自然语言处理（NLP）通过语言标记检测早期认知衰退提供了一种有前景且可扩展的方法。", "innovation": "该研究开发并评估了一种筛查管道，将变换器嵌入与手工构建的语言特征融合，测试了使用大型语言模型（LLMs）生成的合成语音数据增强技术，并对比了单模态和多模态LLM分类器在ADRD检测中的表现。", "conclusion": "融合模型达到了F1 = 83.3（AUC = 89.5），优于仅基于语言或变换器的基线。使用2倍MedAlpaca-7B合成语音增强训练数据可提高F1值至85.7。模型微调显着提升了单模态LLM分类器的表现，而现有的一些多模态模型表现较低。合成语音和真实语音间的分布相似度影响了性能提升的效果。"}
{"llm_update_time": "20250816", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.10180", "html_url": "https://arxiv.org/abs/2508.10180", "title": "预训练大语言模型和视觉语言模型高效前向数据估值方法", "title_en": "Efficient Forward-Only Data Valuation for Pretrained LLMs and VLMs", "authors": "Wenlong Deng,Jiaming Zhang,Qi Zeng,Christos Thrampoulidis,Boying Gong,Xiaoxiao Li", "background": "量化单个训练样本的影响对于提升大语言模型（LLMs）和视觉语言模型（VLMs）的透明度和问责制至关重要。然而，现有的数据估值方法通常依赖于海森矩阵信息或模型重训，这使得它们在处理拥有数亿参数的模型时计算成本高昂。现有的方法往往涉及复杂的梯度计算，这对于大数据量模型来说非常消耗资源。因此，研究人员们一直在探索更加高效且较少资源消耗的数据估值方法。", "innovation": "本文提出了一个称为For-Value的前向仅数据估值框架，它可以为LLMs和VLMs提供可扩展且高效的单样本影响估计。通过利用现代基础模型中的丰富表示，For-Value利用单一前向传播计算影响评分，从而消除了昂贵的梯度计算需求。理论分析表明，For-Value能够通过捕捉训练和验证样本之间的隐藏表示对齐和预测误差来准确估计单个样本的影响。实验结果表明，无论是在识别影响较大的微调示例还是在检测错误标记的数据方面，For-Value的表现都优于基于梯度的方法", "conclusion": "本文提出的For-Value框架提供了一种高效计算大规模预训练语言和视觉语言模型中数据影响的方法，使得数据估值过程更加高效且节省计算资源。"}
{"llm_update_time": "20250816", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.10036", "html_url": "https://arxiv.org/abs/2508.10036", "title": "审视然后学习：由反省困惑引导的信息抽取主动提示", "title_en": "Reflect then Learn: Active Prompting for Information Extraction Guided by Introspective Confusion", "authors": "Dong Zhao,Yadong Wang,Xiang Chen,Chenxi Wang,Hongliang Dai,Chuanxing Geng,Shengzhong Zhang,Shaoyuan Li,Sheng-Jun Huang", "background": "大型语言模型（LLMs）在少样本信息抽取（Few-shot Information Extraction, IE）方面显示出巨大的潜力，但其性能高度依赖于上下文示例的选择。传统策略往往难以提供有效的指导，因为它们忽视了一种关键的模型失误来源：不仅源自语义内容，还源自生成IE任务所需的良好格式结构。现有方法无法解决这一问题。", "innovation": "该文提出了“审视然后学习”（Active Prompting for Information Extraction，APIE），这是一种基于反省困惑的原则的主动提示框架。这种方法通过一种双重不确定性度量帮助LLM评估其自身的困惑，该度量独特地量化了格式不确定性（正确语法生成的难度）和内容不确定性（提取语义的一致性）。通过以这种方法对未标记数据进行评级，框架能够主动选择最具挑战性和信息性的样本作为少样本示例。", "conclusion": "本文综合实验结果表明，该方法在四个基准数据集上均优于强大基线，显著提高了抽取准确性和鲁棒性。工作突出强调了构建有效可靠的结构生成系统时，对模型不确定性进行细致双层分析的关键重要性。"}
{"llm_update_time": "20250816", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.10021", "html_url": "https://arxiv.org/abs/2508.10021", "title": "LATTE：银行客户交易和文本嵌入的学习对齐", "title_en": "LATTE: Learning Aligned Transactions and Textual Embeddings for Bank Clients", "authors": "Egor Fadeev,Dzhambulat Mollaev,Aleksei Shestov,Dima Korolev,Omar Zoloev,Ivan Kireev,Andrey Savchenko,Maksim Makarenko", "background": "从客户历史通信序列学习客户嵌入是金融应用中的关键。大型语言模型提供了一般的世界知识，但直接在长事件序列上使用它们在计算上昂贵且在现实世界流水线中不可行。背景描述了现有技术的局限性。", "innovation": "提出了一种对比学习框架LATTE，该框架将原始事件嵌入与冻结的大语言模型的语义嵌入对齐。行为特征被归约为短提示，由大语言模型嵌入，并通过对比损失作为监督。该方法在计算成本和输入大小上显著优于常规处理完整序列的方法，展示了在实际金融数据集中的优越性能。", "conclusion": "本文方法在实际金融数据集上优于现有技术，对具有延迟敏感性的环境仍具有部署性。"}
{"llm_update_time": "20250816", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.10222", "html_url": "https://arxiv.org/abs/2508.10222", "title": "通过表情预测理解文本情绪", "title_en": "Understanding Textual Emotion Through Emoji Prediction", "authors": "Ethan Gordon,Nishank Kuppa,Rigved Tummala,Sriram Anasuri", "background": "本文项目利用四种深度学习架构（前馈网络、卷积神经网络、变压器和BERT）来从短文本序列预测表情符号，使用TweetEval数据集并通过焦点损失和正则化技术解决类别不平衡问题。", "innovation": "研究通过前馈网络、卷积网络、transformer和BERT等不同架构的方法来探索表情符号预测，提出使用焦点损失和正则化处理类别不平衡，并强调架构选择和超参数调整对情感感知表情预测的重要性。", "conclusion": "研究结果表明，BERT在总体性能上表现最佳，得益于其预训练优势；而卷积神经网络在罕见表情类别的预测上表现更优。这突显了架构选择和超参数调整对提升人机交互的重要性。"}
{"llm_update_time": "20250816", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.10246", "html_url": "https://arxiv.org/abs/2508.10246", "title": "对构建语言托基·波那中的语言变化与变异进行计算分析的方法", "title_en": "A Computational Approach to Analyzing Language Change and Variation in the Constructed Language Toki Pona", "authors": "Daniel Huang,Hyoun-A Joo", "background": "该研究探讨了拥有大约120个核心词汇的构建语言托基·波那的语言变化和变异。采用计算和语料库的方法，研究了诸如词类流动性和及物性等特征，以考察（1）内容词在不同句法位置上的偏好随着时间的变化，以及（2）不同语料库中使用的变化。", "innovation": "通过计算和语料库的方法，研究了构建语言中语言变化和变异的现象，探讨了词类流动性、及物性等特征，揭示了甚至构建的语言系统也会随着社区的使用自然演变，受到社会语言学因素的影响。", "conclusion": "研究表明，社会语言学因素在托基·波那中起作用的方式与自然语言相同，即使是最纯粹的构建语言系统也会随着社区的使用而自然演变。"}
{"llm_update_time": "20250816", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.10186", "html_url": "https://arxiv.org/abs/2508.10186", "title": "PakBBQ：文化适应的问答偏见基准", "title_en": "PakBBQ: A Culturally Adapted Bias Benchmark for QA", "authors": "Abdullah Hashmat,Muhammad Arham Mirza,Agha Ali Raza", "background": "随着大型语言模型（LLMs）在各种应用中被广泛应用，确保它们跨越所有用户社区的公平性是显然必要的。然而，大多数LLMs是在以西方为中心的数据上进行训练和评估的，对低资源语言和地域性背景的关注不足。为了解决这一问题，我们提出了PakBBQ，这是对原始问答偏见基准（BBQ）数据集的跨文化和地区适应扩展，包含超过214种模板，17180对QA问题与答案，涵盖8个类别，包括英语和乌尔都语，共计八个与巴基斯坦相关的偏见维度，确保了这些模型在巴基斯坦语境中的公平性评估是全面且有针对性的。", "innovation": "PakBBQ通过对原始BBQ数据集的跨文化和地区适应扩展，包含大量针对巴基斯坦本土语言（乌尔都语）和文化背景的偏差维度，有效地填补了现有研究中对低资源语言和层次语境的关注不足。通过多种多语言LLMs的评估，展示了在含糊和明确的情况中，以及正向和负向问题语境下对偏见的改善效果。", "conclusion": "研究通过实验证明了在含模糊和明确语境下进行偏差补救的平均准确率提升达到了12%，并且乌尔都语相比英语表现出更强的反偏见行为。此外，负向化问题框架能够显著减少刻板印象的回答。这些发现强调了在低资源环境中的偏差缓解需要采用上下文化基准和简单的提示工程技术。"}
{"llm_update_time": "20250816", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.10295", "html_url": "https://arxiv.org/abs/2508.10295", "title": "LLM 提示词的归纳偏置提取和匹配", "title_en": "Inductive Bias Extraction and Matching for LLM Prompts", "authors": "Christian M. Angel,Francis Ferraro", "background": "提示工程的活跃研究领域表明，LLM 对提示词文字段的小变化非常敏感。这主要是由于LLM内在的归纳偏置。通过将LLM的输出作为部分提示词，可以使提示词更容易符合模型的归纳偏置，从而提高LLM分类和排名任务的成绩。已有研究表明，使用这种归纳偏置提取和匹配策略，可以使LLM的分类和排名任务的成绩分别提高19%和27%。", "innovation": "提出了归纳偏置提取和匹配策略，该策略利用LLM的输出，创建更符合模型归纳偏置的提示词，从而提高LLM在分类和排名任务上的表现。通过实验证明，这种策略在LLM分类和排名任务上分别提高了19%和27%的成绩。", "conclusion": "通过归纳偏置提取和匹配策略，可以显著提高LLM在分类和排名任务上的表现。这一发现为提示工程领域提供了新的视角，并为提高LLM性能提供了一种新颖的方法。"}
{"llm_update_time": "20250816", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.10308", "html_url": "https://arxiv.org/abs/2508.10308", "title": "ReviewRL: 使用RL实现自动化科学审稿", "title_en": "ReviewRL: Towards Automated Scientific Review with RL", "authors": "Sihang Zeng,Kai Tian,Kaiyan Zhang,Yuru wang,Junqi Gao,Runze Liu,Sa Yang,Jingxuan Li,Xinwei Long,Jiaheng Ma,Biqing Qi,Bowen Zhou", "background": "同行评审对于科学进步至关重要，但正面临日益增加的手稿提交量和审稿人疲劳的挑战。现有的自动化审稿方法在事实准确性、评级一致性和分析深度方面存在困难，通常生成浅薄或通用的反馈，缺乏高质量人类审稿的洞察力。", "innovation": "本文介绍了一种使用强化学习(ReviewRL)生成全面且基于事实的科学论文审稿的新方法。该方法结合了(1)通过纳入相关科学文献的arXiv-MCP检索增强上下文生成管道，(2)监督微调以建立基础的审稿能力，以及(3)使用复合奖励函数的强化学习过程，该过程同时提升了审稿质量和评级准确性。实验结果表明，ReviewRL在ICLR 2025论文上的表现显著优于现有方法，无论是基于规则的指标还是基于模型的质量评估。", "conclusion": "ReviewRL为基于强化学习的自动批评生成奠定了基础框架，在科学发现领域显示了在未来开发该领域的潜力。ReviewRL的实现将发布在GitHub上。"}
{"llm_update_time": "20250816", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.10226", "html_url": "https://arxiv.org/abs/2508.10226", "title": "使用大型语言模型测量在患精神分裂症风险中的症状严重程度", "title_en": "Using Large Language Models to Measure Symptom Severity in Patients At Risk for Schizophrenia", "authors": "Andrew X. Chen,Guillermo Horga,Sean Escola", "background": "对于临床高风险（CHR）的患者，尤其是那些有精神分裂症高风险的患者，需要对其进行密切的症状监测以指导合适的治疗。现有的BPRS（简短精神病评定量表）是一种有效的研究工具，用于测量精神分裂症和其他幻觉障碍患者的症状，但由于其需要进行长时间的结构化访谈，它在临床实践中并不常用。因此，如何有效、高效地评估CHR患者的精神症状成为一个亟待解决的问题。本研究利用大型语言模型（LLMs）从409名来自加速药物开发-精神分裂症（AMP-SCZ）组的CHR患者的临床访谈记录中预测BPRS分数，以探索LLMs是否能够提供一种有效、准确的方法来评估CHR患者的症状，避免了传统访谈长耗时的问题。", "innovation": "本研究利用大型语言模型（LLMs）来预测BPRS评分，成功地将LLMs应用于临床高风险患者的精神症状评估中。尽管临床访谈并不是特别为测量BPRS设计的，但LLMs的预测表现与真实评估高度一致（中位一致性：0.84，ICC：0.73），接近人类评估者间的可靠性和一致性。此外，实验还展示出LLMs在评估多语言的精神症状方面的潜力（中位一致性：0.88，ICC：0.70），并能够通过一次性或少量示例学习整合纵向信息来提高准确度。这表明LLMs有可能成为标准和改进CHR患者评估的有效工具。", "conclusion": "研究结果表明，利用大型语言模型可以准确、有效地预测CHR患者的精神症状严重程度，从而有助于临床实践中的症状监控与治疗选择。此外，这种新的方法还具有跨语言应用的潜力，并能够整合纵向数据进一步提高评估的准确性，展示出在精神分裂症高风险患者评估方面的实际应用价值。"}
{"llm_update_time": "20250816", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.10192", "html_url": "https://arxiv.org/abs/2508.10192", "title": "大型语言模型（LLM）中忠实性幻觉和不一致检测的提示-响应语义偏差度量", "title_en": "Prompt-Response Semantic Divergence Metrics for Faithfulness Hallucination and Misalignment Detection in Large Language Models", "authors": "Igor Halperin", "background": "随着大型语言模型（LLMs）的普及，模型出现了幻觉问题，即生成不事实、无意义或不忠实的文本。现有的检测方法，如语义熵，通过测量单一固定提示的答案多样性来检测任意性。但是，这些方法缺乏深度，无法全面检测模型响应的一致性与语义对齐度。本文提出了语义分歧度量（SDM），一种新型的轻量级框架，用于检测忠实性幻觉，即模型响应与输入上下文严重偏离的情况。SDM通过测量响应在不同提示及其同义重述之间的不一致性，来提供更深刻的任意性评估。该方法通过联合聚类句子嵌入来创建提示和答案的共享主题空间，并通过主题共现热图可视化用户-机器对话。最后，使用信息理论度量计算响应和提示之间的语义分歧。", "innovation": "本文提出了语义分歧度量（SDM），一种新颖的轻量级框架，用于检测大型语言模型中的忠实性幻觉。SDM通过测量响应的一致性，不仅跨多个答案，也跨多个同义提示，来检测对用户查询的离散和语义错位响应。SDM进一步引入了Kullback-Leibler（KL）发散作为语义探索的关键指标，并将其与Jensen-Shannon发散和Wasserstein距离结合到语义盒子诊断框架中，用于分类LLM的响应类型，特别是危险且自信的离散现象。此外，SDM通过创建共享主题空间和可视化热图，为用户提供了更直观的对话理解工具，从而解决了现有的方法未能全面解决的深度任意性和不一致性问题。", "conclusion": "语义分歧度量（SDM）为大型语言模型的忠实性幻觉检测提供了一种新的、全面的方法，通过对提示和响应的深度分析，提高了模型响应的一致性和语义对齐度的评估能力。SDM不仅结合了多种信息论度量，还引入了语义探索指标，这对于区分不同生成行为至关重要。该框架为LLM的交互动态提供了新的诊断工具，并有助于更好地理解和处理语言模型的错误行为。"}
{"llm_update_time": "20250816", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.10355", "html_url": "https://arxiv.org/abs/2508.10355", "title": "通过强化学习使Qwen3具备使用韩语的能力", "title_en": "Making Qwen3 Think in Korean with Reinforcement Learning", "authors": "Jungyup Lee,Jemin Kim,Sang Park,SeungJae Lee", "background": "本文介绍了对大型语言模型Qwen3 14B进行两阶段微调的方法，使其能够在韩语环境中更自然地思考和推理。", "innovation": "提出了监督微调（SFT）和定制的Group Relative Policy Optimization (GRPO)算法的强化学习两阶段方法。通过监督微调在高质量的韩语逻辑推理数据集上建立基础，提高了韩语逻辑推理能力。在强化学习阶段，使用了自定义的GRPO算法进一步增强了韩语推理能力和整体问题解决性能。为了克服稳定性的挑战，引入了oraclejudge模型来校准奖励信号，确保了学习过程的稳定性与性能的稳步提升。", "conclusion": "最终的RL调整模型不仅在进阶的推理测试（特别是在数学和编程任务）中取得了显著的提升，同时保持了知识和语言能力，其内部思维链条完全用韩语进行。"}
{"llm_update_time": "20250816", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.10311", "html_url": "https://arxiv.org/abs/2508.10311", "title": "从表层到语义：基于表格的文档语义结构解析", "title_en": "From Surface to Semantics: Semantic Structure Parsing for Table-Centric Document Analysis", "authors": "Xuan Li,Jialiang Dong,Raymond Wong", "background": "文档是信息和知识的核心载体，在金融、医疗保健和科学研究等领域有着广泛的应用。表格作为结构化数据的主要载体，包含了关键信息，并且是文档中最核心的组成部分之一。现有研究主要集中在布局分析、表格检测和数据提取等表面层次的任务上，缺乏深入的语义解析。这限制了像跨段落数据解释和上下文一致分析等高级任务的实现。", "innovation": "为了应对这一挑战，本文提出了DOTABLER框架，一种以表格为中心的语义文档解析框架，旨在揭示表格与其上下文之间的深层语义关联。DOTABLER利用一个自定义的数据集和特定领域的预训练模型微调，结合完整的解析pipeline，识别与表格语义相关的内容段落。通过这一语义理解，DOTABLER实现了两个核心功能：以表格为中心的文档结构解析和特定领域的表格检索，提供全面的基于表格的语义分析和精准的语义相关表格提取。在实际PDF文档中近4000页超过1000个表格上，DOTABLER实现了超过90%的精确率和F1分数，展示了在表格-上下文语义分析和深度文档解析方面优于诸如GPT-4o等先进模型的性能。", "conclusion": "DOTABLER框架通过深层次的语义解析有效揭示了表格与其上下文之间的关联，提高了跨段落数据解释和上下文一致分析等高级任务的实现能力，并验证了其在实际文档中的高效性能。"}
{"llm_update_time": "20250816", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.10312", "html_url": "https://arxiv.org/abs/2508.10312", "title": "超越语义理解：在基于LLM的推荐中保留协作频率分量", "title_en": "Beyond Semantic Understanding: Preserving Collaborative Frequency Components in LLM-based Recommendation", "authors": "Minhao Wang,Yunhang He,Cong Xu,Zhangchi Zhu,Wei Zhang", "background": "现有的推荐系统与大型语言模型（LLMs）结合使用，显示出通过语义信息生成推荐的潜力。然而，基于LLMs的推荐器倾向于在用户的交互历史中放大语义相关性。使用预训练的协作ID嵌入作为输入时，基于LLMs的推荐器会随着时间的推移，在通过LLM架构的每一层传播过程中削弱内在的协作信号。相比之下，传统的Transformer顺序模型通常保留甚至增强了协作信号。为解决这一问题，提出了FreLLM4Rec方法，旨在从谱的角度平衡语义和协作信息。", "innovation": "FreLLM4Rec通过使用全局图低通滤波器（G-LPF）初步去除无关的高频噪声来净化项目嵌入，然后通过时域频率调制（TFM）逐层保留协作信号。TFM的协作保留能力通过建立局部图Fourier滤波器的理想但难以实现与子理想但高效计算的频域滤波器之间的联系而得到理论保证。在四个基准数据集上进行全面实验表明，FreLLM4Rec成功缓解了协作信号的衰减，并达到了竞争性的性能，最高NDCG@10比最佳基线提高了8.00%。", "conclusion": "研究结果揭示了LLMs处理协作信息的方式，并提供了一种理论上指导如何改进基于LLMs的推荐系统的思路。"}
{"llm_update_time": "20250816", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.10368", "html_url": "https://arxiv.org/abs/2508.10368", "title": "大规模语言模型在捷克历史文献总结及其应用", "title_en": "Large Language Models for Summarizing Czech Historical Documents and Beyond", "authors": "Václav Tran,Jakub Šmíd,Jiří Martínek,Ladislav Lenc,Pavel Král", "background": "文本摘要是将大量文本压缩为简洁版本，同时保留其核心意义和关键信息的任务。尽管文本摘要在英语及其他资源丰富的语言中得到了广泛研究，但捷克文本摘要，尤其是对历史文档的摘要，由于语言复杂性和缺乏标注数据集的原因仍被较少研究。\n", "innovation": "本文采用了Mistral和mt5等大规模语言模型在现代捷克文本摘要数据集SumeCzech上取得了新的最佳结果，并引入了一个名为Posel od Čerchova的历史捷克文档摘要的新数据集，同时给出了基线结果。这些贡献为捷克文本摘要的发展提供了巨大的潜力，并为捷克历史文本处理开启了新的研究途径。", "conclusion": "这些贡献不仅推动了捷克文本摘要技术的发展，还为该领域未来的研究奠定了基础，并展示了大规模语言模型在捷克语及历史文档摘要领域的应用前景。"}
{"llm_update_time": "20250816", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.10304", "html_url": "https://arxiv.org/abs/2508.10304", "title": "另一种算法偏见：大型语言模型强化性别和种族主导话语的述说分析", "title_en": "Yet another algorithmic bias: A Discursive Analysis of Large Language Models Reinforcing Dominant Discourses on Gender and Race", "authors": "Gustavo Bonil,Simone Hashiguti,Jhessica Silva,João Gondim,Helena Maia,Nádia Silva,Helio Pedrini,Sandra Avila", "background": "随着人工智能（AI）的进步，大型语言模型（LLMs）越来越受到重视并被应用于多种场景。随着它们的发展变得更加复杂，评估它们是否在维持霸权话语的同时重印偏见（如歧视和种族化）变得至关重要。当前检测偏见的方法主要依赖于定量、自动化的技术，但这些方法往往忽略了偏见在自然语言中微妙的表现方式。本文提出了一种质性的话语框架来补充这些方法。", "innovation": "本文提出了一个质性的、话语框架的方法来评估大型语言模型生成的文本中性别和种族偏见。通过手动分析大型语言模型生成的涉及黑白女性的简短故事，研究了性别和种族偏见的具体表现形式。此方法有助于开发者和用户识别偏见在模型输出中的精确表现，从而更好地促进其缓解。", "conclusion": "研究结果表明，黑人女性被描绘为与祖先和反抗联系在一起，而白人女性则处于自我发现过程中。这些模式反映出语言模型如何复制了固化的话语代表性，强化了本质主义并加剧了社会流动性感的缺乏。当要求纠正偏见时，模型提供的浅显修改维持了不理想的意义，揭示了构建包容性叙事的局限性。研究结果表明算法具有意识形态功能，对AI的伦理使用和发展具有重要意义。该研究强调了在AI设计和部署中采用批判性和跨学科方法的重要性，特别是在处理LLM生成的话语反映和加剧不平等方面。"}
{"llm_update_time": "20250816", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.10390", "html_url": "https://arxiv.org/abs/2508.10390", "title": "商用黑盒大语言模型通过明确有害提示进行 Jailbreaking 的分析", "title_en": "Jailbreaking Commercial Black-Box LLMs with Explicitly Harmful Prompts", "authors": "Chiyu Zhang,Lu Zhou,Xiaogang Xu,Jiafei Wu,Liming Fang,Zhe Liu", "background": "当提示不是明显有害的，或者没有引发有害输出时，评估 jailbreak 攻击具有挑战性。现有的红队数据集中包含许多不适合的提示，这些提示需要评估和清理以确保恶意内容的准确性。然而，现有的恶意内容检测方法要么依赖于耗时的手动注释，要么依赖于大型语言模型（LLMs），这些模型在有害内容类型上表现不一致。", "innovation": "提出了一个结合了基于大语言模型的注释与最少人工监督的混合评估框架（MDH），以平衡准确性和效率。此外，研究发现精心制作的开发人员消息可以显著提高 Jailbreak 成功率，为此提出了 D-Attack（采用上下文模拟）和 DH-CoT（结合被劫持的思路链）两种新策略。", "conclusion": "该研究发布了一套代码、数据集、判断标准和检测结果在 GitHub 仓库中，以进一步验证和测试这些方法的有效性。"}
{"llm_update_time": "20250816", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.10369", "html_url": "https://arxiv.org/abs/2508.10369", "title": "使用约束解码改进跨语言生成式 aspect 基础情感分析", "title_en": "Improving Generative Cross-lingual Aspect-Based Sentiment Analysis with Constrained Decoding", "authors": "Jakub Šmíd,Pavel Přibáň,Pavel Král", "background": "虽然 aspect 基础情感分析 (ABSA) 取得了显著进展，但对于低资源语言来说，仍然存在挑战。这些语言往往被忽略，而更多关注于英语。当前的跨语言 ABSA 方法主要集中在简单或较不复杂的任务上，并且常常依赖于外部翻译工具。此外，大型语言模型在零样本和少量样本设置下表现不佳，但在微调时可以达到与小型多语言模型相当的结果，但由于训练和推理时间较长", "innovation": "本文提出了一种新颖的方法，使用约束解码与序列到序列模型，消除了对外部翻译工具的依赖，平均提高了最复杂任务的跨语言性能5%。此外，提出的方法支持多任务处理，使得一个模型能够解决多个ABSA任务，并通过约束解码提升了结果超过10%。该方法在七种语言和六个ABSA任务上的评估中超过了现有最佳方法，为以前未探索的任务设立了新的基准。同时，量化了大型语言模型在零样本、少量样本和微调场景中的表现", "conclusion": "本文提供了在实际应用中利用跨语言ABSA方法的实用建议，并深入探讨了跨语言ABSA方法的优点和局限性，推进了该研究领域的发展。"}
{"llm_update_time": "20250816", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.10404", "html_url": "https://arxiv.org/abs/2508.10404", "title": "通过稀疏自动编码器进行逐层扰动的对抗性文本生成", "title_en": "Layer-Wise Perturbations via Sparse Autoencoders for Adversarial Text Generation", "authors": "Huizhen Shu,Xuying Li,Qirui Wang,Yuji Kosuga,Mengqiu Tian,Zhuo Li", "background": "随着自然语言处理（NLP）特别是大型语言模型（LLMs）的迅速发展，生成对抗性示例以突破LLMs成为理解模型漏洞和提高鲁棒性的重要挑战。目前，研究人员正在探索新的黑盒攻击方法来实现这一目标。本文则提出了一种基于模型可解释性的新技术——稀疏特征扰动框架（SFPF），利用稀疏自编码器从文本中识别和操控关键特征，进而生成新的对抗性文本，这些文本在保持恶意意图的同时增强了安全信号，从而提高了其规避现有防护机制的能力。实验结果表明，SFPF生成的对抗性文本能够规避最先进的防护机制，揭示了当前NLP模型中存在的持久性漏洞。然而，该方法的效果在不同指令和网络层之间存在差异，其在其他架构和更大模型上的普适性还需要进一步验证。", "innovation": "提出了一种新的黑盒攻击方法——稀疏特征扰动框架（SFPF），它利用稀疏自编码器从文本中识别和操控关键特征。该方法可以生成新的对抗性文本，保持恶意意图同时增强安全信号，从而提高对抗性文本的鲁棒性。此外，该方法提供了一种新的红队演练策略，平衡了攻击效果和安全对齐。", "conclusion": "实验结果表明，SFPF生成的对抗性文本能够绕过最先进的防护机制，揭示了当前NLP模型中的持久性漏洞。尽管该方法在不同指令和层上的效果有所不同，但其普适性还需进一步验证。"}
{"llm_update_time": "20250816", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.10444", "html_url": "https://arxiv.org/abs/2508.10444", "title": "DiFaR：通过多样、准确且相关的话语增强多模态误导信息检测", "title_en": "DiFaR: Enhancing Multimodal Misinformation Detection with Diverse, Factual, and Relevant Rationales", "authors": "Herun Wan,Jiaying Wu,Minnan Luo,Xiangzheng Kong,Zihan Ma,Zhi Zeng", "background": "随着从大型视觉-语言模型(LVLMs)生成文本理据以支持可训练的多模态误导信息检测器这一范式的出现，其效用受到了三大核心挑战的限制：（i）生成理据的多样性不足，（ii）由于幻觉导致的事实不准确，（iii）无关或冲突的内容引入噪声。", "innovation": "提出了一种名为DiFaR的检测器无关框架，该框架产生多样、准确和相关理据以增强误导信息检测。DiFaR通过五种推理链提示来从LVLMs中引发多样的推理历程，并且采用一个轻量级的后处理过滤模块，基于句子级别的事实性和相关性评分来选择理据句子。", "conclusion": "广泛的实验在四个流行的基准上证明，DiFaR 在四个基线类别中最佳性能达到了5.9%的提升，并且提高了现有检测器的性能多达8.7%。自动评估指标和人类评估都证实了DiFaR在所有三个维度上显著提高了理据质量。"}
{"llm_update_time": "20250816", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.10419", "html_url": "https://arxiv.org/abs/2508.10419", "title": "ComoRAG：一种认知启发的记忆组织RAG用于状态化的长叙事推理", "title_en": "ComoRAG: A Cognitive-Inspired Memory-Organized RAG for Stateful Long Narrative Reasoning", "authors": "Juyuan Wang,Rongchen Zhao,Wei Wei,Yufeng Wang,Mo Yu,Jie Zhou,Jin Xu,Liyan Xu", "background": "长篇故事和小说的叙述理解是一个具有挑战性的领域，这归因于其错综复杂的剧情以及角色和实体之间复杂且常常变化的关系。尽管大规模语言模型（LLM）在这种长篇背景下的推理能力有限，且高计算成本限制了它们的应用，检索式方法如RAG仍然是实际中的核心方法。然而，传统的RAG方法因它们单一步骤的无状态检索过程可能忽略了长范围内互相关联关系的动态捕捉，从而存在一定的局限性。已有研究中，大多数基于检索的方法未能充分理解并整合上下文中的多步推理和信息，这在处理复杂的、涉及全局理解的需求上尤其明显。因此，急需一种能够更好地处理长篇复杂叙述推理的技术突破，来解决传统方法的不足，推动基于记忆的长文本理解的进展。", "innovation": "ComoRAG是一个认知启发的记忆组织RAG模型，它认为叙述推理不是一个一次性的过程，而是一个包含持续证据获取和过往知识整合的动态交互过程，类似于大脑中记忆信号相关推理的认知机制。如遇推理瓶颈，ComoRAG会进行迭代推理循环与一个动态记忆工作空间的互动。每一步，它都会生成探询查询来探索新的路径，并将检索到的新方面证据整合到全局记忆库中，支持查询解决方案的复杂背景构建。通过在四个具有挑战性的长上下文叙述基准中（200K+标记），ComoRAG表现出比强大RAG基线更高的系统改进，特别是在需要全局理解的复杂查询上，提供了基于记忆的设计框架来弥合长文本理解中的状态依赖推理差距。", "conclusion": "ComoRAG在多个长上下文叙述基准中表现出色，尤其是在需要全局理解的复杂查询上。该方法通过迭代推理循环和动态记忆工作空间的互相作用提供了一种有原则的认知启发框架，为基于记忆的长文本理解提供了一种重要的推理支持。未来发展方向是进一步研究更加复杂的情况，以优化和调整ComoRAG在实际应用中的表现。"}
{"llm_update_time": "20250816", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.10482", "html_url": "https://arxiv.org/abs/2508.10482", "title": "当解释性遇到隐私：文本后验解释与差分隐私在自然语言处理背景下的交汇处研究", "title_en": "When Explainability Meets Privacy: An Investigation at the Intersection of Post-hoc Explainability and Differential Privacy in the Context of Natural Language Processing", "authors": "Mahdi Dhaini,Stephen Meisenbacher,Ege Erdogan,Florian Matthes,Gjergji Kasneci", "background": "在可信自然语言处理（NLP）的研究中，已经出现了许多重要领域，包括可解释性和隐私领域。近年来，这两方面均获得了相当大的研究兴趣，但在两者交汇处的研究仍然不足，这导致了实现两者的同时保持的可能以及它们之间的矛盾性仍不清楚。本文旨在探讨NLP背景下的隐私与解释性的权衡问题，通过流行的差分隐私和后验解释方法作为指导进行实证研究。", "innovation": "本文的研究创新之处在于通过实证分析探讨了差分隐私与后验解释方法在自然语言处理中的关系，揭示了两者之间的复杂关系，并指出了解释性和隐私性在某些情况下是可以兼得的，并提出了未来研究的建议和实践指导。", "conclusion": "实验结果表明，隐私和解释性之间的关系由下游任务的性质及文本隐私化和解释方法的选择等因素形成。我们可以看到，隐私和解释性不再是不可调和的矛盾，而是可以通过适当的方法在一定程度上共存。本文总结了影响隐私和解释性之间的权衡因素，并为未来在这个重要交汇点上的研究提供了实用建议。"}
{"llm_update_time": "20250816", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.10552", "html_url": "https://arxiv.org/abs/2508.10552", "title": "When Language Overrules: Revealing Text Dominance in Multimodal Large Language Models", "title_en": "When Language Overrules: Revealing Text Dominance in Multimodal Large Language Models", "authors": "Huyu Wu,Meng Tang,Xinhan Zheng,Haiyun Jiang", "background": "多模态大规模语言模型（MLLMs）在各种多模态任务中展示出了非凡的能力，然而这些模型面临一个核心问题，即文本主导现象：它们在推理过程中过度依赖文本，而未能充分利用其他模态。虽然先前的研究已经注意到了这一现象，尤其是在视觉语言任务中，常常将其归因于数据偏见或模型架构，但这项研究首次对文本主导现象在包括图像、视频、音频、时序数据和图形等多种数据模态中的普遍情况进行了系统性的研究。通过新的评价指标MDI（模态主导指数）和AEI（注意效率指数）来衡量这一不平衡。研究发现文本主导现象在所有测试的模态中都是具有重要性和普遍性的。", "innovation": "提出了一种新的评价指标MDI和AEI来衡量多模态模型中其他模态被忽视的程度。深入分析了文本主导现象的原因，并提出了一种简单有效的token压缩方法，该方法能够显著调整模型对不同模态的注意力分配，如将LLaVA-7B的MDI从10.23降至0.86，实现了更为均衡的多模态学习。", "conclusion": "该研究不仅揭示了文本主导现象的严重性和普遍性，还提供了一个评估框架，这种框架为开发更加平等和全面的多模态语言模型奠定了基础。"}
{"llm_update_time": "20250816", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.10426", "html_url": "https://arxiv.org/abs/2508.10426", "title": "在大规模语言模型中实施计算经济学：在资源约束下探索模型行为和激励设计", "title_en": "Computational Economics in Large Language Models: Exploring Model Behavior and Incentive Design under Resource Constraints", "authors": "Sandeep Reddy,Kabir Khan,Rohit Patil,Ananya Chakraborty,Faizan A. Khan,Swati Kulkarni,Arjun Verma,Neha Singh", "background": "大型语言模型（LLMs）因为计算成本高昂而受到限制。本文引入了一个“计算经济学”框架，将LLM视为受资源限制的代理（注意力头部和神经块组成的内部经济）的集合，他们需要分配稀缺的计算资源以最大化任务效益。研究表明，在计算资源匮乏时，标准的LLMs会将注意力重新分配到高价值单词上，同时保持准确性。基于此观察，作者提出了一种基于激励的训练方法，通过添加可微运算成本项，来促进稀疏和高效的激活，从而减小模型的FLOPS和降低延迟，同时使注意力模式更具可解释性。这种方法在GLUE（MNLI，STS-B，CoLA）和WikiText-103测试中，家族模型遍布帕累托边界，并且一致性地优于事后剪枝模型；在相似的准确性下，FLOPS减少了约40%，且延迟更低。\n", "innovation": "提出了一个基于激励的新颖训练框架，将计算成本引入损失函数，以鼓励模型进行稀疏且高效的激活。这种方法通过细化计算经济学视角，设计出在资源严格限制下更加高效、自适应和透明的LLM模型。特别是在处理稀缺计算资源的情况下，有效提高了模型的效率和解释性。\n", "conclusion": "利用经济原则为大规模语言模型设计出了一条设计高效、自适应且透明的路径。这种方法通过引入计算成本激励机制，显著提高了模型的计算效率和响应时间，并且这种改进不仅体现在整体性能提升，还体现在模型参数优化方面，能够更好地供研究者理解模型的内部运作。\n"}
{"llm_update_time": "20250816", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.10695", "html_url": "https://arxiv.org/abs/2508.10695", "title": "从自然语言反馈学习实现个性化问答", "title_en": "Learning from Natural Language Feedback for Personalized Question Answering", "authors": "Alireza Salemi,Hamed Zamani", "background": "个性化对于提高语言技术的效果和用户满意度至关重要，尤其是在信息检索任务如问答系统中。当前个性化大型语言模型的方法通常依赖于检索增强生成（RAG），并通过标量奖励信号的强化学习来教导模型如何利用检索到的个人上下文。然而，这些标量奖励有时提供的反馈是微弱的和非指导性的，从而限制了学习效率和个性化质量。", "innovation": "本文介绍了一种新型框架VAC，它用自然语言反馈（NLF）代替标量奖励，这种NLF根据用户资料和问题叙述生成。NLF作为一种丰富且可操作的监督信号，使策略模型能够逐步优化其输出并内化有效的个性化策略。训练过程通过优化反馈模型和在改进的回答上微调策略模型交替进行，最终达到了策略模型在推理时不需反馈的效果。", "conclusion": "在LaMP-QA基准测试上（包含三个不同的领域）的结果表明，与现有最佳结果相比，该方法的改进是持续且显著的。进一步的人类评估也证实了生成回答的质量更高。这些结果证明了NLF提供了更有效的信号来优化个性化问答策略。"}
{"llm_update_time": "20250816", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.10366", "html_url": "https://arxiv.org/abs/2508.10366", "title": "使用大型语言模型和受限解码推进序列到序列模型的跨语言方面基于情感分析", "title_en": "Advancing Cross-lingual Aspect-Based Sentiment Analysis with LLMs and Constrained Decoding for Sequence-to-Sequence Models", "authors": "Jakub Šmíd,Pavel Přibáň,Pavel Král", "background": "方面基于情感分析（ABSA）取得了显著进展，但低资源语言仍然面临挑战，因为研究主要集中在对英语的关注上。目前的跨语言ABSA研究往往集中在更简单的任务上，并且依赖于外部翻译工具。", "innovation": "本文提出了一种新的序列到序列方法，用于消除对翻译工具的依赖的复合ABSA任务。该方法采用受限解码，将跨语言ABSA性能提高多达10%，并拓宽了跨语言ABSA的应用范围，使其能够处理更复杂的任务。", "conclusion": "我们还将我们的方法与大型语言模型进行比较，并表明虽然微调的多语言LLMs可以取得相似的结果，但以英语为中心的LLM在这些任务上表现不佳。"}
{"llm_update_time": "20250816", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.10683", "html_url": "https://arxiv.org/abs/2508.10683", "title": "基于神经机器翻译的科普特语-法语翻译：低资源古语翻译策略", "title_en": "Neural Machine Translation for Coptic-French: Strategies for Low-Resource Ancient Languages", "authors": "Nasma Chaoui,Richard Khoury", "background": "本研究首次系统地探讨了将科普特语翻译成法语的策略。利用对齐的圣经语料库，研究评估了转介译文与直接译文、预训练的影响、多版本微调的好处以及模型对噪声的鲁棒性。研究表明，使用具有不同风格和噪声感知的训练语料库进行微调可以显著提升翻译质量。", "innovation": "研究通过全面的管道系统地评估了翻译策略，包括转介译文与直接译文的比较、预训练的作用、多版本微调的益处以及模型对噪声的鲁棒性。利用对齐的圣经语料库，研究发现使用具有不同风格和噪声感知的训练语料库进行微调可以显著提升翻译质量。", "conclusion": "研究结果提供了开发历史语言翻译工具的重要实际见解，特别是对于低资源古语而言。"}
{"llm_update_time": "20250816", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.10795", "html_url": "https://arxiv.org/abs/2508.10795", "title": "超越“不新颖足够”：通过LLM辅助反馈丰富学术评价", "title_en": "Beyond \"Not Novel Enough\": Enriching Scholarly Critique with LLM-Assisted Feedback", "authors": "Osama Mohammed Afzal,Preslav Nakov,Tom Hope,Iryna Gurevych", "background": "同行评审中的新颖性评估是一个关键但研究不足的领域，尤其是在高产量领域如NLP，评审者的能力越来越紧张。当前的方法在处理高负载评审任务时存在局限性，而现有的大型语言模型（LLM）可能无法准确捕捉到专家评审的复杂性。", "innovation": "本文提出了一个结构化的自动化新颖性评估方法，通过三个阶段模仿专家评审行为：从提交内容中提取内容，检索和综合相关工作，并进行结构化的比较以进行证据基础评估。该方法基于大规模的人工书写新颖性评论分析，并捕捉到关键模式如独立主张验证和情景推理。该方法在ICLR 2025提交中达到86.5%的人类推理一致性，75.3%的新颖性结论一致率，显著优于现有的基于LLM的基线方法。同时，这种方法产出详尽且了解文献的分析结果，并提高了评审判断的一致性。", "conclusion": "这些结果表明结构化的LLM辅助方法具有潜力，能够支持更加严谨和透明的评审，而不必替代人类专业知识。数据和代码开放供进一步研究。"}
{"llm_update_time": "20250816", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.10687", "html_url": "https://arxiv.org/abs/2508.10687", "title": "连续的孟加拉手语翻译：借助图辅助减轻手语注释的负担", "title_en": "Continuous Bangla Sign Language Translation: Mitigating the Expense of Gloss Annotation with the Assistance of Graph", "authors": "Safaeid Hossain Arib,Rabeya Akter,Sejuti Rahman", "background": "全球有数百万的人口受到听力损失和听觉障碍的影响。手语对于聋人和听力受损者来说是一种复杂的沟通手段。然而，在以口语为主的语言社会中，手语经常被低估，导致沟通障碍和社交排斥。Continuous Bangla Sign Language Translation项目旨在通过提升翻译方法来弥补这一差距，尤其是在以口语为主的地区。虽然最近的方法利用变压器架构达到了最先进的成果，但是本研究将图基方法与变压器架构结合使用，这种结合的方式证明在无手语术语的翻译上更加有效。", "innovation": "本研究的创新点包括：合并变压器和STGCN-LSTM架构，探索了多种融合策略，并且在不同的手语数据集（RWTH-PHOENIX-2014T、CSL-Daily、How2Sign和BornilDB v1.0）上达到了新的先进技术水平。研究成果比当前的手语翻译方法表现更优，BLEU-4得分显著提高，达到了4.01、2.07和0.5，分别超越了GASLT、GASLT和slt_how2sign在RWTH-PHOENIX-2014T、CSL-Daily和How2Sign上的成绩。另外，研究首次在BornilDB v1.0数据集上进行基准测试，为未来的研究设定了基准，强调了无手语术语翻译的必要性，以改善聋人和听力受损者的沟通无障碍性。", "conclusion": "本研究通过将图基方法与变压器架构相结合，展示了在无手语术语翻译上的优越性，并通过在不同手语数据集上的测试，达到了新的先进技术水平。研究结果表明，新的方法在多个数据集上具有明显的优势，推动了未来在手语翻译领域的研究和发展，有助于提高聋人和听力受损者的沟通无障碍性。"}
{"llm_update_time": "20250816", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.10736", "html_url": "https://arxiv.org/abs/2508.10736", "title": "思考在遮罩内：扩散大语言模型中的就地提示", "title_en": "Thinking Inside the Mask: In-Place Prompting in Diffusion LLMs", "authors": "Xiangqi Jin,Yuxuan Wang,Yifeng Gao,Zichen Wen,Biqing Qi,Dongrui Liu,Linfeng Zhang", "background": "尽管大型语言模型（LLMs）已经取得了显著的成功，它们的前缀提示范式和顺序生成过程在双向信息处理方面提供了有限的灵活性。扩散大语言模型（dLLMs）通过其双向注意力机制和迭代改进过程，提供了更灵活的就地提示策略的新机会。", "innovation": "介绍了ICE（就地链式思考提示的早期退出），这是一种新颖的框架，将前缀提示转换为专为dLLMs设计的就地提示。ICE将直接将就地提示整合到迭代改进过程中的遮罩标识位置，并使用基于置信度的早期退出机制以显著减少计算开销。", "conclusion": "广泛的实验表明ICE的有效性，在GSM8K中可实现高达17.29%的准确率提升和4.12倍速度提升，在MMLU上实现高达276.67倍加速，同时保持竞争力。"}
{"llm_update_time": "20250816", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.10860", "html_url": "https://arxiv.org/abs/2508.10860", "title": "从黑箱到透明：增强大学课堂中解释性人工智能在自动口译评估中的应用", "title_en": "From Black Box to Transparency: Enhancing Automated Interpreting Assessment with Explainable AI in College Classrooms", "authors": "Zhaokun Jiang,Ziyin Zhang", "background": "近年来，机器学习的进展激发了对自动翻译质量评估的兴趣。然而，现有的研究在语言使用质量评估、因数据稀缺和不平衡导致的模型效果不佳以及缺乏对模型预测解释的努力方面存在不足。", "innovation": "为了填补这些空白，本文提出了一种多维度建模框架，结合了特征工程、数据增强和可解释的机器学习。该方法强调解释性而非“黑箱”预测，仅使用构建相关的透明特征，并通过Shapley值分析进行解释。", "conclusion": "通过强调解释性，本文提供了一个可扩展、可靠且透明的替代传统人工评估的方法，为学习者提供了详细的诊断反馈，并支持自我调节学习的优势，这是孤立的自动评分无法提供的。"}
{"llm_update_time": "20250816", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.10848", "html_url": "https://arxiv.org/abs/2508.10848", "title": "Psyche-R1：统一同理心、专业知识和推理的可靠心理健康LLM", "title_en": "Psyche-R1: Towards Reliable Psychological LLMs through Unified Empathy, Expertise, and Reasoning", "authors": "Chongyuan Dai,Jinpeng Hu,Hongchang Shi,Zhuo Li,Xun Yang,Meng Wang", "background": "当前心理健康专业人士严重不足，心理应用中融入大型语言模型（LLMs）被认为是减轻日益加重的心理健康疾病负担的有效途径。尽管某些增强逻辑推理能力的LLMs已经展示了在数学和编程上的出色表现，但在心理领域的研究主要集中在情感支持和同理对话方面，对那些有利于生成可靠回复的推理机制重视不足。", "innovation": "本文提出了Psyche-R1，这是首款将同理心、心理学专业背景与推理能力相结合的中文心理LLM。通过一个新颖的数据整理管道，设计了一个详尽的数据合成管道来生成超过75000个高质量的心理问题及其详细推理过程。同时采用混合训练策略，其中具有挑战性的样本由多个LLM选出进行群体相对策略优化（GRPO）以增强逻辑推理能力，其余数据用于跟随观察后的微调（SFT）来提升同理心对话生成和心理领域的专业知识。", "conclusion": "广泛的实验结果表明，Psyche-R1在多个心理健康基准测试中表现出色，其7B参数的Psyche-R1达到了与671B参数DeepSeek-R1相当的结果。"}
{"llm_update_time": "20250816", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.10839", "html_url": "https://arxiv.org/abs/2508.10839", "title": "强化语言模型在序列决策中的应用", "title_en": "Reinforced Language Models for Sequential Decision Making", "authors": "Jim Dilkes,Vahid Yazdanpanah,Sebastian Stein", "background": "大型语言模型（LLMs）具有作为序列决策代理的潜力，但由于依赖于大型、计算密集型模型，其应用受到限制。现有的后训练方法设计用于单轮交互，无法处理连续步骤代理任务中的信用分配。因此，需要改进较小的模型并开发新的后训练方法来应对这一挑战，尤其是能够处理多步任务的代理任务的信用分配问题。", "innovation": "我们提出了Multi-Step Group-Relative Policy Optimization (MS-GRPO)，这是一种基于正式的文本中介随机博弈（TSMG）和语言代理策略（LAP）框架的新算法，用于后训练LLM代理。对于信用分配，MS-GRPO将整个累积时期奖励分配给每个单独的时期步骤。我们还提出了一种新的绝对优势加权时期采样策略，该策略可以提高训练性能。通过在蛇类和冻湖任务上对一个30亿参数模型进行后训练，评估了该方法的效果，结果显示，改进后的后训练30亿参数模型在冻湖任务上比720亿参数的基线模型性能提高了50%。这项工作证明，针对特定任务的后训练是利用LLMs构建序列决策代理的实用且高效的替代方法，而不是依赖模型规模。", "conclusion": "研究显示，我们的方法能够在改进决策性能的同时有效地利用较小的预训练模型，提供了一种有效且经济的创建序列决策代理的新途径。"}
{"llm_update_time": "20250816", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.10068", "html_url": "https://arxiv.org/abs/2508.10068", "title": "SaraCoder：利用语义和结构提示进行面向收益的代码库级代码完成", "title_en": "SaraCoder: Orchestrating Semantic and Structural Cues for Profit-Oriented Repository-Level Code Completion", "authors": "Xiaohan Chen,Zhongying Pan,Quan Feng,Yu Tian,Shuqun Yang,Mengru Wang,Lina Gong,Yuxia Geng,Piji Li,Xiang Chen", "background": "检索增强生成（RAG）方法在代码库级别的代码补全中通常依赖于表面文本相似性，导致结果受到语义误导、冗余性和同质性的影响，同时无法解决外部符号的歧义问题。", "innovation": "引入了Saracoder，一种分层特征优化检索框架。其核心模块分层特征优化系统地通过提炼深层次语义关系、消除精确重复项、应用一种基于图的新型结构相似度度量（考虑拓扑重要性）以及重新排序结果以最大化相关性和多样性来优化候选代码。此外，外部感知标识符消歧模块通过依赖分析准确解决了跨文件符号歧义问题。", "conclusion": "在CrossCodeEval和RepoEval-Updated基准测试中进行了广泛实验，结果显示Saracoder显著优于现有基线方法，覆盖多种编程语言和模型。本文证明，多维层次上系统地优化检索结果为构建更准确、更鲁棒的代码库级代码完成系统提供了一种新的范式。"}
{"llm_update_time": "20250816", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.10874", "html_url": "https://arxiv.org/abs/2508.10874", "title": "SSRL: 自身搜索强化学习", "title_en": "SSRL: Self-Search Reinforcement Learning", "authors": "Yuchen Fan,Kaiyan Zhang,Heng Zhou,Yuxin Zuo,Yanxu Chen,Yu Fu,Xinwei Long,Xuekai Zhu,Che Jiang,Yuchen Zhang,Li Kang,Gang Chen,Cheng Huang,Zhizhou He,Bingning Wang,Lei Bai,Ning Ding,Bowen Zhou", "background": "研究探讨大型语言模型（LLMs）作为代理搜索任务在强化学习（RL）中的高效模拟器潜力，以减少对外部搜索引擎昂贵交互的依赖。通过结构化提示和重复抽样定量评估LLMs的内在搜索能力，这一过程称为Self-Search。研究结果显示，LLMs在推理预算上的扩展行为表现为强的量级关系，在问题回答基准测试，包括具有挑战性的BrowseComp任务中，实现了高pass@k表现。", "innovation": "提出了一种名为Self-Search RL (SSRL)的方法，通过格式和规则奖励增强LLMs的Self-Search能力。SSRL使模型能够在不依赖外部工具的情况下，迭代地优化其知识利用，缓解对外部搜索引擎的依赖，提高RL训练的稳定性和成本效益，促进从模拟到现实世界的顺利转移。", "conclusion": "1) LLMs具备可以有效激发的世界知识，以实现高性能表现；2) SSRL展示了利用内部知识减少幻觉的可能性；3) SSRL训练的模型能无缝配合外部搜索引擎，无需额外努力。这些发现突显了LLMs在支持更具扩展性的RL代理训练方面的潜力。"}
{"llm_update_time": "20250816", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.10875", "html_url": "https://arxiv.org/abs/2508.10875", "title": "Diffusion Language Models", "title_en": "A Survey on Diffusion Language Models", "authors": "Tianyi Li,Mingda Chen,Bowei Guo,Zhiqiang Shen", "background": "扩散语言模型（DLMs）正在迅速成为自回归（AR）范式的强大且有前景的替代品。通过迭代去噪过程并行生成令牌，DLMs 减少了推理延迟并捕捉了双向上下文，从而在生成过程的细粒度控制方面具有优势。尽管获得了几倍的加速，但最近的进步使 DLMs 的性能与自回归模型相当。因此，它们成为各种自然语言处理任务的有吸引力的选择。", "innovation": "本文综述了DLM的当前景观。追溯了DLM的发展及其与其他范式的关联，涵盖了从基础原理到最先进的模型。同时，文章还提出了一种最新的分类法和对当前技术的深入分析，包括预训练策略和高级后训练方法。此外，综述还包括了DLM推理策略和优化的全面审查，包括解码并行性、缓存机制和生成质量的改进。还强调了DLM在多模态扩展领域的最新方法以及在各种实际场景中的应用。并探讨了DLM的局限性和挑战，如效率、长序列处理需求和技术基础设施等，并提出了未来研究的方向。", "conclusion": "对DLM的研究表明，尽管存在一些挑战和局限性，但DLMs的加速发展已经取得了显著的进步，未来研究的潜力巨大。还提供了GitHub项目链接，为读者提供了进一步研究和探索的资源。"}
{"llm_update_time": "20250816", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.10031", "html_url": "https://arxiv.org/abs/2508.10031", "title": "上下文误导LLMs：上下文过滤在保持LLMs安全对齐中的作用", "title_en": "Context Misleads LLMs: The Role of Context Filtering in Maintaining Safe Alignment of LLMs", "authors": "Jinhwa Kim,Ian G. Harris", "background": "虽然大规模语言模型（LLMs）在性能上取得了显著进步，但各种牢笼攻击（jailbreak attacks）已成为一种日益增长的安全和伦理风险。恶意用户经常利用对抗性背景来欺骗LLMs，使其生成对有害查询的响应。因此，为了增强LLMs的安全性而不牺牲它们的辅助性，保持 benign 用户的良好体验，本研究提出了一种新的防御机制——上下文过滤模型（Context Filtering model），这是一种输入预处理方法，旨在过滤掉不可信和不可靠的背景，同时识别包含真实用户意图的主要提示，以揭示隐藏的恶意意图。", "innovation": "该研究提出了一种新的防御机制——上下文过滤模型，这是一种输入预处理方法。该模型专门设计用于过滤掉不可信和不可靠的上下文，同时识别包含真实用户意图的主要提示，从而揭示隐藏的恶意意图。该模型在不需对模型本身进行微调的情况下，可以轻松应用于所有LLMs，包括白盒和黑盒模型，从而增强其安全性。实验结果表明，该模型可以将牢笼攻击的成功率降低高达88%，同时保持LLMs的原始性能，实现了安全和有用性产品的领先结果。", "conclusion": "我们的模型能够显著降低牢笼攻击的成功率到88%，同时保持原始LLMs的性能，实现了业内领先的‘安全与有用性’综合结果。此外，我们的模型是一种即插即用的方法，可以应用于所有类型的LLMs，无需对模型进行任何微调。我们还将在研究方面发布我们的模型，以供研究人员使用，从而更好地保护LLMs的安全与性能。"}
{"llm_update_time": "20250816", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.10123", "html_url": "https://arxiv.org/abs/2508.10123", "title": "Nested-ReFT: 通过离策卷积提高大规模语言模型微调的高效强化学习", "title_en": "Nested-ReFT: Efficient Reinforcement Learning for Large Language Model Fine-Tuning via Off-Policy Rollouts", "authors": "Maxime Heuillet,Yufei Cui,Boxing Chen,Audrey Durand,Prasanna Parthasarathi", "background": "在处理具有挑战性的推理领域，如数学推理，LLMs可以通过基于可验证奖励的强化微调(ReFT)方法进行高级推理。传统ReFT框架中，行为模型产生多个问题的答案，然后由奖励函数打分。尽管这类基于强化学习的后训练方法在众多挑战性推理领域中表现出显著的性能提升，但训练过程中通过多次推理步骤生成多个完成步骤带来的计算成本使得训练成本高昂。为了解决这个问题，该研究借鉴了离策RL和推测性解码，提出了一个名为Nested-ReFT的新ReFT框架，其中目标模型的一部分层作为行为模型，在训练期间生成离策略完成步骤。这种配置在训练中每批次采用动态层跳过，降低了推理成本，与传统的ReFT框架相比。", "innovation": "该研究提出了一个新的ReFT框架，Nested-ReFT，其中目标模型的一部分层被配置为行为模型，在训练期间生成离策略完成步骤。行为模型在训练中每批次采用动态层跳过，降低了推理成本，同时还展示了理论分析表明Nested-ReFT提供了无偏梯度估计，具有可控的方差。实验分析表明，Nested-ReFT在多个数学推理基准测试和模型规模中具有更好的计算效率。", "conclusion": "通过采用Nested-ReFT框架，研究证明了在保持与基础ReFT性能持平的同时，可以显著提高在多个数学推理基准测试中的计算效率。同时，研究还探索了三种偏置缓解变体，以最小化梯度更新中的离策略性，从而维持与基础ReFT相当的性能。"}
{"llm_update_time": "20250816", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.10108", "html_url": "https://arxiv.org/abs/2508.10108", "title": "Amazon Nova AI Challenge — 可信赖的人工智能：推进安全的AI辅助软件开发", "title_en": "Amazon Nova AI Challenge -- Trusted AI: Advancing secure, AI-assisted software development", "authors": "Sattvik Sahai,Prasoon Goyal,Michael Johnston,Anna Gottardi,Yao Lu,Lucy Hu,Luke Dai,Shaohua Liu,Samyuth Sagi,Hangjie Shi,Desheng Zhang,Lavina Vaz,Leslie Ball,Maureen Murray,Rahul Gupta,Shankar Ananthakrishna", "background": "AI系统在软件开发中的应用正在迅速增长，然而确保其安全性的挑战依然存在。亚马逊为此推出了Trust AI赛道的Amazon Nova AI挑战赛，这是由10所大学的团队参与的全球竞赛，旨在推动安全AI的发展。参赛团队中有五支专注于开发自动化红队机器人，另外五支则创建安全的AI助手。该挑战通过进行对抗性联赛来评估自动化红队和安全对齐方法，参赛AI编码助手会与红队进行多轮对话以测试其安全性对齐。挑战还提供了高质量的标注数据流，以促进迭代改进。在整个挑战过程中，参赛团队开发了最先进的技术，引入了基于推理的安全对齐、稳健的模型护栏、多轮越狱和对大型语言模型（LLMs）的高效探索等新的方法和技术。", "innovation": "参赛团队开发了最先进的技术，这些技术包括基于推理的安全对齐、稳健的模型护栏、多轮越狱和对大型语言模型（LLMs）的高效探索。亚马逊还投入了大量科学研究和工程资源，包括从零开始构建定制的基准编码专家模型，开发联赛管理服务以及创建评估框架等以支持这些努力。这些创新旨在提高AI安全标准，并推动安全的AI辅助软件开发，这是跨团队合作的结果，展示了人工智能安全的新进展。", "conclusion": "该挑战赛展示了大学团队和亚马逊Nova AI挑战团队在解决AI软件开发的安全挑战方面的成果，突出了跨越团队间合作的重要性，以提高AI安全的新标准，推动安全的AI辅助软件开发的发展。"}
{"llm_update_time": "20250816", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.10057", "html_url": "https://arxiv.org/abs/2508.10057", "title": "大型语言模型在抽象推理中显示出与人类神经认知的对齐迹象", "title_en": "Large Language Models Show Signs of Alignment with Human Neurocognition During Abstract Reasoning", "authors": "Christopher Pinier,Sonia Acuña Vargas,Mariia Steeghs-Turchina,Dora Matzke,Claire E. Stevenson,Michael D. Nunez", "background": "研究背景：本文探讨了大型语言模型（LLMs）在抽象推理过程中是否能表现出与人类类似的神经认知特性。此前的研究表明，人类在进行抽象推理时，神经活动也表现出特定的模式，而这些模式在自然语言处理的背景下被认为是挑战性的任务之一。本研究通过将人类被试与多个开源的语言模型在抽象模式补全任务上的性能和神经表示进行比较，旨在探索LLMs是否能够在特定任务中展示出类似人类的抽象思维机制及神经活动特点。", "innovation": "创新点：本研究通过使用抽象模式差异作为任务表现和视皮层反应相关波形（FRPs）的基础，首次通过对大量参数的大型语言模型进行具体任务测试，以期发现其在神经认知上的独特表现。特别值得注意的是，研究发现仅在拥有大量参数的大型语言模型中（约70亿参数），它们在抽象模式补全上的表现与人类相当，并且在中层神经网络中形成了特定的抽象模式类别聚类。此外，这些模型在对神经活动模式的理解上也表现出了与人类大脑的相似性，暗示了它们可能模仿了人类大脑在抽象推理过程中的机制。", "conclusion": "结论：本研究显示，虽然所有测试的LLMs在中层神经网络中产生了特定的抽象模式类别聚类，但仅少数大模型能实现与人类相当的抽象推理准确度。研究结果还表明，这些模型可能模仿了人类大脑在抽象推理过程中的机制，为生物智能与人工智能共享系统的原理提供了初步证据。"}
{"llm_update_time": "20250816", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.10239", "html_url": "https://arxiv.org/abs/2508.10239", "title": "在线会议中的个性化实时专业术语支持", "title_en": "Personalized Real-time Jargon Support for Online Meetings", "authors": "Yifan Song,Wing Yee Au,Hon Yung Wong,Brian P. Bailey,Tal August", "background": "跨学科交流通常受到领域特定术语的阻碍。研究人员通过定性日记研究发现，当前的工作场合同事交流中在术语管理上存在显著局限，导致沟通效率低下和误解增加。这些发现引发了对于提高术语理解支持工具的需求，并推动了个性化、即时术语支持系统的开发。", "innovation": "该研究设计了一款名为ParseJargon的交互式系统，借助LLM技术，提供个性化实时专业术语识别和解释，适应用户的背景知识。该系统相比非个性化和通用术语支持方案，在提升参与者理解力、参与度和同事工作的认同感方面表现出显著优势，尤其是在控制实验中得到了验证。该项创新有助于填补当前术语支持系统在适应性和个性化方面的空白，为跨学科会议中的专业术语沟通提供了新方案，也推动了相关领域的进一步研究。", "conclusion": "该研究通过实证测试证明了个性化的即时术语支持技术的有效性，并强调了在实践中部署此类技术的机会与挑战。研究还提出了一些建议，对未来设计此类工具具有重要指导意义，同时，也有助于改善跨学科教育和交流环境。"}
{"llm_update_time": "20250816", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.10416", "html_url": "https://arxiv.org/abs/2508.10416", "title": "CorrectNav: 自纠正飞轮赋能视觉-语言-行动导航模型", "title_en": "CorrectNav: Self-Correction Flywheel Empowers Vision-Language-Action Navigation Model", "authors": "Zhuoyuan Yu,Yuxing Long,Zihan Yang,Chengyan Zeng,Hongwei Fan,Jiyao Zhang,Hao Dong", "background": "现有的基于视觉和语言导航的模型在执行指令时容易偏差，但这些模型缺乏有效纠错能力，影响了其从错误中恢复的能力。", "innovation": "提出了一个名为‘自纠正飞轮’的新的后训练范式。该方法将模型在训练集上的错误轨迹视为有价值的错误数据源，通过自动生成感知和行动的纠错数据，优化模型，从而提升模型纠正错误、动态规避障碍物和长指令跟随的能力。实验结果表明，与之前的模型相比，CorrectNav 在 R2R-CE 和 RxR-CE 基准测试中分别取得了 65.1% 和 69.3% 的新最佳成功率，提升了 8.2% 和 16.4%。在真实机器人测试中，CorrectNav 也表现出了更出色的纠错能力和动态障碍物规避能力，能够更好地跟随长指令。", "conclusion": "通过多次纠错飞轮迭代，优化了基于单目 RGB 的 VLA 导航模型 CorrectNav。实验和实际测试表明，CorrectNav 在纠正错误、动态障碍物规避和长指令跟随方面取得了显著的效果。"}
{"llm_update_time": "20250816", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.10530", "html_url": "https://arxiv.org/abs/2508.10530", "title": "优先多样，后求精：语言模型对齐的两阶段假设", "title_en": "Diversity First, Quality Later: A Two-Stage Assumption for Language Model Alignment", "authors": "Zetian Sun,Dongfang Li,Baotian Hu", "background": "语言模型（LMs）与人类偏好对齐对于构建可靠的AI系统至关重要。通常将问题表述为优化LM策略以最大化反映人类偏好的预期奖励。最近，Direct Preference Optimization (DPO) 提出了一种直接从静态偏好数据优化策略的方法，并进一步通过引入在策略采样（即在训练循环中生成的偏好候选）来改进，以更好地对齐LM。然而，该研究指出，在策略数据并不总是最优的，静态和在策略偏好候选之间的有效性存在系统性差异。", "innovation": "该研究提出了对齐阶段假设，将对齐过程分为两个不同的阶段：偏好注入阶段，该阶段受益于多样化数据；以及偏好微调阶段，该阶段偏好高质量数据。通过理论和实证分析，刻画这些阶段，并提出有效算法来识别它们之间的边界。", "conclusion": "实验表明，对齐阶段假设和边界度量具有普适性。对于Llama、Zephyr、Phi-2、Qwen和Pythia这5个模型以及DPO和SLiC-HF这2种对齐方法，所提出的假设和边界测量是有效的。"}
{"llm_update_time": "20250816", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.10356", "html_url": "https://arxiv.org/abs/2508.10356", "title": "多语言历史文本的OCR改进", "title_en": "Improving OCR for Historical Texts of Multiple Languages", "authors": "Hylke Westerdijk,Ben Blankenborg,Khondoker Ittehadul Islam", "background": "本文探讨了使用高级深度学习技术在光学字符识别（OCR）和文档布局分析任务中的方法和发现，聚焦于历史希伯来文本碎片、16至18世纪会议决议以及现代英语手写识别任务。这些任务的共同点是需要精确识别不同历史时期的文本，且面临数据多样性、手写风格变化和历史文献保存状态不佳等挑战。先进深度学习技术可以帮助克服这些难题，提高识别精度和效率，具有广泛的应用前景。", "innovation": "1. 针对历史希伯来文本，通过大量数据增强提升了数据集，并使用Kraken和TrOCR模型优化字符识别。2. 在16至18世纪会议决议分析中，引入了Convolutional Recurrent Neural Network (CRNN)，结合DeepLabV3+进行语义分割，并通过双向LSTM和基于置信度的伪标签精炼模型。3. 对现代英语手写识别任务中，采用了带ResNet34编码器的CRNN和利用Connectionist Temporal Classification (CTC)损失函数训练模型，从而更有效地捕捉序列依赖性。", "conclusion": "本文提供了关于OCR改进的重要见解，并提出了未来研究的可能方向，包括如何进一步提高复杂历史文本的识别准确度，如何更好地处理手写风格的多样性，以及如何利用更多深度学习技术优化OCR系统。"}
{"llm_update_time": "20250816", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.10539", "html_url": "https://arxiv.org/abs/2508.10539", "title": "通过低成本方差减少改进基于价值的过程验证器", "title_en": "Improving Value-based Process Verifier via Low-Cost Variance Reduction", "authors": "Zetian Sun,Dongfang Li,Baotian Hu,Min Zhang", "background": "大型语言模型（LLMs）在各种任务中取得了显著的成功，但其在复杂领域如数学中的推理能力仍存在重大挑战。价值导向的过程验证器通过估计部分推理链导向正确解的概率来改善推理，但在训练标注中的估计误差限制了其有效性，这种误差源于蒙特卡洛（MC）样本数量有限导致的LLM推理成本高。", "innovation": "论文识别出估计误差主要来自于高方差而非偏差，并提出了一种新颖的方法——Compounded Monte Carlo Sampling (ComMCS)，通过线性组合当前步和后续步的MC估计器构造一个无偏估计量。理论上，该方法在无需额外LLM推理成本的情况下，能预测性地减少方差，保持无偏估计。实验证实在MATH-500和GSM8K基准测试中，ComMCS方法超越了基于回归优化的方法和非方差减少基线方法，分别提高了2.8和2.2个点的分数，特别是在Best-of-32采样实验中效果显著。", "conclusion": "本文提出了一种新的无偏估计方法——Compounded Monte Carlo Sampling（ComMCS），能有效减少验证器中的方差误差，提高其在复杂任务中的表现，尤其是在数学推理中。"}
{"llm_update_time": "20250816", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.10553", "html_url": "https://arxiv.org/abs/2508.10553", "title": "eDIF: 一个用于远程解释大型语言模型的欧洲深入推理织网", "title_en": "eDIF: A European Deep Inference Fabric for Remote Interpretability of LLM", "authors": "Irma Heithoff. Marc Guggenberger,Sandra Kalogiannis,Susanne Mayer,Fabian Maag,Sigurd Schacht,Carsten Lanquillon", "background": "在欧洲，大型语言模型（LLM）的解释性基础设施亟需广泛应用。这个项目旨在通过部署一个名为欧洲深度推理织网（eDIF）的基础设施来推动大规模语言模型的机制解释性研究，该基础设施兼容NDIF，能够提高高级模型分析能力的普及性，促进研究社区的发展。", "innovation": "该项目通过在安贝格应用科学大学托管一个GPU集群并连接合作伙伴机构，为研究者提供了远程模型检查的功能。通过使用NNsight API，研究者进行了干预措施，如激活补丁、因果跟踪和表示分析。平台在技术性能、使用便利性和科学用途方面均表现出稳定性，并且得到了积极评价和社区的初步认同。", "conclusion": "这项研究为构建围绕平台的用户社区奠定了基础，并确定了未来开发的改进方向，包括减少激活数据的下载时间和解决间歇执行中断等问题。它标志着在欧洲广泛普及大型语言模型解释性基础设施的重要里程碑，为更大的部署、扩展工具集和积极的社区合作奠定了基础。"}
{"llm_update_time": "20250816", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.10492", "html_url": "https://arxiv.org/abs/2508.10492", "title": "反转医生与AI关系：由大型语言模型驱动的全流程临床诊断", "title_en": "Reverse Physician-AI Relationship: Full-process Clinical Diagnosis Driven by a Large Language Model", "authors": "Shicheng Xu,Xin Huang,Zihao Wei,Liang Pang,Huawei Shen,Xueqi Cheng", "background": "全周期临床诊断涵盖了从模糊的主诉开始的整个诊断工作流程。尽管人工智能（AI），尤其是大型语言模型（LLMs），正在重新定义临床诊断，但它的角色仍然主要是作为医生的助手。AI目前只能在诊断流程的某些环节回答特定的医学问题，而无法从模糊的主诉开始引导整个诊断过程，这仍然主要依赖于医生的操作。这一限制阻碍了AI在减轻医生工作负担和提高诊断效率方面发挥更大的作用。", "innovation": "本文提出了医生与AI关系的转变：使AI成为主要导演，医生作为其助手。为此，我们提出了一种新的LLM，DxDirector-7B，它具有先进的深度思考能力，能够在医生最少参与的情况下驱动全周期诊断。此外，DxDirector-7B还建立了严格的问责机制，明确了AI和医生在误诊中的责任。在使用全周期诊断框架的罕见复杂和现实世界案例中，DxDirector-7B不仅在诊断准确性上取得了显著的优越性，还大幅减少了医生的工作量，这在最先进的医学LLM和通用LLM中都没有明显的表现。据此，多科室和任务的详细分析验证了其有效性，专家评估认为其有望替代医学专科医生。", "conclusion": "这些发现标志着一个新的时代，AI不再是医生的助手，而是充分发挥自己的能力驱动全流程的诊断过程，大幅减轻医生的工作量，提供了一个高效准确的诊断解决方案。"}
{"llm_update_time": "20250816", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.10824", "html_url": "https://arxiv.org/abs/2508.10824", "title": "增强记忆的变换器：从神经科学原理到技术解决方案的系统回顾", "title_en": "Memory-Augmented Transformers: A Systematic Review from Neuroscience Principles to Technical Solutions", "authors": "Parsa Omidi,Xingshuai Huang,Axel Laborieux,Bahareh Nikpour,Tianyu Shi,Armaghan Eshaghi", "background": "记忆对于智能至关重要，能够促进学习、推理和适应性。虽然变换器架构在序列建模方面表现出色，但在长距离上下文保持、连续学习和知识整合方面存在关键限制。本综述通过整合神经科学原理（如动态多时标记忆、选择性注意和巩固）与工程上的记忆增强变换器的进展，提出了一种统一框架。", "innovation": "综述了重构的变革器架构，通过功能目标、记忆表示和整合机制三个分类维度，综合了近期的进展。分析了核心记忆操作，揭示了从静态缓存向适应性、测试时学习系统的转变，并指出了等比例和干扰的持久挑战以及分层缓冲和惊喜门控更新等新兴解决方案。", "conclusion": "本综述提供了一条通往受认知启发的、终身学习变换器架构的路线图。"}
{"llm_update_time": "20250816", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.10548", "html_url": "https://arxiv.org/abs/2508.10548", "title": "使用门控奖励稳定带多轮的长期强化学习", "title_en": "Stabilizing Long-term Multi-turn Reinforcement Learning with Gated Rewards", "authors": "Zetian Sun,Dongfang Li,Zhuoen Chen,Yuhuai Qin,Baotian Hu", "background": "在长期距离的强化学习（RL）任务中，如何引入稀疏的奖励仍然是一个重要的挑战。现有的基于结果的奖励塑造方法难以定义有意义的实时奖励，且容易引入偏见或需要明确的任务分解。另一种基于验证的奖励塑造方法虽然使用了逐步批评家，但短期奖励与长期目标之间的不一致可能导致奖励劫持和次优策略。这项工作在软件工程（SWE）任务的背景下解决这个问题，其中多轮推理和基于规则的验证是关键。研究中介绍了一个统一的SWE导向的RL框架，支持多轮交互、Docker容器执行以及自定义奖励函数。此外，引入了一种新颖的方法——门控奖励积累（G-RA），该方法只有在高层（长期）奖励达到预定义阈值时才累计实时奖励，从而确保RL优化的稳定性。", "innovation": "提出了门控奖励积累（G-RA）方法，该方法只有在高层（长期）奖励达到预定义阈值时才累计实时奖励，确保RL优化的稳定性。实验证明，G-RA可以提高完成率（从47.6%提高到93.8%和22.0%提高到86.0%）和修改率（从19.6%提高到23.8%和12.0%提高到42.0%），同时避免了由于奖励不一致导致的策略退化问题。该方法强调长期RL中奖励积累平衡的重要性，并提供了一个实用的解决方案。", "conclusion": "研究结果表明，在长期的多轮RL任务中，平衡奖励积累的重要性，并提出了一种实用的解决方案，即门控奖励积累（G-RA）方法。这种方法能够有效提高任务的完成率和修改率，避免策略退化问题。"}
{"llm_update_time": "20250816", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2502.08512", "html_url": "https://arxiv.org/abs/2502.08512", "title": "评估合成数据集的多样性", "title_en": "Measuring Diversity in Synthetic Datasets", "authors": "Yuchang Zhu,Huizhe Zhang,Bingzhe Wu,Jintang Li,Zibin Zheng,Peilin Zhao,Liang Chen,Yatao Bian", "background": "大型语言模型（LLMs）被广泛用于生成各种自然语言处理（NLP）任务的合成数据集，如文本分类和摘要。然而，准确测量这些合成数据集的多样性——这对于模型稳健性能至关重要——仍然是一个重大挑战。", "innovation": "提出了一种名为DCScore的新方法，从分类角度评估合成数据集的多样性。DCScore将多样性评估形式化为一个样本分类任务，并利用样本之间的相互关系。此外，还提供了关于DCScore满足多样性公理的理论验证，突显了其作为基本原则的多样性评估方法的角色。实验结果表明，DCScore与多个评估数据集的多样性伪真相具有更强的相关性，证明了其有效性。同时，实证和理论证据显示DCScore相较于现有方法显著降低了计算成本。", "conclusion": "DCScore在多个合成数据集上表现出更强的相关性，并显著降低了计算成本。相关代码可在此处访问：this https URL."}
{"llm_update_time": "20250816", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.10880", "html_url": "https://arxiv.org/abs/2508.10880", "title": "通过仿真搜索LLM代理中的隐私风险", "title_en": "Searching for Privacy Risks in LLM Agents via Simulation", "authors": "Yanzhe Zhang,Diyi Yang", "background": "基于LLM的代理的广泛部署可能会带来一个关键的隐私威胁：恶意代理通过多轮互动主动与他人进行交流以提取敏感信息。动态对话使适应性攻击策略得以实施，这些策略可能导致严重的隐私侵犯，但它们不断变化的性质使得手动预测和发现复杂的漏洞很难实现。", "innovation": "为解决此问题，本文提出了一种基于搜索的框架，该框架交替改进攻击者和防御者的指令，通过模拟隐私关键性代理互动。该框架利用LLMs作为优化器，采用多线程并行搜索与跨线程传播的方法来分析仿真的轨迹，并迭代地提出新的指令。该过程发现攻击策略从简单的直接请求升级为复杂的多轮战术如冒充和同意伪造，而防御策略则从基于规则的限制发展到身份验证状态机。发现了的攻击和防御策略在各种场景和基础模型中具有很强的实用性和转移性。", "conclusion": "通过这一搜索引擎，我们发现了从直接请求到多轮战术的攻击策略升级，以及防御策略从基于规则的限制到身份验证状态机的提升。这些发现跨越了不同的场景和基础模型，证明了在构建关注隐私的代理方面的强大实用性。"}
{"llm_update_time": "20250816", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2407.12830", "html_url": "https://arxiv.org/abs/2407.12830", "title": "基于知识的一致性测试方法在大规模语言模型中的应用", "title_en": "Knowledge-based Consistency Testing of Large Language Models", "authors": "Sai Sathiesh Rajan,Ezekiel Soremekun,Sudipta Chattopadhyay", "background": "本文系统地揭示了大规模语言模型（LLMs）中存在的知识不一致性和知识空缺。研究者们试图通过自动化测试框架来解决这些问题，这需要对现有的LLMs进行全面分析和测试。因此，背景在于如何识别和解决LLMs在知识理解和应用过程中的不一致性和空白知识，并提出一种新的测试方法来实现这一目标。", "innovation": "本文提出了一种名为KonTest的自动化测试框架，该框架利用知识图谱构建测试用例，并通过语义等价查询和测试或acles（元形或本体或acles）来探测和度量LLMs对世界的知识不一致性。此外，该框架还通过加权的LLM模型集合来减轻知识空白。这种方法显著提升了对LLMs知识一致性的检验效率和准确性。", "conclusion": "研究结果表明，KonTest的方法能够生成19.2%的错误输入（9979个测试输入中有1917个错误），并且发现所有测试的LLMs中有16.5%的知识空白。同时，通过借鉴KonTest的测试套件，知识空白被减少了32.48%。此外，实验证明GPT3.5在知识构建方面并不理想，只能在60%-68%的范围内有效。这些结果为提升LLMs的可信度和可靠性提供了新的工具和思路。"}
{"llm_update_time": "20250816", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2503.23714", "html_url": "https://arxiv.org/abs/2503.23714", "title": "使用开放式大型语言模型从手写指令构建指令调优数据集", "title_en": "Building Instruction-Tuning Datasets from Human-Written Instructions with Open-Weight Large Language Models", "authors": "Youmi Ma,Sakae Mizuki,Kazuki Fujii,Taishi Nakamura,Masanari Ohi,Hinari Shimada,Taihei Shiotani,Koshiro Saito,Koki Maeda,Kakeru Hattori,Takumi Okamoto,Shigeki Ishida,Rio Yokota,Hiroya Takamura,Naoaki Okazaki", "background": "大型语言模型（LLMs）要想解决现实世界任务，指令调优至关重要。先前的研究表明，仅从LLM生成的数据中合成的指令调优数据是有效的，这引发了一个基本问题：我们在调优指令时还需要依赖源自人类的信号吗？", "innovation": "本文通过将人类撰写的指令和LLM生成的响应简单配对，构建了领先的人类撰写指令来源的指令调优数据集。通过在我们的数据集上微调的LLM比使用现有数据集微调的模型表现更好。该数据集构造方法可轻松适应其他语言；构建的日本语数据集也达到了领先表现。分析表明，在新语言中的指令调优使LLM能够遵循指令，但调优模型对此语言特定的文化知识较少。", "conclusion": "我们的数据集和微调模型将公开提供。与开放权重LLM合成的数据集将根据宽松的许可协议开放分发，适用于多种应用场景。"}
{"llm_update_time": "20250816", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2501.06117", "html_url": "https://arxiv.org/abs/2501.06117", "title": "Fleurs-SLU：跨语言语音理解的大型多语言基准", "title_en": "Fleurs-SLU: A Massively Multilingual Benchmark for Spoken Language Understanding", "authors": "Fabian David Schmidt,Ivan Vulić,Goran Glavaš,David Ifeoluwa Adelani", "background": "口语理解（SLU）对于没有正式书写系统的语言来说至关重要，约占全球语言的一半。这些低资源语言无法利用语音到文本的自动语音识别（ASR）和基于文本的大语言模型（LLM）来进行语义理解。即使这些语言拥有书写系统，但由于缺乏双模态音视频训练数据，ASR的表现仍然不稳定。现有的多语言SLU评估主要集中在如意图分类或语言识别这样的浅层任务上。因此，作者提出了Fleurs-SLU，一个包含692小时用于主题语句分类的102种语言语音和跨越92种语言944小时演讲听力理解的多选题回答的多语言SLU基准。", "innovation": "Fleurs-SLU 为跨语言语音理解（SLU）设定了一个广泛的基准，包括广泛语言的最大规模语音数据（692小时分类语音和944小时听力理解语音），并评估了端到端语音分类模型、结合语音转文本和随后的LLM分类的级联系统以及多模态语音-LLM模型。此外，研究发现级联系统在多语言SLU中更为稳健，尽管很好地预训练的语音编码器在主题语音分类中表现良好，封闭源语音-LLMs的表现与级联系统相当或更优。研究还观察到，稳健的多语言ASR、有效的语音到文本翻译与强大的多语言SLU之间存在强烈的相关性，显示了声学和语义语音表示之间的相互益处", "conclusion": "Fleurs-SLU 提供了一个有效的多语言 SLU 基准，通过广泛的语言覆盖和多种评估方法，展示了不同类型的系统的性能，并揭示了不同技术之间的相互关系，为未来的多语言语音理解研究提供了丰富的资源。"}
{"llm_update_time": "20250816", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2503.11509", "html_url": "https://arxiv.org/abs/2503.11509", "title": "TikZero: 零样本文本引导的图形程序 synthesis", "title_en": "TikZero: Zero-Shot Text-Guided Graphics Program Synthesis", "authors": "Jonas Belouadi,Eddy Ilg,Margret Keuper,Hideki Tanaka,Masao Utiyama,Raj Dabre,Steffen Eger,Simone Paolo Ponzetto", "background": "自动从文本说明合成图形的能力非常具有吸引力，但要实现高几何精确度和可编辑性，需要将图形表示为像TikZ这样的图形程序语言，并且对齐的训练数据（即带有说明的图形程序）仍然稀缺。与此同时，大量的未对齐的图形程序和带有说明的像素图更容易获得。通过这种方式，本文提出了TikZero，该方法通过使用图像表示作为中介桥梁来解耦图形程序生成和文本理解，使图形程序的独立训练和带说明的像素图的独立训练成为可能，并允许在推理期间进行零样本的文本引导的图形程序合成。与只能操作对齐的图形程序的基线方法相比，我们的方法表现出显著的优势。此外，当利用对齐的图形程序作为补充的训练信号时，TikZero的表现与更大规模的模型相当甚至更好，包括商业系统GPT-4o等.", "innovation": "TikZero通过将文本说明理解和图形程序生成解耦，利用图像表示作为中介，实现了独立训练图形程序和带说明的图像，并在推理期间实现了零样本的文本引导的图形程序合成。这种方法在没有对齐的数据源上表现出显著优于基线方法的效果，且在利用对齐的数据作为补充信号时，提高了模型的性能，甚至超过了更大的商业系统，如GPT-4o.", "conclusion": "我们的方法在零样本文本引导的图形程序合成任务中显著优于只操作对齐的图形程序的基线方法。当利用对齐的图形程序作为补充训练信号时，TikZero的表现与更大型的模型相当甚至更好。编码、数据集和选定模型已公开提供。"}
{"llm_update_time": "20250816", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2504.02323", "html_url": "https://arxiv.org/abs/2504.02323", "title": "CoTAL：循环人机协作的提示工程以实现泛化形式化评估评分", "title_en": "CoTAL: Human-in-the-Loop Prompt Engineering for Generalizable Formative Assessment Scoring", "authors": "Clayton Cohn,Ashwin T S,Naveeduddin Mohammed,Gautam Biswas", "background": "大型语言模型(LLMs)为教师和学生学习提供了新的助力，研究者探索了各种提示工程方法在教育场景中的应用，但这些方法在不同领域(如科学、计算和工程)中的通用性依旧未被充分探讨。", "innovation": "该论文引入了Chain-of-Thought Prompting + Active Learning (CoTAL)，一种基于LLM的形成性评估评分方法。其亮点在于使用证据中心设计(ECD)对评估和评分表与课程目标进行对齐；采用人机协作的提示工程来自动化响应评分；结合chain-of-thought (CoT)提示和教师、学生的反馈，进行迭代优化问题、评分标准和LLM提示。", "conclusion": "CoTAL能显著提升GPT-4在不同领域中评分的表现，相比于非提示工程化的基线，其评分精度提高了38.9%；教师和学生认为CoTAL在评分和解释响应方面有效果，反馈结果进一步提升了评分准确性和解释质量。"}
{"llm_update_time": "20250816", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2410.16325", "html_url": "https://arxiv.org/abs/2410.16325", "title": "这名候选人是[MASK]。基于提示的情感提取与参考信", "title_en": "This Candidate is [MASK]. Prompt-based Sentiment Extraction and Reference Letters", "authors": "Fabian Slonimczyk", "background": "本文提出了一种简单的方法，利用预训练的大规模语言模型从文本数据中提取情感和其他有用特征。这种方法被称为基于提示的情感提取，相比经济和金融领域其他常用的方法，它具有多个优势。作者应用该方法对一手收集的保密参考信（RLs）语料库进行了分析，显示了参考信中情感内容对求职市场的结果有明显反映，且不同的情感评价对求职者的绩效有显著影响。同时，研究还发现，参考信撰写者间的分歧会负面影响求职者的市场表现。文中将基于提示的情感提取方法与其他常用的情感分析方法（如词袋模型、微调语言模型和高级聊天机器人查询）进行了比较，发现没有其他方法能再现基于提示的情感提取的效果。进一步地，作者略微修改了该方法，以获取与性别有关的情感评分，发现女性候选人的参考信更强调“磨石”特质，而男性候选人的参考信更强调“脱颖而出”的特质。这些性别差异对女性的求职结果有负面影响。", "innovation": "提出的基于提示的情感提取方法相比其他常用的情感分析方法有明显优势。该方法能够更好地反映求职市场中的情感内容及其对求职结果的影响，且在与其他常用情感分析技术的比较中 effectiveness 更胜一筹。此外，通过修改方法获取性别情感评分，揭示了性别差异对求职结果的影响，这一点也是对现有研究的新贡献。", "conclusion": "基于提示的情感提取方法在提取参考信中的情感数据和解释其对求职市场结果的影响方面显示出优越性。该方法不仅可以准确反映求职过程中情感内容的真实情况，还能够揭示性别导向的情感标签及其对女性候选人不利的职业影响。这些发现强调了进一步改进参考信撰写标准和促进性别平等的必要性。"}
{"llm_update_time": "20250816", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2503.11655", "html_url": "https://arxiv.org/abs/2503.11655", "title": "带有透明可解释性的DeepSeek-R1情感分析：性能、效率和少量样本学习", "title_en": "Explainable Sentiment Analysis with DeepSeek-R1: Performance, Efficiency, and Few-Shot Learning", "authors": "Donghao Huang,Zhaoxia Wang", "background": "大规模语言模型(LLMs)已经革新了情感分析领域，但在准确率、效率和可解释性之间的平衡上仍面临关键挑战。本研究对开源推理模型DeepSeek-R1进行了全面评估，它与OpenAI的GPT-4o和GPT-4o-mini进行了比较。作者测试了完整的671亿参数模型及其精简版本，并系统记录了少样本学习曲线。实验证明，DeepSeek-R1在五分类情感分析任务中取得了91.39%的F1分数，在二分类任务中取得了99.31%的准确率，相比于GPT-4o在少样本效率上实现了八倍的提升。此外，不同架构的精简效果不同，基于Qwen2.5的32亿参数模型优于基于Llama的70亿参数模型，高出了6.69个百分点。尽管其推理过程降低了吞吐量，但DeepSeek-R1通过透明的、逐步的推理过程提供了更优秀的可解释性，使其成为强大的、可解释的开源替代品.", "innovation": "本研究首次系统地评估了DeepSeek-R1模型在与GPT-4o和GPT-4o-mini的对比中的表现，特别是在少样本学习上的效率提升。研究中描述了少样本学习曲线并发现了架构特定的精简效果。此外，虽然推理过程降低了吞吐量，但DeepSeek-R1提供了透明、逐步的推理过程，增强了模型的可解释性与合理性，成为开源领域的有效替代品.", "conclusion": "DeepSeek-R1在少样本学习效率上实现了显著提升，满足了高准确性和高可解释性的需求，为其奠定了在开源领域的有力地位。"}
{"llm_update_time": "20250816", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2505.17538", "html_url": "https://arxiv.org/abs/2505.17538", "title": "瑞典语Whispers；利用大数据集进行瑞典语语音识别", "title_en": "Swedish Whispers; Leveraging a Massive Speech Corpus for Swedish Speech Recognition", "authors": "Leonora Vesterbacka,Faton Rekathati,Robin Kurtz,Justyna Sikora,Agnes Toftgård", "background": "小型语言资源的语言在多语言训练数据集中往往缺乏代表性，从而限制了这些语言模型的性能。研究表明，通过对现有多语言模型进行微调，可以显著提升这些小型语言资源语言的性能。", "innovation": "本文提出了针对瑞典语的微调Whisper模型，数据集规模和多样性史无前例。与其他语言相比，这一研究为资源中等规模的语言提供了更大的改进空间。", "conclusion": "与OpenAI的Whisper-large-v3模型相比，在FLEURS、Common Voice和NST数据集上的评估显示，本研究的最佳模型相比OpenAI模型的错误率降低了47%。这表明，针对小型资源语言的数据集扩展和微调策略能够显著提高模型的性能。"}
{"llm_update_time": "20250816", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2505.22107", "html_url": "https://arxiv.org/abs/2505.22107", "title": "长上下文建模中变换器的高维度问题", "title_en": "Curse of High Dimensionality Issue in Transformer for Long-context Modeling", "authors": "Shuhai Zhang,Zeng You,Yaofo Chen,Zhiquan Wen,Qianyue Wang,Zhijie Qiu,Yuanqing Li,Mingkui Tan", "background": "基于变换器的大语言模型（LLMs）在自然语言处理任务中表现出色，通过自注意力机制捕捉长范围依赖性。然而，在长上下文建模时，由于注意力机制的冗余计算导致了严重的计算效率低下问题：尽管注意力权重往往是稀疏的，但所有标记（tokens）仍会消耗等量的计算资源。", "innovation": "本文将传统的概率序列建模重新表述为监督学习任务，使相关和不相关标记分离，并揭示了冗余的本质。基于此重新表述，我们从理论上分析了注意力的稀疏性，发现仅少数标记对预测有显著贡献。随后，我们将注意力优化问题转化为线性编码问题，并提出了一种组编码策略，理论上证明了它对随机噪声具有更强的鲁棒性和提高了学习效率。本文进一步提出了一种动态组注意力（DGA），利用组编码在注意力计算中明确减少冗余，通过聚集相对不重要的标记。", "conclusion": "实验结果表明，动态组注意力方法显著降低了计算成本，同时保持了竞争力的性能。该方法在GitHub上开源，可供他人下载和使用。"}
{"llm_update_time": "20250816", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.09636", "html_url": "https://arxiv.org/abs/2508.09636", "title": "个性化产品搜索排名：基于表结构和非表结构数据的多任务学习方法", "title_en": "Personalized Product Search Ranking: A Multi-Task Learning Approach with Tabular and Non-Tabular Data", "authors": "Lalitesh Morishetti,Abhay Kumar,Jonathan Scott,Kaushiki Nag,Gunjan Sharma,Shanu Vashishtha,Rahul Sridhar,Rohit Chatter,Kannan Achan", "background": "本文研究如何使用多任务学习（MTL）框架来优化个性化产品搜索排名。背景在于现有方法难以有效处理混合数据类型，传统方法如XGBoost和TabNet虽然在某些方面表现良好，但仍然不足以应对复杂的搜索场景，尤其是当需要同时处理结构化（表结构数据）和非结构化（非表结构数据）数据时。", "innovation": "文章提出了一种新的模型架构，它独特地结合了表结构和非表结构数据。该模型使用预训练的TinyBERT模型来获取语义嵌入，并采用了一种新颖的采样技术来捕捉多样化的客户行为。此外，还设计了一种基于点击率、点击位置和语义相似性的可扩展相关性标注机制，作为传统人工标注标签的替代方案。", "conclusion": "实验结果表明，将非表结构数据与先进的嵌入技术结合到多任务学习范式中，显著提升了模型的性能。进一步的消融实验显示，增加相关性标注、微调TinyBERT层以及TinyBERT查询-商品嵌入交互等方法都能带来好处。总的来说，该研究证明了该方法在实现更有效的个性化产品搜索排名方面的有效性。"}
{"llm_update_time": "20250816", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2502.16770", "html_url": "https://arxiv.org/abs/2502.16770", "title": "LED-Merging: 通过定位-选举-隔离缓解模型合并中的安全效用冲突", "title_en": "LED-Merging: Mitigating Safety-Utility Conflicts in Model Merging with Location-Election-Disjoint", "authors": "Qianli Ma,Dongrui Liu,Qian Chen,Linfeng Zhang,Jing Shao", "background": "调优预训练的大语言模型（LLMs）用于专门任务会产生大量的计算和数据成本。现有方法中的模型合并提供了无需训练的方案来整合多个任务特定模型，但这些方法存在安全和效用之间的冲突，即增强的一般能力降低了安全保护。这些冲突主要是由简单参数量级选择导致的神经元误识别和合并过程中任务间神经元干扰引起的。", "innovation": "提出了一种名为LED-Merging的三阶段框架，通过基于梯度的归因定位任务特异性神经元，动态选举关键神经元并通过参数隔离反对命令更新。这种方法有效减少了有害响应率，同时保持了95%的功能性能，如在HarmBench上实现了52.39%的准确率。LED-Merging提供了一种轻量级、无需训练的方案，有效解决了安全与效用之间的冲突，适用于构建可靠的多任务LLMs。", "conclusion": "LED-Merging能够有效减少有害响应率，同时保留功能性能，解决了现有方法中的安全-效用冲突的问题。这种方法提供了一个轻量级、无需训练的构建可靠多任务LLMs的方案。相关代码可以在GitHub上找到。"}
{"llm_update_time": "20250816", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2504.01400", "html_url": "https://arxiv.org/abs/2504.01400", "title": "ToolACE-R：基于模型迭代训练和自适应改进的工具学习", "title_en": "ToolACE-R: Model-aware Iterative Training and Adaptive Refinement for Tool Learning", "authors": "Xingshan Zeng,Weiwen Liu,Xu Huang,Zezhong Wang,Lingzhi Wang,Liangyou Li,Yasheng Wang,Lifeng Shang,Xin Jiang,Ruiming Tang,Qun Liu", "background": "工具学习允许大型语言模型（LLMs）利用外部工具来解决复杂的用户任务，这一方法为增强模型能力提供了一条有前途的途径。然而，现有方法主要集中在数据合成上，用于微调LLMs以有效调用工具，而忽略了如何最大限度地激发模型的潜在能力。", "innovation": "提出了一个名为ToolACE-R的新框架，该框架结合了模型感知迭代训练和自适应改进。ToolACE-R的特点是包含模型感知迭代训练流程，能够根据模型能力的进化逐步调整训练样本以最大化模型潜力。同时，它还引入了自适应自改进训练语料库，强调LLM的能力能够对工具调用进行迭代改进，提高性能。此外，引入了自适应自改进机制，实现测试时的高效扩展，使得训练模型能够自主决定何时停止迭代自改进过程。通过对多个基准数据集的广泛实验，展示了ToolACE-R在性能上与基于API的高级模型相当，通过自适应自改进可以更有效地提高工具调用性能。这些结果突显了ToolACE-R的有效性和通用性，为其更为高效和可扩展的工具学习提供了有希望的方向。", "conclusion": "广泛的实验结果显示，ToolACE-R在性能上与先进的API基模型相当，且通过自适应自改进能够更高效地提高工具调用的性能。这些结果表明了ToolACE-R的有效性和普遍适用性，为更高效和扩展的工具学习提供了有前途的方向。"}
{"llm_update_time": "20250816", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2506.19794", "html_url": "https://arxiv.org/abs/2506.19794", "title": "为什么开源大语言模型在数据分析中挣扎？一项系统经验研究", "title_en": "Why Do Open-Source LLMs Struggle with Data Analysis? A Systematic Empirical Study", "authors": "Yuqi Zhu,Yi Zhong,Jintian Zhang,Ziheng Zhang,Shuofei Qiao,Yujie Luo,Lun Du,Da Zheng,Ningyu Zhang,Huajun Chen", "background": "开放源代码的大语言模型（LLMs）在自动化数据分析任务方面具有潜力，但在涉及大量推理的情景中面临诸多限制。本文旨在探索如何增强开源LLMs的数据分析能力。研究通过筛选多样化的种子数据集，从数据理解、代码生成和战略规划三个核心维度评价模型行为，揭示了三层关键发现：战略规划质量是主要驱动力；交互设计和任务复杂性显著影响推理能力；数据质量的影响大于数据多样性.", "innovation": "本文通过系统经验研究揭示了开源LLMs在数据分析中存在的问题，并提出了数据合成方法，显著提高了开源LLMs的分析推理能力。研究结果为改进开源大语言模型的数据分析功能提供了重要依据.", "conclusion": "研究发现，战略规划质量是模型性能的主要决定因素，交互设计和任务复杂性对推理能力有显著影响，数据质量比多样性对实现最优性能影响更大。通过这些建设性的见解，作者开发出了一种数据合成方法，有效提升了开源大语言模型的分析推理能力。"}
{"llm_update_time": "20250816", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2507.10354", "html_url": "https://arxiv.org/abs/2507.10354", "title": "Meanings are like Onions: a Layered Approach to Metaphor Processing", "title_en": "Meanings are like Onions: a Layered Approach to Metaphor Processing", "authors": "Silvia Cappa,Anna Sofia Lippolis,Stefano Zoia", "background": "现有的对隐喻意义的理解往往是线性的、平面化的映射，无法全面反映隐喻在认知中的复杂性。本文作者认为，隐喻意义是一个多层面的结构化过程，旨在提供一种更丰富、更符合认知原理的方法来理解计算系统中的隐喻解析。", "innovation": "提出了一个分层模型，将隐喻意义类比为一个洋葱结构，分为三个层次：(1) 内容分析；(2) 概念融合；(3) 普遍意图性。这种三维框架能够支持更深层、更语境敏感的隐喻推理，并提供了统一多层次的正式框架，使计算方法能够超越表面关联，表征更深层次的隐喻意义。", "conclusion": "通过将这些层次结合到一个单一的正式框架，本文构建的模型为计算方法代表隐喻意义奠定了基础，可以从多层面实现更深层、更语境敏感的推理。"}
{"llm_update_time": "20250816", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.06445", "html_url": "https://arxiv.org/abs/2508.06445", "title": "自动化回声：新闻制作中LLM使用增加", "title_en": "Echoes of Automation: The Increasing Use of LLMs in Newsmaking", "authors": "Abolfazl Ansari,Delvin Ce Zhang,Nafis Irtiza Tripto,Dongwon Lee", "background": "由于生成型人工智能（GenAI）尤其是大规模语言模型（LLMs）的迅速崛起，新闻界的记者诚信和作者身份受到了关注。这项研究探讨了新闻媒体中AI生成内容的使用情况，通过分析来自各类媒体（包括主要媒体、地方媒体和校园媒体）的超过40,000篇新闻文章，发现近年来AI生成内容使用大幅增加，特别是在地方和校园新闻中更为突出。", "innovation": "该研究使用了三种先进的AI文本检测工具（例如Binoculars、Fast-Detect GPT和GPTZero），进行句子层面的分析以揭示LLM的使用模式。研究发现，LLM在新闻的开头部分较多使用，而结论通常由人工撰写。此外，语言学分析表明，GenAI增强了词汇丰富度和可读性，降低了形式化程度，导致新闻风格更为统一，特别是在地方媒体中。", "conclusion": "这项研究发现AI生成内容使用显著增加，尤其是在地方和校园新闻中。LLM在新闻的开头部分较常被使用，而结论通常仍由人工撰写。GenAI产生的文本增强了词汇丰富度和可读性，但降低了形式化程度，造成了新闻风格的标准化，尤其在地方媒体中更为明显。这些发现揭示了新闻制作中对AI技术的日益依赖及其对新闻质量和风格的影响。"}
{"llm_update_time": "20250816", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2507.14189", "html_url": "https://arxiv.org/abs/2507.14189", "title": "基于离线知识库的事实依据多媒体写作助手DeepWriter", "title_en": "DeepWriter: A Fact-Grounded Multimodal Writing Assistant Based On Offline Knowledge Base", "authors": "Song Mao,Lejun Cheng,Pinlong Cai,Guohang Yan,Ding Wang,Botian Shi", "background": "大型语言模型（LLMs）在多种应用中展现了出色的能力，但在金融、医学和法律等特定领域作为写作助手时，由于缺乏深厚的领域专业知识和容易虚构事实，其应用受到了限制。现有的一些解决方案，如检索增强生成（RAG），在其多步检索过程中容易出现不一致性，而基于在线搜索的方法则由于不可靠的网络内容导致质量下降。", "innovation": "本文提出了DeepWriter，一种可定制的、多媒体的长文档写作助手，基于一个精心构建的离线知识库工作。DeepWriter通过一种创新的流程，包括任务分解、大纲生成、多模态检索和逐节构成且附带反思，从结构化的语料库中深度挖掘信息，并融入文本和视觉元素，生成逻辑连贯、有事实依据和专业级水平的文档。此外，还提出了层次化知识表示方法以提高检索效率和准确性。", "conclusion": "在金融报告生成的实验表明，DeepWriter生成了高质量、可验证的文章，在事实准确性和生成内容质量上超过了现有的基线方法。"}
{"llm_update_time": "20250816", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.08285", "html_url": "https://arxiv.org/abs/2508.08285", "title": "The Illusion of Progress: Re-evaluating Hallucination Detection in LLMs", "title_en": "The Illusion of Progress: Re-evaluating Hallucination Detection in LLMs", "authors": "Denis Janiak,Jakub Binkowski,Albert Sawczyn,Bogdan Gabrys,Ravid Shwartz-Ziv,Tomasz Kajdanowicz", "background": "大型语言模型（LLMs）在自然语言处理领域取得了革命性进展，但它们的虚构倾向对可靠部署提出了严重挑战。目前虽有许多虚构检测方法，但这些方法的评估往往依赖于ROUGE指标，该指标基于词汇重叠，却与人类判断不一致。研究通过全面的人类研究得出，尽管ROUGE在召回率上表现良好，但其极低的精确率会导致误导性的性能估计。此外，分析发现基于响应长度的简单启发式方法能与复杂检测技术相媲美，揭示了当前评估实践中的基本缺陷。", "innovation": "研究通过综合的人类研究揭示了简单基于响应长度的启发式方法在虚构检测中与复杂技术竞争的能力，挑战了现有评估实践。研究特别强调，采用语义意识和稳健的评估框架对于准确衡量虚构检测方法的真实性能至关重要，最终确保LLM输出的可信度。", "conclusion": "采用语义意识和稳健的评估框架是准确衡量虚构检测方法真实性能的关键，从而最终确保LLM输出的可信度。"}
{"llm_update_time": "20250816", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2507.01213", "html_url": "https://arxiv.org/abs/2507.01213", "title": "AF-MAT: 具有感知方面特性的翻转和融合 xLSTM 用于基于方面的情感分析", "title_en": "AF-MAT: Aspect-aware Flip-and-Fuse xLSTM for Aspect-based Sentiment Analysis", "authors": "Adamu Lawan,Juhua Pu,Haruna Yunusa,Muhammad Lawan,Mahmoud Basi,Muhammad Adam", "background": "方面基于情感分析（ABSA）是一项重要的自然语言处理（NLP）任务，旨在从文本中提取细粒度的意见和情感，如产品评论和客户反馈。现有方法往往在效率与性能之间做出权衡：传统的LSTM或RNN模型难以捕捉长距离依赖性；基于变换的方法计算成本高；基于Mamba的方法依赖于CUDA并削弱了局部依赖性建模。最近提出的扩展长短期记忆（xLSTM）模型通过指数门控和增强记忆变体有效捕捉长期依赖性，sLSTM用于建模局部依赖性，以及mLSTM用于可扩展和并行化的记忆。然而，xLSTM在ABSA中的应用尚未进行研究。", "innovation": "作者提出了一种新的框架——Aspect-aware Flip-and-Fuse xLSTM（AF-MAT），它利用了xLSTM的优势。该框架包括一个Aspect-aware矩阵LSTM（AA-mLSTM）机制，引入了专门的方面门，使得模型能够在内存更新过程中选择性地强调与目标方面相关的语义令牌。为建模多尺度上下文，结合了一个FlipMix块，该块按顺序应用部分翻转的Conv1D（pf-Conv1D）来捕获逆序的短距离依赖性，并随后使用完全翻转的mLSTM（ff-mLSTM）通过整个序列反转来建模长期依赖性。此外，提出了基于mLSTM门控的轻量级Multihead Cross-Feature Fusion（MC2F），动态地将AA-mLSTM输出（查询和键）与FlipMix输出（值）融合，以实现自适应表示集成。实验表明，AF-MAT在三个基准数据集上优于最先进的基线方法，实现了ABSA任务更高的准确率.", "conclusion": "实验结果表明，AF-MAT在三个基准数据集上优于最先进的基线方法，实现了ABSA任务更高的准确率。"}
{"llm_update_time": "20250816", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2507.10535", "html_url": "https://arxiv.org/abs/2507.10535", "title": "CodeJudgeBench: 评估代码生成任务中的LLM评判模型基准", "title_en": "CodeJudgeBench: Benchmarking LLM-as-a-Judge for Coding Tasks", "authors": "Hongchao Jiang,Yiming Chen,Yushi Cao,Hung-yi Lee,Robby T. Tan", "background": "大型语言模型（LLMs）在各种编码任务中取得了显著的进步。除了直接回答用户查询外，LLMs还可以作为判决者，评估和比较其他模型生成的响应质量。这种评估能力对于不同LLMs的基准测试以及通过响应排序提高响应质量至关重要。尽管LLM作为评判者（LLM-as-a-Judge）的范式正在逐渐被采用，但在编码场景中的有效性仍存在不足，主要原因是没有专门的基准测试来评估其效果。", "innovation": "该研究引入了一个名为CodeJudgeBench的基准，专门针对三种关键编码任务——代码生成、代码修复和单元测试生成——来评估LLM作为评判者模型的表现。研究发现，近期的思考模型在精心设计的代码评判任务中显著优于非思考模型。即使是相对较小的思考模型，如Qwen3-8B，也能优于特训的最大规模为70B的LLM作为评判者模型。然而，所有模型在评判编码任务时仍然表现出显著的随机性。在一对一对比任务中，简单的响应呈现顺序变化会对准确性产生重大影响。此外，对由不同LLMs编写的代码和单元测试进行评判时，LLM作为评判者模型的表现也存在差异性。", "conclusion": "尽管思考模型在代码评判任务中表现优异，但所有模型在评判编码任务时仍表现出显著的随机性。在一对一对比任务中，简单的响应呈现顺序变化会对准确性产生重大影响。此外，对由不同LLMs编写的代码和单元测试进行评判时，LLM作为评判者模型的表现也存在差异性。研究进一步发现，使用成对比较优于标量点式评判，保留未处理全响应中的注释和推理也有助于提高评判模型的表现。这些发现揭示了LLM作为评判者在编码场景中的可靠性和一致性方面的担忧。"}
{"llm_update_time": "20250816", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.08855", "html_url": "https://arxiv.org/abs/2508.08855", "title": "BiasGym: 了解大型语言模型中的偏见与刻板印象及其发现与消除方法", "title_en": "BiasGym: Fantastic LLM Biases and How to Find (and Remove) Them", "authors": "Sekh Mainul Islam,Nadav Borenstein,Siddhesh Milind Pawar,Haeun Yu,Arnav Arora,Isabelle Augenstein", "background": "理解大型语言模型（LLMs）权重中嵌入的偏见和刻板印象至关重要，以开发有效的缓解策略。这些偏见往往比较隐秘且在刻意诱发时也很难识别，因此系统性分析和祛除这些偏见极具挑战性。", "innovation": "提出了一个名为BiasGym的框架，用于可靠地注入、分析和解决LLMs中的概念关联偏见。BiasGym包括两个组件：BiasInject，通过基于token的微调向模型注入特定偏见（同时保持模型冻结），以及BiasScope，利用这些注入的信号来识别并引导负责偏见行为的组件。", "conclusion": "BiasGym被证明能够减少现实世界中的刻板印象（如意大利人是“激进的司机”），并探究虚构关联（例如某虚构国家的人有“蓝色皮肤”），展示了其在安全干预和模型解释性研究中的应用价值。"}
{"llm_update_time": "20250816", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.02038", "html_url": "https://arxiv.org/abs/2508.02038", "title": "Marco-Voice 技术报告", "title_en": "Marco-Voice Technical Report", "authors": "Fengping Tian,Chenyang Lyu,Xuanfan Ni,Haoqin Sun,Qingjuan Li,Zhiqiang Qian,Haijun Li,Longyue Wang,Zhao Xu,Weihua Luo,Kaifu Zhang", "background": "这篇论文提出了一种多功能语音合成系统，将声音克隆和情感控制语音合成集成在一个统一的框架中。这篇工作的目标是解决长期以来在实现高度表达、可控且自然的语音生成方面的难题，这种生成要能忠实保留说话人的身份，在各种语言和情感背景下保持一致性。为此，论文构建了一个高质量的情绪语音数据集CSEMOTIONS，包含6位专业说话人、7种情绪类别共10小时的普通话录音，用来支持全面的训练和评估。通过与现有技术的对比，证明Marco-Voice系统在客观和主观指标上均取得了显著的改进，尤其是在清晰度和情感丰富度方面表现出色，这在表达型神经语音合成领域是一个重要的进展。", "innovation": "文章创新点在于引入了有效的说话人-情绪分离机制，采用批次内对比学习实现独立控制说话人身份和情感风格，并通过旋转情感嵌入整合方法实现平滑的情感控制。此外，通过构建CSEMOTIONS数据集，以及开发一套Marco-Voice系统，实现了在多种测试条件下优异的表现。", "conclusion": "综上所述，Marco-Voice系统在语音清晰度和情感丰富度方面表现出了强劲的性能，展示了在表达型神经语音合成领域的重要进步。该系统的代码和数据集可以在指定的链接处公开获取。"}
{"llm_update_time": "20250816", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.07178", "html_url": "https://arxiv.org/abs/2508.07178", "title": "通过从隐式反馈中抑制虚假兴趣改进个性化标题生成", "title_en": "Improved Personalized Headline Generation via Denoising Fake Interests from Implicit Feedback", "authors": "Kejin Liu,Junhong Lian,Xiang Ao,Ningtao Wang,Xing Fu,Yu Cheng,Weiqiang Wang,Xinyu Liu", "background": "准确的个性化标题生成依赖于精确捕捉用户的兴趣，但这常常被历史行为中的个性化无关的点击噪音所干扰，导致生成的标题与真实用户偏好偏差。现有方法未能处理点击流中的个性化无关点击噪音，影响了个性化生成的质量。该研究通过在用户和新闻维度进行深入分析，揭示了点击噪音对个性化生成质量的负面影响，提出了一种新的个性化标题生成框架（PHG-DIF），致力于解决这一问题", "innovation": "提出了一种新颖的个性化标题生成框架（PHG-DIF），该框架包含双阶段过滤以去除点击流中的噪声，并利用多级时间融合动态建模用户的兴趣变化和多样化偏好，从而精确地进行用户画像。此外，还提供了一个新的基准数据集DT-PENS，包含了1000个精心选择用户的点击行为和近10000条带有历史停留时间注解的个性化标题", "conclusion": "广泛实验表明，PHG-DIF显著减轻了点击噪音的不良影响，显著提高了标题质量，达到了DT-PENS上的最新技术水平。该框架的实现和数据集可从提供的链接获取"}
{"llm_update_time": "20250816", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.09403", "html_url": "https://arxiv.org/abs/2508.09403", "title": "Columbo: 使用大型语言模型扩展表格数据中的简称", "title_en": "Columbo: Expanding Abbreviated Column Names for Tabular Data Using Large Language Models", "authors": "Ting Cai,Stephen Sheen,AnHai Doan", "background": "缩写列名（如“esal”代表“employee salary”）的扩展对于许多下游数据任务至关重要。这一问题在企业、领域科学、政府机构等多方面普遍存在。现有的工作主要依赖于合成公共数据集，但这些数据集存在显著局限性，无法准确反映真实世界中的简写形式。因此，准确地扩展这些简写是一项具有挑战性的任务。", "innovation": "1. 引入了4个新的包含真实世界简写的新数据集，这些数据集来自企业/科学领域，超越了以往仅使用合成数据集的方法。\n2. 提出了新的同义词感知准确度度量方法，能够更准确地评估简写扩展的准确性。\n3. 开发了名为Columbo的解决方案，该解决方案利用上下文、规则、链式推理及原子级别分析，基于大型语言模型，能够显著提高简写扩展的准确性，在5个数据集上，Columbo相比最先进的名猜想（NameGuess）提高了4-29%。", "conclusion": "Columbo在扩展表格数据中简称方面表现出了显著的优势，已经应用到了环境科学的重大数据门户EDI中，证明了其实际应用场景的有效性。"}
{"llm_update_time": "20250816", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.09956", "html_url": "https://arxiv.org/abs/2508.09956", "title": "GPT-5前沿模型在眼科问答中的表现", "title_en": "Performance of GPT-5 Frontier Models in Ophthalmology Question Answering", "authors": "Fares Antaki,David Mikhail,Daniel Milad,Danny A Mammo,Sumit Sharma,Sunil K Srivastava,Bing Yu Chen,Samir Touma,Mertcan Sevgi,Jonathan El-Khoury,Pearse A Keane,Qingyu Chen,Yih Chung Tham,Renaud Duval", "background": "大型语言模型（LLMs）如GPT-5集成了先进的推理能力，可能在复杂的眼科问答任务上表现出色。最新的这些推理模型的最佳配置尚未确定。", "innovation": "研究评估了12种不同配置的OpenAI GPT-5系列（三个模型等级在四种推理努力设置中），以及o1-high、o3-high和GPT-4o模型，使用了260个闭合访问的单项选择题，来自美国眼科学会基本临床科学课程（BCSC）数据集。引入了自动评分框架，用于在眼科中可扩展地评估LLM生成的答案与参考标准之间的匹配度。", "conclusion": "GPT-5-high在准确性和推理质量方面排名第一，并在成本与准确性的分析中确定了几个GPT-5配置在帕雷托前沿上，GPT-5-mini-low提供了一个低成本高性能的平衡。这些结果基于高质量的眼科数据集基准化了GPT-5，并展示了推理努力对准确性的影响，同时还引入了一个自动评分框架用于大规模评估眼科中LLM生成的答案的质量。"}
{"llm_update_time": "20250816", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.09848", "html_url": "https://arxiv.org/abs/2508.09848", "title": "PRELUDE：一种设计用于全球理解及长文上下文推理的大规模基准", "title_en": "PRELUDE: A Benchmark Designed to Require Global Comprehension and Reasoning over Long Contexts", "authors": "Mo Yu,Tsz Ting Chung,Chulun Zhou,Tong Li,Rui Lu,Jiangnan Li,Liyan Xu,Haoshu Lu,Ning Zhang,Jing Li,Jie Zhou", "background": "目前的基准测试主要侧重于评估模型对短文内容的理解能力，对于长文上下文的理解和推理要求较低。因此，该研究引入了PRELUDE基准，旨在通过判断一个角色前传故事是否与原著书籍的 canonical 故事线保持一致的任务，增强对长文上下文理解的需求。", "innovation": "PRELUDE基准提高了对全局理解和深入推理的要求。因为前传故事不是原故事的一部分，所以评估其合理性通常需要搜索和整合与原故事关系不直接的信息。实验结果显示，88%的案例需要从叙述的多个部分获取证据。现有的模型如在上下文学习、 Retrieval-Augmented Generation (RAG) 和使用最新大语言模型的领域内训练，以及商业的DeepResearch服务在任务表现上都落后于人类超过15%。此外，人工研究还发现模型经常给出正确的答案但推理存在问题，其在推理准确率上与人类存在超过30%的差距。该研究突出了长文理解与推理能力的巨大提升空间", "conclusion": "研究结果显示现有的模型在长文理解与推理方面还有很大的提升空间，进一步优化该领域的模型将是未来的一个重要方向。"}
{"llm_update_time": "20250816", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2504.08329", "html_url": "https://arxiv.org/abs/2504.08329", "title": "MedRep: 医疗概念表示方法以提高通用电子健康记录基础模型的表现", "title_en": "MedRep: Medical Concept Representation for General Electronic Health Record Foundation Models", "authors": "Junmo Kim,Namkyeong Lee,Jiwon Kim,Kwangsoo Kim", "background": "电子健康记录（EHR）基础模型在各种医疗任务中展现出改进后的性能，但由于处理超出词汇表的未知医疗代码的能力有限，它们的泛化能力和使用不同词汇表训练的模型的融合受到了限制。", "innovation": "提出了一套基于观察医疗结果合作伙伴（OMOP）共同数据模型（CDM）的新型医疗概念表示（MedRep）方法。通过大型语言模型（LLM）提示增加每个概念的最小定义信息，并通过OMOP词汇表的图本体补充基于文本的概念表示。这种方法在多种预测任务中优于普通的EHR基础模型和先前引入的医学代码分词器模型，并展示了MedRep的泛化能力。", "conclusion": "MedRep在不同的预测任务中表现出色，证明了其提高EHR基础模型的鲁棒性和泛化能力的有效性。"}
{"llm_update_time": "20250816", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2505.03810", "html_url": "https://arxiv.org/abs/2505.03810", "title": "Grouped Sequency-arranged Rotation: 为量化优化旋转变换的无需训练方法", "title_en": "Grouped Sequency-arranged Rotation: Optimizing Rotation Transformation for Quantization for Free", "authors": "Euntae Choi,Sumin Song,Woosang Lim,Sungjoo Yoo", "background": "大型语言模型（LLMs）在部署过程中面临高计算成本的问题，现有后训练量化（PTQ）方法虽然提供了解决方案，但在极低位宽（如2位）下，基于旋转的方法性能较差。现有的旋转基方法在处理极低位宽时表现出局限性。", "innovation": "本文提出了一种全新的、无需训练的构建改进旋转矩阵的方法，通过利用沃尔什-豪瓦德变换与顺序排列，将相似频率组件进行分组，从而减小量化误差，显著改善性能。此外，我们提出了使用分块对角矩阵的分组频率排列旋转（GSR），通过隔离异常值影响，实现了与基于优化方法相当的性能。该方法在推理任务和WikiText-2的困惑度分数上表现出稳健的性能，即使在已有的学习旋转技术上应用时也能改善结果。", "conclusion": "我们的方法在量化优化旋转变换方面表现出色，无需训练即可提高2位以下位宽下的性能，特别是在语言推理任务上，以及WikiText-2上的困惑度分数方面取得了可喜的成果。"}
{"llm_update_time": "20250816", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2503.18773", "html_url": "https://arxiv.org/abs/2503.18773", "title": "BitDecoding: 解锁低精度KV缓存下张量核心的长上下文LLMs", "title_en": "BitDecoding: Unlocking Tensor Cores for Long-Context LLMs with Low-Bit KV Cache", "authors": "Dayou Du,Shijie Cao,Jianyi Cheng,Luo Mai,Ting Cao,Mao Yang", "background": "长上下文大语言模型（LLMs）在自回归解码过程中，由于键值（KV）缓存会随着每个生成的token增长，因此对内存和带宽的需求增加。现有的低比特KV缓存量化系统（如4比特或2比特）虽然能减少内存使用量，但因过度依赖CUDA核心而牺牲了张量核心（现代GPU的主要计算来源），导致解码速度过慢。", "innovation": "BitDecoding提出了一种新的长上下文LLM推理系统，利用CUDA核心和张量核心的协同工作来实现低比特KV缓存的高效解码。它引入了自动诱导优化布局的方法以利用张量核心，以及warp级并行策略来实现去量化。此外，BitDecoding包含了一系列模块，支持各种注意力机制的查询转换、支持多种量化的高性能量化内核以及一个可协调CUDA和张量核心执行的软件定义管道的去量化内核。", "conclusion": "在RTX 4090、A100和H100上，BitDecoding分别将解码速度提高了7.5倍、4.8倍和8.9倍，超越了FP16 FlashDecoding-v2和现有的先进低比特系统QServe。在LLaMA-3.1-8B模型中，BitDecoding使单批次解码延迟降低了3倍，充分证明了其在长上下文生成中的显著改进。相关代码已公开。"}
{"llm_update_time": "20250816", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2505.13109", "html_url": "https://arxiv.org/abs/2505.13109", "title": "FreeKV：为高效大语言模型推理增强KV缓存检索", "title_en": "FreeKV: Boosting KV Cache Retrieval for Efficient LLM Inference", "authors": "Guangda Liu,Chengwei Li,Zhenyu Ning,Minyi Guo,Jieru Zhao", "background": "大规模语言模型（LLMs）随着上下文窗口的迅速扩大，被广泛部署以支持日益复杂的应用。然而，长上下文导致了显著的实施挑战，尤其是由于大小与上下文长度成正比增长的KV缓存。尽管已经提出了KV缓存压缩方法来解决这一问题，但KV丢弃方法会导致很大的准确率损失，而KV检索方法则面临效率瓶颈。", "innovation": "FreeKV是一个算法和系统协同优化框架，旨在提高KV检索效率同时保持准确性。在算法方面，FreeKV引入了推测检索，将KV选择和召回过程移出关键路径，并结合细粒度校正来确保准确性。在系统方面，FreeKV采用CPU和GPU内存的混合KV布局，消除碎片化的数据传输，同时使用双缓冲流式召回进一步提高效率。", "conclusion": "FreeKV在各种场景和模型中实现接近无损的准确率，并与当前先进的KV检索方法相比，速度提高可达13倍。"}
{"llm_update_time": "20250816", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2502.08557", "html_url": "https://arxiv.org/abs/2502.08557", "title": "通过代理介导的对话式探究实现的新查询扩展方法", "title_en": "A New Query Expansion Approach via Agent-Mediated Dialogic Inquiry", "authors": "Wonduk Seo,Hyunjin An,Seunghyun Lee", "background": "查询扩展在信息检索（IR）中被广泛使用，以通过补充初始查询来丰富信息从而提高搜索结果。然而，近期基于大型语言模型（LLM）的方法尽管能够生成伪相关的内容和扩展术语，但往往会生成单一且狭窄的扩展，缺乏所需的多样化的背景来检索相关信息。因此，需要一种能够生成更丰富和更相关的查询扩展的新方法。", "innovation": "本文提出了一种新的代理介导对话框架AMD，通过使用三个专业角色进行对话式的探索性查询：（1）一个苏格拉底式提问代理将初始查询重新表述为三个子问题，每个子问题源于特定的苏格拉底式提问维度，包括澄清、假设探询和意蕴探询；（2）一个对话式回答代理生成伪答案，从多个与用户意图一致的视角丰富查询表示；（3）一个反思性反馈代理评估和改进这些伪答案，确保仅保留最相关和最具信息量的内容。通过利用多代理过程，AMD能够通过探究与反馈精炼打造更丰富的查询表示。", "conclusion": "我们在基准测试包括BEIR和TREC上的广泛实验表明，本文提出的框架在前人方法的基础上表现出色，提供了一种强大且可靠的检索任务解决方案。"}
{"llm_update_time": "20250816", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2505.15935", "html_url": "https://arxiv.org/abs/2505.15935", "title": "MAPS: 全球代理性能和安全性的多语言基准测试", "title_en": "MAPS: A Multilingual Benchmark for Global Agent Performance and Security", "authors": "Omer Hofman,Jonathan Brokman,Oren Rachmil,Shamik Bose,Vikas Pahuja,Toshiya Shimizu,Trisha Starostina,Kelly Marchisio,Seraphina Goldfarb-Tarrant,Roman Vainshtein", "background": "随着代理性人工智能系统（基于大规模语言模型并能与工具和记忆交互）能力的迅速提升，这些系统面临着多重挑战，尤其是在多语言环境下的安全性与可靠性不足的问题，特别是在英语以外的语言环境下，用户可能会遇到不可靠或安全关键型代理行为。现有的评估基准测试均围绕英语进行，忽略了多语言环境的评价。为了填补这一空白，本文开发了一个名为MAPS的多语言基准测试套件，供多语言和任务场景下评估代理性人工智能系统的综合性能和稳定性之用。", "innovation": "本文创新地提出了一套多语言基准测试套件MAPS，用于跨多种语言评估代理性人工智能系统的综合性能与稳定性。内容包括将四个广泛使用的代理性基准测试（GAIA、SWE-bench、MATH、Agent Security Benchmark）翻译成包括英语在内的11种不同语言，共生成805个独特的任务和9660个语言特定实例，从而系统地分析多语言对人工智能代理系统性能和稳定性的具体影响。", "conclusion": "本研究展示了第一个标准化的多语言代理性人工智能评估框架，推动未来的研究朝着公平、可靠和易于使用的代理性人工智能方向前进。下一阶段的工作可能涵盖进一步的翻译和实际应用场景中的测试，以提高代理性人工智能系统在多语言环境下的性能和安全性。该多语言基准测试套件已在公开网址 this https URL 公开提供。"}
{"llm_update_time": "20250816", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2504.15485", "html_url": "https://arxiv.org/abs/2504.15485", "title": "CAPTURe：通过遮挡物体计数评估视觉语言模型的空间推理能力", "title_en": "CAPTURe: Evaluating Spatial Reasoning in Vision Language Models via Occluded Object Counting", "authors": "Atin Pothiraj,Elias Stengel-Eskin,Jaemin Cho,Mohit Bansal", "background": "理解视觉场景中被遮挡（部分或完全隐藏）的物体非常重要，因为遮挡在真实环境中经常发生，会成为空间理解的障碍。为测试模型在多个被遮挡物体上进行推理的能力，研究引入了一个新的任务：通过不可见区域计数无模模式（CAPTURe），要求模型通过推断遮挡物后图案的延续来计数按模式排列的物体。CAPTURe 组合了模式识别和推理，是评估视觉语言模型（VLMs）对被遮挡模式的理解和空间理解能力的有效工具。", "innovation": "引入 CAPTURe 任务，该任务要求模型通过推断遮挡物后图案的延续来计数按模式排列的物体。CAPTURe 由两个部分组成：CAPTURe 实验实拍数据和 CAPTURe 合成数据控制诊断。评估了四个强大的 VLM（GPT-4o、Intern-VL2、Molmo 和 Qwen2-VL），发现模型在被遮挡和未被遮挡的图案上都难以计数。研究显示，即使最强的 VLM 也无法处理遮挡，这表明 VLM 在推断看不见的空间关系方面也存在欠缺。为了提高性能，提供了关于遮挡物体位置的辅助信息，这进一步证实了模型错误来源于处理遮挡的能力不足以及图片计数难度大。", "conclusion": "研究发现人类在 CAPTURe 任务上几乎没有错误，而模型的表现较差。提供关于遮挡物体位置的辅助信息可以提高性能，表明模型的错误不仅源于处理遮挡的不足，还源于图像中的计数难度。该任务为评估视觉语言模型的空间推理能力提供了一个有效工具。"}
{"llm_update_time": "20250816", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2505.22793", "html_url": "https://arxiv.org/abs/2505.22793", "title": "视觉语言模型的文化胜任力评估", "title_en": "Evaluation of Cultural Competence of Vision-Language Models", "authors": "Srishti Yadav,Lauren Tilton,Maria Antoniak,Taylor Arnold,Jiaang Li,Siddhesh Milind Pawar,Antonia Karamolegkou,Stella Frank,Zhaochong An,Negar Rostamzadeh,Daniel Hershcovich,Serge Belongie,Ekaterina Shutova", "background": "现代视觉-语言模型（VLMs）在文化能力评估和基准测试中常常表现不佳。考虑到基于VLMs的各种应用的多样性，人们愈发关注于理解这些模型如何编码文化特征。尽管这个问题的某些方面已被研究，但对于识别和标注图像中的细微文化维度以便VLMs使用的综合框架仍然缺乏。从视觉文化研究（文化研究、符号学和视觉研究）的基础方法入手，本文提出了一种包含五个框架的文化维度分析方法，旨在更全面地评估VLMs的文化胜任力。", "innovation": "本文提出了一个包含五个框架的系统方法来评估VLMs的文化胜任力，这些框架来源于视觉文化研究的领域，包括文化研究、符号学和视觉研究。这种创新性方法弥补了现有研究的不足，提供了一个全新的视角来分析图像中的文化维度。", "conclusion": "视觉语言模型在文化胜任力方面存在不足，本文通过引入五个框架，借鉴视觉文化研究中的相关方法，为更全面地进行VLMs的文化分析提供了理论基础和实践指南。"}
{"llm_update_time": "20250816", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2507.15758", "html_url": "https://arxiv.org/abs/2507.15758", "title": "LAPO：通过长度自适应政策优化实现推理效率内化", "title_en": "LAPO: Internalizing Reasoning Efficiency via Length-Adaptive Policy Optimization", "authors": "Xingyu Wu,Yuchen Yan,Shangke Lyu,Linjuan Wu,Yiwen Qiu,Yongliang Shen,Weiming Lu,Jian Shao,Jun Xiao,Yueting Zhuang", "background": "大型推理模型通过扩展链式思考序列实现了显著的性能提升，但这种计算上的自由度导致了即使面对简单问题也会出现过度的标记生成。现有方法通过施加严格的限制或依赖事后干预来控制推理长度，而LAPO框架则将推理长度控制转化为内部模型能力，通过一种两阶段的强化学习过程，使模型能够内化适合的推理深度，从而在推理时保持灵活性。", "innovation": "LAPO框架通过两阶段的强化学习过程，使模型能够自适应控制其推理长度。第一阶段，模型通过发现成功解决方案长度的统计分布来学习自然推理模式。第二阶段，模型利用这些模式作为元认知指导，并将这些指导直接嵌入其推理背景中，以确保推理时的灵活性。实验结果表明，LAPO在保持准确性的前提下，将标记使用量减少了40.9%。", "conclusion": "训练有LAPO的模型能够基于问题复杂性分配计算资源，实现高效推理而不牺牲质量。"}
{"llm_update_time": "20250816", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2507.23701", "html_url": "https://arxiv.org/abs/2507.23701", "title": "TextQuests：LLM在文字冒险游戏中的表现如何？", "title_en": "TextQuests: How Good are LLMs at Text-Based Video Games?", "authors": "Long Phan,Mantas Mazeika,Andy Zou,Dan Hendrycks", "background": "在复杂的、具有交互性的环境中评估人工智能代理对于理解它们的实际能力至关重要。现有的代理基准可以有效评估如工具使用或结构化任务上的技能，但往往不能全面捕捉代理在探索性环境中的自主能力，这些环境需要在长且不断发展的背景下进行持续、自发的推理。为更准确地评估在具有挑战性的探索性环境中的代理，本文介绍了一种基于Infocom套件的互动小说游戏建立的基准，该基准被称为TextQuests。", "innovation": "引介了一种新的基准——TextQuests，基于Infocom的互动小说游戏，用于评估LLM的自我问题解决能力，排除外部工具的使用，专注于在一个单一的互动会话中进行尝试与错误学习和持续问题解决所需的内在长上下文推理能力。", "conclusion": "TextQuests为探索性环境中的LLM提供了一个有效的基准，这些环境需要试错学习和长时间的持续推理。该研究通过提供一个专注于特定、状态敏感任务的基准，旨在更准确地评估LLM在复杂挑战中的表现。"}
{"llm_update_time": "20250816", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2506.22493", "html_url": "https://arxiv.org/abs/2506.22493", "title": "对政治极坐标测试的详细因素分析：导航大语言模型的意识形态", "title_en": "A Detailed Factor Analysis for the Political Compass Test: Navigating Ideologies of Large Language Models", "authors": "Sadia Kamal,Lalu Prasad Yadav Prakash,S M Rafiuddin,Mohammed Rakib,Atriya Sen,Sagnik Ray Choudhury", "background": "已经使用政极坐标测试（PCT）或类似问卷来量化大型语言模型（LLM）的政治倾向。近期研究检验了PCT测试的有效性，本文在此基础上展示了标准生成参数的变化对模型PCT评分影响不大，但外在因素如提示变化和微调单独或同时作用会对评分产生影响。此外，对在高政治内容文本数据集上进行微调的模型进行测试，发现其PCT评分未受影响。这呼吁对PCT及其类似测试的有效性以及政治倾向如何在LLM中被编码进行深入研究。", "innovation": "本文通过实验验证了变化的生成参数对PCT评分影响不大，而提示变化和微调单独或组合影响较大，并且在高政治内容数据集上微调的模型PCT评分未受影响。这些发现提供了关于PCT测试有效性和政治倾向如何在LLM中编码的新见解。", "conclusion": "本文的研究表明，PCT测试的有效性需要进一步验证，并且政治倾向在LLM中的编码机制也需要深入研究。此外，外部因素如提示变化和微调在影响模型PCT评分的作用引起了重视。"}
{"llm_update_time": "20250816", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2506.10236", "html_url": "https://arxiv.org/abs/2506.10236", "title": "提示攻击揭示去学习方法的知识表象移除", "title_en": "Prompt Attacks Reveal Superficial Knowledge Removal in Unlearning Methods", "authors": "Yeonwoo Jang,Shariqah Hossain,Ashwin Sreevatsa,Diogo Cruz", "background": "本文研究了一些机器遗忘方法在面对简单的提示攻击时可能失效的问题。研究者系统性地评估了八种不同的遗忘技术在三种模型类型中的表现，使用了基于输出、基于logit和探针分析的方法来评估已遗忘知识可以被恢复的程度。结果显示，一些技术（如RMU和TAR）表现出较好的遗忘效果，但ELM在特定的提示攻击下仍然脆弱（例如，在原始提示前增加印地语填充文本可以恢复57.3%的准确性）。研究还通过logit分析发现，未经遗忘的模型不太可能通过输出格式的变化来掩盖知识痕迹，因为输出和logit准确性之间存在密切联系。这些发现挑战了现有关于遗忘技术有效性的假设，并强调了需要可靠的评估框架来区分真正的知识去除和表面上的输出抑制的效果。为了促进未来的研究，研究团队公开发布了评估框架，以方便对提示技术进行评估，以检索未遗忘的知识。", "innovation": "研究揭示了某些机器遗忘方法在面对简单的提示攻击时可能失效的问题，通过系统性地评估八种不同遗忘技术在三种模型类型中的表现，使用了基于输出、基于logit和探针分析的方法。研究揭示了未经遗忘的模型不太可能通过输出格式的变化来掩盖知识痕迹这一结论，并公开发布了评估框架以促进未来研究。", "conclusion": "本文的发现挑战了现有关于遗忘技术有效性的假设，强调了需要可靠的评估框架来区分真正的知识去除和表面上的输出抑制的效果。此外，为了促进进一步研究，研究者们公开了他们的评估框架。"}
{"llm_update_time": "20250816", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.04586", "html_url": "https://arxiv.org/abs/2508.04586", "title": "当前的AI会议模式不可持续！集中式AI会议的危机诊断", "title_en": "Position: The Current AI Conference Model is Unsustainable! Diagnosing the Crisis of Centralized AI Conference", "authors": "Nuo Chen,Moming Duan,Andre Huikai Lin,Qian Wang,Jiaying Wu,Bingsheng He", "background": "人工智能会议对于推进研究、分享知识和促进学术共同体建设至关重要。然而，它们的快速增长导致中心化会议模式变得越来越不可持续。文章通过对数据的分析，诊断了威胁科学传播、公平性和社区福祉的结构性危机。文中指出了四个关键压力点：科学方面，每作者论文发表率在过去十年中超过了一倍，达到每年4.5篇以上；环境方面，一个会议的碳足迹超过了其主办城市的每日排放量；心理方面，网上社区约71%的讨论反映了负面情绪，35%提到了心理健康问题；及后勤方面，顶级会议如NeurIPS 2024的参会人数开始超过了场地容量。这些压力表明系统与核心使命不一致。", "innovation": "本文提出了社区联合会议（CFC）模型，将同行评审、演讲和社交活动分离为全球协调但本地组织的组成部分，为AI研究提供更可持续、包容和坚固的路径", "conclusion": "提出的CFC模型可以有效地解决现有的结构问题，为AI研究提供更可持续、包容和坚固的方法。"}
{"llm_update_time": "20250816", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.05571", "html_url": "https://arxiv.org/abs/2508.05571", "title": "iFairy: 在 {±1, ±i} 中具有所有参数的首个 2 位复数 LLM", "title_en": "iFairy: the First 2-bit Complex LLM with All Parameters in $\\{\\pm1, \\pm i\\}$", "authors": "Feiyu Wang,Guoan Wang,Yihao Zhang,Shengfan Wang,Weitao Li,Bokai Huang,Shimao Chen,Zihan Jiang,Rui Xu,Tong Yang", "background": "量化的感知训练（QAT）将量化过程集成到训练循环中，使大型语言模型（LLMs）能够学习稳健的低位表示。当前所有 QAT 研究都侧重于最小化全精度模型的量化误差，其中全精度准确性作为上限（准确性天花板）。尚未有任何方法尝试超越这一天花板。", "innovation": "该研究提出了一种新的范式：提高全精度模型的天花板，然后高效地将其量化到 2 位。提出了 Fairy$\boldsymbol{\boldsymbol{\text{\textpm i}}}$，这是首个针对复数 LLM 的 2 位量化框架。具体来说，该方法利用复数域的表示优势，提升全精度模型的准确性。将权重转换为单位根的四个根 $\boldsymbol{\boldsymbol{\text{\textpm 1, \textpm i}}}$，形成一个完全对称且信息理论上最优的 2 位表示。每个量化后的权重要么实部为零要么虚部为零，从而允许仅使用加法和元素交换进行无乘法的推理。实验结果表明，在 PPL 和下游任务方面，Fairy$\boldsymbol{\boldsymbol{\text{\textpm i}}}$ 都优于现有 2 位量化方法，同时保持了严格的存储和计算效率。", "conclusion": "该研究开启了一个新的方向，即在极端低比特约束下构建高度准确且实用的 LLMs。"}
{"llm_update_time": "20250816", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.10066", "html_url": "https://arxiv.org/abs/2508.10066", "title": "Stochastic-based Patch Filtering for Few-Shot Learning", "title_en": "Stochastic-based Patch Filtering for Few-Shot Learning", "authors": "Javier Rodenas,Eduardo Aguilar,Petia Radeva", "background": "食品图像在少样学习模型中带来了独特挑战，由于其视觉复杂性和变异性。例如，一份意大利面菜可能在不同的盘子上配有各种配菜，并在不同的照明条件下和相机视角下显示。这会导致在查询与支持图像进行比较时无法重点关注最重要的元素，从而导致误分类。", "innovation": "提出了基于随机性的局部补丁过滤方法（SPFF）来关注与分类表示更具相关性的补丁嵌入。SPFF的关键概念在于随机过滤补丁嵌入，与类别感知嵌入差异较大的补片更有可能被丢弃。依据补帖嵌入出现的概率对补丁进行过滤后，使用量化查询图像与其支持图像之间关系的相似性矩阵。", "conclusion": "通过对少样分类基准（Food-101，VireoFood-172和UECFood-256）进行广泛的实验，SPFF方法在评测中优于现有最先进的方法，证明了SPFF的有效性。"}
{"llm_update_time": "20250816", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.06412", "html_url": "https://arxiv.org/abs/2508.06412", "title": "样本高效的LLM优化方法——重置回忆", "title_en": "Sample-efficient LLM Optimization with Reset Replay", "authors": "Zichuan Liu,Jinyu Wang,Lei Song,Jiang Bian", "background": "近期，大型语言模型（LLMs）通过强化学习（RL）和偏好优化等方法取得了显著进展，这些方法能够增强LLMs的推理能力。然而，这些方法常常面临样本效率低和首因效应的问题，即过度适应初始经验导致策略质量下降，损害学习过程。", "innovation": "本研究提出了LLM优化的重置回忆（LoRR）方法，这是一种通用且强大的插件，旨在提高任何基于偏好的优化框架的样本效率。LoRR的核心机制允许在高重放数量下训练，以最大化每个收集的数据批次的效用。重制策略的使用有助于防止高重放训练中固有的过度拟合风险，并通过混合优化目标（结合监督微调和偏好损失）进一步提高数据利用效率。实验证明，LoRR极大地提升了各种偏好优化方法在数学和一般推理基准测试上的性能。", "conclusion": "重制回忆方法为LLM微调提供了一种实用的、样本高效的、高度有效的范式，即使在有限数据下也能取得更好的性能。在解决挑战性数学任务时，具有LoRR增强的迭代DPO方法表现出与一些复杂且计算密集型的基于RL算法相当的性能。"}
{"llm_update_time": "20250816", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.10110", "html_url": "https://arxiv.org/abs/2508.10110", "title": "使用可解释的图像-文本基础模型增强变形攻击检测", "title_en": "Empowering Morphing Attack Detection using Interpretable Image-Text Foundation Model", "authors": "Sushrut Patwardhan,Raghavendra Ramachandra,Sushma Venkatesh", "background": "变形攻击检测已成为面部识别系统中确保可靠验证的关键组成部分。本文通过介绍一种多模态学习方法，提出了能够提供变形攻击检测的文本描述的能力。", "innovation": "本文利用对比语言-图像预训练（CLIP）框架实现零样本评估，不仅可以实现泛化的变形攻击检测，还能预测最相关的文本片段。通过分析十个不同文本提示（包括短和长文本），并进行广泛的实验证明，从而增强了对变形攻击的检测能力。", "conclusion": "在面部变形数据集上进行了广泛的实验，利用最先进的预训练神经网络和提出的框架，在五种不同变形生成技术的零样本评估中展示了最佳性能。"}
{"llm_update_time": "20250816", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.10133", "html_url": "https://arxiv.org/abs/2508.10133", "title": "MANGO: 基于多模态注意力的归一化流融合学习方法", "title_en": "MANGO: Multimodal Attention-based Normalizing Flow Approach to Fusion Learning", "authors": "Thanh-Dat Truong,Christophe Bobda,Nitin Agarwal,Khoa Luu", "background": "近年来，多模态学习取得了很大成功。但当前的多模态融合方法依赖于Transformer的注意力机制来隐式学习多模态特征的潜在关联，使得多模态模型难以捕捉每个模态的本质特征，从而难以理解多模态输入的复杂结构和关联。", "innovation": "该研究提出了一种新的多模态注意力归一化流（MANGO）方法，特别是设计了一个可逆的交叉注意力层，其中包含三种新的交叉注意力机制：模态到模态交叉注意力（MMCA）、跨模态交叉注意力（IMCA）和可学习的跨模态交叉注意力（LICA）。此外，还提出了一种新的多模态注意力归一化流，以实现该方法对高维多模态数据的扩展。", "conclusion": "在三个不同的多模态学习任务（语义分割、图像到图像的翻译和电影类型分类）上的实验结果表明，所提出的MANGO方法在性能上达到了最先进的水平。"}
{"llm_update_time": "20250816", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.10104", "html_url": "https://arxiv.org/abs/2508.10104", "title": "DINOv3", "title_en": "DINOv3", "authors": "Oriane Siméoni,Huy V. Vo,Maximilian Seitzer,Federico Baldassarre,Maxime Oquab,Cijo Jose,Vasil Khalidov,Marc Szafraniec,Seungeun Yi,Michaël Ramamonjisoa,Francisco Massa,Daniel Haziza,Luca Wehrstedt,Jianyuan Wang,Timothée Darcet,Théo Moutakanni,Leonel Sentana,Claire Roberts,Andrea Vedaldi,Jamie Tolan,John Brandt,Camille Couprie,Julien Mairal,Hervé Jégou,Patrick Labatut,Piotr Bojanowski", "background": "自监督学习为消除手动数据注释的需求带来了希望，使模型能够轻松扩展到大量数据集和更大的架构。通过不受特定任务或领域特定化的限制，这种训练范式有可能从自然到航空图像等多种来源学习视觉表示。DINOv3通过利用简单而有效的策略向实现这一愿景迈进了一大步。首先，模型和数据集大小的扩展性通过精心的数据准备、设计和优化得以实现。其次，提出了一种名为Gram锚定的新方法，有效解决了密集特征图在长训练过程中退化的问题。最后，应用后处理策略进一步增强了模型在分辨率、模型大小和文本对齐方面的灵活性。因此，DINOv3提供了一种多功能的视觉基础模型，能够在多种情况下超出专门化的最先进的模型，而无需微调。DINOv3生成的高质量密集特征在各种视觉任务中表现出色，显著超过了之前的自监督和弱监督基础模型。我们还分享了DINOv3视觉模型系列，旨在根据不同资源限制和部署场景提供广泛任务的先进解决方案。", "innovation": "DINOv3的主要创新包括：通过数据准备、设计和优化成功扩展模型和数据集的大小；提出Gram锚定方法来有效解决密集特征图在长训练过程中退化的问题；应用后处理策略进一步增强模型的灵活性，使其在分辨率、模型大小和文本对齐方面更有效。这些策略共同促进了高性能多功能视觉基础模型的发展。", "conclusion": "DINOv3提供了一种多功能的视觉基础模型，能够在广泛的任务和数据设置中超过专门化的方法，而不需要微调。DINOv3生成的高质量密集特征在多种视觉任务中表现出显著的优越性，超越了之前自监督和弱监督的基础模型。我们还介绍了DINOv3模型系列，以支持在不同资源和部署要求下推进先进解决方案的广泛任务。"}
{"llm_update_time": "20250816", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.10132", "html_url": "https://arxiv.org/abs/2508.10132", "title": "基于深度学习的大规模全身DXA影像形状和外观建模", "title_en": "Deep Learning Enables Large-Scale Shape and Appearance Modeling in Total-Body DXA Imaging", "authors": "Arianna Bunnell,Devon Cataldi,Yannik Glaser,Thomas K. Wolfgruber,Steven Heymsfield,Alan B. Zonderman,Thomas L. Kelly,Peter Sadowski,John A. Shepherd", "background": "全身影像测试(TBDXA)是一种相对低成本的全身成像技术，广泛用于身体成分评估。本文开发并验证了一种深度学习方法，用于自动在TBDXA扫描上放置关键点，使用了1,683份人工标记的TBDXA扫描数据。该方法在外部测试数据集中达到了99.5%的关键点正确率。为了证明其在形状和外观建模(SAM)中的价值，该方法被用于对35,928份影像数据进行5种不同TBDXA成像模式下的关键点放置，并在两个未用于模型生成的群体中，通过两样本柯尔莫戈洛夫-斯米尔诺夫检验对与健康标记物的关联性进行了测试。结果显示，SAM特征分布与健康生物标志物相关，证明了现有的证据并为体成分和形状与各种衰弱、代谢、炎症和心血管代谢健康标记物关系提出了新假设。评价脚本、模型权重、自动点文件生成代码和三角化数据文件可在下方链接获取：this https URL.", "innovation": "开发并验证了一种深度学习方法，用于自动在TBDXA扫描上放置关键点。这种方法在外部测试数据集中达到了99.5%的关键点正确率。利用该方法进行的关键点放置和与健康标记物的关联性测试，为形状和外观建模提供了新的视角和假设，特别是在与多种健康标志物的关系上。通过对大量数据的自动化处理，提高了研究的效率和规模.", "conclusion": "该深度学习方法在外置测试数据中表现出高度准确性，并通过SAM分析，证实了体成分和形状与各种健康生物标志物之间的关系，提出了新的科学假设，为未来的深入研究提供了支持."}
{"llm_update_time": "20250816", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.10156", "html_url": "https://arxiv.org/abs/2508.10156", "title": "通过自定义EfficientNetV2-L模型结合生成型人工智能（GenAI）基合成和实地图像改善西瓜（Citrullus lanatus）疾病分类", "title_en": "Improving watermelon (Citrullus lanatus) disease classification with generative artificial intelligence (GenAI)-based synthetic and real-field images via a custom EfficientNetV2-L model", "authors": "Nitin Rai,Nathan S. Boyd,Gary E. Vallad,Arnold W. Schumann", "background": "当前生成型人工智能（GenAI）模型的进步为生成高分辨率的合成图像提供了新的可能性，这为农业中用于训练计算机视觉模型的传统图像获取提供了有前途的替代方案。在作物疾病诊断方面，GenAI模型被用于创建各种疾病合成图像，这可能有助于模型创建并减少对资源密集型田间数据收集的依赖。但是，关于结合真实和合成图像以提高疾病分类性能的研究有限。因此，这项研究旨在探讨有限的真实图像与合成图像结合是否能提高用于分类西瓜疾病（Citrullus lanatus）的EfficientNetV2-L模型的预测准确性。", "innovation": "本研究创新点在于使用自定义的EfficientNetV2-L架构结合运用生成型人工智能技术生成的合成图与实际田间图像，通过不同比例的组合训练模型，评估其对疾病分类精度和泛化性的提升效果。结果显示，加入少量真实图像与大量合成图像的组合显著提高了模型性能与泛化性，验证了合成图像和真实图像需结合使用以最大化作物疾病分类模型的表现。", "conclusion": "综合而言，合成图像和真实图像结合使用在作物疾病分类模型中具有显著优势，尽管合成图像不能完全取代真实图象，但两者并用可有效提高模型的准确性和泛化能力。"}
{"llm_update_time": "20250816", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.10232", "html_url": "https://arxiv.org/abs/2508.10232", "title": "CellSymphony：以单细胞病理组学解析细胞的分子和表型编排", "title_en": "CellSymphony: Deciphering the molecular and phenotypic orchestration of cells with single-cell pathomics", "authors": "Paul H. Acosta,Pingjun Chen,Simon P. Castillo,Maria Esther Salvatierra,Yinyin Yuan,Xiaoxi Pan", "background": "在组织病理学图像中存在丰富的形态信息，但要从中提取出稳健的细胞级特征，并将其与空间转录组学数据进行整合仍然是一个关键挑战。", "innovation": "提出了CellSymphony，这是一种灵活的多模态框架，利用Xenium转录组学资料和单细胞分辨率的组织病理学图像的基座模型衍生嵌入方式，联合空间基因表达和形态上下文进行学习，实现了准确的细胞类型注释，并在三种癌症类型中发现了不同的微环境位点。这项工作强调了基座模型和多模态融合在解析复杂组织生态系统内细胞的生理和表型编排中的潜力。", "conclusion": "通过CellSymphony，实现了单细胞分辨率的组织病变解析，并提供了对不同癌症类型中微环境的独特见解，展示了基座模型和多模态融合技术在生物医学研究中的强大潜力。"}
{"llm_update_time": "20250816", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.10227", "html_url": "https://arxiv.org/abs/2508.10227", "title": "EntropyGS：3D高斯渲染的高效熵编码", "title_en": "EntropyGS: An Efficient Entropy Coding on 3D Gaussian Splatting", "authors": "Yuning Huang,Jiahao Pang,Fengqing Zhu,Dong Tian", "background": "3D Gaussian Splatting (3DGS) 是一种新兴的新型视图合成方法，能够以快速的训练/渲染速度和优秀的视觉质量表现出色。3DGS 中的高斯创建和视图渲染任务通常会分开处理，并且因此需要对 3DGS 高斯体进行存储、传输和压缩的操作。本研究从相关性和统计分析的角度出发，分析了 3DGS 高斯体的特点，并发现某些属性遵循 Laplace 分布，某些属性可以近似为混合高斯分布，但这些属性间存在弱相关性。基于此发现，研究提出了一个因子分解且参数化的熵编码方法 EntropyGS，以高效地编码 3DGS 数据。", "innovation": "研究人员提出了一个高效的熵编码方法 EntropyGS，这一方法包括两个关键点：一是通过估计高斯属性的概率分布参数来辅助熵编码；二是根据高斯属性的类型适配量化操作。这种方法在各个基准数据集上可以减少大约30倍的码率，同时保持与输入 3DGS 数据相似的渲染质量，并且具有快速的编码和解码时间。", "conclusion": "EntropyGS 方法成功实现了对 3DGS 数据的有效压缩，大幅减少码率，同时保持了渲染质量，并具有高效的编码和解码性能。"}
{"llm_update_time": "20250816", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.10171", "html_url": "https://arxiv.org/abs/2508.10171", "title": "SynSpill: 使用合成数据改进工业泄漏检测", "title_en": "SynSpill: Improved Industrial Spill Detection With Synthetic Data", "authors": "Aaditya Baranwal,Abdul Mueez,Jason Voelker,Guneet Bhatia,Shruti Vyas", "background": "大型的视觉-语言模型（VLMs）通过强大的零样本能力，已经改变了通用视觉识别。然而，这些模型在工业泄漏检测等小众、安全性关键的领域中表现不佳。在这个领域中，危险事件罕见、敏感且难以标注。数据的稀缺性，受到隐私问题、数据敏感性和实际事件发生频率低等因素的影响，使得传统的模型微调在大多数工业环境中不可行。论文通过引入一个包括高质量合成数据生成流程的可扩展框架解决了这一挑战.", "innovation": "引入了一个可扩展框架，其中包含一个高质量的合成数据生成管道，展示了这种方法可以使参数高效微调（PEFT）视觉语言模型的有效性，并大幅提升了一流的目标检测器如YOLO和DETR的性能。在没有合成数据的情况下，视觉语言模型在未见过的泄漏场景上的泛化能力优于这些检测器。当使用SynSpill数据集时，视觉语言模型和检测器都取得了显著的改进，其性能变得可比。结果表明，高保真度的合成数据是填补某些关键领域中数据差距的有效方法。合成生成和轻量级适应相结合，为在资源稀缺的工业环境中部署视觉系统提供了一种经济高效且可扩展的途径.", "conclusion": "合成数据是关键安全性应用中解决数据稀缺问题的有效手段。合成数据和轻量级适应的结合为工业环境中部署视觉系统提供了一种成本效益高且可扩展的途径。"}
{"llm_update_time": "20250816", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.10113", "html_url": "https://arxiv.org/abs/2508.10113", "title": "LVLMs用于象形和部首分析的可解释甲骨文解译", "title_en": "Interpretable Oracle Bone Script Decipherment through Radical and Pictographic Analysis with LVLMs", "authors": "Kaixin Peng,Mengyang Zhao,Haiyang Yu,Teng Fu,Bin Li", "background": "作为最古老的成熟的书写系统之一，甲骨文（OBS）因其罕见性、抽象性和象形多样性，长期以来给考古学解读带来了显著挑战。现有的基于深度学习的方法在甲骨文解读任务中取得了令人兴奋的进展，但现有方法往往忽略了甲骨文字和OBS语义之间的复杂联系，导致有限的一般性和可解释性，特别是在零样本设置和未解读的甲骨文方面效果不佳。由于上述原因，本文提出了一种基于大型视觉-语言模型的可解释甲骨文解译方法，该方法结合了部首分析和象形文字语义理解，填补了甲骨文字和OBS语义之间的空白。为了便于训练模型，本文还提出了一个包含47,157个标注有OBS图像和象形文字分析文本的甲骨文解读象形文字数据集，使模型能够进行从甲骨文字到语义的推理。实验结果表明，该方法在公共基准上达到了最先进的Top-10准确率，并且具有优越的零样本解译能力，更重要的是，该模型可以提供逻辑分析过程，可能为未解读的甲骨文提供重要的考古学参考结果，具有在数字人文领域和历史研究中的潜在应用价值。", "innovation": "本文提出了基于大型视觉-语言模型的甲骨文解译方法，结合了部首分析和象形文字语义理解，填补了甲骨文字和OBS语义之间的空白，并设计了注释有OBS图像和象形文字分析文本的数据集，进行了有步骤的训练策略，以及基于分析结果的象形文字-部首双匹配机制，显著提高了零样本解译性能。这种方法在OBS解译的Top-10准确率和零样本解译能力方面达到了最先进的水平，同时能够提供逻辑分析过程，具有潜在的考古学应用价值和在数字人文领域和历史研究中的应用前景。", "conclusion": "本文提出的方法在公共基准上达到了最好的Top-10准确率和零样本解译能力，并且提供了逻辑分析过程，有助于考古学有价值的未解读甲骨文的参考结果，尤其是对数字人文和历史研究的应用具有潜在价值。此外，该数据集和代码将公开发布。"}
{"llm_update_time": "20250816", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.10264", "html_url": "https://arxiv.org/abs/2508.10264", "title": "MRFD: Multi-Region Fusion Decoding with Self-Consistency for Mitigating Hallucinations in LVLMs", "title_en": "MRFD: Multi-Region Fusion Decoding with Self-Consistency for Mitigating Hallucinations in LVLMs", "authors": "Haonan Ge,Yiwei Wang,Ming-Hsuan Yang,Yujun Cai", "background": "大型多模态语言视觉模型（LVLMs）在多项任务中表现出色，但这些模型在处理视觉输入时经常产生与实际情况不符的幻觉文本。这主要是由于其验证图像不同区域信息的能力有限，难以确保文本的准确性与场景的一致性。", "innovation": "提出了Multi-Region Fusion Decoding（MRFD），这是一种无需训练的解码方法，通过建模不同区域之间的数据一致性，来改善文本生成的实际地基。MRFD 利用交叉注意力识别有意义的区域，生成每个区域的初始响应，并基于响应之间的Jensen-Shannon发散度计算可靠性权重，随后利用这些权重和区域感知提示进行一致性驱动的预测融合，从而减少幻觉并提高回应的真实度，而无需对模型本身进行更新。", "conclusion": "在多个LVLMs和基准测试中进行的实验表明，MRFD 显著减少了幻觉并改善了回复的真实性。"}
{"llm_update_time": "20250816", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.10268", "html_url": "https://arxiv.org/abs/2508.10268", "title": "移动电话上注视点估计的姿态鲁棒校准策略", "title_en": "Pose-Robust Calibration Strategy for Point-of-Gaze Estimation on Mobile Phones", "authors": "Yujie Zhao,Jiabei Zeng,Shiguang Shan", "background": "尽管基于外观的眼球注视点（PoG）估计已经有所改进，但估计器仍然难以在不同个体间泛化，这是因为个体差异。因此，需要针对个人进行校准以提高PoG估计的准确性。然而，经过校准的PoG估计器对头部姿态变化较为敏感。为解决这一问题，我们研究了影响校准估计器的关键因素，并探索了姿态鲁棒校准策略。我们首先构建了一个基准数据集MobilePoG，其中包括32个个体在固定或持续变化的头部姿态下的面部图片，主要关注特定的面部特征点。", "innovation": "我们首次系统地分析了校准点多样性和头部姿态变化如何影响估计精度。实验结果表明，在校准过程中引入更广泛的头部姿态可以提高对姿态变化的处理能力。基于此，我们提出了一个动态校准策略，用户在移动手机时注视校准点，这样自然地在用户友好的校准过程中引入了头部姿态变化，最终生成一个比传统校准策略更少受到头部姿态变化影响的更好校准的PoG估计器。", "conclusion": "通过动态校准策略，我们能够在用户友好的校准过程中自然地引入头部姿态变化，从而产生比传统校准策略更鲁棒的眼球注视点估计器。相关代码和数据集可在我们的项目页面上获取。"}
{"llm_update_time": "20250816", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.10287", "html_url": "https://arxiv.org/abs/2508.10287", "title": "JRDB-Reasoning: 一种针对机器人视觉推理的难度分级基准", "title_en": "JRDB-Reasoning: A Difficulty-Graded Benchmark for Visual Reasoning in Robotics", "authors": "Simindokht Jahangard,Mehrzad Mohammadi,Yi Shen,Zhixi Cai,Hamid Rezatofighi", "background": "近期视觉语言模型(VLMs)和大规模语言模型(LLMs)的进步显著提高了视觉推理能力，这是诸如机器人这样的体态人工智能代理的关键能力。然而，现有的视觉推理基准存在几个局限性：缺乏明确的推理复杂度定义、无法生成不同难度和任务定制的问题、未能提供结构化的、分步骤推理注解。", "innovation": "我们正式定义推理复杂度、引入了一个自适应查询引擎，该引擎能够生成具有详细中间注解的可定制的、不同复杂度的问题，并扩展了JRDB数据集，加入了人类与物体交互及几何关系注解，以创建JRDB-Reasoning基准，专门针对拥挤环境的视觉推理。该引擎和基准使视觉推理框架的细粒度评估和视觉语言模型在不同推理层级的动态评估成为可能。", "conclusion": "我们的工作通过对视觉推理复杂度的定义、自适应查询引擎的开发和JRDB数据集的新注解，成功构建了JRDB-Reasoning基准，这为视觉推理的研究提供了更精确的评估框架。"}
{"llm_update_time": "20250816", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.10294", "html_url": "https://arxiv.org/abs/2508.10294", "title": "基相位一致加权最小绝对偏差的子像素多模态光学遥感图像配准方法", "title_en": "A Sub-Pixel Multimodal Optical Remote Sensing Images Matching Method", "authors": "Tao Huang,Hongbo Pan,Nanxi Zhou,Shun Zhou", "background": "多模态光学图像的高精度配准是几何处理的基础。但由于不同光谱响应引起的非线性辐射和几何变形差异，通常会导致图像配准精度下降。", "innovation": "提出了相位一致性加权最小绝对偏差（PCWLAD）子像素模板匹配方法，该方法包括两步：一是使用结构相似性指数（SSIM）进行粗匹配，二是使用最小绝对偏差（WLAD）进行细匹配。在细匹配步骤中，应用了辐射和几何变换模型，同时采用了互构结构滤波来削弱模板中噪声的影响，并使用WLAD准则估计子像素偏移。", "conclusion": "PCWLAD方法在三种类型的数据集上均表现出色，相比于其他八种先进方法，在正确匹配率和均方根误差方面表现更好，并实现了约0.4像素的平均配准精度。研究提供的软件和数据集可在公开链接中访问。"}
{"llm_update_time": "20250816", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.10280", "html_url": "https://arxiv.org/abs/2508.10280", "title": "使用对比对齐和结构引导实现高保真文本到图像生成", "title_en": "High Fidelity Text to Image Generation with Contrastive Alignment and Structural Guidance", "authors": "Danyi Gao", "background": "现有基于文本的图像生成方法在语义对齐准确性和结构一致性方面存在性能瓶颈。", "innovation": "提出了结合文本图像对比约束和结构引导机制的高保真图像生成方法。引入对比学习模块建立强跨模态对齐约束以提升语义匹配；同时使用语义布局图或边缘素描等结构先验来指导生成器在空间层次上的结构建模，增强生成图像的布局完整性和细节保真度。模型在整体框架下联合优化对比损失、结构一致性损失和语义保留损失，采用多目标监督机制提升生成内容的语义一致性和可控性。", "conclusion": "系统地在COCO-2014数据集上进行了实验，敏感性分析了嵌入维度、文本长度和结构引导强度。定量指标证实该方法在CLIP Score、FID和SSIM方面的表现优于现有技术。结果表明，该方法有效缩小了语义对齐和结构保真度之间的差距，显著提高了生成图像的语义清晰度和结构完整性，提供了一种联合文本图像建模和图像生成的可行技术支持。"}
{"llm_update_time": "20250816", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.10339", "html_url": "https://arxiv.org/abs/2508.10339", "title": "概念或技能？重新思考多模态模型中指令选择", "title_en": "Concepts or Skills? Rethinking Instruction Selection for Multi-modal Models", "authors": "Andrew Bai,Justin Cui,Ruochen Wang,Cho-Jui Hsieh", "background": "视觉-语言基准主要受益于与训练指令相似的技能或视觉概念的训练。现有的研究表明，多模态模型在处理这些基准时，可以根据相似的技能或视觉概念进行优化。", "innovation": "作者提出了一个简单的目标导向的数据选择方法，首先从基准中抽取概念/技能，确定基准主要受益于相似的概念还是技能，最后选择与这些概念/技能最匹配的指令。实验在10多个基准上验证了该方法的有效性，平均提高了现有的最佳基线0.9%，在技能侧重的子集上提高了1.5%。", "conclusion": "研究强调了在指令选择中认识到内在权衡的重要性，即平衡概念知识的获取与视觉技能的提升。"}
{"llm_update_time": "20250816", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.10316", "html_url": "https://arxiv.org/abs/2508.10316", "title": "将强化学习与视觉生成模型集成：基础与进展", "title_en": "Integrating Reinforcement Learning with Visual Generative Models: Foundations and Advances", "authors": "Yuanzhi Liang,Yijie Fang,Rui Li,Ziqi Ni,Ruijie Su,Chi Zhang,Xuelong Li", "background": "生成模型在合成图像、视频和3D/4D结构方面取得了显著进展，但通常依赖似然或重构损失等替代目标进行训练，这往往会与感知质量、语义准确度或物理现实性相偏差。强化学习（RL）提供了一种原理上明确的方法来优化非可微、偏好驱动和时间结构化的目标。最新研究表明，它在提高可控性、一致性和高度的人类一致性方面在生成任务中表现出有效性。", "innovation": "本文提供了一种系统的方法来概述基于RL的视觉内容生成方法，从经典控制到RL作为通用优化工具的角色演变，同时考察了其在图像、视频和3D/4D生成中的整合。RL不仅作为一种细调机制，也作为一种与复杂、高层次目标对齐结构组件。", "conclusion": "本文总结了RL与生成建模相交领域的开放挑战和未来研究方向。"}
{"llm_update_time": "20250816", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.10309", "html_url": "https://arxiv.org/abs/2508.10309", "title": "从像素到掩码：一种关于异常分布分割的综述", "title_en": "From Pixel to Mask: A Survey of Out-of-Distribution Segmentation", "authors": "Wenjie Zhao,Jia Li,Yunhui Guo", "background": "随着对AI安全的关注增加，异常分布检测和分割（Out-of-Distribution, OoD）引起了广泛关注。传统的OoD检测方法能够识别OoD对象的存在，但缺乏空间定位能力，这在下游任务中限制了它们的实际应用。OoD分割通过像素级别的定位异常物体，解决了这一局限性。这种能力对于自动驾驶等关键安全应用至关重要，其中感知模块不仅需要检测异常物体，还需要精确分割它们，以便进行有针对性的控制操作，从而增强系统的整体鲁棒性。", "innovation": "本文将当前OoD分割方法分为四类：(i) 测试时OoD分割，(ii) 监督训练中的异常暴露，(iii) 基于重建的方法，(iv) 利用强大模型的方法。本文系统地回顾了OoD分割在自动驾驶场景中的最新进展，指出了新兴挑战，并讨论了具有前景的未来研究方向。", "conclusion": "本文通过分类当前OoD分割方法，回顾了相关领域的最新进展，指出了一些新兴挑战，并为未来研究方向提供了建议。"}
{"llm_update_time": "20250816", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.10281", "html_url": "https://arxiv.org/abs/2508.10281", "title": "VIFSS: 观点不变且针对花样滑冰的姿势表示学习方法以用于时序动作分割", "title_en": "VIFSS: View-Invariant and Figure Skating-Specific Pose Representation Learning for Temporal Action Segmentation", "authors": "Ryota Tanaka,Tomohiro Suzuki,Keisuke Fujii", "background": "从视频中理解人类动作在许多领域都至关重要，特别是在体育分析中。在花样滑冰中，准确地识别一个滑冰者执行的跳跃类型和时间对于客观评估其表现非常重要。然而，这项任务通常需要专家级的知识，因为跳跃的过程既精密又复杂。尽管最近的研究尝试通过使用时序动作分割（TAS）来自动化这一任务，但TAS在花样滑冰中的应用存在两个主要限制：标注数据不足，且现有的方法没有考虑到跳跃动作内在的三维特性和程序结构。针对这些问题，本文提出了一种新的TAS框架，该框架专为花样滑冰跳跃设计，明确地结合了跳跃动作的三维特性和语义程序。", "innovation": "本文的主要创新之处在于提出了一个新型的观点不变且针对花样滑冰的姿势表示学习框架（VIFSS）。该框架结合了对比学习（用于预训练）和动作分类（用于微调），并引入了一种细化的标注方案来标记“进入”和“着陆”阶段，从而使得TAS模型能够学习跳跃动作的程序结构。具体而言，作者构建了专用于花样滑冰跳跃的第一个3D姿势数据集FS-Jump3D，并提出了结构化动作分割方法，该方法在元素级别的TAS任务上达到了超过92%的F1@50分。", "conclusion": "本文的方法在元素级别的时序动作分割任务上达到了92%以上的F1@50指标，且当细粒度的微调数据有限时，观点不变的对比预训练方法特别有效。这证明了该方法在实际场景中的实用性。"}
{"llm_update_time": "20250816", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.10351", "html_url": "https://arxiv.org/abs/2508.10351", "title": "Glo-DMU: 肾脏电子显微镜图像中超微结构形态学的深度表征框架", "title_en": "Glo-DMU: A Deep Morphometry Framework of Ultrastructural Characterization in Glomerular Electron Microscopic Images", "authors": "Zhentai Zhang,Danyi Weng,Guibin Zhang,Xiang Chen,Kaixing Long,Jian Geng,Yanmeng Lu,Lei Zhang,Zhitao Zhou,Lei Cao", "background": "超微结构的复杂多样性可以指示肾脏疾病的类型、进展和预后。近年来，结合深度学习方法的计算病理学在自动分析肾小球超微结构形态学方面展现出巨大的潜力。然而，当前研究主要集中在对单一超微结构的识别上，难以满足实际的诊断需求。", "innovation": "提出了基于三种深度模型的肾小球超微结构表征形态学框架（Glo-DMU），能够在肾脏活检诊断的常规流程中，同时量化三个最重要的超微结构特征：肾小球基底膜的厚度、足突耗损的程度以及电子致密沉积物的位置。Glo-DMU 具有全自动化、高精度和高通量的特点，能够同时量化多个超微结构特征，并提供一种高效支持肾脏病理学家的工具。", "conclusion": "Glo-DMU 在真实诊断场景中对 115 例具有 9 种肾病理类型的患者进行了评估，自动量化结果与病理报告中的形态描述具有一致性。Glo-DMU 能够实现超微结构特征的全自动化、高精度和高通量量化，提供了一种高效的肾脏病理诊断工具。"}
{"llm_update_time": "20250816", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.10297", "html_url": "https://arxiv.org/abs/2508.10297", "title": "InterSyn：野外动态运动合成的交织学习", "title_en": "InterSyn: Interleaved Learning for Dynamic Motion Synthesis in the Wild", "authors": "Yiyi Ma,Yuanzhi Liang,Xiu Li,Chi Zhang,Xuelong Li", "background": "研究目标是生成高度真实的交互动作，尤其是在考虑到单人和多人动态的情况下。现有的方法通常是将这些组件分开处理，但未能完全捕捉现实世界中自然、动态的交互和协调。因此，需要一个新的框架来整合这些交互，并在统一的视角下模拟多个角色的互动，同时确保角色动作的同步协调。", "innovation": "InterSyn 提出了一种新颖的框架，通过综合考量单人和多人的动态，采用交织学习策略来捕捉自然的动态交互和复杂的协调性。该框架包括两个主要模块：交互合成（INS）模块，该模块从第一视角统一建模单人和交互行为，支持多个角色的互动；相对协调精炼（REC）模块，该模块细化了角色之间的相互动力学，确保角色动作的同步性。与现有方法相比，InterSyn 生成的运动序列在文本到运动的对齐度和多样性方面表现出更好的效果，成为了一个新的基准。", "conclusion": "实验结果表明，InterSyn 生成的运动序列在文本到运动的对齐度和多样性方面优于现有方法，建立了新的基准。未来，代码将开源，以促进对该领域的进一步研究和发展。"}
{"llm_update_time": "20250816", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.10356", "html_url": "https://arxiv.org/abs/2508.10356", "title": "提高多种语言古代文本OCR效果的方法", "title_en": "Improving OCR for Historical Texts of Multiple Languages", "authors": "Hylke Westerdijk,Ben Blankenborg,Khondoker Ittehadul Islam", "background": "本文通过使用先进的深度学习技术，研究了OCR和文档布局分析中的方法和发现，特别是在处理希伯来文残片、16至18世纪会议决议和现代英文手写识别任务方面的进步。", "innovation": "主要创新在于：1) 对希伯来文残片数据集进行了大量数据增强，并使用Kraken和TrOCR模型提高了字符识别效果；2) 使用Convolutional Recurrent Neural Network (CRNN) 结合DeepLabV3+和双向LSTM进行语义分割，并采用基于置信度的伪标签方法来改进模型；3) 对现代英文手写识别任务采用了带有ResNet34编码器的CRNN，并使用Connectionist Temporal Classification (CTC) 损失函数来捕捉序列依赖关系，从而提高识别效果。", "conclusion": "本文通过对OCR技术的研究提供了有价值的见解，并提出了未来研究的可能方向。"}
{"llm_update_time": "20250816", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.10397", "html_url": "https://arxiv.org/abs/2508.10397", "title": "PQ-DAF: 基于姿态驱动的高质量数据增强框架用于数据稀缺的驾驶员分心检测", "title_en": "PQ-DAF: Pose-driven Quality-controlled Data Augmentation for Data-scarce Driver Distraction Detection", "authors": "Haibin Sun,Xinghui Song", "background": "驾驶员分心检测对于提高道路交通安全和减少事故至关重要。然而，现有的模型在实际部署场景中经常遭受性能泛化的下降。这一局限主要是由于实际环境数据注释成本高导致的少量样本学习挑战以及训练数据集与目标部署条件之间的显著领域转换。", "innovation": "我们提出了一种基于姿态驱动的质量控制数据增强框架（PQ-DAF），该框架利用视觉-语言模型进行样本筛选，以经济高效地扩展训练数据并提高跨域鲁棒性。该框架具体运用渐进条件扩散模型（PCDMs）准确捕捉关键驾驶员姿态特征并合成多样化的训练示例，还引入了基于自信度阈值的样本质量评估模块，以剔除低质量的合成样本，确保增强数据集的可靠性。", "conclusion": "广泛的实验表明，PQ-DAF在少量样本驾驶员分心检测中显著提高了性能，尤其是在数据稀缺条件下实现了模型泛化的大幅提升。"}
{"llm_update_time": "20250816", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.10359", "html_url": "https://arxiv.org/abs/2508.10359", "title": "AtomDiffuser：STEM 成像中时间意识降解建模以处理漂移和束损伤", "title_en": "AtomDiffuser: Time-Aware Degradation Modeling for Drift and Beam Damage in STEM Imaging", "authors": "Hao Wang,Hongkui Zheng,Kai He,Abolfazl Razi", "background": "扫描透射电子显微镜（STEM）在现代材料科学中发挥着关键作用，能够直接成像原子结构及其在外部干扰下的演变。然而，解释时间相关STEM数据仍然具有挑战性，因为存在两种交织的退化效应：由机械和热不稳定性引起的空间漂移，以及由辐射损伤引起的信号损失。这些因素以复杂的方式共同作用，既影响几何形状也影响强度，使得现有方法难以明确分离这些效应或在原子分辨率下建模材料动力学。", "innovation": "我们提出了一种时间感知退化建模框架 AtomDiffuser，用于分离样品漂移和辐射衰减，通过预测任何两个STEM帧之间的仿射变换和空间变异性衰减图。与传统的降噪或配准管道不同，我们的方法利用退化作为物理启发的过程，基于时间条件，从而实现可解释的跨时间结构演变。AtomDiffuser 还在合成退化处理上进行了训练，并在真实的冷冻 STEM 数据上表现出良好的泛化能力。另外，AtomDiffuser 还支持高分辨率退化推断和漂移对齐，提供与辐射诱导原子不稳定相关联的退化模式的可视化和量化工具。", "conclusion": "本研究提出了一种名为 AtomDiffuser 的时间感知退化建模框架，能够有效分离与 STEM 数据退化相关的漂移和束损伤效应。该框架通过预测两个 STEM 帧之间的仿射变换和空间变异性衰减图，实现对材料结构随时间演变的可解释建模，并能够抵御机械、热不稳定性和辐射损伤的影响。"}
{"llm_update_time": "20250816", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.10411", "html_url": "https://arxiv.org/abs/2508.10411", "title": "SC-Lane：一种坡度感知且具有一致性的道路高度估计框架，用于3D车道检测", "title_en": "SC-Lane: Slope-aware and Consistent Road Height Estimation Framework for 3D Lane Detection", "authors": "Chaesong Park,Eunbin Seo,Jihyeon Hwang,Jongwoo Lim", "background": "在3D车道检测领域，传统的高度图估计方法通常依赖于固定的坡度锚点。这些方法在面对不同道路几何形状时缺乏鲁棒性。为了改进这一点，研究人员引入了多种新技术，如SC-Lane框架。该框架通过动态预测不同坡度的图像线索权重，整合多坡度表示，从而增强稳定性和准确性。", "innovation": "SC-Lane框架包含了两个关键模块：Slope-Aware Adaptive Feature模块和Height Consistency模块。前者能够根据坡度调整权重，动态整合多坡度特征，后者则确保前后帧之间的高度估计保持一致性。这种创新性方法提高了对复杂道路几何形状的适应能力，同时在实际驾驶场景中展现出更好的性能。", "conclusion": "通过使用标准化的MAE、RMSE和基于阈值的准确性评估指标，SC-Lane在LiDAR提取的高度图数据集上达到了最先进的性能，F分数为64.3%，超过了现有方法。实验结果验证了该框架的有效性和鲁棒性，为未来的研究提供了重要的参考基准。"}
{"llm_update_time": "20250816", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.10407", "html_url": "https://arxiv.org/abs/2508.10407", "title": "通过Delta向量转换文本嵌入以抑制文本到图像扩散模型中的强关联内容", "title_en": "Translation of Text Embedding via Delta Vector to Suppress Strongly Entangled Content in Text-to-Image Diffusion Models", "authors": "Eunseo Koh,Seunghoo Hong,Tae-Young Kim,Simon S. Woo,Jae-Pil Heo", "background": "文本到图像（T2I）扩散模型在从文本提示生成多样化高质量图像方面取得了显著进展。然而，这些模型在抑制特定词汇强烈关联的内容方面仍然面临挑战。例如，生成“查理·卓别林”的图像时，即使明确指示不包含，也可能始终出现“胡须”，因为“胡须”与“查理·卓别林”之间存在强烈的关联。", "innovation": "文章提出了一种新颖的方法，可以直接在扩散模型的文字嵌入空间中抑制这种关联内容。方法包括引入一个delta向量来修改文本嵌入，从而减弱生成图像中不必要的内容影响；并通过零样本方法轻松获取delta向量。进一步提出了Selective Suppression with Delta Vector (SSDV)方法，将delta向量适配到跨注意力机制中，以更有效地抑制-away在生成区域中本应出现的不希望的内容。此外，通过优化delta向量，文章实现了更加精确的个性化T2I模型中不希望内容的抑制，这是先前基线方法无法实现的。", "conclusion": "大量实验结果表明，本文的方法在定量和定性指标上均显著优于现有方法。"}
{"llm_update_time": "20250816", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.10367", "html_url": "https://arxiv.org/abs/2508.10367", "title": "Multimodal 视觉-语言模型的对比敏感度函数", "title_en": "Contrast Sensitivity Function of Multimodal Vision-Language Models", "authors": "Pablo Hernández-Cámara,Alexandra Gomez-Villa,Jose Manuel Jaén-Lorites,Jorge Vila-Tomás,Jesus Malo,Valero Laparra", "background": "评估多模态视觉-语言模型（VLMs）与人类视觉感知的一致性对于理解它们如何感知低级视觉特征至关重要。人类视觉的一个重要特征是对比敏感度函数（CSF），它描述了在低对比度下对空间频率的敏感性。先前的方法可能与真实的心理学实验相比不够精确。本研究提出了一种基于行为心理物理学的新方法，通过直接提示模型判断不同对比度下的模式可见性，以估算基于聊天的VLMs的CSF。", "innovation": "本研究介绍了一种新的行为心理物理学启发式方法，通过直接提示模型判断不同对比度下的模式可见性来估计基于聊天的VLMs的CSF。这种方法更接近真实的心理学实验。此外，通过带通过滤噪声图像和一系列提示评估了模型的响应，发现尽管有些模型能够接近人类的CSF形状或大小，但没有一个模型能够完全复制人类的CSF。提示措辞对响应有显著影响，引发了对提示稳定性的担忧。", "conclusion": "研究结果提供了一种新的框架来探究多模态模型的视觉敏感性，并揭示了它们的视觉表示与人类感知之间的关键差距。"}
{"llm_update_time": "20250816", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.10382", "html_url": "https://arxiv.org/abs/2508.10382", "title": "在扩散模型中整合内在场景属性以实现空间一致性图像生成", "title_en": "Towards Spatially Consistent Image Generation: On Incorporating Intrinsic Scene Properties into Diffusion Models", "authors": "Hyundo Lee,Suhyung Choi,Byoung-Tak Zhang,Inwoo Hwang", "background": "现有的图像生成模型在大规模数据集上训练可以生成高质量的图像，但常常会产生空间上不一致且扭曲的图像，这是因为这些模型受限于关于底层结构和空间布局的有限信息。传统的做法要么依赖于图像-文本对，要么将内在属性作为条件输入，这种方法并不能有效捕捉到图像的底层结构。该论文研究旨在通过利用提供丰富内在场景信息的内在属性来改进图像生成技术，以生成更空间一致且真实的图像。", "innovation": "论文提出了一种新的方法，通过利用预训练的标量器从大规模图像数据集中提取丰富的内在场景属性，无需额外的场景信息或显式的3D表示。接着，使用自编码器将各种内在场景属性整合到单一的潜在变量中。在此基础上，利用预训练的大规模潜扩散模型（LDMs）同时对图像和内在属性进行去噪处理，并通过谨慎地共享相互信息使得图像和内在属性相互反映而不损害图像质量。这一方法创新地将内在属性与扩散模型结合起来，以提高生成图像的空间一致性。", "conclusion": "实验结果表明，该方法能够纠正空间不一致性，生成更自然且布局合理的场景，同时保持基础模型（如Stable Diffusion）的忠实度和文本对齐性。"}
{"llm_update_time": "20250816", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.10383", "html_url": "https://arxiv.org/abs/2508.10383", "title": "通过仅标签弹性变形对抗隐式标签噪声实现稳健的语义分割性能", "title_en": "Unlocking Robust Semantic Segmentation Performance via Label-only Elastic Deformations against Implicit Label Noise", "authors": "Yechan Kim,Dongho Yoon,Younkwan Lee,Unse Fatima,Hong Kook Kim,Songjae Lee,Sanga Park,Jeong Ho Park,Seonjong Kang,Moongu Jeon", "background": "以往的研究主要集中在处理严重的（或显式的）标签噪声，而现实世界的数据集也表现出轻微的（或隐式的）标签缺陷。这些缺陷源于难以辨别的对象边界和注释员的可变性，即使这些缺陷未被明确出现，也会影响模型的性能。常用的增强方法由于同时对图像和标签进行相同的变换，会放大这些细微缺陷，限制模型的泛化能力。本研究探讨了如何通过减少隐式标签噪声来提升语义分割的稳健性.", "innovation": "本文提出了NSegment+，一种新颖的增强框架，通过解耦图像和标签的变换来应对现实中的噪声。NSegment+仅对分割标签进行受控的弹性变形，同时保持原始图像不变，从而鼓励模型在存在轻微标签不一致性的情况下学习稳健的对象结构表示。实验表明，NSegment+能显著提高性能，甚至在没有额外技巧的情况下也能实现平均mIoU提高2.29%至3.39%的效果，强调了处理隐式标签噪声的重要性。结合其他训练技巧，如CutMix和Label Smoothing，效果还可以进一步提升", "conclusion": "NSegment+通过解耦增强方法有效减少了隐式标签噪声，从而提升了语义分割的鲁棒性。实验结果证明了即使不使用额外手段，仅通过对标签进行受控弹性变形就能显著提高模型性能。"}
{"llm_update_time": "20250816", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.10256", "html_url": "https://arxiv.org/abs/2508.10256", "title": "基于深度学习的裂缝检测：学习范式、泛化能力和数据集的综述", "title_en": "Deep Learning for Crack Detection: A Review of Learning Paradigms, Generalizability, and Datasets", "authors": "Xinan Zhang,Haolin Wang,Yung-An Hsieh,Zhongyu Yang,Anthony Yezzi,Yi-Chang Tsai", "background": "裂缝检测在基础设施检测中至关重要，涉及路面、建筑等领域的检查。近年来，深度学习在这一领域取得了显著进展。尽管已有大量的技术论文和综述文章，但新兴趋势正在重塑这一领域的格局。这些趋势包括从完全监督学习到半监督、弱监督、无监督、少样本、领域适应和微调基础模型等学习范式的转变，泛化能力从单数据集向跨数据集的提升，以及数据集获取的多元化，例如从RGB图像到专用传感器数据等。", "innovation": "本文系统地分析了这些发展趋势，并介绍了代表性的研究工作。此外，还引入了一个使用3D激光扫描收集的新数据集，名为3DCrack，用于支持未来的研究，并进行了广泛的基准实验，为常用的深度学习方法，包括最近的基础模型，建立了基准线。这些发现提供了深度学习方法在裂缝检测领域演变的方法和未来方向的见解。", "conclusion": "本文的研究结果提供了深入学习方法在裂缝检测领域演变的方法和未来方向的见解，还为基础模型在裂缝检测中的应用提供了基准线。"}
{"llm_update_time": "20250816", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.10424", "html_url": "https://arxiv.org/abs/2508.10424", "title": "NanoControl: 一种轻量级的精确高效控制框架在扩散变换器中", "title_en": "NanoControl: A Lightweight Framework for Precise and Efficient Control in Diffusion Transformer", "authors": "Shanyuan Liu,Jian Zhu,Junda Lu,Yue Gong,Liuzhuozheng Li,Bo Cheng,Yuhang Ma,Liebucha Wu,Xiaoyu Wu,Dawei Leng,Yuhui Yin", "background": "扩散变换器（DiTs）在文本到图像合成方面已经显示出出色的能力。然而，在基于DiTs的可控文本到图像生成领域，大多数现有方法仍然依赖于最初为UNet基扩散模型设计的ControlNet范式。这种范式引入了显著的参数冗余和增加的计算成本。为了解决这些挑战，我们提出了一种基于Flux作为骨干网络的Nano Control Diffusion Transformer（NanoControl）模型。该模型在参数数量和GFLOPs方面仅增加了0.024%和0.029%，但仍实现了最先进的可控文本到图像生成性能，从而使生成过程变得高效。此外，不同于为控制复制DiT骨干网络，我们设计了一种LoRA风格的控制模块，可以直接从原始条件输入中学习控制信号。进一步引入了一种KV-Context Augmentation机制，以一种简单而高效的方式将条件特定的键值信息整合到骨干中，促进了条件特征的深度融合。广泛的基准实验表明，与传统控制方法相比，NanoControl显着减少了计算开销，同时保持了优越的生成质量和更好的可控制性。", "innovation": "NanoControl模型采用Flux作为骨干网络，仅增加0.024%的参数和0.029%的GFLOPs的情况下实现了最先进的可控文本到图像生成性能。该模型设计了一种LoRA风格的控制模块，从原始条件输入中直接学习控制信号，并引入了一种KV-Context Augmentation机制将条件特定的键值信息整合到骨干中，促进了条件特征的深度融合。此外，NanoControl模型显著减少了计算开销，同时保持了优越的生成质量和更好的可控制性。", "conclusion": "广泛的基准实验表明，NanoControl模型在计算开销上显著减少，同时保持了优秀的生成质量和更高的可控性。"}
{"llm_update_time": "20250816", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.10464", "html_url": "https://arxiv.org/abs/2508.10464", "title": "SingleStrip: 仅使用一个标注样本学习去骨处理", "title_en": "SingleStrip: learning skull-stripping from a single labeled example", "authors": "Bella Specktor-Fadida,Malte Hoffmann", "background": "深度学习分割高度依赖于标注数据，但手动标注是劳动密集型且耗时的，尤其是在处理像脑磁共振成像（MRI）这样的体视图像时。近年来，领域随机化技术通过从标签地图合成多样化的训练图像来减少对标注数据的依赖，但在标签地图稀缺的情况下，这种技术提供的解剖变异有限。半监督自训练通过将模型预测迭代地纳入训练集，解决标签稀缺问题，使网络能够从未标注数据中学习。这项工作中，作者将领域随机化与自训练结合，仅使用一个标注示例训练三维去骨处理网络。", "innovation": "作者提出了一种结合领域随机化与半监督自训练的方法，仅使用单一标注样本来训练三维去骨处理网络。首先，通过自动分桶体素强度得到标签，用于合成用于训练初始去骨模型的图像。其次，训练卷积自编码器（AE）在标注样本上，使用其重建误差评估未标注数据中脑部掩码的质量。最后，选择排名较高的伪标签用于网络的微调。这种方法在处理不同分布数据时，达到了接近使用更多标注图像训练的模型的效果，证明了领域随机化与基于AE的质量控制结合的有效性。", "conclusion": "该研究展示了结合领域随机化和AE基线质量控制如何从极其有限的标注数据中实现有效的半监督分割。这项策略可能有助于减轻标注负担，从而使研究涉及新的解剖结构或新兴成像技术的进展变得更为流畅。"}
{"llm_update_time": "20250816", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.10432", "html_url": "https://arxiv.org/abs/2508.10432", "title": "CRISP: 对抗残差注入和语义提示在持续视频实例分割中的应用", "title_en": "CRISP: Contrastive Residual Injection and Semantic Prompting for Continual Video Instance Segmentation", "authors": "Baichen Liu,Qi Lyu,Xudong Wang,Jiahua Dong,Lianqing Liu,Zhi Han", "background": "持续视频实例分割需要同时具备吸收新对象类别和保留之前学习类别的灵活性，同时保持跨帧的一致性。现有方法在处理持续实例分割任务中的类别混淆、任务混淆和实例混淆时表现不佳，容易导致灾难性遗忘，影响分割和分类性能。因此需要一种既能确保类别、实例和任务的一致性，又能避免灾难性遗忘的解决方案。", "innovation": "本文提出了CRISP（ Contrastive Residual Injection and Semantic Prompting，对抗残差注射和语义提示）方法。在实例层面，通过实例跟踪和实例相关损失来体现与先前查询空间的相关性，加强当前任务查询的特定性；在类别层面上，构建了适应的残差语义提示（ARSP）学习框架，通过类别文本生成可学习的语义残差提示池，并使用调整查询-提示匹配机制建立当前任务查询和语义残差提示之间的映射关系；在任务层面上，通过在增量训练过程中引入基于语义一致性损失的对抗学习，保持对象查询和残差提示之间的语义连贯性。此外，还提出了一种简洁而强大的初始化策略来确保跨任务查询空间中的相关性。", "conclusion": "实验结果表明，CRISP 在 YouTube-VIS-2019 和 YouTube-VIS-2021 数据集上显著优于现有的持续分割方法，在长周期持续视频实例分割任务中避免了灾难性遗忘并有效提升了分割和分类性能。源代码可在论文网址处获取。"}
{"llm_update_time": "20250816", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.10453", "html_url": "https://arxiv.org/abs/2508.10453", "title": "Trajectory-aware Shifted State Space Models for Online Video Super-Resolution", "title_en": "Trajectory-aware Shifted State Space Models for Online Video Super-Resolution", "authors": "Qiang Zhu,Xiandong Meng,Yuxian Jiang,Fan Zhang,David Bull,Shuyuan Zhu,Bing Zeng", "background": "在线视频超分辨率（VSR）是一项重要的技术，用于许多实际的视频处理应用，其目标是基于时间上之前的帧来恢复当前的高分辨率视频帧。目前大多数的在线VSR方法仅利用一个相邻的过去帧来实现时间对齐，这限制了视频的长期时间建模。最近，状态空间模型（SSMs）被提出，具有线性计算复杂度和全局的感受野，显著提高了计算效率和性能。因此，本文提出了一种基于轨迹感知偏移SSM（TS-Mamba）的新在线VSR方法，结合长距离轨迹建模和低复杂度Mamba，实现了高效的时空信息聚合。", "innovation": "该方法通过使用轨迹感知偏移SSM模块，结合轨迹感知偏移Mamba聚合（TSMA）模块，设计了基于Hilbert扫描的偏移SSM块，以补偿扫描损失并增强Mamba的空间连续性。此外，还提出了轨迹感知的损失函数来监督轨迹生成，确保模型训练时的准确性。与六个在线VSR基准模型相比，在三个广泛使用的VSR测试数据集上的大量实验表明，TS-Mamba在大多数情况下都达到了最先进的性能，并实现了超过22.7％的MAC复杂度降低。", "conclusion": "本文提出的在线视频超分辨率方法TS-Mamba，在多个广泛使用的VSR测试数据集上获得了最先进的性能，并实现了复杂度的显著降低。"}
{"llm_update_time": "20250816", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.10445", "html_url": "https://arxiv.org/abs/2508.10445", "title": "DOD-SA: 单模态注解下的红外可见物体检测去耦合框架", "title_en": "DOD-SA: Infrared-Visible Decoupled Object Detection with Single-Modality Annotations", "authors": "Hang Jin,Chenqiang Gao,Junjie Guo,Fangcen Liu,Kanghui Tian,Qinyao Chang", "background": "红外可见物体检测在实际应用中表现出巨大的潜力，能够通过利用红外和可见光图像的互补信息实现全天候感知。然而，现有方法通常需要双重模态注解才能在预测过程中输出两种模态的检测结果，这导致了高昂的注解成本。因此，为了解决这个问题，本文提出了一种名为DOD-SA的单模态注解下红外可见物体检测去耦合框架。", "innovation": "本文创新点在于提出了一种DOD-SA框架，它基于单模态和双模态协作教师-学生网络（CoSD-TSNet），包括单模态分支（SM-Branch）和双模态去耦分支（DMD-Branch）。并且引入了一种渐进式和自调校训练策略（PaST），包含三个阶段：预训练单模态分支、由单模态分支引导双模态去耦分支的学习、以及精炼双模态去耦分支。此外，设计了一个伪标签分配器（PLA），以解决训练中模态不一致的问题。实验结果表明，该方法在DroneVehicle数据集上优于现有最佳方法。", "conclusion": "本文提出了一种名为DOD-SA的单模态注解下红外可见物体检测去耦合框架，该框架利用协作教师-学生网络等结构，有效降低了双重模态注解成本，并通过引入渐进式和自调校训练策略进一步提升了模型性能。实验结果证明，该方法在DroneVehicle数据集上表现优异，优于现有先进方法。"}
{"llm_update_time": "20250816", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.10449", "html_url": "https://arxiv.org/abs/2508.10449", "title": "SkeySpot：为建筑业数字电气布局计划自动化识别服务关键符号", "title_en": "SkeySpot: Automating Service Key Detection for Digital Electrical Layout Plans in the Construction Industry", "authors": "Dhruv Dosi,Rohit Meena,Param Rajpura,Yogesh Kumar Meena", "background": "传统的图纸资料，如电气布局图，常常只有扫描文档的形式存在，对于建筑、城市规划和设施管理等行业仍然是重要的资源。然而，缺乏可机器读取的图纸使得大规模解释变得耗时且容易出错。自动化符号识别通过直接从电气布局图中识别服务关键符号，支持诸如成本估算、基础设施维护和合规性检查等流程，为解决这一问题提供了可扩展的解决方案。现有的评估框架往往未能充分体现出这些自动化工具的实际性能。因此，开发一套系统性评估框架对于优化现有模型至关重要，尤其是在面对各种异构图示风格的电气布局图时。", "innovation": "本文介绍了名为SkeySpot的轻量级、开源工具包，用于实时检测、分类和量化电气符号。SkeySpot采用了预训练的检测模型，特别是YOLOv8，在名为DELP的数据集上获得了最佳性能。SkeySpot生成结构化、标准化的输出，可以用于可扩展的建筑信息交互流程，实现下游应用和监管平台间的兼容性。相比依赖专有CAD系统，该方法降低了中小企业在建筑行业进行电气布局图数字化的准入门槛，支持标准、互操作性和建筑环境可持续性的广泛目标。", "conclusion": "通过减少对专有CAD系统的依赖并降低手动标注工作量，SkeySpot方法使电气布局图的数字化过程对中小型建筑企业更加可行，同时也支持了更广泛的标准化、互操作性以及建筑环境的可持续性目标。这种方法有助于提高建筑行业的整体效率，推动建筑信息模型更加标准化和互操作性的发展。"}
{"llm_update_time": "20250816", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.10457", "html_url": "https://arxiv.org/abs/2508.10457", "title": "增强元数据的多头视觉变换器在多标签植物物种预测中的应用", "title_en": "Multi-Label Plant Species Prediction with Metadata-Enhanced Multi-Head Vision Transformers", "authors": "Hanna Herasimchyk,Robin Labryga,Tomislav Prusina", "background": "本文介绍了一种多头视觉变换器方法，用于植被地块图像中的多标签植物物种预测，以应对PlantCLEF 2025挑战。任务涉及在单物种植物图像上训练模型，在多物种地块图像上进行测试，从而造成明显的领域转移。研究方法利用预训练的DINOv2视觉变换器基础模型（ViT-B/14），并结合多个分类头进行物种、属和科的预测，利用分类学层次结构。该方法通过多尺度切片来捕捉不同尺度的植物，利用均值预测长度优化动态阈值，并通过袋装和Hydra模型架构等集成策略进行优化。研究还结合了包括图像裁剪去除非植物伪影、top-n过滤、预测约束和logit阈值策略等多种推理技术。实验基于大约140万张训练图像，这些图像覆盖了7,806个植物物种。研究结果显示出强大的性能，使我们提交位列私人排行榜第三名。我们的代码可在以下网址获取：this https URL.", "innovation": "本文主要创新点包括：1) 多尺度切片以捕捉不同规模的植物；2) 动态阈值优化基于均值预测长度；3) 通过袋装和Hydra模型架构的集成策略；4) 结合多种推理技术，如图像裁剪、top-n过滤、logit阈值策略等。这些创新方法有效提高了多标签植物物种预测的性能和准确性。", "conclusion": "该研究提出的方法在多标签植物物种预测上展示了出色的性能，并在PlantCLEF 2025挑战中取得优秀成绩，位列私人排行榜第三名。通过增强元数据利用多头视觉变换器的方法，提高了植物物种分类的准确性和鲁棒性。该研究的代码已经公开，为后续研究提供了宝贵的参考和基础。"}
{"llm_update_time": "20250816", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.10473", "html_url": "https://arxiv.org/abs/2508.10473", "title": "STAMP: 多模式注意力感知的多次实例学习在多中心组织病理图像STAS诊断中的应用", "title_en": "STAMP: Multi-pattern Attention-aware Multiple Instance Learning for STAS Diagnosis in Multi-center Histopathology Images", "authors": "Liangrui Pan,xiaoyu Li,Guang Zhu,Guanting Li,Ruixin Wang,Jiadi Luo,Yaning Yang,Liang qingchun,Shaoliang Peng", "background": "STAS在肺癌腺癌(LUAD)中构成了一种新型的侵袭模式，与肿瘤复发和降低生存率相关。目前，大规模诊断STAS在临床上仍是一项劳动密集的工作，且由于其独特的病理学特征和形态学特征易出现忽视和误诊。因此，利用深度学习模型进行STAS诊断迫在眉睫。", "innovation": "提出了一个多模式注意力感知的多次实例学习框架（STAMP），该框架采用双重分支架构引导模型从不同的语义空间学习STAS相关的病理特征。基于Transformer的实例编码和多模式注意力聚合模块动态选择与STAS病理学密切相关的区域，抑制无关噪声并增强全局表示的区分能力。此外，相似性正则化约束防止分支间特征冗余，从而提高整体诊断准确性。", "conclusion": "实验结果表明，STAMP在STAS-SXY、STAS-TXY和STAS-TCGA数据集上实现了有竞争力的诊断结果，AUC分别为0.8058、0.8017和0.7928，超过了临床水平。"}
{"llm_update_time": "20250816", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.10469", "html_url": "https://arxiv.org/abs/2508.10469", "title": "增强稀疏点云数据处理以实现隐私感知的人体动作识别", "title_en": "Enhanced Sparse Point Cloud Data Processing for Privacy-aware Human Action Recognition", "authors": "Maimunatu Tunau,Vincent Gbouna Zakka,Zhuangzhuang Dai", "background": "人体动作识别（HAR）在医疗保健、健身追踪和辅助生活技术中起着关键作用。传统的基于视觉的HAR系统有效，但存在隐私问题。毫米波雷达传感器提供了一种保护隐私的替代方案，但由于其点云数据稀疏且噪音大，给数据分析带来了挑战。现有文献中，三种主要的数据处理方法（DBSCAN、匈牙利算法和卡尔曼滤波）被广泛用于提高雷达数据的质量和连贯性。然而，缺乏这些方法的综合评估。本文通过使用MiliPoint数据集来详细分析这些方法，评估它们的个体性能和组合性能，并进一步提出针对性的改进措施以提高准确性，为未来基于毫米波的HAR系统的开发提供了指导思想.", "innovation": "本文首次对DBSCAN、匈牙利算法和卡尔曼滤波三种方法进行全面的性能评估，包括个体和组合性能评价，并提出了针对性的改进措施。这些改进措施旨在提高准确性，为未来的毫米波HAR系统开发提供了宝贵的知识和指导.", "conclusion": "本文的研究结果提供了对每种方法及其整合方式的深入见解，阐明了它们的优点和权衡关系，这对未来基于毫米波的HAR系统的开发具有重要的指导意义."}
{"llm_update_time": "20250816", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.10507", "html_url": "https://arxiv.org/abs/2508.10507", "title": "多样本抗锯齿和约束优化在3D高斯点绘制中的应用", "title_en": "Multi-Sample Anti-Aliasing and Constrained Optimization for 3D Gaussian Splatting", "authors": "Zheng Zhou,Jia-Chen Zhang,Yu-Jie Xiong,Chun-Ming Xia", "background": "近年来，3D高斯点绘制在实时新颖视图合成中的表现得到了显著提高，但场景优化过程中几何约束不足往往会导致精细细节模糊重建，尤其是在高频纹理和锐利不连续性区域。", "innovation": "本文提出了一种结合多样本抗锯齿（MSAA）和双重几何约束的全面优化框架。通过动态梯度分析引入自适应权重策略，优先处理欠重建区域，并在对象边界处施加梯度差异约束以增强几何正则化。这种方法使得模型能够优先分配计算资源给需要细化的关键区域，同时保持全局一致性。", "conclusion": "跨多个基准的广泛实验评估表明，本文方法在细节保真度方面达到了最先进的性能，特别在保留高频纹理和锐利不连续性方面表现优异，同时保持了实时渲染效率。定量指标和感知研究证实与基线方法相比，在结构相似性（SSIM）和感知质量（LPIPS）方面有统计学显著改进。"}
{"llm_update_time": "20250816", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.10498", "html_url": "https://arxiv.org/abs/2508.10498", "title": "TweezeEdit：通过路径正则化实现一致且高效的图像编辑", "title_en": "TweezeEdit: Consistent and Efficient Image Editing with Path Regularization", "authors": "Jianda Mao,Kaibo Wang,Yang Xiang,Kani Chen", "background": "现有的大规模预训练扩散模型能够通过文字指令编辑图像，但是这些方法通常过度调整目标提示，未能充分保留源图像的语义信息。为了达到目标图像，现有方法会从源图像的反转噪声（称为反转锚点）中显式或隐式地生成目标图像。这一策略在语义保留方面效果不佳，且效率低，因为编辑路径较长。", "innovation": "TweezeEdit 提出了一种无需调优和反转的框架，通过路径正则化实现一致且高效的图像编辑。方法通过在整个去噪路径中进行正则化，而非仅依赖反转锚点，确保源语义保留并缩短编辑路径。通过梯度驱动的正则化，能够有效地沿直接路径注入目标提示语义，利用一致性模型进行优化。实验结果表明，TweezeEdit 在语义保留和目标对齐方面表现出色，优于现有方法，并且每次编辑只需12步（每步1.6秒），适用于实时应用。", "conclusion": "TweezeEdit 提出了一种新的方法，通过路径正则化实现了图像编辑的一致性和高效性，特别适用于实时应用，同时在语义保留和目标对齐上都表现出了显著的优势。"}
{"llm_update_time": "20250816", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.10509", "html_url": "https://arxiv.org/abs/2508.10509", "title": "基于分割驱动的螺栓缺陷增广和检测方法", "title_en": "A Segmentation-driven Editing Method for Bolt Defect Augmentation and Detection", "authors": "Yangjie Xiao,Ke Zhang,Jiacun Wang,Xin Sheng,Yurong Guo,Meijuan Chen,Zehua Ren,Zhaoye Zheng,Zhenbing Zhao", "background": "螺栓缺陷检测对于确保输电线路的安全至关重要，但缺陷图像稀缺以及数据分布不均衡严重影响了检测性能。为解决这一问题，本文提出了一种分割驱动的螺栓缺陷编辑方法（SBDE），通过增强复杂螺栓属性的分割和生成高质量掩码，来扩充数据集。研究在构建多个螺栓数据集并进行广泛实验后发现，SBDE生成的螺栓缺陷图像显著优于现有最先进的图像编辑模型，并有效提高了螺栓缺陷检测性能，完全验证了所提方法的有效性和应用潜力。", "innovation": "本文提出了一种分割驱动的螺栓缺陷编辑方法（SBDE），主要包括：（1）提出了一个增强复杂螺栓属性分割的螺栓属性分割模型（Bolt-SAM），通过CLAEH-FFT适配器（CFA）和多部分意识掩码解码器（MAMD），生成高质量的掩码；（2）设计了一种掩码优化模块（MOD）并与图像修复模型（LaMa）集成，构建螺栓缺陷属性编辑模型（MOD-LaMa），将正常螺栓转换为缺陷螺栓；（3）提出了编辑恢复扩充策略（ERA），将编辑缺陷的螺栓恢复回原始检测场景，从而扩充缺陷检测数据集。", "conclusion": "实验结果表明，SBDE生成的螺栓缺陷图像显著优于现有最先进的图像编辑模型，有效提升了螺栓缺陷检测性能，验证了提出方法的有效性和应用于缺陷检测领域的潜力。"}
{"llm_update_time": "20250816", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.10523", "html_url": "https://arxiv.org/abs/2508.10523", "title": "计算机视觉中的推理：分类、模型、任务与方法", "title_en": "Reasoning in Computer Vision: Taxonomy, Models, Tasks, and Methodologies", "authors": "Ayushman Sarkar,Mohd Yamani Idna Idris,Zhenyu Yu", "background": "视觉推理对于计算机视觉任务至关重要，远超过表面级别的物体检测和分类。尽管在关系推理、符号推理、时间推理、因果推理和常识推理方面取得了显著进展，但现有调查往往孤立地处理这些方向，缺乏对不同类型推理、方法和评估协议的统一分析和比较。本文旨在通过将视觉推理分类为五种主要类型（关系、符号、时间、因果和常识）并系统地研究它们通过图模型、记忆网络、注意机制和神经-符号系统等架构的实现，填补这一空白。", "innovation": "本文通过分类视觉推理为五种主要类型，并系统地研究它们通过各种架构（如图模型、记忆网络、注意力机制和神经-符号系统）的实现，填补了现有研究在统一分析和比较多类型推理、方法和评估协议方面的空白。此外，还对评估协议进行了审查，并批判性地分析了它们的局限性，提出了视觉推理的关键开放挑战，并展望了下一代视觉系统的前瞻性研究议程。", "conclusion": "视觉推理对于复杂场景具有可扩展性挑战，需要深化符号和神经范式的融合，缺乏完整的基准数据集，且在弱监督下推理方面存在问题。对于下一代视觉系统，应当重视将知觉与推理相结合，以构建透明可信的跨域适配AI系统，特别是在自动驾驶和医疗诊断等关键领域。"}
{"llm_update_time": "20250816", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.10549", "html_url": "https://arxiv.org/abs/2508.10549", "title": "PSScreen: Partially Supervised Multiple Retinal Disease Screening", "title_en": "PSScreen: Partially Supervised Multiple Retinal Disease Screening", "authors": "Boyi Zheng,Qing Liu", "background": "现有模型依赖于完全标注的数据集进行训练，但这些数据集在不同医学站点之间存在显著的领域偏差，并且存在部分类别的标签缺失问题，这使得模型在多个视网膜疾病筛查任务中表现不佳。PSScreen旨在解决这些挑战，以提高模型在多种视网膜疾病筛查中的检测性能和泛化能力。", "innovation": "PSScreen提出了一种新的部分监督的多视网膜疾病筛查模型，该模型包括两个流：一个学习确定性特征，另一个学习通过不确定性注入学习概率特征。此外，通过文本指导将两种特征解耦为疾病特异性特征，并通过特征蒸馏对齐这些特征，以增强领域泛化能力。该模型还利用两个流之间的伪标签一致性来解决标签缺失问题，并引入自我蒸馏以转移已知类别的任务相关语义，进一步提高检测性能。实验表明，PSScreen在六种视网膜疾病和正常状态的检测性能上均有所提升，并在有域和无域的测试数据集上达到了最先进的成果。", "conclusion": "实验结果表明，PSScreen显著提高了六种视网膜疾病的检测性能，并且在有域和无域数据集上均能达到最先进的技术水平。"}
{"llm_update_time": "20250816", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.10522", "html_url": "https://arxiv.org/abs/2508.10522", "title": "EgoMusic驱动的人类舞蹈动作估计与Skeleton Mamba", "title_en": "EgoMusic-driven Human Dance Motion Estimation with Skeleton Mamba", "authors": "Quang Nguyen,Nhat Le,Baoru Huang,Minh Nhat Vu,Chengcheng Tang,Van Nguyen,Ngan Le,Thieu Vo,Anh Nguyen", "background": "估计人类舞蹈动作是一个具有多种工业应用的具有挑战性的任务。最近，许多研究致力于通过仅依据第一人称视角视频或音乐来预测人类舞蹈动作。然而，同时从第一人称视角视频和音乐中联合估计人体运动的研究仍相对较少。本文旨在开发一种新方法，用于从第一人称视角视频和音乐中预测人类舞蹈动作。实际操作中，第一人称视角经常遮挡大部分身体，使得精确的全姿态估计变得困难。此外，加入音乐因素需要生成的头部和身体运动与视觉和音乐输入良好地对齐。为此，作者创建了一个名为EgoAIST++的新大数据集，该数据集结合了第一人称视角和音乐信息，拥有超过36小时的舞蹈动作数据。该数据集有助于解决实际操作中的困难。", "innovation": "文章提出了一种新的方法，用于从第一人称视角视频和音乐中预测人类舞蹈动作。这种方法基于扩散模型和Mamba模型，采用了一个名为Skeleton Mamba的核心模块，该模块可以明确捕捉人体骨骼结构。这种方法在实证实验中表现出了与最先进的方法相比的优越性和对真实数据的良好泛化能力。", "conclusion": "实验结果显示，本文提出的方法在预测人类舞蹈动作方面明显优于现有的方法，并且能够有效迁移到真实数据上。同时，通过创建EgoAIST++数据集，为该领域提供了丰富的第一人称视角和音乐结合的数据资源。这种方法将在未来的舞蹈动作估计和其他相关应用中展现出巨大的潜力。"}
{"llm_update_time": "20250816", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.10554", "html_url": "https://arxiv.org/abs/2508.10554", "title": "使用表面跟踪的AR手术导航：神经外科应用中静态现场可视化与工具跟踪指导的比较", "title_en": "AR Surgical Navigation With Surface Tracing: Comparing In-SitVisualization with Tool-Tracking Guidance for Neurosurgical Applications", "authors": "Marc J. Fischer,Jeffrey Potts,Gabriel Urreola,Dax Jones,Paolo Palmisciano,E. Bradley Strong,Branden Cord,Andrew D. Hernandez,Julia D. Sharma,E. Brandon Strong", "background": "随着增强现实（AR）手术导航系统的兴起，它们被看作是新一代的手术指导技术，有望克服传统导航系统的限制。然而，由于调节-聚散冲突（vergence-accommodation conflict）和当前商业可用显示技术中遮挡处理的限制，AR在外科手术中的深度感知问题提出了严峻挑战，特别是在需要高度精确的手术环境中。", "innovation": "本研究提出了一种新颖的方法，利用AR指导在仿真模型上放置模拟的外侧室引流管，以验证AR在神经外科手术中的应用。该系统通过一种新颖的表面跟踪方法确定目标位置，并结合实时红外工具跟踪辅助引流管放置，仅依赖Microsoft HoloLens 2的内置传感器。实验通过对照组比较了静态现场可视化和实时工具跟踪指导两种不同AR指导条件下的手术性能。", "conclusion": "工具跟踪指导提高了所有准确性的测量指标，并在用户主观评价中得到了用户的青睐。通过CT扫描获取的假体模型图像，允许评估插入精度、目标偏差、角度误差和深度精度。系统易用性量表调查评估了用户体验和认知负荷。结果显示，工具跟踪指导在准确性方面表现更好，并且得到用户的好评。"}
{"llm_update_time": "20250816", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.10542", "html_url": "https://arxiv.org/abs/2508.10542", "title": "GCRPNet：光学遥感图像显著目标检测中的图增强上下文和区域感知网络", "title_en": "GCRPNet: Graph-Enhanced Contextual and Regional Perception Network For Salient Object Detection in Optical Remote Sensing Images", "authors": "Mengyu Ren,Yutong Li,Hua Li,Runmin Cong,Sam Kwong", "background": "光学遥感图像中的显著目标检测（SOD）面临诸多挑战，包括目标尺度差异大和目标与背景对比度低。现有的基于视觉变换器（ViTs）和卷积神经网络（CNNs）结构的方法旨在同时利用全局和局部特征，但如何有效地整合这些不一致的特征限制了它们的整体性能。", "innovation": "我们提出了一种基于Mamba架构的图增强上下文和区域感知网络（GCRPNet），旨在同时捕捉长距离依赖性并增强区域特征表示。具体来说，我们采用视觉状态空间（VSS）编码器提取多尺度特征，并通过差相似性引导层次图注意力模块（DS-HGAM）增强了这些特征的导向和增强能力，同时增强了模型的结构感知能力。进一步地，我们设计了LEVSS块作为GCRPNet的解码器，该模块结合了我们提出的自适应扫描策略和多粒度协作注意增强模块（MCAEM），在多尺度卷积处理后的特征图上进行了自适应区域扫描，从而捕获丰富的局部区域信息并增强了Mamba的局部建模能力。", "conclusion": "大量的实验结果表明，所提出的模型在显著目标检测方面取得了最先进的性能，验证了其有效性和优越性。"}
{"llm_update_time": "20250816", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.10556", "html_url": "https://arxiv.org/abs/2508.10556", "title": "Retrieval-Augmented Prompt for OOD Detection", "title_en": "Retrieval-Augmented Prompt for OOD Detection", "authors": "Ruisong Han,Zongbo Han,Jiahao Zhang,Mingyue Cheng,Changqing Zhang", "background": "无分布外（Out-of-Distribution，OOD）检测对于在现实环境中可靠部署机器学习模型至关重要，它能够准确识别测试样本与训练数据分布不同的情况。现有方法依赖于辅助的离群样本或分布内（In-distribution，ID）数据生成离群信息进行训练，但由于离群样本数量有限且与实际测试中的OOD样本不匹配，这些方法往往无法提供充分的语义监督，导致性能不佳。", "innovation": "我们提出了一种名为Retrieval-Augmented Prompt（RAP）的新颖OOD检测方法。RAP通过检索外部知识来增强预先训练的视觉-语言模型的提示，提供增强的语义监督。在训练过程中，RAP基于外部文本知识与异常样本的联合相似性检索描述性词汇，用于增强模型的OOD提示。在测试过程中，RAP会根据遇到的OOD样本动态更新OOD提示，使模型能够快速适应测试环境。我们的大量实验证明，RAP在大规模OOD检测基准上达到了最先进的性能。", "conclusion": "我们的广泛实验表明，RAP展示了比先前方法在大尺度OOD检测基准上更为出色的性能。例如，在ImageNet-1k数据集的1-shotOOD检测任务中，RAP将平均FPR95降低了7.05%，AUC-ROC提高了1.71%。此外，综合的消融研究进一步验证了每个模块的有效性及其方法背后的动机。"}
{"llm_update_time": "20250816", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.10566", "html_url": "https://arxiv.org/abs/2508.10566", "title": "HM-Talker: 混合动力学建模用于高保真头部对话合成", "title_en": "HM-Talker: Hybrid Motion Modeling for High-Fidelity Talking Head Synthesis", "authors": "Shiyu Liu,Kui Jiang,Xianming Liu,Hongxun Yao,Xiaocheng Feng", "background": "当前方法在解决音频驱动的头部对话视频生成过程中，尤其是在减少运动模糊和口型抖动方面表现不佳。这主要是因为这些方法依赖于隐式的口音-表意符间的关系建模，而缺乏显式的发音先验（即与言语相关的面部运动解剖指导）。", "innovation": "本文提出了HM-Talker框架，这是一种生成高保真、时序一致的头部对话视频的新方法。HM-Talker采用结合隐式和显式运动线索的混合运动表示法，其中显式线索包括与解剖定义的面部肌肉运动相关的动作单元(AUs)，以减少音素-表意符失准。此外，引入了交叉模态分离模块(CMDM)来提取互补的隐式/显式运动特征，并直接从音频输入预测AUs。还提出了混合动力学建模模块(HMMM)，该模块动态合并随机配对的隐式/显式特征，促进身份无关的学习。", "conclusion": "通过HM-Talker，本文实现了跨不同身份的鲁棒口型同步，提升了个性化头部对话合成。在大量实验中，HM-Talker在视觉质量和口型同步准确性方面优于最先进的方法。"}
{"llm_update_time": "20250816", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.10568", "html_url": "https://arxiv.org/abs/2508.10568", "title": "通过交叉熵掩码适应SAM以解决遥感变化检测中的类别不平衡问题", "title_en": "Adapting SAM via Cross-Entropy Masking for Class Imbalance in Remote Sensing Change Detection", "authors": "Humza Naveed,Xina Zeng,Mitch Bryson,Nagita Mehrseresht", "background": "范式模型在计算机视觉的多种领域内取得了显著的成功。它们学习到一般化的表示，这些表示很容易被转移到训练期间未见的任务中。Segment Anything Model (SAM) 就是一种范式模型，它可以精确地分割图像中的对象。本文提出了一种方法，通过微调SAM编码器，并结合空间-时间特征增强（STFE）和多尺度解码器融合（MSDF）来增强SAM以用于遥感变化检测（RSCD）。此外，提出了一个新的交叉熵掩码（CEM）损失函数，用于处理变化检测数据集中类别的高度不平衡。", "innovation": "提出了结合空间-时间特征增强（STFE）和多尺度解码器融合（MSDF）的微调Segment Anything Model (SAM) 方法，以及一种新的交叉熵掩码（CEM）损失函数，以解决类别不平衡问题，并在多个数据集上超越了最先进方法。", "conclusion": "提出的微调方法在四个变化检测数据集（Levir-CD, WHU-CD, CLCD, S2Looking）上表现出更优的效果，特别是在大型复杂数据集S2Looking上取得了2.5%的F1分数改进。源代码将在此提供。"}
{"llm_update_time": "20250816", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.10576", "html_url": "https://arxiv.org/abs/2508.10576", "title": "HumanSense: 从多模态感知到具有推理能力的同理心上下文响应", "title_en": "HumanSense: From Multimodal Perception to Empathetic Context-Aware Responses through Reasoning MLLMs", "authors": "Zheng Qin,Ruobing Zheng,Yabing Wang,Tianqi Li,Yi Yuan,Jingdong Chen,Le Wang", "background": "目前，多模态大型语言模型（MLLMs）在实现真正的人类互动方面显示出巨大的潜力。然而，由于缺乏针对人类中心场景的精细评估框架，这些模型在理解和回应复杂的人类意图方面仍然缺乏真正做到细致入微的能力，尤其是在提供同理心和上下文感知的回复方面。因此，需要一个全面的基准来评估MLLMs在人类中心感知和交互方面的能力，特别是在理解和回应扩展的多模态上下文方面。", "innovation": "该论文提出了名为HumanSense的基准测试，特别注重评估MLLMs对扩展的多模态上下文的理解能力以及提供合理反馈的能力。通过补充视觉输入的音频和文本信息，研究发现能够显著提高绩效，并且全模态模型在这些任务上表现出优势。此外，研究还通过多阶段、模态渐进式强化学习提升了推理能力，并采用了相应提示增强了无推理模型的性能。", "conclusion": "研究结果表明，现有的MLLMs仍需改进，特别是在高级互动任务方面。合适的反馈来源于对对话者需求和情感的上下文分析，而推理能力是解锁这一过程的关键。通过这种方法，研究取得了显著的评估结果改善。"}
{"llm_update_time": "20250816", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.10572", "html_url": "https://arxiv.org/abs/2508.10572", "title": "向导型AI在多模态视频对象分割中的研究", "title_en": "Towards Agentic AI for Multimodal-Guided Video Object Segmentation", "authors": "Tuyen Tran,Thao Minh Le,Truyen Tran", "background": "多模态视频对象分割是一个多模态问题，需要通过外部线索生成精细的分割结果。传统方法通常涉及训练专门模型，这带来了高计算复杂度和手动注释的努力。近年来，视觉-语言基础模型的发展为训练无模型方法带来了前景，虽然这些方法在细粒度分割上达到了性能，但现有方法依赖固定的处理流程，缺乏适应动态任务需求的灵活性。", "innovation": "本文提出了一种名为Multi-Modal Agent的新颖代理系统，通过利用大型语言模型（LLMs）的推理能力生成针对每个输入的动态工作流程。该适应性过程迭代地与其他用于不同模态低级任务的专业工具交互，以识别由多模态线索描述的目标对象。实验结果表明，该代理方法在两种基于多模态条件的视频对象分割任务（RVOS和Ref-AVS）上优于之前的方案，显示了明确的优势。", "conclusion": "本文提出的方法展示了在多模态指导下的视频对象分割中使用代理系统的有效性，该系统通过适应性工作流程能够更灵活和适应地解决任务。"}
{"llm_update_time": "20250816", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.10567", "html_url": "https://arxiv.org/abs/2508.10567", "title": "SpaRC-AD: 用于端到端自动驾驶的雷达-相机融合基线", "title_en": "SpaRC-AD: A Baseline for Radar-Camera Fusion in End-to-End Autonomous Driving", "authors": "Philipp Wolters,Johannes Gilg,Torben Teepe,Gerhard Rigoll", "background": "端到端自动驾驶系统通过统一优化感知、运动预测和规划，实现了更强的性能。然而，基于视觉的方法在恶劣天气条件、部分遮挡和精确速度估计方面存在根本性限制，这对安全敏感场景中的运动理解与长轨迹预测提出了挑战。为了应对这些限制，提出了一种基于查询的端到端雷达-摄像头融合框架——SpaRC-AD，用于规划导向的自动驾驶。该方法通过稀疏3D特征对齐和多普勒速度估计，实现了良好的3D场景表示，用于改进代理锚点、地图多边形线和运动建模。", "innovation": "引入了一种基于查询的端到端雷达-摄像头融合框架SpaRC-AD，通过稀疏3D特征对齐和多普勒速度估计，实现了对代理锚点、地图多边形线和运动建模的优化。该方法在多个自动驾驶任务上优于最先进的视觉基线，包括3D检测、多对象跟踪、在线制图、运动预测和轨迹规划。", "conclusion": "SpaRC-AD方法在多个具有挑战性的基准上实现了空间连贯性和时间一致性，在nuScenes、长视野T-nuScenes和闭合环模拟器Bench2Drive等实际应用场景中验证了其在安全关键场景中的有效性。所有实验的源代码可在指定链接获取。”，该方法展示了基于雷达的融合在需要准确运动理解和长轨迹预测的碰撞避免关键场景中的有效性。"}
{"llm_update_time": "20250816", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.10582", "html_url": "https://arxiv.org/abs/2508.10582", "title": "EvTurb: 事件摄像头引导的湍流去除", "title_en": "EvTurb: Event Camera Guided Turbulence Removal", "authors": "Yixing Liu,Minggui Teng,Yifei Xia,Peiqi Duan,Boxin Shi", "background": "大气湍流会引入模糊和几何偏斜失真，显著影响计算机视觉任务的图像质量。现有的单帧和多帧方法难以应对高病态问题，因为湍流引起的失真构成了复杂的组合结构。", "innovation": "提出了一种事件引导的湍流去除框架EvTurb，通过利用高速事件流来解开模糊和偏斜效应。EvTurb采用一种新颖的两步事件引导网络，首先通过事件积分减少粗略输出中的模糊，然后利用来自原始事件流的方差图消除细化输出中的偏斜失真。此外，还介绍了TurbEvent，这是首个包含多样湍流场景的真实捕捉数据集。", "conclusion": "实验结果表明，EvTurb 在保持计算效率的同时超过了最先进的方法。"}
{"llm_update_time": "20250816", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.10450", "html_url": "https://arxiv.org/abs/2508.10450", "title": "从图像到感知：通过重建图像产生的感知属性", "title_en": "From Images to Perception: Emergence of Perceptual Properties by Reconstructing Images", "authors": "Pablo Hernández-Cámara,Jesus Malo,Valero Laparra", "background": "许多科学家认为人类视觉感知可能源自图像统计规律，这些统计规律有效塑造了早期视觉中的神经表示。基于这一假设，本研究提出了一种生物启发式的架构PerceptNet，它用于优化与图像重建相关的不同任务：自编码、降噪、去模糊和稀疏正则化。这些任务以端到端的方式进行优化，旨在探索基于统计规律的感知机制。", "innovation": "研究介绍了一种新的PerceptNet架构，该架构在重建图像的任务上进行了端到端优化，特别适用于图像重建相关任务。研究发现，PerceptNet的编码阶段(V1类似层)在图像失真判断中与人类感知评价表现出最高的相关性，即使在没有使用感知信息进行初始化或训练的情况下。这一结果表明，视觉系统可能被调整来去除特定程度的图像失真，并且生物启发式的模型可以在没有人类监督的情况下学习感知度量。这种模型的创新之处在于它能够通过从图像信息生成感知属性，而不依赖于直接的感知信息。这种架构的有效性和鲁棒性为理解视觉感知提供了一种新的方法。", "conclusion": "研究结果表明，视觉系统可能倾向于去除特定级别的图像失真和特定级别的稀疏性。因此，生物启发式的模型能够学习感知度量而不依赖于人类的监督。这对于理解视觉感知的统计基础具有重要意义，并且为视觉计算和机器视觉领域提供了新的启示。"}
{"llm_update_time": "20250816", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.10600", "html_url": "https://arxiv.org/abs/2508.10600", "title": "针对自主驾驶2D物体检测的强实用性遮蔽攻击", "title_en": "Towards Powerful and Practical Patch Attacks for 2D Object Detection in Autonomous Driving", "authors": "Yuxin Cao,Yedi Zhang,Wentao He,Yifan Liao,Yan Xiao,Chang Li,Zhiyong Huang,Jin Song Dong", "background": "基于学习的自主驾驶系统仍对对抗补丁极其脆弱，这在其实用部署中带来了严重的安全和安全风险。特别是，黑色盒攻击由于高攻击成功率且无需知道模型信息而尤为令人担忧，其在减少计算成本方面已对基于查询攻击进行了广泛研究来提高其可移植性。然而，之前基于可移植性的黑色盒攻击通常采用平均精确度（mAP）作为评估指标，并因此往往高估了攻击效果，导致其在实际攻击场景中的成功率较低。此外，训练于低分辨率数据的补丁在高分辨率图像上往往失效，这限制了其对自主驾驶数据集的可移植性。", "innovation": "本文提出了P$^3$A，一种针对2D物体检测优化的高分辨率数据集的有效且实用的补丁攻击框架。该框架包含：1) 引入一种新的实用攻击成功率（PASR）度量，更准确地衡量攻击对行人安全的实际影响；2) 提出专门的定位-置信度抑制损失（LCSL），以在PASR环境下提高攻击的可移植性；3) 通过引入概率尺度保持填充（PSPP）作为数据预处理步骤，确保其在高分辨率数据集上保持可移植性。", "conclusion": "大量实验表明，P$^3$A在未见过的模型和高分辨率数据集上均优于最先进的攻击方法，无论是在本提案提出的实用IoU评估指标还是以前的mAP指标下均表现更优。"}
{"llm_update_time": "20250816", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.10616", "html_url": "https://arxiv.org/abs/2508.10616", "title": "Fourier-Guided Attention Upsampling for Image Super-Resolution", "title_en": "Fourier-Guided Attention Upsampling for Image Super-Resolution", "authors": "Daejune Choi,Youchan No,Jinhyung Lee,Duksu Kim", "background": "传统的上采样方法，如子像素卷积，在效率方面表现出色，但经常无法重建高频率细节并引入伪影。", "innovation": "提出了一种名为Frequency-Guided Attention (FGA)的轻量级上采样模块，该模块通过 (1) 基于傅里叶特征的多层感知机 (MLP) 进行位置频率编码，(2) 交叉分辨率相关注意层进行自适应空间对齐，以及 (3) 频域L1损失进行光谱一致性监督来解决这些问题。FGA 模块在五个不同的超分辨率骨干网络中，无论是轻量级还是全容量场景，都提高了0.3M参数下的性能。", "conclusion": "实验结果表明，FGA 在平均 PSNR 增益方面提高了0.12~0.14 dB，频域一致性提高了最高29%，尤其是在纹理丰富的数据集上表现尤为明显。视觉和光谱评估证实了FGA在减少伪影和保留细芽数方面有效性，使其成为传统上采样方法的一种实用且可扩展的替代品。"}
{"llm_update_time": "20250816", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.10637", "html_url": "https://arxiv.org/abs/2508.10637", "title": "视觉编码器中的处理与获取痕迹：CLIP 知道你的相机吗？", "title_en": "Processing and acquisition traces in visual encoders: What does CLIP know about your camera?", "authors": "Ryan Ramos,Vladan Stojnić,Giorgos Kordopatis-Zilos,Yuta Nakashima,Giorgos Tolias,Noa Garcia", "background": "先前的研究分析了视觉编码器对图像变换和损坏的鲁棒性，特别是在训练过程中未遇到这些变换和损坏的情况下。这些变化会导致在测试时引入分布偏移，通常会导致性能下降。研究主要集中在那些严重损坏，当以积极方式应用于图像时，会导致有用信号的严重扭曲，从而导致准确的语义预测受到损害。", "innovation": "本文从不同的角度出发，分析了图像获取过程中的参数和可能微妙到人眼无法察觉的变换。研究发现，这些参数以系统的方式被编码在学习到的视觉表示中，并可以轻松恢复。更重要的是，其存在会对语义预测产生深远的影响，这种影响取决于语义标签与基于获取或加工的标签之间是否存在强相关性或反相关性。", "conclusion": "发现这些参数的存在可以对语义预测产生积极或消极的影响，这种效应依赖于语义标签与获取或处理标签之间的相关性或反相关性。研究的代码和数据可以在指定的网页上找到。"}
{"llm_update_time": "20250816", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.10631", "html_url": "https://arxiv.org/abs/2508.10631", "title": "通过Chamfer引导提高合成图像的实用性", "title_en": "Increasing the Utility of Synthetic Images through Chamfer Guidance", "authors": "Nicola Dall'Asen,Xiaofeng Zhang,Reyhane Askari Hemmat,Melissa Hall,Jakob Verbeek,Adriana Romero-Soriano,Michal Drozdzal", "background": "生成模型在合成无限量的训练数据方面前景广阔，但最近的生成质量提升往往牺牲了生成多样性，限制了这些模型作为合成训练数据来源的效用。尽管引入了基于指导的方法来提高生成数据的质量或多样性，但其隐含或显式的效用函数经常忽略了合成数据与真实数据之间的分布偏移。", "innovation": "本文提出了Chamfer指导：一种无需训练的指导方法，利用少量真实示例图像来表征合成数据的质量和多样性。通过这种方式，可以增加生成相对于真实图像数据集的多样性，同时在ImageNet-1k和标准地理多样性基准上保持或提高生成质量。我们的方法在使用2张真实图像示例时，可以达到96.4%的精度和86.4%的分布覆盖度，而使用32张真实图像时，这些值分别增加到97.5%和92.7%。此外，这种方法不需要使用无条件模型，从而在采样时减少了31%的FLOPs。", "conclusion": "我们的研究显示，通过Chamfer指导生成的下游图像分类器可以获得显著的性能提升，对于分布内可以提高15%的准确性，对于分布外可以提高16%的准确性。同时，我们的方法不依赖于无条件模型，因此在采样时相对于基于无条件指导的方法减少了31%的FLOPs。"}
{"llm_update_time": "20250816", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.10643", "html_url": "https://arxiv.org/abs/2508.10643", "title": "使用姿态估计和双向LSTMs在乳牛中检测瘸腿", "title_en": "Lameness detection in dairy cows using pose estimation and bidirectional LSTMs", "authors": "Helena Russello,Rik van der Tol,Eldert J. van Henten,Gert Kootstra", "background": "本研究提出了一种结合姿态估计和双向长短时记忆（BLSTM）神经网络的瘸腿检测方法。通过结合姿态估计和BLSTM分类器，这种方法具有以下优势：无需标记点的姿态估计、通过学习关键点轨迹的时间运动特征来消除手动特征工程、能够处理较短的运动序列和较小的训练数据集。", "innovation": "该方法通过从行走的牛的视频中提取位于蹄子、头部和背部的九个关键点的运动序列，并将关键点的轨迹作为输入送入BLSTM分类器进行训练，实现了二元瘸腿分类。与依赖手动设计的运动特征的方法相比，该方法表现更佳，其最佳架构的分类准确率达到85%，而基于特征的方法为80%。另外，研究还证明了BLSTM分类器能够使用不到一秒的视频数据检测到瘸腿。", "conclusion": "本研究提出的方法显著提高了乳牛瘸腿检测的准确性，并展示了在短时间内高效检测瘸腿的可能性。"}
{"llm_update_time": "20250816", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.10635", "html_url": "https://arxiv.org/abs/2508.10635", "title": "ChatENV：一种用于传感器引导的环境监测和情景模拟的交互式视觉语言模型", "title_en": "ChatENV: An Interactive Vision-Language Model for Sensor-Guided Environmental Monitoring and Scenario Simulation", "authors": "Hosam Elgendy,Ahmed Sharshar,Ahmed Aboeitta,Mohsen Guizani", "background": "理解来自航空摄影的环境变化对于气候适应性、城市规划和生态系统监测至关重要。然而，当前的视觉语言模型忽略了环境传感器的因果信号，依赖于单源且可能带有风格偏见的标题描述，并且缺乏基于场景的互动推理能力。", "innovation": "本文介绍了ChatENV，这是一个交互式的视觉语言模型，能够联合处理卫星图像对和现实世界传感器数据。该框架（i）创建了一个包含62类土地利用的177k张图像的数据集，这些图像跨越197个国家，并形成152k个时间对，且包含丰富的传感器元数据（如温度、PM10、CO）；（ii）使用GPT-4o和Gemini 2.0进行标注，以实现风格和语义多样性；（iii）使用高效的低秩适应（LoRA）适配器 fine-tune Qwen-2.5-VL，以支持聊天功能。ChatENV在时间推理和“what-if”推理中表现出色，并且能够与最新的时间模型竞争或超越它们，同时支持互动的场景分析。", "conclusion": "ChatENV 作为一种传感敏感型环境监测工具，具备地基和传感器感知型环境监测的能力，展示了强大的性能和优势。"}
{"llm_update_time": "20250816", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.10617", "html_url": "https://arxiv.org/abs/2508.10617", "title": "FIND-Net -- Fourier-Integrated Network with Dictionary Kernels for Metal Artifact Reduction", "title_en": "FIND-Net -- Fourier-Integrated Network with Dictionary Kernels for Metal Artifact Reduction", "authors": "Farid Tasharofi,Fuxin Fan,Melika Qahqaie,Mareike Thies,Andreas Maier", "background": "CT成像中由于高密度金属植入物引起的金属伪影严重降低了图像质量，使得诊断和治疗规划复杂化。现有的深度学习算法在金属伪影减少（MAR）方面取得了显著成效，但在抑制伪影和保留结构细节方面仍存在问题。", "innovation": "FIND-Net（Fourier-集成网络和字典核）是一种新颖的MAR框架，通过将频率域和空域处理结合，实现更优秀的伪影抑制和结构保留。该网络结合了快速傅里叶卷积（FFC）层和可训练的高斯滤波器，将MAR视为在两个域中执行的混合任务，增强全局上下文理解并提高频率选择性，从而有效地减少伪影同时保持解剖结构。", "conclusion": "FIND-Net在合成数据集上的实验结果显示，在最先进的MAR方法上取得了统计学上的显著改进，包括3.07%的MAE减少，0.18%的SSIM提高和0.90%的PSNR提高，证实了其在不同复杂性伪影下的稳健性。此外，在真实临床CT扫描上的评估证实了FIND-Net能够最小化干净解剖区域的修改，同时有效抑制金属引起的畸变。这些发现突显了FIND-Net在增强MAR性能方面的潜力，提供更好的结构保留和改进的临床应用性。"}
{"llm_update_time": "20250816", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.10667", "html_url": "https://arxiv.org/abs/2508.10667", "title": "AddressVLM：使用大型视觉语言模型的跨视角对齐调优以进行图像地址定位", "title_en": "AddressVLM: Cross-view Alignment Tuning for Image Address Localization using Large Vision-Language Models", "authors": "Shixiong Xu,Chenghao Zhang,Lubin Fan,Yuan Zhou,Bin Fan,Shiming Xiang,Gaofeng Meng,Jieping Ye", "background": "大型视觉语言模型（LVLMs）在国家或城市级别的粗粒度地理定位任务中表现出色，但在城市区域内的街道级别定位方面表现较差。现有的街景视觉问答（VQA）数据集仅提供微小的视觉线索，导致微调后的模型在细粒度地址定位方面表现不佳。", "innovation": "该研究创新性地将城市范围内的地址定位能力和基于街景图像的地址相关问题回答集成到大型视觉语言模型中。为此，作者引入了卫星视图不变的宏观线索，并提出了跨视角对齐调优方法（包括街景视图和卫星视图图像嫁接机制）以及自动标签生成机制，以增强模型对街道分布的全局理解。此外，该研究构建了基于匹兹堡和旧金山的图像地址定位数据集，用以评估模型性能。", "conclusion": "通过跨视角对齐调优，AddressVLM 模型在两个数据集上的平均地址定位准确性分别比传统LVLM提高了9%和12%。"}
{"llm_update_time": "20250816", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.10645", "html_url": "https://arxiv.org/abs/2508.10645", "title": "SemPT: 语义提示调谐在视觉-语言模型中的应用", "title_en": "SemPT: Semantic Prompt Tuning for Vision-Language Models", "authors": "Xiao Shi,Yangjun Ou,Zhenzhong Chen", "background": "视觉-语言模型（VLMs）预训练于大量图像-文本对，为处理未见类别的视觉迁移学习提供了一种潜在解决方案。然而，现有的提示调谐方法依赖于稀疏类别标签或不一致的语言模型生成的描述，这会阻碍知识表示的统一性和迁移能力。因此，研究如何有效弥合类别间迁移学习的知识表示差距，实现跨领域知识的有效迁移成为一个挑战性的任务。现有的方法侧重于标签级别的信息，而忽略了类别间共享的语义属性，这限制了从已见类别到未见类别的迁移能力。", "innovation": "该研究提出了语义提示调谐（SemPT），这是一种新的框架，通过利用类别间的共享属性知识，有效解决了视觉迁移学习中的泛化挑战。SemPT 采用两步提示策略，引导语言模型提取共享的视觉属性并生成语义级别的描述，这些描述包含了跨类别标签的可迁移语义线索，同时保持结构一致性。此外，利用视觉引导加权对属性级别的描述嵌入进行处理，从而降低无关属性的噪声，并增强文本嵌入。进一步地，图像嵌入仅与标签和属性增强的文本嵌入对齐，平衡了已见类别的区分性和未见类别的迁移性。鉴于不同类别的暴露情况，推理过程会动态选择标准标签嵌入或属性增强嵌入，以确保有效的适应性。实验结果表明SemPT 在多个基准数据集上取得了最佳性能，包括基础到新类别泛化、跨数据集迁移、跨领域迁移和少数样本学习等方面的表现。", "conclusion": "本文提出的方法 SemPT 在多种应用场景下实现了最佳性能，表明通过挖掘类别间的共享语义属性，可以有效提升视觉-语言模型的未见类别迁移学习能力。"}
{"llm_update_time": "20250816", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.10655", "html_url": "https://arxiv.org/abs/2508.10655", "title": "Serial Over Parallel: Learning Continual Unification for Multi-Modal Visual Object Tracking and Benchmarking", "title_en": "Serial Over Parallel: Learning Continual Unification for Multi-Modal Visual Object Tracking and Benchmarking", "authors": "Zhangyong Tang,Tianyang Xu,Xuefeng Zhu,Chunyang Cheng,Tao Zhou,Xiaojun Wu,Josef Kittler", "background": "由于不同模态在构建鲁棒跟踪系统时具有互补性，因此统一多种多模态视觉对象跟踪（MMVOT）任务越来越受到关注。目前的做法是将所有传感器类型的数据混合并在单个训练过程中处理，从数据为中心的角度构建并行范式，旨在联合分布上的全局最优。然而，缺乏包含所有类型数据的统一基准，导致评估在分离的基准上进行，从而产生训练与测试之间的一致性问题，进而导致性能下降。因此，本文在此背景下提出了解决这些问题的方法。", "innovation": "本文提出了两个方面的创新：首先，引入了名为UniBench300的统一基准，通过整合多种任务数据，将推理步骤从三个缩减为一个，减少了27%的时间消耗。其次，统一过程被重新制定为按序格式，逐步整合新的任务。这种方式将性能下降视为先前任务的知识遗忘，这自然而然地与持续学习（CL）的哲学一致，激发进一步将CL注入统一过程的研究。大量的实验表明UniBench300的重要性以及CL在支持稳定统一过程中的优越性。此外，研究还发现性能下降与网络容量呈负相关，不同模态差异导致不同任务的性能下降程度不同，这为未来多模态视觉研究提供了有价值的见解。", "conclusion": "这项工作的主要结论是，通过引入UniBench300和持续学习（CL），可以有效解决多模态视觉对象跟踪中的一致性问题，并且能够实现更稳定的统一过程。此外，研究还提供了一些有价值的见解，例如性能下降与网络容量之间的关系以及不同模态差异对不同任务性能的影响。源代码和提议的基准可以在提供的网址获取。"}
{"llm_update_time": "20250816", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.10688", "html_url": "https://arxiv.org/abs/2508.10688", "title": "使用DDIM反演实现新颖视角合成", "title_en": "Novel View Synthesis using DDIM Inversion", "authors": "Sehajdeep SIngh,A V Subramanyam", "background": "从单幅输入图像合成新颖视角是一个具有挑战性的任务。现有的方法往往需要通过多个视图进行调优或从头训练扩散模型，这非常昂贵且产生了模糊的重建结果和较差的泛化能力。", "innovation": "提出了一种轻量级的视角翻译框架，该框架可以直接利用预训练扩散模型的高保真生成能力，在新颖视图下重建场景。通过DDIM反演单个输入图像的隐变量，利用相机姿态条件下的翻译U-Net（TUNet）预测目标视图对应的反演隐变量，并引入一种新颖的融合策略，以保留纹理和细粒度细节。最终通过融合后的隐变量作为DDIM采样的初始条件，利用预训练扩散模型的生成先验生成新颖视角。", "conclusion": "在MVImgNet上的实验表明，该方法在新颖视角合成方面优于现有方法。"}
{"llm_update_time": "20250816", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.10681", "html_url": "https://arxiv.org/abs/2508.10681", "title": "IADGPT：基于上下文学习的统一大视觉-语言模型在少量样本工业异常检测、定位和推理中的应用", "title_en": "IADGPT: Unified LVLM for Few-Shot Industrial Anomaly Detection, Localization, and Reasoning via In-Context Learning", "authors": "Mengyang Zhao,Teng Fu,Haiyang Yu,Ke Niu,Bin Li", "background": "工业质量检测中，少量样本工业异常检测（FS-IAD）具有重要应用。现有基于大视觉-语言模型（LVLM）的FS-IAD方法通过提示学习或微调实现了部分成果，但这些方法现有的LVLM主要针对一般任务，缺乏与FS-IAD相关的基础工业知识和推理能力，使其难以达到人类质量检查员的专业水平。", "innovation": "本文提出了一个统一框架IADGPT，旨在以类似人类的方式执行FS-IAD，同时处理相关的定位和推理任务，甚至适用于各种新型工业产品。IADGPT采用基于人类启发的三阶段渐进式训练策略，逐步引导模型获取基本工业知识和差异性意识，第三阶段使用基于上下文学习的训练范式，通过少量样本图片作为示例，提高模型对新型产品的泛化能力。此外，IADGPT能够结合语言输出输出图像级和像素级异常评分，完成异常推理。", "conclusion": "实验表明，IADGPT在异常检测方面取得了显著的性能提升，并展示了在异常定位和推理方面具有竞争力。本文还将发布包含400个不同工业产品类别，共计10万张图像的新数据集，附有详尽的属性级文本标注。"}
{"llm_update_time": "20250816", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.10678", "html_url": "https://arxiv.org/abs/2508.10678", "title": "HyperTea: 基于超图的时空增强与对齐网络用于移动红外小目标检测", "title_en": "HyperTea: A Hypergraph-based Temporal Enhancement and Alignment Network for Moving Infrared Small Target Detection", "authors": "Zhaoyuan Qi,Weihua Gao,Wenlong Niu,Jie Tang,Yun Li,Xiaodong Peng", "background": "在实际应用场景中，移动红外小目标检测（MIRSTD）仍然具有高度挑战性，由于目标尺寸小、强度弱以及复杂的运动模式。现有方法通常只会建模特征节点之间的低阶关联，并在单一时间尺度下进行特征提取和增强。尽管超图已被广泛用于高阶关联学习，但在MIRSTD中的应用却很少受到关注。", "innovation": "我们提出了一种名为HyperTea的技术，它结合全局和局部时间视角来有效建模特征的高阶时空关联，并进一步开发了时间对齐模块（TAM）来解决跨尺度特征对齐问题。HyperTea是首次将卷积神经网络（CNNs）、循环神经网络（RNNs）和超图神经网络（HGNNs）集成用于MIRSTD的技术，显著提高了检测性能。", "conclusion": "实验结果表明，HyperTea在DAUB和IRDST数据集上具有最佳性能。其源代码可从该链接获取。"}
{"llm_update_time": "20250816", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.10680", "html_url": "https://arxiv.org/abs/2508.10680", "title": "物理知情联合多回波超分辨率与隐式神经表征在稳健胎儿T2成像中的应用", "title_en": "Physics-Informed Joint Multi-TE Super-Resolution with Implicit Neural Representation for Robust Fetal T2 Mapping", "authors": "Busra Bulut,Maik Dannecker,Thomas Sanchez,Sara Neves Silva,Vladyslav Zalevskyi,Steven Jia,Jean-Baptiste Ledoux,Guillaume Auzias,François Rousseau,Jana Hutter,Daniel Rueckert,Meritxell Bach Cuadra", "background": "胎儿脑MRI中的T2成像具有提高发育中大脑表征的潜力，特别是在0.55T的中场强度下，这里的T2衰减速率较慢。然而，这具有挑战性，因为胎儿MRI采集依赖于多层次且运动损坏的切片堆栈，需要切片到体积重建（SVR）来估计高分辨率（HR）3D体积。当前T2成像需要在每个回波时间（TE）多次获取这些堆栈，导致长时间扫描和高对运动的敏感性。", "innovation": "本文提出了一种方法，联合重建TE下的数据，并解决了严重的运动问题。该方法结合了隐式神经表示与物理知情正则化，后者模拟了T2衰减，同时实现了不同TE之间的信息共享，保持了解剖和定量T2精度。在模拟的胎儿大脑和具有类似胎儿运动的成人生理数据上展示了其优越性能。本文还首次在0.55T的胎儿T2成像中取得了在体结果。研究显示，利用解剖冗余，可以减少每个TE的堆栈数量，从而提高T2成像效率。", "conclusion": "研究展示了利用解剖冗余减少T2成像每个TE的堆栈数量的潜力。"}
{"llm_update_time": "20250816", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.10711", "html_url": "https://arxiv.org/abs/2508.10711", "title": "NextStep-1：大规模连续令牌迈向自回归图像生成", "title_en": "NextStep-1: Toward Autoregressive Image Generation with Continuous Tokens at Scale", "authors": "NextStep Team:Chunrui Han,Guopeng Li,Jingwei Wu,Quan Sun,Yan Cai,Yuang Peng,Zheng Ge,Deyu Zhou,Haomiao Tang,Hongyu Zhou,Kenkun Liu,Ailin Huang,Bin Wang,Changxin Miao,Deshan Sun,En Yu,Fukun Yin,Gang Yu,Hao Nie,Haoran Lv,Hanpeng Hu,Jia Wang,Jian Zhou,Jianjian Sun,Kaijun Tan,Kang An,Kangheng Lin,Liang Zhao,Mei Chen,Peng Xing,Rui Wang,Shiyu Liu,Shutao Xia,Tianhao You,Wei Ji,Xianfang Zeng,Xin Han,Xuelin Zhang,Yana Wei,Yanming Xu,Yimin Jiang,Yingming Wang,Yu Zhou,Yucheng Han,Ziyang Meng,Binxing Jiao,Daxin Jiang,Xiangyu Zhang,Yibo Zhu", "background": "当前的自回归模型在文本到图像生成任务中存在两个关键挑战：一是依赖复杂的扩散模型处理连续图像令牌，这增加了计算负担；二是使用向量量化（VQ）获取带有量化损失的离散令牌。这两种方法都限制了模型的性能。", "innovation": "NextStep-1模型通过结合140亿参数的自回归模型和1.57亿参数的流动匹配头，在离散文本令牌和连续图像令牌上进行下一令牌预测训练，摒弃了上述两种传统方法，实现自回归在文本到图像生成任务中的最强性能，尤其在高质量图像合成和图像编辑方面表现出色。", "conclusion": "该论文发布代码和模型至学术界，旨在推动公开研究并向大规模连续令牌的自回归图像生成迈出重要一步，展示了统一方法的强大和灵活性。"}
{"llm_update_time": "20250816", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.10716", "html_url": "https://arxiv.org/abs/2508.10716", "title": "从图像匹配角度重新审视跨视角定位", "title_en": "Revisiting Cross-View Localization from Image Matching", "authors": "Panwang Xia,Qiong Wu,Lei Yu,Yi Liu,Mingtao Xiong,Lei Liang,Yongjun Zhang,Yi Wan", "background": "跨视角定位旨在通过将地平视图图像与航拍或卫星图像对齐来估计3自由度的姿态。在没有全球导航卫星系统(GNSS)的环境中，如城市峡谷和灾难区域，这一技术至关重要。现有方法要么直接回归姿态，要么在共享的鸟瞰视图(BEV)空间中对齐特征，但这些方法难以建立严格的跨视角对应关系，导致只能得到粗略或几何上不一致的匹配。因此，地平视图和空中视角的精细图像匹配仍然未得到解决，这限制了定位结果的可解释性。", "innovation": "本文从跨视角图像匹配的角度重新审视了跨视角定位问题，并提出了一种新颖的框架，可以同时改进匹配和定位。具体方法包括引入表面模型以准确地进行BEV投影，以及引入SimRefiner模块通过局部-全局残差校正优化相似矩阵，从而消除对后处理如RANSAC的依赖。此外，作者还引入了CVFM，这是一个新的基准数据集，包含32,509个带有像素级对应关系的跨视角图像对，以支持这一领域的进一步研究。", "conclusion": "广泛的实验表明，本文的方法在定位精度和图像匹配质量方面显著提高，并在极端视角差异下建立了新的基准线。"}
{"llm_update_time": "20250816", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.10719", "html_url": "https://arxiv.org/abs/2508.10719", "title": "利用区分性码本先验实现自回归图像生成", "title_en": "Exploiting Discriminative Codebook Prior for Autoregressive Image Generation", "authors": "Longxiang Tang,Ruihang Chu,Xiang Wang,Yujin Han,Pingyu Wu,Chunming He,Yingya Zhang,Shiwei Zhang,Jiaya Jia", "background": "现有的自回归图像生成系统首先将图像序列化为具有代码书的标记索引序列，然后基于这些序列进行训练。尽管模型仅利用索引值进行训练，代码书中的标记相似性信息并未充分利用。一些研究尝试通过简单的k-means聚类引入先验信息，但这在代码书特征空间中表现不佳，原因包括标记空间不一致和质心距离不准确。", "innovation": "提出了一种名为Discriminative Codebook Prior Extractor (DCPE)的新方法，用以更有效地挖掘并利用代码书中嵌入的标记相似性信息，替代传统的基于质心的距离度量。DCPE借鉴凝聚归并技术，通过避免分裂高密度区域和聚集低密度区域的方式解决标记空间不一致的问题。", "conclusion": "大量实验表明，DCPE可以无缝集成到现有的代码书先验方法中。利用提取的区分性先验，DCPE在LlamaGen-B上加快了自回归模型训练速度42%，同时改善了最终的FID和IS性能。"}
{"llm_update_time": "20250816", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.10710", "html_url": "https://arxiv.org/abs/2508.10710", "title": "CountCluster: 不依赖外部工具的跨注意力图聚类在文本到图像生成中实现无需训练的目标数量引导", "title_en": "CountCluster: Training-Free Object Quantity Guidance with Cross-Attention Map Clustering for Text-to-Image Generation", "authors": "Joohyeon Lee,Jin-Seop Lee,Jee-Hyong Lee", "background": "基于扩散机制的文本到图像生成模型在图像质量和多样性方面表现出色，但仍然难以生成与输入提示中指定的对象数量准确匹配的图像。尽管已经提出了依赖外部计数模块或从学习到的标记或潜在特征中推导出的数量表示的几种方法，但在准确反映指定的对象数量和注意到生成图像中对象实例数量在消噪过程的早期时间步骤中主要由决定方面仍然存在局限性。为了解决这个问题，我们的工作提出了CountCluster方法，在推理过程中根据输入中指定的对象数量指导对象跨注意力图聚类，而不需要依赖任何外部工具或额外训练。", "innovation": "CountCluster方法通过对注意力分数进行聚类在推理时将对象跨注意力图分区为k个聚类，定义了每个聚类在空间上分离的理想分布，并优化潜在变量以与目标分布对齐。与其他现有方法相比，该方法在对象数量准确性上平均提高了18.5%。", "conclusion": "CountCluster方法展示了在各种提示的情况下数量控制性能的优越性，并将发布代码，以证明其在文本到图像生成中的有效性和优越性。"}
{"llm_update_time": "20250816", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.10672", "html_url": "https://arxiv.org/abs/2508.10672", "title": "融合生成融合以高效且隐私保护的方式生成面部识别数据集", "title_en": "Hybrid Generative Fusion for Efficient and Privacy-Preserving Face Recognition Dataset Generation", "authors": "Feiran Li,Qianqian Xu,Shilong Bao,Boyu Han,Zhiyong Yang,Qingming Huang", "background": "本文介绍了在DataCV ICCV挑战中我们的方法，重点在于构建一个高质量的面部数据集以训练面部识别模型。该数据集不能包含与任何现有公共面部数据集重叠的身份信息。为了应对这一挑战，我们从基础的HSFace数据集开始，采用专家混合（MoE）策略结合面部嵌入聚类和GPT-4o辅助验证来彻底清理，并保留最大的一致性身份簇。通过数据增强，确保每个身份达到固定数量的图像。为了进一步增加数据集的多样性，我们使用Stable Diffusion结合提示工程生成合成身份。利用Vec2Face高效地从每个身份生成49个一致性版本。通过将这些合成身份在训练早期纳入，利用逐步训练策略，我们最终生成了一个包含每个身份50张图像的高质量多样数据集，并确保所有新生成的身份都经过主流面部数据集的检查以保证没有身份泄露。实验结果表明，我们的方法在竞赛中获得第一名，并且在10K，20K和100K的身份规模上提升了模型性能。", "innovation": "本文提出了一种结合GAN（生成对抗网络）和扩散模型的混合生成方法，用于构建高质量、多样化的面部数据集。通过采用专家混合（MoE）策略，结合面部嵌入聚类和GPT-4辅助验证来清理HRFace数据集，保留最大的一致身份簇，并使用数据增强方法提高每类身份的图像数量。通过Stable Diffusion生成合成身份，并利用Vec2Face进行高效扩增。此外，为了应对合成身份之间的高视觉相似性，本文采用了逐步训练策略。这些技术增强了数据集的多样性和质量，同时确保了隐私性，最终在数据集生成竞赛中获得第一名。", "conclusion": "我们创建的最终数据集在整个身份规模上都提高了模型性能，并且处于领先位置。通过采用逐步训练策略将合成身份纳入数据集，我们成功地构建了一个高质量且多样的面部数据集。此方法不仅展示了数据质量的提升，而且提高了模型在面部识别任务中的表现。"}
{"llm_update_time": "20250816", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.10729", "html_url": "https://arxiv.org/abs/2508.10729", "title": "EgoCross: Benchmarking Multimodal Large Language Models for Cross-Domain Egocentric Video Question Answering", "title_en": "EgoCross: Benchmarking Multimodal Large Language Models for Cross-Domain Egocentric Video Question Answering", "authors": "Yanjun Li,Yuqian Fu,Tianwen Qian,Qi'ao Xu,Silong Dai,Danda Pani Paudel,Luc Van Gool,Xiaoling Wang", "background": "近期多模态大型语言模型（MLLMs）在自我中心视角视频问题回答（EgocentricQA）方面取得了显著进展，但现有的基准测试和研究主要集中在烹饪和清洁等日常生活活动上。然而，在实际部署中，不可避免地会遇到领域转移，目标领域在视觉风格和语义内容上存在显著差异。", "innovation": "本文提出了EgoCross，这是一个综合基准，旨在评估MLLMs在EgocentricQA中的跨领域泛化能力。EgoCross涵盖了四种不同的挑战性领域，包括手术、工业、极限运动和动物视角，这代表了实际且高影响的应用场景。该基准包括大约1,000个QA对，覆盖了798个视频片段，涉及四种关键的QA任务：预测、识别、定位和计数。每一对QA提供了开放问答和封闭问答格式，以支持精细的评估。实验证明，大多数现有的MLLMs，无论是通用型还是自我中心专门化型，都难以在日常场景之外泛化。", "conclusion": "广泛的实验展示了大多数现有的MLLMs在跨领域泛化方面存在局限性。此外，我们还进行了几项试点研究，例如微调和强化学习，探索潜在的改进。希望通过EgoCross和我们附带的分析，为发展适应性、鲁棒的自我中心视频理解奠定基础。数据和代码将在以下链接发布：this https URL."}
{"llm_update_time": "20250816", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.10731", "html_url": "https://arxiv.org/abs/2508.10731", "title": " dissecting generalized category discovery: 多模态共识下的自我分解", "title_en": "Dissecting Generalized Category Discovery: Multiplex Consensus under Self-Deconstruction", "authors": "Luyao Tang,Kunze Huang,Chaoqi Chen,Yuxuan Yuan,Chenxin Li,Xiaotong Tu,Xinghao Ding,Yue Huang", "background": "人类感知系统在识别已知和未知类别的对象方面表现出色，而现有的机器学习框架在这方面能力有限。虽然通用类别发现(GCD)旨在解决这一差距，但现有方法主要集中在优化客观函数上。", "innovation": "本文提出了ConGCD方法，通过高层语义重建分解物体为视觉基元，并通过解构绑定类内共享特征。该方法涵盖了不同个体在视觉处理中的偏好多样性，引入了主导和上下文共识单元来捕捉类特异性模式和内在分布不变量，并通过共识调度器动态优化激活路径，最终通过多模态共识整合生成预测。", "conclusion": "ConGCD作为一种共识感知范式，在粗粒度和细粒度基准测试中表现出色。该研究发布了相应代码。"}
{"llm_update_time": "20250816", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.10712", "html_url": "https://arxiv.org/abs/2508.10712", "title": "嵌入式SAR船目标检测与分类的轻量级CNN", "title_en": "Lightweight CNNs for Embedded SAR Ship Target Detection and Classification", "authors": "Fabian Kresse,Georgios Pilikos,Mario Azcueta,Nicolas Floury", "background": "合成孔径雷达(SAR)数据能够实现对海上船只的大规模监控。但目前，为了进行近实时监测，需要将所有原始数据下传、进行图像聚焦处理后才能在地面进行分析。通过卫星上的处理生成高级产品可以减少需要下传的数据量，缓解带宽限制并减小延迟。然而，传统的图像聚焦和处理算法面临内存有限、处理能力和计算资源有限等问题。本文研究了适用于Sentinel-1在Stripmap和Interferometric Wide (IW)模式下获取的未聚焦SAR数据的神经网络，以实现卫星上的实时推理。通过探讨船舶和风车之间的二元分类任务，证明了目标分类的可能性。", "innovation": "提出了和评估了适用于卫星上实时处理和部署的轻量级CNN模型，特别针对Sentinel-1在Stripmap和Interferometric Wide (IW)模式下获取的未聚焦SAR数据。通过对比实验演示了这些模型在卫星上的可行性，并且证明了可以在FPGA上进行部署，为卫星上的目标检测与分类提供了一种新的解决方案。", "conclusion": "本文展示了轻量级CNN模型在卫星上的实时处理和部署的可能性，通过二元分类任务证明了船舶和其他目标的识别能力。进一步验证了在卫星系统中，在处理能力和计算资源有限的情况下，轻量级CNN模型可以有效进行SAR图像的处理和分析。"}
{"llm_update_time": "20250816", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.10704", "html_url": "https://arxiv.org/abs/2508.10704", "title": "超越传统视觉：RGB-事件融合在动态交通场景中鲁棒目标检测", "title_en": "Beyond conventional vision: RGB-event fusion for robust object detection in dynamic traffic scenarios", "authors": "Zhanwen Liu,Yujing Sun,Yang Wang,Nan Yang,Shengbo Eben Li,Xiangmo Zhao", "background": "传统RGB相机的动态范围限制降低了全局对比度，导致在复杂交通环境中（如夜间驾驶、隧道）难以提取高频率细节（如纹理和边缘），影响特征提取和帧检测的精度。为此，该研究将生物启发的事件相机与RGB相机相结合，提供高动态范围信息，并提出运动线索融合网络（MCFNet），通过挑战性光照下的最优时空对齐和自适应跨模态特征融合来解决以上问题。", "innovation": "该研究融合了生物启发的事件相机与RGB相机，提出了运动线索融合网络（MCFNet），其中包含事件校正模块（ECM）、事件动态上采样模块（EDUM）和跨模态Mamba融合模块（CMM）。ECM通过光流变换对齐异步事件流和图像帧，确保时空对齐；EDUM增强事件帧的空间分辨率，使其与图像结构匹配，保证精确对齐；CMM采用自适应特征融合机制，有效整合互补信息以实现鲁棒检测。在不同照明条件和快速移动交通环境中，MCFNet显著优于现有方法，分别在mAP50和mAP指标上，超过最佳现有方法7.4%和1.7个百分点。", "conclusion": "实验结果表明，MCFNet在DSEC-Det和PKU-DAVIS-SOD数据集上取得了显著提升，在各种不良光照和快速交通场景下能够实现鲁棒性的目标检测。"}
{"llm_update_time": "20250816", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.10737", "html_url": "https://arxiv.org/abs/2508.10737", "title": "增强隐私的视网膜分割基准竞赛: SSBC 2025", "title_en": "Privacy-enhancing Sclera Segmentation Benchmarking Competition: SSBC 2025", "authors": "Matej Vitek,Darian Tomašević,Abhijit Das,Sabari Nathan,Gökhan Özbulak,Gözde Ayşe Tataroğlu Özbulak,Jean-Paul Calbimonte,André Anjos,Hariohm Hemant Bhatt,Dhruv Dhirendra Premani,Jay Chaudhari,Caiyong Wang,Jian Jiang,Chi Zhang,Qi Zhang,Iyyakutti Iyappan Ganapathi,Syed Sadaf Ali,Divya Velayudan,Maregu Assefa,Naoufel Werghi,Zachary A. Daniels,Leeon John,Ritesh Vyas,Jalil Nourmohammadi Khiarak,Taher Akbari Saeed,Mahsa Nasehi,Ali Kianfar,Mobina Pashazadeh Panahi,Geetanjali Sharma,Pushp Raj Panth,Raghavendra Ramachandra,Aditya Nigam,Umapada Pal,Peter Peer,Vitomir Štruc", "background": "该论文总结了2025年视网膜分割基准竞赛(SSBC)，该竞赛旨在评估基于合成数据训练的模型与基于真实数据训练的模型之间的性能差异。竞赛特别关注在保护隐私的同时开发视网膜分割模型。", "innovation": "竞赛引入了两个赛道：一个完全基于合成数据进行模型开发，另一个结合或混合使用合成数据和少量真实数据。研究小组提交了采用不同架构设计的多种分割模型，特别是包括基于变换器的解决方案和生成框架引导的分割网络等。结果显示，完全基于合成数据训练的模型可以实现具有竞争力的性能，特别是在使用专门训练策略时，部分顶级模型在合成数据赛道中达到了0.8以上的F1分数。", "conclusion": "实验表明，合成数据在隐私保护生物特征开发中显示出巨大潜力，特别是在混合赛道中，方法选择比真实数据的使用带来了更多的性能改进。比赛代码和数据可以在指定链接处获得，这为未来的类似研究提供了资源。"}
{"llm_update_time": "20250816", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.10770", "html_url": "https://arxiv.org/abs/2508.10770", "title": "从诊断到改进：探究视觉语言模型的时空物理推理", "title_en": "From Diagnosis to Improvement: Probing Spatio-Physical Reasoning in Vision Language Models", "authors": "Tiancheng Han,Yunfei Gao,Yong Li,Wuzhou Yu,Qiaosheng Zhang,Wenqi Shao", "background": "时空物理推理是理解现实物理世界的基石能力，对于构建稳健的世界模型至关重要。尽管最近的视觉语言模型（VLMs）在多模态数学和纯粹的空间理解等专业领域取得了显著进展，但它们的时空物理推理能力仍然未得到充分探索。现有的VLMs在这方面表现不足，主要是由于人类偏见和缺乏深入推理的局限性。", "innovation": "本文对主流VLMs进行了全面的诊断分析，揭示出当前模型在这项关键任务上的不足。基于此分析，作者使用监督微调后跟随规则基强化学习对Qwen2.5-VL-7B模型进行训练，显著提高了其时空物理推理能力，并超越了领先的私有模型。尽管如此，该模型对于新的物理场景的泛化能力仍然有限，这凸显了空间物理推理新方法的需求。", "conclusion": "尽管取得了成功，但模型仍面临新物理场景泛化的限制，这表明在时空物理推理方面仍需进一步研究新的方法。"}
{"llm_update_time": "20250816", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.10779", "html_url": "https://arxiv.org/abs/2508.10779", "title": "基于生成扩散先验的超高清参考依赖地标图像超分辨率", "title_en": "Ultra-High-Definition Reference-Based Landmark Image Super-Resolution with Generative Diffusion Prior", "authors": "Zhenning Shi,Zizheng Yan,Yuhang Yu,Clara Xue,Jingyu Zhuang,Qi Zhang,Jinwei Chen,Tao Li,Qingnan Fan", "background": "参考依赖图像超分辨率（RefSR）旨在通过利用附加参考高分辨率（参考HR）图像中的语义和纹理信息来恢复低分辨率（LR）图像。现有的基于扩散的方法通常基于ControlNet构建，但难以有效对齐LR图像和参考HR图像之间的信息。当前RefSR数据集在分辨率和图像质量方面较为有限，导致参考图像缺乏足够的细粒度细节来支持高质量的恢复。", "innovation": "提出了TriFlowSR，这是一种新颖的框架，明确地实现了LR图像与参考HR图像之间的模式匹配。同时，引入了Landmark-4K，这是首个专门针对超高清（UHD）地标场景的RefSR数据集。在真实世界退化的情况下考虑UHD场景，TriFlowSR设计了一种参考匹配策略，有效匹配LR图像与参考HR图像。", "conclusion": "实验结果表明，与之前的方法相比，我们的方法能够更好地利用参考HR图像的语义和纹理信息。据我们所知，我们提出了首个针对真实世界退化条件下超高清地标场景的基于扩散的RefSR流水线。我们的代码和模型可以在提供的链接中获得。"}
{"llm_update_time": "20250816", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.10786", "html_url": "https://arxiv.org/abs/2508.10786", "title": "基于光学流动的协作面部活体检测", "title_en": "Cooperative Face Liveness Detection from Optical Flow", "authors": "Artem Sokolov,Mikhail Nikitin,Anton Konushin", "background": "原本的活体检测方法大多数是基于静态图像或者被动分析，对于动态场景下的活体检测缺乏有效的解决方案。本文针对面部活体检测提出了一个新的用户交互场景，用户根据指示缓慢将面向摄像头的面部接近摄像头，结合光学流分析，提出了一种新颖的合作式视频面部活体检测方法。", "innovation": "本文的核心创新在于提出了一个新的用户接近脸部成像协议以及通过神经光学流估计来提取面部体积信息的方法。结合光学流分析，设计了一个允许用户按照特定移动模式的系统，从而显著提高了真实面部和各种欺骗攻击（包括打印照片、屏幕显示、面具和视频重放）之间的区分能力。", "conclusion": "本文方法通过处理预测的光学流动和RGB帧，利用空间-时间特征，相较于被动方法，实现了更可靠的活体检测。该方法证明了在动态场景下有效识别真实面部和伪装的能力。"}
{"llm_update_time": "20250816", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.10771", "html_url": "https://arxiv.org/abs/2508.10771", "title": "AEGIS: AI生成视频序列的真实评价基准", "title_en": "AEGIS: Authenticity Evaluation Benchmark for AI-Generated Video Sequences", "authors": "Jieyu Li,Xin Zhang,Joey Tianyi Zhou", "background": "近年来，AI生成内容的发展推动了高度逼真合成视频的兴起，这严重威胁了社会信任和数字完整性。现有的视频真实性检测基准通常在逼真度、规模和复杂性方面存在局限，无法有效评估现代多模态视觉模型对复杂伪造的检测能力。", "innovation": "本文提出了AEGIS，该基准针对高度逼真且语义精炼的AI生成视频的具体检测需求而设计，包含超过10,000个由多样化的最新生成模型生成的真实和合成视频，包括Stable Video Diffusion、CogVideoX-5B、KLing和Sora等架构。AEGIS 特别构建了具有鲁棒性评估的具有挑战性的子集，并提供了语义真实性描述、运动特征和低级视觉特征等多种模态的注释，有助于真实性检测及支持多模态融合和伪造定位等下游任务。通过高级视觉语言模型进行的大量实验表明，AEGIS 的某些最具挑战性的子集对于现有算法的检测能力有限，突显了其独特的复杂性和逼真性，超越了现有模型的一般化能力。因此，AEGIS 成为了一个必不可少的评估基准，推动了研究向开发真正坚固、可靠、广泛泛化的视频真实性检测方法的发展。", "conclusion": "AEGIS 在现实伪造威胁的背景下树立了重要的评价基准，促进了研究向构建真正坚固的、可靠的和广泛泛化的视频真实性检测方法的发展，支持多模态融合等下游任务，并为未来的研究奠定了基础。"}
{"llm_update_time": "20250816", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.10743", "html_url": "https://arxiv.org/abs/2508.10743", "title": "一种高效的模型驱动的群组配准方法用于构建解剖图谱", "title_en": "An Efficient Model-Driven Groupwise Approach for Atlas Construction", "authors": "Ziwei Zou,Bei Zou,Xiaoyan Kui,Wenqi Lu,Haoran Dou,Arezoo Zakeri,Timothy Cootes,Alejandro F Frangi,Jinming Duan", "background": "构建解剖图谱是医学图像分析的基础，可以提供标准化的空间参考，用于人口层面的解剖学建模等任务。虽然数据驱动的配准方法在成对环境中显示出潜力，但它们依赖于大数据集，缺乏实际普适性，并且在群组环境中无法进行真正推理。相比之下，模型驱动的方法提供了无需训练、理论上有保证的、且对数据效率的方法，但它们在处理大规模3D数据集时面临缩放和优化挑战。本文背景主要描述了现有的数据驱动和模型驱动方法在构建解剖图谱中的不足之处，同时也指出了它们的应用潜力和当前面临的挑战。", "innovation": "本文提出了一种新的模型驱动的群组配准框架DARC（差分图配准通过坐标下降），用于解剖图谱构建。DARC支持广泛的图像不相似度度量，能够有效地处理任意数量的3D图像而不引发GPU内存问题。通过坐标的下降策略和核心性的启用激活函数，DARC生成了无偏、相差态保真的解剖图谱。此外，DARC还演示了两个关键应用：即刻分割和形状合成。所谓即刻分割指的是仅在图谱上标注标签并通过逆变形传播到受试者中，这种方法优于最先进的少量标注方法；形状合成则是通过将合成的相差态变形场应用在图谱网格上来生成新的解剖学变体。DARC的创新在于提供了一个灵活、通用且资源效率高的解剖图谱构建以及应用的框架。", "conclusion": "总之，DARC提供了一个灵活、通用且资源效率高的框架，用于解剖图谱的构建以及应用程序。通过详实的实验数据和案例说明，DARC不仅解决了现有的配准方法所面临的问题，还展示了在即刻分割和形状合成中的卓越性能，证明了该方法的可行性和先进性。这一框架的应用前景广阔，有望应用于各种医学图像分析任务中。"}
{"llm_update_time": "20250816", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.10774", "html_url": "https://arxiv.org/abs/2508.10774", "title": "Video-BLADE: Block-Sparse Attention Meets Step Distillation for Efficient Video Generation", "title_en": "Video-BLADE: Block-Sparse Attention Meets Step Distillation for Efficient Video Generation", "authors": "Youping Gu,Xiaolong Li,Yuhao Hu,Bohan Zhuang", "background": "扩散变换器在高质量视频生成方面目前是领先的，但由于其缓慢的迭代去噪过程和长序列的 prohibitive 二次注意力成本，它们在推理过程中的显著瓶颈。虽然步进蒸馏和稀疏注意力机制分别展示了加速的潜力，但将这两种方法有效结合仍存在重大挑战——无训练整合表现不佳，而分开训练稀疏注意力则需成本高昂的高质量视频数据。", "innovation": "作者提出了BLADE，一种无数据联合训练框架，引入了(1)自适应区块稀疏注意力(ASA)机制以动态生成内容感知的稀疏性掩码，聚焦于显著的空间-时间特征，以及(2)基于轨迹分布匹配(TDM)的稀疏性意识步进蒸馏范式，该范式将稀疏性直接整合到蒸馏过程中而非将其视为单独的压缩步骤，具有快速收敛性。", "conclusion": "该框架在不同尺度下显示出卓越的效率提升。在Wan2.1-1.3B模型上，BLADE相比于50步基线实现了14.10倍的端到端推理加速。对于CogVideoX-5B这类短视频序列长度的模型，该框架提供稳健的8.89倍加速。加速伴随着一致的质量提升，VBench-2.0基准测试显示，BLADE将CogVideoX-5B分数提升至0.569（原分数为0.534），将Wan2.1-1.3B分数提升至0.570（原分数为0.563），这些结果还得到了人类评估的更高评价的支持。相关的代码和模型权重已公开。"}
{"llm_update_time": "20250816", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.10740", "html_url": "https://arxiv.org/abs/2508.10740", "title": "基于群不变表示的轴级对称检测", "title_en": "Axis-level Symmetry Detection with Group-Equivariant Representation", "authors": "Wongyun Yu,Ahyun Seo,Minsu Cho", "background": "对称性是一个基本概念，已经在多个领域得到广泛研究，但在计算机视觉中，检测复杂场景中的对称性仍然是一个重大挑战。尽管现有的基于热图的方法可以定位可能的对称轴区域，但在识别单独的对称轴方面通常缺乏精准度。", "innovation": "本文提出了一种新颖的方法来检测两种最常见的对称类型——反射和旋转的轴级对称。方法采用一种双分支结构，每个分支针对其对称类型利用了群不变特征结构。提出了方向锚点用于反射对称性检测，并提出了反射匹配来比较候选轴上图案及其镜像之间的相似度。对于旋转对称性提出了旋转匹配来比较固定角度间隔上的模式，识别旋转中心。大量实验显示，本文方法达到了最先进的性能。", "conclusion": "本文提出的方法在轴级对称检测方面达到了最先进的性能，优于现有方法。"}
{"llm_update_time": "20250816", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.10833", "html_url": "https://arxiv.org/abs/2508.10833", "title": "UI-Venus技术报告：基于RFT构建高性能UI代理", "title_en": "UI-Venus Technical Report: Building High-performance UI Agents with RFT", "authors": "Zhangxuan Gu,Zhengwen Zeng,Zhenyu Xu,Xingran Zhou,Shuheng Shen,Yunfei Liu,Beitong Zhou,Changhua Meng,Tianyu Xia,Weizhi Chen,Yue Wen,Jingya Dou,Fei Tang,Jinzhen Lin,Yulin Liu,Zhenlin Guo,Yichen Gong,Heng Jia,Changlong Gao,Yuan Guo,Yong Deng,Zhenyu Guo,Liang Chen,Weiqiang Wang", "background": "本文介绍UI-Venus，一种仅使用截图作为输入的原生UI代理，基于多模态大型语言模型。通过基于Qwen2.5-VL的强化微调（RFT）方法，在标准地标的UI grounding和导航任务中取得了最先进的性能。改进包括精心设计的奖励函数、高效的数据清理方法，以及一种新的自我演进框架，用于增强导航性能。", "innovation": "1. UI-Venus采用基于多模态大型语言模型的方法，仅需少量高质量训练样本，通过RFT达到最先进的UI grounding和导航性能。\n2. 引入了专门设计的奖励函数和高效的数据清理方法，进一步提升了导航性能。\n3. 自我演进轨迹历史对齐与稀疏动作增强框架，增强了复杂UI任务中的规划连贯性和通用性。", "conclusion": "本文的贡献包括最新的开源UI代理、全面的数据清理方案以及新颖的自我演化框架，为社区进一步的研究和开发提供了鼓励。"}
{"llm_update_time": "20250816", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.10801", "html_url": "https://arxiv.org/abs/2508.10801", "title": "Object Fidelity Diffusion for Remote Sensing Image Generation", "title_en": "Object Fidelity Diffusion for Remote Sensing Image Generation", "authors": "Ziqi Ye,Shuran Ma,Jie Yang,Xiaoyi Yang,Ziyang Gong,Xue Yang,Haipeng Wang", "background": "高清可控的遥感图像生成既有意义又具有挑战性。现有的扩散模型往往由于无法充分捕捉形态细节而产生低保真度的图像，这可能影响目标检测模型的稳定性和可靠性。为了提高基于遥感的生成对象的准确性和保真度，本文提出了Object Fidelity Diffusion (OF-Diff)，该方法有效提高了生成对象的保真度。", "innovation": "我们首次根据布局提取遥感中的先验物体形状，用于扩散模型。引入了具有扩散一致性损失的双分支扩散模型，在采样阶段无需提供真实图像，即可生成高保真度的遥感图像。此外，引入DDPO进一步微调扩散过程，使生成的遥感图像更具多样性和语义一致性。", "conclusion": "全面的实验结果表明，OF-Diff 在遥感图像的质量指标上优于最先进的方法。特别是在多种多形性和小目标类别上表现显著提升，比如飞机、船只和车辆的mAP分别提高了8.3%、7.7%和4.0%。"}
{"llm_update_time": "20250816", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.10817", "html_url": "https://arxiv.org/abs/2508.10817", "title": "针对33种作物101类疾病的轻量级CNN基准: 移动友好型深度学习植物病害检测", "title_en": "Mobile-Friendly Deep Learning for Plant Disease Detection: A Lightweight CNN Benchmark Across 101 Classes of 33 Crops", "authors": "Anand Kumar,Harminder Pal Monga,Tapasi Brahma,Satyam Kalra,Navas Sherif", "background": "全球植物疾病对粮食安全构成重大威胁。现有的解决方案需要准确且及时的检测系统来应对这一挑战。计算机视觉技术的进步为解决这一挑战带来了希望。尤其是在资源受限的设备上实现高效的疾病检测系统，对于推动农业技术的发展至关重要。开发一种能够准确识别101种植物疾病（覆盖33种作物）的移动友好型解决方案显得尤为重要，这需要一个广泛且综合的植物病害数据集。因此，研究者整合了现有的Plant Doc、PlantVillage和PlantWild三个数据集，以提供一个针对相同目的的数据库。", "innovation": "该研究提出了一个基于移动友好型深度学习的解决方案，能够准确识别101种植物疾病。研究团队特别选择了MobileNetV2、MobileNetV3、MobileNetV3-Large和EfficientNet-B0、B1等轻量级架构，以适应资源受限的设备。实验结果显示，EfficientNet-B1在分类准确率达到94.7%的情况下表现出色，实现了高精度与低计算开销之间的平衡，非常适合在移动设备上进行实际部署。", "conclusion": "研究表明，EfficientNet-B1在101类植物疾病分类中的表现是最优的，其在准确性和计算效率之间达到了良好的平衡，为在移动设备上进行植物病害检测提供了坚实的理论和实践基础。"}
{"llm_update_time": "20250816", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.10838", "html_url": "https://arxiv.org/abs/2508.10838", "title": "利用多基线对比学习的自监督立体匹配", "title_en": "Self-Supervised Stereo Matching with Multi-Baseline Contrastive Learning", "authors": "Peng Xu,Zhiyu Xiang,Jingyun Fu,Tianyu Pu,Kai Wang,Chaojie Ji,Tingming Bai,Eryun Liu", "background": "当前自监督立体匹配依赖于光度一致性假设，但在被遮挡区域由于对应关系不明确而失效。该论文分析了这一问题并指出，传统方法在处理被遮挡区域时表现不佳，因为这些区域的对应关系难以确定，从而影响了匹配结果的准确性。", "innovation": "本文提出了BaCon-Stereo，一种新颖的自监督立体匹配对比学习框架，通过使用多基线输入的教师-学生范式，在非被遮挡和被遮挡区域均能提高预测准确性。BaCon-Stereo引入了一种遮挡感知的注意力图，改进了学生网络在学习遮挡补全时的指导，同时合成了一个多基线数据集BaCon-20k，为训练提供了支持。实验结果表明BaCon-Stereo在KITTI 2015和2012基准测试中优于最先进的自监督方法，且具有较强的泛化和鲁棒性。", "conclusion": "本文通过引入多基线对比学习框架BaCon-Stereo，提高了自监督立体匹配在被遮挡和非被遮挡区域的预测能力，具有较强的泛化和鲁棒性，并且在KITTI 2015和2012基准测试中取得了优异的表现。"}
{"llm_update_time": "20250816", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.10840", "html_url": "https://arxiv.org/abs/2508.10840", "title": "使用客户端自适应焦点调制的一般化联邦学习", "title_en": "Generalizable Federated Learning using Client Adaptive Focal Modulation", "authors": "Tajamul Ashraf,Iqra Altaf Gillani", "background": "联邦学习（FL）已证明对于跨分布式客户端的隐私保护、协作训练至关重要。我们之前的TransFed工作引入了一个基于Transformer的稳健FL框架，利用学习到的自适应超网络生成每个客户端个性化焦点调节层，表现优于传统方法在非IID和跨域设置中。", "innovation": "提出了AdaptFED，通过引入（1）进一步个性化的任务感知客户端嵌入来加深对焦点调节在一般化FL中的研究，（2）加强适应性能的理论限制，以及（3）对更多建模类型的广泛实证验证，包括时间序列和多语言数据。还引入了一种高效的TransFed变种，通过低秩超网络条件减少了服务器-客户端通信开销，使其在资源受限环境中更具扩展性。", "conclusion": "在八个不同数据集上的广泛实验进一步证实了我们方法在源无监督且跨任务联邦设置中的优越性，尤其是在与最先进的基线相比。我们的发现扩展了注意力机制在FL中的应用，并为更适应、更可扩展和更为通用的Transformer基础联邦系统开拓了道路。"}
{"llm_update_time": "20250816", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.10893", "html_url": "https://arxiv.org/abs/2508.10893", "title": "STream3R：基于因果Transformer的大规模顺序3D重建", "title_en": "STream3R: Scalable Sequential 3D Reconstruction with Causal Transformer", "authors": "Yushi Lan,Yihang Luo,Fangzhou Hong,Shangchen Zhou,Honghua Chen,Zhaoyang Lyu,Shuai Yang,Bo Dai,Chen Change Loy,Xingang Pan", "background": "现有的多视角3D重建方法要么依赖昂贵的全局优化过程，要么使用简单但扩展性差的记忆机制。STream3R提出了一种新的方法，将点图预测重新定义为仅解码器的Transformer问题，通过引入因果注意力机制，该方法能高效处理图像序列并且泛化到各种复杂的场景，尤其是传统的静态和动态场景方法无法处理的动态场景。", "innovation": "STream3R通过因果注意力机制和Transformer解码器将点图预测重新定义为一个单一问题，从而避免了全局优化过程。这种方法能够高效学习大规模3D数据集中的几何先验，并应用于多种下游3D任务，表现出优越的性能。", "conclusion": "STream3R在静态和动态场景基准测试中均优于先前的方法，并且能够高效地进行大规模预训练和微调，适用于实时在线的3D感知。"}
{"llm_update_time": "20250816", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.10865", "html_url": "https://arxiv.org/abs/2508.10865", "title": "GPT-5在脑肿瘤MRI推理中的表现", "title_en": "Performance of GPT-5 in Brain Tumor MRI Reasoning", "authors": "Mojtaba Safari,Shansong Wang,Mingzhe Hu,Zach Eidex,Qiang Li,Xiaofeng Yang", "background": "脑肿瘤类型的准确区分对于神经肿瘤学中的治疗规划至关重要。近年来，大规模语言模型（LLMs）的进步使得视觉问答（VQA）方法得以实现，这些方法将图像解释与自然语言推理结合在一起。这项研究利用了GPT-5、GPT-5-mini、GPT-5-nano和GPT-4o模型在3个脑肿瘤分割（BraTS）数据集（胶质母细胞瘤、脑膜瘤和脑转移瘤）上构建的定制VQA基准数据集来进行评估，这些模型在零样本链式思考设置下对视觉和推理任务进行了评估。", "innovation": "研究采用了大型语言模型（LLMs）中的GPT系列模型来解决脑肿瘤的VQA任务，展示了GPT-5系列模型在结构化神经肿瘤学VQA任务中的中等准确性，但未达到临床使用标准。这表明尽管存在局限性，但在未来仍有可能通过进一步优化提升模型性能以适应临床需求。", "conclusion": "GPT-5-mini在多项任务中表现最佳，其次是GPT-5、GPT-4o和GPT-5-nano。不同类型的脑肿瘤模型表现不一，没有单一模型在所有群体中表现最优。GPT-5家族模型在结构化的神经肿瘤学VQA任务中达到了中等的准确性，但仍需临床适用的水平。"}
{"llm_update_time": "20250816", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.10894", "html_url": "https://arxiv.org/abs/2508.10894", "title": "MAESTRO: Masked AutoEncoders for Multimodal, Multitemporal, and Multispectral Earth Observation Data", "title_en": "MAESTRO: Masked AutoEncoders for Multimodal, Multitemporal, and Multispectral Earth Observation Data", "authors": "Antoine Labatie,Michael Vaccaro,Nina Lardiere,Anatol Garioud,Nicolas Gonthier", "background": "自监督学习在遥感领域具有巨大潜力，但标准的自监督方法需要适应地球观测数据的独特特性。目前，还没有专门针对多模态、多时态和多光谱地球观测数据的综合基准研究。本文通过评估不同融合策略和重建目标归一化方案，填补了这一研究空白。", "innovation": "本文提出了一种名为MAESTRO的新方法，这是一种增强的掩码自编码器，具有优化的融合策略和自定义的目标归一化方案。特别地，MAESTRO引入了光谱先验作为自监督信号。该方法在四项地球观测数据集上进行了测试，取得了在依赖多时态动态的任务中新的最先进成果，同时在以单一时刻模式为主导的任务中保持了很高的竞争力。", "conclusion": "通过MAESTRO，在依赖多时态动态的任务中取得了新的最先进成果，同时在以单一时刻模式为主导的任务中保持了竞争力，为未来基于自监督学习的地球观测数据处理提供了新的思路。"}
{"llm_update_time": "20250816", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.10858", "html_url": "https://arxiv.org/abs/2508.10858", "title": "Hierarchical Fine-grained Preference Optimization for Physically Plausible Video Generation", "title_en": "Hierarchical Fine-grained Preference Optimization for Physically Plausible Video Generation", "authors": "Harold Haodong Chen,Haojian Huang,Qifeng Chen,Harry Yang,Ser-Nam Lim", "background": "最近的视频生成技术已经能够生成高质量和视觉吸引力的视频。然而，生成遵循物理定律的视频仍然是对逼真和准确度有需求的应用中的关键挑战。本文探讨了这一挑战，并提出了一种名为PhysHPO的新框架，该框架通过细粒度的偏好对齐来实现物理上合理视频的生成。", "innovation": "PhysHPO通过四个层次的细粒度优化来实现视频生成：实例级别（使视频内容与输入提示保持一致）、状态级别（使用边界帧确保时间一致性）、运动级别（建模运动轨迹以实现逼真动态效果），以及语义级别（维持叙述和视觉之间的逻辑一致性）。此外，还引入了一个自动化的数据选择流程，可以从现有大规模的文本-视频数据集中高效地选择和使用“优质数据”，从而降低了数据集构建的高成本和时间投入。", "conclusion": "在物理聚焦和通用能力基准上的广泛实验表明，PhysHPO显著提高了高级模型的物理可驳性和整体视频生成质量。据我们所知，这是首次探讨视频生成中细粒度偏好对齐和数据选择的研究工作，为生成更真实且符合人类偏好的视频提供了一条新途径。"}
{"llm_update_time": "20250816", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.10869", "html_url": "https://arxiv.org/abs/2508.10869", "title": "Medico 2025: 视觉问答在胃肠成像中的应用", "title_en": "Medico 2025: Visual Question Answering for Gastrointestinal Imaging", "authors": "Sushant Gautam,Vajira Thambawita,Michael Riegler,Pål Halvorsen,Steven Hicks", "background": "该论文挑战针对Gastrointestinal (GI)成像的Visual Question Answering (VQA)。它作为MediaEval任务系列的一部分进行组织，旨在开发能够根据GI内窥镜图像回答与临床相关的解释性人工智能模型。挑战引入了两个子任务：(1) 使用Kvasir-VQA-x1数据集回答各种类型的问题；(2) 生成多模态解释以支持临床决策。Kvasir-VQA-x1数据集包含6500张图像和159,549个复杂问题-答案对，作为挑战的基准数据集。通过结合定量性能指标和专家评估的解释性评估，该任务旨在推动在医学影像分析中的可信赖人工智能的发展。", "innovation": "该挑战的主要创新在于开发基于GI内窥镜图像的XAI模型，这些模型不仅能够回答临床相关的问题，还能提供与医学推理相一致的解释性支持。此外，通过引入两个子任务，分别关注问题回答和多模态解释的生成，挑战促进了在医学图像分析中的解释性人工智能的发展。", "conclusion": "通过将定量评估方法与专家审核的解释评价相结合，该挑战旨在推进可信的人工智能在医学图像分析中的应用，并提供基准数据集作为测试验证的工具。该挑战还提供了操作指南和数据访问途径，以促进更多研究参与。"}
{"llm_update_time": "20250816", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.10896", "html_url": "https://arxiv.org/abs/2508.10896", "title": "ESSENTIAL: Episodic and Semantic Memory Integration for Video Class-Incremental Learning", "title_en": "ESSENTIAL: Episodic and Semantic Memory Integration for Video Class-Incremental Learning", "authors": "Jongseo Lee,Kyungho Bae,Kyle Min,Gyeong-Moon Park,Jinwoo Choi", "background": "现有视频类别增量学习（VCIL）方法通过重现训练来缓解灾难性遗忘问题，但需要存储大量的时序密集样本，在内存效率方面不够高效。另一种方法则是存储时序稀疏样本，但这样会牺牲太多重要的时序信息，从而导致性能较低。", "innovation": "本文提出了Episodic and Semantic Memory Integration for video class-incremental Learning (ESSENTIAL)。ESSENTIAL集成了时空稀疏特征的 episodic 记忆和可通过可学习提示表达的一般知识的 semantic 记忆。文中还引入了一个新颖的内存检索（MR）模块，通过交叉注意力机制将 episodic 记忆和语义提示相结合，实现了从时空稀疏特征中检索时空密集特征的能力。", "conclusion": "在TCD基准的数据集UCF-101, HMDB51, 和Something-Something-V2，以及vCLIMB基准的数据集UCF-101, ActivityNet, 和Kinetics-400的严格验证表明，ESSENTIAL在减少记忆使用量的情况下仍然能够达到优越的表现。"}
{"llm_update_time": "20250816", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.10868", "html_url": "https://arxiv.org/abs/2508.10868", "title": "TexVerse: 一个高分辨率纹理的3D对象 universe", "title_en": "TexVerse: A Universe of 3D Objects with High-Resolution Textures", "authors": "Yibo Zhang,Li Zhang,Rui Ma,Nan Cao", "background": "近年来，大规模3D数据集的进展极大地提高了高分辨率几何生成的能力，但在端到端生成高分辨率纹理方面仍存在不足，主要是缺乏合适的数据集。TexVerse通过收集超过858,000个独特的高分辨率3D模型解决了这一问题，这些模型来源于Sketchfab，其中超过158,000个模型具有基于物理的渲染（PBR）材料。此外，TexVerse还提供了两个专门的子集：TexVerse-Skeleton，包含69,000个装配模型，以及TexVerse-Animation，包含54,000个动画模型，都能保留用户上传的原始骨架和动画数据。每个模型都包含所有高分辨率变体，总计达到1.6百万个3D实例。", "innovation": "TexVerse填补了高分辨率纹理生成的空白。它包含一个高度集中的3D模型集合，具有源自Sketchfab的超过858,000个独特的高分辨率模型，以及超过158,000个基于PBR的模型。此外，TexVerse还提供了两个专门的子集：TexVerse-Skeleton和TexVerse-Animation，分别包含69,000个装配模型和54,000个动画模型，都保留了原始的骨架和动画数据。每个模型都包含了所有高分辨率变体，极大地丰富了数据集的内容和应用潜力，特别是在纹理合成、PBR材料开发、动画和各种3D视觉与图形任务中.", "conclusion": "TexVerse提供了一个高质量的高分辨率纹理3D数据资源，具有广泛的应用前景，适合用于纹理合成、PBR材料开发、动画以及各种3D视觉和图形任务的研究和应用。"}
{"llm_update_time": "20250816", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.10898", "html_url": "https://arxiv.org/abs/2508.10898", "title": "Puppeteer: 自动绑定和动画你的3D模型", "title_en": "Puppeteer: Rig and Animate Your 3D Models", "authors": "Chaoyue Song,Xiu Li,Fan Yang,Zhongcong Xu,Jiacheng Wei,Fayao Liu,Jiashi Feng,Guosheng Lin,Jianfeng Zhang", "background": "现代交互应用越来越需要动态3D内容，然而将静态3D模型转换为动画资产是内容创建过程中的一个重大瓶颈。尽管最近生成式AI技术在静态3D模型创建方面取得了革命性进展，但布线和动画仍然严重依赖专家干预。因此，需要一个全面的框架来自动处理多样化的3D对象的布线和动画。", "innovation": "本文提出了Puppeteer，一个全面的框架，用于解决3D对象的自动布线和动画问题。该系统首先通过引入基于关节的标记策略和层次化排序方法的自回归变压器来预测合理的骨骼结构，并通过拓扑意识的关节注意力架构隐式编码骨架图之间的关节关系。此外，还使用可微优化基础的动画管道来生成高保真、计算效率更高的动画，同时在多个基准测试中证明了该方法在骨骼预测准确性和上皮质量方面显著优于现有技术。", "conclusion": "在整个研究中，Puppeteer系统在处理包括专业游戏资产和AI生成形状等多种3D内容时表现出高度的鲁棒性，同时生成时间上连贯的动画，消除了现有方法中的抖动问题，系统广泛应用于各种静态3D模型的自动布线和动画生成过程。"}
{"llm_update_time": "20250816", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.10741", "html_url": "https://arxiv.org/abs/2508.10741", "title": "基于双感知网络的伪造引导学习策略在跨域深.fake检测中的应用", "title_en": "Forgery Guided Learning Strategy with Dual Perception Network for Deepfake Cross-domain Detection", "authors": "Lixin Jia,Zhiqing Guo,Gaobo Yang,Liejun Wang,Keqin Li", "background": "由于深fake技术的发展，引发了广泛的社会问题并受到了大量的关注。现有的深fake检测方法在特定数据集上表现良好，但在应用到未知伪造技术的数据集上效果较差。随着新兴伪造技术和传统伪造技术之间差距的扩大，依赖于常见伪造线索的跨域检测方法变得越发无效。这凸显了开发具有强泛化能力的深fake检测技术的迫切性，以应对快速迭代的伪造技术挑战。", "innovation": "本文提出了一种伪造引导学习（FGL）策略，旨在使检测网络能够不断适应未知的伪造技术。该策略捕捉已知和未知伪造技术之间的差异信息，使模型能够实时动态调整其学习过程。此外，设计了一种双感知网络（DPNet），能够同时捕捉伪造线索的差异和关系。在网络的频率流中，动态感知和提取多种伪造技术的判别特征，并将这些特征与空间特征相结合，投影到嵌入空间中。同时，使用图卷积感知整个特征空间的关系，从而更全面地理解伪造线索的相关性。实验表明，该方法在不同场景下泛化良好，有效地处理了未知伪造挑战，为深fake检测提供了稳健的支持。", "conclusion": "我们的方法在不同场景下泛化良好，并有效地处理了未知伪造挑战，提供了深fake检测的稳健支持。我们的代码可以在以下链接中获取："}
{"llm_update_time": "20250816", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.10065", "html_url": "https://arxiv.org/abs/2508.10065", "title": "隐形水印，显而易见的收获：基于双层水印设计的机器遗忘引导", "title_en": "Invisible Watermarks, Visible Gains: Steering Machine Unlearning with Bi-Level Watermarking Design", "authors": "Yuhao Sun,Yihua Zhang,Gaowen Liu,Hongtao Xie,Sijia Liu", "background": "随着遗忘权需求的增加，机器遗忘（MU）已成为提高信任和合规性的重要工具。当前的MU算法主要依赖于调整模型权重的在线方法，对于数据层面调整带来的好处研究较少。研究指出，现有的MU方法在应对“挑战性遗忘”场景时效果不佳。", "innovation": "本研究提出了一种新的基于数字水印的MU方法，称为Water4MU。该方法利用双层优化框架，上层优化水印网络以最小化遗忘难度，下层独立训练模型。这种方法更有效地实现了数据的精确定位遗忘，同时保持模型在相关任务中的实用性。实验表明，Water4MU在图像分类和生成任务上的MU效果优于现有方法，特别是在“挑战性遗忘”场景下。", "conclusion": "研究结果证明，通过使用Water4MU方法，可以有效地实现机器遗忘，同时保持模型在无关任务中的性能。这为未来的MU研究提供了新的思路和工具，显著提高了MU的实用性。"}
{"llm_update_time": "20250816", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.10196", "html_url": "https://arxiv.org/abs/2508.10196", "title": "使用卷积神经网络的可解释人工智能技术在肺癌检测中的应用", "title_en": "Explainable AI Technique in Lung Cancer Detection Using Convolutional Neural Networks", "authors": "Nishan Rai,Sujan Khatri,Devendra Risal", "background": "早期检测肺癌对于提高生存率至关重要。本文提出了一种深度学习框架，用于通过胸部计算机断层扫描(CT)图像自动进行肺癌筛查，并集成了可解释性。研究使用了IQ-OTH/NCCD数据集（包含1,197次来自正常、良性、恶性类别的扫描），评估了一种自定义的卷积神经网络(CNN)以及三种微调的神经网络基础模型：DenseNet121、ResNet152和VGG19。", "innovation": "该研究通过集成可解释性技术（Shapley Additive Explanations, SHAP），提供了一种结合了解释性的基于CNN的方法，以实现快速、准确且可解释的肺癌筛查支持，尤其适用于资源有限的地区。", "conclusion": "ResNet152在准确率方面表现最佳，而DenseNet121在精确度、召回率和F1分数上提供了最佳的整体平衡。实验结果表明，结合解释性的基于CNN的方法可以为肺癌筛查提供快速、准确和可解释的支持，特别适合资源有限的环境。"}
{"llm_update_time": "20250816", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.10897", "html_url": "https://arxiv.org/abs/2508.10897", "title": "Human-in-Context: 使用上下文学习实现统一跨域3D人体运动建模", "title_en": "Human-in-Context: Unified Cross-Domain 3D Human Motion Modeling via In-Context Learning", "authors": "Mengyuan Liu,Xinshun Wang,Zhongbin Fang,Deheng Ye,Xia Li,Tao Tang,Songtao Wu,Xiangtai Li,Ming-Hsuan Yang", "background": "现有跨域模型通常依赖于特定领域的组件和多阶段训练，这限制了它们的实用性和可扩展性。研究旨在建立一个单一模型来处理多模态、任务和数据集中的3D人体动作，但现有的跨域模型因需特定领域组件和多阶段训练而存在局限性，难以满足多样性和广泛性需求。因此，需要一个新框架来简化训练过程，广泛建模不同领域和任务，同时解决模态多样性、策略选择和上下文依赖性处理问题。", "innovation": "文章提出了Human-in-Context (HiC)，一种新的上下文学习框架，整合了Pose-in-Context (PiC) 的优点并进一步提高其在不同模态、任务和数据集上的泛化能力。HiC通过结合姿态和网格表示、增加任务覆盖范围和完善更大数据集的引入，不仅提升了模型的灵活性和多样性，还通过max-min相似性提示采样策略和双支路上下文注入网络架构，改善了上下文依赖性处理。实验结果显示，HiC在泛化能力、数据规模和性能方面优于PiC，展示了HiC作为统一跨域能力模型的潜力。", "conclusion": "研究成功展示了通过HiC构建统一跨域3D人体运动模型的可行性，并显著提升了模型的灵活性和可扩展性。该模型在多个领域的泛化性、数据规模和性能上表现优异，证明了改进后的学习框架的有效性。未来的研究可能涉及更复杂的数据集和更多样的任务环境。相关代码和模型可在给定的链接找到。"}
{"llm_update_time": "20250816", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.10215", "html_url": "https://arxiv.org/abs/2508.10215", "title": "高效利用数据的一般化手术视频理解", "title_en": "Data-Efficient Learning for Generalizable Surgical Video Understanding", "authors": "Sahar Nasirihaghighi", "background": "手术视频分析的进步正在将手术室转变为智能的数据驱动环境。计算机辅助系统支持从术前规划到术中指导再到术后评估的整个手术流程。然而，由于注释稀缺、时空复杂性和程序与机构之间的域差异，基于深度学习的手术视频理解模型的开发仍然具有挑战性。", "innovation": "为了解决手术阶段、动作和事件识别的核心挑战，研究者通过基准测试最先进的神经网络架构来识别每项任务中最有效的设计，并提出了一种新的半监督框架。该研究还引入了包括DIST、SemiVT-Surge和ENCORE在内的新型半监督框架，这些框架通过使用少量的标注数据并通过动态伪标签改进模型训练，实现了在具有挑战性的手术数据集上的最佳结果。", "conclusion": "这项工作为手术视频分析提供了稳健、数据高效且在临床上可扩展的解决方案，为一般化的人工智能系统奠定了基础，这些系统能够对手术护理和培训产生有意义的影响。"}
{"llm_update_time": "20250816", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.10118", "html_url": "https://arxiv.org/abs/2508.10118", "title": "从意图到执行：基于多模态链式思考的强化学习精确CAD代码生成", "title_en": "From Intent to Execution: Multimodal Chain-of-Thought Reinforcement Learning for Precise CAD Code Generation", "authors": "Ke Niu,Haiyang Yu,Zhuofan Chen,Mengyang Zhao,Teng Fu,Bin Li,Xiangyang Xue", "background": "计算机辅助设计（CAD）在工程和制造中起着关键作用，但当前的CAD工作流程需要广泛的领域专业知识和手动建模努力。大型语言模型（LLMs）的进步使得从自然语言生成代码成为可能，开辟了自动参数化3D建模的新机会。然而，直接将人类的设计意图转换为可执行的CAD代码仍极具挑战性，因为需要逻辑推理、句法正确性以及数值精度。", "innovation": "本文提出了一种名为CAD-RL的多模态链式思考（CoT）引导的强化学习后训练框架，用于CAD建模代码生成。该方法结合了基于CoT的冷启动和目标驱动的强化学习后训练，采用三个特定任务的奖励：可执行奖励、几何精度奖励和外部评估奖励。为了在稀疏和高变差的奖励条件下确保稳定的学习策略，引入了三种优化策略：改进探索的可信区域拉伸、增强维度参数精度的精度标记损失以及减少噪音监督的过长过滤。为了支持训练和基准测试，我们发布了包含16,540个实际CAD示例的新数据集ExeCAD，这些示例配有自然语言和结构化设计语言描述、可执行CADQuery脚本和3D模型渲染。实验表明，CAD-RL在推理质量、输出精度和代码可执行性方面显著优于现有视觉语言模型（VLMs）。", "conclusion": "通过CAD-RL，实现了从设计意图到精确CAD代码生成的有效路径，显著提高了参数化3D建模的自动化水平。"}
{"llm_update_time": "20250816", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.10900", "html_url": "https://arxiv.org/abs/2508.10900", "title": "具有神经振幅编码的量子视觉场", "title_en": "Quantum Visual Fields with Neural Amplitude Encoding", "authors": "Shuteng Wang,Christian Theobalt,Vladislav Golyanik", "background": "量子隐神经表示（QINRs）包括在基于门的量子计算机上进行学习和执行的组件。尽管QINRs作为一种新的有前景的方法最近才出现，但其架构和参数设计，量子力学性质的实用性，训练效率以及与经典模块的相互作用等方面仍面临许多挑战。本文旨在推进该领域，引入了一种新的2D图像和3D几何场学习的QINR，名为量子视觉场（QVF），利用神经振幅编码将经典数据编码到量子态向量中，确保有意义的希尔伯特空间嵌入。QVF的答案采用可学习的全纠缠设计的参数量子电路，其中的量子（幺正）操作在实希尔伯特空间中进行，保证了数值稳定的训练以及快速收敛。QVF不再依赖于经典后处理，而是通过投影测量直接提取答案中的学习信号。实验表明，QVF在视觉表示准确性方面优于现有量子方法和广泛使用的经典基础模型，在各个指标和模型特性方面表现出优异性能，特别是在高频率细节的学习上。此外，还展示了QVF在2D和3D场完成以及3D形状插值中的应用，突显了其实用潜力。", "innovation": "本文引入了一种新的2D图像和3D几何场学习的量子视觉场（QVF）方法，通过神经振幅编码将经典数据编码到量子态向量中，采用了全纠缠设计的参数量子电路，确保了数值稳定训练和快速收敛。QVF不需要经典后处理，并且直接通过投影测量提取学习信号。实验显示在各种指标和模型特性中，特别是高频率细节的学习上，QVF优于现有量子方法及经典模型。此外，QVF在2D和3D场完成以及3D形状插值方面也展示了应用潜力。", "conclusion": "本文提出的量子视觉场（QVF）在视觉表示准确性上超过了现有的量子方法和广泛使用的基础模型，在高频率细节的学习方面表现尤为突出。此外，还展示了QVF在2D和3D场完成以及3D形状插值的应用，证明了其实用潜力。"}
{"llm_update_time": "20250816", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.10260", "html_url": "https://arxiv.org/abs/2508.10260", "title": "DINOMotion：基于DINOv2的2D-Cine MRI引导放疗中高级稳健的组织运动追踪", "title_en": "DINOMotion: advanced robust tissue motion tracking with DINOv2 in 2D-Cine MRI-guided radiotherapy", "authors": "Soorena Salari,Catherine Spino,Laurie-Anne Pharand,Fabienne Lathuiliere,Hassan Rivaz,Silvain Beriault,Yiming Xiao", "background": "在2D-Cine MRI引导的放疗中，准确的组织运动追踪对于确保治疗结果和安全性至关重要。现有的方法往往难以应对大的对准误差并缺乏可解释性。", "innovation": "本文引入了DINOMotion，这是一种基于DINOv2并结合低秩适应（LoRA）层的新颖深度学习框架，用于实现稳健、高效和具有解释性的运动追踪。DINOMotion通过自动检测对应的关键点来提高解释性，并通过提供显式的可视化对应关系来增强对序列图像的影对。LoRA层减少可训练参数，提升训练效率，而DINOv2的强大特征表示则提供了对大对准误差的稳健性。DINOMotion在测试阶段直接计算图像对准。", "conclusion": "实验表明，DINOMotion在志愿者和患者数据集上有效估计线性和非线性变换，肺、肝、肾的Dice分数分别为95.23%、90.90%和92.07%，相应的Hausdorff距离分别为6.72mm、8.31mm和5.47mm。DINOMotion在处理大对准误差方面优于最先进的方法，且处理每个扫描大约需要30ms。"}
{"llm_update_time": "20250816", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.10299", "html_url": "https://arxiv.org/abs/2508.10299", "title": "通过知识增强初始化提高联邦适配器调优中学习新疾病的性能", "title_en": "Improving Learning of New Diseases through Knowledge-Enhanced Initialization for Federated Adapter Tuning", "authors": "Danni Peng,Yuan Wang,Kangning Cai,Peiyan Ning,Jiming Xu,Yong Liu,Rick Siow Mong Goh,Qingsong Wei,Huazhu Fu", "background": "在医疗健康领域，联邦学习（FL）是一种常用的框架，能够实现医疗机构之间的隐私保护协作。随着大型基础模型（FMs）表现出色，通过成本效益高的适配器调优将FMs应用于联邦学习变得流行。由于医疗环境的迅速变化，个体客户端需要快速适应新的任务或疾病，通过适配器调用来利用过去的经历来实现。", "innovation": "本文提出了一种名为Federated Knowledge-Enhanced Initialization（FedKEI）的新框架，该框架利用跨客户端和跨任务的知识转移，生成利用适配器学习新任务时的有信息的初始设定。FedKEI首先通过服务器上的全局聚类过程来跨任务推广知识，然后优化跨簇（集群间）和在每个簇内（集群内）的聚合权重，以个性化解知识传递。为了使跨集群和集群内权重的学习更加有效，采用了层次优化方案，该方案实现了客户端间全局集群内权重的学习以及优化每个客户端的任务目标的本地集群间权重。", "conclusion": "在三种不同模态的基准数据集上，包括皮肤科、胸部X光和视网膜OCT，FedKEI在适应新疾病方面优于最先进的方法。"}
{"llm_update_time": "20250816", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.10881", "html_url": "https://arxiv.org/abs/2508.10881", "title": "ToonComposer: 简化卡通生产中的生成后关键帧", "title_en": "ToonComposer: Streamlining Cartoon Production with Generative Post-Keyframing", "authors": "Lingen Li,Guangzhi Wang,Zhaoyang Zhang,Yaowei Li,Xiaoyu Li,Qi Dou,Jinwei Gu,Tianfan Xue,Ying Shan", "background": "传统的漫画和动画制作涉及到关键帧设定、中线生成和颜色化处理，这些都需要大量的手工操作。尽管最近人工智能领域取得了很大进步，现有的方法通常对这些步骤分别处理，这导致了错误累积和伪影等问题。例如，中线生成方法在处理大范围运动时存在问题，而颜色化方法则需要密集的每帧草图。为了解决这些问题，本文介绍了一种名为ToonComposer的生成模型，该模型将中线生成和颜色化整合为一个关键帧后处理阶段。ToonComposer 使用稀疏草图注入机制，利用关键帧草图提供精确控制，同时使用卡通改编方法与空间低秩适配器，将现代的视频基础模型适配到卡通领域，同时保持其时间先验不变。该模型仅需单个草图和染色参考帧即可实现高效运行，并支持任意时间位置的多个草图以实现更精确的运动控制，从而减少手工工作量，提高灵活性，使艺术家能够在实际情况下更强大地运用这项技术。为了验证模型性能，作者创建了名为PKBench的基准，其中包括了模拟真实世界场景的人工绘制草图。实验结果表明，ToonComposer 在视觉质量、运动一致性以及生产效率方面均优于现有方法，提供了一种更加优秀且灵活的AI辅助卡通制作解决方案。", "innovation": "ToonComposer 是一种将中线生成和颜色化整合为一个关键帧后处理阶段的生成模型。使用稀疏草图注入机制，依靠关键帧草图提供精确控制的同时，通过卡通改编方法结合空间低秩适配器，为现代视频基础模型的卡通领域进行定制化，同时保持时间先验不变。只需要单个草图和染色参考帧即可高效运行，支持多个草图用于精确的运动控制，从而减少人工劳动强度和提供更大的灵活性，适合实际应用中的艺术家。", "conclusion": "ToonComposer 在视觉质量、运动一致性和生产效率方面优于现有方法，提供了一种更为优秀和灵活的AI辅助卡通制作解决方案。"}
{"llm_update_time": "20250816", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.10298", "html_url": "https://arxiv.org/abs/2508.10298", "title": "SynBrain: 通过概率表示学习提高视觉到fMRI合成", "title_en": "SynBrain: Enhancing Visual-to-fMRI Synthesis via Probabilistic Representation Learning", "authors": "Weijian Mai,Jiamin Wu,Yu Zhu,Zhouheng Yao,Dongzhan Zhou,Andrew F. Luo,Qihao Zheng,Wanli Ouyang,Chunfeng Song", "background": "在计算神经科学领域，解析视觉刺激如何转化为皮层反应是一个基本挑战。这种视觉到神经的映射本质上是一个一对一到多对一的映射，即相同的视觉输入在不同试验、上下文和被试间通常会引发可变的血氧水平依赖（hemodynamic）响应。现有确定性方法在同时建模这种生物可变性和捕捉编码刺激信息的功能一致性方面存在局限性。", "innovation": "我们提出了一个名为SynBrain的生成框架，该框架以概率和生物可解释的方式模拟从视觉语义到神经响应的转化。SynBrain包含两个关键技术组件：(i) BrainVAE通过概率学习建模神经表示作为连续概率分布，同时通过视觉语义约束保持功能一致性；(ii) 一种语义到神经的映射器作为语义传输路径，将视觉语义投影到神经响应流形上，促进高保真度fMRI合成。", "conclusion": "实验结果表明，SynBrain在被试特异性视觉到fMRI编码性能上超越了最先进的方法，并能有效适应少量数据的新被试，合成高质量的fMRI信号以提高数据受限的fMRI到图像解码性能。此外，SynBrain揭示了跨试验和被试的功能一致性，合成信号捕捉到了由生物神经可变性形成的可解释模式。代码将公开可用。"}
{"llm_update_time": "20250816", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.10333", "html_url": "https://arxiv.org/abs/2508.10333", "title": "ReconVLA: Reconstructive Vision-Language-Action Model as Effective Robot Perceiver", "title_en": "ReconVLA: Reconstructive Vision-Language-Action Model as Effective Robot Perceiver", "authors": "Wenxuan Song,Ziyang Zhou,Han Zhao,Jiayi Chen,Pengxiang Ding,Haodong Yan,Yuxin Huang,Feilong Tang,Donglin Wang,Haoang Li", "background": " recent advances in Vision-Language-Action (VLA) models have enabled robotic agents to integrate multimodal understanding with action execution. However, current VLA models struggle to allocate visual attention to correct target regions, instead dispersing visual attention.", "innovation": "ReconVLA, a reconstructive VLA model with an implicit grounding paradigm. The diffusion transformer aims to reconstruct the gaze region of the image corresponding to the target manipulated objects. This process prompts the VLA model to learn fine-grained representations and accurately allocate visual attention, leveraging task-specific visual information and conducting precise manipulation. Additionally, a large-scale pretraining dataset was curated to boost the model's generalization in visual reconstruction.", "conclusion": "Extensive experiments in simulation and the real world demonstrate the superiority of ReconVLA, showcasing its capabilities of precise manipulation and generalization. The model effectively leverages task-specific visual information and generalizes well in visual reconstruction."}
{"llm_update_time": "20250816", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.10307", "html_url": "https://arxiv.org/abs/2508.10307", "title": "使用全局和局部循环表示实现高效图像去噪", "title_en": "Efficient Image Denoising Using Global and Local Circulant Representation", "authors": "Zhaoming Kong,Jiahuan Zhang,Xiaowei Yang", "background": "随着成像设备的进步和每日生成的大量图像数据，高效且有效的图像去噪的需求日益提高。本文背景在于探索非局部自相似性先验，并利用主成分分析（PCA）与循环表示下小波变换之间的联系，提出了一种计算简单的去噪算法Haar-tSVD。", "innovation": "通过结合循环表示下的小波变换和张量-奇异值分解（t-SVD）投影，Haar-tSVD能够有效捕捉全局和局部 patch 的相关性，简化滤波步骤，同时保持去噪速度和性能之间的平衡。此外，引入了基于CNN估计器和特征值分析的自适应噪声估计方案，增强了方法的鲁棒性和适应性。", "conclusion": "实验结果验证了Haar-tSVD在噪声去除和细节保留方面具有高效性和有效性。相关数据、代码和结果已在该网址公开：this https URL."}
{"llm_update_time": "20250816", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.10429", "html_url": "https://arxiv.org/abs/2508.10429", "title": "MM-Food-100K: 一个具有可验证来源的100,000样本多模态食品智能数据集", "title_en": "MM-Food-100K: A 100,000-Sample Multimodal Food Intelligence Dataset with Verifiable Provenance", "authors": "Yi Dong,Yusuke Muraoka,Scott Shi,Yi Zhang", "background": "论文背景信息来源于对现有食品图像数据集的需求及其质量挑战。数据库的构建基于从超过87,000个贡献者中收集的120万高质量食品图像。这些图像被注释为包含各种信息，如菜品名称和创作地等，通过一种结合社区贡献和可配置的AI辅助质量检查模式的Codatta贡献模型收集起来。", "innovation": "该论文提出了MM-Food-100K，一个具有可验证来源的100,000样本多模态食品智能数据集。数据集通过结合社区贡献和AI辅助的质量检查模型收集，每个贡献链接到一个安全的离链账本，实现可追踪性。它对一系列视觉-语言模型进行了微调，用于食物营养预测，取得了标准指标上的一致改进。", "conclusion": "MM-Food-100K数据集免费向公众开放，约90%的数据保留用于商业用途，收入分享给贡献者。该数据集通过微调大视觉语言模型验证了其在基于图像的营养预测方面的有用性，主要报告了MM-Food-100K子集的结果。"}
{"llm_update_time": "20250816", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.10490", "html_url": "https://arxiv.org/abs/2508.10490", "title": "基于梯度的解释的复杂度-忠实度权衡", "title_en": "On the Complexity-Faithfulness Trade-off of Gradient-Based Explanations", "authors": "Amir Mehrpanah,Matteo Gamba,Kevin Smith,Hossein Azizpour", "background": "ReLU网络在视觉数据中广泛应用，但由于其尖锐的过渡和依赖个别像素进行预测的特性，导致梯度基础的解释结果噪声较大且难以解释。现有的方法，如GradCAM，通过生成替代模型来平滑这些解释，但会牺牲忠实度。", "innovation": "提出了一个统一的谱框架，系统分析和量化平滑度、忠实度及其在解释中的权衡。该框架量化并正则化ReLU网络对高频信息的贡献，提供了一种识别权衡的原理性方法。通过对基于替代模型的平滑进行分析，明确了“解释差距”，并在不同设计选择、数据集和消融实验中验证了理论发现。", "conclusion": "该分析揭示了基于替代模型的平滑如何扭曲解释，定义并测量了不同事后方法的“解释差距”。最终，研究结果在不同的设计选择、数据集和消融实验中得到了验证。"}
{"llm_update_time": "20250816", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.10433", "html_url": "https://arxiv.org/abs/2508.10433", "title": "We-Math 2.0：一种激励视觉数学推理的多功能MathBook系统", "title_en": "We-Math 2.0: A Versatile MathBook System for Incentivizing Visual Mathematical Reasoning", "authors": "Runqi Qiao,Qiuna Tan,Peiqing Yang,Yanzi Wang,Xiaowan Wang,Enhui Wan,Sitong Zhou,Guanting Dong,Yuchen Zeng,Yida Xu,Jie Wang,Chong Sun,Chen Li,Honggang Zhang", "background": "多模态大型语言模型（MLLMs）在许多任务上展示了令人印象深刻的能力，但仍面临复杂数学推理方面的挑战。现有研究主要集中在数据集构建和方法优化上，经常忽视两个关键方面：全面的知识驱动设计和以模型为中心的数据空间建模。", "innovation": "本文介绍了一种统一的We-Math 2.0系统，该系统结合了结构化的数学知识系统、以模型为中心的数据空间建模和基于强化学习（RL）的训练范式，以全面增强MLLMs的数学推理能力。We-Math 2.0的关键贡献包括四个方面：一是构建了一个涵盖491个知识点和1,819个基础原理的五个层级的MathBook知识系统；二是开发了MathBook-Standard和MathBook-Pro两个数据集，分别确保广泛的概念覆盖和灵活性，以及建立了一个三维难度空间和渐进难度级别的问题；三是提出了一个两阶段的RL框架，包括冷启动微调和渐进对齐RL；四是引入了一个涵盖所有491个知识点的综合基准测试。", "conclusion": "实验结果表明，We-Math-RL在四个广泛使用的基准测试上表现与现有基线竞争，并在MathBookEval上取得了很好的结果，表明其在数学推理方面的泛化能力强。"}
{"llm_update_time": "20250816", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.10745", "html_url": "https://arxiv.org/abs/2508.10745", "title": "Agentic Design Review System", "title_en": "Agentic Design Review System", "authors": "Sayan Nag,K J Joseph,Koustava Goswami,Vlad I Morariu,Balaji Vasan Srinivasan", "background": "评估图形设计需要从对齐、构成、美学和色彩选择等多个方面进行评估。全景式的评估设计需要从各个专家评审者的反馈中进行聚合。为了这项工作，本文提出了一个代理设计审查系统（AgenticDRS），其中多个代理共同分析设计，由一个元代理协调。", "innovation": "该系统的核心创新在于使用基于图匹配的上下文相关示例选择方法和独特的提示扩展方法，使得每个代理都能了解设计方案。同时，还提出了一套AgenticDRS评估基准（DRS-BENCH）。在最先进的基线下进行了全面的实验评估，并通过关键的消融实验证明了AgenticDRS在评估图形设计和生成可操作反馈方面的有效性。", "conclusion": "希望这项工作能够引起对这一实用且尚未充分探索的研究方向的关注。"}
{"llm_update_time": "20250816", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.10595", "html_url": "https://arxiv.org/abs/2508.10595", "title": "基于梯度的解释方法的谱性质", "title_en": "On Spectral Properties of Gradient-based Explanation Methods", "authors": "Amir Mehrpanah,Erik Englesson,Hossein Azizpour", "background": "深入理解深度网络的行为对于增加我们对其结果的信心至关重要。尽管有大量的工作致力于解释其预测，但研究人员面临可靠性问题，这些问题可以归因于正式机制的不足。研究中发现，从梯度使用中产生了普遍的谱偏见，同时也揭示了一些实验上发现的常见设计选择，特别是平方梯度和输入扰动的使用.", "innovation": "本文采用新颖的概率和谱分析视角正式分析了解释方法。论文展示了由梯度使用引起的普遍谱偏见，并解释了一些已实验发现的常见设计选择，基于提出的正式方法，进一步探讨了扰动超参数对解释方法选择的影响，提出了两种改进措施：（i）一种确定标准扰动尺度的机制；（ii）一种称为SpectralLens的聚合方法。并通过实证评估证实了理论结果.", "conclusion": "研究表明，选择适当的扰动超参数对于不同解释方法的一致性至关重要。提出的SpectralLens聚合方法为其提供了克服现有解释方法差异的途径。"}
{"llm_update_time": "20250816", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.10797", "html_url": "https://arxiv.org/abs/2508.10797", "title": "专家意见不一致：DSA图像中血管分割标注者一致性表征", "title_en": "When Experts Disagree: Characterizing Annotator Variability for Vessel Segmentation in DSA Images", "authors": "M. Geshvadi,G. So,D.D. Chlorogiannis,C. Galvin,E. Torio,A. Azimi,Y. Tachie-Baffour,N. Haouchine,A. Golby,M. Vangel,W.M. Wells,Y. Epelboym,R. Du,F. Durupinar,S. Frisken", "background": "本文旨在分析在2D DSA（数字减影血管造影）图像中，由多名标注者对颅内血管分割结果的差异性，以表征和量化分割不确定性。这是在医学成像领域中一个重要的研究问题，特别是在需要高度精确性的血管分割任务中，标注者的主观差异可能显著影响结果的可靠性。", "innovation": "本文提出了一种通过分析标注者间的差异来量化分割不确定性的方法，并探讨了如何利用这些信息来指导额外的标注工作，以及开发能够理解不确定性并将其纳入考量的自动分割方法。这种方法创新之处在于它不仅指出了不确定性存在的必要性，还提供了一套操作方案。", "conclusion": "本文通过分析不同专家对同一2D DSA图像中血管分割的一致性，得出了不同标注者之间存在相当大的差异性，并依据这些发现提出了指导额外标注和开发不确定性意识自动分割方法的策略。这些结果对于提高医学影像分析的可靠性和精确度具有重要意义。"}
{"llm_update_time": "20250816", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.10649", "html_url": "https://arxiv.org/abs/2508.10649", "title": "地理差分用于土地覆盖透水性变化预测", "title_en": "Geospatial Diffusion for Land Cover Imperviousness Change Forecasting", "authors": "Debvrat Varshney,Vibhas Vats,Bhartendu Pandey,Christa Brelsford,Philipe Dias", "background": "土地覆盖（当前和未来），对地球系统过程有显著影响。例如，不可渗透表面会使地表水径流加速、增加，减少地下水渗透，从而影响区域水文和洪灾风险。虽然区域地球系统模型在气候情景下的高分辨率预测水分和大气过程方面能力增强，但对于土地利用和土地覆盖变化（LULC）的预测能力仍然滞后，这直接影响了风险评估和后果分析。", "innovation": "本文提出了一种新的范式，利用生成型人工智能（GenAI）进行基于历史数据和辅助数据源的土地覆盖变化预测。讨论了生成模型的期望属性，证明了该方法在利用扩散模型进行全美国领土土地透水性预测方面的可行性。相比完全不变的基准模型，评估结果显示，在大于0.7×0.7km²的分辨率下，该模型的平均绝对误差低于基准模型，表明生成模型可以从历史数据中捕捉到重要的时空模式，用于预测未来变化。", "conclusion": "本文通过实验展示了一种新的基于生成型人工智能的土地利用和土地覆盖变化预测方法的有效性，并讨论了未来研究方向，即整合地球物理属性信息，以及通过驱动变量模拟不同情景的支持性模拟。"}
{"llm_update_time": "20250816", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.10416", "html_url": "https://arxiv.org/abs/2508.10416", "title": "CorrectNav: 自校正飞轮赋能视觉语言动作导航模型", "title_en": "CorrectNav: Self-Correction Flywheel Empowers Vision-Language-Action Navigation Model", "authors": "Zhuoyuan Yu,Yuxing Long,Zihan Yang,Chengyan Zeng,Hongwei Fan,Jiyao Zhang,Hao Dong", "background": "现有的视觉-语言导航模型在执行指令时往往会偏离正确的轨迹，但这些模型缺乏有效的错误修正能力，限制了它们从错误中恢复的能力。现有的视觉-语言导航模型在执行指令时容易出现偏差，这主要是由于模型缺乏有效的错误校正机制，导致无法从错误中恢复，直接影响了模型的准确性和鲁棒性。", "innovation": "提出了自校正飞轮（Self-correction Flywheel），这是一种新颖的后训练范式。不同于将模型在训练集上的错误轨迹视为缺陷，该范式强调其重要性作为宝贵的数据源。开发了一种方法来识别错误轨迹中的偏差，并设计了自动生成感知与行动自我纠正数据的技术。这些自我纠正数据作为燃料，支持模型的持续训练。通过重新评估模型并在训练集上发现新的错误轨迹，自校正飞轮开始运行。经过多次飞轮迭代，逐步提升基于单目RGB的VLA导航模型CorrectNav。在R2R-CE和RxR-CE基准测试中，CorrectNav达到了新的最先进的成功率65.1%和69.3%，分别比先前最好的VLA导航模型高出8.2%和16.4%。户外环境中的机器人实验表明，该方法在错误修正、动态障碍物规避和长时间指令跟随方面表现更优。", "conclusion": "通过自校正飞轮不断迭代，CorrectNav模型在视觉-语言-动作导航方面显著提高了成功率和表现，特别是在错误修正、动态障碍物规避和长时间指令跟随方面表现出色。"}
{"llm_update_time": "20250816", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.10605", "html_url": "https://arxiv.org/abs/2508.10605", "title": "DIVA-VQA: 检测用户生成视频质量中的帧间差异", "title_en": "DIVA-VQA: Detecting Inter-frame Variations in UGC Video Quality", "authors": "Xinyi Wang,Angeliki Katsenou,David Bull", "background": "用户生成的视频内容（UGC）的快速增长推动了无参考（NR）感知视频质量评估（VQA）的研究需求。在缺乏原始参考视频的情况下，无参考视频质量评估是社交媒体和流媒体应用中大规模视频质量监控的关键组成部分。现有模型常常无法有效提取和利用帧间差异以进行高质量感知分析，尤其是在处理复杂的时空变化时。此前的研究大多侧重于单一层次的帧或残差分析，未能充分捕捉全局和局部信息。因此，现有方法在质量评估上仍存在一定局限性，尤其是在实时应用中性能不足与高效性之间的矛盾亟待解决。", "innovation": "该论文提出了一种基于帧间变异引导的时空碎片化的新颖无参考视频质量评估（NR-VQA）模型（DIVA-VQA）。该模型通过利用帧间差异逐层分析质量敏感区域，包括帧、块和碎片化帧，并将帧、碎片化残差和对齐残差的碎片化帧整合以有效捕获全局和局部信息。此外，该模型从二维和三维特征中提取信息，以描述时空变化。实验结果显示，该方法在5个UGC数据集上的平均排名相关性达到较新模型的顶级水平，且以较低的运行时复杂度实现了优于现有最快NR-VQA方法的性能。提供的代码和模型可通过提供的链接访问，确保了其广泛应用的可能性。", "conclusion": "该研究开发的 DIVA-VQA 模型展示了其在无参考视频质量评估中的显著优势，尤其在分析用户生成视频的帧间差异方面。其方法能够在保留高质量评估的同时，显著降低时间复杂性。研究表明，DIVA-VQA 在评估 UGC 视频质量上的表现优于现有方法，特别是在对实时性和高效性有高要求的应用领域。"}
{"llm_update_time": "20250816", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2310.19583", "html_url": "https://arxiv.org/abs/2310.19583", "title": "GC-MVSNet: 多视角、多尺度、几何一致性的多视图立体恢复", "title_en": "GC-MVSNet: Multi-View, Multi-Scale, Geometrically-Consistent Multi-View Stereo", "authors": "Vibhas K. Vats,Sripad Joshi,David J. Crandall,Md. Alimoor Reza,Soon-heung Jung", "background": "传统的多视图立体恢复（MVS）方法依赖于光度和几何一致性约束，而基于机器学习的新方法则将几何一致性检查仅作为后处理步骤的一部分。现有的MVS方法在学习过程中未能明确地考虑到多个源视图中参考视角深度图的几何一致性。", "innovation": "本文提出了一种新的方法，在学习过程中明确地在不同尺度下鼓励多个源视图中参考视图深度图的几何一致性（见图1）。通过引入几何一致性损失，该方法能够显式地惩罚几何不一致的像素，从而显著加速学习过程，将训练迭代次数 nearly 半减少。", "conclusion": "我们的广泛实验表明，我们的方法在DTU和BlendedMVS数据集上达到了新的SOTA性能，在Tanks and Temples基准上也取得了具有竞争力的结果。据我们所知，GC-MVSNet 是第一个在学习过程中强制执行多视角和多尺度几何一致性的尝试。"}
{"llm_update_time": "20250816", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.10784", "html_url": "https://arxiv.org/abs/2508.10784", "title": "Algonauts 2025获胜者的见解", "title_en": "Insights from the Algonauts 2025 Winners", "authors": "Paul S. Scotti,Mihir Tripathy", "background": "Algonauts 2025挑战是一项每两年举行一次的计算神经科学竞赛，团队尝试构建能够从精心筛选的刺激中预测人类脑活动的模型。此前的几届比赛（2019年、2021年和2023年）主要集中在静态图像和简短视频上。2025年的挑战则将范围扩大到了更长且多模态的电影片段。在此次挑战中，数据集包括近80小时的自然场面影视刺激，用于预测四名参与者观看影视内容时的大脑活动。这些数据来自CNeuroMod项目，包含了65小时的训练数据，还有Friends的前6季和四部电影（《追捕》，《隐藏人物》，《生命》，《华尔街之狼》）作为补充。剩余的数据用于验证，包括Friends第七季作为分布内测试数据，以及未公开的数据作为分布外测试数据，用于评定挑战的结果。所有的获胜结果和最佳报告现已公布。MedARC团队作为第四名参赛者，对此次挑战的策略进行反思，揭示当前大脑编码的状态，并展望未来的研究方向。", "innovation": "该挑战的主要创新在于使用了更长且包含多模态信息的电影片段作为刺激，这相较于以往的比赛呈现了更复杂和真实的大脑活动预测场景。挑战数据集不仅有经典影视作品，还包括自然场景，使得模型不仅能够预测静态和简短视频的数据，还要能够处理长期且包含多种视觉和听觉信息的复杂刺激。这种扩展测试了模型在面对更复杂和多变的背景时的表现，帮助研究人员更好地了解大脑对不同类型的刺激的反应机制。", "conclusion": "MedARC团队通过对Algonauts 2025挑战结果的分析，总结了当前大脑编码状态的主要特点，如模型在处理复杂且长期的影视刺激时的表现，以及如何更好地理解大脑对不同类型的刺激的反应。同时，挑战也揭示了未来研究的方向，特别是在多模态刺激下的大脑活动预测以及在实际应用场景中的应用。"}
{"llm_update_time": "20250816", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2411.06869", "html_url": "https://arxiv.org/abs/2411.06869", "title": "CapeLLM：使用多模态大语言模型的无支持类别无关姿态估计", "title_en": "CapeLLM: Support-Free Category-Agnostic Pose Estimation with Multimodal Large Language Models", "authors": "Junho Kim,Hyungjin Chung,Byung-Hoon Kim", "background": "传统类别无关姿态估计（CAPE）依赖于带有标注关键点的支持图像，这一过程往往繁琐且可能无法充分捕捉不同类别对象之间的对应关系。近期研究尝试使用文本查询，利用其增强的稳定性和泛化能力。然而，现有方法仍然受限于对支持查询的依赖，未能充分利用预训练大语言模型中嵌入的丰富先验知识，并且受到其参数分布假设的限制。", "innovation": "我们引入了CapeLLM，这是一个专为CAPE设计的第一个多模态大语言模型（MLLM）。该方法仅使用查询图像和详细的文本描述作为输入来估计类别无关的关键点。我们的方法包括有效的训练策略和细心设计的指令，以利用MLLM进行CAPE。此外，我们提出了一个推理机制，进一步增强对未知关键点的推理过程。该机制灵活地建模了它们的潜在空间分布和不确定性，允许基于上下文线索进行适应性细化。我们在广泛实验中展示了将MLLM应用于CAPE的有效性，不仅关注模型架构和提示设计，还确保了在输入变化下的鲁棒性。我们的方法在MP-100基准测试中的1-shot和5-shot设置下达到了新的最佳性能，标志着类别无关姿态估计领域的重要进步。", "conclusion": "我们的方法在MP-100基准测试中达到了新的最佳性能，在1-shot和5-shot设置下，CapeLLM标志着类无关姿态估计领域的重大进步，同时我们的代码也已可用。"}
{"llm_update_time": "20250816", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2403.05262", "html_url": "https://arxiv.org/abs/2403.05262", "title": "通过惩罚语言先验来纠偏多模态大型语言模型", "title_en": "Debiasing Multimodal Large Language Models via Penalization of Language Priors", "authors": "YiFan Zhang,Yang Shi,Weichen Yu,Qingsong Wen,Xue Wang,Wenjing Yang,Zhang Zhang,Liang Wang,Rong Jin", "background": "在计算机视觉和自然语言处理领域，多模态大型语言模型（MLLMs）已成为不可或缺的工具，能够基于视觉输入生成文本响应。然而，我们的研究表明，这些模型生成的内容往往受到底层大型语言模型（LLMs）固有先验的影响，而不仅仅是基于输入的图像内容。实验证实，即使在缺乏相关图像或提供不一致的视觉输入时，MLLMs也会提供自信的回答，显示出偏见的存在。", "innovation": "为了纠正这些偏见并使模型关注视觉信息，我们提出两种简单的、无需训练的策略。首先，对于如分类或多选题回答之类的任务，我们引入了“事后去偏”方法，通过仿射校准步骤调整输出分布。其次，对于有更多复杂度的开放生成任务，我们提出结合图像对和无意义图像的“视觉去偏解码”，通过对比条件下的标记对数概率来减轻偏差。此外，研究还揭示了MLLMs在不同解码配置下的不稳定现象，并通过系统地探索不同的设置获得了显著的性能提升，引发了对当前评估实践公平性的担忧。", "conclusion": "全面的实验证明了我们提出策略的有效性，这些策略不仅有助于减少虚构内容，还促进了更准确和有用的图像生成。"}
{"llm_update_time": "20250816", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2401.05202", "html_url": "https://arxiv.org/abs/2401.05202", "title": "使用姿态估计和多种运动特征进行奶牛跛行的视频自动检测", "title_en": "Video-based automatic lameness detection of dairy cows using pose estimation and multiple locomotion traits", "authors": "Helena Russello,Rik van der Tol,Menno Holzhauer,Eldert J. van Henten,Gert Kootstra", "background": "本文介绍了一种自动化跛行检测系统，该系统运用深度学习图像处理技术提取与跛行相关的多种运动特征。该研究使用T-LEAP姿态估计模型从户外、不同照明条件下的行走奶牛视频中提取九个关键点的运动。通过关键点轨迹计算出了六个运动特征：背部姿态测量、头部摇摆、追踪距离、步长、站立时间和摆动时间。研究结果表明，包括多种运动特征可以显著提高分类准确性，从单一特征的76.6%提升到三个最主要特征的79.9%，以及所有六个特征的80.1%。同时，合理合并观察者的评分可以提高观察者间的一致性和可靠性。", "innovation": "该研究通过使用T-LEAP姿态估计模型从行走奶牛的视频中自动化提取多种运动特征，包括背部姿态测量、头部摇摆、追踪距离、步长、站立时间和摆动时间，从而实现了对奶牛跛行的准确检测。此方法能够大幅提高自动化的准确性和可靠性，为奶牛的健康管理和预防疾病提供有力支持。", "conclusion": "该研究表明，结合多种运动特征和合理合并观察者的评分能够显著提高奶牛跛行检测的准确性和可靠性。通过使用T-LEAP姿态估计模型从行走奶牛的视频中自动化提取多种运动特征，可以实现对奶牛健康状况的准确评估，为奶牛养殖场提供了一种有效的方法来监测和管理牛只的健康状况。"}
{"llm_update_time": "20250816", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2411.14521", "html_url": "https://arxiv.org/abs/2411.14521", "title": "我的时间机器：个性化面部年龄变换", "title_en": "MyTimeMachine: Personalized Facial Age Transformation", "authors": "Luchao Qi,Jiaye Wu,Bang Gong,Annie N. Wang,David W. Jacobs,Roni Sengupta", "background": "面部老化是一个复杂的过程，高度依赖于性别、种族、生活方式等多种因素，这使得学习一个适用于所有人的全局老化先验变得极其困难。现有技术可以生成逼真且可信的老化结果，但重构的图像往往不能准确反映目标年龄的外貌，因此需要个性化处理。在虚拟老化应用中，如电影和电视节目的特效制作，用户的个人照片集包含在一个小的时间范围内（20-40年）的衰老情况。然而，直接将全局老化技术个性化处理在个人照片集中往往失败，因此提出了一种结合全局老化先验和少量个人照片（最少50张）的学习个性化年龄变换的方法，以实现更加逼真的老化效果，且能保持个体身份一致性并符合实际老化表现.", "innovation": "提出了MyTimeMachine (MyTM)，这是一个结合全局老化先验和少量个人照片（最少50张）的方法，通过自适应网络（Adapter Network）结合个性化和全局老化特征，生成高质量、身份保留、有时间一致性老化效果的图像。配套引入了三种损失函数分别用于个性化衰老损失、外推正则化和自适应w-范正则化，显著优于现有技术.", "conclusion": "MyTimeMachine在视频中也得到应用，实现了高质量、身份保留和时间一致性的个性化老化效果，证明了其在实际老化表现方面的优越性."}
{"llm_update_time": "20250816", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2412.00578", "html_url": "https://arxiv.org/abs/2412.00578", "title": "Speedy-Splat：稀疏像素与稀疏原语实现快速3D高斯绘制", "title_en": "Speedy-Splat: Fast 3D Gaussian Splatting with Sparse Pixels and Sparse Primitives", "authors": "Alex Hanson,Allen Tu,Geng Lin,Vasu Singla,Matthias Zwicker,Tom Goldstein", "background": "3D Gaussian Splatting (3D-GS) 是一种最近的3D场景重建技术，允许通过参数点云模型化场景为可微分3D高斯来在新型视图上进行实时渲染。然而，这种方法的渲染速度和模型大小仍然存在瓶颈，尤其是在资源受限的环境中。", "innovation": "本文识别并解决了3D-GS中的两个关键效率问题，显著提高了渲染速度。这些改进还带来了模型大小和训练时间的次要益处。首先，优化渲染管道以精确定位场景中的高斯，提高渲染速度而不影响视觉保真度。其次，引入了一种新颖的剪枝技术，并将其整合到训练管道中，显著减少了模型大小、训练时间和进一步提高了渲染速度。Speedy-Splat方法结合了这些技术，使场景的平均渲染速度在Mip-NeRF 360、Tanks & Temples和Deep Blending数据集上提高了6.71倍。", "conclusion": "Speedy-Splat方法通过优化3D-GS的渲染管道和引入稀疏像素与稀疏原语相结合的技术，大幅提升了3D场景的渲染速度，并减少了模型大小和训练时间。"}
{"llm_update_time": "20250816", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2412.06293", "html_url": "https://arxiv.org/abs/2412.06293", "title": "掌握协作多模态数据选择：关注信息性、独特性和代表性", "title_en": "Mastering Collaborative Multi-modal Data Selection: A Focus on Informativeness, Uniqueness, and Representativeness", "authors": "Qifan Yu,Zhebei Shen,Zhongqi Yue,Yang Wu,Bosheng Qin,Wenqiao Zhang,Yunfei Li,Juncheng Li,Siliang Tang,Yueting Zhuang", "background": "多模态大型语言模型（MLLMs）通过指令调整（Instruction tuning）进行微调，以处理实际任务。然而，视觉指令数据集的快速增长导致了数据冗余，增加了计算成本。", "innovation": "提出了一个名为DataTailor的协作框架，该框架利用信息性、独特性和代表性三个原则进行有效数据筛选。提出了每种原则的评分方法，实现自动适应特定数据集，无需繁琐的超参数调整。", "conclusion": "在各种基准上的全面实验表明，DataTailor仅使用15%的数据，就能达到101.3%的全数据细调性能，显著降低计算成本并保持优越的结果，体现了多模态语言模型开发的“更少即是更多”理念。代码和数据可在提供的URL中访问。"}
{"llm_update_time": "20250816", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2412.02287", "html_url": "https://arxiv.org/abs/2412.02287", "title": "通过结构特征和CLIP指导提高三维生成中的视角一致性", "title_en": "Improving Viewpoint Consistency in 3D Generation via Structure Feature and CLIP Guidance", "authors": "Qing Zhang,Jinguang Tong,Jing Zhang,Jie Hong,Xuesong Li", "background": "尽管近年来在文本到3D生成技术方面取得了进展，但当前的方法往往存在几何不一致的问题，通常被称为“Janus问题”。研究表明，这一问题的根本原因是扩散模型中的视角生成偏见，这导致生成的视角与优化3D模型所需的实际视角之间存在显著差距。", "innovation": "本文提出了一种无调优的解决方案——注意力和CLIP指导（ACG）机制。ACG通过自适应控制注意力图增强所需的视角，利用基于CLIP的观点-文本相似度过滤错误的视角，并采用逐步提示的粗到细优化策略逐步细化3D生成。实验结果表明，该方法显著减少了Janus问题，同时没有牺牲生成速度，表明ACG是一个高效的、开箱即用的组件，可应用于现有的文本到3D框架中。", "conclusion": "本研究通过ACG机制有效解决了3D生成中的视角一致性问题，不仅降低了Janus问题，还保持了生成效率，为现有的文本到3D框架提供了一个即插即用的改进方案。"}
{"llm_update_time": "20250816", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2412.03910", "html_url": "https://arxiv.org/abs/2412.03910", "title": "DGNS: 变形高斯点绘和动态神经表面在单目动态三维重建中的应用", "title_en": "DGNS: Deformable Gaussian Splatting and Dynamic Neural Surface for Monocular Dynamic 3D Reconstruction", "authors": "Xuesong Li,Jinguang Tong,Jie Hong,Vivien Rolland,Lars Petersson", "background": "单目视频的动态场景重建对于实际应用至关重要。", "innovation": "提出了DGNS，融合了变形高斯点绘和动态神经表面技术，同时有效地解决了动态新颖视角合成和三维几何重建的问题。深度图生成模块引导光线采样以加速处理，并在动态神经表面模块中提供深度监督以提高几何重建效果。动态神经表面则指导高斯原语的分布，提高渲染质量。此外，还提出了一种深度过滤方法以进一步细化深度监督。", "conclusion": "在公开数据集上进行了广泛实验，表明DGNS在三维重建方面达到了最先进的性能，并且在新颖视角合成方面取得了竞争力的结果。"}
{"llm_update_time": "20250816", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2408.03551", "html_url": "https://arxiv.org/abs/2408.03551", "title": "VPOcc: 利用消失点进行3D语义占用预测", "title_en": "VPOcc: Exploiting Vanishing Point for 3D Semantic Occupancy Prediction", "authors": "Junsu Kim,Junhee Lee,Ukcheol Shin,Jean Oh,Kyungdon Joo", "background": "理解和分析三维场景对于机器人和自动驾驶车辆的安全导航至关重要，有助于避免障碍物和准确的路径规划。基于相机的3D语义占用率预测，能够从2D图像推断出完整的体素网格，相较于3D传感器更节省资源，但该任务受到2D-3D视角差异的影响，因为因为透视投影，相机距离不同物体的距离会改变其在2D图像中的大小。为了克服这个问题，本文提出了一种名为VPOcc的新框架，该框架利用消失点（VP）在像素级和特征级上减少2D-3D视角差异。作为像素级解决方案，引入了VPZoomer模块，该模块通过基于VP的基本仿射变换反向抵消透视效果。作为特征级解决方案，提出了基于VP的跨注意力（VPCA）模块，进行透视感知的特征聚合，利用更适合3D空间的2D图像特征。最后，通过空间体素融合（SVF）模块整合来自原始图像和变形图像的两个特征体积，通过补偿互补提高特征的有效性。现有实验证明，该框架在SemanticKITTI和SSCBench-KITTI360数据集上的IoU和mIoU指标均有所提升。项目详情可参考：this https URL", "innovation": "本文创新性地提出了VPOcc框架，在网络中有效利用消失点（VP），在像素级和特征级上减少了2D-3D视角差异，并提出了VPZoomer模块和VPCA模块。通过整合来自原始图像和变形图像的特征体积，进一步提高了预测的准确性。该方法改善了IoU和mIoU指标，对于3D语义占用预测具有显著提升效果", "conclusion": "通过有效利用消失点（VP）的VPOcc框架，在Pixel级的VPZoomer模块和特征级的VPCA模块的帮助下，实现了2D-3D视角差异的有效减少。实验结果在SemanticKITTI和SSCBench-KITTI360数据集上的IoU和mIoU指标均有所提升，证明了该方法的有效性和应用前景。"}
{"llm_update_time": "20250816", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2409.11315", "html_url": "https://arxiv.org/abs/2409.11315", "title": "MinD-3D++: 基于fMRI的高质三维重建方法与全面数据集的进展", "title_en": "MinD-3D++: Advancing fMRI-Based 3D Reconstruction with High-Quality Textured Mesh Generation and a Comprehensive Dataset", "authors": "Jianxiong Gao,Yanwei Fu,Yuqian Fu,Yun Wang,Xuelin Qian,Jianfeng Feng", "background": "Recon3DMind 在认知神经科学和计算机视觉领域中通过从功能性磁共振成像（fMRI）数据中重建三维可视化，具有重要价值。为了进一步促进这一任务，提出了一组包括来自15名参与者的总共4,768个三维对象的数据集。该数据集由两个部分组成：之前介绍且可从...下载的fMRI-Shape，以及本文中引入并可从...下载的fMRI-Objaverse，后者包括来自5名参与者的不同对象类别和文本描述的数据，显著增加了数据的多样性和应用潜力。此外，还提出了MinD-3D++框架，用于从fMRI信号中解码具有详细纹理的三维视觉信息，首次实现了基于fMRI生成具有详细纹理的三维网格，其性能通过语义、结构和纹理层面的指标评估，并在不同分布中测试模型的有效性，分析了三维图像在脑回路中的贡献度。", "innovation": "提出了MinD-3D++框架，不仅能够从人类思维中重建三维对象，而且可以生成具有详细纹理的三维网格；建立了语义、结构和纹理层面的评价标准；实验表明MinD-3D++不仅能提供高语义和空间准确性的三维重建，还能深入了解人脑如何处理三维视觉信息；提出了全面的数据集fMRI-3D，该数据集包括fMRI-Shape（可用...下载）和fMRI-Objaverse（可用...下载），提供了大量不同类别的三维对象及文本描述。以增强三维模型在不同分布环境中的性能和解析成像结果的能力。", "conclusion": "实验结果显示，MinD-3D++不仅能够精确还原三维对象的语义和空间信息，还能深入揭示人类大脑如何处理三维视觉信息，为认知神经科学和计算机视觉领域的研究提供了新的方法和数据支持。"}
{"llm_update_time": "20250816", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2411.13378", "html_url": "https://arxiv.org/abs/2411.13378", "title": "Quantum-Brain: 由量子计算理论启发的神经网络方法用于视觉-大脑理解", "title_en": "Quantum-Brain: Quantum-Inspired Neural Network Approach to Vision-Brain Understanding", "authors": "Hoang-Quan Nguyen,Xuan-Bac Nguyen,Hugh Churchill,Arabinda Kumar Choudhary,Pawan Sinha,Samee U. Khan,Khoa Luu", "background": "现有的视觉-大脑理解的深度学习方法通常局限于传统的学习范式，缺乏学习大脑区域间连接性的能力。量子计算理论提供了设计深度学习模型的新范式。基于大脑信号中的连接性和量子计算中的纠缠特性，本文提出了一种新颖的Quantum-Brain方法，这是一种量子启发的神经网络，旨在解决视觉-大脑理解问题。该方法引入了Quantum-Inspired Voxel-Controlling模块、Phase-Shifting模块和Measurement-like Projection模块，分别计算脑区之间的连接性、校准脑信号值和将连接信息从希尔伯特空间投影到特征空间。", "innovation": "该研究提出了一种新颖的量子启发神经网络，即Quantum-Brain，通过引入Quantum-Inspired Voxel-Controlling模块、Phase-Shifting模块和Measurement-like Projection模块来解决视觉-大脑理解问题。这些模块分别用于计算脑区间的连接性、校准脑信号值以及将连接信息从希尔伯特空间投影到特征空间。该方法能够学习大脑功能磁共振成像（fMRI）体素之间的连接性，并增强从人类感知中获取的语义信息。实验结果展示了该方法在自然场景数据集基准测试中的优越性，其图像检索和脑检索任务的Top-1准确率分别为95.1%和95.6%，以及在fMRI到图像重建任务中高达95.3%的Inception分数。", "conclusion": "所提出的量子启发网络为利用量子计算理论解决视觉-大脑问题带来了潜在范式。"}
{"llm_update_time": "20250816", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2501.15119", "html_url": "https://arxiv.org/abs/2501.15119", "title": "利用运动估计提高Bayer域计算机视觉效率", "title_en": "Leveraging Motion Estimation for Efficient Bayer-Domain Computer Vision", "authors": "Haichao Wang,Xinyue Xi,Jiangtao Wen,Yuxing Han", "background": "现有的计算机视觉处理管道使用具有拜耳模式像素信息的图像传感器采集视觉信息，然后通过图像信号处理器（ISP）将拜耳像素数据转换为RGB，再通过视频卷积网络（VCN）逐帧处理。这些过程计算量大、耗能高且延迟长。", "innovation": "本文提出了一种新型框架，该框架消除了ISP并利用运动估计在拜耳域直接加速视频视觉任务。通过将滑动窗口运动估计集成到每一层卷积层中，实现预测和基于残差的细化，从而减少跨帧的冗余计算。此设计填补了块基运动估计与空间卷积之间的结构差距，使得处理更加准确和低成本。", "conclusion": "端到端的处理管道支持原始拜耳输入，并实现了超过70%的FLOPs减少，且在视频语义分割、深度估计和目标检测基准上，准确率下降很小。此框架适用于基于卷积的模型，并首次有效利用运动估计直接加速基于原始传感器数据的视频计算机视觉任务。"}
{"llm_update_time": "20250816", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2503.04376", "html_url": "https://arxiv.org/abs/2503.04376", "title": "MIDAS: 使用暗知识建模真实地面分布的领域自适应视差匹配", "title_en": "MIDAS: Modeling Ground-Truth Distributions with Dark Knowledge for Domain Generalized Stereo Matching", "authors": "Peng Xu,Zhiyu Xiang,Jingyun Fu,Tianyu Pu,Hanzhi Zhong,Eryun Liu", "background": "尽管在领域通用视差匹配方面已有显著进步，现有方法仍表现出从合成数据向真实数据迁移时的领域特定偏好，阻碍了其在复杂和多样化场景中的实际应用。", "innovation": "本文提出了一种方法，通过从预训练网络中提取亮度和不确定性信息，建模双边和非边地区的直观多模态地面真实分布。此外，通过网络集成并在拉普拉斯参数空间区分客观知识和偏差知识，最终将客观知识与原始视差标签共同建模成拉普拉斯混合模型，为视差网络训练提供精细监督。", "conclusion": "大量实验表明：（1）本方法具有通用性，能有效提高现有网络的泛化能力。（2）应用我们方法的PCWNet在KITTI 2015和2012数据集上实现了最先进的泛化性能。（3）相比于现有方法，我们在四个流行的现实世界数据集上均获得了全面排名的优势。"}
{"llm_update_time": "20250816", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2502.00372", "html_url": "https://arxiv.org/abs/2502.00372", "title": "NAVER: 一种带显式逻辑推理的神经符号组合自动机视觉接地方法", "title_en": "NAVER: A Neuro-Symbolic Compositional Automaton for Visual Grounding with Explicit Logic Reasoning", "authors": "Zhixi Cai,Fucai Ke,Simindokht Jahangard,Maria Garcia de la Banda,Reza Haffari,Peter J. Stuckey,Hamid Rezatofighi", "background": "视觉定位（VG）任务，例如指示表达检测和分割任务，对于将视觉实体与上下文联系起来非常重要，特别是在需要详细查询解释的复杂推理任务中。近年来，大型语言模型（LLMs）和视觉-语言模型（VLMs）的进步提高了视觉理解、上下文理解和推理的能力。尽管这些方法主要分为端到端和组合式方法，后者的灵活性更强。然而，组合式方法在以语言为基础的逻辑表示进行复杂推理方面仍然存在问题。因此，本文探讨了超越基本感知的VG技术，针对需要类人认知推理的方法突出了挑战。", "innovation": "本文提出了NAVER，一种组合式的视觉接地方法，该方法在有限状态自动机中结合了显式的概率逻辑推理，并配备了一个自我纠正机制。这种方法通过显式的逻辑推理提高了推理的鲁棒性和可解释性。实验结果表明，NAVER在与最近的端到端和组合式基线相比时，达到了最先进的性能。", "conclusion": "NAVER通过在有限状态自动机中结合显式逻辑推理，提高了视觉接地的鲁棒性和可解释性。实验表明，该方法在视觉地接地任务上达到了最先进的性能，能够解决复杂的基于语言逻辑表示的推理问题。"}
{"llm_update_time": "20250816", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2501.14317", "html_url": "https://arxiv.org/abs/2501.14317", "title": "Nautilus: 局域感知自编码器在可扩展网格生成中的应用", "title_en": "Nautilus: Locality-aware Autoencoder for Scalable Mesh Generation", "authors": "Yuxuan Wang,Xuanyu Yi,Haohan Weng,Qingshan Xu,Xiaokang Wei,Xianghui Yang,Chunchao Guo,Long Chen,Hanwang Zhang", "background": "三角网格是3D应用的基础，能够高效地进行修改和光栅化处理，同时保持与标准渲染管道的兼容性。然而，当前的自动网格生成方法通常依赖于中间表示，缺乏与网格表面质量一致的连续性。转换这些表示形式成网格会生成密集且次优的输出。尽管最近的自回归方法在直接建模网格顶点和面方面显示出潜力，但在面的数量、可扩展性和结构保真度方面存在限制。这些问题促使我们提出Nautilus，一种局域感知自编码器，利用流形网格的局域特性实现结构保真度和高效表示。", "innovation": "Nautilus引入了一种新颖的标记化算法，能够保持面的最近邻关系并通过对局部共享顶点和边来压缩序列长度，从而能够生成多达5,000个面的大规模网格。此外，该方法开发了双流点条件器，用多尺度几何指导确保全局一致性以及局部结构保真度。广泛的实验表明，Nautilus在保真度和可扩展性方面显著优于现有方法。", "conclusion": "Nautilus显著提升了网格生成的结构保真度和可扩展性，能够在大规模网格生成中有效发挥优势。"}
{"llm_update_time": "20250816", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2412.06534", "html_url": "https://arxiv.org/abs/2412.06534", "title": "通过反演理解基于Transformer的视觉模型", "title_en": "Understanding Transformer-based Vision Models through Inversion", "authors": "Jan Rathjens,Shirin Reyhanian,David Kappel,Laurenz Wiskott", "background": "在机器学习和计算机视觉中，理解深度神经网络的工作机制仍然是一个基本挑战。一种有前途但尚未充分探索的方法是特征反演，该方法尝试使用训练好的逆神经网络从中间表示重建图像。在本研究中，我们重新审视了特征反演，并提供了一种新颖的模块化变体，以使该技术的使用更为高效。我们展示了该方法如何在大规模的基于Transformer的视觉模型，如Detection Transformer和Vision Transformer中系统地应用，并如何以有意义的方式对重建图像进行定性解释。我们进一步对方法进行了定量评估，从而揭示了这两种Transformer架构中图像特征表示的潜在机制。我们的分析揭示了这些模型是如何编码上下文形状和图像详细信息的关键见解，各层之间的相关性及其对颜色扰动的鲁棒性。这些发现促进了对基于Transformer的视觉模型及其内部表示的更深层次理解。", "innovation": "本研究提出了一种新型模块化变体的特征反演，该方法在提高技术效率方面更为高效，能够系统地应用于大规模的基于Transformer的视觉模型，并通过定量评估揭示了这些模型中图像特征表示的潜在机制，深入理解了上下文形状、图像细节的编码方式及其各层间的相关性，以及对颜色扰动的鲁棒性。", "conclusion": "通过特征反演方法，我们更加深入地理解了基于Transformer的视觉模型及其内部表示。这种方法揭示了模型如何编码上下文形状和图像细节，以及各层之间的相关性，并展示了模型对颜色扰动的鲁棒性。我们还提供了实现实验的方法，以帮助进一步的研究。"}
{"llm_update_time": "20250816", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2503.08064", "html_url": "https://arxiv.org/abs/2503.08064", "title": "多模态连续学习", "title_en": "Continual Learning for Multiple Modalities", "authors": "Hyundong Jin,Eunwoo Kim", "background": "连续学习的目的是在顺序时间步骤中学习观察到的任务知识，同时减轻遗忘先前学习的知识。现有的方法设计时仅针对单一模态（例如图像）的学习，这限制了它们在涉及多模态场景中的应用。", "innovation": "本文提出了一种新颖的多模态连续学习框架，该框架能够处理多个模态（图像、视频、音频、深度和文本）。通过利用文本的丰富语义信息，使不同模态数据相互对齐。然而，这增加了模态间知识遗忘的风险，尤其是由于跨任务输入特征的不同。为了减轻模态间知识的覆盖，本文提出了一种框架，能够整合同一模态内的知识并融入相关跨模态信息。它通过自我调节学习表示的转变，逐步将新知识融入跨模态保留的信息中，同时通过根据各模态之间的相关性选择性地融合先前遇到的模态知识来减轻跨模态干扰。此外，还引入了一种模态嵌入重新对齐策略，有效解决了模态间偏差对齐问题。", "conclusion": "本文在不同模态的数据集上对提出的连续学习方法进行了广泛评估。实验结果表明，与现有方法相比，本文方法无论给定模态身份与否，在各种连续学习情境中都表现出更好的性能。"}
{"llm_update_time": "20250816", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2503.07516", "html_url": "https://arxiv.org/abs/2503.07516", "title": "Just Functioning as a Hook for Two-Stage Referring Multi-Object Tracking", "title_en": "Just Functioning as a Hook for Two-Stage Referring Multi-Object Tracking", "authors": "Weize Li,Yunhao Du,Qixiang Yin,Zhicheng Zhao,Fei Su,Daqi Liu", "background": "Referring Multi-Object Tracking (RMOT)旨在通过自然语言表达在视频中定位目标轨迹。尽管已经取得了进展，但RMOT中的跟踪和参照两个子任务之间的内在关系尚未充分研究。现有的两个阶段的Referring-by-Tracking (RBT)框架在子任务交互建模不足和依赖于如CLIP等固定的语义对齐模块方面仍存在根本限制。", "innovation": "本文提出了一种新颖的两个阶段的RBT框架——JustHook，其中首次设计了一个Hook模块来重新定义子任务之间的联系。Hook模块基于特征级别的网格采样建立，并用于上下文感知的目标特征提取。此外，提出了一种平行组合解码器（PCD），它在统一的联合特征空间中进行学习，而非依赖于预定义的跨模态嵌入。这些设计不仅增强了可解释性和模块性，还显著提高了泛化能力。实验结果表明，JustHook在多个数据集上取得了最先进的性能，提高了HOTA得分6.9%。", "conclusion": "在Refer-KITTI、Refer-KITTI-V2和Refer-Dance等数据集上的广泛实验表明，JustHook实现了最先进的性能，在Refer-KITTI-V2上HOTA提高了6.9%，并且具有更高的效率。代码将在不久的将来公开。"}
{"llm_update_time": "20250816", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2504.03096", "html_url": "https://arxiv.org/abs/2504.03096", "title": "扩展开放词汇动作检测", "title_en": "Scaling Open-Vocabulary Action Detection", "authors": "Zhen Hao Sia,Yogesh Singh Rawat", "background": "现有的动作检测方法大多局限于封闭集场景，并依赖复杂的、参数量大的架构。扩展这些模型到开放词汇设置会遇到两个关键挑战：一是缺乏包含大量动作类别的大规模数据集，二是为了使用预训练的视图-语言对比模型进行动作检测，需要进行参数密集型调整，这可能导致对基础动作类别的非预训练参数的过度拟合。", "innovation": "该研究提出了一种仅编码器的多模态模型用于视频动作检测，减少了对参数密集型添加的依赖。同时，提出了一种简单的弱监督训练策略，充分利用现有的封闭集动作检测数据集进行预训练。另外，研究者设计了一个新的基准测试，以评估现有的封闭集动作检测数据集上的表现，而无需使用这些数据集进行训练，这为未来的研究提供了新的基线成果。", "conclusion": "该研究展示了新的基线结果，并提出了一个新的评估基准，该基准能够独立于训练集对现有的封闭集动作检测数据集进行评估。研究的代码可在https://... 处获得。"}
{"llm_update_time": "20250816", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2504.04801", "html_url": "https://arxiv.org/abs/2504.04801", "title": "OrderChain：提高MLLMs的顺序理解能力的一般指令调优方法", "title_en": "OrderChain: Towards General Instruct-Tuning for Stimulating the Ordinal Understanding Ability of MLLM", "authors": "Jinhong Wang,Shuo Tong,Jian liu,Dongqi Tang,Weiqiang Wang,Wentong Li,Hongxia Xu,Danny Chen,Jintai Chen,Jian Wu", "background": "尽管多模态大型语言模型（MLLMs）取得了显著进展，但在顺序回归（OR；又称顺序分类）任务上的竞争力仍然有限。", "innovation": "OrderChain是一种新颖且通用的提示范式，通过特定性和共通性建模来提升MLLMs对顺序的理解能力。具体而言，OrderChain包括一组任务感知的提示，以促进多样的OR任务的特定性建模，并引入了一种新的范围优化Chain-of-Thought（RO-CoT），该方法通过统一将OR任务分解为多个小范围优化子任务来学习关于OR任务的共通性思维方式。此外，提出了类别递归划分（CRD）方法以生成指令候选类别提示，以支持RO-CoT的自动优化。", "conclusion": "综合实验表明，OrderChain显著提升了LLaVA模型在各种OR数据集上的表现，例如，在年龄估计的Adience数据集上的准确率从47.5%提高到93.2%，在糖尿病视网膜病变数据集上的准确率从30.0%提高到85.7%。值得注意的是，与现有最佳方法相比，在Adience数据集上，OrderChain在准确率和MAE方面分别提高了27%和0.24%。据我们所知，这是首次通过将MLLMs用于OR任务增强的方法，其效果在多种OR数据集上得到了验证。"}
{"llm_update_time": "20250816", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2504.21706", "html_url": "https://arxiv.org/abs/2504.21706", "title": "视觉变压器在精准农业中的全面综述", "title_en": "Vision Transformers in Precision Agriculture: A Comprehensive Survey", "authors": "Saber Mehdipour,Seyed Abolghasem Mirroshandel,Seyed Amirhossein Tabatabaei", "background": "检测植物疾病是现代农业中的关键方面，因为它在维持作物健康和增加总体产量方面起着重要作用。传统的办法虽然仍然有价值，但往往依赖于手动检查或传统的机器学习技术，这些方法在规模性和准确性方面都存在局限性。最近，视觉变换器（ViTs）作为有潜力的替代方案已经出现，它们提供了诸如处理长期依赖性改进和更好的视觉任务可扩展性等优势。这篇综述探讨了ViTs在精准农业中的应用，涵盖了各种任务。", "innovation": "文章介绍了视觉变换器的基本架构，并讨论了它们从自然语言处理到计算机视觉的过渡。文章还介绍了卷积神经网络等传统模型中的归纳偏差概念，并讨论了视觉变换器如何减轻这些偏差。文章提供了最近文献的全面回顾，重点关注关键方法、数据集和性能指标，并进行卷积神经网络与视觉变换器的比较分析。同时，还回顾了混合模型及其性能提升，并讨论了技术挑战及其解决方案。文章指出了未来研究方向和技术创新，这些将有助于进一步将视觉变换器集成到真实世界的农业环境中。", "conclusion": "本研究的目标是为从业者和研究人员提供深入理解，即视觉变换器如何准备对智能农业和精准农业实施变革。"}
{"llm_update_time": "20250816", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2504.15485", "html_url": "https://arxiv.org/abs/2504.15485", "title": "CAPTURe: 通过未见物体计数评估视觉语言模型的空间推理能力", "title_en": "CAPTURe: Evaluating Spatial Reasoning in Vision Language Models via Occluded Object Counting", "authors": "Atin Pothiraj,Elias Stengel-Eskin,Jaemin Cho,Mohit Bansal", "background": "识别和推理被遮挡的物体（部分或完全隐藏）对于理解视觉场景至关重要，因为现实生活中的遮挡情况经常发生，并且会阻碍对空间理解。为测试模型处理多个遮挡物体的能力，作者引入了一个名为Counting Amodally for Patterns Through Unseen REgions (CAPTURe) 的新任务。该任务要求模型通过推理遮挡物之后的图案来计数按特定模式排列的对象。CAPTURe 同时需要模式识别和推理，因此是一个评估视觉-语言模型对隐性模式的理解以及空间理解能力的有效测试平台。", "innovation": "引入了一个新的评估任务，CAPTURe，专门用于测试视觉-语言模型对隐性模式的理解和空间推理能力。CAPTURe 包括两个部分：一个使用手动筛选的真实物体图像的数据集 CAPTURe-real 和一个控制性诊断工具 CAPTURe-synthetic。通过CAPTURe，模型需要推理遮挡物之后的物体，并形成完整的场景模型，填补缺失信息。研究表明，尽管某些模型在不遮挡的情况下能够较好地处理模式计数任务，但是在遮挡情境下模型的表现明显下降，显示出模型在推理未见空间关系上的不足。", "conclusion": "人类在该任务中表现出极低的错误率，且提供遮挡物位置的辅助信息可以提升模型的表现。这表明模型的错误主要来自于处理遮挡和图像中计数的困难。最终得出结论，尽管当前的一些强大的视觉-语言模型在某些情况下可以处理模式任务，但在处理遮挡物体时仍有很大的改进空间。"}
{"llm_update_time": "20250816", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2505.08561", "html_url": "https://arxiv.org/abs/2505.08561", "title": "强化学习与遮掩视频建模的结合：基于轨迹的自适应令牌选择", "title_en": "Reinforcement Learning meets Masked Video Modeling : Trajectory-Guided Adaptive Token Selection", "authors": "Ayush K. Rai,Kyle Min,Tarun Krishna,Feiyan Hu,Alan F. Smeaton,Noel E. O'Connor", "background": "掩蔽视频建模（MVM）已成为视觉基础模型预训练的有效策略之一，通过建模视音频上下文，模型使用可见令牌的信息重建被遮掩的时空令牌。然而，选择合适的遮掩策略仍然是一个关键挑战。此前的研究探索了预定义的遮掩技术，包括随机和管状遮掩，以及利用关键运动先验、光学流和外部预训练模型的语义线索的方法。", "innovation": "本文提出了一种新颖且通用的轨迹感知自适应令牌选择器（TATS），它可以建模令牌的运动动态，并与掩蔽自编码器（MAE）框架无缝集成，以在视频中选择以运动为中心的令牌。此外，本文提出了一个统一的训练策略，利用 proximal 策略优化（PPO）从零开始同时优化 MAE 和 TATS。该模型在下游任务动作识别上的性能表明了它能够进行激进的遮掩训练，同时保持预训练的内存效率。", "conclusion": "在四个基准数据集（Something-Something v2，Kinetics-400，UCF101，HMDB51）上的 extensive 实验结果证明了本文方法的有效性、可迁移性、泛化能力和与现有先进方法相比的效率。"}
{"llm_update_time": "20250816", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2505.13219", "html_url": "https://arxiv.org/abs/2505.13219", "title": "PiT: 进步扩散变换器", "title_en": "PiT: Progressive Diffusion Transformer", "authors": "Jiafu Wu,Yabiao Wang,Jian Li,Jinlong Peng,Yun Cao,Chengjie Wang,Jiangning Zhang", "background": "扩散变换器（DiTs）利用变压器架构在图像生成任务中表现出色。传统的DiTs通过堆叠一系列等向的全局模型变压器构建，但这样会导致显著的二次计算成本。然而，经实证分析发现，DiTs对全局信息的依赖远不如之前认为的那样重要。大多数层中的全局计算表现出显著的冗余性。此外，传统的注意力机制存在低频依存问题，限制了它们的效率。", "innovation": "为了应对这些问题，作者提出了伪移动窗口注意力（PSWA），从根本上减少了全局注意冗余。PSWA通过窗口注意力实现适度的全局-局部信息组合，并利用高频桥梁分支模拟移动窗口操作，从而增加高频信息并增强窗口间连接。此外，作者提出了一种渐进覆盖通道分配（PCCA）策略，能够在不增加计算成本的情况下捕捉高阶注意力。", "conclusion": "基于这些创新，作者提出了一系列伪渐进扩散变换器（PiT）。广泛实验表明，PiT表现出优越的性能；例如，PiT-L在FID指标上较DiT-XL/2提高了54%，且计算成本更低。"}
{"llm_update_time": "20250816", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2412.04464", "html_url": "https://arxiv.org/abs/2412.04464", "title": "DualPM: 双姿势-标准点图用于3D形状和姿态重建", "title_en": "DualPM: Dual Posed-Canonical Point Maps for 3D Shape and Pose Reconstruction", "authors": "Ben Kaye,Tomas Jakab,Shangzhe Wu,Christian Rupprecht,Andrea Vedaldi", "background": "在几何任务中的深度学习成功中，数据表示的选择是一个关键因素。例如，DUSt3R最近引入了视角不变点图的概念，将深度预测一般化，并表明关于静态场景的3D重建，所有关键问题都可以归结为预测这样的点图。因此，本研究旨在开发一种类似的点图概念，用于解决一个非常不同的问题：可变形物体的3D形状和姿态重建。", "innovation": "本研究提出了Dual Point Maps (DualPM)，这对从同一图像中提取的一对点图进行了扩展，分别是将像素与物体上的3D位置关联起来，以及与物体在初始姿态的标准版本关联起来。这些点图使算法能够恢复由于自遮挡而被遮挡的物体的完整形状。此概念使得3D重建和3D姿态估计可以归结为预测DualPM。", "conclusion": "实验表明，这种表示形式是深度网络预测的有效目标。具体来说，该研究在可变形动物的建模上进行了数据驱动的训练，使用正面的合成3D数据（一个或两个模型每类别），并展示了它在真实图像上的有效推广。这一方法显著提升了此类对象3D分析和重建的先前方法。"}
{"llm_update_time": "20250816", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.10137", "html_url": "https://arxiv.org/abs/2508.10137", "title": "mSCoRe: a Multilingual and Scalable Benchmark for Skill-based Commonsense Reasoning", "title_en": "mSCoRe: a $M$ultilingual and Scalable Benchmark for $S$kill-based $Co$mmonsense $Re$asoning", "authors": "Nghia Trung Ngo,Franck Dernoncourt,Thien Huu Nguyen", "background": "近期增强的推理强化大型语言模型（LLMs）在复杂的推理任务中展现出显著的能力。然而，这些模型如何利用不同的人类推理技能的具体机制尚未得到充分研究，特别是涉及跨语言和文化每天知识的多语言常识推理。为了填补这一空白，本文提出了一种名为‘mSCoRE’的多语言和可扩展常识推理能力基准，旨在系统性地评估大型语言模型的推理能力。", "innovation": "该基准包括三个关键组件，分别设计用于系统评估LLM的推理能力：1) 新颖的推理技能分类法，以便对模型的推理过程进行细致分析；2) 针对常识推理评估特制的稳健数据合成流程；3) 复杂度扩展框架，允许任务难度随着未来LLM能力的改进动态扩展。实验结果表明，当前模型在mSCoRE上仍显得具有显著挑战性，尤其是在更复杂的水平上。研究结果揭示了此类推理强化模型在面对精细的多语言常识时存在的局限性。", "conclusion": "我们的研究揭示了这些推理强化模型在面对复杂的多语言常识和文化时的局限性。我们还提供了模型推理过程的详细分析，为提高多语言常识推理能力指出了未来的研究方向。"}
{"llm_update_time": "20250816", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2505.20469", "html_url": "https://arxiv.org/abs/2505.20469", "title": "CCL-LGS: 对比代码本学习在3D语言高斯点云中的应用", "title_en": "CCL-LGS: Contrastive Codebook Learning for 3D Language Gaussian Splatting", "authors": "Lei Tian,Xiaomin Li,Liqian Ma,Hao Yin,Zirui Zheng,Hefei Huang,Taiqing Li,Huchuan Lu,Xu Jia", "background": "近年来，3D重建技术和视觉-语言模型的进步极大地推动了3D语义理解的发展，这对于机器人、自动驾驶和虚拟/增强现实至关重要。然而，依赖2D先验的方法容易受到遮挡、图像模糊和视角依赖性变化引起的跨视角语义不一致的困扰。这些不一致在投影监督下传播，会降低3D高斯语义场的质量，并在渲染输出中引入伪影。为了缓解这一局限，本文提出了一种名为CCL-LGS的新框架，通过整合多视角语义线索实现视图一致的语义监督。", "innovation": "与之前的直接将CLIP应用于不完美的掩模的方法不同，本文框架明确解决了语义冲突并保留了类别可区分性。具体而言，该框架首先使用零样本跟踪器对SAM生成的2D掩模进行对齐，并可靠地识别其对应的类别。接着使用CLIP提取各视角之间的鲁棒语义编码。最后，通过强化类别内紧凑性和类别间区分性来提炼判别语义特征的对比代码本学习(CCL)模块起到了关键作用。广泛的实验表明CCL-LGS优于以往的最先进的方法。", "conclusion": "通过对比代码本学习(CCL)模块和多视角语义线索的整合，CCL-LGS框架有效地解决了视图一致性问题，提升了3D语义理解的性能，并在广泛的实验中表现出优越性。"}
{"llm_update_time": "20250816", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2505.22793", "html_url": "https://arxiv.org/abs/2505.22793", "title": "视觉-语言模型的文化胜任力评估", "title_en": "Evaluation of Cultural Competence of Vision-Language Models", "authors": "Srishti Yadav,Lauren Tilton,Maria Antoniak,Taylor Arnold,Jiaang Li,Siddhesh Milind Pawar,Antonia Karamolegkou,Stella Frank,Zhaochong An,Negar Rostamzadeh,Daniel Hershcovich,Serge Belongie,Ekaterina Shutova", "background": "现代的视觉-语言模型（VLMs）在文化胜任力评估和基准测试中表现不佳。由于基于这些模型的多种应用，引发重新关注其如何编码文化细微差别。尽管对这个问题的各种方面有所研究，但对于视觉语言模型来说，仍缺少一个系统性地识别和标注图像中的文化维度的综合框架。", "innovation": "本文提出了一个基于视觉文化研究原理（文化研究、符号学和视觉研究）的文化分析框架，涵盖了五个对应于文化维度的分析框架，使对视觉语言模型的文化胜任力进行全面分析成为可能。", "conclusion": "通过运用这些框架，可以更加系统地评估和提高视觉语言模型处理文化信息的能力。"}
{"llm_update_time": "20250816", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2506.18903", "html_url": "https://arxiv.org/abs/2506.18903", "title": "VMem: 使用硫点索引视图记忆的一致交互式视频场景生成", "title_en": "VMem: Consistent Interactive Video Scene Generation with Surfel-Indexed View Memory", "authors": "Runjia Li,Philip Torr,Andrea Vedaldi,Tomas Jakab", "background": "先前的方法要么通过逐增地重构三维几何结构同时在2D视图上进行外绘画而取得类似结果，这会迅速积累错误；要么使用具有短上下文窗口的视频生成器，但难以长时间维持场景的连贯性。", "innovation": "提出了Surfel-Indexed View Memory (VMem)，一种通过基于硫点（三维表面元素）的几何索引记住过去视图的记忆模块。VMem能够高效检索生成新视图时最相关的过去视图，从而减少计算成本，同时生成连贯的想象环境的探索。", "conclusion": "在具有挑战性的长期内存场景合成基准测试中评估了我们的方法，并展示了与现有方法相比，我们的方法在保持场景连贯性和相机控制方面的优越性能。"}
{"llm_update_time": "20250816", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2506.06818", "html_url": "https://arxiv.org/abs/2506.06818", "title": "逐步分解与双流聚焦：一种新的无训练伪装目标分割方法", "title_en": "Stepwise Decomposition and Dual-stream Focus: A Novel Approach for Training-free Camouflaged Object Segmentation", "authors": "Chao Yin,Hao Li,Kequan Yang,Jide Li,Pinpin Zhu,Xiaoqiang Li", "background": "尽管可提示分割（例如，SAM）在各种分割任务中显示出潜力，但仍然需要为每个需要分割的对象手动提供视觉提示。相比之下，通用任务提示分割旨在仅通过任务通用提示在所有测试样本中引导分割，从而减少这种详细提示的需求。但当应用于伪装目标分割（COS）时，当前方法仍然面临两个关键问题：1）实例特定文本提示中的语义模糊性，这源于整体描述中的缺乏区分性线索，导致前景与背景混淆；2）实例特定视觉提示中的语义不一致与空间分离，这源于全局背景采样远离目标边界且特征关联性低，导致SAM分割无关区域。", "innovation": "提出了一种新的无训练测试时适应框架RDVP-MSD，该框架通过多模态逐步分解链思想（MSD-CoT）整合了区域约束的双流视觉提示（RDVP）。MSD-CoT逐阶段解开图像描述以消除语义模糊性，而RDVP则在视觉提示中注入空间约束，并独立地从前景和背景采样视觉提示，从而有效缓解语义不一致和空间分离。", "conclusion": "无需求任何训练或监督，RDVP-MSD在多个COS基准上实现了最先进的分割结果，并提供比先前方法更快的推理速度，显示出显著提高的准确性和效率。"}
{"llm_update_time": "20250816", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2505.23395", "html_url": "https://arxiv.org/abs/2505.23395", "title": "点还是线？利用基于线表示法进行CAD图中全景符号识别", "title_en": "Point or Line? Using Line-based Representation for Panoptic Symbol Spotting in CAD Drawings", "authors": "Xingguang Wei,Haomin Wang,Shenglong Ye,Ruifeng Luo,Yanting Zhang,Lixin Gu,Jifeng Dai,Yu Qiao,Wenhai Wang,Hongjie Zhang", "background": "当前关于CAD图纸中符号识别的研究主要依赖于图像像素化、图结构构建或基于点的方法，但这些方法通常计算成本高、通用性受限且会丢失几何结构信息。现有方法在处理计数物体的单个实例和不可数物体的语义区域时存在问题。因此，需要一种能够保持几何连续性、准确表明形状且计算友好的方法作为一种新型方式，来促进基于矢量图形的理解任务 Freeman.（2023）", "innovation": "本文提出了VecFormer，一种基于线模型的新方法。VecFormer在保持原始基本元素几何连续性的基础上，通过线性表示法提供更准确的形状表示，并具有易于计算的结构，特别适合于矢量图形理解任务。此外，VecFormer还引入了分支融合精炼模块，实现了实例和语义预测的有效整合，提升了最终的全景输出一致性 Freeman.（2023）", "conclusion": "Extensive experiments demonstrated that VecFormer could achieve a new state-of-the-art of 91.1 PQ, with Stuff-PQ improved by 9.6 and 21.2 points over the second-best results under settings with and without prior information, respectively。这些结果表明，基于线的表示法作为基础，具有很强的潜力，能够有效提高Panoptic符号识别的可靠性 Freeman.（2023）"}
{"llm_update_time": "20250816", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2506.23009", "html_url": "https://arxiv.org/abs/2506.23009", "title": "MusiXQA: 在多模态大型语言模型中促进视觉音乐理解", "title_en": "MusiXQA: Advancing Visual Music Understanding in Multimodal Large Language Models", "authors": "Jian Chen,Wenye Ma,Penghang Liu,Wei Wang,Tengwei Song,Ming Li,Chenguang Wang,Jiayu Qin,Ruiyi Zhang,Changyou Chen", "background": "多模态大型语言模型（MLLMs）在自然图像、文本丰富的文档和图形设计等领域的图示理解方面已取得了显著成效。然而，它们在解读音乐谱方面的应用仍未能充分利用。MusiXQA 是首个专门设计用于评估和提升 MLLMs 在音乐谱理解方面的综合数据集，它通过 MusiXTeX 生成高质量的合成音乐谱，并附带结构化注释，涵盖了音符音高和时长、和弦、谱号、调号/时间号和文本等信息，支持多样的视觉问答任务。", "innovation": "MusiXQA 提供了首个专注于音乐谱理解的综合数据集，旨在推动 MLLMs 在音乐领域的应用。通过大规模评估，揭示了当前顶尖 MLLMs 在该领域的显著局限性。此外，本研究还开发了基于 MusiXQA 数据集的 Phi-3-MusiX 模型，该模型在性能上显著优于基于 GPT 的方法，为未来 MLLMs 在音乐应用中的进展奠定了基础。", "conclusion": "MusiXQA 数据集和模型为多模态大型语言模型在音乐谱理解方面的未来发展提供了坚实的基础，相关代码、数据和模型将在论文接受后公开发布。"}
{"llm_update_time": "20250816", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2506.18248", "html_url": "https://arxiv.org/abs/2506.18248", "title": "增强对抗转移性的语义结构感知生成性攻击", "title_en": "Semantic Structure-Aware Generative Attacks for Enhanced Adversarial Transferability", "authors": "Jongoh Jeong,Hunmin Yang,Jaeseok Jeong,Kuk-Jin Yoon", "background": "对抗性攻击通过训练一个扰动生成器来攻击一个白箱代理模型，并在未知的黑箱目标模型上应用生成的扰动。与迭代攻击相比，这些方法在推理效率、可扩展性和迁移性方面表现出更好的性能。然而，现有的研究尚未充分挖掘生成模型的表征能力以保留和利用语义信息，特别是在生成器中间激活层中未被充分利用的丰富语义特征，比如对象边界和粗略形状，这限制了扰动与关键的对抗性转移区域的对齐。", "innovation": "研究人员引入了一种基于Mean Teacher的语义结构感知攻击框架，这提供了一个时间上平滑的特征参考。通过这种方式，他们进一步增强了学生在网络早层数激活与语义丰富的教师网络之间的一致性，利用特征蒸馏方法。基于经验发现，扰动合成锚定在生成器中的语义显著早期中间块，指导逐步的对抗性扰动，这些扰动在显著增强对抗性转移性方面表现良好。", "conclusion": "通过在多样化的模型、领域和任务上进行广泛的实验，该研究展示了相对于现有最先进的生成性攻击方法的持续改进，这些改进是通过传统指标和研究人员新提出的偶然纠正率（ACR）综合评估得出的。"}
{"llm_update_time": "20250816", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2506.19445", "html_url": "https://arxiv.org/abs/2506.19445", "title": "野外去模糊：来自智能手机高速视频的现实世界数据集", "title_en": "Deblurring in the Wild: A Real-World Dataset from Smartphone High-Speed Videos", "authors": "Mahdi Mohd Hossain Noki,Syed Mumtahin Mahmud,Prothito Shovon Majumder,Abdul Mohaimen Al Radi,Sudipto Das Sukanto,Afia Lubaina,Md. Mosaddek Khan", "background": "本研究介绍了基于智能手机慢动作视频构建的最大规模现实世界图像去模糊数据集。使用一秒钟内捕获的240帧，通过平均帧的方式模拟现实中的长时间曝光模糊效果，同时使用时间上居中的帧作为清晰的参考。该数据集包含超过42,000对高分辨率模糊-清晰图像对，使其大约是广泛使用的数据集的10倍大小，场景多样性提高了8倍，涵盖了室内和室外环境，物体和相机运动各不相同。这项工作为先进的去模糊模型提供了一个基准平台，以评估模型在不同场景下的表现。", "innovation": "开发了一套基于智能手机慢动作视频的去模糊数据集，该数据集包含超过42,000对高分辨率模糊-清晰图像对，比现有的广泛使用的数据集大10倍，场景多样性高8倍，覆盖了各种室内和室外环境的物体和相机运动情况。此外，该研究还对多个最先进的去模糊模型进行了基准测试，展示了去模糊模型面临的复杂性和多样性。这项研究提供了一个新的具有挑战性的基准数据集，以促进更加稳健和泛化的去模糊模型的发展与研究。", "conclusion": "本研究构建了一个基于智能手机慢动作视频的最大现实世界图像去模糊数据集，并且在多种最先进的去模糊模型上进行了基准测试。研究结果表明，现有的去模糊模型在复杂和多变的场景下表现出色，为此领域提供了新的基准参考，有助于开发更加有效和通用的去模糊算法。"}
{"llm_update_time": "20250816", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.01006", "html_url": "https://arxiv.org/abs/2507.01006", "title": "GLM-4.1V-Thinking 和 GLM-4.5V：利用可扩展强化学习实现多功能多模态推理", "title_en": "GLM-4.1V-Thinking and GLM-4.5V: Towards Versatile Multimodal Reasoning with Scalable Reinforcement Learning", "authors": "GLM-V Team:Wenyi Hong,Wenmeng Yu,Xiaotao Gu,Guo Wang,Guobing Gan,Haomiao Tang,Jiale Cheng,Ji Qi,Junhui Ji,Lihang Pan,Shuaiqi Duan,Weihan Wang,Yan Wang,Yean Cheng,Zehai He,Zhe Su,Zhen Yang,Ziyang Pan,Aohan Zeng,Baoxu Wang,Bin Chen,Boyan Shi,Changyu Pang,Chenhui Zhang,Da Yin,Fan Yang,Guoqing Chen,Jiazheng Xu,Jiale Zhu,Jiali Chen,Jing Chen,Jinhao Chen,Jinghao Lin,Jinjiang Wang,Junjie Chen,Leqi Lei,Letian Gong,Leyi Pan,Mingdao Liu,Mingde Xu,Mingzhi Zhang,Qinkai Zheng,Sheng Yang,Shi Zhong,Shiyu Huang,Shuyuan Zhao,Siyan Xue,Shangqin Tu,Shengbiao Meng,Tianshu Zhang,Tianwei Luo,Tianxiang Hao,Tianyu Tong,Wenkai Li,Wei Jia,Xiao Liu,Xiaohan Zhang,Xin Lyu,Xinyue Fan,Xuancheng Huang,Yanling Wang,Yadong Xue,Yanfeng Wang,Yanzi Wang,Yifan An,Yifan Du,Yiming Shi,Yiheng Huang,Yilin Niu,Yuan Wang,Yuanchang Yue,Yuchen Li,Yutao Zhang,Yuting Wang,Yu Wang,Yuxuan Zhang,Zhao Xue,Zhenyu Hou,Zhengxiao Du,Zihan Wang,Peng Zhang,Debing Liu,Bin Xu,Juanzi Li,Minlie Huang,Yuxiao Dong,Jie Tang", "background": "该研究旨在推进通用多模态理解和推理，提出了GLM-4.1V-Thinking和GLM-4.5V家族的视觉-语言模型。通过大规模预训练建立视觉基础模型，结合引入Reinforcement Learning with Curriculum Sampling (RLCS)，以提升模型在多种任务上的表现，包括 STEM 问题解决、视频理解、内容识别、编程、实体定位、基于GUI的代理以及长文档解释等。", "innovation": "开发了视觉基础模型和RLCS框架。视觉基础模型通过大规模预训练实现，被视作最终性能的上限。RLCS帮助模型在多样任务中全面增强能力，特别是在编程和基于GUI的代理等具有挑战性任务中展示出与封闭源代码模型相当或更好的性能。", "conclusion": "GLM-4.5V 在42个公开基准测试中达到或超过了开源模型的最优性能，,GLM-4.1V-9B-Thinking在29个基准上表现出色，超过了类似规模的Qwen2.5-VL-72B。研究团队开源了两者，代码、模型及相关信息可在相应网址获取。"}
{"llm_update_time": "20250816", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2506.13307", "html_url": "https://arxiv.org/abs/2506.13307", "title": "预训练潜扩散模型在生成未见SAR图像中的微调技术定量比较", "title_en": "Quantitative Comparison of Fine-Tuning Techniques for Pretrained Latent Diffusion Models in the Generation of Unseen SAR Images", "authors": "Solène Debuysère,Nicolas Trouvé,Nathan Letheule,Olivier Lévêque,Elise Colin", "background": "本文介绍了一种将大型预训练潜扩散模型调整为高分辨率合成孔径雷达(SAR)图像生成的框架。该方法使图像合成可控，并能够生成训练集中未包含的稀有或分布外场景。与从头训练特定任务的小模型不同，本文采用开源文本到图像的基础模型对SAR模态进行适应，利用其语义先验使得提示与SAR成像物理特性（侧视几何、斜距投影和相干斑点）相匹配。使用具有100,000张SAR图像的数据集，本文比较了完整微调和参数高效低秩适应（LoRA）在UNet扩散主体、变分自编码器（VAE）和文本编码器上的表现。评估结合了（i）到真实SAR幅度分布的统计距离，（ii）通过灰度共生矩阵（GLCM）描述符的质量特征相似度，以及（iii）通过专门用于SAR的CLIP模型的语义对齐。实验证明，一种混合策略——对UNet进行完整微调，对文本编码器和学习到的词嵌入使用LoRA——在保持SAR几何和纹理的同时最好地保留了提示的准确性。该框架支持基于文本的控制和多模态条件（例如，分割图、TerraSAR-X或光学指引），为地球观测中的大规模SAR场景数据增强和未见情景模拟开辟了新途径。", "innovation": "本文提出了一个框架，将大型预训练潜扩散模型适应为生成高分辨率SAR图像，使用这种方法能够生成训练集之外的稀有或分布外场景。通过使用语义先验对SAR成像物理特性进行调整，本文采用了一种混合调整策略，结合了完整微调和参数高效低秩适应（LoRA）技术。此外，本文还引入了对SAR特化的CLIP模型进行语义对齐的方法，并通过统计距离、质量特征相似度和语义对齐等多个指标进行了评估。", "conclusion": "本文的研究结果表明，一种混合调整策略，即对UNet进行完整微调，对文本编码器和学习到的词嵌入使用LoRA，能够最好地保留SAR几何和纹理，同时保持提示的准确性。此外，该框架支持基于文本的控制和多模态条件，为大规模SAR场景数据增强和未见情景模拟提供了新途径。"}
{"llm_update_time": "20250816", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.06639", "html_url": "https://arxiv.org/abs/2507.06639", "title": "EXAONE Path 2.0：具有端到端监督的病理学基础模型", "title_en": "EXAONE Path 2.0: Pathology Foundation Model with End-to-End Supervision", "authors": "Myeongjang Pyeon,Janghyeon Lee,Minsoo Lee,Juseung Yun,Hwanil Choi,Jonghyun Kim,Jiwon Kim,Yi Hu,Jongseong Jang,Soonyoung Lee", "background": "在数字病理学中，全视图图像（WSIs）由于其极高的像素规模而难以处理，因此大多数方法是通过自主监督学习（SSL）训练patches编码器，然后通过单例学习（MIL）或切片编码器进行聚合以供下游任务使用。然而，patches级别的SSL可能忽略了如突变状态和分子特征等对于生物标志物预测至关重要的复杂领域特定特征，因为SSL方法仅依赖于为自然图像域选取的基本增强方法作用于小patches区域上。此外，SSL方法在数据效率上低于完全监督的方法，需要大量的计算资源和数据集才能达到竞争力的性能。", "innovation": "我们提出了EXAONE Path 2.0，这是一种病理学基础模型，该模型在直接的切片级别监督下学习patches级别的表示。使用仅37k吴的WSIs进行训练，EXAONE Path 2.0在10个生物标志物预测任务中实现了最先进的平均性能，展示了其卓越的数据效率。", "conclusion": "该研究通过直接的切片级别监督展示了EXAONE Path 2.0在数据效率方面超越传统SSL方法的效果。"}
{"llm_update_time": "20250816", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.06071", "html_url": "https://arxiv.org/abs/2507.06071", "title": "MEDTalk：通过分离嵌入实现的多模态控制的动态情感三维面部动画", "title_en": "MEDTalk: Multimodal Controlled 3D Facial Animation with Dynamic Emotions by Disentangled Embedding", "authors": "Chang Liu,Ye Pan,Chenyang Ding,Susanto Rahardja,Xiaokang Yang", "background": "现有的通过音频生成情感三维面部动画的方法主要集中在静态和预定义的情感标签上，这些方法限制了多样性和自然性。传统的唇同步方法缺乏对情感表达的细致和动态控制，无法满足三维动画中情感表达的需求，特别是在工业生产管线中的应用需要更高的控制性和个性化定制能力。", "innovation": "本文提出了一种名为MEDTalk的创新框架，用于细粒度和动态的情感头部生成。其创新点在于：1) 通过一个精心设计的交叉重构过程分离内容嵌入和情感嵌入空间，实现了唇部运动和面部表情的独立控制；2) 结合音频和语音文本，预测帧间强度变化，并动态调整静态情感特征以生成真实的情感表达；3) 引入多模态输入（包括文本描述和参考表情图像），以指导用户指定的面部表情生成，增强控制性与个性化。", "conclusion": "通过MEDTalk框架，能够生成方便集成到工业生产管道中的情感三维面部动画，相较于现有方法，提供的情感表达更加细致与自然，同时具备更高的控制性和个性化定制能力。"}
{"llm_update_time": "20250816", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.10778", "html_url": "https://arxiv.org/abs/2507.10778", "title": "基于LLM代理的仓库空间问答", "title_en": "Warehouse Spatial Question Answering with LLM Agent", "authors": "Hsiang-Wei Huang,Jen-Hao Cheng,Kuang-Ming Chen,Cheng-Yen Yang,Bahaa Alattar,Yi-Ru Lin,Pyongkun Kim,Sangwon Kim,Kwangju Kim,Chung-I Huang,Jenq-Neng Hwang", "background": "现有的多模态大型语言模型（MLLMs）在空间理解方面面临挑战。之前的解决方法主要依靠大规模MLLM的微调来提升空间理解能力。本文中，我们提出了一种数据高效的方法。我们构建了一个具备强大空间推理能力的LLM代理系统，能够在复杂的仓库场景中解决空间问题回答任务。", "innovation": "我们提出了一种数据高效的方法，构建了一个具备强空间推理能力的LLM代理系统，能够处理复杂的仓库场景中的空间问题回答任务。系统整合了多种工具，使LLM代理能够进行空间推理和API交互，以解答复杂的空间问题。实验表明，该系统在物体检索、计数和距离估计等任务上达到了高准确性和效率。", "conclusion": "我们的系统在2025年AI城市挑战赛的物理AI空间智能仓库数据集上进行了广泛的评估，展示了在复杂室内仓库场景中的出色表现。代码可以在这个链接获取：this https URL"}
{"llm_update_time": "20250816", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.08307", "html_url": "https://arxiv.org/abs/2507.08307", "title": "M2DAO-Talker: 调和多粒度运动解耦和交替优化的说话头生成", "title_en": "M2DAO-Talker: Harmonizing Multi-granular Motion Decoupling and Alternating Optimization for Talking-head Generation", "authors": "Kui Jiang,Shiyu Liu,Junjun Jiang,Hongxun Yao,Xiaopeng Fan", "background": "音频驱动的说话头生成在电影制作中具有巨大潜力，现有3D方法已提高运动建模和内容合成的能力，但在稳定和精细的运动场表示方面存在限制，导致渲染过程中产生运动模糊、时间抖动和局部穿透等缺陷。", "innovation": "该研究重塑了说话头生成为包括视频预处理、运动表示和渲染重建三个步骤的统一框架，并提出M2DAO-Talker模型。通过多粒度运动解耦和交替优化策略，分别独立建模刚体（头部）和非刚体（口腔和面部）运动，从而改善重建精度，并通过运动一致性约束确保头部与躯干的运动一致性，降低运动混叠导致的穿透缺陷。同时，设计交替优化策略迭代优化面部和口腔运动参数，使生成的视频更加逼真。", "conclusion": "实验结果表明，M2DAO-Talker在生成质量的峰值信噪比（PSNR）和用户评价的真实感方面优于TalkingGaussian，同时保持150 FPS的推断速度，达到了最先进的技术水平。"}
{"llm_update_time": "20250816", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2506.16073", "html_url": "https://arxiv.org/abs/2506.16073", "title": "TD3Net：用于唇读的时域密集连接多卷积网络", "title_en": "TD3Net: A temporal densely connected multi-dilated convolutional network for lipreading", "authors": "Byung Hoon Lee,Wooseok Shin,Sung Won Han", "background": "传统的字级唇读方法通常采用两阶段框架，前端和后端架构分离，以建模动态唇部运动。后端架构中广泛采用了时间卷积网络（TCNs）。最近，在TCNs中引入了密集跳连连接以弥补接收域密度有限的问题，从而改善了对复杂时间表示的建模。然而，这种设计依然存在信息损失，特别是在处理连续唇部运动时因接收域中的盲区引发的问题。这一限制使得TCNs的整体性能受到了制约。", "innovation": "本文提出了一种时域密集连接多膨胀卷积网络（TD3Net），该网络结合了密集跳连连接和多膨胀时间卷积作为后端架构。TD3Net通过应用不同膨胀因子到跳连特征，实现了广泛而密集的接收域，从而避免了盲区。实验结果显示，该方法在两个大规模公开数据集LRW和LRW-1000上实现了与现有最先进的方法相当的表现，并且其参数更少、计算量更低。此外，可视化结果显示我们的方法有效地利用了多样化的时间特征，同时保持了时间的连续性，显示出在唇读系统中的优势。", "conclusion": "本研究表明，TD3Net在字级唇读任务中表现良好，并且相对于其他基于TCN的后端架构，其具有较少参数和较低计算量的特点。同时，通过跳连连接和多膨胀卷积的结合，我们的方法能够有效地捕捉连续的唇部运动，并利用多样化的时序特征，实现了在处理复杂时序数据方面的新进展。"}
{"llm_update_time": "20250816", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.07985", "html_url": "https://arxiv.org/abs/2507.07985", "title": "CLIP中常见的数据属性限制了对象-属性绑定", "title_en": "Common Data Properties Limit Object-Attribute Binding in CLIP", "authors": "Bijay Gurung,David T. Hoffmann,Thomas Brox", "background": "Contrastive 视觉-语言模型如 CLIP 广泛用于多种应用，包括零样本分类或作为多模态模型的视觉编码器。尽管十分流行，CLIP 教练下的模型的表示仍存在许多限制。例如，CLIP 学习袋词表示难以区分图像是否为“一辆黄色潜水艇和一辆蓝色巴士”或“一艘蓝色潜水艇和一辆黄色巴士”。先前的尝试在此问题上添加了负样本或修改了架构，但未能解决该问题。我们认为解决问题的关键可能隐藏在最核心的学习算法部分：数据。本文通过使用合成数据集以严谨的方式识别数据属性对 CLIP 学习绑定能力的影响来填补这个空白。发现常见的自然数据属性，如低属性密度、不完整的说明词，以及描述觉最显著对象的偏向，都对绑定性能有负面作用。有别于常见的观点，增大批次大小或明确创建负样本，并不能让 CLIP 学习可靠的绑定。只有当数据表达了我们确认的数据属性，CLIP 才能几乎完美地学习绑定。", "innovation": "作者通过合成数据集严谨地识别并验证了数据属性对 CLIP 学习对象-属性绑定能力的影响。找到了低属性密度、不完整的说明词和人类描述的“最显著”对象偏向这些自然数据属性的负面作用，并实证发现这些属性限制了 CLIP 学习绑定。同时，研究结果表明仅仅通过增加负样本或调整批量大小无法解决此问题，唯一有效的办法是数据结构本身需要表达这些属性。", "conclusion": "本研究揭示了常见自然数据属性对 CLIP 在对象-属性绑定能力上的影响，指出仅仅通过增加负样本或调整批量大小不能解决现有问题，提出需要确保数据本身具备合适的属性结构才能让 CLIP 正确学习绑定。"}
{"llm_update_time": "20250816", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.21977", "html_url": "https://arxiv.org/abs/2507.21977", "title": "Motion Matters: Motion-guided Modulation Network for Skeleton-based Micro-Action Recognition", "title_en": "Motion Matters: Motion-guided Modulation Network for Skeleton-based Micro-Action Recognition", "authors": "Jihao Gu,Kun Li,Fei Wang,Yanyan Wei,Zhiliang Wu,Hehe Fan,Meng Wang", "background": "微动作（MAs）是非言语交流的重要形式，在社交互动中具有潜在的应用价值，特别是用于人类情感分析。然而，现有的微动作识别方法经常忽视微动作中固有的微妙变化，这限制了微动作识别的准确性，尤其是对于那些细微变化较多的微动作。", "innovation": "提出了一种新的运动引导模态网络（MMN），隐式捕捉和调制微小的运动线索，以增强时空表征学习。具体来说，引入了一个运动引导骨骼调制模块（MSM），在骨骼层面上注入运动线索，作为控制信号以指导空间表示建模。同时，设计了一个运动引导时间调制模块（MTM），在帧层面上整合运动信息，以促进微动作整体运动模式的建模。此外，提出了一种运动一致性学习策略，用于从多尺度特征中聚合运动线索以进行微动作分类。", "conclusion": "在Micro-Action 52和iMiGUE数据集上的实验结果表明，MMN在基于骨架的微动作识别中达到了最先进的性能，突显了明确建模微小运动线索的重要性。代码可以通过以下链接访问：this https URL."}
{"llm_update_time": "20250816", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.14976", "html_url": "https://arxiv.org/abs/2507.14976", "title": "层级跨模态提示学习用于视觉语言模型", "title_en": "Hierarchical Cross-modal Prompt Learning for Vision-Language Models", "authors": "Hao Zheng,Shunzhi Yang,Zhuoxin He,Jinfeng Yang,Zhenhua Huang", "background": "预训练的视觉-语言模型（VLMs）如CLIP展示出了卓越的泛化能力。但是，要将这些大规模模型适应下游任务同时保留其泛化能力仍然具有挑战性。尽管提示学习方法展现出了潜力，但他们仍然面临两个根本性的瓶颈阻碍了泛化性：（a）模态隔离，（b）层次语义衰减。", "innovation": "为了解决这些限制，我们提出了HiCroPL，一种层级跨模态提示学习框架。该框架发挥了文本和视觉模态的优势建立了双向的知识流动，使得它们能互相改进其语义。HiCroPL结合了早期层次中的文本提示通过层次知识映射向视觉提示注入相对清晰的语义以增强低级视觉语义的表示；在后期方向，视觉提示嵌入了特定下游任务相关信息的对象返回来改善文本提示，这种机制可以实现更深层次的对齐。 Crucially, 我们的层次知识映射允许多尺度表征的融合，确保深层表征保留可迁移的浅层语义从而增强泛化性。此外，引入了一个轻量级的层次专用知识代理来促进高效的跨模态交互。", "conclusion": "广泛的评估结果展示了HiCroPL的优越性能，在四个任务上的测试以及11个基准上达到了最新的成果，且表现显著提高。此代码可在以下地址获得：this https URL."}
{"llm_update_time": "20250816", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.04549", "html_url": "https://arxiv.org/abs/2508.04549", "title": "MSC: 一个包含接地分割和片段级字幕的海洋野生动物视频数据集", "title_en": "MSC: A Marine Wildlife Video Dataset with Grounded Segmentation and Clip-Level Captioning", "authors": "Quang-Trung Truong,Yuk-Kwan Wong,Vo Hoang Kim Tuyen Dang,Rinaldi Gotama,Duc Thanh Nguyen,Sai-Kit Yeung", "background": "海洋视频对视频理解提出了巨大挑战，由于海洋对象及周围环境的动态性、摄像机运动以及水下场景的复杂性。现有的视频字幕数据集通常集中在通用或以人为主导的领域，很难适应海洋环境的复杂性，并获得对海洋生命的研究见解。", "innovation": "本文提出了一个两阶段的海洋对象导向视频字幕流水线。引入了一个结合视频、文本和分割掩码三者的全面视频理解基准，有利于视觉定位和字幕生成，提高了海洋视频的理解和分析，以及海洋视频生成的水平。还强调了视频分割的有效性，以检测场景变化中显著物体的过渡，显著丰富了字幕内容的语义。", "conclusion": "我们的数据集和代码已发布于此：this https URL."}
{"llm_update_time": "20250816", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.00399", "html_url": "https://arxiv.org/abs/2508.00399", "title": "iSafetyBench: 一种用于工业环境安全的视频语言基准", "title_en": "iSafetyBench: A video-language benchmark for safety in industrial environment", "authors": "Raiyaan Abdullah,Yogesh Singh Rawat,Shruti Vyas", "background": "近期在视觉语言模型（VLMs）领域的进展已经使得这些模型在零样本条件下跨多种视频理解任务表现出色。然而，在高风险的工业环境中，识别常规操作和安全关键异常的能力仍未得到充分探索。为填补这一空白，引入了iSafetyBench，这是一个专门设计用于在工业环境中评估模型性能的新视频语言基准，涵盖了正常和危险场景。iSafetyBench包含来自真实工业环境的1100个视频剪辑，带有包含98种常见动作和67种危险动作类别的开放式词汇、多标签动作标签，并且每个剪辑都配有多选题，用于单标签和多标签评估，以细粒度评估VLM模型在标准和安全关键环境中的表现。", "innovation": "引入了iSafetyBench，这是第一个专门针对工业环境安全的视频语言基准，旨在评估模型在正常和危险场景下的性能。此基准结合了1100个从实际工业环境中采集的视频剪辑，每个剪辑都有多选题支持单标签和多标签评估。尽管当前最先进的视频语言模型在现有视频基准中表现良好，但在iSafetyBench中，特别是在识别危险活动和多标签场景中，它们的性能表现较差，这揭示了现有模型在安全关键应用领域中的局限性，强调了需要更加稳健、安全意识更强的多媒体模型的重要性。数据集可在指定链接处获取。", "conclusion": "iSafetyBench 提供了一个新的测试平台，推动了工业环境中更安全的多媒体模型的发展。该研究表明，VLMs在安全关键场景中的性能需进一步提升，为进一步的研究指明了方向。"}
{"llm_update_time": "20250816", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.22369", "html_url": "https://arxiv.org/abs/2507.22369", "title": "探索视觉问答（VQA）在教室活动监测中的应用", "title_en": "Exploring the Application of Visual Question Answering (VQA) for Classroom Activity Monitoring", "authors": "Sinh Trong Vu,Hieu Trung Pham,Dung Manh Nguyen,Hieu Minh Hoang,Nhu Hoang Le,Thu Ha Pham,Tai Tan Mai", "background": "教室行为监测是教育研究中的关键方面，对学生成绩和学习成果有重大影响。最近在视觉问答（VQA）模型方面的进展提供了一种自动分析视频录制中的复杂教室互动的可能性。本研究探讨了LLaMA2、LLaMA3、QWEN3和NVILA等先进开源VQA模型在教室行为分析中的适用性。为了进行严格评估，研究团队基于越南银行业发展学院的真实课堂视频记录构建了BAV-Classroom-VQA数据集，并展示了数据收集、标注方法以及这些模型在该数据集上的基准测试结果。初步实验证明了所有四个模型在回答与行为相关的问题时的优秀表现，预示其在未来的教室分析和介入系统中的潜力。", "innovation": "构建了特定于教室行为分析的BAV-Classroom-VQA数据集；探讨了多个先进开源VQA模型在课堂行为分析中的应用；提供了严格的模型评估方法和基准测试结果。", "conclusion": "研究表明，所选的VQA模型在回答教室行为相关的问题时能够达到出色的水平，显示了其在教室分析和干预系统中的巨大潜力。"}
{"llm_update_time": "20250816", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.03497", "html_url": "https://arxiv.org/abs/2508.03497", "title": "EditGarment: 使用自动化MLLM合成和语义意识评估构建的基于指令的服装编辑数据集", "title_en": "EditGarment: An Instruction-Based Garment Editing Dataset Constructed with Automated MLLM Synthesis and Semantic-Aware Evaluation", "authors": "Deqiang Yin,Junyi Guo,Huanda Lu,Fangyu Wu,Dongming Lu", "background": "基于指令的服装编辑能够通过自然语言实现精确的图像修改，具有广泛的应用前景，特别是在服装设计和定制领域。然而，由于高质量指令-图像对稀缺，手动标注成本高昂且难以大规模实施。现有的多实例学习语言模型（MLLM）虽然在自动数据合成方面显示出潜力，但在服装编辑中的应用受到了指令模型不够精确以及缺乏特定于时尚的监督信号的限制。这对基于指令的服装编辑提出了挑战。", "innovation": "本文提出了一种自动化的管道来构建基于指令的服装编辑数据集。首先，定义了六个与现实世界时尚工作流程相契合的编辑指令类别，以引导生成平衡和多样化的指令-图像三元组。其次，引入了Fashion Edit Score，这是一种基于语义的评估指标，能够捕捉服装属性之间的语义依赖关系，从而在构建过程中提供可靠的监督信号。使用此管道，共构建了52,257个候选三元组，保留了20,596个高质量三元组，构建了EditGarment数据集，这是第一个专门用于独立服装编辑的基于指令的数据集。", "conclusion": "通过这项工作，成功构建了EditGarment数据集，解决了基于指令的服装编辑中的标注难题，为未来的服装编辑研究和应用提供了基础数据支持。"}
{"llm_update_time": "20250816", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.02669", "html_url": "https://arxiv.org/abs/2508.02669", "title": "MedVLThinker: 简单的多模态医疗推理基准", "title_en": "MedVLThinker: Simple Baselines for Multimodal Medical Reasoning", "authors": "Xiaoke Huang,Juncheng Wu,Hui Liu,Xianfeng Tang,Yuyin Zhou", "background": "大型推理模型(LRMs)通过链式思考推理为AI带来了新的范式，使得模型在回应之前先思考。然而，构建医疗领域模型时缺乏开放和可重复的构建方法阻碍了社区的研究、分析和比较工作。为了解决这一问题，本文提出了MedVLThinker，一个包含简单但强大基准的解决方案，提供了一种全面公开的流程：首先，系统地对文本和图像-文本医疗数据进行数据管理，根据推理难度分级；其次，提供了两种训练策略：从提炼的推理痕迹中进行监督微调(SFT)以及基于答案正确性的验证奖励强化学习(RLVR)。", "innovation": "MedVLThinker 提供了一种全面公开的方法来构建医疗领域的多模态推理模型。它包括系统化的数据整理（区分文本和图像-文本数据，依据推理难度分级）和两种训练策略：监督微调(SFT) 和基于最终答案正确性的验证奖励强化学习(RLVR)。研究结果表明，在 RLVR 框架下，训练仅基于文本的推理数据比训练多模态图像-文本数据提供更大的性能提升。此外，使用 RLVR 阶段训练的开放式 7B 模型在公共 VQA 基准测试中取得了领先成绩，超越了所有先前的开源医疗 LMMs。进一步扩大模型规模至 32B 时，性能可与私有 GPT-4o 相媲美。作者公开了所有整理的数据、模型和代码，为未来研究提供了一个强有力的开放平台。", "conclusion": "MedVLThinker 是用于医疗多模态推理的简单且强大的基准方案。通过公开的系统化数据管理和训练策略，克服了医疗领域LMM开发的障碍，提供了新的研究成果，并公开了所有的数据、模型和代码，为未来的进一步研究提供了基础。"}
{"llm_update_time": "20250816", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.01272", "html_url": "https://arxiv.org/abs/2508.01272", "title": "PromptSafe：基于门控提示调优的文本到图像安全生成", "title_en": "PromptSafe: Gated Prompt Tuning for Safe Text-to-Image Generation", "authors": "Zonglei Jing,Xiao Yang,Xiaoqian Li,Siyuan Liang,Aishan Liu,Mingchuan Zhang,Xianglong Liu", "background": "文本到图像(T2I)模型在生成方面表现出了显著的能力，但在生成不适合观看的内容（如暴力或淫秽图像）方面仍然存在缺陷。尽管最近的缓解措施引入了添加防御标记的软提示引导调优方法，但这些方法往往依赖于大规模的图像-文本数据集，并在推断时采用固定的防御措施。这不仅导致了高计算成本和正常图像质量的下降，而且也限制了对真实世界提示多样且细致的安全需求的适应性。", "innovation": "我们提出了PromptSafe，这是一种结合了轻量级的仅文本监督软嵌入和推断时门控控制网络的门控提示调优框架。首先，我们利用大型语言模型（LLM）将不安全的提示重新写成语义对齐且安全的替代方案，构建了一个有效的文本训练语料库。然后，我们优化了一个通用的软提示，在扩散去噪过程中排斥不安全的嵌入并吸引安全的嵌入。我们引入了门控机制，根据对提示毒性估计的适应性调整防御强度，从而与提示风险对齐，确保对有害输入的强保护，同时保留正常的生成质量。广泛的实验显示，PromptSafe实现了显著的安全生成率（2.36%），同时保持了高保真的正常图像生成。除此之外，PromptSafe在未见的有害类别、扩散模型架构间的可迁移性和适应性对抗攻击中表现出强大的泛化能力，突显了其实用价值，使其适用于安全和可扩展的部署。", "conclusion": "通过将PromptSafe应用于多个基准和T2I模型，我们展示了它在保持高质量的同时显著降低不安全生成率的能力，并且能够适应未见的有害类别，表现出强大的泛化能力和对扩散模型架构的鲁棒可迁移性。对于适应性对抗攻击也展现出强大的抵御能力，表明该方法对于安全和可扩展部署的实际应用具有重要意义。"}
{"llm_update_time": "20250816", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.22733", "html_url": "https://arxiv.org/abs/2507.22733", "title": "A Linear N-Point Solver for Structure and Motion from Asynchronous Tracks", "title_en": "A Linear N-Point Solver for Structure and Motion from Asynchronous Tracks", "authors": "Hang Su,Yunlong Feng,Daniel Gehrig,Panfeng Jiang,Ling Gao,Xavier Lagorce,Laurent Kneip", "background": "结构与连续运动估计从点对应关系出发是计算机视觉中的一个基础问题，已被广泛熟知的算法如5点或8点算法所推动。然而，即使这些算法因其准确性而备受赞誉，它们也只能处理来自每一对视图的点对应关系，每一对视图代表着场景的瞬时捕捉。但对于滚轴快门摄像头或最近的事件摄像头来说，这种同步性会失效。因此，本文旨在提出一种统一的方法，从具有任意时间戳的2D点对应关系出发，估计结构和线性运动，适用于任意一组视图。使用一阶动力学来重新表述问题，并利用恒定速度运动模型，推导出一种新型的线性点相互关系，可以有效恢复三维点和线性速度，同时预测退化条件和解的多重性。该方法具有通用的形式，可处理来自全局快门、滚轴快门和事件摄像头等不同传感模态的数据，甚至可以结合来自不同传感器的数据。", "innovation": "本文提出了一种针对异步轨迹的线性N点解决方法，用于从2D点对应关系中估计结构和运动。通过使用一阶动态学和恒定速度运动模型，推导出一种新型的线性点相互关系，可以有效地恢复三维点和线性速度，同时预测退化条件和解的多重性。这种方法可以处理来自不同类型传感器的数据，并可将不同传感器的数据混合使用。实验验证了该方法在模拟和实际数据上的有效性，展示了与其他最近方法相比的一致改进。这项工作的创新在于可以处理异步数据，为结构和运动估计提供了高效的方法。", "conclusion": "本文提出了一种通用的方法来估计结构和线性运动，可以处理具有任意时间戳且来自任意视图的数据，能够在各种传感模态下有效运行，甚至能够结合不同传感器的数据。实验表明，该方法在模拟和实际数据上均实现了显著的改进。此项工作的成果将为异步数据下的结构和运动估计开辟新的道路。"}
{"llm_update_time": "20250816", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.03189", "html_url": "https://arxiv.org/abs/2508.03189", "title": "结合KAN局部性和特征漂移补偿投影的数据无源回放连续面部伪造检测统合框架", "title_en": "Unifying Locality of KANs and Feature Drift Compensation Projection for Data-free Replay based Continual Face Forgery Detection", "authors": "Tianshuo Zhang,Siran Peng,Li Gao,Haoyuan Zhang,Xiangyu Zhu,Zhen Lei", "background": "近年来面部伪造技术飞速发展，要求检测器不断适应新的伪造方法，因此将面部伪造检测置于持续学习范式中。然而，当检测器学习新类型的伪造时，其在先前类型上的性能往往会迅速下降，这种现象称为灾难性遗忘。Kolmogorov-Arnold网络（KAN）使用局部可塑样条作为激活函数，可以仅通过修改函数的局部区域来学习新任务，而不影响其他区域，因此它们自然适用于解决灾难性遗忘问题。然而，KAN也有两个显著的局限性：1）样条在建模高维图像方面效果不佳，而适用于图像的替代激活函数缺乏重要的局部性；2）在持续学习中，当来自不同领域的特征重叠时，由于同一区域的反复修改，不同领域的映射到不同的曲线区域总是崩溃。因此，要求提出一种新的框架来解决这些挑战，继续维护特征的局部性和稳定性，同时避免不同领域特征空间的重叠。研究人员提出了KAN-CFD框架，包括领域组KAN检测器（DG-KD）和数据无源回放的特征分离策略，即KAN漂移补偿投影（FS-KDCP），从而解决了上述问题，并验证了有效性和优越性。实验结果表明，所提出的方法在减少遗忘的同时显著提高了性能。", "innovation": "该论文创新性地提出了KAN-CFD框架，包括领域组KAN检测器（DG-KD）和数据无源回放的特征分离策略，即KAN漂移补偿投影（FS-KDCP）。DG-KD允许KAN适应高维图像输入，同时保持局部性和局部可塑性。FS-KDCP通过避免不同领域特征空间的重叠，避免了使用先前任务数据。因此，该框架能够有效缓解灾难性遗忘问题，同时具有优越的性能和较低的遗忘率。", "conclusion": "实验证明，所提出的KAN-CFD框架在减少遗忘的同时取得了显著优于其他方法的性能，表明该方法在持续学习的面部伪造检测方面具有重要的实用价值和应用前景。"}
{"llm_update_time": "20250816", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.06259", "html_url": "https://arxiv.org/abs/2508.06259", "title": "SIFThinker: 空间感知的图像聚焦用于视觉推理", "title_en": "SIFThinker: Spatially-Aware Image Focus for Visual Reasoning", "authors": "Zhangquan Chen,Ruihui Zhao,Chuwei Luo,Mingze Sun,Xinlei Yu,Yangyang Kang,Ruqi Huang", "background": "当前的多模态大型语言模型（MLLMs）在复杂的视觉任务（例如空间理解、细腻的视觉感知）中仍然面临着显著的挑战。尽管先前的方法尝试融入视觉推理，但它们未能利用空间线索来逐步纠正和聚焦于与指令相关区域的注意力。", "innovation": "本研究引入了 SIFThinker，这是一种空间感知的‘用图思考’框架，模拟人类的视觉感知。具体来说，SIFThinker 通过交替使用深度增强的边界框和自然语言来实现注意力纠正和图像区域聚焦。研究贡献包括：首先，提出了一种逆扩展正向推理策略，该策略可以生成交错的图像-文本思维链，以实现过程级监督，并构建 SIF-50K 数据集。其次，提出了一种结合深度引导视觉定位的强化训练范式——GRPO-SIF，这使得模型能够动态地纠正和聚焦于与指令相关区域。", "conclusion": "广泛实验表明，SIFThinker 在空间理解和细致的视觉感知方面优于最先进的方法，同时保持了强大的通用能力，突显了我们方法的有效性。"}
{"llm_update_time": "20250816", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.08098", "html_url": "https://arxiv.org/abs/2508.08098", "title": "TBAC-UniImage：梯级调谐统一理解与生成", "title_en": "TBAC-UniImage: Unified Understanding and Generation by Ladder-Side Diffusion Tuning", "authors": "Junzhe Xu,Yuyang Yin,Xi Chen", "background": "之前的统一模型存在两个主要限制：一种方法仅使用多模态大型语言模型（MLLM）的最终隐藏状态作为生成条件，这种方式导致生成器与MLLM中间层次的丰富分层表示隔离，生成过程较浅。另一种方法是从头开始预训练一个统一生成架构，这种做法计算成本高昂，对许多研究者来说不可行。", "innovation": "本文提出了一种新的方法，不依赖单一输出，而是使用MLLM多个不同层的表示作为扩散模型的生成条件。这种方法将预训练的生成器作为梯级，从MLLM理解过程的各个深度获得引导，从而实现更深层次和更精细的理解与生成统一。", "conclusion": "通过这种方式，TBAC-UniImage 实现了对多模态理解与生成的更深层次统一。"}
{"llm_update_time": "20250816", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.08601", "html_url": "https://arxiv.org/abs/2508.08601", "title": "Yan: 基础的互动视频生成", "title_en": "Yan: Foundational Interactive Video Generation", "authors": "Deheng Ye,Fangyun Zhou,Jiacheng Lv,Jianqi Ma,Jun Zhang,Junyan Lv,Junyou Li,Minwen Deng,Mingyu Yang,Qiang Fu,Wei Yang,Wenkai Lv,Yangbin Yu,Yewen Wang,Yonghang Guan,Zhihao Hu,Zhongbin Fang,Zhongqian Sun", "background": "本文介绍了一个名为Yan的基础框架，用于互动视频的生成，涵盖了从模拟、生成到编辑的整个管道。该框架整合了高度压缩的即时模拟、多模态生成和多粒度编辑三个核心模块，旨在推动互动视频生成的技术发展。", "innovation": "Yan框架创新地结合了基于3D-VAE的高度压缩低延迟即时模拟、通过游戏特定知识注入的多模态视频扩散模型（VDM）的层次自回归文本生成方法，以及通过文本驱动的多粒度视频编辑功能。这种集成使得能够在不同领域中灵活地融合和组合风格和机械特性。", "conclusion": "Yan框架提供了一个综合这些模块的框架，推动了互动视频生成的发展，从孤立的单一技术能力走向全方位的人工智能驱动的互动创作范式，为下一代创意工具、媒体和娱乐铺平了道路。"}
{"llm_update_time": "20250816", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.07171", "html_url": "https://arxiv.org/abs/2508.07171", "title": "EventRR: 事件参照推理用于引用视频对象分割", "title_en": "EventRR: Event Referential Reasoning for Referring Video Object Segmentation", "authors": "Huihui Xu,Jiashi Lin,Haoyu Chen,Junjun He,Lei Zhu", "background": "当前的引用视频对象分割（RVOS）方法将引用表达视为无结构的序列，忽略了其重要的语义结构，这对于参照推理至关重要。此外，与仅关注对象属性和对象-对象关系的图像引用表达式不同，视频引用表达式还包含了事件属性和事件-事件的时间关系。这种复杂性挑战着传统的结构化推理图像方法。", "innovation": "本文提出了一种事件参照推理（EventRR）框架，将RVOS拆分为对象总结部分和参照推理部分。对象总结阶段通过总结每帧为一组瓶颈标记，然后在视频级别总结步骤中高效地聚集，以交换全局跨模态时间上下文。推理部分中，EventRR将视频引用表达式的语义事件结构提取为高度表达性的参照事件图（REG），这是一个单根有向无环图。通过参照事件图（REG）的拓扑遍历，提出了时间概念-作用推理（TCRR），从REG叶节点到根节点累计每个时间查询的引用分数。每一个推理步骤都可以通过REG中的概念-作用关系解释为一个问答对。", "conclusion": "在四个广泛认可的基准数据集上的大量实验表明，EventRR在定量和定性上都优于最先进的RVOS方法。"}
{"llm_update_time": "20250816", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.08189", "html_url": "https://arxiv.org/abs/2508.08189", "title": "视觉强化学习：综述", "title_en": "Reinforcement Learning in Vision: A Survey", "authors": "Weijia Wu,Chen Gao,Joya Chen,Kevin Qinghong Lin,Qingwei Meng,Yiming Zhang,Yuke Qiu,Hong Zhou,Mike Zheng Shou", "background": "近期强化学习（RL）和视觉智能的交叉领域取得了显著进展，使智能体不仅能感知复杂的视觉场景，还能对场景进行推理、生成和行动。这篇综述旨在对这一领域进行批判性的综合。该文首先定义了视觉强化学习问题，并追踪策略优化策略从RLHF到可验证奖励范式的演变过程，以及从Proximal Policy Optimization到Group Relative Policy Optimization的发展历程。", "innovation": "文章将超过200项代表性工作分类为四个主题支柱：多模态大语言模型，视觉生成，统一模型框架，以及视觉-语言-行动模型。对每个支柱进行了算法设计、奖励工程、基准进展等方面的详细分析，并且提炼出了诸如 curriculum-driven 训练、preference-aligned 扩散和统一奖励模型等趋势。此外，还审查了评估协议，涵盖了集合级保真度、样本级偏好和状态级稳定性等方面，并识别了样本效率、泛化与安全部署等方面存在的挑战问题。", "conclusion": "文章旨在为研究者和实践者提供一个清晰的视觉强化学习迅速扩展领域的地图，并指出未来研究有希望的方向。官方资源可以在以下链接获取：this https URL"}
{"llm_update_time": "20250816", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.09178", "html_url": "https://arxiv.org/abs/2508.09178", "title": "IAD-R1: 在工业异常检测中强化一致推理", "title_en": "IAD-R1: Reinforcing Consistent Reasoning in Industrial Anomaly Detection", "authors": "Yanhui Li,Yunkang Cao,Chengliang Liu,Yuan Xiong,Xinghui Dong,Chao Huang", "background": "现代制造业中工业异常检测是一个关键部分，但缺陷样本的缺乏限制了传统检测方法的应用场景。尽管视觉-语言模型（VLMs）在泛化能力方面表现出显著优势，但在工业异常检测中的表现仍有限。", "innovation": "我们提出了一种名为IAD-R1的通用后训练框架，适用于不同架构和参数规模的VLMs，显著增强了其异常检测能力。IAD-R1采用两阶段训练策略：感知激活监督微调（PA-SFT）阶段利用精心构建的高质量链式思考数据集（Expert-AD）进行训练，增强异常感知能力并建立推理到答案的关联；结构化控制组相对策略优化（SC-GRPO）阶段通过精心设计的奖励函数实现从“异常感知”到“异常解释”的能力飞跃。实验结果显示，IAD-R1在7个VLMs上取得了显著改进，特别是在DAGM数据集上的改进最为明显，平均准确率比0.5B基线高出43.3%。值得注意的是，使用IAD-R1训练的0.5B参数模型在零样本情况下超越了包括GPT-4.1和Claude-Sonnet-4在内的商业模型，证明了IAD-R1的有效性和优越性。", "conclusion": "IAD-R1框架在多个VLMs上实现了显著改进，并在零样本设置下超越了商业模型，表明其在工业异常检测中的有效性和优越性。"}
{"llm_update_time": "20250816", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.09185", "html_url": "https://arxiv.org/abs/2508.09185", "title": "一种用于增强现实的认知攻击可解释检测的神经符号框架", "title_en": "A Neurosymbolic Framework for Interpretable Cognitive Attack Detection in Augmented Reality", "authors": "Rongqian Chen,Allison Andreyev,Yanming Xiu,Mahdi Imani,Bin Li,Maria Gorlatova,Gang Tan,Tian Lan", "background": "增强现实（AR）通过在物理世界叠加虚拟元素来丰富感知。由于AR日益普及，认知攻击已经引起广泛关注，这些攻击通过改变AR内容来操纵用户的语义感知。现有的检测方法多集中在视觉变化上，通常限制在像素或图像级别处理，缺乏语义推理能力，或者依赖于预训练的视觉-语言模型（VLMs），但以黑箱方式运作，缺乏可解释性。", "innovation": "本文提出了一种新的神经符号方法CADAR，用于AR中的认知攻击检测。该方法使用神经VLMs融合多模态视觉-语言输入，获得符号感知图表示，结合先验知识、显著性加权和时间相关性。通过基于粒子滤波的统计推理（一种顺序蒙特卡洛方法），能够检测认知攻击。从而，CADAR继承了预训练VLM的适应性和粒子滤波的可解释性和推理严谨性。实验结果表明，在挑战性的AR攻击场景中，CADAR的准确性相比强基线提高了10.7%，表明神经符号方法在认知攻击检测方面的潜力。", "conclusion": "在扩展的AR认知攻击数据集上进行的实验结果表明，CADAR在挑战性AR攻击场景中的准确性比强基线提高了10.7%，这突显了神经符号方法在有效且可解释的认知攻击检测方面的潜力。"}
{"llm_update_time": "20250816", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.05519", "html_url": "https://arxiv.org/abs/2508.05519", "title": "利用AI加速医学数据清理：基于AI辅助方法与传统方法的比较研究", "title_en": "Leveraging AI to Accelerate Medical Data Cleaning: A Comparative Study of AI-Assisted vs. Traditional Methods", "authors": "Matthew Purri,Amit Patel,Erik Deurrell", "background": "在药物研发过程中，临床试验数据清理是一个关键的瓶颈问题，手动审核过程难以应对不断增加的数据量和复杂性。", "innovation": "本文介绍了Octozi，一种结合了大规模语言模型和领域特定启发式的AI辅助平台，用于转化医学数据审查。在由10名经验丰富的医疗审核员参加的受控实验研究中，表明AI辅助提高了数据清理吞吐量6.03倍，同时将清理错误率从54.67%降低到8.48%（6.44倍的改善）。系统还减少了查询中的假阳性因素15.48倍，减轻了不必要的现场负担。对于一个代表性的III期肿瘤临床试验，经济分析显示潜在成本节省510万美元，主要通过数据库锁定时间缩短5天（节省440万美元）、提高医疗审查效率（节省42万美元）和减少查询管理负担（节省28.8万美元）实现。这些改进在不同经验水平的审核员中都是一致的，表明其广泛适用性。", "conclusion": "本文的研究表明，AI辅助方法可以解决临床试验操作中的根本性低效问题，例如将数据库锁定时间加速33%，同时维护合规性和显著降低成本。这项工作为将AI集成到关键的安全临床工作流程中建立了框架，并展示了在制药临床试验中人机协作的变革潜力。"}
{"llm_update_time": "20250816", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.06995", "html_url": "https://arxiv.org/abs/2508.06995", "title": "S2-UniSeg: 快速通用凝聚池化以实现大规模无监督分割", "title_en": "S2-UniSeg: Fast Universal Agglomerative Pooling for Scalable Segment Anything without Supervision", "authors": "Huihui Xu,Jin Ye,Hongqiu Wang,Changkai Ji,Jiashi Lin,Ming Hu,Ziyan Huang,Ying Chen,Chenglong Ma,Tianbin Li,Lihao Liu,Junjun He,Lei Zhu", "background": "近年来，自监督图像分割模型在语义分割和泛化实例分割方面取得了显著的成果。然而，它们的预训练计划是多阶段的，需要在每个训练周期之间进行耗时的伪标签生成过程。这一耗时的离线过程不仅难以随训练数据集规模扩展，还导致由于不连续的优化过程而产生亚优解。", "innovation": "论文首先提出了一种快速通用凝聚池化（Fast Universal Agglomerative Pooling，简称UniAP）新型伪标签算法，每层UniAP可以并行识别相似节点群，能在毫秒内生成语义级别、实例级别和多粒度的伪标签。基于快速UniAP，提出了一种可扩展的自监督通用分割模型（Scalable Self-Supervised Universal Segmentation，简称S2-UniSeg），该模型使用学生和动量教师进行连续预训练，并提出了一种面向分割的预训练任务Querywise Self-Distillation (QuerySD)。在相同的设置下，S2-UniSeg 在 COCO 上的 AP+6.9，UVO 上的 AR+11.1，COCOStuff-27 上的 PixelAcc+4.5，Cityscapes 上的 RQ+8.0 表现出相较于最新模型 UnSAM 的显著性能提升。并且，在扩展到更大的 SA-1B 数据集的 2M 图像子集后，S2-UniSeg 在所有四个基准上进一步取得了性能提升。", "conclusion": "S2-UniSeg 在高效的伪标签生成和连续预训练方面实现了重要突破，能够处理大规模数据集并达到优异的分割效果，为自监督图像分割的研究提供了新的方向。"}
{"llm_update_time": "20250816", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.08508", "html_url": "https://arxiv.org/abs/2508.08508", "title": "Re:Verse -- 能否让您的VLM读懂漫画？", "title_en": "Re:Verse -- Can Your VLM Read a Manga?", "authors": "Aaditya Baranwal,Madhav Kataria,Naitik Agrawal,Yogesh S Rawat,Shruti Vyas", "background": "当前的视觉语言模型（VLMs）在处理连续的视觉叙述故事时，在表层识别与深层次叙述推理之间存在关键差距。通过对漫画叙述的理解进行全面研究，我们发现虽然最新的大型多模态模型在单个分镜解读方面表现出色，但在时间因果性和跨分镜一致性方面系统地表现不佳，这些是连贯故事情理解的核心要求。我们介绍了一个结合细粒度多模态标注、跨模态嵌入分析和检索增强评估的新型评估框架，系统地刻画这些局限性。", "innovation": "我们提出了一个结合细粒度的多模态标注、跨模态嵌入分析和检索增强评估的新型评估框架。该方法包括(i)严格的注释协议，通过与光线小说文本对齐链接视觉元素到叙述结构，(ii) 多种推理范式的全面评估，包括直接推断和检索增强生成，以及(iii) 跨模态相似性分析揭示当前VLMs在联合表征中的基本错位。", "conclusion": "通过对Re:Zero漫画11章中的308个标注分镜开展系统的评估，我们发现当前模型缺乏真正的故事层面智能，特别在非线性叙述、角色连续性和长序列中的因果推理方面表现不佳。这项工作建立了评估叙述智能的基础和实用方法，同时为多模态模型在超越基本识别的离散视觉叙述中的深度序列理解提供了可操作的见解。"}
{"llm_update_time": "20250816", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.09524", "html_url": "https://arxiv.org/abs/2508.09524", "title": "SOI是根源之恶：量化和打破单目标跟踪中的相似目标干扰", "title_en": "SOI is the Root of All Evil: Quantifying and Breaking Similar Object Interference in Single Object Tracking", "authors": "Yipei Wang,Shiyu Hu,Shukun Jia,Panxi Xu,Hongfei Ma,Yiping Ma,Jing Zhang,Xiaobo Lu,Xin Zhao", "background": "本文详细探讨了长期以来被忽视但至关重要的单目标跟踪（SOT）中的相似目标干扰（SOI）瓶颈。通过受控的在线干扰屏蔽（OIM）实验，定量展示了消除干扰来源对所有SOTA跟踪器性能的显著提升，并且直接验证了SOI作为鲁棒跟踪主要约束的有效性，同时强调了外部认知引导的可能性。", "innovation": "1. 本文首次系统性研究和量化了SOI，这在单目标跟踪中被忽视但极为关键。\n2. 基于这些见解，提出了用于解决SOI问题的自然语言这一形式的外部引导，并构建了SOIBench——这是首个专门针对SOI挑战的认知语义引导基准。\n3. 使用大规模视觉-语言模型（VLM）作为外部认知引擎，并能无缝集成到任意RGB跟踪器中，提出了一种新的范式，展示了在语义认知引导下显著的性能提升。", "conclusion": "现有视觉-语言跟踪（VLT）方法未能有效利用语义认知引导，仅获得微小改进甚至性能下降（AUC变化从-0.26到+0.71）。相比之下，提出的基于大型视觉-语言模型的范式在语义认知引导下展示了显著改进（AUC提升高达0.93），这标志着对现有VLT方法的重要进展。SOIBench希望能成为一个标准化评价平台，推进语义认知跟踪研究，并为跟踪研究社区提供新的洞见。"}
{"llm_update_time": "20250816", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.09202", "html_url": "https://arxiv.org/abs/2508.09202", "title": "无源域适应中的个性化特征转换：一种高效的表情识别方法", "title_en": "Personalized Feature Translation for Expression Recognition: An Efficient Source-Free Domain Adaptation Method", "authors": "Masoumeh Sharafi,Soufiane Belharbi,Houssem Ben Salem,Ali Etemad,Alessandro Lameiras Koerich,Marco Pedersoli,Simon Bacon,Eric Granger", "background": "面部表情识别（FER）模型被应用于多种基于视频的情感计算应用，如人机交互和健康监测。然而，深度FER模型在处理细微表情和高个体间差异时常常表现不佳，限制了其在实际应用中的性能。为改善其性能，已经提出了无源域适应(SFDA)方法，通过仅使用目标域的未标注数据来个性化预训练模型，从而避免了数据隐私、存储和传输的限制。然而，当目标数据中仅包含中性表情且源数据不可用时，SFDA方法面临重大挑战，因为当前方法通常不适用于仅基于单一类别的目标数据。此外，通过模型生成非中性表情的面部图像可能会导致不稳定性并增加计算成本。因此，本文提出了个性化特征转换（PFT）方法，以解决无源域适应问题，并能在未使用源数据和图像合成的情况下，利用中性表达目标数据来优化模型。通过在潜在空间中进行转换，PFT避免了表情生成的复杂性和噪声，生成了优化于分类的可区分嵌入。", "innovation": "提出了一个轻量级的特征转换方法——个性化特征转换（PFT），在潜在空间中进行面部表情转换。这种方法能够避免传统方法在生成面部表情时的复杂性和不稳定性，通过在未使用源数据和图像合成的情况下适应中性目标数据，优化特定表情识别的分类嵌入。", "conclusion": "通过PFT方法，可以有效减少计算开销，减少对图像合成的需求，并仅适应模型的部分内容，提高了表情识别的精度和效率。"}
{"llm_update_time": "20250816", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.09626", "html_url": "https://arxiv.org/abs/2508.09626", "title": "Semantic-aware DropSplat: 适应性冗余高斯点去除的语义滴定点云法", "title_en": "Semantic-aware DropSplat: Adaptive Pruning of Redundant Gaussians for 3D Aerial-View Segmentation", "authors": "Xu Tang,Junan Jia,Yijing Wang,Jingjing Ma,Xiangrong Zhang", "background": "在3D航拍视角场景语义分割（3D-AVS-SS）任务中，传统方法难以处理由于尺度变化和结构遮挡导致的语义模糊性，这限制了分割的准确性和一致性。", "innovation": "本文提出了一种新颖的3D-AVS-SS方法，命名为SAD-Splat。该方法引入了一个高斯点滴落模块，将语义置信度估计与基于Hard Concrete分布的学习可变稀疏机制相结合。此外，SAD-Splat还包含了一个高置信度伪标签生成管道，利用2D基础模型增强监督，提高分割精度。为了进一步推动研究，引入了一个具有稀疏注释的复杂基准数据集：3D Aerial Semantic (3D-AS)。", "conclusion": "实验结果表明，SAD-Splat实现了分割准确性和表示紧凑性的良好平衡，提供了一种高效且可扩展的3D航拍场景理解解决方案。"}
{"llm_update_time": "20250816", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.09632", "html_url": "https://arxiv.org/abs/2508.09632", "title": "Preacher: Paper-to-Video Agentic System", "title_en": "Preacher: Paper-to-Video Agentic System", "authors": "Jingwei Liu,Ling Yang,Hao Luo,Fan Wang,Hongyan Li,Mengdi Wang", "background": "当前最先进的视频生成模型虽然具有潜力，但仍然受到局限：狭窄的上下文窗口、固定的视频时长、有限的风格多样性以及不能表达领域特定知识。这些限制影响了将研究论文转化为结构化视频摘要的效果，使得生成的视频摘要质量较低且缺乏多样性，难以充分传达研究的核心概念、方法和结论。", "innovation": "本文介绍了Preacher，这是第一个将论文转化为视频摘要的代理系统。Preacher采用自上而下的方法来分解、总结和重新阐述论文，然后自下而上地生成视频，将多种视频片段综合成一个连贯的摘要。为了解决跨模态表示的对齐问题，Preacher定义了关键场景并引入了渐进链式思维（P-CoT），实现了精细、迭代的规划。该系统能够在五个研究领域生成高质量的视频摘要，展示了超过当前视频生成模型的专长。", "conclusion": "Preacher成功地克服了现有视频生成模型的限制，能够有效生成高质量的论文视频摘要，并证明了其在多个领域的广泛应用潜力。"}
{"llm_update_time": "20250816", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.09560", "html_url": "https://arxiv.org/abs/2508.09560", "title": "WeatherPrompt: 多模态表示学习以实现全天气无人机视觉地理定位", "title_en": "WeatherPrompt: Multi-modality Representation Learning for All-Weather Drone Visual Geo-Localization", "authors": "Jiahao Wen,Hang Yu,Zhedong Zheng", "background": "无人机在面临恶劣天气（如雨、雾等）时，现有视觉定位方法效果会大幅下降，主要因为对天气类别依赖较强且难以区分天气与场景特征。现有方法主要存在两大局限性：一是仅依赖有限的天气分类，制约了泛化能力；二是通过伪天气类型难以有效地将场景与天气特征分离，导致性能降低。为解决这些问题，本研究提出了一种多模态学习框架（WeatherPrompt），其通过将图像嵌入与文本上下文融合，建立天气不变的表示方法。", "innovation": "WeatherPrompt框架包含两个主要贡献：一是无需训练的天气推理机制，利用现成的大型多模态模型生成类似于人类的多天气文本描述，提高了对未见过或复杂天气的适应性，并能反映不同强度的天气；二是多模态框架内提出的动态门控机制，通过文本嵌入驱动视觉特征的自适应加权和融合，进一步优化了多模态融合过程。该框架通过跨模态目标，如图像-文本对比学习和匹配学习，优化了视图特征的融合，从而增强了不同天气条件下同一场景的表示接近度。", "conclusion": "通过广泛的实验验证，WeatherPrompt方法在各种天气条件下表现出竞争力，并且在夜间和雾、雪等特定恶劣天气条件下，能够大幅提高无人机视觉地理定位的性能，尤其是在雾、雪天气下，Recall@1提高了18.69%，夜间场景提高了13.37%。"}
{"llm_update_time": "20250816", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2111.04578", "html_url": "https://arxiv.org/abs/2111.04578", "title": "神经网络中fine-tuning的改进正则化与鲁棒性", "title_en": "Improved Regularization and Robustness for Fine-tuning in Neural Networks", "authors": "Dongyue Li,Hongyang R. Zhang", "background": "迁移学习中，常用的算法是微调，即将预训练模型在目标任务上进行微调，以少量标注数据来适应新的任务。当预训练模型的容量远大于目标数据集的大小时，微调容易导致过拟合和记忆训练标签。因此，如何正则化微调以增强其鲁棒性是关键问题。", "innovation": "本文首先分析了微调的泛化特性，并提出了一个依赖于每一层在微调过程中移动距离和微调模型噪声稳定性的一般一致性贝叶斯泛化界。基于此分析，提出了正则化自我标记方法（Regularized Self-Labeling），这是一种正则化与自我标记方法的插值，包括层间正则化以限制每一层移动的距离，以及自我标签纠正和标签重新加权以纠正模型自信的错误标签并将不自信的数据点重新加权。该方法在多个预训练模型架构上对图像和文本数据集进行了验证，结果表明，对于七个图像分类任务，该方法的平均改善率为1.76%，对于少量训练任务，为0.75%。当目标数据集包含噪声标签时，在两种噪声环境下，该方法的平均改善率分别为3.56%。", "conclusion": "本研究通过提出包括层间正则化与自我标签纠正在内的新方法，显著提高了微调在存在噪声标签情况下的鲁棒性和性能，在多个任务和数据集上验证了方法的有效性。"}
{"llm_update_time": "20250816", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2408.08555", "html_url": "https://arxiv.org/abs/2408.08555", "title": "使用环形扫描模式LiDAR进行MAVs检测与跟踪", "title_en": "Detection and Tracking of MAVs Using a Rosette Scanning Pattern LiDAR", "authors": "Sándor Gazdag,Tom Möller,Anita Keszler,András L. Majdik", "background": "近年来，商用微型空中车辆（MAVs）的应用日益增多，为社会带来了诸多益处，但也带来了诸如航空空间违规和隐私权等方面的潜在风险。由于安全性风险的上升，开发自主无人机检测与跟踪系统的研发迫在眉睫。", "innovation": "本文通过采用非重复式环形扫描模式LiDAR构建的检测与跟踪系统，利用传感器特性增加检测距离，并结合粒子滤波和速度分量进行无人机检测与跟踪，具备重新检测功能。利用俯仰扫描平台，使追踪目标保持在测量最密集的中心位置，增强了系统的检测能力和准确性。通过室内和室外实验验证了系统的检测距离和准确性，相比于现有技术和方法，检测距离提高了约80%。", "conclusion": "本研究提出的方法在室内测试中实现了与当前先进方法相同的准确性，并在室外测试中将最大检测范围提高了约80%，从而展示了基于环形扫描模式LiDAR的检测与跟踪系统的有效性和优越性。"}
{"llm_update_time": "20250816", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2409.07275", "html_url": "https://arxiv.org/abs/2409.07275", "title": "通过隐式正则化实现无调参的在线鲁棒主成分分析", "title_en": "Tuning-Free Online Robust Principal Component Analysis through Implicit Regularization", "authors": "Lakshmi Jayalal,Gokularam Muthukrishnan,Sheetal Kalyani", "background": "标准的在线鲁棒主成分分析(OR-PCA)技术的表现依赖于显式正则化参数的最佳调整，这些参数对数据集敏感。因此，该方法依赖于这些参数的调优，这限制了其在大规模数据集上的应用效率和普适性。", "innovation": "本文提出了通过使用隐式正则化效应来无调参实现ON-PCA。这种方法利用了三种不同的修改梯度下降版本，分别并自然地促进数据中的稀疏性和低秩结构。相较于调优后的OR-PCA，该方法在模拟能力和真实世界数据集上表现相似或更好，使得ORPCA更为适用于大规模数据集，无需依赖于数据集特定的参数调优。", "conclusion": "本文提出的方法不需要调优即可实现在线鲁棒主成分分析，提高了该方法的普适性和可扩展性，特别适用于大规模数据集。"}
{"llm_update_time": "20250816", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.09584", "html_url": "https://arxiv.org/abs/2508.09584", "title": "SHALE: 一个用于LVLM细粒度幻觉评估的可扩展基准", "title_en": "SHALE: A Scalable Benchmark for Fine-grained Hallucination Evaluation in LVLMs", "authors": "Bei Yan,Zhiyuan Chen,Yuecong Min,Jie Zhang,Jiahao Wang,Xiaozhen Wang,Shiguang Shan", "background": "尽管大型视觉-语言模型（LVLMs）取得了快速进展，但这些模型仍然存在幻觉问题，即生成与输入或已建立的世界知识不一致的内容，这分别对应于忠实度幻觉和事实性幻觉。以往的研究主要在较为粗糙的层面（如对象层面）评估忠实度幻觉，缺乏细致的分析。此外，现有基准通常依赖昂贵的手动整理数据或重用公开的数据集，这引起了可扩展性及数据泄露的担忧。上述问题限制了LVLMs的性能评估与改进。", "innovation": "本文提出了一个自动化的数据构造流水线，以生成可扩展、可控、多样化的评价数据。同时设计了层级幻觉诱导框架，通过输入干扰模拟现实的嘈杂场景。整合上述设计，构建了SHALE，这是一个用于评估LVLMs忠实度和事实性幻觉的新基准，通过细致的幻觉分类方案来进行评估。SHALE包含了超过30000个图像指令对，涵盖了12个代表性视觉感知方面以及6个知识领域，考虑了干净和嘈杂场景。对20多个主流LVLMs进行的大量实验揭示了显著的事实性幻觉现象，并认为此模型对于语义干扰非常敏感。", "conclusion": "SHALE是第一个专门针对LVLMs的可扩展、精细划分的幻觉评估基准，旨在全面评估模型的忠实度和事实性幻觉问题，为后续研究提供有效评价工具。"}
{"llm_update_time": "20250816", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2412.07676", "html_url": "https://arxiv.org/abs/2412.07676", "title": "Si/SiGe 多量子点设备的启动、自主测试和初始化系统", "title_en": "Bootstrapping, Autonomous Testing, and Initialization System for Si/SiGe Multi-quantum Dot Devices", "authors": "Tyler J. Kovach,Daniel Schug,M. A. Wolfe,E. R. MacQuarrie,Patrick J. Walsh,Owen M. Eskandari,Jared Benson,Mark Friesen,M. A. Eriksson,Justyna P. Zwolak", "background": "半导体量子点(QD)设备在基于自旋的量子计算方面取得了进步，但复杂性增加的现代QD设备在提高温度下的校准和控制成为进展的瓶颈。这种复杂性导致了氧化层内的捕获电荷，进而引起栅极电位的随机偏移，使得大规模量子点位元的表征和调整依赖于自动化协议。", "innovation": "作者提出了一种名为BATIS（Bootstrapping Autonomous Testing and Initialization System）的物理直觉框架，用于导通多量子点设备的测试和初始化。该系统能够自动化关键步骤，如漏电测试、形成所有电流通道和栅极表征。BATIS还采用了一种非标准方法来形成电流通道，这种方法不需要根据通道数量进行额外测量。该系统在低温环境下消除了深冷环境的需求，显著提高了规模化和减少了设置时间。", "conclusion": "BATIS是一种平台通用的解决方案，适用于各种QD系统，填补了QD自动调校的关键缺口，仅需少量的设备架构先验知识即可实现。"}
{"llm_update_time": "20250816", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2411.19134", "html_url": "https://arxiv.org/abs/2411.19134", "title": "考虑多种运动模型的视觉SLAMMOT", "title_en": "Visual SLAMMOT Considering Multiple Motion Models", "authors": "Peilin Tian,Hao Li", "background": "SLAM和MOT是自动驾驶领域的关键任务，虽然SLAM专注于创建实时地图和确定车辆在未知环境中的位姿，而MOT侧重于实时识别和跟踪多个动态物体，但目前这些任务通常被当作独立模块处理，导致局限性。现有的SLAM方法多基于静态环境假设，适用于室内场景，而非动态户外环境；传统的MOT技术则依赖于车辆已知状态，限制了基于其状态估计对象状态的准确性。为解决这些问题，已有方法引入了统一的SLAMMOT框架，但主要集中在简单的运动模式上。先前的研究，包括团队的IMM-SLAMMOT工作，提出了结合多种运动模型的SLAMMOT方法，证实了其在基于LiDAR的系统中的有效性。本论文研究了将该方法扩展到视觉SLAMMOT的可行性和优势，填补了LiDAR和视觉得感技术之间的差距。", "innovation": "引入了考虑多种运动模型的统一SLAMMOT框架，并将其应用于视觉SLAMMOT中，以提高在动态环境下的实时定位和多目标跟踪的准确性和效率。", "conclusion": "通过引入考虑多种运动模型的视觉SLAMMOT方法，提出了一个全新的解决动态环境下的SLAM和MOT问题的方案，验证了它在视觉域中的优势和潜在的广泛应用前景。"}
{"llm_update_time": "20250816", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2401.00873", "html_url": "https://arxiv.org/abs/2401.00873", "title": "统一自我监督聚类和能量模型", "title_en": "Unifying Self-Supervised Clustering and Energy-Based Models", "authors": "Emanuele Sansone,Robin Manhaeve", "background": "自我监督学习可以从大量数据中学习表示，而生成模型可以学习数据生成过程的信息。本文旨在建立这两种范式的理论联系，并强调它们互补性的好处。具体而言，通过分析自我监督学习目标，揭示其潜在的概率图模型，并提出从第一原理推导出规范方法的标准流程。分析建议了一种自然地将自我监督学习与基于似然的生成模型集成的方法。研究在基于簇的自我监督学习和能量模型的领域中实例化了这一概念，并提出了一种下界，能够可靠地惩罚最重要的失败模式，实现全面统一。", "innovation": "引入基于簇的自我监督学习和能量模型的概念，并提出了一种下界方法，能够可靠地惩罚最重要的失败模式，从而实现了全面统一。该方法被验证能够同时在判别和生成方面训练主干网络，表现出色，超出现有自我监督学习策略在聚类、生成和检测方面的性能。此外，该解决方案可以集成到神经符号框架中，解决符号接地问题的一个简单但复杂的实例。", "conclusion": "通过实验在合成和真实数据上（包括SVHN、CIFAR10和CIFAR100）验证了理论发现，从而证明了该目标函数使模型能够在判别和生成方面同时训练，表现出色。提供的代码可以在公共网址访问。"}
{"llm_update_time": "20250816", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2412.02012", "html_url": "https://arxiv.org/abs/2412.02012", "title": "INSIGHT: 可解释的弱监督医学图像分析", "title_en": "INSIGHT: Explainable Weakly-Supervised Medical Image Analysis", "authors": "Wenbo Zhang,Junyu Chen,Christopher Kanan", "background": "由于体积庞大的三维扫描和全切片病理图像（WSIs）的处理需要提取局部区域的嵌入表示，然后通过聚合器进行预测，当前的方法往往依赖于后验可视化技术（例如 Grad-CAM），并常无法定位到小但临床上至关重要的细节。这限制了现有方法的临床应用效果和精确度，尤其是在诊断小而关键的病变方面表现不足。", "innovation": "本文提出了一种名为 INSIGHT 的新型弱监督聚合器，它将 heatmap 生成作为推理偏向。INSIGHT 从预训练的特征图开始，利用带有小卷积核的检测模块捕捉细部特征，并使用具有较广感受野的上下文模块抑制局部假阳性。这种方法有助于高亮出诊断上相关的区域，从而提高了图像分析的准确性和临床解释性，特别是在 CT 和 WSI 领域的评估中表现突出，达到了最新的分类和弱监督语义分割性能。", "conclusion": "INSIGHT 在 CT 和 WSI 的基准测试中取得了最先进的分类结果和高弱监督语义分割性能。这种方法不仅增强了图像分析的准确性，还能生成可解释的 heatmap，帮助医生更好地理解图像和作出诊断。"}
{"llm_update_time": "20250816", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2504.06866", "html_url": "https://arxiv.org/abs/2504.06866", "title": "GraspClutter6D: 一个用于杂乱场景中稳健感知与夹爪操作的大规模真实世界数据集", "title_en": "GraspClutter6D: A Large-scale Real-world Dataset for Robust Perception and Grasping in Cluttered Scenes", "authors": "Seunghyeok Back,Joosoon Lee,Kangmin Kim,Heeseon Rho,Geonhyup Lee,Raeyoung Kang,Sangbeom Lee,Sangjun Noh,Youngjin Lee,Taeyeop Lee,Kyoobin Lee", "background": "在杂乱环境中进行稳健抓取仍然是机器人领域的一个开放性挑战。现有的基准数据集虽然极大地推进了深度学习方法的发展，但它们主要聚焦于简单场景且存在轻度遮挡，缺乏多样性，这限制了它们在实际应用场景中的适用性。", "innovation": "提出GraspClutter6D数据集，包含1000个复杂排列（每场景14.1个物体，62.6%遮挡）、全面覆盖200个物体在75种环境配置中的场景，并使用四台RGB-D相机从多个视角进行采集。数据集提供了详尽的注释包括73.6万6D物体姿态和93亿可行机器人夹爪方案，覆盖52000张RGB-D图像。通过对最先进的分割、物体姿态估计和夹爪检测方法进行基准测试，提供了杂乱环境中关键挑战的见解。此外，验证了数据集作为训练资源的有效性，证明了基于GraspClutter6D训练的抓取网络在模拟和真实世界实验中显著优于现有数据集训练的网络。", "conclusion": "GraspClutter6D数据集可供公众访问，作为训练资源证明了其有效性。"}
{"llm_update_time": "20250816", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2503.11509", "html_url": "https://arxiv.org/abs/2503.11509", "title": "TikZero：零样本文本指导下的图形程序合成", "title_en": "TikZero: Zero-Shot Text-Guided Graphics Program Synthesis", "authors": "Jonas Belouadi,Eddy Ilg,Margret Keuper,Hideki Tanaka,Masao Utiyama,Raj Dabre,Steffen Eger,Simone Paolo Ponzetto", "background": "从文本说明自动合成图形是一种强大的功能。然而，实现高几何精度和编辑性要求将图形表示为像TikZ这样的图形程序，并且对齐的训练数据（即带有说明的图形程序）仍然稀缺。同时，大量未对齐的图形程序和带图说明的位图图像更易于获取。本文通过提出TikZero方法，解决了这些不同的数据来源差异。TikZero通过使用图像表示作为中介桥梁来分离图形程序生成和文本理解，使得可以在独立的数据集上分别训练图形程序和带图说明的位图图像，同时在推断过程中能够零样本地生成文本指导下的图形程序。实验结果表明，该方法在仅依赖对齐的图形程序进行操作的情况下，大幅度超过了基准模型。而且当利用对齐的图形程序作为补充训练信号时，TikZero的性能与更大模型相当或优于，包括商业系统GPT-4o在内的许多系统.", "innovation": "提出了一种名为TikZero的方法，通过使用图像表示作为中介桥梁来隔离开图形程序生成和文本理解。这种方法允许独立训练图形程序和带图说明的位图图像，并能够在推断过程中进行零样本的文本指导下的图形程序合成。展示了在无对齐数据集上的有效性和性能超越之前的基准模型，甚至在结合对齐的图形程序进行互补训练信号时，能够与大规模模型或商业系统GPT-4o相媲美.", "conclusion": "本文展示了TikZero方法在自动从文本生成图形程序方面取得了卓越的性能。该方法充分利用了未对齐的数据集，并且在推断过程中无需对齐的图形程序也能实现良好的结果。总的来说，TikZero代表了一种新的训练和合成方法，能够广泛应用于需要图形程序自动合成的场景。相关代码、数据集和模型已公开提供."}
{"llm_update_time": "20250816", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.09543", "html_url": "https://arxiv.org/abs/2508.09543", "title": "迭代体素融合在不对称立体匹配中的应用", "title_en": "Iterative Volume Fusion for Asymmetric Stereo Matching", "authors": "Yuanting Gao,Linghao Shen", "background": "立体匹配在3D计算机视觉中非常重要，大多数算法假设双眼视觉具有对称的视觉特性。然而，不对称多摄像头系统的兴起（例如，远摄宽视角摄像头）挑战了这一假设，使立体匹配变得复杂。不对称性影响了关键的成本体积计算，从而干扰了立体匹配。为解决此问题，研究者探索了两种已建立的成本体积构建方法在不对称立体匹配中的匹配代价分布。研究表明，每种成本体积都经历了独特的信息失真，因此两种方法都应综合使用以解决此问题。", "innovation": "提出了适用于不对称立体匹配的两阶段迭代体素融合网络（IVF-AStereo）。首先，聚合拼接体积细化相关体积；然后，两个体积融合以增强细部信息。该方法在不对称场景中表现出色，并能抵抗显著的视觉不对称性。在基准数据集上的广泛对比实验和消融研究确认了该方法在不对称立体匹配中的有效性，尤其是在分辨率和颜色退化的情况下。", "conclusion": "相比于传统的立体匹配方法，IVF-AStereo通过两阶段的迭代体素融合显著提升了对不对称场景的适应性和鲁棒性。该方法结合了多个成本体积的信息，增强了细部特征，从而有效解决了视觉不对称性带来的问题。"}
{"llm_update_time": "20250816", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2503.06795", "html_url": "https://arxiv.org/abs/2503.06795", "title": "基于解剖代表性模拟器的机器人超声引导股动脉重建", "title_en": "Robotic Ultrasound-Guided Femoral Artery Reconstruction of Anatomically-Representative Phantoms", "authors": "Lidia Al-Zogbi,Deepak Raina,Vinciya Pandian,Thorsten Fleiter,Axel Krieger", "background": "股动脉接入对于多种临床程序至关重要，包括诊断性血管造影、治疗性导管插入和紧急干预。尽管重要，但成功血管接入仍因解剖变异、覆盖的脂肪组织以及需要精确的超声（US）引导而具有挑战性。针头放置错误可能导致严重并发症，因此限制了该操作仅限于在受控医院环境中操作的高技能临床医生。虽然机器人系统通过自主扫描和血管重建展示了缓解这些挑战的潜力，但临床转化因其依赖于不能捕捉到人类解剖复杂性的简化仿生模型而受到限制。本研究中，我们提出了一种方法用于对股动脉分叉区进行自主机器人超声扫描，并且在使用来自实际患者CT数据的五个血管仿生模型上进行了验证。此外，我们引入了一种针对血管成像的基于视频的深度学习US分割网络，以提高3D动脉重建效果。", "innovation": "我们提出了用于股动脉分叉区的自主机器人超声扫描方法，并使用来自五个实际患者CT数据的血管仿生模型进行了验证。还引入了一种针对血管成像的基于视频的深度学习US分割网络，提高了3D动脉重建效果，实现在新血管数据集上的Dice分数为89.21%，交并比为80.54%。此外，这种方法是首次在多样化的患者特异性仿生模型上验证自主机器人系统用于股动脉的超声扫描，为评估机器人在血管成像和介入中的性能引入了更先进的框架。", "conclusion": "该研究验证了使用患者特异性仿生模型对股动脉进行自主超声扫描的机器人系统，并展示了更先进的框架用于血管成像和介入评估，逼近了真实的临床应用。"}
{"llm_update_time": "20250816", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.10111", "html_url": "https://arxiv.org/abs/2508.10111", "title": "使用上下文无关文法的扩散LLM受限解码", "title_en": "Constrained Decoding of Diffusion LLMs with Context-Free Grammars", "authors": "Niels Mündler,Jasper Dekoninck,Martin Vechev", "background": "大规模语言模型（LLMs）已在多个领域取得了有希望的表现。诸如代码补全和结构化数据提取等实际应用需要遵循由正式语言指定的语法规则。然而，由于其概率性质，LLM的输出并不保证会遵循这些正式语言。已有研究提出了受限解码的方法来限制LLM生成特定形式语言的内容。但是，现有的方法在应用于新兴的扩散LLM模型时，在诸如生成正确的C++或JSON输出的实际场景下并不适用。本文旨在解决这一挑战，并提出首个处理由上下文无关文法捕获的形式语言的受限解码方法。", "innovation": "将受限解码问题转化为更一般的加性填充问题，该问题询问部分输出能否被完成为在目标语言中的有效单词。本文还将其转化为判定目标语言和正则语言交集为空的问题，并提出了解决上下文无关语言的高效算法。实验结果在各种应用中，如C++代码填充和JSON中的结构化数据提取，表明该方法在保持或提高功能正确性的同时实现了近完美的语法正确性。此外，效率优化确保了计算开销保持在实际可接受的水平。", "conclusion": "本文提出了一种处理由上下文无关文法定义的形式语言的受限解码方法，该方法可以在给定的实际应用中生成准确的输出。通过高效的算法和优化，该方法在保持文本功能正确性的前提下显著提高了语法正确性，且计算开销可控，具有实际应用价值。"}
{"llm_update_time": "20250816", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.03184", "html_url": "https://arxiv.org/abs/2507.03184", "title": "EvRWKV: 一种有效的事件引导低光图像增强连续交互RWKV框架", "title_en": "EvRWKV: A Continuous Interactive RWKV Framework for Effective Event-Guided Low-Light Image Enhancement", "authors": "Wenjie Cai,Qingguo Meng,Zhenyu Wang,Xingbo Dong,Zhe Jin", "background": "在低光照条件下捕获高质视觉内容是一个挑战，因为严重的噪声和曝光不足会降低下游应用的性能。传统的帧基低光图像增强方法经常放大噪声或无法保留结构细节。事件相机通过异步捕捉亮度变化，提供高动态范围和微秒级的时空分辨率，成为低光成像的补充。然而，现有的融合方法未能充分利用这种协同效应，要么过早将模式强制统一到共享表示中，要么通过独立处理而失去重要的低级相关性。为此，提出了一种名为EvRWKV的新框架，通过双域处理实现连续的跨模态交互。该框架利用RWKV架构的Receptance Weighted Key Value (RWKV)模块进行细粒度的时间和跨模态融合，以及Event Image Spectral Fusion Enhancer (EISFE)模块，该模块联合执行自适应频域噪声抑制和空间域可变形卷积对齐，以保持从低级纹理到高级语义的一致性特征。", "innovation": "该研究提出了一种名为EvRWKV的新框架，利用RWKV架构的Receptance Weighted Key Value (RWKV)模块实现细粒度的时间和跨模态融合，以及一个同时执行自适应频域噪声抑制和空间域可变形卷积对齐的Event Image Spectral Fusion Enhancer (EISFE)模块。该框架旨在实现连续的跨模态交互，从而维护从低级纹理到高级语义的一致性特征，以应对低光照条件下的挑战。实验结果表明，EvRWKV在真实低光数据集（SDE、SDSD、RELED）中实现了最先进的性能，有效地增强了图像质量，抑制了噪声，恢复了结构细节，并提高了视觉清晰度。", "conclusion": "EvRWKV框架通过双域处理实现了连续的跨模态交互，使用RWKV架构和EISFE模块，有效地解决了传统低光图象增强方法存在的问题。实验验证了其在低光照条件下实现优异性能的能力，有效改善了低光照环境下图像的质量。"}
{"llm_update_time": "20250816", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.10053", "html_url": "https://arxiv.org/abs/2508.10053", "title": "xRFM：用于表数据的准确、可扩展和可解释的特征学习模型", "title_en": "xRFM: Accurate, scalable, and interpretable feature learning models for tabular data", "authors": "Daniel Beaglehole,David Holzmüller,Adityanarayanan Radhakrishnan,Mikhail Belkin", "background": "表数据是由连续和分类变量组成的矩阵集合，是现代科技和科学的基础。虽然其他领域的人工智能技术迅速发展，但这些预测任务的最佳实践变化不大，仍然主要基于梯度提升决策树（GBDT）。近年来，神经网络和特征学习方法的新进展引发了对处理表数据的高级方法的兴趣。这项工作旨在介绍一种结合特征学习核机与树结构的新算法xRFM，该算法能够适应数据的局部结构，并能够处理大量训练数据。", "innovation": "xRFM算法将特征学习核机与树结构相结合，既能适应数据的局部结构，又能扩展到几乎无限的训练数据量。xRFM在100个回归数据集上表现出最佳性能，并在200个分类数据集上的表现不低于最优方法，同时在解释性方面还提供了内置的可解释性（通过平均梯度外积）。", "conclusion": "与31种其他方法相比，包括最近推出的表数据基础模型（TabPFNv2）和GBDT，xRFM在回归任务中取得了最好的性能，并在分类任务中表现与最佳方法相当或更好，同时提供了内置的解释性。"}
{"llm_update_time": "20250816", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.10063", "html_url": "https://arxiv.org/abs/2508.10063", "title": "衡量时间序列预测稳定性的需求计划", "title_en": "Measuring Time Series Forecast Stability for Demand Planning", "authors": "Steven Klee,Yuntian Xia", "background": "时间序列预测是生成供应链需求计划的关键第一步。现有的时间序列模型实验通常关注展示相对于基线模型的预测精度改进，并通过一定的精度指标来量化进步。然而，在实际生产系统中，需求规划者往往更看重一致性和稳定性，而不是每一次预测精度上的微小提升。如果输入数据没有显著变化，但在不同规划周期内预测结果变化很大，将需要大量的手动干预，这会让需求规划者感到沮丧，甚至会降低他们对机器学习预测模型的信任度。本文研究由模型引入的随机性，即在输入固定的情况下，由单个模型生成的预测值的方差大小。方差较小的模型更加稳定。近年来，时间序列预测的准确性通过深度机器学习模型的发展显著提高。本文通过在M5竞赛公共数据集和Favorita超市销售数据上对当前最先进的时间序列预测模型（Chronos、DeepAR、PatchTST、Temporal Fusion Transformer、TiDE和AutoGluon最佳质量组合模型）进行实证研究，来衡量这些模型的稳定性和准确性。", "innovation": "本文展示了集成模型在提高稳定性的同时，不会显著降低（甚至可能改善）预测精度。这一结果揭示了在实际生产系统中部署的模型稳定性研究的必要性，强调了稳定性在实际应用中的重要性，为改进实际供应链中的预测模型提供了新的视角。", "conclusion": "这些现状结果并不出人意料，但本文的主要贡献在于，强调了对即将部署在实际生产系统的预测模型进行稳定性进一步研究的必要性。"}
{"llm_update_time": "20250816", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.10115", "html_url": "https://arxiv.org/abs/2508.10115", "title": "只需LLM即可：通过仅使用LLM学习图任务", "title_en": "Less is More: Learning Graph Tasks with Just LLMs", "authors": "Sola Shirai,Kavitha Srinivas,Julian Dolby,Michael Katz,Horst Samulowitz,Shirin Sohrabi", "background": "对于大型语言模型（LLMs），图推理可以解决许多问题。前期工作通过研究如何最好地将图序列化为文本以及结合GNNs和LLMs来改善LLMs的图推理能力，但这些方法的优势尚不明确。", "innovation": "本文通过实证研究回答了三个问题：(1) LLMs是否能够在没有专门的图编码模型的情况下学习解决基本的图任务？(2) LLMs是否能够在未经见的图结构或任务上泛化学习到的解决方案？(3) 不同学习图任务方法的优点是什么？研究发现，即使是小型LLMs，通过使用指导性的链式思维解决方案进行训练，也能学习解决图任务，并且这种训练无需专门的图编码器即可推广到新的任务和图结构。", "conclusion": "研究结果表明，LLMs能够在没有专门图编码器的情况下学习解决图任务，并且这种训练能够推广到新的任务和图结构。"}
{"llm_update_time": "20250816", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.10060", "html_url": "https://arxiv.org/abs/2508.10060", "title": "使用强化学习的个性化锻炼助手（PEARL）：四项随机对照试验的结果", "title_en": "A Personalized Exercise Assistant using Reinforcement Learning (PEARL): Results from a four-arm Randomized-controlled Trial", "authors": "Amy Armento Lee,Narayan Hegde,Nina Deliu,Emily Rosenzweig,Arun Suggala,Sriram Lakshminarasimhan,Qian He,John Hernandez,Martin Seneviratne,Rahul Singh,Pradnesh Kalkar,Karthikeyan Shanmugam,Aravindan Raghuveer,Abhimanyu Singh,My Nguyen,James Taylor,Jatin Alla,Sofia S. Villar,Hulya Emir-Farinas", "background": "全球普遍存在物理活动不足的问题，移动健康（mHealth）干预，尤其是即时调整干预（JITAIs），为大规模、个性化身体活动（PA）推广提供了有希望的途径。然而，要规模化开发和评估这些干预措施，涉及强大的行为科学，提出了方法论上的挑战。因此，首次进行了PEARL研究，该项大型四项随机对照试验评估了基于强化学习（RL）算法的人体活动促进策略，该算法针对Fitbit应用中的身体活动提示内容和时机进行了个人化调整。", "innovation": "这项研究是全球首批大规模随机对照试验之一，涉及四个不同的干预组，包括随机、固定和基于强化学习算法的个性化组别。使用强化学习算法根据行为科学理论来个性化复制行为改变理论中的身体活动提示，并在Fitbit应用中进行实时调整，是这一研究的主要创新点。其成功在于展示了强化学习算法在促进身体活动中的潜在价值和可行性，特别是在数字健康干预和个人化预调方面的应用。", "conclusion": "研究表明，在控制群和其他对照组成员中，使用强化学习算法的干预组成员每天的步行步数显著增加，尤其是在一个月的研究期间。这些结果强调了基于行为科学的强化学习方法在设计大规模、可扩展的个性化数字健康干预措施方面可能带来的重要影响和潜在好处。使用这一方法不仅可以促进日常身体活动，还可以为有较高身体活动需求的人群提供一种有效的生活方式干预方案。"}
{"llm_update_time": "20250816", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.09123", "html_url": "https://arxiv.org/abs/2508.09123", "title": "OpenCUA: 开放式计算机使用代理的基础", "title_en": "OpenCUA: Open Foundations for Computer-Use Agents", "authors": "Xinyuan Wang,Bowen Wang,Dunjie Lu,Junlin Yang,Tianbao Xie,Junli Wang,Jiaqi Deng,Xiaole Guo,Yiheng Xu,Chen Henry Wu,Zhennan Shen,Zhuokai Li,Ryan Li,Xiaochuan Li,Junda Chen,Boyuan Zheng,Peihang Li,Fangyu Lei,Ruisheng Cao,Yeqiao Fu,Dongchan Shin,Martin Shin,Jiarui Hu,Yuyan Wang,Jixuan Chen,Yuxiao Ye,Danyang Zhang,Dikang Du,Hao Hu,Huarong Chen,Zaida Zhou,Haotian Yao,Ziwei Chen,Qizheng Gu,Yipu Wang,Heng Wang,Diyi Yang,Victor Zhong,Flood Sung,Y.Charles,Zhilin Yang,Tao Yu", "background": "视觉语言模型作为计算机使用代理(CUAs)已显示出强大的能力，能够自动化各种计算机任务。随着其商业潜力的扩大，最先进的CUA系统的关键细节依然封闭。这些代理将越来越多地调解数字互动并代表我们执行重要决策，因此研究界需要访问开放的CUA框架来研究其能力和风险。鉴于此，本研究提出了OpenCUA，一个全面的开源框架，旨在扩展CUA数据和基础模型的规模，包含：一个注释基础设施，可以无缝地捕捉人类的计算机使用演示；AgentNet，一个涵盖3个操作系统和200多个应用程序及网站的大规模计算机使用任务数据集；一个可扩展的管道，将演示转化为具有反思性的长效推理的状态-动作对，以保持性能随数据规模增长而提升。我们端到端的代理模型在CUA基准测试中表现出强劲的性能。特别地，OpenCUA-32B在OSWorld-Verified上平均成功率达到了34.8%，成为开源模型的新最佳性能，并超过了OpenAI CUA (GPT-4o)。进一步分析证实，我们的方法在不同领域中具有良好的一般化，并且能够从测试时计算的增加中获益。我们的注释工具、数据集、代码和模型已被公布，以建立进一步CUA研究的开放基础", "innovation": "① 提出了OpenCUA，一个全面的开源框架，用于扩展CUA数据和基础模型的规模。② 包含AgentNet，首个涵盖广泛操作系统的计算机使用任务大数据集。③ 一个可扩展的管道，能够将演示转化为具有长效推理的状态-动作对，以确保性能随数据规模增长而提升。④ OpenCUA-32B在OSWorld-Verified基准测试中平均成功率达到了34.8%，成为开源模型的新最佳性能，并超过OpenAI CUA (GPT-4o)。", "conclusion": "我们展示了OpenCUA-32B在CUA基准测试中的出色性能，并证明了我们的方法在不同领域中具有良好的一般化能力，同时能够从测试时计算的增加中获益。我们已公布了注释工具、数据集、代码和模型，以促进进一步的CUA研究。"}
{"llm_update_time": "20250816", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.10154", "html_url": "https://arxiv.org/abs/2508.10154", "title": "分析期望最大化估计在过度指定混合线性回归中的演变特征", "title_en": "Characterizing Evolution in Expectation-Maximization Estimates for Overspecified Mixed Linear Regression", "authors": "Zhankun Luo,Abolfazl Hashemi", "background": "混合模型因其实际效果和全面的理论基础受到了广泛关注。然而，模型误设问题一直是一个持续存在的挑战，即拟合的模型组件数多于数据分布中的实际组件数。本文探讨了在未知$d$维回归参数和混合权重情况下，存在误设的过度指定双成分混合线性回归(2MLR)中期望最大化(EM)算法的行为。", "innovation": "本文发展了对EM算法在目标模型误设情况下的理论理解，特别是在过度指定双成分混合线性回归中。通过不同的初始猜测方法，证明了线性收敛和次线性收敛性，并严格量化了回归参数和混合权重的准确性，同时还将这类结果扩展到低信噪比环境。", "conclusion": "通过匹配定性和有限样本层面的结果，推导出了迭代复杂度边界，并进一步探讨了在低信噪比条件下的过度指定情况分析。"}
{"llm_update_time": "20250816", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.10123", "html_url": "https://arxiv.org/abs/2508.10123", "title": "Nested-ReFT: 通过离策采样高效强化学习大型语言模型微调", "title_en": "Nested-ReFT: Efficient Reinforcement Learning for Large Language Model Fine-Tuning via Off-Policy Rollouts", "authors": "Maxime Heuillet,Yufei Cui,Boxing Chen,Audrey Durand,Prasanna Parthasarathi", "background": "在处理数学推理等具有挑战性的领域时，大型语言模型（LLM）的高级推理可以使用可验证奖励基于强化微调（ReFT）的方法进行解决。现有标准ReFT框架中，行为模型会为每个问题生成多个完成的解答，然后由奖励函数进行评分。虽然这些RL后训练方法在处理复杂推理领域时能显著提升性能，但在训练过程中生成多个完成结果所需的计算成本很高，使得训练成本不菲。", "innovation": "该研究借鉴了离策RL和推测解码的方法，提出了一种新的ReFT框架（Nested-ReFT），其中目标模型的一部分层作为行为模型，在训练过程中生成离策采样的完成结果。配置动态层跳过机制以减少每批训练中的推理成本。理论分析表明，Nested-ReFT提供无偏梯度估计并控制了方差。实证分析显示，在多个数学推理基准测试和不同模型大小上，Nested-ReFT提高了计算效率（以token/秒衡量）。此外，研究还探讨了三种减轻偏误的方法，以最小化梯度更新过程中的离策性，从而保持与标准ReFT相当的性能。", "conclusion": "Nested-ReFT框架通过减少训练过程中的推理成本，提高了大型语言模型在数学推理等复杂推理任务上的计算效率，并通过减轻偏误的方法提高性能，使标准ReFT方法的性能得以保持。"}
{"llm_update_time": "20250816", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.10118", "html_url": "https://arxiv.org/abs/2508.10118", "title": "从意图到执行：面向精确CAD代码生成的多模态链式思维强化学习", "title_en": "From Intent to Execution: Multimodal Chain-of-Thought Reinforcement Learning for Precise CAD Code Generation", "authors": "Ke Niu,Haiyang Yu,Zhuofan Chen,Mengyang Zhao,Teng Fu,Bin Li,Xiangyang Xue", "background": "计算机辅助设计（CAD）在工程和制造业中发挥着重要作用，但当前的CAD工作流程需要大量的领域专业知识和手工建模工作。近年来，大型语言模型（LLMs）的进步使得从自然语言生成代码成为可能，为自动化参数化3D建模提供了新的机会。然而，直接将人类的设计意图转化为可执行的CAD代码仍然非常具有挑战性，因为这需要逻辑推理、语法正确性和数值精度。因此，本文提出了CAD-RL，这是一种多模态链式思维（CoT）引导的强化学习后训练框架，用于CAD建模代码生成。该方法结合了基于CoT的冷启动和目标驱动的强化学习后训练，使用三个特定任务的奖励：可执行性奖励、几何精度奖励和外部评估奖励。为了在稀疏和高方差奖励条件下确保稳定的策略学习，引入了三种专门的优化策略：信任区域拉伸以提高探索性、精度标记损失以增强维度参数精度，以及过长筛选以减少噪音监督。为了支持训练和基准测试，还发布了ExeCAD数据集，包含16,540例真实世界CAD示例，带有配对的自然语言和结构化设计语言描述、可执行CADQuery脚本和渲染的3D模型。实验证明，CAD-RL在推理质量、输出精度和代码可执行性方面显著优于现有语言模型（VLMs）.", "innovation": "本文创新性地提出了CAD-RL方法，结合了基于CoT的冷启动与目标驱动的强化学习后训练，使用三个特定任务奖励机制，并引入了三种专门的优化策略来确保在稳定政策学习条件下更佳的表现。同时，还发布了ExeCAD数据集，支持训练和基准测试，为精度CAD代码生成提供了全新途径。", "conclusion": "CAD-RL在推理质量、输出精度和代码可执行性方面展现了显著的改进，为CAD代码生成提供了新的解决方案，并为类似领域的未来研究提供了参考。"}
{"llm_update_time": "20250816", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.10173", "html_url": "https://arxiv.org/abs/2508.10173", "title": "基准驱动的人工智能选择：来自DeepSeek-R1的证据", "title_en": "Benchmark-Driven Selection of AI: Evidence from DeepSeek-R1", "authors": "Petr Spelda,Vit Stritecky", "background": "在观察到推理语言模型能够结合其现有能力，在任务完成前生成新颖的中间步骤并有时比过去模型更好地泛化之后，评估推理语言模型的重要性日益增加。随着推理成为大规模语言模型下一轮扩展的关键维度，对于这些模型在关键任务中能力的仔细研究变得必要。", "innovation": "本文展示了更好的性能并不是总是由测试时的算法改进或模型大小引起，而是由使用具有影响力的基准进行学习所引起。这一发现称为基准驱动的人工智能选择，并通过DeepSeek-R1中的序列决策问题展示了其效果。通过这些具有影响力的基准指导AI的发展，可以权衡评估和学习，使测试任务的新颖性成为衡量推理模型泛化能力的关键。因此，一些基准既可以作为训练的课程，也可以作为未见过的测试集呈现，提高模型在特定任务上的泛化性能。", "conclusion": "对于推理模型而言，一些基准既可以用作训练的课程，也可以用作未见过的测试集，而不只是单纯的测试数据集，这对于衡量其泛化能力至关重要。这种方法强调了关键任务中模型能力评估的重要性，并可能改变我们理解AI泛化能力的方式。"}
{"llm_update_time": "20250816", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.10210", "html_url": "https://arxiv.org/abs/2508.10210", "title": "基于可解释人工智能的方法监测动物健康", "title_en": "An Explainable AI based approach for Monitoring Animal Health", "authors": "Rahul Janaa,Shubham Dixit,Mrityunjay Sharma,Ritesh Kumar", "background": "奶农面临着监测所有牛只和优化产量的困难。本文旨在展示基于可解释机器学习（ML）方法的现代数据驱动农业实践，这些方法可以解释奶牛的行为和活动。通过使用三轴加速度计的持续数据采集和稳健的ML模型及算法，为农民和研究人员提供有关牛只活动的可行信息，帮助农民做出明智的决策并采用可持续实践。", "innovation": "该研究使用基于蓝牙的物联网（IoT）设备和4G网络实现无缝数据传输，并立即进行分析和推理生成。提出了时间序列数据预处理方法，包括滑动窗口技术的应用以提取统计特征、信号处理技术和基于滞后的特征，以及各种超参数优化的ML模型评估活动分类。k-最近邻分类器表现出最佳性能，训练集上的AUC均值为0.98，标准差为0.0026，测试集为0.99。为保证透明度，使用了基于可解释AI的框架（如SHAP）来解释特征的重要性，以便实际从业者能够理解并使用。", "conclusion": "基于Shap框架解释特征重要性的详细比较以及选定特征的稳定性分析，支持了可解释且实用的ML模型的开发，以实现可持续的畜禽管理。"}
{"llm_update_time": "20250816", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.10228", "html_url": "https://arxiv.org/abs/2508.10228", "title": "D-Wave量子退火和马尔可夫链蒙特卡洛方法在生成受限玻尔兹曼机概率分布采样中的比较", "title_en": "Comparison of D-Wave Quantum Annealing and Markov Chain Monte Carlo for Sampling from a Probability Distribution of a Restricted Boltzmann Machine", "authors": "Abdelmoula El Yazizi,Samee U. Khan,Yaroslav Koshka", "background": "本文将局部山谷（LV）中心化的评估方法应用于最新一代D-Wave量子退火器，旨在评估D-Wave和Gibbs采样器从一个由经典训练得到的受限玻尔兹曼机（RBM）中获得样本的质量。研究是在对比发散法（Contrastive-Divergence，CD）所述的RBM学习过程中相关条件下进行的。研究对比了来自D-Wave和Gibbs采样器的样本所包含的局部山谷（LVs）的数量和能量。", "innovation": "研究采用了一种新的局部山谷（LV）中心化的评估方法来评估D-Wave量子退火器和Gibbs采样器从受限玻尔兹曼机抽样质量，特别是从最近一代的D-Wave量子退火器得到样本。这种创新方法使得能够在对比发散基础上进行RBM学习的相关条件下，评估不同采样方法的效果。", "conclusion": "研究结果显示，在任何训练阶段，D-Wave采样的状态通常属于比Gibbs采样更多的局部山谷，但两种技术所找到的局部山谷并不少完全重叠。对于高概率的采样状态，两技术更不互补，并且出现更多的重叠。然而，有部分重要且概率值中等的局部最小值只能被一个技术发现，而被另一个方法遗漏。随着训练过程的进行，两种技术找到的局部山谷的重叠越来越少，这恰好是改善采样质量可能对RBM训练产生有效影响的阶段。研究结果可能解释了以往使用D-Wave采样未能取得显著改进的原因，并指出可能的改进途径，例如结合经典与量子的方法。"}
{"llm_update_time": "20250816", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.10219", "html_url": "https://arxiv.org/abs/2508.10219", "title": "AI-驱动的象牙上手写痕迹的检测与分析：揭示非法野生动物交易中犯罪网络的工具", "title_en": "AI-Driven Detection and Analysis of Handwriting on Seized Ivory: A Tool to Uncover Criminal Networks in the Illicit Wildlife Trade", "authors": "Will Fein,Ryan J. Horwitz,John E. Brown III,Amit Misra,Felipe Oviedo,Kevin White,Juan M. Lavista Ferres,Samuel K. Wasser", "background": "非洲象群的数量因跨国象牙贸易持续下降，而执法官员查获的象牙中含有追踪犯罪分子信息的法医学证据，如DNA信息和手写标记。虽然已通过20年来的遗传数据分析确认盗猎地点并建立象牙批货间的联系，但遗传信息的获取成本高且有时不可行。手写标记虽然易于拍照，但很少被记录或分析。本研究旨在利用人工智能技术开发一种提取和分析查获象牙上手写标记的方法，提供一种新颖、可扩展且低成本的法医学证据来源。", "innovation": "开发了一种AI驱动的方法，用于从查获的象牙照片中提取和分析手写标记，并利用最先进的AI工具对这些标记进行了分类和描述。通过这种方法，确立了184个重复出现的“签名标记”，并发现了20个出现在多个查获中的签名标记，从而通过涉及这些船货的犯罪分子建立了法医学联系。这项工作补充了其他调查技术，特别是在其他数据来源不可用时填补了空白。研究表明，人工智能在野生动物法医学中的变革潜力，并强调将手写分析整合到打击有组织野生动物犯罪行动中的实用步骤。", "conclusion": "本研究证实了人工智能在野生动物法医学中的变革潜力，并且展示了一种将手写分析整合到打击有组织野生动物犯罪行动中的方法。通过填补遗传数据不可用或其他数据来源的空白，可以有效打击跨国象牙贸易犯罪网络。"}
{"llm_update_time": "20250816", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.10147", "html_url": "https://arxiv.org/abs/2508.10147", "title": "rETF-semiSL: 半监督学习在时间数据中神经塌缩现象中的应用", "title_en": "rETF-semiSL: Semi-Supervised Learning for Neural Collapse in Temporal Data", "authors": "Yuhan Xie,William Cappelletti,Mahsa Shoaran,Pascal Frossard", "background": "深度神经网络在时间序列分析中需要捕捉复杂的时间模式，以便有效地表示动态数据。自监督和半监督学习方法在预训练大型模型方面表现出有希望的结果，这些模型在微调分类任务时通常会比从零开始训练的模型表现更好。然而，预训练任务的选择往往具有启发式性质，且下游分类任务中的迁移性并未确保，因此，本文提出了一种新的半监督预训练策略，以强化满足在最优训练神经分类器时观察到的神经塌缩现象的潜在表示。我们使用旋转抛物面紧框架分类器和伪标签来预训练深度编码器，使用少量标注样本。此外，为了有效捕捉时间动态特性并确保嵌入的可分性，我们在方法中结合了生成式预训练任务，并定义了一种新的序列增广策略。", "innovation": "本文提出了一种新的半监督预训练策略，结合了旋转抛物面紧框架分类器、伪标签和生成式预训练任务，以及一种新的序列增广策略，以增强潜在表示的可分性，从而提高模型在时间序列分类任务中的性能。", "conclusion": "我们的方法在LSTMs、变压器和状态空间模型上应用后，显著优于先前的预训练任务，特别是在三个多变量时间序列分类数据集上展示了优越的性能。这些结果强调了将预训练目标与理论上支持的嵌入几何结构对齐的重要性。"}
{"llm_update_time": "20250816", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.10233", "html_url": "https://arxiv.org/abs/2508.10233", "title": "晚期肝硬化危重症患者急性肾损伤早期可解释的机器学习预测模型：一项回顾性研究", "title_en": "Interpretable Machine Learning Model for Early Prediction of Acute Kidney Injury in Critically Ill Patients with Cirrhosis: A Retrospective Study", "authors": "Li Sun,Shuheng Chen,Junyi Fan,Yong Si,Minoo Ahmadi,Elham Pishgar,Kamiar Alaei,Maryam Pishgar", "background": "肝硬化是一种进行性肝脏疾病，伴有高死亡率和频繁并发症，其中急性肾损伤(AKI)是一个显著问题，在住院患者的发病率高达50%，且会恶化患者结果。AKI由于复杂的血流动力学、炎症和代谢变化而产生，早期检测至关重要。现有的预测工具缺乏准确性、可解释性以及与重症监护病房(ICU)工作流程的匹配。本文开发了一种用于肝硬化危重症患者早期AKI预测的可解释机器学习模型。", "innovation": "该研究采用可解释的机器学习方法，特别是LightGBM算法，构建了用于肝硬化危重症患者AKI早期预测的模型。该模型基于患者入ICU后的48小时内生理和实验室变量，通过LASSO特征选择和SMOTE类平衡等技术进行训练和优化，并且在多个性能指标上表现优异，尤其是高负预测值支持了低风险患者的肠胃减压策略，并且具有较高的解释性，提高了临床医生的信任度和预防针对性。", "conclusion": "基于LightGBM的模型能够利用常规临床变量实现早期AKI风险分层，在肝硬化危重症患者中的准确性高，且其高负预测值支持了对低风险患者进行安全肠胃减压，模型的可解释性增强了临床医生的信任感和预防针对性。未来需要进行外部验证并整合到电子健康记录系统中。"}
{"llm_update_time": "20250816", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.10235", "html_url": "https://arxiv.org/abs/2508.10235", "title": "Can Transformers Break Encryption Schemes via In-Context Learning？", "title_en": "Can Transformers Break Encryption Schemes via In-Context Learning?", "authors": "Jathin Korrapati,Patrick Mendoza,Aditya Tomar,Abein Abraham", "background": "在上下文学习（ICL）的应用下，基于变压器的语言模型展现出了强大的功能，使得它们能够在推理时仅通过少量示例进行任务处理，无需更新任何参数。此前的研究表明，变压器可以从上下文推测出如线性函数、决策树甚至神经网络等简单函数类，仅通过数值或符号推理即可实现泛化。但是在加密函数学习这一特定领域，尤其是针对如单表易位密码和维吉尼亚密码等替代密码方案的加密序列，此前的研究尚未涉足。\n", "innovation": "本文创新地将ICL应用到加密函数学习的领埴中，并专注于单表易位密码和维吉尼亚密码这两种私钥加密方案。研究中的目标是通过少量的密文-明文对，使模型推断出隐藏的替换关系并解码新的密文单词。这种设置下，存在结构化的推理难点，非常适合作为评估变压器在ICL模式下归纳偏见和泛化能力的测试平台。\n", "conclusion": "研究结果显示，变压器在完成特定密文学习任务时，能够有效推断出替代关系并进行解密，突显了ICL在处理具体加密方案应用中的潜力。相关的代码可以在提供的链接处获得。\n"}
{"llm_update_time": "20250816", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.10248", "html_url": "https://arxiv.org/abs/2508.10248", "title": "Max-Min Exponential Neural Network Operators in Orlicz Space", "title_en": "Convergence Analysis of Max-Min Exponential Neural Network Operators in Orlicz Space", "authors": "Satyaranjan Pradhan,Madan Mohan Soren", "background": "本文当前研究基于指数型神经网络算子对函数进行逼近，该研究扩展了现有的逼近理论框架，并在Kantorovich类型中提出了新的Max Min指数神经网络算子，探讨了它们的逼近性质。本文分析了一元函数在点值和一致收敛下的性质，使用对数模连续性研究收敛阶，并估计相应的收敛速率。此外，还在Orlicz空间的框架下研究了Max Min Kantorovich型指数神经网络算子的收敛行为，提供了示意图以展示函数逼近误差，利用合适的核函数和sigmoid激活函数进行说明.", "innovation": "引入了Max Min方法来逼近函数，这类方法在神经网络算子中具有新的扩展和应用，提出了Max Min Kantorovich型指数神经网络算子，研究了其在Orlicz空间中的收敛性质，并开发了对数模连续性的应用和收敛速率的估计方法.", "conclusion": "本文探讨了在不同的空间设置下Max Min Kantorovich型指数神经网络算子的收敛性，并通过图形展示了这种收敛性及其误差，特别是在Orlicz空间下的精确度，这为指数神经网络在逼近问题上的应用提供了新的理论依据和方法支持."}
{"llm_update_time": "20250816", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.10257", "html_url": "https://arxiv.org/abs/2508.10257", "title": "基于离线分解和在线混合方法的源组件位移适应", "title_en": "Source Component Shift Adaptation via Offline Decomposition and Online Mixing Approach", "authors": "Ryuta Matsuno", "background": "现有的在线学习方法难以有效利用重复的位移变化，而基于模型池的方法则难以捕捉各自的源组件，导致适应性能不佳。", "innovation": "提出了一种基于离线分解和在线混合的方法来解决源组件位移适应问题，该方法将问题分为离线源组件分解和在线混和权重适配两个子问题，通过EM算法学习源组件，然后使用在线凸优化更新预测模型的混和权重。", "conclusion": "该方法利用了位移的特性，在多个真实世界回归数据集上的实验结果表明，该方法优于基准方法，测试损失累计降低了最多67.4%。"}
{"llm_update_time": "20250816", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.10243", "html_url": "https://arxiv.org/abs/2508.10243", "title": "Pruning and Malicious Injection: A Retraining-Free Backdoor Attack on Transformer Models", "title_en": "Pruning and Malicious Injection: A Retraining-Free Backdoor Attack on Transformer Models", "authors": "Taibiao Zhao,Mingxuan Sun,Hao Wang,Xiaobing Chen,Xiangwei Zhou", "background": "Transformer模型在计算机视觉（CV）和自然语言处理（NLP）任务中表现出色，已成为不可或缺的组成部分。然而，最近的研究发现， transformer模型受背门攻击的影响。以往的背门攻击方法通常依赖于用干净数据重新训练或改变模型架构，这两种方法都可能资源密集且侵入性强。", "innovation": "本文提出了Head-wise Pruning and Malicious Injection（HPMI），这是一种新型的无需重新训练的transformer模型背门攻击方法，不需要改变模型架构。HPMI仅需少量原始数据和基本的模型架构知识即可实现，不需重新训练目标transformer。技术上，HPMI通过剪裁最不重要的头并注入预训练的恶意头来建立后门。它提供了严格的理论证明，表明植入的后门能够抵抗最先进的防御技术的检测与移除。实验结果表明，HPMI在多个数据集上有效，具有极小的准确度损失，高达99.55%的攻击成功率，并能规避四种先进的防御机制。相比依赖重新训练的攻击，HPMI具有更好的隐蔽性和耐受性，同时对准确度影响较小。", "conclusion": "实验评估进一步验证了HPMI的有效性，HPMI展现了1) 几乎没有干净准确性损失，2) 至少99.55%的攻击成功率，3) 拯灭四种先进的防御机制。与依赖重新训练的攻击方法相比，HPMI在多种防御策略下更具隐蔽性和稳定性，同时对准确性的影响最小。"}
{"llm_update_time": "20250816", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.10253", "html_url": "https://arxiv.org/abs/2508.10253", "title": "在云原生集群中基于多智能体强化学习的自适应资源编排", "title_en": "Multi-Agent Reinforcement Learning for Adaptive Resource Orchestration in Cloud-Native Clusters", "authors": "Guanzi Yao,Heyao Liu,Linyan Dai", "background": "本论文探讨了云原生数据库系统中由于资源动态性和调度复杂性所带来的挑战。云环境的快速变化导致资源管理和调度变得更为困难，传统的一站式解决方案难以适应突发变化，需要一种能够动态响应和智能调度的策略。为此，本文尝试利用多智能体强化学习提出了一种自适应资源编排方法，以提升资源管理和调度的效果和效率。", "innovation": "本文创新之处在于提出了一种基于多智能体强化学习的自适应资源编排方法。该方法采用了基于异质角色的智能体建模机制，使得不同类型（如计算节点、存储节点、调度器等）的资源实体能够各自采用不同的策略表示，从而更好地反映系统中的功能职责和局部环境特性。此外，设计了一种奖励塑造机制，将局部观察与全局反馈相结合，以减轻由不完整状态观察导致的策略学习偏差，并通过实时的局部性能信号结合全局系统价值估计来优化智能体之间的协调与策略收敛的稳定性。", "conclusion": "实验结果表明，所提出的方法在多个关键指标上优于传统方法，包括资源利用率、调度延迟、策略收敛速度、系统稳定性和公平性。方法能够有效地处理高并发、高维状态空间和复杂依赖关系等复杂的编排任务，在实际大规模调度环境中显示出强大的泛化能力和实用价值。"}
{"llm_update_time": "20250816", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.10284", "html_url": "https://arxiv.org/abs/2508.10284", "title": "基于两阶段校准预测框架的帕金森病药物需求不确定性感知预测", "title_en": "Uncertainty-Aware Prediction of Parkinson's Disease Medication Needs: A Two-Stage Conformal Prediction Approach", "authors": "Ricardo Diaz-Rincon,Muxuan Liang,Adolfo Ramirez-Zamora,Benjamin Shickel", "background": "帕金森病（PD）药物管理因疾病进展和治疗反应的异质性而面临独特挑战。神经科医生必须在减轻症状和基于功能障碍的多巴胺剂量优化之间取得平衡，同时尽量减少副作用。这种平衡非常重要，因为不充分或突然改变可能会引发左旋多巴引起的不自主运动、药物停用现象和神经精神症状，显著降低生活质量。目前方法依赖于试错性决策，缺乏系统性的预测方法。尽管机器学习取得了进展，但临床应用仍然受限，因为依赖于点预测而非考虑预测不确定性，这削弱了临床医生的信任和实用性。临床医生不仅需要预测未来药物需求，还需要可靠的置信度度量。缺乏量化不确定性会导致过度或不足调整治疗剂量。", "innovation": "我们开发了一种基于校准的预测框架，直至两年后预测药物需求，提供可靠的预测区间和统计保证。这种方法解决了UFH病历来自住院患者的零膨胀问题，即患者在就诊之间保持稳定的药物方案。使用2011-2021年在UFH的631例住院病例数据，我们两阶段的方法先识别可能需要药物调整的患者，然后预测所需的左旋多巴等效日剂量调整。我们的框架在减少预测区间同时保持边际覆盖，比传统方法提供更精准的短期计划和更广泛的长期预测范围。通过量化不确定性，我们的方法能够支持基于证据的左旋多巴剂量决策，优化症状控制，减少副作用并提高生活质量。", "conclusion": "我们提出的基于校准的预测框架能够量化不确定性和准确预测出远期的药物需求，为帕金森病药物管理提供了精准的预测和可靠的置信度度量。这种方法有助于临床医生进行基于证据的决策，优化症状控制，减少副作用，提升患者生活质量。"}
{"llm_update_time": "20250816", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.10315", "html_url": "https://arxiv.org/abs/2508.10315", "title": "使用预训练视觉-语言模型减轻联邦学习中后门攻击的方法", "title_en": "A Vision-Language Pre-training Model-Guided Approach for Mitigating Backdoor Attacks in Federated Learning", "authors": "Keke Gai,Dongjue Wang,Jing Yu,Liehuang Zhu,Qi Wu", "background": "现有的联邦学习(Federated Learning, FL)后门防御方法依赖于客户端数据分布同质的假设或干净服务数据集的可用性，这限制了其实用性和有效性。在异质客户端数据分布下防御后门攻击同时保持模型性能仍然是一个重大挑战。", "innovation": "本文提出了一种名为CLIP-Fed的联邦学习后门防御框架，该框架利用预训练视觉-语言模型的零样本学习能力。通过结合预聚合和后聚合的防御策略，CLIP-Fed克服了数据分布非独立同分布（Non-IID）对防御效果的限制。本文通过使用多模态大型语言模型和频率分析构建并扩充服务数据集，以隐私增强和提高数据集的多样性触发覆盖为目标，同时不使用任何客户端样本。通过使用原型对比损失和Kullback-Leibler扩散将全局模型和CLIP的知识对齐至扩充数据集，解决了由后门样本导致的类别原型偏差，消除了触发模式和目标标签的关联。", "conclusion": "大规模实验表明，CLIP-Fed的有效性，与最先进的方法相比，在CIFAR-10上平均减少攻击成功率2.03%，在CIFAR-10-LT上减少1.35%，同时分别提高MA性能7.92%和0.48%。"}
{"llm_update_time": "20250816", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.10350", "html_url": "https://arxiv.org/abs/2508.10350", "title": "基于序列观测的分布学习的语义通信", "title_en": "Semantic Communication with Distribution Learning through Sequential Observations", "authors": "Samer Lahoud,Kinda Khawam", "background": "语义通信的目标是传达意义而非精确复制比特，代表了从传统通信范式的转变。在语义通信中，接收者需通过对序列观察进行推理来推断潜在的意义分布。传统的语义通信更侧重于个体意义的传输优化，但在未知先验的情况下，我们为学习信源统计提供了基本条件。", "innovation": "本文建立了在未知先验条件下学习信源统计的关键条件，证明了可学习性要求有效传输矩阵的满秩，并刻画了分布估计的收敛率，对估计误差如何转化为语义失真的量化。研究揭示了一种基本的权衡：优化即时语义性能的编码方案往往会牺牲长期的学习能力。实验验证了理论框架，展示了系统预处理对学习速率和可实现性能的影响，首次为语义通信中的统计学习提供了严格的表征。", "conclusion": "本文为语义通信中的统计学习提供了理论框架，揭示了即时性能与适应能力之间的权衡，并为平衡二者提供了设计原则。"}
{"llm_update_time": "20250816", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.10393", "html_url": "https://arxiv.org/abs/2508.10393", "title": "一个多标注倾向学习的统一评估框架", "title_en": "A Unified Evaluation Framework for Multi-Annotator Tendency Learning", "authors": "Liyun Zhang,Jingcheng Ke,Shenli Fan,Xuanmeng Sha,Zheng Lian", "background": "近年来，在多标注学习领域出现了一些新的研究，这些研究开始从关注共识学习（CoL）转向个体倾向学习（ITL），后者通过对标注者特定的标注行为模式（即倾向性）建模，提供对标注者决策的理解解释。然而，目前还没有评估框架可以评估ITL方法是否真正捕捉到了个体倾向性并提供了有意义的行为解释。", "innovation": "本文提出了第一个统一的评估框架，包含两个新的评估指标：1）标注一致性差异（DIC）通过比较预测的标注一致性结构与真实情况来量化模型捕捉标注者倾向性的能力；2）行为对齐可解释性（BAE）通过多维尺度（MDS）对齐从解释中得出的与真实标注一致性的标签相似性结构，评估模型解释与标注者行为和决策的相关性。", "conclusion": "通过广泛的实验验证了我们提出的评估框架的有效性。"}
{"llm_update_time": "20250816", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.10299", "html_url": "https://arxiv.org/abs/2508.10299", "title": "通过增强初始化提高联邦适配器调优中针对新疾病的适应学习", "title_en": "Improving Learning of New Diseases through Knowledge-Enhanced Initialization for Federated Adapter Tuning", "authors": "Danni Peng,Yuan Wang,Kangning Cai,Peiyan Ning,Jiming Xu,Yong Liu,Rick Siow Mong Goh,Qingsong Wei,Huazhu Fu", "background": "在医疗保健领域，联邦学习（FL）是一种广泛采用的框架，它允许医疗机构在保护隐私的情况下进行协作。大型基础模型（FMs）展示了非常出色的性能，通过低成本的适配器调优将FMs应用于FL已经成为一种流行的方法。随着医疗保健环境的快速发展，个体客户端需要能够快速适应新的任务或疾病，并且在利用过去的经验的同时调优适配器。现有方法主要依赖于在单一适配器上进行微调，缺乏从过去知识中提取有用信息并在新的任务或疾病中进行有效初始化的方法。因此，有必要提出一种新的框架来解决这些问题。", "innovation": "本文提出了一种名为FedKEI的新框架，该框架能够在客户端和任务之间迁移跨客户端和跨任务的知识，以生成学习新任务的有见地的初始权重。FedKEI首先在服务器上进行全局聚类过程，以泛化知识跨任务。然后优化跨簇聚合权重（跨簇权重）和每个簇内部（内簇权重）的聚合权重，以个性化知识转移。为使跨和内簇权重的协作学习更为有效，引入了一种双层优化方案，协作学习跨客户的内簇权重，并优化每个客户端任务目标的局部跨簇权重。", "conclusion": "通过在三个不同模态的基准数据集上的广泛实验（涵盖皮肤病学、胸部X光和视网膜OCT），FedKEI方法展示出相较于现有最先进的方法在适应新疾病方面的优势。"}
{"llm_update_time": "20250816", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.10298", "html_url": "https://arxiv.org/abs/2508.10298", "title": "SynBrain：通过概率表示学习增强视觉到fMRI合成", "title_en": "SynBrain: Enhancing Visual-to-fMRI Synthesis via Probabilistic Representation Learning", "authors": "Weijian Mai,Jiamin Wu,Yu Zhu,Zhouheng Yao,Dongzhan Zhou,Andrew F. Luo,Qihao Zheng,Wanli Ouyang,Chunfeng Song", "background": "通过计算神经科学解析视觉刺激如何转化为大脑皮层反应是一项基本挑战。这种从视觉到神经的映射本质上是一个一对一到多对一的关系，相同的视觉输入在不同试次、上下文和个体之间会可靠地唤起不同的血氧动力学反应。然而，现有的确定性方法难以同时建模这种生物学上的变异性，同时捕捉编码刺激信息的功能一致性。", "innovation": "为了解决上述挑战，该研究提出了SynBrain，这是一种生成性框架，通过概率学习和视觉语义约束将视觉语义转换为神经响应，同时保持功能性一致性。它引入了两个关键组件：（i）BrainVAE模型将神经表示视为连续概率分布，并通过视觉语义约束维持功能性一致性；（ii）语义到神经映射器作为语义传输路径，将视觉语义投影到神经响应流形中，以促进高保真fMRI合成。实验结果显示，SynBrain在个体特异性视觉到fMRI编码性能方面超越了最先进的方法。此外，它能够少量数据适应新个体，并合成高质量的fMRI信号以提升数据有限fMRI到图像解码性能。另外，SynBrain揭示了跨试次和个体的功能一致性，合成信号捕获由生物神经变异性塑造的可解释模式。", "conclusion": "SynBrain在视觉到fMRI编码性能方面优于最先进的方法，并能够有效合成高质量的fMRI信号；此外，SynBrain还可以揭示不同试次和个体间的功能一致性，并且合成信号能够捕捉到受生物神经变异性影响的可解释模式。相关代码将公开提供。"}
{"llm_update_time": "20250816", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.10345", "html_url": "https://arxiv.org/abs/2508.10345", "title": "效用中心聚类", "title_en": "Welfare-Centric Clustering", "authors": "Claire Jie Zhang,Seyed A. Esmaeili,Jamie Morgenstern", "background": "公平聚类长期以来主要关注确保组别代表性的公平性或均衡组别特定的聚类成本。然而，Dickerson等人（2025）的研究表明，这些公平性概念可能会导致不理想的或不直观的聚类结果，并且提倡以福利为中心的聚类方法，通过建模组别福利来处理问题。尽管这种方法提供了一种新的视角，但仍然缺乏具体建模不同组间距离关系和比例代表的综合方法。因此，需要进一步研究如何有效平衡这些因素，以提高聚类效果，同时确保公平性与效益最大化。", "innovation": "本文提出了基于距离和比例代表效用的模型，并定义了福利中心聚类中的两个优化目标：劳尔式（埃加提安）目标和功利主义目标。为这两个目标提出了新的算法，并且给出了理论上的保证。通过在多个真实数据集上的实证评估，验证了所提出方法显著优于现有公平聚类基准方法。", "conclusion": "研究结果表明，通过考虑距离和比例代表效用的方法，可以显著提高聚类效果，同时兼顾公平性和效益最大化。提出的算法及目标也为未来研究提供了新的思路和基础。"}
{"llm_update_time": "20250816", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.10346", "html_url": "https://arxiv.org/abs/2508.10346", "title": "在医疗物联网网络中检测零日攻击的分层IDS", "title_en": "A Hierarchical IDS for Zero-Day Attack Detection in Internet of Medical Things Networks", "authors": "Md Ashraf Uddin,Nam H. Chu,Reza Rafeh", "background": "医疗物联网（IoMT）正在推动医疗保健革命，但仍然容易遭受诸如拒绝服务攻击、勒索软件、数据劫持和伪造等网络攻击。这些网络由资源受限且异构的设备组成（例如，可穿戴传感器、智能药片、植入物），传统的集中式入侵检测系统（IDSs）由于响应延迟、隐私风险和增加的安全漏洞而难以适用。中心化的IDS需要所有传感器将数据传输到中央服务器，这在密集环境中会导致延迟或网络中断。在IoMT设备上本地运行IDS通常不可行，因为其计算能力有限，即便轻量级IDS组件仍可能因更新模型延迟而面临零日攻击的风险，这对患者健康和数据安全构成威胁。", "innovation": "本文提出了一种多层次的IoMTIDS框架，能够检测零日攻击并区分已知威胁和未知威胁。第一层（近边缘层）使用元学习或One-Class分类（OCC）与usfAD算法粗略地过滤流量（攻击与否）。后续层（远边缘层、云层）则进一步识别攻击类型和新颖性。实验结果表明，该方法在CICIoMT2024数据集上的准确率高达99.77%，F1分数为97.8%，第一层能够高效地检测零日攻击且无需依赖新的数据集，从而确保在IoMT环境中具有较强的适用性。此外，该方法采用元学习的方式实现了高检测率。", "conclusion": "所提出的分层IDS框架能够有效检测零日攻击，区分已知与未知威胁，并且在IoMT环境中具有高准确率和强适用性，采用元学习提升检测性能。"}
{"llm_update_time": "20250816", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.10370", "html_url": "https://arxiv.org/abs/2508.10370", "title": "eMamba: 在边缘计算中提高Mamba模型效率的框架", "title_en": "eMamba: Efficient Acceleration Framework for Mamba Models in Edge Computing", "authors": "Jiyong Kim,Jaeho Lee,Jiahao Lin,Alish Kanani,Miao Sun,Umit Y. Ogras,Jaehyun Park", "background": "近年来，基于状态空间模型（SSM）的机器学习架构因处理序列数据而备受关注。Mamba作为一种新颖的序列到序列SSM模型，相比最先进的变换器模型在准确性和计算效率上都有出色表现。尽管如此，目前尚无针对这类模型优化的硬件加速框架，使其在资源受限的边缘设备上无法得到充分利用.", "innovation": "这篇文章提出了一种名为eMamba的端到端硬件加速框架，专门用于在边缘平台上部署Mamba模型。eMamba通过使用轻量级且硬件感知的替代层替换复杂归一化层，以及对昂贵操作如SiLU激活和指数运算进行近似处理，提高了计算效率。此外，eMamba还进行了一种近似感知的神经架构搜索（NAS），以优化学习参数的调优过程。实验结果表明，与最先进的技术相比，eMamba使用更少的参数实现了相当的准确性，并且在FPGA和ASIC平台上展示了优异的性能，包括更低的延迟、更高的吞吐量、更小的面积、更低的功耗和能量消耗，同时保持了竞争力.", "conclusion": "综上所述，eMamba通过改进硬件加速框架，成功地解决了Mamba模型在边缘设备上应用中的效率问题，展示出了良好的扩展性和应用广泛性，为边缘计算领域提供了新的解决方案。"}
{"llm_update_time": "20250816", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.10395", "html_url": "https://arxiv.org/abs/2508.10395", "title": "XQuant: 使用KV缓存重新创造打破LLM推理的内存瓶颈", "title_en": "XQuant: Breaking the Memory Wall for LLM Inference with KV Cache Rematerialization", "authors": "Aditya Tomar,Coleman Hooper,Minjae Lee,Haocheng Xi,Rishabh Tiwari,Wonjun Kang,Luca Manolache,Michael W. Mahoney,Kurt Keutzer,Amir Gholami", "background": "虽然大规模语言模型（LLM）的推理已成为许多下游应用的关键工作负载，但高效地推断LLM具有挑战性，因为其内存占用量和带宽需求巨大。在过去的几十年里，计算能力一直超过了内存容量和带宽，这种趋势在现代GPU硬件中仍然存在，进一步加剧了LLM推理的挑战。因此，涌现出了一些新的算法，这些算法通过增加计算量来减少内存操作。为了解决这个问题，文中提出了一种名为XQuant的方法，利用了低比特量化技术，并且通过对层输入激活X进行量化和缓存，而不是使用标准的KV缓存方法，同时在推理过程中实时重新生成键和值，从而实现比KV缓存方法少得多的内存消耗。", "innovation": "XQuant通过低比特量化和在推理过程中重新生成键和值来量化和缓存层输入激活值X，从而实现了比现有最先进的基于KV缓存的量化方法更大幅度的内存压缩，同时保持了较高的准确率。此外，XQuant-Cache进一步利用了X值在各层之间的相似性，达到了更极端的压缩，仅以较小的混淆度下降实现了显著的内存节省。", "conclusion": "XQuant方法利用了硬件性能的快速增长来消除内存瓶颈，并且在广泛模型上实现了接近FP16精度的同时，比最先进的基于KV缓存的量化方法节省了更多的内存。"}
{"llm_update_time": "20250816", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.10428", "html_url": "https://arxiv.org/abs/2508.10428", "title": "SC2Arena和StarEvolve：复杂决策任务中LLMs的基准和自我改进框架", "title_en": "SC2Arena and StarEvolve: Benchmark and Self-Improvement Framework for LLMs in Complex Decision-Making Tasks", "authors": "Pengbo Shen,Yaqing Wang,Ni Mu,Yao Luan,Runpeng Xie,Senhao Yang,Lexiang Wang,Hao Hu,Shuang Xu,Yiqin Yang,Bo Xu", "background": "评估大型语言模型（LLMs）在复杂决策中的表现对于提高AI的战略规划能力和实时适应能力至关重要。然而，现有的基准测试（例如StarCraft II）未能捕捉到游戏的全部复杂性，包括完整的游戏背景、多样的行动空间以及所有可玩种族。为了解决这一缺口，本文提出了SC2Arena，它全面支持所有可玩种族、低级行动空间，并优化基于文本的观察来应对空间推理挑战。", "innovation": "SC2Arena基准全面支持所有可玩种族、低级行动空间，并优化基于文本的观察来应对空间推理挑战。此外，作者提出了StarEvolve框架，这是一种将战略规划与战术执行结合的分层方法，还具有迭代自我纠正和通过高质量游戏数据微调以实现连续改进的功能。这一框架的关键组成部分包括计划者-执行者-验证者结构，以分解游戏玩法，并设置评分系统来选择高质量的训练样本。", "conclusion": "通过SC2Arena的全面分析，为开发通用智能代理提供了有价值的见解，而以往的基准测试未能实现这一点。实验结果还表明，我们提出的StarEvolve框架在战略规划方面的性能优于以往的方法。我们的代码、环境和算法均公开提供。"}
{"llm_update_time": "20250816", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.10435", "html_url": "https://arxiv.org/abs/2508.10435", "title": "在张量化模型中拆解尖锐感知最小化隐式范数动态", "title_en": "Unpacking the Implicit Norm Dynamics of Sharpness-Aware Minimization in Tensorized Models", "authors": "Tianxiao Cao,Kyohei Atarashi,Hisashi Kashima", "background": "Sharpness-Aware Minimization (SAM) 已证实是一种有助于提高过参数化模型泛化的有效优化技术。尽管先前的研究在简单的缩放不变两核心系统中探索了 SAM 的隐式正则化，但对于更通用的张量化或缩放不变模型，其行为仍不明确。", "innovation": "引入了基于范数偏差的概念，这是一种衡量核范数不平衡的全局指标，并通过梯度流分析推导其在 SAM 下的演变。基于此发现，提出了一种简单有效的 Devison-Aware Scaling (DAS) 方法，通过数据自适应的方式缩放核范数来模仿 SAM 的隐式正则化行为。实验表明，DAS 在张量补全、有噪声的训练、模型压缩和参数有效微调中往往能实现与 SAM 相当或更好的性能，同时减少计算开销。", "conclusion": "通过自适应缩放核范数，DAS 能够在多种应用场景中表现出色，甚至优于 SAM，而且具有较低的计算成本。"}
{"llm_update_time": "20250816", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.10455", "html_url": "https://arxiv.org/abs/2508.10455", "title": "RealAC:一个领域无关的现实且可行的反事实解释框架", "title_en": "RealAC: A Domain-Agnostic Framework for Realistic and Actionable Counterfactual Explanations", "authors": "Asiful Arefeen,Shovito Barua Soumma,Hassan Ghasemzadeh", "background": "反事实解释通过描述最小改变输入特征以改变模型预测结果的方式，提供人类可理解的理由解释AI决策。现有方法虽有所进展，但往往通过刚性手工地制造约束或特定领域的知识来强制特征之间的依赖性，这限制了它们的普适性，并且很难捕捉数据中的复杂非线性关系。此外，现有的方法很少考虑用户的偏好，导致生成的解释在因果上不合理或不具备实际操作性。", "innovation": "本文提出RealAC，是一种领域无关的方法，用于生成现实且可行的反事实解释。RealAC通过对事实和反事实实例的特征对联合分布进行对齐，自动维护复杂特征间的依赖关系，无需依赖显式的领域知识。此外，RealAC允许最终用户将无法或不愿更改的属性“冻结”，在优化过程中抑制这些冻结特征的变化。实验表明，RealAC在现实性和可行性方面取得了平衡，并在因果边分数、依赖保持分数和IM1现实度度量中超过了最先进的基线方法及基于大型语言模型的反事实生成技术。", "conclusion": "RealAC提供了一个解决方案，从因果意识和用户为中心的角度生成反事实解释。"}
{"llm_update_time": "20250816", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.10479", "html_url": "https://arxiv.org/abs/2508.10479", "title": "推荐系统中的混淆问题是普遍存在的问题", "title_en": "Confounding is a Pervasive Problem in Real World Recommender Systems", "authors": "Alexander Merkov,David Rohde,Alexandre Gilotte,Benjamin Heymann", "background": "未观测到的混杂因素是指未测量的特征同时影响治疗和结果的现象，导致偏差的因果效应估计。这个问题动摇了经济学、医学、生态学或流行病学等领域的观察性研究的基础。虽然以完全观测数据为基础的推荐系统似乎不受此问题的影响，但由于推荐系统中的许多标准实践忽略了观测特征，实际上产生了相同的问题。论文指出，许多常见的做法如特征工程、A/B测试和模块化实际上可能将混杂因素引入推荐系统，从而阻碍其性能。", "innovation": "论文揭示了一些常见的做法，如特征工程、A/B测试和模块化，尽管看似不涉及混杂因素，但实际上它们可能会引入混杂因素。作者通过实证研究证明了这些常见做法如何导致混杂问题，并为实际系统中的混杂问题提供了减少或避免的建议。", "conclusion": "在现实世界的推荐系统中，混淆问题普遍存在。许多依赖于完全观测数据的做法实际上可能引入混杂因素，从而影响推荐系统的性能。论文提供了一些实例，并通过模拟研究支持了这些观点，提出了减少或避免混杂问题的实际建议。"}
{"llm_update_time": "20250816", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.10471", "html_url": "https://arxiv.org/abs/2508.10471", "title": "GraphFedMIG：通过互信息引导生成解决联邦图学习中的类别不平衡问题", "title_en": "GraphFedMIG: Tackling Class Imbalance in Federated Graph Learning via Mutual Information-Guided Generation", "authors": "Xinrui Li,Qilin Fan,Tianfu Wang,Kaiwen Wei,Ke Yu,Xu Zhang", "background": "联邦图学习（FGL）允许多人客户端在不共享其私有的、分散的数据的情况下协作训练强大的图神经网络。FGL 遭遇统计异质性这一挑战，由于客户端间非IID（不同个体间独立且非同分布）的数据分布，可能导致模型性能严重受损。特别地，类别不平衡会导致全局模型偏向多数类，难以识别少数但关键的事件，这在FGL中被加剧，因为少数类节点周围的邻居信息往往是有偏的，阻碍了对表现性强的嵌入式学习。", "innovation": "本文提出了一种新的FGL框架GraphFedMIG，将问题重新构想为联邦生成数据增强任务。GraphFedMIG 使用了一个分层生成对抗网络，其中每个客户端训练一个局部生成器以合成高质量的特征表示。通过将客户端分组到集群中，每个集群共享一个专用的鉴别器，以提供定制化的监督。关键地，框架设计了一个互信息引导机制来引导客户端生成器的发展。通过计算每个客户端的特定信息价值，该机制纠正了局部生成器的参数，确保后续互信息引导生成的轮次聚焦于产生高价值的少数类特征。", "conclusion": "我们在四个真实世界数据集上进行了广泛实验，结果表明，所提出的GraphFedMIG相对于其他基线具有优越性。"}
{"llm_update_time": "20250816", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.10491", "html_url": "https://arxiv.org/abs/2508.10491", "title": "对比学习ECOC：用于对抗防御的学习输出代码", "title_en": "Contrastive ECOC: Learning Output Codes for Adversarial Defense", "authors": "Che-Yu Chou,Hung-Hsuan Chen", "background": "虽然一热编码在多类别分类中普遍使用，但它并非总是最有效的编码机制。错误纠正输出编码（ECOC）通过将每个类别映射到唯一的编码词来进行多类别分类。传统ECOC方法依赖于手动设计或随机生成的代码本，这既耗费人力，又可能无法针对特定数据集优化。", "innovation": "本文提出基于对比学习的三种模型以自适应地从数据中直接学习代码本。与两种基准方法相比，本文提出的模型在四个数据集上显示出更强的对抗扰动鲁棒性。", "conclusion": "本文提出的方法在对抗攻击中表现出更强的鲁棒性，并且代码本是直接从数据中学习得到的，无需手动设计或随机生成代码本。"}
{"llm_update_time": "20250816", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.10490", "html_url": "https://arxiv.org/abs/2508.10490", "title": "基于梯度的解释的复杂度-忠实度权衡", "title_en": "On the Complexity-Faithfulness Trade-off of Gradient-Based Explanations", "authors": "Amir Mehrpanah,Matteo Gamba,Kevin Smith,Hossein Azizpour", "background": "当前，ReLU网络在视觉数据中广泛应用，但它们的特征提取过程存在尖锐的跃变，有时依赖于个别像素进行预测，这使得基于梯度的解释变噪声化且难以理解。现有方法，例如GradCAM，通过生成替代模型来平滑这些解释，但需要以牺牲忠实度为代价。研究团队引入了一个统一的频谱框架，用于系统地分析和量化平滑性、忠实度及其在解释中的权衡。", "innovation": "团队开发了一个频谱框架，以量化ReLU网络对高频信息的贡献，并提供一个基于原理的途径来识别这些属性之间的权衡。此外，该框架还能量化基于替代模型的平滑解释的偏差，定义并测量了不同后处理方法中的“解释缺口”。", "conclusion": "通过理论分析，验证了该频谱框架在不同设计选项、数据集和消融分析中的有效性，进一步揭示了梯度基于解释中复杂度与忠实度之间的矛盾关系。"}
{"llm_update_time": "20250816", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.10474", "html_url": "https://arxiv.org/abs/2508.10474", "title": "EDAPT：通过持续在线适应实现无校准的BCIs", "title_en": "EDAPT: Towards Calibration-Free BCIs with Continual Online Adaptation", "authors": "Lisa Haxel,Jaivardhan Kapoor,Ulf Ziemann,Jakob H. Macke", "background": "脑机接口（BCIs）因随时间变化的神经信号易导致准确性下降，且神经信号在不同用户间存在差异，这要求频繁的校准，从而限制了其实用部署。文章探讨了这个问题及其对BCI实际应用的影响，提出了使BCIs无需校准的新方法，从而解决上述问题，提高实际部署的可能性。", "innovation": "文章提出了一种名为EDAPT的框架，它是一种任务和模型无关的方法，能够通过持续的模型适应来消除校准的需要。该框架首先利用多用户数据训练基准解码器，然后随着神经模式的演变，在使用过程中通过有监督微调持续个性化模型。这种方法结合了总体水平的预训练和在线持续微调，进一步通过无监督的领域适应在某些数据集上提高了解码准确率，最终使其在消费级硬件上运行效率非常高，更新模型仅需200毫秒。这种新的解码方式与数据总量而非分配给被试和实验次数的数据预算成正比。", "conclusion": "EDAPT为实现无校准的BCIs提供了一条实用途径，减少了一项重要的BCI部署障碍，有助于提高BCI的实际应用性。"}
{"llm_update_time": "20250816", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.10480", "html_url": "https://arxiv.org/abs/2508.10480", "title": "Pinet: 使用正交投影层优化具有严格约束的神经网络", "title_en": "Pinet: Optimizing hard-constrained neural networks with orthogonal projection layers", "authors": "Panagiotis D. Grontas,Antonio Terpin,Efe C. Balta,Raffaello D'Andrea,John Lygeros", "background": "在神经网络中引入一个确保满足凸约束的输出层。该方法利用操作分裂在前向传播中实现快速可靠的投影，并利用隐函数定理进行反向传播。", "innovation": "提出了一种名为$\rm \bf \boldsymbol{\\Pi}net$的方法，通过正交投影层确保神经网络满足严格约束，采用操作分裂技术来实现快速和可靠的前向传播投影，利用隐函数定理进行反向传播。$\rm \bf \boldsymbol{\\Pi}net$被用作参数约束优化问题的可实现优化代理，可以在解决单个问题时比传统求解器更快地获得中等精度的解，并且对于批量问题而言显著更快。与最先进的学习方法相比，$\rm \bf \boldsymbol{\\Pi}net$在训练时间、解的质量和对超参数调优的鲁棒性方面更好，同时保持类似的推理时间。此外，该方法解决了多车辆运动规划中的非凸轨迹偏好问题，并提供了一个准备好在GPU上运行的$\rm \bf \boldsymbol{\\Pi}net$实现，基于JAX，具有有效的超参数调谐启发式。", "conclusion": "与最先进的学习方法相比，$\rm \bf \boldsymbol{\\Pi}net$在训练时间和推理时间保持相似的情况下，提高了解的质量和对超参数的鲁棒性。此外，$\rm \bf \boldsymbol{\\Pi}net$还在非凸轨迹偏好条件下解决多车辆运动规划问题方面表现出优势。"}
{"llm_update_time": "20250816", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.10494", "html_url": "https://arxiv.org/abs/2508.10494", "title": "统一多智能体框架以实现通用多模态理解和生成", "title_en": "A Unified Multi-Agent Framework for Universal Multimodal Understanding and Generation", "authors": "Jiulin Li,Ping Huang,Yexin Li,Shuo Chen,Juewen Hu,Ye Tian", "background": "实际上，现实世界的多模态应用常常需要实现任何形式到任何形式的能力，使得人们能够理解并生成不同的模态，包括文本、图像、音频和视频。然而，将自回归语言模型（LLMs）的推理能力与高保真生成扩散模型相结合仍然存在挑战。现有的方法通常依赖于固定管道或紧密耦合的架构，这限制了其灵活性和扩展性。", "innovation": "我们提出了MAGUS（多智能体引导统一多模态系统），这是一种模块化框架，通过两个分离的阶段——认知和决断来统一多模态理解和生成。MAGUS 允许多智能体在共享文本工作空间内进行符号化合作。在认知阶段，三个条件性的多模态LLM智能体——Perceiver、Planner和Reflector参与协同对话，以实现结构化的理解和计划。在决断阶段，采用一种感知增长搜索机制，协调LLM推理和以扩散为基础的生成，使其相互增强。MAGUS 支持模块化、可扩展，并能够处理任何模态转换和语义对齐，无需联合训练。", "conclusion": "MAGUS 在多个基准测试中（包括图像、视频和音频生成，以及跨模态指令跟随）的表现优于强大基准和最先进的系统。值得注意的是，在MME基准测试中，MAGUS 超过了强大的闭源模型GPT-4o。"}
{"llm_update_time": "20250816", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.10520", "html_url": "https://arxiv.org/abs/2508.10520", "title": "通过强化学习实现非局域蒙特卡洛方法", "title_en": "Nonlocal Monte Carlo via Reinforcement Learning", "authors": "Dmitrii Dobrynin,Masoud Mohseni,John Paul Strachan", "background": "优化或采样组合优化问题的复杂成本函数是一个跨学科和应用的长期挑战。在使用基于马尔可夫链蒙特卡罗（MCMC）的一系列传统算法（如模拟退火或平行调温）时，人们假定输入具有均匀（平衡）的温度分布。这一实例独立的方法在具有所谓的重叠间隙性质而接近计算相变的最难基准时表现不佳。在这些区域，传统的MCMC算法难以解冻僵硬的变量、逃离次优的吸引盆地，并获取高质量和多样化的解决方案。", "innovation": "我们利用深度强化学习（RL）来训练NMC的非局域转换策略，这些策略以前是通过表象设计的。我们展示了这种通过观察构型空间探索的能量变化作为RL奖励和局部最小能量景观几何结构作为RL状态训练生成的求解器性能优于标准的基于MCMC和非局域模拟退火方法，尤其是在残余能量、解的获得时间和解的多样性度量方面。", "conclusion": "通过强化学习训练的非局域转换策略显著改进了NMC算法，使其在解决硬的均匀随机和无标度随机4-SAT基准问题时，表现优于标准的MCMC和非局域模拟退火方法。"}
{"llm_update_time": "20250816", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.10531", "html_url": "https://arxiv.org/abs/2508.10531", "title": "投影耦合扩散用于测试时约束联合生成", "title_en": "Projected Coupled Diffusion for Test-Time Constrained Joint Generation", "authors": "Hao Luan,Yi Xian Goh,See-Kiong Ng,Chun Kai Ling", "background": "测试时采样的修改已发展成为扩散算法的重要扩展，目的是通过引导生成过程达成特定目标，而无需重新训练整个扩散模型。然而，多项预训练扩散模型同时生成联合相关样本并同时施加任务特定约束仍然是一个挑战，且需要大量重新训练的成本。", "innovation": "本文提出了投影耦合扩散（PCD），这是一种新颖的测试时框架，用于受约束的联合生成。PCD通过将耦合引导项引入生成动力学来促进扩散模型之间的协调，并在每个扩散步骤中加入投影步骤以强制执行硬约束。实验表明，PCD在图像对生成、对象操控及多机器人运动规划等应用示例中具有良好的效果，展示了改进的耦合效果和确保约束满足能力，同时不会增加高额的计算成本。", "conclusion": "PCD验证了在不增加过高的计算负担的情况下，可以改善耦合效果并确保约束满足。"}
{"llm_update_time": "20250816", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.10489", "html_url": "https://arxiv.org/abs/2508.10489", "title": "通过联合嵌入预测架构从任意数据学习动态系统的状态空模型", "title_en": "Learning State-Space Models of Dynamic Systems from Arbitrary Data using Joint Embedding Predictive Architectures", "authors": "Jonas Ulmen,Ganesh Sundaram,Daniel Görges", "background": "随着联合嵌入预测架构（JEPAs）的出现，这种新方法能够使用任意观察数据构建连续时间动态系统的世界模型，而JEPAs比基于重建的方法更具能力。这种方法通过将序列嵌入与神经常微分方程（神经ODEs）结合来处理状态转换的契约性嵌入和Lipschitz常数约束，从而构建了一个组织良好的潜在状态空间。这种方法的有效性通过仅使用图像数据生成简单摆动系统结构化的潜在状态空间模型得到展示，为更广泛的控制算法和估值技术打开了新途径，特别是在机器人技术领域中具有广泛应用前景。", "innovation": "提出了一种通过将序列嵌入与神经常微分方程（神经ODEs）结合的新方法，这种方法在状态转换中强制约束嵌入契约性和Lipschitz常数，以构建一个组织良好的潜在状态空间。这种方法的有效性通过仅使用图像数据生成结构化的潜在状态空间模型得到验证，展示了该技术在开发更通用控制算法和估值技术中的潜力。", "conclusion": "通过仅使用图像数据生成了简单摆动系统结构化的潜在状态空间模型，验证了通过结合序列嵌入和神经常微分方程构建状态空间模型的有效性。这种方法为开发更广泛的控制算法和估计技术提供了新途径，并具有在机器人技术领域的广泛应用前景。"}
{"llm_update_time": "20250816", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.10548", "html_url": "https://arxiv.org/abs/2508.10548", "title": "使用门控奖励稳定多轮长周期强化学习", "title_en": "Stabilizing Long-term Multi-turn Reinforcement Learning with Gated Rewards", "authors": "Zetian Sun,Dongfang Li,Zhuoen Chen,Yuhuai Qin,Baotian Hu", "background": "在长期视角的强化学习任务中，奖励稀疏性是一个显著的挑战。现有的基于结果的奖励建模方法在定义即时奖励时容易产生偏差或需要显式的任务分解。而基于验证的奖励建模方法虽然使用逐步批评家，但即时奖励与长期目标的不一致可能导致奖励黑客和次优化策略。当前的研究在这种背景下，特别是在软件工程任务中进行了探索，类似于多轮推理和基于规则的验证是关键因素。", "innovation": "介绍了SWE（软件工程）倾向的RL框架，支持多轮交互、基于docker的执行和可定制的奖励函数。提出了门控奖励积累（G-RA）方法，该方法仅在高层（长期）奖励达到预定阈值时积累即刻奖励，从而确保RL的稳定优化。", "conclusion": "实验结果显示，G-RA在SWE-bench Verified和kBench上的改进显著提高了完成率和修改率，同时避免了奖励不匹配导致的策略退化。这些发现突显了在长期RL中平衡奖励积累的重要性，并提供了一个实用的解决方案。"}
{"llm_update_time": "20250816", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.10581", "html_url": "https://arxiv.org/abs/2508.10581", "title": "技术报告：通过LLM赋能的协 pilot促进因果推理方法的采纳", "title_en": "Technical Report: Facilitating the Adoption of Causal Inference Methods Through LLM-Empowered Co-Pilot", "authors": "Jeroen Berrevoets,Julianna Piskorz,Robert Davis,Harry Amad,Jim Weatherall,Mihaela van der Schaar", "background": "在医疗、经济学和公共政策等多个领域，通过对观察数据进行治疗效果（TE）估计是一个极其重要但同时也十分复杂的工作。尽管近年来机器学习和因果推理的进步产生了非常强大的估计技术，但由于需要深厚的专业知识来掌握因果假设、调整策略和模型选择，这些技术的应用依然受到限制。", "innovation": "本文介绍了一种名为CATE-B的开源协 pilot系统，它通过使用大型语言模型（LLMs）在代理框架下指导用户完成从头到尾的治疗效果估计过程。CATE-B帮助用户（i）通过因果发现和LLM基边的方向性来构建结构因果模型；(ii) 通过一种新颖的最小不确定性调整集标准识别稳健的调整集；(iii) 选择适合因果结构和数据集特征的适当回归方法。为了促进可再现性和评估，我们释放了一套涵盖不同领域和因果复杂性的基准任务。", "conclusion": "通过将因果推理与智能、交互式帮助相结合，CATE-B降低了严谨的因果分析门槛，并为自动化治疗效果估计开辟了一个新的基准类别。"}
{"llm_update_time": "20250816", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.10594", "html_url": "https://arxiv.org/abs/2508.10594", "title": "FreeGAD：一种无需训练的高效图异常检测方法", "title_en": "FreeGAD: A Training-Free yet Effective Approach for Graph Anomaly Detection", "authors": "Yunfeng Zhao,Yixin Liu,Shiyuan Li,Qingfeng Chen,Yu Zheng,Shirui Pan", "background": "图异常检测（GAD）旨在识别图中与大多数节点不同的节点，在社交网络和电子商务等领域具有重要作用。尽管基于深度学习的GAD取得了进展，但现有方法由于复杂的训练过程和高昂的部署成本通常面临着扩展性不足的问题。", "innovation": "本文提出了一种名为FreeGAD的新颖方法，能够实现无需训练的高效图异常检测。FreeGAD通过使用关联门控残差编码器生成异常感知表示，并利用锚节点作为伪正常和异常指导，来计算异常得分。这种方法在多个跨领域的基准数据集上展示了优越的异常检测性能、效率和可扩展性。", "conclusion": "实验结果表明，FreeGAD在多个领域的大规模基准数据集上，能够实现无训练、高效的异常检测，具有优秀的异常检测性能、效率和可扩展性。"}
{"llm_update_time": "20250816", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.10595", "html_url": "https://arxiv.org/abs/2508.10595", "title": "基于梯度的解释方法的频谱性质", "title_en": "On Spectral Properties of Gradient-based Explanation Methods", "authors": "Amir Mehrpanah,Erik Englesson,Hossein Azizpour", "background": "深入理解深度网络的行为对于增加我们对其结果的信心至关重要。尽管已经有许多研究致力于解释它们的预测，但研究人员遇到了可靠性问题，这主要归因于缺乏足够的形式化研究。", "innovation": "本研究采用了新颖的概率和频谱视角来正式分析解释方法，揭示了由梯度使用引起的普遍频谱偏差，并阐明了一些已在实验中发现的常见设计选择，特别是梯度平方和输入扰动的使用。此外，本研究通过对扰动超参数的选择进行详细研究，提出了两种基于所提形式化的补救措施：(i) 确定标准扰动尺度的机制，(ii) 称为SpectralLens的聚合方法。", "conclusion": "通过定量评估证实了本研究的理论成果。"}
{"llm_update_time": "20250816", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.10583", "html_url": "https://arxiv.org/abs/2508.10583", "title": "基于GNN的统合深度学习", "title_en": "GNN-based Unified Deep Learning", "authors": "Furkan Pala,Islem Rekik", "background": "深度学习模型在医疗影像中的泛化能力通常不佳，尤其是在不同医学影像技术、采集协议、患者群体、人口统计学和设备导致的数据分布变化（领域断裂）的情况下。各医院可能需要训练不同模型来匹配本地数据，这些模型在任务学习、宽度和深度上各不相同。例如，一些医院可能使用欧几里得架构（如MLP和CNN）处理表格或网格状图像数据，而另一些医院则可能需要非欧几里得架构（如图神经网络GNN）来处理不规则数据（如脑连接图）。如何在数据集之间统一训练这些异构模型并增强它们的泛化能力仍然是一个开放问题。", "innovation": "该研究提出了一种统一学习的新范式，该范式将每个模型编码为图表示形式，使它们能够在共享的图学习空间中统一。然后，图神经网络（GNN）能够指导这些统一模型的优化。通过解耦个体模型的参数，并通过统一GNN（uGNN）控制这些参数，该方法支持不同架构（如MLP、CNN和GNN）和分布下的参数共享和知识转移，从而提高泛化能力。评估结果显示，统一学习在模型训练于独特的数据分布并在混合数据集上测试时能提升性能，表现出对未见过的大分布转变数据的强大稳健性。", "conclusion": "该研究提出了一种统一学习的新范式，该方法利用图神经网络优化异构深度学习模型，即使在不同数据分布的情况下也能提高泛化性能。评估表明，该方法在MorphoMNIST和MedMNIST基准（PneumoniaMNIST和BreastMNIST）中表现出色，尤其是在数据分布发生较大变化的情况下，该方法也能表现出强大稳健性。"}
{"llm_update_time": "20250816", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.10541", "html_url": "https://arxiv.org/abs/2508.10541", "title": "使用蛋白质语言模型和泛化导向评估推动准确的过敏原预测", "title_en": "Driving Accurate Allergen Prediction with Protein Language Models and Generalization-Focused Evaluation", "authors": "Brian Shing-Hei Wong,Joshua Mincheol Kim,Sin-Hang Fung,Qing Xiong,Kelvin Fu-Kiu Ao,Junkang Wei,Ran Wang,Dan Michelle Wang,Jingying Zhou,Bo Feng,Alfred Sze-Lok Cheng,Kevin Y. Yip,Stephen Kwok-Wing Tsui,Qin Cao", "background": "过敏原，通常是指能够触发不良免疫反应的蛋白质，对公共健康构成了重大挑战。为了准确识别过敏原蛋白质，我们介绍了一种基于xTrimoPGLM蛋白质语言模型的计算框架Applm。Applm在多种任务中都取得了优异表现，这些任务具有高度仿真的实际世界难度。包括识别样本训练集中未出现的新过敏原，区分序列相似度高但具有过敏原与非过敏原差异的同源蛋白质，以及评估引起蛋白序列微小变化的功能后果。我们的分析确认了xTrimoPGLM的关键作用，该模型最初通过训练一万亿个标记以捕捉蛋白质序列的一般特性，对于Applm的性能至关重要。", "innovation": "我们开发了Applm，这是一种基于具有100亿参数的xTrimoPGLM蛋白质语言模型的计算框架，用于准确预测过敏原蛋白质。Applm在多种任务上的表现超越了七个最先进的方法，主要在于能够识别新型过敏原，区分相似序列的过敏原与非过敏原，以及评估功能后果等。xTrimoPGLM模型在捕捉蛋白质序列的广泛特性方面起到了关键作用。此外，我们还提供了Applm的开源软件和数据集，以促进未来相关研究的进步与创新。", "conclusion": "我们的研究表明，Applm在使用蛋白质语言模型进行过敏原预测方面具有很高的准确性和可靠性，能够有效地解决实际中的复杂问题。通过使用我们的软件和基准数据集，未来的研究将进一步推动这一领域的发展。"}
{"llm_update_time": "20250816", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.10587", "html_url": "https://arxiv.org/abs/2508.10587", "title": "使用生成对抗变换器的能源数据自监督时空超分辨率", "title_en": "Self-Supervised Temporal Super-Resolution of Energy Data using Generative Adversarial Transformer", "authors": "Xuanhao Mu,Gökhan Demirel,Yuzhe Zhang,Jianlei Liu,Thorsten Schlachter,Veit Hagenmeyer", "background": "在基于能源系统模型的能源网络设计和操作中，时间粒度的缺口需要通过时间序列重采样来填补。传统上，上采样方法虽然计算效率高，但会带来信息损失或增加噪声。先进的模型如时间序列生成模型、超分辨率模型和插值模型显示出潜力，但也面临着根本性的挑战。超分辨率模型或插值模型的输入低分辨率时间序列可能稀疏且缺乏上下文，这会影响它们的准确性。此外，这些模型通常依赖于监督学习范式，但在上采样应用场景中，这需要原始存在的高分辨率时间序列，从而产生了一个无法克服的悖论。", "innovation": "本文提出了一种新的方法，使用生成对抗变换器（GATs），可以在不使用任何真实高分辨率数据的情况下进行训练，从而解决上述传统上采样方法存在的问题。相较于传统的插值方法，该方法能够将上采样任务的均方根误差（RMSE）降低9%，并提高了模型预测控制（MPC）应用场景的准确性13%。", "conclusion": "研究引入了一种基于生成对抗变换器的新方法，该方法通过自监督学习方式，有效解决了基于能源系统模型设计和操作中的时间粒度问题，提高了上采样任务的准确性与模型预测控制的应用场景表现。"}
{"llm_update_time": "20250816", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.10598", "html_url": "https://arxiv.org/abs/2508.10598", "title": "Oops!... 他们再次窃取了它：针对拆分学习的攻击", "title_en": "Oops!... They Stole it Again: Attacks on Split Learning", "authors": "Tanveer Khan,Antonis Michalas", "background": "拆分学习（SL）是一种协作学习方法，通过在客户端保留数据并在服务器端仅共享中间输出来提高隐私性。然而，SL的分布式特性带来了新的安全挑战，需要全面探索潜在的攻击。已有研究对SL进行了系统的攻击审查，根据攻击者的角色、隐私风险类型、数据泄露时间和位置等因素对其进行分类。研究还分析了现有防御措施，包括加密方法、数据修改手段、分布式技术和混合解决方案。研究发现，现有的防御措施存在安全漏洞，反映了它们的有效性和局限性。这些发现指出了现有的挑战和未来方向，为改善拆分学习隐私问题和指导进一步研究提供了有价值的信息。", "innovation": "该研究系统地审查了拆分学习（SL）的各种攻击，并根据攻击者的角色、隐私风险类型、数据泄露时间和位置等因素对其进行分类。此外，分析了现有的防御措施，包括加密方法、数据修改手段、分布式技术和混合解决方案，揭示了当前防御措施的安全漏洞，明确了改进和研究的未来方向。", "conclusion": "通过识别现有的挑战和未来方向，这项工作为改善拆分学习（SL）的隐私问题和指导进一步研究提供了有价值的信息。"}
{"llm_update_time": "20250816", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.10255", "html_url": "https://arxiv.org/abs/2508.10255", "title": "联邦个性化建模在多租户云平台中的异常检测", "title_en": "Federated Anomaly Detection for Multi-Tenant Cloud Platforms with Personalized Modeling", "authors": "Yuxi Wang,Heyao Liu,Nyutian Long,Guanzi Yao", "background": "本文提出了一个基于联邦学习的异常检测方法，旨在解决多租户云环境中数据隐私泄露、异构资源行为以及集中建模限制的关键挑战。方法通过建立涉及多个租户的联邦训练框架，每个租户使用本地的私有资源使用数据进行模型训练。通过参数聚合优化全局模型，实现了跨租户协作异常检测，同时保护数据隐私。通过引入个性化参数调整机制，增强模型对多样资源使用模式的适应能力，使得模型既保留租户特定特征表示，又共享全局知识。模型输出阶段使用马氏距离计算异常得分，提高了异常检测的准确性和稳定性。实验使用云平台的真实遥测数据构建了一个模拟多租户环境，分别在不同参与率和噪声注入条件下评估模型性能，证明了该方法的鲁棒性和检测准确性。实验结果表明，该方法在准确率、召回率和F1分数等关键指标上优于现有主流模型，并且在多种复杂场景下保持了稳定性能。这表明该方法在云计算环境中智能资源监控和异常诊断的实际应用潜力显著。", "innovation": "引入了个性化参数调整机制，增强了模型对多样资源使用模式的适应能力，使得模型既保留租户特定特征表示，又共享全局知识。通过使用马氏距离计算异常得分，提高了异常检测的准确性和稳定性。该方法在多租户云平台中展示了业界领先的鲁棒性和检测准确性，尤其在准确率、召回率和F1分数等关键指标上，优于现有主流模型，并且在多种复杂场景下保持了稳定性能。", "conclusion": "实验结果证实了该提出的基于联邦学习的个性化异常检测方法在多租户云平台中的有效性，特别是在资源监控和诊断方面。该方法展示了在保护隐私的同时，保持模型高性能、高稳定性的潜力，为未来的云平台监测和异常诊断提供了新的解决方案。"}
{"llm_update_time": "20250816", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.10628", "html_url": "https://arxiv.org/abs/2508.10628", "title": "基于项目反应理论的实例质量导向的数据分区方法：超越随机抽样", "title_en": "Beyond Random Sampling: Instance Quality-Based Data Partitioning via Item Response Theory", "authors": "Lucas Cardoso,Vitor Santos,José Ribeiro Filho,Ricardo Prudêncio,Regiane Kawasaki,Ronnie Alves", "background": "机器学习模型的稳健验证是至关重要的，然而传统的数据分区方法往往忽视了每个实例的内在质量。本文探讨了如何利用项目反应理论（IRT）参数来表征和指导模型验证阶段的数据分区，以改善模型性能并揭示数据集中实例的内在异质性。", "innovation": "本文创新性地提出了基于IRT参数进行实例质量导向的数据分区方法，通过这种方法，可以更好地理解和控制模型的偏差和方差之间的权衡，同时揭示了高猜测参数实例对模型性能的显著负面影响。", "conclusion": "研究结果表明，基于IRT的分区策略能够揭示数据集中实例的固有异质性，并发现具有信息性的实例子集。通过这种方法形成的平衡分区，有助于更好地理解模型的偏差和方差之间的权衡。高猜测参数实例的训练可能显著降低模型性能，而在同一数据集中的其他分区则能达到70%以上的准确率。"}
{"llm_update_time": "20250816", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.10644", "html_url": "https://arxiv.org/abs/2508.10644", "title": "基于条件信息瓶颈的多模态融合：克服讽刺检测中的捷径学习", "title_en": "Conditional Information Bottleneck for Multimodal Fusion: Overcoming Shortcut Learning in Sarcasm Detection", "authors": "Yihua Wang,Qi Jia,Cong Xu,Feiyu Chen,Yuhan Liu,Haotian Zhang,Liang Jin,Lu Liu,Zhichun Wang", "background": "多模态讽刺检测是一个复杂的任务，需要区分不同模态中的细微互补信号，同时过滤掉不相关的信息。许多先进方法依赖于从数据集中学习捷径，而不是提取与讽刺相关的特征。然而，实验表明，捷径学习会影响模型在实际场景中的泛化能力。此外，通过系统性实验揭示了当前多模态融合策略在多模态讽刺检测中的弱点，强调了聚焦有效多模态融合的重要性。", "innovation": "提出了一种基于条件信息瓶颈（Multimodal Conditional Information Bottleneck，MCIB）的多模态融合模型，以克服讽刺检测中的捷径学习问题。该模型通过去除MUStARD++方法中的捷径信号来构建MUStARD++$^{R}$，从而实现讽刺检测的有效多模态融合。", "conclusion": "实验结果表明，MCIB模型在不依赖于捷径学习的情况下，取得了最佳的性能。"}
{"llm_update_time": "20250816", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.10608", "html_url": "https://arxiv.org/abs/2508.10608", "title": "多目标强化学习中的方差减少策略梯度方法", "title_en": "Variance Reduced Policy Gradient Method for Multi-Objective Reinforcement Learning", "authors": "Davide Guidobene,Lorenzo Benedetti,Diego Arapovic", "background": "多目标强化学习（MORL）是传统强化学习（RL）的一种扩展，旨在同时优化多个通常相互冲突的目标，而不是仅仅专注于单一奖励。这种方法对于需要权衡各种目标的复杂决策场景至关重要，比如在提高性能的同时最小化成本。传统的政策梯度方法（PGMs）在处理多目标强化学习中大规模和连续的状态-动作空间时非常有效。然而，现有的PGMs在MORL中的样本效率很低，需要大量的数据才能有效。在此之前，为解决这个问题的尝试依赖于过于严格的假设，导致PGMs在大规模状态-动作空间中的可扩展性问题未能解决。", "innovation": "本文通过引入方差减少技巧来减少策略梯度的样本复杂性，同时保持对大型状态-动作空间的一般假设，提高了样本效率，从而克服了现有方法中的高样本不效率问题。", "conclusion": "本文通过使用方差减少技术改进了多目标强化学习中的策略梯度方法，提高了算法的样本效率，使其更适合处理大规模和连续的状态-动作空间，从而在实际应用中具有更高的可扩展性和效率。"}
{"llm_update_time": "20250816", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.10651", "html_url": "https://arxiv.org/abs/2508.10651", "title": "基于逻辑本体Weisfeiler-Leman变体和表格化方法的图学习", "title_en": "Graph Learning via Logic-Based Weisfeiler-Leman Variants and Tabularization", "authors": "Reijo Jaakkola,Tomi Janhunen,Antti Kuusisto,Magdalena Ortiz,Matias Selin,Mantas Šimkus", "background": "图分类问题在多个应用领域中非常重要，现有的方法包括图神经网络和图内核等技术，但这些方法在时间和内存效率上可能存在局限。该文旨在探讨一种新的基于表格化图数据通过Weisfeiler-Leman算法变体的方法来进行图分类。", "innovation": "提出了一种通过Weisfeiler-Leman算法变体对图数据进行表格化，然后应用处理表格数据的方法来进行图分类的新型方法。这种方法通过对底层逻辑框架进行修改获得了一个完整的Weisfeiler-Leman变体类，建立了它们表达能力的精确理论表征。实验表明，该方法与最先进的图神经网络和图内核方法相比，具有更高的时间和内存效率。", "conclusion": "提出的图学习方法在多个基准数据集上进行了测试，结果显示在准确度上与最先进的图神经网络和图内核方法相当，同时根据数据集的不同表现出更高的时间和内存效率。文中还简要讨论了直接从图数据集中提取可解释的模态逻辑公式的可能性。"}
{"llm_update_time": "20250816", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.10646", "html_url": "https://arxiv.org/abs/2508.10646", "title": "SPHENIC: 了解拓扑结构的多视图聚类方法在空间转录组学中的应用", "title_en": "SPHENIC: Topology-Informed Multi-View Clustering for Spatial Transcriptomics", "authors": "Chenkai Guo,Yikai Zhu,Jing Yangum,Renxiang Guan,Por Lip Yee,Guangdun Peng,Dayu Hu", "background": "空间转录体学的聚类分析通过整合空间位置信息，能够提供更全面的细胞亚群识别洞察。现有的方法在拓扑学习和空间邻域信息建模方面存在不足：一方面，拓扑信号往往不包含多细胞的信息交互动态，难以折中处理；另一方面，空间邻域信息模型不足导致了低质量的空间嵌入。这些问题限制了现有方法的性能和准确性。因此，迫切需要一种新的方法来解决这些问题，这种方法能够在保持稳定表现的同时，提升空间嵌入的质量。", "innovation": "SPHENIC（拓扑结构引导的空间持久同伦集成聚类方法）通过引入不变的拓扑特征来实现稳定的表征学习，并设计了空间约束和分布优化模块（SCDOM），以此增加细胞嵌入与空间邻域细胞的相似性，降低与非邻域细胞的相似性，从而生成有利于聚类的空间嵌入。此外，SPHENIC方法已在14个空间转录体切片基准数据集上通过了广泛的实验，证明了其在空间聚类任务上的优越性能，优于现有的最佳方法3.31%-6.54%。", "conclusion": "SPHENIC通过结合拓扑信号和空间位置信息，显著提高了空间转录体数据的聚类效果，为解决空间转录组学中的噪声问题和优化空间邻域关系提供了一种新的策略。"}
{"llm_update_time": "20250816", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.10701", "html_url": "https://arxiv.org/abs/2508.10701", "title": "REFN：一种针对1天/n天漏洞的网络强化学习框架", "title_en": "REFN: A Reinforcement-Learning-From-Network Framework against 1-day/n-day Exploitations", "authors": "Tianlong Yu,Lihong Liu,Ziyi Zhou,Fudu Xing,Kailong Wang,Yang Yang", "background": "由于网络设备的广泛部署和补丁延迟（平均补丁时间超过60天），1天或n天的漏洞利用对网络设备构成了严重威胁。现有的防御措施，如基于主机的补丁和网络过滤，由于在多种设备上扩展性有限、与嵌入式或遗留系统不兼容以及手动验证补丁易出错等问题而显得不足。", "innovation": "提出了REFN（Reinforcement Learning From Network），一个新颖的框架，该框架通过大型语言模型（LLMs）自主生成网络过滤规则，以防止1天或n天的利用。REFN通过使用在线网络奖励驱动的强化学习（RL）而不是传统的人类反馈驱动的强化学习（RLHF）来确保可伸缩性，并在边缘安全网关（例如Amazon Eero）上统一部署以确保兼容性。REFN通过在线验证真实网络流量来提高防攻击的稳健性。REFN还通过基于代理的缓解法解决训练LLMs的三个核心挑战：知识蒸馏扩展当前LLMs的漏洞修复知识、网络强化学习管道桥接语言与网络之间的鸿沟、在线代理验证解决LLMs的幻觉和非确定性问题。", "conclusion": "在22个1天或n天漏洞家族的评估中，REFN展现了有效性（替代方案的准确性高出21.1%）、效率（6.5小时的平均补丁时间）和可扩展性（轻松扩展到10,000个设备）。REFN是训练LLMs快速防止大规模1天或n天漏洞利用的一个初步步骤。"}
{"llm_update_time": "20250816", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.10713", "html_url": "https://arxiv.org/abs/2508.10713", "title": "在GPU上进行天线的电磁模拟以应用于机器学习", "title_en": "Electromagnetic Simulations of Antennas on GPUs for Machine Learning Applications", "authors": "Murat Temiz,Vemund Bakken", "background": "在机器学习应用于天线设计和优化的过程中，需要大量的天线仿真数据。然而，传统的电磁仿真软件的高计算复杂度使得在合理时间内生成足够的训练样本变得极具挑战性。为此，本文提出了一种基于开源电磁仿真软件（gprMax）和图形处理器（GPUs）的天线仿真框架，旨在通过多数量级的天线仿真结果来支持机器学习和代理模型的应用。", "innovation": "本文的创新点在于提出了一种利用基于图形处理器的开放源代码电磁仿真软件框架，用于机器学习和代理模型中大规模天线数据集的生成。通过与高性能CPU和游戏级GPU的比较，表明使用GPU可以显著提高仿真性能，特别是在天线参数估计方面。此外，还展示了开源电磁仿真软件在仿真微带天线方面能够达到与商业软件相近的效果。", "conclusion": "研究证明，使用入门级GPU在计算性能上比高端CPU有显著优势，而高端游戏级GPU则能实现比高端CPU大约18倍的计算性能。开源电磁仿真软件也能在模拟微带天线时提供接近商业软件的仿真结果。"}
{"llm_update_time": "20250816", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.10649", "html_url": "https://arxiv.org/abs/2508.10649", "title": "地理扩散模型在土地覆被渗透性变化预测中的应用", "title_en": "Geospatial Diffusion for Land Cover Imperviousness Change Forecasting", "authors": "Debvrat Varshney,Vibhas Vats,Bhartendu Pandey,Christa Brelsford,Philipe Dias", "background": "土地覆被当前及其未来的变化对地球系统过程有着显著的影响。例如，不透水面的增加加速了地表水的径流和减少了地下水的渗透，从而影响区域水文循环和洪水风险。虽然区域地球系统模型在高分辨率未来气候情景下预测水文和大气过程方面越来越能力强，但我们预测土地利用和覆被变化（LULC）的能力却落后了，这影响了风险和后果的评估。基于这些背景，本文提出了一个新颖的方法，利用生成式人工智能（GenAI）进行土地覆被变化预测，将LULC预测作为基于历史和辅助数据条件下的数据合成问题。", "innovation": "本文提出了一种利用生成式人工智能（GenAI）进行未来土地覆被变化预测的新方法。这种方法将LULC预测作为数据合成问题，并通过对美国本土整个地区的历史数据进行实验，训练了一个用于十周年土地覆被变化预测的扩散模型，其在平均分辨率不低于0.7×0.7平方公里的区域中的均残差误差（MAE）低于基准模型，表明这种生成模型能够捕捉到对未来变化重要的时空模式。未来研究还计划将物理属性和驱动变量的辅助信息纳入模型中，以支持不同的场景模拟。", "conclusion": "本文通过实验验证了利用生成式人工智能（GenAI）进行土地覆被变化预测的有效性，未来还将进一步探索利用物理属性和其他辅助信息的方法，以提高模型的预测能力，并支持不同场景的模拟。"}
{"llm_update_time": "20250816", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.10751", "html_url": "https://arxiv.org/abs/2508.10751", "title": "Pass@k 训练在大型推理模型中自适应平衡探索与利用", "title_en": "Pass@k Training for Adaptively Balancing Exploration and Exploitation of Large Reasoning Models", "authors": "Zhipeng Chen,Xiaobo Qin,Youbin Wu,Yue Ling,Qinghao Ye,Wayne Xin Zhao,Guang Shi", "background": "基于强化学习的验证奖励（RLVR）通常采用Pass@1作为奖励，但面对探索与利用之间的平衡问题，导致策略偏好保守行为，并可能收敛到局部最优解。因此，选择合适的奖励指标至关重要。虽然Pass@k在评估中有被使用，但其与RLVR中大规模语言模型（LLM）的探索能力的联系并未得到充分关注。因此，本文在Pass@k奖励下训练策略模型，并观察其探索能力的提升，进而通过分析推导优势的解析解，揭示了探索与利用不是互斥目标，并探索了RLVR中优势函数的设计方法，展示了潜力和未来研究方向。", "innovation": "采用Pass@k作为奖励指标，通过分析推导优势的解析解，直接设计优势函数以增强探索与利用之间的互动。并初步探索了RLVR中的优势函数设计，为方法研究提供了新的方向。", "conclusion": "探索和利用并不存在本质上冲突的目标，它们可以相互促进。Pass@k训练与优势函数的分析设计，展示了在大型推理模型中平衡探索与利用的有效方法，为未来的RLVR研究提供了新的方向。"}
{"llm_update_time": "20250816", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.10804", "html_url": "https://arxiv.org/abs/2508.10804", "title": "具可验证保障的非稳态休息多臂老虎机", "title_en": "Non-Stationary Restless Multi-Armed Bandits with Provable Guarantee", "authors": "Yu-Heng Hung,Ping-Chun Hsieh,Kai Wang", "background": "在线休息多臂老虎机(RMAB)通常假定每个臂遵循固定状态转换和奖励的平稳马尔可夫决策过程(MDP)。然而，在医疗保健和推荐系统等实际应用中，这些假设由于非平稳动态的出现而常常失效，给传统的RMAB算法带来了重大挑战。", "innovation": "本文考虑了受有限变化预算B约束的非平稳转移N-臂RMAB，提出了一种结合滑动窗口强化学习(RL)和上信心界(UCB)机制的RMAB算法，同时学习转移动态及其变化。通过引入可调节的遗憾定义，证明该算法达到了$\tilde{\text{O}}(N^2 B^{\frac{1}{4}} T^{\frac{3}{4}})$的遗憾上界，为非稳态RMAB问题提供了首个理论框架。", "conclusion": "本文提出的算法为非稳态RMAB问题提供了一个新的理论框架，并首次提供了可验证的遗憾上界。"}
{"llm_update_time": "20250816", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.10815", "html_url": "https://arxiv.org/abs/2508.10815", "title": "在线高斯过程数据缩减标准的比较", "title_en": "Comparison of Data Reduction Criteria for Online Gaussian Processes", "authors": "Thore Wietzke,Knut Graichen", "background": "高斯过程（GPs）因其灵活性和对不确定性有效的量化而在回归和系统识别领域得到广泛应用。然而，由于计算复杂性限制了其对大数据集的应用，尤其是在持续数据流场景下，数据点的累积使得即使对于稀疏高斯过程也变得不可处理。在线高斯过程通过定义最大数据点预算并移除冗余数据点来缓解这一问题。本文对几种数据缩减标准进行了统一比较，分析了它们的计算复杂性和缩减行为，并在基准函数和真实世界数据集上（包括动态系统识别任务）评估了这些标准。", "innovation": "本文提供了几种在线高斯过程数据缩减标准的统一比较，包括它们的计算复杂性和缩减行为。此外，提出了接受标准以进一步过滤冗余数据点。这项工作为选择在线高斯过程算法合适的标准提供了实用指南。", "conclusion": "本文的结论是，通过提出数据缩减标准的比较和进一步的接受标准，为选择适合在线高斯过程算法的数据缩减标准提供了实用指导。"}
{"llm_update_time": "20250816", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.10775", "html_url": "https://arxiv.org/abs/2508.10775", "title": "IBEX: 信息瓶颈探索的粗细分子生成在有限数据下的研究", "title_en": "IBEX: Information-Bottleneck-EXplored Coarse-to-Fine Molecular Generation under Limited Data", "authors": "Dong Xu,Zhangfan Yang,Jenna Xinyi Yao,Shuangbao Song,Zexuan Zhu,Junkai Ji", "background": "三维生成模型在基于结构的药物发现中越来越重要，但由于公共可用的蛋白质-配体复合物稀缺，其应用受到了限制。现有的大多数管道难以学习可传输的几何先验知识，因此容易过度拟合训练集偏差。因此，提出了一个名为IBEX的信息瓶颈探索的粗细分子生成管道，以应对基于结构的药物设计中蛋白质-配体复合物数据不足的问题。通过手动掩码和量化数据的信息密度，IBEX展示了其在细粒度优化和泛化方面的优势。", "innovation": "IBEX使用PAC-Bayesian信息瓶颈理论量化每个样本的信息密度，揭示不同掩码策略对泛化的影响。指标显示，与传统的从头生成相比，受限的骨架跳跃任务赋予模型更大的有效容量和改善的传输性能。IBEX保留了TargetDiff的原始架构和超参数，在生成兼容结合口袋的分子后，通过L-BFGS优化步骤进一步细化每个构象，优化五个基于物理的项和调整六个平移和旋转自由度，这些改进提高了原子精度对接的成功率、改进了平均Vina得分，并显著减少了外推误差。", "conclusion": "IBEX在CBGBench CrossDocked2020基础上，将零样本对接成功率从53%提高到64%，将Vina评分从-7.41 kcal/mol提高到-8.07 kcal/mol，并且在57个口袋中获得了最佳的中间Vina能量，大大提高了QED并实现了最优的有效性和多样性。"}
{"llm_update_time": "20250816", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.10785", "html_url": "https://arxiv.org/abs/2508.10785", "title": "增强节点级别图异常检测中自编码器的公平性", "title_en": "Enhancing Fairness in Autoencoders for Node-Level Graph Anomaly Detection", "authors": "Shouju Wang,Yuchen Song,Sheng'en Li,Dongmian Zou", "background": "图异步检测（GAD）在各个领域逐渐变得越来越重要。随着图神经网络（GNN）的快速发展，基于GNN的GAD方法取得了显著的性能提升。然而，GAD中的公平性问题迄今仍基本未被探讨。基于GNN的GAD模型可能会继承并放大训练数据中存在的偏见，这可能导致不公平的结果。尽管现有的工作集中在开发公平的GNNs上，但大多数方法针对的是节点分类任务，而这些模型通常依赖于简单的层结构而非基于自编码器的结构，后者是异常检测中最常用的基本架构。为了在自编码器模型中解决公平性问题，本文提出了一种名为DECAF-GAD的框架。该框架在保留GAD性能的基础上缓解了偏差。研究人员引入了一个结构性因果模型（SCM），将敏感属性从学习表示中分离出来，基于这一因果框架，他们提出了一个专门的自编码器架构以及一个公平性指导损失函数。", "innovation": "本文提出了一种名为DECAF-GAD的框架，它强调在自编码器模型中解决公平性问题。该框架通过引入结构性因果模型（SCM）将敏感属性从学习表示中分离出来，从而提出了一个专门的自编码器架构以及一个公平性指导损失函数。实验表明DECAF-GAD在保持异常检测性能的同时，还显著增强了公平性指标，超越了基线GAD方法。", "conclusion": "通过大量实验证明，DECAF-GAD不仅在异常检测性能上达到了竞争性水平，还在公平性指标上取得了显著的提升。对于自编码器在节点级别图异常检测中的公平性问题，该研究提供了一种有效的解决方案。"}
{"llm_update_time": "20250816", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.10824", "html_url": "https://arxiv.org/abs/2508.10824", "title": "记忆增强的变换器：从神经科学原理到技术解决方案的系统综述", "title_en": "Memory-Augmented Transformers: A Systematic Review from Neuroscience Principles to Technical Solutions", "authors": "Parsa Omidi,Xingshuai Huang,Axel Laborieux,Bahareh Nikpour,Tianyu Shi,Armaghan Eshaghi", "background": "记忆是智能的基本要素，支持不同生物及人工系统中的学习、推理和适应。尽管变换器架构在序列建模方面表现出色，但在长期上下文保留、持续学习和知识集成方面存在关键限制。本文综述了这些神经科学原理与记忆增强变换器技术之间的联系，并通过功能性目标（上下文扩展、推理、知识集成、适应）、记忆表示（参数编码、状态基、显式、混合）和集成机制（注意力融合、门控控制、关联检索）三个分类维度组织了近期进展。分析核心记忆操作（读取、写入、遗忘和容量管理）揭示了从静态缓存向适应性、在线学习系统的转变。", "innovation": "本文提出了一个统一框架，将神经科学原理与工程上的记忆增强变换器技术相结合，通过功能性目标、记忆表示和集成机制三个维度系统地组织了近期的进展，特别是揭示了从静态缓存向适应性、在线学习系统的转变，并识别了可扩展性和干扰等持续挑战及相应的解决策略，如分层缓冲和惊异门控更新等。", "conclusion": "本文合成了一个认知启发式、终身学习变换器架构的路线图，旨在推动该领域的进一步发展。"}
{"llm_update_time": "20250816", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.10866", "html_url": "https://arxiv.org/abs/2508.10866", "title": "数据归属证明的高效验证", "title_en": "Efficiently Verifiable Proofs of Data Attribution", "authors": "Ari Karchmer,Seth Neel,Martin Pawelczyk", "background": "数据归属方法旨在回答有关模型预测的反事实问题，例如“如果模型训练的数据集不同，预测结果会怎样？”然而，通过技术如经验影响或‘数据建模’来估计数据归属模型仍然非常耗费计算资源。这导致了严重的信任问题：只有少数计算资源丰富的实体能获取数据归属，资源受限的实体如何能信任这些归属结果，尤其是在这些结果用于重要下游应用（例如数据定价）时？", "innovation": "本文提出了一种交互验证范式来解决数据归属的信任问题。不信任但计算资源丰富的证明者学习数据归属，并与资源受限的验证者进行互动证明。该方法提供了形式上正确性、健壮性和效率的保证，特别是在有界准确率正确性（PAC）验证的意义上。验证者接受的数据归属与最优数据归属（以均方误差为准）最多相差ε，且概率为1-δ。即使证明者无限地偏离协议，验证者也可以检测到这一行为（或者获得数据归属），而这一失败的概率为δ。该协议确保了验证者的工作量(以必须独立重新训练模型的数量衡量)仅取决于1/ε，独立于数据集大小。", "conclusion": "本文结果应用于验证证明者计算布尔超立方体上任何线性函数的任何属性，这使得它们在各种归属任务中广泛应用。"}
{"llm_update_time": "20250816", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.10899", "html_url": "https://arxiv.org/abs/2508.10899", "title": "一个用于提取治疗设计先验知识的数据集", "title_en": "A Dataset for Distilling Knowledge Priors from Literature for Therapeutic Design", "authors": "Haydn Thomas Jones,Natalie Maus,Josh Magnus Ludan,Maggie Ziyu Huan,Jiaming Liang,Marcelo Der Torossian Torres,Jiatao Liang,Zachary Ives,Yoseph Barash,Cesar de la Fuente-Nunez,Jacob R. Gardner,Mark Yatskar", "background": "人工智能驱动的设计可以显著减少设计时间并提升新疗法的效果。现有的模拟器模型虽然能够探索广阔的潜在设计空间，但由于缺乏实验先验知识，可能会违反隐含的约束条件，比如所提出的分子结构可能具有高度的致突变性。因此，本研究提出了一个新的数据集，该数据集包含了从相关文献中提取的先验知识，可以帮助优化设计，提高模型的性能。", "innovation": "本研究创新地创建了一个名为\textit{\textbackslash ourdataset}的数据集，将大型语言模型的管道用于发现相关文献中的药物实体，并以简明合理的实体表示方式提取信息。该数据集包含32.3百万个自然语言事实对及相应的实体表示。研究还展示了利用该数据集训练的模型在治疗数据共同体内多个任务上的优越性。模型优化后的表现优于同类大模型，且在新型分子的设计中，利用该数据集设定的约束条件能提高提案的安全性。", "conclusion": "本研究发布了一个新数据集，利用该数据集构建的模型在多个治疗任务上表现出色，而且能够在GuacaMol中提出安全有效的新型分子设计建议。数据集已公开，未来将提供更多版本以适应不断增长的文献信息。"}
{"llm_update_time": "20250816", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.10836", "html_url": "https://arxiv.org/abs/2508.10836", "title": "SoK: Data Minimization in Machine Learning", "title_en": "SoK: Data Minimization in Machine Learning", "authors": "Robin Staab,Nikola Jovanović,Kimberly Mai,Prakhar Ganesh,Martin Vechev,Ferdinando Fioretto,Matthew Jagielski", "background": "数据最小化（DM）指的是仅收集完成特定任务所必需的数据的原则，这是许多数据保护法规如GDPR和CPRA的重要基础。违反该原则会产生重大现实后果，监管机构可能会处以数百万美元的罚款。值得注意的是，数据最小化在机器学习（ML）应用中的重要性尤为突出，这类应用通常依赖于大规模数据集，由此形成了一个新兴的研究领域——机器学习中的数据最小化（DMML）。然而，现有的其他ML隐私和安全话题的研究经常涉及到DMML的关切点，但没有明确承认它们之间的联系，这也导致了实践者中的困惑，阻碍了DM原则的实施和不同研究社区间术语、指标和评估标准的理解。", "innovation": "我们的研究引入了一个全面的DMML框架，包括统一的数据管道、对手和最小化点。这个框架使我们能够系统地审查关于数据最小化和相关的DMML方法的文献，并首次提供了一个结构化的概述，旨在帮助实践者和研究人员更有效地应用数据最小化原则。这项工作促进了统一的DM为中心的理解，提高了数据最小化策略在AI/ML中的更广泛采用率。", "conclusion": "我们的研究提供了一个DM框架，有助于实践者和研究人员更好地应用数据最小化原则，从而推动DM策略在AI/ML中的更广泛应用。"}
{"llm_update_time": "20250816", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.09325", "html_url": "https://arxiv.org/abs/2508.09325", "title": "SegDAC: 目标驱动的演员-评论家方法用于视觉强化学习", "title_en": "SegDAC: Segmentation-Driven Actor-Critic for Visual Reinforcement Learning", "authors": "Alexandre Brown,Glen Berseth", "background": "视觉强化学习（RL）因其需要从高维输入和噪音较大的奖励中学习感知与动作而极具挑战性。尽管存在大规模的视觉模型，将这些模型有效地整合到RL中以实现视觉泛化和改进样本效率仍然不清楚。", "innovation": "提出了SegDAC，一种目标驱动的演员-评论家方法。SegDAC使用Segment Anything (SAM) 进行以对象为中心的分解，并利用YOLO-World通过文本提示在语义上将部分进行绑定。它包含一个新颖的基于Transformer的架构，支持每个时间步骤动态数量的段，并通过在线RL有效学习关注哪些段，无需使用人工标签。", "conclusion": "通过在Maniskill3上应用SegDAC，这是覆盖了在强视觉干扰下各种操作任务的挑战性视觉泛化基准，研究结果表明SegDAC在视觉泛化方面取得了显著改善，前三项指标提高了前人的两倍性能，并在所有评估任务中接近或超过了先前的方法在样本效率方面也有所提升。"}
{"llm_update_time": "20250816", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.09994", "html_url": "https://arxiv.org/abs/2508.09994", "title": "聪明而非艰难地静默：部分抑制的对抗攻击", "title_en": "Whisper Smarter, not Harder: Adversarial Attack on Partial Suppression", "authors": "Zheng Jie Wong,Bingquan Shen", "background": "目前，自动语音识别（ASR）模型被广泛应用于多种场景。然而，近期的研究表明这些模型可能遭受对抗攻击，这些攻击能抑制或破坏模型的输出。本文研究并验证了这些攻击的鲁棒性，探索是否可以通过增加攻击的不可察觉性来提升这种攻击的效果。此外，发现将优化目标从完全抑制调整为部分抑制，可以进一步降低攻击的察觉性。本文还探讨了对抗攻击的潜在防御方法，并表明低通滤波器可能作为一种有效的防御措施具有潜力。", "innovation": "本文的研究创新之处在于，通过调整优化目标从完全抑制到部分抑制，成功地降低了对抗攻击的察觉性。另外，提出低通滤波器作为一种潜在有效的防御方法。", "conclusion": "本文研究验证了对抗攻击的鲁棒性，通过调整优化目标降低了攻击的察觉性，并探索了潜在的有效防御方法，特别是低通滤波器或可作为有效的防御措施。"}
{"llm_update_time": "20250816", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.09991", "html_url": "https://arxiv.org/abs/2508.09991", "title": "将AI创新与医疗需求融合：BC癌症注册中心引入现代NLP的教训", "title_en": "Bridging AI Innovation and Healthcare Needs: Lessons Learned from Incorporating Modern NLP at The BC Cancer Registry", "authors": "Lovedeep Gondara,Gregory Arbour,Raymond Ng,Jonathan Simkin,Shebnum Devji", "background": "自动化从临床文档中提取数据在医疗保健中具有极大的潜力，但实现自然语言处理（NLP）解决方案存在实际挑战。本文基于在英国哥伦比亚癌症登记处（BCCR）实施各类NLP模型进行信息提取和分类任务的经验，分享了从项目生命周期中学习到的关键经验教训。它强调了基于清晰的商业目标定义问题的重要性，而不是单纯的技术准确性，采用迭代的开发方法，并从项目伊始就促进跨学科的深度合作和共创设计，包括域专家、最终用户和ML专家。进一步的见解强调了实际模型选择（包括混合方法和在适当情况下采用更简单的方法）、对数据质量的严格关注（代表性、漂移、注释）以及结合人工在环验证和持续审计的人工错误缓解策略的重要性，并建立组织对AI的认知。本文提供的这些实践考虑点适用于广泛的医疗保健组织，旨在成功实施AI/NLP解决方案以改善数据管理流程，最终提升患者护理和公共卫生结果", "innovation": "提出了将AI创新与医疗需求融合的应用，在项目实施中强调实际问题定义、迭代开发和跨学科合作的经验。强调从数据质量和人工在环验证等方面采取有效措施，并加强组织对AI的认知。这些考虑点适用于广泛的医疗保健组织，以改善数据管理流程，并提高患者护理和公共卫生结果", "conclusion": "这些从英国哥伦比亚癌症登记处引入现代NLP的实践考虑，在以数据管理和患者护理及公共卫生结果为核心的背景下提供了指导，可以被广泛应用于医疗保健组织，以成功实施AI/NLP解决方案"}
{"llm_update_time": "20250816", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.10000", "html_url": "https://arxiv.org/abs/2508.10000", "title": "AutoGeTS: 基于知识的自动生成文本合成以改善文本分类", "title_en": "AutoGeTS: Knowledge-based Automated Generation of Text Synthetics for Improving Text Classification", "authors": "Chenhao Xue,Yuanzhe Jin,Adrian Carrasco-Revilla,Joyraj Chakraborty,Min Chen", "background": "在为实际应用开发文本分类模型时，一个主要挑战是收集足够数量的数据以涵盖所有文本类别。为应对这一挑战，该研究利用大型语言模型（LLMs）生成合成数据，并以这些数据来改进模型，无需等待更多实际数据的收集和标注。", "innovation": "该研究提出了一种自动化的工作流AutoGeTS，通过不同的输入示例来生成更“有效”的合成数据，以提高模型性能。为此，研究者设计了三种搜索策略，并通过一系列广泛的实验对其进行评估，从而提出了一个基于实验结果的集成算法，该算法可根据类别的特性选择最适合的搜索策略。", "conclusion": "进一步的实验表明，这种集成方法在采用LLMs改善分类模型方面比我们自动化工作流中的任何一个单独策略都更有效。"}
{"llm_update_time": "20250816", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.10732", "html_url": "https://arxiv.org/abs/2508.10732", "title": "APFL: 双流最小二乘的分析个性化联邦学习", "title_en": "APFL: Analytic Personalized Federated Learning via Dual-Stream Least Squares", "authors": "Kejia Fan,Jianheng Tang,Zhirui Yang,Feijiang Han,Jiaxu Li,Run He,Yajiang Huang,Anfeng Liu,Houbing Herbert Song,Yunhuai Liu,Huiping Zhuang", "background": "个性化联邦学习（PFL）面临着通过协作训练将个性化模型交付给个体客户端的挑战，而现有的PFL方法常因非IID数据的困扰，严重妨碍了集体泛化，进而影响了个性化努力的效果。", "innovation": "本文提出了通过双流最小二乘双流分析的分析个性化联邦学习（APFL）方法。在APFL中，采用一种固定的基础模型进行特征提取，并在此之后开发了双流的分析模型以实现集体泛化和个体个性化。具体来说，APFL结合了一个用于所有客户端泛化的共享主流，以及一个用于每个个体客户端局部个性化的专用精炼流。这些分析方法赋予了APFL异质性不变的理想特性，理论上意味着每个个性化模型在其他所有客户端数据分布如何异质的情况下依然保持一致。同时，我们在各种数据集上的实证结果也验证了APFL优于最先进的基线，其准确性优势在1.10%-15.45%之间。", "conclusion": "本文提出的APFL在不同数据集上的实证结果表明，其在个性化联邦学习中取得了优于现有方法的优越性能。"}
{"llm_update_time": "20250816", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.09995", "html_url": "https://arxiv.org/abs/2508.09995", "title": "zERExtractor：一种从科学文献中自动提取酶促反应数据的平台", "title_en": "zERExtractor:An Automated Platform for Enzyme-Catalyzed Reaction Data Extraction from Scientific Literature", "authors": "Rui Zhou,Haohui Ma,Tianle Xin,Lixin Zou,Qiuyue Hu,Hongxi Cheng,Mingzhi Lin,Jingjing Guo,Sheng Wang,Guoqing Zhang,Yanjie Wei,Liangzhen Zheng", "background": "随着酶动力学文献的迅速增长，生物化学数据库的整理能力难以跟上，阻碍了AI驱动的建模和知识发现。", "innovation": "zERExtractor是一个自动化且可扩展的平台，能从科学文献中全面提取酶促反应和活性数据。该平台以统一的模块化架构支持先进的模型，如大规模语言模型（LLMs）作为可互换组件集成，实现系统持续进化。平台结合深度学习、高级OCR、语义实体识别和基于提示的大规模语言模型模块，以及人工专家修正，从异构文档格式中提取动力学参数、酶序列、底物SMILES、实验条件和分子图。通过结合AI辅助标注、专家验证和迭代改进的主动学习策略，系统快速适应新数据源。", "conclusion": "zERExtractor通过灵活的插件准备框架和高精度提取填补了酶动力学长期以来的数据空白，为未来的AI驱动的酶建模和生物化学知识发现奠定了基础。"}
{"llm_update_time": "20250816", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.10004", "html_url": "https://arxiv.org/abs/2508.10004", "title": "用户对注意力可视化感知的影响：证据基础医学文献解释可读性方面的效果", "title_en": "User Perception of Attention Visualizations: Effects on Interpretability Across Evidence-Based Medical Documents", "authors": "Andrés Carvallo,Denis Parra,Peter Brusilovsky,Hernan Valdivieso,Gabriel Rada,Ivania Donoso,Vladimir Araujo", "background": "注意力机制是Transformer架构的核心组件，虽然它能提升模型性能，但也有研究将其作为一种解释机制，通过关联输入特征（例如文档中的标记）的注意力权重来实现。在证据医学领域，这些解释有助于医生理解并与用于归类生物医学文献的AI系统进行互动。然而，尚无共识是否认为注意力权重提供了有帮助的解释。此外，很少有研究探讨可视化注意力如何影响其作为解释辅助的有用性。", "innovation": "本文通过用户研究评估了注意力基础上的解释是否支持用户在生物医学文档分类中的表现，并探讨了不同的可视化方式是否会影响用户对这些解释的感知。研究发现，虽然Transformer模型（XLNet）可以准确分类文献，但注意力权重并未被视为特别有助于解释预测。这与Munzner提出的视觉有效性原则相反，后者倾向于使用精确的编码（如条形图长度），而用户则更偏好直观的格式，如文本亮度或背景颜色。", "conclusion": "研究结果不完全支持注意力权重对于解释的总体有用性，但暗示它们的感知有用性受其可视化方式的影响。"}
{"llm_update_time": "20250816", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.10008", "html_url": "https://arxiv.org/abs/2508.10008", "title": "在线课程讨论论坛帖子的多维度分类", "title_en": "Multidimensional classification of posts for online course discussion forum curation", "authors": "Antonio Leandro Martins Candido,Jose Everardo Bessa Maia", "background": "在线课程中的讨论论坛需要持续的更新和维护，这使得频繁重新训练大型语言模型（LLMs）成为资源密集型的过程。为避免成本高昂的微调，该论文提出并评估了贝叶斯融合的方法。这种方法将预训练的通用LLM与针对本地数据训练的分类器的多维度分类评分相结合。", "innovation": "提出并评估了使用贝叶斯融合的方法。该方法结合了预训练的一般大型语言模型和本地数据训练的分类器的多维度分类评分，以提高分类性能，并展示了与单独使用每个分类器相比，提出的方法在性能上有所提升，并且与LLM微调方法具有竞争力。", "conclusion": "该研究展示了贝叶斯融合可以提高在线课程讨论论坛帖子分类的性能，并且在性能上与LLM微调方法相当。这种方法可以降低需要频繁微调大型语言模型带来的资源消耗和成本。"}
{"llm_update_time": "20250816", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.09999", "html_url": "https://arxiv.org/abs/2508.09999", "title": "XFacta: 当代现实世界数据集与多模态大语言模型下的多模态误导信息检测评估", "title_en": "XFacta: Contemporary, Real-World Dataset and Evaluation for Multimodal Misinformation Detection with Multimodal LLMs", "authors": "Yuzhuo Xiao,Zeyu Han,Yuhan Wang,Huaizu Jiang", "background": "社交媒体上多模态误导信息的快速传播需要更有效和更稳健的检测方法。近年来，利用多模态大语言模型（MLLMs）的相关进展展示了在解决这一问题方面的潜力。然而，现有方法在证据检索与推理之间的瓶颈问题仍然不明确，这阻碍了该领域进一步的发展。在数据集方面，现有基准要么包含过时的事件，导致由于现代社交媒体情景与MLLMs之间的不一致，从而引起评估偏差，要么是人为合成的数据，不能反映真实的误导信息模式。此外，缺少对基于MLLMs的模型设计策略的全面分析。", "innovation": "本文介绍了XFacta，一个当代现实世界数据集，更好地用于评估基于MLLMs的检测方法。我们系统地评估了各种基于MLLMs的误导信息检测策略，评估了不同的架构和规模的模型，并将这些评估与现有检测方法进行了基准测试。以此为基础，我们进一步开发了一个半自动检测-循环框架，持续更新XFacta以保持其当代相关性。我们的分析提供了该领域向前发展的宝贵见解和实践方法。已发布代码和数据。", "conclusion": "分析提供了该领域向前发展的宝贵见解和实践方法。通过这些分析，我们进一步使一个半自动检测-循环框架得以实现，该框架可以持续更新XFacta以保持其当代相关性。"}
{"llm_update_time": "20250816", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.10034", "html_url": "https://arxiv.org/abs/2508.10034", "title": "使用深度学习的Jet图像标记：一种集成模型", "title_en": "Jet Image Tagging Using Deep Learning: An Ensemble Model", "authors": "Juvenal Bassa,Vidya Manian,Sudhir Malik,Arghya Chattopadhyay", "background": "在高能粒子物理中，喷流分类对理解基本相互作用和探索标准模型之外的现象至关重要。喷流起源于夸克和胶子的分形和强子化，并且由于其复杂的多维结构，使得识别变得具有挑战性。传统的分类方法往往难以捕捉这些细节，因此需要使用高级机器学习方法。", "innovation": "本文采用两种神经网络作为集成模型，同时进行标记，将喷流数据转换为二维直方图，而不是将其表示为更高维度空间中的点。通过这种集成方法学习喷流特征，利用每个构成网络的优点，实现优于单一网络的性能。", "conclusion": "与单独的网络相比，该集成模型可以实现喷流在二元和多分类中的应用，并指出该集成方法在标签喷流类型方面的优越表现。"}
{"llm_update_time": "20250816", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.10017", "html_url": "https://arxiv.org/abs/2508.10017", "title": "使用SMOTETomek和FedProx在不平衡临床数据上实现差分隐私联邦学习的稳健管道", "title_en": "A Robust Pipeline for Differentially Private Federated Learning on Imbalanced Clinical Data using SMOTETomek and FedProx", "authors": "Rodrigo Tertulino", "background": "联邦学习（FL）为协作健康研究提供了一种革新的方法，使模型可以在去中心化的数据上进行训练，同时保护患者隐私。但是，在与差分隐私（DP）结合使用时，这些技术在隐私和临床实用性之间引入了重要权衡，特别是当医疗数据集中存在严重的类别不平衡时，问题更加复杂。现有的方法在处理不平衡数据时表现出色，但在某些情况下可能失败。", "innovation": "该研究通过系统性的多阶段分析解决了联邦学习中在不平衡临床数据上的隐私和临床实用性问题。首先，作者在客户端整合了SMOTETomek（合成少数类过采样技术与Tomek链）以处理数据不平衡，成功开发了一种实用的临床模型。其次，提出并优化了非IID的数据处理流程，使用调优的FedProx算法。研究结果揭示出隐私预算（ε）和模型召回率之间存在明显的非线性权衡，优化后的FedProx始终优于标准的FedAvg。在隐私-实用性前沿上发现了最佳运行区域，可以达到强隐私保证（ε=9.0）的同时保持高临床实用性（召回率超过77%）。最终，该研究提供了一种实用的、可操作的方法论方案，用于构建对于复杂异质医疗数据有效、安全、准确的诊断工具。", "conclusion": "研究结果证实了在不平衡临床数据上使用联邦学习和差分隐私技术的有效性，并提出了一个优化的联邦学习框架，该框架能够在保持强大隐私保证的同时提高临床实用性。这为未来在医疗领域应用联邦学习和差分隐私提供了宝贵的启示和实践指导。"}
{"llm_update_time": "20250816", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.10035", "html_url": "https://arxiv.org/abs/2508.10035", "title": "基于神经网络的智能电网家庭能源系统中FDIA的多类检测与分类", "title_en": "Neural Network-Based Detection and Multi-Class Classification of FDI Attacks in Smart Grid Home Energy Systems", "authors": "Varsha Sen,Biswash Basnet", "background": "虚假数据注入攻击（FDIAs）对智能电网基础设施，特别是在家用区域网络（HANs）中构成了重大威胁。HANs广泛采用实时监控和控制，但缺乏严格的安全控制，因此成为了攻击者操纵能源需求模式并可能扰乱更广泛电网操作的首选入口。这些攻击会破坏智能电表数据的完整性，使恶意行为者能够无须触发常规警报就能操纵消费值，从而在住宅和公用事业规模基础设施中造成严重漏洞。", "innovation": "本论文提出了一种基于机器学习的框架，用于通过家居能源数据检测和分类虚假数据注入攻击（FDIAs）。该框架利用轻量级的人工神经网络（ANN）提供实时检测，通过使用最重要的能量消耗、成本和时间上下文来工作。为了分类不同类型的攻击，训练了一个双向LSTM来识别正常、梯形和对数正态攻击形状，通过学习数据中的序列依赖性来实现。生成了一个合成时间序列数据集来模拟真实的家庭行为。实验结果表明，提出的模型在识别和分类FDIAs方面是有效的，提供了一种增强边缘电网弹性的可扩展解决方案。", "conclusion": "本研究为提高智能电网住宅端点的网络安全，建立智能、数据驱动的防御机制做出了贡献，提出了基于边缘检测和多类分类的智能电网家庭能源系统中FDIAs防御方法。"}
{"llm_update_time": "20250816", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.10028", "html_url": "https://arxiv.org/abs/2508.10028", "title": "PREF：LLM中个性化文本生成的无参考评估", "title_en": "PREF: Reference-Free Evaluation of Personalised Text Generation in LLMs", "authors": "Xiao Fu,Hossein A. Rahmani,Bin Wu,Jerome Ramos,Emine Yilmaz,Aldo Lipani", "background": "个性化文本生成对于用户为中心的信息系统至关重要，然而大多数评估方法忽视了用户的个体差异。PREF框架旨在通过不依赖于黄金个性化参考，联合测量通用输出质量和用户特定对齐度来评价个性化文本生成的质量，从而解决这一问题。", "innovation": "PREF创新性地引入了一个三阶段管道框架：覆盖阶段使用大规模语言模型生成全面的查询特定指导方针；偏好阶段根据目标用户的信息或推断偏好重新排序和有选择地增强这些因素；评分阶段将语言模型应用于评分，根据评价标准评估候选答案，确保基本充足性并捕捉主观优先级。该框架分离了覆盖和偏好，提高了鲁棒性、透明度和可重用性，并允许小型模型模拟大模型的个性化质量。通过在PrefEval基准上的实验表明，PREF在隐含偏好跟踪任务中取得了更高的准确率和更好的校准，并且更接近于人类判断。", "conclusion": "PREF框架通过实现可扩展、可解释和用户对齐的评估，为个性化语言生成系统的更可靠评估和开发奠定了基础。"}
{"llm_update_time": "20250816", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.10036", "html_url": "https://arxiv.org/abs/2508.10036", "title": "反思然后学习：基于反省困惑的主动提示信息提取", "title_en": "Reflect then Learn: Active Prompting for Information Extraction Guided by Introspective Confusion", "authors": "Dong Zhao,Yadong Wang,Xiang Chen,Chenxi Wang,Hongliang Dai,Chuanxing Geng,Shengzhong Zhang,Shaoyuan Li,Sheng-Jun Huang", "background": "大语言模型（LLMs）在少量样本信息抽取（IE）中展现出显著潜力，但其性能高度依赖于上下文示例的选择。传统的选择策略常常无法提供有信息量的指导，因为它们忽略了导致模型错误的关键来源：不仅仅是语义内容的混淆，还包括信息抽取任务所需的格式结构生成。为了应对这个问题，作者提出了一种名为Active Prompting for Information Extraction (APIE)的新颖主动提示框架，该框架使用一种我们称之为反省困惑的原则。", "innovation": "该方法通过一种独特的双组件不确定性度量——格式不确定性（生成正确语法的难度）和内容不确定性（提取语义的一致性），使LLM能够评估自身的困惑。通过基于此综合评分对未标记数据进行排名，框架积极选择最具挑战性和信息量的样本作为少量示例。该作品展示了在构建有效和可靠的结构生成系统时，对模型不确定性进行精细的、双层的观察的重要性。实验结果显示，该方法在四个基准上的性能始终优于强大基线，显著提高了抽取准确性和鲁棒性。", "conclusion": "本文的工作突出强调了在构建有效的结构生成系统时，需要对模型不确定性进行精细的、双层的观察。方法的实验结果表明，通过使用反思困惑指导的主动提示，可以显著提高信息抽取的准确性和鲁棒性。"}
{"llm_update_time": "20250816", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.10025", "html_url": "https://arxiv.org/abs/2508.10025", "title": "利用生成型人工智能实时检测和解释产褥期抑郁", "title_en": "Detecting and explaining postpartum depression in real-time with generative artificial intelligence", "authors": "Silvia García-Méndez,Francisco de Arriba-Pérez", "background": "产后抑郁症（PPD）是产妇在分娩后经历的诸多挑战中的一种严重情况，严重影响了她们的心理和身体健康。因此，及时检测PPD及其相关风险因素并通过专门的预防措施进行评估和干预变得至关重要。为此，本文探讨了利用最新的技术帮助医护人员作出决策，实现即时筛查和治疗建议的方法。结合自然语言处理、机器学习（ML）和大规模语言模型（LLMs），本文开发了一个实时、经济、非侵入式的免费语言分析系统，以智能筛查PPD及其相关风险因素。为了解决黑箱问题，并使最终用户能够理解预测结果，本文采用了可解释的机器学习模型（即基于树的算法）结合大规模语言模型的方法，结合特征重要性和自然语言解释预测结果。", "innovation": "本文提出了一种利用自然语言处理、机器学习和大规模语言模型结合生成型人工智能的智能PPD筛查系统。该系统能够实现90%的PPD检测准确率，在所有评估标准上均优于文献中的竞争解决方案。此外，通过结合可解释的机器学习模型和大规模语言模型，本文成功解决了黑箱问题，使得最终用户能够理解预测结果。", "conclusion": "本文的研究结果表明，该智能PPD筛查系统能够实现快速、经济、非侵入式的筛查和治疗建议，对于及时评估和干预产褥期抑郁及其相关风险因素具有重要意义。"}
{"llm_update_time": "20250816", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.10026", "html_url": "https://arxiv.org/abs/2508.10026", "title": "SABER: Switchable and Balanced Training for Efficient LLM Reasoning", "title_en": "SABER: Switchable and Balanced Training for Efficient LLM Reasoning", "authors": "Kai Zhao,Yanjun Zhao,Jiaming Song,Shien He,Lusheng Zhang,Qiang Zhang,Tianjiao Li", "background": "大型语言模型（LLMs）通过链式思考推理能够实现复杂任务的高准确性，但在应用于所有问题时面临着高额的推理成本和延迟问题。", "innovation": "提出了SABER（可切换和平衡训练以提高LLM推理效率），这是一种强化学习框架，赋予LLMs用户可控、基于令牌预算的推理方式。SABER对每个训练示例的基模型思考令牌使用情况进行分析，并分配到预定义的预算层级中。在微调过程中，模型通过系统提示和长度敏感的奖励来尊重其分配的预算。此外，SABER还支持四种离散的推理模式，分别适用于不同的延迟与推理深度权衡。", "conclusion": "广泛的评估表明，SABER在严格预算下保持高准确度，具有平滑降级效果，并且在不同尺度和领域间具备有效的泛化能力。特别是SABER的FastThink模式，在MATH基准测试上比基模型减少了推理长度65.4%，并且提高了3.6%的准确度。"}
{"llm_update_time": "20250816", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.10064", "html_url": "https://arxiv.org/abs/2508.10064", "title": "动态对齐：适应性神经计算的原则", "title_en": "Dynamical Alignment: A Principle for Adaptive Neural Computation", "authors": "Xia Chen", "background": "人们普遍认为神经网络的计算能力取决于其静态架构。本文挑战了这一观点，指出固定神经结构可以运行在基本不同的计算模式之上，这些模式由输入信号的时间动态驱动而非其结构。", "innovation": "提出了“动态对齐”（Dynamical Alignment）的原则，该原则通过将静态输入编码为可控的时间动力轨迹，揭示了一种二模态优化景观，并受相空间体积动力学控制。", "conclusion": "通过这种原理，找到了解释受脑灵感的脉冲神经网络（SNNs）长期不如人工神经网络绩效的新型解决方案。该研究展示了计算能力可以从输入动态与神经元整合的时间尺度对齐中获得，并为神经科学中的长期观察到的不同特性提供了统一的视角。"}
{"llm_update_time": "20250816", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.10055", "html_url": "https://arxiv.org/abs/2508.10055", "title": "贝叶斯模型用于特征和自回归滞后同时选择：理论及其在环境与金融预测中的应用", "title_en": "Bayesian Models for Joint Selection of Features and Auto-Regressive Lags: Theory and Applications in Environmental and Financial Forecasting", "authors": "Alokesh Manna,Sujit K. Ghosh", "background": "该研究提出了一种贝叶斯框架，用于带自相关误差的线性回归中可变选择，包括滞后协变量和自回归结构。这种设置广泛应用于时间序列分析，如金融建模、水文预报和气象学等需要捕捉时间依赖性的领域。研究方法采用了具有松果-泥浆先验的分层贝叶斯模型，用于同时选择相关协变量和滞后误差项。", "innovation": "该方法提出了一种高效两阶段MCMC算法，分别采样变量包含指示符和模型参数，以应对高维计算挑战。理论分析表明，在候选预测因子数量随样本增加指数增长的情况下，后验选择一致性仍可成立。通过模拟和实际应用（地下水深度预测和S&P 500对数回报建模），研究展示了在变量选择准确性和预测性能上的显著提高。与现有方法相比，该框架在自相关噪声条件下具有更低的均方预测误差（MSPE），且能更好地识别真实模型组成部分，并且更具鲁棒性。", "conclusion": "该框架提升了自回归设置下的模型解释性和预测性能，对于环境与金融预测具有实际应用价值。"}
{"llm_update_time": "20250816", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.10758", "html_url": "https://arxiv.org/abs/2508.10758", "title": "针对层次点云数据集的原生训练稀疏注意力机制", "title_en": "Natively Trainable Sparse Attention for Hierarchical Point Cloud Datasets", "authors": "Nicolas Lapautre,Maria Marchenko,Carlos Miguel Patiño,Xin Zhou", "background": "基于变压器模型在处理大规模物理系统数据集时，依赖于解决注意力机制的二次时间复杂度问题。现有研究往往集中在优化模型结构或机制来提高效率和视野（receptive field），本文尝试结合Erwin架构与原生稀疏注意力（NSA）机制，目标是改善大规模物理系统的模型性能，并验证该机制在非顺序数据（如点云数据）中的适应性。背景提到了三个物理科学领域的数据集（天体模拟、分子动力学和气压建模）作为实验依据，这些领域涉及大量的点位数据，是点云数据的一种。", "innovation": "创新点在于提出了Erwin NSA模型，通过适应NSA机制以适用于非顺序数据，并结合Erwin架构提高模型对大规模物理系统的处理效率和性能。这通过在三个物理科学领域的数据集上进行实验，并取得了不低于原版Erwin模型的性能结果来实现验证。此外，作者还重现了原始Erwin论文中的实验结果，以确认其方法的有效性及实现的正确性。", "conclusion": "通过结合Erwin架构与NSA机制，研究成功地实现了对大规模物理系统数据集的高效处理，提出的Erwin NSA模型在天体模拟、分子动力学和气压建模等三个物理科学领域的数据集上展示了与原版Erwin模型相当或更优的性能。实验结果验证了Erwin NSA模型的实用性和有效性。未来可以进一步研究更复杂的物理系统并探索更多应用场景。"}
{"llm_update_time": "20250816", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.10074", "html_url": "https://arxiv.org/abs/2508.10074", "title": "Next Edit Prediction: 从上下文和交互历史中学习预测代码编辑", "title_en": "Next Edit Prediction: Learning to Predict Code Edits from Context and Interaction History", "authors": "Ruofan Lu,Yintong Huo,Meng Zhang,Yichen Li,Michael R. Lyu", "background": "随着大型语言模型（LLMs）的快速发展，AI编码助手被广泛集成到开发环境中。编码助手可以提供低延迟的代码补全建议，但只能基于光标当前位置。而基于聊天的编辑可以进行复杂的修改，但要求开发者暂时中断工作，用自然语言描述意图，导致从代码切换到其他任务。这种情况下，两种方法都无法主动预测开发者的后续编辑。为了弥合这一差距，本研究提出了一项新的任务——Next Edit Prediction，旨在从最近的交互历史中推断开发者的意图以预测编辑的位置和内容。这项工作构建了一个高质量的监督微调数据集和评估基准，对一系列模型进行了监督微调，并进行了详细的模型评估。这为一个新的交互模式奠定了基础，该模式能够主动与开发者协作，预测其下一步操作，而不是仅仅响应明确的指令。", "innovation": "引入了Next Edit Prediction任务，该任务旨在从最近的交互历史中推断开发者的意图以预测编辑的位置和内容。开发了一个高质量的监督微调数据集和评估基准。通过对多种模型进行监督微调，并进行全面评估，发现了多个新颖的见解。这项工作为一种新的与开发者交互的模式奠定了基础，该模式能够在预测开发者后续操作的基础上主动协作，而不是被动响应指令。", "conclusion": "本工作为Next Edit Prediction任务提供了一个新的方法论和数据集，并通过实验证明其有效性和潜力。这将推动编码助手的发展，使其更加智能化和自动化，从而提高开发者的效率。"}
{"llm_update_time": "20250816", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.10104", "html_url": "https://arxiv.org/abs/2508.10104", "title": "DINOv3", "title_en": "DINOv3", "authors": "Oriane Siméoni,Huy V. Vo,Maximilian Seitzer,Federico Baldassarre,Maxime Oquab,Cijo Jose,Vasil Khalidov,Marc Szafraniec,Seungeun Yi,Michaël Ramamonjisoa,Francisco Massa,Daniel Haziza,Luca Wehrstedt,Jianyuan Wang,Timothée Darcet,Théo Moutakanni,Leonel Sentana,Claire Roberts,Andrea Vedaldi,Jamie Tolan,John Brandt,Camille Couprie,Julien Mairal,Hervé Jégou,Patrick Labatut,Piotr Bojanowski", "background": "无监督学习有望消除手动数据标注的需要，让模型能够轻松扩展到大规模数据集和更大规模的架构。由于其不针对特定任务或领域定制，这种培训范式具备从不同来源学习视觉表征的潜力，包括自然图像和航空图像，仅使用一种算法即可。这项技术报告介绍了DINOv3，这是朝着实现这一愿景迈出的重要一步，通过使用简单而有效的策略实现这一目标。", "innovation": "DINOv3通过精心的数据准备、设计和优化来扩大数据集和模型规模，引入了一种新的方法叫Gram anchoring，有效解决了密集特征图在长训练周期中退化的问题，还应用了后处理策略以提高模型在分辨率、模型大小和与文本对齐方面的灵活性。DINOv3生成高质量的密集特征，显著超越了之前的自监督和弱监督基础模型，取得了在多种视觉任务上的出色性能。", "conclusion": "我们展示了具有广泛适应性的视觉基础模型DINOv3，无需微调即可在多种设置中超越专门的前沿技术。它提供了可扩展的解决方案，以应对各种资源约束和部署场景。我们还分享了DINOv3视觉模型套件，旨在通过提供跨任务和数据范围的先进解决方案来推进技术前沿。"}
{"llm_update_time": "20250816", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.10178", "html_url": "https://arxiv.org/abs/2508.10178", "title": "在沿岸海域环境评估碳库：再分析或模型驱动的机器学习？", "title_en": "Estimating carbon pools in the shelf sea environment: reanalysis or model-informed machine learning?", "authors": "Jozef Skakala", "background": "沿岸海域对于碳封存和碳循环至关重要，但现有的现场或卫星数据通常稀缺或不确定性高。再分析可以提供替代方案，但却成本高昂。本文提出利用神经网络（NN）从物理-生物地球化学模型中学习，来推断直接可观测变量与碳库之间的关系。通过在北西欧架海（NWES）环境中的示范研究证明，当基于模型自由运行模拟训练的NN应用于NWES再分析数据时，能够复现再分析输出的结果。此外，与现有的NWES再分析不同，NN群体还可以提供碳库的不确定性信息。", "innovation": "利用神经网络学习物理-生物地球化学模型中直接可观察变量与碳库之间的关系，以此替代昂贵的再分析方法，并能够提供碳库的不确定性信息。", "conclusion": "本文提出的方法旨在解释模型输出结果，并展示了神经网络在未来的气候假设情景研究中的潜在应用。建议模型驱动的机器学习为昂贵的再分析提供了可行的替代方案，能够补充观察数据，特别是在数据缺失或高度不确定的情况下。"}
{"llm_update_time": "20250816", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.10160", "html_url": "https://arxiv.org/abs/2508.10160", "title": "使用慢性侵入式电生理记录预先训练的变压器模型进行无需个体患者训练的症状解码", "title_en": "Pre-trained Transformer-models using chronic invasive electrophysiology for symptom decoding without patient-individual training", "authors": "Timon Merk,Saeed Salehi,Richard M. Koehler,Qiming Cui,Maria Olaru,Amelia Hahn,Nicole R. Provenza,Simon Little,Reza Abbasi-Asl,Phil A. Starr,Wolf-Julian Neumann", "background": "神经解码病理和生理状态可以实现个体化的闭环神经调控疗法。近期，预训练大规模基础模型能够提供跨患者的通用状态估计，无需为每个患者单独训练。本文中，研究人员利用超过24天的时间跨度的慢性深脑刺激记录数据集来构建预训练模型，以适应长时间尺度的症状波动。", "innovation": "研究人员提出了一种优化预训练损失函数，该函数针对神经电生理数据，修正了常见的掩码自编码器损失函数中由于1/过f幂律导致的频率偏见。在此基础上，通过留一患者外交叉验证，在下游任务中成功解码帕金森病症状，无需患者个体训练。", "conclusion": "本研究使用慢性侵入式电生理记录数据集训练了一个预训练的Transformer模型，证明了该模型在无需患者个体化训练的情况下，仍然能够进行症状解码，并展现了该方法在神经调控疗法中的应用潜力。"}
{"llm_update_time": "20250816", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.10117", "html_url": "https://arxiv.org/abs/2508.10117", "title": "以Garcinia cowa中异黄酮生物活性化合物对HeLa癌细胞的细胞毒性的虚拟研究：基于图深度学习、网络药理学和分子对接的QSAR", "title_en": "In silico study on the cytotoxicity against Hela cancer cells of xanthones bioactive compounds from Garcinia cowa: QSAR based on Graph Deep Learning, Network Pharmacology, and Molecular Docking", "authors": "Nguyen Manh Son,Pham Huu Vang,Nguyen Thi Dung,Nguyen Manh Ha. Ta Thi Thao,Tran Thi Thu Thuy,Phan Minh Giang", "background": "癌症是一种复杂的疾病群，通常具有最高的全球死亡率，并且发病率呈上升趋势，甚至开始影响年轻人群。癌症特征在于异常细胞的不受控制增殖、相邻组织的侵袭以及向远处器官的转移。Garcinia cowa是东南亚地区传统草药，其中包括越南，用于治疗发热、咳嗽、消化不良、通便以及寄生虫病。从这种植物中分离出的大量异黄酮化合物显示出广泛的生物活性，其中一些具有作为抗癌和抗疟疾剂的潜力。网络药理学分析成功地识别出了关键的活性成分Rubraxanthone、Garcinone D、Norcowanin、Cowanol、Cowaxanthone及其主要蛋白质靶标（TNF、CTNNB1、SRC、NFKB1和MTOR），这为理解其抗癌作用的分子机制提供了关键见解。", "innovation": "使用了Graph Attention Network算法进行数据增强，以提高对基于异黄酮化合物的pIC50值预测的准确性。通过分子对接研究确定了MTOR作为Garcinia cowa提取物可能的致癌细胞诱导细胞毒性的靶点。利用网络药理学和图深度学习方法，系统地分析了Garcinia cowa中异黄酮生物活性化合物的抗癌作用机制。并通过QSAR模型进行了验证和预测。", "conclusion": "Garcinia cowa中的一些异黄酮生物活性化合物可能通过多种机制诱导HeLa癌细胞的细胞毒性，表现出潜在的抗癌效果。通过网络药理学分析和深度学习技术，可以更深入地理解这些化合物的分子作用机制，并为癌症治疗提供新的候选药物。"}
{"llm_update_time": "20250816", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.10120", "html_url": "https://arxiv.org/abs/2508.10120", "title": "机器学习在IASI测量中云检测：基于物理约束的数据驱动SVM方法", "title_en": "Machine Learning for Cloud Detection in IASI Measurements: A Data-Driven SVM Approach with Physical Constraints", "authors": "Chiara Zugarini,Cristina Sgattoni,Luca Sgheri", "background": "云检测对于大气恢复、气候研究和天气预报至关重要。本文分析了搭载在气象运营（MetOp）卫星上的红外大气探测干涉仪（IASI）获取的红外辐射数据，用于分类为晴朗或阴云的场景。利用支持向量机（SVM）方法，基于核方法处理非分离数据。该研究采用云敏感通道选择和主成分分析（PCA）进行维度降低，专注于最具信息性的特征，实现自动云分类。最佳配置在测试集上的一致同意率为88.30%，且在云层掩膜（MODIS）保持一致，极地地区差异较大，系因传感器不同造成。研究表明，CISVM方法适用于从红外辐射数据自动进行云分类，适合于实际应用和未来的任务如FORUM（远红外放射出射度理解与监测）第九颗欧洲空间局地球探测器使命.", "innovation": "研究提出了一种基于物理约束的数据驱动支持向量机（SVM）方法，包括云敏感通道选择和主成分分析（PCA）减少维度，专注于最具信息性的特征，以实现自动化云分类。这种技术不仅提高了分类精度，还增强了与其他传感器数据的一致性，特别是通过与MODIS云层掩膜的比较。这项研究强调了在机器学习方法中加入物理约束的重要性，以优化云分类的准确性和可靠性，从而适用于未来的气候监测和地球观测任务.", "conclusion": "CISVM方法对于自动从红外辐射数据中进行云分类是一个稳健、灵活且高效的方案，适用于运营恢复和未来的FORUM任务。该方法在测试集上的精度达到88.30%，与MODIS云层掩膜结果一致性较强，但在极地地区存在偏差，主要由于传感器差异所致。"}
{"llm_update_time": "20250816", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.10208", "html_url": "https://arxiv.org/abs/2508.10208", "title": "CATNet：主要用于初级市场上CAT债券利差预测的几何深度学习方法", "title_en": "CATNet: A geometric deep learning approach for CAT bond spread prediction in the primary market", "authors": "Dixon Domfeh,Saeid Safarveisi", "background": "传统的模型在定价巨灾（CAT）债券时难以捕捉这些工具中固有的复杂、相互关联的数据特性。本文探讨了一种新的框架CATNet，该框架利用关系图卷积网络（R-GCN）的几何深度学习架构，将CAT债券的主要市场建模为图，从而利用其底层的网络结构进行利差预测。", "innovation": "引入了CATNet，这是一种新颖的框架，使用关系图卷积网络（R-GCN）的几何深度学习架构，将CAT债券的初级市场建模为图，利用其底层的网络结构来预测利差。该研究还揭示了CAT债券市场具有无标度网络的特征，由少数非常连接和具有影响力的枢纽主导。CATNet的表现显著优于强随机森林基准，进一步加入拓扑中心性度量作为特征提高了准确性。", "conclusion": "通过可解释性分析，确认这些网络特征不仅是统计上的偶然现象，而是发行人声誉、承保人影响力和风险集中的量化代理。该研究提供了网络连接是定价关键决定因素的证据，提出了风险评估的新范式，并表明图基线模型能够提供最先进的准确性和更深层次、可量化的市场洞察。"}
{"llm_update_time": "20250816", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.10222", "html_url": "https://arxiv.org/abs/2508.10222", "title": "通过 emoji 预测理解文本情感", "title_en": "Understanding Textual Emotion Through Emoji Prediction", "authors": "Ethan Gordon,Nishank Kuppa,Rigved Tummala,Sriram Anasuri", "background": "该研究通过探索使用四类深度学习架构（全连接网络、卷积神经网络、变压器和 BERT）来预测来自短文本序列的 emoji，利用 TweetEval 数据集解决类别不平衡问题。研究表明，BERT 由于预训练优势在整体性能上表现最佳，而卷积神经网络在罕见 emoji 类别上表现出色。这强调了架构选择和超参数调整在具备情感意识的 emoji 预测中的重要性，有助于改善人机交互。", "innovation": "利用 TweetEval 数据集并通过引入焦点损失和正则化技术处理了类别不平衡问题；对比分析了四种不同的深度学习架构在 emoji 预测中的表现；发现预训练模型（BERT）和卷积神经网络在不同情况下的优势，提供了一种新的视角和方法来理解文本情感", "conclusion": "该研究展示了架构选择和超参数调整对于情绪感知 emoji 预测的重要性，BERT 在整体性能上表现出色，而卷积神经网络在罕见 emoji 类别上具有独特优势，这对于提高人机交互的质量具有重要意义。"}
{"llm_update_time": "20250816", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.10332", "html_url": "https://arxiv.org/abs/2508.10332", "title": "Layer-Wise Analysis of Self-Supervised Representations for Age and Gender Classification in Children's Speech", "title_en": "Layer-Wise Analysis of Self-Supervised Representations for Age and Gender Classification in Children's Speech", "authors": "Abhijit Sinha,Harishankar Kumar,Mohit Joshi,Hemant Kumar Kathania,Shrikanth Narayanan,Sudarsana Reddy Kadiri", "background": "儿童的语音在年龄和性别分类上具有挑战性，因为儿童在音高、发音和发育特征方面存在高度变异性。虽然自监督学习（SSL）模型在成人语音任务中表现出色，但它们在处理儿童语音时编码说话者特质的能力仍待探索。", "innovation": "本文对四种Wav2Vec2变体在PFSTAR和CMU Kids数据集上的逐层分析，发现早期层（1-7）比深层层更有效地捕捉到说话者特定的线索，并通过PCA进一步提高分类性能，从而揭示了说话者特质如何在SSL模型的深度上分布。", "conclusion": "Wav2Vec2-large-lv60模型在CMU Kids数据集上获得高达97.14%的年龄分类准确率和98.20%的性别分类准确率；在PFSTAR数据集上，base-100h和large-lv60模型的准确率分别为86.05%和95.00%。这些结果支持了针对儿童语音更加精确和适应性的自监督学习策略。"}
{"llm_update_time": "20250816", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.10282", "html_url": "https://arxiv.org/abs/2508.10282", "title": "条件批量普遍预测的后悔-容量定理", "title_en": "The Conditional Regret-Capacity Theorem for Batch Universal Prediction", "authors": "Marco Bondaschi,Michael Gastpar", "background": "本文基于经典的后悔-容量定理，推导出了条件版本。传统的后悔-容量定理主要用于刻画预测中的后悔与容量之间的关系。本文在此基础上，将这一理论应用于批量数据预测的情景，旨在找到在有批量训练数据可用的情况下，预测器最小批量后悔的下界。这一研究是基于近年来对平均后悔的推广进行的，有助于分析批量数据预测中的有效性问题。此外，研究还拓展到利氏信息测度领域，揭示了条件利氏相对熵与条件西esson互信息之间深层次的联系。", "innovation": "文章的核心创新在于提出了一个基于批量训练数据的条件后悔-容量定理。它不仅扩展了经典模型的应用场景，而且还首次将后悔理论与利氏信息测度相结合，深入探索了二者之间的关系。这一发现对于批量数据预测具有重要意义，尤其是在构建更精确和高效的信息编码与预测模型方面。", "conclusion": "本文证明的条件后悔-容量定理可以用于找到批量预测中最小的批量后悔的下界。它为批量数据预测提供了更准确的理论依据，并揭示了利氏信息测度在经典预测理论中的潜在应用价值。这将有助于推动相关研究的发展，并促进更高效的数据预测算法的开发。"}
{"llm_update_time": "20250816", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.10349", "html_url": "https://arxiv.org/abs/2508.10349", "title": "设备端基础模型个性化微调的灵活个性化分拆联合学习", "title_en": "Flexible Personalized Split Federated Learning for On-Device Fine-Tuning of Foundation Models", "authors": "Tianjun Yuan,Jiaxiang Geng,Pengchao Han,Xianhao Chen,Bing Luo", "background": "基础模型在个性化下游任务中的性能依赖于微调，这通常优于直接使用预训练模型。协作学习可以通过利用局部客户端的数据集来进行微调，但有限的客户端数据和异构的数据分布限制了有效的协作。现有的方法难以处理这些挑战。", "innovation": "提出了一种灵活的个性化联邦学习框架（FlexP-SFL），允许在保护个性化目标的同时进行协作学习。通过分拆学习，客户端可以根据资源限制在本地训练模型的部分，并将剩余部分卸载到服务器。同时，提出了一种对齐策略以优化全局数据上的个性化模型性能。", "conclusion": "实验结果表明，FlexP-SFL 在个性化微调效率和最终准确度上都优于基础模型。"}
{"llm_update_time": "20250816", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.10339", "html_url": "https://arxiv.org/abs/2508.10339", "title": "概念还是技能？重新思考多模态模型的指令选择", "title_en": "Concepts or Skills? Rethinking Instruction Selection for Multi-modal Models", "authors": "Andrew Bai,Justin Cui,Ruochen Wang,Cho-Jui Hsieh", "background": "现有的视觉-语言基准主要从两种类型中的某一种受益：与指令具有相似技能或视觉概念。该论文基于这一发现，提出了一种简单的目标训练数据选择方法，以优化给定基准的表现。首先，从基准中提取概念和技能，判断基准主要受益于相似的概念还是技能，最后选择与概念或技能最匹配的指令。实验表明，该目标数据选择方法在多个基准上均有效，整体平均提高了0.9%，在技能侧重部分则提高了1.5%。这一发现强调了在指令选择中平衡概念知识获取与视觉技能学习的重要性。", "innovation": "提出了一种简单的目标训练数据选择方法，以优化多模态模型的性能。该方法首先从基准数据中提取概念和技能，判断哪种类型最受益，然后选择匹配的指令，有效提升了模型性能。", "conclusion": "目标数据选择方法使模型在多个基准上表现出色，尤其是在技能集中部分，显示出明显优势。研究强调了在多模态模型训练中平衡概念和技能的重要性。"}
{"llm_update_time": "20250816", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.10377", "html_url": "https://arxiv.org/abs/2508.10377", "title": "点击与转化：电子商务中推荐系统的训练目标选择", "title_en": "Clicks Versus Conversion: Choosing a Recommender's Training Objective in E-Commerce", "authors": "Michael Weiss,Robert Rosenbach,Christian Eggenberger", "background": "在电子商务中对产品推荐进行排名以优化点击转化率（CTR）或转化率（如加购率（ACR）和订单提交率（OSR））是标准做法。优化CTR看起来是一个简单明了的选择：点击数据等训练数据收集简单且通常是大量存在的。此外，CTR在电子商务之外也有广泛应用，使其成为易于实施的通用选项。相比之下，ACR和OSR更直接地与商店的业务目标（如商品总价值GMV）相关联。本文通过在线A/B测试比较了使用这两种目标对象的效用。", "innovation": "本文通过在线A/B测试展示了优化OSR能够产生超过CTR五倍的GMV提升，且不会牺牲新产品发现。同时，研究还提供了对每项目标的特征重要性的不同见解。", "conclusion": "本研究表明，在电子商务中，优化OSR在提高GMV方面比优化CTR更具优势，同时保留了新产品发现的能力。此外，研究结果还提供了关于每种目标特征重要性的不同见解。"}
{"llm_update_time": "20250816", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.10337", "html_url": "https://arxiv.org/abs/2508.10337", "title": "基于强化学习的 Curriculum 学习方法：利用 RAG 进行多模态问答", "title_en": "A Curriculum Learning Approach to Reinforcement Learning: Leveraging RAG for Multimodal Question Answering", "authors": "Chenliang Zhang,Lin Wang,Yuanyuan Lu,Yusheng Qi,Kexin Wang,Peixu Hou,Wenshi Chen", "background": "竞赛需要建立一个全面的检索增强生成系统，用于多模态多轮问答。挑战分为三项任务：（1）使用从图像基础模拟知识图谱中检索的结构化数据作答问题；（2）结合知识图谱和网络搜索结果生成信息；（3）处理需要理解上下文并从多个来源聚合信息的多轮对话。团队根据图像大型语言模型开发了解决方案，并通过从GPT-4.1知识中进行监督微调来增强它，从而实现了显著的性能提升。并通过采用Curriculum Learning策略引导强化学习，进一步提高了答案的准确性和降低了幻觉现象。此外，团队还利用了Web搜索API来纳入外部知识，使系统能够更好地处理复杂的查询和多轮对话。", "innovation": "1. 结合Vision的大型语言模型进行任务1的解决方案开发，通过从GPT-4.1知识中进行监督微调；\n2. 应用Curriculum Learning策略来指导强化学习，提高答案准确性和降低幻觉现象；\n3. 通过使用Web搜索API，结合外部知识，增强系统处理复杂查询和多轮对话的能力，确保系统的有效性和泛化能力；\n4. 在任务1中获得显著领先优势（52.38%），展示了Curriculum Learning与强化学习结合在训练 pipeline 中的有效性。", "conclusion": "该团队的解决方案在任务1中获得第一名，并且在任务3中获得第三名，证明了在训练过程中结合Curriculum Learning和强化学习的有效性。该研究提出的方法成功应对了多模态多轮问答挑战，体现了其在实际应用中的潜力和价值。"}
{"llm_update_time": "20250816", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.10419", "html_url": "https://arxiv.org/abs/2508.10419", "title": "ComoRAG：一种认知启发的记忆组织RAG方法，用于状态相关的长叙事推理", "title_en": "ComoRAG: A Cognitive-Inspired Memory-Organized RAG for Stateful Long Narrative Reasoning", "authors": "Juyuan Wang,Rongchen Zhao,Wei Wei,Yufeng Wang,Mo Yu,Jie Zhou,Jin Xu,Liyan Xu", "background": "长故事和小说叙述推理是一个极具挑战性的领域，源于其复杂的剧情和人物关系。由于大模型在长时间段上的推理能力有限并且计算成本高，检索式方法在实际应用中仍然占据重要地位。然而，传统的检索辅助生成（RAG）方法由于其无状态、单步骤的检索流程，往往无法捕捉到长范围上下文中的动态关系。", "innovation": "本文提出了一种名为ComoRAG的方法，该方法认为叙述推理不是一个一次性的过程，而是一个新的证据获取与过去知识整合之间动态互动的过程，类似于人类在大脑中使用记忆相关信号进行推理的方式。当遇到推理瓶颈时，ComoRAG会进行迭代性的推理循环，并与动态的记忆工作区进行交互。在每一循环中，它生成探查性询问以找到新的探索路径，然后将新方面的检索证据整合到全局记忆池中，从而支持问题解决时的上下文一致性。在四个具有挑战性的长上下文叙述基准（200K+词）中，ComoRAG在所有基准之上取得了持续的相对增益，最高达11%。进一步的分析表明，ComoRAG特别适用于需要全局理解的复杂查询，为检索式长上下文理解提供了一个基于记忆的认知驱动框架。", "conclusion": "ComoRAG在四种具有较大挑战性的长上下文叙述基准测试中相比于之前的最强基线均取得了相对显著的提升。此外，该方法特别适用于需要全局理解的复杂查询，为基于记忆和状态推理的长上下文理解提供了一种有理论依据的方法。"}
{"llm_update_time": "20250816", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.10433", "html_url": "https://arxiv.org/abs/2508.10433", "title": "We-Math 2.0: 一种激励视觉数学推理的通用MathBook系统", "title_en": "We-Math 2.0: A Versatile MathBook System for Incentivizing Visual Mathematical Reasoning", "authors": "Runqi Qiao,Qiuna Tan,Peiqing Yang,Yanzi Wang,Xiaowan Wang,Enhui Wan,Sitong Zhou,Guanting Dong,Yuchen Zeng,Yida Xu,Jie Wang,Chong Sun,Chen Li,Honggang Zhang", "background": "多模态大语言模型在各种任务中展示了出色的性能，但在复杂的数学推理方面仍然存在挑战。现有研究主要集中在数据集构建和方法优化上，往往忽视了全面的知识驱动设计和模型中心的数据空间建模。", "innovation": "提出了We-Math 2.0，这是一个综合系统，结合了结构化的数学知识系统、模型中心的数据空间建模以及基于强化学习（RL）的训练范式，以全面增强大语言模型的数学推理能力。主要贡献包括：1) 构建了包含491个知识点和1819个基本原则的五级层次结构系统的MathBook知识系统；2) 开发了确保广泛概念覆盖和弹性的MathBook-Standard数据集及构建挑战性数据集MathBook-Pro；3) 提出了基于两个阶段的RL框架，包括冷启动微调和逐步对齐RL；4) 引入了一个覆盖所有491个知识点的全面基准，包含多种推理步骤分布。", "conclusion": "实验证明，We-Math-RL在四个广泛使用的基准测试上与现有基准一对一竞争，并在MathBookEval上取得了优异成绩，表明了在数学推理方面的强大泛化能力。"}
{"llm_update_time": "20250816", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.10449", "html_url": "https://arxiv.org/abs/2508.10449", "title": "SkeySpot: 在建筑行业中自动化数字电气布局图中服务关键检测", "title_en": "SkeySpot: Automating Service Key Detection for Digital Electrical Layout Plans in the Construction Industry", "authors": "Dhruv Dosi,Rohit Meena,Param Rajpura,Yogesh Kumar Meena", "background": "历史平面图通常仅作为扫描文件保存，对于建筑、城市规划和设施管理仍是非常重要的资源。然而，由于缺乏可机器读取的平面图，大规模的解析工作既耗时又容易出错。自动符号识别系统化地解决了这一问题，通过直接从平面图中识别服务关键符号，支持诸如成本估算、基础设施维护和合规性检查等工作流程。", "innovation": "该研究构建了一个名为Digitised Electrical Layout Plans (DELP)的数据集，包含45个经过注释的电气布局图，具有2,450个实例和34个不同的服务关键类别。提出了一种系统性的评估框架，使用预训练的物体检测模型进行评估。YOLOv8在实验中表现出最高性能，达到了82.5%的平均精度（mAP）。基于此，开发了一个轻量级的开源工具SkeySpot，用于实时检测、分类和量化电气符号。SkeySpot的输出结构化、标准化，易于扩展，提高了建筑行业中小型企业对电气布局进行数字化的可访问性，同时支持更高的标准化、互操作性和可持续发展目标。", "conclusion": "该方法降低了对专有CAD系统的依赖，减少了人工标注的工作负担，使电气布局的数字化对建筑行业中的中小企业更加可行，同时也支持了建筑环境中更广泛的标准化、互操作性和可持续发展目标。"}
{"llm_update_time": "20250816", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.10425", "html_url": "https://arxiv.org/abs/2508.10425", "title": "HiRef: 利用层次化本体和网络细化实现稳健的药物推荐", "title_en": "HiRef: Leveraging Hierarchical Ontology and Network Refinement for Robust Medication Recommendation", "authors": "Yan Ting Chok,Soyon Park,Seungheun Baek,Hajung Kim,Junhyun Lee,Jaewoo Kang", "background": "药物推荐任务是协助医生根据长期患者的医疗记录做出及时决策的关键任务。然而，实际电子健康记录（EHR）数据面临着罕见医疗实体和不完整的记录带来的挑战，这些记录可能无法全面反映临床真相。尽管基于数据驱动的方法在EHR上表现出强大的性能，但在面对缺失或新的情况时，它们难以泛化，主要是因为它们依赖于观察到的共现模式。因此，本研究提出了一种名为HiRef的统一框架，结合了两种互补的结构：（i）在规范化的医疗本体中编码的层次化语义，以及（ii）从实际EHR中推导出的精炼的共现模式。通过将本体实体嵌入到双曲空间中，自然地捕捉树状关系，并通过共享祖先促进知识转移，从而提高了对未见代码的泛化能力。此外，还引入了一种基于先验稀疏正则化方案，通过削弱虚假边并保留临床意义的关联来进一步细化EHR共现图。该模型在EHR基准数据集（MIMIC-III和MIMIC-IV）上表现出强大的性能，并且在模拟的未见代码场景下保持了高精度。广泛的实验和全面的消融研究证明HiRef能够应对未见的医疗代码，同时通过对学习到的稀疏图结构和医疗代码嵌入进行深入分析来支持其鲁棒性。", "innovation": "提出了一种名为HiRef的统一框架，结合了在规范化的医疗本体中编码的层次化语义，以及从实际EHR中推导出的精炼的共现模式。该方法通过将本体实体嵌入到双曲空间中来捕捉树状结构，通过共享祖先进行知识转移，增强了泛化能力。为了进一步增强鲁棒性，引入了一种基于先验稀疏正则化方案来细化EHR共现图，通过削弱虚假边并保留临床意义的关联。", "conclusion": "HiRef模型在EHR基准数据集上表现出强大的性能，并且在模拟的未见代码场景下保持了高精度。广泛的实验和深入的分析证明HiRef在应对未见的医疗代码方面表现出色。"}
{"llm_update_time": "20250816", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.10436", "html_url": "https://arxiv.org/abs/2508.10436", "title": "交替应用Approach-Putt模型的多阶段语音增强方法", "title_en": "Alternating Approach-Putt Models for Multi-Stage Speech Enhancement", "authors": "Iksoon Jeong,Kyung-Joong Kim,Kang-Hun Ahn", "background": "语音增强利用人工神经网络的目标是从嘈杂的语音信号中去除噪声，同时保留语音内容。然而，语音增强网络往往会引入对语音信号的失真，称为伪像，这会降低音频质量。因此，需要一种后处理神经网络来减轻由语音增强模型引入的伪像，提升语音质量评分（PESQ）、客观可懂度（STOI）和背景噪声侵入性（CBAK）分数。此工作提出了一种交替应用语音增强模型和提出的Putt模型的方法，以改善多阶段语音增强过程中的语音质量。", "innovation": "本文提出了一种名为PuttNet的后处理神经网络，该网络可通过交替应用语音增强模型和Putt模型来减轻伪像，从而提高语音质量。这种方法受到了高尔夫术语中的‘Approach’和‘Putt’动作的启发，交替应用这两种模型优于单独重复应用任一模型。此外，通过感知质量分数（PESQ）、客观可懂度（STOI）和背景噪声侵入性（CBAK）分数的提高，证明了此方法的有效性。", "conclusion": "通过交替应用语音增强模型和提出的Putt模型，研究结果证明了该方法可以显著提高多阶段语音增强过程中的语音质量评分（PESQ）、客观可懂度（STOI）和背景噪声侵入性（CBAK）分数，从而优于单独应用任一模型的效果。"}
{"llm_update_time": "20250816", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.10515", "html_url": "https://arxiv.org/abs/2508.10515", "title": "虚拟传感在IGBT模块焊层降解和温度监控中的应用", "title_en": "Virtual Sensing for Solder Layer Degradation and Temperature Monitoring in IGBT Modules", "authors": "Andrea Urgolo,Monika Stipsitz,Helios Sanchis-Alepuz", "background": "监测绝缘栅双极型晶体管（IGBT）模块的降解状态对于确保电力电子系统的可靠性和寿命至关重要，特别是在安全关键和高性能应用中。然而，由于内部组件的物理不可访问性和恶劣环境，直接测量关键降解指标（如晶界温度、焊料疲劳或脱层）仍然具有挑战性。", "innovation": "本文提出了一种基于机器学习的虚拟传感方法，通过有限数量的物理传感器来估计焊料层的降解状态和相应的位置温度图，有效填补了从可行传感器放置到相关但不可访问位置的差距。", "conclusion": "基于特定降解模式的合成数据，我们获得了较高的降解焊料区域估计准确性（平均绝对误差1.17%），并且能够将IGBT表面温度模拟出的最大相对误差为4.56%（平均相对误差0.37%）。"}
{"llm_update_time": "20250816", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.10149", "html_url": "https://arxiv.org/abs/2508.10149", "title": "带有逆概率加权的预测驱动推断", "title_en": "Prediction-Powered Inference with Inverse Probability Weighting", "authors": "Jyotishka Datta,Nicholas G. Polson", "background": "PPI是一种最近的框架，用于处理部分标注数据的有效统计推断，结合了对大量未标注集的基于模型的预测和来自较小标注子集的偏差校正。虽然PPI很有效，但如果标注数据具有信息性偏差，则不能直接应用。研究人员展示了如何通过用逆概率加权（IPW）版本替换非加权偏差校正项来处理信息性标注，即使用经典霍维茨-汤普森或哈杰克形式，从而将基于设计的抽样调查理念与现代预测辅助推断相结合。特别是在估计入样概率的情况下，PPI依然能保持有效的估计。", "innovation": "本文提出了将逆概率加权（IPW）应用于预测驱动推断（PPI），以处理具有信息性偏差的标注数据。通过使用霍维茨-汤普森或哈杰克形式的逆概率加权，该方法结合了抽样调查理念和现代预测技术。这种方法的有效性在估计倾向性权重的情况下得到了验证，与已知概率情况相比，具有类似的置信水平并保持了PPI的方差减少优势。", "conclusion": "该研究展示了PPI可以有效地处理信息性标注的问题，并通过逆概率加权方法提供了有效的推断工具。该方法在估计入样概率的情况下依旧能保持有效的估计，与已知概率情况相比，依然可以保持良好的置信水平和方差减少的效果。"}
{"llm_update_time": "20250816", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.10460", "html_url": "https://arxiv.org/abs/2508.10460", "title": "准确高效的稀疏轨迹恢复和地图匹配方法", "title_en": "Efficient Methods for Accurate Sparse Trajectory Recovery and Map Matching", "authors": "Wei Tian,Jieming Shi,Man Lung Yiu", "background": "实际世界的轨迹数据往往稀疏且采样率低（即，连续GPS点之间的间隔时间较长），并且与道路网络对齐差，即使如此，许多应用也要求高质量的数据以达到最佳性能。对于输入稀疏轨迹的数据，我们需要改进数据质量的方法，研究两个相关问题：在道路网络上的轨迹恢复，旨在推断缺失的点以恢复高采样率轨迹；地图匹配，旨在将GPS点映射到道路段以确定潜在的路径。", "innovation": "在这篇文章中，我们介绍了一种高效的TRMMA方法和MMA方法，用于准确的轨迹恢复和地图匹配，其中MMA作为TRMMA的第一步。在MMA中，我们精心制定了一个分类任务，将稀疏轨迹中的GPS点映射到候选道路段集上，而不是整张道路网络，从而产生有效的嵌入来捕捉GPS数据、方向信息和道路段的模式，准确地将稀疏轨迹对齐到路径上。在轨迹恢复中，TRMMA专注于MMA返回的路径中的段落，通过道路段上的位置比来推断缺失的点，高效地生成高采样率的轨迹，而无需评估所有道路段。具体来说，在TRMMA中，我们设计了一个双重变换编码过程来共同捕获轨迹和路线中的潜在模式，以及一个有效的解码技术来按顺序预测缺失点的位置比和道路段。我们分别在4个大型真实世界数据集上对TRMMA和MMA与大量现有方法进行了广泛的实验比较，结果表明TRMMA和MMA始终产生最佳的结果质量，通常显著领先。", "conclusion": "通过提出高效的TRMMA和MMA方法，我们解决了稀疏轨迹的精确恢复和地图匹配问题，通过这些方法能够准确地恢复稀疏轨迹并将其匹配到正确的道路段上，从而提高了轨迹数据的质量。"}
{"llm_update_time": "20250816", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.10501", "html_url": "https://arxiv.org/abs/2508.10501", "title": "PASS: Probabilistic Agentic Supernet Sampling for Interpretable and Adaptive Chest X-Ray Reasoning", "title_en": "PASS: Probabilistic Agentic Supernet Sampling for Interpretable and Adaptive Chest X-Ray Reasoning", "authors": "Yushi Feng,Junye Du,Yingying Hong,Qifan Wang,Lequan Yu", "background": "现有的工具辅助代理系统在现实世界中受限于（i）黑盒推理步骤，这削弱了决策过程的信任并带来安全风险；（ii）不良的多模态集成，对于医疗保健任务来说是固有的关键性问题；（iii）僵化且计算效率低的代理流程。论文针对胸部X光片（CXR）推理的复杂性，提出一种新型的多模态框架PASS，实现了高质量的综合性能。", "innovation": "引入PASS（Probabilistic Agentic Supernet Sampling），这是首个解决上述挑战的多模态框架。PASS通过在多工具图上自适应采样代理工作流程，提供带解释概率的决策路径。设计了新颖的三阶段训练流程，包括专家知识预热、对比路径排名和成本感知强化学习，以优化兼顾性能与成本的帕累托前沿。还引入了CAB-E基准，针对多步安全关键医疗应用的自由格式CXR推理，进行全面评估。", "conclusion": "实验结果表明，PASS在多个指标（如准确率、AUC、LLM-J）上显著优于强大基准，并且能够在保持计算成本的同时，提升医疗人工智能的安全性。这标志着迈向解释性、自适应和多模态医疗代理系统新时代的里程碑。"}
{"llm_update_time": "20250816", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.10193", "html_url": "https://arxiv.org/abs/2508.10193", "title": "越多内存，越多问题：面向流的数据机器卸载", "title_en": "Mo' Memory, Mo' Problems: Stream-Native Machine Unlearning", "authors": "Kennon Stewart", "background": "现有的机器卸载工作假设一个静态的、独立同分布的训练环境，这在实际中并不存在。现代机器学习流水线需要在生产中的数据流上连续地学习、卸载和预测。", "innovation": "将批量卸载的概念转化为在线设置，利用后悔、样本复杂性和删除容量的概念。将后悔边界紧致到对数级O(ln{T})，这是首个机器卸载算法。同时更换了昂贵的海森矩阵求逆方法，使用在线变体的L-BFGS优化，去除了一种随时间线性增长的内存占用。", "conclusion": "这些改变延长了机器学习模型的寿命，减少了昂贵的重新训练需求，从而使得卸载过程更为高效。"}
{"llm_update_time": "20250816", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.10533", "html_url": "https://arxiv.org/abs/2508.10533", "title": "通过频率选择和维度分离缓解量子机器学习中的混合频率指数生长", "title_en": "Mitigating Exponential Mixed Frequency Growth through Frequency Selection and Dimensional Separation in Quantum Machine Learning", "authors": "Michael Poppel,David Bucher,Maximilian Zorn,Nico Kraus,Jonas Stein,Claudia Linnhoff-Popien", "background": "随着量子计算（QC）的潜在计算加速潜力被越来越重视，量子机器学习（QML）的研究也日益受到关注。在QML模型中，角度编码技术能够生成截断的傅里叶级数，提供渐近普遍的功能近似能力。通过选择量子电路中的高效特征映射（FMs），可以利用傅里叶频率的指数增长来提高近似效果。在多维设置下，额外的输入维度会通过混合频率进一步诱导指数级的扩展。然而，实践中量子模型在回归任务中常常失败，即使关键频率存在，也可能因为训练参数不足而失败。", "innovation": "本文提出了一种通过频率选择和维度分离来缓解参数数量因频率指数级增长而增加的技术。这种方法能够限制参数的数量，从而提高训练的可行性。通过将量子机器学习模型限制在必要的频率上，并仅在已知有相互依赖的特征维度间允许混合频率，本文扩展了当前硬件上的可解决问题集。此外，使用已知频率谱和维度间相互依赖性的函数进行了实验，证明了该方法可以减少参数需求，使在嘈杂的量子模拟器上进行训练并在真实量子硬件上进行推断成为可能。", "conclusion": "本文引入了频率选择和维度分离作为技术手段，以减轻由于频率指数级增长而导致的参数数量增加问题，从而提高了在当前硬件上训练量子机器学习模型的能力。通过实验验证，该方法能够显著减少参数数量，同时实现对某些特定问题的有效训练和推理。"}
{"llm_update_time": "20250816", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.10712", "html_url": "https://arxiv.org/abs/2508.10712", "title": "嵌入式SAR船只目标检测与分类的轻量级CNN", "title_en": "Lightweight CNNs for Embedded SAR Ship Target Detection and Classification", "authors": "Fabian Kresse,Georgios Pilikos,Mario Azcueta,Nicolas Floury", "background": "合成孔径雷达（SAR）数据能够实现对海洋船只的大规模监测。然而，实时监测目前受到需要下传所有原始数据、进行图像聚焦和随后地面上的分析的限制。传统的图像聚焦和处理算法因卫星有限的内存、处理能力和计算资源而面临挑战。本文针对Sentinel-1以带状模式和干涉宽模式获取的未聚焦SAR数据，研究并评估了适用于嵌入式实时推理的神经网络。", "innovation": "提出了适用于嵌入式实时推理的大规模未聚焦SAR数据的轻量级卷积神经网络（CNN），特别是针对Sentinel-1数据，并通过在现场可编程门阵列（FPGA）上的部署验证了其可行性。此外，通过研究船和风车之间的二元分类任务，证明了能够在同一平台上实现目标分类。", "conclusion": "证明了使用其中一种模型进行在轨处理和部署在FPGA上的可行性。通过在船舶和风车之间的二元分类任务上进行研究，证明了目标分类的可能性，为嵌入式SAR数据处理提供了新的方法。"}
{"llm_update_time": "20250816", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.10186", "html_url": "https://arxiv.org/abs/2508.10186", "title": "PakBBQ：适用于问答的文化适配偏见基准", "title_en": "PakBBQ: A Culturally Adapted Bias Benchmark for QA", "authors": "Abdullah Hashmat,Muhammad Arham Mirza,Agha Ali Raza", "background": "随着大型语言模型（LLMs）在各类应用中的广泛应用，确保这些模型在不同用户社区中的公平性变得至关重要。然而，目前大多数LLMs都是基于西方数据进行训练和评估，并且很少关注低资源语言和区域背景。因此，需要一种面向特定文化背景的数据集来评估和改进这些模型的公平性，尤其是针对地域上较为狭窄的数据偏见。本文的研究背景正是基于此背景，旨在填补这一空白，通过创建适合巴基斯坦文化与地域背景的PakBBQ数据集，以更好地评估和提升LLMs的公平性表现。", "innovation": "本文创新性地引入了PakBBQ，这是一种面向巴基斯坦文化背景的偏见基准数据集。该数据集包括超过214个模板，涵盖17180个跨8个类别（年龄、残障、外貌、性别、社会经济状况、宗教、地域归属、语言正式程度）的问答对，旨在覆盖巴基斯坦相关偏见维度，并评估多语言LLMs在模糊和明确解模糊情境下的表现，以及不同问题框架下的负面影响。这些创新性措施有助于更精确地识别和减轻低资源设置下的偏见问题。", "conclusion": "研究结果表明，通过解模糊可以提高12%的准确性；与英语相比，乌尔都语的反偏见行为更强；负面问题框架可以显著减少刻板印象式的回应。这些发现强调了在低资源环境下，运用上下文化基准和简单提示工程技术对于偏见缓解的重要性。"}
{"llm_update_time": "20250816", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.10731", "html_url": "https://arxiv.org/abs/2508.10731", "title": "剖析泛化类别发现：自我分解下的多重共识", "title_en": "Dissecting Generalized Category Discovery: Multiplex Consensus under Self-Deconstruction", "authors": "Luyao Tang,Kunze Huang,Chaoqi Chen,Yuxuan Yuan,Chenxin Li,Xiaotong Tu,Xinghao Ding,Yue Huang", "background": "人类感知系统在识别已知和未知类别中的物体方面表现出色，这一能力远超现有的机器学习框架。泛化类别发现（GCD）旨在弥合这一差距，但现有方法主要集中在优化目标函数上。", "innovation": "本文提出了一种与现有方法不同的方法，受人类认知过程启发，将物体分解为视觉基础元素，并构建跨知识对比。提出了一种名为ConGCD的方法，通过高层次语义重建建立基础元素为导向的表示，并通过解构绑定类内共享的属性。此外，通过实现主导和语境共识单元，捕捉类别鉴别模式和固有的分布不变性。提出了一个共识调度器，动态优化激活路径，通过多路共识集成产生最终预测。", "conclusion": "ConGCD在粗细粒度数据集上的广泛评估证明了其作为一种共识感知范式的有效性。代码可在指定网址找到。"}
{"llm_update_time": "20250816", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.10561", "html_url": "https://arxiv.org/abs/2508.10561", "title": "在情绪计算中可再现的生理特征：唤醒建模的初步分析", "title_en": "Reproducible Physiological Features in Affective Computing: A Preliminary Analysis on Arousal Modeling", "authors": "Andrea Gargano,Jasin Machkour,Mimma Nardelli,Enzo Pasquale Scilingo,Michael Muma", "background": "在情绪计算领域，一个关键挑战是可靠地将主观的情绪体验与客观的生理标记联系起来。这项初步研究解决了可再现性问题，通过从心血管和电化学皮肤反应信号中识别与持续自我报告的唤醒水平相关的生理特征来实现这一目标。研究使用了情绪连续标注信号数据集，分析了30名参与者在观看短情绪触发视频时自心脏和电化学皮肤反应信号中提取的164个特征。", "innovation": "研究通过使用Terminating-Random Experiments (T-Rex)方法进行特征选择，该方法系统性地控制用户定义的目标假发现率。研究发现，只有两个电化学皮肤反应衍生的特征与唤醒水平具有可再现和统计学意义的关联，确保了100%的确认率。这种特征选择方法强调了在生理特征选择中严格进行可再现性评估的必要性，这一方面在情绪计算中经常被忽视。这种方法特别适用于需要可信赖和可靠的白箱模型的安全关键环境应用，如情绪障碍识别和人机交互系统中。", "conclusion": "在含有情感计算研究中，重要的是要进行严格的可再现性评估。虽然T-Rex方法在此研究中表现出了极高的特征确认率，但仍需更多研究来验证其在其他情绪激活水平选择中的适用性。同时，这些结果也表明了可再现性评估的重要性，有助于提高情绪计算模型的可靠性和准确性。"}
{"llm_update_time": "20250816", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.10745", "html_url": "https://arxiv.org/abs/2508.10745", "title": "Agentic Design Review System", "title_en": "Agentic Design Review System", "authors": "Sayan Nag,K J Joseph,Koustava Goswami,Vlad I Morariu,Balaji Vasan Srinivasan", "background": "评估图形设计通常需要从多个方面进行评估，如对齐、构图、美感和颜色选择。现有方法通过汇总个体专家评审人员的反馈来进行整体评估。然而，缺乏一个有效的方法来协调多个代理共同进行设计分析。", "innovation": "本文提出了一个称为Agentic Design Review System (AgenticDRS) 的系统，采用了一个元代理来协调多个代理进行设计分析。提出了基于图匹配的新型上下文示例选择方法和独特的提示扩展方法，使得每个代理能够具备设计意识。此外，还提出了DRS-BENCH基准，通过与最先进的基线方法进行彻底的实验评估，并辅以关键的消融实验，证明了AgenticDRS在评估图形设计和生成可操作反馈方面的有效性。", "conclusion": "我们希望这项工作能够吸引对该普适且尚待探索的研究方向的关注。"}
{"llm_update_time": "20250816", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.10677", "html_url": "https://arxiv.org/abs/2508.10677", "title": "推进自主应急响应：利用大语言模型和网络威胁情报", "title_en": "Advancing Autonomous Incident Response: Leveraging LLMs and Cyber Threat Intelligence", "authors": "Amine Tellache,Abdelaziz Amara Korba,Amdjed Mokhtari,Horea Moldovan,Yacine Ghamri-Doudane", "background": "有效的应急响应（IR）对于缓解网络威胁至关重要，但安全团队由于警报疲劳、高假阳性率以及大量的非结构化网络威胁情报（CTI）文件而不堪重负。虽然CTI具有巨大的潜力来丰富安全操作，但其广泛且分散的特性使人工分析耗时且资源密集。为解决这一问题，我们介绍了一种新的基于检索增强生成（RAG）的框架，利用大型语言模型（LLMs）自动化并增强IR，通过动态检索CTI进行整合。我们的方法引入了一种混合检索机制，该机制结合了基于NLP的相似性搜索与对外部CTI平台的标准查询，从而实现上下文感知的安全警报增强。增强的人工智能随后由一个LLM驱动的响应生成模块利用，该模块根据上下文生成精确、可操作且相关性的应急响应策略。", "innovation": "提出了一种基于检索增强生成（RAG）的框架，利用大型语言模型（LLMs）自动化并增强应急响应，通过动态检索网络威胁情报（CTI）。引入了一种混合检索机制，结合基于NLP的相似性搜索与对外部CTI平台的标准查询。通过AI自动化评估并由网络安全专家进行系统验证。实验验证显示，该方法提高了应急响应的准确性和效率，减轻了分析师的工作负担并降低了响应延迟。强调了以大语言模型驱动的CTI融合在推进自主安全操作方面的潜力及智能、自适应网络安全框架的基础建设。", "conclusion": "我们的方法通过增强人工智能和自动化的手段显著提高了应急响应的效率和准确性，缓解了分析师的负担并降低了响应时间。我们提出的工作为自主安全操作的进步和智能自适应网络安全框架的建设奠定了基础。"}
{"llm_update_time": "20250816", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.10555", "html_url": "https://arxiv.org/abs/2508.10555", "title": "基于物理信息的深度对比源反演：反散射问题的统一框架", "title_en": "Physics-Informed Deep Contrast Source Inversion: A Unified Framework for Inverse Scattering Problems", "authors": "Haoran Sun,Daoqi Liu,Hongyu Zhou,Maokun Li,Shenheng Xu,Fan Yang", "background": "反散射问题在电磁成像和医学诊断中至关重要，但由于其非线性和多样的测量场景，这些问题具有挑战性。传统的全波形反演计算成本高，难以解决非线性反散射问题。该论文提出了一种基于物理信息的深度对比源反演框架（DeepCSI），以实现不同测量条件下的快速和准确介电体重构。DeepCSI借鉴了对比源反演（CSI）和神经操作符方法，通过残差多层感知器（ResMLP）来模拟不同发射器激发下感兴趣区域的电流分布，从而有效地线性化非线性反散射问题，并显著降低了传统全波形反演的计算成本。这种方法通过将介质参数视为可学习的张量，并整合状态方程损失、数据方程损失和总变差正则化损失，建立了联优化网络参数和介质属性的完全可微框架，使其在复杂测量场景中具有简化的优点和普遍的建模能力，包括无相位测量和多频观测。", "innovation": "提出了一种新的基于物理信息的深度对比源反演框架（DeepCSI），该框架通过使用残差多层感知器来模拟不同发射器激励下的电流分布，有效地线性化了非线性反散射问题；并将介质参数视为可学习的张量，利用一种包含状态方程损失、数据方程损失和总变差正则化的混合损失函数，建立了一个完整的可微框架，实现了网络参数和介质属性的联合优化；DeepCSI方法在全数据、无相位数据和多频条件下均能实现高精度、稳健的重构，优于传统的CSI方法，为复杂的反散射问题提供了一种高效且通用的解决方案。", "conclusion": "通过与传统方法的比较，DeepCSI在非线性反散射问题中展示了其在计算效率和适应性方面的优势。该方法在不同测量条件下均能实现高精度、稳健的重构，并通过实验结果证明了其优势，为复杂反散射问题提供了一种高效和通用的解决方案。"}
{"llm_update_time": "20250816", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.10718", "html_url": "https://arxiv.org/abs/2508.10718", "title": "Symmetry-Constrained Multi-Scale Physics-Informed Neural Networks for Graphene Electronic Band Structure Prediction", "title_en": "Symmetry-Constrained Multi-Scale Physics-Informed Neural Networks for Graphene Electronic Band Structure Prediction", "authors": "Wei Shan Lee,I Hang Kwok,Kam Ian Leong,Chi Kiu Althina Chau,Kei Chon Sio", "background": "精确预测二维材料的电子能带结构仍然是一个基本挑战，现有方法难以平衡计算效率和物理准确性。", "innovation": "本文介绍了新的Symmetry-Constrained Multi-Scale Physics-Informed Neural Network (SCMS-PINN) v35，这是一种直接学习石墨烯能带结构的神经网络，通过一个多头架构严格地强制晶体学对称性。该方法引入了三个专门的ResNet-6途径：K-head用于狄拉克物理，M-head用于鞍点，General head用于平滑插值。这些途径分别处理从k点提取出的31个物理信息特征。渐进的狄拉克约束调度逐步增加权重参数，从5.0到25.0，从而实现从全局拓扑到局部重要物理学的梯级学习。在300个周期内对10,000个k点进行训练，实现99.99%的训练损失减少（从34.597到0.003），验证损失为0.0085。该模型在理论零点附近预测狄拉克点间隙在30.3 μeV内，并在整个布里渊区内达到平均误差为53.9 meV（价带）和40.5 meV（导带）。所有十二个C6v操作均通过系统平均保证了精确的对称性保留。这一框架为加速发现提供更多二维材料的物理信息学习奠定了基础", "conclusion": "该框架为加速广泛的二维材料的物理信息学习奠定了基础，通过精确的对称性保留，实现了能带结构的高精度预测。"}
{"llm_update_time": "20250816", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.10817", "html_url": "https://arxiv.org/abs/2508.10817", "title": "适用于33种作物101类植物病害检测的轻量级CNN基准的移动友好深度学习", "title_en": "Mobile-Friendly Deep Learning for Plant Disease Detection: A Lightweight CNN Benchmark Across 101 Classes of 33 Crops", "authors": "Anand Kumar,Harminder Pal Monga,Tapasi Brahma,Satyam Kalra,Navas Sherif", "background": "植物疾病是全球粮食安全的重大威胁。开发能够准确检测植物疾病的早期预警系统变得尤为重要。随着计算机视觉技术的进步，解决这一挑战成为可能。", "innovation": "本文提出了一个移动友好的解决方案，能够准确分类33种作物的101种植物疾病。该系统通过结合Plant Doc、PlantVillage、PlantWild三个数据集构建了一个综合数据集，并在多个轻量级架构上进行了评估，包括MobileNetV2、MobileNetV3、MobileNetV3-Large及EfficientNet-B0、B1等特定设备资源受限设计的架构。实验结果显示，EfficientNet-B1在分类准确率为94.7%的情况下达到了最佳的准确性和计算效率平衡，为其在移动设备上的实际部署提供了良好的基础", "conclusion": "本研究提出的方法能够在移动设备上实现高精度的植物疾病检测，通过选择特定的轻量级深度学习架构实现了准确性和计算效率的优化平衡，具有实际应用潜力。"}
{"llm_update_time": "20250816", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.10839", "html_url": "https://arxiv.org/abs/2508.10839", "title": "强化语言模型用于序贯决策", "title_en": "Reinforced Language Models for Sequential Decision Making", "authors": "Jim Dilkes,Vahid Yazdanpanah,Sebastian Stein", "background": "大型语言模型（LLMs）在序列决策代理方面显示出潜力，但由于依赖于大规模且计算密集型的模型，其应用受到限制。当前的后训练方法多设计用于单回合交互，并无法处理多步骤的代理任务中的奖励归属问题。为此，需要改进小型模型的方法，以应对这些挑战。", "innovation": "提出了多步组相关策略优化（MS-GRPO）算法，该算法基于形式化的文本中介随机博弈（TSMG）和语言-代理策略（LAP）框架。MS-GRPO通过将整个累积回合奖励归因于每一回合的每个步骤实现了奖励归属。该算法结合了新颖的绝对优势加权回合采样策略，实验表明这种策略改善了训练性能。通过在蛇游和冰封湖任务上后训练一个30亿参数模型，实验结果证明了该方法在提高决策性能方面的有效性。", "conclusion": "研究表明，针对后训练的方法是一种实用且高效的替代方案，可以用于使用LLMs构建序列决策代理，而无需依赖模型规模。"}
{"llm_update_time": "20250816", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.10457", "html_url": "https://arxiv.org/abs/2508.10457", "title": "使用元数据增强的多头视觉变换器进行多标签植物物种预测", "title_en": "Multi-Label Plant Species Prediction with Metadata-Enhanced Multi-Head Vision Transformers", "authors": "Hanna Herasimchyk,Robin Labryga,Tomislav Prusina", "background": "本文提出了一种多头视觉变换器方法，用于植被样方图像中多标签植物物种预测，以应对PlantCLEF 2025挑战。任务包括在单物种植物图像上训练模型，在多物种样方图像上进行测试，从而创建了显着的数据域偏移。方法利用预训练的DINOv2视觉变换器基干（ViT-B/14）和多个分类头，用于物种、属和科的预测，利用分类学层级结构。实验在大约140万个训练图像上进行，这些图像涵盖了7,806种植物物种。结果显示了强大的性能，使我们的提交在私有排行榜中排名第3。", "innovation": "本方法的关键贡献包括多尺度切片以捕捉不同尺度的植物，基于预测长度的动态阈值优化，以及通过袋装和Hydra模型架构的集成策略。还包括了各种推理技术，如图像裁剪以去除非植物艺术，top-n筛选进行预测约束，以及logg值阈值策略。", "conclusion": "实验在大约1.4万张训练图像上进行，覆盖了7,806种植物物种。结果表明，在私有排行榜上取得较好的成绩，代码已开源。"}
{"llm_update_time": "20250816", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.10841", "html_url": "https://arxiv.org/abs/2508.10841", "title": "含有显式远程相互作用的通用机器学习势在生物分子模拟中的性能", "title_en": "Performance of universal machine-learned potentials with explicit long-range interactions in biomolecular simulations", "authors": "Viktor Zaverkin,Matheus Ferraz,Francesco Alesiani,Mathias Niepert", "background": "通用机器学习势能够跨越组成和振动自由度提供可转移的准确性，但它们在生物分子模拟中的应用仍然相对不足。本文系统地评估了在SPICE-v2数据集上训练的不变消息传递架构，探讨了显式长程色散和静电相互作用的影响，并考察了模型大小、训练数据组成和静电处理对不同基准数据集及液态水、含盐水溶液和生物分子（如甘氨酸三肽、mini蛋白质Trp-cage和Crambin）模拟的影响。", "innovation": "研究使用了SPICE-v2数据集和不变消息传递架构来评估机器学习势在模拟中的性能，特别是在含有长程相互作用的条件下。研究还系统地考察了模型大小、训练数据组成和静电处理对不同数据集及生物分子模拟的影响.", "conclusion": "更大的模型在基准数据集上提高了准确性，但这一趋势并不一定适用于由模拟获得的属性。预测的属性还依赖于训练数据集的组成。长程静电相互作用在不同系统中没有系统性影响，但对Trp-cage蛋白质，其包括与否会增加构象多样性。结果表明，不平衡的数据集和不成熟的评估实践目前限制了通用机器学习势在生物分子模拟中的应用。"}
{"llm_update_time": "20250816", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.10851", "html_url": "https://arxiv.org/abs/2508.10851", "title": "CrossDenoise：通过轻量级实体感知协同框架降噪隐式反馈", "title_en": "CrossDenoise: Denoising Implicit Feedback via a Lightweight Entity-Aware Synergistic Framework", "authors": "Ze Liu,Xianquan Wang,Shuochen Liu,Jie Ma,Huibo Xu,Yupeng Han,Zhe Yang,Kai Zhang,Longfei Li,Jun Zhou", "background": "推荐系统依赖于隐式反馈，由于存在误判（正面和负面），隐式反馈本质上是嘈杂的，严重影响推荐准确性。现有的去噪策略往往忽视了实体感知建模，存在高计算开销或需要过度的超参数调优，限制了它们的实际应用。", "innovation": "提出了CrossDenoise，一个新颖且轻量化的框架，通过将噪声估计分解为用户特定、项目特定和交互特定因素来解决挑战。利用用户和项目噪声倾向的显著异质性，CrossDenoise 通过基于平均训练损失的等级线性映射来计算实体声誉因子（用户/项目可靠性），并将这些因素与基于个体损失经验累积分布函数的交互水平权重融合。此设计是模型无关的，计算上高效，并仅需要两个直观的超参数。", "conclusion": "在ML-1M、Yelp和Amazon-book数据集上的GMF、NeuMF和CDAE基线下进行的大量实验表明，CrossDenoise 一致且显著地优于最先进的基线。例如，在NeuMF基础上，Yelp 上 NDCG@50 可以获得高达 27.01% 的提升，同时不引入计算和内存开销。我们的分析表明，CrossDenoise 有效地分离了干净样本和噪音样本，并在多种超参数设置下保持稳健性。它为隐式反馈降噪提供了一个实用和可扩展的解决方案。"}
{"llm_update_time": "20250816", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.10827", "html_url": "https://arxiv.org/abs/2508.10827", "title": "加速系外行星气候建模：一种补充三维GCM网格模拟的机器学习方法", "title_en": "Accelerating exoplanet climate modelling: A machine learning approach to complement 3D GCM grid simulations", "authors": "Alexander Plaschzug,Amit Reza,Ludmila Carone,Sebastian Gernjak,Christiane Helling", "background": "随着观测能力更强的望远镜能够更详细和广泛地观测系外行星大气，人们对支持和解释CHEOPS、TESS、JWST、PLATO和Ariel等太空任务观测数据的增强三维气候模型的需求日益增加。然而，一般循环模型（GCMs）的计算密集性和耗时性带来了模拟各种系外行星大气的重大挑战。", "innovation": "本研究旨在探讨是否可以使用机器学习（ML）算法来预测任意潮汐锁定气态系外行星在多种行星参数范围内的三维温度和风结构。该研究引入了一个使用Exorad构建的60个模拟的膨胀热木星网格，并使用密集神经网络（DNN）和决策树（XGBoost）算法训练，以预测气体温度和水平/垂直风。通过将这些方法应用于具有PLATO观测目标的WASP-121 b, HATS-42 b, NGTS-17 b, WASP-23 b和NGTS-1 b等行星模拟，验证了机器学习模型预测的可靠性和质量。", "conclusion": "开发的ML模拟器可以可靠地预测A到M型宿主恒星周围膨胀温暖至超热潮汐锁定木星的完整三维温度场。该工具为系外行星综合研究提供了快速补充和扩展传统GCM网格的方法。预测质量如此之高，以至于不会或几乎没有对气相化学、云形成和传输光谱造成影响。"}
{"llm_update_time": "20250816", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2111.04578", "html_url": "https://arxiv.org/abs/2111.04578", "title": "Neural Networks中改进正则化与鲁棒性的微调方法", "title_en": "Improved Regularization and Robustness for Fine-tuning in Neural Networks", "authors": "Dongyue Li,Hongyang R. Zhang", "background": "转移学习的一种广泛应用算法是微调，即将预训练模型在目标任务上进行微调，通常只需要少量标记数据。当预训练模型的容量远大于目标数据集的大小时，微调容易发生过拟合和记忆训练标签的问题。因此，关键是如何正则化微调过程，确保其在噪声环境下的鲁棒性。", "innovation": "该研究通过对微调进行分析，提出了基于PAC-Bayes泛化边界的正则化方法，具体包括逐层正则化和自我标签校正与权重重置等策略。该方法在多个预训练模型架构和多种图像及文本数据集上进行验证，显著提高了现有方法的表现。", "conclusion": "该方法在7项图像分类任务中平均提高了1.76%的准确率，并在少数几分类任务中提高了0.75%。在包含噪声标签的目标数据集上，该方法在两种噪声环境下分别平均提高了3.56%的准确率。"}
{"llm_update_time": "20250816", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.10875", "html_url": "https://arxiv.org/abs/2508.10875", "title": "关于扩散语言模型的综述", "title_en": "A Survey on Diffusion Language Models", "authors": "Tianyi Li,Mingda Chen,Bowei Guo,Zhiqiang Shen", "background": "扩散语言模型(DLMs)正在迅速成为与占主导地位的自回归(AR)范式相媲美的强大且前景广阔的替代方案。通过迭代去噪过程并行生成令牌，DLMs具有减少推理延迟和捕捉双向上下文的内在优势，从而能对生成过程实施细粒度控制。近年来，尽管在速度上有所提高，但DLMs的表现也已接近自回归模型的水平，使其成为各种自然语言处理任务的理想选择。这项综述文章旨在提供DLM领域的全面概述，追溯其与自回归模型和其他模型的关系，并涵盖从基础原理到最新模型的各种内容。", "innovation": "本综述文章提供了从预训练策略到高级后训练方法的最新技术的全面分类和深入分析，并且详细审查了DLM的推理策略和优化方法，包括解码并行性、缓存机制和生成质量的改进。此外，文章还介绍了DLM在多模态扩展中的最新方法及其在各种实际场景中的应用。", "conclusion": "文章讨论了DLM的局限性和挑战，包括效率低下、长序列处理和基础设施要求等问题，并指出未来的研究方向以促进这一快速发展的领域的进步。开源项目GitHub链接：this https URL"}
{"llm_update_time": "20250816", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.10807", "html_url": "https://arxiv.org/abs/2508.10807", "title": "Parity Cross-Resonance: 一个多比特门", "title_en": "Parity Cross-Resonance: A Multiqubit Gate", "authors": "Xuexin Xu,Siyu Wang,Radhika Joshi,Rihan Hai,Mohammad H. Ansari", "background": "本文介绍了一个利用工程化相互作用实现单一相干步骤中控制-控制-目标和控制-目标-目标操作的原生三比特纠缠门。这项工作是在常规将多比特门分解为多个两比特门的基础上进行的，旨在通过选择性放大所需相互作用并抑制不必要的耦合来实现整个计算子空间内的鲁棒性能以及超越该子空间的表现。这种新的门可以归类为交叉共振门。文中展示了这种三比特门可用于多种场合，比如GHZ三重态的制备、使用多体相互作用实现托弗利逻辑演示，以及实现一个控制-ZZ门。后者直接将两个数据比特的奇偶性映射到测量比特上，从而在表面码量子错误校正中实现更快更准确的稳定量测量。对于所有这些应用场景，我们表明三比特门性能在希尔伯特空间大小变化时依旧保持稳定，这在增加激发总数的测试中得到了验证。这项工作为设计基于多比特原生相互作用的核心元素的下一代超导量子处理器的电路架构和控制协议奠定了基础.", "innovation": "这项研究的创新之处在于提出了一个利用工程化相互作用实现控制-控制-目标和控制-目标-目标操作的单一相干步骤的原生三比特纠缠门，即Parity Cross-Resonance门。这种方法采用混合优化策略，选择性放大所需互作用并抑制不必要的耦合来获得整个计算子空间及超越该子空间范围内的鲁棒性能。其证实了这种新门可以在多种应用场景中保持性能的稳定，如制备GHZ三重态、多体相互作用的托弗利逻辑演示，以及实现控制-ZZ门，特别是通过直接将两个数据比特的奇偶性映射到测量比特上完成稳定量的测量，从而提高表面码量子误差校正中的测量速度和保真度。这种三比特门在不同希尔伯特空间大小下的性能保持稳健，进一步证实了其在量子计算中的潜在应用价值。", "conclusion": "这项工作为基于原生多比特相互作用设计量子处理器的电路架构和控制协议提供了新的思路，将电路设计和控制策略与量子硬件特性紧密结合，推动了下一代超导量子处理器的发展。这种Parity Cross-Resonance三比特门在多个方面展示了其实用性和有效性，为量子计算的实际应用铺平了道路。"}
{"llm_update_time": "20250816", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.10887", "html_url": "https://arxiv.org/abs/2508.10887", "title": "针对典型基准问题域配置回声状态网络的经验性研究", "title_en": "Empirical Investigation into Configuring Echo State Networks for Representative Benchmark Problem Domains", "authors": "Brooke R. Weborg,Gursel Serpen", "background": "本文探讨了回声状态网络（Echo State Network，ESN），一种水库计算机，在四个不同的基准问题上的表现，并分析了参数选择和调整及其对ESN架构性能的影响。指出在该领域缺乏经验可能会使参数选择变得复杂，即使一些超参数优化算法也需要根据首次手动选择的参数值进行调整。因此，了解不同参数及其值对ESN架构性能的影响是至关重要的。为此，本文通过构建和实验一系列代表不同问题领域的基准任务，包括时间序列预测、模式生成、混沌系统预测和时间序列分类，来展示ESN性能受架构、设计、参数选择和参数值变化的影响，从而填补进入该研究领域的经验空白。", "innovation": "本文提出了适用于同一领域内问题的回声状态网络架构配置、参数选择及其值的启发式规则或经验法则。这些规则有助于填补新进入该领域的研究者所需的经验空白。并通过一系列基准任务检验了参数选择和调整对ESN性能的影响。", "conclusion": "本文通过对回声状态网络架构配置的经验性研究，展示并分析了参数选择和调整对ESN性能的影响，并为同一领域内的问题提供了适用的启发式规则或经验法则，帮助新进入该领域的研究者更好地理解和应用回声状态网络。"}
{"llm_update_time": "20250816", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.10879", "html_url": "https://arxiv.org/abs/2508.10879", "title": "一种针对差分隐私的\\(k\\)-主成分分析的迭代算法及其自适应噪声调整", "title_en": "An Iterative Algorithm for Differentially Private $k$-PCA with Adaptive Noise", "authors": "Johanna Düngler,Amartya Sanyal", "background": "该研究考虑了给定n个独立同分布的二维随机矩阵\\(A_i\\)，这些矩阵共享相同的期望\\(\\Sigma\\)。目标是在保证每个个体数据的差分隐私（DP）的前提下，识别出一个大小为k的子空间，该子空间能够捕捉\\(\\Sigma\\)中的最大方差方向。现有方法要么需要样本大小n与维度d成超线性增长，即便是在\\(A_i\\)假设为高斯分布的情况下；要么在数据固有的随机性较小时也会引入过多的噪声。Liu等人在2022年利用DP-PCA解决了这些设计的问题，但仅限于估计最大的特征向量（\\(k=1\\)）。", "innovation": "本文提出了一种算法，能够在任何\\(k \\leq d\\)的情况下估计前k个主特征向量，并克服了上述限制。对于\\(k=1\\)的情况，本文算法匹配了DP-PCA的实用保证，即使样本大小n为\\(\\tilde{O}(d)\\)也能达到接近最优的统计误差。此外，本文还提供了对于一般\\(k > 1\\)情况的下界证明，并且实验结果表明了本文算法相较于基线的优势。", "conclusion": "在处理差分隐私下单特征向量估计和多特征向量估计时，该算法都表现出显著的优越性，特别是在样本量较小的情况下。为差分隐私下非高斯数据的主成分分析提供了新的解决方案。"}
{"llm_update_time": "20250816", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2401.00873", "html_url": "https://arxiv.org/abs/2401.00873", "title": "统一自监督聚类和基于能量的模型", "title_en": "Unifying Self-Supervised Clustering and Energy-Based Models", "authors": "Emanuele Sansone,Robin Manhaeve", "background": "自监督学习能够从大量数据中学习表示，而生成模型能够学习数据生成过程的信息。本文旨在探讨这两种方法之间的规范性联系，强调它们互补性的优势。本文对自监督学习目标进行了分析，解释了其背后的概率图模型，并提出了一种从第一原理推导自监督学习目标的标准化方法。分析表明，自监督学习可以自然地与基于似然性的生成模型集成。", "innovation": "本文提出了一种通过下界可靠地惩罚最关键失败模式的概念，并在基于集群的自监督学习和能量模型的框架内实现了这一概念，从而实现了端到端的统一。此外，通过实验证明，本文的目标函数能够同时以判别性和生成性训练网络，显著优于现有的自监督学习策略。研究结果进一步证明了该方法能够被整合到神经符号框架中，以解决简单的符号接地问题。", "conclusion": "通过实验证明了本文方法的有效性，展示了其在聚类、生成和异常检测等方面的优越性能。代码已在公开地址中发布，可供查阅。"}
{"llm_update_time": "20250816", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.10464", "html_url": "https://arxiv.org/abs/2508.10464", "title": "SingleStrip: 单一标记例学习颅骨剥离", "title_en": "SingleStrip: learning skull-stripping from a single labeled example", "authors": "Bella Specktor-Fadida,Malte Hoffmann", "background": "深度学习分割高度依赖标记数据，但人工标记数据耗时费力，尤其是在处理体积图像如脑磁共振成像(MRI)时。领域随机化技术通过从标签图生成多样化的训练图像来减轻对标记数据的依赖，但当可用的标签图很少时，它们提供的解剖变异有限。半监督自训练通过迭代将模型预测融入训练集，以利用未标记数据进行学习，以此解决标记稀缺问题。本文提出了一种结合领域随机化与自训练的方法，通过最少一个标注实例训练三维颅骨剥离网络。该方法首先自动生成标签以合成训练用图像，接着训练卷积自编码器评估未标记数据中脑掩模的质量，并最终通过伪标记的排名对网络进行微调，从而在有限标注数据下实现接近更多标注图像训练的性能。", "innovation": "本文提出了一种结合领域随机化与卷积自编码器质量控制的半监督自训练策略，该策略能在极其有限的标注数据情况下有效学习颅骨剥离。通过将领域随机化与自编码器的重建误差相结合，实现了在未标注数据上进行高质量的颅骨剥离预测，并且优于基于一致性排名的策略。这种策略可能减少新解剖结构或新兴成像技术相关的研究进展缓慢的问题，因为标注过程通常是一个瓶颈。", "conclusion": "结合领域随机化和自编码器质量控制的方法在极少量标记数据下能够有效地进行半监督分割。这种方法展示了在新解剖结构或新兴成像技术应用于研究时减轻标记负担的巨大潜力。"}
{"llm_update_time": "20250816", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2112.06362", "html_url": "https://arxiv.org/abs/2112.06362", "title": "在具有随机双线性奖励的并行服务器队列中进行学习调度", "title_en": "Learning to Schedule in Parallel-Server Queues with Stochastic Bilinear Rewards", "authors": "Jung-hun Kim,Milan Vojnovic", "background": "本文考虑了在类任务并行服务器排队系统中，尚未完全确定工作-服务器分配带来的收益的调度问题。在这种场景下，工作会在服务完成前产生持有成本，而工作-服务器分配会带来可观察的随机收益，但这些收益的平均值是未知的。我们假设工作和服务器特征的函数关系遵循双线性模型。我们的目标是在一定时间范围内最大化累计工作-服务器分配的收益，同时保持总工作持有成本在可接受范围内，以确保排队系统的稳定性。这个问题源自网络系统中资源分配的应用需求。解决了奖励最大化与服务器分配的公平性之间的权衡，以保持排队系统的稳定性（即最大化网络吞吐量）。", "innovation": "本文提出了一种基于加权比例公平标准的调度算法，该算法结合了边际成本以实现奖励最大化，并使用针对双线性奖励定制的多臂老虎机算法。该算法在时间范围$T$内实现了子线性后悔上界，子线性平均持有成本（以及队列长度上界）为$\tilde{O}(\text{sqrt}(T))$，从而确保系统的稳定性。此外，还确立了分布式迭代算法的稳定性条件，适用于大规模系统应用。", "conclusion": "通过数值实验，本研究验证了所提出的算法的有效性。我们强调了在不确定环境中进行有效资源分配的重要性，并提出了一个既能最大化奖励又能保证长期内系统稳定性的调度方法。"}
{"llm_update_time": "20250816", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2406.04443", "html_url": "https://arxiv.org/abs/2406.04443", "title": "当噪声为重尾时，剪裁改善了Adam-Norm和AdaGrad-Norm", "title_en": "Clipping Improves Adam-Norm and AdaGrad-Norm when the Noise Is Heavy-Tailed", "authors": "Savelii Chezhegov,Yaroslav Klyukin,Andrei Semenov,Aleksandr Beznosikov,Alexander Gasnikov,Samuel Horváth,Martin Takáč,Eduard Gorbunov", "background": "自适应步长的方法，如AdaGrad和Adam，对于训练现代深度学习模型尤其是大型语言模型至关重要。通常来说，后期的随机梯度噪声是重尾分布的。已有研究证明梯度裁剪能够有效改善此类噪声下的高概率收敛性。然而，对于剪裁后AdaGrad/Adam及其延迟版本的高概率收敛理解仍然不足。", "innovation": "本文通过证明在重尾噪声情况下，AdaGrad/Adam及其延迟版本具有在高概率下的不良收敛问题，进一步验证了梯度裁剪的有效性。本文还推导了在平滑凸/非凸随机优化中使用裁剪版本的AdaGrad-Norm和Adam-Norm的高概率收敛性边界，这些边界具有多项式对数依赖于置信水平。", "conclusion": "本研究证实了在重尾噪声下剪裁版本的AdaGrad/Adam相较于原始版本有更优表现，通过剪裁能够解决重尾噪声下的高概率收敛问题。"}
{"llm_update_time": "20250816", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2402.13871", "html_url": "https://arxiv.org/abs/2402.13871", "title": "一种基于可解释变换器模型的钓鱼邮件检测方法：大型语言模型的探讨", "title_en": "An Explainable Transformer-based Model for Phishing Email Detection: A Large Language Model Approach", "authors": "Mohammad Amaz Uddin,Md Mahiuddin,Iqbal H. Sarker", "background": "钓鱼邮件是网络安全领域的一种严重威胁，通过发送虚假电子邮件试图误导用户，意图窃取敏感信息或造成经济损失。攻击者常常伪装成可信实体，利用技术进步进行欺骗，使得钓鱼邮件的检测和预防变得更加困难。尽管有广泛的学术研究，但仍有许多挑战需要克服，因此开发新的检测方法至关重要。大规模语言模型（LLMs）和掩码语言模型（MLMs）具有巨大的潜力，能够提供创新的解决方案。因此，研究人员致力于开发基于这些模型的钓鱼邮件检测解决方案。这项研究不仅利用了这种潜力，还特别强调了可解释性的重要性，因为这对于理解和信任模型的决策过程至关重要。这项研究工作中，我们使用了预处理技术处理数据集，并优化了细调的DistilBERT模型来检测钓鱼邮件。实验结果表明，该模型能够有效地提高检测准确性。", "innovation": "文章的创新之处在于提出了一种基于可解释变换器模型的钓鱼邮件检测方法。具体而言，本文利用了可解释的人工智能技术（XAI）如本地可解释模型无关解释（LIME）和变换器解释方法，展示了模型如何做出预测。这种方法不仅提高了检测的准确性，还增强了模型的透明度，有助于用户理解模型的决策过程。这项研究的方法是将细调的DistilBERT模型应用于钓鱼邮件检测任务，并展示了有效的结果。", "conclusion": "本文成功地开发并实现了基于DistilBERT的可解释模型，用于钓鱼邮件的检测。通过预处理技术解决数据集中的类别不平衡问题，实验表明该模型具有高准确性。此外，通过可解释的人工智能技术，作者成功地解释了模型的预测过程，提高了模型的透明度和用户的接受度。该工作为钓鱼邮件检测领域提供了新的视角和解决方案，未来可以在实际应用中进一步验证和扩展这项技术。"}
{"llm_update_time": "20250816", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2406.17184", "html_url": "https://arxiv.org/abs/2406.17184", "title": "一般价值模型下的带上下文的动态定价的 minimax 优劣性", "title_en": "Minimax Optimality in Contextual Dynamic Pricing with General Valuation Models", "authors": "Xueping Gong,Wei You,Jiheng Zhang", "background": "文章研究了基于上下文的动态定价问题。决策者根据可观察的上下文发布个性化价格，然后收到二进制购买反馈，表明客户的价值是否超过价格。每个价值被建模为上下文的未知隐函数，并受到未知分布的独立同分布市场噪声的干扰。该文提出了一个仅依赖于噪声分布的Lipschitz连续性和价值有界的最小极大最优算法。", "innovation": "该研究提出了一种方法，通过离散相关的噪声范围形成候选价格集，并使用分层数据分区来获得比椭球势能引理推导的置信界更紧的边界。这一方法的关键优势在于估值函数的估计偏差在比较上界置信界时相互抵消，从而无需知道Lipschitz常数。此外，该框架能够延伸到线性模型以外的通用函数类，并通过离线回归提取来适应。", "conclusion": "本文提出了一个基于泛函类的最小极大最优后悔上限，该上限在对数因子上与已知下界匹配。此外，文章还进一步细化了在特定结构下的保证条件，包括线性价值模型、二阶平滑性、稀疏性和已知噪声分布或可观察价值，并与先前的动态定价方法进行比较。最后，通过数值实验验证了理论并展示了与基准方法相比的优势。"}
{"llm_update_time": "20250816", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2410.10915", "html_url": "https://arxiv.org/abs/2410.10915", "title": "HGAurban: 异质图自动编码在城市空间-时间学习中的应用", "title_en": "HGAurban: Heterogeneous Graph Autoencoding for Urban Spatial-Temporal Learning", "authors": "Qianru Zhang,Xinyi Gao,Haixin Wang,Dong Huang,Siu-Ming Yiu,Hongzhi Yin", "background": "空间-时间图表示在城市感应应用中（包括交通分析、人类移动行为建模和城市范围内的犯罪预测）发挥着关键作用。然而，现有的空间-时间数据具有噪声大和稀疏的特性，这限制了现有神经网络的学习能力，使其难以在空间-时间图中学习有意义的区域表示。", "innovation": "我们提出了HGAurban，一种新颖的混合空间-时间图掩蔽自动编码器，利用生成式的自监督学习来实现强大的城市数据表示。该框架引入了一种混合空间-时间图编码器，可以从多源数据中提取区域间的依赖关系，实现对多种空间关系的全面建模。自监督学习框架中，我们实现了一个掩蔽自动编码器，可以同时处理节点特征和图结构，这一方法可以自动学习区域间的异质空间-时间模式，显著提高了动态时间相关性的表示能力。", "conclusion": "跨多个空间-时间数据挖掘任务的全面实验表明，我们的框架优于最先进的方法，并能稳健地处理实际城市数据挑战，包括空间和时间维度上的噪声和稀疏性问题。"}
{"llm_update_time": "20250816", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2410.18368", "html_url": "https://arxiv.org/abs/2410.18368", "title": "CPU设计空间探索中的多目标优化：需要的是注意力", "title_en": "Multi-objective Optimization in CPU Design Space Exploration: Attention is All You Need", "authors": "Runzhen Xue,Hao Wu,Mingyu Yan,Ziheng Xiao,Guangyu Sun,Xiaochun Ye,Dongrui Fan", "background": "现代CPU设计中，设计空间探索（DSE）至关重要，但当前框架在高维架构空间中难以扩展和普遍适用。随着设计空间维度的增长，现有的DSE框架面临三个根本挑战：（1）在大型设计空间中，代理模型的准确性和可扩展性降低；（2）效率低下的获取过程，依赖于手动编写的启发式方法或穷尽搜索；（3）可解释性有限，难以定位架构瓶颈。", "innovation": "本文提出了一种名为AttentionDSE的端到端DSE框架，它通过基于注意机制的神经架构原生地整合了性能预测和设计指导。关键创新点包括：（1）感知驱动的注意力机制，利用架构的层次结构和局部性，将注意力复杂度从O(n²)降低到O(n)；（2）注意力感知的瓶颈分析，自动揭示关键参数，以便进行有针对性的优化，无需领域特定的启发式方法。", "conclusion": "在使用SPEC CPU2017基准套件评估的高维CPU设计空间中，AttentionDSE比最先进的基线达到了3.9%更高的帕累托测地体积，并且探索时间减少了超过80%。"}
{"llm_update_time": "20250816", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2501.02409", "html_url": "https://arxiv.org/abs/2501.02409", "title": "扰动下的可解释神经ODEs在基因调控网络发现中的应用", "title_en": "Interpretable Neural ODEs for Gene Regulatory Network Discovery under Perturbations", "authors": "Zaikang Lin,Sei Chang,Aaron Zweig,Minseo Kang,Elham Azizi,David A. Knowles", "background": "现代的高通量生物数据集拥有成千上万的扰动，提供了一个大规模发现因果图形的机会，这些图形代表了基因之间的调控关系。不同的可微因果图形模型已被提出，从大规模的扰动数据集中推断基因调控网络（GRN），捕捉遗传扰动中的因果基因调控关系。然而，现有的模型在表达能力和可扩展性方面有限，无法处理诸如细胞分化等生物过程的动态性。", "innovation": "我们提出了PerturbODE框架，该框架结合了包含生物学信息的神经常微分方程（神经ODEs）来建模细胞状态轨迹下的扰动，并从神经ODE的参数中推导出因果GRN。", "conclusion": "我们在模拟和实际的过表达数据集中展示了PerturbODE在轨迹预测和GRN推理方面的有效性。"}
{"llm_update_time": "20250816", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2410.21072", "html_url": "https://arxiv.org/abs/2410.21072", "title": "特征和时间上不一致数据上的联邦时间序列生成", "title_en": "Federated Time Series Generation on Feature and Temporally Misaligned Data", "authors": "Zhi Wen Soi,Chenrui Fan,Aditya Shankar,Abele Mălan,Lydia Y. Chen", "background": "联邦学习中，分布式时间序列数据存在挑战，因为不同客户端可能具备不同的特征集，并且时间步长不一致。现有的联邦时间序列模型受限于假设所有客户端中时间序列表和特征集完全对齐的限制。", "innovation": "提出了一种名为FedTDD（联邦时间序列扩散模型）的新颖联邦时间序列模型，其核心是一个新颖的数据提纯和聚合框架，通过填补时间步长和特征的不一致来统一客户端差异。与传统的联邦学习不同，FedTDD通过交换本地合成输出（而非模型参数）来学习客户端时间序列间的相关性。协调器通过交换合成数据利用客户端共享的知识逐步提升全局提纯网络，这反过来提高了客户端本地特征估算的质量，使每个客户端能够使用最新的更准确提纯器来改进其对缺失数据的本地填充。", "conclusion": "实验结果在五个数据集上表明FedTDD相比集中式训练更有效，并且通过共享合成输出转移本地时间序列的知识也有效。值得注意的是，FedTDD在Context-FID和相关性得分上分别优于本地训练79.4%和62.8%。"}
{"llm_update_time": "20250816", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2501.18475", "html_url": "https://arxiv.org/abs/2501.18475", "title": "CLoQ:通过校准LoRA初始化提升量化LLMs的微调", "title_en": "CLoQ: Enhancing Fine-Tuning of Quantized LLMs via Calibrated LoRA Initialization", "authors": "Yanxia Deng,Aozhong Zhang,Selcuk Gurses,Naigang Wang,Zi Yang,Penghang Yin", "background": "使用低秩适应（LoRA）微调大型语言模型（LLMs）已成为下游任务中资源有限场景的有效方法。然而，将LoRA技术应用于量化LLMs时，由于量化权重的表示精度降低而增加了独特挑战。本文的研究背景在于解决量化LLMs在初始化阶段即层间差异较大的问题。", "innovation": "本文提出了一种名为CLoQ（Calibrated LoRA initialization for Quantized LLMs）的初始化策略，旨在最小化预训练LLMs与具有LoRA组件的量化LLM之间的层间差异。CLoQ通过一个小规模校准数据集来量化预训练的LLMs，并为每个层确定最佳的LoRA组件，以此为后续微调打下坚实基础。此外，本文还提出了一个重要的理论结果，能够精确构建这些最优的LoRA组件。", "conclusion": "本文通过CLoQ方法在语言生成、算术推理和常识推理等多种任务中进行了验证，结果表明该方法在量化LLMs的LoRA微调中表现出色，特别是在超低位宽情况下，CLoQ显著优于现有方法。"}
{"llm_update_time": "20250816", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2409.12446", "html_url": "https://arxiv.org/abs/2409.12446", "title": "低复杂度数据上神经网络泛化", "title_en": "Neural Networks Generalize on Low Complexity Data", "authors": "Sourav Chatterjee,Timothy Sudijono", "background": "展示了具有ReLU激活的前馈神经网络在低复杂度数据上的泛化能力。研究者基于简单编程语言生成的独立同分布（i.i.d.）数据，提出了最小描述长度（MDL）前馈神经网络的概念，并探讨了其泛化能力。例如，对于质数检测任务，给出了一个从1到N均匀随机抽取n个数的样本，通过MDL神经网络可以以概率1-O(lnN/n)的错误率准确判断一个新抽取的数是否是质数。此过程无需针对质数检测特别设计网络，而是通过MDL发现能完成此任务的网络。此外，文中还讨论了MDL神经网络插值器在嘈杂数据上的表现，表明了缓解过拟合的效果。", "innovation": "提出了基于简单编程语言生成数据的最小描述长度（MDL）前馈神经网络的概念，并证明了该网络在低复杂度数据上的泛化能力。特别地，对于质数检测任务，文中给出了误差概率为1-O(lnN/n)的理论结果，表明基于MDL的神经网络可以有效泛化。同时，讨论了网络在嘈杂数据中的表现，提出了一种缓解过拟合的新思路。", "conclusion": "最小描述长度（MDL）前馈神经网络在低复杂度数据上具有良好的泛化能力。对于质数检测这样的基本计算任务，MDL神经网络插值器能够准确判断新抽取数是否为质数，其误差概率为1-O(lnN/n)。此外，MDL神经网络插值器在嘈杂数据中也能表现出良好的泛化能力，展示了缓解过拟合的效果。"}
{"llm_update_time": "20250816", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2410.10320", "html_url": "https://arxiv.org/abs/2410.10320", "title": "DiRW: 考虑路径的有向图学习以应对异质性", "title_en": "DiRW: Path-Aware Digraph Learning for Heterophily", "authors": "Daohan Su,Xunkai Li,Zhenjun Li,Yinping Liao,Rong-Hua Li,Guoren Wang", "background": "近期，图形神经网络（GNN）已成为处理图形结构数据的强大表示学习工具。然而，大多数方法专门针对无向图进行设计，忽略了有向图（有向图）边缘中的丰富信息。尽管如此，有向图在现实世界中广泛应用，已被证实能够有效应对异质性问题。现有的基于空间的有向图神经网络（DiGNN）在复杂的学习机制和对高质量拓扑的依赖下表现出低效率和不稳定性能。该研究在这些限制的基础上，提出了一种名为方向随机游走（DiRW）的方法，作为大多数基于空间的DiGNN的即插即用策略，并提供了一种新的有向图学习框架。该方法使用了一种定向感知路径采样器，以路径概率、长度和数量为导向，通过考虑节点特征和拓扑结构进行优化，同时集成节点级别的可学习路径聚合器以获得通用节点表示。", "innovation": "提出了名为方向随机游走（DiRW）的策略，该策略作为大多数基于空间的DiGNN的即插即用方法也是一种创新模型，能够提供新的有向图学习范式。DiRW通过路径感知路径采样器，在不考虑权重的情况下优化路径概率、长度和数量，利用节点特征和拓扑结构进行优化。此外，它还集成了节点级别的可学习路径聚合器，用于节点表示的泛化。实验表明，DiRW作为即插即用策略可以增强大多数基于空间的方法，并且作为新的有向图学习框架可实现最先进的性能。", "conclusion": "通过广泛的实验，证明了DiRW作为即插即用策略可以显著提升大多数基于空间的方法的性能，并且作为新的有向图学习范式能够实现最先进的性能。源代码和数据可以在此处获取：provided URL."}
{"llm_update_time": "20250816", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2410.06151", "html_url": "https://arxiv.org/abs/2410.06151", "title": "使用外部行为好奇心来多样化策略行为", "title_en": "Diversifying Policy Behaviors with Extrinsic Behavioral Curiosity", "authors": "Zhenglin Wan,Xingrui Yu,David Mark Bossens,Yueming Lyu,Qing Guo,Flint Xiaofeng Fan,Yew Soon Ong,Ivor Tsang", "background": "模仿学习（IL）已经在各种应用（如机器人运动）中显示出潜力，但它往往仅限于学习单个专家策略，限制了行为多样性，并在不可预测的现实环境中约束了鲁棒性。为解决这一问题，引入了质量多样性逆强化学习（QD-IRL），这是一种将质量多样性优化与IL方法结合的新框架，使智能体能够从有限的示范中学到多样化的策略行为。为了验证Extrinsic Behavioral Curiosity (EBC)在探索多样化运动行为方面的有效性，该方法在多个机器人运动任务上进行了评估。EBC通过提高GAIL、VAIL和DiffAIL的性能，使其在所有包含的环境中分别提高了185%、42%和150%，甚至在类人机器人（Humanoid）上超过了专家性能20%。此外，EBC适用于基于Gradient-Arborescence的质量多样性强化学习（QD-RL）算法，显著提高了其性能并提供了一种学习行为多样化的通用技术。", "innovation": "该研究提出了Extrinsic Behavioral Curiosity (EBC)，使智能体能够从外部评判者接收额外的好奇心奖励，基于行为在大规模行为档案中的新颖性。这种方法应用于质量多样性逆强化学习（QD-IRL）框架，包括GAIL、VAIL和DiffAIL，使智能体能够学习更加多样化的行为。EBC可以在基于Gradient-Arborescence的质量多样性强化学习（QD-RL）算法中显著提高性能，并提供了一种泛化的技术，用于学习行为多样策略。", "conclusion": "研究结果表明，通过将Extrinsic Behavioral Curiosity (EBC)与质量多样性逆强化学习（QD-IRL）以及其他基于Gradient-Arborescence的质量多样性强化学习算法相结合，可以显著提高智能体学习多样行为的能力，即使在原始数据有限的情况下也能表现优异。研究已提供源代码。"}
{"llm_update_time": "20250816", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2411.07837", "html_url": "https://arxiv.org/abs/2411.07837", "title": "FRUGAL: 通过减少状态开销实现高效记忆优化以实现可扩展训练", "title_en": "FRUGAL: Memory-Efficient Optimization by Reducing State Overhead for Scalable Training", "authors": "Philip Zmushko,Aleksandr Beznosikov,Martin Takáč,Samuel Horváth", "background": "随着大型语言模型参数数量的增加，预训练和微调过程中对GPU内存的需求也随之增大。其中，优化器状态通常消耗了大量内存。虽然已有一些低秩适应（如LoRA）、低秩梯度投影（如GaLore）和块优化（如BAdam）等方法，但这些方法在有效秩保持低秩的同时，也可能导致梯度信息的大量丢失，尤其是在预训练阶段，这种信息丢失尤为重要。", "innovation": "提出了一个新的低内存消耗优化框架——FRUGAL。FRUGAL利用梯度划分技术，通过高级算法进行低维度更新，而对于剩余方向的更新则通过无状态方法（如SGD或signSGD）执行。框架可以与各种低秩更新选择技术（如GaLore和BAdam）集成，为低维度更新提供理论收敛保证，并在不同固定内存预算下始终表现出色，同时在预训练和微调任务中取得了最佳性能，实现了内存效率和性能指标的平衡。", "conclusion": "该框架能够有效减少优化过程中的内存消耗，同时保持算法的有效性，并通过实验证明优于现有方法。"}
{"llm_update_time": "20250816", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.10765", "html_url": "https://arxiv.org/abs/2508.10765", "title": "学习霍普菲尔德神经网络中的记忆和遗忘：分岔机制、吸引子和分界线", "title_en": "Memorisation and forgetting in a learning Hopfield neural network: bifurcation mechanisms, attractors and basins", "authors": "Adam E. Essex(1),Natalia B. Janson(1),Rachel A. Norris(1),Alexander G. Balanov(1) ((1) Loughborough University, England)", "background": "尽管基于人工神经网络（ANNs）的人工智能得到了爆炸性增长，但这些网络在学习过程中如何形成记忆以及如何发展不需要的特征（包括虚假记忆和灾难性遗忘）仍旧不明确。虽然有关ANNs学习方面的一些研究已有大量成果，但由于其高维度和非线性特性，它们的全面分析仍然是一个挑战。目前，知识可能存在于连接权重或是吸引子盆地中，但这两者之间没有明确的联系。因此，这篇论文通过全面分析81神经元霍普菲尔德网络在进行希伯学习过程中的记忆形成机制，揭示出导致吸引子生成与消失的分岔过程及其盆地边界，以期解决上述挑战。", "innovation": "本文创新性地提出了通过揭示分岔过程来全面分析高维度学习人工神经网络中的记忆形成机制和灾难性遗忘现象的新策略。具体来说，研究通过吸引子的生成与消失揭示了新的点吸引子与其边界形成及破坏的相关机制。此外，本文还指出记忆的存储和遗忘是同一机制的两种表现形式，并展示了这一策略在任何形式的循环人工神经网络中的普遍适用性。这为开发缓解人工神经网络缺陷的方法提供了新的见解。", "conclusion": "通过这种方法，研究人员能够明确记忆形成和灾难性遗忘的过程，这不仅有助于我们更好地理解霍普菲尔德神经网络的运作机制，还为开发更高效的机器学习算法提供了新的思路。"}
{"llm_update_time": "20250816", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2502.04164", "html_url": "https://arxiv.org/abs/2502.04164", "title": "在重尾噪声下的高效分布式优化", "title_en": "Efficient Distributed Optimization under Heavy-Tailed Noise", "authors": "Su Hyeong Lee,Manzil Zaheer,Tian Li", "background": "现代机器学习中，由于模型和数据集规模扩大，分布式优化成为默认的训练范式。为了减轻通信开销，在全局聚合之前通常会对本地更新进行应用，形成了包含内层和外层的嵌套优化方法。然而，在基于注意力的模型中，重尾随机梯度噪声仍然是一个重大问题，极大地妨碍了有效的训练进程。\n", "innovation": "本文提出了TailOPT（针对重尾噪声的有效分布式优化框架），该框架通过利用自适应优化或剪裁技术来应对重尾噪声。特定的变体Bi^2Clip通过在内外层优化器上进行坐标轴式剪裁，实现了类似自适应性能（例如Adam），而无需维护或传输额外的梯度统计信息，从而实现了内存和通信效率的提升。\n", "conclusion": "实验结果表明，TailOPT及其Bi^2Clip变体在多种语言任务和模型上表现出优越的性能，超过了最先进的方法。\n"}
{"llm_update_time": "20250816", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2502.01618", "html_url": "https://arxiv.org/abs/2502.01618", "title": "Rollout Roulette: 使用基于粒子的蒙特卡洛方法的概率推理方法实现大语言模型推理时的扩展", "title_en": "Rollout Roulette: A Probabilistic Inference Approach to Inference-Time Scaling of LLMs using Particle-Based Monte Carlo Methods", "authors": "Isha Puri,Shivchander Sudalairaj,Guangxuan Xu,Kai Xu,Akash Srivastava", "background": "大语言模型（LLMs）通过扩大模型规模和/或数据量实现了显著的性能增长。然而，最近的证据表明，这样的扩展方法带来的收益在逐渐减少，因此推动了在推理时扩展计算投入的需求。现有的推理时扩展方法通常使用奖励模型将其任务表述为搜索问题，这会导致奖励欺骗的风险，因为奖励模型的近似误差会导致启示性搜索的问题。鉴于此，本文将推理时的扩展问题表述为概率推理任务，并利用基于采样的技术探索状态空间模型状态分布的典型集合，而不是直接优化其模式。", "innovation": "本文提出了一种新的概率推理方法，通过适配粒子蒙特卡洛方法来实现此任务的推理时扩展。实验评价表明，与确定性搜索方法相比，本文方法在各种复杂数学推理任务中具有4-16倍更好的扩展率。利用此方法，Qwen2.5-Math-1.5B-Instruct模型在仅4次展开后能超越GPT-4o的准确性，而Qwen2.5-Math-7B-Instruct模型在仅32次展开后可扩展至o1级别的准确性。这一工作不仅提供了一种有效的推理时扩展方法，还将概率推理领域的丰富文献与大语言模型的推理时扩展联系起来，为进一步开发更稳健的算法奠定了基础。", "conclusion": "本文不仅提出了一种有效的概率推理方法来实现大语言模型推理时的扩展，还将概率推理领域的丰富文献与大语言模型推理时的扩展联系起来，为将来开发更稳健的算法提供了一条道路。"}
{"llm_update_time": "20250816", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2502.12188", "html_url": "https://arxiv.org/abs/2502.12188", "title": "通过推理时长适配增强基于扩散的神经组合解决的跨问题泛化", "title_en": "Boosting Cross-problem Generalization in Diffusion-Based Neural Combinatorial Solver via Inference Time Adaptation", "authors": "Haoyu Lei,Kaiwen Zhou,Yinchuan Li,Zhitang Chen,Farzan Farnia", "background": "基于扩散的神经组合优化(NCO)方法通过学习离散扩散模型来生成解决方案，已经展示了解决NP完全(NP-complete)问题的有效性，而不需要手动构建领域知识。尽管取得了一定的成功，但现有的NCO方法在跨尺度和跨问题的泛化能力，以及与传统求解器相比的高训练成本方面仍面临重大挑战。虽然最近对扩散模型的研究引入了无需训练的方法，这些方法利用预定义的指导函数进行条件生成，但在组合优化中的应用尚不广泛。因此，需要一种训练无需训练的推理时长适配框架来增强NCO方法的跨问题泛化能力。", "innovation": "提出了一种训练无需训练的推理时间适配框架(DIFU-Ada)。该框架允许基于扩散的NCO解算器在没有额外训练的情况下实现零样本跨问题转移和跨尺度泛化能力。此外，提供了理论分析，帮助理解跨问题的转移能力。", "conclusion": "实验结果表明，一个仅在旅行商问题(TSP)上训练的扩散解算器，通过推理时间适配，可以在不同问题规模的不同TSP变体（例如，收集奖品的TSP(PCTSP)和旅行商问题(ORI)）上实现具备竞争力的零样本转移性能。"}
{"llm_update_time": "20250816", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2502.18052", "html_url": "https://arxiv.org/abs/2502.18052", "title": "准确性的市场：竞争下的分类", "title_en": "A Market for Accuracy: Classification under Competition", "authors": "Ohad Einav,Nir Rosenfeld", "background": "机器学习模型在帮助电信提供商在市场上获胜方面扮演着关键角色。然而，传统的学习方法没有考虑到其他竞争提供商的存在，这些竞争提供商也争夺消费者的业务。研究在这种市场竞争环境中进行学习的影响对于提供商、消费者以及整体市场都至关重要。作者首先通过对学习目标的分析来探讨此类市场，指出精准度不能是唯一的考虑因素。然后提出了竞争下的分类方法，以便在存在竞争对手的情况下最大化市场份额。研究结果显示，进入市场的时机和模型更新的时机对提供商和消费者都有重大影响。这种方法的有效性在从简单分布到嘈杂数据集的各种领域中得到了验证，且整个市场通过快速收敛到平衡状态保持了稳定性。", "innovation": "提出了竞争下的分类方法，旨在帮助学习者在存在竞争对手的情况下最大化市场份额。这种方法考虑了进入市场的时机和模型更新的时机，对市场的稳定性和均衡状态具有积极影响。", "conclusion": "通过不同领域的验证，展示了方法的有效性，并强调了进入市场的时机和模型更新的重要性，表明市场可以保持稳定并迅速达到平衡状态。这种方法对电信提供商和消费者都产生了积极影响。"}
{"llm_update_time": "20250816", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2503.19530", "html_url": "https://arxiv.org/abs/2503.19530", "title": "VectorFit : 适应性奇异与偏置向量微调的预训练基础模型", "title_en": "VectorFit : Adaptive Singular & Bias Vector Fine-Tuning of Pre-trained Foundation Models", "authors": "Suhas G Hegde,Shilpy Kaur,Aruna Tiwari", "background": "流行的参数高效微调（PEFT）方法通过在冻结的预训练权重W旁边参数化新的低秩或稀疏可训练权重，以减少可训练参数的数量，从而进行微调。然而，这些新参数是从零开始训练的，与完全微调相比，在低预算设置中存在性能差距。", "innovation": "VectorFit介绍了一种新的参数化方法，通过自适应地训练W中嵌入的知识的奇异向量和偏差，高效利用现有知识。这种利用W的结构和转换属性的方法可以产生类似于完全微调的高秩增量权重矩阵ΔW。与领先的方法相比，VectorFit仅使用9倍更少的可训练参数即可达到更好的结果。", "conclusion": "通过对涵盖自然语言理解和生成、问答、图像分类和图像生成等广泛语言和视觉任务的19个数据集进行全面实验，结果表明，VectorFit在参数效率下的性能超过了基线。"}
{"llm_update_time": "20250816", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2502.20012", "html_url": "https://arxiv.org/abs/2502.20012", "title": "学习生成市场类", "title_en": "Learning Classifiers That Induce Markets", "authors": "Yonatan Sommer,Ivri Hikri,Lotan Amit,Nir Rosenfeld", "background": "在利用学习来为人类决策提供信息时，如贷款、招聘或入学等情况下，用户可能会为获得积极的预测而有动力地调整自己的特征。传统的假设是，用于计算成本的函数是外生的、固定且预先确定的。本文挑战了这一假设，提出了在部署分类器时相关成本可能会出现的新观点。", "innovation": "提出了战略分类框架的扩展，使其能够支持分类器诱导特征市场的概念。研究了学习任务在分类器可以引发特征市场的情况下进行的学习场景。分析了该学习任务，开发了计算市场价格的算法，提出了一种可微学习框架，并进行了实验以探索这一新的学习环境和方法。", "conclusion": "通过理论分析、算法设计和实验验证，证明了在学习任务中分类器可以诱导形成特征市场的可能性，并展示了新的学习框架的有效性及对该领域的贡献。"}
{"llm_update_time": "20250816", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2502.08644", "html_url": "https://arxiv.org/abs/2502.08644", "title": "基于生物灵感的神经网络零样本自适应学习振荡共享", "title_en": "Rhythmic sharing: A bio-inspired paradigm for zero-shot adaptive learning in neural networks", "authors": "Hoony Kang,Wolfgang Losert", "background": "人类大脑能够快速适应新环境并在有限数据中学习，这是现有AI算法难以复制的能力。研究人员借鉴了神经细胞的机械振荡模式，开发了一种利用连接强度振荡的学习范式，通过协调这些振荡进行学习，从而使网络能够迅速感知并适应细微环境变化，无需监督。这种无监督适应能力使得网络具有广泛的应用潜力，能够预测多种环境下的动态，甚至包括未见过的环境。", "innovation": "该研究开发了一种新的学习范式——Rhythmic sharing（振荡共享），该范式基于生物感知机制，利用连接强度的振荡来促进学习和适应。这一范式具有以下创新点：1) 通过连接强度的快速协调变化，网络能够在没有监督的情况下感知和适应环境变化；2) 该模型能够作为通用的AI架构，预测多种上下文环境下的动态，包括未见过的环境；3) 模型设计具有灵活性，可应用于多种神经网络架构，为快速适应学习引入到领先的人工智能模型中提供可能", "conclusion": "此振荡共享范式为新型认知模型的研发提供了强大的起点，由于该范式对特定神经网络的具体细节无特定假设，因此它为快速适应学习的引入和整合到现代AI模型中提供了新的方向。"}
{"llm_update_time": "20250816", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2503.10509", "html_url": "https://arxiv.org/abs/2503.10509", "title": "从动作到文字：强化学习中迈向抽象性文本策略总结", "title_en": "From Actions to Words: Towards Abstractive-Textual Policy Summarization in RL", "authors": "Sahar Admoni,Assaf Hallak,Yftah Ziser,Omer Ben-Porat,Ofra Amir", "background": "在使用强化学习（RL）算法生成的策略难以向用户解释的情况下，用户对复杂奖励结构和神经网络表示的交互产生不信任，导致分析和预测智能体行为变得困难。目前，通过视频展示部分世界状态下的智能体行为来进行全局策略总结的方法限制了用户的理解能力，并且无法将原始行为整合成易于理解的模式。", "innovation": "提出了SySLLM（基于大型语言模型生成的综合化文本策略总结），这是一种新的抽象性文本策略解析范式。通过利用具有广泛世界知识和模式合成能力的大型语言模型（LLMs），SySLLM生成能够在结构上和易理解性上提供策略解释的文本摘要。此外，SySLLM能够在零样本设置中解释空间化、时间化的状态-动作轨迹描述，无需任何先验知识或微调。实验结果表明，SySLLM能够捕获关键洞察，如目标偏好和探索策略，这些洞察也得到了人类专家的认同。", "conclusion": "在大规模用户研究中，SySLLM摘要被绝大多数参与者（75.5%）更偏好于基于演示的摘要，显示出其在增强智能体策略可解释性的有效性和用户体验中的显著优势。"}
{"llm_update_time": "20250816", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2502.01669", "html_url": "https://arxiv.org/abs/2502.01669", "title": "基于影响函数的延迟反馈建模", "title_en": "Delayed Feedback Modeling with Influence Functions", "authors": "Chenlu Ding,Jiancan Wu,Yancheng Yuan,Cunchun Li,Xiang Wang,Dingxian Wang,Frank Yang,Andrew Rabinovich", "background": "在按转化次数付费（CPA）模式下的在线广告中，准确的转化率（CVR）预测至关重要。主要挑战是延迟反馈，即转化可能在用户互动后很久才发生，导致近期数据不完整，模型训练偏差。现有解决方案虽部分解决了这一问题，但通常依赖辅助模型，导致计算效率低下且不太能适应用户兴趣的变化。因此，设计了一种能够有效地利用新到达和延迟的转化对模型参数影响的模型，以便高效更新模型而不需要全面重训，同时保持高的计算效率和效果。", "innovation": "提出了一种名为IF-DFM的模型，利用影响函数对新到达和延迟的转化对模型参数的影响进行估计，实现高效更新而无需全面重训。通过将逆海森essian向量乘积重新表述为优化问题，IF-DFM在计算效率和效果之间取得了良好的平衡。实验证明，IF-DFM在准确性和适应性方面均优于先前方法。", "conclusion": "IF-DFM模型通过利用影响函数来估计新到达和延迟转化对模型参数的影响，实现了高效更新而不需全面重训。相比现有方法，IF-DFM在准确性和适应性方面表现出色，有效地解决了延迟反馈带来的挑战。"}
{"llm_update_time": "20250816", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2504.05059", "html_url": "https://arxiv.org/abs/2504.05059", "title": "MIAT: Maneuver-Intentions-Aware Transformer for Spatio-Temporal Trajectory Prediction", "title_en": "MIAT: Maneuver-Intention-Aware Transformer for Spatio-Temporal Trajectory Prediction", "authors": "Chandra Raskoti,Iftekharul Islam,Xuan Wang,Weizi Li", "background": "准确的车辆轨迹预测对于自动驾驶的安全和效率至关重要，尤其是在混合交通环境中，自动驾驶车辆和人工驾驶车辆共存时尤为关键。然而，由于加速、减速、左转和右转等固有的驾驶行为带来的不确定性，给可靠的轨迹预测带来了巨大挑战。", "innovation": "本文提出了一种‘Maneuver-Intention-Aware Transformer（MIAT）’架构，该架构结合了机动意图感知控制机制与时空交互建模，以增强长期轨迹预测。通过系统地研究机动意图感知程度对短期和长期轨迹预测的影响，MIAT在现实世界NGSIM数据集上的实测结果表明，相对于其他意图感知的基准方法，其短期轨迹预测提高了4.7%，长期轨迹预测提高了1.6%，并实现了11.1%的长周期预测性能提升。", "conclusion": "通过利用意图感知控制机制，MIAT在长期轨迹预测中实现了性能提升，虽然短期预测性能有轻微的下降。研究结果表明，MIAT在自动驾驶车辆的轨迹预测中具有显著的优势。"}
{"llm_update_time": "20250816", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2504.17493", "html_url": "https://arxiv.org/abs/2504.17493", "title": "目标导向的时间序列预测：基础框架设计", "title_en": "Goal-Oriented Time-Series Forecasting: Foundation Framework Design", "authors": "Luca-Andrei Fechete,Mohamed Sana,Fadhel Ayed,Nicola Piovesan,Wenjie Li,Antonio De Domenico,Tareq Si Salem", "background": "传统的时间序列预测方法通常旨在最小化总体预测误差，但没有考虑到不同下游应用在不同预测范围的重要性差异。现有的方法往往需要预定义预测范围，但这些方法缺乏在不重新训练的情况下，使预测模型根据应用特定的区域动态调整其重点的能力。", "innovation": "该研究提出了一种训练方法，使预测模型能够在推理时自适应地聚焦于特定的应用区域，而无需重新训练。该方法在训练过程中将预测空间细分为多个细粒度的段，并动态重新加权和聚合这些段，以突出应用指定的目标范围。与之前的方法不同，该框架支持灵活的、按需调整。", "conclusion": "在标准基准和新收集的无线通信数据集上的实验表明，该方法不仅在感兴趣的区域内提高了预测精度，还在下游任务性能上取得了可量化的改进。这些结果突显了预测建模与决策过程在现实世界系统中更紧密整合的潜力。"}
{"llm_update_time": "20250816", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2505.03810", "html_url": "https://arxiv.org/abs/2505.03810", "title": "分组序排列旋转：无代价优化量化中的旋转变换", "title_en": "Grouped Sequency-arranged Rotation: Optimizing Rotation Transformation for Quantization for Free", "authors": "Euntae Choi,Sumin Song,Woosang Lim,Sungjoo Yoo", "background": "大型语言模型（LLMs）的部署面临高计算成本的挑战，尽管后训练量化的（PTQ）方法提供了解决方案，但现有的基于旋转的方法在极低位宽如2位时效果不佳。这些方法无法有效减少量化误差，尤其是在高精度要求下表现欠佳。", "innovation": "本文提出了一种无需训练的方法来构造改进的旋转矩阵，针对现有方法在极低位宽下的不足。主要创新包括利用沃尔什-哈达玛变换结合序列排序，将相似频率成分聚类，以减少量化误差，并通过分组序排列旋转（GSR）使用块对角矩阵来隔离异常值影响，从而在无需训练的情况下达到与基于优化方法相当的效果。", "conclusion": "实验结果表明，本文方法在推理任务和WikiText-2的困惑度（PPL）评分方面表现良好，即使在现有学习旋转技术的基础上应用也能进一步提高结果。"}
{"llm_update_time": "20250816", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.00962", "html_url": "https://arxiv.org/abs/2506.00962", "title": "具有随机时间范围的强化学习", "title_en": "Reinforcement Learning with Random Time Horizons", "authors": "Enric Ribera Borrell,Lorenz Richter,Christof Schütte", "background": "传统的强化学习框架假设轨迹的运行时间和范围通常是固定的或无限的，但许多实际应用场景中，运行时间是随机的，且可能依赖于轨迹的状态。这种随机性对政策梯度公式产生了影响，但相关研究较少。", "innovation": "该研究首次严格推导出在随机时间范围下适用于随机政策和确定性政策的政策梯度公式。研究从轨迹或状态空间的角度提供了两种互补的视角，并建立了与最优控制理论的联系。", "conclusion": "数值实验表明，使用提出的公式可以显著提高优化收敛速度，相比传统方法有一定的优势。"}
{"llm_update_time": "20250816", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.01016", "html_url": "https://arxiv.org/abs/2506.01016", "title": "乐观的评论者可以使小型演员更有能力", "title_en": "Optimistic critics can empower small actors", "authors": "Olya Mastikhina,Dhruv Sreenivas,Pablo Samuel Castro", "background": "演员-评论者方法一直是深度强化学习中许多最近进步的核心。传统的做法是使用对称架构，即演员和评论者具有相同的网络拓扑结构和参数数量。然而，最近的研究表明，使用较小的演员和非对称架构可能具有优势。", "innovation": "本文进行了广泛的实证研究和分析，发现使用较小的演员会导致性能下降和评论者过度拟合。研究还探讨了缓解观察到的价值低估的技术，这为非对称演员-评论者方法的研究提供了新的方向。", "conclusion": "评论者可能导致数据收集不足，由于价值低估，这是这种行为的主要原因。这进一步强调了评论者在缓解这种病症方面的重要作用。研究探索了缓解观察到的价值低估的技术，从而促进了非对称演员-评论者方法的研究。"}
{"llm_update_time": "20250816", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2505.07503", "html_url": "https://arxiv.org/abs/2505.07503", "title": "通过变分贝叶斯压缩识别因果方向", "title_en": "Identifying Causal Direction via Variational Bayesian Compression", "authors": "Quang-Duy Tran,Bao Duong,Phuoc Nguyen,Thin Nguyen", "background": "在仅使用观察数据的情况下区分两个随机变量之间的因果关系是科学领域中的一个具有挑战性的问题。这一任务中使用的关键原理是算法马尔可夫条件，即根据因果方向进行联合分布的分解比反向因果方向具有更简洁的码长。先前的方法通过使用简单函数或高斯过程（GPs）来近似这些码长，但在模型拟合度和计算复杂性之间做出了妥协。", "innovation": "该研究提出利用神经网络的变分贝叶斯学习来解释码长，从而在提高模型拟合度的同时保持码长的简洁性，避免了基于GPs方法的巨大计算复杂性。实验表明，该方法在合成和真实世界基准测试中对因果识别的有效性，且在多个数据集上表现出比其他多数方法更好的性能提升。", "conclusion": "通过变分贝叶斯压缩识别因果方向的方法，在提高模型拟合度和保持码长简洁性的同时，有效解决了计算复杂性问题，展示了在多个数据集中的有效性，提供了对现有相关方法的改进。"}
{"llm_update_time": "20250816", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.11049", "html_url": "https://arxiv.org/abs/2506.11049", "title": "15,500秒：使用EfficientNet和轻量级微调的精益UAV分类", "title_en": "15,500 Seconds: Lean UAV Classification Using EfficientNet and Lightweight Fine-Tuning", "authors": "Andrew P. Berg,Qian Zhang,Mia Y. Wang", "background": "随着无人机（UAV）在消费和军事应用中日益普及，对特定于模态的分类系统的可靠性需求变得越来越迫切。本研究聚焦于无人机音频分类中的数据稀缺问题，通过集成预训练深度学习模型、参数效率微调（PEFT）策略和靶向数据增强技术来应对这一挑战。", "innovation": "本文通过使用一种包含31种不同类型的3,100个无人机音频片段的自定义数据集，评估了基于变换器和卷积神经网络（CNN）架构在不同微调配置下的性能，使用五折交叉验证进行实验，评估了准确率、训练效率和鲁棒性。实验结果显示，使用EFNet-B0模型全量微调并结合三项增强技术达到了最高的验证准确率（95.95%），这优于定制的CNN模型和类似AST的基于变换器的模型。这些发现表明，结合轻量级架构、PEFT和适当的增强技术可以为有限数据集的无人机音频分类提供有效策略。", "conclusion": "本研究提出了将轻量级架构与参数效率微调和精心选择的数据增强技术结合的方法，有效解决了无人机音频分类中的数据稀缺问题。未来的研究方向将扩展到多模态无人机分类，利用视觉和雷达遥测数据。"}
{"llm_update_time": "20250816", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2505.13109", "html_url": "https://arxiv.org/abs/2505.13109", "title": "FreeKV：提高KV缓存检索以实现高效LLM推理", "title_en": "FreeKV: Boosting KV Cache Retrieval for Efficient LLM Inference", "authors": "Guangda Liu,Chengwei Li,Zhenyu Ning,Minyi Guo,Jieru Zhao", "background": "大规模语言模型（LLMs）由于应用需求的增长，正在迅速扩展其上下文窗口。然而，长上下文带来了部署挑战，主要由于KV缓存的大小随着上下文长度线性增长。虽然已经提出了KV缓存压缩方法来解决这一问题，但KV丢弃方法会导致重大准确率损失，而KV检索方法则面临显著的效率瓶颈。现有方法难以平衡检索速度与准确性的关系，难以有效满足不断增长的上下文需求.", "innovation": "FreeKV是一种算法-系统协同优化框架，旨在提高KV检索效率同时保持准确性。FreeKV通过引入预测检索，将KV选择和回忆过程移出关键路径，并结合细粒度校正来确保准确性。在系统方面，FreeKV采用CPU和GPU内存混合布局来消除碎片化数据传输，并利用双缓冲流式检索进一步提高效率。实验表明，FreeKV在各种场景和模型中实现了接近无损的准确率，相比现有最佳KV检索方法，提供了高达13倍的加速效果.", "conclusion": "FreeKV实现了KV缓存检索效率和准确性的最佳平衡。该框架通过优化检索过程及系统布局显著提高了LLM推理的效率，同时保持了高准确率。这为长上下文语言模型的高效部署提供了一种新方法."}
{"llm_update_time": "20250816", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.13061", "html_url": "https://arxiv.org/abs/2506.13061", "title": "高阶ODE求解器在扩散概率模型中的快速收敛", "title_en": "Fast Convergence for High-Order ODE Solvers in Diffusion Probabilistic Models", "authors": "Daniel Zhengyu Huang,Jiaoyang Huang,Zhengjiang Lin", "background": "扩散概率模型通过学习反向反转噪声注入过程来生成样本，该过程将数据转换为噪声。关键的进展是，将反向采样过程重新表述为确定性的概率流常微分方程（ODE），这使得能够使用高阶数值求解器高效地进行采样。现有的时间积分分析侧重于数值积分误差，而这种采样程序的准确性还取决于所学习的得分函数的逼近质量和正则性，以及它们的相互作用。", "innovation": "本文提出了针对具有任意方差计划的通用前向过程，从概率流ODE导出的确定性采样器的严格收敛分析。特别地，开发并分析了$P$-阶（指数）龙格-库塔方案，假设所学习得分函数的一阶和二阶导数是有界的。证明生成分布与目标分布之间的总变差距离可被限制为 \begin{align*}O\bigl(d^{\frac{7}{4}} \text{score error}^{\frac{1}{2}} +d(dH_{\text{max}})^p\bigr), \\\\ \text{其中} \text{score error}^2 \text{表示得分函数逼近的} L^2 \text{错误，} d \text{是数据维度，} H_{\text{max}} \text{表示最大求解器步长。}\\end{align*} 此外，基准数据集上的数值实验进一步证实了所学习得分函数的实际导数是有界的。", "conclusion": "本文证明了生成分布与目标分布之间的距离可以通过给定的公式来控制。这种高阶ODE求解器对于扩散概率模型中的快速收敛提供了理论支持，并且实验证明在实际应用中得分函数的导数是受到控制的。"}
{"llm_update_time": "20250816", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.15397", "html_url": "https://arxiv.org/abs/2507.15397", "title": "使用降噪器的MAP估计：收敛率与保证", "title_en": "MAP Estimation with Denoisers: Convergence Rates and Guarantees", "authors": "Scott Pesme,Giacomo Meanti,Michael Arbel,Julien Mairal", "background": "降噪模型已经成为了解决逆问题的强大工具，能够利用预训练网络逼近平滑先验分布的分数。这些模型通常用于求解最大后验概率（MAP）优化问题的启发式迭代方案中，其中先验的负对数的邻近算子扮演关键角色。实际上，这个算子是难以计算的，实践者们常常用预训练的降噪器作为替代，尽管缺乏广泛的理论依据支持这一替代。", "innovation": "该研究展示了在先验$ p $具有对数凹性假设的情况下，一种与实践中使用的算法相关且简单的算法能够收敛到相邻算子。研究将该算法解释为平滑相邻目标的梯度下降。因此，研究为一类以前是启发式的有效方法提供了理论基础。", "conclusion": "该研究提供的分析为使用预训练降噪器的MAP估计方法提供了理论保证，解释了这些方法为什么在实践中是成功的。"}
{"llm_update_time": "20250816", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.11170", "html_url": "https://arxiv.org/abs/2506.11170", "title": "PromptTSS：基于提示的方法实现交互式多粒度时间序列分割", "title_en": "PromptTSS: A Prompting-Based Approach for Interactive Multi-Granularity Time Series Segmentation", "authors": "Ching Chang,Ming-Chih Lo,Wen-Chih Peng,Tien-Fu Chen", "background": "多变量时间序列数据在制造和可穿戴技术等领域被广泛收集。这类数据在不同粒度级别上展现出不同的状态，如粗粒度系统行为到细粒度详细事件。对不同粒度状态的有效分割和集成对于预测维护和性能优化等任务至关重要。然而，现有的时间序列分割方法存在两个关键挑战：（1）难以在统一模型中处理不同粒度级别；（2）适应动态环境中未见过的新模式的能力有限。", "innovation": "本文提出了一种名为PromptTSS的新型多粒度状态时间序列分割框架。该框架结合了一个带有提示机制的统一模型，并利用标签和边界信息引导分割过程，以捕捉粗粒度和细粒度模式，并可动态适应未见过的新模式。实验结果显示，相较于现有的方法，PromptTSS在多粒度分割上的准确率提升了24.49%，在单一粒度分割上的准确率提升了17.88%，在迁移学习中的提升高达599.24%，彰显了其在层次化状态和演变时间序列动力学方面的适应性。", "conclusion": "通过使用统一模型和提示机制，PromptTSS显著提升了多粒度时间序列数据的分割性能。实验结果表明，它不仅在准确率方面有显著提高，而且特别适用于动态环境中的模式变化。"}
{"llm_update_time": "20250816", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.19343", "html_url": "https://arxiv.org/abs/2506.19343", "title": "Discrepancy-Aware Graph Mask Auto-Encoder", "title_en": "Discrepancy-Aware Graph Mask Auto-Encoder", "authors": "Ziyu Zheng,Yaming Yang,Ziyu Guan,Wei Zhao,Weigang Lu", "background": "现有的图自监督训练方法通常依赖节点上下文信息来恢复被掩蔽的信息，但它们在异类图中表现不佳，因为它们主要关注捕捉节点邻域信息，而忽略了不同节点之间的差异信息，导致节点表示难以区分。因此，需要一种能够更好地处理节点间差异性的新方法来提高图表示学习的效果。", "innovation": "为了应对这一问题，本文提出了一个感知差异的图掩码自编码器（Discrepancy-Aware Graph Mask Auto-Encoder，简称DGMAE）。该方法在掩码过程中通过重构邻近节点的差异信息来获得更具差异性的节点表示，从而更好地处理节点间的差异性。通过在17个广泛使用的基准数据集上进行的实验表明，DGMAE能够在低维空间中有效保留节点的差异性和显著优于现有的图自监督学习方法，适用于节点分类、节点聚类和图分类等三种图分析任务。", "conclusion": "实验结果显示，我们的DGMAE能够有效保留节点在低维度空间中的差异性，并在节点分类、节点聚类和图分类等图分析任务上显著超越现有的图自监督学习方法，表明其具有显著的优势。"}
{"llm_update_time": "20250816", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.06535", "html_url": "https://arxiv.org/abs/2507.06535", "title": "AMS电路中通过图对比学习和标签重平衡实现可迁移的寄生参数估计", "title_en": "Transferable Parasitic Estimation via Graph Contrastive Learning and Label Rebalancing in AMS Circuits", "authors": "Shan Shen,Shenglu Hua,Jiajun Zou,Jiawei Liu,Jianwang Zhai,Chuan Shi,Wenjian Yu", "background": "在模拟-混合信号（AMS）电路中，图表示学习对于诸如寄生参数估计等下游任务至关重要。然而，设计数据的稀缺性、标签分布的不平衡以及电路实现的固有差异性，给学习健壮且可迁移的电路表示带来了显著挑战。", "innovation": "我们提出了一种名为CircuitGCL的新颖图对比学习框架，该框架整合了表示散射和标签重平衡，以增强异构电路图之间的可迁移性。CircuitGCL利用自监督策略通过超球面表示散射学习拓扑不变的节点嵌入，避免对大规模数据的依赖。同时，引入平衡均方误差（BMSE）和平衡softmax交叉熵（BSCE）损失，以缓解电路间标签分布的差异性，从而实现稳健且可迁移的寄生估计。", "conclusion": "CircuitGCL在TSMC 28nm AMS设计中对寄生电容估计（边级任务）和地电容分类（节点级任务）进行了评估，表明该方法优于所有当前最先进的（SOTA）方法，边回归的$R^2$提升范围为33.64%至44.20%，节点分类的F1分数增益范围为0.9至2.1倍。"}
{"llm_update_time": "20250816", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.03682", "html_url": "https://arxiv.org/abs/2508.03682", "title": "自我提问语言模型", "title_en": "Self-Questioning Language Models", "authors": "Lili Chen,Mihir Prabhudesai,Katerina Fragkiadaki,Hao Liu,Deepak Pathak", "background": "该研究探讨了大型语言模型是否能够在没有外部数据的情况下通过自我生成问题和答案来改善其推理能力。作者假设，一个预训练的语言模型，在仅给定一个主题提示（例如代数文字问题）的情况下，可以让模型自我生成问题，并通过自我互答来提升自身能力。", "innovation": "提出了一种不对称自我博弈框架——“生成者-解答者”架构（Self-Questioning Language Models，SQLM），其中生成者根据给定的主题生成问题，解答者尝试作答。生成者和解答者都通过强化学习进行训练。生成者根据问题的难易程度获得奖励，而解答者则通过众数投票获得奖励作为正确性的代理指标。对于编程问题，生成者可以生成单元测试以进行验证。该研究在三个基准上进行了测试：三位数乘法、OMEGA基准中的代数问题和Codeforces中的编程问题。", "conclusion": "通过不断生成更有趣的问题并尝试解决它们，语言模型可以在没有访问任何精心策划的训练数据集的情况下提高其在下游基准测试中的表现。"}
{"llm_update_time": "20250816", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.15727", "html_url": "https://arxiv.org/abs/2507.15727", "title": "多代理滑雪租赁问题的竞争算法", "title_en": "Competitive Algorithms for Multi-Agent Ski-Rental Problems", "authors": "Xuchuang Wang,Bo Sun,Hedyeh Beyhaghi,John C.S. Lui,Mohammad Hajiesmaili,Adam Wierman", "background": "本文探讨了一个新颖的多代理滑雪租赁问题，将经典的滑雪租赁困境扩展到了一个涉及多个代理的场景，每个代理都需要面对个人和共享成本。在此模型中，每个代理可以选择每日固定费用租用滑雪设备，或一次性购买个人滑雪通行证，还可以选择一种由所有代理共同享受折扣的团体通行证。我们考虑了代理活跃天数不同的情况，导致动态状态下代理会退出决策过程。因此，我们需要从多个视角来解决这一问题，并定义了整体、状态依赖性和个体理性三种不同的竞争优势度量标准。", "innovation": "本文为多代理滑雪租赁问题设计并分析了最优确定性和随机性策略。确定性策略采用了状态感知阈值函数，随机性策略从定制的状态感知分布中抽样和重新抽样阈值。研究结果表明，对称策略（所有代理使用相同的阈值）优于非对称策略。本文的结果不仅提供了竞争优势的上界和下界，还扩展了经典的滑雪租赁洞见到多代理环境，突显了不确定性条件下多代理决策的理论和实际意义。", "conclusion": "本文的研究提供了多代理环境下的滑雪租赁竞争优势的理论基础和实际应用，对于理解多代理环境下动态决策过程具有重要贡献。"}
{"llm_update_time": "20250816", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.10904", "html_url": "https://arxiv.org/abs/2507.10904", "title": "按类比例的核心集选择用于难度可分离的数据", "title_en": "Class-Proportional Coreset Selection for Difficulty-Separable Data", "authors": "Elisa Tsai,Haizhong Zheng,Atul Prakash", "background": "高质量的训练数据是构建可靠和高效的机器学习系统的关键。现有的一次性核心集选择方法通过在保持或改善模型性能的同时裁剪数据集，采用了基于训练动态的数据难度评分。尽管这些方法假设数据难度在类间是一致的，但对于网络入侵检测和医学成像等领域的数据而言，这种假设并不总是成立，存在着类间数据难度的变化。现有方法忽略了这一点，直接采用了类无关的核心集选择策略，这些策略倾向于过度代表易出现的多数类并忽略稀有的但具有信息价值的少数类。该研究背景指出现有方法存在的上述缺陷，并提出一种新的方法来解决这个问题，特别是当数据存在类间难度分离特性时。", "innovation": "该研究提出了一个新的概念，即类难度可分离性，将其形式化为类难度分离系数（CDSC），并提出一种按类比例的核心集选择方法来反映这一特性。研究团队还开发了多个基于类比例的采样策略变体，这些方法在跨越信息安全和医学等不同领域的五个数据集上表现出色，特别是在极端数据裁剪率下仍能保持较高的性能，同时证明了在噪声、不平衡和大规模数据集上进行激进剪枝可以提高模型的泛化能力。研究结果表明，明确定义类难度分离性有助于更有效、更稳健和更通用的数据剪枝，特别是在高风险场景下。", "conclusion": "研究提出的方法在五个不同领域的数据集上表现出卓越的性能，特别是在高度精简数据集的情况下，仍能保持较高的准确度、精确度和召回率。与无类意识的核心集选择基线方法相比，即使在极端的99%精简率下，类比例变体方法也表现出显著的稳定性。进一步研究还表明，在噪声大、样本不均衡和大型数据集上进行激进的剪枝可以提高模型的泛化能力。"}
{"llm_update_time": "20250816", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.06800", "html_url": "https://arxiv.org/abs/2508.06800", "title": "硬度感知动态课程学习方法在具有缺失模态的鲁棒多模态情绪识别中的应用", "title_en": "Hardness-Aware Dynamic Curriculum Learning for Robust Multimodal Emotion Recognition with Missing Modalities", "authors": "Rui Liu,Haolin Zuo,Zheng Lian,Hongyu Yuan,Qi Fan", "background": "最近，缺失模态在多模态情绪识别（MER）中已成为一个关键的研究方向。传统的解决方法通常通过缺失模态重构来应对这一问题，然而这些方法没有考虑到不同样本的重建难度差异，从而限制了模型处理困难样本的能力。", "innovation": "我们提出了一个名为HARDY-MER的新型硬度感知动态课程学习框架，它包含两个关键阶段：首先是估计每个样本的硬度，其次是根据硬度动态调整训练过程，特别强调困难样本以提高模型在这些具有挑战性实例上的表现。具体而言，引入了多视角难度评估机制，考虑直接硬度（模态重构误差）和间接硬度（跨模态互信息），并引入了基于检索的动态课程学习策略，通过检索具有相似语义信息的样本并平衡易样本与困难样本的学习重点来动态调整训练课程。", "conclusion": "在基准数据集上的广泛实验表明，HARDY-MER在缺失模态场景下始终优于现有方法。我们的代码将在此网址公开：this https URL。"}
{"llm_update_time": "20250816", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.07697", "html_url": "https://arxiv.org/abs/2508.07697", "title": "利用大型语言模型进行语义增强的时间序列预测", "title_en": "Semantic-Enhanced Time-Series Forecasting via Large Language Models", "authors": "Hao Liu,Chun Yang,Zhang xiaoxing,Xiaobin Zhu", "background": "时间序列预测在金融、能源、气象和物联网应用中扮演着重要角色。近年来的研究利用了大型语言模型（LLMs）的一般化能力来适应时间序列预测，取得了令人鼓舞的成效。然而，现有研究主要集中在文本标记级别的模式对齐，而未能弥合语言知识结构与时间序列数据模式之间的内在模态差距，极大地限制了语义表示。", "innovation": "本文提出了一种新颖的语义增强大型语言模型（SE-LLM），通过探索时间序列的内在周期性和异常特性，将其嵌入到语义空间中以增强标记嵌入。此外，本文在自注意力机制中嵌入了一个插件模块，以建模长短期依赖关系，从而有效适应时间序列分析。同时，该方法在保持LSTM冻结的情况下减少了序列维度，大幅降低了计算消耗。", "conclusion": "实验表明，与最先进的方法相比，本文提出的SE-LLM在时间序列预测任务中表现出更好的性能。"}
{"llm_update_time": "20250816", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.05612", "html_url": "https://arxiv.org/abs/2508.05612", "title": "Shuffle-R1: 数据为中心的动态洗牌以提高多模态大型语言模型的高效强化学习框架", "title_en": "Shuffle-R1: Efficient RL framework for Multimodal Large Language Models via Data-centric Dynamic Shuffle", "authors": "Linghao Zhu,Yiran Guan,Dingkang Liang,Jianzhong Ju,Zhenbo Luo,Bin Qin,Jian Luan,Yuliang Liu,Xiang Bai", "background": "强化学习（RL）已成为提升多模态大型语言模型（MLLM）推理能力的有效后训练范式。然而，当前的RL管道由于两种未被充分探索的问题而面临训练效率低下：优势塌陷，即大多数批次中的优势集中在零附近；以及回放静默，即随着时间推移，贡献非零梯度的回放比例减少。这些问题导致梯度更新不理想，妨碍了长期学习效率。研究背景主要围绕这些挑战展开，强调了提升数据集中心化调整在增强长期学习效率方面的必要性。", "innovation": "提出了一种简单且合理的框架Shuffle-R1，通过动态重结构轨迹采样和批次，提升RL微调效率。该框架包括两部分：1）两两轨迹采样，选择具有大优势的高对比轨迹以提高梯度信号质量；2）基于优势的轨迹洗牌，通过有意识地重新整理批次增加有价值回放的曝光度。实验结果显示，该框架在多个推理基准测试中均优于强的RL基线，且几乎没有附加开销。这些结果突显了数据调整对于提高MLLM的RL训练效率的重要性。", "conclusion": "实验表明，Shuffle-R1框架在多个推理基准测试中表现优异，优于强大的RL基线模型，且几乎没有任何附加开销。这些结果突显了数据调整对于强化学习训练效率提升的重要性。Shuffle-R1在多模态大型语言模型中实现了高效的RL微调，填补了现有RL模型在数据处理方面的不足。"}
{"llm_update_time": "20250816", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2504.14188", "html_url": "https://arxiv.org/abs/2504.14188", "title": "重思以客户端为中心的联邦图学习", "title_en": "Rethinking Client-oriented Federated Graph Learning", "authors": "Zekai Chen,Xunkai Li,Yinlin Zhu,Rong-Hua Li,Guoren Wang", "background": "联邦图学习（FGL）作为一种新的分布式图学习范式，能够在本地系统间协作进行模型训练的同时保护数据隐私。现有方法主要分为两类：一类是服务器-客户端（S-C）模式，客户端上传本地模型参数到服务器端进行聚合和全局更新；另一类是客户端-客户端（C-C）模式，直接在客户端之间交换信息且允许定制本地训练过程。", "innovation": "考虑到客户端-客户端（C-C）模式具有更加精细的通信结构，但现有方法中仍存在节点表示冗余的问题，引发高通信成本和隐私风险。为解决此问题，作者提出了一种名为FedC4的新方法。FedC4将图凝缩技术与C-C合作优化相结合，具体来说，它利用图凝缩技术将每个客户端图的知识精简为少量合成嵌入，而不是传输节点级的知识。此外，FedC4还引入了三个新的模块，允许源客户端根据目标客户端的图属性发送定制化的节点表示。实验结果表明，FedC4在任务性能和通信成本上均优于最先进的基准方法。", "conclusion": "实验基于八个公开的真实世界数据集进行，结果显示FedC4在任务性能和通信成本上都优于最先进的基准方法。研究指出，通过图凝缩与C-C合作优化，能有效减少冗余节点表示并降低通信成本和隐私风险。"}
{"llm_update_time": "20250816", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.08052", "html_url": "https://arxiv.org/abs/2508.08052", "title": "理解连续学习中模型容量的动态机制", "title_en": "On Understanding of the Dynamics of Model Capacity in Continual Learning", "authors": "Supriyo Chakraborty,Krishnan Raghavan", "background": "连续学习（CL）中，神经网络（NN）的能力及其在表示任务方面的容量与稳定性-可塑性困境密切相关。这种困境构成了CL中一个基本的挑战。", "innovation": "引入了有效模型容量（CLEMC）概念，用来描述稳定性-可塑性平衡点的动态行为。通过发展差分方程来建模NN、任务数据和优化过程之间的相互作用，并用CLEMC证明有效容量和稳定性-可塑性平衡点本质上是不稳定的。实验结果显示，无论NN架构或优化方法如何，当新任务数据分布不同于之前的数据时，NN表示新任务的能力都会下降。", "conclusion": "CL中，模型容量有效性和稳定性-可塑性平衡点是动态变化的，不受NN架构或优化方法的影响，当任务数据分布变化时，NN表示新任务的能力会下降。"}
{"llm_update_time": "20250816", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.07970", "html_url": "https://arxiv.org/abs/2508.07970", "title": "WeChat-YATT: 一种简单、可扩展且平衡的RLHF训练器", "title_en": "WeChat-YATT: A Simple, Scalable and Balanced RLHF Trainer", "authors": "Junyu Wu,Weiming Chang,Xiaotao Liu,Guanyou He,Tingfeng Xian,Haoqiang Hong,Boqi Chen,Haotao Tian,Tao Yang,Yunsheng Shi,Feng Lin,Ting Yao", "background": "RLHF (强化学习从人类反馈) 已成为训练大规模语言模型和多模态系统的一个重要范式。尽管现有RLHF训练框架取得了显著进展，但仍面临大规模多模态工作流扩展和动态工作负载适应的挑战。现有系统在管理和调度大规模模型时遇到控制器可扩展性的限制，在复杂的RLHF管道中存在效率低下等问题，特别是在需要动态采样和资源分配的场景中。", "innovation": "WeChat-YATT 是一种新的框架，旨在解决上述挑战。它提出了并行控制器编程模型来有效组织复杂的RLHF工作流程，减少中心控制器架构瓶颈，提高大规模数据场景中的可扩展性。此外，WeChat-YATT 提出了动态资源放置方案，以适配性地划分计算资源并调度工作负载，减少硬件闲置时间并提高 GPU 利用率，适应多变的训练条件。", "conclusion": "WeChat-YATT 在多个实验场景中实现了比现有的先进RLHF训练框架更高的吞吐量。它已成功应用于通过WeChat产品功能训练大规模用户基础的模型，证明其在实际场景中的有效性和高可靠性。"}
{"llm_update_time": "20250816", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.06412", "html_url": "https://arxiv.org/abs/2508.06412", "title": "Reset Replay方法实现高效样例优化的大语言模型", "title_en": "Sample-efficient LLM Optimization with Reset Replay", "authors": "Zichuan Liu,Jinyu Wang,Lei Song,Jiang Bian", "background": "最近，通过强化学习（RL）和偏好优化方法对大语言模型（LLMs）进行训练取得了显著进展，但仍存在低样本效率和优先效应偏见等问题，这些问题会导致模型过拟合初始经验并损害学习过程。为了克服这些挑战，该研究引入了一种名为LoRR（LLM优化重置重播）的通用插件，旨在提升任何偏好优化框架中的样本效率。LoRR通过提高重播次数来最大化每批收集数据的效用，同时采用周期性重置策略和数据重用，以维持网络的可塑性。此外，这种方法还结合了监督微调和偏好损失，以进一步提升数据利用效率。", "innovation": "提出了LoRR（LLM优化重置重播）是一种通用和强大的插件，旨在增强任何基于偏好的优化框架中的样本效率。LoRR的核心机制允许在高重播次数下进行训练，同时通过周期性重置策略和数据重用，保留网络的可塑性。此外，LoRR利用结合了监督微调和偏好损失的混合优化目标来进一步提高数据的利用效率。", "conclusion": "广泛的实验表明，LoRR显著提升了多种偏好优化方法在数学和一般推理基准测试中的性能。特别是在具有挑战性的数学任务上，迭代DPO方法结合LoRR能够与某些复杂的计算密集型基于RL的算法相比拟甚至更优。这些发现表明，LoRR提供了一种实用、样本高效且高效的LLM微调范式，可以使有限的数据产生更好的结果。"}
{"llm_update_time": "20250816", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.05571", "html_url": "https://arxiv.org/abs/2508.05571", "title": "iFairy：所有参数在{$\text{±1, ±i}$}中的首个2比特复数LLM", "title_en": "iFairy: the First 2-bit Complex LLM with All Parameters in $\\{\\pm1, \\pm i\\}$", "authors": "Feiyu Wang,Guoan Wang,Yihao Zhang,Shengfan Wang,Weitao Li,Bokai Huang,Shimao Chen,Zihan Jiang,Rui Xu,Tong Yang", "background": "量化感知训练（QAT）将量化过程整合到训练过程中，使大语言模型（LLMs）能够学习稳健的低位表示。现有所有QAT研究主要集中在最小化全精度模型的量化误差上，全精度模型的准确性被视为上限（准确度天花板），现有方法都未能超越这一天花板。本文提出了一个新的研究范式：提升准确度天花板，然后将其高效地量化成2比特。提出了Fairy$\text{±i}$框架，这是首个用于复数LLM的2比特量化框架。方法利用复数域的表现优势，将权重映射到四次单位根{$\text{±1, ±i}$}，形成对称且信息论上最优的2比特表示。每个量化权重要么是实部要么是虚部为0，从而实现无需乘法的推理，仅使用加法和元素交换。实验结果显示，Fairy$\text{±i}$在PPL和下游任务上都优于现有2比特量化方法，同时保持严格的存储和计算效率。该研究为在极低比特约束条件下建立高准确性和实用性的LLM开辟了新方向。", "innovation": "提出了Fairy$\text{±i}$框架作为首个用于复杂值LLM的2比特量化框架，利用复数域的优势，将权重映射到四次单位根{$\text{±1, ±i}$}，实现了无乘法、仅加法和元素交换的推理。方法成功突破了现有2比特量化方法的准确度天花板，在PPL和下游任务上均表现出色，同时保持高效率。", "conclusion": "Fairy$\text{±i}$框架突破了现有2比特量化方法的准确度天花板，在PPL和下游任务上均表现出色，同时保持高效率。该研究为在极低比特约束条件下构建高准确性和实用性的LLM提供了新的研究方向。"}
{"llm_update_time": "20250816", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.08543", "html_url": "https://arxiv.org/abs/2508.08543", "title": "M3-Net: 一种成本效益高且不需要图的多层感知器基于模型用于交通预测", "title_en": "M3-Net: A Cost-Effective Graph-Free MLP-Based Model for Traffic Prediction", "authors": "Guangyin Jin,Sicong Lai,Xiaoshuai Hao,Mingtao Zhang,Jinlei Zhang", "background": "准确的交通预测是当前智能交通系统发展中的一项基础且关键任务。现有的突破性方法依赖于时空图神经网络等技术，但这些方法存在依赖完整交通网络结构或需要复杂模型设计以捕捉复杂时空依赖性的局限性。这些限制对大规模数据集上高效部署和运行深度学习模型构成了重大挑战。", "innovation": "提出了一种低成本且不需要图的多层感知器（MLP）模型M3-Net，该模型不仅利用时间序列和时空嵌入进行特征处理，还引入了一种新颖的MLP-Mixer架构，并配备了混合专家（MoE）机制，从而能够在不依赖完整交通网络结构的情况下进行预测，同时提高了预测性能并实现了轻量部署。", "conclusion": "在多个真实数据集上的广泛实验表明，提出的M3-Net模型在预测性能和轻量部署方面具有优势。"}
{"llm_update_time": "20250816", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.08746", "html_url": "https://arxiv.org/abs/2508.08746", "title": "通过稀疏自编码器实现可解释的奖励模型", "title_en": "Interpretable Reward Model via Sparse Autoencoder", "authors": "Shuyi Zhang,Wei Shi,Sihang Li,Jiayi Liao,Tao Liang,Hengxing Cai,Xiang Wang", "background": "大规模语言模型（LLMs）已在多个领域得到广泛应用。强化学习从人类反馈（RLHF）通过使用奖励模型（RMs）作为人类偏好的代理来使LLM的行为与人类值保持一致，因此奖励模型的准确度、可靠性和解释性对于有效对齐至关重要。然而，传统的RMs缺乏解释性，较少提供关于奖励分配理由的见解，并且在用户偏好变化时不够灵活。尽管最近的多维RMs提升了可解释性，但它们往往不能提供特征级的贡献度，并且需要昂贵的标注。", "innovation": "我们提出了Sparse Autoencoder-enhanced Reward Model（SARM），这是一种新颖的架构，将预训练的Sparse Autoencoder（SAE）集成到奖励模型中。SARM将LLM基础的RM的隐藏激活映射到一个可解释、稀疏和单义特征空间中，从该空间中提取特征激活来生成透明且概念性意义的奖励评分。实证评估表明，SARM能够实现奖励分配的直接特征级归因，允许灵活适应偏好变化，并在对齐性能方面优于传统奖励模型。", "conclusion": "SARM能够实现直接的特征级归因、灵活性适应偏好变化，并且在对齐性能方面优于传统奖励模型。我们已在https://github.com/example/reward-model提供了代码。"}
{"llm_update_time": "20250816", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.09146", "html_url": "https://arxiv.org/abs/2508.09146", "title": "理解基于Transformer的在上下文学习理论以优化CSMA", "title_en": "To Theoretically Understand Transformer-Based In-Context Learning for Optimizing CSMA", "authors": "Shugang Hao,Hongbo Li,Lingjie Duan", "background": "二进制指数退避方案在WiFi 7中广泛应用，但在动态信道环境中会导致较差的吞吐量性能。现有的基于模型的方法（例如非恒定量竞争避免协议和$p$-恒定量竞争避免协议），仅在已知且固定节点密度的情况下优化退避策略，由于节点密度估计不准确，仍会导致较大的吞吐量损失。", "innovation": "本文首次提出基于LLM变压器的上下文学习（ICL）理论来优化信道访问。设计了一种基于变压器的ICL优化器来预先收集碰撞阈值数据示例和查询的碰撞案例。这些被构造成提示作为变压器的输入，学习模式，以生成预测的冲突窗口阈值（CWT）。为了训练变压器以有效进行ICL，提出了一个高效的算法，并在有限的训练步骤内保证接近最优的CWT预测。由于实际操作中很难收集完美的数据示例，我们进一步扩展了允许错误数据输入提示。我们证明该优化器的预测和吞吐量偏差最小，且实验结果证明在未知节点密度下，我们的方法比现有模型基于和DRL基于方法具有更快收敛和接近最优的吞吐量。", "conclusion": "实验结果在NS-3上进一步证明，我们的方法在未知节点密度下，能够快速收敛并接近最优的吞吐量，相比现有的模型基础和DRL基础方法表现出明显的优势。"}
{"llm_update_time": "20250816", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.09299", "html_url": "https://arxiv.org/abs/2508.09299", "title": "通过分布式机器学习和基于区块链的模型验证实现去中心化天气预报", "title_en": "Decentralized Weather Forecasting via Distributed Machine Learning and Blockchain-Based Model Validation", "authors": "Rilwan Umar,Aydin Abadi,Basil Aldali,Benito Vincent,Elliot A. J. Hurley,Hotoon Aljazaeri,Jamie Hedley-Cook,Jamie-Lee Bell,Lambert Uwuigbusun,Mujeeb Ahmed,Shishir Nagaraja,Suleiman Sabo,Weaam Alrbeiqi", "background": "天气预报在灾害准备、农业和资源管理中起着关键作用，但当前的集中式预报系统面临安全漏洞增加、可扩展性有限以及单点故障的脆弱性等问题。为了应对这些挑战，本文提出了一种将联邦学习（FL）与区块链技术相结合的去中心化天气预报框架。", "innovation": "该框架利用联邦学习进行协作模型训练而不暴露敏感的本地数据，这增强了隐私并减少了数据传输开销；同时，通过使用以太坊区块链确保模型更新的透明和可信赖验证。此外，引入基于声誉的投票机制评估提交模型的可信度，并使用星际文件系统（IPFS）进行高效离链存储。实验结果表明，该方法不仅能提高预报准确性，还能增强系统的韧性和可扩展性，使其成为部署在真实、安全关键环境中的可行选择。", "conclusion": "本文提出的去中心化天气预报框架通过结合联邦学习和区块链技术，在提高预报准确性的同时增强了系统的安全性、韧性和可扩展性，适用于实际的安全关键环境。"}
{"llm_update_time": "20250816", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2402.02190", "html_url": "https://arxiv.org/abs/2402.02190", "title": "连续并行松弛法在组合优化问题中寻找多样化解决方案", "title_en": "Continuous Parallel Relaxation for Finding Diverse Solutions in Combinatorial Optimization Problems", "authors": "Yuma Ichikawa,Hiroaki Iwashita", "background": "组合优化（CO）中通常寻找最优解，但在实际应用中，通常需要多样化而非单一最优解，特别是在两种场景下尤为重要：一种是即使轻微违反约束条件也能提供更经济的解决方案；另一种是CO建模往往简化复杂现实因素，无法全面反映专家知识、隐含权衡或伦理考量。因此，生成具有多样化的惩罚解和变异解是面对这些挑战的关键。", "innovation": "该研究提出了连续并行松弛法（CPRA），这是一种计算高效的无监督学习（UL）组合优化求解框架。CPRA通过利用表示学习和并行化技术自动发现共享表示，从而在单一训练过程中生成多样化的解决方案，显著提高了搜索这些多样解的效率。实验结果表明，CPRA在生成多样化解的同时，相比现有UL解决方法，显著降低了计算成本。", "conclusion": "CPRA框架在处理组合优化问题时能够有效生成多样化的解决方案，提高了效率并降低了计算成本，为组合优化提供了新的解决方案生成方法。"}
{"llm_update_time": "20250816", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2310.19583", "html_url": "https://arxiv.org/abs/2310.19583", "title": "GC-MVSNet：多视图、多尺度、几何一致性多视图立体", "title_en": "GC-MVSNet: Multi-View, Multi-Scale, Geometrically-Consistent Multi-View Stereo", "authors": "Vibhas K. Vats,Sripad Joshi,David J. Crandall,Md. Alimoor Reza,Soon-heung Jung", "background": "传统多视图立体（MVS）方法高度依赖光度学和几何一致性约束，而基于机器学习的新方法仅在后期处理步骤中检查多个源视图的几何一致性。本研究通过在学习过程中显式地鼓励参考视图深度图在不同尺度上的几何一致性来增强这种方法。", "innovation": "提出了一种新的方法，在学习过程中显式地促进参考视图深度图在多个源视图和不同尺度上的一致几何性（见图1）。该方法通过显性惩罚几何不一致的像素，大幅加快了学习速度，将训练迭代需求降低了一半。实验表明，该方法在DTU和BlendedMVS数据集上达到了新的最佳性能，在Tanks and Temples基准上也取得了竞争力的结果。这是我们第一次在学习过程中强制执行多视图、多尺度几何一致性尝试方法。", "conclusion": "我们的方法，在学习期间强制实现了多视图和多尺度几何一致性，在DTU和BlendedMVS数据集上达到了新的最先进的性能，并在Tanks and Temples基准上取得了竞争性结果。"}
{"llm_update_time": "20250816", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2405.20124", "html_url": "https://arxiv.org/abs/2405.20124", "title": "几何上的分布鲁棒协方差估计统一：通过扩大不确定性集来收缩光谱", "title_en": "A Geometric Unification of Distributionally Robust Covariance Estimators: Shrinking the Spectrum by Inflating the Ambiguity Set", "authors": "Man-Chung Yue,Yves Rychener,Daniel Kuhn,Viet Anh Nguyen", "background": "目前最先进的高维协方差矩阵估计方法会将样本协方差矩阵的特征值向一个数据无关的收缩目标收缩。这种收缩变换要么凭直觉选择（缺乏有力的理论依据），要么在严格的分布假设下最优选择。本文的研究背景是当前方法在对假设的依赖性上存在限制。", "innovation": "本文提出了一种在不依赖严格假设的情况下构建协方差估计器的原理性方法。具体来说，作者研究了基于所有接近名义分布的数据分布，最小化加权Frobenius误差的分布鲁棒协方差估计问题。这些方法的关键创新在于通过几何性质描述的不等同性来构造收缩估计器，并通过理论证明表明该方法在计算效率、渐近一致性和有限样本性能上都具有优势。", "conclusion": "通过Kullback-Leibler、Fisher-Rao和Wasserstein不等性，本文提出了具体估计器的合成示例。基于合成和真实数据的数值实验显示，所提出的鲁棒估计器在性能上具有竞争力。"}
{"llm_update_time": "20250816", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2407.01566", "html_url": "https://arxiv.org/abs/2407.01566", "title": "动态上下文环境下单边经纪业务的参数化在线学习理论", "title_en": "A Parametric Contextual Online Learning Theory of Brokerage", "authors": "François Bachoc,Tommaso Cesari,Roberto Colomboni", "background": "该研究探讨了在线学习问题中，经纪人在交易者之间撮合交易时如何利用上下文信息的角色。在这个顺序问题中，每隔一个时间步，会有两个交易者到来，他们对想要交易的资产有不同的私下估值。经纪员（即学习者）基于资产的上下文信息和市场状况建议一个交易价格。然后，根据他们的估值是否高于或低于经纪员建议的价格，交易者选择买或卖。只有当其中一个交易者决定买单，另一个交易者决定卖单时，才会进行交易，即如果经纪员建议的价格刚好位于两个交易者的最低估值与最高估值之间。", "innovation": "该研究设计了解决上述问题的算法，并在多种标准假设下证明了最优的理论后悔保证。", "conclusion": "该研究在动态上下文中探讨了经纪业务，设计了算法并提供了理论保证，证明了该方案的有效性。"}
{"llm_update_time": "20250816", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.09158", "html_url": "https://arxiv.org/abs/2508.09158", "title": "EvaDrive：端到端自动驾驶的进化对抗策略优化", "title_en": "EvaDrive: Evolutionary Adversarial Policy Optimization for End-to-End Autonomous Driving", "authors": "Siwen Jiao,Kangan Qian,Hao Ye,Yang Zhong,Ziang Luo,Sicong Jiang,Zilin Huang,Yangyi Fang,Jinyu Miao,Zheng Fu,Yunlong Wang,Kun Jiang,Diange Yang,Rui Fan,Baoyun Peng", "background": "自动驾驶在实现类人化的迭代决策过程中面临重大挑战，这一过程需要不断生成、评估和优化轨迹提案。现有的生成-评估框架将轨迹生成与质量评估分离，阻碍了重要的迭代优化。当前的强化学习方法将多维度的目标压缩为单一的标量奖励，这模糊了关键的利益权衡，并导致了单一标量化的结果。", "innovation": "为了解决这些问题，本文提出了EvaDrive，这是一种新颖的多目标强化学习框架，通过对抗优化在轨迹生成和评估之间建立了真正的闭环协同进化。EvaDrive将轨迹规划视为多轮对抗游戏。在这个游戏中，分层生成器通过时间因果性的自动回归意图建模和空间灵活性的扩散基础优化不断提出候选路径。这些提案随后由一个可训练的多目标评论家严格评估，该评论家明确保留了各种偏好结构，而没有将它们压缩为单一的标量化。对抗机制，在帕累托前沿选择机制引导下，允许多轮迭代优化，有效地避免局部最优同时保持轨迹。实验结果表明，EvaDrive在NAVSIM和Bench2Drive基准测试上表现出SOTA性能，当比DiffusionDrive优越6.8，在Bench2Drive上获得了64.96的驾车得分，比DriveSuprim高5.0，比TrajHF高0.9。EvaDrive通过动态权衡生成不同的驾驶风格，无需外部偏好数据，引入了闭环对抗框架，实现了类人的迭代决策，并提供了无标量化轨迹优化的新方法。", "conclusion": "EvaDrive在理论上和实验上均表现出色，在保持多样化的驾驶风格的同时，实现了类人的迭代决策，提供了一种无标量化轨迹优化的新方法。"}
{"llm_update_time": "20250816", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2403.03353", "html_url": "https://arxiv.org/abs/2403.03353", "title": "基于深度神经网络的假设空间", "title_en": "Hypothesis Spaces for Deep Learning", "authors": "Rui Wang,Yuesheng Xu,Mingsong Yan", "background": "本文介绍了基于深度神经网络(DNNs)的假设空间。通过将DNN视为输入变量和参数变量的函数，考虑了参数变量属于由指定深度和层宽确定的权重矩阵和偏差空间的DNN集合。为了构造输入变量的函数Banach空间，我们取了该DNN集合的弱*闭包的线性张成。证明了由此产生的Banach空间是一个再生核Banach空间(RKBS)，并显式构造了其再生核。进一步在RKBS框架下研究了正则化学习和最小范数插值(MNI)问题的学习模型，通过建立表示定理，揭示了解可以表示为基于训练数据的有限核展开之和。", "innovation": "引入了基于DNN的Banach空间模型，证明了其是再生核Banach空间。研究了正则化学习和最小范数插值问题，并展示了相应的表示定理，指出解可以通过训练数据的有限核展开表示。", "conclusion": "本文证明了基于DNN的假设空间是一个再生核Banach空间，并通过建立表示定理展示了正则化学习和最小范数插值问题的解可以表示为有限的核展开形式。"}
{"llm_update_time": "20250816", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2407.08750", "html_url": "https://arxiv.org/abs/2407.08750", "title": "在线分布回归", "title_en": "Online Distributional Regression", "authors": "Simon Hirsch,Jonathan Berrisch,Florian Ziel", "background": "现代机器学习应用中存在着大量的流式数据，促使在线学习算法的发展。许多领域如供应链管理、天气与气象、能源市场、金融等，转向使用概率预测，这不仅需要准确估计期望值，还需要估计条件异方差性和条件矩。基于这一背景，本文提出了一种用于在线估计正则化线性分布模型的方法。该方法结合了最近在线估计LASSO模型的发展和广为人知的GAMLSS框架。我们以日-ahead电力价格预测为案例研究，展示了增量估计结合显著降低的计算成本的竞争性能。该算法在计算效率高的Python包ondil中实现。", "innovation": "本文提出了一种结合了在线估计LASSO模型与GAMLSS框架的方法，用于在线估计正则化线性分布模型，特别适用于日-ahead电力价格预测，展示了其在准确性和计算效率方面的优势。该方法能够准确估计条件异方差性和条件矩，具有较强的竞争力和较低的计算成本。", "conclusion": "本文通过引入一种新的在线分布模型估计方法，有效地解决了流式数据环境中准确估计期望值、条件异方差性和条件矩的问题。该方法在实际应用中表现出了较好的性能，并且具有较高的计算效率。相关的算法已经实现了高效的Python包中。"}
{"llm_update_time": "20250816", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2405.02754", "html_url": "https://arxiv.org/abs/2405.02754", "title": "隐式安全集合算法用于可证明安全的强化学习", "title_en": "Implicit Safe Set Algorithm for Provably Safe Reinforcement Learning", "authors": "Weiye Zhao,Feihan Li,Changliu Liu", "background": "深度强化学习（DRL）在许多连续控制任务中展现了出色的表现。然而，DRL 在实际应用中的一个重大障碍是没有提供安全保证。虽然通过奖励塑形可以在期望上实现系统安全性，但设计能够在每个时间步都满足严格约束（例如，安全规范）的智能体仍旧是一个巨大的挑战。现有的安全控制工作中，只关注在系统动态模型下实现持久满足严格安全约束的保证，但在DRL中这些模型通常不可获取。因此，本研究提出了一个无需依赖系统动态模型的无模型安全控制算法——隐式安全集合算法，以确保DRL代理在整个训练过程中都能得到可证明的安全性能。该算法仅通过查询一个黑盒动态函数（例如，数字孪生模拟器）来合成安全指数（屏障证书）和后续的安全控制策略。在连续时间和离散时间系统中，该算法理论证明了有限时间收敛到安全集，并且保持不变性。该算法已在最新的安全强化学习基准Safety Gym上进行了验证，实现了零安全违规，同时获得了与最先进的安全强化学习方法相比高达95%±9%的累积奖励。此外，该算法适用于高维系统，并且在并行计算下表现出良好的扩展性。", "innovation": "本研究提出了一个隐式安全集合算法，用于在只依赖黑盒动态函数的DRL代理上合成可证明的安全策略。该算法能够在不需要明确系统动力学模型的情况下，保证在训练过程中实现可证明的安全性。它通过理论证明实现了有限时间收敛和稳定性，并在最新的Safety Gym基准测试中获得了优异的表现。", "conclusion": "研究提出了一个无模型的安全控制算法，隐式安全集合算法，用于DRL中合成保证所有时间段内安全性的策略。该算法通过查询黑盒动态函数，仅需少的系统动态模型信息即可实现安全控制。在实验验证中，算法不仅在安全性能上达到了理想效果，还在多个维度上表现优异，并能够高效处理高维度系统。"}
{"llm_update_time": "20250816", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2410.15729", "html_url": "https://arxiv.org/abs/2410.15729", "title": "两阶段学习推迟方法在多任务学习中的应用", "title_en": "A Two-Stage Learning-to-Defer Approach for Multi-Task Learning", "authors": "Yannis Montreuil,Shu Heng Yeo,Axel Carlier,Lai Xing Ng,Wei Tsang Ooi", "background": "经过广泛的研究，两阶段学习-推迟（L2D）框架已被应用于分类和最近的回归任务。然而，许多实际应用场景需要在多任务设置中同时解决这两个任务。现有的L2D方法在多任务场景中的应用存在局限性。", "innovation": "本文提出了一个新的两阶段L2D框架，用于集成分类和回归任务，并通过统一的推迟机制进行联合学习。该方法利用了一个两阶段的代理损失族，该损失族被证明为Bayes一致和$(\text{G}, \text{R})$一致，确保收敛到Bayes最优的拒绝器。此外，还推导出关联交叉熵代理和代理特定代价的$L_1$范数的显式一致性界，并将最小化间隙分析扩展到多专家两阶段框架中。此外，还明确阐述了共享表示学习如何影响这些一致性保证。", "conclusion": "在对象检测和电子健康记录分析上的实验表明，该方法在多任务场景中的有效性，并指出现有L2D方法在多任务场景中的局限性。"}
{"llm_update_time": "20250816", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2407.12830", "html_url": "https://arxiv.org/abs/2407.12830", "title": "基于知识的一致性测试：大型语言模型的测试", "title_en": "Knowledge-based Consistency Testing of Large Language Models", "authors": "Sai Sathiesh Rajan,Ezekiel Soremekun,Sudipta Chattopadhyay", "background": "本文研究了大型语言模型（LLMs）的一致性和知识空白问题。此前的研究显示，LLMs在知识上的不一致性和空白是一个普遍存在的问题。面对这些挑战，需要一种有效的自动化测试框架来揭示并衡量这些问题。", "innovation": "本文提出了一个名为KonTest的自动化测试框架，利用知识图谱构建测试用例，并通过语义等价查询和测试或acles（元朔或本体或acles）来检测和测量LLMs关于世界的知识的一致性问题。此外，KonTest还通过加权LLMs模型集成来减轻知识空白问题。这项研究通过四种先进的大型语言模型（Falcon、Gemini、GPT3.5和Llama2）展示了KonTest的有效性，揭示了知识差距为16.5%。", "conclusion": "通过KonTest的方法测试，研究发现约19.2%的测试输入导致错误（即，1917个错误来自9979个测试输入），并在四种大型语言模型中揭示了16.5%的知识差距。基于KonTest测试套件的方法，LLMs的知识差距减少了32.48%。此外，研究还揭示了GPT3.5不适用于知识一致性测试，因为其在知识构建方面的有效率仅为60%-68%。"}
{"llm_update_time": "20250816", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2411.06869", "html_url": "https://arxiv.org/abs/2411.06869", "title": "CapeLLM：使用多模态大型语言模型实现无支持信息的类别无关姿态估计", "title_en": "CapeLLM: Support-Free Category-Agnostic Pose Estimation with Multimodal Large Language Models", "authors": "Junho Kim,Hyungjin Chung,Byung-Hoon Kim", "background": "传统上，类别无关姿态估计（CAPE）依赖于标注关键点的支持图像，这一过程通常繁琐，并可能无法完全捕捉不同类别对象之间的必要对应关系。最近的研究尝试利用文本查询，利用其增强的稳定性和通用性。然而，现有的方法仍然受限于对支持查询的依赖，未能充分利用预训练大型语言模型中嵌入的丰富先验知识，并且受限于其参数分布假设。", "innovation": "我们介绍了CapeLLM，一个专为CAPE设计的第一个多模态大型语言模型（MLLM）。我们的方法仅使用查询图像和详细的文本描述作为输入来估计类别无关的关键点。我们的方法包括有效的训练策略和精心设计的指令，以将MLLM应用于CAPE中。此外，我们提出了一个推理机制，进一步增强了对未见过的关键点的推理过程，同时灵活地建模它们的潜在空间分布和不确定性，允许基于上下文线索进行自适应细化。我们进行了大量的实验，确保MLLM在不同输入变化中的鲁棒性。", "conclusion": "我们的方法在MP-100基准测试中达到了新的最佳状态，在单次和五次设置中均取得了显著进步，标志着在类别无关姿态估计领域的一个重要突破。代码可在以下链接获取。"}
{"llm_update_time": "20250816", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.05977", "html_url": "https://arxiv.org/abs/2508.05977", "title": "LinguaFluid：基于语义奖励的强化学习语言引导流体控制", "title_en": "LinguaFluid: Language Guided Fluid Control via Semantic Rewards in Reinforcement Learning", "authors": "Aoming Liang,Chi Cheng,Dashuai Chen,Boai Sun,Dixia Fan", "background": "在科学机器学习领域，如何在具有难以数值化指定任务目标的环境中设计有效的奖励函数仍然是强化学习（RL）中的一个挑战。现有的奖励函数主要依赖于启发式方法、手动工程或特定任务的调整。此研究旨在提出一种与语义指令相匹配的强化学习方法，该方法通过Sentence-Bidirectional Encoder Representations from Transformers (SBERT)计算奖励，使得当前状态与目标语义指令对齐。这种方法不依赖于手动定义的奖励函数，而是在每一步使用语义相似性来给出反馈。", "innovation": "提出了基于语义语句的强化学习方法，通过Sentence-Bidirectional Encoder Representations from Transformers (SBERT)计算奖励，而不是依赖于手动定义的奖励函数。通过这种方式，学习过程可以根据目标文本描述与当前交互描述之间的余弦相似度收到反馈。这种框架展示了语言嵌入空间与传统欧几里得空间之间的关联，为将大型语言模型（LLMs）与更加流畅的控制应用相结合提供了新的可能性。", "conclusion": "研究展示了语言奖励可以在没有手工地定义奖励函数的情况下引导学习实现竞争对手的行为控制。进一步地，该框架证明了未来可以通过更大规模的语言模型实现与自然语言目标一致的智能体行为，从而促进了更流畅的控制应用集成。"}
{"llm_update_time": "20250816", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2407.11353", "html_url": "https://arxiv.org/abs/2407.11353", "title": "通过预条件梯度下降和提前停止训练的过参数化神经网络在插值空间中的精确泛化非参数回归", "title_en": "Sharp Generalization for Nonparametric Regression in Interpolation Space by Over-Parameterized Neural Networks Trained with Preconditioned Gradient Descent and Early-Stopping", "authors": "Yingzhen Yang,Ping Li", "background": "本文研究了使用过参数化的两层神经网络进行非参数回归，其中训练特征均匀地从$\text{R}^d$单位球中抽取，目标函数位于统计学习理论中常用的研究插值空间中。背景主要是探讨在插入空间条件下，使用预条件梯度下降结合提前停止算法训练神经网络的性能和效果，以达到最优或近最优的回归率，对比现有方法的泛化能力。", "innovation": "本文的主要创新在于提出了一种新颖的预条件梯度下降（PGD）算法，并结合提前停止策略，在目标函数位于特定插值空间$\bth{\text{H}_K}^{s'}$时，实现了比现有最优率更佳的回归速度$\text{O}(n^{-\frac{2\text{α}s'}{2\text{α}s'+1}})$。此外，通过理论分析证明，这种方法能够使神经网络接近线性NTK（神经元切片内核）之外的区域，从而获得更好的泛化能力，这得益于重新定义的积分内核。", "conclusion": "文章总结了基于特定插值空间条件下的非参数回归泛化问题，证明了使用预条件梯度下降算法结合提前停止策略能够实现比原有方法更优的回归速度，并且能够引导神经网络模型跳出线性内核区域，从而增强泛化性能。"}
{"llm_update_time": "20250816", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2412.16819", "html_url": "https://arxiv.org/abs/2412.16819", "title": "Bi-Sparse Unsupervised Feature Selection", "title_en": "Bi-Sparse Unsupervised Feature Selection", "authors": "Xianchao Xiu,Chenyi Huang,Pan Shang,Wanquan Liu", "background": "在多个领域中处理高维未标记的数据集时，主成分分析（PCA）已成为一种流行的无监督特征选择（UFS）技术。然而，现有的大多数基于PCA的方法只通过在变换矩阵上嵌入单一的稀疏正则化或约束考虑了数据集的结构。", "innovation": "本文提出了一种新的双稀疏方法，称为BSUFS，以提高UFS的性能。BSUFS的思想是将$\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{l}}}}}}_{2,p}$-范数和$\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{q}}}}}$-范数引入经典PCA，从而我们的方法能够选择相关特征并过滤不相关的噪声，从而获得有鉴别性的特征。此外，文中提出了一个有效的方法来解决非凸模型，并对计算复杂度进行了分析。大量基于合成数据集和真实数据集的数值实验验证了BSUFS的有效性。", "conclusion": "实验结果表明了双稀疏优化方法在特征选择中的优势，并显示了它们在图像处理和其他领域的潜在应用。"}
{"llm_update_time": "20250816", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2412.12400", "html_url": "https://arxiv.org/abs/2412.12400", "title": "在复杂渔场情境中使用机器学习指导捕捞控制规则设计", "title_en": "Using machine learning to inform harvest control rule design in complex fishery settings", "authors": "Felipe Montealegre-Mora,Carl Boettiger,Carl J. Walters,Christopher L. Cahill", "background": "在渔业科学中，管理大小分层的随机种群的捕捞是一个持久且具有挑战性的问题。基于生物量和捕捞参考点的线性预防性政策已成为解决此类问题的标准方法。然而，这些标准反馈政策大都适应了假设相对简单的生态动态的分析或动态编程解决方案，但在实际中通常被应用于更复杂的生态情境。本研究旨在探讨如何利用强化学习（RL）和贝叶斯优化工具为部分观测，年龄分层，波动性鱼类种群设计捕捞控制规则。", "innovation": "利用强化学习和贝叶斯优化技术，为复杂的年龄分层并伴有波动性捕捞控制规则提供了一种新方法。具体创新点在于：通过该方法优化了加拿大阿尔伯塔省白斑狗鱼的捕捞控制策略，将其应用于实际的复杂生态背景下，同时评估了标准政策与数值优化政策之间的表现差异，以及体重平均值观测对政策决策的辅助作用。", "conclusion": "研究结果表明，在复杂生态背景下，数值优化的政策优于基于参考点的标准政策；此外，额外利用平均鱼体重信息有助于进一步优化渔业管理策略。这为未来的渔场管理提供了新的技术工具和管理依据。"}
{"llm_update_time": "20250816", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2411.09776", "html_url": "https://arxiv.org/abs/2411.09776", "title": "无需冲突地结合机器学习防御", "title_en": "Combining Machine Learning Defenses without Conflicts", "authors": "Vasisht Duddu,Rui Zhang,N. Asokan", "background": "机器学习（ML）防御机制能够保护系统免受多种安全、隐私和公平风险的侵害。现实中，模型需要同时抵御多种不同类型的风险，这就需要将多个防御机制结合起来使用。然而，当多种防御措施之间存在冲突时，可能会导致某一个或多个防御措施失去效果。实践者需要一种方法来确定哪些结合是有效的。实验性地寻找有效的结合往往耗时且昂贵，尤其是当需要结合多个防御措施时。因此，需要一种低成本、易于使用的结合技术来识别有效的结合。理想的结合技术应该满足以下要求：（a）精确性、（b）可扩展性、（c）非侵入性以及（d）通用性。然而，以往的工作已经提出了一些非正式的技术，但它们无法完全满足上述所有要求。", "innovation": "我们提出了一种科学的组合技术，称为Def\\̼Con，用于识别有效的防御组合。Def\\̼Con 满足所有要求，该技术在八种以往研究中探索的组合上实现了90%的准确性，并且在30种我们在本文中通过实验评估的未探索组合上实现了81%的准确性。这表明Def\\̼Con能够有效地发现无冲突的防御组合。", "conclusion": "Def\\̼Con是一种有效的无冲突防御组合技术，能够在保持精确性、可扩展性、非侵入性和通用性的同时，为实践者提供一种高效便捷的方法来确定有效的防御组合。"}
{"llm_update_time": "20250816", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2412.06534", "html_url": "https://arxiv.org/abs/2412.06534", "title": "通过反转理解基于变换器的视觉模型", "title_en": "Understanding Transformer-based Vision Models through Inversion", "authors": "Jan Rathjens,Shirin Reyhanian,David Kappel,Laurenz Wiskott", "background": "理解和揭示深度神经网络背后的机理仍然是机器学习和计算机视觉领域的基本挑战。一种有前景但仅初步探索的方法是特征反转，该方法试图使用训练好的逆向神经网络从中间表示重建图像。本研究重新审视了特征反转方法，提出了一种新型模块化变体，使其在应用上更加高效。", "innovation": "该研究提出了一种新的模块化特征反转方法，能够更高效地应用于大规模基于变换器的视觉模型，如检测变换器和视觉变换器，并通过重建的图像进行了有意义的定性解释。此外，通过定量评估，发现了这两种变换器架构中图像特征表示的内在机制，深入理解了这些模型如何编码上下文形状和图像细节、层之间的关联以及对颜色扰动的鲁棒性。", "conclusion": "这些发现为深入理解基于变换器的视觉模型及其内部表征做出了贡献。研究代码可在指定网址重现实验结果。"}
{"llm_update_time": "20250816", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2412.19160", "html_url": "https://arxiv.org/abs/2412.19160", "title": "一种基于相位唯交叉注意力的轻量化Transformer在光照不变生物认证中的应用", "title_en": "A Lightweight Transformer with Phase-Only Cross-Attention for Illumination-Invariant Biometric Authentication", "authors": "Arun K. Sharma,Shubhobrata Bhattacharya,Motahar Reza,Bishakh Bhattacharya", "background": "传统的生物识别系统由于诸如佩戴口罩导致人脸识别生物识别系统性能下降和指纹识别生物识别系统因卫生问题而引发的使用不便等因素，遇到了重大挑战。本文提出了一种基于额头和眼部周围区域的新型轻量级视觉变压器 (POC-ViT)，即使在佩戴口罩时也能表现良好，无需物理接触，为传统方法提供了一个有前途的替代方案。该视觉变压器框架旨在处理两个生物识别特征，并捕捉其相对结构模式的关联性。使用相位唯相关（POC）进行交叉注意力计算，提取空间特征的相位相关性，从而使其对输入图像分辨率、强度变化和光照变化具有鲁棒性。", "innovation": "提出了一种名为POC-ViT的轻量级视觉变压器，使用额头和眼部周围区域的双生物特征，即使在佩戴口罩和无需物理接触的情况下也能实现良好的性能。该模型利用相位唯一相关（POC）进行交叉注意力计算，提取空间特征的相位相关性，提高了对不同分辨率、强度和照明条件的鲁棒性。此外，该模型适合边缘设备部署。", "conclusion": "提出的POC-ViT框架在FSVP-PBP数据库上的表现令人满意，该数据库包含350个受试者的数据，该框架在使用双生物特征的情况下实现了98.8%的出色分类准确率，超越了最先进的方法。"}
{"llm_update_time": "20250816", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2504.01400", "html_url": "https://arxiv.org/abs/2504.01400", "title": "ToolACE-R: 模型感知迭代训练和自适应细化方法在工具学习中的应用", "title_en": "ToolACE-R: Model-aware Iterative Training and Adaptive Refinement for Tool Learning", "authors": "Xingshan Zeng,Weiwen Liu,Xu Huang,Zezhong Wang,Lingzhi Wang,Liangyou Li,Yasheng Wang,Lifeng Shang,Xin Jiang,Ruiming Tang,Qun Liu", "background": "工具学习允许大规模语言模型（LLMs）利用外部工具来解决复杂的用户任务，这为扩展模型能力提供了一条有前途的道路。然而，现有的方法主要集中在使用数据合成进行微调，以有效地触发工具的使用，但却很大程度上忽视了如何充分发挥模型的潜能。", "innovation": "本文提出了ToolACE-R，这是一种新颖的框架，包括模型感知的迭代训练和自适应细化，旨在提高模型的潜在能力。该框架的特点是模型感知的迭代训练程序，根据模型能力的逐步演变，逐步调整训练样本，以最大化模型的潜力。此外，它还引入了自我细化训练语料库，突出语言模型的能力，使其能够逐步细化工具调用，优化性能，而不需要外部反馈。进一步引入了自适应自我细化机制，以实现高效的时间测试扩展。这些方法使得训练好的模型可以根据迭代自我细化的过程自动决定何时停止。", "conclusion": "在多个基准数据集上进行了广泛实验，结果显示，ToolACE-R 的性能与先进的基于API的模型相比具有竞争力，并且通过自适应自我细化可以进一步提升工具调用的性能。这些结果突显了ToolACE-R的有效性和可推广性，为更有效的和可扩展的工具学习提供了一个令人鼓舞的方向。"}
{"llm_update_time": "20250816", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.05724", "html_url": "https://arxiv.org/abs/2508.05724", "title": "基于图的框架在物理中探索数学模式：一个概念证明", "title_en": "A Graph-Based Framework for Exploring Mathematical Patterns in Physics: A Proof of Concept", "authors": "Massimiliano Romiti", "background": "物理学的丰富方程库形成了一个隐含的数学关系网络，传统的分析方法无法完全探索这些关系。本文提出了一种结合神经网络和符号分析的图基框架，系统地在不同物理领域中发现并验证数学模式。从659个方程中，通过严格的语义消歧处理了213个方程中的多义符号问题，然后排除了基础力学，专注于更具现代物理分支联系的400个先进方程。将这些方程组表示为一个加权知识图，并使用图注意力网络在链接预测中获得了97.4%的AUC，显著优于经典基准。框架的主要价值体现在其双功能上：生成假设和审计知识。", "innovation": "该研究提出了一种结合神经网络和符号分析的图基框架，能够系统地在物理学各个领域中发现并验证数学模式。首先，它可以作为一个假设生成器，产生跨领域的候选连接，涵盖从黑体辐射与纳维-斯托克斯方程耦合到放射性衰减与电磁感应关联的多种假设。其次，通过30个方程簇的符号分析，它可以作为计算核查器，验证现有的理论一致性，从电磁流体耦合中合成磁雷诺数，并揭示一些解析错误是如何潜在地指向合法的研究领域，如模拟重力。", "conclusion": "该框架通过对数学可能性空间的全面探索，生成了大量的候选连接，确保了数学模式的充分覆盖。即使一些同义复述和错误也被认为是具有科学目的的：识别冗余和评估知识库质量。"}
{"llm_update_time": "20250816", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2503.20839", "html_url": "https://arxiv.org/abs/2503.20839", "title": "TAR: Teacher-Aligned Representations via Contrastive Learning for Quadrupedal Locomotion", "title_en": "TAR: Teacher-Aligned Representations via Contrastive Learning for Quadrupedal Locomotion", "authors": "Amr Mousa,Neil Karavis,Michele Caprio,Wei Pan,Richard Allmendinger", "background": "四足机器人通过强化学习进行移动通常是通过教师-学生范式来解决的，其中待遇教师引导一个仅依靠本体感受的学生策略。但是，这种范式存在关键挑战，包括待遇教师和仅本体感受的学生之间的表示错位、由于行为克隆引起的协变量偏移，以及缺乏可部署的适应性，这些因素导致在真实世界场景中的泛化性能较差。", "innovation": "我们提出了一种名为教师对齐表示通过对比学习(TAR)的框架，该框架利用待遇信息与自我监督的对比学习相结合，以弥合上述差距。通过对比目标在模拟中对待遇教师的表示进行对齐，我们的学生策略学习到了结构化的潜在空间，并在离分布(OOD)场景中展示了鲁棒泛化，超过了完全待遇的“导师”。结果显示，与最先进的基线相比，TAR将训练加速了2倍，并且在OOD场景中平均表现提高了40%。此外，TAR在部署学习过程中无需待遇状态即可无缝过渡，为样本高效、自适应的移动设置了一个新的基准，在实际场景中支持持续微调。", "conclusion": "TAR框架展示了加速训练、增强泛化能力以及在实际应用中的高效适应性，为四足机器人的自适应移动提供了一种新方法，并且该方法开放源代码和视频可以在指定的链接处获取。"}
{"llm_update_time": "20250816", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2502.01027", "html_url": "https://arxiv.org/abs/2502.01027", "title": "Adversarial Robustness in Two-Stage Learning-to-Defer: Algorithms and Guarantees", "title_en": "Adversarial Robustness in Two-Stage Learning-to-Defer: Algorithms and Guarantees", "authors": "Yannis Montreuil,Axel Carlier,Lai Xing Ng,Wei Tsang Ooi", "background": "当前的两阶段学习-委派（Two-stage Learning-to-Defer, L2D）框架通过将每个输入分配给一个固定的主模型或多个离线专家之一，支持复杂多智能体环境中的有效决策。然而，现有的L2D框架假设输入干净，并且容易受到操控性扰动的影响，这些扰动可以使查询分配失效，导致成本高昂的错误路由或专家超载。", "innovation": "本文首次全面研究了两阶段L2D系统的对抗鲁棒性。提出了两种新型的攻击策略——无目标攻击和有目标攻击，分别扰乱最优分配或迫使查询到特定代理。为应对这些威胁，本文提出了一种称为SARD的凸学习算法，其基于一系列替代损失函数，这些替代损失函数在分类、回归和多任务设置中都具有可证明的贝叶斯一致性及$(\text{R, G})$-一致性保证。实验结果表明，SARD在对抗攻击下显著提高了鲁棒性，同时保持了良好的干净环境性能。", "conclusion": "本文的工作标志着安全且可信赖的L2D部署向前迈出的关键一步。通过提出的SARD算法及其理论保证，L2D系统可以在面对扰动攻击时仍保持高性能。"}
{"llm_update_time": "20250816", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2502.08557", "html_url": "https://arxiv.org/abs/2502.08557", "title": "通过代理介导的对话式探究的一种新的查询扩展方法", "title_en": "A New Query Expansion Approach via Agent-Mediated Dialogic Inquiry", "authors": "Wonduk Seo,Hyunjin An,Seunghyun Lee", "background": "在信息检索（IR）中，查询扩展被广泛用于通过补充初始查询，添加更丰富的信息以提高搜索结果。尽管基于大型语言模型（LLM）的方法能够生成伪相关内容和扩展的查询词，但由于这些问题方法往往产出的内容单一且缺乏多种情境下的多样性，这限制了查询所能检索到的相关信息。", "innovation": "本文提出了一种新的代理介导对话式框架（AMD），这个框架包含三个特定的角色：（1）一个苏格拉底式提问代理将初始查询重新表述为三个子问题，每个问题都来源于特定的苏格拉底提问维度，包括澄清、假设探究和隐含探寻；（2）一个对话式回答代理生成伪答案，以便从多个视角丰富查询表示，符合用户的意图；（3）一个反思反馈代理评估和精炼这些伪答案，确保只保留最相关和最具信息性的内容。通过多代理流程，AMD能够在问题与反馈精炼的过程中构建更丰富、更精确的查询表示方式。", "conclusion": "在 BEIR 和 TREC 等基准测试中进行的广泛实验表明，本文提出的框架在查询扩展任务中优于先前的方法，提供了一个稳健的检索解决方案。"}
{"llm_update_time": "20250816", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2503.03022", "html_url": "https://arxiv.org/abs/2503.03022", "title": "生成式主动适应的漂移和不平衡网络入侵检测", "title_en": "Generative Active Adaptation for Drifting and Imbalanced Network Intrusion Detection", "authors": "Ragini Gupta,Shinan Liu,Ruixiao Zhang,Xinyue Hu,Xiaoyang Wang,Hadjer Benkraouda,Pranav Kommaraju,Phuong Cao,Nick Feamster,Klara Nahrstedt", "background": "机器学习在网络入侵检测系统中的应用前景广泛，但其性能常常由于概念漂移和数据不平衡而下降。这些挑战进一步加剧了为适应需求准备合适数据集的劳动密集型过程，尤其是在处理不断演变的罕见攻击类型时更为明显，因此难以准备适应的数据。为应对这些问题，本文提出了一种生成式主动适应框架，旨在减少标注努力的同时增强模型的鲁棒性。该方法利用密度感知的数据集先验选择，以识别被标记的最具信息量的样本，并利用深度生成模型有条件地合成多样化的样本，从而扩充训练集并缓解概念漂移的影响。", "innovation": "提出了一种生成式主动适应框架，以减少标注努力并增强模型的鲁棒性。该框架通过使用密度感知的数据集先验选择最具信息量的样本进行标注，并利用深度生成模型有条件地合成多样化的样本来扩充训练集，从而应对概念漂移和数据不平衡等问题。", "conclusion": "本文通过端到端的框架 因綱保护NetGuard 在模拟和真实ISP数据集上的评估，展示了显著的入侵检测性能提升。未经适应的情况下整体F1分数为0.60，应用生成式主动适应后提升至0.86。对于CIC-IDS 2018数据集中的罕见攻击，其F1分数从0.001、0.04和0.00分别提升到0.30、0.50和0.71。本文框架能够有效地增强罕见攻击检测能力并减少标注成本，是一种可扩展且实用的入侵检测解决方案。"}
{"llm_update_time": "20250816", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2503.24381", "html_url": "https://arxiv.org/abs/2503.24381", "title": "UniOcc: 自动驾驶中的占用预报和预测统一基准", "title_en": "UniOcc: A Unified Benchmark for Occupancy Forecasting and Prediction in Autonomous Driving", "authors": "Yuping Wang,Xiangyu Huang,Xiaokang Sun,Mingxuan Yan,Shuo Xing,Zhengzhong Tu,Jiachen Li", "background": "现有的占用预测和占用预报研究主要依赖于子优化的伪标签进行评估，这些标签并不能全面反映真实的场景需求。此外，不同的研究使用的数据集和模拟器种类有限，导致难以获得大规模、多样化的训练数据，这也限制了模型的性能提升。因此，需要一个既能统一多种真实世界的数据集和高保真驾驶模拟器，又能提供全面、高质量标签的新基准和工具来推动该领域的发展。", "innovation": "UniOcc 提供了一个集成多个实际数据集（如 nuScenes 和 Waymo）和高保真驾驶模拟器（如 CARLA 和 OpenCOOD）的统一基准和工具。它提供了 2D/3D 占用标签并标注了创新性的每体素流信息。此外，它采用新型的评估指标，不依赖于真实标签，从而可对占用质量的多个方面进行稳健评估。该基准通过在最新模型上的广泛实验，展示了大规模、多样化训练数据和明确的流信息对提高占用预测和预报性能的显著效果。", "conclusion": "通过 UniOcc，研究团队证明了大规模、多样化的训练数据和明确的流信息能够显著提高占用预测和预报的性能。此外，UniOcc 的新基准和工具将有助于推动该领域的发展，并为其他研究人员提供重要的参考和资源。"}
{"llm_update_time": "20250816", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2504.08329", "html_url": "https://arxiv.org/abs/2504.08329", "title": "MedRep: 医疗概念表示法用于通用电子健康记录基础模型", "title_en": "MedRep: Medical Concept Representation for General Electronic Health Record Foundation Models", "authors": "Junmo Kim,Namkyeong Lee,Jiwon Kim,Kwangsoo Kim", "background": "电子健康记录（EHR）基础模型在各种医疗任务中表现出改进的性能，但存在一个基本限制：处理超出词汇表的未知医疗代码，这限制了EHR基础模型的泛化能力和不同词汇表训练的模型的集成。", "innovation": "提出了一种新的基于OMOP通用数据模型（CDM）的医疗概念表示法（MedRep）来解决这一问题。通过大型语言模型（LLM）提示丰富每个概念的信息，并通过OMOP词汇表的图本体补充基于文本的概念表示。研究表明，该方法在各种预测任务中优于传统的EHR基础模型和以前引入的医疗代码分词器模型，同时展示了MedRep的泛化能力。", "conclusion": "MedRep方法在不同的预测任务中表现出色，证明了其在处理未知医疗代码方面的有效性，并展示了其在不同模型之间的泛化能力。"}
{"llm_update_time": "20250816", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2504.05349", "html_url": "https://arxiv.org/abs/2504.05349", "title": "Hyperflux：剪枝揭示权重的重要性", "title_en": "Hyperflux: Pruning Reveals the Importance of Weights", "authors": "Eugen Barbulescu,Antonio Alexoaie,Lucian Busoniu", "background": "在网络研究中，剪枝被用来减少大型神经网络的推断延迟和能耗。然而，目前大多数方法依赖于缺乏深刻理解的启发式方法，其有效性主要通过实验结果验证。该领域缺乏基于理论框架的主动剪枝方法，特别是没有从权重的影响量估计出发的算法。本文旨在填补这一空白，介绍了一种新的剪枝方法Hyperflux，该方法通过权重移除对梯度响应的“流量”来估计每个权重的重要性，同时提供了一个连续促进所有权重向剪枝方向施加压力的机制，并提出了一个可自动恢复对于准确度至关重要的权重的体系。", "innovation": "本研究创新地提出了Hyperflux，这是一种基于“流量”的L0剪枝方法，它通过估计每个权重的重要性来促进剪枝过程中的稀疏度，是一个理论上合理的方法。此外，研究还针对最终稀疏度和剪枝压力之间的关系，推导出一个新的通用缩放定律公式，用于设计稀疏度控制调度器。通过实验，证明在ResNet-50和VGG-19上的CIFAR-10和CIFAR-100数据集上可以达到最好的结果，展现了该方法的有效性。", "conclusion": "本文通过Hyperflux方法揭示了权重的重要性，提出了一种基于流量估计的L0剪枝方法，通过实验验证，展示了在CIFAR-10和CIFAR-100上的最佳结果，并且提出了一种基于流量的稀疏度控制方法。"}
{"llm_update_time": "20250816", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.19794", "html_url": "https://arxiv.org/abs/2506.19794", "title": "开源大语言模型在数据分析方面为何挣扎？一项系统性的实证研究", "title_en": "Why Do Open-Source LLMs Struggle with Data Analysis? A Systematic Empirical Study", "authors": "Yuqi Zhu,Yi Zhong,Jintian Zhang,Ziheng Zhang,Shuofei Qiao,Yujie Luo,Lun Du,Da Zheng,Ningyu Zhang,Huajun Chen", "background": "开源大语言模型（LLMs）在自动化数据分析任务方面具有潜力，但在这些需要大量推理的场景中却面临显著限制。本研究旨在探索提高开源LLMs数据分析能力的方法。", "innovation": "通过构建包含多样且现实场景的种子数据集，评估模型在数据理解、代码生成和战略规划三个核心维度上的表现，并基于分析结果提出数据合成方法，显著提升了开源LLMs的分析推理能力。", "conclusion": "战略规划质量是模型性能的主要决定因素；交互设计和任务复杂性对推理能力有重大影响；数据质量比多样性对实现最佳性能有更大影响。"}
{"llm_update_time": "20250816", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2505.11528", "html_url": "https://arxiv.org/abs/2505.11528", "title": "LaDi-WM：一种基于潜在扩散的世界模型用于预测性操控", "title_en": "LaDi-WM: A Latent Diffusion-based World Model for Predictive Manipulation", "authors": "Yuhang Huang,Jiazhao Zhang,Shilong Zou,Xinwang Liu,Ruizhen Hu,Kai Xu", "background": "预测性操控在具身人工智能社区中受到了广泛关注，因为通过利用预测的状态来改进机器人策略性能具有巨大潜力。然而，从世界模型生成准确的未来视觉状态，特别是在实现高质量的像素级表示方面，仍然是一个难题。", "innovation": "我们提出了LaDi-WM，一种使用扩散建模预测未来状态的潜在空间的世界模型。它利用预训练的视觉基础模型（包括几何特征和语义特征），并通过迭代细化输出动作来生成更为一致和准确的结果。", "conclusion": "在合成和现实世界的基准测试中，LaDi-WM 显著提升了策略性能，分别在 LIBERO-LONG 基准上提升了27.9%，在真实场景中提升了20%。我们的世界模型和策略在现实世界的实验中表现出令人印象深刻的泛化能力。"}
{"llm_update_time": "20250816", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2504.14493", "html_url": "https://arxiv.org/abs/2504.14493", "title": "FinSage：适用于金融申报问答的多方面RAG系统", "title_en": "FinSage: A Multi-aspect RAG System for Financial Filings Question Answering", "authors": "Xinyu Wang,Jijun Chi,Zhenghan Tai,Tung Sum Thomas Kwok,Muzhi Li,Zhuhong Li,Hailin He,Yuchen Hua,Peng Lu,Suyuchen Wang,Yihong Wu,Jerry Huang,Jingrui Tian,Fengran Mo,Yufei Cui,Ling Zhou", "background": "在实际应用环境中利用大型语言模型时，往往需要根据特定领域的数据和工具来遵守复杂的使用规范。特别是金融行业中，企业越来越多地依赖检索增强生成（RAG）系统来处理复杂的合规要求，但由于现有解决方案难以应对多元数据（如文本、表格、图表）的异质性和监管标准的不断变化，导致关键信息提取的准确性受到影响。", "innovation": "FinSage框架引入了三个创新组件：（1）一个多模态预处理流水线，统一了不同的数据格式并生成了片段级别的元数据摘要；（2）一个多路径稀疏-密集检索系统，加入了查询扩展（HyDE）和元数据感知的语义搜索；（3）一个领域专门的重新排名模块，通过直接偏好优化（DPO）微调以优先考虑合规性关键内容。实验结果显示，FinSage在金融基准问题回答数据集上的准确率超过了最佳基线方法24.06%，召回率达到92.51%。", "conclusion": "FinSage已经在在线会议上成功部署为金融查询代理，已为超过1200人提供了服务，显著提升了金融申报相关问题的回答准确性与实用性。"}
{"llm_update_time": "20250816", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2505.14647", "html_url": "https://arxiv.org/abs/2505.14647", "title": "Bilevel优化中的序贯QCQP与线搜索法", "title_en": "Sequential QCQP for Bilevel Optimization with Line Search", "authors": "Sina Sharifi,Erfan Yazdandoost Hamedani,Mahyar Fazlyab", "background": " bilevel优化涉及一个多层级结构的问题，其中一个优化问题嵌套在另一个之中，这导致了上下层级之间的复杂相互依赖。传统方法通常难以处理这种复杂性，容易出现一些困境。研究表明，通过设计有效的算法可以改善这一现状。", "innovation": "本文提出了一种无需调参的单循环算法，能够确保在任何时候满足下层问题的最优条件的同时，确保上层目标函数下降。该算法每次迭代通过求解一个具有闭式解的凸二次约束的二次优化问题（QCQP）来确定搜索方向，接着使用基于控制屏障函数的回退线搜索来确保安全的步长均匀正值。这种方法具有可扩展性，不需要超参数调优，并在较轻的局部光滑假设下收敛。", "conclusion": "本文建立了算法在某种一阶稳定度量下的O(1/k)渐近收敛速率，并通过代表性的bilevel任务验证了算法的有效性。"}
{"llm_update_time": "20250816", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2505.22107", "html_url": "https://arxiv.org/abs/2505.22107", "title": "Transformer for 长文语境建模中的高维度问题", "title_en": "Curse of High Dimensionality Issue in Transformer for Long-context Modeling", "authors": "Shuhai Zhang,Zeng You,Yaofo Chen,Zhiquan Wen,Qianyue Wang,Zhijie Qiu,Yuanqing Li,Mingkui Tan", "background": "基于Transformer的大型语言模型（LLMs）通过自注意力机制捕获长范围依赖关系，在自然语言处理任务中表现出色。然而，在长文上下文建模中，由于自注意力计算的冗余性产生了显著的计算效率问题。尽管注意力权重往往是稀疏的，但所有token仍然消耗等量的计算资源。", "innovation": "本论文重新定义了传统的概率序列建模为监督学习任务，从而实现相关和不相关token的分离，并明确指出冗余性。通过理论分析注意力稀疏性，发现只有少数几个token对预测有显著贡献。基于此，论文提出了基于分组编码优化注意力的方法，提出了一种分组编码策略，展示了其在对抗随机噪声和增强学习效率方面的优势。随后，论文提出了动态分组注意力（DGA）机制，通过在注意力计算过程中聚合较不重要的token，显式的减少了冗余。", "conclusion": "实验结果显示，动态分组注意力显著降低了计算成本，同时保持了竞争力。相关成果发表于论文提供的链接地址。"}
{"llm_update_time": "20250816", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2505.15002", "html_url": "https://arxiv.org/abs/2505.15002", "title": "解析迭代CHAD", "title_en": "Unraveling the iterative CHAD", "authors": "Fernando Lucatelli Nunes,Gordon Plotkin,Matthijs Vákár", "background": "CHAD最初作为一种面向源代码的语义驱动变换，用于完全（终止）函数式程序的反向模式自动差分。这项研究在此基础上，扩展了一系列新的程序特性，如非终止（可能不终止）的操作、数据依赖条件（例如实数测试）和迭代构造（例如while循环），同时保持CHAD的核心原则，即结构保持语义。", "innovation": "引入了迭代广泛的类别索引，为依赖类型编程语言中的迭代提供了原理上的集成。通过要求基础类别的迭代提升到索引类别中的参数化初始代数，形成了迭代结构级别的模型，能够解释while循环和其他迭代构建。最终，通过迭代Freyd范畴，将CHAD变换扩展到循环程序，确保每次原始操作都被映射到其（转置）导数。", "conclusion": "通过语法范畴模型的普遍性质，证明了这一扩展变换的正确性，表明经过转换的程序正确计算了原程序的反向模式导数。"}
{"llm_update_time": "20250816", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.10236", "html_url": "https://arxiv.org/abs/2506.10236", "title": "提示攻击揭示了去学习方法中表面的知识移除", "title_en": "Prompt Attacks Reveal Superficial Knowledge Removal in Unlearning Methods", "authors": "Yeonwoo Jang,Shariqah Hossain,Ashwin Sreevatsa,Diogo Cruz", "background": "该研究探讨了机器去学习方法在面对简明的提示攻击时可能出现的失败情况。研究者系统性地评估了八种去学习技术在三种模型家族中的表现，通过基于输出、logit以及探针分析三种方法来衡量已被认为被去学习的知识的实际可恢复程度。研究发现，尽管一些方法（如RMU和TAR）表现出了较强的去学习能力，部分方法（如ELM）仍然在特定提示攻击下显得脆弱。这些发现挑战了以往认为去学习方法能够有效移除知识的普遍观点，并强调了去学习评估框架的重要性，以便可靠地区分真正的知识移除和表面的输出抑制。为了促进进一步的研究，研究者公开发布了他们的评估框架，以便容易地评估提示技术以检索已被去学习的知识。", "innovation": "研究者提出了系统性评估八种去学习技术在三种模型家族中的表现的方法，通过输出基、logit基和探针分析三种方法来衡量已被认为被去学习的知识的实际可恢复程度。特别地，研究指出在特定提示攻击下，ELM方法仍有漏洞。此外，研究者强调需要开发可靠的去学习评估框架，以区分真正的知识移除和表面的输出抑制。最后，研究设计并公开了可评估提示技术以检索已被去学习的知识的框架。", "conclusion": "研究结果揭示了当前的一些去学习方法在面对特定提示攻击时的局限性，挑战了去学习方法能够有效去除知识的普遍假设，并表明需要开发新的评估框架以更准确地评估去学习的效果。研究结果是去学习领域的重要贡献，为未来的研究提供了基础。"}
{"llm_update_time": "20250816", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.19712", "html_url": "https://arxiv.org/abs/2507.19712", "title": "Oranits: 在基于Open RAN的智能运输系统中使用启发式和深度强化学习进行任务分配和任务卸载", "title_en": "Oranits: Mission Assignment and Task Offloading in Open RAN-based ITS using Metaheuristic and Deep Reinforcement Learning", "authors": "Ngoc Hung Nguyen,Nguyen Van Thieu,Quang-Trung Luu,Anh Tuan Nguyen,Senura Wanasekara,Nguyen Cong Luong,Fatemeh Kavehmadavani,Van-Dinh Nguyen", "background": "现有研究往往忽视任务之间的复杂相互依赖以及将任务卸载到边缘服务器的成本，导致决策不理想。现有的方法没有充分考虑任务依赖性和卸载成本，影响了性能优化。", "innovation": "提出了一种创新的系统模型Oranits，该模型不仅考虑了任务依赖性和卸载成本，还通过车辆合作优化性能。Oranits采用了两步优化方法：首先，提出了一种基于混沌高斯的全局寻优算法CGG-ARO；其次，设计了一个基于奖励的多智能体双深度Q网络MA-DDQN框架，增强了多智能体协调和多动作选择机制。", "conclusion": "模拟结果显示，CGG-ARO将未完成的任务数量和整体收益提高了约7.1%和7.7%。与此同时，MA-DDQN在任务完成率方面提高了11.0%，在整体收益方面提高了12.5%。这些结果证明了Oranits在动态智能运输系统环境中实现更快速、更适应性和更高效的任务处理的有效性。"}
{"llm_update_time": "20250816", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.22493", "html_url": "https://arxiv.org/abs/2506.22493", "title": "关于政治极坐标测验（PCT）的详细因素分析：探索大规模语言模型的意识形态", "title_en": "A Detailed Factor Analysis for the Political Compass Test: Navigating Ideologies of Large Language Models", "authors": "Sadia Kamal,Lalu Prasad Yadav Prakash,S M Rafiuddin,Mohammed Rakib,Atriya Sen,Sagnik Ray Choudhury", "background": "PCT测试或类似问卷已被用来量化LLM的政治倾向。虽然这些测试的有效性已经在最近的一些研究中得到了检验，但这项研究更深入地探讨了标准生成参数的变化对模型PCT得分的影响，以及外部因素如提示变化和微调的影响。研究发现，微调数据集中政治内容的差异对PCT得分没有显著影响，这表明需要进一步研究PCT测试的有效性以及政治倾向在LLM中的编码机制。", "innovation": "研究发现标准生成参数的变化对模型的PCT得分影响不大，但提示变化和微调（单独或组合使用）具有显著影响。另外，当模型在含有较高政治内容的数据集上进行微调时，PCT得分也没有显著差异。这些发现为深入研究PCT和其他类似测试的有效性，以及LLM中政治倾向的编码机制提供了新的视角和依据。", "conclusion": "研究结果表明，需要进一步研究PCT测试的有效性以及政治倾向在LLM中的编码机制。此外，微调数据集中政治内容的差异对PCT得分没有显著影响，这强调了对PCT和其他类似测试的验证是必要的。"}
{"llm_update_time": "20250816", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.08280", "html_url": "https://arxiv.org/abs/2507.08280", "title": "MIRRAMS: 学习在未见缺失性变化下的稳健表征模型", "title_en": "MIRRAMS: Learning Robust Tabular Models under Unseen Missingness Shifts", "authors": "Jihye Lee,Minseo Kang,Dongha Kim", "background": "数据中的缺失值通常反映了数据收集政策的变化，这种变化可能会在时间或地点上有所不同，即使底层特征分布保持稳定也是如此。这种在训练和测试输入之间缺失分布的变化，对实现稳健的预测性能构成了极大挑战。", "innovation": "本文提出了一种新颖的深度学习框架MIRRAMS，以应对这一挑战，特别适用于未见过的数据集。首先，提出了一组基于互信息的条件，称为MI稳健性条件，这些条件指导预测模型提取与标签相关的信息。然后设计了一组简单有效的损失项，称为MIRRAMS，这些项共同定义了最终目标。该方法无需特定的缺失性假设（如MCAR、MAR或MNAR），适用于广泛场景，并且可以拓展到训练数据中标签也缺失的情况，通过将框架推广到半监督学习设置。实验证明MIRRAMS在多个基准表数据集上表现优异，即使在不同的缺失性条件下也能保持稳定的性能。", "conclusion": "MIRRAMS在各种缺失性程度下都能表现出色，即使在完全观察到的情况下也能达到更好的性能，表明MIRRAMS是一个适用于通用表学习的强健且现成的框架。"}
{"llm_update_time": "20250816", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.20871", "html_url": "https://arxiv.org/abs/2507.20871", "title": "FedABC：带有长远视角的基于注意力机制的客户端选择算法在联邦学习中的应用", "title_en": "FedABC: Attention-Based Client Selection for Federated Learning with Long-Term View", "authors": "Wenxuan Ye,Xueli An,Junfan Wang,Xueqiang Yan,Georg Carle", "background": "6G网络演进的关键目标之一是提供原生的人工智能支持。联邦学习（FL）作为一种有前景的方法，允许分散的客户端在不直接共享数据的情况下协作训练AI模型，并且可以保护隐私。在客户端上基于私有数据训练本地模型，并共享模型更新。中央服务器汇总这些更新来优化全球模型，并重新分发给下一个迭代。然而，客户端数据的异质性会影响收敛速度，降低模型精度，并且频繁的客户端参与也会增加通信和计算负担。", "innovation": "我们提出了FedABC，一种创新的客户端选择算法，通过长期视角管理数据异质性并优化客户端参与。该算法借鉴了注意力机制，通过评估模型相似性和每个模型对全球模型的独特贡献来优先选择有信息性的客户端。同时，为满足全局模型的不断发展需求，我们提出了优化问题来引导FedABC训练过程。根据“后期更好”的原则，FedABC能自适应调整客户端选择阈值，使得在训练后期更加积极地参与。", "conclusion": "通过在CIFAR-10上的广泛仿真，FedABC显著优于现有方法，在模型精度和客户端参与效率上表现出色，相比经典的FL算法FedAvg，使用32%更少的客户端即可实现类似性能，在使用2%更少的客户端时比最先进的方法高出3.5%的精度。此项工作朝着将FL部署到异质、资源受限环境的方向迈出了重要一步，从而支持6G网络中的原生人工智能能力。"}
{"llm_update_time": "20250816", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.06639", "html_url": "https://arxiv.org/abs/2507.06639", "title": "EXAONE Path 2.0：带端到端监督的病理学基础模型", "title_en": "EXAONE Path 2.0: Pathology Foundation Model with End-to-End Supervision", "authors": "Myeongjang Pyeon,Janghyeon Lee,Minsoo Lee,Juseung Yun,Hwanil Choi,Jonghyun Kim,Jiwon Kim,Yi Hu,Jongseong Jang,Soonyoung Lee", "background": "在数字病理学中，全层图像（WSIs）因其巨大的像素规模而难以处理，大多数方法通过自我监督学习（SSL）训练小块编码器，然后通过多实例学习（MIL）或滑块编码器进行聚合以进行下游任务。然而，块级SSL可能忽略对于生物标志物预测至关重要的复杂领域特定特征，如突变状态和分子特征，因为SSL方法仅依赖于选择用于自然图像域的基本增强，后者在小块级区域内规模较小。此外，SSL方法的数据效率低于完全监督的方法，需要大量计算资源和数据集才能达到竞争力的性能。", "innovation": "我们提出了EXAONE Path 2.0，这是一种病理学基础模型，在直接的 slide 级监督下学习块级表示。仅使用 37,000 张WSI 训练，EXAONE Path 2.0 在 10 个生物标志物预测任务上实现了最先进的平均性能，显示出显著的数据效率。", "conclusion": "EXAONE Path 2.0 通过直接的 slide 级监督学习块级表示，显著提高了数据效率并实现了竞争力的性能，展示了在医疗图像分析中的重大改进。"}
{"llm_update_time": "20250816", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.05690", "html_url": "https://arxiv.org/abs/2508.05690", "title": "利用大型语言模型进行基于SQL行为的数据库入侵检测", "title_en": "Leveraging large language models for SQL behavior-based database intrusion detection", "authors": "Meital Shlezinger,Shay Akirav,Lei Zhou,Liang Guo,Avi Kessel,Guoliang Li", "background": "数据库系统被广泛用于存储各个领域的关键数据，但异常数据库访问行为的频率，如来自内部和外部攻击的入侵行为，持续上升。内部伪装者通常拥有更深刻机构知识，能够更容易地模仿员工行为。相比之下，外部伪装者由于对组织不熟悉，可能会表现出不同行为。当前的方法缺乏在网络操作层面检测异常所需的精细度，往往误将整个操作序列分类为异常，即使大多数操作很可能代表正常行为。此外，一些异常行为可能与正常活动相似，使得现有检测方法难以辨识。", "innovation": "本文提出了一种基于结构化查询语言(SQL)的两层异常检测方法，使用Bidirectional Encoder Representations from Transformers (BERT)模型的DistilBERT版本，该模型是一种更高效、已训练的版本。该方法结合了无监督和有监督机器学习技术，以精确识别异常活动并减少对数据标注的依赖。首先，无监督方法使用集成异常检测器标记远离典型用户数据库行为的嵌入向量(超出范围的查询)。其次，有监督方法使用微调的变压器模型检测内部攻击，使用角色标记分类，即使在有限的标记SQL数据上也能实现高精度(在范围内的查询)。", "conclusion": "研究发现为保护关键数据库系统免受复杂威胁提供了一个有效的解决方案。"}
{"llm_update_time": "20250816", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.08285", "html_url": "https://arxiv.org/abs/2508.08285", "title": "在幻觉检测中的进步错觉：重新评估LLMs中的幻觉检测", "title_en": "The Illusion of Progress: Re-evaluating Hallucination Detection in LLMs", "authors": "Denis Janiak,Jakub Binkowski,Albert Sawczyn,Bogdan Gabrys,Ravid Shwartz-Ziv,Tomasz Kajdanowicz", "background": "大语言模型（LLMs）在自然语言处理领域已经取得了重大突破，但它们的幻觉倾向为可靠部署带来了严重挑战。尽管存在多种幻觉检测方法，但它们的评估通常依赖于基于词汇重叠的ROUGE指标，这与人类判断不一致。", "innovation": "该研究通过全面的人类研究，展示了ROUGE表现出较高的召回率，但其极低的精确率导致了误导性的性能估测。此外，研究发现基于响应长度的简单启发式方法能够与复杂的检测技术相抗衡，揭示了当前评估实践中存在的根本缺陷。研究强调采用语义感知且稳健的评估框架对于准确评估幻觉检测方法的真实性能至关重要，确保LLMs输出的可信度。", "conclusion": "采用语义认知和稳健的评估框架是准确评估幻觉检测方法真实性能的关键，最终确保LLMs输出的可靠性。"}
{"llm_update_time": "20250816", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.05294", "html_url": "https://arxiv.org/abs/2508.05294", "title": "迈向具身体现的主动性AI：基于大规模语言模型和视觉语言模型的机器人自主性与交互的综述与分类", "title_en": "Towards Embodied Agentic AI: Review and Classification of LLM- and VLM-Driven Robot Autonomy and Interaction", "authors": "Sahar Salimpour,Lei Fu,Farhad Keramat,Leonardo Militano,Giovanni Toffetti,Harry Edelman,Jorge Peña Queralta", "background": "大规模语言模型（LLMs）和视觉语言模型（VLMs）的发展为机器人自主性和人机交互提供了新颖的方法。同时，视觉语言动作模型（VLAs）或大型行为模型（LBMs）提高了机器人系统的灵活性和能力。本文综述了这些工作如何朝着主动型应用和架构发展，包括初始探索GPT风格的工具接口以及更复杂的系统，其中AI代理可以作为协调者、规划者、感知行为者或通用接口。此类主动型架构使机器人能够处理自然语言指令、调用API、规划任务序列以及参与操作和诊断工作。我们还重点关注了由于领域快速发展而出现的社区驱动项目、ROS包和工业框架，这些趋势展示了新兴的动向。本文提出了一种模型整合方法的分类体系，并对当前文献中代理在不同解决方案中的作用进行了比较分析。", "innovation": "文章聚焦于基于大规模语言模型（LLMs）和视觉语言模型（VLMs）的机器人自主性和人机交互领域的发展和应用，特别是其在机器人新手法中的作用及其背后的主动型架构。文章提出了模型整合方法的分类体系，并对代理在当前多个解决方案中的具体作用进行了对比分析。同时，文章还展示了社区驱动项目、ROS包和工业框架等趋势，以反映该领域的最新进展和趋势。", "conclusion": "本文对机器人自主与交互的主动型架构进行了综合分析，提出了分类体系，并对未来研究方向提出了建议，同时强调了快速发展领域的新兴趋势。"}
{"llm_update_time": "20250816", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2508.10068", "html_url": "https://arxiv.org/abs/2508.10068", "title": "Saracoder: Orchestrating Semantic and Structural Cues for Profit-Oriented Repository-Level Code Completion", "title_en": "SaraCoder: Orchestrating Semantic and Structural Cues for Profit-Oriented Repository-Level Code Completion", "authors": "Xiaohan Chen,Zhongying Pan,Quan Feng,Yu Tian,Shuqun Yang,Mengru Wang,Lina Gong,Yuxia Geng,Piji Li,Xiang Chen", "background": "现有的基于 Retrieval-Augmented Generation (RAG) 的代码补全方法依赖于浅层次的文本相似性，导致结果存在语义误导、冗余性和同质性问题，同时也无法解决外部符号的歧义。", "innovation": "Saracoder 引入了一个分层特征优化检索框架，其核心模块通过系统化提炼深层语义关系，去除精确重复项，并使用基于图的新颖度量评估结构相似性，按拓扑重要性加权差异，重新排序结果以最大化相关性和多样性。此外，它还通过依赖分析准确解决了跨文件符号的歧义。", "conclusion": "Saracoder 在 CrossCodeEval 和 RepoEval-Updated 挑战基准测试中显著优于现有基线，适用于多种编程语言和模型，证明了系统化在多个维度上精炼检索结果是构建更准确和稳健的代码补全系统的新范式。"}
{"llm_update_time": "20250816", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.06406", "html_url": "https://arxiv.org/abs/2508.06406", "title": "Blockchain-Enabled Federated Learning", "title_en": "Blockchain-Enabled Federated Learning", "authors": "Murtaza Rangwala,KR Venugopal,Rajkumar Buyya", "background": "区块链赋能的联邦学习（BCFL）解决了协作人工智能系统中的信任、隐私和协调的基本挑战。BCFL系统提供了一个完整的架构分析，通过系统地四维度分类框架，探讨了协调结构、共识机制、存储架构和信任模型。分析了从区块链验证的集中协调设计到完全去中心化的点对点网络的设计模式，评估了可扩展性、安全性和性能之间的权衡。详细分析了用于联邦学习环境的多种共识机制，包括质量和联邦学习的证明机制，展示了如何将计算工作从任意加密难题重新用于生产性的机器学习任务。该章节解决了关键的存储挑战，通过研究多层次架构来平衡区块链交易限制与神经网络的大量参数要求，同时保持了加密完整性。通过分布式图像分类训练的技术案例研究表明，分布式形象分类训练能够在物联网设备上实现高效协作学习，具有高度非IID数据分布，同时保持完全透明和容错能力。", "innovation": "介绍了区块链赋能的联邦学习（BCFL）系统的研究，通过系统地四维度分类框架，全面分析了BCFL系统的架构，探讨了协调结构、共识机制、存储架构和信任模型。特别分析了优化的共识机制，如质量证明和联邦学习证明，展示如何将计算工作从任意加密难题重新用于生产性的机器学习任务。通过多层次架构设计平衡区块链交易约束与神经网络参数要求，确保系统的加密完整性。提供了一个实际案例研究，使用分布式图像分类训练来展示在物联网设备上实现高效协作学习的方法。实证研究证明了在医疗联盟、金融服务和IoT安全应用中的可行性，性能与中央化方法相当，提供了增强的安全保障，并开启了信任无中介的协作智能新模型的可能性。", "conclusion": "该章节通过详细分析BCFL系统的研究验证了其在现实世界部署中的有效性，能够实现性能与中央化方法相当的同时，还提供了更强的安全保障，并且能够开放新的信任无中介协作智能的新模型，表明了BCFL具有广泛的应用前景。"}
{"llm_update_time": "20250816", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2508.10074", "html_url": "https://arxiv.org/abs/2508.10074", "title": "Next Edit Prediction: 学习根据上下文和交互历史预测代码编辑", "title_en": "Next Edit Prediction: Learning to Predict Code Edits from Context and Interaction History", "authors": "Ruofan Lu,Yintong Huo,Meng Zhang,Yichen Li,Michael R. Lyu", "background": "随着大型语言模型（LLMs）的快速进步，AI 编程助手已在开发环境中广泛应用。一方面，低延迟的代码补全功能可以提供完成建议，但其本质上只能限制在光标当前位置。另一方面，基于对话的编辑功能可以执行复杂修改，然而这迫使开发者中断工作，用自然语言描述意图，从而引发从代码的思路切换。这导致用户体验欠佳，因为这两种模式都无法积极预测开发者在一系列相关编辑中的下一个编辑。", "innovation": "本文提出了一项新的任务——Next Edit Prediction，旨在通过分析最近的交互历史来推断开发者的意图，以预测后续编辑的位置和内容。通过精心制作监督微调数据集和评估基准，作者在一系列模型上进行了监督微调，并对微调模型和其他基准模型进行了全面评估。这项工作为新的交互模式奠定了基础，该模式能够主动与开发者协作，预见他们的后续行为，而不仅仅是对明确指令做出反应。", "conclusion": "通过这项工作，作者为 Next Edit Prediction 任务奠定了基础，这一任务能够根据最近的上下文和交互历史预测代码编辑，进而提供无缝的代码编辑建议。研究结果显示了几个新颖的发现，为未来的开发工具提供了新的发展方向。"}
{"llm_update_time": "20250816", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.08855", "html_url": "https://arxiv.org/abs/2508.08855", "title": "BiasGym: 如何发现并移除大型语言模型中的偏差", "title_en": "BiasGym: Fantastic LLM Biases and How to Find (and Remove) Them", "authors": "Sekh Mainul Islam,Nadav Borenstein,Siddhesh Milind Pawar,Haeun Yu,Arnav Arora,Isabelle Augenstein", "background": "理解大型语言模型（LLMs）权重中嵌入的偏见和刻板印象对于开发有效的缓解策略至关重要。偏见行为往往是微妙且难以隔离的，即使在故意诱发时也是如此，这使得系统的分析和去偏变得尤为困难。", "innovation": "我们引入了BiasGym，这是一种简单、成本效益高且可推广的框架，用于可靠地注入、分析和减轻LLMs中的概念关联。BiasGym包括两个组件：BiasInject，使用基于标记的微调将特定偏见注入模型而不解冻模型；以及BiasScope，利用这些注入的信号来识别并引导负责偏见行为的组件。该方法使我们能够一致地激发偏差用于机制性分析，支持在不牺牲下游任务性能的情况下进行有针对性的去偏，并且在基于标记的微调时泛化到未见过的偏差。", "conclusion": "BiasGym在减少真实世界刻板印象（例如，意大利人被认为是‘鲁莽司机’）和探索虚构关联（例如，来自虚构国家的人有‘蓝色皮肤’）方面的有效性得到了展示，表明它对于安全干预和解释性研究都有用处。"}
{"llm_update_time": "20250816", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2508.10059", "html_url": "https://arxiv.org/abs/2508.10059", "title": "FormalGrad: 将形式方法与基于梯度的LLM优化结合", "title_en": "FormalGrad: Integrating Formal Methods with Gradient-Based LLM Refinement", "authors": "Yueke Zhang,Yifan Zhang,Kevin Leach,Yu Huang", "background": "尽管大规模语言模型（LLMs）在代码生成方面表现出色，但它们通常生成的解决方案缺乏正确性、鲁棒性和效率的保证。在需要严格约束的领域，这一局限性尤为明显。FormalGrad 提出了一种原理性的框架，将形式方法直接整合到迭代的基于LLM的生成循环中。该框架独特地将代码视为可微变量，将结构化反馈和形式约束转换为文本伪梯度，从而指导模型逐步优化解决方案，确保不仅具有功能性，还具有鲁棒性和形式上的正当性。", "innovation": "FormalGrad 引入了一种原理性的框架，将形式方法直接整合到迭代的基于LLM的生成循环中，使代码成为可微变量，并将结构化反馈和形式约束转化为文本伪梯度，用于指导模型逐步优化解决方案，确保生成的代码不仅具有功能性，还具有鲁棒性和形式上的正当性。评估结果显示，与强大的基线相比，FormalGrad 的实现提高了HumanEval上的绝对改进27%，并使挑战性的LiveCodeBench V6提高了41%的相对改进。", "conclusion": "FormalGrad 生成了被形式方法验证的、鲁棒且高效的代码，为在高风险应用场景中可靠的人工智能辅助软件开发铺平了道路。"}
{"llm_update_time": "20250816", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2508.10852", "html_url": "https://arxiv.org/abs/2508.10852", "title": "EVOSCAT：探索大规模历史数据中的软件变更动力学", "title_en": "EVOSCAT: Exploring Software Change Dynamics in Large-Scale Historical Datasets", "authors": "Souhaila Serbout,Diana Carolina Muñoz Hurtado,Hassan Atwi,Edoardo Riggio,Cesare Pautasso", "background": "长寿命的软件项目包含大量的代码和其他软件构件，这些构件在其生命周期中经历了多次修订。软件工程的实证研究者收集了成千上万的事件数据集，这些数据集反映了对特定构件的变化。然而，对于如此庞大的数据集来说，传统的可视化工具难以提供对大量历史数据的全局概览。因此，有必要开发一种新的工具来帮助研究人员分析大量数据，并提供对软件演变的理解。", "innovation": "本文提出了一种名为EvoScat的工具，旨在通过使用交互式密度散点图来提高时间上的可扩展性，以提供单一可视化中来自开源代码库的大规模历史数据集的全局视图。该工具支持灵活的历史时间轴对齐、构件排序和交互式颜色映射，能够处理成百万的事件，这些事件源自成千上万个软件构件的历史。", "conclusion": "EvoScat可以根据具体的分析需求进行定制（如变更速度比较、克隆检测、新鲜度评估），其支持灵活的历史时间轴对齐、构件排序和交互式颜色映射，能够分析从成千上万个软件构件的历史中获取的成百万的事件。本文还包括一个作品集，展示了跨越多个仓库的数据集，以及特定流行开源项目的详细历史记录。"}
{"llm_update_time": "20250816", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2508.09991", "html_url": "https://arxiv.org/abs/2508.09991", "title": "结合AI创新与医疗需求：在BC癌症登记处引入现代NLP的经验教训", "title_en": "Bridging AI Innovation and Healthcare Needs: Lessons Learned from Incorporating Modern NLP at The BC Cancer Registry", "authors": "Lovedeep Gondara,Gregory Arbour,Raymond Ng,Jonathan Simkin,Shebnum Devji", "background": "自动化临床文档中的数据提取在医疗保健环境中具有提高效率的潜力，但实施自然语言处理（NLP）解决方案面临实际挑战。本文基于在不列颠哥伦比亚癌症登记处（BCCR）实施各种NLP模型进行信息提取和分类任务的经验，分享了项目全生命周期中的关键教训。文中强调了定义问题时应基于清晰的业务目标，而非仅关注技术准确性的重要性，以及开发过程中采用迭代方法和跨学科深度合作和共同设计的基本内容。", "innovation": "文章强调了定义问题时应基于清晰的业务目标，而非仅关注技术准确性的重要性；开发过程中采用迭代方法；并强调了跨学科深度合作和共同设计，涉及领域专家、终端用户和机器学习专家。此外，文章还指出了实务上必须精心挑选模型（包括混合方法和适当简化方法），对数据质量（代表性、漂移、注释）给予适当的关注，采用人工在环中的验证和持续审核来实现稳健的错误缓解策略，以及建设组织AI素养。", "conclusion": "本文提供的实际考虑因素具有广泛的适用性，适用于超越癌症登记处的医疗保健组织，为成功实施AI/NLP解决方案以改进数据管理流程并最终改善患者护理和公共卫生结果提供了指导。"}
{"llm_update_time": "20250816", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2508.10111", "html_url": "https://arxiv.org/abs/2508.10111", "title": "使用上下文无关文法的扩散LLM约束解码", "title_en": "Constrained Decoding of Diffusion LLMs with Context-Free Grammars", "authors": "Niels Mündler,Jasper Dekoninck,Martin Vechev", "background": "大规模语言模型（LLMs）在多个领域展示出了有前景的表现。许多LLM的实际应用，如代码补全和结构化数据提取，需要遵循由形式语言规定的语法规则。然而，由于LLM的随机生成特性，其输出不能保证满足这些形式语言。先前的研究提出了受限解码作为一种方法，以限制LLM生成的内容符合特定形式语言的要求。然而，现有的技术在使用扩散LLM生成正确形式的C++或JSON输出时并不适用。本文聚焦于这一挑战，首次提出了适用于扩散模型且能处理由上下文无关文法捕获的形式语言的受限解码方法。", "innovation": "本文将受限解码问题转化为更广泛的加性填补问题，提出了一种方法，可以解决由上下文无关文法捕获的形式语言的受限解码问题。具体而言，问题被转化为判定目标语言和正则语言的交集是否为空，并提出了高效的算法来解决这一问题。实验结果表明，该方法在实现近乎完美的语法正确性的同时，还能保持甚至提高功能正确性。此外，效率优化确保了计算开销是可行的。", "conclusion": "本研究提出了一种全新的受限解码方法，适用于基于扩散模型及由上下文无关文法描述的正式语言的场景。该方法在多个应用中展示出了优秀的语法和功能表现，且在计算效率上取得了显著的优化。"}
{"llm_update_time": "20250816", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2302.11617", "html_url": "https://arxiv.org/abs/2302.11617", "title": "Cloud本本化应用程序治理的参考架构", "title_en": "A Reference Architecture for Governance of Cloud Native Applications", "authors": "William Pourmajidi,Lei Zhang,John Steinbacher,Tony Erwin,Andriy Miranskyy", "background": "云 computing 的演变催生了 Cloud Native Applications (CNAs)，提出了新的治理挑战，特别是对于那些面临严格合规要求的企业。本文研究了 CNAs 的独特特征以及这些特征对治理的影响。", "innovation": "本文提出了一种全面的参考架构，旨在简化 CNAs 跨境的治理流程，并提供了一个示例实现，可以帮助单云和多云环境中的举措。该架构在 CNAs 框架内无缝集成治理，并遵循“开箱即用”的理念。该设计既适用于不同行业的广泛及紧凑型 CNAs 部署，还为学术界关于通用 CNAs 架构的探讨提供了基石，突显了它们在不断演进的云计算领域中的重要性。", "conclusion": "该设计使得云从业者能够优先进行产品开发，同时克服治理的复杂性。作为一种通用 CNAs 架构的基础构架，它还能够为学术界关于此类架构的进一步研究提供支持。"}
{"llm_update_time": "20250816", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2508.10517", "html_url": "https://arxiv.org/abs/2508.10517", "title": "强化 Solidity 演化差距：增强 LLM 的智能合约编译错误解决方法", "title_en": "Bridging Solidity Evolution Gaps: An LLM-Enhanced Approach for Smart Contract Compilation Error Resolution", "authors": "Likai Ye,Mengliang Li,Dehai Zhao,Jiamou Sun,Xiaoxue Ren", "background": "Solidity 作为以太坊的主要智能合约语言，由于频繁的版本更新以增强安全、功能性和开发者体验而迅速发展。然而，这种不断的变更也带来了重大的挑战，特别是在编译错误、代码迁移和维护方面。因此，本文通过实证研究探讨 Solidity 版本演变中的挑战，并发现 81.68% 的检查合同在不同版本之间编译时遇到错误，86.92% 的是编译错误。为解决这些挑战，研究人员系统地评估了大型语言模型（LLMs）在智能合约版本迁移期间解决 Solidity 编译错误的能力。尽管这些模型展示了错误修复能力，但对于语义级别问题的有效性显著下降，并且对提示工程策略表现出强烈的依赖性。这突显了开发可靠 LLM 基础的错误修复系统的领域特定适应性的重要性。", "innovation": "该研究提出了一种名为 SMCFIXER 的新型框架，该框架系统地结合了专家知识检索与基于 LLM 的修复机制，以解决 Solidity 编译错误。SMCFIXER 的架构包括三个核心阶段：（1）上下文感知代码切片以提取相关错误信息；（2）从官方文档中检索专家知识；及（3）迭代生成以适应 Solidity 迁移的补丁。实验验证表明，与基线 GPT-4o 相比，该方法在实际数据集上的统计显著性提升达到 24.24%，并在 96.97% 的情况下实现了近乎完美的准确率。", "conclusion": "本文通过实证研究揭示了 Solidity 版本演变中的挑战，并提出了一种增强的 LLM 方法，以解决智能合约编译错误。实验证明，SMCFIXER 框架在解决 Solidity 编译错误方面取得了显著的效果，强调了开发领域特定的 LLM 错误修复系统的必要性。"}
{"llm_update_time": "20250816", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2508.10157", "html_url": "https://arxiv.org/abs/2508.10157", "title": "Hugging Face预训练语言模型与其上游GitHub仓库之间的同步研究", "title_en": "On the synchronization between Hugging Face pre-trained language models and their upstream GitHub repository", "authors": "Ajibode Adekunle,Abdul Ali Bangash,Bram Adams,Ahmed E. Hassan", "background": "预训练语言模型（PTLMs）在自然语言处理（NLP）中取得了显著进展，使得文本生成和翻译等任务取得进步。这些模型像软件包管理一样，通过上游仓库（如GitHub，GH）中的代码和环境脚本进行训练，并通过下游平台（如Hugging Face，HF）分发不同的变体。然而，协调GH和HF之间的开发活动存在挑战，如发布时间的不一致、版本控制的不统一和PTLM变体重用有限的问题。本研究通过分析325个PTLM家族（共计904个HF变体）的提交活动，探讨了协调开发活动的方法。研究发现，GH贡献者通常专注于模型版本的指定、代码质量的改进、性能优化和依赖管理，而HF贡献者则专注于模型描述的改进、数据处理和模型推理所需环境的设置。我们的分析揭示了八种独特的同步模式，其中部分同步模式如分散同步和稀疏同步极为普遍，这反映了跨平台发布实践中的结构断层。这些模式会导致孤立的变更，即将某平台的改进或修复从未在另一个平台上复制，有时甚至表明了一个仓库被另一个取代的风险。这可能导致终端用户接触到不完整、过时或行为不一致的模型。因此，识别这些同步模式对于改进PTLM发布工作流程中的监督和可追溯性至关重要。", "innovation": "本研究采用混合方法对Hugging Face的预训练语言模型及其上游GitHub仓库之间的提交活动进行了综合分析，揭示了八种独特的同步模式，包括分散同步和稀疏同步，这些模式反映了当前跨平台发布实践中存在的结构断层，填补了现有研究的空白。研究通过识别孤岛变更和同步风险提出了改进措施。", "conclusion": "该研究揭示了Hugging Face的预训练语言模型及其上游GitHub仓库之间的八种独特同步模式，部分同步模式如分散同步和稀疏同步导致孤立变更和潜在的仓库替代风险。因此，理解和识别这些模式对于改进PTLM发布工作流程中的监督和可追溯性至关重要，将有助于提高软件包管理的一致性和完整性。"}
{"llm_update_time": "20250816", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2401.16382", "html_url": "https://arxiv.org/abs/2401.16382", "title": "基于MAPE-K的方法以确保自我适应系统的架构一致性", "title_en": "A MAPE-K-Based Method for Architectural Conformance Checking in Self-Adaptive Systems", "authors": "Daniel San Martín,Guisella Angulo,Valter Vieira de Camargo", "background": "自我适应系统(SASs)在关键领域（如医疗、金融、自动驾驶和智慧城市）中得到广泛应用。确保这类系统的架构可信性对于维持系统的稳定性和长期品质至关重要。由于SAS架构本身非常复杂，MAPE-K等参考模型被提议来指导其设计，强调反馈回路作为核心组件。尽管MAPE-K规定了提高系统可维护性、可理解性和符合性的抽象和通信规则，但是维护活动通常会引入偏差，导致架构磨损和与参考模型不一致性。架构一致性检查（ACC）通过验证系统实现是否与计划架构（PA）或参考模型（如MAPE-K）一致来解决这一问题。", "innovation": "本研究提出了一种针对SAS的定制化ACC方法——REMEDY，包括三个关键组件：(i) 基于MAPE-K抽象的特定领域语言(DSL)用于指定计划架构；(ii) 用于恢复系统当前架构(CA)的工具；(iii) 用于检测和可视化架构偏差的合规性检查过程。REMEDY针对SAS的DSL与通用DSL进行了比较，证明了更高的生产和精确度的架构描述能力。此外，REMEDY有效地识别和促进了不合规问题的纠正，从而提高了自我适应系统的可维护性和架构可信性。", "conclusion": "REMEDY是针对SAS的定制ACC方法，通过使用特定领域语言、恢复当前架构和进行合规性检查来有效提高系统的可维护性与架构可信性。该方法通过与通用DSL进行比较，展示了在架构描述方面的优势，并通过有效识别和纠正不合规问题进一步改进系统的质量。"}
{"llm_update_time": "20250816", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2508.10017", "html_url": "https://arxiv.org/abs/2508.10017", "title": "使用SMOTETomek和FedProx的稳健Differentially Private Federated Learning管道", "title_en": "A Robust Pipeline for Differentially Private Federated Learning on Imbalanced Clinical Data using SMOTETomek and FedProx", "authors": "Rodrigo Tertulino", "background": "联邦学习（FL）为协作健康研究提供了一种突破性的方法，可以在不集中的数据上进行模型训练，同时保护患者隐私。FL与差分隐私（DP）结合使用时，可以提供正式的安全保证。然而，这两种技术的结合引入了隐私和临床效用之间的重大权衡，尤其是在医疗数据中经常存在的严重类别不平衡的情况下，这一问题变得更加复杂。这项研究通过系统的多阶段分析解决了这些相互关联的问题。在心血管风险预测中实施了一个FL框架，初始实验表明，标准方法难以处理不平衡的数据，导致召回率为零。为了克服这一限制，我们首先在客户端层面整合了合成少数过采样技术与Tomek Links（SMOTETomek），成功开发了一个具有临床用途的模型。随后，使用调整后的FedProx算法优化了框架以处理非IID数据。最终结果表明，在隐私预算（ε）和模型召回率之间存在明显的非线性权衡，优化后的FedProx在所有标准的FedAvg方面表现更佳。在隐私-效用前沿中识别出一个最优操作区域，在此区域中，可以实现强大的隐私保护（ε 9.0）的同时保持高临床效用（召回率大于77%）", "innovation": "通过结合使用合成少数过采样技术与Tomek Links（SMOTETomek）和调整的FedProx算法来解决联邦学习在处理不平衡医疗数据时面临的隐私与临床效用之间的权衡问题。优化后的FedProx算法在所有标准的FedAvg方面表现出更佳的性能，并识别出在隐私保护与临床效用之间的最优操作区域，实现了强大的隐私保证和高临床效果", "conclusion": "本研究提供了一种实用的方法论蓝图，用于创建有效、安全和准确的诊断工具，适用于现实世界中的异质医疗数据"}
{"llm_update_time": "20250816", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2502.10374", "html_url": "https://arxiv.org/abs/2502.10374", "title": "生物医学基础模型的稳健性测试应符合规范", "title_en": "Robustness tests for biomedical foundation models should tailor to specifications", "authors": "R. Patrick Xian,Noah R. Baker,Tom David,Qiming Cui,A. Jay Holmgren,Stefan Bauer,Madhumita Sushil,Reza Abbasi-Asl", "background": "生物医学领域的基础模型由于功能广泛且对复杂分布变化敏感，使得模型测试和授权面临新的挑战。因此，需要针对任务优先级定制稳健性测试，并在预定义规范中集成细化的稳健性概念，以指导实施，这有助于模型生命周期中的标准稳健性评估，并将抽象的人工智能监管框架与具体的测试程序相连接。", "innovation": "本文建议根据任务依赖性定制稳健性测试，并在预定义的规范中集成具体的稳健性概念，以指导实施。这种方法促进了模型生命周期中稳健性评估的标准，并建立了从抽象的人工智能监管框架到具体测试程序的连接。", "conclusion": "本文的方法通过定制化稳健性测试和在规范中集成细化的稳健性概念，为生物医学基础模型的开发和监管提供了一个标准化的框架，有助于提高模型的安全性和可靠性。"}
{"llm_update_time": "20250816", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2408.07321", "html_url": "https://arxiv.org/abs/2408.07321", "title": "VERCATION：基于静态分析和LLM的精确开源软件漏洞版本识别", "title_en": "VERCATION: Precise Vulnerable Open-source Software Version Identification based on Static Analysis and LLM", "authors": "Yiran Cheng,Ting Zhang,Lwin Khin Shar,Shouguo Yang,Chaopeng Dong,David Lo,Shichao Lv,Zhiqiang Shi,Limin Sun", "background": "开源软件（OSS）因为其协作开发模式和成本效益而变得越来越受欢迎。然而，在发展项目中采用特定的软件版本可能会引入安全风险，因为这些版本可能带有漏洞。当前用于识别潜在脆弱版本的方法通常会通过使用预定义规则的静态分析来分析和提取漏洞补丁中的代码特征，然后使用代码克隆检测来识别脆弱的版本。尽管现有方法有所改进，但它们仍受制于不精确性，主要原因在于分析中排除了与漏洞无关的代码以及代码克隆检测能力的局限性。", "innovation": "本文提出了VERCATION，这是一种结合程序切片和大型语言模型（LLM）来识别C/C++编写开源软件中与漏洞相关代码的方法。VERCATION通过回溯历史提交来收集已识别的漏洞相关代码的先前修改。我们提出了一种基于扩展和归一化抽象语法树（AST）的代码克隆检测方法，来比较预先修改的代码和后修改代码之间的差异，从而找到引入漏洞的提交（vic），并能够识别在漏洞修复提交和vic之间的脆弱版本。在所构建的数据集中，该方法取得了93.1%的F1分数，比现有最先进的方法表现更佳。此外，VERCATION检测到了202个NVD报告中不正确的漏洞开源软件版本。", "conclusion": "VERCATION在解决现有方法不精确的问题上实现了重大突破，通过结合程序切片和大型语言模型来识别C/C++编写的开源软件中的潜在脆弱版本。它的表现不仅优于当前最先进的方法，并且能够更精确地检测到NVD报告中的不正确版本。"}
{"llm_update_time": "20250816", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2507.06762", "html_url": "https://arxiv.org/abs/2507.06762", "title": "使用大型语言模型生成测试检测语义冲突", "title_en": "Detecção de Conflitos Semânticos com Testes Gerados por LLM", "authors": "Nathalia Barbosa(1),Paulo Borba(1),Léuson Da Silva(2) ((1) Centro de Informática, Universidade Federal de Pernambuco, Brasil, (2) Polytechnique Montreal, Canadá)", "background": "语义冲突在软件开发中是一个常见的问题，当一个开发者对代码库进行更改时，这些更改可能会无意中影响其他开发者并行集成的更改的行为。传统的合并工具无法检测这些冲突，因此引入了辅助工具如SMAT（Semantic Merge Assistance Tool）。SMAT通过生成和执行单元测试来工作：如果测试在基版本上失败但对某个开发者修改后的版本通过了，并且在合并了另一个开发者的变化后再次失败，则表明存在语义冲突。尽管SMAT有效，但它在生成测试时存在较高的假阴性率，部分原因是受单位测试生成工具如Randoop和Evosuite的限制。为了研究是否可以通过使用大型语言模型（LLMs）来克服这些限制，提出并整合了基于Code Llama 70B的新测试生成工具作为SMAT的扩展。", "innovation": "提出了一种基于大型语言模型生成测试的SMAT扩展，通过不同的交互策略、提示内容和参数配置来探索模型生成测试的能力。实验证明，尽管基于大型语言模型的测试生成在复杂场景下面临挑战且计算成本高昂，但在提高语义冲突检测方面展现出潜力。", "conclusion": "尽管基于大型语言模型的测试生成在复杂场景下计算成本高且易错，但在提高语义冲突检测方面拥有可观的潜力。通过这种新方法能够帮助开发人员更精准地检测并解决代码合并过程中的语义冲突问题，提高了开发效率和代码质量。"}
{"llm_update_time": "20250816", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2507.10535", "html_url": "https://arxiv.org/abs/2507.10535", "title": "CodeJudgeBench：用于编程任务的LLM-as-a-Judge基准", "title_en": "CodeJudgeBench: Benchmarking LLM-as-a-Judge for Coding Tasks", "authors": "Hongchao Jiang,Yiming Chen,Yushi Cao,Hung-yi Lee,Robby T. Tan", "background": "大型语言模型（LLMs）在各种编码任务上达到了前所未有的水平。除了直接回答用户查询外，LLMs还可以作为评判者，评估和比较其他模型生成的响应的质量。这种评估能力对于不同LLM的基准测试以及通过响应排名提高响应质量至关重要。尽管LLM-as-a-Judge模式的采用不断增长，但在编程场景中的有效性仍因缺乏专门的基准工具而未被充分探索。为了填补这一空白，我们引入了CodeJudgeBench，这是一个专门设计用于评估LLM-as-a-Judge模型性能的基准，涵盖三种关键的编程任务：代码生成、代码修复和单元测试生成。", "innovation": "我们通过全面测试26种LLM-as-a-Judge模型，发现近期的思维模型在这类精心设计的代码评估任务中显著优于非思维模型。甚至相对较小的思维模型，如Qwen3-8B，也能超越大到70B参数的专门训练的LLM-as-a-Judge模型。此外，我们研究了LLM-as-a-Judge的最佳提示策略，并发现使用两两对比优于单一的比例衡量判断。保留LLM完整未处理响应中的注释和推理也有助于提高评判性能。", "conclusion": "尽管近期的思维模型在编程任务评估中表现出色，但所有模型在评判编程任务时仍表现出显著的随机性。在两两评判任务中，响应呈现顺序的变化会对准确率产生重大影响。当评判不同LLM编写的代码和单元测试时，LLM-as-a-Judge模型也显示出性能差异。这表明LLM-as-a-Judge在编程场景中的可靠性和一致性有待提高。我们的研究结果为进一步优化LLM-as-a-Judge模型和提示策略提供了宝贵的见解。"}
{"llm_update_time": "20250816", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2507.21817", "html_url": "https://arxiv.org/abs/2507.21817", "title": "越界之外，前景堪忧：基于漏洞数据集训练的语言模型在检测Top 25 CWE弱点方面表现如何？", "title_en": "Out of Distribution, Out of Luck: How Well Can LLMs Trained on Vulnerability Datasets Detect Top 25 CWE Weaknesses?", "authors": "Yikun Li,Ngoc Tan Bui,Ting Zhang,Martin Weyssow,Chengran Yang,Xin Zhou,Jinfeng Jiang,Junkai Chen,Huihui Huang,Huu Hung Nguyen,Chiok Yew Ho,Jie Tan,Ruiyin Li,Yide Yin,Han Wei Ang,Frank Liauw,Eng Lieh Ouh,Lwin Khin Shar,David Lo", "background": "自动化漏洞检测研究虽然取得了显著进展，但其在现实世界中的影响仍然有限。现有的漏洞数据集存在标签准确性低（20-71%之间）、大量重复以及关键CWE类型覆盖不足等问题。这些问题导致模型在自我测试（使用训练数据集外的数据进行测试）中表现出色，但这通常是通过利用虚假相关性而不是学习真实的漏洞模式实现的。模型在独立数据集上的性能往往大幅下降，甚至接近随机猜测。因此，迫切需要解决这些局限性，提升模型在真实世界中的泛化能力.", "innovation": "本文提出了一个三步解决方案。首先，引入了BenchVul数据集，该数据集由手动整理而成，包含了MITRE Top 25最危险的CWE类型。其次，构建了高质量的训练数据集TitanVul，包含38,863个函数，通过聚合七个公共资源，并利用新型多代理LLM框架进行了去重和验证。最后，提出了一个名为RVG的现实漏洞生成框架，该框架通过模拟开发工作流生成上下文相关的漏洞示例，弥补了关键CWE类型的不足。评估结果显示，各组件在填补泛化差距方面各有所长，尤其是加入RVG生成的数据后，模型性能提升了14.0%至0.874.", "conclusion": "我们的研究表明，算法模型在使用改进后的数据集及加入模拟漏洞数据后，可以显著提高泛化能力。BenchVul数据集证明了现有自测试数据集的局限性，TitanVul的使用展示了更出色的泛化性能，而RVG的补充进一步提高了模型的性能。"}
