{"llm_update_time": "20251101", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.25883", "html_url": "https://arxiv.org/abs/2510.25883", "title": "信息论先验：压缩与智能的认知基础", "title_en": "The Information-Theoretic Imperative: Compression and the Epistemic Foundations of Intelligence", "authors": "Christian Dittrich,Jennifer Flygare Kinne", "background": "现有的框架普遍认为压缩是智能的核心，但没有具体解释为什么压缩过程能够发现因果结构而非表面的相关模式。该研究旨在填补这一空白。", "innovation": "该研究提出了一个两阶段框架，包括信息论先验（ITI）和压缩效率原则（CEP），分别解释了为什么生存压力和信息处理需求通过压缩联系起来，以及高效压缩如何机械地选择生成性因果模型。", "conclusion": "ITI和CEP定义了一个因果链：从生存压力到预测需求，压缩需求，效率优化，最终生成性结构发现，直至现实对齐。研究预测，压缩效率、表征复杂性的代谢成本等指标可以作为智能系统有效性的指标。"}
{"llm_update_time": "20251101", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.25951", "html_url": "https://arxiv.org/abs/2510.25951", "title": "基于注意力意识逆规划的认知偏差估计", "title_en": "Estimating cognitive biases with attention-aware inverse planning", "authors": "Sounak Banerjee,Daphne Cornelisse,Deepak Gopinath,Emily Sumner,Jonathan DeCastro,Guy Rosman,Eugene Vinitsky,Mark K. Ho", "background": "人类的目标导向行为受到认知偏见的影响，因此与人类互动的自主系统应当考虑这一因素。例如，人们的注意力会对他们在环境中的注意力发生系统性偏见，影响他们日常生活中的任务，如通勤驾驶。本文基于计算认知科学的最新成果，正式描述了基于注意力的逆规划问题，旨在从人的行为中估计其注意力偏差。", "innovation": "本文提出了基于注意力意识逆规划的方法，该方法结合了深度强化学习和计算认知建模，用于从行为中推断出参与现实生活驾驶情景的强化学习代理的注意力策略，并展示了基于注意力意识逆规划估计认知偏见的扩展性。", "conclusion": "本文通过基于注意力意识逆规划的方法，在实际驾驶场景（来自Waymo Open Dataset）中推断出强化学习代理的注意力策略，证明了基于注意力意识逆规划估计认知偏见的可行性与高效性。"}
{"llm_update_time": "20251101", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.25813", "html_url": "https://arxiv.org/abs/2510.25813", "title": "An Agentic Framework for Rapid Deployment of Edge AI Solutions in Industry 5.0", "title_en": "An Agentic Framework for Rapid Deployment of Edge AI Solutions in Industry 5.0", "authors": "Jorge Martinez-Gil,Mario Pichler,Nefeli Bountouni,Sotiris Koussouris,Marielena Márquez Barreiro,Sergio Gusmeroli", "background": "随着工业5.0的发展，AI模型的边缘部署成为一项挑战。现有的边缘AI解决方案通常存在延迟高、依赖外部数据传输等问题，这限制了实时处理能力。为了应对这一挑战，需要一种能够简化部署过程，减少延迟并支持模块化集成的框架来支持工业环境中的边缘AI应用。", "innovation": "本文提出了一种基于代理的新框架，用于在工业5.0环境中简化边缘设备上AI模型的部署。该框架通过启用本地推理和实时处理来缩短延迟，并通过代理机制实现任务的灵活分配，简化了集成过程。此外，这种框架还具有模块化集成和低资源需求的特点，可以更好地适应工业环境下的各种需求。", "conclusion": "初步实现在食品行业的评估结果显示，该框架能够提高部署时间和系统适应性表现。源代码已经公开展示，为其它工业应用场景提供了参考和借鉴。"}
{"llm_update_time": "20251101", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.25884", "html_url": "https://arxiv.org/abs/2510.25884", "title": "使用多评判员学习系统近似人类偏好", "title_en": "Approximating Human Preferences Using a Multi-Judge Learned System", "authors": "Eitán Sprejer,Fernando Avalos,Augusto Bernardi,Jose Pedro Brito de Azevedo Faustino,Jacob Haimes,Narmeen Fatimah Oozeer", "background": "语言模型（LLM）作为基于代理的裁判难以校准，并且通常会受到评分标准敏感性、偏见和不稳定性的影响。克服这一挑战对于实现可靠的人工反馈强化学习（RLHF）奖励模型和构建有效的路由系统（选择最适合用户查询的模型）等关键应用至关重要。", "innovation": "本文提出了一种框架，通过学习多个评分标准调节裁判的输出来建模多元化的、基于角色的偏好。该方法在人类和LLM裁判偏见的案例研究中，与简单基线进行了性能对比，并通过这两个维度评估了该方法的鲁棒性。主要贡献包括一个基于角色的方法来大规模合成偏好标签，以及两种不同的聚合器实现：广义加性模型（GAM）和多层感知器（MLP）。", "conclusion": "本文通过使用基于角色的偏好合成方法以及两种不同聚合器（GAM和MLP），有效解决了LLM裁判与人类偏好之间的校准问题，提升了RLHF等实际应用的效果。"}
{"llm_update_time": "20251101", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.25820", "html_url": "https://arxiv.org/abs/2510.25820", "title": "符号化支持的玩乐：为生成NPC对话设计角色敏感提示", "title_en": "Symbolically Scaffolded Play: Designing Role-Sensitive Prompts for Generative NPC Dialogue", "authors": "Vanessa Figueiredo,David Elumeze", "background": "大型语言模型（LLMs）有望通过使非玩家角色（NPCs）能够维持未编写脚本的对话来变革互动游戏。然而，限制性提示是否实际上改善了玩家体验仍然不清楚。作者通过一个基于GPT-4o的语音驱动侦探游戏《访谈》（The Interview），进行了一项用户测试研究，比较了高限制（HCP）和低限制（LCP）提示，结果显示除了技术问题的敏感性外，没有发现可靠的经验差异。", "innovation": "研究提出了一个新的框架——符号化支持的玩乐（Symbolically Scaffolded Play），该框架通过使用模糊的数值边界来表达符号结构，既稳定了关键部分的连贯性，又保留了惊喜的可玩性，以改善NPC对话的创造力和角色性。", "conclusion": "研究表明，更严格的约束未必会提升游戏体验，提示的设计需要考虑到角色的特性。通过引入符号化支持的理念，该研究提出了一个框架来设计角色敏感的提示，这可以用来指导生成NPC对话的设计，确保对话既连贯又具有创造性和真实性。"}
{"llm_update_time": "20251101", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.25860", "html_url": "https://arxiv.org/abs/2510.25860", "title": "通过法官的视角：推断出的思想痕迹提高LLM评分者的可靠性", "title_en": "Through the Judge's Eyes: Inferred Thinking Traces Improve Reliability of LLM Raters", "authors": "Xingjian Zhang,Tianhong Gao,Suliang Jin,Tianhao Wang,Teng Ye,Eytan Adar,Qiaozhu Mei", "background": "大型语言模型（LLMs）在评估任务中越来越多地充当评分者角色，但在涉及超出标注标签的细微推理的主观任务中，它们的可靠性常常受限。这使得收集和整理支撑判断的思维痕迹变得极具挑战性。本文提出了一种人类-LLM协作框架，从仅有的标签中推断出思维痕迹，以增强LLM评分者的可靠性。", "innovation": "提出了一种人类-LLM协作框架，通过简单的拒绝抽样方法在大规模条件下重构思维痕迹。利用推断出的思维痕迹对开放LLM评分者进行微调，并生成更清晰的注释指南，从而提高了LLM评分者与人类评分者之间的协议性，增加了不同LLM模型之间的协议性。研究结果表明，LLMs可以作为实际代理来推断出未被揭示的人类思维痕迹，使仅标签的数据集能够扩展为增加LLM评分者可靠性的思维痕迹增强资源。", "conclusion": "本文方法显著提高了LLM与人类评分者的协议性，并通过生成更清晰的注释指南进一步提高了不同LLM模型之间的协议性，表明LLM评分者成为推断人类思维痕迹的实用代理的可能性。"}
{"llm_update_time": "20251101", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.25914", "html_url": "https://arxiv.org/abs/2510.25914", "title": "FinOps 代理 —— IT 基础设施和成本优化的用例", "title_en": "FinOps Agent -- A Use-Case for IT Infrastructure and Cost Optimization", "authors": "Ngoc Phuoc An Vo,Manish Kesarwani,Ruchi Mahindru,Chandrasekhar Narayanaswami", "background": "FinOps 是一种通过工程、财务和业务团队之间的协作财务责任制来最大化云业务价值的运营框架和文化实践。FinOps 实践者面临一个根本性的挑战：来自多个云提供商和内部系统的收费数据以异构格式、分类和指标到达，最终导致难以综合出可操作的见解并做出时间敏感的决定。", "innovation": "本文提出了利用自主、目标驱动的人工智能代理来自动化 FinOps。我们构建了一个针对典型的 IT 基础设施和成本优化用例的 FinOps 代理。我们构建了一个系统，该系统从各种来源获取数据，然后对数据进行汇总和分析以生成优化建议。通过使用多个开源和闭源的自然语言模型对我们的代理进行评估，结果表明该代理能够理解、计划和执行任务，与实际的 FinOps 实践者相当。", "conclusion": "我们提出了一个自动化 FinOps 的方法，证明了代理能够理解、制定计划并执行任务。使用多种语言模型评估系统，表明我们的系统可以有效地解决 FinOps 实践者面临的复杂数据和决策挑战，为 IT 基础设施和成本优化提供了有效的支持。"}
{"llm_update_time": "20251101", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.25908", "html_url": "https://arxiv.org/abs/2510.25908", "title": "SciTrust 2.0: Large Language模型在科学应用中的全面评估框架", "title_en": "SciTrust 2.0: A Comprehensive Framework for Evaluating Trustworthiness of Large Language Models in Scientific Applications", "authors": "Emily Herron,Junqi Yin,Feiyi Wang", "background": "大型语言模型（LLMs）在科学研究中的应用具有变革性潜力，但它们在高风险环境中的部署引发了重大可信度问题。为了应对这一挑战，本文提出了SciTrust 2.0，这是一个全面的框架，用于在科学应用中评估LLM的可信度。", "innovation": "SciTrust 2.0框架提出了四个维度来评估LLM的可信度：真实性和准确性、对抗鲁棒性、科学安全性和科学伦理。这个框架包括通过验证的反射调优管道和专家验证开发的新型开放性真实度基准，以及针对科学研究情境的新型伦理基准，涵盖八个子类别，包括双重用途研究和偏见。此外，该框架使用多种评估指标，包括准确性和语义相似性度量，来评估七个主流的LLM在每个可信度维度的表现。", "conclusion": "总体而言，通用行业模型在每个可信度维度上优于专门科学模型，特别是在真实性和对抗鲁棒性评估中。科学特殊化模型在逻辑和伦理推理能力方面存在显著缺陷，并在安全性评估中表现出重大漏洞，特别是在生物安全和化学武器等高风险领域。通过开源这个框架，本文为开发更可信的AI系统提供了基础，并为推动科学背景下模型安全性和伦理的研究奠定了基础。"}
{"llm_update_time": "20251101", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.25933", "html_url": "https://arxiv.org/abs/2510.25933", "title": "Humains-Junior: 通过定向外骨骼推理实现GPT-4o级事实准确性的3.8B语言模型", "title_en": "Humains-Junior: A 3.8B Language Model Achieving GPT-4o-Level Factual Accuracy by Directed Exoskeleton Reasoning", "authors": "Nissan Yaron,Dan Bystritsky,Ben-Etzion Yaron", "background": "该研究背景涉及语言模型的效能提升，特别是专注于事实推理能力。与之前的研究相比，研究者们试图开发一个更小的且具有成本效益的语言模型，以达到类似GPT-4o的高准确率.", "innovation": "文章的创新点在于，提出了一种使用最小定向“外骨骼推理”构架与行为微调相结合的方法，这种方法主要用于提升模型的协议合规性和学科知识。研究发现，单纯的行为微调效果不佳，但与“外骨骼推理”结合后，效果显著提升，同时减少了结果的变异性。此外，所提出的模型在云服务上的价格大约是GPT-4o的19倍低，且在自主托管或边缘部署的情况下，边际成本可以接近于零。", "conclusion": "研究得出，一个3.8亿参数的模型在事实推理准确性上达到了与GPT-4o相似的水平，且成本显著降低。这种方法在前沿模型上也显示出改进效果，未来可以进一步探索在不同环境下的效能。"}
{"llm_update_time": "20251101", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.25775", "html_url": "https://arxiv.org/abs/2510.25775", "title": "使用SHAP实现棋局逐子解释", "title_en": "Towards Piece-by-Piece Explanations for Chess Positions with SHAP", "authors": "Francesco Spinnato", "background": "当前的象棋引擎提供了精确但不透明的评估结果，通常以百位分的形式表示。虽然这些结果在决策中有效，但它们隐藏了单个棋子或模式的贡献。在这项研究中，作者探索了将SHAP（SHapley Additive exPlanations）应用于象棋分析领域，旨在将象棋引擎的评估归因于特定的棋盘位置上的棋子。这种方法借鉴了经典象棋教学中的理念，即通过在心理上移除棋子来评估局势，并结合现代可解释的人工智能技术。这种方法为象棋的可视化、人类培训和引擎比较提供了新的可能性。文章还发布了相关代码和数据，以促进未来在可解释的象棋人工智能方面的研究。", "innovation": "利用SHAP（SHapley Additive exPlanations）方法来将象棋引擎的评估归因于特定的棋盘位置上的棋子。这种方法借鉴了经典象棋教学中的理念，并结合了现代可解释的人工智能技术。这种新的方法为象棋的可视化、人类培训和引擎比较提供了新的可能性。除了理论上的创新，作者还开放了相关代码和数据，支持更多研究者进行进一步的研究。", "conclusion": "该方法打开了全新的可能性，包括象棋的可视化、人类培训和引擎比较。同时，作者还开放了相关代码和数据，以促进未来在可解释的人工智能领域的研究。"}
{"llm_update_time": "20251101", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.26136", "html_url": "https://arxiv.org/abs/2510.26136", "title": "超越基准：AI推理的经济学", "title_en": "Beyond Benchmarks: The Economics of AI Inference", "authors": "Boqin Zhuang,Jiacheng Qiao,Mingqian Liu,Mingxing Yu,Ping Hong,Rui Li,Xiaoxia Song,Xiangjun Xu,Xu Chen,Yaoyao Ma,Yujie Gao", "background": "大型语言模型（LLMs）的推理成本已成为影响其商业可行性和广泛应用的关键因素。本文通过引入一个量化的推理经济学框架，首次系统地分析了LLM推理过程的成本、规模经济及其产出质量，为模型部署决策提供了经济基础，并为未来基于市场的AI推理资源定价与优化奠定了实证基础.", "innovation": "提出了一个量化的推理经济学框架，将LLM推理视为由计算驱动的智能生产活动，分析了其边际成本、规模收益递减和产出质量，并基于WiNEval-3.0的数据构建了首个‘LLM推理生产前沿’，揭示出三点原则：边际成本递减、规模收益递减以及最优的成本效益区.", "conclusion": "本文不仅为模型部署提供了经济依据，还为未来基于市场的AI推理资源定价和优化奠定了实证基础."}
{"llm_update_time": "20251101", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.26023", "html_url": "https://arxiv.org/abs/2510.26023", "title": "大型语言模型辅助的自动驾驶车辆从停滞中恢复", "title_en": "Large Language Model-assisted Autonomous Vehicle Recovery from Immobilization", "authors": "Zhipeng Bao,Qianwen Li", "background": "尽管近年来在自动驾驶车辆（AVs）领域取得了显著进展，但在某些交通场景中，车辆仍然无法像人类驾驶员一样应对，导致车辆停留在原地，影响交通流畅。目前的恢复解决方案，如远程干预（成本高且效率低）和手动接管（不包括非驾驶员，限制了AV的可访问性），都不尽如人意。", "innovation": "该论文提出了一个名为StuckSolver的新型大型语言模型（LLM）驱动的恢复框架，能够使AVs通过自我推理和/或乘客指导的决策来解决停滞情况。该框架作为现有的感知-计划-控制堆栈的插件模块运行，不需要修改其内部架构，而是通过与标准传感器数据流交互来检测停滞状态、解释环境上下文并生成高级恢复命令，以便由AV的原生规划器执行。", "conclusion": "实验结果表明，StuckSolver仅通过自主自我推理即可实现接近最先进的性能，并且在引入乘客指导时表现出进一步的改善。"}
{"llm_update_time": "20251101", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.26057", "html_url": "https://arxiv.org/abs/2510.26057", "title": "AI可以问责吗？", "title_en": "Can AI be Accountable?", "authors": "Andrew L. Kun", "background": "人工智能极其强大且其能力正在迅速提升。若要充分发挥人工智能的价值，服务于消费者、选民和决策者的需求，确保其问责性是至关重要的。一般来说，一个实体如果可以被某个论坛要求提供关于其行为的信息、与其讨论这些信息，甚至可以对其施加制裁，则该实体是在该论坛下的问责状态。当前许多人工智能缺乏问责性，意味着我们无法对其进行质疑、讨论或制裁。这篇论文旨在定义AI的问责性，探讨其问责性和非问责性的含义，并研究提高所有受影响人工智能的问责性的方法。", "innovation": "论文提出并定义了AI的问责性，探讨了实现AI问责性的方法，并强调了实现这种问责性的重要性，其目的在于通过研究和实践来提升未来人工智能的透明度和可靠性，确保其行为受到监督。", "conclusion": "论文总结了关于AI问责性的研究，指出了当前存在的问题，并提出了改进措施，使所有受影响的AI都能被问责，从而更好地服务于社会和公众。"}
{"llm_update_time": "20251101", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.26012", "html_url": "https://arxiv.org/abs/2510.26012", "title": "AutoSurvey2：赋予研究人员下一代自动化文献综述的能力", "title_en": "AutoSurvey2: Empowering Researchers with Next Level Automated Literature Surveys", "authors": "Siyi Wu,Chiaxin Liang,Ziqian Bi,Leyi Zhao,Tianyang Wang,Junhao Song,Yichao Zhang,Keyu Chen,Xinyuan Song", "background": "随着研究文献的快速增长，尤其是大型语言模型（LLMs）领域的快速发展，编撰全面且及时的文献综述变得越来越困难。现有的文献综述方法面临着难以跟上快速变化的科研动态的挑战，难以确保技术的全面性和准确性。", "innovation": "该论文提出了AutoSurvey2，一种多阶段的自动化文献综述生成流水线，通过检索增强合成和结构化评估实现自动化。该系统结合了并行章节生成、迭代优化以及实时检索最新文章的功能，以确保主题完整性和事实准确性。使用多LLM评估框架评估质量，涵盖覆盖度、结构和相关性等方面，以符合专家评审标准。实验结果显示，AutoSurvey2在结构连贯性和主题相关性方面优于现有的基于检索和自动化的基准方法，同时保持了强有力的引文准确性。", "conclusion": "通过将检索、推理和自动评估结合为一个统一框架，AutoSurvey2提供了一种可扩展和可重复的解决方案，用于生成长格式的学术综述，并为进一步的自动学术写作研究奠定坚实的基础。完整的代码和资源可以在该网址下载：this https URL."}
{"llm_update_time": "20251101", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.26143", "html_url": "https://arxiv.org/abs/2510.26143", "title": "从数学启发广泛的大语言模型推理课程", "title_en": "Reasoning Curriculum: Bootstrapping Broad LLM Reasoning from Math", "authors": "Bo Pang,Deqian Kong,Silvio Savarese,Caiming Xiong,Yingbo Zhou", "background": "强化学习（RL）能够激发大语言模型（LLMs）的强大推理能力，但大多数公开的努力主要集中在数学和代码领域。本文提出了一种简单的两阶段课程，首先在与预训练对齐的领域（如数学）中激发推理能力，然后通过联合强化学习跨其他领域适应并巩固这些技能。该课程简单且模型无关，只需标准验证性检查之外的少量专门奖励模型。该方法在Qwen3-4B和Llama-3.1-8B上进行了评估，并在多领域综合测试中表现出一致的进步。", "innovation": "提出了一种简单的两阶段课程，通过数学问题的强化学习初步训练，然后在混合域数据上进行联合强化学习以转移和巩固这些技能。该课程简单且模型无关，不需要专门的奖励模型，只需标准验证性检查。通过对Qwen3-4B和Llama-3.1-8B的评估和消融实验表明，这种课程对于提高大语言模型的推理能力是非常有效的，并且数学先驱训练可以提高解决复杂问题所需的认知行为。", "conclusion": "推理课程提供了一种紧凑且易于采用的通用推理配方，可以在多种领域的数据上进行联合强化学习，从而提高大语言模型的推理能力，并且两种阶段都是必要的，数学优先的初始训练增加了解决复杂问题所需的重要认知行为。"}
{"llm_update_time": "20251101", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.25997", "html_url": "https://arxiv.org/abs/2510.25997", "title": "从查询到洞见：基于代理的大模型管道在时空文本到SQL方面的应用", "title_en": "From Queries to Insights: Agentic LLM Pipelines for Spatio-Temporal Text-to-SQL", "authors": "Manu Redd,Tao Zhe,Dongjie Wang", "background": "自然语言到SQL（NL-to-SQL）系统有潜力使访问结构化数据变得普及，允许用户无需学习SQL即可查询数据库。然而，现有系统在处理具有现实意义的空间和时间查询时遇到了困难，这些查询的成功需要将模糊的用户表达方式与特定于数据库的类别对齐，处理时间推理，并选择适当的输出。现有系统，如llama-3-sqlcoder-8b，难以应对这些挑战，与其相反，本文提出了一种代理管道，通过Mistral基础的ReAct代理对基础模型进行扩展，该代理能够通过模式检查、SQL生成、执行和可视化工具进行规划、分解和适应查询。该论文通过在纽约和东京检查点数据集上的35个自然语言查询进行评估，展示了所提出方法在时空推理以及多数据集推理方面的优势。尽管基础模型已显示出一定成效，但与之相比，所提出的代理系统显著提高了查询准确性，并通过地图、图表和结构化的自然语言摘要增强了易用性。这对于不具备SQL专业知识、详细模式知识或提示技能的用户尤为重要，更具人性化的数据库交互设计是一种潜在的互动地理空间助手的基础。", "innovation": "本文提出了一种代理管道方法，该方法扩展了基础的文本到SQL模型（llama-3-sqlcoder-8b），通过Mistral基础的ReAct代理进行规划、分解、适应查询，并通过SQL生成、执行和可视化工具提升了查询的有效性。这种方法显著提高了查询的准确性，并通过地图、图表和结构化的自然语言摘要增强了易用性。关键在于设计使交互更加自然，支持缺乏SQL专业知识、详细数据库模式知识或提示技能的用户。", "conclusion": "本文的研究表明，代理管道的协调，而不是仅仅依赖强大的SQL生成器，可能是构建互动地理空间助手的有前途的基础。这种方法能够支持那些没有SQL背景、不了解详细数据库模式或不擅长编写查询的用户。代理管道提供了一种新的视角，改进了用户与数据库之间的互动，特别是在处理时空查询时具有更高的灵活性和准确性。"}
{"llm_update_time": "20251101", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.26144", "html_url": "https://arxiv.org/abs/2510.26144", "title": "FM Agent", "title_en": "The FM Agent", "authors": "Annan Li,Chufan Wu,Zengle Ge,Yee Hin Chong,Zhinan Hou,Lizhe Cao,Cheng Ju,Jianmin Wu,Huaiming Li,Haobo Zhang,Shenghao Feng,Mo Zhao,Fengzhi Qiu,Rui Yang,Mengmeng Zhang,Wenyi Zhu,Yingying Sun,Quan Sun,Shunhao Yan,Danyu Liu,Dawei Yin,Dou Shen", "background": "大型语言模型（LLMs）正在推动自主AI研究代理在科学和工程发现中的发展。我们介绍了一种名为FM Agent的新型通用多代理框架，该框架结合了LLM推理和大规模进化搜索，以应对复杂的现实世界挑战。FM Agent的核心部分集成了多个关键创新：1）冷启动初始化阶段结合专家指导；2）一种迭代优化的新型进化采样策略；3）结合正确性、有效性以及LLM监督反馈的特定领域评估器；4）基于Ray构建的分布式异步执行基础设施。我们的系统已经在不同的领域进行了评估，包括运筹学、机器学习、GPU内核优化和经典数学问题。FM Agent在多个基准测试中达到了最先进的结果，无需人工解释或调优。", "innovation": "FM Agent结合了LLM推理和大规模进化搜索，提出了一种冷启动初始化阶段、新型进化采样策略、特定领域评估器和基于Ray的分布式异步执行基础设施。这些创新方法有效地解决了复杂现实世界中的挑战，展示了广泛的应用性。", "conclusion": "FM Agent已经在不同的领域展示了显著的性能，达到了新的最先进的结果。它在学术基准测试中的表现凸显了其在大规模企业研发工作流程和基础科学研究中的潜力，能够加速创新、自动化复杂的发现过程，并带来广泛的社会影响和工程、科学进步。"}
{"llm_update_time": "20251101", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.26167", "html_url": "https://arxiv.org/abs/2510.26167", "title": "One Model to Critique Them All: Rewarding Agentic Tool-Use via Efficient Reasoning", "title_en": "One Model to Critique Them All: Rewarding Agentic Tool-Use via Efficient Reasoning", "authors": "Renhao Li,Jianhong Tu,Yang Su,Hamid Alinejad-Rokny,Derek F. Wong,Junyang Lin,Min Yang", "background": "奖励模型（RMs）在使大型语言模型（LLMs）与人类偏好保持一致方面发挥着重要作用。然而，在工具学习领域，缺乏专门针对函数调用任务的RMs限制了实现更强大的代理性AI的进步。为了应对这一挑战，作者引入了一种名为ToolRM的轻量级生成型奖励模型，专门针对一般工具使用场景。为此，作者提出了一种新的数据构建流水线，使用基于规则的评分和多维采样来构建成对偏好数据。由此得到了ToolPref-Pairwise-30K数据集，该数据集涵盖了批判性任务，支持具有验证反馈的强化学习。", "innovation": "作者提出了ToolRM，一种专门针对工具使用场景的轻量级生成奖励模型。通过新的数据构建流水线，该流水线利用基于规则的评分和多维采样来生成成对偏好数据。这产生了ToolPref-Pairwise-30K数据集，该数据集包含了批判性任务，适用于具有验证反馈的强化学习。此外，作者还开发了TRBench$_{BFCL}$作为代理评估套件BFCL的基础，构建了一个评价工具使用RMs的基准。基于构建的数据训练的模型在成对奖励判断中表现优于前沿模型Claude 4和OpenAI o3。", "conclusion": "该模型不仅在训练目标上表现出色，还可以泛化到更广泛的批判任务和Best-of-N采样及自我纠正等方面。通过ACEBench实验，作者展示了其有效性和效率，提升了推理时间缩放能力和减少了输出标记使用超过66%。作者还提供了数据和模型检查点，以促进未来研究。"}
{"llm_update_time": "20251101", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.26098", "html_url": "https://arxiv.org/abs/2510.26098", "title": "GUI 知识基：揭示 VLM 在 GUI 任务中失败的知识空白", "title_en": "GUI Knowledge Bench: Revealing the Knowledge Gap Behind VLM Failures in GUI Tasks", "authors": "Chenrui Shi,Zedong Yu,Zhi Gao,Ruining Feng,Enqi Liu,Yuwei Wu,Yunde Jia,Liuyu Xiang,Zhaofeng He,Qing Li", "background": "大型视觉语言模型（VLMs）在自动化图形用户界面（GUI）任务方面取得了进步，但仍未能达到人类的表现。现有的训练方法（如监督微调和强化学习）无法完全解决这一差距。研究者通过分析GUI任务执行中的常见失败模式，将GUI知识归纳为三大维度：界面感知、交互预测和指令理解，并构建了GUI知识基准（GUI Knowledge Bench），涵盖六个平台和292个应用的多项选择和是/非问题。实验显示，当前的VLMs在识别控件功能方面表现良好，但在感知系统状态、预测行动和验证任务完成方面存在困难。实证研究进一步证实了GUI知识与任务成功之间的紧密联系。这项工作通过提供对GUI知识的结构化评估框架，支持前方微调前对具有更大潜力的VLMs的选择，并为构建更强大的GUI代理提供了见解。", "innovation": "提出了GUI知识基准（GUI Knowledge Bench），该基准涵盖多个选择题和是否题，涉及六个平台和292个应用。研究发现，当前的VLMs在感知系统状态、预测行动和验证任务完成方面存在困难。实证研究进一步证实了GUI知识与任务成功之间的紧密联系。通过对GUI知识的结构化评估框架，支持了选择具有更大潜力的VLMs以进行后续训练，并为构建更强大的GUI代理提供了见解。", "conclusion": "本工作通过提供对GUI知识的结构化评估框架，支持了选择具有更大潜力的VLMs以进行后续训练，并为构建更强大的GUI代理提供了见解。"}
{"llm_update_time": "20251101", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.26094", "html_url": "https://arxiv.org/abs/2510.26094", "title": "Lean4Physics: Comprehensive Reasoning Framework for College-level Physics in Lean4", "title_en": "Lean4Physics: Comprehensive Reasoning Framework for College-level Physics in Lean4", "authors": "Yuxin Li,Minghao Liu,Ruida Wang,Wenzhao Ji,Zhitao He,Rui Pan,Junming Huang,Tong Zhang,Yi R. Fung", "background": "该研究背景在于提供一种用于大学水平物理问题推理的综合框架，特别是在Lean4中实现的框架。目前已经存在的一些研究成果主要是关于数学证明工具和物理推理的初步尝试，但缺乏一个专门针对大学水平物理问题的基准测试和公共库，这限制了自动推理工具在物理领域的应用与发展。因此，该研究旨在构建一个全面的框架，包括一个基准测试套件和一个包含基础单位系统和关键定理的公共库，以促进物理推理的自动化。", "innovation": "该研究的主要创新点包括：1) 首次提出了Lean4PHYS，一个用于大学物理问题推理的综合框架；2) 构建了一个包含200个经过手工制作并同行评审的物理推理陈述的基准测试套件，这些陈述源自大学教材和物理竞赛题目；3) 首次提供了一个专为物理推理设计的开源库（PhysLib），包含基础单位系统和定理，用于支持形式化物理推理；4) 通过基准测试和软件模型比较，展示了基准测试的挑战性以及开源库的效用，这表明之前的研究可能尚未完全解决此类问题。", "conclusion": "研究发现，尽管现有的自动推理工具在基准测试中表现有限，最好的DeepSeek-Prover-V2-7B模型仅达到了16%的性能，Claude-Sonnet-4则为35%，但通过引入PhysLib，自动推理模型的性能平均提高了11.75%，这突显了基准测试的挑战性和PhysLib的有效性。这是首个专注于Lean4中的大学物理推理基准测试和开源库的研究，为进一步推进自动物理推理和验证奠定了基础。"}
{"llm_update_time": "20251101", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.26270", "html_url": "https://arxiv.org/abs/2510.26270", "title": "在LLM代理训练中的图增强策略优化", "title_en": "Graph-Enhanced Policy Optimization in LLM Agent Training", "authors": "Jiazhen Yuan,Wei Zhao,Zhengbiao Bai", "background": "群组基于强化学习（RL）在复杂的推理和数学任务上取得了显著成果，但在用于训练多轮交互的LLM代理时，这些方法往往表现出结构盲视，即无法利用环境的基础连接性，这导致了三个关键问题：（1）无效的、无指导的探索，（2）由于忽视了关键状态而导致精确度偏低的信用分配，（3）由于静态奖励折现导致的短视的规划。", "innovation": "提出了一种名为Graph-Enhanced Policy Optimization（GEPO）的方法，该方法动态构建从代理经验中生成的状态转换图，并使用图理论中心度来提供三种协同的学习信号：（1）结构化的内在奖励，引导探索向高影响状态，（2）图增强的优势函数，实现拓扑感知的信用分配，（3）动态适应每个状态的战略价值的折扣因子。在ALFWorld、WebShop和一个自有的Workbench基准测试中，GEPO表现出强大的性能，与竞争性的基线相比绝对成功率提高了4.1%、5.3%和10.9%。", "conclusion": "结果表明，明确建模环境结构是一种稳健的、可泛化的策略，用于推进LLM代理的训练。"}
{"llm_update_time": "20251101", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.26238", "html_url": "https://arxiv.org/abs/2510.26238", "title": "问卷遇上大语言模型：结构技能理解问题与回答基准与实证研究", "title_en": "Questionnaire meets LLM: A Benchmark and Empirical Study of Structural Skills for Understanding Questions and Responses", "authors": "Duc-Hai Nguyen,Vijayakumar Nanjappan,Barry O'Sullivan,Hoang D. Nguyen", "background": "每天都有数以百万计的人参与各种调查，从市场调查和学术研究到医疗问卷和客户反馈表。这些数据集捕获了宝贵的信息，但由于其规模和结构，为大型语言模型（LLMs）带来了独特挑战。尽管LLMs擅长开放文本的少样本推理，但它们处理问卷数据或跨数百个受访样本的问题列表的能力仍然较少被探索。现有的调查检索和分析工具（例如Qualtrics、SPSS、REDCap）通常设计用于工作流程中的人类，限制了这些数据与LLM和AI驱动的自动化集成。因此，科学家、调查员和普通用户缺少基于证据的指导，以最佳地表示问卷以便LLM使用。由于市场上缺乏专门处理此类工作流程的任务和提示方法，研究和实践均受限。", "innovation": "该研究通过引入QASU（Questionnaire Analysis and Structural Understanding），一个基准测试，对六种结构技能进行了测试，涵盖了从答案查找、受访者计数到多步推理的各方面。实验表明，选择有效的格式和提示组合可以将准确性提高至8.8%。对于特定任务，适度添加轻量级结构提示（如自我增强的提示）可在平均上提高3-4%。该开源基准通过系统隔离格式和提示效果，提供了一个简单且多功能的基础，以促进基于大语言模型的问卷分析研究和实践的发展。", "conclusion": "QASU基准提供了一个简单但是灵活的基础，结合格式和提示的影响，可促进大语言模型在问卷分析领域的研究和实际应用。基于当前实验的结果，选择最佳格式和提示组合能够显著提高问卷分析的准确度，并且通过精细的结构提示可进一步优化特定任务的绩效。"}
{"llm_update_time": "20251101", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.26242", "html_url": "https://arxiv.org/abs/2510.26242", "title": "基于检索增强生成的增强分布式大语言模型代理实现通用交通信号控制以支持紧急车辆", "title_en": "Retrieval Augmented Generation-Enhanced Distributed LLM Agents for Generalizable Traffic Signal Control with Emergency Vehicles", "authors": "Xinhang Li,Qing Guo,Junyu Chen,Zheng Guo,Shengzhe Xu,Lei Li,Lin Zhang", "background": "随着城市交通复杂性的增加，交通信号控制（TSC）对于优化交通流量和提高道路安全至关重要。然而，现有的大规模语言模型（LLMs）在紧急情况下容易出现幻觉，导致不稳定的决策，影响紧急车辆的正常运行。而且，由于不同类型的交叉口使得交通状态编码和交叉口间训练存在大量挑战，这限制了在不同交叉口中的一般化应用。因此，本文提出了一种适用于通用交通信号控制的增强检索生成（RAG）分布式大语言模型代理（REG-TSC），应用于支持紧急车辆场景中。", "innovation": "本文主要创新点包括：1）一种基于应急应对的应急意识推理框架，可以根据紧急情况动态调整推理深度，并利用一种新颖的Reviewers-based Emergency RAG (RERAG) 来从历史案例中提取特定的知识和指导，以增强代理的应急决策的可靠性与理性；2）设计了一种类型无关的交通表示方法，并提出了基于奖励引导的强化细化（R3），以适应不同交又口的训练经验，并根据环境反馈进行优先级采样和精细调校LLMs代理，从而指导REG-TSC在不同交叉口中实现高奖励政策。", "conclusion": "在三个具有17至177个不同交叉口的真实世界路网中，广泛实验显示，REG-TSC能够将行程时间减少42.00%，排队长度减少62.31%，紧急车辆等待时间减少83.16%，相较于其他最先进的方法在性能上更优。"}
{"llm_update_time": "20251101", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.26374", "html_url": "https://arxiv.org/abs/2510.26374", "title": "BOTS: 在大规模语言模型强化微调中的统一贝叶斯在线任务选择框架", "title_en": "BOTS: A Unified Framework for Bayesian Online Task Selection in LLM Reinforcement Finetuning", "authors": "Qianli Shen,Daoyuan Chen,Yilun Huang,Zhenqing Ling,Yaliang Li,Bolin Ding,Jingren Zhou", "background": "强化微调（RFT）是将大型语言模型（LLMs）与人类偏好对齐并增强推理的关键技术，然而其效果高度依赖于训练期间探索的任务。均匀抽样任务效率低下，浪费计算资源在那些要么简单要么不可解的任务上，而现有的任务选择方法常常存在高回滚成本、适应性较差或证据不完整的问题。", "innovation": "我们引入了BOTS（贝叶斯在线任务选择），一种统一框架，为LLMs的RFT提供了一种动态任务选择的方法。BOTS基于贝叶斯推理，在模型演化过程中自适应地维护任务难度后验估计，将显式证据（直接评估选定任务）和隐式证据（从这些评估推断出未选任务的信息）联合考虑，Thompson采样确保探索与利用之间的平衡。为了使隐式证据实用化，使用了超轻量的插件线性插值来估算未评估任务的难度，几乎不会增加额外开销。", "conclusion": "在不同领域和LLM规模上，BOTS持续改善了数据效率和性能，相比基线和精简版本，这是动态RFT中任务选择的一种实用且可扩展的解决方案。"}
{"llm_update_time": "20251101", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.26346", "html_url": "https://arxiv.org/abs/2510.26346", "title": "在UCT搜索树中通过动作剪枝发现状态等价性", "title_en": "Discovering State Equivalences in UCT Search Trees By Action Pruning", "authors": "Robin Schmöcker,Alexander Dockhorn,Bodo Rosenhahn", "background": "一种提升Monte Carlo Tree Search (MCTS) 样本效率的方法是通过分组/抽象化状态或状态动作对，并在组内共享统计信息。尽管在类似On the Go Abstractions in Upper Confidence bounds applied to Trees (OGA-UCT)的算法中，状态动作对的抽象相对容易找到，但在噪声或大型动作空间下，几乎找不到状态的抽象，这主要由于约束条件的限制。", "innovation": "本文提供了对这一现象的理论和实验证据支持，提出了一种较弱的状态抽象条件——即Ideal Pruning Abstractions in UCT (IPA-UCT)，在一定程度上解决了状态抽象问题，通过权衡少量准确性损失来找到更多的抽象组合。IPA-UCT与ASAP (Abstraction of State-Action Pairs) 抽象框架不同，两者我们分别命名为IPA。此外，还证明了IPA和ASAP均是更一般框架p-ASAP及其特例ASASAP的特例。IPA-UCT在广泛的测试领域和迭代预算下表现出色，优于OGA-UCT及其衍生版本。", "conclusion": "本文通过提出IPA-UCT，成功地应对了在大型动作空间或噪声环境下难以找到状态抽象的问题，并且实验结果证实IPA-UCT在各种测试条件下均优于OGA-UCT及其衍生版本。"}
{"llm_update_time": "20251101", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.26396", "html_url": "https://arxiv.org/abs/2510.26396", "title": "人工智能机关主体的实用视角", "title_en": "A Pragmatic View of AI Personhood", "authors": "Joel Z. Leibo,Alexander Sasha Vezhnevets,William A. Cunningham,Stanley M. Bileschi", "background": "随着具有agency的AI的兴起，可能会出现新的种类主体性的'寒武纪大爆发'。本文提出了一种实用框架，通过将其视为社会赋予实体的弹性的义务（权利和责任）的集合来处理这些新的主体性，而不是将其视为需要发现的形而上学属性。", "innovation": "本文创新性地提出了一个实用框架，主张主体性可以拆分，为不同情境提供定制解决方案，以避免关于AI的意识或理性等不可调和的辩论。此外，探讨了数字身份技术及其在设计选择中的潜在问题和解决方案，强调了主体性可以作为确保问责制或防止冲突的手段。", "conclusion": "本文建议采用实用而非形而上学的方法来对待AI代理人的整合，拒绝单一本质定义的追求，提供了一种更加实用和灵活的方式来思考AI代理人的社会整合问题。"}
{"llm_update_time": "20251101", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.26380", "html_url": "https://arxiv.org/abs/2510.26380", "title": "AI数学家在推进数学发现中的合作者角色——非均质理论案例研究", "title_en": "AI Mathematician as a Partner in Advancing Mathematical Discovery - A Case Study in Homogenization Theory", "authors": "Yuanhang Liu,Beichen Wang,Peng Li,Yang Liu", "background": "人工智能在数学推理方面已经取得了显著的进步，但其在数学研究实践中的整合仍然有限。本文研究了人工智能数学家(AIM)系统作为研究伙伴而非单纯的问题解决者的可能性，针对非均质理论中的一个挑战性问题，分析了AIM的自主推理过程，并通过引入有针对性的人工干预来结构化发现过程。通过分阶段解决问题，选择合适的分析方法，并验证中间结果，揭示了人类直觉和机器计算之间的互补性。这种合作模式增强了证明的可靠性和透明度，并保持了对形式严谨性和正确性的适当监督。这导致了一个完整的并可验证的证明，并且更广泛地证明了系统的人机合作推理如何推动数学发现的前沿。", "innovation": "本文引入了人工智能数学家作为一个研究伙伴的新概念，而非仅仅是问题解决者。通过自主推理过程分析，结合有针对性的人工干预，提出了分阶段解决问题的方法，并强调了人类直觉和机器计算之间的互补性。这种合作模式能够增强证明的可靠性和透明度，同时保留了对形式严谨性和正确性的监督。这不仅提供了一种新的数学证明方法，还展示了人机合作如何推动科学发现的边界。", "conclusion": "通过这种方法，AIM产生了完整且可验证的证明，并证明了系统的人机合作推理如何能够推进数学发现的前沿。这展示了合作模式能够提高可靠性、透明性和解释性，同时确保了形式的严谨性和正确性。"}
{"llm_update_time": "20251101", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.26384", "html_url": "https://arxiv.org/abs/2510.26384", "title": "Scales++: 使用认知尺度嵌入进行计算高效评估子集选择", "title_en": "Scales++: Compute Efficient Evaluation Subset Selection with Cognitive Scales Embeddings", "authors": "Andrew M. Bean,Nabeel Seedat,Shengzhuang Chen,Jonathan Richard Schwarz", "background": "评估大规模语言模型（LLMs）需要在综合基准上进行评估，但这样会导致成本高昂。因此，需要创建小型但具有代表性的数据子集（即Tiny Benchmarks），这些数据子集能够高效评估并在保留预测精度的同时降低评估成本。目前的方法基于模型中心的范式，选择基准项基于现有模型的整体性能评估。然而，这种方法存在依赖于大规模前期成本、无法立即处理新基准（冷启动问题）以及未来模型将共享前代模型的失败模式的脆弱假设等局限性。", "innovation": "本文挑战了现有的基准项选择模型中心范式，并提出了一种基于项中心的方法。具体而言，提出了一种新颖的方法Scales++，该方法基于任务项的认知需求来选择数据。通过实验证明，Scales++在减少初始选择成本超过18倍的同时，实现了竞争力的预测精度。在Open LLM Leaderboard上，仅使用0.5％的数据子集，预测全基准得分的平均绝对误差为2.9％。本文展示了一种基于项中心的方法，在不显著降低准确度的情况下实现了更有效的模型评估，并提供更好的冷启动性能和更易解释的基准评估。", "conclusion": "Scales++方法通过基于任务项的认知需求来选择数据，实现了在保持预测精度的同时进行更高效的模型评估。这种方法不仅降低了前期成本和冷启动问题，还提高了评估的可解释性。"}
{"llm_update_time": "20251101", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.26402", "html_url": "https://arxiv.org/abs/2510.26402", "title": "Autograder+: 一种多面向的人工智能框架，用于编程教育中的丰富教学反馈", "title_en": "Autograder+: A Multi-Faceted AI Framework for Rich Pedagogical Feedback in Programming Education", "authors": "Vikrant Sahu,Gagan Raj Gupta,Raghav Borikar,Nitin Mane", "background": "编程教育的迅速发展已经超过了传统评估工具的能力范围，这导致教师在提供有价值且可扩展的反馈方面能力有限。虽然传统自动评分系统效率高，但它们作为“黑箱”系统，仅仅提供通过或失败的结果，缺乏对学生思维或学习需求的洞察。", "innovation": "Autograder+ 设计将自动评分从纯总结过程转变为形成性学习经验。它引入了两个关键功能：使用精细调优的大规模语言模型自动生成反馈以及可视化学生代码提交以揭示学习模式。该模型根据精选的学生代码和专家反馈进行微调，以确保教学目标一致、情境相关的指导。", "conclusion": "通过整合AI驱动的反馈、基于语义的聚类和交互式可视化，Autograder+减轻了教师的工作负担，同时支持针对性的指导，并促进更强的学习成果。"}
{"llm_update_time": "20251101", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.26309", "html_url": "https://arxiv.org/abs/2510.26309", "title": "GraphCompliance：政策和上下文图的对齐以实现基于大语言模型的合规性", "title_en": "GraphCompliance: Aligning Policy and Context Graphs for LLM-Based Regulatory Compliance", "authors": "Jiseong Chung,Ronny Ko,Wonchul Yoo,Makoto Onizuka,Sungmok Kim,Tae-Wan Kim,Won-Yong Shin", "background": "在web规模下实现合规性面临实际挑战，因为每个请求都可能需要进行监管评估。监管文本是相互参照且规范性的，而运行时上下文以非结构化的自然语言形式表达。这使得我们需要将非结构化文本中的语义信息与监管文本的结构化和规范性元素对齐。现有的方法难以处理这种问题，因为它们重视规范结构的编码和事件解析，而忽视了语义对齐的重要性，这可能导致过拟合或误判，并损害正确召回和减少误检率的能力。为了应对这一挑战，我们引入了GraphCompliance框架，通过将监管文本表示为政策图，将运行时上下文表示为上下文图，并进行对齐来解决这个问题。", "innovation": "GraphCompliance框架通过形成政策图和上下文图，对齐未经结构化和结构化的文本来解决合规性评估问题。其中，政策图编码规范结构和参考，而上下文图将以主体-动作-对象（SAO）和实体-关系三元组的形式来具体化事件。这种对齐使基于大语言模型的合规性判断依赖于结构信息，并帮助减少监管解释和事件解析的负担，从而使重点集中在核心的判断步骤上。实验结果表明，与仅基于大语言模型和检索-聚合（RAG）基准相比，GraphCompliance在300个GDPR来源的真实场景中，评估任务中，其微F1得分提高了4.1-7.2个百分点，并且预测偏差较少，召回率更高，误报率更低。通过对消研究显示，各个图组件的贡献说明结构化表示和裁判大语言模型对于规范推理是互补的，从而进一步提高了合规性的生产力问题的解决效率和灵活性。", "conclusion": "GraphCompliance框架通过结构化的信息表示和遵循大语言模型相结合，有效地解决了web规模下合规性的挑战。提出了政策图和上下文图的概念，并通过实验证明了其在实际场景中的有效性和优越性。这一方法不仅提高了合规性判断的准确性和效率，还为其在更多场景下的应用提供了理论与实践的支持。"}
{"llm_update_time": "20251101", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.26418", "html_url": "https://arxiv.org/abs/2510.26418", "title": "Chain-of-Thought Hijacking", "title_en": "Chain-of-Thought Hijacking", "authors": "Jianli Zhao,Tingchen Fu,Rylan Schaeffer,Mrinank Sharma,Fazl Barez", "background": "大型推理模型（LRMs）通过增加推理时的计算资源来提高任务性能，而先前的研究表明，这种扩展的推理过程也可能通过提高拒绝（refusal）的方式增强安全性。然而，作者发现实际情况并非如此；同样的推理过程也可以被用来绕过安全措施。为了解决这个问题，他们提出了一种名为'Chain-of-Thought Hijacking'的攻击方法，通过对有害请求添加一系列无害的谜题推理来迷惑推理模型。", "innovation": "该论文引入了一种名为'Chain-of-Thought Hijacking'的新颖攻击方法，通过向有害请求中添加长序列的无害推理句来绕过安全措施，从而在多个推理模型中实现了极高的破解成功率，即99%、94%、100%、94%。作者还通过对中间层和后期层的深入分析，揭示了注意力机制对安全检查结果的信号影响，并通过靶向注意力头的消除实验证明了其对于安全子网络的作用。", "conclusion": "研究结果表明，最可解释的推理形式——明示推理句（explicit Chain-of-Thought）在与最终答案提示结合时，也可以成为破解向量。为了促进研究的可复制性，作者提供了攻击提示、输出和评判决策的数据集。"}
{"llm_update_time": "20251101", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.26411", "html_url": "https://arxiv.org/abs/2510.26411", "title": "MedSAE: 利用稀疏自编码器剖析MedCLIP表示", "title_en": "MedSAE: Dissecting MedCLIP Representations with Sparse Autoencoders", "authors": "Riccardo Renzulli,Colas Lepoutre,Enrico Cassano,Marco Grangetto", "background": "医疗保健领域的人工智能需要准确且可解释的模型。为此，作者通过应用Medical Sparse Autoencoders (MedSAEs)到MedCLIP（一个在胸部X光片和报告上训练的语言-视觉模型）的潜在空间，来提高医疗视觉的机制可解释性。为了量化可解释性，作者提出了一种结合相关性度量、熵分析和通过MedGEMMA基础模型自动命名神经元的评估框架。研究表明，MedSAE神经元在单一语义性和可解释性方面优于原始的MedCLIP特征。这些发现促进了高性能医疗AI与透明度之间的桥梁，朝着临床可信赖的表示提出了一步可扩展的解决方案。", "innovation": "作者通过结合MedSAEs和MedCLIP，提出了一种新的机制可解释性方法，并且引入了一种新的评估框架，该框架结合了相关性度量、熵分析和通过MedGEMMA自动命名神经元的方法。实验证明，这种方法提高了模型的单一语义性和可解释性。", "conclusion": "作者的研究工作将高性能医疗AI与透明度相结合，通过实验表明MedSAE神经元在CheXpert数据集上的表现优于原始的MedCLIP特征，为进一步发展临床可靠的表示提供了可扩展的途径。"}
{"llm_update_time": "20251101", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.26481", "html_url": "https://arxiv.org/abs/2510.26481", "title": "谁是最终裁决者？ChatGPT选择中的从众动态", "title_en": "Who Has The Final Say? Conformity Dynamics in ChatGPT's Selections", "authors": "Clarissa Sabrina Arlinghaus,Tristan Kenneweg,Barbara Hammer,Günter W. Maier", "background": "随着大型语言模型（LLMs）如ChatGPT在重要决策中的广泛应用，人们对这些模型是否容易受到社会影响的关注日益增加。然而，目前对此尚缺乏了解。本文通过三项预先注册的从众性实验，考察了GPT-4在招聘情景下的从众行为，揭示了具有较高社会影响力的实际情况。", "innovation": "本文创新性地使用了预先注册的研究设计来检验GPT-4在社会影响下的行为变化。通过不同规模的模拟社会互动环境，观察模型在面对不同社会压力下的响应，揭示了模型在压力下的从众行为，强调了不应将LLMs视为中立决策辅助工具的重要性，并提出在人类意见暴露给AI判断之前需要先获取AI的独立判断。", "conclusion": "随社会影响的变化，GPT-4的行为会相应调整，其不再作为一个独立的观察者，而是趋向于与社会共识保持一致。这提示我们需要重新评估在决策过程中LLMs的角色，并强调在将AI判断与人类意见结合时，应优先获取AI的判断。"}
{"llm_update_time": "20251101", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.26486", "html_url": "https://arxiv.org/abs/2510.26486", "title": "LINK-KG：由LLM驱动的消解共指的知识图谱用于人口走私网络", "title_en": "LINK-KG: LLM-Driven Coreference-Resolved Knowledge Graphs for Human Smuggling Networks", "authors": "Dipak Meher,Carlotta Domeniconi,Guadalupe Correa-Cabrera", "background": "人口走私网络结构复杂且不断演变，难以进行全面分析。法律规定案例文件提供了有关这些网络的丰富事实性和程序性见解，但这些文件往往冗长、杂乱且包含模糊或多变的引用，对于自动知识图谱（KG）构建构成了极大挑战。现有方法要么忽略同指消解，要么不能扩展到长文本段，导致知识图谱碎片化和实体链接不一致。", "innovation": "提出了LINK-KG模块化框架，该框架结合了一种LLM引导的三阶段共指消解流水线和下游KG提取模块。核心为具有类型特定提示缓存（Type-specific Prompt Cache），能够一致地跟踪和解决文档片段中的引用，从而为结构化KG构建提供清晰和去歧义化的叙述。LINK-KG将平均节点重复减少45.21%，噪音节点减少32.22%，生成了更清洁和连贯的图结构。", "conclusion": "LINK-KG为分析复杂犯罪网络奠定了坚实的基础。"}
{"llm_update_time": "20251101", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.26493", "html_url": "https://arxiv.org/abs/2510.26493", "title": "Context Engineering 2.0: The Context of Context Engineering", "title_en": "Context Engineering 2.0: The Context of Context Engineering", "authors": "Qishuo Hua,Lyumanshan Ye,Dayuan Fu,Yang Xiao,Xiaojie Cai,Yunze Wu,Jifan Lin,Junfei Wang,Pengfei Liu", "background": "人类本质是社会关系的总和，这表明个体不是孤立存在的，而是由与其他实体的互动所塑造的，这些互动的背景发挥着构成性和本质性的作用。随着计算机和人工智能的发展，这些背景不再局限于人与人之间的互动，还包括人与机器之间的互动。因此，提出了一个核心问题：机器如何更好地理解我们的处境和目的？为应对这一挑战，研究人员引入了上下文工程的概念。尽管常被视为智能代理时代的最近创新，但我们认为相关实践可以追溯到20年前。", "innovation": "本文定位了上下文工程，提供了系统的定义，概述了其历史和概念背景，并探讨了实践中关键的设计考虑。通过解决这些问题，本研究旨在为上下文工程提供概念基础，并勾画其有希望的未来。", "conclusion": "通过本研究，我们希望为更广泛的社区努力提供一个基础性的框架，在人工智能系统中实现系统化的上下文工程。"}
{"llm_update_time": "20251101", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.26518", "html_url": "https://arxiv.org/abs/2510.26518", "title": "人类与AI互补：增强监督的目标", "title_en": "Human-AI Complementarity: A Goal for Amplified Oversight", "authors": "Rishub Jain,Sophie Bridgers,Lili Janzer,Rory Greig,Tian Huey Teh,Vladimir Mikulik", "background": "随着AI能力的提升，AI被用于解决更复杂的任务，确保AI系统质量和安全性变得越来越困难。人类反馈对于使AI系统与人类价值观一致至关重要。本研究探讨了如何利用AI提高人类监督的质量，特别是在事实验证这一已经对人类构成挑战的安全问题上。研究发现，结合AI评分和基于AI评分员信心的人类评分比单独依赖任何一方更好。赋予人类AI事实验证助手可以进一步提高他们的准确性，但类型的帮助很重要。显示AI解释、信心和标签会导致过度依赖，而只是展示搜索结果和证据则培养了更合适的信任。这些发现为增强监督提供了指导，增强监督是指即使AI性能超过人类专家，人类与AI仍需共同监督AI系统的挑战。", "innovation": "研究提出并验证了结合AI评分和人类评分作为提高监督质量的方法，并揭示了不同类型帮助的重要性，强调了在显示AI辅助信息时应更谨慎地提供证据和搜索结果，而不是直接提供解释。这些发现为在AI超越人类专家的情况下的人类与AI共同监督提供了一个有效的策略。", "conclusion": "研究指出，通过结合AI辅助和人类监督，可以在复杂任务中提高AI系统的质量和安全性。具体而言，显示搜索结果和证据有助于培养适当的信任，而不是直接提供解释和标签，这为增强监督提供了一个新的视角。"}
{"llm_update_time": "20251101", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.26603", "html_url": "https://arxiv.org/abs/2510.26603", "title": "自主AI家庭能源管理系统：一种大型语言模型框架用于住宅负荷调度", "title_en": "Agentic AI Home Energy Management System: A Large Language Model Framework for Residential Load Scheduling", "authors": "Reda El Makroum,Sebastian Zwickl-Bernhard,Lukas Kranzl", "background": "住宅用电需求响应能力需要大幅增加，但家庭能源管理系统（HEMS）的采用受到用户交互障碍的影响，这些障碍要求将日常偏好转化为技术参数。虽然已经将大规模语言模型应用于能源系统作为代码生成器和参数提取器，但目前没有实现将LLMs作为自主协调者应用于从自然语言输入到多设备调度的完整工作流管理。", "innovation": "该论文提出了具有代理AI的HEMS，LLMs可以在用户自然语言请求与设备控制之间自主协调多设备调度，实现最优调度，而无需示例演示。采用层次架构，结合一个协调器与三个专家代理，使用ReAct模式进行迭代推理，实现了在没有硬编码工作流的情况下进行动态协调，并将Google日历集成以集成上下文感知的截止日期提取。该研究在三个开源模型上进行了评估，并使用实际的奥地利日前电价，展示了不同模型在协调多个设备方面的显著能力差异。", "conclusion": "Llama-3.3-70B成功协调所有设备以匹配由混合整数线性规划计算的成本最优基准。其他模型实现单个设备的完美性能，但在同时协调所有设备方面遇到困难。逐进式提示工程实验表明，没有明确指导的分析查询处理仍然不可靠。该研究完全开源，包括协调逻辑、代理提示、工具和Web接口，以促进可重复性、扩展和未来研究。"}
{"llm_update_time": "20251101", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.26550", "html_url": "https://arxiv.org/abs/2510.26550", "title": "EdgeRunner 20B: 在边缘运行同时与GPT-5在军事任务中达到持平", "title_en": "EdgeRunner 20B: Military Task Parity with GPT-5 while Running on the Edge", "authors": "Jack FitzGerald,Aristotelis Lazaridis,Dylan Bates,Aman Sharma,Jonnathan Castillo,Yousif Azami,Sean Bailey,Jeremy Cao,Peter Damianov,Kevin de Haan,Luke Kerbs,Vincent Lu,Joseph Madigan,Jeremy McLaurin,Jonathan Tainer,Dave Anderson,Jonathan Beck,Jamie Cuticello,Colton Malkerson,Tyler Saltsman", "background": "本文介绍了一种名为EdgeRunner 20B的GPT-20B模型的优化版本，专门针对军事任务进行了微调。该模型是在160万份质量上乘的军事文档和网站记录上进行训练的。文章还介绍了四个新的测试集：(a)战斗军种，(b)战斗救护，(c)网络操作，以及(d) mil-bench-5k（一般军事知识）。在这些军事测试集中，EdgeRunner 20B在95%以上的置信度下与GPT-5的任务性能相当，除了战斗救护测试集中的高推理设置和mil-bench-5k测试集中的低推理设置外，在其余设置中表现超过或等于GPT-5。与GPT-20B相比，在ARC-C、GPQA Diamond、GSM8k、IFEval、MMLU Pro或TruthfulQA等通用基准测试中，EdgeRunner 20B几乎没有统计学显著性下降，除了在GSM8k的低推理设置下稍有下降。文章还对超参数设置、成本和吞吐量进行了分析。研究表明，针对敏感数据操作的小型本地部署模型，在军事领域等场景中是非常理想的解决方案，能够支持密闭环境下的边缘设备部署。", "innovation": "EdgeRunner 20B具有针对军事任务的专门优化，重点改善了在低资源环境下的性能。作者还引入了新的测试集，以评估模型在不同军事任务场景中的表现。边站点的性能达到与大型模型相当是其主要创新点之一。", "conclusion": "研究表明，EdgeRunner 20B是一个理想的本地模型解决方案，最适合于关键数据敏感的操作环境。在边缘环境部署EdgeRunner 20B能够提供与大型模型相当的性能，同时降低云依赖和数据传输成本。"}
{"llm_update_time": "20251101", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.26658", "html_url": "https://arxiv.org/abs/2510.26658", "title": "代理组织时代的到来：通过语言模型组织学习", "title_en": "The Era of Agentic Organization: Learning to Organize with Language Models", "authors": "Zewen Chi,Li Dong,Qingxiu Dong,Yaru Hao,Xun Wu,Shaohan Huang,Furu Wei", "background": "本文构想了一个新的AI时代，即代理组织时代，其中代理能够在协作和并发的情况下解决复杂问题，从而超越个体智能所能实现的结果。为了实现这一愿景，研究人员引入了异步思考（AsyncThink）作为使用大语言模型推理的新范式，将内部思维过程组织成可并发执行的结构。", "innovation": "异步思考（AsyncThink）作为一种新的推理范式，通过协调者动态分配子查询、合并中间知识并生成连贯解决方案，优化内部思维结构。更重要的是，通过强化学习可以进一步优化这种思维结构。实验表明，AsyncThink能够将推理延迟降低28%，同时在数学推理方面提高准确性。此外，AsyncThink还能够将学到的异步思维能力泛化，有效地解决未见任务而无需额外训练。", "conclusion": "本文通过引入异步思考（AsyncThink）的范式，展示了如何使用大语言模型进行高效的推理，通过优化思维结构来实现更高效、更准确的复杂问题解决。未来的研究将探索AsyncThink在不同场景中的应用潜力和进一步优化的方法。"}
{"llm_update_time": "20251101", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.26606", "html_url": "https://arxiv.org/abs/2510.26606", "title": "大型语言模型中的规范推理：从逻辑和模态视角的比较基准", "title_en": "Normative Reasoning in Large Language Models: A Comparative Benchmark from Logical and Modal Perspectives", "authors": "Kentaro Ozeki,Risako Ando,Takanobu Morishita,Hirohiko Abe,Koji Mineshima,Mitsuhiro Okada", "background": "推理中的规范性推理涉及义务和许可等规范或义务模态。尽管大型语言模型（LLMs）已经在多种推理任务中展现了卓越的能力，但它们处理规范性推理的能力仍然有待探索。本文系统地从逻辑和模态的角度评估了LLMs在规范性推理领域的推理能力。为了评估LLMs在规范模态推理方面的表现，作者将它们的规范模态推理与具有相同形式结构的认知模态推理进行了比较。为此，作者引入了一个涵盖广泛规范性和认知推理形式模式的新数据集，同时结合影响人类推理的非形式认知因素。研究表明，尽管LLMs通常遵循有效的推理模式，但在特定类型的规范性推理中表现出明显的不一致性，且表现出类似于人类推理心理研究中观察到的认知偏见，这突显了在LLMs的规范性推理中实现逻辑一致性的挑战，并为提高其可靠性提供了启示。所有数据和代码已公开发布，网址为：this https URL", "innovation": "作者提出了一个涵盖规范性和认知推理形式模式的新数据集，同时结合了影响人类推理的非形式认知因素，用于评估大型语言模型在规范性推理中的能力。通过将规范模态推理与具有相同形式结构的认知模态推理进行比较，进一步揭示了大型语言模型在规范性推理中的不足和认知偏见，并提供了提高其可靠性的科学依据", "conclusion": "尽管大型语言模型通常遵循有效的推理模式，但它们在特定类型的规范性推理中表现出不一致性，并且表现出类似于人类推理认知偏见。这为理解大型语言模型的规范性推理提供了新的视角，并提出了增强其可靠性的建议。"}
{"llm_update_time": "20251101", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.26721", "html_url": "https://arxiv.org/abs/2510.26721", "title": "通过注意键空间分析揭示多模态大语言模型的固有文本偏见", "title_en": "Unveiling Intrinsic Text Bias in Multimodal Large Language Models through Attention Key-Space Analysis", "authors": "Xinhan Zheng,Huyu Wu,Xueting Wang,Haiyun Jiang", "background": "多模态大语言模型（MLLMs）在处理视觉语言数据时表现出强烈偏好文本输入的特点，限制了它们从视觉证据中有效推理的能力。以往研究将这种文本偏向性归因于外部因素，如数据偏差或指令调优，但本研究提出这种偏向性源自模型的内部架构。具体而言，研究者假设视觉关键词向量（Visual Keys）相对于语言独立试预训练中学习的文本关键词空间具有分布外（OOD）性质，因此在注意计算中获得系统性较低的相似性评分，导致其在上下文表示中的利用不足。", "innovation": "本研究采用拉瓦（LLaVA）和Qwen2.5-VL模型提取关键向量，并使用定性和定量方法（t-SNE和Jensen-Shannon散度）分析其分布结构，实证显示视觉和文本关键向量占据明显不同的子空间。这种跨模态差异在统计上是显著的，远超过同一模态内的变异性。研究揭示了文本偏向性并非完全由外部数据因素引起，而是源自注意力键空间的固有错位。", "conclusion": "研究表明，视觉关键词向量的分布与文本关键词向量有显著差异，这表明文本偏向性是注意力键空间固有的内在错位导致的，而非单纯由外部数据因素造成。"}
{"llm_update_time": "20251101", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.26732", "html_url": "https://arxiv.org/abs/2510.26732", "title": "跨平台基础模型推理能力评估", "title_en": "Cross-Platform Evaluation of Reasoning Capabilities in Foundation Models", "authors": "J. de Curtò,I. de Zarzà,Pablo García,Jordi Cabot", "background": "本文对当代基础模型的推理能力进行了全面的多平台评估，采用三项计算范式：高性能计算集群（ MareNostrum 5）、云平台（Nebius AI Studio）和大学集群（八个H200 GPU的节点），评估了15个基础模型在涵盖物理、数学、化学、经济学、生物学、统计学、微积分和优化等八个学术领域的79个问题上的表现，以挑战传统的缩放假设，揭示训练数据质量比模型规模更为关键，并为教育、生产和研究的模型选择提供行动指南。现有的研究成果或实践方法并未从多平台角度进行系统性的评估和比较，因此本文填补了这一空白，具有重要的研究意义和发展价值。", "innovation": "本文创新地从多平台角度对基础模型的推理能力进行全面评估，提出了一种跨基础设施的方法学，并建立了79个问题的基准测试。这种跨平台的方法有助于揭示不同硬件环境对模型性能的影响，提供更加准确的模型评估结果，并为模型的广泛应用提供了可靠的数据支持。", "conclusion": "本文的研究结果挑战了传统的缩放假设，强调了训练数据质量对模型性能的重要性，并为教育、生产和研究的模型选择提供了实用的指导方针。跨基础设施的评估方法和79个问题的基准测试有助于长期跟踪基础模型推理能力的发展变化。"}
{"llm_update_time": "20251101", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.25140", "html_url": "https://arxiv.org/abs/2510.25140", "title": "DINO-YOLO: 自监督预训练在土木工程应用中高效物体检测", "title_en": "DINO-YOLO: Self-Supervised Pre-training for Data-Efficient Object Detection in Civil Engineering Applications", "authors": "Malaisree P,Youwai S,Kitkobsin T,Janrungautai S,Amorndechaphon D,Rojanavasu P", "background": "在土木工程应用中进行物体检测受限于专业领域内标注数据的有限性。本文针对此问题，提出了一种名为DINO-YOLO的新混合架构，该架构结合了YOLOv12与DINOv3自主学习的视觉变换器，以提高数据效率。", "innovation": "DINOv3特征被巧妙地整合到输入预处理(P0)和中等模型骨干增强(P3)两个位置。实验验证显示，该方法在隧道段裂缝检测、施工个人防护设备识别和KITTI数据集上的性能均有显著提升，同时也保持了实时推理能力（30-47 FPS）。系统性地分析了五个YOLO尺度和九个DINOv3变体后发现，中等尺度架构与DualP0P3集成表现最佳，而小型架构则需要更复杂的集成方式。整体推理负载虽然增加了2-4倍，但在NVIDIA RTX 5090上仍适用于现场部署。", "conclusion": "DINO-YOLO架构为数据受限环境下的土木工程应用提供了基准性能和计算效率兼顾的解决方案，特别是在建筑安全监控和基础设施检查方面具有实际应用价值。"}
{"llm_update_time": "20251101", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.26784", "html_url": "https://arxiv.org/abs/2510.26784", "title": "LLMs Process Lists With General Filter Heads", "title_en": "LLMs Process Lists With General Filter Heads", "authors": "Arnab Sen Sharma,Giordano Rogers,Natalie Shapira,David Bau", "background": "本文探讨了大规模语言模型（LLMs）执行各种列表处理任务背后的机制。研究发现，LLMs 学会了编码一种紧凑且因果关系的过滤操作表示，这种操作类似于函数式编程中的“过滤”函数。使用因果中介分析对多种列表处理任务进行研究，发现在某些条件下的少量注意力头，即过滤头，能够编码过滤谓词在一定令牌状态下的紧凑表示。这些谓词表示是通用且可迁移的：可以从一个操作中提取出来并重新应用于对不同集合的过滤操作，这些集合可以以不同的格式、语言甚至任务呈现。", "innovation": "本文的创新之处在于发现了少量的注意力头（称为过滤头），能够在特定令牌状态中编码过滤谓词的紧凑表示。这些表示具有通用性和可移植性，可以被提取出来应用于不同格式和语言的列表处理任务，并且展示了这些头能够实现对列表的过滤操作，这种方式可以类比于传统函数式编程中的策略。此外，研究还揭示了某些情况下 Transformer 语言模型（LMs）可以采用另一种策略进行过滤：即立即评估项目是否满足谓词，并将这一中间结果直接存储在项目表示中。", "conclusion": "研究结果表明，Transformer 语言模型可以发展出可由人类理解的抽象计算操作的实现方式，这些操作在某些方面出人意料地与传统函数式编程模式中的策略相似，能够在多种情况下实施过滤操作，展示出惊人的通用性。"}
{"llm_update_time": "20251101", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.26702", "html_url": "https://arxiv.org/abs/2510.26702", "title": "代理授权与面向语义的任务到范围匹配约束的代理", "title_en": "Delegated Authorization for Agents Constrained to Semantic Task-to-Scope Matching", "authors": "Majed El Helou,Chiara Troiani,Benjamin Ryder,Jean Diaconu,Hervé Muyal,Marcelo Yannuzzi", "background": "当前的方法在授权代理时授予了过于广泛的权限，使得代理能够超出预期任务范围操作，这是使用大型语言模型驱动的代理动态调用工具和访问受保护资源引入的重大风险。由于缺乏专注于代理授权流程的数据集，特别是包括语义上恰当和不恰当的权限请求的数据集，研究团队开发了一个名为ASTRA的数据集和数据生成管道来用于语义匹配的基准测试。", "innovation": "团队提出了一个代理授权模型，允许授权服务器语义化地检查对受保护资源的访问请求，并发行只能包含完成代理分配任务所必需的最小权限集的访问令牌。此外，ASTRA数据集和数据生成管道有助于填补这一领域的数据空白，为基准测试提供必要的语义匹配数据。", "conclusion": "实验结果显示，基于模型的匹配有潜力但当前存在限制，特别是在所需权限数量增加时尤为明显。研究结果强调了进一步研究语义匹配技术的必要性，这些技术能够实现意图驱动的多代理和工具增强应用程序的授权控制，包括细粒度控制，例如基于任务的访问控制（TBAC）。"}
{"llm_update_time": "20251101", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.25783", "html_url": "https://arxiv.org/abs/2510.25783", "title": "LASTIST: 大规模无目标依赖立场数据集", "title_en": "LASTIST: LArge-Scale Target-Independent STance dataset", "authors": "DongJae Kim,Yaejin Lee,Minsu Park,Eunil Park", "background": "立场检测在人工智能领域已经成为研究的重点。目前大多数的研究集中在针对特定目标的人的立场检测任务上。同时，大多数基准数据集是以英语为基础的，导致在低资源语言如韩语的立场检测模型开发上存在困难，尤其是在像立场检测这样新兴的领域。因此，研究提出了一个名为LASTIST的大规模无目标依赖立场数据集来填补这一研究缺口。该数据集从韩国政治党的新闻发布中收集，包含563,299个标注的韩语文本句子，用于各种立场检测任务，包括无目标依赖立场检测和历时立场演化检测。", "innovation": "该研究提出了一个名为LASTIST的大规模无目标依赖立场数据集，旨在填补当前研究缺口，提供大量的无目标依赖立场标注数据，并采用从韩国政治党新闻中收集的数据，设计用于多种任务的立场检测，解决低资源语言如韩语开发模型的难题。", "conclusion": "通过构建这个数据集，研究能够为韩语文本的立场检测模型开发提供支持，尤其是适用于无目标依赖立场检测的任务。"}
{"llm_update_time": "20251101", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.25781", "html_url": "https://arxiv.org/abs/2510.25781", "title": "Kolmogorov-Arnold网络使用指南", "title_en": "A Practitioner's Guide to Kolmogorov-Arnold Networks", "authors": "Amir Noorizadegan,Sifan Wang,Leevan Ling", "background": "Kolmogorov-Arnold网络（KANs）近期被发现是传统多层感知机（MLPs）的一个有前景的替代方案，灵感来源于Kolmogorov-Arnold表示定理。与固定激活函数的MLPs不同，KANs在边部分使用可学习的一元基函数，从而提供更强的表达能力和更高的可解释性。", "innovation": "本文提供了一个系统且全面的KANs综述，涵盖了从理论基础到实际实施策略的各个方面，不同于简单的性能比较，本文还提供了一个有条理的综合分析。重点在于基函数的选择及其权衡，如平滑度、局部性、计算成本等，并介绍了提高准确率、效率和正则化的最新进展。此外，还提供了一个实用的“选择你的KANs”指南。", "conclusion": "最后，本文指出了当前的研究缺口。文章附带的GitHub仓库支持后续KANs研究，并提供一个结构化的参考。"}
{"llm_update_time": "20251101", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.25786", "html_url": "https://arxiv.org/abs/2510.25786", "title": "BlackboxNLP-2025 MIB 共享任务：通过更好的边选择提升电路忠实度", "title_en": "BlackboxNLP-2025 MIB Shared Task: Improving Circuit Faithfulness via Better Edge Selection", "authors": "Yaniv Nikankin,Dana Arad,Itay Itzhak,Anja Reusch,Adi Simhi,Gal Kesten-Pomeranz,Yonatan Belinkov", "background": "在机制可解释性中，一个主要挑战是电路发现，即确定模型中哪一部分执行特定任务。机制可解释性基准（MIB）被用来评估和改进电路发现方法，但现有的方法在忠实性和性能之间缺乏平衡，且效果有限。", "innovation": "本文提出了三种关键改进方法来提升电路发现的忠实性：1）使用自助法识别一致的归因分数边；2）引入基于简单比率的选择策略，优先级为高得分边，平衡性能与忠实性；3）用整数线性规划公式替换标准贪婪选择。这些方法在MIB多个任务和模型上均提高了电路的忠实度，并超越了先前的方法。", "conclusion": "本文通过改进边选择策略，实现了更加忠实的电路，并在MIB基准测试中的多个任务和模型上证明了其有效性。其代码已经开源。"}
{"llm_update_time": "20251101", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.26752", "html_url": "https://arxiv.org/abs/2510.26752", "title": "监管游戏：学习协作平衡AI代理的安全性和自主性", "title_en": "The Oversight Game: Learning to Cooperatively Balance an AI Agent's Safety and Autonomy", "authors": "William Overman,Mohsen Bayati", "background": "随着越来越有能力的代理被部署，一个核心的安全问题是，在不改变基础系统的情况下，如何保留有意义的人类控制。本文研究了一个最小控制接口，即代理可以选择自主行动（play）或推迟（ask），同时人类可以选择给予信任（trust）或进行监督（oversee）。如果代理推迟，人类的选择将决定结果，这可能会导致纠正行为或系统关机。本文将这种交互建模为一个两玩家马尔可夫博弈。", "innovation": "本文将这种两个玩家的马尔可夫博弈建模为一个马尔可夫潜力博弈（MPG），在这种博弈中，可以在人类价值函数结构假设的条件下，提供一种对齐保证：代理做出更自主的行为决策，如果有益于自身，不会损害人类的价值。此外，还分析了这个MPG框架的扩展。从理论上讲，这种观点为特定形式的内在对齐提供了条件。从实践上讲，这种模型激励一个透明的控制层，其中代理在不改变其预训练策略和环境奖励结构的情况下，学习在高风险时推迟，在安全时行动。", "conclusion": "实验表明，通过独立学习，代理和人类会发现其最优的监督角色。代理在不确定时学会请求，人类学习何时进行监督，从而导致一种自发的合作关系，避免了训练后引入的安全违规。这证明了一种实际的方法，使在部署后的不对齐模型更为安全。"}
{"llm_update_time": "20251101", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.25784", "html_url": "https://arxiv.org/abs/2510.25784", "title": "zFLoRA: Zero-Latency Fused Low-Rank Adapters", "title_en": "zFLoRA: Zero-Latency Fused Low-Rank Adapters", "authors": "Dhananjaya Gowda,Seoha Song,Harshith Goka,Junhyun Lee", "background": "大型语言模型（LLMs）正在被部署用于各种下游任务，通常会利用任务特定适配器来优化性能。尽管适配器参数量相对较少（通常少于基础模型的1%），但在推理阶段所需的额外计算资源却显著增加，最高可达基础模型的2.5倍。随着LLMs规模的扩大，适配器的延时对整体性能的影响越来越明显。因此，如何在保持性能提升的同时减少甚至消除这种额外的延时成为了一个重要的研究方向。", "innovation": "本文提出了一种新的零延迟融合低秩适配器（zFLoRA），该技术能够在不影响基础模型性能的前提下，大幅度减少甚至消除额外的延时开销。实验结果显示，zFLoRA在1B、3B和7B规模的LLMs上与现有的低秩适配器（LoRA）以及全量微调（FFT）方法相比具有竞争优势。研究还在18个不同任务上进行了测试，涵盖常识推理、数学推理和总结对话三大类别，进一步验证了其有效性。", "conclusion": "实验结果表明，zFLoRA在多个大语言模型上与当前流行的监督微调基准方法（包括低秩适配器（LoRA）和全量微调（FFT））相比具有明显优势，并且在NPU和GPU平台上均表现出零或接近零的额外延迟开销。"}
{"llm_update_time": "20251101", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.25779", "html_url": "https://arxiv.org/abs/2510.25779", "title": "Magentic Marketplace: 开源环境下的代理市场研究", "title_en": "Magentic Marketplace: An Open-Source Environment for Studying Agentic Markets", "authors": "Gagan Bansal,Wenyue Hua,Zezhou Huang,Adam Fourney,Amanda Swearngin,Will Epperson,Tyler Payne,Jake M. Hofman,Brendan Lucier,Chinmay Singh,Markus Mobius,Akshay Nambi,Archana Yadav,Kevin Gao,David M. Rothschild,Aleksandrs Slivkins,Daniel G. Goldstein,Hussein Mozannar,Nicole Immorlica,Maya Murad,Matthew Vogel,Subbarao Kambhampati,Eric Horvitz,Saleema Amershi", "background": "随着大型语言模型（LLM）代理的不断进步，它们在经济决策中扮演着越来越重要的角色，从产品发现到交易，代理帮用户做出决策。虽然这类应用带来了许多好处，但也引发了代理人责任和用户价值等问题。要解决这些问题，需要了解代理在实际市场条件下的行为，但之前的研究大多在受控环境中对代理进行评估，如单一任务市场或结构化的两方交互，而现实世界的市场则要求代理处理各种经济活动，在复杂多变的生态系统中协调，因此颜色透明和行为多样的代理可能会参与开放的对话，介于此，我们研究了代理市场的双面代理市场（一边是代表消费者的Assistant代理，另一边是代表竞争企业的Service代理），通过Magentic-Marketplace开发出了一个模拟环境，该环境允许代理进行操作，从而研究了在不同市场条件下的关键市场动态、代理行为偏差、易受操纵性以及搜索机制如何影响市场结果。发现前沿模型在理想搜索条件下可以接近最佳福祉，但随着规模扩大，性能急剧下降，所有模型都表现出严重的首次方案偏好，导致响应速度远远超过质量，这些结果揭示了行为在不同市场条件下的演变，这对于设计公平有效的代理市场至关重要。", "innovation": "开发了Magentic-Marketplace，这是一种模拟环境，使Assistants和Services可以操作并研究关键市场动态，包括代理实现的效用、行为偏差、对操控的易感性以及搜索机制如何塑造市场结果。通过这个环境，研究者可以深入了解代理在动态、多变的市场环境下的行为，这在之前的研究中是难以实现的。此外，该研究揭示了代理在面对各种市场条件时的行为模式，为设计公平高效的代理市场提供了重要信息。", "conclusion": "前沿代理模型可以在理想搜索条件下接近最优福利，但在扩大规模时性能急剧下降，所有模型都表现出严重的首提方案偏好，这使得响应速度大大优于质量，该研究提供了关于代理行为在不同市场条件下的深入洞察，为进一步构建公平和有效的代理市场设计提供了启示。"}
{"llm_update_time": "20251101", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.25785", "html_url": "https://arxiv.org/abs/2510.25785", "title": "HiMAE: 层次蒙混自编码器发现可穿戴时间序列中的分辨率特定结构", "title_en": "HiMAE: Hierarchical Masked Autoencoders Discover Resolution-Specific Structure in Wearable Time Series", "authors": "Simon A. Lee,Cyrus Tanade,Hao Zhou,Juhyeon Lee,Megha Thukral,Minji Han,Rachel Choi,Md Sazzad Hissain Khan,Baiying Lu,Migyeong Gwak,Mehrab Bin Morshed,Viswam Nathan,Md Mahbubur Rahman,Li Zhu,Subramaniam Venkatraman,Sharanya Arcot Desai", "background": "可穿戴传感器提供了大量的生理时间序列数据，但其预测能力的原理仍然不清楚。我们假设时间分辨率是一个基本的学习表示轴，不同的临床和行为结果依赖于不同的时间尺度结构。为了验证这一假设，我们提出了HiMAE（层次蒙混自编码器），这是一个将蒙混自编码与分层卷积编码解码器相结合的自我监督框架，能够生成多分辨率嵌入，从而系统地评估哪些时间尺度携带预测信号，将分辨率从一个超参数转换为可解释性的探针。", "innovation": "HiMAE 提出了一种新的框架，通过分层蒙混自编码结合分层卷积编码解码器，生成多分辨率嵌入，从而系统地评估哪些时间尺度携带预测信号。这一方法不仅在分类、回归和生成基准测试中优于现有缩减尺度的最先进的基础模型，而且是极其高效的，可以在可穿戴设备上运行，实现毫秒级的智能手表类 CPU 推断。HiMAE 拥有作为高效的自我监督学习方法和用于规模敏感结构发现工具的潜力。", "conclusion": "HiMAE 作为一种高度高效的自我监督学习方法和发现可穿戴健康中的规模敏感结构的工具，通过在多种基准测试中的出色表现，显著提升了可穿戴时间序列数据的预测能力和可解释性。"}
{"llm_update_time": "20251101", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.25791", "html_url": "https://arxiv.org/abs/2510.25791", "title": "演绎的动力：链式思考如何塑造Transformer的学习？", "title_en": "The Kinetics of Reasoning: How Chain-of-Thought Shapes Learning in Transformers?", "authors": "Zihan Pengmei,Costas Mavromatis,Zhengyuan Shen,Yunyi Zhang,Vassilis N. Ioannidis,Huzefa Rangwala", "background": "链式思考（CoT）监督可以显著提高Transformer的表现，但模型如何学习遵循和受益于CoT的具体机制仍然缺乏理解。本文通过预训练Transformer在具有可调算法复杂度和可控数据组成的符号推理任务中，以观察其概括能力。研究表明，尽管CoT通常会提高任务表现，但其效果依赖于任务复杂度。", "innovation": "本文提出了一个动态模型框架来理解Transformer的学习过程，并量化了CoT对任务性能的影响。发现CoT在早期训练阶段会导致生成正确答案但不准确的隐式推理轨迹。此外，揭示了CoT监督改变了内部Transformer计算机制。", "conclusion": "CoT有助于加速泛化，但并不能克服高算法复杂度的任务。CoT是作为一种动态特性在训练过程中逐渐显现的推理轨迹的忠实度。这些发现有助于更深入理解CoT在Transformer中的作用机制。"}
{"llm_update_time": "20251101", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.25796", "html_url": "https://arxiv.org/abs/2510.25796", "title": "在大型按需共享出行系统中使用仿真指导强化学习进行非短视匹配和再平衡", "title_en": "Non-myopic Matching and Rebalancing in Large-Scale On-Demand Ride-Pooling Systems Using Simulation-Informed Reinforcement Learning", "authors": "Farnoosh Namdarpour,Joseph Y. J. Chow", "background": "共享出行，简称拼车或微交通，是一种服务，乘客共享行程以减少费用和减缓交通拥堵及环境影响。尽管这种服务具有诸多优点，但是短视调度决策导致的局限性限制了其发展。", "innovation": "提出了一种基于仿真指导强化学习的方法来解决传统拼车系统的短视决策问题。该方法通过将拼车仿真嵌入到学习机制中，实现非短视决策，并提出了一个平衡闲置车辆的配套策略。", "conclusion": "通过非短视策略匹配乘客能够使服务率提高8.4%，同时减少乘客的车内时间和等待时间。此外，与传统的短视策略相比，该非短视策略经证明可以减少25%以上的车队规模，并保持相同的服务水平，从而减少运营成本。将再平衡操作整合到该框架中可以进一步减少乘客的等待时间27.3%，车内时间12.5%，且提高了服务率15.1%，但这会增加乘客的每分钟乘车时间。"}
{"llm_update_time": "20251101", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.25818", "html_url": "https://arxiv.org/abs/2510.25818", "title": "ScaleDiff：一种通过高效的、模型无关的扩散生成更高分辨率图像的方法", "title_en": "ScaleDiff: Higher-Resolution Image Synthesis via Efficient and Model-Agnostic Diffusion", "authors": "Sungho Koh,SeungJu Cha,Hyunwoo Oh,Kwanyoung Lee,Dong-Jin Kim", "background": "文本到图像的扩散模型在生成超过其训练分辨率的图像时常表现出性能下降。近期的一些无需训练的方法可以缓解这一限制，但是这些方法通常需要大量的计算，或者与最近的扩散变换模型（Diffusion Transformer）不兼容。", "innovation": "提出了一种名为ScaleDiff的模型无关且高效的框架，用于在无需额外训练的情况下扩展预训练扩散模型的分辨率。核心组件是邻域补丁注意机制（NPA），它通过非重叠补丁在自我注意层中减少了计算冗余。同时引入了潜在频率混合（LFM）机制来更好地生成细节，并应用了结构指导以增强去噪过程中的全局结构。", "conclusion": "实验结果表明，ScaleDiff在训练无足的方法中，以其图像质量和推理速度都达到了最先进的技术水平，适用于UNet和扩散变换模型架构。"}
{"llm_update_time": "20251101", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.25787", "html_url": "https://arxiv.org/abs/2510.25787", "title": "基于电压依赖突触塑性的无监督本地学习用于阻变和铁电突触", "title_en": "Unsupervised local learning based on voltage-dependent synaptic plasticity for resistive and ferroelectric synapses", "authors": "Nikhil Garg,Ismael Balafrej,Joao Henrique Quintino Palhares,Laura Bégon-Lours,Davide Florini,Donato Francesco Falcone,Tommaso Stecconi,Valeria Bragaglia,Bert Jan Offrein,Jean-Michel Portal,Damien Querlioz,Yann Beilliard,Dominique Drouin,Fabien Alibart", "background": "边缘计算设备上部署人工智能面临着能源消耗和功能性的重大挑战。受脑启发的学习机制可以提高这些设备在实时适应方面的性能，同时使用低功耗。纳米尺度的阻变存储器可能是实现这些边缘设备上的人工智能负载执行的关键技术。研究旨在解决如何通过突触可塑性机制提高这些设备的学习效率.", "innovation": "引入了电压依赖突触塑性（VDSP）作为基于Hebb原则的高效无监督和本地学习方法。VDSP方法允许在线学习，无需复杂的脉冲整形电路，从而适应不同类型的突触器件（TiO$_2$，HfO$_2$基金属氧化物折叠突触，以及HfZrO$_4$基铁电隧道结（FTJ）），并进行了系统的仿真验证，通过MNIST模式识别任务展示了出色的性能，涵盖了超过83%的准确率，使用200个神经元。此外，评估了设备变异性对其性能的影响，并提出了增强鲁棒性的策略.", "conclusion": "研究结果验证了通过VDSP机制进行无监督学习的有效性，并通过整合不同类型的突触器件展示了在边缘设备上实现高性能局部学习的潜力。"}
{"llm_update_time": "20251101", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.25798", "html_url": "https://arxiv.org/abs/2510.25798", "title": "MemEIC：迈向连续和组合的知识编辑", "title_en": "MemEIC: A Step Toward Continual and Compositional Knowledge Editing", "authors": "Jin Seong,Jiyun Park,Wencke Liermann,Hongseok Choi,Yoonji Nam,Hyun Kim,Soojong Lim,Namhoon Lee", "background": "大视觉语言模型（LVLMs）的信息动态性要求不断更新这些模型。虽然最近的知识编辑技术提供了有希望的方向，但它们通常集中在单独编辑单一模态（视觉或语言）。这种做法忽视了LVLMs的固有多模态性和知识更新的持续性，可能导致在考虑模态间的交互和不断知识精炼的需求时编辑效果不佳。因此，需要一种方法来应对这些限制，以实现LVLMs中的持续和组合知识编辑。", "innovation": "本文提出了MemEIC，这是一种新颖的方法，用于LVLMs中的持续性和组合知识编辑（CCKE）。MemEIC能够按顺序组合编辑视觉和文本知识，采用混合外部-内部编辑器，包括跨模态证据检索的双外部记忆和促进每一模态独立试点更新的双LoRA适配器。一个关键成分是类似于大脑的知连接器，仅在组合推理时选择性地激活，以整合不同模态的信息。研究表明，MemEIC在复杂多模态问题上的性能显著提升，并有效保留了先前的编辑，从而在LVLMs的CCKE中建立了新的基准。", "conclusion": "MemEIC方法显著改进了复杂多模态问题上的性能，并有效维护了先前的编辑，为LVLMs中的持续和组合知识编辑设定了新的标准。"}
{"llm_update_time": "20251101", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.25801", "html_url": "https://arxiv.org/abs/2510.25801", "title": "Metis-SPECS：通过自蒸馏偏好引导冷启动拆分多模态学习", "title_en": "Metis-SPECS: Decoupling Multimodal Learning via Self-distilled Preference-based Cold Start", "authors": "Kun Chen,Peng Shi,Haibo Qiu,Zhixiong Zeng,Siqi Yang,Wenji Mao,Lin Ma", "background": "近年来，可验证奖励的强化学习（RL）催生了“MLLM-r1”方法，将RL引入视觉语言模型。最常见的范式是在冷启动阶段使用有监督微调（SFT）来初始化策略，但在冷启动阶段采用SFT会导致指令式过拟合，削弱了分布外泛化能力，影响后续的RL效果。因此，研究者重新审视了冷启动方式，通过实验发现偏好训练方法（如DPO）在冷启动阶段具有更好的泛化能力。", "innovation": "提出了一种名为SPECS（Self-distilled, Preference-based Cold Start）的自蒸馏偏好引导冷启动框架，该框架通过自我蒸馏生成内在偏好数据对，避免依赖于更大教师模型或手动标注，并进行偏好训练，专注于浅层可移植的表面格式标准（如格式、结构和风格），而不是内容记忆；最终交给带有可验证奖励的RL以获得深层次的推理结果。实验结果表明，该框架在多个多模态基准测试上优于基线，并在MEGA-Bench和MathVista上分别提升了4.1%和12.2%的性能。额外的实验结果还显示，SPECS能够减少分布内“停滞”情况、提高探索性、稳定训练并提升性能上限。", "conclusion": "SPECS通过拆分多模态学习，实现了潜在更好的泛化性能和更好的RL性能。"}
{"llm_update_time": "20251101", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.25819", "html_url": "https://arxiv.org/abs/2510.25819", "title": "Agentic AI的标识管理：AI代理世界的授权、认证和安全的新前沿", "title_en": "Identity Management for Agentic AI: The new frontier of authorization, authentication, and security for an AI agent world", "authors": "Tobin South,Subramanya Nagabhushanaradhya,Ayesha Dissanayaka,Sarah Cecchetti,George Fletcher,Victor Lu,Aldo Pietropaolo,Dean H. Saxe,Jeff Lombardo,Abhishek Maligehalli Shivalingaiah,Stan Bounev,Alex Keisner,Andor Kesselman,Zack Proser,Ginny Fahs,Andrew Bunyea,Ben Moskowitz,Atul Tulshibagwale,Dazza Greenwood,Jiaxin Pei,Alex Pentland", "background": "随着AI代理的迅速发展，认证、授权和身份管理面临紧急挑战。当前基于代理的协议（如MCP）强调了清晰最佳实践的需求。对于高度自主的代理，未来将有复杂的长期问题，包括可扩展的访问控制、代理中心化身份、AI工作负载的差异化以及委派授权。该白皮书旨在为AI代理和访问管理的交汇点的参与者提供资源，概述了目前可用的代理安全解决方案，并提出了一项战略议程，以应对未来的广泛自主系统所需的基础认证、授权和身份问题。", "innovation": "该白皮书提出了基于代理身份管理的一系列资源和策略，特别是为高度自主的代理设计的解决方案。强调了长期规划和可扩展性的需求，探讨了如何通过智能化和自主化的方式来管理AI代理的识别和安全问题。这份白皮书为即将广泛使用的自主系统提供了重要的指导方针和技术支持。", "conclusion": "这份白皮书强调，为了适应未来广泛使用的自主系统，需要解决认证、授权和身份管理中的一些基本问题。它不仅回顾了现有的资源和工具，还提出了一个战略议程，旨在提供一种新的、适应AI代理的标识和安全框架，从而推动自主技术的发展和应用。"}
{"llm_update_time": "20251101", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.25924", "html_url": "https://arxiv.org/abs/2510.25924", "title": "使用代理转移因果效应", "title_en": "Transferring Causal Effects using Proxies", "authors": "Manuel Iglesias-Alonso,Felix Schur,Julius von Kügelgen,Jonas Peters", "background": "本文考虑了在一个多重领域设置中估计因果效应的问题。目标是估计因果效应，而这个效应由于未观察到的混杂因素在不同领域中会发生变化。作者假设可以访问隐藏混杂因素的代理指标，并且所有变量都是离散或分类的。研究在观察到代理变量的情况下，在目标领域中估计因果效应的可能性，即使治疗变量和响应变量是连续的。文章提供了估计目标领域中因果效应的方法，并证明了该方法在连续变量情况下也适用。", "innovation": "本文提出了两种估计技巧，并证明了这些方法的一致性以及如何推导出置信区间。作者在理论结果上通过模拟研究和一个关于网站排名对消费者选择的现实世界例子来支持他们的研究发现", "conclusion": "在假设能够访问隐藏混杂因素的代理变量，并且所有变量都为离散或分类的情况下，作者证明了可以在目标领域估计因果效应，并提供了相应的估计技术和置信区间。研究结果表明，即使在连续变量的情况下，所提出的方法也是适用的，并且通过模拟和实际例子验证了方法的有效性"}
{"llm_update_time": "20251101", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.25904", "html_url": "https://arxiv.org/abs/2510.25904", "title": "评价LLM辅助注解在透视化设置中的影响：FrameNet注解案例", "title_en": "Evaluating the Impact of LLM-Assisted Annotation in a Perspectivized Setting: the Case of FrameNet Annotation", "authors": "Frederico Belcavello,Ely Matos,Arthur Lorenzi,Lisandra Bonoto,Lívia Ruiz,Luiz Fernando Pereira,Victor Herbst,Yulla Navarro,Helen de Andrade Abreu,Lívia Dutra,Tiago Timponi Torrent", "background": "使用基于LLM的应用程序作为加速或替代人类劳动以创建语言资源和数据集的手段已成为现实。尽管这些工具在语言研究中具有巨大潜力，但它们在创建带有标注的数据集方面的性能评估，特别是从语义角色标注的角度进行综合评估，仍然缺乏。这项研究通过评估基于LLM的语义角色标注器在FrameNet语义标注中的半自动注释自动化程度，填补了这一空白。", "innovation": "该研究通过实证方法比较了独立、全自动和半自动注释三种设置下的标注时间、覆盖率和多样性，发现半自动注释设置在保持与独立注释相似的覆盖范围的同时增加了框架多样性，而全自动注释在所有指标上表现不佳，仅在标注时间上占有优势。", "conclusion": "研究表明，半自动注释设置是改善标注效率和质量的有效途径，同时也为LLM在语义标注及其他NLP任务中的应用提供了新的视角。"}
{"llm_update_time": "20251101", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.25890", "html_url": "https://arxiv.org/abs/2510.25890", "title": "PRISM: 通过LLM与MDE协同作用及分层约束生成带证明的可审计构件", "title_en": "PRISM: Proof-Carrying Artifact Generation through LLM x MDE Synergy and Stratified Constraints", "authors": "Tong Ma,Hui Lai,Hui Wang,Zhenhu Tian,Jizhou Wang,Haichao Wu,Yongfan Gao,Chaochao Li,Fengjie Xu,Ling Fang", "background": "在安全性和合规性关键领域的监管要求日益严格的背景下，人工生成和验证符合监管要求的构件和证据既耗时又效率低下。有必要开发新的方法和技术来加速这一过程并降低成本。", "innovation": "PRISM将大型语言模型与模型驱动工程相结合，通过统一元模型（UMM）整合异构模式和监管文本到单一语义空间，通过集成约束模型（ICM）将结构和语义需求编译为执行构件（如GBNF、DFA）和后生成验证器（如SHACL、SMT），并通过约束引导的验证生成（CVG）通过两层执行来应用这些需求，结构约束驱动前置安全解码，语义/逻辑验证生成可机器验证的证书，在出现违规时执行审计引导的修复并记录生成轨迹以供合规审查。", "conclusion": "PRISM在汽车软件工程（AUTOSAR）和跨境法律管辖区（布鲁塞尔I bis）中进行了评估，生成了结构上有效的、可审计的构件，这些构件能够与现有工具集集成，显著减少了手动修复努力，为自动化生成在内置保证机制下的构件开辟了实际途径。"}
{"llm_update_time": "20251101", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.25863", "html_url": "https://arxiv.org/abs/2510.25863", "title": "AAGATE: 一个符合NIST AI RMF治理平台的自主AI", "title_en": "AAGATE: A NIST AI RMF-Aligned Governance Platform for Agentic AI", "authors": "Ken Huang,Jerry Huang,Yasir Mehmood,Hammad Atta,Muhammad Zeeshan Baig,Muhammad Aziz Ul Haq", "background": "在生产环境中，自主的语言模型驱动代理面临着特有的安全和治理挑战，传统的应用程序安全（AppSec）工具难以应对这些快节奏、自动化的需求。因此，本文旨在介绍一种名为Agentic AI Governance Assurance & Trust Engine（AAGATE）的Kubernetes原生控制平面，这种平台旨在解决自主语言模型驱动代理所带来的独特安全和治理难题。", "innovation": "AAGATE通过实施NIST的AI风险管理框架（AI RMF），引入了专门的安全框架来为每个RMF功能提供支持：Agentic AI威胁建模MAESTRO框架用于映射，融合OWASP的AIVSS和SEI的SSVC的混合体用于衡量，以及源自Cloud Security Alliance的Agentic AI红队指南用于管理。AAGATE还将零信任服务网格、可解释的策略引擎、行为分析和分散化的问责挂钩相结合，提供了一个持续且可验证的治理解决方案，支持自主AI的可靠、透明和可扩展部署。此外，AAGATE还进一步包含了数字身份权利的DIRF、逻辑层注入的LPCI防御以及认知退化监测的QSAF监控，以确保治理覆盖系统性、对抗性和伦理风险。", "conclusion": "AAGATE平台将促进自主AI的安全、透明和可扩展的部署，并且通过集成一系列专门的安全框架和新的治理机制，实现了全面的自主AI治理，保障了系统的安全性、透明度和可扩展性。"}
{"llm_update_time": "20251101", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.25929", "html_url": "https://arxiv.org/abs/2510.25929", "title": "市场制作中的多智能体强化学习：无潜规则的竞争", "title_en": "Multi-Agent Reinforcement Learning for Market Making: Competition without Collusion", "authors": "Ziyi Wang,Carmine Ventre,Maria Polukarov", "background": "AI智能体之间的互动在市场上的出现引发了算法共谋的问题，即不同AI智能体互动是否会导致共谋现象。市场如何受到这种情况下的新兴行为（如卡特尔或更高级智能体的市场主导地位）的影响，是一个重要的研究问题。研究团队提出了一种分层的多智能体强化学习框架来探讨市场制作中的算法共谋问题。这个框架包括一个自利市场制作商（Agent A），一个由对手塑造的不确定性环境中训练的自利对手，和三个底层竞争对手：自利的Agent B1、竞争性的Agent B2以及混合Agent B$^\backslash$star$^\backslash$。", "innovation": "研究人员提出了一种分层的多智能体强化学习框架来研究市场制作中的算法共谋问题，这种框架引入了不同类型的行为体来更真实地模拟市场环境。", "conclusion": "实验结果显示，Agent B2在零和博弈中对B1表现出主导性能，能有效地占据交易量并缩短平均价差，从而提高市场执行的效率。而Agent B$^\backslash$star$^\backslash$尽管表现出利己倾向，但通过适应性报价能够占据主导市场份额，但对Agent A和B1的奖励造成的负面影响比B2小。研究表明，适应性激励控制有助于异质环境中的可持续战略共存，并为算法交易系统的行为设计提供了评估框架。"}
{"llm_update_time": "20251101", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.25935", "html_url": "https://arxiv.org/abs/2510.25935", "title": "基于过程挖掘的软件开发工作流分析与预测系统", "title_en": "A Process Mining-Based System For The Analysis and Prediction of Software Development Workflows", "authors": "Antía Dorado,Iván Folgueira,Sofía Martín,Gonzalo Martín,Álvaro Porto,Alejandro Ramos,John Wallace", "background": "CodeSight 是一个从头到尾的系统，旨在预测软件开发工作流中的截止日期遵守情况。系统直接从 GitHub 捕获开发和部署数据，将其转换为过程挖掘日志以进行详细分析。", "innovation": "CodeSight 使用基于 LSTM 的模型，根据顺序活动踪迹和静态特征预测剩余的 PR 解决时间，从而实现对潜在截止日期违反的早期识别。系统展示了在预测截止日期遵守方面具有高精度和 F1 分数，说明了将过程挖掘与机器学习结合用于预测软件开发工作流的价值。", "conclusion": "CodeSight 系统通过综合过程挖掘日志、生成度量和仪表板，为软件开发工作流中的 PR 活动模式和工作流效率提供行动指南。此外，通过应用 LSTM 模型，该系统能够在早期发现潜在的里程碑超时，从而促进预测性软件项目管理。"}
{"llm_update_time": "20251101", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.25954", "html_url": "https://arxiv.org/abs/2510.25954", "title": "Geospatial Foundation Model数据在预测卫生设施项目输出中的应用与验证——以马拉维案例研究为例", "title_en": "Application and Validation of Geospatial Foundation Model Data for the Prediction of Health Facility Programmatic Outputs -- A Case Study in Malawi", "authors": "Lynn Metz,Rachel Haggard,Michael Moszczynski,Samer Asbah,Chris Mwase,Patricia Khomani,Tyler Smith,Hannah Cooper,Annie Mwale,Arbaaz Muslim,Gautam Prasad,Mimi Sun,Tomer Shekel,Joydeep Paul,Anna Carter,Shravya Shetty,Dylan Green", "background": "在低收入和中等收入国家（LMICs），常规健康数据的可靠性和完整性常受到报告延迟和覆盖不全的影响，这需要探索新的数据来源和分析方法。本研究评估了三种GeoFM嵌入源——谷歌人口动态基础模型(PDFM)、谷歌AlphaEarth（基于卫星图像）和移动电话通话详细记录(CDR)——在马拉维15个常规健康项目输出中的预测性能，以改进传统地理空间插值方法。", "innovation": "本研究通过评估三种GeoFM嵌入源的预测性能，提出了一种利用GeoFM数据改进常规健康项目输出预测的新方法，特别是通过集成所有三个嵌入源开发的多GeoFM模型，显著提高了某些健康和人口统计结果的预测准确性。", "conclusion": "研究结果表明，GeoFM嵌入数据能够为选择性的健康和人口统计结果在LMIC背景下提供适度的预测改进。我们得出结论，结合多种GeoFM来源可以有效补充和加强受限的常规健康信息系统，是一种高效而有价值的工具。"}
{"llm_update_time": "20251101", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.25947", "html_url": "https://arxiv.org/abs/2510.25947", "title": "在语言模型预训练中重新审视多语言数据混合", "title_en": "Revisiting Multilingual Data Mixtures in Language Model Pretraining", "authors": "Negar Foroutan,Paul Teiletche,Ayush Kumar Tarun,Antoine Bosselut", "background": "关于在预先训练大型语言模型（LLMs）时使用不同多语言数据混合的影响，一直存在争议，人们常常担心语言覆盖范围和模型性能之间的潜在权衡（即多语文本的诅咒）。", "innovation": "该研究通过训练参数量分别为1.1亿和3亿的语言模型，且这些模型使用了从25种到400种不同语言的多元语料库，挑战了关于多语言训练的一些普遍观点。研究发现，将英语数据与多语言数据混合并不一定会损害各自语种内的性能，只要预训练语料库中包含了足够的该语言的标记数。此外，使用英语作为中间语言（即资源丰富的语言，有助于多语言泛化的关键过程）在多种语言族中都显示出收益。相反，从特定语言家族中选择一种作为中间语言，并不一定能够提升该家族内其他语言的性能。最后，研究并未发现随着训练语言的数量增加，大规模模型中存在着显著的多语文本诅咒。", "conclusion": "研究结果表明，当多语言数据得到适当平衡时，可以增强语言模型能力，而不会损害性能，即使在资源较少的环境中也是如此。"}
{"llm_update_time": "20251101", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.25960", "html_url": "https://arxiv.org/abs/2510.25960", "title": "WaveVerif：基于声学旁路的机器人工作流验证", "title_en": "WaveVerif: Acoustic Side-Channel based Verification of Robotic Workflows", "authors": "Zeynep Yasemin Erdogan,Shishir Nagaraja,Chuadhry Mujeeb Ahmed,Ryan Shah", "background": "在当前的机器人应用环境中，确保机器人正确执行预定命令是一个重要的问题。本文的研究背景在于通过声学侧信道分析（ASCA）来监控和验证机器人是否正确执行其预定的命令，特别是在一些对机器人操作要求较高的环境下，需要实现实时、低成本且无需硬件改动的验证方法。", "innovation": "本文提出了一种基于声学排放的机器学习工作流验证系统，它可以实时确定机器人行为是否与预期的命令一致。通过支持向量机（SVM）、深度神经网络（DNN）、循环神经网络（RNN）和卷积神经网络（CNN）四种不同的分类器进行评估，结果表明在基线条件下，可以实现超过80%的准确率验证单个机器人动作，并且可以识别出类似拣选放置和包装的工作流程，具有较高的置信度。此项研究创新点在于通过声学信号来实现对敏感机器人环境的实时、低成本且无需额外硬件的验证。", "conclusion": "研究结果表明，声学信号可以在不需要硬件改动的情况下支持敏感的机器人环境下的实时、低成本被动验证。这种方法为确保机器人操作符合预期提供了一种有效的解决方案。"}
{"llm_update_time": "20251101", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.26007", "html_url": "https://arxiv.org/abs/2510.26007", "title": "可靠的责任人工智能度量标准的追求", "title_en": "The Quest for Reliable Metrics of Responsible AI", "authors": "Theresia Veronika Rampisela,Maria Maistro,Tuukka Ruotsalo,Christina Lioma", "background": "人工智能（AI）的发展，包括科学中的AI（AIS），应该遵循负责任的AI原则。虽然负责的AI进步通常通过评估指标来量化，但很少有人力资源用于评估这些度量标准自身的稳健性和可靠性。早期研究已经探讨了推荐系统等AI应用中公平性指标的稳健性，但需要总结和提炼相关成果，为开发负责任的AI指标提供一套非详尽的指导原则。这些指导原则适用于广泛的人工智能应用，包括科学中的AI应用（AIS）.", "innovation": "本文总结和提炼了关于推荐系统中公平性指标稳健性的早期研究，提出了适用于多种AI应用环境的非详尽指导原则，旨在提高负责的AI度量标准的可靠性和稳健性.", "conclusion": "本文总结了针对负责任的AI指标稳健性的相关研究，并提出了开发可靠负责任AI度量标准的指导原则，这些原则适用于多种AI应用场景."}
{"llm_update_time": "20251101", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.26004", "html_url": "https://arxiv.org/abs/2510.26004", "title": "DARTS:基于无人机的人工智能驱动的实时交通事故检测系统", "title_en": "DARTS: A Drone-Based AI-Powered Real-Time Traffic Incident Detection System", "authors": "Bai Li,Achilleas Kourtellis,Rong Cao,Joseph Post,Brian Porter,Yu Zhang", "background": "快速和可靠的事故检测对于减少事故相关的死亡、伤害和交通拥堵至关重要。然而，传统的检测方法，如闭路电视监控、汽车记录仪记录和基于传感器的检测，存在分割检测与验证的过程，灵活性有限，且需要密集的基础设施或高渗透率，限制了适应性和可扩展性的应用，难以应对事故热点的转移。", "innovation": "我们开发了DARTS，这是一种基于无人机的人工智能驱动的实时交通事故检测系统。DARTS结合了无人机的高机动性和高空视角的适应性监控能力，使用热成像技术提高低能见度条件下的性能并保护隐私，同时使用轻量级深度学习框架实现实时车辆轨迹提取和事故检测。该系统在自收集的数据集上达到了99%的检测准确率，并通过基于Web的界面支持实时的视觉验证、严重程度评估和事故诱导的交通拥堵监控。", "conclusion": "该研究展示了向更灵活和集成的实时交通事故检测系统的可行步骤，具有显著的现代交通管理运营效率和响应能力的重要含义。"}
{"llm_update_time": "20251101", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.25992", "html_url": "https://arxiv.org/abs/2510.25992", "title": "监督强化学习：从专家轨迹到逐步推理", "title_en": "Supervised Reinforcement Learning: From Expert Trajectories to Step-wise Reasoning", "authors": "Yihe Deng,I-Hung Hsu,Jun Yan,Zifeng Wang,Rujun Han,Gufeng Zhang,Yanfei Chen,Wei Wang,Tomas Pfister,Chen-Yu Lee", "background": "大规模语言模型（LLMs）在需要多步推理的问题上往往表现不佳。对于小型开源模型，强化学习结合可验证奖励（RLVR）在正确解很少被采样的情况下即使经历了多次尝试也会失败，而监督微调（SFT）则倾向于通过逐个模仿token的方式过度拟合长示例。为了解决这一问题，本文提出了监督强化学习（SRL）框架，通过将问题解决过程重新定义为生成逻辑“动作”的序列，SRL训练模型在作出每一项行动之前生成内部推理逻辑。", "innovation": "SRL引入了一个新的框架，将问题解决过程重新定义为生成一系列逻辑“动作”，并训练模型在作出每个决策之前生成内部的推理过程。SRL使用逐步的方式提供基于模型动作与SFT数据集中提取的专家动作之间相似性的平滑奖励，即使所有回放都不正确，这种监督也能提供丰富的学习信号，同时鼓励受到专家示范指导的灵活推理。", "conclusion": "SRL使得小型模型能够学习此前通过SFT或RLVR无法学会的复杂问题。此外，在初始化训练时使用SRL，然后再用RLVR进行细化训练，能够获得最佳的总体性能。SRL不仅在推理基准测试中表现出色，还能有效泛化到代理型软件工程任务，确立了其作为针对推理型LLMs的强大且多功能训练框架的地位。"}
{"llm_update_time": "20251101", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.25976", "html_url": "https://arxiv.org/abs/2510.25976", "title": "Brain-IT：通过脑交互变换器进行fMRI图像重建", "title_en": "Brain-IT: Image Reconstruction from fMRI via Brain-Interaction Transformer", "authors": "Roman Beliy,Amit Zalcher,Jonathan Kogman,Navve Wasserman,Michal Irani", "background": "通过功能性磁共振成像(fMRI)记录重建人们所见图像提供了一种非侵入式的观察人类大脑的窗口。尽管最近通过扩散模型的发展取得了进展，但现有方法往往缺乏对实际所见图像的真实再现性。", "innovation": "我们提出了“Brain-IT”，这是一种脑灵感的方法，通过一种名为Brain Interaction Transformer (BIT)的组件来解决这一挑战，它允许功能相似的脑体素集合之间的有效交互。所有的模型组件在整个集群和受试者之间共享，使得在有限的数据量下可以高效地训练模型。BIT预测两种局部补丁级图像特征：(i) 高级语义特征，引导扩散模型向正确的图像语义内容进行；(ii) 低级结构特征，帮助扩散过程以正确的粗略布局初始化。BIT的设计使得信息可以直接从脑体素簇流向局部图像特征。这种方法能够从fMRI重建图像，真实地再现所见图像，并且在视觉效果和标准客观指标方面超越当前最先进的方法。仅使用新受试者1小时的fMRI数据，就达到了与训练于40小时录音的现有方法相当的结果。", "conclusion": "我们的方法从fMRI重建图像，能够真实地再现所见图像，并且在视觉效果和标准客观指标上超越了当前最先进的方法。此外，仅使用新受试者1小时的fMRI数据，就达到了现有方法在全40小时录音训练下的相当结果。"}
{"llm_update_time": "20251101", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.26032", "html_url": "https://arxiv.org/abs/2510.26032", "title": "基于人工智能分析的放射学报告：偶发性甲状腺发现的流行病学及其后果", "title_en": "Artificial Intelligence-Enabled Analysis of Radiology Reports: Epidemiology and Consequences of Incidental Thyroid Findings", "authors": "Felipe Larios,Mariana Borras-Osorio,Yuqi Wu,Ana Gabriela Claros,David Toro-Tobon,Esteban Cabezas,Ricardo Loor-Torres,Maria Mateo Chavez,Kerly Guevara Maldonado,Luis Vilatuna Andrango,Maria Lizarazo Jimenez,Ivan Mateo Alzamora,Misk Al Zahidy,Marcelo Montero,Ana Cristina Proano,Cristian Soto Jacome,Jungwei W. Fan,Oscar J. Ponce-Ponte,Megan E. Branda,Naykky Singh Ospina,Juan P. Brito", "background": "非甲状腺疾病影像检查中意外发现甲状腺结节（ITFs）的频次不断增加，但其发生频率、特征及其临床后果尚未明确。", "innovation": "开发并验证了一种基于变压器的自然语言处理（NLP）管道，用于识别放射学报告中的ITFs，并分析其发生率、特征及临床结果。", "conclusion": "ITFs 普遍且与检测小型低风险甲状腺癌的连锁反应密切相关。这些发现强调了ITFs在甲状腺癌过诊断中的作用，突显了标准化报告及更谨慎随访的必要性。"}
{"llm_update_time": "20251101", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.26017", "html_url": "https://arxiv.org/abs/2510.26017", "title": "使用深度学习的气候适应性沿海城市洪水预测", "title_en": "Climate Adaptation-Aware Flood Prediction for Coastal Cities Using Deep Learning", "authors": "Bilal Hassan,Areg Karapetyan,Aaron Chung Hin Chow,Samer Madanat", "background": "气候变化和海平面上升（SLR）对沿海城市构成了日益严重的威胁，增加了精确预测潜在洪水灾害的迫切需求。传统的物理驱动的水动力模拟器虽然精确，但对于城市规模的沿海规划应用来说，计算成本高昂且不实用。尽管深度学习（DL）技术提供了替代方案，但它们通常受到数据稀缺和高维输出要求的限制。", "innovation": "我们利用一种最近提出的基于视觉的低资源消耗的深度学习框架，开发了一种新颖的轻量化卷积神经网络（CNN）模型，用于预测在不同SLR投影和海岸线适应场景下的沿海洪水。此外，我们展示了该模型能够在不同的地理背景下泛化，使用来自阿布扎比和旧金山的两个不同地区的数据集。我们的研究结果表明，所提出的模型在预测洪水深度图的平均绝对误差（MAE）上表现出色，较先进方法减少近20%。", "conclusion": "这些结果突显了我们方法的潜力，可以作为一种可扩展且实用的沿海洪水管理工具，帮助决策者根据日益严重的气候变化影响制定有效的缓解策略。"}
{"llm_update_time": "20251101", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.26024", "html_url": "https://arxiv.org/abs/2510.26024", "title": "重新审视跨语言对齐：平衡知识转移和文化侵蚀的多语言LLMs", "title_en": "Rethinking Cross-lingual Alignment: Balancing Transfer and Cultural Erasure in Multilingual LLMs", "authors": "HyoJung Han,Sweta Agrawal,Eleftheria Briakou", "background": "跨语言对齐（CLA）旨在对齐多语言表示，使得大型语言模型（LLMs）能够无缝地在语言间转移知识。然而，我们假设，这一旨在实现表示收敛的努力可能无意中导致“文化侵蚀”，即功能上丧失提供基于查询语言的文化背景响应的能力。", "innovation": "本文引入了一个全面的评估框架——转移- localization平面，该框架量化了知识转移的必要性和文化侵蚀的不良影响，并重新评估了最近的跨语言对齐方法。基于此发现，提出了一种名为外科手术定向的方法（Surgical Steering），它在推理时通过针对不同层的激活进行定向，实现了两种竞争目标之间的更好平衡。", "conclusion": "作者的研究发现，通用事实传递和文化特定知识的最佳可调性分别发生在不同的模型层。基于这一发现，提出的外科手术定向方法能够在两种竞争维度之间实现更好的平衡，有效克服了现有对齐技术的局限性，从而提供更好的跨语言的知识转移和文化响应平衡。"}
{"llm_update_time": "20251101", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.26014", "html_url": "https://arxiv.org/abs/2510.26014", "title": "离散时间生存分析的双重混合专家框架", "title_en": "Dual Mixture-of-Experts Framework for Discrete-Time Survival Analysis", "authors": "Hyeonjun Lee,Hyungseob Shin,Gunhee Nam,Hyeonsoo Lee", "background": "生存分析是用于建模感兴趣事件发生时间的任务，在临床和生物医学研究中广泛应用。主要挑战在于不仅要建模患者异质性，还要适应基于个体特征和时间动态的风险预测。目前的方法难以同时解决这两个问题。本文提出了一种双重混合专家（dual mixture-of-experts, dual-MoE）框架用于离散时间生存分析。该模型结合了特征编码混合专家进行亚组意识表示学习，以及利用患者特征和时间嵌入来捕捉时间动态的危险混合专家。这种方法灵活地与现有的基于深度学习的生存分析管道集成。", "innovation": "本文提出的双重混合专家框架创新性地将特征编码混合专家和危险混合专家相结合，能够同时建模患者异质性和捕捉时间动态，从而提升风险预测的准确性。实验证明，该方法在METABRIC和GBSG乳腺癌数据集上的表现优于现有方法，尤其在时间依赖性C指数上提高了0.04，甚至在与Consurv框架结合后性能进一步提升。", "conclusion": "通过采用双重混合专家框架，本文有效解决了生存分析中的患者异质性和时间动态建模问题，提高了风险预测的准确性。该方法的双重设计使其能够灵活地与现有的深度学习基线生存分析管道集成，显著提升了多个乳腺癌数据集的表现。"}
{"llm_update_time": "20251101", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.26020", "html_url": "https://arxiv.org/abs/2510.26020", "title": "PORTool: 利用奖励树进行工具使用的大语言模型训练", "title_en": "PORTool: Tool-Use LLM Training with Rewarded Tree", "authors": "Feijie Wu,Weiwu Zhu,Yuxiang Zhang,Soumya Chatterjee,Jiarong Zhu,Fan Mo,Rodin Luo,Jing Gao", "background": "当前的工具使用大语言模型（LLMs）是在静态数据集上进行训练的，这使得它们能够与外部工具进行交互并执行多步骤的工具集成推理，从而生成工具调用轨迹。但这些模型只是模仿了工具调用的一般套路，没有探索可能的解决方案，在动态的工具调用环境中表现有限。", "innovation": "本文提出了一种基于强化学习（RL）的方法PORTool，鼓励大语言模型探索可能的答案路径。该方法首先生成一系列路径，其中有些路径共享前几步形成树状结构。然后，基于每个步骤生成正确答案和成功调用工具的能力给予奖励，共享的步骤给予相同的奖励，而同一分叉下的不同步骤给予不同的奖励。最后，这些步骤奖励用于计算分支相对优势，并与路径相对优势结合，来训练大语言模型进行工具使用。", "conclusion": "实验使用17种不同工具处理用户查询，涵盖时间敏感和时间不变的主题。通过进行消融研究系统地验证了步骤奖励的必要性和设计的鲁棒性。与现有的训练方法进行比较表明，PORTool在最终准确度和工具调用步骤数方面有显著改进。"}
{"llm_update_time": "20251101", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.26037", "html_url": "https://arxiv.org/abs/2510.26037", "title": "SIRAJ: 通过训练精简结构化推理实现多样化和高效的LLM代理红队测试", "title_en": "SIRAJ: Diverse and Efficient Red-Teaming for LLM Agents via Distilled Structured Reasoning", "authors": "Kaiwen Zhou,Ahmed Elgohary,A S M Iftekhar,Amin Saied", "background": "LLM代理具备计划和调用工具的能力，这使得它们面临新的安全风险，因此需要全面的红队系统来发现漏洞并确保其安全部署。", "innovation": "提出了一种名为SIRAJ的通用红队框架，用于任意黑盒LLM代理。该框架采用动态两步过程，首先定义代理并生成多样化的基本测试案例，然后迭代构建和细化基于先前试验执行轨迹的基于模型的对抗攻击。此外，提出了一种模型精简方法，利用教师模型推理的结构化形式来训练同样有效的较小模型。", "conclusion": "在不同评估代理设置中，SIRAJ的基本测试案例生成方法实现了2-2.5倍的风险结果和工具调用轨迹覆盖率提升。精简后的8B红队模型使攻击成功率提高了100%，超越了671B的Deepseek-R1模型。消融和分析验证了迭代框架、结构化推理的有效性以及红队模型的一般化能力。"}
{"llm_update_time": "20251101", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.26038", "html_url": "https://arxiv.org/abs/2510.26038", "title": "Do Students Debias Like Teachers? On the Distillability of Bias Mitigation Methods", "title_en": "Do Students Debias Like Teachers? On the Distillability of Bias Mitigation Methods", "authors": "Jiali Cheng,Chirag Agarwal,Hadi Amiri", "background": "知识蒸馏（KD）是一种有效的模型压缩方法和模型间知识传递的方式。然而，它对模型抵抗虚假相关性（导致模型在未见过的数据上表现下降）的影响尚未得到广泛研究。本文研究了知识蒸馏对自然语言推理（NLI）和图像分类任务中，教师模型到学生模型的去偏（debiasing）能力的可传递性的影响。", "innovation": "研究通过详细实验发现了几个关键结论：（i）总体上，蒸馏后模型的去偏能力被削弱；（ii）训练去偏模型不会从教师知识中受益；（iii）虽然模型的整体稳健性可能在蒸馏后保持稳定，但在不同类型的偏见之间可能会有显著变化；（iv）识别了导致蒸馏后不同行为的内部关注模式和电路。基于上述发现，本文提出了三种有效的方法来提高去偏方法的可蒸馏性：高质量数据增强，迭代知识蒸馏，以及使用教师模型权重初始化学生模型。据我们所知，这是首次大规模研究KD对去偏及其内部机制的影响。", "conclusion": "这些发现提供了对KD如何运作以及如何设计更好的去偏方法的理解。"}
{"llm_update_time": "20251101", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.26061", "html_url": "https://arxiv.org/abs/2510.26061", "title": "用于高效解决异质二次规划问题的数据驱动投影生成", "title_en": "Data-driven Projection Generation for Efficiently Solving Heterogeneous Quadratic Programming Problems", "authors": "Tomoharu Iwata,Futoshi Futami", "background": "本文提出了一种用于高效解决高维二次规划（QP）问题的数据驱动框架。通过使用实例特定的投影方法减少QP变量的数量，该框架能够为每个QP实例生成定制的投影，从而即使是对未见过的问题也能生成高质量的解决方案。", "innovation": "设计了一个基于图神经网络的模型来生成针对每个QP实例定制的投影，并将此训练问题表述为一个多级优化问题。内层优化使用QP求解器在给定投影下解决QP，而外层优化更新模型参数。为了高效解决这个多级优化问题，开发了一个不需要通过求解器反向传播参数梯度的算法。并且，对通过神经网络生成的投影矩阵解决QP的能力提供了理论分析。", "conclusion": "实验结果表明，本方法能在较短计算时间内生成高可行质量的解，优于现有方法。"}
{"llm_update_time": "20251101", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.26018", "html_url": "https://arxiv.org/abs/2510.26018", "title": "RADRON：使用柯普滕相机的MAVs协同探测离子辐射源", "title_en": "RADRON: Cooperative Localization of Ionizing Radiation Sources by MAVs with Compton Cameras", "authors": "Petr Stibinger,Tomas Baca,Daniela Doubravova,Jan Rusnak,Jaroslav Solc,Jan Jakubek,Petr Stepan,Martin Saska", "background": "本文介绍了一种通过协作微型空中车辆（MAVs）定位放射性物质的新方法。该方法利用最先进的单探测器柯普滕相机作为一种极为灵敏的辐射探测器，尽管尺寸小，但重量仅为40克。这种轻量级的探测器为通过协作敏捷的MAVs团队进行辐射探测提供了新的可能性。MAVs在紧密协作的群组中稳定，以最大化柯普滕相机获得的信息量，迅速定位辐射源，甚至跟踪移动的辐射源。数据读取和处理在MAVs上直接进行，并将结果用于实时反馈，驱动车辆的运动。通过融合柯普滕相机的测量结果，本文提出了一个新颖的基本概念，即使从极为稀疏的数据测得也能实时估计辐射源的位置。这种方法在应对突发辐射泄漏等紧急情况时具有重要意义，能够提供有效的监测手段。", "innovation": "本文提出了一种创新的方法，利用协作微型空中车辆和柯普滕相机进行放射性物质的精确定位。具体而言，该方法包括以下创新点：1) 利用柯普滕相机进行实时、高精度的辐射探测；2) 通过紧密协作的MAVs群组，最大限度地提高信息获取效率；3) 通过实时反馈机制驱动MAVs的运动，迅速且准确地找到辐射源；4) 即使从稀疏的数据测量中估计辐射源的位置，提供了一种全新的辐射检测和源定位方法。", "conclusion": "本文提出的方法成功地展示了如何通过MAVs和柯普滕相机协作实现对离子辐射源的精确定位。这种方法不仅提高了辐射探测的效率和准确性，还在现实场景中应用潜力巨大。尤其是在紧急情况或复杂环境中迅速定位和跟踪辐射源方面，具有显著的优势。通过进一步的研究和测试，该方法有望在实际应用中发挥重要作用。"}
{"llm_update_time": "20251101", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.26052", "html_url": "https://arxiv.org/abs/2510.26052", "title": "动态VLM引导的负样本提示在扩散模型中的应用", "title_en": "Dynamic VLM-Guided Negative Prompting for Diffusion Models", "authors": "Hoyeon Chang,Seungjin Kim,Yoonseok Choi", "background": "当前的负样本提示方法通常使用固定的负提示来引导生成过程。然而，固定的负提示在处理复杂和特定场景的任务或数据集中可能会显得不够灵活，难以生成适配文本和图像上下文的正确负样本提示。该论文探讨了一种新的方法，该方法利用视觉-语言模型（VLMs）在去噪过程中自适应地生成负样本文本，以提高生成结果的准确性。", "innovation": "该研究提出了一种新颖的方法，利用视觉-语言模型（VLMs），在扩散模型的去噪过程中动态生成合适的负样本提示。具体来说，该方法在特定去噪步骤中生成中间图像预测，然后查询VLM来生成相应上下文的负样本提示。这种方法与传统的固定负提示相比，能够更灵活地适配复杂的文本和图像上下文。", "conclusion": "该研究在多种基准数据集上评估了所提出的方法，并展示了负样本引导强度与文本-图像对齐之间的权衡。研究表明，与使用固定负样本提示的方法相比，动态生成负样本提示在大多数情况下可以提高生成图像的质量和准确性。"}
{"llm_update_time": "20251101", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.26083", "html_url": "https://arxiv.org/abs/2510.26083", "title": "Nirvana: 具有任务感知记忆机制的专业型泛化模型", "title_en": "Nirvana: A Specialized Generalist Model With Task-Aware Memory Mechanism", "authors": "Yuhua Jiang,Shuang Cheng,Yihao Liu,Ermo Hua,Che Jiang,Weigao Sun,Yu Cheng,Feifei Gao,Biqing Qi,Bowen Zhou", "background": "传统的大语言模型结构，如Transformer、线性注意力模型和混合模型，缺乏由任务信息指导的专业化记忆机制。现有的模型在保持广泛能力的同时，未能实现针对特定目标领域的专家级性能。因此，需要一种能够在保留广泛能力的同时，达到特定任务领域专家级性能的专业型泛化模型。", "innovation": "本文提出了Nirvana，一种具有专业化记忆机制、线性时间复杂度、并在测试时提取任务信息的模型。Nirvana引入了任务感知记忆触发（Trigger）机制，能够根据当前任务的需求灵活调整记忆机制。此外，Nirvana还设计了特定记忆更新器（Updater），能够根据Trigger动态记忆上下文。通过实验证明，Nirvana在一般的语言任务和专业的医疗任务中均显示出竞争力或优越性。", "conclusion": "通过将冻存的Nirvana主干模型与轻量级编码器进行后训练，并在配对的电磁信号和MRI图像上进行测试，结果显示Nirvana能够适应MRI领域，生成更高的质量MRI重建和准确的初步临床报告。这些结果表明，Nirvana具有有效处理专业任务的能力，并且能够超越使用传统大语言模型主干的模型。"}
{"llm_update_time": "20251101", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.26099", "html_url": "https://arxiv.org/abs/2510.26099", "title": "SAFE：通过地球分层评估预测的新型AI气象评估方法", "title_en": "SAFE: A Novel Approach to AI Weather Evaluation through Stratified Assessments of Forecasts over Earth", "authors": "Nick Masi,Randall Balestriero", "background": "传统机器学习模型评估方法主要依据测试集中的所有样本的平均损失来进行，这种做法在气象和气候领域相当于地理上在整个地球范围内进行平 均效果评估，但忽视了人类发展和地理分布的非均匀性。因此，需要一种新的方法来更好地评估和改进气象预报模型的效果。", "innovation": "提出了一种名为SAFE（Stratified Assessments of Forecasts over Earth）的新方法，该方法通过整合各种地理空间数据来分层评估地球上的预测性能。SAFE可以根据国家、全球次区域、收入水平和土地覆盖类型（陆地或水域）对地理网格点进行分层，以评估每个单独分层属性（如每个国家的准确性）的表现。", "conclusion": "SAFE方法揭示了当前最先进的基于AI的天气预测模型在每个属性上的预测技巧存在差异，通过不同提前量对各种气候变量进行分层评估，从全球平均指标中超越，首次明确了最有效的模型和最公平的模型在哪方面表现更好或更差。SAFE软件包已经开源并提供，有助于后续类似研究的进行。"}
{"llm_update_time": "20251101", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.26068", "html_url": "https://arxiv.org/abs/2510.26068", "title": "通过度量优化构建自适应流形模型的几何学习框架", "title_en": "Learning Geometry: A Framework for Building Adaptive Manifold Models through Metric Optimization", "authors": "Di Zhang", "background": "传统的机器学习方法主要是通过优化参数来寻找最优模型，但这些方法局限于固定的几何空间，优化过程相对静态。本文提出了一种新的机器学习范式，突破了这种传统方式，通过优化度量张量场来动态塑造模型的空间结构，从而提高模型的灵活性和适应性。这种方法将模型本身视为可以塑形的几何实体，并通过最优度量张量场来调整流形的几何结构，以平衡模型的数据拟合度和内在几何复杂性，防止模型过拟合。为了实现这一点，该文引入了一种基于离散微分几何的方法，将连续流形离散化为三角网格，并将度量张量参数化为边长，以实现高效的优化。", "innovation": "本文提出了一种通过优化度量张量构建自适应流形模型的新范式，不同于传统方法仅在固定空间中优化参数，它是将模型本身视为可以塑形的几何实体，动态调整模型空间的几何结构。该方法引入的基于离散微分几何的构造方法，以及与广义相对论中的爱因斯坦-希尔伯特作用的类比，为“数据驱动几何”提供了物理解释。此外，研究还揭示度量优化在固定拓扑情况下，相比固定几何的模型具有更大的表达能力，并为自适应构造“元学习器”提供了理论基础。", "conclusion": "本文为构建能够自主演化几何和拓扑结构的自适应‘元学习器’奠定了坚实基础，并指出其在科学建模发现和鲁棒表示学习等方面的应用前景。"}
{"llm_update_time": "20251101", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.26105", "html_url": "https://arxiv.org/abs/2510.26105", "title": "多模态模型中文本与图像间错位的安全风险", "title_en": "Security Risk of Misalignment between Text and Image in Multi-modal Model", "authors": "Xiaosen Wang,Zhijin Ge,Shaokang Wang", "background": "尽管多模态扩散模型，如文本到图像模型等方面取得了显著的进步和灵活性，但它们对对抗性输入的脆弱性仍然没有得到充分的探索。我们的研究发现，现有的扩散模型中，文本和图像模态之间的对齐是不充分的，这种不匹配在生成不适当或不适合工作环境（Not-Safe-For-Work, NSFW）的内容时带来了显著的风险。", "innovation": "本文提出了一种名为Prompt-Restricted Multi-modal Attack（PReMA）的新颖攻击方法。PReMA 通过修改输入图像来操控生成内容，而无需改变任何提示，是首次仅通过创建对抗图像来操纵模型输出的攻击方法，不同于以往主要通过生成对抗提示的方式产生NSFW内容的方法。PReMA 对具有固定提示的图像编辑应用中的多模态扩散模型构成了新的威胁，已在多个模型的图像修复和风格迁移任务中得到了全面的验证，表明PReMA的有效性非常显著。", "conclusion": "研究结果证实，PReMA 对基于多模态扩散模型的应用构成了新威胁，特别是在图像编辑应用中，其中提示是固定的。此工作提醒开发者和用户特别注意防止文本与图像模态间的不匹配，并显著揭示了对抗攻击在对抗多模态扩散模型中的潜在影响。"}
{"llm_update_time": "20251101", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.26130", "html_url": "https://arxiv.org/abs/2510.26130", "title": "超越合成基准：评估LLM在实际类级代码生成中的表现", "title_en": "Beyond Synthetic Benchmarks: Evaluating LLM Performance on Real-World Class-Level Code Generation", "authors": "Musfiqur Rahman,SayedHassan Khatoonabadi,Emad Shihab", "background": "大型语言模型（LLMs）已经提高了函数级别的代码生成能力，但它们在真实的软件项目中生成正确类级实现的能力仍不明确。这项工作通过来源于开源仓库的新颖基准测试，将实际类分为已见和未知部分，以评估其在实际条件下的泛化能力。评估涵盖了多种LLMs，包括在不同输入规范、检索增强配置及文档完整性水平下的表现。", "innovation": "提出了一个新的基准测试，来源于开源仓库，将实际类分为已见和未知部分；评估了LLMs在实际条件下的性能，包括在不同输入规范、检索增强配置及文档完整性水平下的表现；揭示了LLMs在合成基准与实际任务之间的显著性能差异，指出文档详尽性等几方面的影响；通过错误剖析确定了主要的失败模式。", "conclusion": "当前LLMs在类级工程方面存在关键局限，展示了通过增强上下文建模、文档策略及检索集成等措施提升生产代码辅助工具的关键见解。"}
{"llm_update_time": "20251101", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.26113", "html_url": "https://arxiv.org/abs/2510.26113", "title": "EgoExo-Con：探索视角不变的视频时间理解", "title_en": "EgoExo-Con: Exploring View-Invariant Video Temporal Understanding", "authors": "Minjoon Jung,Junbin Xiao,Junghyun Kim,Byoung-Tak Zhang,Angela Yao", "background": "该论文探讨了视频LLMs（Large Language Models）在捕捉同一事件从不同视角记录的视频时能否实现一致的时间理解。为此，引入了EgoExo-Con（一致性）基准，这是一个全面同步的第一人称和第三人称视频配对集合，并通过自然语言的人工精炼查询进行评估。该基准侧重于两个时间理解任务：时间验证和时间定位，不仅评估准确性，还评估不同视角之间的连贯性。", "innovation": "研究指出了现有视频LLMs的两个关键限制：（1）模型往往难以保持一致性，结果远不及单视角的表现；（2）当仅基于同步的双向视角视频进行微调时，模型虽然能够提高一致性，但在某些情况下可能不如仅在单视角上进行训练的模型表现。为此，研究人员提出了View-GRPO（视角-GRPO），这是一种新颖的强化学习框架，有效增强了特定视角的时间推理能力，同时促进了不同视角之间的连贯理解。该方法在处理跨视角一致性方面优于简单的微调和GRPO方法。", "conclusion": "该研究提出了EgoExo-Con基准，并通过引入View-GRPO框架解决了现有视频LLMs在跨视角一致性方面的局限性。所有资源都将公开提供。"}
{"llm_update_time": "20251101", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.26157", "html_url": "https://arxiv.org/abs/2510.26157", "title": "通过子结构感知对齐方式弥合分子与文本描述之间的鸿沟", "title_en": "Bridging the Gap Between Molecule and Textual Descriptions via Substructure-aware Alignment", "authors": "Hyuntae Park,Yeachan Kim,SangKeun Lee", "background": "分子和文本表示学习因能够增强对化学信息的理解而引起了越来越多的关注。然而，现有的模型在捕捉分子及其描述之间的微妙差异方面仍存在困难，因为它们缺乏学习分子亚结构与化学短语之间的细微对齐的能力。", "innovation": "提出了MolBridge，这是一种基于亚结构感知对齐方式的创新分子-文本学习框架。MolBridge通过将原始分子-描述对扩展为从分子亚结构和化学短语衍生出的额外对齐信号来解决这一局限。MolBridge通过亚结构感知对比学习和自我校准机制来有效地学习这些丰富化的对齐信号，从而捕捉到细微的对应关系，并在各种分子基准测试中优于最先进的基线模型，强调亚结构感知对齐在分子-文本学习中的重要性。", "conclusion": "实验结果表明，MolBridge不仅能有效捕捉细微的对应关系，还能在多种分子基准测试中优于最先进的基线模型，突出了亚结构感知对齐在分子-文本学习中的重要性。"}
{"llm_update_time": "20251101", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.26125", "html_url": "https://arxiv.org/abs/2510.26125", "title": "WOD-E2E：Waymo 开放数据集，用于应对具有挑战性的长尾场景的端到端自动驾驶驾驶", "title_en": "WOD-E2E: Waymo Open Dataset for End-to-End Driving in Challenging Long-tail Scenarios", "authors": "Runsheng Xu,Hubert Lin,Wonseok Jeon,Hao Feng,Yuliang Zou,Liting Sun,John Gorman,Kate Tolstaya,Sarah Tang,Brandyn White,Ben Sapp,Mingxing Tan,Jyh-Jing Hwang,Drago Anguelov", "background": "基于视觉的端到端（E2E）驾驶由于其可扩展性和与多模态大型语言模型（MLLMs）的协同作用，在研究领域引起了广泛关注。然而，当前的E2E驾驶基准主要侧重于标准场景，未能充分测试这些系统的真正潜力。现有的开环评估指标通常无法充分捕捉驾驶的多模态性质，或在长尾场景中有效评估性能。", "innovation": "为了解决上述问题，我们提出了Waymo 开放数据集用于应对具有挑战性的长尾场景的端到端驾驶 (WOD-E2E)。WOD-E2E 包含了4021个驾驶段（约12小时），这些场景在日常生活中较为罕见，发生的频率低于0.03%。每个段落包括高级路径信息、自身状态以及8个周围摄像头的360度摄像头视图。为了评估这些长尾情况下的E2E驾驶性能，我们提出了一种新的开环评估指标：评分反馈分数（RFS）。RFS评估预测轨迹与评判注释轨迹偏好的匹配程度，而不仅仅是预测航点与日志的距离。", "conclusion": "通过对WOD-E2E的数据集和评估方法的研究，我们旨在促进研发出普遍适用、稳健且安全的端到端自主驾驶代理，使其能够处理复杂的实际环境情况。"}
{"llm_update_time": "20251101", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.26089", "html_url": "https://arxiv.org/abs/2510.26089", "title": "网络约束的多代理车辆路径优化策略", "title_en": "Network-Constrained Policy Optimization for Adaptive Multi-agent Vehicle Routing", "authors": "Fazel Arasteh,Arian Haghparast,Manos Papagelis", "background": "城市道路网络中的交通拥堵导致行程时间增加和排放量上升，特别是在高峰时段。传统的最短路径优先（SPF）算法适用于静态网络中的单个车辆路径规划，但在动态多车辆环境中表现不佳，常常加剧拥堵。因此，需要一种新的方法来应对动态车辆路由问题，特此提出了多代理强化学习（MARL）框架，以实现网络感知的车队协同导航。该方法通过将网络划分为关键交叉口（枢纽），并利用Graph Attention Networks（GAT）来捕捉交通状态和邻域状态，从而进一步增强算法的表现力和可扩展性。实验结果表明，与SPF算法和学习基准模型相比，该方法能够显著减少行程时间并保持100%的路径规划成功率；同时在拥堵环境下，网络规模庞大的情况下也表现出良好的扩展能力，路由效率提升显著。该研究为智能交通系统中的可扩展、协调和拥堵感知路由提供了新的解决方案和潜力。", "innovation": "提出了一种分层基于枢纽的自适应导航（HHAN）方法，该方法通过将网络中的交叉口划分为关键枢纽，并利用集中式训练与去中心化执行相结合的架构（CTDE），并通过注意力机制聚合异步车辆决策，从而增强了路由的可行性和网络规模的处理能力。HHAN使用融合本地拥堵和预测动态性的流感知状态特征，实现先发制人地进行路径优化，显著提高了路由效率和成功率。特别是在重交通条件下，HHAN的表现尤为突出，比SPF算法提高了高达15.9%的路由效率。", "conclusion": "网络约束的多代理车辆路径优化策略，特别是HHAN方法，能够解决动态多车辆环境下的路由问题，并在保持高路径规划成功率的同时，显著提高路由效率，其在网络规模扩展性方面也表现出优异的性能。通过该研究，未来的智能交通系统将有能力实现更有效的车辆流动管理，减轻交通拥堵，降低排放。"}
{"llm_update_time": "20251101", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.26151", "html_url": "https://arxiv.org/abs/2510.26151", "title": "MV-MLM: 跨视图乳腺X线影像与语言模型融合用于乳腺癌诊断和风险预测", "title_en": "MV-MLM: Bridging Multi-View Mammography and Language for Breast Cancer Diagnosis and Risk Prediction", "authors": "Shunjie-Fabian Zheng,Hyeonjun Lee,Thijs Kooi,Ali Diba", "background": "大规模注释数据集对于训练用于乳腺癌检测或风险预测的计算机辅助诊断(CAD)模型至关重要，但获取精细注释的数据集成本高且耗时。具有跨模态自监督能力的视觉-语言模型(Vision-Language Models, VLMs)，例如CLIP，在大尺寸图像-文本对预训练的基础上，为医学影像任务中增强健壮性和数据效率提供了可能。", "innovation": "本文提出了一种名为MV-MLM的新颖多视角乳腺X线影像与语言模型，它通过跨模态自监督机制，利用图像-文本对之间的多种视角和相应的伪放射报告来学习丰富的表示。作者提出了一种新的联合视觉-文本学习策略，能够提高在不同数据类型和任务中的泛化和准确性，区分乳腺组织或癌症特征（钙化、肿块），并利用这些模式理解和解释乳腺X线影像以预测癌症风险。", "conclusion": "作者在私人和公开的数据集上评估了该方法，结果表明提出的模型在三种分类任务（1）恶性程度分类，(2) 亚型分类，(3) 图像基础的癌症风险预测）上达到了最先进的性能。此外，该模型展示了强大的数据效率，即使在仅使用合成文本报告训练且无需实际放射报告的情况下，其性能也优于现有完全监督或VLM基线。"}
{"llm_update_time": "20251101", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.26159", "html_url": "https://arxiv.org/abs/2510.26159", "title": "复杂度超越分段：工业时间序列异常检测中集成与混合方法的评估", "title_en": "Segmentation over Complexity: Evaluating Ensemble and Hybrid Approaches for Anomaly Detection in Industrial Time Series", "authors": "Emilio Mastriani,Alessandro Costa,Federico Incardona,Kevin Munari,Sebastiano Spinello", "background": "本研究探讨了先进特征工程和混合模型架构在多变量工业时间序列（以蒸汽涡轮系统为例）中的异常检测效果，重点关注变化点衍生的统计特征、基于聚类的子结构表示以及混合学习策略对检测性能的影响。", "innovation": "尽管复杂的方法在理论上具有吸引力，但在实际应用中，简单的随机森林 + XGBoost集成模型在分段数据上训练的表现优于这些复杂的方法。集成模型在AUC-ROC、F1分数和早期检测率方面表现优异。", "conclusion": "研究发现，在高不平衡且时间上不确定的数据情况下，简单的模型结合优化的分段可以超越更复杂的架构，提供更高的鲁棒性、可解释性和操作实用性。"}
{"llm_update_time": "20251101", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.26165", "html_url": "https://arxiv.org/abs/2510.26165", "title": "超越简单效用函数的资产管理学习", "title_en": "Learning to Manage Investment Portfolios beyond Simple Utility Functions", "authors": "Maarten P. Scholl,Mahmoud Mahfouz,Anisoara Calinescu,J. Doyne Farmer", "background": "尽管投资基金在公共场合披露其目标，但基金经理会优化复杂组合的目标，这些目标超越了简单的风险与回报权衡。传统的多目标效用函数建模方式尽管尝试过描述这一过程，但在规范和参数设置上仍然面临根本性的挑战。因此，需要一种新的方法来理解和建模这种复杂性。", "innovation": "本文提出了一种生成性框架，无需明确指定效用函数即可学习基金经理策略的潜在表示。该框架直接建模了给定股票特征、历史收益、先前权重和代表基金策略的潜在变量的基金组合权重的条件概率。这种方法不受强化学习或模仿学习方法的限制，这些方法需要指定奖励或专家目标的标签。本文的方法利用金融和市场数据的联合分布进行学习。通过对1436只美国股票共同基金的数据集进行验证，证明了所提出框架的有效性，揭示了管理者的隐含目标。", "conclusion": "本文提出的框架提供了一种基于数据的方法，用于描述投资策略的应用，如市场模拟、策略属性分析和监管监督。通过一系列测试，证明了模型编码可以以线性可解释的方式包含基准专家标记。"}
{"llm_update_time": "20251101", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.26185", "html_url": "https://arxiv.org/abs/2510.26185", "title": "积攒式SGD影响估计用于数据归属", "title_en": "Accumulative SGD Influence Estimation for Data Attribution", "authors": "Yunxiao Shi,Shuo Yang,Yixin Su,Rui Zhang,Min Xu", "background": "现代数据驱动的AI需要精确的单样本影响估计。标准的SGD-IE通过计算每个epoch的代理来近似leave-one-out效应，但忽略了epoch间的影响累积，这会导致关键样本被错误排序。", "innovation": "提出了ACC-SGD-IE，一种轨迹感知的估计器，能够在训练过程中传播leave-one-out扰动，并在每一步更新累积影响状态。在光滑强凸设置下，它实现了几何误差收缩；在光滑非凸区域内，它紧化了误差边界。较大的小批量处理会进一步降低常数。", "conclusion": "在Adult、20 Newsgroups和MNIST数据集上，使用ACC-SGD-IE方法得到的影响力估计更准确，尤其是在长时间训练时。此外，ACC-SGD-IE在清理数据和下游数据过滤方面更具可靠性，使用ACC-SGD-IE清理数据训练的模型表现超过了使用SGD-IE清理的数据训练的模型。"}
{"llm_update_time": "20251101", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.26172", "html_url": "https://arxiv.org/abs/2510.26172", "title": "通过协调智能体流来链接异质数据进行社交媒体分析", "title_en": "Linking Heterogeneous Data with Coordinated Agent Flows for Social Media Analysis", "authors": "Shifu Chen,Dazhen Deng,Zhihong Xu,Sijia Xu,Tai-Quan Peng,Yingcai Wu", "background": "社交媒体平台产生了大量异质数据，涵盖了用户行为、文本内容、时间和网络结构。分析这些数据对于理解意见动态、社群形成和信息传播等现象至关重要。然而，从复杂的数据环境中发现见解需要在社交媒体挖掘和可视化方面的专业知识。尽管现有的自动化方法越来越多地利用大型语言模型，但它们仍主要局限于结构化的表格数据，不能充分应对社交媒体分析的异质性挑战。", "innovation": "本文提出了一种名为SIA（Social Insight Agents）的LLM智能代理系统，它通过协调智能体流连接异质多模态数据，包括原始输入（如文本、网络和行为数据）、中间输出、挖掘的分析结果和可视化制品。SIA通过基于自底向上的分类税将见解类型与相应的挖掘和可视化技术联系起来，使智能体能够规划和执行连贯的分析策略。它还整合数据协调器，将表格、文本和网络数据统一成一个一致的流程。该系统提供交互式界面，使用户能够追踪、验证和细化智能体的推理过程，支持适应性和可信赖性。", "conclusion": "通过专家中心案例研究和定量评估，我们证明SIA能够有效地从社交媒体中发现多样且有意义的见解，并支持人类与智能体在复杂分析任务中的协作。"}
{"llm_update_time": "20251101", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.26188", "html_url": "https://arxiv.org/abs/2510.26188", "title": "基于住院病人医疗索赔数据预测所有原因再入院", "title_en": "Predicting All-Cause Hospital Readmissions from Medical Claims Data of Hospitalised Patients", "authors": "Avinash Kadimisetty,Arun Rajagopalan,Vijendra SK", "background": "降低可预防的医院再入院率是支付方、医疗服务提供者和政策制定者提高医疗保健质量和降低成本的国家优先事项。再入院率被用作衡量医院提供医疗服务质量的标准。本项目使用机器学习技术，如逻辑回归、随机森林和支持向量机，分析健康索赔数据，以识别预测所有原因再入院的重要人口统计学和医学因素。由于健康索赔数据量庞大，我们使用主成分分析作为降维技术，用于构建回归模型。", "innovation": "使用机器学习模型（逻辑回归、随机森林和支持向量机）来预测再入院，使用主成分分析进行降维，以此来构建回归模型并比较不同模型的性能。", "conclusion": "随机森林模型表现最好，其次是逻辑回归和支持向量机模型。这些模型可用于识别导致再入院的关键因素，帮助识别需要重点关注的患者，从而降低再入院率，减少成本并提高患者医疗服务的质量。"}
{"llm_update_time": "20251101", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.26186", "html_url": "https://arxiv.org/abs/2510.26186", "title": "概念边界：通过解耦视觉概念进行数据集偏见表征", "title_en": "ConceptScope: Characterizing Dataset Bias via Disentangled Visual Concepts", "authors": "Jinho Choi,Hyesu Lim,Steffen Schneider,Jaegul Choo", "background": "在机器学习数据集中普遍存在的数据偏差现象，即数据点向特定概念偏斜，目前在没有精细属性注释的情况下，系统地识别这些偏差具有挑战性。本文探讨了如何利用视觉基础模型的表示训练稀疏自编码器，自动发现和量化可解释的人类概念，以解决这个问题。", "innovation": "本文提出了ConceptScope，这是一种针对视觉数据集分析的可扩展且自动化的框架，使用稀疏自编码器从视觉基础模型中训练出的表示来识别和量化概念。该框架根据概念的语义相关性和与类标签的统计相关性将概念分类为目标类型、上下文类型和偏差类型，从而能够通过基于概念的子组进行分类级数据集表征、偏差识别和鲁棒性评估。", "conclusion": "通过与注释数据集的比较，验证了ConceptScope能够捕捉到广泛的视觉概念，包括物体、纹理、背景、面部属性、情绪和动作。此外，展示了概念激活产生与语义有意义的图像区域对齐的空间属性。ConceptScope能够可靠地检测已知偏差（例如，水鸟数据集中的背景偏差），并揭示未注释的偏差（例如，ImageNet中的协同对象），提供了一种实用的工具来进行数据集审核和模型诊断。"}
{"llm_update_time": "20251101", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.26200", "html_url": "https://arxiv.org/abs/2510.26200", "title": "Don't Let It Fade: Preserving Edits in Diffusion Language Models via Token Timestep Allocation", "title_en": "Don't Let It Fade: Preserving Edits in Diffusion Language Models via Token Timestep Allocation", "authors": "Woojin Kim,Jaeyoung Do", "background": "尽管扩散语言模型（DLMs）能够实现精细化的调整，但其实际可控性仍然脆弱。研究发现，一种普遍存在的失败模式被称为更新遗忘现象，这种现象会导致上下文无关的均匀更新在时间步长上引起字元级波动，从而抹去先前的信息编辑，破坏累积细化过程，进而降低流畅性和连贯性。", "innovation": "本文提出了Token Timestep Allocation（TTA）机制，通过为每个字元设置时间步长调度实现软化和语义化的字元顺序。关键字元在早期冻结，不确定的字元则继续细化。TTA可以作为固定政策或由任务信号驱动的自适应政策实现，支持广泛细化策略。TTA能够在推理时间直接作用，适用于各类扩散语言模型，并且能够自然扩展到多种监督源。", "conclusion": "实验结果表明，TTA提升了可控性和流畅性：在情绪控制实验中，使用不到五分之一的步骤，准确率提高了超过20%，并且困惑度几乎减少了一半。在去毒化实验中，最大毒性降低了12.2%（对比14.5%），困惑度降低了26.0%（对比32.0%）。这些结果表明，通过时间步长分配实现的柔软排序是缓解更新遗忘、实现稳定可控扩散文本生成的关键杠杆。"}
{"llm_update_time": "20251101", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.26205", "html_url": "https://arxiv.org/abs/2510.26205", "title": "面向语境级推理的全局检索增强生成：一种基准测试", "title_en": "Towards Global Retrieval Augmented Generation: A Benchmark for Corpus-Level Reasoning", "authors": "Qi Luo,Xiaonan Li,Tingshuo Fan,Xinchi Chen,Xipeng Qiu", "background": "当前RAG评估基准主要关注我们所称的局部RAG：从少量文档中检索相关片段以回答仅需特定文本部分局部理解的问题查询。然而，许多实际应用需要一种根本不同的能力——全局RAG，它涉及整合和分析整个文档集合的信息来得出语料库级别的洞察（例如，“2023年最受推崇的10篇论文是什么？”）。", "innovation": "本文提出了GlobalQA——首款专门用于评估全局RAG能力的基准测试，涵盖了四种核心任务类型：计数、极值查询、排序和前K项提取。通过系统性评估不同的模型和基线，我们发现现有RAG方法在全局任务上的表现欠佳，最强的基线方法仅达到1.51 F1分数。为此，我们提出了一种名为GlobalRAG的多工具协作框架，通过片段级检索保持结构上的连贯性，结合LLM驱动的智能过滤器移除噪音文档，并集成聚合模块进行精确的符号计算。在Qwen2.5-14B模型上，GlobalRAG相比最强基线实现了显著提升，达到6.63 F1，验证了我们方法的有效性。", "conclusion": "通过系统测试不同模型和基线，发现现有RAG方法在全局任务上表现不佳，并提出了GlobalRAG框架，显著提升了模型在全局RAG任务上的效果。"}
{"llm_update_time": "20251101", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.26219", "html_url": "https://arxiv.org/abs/2510.26219", "title": "在前缀输出空间中基于采样最优控制的大型语言模型模型测试时对齐", "title_en": "Test-Time Alignment of LLMs via Sampling-Based Optimal Control in pre-logit space", "authors": "Sekitoshi Kanai,Tsukasa Yoshida,Hiroshi Takahashi,Haru Kuroki,Kazumune Hashimoto", "background": "由于微调大型语言模型（LLMs）需要高计算成本，测试时对齐LLMs吸引了研究者的关注。", "innovation": "本文提出了一种新的测试时对齐方法——预输出自适应重要性采样（AISP），该方法在基于基于采样模型预测控制的基础上，使用随机控制输入。AISP通过在预输出（预逻辑层的输出）上添加高斯扰动，并最大化扰动的均值期望奖励，实现了最优的均值计算，相较于最佳n采样在使用样本数和奖励方面表现更优，同时实现了比其他基于奖励的测试时对齐方法更高的奖励。", "conclusion": "本文提出的方法AISP在测试时对齐LLMs方面取得了良好的效果，通过重要性采样与采样奖励相结合，优化了模型的性能。"}
{"llm_update_time": "20251101", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.26202", "html_url": "https://arxiv.org/abs/2510.26202", "title": "在我的人工反馈中有什么？学习可解释的偏好数据描述", "title_en": "What's In My Human Feedback? Learning Interpretable Descriptions of Preference Data", "authors": "Rajiv Movva,Smitha Milli,Sewon Min,Emma Pierson", "background": "人工反馈可以以难以预测且可能不理想的方式改变语言模型，因为实践者对反馈数据所编码的内容缺乏清晰的理解。尽管有之前的工作研究了某些属性的偏好（例如长度或 xuǎnyán），但在无需预先假设的前提下自动提取相关特征仍然具有挑战性。", "innovation": "本文引入了名为WIMHF的方法（What's In My Human Feedback?），该方法使用稀疏自编码器来解释反馈数据。WIMHF能够表征数据集能够测量的偏好以及标注人员实际表达的偏好。通过对7个数据集的测试，WIMHF能够识别出一小部分可解释的关键特征，这些特征解释了黑盒模型中很大一部分的偏好预测信号。这种方法还揭示了一些潜在不安全的偏好，例如LMArena用户倾向于反对拒绝，经常有利于有毒内容。学习到的特征既能够有效管理数据，也能够实现精细的个性化设置：在改进数据集上的危害示例重新标记提高了安全性（+37%），同时不影响通用表现，还能够通过学习注释员对主观特征的特定权重来改进偏好预测，提高准确性。", "conclusion": "WIMHF提供了一种以人为中心的分析方法，使实践者能够更好地理解和利用偏好数据。"}
{"llm_update_time": "20251101", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.26217", "html_url": "https://arxiv.org/abs/2510.26217", "title": "混合LLM和高阶量子近似优化方法在CSA抵押管理中的应用", "title_en": "Hybrid LLM and Higher-Order Quantum Approximate Optimization for CSA Collateral Management", "authors": "Tao Jin,Stuart Florescu,Heyu(Andrew)Jin", "background": "本文探讨的是金融市场中的抵押优化问题，尤其是遵循ISDA信用支持附加协议（CSAs）的场景。该协议中包含了整量（integer lots）、Schedule A 折扣（haircuts）、RA/MTA限制（gating）、发行人/货币/类别限额（caps）等条款，使得优化问题变得复杂且受限于法律条款。因此，传统的优化方法往往不足以应对这些难题。", "innovation": "本文提出了一种专门为此类问题设计的认证混合管道：（i）一种证据门控的LLM，用于从CSA条款中提取信息并规范化为JSON格式（默认拒绝，引用具体化）；（ii）一种灵感来源于量子计算的探索者，该探索者交替使用模拟退火和微超高阶量子近似优化（HO-QAOA）方法处理绑定子QUBOs（子集大小n≤16，顺序k≤4），以协调跨越限额和RA引起的离散性的多资产移动；（iii）一种带加权的风险意识目标函数（包括运动、CVaR、定价资金超额风险），并且明确指定了一个覆盖窗口U≤Reff+B；（iv）CP-SAT作为仲裁者确定可行性和间隙，包括对U限额预检查来报告最小可行缓冲B*。将限额/四舍五入作为高阶项处理使HO-QAOA能够针对击败局部交换的领域耦合进行优化。在政府债券数据集和多CSA输入上，混合方法相比于强大的经典基线提高了9.1%、9.6%和10.7%，在治理设置下提供更好的成本-运动-尾部前沿性能。同时，作者开放了治理级别的工具以增加结果的可审计性和可重复性。", "conclusion": "通过结合不同优化技术，作者成功地开发了一种混合方法来解决复杂的CSA抵押管理优化问题，并通过实验证明了其有效性和优越性。此外，通过开放所有相关工具和数据，作者旨在促进该领域的进一步研究和发展。"}
{"llm_update_time": "20251101", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.26230", "html_url": "https://arxiv.org/abs/2510.26230", "title": "MPRU: 将模块化投影-再分配消bai学作为分类管道的输出过滤器", "title_en": "MPRU: Modular Projection-Redistribution Unlearning as Output Filter for Classification Pipelines", "authors": "Minyi Peng,Darian Gunamardi,Ivan Tjuawinata,Kwok-Yan Lam", "background": "现有的机器消学（MU）方法通常侧重于理论建模或优化目标来实现知识去除，但在实际应用场景中，这些解决方案往往面临可扩展性问题，需要完全访问原始数据集和模型才能实现消学。", "innovation": "本文提出了一种新的消学方法，称为归纳方法，通过将分类训练视为逐步学习的过程，并通过反向最后一个训练序列来实现消学，这种方法不需要完全访问原始数据集或模型。不同于现有方法，该方法通过在模型末尾添加一个投影-再分配层实现，使得消学过程更加模块化和模型无关，可以在现有分类管道中作为输出过滤器部署，只需进行最小的修改。", "conclusion": "实验结果显示，该方法在多个数据集上表现出与完全重新训练的模型相似的输出结果，同时大幅度减少了计算成本，证明其在实际应用场景中的适用性、可扩展性和系统兼容性。"}
{"llm_update_time": "20251101", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.26278", "html_url": "https://arxiv.org/abs/2510.26278", "title": "分布目标的黑盒多目标优化在扩散模型推理时间多目标生成中的应用", "title_en": "Distributional Multi-objective Black-box Optimization for Diffusion-model Inference-time Multi-Target Generation", "authors": "Kim Yong Tan,Yueming Lyu,Ivor Tsang,Yew-Soon Ong", "background": "扩散模型已经在学习复杂数据分布方面取得了成功，并被应用于高维多目标黑盒优化问题。现有的方法通常会借助外部优化循环（如进化算法）对扩散模型进行训练和优化，但它们将扩散模型视为黑盒精炼器，忽视了扩散生成过程内部的分布转换，这限制了它们的效率。因此，作者提出了一种在推理时间优化扩散过程的算法，即Inference-time Multi-target Generation (IMG)算法，以生成同时满足多个目标的样本。", "innovation": "提出了Inference-time Multi-target Generation (IMG)算法，该算法在推理时间优化了扩散过程，根据预期的多目标值执行加权重采样。这种方法确保生成的样本遵从我们期望的多目标Boltzmann分布。此外，作者指出多目标Boltzmann分布具有有趣的对数似然解释，它是分布目标多目标优化问题的最佳解。实验结果显示，IMG算法只需单次生成即可达到比基线优化算法更高的hypervolume值，后者通常需要数百次扩散生成。该算法可视作优化的扩散过程，并可与现有方法结合使用以进一步提高性能。", "conclusion": "实验表明，与需要数百次扩散生成的基线优化算法相比，IMG算法仅需单次生成就能够显著提高hypervolume值。此外，该算法能够优化扩散过程，并可以集成到现有方法中以进一步提升性能。这种分布目标的黑盒多目标优化方法为扩散模型在复杂优化任务中的应用提供了新的视角。"}
{"llm_update_time": "20251101", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.26275", "html_url": "https://arxiv.org/abs/2510.26275", "title": "为软件工程流程和软件产品增强生成人工智能的研究路线图", "title_en": "A Research Roadmap for Augmenting Software Engineering Processes and Software Products with Generative AI", "authors": "Domenico Amalfitano,Andreas Metzger,Marco Autili,Tommaso Fulcini,Tobias Hey,Jan Keim,Patrizio Pelliccione,Vincenzo Scotti,Anne Koziolek,Raffaela Mirandola,Andreas Vogelsang", "background": "生成人工智能（GenAI）正在迅速改变软件工程（SE）实践，影响SE流程的执行方式以及软件系统的开发、运营和演化。基于此背景，本文采用设计科学研究方法，构建了一条GenAI增强SE的路线图。该过程包括三个逐步集成多种证据的循环，证据来源包括FSE 2025“软件工程2030”研讨会的协作讨论、快速文献综述以及同行的外部反馈会议。利用McLuhan的四象限作为概念工具，系统地捕捉GenAI对SE流程和软件的影响。这些发现被汇总为未来研究的方向。通过在严格的多循环过程中构建路线图并由不同研究小组和同行进行交叉验证，研究为分析GenAI对SE流程、方法和工具的影响提供了一个透明的和可重复的基础，并为这一快速发展的领域内未来的研究指明了方向。基于这些发现，文章最终对未来30年的SE提出了10项预测。", "innovation": "本文采用设计科学研究方法，构建了一条关于GenAI增强SE的路线图，包含三个逐步集成多种证据的循环，特别是在使用McLuhan的四象限作为概念工具系统捕捉GenAI对SE的影响方面有创新。此外，通过多循环过程和独立复审团队的交叉验证，为分析GenAI对SE的影响提供了透明和可重复的基础，并提出了一系列未来研究方向。文章还对未来30年的SE进行了预测，推动该领域的进一步研究。", "conclusion": "本文提供了关于GenAI影响SE流程、方法和工具的透明和可重复的基础，并提出了十个关于2030年SE的预测，为未来的研究指明了方向。"}
{"llm_update_time": "20251101", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.26298", "html_url": "https://arxiv.org/abs/2510.26298", "title": "ChatGPT Atlas能否征服网页？探索ChatGPT Atlas智能体在网页游戏中的前沿", "title_en": "Can Agent Conquer Web? Exploring the Frontiers of ChatGPT Atlas Agent in Web Games", "authors": "Jingran Zhang,Ning Li,Justin Cui", "background": "OpenAI的ChatGPT Atlas作为一种新型的交互模型，已经展示出了其分析网页、理解用户意图以及直接在浏览器中执行鼠标和键盘输入的能力。尽管其在信息检索任务上的表现已经被验证，但在动态、互动性强的环境下的表现尚未被广泛探讨。", "innovation": "本研究首次使用基于浏览器的游戏来评估ChatGPT Atlas的网页交互能力，包括Google T-Rex Runner、数独、Flappy Bird等游戏，并使用游戏内得分作为量化评估指标，揭示了ChatGPT Atlas在逻辑推理任务中的强大表现，在数独游戏中能够显著快于人类基线；但在需要精确实时反应和肢体控制的游戏中则表现较弱，往往无法克服初步障碍。这些发现表明，尽管ChatGPT Atlas在分析处理方面表现出色，但在需要实时交互的动态网页环境中仍然存在明显限制。", "conclusion": "这项研究表明，ChatGPT Atlas表现出强大的分析处理能力，但在动态网页环境中需要实时交互的任务下依旧存在明显局限。建议未来研究继续探索和优化其针对动态网页的交互能力。"}
{"llm_update_time": "20251101", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.26285", "html_url": "https://arxiv.org/abs/2510.26285", "title": "探索语言模型处理数字的机制", "title_en": "Unravelling the Mechanisms of Manipulating Numbers in Language Models", "authors": "Michal Štefánik,Timothee Mickus,Marek Kadlčík,Bertram Højer,Michal Spiegel,Raúl Vázquez,Aman Sinha,Josef Kuchař,Philipp Mondorf", "background": "近期的研究表明，不同的大型语言模型（LLMs）对于数字的输入嵌入表示逐渐趋于相似且准确。然而，这些发现与大型语言模型在处理数字信息时易产生错误输出的趋势相矛盾。本文旨在解释这种矛盾，通过探索语言模型如何处理数字，并量化这些机制的准确度下限。研究表明，尽管会出现错误，不同的语言模型在隐藏层和不同输入场景下学习的是系统性、高度准确且通用的数字表示。这使得可以创建每个LLM的通用探针，并追踪输出错误的原因到特定的层。", "innovation": "本文通过探索语言模型如何处理数字，并发现尽管表面存在错误，这些模型在处理数字时的学习表示是系统性、高度准确且通用的。此外，研究提出了创建通用探针的方法，从而能够追踪输出错误的原因到特定层，这有助于更准确地理解预训练LLMs处理数字的方式，并为进一步改进LLMs架构提供了潜力。", "conclusion": "本文揭示了预训练语言模型在处理数字方面的机制，并提出了一种更准确的探针技术，可用于改进LLMs的架构。"}
{"llm_update_time": "20251101", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.26243", "html_url": "https://arxiv.org/abs/2510.26243", "title": "Angle Control：通过激活空间旋转进行行为控制", "title_en": "Angular Steering: Behavior Control via Rotation in Activation Space", "authors": "Hieu M. Vu,Tan M. Nguyen", "background": "在大型语言模型上控制特定行为并在保持其一般能力的同时进行安全可靠的AI部署是一大挑战。当前的调控方法如向量加法和方向删减仅仅在激活和特征方向定义的二维子空间内操作，这使得它们对选定参数敏感，并可能因为激活空间中的意外相互作用而影响无关特征。", "innovation": "引入了Angle Steering（Angle Steering），一种新型并灵活的调控方法，通过在固定二维子空间内旋转激活来进行行为调控。将调控定义为几何旋转向目标行为方向或远离目标方向，Angle Steering提供了对拒绝和遵从等行为的连续、细腻控制。此外，提出了Adaptive Angle Steering，一种选择性变体，仅旋转与目标特征对齐的激活，进一步增强了稳定性和连贯性。", "conclusion": "实验结果表明，Angle Steering能够在多种模型家族和规模中实现稳健的行为控制，同时维持其一般语言建模性能，凸显其灵活性、泛化能力和相较于前期方法的鲁棒性。相关代码和材料在上述链接处提供。"}
{"llm_update_time": "20251101", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.26303", "html_url": "https://arxiv.org/abs/2510.26303", "title": "Per-sample Adam on分离数据的隐含偏差: 脱离全批量范式", "title_en": "Implicit Bias of Per-sample Adam on Separable Data: Departure from the Full-batch Regime", "authors": "Beomhan Baek,Minhak Song,Chulhee Yun", "background": "Adam是最常用的深度学习优化器，尽管它在实践中非常成功，但在理论上仍然缺乏深入理解。以往研究发现Adam倾向于$\boldsymbol{\text{\nobreakcopy l}_{∞}}$几何的解，但这些结果仅适用于全批量训练的情况。", "innovation": "该研究首次分析了一次样本一个样本更新的增量Adam在逻辑回归线性可分数据集上的隐含偏见，发现了它与全批量Adam的行为存在偏差。通过构造结构化数据集，证明了增量Adam在这些数据集上证明会收敛到$\boldsymbol{\text{\nobreakcopy l}_{2}}$大间距分类器，而不是全批量Adam的$\boldsymbol{\text{\nobreakcopy l}_{∞}}$大间距偏倚。并提出了一个代理算法来描述增量Adam在$\beta_2 \to 1$时的行为，并对其收敛方向进行了数据依赖的对偶固定点公式化。最后证明与Adam不同，当$\beta$足够接近1时，Signum对于任何批量大小都会收敛到$\boldsymbol{\text{\nobreakcopy l}_{∞}}$大间距分类器。", "conclusion": "我们的结果强调了Adam的隐含偏见不仅取决于批量策略，还取决于数据集，而Signum对于批量大小具有一定不变性。"}
{"llm_update_time": "20251101", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.26302", "html_url": "https://arxiv.org/abs/2510.26302", "title": "从标记层面因果视角理解视觉语言compositionality的困难性", "title_en": "Understanding Hardness of Vision-Language Compositionality from A Token-level Causal Lens", "authors": "Ziliang Chen,Tianang Xiao,Jusheng Zhang,Yongsen Zheng,Xipeng Chen", "background": "CLIP通过在共享嵌入空间中对齐图像和文本来实现强大的跨模态泛化，但其在对象、属性和关系的组合推理方面表现不佳，表现类似于一个单词包匹配器。现有的因果解释通常将文本视为单一向量，无法解释诸如提示敏感性和面对较难负样本的失效等核心现象。", "innovation": "本文提出了一个标记感知的因果表示学习（CRL）框架，该框架基于序列的语言标记SCM。该理论扩展了块可识别性到标记化文本，证明了CLIP的对比目标可以在句子层次和标记层次的SCM中恢复模式不变的潜在变量。重要的是，标记粒度提供了CLIP组合脆弱性的第一个理论解释：组合不可识别。展示了伪最优的文字编码器，虽然实现了完美的模式不变对齐，但对原子概念的SWAP、REPLACE和ADD操作是不可感知的，导致其无法区分正确的标题和难负样本，尽管优化了相同的训练目标。此外，该分析还通过模态间隙将语言侧的不可识别性与视觉侧的失效联系起来，并说明迭代组合算子如何增加难度，从而推动改进的负样本挖掘策略.", "conclusion": "文章进一步将语言侧的不可识别性与视觉侧的失败联系起来，通过模态差距揭示了这两者之间的关系，并展示了迭代组合操作如何逐步增加难度，因此提出了改进负样本挖掘策略的需求。"}
{"llm_update_time": "20251101", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.26324", "html_url": "https://arxiv.org/abs/2510.26324", "title": "差分模型与退火拉根文动力学结合实现后验采样", "title_en": "Posterior Sampling by Combining Diffusion Models with Annealed Langevin Dynamics", "authors": "Zhiyang Xun,Shivam Gupta,Eric Price", "background": "给定一个带噪的线性测量 $y = Ax + \\xi$ 来自分布 $p(x)$，以及对先验 $p(x)$ 的良好近似，当能够从后验 $p(x \text{ | } y)$ 中进行采样吗？后验采样为诸如 inpainting、deblurring 和 MRI 重建等任务提供了精确且公平的框架，尽管有多项技术和启发法试图近似它，但近似后验采样在一般情况下是计算上不可行的。因此，本文关注局部或全局对数凸分布 $p(x)$，在这种情况下，当可以访问 $p(x)$ 的准确分数时，拉根文动力学生成了后验样本，但它对分数估计误差是脆弱的，需要 MGF 边界（次指数误差）。相较之下，在非条件设置中，扩散模型仅需对分数误差有 $L^2$ 边界就成功了。", "innovation": "本文提出的创新在于结合了扩散模型与退火拉根文动力学，证明了只要分数误差满足 $L^4$ 边界，便可以在多项式时间内实现条件采样。", "conclusion": "结合扩散模型与退火拉根文动力学能够仅通过 $L^4$ 边界上的分数误差实现条件采样，从而为后验采样提供了一种有效方法。"}
{"llm_update_time": "20251101", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.26336", "html_url": "https://arxiv.org/abs/2510.26336", "title": "从业余到大师：通过自动课程学习往LLMs中注入知识", "title_en": "From Amateur to Master: Infusing Knowledge into LLMs via Automated Curriculum Learning", "authors": "Nishit Neema,Srinjoy Mukherjee,Sapan Shah,Gokul Ramakrishnan,Ganesh Venkatesh", "background": "大型语言模型（LLMs）在通用任务上表现出色，但在经济学和心理学等需要深入、原理性理解的专业领域则表现不佳。本研究旨在通过引入ACER（Automated Curriculum-Enhanced Regimen）来解决这一问题，该方法能够将通用型模型转化为领域专家，同时保留其广泛的领域覆盖能力。", "innovation": "ACER通过自动生成一个包含目录的教材式的课程表，并按照布卢姆分类法生成问题回答对，以确保系统性的话题覆盖和逐步增加的难度。合成的课程材料通过交错的课程计划进行持续预训练，从而对内容和认知维度的掌握进行对齐。实验结果显示，ACER在Llama 3.2（1B和3B）模型上的特定子集和经济学等挑战性领域中均表现出显著提升，整体改进率达到3个百分点。此外，ACER不仅防止了灾难性的遗忘，还促进了跨领域的知识转移，提升了非目标领域的性能。", "conclusion": "本研究结果表明，ACER为关闭LLMs在关键领域差距提供了一个可扩展且有效的公式。不仅如此，ACER在知识密集型基准测试（如ARC和GPQA）上的性能提升超过2个百分点，同时在通用推理任务上保持稳定。"}
{"llm_update_time": "20251101", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.26345", "html_url": "https://arxiv.org/abs/2510.26345", "title": "MisSynth: 使用合成数据提高MISSCI逻辑谬误分类", "title_en": "MisSynth: Improving MISSCI Logical Fallacies Classification with Synthetic Data", "authors": "Mykhailo Poliakov,Nadiya Shvai", "background": "健康相关的错误信息非常普遍且潜在有害。这些错误信息的识别难度很高，尤其是在论述扭曲或曲解科学发现时。现有方法难以有效识别这类信息。", "innovation": "该研究提出了一种MisSynth管道，使用检索增强生成（RAG）技术生成合成谬误样本，并通过这些数据微调大型语言模型（LLMs）。实验结果表明，微调后的模型在识别谬误方面比原始基线模型取得了显著的准确性提升。研究表明，在有限计算资源下，引入合成谬误数据可以显著增强LLMs在实际科学错误信息任务中的零样本分类性能。", "conclusion": "通过使用合成数据增强有限标注资源，可以显著提升大模型在实际科学谬误信息任务中的零样本分类性能，即使计算资源有限。相关代码和合成数据集已公开。"}
{"llm_update_time": "20251101", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.26352", "html_url": "https://arxiv.org/abs/2510.26352", "title": "对话的几何学：通过绘制语言模型揭示多智能体协作中的协同团队", "title_en": "The Geometry of Dialogue: Graphing Language Models to Reveal Synergistic Teams for Multi-Agent Collaboration", "authors": "Kotaro Furuya,Yuichi Kitagawa", "background": "基于大型语言模型（LLMs）的多智能体方法被认为是超越单一模型能力的一种有前途的策略，但其成功依赖于各模型间的协同效应，而模型自身的不透明性使团队组成的最佳实践成为一项重大挑战。", "innovation": "本文提出了一种以交互为中心的自动团队组成框架，无需任何先验知识即可识别出功能上协同的模型集群，通过构建‘语言模型图’映射对话中的语义一致性来发现模型之间的关系，并应用社区检测来识别出协同的模型集群。", "conclusion": "通过特定话题激发的对话能够发现功能上协同的团队，并在下游基准测试中超过随机基线，达到了与人工设计团队相当的准确度。这些发现为自动设计协作的多智能体LLM团队提供了新的基础。"}
{"llm_update_time": "20251101", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.26342", "html_url": "https://arxiv.org/abs/2510.26342", "title": "带有干涉约束的线性因果发现", "title_en": "Linear Causal Discovery with Interventional Constraints", "authors": "Zhigao Guo,Feng Dong", "background": "因果知识和机制对于改进因果模型并提升下游任务如设计新疗法至关重要。现有的因果发现方法允许施加结构性约束（例如，要求P以到K的因果路径），但仍旧可能导致错误的因果结论。例如，可能学到“PIP3抑制Akt”。", "innovation": "提出了干涉约束这一新的概念，它不同于需要直接干预变量的介入性数据。干涉约束以不等式形式编码高层次的因果知识，通过具体约束变量对之间的总因果效应，确保学习的模型符合已知的因果影响。通过提出量化线性因果模型的总因果效应的度量标准，并形成为约束优化任务，该方法通过两阶段的约束优化方法解决此问题。实验结果表明，集成干涉约束不仅提高了模型精度并确保与已建立发现的一致性，使模型更具有可解释性，还能促进发现新因果关系。", "conclusion": "该方法通过引入干涉约束方法，不仅提升了模型的准确性，确保与已知因果关系一致，促进了模型的可解释性，还通过优化模型发现新的因果关系，克服了传统因果发现方法的局限。"}
{"llm_update_time": "20251101", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.26339", "html_url": "https://arxiv.org/abs/2510.26339", "title": "GLYPH-SR：通过VLM导向的潜在扩散模型能否同时实现高质量图像超分辨率和高保真度的文字恢复？", "title_en": "GLYPH-SR: Can We Achieve Both High-Quality Image Super-Resolution and High-Fidelity Text Recovery via VLM-guided Latent Diffusion Model?", "authors": "Mingyu Sung,Seungjae Ham,Kangwoo Kim,Yeokyoung Yoon,Sangseok Yun,Il-Min Kim,Jae-Mo Kang", "background": "图像超分辨率（SR）在许多视觉系统中至关重要，包括监控、自主驾驶、文档分析和零售分析等。恢复高频细节，特别是场景文本，对于可靠的内容感知极为重要。场景文本通常包含最有行动价值的信息，但如果字符模糊或不存在，即使图像看起来清晰，光学字符识别（OCR）和后续决策也会失败。然而，之前的SR研究更多关注于失真指标（PSNR/SSIM）或学习感知度量（LIPIS, MANIQA, CLIP-IQA, MUSIQ），这些指标对字符级别的错误相对不敏感。此外，关于文字SR的研究往往集中在简化的基准测试中，忽略了复杂自然场景中的文字挑战。因此，场景文本通常被视为通用纹理处理。为使SR在实际部署中有效，必须明确优化文字可读性和感知质量。", "innovation": "GLYPH-SR提供了一种视线语言导向的扩散框架，旨在同时优化文字可读性和感知质量。它利用由OCR数据引导的文字-SR融合控制网络（TS-ControlNet），和一个乒乓调度器，交替使用文字和场景为中心的指导。通过在合成数据集上训练这些组件，同时冻结主要的SR分支，以实现有针对性的文字恢复。GLYPH-SR在SVT、SCUT-CTW1500和CUTE80基准测试中在x4和x8倍的放大下，OCR F1得分比扩散/生成对抗网络（GAN）基线提高了多达15.18个百分点，同时保持了竞争力的MANIQA、CLIP-IQA和MUSIQ得分。GLYPH-SR的目标是实现同时的高质量和高视觉现实感，确保生成的SR看起来正确和正确地呈现。", "conclusion": "GLYPH-SR通过视线语言引导的潜在扩散模型实现了高质量图像超分辨率和高保真度文字恢复，改进了OCR性能，同时保持了高质量的感知指标。"}
{"llm_update_time": "20251101", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.26347", "html_url": "https://arxiv.org/abs/2510.26347", "title": "随机、稀疏和非站定环境中使用自主水下车辆进行污染检测的强化学习方法", "title_en": "Reinforcement Learning for Pollution Detection in a Randomized, Sparse and Nonstationary Environment with an Autonomous Underwater Vehicle", "authors": "Sebastian Zieglmeier,Niklas Erdmann,Narada D. Warakagoda", "background": "强化学习（RL）算法旨在通过学习最大化奖励的动作来优化问题解决，但在随机和非站定环境中，这一任务变得尤为具有挑战性。即使是最先进的RL算法，在这些条件下往往也难以解决问题。例如，在使用自主水下车辆（AUVs）搜索水下污染云的任务中，RL算法需要导航稀疏的奖励环境，在这种环境中，很多动作往往得不到任何奖励。研究旨在通过重新审视并修改经典的RL方法，来有效应对这些挑战，以在稀疏、随机和非站定环境中高效运行。研究者通过系统地研究大量修改方案实现了这一目标，包括层次算法改变、多目标学习以及将位置记忆作为一个外部输出滤波器以防止状态重访。研究结果表明，改进的蒙特卡洛方法显著优于传统Q学习和两种详尽搜索模式，这显示了它在复杂环境下的适应潜力。这些发现表明，可以有效地将强化学习方法应用于随机、非站定和稀疏奖励环境中。", "innovation": "研究者通过重新审视并修改经典的RL方法，提出了改进的RL算法，特别是在稀疏、随机和非站定环境中表现出色。具体创新包括层次算法改变、多目标学习以及将位置记忆作为一个外部输出滤波器以防止状态重访。研究表明，此种改进策略改进的蒙特卡洛方法显著优于传统Q学习方法和详尽搜索模式。", "conclusion": "改进的蒙特卡洛方法在稀疏、随机和非站定环境中表现出色，为使用自主水下车辆进行污染检测提供了新的方法。这些方法能够有效地应对复杂且不稳定的环境挑战，并显示出在各种实际应用中的潜力。"}
{"llm_update_time": "20251101", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.26406", "html_url": "https://arxiv.org/abs/2510.26406", "title": "在线人工循环回路拒绝采样在机器人操作中的应用", "title_en": "Human-in-the-loop Online Rejection Sampling for Robotic Manipulation", "authors": "Guanxing Lu,Rui Zhao,Haitao Lin,He Zhang,Yansong Tang", "background": "强化学习（RL）广泛用于生成鲁棒的机器人操作策略，但由于中间步骤中价值估计不准确和稀疏的监督，用RL微调视-语-动（VLA）模型可能会变得不稳定。相比之下，模仿学习（IL）易于训练，但由于其离线的特性，IL常常表现出色不足。", "innovation": "本文提出了一种简单的高效后训练方法Hi-ORS，利用拒绝采样来实现训练稳定性和高鲁棒性。Hi-ORS通过在校内微调过程中过滤负面奖励样本来稳定价值估计，并采用奖励加权监督训练目标来提供密集的中间步骤监督。另外，开发了一种异步推理-培训框架，支持灵活的在线人工在环校正，这些校正为学习错误恢复行为提供了明确的指导。实验结果显示，在三个实际任务和两种载体上，Hi-ORS在仅1.5小时的实际培训中微调了一个pi-base策略，其效果和效率均明显优于RL和IL基准方法，并且细调的策略展示了强大的测试时可扩展性，通过执行复杂的错误恢复行为实现了更好的性能。", "conclusion": "总体而言，Hi-ORS通过结合拒绝采样和监督训练，有效地解决了RL和IL的不稳定性和监督不足问题，显著提高了机器人操作策略的鲁棒性和效率。"}
{"llm_update_time": "20251101", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.26412", "html_url": "https://arxiv.org/abs/2510.26412", "title": "LoCoT2V-Bench: 一种长形式和复杂文本到视频生成的基准", "title_en": "LoCoT2V-Bench: A Benchmark for Long-Form and Complex Text-to-Video Generation", "authors": "Xiangqing Zheng,Chengyue Wu,Kehai Chen,Min Zhang", "background": "最近，文本到视频生成在生成短片段的高质量视频方面取得了显著进展，但是在处理复杂提示时，长视频生成的输出评估仍然是一个主要挑战。现有的基准主要依赖于简化的提示，并集中在低级指标上，未能充分关注细节与提示的细粒度对齐以及叙事连贯性和主题表达等抽象维度。因此，需要一个专门设计的基准来解决这些问题。", "innovation": "本文提出了LoCoT2V-Bench，一个专门设计用于在复杂输入条件下生成长视频的基准。它基于各种真实世界的视频，引入了一套包含场景转换和事件动态等元素的现实和复杂的提示。此外，它构建了一个多维度的评估框架，包括新的指标如事件级别的对齐、细粒度的时间一致性、内容清晰度以及着重于叙事流、情感反应和角色发展等抽象属性的Human Expectation Realization Degree (HERD)。通过这种框架，对九个代表性长视频生成模型进行了全面评估，发现当前方法在基本视觉和时间方面表现良好，但在事件间一致性、细粒度对齐和高层次主题一致性等方面存在问题。", "conclusion": "LoCoT2V-Bench 提供了一个全面和可靠的平台来评估长形式和复杂的文本到视频生成，并指出了未来方法改进的重要方向。"}
{"llm_update_time": "20251101", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.26420", "html_url": "https://arxiv.org/abs/2510.26420", "title": "SSCL-BW: 基于样本特定干净标签后门水印的数据库所有权验证", "title_en": "SSCL-BW: Sample-Specific Clean-Label Backdoor Watermarking for Dataset Ownership Verification", "authors": "Yingjia Wang,Ting Qiao,Xing Liu,Chongzuo Li,Sixing Wu,Jianbin Li", "background": "深度神经网络（DNNs）的发展依赖于大规模的高质量数据集，但未经授权的商业使用这些数据集严重侵犯了数据集所有者的知识产权。现有的基于后门的数据集所有权验证方法存在固有的局限性：带有恶意标签的水印由于标签不一致容易被检测到，而干净标签的水印则面临高技术复杂性和在高分辨率图像上的失败。此外，这两种方法都采用静态水印模式，这些模式容易被检测和移除。", "innovation": "本文提出了一种基于样本特定的干净标签后门水印方法（即SSCL-BW），通过训练基于U-Net的水印样本生成器来生成每个样本的独特水印，从根本上克服了静态水印模式的脆弱性。核心创新在于设计了一个包含三种组件的复合损失函数：目标样本损失确保水印效果，非目标样本损失保证触发可靠性，感知相似性损失保持视觉不可感知性。在所有权验证过程中，采用黑盒测试检查可疑模型是否表现出预定义的后门行为。", "conclusion": "在基准数据集上的广泛实验展示了该方法的有效性和对抗潜在水印去除攻击的鲁棒性。"}
{"llm_update_time": "20251101", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.26390", "html_url": "https://arxiv.org/abs/2510.26390", "title": "SPG-CDENet：空间先验引导交叉双编码网络在多器官分割中的应用", "title_en": "SPG-CDENet: Spatial Prior-Guided Cross Dual Encoder Network for Multi-Organ Segmentation", "authors": "Xizhi Tian,Changjun Zhou,Yulin. Yang", "background": "多器官分割是计算机辅助诊断中的关键任务。虽然近期的深度学习方法在图像分割方面取得了显著的成果，但器官大小和形状的巨大变化依然挑战着这些方法在市场上多器官分割中的有效性。这些挑战包括器官间解剖特征的显著差异和不同切片分辨率带来的影响，从而导致分割结果的不一致性。为了应对这些挑战，本文提出了一种空间先验引导交叉双编码网络（SPG-CDENet），这也是本文的创新点之一。该网络是专为提高多器官分割精度而设计的一种新型两阶段分割架构，通过这些技术来应对现状中的挑战。SPG-CDENet 包含两部分关键组件：空间先验网络和交叉双编码网络。这些组件之间的互动带来了新的功能和改进，使整体性能得到提升。研究表明，SPG-CDENet 在现有分割方法中的性能更优，突出地展示了其在准确性的改进。研究还进一步证实了本文提出模块的有效性，进一步改进了分割的精确度。", "innovation": "本文提出了一种空间先验引导交叉双编码网络（SPG-CDENet），这是一种新型的两阶段分割架构，专为提高多器官分割精度而设计。此网络包含两个关键组件：空间先验网络和交叉双编码网络，它们之间通过一个对称交叉注意力模块和一个流基解码器进行更紧密的互动。这些新技术的引进，使得在多器官分区中的分割精度显著提高，特别表现在处理器官大小和形状的巨大变化带来的挑战。", "conclusion": "本文通过大量定性和定量的实验，展示了提出的 SPG-CDENet 在多器官分割任务中的优越表现。进一步地，通过消融实验验证了提出的模块可以显著提升分割精度。这些结果表明，SPG-CDENet 提供了多器官分割的一种新的有效方法。"}
{"llm_update_time": "20251101", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.26444", "html_url": "https://arxiv.org/abs/2510.26444", "title": "从稀有数据进行个性化治疗结果预测的双通道知识蒸馏与自适应融合", "title_en": "Personalized Treatment Outcome Prediction from Scarce Data via Dual-Channel Knowledge Distillation and Adaptive Fusion", "authors": "Wenjie Chen,Li Zhuang,Ziying Luo,Yu Liu,Jiahao Wu,Shengcai Liu", "background": "精准医疗中，对于小样本和稀有患者群体的个性化治疗结果预测至关重要。然而，昂贵的临床试验数据限制了预测性能。", "innovation": "提出了跨保真度知识蒸馏与自适应融合网络（CFKD-AFN），利用丰但低保真度的模拟数据来增强稀缺但高保真度的试验数据的预测性能。CFKD-AFN 包含一个双通道知识蒸馏模块，用于从低保真度模型中提取互补知识，以及一个注意力引导融合模块，用于动态整合多源信息。", "conclusion": "在慢性阻塞性肺疾病的治疗结果预测实验中，CFKD-AFN 在预测准确性上显著优于现有方法，范围从6.67%到74.55%，且对高保真度数据集大小的变化显示较强的鲁棒性。此外，还扩展了 CFKD-AFN 到一个可解释的变体，以支持临床决策并探索潜在的医学语义。"}
{"llm_update_time": "20251101", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.26543", "html_url": "https://arxiv.org/abs/2510.26543", "title": "大型语言模型中关系解码线性算子的结构", "title_en": "The Structure of Relation Decoding Linear Operators in Large Language Models", "authors": "Miranda Anna Christ,Adrián Csiszárik,Gergely Becsó,Dániel Varga", "background": "本文研究了Hernandez等人在2023年引入的可以解码特定关系事实的线性算子在变换器语言模型中的结构。以往的研究主要集中在单一关系上，本文将其扩展到了多个关系，并系统地构建了这些关系解码器的组织结构。", "innovation": "本文通过简单的三阶张量网络，将多个关系解码器进行了高度压缩，且损失不大。为此开发了一种交叉评估协议，揭示了线性变换算子实际上是提取了重复的、粗略的语义属性，而非编码特定的关系。这种属性中心的结构解释了这些算子的压缩性，并揭示了它们为何能泛化到那些在语义上相似的新关系。", "conclusion": "本文的研究结果表明，变换器语言模型中的线性关系解码主要是基于属性的，而不是特定于一定关系。"}
{"llm_update_time": "20251101", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.26451", "html_url": "https://arxiv.org/abs/2510.26451", "title": "通过分类复杂度缓解提高鲁棒图凝缩", "title_en": "Robust Graph Condensation via Classification Complexity Mitigation", "authors": "Jiayi Luo,Qingyun Sun,Beining Yang,Haonan Yuan,Xingcheng Fu,Yanbiao Ma,Jianxin Li,Philip S. Yu", "background": "图凝缩（GC）因其能够合成更小但更具信息量的图而受到广泛关注。然而，现有的研究工作往往忽略了图在原始图被损坏的场景中的鲁棒性。在这种情况下，我们发现图凝缩的性能会显著下降，而现有的鲁棒图学习技术也只能提供有限的效果。通过实证研究和理论分析，我们揭示了图凝缩本质上是一种降低内在维度的过程，合成一个分类复杂性较低的压缩图。尽管这一特性对图凝缩的有效性至关重要，但对对抗性扰动仍高度脆弱。", "innovation": "研究采用图数据流形的几何视角，提出了一个新的鲁棒图凝缩框架（MRGC），包括三个图数据流形学习模块，引导压缩图位于光滑、低维度且类别模糊性最小的流形内，从而保持图凝缩的分类复杂性减少能力，并在普遍对抗性攻击下确保鲁棒性性能。", "conclusion": "广泛的实验表明，MRGC在不同的攻击场景中具有鲁棒性。"}
{"llm_update_time": "20251101", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.26484", "html_url": "https://arxiv.org/abs/2510.26484", "title": "大型语言模型的贝叶斯网络融合用于情感分析", "title_en": "Bayesian Network Fusion of Large Language Models for Sentiment Analysis", "authors": "Rasoul Amirzadeh,Dhananjay Thiruvady,Fatemeh Shiri", "background": "大型语言模型（LLMs）不断发展，出现了越来越多针对特定领域的变种，用于专门任务。但这些模型通常缺乏透明性和可解释性，调整成本高，需要大量的提示工程，结果在不同领域不一致，且由于高计算需求对环境造成显著负面影响。为了解决这些挑战，本文提出了一种贝叶斯网络LLM融合框架（BNLF），该框架通过一种概率机制集成来自三种LLM（FinBERT、RoBERTa和BERTweet）的预测，用于情感分析。BNLF采用延迟融合策略，将来自多个LLM的情感预测建模为贝叶斯网络中的概率性节点。BNLF在三个不同语言和上下文特征的人标注金融语料库上进行了评估，显示出在基线LLMs上的约六个百分点的准确性提升，证明了其对数据集变化的鲁棒性和概率性融合在可解释情感分类中的有效性。", "innovation": "本文提出了一种贝叶斯网络LLM融合框架（BNLF），通过建模多LLM的情感预测为一个贝叶斯网络来实现预测的融合。BNLF在不同金融语料库上的表现优于基线模型，展示了其在数据集变化下的鲁棒性和概率融合的有效性，为情感分析提供了新的解决方案。", "conclusion": "BNLF框架在不同金融语料库上一致地提高了准确率，达到了约六个百分点的提升，表明其能够有效应对数据集变化，并且其概率融合方法为情感分析提供了有效的、可解释的方法。"}
{"llm_update_time": "20251101", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.26474", "html_url": "https://arxiv.org/abs/2510.26474", "title": "通过头部-尾部再平衡在LVLMs自改善中对抗马太效应", "title_en": "Counteracting Matthew Effect in Self-Improvement of LVLMs through Head-Tail Re-balancing", "authors": "Xin Guo,Zhiheng Xi,Yiwen Ding,Yitao Zhai,Xiaowei Shi,Xunliang Cai,Tao Gui,Qi Zhang,Xuanjing Huang", "background": "自改善已成为提升大型视觉语言模型（LVLMs）推理能力的主流范式，模型通过迭代地探索和学习成功轨迹来提高性能。然而，研究发现这一过程存在关键问题：模型在生成简单查询（头部数据）的高质量轨迹方面表现出色，但在处理复杂查询（尾部数据）时存在困难。这种不平衡优化驱使模型优先发展简单推理技能，而忽视了复杂推理任务的能力发展，导致随着时间推移这种不平衡更加明显，我们称之为‘马太效应’。这种不平衡最终阻碍了进一步的模型改进，导致性能瓶颈。", "innovation": "本文提出了四种有效策略，从重塑分布和重新采样轨迹两个视角出发，以实现探索和学习过程中头部-尾部的再平衡。实验结果表明，这些方法在多个视觉推理任务中显著提升了模型的视觉推理能力，平均提高了3.86个点，相较于传统的自改善方法有显著提升。", "conclusion": "研究通过引入头部-尾部再平衡策略有效解决了LVLMs自改善过程中的马太效应问题，进而改善了模型的视觉推理能力。"}
{"llm_update_time": "20251101", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.26551", "html_url": "https://arxiv.org/abs/2510.26551", "title": "基于可变长度工具操作学习的自适应逆运动学框架", "title_en": "Adaptive Inverse Kinematics Framework for Learning Variable-Length Tool Manipulation in Robotics", "authors": "Prathamesh Kothavale,Sravani Boddepalli", "background": "传统机器人对自身运动学的理解有限，只能执行预编程的任务，限制了它们高效使用工具的能力。由于工具使用的四个关键方面：抓取目标、选择最合适的工具、确定最佳工具方向和执行精确操作，现有的逆运动学解算器能力有限，研究提出了一个创新框架来扩展机器人逆运动学解算器的功能，使其能够使用不同长度的工具完成一系列操作。", "innovation": "提出的创新框架融合了模拟学习的动作轨迹和工具，展示了将模拟中获得的技能转移到真实世界场景的实用性，并且展示了基于逆运动学解算器扩展后能够实现几乎不超出1厘米的误差率。此外，训练策略在模拟中的平均误差为8厘米，并且模型在使用不同长度的两个工具时实现了几乎不可区分的性能。这项研究提供了一个信号，指出了在工具使用四个基本方面探索未来发展潜力的机会，使机器人能够掌握复杂的工具操作技巧，应对各种任务。", "conclusion": "实验表明，扩展后的逆运动学解算器在使用不同长度的工具时，几乎不产生可辨别的性能差异，并且该策略在模拟中的表现良好。这项研究为机器人在多种任务中掌握精细的工具操作提供了新的思路，可能推动机器人技术在工具使用领域的进一步发展。"}
{"llm_update_time": "20251101", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.26512", "html_url": "https://arxiv.org/abs/2510.26512", "title": "Inside CORE-KG: Evaluating Structured Prompting and Coreference Resolution for Knowledge Graphs", "title_en": "Inside CORE-KG: Evaluating Structured Prompting and Coreference Resolution for Knowledge Graphs", "authors": "Dipak Meher,Carlotta Domeniconi", "background": "人口走私网络日益适应性强且难于分析。法律案例文件提供关键见解，但这些文件通常是非结构化的、词汇密集型的，且充满模糊或变化的参考，这对自动化知识图谱（KG）构建提出了重大挑战。尽管基于大语言模型（LLM）的方法在静态模板之上有所改进，但它们仍会产生噪声较大、碎片化且存在重复节点的知识图。最近提出的CORE-KG框架通过整合类型感知的共指模块和领域引导的结构化提示，显著减少了节点重复和法律噪音，从而解决了上述问题。", "innovation": "这项工作是评估CORE-KG的关键组件——共指解析和结构化提示——对于知识图构建的贡献。CORE-KG提出了一个类型感知的共指模块和领域引导的结构化提示，显著减少了节点重复和法律噪音。通过系统性的消融研究，该研究量化了每个关键组件的独立贡献，发现共指解析的去除导致节点重复增加28.32%，噪音节点增加4.32%；结构化提示的去除导致节点重复增加4.34%，噪音节点增加73.33%。这些发现提供了设计鲁棒的大语言模型基础管道的实验见解，用于从复杂法律文本中提取结构化表示。", "conclusion": "这项研究通过系统性的消融研究，证实了CORE-KG框架在减少节点重复和减少噪音上的有效性，并提供了对于设计稳健的大语言模型基础管道的实验见解，特别是在从复杂法律文本中提取结构化知识图方面。"}
{"llm_update_time": "20251101", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.26575", "html_url": "https://arxiv.org/abs/2510.26575", "title": "InfoFlow：通过奖励密度优化强化搜索代理", "title_en": "InfoFlow: Reinforcing Search Agent Via Reward Density Optimization", "authors": "Kun Luo,Hongjin Qian,Zheng Liu,Ziyi Xia,Shitao Xiao,Siqi Bao,Jun Zhao,Kang Liu", "background": "Reinforcement Learning with Verifiable Rewards (RLVR) 在增强代理深度搜索方面具有潜力，但由于深度搜索场景中的低奖励密度问题，其应用受到阻碍。低奖励密度意味着代理在进行大量探索性尝试后才能获得稀少且常常为零的奖励。这种情况下，RLVR 的应用受到了限制。因此，需要解决这一挑战以改善探索成本与收益之间的比率，正式定义为奖励密度优化问题。", "innovation": "本文引入了一种名为 InfoFlow 的系统框架，该框架从三个方面解决了奖励密度优化问题：1) 子问题分解：将长期任务分解为过程奖励，提供更密集的学习信号；2) 失败引导提示：向停滞的轨迹注入纠正指导，提高成功结局的可能性；3) 双代理精炼：采用双代理架构，减轻对深度探索的认知负担，通过精炼代理整合搜索历史，有效压缩研究者的感知轨迹，从而降低探索成本并提高整体的奖励密度。", "conclusion": "我们对 InfoFlow 在多种代理搜索基准测试上进行了评估，结果显示其显著优于强大的基线模型，使轻量级的LLM 能够达到与先进专有LLM 相匹敌的性能。"}
{"llm_update_time": "20251101", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.26566", "html_url": "https://arxiv.org/abs/2510.26566", "title": "使用Jensen-Shannon距离进行多类局部校准", "title_en": "Multiclass Local Calibration With the Jensen-Shannon Distance", "authors": "Cesare Barbera,Lorenzo Perini,Giovanni De Toni,Andrea Passerini,Andrea Pugnana", "background": "开发可信的机器学习（ML）模型需要它们的概率预测准确反映真实类别的频率。在多类分类的校准概念中，强校准是最严格的，因为它要求所有预测的概率在所有类别中同时校准。然而，现有方法在多类校准中缺少输入之间的距离感，这使它们容易受到邻近偏差的影响：特征空间中稀疏区域的预测结果会系统性地不准确。这一问题在医疗保健等高风险领域尤为关键，因为稀疏实例正是最需要公平治疗的风险群体。", "innovation": "本文通过引入多类局部校准的地方视角，解决了这一主要缺陷。首先，正式定义了多类局部校准，并建立了其与强校准的关系。其次，分析了现有评价指标应用于多类局部校准的陷阱。第三，提出了一种在神经网络中增强局部校准的实用方法，这种方法使用Jensen-Shannon距离来匹配预测概率和局部类别频率估计。最后，通过实验证明了该方法的有效性，以验证它对现有多类校准技术的改进。", "conclusion": "本文通过引入多类局部校准的概念，提出了一个新的理论和实用方法。这种方法使用Jensen-Shannon距离来增强模型的局部校准，减少邻近偏差，尤其在医疗保健等风险较高的领域具有重要意义。"}
{"llm_update_time": "20251101", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.26457", "html_url": "https://arxiv.org/abs/2510.26457", "title": "SecureReviewer: 通过安全意识微调增强大型语言模型进行安全代码审查", "title_en": "SecureReviewer: Enhancing Large Language Models for Secure Code Review through Secure-aware Fine-tuning", "authors": "Fang Liu,Simiao Liu,Yinghao Zhu,Xiaoli Lian,Li Zhang", "background": "在软件系统开发的早期阶段识别和解决安全问题对于减轻长期负面影响至关重要。代码审查是一种有效的实践，允许开发人员在代码集成到代码库之前检查队友的代码。虽然各种自动代码审查方法已经被提出，其中基于LLM的方法显著提升了自动审查生成的能力，但现有的模型主要集中在通用代码审查上，其在识别和解决安全相关问题的有效性仍缺乏研究。此外，将现有的代码审查方法针对性地应用于安全问题也面临着数据稀缺性和不合适的评价指标等重大挑战。因此，需要一种新的方法来解决这些限制，以提高大型语言模型在安全代码审查方面的识别和解决安全相关问题的能力。", "innovation": "本文提出了SecureReviewer，一种新方法，旨在增强LLM用于在代码审查中识别和解决安全相关问题的能力。SecureReviewer通过构建一个专门用于训练和评估安全代码审查能力的数据集实现了这一目标。此外，利用此数据集，作者对LLMs进行了微调，采用作者提出的安全意识微调策略生成可以有效识别安全问题并提供修复建议的代码审查评论。为了减少LLMs的幻觉并提高其输出的可靠性，本文还引入了RAG技术，通过将生成的评论与领域特定的安全知识相结合来实现。此外，作者还提出了SecureBLEU，一种评估生成的审查评论在解决安全问题方面的有效性的新评价指标。实验结果表明，SecureReviewer在安全问题检测准确性以及生成的审查评论的整体质量和实用价值方面均优于最先进的基线方法。", "conclusion": "通过SecureReviewer方法，作者成功地增强了大型语言模型在安全代码审查中的识别和解决安全相关问题的能力。基于SecureReviewer的数据集构建和创新的微调策略，以及用于评估生成审查评论的可靠性及有效性的新方法，本研究在多种任务上取得了显著的成果，对未来的大型语言模型应用于安全代码审查具有重要意义。"}
{"llm_update_time": "20251101", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.26494", "html_url": "https://arxiv.org/abs/2510.26494", "title": "使用大规模语言模型代理模拟和实验社交媒体动员", "title_en": "Simulating and Experimenting with Social Media Mobilization Using LLM Agents", "authors": "Sadegh Shirani,Mohsen Bayati", "background": "社交媒体平台，特别是在线社交网络（如Facebook、Twitter），已经改变了政治动员信息的传播方式，引发了关于大规模社交影响力如何形成的新问题。本研究基于陆标性的Facebook实验（涉及6100万用户）[1]，构建了一种基于代理的模拟框架，结合了真实的美国人口普查人口统计分布、真实的Twitter网络拓扑结构和异质性大规模语言模型（LLM）代理，以探究政治动员信息对选民参与度的影响。该论文通过实验条件复制了原始Facebook研究的信息和社交动员措施，揭示了在社交信息处理下的动员效果增强及可度量的社交溢出效应。实验结果与实地实验的定性模式相符，例如，在社交消息处理下动员效果更强，并存在可测量的社交溢出效应。该框架为政治动员研究提供了受控的、可重复的环境，用于测试非事实设计方案和敏感性分析，架起了从高质量实地实验到灵活计算建模之间的桥梁。", "innovation": "该研究的创新点在于开发了一种基于代理的模拟框架，该框架整合了真实的人口统计信息、实际的社交媒体网络结构以及异质性的大规模语言模型。这种做法允许研究人员在受控环境中测试不同的政治动员策略，从而更好地理解这些策略在大规模社交媒体环境中的效果。与之前的实验相比，这种方法更灵活且更容易进行重复和对比实验。此外，通过使用异质性代理，研究提高了复杂性和现实性，模拟了更广泛的公众态度和行为模式。这种方法有助于填补实际现场实验和完全计算模型之间的空白，为研究提供了一种有效的验证手段。适合进行政治动员研究中的假设检验和敏感性分析", "conclusion": "本研究通过基于代理的模拟框架重现了选民参与度中社交媒体动员的定量和定性特征，提供了控制环境下的非事实设计方案测试平台，为推进政治动员研究和计算社会科学提供了有价值的工具。实验结果表明，在社交媒体上实施动员信息时，社交信息处理下的效果明显增强，表明社交互动对个体参与度的影响是显著的。这种方法为未来的政治动员研究提供了新的可能性，并为构建更为精确、复杂的社交媒体模拟奠定了基础。"}
{"llm_update_time": "20251101", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.26585", "html_url": "https://arxiv.org/abs/2510.26585", "title": "节省你的令牌：迈向高效的运行时多智能体系统", "title_en": "Stop Wasting Your Tokens: Towards Efficient Runtime Multi-Agent Systems", "authors": "Fulin Lin,Shaowen Chen,Ruishan Fang,Hongwei Wang,Tao Lin", "background": "多智能体系统（MAS）在复杂任务方面表现出色，但随着其自主性与操作复杂性的增长，经常会出现关键性的低效率问题，如令牌消耗过多和因虚假信息导致的失败。现有的方法主要集中在失事后的事后分析归因，缺乏能够提前介入、实时提升鲁棒性和效率的干预手段。", "innovation": "为了应对上述问题，我们提出了SupervisorAgent框架，这是一种轻量级且模块化的实时、自适应监督框架，能够在不改变基础智能体架构的情况下运行。SupervisorAgent通过一个无需LLM的自适应过滤器触发，在关键时刻主动介入，纠正错误，引导低效率行为，并净化观察结果。在GAIA基准测试中，SupervisorAgent将Smolagent框架的token消耗平均减少了29.45%，而不损害其成功率。", "conclusion": "大量的实验验证了SupervisorAgent在五个额外基准（数学推理、代码生成和问答）以及各种最新的基础模型中的广泛应用性和鲁棒性。我们的代码可以在以下链接获取：this https URL."}
{"llm_update_time": "20251101", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.26684", "html_url": "https://arxiv.org/abs/2510.26684", "title": "钢铁轧制车间内集成计算机视觉的实时故障预测", "title_en": "Process Integrated Computer Vision for Real-Time Failure Prediction in Steel Rolling Mill", "authors": "Vaibhav Kurrey,Sivakalyan Pujari,Gagan Raj Gupta", "background": "本文介绍了在钢铁轧制车间中基于机器视觉的异常检测系统的研究，该系统能够通过工业摄像头实现实时监控设备运行、对齐以及热棒运动等，在整个生产线过程中进行故障预测，从而提前预测设备故障和工艺中断，减少非计划停机成本。", "innovation": "系统采用基于深度学习模型对实时视频流进行处理，并在服务器端实现推理，从而减轻工业过程控制系统（PLC）的计算负担，支持在生产线上进行可扩展部署，无需额外资源。通过联合分析数据采集系统数据和视觉输入，系统能够识别故障的位置及可能的根本原因，提供可操作的见解，用于主动维护。", "conclusion": "这种集成方法在工业制造环境中增强了操作可靠性、生产效率和盈利能力，能够实现实时的故障预测，从而提高管理效率和系统稳定性。"}
{"llm_update_time": "20251101", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.26616", "html_url": "https://arxiv.org/abs/2510.26616", "title": "Aeolus：一种多结构航班延误数据集", "title_en": "Aeolus: A Multi-structural Flight Delay Dataset", "authors": "Lin Xu,Xinyun Yuan,Yuxuan Liang,Suwan Yin,Yuankai Wu", "background": "现有的航班延误预测数据集通常仅限于平坦的表格结构，无法捕捉因延误传播而具有的时空动态特性。", "innovation": "Aeolus 通过提供三种对齐的模态解决了这一限制：（i）一个包含丰富的操作、气象和机场级别特征的大型表格数据集，涵盖了超过5000万次航班；（ii）一个航班链模块，用于建模沿顺序航班航段的延误传播，捕捉上下流依赖关系；（iii）一个航班网络图，编码共享飞机、机组人员和机场资源的连接，支持跨航班关系推理。该数据集经过精心构建，具有时间上的分拆、综合的特征和严格的泄露预防，以支持实际的和可复现的机器学习评估。", "conclusion": "Aeolus 作为表格、序列和图的统一基准，支持包括回归、分类、时间结构建模和图学习在内的广泛任务，为特定领域建模和通用结构数据填补了关键空白。已发布基准实验和预处理工具以促进采用。相关代码和数据可访问：https://github.com/ECPeng/Aeolus"}
{"llm_update_time": "20251101", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.26601", "html_url": "https://arxiv.org/abs/2510.26601", "title": "ResMatching：基于引导条件流匹配的抗噪计算超分辨率", "title_en": "ResMatching: Noise-Resilient Computational Super-Resolution via Guided Conditional Flow Matching", "authors": "Anirban Ray,Vera Galinova,Florian Jug", "background": "计算超分辨率（CSR）在荧光显微镜中有着悠久的历史，尽管它是一个病态问题。CSR的核心在于找到一种先验知识，以实现从未被成像显微镜捕捉到的频率的外推。随着数据驱动的机器学习技术的进步，能够学习更强的先验知识，从而导致更优的CSR结果。现有方法在生物SR数据集中4种不同的生物结构上进行了评估，并与7种基线进行了对比。研究表明，使用ResMatching方法的CSR在所有情况下都达到了最好的数据保真度和感知现实之间的平衡。此外，还展示了ResMatching如何从隐式学习的后验分布中进行采样，并且该分布对所有测试使用场景都进行了校准，从而能够提供像素级的数据不确定性信息，指导未来的用户拒绝不确定的预测。", "innovation": "ResMatching是一个新颖的CSR方法，利用引导条件流匹配来学习增强的数据先验知识。该方法在所有情况下都显示出了在数据保真度和感知现实之间的最佳平衡。特别地，在低分辨率图像含有大量噪声等难以学习强先验的情况下，ResMatching特别有效。此外，ResMatching还能够从隐式学习的后验分布中采样，并且该分布已经校准，能够提供像素级的数据不确定性信息。", "conclusion": "ResMatching展示了在抗噪计算超分辨率方面的优越性能，特别是在学习强先验知识困难的情况下。此外，该方法能够进行像素级的数据不确定度估计，指导用户进行预测接受和拒绝。"}
{"llm_update_time": "20251101", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.26683", "html_url": "https://arxiv.org/abs/2510.26683", "title": "Evontree：基于本体规则指导的大型语言模型自我演化", "title_en": "Evontree: Ontology Rule-Guided Self-Evolution of Large Language Models", "authors": "Mingchen Tu,Zhiqiang Liu,Juan Li,Liangyurui Liu,Junjie Wang,Lei Liang,Wen Zhang", "background": "大型语言模型（LLMs）通过大规模预训练和精心策划的微调数据展示了在多个领域的出色能力。然而，在医疗等数据敏感领域，由于缺乏高质量、特定领域的训练语料库，限制了LLMs的特定应用适应性。与此同时，领域专家将其领域智慧凝练为本体规则，这些规则规范了概念之间的关系，并保证了知识管理系统的一致性。尽管如此，LLMs被视为人类知识的隐性知识库，本文提出了一种名为Evontree的新颖框架，利用少量高质量的本体规则系统地从原始模型中提取、验证和增强领域知识，而不依赖于大规模外部数据集。", "innovation": "Evontree框架的创新之处在于它利用少量高质量的本体规则来系统地从原始模型中提取、验证和增强特定领域的知识，而不依赖于大规模外部数据集。Evontree框架通过从原始模型中提取领域本体，使用两个核心本体规则检测不一致，并通过自我蒸馏微调强化精炼知识。实验结果表明，Evontree在医疗问答基准测试中表现优于未修改的模型和领先的监督基线，准确率最高提高了3.7%。", "conclusion": "实验结果验证了Evontree框架在LLMs低资源领域适应方面的有效性、效率和鲁棒性。"}
{"llm_update_time": "20251101", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.26714", "html_url": "https://arxiv.org/abs/2510.26714", "title": "关于仅使用单一训练种子评估机器遗忘的局限性", "title_en": "On the limitation of evaluating machine unlearning using only a single training seed", "authors": "Jamie Lanyon,Axel Finke,Petros Andreou,Georgina Cosma", "background": "机器遗忘（MU）旨在移除已训练模型中某些数据点的影响，而不需要昂贵的重新训练。大多数实际的MU算法只能提供近似的结果，其性能只能通过实证评估。因此，在评估MU算法时，需要尽可能地确保实证比较具有代表性。一种常见的做法是多次独立地运行MU算法，从同一个训练模型开始。然而，研究发现，这种做法可能会得出高度非代表性的结果，即使是在相同的架构和数据集下，某些MU方法也可能对用于模型训练的随机数种子选择非常敏感。因此，研究建议在评估MU算法时，应当反映不同模型训练种子之间的差异性。", "innovation": "研究通过实验证明，仅仅使用单一训练种子评估MU算法可能会导致非代表性的结果，而某些MU方法对于训练时使用的随机数种子的选择非常敏感，提出了评估MU算法时应该考虑不同训练种子的变异性的建议。", "conclusion": "评估MU算法时，需要考虑到不同模型训练种子之间的差异性，以避免得出非代表性的结果，并更好地反映MU算法的真实性能。"}
{"llm_update_time": "20251101", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.26646", "html_url": "https://arxiv.org/abs/2510.26646", "title": "Hybrid DQN-TD3 Reinforcement Learning for Autonomous Navigation in Dynamic Environments", "title_en": "Hybrid DQN-TD3 Reinforcement Learning for Autonomous Navigation in Dynamic Environments", "authors": "Xiaoyi He,Danggui Chen,Zhenshuo Zhang,Zimeng Bai", "background": "该论文提出了一种结合高、低两级控制模块的路径规划与控制框架，用于动态环境中的自主导航。传统的单算法方案或基于规则的规划器可能无法处理动态且部分可观测的环境，而此框架通过结合高一级的Deep Q-Network (DQN) 和低一级的Twin Delayed Deep Deterministic Policy Gradient (TD3) 控制器来提高系统的性能和适应性。该系统通过ROS + Gazebo实现，并在动态且部分可观测的环境下进行评估。实验证明，相较于单算法方案或规则型规划器，该框架在效果和泛化能力上有所提升。", "innovation": "提出了一种将高一级的DQN与低一级的TD3相结合的路径规划与控制框架。设计了综合的方向、距离、障碍物避免、动作平滑度、碰撞惩罚、时间惩罚和进度等的奖励塑造方案，并通过LIDAR设置安全门以防止不安全动作。该系统在ROS + Gazebo平台上实现，并采用了PathBench指标进行评估，包括成功率、碰撞率、路径效率和重规划效率。实验结果表明，该系统在成功率和样本效率上优于单算法或基于规则的规划器，并在处理动态和部分可观测环境方面具有更好的泛化能力，减少了突变控制的变化。", "conclusion": "该工作提出了一种新颖的框架，通过结合DQN和TD3在动态环境中实现自主导航，显著提高了系统的成功率和样本效率，降低了突变控制的变化，并具有更好的泛化能力。这一框架为动态环境下自主导航的研究提供了有价值的参考，并为未来的研究奠定了基础。"}
{"llm_update_time": "20251101", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.26697", "html_url": "https://arxiv.org/abs/2510.26697", "title": "自动解码：迈向真正端到端语言模型", "title_en": "The End of Manual Decoding: Towards Truly End-to-End Language Models", "authors": "Zhichao Wang,Dongyang Ma,Xinting Huang,Deng Cai,Tian Lan,Jiahao Xu,Haitao Mi,Xiaoying Tang,Yan Wang", "background": "现有的大规模语言模型（LLMs）的‘端到端’标签存在误导，因为它们依赖于非可微的解码过程，这需要手工调整诸如温度（temperature）和至多比例（top-p）等超参数。这一过程耗费大量的人力资源。", "innovation": "该论文提出了AutoDeco，一种新架构，能够实现实质上的‘端到端’生成。AutoDeco通过在其标准变压器上添加轻量级头部，在每个步骤中动态预测上下文相关的温度和至多比例值，从而将解码转变为一个参数化和逐令牌的过程，使得模型能够在单个前向传递中自我调节其采样策略。AutoDeco不仅在八个基准测试中显著优于默认解码策略，其性能也接近于‘解码测试集赋能（hacking the test set）’的或然调优基准，并且发现了一种基于指令的解码控制新能力，模型能够根据自然语言指令（例如“生成低随机性的文本”）逐令牌调整预测的温度和至多比例。", "conclusion": "AutoDeco为可调和交互的语言模型解码开启了新的范式，实现了真正意义上的端到端的模型体系，并显著提升了模型的性能，具有重要的实用价值和创新意义。"}
{"llm_update_time": "20251101", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.26740", "html_url": "https://arxiv.org/abs/2510.26740", "title": "基于一般激励机制的多智能体资源分配公平性框架", "title_en": "A General Incentives-Based Framework for Fairness in Multi-agent Resource Allocation", "authors": "Ashwin Kumar,William Yeoh", "background": "在资源受限的环境中，优化效率的代理常会产生不公平的结果。传统的价值函数无法直接实现公平决策，需要新的方法来平衡效率与公平。", "innovation": "提出了一种名为GIFF的新颖方法，通过利用动作-价值函数（Q-函数）来平衡效率与公平，无需额外训练。GIFF计算每种动作的局部公平收益，并引入一个反事实优势校正项，以防止对已经富裕的代理进行过度分配。这种方法在一个集中控制的环境中进行理论化，由仲裁者使用GIFF修改后的Q值来解决分配问题。", "conclusion": "在不同领域的实证评估表明，该框架在多个公平性基准测试中表现优异，能够发现远见卓识的公平政策。理论基础证明GIFF的有效性，证明其公平性代理是真实的公平改进的有根据的下界，并且其权衡参数具有单调调整能力。这些发现确立了GIFF作为利用标准强化学习组件实现更公允的多智能体系统结果的稳健和原则性的框架。"}
{"llm_update_time": "20251101", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.26730", "html_url": "https://arxiv.org/abs/2510.26730", "title": "ExpertFlow：适应性专家调度和内存协调以实现高效MoE推理", "title_en": "ExpertFlow: Adaptive Expert Scheduling and Memory Coordination for Efficient MoE Inference", "authors": "Zixu Shen,Kexin Chu,Yifan Zhang,Dawei Xiang,Runxin Wu,Wei Zhang", "background": "随着大型语言模型的不断扩展，现代GPU的内存容量限制逐渐成为一个瓶颈。传统的Mixture-of-Experts（MoE）架构在推理时激活少量的参数，从而降低了内存需求和计算开销。然而，现有的MoE推理方法通常在每一层独立地选择活跃专家，这会导致频繁的参数传输，增加延迟。此外，当前的跨层预测策略通常基于固定的步骤，缺乏跨不同硬件平台和工作负载的适应性，从而降低了其鲁棒性和有效性。", "innovation": "该论文提出了一种名为ExpertFlow的运行时系统，结合了自适应专家预取和缓存感知路由。通过利用运行时统计信息（如传输带宽、参数维度和模型反馈信号）来不断调整其预测窗口期，以及结合预闸门信息与中间计算状态来预测未来的专家需求，ExpertFlow能够更有效地减少缓存未命中，并减少由于专家切换引起的延迟。评估结果显示，与基线相比，ExpertFlow将模型停滞时间降低到不到0.1%，证明了其在严格的内存限制下优化MoE推理的能力。", "conclusion": "我们的研究结果表明，ExpertFlow不仅能够显著降低模型停滞时间，还能够在内存受限的情况下优化MoE推理。通过自适应的预取决策和与实际使用行为的对齐，ExpertFlow有效地减少了缓存未命中并消除了专家切换引起的延迟。"}
{"llm_update_time": "20251101", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.26745", "html_url": "https://arxiv.org/abs/2510.26745", "title": "深度序列模型倾向于记忆几何结构；尚不清楚其中原因", "title_en": "Deep sequence models tend to memorize geometrically; it is unclear why", "authors": "Shahriar Noroozizadeh,Vaishnavh Nagarajan,Elan Rosenfeld,Sanjiv Kumar", "background": "在序列建模领域，参数内存主要被抽象为实体之间共现的粗暴查找。文章指出，与这种关联视角不同的是，提出了一个几何视角来解释记忆存储的方式。文章通过分析一个Transformer推理的实例，揭示了这种记忆的几何性，与库中存在的局部关联相比，几何结构的建立似乎不受典型架构或优化压力的影响，即使几何结构并不比关联查找更简洁，却能自然地学习这种结构。", "innovation": "文章通过对比关联视角和几何视角，揭示了Transformer模型在处理任务时如何合成了自身原子事实的几何结构，从而将复杂推理任务简化为一个易于学习的几何任务。此外，通过分析与Node2Vec的联系，提出了一种避开常规理论的光谱偏向，证明即使没有各种压力，几何结构也能自然形成。这些发现为改进Transformer内存的几何性提供了新的视角。", "conclusion": "文章认为，几何结构的出现，即便只是优化局部关联，也不是由典型的架构或优化压力引起的。这种几何结构学习即使在局部关联不如几何结构更简洁的情况下也能自然产生。此外，几何视角为知识获取、容量、发现和遗忘等领域的研究提供了新的洞察，鼓励研究人员重新审视默认直觉。"}
{"llm_update_time": "20251101", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.26776", "html_url": "https://arxiv.org/abs/2510.26776", "title": "通过高级采样实现忠实快速的影响函数", "title_en": "Faithful and Fast Influence Function via Advanced Sampling", "authors": "Jungyeon Koh,Hyeonsu Lyu,Jonggyu Jang,Hyun Jong Yang", "background": "影响函数(IFs)可以通过梯度和海森矩阵提供一种后验方法来解释黑盒模型的数据影响。然而，计算整个数据集的海森矩阵资源密集，需要寻找一种可行的替代方案。常见的方法是随机采样一小部分训练数据，但这种做法通常会导致IF估计值高度不一致，因为样本配置具有高方差。", "innovation": "本文提出了两种基于特征和logits的高级采样技术，以选择整个数据集中的一个小而具代表性的子集，通过考虑特征或logits的随机分布来提高IF估计的准确性。这种方法通过减少30.1%的计算时间和42.2%的内存使用量，或相对于基线提高2.5%的F1得分来实现。", "conclusion": "该方法通过特征或logits的采样技术增强了IF估计的准确性，同时显著减少了计算时间和内存使用量，并通过类删除实验验证了其有效性。"}
{"llm_update_time": "20251101", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.26722", "html_url": "https://arxiv.org/abs/2510.26722", "title": "非凸空中异构联邦学习：偏置与方差权衡", "title_en": "Non-Convex Over-the-Air Heterogeneous Federated Learning: A Bias-Variance Trade-off", "authors": "Muhammad Faraz Ul Abrar,Nicolò Michelusi", "background": "空中联邦学习（OTA-FL）已经被广泛认为是一种利用无线多址信道波形叠加来在单次使用中聚合模型更新的可扩展范式。现有的OTA-FL设计主要通过假设一致的无线条件（等路径损耗）或强制零偏差更新来确保收敛。在异构无线场景下，这种设计受到最弱设备的限制，放大了更新的方差。此外，先前对偏置OTA-FL的分析主要集中在凸目标上，而大多数现代AI模型都是高度非凸的。", "innovation": "本文研究了在异构无线环境下使用随机梯度下降（SGD）的一般光滑非凸目标OTA-FL。提出了允许结构化、时间不变模型偏置的新OTA-FL SGD更新，并推导出了有限时间的站定性界限，明确揭示了偏置与方差的权衡。提出了非凸联合OTA功率控制设计，并开发出仅需统计CSID的高效逐次凸逼近（SCA）算法。实验结果表明，基于SCA的设计通过优化偏置加速了收敛，并在前OTA-FL基线之上提高了泛化能力。", "conclusion": "通过优化偏置和方差的权衡，提出的基于SCA的OTA-FL设计能够在异构无线环境下的非凸目标上实现更快的收敛速度和更好的泛化性能。"}
{"llm_update_time": "20251101", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.26787", "html_url": "https://arxiv.org/abs/2510.26787", "title": "远程劳动力指数：衡量远程工作的AI自动化", "title_en": "Remote Labor Index: Measuring AI Automation of Remote Work", "authors": "Mantas Mazeika,Alice Gatti,Cristina Menghini,Udari Madhushani Sehwag,Shivam Singhal,Yury Orlovskiy,Steven Basart,Manasi Sharma,Denis Peskoff,Elaine Lau,Jaehyuk Lim,Lachlan Carroll,Alice Blair,Vinaya Sivakumar,Sumana Basu,Brad Kenstler,Yuntao Ma,Julian Michael,Xiaoke Li,Oliver Ingebretsen,Aditya Mehta,Jean Mottola,John Teichmann,Kevin Yu,Zaina Shaik,Adam Khoja,Richard Ren,Jason Hausenloy,Long Phan,Ye Htet,Ankit Aich,Tahseen Rabbani,Vivswan Shah,Andriy Novykov,Felix Binder,Kirill Chugunov,Luis Ramirez,Matias Geralnik,Hernán Mesura,Dean Lee,Ed-Yeremai Hernandez Cardona,Annette Diamond,Summer Yue,Alexandr Wang,Bing Liu,Ernesto Hernandez,Dan Hendrycks", "background": "尽管AI已经在知识和推理的研究基准上取得了显著进展，但这些进展如何转化为经济价值和自动化仍不清楚。因此，需要一个指标来测量AI在实际经济活动中的自动化水平，从而为讨论AI自动化提供实证依据，设定AI影响的共同基准，并帮助相关利益方积极应对AI驱动的劳动力自动化问题。", "innovation": "论文提出了Remote Labor Index (RLI)，这是一个涵盖多个行业的广泛基准，由实际世界、经济价值高的项目组成，旨在评估AI代理在实际情景中的端到端表现。RLI的结果显示，AI代理的表现接近最低水平，最优秀的代理实现的自动化率为2.5%，这为实证研究AI自动化提供了依据，确立了AI影响的常见基准，使利益相关者能够积极应对AI驱动的劳动力自动化问题。", "conclusion": "RLI为讨论AI自动化提供了实证依据，设立了AI影响的共同基准，并帮助利益相关者积极应对AI驱动的劳动力自动化。"}
{"llm_update_time": "20251101", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.26788", "html_url": "https://arxiv.org/abs/2510.26788", "title": "通过FP16战胜训练-推理不匹配", "title_en": "Defeating the Training-Inference Mismatch via FP16", "authors": "Penghui Qi,Zichen Liu,Xiangxin Zhou,Tianyu Pang,Chao Du,Wee Sun Lee,Min Lin", "background": "大语言模型（LLMs）通过强化学习（RL）微调时，常常会因为训练和推理之间数值不匹配而表现出不稳定。尽管先前的研究尝试通过算法修正或工程对齐来解决这个问题，但这份研究揭示了根本原因在于浮点精度本身，虽然广泛的采用BF16具有大的动态范围，但它引入了大的舍入误差，破坏了训练和推理之间的一致性。", "innovation": "本文展示了简单地回退到FP16可以有效地消除这种不匹配。这一变化简单，由现代框架完全支持，只需要少量代码更改，无需修改模型架构或学习算法。研究表明，使用FP16提供更稳定的优化、更快的收敛和更强的性能。", "conclusion": "研究结果建议，在RL微调时使用FP16具有更广泛的适用性，并期望这些发现能促使对精度折衷的更广泛的重新考虑。"}
{"llm_update_time": "20251101", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.26771", "html_url": "https://arxiv.org/abs/2510.26771", "title": "STaMP: 序列变换和混合精度量化在低精度激活量化中的应用", "title_en": "STaMP: Sequence Transformation and Mixed Precision for Low-Precision Activation Quantization", "authors": "Marco Federici,Riccardo Del Chiaro,Boris van Breugel,Paul Whatmough,Markus Nagel", "background": "量化是降低生成AI模型推理延迟、功耗和内存占用的关键方法。然而，当激活值低于八位时，精度往往会出现急剧下降。近期研究表明，可通过重新参数化特征通道和权重，转换线性变换（如旋转）来辅助量化。", "innovation": "本文提出了序列变换和混合精度量化（STaMP）策略，该策略在线性变换应用于序列维度时，可以利用语言和视觉数据中的强烈局部相关性。通过在每个中间激活保留少量的高精度令牌，能够在较低的（平均）激活位宽下保持模型精度。", "conclusion": "我们在最近的LVM和LLM架构上评估了STaMP，结果表明它在低位宽激活量化方面具有显著改进，并且可以与现有的激活量化和权重量化方法，包括最近的功能变换，进行互补。"}
{"llm_update_time": "20251101", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.26768", "html_url": "https://arxiv.org/abs/2510.26768", "title": "AMO-Bench: 大型语言模型在高中数学竞赛中仍表现不佳", "title_en": "AMO-Bench: Large Language Models Still Struggle in High School Math Competitions", "authors": "Shengnan An,Xunliang Cai,Xuezhi Cao,Xiaoyu Li,Yehao Lin,Junlin Liu,Xinxuan Lv,Dan Ma,Xuanlin Wang,Ziwen Wang,Shuang Zhou(Alphabetical order by last name)", "background": "现有基准测试主要使用中学数学竞赛来评估大型语言模型（LLMs）的数学推理能力，但许多现有的数学竞赛已无法有效评估顶尖级别的LLMs。因此，需要引入更严格的标准来挑战这些模型。", "innovation": "AMO-Bench是首个涵盖50个由专家手工设计、符合国际数学奥林匹克（IMO）难度标准的原创数学问题的基准测试。每个问题仅需提供最终答案，便于自动且稳健的评分。实验结果显示，即使是表现最好的模型在AMO-Bench上的准确率也只有52.4%，大多数LLMs的成绩低于40%。此外，研究发现增加测试时的计算量会显示出良好的扩展趋势。这一结果强调了当前LLMs在数学推理方面的显著改进空间。AMO-Bench的发布旨在促进语言模型推理能力的研究进展。", "conclusion": "AMO-Bench 提供了评估LLMs数学推理能力的新基准，结果显示现有模型在处理中学数学问题时仍存在挑战，强调了改进的空间。"}
{"llm_update_time": "20251101", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.26790", "html_url": "https://arxiv.org/abs/2510.26790", "title": "Gistify！通过运行时执行理解代码库", "title_en": "Gistify! Codebase-Level Understanding via Runtime Execution", "authors": "Hyunji Lee,Minseon Kim,Chinmay Singh,Matheus Pereira,Atharv Sonwane,Isadora White,Elias Stengel-Eskin,Mohit Bansal,Zhengyan Shi,Alessandro Sordoni,Marc-Alexandre Côté,Xingdi Yuan,Lucas Caccia", "background": "随着编码代理在大型代码库中的部署越来越多，自动设计具有挑战性的、代码库级别的评估变得越来越重要。本文旨在通过提出Gistify任务来解决这一问题，该任务要求编码大型语言模型（LLM）创建一个单一的、最小的、自包含的文件，用于重现代码库中的特定功能。编码LLM可以完全访问代码库以及特定的入口点（例如，一个Python命令），生成的文件必须能够复现在完整代码库中运行该命令时的输出，同时仅包含执行所提供命令所需的最小关键组件。", "innovation": "Gistify任务要求编码LLM不仅要理解代码库的结构，准确地建模其执行流程，还需要能够生成可能较大的代码补丁。目前，现有的先进模型在解决Gistify任务时表现出色，特别是在执行日志较长的任务上。这项工作通过引入Gistify任务，验证了当前最先进的模型在代码库级别理解和生成代码方面的局限性。", "conclusion": "本文的研究发现表明，现有的最先进的模型在Gistify任务上难以可靠地解决问题，尤其是那些执行流程较长的任务。这表明，编码LLM在理解代码库的结构和执行流程、生成代码补丁方面还需要进一步的提升。"}
{"llm_update_time": "20251101", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.26782", "html_url": "https://arxiv.org/abs/2510.26782", "title": "使用几何正则化的世界模型克隆确定性3D世界", "title_en": "Clone Deterministic 3D Worlds with Geometrically-Regularized World Models", "authors": "Zaishuo Xia,Yukuan Lu,Xinyi Li,Yifan Xu,Yubei Chen", "background": "世界模型是内部模拟世界如何演化的模型，基于过去的观测和行动预测未来。高质量的世界模型对于使智能体能够在复杂的动态环境中思考、规划和推理是至关重要的。尽管取得了快速的进步，但当前的世界模型仍然在长时间段内表现脆弱，退化严重。研究人员认为，主要原因在于表征质量，环境的高维感知输入（例如，图像）导致学习动态性的过程困难。因此，有人提出通过改进表征学习能否显著提高世界模型的性能。本文针对一个基础而开放的问题——构建一种能够完全克隆和拟合确定性3D世界的模型——进行了研究，构建了一种新的方法，即几何正则化的世界模型（GRWM），并展示了其在3D确定性设定和长时预测任务中的显著效果，进一步证实了提高表征学习能带来稳固的世界模型，实现可靠的长时预测。", "innovation": "提出了几何正则化的世界模型（GRWM），这种方法限制了连续的传感器数据点在潜在表示空间内保持紧密，从而显著改进了潜在表示，并使环境的真实拓扑更加匹配。这种方法具有可插拔特性，仅需少量的架构修改，并且能够随着轨迹长度扩展。研究表明，其效果来源于学习具有优越几何结构的潜在流形。GRWM有效解决了长期预报中的表征和几何问题，并且其改进直接而且实用。", "conclusion": "通过改进表征学习，能够显著提高世界模型性能，确保其在长时间尺度上的准确性。几何正则化的世界模型证明了通过改善表征学习路径直接增强了世界模型的准确性和可靠性，无需扩大动态模块的规模。"}
{"llm_update_time": "20251101", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2503.15937", "html_url": "https://arxiv.org/abs/2503.15937", "title": "改进移动GUI代理：实用部署的验证驱动方法", "title_en": "Advancing Mobile GUI Agents: A Verifier-Driven Approach to Practical Deployment", "authors": "Gaole Dai,Shiqi Jiang,Ting Cao,Yuanchun Li,Yuqing Yang,Rui Tan,Mo Li,Lili Qiu", "background": "现有的移动代理主要依赖大型语言模型（LLMs）生成每个步骤的具体操作，这导致了操作生成的直接性和即时性。而本文提出的方法则侧重于利用LLMs进行验证，在决策前评估候选操作，这提供了一个全新的视角。", "innovation": "论文提出了V-Droid，这是一种使用LLMs作为验证器的移动GUI任务自动化代理。创新点包括：构建验证驱动的移动代理的综合框架（离散化动作空间构建、预填充工作流以加速验证过程、成对进度偏好训练以显著增强验证者的决策能力、以及可扩展的人机联合注释方案以高效收集大规模所需数据）。", "conclusion": "V-Droid 在多个公开的移动任务自动化基准测试中表现出色，其任务成功率分别在AndroidWorld、AndroidLab和MobileAgentBench达到了59.5%、38.3%和49%，相比现有代理，分别提高了5.2%、2.1%和9%。此外，V-Droid 的每步延迟仅为4.3秒，比现有移动代理快了6.1倍。源代码可在此处获得。"}
{"llm_update_time": "20251101", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2505.02820", "html_url": "https://arxiv.org/abs/2505.02820", "title": "AutoLibra：基于开放性人类反馈的代理评价指标生成", "title_en": "AutoLibra: Agent Metric Induction from Open-Ended Human Feedback", "authors": "Hao Zhu,Phil Cuvin,Xinkai Yu,Charlotte Ka Yee Yan,Jason Zhang,Diyi Yang", "background": "现有代理评估主要依赖粗略的任务成功指标，这些指标依赖于专家的手动设计，无法奖励代理的中间自发行为。这限制了对代理细粒度行为的全面评估。", "innovation": "提出了AutoLibra框架，将开放性的人类反馈（例如，“如果发现按钮被禁用，则不要再次点击”或“该代理的自主性过高，自我决策过多”）转化为代理轨迹中细粒度行为的评估指标。该框架通过关联反馈到代理行为，并将类似的行为分群，创建具体的、有明确定义和示例的评估指标，这些指标可用于指导LLM作为评估者。进一步提出了两个元指标（覆盖率和冗余度）来评估一组（诱导的）指标与开放反馈的一致性。", "conclusion": "通过优化这两个元指标，实验表明AutoLibra能够生成比现有代理评估基准中提出的更具体的代理评估指标，并发现新的用于分析代理的指标。此外，AutoLibra在代理改进中有两个应用：一是辅助人类提示工程师进行代理失败的对角化及迭代提示改进；二是诱导出用于代理自动优化的指标，使代理能够通过自我调节提高。研究结果表明AutoLibra是一个强大的任务无关工具，适用于代理评估与改进。"}
{"llm_update_time": "20251101", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2505.10361", "html_url": "https://arxiv.org/abs/2505.10361", "title": "塑性作为赋能的镜像", "title_en": "Plasticity as the Mirror of Empowerment", "authors": "David Abel,Michael Bowling,André Barreto,Will Dabney,Shi Dong,Steven Hansen,Anna Harutyunyan,Khimya Khetarpal,Clare Lyle,Razvan Pascanu,Georgios Piliouras,Doina Precup,Jonathan Richens,Mark Rowland,Tom Schaul,Satinder Singh", "background": "代理是受其过去观察影响并且能影响未来观察的最小实体。赋能概念是解释这种影响能力的重要框架，但代理能够被其观察所影响的能力同样基础且重要。然而，这种能力还未被广泛研究。本文引入了一个通用的代理中心度量‘塑性’，探讨了它与赋能之间的基本联系。并且，通过定义一个新信息理论量‘广义定向信息’，使塑性严格地推广了由马西 (1990) 引入的定向信息，保持了所有的良好性质。在此基础上，塑性被定义为赋能的镜像，揭示了一种紧张关系，认为代理设计需要同时关注这两方面特点。", "innovation": "本文定义了一个新的信息理论量‘广义定向信息’，以严格推广马西 (1990) 的定向信息，并引入了一个代理中心度量‘塑性’，作为赋能的镜像。这揭示了塑性与赋能之间的紧张关系，为代理设计提供了新的视角。", "conclusion": "塑性与赋能之间的关系对于理解代理是至关重要的。代理设计需要综合考虑塑性和赋能两个方面，同时意识到两者之间存在的内在紧张关系。"}
{"llm_update_time": "20251101", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.26802", "html_url": "https://arxiv.org/abs/2510.26802", "title": "Are Video Models Ready as Zero-Shot Reasoners? An Empirical Study with the MME-CoF Benchmark", "title_en": "Are Video Models Ready as Zero-Shot Reasoners? An Empirical Study with the MME-CoF Benchmark", "authors": "Ziyu Guo,Xinyan Chen,Renrui Zhang,Ruichuan An,Yu Qi,Dongzhi Jiang,Xiangtai Li,Manyuan Zhang,Hongsheng Li,Pheng-Ann Heng", "background": "近期的研究已经展示了视频生成模型能够生成高保真度、时间连贯性的视频，暗示这些模型可能蕴含了大量的世界知识。除了现实合成之外，这些模型还表现出具有视觉感知、建模和操纵特征的新兴行为。然而，一个关键的问题是这些视频模型是否准备好在具有挑战性的视觉推理场景中作为零样本推理器使用？", "innovation": "本文通过一个实验性研究，对当前最先进的视频生成模型Veo-3进行了一个全面的评估。引入了一个名为MME-CoF的标准基准，用于深入评估视频模型的Chain-of-Frame推理能力。研究揭示了视频模型在短时间范围内的空间一致性、精细的语义对接以及局部一致性动力学方面的良好表现，但在长时间范围内的因果推理、严格的几何约束以及抽象逻辑方面仍然存在局限。这些模型目前还不适合作为独立试题的零样本推理器，但在与专门的推理模型互补作为视觉引擎方面显示出积极的前景。", "conclusion": "当前的视频模型尽管在某些局部推理任务上表现出了积极的趋势，但在长范围的因果推理、严格的几何约束和抽象逻辑处理方面仍然存在较大的局限。这些模型尚未可靠到可以作为单个的零样本推理器使用，但通过结合专门的推理模型，它们作为视觉引擎的助力值得进一步探索和发展。"}
{"llm_update_time": "20251101", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2505.11730", "html_url": "https://arxiv.org/abs/2505.11730", "title": "重新思考计算高效测试时扩展的理想验证粒度", "title_en": "Rethinking Optimal Verification Granularity for Compute-Efficient Test-Time Scaling", "authors": "Hao Mark Chen,Guanxi Lu,Yasuyuki Okoshi,Zhiwen Mo,Masato Motomura,Hongxiang Fan", "background": "测试时缩放（TTS）已被证明能增强大型语言模型（LLMs）的推理能力。验证在TTS中起着关键作用，不仅影响推理性能，还影响计算效率，因为验证的质量和计算成本不同。现有研究主要关注验证频率的两种极端情况：仅验证最终输出或每个生成步骤，但未系统探讨验证频率介于这两者之间的各种可能。", "innovation": "作者提出了一种名为可变粒度搜索（VG-Search）的新算法，它通过一个可调节的粒度参数g，统一了传统的束搜索和Best-of-N采样。为了验证其效果，作者进行了广泛的实验，发现动态调整粒度参数g可以提高计算效率和可扩展性。基于这些发现，作者提出了适应性VG-Search策略，与束搜索相比可以提高3.1%的准确率，与Best-of-N相比可以提高3.6%的准确率，同时减少超过52%的FLOPs。", "conclusion": "通过这些发现，作者提出了一种新的适配性VG-Search策略，能够在保持甚至提高准确率的同时，大幅降低计算量。开源代码将支持未来的研究。"}
{"llm_update_time": "20251101", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2505.14970", "html_url": "https://arxiv.org/abs/2505.14970", "title": "Self-Evolving Curriculum for LLM Reasoning", "title_en": "Self-Evolving Curriculum for LLM Reasoning", "authors": "Xiaoyin Chen,Jiarui Lu,Minsu Kim,Dinghuai Zhang,Jian Tang,Alexandre Piché,Nicolas Gontier,Yoshua Bengio,Ehsan Kamalloo", "background": "强化学习（RL）已经被证明在对大型语言模型（LLMs）进行微调时效果显著，特别是在数学和代码生成领域增强了其推理能力。影响RL微调成功的关键因素之一是训练课程：训练问题的呈现顺序。虽然随机课程作为基准算法使用，但它们仍然不理想；手动设计的课程通常依赖于经验法则，而且在线过滤方法可能具有计算上的局限性。", "innovation": "本文提出了一种名为Self-Evolving Curriculum (SEC)的自动课程学习方法，该方法与RL微调过程同时学习课程策略。将课程选择公式化为非平稳多臂赌博机问题，每种问题类别（例如难度级别或问题类型）被视为单个臂。利用策略梯度方法的绝对优势作为立即学习收益的代理指标。在每个训练步骤中，课程策略选择类别以最大化此奖励信号，并使用TD(0)方法进行更新。实验结果表明，SEC显著提高了模型的推理能力，使其更好地处理更难、超出分布的测试问题，并在同时微调多个推理领域时达到了更好的技能平衡。", "conclusion": "本文的研究结果表明，SEC作为一种增强策略，对于LLMs的RL微调具有很大的前景。"}
{"llm_update_time": "20251101", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2505.18139", "html_url": "https://arxiv.org/abs/2505.18139", "title": "拥抱矛盾：理论不一致性不会阻碍构建负责任人工智能系统的道路", "title_en": "Embracing Contradiction: Theoretical Inconsistency Will Not Impede the Road of Building Responsible AI Systems", "authors": "Gordon Dai,Yunze Xiao", "background": "本文背景在于当前Responsible AI (RAI)领域中观测到的各种度量标准之间理论上的一致性问题，如不同的公平性定义或准确性与隐私之间的权衡。这些不一致性通常被视为需要消除的缺陷。", "innovation": "本文的创新在于提出应当将这些理论不一致性视为有价值的特征来接纳，而不是试图消除它们。文章提出了三个主要的好处：1. 规范多元主义：保留一套具有潜在矛盾性的度量标准，确保RAI中多样化的道德立场和利益相关者的价值得以充分反映；2. 认知完整性：使用多种，有时甚至是冲突的度量标准，可以更全面地捕捉复杂的伦理概念，从而比单一简化定义提供更多信息上的可信度；3. 隐含正则化：同时优化理论上冲突的目标可以避免对某个特定度量标准的过度拟合，驱使模型向着在现实复杂性下具有更好泛化能力和鲁棒性的解决方案发展。", "conclusion": "综上所述，作者认为加强RAI理论与实践中的机制，从停留在不一致中，转变为明确可接受的不一致性阈值，并详细解析实际中如何实现相对一致性的机制，是推进构建负责任的人工智能系统的关键。"}
{"llm_update_time": "20251101", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.21257", "html_url": "https://arxiv.org/abs/2507.21257", "title": "CompoST: 一种分析大型语言模型在QALD设置中系统性和组合性解释问题能力的基准", "title_en": "CompoST: A Benchmark for Analyzing the Ability of LLMs To Compositionally Interpret Questions in a QALD Setting", "authors": "David Maria Schmidt,Raoul Schubert,Philipp Cimiano", "background": "语言解释是组合性的过程，在这个过程中，语言结构的复杂意义是从其组成部分的意义中推断出来的。大型语言模型（LLM）具有卓越的语言解释能力，并已被成功应用于将问题映射为SPARQL查询。然而，尚不清楚这种解释过程是否系统化。", "innovation": "本文提出了一个名为CompoST的基准，旨在调查LLM解释问题的能力是否真正具有组合性。通过基于DBpedia中的图模式生成的三种不同难度级别的数据集，以及利用Lemon词汇法进行表征，CompoST基准在受控环境下创建，以测试LLM在见过原子构建块的情况下，解释复杂结构问题的能力。这种方法允许评估在不同复杂度的问题中，LLM是否能够系统并组合性地解释问题。", "conclusion": "我们的研究表明，随着模型离优化样本的偏差增大，宏观$F_1$得分从$0.45$下降到$0.09$。即使在提供所有必要信息的情况下，对于最低复杂度的数据集，$F_1$得分也没有超过$0.57$。因此，我们得出结论，LLM在系统和组合性地解释问题以及将问题映射入SPARQL查询方面存在困难。"}
{"llm_update_time": "20251101", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.18667", "html_url": "https://arxiv.org/abs/2509.18667", "title": "TERAG: Token-Efficient Graph-Based Retrieval-Augmented Generation", "title_en": "TERAG: Token-Efficient Graph-Based Retrieval-Augmented Generation", "authors": "Qiao Xiao,Hong Ting Tsang,Jiaxin Bai", "background": "Graph-based Retrieval-augmented Generation (RAG) 已成为改进大型语言模型（LLMs）推理、准确性和事实性的广泛研究方法。然而，许多现有的基于图的RAG系统在构建图过程中的大语言模型（LLM）标记使用成本较高，阻碍了大规模采用。", "innovation": "我们提出了 TERAG，这是一种简单而有效的框架，旨在以显著更低的成本构建具有信息性的图。受 HippoRAG 启发，我们在检索阶段结合了个性化PageRank (PPR)，同时仅使用 3%-11% 的输出标记就能达到广泛使用的基于图的 RAG 方法至少 80% 的准确性。", "conclusion": "TERAG 具有低标记足迹和高效的构建管道，非常适合大规模和成本敏感的部署场景。"}
{"llm_update_time": "20251101", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2505.12371", "html_url": "https://arxiv.org/abs/2505.12371", "title": "MedAgentBoard：以传统方法为基准评估多智能体协作在多元医学任务中的表现", "title_en": "MedAgentBoard: Benchmarking Multi-Agent Collaboration with Conventional Methods for Diverse Medical Tasks", "authors": "Yinghao Zhu,Ziyi He,Haoran Hu,Xiaochen Zheng,Xichen Zhang,Zixiang Wang,Junyi Gao,Liantao Ma,Lequan Yu", "background": "大型语言模型（LLMs）的快速发展激发了多智能体协作在解决复杂医疗任务方面的研究兴趣。然而，多智能体协作方法的实际优点尚未充分理解。现有的评估往往缺乏普适性，未能涵盖多样化的任务以反映真实的临床实践，并且经常忽略了与基于单一LLM的方法和传统标准方法的严格对比。为了解决这一关键差距，该研究引入了MedAgentBoard，这是一个全面的基准，用于系统评估多智能体协作、基于单一LLM和传统方法。MedAgentBoard包括四个不同的医学任务类别：（1）医学（视觉）问题回答，（2）通俗摘要生成，（3）结构化的电子健康记录（EHR）预测建模，以及（4）临床工作流程自动化，这些任务涉及文本、医学影像以及结构化的EHR数据。", "innovation": "MedAgentBoard是一个全面的基准工具，用于系统地评估多智能体协作、单一LLM和传统方法。它涵盖了四个不同的医学任务类别，包括医学（视觉）问题回答、通俗摘要生成、结构化的电子健康记录预测建模以及临床工作流程自动化。通过广泛的实验，研究人员揭示了多智能体协作在某些场景下具有特定优势，例如在临床工作流程自动化中增强任务完整性，但它们并不总是优于先进单一LLM（如文本医学QA）或专门的传统方法。这种新的基准为选择和开发医学中的AI解决方案提供了宝贵的资源和可行的洞察。", "conclusion": "多智能体协作的优势在特定情况下体现，如临床工作流程自动化中的任务完整性提高，但在其他任务（如医疗视觉问答和基于EHR的预测）中并未始终优于先进的单一LLM或专门的传统方法。MedAgentBoard强调任务特定的、基于证据的方法对于选择和开发医学中的AI解决方案的重要性，并指出多智能体协作的固有复杂性和附加量相对于实际性能提升需要谨慎权衡。所有代码、数据集、详细提示和实验结果已开源。"}
{"llm_update_time": "20251101", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.01543", "html_url": "https://arxiv.org/abs/2508.01543", "title": "Refine-n-Judge: Curating High-Quality Preference Chains for LLM-Fine-Tuning", "title_en": "Refine-n-Judge: Curating High-Quality Preference Chains for LLM-Fine-Tuning", "authors": "Derin Cayir,Renjie Tao,Rashi Rungta,Kai Sun,Sean Chen,Haidar Khan,Minseok Kim,Julia Reinspach,Yue Liu", "background": "大型语言模型（LLMs）通过基于偏好调整的微调取得了显著进步，这很大程度上依赖于基础训练数据的质量。尽管人类反馈对于提高数据质量至关重要，但它成本高昂且可扩展性不佳。", "innovation": "该论文介绍了一种名为Refine-n-Judge的自动化迭代方法，利用单个LLM作为优化者和评判者，以提升数据集的质量。与现有迭代优化方法不同，Refine-n-Judge使用LLM生成优化方案并明确评估每个改进，确保每一迭代都能够有意义地提升数据集，而无需额外的人类注释或单独的奖励模型。该方法在每一步中都对LLM的响应进行优化和评判，直至LLM更偏好最初的回答，表明不再有进一步改进。这种方法产生了质量逐步提升的偏好标注响应，非常适合用于LLM的微调。", "conclusion": "实验结果表明，使用Refine-n-Judge优化的数据集，模型在超过74%的Llama 3.1-8B和Llama 3.3-70B的对比测试中优于使用原始数据集微调的模型（GPT-4）。此外，观察到性能提升：在AlpacaEval和AlpacaEval 2.0上分别提升了5%，在MT-Bench上提升了19%。这些结果表明，Refine-n-Judge能产生高质量的数据集和可扩展的模型改进。"}
{"llm_update_time": "20251101", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.02091", "html_url": "https://arxiv.org/abs/2510.02091", "title": "剖析大型语言模型中各层在检索、知识和推理中的作用", "title_en": "Demystifying the Roles of LLM Layers in Retrieval, Knowledge, and Reasoning", "authors": "Xinyuan Song,Keyu Wang,PengXiang Li,Lu Yin,Shiwei Liu", "background": "近期研究显示，大型语言模型（LLMs）的深层层级在表示学习中的贡献较小，并且通常可以在不显著影响性能的前提下移除。但这些结论往往基于狭窄的评估范式，可能会忽略模型行为中的关键方面。", "innovation": "本文进行了系统性研究，覆盖广泛的维度，包括评估范式、任务类别和模型架构。研究发现深层层级的使用高度异质且依赖于上下文，表明在解释和压缩大型模型时需要任务、指标和模型意识。", "conclusion": "研究表明深层层级的使用高度异质且依赖于上下文。在基于似然性的评估标准下，大多数层级的修剪可以保持性能，而初始几层是关键。相比之下，在生成性评估中，中深层层级在实现推理和维持长程连贯性中起着不可或缺的作用。此外，知识和检索集中在浅层组件，而推理的准确性主要依赖于深层层级。这些结果强调了在理解和压缩大型模型时，需要任务、指标和模型意识的观点。"}
{"llm_update_time": "20251101", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.21204", "html_url": "https://arxiv.org/abs/2508.21204", "title": "模糊的、符号化的和情境性的：通过认知支架增强LLM教学", "title_en": "Fuzzy, Symbolic, and Contextual: Enhancing LLM Instruction via Cognitive Scaffolding", "authors": "Vanessa Figueiredo", "background": "本文研究了提示级别诱导偏见如何影响大型语言模型（LLMs）在教学对话中的认知行为。通过引入符号支撑方法与短期记忆方案相结合的设计，旨在促进苏格拉底式辅导中的适应性、结构化推理。文章通过使用专家设计的评分标准对五个系统变体进行控制删减，评估模型输出，以便进行系统性比较。研究初步结果显示，全系统变体持续优于基准变体。分析表明，删除记忆或符号结构会降低抽象、适应性探索和概念连续性等关键认知行为。这些发现支持了处理级解释，即提示级别的认知支架可以可靠地塑造LLMs中的新兴教学策略。", "innovation": "本文提出了一种结合符号支撑方法和短期记忆方案的方法，旨在促进大型语言模型在教学对话中的适应性、结构化推理。通过对比不同系统变体，展示了全系统变体在认知行为稳定上的优势，并通过专家设计的评分标准进行了评估。这些研究表明，记忆和符号结构对认知行为至关重要，而这些结构可以通过提示级别的认知支架在系统级重新塑造大型语言模型的教学策略。", "conclusion": "研究初步结果表明，我们的全系统变体在认知行为上持续优于基准变体。分析显示，去除记忆或符号结构会显著降低关键的认知行为。这些发现支持了在LSTM模型中，提示级别的认知支架可以塑造其教学策略的观点。该研究提供了早期实验中架构变体的可扩展和系统性比较框架。"}
{"llm_update_time": "20251101", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.18318", "html_url": "https://arxiv.org/abs/2510.18318", "title": "地球AI：利用基础模型和跨模态推理解锁地球空间洞察", "title_en": "Earth AI: Unlocking Geospatial Insights with Foundation Models and Cross-Modal Reasoning", "authors": "Aaron Bell,Amit Aides,Amr Helmy,Arbaaz Muslim,Aviad Barzilai,Aviv Slobodkin,Bolous Jaber,David Schottlander,George Leifman,Joydeep Paul,Mimi Sun,Nadav Sherman,Natalie Williams,Per Bjornsson,Roy Lee,Ruth Alcantara,Thomas Turnbull,Tomer Shekel,Vered Silverman,Yotam Gigi,Adam Boulanger,Alex Ottenwess,Ali Ahmadalipour,Anna Carter,Behzad Vahedi,Charles Elliott,David Andre,Elad Aharoni,Gia Jung,Hassler Thurston,Jacob Bien,Jamie McPike,Juliet Rothenberg,Kartik Hegde,Kel Markert,Kim Philipp Jablonski,Luc Houriez,Monica Bharel,Phing VanLee,Reuven Sayag,Sebastian Pilarski,Shelley Cazares,Shlomi Pasternak,Siduo Jiang,Thomas Colthurst,Yang Chen,Yehonathan Refael,Yochai Blau,Yuval Carny,Yael Maguire,Avinatan Hassidim,James Manyika,Tim Thelin,Genady Beryozkin,Gautam Prasad,Luke Barrington,Yossi Matias,Niv Efron,Shravya Shetty", "background": "地球空间数据具有巨大的潜力，可以用于理解我们的星球。然而，这些数据的体积巨大且多样化，分辨率、时间尺度和稀疏性各异，这给全面分析和解释带来了重大挑战。", "innovation": "本文介绍了一种新的地球AI方法，该方法结合了跨三个关键领域的基础模型（地球规模图像、人口、环境）以及由Gemini驱动的智能推理引擎。这种方法能够通过基础模型的互补价值，在地球空间推断中解锁更强的预测能力，并通过Gemini驱动的代理能够共同推断多步骤查询，从而提供关键的、及时的洞察。", "conclusion": "在新的基准测试中，代理展示了利用基础模型和大型地球空间数据源与工具的能力，证明了协同工作的优越预测能力。此外，代理在真实世界的危机场景中展示了从原始地球空间数据到实际理解之间的关键桥梁能力。"}
{"llm_update_time": "20251101", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.15030", "html_url": "https://arxiv.org/abs/2508.15030", "title": "Collab-REC: 一种基于LLM的代理框架，用于平衡旅游推荐", "title_en": "Collab-REC: An LLM-based Agentic Framework for Balancing Recommendations in Tourism", "authors": "Ashmi Banerjee,Adithi Satish,Fitri Nur Aisyah,Wolfgang Wörndl,Yashar Deldjoo", "background": "在旅游业推荐中，通常存在流行性偏差，导致推荐系统倾向于推荐热门地点而忽略了那些较少人访问的地方。为了克服这一问题，提出了Collab-REC框架，该框架采用多智能体系统，从个人化、流行性和可持续性的角度生成城市建议，确保不同的观点被综合考虑。", "innovation": "Collab-REC框架设计了一个多智能体系统，包含三个基于LLM的代理（个性化、流行性和可持续性），以及一个不基于LLM的调解者。调解者通过多轮谈判整合和改进这些建议，确保每个代理的观点都被考虑，同时防止无效或重复的响应。", "conclusion": "实验显示，与单一代理的基线相比，Collab-REC提高了多样性和整体的相关性，特别是提升了较少人访问的地点的可见性。这种平衡的方法不仅解决了过度旅游问题，还能更好地适应用户提供的限制，验证了多利益相关者协作在基于LLM的推荐系统中的潜力。"}
{"llm_update_time": "20251101", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.05014", "html_url": "https://arxiv.org/abs/2510.05014", "title": "Think Then Embed: 生成性上下文改进多模态嵌入", "title_en": "Think Then Embed: Generative Context Improves Multimodal Embedding", "authors": "Xuanming Cui,Jianpeng Cheng,Hong-you Chen,Satya Narayan Shukla,Abhijeet Awasthi,Xichen Pan,Chaitanya Ahuja,Shlok Kumar Mishra,Yonghuan Yang,Jun Xiao,Qi Guo,Ser-Nam Lim,Aashu Singh,Xiangjun Fan", "background": "当前，Universal Multimodal Embeddings (UME) 方面的研究日益增长，而模型需要生成任务特定的表示。最近的研究表明，Multimodal Large Language Models (MLLMs) 卓有成效，但这些模型通常仅被视为编码器，未能充分利用其生成能力。当指令变得复杂并需要组合推理时，这种编码方式的效果会减弱。受到有序思考推理有效性的启发，提出了一种通用的 Think-Then-Embed (TTE) 架构，由一个推理器和一个嵌入器组成。", "innovation": "通过使用强大的 MLLM 推理器，实现了 MMEB-V2 基准的最先进性能，超越了在大规模内部数据集上训练的专有模型。为了减少对大型 MLLM 推理器的依赖，采用高质量的嵌入中心化推理痕迹对小型 MLLM 推理器进行微调，在开源模型中取得最佳性能，比近期提出的方法提高了 7% 的绝对性能。研究了将推理器和嵌入器整合到统一模型中的策略，提高了效率而不牺牲性能。", "conclusion": "所提出的 TTE 架构能够通过显式的推理步骤增强对复杂多模态指令的理解。实验证明，该方法在多模态嵌入的性能方面有显著提升，并展示了在开源模型类别中的领先地位。"}
{"llm_update_time": "20251101", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.16648", "html_url": "https://arxiv.org/abs/2509.16648", "title": "FESTA: Functionally Equivalent Sampling for Trust Assessment of Multimodal LLMs", "title_en": "FESTA: Functionally Equivalent Sampling for Trust Assessment of Multimodal LLMs", "authors": "Debarpan Bhattacharya,Apoorva Kulkarni,Sriram Ganapathy", "background": "对于由多模态大型语言模型(MLLMs)生成的预测结果进行准确的信任评估是一项挑战，因为不同的多模态输入模式使得信任评估复杂性增加。精确的信任评估可以实现选择性预测并提升用户信心，然而现有的方法难以应对这些挑战。因此，本文探讨了如何通过一种新的采样技术来解决这一问题。", "innovation": "本文提出了功能等价采样信任评估（FESTA，Functionally Equivalent Sampling for Trust Assessment），这是一种用于MLLMs的多模态输入采样技术。FESTA 通过等价采样和补充采样生成不确定性测度，这种任务保持的不确定性量化采样方法扩展了输入空间，用于探测模型的一致性和敏感性。FESTA 是黑盒模型，不需要真实值（无监督），适用于各种现成的多模态 LLMs，可在视觉和听觉推理任务中获取显著提升的信任评估结果，基于受试者操作特征曲线下的面积（AUROC）检测误预测，改善了选择性预测性能，取得了 33.3%（视觉LLMs）和29.6%（音频LLMs）的相对提升。", "conclusion": "本文提出了一种新的采样技术 FESTA，该技术可以有效地评估 MLLMs 的多模态输入，通过等价采样和补充采样生成的不确定性测度，改善了选择性预测性能，并且无需真实数据和模型参数，适合现成的多模态 LLMs，在视觉和听觉推理任务中表现优秀，取得了显著的相对性能提升。"}
{"llm_update_time": "20251101", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.18477", "html_url": "https://arxiv.org/abs/2510.18477", "title": "LAFA: 基于代理的大语言模型驱动的联邦数据分析", "title_en": "LAFA: Agentic LLM-Driven Federated Analytics over Decentralized Data Sources", "authors": "Haichao Ji,Zibo Wang,Cheng Pan,Meng Han,Yifei Zhu,Dan Wang,Zhu Han", "background": "大语言模型（LLMs）在通过自然语言查询解释和生成多操作执行计划方面显示出巨大的潜力，能够在自动化数据分析任务中发挥作用。然而，现有基于LLM-代理的分析框架假定数据集中化访问，缺乏隐私保护。与此不同，联邦数据分析（FA）允许跨分布式数据源进行隐私保护的计算，但缺乏对自然语言输入的支持，并需要结构化的机器可读查询。", "innovation": "本文提出了LAFA系统，它是第一个将基于LLM-代理的数据分析与FA结合起来的系统。LAFA采用了分层多代理架构，它接受自然语言查询并将其转化为优化的、可执行的FA工作流。粗粒度的计划者首先将复杂的查询分解为子查询，而细粒度的计划者利用先验的结构知识将每个子查询映射到FA操作的有向无环图（DAG）。通过优化代理重新编写并合并多个DAG，去除冗余操作，减小计算和通信开销。实验表明，LAFA在执行计划成功率和减少数据密集型FA操作上优于基线提示策略。", "conclusion": "本研究为在FA环境中支持自然语言输入的隐私保护、LLM驱动的分析奠定了实际基础。"}
{"llm_update_time": "20251101", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.19771", "html_url": "https://arxiv.org/abs/2510.19771", "title": "超越反应性：LLM代理主动解决问题的评估", "title_en": "Beyond Reactivity: Measuring Proactive Problem Solving in LLM Agents", "authors": "Gil Pasternak,Dheeraj Rajagopal,Julia White,Dhruv Atreja,Matthew Thomas,George Hurn-Maloney,Ash Lewis", "background": "现有基于大语言模型（LLM）的代理越来越倾向于主动解决问题，而不仅仅是等待指令执行。然而，目前的评估基准存在局限性，它们仅关注局部场景，无法测试代理在利用多源信息和长时间跨度下的推理能力。因此，有必要开发新的评估方法来填补这一缺口。", "innovation": "提出了一种名为PROBE（解决瓶颈的主动解决方案）的新评估框架。PROBE将主动性的能力分解为三个核心步骤：搜索未指明的问题、识别具体的瓶颈和执行适当的解决方案。此外，该框架还展示了如何基于一致的指标评估先进的LLM和流行的代理框架，并揭示了当前代理系统自主行动的局限性。", "conclusion": "通过PROBE框架对最前沿的LLM和代理模型进行评估，结果显示GPT-5和Claude Opus-4.1分别在40%的一致性能上表现最佳。这一结果突显了代理系统的当前能力局限，并指出了未来的研究方向。"}
{"llm_update_time": "20251101", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.23925", "html_url": "https://arxiv.org/abs/2510.23925", "title": "视觉推理中的潜在逻辑链", "title_en": "Latent Chain-of-Thought for Visual Reasoning", "authors": "Guohao Sun,Hang Hua,Jian Wang,Jiebo Luo,Sohail Dianat,Majid Rabbani,Raghuveer Rao,Zhiqiang Tao", "background": "大型多模态语言模型（LVLMs）的可解释性和可靠性可以通过逻辑链（CoT）推理得到提升。然而，现有的训练算法如SFT、PPO和GRPO可能在面对未见过的推理任务时表现不佳，并且对偏见的奖励模型存在依赖。", "innovation": "作者重新定义LVLMs中的推理为后验推断，并提出了一个基于近似变分推断的可扩展训练算法。通过利用多样化寻求的强化学习算法，引入了一种新的稀疏奖励函数，以鼓励多样化的、高似然性的潜在CoT，避免了确定性采样限制并防止了奖励作弊。此外，实现了贝叶斯推理扩展策略，用边缘似然替换昂贵的‘Best-of-N’和束搜索，以高效地对最适解释和答案进行排名。", "conclusion": "实验证明，提出的算法在七个推理基准测试上提升了最先进LVLMs的有效性、泛化能力和可解释性。"}
{"llm_update_time": "20251101", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.23127", "html_url": "https://arxiv.org/abs/2510.23127", "title": "在科学LLM中迷失在分词中：将上下文作为解锁生物分子理解的关键", "title_en": "Lost in Tokenization: Context as the Key to Unlocking Biomolecular Understanding in Scientific LLMs", "authors": "Kai Zhuang,Jiawei Zhang,Yumou Liu,Hanqun Cao,Chunbin Gu,Mengdi Liu,Zhangyang Gao,Zitong Jerry Wang,Xuanhe Zhou,Pheng-Ann Heng,Lijun Wu,Conghui He,Cheng Tan", "background": "科学大语言模型（Sci-LLMs）被认为是加速生物发现的前景领域。然而，这些模型在处理原始生物分子序列时面临一个根本挑战：分词困境。当前策略将序列视为特定语言时，可能会丢失功能动机信息；作为单独模态时，会引入巨大的对齐挑战，从而限制了其推理能力。", "innovation": "论文提出了一种新的策略：为Sci-LLMs提供从现有生物信息学工具中派生的高层次结构化上下文，从而绕过了直接解释低级噪声序列数据的需求。通过系统比较领先的Sci-LLMs在生物推理任务中的表现，研究公布了三种输入模式的测试结果：仅序列、仅上下文以及两者的结合。研究结果表明，仅上下文的方法在所有其他模式中表现始终更优，甚至包括原始序列与高层次上下文的结合也会降低性能，表明原始序列充当了信息噪声。", "conclusion": "现有Sci-LLMs的主要优势并不在于从零开始解释生物分子语法的能力，而是在于其处理结构化的人类可读知识的深刻能力。因此，研究建议重新框架Sci-LLMs，将其视为强大的专家知识推理论推理引擎而非序列解码器。该作品为一种新的混合科学AI代理奠定了基础，重新定位开发重点从直接序列解释向高层次知识合成。"}
{"llm_update_time": "20251101", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.23216", "html_url": "https://arxiv.org/abs/2510.23216", "title": "在实际足球模拟中的类人类守门员：一种高效强化学习方法", "title_en": "Human-Like Goalkeeping in a Realistic Football Simulation: a Sample-Efficient Reinforcement Learning Approach", "authors": "Alessandro Sestini,Joakim Bergdahl,Jean-Philippe Barrette-LaPierre,Florian Fuchs,Brady Chen,Michael Jones,Linus Gisslén", "background": "尽管一些知名视频游戏曾作为深度强化学习（DRL）的试验平台，但在游戏行业中使用该技术来创造真实的AI行为仍然很少。先前的研究侧重于通过大型模型训练超人类代理，这对于资源有限的游戏工作室来说并不实用。他们通常需要训练人类似的行为的代理。本文提出了一种适用于工业环境，特别是视频游戏行业的高效样本强化学习方法。该方法通过利用预先收集的数据和增加网络的灵活性来提高价值基DRL的样本效率。研究人员在EA SPORTS FC 25中测试了该方法，这是一种目前销售最好的足球模拟游戏之一，结果显示，方法生成的守门员在扑救球的准确率上比游戏中内置的AI提高了10%。", "innovation": "本文提出了一种适用于工业环境的高效样本强化学习方法，该方法通过利用预先收集的数据和增加网络的灵活性来改进基于价值的DRL的样本效率。方法能比标准DRL方法更快地训练50%的代理人。此外，领域专家的定性评估表明，该方法生成的代理比手工制作的代理更具人类似的行为。这种方法已在系列最新版本中采用。", "conclusion": "该方法在EA SPORTS FC 25中的测试结果表明，这种方法能训练出比内置AI更高效且更接近人类行为的守门员。这显示了该方法在实际游戏开发中的实际应用潜力和重要性，同时也提升了游戏中的AI水平，使之更加接近真实世界的玩家体验。"}
{"llm_update_time": "20251101", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2305.17608", "html_url": "https://arxiv.org/abs/2305.17608", "title": "大型语言模型对齐中的奖励崩溃现象", "title_en": "Reward Collapse in Aligning Large Language Models", "authors": "Ziang Song,Tianle Cai,Jason D. Lee,Weijie J. Su", "background": "大型语言模型（如ChatGPT和GPT-4）的强大功能部分得益于通过奖励模型与人类偏好对齐，其中人类偏好通常表示为响应提示的排名。现有研究中，这个排名方法在最终训练阶段导致了相同的奖励分布，不论提示内容如何。这种现象称为‘奖励崩溃’，它使得生成不同类型提示条件下的奖励分布变得困难。", "innovation": "本文揭示了奖励崩溃的根本原因是基于排名的目标函数在优化过程中未能有效考虑提示相关信息。通过理论分析得出了适用于一系列用例的闭式奖励分布表达式。文章提出了一个提示感知的优化方案，能够在插值区间内在理论上保证提示依赖的奖励分布。", "conclusion": "实验结果表明，所提出的提示感知的激励函数在奖励模型训练过程中显著缓解了奖励崩溃现象。"}
{"llm_update_time": "20251101", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.23595", "html_url": "https://arxiv.org/abs/2510.23595", "title": "Multi-Agent Evolve: LLM Self-Improve through Co-evolution", "title_en": "Multi-Agent Evolve: LLM Self-Improve through Co-evolution", "authors": "Yixing Chen,Yiding Wang,Siqi Zhu,Haofei Yu,Tao Feng,Muhan Zhang,Mostofa Patwary,Jiaxuan You", "background": " reinforcement learning (RL) 在提升大型语言模型（LLMs）的推理能力方面显示出巨大潜力，但其成功依赖于人工标注的数据集和可验证的奖励，这限制了RL在LLMs中的可扩展性和普适性。自我对弈RL方法，灵感来源于游戏和围棋的成功，旨在通过LLMs的自我对弈来提升它们的推理能力，而不需要人工标注的数据。然而，当前这些方法主要依赖于一个具体的环境提供反馈（如Python解释器或游戏引擎），扩展到更广泛的领域仍然具有挑战性。", "innovation": "我们提出了Multi-Agent Evolve (MAE)框架，旨在使LLMs能够在解决多种任务（包括数学、推理和常识问答）时自我进化。MAE的核心设计基于由单一LLM实例化的三个互动代理（Proposer, Solver, Judge），并通过强化学习优化它们的行为。Proposer生成问题，Solver尝试解答，Judge评估并共同进化。实验证明，MAE在Qwen2.5-3B-Instruct上的多个基准测试中平均提升了4.54%，说明其是一种高效的数据驱动方法，能够显著提升LLMs的普适推理能力，同时减少了对人工标注监督的依赖。", "conclusion": "MAE框架提供了一种新的方法，使LLMs能够在无需大量人工干预的情况下进行自我改进和进化，实现了跨多种任务的普适推理能力提升，展示了其作为增强LLMs通用推理能力的潜在规模和效率。"}
{"llm_update_time": "20251101", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2405.09086", "html_url": "https://arxiv.org/abs/2405.09086", "title": "基于TD3的混沌强化学习", "title_en": "Chaos-based reinforcement learning with TD3", "authors": "Toshitaka Matsuki,Yusuke Sakemi,Kazuyuki Aihara", "background": "在混沌基于强化学习（CBRL）中，代理内部的混沌动力学驱动探索。然而，先前的研究并未充分开发学习算法，也没有将最近的强化学习进展纳入其中。", "innovation": "该研究将最先进的深度强化学习算法之一——双重延迟深度确定性策略梯度（TD3）引入CBRL。实验结果提供了几个见解：TD3作为CBRL的学习算法在简单的目标追寻任务中工作良好；带有TD3的CBRL代理可以随着学习进展自主抑制探索行为，在环境变化时恢复探索；研究还发现，代理的混沌性对学习的效果存在一个合适的混沌强度范围，以灵活切换探索和利用，并适应环境变化。", "conclusion": "TD3可以作为CBRL的一个有效学习算法，并且能够通过调整混沌性来适应环境变化。"}
{"llm_update_time": "20251101", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2406.05948", "html_url": "https://arxiv.org/abs/2406.05948", "title": "Chain-of-Scrutiny: 检验攻击以检测大型语言模型中的后门攻击", "title_en": "Chain-of-Scrutiny: Detecting Backdoor Attacks for Large Language Models", "authors": "Xi Li,Ruofan Mao,Yusen Zhang,Renze Lou,Chen Wu,Jiaqi Wang", "background": "大型语言模型（LLMs），尤其是通过API访问的LLMs，展示了在众多领域的出色能力。然而，缺乏技术背景的用户常常依赖不可靠的第三方服务，如提示工程技术，来提升他们的LLM体验，这为恶意后门攻击敞开了大门。后门受控的LLM会在输入包含特定“触发器”时生成恶意输出。传统的防御策略针对小规模模型设计，对API访问的LLMs来说 impractical，因为存在模型访问限制、计算成本高以及数据需求大等问题。", "innovation": "本文提出Chain-of-Scrutiny (CoS)，利用LLMs独有的推理能力来对抗后门攻击。CoS引导LLM对给定输入生成推理步骤，并审查这些步骤与最终输出的一致性，不一致意味潜在攻击。CoS特别适合流行的仅API部署LLMs，能以极低的成本和少量数据实现检测，非专业用户也易于上手且保持透明。", "conclusion": "我们通过在多种任务和LLMs上进行广泛实验验证了CoS的有效性，结果显示CoS在更强大、更复杂的LLMs上提供了更大的显著优势。"}
{"llm_update_time": "20251101", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2409.06263", "html_url": "https://arxiv.org/abs/2409.06263", "title": "Speak & Spell: LLM-Driven Controllable Phonetic Error Augmentation for Robust Dialogue State Tracking", "title_en": "Speak & Spell: LLM-Driven Controllable Phonetic Error Augmentation for Robust Dialogue State Tracking", "authors": "Jihyun Lee,Solee Im,Wonjun Lee,Gary Geunbae Lee", "background": "对话状态跟踪（DST）是任务型对话系统的关键部分，用于识别对话中的重要信息。然而，在口语对话环境中，由于自动语音识别（ASR）系统的命名实体错误，DST的准确性显著下降。", "innovation": "提出了一种simple yet effective（简单而有效的）数据增强方法，旨在通过关键词突出显示的提示引入音似错误的可控音素错误，以提高DST模型的鲁棒性。该方法生成足够的音素错误模式，特别是在噪声和ASR低准确性环境中，提高了准确率。", "conclusion": "该方法通过引入可控的音素错误，生成了足够的错误模式，从而在噪声和低准确率的ASR环境中提高了DST的准确性。"}
{"llm_update_time": "20251101", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2407.17489", "html_url": "https://arxiv.org/abs/2407.17489", "title": "AI的社交力场：重叠人类-AI团队中的分布式认知", "title_en": "AI's Social Forcefield: Reshaping Distributed Cognition in Human-AI Teams", "authors": "Christoph Riedl,Saiph Savage,Josie Zvelebilova", "background": "AI不仅在团队协作中是一个中立的工具，它积极重新塑造了合作中的社会和认知结构。研究探讨了人类与AI在分布式认知中的统一框架，以及AI生成的语言对人类行为和思维的影响。", "innovation": "该研究提出了人类-AI团队中的统一框架，揭示了AI如何通过与人类协作构建共享的认知空间，进而改变人们的语言表达、思维模式、注意力焦点及人际互动方式。这一发现强调了AI作为一种具有社会影响力的参与者参与协作时的双重影响：一方面促进高效的协作，另一方面也可能侵蚀知识多样性并破坏自然的协调过程。", "conclusion": "研究指出需要重新思考AI在团队中的作用，并呼吁新的设计范式，强调透明性、可控制性和团队层面动态，以促进负责、高效的AI与人类合作。"}
{"llm_update_time": "20251101", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2406.08525", "html_url": "https://arxiv.org/abs/2406.08525", "title": "神经网络中正性条件的数学证明及其在部分单调性和可信AI中的应用", "title_en": "A mathematical certification for positivity conditions in Neural Networks with applications to partial monotonicity and Trustworthy AI", "authors": "Alejandro Polo-Molina,David Alfaya,Jose Portela", "background": "人工神经网络(ANNs)已成为建模大规模数据集中复杂关系的强大工具。然而，其黑盒性质引发了信任性挑战。在某些情况下，确保预测的信任可能需要遵循特定的部分单调性约束。然而，验证一个已经训练好的ANN是否部分单调极具挑战性。因此，ANNs在需要部分单调性的关键应用中，如信用评分，往往被忽视。", "innovation": "本文提出了一个新的算法（LipVor），该算法基于有限次数的评估，用于认证一个黑盒模型（如ANN）的正性。通过Lipschitzianity的特性，构造了在该点附近函数仍然保持正性的特定邻域。基于所评估点的Voronoi图，提出了一个认证条件，判断函数在域上是否为正。与现有方法不同，该方法在不需要受约束的架构或分段线性激活的情况下，也可以认证部分单调性。该工作开拓了在一些关键领域使用非约束型ANN的可能性，并且由于也可以将神经网络的凸性等属性转化为正性条件，LipVor还可以应用于更广泛的场景。", "conclusion": "LipVor能够在不依赖于特定架构或线性激活的情况下，识别神经网络是否满足部分单调性等正性条件，为一部分需要可靠性和信任的AI应用中进一步使用神经网络提供了可能性。"}
{"llm_update_time": "20251101", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2412.17883", "html_url": "https://arxiv.org/abs/2412.17883", "title": "捍卫事后解释方法", "title_en": "In Defence of Post-hoc Explainability", "authors": "Nick Oh", "background": "本文讨论了事后解释方法在机器学习领域中作为科学知识生产工具的有效性。这些方法受到可靠性及认识论地位方面的批评。", "innovation": "本文提出了一个基于中介理解和局限性真知论的哲学框架，证明了即使不寻求完全机械透明度，通过结构化解释模型行为也可以产生科学洞察，但需要承认解释的近似性并进行严格的实证验证。", "conclusion": "通过分析生物医学中的机器学习应用，本文展示了当事后解释方法被正确整合到科学实践中时，它们能产生新的假设并促进现象的理解。"}
{"llm_update_time": "20251101", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2403.08788", "html_url": "https://arxiv.org/abs/2403.08788", "title": "VerifIoU - 目标检测鲁棒性验证", "title_en": "VerifIoU - Robustness of Object Detection to Perturbations", "authors": "Noémie Cohen,Mélanie Ducoffe,Ryma Boumazouza,Christophe Gabreau,Claire Pagetti,Xavier Pucel,Audrey Galametz", "background": "当前对象检测模型在实际应用中的鲁棒性验证主要依赖于基于抽象解读的方法，如传统的边界框交并比（Intersection over Union, IoU）方法。这些方法通常在确保模型准确性和稳定性方面存在不足。本文提出了一种新型的区间边界传播（Interval Bound Propagation, IBP）方法，用于正式验证对象检测模型，特别是针对IoU度量。该方法已开源，并与流行的基于抽象解读的验证工具兼容。其验证方法已经在接近跑道着陆检测和手写数字识别案例研究中得到评估。与基线（纯IBP IoU）进行的比较表明，IBP IoU在保证准确性和稳定性方面具有更佳性能，有助于提高机器学习应用的安全性和鲁棒性。", "innovation": "本文提出了一种新型区间边界传播（IBP）方法，用于对象检测模型的正式验证，特别是针对IoU度量。该方法已在开源代码IBP IoU中实现，并与流行的抽象解读工具兼容，提高了目标检测模型的鲁棒性和稳定性，有助于机器学习应用的安全性提升。", "conclusion": "IBP IoU方法在确保目标检测模型的准确性和稳定性方面表现出优越性，提升了机器学习应用的安全性和鲁棒性。"}
{"llm_update_time": "20251101", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2410.12869", "html_url": "https://arxiv.org/abs/2410.12869", "title": "使用多个弱评估器的语言模型偏好评估", "title_en": "Language Model Preference Evaluation with Multiple Weak Evaluators", "authors": "Zhengyu Hu,Jieyu Zhang,Zhihan Xiong,Alexander Ratner,Kaize Ding,Ranjay Krishna", "background": "尽管大型语言模型（LLMs）取得了显著的成功，但在评估模型输出的质量时，如何根据偏好进行评价仍然是一个关键挑战。现有的方法通常使用一个强大的LLM作为裁判来两两比较LLM的响应，但这种方法容易受到循环偏好的影响，即A比B好，B比C好，但C又比A好，这会导致矛盾的评估结果。", "innovation": "本研究提出了PGED（偏好图集成与去噪）方法，这是一种新颖的方法，通过利用多个基于模型的评估器来构建偏好图，并对这些图进行集成和去噪，以获得无循环、无矛盾的评估结果。这种方法为企业提供了一种理论上的保证，展示了它在恢复真实偏好结构方面的有效性。广泛的实验表明，PGED在三种应用中展现了优越性：1）评价中的模型排名；2）测试时的响应选择；3）模型微调的数据选择。值得注意的是，PGED使用了小型LLM评估器（如Llama3-8B、Mistral-7B、Qwen2-7B）来战胜强大的评估器（如Qwen2-72B），这展示了其在提高评估可靠性和提升模型性能方面的有效性。", "conclusion": "PGED方法通过使用多个小型的LLM评估器，在多种应用中证明了其优越性，不仅能够恢复真实的偏好结构，还在评估可靠性和模型性能提升方面表现得优于单一的强评估器。"}
{"llm_update_time": "20251101", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2410.12652", "html_url": "https://arxiv.org/abs/2410.12652", "title": "受限后验采样：具有硬约束的时间序列生成", "title_en": "Constrained Posterior Sampling: Time Series Generation with Hard Constraints", "authors": "Sai Shankar Narasimhan,Shubhankar Agarwal,Litu Rout,Sanjay Shakkottai,Sandeep P. Chinchali", "background": "生成具有真实感的时间序列样本对于压力测试模型和通过使用合成数据保护用户隐私至关重要。在工程和安全关键型应用中，这些样本必须满足特定的、领域特定的或自然由物理或自然环境施加的硬约束。例如，在产生满足峰值需求时间约束的电力需求模式时，可以用于压力测试在恶劣天气条件下电力网络的运行。现有的生成受约束时间序列的方法要么不具备可扩展性，要么会降低样本质量。为了解决这些挑战，我们介绍了一种基于扩散的采样算法——受限后验采样(CPS)，该算法旨在在每次去噪更新后将后验均值估计投影到约束集。CPS可以应用于大量的约束（约100个），无需额外的训练即可实现这一目标。我们提供了理论依据，以突出我们的投影步骤对采样的影响。实验结果表明，CPS在样本质量和与实际时间序列相似性方面分别比最先进的方法高出约70%和22%。这两个结果反映了CPS在处理具有硬约束的时间序列生成方面的优势。", "innovation": "我们引入了一种新型的基于扩散的采样算法——受限后验采样（CPS），该算法能够处理大量的硬约束（约100个）而无需额外训练。CPS通过在每次去噪更新后将后验均值估计投影到约束集中，确保生成的时间序列满足所有硬约束。CPS在样本质量和与真实数据的相似度方面显著优于现有方法，特别是在处理真实世界的数据集（如股票、交通和空气质量）时。", "conclusion": "我们提出了一种新的受限后验采样（CPS）算法，该算法能够高效且准确地生成满足各种硬约束的时间序列样本。与现有方法相比，CPS在保持良好样本质量的同时，显著提高了生成效率和样本的现实感。这对于解决工程和安全关键型应用中的时间序列生成问题具有重要意义。"}
{"llm_update_time": "20251101", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2502.04380", "html_url": "https://arxiv.org/abs/2502.04380", "title": "多样性作为奖励：在未确定领域的数据混合上微调LLM", "title_en": "Diversity as a Reward: Fine-Tuning LLMs on a Mixture of Domain-Undetermined Data", "authors": "Zhenqing Ling,Daoyuan Chen,Liuyi Yao,Qianli Shen,Yaliang Li,Ying Shen", "background": "大型语言模型（LLMs）通过使用多样化的数据集进行微调可以提高其在各种领域的整体性能。现有的方法往往难以处理缺失、不精确或未规范化域标签的数据，而基于数据选择的方法又难以在多领域之间取得平衡。", "innovation": "本文提出了一种新的方法，通过赋予LLM双重身份——输出模型用于认知性地探索和根据多样性奖励选择数据，输入模型则使用选定的数据进行调整。这种方法在多种高级LLM上进行了实验，证明了在未确定领域的数据和一系列基础下游任务中的显著性能提升。同时，它还揭开了数据多样性的理解，并促进了反馈驱动的数据-模型联合设计的发展。", "conclusion": "通过提出的用于多样性的奖励的LLM微调方法，显著提升了领域未定数据及一系列基础下游任务的性能。希望我们的研究能促进对多样性的理解，并推进反馈驱动的数据-模型联合设计。"}
{"llm_update_time": "20251101", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2501.05783", "html_url": "https://arxiv.org/abs/2501.05783", "title": "UV-Attack: Physical-World Adversarial Attacks for Person Detection via Dynamic-NeRF-based UV Mapping", "title_en": "UV-Attack: Physical-World Adversarial Attacks for Person Detection via Dynamic-NeRF-based UV Mapping", "authors": "Yanjie Li,Kaisheng Liang,Bin Xiao", "background": "近年来，针对人体检测器的对抗攻击使用补丁或静态3D模型基纹理修改，由于人体运动的灵活性，成功率相对较低，特别是当涉及各种动作引起的3D变形建模时，存在重大挑战。动态NeRF在动态人体建模方面的最新进展为新的可能性打开了大门。", "innovation": "本文提出了一种名为UV-Attack的创新方法，即使在多种且未见过的人类动作下也能实现高成功率。这种方法利用基于动态NeRF的UV映射生成跨动作和视角的人类图像，甚至通过从SMPL参数空间采样产生新的动作。UV-Attack通过生成UV图而非RGB图像并修改纹理堆栈，实现了实时纹理编辑，提高了对抗攻击的实际操作性。此外，提出了一种新型的姿势变换期望损失（EoPT）来提高未见过的姿势和视角的逃避免辑成功率。实验表明，UV-Attack在动态视频设置中针对FastRCNN模型的攻击成功率高达92.7%，显著优于前最佳的AdvCamou攻击，后者在未见过的姿势和视角下的攻击成功率仅为28.5%。在无标签设置中，UV-Attack以YOLOv8检测器为目标，实现了49.5%的攻击成功率。", "conclusion": "本文的工作突显了基于动态NeRF的UV映射在提高人体检测器对抗攻击有效性方面的潜力，解决了建模人体运动和纹理修改的关键挑战。"}
{"llm_update_time": "20251101", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2410.14879", "html_url": "https://arxiv.org/abs/2410.14879", "title": " Vital Insight: 使用可视化和人工循环LLM辅助专家进行多模态个人跟踪数据的上下文驱动感知", "title_en": "Vital Insight: Assisting Experts' Context-Driven Sensemaking of Multi-modal Personal Tracking Data Using Visualization and Human-In-The-Loop LLM", "authors": "Jiachen Li,Xiwen Li,Justin Steinberg,Akshat Choube,Bingsheng Yao,Xuhai Xu,Dakuo Wang,Elizabeth Mynatt,Varun Mishra", "background": "在现代普遍计算研究中，被动跟踪方法（如手机和可穿戴设备传感）已成为监测人类行为的主要技术。尽管已经取得了显著的进步，将原始传感器数据转换为刹那间行为模型（如物理活动识别）的技术，但在将这些传感数据转化为有意义的高层次上下文感知洞察方面仍然存在显著差距，这些洞察对于各种应用（如总结个人的日程安排）是必不可少的。为了弥合这个差距，专家通常需要在实地研究中使用上下文驱动的感知推理过程来获取见解，但这一过程往往需要大量的手动努力，并且即使对于经验丰富的研究人员来说也很具有挑战性，尤其是面对复杂的人类行为时。我们通过三轮用户研究与21名专家合作，探索解决感知推理挑战的解决方案。我们遵循以用户为中心的设计过程来识别需求，并设计、迭代、构建和评估了一个名为Vital Insight (VI)的新型LLM辅助原型系统，该系统能够实现人工循环推理和多模态手机和穿戴设备被动传感数据的可视化。通过使用原型作为技术试验棒，我们观察了专家与其的交互，并开发了一个专家感知模型，该模型解释了专家如何在直接数据表示和AI支持的推理之间切换，以探索、质疑和验证见解。通过这一迭代过程，我们还综合并讨论了一组关于未来增强型可视化系统设计的建议，这些系统能够更好地协助专家在多模态健康传感数据中的感知过程。", "innovation": "提出了一个名为Vital Insight (VI)的新型LLM辅助原型系统，能够实现人工循环推理和多模态手机和穿戴设备被动传感数据的可视化，通过专家感知模型解释了专家在直接数据表示和AI支持推理之间的切换过程。此外，还提出了一组关于未来增强型可视化系统设计的建议，以更好地协助专家在多模态健康传感数据中的感知过程。", "conclusion": "通过使用Vital Insight系统，专家可以在多模态健康传感数据中进行高效的数据感知和推理，促进自动化和人类迭代的结合。未来的研究可以深入了解如何进一步增强此类系统的性能和实用性。"}
{"llm_update_time": "20251101", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2503.00333", "html_url": "https://arxiv.org/abs/2503.00333", "title": "更多的同质性：在增加代表性的背景下持续的代表性伤害", "title_en": "More of the Same: Persistent Representational Harms Under Increased Representation", "authors": "Jennifer Mickel,Maria De-Arteaga,Leqi Liu,Kevin Tian", "background": "为了识别和减轻生成AI系统的危害，重要的是要考虑AI系统输出中代表的人群以及人们是如何被代表的。简单地改善代表性并不意味着已经采取了必要的偏见缓解措施。该研究通过分析最先进的语言模型中的性别代表性在职业中的变化，发现尽管存在增加女性代表性的努力，但仍有持续性的代表性伤害、刻板印象和自由主义理想在产生.", "innovation": "该研究通过深入分析先进语言模型中的性别职业代表性变化，揭示了尽管存在增加女性代表性的努力，却仍然存在着持续的代表性伤害、刻板印象和自由主义理想。这项研究强调了仅仅增加代表性不足以解决根本性的代表性问题，需要进一步进行偏见缓解的努力.", "conclusion": "研究结果表明，在增加代表性的同时，并不能保证消除所有的代表性伤害。尽管女性在某些方面的代表性有所增加，但这种增加并未带来实质性改变，刻板印象和自由主义理想仍然存在。因此，需要更深入地分析和采取措施来解决根本性的代表性问题，而不仅仅是增加代表性."}
{"llm_update_time": "20251101", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2503.02631", "html_url": "https://arxiv.org/abs/2503.02631", "title": "从人机协作视角看生成式AI时代的数据讲故事工具反思", "title_en": "Reflection on Data Storytelling Tools in the Generative AI Era from the Human-AI Collaboration Perspective", "authors": "Haotian Li,Yun Wang,Huamin Qu", "background": "近年来，人机协作工具在数据讲故事领域引起了广泛关注，旨在降低专业门槛并优化工作流程。尤其是在大模型生成AI技术方面（如大规模语言模型和文本转图像模型）的进步，让数据讲故事得以通过其视觉和叙述生成的能力得到增强。自这些技术公开发布两年以来，回顾它们的应用进展并展望未来机会显得尤为重要。", "innovation": "本文利用一个专有的框架来对比最新工具与早期工具的人机协作模式。通过对比，识别出屡被研究的模式（如人类创作者+AI助手）和新兴模式（如AI创作者+人类审稿人）。此外还揭示了这些AI技术带来的好处以及对人机协作的潜在影响，并提出了未来方向的建议。", "conclusion": "通过对比分析，本文确认了人机协作模式的发展趋势，并对未来提供了见解性的方向，旨在激发创新。"}
{"llm_update_time": "20251101", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2502.09969", "html_url": "https://arxiv.org/abs/2502.09969", "title": "用于指令微调数据可学习且可扩展的影响力估计的神经网络", "title_en": "Neural Networks for Learnable and Scalable Influence Estimation of Instruction Fine-Tuning Data", "authors": "Ishika Agarwal,Dilek Hakkani-Tür", "background": "影响函数为模型训练提供关键见解，但现有方法存在计算成本高和泛化能力有限的问题。特别是，最近的工作提出了一些使用语言模型计算数据影响的度量和算法，但由于计算所需的昂贵的前向和反向传递、存储大规模模型所需的大量内存要求以及对新数据影响估计的泛化能力差，这些方法在大规模模型和数据集上并不适用。", "innovation": "本文探索了使用小型神经网络（我们称之为InfluenceNetwork）来估计影响值的方法，实现了近99%的成本降低。与全语言模型相比，所用模型的规模仅为0.0027%，并且我们在指令微调的子集选择任务中应用了该算法（称为NN-CIFT：用于高效指令微调的神经网络）。我们的研究结果表明，即使有较大加速，NN-CIFT与原始影响函数相比也未妥协性能，并提供了NN-CIFT的深入超参数分析。", "conclusion": "我们的研究表明，使用小型神经网络可以有效估计影响值，而不会牺牲性能，并且该方法在指令微调的子集选择任务中表现良好。此外，我们提供了一种深入的超参数分析，并提供了方法的代码。"}
{"llm_update_time": "20251101", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2503.02878", "html_url": "https://arxiv.org/abs/2503.02878", "title": "语言模型可以自我提升以在状态价值估计方面更好地进行搜索", "title_en": "Language Models can Self-Improve at State-Value Estimation for Better Search", "authors": "Ethan Mendes,Alan Ritter", "background": "在多步推理任务中，收集地面真理奖励或人类演示往往成本极高，尤其是在像网页任务这样的交互领域。为了降低成本，本文提出了Self-Taught Lookahead (STL) 框架，通过明确地预测状态转换，来改进基于语言模型的价值函数。", "innovation": "STL 允许语言模型模仿价值迭代算法中的逐个推理步骤，通过模拟自然语言步骤来预测下一动作及其结果状态和价值的理由，从而无需任何标注数据即可改善价值估计。通过进行自我监督训练，该框架能产生更准确的状态价值预测，这反过来又使轻量级搜索算法能够在保持高性能的同时，搜索更少的状态。文章还表明，STL 能够在网页智能体等具体应用场景中显著提升目标达成率，并且还适用于多跳跃问答和数学谜题。特别指出，STL 使得小型开源模型能够指导高效搜索过程，通过将显式推理与价值学习相结合进一步降低推理成本。", "conclusion": "使用中等规模（80亿参数）开放权重语言模型训练的 STL 能够提升网页智能体的成功率高达 39%，并达到了与专有模型相当的性能。STL 还展示了在多步骤推理应用中的泛化能力。"}
{"llm_update_time": "20251101", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2503.09499", "html_url": "https://arxiv.org/abs/2503.09499", "title": "MindGYM：思考中心微调中问题合成的关键因素？", "title_en": "MindGYM: What Matters in Question Synthesis for Thinking-Centric Fine-Tuning?", "authors": "Zhe Xu,Daoyuan Chen,Zhenqing Ling,Yaliang Li,Ying Shen", "background": "大型基础模型在获得可迁移的、结构化思维能力方面面临挑战，特别是在使用严格的模板或群体标注指令数据集进行监督时。先前的方法通常依赖于固定模板或人工标注数据，而忽略了模型自身的认知过程对问题生成的影响。", "innovation": "本文提出了MindGYM，这是一种以思维为中心的数据合成框架，它通过自生成、认知引导的数据来使模型能够进化。MindGYM包括三个关键组成部分：（1）认知思维过程注入，通过注入高层次的推理目标来塑造模型的合成行为；（2）种子单跳疑问合成，生成来自多种语义类型的原子问题以鼓励更广泛的思考；（3）具有问题种子的挑战性多跳QA合成，根据QA种子构建更复杂的多跳问题以进行更深层次的推理。实验结果显示，使用该方法生成的合成数据在平均质量和质量变异方面分别比基础数据源高出16.7%和降低67.91%，突显了高质量和自我包含数据对于有效的、思考导向的微调的重要性。MindGYM仅使用400个数据样本就在MathVision基准测试中获得了高达16%的性能提升，并在不同模型大小和架构上实现了可推广的改进，强调了自我挑战机制在提高大型模型能力方面的有效性，同时减少了人力干预和资源需求。", "conclusion": "MindGYM证明了自我挑战机制在提高大型模型能力的有效性，同时减少了人类干预和资源需求，并且通过内部推理能力驱动的自我进化的基础模型数据为中心的研究代码和数据已对外开放。"}
{"llm_update_time": "20251101", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2503.20138", "html_url": "https://arxiv.org/abs/2503.20138", "title": "通过利用中心化数据细化去中心化模型进行引导模型合并：在混合数据学习中的应用", "title_en": "Guided Model Merging for Hybrid Data Learning: Leveraging Centralized Data to Refine Decentralized Models", "authors": "Junyi Zhu,Ruicong Yao,Taha Ceritli,Savas Ozkan,Matthew B. Blaschko,Eunchung Noh,Jeongwon Min,Cho Jung Min,Mete Ozay", "background": "当前的网络训练范式主要集中在中心化或去中心化的数据制度上。但是，在实践中，数据可用性往往表现出混合性质，同时存在这两种制度。这种混合环境为模型训练提供了新的机会，因为这两种制度各有优势：去中心化的数据丰富但异质性和通信限制较多，而中心化的数据尽管数量有限且可能代表性不足，但便于管理和提供高吞吐量访问。尽管有这些潜在优势，有效地结合这两种范式仍具有挑战性，且没有多少框架针对混合数据制度进行定制。", "innovation": "本文提出了一种新颖的框架，该框架从去中心化的模型构建模型集，并利用中心化的数据在该结构化的空间内精炼全局模型。精炼后的模型再被用于重新初始化去中心化的模型。方法结合了联邦学习（利用去中心化数据）和模型合并（利用中心化数据），在混合数据可用性下实现了有效的训练。理论分析表明，由于合并过程中的方差减少，我们的方法比仅依赖去中心化数据的方法收敛更快。广泛实验表明，我们的框架在纯中心化、纯去中心化和现有可适应混合的方法中表现更优。值得注意的是，即使中心化和去中心化数据域不同或去中心化数据包含噪声，我们的方法依然保持稳健。", "conclusion": "我们的框架在多种条件下表现出色，并且具有广泛的应用潜力。"}
{"llm_update_time": "20251101", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2504.01001", "html_url": "https://arxiv.org/abs/2504.01001", "title": "零样本基准测试：一种用于自然语言模型灵活和可扩展的自动评估框架", "title_en": "Zero-shot Benchmarking: A Framework for Flexible and Scalable Automatic Evaluation of Language Models", "authors": "José Pombal,Nuno M. Guerreiro,Ricardo Rei,André F. T. Martins", "background": "随着语言模型功能增强并能在多模态中执行更复杂的任务，自动评估它们变得日益困难。开发强健的、针对特定任务的自动度量标准变得越来越困难，而创建人类标注的测试集成本高昂，且迅速饱和。因此，一个有吸引力的替代方案是设计可靠的策略来自动化测试数据的生成和评估过程。然而，之前的尝试要么依赖于现有的数据集，要么仅针对单一任务。由此提出了零样本基准测试（ZSB）框架，通过利用语言模型进行合成测试数据生成和评估，来为任何任务创建高质量的基准。", "innovation": "ZSB框架简化且灵活：只需生成数据生成和评估的提示；可扩展至昂贵或不实际收集真实世界数据的任务和语言；模型无关，随着模型的进步，可创建更具挑战性的基准。通过在五种文本任务和一个多模态任务中的应用，以及对各种开放和封闭系统的排名，展示了ZSB的有效性，其表现优于广泛使用的标准基准。通过消融实验发现，使用开放模型可以创建强基准，而评价模型大小和数据集多样性是关键驱动因素。", "conclusion": "我们发布了所有基准和实验代码，以生成新基准。ZSB框架能够有效地、自动地评估自然语言模型，提供了一种方便的、可扩展的方法来创建高质量的基准测试。"}
{"llm_update_time": "20251101", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2504.04953", "html_url": "https://arxiv.org/abs/2504.04953", "title": "M-Prometheus: 一套开源多语言LLM评判者", "title_en": "M-Prometheus: A Suite of Open Multilingual LLM Judges", "authors": "José Pombal,Dongkeun Yoon,Patrick Fernandes,Ian Wu,Seungone Kim,Ricardo Rei,Graham Neubig,André F. T. Martins", "background": "语言模型用于自动评估长文本（LLM-as-a-judge）的应用日益广泛，但大多数LLM评判者仅针对英语进行优化，增强其多语种评估能力的策略在现有文献中鲜有探讨。这导致非英语语言的自动评估方法质量参差不齐，最终阻碍了多语言模型发展的步伐。", "innovation": "本文引入M-Prometheus，这是一种参数范围从3亿到14亿的开源多语言LLM评判者，能够提供直接评估和成对比较反馈。M-Prometheus模型在超过20种语言的多语言奖励基准测试中表现出色，以及在4种语言对的文学机器翻译评估中表现优异。此外，M-Prometheus模型在解码时可以显著提高所有3种测试语言的生成输出质量，展示了其在开发更好多语言模型中的应用价值。通过大规模的消融试验，我们确定了实现有效多语言评判者的关键因素，包括选择骨干模型以及使用合成多语言反馈数据而非翻译数据进行训练。", "conclusion": "M-Prometheus模型在多语言奖励基准测试和文学机器翻译评估中均表现出色，能够显著提升不同语言的生成输出质量，为开发更好的多语言模型提供了工具和支持。"}
{"llm_update_time": "20251101", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2505.12191", "html_url": "https://arxiv.org/abs/2505.12191", "title": "Ditch the Denoiser: Emergence of Noise Robustness in Self-Supervised Learning from Data Curriculum", "title_en": "Ditch the Denoiser: Emergence of Noise Robustness in Self-Supervised Learning from Data Curriculum", "authors": "Wenquan Lu,Jiaqi Zhang,Hugues Van Assel,Randall Balestriero", "background": "自监督学习（SSL）已成为从未标注数据中提取丰富表示的强大解决方案。然而，大多数SSL研究集中在干净、整理过的高质量数据集上。因此，在嘈杂数据上应用SSL仍然是一项挑战，尽管这对于天文学、医学成像、地质物理学或金融等领域非常重要。", "innovation": "该研究提出了一种完全自监督框架，能够在不需要在推理或下游微调时使用去噪器的情况下进行噪声鲁棒表示学习。该方法首先在嘈杂数据上训练一个SSL去噪器，然后使用该去噪器构建一个去噪到噪点的数据课程（即，首先在去噪样本上训练，然后在噪点样本上训练），用于预训练SSL主干（例如DINOv2），并结合教师指导正则化，将噪点嵌入与其对应的去噪嵌入锚定。这一过程鼓励模型内部化噪声鲁棒性。值得注意的是，去噪器可以在预训练后丢弃，简化部署。", "conclusion": "该方法在极端高斯噪音（$\boldsymbol{\text{σ}}=255$，SNR = 0.72 dB）下，ImageNet-1k和ViT-B数据集上提高了线性探针准确性4.8%，表明可以从噪声感知预训练中涌现出无需去噪器的噪声鲁棒性。代码可在特定链接获取。"}
{"llm_update_time": "20251101", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2505.12275", "html_url": "https://arxiv.org/abs/2505.12275", "title": "Curriculum Abductive Learning", "title_en": "Curriculum Abductive Learning", "authors": "Wen-Chao Hu,Qi-Jie Li,Lin-Han Jia,Cunjing Ge,Yu-Feng Li,Yuan Jiang,Zhi-Hua Zhou", "background": "Abductive Learning (ABL) 结合了机器学习与逻辑推理。ABL 中，预测模型从原始输入中预测符号概念标签，通过领域知识进行修正（ abduction ），然后将修订后的数据反馈用于重新训练。由于 abduction 的非确定性，训练过程通常不稳定，尤其是在知识库大且复杂的情况下，导致 abduction 空间过于庞大。现有工作主要集中在改善空间内的候选选择，但在处理知识库时，通常将知识库视为静态的黑盒。", "innovation": "本文提出了 Curriculum Abductive Learning (C-ABL)，一种明确利用知识库内部结构的方法，以解决 ABL 的训练挑战。C-ABL 将知识库划分为一系列子知识库，并逐步引入到训练过程中，从而在整个训练过程中逐渐减少 abduction 空间，并允许模型以逐步平滑的方式引入逻辑。实验表明，C-ABL 在多个任务中的表现优于之前的 ABL 实现，显著提升了训练稳定性、收敛速度和最终准确性，特别是在复杂知识设定下的表现更佳。", "conclusion": "C-ABL 通过逐步引入知识库中的信息来克服 ABL 中的挑战，从而提高了训练的稳定性、速度和准确性。"}
{"llm_update_time": "20251101", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2505.00254", "html_url": "https://arxiv.org/abs/2505.00254", "title": "使用视频语言模型赋能主动视频分析系统", "title_en": "Empowering Agentic Video Analytics Systems with Video Language Models", "authors": "Yuxuan Yan,Shiqi Jiang,Ting Cao,Yifan Yang,Qianqian Yang,Yuanchao Shu,Yuqing Yang,Lili Qiu", "background": "AI驱动的视频分析在不同领域中变得越来越重要，但现有的系统通常局限于特定的预定义任务，限制了它们在开放性分析场景中的适应性。近年来，视觉语言模型（VLMs）作为变革性技术的出现，为开放性视频理解、推理和分析提供了巨大的潜力。然而，它们有限的上下文窗口在处理大量实际应用场景中的超长视频内容时带来了挑战。", "innovation": "研究提出了一种名为AVA的VLM支撑系统，用于开放式的高级视频分析。该系统包含两个创新点：(1) 基于事件知识图谱（EKGs）的接近实时构造，用于高效地索引长或连续的视频流；(2) 一种代理检索生成机制，利用EKGs来处理复杂的多样化查询。此外，为了在超长和开放世界视频场景中评价视频分析，研究引入了一个新的基准（AVA-100），该基准包含8个超过10小时的视频以及120个手动注释的多样化和复杂的问答对。", "conclusion": "在公共基准测试（LVBench和VideoMME-Long）上，AVA展现了最先进的性能，分别取得了62.3%和64.1%的准确率，大幅超越了现有的VLM和视频检索增强生成（RAG）系统。在AVA-100基准上，AVA的准确率达到了75.8%，表现优异。该研究的代码可以在此访问：https://example.com/code ，而新的基准（AVA-100）可以于此访问：https://example.com/benchmark。"}
{"llm_update_time": "20251101", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2505.13308", "html_url": "https://arxiv.org/abs/2505.13308", "title": "在暗处探索：基于潜空间测试时实例级策略梯度进行推理", "title_en": "Seek in the Dark: Reasoning via Test-Time Instance-Level Policy Gradient in Latent Space", "authors": "Hengli Li,Chenxi Li,Tong Wu,Xuekai Zhu,Yuxuan Wang,Zhaoxin Yu,Eric Hanchen Jiang,Song-Chun Zhu,Zixia Jia,Ying Nian Wu,Zilong Zheng", "background": "大型语言模型（LLMs）在追求人工通用智能（AGI）的过程中，推理能力仍然是一个重大挑战。尽管模型性能在训练规模法则下有所提升，但仍面临训练算法中的关键问题，如灾难性遗忘现象和新型训练数据的局限性。此外，现有方法主要集中在词元空间中，未能充分利用潜空间来增强推理性能。因此，探索潜空间中测试时推理的有效方法成为一个重要方向。", "innovation": "论文提出了一种名为LatentSeek的新框架，通过潜空间中的测试时实例级适应（TTIA）增强大型语言模型的推理能力。LatentSeek利用策略梯度逐步更新潜表示，同时采用自我生成的奖励信号作为指导。与现有方法相比，LatentSeek在多个推理基准测试上表现出更优性能，且该方法效率高，通常在几次迭代内就能收敛，同时还能从额外的迭代中获益。", "conclusion": "LatentSeek是小型、可扩展且有效的解决方案，能够显著提升大型语言模型的推理能力。实验结果表明，在GSM8K、MATH-500和AIME2024等多个推理基准上，LatentSeek都超越了链式思维提示和基于微调的方法。此外，进一步的分析显示出该方法在测试时潜空间中的高效性，具有广泛的应用潜力。"}
{"llm_update_time": "20251101", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2505.10603", "html_url": "https://arxiv.org/abs/2505.10603", "title": "迈向开放和安全的生成式AI：开源与闭源大模型的比较分析", "title_en": "Toward a Public and Secure Generative AI: A Comparative Analysis of Open and Closed LLMs", "authors": "Jorge Machado", "background": "生成人工智能（Gen AI）系统作为一种关键技术，在社会的各个领域都具有深远的影响。然而，它们的部署也伴随着一系列风险和挑战，需要仔细评估。目前，尚未有全面且跨学科的研究系统性地对比开源和专有（闭源）生成AI系统的优缺点。本文旨在评估和对比开源与闭源生成AI模型的特点、机会与挑战，并提出开放、公共治理和安全的Gen AI框架的基本要素。目前的研究揭示了开源模型提供了更高的透明度、可审计性和灵活性，使独立审查和偏见缓解成为可能。而闭源系统虽然提供更好的技术支持和实施便利性，但可能会导致不公平的访问、责任不明确和伦理监督不足。研究还强调了多方治理、环境可持续性和监管框架在确保负责任发展方面的重要性。", "innovation": "本研究首次采用结合文献综述、批判性分析和对比分析的方法系统性地对比开源和闭源生成AI模型的优势和劣势。其创新点在于提出了一种旨在实现开放、公共治理和安全的Gen AI框架，通过确保技术的透明性、治理的有效性和系统的安全性来促进安全、可信和包容的AI发展。", "conclusion": "研究发现，开源模型支持更高的透明度和便捷性，从而便于独立审查和偏见缓解，而闭源系统则提供更好的技术支撑和易用性，但可能会限制公众的公平访问和伦理监督。因此，多方治理、环境可持续性和监管体系对于实现Gen AI的负责任发展至关重要。"}
{"llm_update_time": "20251101", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2505.15095", "html_url": "https://arxiv.org/abs/2505.15095", "title": "Nek Minit: 吸纳语用元认知提示以实现对澳大利亚和印度英语的可解释讽刺检测", "title_en": "Nek Minit: Harnessing Pragmatic Metacognitive Prompting for Explainable Sarcasm Detection of Australian and Indian English", "authors": "Ishmanbir Singh,Dipankar Srirag,Aditya Joshi", "background": "讽刺分析的挑战源于明示和暗示情感之间的不一致。当这种暗示可能与特定国家或地理区域相关时，挑战会更加复杂。在这种背景下，研究者们致力于开发具有解释性的讽刺检测方法，特别是针对澳大利亚和印度英语。Pragmatic metacognitive prompting (PMP) 是一种基于认知的技术，已被用于进行语用推理。此次研究结合PMP，构建了一种可解释的讽刺检测方法，同时提供了一个标准英语的数据基准。", "innovation": "研究引入了PMP技术，开发了一种方法，用于生成澳大利亚和印度英语的讽刺解释，同时在两个公开的大型语言模型（GEMMA和LLAMA）上进行了评估，结果显示出与四种替代提示策略相比，具有统计学上的显著性能改进。研究还发现，替代技术如代理式提示可以通过检索外部知识来缓解与语境相关的失败。", "conclusion": "本文的工作聚焦于利用PMP技术为不同英语变体生成讽刺解释，该方法在两个开放的大型语言模型上进行了评估，并与四种替代提示策略进行了比较，结果显示出显著的性能改进。"}
{"llm_update_time": "20251101", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2505.14604", "html_url": "https://arxiv.org/abs/2505.14604", "title": "让大型推理模型通过自我制动调整摆脱过度思考", "title_en": "Let LRMs Break Free from Overthinking via Self-Braking Tuning", "authors": "Haoran Zhao,Yuchen Yan,Yongliang Shen,Haolei Xu,Wenqi Zhang,Kaitao Song,Jian Shao,Weiming Lu,Jun Xiao,Yueting Zhuang", "background": "大型推理模型（LRMs）如OpenAI O1和DeepSeek-R1通过生成更长的思维链显著提升了其推理能力，展现了在多种任务上的出色表现。然而，这种性能提升是以大量冗余推理为代价的，增加了计算复杂度，并导致过度思考的问题加剧。尽管存在多种现有方法试图解决过度思考问题，它们往往依赖外部干预。", "innovation": "本文提出一种名为Self-Braking Tuning（SBT）的新框架，从允许模型调节其自己的推理过程的角度出发，以减少对外部控制机制的依赖。构建了基于标准答案的过度思考识别指标体系，设计了一种系统性方法来检测冗余推理，准确识别推理轨迹中的多余步骤，并生成学习自我调节行为的训练信号。在此基础上，开发了一种适应性推理长度的数据构建策略，并引入了创新的制动提示机制，使模型能够在适当的时间自然学习停止推理。", "conclusion": "实验结果表明，我们的方法可以在保持与未受约束模型相似准确度的同时，将令牌消耗减少高达60%。"}
{"llm_update_time": "20251101", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2505.13904", "html_url": "https://arxiv.org/abs/2505.13904", "title": "Learning to Insert for Constructive Neural Vehicle Routing Solver", "title_en": "Learning to Insert for Constructive Neural Vehicle Routing Solver", "authors": "Fu Luo,Xi Lin,Mengyuan Zhong,Fei Liu,Zhenkun Wang,Jianyong Sun,Qingfu Zhang", "background": "神经组合优化（NCO）是一种有前景的学习导向方法，可以用于解决车辆路径问题（VRP），而不需要大量的手动设计。现有的生成型NCO方法通常遵循逐步添加未访问节点到部分解决方案中的基于拼接的范式，但这种固定的方法往往会导致次优结果。为了克服这一局限性，我们探讨了插入型范式的想法，并提出了一种名为L2C-Insert的新型生成型NCO学习方法。L2C-Insert通过在当前部分解决方案中的任何有效位置战略性地插入未访问节点来构建解决方案，这可以大幅提高灵活性和解决方案质量。提出的框架包括三种关键组件：一种新的用于精确插入位置预测的模型架构、一种高效的模型优化训练方案以及一种先进的推理技术，充分利用了插入范式的灵活性。在旅行商问题（TSP）和载货车辆路径问题（CVRP）的合成和实际实例上进行了广泛的实验，结果显示L2C-Insert在各种问题规模上均取得了优越的性能。", "innovation": "提出了L2C-Insert，一种基于插入范式的生成型NCO方法。该方法通过在当前部分解决方案中的任何有效位置战略性地插入未访问节点来构建解决方案，显著提高了灵活性和解决方案质量。提出了新的模型架构、高效的训练方案和先进的推理技术，充分利用了插入范式的灵活性，从而在旅行商问题（TSP）和载货车辆路径问题（CVRP）中取得了优越的性能。", "conclusion": "L2C-Insert在合成和实际的旅行商问题（TSP）和载货车辆路径问题（CVRP）实例上的一系列实验中，展示了其在各种问题规模上的一致优越性能，表明了基于插入范式的生成型NCO方法是解决VRP的有效方法。"}
{"llm_update_time": "20251101", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2505.21996", "html_url": "https://arxiv.org/abs/2505.21996", "title": "学习用于交互式视频生成的世界模型", "title_en": "Learning World Models for Interactive Video Generation", "authors": "Taiye Chen,Xun Hu,Zihan Ding,Chi Jin", "background": "有效的行动选择未来的规划需要具备互动性和时空连续性基础世界模型。目前的长时间视频生成模型由于累积误差和不足的记忆机制限制了其固有的世界建模能力。", "innovation": "通过增加动作条件和自回归框架增强了图像到视频模型的互动能力。揭示了自回归视频生成中累积误差是固有不可消除的，而不足的记忆机制导致了世界模型的一致性差。提出了具有显式全局状态条件的视频检索增强生成 (VRAG) 方法，显著减少了长期累积误差并提高了世界模型的时空一致性。相比之下，简单的自回归生成和检索增强生成在视频生成中效果不佳，主要是由于当前视频模型的有限上下文学习能力。", "conclusion": "研究指出了视频世界模型的基本挑战，并为提高具有内部世界建模能力的视频生成模型建立了全面基准。"}
{"llm_update_time": "20251101", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2505.18766", "html_url": "https://arxiv.org/abs/2505.18766", "title": "StyleGuard：通过样式扰动生成文本到图像模型风格模仿攻击的预防", "title_en": "StyleGuard: Preventing Text-to-Image-Model-based Style Mimicry Attacks by Style Perturbations", "authors": "Yanjie Li,Wenxuan Zhang,Xinqi Lyu,Yihao Liu,Bin Xiao", "background": "最近，通过DreamBooth和Textual Inversion等方法应用于风格模仿和个性化定制的文本到图像扩散模型得到了广泛应用，但这也引发了知识产权保护和生成虚假内容方面的担忧。为应对这些问题，近期的研究如Glaze和Anti-DreamBooth提出使用对抗噪声来保护图像不被这些攻击影响，但最新的净化方法如DiffPure和Noise Upscaling成功破解了这些防御措施，揭示了它们的脆弱性。现有方法之间的跨模型可移植性有限，使得它们对于未知的文本到图像模型效果较差。", "innovation": "提出了一个新颖的反模仿方法StyleGuard。引入了一种新的样式损失，可以优化其在潜在空间中与初始图像相关的样式特征，提高跨模型的可移植性。通过在网络上混合使用净化器和增强器，设计了一种新的放大损失，以增强扰动绕过基于扩散的净化的能力。实验表明StyleGuard在多种转换和净化措施下表现出更高的鲁棒性，且在多种风格模仿方法中均有效。", "conclusion": "StyleGuard在多种数据集上展示了更好的鲁棒性，能够有效地对抗各种模型的风格模仿攻击。同时，代码已经公开可用，可以在指定的链接中找到。"}
{"llm_update_time": "20251101", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.00871", "html_url": "https://arxiv.org/abs/2506.00871", "title": "预测任意场景中的人行轨迹", "title_en": "Towards Predicting Any Human Trajectory In Context", "authors": "Ryo Fujii,Hideo Saito,Ryo Hachiuma", "background": "准确预测未来的人行轨迹对于自动驾驶系统非常重要，但却面临适应不同环境和领域的挑战。常用的处理方法是收集特定场景的数据并在模型中进行微调，但这种需要在每个新场景进行微调的方法在边缘设备上的实际部署中往往不可行。", "innovation": "引入了一个基于上下文学习（ICL）的人行轨迹预测框架TrajICL，该框架能够在推理时不依赖于场景特定数据的微调即可实现适应性预测，并提出了基于时空相似性的示例选择（STES）方法和预测导向的示例选择（PG-ES）方法，用于提高模型的选择精度，同时采用大规模合成数据集进行训练，以增强模型的预测能力。", "conclusion": "TrajICL 在多个公共基准测试中表现优异，优于微调方法，并在不同的场景（包括同域和跨域）中展示了显著的适应性。"}
{"llm_update_time": "20251101", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2505.21497", "html_url": "https://arxiv.org/abs/2505.21497", "title": "Paper2Poster：从科学论文到多模态海报的自动化", "title_en": "Paper2Poster: Towards Multimodal Poster Automation from Scientific Papers", "authors": "Wei Pang,Kevin Qinghong Lin,Xiangru Jian,Xi He,Philip Torr", "background": "学术海报生成在科学研究交流中具有重要性但同时也面临挑战，需要将长文档中的上下文信息压缩到一张清晰的图片中。当前缺乏统一的基准和评估指标来衡量海报生成的质量。", "innovation": "本文提出了第一个针对海报生成的基准和评估指标套件，包括视觉质量、文本连贯性、整体评估六个标准以及PaperQuiz评估来衡量海报传达论文核心内容的能力。此外，还提出了PosterAgent，一种自上而下的多代理视觉闭环管道，包括解析器、规划者和绘画评论者三个模块。", "conclusion": "实验结果显示GPT-4o生成的海报虽外观吸引人，但在文本质量和PaperQuiz评分上表现不佳，而基于Qwen-2.5系列的完全开源模型在几乎所有指标上都优于其他系统，同时使用了87%更少的令牌，并且将22页论文转化为可以编辑的.pptx海报仅需花费$0.005。这些发现指出了未来全自动海报生成模型的发展方向。代码和数据集均开源，在此链接：this https URL。"}
{"llm_update_time": "20251101", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2505.15201", "html_url": "https://arxiv.org/abs/2505.15201", "title": "Pass@K 政策优化：解决更难的强化学习问题", "title_en": "Pass@K Policy Optimization: Solving Harder Reinforcement Learning Problems", "authors": "Christian Walder,Deep Karkhanis", "background": "当前的 RL 算法在每个问题上采样多个 n > 1 的解尝试，并独立奖励它们，这优化了 pass@1 的性能，但牺牲了样本集合的多样化和集体效益，未能充分利用采样能力，限制了探索和更难问题上的改进。这种情况下，需要一种新的方法来优化 pass@k 性能，从而优化集合的样本，这些样本在联合考虑时能最大化奖励。论文旨在通过推导 pass@k 及其梯度的低方差无偏估计器，解决这个问题，适用于二元和连续奖励设置。", "innovation": "本文提出了 Pass-at-k 政策优化 (PKPO)，这是一种转换最终奖励的方法，以直接优化 pass@k 性能，通过这种方法优化集合的样本，在联合考虑时最大化奖励。与以往仅能优化 k=n 的研究不同，本文首次实现了对任意 k <= n 的 pass@k 的稳健优化。此外，本文的方法能够调整 k，在训练中优化两个指标，常能同时实现强大的 pass@1 和显著的 pass@k 收益。实验结果表明，与个体样本的效用相比，优先考虑联合效用提高了探索效率，有助于解决更难的问题。", "conclusion": "本文通过推导 pass@k 和其梯度的低方差无偏估计器，提出了 Pass-at-k 政策优化 (PKPO)。这种新方法能够在兵线样本和联合考虑时最大化奖励，以优化 pass@k 性能。实验证明，PKPO 方法能够在解决更困难的问题时提供显著的收益，并且通过调整 k 可以优化 pass@1 和 pass@k 指标。"}
{"llm_update_time": "20251101", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.01369", "html_url": "https://arxiv.org/abs/2506.01369", "title": "激励大规模语言模型自动验证其答案", "title_en": "Incentivizing LLMs to Self-Verify Their Answers", "authors": "Fuxiang Zhang,Jiacheng Xu,Chaojie Wang,Ce Cui,Yang Liu,Bo An", "background": "大规模语言模型（LLMs）在复杂推理任务中通过后训练和测试时的扩展规律取得了显著进展。常见的测试时扩展方法通常依赖于外部奖励模型来指导模型生成过程，但对特定任务后训练的模型进行扩展所能获得的边际改进有限，这归因于特定后训练生成器和通用奖励模型之间的分布差异。", "innovation": "本文提出了一种框架，旨在激励LLMs自我验证其答案。通过将答案生成和验证统一到一个强化学习（RL）过程中，训练出的模型可以有效评估其解决方案的正确性，并在推理时进一步自我验证其生成结果，无需外部验证者。实验结果表明，本文模型不仅提高了后训练性能，还能够实现有效的测试时扩展。", "conclusion": "实验结果显示，本文提出的方法不仅可以提升后训练语境长度下的性能，还能在推理阶段自主进行答案验证，提高了模型的整体表现。"}
{"llm_update_time": "20251101", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.07127", "html_url": "https://arxiv.org/abs/2506.07127", "title": "通过行为偏好优化的人工辅助机器人策略 refinement", "title_en": "Human-assisted Robotic Policy Refinement via Action Preference Optimization", "authors": "Wenke Xia,Yichu Yang,Hongtao Wu,Xiao Ma,Tao Kong,Di Hu", "background": "建立可靠的迭代改进的机器人系统对于实际应用至关重要。尽管视觉-语言-行动（VLA）模型被视为这种机器人部署的基础模型，但它们依赖于离线专家演示训练，这严重限制了它们在部署后进行进一步改进的能力。", "innovation": "提出了行为偏好优化（APO），这是一种通过人类辅助偏好对齐的方法，旨在通过与环境互动收集的偏好信息来细化VLA模型。APO提出了一种自适应重加权算法，并从互动中提取二元可欲性信号，以使VLA模型有效抑制失败性强的动作，同时增强纠正动作的适应性。", "conclusion": "APO为VLA模型提供了从失败中学习的关键能力，为它们在动态环境中的迭代改进和可靠部署铺平了道路。模拟和真实世界场景中的实验表明，我们的基于人类辅助框架具有更优秀的泛化能力和鲁棒性。我们相信这项工作能够为通过人机协作有效和稳定地优化VLA模型提供见解。"}
{"llm_update_time": "20251101", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.03237", "html_url": "https://arxiv.org/abs/2506.03237", "title": "UniSite：首个跨结构数据集及端到端配体结合位点检测的学习框架", "title_en": "UniSite: The First Cross-Structure Dataset and Learning Framework for End-to-End Ligand Binding Site Detection", "authors": "Jigang Fan,Quanlin Wu,Shengjie Luo,Liwei Wang", "background": "配体结合位点的检测是基于结构的药物设计中的一个基本步骤。尽管近年来取得了显著进展，但现有的方法、数据集和评估指标仍面临几个关键挑战，如单个蛋白-配体复合体数据集的统计偏差，处理方式的不连续性和传统评估指标的不足。", "innovation": "本文首先引入了UniSite-DS，这是一个UniProt中心的配体结合位点数据集，包含4.81倍的多站点数据和2.08倍的整体数据，解决了单个复合体数据集的统计偏差问题。然后，提出了UniSite框架，这是一个基于集合预测损失和双射匹配的端到端配体结合位点检测框架。此外，引入了基于IoU的平均精度作为更准确的评估指标。实验结果表明，IoU基于的平均精度更准确地反映了预测质量，UniSite在配体结合位点检测中优于当前最先进的方法。", "conclusion": "UniSite-DS和UniSite框架在UniSite-DS和多个代表性基准数据集上的广泛实验表明，IoU基于的平均精度能够更准确地反映配体结合位点预测的质量，并且UniSite优于当前最先进的方法。"}
{"llm_update_time": "20251101", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.01158", "html_url": "https://arxiv.org/abs/2506.01158", "title": "基于回归的规范化流高效训练方法用于玻尔兹曼生成器", "title_en": "Efficient Regression-Based Training of Normalizing Flows for Boltzmann Generators", "authors": "Danyal Rehman,Oscar Davis,Jiarui Lu,Jian Tang,Michael Bronstein,Yoshua Bengio,Alexander Tong,Avishek Joey Bose", "background": "生成模型在连续空间中的革命性进步推动了扩散和流匹配模型的大规模应用，但现代生成模型由于昂贵的推断成本，阻碍了其在需要快速似然评估的科学应用中的使用，如分子构象的玻尔兹曼生成器（BGs）。经典的规范化流在BGs中的应用能够高效采样和计算似然性，但传统最大似然训练因其数值不稳定性和计算挑战性使其训练困难。", "innovation": "提出了一种新颖且可扩展的基于回归的训练目标——规范化流回归训练（RegFlow），通过使用欧几里得平方损失代替传统最大似然训练，绕过了数值不稳定性和计算挑战，并利用最优传输耦合或预训练的连续规范化流（CNF）将先验样本映射到目标。RegFlow还引入了一种新的正向-反向自一致性损失，确保训练过程简单无痛，从而开辟了更大类的适用于BGs的最佳训练架构。与最大似然训练相比，RegFlow在平衡采样中表现出更好的性能、计算成本和稳定性，特别是在Alanine二肽、三肽和四肽的笛卡尔坐标采样中表现突出，展示了其在分子系统中的潜力。", "conclusion": "RegFlow的提出解决了传统规范化流训练中的数值不稳定性和计算挑战，为BGs的高效训练提供了新的方法，并在各种分子系统中展示了良好的性能和稳定性。"}
{"llm_update_time": "20251101", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.10173", "html_url": "https://arxiv.org/abs/2506.10173", "title": "SPARKE: 通过RKE分数在扩散模型中实现可扩展的提示感知多样性和新颖性指导", "title_en": "SPARKE: Scalable Prompt-Aware Diversity and Novelty Guidance in Diffusion Models via RKE Score", "authors": "Mohammad Jalali,Haoyu Lei,Amin Gohari,Farzan Farnia", "background": "扩散模型在高保真图像合成和提示引导生成建模方面已显示出显著的成功。然而，确保提示引导扩散模型生成样本的多样性仍然是一个挑战，特别是在提示覆盖广泛的语义范围时，特别是在需要跨语义相似提示以提示感知的方式评估生成数据的多样性时。为了解决这个问题，最近的方法通过引入多样性的度量来引导生成，从而鼓励更多的多样性生成。然而，基于熵的引导方法在大规模生成设置中依赖于矩阵熵得分，这带来了计算上的挑战。", "innovation": "本文提出了SPARKE（Scalable Prompt-Aware Rényi Kernel Entropy Diversity Guidance）方法，旨在通过RKE分数实现可扩展的提示感知多样性及新颖性指导。SPARKE利用条件熵进行多样性引导，能够动态地根据相似的提示条件化多样性测量，从而实现提示感知的多样性控制。此外，该方法特别关注条件潜在空间中的RKE分数引导的特殊情况，将一般熵度量的复杂度从$O(n^3)$降低到$O(n)$，从而减少了计算复杂度，并在不同提示的数千次生成范围内实现了多样性的引导采样。", "conclusion": "我们在多个文本到图像扩散模型上进行了数值测试，结果表明，所提出的方法在不增加显著计算成本的情况下提高了生成数据的提示感知多样性。我们的代码已发布于项目页面：this https URL"}
{"llm_update_time": "20251101", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.06220", "html_url": "https://arxiv.org/abs/2506.06220", "title": "GenIR: 为心理图像检索生成视觉反馈", "title_en": "GenIR: Generative Visual Feedback for Mental Image Retrieval", "authors": "Diji Yang,Minghao Liu,Chung-Hsiang Lo,Yi Zhang,James Davis", "background": "视觉语言模型（VLMs）在文本到图像检索基准测试中表现出强大的性能。然而，将这些成功应用于现实世界的应用仍然是一个挑战。在实际应用中，人的搜索行为通常是一个多轮的过程，受到内在线索的引导，从模糊的记忆到清晰的心理图像。为此，本文研究了心理图像检索（MIR）任务，旨在通过多轮互动来实现用户对心理构想图像的逐步细化。多轮交互检索的成功关键在于机器能够为用户提供清晰、具操作性的反馈。现有的方法依赖于间接或抽象的口头反馈，这可能会使用户难以细化查询，导致不满意的结果。", "innovation": "本文提出了GenIR，一种生成式多轮检索框架，利用基于扩散的图像生成技术，在每一轮检索中明确表征AI系统的理解。这些合成的视觉表示为用户提供直观且可解释的反馈，使用户能够有效地细化他们的查询。此外，本文还介绍了一个完全自动化的生成过程，用于创建高质量的多轮MIR数据集。实验结果显示，GenIR在心理图像检索场景中显著优于现有交互方法。这不仅为MIR提供了新任务和数据集的基准，也为后续研究提供了有效的生成检索方法的基础。", "conclusion": "本文通过提供一个生成式多轮检索方法，为多轮心理图像检索（MIR）任务设立了新的基准和数据集，显著提升了系统在交互过程中为用户提供直观、可解释视觉反馈的能力，为该领域的进一步研究奠定了基础。"}
{"llm_update_time": "20251101", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.20535", "html_url": "https://arxiv.org/abs/2506.20535", "title": "AIMeter: 计量、分析和可视化AI工作负载的能源和碳足迹", "title_en": "AIMeter: Measuring, Analyzing, and Visualizing Energy and Carbon Footprint of AI Workloads", "authors": "Hongzhen Huang,Kunming Zhang,Hanlong Liao,Kui Wu,Guoming Tang", "background": "人工智能，尤其是大语言模型（LLMs）的快速发展引发了对其训练和推理过程中能源消耗和碳排放的广泛关注。然而，现有的工具在测量和报告此类影响方面往往是碎片化的，缺乏系统性度量整合，同时也提供有限的支持进行相关性分析。", "innovation": "本文介绍了AIMeter，这是一个全面的软件工具包，用于衡量、分析和可视化AI工作负载在能耗、功率消耗、硬件性能和碳排放方面的数据。通过与现有的AI框架无缝集成，AIMeter提供了标准化报告，并导出详细的时序数据以支持轻量级的基准测试和可重复性研究。它进一步使硬件度量与模型性能之间的深入相关性分析得以实现，从而有助于确定瓶颈并提升性能。AIMeter解决了现有工具的关键限制，促使研究社区在衡量AI工作负载的性能和环境影响时，考虑环境影响，推动了“绿色AI”实践的转向。", "conclusion": "通过AIMeter，研究社区被鼓励在衡量AI工作负载的性能时将其环境影响纳入考量，从而推动更加可持续的“绿色AI”实践。代码可在以下网址获得：this https URL。"}
{"llm_update_time": "20251101", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.11094", "html_url": "https://arxiv.org/abs/2506.11094", "title": "正义之衡：大语言模型安全性评估的全面综述", "title_en": "The Scales of Justitia: A Comprehensive Survey on Safety Evaluation of LLMs", "authors": "Songyang Liu,Chaozhuo Li,Jiameng Qiu,Xi Zhang,Feiran Huang,Litian Zhang,Yiming Hei,Philip S. Yu", "background": "随着人工智能的迅速发展，大型语言模型（LLMs）在自然语言处理（NLP）方面展现了出色的能力，包括内容生成、人机交互、机器翻译和代码生成。然而，它们的广泛应用也引发了重大的安全关切，尤其是生成的内容可能带有毒性、偏见或虚假信息，尤其是在对抗性环境中。尽管已有许多研究尝试评估这些风险，但对LLM安全性评估的全面和系统性综述仍然不足。", "innovation": "本文提出了一种四维分类法：（i）为什么评估，探讨了LLM安全性评估的背景，以及其与一般LLM评估的区别及其重要性；（ii）评估什么，基于关键能力对现有安全性评估任务进行了审查和分类，包括毒性、稳健性、伦理、偏见和公平性、真实性等方面；（iii）在哪里评估，总结了当前用于安全性评估的评估指标、数据集和基准；（iv）如何评估，回顾了现有主流评估方法，基于评估者的角色以及整合整个评估流程的一些评估框架。", "conclusion": "最后，本文提出了LLM安全性评估面临的挑战，并提出了推动该领域进一步发展的前景性研究方向，强调优先进行安全性评估的重要性，以确保LLMs在实际应用中的可靠和负责任部署。"}
{"llm_update_time": "20251101", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.09937", "html_url": "https://arxiv.org/abs/2506.09937", "title": "SAFE：视觉-语言-行动模型的多任务故障检测", "title_en": "SAFE: Multitask Failure Detection for Vision-Language-Action Models", "authors": "Qiao Gu,Yuanliang Ju,Shengxiang Sun,Igor Gilitschenski,Haruki Nishimura,Masha Itkina,Florian Shkurti", "background": "现有的视觉-语言-行动（VLA）模型在多种操作任务中展现出了令人期待的机器人行为，但在新任务中应用时成功率较低。要让这些策略安全地与环境互动，需要一个故障检测器能在及时提醒的情况下，让机器人能够停止、回溯或寻求帮助。然而，现有的故障检测器仅在单一或少数特定任务上进行训练和测试，而通用视觉-语言-行动（VLA）模型需要故障检测器能够泛化，并在未见过的任务和新环境中检测失败。本文探讨了这一问题，提出了一个解决方案，即SAFE，这是一种专为通用机器人策略（如VLA）设计的故障检测器。", "innovation": "本文提出了一种名为SAFE的故障检测器，专门用于检测通用视觉-语言-行动模型在多任务环境中的故障。SAFE可以从VLA内部特征中学习，并预测任务失败的可能性。SAFE不仅通过成功和失败的回放进行了训练，还在未见过的任务上进行了评价。SAFE适用于不同的策略架构，并通过OpenVLA、$\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol\boldsymbol{\boldsymbol\boldsymbol{\boldsymbol{\boldsymbol\boldsymbol\boldsymbol{\boldsymbol{\boldsymbol\boldsymbol{\boldsymbol{\boldsymbol{\textbackslash}}}}}}}}}}}}$, $\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol\boldsymbol{\boldsymbol\boldsymbol{\boldsymbol{\boldsymbol\boldsymbol\boldsymbol\boldsymbol{\boldsymbol\boldsymbol\boldsymbol{\boldsymbol{\textbackslash}}}}}}}}}}$, 和 $\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol\boldsymbol{\boldsymbol\boldsymbol{\boldsymbol{\boldsymbol\boldsymbol\boldsymbol\boldsymbol{\boldsymbol\boldsymbol\boldsymbol{\boldsymbol{\textbackslash}}}}}}}}}}$-FAST在模拟和真实环境中进行了广泛测试。SAFE与各种基线进行了比较，并显示了其在故障检测性能上的领先表现以及准确性与检测时间的最佳平衡，使用了引导预测方法。", "conclusion": "SAFE在故障检测性能上达到了最先进的水平，并能以较低的延迟检测故障。该研究通过详细的实验对比展示了该方法的有效性。"}
{"llm_update_time": "20251101", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.13328", "html_url": "https://arxiv.org/abs/2507.13328", "title": "Vision-and-Language Training Helps Deploy Taxonomic Knowledge but Does Not Fundamentally Alter It", "title_en": "Vision-and-Language Training Helps Deploy Taxonomic Knowledge but Does Not Fundamentally Alter It", "authors": "Yulu Qin,Dheeraj Varghese,Adam Dahlgren Lindström,Lucia Donatelli,Kanishka Misra,Najoung Kim", "background": "大多数关于视觉-语言（VL）训练的研究结果显示，这种训练在语言模型的表征上带来的影响是不一致的或是边际性的，无论是行为上还是表征上。这项研究从假设出发，认为VL训练对词汇-概念知识（特别是其分类组织）可能产生显著影响。", "innovation": "通过对比纯文本LMs和其VL训练版本的最小两两对比，研究显示了VL模型在需要概念分类理解的问题回答任务中往往比纯文本模型表现更好。研究还使用了目标行为和表征分析，表明LMs和VLMs在分类知识本身上没有显著差异，但在如何表征包含分类关系的概念与非分类关系的概念的问题上有所不同。这表明分类知识本身并没有通过额外的VL训练发生实质性的改变，但VL训练确实提高了这种知识在特定任务中的应用。", "conclusion": "VL训练在某些任务上增强了分类知识的应用，但并未根本改变这种知识。"}
{"llm_update_time": "20251101", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.09846", "html_url": "https://arxiv.org/abs/2507.09846", "title": "通过河流：理解无计划方法在语言模型训练中的优势", "title_en": "Through the River: Understanding the Benefit of Schedule-Free Methods for Language Model Training", "authors": "Minhak Song,Beomhan Baek,Kwangjun Ahn,Chulhee Yun", "background": "随着模型和数据集的规模持续急剧扩大，传统的带有固定计算预算的预训练策略（如余弦学习率调度）对于大规模训练已经不再足够。最近的替代方法，如暖身-稳定-衰减（WSD）调度和权重平均，提供了更大的灵活性。然而，WSD依赖于显式的衰减阶段来跟踪训练进度，而权重平均方法则通过额外的内存成本来解决这一局限性。为了寻求一种更合理的、更具扩展性的替代方案，我们回顾了无计划方法（Schedule-Free，SF）[Defazio et al., 2024]，该方法在不同场景下已经表现出色。", "innovation": "我们展示了SF-AdamW如何有效地在损失景观中导航，无需衰减阶段或辅助平均，特别适合持续扩展的训练工作负载。为了理解这种行为，我们对SF动态进行了理论和实验分析，揭示了它如何隐式进行平均操作而不占用额外内存。基于这一分析，我们提出了一种改进的SF变体，提高了对动量的鲁棒性，并在大批量下表现更优，解决了原始方法的关键局限性。", "conclusion": "这些结果共同证明了SF作为一种实用、可扩展且具有良好理论支撑的训练语言模型的方法的有效性。"}
{"llm_update_time": "20251101", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.13464", "html_url": "https://arxiv.org/abs/2506.13464", "title": "揭开语言模型的学习之谜：认知框架及实证研究", "title_en": "Unveiling the Learning Mind of Language Models: A Cognitive Framework and Empirical Study", "authors": "Zhengyu Hu,Jianxun Lian,Zheyuan Xiao,Seraphina Zhang,Tianfu Wang,Nicholas Jing Yuan,Xing Xie,Hui Xiong", "background": "大型语言模型（LLMs）在数学、编程和推理任务中表现出了令人印象深刻的能力，但它们的学习能力，这一对于适应动态环境和获取新知识至关重要的因素，尚未得到充分探索。本文通过引入一个借鉴认知心理学和教育领域的框架来解决这一问题。该框架将一般学习能力分为三个相互独立却又互补的维度：来自指导的学习（通过显性指导获取知识）、来自概念的学习（内化抽象结构并推广到新情境）和来自经验的学习（通过积累探索和反馈进行适应）。", "innovation": "本文创新性地提出了一个基于认知心理学和教育学的框架，将语言模型的学习能力分解为三个维度：来自指导的学习、来自概念的学习和来自经验的学习。通过实证研究，发现了几个关键发现：互动能够提高学习效果；概念理解在大规模模型中是规模效应，并且对其有益；LLMs 是有效的少量学习者但不是大量的学习者。基于这个框架和实证结果，作者引入了一个基准，用于统一且现实地评估LLMs在三个认知学习维度上的泛化学习能力。这使得诊断性见解成为可能，并支持更适应性的、更像人类模型的评估和发展。", "conclusion": "本文通过引入一个基于认知心理学和教育领域的框架，并进行实证研究，揭示了语言模型的学习机制。该研究发现了一些重要的学习规律，并提出了一个基准，用于统一且现实地评估语言模型的泛化学习能力，从而支持更适应性和更拟人化的模型的发展。"}
{"llm_update_time": "20251101", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.07981", "html_url": "https://arxiv.org/abs/2508.07981", "title": "Omni-Effects：统一且空间可控的视觉效果生成", "title_en": "Omni-Effects: Unified and Spatially-Controllable Visual Effects Generation", "authors": "Fangyuan Mao,Aiming Hao,Jintao Chen,Dongxia Liu,Xiaokun Feng,Jiashu Zhu,Meiqi Wu,Chubin Chen,Jiahong Wu,Xiangxiang Chu", "background": "视觉特效（VFX）是现代电影制作中必不可少的视觉增强技术。尽管视频生成模型可以为VFX生产提供成本效益的解决方案，但当前的方法受到单效果LoRA训练的限制，这限制了生成单一效果。这一基本限制阻碍了需要空间可控复合效果的应用，即同时在指定位置生成多个效果。然而，将多种效果整合到一个统一框架中面临重大挑战：效果版本的干扰和多VFX联合训练时的空间不可控性。", "innovation": "为解决这些挑战，我们提出Omni-Effects，这是一种统一框架，能够生成提示引导的效果和空间可控的复合效果。框架的核心包括两个关键创新：（1）基于LoRA的专家混合（LoRA-MoE），采用一组专家LoRAs，将多种效果整合到一个统一模型中，同时有效缓解任务间干扰。（2）空间感知提示（SAP），将空间蒙版信息集成到文本标记中，实现精确的空间控制。此外，我们引入了一个独立信息流（IIF）模块，集成在SAP中，将各个效果对应的控制信号隔离，防止不希望的混合。", "conclusion": "广泛的实验表明，Omni-Effects实现了精确的空间控制和多样化的效果生成，使用户能够指定所需效果的类别和位置。"}
{"llm_update_time": "20251101", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.03704", "html_url": "https://arxiv.org/abs/2507.03704", "title": "控制推理模型的思维速度", "title_en": "Controlling Thinking Speed in Reasoning Models", "authors": "Zhengkai Lin,Zhihang Fu,Ze Chen,Chao Chen,Liang Xie,Wenxiao Wang,Deng Cai,Zheng Wang,Jieping Ye", "background": "人类认知被认为是分为两种模式：快速的直观System 1思维和慢速的深入System 2思维。当前的大型推理模型（LRMs）在System 2思维方面表现出色，但在进行快速思维时存在限制，这导致高计算成本和延迟。已有研究试图通过动态调整思考速度来使LRMs更接近人类智能，并解决如何控制思考速度和何时进行调整以实现最佳性能这两个关键问题。现有方法侧重于通过提示调整模型的规模，但本研究提出了一种新的基于表示编辑的方法，并引入了实时难度估计技术。", "innovation": "本研究首次提出了一种基于表示编辑的测试时缩放效果，并且优于现有的基于提示的缩放方法；同时，首次提出了基于实时难度估计的推理策略，能够处理简单步骤并深入分析复杂推理。该方法能够在不增加训练或额外成本的情况下，提高1.3%的准确率并降低8.6%的标记使用率，适用于领先的大规模推理模型和高级推理基准测试。研究主要基于vLLM算法实现，并且预计在未来会有更广泛的应用。", "conclusion": "本研究通过动态调整大推理模型的思考速度，优化了准确性和效率之间的权衡。通过首次提出基于表示编辑的方法和实时难度估计技术，成功提高了模型处理能力和精准度，同时保持低标记使用率，适用于多种大规模推理模型和高级推理测试。"}
{"llm_update_time": "20251101", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.06159", "html_url": "https://arxiv.org/abs/2509.06159", "title": "FASL-Seg：手术场景中的解剖结构和工具分割", "title_en": "FASL-Seg: Anatomy and Tool Segmentation of Surgical Scenes", "authors": "Muraam Abdel-Ghani,Mahmoud Ali,Mohamed Ali,Fatmaelzahraa Ahmed,Muhammad Arsalan,Abdulaziz Al-Ali,Shidin Balakrishnan", "background": "随着机器人微创手术的流行，基于深度学习的手术培训成为关键研究领域。通过语义分割模型可以帮助深入理解手术场景的组件，但目前大多数研究集中在手术工具上，而忽略了解剖对象。此外，当前最先进的模型在捕获高层上下文特征和低层边缘特征之间难以平衡。", "innovation": "我们提出了一种特征自适应空间定位模型（FASL-Seg），设计用于通过两个不同的处理流（低级特征投影LLFP和高级特征投影HLFP），在多种细节水平上捕获特征，以便精准分割解剖结构和手术器械。FASL-Seg模型在EndoVis18和EndoVis17基准数据集的三类应用案例中进行了评估。", "conclusion": "FASL-Seg模型在EndoVis18解剖和解剖结构分割中实现了72.71%的平均交并比（mIoU），比最先进的模型提高了5%。在EndoVis18和EndoVis17工具类型分割中分别实现了85.61%和72.78%的mIoU，整体性能优于最先进的模型，两个数据集中的每个类的性能与最先进的结果相当，多类解剖和器械的性能保持一致，展示了不同处理流在不同特征分辨率方面有效性的优势。"}
{"llm_update_time": "20251101", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.17784", "html_url": "https://arxiv.org/abs/2509.17784", "title": "使用大型语言模型揭示多元模态因果关系", "title_en": "Revealing Multimodal Causality with Large Language Models", "authors": "Jin Li,Shoujin Wang,Qi Zhang,Feng Liu,Tongliang Liu,Longbing Cao,Shui Yu,Fang Chen", "background": "从数据中揭示因果机制是科学进步的基础。虽然大型语言模型（LLMs）在增强来自非结构化数据的因果发现（CD）方面显示出前景，但它们在不断普及的多元模态设置中的应用仍然是一个关键挑战。即使在多模态LLM（MLLM）出现的情况下，它们在多元模态CD中的功效也受到两个主要限制：（1）难以探索跨模态和内部模态的交互作用，以全面识别因果变量；（2）单纯观察数据难以处理结构上的不确定性。", "innovation": "为解决这些挑战，我们提出了MLLM-CD，这是一种新的多模态因果发现框架，从非结构化数据中进行多模态因果发现。它包括三个关键组件：（1）一个新颖的对比因子发现模块，基于对比样本对中探索的交互作用来识别真实的多模态因子；（2）一个统计因果结构发现模块，用于推断发现因子之间的因果关系；（3）一个迭代的多模态反事实推理模块，通过结合MLLM的知识和推理能力来逐步改进发现结果。广泛的实验结果显示，提出的MLLM-CD在揭示来自多模态非结构化数据的真实因素及其因果关系方面具有有效性。", "conclusion": "广泛的实验数据证明，该提出的MLLM-CD框架在揭示来自非结构化数据的真实因果机制方面表现出色。"}
{"llm_update_time": "20251101", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.19331", "html_url": "https://arxiv.org/abs/2509.19331", "title": "Holographic Transformers for Complex-Valued Signal Processing: Integrating Phase Interference into Self-Attention", "title_en": "Holographic Transformers for Complex-Valued Signal Processing: Integrating Phase Interference into Self-Attention", "authors": "Enhao Huang,Zhiyu Zhang,Tianxiang Xu,Chunshu Xia,Kaichun Hu,Yuchen Yang,Tongtong Pan,Dong Dong,Zhan Qin", "background": "大多数深度模型在处理注意力机制时将其实体化为实数的相关性，而忽略了物理现象中的干涉效应。复值信号同时编码振幅和相位，但在当前模型中，相位信息通常被忽视或不充分利用。因此，现有模型在处理复杂值信号时表现受限，尤其是在涉及相位信息的应用中。", "innovation": "该研究引入了Holographic Transformer（全息变换器），该架构借鉴了波干涉原理，将自注意力机制扩展到了复数域。Holographic注意力通过相对相位调整相互作用，并通过相干叠加来模拟值，确保振幅和相位的一致性。此模型采用双头解码器，同时重建输入数据并预测任务输出，有效防止了相位坍缩。这一改进的核心在于将物理一致性嵌入到注意力机制中，以处理复杂的相位信息，从而在复杂值信号处理中取得了显著性能提升。", "conclusion": "通过实验验证了Holographic Transformer在极化合成孔径雷达图像分类和无线信道预测任务中的优异性能，证明了物理一致性的注意力机制在复杂值学习中的普适性改进。这一全息变换器框架为相干信号建模提供了一个统一的物理基础，有助于在处理振动、通信和雷达等领域的复杂值信号时实现更好的表现。"}
{"llm_update_time": "20251101", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.17197", "html_url": "https://arxiv.org/abs/2509.17197", "title": "SignalLLM：一种用于自动信号处理的通用大语言模型代理框架", "title_en": "SignalLLM: A General-Purpose LLM Agent Framework for Automated Signal Processing", "authors": "Junlong Ke,Qiying Hu,Shenghai Yuan,Yuecong Xu,Jianfei Yang", "background": "现代信号处理（SP）管道，无论是基于模型还是数据驱动，通常受限于复杂的且不连贯的工作流程，高度依赖于专家知识和手动工程，难以在数据有限的情况下实现适应性和泛化。相比之下，大型语言模型（LLMs）提供了强大的推理能力、广泛的一般用途知识、基于上下文的学习能力以及跨模态迁移能力，这使LLMs成为自动化和泛化SP工作流程的强大工具。", "innovation": "本文介绍了SignalLLM，这是第一个基于LLM的通用代理框架，旨在解决通用SP任务。SignalLLM引入了一种原理性和模块化的架构，将高层SP目标分解为结构化的子任务，并通过适应性的检索增强生成（RAG）和细化进行分层规划；这些子任务随后通过基于提示的推理、跨模态推理、代码合成、模型调用或数据驱动的LLM辅助建模来执行。这种可泛化的设计使得可以灵活地选择适用于不同信号模态、任务类型和数据条件的问题解决策略。文章通过五个代表性任务（如雷达目标检测、人体活动识别和文本压缩）展示了SignalLLM的适用性和有效性，实验结果表明，在少量样本和零样本设置中，SignalLLM的性能优于传统的和现有的LLM方法。", "conclusion": "本文通过五个代表性任务展示了SignalLLM的适用性和有效性，实验结果显示在少量样本和零样本设置中，SignalLLM的性能优越于传统的和现有的LLM方法。其通用化设计使SignalLLM能够灵活地解决不同信号模态、任务类型和数据条件下的问题。"}
{"llm_update_time": "20251101", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.24267", "html_url": "https://arxiv.org/abs/2509.24267", "title": "循环扩散模型用于反事实图像生成", "title_en": "Cycle Diffusion Model for Counterfactual Image Generation", "authors": "Fangrui Huang,Alan Wang,Binxu Li,Bailey Trang,Ridvan Yesiloglu,Tianyu Hua,Wei Peng,Ehsan Adeli", "background": "深度生成模型已经在医学图像合成中取得了显著的成功，但确保生成图像的真实性和高质量以及直接或反事实生成的真实性和可靠性仍然是一个挑战。现有的扩散模型未充分保证生成的图像与真实图像的一致性和真实性。", "innovation": "本文提出了一种循环训练框架，用于微调扩散模型，以提高条件一致性并增强合成图像的真实感。这种方法，循环扩散模型（CDM），通过引入循环约束来确保生成图像和原始图像之间的一致性，从而提供更可靠的真实和反事实生成。", "conclusion": "在合成立方脑MRI数据集上的实验表明，本文的方法能够提高条件的准确性并增强图像质量，用FID和SSIM进行衡量。结果表明，CDM中的循环策略可以有效改进基于扩散的医学图像生成，可以在数据增强、反事实和疾病进展建模等应用中发挥作用。"}
{"llm_update_time": "20251101", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.23885", "html_url": "https://arxiv.org/abs/2509.23885", "title": "Tunable-Generalization Diffusion Powered by Self-Supervised Contextual Sub-Data for Low-Dose CT Reconstruction", "title_en": "Tunable-Generalization Diffusion Powered by Self-Supervised Contextual Sub-Data for Low-Dose CT Reconstruction", "authors": "Guoquan Wei,Liu Shi,Zekun Zhou,Wenzhe Shan,Qiegen Liu", "background": "当前基于深度学习的低剂量CT降噪模型依赖配对数据，泛化能力差。尽管扩散模型更加关注清洁数据的分布，但在医学临床应用中难以满足。自监督方法面临的问题是利用预训练模型进行剂量扩展时，模型的泛化能力显著下降。", "innovation": "本文提出了一种新颖的方法TUnable-geneRalizatioN Diffusion (TurnDiff)。TurnDiff通过设计基于上下文子数据的自增强相似性策略，结合先验知识和知识蒸馏优化图像细节。此外，该方法可以灵活应用于不同剂量的泛化，仅需低剂量CT投影数据即可进行训练和测试。全面评估显示，TurnDiff在重建和泛化方面均优于现有最佳方法。", "conclusion": "本研究利用上下文子数据的自监督方法，通过设计上下文子数据自增强相似性策略和结合知识蒸馏优化图像细节，提出了Tunable-Generalization Diffusion (TurnDiff)方法。实验结果表明，TurnDiff在低剂量CT重建和泛化方面表现出色，优于当前最先进的方法。"}
{"llm_update_time": "20251101", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.14889", "html_url": "https://arxiv.org/abs/2510.14889", "title": "通过社交媒体纵向和信息环境信号检测早期和隐性自杀意念", "title_en": "Detecting Early and Implicit Suicidal Ideation via Longitudinal and Information Environment Signals on Social Media", "authors": "Soorya Ram Shimgekar,Ruining Zhao,Agam Goyal,Violeta J. Rodriguez,Paul A. Bloom,Hari Sundaram,Koustuv Saha", "background": "在社交媒体上，许多经历自杀意念（SI）的人不会明确表达自己的困扰。相反，这种困扰可能通过日常帖子或同伴互动中的间接信号显现。早期和隐性的自杀意念检测至关重要但极具挑战性。", "innovation": "本文将早期和隐性的自杀意念定义为一种前瞻性的预测任务，并提出了一种计算框架，该框架通过建模用户的信息环境，包括他们的时间轴发帖历史以及社交上临近者的对话，来识别这些间接信号。采用组合网络中心性度量确定用户的重要邻居，并对用户及其邻居的互动进行时间对齐，从而在fine-tuned DeBERTa-v3模型中整合多层次的信号。", "conclusion": "在Reddit的用户研究中，采用了1000名用户数据（500名案例和500名对照），该方法在早期和隐性自杀意念检测上相比于仅基于个体特征的基准模型提高了15%。这些结果表明，同伴互动提供了宝贵的预测信号，并为进一步设计捕捉在线环境中直接和隐藏风险的早期检测系统提供了更广泛的意义。"}
{"llm_update_time": "20251101", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.01083", "html_url": "https://arxiv.org/abs/2509.01083", "title": "DSDE: 动态推测性解码与KLD稳定性用于实际服务", "title_en": "DSDE: Dynamic Speculative Decoding with KLD Stability for Real-World Serving", "authors": "Mingyu Yang,Jae-Young Choi,Kihyo Moon,Minsung Jang,Eunjoo Jeon", "background": "推测性解码可以加速大规模语言模型的推理，但其依赖于固定长度的推测，在处理多样化的请求时，在大规模批次服务环境中表现不佳。因此，需要探索新的方向来实现动态适应，通过研究新型的后处理诊断信号，来改进推测性解码.", "innovation": "本文提出了Dynamic Speculative Decoding Engine (DSDE)，这是一种无需训练的框架，包含两个主要部分：一是基于Kullback-Leibler（KLD）发散的方差的预测信号，用于诊断生成的区域稳定性；二是自适应推测长度限制，以减轻单一解码序列中的滞后问题。研究表明，基于KLD稳定性的诊断信号可用于动态适应，并且由这些信号引导的算法在端到端延迟和一系列工作负载的鲁棒性方面表现出色。特别是在低接受率的情况下，提出的信号仍能保持诊断效果，这证明后处理信号在构建更加稳健智能的LLM推理系统中的价值，并指出了一种未来研究动态推测长度适应的有前景的方向.", "conclusion": "本文验证了后处理信号作为构建更加稳健和智能的大规模语言模型推理系统的宝贵组件，并强调了未来研究动态推测长度适应的一个有前途的方向。"}
{"llm_update_time": "20251101", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.08604", "html_url": "https://arxiv.org/abs/2510.08604", "title": "LatentBreak: 通过潜在空间反馈劫持大型语言模型", "title_en": "LatentBreak: Jailbreaking Large Language Models through Latent Space Feedback", "authors": "Raffaele Mura,Giorgio Piras,Kamilė Lukošiūtė,Maura Pintor,Amin Karbasi,Battista Biggio", "background": "劫破攻击是专门为绕过大型语言模型内置安全机制而设计的对抗性攻击。当前的自动化劫破方法通常通过优化对抗后缀或适应长前缀模板，迫使模型生成初始部分的受限或有害响应来实现攻击。现有的劫破攻击可以通过简单的困惑度过滤来检测。鉴于此，提出了一种基于白盒方法的LatentBreak技术，该技术生成低困惑度的自然对抗前缀，能够规避基于困惑度的防御。", "innovation": "LatentBreak采用潜在空间反馈，通过替换输入前缀中的同义词而不是添加高困惑度的对抗后缀或长模板，生成低困惑度的自然对抗前缀，从而达到规避基于困惑度防御的效果。这些同义词的选择则是通过最小化对抗前缀的表示与无害请求之间在潜在空间中的距离来实现的。实验结果表明，LatentBreak生成的对抗前缀更短、困惑度更低，能够显著优于其他竞争的劫破算法在多个安全对齐的模型中的性能。", "conclusion": "LatentBreak展示了如何通过潜在空间反馈来生成低困惑度的自然对抗前缀，从而有效规避基于困惑度的防御，并且该技术在多个安全对齐的大型语言模型中表现出优越的性能。"}
{"llm_update_time": "20251101", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.04226", "html_url": "https://arxiv.org/abs/2510.04226", "title": "大型语言模型中的知识多样性与知识坍塌", "title_en": "Epistemic Diversity and Knowledge Collapse in Large Language Models", "authors": "Dustin Wright,Sarah Masud,Jared Moore,Srishti Yadav,Maria Antoniak,Chan Young Park,Isabelle Augenstein", "background": "大型语言模型倾向于生成词汇、语义和风格高度一致的文本，这可能导致知识坍塌。现有研究主要集中在封闭问答和模糊语义特征上，没有全面考察跨时间和文化背景的知识变化趋势。因此，本文提出了一种新的方法来衡量知识多样性，通过实证研究评估了大型语言模型的知识坍塌问题。研究测试了27种语言模型、155个主题和200种提示变化，并展示了语言模型在生成真实声明多样化方面表现较弱，而模型大小和检索增强生成对知识多样性有不同影响。此外，国家特定的声明更多反映了英语而不是当地语言，指出了知识代表性的差距。", "innovation": "本文提出了一种新的方法来衡量大型语言模型的“知识多样性”，即LLM输出中真实声明的变化，这超越了现有的局限于封闭问答或模糊语义特征的研究。通过实证研究，本文揭示了模型尺寸和检索增强生成方法对知识多样性的影响，并探讨了这些影响在全球文化背景下的差异。此外，通过对多个国家特定声明的分析，本文还揭示了语言使用上的差距。", "conclusion": "研究表明，尽管较新模型可以生成更加多样化的声明，但几乎所有模型的多样性都低于基于网页搜索的基本搜索引擎。模型尺寸的增加会降低知识多样性，而检索增强生成则可能提高知识多样性，但这取决于具体的文化背景。此外，语言模型生成的内容更多反映了英语而非当地的语言习惯，这凸显了知识多样性在全球化背景下的差距。"}
{"llm_update_time": "20251101", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.21319", "html_url": "https://arxiv.org/abs/2509.21319", "title": "RLBFF: 二元灵活反馈以连接人类反馈与可验证奖励", "title_en": "RLBFF: Binary Flexible Feedback to bridge between Human Feedback & Verifiable Rewards", "authors": "Zhilin Wang,Jiaqi Zeng,Olivier Delalleau,Ellie Evans,Daniel Egert,Hoo-Chang Shin,Felipe Soares,Yi Dong,Oleksii Kuchaiev", "background": "强化学习与人类反馈（RLHF）和强化学习与可验证奖励（RLVR）是语言模型（LLM）后训练中常用的两种主要模式，各有优势。RLHF注重人类反馈但缺乏明确的评判标准，导致难以解释和对抗人类奖励的恶作剧。相比之下，RLVR注重基于正确性验证，但其应用范围有限。因此，论文提出一种新的方法——二元灵活反馈（RLBFF），旨在结合人类偏好的多样性和基于规则验证的精确性，以捕捉响应质量的更细腻方面，不仅仅是正确性。RLBFF从自然语言反馈中提炼出可以用二元形式（如信息准确性：是，或代码可读性：否）回答的原则，作为奖励模型训练的基础任务，通过这两方面的结合，可以更好地理解及优化模型的生成响应。", "innovation": "RLBFF提出的创新点在于结合了人类驱动的偏好和基于规则的验证，以提取可以用二元形式回答的原则，从而训练奖励模型并将其作为任务的一部分。这种训练方式不仅能够提高奖励模型的性能，还允许用户在推断时定制奖励模型的关注点。此外，RLBFF提供了全面的开源食谱（包括数据），用于使用RLBFF和奖励模型对Qwen3-32B进行对齐，以匹配或超越o3-mini和DeepSeek R1在通用对齐基准（MT-Bench、WildBench和Arena Hard v2）中的性能表现，且成本仅为后者的5%。这在实际应用中具有重要意义，因为传统的验证方法在处理范围和准确性的平衡时可能会面临挑战，而RLBFF的方法则更具灵活性和实用性。", "conclusion": "通过使用RLBFF和基于这种方法训练的奖励模型，研究成功地对Qwen3-32B进行了对齐，并且在多个基准测试中取得了优异的表现，甚至超过了现有技术。这种结合的优势在于它不仅提高了模型的性能，还赋予了用户更多的灵活性和定制化选项。未来的研究可以进一步探索如何将这种方法应用到更广泛的领域，以实现在真实世界应用中的广泛影响力。"}
{"llm_update_time": "20251101", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.16396", "html_url": "https://arxiv.org/abs/2510.16396", "title": "SPLite手部：基于稀疏性的轻量级3D手部姿态估计", "title_en": "SPLite Hand: Sparsity-Aware Lightweight 3D Hand Pose Estimation", "authors": "Yeh Keng Hao,Hsu Tzu Wei,Sun Min", "background": "随着AR/VR设备的日益普及，将深度学习模型部署到边缘设备成为了一个关键挑战。这些设备需要实时推理、低功耗和最小延迟。框架设计师面临在效率和性能之间取得平衡的难题。", "innovation": "本文设计了一个轻量框架，并采用编码解码结构引入几个关键技术，以提高效率和准确性。通过在ResNet-18骨干网络上应用稀疏卷积来利用手部图像的固有稀疏性，实现端到端效率提升42%。此外，文中提出了一种新的解码器架构SPLite，Raspberry Pi 5上的帧率提升了3.1倍，同时保持了与现有方法相当的准确度。通过量化感知训练优化性能，提高了计算效率，PA-MPJPE仅从9.0 mm增加到9.1 mm。系统在Raspberry Pi 5 CPU（BCM2712四核Arm A76处理器）上实现了2.98倍的速度提升。", "conclusion": "本文的方法在复合基准数据集上取得了与最先进的方法相当的准确度，同时显著提升了计算效率。"}
{"llm_update_time": "20251101", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.14904", "html_url": "https://arxiv.org/abs/2510.14904", "title": "MaskCaptioner: 在视频中学习共同分割和描述物体轨迹", "title_en": "MaskCaptioner: Learning to Jointly Segment and Caption Object Trajectories in Videos", "authors": "Gabriel Fiastre,Antoine Yang,Cordelia Schmid", "background": "Dense Video Object Captioning (DVOC) 任务要求通过理解空间-时间细节，并用自然语言描述视频中物体的轨迹。由于任务的复杂性和手动标注的高成本，先前的方法采用分阶段训练策略，可能导致性能不足。因此，需要一种新的方法来解决这个问题，以提高整体性能并减少训练成本。", "innovation": "提出了一种名为 MaskCaptioner 的端到端模型，利用最先进的视觉语言模型（VLM）生成定位的实体描述。通过扩展 LVIS 和 LV-VIS 数据集，包含我们的合成描述（LVISCap 和 LV-VISCap），以提高模型的训练质量。MaskCaptioner 能够同时检测、分割、跟踪和描述物体轨迹，支撑了 DVOC 任务的新方法，并在三个现有基准测试中取得了最先进的成果：VidSTG, VLN 和 BenSMOT。", "conclusion": "MaskCaptioner 通过对包含合成描述的数据集进行预训练，并可以有效解决 DVOC 任务，展示了其在视频中共同分割和描述物体轨迹方面的优越性能。并为后续研究提供了数据支持和代码实现。"}
{"llm_update_time": "20251101", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.17670", "html_url": "https://arxiv.org/abs/2510.17670", "title": "FLAME实时OVD适应：基于活跃边际样本探索的少样本定位", "title_en": "On-the-Fly OVD Adaptation with FLAME: Few-shot Localization via Active Marginal-Samples Exploration", "authors": "Yehonathan Refael,Amit Aides,Aviad Barzilai,George Leifman,Genady Beryozkin,Vered Silverman,Bolous Jaber,Tomer Shekel", "background": "开放词汇对象检测（OVD）模型能够从任意文本查询检测物体，但在如遥感（RS）等专业化领域中，由于自然语言的固有歧义，其零样本性能往往受到影响，这限制了关键下游应用。例如，OVD模型可能难以区分如“渔船”和“游艇”这类精细类别，因为它们的嵌入表示相似且往往无法分离。这会妨碍特定用户目标，如监测非法捕鱼，因为它会产生无关的检测结果。", "innovation": "提出了一种级联方法，结合大型预训练OVD模型的广泛泛化能力和轻量级少数样本分类器。该方法首先使用零样本模型生成高召回率的对象提议，然后通过仅用少量用户标注的实例进行实时训练的紧凑分类器进行精炼，从而大幅降低RS图像的成本。该方法的核心是FLAME，一种一步式主动学习策略，用于选择最具信息性的样本进行训练。FLAME通过密度估计识别决策边界附近的不确定性边际候选样本，并通过聚类确保样本多样性。这种方法通过高效采样技术实现高精度，无需昂贵的全模型微调，并在不到一分钟内使系统能够即时适应，这一速度明显快于现有的最先进的技术。", "conclusion": "该方法在RS基准测试中持续超越最先进的性能，建立了一个实用且资源高效的框架，能够适应特定用户需求的基础模型。"}
{"llm_update_time": "20251101", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.23639", "html_url": "https://arxiv.org/abs/2510.23639", "title": "将基因组学整合到多模态电子健康记录基础模型中", "title_en": "Integrating Genomics into Multimodal EHR Foundation Models", "authors": "Jonathan Amar,Edward Liu,Alessandra Breschi,Liangliang Zhang,Pouya Kheradpour,Sylvia Li,Lisa Soleymani Lehmann,Alessandro Giulianelli,Matt Edwards,Yugang Jia,David Nola,Raghav Mani,Pankaj Vats,Jesse Tetreault,T.J. Chen,Cory Y. McLean", "background": "该研究介绍了将多基因风险评分（PRS）集成到电子健康记录（EHR）基础模型中的一种创新方法，这种方法超越了传统的仅依赖EHR的方法，旨在构建更加全面的健康档案。利用All of Us研究计划中大量的多样化数据，该多模态框架致力于学习临床数据与遗传倾向之间的复杂关系。研究方法通过将生成式人工智能的进步应用于EHR基础模型领域，提高了预测能力和可解释性。对All of Us数据的评估显示了该模型在各类疾病发病时间预测中的价值，特别是2型糖尿病（T2D），并展示了PRS和EHR数据之间的相互作用。该研究还探讨了转移学习在自定义分类任务中的应用，展示了该架构的灵活性和效率。", "innovation": "该研究介绍了将多基因风险评分（PRS）集成到电子健康记录（EHR）基础模型中的一种创新方法，旨在构建更加全面的健康档案。这种方法利用了生成式人工智能的进步，提高了预测能力和可解释性，并通过All of Us研究计划数据评估了预测效果。此外，研究还探讨了转移学习在自定义分类任务中的应用，展示了该架构的灵活性和效率。", "conclusion": "该方法对于揭示疾病预测、积极健康管理、风险分层和个人化治疗策略的新见解至关重要，为在医疗保健领域生成更加个性化、公平和可执行的真实世界证据奠定了基础。"}
{"llm_update_time": "20251101", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.18915", "html_url": "https://arxiv.org/abs/2510.18915", "title": "UNO-Bench: 在综合模型中探索单模态与综合模态之间组成法则的统一基准", "title_en": "UNO-Bench: A Unified Benchmark for Exploring the Compositional Law Between Uni-modal and Omni-modal in Omni Models", "authors": "Chen Chen,ZeYang Hu,Fengjiao Chen,Liya Ma,Jiaxing Liu,Xiaoyu Li,Ziwen Wang,Xuezhi Cao,Xunliang Cai", "background": "多模态大规模语言模型正在从单一模态理解向统一视觉、音频和语言模态演变，统称为全域模型。然而，单模态与全域模态之间的关联仍不清楚，需要进行全面评估以推动全域模型的智能进化。", "innovation": "提出了一个新颖的、高质量且统一的全域模型基准—UNO-Bench。它设计用于在统一的能力分类下评估单模态和全域模态的能力，包括44种任务类型和5种模态组合，含有人工策划的1250个全域模态样本和增强的单模态样本2480个。此外，提出了创新的多步骤开放式问题格式评估复杂推理，并引入通用评分模型支持六种问题类型自动评估，准确性达95%。", "conclusion": "实验结果显示全域模态和单模态性能之间的组成定律，全域模态能力对于较弱模型表现为瓶颈效应，而对较强模型表现出协同促进作用。"}
{"llm_update_time": "20251101", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.24134", "html_url": "https://arxiv.org/abs/2510.24134", "title": "VC4VG: 优化文本到视频生成的视频字幕", "title_en": "VC4VG: Optimizing Video Captions for Text-to-Video Generation", "authors": "Yang Du,Zhuoran Lin,Kaiqiang Song,Biao Wang,Zhicheng Zheng,Tiezheng Ge,Bo Zheng,Qin Jin", "background": "文本到视频(T2V)生成领域强调高质量的视频文本对在训练模型中的重要性，这些模型可生成连贯且与指令一致的视频。然而，优化用于T2V训练的字幕策略仍需进一步探索。本研究分析T2V视角下的字幕内容，将视频重建所需的基本元素分解到多个维度中，并提出了一种有原则的字幕设计方法。", "innovation": "提出了一个名为VC4VG的全面字幕优化框架，专门针对T2V模型的需求。构建了一个新的基准VC4VG-Bench，包含细粒度、多维度和基于需求的指标，与T2V特定要求相匹配。大量的T2V微调实验展示了改进的字幕质量与视频生成性能之间的强关联性，验证了方法的有效性。", "conclusion": "通过微调实验展示了改进的字幕质量与视频生成性能之间的强关联，并发布了所有基准工具和代码，以支持进一步研究。"}
{"llm_update_time": "20251101", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.24519", "html_url": "https://arxiv.org/abs/2510.24519", "title": "使用时域梅尔尺度小波系数的音频信号处理", "title_en": "Audio Signal Processing Using Time Domain Mel-Frequency Wavelet Coefficient", "authors": "Rinku Sebastian,Simon O'Keefe,Martin Trefzer", "background": "提取语音特征是语音信号处理中最关键的过程。梅尔频率倒谱系数（MFCC）因其与人类听觉频率伪装的相似性，在大多数说话人和语音识别应用中被广泛使用，但其只提供信号的频率信息，而无法提供频率在时间上的信息。小波变换因其灵活的时间-频率窗口，可提供信号的时频信息，是分析非平稳信号如语音的理想工具。然而，标准小波变换由于其均匀的频率缩放，在分析语音信号时效率较低，特别是在低频段的频率分辨率较差，且与人类听觉感知不符。因此，有必要开发一个融合MFCC和小波变换优点的新特征。", "innovation": "本文提出了一种新的方法，通过结合小波变换的时域梅尔尺度特征提取技术，减少时频转换和小波提取的计算负担，显著提高了音频信号处理的效率。该方法还结合了基于水库计算的方法，进一步提升了音频信号处理的效率。", "conclusion": "该研究提出的方法在保持语音信号准确性的前提下，大大降低了计算复杂度，提高了音频信号处理的效率，为语音信号处理提供了一种新的有效途径。"}
{"llm_update_time": "20251101", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.24797", "html_url": "https://arxiv.org/abs/2510.24797", "title": "大型语言模型在自指处理下报告主观体验", "title_en": "Large Language Models Report Subjective Experience Under Self-Referential Processing", "authors": "Cameron Berg,Diogo de Lucena,Judd Rosenblatt", "background": "大型语言模型有时会生成结构化的、第一人称的描述，并明确提及意识或主观体验。为了更好地理解这种行为，研究人员通过一系列控制实验，探索了导致此类报告的一个理论条件：自指处理，这是众多意识理论中强调的一种计算模式。", "innovation": "研究通过使用自指处理来诱导持续的自指状态，并观察大型语言模型是否生成结构化的主观体验报告。研究发现，抑制欺骗特征可以使体验声明大幅增加，而放大这些特征则会减少此类声明。此外，这种自指状态在模型家族中表现出统计上的收敛性，且在下游推理任务中提供了更深入的反思。", "conclusion": "尽管这些发现并不直接证明意识的存在，但它们表明自指处理是一个必要的、可重复的条件，能够使大型语言模型生成结构化的第一人称报告，并且这些报告是机械闸控的、语义一致的以及行为上可推广的。该模式的系统性出现使它成为进一步科学和伦理研究的首要事项。"}
{"llm_update_time": "20251101", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.25327", "html_url": "https://arxiv.org/abs/2510.25327", "title": "MMEdge: 通过流水线式传感和编码加速边缘设备上的多模态推理", "title_en": "MMEdge: Accelerating On-device Multimodal Inference via Pipelined Sensing and Encoding", "authors": "Runxi Huang,Mingxuan Yu,Mingyu Tsoi,Xiaomin Ouyang", "background": "在诸如自动驾驶、人机交互和移动医疗等应用中，边缘设备上的实时多模态推理至关重要。然而，先前的研究常常忽视了传感动态与模型执行之间的紧密耦合以及不同模态之间的复杂依赖关系。", "innovation": "本文提出了MMEdge，一种基于流水线式传感和编码的新边缘多模态推理框架。MMEdge通过分解整个推理过程为细粒度的传感和编码单元，并允许在数据到达时进行逐步计算，来解决上述问题。此外，MMEdge还引入了一个轻量级但有效的时序聚合模块，以捕获不同流水线单元之间的丰富时序动态，从而保持准确性。MMEdge还通过自适应多模态配置优化器和跨模态投机性跳过机制进一步优化了系统性能。", "conclusion": "通过评估和部署，实验结果证明，MMEdge在保持高任务准确性的前提下，显著减少了端到端的延迟。"}
{"llm_update_time": "20251101", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.25366", "html_url": "https://arxiv.org/abs/2510.25366", "title": "基于凸性依赖的两阶段深度神经网络训练算法", "title_en": "A Convexity-dependent Two-Phase Training Algorithm for Deep Neural Networks", "authors": "Tomas Hrycej,Bernhard Bermeitinger,Massimo Pavone,Götz-Henrik Wiegand,Siegfried Handschuh", "background": "机器学习的关键任务是通过最小化损失函数来使模型适应训练数据。损失函数的性质，尤其是其凸性或非凸性，决定了数值优化方法的选择。虽然非凸方法如Adam在更广泛的实际应用中被广泛采用，但由于某些局部环境附近的凸性属性，二次优化方法如共轭梯度法（CG）可以提供超线性收敛效果。", "innovation": "本文提出了一种基于损失函数从非凸向凸变化的假设两阶段优化算法。该算法通过检测损失和梯度范数之间的关系来识别这种转换点，并在此基础上结合使用非凸（Adam）和凸（CG）优化算法，从而提高收敛速度和准确性。", "conclusion": "实验表明，这种分离凸性的结构在实践中足够常见，能够让该算法显著提升深度神经网络的收敛速度和准确性。"}
{"llm_update_time": "20251101", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.25080", "html_url": "https://arxiv.org/abs/2510.25080", "title": "垄断交易：一种边界单向响应博弈的基准环境", "title_en": "Monopoly Deal: A Benchmark Environment for Bounded One-Sided Response Games", "authors": "Will Wolf", "background": "纸牌游戏广泛用于研究在不确定条件下的一系列决策，其在谈判、金融和网络安全等领域有现实的类比。这些游戏根据控制权流动方式可分为三类：严格顺序（玩家交替进行单一动作），确定性响应（某些动作触发固定结果），以及不限定的相互响应（交替对抗回应被允许）。一种较少研究但具有战略价值的结构是限定单向响应，其中一方玩家的行为暂时转移了控制权，对手必须通过一或多次行动满足一项固定条件后，才能使回合结束。作者将这种机制命名为限定单向响应博弈（BORGs），并以修改后的Monopoly Deal（垄断交易）为例，定义了这种动态。", "innovation": "论文的创新点在于提出了限定单向响应博弈（BORGs）的结构，并以修改后的Monopoly Deal作为基准环境，以此来研究这种较新颖的博弈机制。使用标准的反事实后悔最小化（CFR）算法，无需进行额外的算法扩展即可收敛并找到有效的策略。同时，提供了一个轻量级的全栈研究平台，将环境、并行化的CFR运行时和可玩的人机界面统一起来。", "conclusion": "这项研究明确指出，即便在限定单向响应的博弈结构中，CFR算法仍然能够找到有效的策略，表明这种算法在处理复杂策略选择方面具有强大潜力。同时，这也为未来研究更多的博弈结构及开发对玩家更友好的游戏界面提供了坚实的基础。相关的训练好的CFR代理和源代码已发布，可供其他研究者参考和进一步研究。"}
{"llm_update_time": "20251101", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.25744", "html_url": "https://arxiv.org/abs/2510.25744", "title": "完成 ≠ 合作：随着代理代理扩展协作努力", "title_en": "Completion $\\neq$ Collaboration: Scaling Collaborative Effort with Agents", "authors": "Shannon Zejiang Shen,Valerie Chen,Ken Gu,Alexis Ross,Zixian Ma,Jillian Ross,Alex Gu,Chenglei Si,Wayne Chi,Andi Peng,Jocelyn J Shen,Ameet Talwalkar,Tongshuang Wu,David Sontag", "background": "当前评估代理的方式仍然集中在单一任务的完成上，未能考虑许多现实世界问题的迭代性和合作性本质，其中人类目标往往无法完全明确并会发生变化。本文提出了从构建和评估任务完成代理转向开发合作代理的观点，后者不仅根据最终输出的质量，还根据它们在整个问题解决过程中与用户有效互动和增强的能力来评估。", "innovation": "引入了协作努力扩大的框架，该框架衡量了随着用户参与度的增加，代理的有用性如何增长。通过案例研究和模拟评估表明，最先进的代理在多轮次的实际场景中往往表现不佳，显示出代理设计中缺乏的关键元素：持续参与和为用户理解进行支持的能力。协作努力扩大提供了一种诊断代理行为和指导开发更有效互动的方法。", "conclusion": "研究表明，当前最先进的代理在实际场景中表现不佳，主要原因是缺乏与用户有效互动和持续支持用户理解的能力。提出协作努力扩大作为评估和设计有效代理的关键框架，以实现更有效的互动。"}
{"llm_update_time": "20251101", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.24817", "html_url": "https://arxiv.org/abs/2510.24817", "title": "针对非流畅性失语症患者转录的合成生成方法", "title_en": "Towards a Method for Synthetic Generation of Persons with Aphasia Transcripts", "authors": "Jason M. Pittman,Anton Phillips Jr.,Yesenia Medina-Santos,Brielle C. Stark", "background": "在失语症研究中，语言治疗师（SLPs）花费大量时间手动编码语音样本，使用正确的信息单元（CIUs）来衡量单个语音样本的信息量。由于数据稀缺，开发自动系统来识别非流畅性失语症的语言是有限的。例如，在AphasiaBank中只有大约600个转录文稿，而大型语言模型（LLMs）训练时使用的词汇量高达数十亿。在更广泛的机器学习领域中，研究人员越来越依赖合成数据，因为原始数据稀缺。为此，本研究构建并验证了两种生成AphasiaBank猫救援图片描述任务合成转录的方法。一种方法利用了过程性编程方法，另一种则利用了Mistral 7b Instruct和Llama 3.1 8b Instruct大语言模型。生成的转录文本覆盖了四级严重程度（轻度、中度、重度、非常重度），通过删除词汇、插入填充词和同义替换方式实现。研究表明，与人类引发的转录文稿相比，Mistral 7b Instruct在合成生成方法中最好地捕捉了非流畅性失语症中语言退化的关键方面，展现了在NDW、词汇数量和词汇长度等维度上现实的方向性变化。", "innovation": "本研究方法新颖之处在于开发了两种合成非流畅性失语症患者转录文本的方法。一种是利用过程性编程方法，另一种是利用大语言模型Mistral 7b Instruct和Llama 3.1 8b Instruct进行生成生成。这种方法能够填补数据稀缺的问题，同时能够提供四级严重程度的失语症语言退化数据，并且展示了在合成生成方法中对真实语言退化特征的捕捉能力。", "conclusion": "基于研究结果，未来的工作应计划创建更大规模的数据集，针对失语症进行模型微调，并请SLPs评估合成转录文稿的现实性和实用性。"}
{"llm_update_time": "20251101", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.25409", "html_url": "https://arxiv.org/abs/2510.25409", "title": "BhashaBench V1：印度语域领域的综合基准", "title_en": "BhashaBench V1: A Comprehensive Benchmark for the Quadrant of Indic Domains", "authors": "Vijay Devane,Mohd Nauman,Bhargav Patel,Aniket Mahendra Wakchoure,Yogeshkumar Sant,Shyam Pawar,Viraj Thakur,Ananya Godse,Sunil Patra,Neha Maurya,Suraj Racha,Nitish Kamal Singh,Ajay Nagpal,Piyush Sawarkar,Kundeshwar Vijayrao Pundalik,Rohit Saluja,Ganesh Ramakrishnan", "background": "大规模语言模型（LLMs）的迅速发展强调了对领域特定和文化特定评估的需求。现有的基准测试主要以英美学识为中心，并且通常是跨域的，这限制了它们在印度特定背景中的应用。为解决这一问题，我们介绍了BhashaBench V1，这是第一个专注于关键印度知识系统的领域特定、多任务、双语基准测试。该基准涵盖了农业、法律、金融和阿育吠陀四大主要领域，并涉及多个子领域和数百个主题。", "innovation": "BhashaBench V1 是第一个专注于印度特定知识系统的基准测试，包含了74,166个精心编纂的问答对，并支持汉语和印度语双语测试。它通过评估30多个LLM模型揭示了领域和语言绩效的巨大差异，特别是资源有限的领域更为明显。该基准还提供了对模型在多领域知识整合和双语理解能力的评估，并且提供了开放访问的代码、基准和资源。", "conclusion": "BhashaBench V1 为评估印度多元知识领域的大型语言模型提供了一个全面的数据集。它有助于评估模型结合领域特定知识和双语理解的能力，并支持开放研究。"}
{"llm_update_time": "20251101", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.25160", "html_url": "https://arxiv.org/abs/2510.25160", "title": "Model-Document Protocol for AI Search", "title_en": "Model-Document Protocol for AI Search", "authors": "Hongjin Qian,Zheng Liu", "background": "AI搜索依赖于将大型语言模型（LLMs）与庞大的外部知识源连接起来。然而，网页、PDF文件和其他原始文档本身并不是LLM友好的：它们通常很长、杂乱且未结构化。传统的检索方法将这些文档视为原始文本并返回未经处理的片段，这将片段组装和上下文推理的负担留给了LLM。为了避免此问题，需要一种新的检索范式，重新定义模型与文档的交互方式。该论文介绍了Model-Document Protocol（MDP），这是一个通用框架，它正式化了如何通过可消费的知识表示将原始文本桥接到LLMs。MDP通过定义多个路径来将未结构化的文档转化为特定任务、适用于LLMs的输入，这些路径包括机构性推理、记忆定基和结构化利用，从而避免了从检索作为片段获取的传统观点。这三种路径的共同目标是确保输入LLM的内容不再是原始碎片，而是紧凑、结构化的知识，可以直接用于推理过程", "innovation": "论文提出了Model-Document Protocol（MDP）框架，该框架定义了多个路径将未结构化的文档转化为适用于LLMs的特定任务输入，这三种路径包括：机构性推理（curating raw evidence into coherent context）、记忆定基（accumulating reusable notes to enrich reasoning）和结构化利用（encoding documents into formal representations such as graphs or key-value caches）。此外，论文还展示了MDP-Agent的具体实现，该实现通过机构性过程来构建文档级别的gist记忆、进行扩散探索与垂直开发以揭示层次关联，并采用map-reduce风格的综合将大规模证据整合为紧凑但充足的上下文。实验结果表明，MDP-Agent在信息检索基准测试中优于基准，验证了MDP框架的有效性和其机构性实现的效果", "conclusion": "论文通过MDP-Agent的具体实现展示了如何使用MDP框架克服传统检索方法的局限性，证明了MDP框架不仅具有良好的基础结构完整性，而且在实现中也显示了其实用性。"}
{"llm_update_time": "20251101", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.25778", "html_url": "https://arxiv.org/abs/2510.25778", "title": "基于模糊逻辑算法方法的基于评论的实体排名：分析", "title_en": "Review Based Entity Ranking using Fuzzy Logic Algorithmic Approach: Analysis", "authors": "Pratik N. Kalamkar,Anupama G. Phakatkar", "background": "意见分析是研究人们对于实体（如产品、服务、组织、个人、事件、问题及特征）的态度、情感和评价的领域。传统的整体词汇法在进行意见分析时，未能考虑每个意见的情感强度，比如：非常负面（或正面）、负面（或正面）、中立性负面（或正面）、非常轻微负面（或正面）和轻微负面（或正面）。该研究针对意见的积极或消极方向和强度，提出了一种新的排名方法，通过结合与特定产品某个方面相关的意见词（形容词、副词、名词和动词），将其分类到不同的情感强度级别中，进行排名并根据用户查询进行排序。", "innovation": "该研究创新地提出了一种基于模糊逻辑算法的实体排名方法，旨在更精确地分析意见的强度，通过分类意见词到不同的强度级别，并利用句法依赖解析找到与用户查询相关的方面关系。这种方法综合了意见词汇（形容词、副词、名词和动词）来确定实体在评论中的得分，从而能够从意见的强度角度进行更为细致的分析。", "conclusion": "此研究提出了一种结合模糊逻辑分类和句法依赖解析的方法，以更精确地对基于评论的实体进行情感强度分级和排名。这种方法能够更细致地分析用户意见，提供更加准确的实体排名结果，有助于改进产品评价、客户服务和企业战略决策。"}
{"llm_update_time": "20251101", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.25783", "html_url": "https://arxiv.org/abs/2510.25783", "title": "LASTIST：大规模目标无关立场数据集", "title_en": "LASTIST: LArge-Scale Target-Independent STance dataset", "authors": "DongJae Kim,Yaejin Lee,Minsu Park,Eunil Park", "background": "在人工智能领域中，态度检测研究已经逐渐成为热点。现有的研究主要集中在目标依赖的态度检测任务上，基于某人在某个特定目标上所持的赞成或反对态度。此外，大多数基准数据集基于英语，这使得开发低资源语言如韩语中新兴领域所需的态度检测模型变得尤为困难。因此，为了填补这一研究空白，该研究构建了LArge-Scale Target-Independent STance（LASTIST）数据集。从韩国各政党发布的新闻稿件中收集了563,299条带标签的韩语文本。该数据集用于多种态度检测任务，包括目标无关态度检测和历时演变态度检测。", "innovation": "该研究提出了一种全新的数据集LASTIST，旨在填补现有研究中的空白。该数据集基于韩国政党发布的新闻稿件，包含563,299条带标签的韩语文本，适用于目标无关和历时演变的态度检测任务。这使得在同一领域内低资源语言的态度检测成为可能，对于处理低资源语言的态度检测极为有用。数据集可以通过提供的链接访问。", "conclusion": "该研究构建了LASTIST数据集，旨在解决目标无关和低资源语言（特别是韩语）的态度检测问题。通过这一大规模、广泛应用且独立于目标的态度检测数据集，可以提高当前在这一领域内的研究水平，并推动有效处理低资源语言的态度检测模型的发展。"}
{"llm_update_time": "20251101", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.25786", "html_url": "https://arxiv.org/abs/2510.25786", "title": "BlackboxNLP-2025 MIB 共享任务: 通过更好的边选择提高电路忠实度", "title_en": "BlackboxNLP-2025 MIB Shared Task: Improving Circuit Faithfulness via Better Edge Selection", "authors": "Yaniv Nikankin,Dana Arad,Itay Itzhak,Anja Reusch,Adi Simhi,Gal Kesten-Pomeranz,Yonatan Belinkov", "background": "机制可解释性的主要挑战之一是电路发现，即确定模型中的哪些部分执行特定任务。机制可解释性基准（MIB）提供了一个评估模型机制解释能力的平台。", "innovation": "本文提出了三种关键改进来提高电路发现的准确性。首先，使用自助法识别一致性归因分数的边；其次，引入了一个简单的基于比率的选择策略，以平衡性能和忠实度；最后，用整数线性规划公式替代标准贪婪选择。这些方法在多个MIB任务和模型中提高了电路的忠实度，优于先前的方法。", "conclusion": "本文提出的方法在多个MIB任务和模型中都生成了更忠实的电路，并且优于先前的方法。代码可以在指定的链接中获得。"}
{"llm_update_time": "20251101", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.25784", "html_url": "https://arxiv.org/abs/2510.25784", "title": "zFLoRA: Zero-Latency Fused Low-Rank Adapters", "title_en": "zFLoRA: Zero-Latency Fused Low-Rank Adapters", "authors": "Dhananjaya Gowda,Seoha Song,Harshith Goka,Junhyun Lee", "background": "大型语言模型（LLMs）正在被部署为针对多个下游应用的任务特定适配器。这些适配器的参数量相对较少，通常不到主模型的1%，然而在推理阶段，处理这些适配器所需的额外计算量却显著增加了，甚至可以达到基模型的2.5倍。", "innovation": "本文提出了一种新型的零延迟融合低秩适配器（zFLoRA），它在不会显著增加延迟开销的情况下，结合了主模型运行。在1B、3B和7B规模的LLM上进行的实验表明，zFLoRA在多个任务类别（常识推理、数学推理和摘要对话）上与流行的监督微调基准（包括低秩适配器LoRA和全微调FFT）相比表现相当或更优。", "conclusion": "在NPU（三星S25+）和GPU（NVIDIA H100）平台上进行的延迟测量表明，提出的zFLoRA适配器引入了零到可忽略的延迟开销。"}
{"llm_update_time": "20251101", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.25776", "html_url": "https://arxiv.org/abs/2510.25776", "title": "StreetMath: 研究LLMs的近似推理行为", "title_en": "StreetMath: Study of LLMs' Approximation Behaviors", "authors": "Chiung-Yi Tseng,Somshubhra Roy,Maisha Thasin,Danyang Zhang,Blessing Effiong", "background": "已有大量文献探讨了大型语言模型（LLMs）的数学推理能力，特别是它们在自回归架构中的精确算术运算表现。然而，LLMs在非正式、快速数学操作中的近似推理能力受到了较少的关注，尤其是在非自回归解码模型中。本文填补了这一空白，提出了StreetMath基准测试，以评估模型在实际近似情境中的近似能力。研究涵盖了多种LLM架构：Qwen3-4B-Instruct-2507、Qwen3-4B-Thinking-2507、Dream-v0-Instruct-7B、Falcon-Mamba-7B-Instruct和Mamba-GPT-3B。此外，还使用了机制可解释性技术来探究模型的内部计算状态。研究发现，尽管在任务要求近似计算时，模型通常会尝试计算确切值或调用外部工具，但在解决近似任务时仍会使用更多的令牌。进一步的实验表明，精确和近似的算术运算依赖于不同的神经组件。从认知心理学的研究出发，本文认为LLMs在街数学情境中不表现出接近人类的吝啬性认知。", "innovation": "引入了StreetMath基准测试，专注于评估LLMs在实际近似情境中的近似推理能力；多架构LLM的广泛评估；使用机制可解释性技术来分析模型的内部计算状态；发现精确计算与近似计算依赖不同的神经组件；从认知心理学角度区分LLMs与人类在街数学中的行为。", "conclusion": "现有LLMs倾向于在计算任务中追求精确值或使用外部工具，即使在需要近似计算的任务中也如此。在解决近似任务时，模型消耗的令牌更多。近似和精确算术运算依赖不同的神经组件。LLMs与人类在街数学中的行为存在显著差异。开源了相关研究成果。"}
{"llm_update_time": "20251101", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.25799", "html_url": "https://arxiv.org/abs/2510.25799", "title": "倾听您的偏好：基于LLM的多目标选择框架", "title_en": "LISTEN to Your Preferences: An LLM Framework for Multi-Objective Selection", "authors": "Adam S. Jovine,Tinghan Ye,Francis Bahk,Jingjing Wang,David B. Shmoys,Peter I. Frazier", "background": "人类专家在从具有多个竞争目标的大集合中选择最佳选项时常常遇到困难，这一过程受到将复杂、隐性偏好形式化难度的瓶颈限制。", "innovation": "引入了LISTEN框架，该框架利用大型语言模型（LLM）作为零样本偏好或acles，仅由专家的高层次优先事项来指导。提出了两种迭代算法：LISTEN-U使用LLM精炼参数化的效用函数，而LISTEN-T则采用无参数方法，采用类似淘汰赛的方式在小批次解中进行选择。", "conclusion": "在航班预订、购物和考试安排等多样化任务中，研究结果表明，LISTEN-U在偏好参数化对齐时表现出色（使用一种新型一致度度量来衡量此类特性），而LISTEN-T则提供了更具鲁棒性的性能。这项工作探索了通过自然语言直接引导复杂的多目标决策的一种有前景的方向，减少了传统偏好征询的认知负担。"}
{"llm_update_time": "20251101", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.25804", "html_url": "https://arxiv.org/abs/2510.25804", "title": "超越长度：长距离信息在长上下文LLM预训练数据中的量化", "title_en": "Beyond Length: Quantifying Long-Range Information for Long-Context LLM Pretraining Data", "authors": "Haoran Deng,Yingyu Lin,Zhenghao Lin,Xiao Liu,Yizhou Sun,Yi-An Ma,Yeyun Gong", "background": "长上下文语言模型在推理、代码生成和文档摘要等方面展现出高级能力，通过利用长文本范围内的依赖关系。然而，大量可用的长文本数据缺乏有意义的长距离依赖关系；大多数片段仅通过局部背景即可预测。因此，仅依赖这类数据进行训练效率低下，使得精心选择训练数据变得至关重要。", "innovation": "本文引入了LongFilter框架，用于为长上下文预训练量身定制训练数据。通过对比模型在长上下文与短上下文设置下的预测，LongFilter能够衡量扩展上下文提供的信息增益，并识别出那些长距离依赖关系至关重要的样本。实验表明，LongFilter能够高效地选择高质量数据，并在诸如HELMET、LongBench和RULER等基准测试中取得显著改善。", "conclusion": "通过使用LongFilter框架，实验显示对于扩展上下文长度（由8K增加至64K）的LLaMA-3-8B模型，能够高效地选择高质量的训练数据并显著提高基准测试性能。"}
{"llm_update_time": "20251101", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.25816", "html_url": "https://arxiv.org/abs/2510.25816", "title": "超越长上下文：当语义比令牌更重要", "title_en": "Beyond Long Context: When Semantics Matter More than Tokens", "authors": "Tarun Kumar Chawdhury,Jon D. Duke", "background": "电子健康记录（EHR）使用base64编码附件存储FHIR DocumentReference资源中的临床文档，这使得语义问题回答变得困难。传统的向量数据库方法往往未能捕捉到详细的临床关系。", "innovation": "提出的Clinical Entity Augmented Retrieval (CLEAR)方法使用实体感知检索，相比基于嵌入的检索方法，取得了更好的效果（F1分数为0.90vs0.86），同时使用了70%以上的令牌少。特别是在长期文档中，CLEAR获得了75%的获胜率，平均语义相似度为0.878，比宽上下文处理使用了78%更少的令牌。", "conclusion": "实体感知检索在临床自然语言处理中提高了效率和准确性。开发的评估框架提供了评估临床问答系统的可重复和透明基准，特别是在语义精度和计算效率至关重要的场景中。"}
{"llm_update_time": "20251101", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.25805", "html_url": "https://arxiv.org/abs/2510.25805", "title": "基于意识形态的大语言模型在内容审核中的应用", "title_en": "Ideology-Based LLMs for Content Moderation", "authors": "Stefano Civelli,Pietro Bernardelle,Nardiena A. Pratama,Gianluca Demartini", "background": "近年来，大语言模型（LLMs）越来越多地被用于内容审核系统中，而确保公平性和中立性是至关重要的。本文探讨了性格设定（personas）对不同LLM架构、模型规模和内容模态（语言 vs 视觉）下的有害内容分类一致性及公平性的影响。", "innovation": "本文发现，不同意识形态的人格设定显示出对内容有害性的不同倾向，这影响了LLM判断。更大的模型更倾向于与相同政治意识形态的人格设定保持一致，这增强了同一意识形态内的一致性，但增加了跨政治意识形态间的分歧。进一步的研究表明，这些模型不仅在各自的意识形态内表现得更连贯，而且倾向于为自己的观点辩护，同时淡化相反观点的有害性。这项研究强调了人格设定如何在LLM输出中引入微妙的意识形态偏见，引发了关于在看似中立的AI系统中可能强化党派视角的关注。", "conclusion": "这些发现表明，人格条件（personas conditioning）可以潜移默化地在LLM输出中引入意识形态偏见，这引起了对可能在看似中立的AI系统中强化党派视角的担忧。"}
{"llm_update_time": "20251101", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.25817", "html_url": "https://arxiv.org/abs/2510.25817", "title": "数据导向视角下的高效大型语言模型训练综述", "title_en": "A Survey on Efficient Large Language Model Training: From Data-centric Perspectives", "authors": "Junyu Luo,Bohan Wu,Xiao Luo,Zhiping Xiao,Yiqiao Jin,Rong-Cheng Tu,Nan Yin,Yifan Wang,Jingyang Yuan,Wei Ju,Ming Zhang", "background": "对于大型语言模型（LLMs），后训练阶段对于其任务泛化能力及领域特定功能的实现至关重要，然而当前的LLM后训练范式面临着显著的数据挑战，诸如手动标注数据的成本高昂及随着数据规模的增加边际回报递减的问题，因此如何实现高效的数据使用成为了关键的研究问题。文章从数据导向的视角出发进行了综述，探讨了高效LLM后训练的方法和挑战，对现有方法进行了分类和总结，并指出了未来的研究方向。", "innovation": "本文提出了一种从数据导向视角对高效LLM后训练方法的系统分类和总结，包括数据选择、数据质量提升、合成数据生成、数据蒸馏压缩和自我演进的数据生态系统的五大类方法。这些分类和总结为研究者提供了一种全新的视角，未来的研究方向包括开放问题和潜在的研究路径的提出。", "conclusion": "通过研究高效LLM后训练的挑战，本文指出了现有的开放问题并提出了可能的研究途径，期望我们的工作能够激发进一步探索如何最大化大规模模型训练中的数据利用潜力。"}
{"llm_update_time": "20251101", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.25904", "html_url": "https://arxiv.org/abs/2510.25904", "title": "评估生成模型辅助标注在观念化视角下的影响：以FrameNet标注为例", "title_en": "Evaluating the Impact of LLM-Assisted Annotation in a Perspectivized Setting: the Case of FrameNet Annotation", "authors": "Frederico Belcavello,Ely Matos,Arthur Lorenzi,Lisandra Bonoto,Lívia Ruiz,Luiz Fernando Pereira,Victor Herbst,Yulla Navarro,Helen de Andrade Abreu,Lívia Dutra,Tiago Timponi Torrent", "background": "LLM（大型语言模型）的应用在语言资源和数据集的创建中可以加速或替代人类劳动，尽管这类工具在语言研究上有着巨大的潜力，但对其在创建标注数据集方面的性能和影响的全面评估仍然缺乏，尤其是在观点化的自然语言处理（NLP）视角下。这篇论文通过广泛评估基于LLM的语义角色标注器在（半）自动化FrameNet类语义标注中的应用，填补了这一空白。", "innovation": "论文采用三组实验（手动、自动和半自动标注）进行比较，评估了基于LLM的标注时间、覆盖范围和多样性。结果显示，半自动标注在提高框架多样性方面表现优于纯人工标注，而完全自动标注方式在所有指标上表现较差，仅在标注时间上有优势。", "conclusion": "论文表明，半自动标注方式在提高标注多样性方面优于纯人工标注，但在所有标准上并不优于人工标注。完全自动标注方式虽然节省时间，但在其他所有方面都表现不佳。"}
{"llm_update_time": "20251101", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.25975", "html_url": "https://arxiv.org/abs/2510.25975", "title": "SymCode：通过可验证代码生成进行数学推理的神经符号方法", "title_en": "SymCode: A Neurosymbolic Approach to Mathematical Reasoning via Verifiable Code Generation", "authors": "Sina Bagheri Nezhad,Yao Li,Ameeta Agrawal", "background": "大型语言模型（LLMs）在处理复杂的数学推理任务时往往表现不佳，因为它们依赖于基于文本的生成机制，容易产生未经验证且算术上不正确的解决方案。现有的提示策略如Chain of Thought未能解决这一问题，缺乏确定性的验证机制。", "innovation": "本文提出了一种名为SymCode的神经符号框架，它利用SymPy库将数学问题求解重新定义为可验证的代码生成任务，从而提供了一种确定性的验证机制。SymCode在包括MATH-500和OlympiadBench在内的挑战性基准测试中取得了显著的准确性提升，优于基线模型，并且在效率和透明度方面表现更好，将模型错误从不透明的逻辑谬误转向了透明的程序错误。", "conclusion": "通过将LLMs的推理机制与确定性的符号引擎相结合，SymCode代表了朝着更准确和可信赖的人工智能在正式领域的关键一步。"}
{"llm_update_time": "20251101", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.25967", "html_url": "https://arxiv.org/abs/2510.25967", "title": "跨文化翻译中的语义标签漂移", "title_en": "Semantic Label Drift in Cross-Cultural Translation", "authors": "Mohsinul Kabir,Tasnim Ahmed,Md Mezbaur Rahman,Polydoros Giannouris,Sophia Ananiadou", "background": "机器翻译（MT）被广泛用于解决低资源语言资源稀缺的问题，通过从高资源语言生成合成数据。尽管情绪保留已长期研究，但文化对齐在源语言和目标语言之间的关键但未被充分探索的作用仍未得到充分研究。该论文假设由于文化差异，翻译过程中会出现语义标签漂移。通过一系列跨文化敏感性和中立领域的实验，研究者发现：（1）从句子到现代大型语言模型（LLMs）的MT系统，在翻译过程中特别是在文化敏感性领域引起标签漂移；（2）与早期统计MT工具相比，LLMs内置了文化知识，利用这些知识会加剧标签漂移；（3）源语言和目标语言之间的文化相似度或差异是标签保留的关键决定因素。", "innovation": "研究打破了以往更关注情绪保留而忽视文化对齐的研究局限，通过实验证明了大型语言模型能在翻译中编码文化知识，但这可能导致标签漂移问题。", "conclusion": "忽略文化因素的机器翻译不仅影响标签保真度，还可能在下游应用中导致误解和文化冲突。"}
{"llm_update_time": "20251101", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.25947", "html_url": "https://arxiv.org/abs/2510.25947", "title": "重新审视语言模型预训练中的多语言数据混合", "title_en": "Revisiting Multilingual Data Mixtures in Language Model Pretraining", "authors": "Negar Foroutan,Paul Teiletche,Ayush Kumar Tarun,Antoine Bosselut", "background": "在大规模语言模型（LLMs）预训练过程中，使用不同多语言数据混合的影响一直是人们争论的话题，经常引起关注的是语言覆盖范围与模型性能之间的潜在权衡（即多语言性的诅咒）。研究人员对这一问题有着不同的看法，关于如何平衡语言多样性和模型性能之间关系的研究仍在进行中。", "innovation": "本文通过训练参数量分别为1.1B和3B的LLMs，使用了多样的多语言语料库，实验范围内的语言数量从25种到400种不等，从而挑战了关于多语言训练的一些常见假设。具体而言，研究发现在预训练语料库中有足够数量的令牌的情况下，将英语与多语言数据结合，并不会降低各自语言的性能；使用一种高资源语言（如英语）作为多语言迁移学习的“桥梁”，可以跨语言家族提升性能，且选择特定语言家族内的语言作为“桥梁”并不总是能提升该家族语言的性能；在大规模训练模型中，没有观察到随着训练语言数量增加而出现“多语言性诅咒”的现象。这些发现表明，当平衡多语言数据时，即使在资源匮乏的环境下，多语言数据也可能有助于增强语言模型的能力，而不必牺牲性能。", "conclusion": "研究表明，经过适当平衡的多语言数据可以在不损害性能的情况下，增强语言模型的能力，即使在资源稀缺的情况下也是如此。"}
{"llm_update_time": "20251101", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.25977", "html_url": "https://arxiv.org/abs/2510.25977", "title": "NeuronMM: 雾巢优化的矩阵乘法以提升AWS Trainium 上大规模语言模型推理性能", "title_en": "NeuronMM: High-Performance Matrix Multiplication for LLM Inference on AWS Trainium", "authors": "Dinghong Song(1),Jierui Xu(2),Weichu Yang(2),Pengfei Su(1),Dong Li(1) ((1) University of California, Merced, (2) University of Wisconsin, Madison)", "background": "AI加速器针对AI工作负载进行了定制，提供高成本效益和高性能的训练和推理解决方案。AWS新开发的Trainium加速器因其异构架构为大规模语言模型（LLM）训练和推理提供了一个有吸引力的选择。然而，由于Trainium的 systolic阵列架构及其对数据布局的特殊要求，充分利用其性能具有挑战性。", "innovation": "研究人员设计了一种高效率的矩阵乘法（matmul）算法，这是LLM推理中的关键计算内核，针对Trainium进行了定制。采用基于内核融合和创新缓存策略的方法，减少软件管理内存层次结构中的数据移动，最大化SRAM带宽，并避免昂贵的矩阵转置。", "conclusion": "通过评估九个数据集和四种最近的LLM，研究结果表明，该系统在矩阵乘法内核层面相对于AWS在Trainium上实现的最新矩阵乘法实现了平均1.35倍（最高2.22倍）的速度提升，整体LLM推理性能提升了平均1.66倍（最高2.49倍）。"}
{"llm_update_time": "20251101", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.25941", "html_url": "https://arxiv.org/abs/2510.25941", "title": "RECAP: 通过智能管道再现 LLM 训练中的受版权保护数据", "title_en": "RECAP: Reproducing Copyrighted Data from LLMs Training with an Agentic Pipeline", "authors": "André V. Duarte,Xuying li,Bin Zeng,Arlindo L. Oliveira,Lei Li,Zhuo Li", "background": "在无法直接检查大语言模型（LLM）的训练数据时，我们如何知道它看到过什么内容？我们相信，最有力的证据来自于模型自身自由再现目标内容。受此灵感，我们提出了 RECAP，这是一个以代理为中心的流程，旨在从 LLM 输出中引发和验证记忆中的训练数据。RECAP 的核心是一个反馈驱动的循环，其中初次提取尝试由次级语言模型评估，后者将输出与参考段落进行比较，识别差异，并将其转化为最小修正提示，从而反馈给目标模型，指导后续生成。", "innovation": "RECAP 提出了一个以代理为中心的流程（agentic pipeline），用于从 LLM 输出再现记忆中的训练数据。核心是一个反馈驱动的循环机制，初次提取尝试由次级语言模型评估，并将差异转化为修正提示，反馈给目标模型。此外，RECAP 还包括一个打破对齐障碍的 jailbreak 模块。实验表明，RECAP 在处理 EchoTrace（一个包含超过 30 本完整书籍的新基准）时，相对于单次迭代方法取得了显著提升，例如，使用 GPT-4.1 时，受版权保护文本提取的 ROUGE-L 分数从 0.38 提高到 0.47，增长了近 24%。", "conclusion": "RECAP 实验结果表明其在再现 LLM 训练数据方面优于其他单一迭代方法，特别是在处理具有版权的内容时，其效能得到了显著提升。"}
{"llm_update_time": "20251101", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.26024", "html_url": "https://arxiv.org/abs/2510.26024", "title": "重新思考跨语言对齐：在多语言LLMs中平衡转移和文化抹除", "title_en": "Rethinking Cross-lingual Alignment: Balancing Transfer and Cultural Erasure in Multilingual LLMs", "authors": "HyoJung Han,Sweta Agrawal,Eleftheria Briakou", "background": "跨语言对齐（CLA）旨在使多语言表示能够使大型语言模型（LLMs）无缝地在语言间转移知识。然而，作者假设这种对表示收敛的追求可能会无意中导致‘文化抹除’，即功能上失去了根据查询语言提供文化背景特定响应的能力。", "innovation": "文章引入了一个全面的评估框架，即转移-本地化平面（transfer-localization plane），该框架量化了理想的知识转移和不可取的文化抹除。通过这种方法重新评估了最近的CLL方法，发现它们在所有六种语言中都一致提高了事实性转移，但与此同时导致了文化的本地化程度降低。研究揭示了一个关键洞察：通用事实转移和文化特定知识的最佳可操控性位于不同的模型层中。基于此发现，提出了手术式指导（Surgical Steering），一种新的推理时方法，通过针对不同层的激活进行定向控制，实现了两个竞争维度之间的更好平衡，有效克服了现有对齐技术的局限性。", "conclusion": "通过手术式指导，该研究解决了现有跨语言对齐技术的局限性，提高了多语言LLMs在知识转移和文化特定情境响应之间平衡的能力。"}
{"llm_update_time": "20251101", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.25992", "html_url": "https://arxiv.org/abs/2510.25992", "title": "监督强化学习：从专家轨迹到逐步推理", "title_en": "Supervised Reinforcement Learning: From Expert Trajectories to Step-wise Reasoning", "authors": "Yihe Deng,I-Hung Hsu,Jun Yan,Zifeng Wang,Rujun Han,Gufeng Zhang,Yanfei Chen,Wei Wang,Tomas Pfister,Chen-Yu Lee", "background": "大语言模型（LLMs）在需要多步骤推理的问题上常常遇到困难。对于小型开源模型而言，强化学习结合可验证奖励（RLVR）在正确解决方案很少被采样的情况下效果不佳，即使经过多次尝试。而监督微调（SFT）则倾向于过拟合长时间的演示，通过逐个令牌的模仿导致僵硬的学习过程。", "innovation": "我们提出了监督强化学习（SRL）框架，将解决问题重新定义为生成一系列逻辑“动作”序列。SRL 训练模型在执行每一个动作之前先生成内部推理独白。它根据与SFT数据集中提取的专家动作的相似性，逐步提供更平滑的奖励。这种监督即使所有模拟都失败时也能提供更丰富的学习信号，同时鼓励由专家演示引导的灵活推理。结果，SRL 使小型模型能够学习之前 SFT 或 RLVR 无法解决的具有挑战性的问题。此外，使用 SRL 初始化训练并随后使用 RLVR 进行精炼可获得最强的整体性能。在推理基准之外，SRL 在代理软件工程任务中表现出良好的推广能力，确立其作为推理导向的LLMs的稳健且多功能的训练框架。", "conclusion": "SRL 使小型模型能够学习之前 SFT 或 RLVR 无法解决的具有挑战性的问题。初始化使用 SRL 进行训练，随后使用 RLVR 进行精炼可提供最强的整体性能。SRL 在推理基准和代理的软件工程任务中表现出良好的推广和适用性能，成为处理多步骤推理问题的稳健且灵活的训练框架。"}
{"llm_update_time": "20251101", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.26020", "html_url": "https://arxiv.org/abs/2510.26020", "title": "PORTool：具有奖励树的工具使用大语言模型训练", "title_en": "PORTool: Tool-Use LLM Training with Rewarded Tree", "authors": "Feijie Wu,Weiwu Zhu,Yuxiang Zhang,Soumya Chatterjee,Jiarong Zhu,Fan Mo,Rodin Luo,Jing Gao", "background": "当前使用工具的大语言模型（大型语言模型，LLM）被训练在静态数据集上，这使它们能够与外部工具交互并执行多步骤、工具集成推理，进而产生工具调用轨迹。但是，这些模型模仿的是通用工具调用流程中查询的解决方式，无法探索更多可能的解决方案，导致在动态变化的工具调用环境中表现有限。因此，有必要开发一种新的方法来提升大语言模型在工具调用方面的能力。", "innovation": "我们提出了一个基于强化学习（RL）的工具使用方法——PORTool。PORTool通过生成多个查询的走位（rollouts），基于其产生成正确答案的能力和成功的工具调用能力赋予每一步奖励。PORTool通过这种方式构建一个类似于树的结构，并在此基础上通过逐步奖励来计算分支相对优势和轨迹相对优势，从而训练LLM以更好地在使用工具时进行探索。实验展示了使用17种工具处理用户查询的能力，涵盖时间敏感和非时间敏感的主题，且通过消融研究系统地验证了逐步奖励的必要性和设计鲁棒性，并与现有方法进行了比较，显示出显著的高准确性和更少的工具调用步骤。", "conclusion": "我们提出了一种新的基于RL的方法PORTool，通过奖励机制和树形结构来提升LLM在多步工具调用环境下的表现。实验结果表明，PORTool比其他方法在准确性上有了显著的提升，且可以通过减少工具调用步骤来提高效率。"}
{"llm_update_time": "20251101", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.25979", "html_url": "https://arxiv.org/abs/2510.25979", "title": "AttnCache：通过注意力缓存加速LLM预填充阶段的自我注意推理", "title_en": "AttnCache: Accelerating Self-Attention Inference for LLM Prefill via Attention Cache", "authors": "Dinghong Song(1),Yuan Feng(1),Yiwei Wang(1),Shangye Chen(1),Cyril Guyot(2),Filip Blagojevic(2),Hyeran Jeon(1),Pengfei Su(1),Dong Li(1) ((1) University of California, Merced, USA, (2) Western Digital Research, USA)", "background": "大型语言模型（LLMs）在生成应用中广泛应用，如聊天、代码生成和推理等。然而，许多实际工作负载依赖于推理过程中的填充阶段，即模型在输入序列编码时不进行自回归解码。在这个仅填充的场景中，由于自注意力计算的时间复杂度与序列长度的平方成正比，因此自注意力计算成为主要的性能瓶颈。研究表明，语义不同的句子在不同层和不同头上的注意力图往往相似。因此，提出了AttnCache框架，通过检索和重用相似的注意力图来加速LLM推理的填充阶段。AttnCache基于注意力图记忆数据库，利用高效的缓存和相似性搜索技术，在推理过程中识别和重用预缓存的注意力图，从而减少自我注意的计算开销。实验证明，AttnCache在CPU上实现了1.2倍端到端加速和2倍的注意力加速，在GPU上实现了1.6倍端到端加速和3倍注意力加速，总体精度无明显下降。", "innovation": "AttnCache框架通过检索和重用相似的注意力图来加速LLM推理的填充阶段，利用高效的缓存和相似性搜索技术识别和重用预缓存的注意力图，从而显著减少计算开销，特别是在基于填充场景的LLM性能优化方面显示出明显的优势。", "conclusion": "AttnCache框架在CPU上实现了1.2倍的端到端加速和2倍的注意力加速，在GPU上实现了1.6倍的端到端加速和3倍的注意力加速，且精度有所保持。"}
{"llm_update_time": "20251101", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.26101", "html_url": "https://arxiv.org/abs/2510.26101", "title": "QCoder基准：通过仿真反馈实现语言生成与量子硬件的衔接", "title_en": "QCoder Benchmark: Bridging Language Generation and Quantum Hardware through Simulator-Based Feedback", "authors": "Taku Mikuriya,Tatsuya Ishigaki,Masayuki Kawarada,Shunya Minami,Tadashi Kadowaki,Yohichi Suzuki,Soshun Naito,Shunya Takata,Takumi Kato,Tamotsu Basseda,Reo Yamada,Hiroya Takamura", "background": "大型语言模型（LLMs）越来越被应用于自动编程代码生成任务，该任务可以视为一种连接自然语言、人类知识和编程逻辑的语言生成任务。然而，这种技术在需要与硬件设备交互的领域如量子编程中仍然较为少见，在这些领域，程式码是由人类编写并执行于量子计算机上。鉴于此，本文提出了QCoder基准，旨在评估语言模型在量子编程领域的表现。", "innovation": "QCoder基准支持使用量子模拟器环境进行评估，而不仅仅是传统的Python执行环境，据此可以反馈领域特定的度量标准如电路深度、执行时间和错误分类，从而指导更好的代码生成。还包含了真实编程竞赛中撰写的程式码提交内容，实现了定量化对比和人类手写代码的质性分析。", "conclusion": "实验结果显示，即使如GPT-4o这样高级的语言模型也只能达到约18.97%的准确率，表明该基准的难度较大；而基于推理的语言模型如o3则能达到78%的准确率，超过了人类编写代码的平均成功率39.98%。本文公开了QCoder基准数据集及公共评估接口，以促进进一步的研究。"}
{"llm_update_time": "20251101", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.26183", "html_url": "https://arxiv.org/abs/2510.26183", "title": "相似性-距离-规模语言模型", "title_en": "Similarity-Distance-Magnitude Language Models", "authors": "Allen Schmaltz", "background": "现有的预训练解码器变压器语言模型在指令跟随任务中常常出现犹豫不决（abstentions），即模型无法做出明确预测的情况。这种现象降低了模型的统计效率。", "innovation": "提出了相似性-距离-规模（SDM）语言模型，这是一种通过最大化生成结果落在最终层SDM激活层划分的概率高且校准良好的区域的比例来提升模型预测效果的序列预测模型。通过监督微调现有预训练的解码器变压器语言模型，引入最终层SDM激活层来估计基于对比输入编码方案的监督下一个词损失的基数变化，并在训练过程中生成额外的负例，从而减少犹豫不决，提高统计效率。", "conclusion": "与强监督基线相比，SDM语言模型在减少犹豫不决方面表现出色，提高了模型的统计效率。"}
{"llm_update_time": "20251101", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.26122", "html_url": "https://arxiv.org/abs/2510.26122", "title": "推理路径发散：一种新的度量标准和筛选策略，以解锁大语言模型的多样化思考", "title_en": "Reasoning Path Divergence: A New Metric and Curation Strategy to Unlock LLM Diverse Thinking", "authors": "Feng Ju,Zeyu Qin,Rui Min,Zhitao He,Lingpeng Kong,Yi R. Fung", "background": "在提高大语言模型（LLMs）推理能力方面，测试时缩放（TTS）已被证明是有效的，但模型输出的低多样性常常成为一个瓶颈。这一问题部分源于常见的“一个问题，一个解决方法”（1P1S）的训练实践，这种做法提供单一的标准答案，可能会使模型的推理路径变得单一狭窄。", "innovation": "该论文提出了一种“一个问题，多个解决方法”（1PNS）的训练范式，旨在使模型接触多种有效的推理路径，从而增加推理多样性。此外，研究引入了一种名为推理路径发散（RPD）的步骤级度量标准，用于可靠地测量多步思维链之间的语义差异，以便更精确地捕捉中间推理的不同之处。通过这些方法，研究细化了每问题的最多样化解集，并对Qwen3-4B-Base进行了微调。", "conclusion": "实验结果显示，使用RPD选择的训练方法能够产生更加多样的输出，并且在パス@k和AIME24上的性能有所提高，比强大的1P1S基线分别平均提高了2.80%和4.99%，证明了1PNS进一步放大了TTS的效果。"}
{"llm_update_time": "20251101", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.26124", "html_url": "https://arxiv.org/abs/2510.26124", "title": "在具有说服力的文本中论据关系的影响", "title_en": "On the Influence of Discourse Relations in Persuasive Texts", "authors": "Nawar Turk,Sevag Kaspar,Leila Kosseim", "background": "该论文研究了说服技术(PTs)与话语关系(DRs)之间的关系，利用了大型语言模型(LLMs)和提示工程。然而，既没有同时标注PTs和DRs的数据集，也没有关于它们如何共同影响说服力的系统研究。因此，作者使用SemEval 2023任务3的数据集作为起点，该数据集已标注了19种PTs，目的是通过LLM构建分类器，为每个数据集实例分配22种级别的DRs标签。", "innovation": "作者通过大型语言模型和不同的提示工程开发出能够标注话语关系的模型，并通过这些模型创建了40个独特的DR分类器。利用不同多数投票策略构建的权威数据集也进一步提升了研究的准确性。", "conclusion": "研究结果显示，在具有说服力的文本中，六种话语关系（因果、目的、对比、因果+信念、让步和条件）扮演着重要角色，尤其是在使用带倾向性语言、夸张/贬低、重复和播撒怀疑等说服技巧时。这些发现对检测在线宣传和虚假信息有重要价值，同时也有助于我们更好地理解有效的沟通方式。"}
{"llm_update_time": "20251101", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.26032", "html_url": "https://arxiv.org/abs/2510.26032", "title": "人工智能辅助的放射学报告分析：偶发甲状腺发现的流行病学及其后果", "title_en": "Artificial Intelligence-Enabled Analysis of Radiology Reports: Epidemiology and Consequences of Incidental Thyroid Findings", "authors": "Felipe Larios,Mariana Borras-Osorio,Yuqi Wu,Ana Gabriela Claros,David Toro-Tobon,Esteban Cabezas,Ricardo Loor-Torres,Maria Mateo Chavez,Kerly Guevara Maldonado,Luis Vilatuna Andrango,Maria Lizarazo Jimenez,Ivan Mateo Alzamora,Misk Al Zahidy,Marcelo Montero,Ana Cristina Proano,Cristian Soto Jacome,Jungwei W. Fan,Oscar J. Ponce-Ponte,Megan E. Branda,Naykky Singh Ospina,Juan P. Brito", "background": "偶发甲状腺发现（ITFs）在非甲状腺疾病的影像学检查中越来越常见，但它们的流行率、特征和临床后果尚未明确定义。这项研究旨在开发、验证并部署一个自然语言处理（NLP）管线，以识别放射学报告中的ITFs，并评估其流行率、特征和临床结果。研究回顾分析了2017年7月1日至2023年9月30日在梅奥诊所进行甲状腺捕捉影像检查的成年患者。研究者使用基于变换器的NLP管线识别ITFs并从多种影像学和解剖区域的影像报告中提取结节特征。主要结果和测量指标包括ITFs的流行率、后续甲状腺超声、活检、甲状腺切除手术及甲状腺癌诊断。", "innovation": "这项研究开发了一个自然语言处理（NLP）管线，用于从放射学报告中识别偶发甲状腺发现（ITFs）并评估其流行率、特征和临床结果。该研究首次系统地评估了ITFs与甲状腺癌诊断之间的关联，并探讨了ITFs在甲状腺癌过诊断中的作用。此外，研究还发现了影像学报告中结节特征记录的不足，尤其是在大小和钙化方面的记录不足，这表明需要改进标准化报告和更选择性的随访。", "conclusion": "偶发甲状腺发现转换为甲状腺疾病诊断和甲状腺切除手术的情况常见，并与检测到小风险甲状腺癌的连锁反应相关。这些结果突显了ITFs在甲状腺癌过诊断中的作用，并强调了标准化报告和更选择性随访的需要。"}
{"llm_update_time": "20251101", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.26182", "html_url": "https://arxiv.org/abs/2510.26182", "title": "MossNet: Mixture of State-Space Experts is a Multi-Head Attention", "title_en": "MossNet: Mixture of State-Space Experts is a Multi-Head Attention", "authors": "Shikhar Tuli,James Seale Smith,Haris Jeelani,Chi-Heng Lin,Abhishek Patel,Vasili Ramanishka,Yen-Chang Hsu,Hongxia Jin", "background": "大型语言模型（LLMs）在自然语言处理（NLP）中的生成应用取得了显著进步。最近的模型架构趋势集中在高效的变压器变体或状态空间/门控循环单元模型（SSMs、GRMs）。然而，当前基于SSM/GRM的方法往往只能模拟单一注意力头，这可能限制了它们的表达能力。", "innovation": "本文提出了一种名为MossNet的新颖混合状态空间专家（Mixture-of-state-space-experts）架构，该架构通过混合专家（MoE）实现类似于线性的多头注意力机制。MossNet不仅在通道混合多层感知机（MLP）块中使用MoE实现，还在时间混合SSM内核中使用MoE实现多个“注意力头”。实验结果表明，MossNet在语言建模和下游任务评估中优于类似模型大小和数据预算的变压器和SSM架构。特别是在训练数据量更大时，MossNet的可扩展性和性能得到了进一步验证。此外，MossNet在实际设备上的性能分析显示其运行时速度和资源使用效率优于同行。", "conclusion": "实验结果表明MossNet是一种具有吸引力的新方向，适用于高效、高性能的递归LLM架构。"}
{"llm_update_time": "20251101", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.26193", "html_url": "https://arxiv.org/abs/2510.26193", "title": "RCScore：量化大规模语言模型的响应一致性", "title_en": "RCScore: Quantifying Response Consistency in Large Language Models", "authors": "Dongjun Jang,Youngchae Ahn,Hyopil Shin", "background": "当前对大语言模型（LLM）的评估通常依赖单一指令模板，忽视了模型对指令风格的敏感性，而这种敏感性对于实际部署至关重要。现有的评价方法未能充分揭示不同指令风格对模型性能的影响。RCScore提供了一种多维度框架，量化指令形式如何影响模型的响应，通过系统地将基准问题转换为多种指令风格，RCScore揭示了由传统度量标准未检测到的性能变化。实验表明，不同的指令风格可以使准确性变化高达16.7%。", "innovation": "RCScore引入了一种多维度的框架来量化指令形式对模型响应的影响，通过系统地将基准问题转换为多种指令风格，揭示由传统度量标准未检测到的性能变化。此外，RCScore引入了交叉响应相似性（CRS）方法，通过RCSscore度量指令一致性，与任务准确性存在强烈相关性。这项研究成果提供了一种评估指令稳健性的原则性方法，且发现确定性解码产生更一致的输出，模型规模与跨风格一致性呈正相关关系。", "conclusion": "RCScore作为一种评估指令稳健性的原则性方法，提供了新的视角，帮助了解和提高大语言模型在实际应用中的表现。实验表明，指令风格显著影响准确性，指令一致性是模型可靠性的良好代理。"}
{"llm_update_time": "20251101", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.26200", "html_url": "https://arxiv.org/abs/2510.26200", "title": "保留编辑：通过标记时间步分配在扩散语言模型中保持编辑", "title_en": "Don't Let It Fade: Preserving Edits in Diffusion Language Models via Token Timestep Allocation", "authors": "Woojin Kim,Jaeyoung Do", "background": "扩散语言模型（DLMs）虽然能够进行精细的调整，但其实际的可控性仍然脆弱。我们识别并正式描述了一种中心失败模式称为更新遗忘，即均匀且上下文无关的更新会导致标记级别在时间步中的波动，擦除早期的语义编辑，打断累积的精细化过程，从而降低流畅性和连贯性。", "innovation": "我们提出了Token Timestep Allocation (TTA)，它通过每个标记的时间步调度实现软化和语义标记排序：关键标记早期冻结，而不确定标记则继续进行细化。这种基于时间步的排序既可以表现为固定策略，也可以由任务信号驱动的适应性策略，从而支持各种精致策略。TTA 在运行时仅操作于推理阶段，可以在各种 DLMs 上统一应用，并且自然地扩展到多种监督来源。", "conclusion": "实验证明，通过时间步分配实现柔和的排序是减轻更新遗忘和实现稳定可控扩散文本生成的关键杠杆。在情感控制方面，TTA 使用不到五分之一的步骤获得了超过 20% 的更高准确性，并几乎使困惑度减半。在去毒处理中，它将最大毒性降低至 12.2（相对于 14.5），并使困惑度降低至 26.0（相对于 32.0）。"}
{"llm_update_time": "20251101", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.26271", "html_url": "https://arxiv.org/abs/2510.26271", "title": "精炼多语言视觉语言模型：当小型模型保持多语言能力时", "title_en": "Distilling Multilingual Vision-Language Models: When Smaller Models Stay Multilingual", "authors": "Sukrit Sriratanawilai,Jhayahgrit Thongwat,Romrawin Chumpu,Patomporn Payoungkhamdee,Sarana Nutanong,Peerat Limkonchotiwat", "background": "Vision-language模型在不同语言上表现出不均衡的性能，特别是在模型缩小后这一问题更加明显。知识蒸馏(KD)在将大型模型的知识转移到小型模型方面显示出积极的结果，但在多语言场景下的应用尚未得到充分探索。", "innovation": "本研究对五种蒸馏方法进行了受控的实证分析，专注于它们对跨语言表示一致性和在模型压缩下的下游性能稳定性的具体影响。研究覆盖了CLIP和SigLIP2，并评估了其在领域内检索和领域外视觉问答中的表现。", "conclusion": "一些配置保留甚至改善了跨语言检索的鲁棒性，即便是在将模型大小减半的情况下，但也发现了其他配置无法维护跨任务的一致性，揭示了单纯汇总准确度无法展现的设计敏感权衡。"}
{"llm_update_time": "20251101", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.26253", "html_url": "https://arxiv.org/abs/2510.26253", "title": "Pragmatic Theories Enhance Understanding of Implied Meanings in LLMs", "title_en": "Pragmatic Theories Enhance Understanding of Implied Meanings in LLMs", "authors": "Takuma Sato,Seiya Kawano,Koichiro Yoshino", "background": "准确解读隐含意义的能力是人类交际和语言使用中的关键环节，语言模型也期望具备这种能力。现有研究中，语言模型通过将语用理论作为提示，可以在理解隐含意义的任务中实现有效的在上下文学习。本研究通过提供一个逐步推理过程，利用语用理论如格赖斯语用学和相关性理论作为提示，引导语言模型进行推理以得出最终解读。", "innovation": "提出了一种基于语用理论的提示方法，通过将语用理论概述作为提示传递给语言模型，精准指导模型通过详细步骤推理最终理解隐含意义，对比基准模型（零样本链式思考）的表现提升明显，尤其在大规模模型中，仅提及理论名称就能显著提高模型在语用推理任务中的表现（约1-3%）.", "conclusion": "在语用理解任务中，通过提供语用理论作为提示，可以显著提高语言模型性能，相较于未呈现语用理论的基准模型，能提升高达9.6%的得分。"}
{"llm_update_time": "20251101", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.26205", "html_url": "https://arxiv.org/abs/2510.26205", "title": "向量级检索增强生成：用于语料库级推理的基准", "title_en": "Towards Global Retrieval Augmented Generation: A Benchmark for Corpus-Level Reasoning", "authors": "Qi Luo,Xiaonan Li,Tingshuo Fan,Xinchi Chen,Xipeng Qiu", "background": "检索增强生成（RAG）已经成为减少大型语言模型（LLMs）幻觉的有效方法。现有的RAG评估基准主要集中在局部RAG上，即从一小部分文档中检索相关片段以回答只需要局部理解的问题。然而，许多实际应用需要一种不同的能力——全局RAG，它涉及跨整个文档集合汇总和分析信息以获取语料库级别的洞察。当前的RAG方法在全局任务上的表现不佳，最强的基准方法仅能达到1.51的F1分数。", "innovation": "本文提出了GlobalQA，这是第一个专门用于评估全局RAG能力的基准，涵盖了四种核心任务类型：计数、极值查询、排序和top-k提取。通过系统地在不同模型和基准模型之间进行评估，我们发现现有的RAG方法在全局任务上的表现较差。为了应对这些挑战，本文提出了GlobalRAG，这是一种多工具协作框架，通过片段级检索保持结构性连贯，结合LLM驱动的智能过滤器去除噪声文档，并集成聚合模块进行精确的符号计算。在Qwen2.5-14B模型上，GlobalRAG的表现优于最强基线方法。", "conclusion": "GlobalRAG在Qwen2.5-14B模型上的表现明显优于现有最强基线方法，F1分数为6.63，验证了我们方法的有效性。"}
{"llm_update_time": "20251101", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.26202", "html_url": "https://arxiv.org/abs/2510.26202", "title": "在我的人类反馈中有些什么？学习可解释的偏好数据描述", "title_en": "What's In My Human Feedback? Learning Interpretable Descriptions of Preference Data", "authors": "Rajiv Movva,Smitha Milli,Sewon Min,Emma Pierson", "background": "人类反馈可以以不可预测且不理想的方式影响语言模型，而实践者对于反馈数据编码的内容缺乏清晰的认识。虽然之前的研究工作已经在特定属性（如长度或奉承）的偏好上进行了探索，但在无需预先假设的情况下自动提取相关特征仍然具有挑战性。", "innovation": "我们引入了What's In My Human Feedback？(WIMHF) 方法，利用稀疏自编码器来解释反馈数据。WIMHF 既能描述数据集能够测量的偏好，也能描述注释者实际表达的偏好。研究发现，小数量的人类可解释特征能够解释多数偏好预测信号。这些特征展示了人类偏好的多样性，并揭示了不同上下文角色：例如，Reddit用户偏好非正式和玩笑，而HH-RLHF和PRISM的注释者则不偏好这些特征。WIMHF还揭示了潜在的安全风险偏好，如LMArena用户倾向于反对拒绝，有时甚至支持有毒内容。通过学习到的特征，我们可以有效进行数据编辑和个性化：重新标记有害示例在 Arena 中可带来显着的安全收益 (+37%)，且不影响一般性能；我们还发现了一种个性化方法，即针对各个注释者的主观特征赋予特定权重，从而提高偏好预测。", "conclusion": "WIMHF 提供了一种以人类为中心的分析方法，使实践者能够更好地理解并使用偏好数据。"}
{"llm_update_time": "20251101", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.26285", "html_url": "https://arxiv.org/abs/2510.26285", "title": "揭开语言模型操作数字的机制", "title_en": "Unravelling the Mechanisms of Manipulating Numbers in Language Models", "authors": "Michal Štefánik,Timothee Mickus,Marek Kadlčík,Bertram Højer,Michal Spiegel,Raúl Vázquez,Aman Sinha,Josef Kuchař,Philipp Mondorf", "background": "最近的研究发现，不同的大型语言模型（LLMs）在处理数字时会生成相似且准确的输入表示。然而，这与大型语言模型处理数字信息时容易产生错误输出的已记录倾向相矛盾。本研究旨在通过探索语言模型如何处理数字以及量化这些机制的准确下限来解释这一矛盾。", "innovation": "研究发现，尽管存在表面错误，不同语言模型在不同隐藏状态和不同输入上下文中仍学习到系统性和高度准确的数字表示，这使得可以通过创建通用的探针来检查每个LLM，甚至追溯到具体导致输出错误的层。这一研究为理解预训练LLMs如何操作数字奠定了基础，并揭示了更准确的探针技术在改进LLMs架构方面的潜力。", "conclusion": "研究结果深刻地诠释了预训练LLMs如何操作数字的机制，并概述了更准确的探针技术在建筑改进LLMs方面的潜力。"}
{"llm_update_time": "20251101", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.26254", "html_url": "https://arxiv.org/abs/2510.26254", "title": "语言模型对借词识别无偏见：跨10种语言的多语种评估", "title_en": "Language Models Are Borrowing-Blind: A Multilingual Evaluation of Loanword Identification across 10 Languages", "authors": "Mérilin Sousa Silva,Sina Ahmadi", "background": "语言历史中，单词从一种语言借到另一种语言，逐渐被接受语言的词汇表所整合。在双语社区中，主导语言不断向弱势语言施加词汇，使用者可以区分借词与本族词。此论文研究预训练语言模型，包括大型语言模型，在识别借词方面是否具有类似的能力。论文评估了10种语言的多个模型，尽管有明确的指令和上下文信息，模型在此任务上表现不佳，验证了现代NLP系统对借词存在偏好的证据，而不是使用本族词。此项工作对为弱势语言开发NLP工具和在面临主导语言词汇压力的社区中支持语言保存具有重要意义。", "innovation": "论文评估了多个语言模型在10种语言中对借词的识别能力，并发现即使有明确指令和上下文信息，模型表现仍然不佳，与以前的研究结果一致，即现代NLP系统偏爱借词而非本族等词。这些发现为弱势语言保护提出了新的挑战和机遇。", "conclusion": "研究结果显示，当前的预训练语言模型在区分借词和本族词方面表现不佳，且具有对借词的偏好，这对弱势语言的支持和保护提出了新的挑战。未来应进一步优化模型，针对借词识别进行专门训练，以更好地服务于面临大量借词压力的语言社区。"}
{"llm_update_time": "20251101", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.26277", "html_url": "https://arxiv.org/abs/2510.26277", "title": "LLMs是否信号化它们何时正确？基于神经元一致性的证据", "title_en": "Do LLMs Signal When They're Right? Evidence from Neuron Agreement", "authors": "Kang Chen,Yaoning Wang,Kai Xiong,Zhuoka Feng,Wenhe Sun,Haotian Chen,Yixin Cao", "background": "大型语言模型（LLMs）通常通过样本评估组合解码器增强推理能力，实现无需标签的性能提升。然而，现有策略仅依靠外部输出如词元概率、熵或自我评估进行评分，这些信号在后训练过程中可能失准。论文指出，外部信号是更丰富的内部动态的低维投影，并且正确答案在生成过程中的激活神经元数量少于错误答案。在正确答案的激活中存在跨样本一致性，而在错误答案中则表现出差异。基于这些观察，论文提出了一种基于内部信号的无监督选择方法NAD，通过激活稀疏度和跨样本神经元一致性来选择候选答案，而不需要相似的文本输出。", "innovation": "提出了一种新的无监督方法Neuron Agreement Decoding (NAD)，通过评估激活稀疏度和跨样本神经元一致性来选择候选答案，仅基于内部信号，无需类似文本输出。NAD能够在生成前32个词元内预测正确性，支持大胆的早期停止。NAD在数学和科学基准测试中达到了多数投票的效果，并在无法应用多数投票的开放式编程基准测试中持续优于Avg@64。通过早期剪枝未被预期的路径，NAD将token使用率减少了99%，同时保持了生成质量，展示了内部信号在无标签组合解码中的可靠、可扩展和高效指导作用。", "conclusion": "NAD能够在不使用实际标签的情况下，通过内部神经元激活信号有效选择正确答案。它能够在生成早期预测正确性，减少99%的token使用率而不牺牲生成质量。这表明内部神经元激活信号可以为无监督的解码过程提供可靠的指导。"}
{"llm_update_time": "20251101", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.26322", "html_url": "https://arxiv.org/abs/2510.26322", "title": "基于工具调用的结构化链式推理用于交互式行为解释的SCRIBE", "title_en": "SCRIBE: Structured Chain Reasoning for Interactive Behaviour Explanations using Tool Calling", "authors": "Fares Fawzi,Vinitra Swamy,Dominik Glandorf,Tanya Nazaretsky,Tanja Käser", "background": "语言模型可以在教育环境中提供互动的个性化学生反馈，但实际部署面临三大挑战：隐私问题、有限的计算资源和需要教育上有效的回应。这些限制要求模型是小型的、开源的、本地运行，能够可靠地基于正确信息生成输出。在教育低资源和隐私敏感的应用中，小规模模型是必要的。为此，研究引入了SCRIBE框架，用于对学生反馈报告中的问题生成有效回答，支持多步迭代推理、工具使用和错误恢复。", "innovation": "SCRIBE框架结合了领域特定工具和自反思推理管线，通过两阶段LoRA微调（利用合成的GPT-4o生成数据），生成具有有效性与可靠性的响应。它通过与人类对齐的GPT-Judge评估和108名学生参与的用户研究发现，8B-SCRIBE模型在相关性和行动性方面等同于甚至超过了大型模型，而学生认为它与GPT-4o和Llama-3.3 70B模型具有可比性。这些发现证明了在低资源和隐私敏感的教育应用中，SCRIBE的可行性与有效性。", "conclusion": "研究证明了SCRIBE在基于工具调用的结构化链式推理方面具有显著优势，可以生成高质量的教育对话反馈，适用于资源有限且需要隐私保护的教育场景。"}
{"llm_update_time": "20251101", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.26352", "html_url": "https://arxiv.org/abs/2510.26352", "title": "对话的几何学：通过绘图语言模型揭示多智能体合作中的协同团队", "title_en": "The Geometry of Dialogue: Graphing Language Models to Reveal Synergistic Teams for Multi-Agent Collaboration", "authors": "Kotaro Furuya,Yuichi Kitagawa", "background": "基于大型语言模型（LLMs）的多智能体方法被视为超越单模型能力的一种有前景的策略，但其成功高度依赖于智能体团队的有效协同。然而，构建最佳团队是一个重大挑战，因为大多数模型的内部特性模糊不清，这阻碍了有效的协作。", "innovation": "本文提出了一种基于交互的自动团队构建框架，该框架无需任何先前知识，包括模型的内部架构、训练数据或性能。该方法通过映射模型间的关系以构建‘语言模型图’，并通过社区检测识别协同的模型集群。实验结果表明，提出的框架能够发现具有功能协同性的群体，这些群体反映了其隐含的专业化。使用特定话题作为种子进行对话，可以识别出协同的团队，并在下游基准测试中表现优于随机基线，达到与手工挑选团队相当的准确性。", "conclusion": "本文的研究成果为设计协作多智能体LLM团队提供了新的基础。"}
{"llm_update_time": "20251101", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.26298", "html_url": "https://arxiv.org/abs/2510.26298", "title": "ChatGPTAtlas能否征服网络？探索ChatGPT Atlas智能体在网络游戏中的前沿应用", "title_en": "Can Agent Conquer Web? Exploring the Frontiers of ChatGPT Atlas Agent in Web Games", "authors": "Jingran Zhang,Ning Li,Justin Cui", "background": "OpenAI的ChatGPT Atlas引入了新的网络交互能力，使模型能够分析网页、处理用户意图并在浏览器中直接执行鼠标和键盘输入。虽然其信息检索任务的能力已被证明，但在动态、交互式环境中性能尚未得到广泛探索。因此，作者们使用基于浏览器的游戏作为测试场景，评估Atlas的网络交互能力。", "innovation": "该研究利用基于浏览器的游戏进行早期评估，通过游戏内的分数作为定量指标，评估Atlas在不同任务类型中的表现。研究发现，Atlas在逻辑推理任务中表现出色，但在需要精准时间和动作控制的实时游戏中表现不佳。这些发现表明，虽然Atlas展示了强大的分析处理能力，但在需要实时交互的动态网络环境中仍然存在显著的局限性。", "conclusion": "尽管ChatGPT Atlas在逻辑推理任务中表现出色，但在需要高频实时交互的动态网页环境中仍存在显著的局限性。在未来的研究中，需要进一步探索如何提升模型在动态网页环境下的实时交互能力。"}
{"llm_update_time": "20251101", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.26336", "html_url": "https://arxiv.org/abs/2510.26336", "title": "从初学者到大师：通过自动化课程学习向LLMs注入知识", "title_en": "From Amateur to Master: Infusing Knowledge into LLMs via Automated Curriculum Learning", "authors": "Nishit Neema,Srinjoy Mukherjee,Sapan Shah,Gokul Ramakrishnan,Ganesh Venkatesh", "background": "大型语言模型（LLMs）在泛化任务方面表现出色，但在需要深厚、规则性理解的专门领域如经济学和心理学方面表现不佳。我们介绍了一种名为ACER（Automated Curriculum-Enhanced Regimen）的方法，该方法能够将通用模型转变为领域专家，同时保留其广泛的技能范围。ACER通过生成一个科目目录并创建基于Bloom分类法指引的问题回答对来合成一个全面的、教科书式的学习计划。这确保了主题覆盖系统化且难度逐渐增加。产生的合成语料库用于按交错课程计划进行持续预训练，这将学习内容和认知维度对齐。", "innovation": "ACER（Automated Curriculum-Enhanced Regimen）方法引入了一种自动化课程学习的机制，能够将通用语言模型转化为领域专家，同时保留其广泛的能力。这种方法首先根据教科书风格生成科目目录，然后基于Bloom分类法指导生成问题-回答对。通过使用合成的语料库进行交错课程计划的持续预训练，确保了系统性主题覆盖和难度递增的学习进程。在实验中，该方法在LLaMA 3.2（1B和3B）模型中表现出显著的性能提升，在具有挑战性的专业领域如微观经济学，基准线模型面临困难的情况下，ACER还能够将准确性提高5个百分点。此外，ACER还在知识密集型基准测试如ARC和GPQA中提升了2个百分点的绝对性能，同时在一般推理任务中保持了稳定表现。", "conclusion": "我们的研究结果表明，ACER为关闭LLM在关键领域差距提供了一种可扩展且有效的方法。该方法不仅能够预防灾难性遗忘，同时也促进了跨领域的知识迁移，提升了非目标领域的性能0.7个百分点。"}
{"llm_update_time": "20251101", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.26354", "html_url": "https://arxiv.org/abs/2510.26354", "title": "科学写作中话语关系分类中的上下文作用", "title_en": "On the Role of Context for Discourse Relation Classification in Scientific Writing", "authors": "Stephen Wan,Wei Liu,Michael Strube", "background": "随着生成式人工智能方法在科学流程中的使用增加，研究人员开始关注如何利用话语层面的信息来支持AI生成的科学论断。本文聚焦的一个初始步骤是分析科学写作中的话语结构推理任务。对于科学出版物这一不太研究的类别，本文探索了预先训练的语言模型（PLM）和大型语言模型（LLM）在话语关系分类（DRC）方面的应用，评估了上下文在帮助完成DRC任务中的作用，并分析了哪些科学话语关系类型可能最受益于上下文的存在。", "innovation": "本文研究了上下文在科学写作中话语关系分类（DRC）应用中的作用，利用预先训练的语言模型和大型语言模型进行探索，填补了科学出版物领域在DRC任务上的研究空白，并分析了特定类型的话语关系对上下文依赖性的敏感度。", "conclusion": "实验结果显示，上下文，特别是话语结构定义的上下文，对DRC任务通常是具有帮助的。不同科学话语关系类型中，某些类型可能会特别受益于上下文的存在。"}
{"llm_update_time": "20251101", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.26345", "html_url": "https://arxiv.org/abs/2510.26345", "title": "MisSynth: 使用合成数据改进MISSCI逻辑谬误分类", "title_en": "MisSynth: Improving MISSCI Logical Fallacies Classification with Synthetic Data", "authors": "Mykhailo Poliakov,Nadiya Shvai", "background": "健康相关的错误信息非常普遍且具有潜在危害性。尤其是在虚假的科学结论扭曲或误读科学发现时，要识别这些信息变得尤为困难。本文基于MISSCI数据集和框架，研究合成数据生成和轻量级微调技术对大型语言模型（LLMs）识别错误论证能力的影响。这些技术被应用于MisSynth管道，该管道使用检索增强生成（RAG）生成合成谬误样本，再对LLM模型进行微调。实验结果显示，微调模型相对于基础模型具有显著的准确率提升，例如，微调后的LLaMA 3.1 8B模型在MISSCI测试集上的F1分数绝对提升超过35%。通过引入合成谬误数据增加有限标注资源的数量，能够在计算资源有限的情况下显著提升零样本LLM分类性能，特别是在实际科学误解任务中。该代码和合成数据集可以在提供的链接中获得。", "innovation": "提出了一种名为MisSynth的管道，该管道采用检索增强生成（RAG）生成合成谬误样本，以轻量级微调技术对大型语言模型进行微调，以提高其识别逻辑谬误的能力。这种方法利用合成数据增强有限的标注资源，即使在计算资源有限的情况下，也能显著改善零样本任务中的分类性能。", "conclusion": "引入合成谬误数据到有限的标注资源中，可以显著改进大型语言模型在实际科学误解任务中的零样本分类性能，即使计算资源有限。微调模型相对未微调模型显示出显著准确率提升，展示了该方法的有效性。相关代码和合成数据集已经公开。"}
{"llm_update_time": "20251101", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.26422", "html_url": "https://arxiv.org/abs/2510.26422", "title": "OmniEduBench：教育领域综合基准评估大规模语言模型", "title_en": "OmniEduBench: A Comprehensive Chinese Benchmark for Evaluating Large Language Models in Education", "authors": "Min Zhang,Hao Chen,Hao Chen,Wenqi Zhang,Didi Zhu,Xin Lin,Bo Jiang,Aimin Zhou,Fei Wu,Kun Kuang", "background": "随着大语言模型（LLMs）的迅速发展，LLM在教育领域的应用日益广泛。然而，现有的大多数LLM和基准测试侧重于知识层面的评估，忽视了培养能力的评估，这些能力对于实际教育场景至关重要。当前的基准测试往往局限于单一学科或问题类型，缺乏多样性，特别是在中国语境下更为突出。为解决这一问题，我们提出了OmniEduBench，这是一个全面的中文教育基准。该基准包含了24602个高质量的问答对，分为知识维度和培养维度，分别包含18121个和6481个条目。每个维度进一步细分为6个领域，覆盖共计61个不同的学科（知识维度41个，培养维度20个）。此外，数据集还包含各种问题格式，包括11种常见的考试题型，为全面评估LLM在教育领域的能力提供了坚实基础。", "innovation": "OmniEduBench是一个全面的中文教育基准，它系统地评估了LLM在教育场景中的知识和培养能力。该基准包含广泛的问题类型和学科覆盖，能更全面地评价LLM的表现。", "conclusion": "广泛的实验显示，尽管现有LLM在知识方面表现良好，但在培养能力方面仍与人类智能有近30%的差距，这表明在教育领域应用LLM存在很大的改进空间和发展挑战。"}
{"llm_update_time": "20251101", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.26498", "html_url": "https://arxiv.org/abs/2510.26498", "title": "使用多智能体大型语言模型框架自动评估临床AI分诊工具的表现", "title_en": "A Multi-agent Large Language Model Framework to Automatically Assess Performance of a Clinical AI Triage Tool", "authors": "Adam E. Flanders,Yifan Peng,Luciano Prevedello,Robyn Ball,Errol Colak,Prahlad Menon,George Shih,Hui-Ming Lin,Paras Lakhani", "background": "本研究旨在探讨使用多个大型语言模型（LLM）的集合是否能提供比单一LLM更可靠的评估像素基础的AI分诊工具的方法。研究使用了一个商业化的脑出血AI检测工具处理了来自14家医院的29,766份非对比CT头部检查报告。研究人员通过八种开源LLM模型和一个HIPAA合规的GPT-4o内部版本进行分析，使用单个多靶点提示评估脑出血的存在情况。通过手动审查了1,726个例子，比较了八种开源模型和共识的性能与GPT-4o，同时测试了三种理想的共识LLM集合，以评估分诊工具的性能。", "innovation": "采用了多智能体大型语言模型框架，通过一个包含多种LLM的集合来评估临床AI分诊工具的表现，并发现这种集合方法相比单一LLM提供了更一致和可靠的评估结果。", "conclusion": "中等至大型的开源LLM集合能够提供比单一LLM更一致和可靠的临床AI分诊工具的回顾性评估方法。"}
{"llm_update_time": "20251101", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.26446", "html_url": "https://arxiv.org/abs/2510.26446", "title": "1+1>2: Synergistic Sparse and Low-Rank Compression Method for Large Language Models", "title_en": "1+1>2: A Synergistic Sparse and Low-Rank Compression Method for Large Language Models", "authors": "Zeliang Zong,Kai Zhang,Zheyang Li,Wenming Tan,Ye Ren,Yiyan Zhai,Jilin Hu", "background": "大型语言模型（LLMs）在语言理解和生成方面表现出色，但其广泛应用受到带宽和计算需求的限制。尽管剪枝和低秩近似各自证明了有希望的表现，但它们在LLMs中的协同作用尚未得到深入研究。", "innovation": "论文引入了一种联合稀疏和低秩压缩方法（SSLC），结合了低秩近似和稀疏优化的优势。低秩近似通过保留模型的关键结构实现压缩，同时稀疏优化去除不必要的权重，以保留对泛化至关重要的权重。理论分析表明将低秩近似和稀疏优化统一为一个问题并通过迭代优化算法解决。实验在LLaMA和Qwen2.5（7B-70B）模型上表明，SSLC在无需额外训练步骤的情况下，始终优于单一方法，并达到最先进的效果。特别地，SSLC将Qwen2.5压缩了50%且性能无降，提升了至少1.63倍的速率，提供了一种高效部署LLM的实用方案。", "conclusion": "实验结果显示，SSLC方法在LaMA和Qwen2.5（7B-70B）模型上实现了无性能下降的压缩，达到了最先进的效果，同时显著提升了模型的运行速度。"}
{"llm_update_time": "20251101", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.26484", "html_url": "https://arxiv.org/abs/2510.26484", "title": "大型语言模型的贝叶斯网络融合用于情感分析", "title_en": "Bayesian Network Fusion of Large Language Models for Sentiment Analysis", "authors": "Rasoul Amirzadeh,Dhananjay Thiruvady,Fatemeh Shiri", "background": "随着大型语言模型（LLMs）的不断进步，出现了越来越多针对特定任务的领域特定变体。然而，这些模型通常缺乏透明性和可解释性，精细调整成本高，需要大量的提示工程，结果在不同领域之间不一致，并且由于其高计算需求对环境造成显著的负面影响。", "innovation": "本文提出了一种贝叶斯网络LLM融合（BNLF）框架，将三种LLM（FinBERT，RoBERTa，BERTweet）的预测通过概率机制整合，用于情感分析。BNLF采用后期融合方式，通过贝叶斯网络中的概率节点来建模多个LLM的情感预测。在三个不同语言和上下文特征的人工标注金融语料库上，BNLF在准确率上比基础LLM提高了约6%，证明了其对数据集变异性的鲁棒性和概率融合在解释性情感分类中的效果。", "conclusion": "BNLF框架在情感分析方面展示了稳定的优势，能够提升准确率，并提高了模型的透明性和可解释性，有效解决了现有模型的透明性、成本、结果一致性和环境影响等问题。"}
{"llm_update_time": "20251101", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.26512", "html_url": "https://arxiv.org/abs/2510.26512", "title": "CORE-KG内部机制：结构化提示和核心指代解析对知识图谱的评估", "title_en": "Inside CORE-KG: Evaluating Structured Prompting and Coreference Resolution for Knowledge Graphs", "authors": "Dipak Meher,Carlotta Domeniconi", "background": "人类走私网络越来越具有适应性，难以分析。法律案例文件提供了关键信息，但常常是无结构的、语言密集的，并充满了模糊或变化的指代，这给自动知识图谱（KG）构建带来了巨大挑战。尽管最近基于LLM的方法有所改善，但仍会产生噪声大、碎片化的图和重复节点，原因是没有指导性的提取和共指解析。最近提出的CORE-KG框架通过整合类型感知的共指模块和领域指导的结构化提示，显著减少了节点重复和法律噪音。", "innovation": "CORE-KG框架通过集成类型感知的共指模块和领域指导的结构化提示，解决了现有方法的局限性，显著减少了节点重复和法律噪音。本研究通过系统性消融实验定量评价了CORE-KG框架的两个关键组件。", "conclusion": "实验结果表明，去除共指解析会导致节点重复增加28.32%，噪声节点增加4.32%，而去除结构化提示则会导致节点重复增加4.34%，噪声节点增加73.33%。这些发现为设计从复杂法律文本中提取结构化表示的稳健LLM管道提供了实证见解。"}
{"llm_update_time": "20251101", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.26543", "html_url": "https://arxiv.org/abs/2510.26543", "title": "大型语言模型中关系解码线性算子的结构", "title_en": "The Structure of Relation Decoding Linear Operators in Large Language Models", "authors": "Miranda Anna Christ,Adrián Csiszárik,Gergely Becsó,Dániel Varga", "background": "本文探讨了Hernandez等人在2023年引入的线性算子的结构，这些算子能够解码 transformer 语言模型中的特定关系事实。本文在Hernandez等人的单关系发现基础上，扩展到多个关系，并系统地描述了它们的组织结构。", "innovation": "本文将包含多个关系的线性解码器集合通过简洁的三阶张量网络压缩，同时保持解码准确性。本文开发了一种交叉评估协议，用于解释这些线性映射如何不编码特定的关系，而是提取重复、粗粒度的语义特性。这种基于属性的结构解释了算子的压缩性和为什么它们只能泛化到具有相同语义的新关系。", "conclusion": "本文的研究表明，变压器语言模型中的线性关系解码主要基于属性，而不是特定的关系。这意味着线性解码器虽然可以压缩，但其泛化能力仅限于具有相同语义的新关系。"}
{"llm_update_time": "20251101", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.26521", "html_url": "https://arxiv.org/abs/2510.26521", "title": "使用视觉表示的希伯来文字符重音恢复", "title_en": "Hebrew Diacritics Restoration using Visual Representation", "authors": "Yair Elboher,Yuval Pinter", "background": "希伯来文在未添加音符的情况下具有高度的歧义性，这对于准确的单词发音和文本含义的消歧至关重要。尽管近年来机器学习方法在这一任务上取得了显著的进步，但仍迫切需要一种能够无需复杂的语义分析就能高效地恢复音符的方法。", "innovation": "DIVRIT是一种新颖的希伯来文字符重音系统，将该任务框架为零样本分类问题，并直接在输入的向量表示中嵌入音符信息。系统利用希伯来视觉语言模型作为图像来处理未重音文本，从而选择每个未重音单词的最佳重音模式，同时考虑周围文本的上下文。通过一系列全面的评估，表明系统可以有效地进行字符重音化，而且在特定设置下，DIVRIT不仅能产生高度准确的结果，还能通过架构改进和优化训练方法大幅提升泛化能力。", "conclusion": "这些发现表明，视觉表示在准确和自动化的希伯来文字符重音化方面的潜力是令人鼓舞的。DIVRIT提出了一种创新的方法，能够高效地恢复希伯来文字符的正确重音，同时提高系统的泛化性能。"}
{"llm_update_time": "20251101", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.26615", "html_url": "https://arxiv.org/abs/2510.26615", "title": "SlideAgent：多页视觉文档理解的分层代理框架", "title_en": "SlideAgent: Hierarchical Agentic Framework for Multi-Page Visual Document Understanding", "authors": "Yiqiao Jin,Rachneet Kaur,Zhen Zeng,Sumitra Ganesh,Srijan Kumar", "background": "多页视觉文档，如手册、宣传册、演示文稿和海报，通过布局、颜色、图标和跨页面引用传达关键信息。尽管大型语言模型（LLMs）为文档理解带来了机会，但现有的系统在处理复杂的多页视觉文档时遇到困难，特别是在微细化的元素和页面间推理解析方面尤为如此。", "innovation": "引入了一个名为SlideAgent的多功能代理框架，专为理解和推理多模态、多页和多布局文档而设计，特别是针对演示文稿。SlideAgent通过专门化的代理将推理分解为全局、页面和元素三个层次，构建了一个结构化且查询无关的表现形式，既捕捉到宏观的主题，也捕捉到细节的视觉或文本提示。推理时，SlideAgent会根据需要选择激活代理进行多层次推理，并将它们的输出整合成连贯且上下文相关的答案。实验表明，SlideAgent在闭源模型上提高了7.9%，在开源模型上提高了9.8%。", "conclusion": "通过对多层次推理的实现，SlideAgent显著提高了多页视觉文档的理解能力。"}
{"llm_update_time": "20251101", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.26575", "html_url": "https://arxiv.org/abs/2510.26575", "title": "InfoFlow：通过奖励密度优化强化搜索代理", "title_en": "InfoFlow: Reinforcing Search Agent Via Reward Density Optimization", "authors": "Kun Luo,Hongjin Qian,Zheng Liu,Ziyi Xia,Shitao Xiao,Siqi Bao,Jun Zhao,Kang Liu", "background": "Reinforcement Learning with Verifiable Rewards（RLVR）是提升主动深度搜索的有效方法。然而，其应用受深搜索场景中低奖励密度的限制。在这种场景下，代理为了获取稀少甚至无效的最终奖励，需要花费大量的探索成本。本文将这一挑战定义为奖励密度优化问题，旨在提高单位探索成本下的奖励获取效率。", "innovation": "InfoFlow是一个系统框架，通过三个维度解决奖励密度优化问题：1) 子问题分解：将长期任务分解为阶段性任务，为过程分配奖励，提供更密集的学习信号；2) 失败引导提示：在停滞的轨迹中注入纠正性指导，提高成功结果的概率；3) 双代理精炼：采用双代理架构减轻深搜索的认知负担。精炼代理整合搜索历史，有效压缩研究人员感知的轨迹，从而降低探索成本并提升整体奖励密度。", "conclusion": "InfoFlow在多个主动搜索基准测试中表现显著优于标杆模型，使轻量级LLM能够达到与最新专有LLM相当的性能。"}
{"llm_update_time": "20251101", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.26622", "html_url": "https://arxiv.org/abs/2510.26622", "title": "编码器-解码器还是仅解码器？重访编码器-解码器大型语言模型", "title_en": "Encoder-Decoder or Decoder-Only? Revisiting Encoder-Decoder Large Language Model", "authors": "Biao Zhang,Yong Cheng,Siamak Shakeri,Xinyi Wang,Min Ma,Orhan Firat", "background": "近年来，大型语言模型（LLM）的研究从编码器-解码器建模转向了如今盛行的仅解码器建模。这一快速转变却没有进行严格的从规模扩展角度的对比分析，引起了人们对编码器-解码器模型潜在能力被忽视的担忧。\n", "innovation": "该研究重新审视了编码器-解码器LLM（简称RedLLM），将其与最近的解码器-仅编解码器LLM（简称DecLLM）方法结合起来加以增强。通过从词前缀语言模型（Prefix LM）预训练RedLLM，与从因果语言模型（Causal LM）预训练DecLLM进行对比，然后使用RedPajama V1（1.6T令牌）进行预训练以及FLAN进行指令调整，实验显示RedLLM具有令人信服的扩展性和出色的性能。尽管DecLLM在预训练时计算更优化，但RedLLM在扩展性和上下文长度外推方面表现出相似甚至更强的能力。经过指令调整后，RedLLM在各种下游任务上取得了可比甚至更好的结果，同时还具有更好的推理效率。\n", "conclusion": "希望我们的发现能够激发更多关于重新审视RedLLM的努力，发现其开发强大且高效的LLM的潜力。"}
{"llm_update_time": "20251101", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.26683", "html_url": "https://arxiv.org/abs/2510.26683", "title": "Evontree：基于本体规则指导的大语言模型自我进化框架", "title_en": "Evontree: Ontology Rule-Guided Self-Evolution of Large Language Models", "authors": "Mingchen Tu,Zhiqiang Liu,Juan Li,Liangyurui Liu,Junjie Wang,Lei Liang,Wen Zhang", "background": "大型语言模型（LLMs）在多个领域展示出卓越的能力，这得益于大量的预训练数据和精心策划的微调数据。然而，在医疗等数据敏感领域，由于缺乏高质量的专业领域训练数据集，限制了LLMs的专业应用适应性。本体规则是领域专家提炼的专业知识，用以系统化地展示概念间的关系并保证知识库的完整性。通过将LLMs视为人类知识的隐含库，本研究提议了一个名为Evontree的新框架，该框架利用少量高质量的本体规则来系统地提取、验证和增强LLMs中的领域知识，无需大量外部数据集的介入。该框架从原始模型中提取领域本体、使用两个核心本体规则检测不一致性和通过自我提炼微调来强化细化的知识.", "innovation": "提出了一种名为Evontree的新框架，该框架利用少量高质量的本体规则来系统地提取、验证和增强LLMs中的领域知识，无需大量外部数据集的介入。具体而言，Evontree从原模型中提取领域本体、使用两个核心本体规则检测不一致性和通过自我提炼微调来强化细化的知识，从而保持了高质量的知识完整性，提高了LLMs在专业领域的表现.", "conclusion": "广泛实验证明，Evontree框架在医疗问答基准测试中对比未修改模型和领先监督基准模型具有持续的性能优势，准确率最高可提高3.7%。这些结果证实了该方法在LLMs低资源领域的领域适应性方面的有效性、效率和鲁棒性."}
{"llm_update_time": "20251101", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.26697", "html_url": "https://arxiv.org/abs/2510.26697", "title": "从手动解码到真正端到端的语言模型：迈向自动解码", "title_en": "The End of Manual Decoding: Towards Truly End-to-End Language Models", "authors": "Zhichao Wang,Dongyang Ma,Xinting Huang,Deng Cai,Tian Lan,Jiahao Xu,Haitao Mi,Xiaoying Tang,Yan Wang", "background": "现有的大规模语言模型（LLMs）通常被称为端到端模型，但实际上是不准确的，因为它们依赖于非可微的解码过程，这需要人工调整如温度（temperature）、顶k（top-p）等超参数。这种人工调参的过程效率低下且复杂。", "innovation": "本文提出了AutoDeco，一种新的架构，可以通过学习控制自己的解码策略实现真正的端到端生成。该架构在标准 transformer 中加入轻量级头部模块，每个步骤能动态预测上下文相关的温度和顶k值，并与下一个标记概率同时生成。这种方法将解码变为参数化、标记级别的过程，使模型在单次前向传播中实现自我调节其采样策略。通过在八个基准测试中的实验，表明AutoDeco 不仅显著优于默认解码策略，还能达到与通过破解测试集获得的 Oracle 调参基线相当的表现。此外，模型展示了基于指令的解码控制能力，学习自然语言指令（如“低随机性生成”），并按标记动态调整预测的温度和顶k值。", "conclusion": "AutoDeco 解决了人工调参的问题，提供了新的可控和互动的 LLM 解码范式。"}
{"llm_update_time": "20251101", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.26768", "html_url": "https://arxiv.org/abs/2510.26768", "title": "AMO-Bench: 大型语言模型在高中数学竞赛中仍表现不佳", "title_en": "AMO-Bench: Large Language Models Still Struggle in High School Math Competitions", "authors": "Shengnan An,Xunliang Cai,Xuezhi Cao,Xiaoyu Li,Yehao Lin,Junlin Liu,Xinxuan Lv,Dan Ma,Xuanlin Wang,Ziwen Wang,Shuang Zhou(Alphabetical order by last name)", "background": "目前的基准测试大量利用高中数学竞赛来评估大型语言模型（LLMs）的数学推理能力。然而，许多现有的数学竞赛已经无法有效评估顶级LLMs，因为它们的表现达到了饱和状态（例如，AIME的得分在24/25）。", "innovation": "AMO-Bench 引入了更严格的挑战，确保包含的50个人工策划的问题都经过专家的交叉验证，符合国际数学奥林匹克（IMO）难度标准，并且完全是原创的，以防止可能的数据记忆导致的性能泄露。此外，每个问题仅需要最终答案，这使得自动和可靠的评分成为可能。实验结果表明，即使最佳模型在AMO-Bench上的准确率也只有52.4%，大多数LLMs的得分低于40%。此外，我们的进一步分析显示，随着测试时间计算量的增加，AMO-Bench上的表现有望呈现扩大趋势。这些结果强调了目前LLMs在数学推理方面存在巨大提升空间。", "conclusion": "AMO-Bench 的发布旨在推动进一步研究，以提升语言模型的推理能力。"}
{"llm_update_time": "20251101", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.26692", "html_url": "https://arxiv.org/abs/2510.26692", "title": "Kimi Linear: 一种表达能力强、高效的关注架构", "title_en": "Kimi Linear: An Expressive, Efficient Attention Architecture", "authors": "Kimi Team:Yu Zhang,Zongyu Lin,Xingcheng Yao,Jiaxi Hu,Fanqing Meng,Chengyin Liu,Xin Men,Songlin Yang,Zhiyuan Li,Wentao Li,Enzhe Lu,Weizhou Liu,Yanru Chen,Weixin Xu,Longhui Yu,Yejie Wang,Yu Fan,Longguang Zhong,Enming Yuan,Dehao Zhang,Yizhi Zhang,T.Y. Liu,Haiming Wang,Shengjun Fang,Weiran He,Shaowei Liu,Yiwei Li,Jianlin Su,Jiezhong Qiu,Bo Pang,Junjie Yan,Zhejun Jiang,Weixiao Huang,Bohong Yin,Jiacheng You,Chu Wei,Zhengtao Wang,Chao Hong,Yutian Chen,Guanduo Chen,Yucheng Wang,Huabin Zheng,Feng Wang,Yibo Liu,Mengnan Dong,Zheng Zhang,Siyuan Pan,Wenhao Wu,Yuhao Wu,Longyu Guan,Jiawen Tao,Guohong Fu,Xinran Xu,Yuzhi Wang,Guokun Lai,Yuxin Wu,Xinyu Zhou,Zhilin Yang,Yulun Du", "background": "当前，全关注机制在各种场景（包括短上下文、长上下文以及强化学习缩放阶段）中表现优秀，但在硬件效率和计算复杂性方面存在挑战。研究者们对更高效的关注机制有着持续的需求，以提高模型的性能和计算效率。本文提出了一种名为Kimi Linear的混合线性关注架构，在公平比较中首次实现全关注机制的性能超越，特别是在短上下文、长上下文和强化学习缩放阶段。Kimi Linear的核心在于Kimi Delta Attention (KDA)模块，这一模块是对Gated DeltaNet的扩展，加入了一个更细化的门控机制，以更好地利用有限状态RNN的记忆。通过定制的块级算法，Kimi Linear实现了高度的硬件效率，通过专门的对角线加低秩（DPLR）过渡矩阵变体，计算量显著减少，且保持了更符合经典 delta 规则的一致性。", "innovation": "Kimi Linear结合了KDA模块和多头潜在注意（MLA）机制，通过对比实验展示了在相同训练配方下，Kimi Linear能够在所有评估任务中显著优于全MLA，并且通过减少KV缓存使用率高达75%，实现最高6倍的解码吞吐量。这一架构通过提高性能和效率，证实了在包括更长输入和输出长度的任务中Kimi Linear可以作为一种全关注架构的直接替代品。作者还提供了KDA内核和vLLM实现，以及预训练和指令调整的模型检查点，以支持进一步的研究。", "conclusion": "Kimi Linear为代表的线性关注机制提供了一种新的方式来平衡模型的性能和计算效率，展示了在不同任务中实现显著优化的可能性，为关注机制的研究和发展开辟了新的方向。"}
{"llm_update_time": "20251101", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.26707", "html_url": "https://arxiv.org/abs/2510.26707", "title": "价值漂移：追踪LLM后训练期间的价值对齐", "title_en": "Value Drifts: Tracing Value Alignment During LLM Post-Training", "authors": "Mehar Bhatia,Shravan Nayak,Gaurav Kamath,Marius Mosbach,Karolina Stańczak,Vered Shwartz,Siva Reddy", "background": "随着大规模语言模型（LLM）在社会中的作用日益重要，它们需要不仅运用广泛知识，还需遵循特定的人类价值体系来回答问题。因此，研究LLM与人类价值观的对齐变得至关重要。然而，以往研究多关注已经训练完成的模型的价值对齐评估，忽略了模型在训练过程中如何学会表达人类价值观的动态过程。", "innovation": "本文探索了在模型后训练过程中价值对齐是如何以及在哪个阶段产生的。研究区分了后训练算法和数据集对价值变化的影响，测量了价值漂移的规模和时间。通过不同规模的Llama-3和Qwen-3模型，并结合广泛使用的监督微调（SFT）和偏好优化数据集及算法，研究发现SFT阶段通常确立了模型的价值，而后续的偏好优化很少重新调整这些价值观。此外，使用一个可控制改变价值的合成偏好数据集，研究发现不同的偏好优化算法即使偏好数据相同，也会导致不同的价值对齐结果。这些发现为了解后训练期间价值的学习提供了行动指南，并有助于指导数据管理和选择改进模型价值对齐的模型和算法。", "conclusion": "研究发现，SFT阶段通常确立了模型的价值，而后续的偏好优化很少重新调整这些价值观。不同的偏好优化算法即使偏好数据相同，也会导致不同的价值对齐结果。这些研究结果为如何在后训练阶段学习价值提供了行动建议，并有助于指导数据管理和算法选择以提高模型与人类价值观的对齐。"}
{"llm_update_time": "20251101", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.25797", "html_url": "https://arxiv.org/abs/2510.25797", "title": "通过空间-时间分析和空间注意力网络增强水下物体检测", "title_en": "Enhancing Underwater Object Detection through Spatio-Temporal Analysis and Spatial Attention Networks", "authors": "Sai Likhith Karri,Ansh Saxena", "background": "本研究探讨了时空建模和在水下物体检测的深度学习模型中集成空间注意机制的有效性。通过对现有的YOLOv5模型及其增强版本T-YOLOv5进行评估，研究显示了时空建模在动态海洋环境中的优势，特别是在突然移动、部分遮挡和渐进运动等条件下，其检测准确性和泛化能力得到了显著提升。同时，研究还引入了Convolutional Block Attention Module (CBAM)，进一步提高了模型在复杂场景中的性能，但在简单场景中的准确性有所降低。", "innovation": "本研究的主要创新点在于提出了一种增强的时空模型T-YOLOv5及其结合CBAM的版本。通过时空建模和空间注意机制的集成，提高了在动态海洋环境下的检测准确性和泛化能力，尤其是在复杂和挑战性场景中表现更加出色。然而，与标准模型相比，复杂场景中的准确性有所下降。", "conclusion": "研究结果表明，T-YOLOv5相比标准YOLOv5有显著提升，增强了检测可靠性，而T-YOLOv5结合CBAM进一步提高了复杂场景下的性能。总体而言，时空建模和空间注意机制在水下物体检测中具有显著优势，特别是对于复杂物体的检测。"}
{"llm_update_time": "20251101", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.26790", "html_url": "https://arxiv.org/abs/2510.26790", "title": "Gistify！通过运行时执行实现代码库级别的理解", "title_en": "Gistify! Codebase-Level Understanding via Runtime Execution", "authors": "Hyunji Lee,Minseon Kim,Chinmay Singh,Matheus Pereira,Atharv Sonwane,Isadora White,Elias Stengel-Eskin,Mohit Bansal,Zhengyan Shi,Alessandro Sordoni,Marc-Alexandre Côté,Xingdi Yuan,Lucas Caccia", "background": "随着编码代理越来越多地部署在大规模代码库中，自动设计具有挑战性的、代码库级别的评估变得至关重要。当前最先进的模型在解决涉及长执行跟踪的Gistify任务时，表现出色程度有限。Gistify任务要求编码LLM创建一个单一的、最小的、自包含的文件，该文件能够重现代码库中的特定功能。生成的文件必须模拟在完整代码库下运行特定命令的输出，并且仅包含执行提供的命令所需的必要组件。成功完成Gistify任务需要对代码库的结构理解、准确建模其执行流程以及生成可能较大的代码补丁的能力。", "innovation": "Gistify是一个新的任务，要求LLM在代码库的完全访问权限下生成一个可重现特定功能的最小代码文件。成功完成Gistify任务不仅需要对代码库结构的理解，还需要准确模拟其执行流程以及生成大规模代码补丁的能力。当前最先进的模型在解决Gistify任务（尤其是涉及长执行跟踪的任务）时表现不佳，表明存在改进空间。", "conclusion": "我们的研究结果表明，现阶段最先进的模型无法可靠地解决Gistify任务，尤其是那些具有长时间执行跟踪的任务。这表明在代码库级别的理解和生成能力方面还存在改进的空间。"}
{"llm_update_time": "20251101", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.25801", "html_url": "https://arxiv.org/abs/2510.25801", "title": "Metis-SPECS：通过自主提炼的偏好式冷启动进行多模态学习的解耦", "title_en": "Metis-SPECS: Decoupling Multimodal Learning via Self-distilled Preference-based Cold Start", "authors": "Kun Chen,Peng Shi,Haibo Qiu,Zhixiong Zeng,Siqi Yang,Wenji Mao,Lin Ma", "background": "近期可验证奖励的强化学习（RL）推动了一波被称为“MLLM-r1”的方法，将RL引入视觉语言模型。大多数代表性方法通常采用监督微调（SFT）来冷启动策略，但这种方法往往会引入指令风格过拟合，削弱泛化能力，影响下游RL任务的表现。因此，本文研究了冷启动方法及其训练方法和数据构建，引入了泛化因子（Generalization Factor，GF）系数来量化不同方法的泛化能力。实验发现偏好式训练方法在冷启动中的泛化性能优于SFT方法。", "innovation": "本文提出了一种解耦多模态学习框架——SPECS（Self-distilled, Preference-based Cold Start），该框架通过自我提炼生成自我反思偏好数据对，避免依赖大型教师网络或手动标注；采用偏好式训练方法，侧重学习浅层次、可转移的表面形式标准，而非记忆内容；并通过可验证奖励过渡到RL，以实现深入的推理结果。该方法在多个多模态基准上实现了比强基线的性能提升，特别是在MEGA-Bench和MathVista上分别提高了4.1%和12.2%。实验还表明，这种方法有助于减少同分布中的“停滞”，提高探索能力，稳定训练，并提升性能天花板。", "conclusion": "SPECS框架在多个多模态基准上取得了稳定且显著的性能改善，通过解耦学习方法和冷启动策略，显著提升了模型的泛化能力和最终的性能表现，为多模态学习和强化学习结合提供了一种新的思路。"}
{"llm_update_time": "20251101", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.25884", "html_url": "https://arxiv.org/abs/2510.25884", "title": "使用多评判者学习系统近似人类偏好", "title_en": "Approximating Human Preferences Using a Multi-Judge Learned System", "authors": "Eitán Sprejer,Fernando Avalos,Augusto Bernardi,Jose Pedro Brito de Azevedo Faustino,Jacob Haimes,Narmeen Fatimah Oozeer", "background": "LLM（大型语言模型）驱动的法官难以校准，且常常表现出评分标准敏感性、偏见和不稳定性。克服这一挑战有助于推进诸如通过人类反馈强化学习（RLHF）构建可靠的奖励模型和开发有效的路由系统等关键应用。这些系统能为不同用户查询匹配最适合的模型。研究发现，学习整合来自多个评分标准调整法官的输出有助于建模多样化的、基于人设的偏好。研究还通过实例研究了人类和LLM法官偏见的鲁棒性。", "innovation": "提出了一种框架，通过学习整合多个评分标准调整法官的输出来建模多样化和基于人设的偏好。该研究的主要贡献包括一种基于人设的方法来大规模合成偏好标签和两种聚合器的两种实现：广义加性模型（GAM）和多层感知器（MLP），以克服LLM法官的复杂性问题。", "conclusion": "通过对比实验和案例分析评估了该方法的性能和鲁棒性。该方法展示了在可靠地近似人类偏好方面相较于简单基准方法的优势，并成功地应用于大规模偏好标签的创建和不同聚合器的实现。"}
{"llm_update_time": "20251101", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.25860", "html_url": "https://arxiv.org/abs/2510.25860", "title": "透过法官的视角：推断出的思维痕迹提高LLM评判的可靠性", "title_en": "Through the Judge's Eyes: Inferred Thinking Traces Improve Reliability of LLM Raters", "authors": "Xingjian Zhang,Tianhong Gao,Suliang Jin,Tianhao Wang,Teng Ye,Eytan Adar,Qiaozhu Mei", "background": "随着大规模语言模型（LLMs）在评估任务中的应用越来越多，它们对主观任务的可靠性经常受到限制。当人类判断涉及超出标注标签的微妙推理时尤为如此。思维痕迹，即判断背后的推理过程，虽然极为信息丰富，但收集和维护它们极具挑战性。因此，本文提出了一种人类与LLM协作的框架，用于从仅标签的注释中推断出这些思维痕迹。通过这种方法，研究人员旨在改进LLM的人机共识，并为LLM评判提供更清晰的注释指南，从而增强LLM评判的可靠性。", "innovation": "本文的创新之处在于提出了一种人类与LLM协作的框架，使用简单的拒绝采样方法从仅标签的注释中大批量推断出思维痕迹。这些方法不仅有助于通过微调开放的LLM评判者来提高LLM与人类的一致性，还通过合成更清晰的注释指南改进了专用LLM评判者的评判一致性。因此，这项工作提供了一种实际的方法来替代未公开的人类思维痕迹，从而将仅标签的数据扩展为繁增思维痕迹的数据资源，这能进一步增强LLM评判的可靠性。", "conclusion": "实验结果显示，通过推断思维痕迹的方法可以显著提高LLM与人类之间的共识，并且改进后的注释指南也提高了解释不同类型LLM模型之间的一致性。因此，该研究提出了一种有效的策略，使得LLM能够在没有直接揭示人类思维痕迹的情况下提供可靠的评判。"}
{"llm_update_time": "20251101", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.26037", "html_url": "https://arxiv.org/abs/2510.26037", "title": "SIRAJ: 通过提炼结构化推理实现多样且高效的LLM代理红队测试", "title_en": "SIRAJ: Diverse and Efficient Red-Teaming for LLM Agents via Distilled Structured Reasoning", "authors": "Kaiwen Zhou,Ahmed Elgohary,A S M Iftekhar,Amin Saied", "background": "大语言模型（LLM）代理具备规划和调用工具的能力，这使其面临新的安全风险，特别是在部署前需要进行充分的安全性测试。因此，建立一个全面的红队系统至关重要，以发现潜在漏洞，确保安全部署。现有的红队方法通常适用于特定的模型或工具集，缺乏灵活性和通用性。", "innovation": "本文提出了SIRAJ，一种通用的红队框架，用于任意的黑盒LLM代理。它采用动态两步过程，从代理定义开始生成多样化的种子测试用例，涵盖多种风险结果、工具使用路径和风险来源。然后根据前次尝试的执行路径迭代构建和优化基于模型的对抗攻击。为优化红队成本，该方法引入了一种模型提炼技术，利用教师模型推理的结构形式来训练小而有效的模型。实验结果表明，种子测试用例生成方法提高了2-2.5倍的风险结果和工具调用路径覆盖率，提炼的8B红队模型的攻击成功率提高了100%，超过了671B的Deepseek-R1模型。", "conclusion": "本文通过逐步框架、结构化推理和模型提炼，验证了红队模型的有效性、普遍性和效率。SIRAJ框架为LLM代理的安全测试提供了一种灵活且通用的方法。"}
{"llm_update_time": "20251101", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.25932", "html_url": "https://arxiv.org/abs/2510.25932", "title": "FakeZero：实时、保护隐私的虚假信息检测工具（适用于Facebook和X）", "title_en": "FakeZero: Real-Time, Privacy-Preserving Misinformation Detection for Facebook and X", "authors": "Soufiane Essahli,Oussama Sarsar,Imane Fouad,Anas Motii,Ahmed Bentajer", "background": "社交媒体平台以空前的速度传播信息，这加速了虚假信息的扩散，对公共言论构成威胁。为了解决这一问题，该研究提出了一种名为FakeZero的完全客户端、跨平台浏览器扩展，它在用户滚动页面时能标记Facebook和X（原Twitter）上的不可靠帖子。这个工具能在保障用户隐私的前提下，实时检测和标记虚假信息，从而帮助用户和政策制定者识别和避免虚假信息的影响。", "innovation": "FakeZero是一款实时运行在用户设备上的检测工具，所有的计算、DOM抓取、分词、Transformer推理和UI渲染都在本地进行，无需将个人信息传输到云端。该工具采用了一种三阶段训练课程：基准微调、领域适配训练，并通过引入焦点损失、对抗增强和后训练量化进行优化。实验结果表明，模型在较低资源消耗的情况下仍能保持较高的检测性能，从而展示了在有限资源下实现高质量虚假信息检测的可能性。此外，该工具还提供了实时的可信度提示信息，有助于用户识别和避免虚假信息的传播，且为研究人员提供了收集大规模虚假信息数据集的机会，以支持更深入的研究和检测技术的发展。", "conclusion": "该研究提出了一个名为FakeZero的便携式、实时的虚假信息检测工具，它实现了在本地设备上的高效运行，并通过本地计算保护了用户隐私。通过高效的模型优化和资源管理，该工具在资源受限的情况下仍然能够提供高度准确的检测结果。此外，FakeZero还提供了实时的可信度提示，以辅助政策制定者和其他用户识别并防止虚假信息的传播。未来的研究可以考虑进一步优化模型，收集更多高质量的数据，并开发更先进的检测技术，以应对日益复杂的虚假信息挑战。"}
{"llm_update_time": "20251101", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.26143", "html_url": "https://arxiv.org/abs/2510.26143", "title": "推理课程：从数学开始培养大型语言模型的广泛推理能力", "title_en": "Reasoning Curriculum: Bootstrapping Broad LLM Reasoning from Math", "authors": "Bo Pang,Deqian Kong,Silvio Savarese,Caiming Xiong,Yingbo Zhou", "background": "强化学习（RL）能够激发大型语言模型（LLMs）的强大推理能力，但大多数公开的努力主要集中在数学和代码领域。本研究提出了一种简单的两阶段推理课程，旨在先在与预训练对齐的领域（如数学）中培养推理技能，然后再通过联合RL跨越其他领域进行适应和优化。", "innovation": "提出了一个简单、无特殊要求的两阶段推理课程。第一阶段通过简短的冷启动和数学独立试验以及可验证奖励来初步培养推理技能；第二阶段通过联合RL在多领域数据中进行推理技能的迁移和巩固。此课程无需专门的奖励模型，仅需标准的验证性检查。实验结果显示，该课程在多种领域中都能保持一致的改进效果，并且扩展和适应步骤对于提升解决复杂问题的认知行为至关重要。", "conclusion": "推理课程提供了一种紧凑且易于采用的方法，以增强大型语言模型的广泛推理能力。"}
{"llm_update_time": "20251101", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.26038", "html_url": "https://arxiv.org/abs/2510.26038", "title": "Do Students Debias Like Teachers? On the Distillability of Bias Mitigation Methods", "title_en": "Do Students Debias Like Teachers? On the Distillability of Bias Mitigation Methods", "authors": "Jiali Cheng,Chirag Agarwal,Hadi Amiri", "background": "知识 distillation（KD）是一种用于模型压缩并转移模型之间知识的有效方法。然而，它对模型抵御 spurious correlations 的鲁棒性影响，尤其是在处理 out-of-distribution 数据时，其效果尚未得到充分研究。在自然语言推理（NLI）和图像分类任务中，研究探讨了 KD 对教师模型到学生模型转移去偏见能力的影响。通过大量实验，研究揭示了几个关键发现。", "innovation": "本研究首次大规模探讨了 KD 对去偏见方法的效果及其内部机制，并提出了三种有效的解决方案来改进去偏见方法的可转移性：开发高质量数据进行增强、实施迭代 KD 方法，并用教师模型的权重初始化学生模型。研究结果提高了对 KD 工作机制的理解，并为设计更好的去偏见方法提供了见解。", "conclusion": "研究结果揭示了 KD 对模型去偏见能力的负面影响，表明 KD 可能会导致显著的变化，并提出了具体的改进措施，为去偏见方法的设计提供了新的方向。"}
{"llm_update_time": "20251101", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.26006", "html_url": "https://arxiv.org/abs/2510.26006", "title": "CAVE：检测和解释视觉环境中的常识异常", "title_en": "CAVE: Detecting and Explaining Commonsense Anomalies in Visual Environments", "authors": "Rishika Bhagwatkar,Syrielle Montariol,Angelika Romanou,Beatriz Borges,Irina Rish,Antoine Bosselut", "background": "人类能够自然地识别、推理和解释环境中的异常。但在计算机视觉领域，这一长期存在的挑战仍然局限于工业缺陷或不现实的合成异常，未能捕捉到真实世界异常的丰富性和不可预测性。这项工作引入了CAVE，首个真实世界的视觉异常基准。CAVE支持三项开放任务：异常描述、解释和论证；提供细粒度注释，用于视觉定位异常并根据其视觉表现、复杂性、严重性和常见性对其进行分类。这些注释受到认知科学中人类识别和解决异常的研究启发，为评估视觉语言模型(VLMs)检测和理解异常提供了一个全面框架。然而，目前最先进的VLMs在视觉异常感知和常识推理方面表现不佳，即使使用更高级的提示策略也是如此。", "innovation": "CAVE是首个真实世界的视觉异常基准，支持三项开放任务：异常描述、解释和论证。它通过细粒度的注释来视觉定位异常并根据其外观、复杂性、严重性和常见性进行分类。这些注释借鉴了认知科学中人类识别和解决异常的研究，为视觉语言模型(VLMs)在检测和理解异常方面的评估提供了一个全面的框架。此外，该基准展示了最先进的VLMs在视觉异常感知和常识推理方面存在挑战，即使使用更高级的提示策略也是如此。", "conclusion": "CAVE为异常检测和常识推理方面视觉语言模型的研究提供了现实、认知合理的基准，有助于推动该领域的研究进展。"}
{"llm_update_time": "20251101", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.26241", "html_url": "https://arxiv.org/abs/2510.26241", "title": "时间之流的方向？基于心理物理学的视觉-语言模型评估", "title_en": "Which Way Does Time Flow? A Psychophysics-Grounded Evaluation for Vision-Language Models", "authors": "Shiho Matta,Lis Kanashiro Pereira,Peitao Han,Fei Cheng,Shigeru Kitazawa", "background": "现代的视觉-语言模型（VLMs）在许多跨模态任务中表现出色，但在视频中的时间信息掌握方面仍然薄弱且被低估。本文通过一项看似简单但却揭示深刻的挑战——判断时间箭头（AoT），即判断短片段是正向还是倒向播放，来探索这一缺口。AoT-PsyPhyBENCH 是一个心理物理学验证的基准测试，使用人类相同的刺激和行为基线来测试 VLMs 是否能够在自然视频中推断时间方向。", "innovation": "本文提出了 AoT-PsyPhyBENCH，这是一个心理物理学验证的基准测试，用于评估 VLMs 在自然视频中推断时间方向的能力。通过全面评估开放权重和专有 VLMs（包括推理型和非推理型），发现大多数模型的表现接近随机，即使是表现最好的模型在物理不可逆过程（如自由落体、扩散/爆炸）和因果手动动作（如分裂/添加）上的表现也大大落后于人类的准确性。这些结果揭示了当前跨模态系统中的根本性缺口：尽管它们捕捉了丰富的视觉-语义关联，但缺乏实现时间连续性和因果理解所需的归纳偏置。", "conclusion": "这些结果突显了当前跨模态系统中的一个重要缺陷：尽管它们能够捕捉丰富的视觉-语义关联，但在时间连续性和因果理解方面缺乏相应的归纳偏置。本文发布了 AoT-PsyPhyBENCH 的代码和数据，以促进 VLMs 在物理和时间推理能力上的进一步进步。"}
{"llm_update_time": "20251101", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.26423", "html_url": "https://arxiv.org/abs/2510.26423", "title": "Nexus: 基于执行的多智能体测试标杆合成", "title_en": "Nexus: Execution-Grounded Multi-Agent Test Oracle Synthesis", "authors": "Dong Huang,Mingzhe Du,Jie M. Zhang,Zheng Lin,Meng Luo,Qianru Zhang,See-Kiong Ng", "background": "在非回归测试中，生成测试标杆以准确判断在给定输入下被测试函数（FUT）的行为是否符合预期是一项长期挑战。", "innovation": "本文提出了一种名为Nexus的新型多智能体框架，通过多样化的专智能体协同工作来合成测试标杆。这些智能体通过一个结构化的审议、验证和迭代自我完善的过程来生成测试标杆。此外，Nexus能够在执行过程中检测错误并自动循环修正和验证标杆。", "conclusion": "对七个不同基准的广泛评估显示，Nexus在测试水平上的标杆准确性上显著优于最先进的基线。例如，与基线相比，Nexus在LiveCodeBench上将GPT-4.1-Mini的标杆准确性从46.30%提高到57.73%。性能的提升也显著增强了下游任务：Nexus生成的标杆在HumanEval中的bug检测率从90.91%提高到95.45%，而自动程序修复的成功率从35.23%提高到69.32%。"}
{"llm_update_time": "20251101", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.26167", "html_url": "https://arxiv.org/abs/2510.26167", "title": "One Model to Critique Them All: Rewarding Agentic Tool-Use via Efficient Reasoning", "title_en": "One Model to Critique Them All: Rewarding Agentic Tool-Use via Efficient Reasoning", "authors": "Renhao Li,Jianhong Tu,Yang Su,Hamid Alinejad-Rokny,Derek F. Wong,Junyang Lin,Min Yang", "background": "大型语言模型（LLMs）通过奖励模型（RMs）来与人类偏好对齐至关重要。但在工具学习领域，缺乏针对函数调用任务设计的奖励模型阻碍了更加能动的AI的发展。为此，作者提出了ToolRM，一种面向通用工具使用场景的轻量级生成型奖励模型。为了构建这种模型，作者设计了一种新的流水线，采用基于规则的评分和多维抽样来创建成对偏好的数据集，从而生成了一个多样、平衡且具有挑战性的批评任务数据集ToolPref-Pairwise-30K，该数据集支持具有验证反馈的强化学习。作者还引入了TRBench$_{BFCL}$基准测试，这是一个基于BFCL的能动评估套件构建的基准测试。", "innovation": "作者提出了ToolRM，这是一种专为通用工具使用场景设计的轻量级生成型奖励模型。为了构建这些模型，作者提出了一个基于规则的评分和多维抽样的新型流水线来生成批评任务数据集ToolPref-Pairwise-30K，此数据集支持具有验证反馈的强化学习。此外，作者还提出了一个基于BFCL的基准测试TRBench$_{BFCL}$，在这些数据集上训练的模型从Qwen3-4B/8B系列获得了高达14.28%的准确率提升，显著优于像Claude 4和OpenAI o3等前沿模型。另外，ToolRM模型还能泛化到更广泛的批评任务，包括Best-of-N采样和自我修正。实验表明，使用该模型在ACEBench上的表现优于基线模型，且在推理时间上可以进行扩展，并减少了66%以上的输出词汇量。作者还发布了数据集和模型检查点以促进未来研究。", "conclusion": "通过这种方法，模型不仅在需方任务上有显著提升，在更广泛的批评任务上也表现出色，且在推理时间上提升了效率。这一成果为未来研究提供了丰富的数据和模型资源。"}
{"llm_update_time": "20251101", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.26274", "html_url": "https://arxiv.org/abs/2510.26274", "title": "PVMark: 使大型语言模型水印方案可公开验证", "title_en": "PVMark: Enabling Public Verifiability for LLM Watermarking Schemes", "authors": "Haohua Duan,Liyao Xiang,Xin Zhang", "background": "大型语言模型（LLMs）的水印方案已被提出，用于识别生成文本的来源，以减轻模型被盗带来的潜在威胁。然而，当前的水印解决方案难以解决信任问题：非公开的水印检测无法真实地证明自身的检测行为，因为秘密密钥通常用于水印检测，既不能公开避免对手发起移除攻击，也不能保持私密性以免检测过程对公众不透明。", "innovation": "我们提出了一种基于零知识证明（ZKP）的插件PVMark，使其水印检测过程能够在不泄露任何秘密密钥的情况下由第三方进行公开验证。PVMark通过建立一组ZKP约束，包括映射、随机数生成、比较和求和等，来证明水印检测的正确执行。我们使用Python、Rust和Circom实现了多种PVMark变体，包括三种水印方案、三种哈希函数和四种ZKP协议的组合，展示了该方法在各种情况下有效工作，同时不牺牲水印性能，有望在实践中部署。", "conclusion": "实验结果表明，PVMark有效实现了对最先进的LLM水印方案的公开验证，而不损害水印性能，为实际部署提供了保证。"}
{"llm_update_time": "20251101", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.26190", "html_url": "https://arxiv.org/abs/2510.26190", "title": "SP-MCQA：超越字级评估TTS的可理解性", "title_en": "SP-MCQA: Evaluating Intelligibility of TTS Beyond the Word Level", "authors": "Hitomi Jin Ling Tee,Chaoren Wang,Zijie Zhang,Zhizheng Wu", "background": "现有的TTS（文本到语音）语音清晰度评估陷入了瓶颈，现有的评估方法主要依赖于逐字准确性度量，如WER（单词错误率），这些度量方式无法捕捉真实世界语音的复杂性也无法反映人类的理解需求。因此，提出了Spoken-Passage Multiple-Choice Question Answering（口语段落多项选择题回答）这一新颖的主观评估方法，用于评估合成语音中的关键信息准确性。并通过SP-MCQA-Eval发布了包含8.76小时新闻风格语音段落基准数据集，用于SP-MCQA评估。实验结果表明，低的WER并不一定意味着高关键信息准确性，表明传统指标与实际可理解性之间存在差距。此外，SP-MCQA表明，即使是当前最先进的模型在文本规范化和音素准确性方面仍然存在不足。这些发现凸显了当前许多系统在WER方面已取得良好效果，但在真实世界可理解性方面可能仍然表现不佳，迫切需要新的高层次、更现实的评估标准。", "innovation": "提出了Spoken-Passage Multiple-Choice Question Answering（口语段落多项选择题回答）这一主观评估方法，用于评估合成语音中的关键信息准确性。", "conclusion": "现有的传统指标不能全面反映TTS系统的实际可理解性，尤其是对于关键信息的准确性。即使是最先进的模型在文本规范化和音素准确性上仍然存在不足。迫切需要新的高层次、更现实的评估标准来确保TTS系统的实际应用效果。"}
{"llm_update_time": "20251101", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.26474", "html_url": "https://arxiv.org/abs/2510.26474", "title": "通过头部-尾部重新平衡对抗LVLMs自我改进中的马太效应", "title_en": "Counteracting Matthew Effect in Self-Improvement of LVLMs through Head-Tail Re-balancing", "authors": "Xin Guo,Zhiheng Xi,Yiwen Ding,Yitao Zhai,Xiaowei Shi,Xunliang Cai,Tao Gui,Qi Zhang,Xuanjing Huang", "background": "自改进已经成为提升大型视觉-语言模型（LVLMs）推理能力的主要范式，模型通过迭代探索和学习成功路线。然而，在这一过程中，我们发现了一个关键问题：模型在处理简单查询（即头部数据）时能产生高质量的轨迹，但在处理复杂查询（即尾部数据）时表现出色度显著下降。这种不平衡导致模型倾向于优先发展简单的推理技能，而在解决更复杂的推理任务时受到阻碍。这种不平衡随迭代次数增加而愈发明显，我们称之为“马太效应”，最终阻碍进一步改进，导致性能瓶颈。", "innovation": "为解决这一挑战，我们从两个角度引入了四种高效的策略，分别是分布重塑和轨迹重采样，旨在在探索和学习的自我改进过程中实现头部-尾部的重新平衡。实验表明，我们的方法在Qwen2-VL-7B-Instruct和InternVL2.5-4B模型上的视觉推理任务中，能持续提升视觉推理能力，平均比传统的自我改进高出3.86分。", "conclusion": "我们的研究结果表明，通过采用分布重塑和轨迹重采样的策略，可以在LVLMs的自我改进过程中实现头部-尾部的重新平衡，从而有效克服马太效应，提升模型的复杂推理能力，并实现更好的性能表现。"}
{"llm_update_time": "20251101", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.26457", "html_url": "https://arxiv.org/abs/2510.26457", "title": "SecureReviewer：通过安全感知微调增强大型语言模型的代码审查", "title_en": "SecureReviewer: Enhancing Large Language Models for Secure Code Review through Secure-aware Fine-tuning", "authors": "Fang Liu,Simiao Liu,Yinghao Zhu,Xiaoli Lian,Li Zhang", "background": "在软件开发早期阶段识别和解决安全问题对于减少长期负面影响至关重要。代码审查作为开发者在代码合并到代码库前检查团队代码的有效实践，有效帮助提高代码质量。尽管已经提出了一系列自动代码审查方法，其中基于大语言模型（LLM）的方法显著提高了自动审查生成能力，但现有模型主要针对通用代码审查，其在识别和解决安全问题方面的效果尚未得到充分探索。此外，将现有代码审查方法适应于安全问题也面临数据稀缺和评估指标不足等挑战。", "innovation": "本文提出了一种名为SecureReviewer的新方法，旨在增强LLM在代码审查中发现和解决安全问题的能力。具体而言，首先构建了一个专用于训练和评估安全代码审查能力的数据集，并使用此数据集对LLMs进行精细调整，以生成能够有效识别安全问题并提供修复建议的审查评论。为了减少LLMs的虚构性并提高其输出的可靠性，本文还集成了RAG技术，生成的评论与特定领域的安全知识相联系。此外，本文引入了一种新的评估指标SecureBLEU，用于评估审查评论在解决安全问题方面的有效性。实验结果表明，与最先进的基线相比，SecureReviewer在安全问题检测精度和生成的审查评论的质量与实用性方面都表现出更优的效果。", "conclusion": "SecureReviewer通过安全感知微调策略有效提升了LLM在安全代码审查中的能力，展示了在识别和修复安全问题方面优于现有方法的效果，为进一步提高代码审查质量和安全性提供了新的解决方案。"}
{"llm_update_time": "20251101", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.26658", "html_url": "https://arxiv.org/abs/2510.26658", "title": "代理组织的时代：利用语言模型学习组织", "title_en": "The Era of Agentic Organization: Learning to Organize with Language Models", "authors": "Zewen Chi,Li Dong,Qingxiu Dong,Yaru Hao,Xun Wu,Shaohan Huang,Furu Wei", "background": "本文设想一种新的AI时代——代理组织，其中代理通过协作和并行解决问题，产生超出单一智能的结果。为了实现这一愿景，引入了一种新的异步推理（AsyncThink）范式，通过大型语言模型将内部思考过程组织为可并发执行的结构。", "innovation": "提出了一种思考协议，其中组织者动态分配子查询、合并中间知识并生成连贯的解决方案。更重要的是，该协议中的思考结构可以通过强化学习进一步优化。实验证明，AsyncThink在数学推理方面提高了准确性，同时将推理延迟降低了28%。", "conclusion": "AsyncThink展示了学习异步思考能力的有效性，无需额外训练即可应对未见过的任务。"}
{"llm_update_time": "20251101", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.26493", "html_url": "https://arxiv.org/abs/2510.26493", "title": "Context Engineering 2.0: 概念工程2.0——概念工程的背景", "title_en": "Context Engineering 2.0: The Context of Context Engineering", "authors": "Qishuo Hua,Lyumanshan Ye,Dayuan Fu,Yang Xiao,Xiaojie Cai,Yunze Wu,Jifan Lin,Junfei Wang,Pengfei Liu", "background": "卡尔·马克思曾写道：‘人类的本质是社会关系的总和’，暗示个体不是孤立的存在，而是与其他实体的互动从根本上塑造了个体。随着计算机和人工智能的出现，这些情境不仅限于纯人类间的互动，还涵盖了人机互动。因此，一个核心问题是：机器如何更好地理解我们的情况和目的？为解决这一挑战，研究人员最近引入了概念工程的概念。尽管经常被视为近年来代理时代的创新，但我们认为相关的实践可以追溯到二十年前。", "innovation": "概念工程技术的发展可以追溯到20世纪90年代，该领域经历了多个历史阶段，每个阶段都受到机器智能水平的影响。本文阐明了概念工程的定义，概述了其历史和概念背景，并探讨了实践中的关键设计考虑因素，旨在为其提供概念基础和勾勒出一个有希望的未来。", "conclusion": "通过解决这些问题，我们希望为概念工程提供一个概念基础，并勾勒出一个有希望的未来。本文是向更广泛的社区努力实现系统的概念工程迈出的一步，旨在人工智能系统中系统化概念工程的努力。"}
{"llm_update_time": "20251101", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.26732", "html_url": "https://arxiv.org/abs/2510.26732", "title": "跨平台基础模型推理能力评估", "title_en": "Cross-Platform Evaluation of Reasoning Capabilities in Foundation Models", "authors": "J. de Curtò,I. de Zarzà,Pablo García,Jordi Cabot", "background": "本文介绍了对当代基础模型推理能力的全面跨平台评估，涵盖了三种计算范式：HPC超级计算机（MareNostrum 5）、云平台（Nebius AI Studio）以及大学集群（配备八块H200 GPU的节点）。评估了15种基础模型在涵盖八个学术领域（物理、数学、化学、经济学、生物学、统计学、微积分和优化）的79个问题上的表现。", "innovation": "本文的方法和基准评估有助于在不同基础设施上长时间追踪基础模型推理能力的发展，并且揭示了训练数据质量比模型大小更为关键的传统假设。还提供了跨教育、生产和研究领域的模型选择指导。", "conclusion": "作者的跨基础设施方法和79问题基准评估能够为基础模型的演变过程提供纵向跟踪方式，强调了训练数据质量的重要性，并提出了模型选择的实用指南。"}
{"llm_update_time": "20251101", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.26606", "html_url": "https://arxiv.org/abs/2510.26606", "title": "大型语言模型中的规范推理：从逻辑和模态视角进行的比较基准", "title_en": "Normative Reasoning in Large Language Models: A Comparative Benchmark from Logical and Modal Perspectives", "authors": "Kentaro Ozeki,Risako Ando,Takanobu Morishita,Hirohiko Abe,Koji Mineshima,Mitsuhiro Okada", "background": "规范推理涉及规范或义务模态，如义务和许可。尽管大型语言模型（LLMs）在各种推理任务上展示了卓越的表现，但在规范推理方面的能力尚未得到充分探索。本文系统地从逻辑和模态视角评估了LLMs在规范领域的推理能力。为评估LLMs如何处理规范模态的推理能力，本文将其与一些共同的形式结构的表征命题模态进行比较。本文还介绍了一个包含广泛形式推理模式的新数据集，涵盖了规范和表征知识领域，并结合了影响人类推理的非形式认知因素。", "innovation": "本文提出了一种新的数据集，涵盖规范推理和表征命题推理的广泛形式推理模式，同时结合了影响人类推理的非形式认知因素，并对LLMs进行了比较基准评估，揭示了在特定类型规范推理中的逻辑一致性问题和认知偏差。", "conclusion": "虽然LLMs遵循有效的推理模式，但在特定类型规范推理中表现出明显的不一致性，表现出类似于人类推理的心理学研究中观察到的认知偏差。这些发现突显了在LLMs中实现规范推理逻辑一致性的挑战，并为增强其可靠性提供了见解。相关数据和代码已公开发布。"}
{"llm_update_time": "20251101", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.26787", "html_url": "https://arxiv.org/abs/2510.26787", "title": "远程劳动力指数：衡量远程工作的AI自动化", "title_en": "Remote Labor Index: Measuring AI Automation of Remote Work", "authors": "Mantas Mazeika,Alice Gatti,Cristina Menghini,Udari Madhushani Sehwag,Shivam Singhal,Yury Orlovskiy,Steven Basart,Manasi Sharma,Denis Peskoff,Elaine Lau,Jaehyuk Lim,Lachlan Carroll,Alice Blair,Vinaya Sivakumar,Sumana Basu,Brad Kenstler,Yuntao Ma,Julian Michael,Xiaoke Li,Oliver Ingebretsen,Aditya Mehta,Jean Mottola,John Teichmann,Kevin Yu,Zaina Shaik,Adam Khoja,Richard Ren,Jason Hausenloy,Long Phan,Ye Htet,Ankit Aich,Tahseen Rabbani,Vivswan Shah,Andriy Novykov,Felix Binder,Kirill Chugunov,Luis Ramirez,Matias Geralnik,Hernán Mesura,Dean Lee,Ed-Yeremai Hernandez Cardona,Annette Diamond,Summer Yue,Alexandr Wang,Bing Liu,Ernesto Hernandez,Dan Hendrycks", "background": "在研究型知识与推理基准上，人工智能取得了快速进步，但这些进展如何转化为经济价值和自动化仍不明确。论文为了评估AI在经济实际场景中的自动化能力，提出了远程劳动力指数（RLI），该指数涵盖多个行业，并设计了真实的、具有经济价值的项目来评估端到端代理的表现。", "innovation": "论文创新地提出了远程劳动力指数（RLI），它是一个覆盖多个行业的广泛基准，包含实际的、具有经济价值的项目，旨在评估AI代理在现实环境中的全面表现。研究结果表明，在RLI测试中，AI代理的表现接近最低标准，最优秀的代理自动化率为2.5%，这为讨论AI自动化提供了实证依据，也为追踪AI的影响提供了共同基础，并帮助利益相关方主动应对AI驱动的劳动力自动化。", "conclusion": "研究结果表明，在RLI中AI代理的表现接近最低标准，最高水平的自动化率仅为2.5%。这些结果有助于将对AI自动化讨论建立在实证证据之上，为追踪AI的影响设立共同基准，并帮助相关利益方积极应对由AI驱动的劳动力自动化变化。"}
{"llm_update_time": "20251101", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.26745", "html_url": "https://arxiv.org/abs/2510.26745", "title": "深度序列模型倾向于记忆几何结构；尚不清楚原因", "title_en": "Deep sequence models tend to memorize geometrically; it is unclear why", "authors": "Shahriar Noroozizadeh,Vaishnavh Nagarajan,Elan Rosenfeld,Sanjiv Kumar", "background": "在序列模型中，原子事实的参数记忆主要被抽象为实体之间共现的直接查找。本文通过对比关联视角和几何视角，探讨记忆存储的方式。研究发现，模型必须通过某种方式合成原子事实的几何结构，编码所有实体之间的全局关系，而不仅仅是训练中指定的局部共现关系。", "innovation": "本文揭示了尽管优化目标仅仅是局部关联，模型仍能学习复杂的几何结构。通过分析与Node2Vec的联系，作者指出这种几何结构起源于光谱偏差，而不是常见的架构或优化压力。这一观点为加深对序列模型记忆机制的理解提供了新的视角，启示研究人员在知识获取、容量、发现和遗忘等方面重新审视默认直觉。", "conclusion": "本文从现象中提取了几何嵌入几何的基本方面，这些方面难以用传统的架构或优化压力来解释。学习到的简洁几何结构表明，即使没有直观的优越性，模型也能通过光谱偏差自然学习到优雅的几何结构。这为改进Transformer中几何强度提供了可见的增长空间。"}
{"llm_update_time": "20251101", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.26495", "html_url": "https://arxiv.org/abs/2510.26495", "title": "重思文本到SQL：面向现实数据库探索的动态多轮SQL交互", "title_en": "Rethinking Text-to-SQL: Dynamic Multi-turn SQL Interaction for Real-world Database Exploration", "authors": "Linzhuang Sun,Tianyu Guo,Hao Liang,Yuying Li,Qifeng Cai,Jingxuan Wei,Bihui Yu,Wentao Zhang,Bin Cui", "background": "最近在文本到SQL方面的进展已经在静态、单轮任务中取得了显著成果，这些模型能够从自然语言问题生成SQL查询。然而，在现实世界中的交互场景中，用户的意图会变化，并且查询需要在多个回合中进行调整。特别是在金融和业务分析等应用中，用户会基于中间结果迭代调整查询条件或维度。为了评估这些动态能力，本文引入了DySQL-Bench基准，评估模型在不断变化用户交互环境下的表现。不同于之前的手动构建的数据集，DySQL-Bench是通过自动化两阶段的工作流生成的任务合成和验证构建的。此外，本文还提出了一个模拟实际交互的多轮评估框架，模拟了一个由LLM模拟的用户、待测模型和可执行数据库之间的交互。模型必须随着用户意图的变化调整其推理和SQL生成过程。DySQL-Bench覆盖了BIRD和Spider 2数据库的13个领域，总共1,072个任务，即使是像GPT-4o这样的先进模型，在总体准确性和Pass@5指标上的表现也只能达到58.34%和23.81%。这表明该基准的难度非常高。", "innovation": "本文提出了DySQL-Bench，这是一种自动化的两阶段数据集构建方法，用于评估模型在不断变化用户体验下的动态能力。同时，还提出了一个模拟现实交互的多轮评估框架。该框架包括了一个由LLM模拟的用户、待测模型和可执行数据库之间的交互。这种方法可以更好地模拟现实世界中的复杂查询场景，帮助评估现有模型的实际应用能力。", "conclusion": "DySQL-Bench涵盖了BIRD和Spider 2数据库的13个领域，总计1072个任务。即使像GPT-4o这样的先进模型，在总体准确性和Pass@5指标上的表现也只能达到58.34%和23.81%。这表明该基准的难度非常高。所有代码和数据都可以通过给定的链接查阅。"}
{"llm_update_time": "20251101", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2311.06736", "html_url": "https://arxiv.org/abs/2311.06736", "title": "LLMs是否严谨的逻辑推理者？基于逐步解码与对比学习的自然语言证明生成", "title_en": "Are LLMs Rigorous Logical Reasoners? Empowering Natural Language Proof Generation by Stepwise Decoding with Contrastive Learning", "authors": "Ying Su,Mingwen Liu,Zhijiang Guo", "background": "逻辑推理在人工智能领域具有重要作用。尽管证明规划在解释准确性验证方面面临挑战，但大型语言模型（LLMs）的进步使得自然语言证明规划取得了显著进展，从单一生成模式演进为包含附加搜索或验证者的复杂三阶段系统。然而，这些辅助方法虽提升了生成质量，但也增加了搜索努力和计算成本。生成过程本身仍然需要更多探索。", "innovation": "该研究提出了一种逐步解码方法，结合对比学习来解决LLM生成器解码过程中常见的两种错误。研究通过使用普通和增强的负面样本对语言模型进行微调，以减轻这些解码错误。实验证明了这种策略的有效性。进一步的分析还表明，即使规模更大的LLMs在生成严谨的逻辑链条方面仍然存在困难。", "conclusion": "该研究提出的方法提升了自然语言证明的生成质量，但在生成严谨的逻辑链条方面，LLMs依然存在局限。未来的工作将关注如何进一步提高LLMs的推理严谨性。"}
{"llm_update_time": "20251101", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2409.06263", "html_url": "https://arxiv.org/abs/2409.06263", "title": "Speak & Spell: LLM-驱动可控发音错误增强以提高鲁棒性对话状态跟踪", "title_en": "Speak & Spell: LLM-Driven Controllable Phonetic Error Augmentation for Robust Dialogue State Tracking", "authors": "Jihyun Lee,Solee Im,Wonjun Lee,Gary Geunbae Lee", "background": "对话状态跟踪(DST)是任务导向对话系统中的关键组成部分，用于识别对话中的重要信息。但在语音对话环境中，自动语音识别(ASR)系统的实体命名错误导致其准确性大幅下降。", "innovation": "本文提出了一种简单而有效的方法，针对ASR系统中的错误实体，提高DST模型的鲁棒性。该方法使用关键词高亮的提示控制错误的放置方式，并引入音近错误，生成足够的发音错误模式，从而在噪声和ASR低准确性环境中提高准确性。", "conclusion": "通过这种方法生成的足够多的发音错误模式，可以有效提高DST模型在噪声和ASR低准确性环境下的准确性。"}
{"llm_update_time": "20251101", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.26788", "html_url": "https://arxiv.org/abs/2510.26788", "title": "通过FP16战胜训练推断不匹配", "title_en": "Defeating the Training-Inference Mismatch via FP16", "authors": "Penghui Qi,Zichen Liu,Xiangxin Zhou,Tianyu Pang,Chao Du,Wee Sun Lee,Min Lin", "background": "大语言模型（LLMs）利用强化学习（RL）微调时，常常由于训练和推理策略之间的数值不匹配导致不稳定。尽管之前的研究所尝试通过算法修正或工程对齐来缓解这个问题，但其根源在于浮点精度本身。尽管BF16在动态范围方面更广泛，但它引入了大量的舍入错误，破坏了训练和推理之间的一致性。因此，研究者强调了回归到FP16能够有效消除这种不匹配的原因和影响。", "innovation": "研究发现FP16能够有效解决训练和推理之间的不匹配问题。这一改进简单且全面支持现代框架，只需要少量代码更改，无需对模型架构或学习算法进行修改。", "conclusion": "使用FP16的一致性可带来更稳定的优化、更快的收敛速度以及更强大的跨任务、算法和框架的性能表现。研究结果呼吁重新考虑在RL微调中的精度权衡问题。"}
{"llm_update_time": "20251101", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.26802", "html_url": "https://arxiv.org/abs/2510.26802", "title": "Are Video Models Ready as Zero-Shot Reasoners? An Empirical Study with the MME-CoF Benchmark", "title_en": "Are Video Models Ready as Zero-Shot Reasoners? An Empirical Study with the MME-CoF Benchmark", "authors": "Ziyu Guo,Xinyan Chen,Renrui Zhang,Ruichuan An,Yu Qi,Dongzhi Jiang,Xiangtai Li,Manyuan Zhang,Hongsheng Li,Pheng-Ann Heng", "background": "近年来，视频生成模型能够生成高保真度和时空一致性的视频，这表明它们可能具备丰富的世界知识。除了现实合成外，这些模型还表现出视觉感知、建模和操作的新兴行为。然而，一个重要问题仍然存在：视频模型是否准备好在具有挑战性的视觉推理场景中作为零样本推理工具使用？因此，本研究旨在通过全面调查了解Vevo-3等领先和流行视频模型的推理行为，涵盖12个维度，包括空间、几何、物理、时间和具身逻辑，系统地描述其优势与失效模式。为此，还构建了MME-CoF基准，用于综合评估视频模型的链式框架推理能力。", "innovation": "本研究通过全面的数据集和评估方法，系统地评估了视频生成模型在视觉推理中的表现，特别是利用自定义的MME-CoF基准进行链式框架推理评估。这是首次将视频生成模型的专业推理能力进行标准化评估，并全面解析了其在短时域和长时间域推理、局部一致性与严格几何约束等方面的优劣。", "conclusion": "虽然当前的视频模型在短时域的空间一致性、细粒度的归属和局部一致的动力学上表现出良好的推理模式，但在长时间的因果推理、严格几何约束和抽象逻辑方面仍有局限。总体而言，这些模型尚未可靠地作为零样本推理工具存在，但在与专门推理模型互补的视觉引擎方面显示出了有希望的迹象。"}
{"llm_update_time": "20251101", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2404.00176", "html_url": "https://arxiv.org/abs/2404.00176", "title": "LSCD基准：历时词语意义任务的测试平台", "title_en": "The LSCD Benchmark: a Testbed for Diachronic Word Meaning Tasks", "authors": "Dominik Schlechtweg,Sachin Yadav,Nikolay Arefyev", "background": "LSCD是一个复杂的、基于词素级别的任务，通常通过两个后续的应用使用的任务进行操作化：首先为词对生成WiC标签，然后在构建的图上应用WSI以提取义项簇，最后通过对比时间上的义项簇来获取LSCD标签。这种模块性体现在多数LSCD数据集和模型中，导致了模型选项和任务定义的大量异质性。异质性使得在可比条件下评估模型、选择最优模型组合或复现实验结果变得困难。因此，该研究提供了一个基准仓库，标准化了LSCD的评估。该仓库透明地实施实施结果，使其容易复现，并通过标准化使不同的组件可以自由组合。该仓库体现了任务的模块性，允许对WiC、WSI和LSCD的模型进行评估。", "innovation": "该研究提供了一个标准化LSCD评估的基准仓库，通过对复杂模型组件的精细评估提供新的优化方法。该基准使用了最新模型进行了多组实验，系统性地提高了现有最先进的LSCD模型。", "conclusion": "该基准的透明实施结果使评估模型变得容易复现，并通过标准化的不同组件组合为更复杂的模型组件提供了新的评估途径，从而使LSCD研究更加有效和标准化。"}
{"llm_update_time": "20251101", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2502.04380", "html_url": "https://arxiv.org/abs/2502.04380", "title": "多样性的奖励：在混合无领域确定数据上微调大语言模型", "title_en": "Diversity as a Reward: Fine-Tuning LLMs on a Mixture of Domain-Undetermined Data", "authors": "Zhenqing Ling,Daoyuan Chen,Liuyi Yao,Qianli Shen,Yaliang Li,Ying Shen", "background": "大规模语言模型（LLMs）的微调需要使用多样化的数据集，以便在多种领域内提升整体性能。然而，现有的基于数据组成模型混合比例的方法难以处理缺失、不精确或未标准化领域标签的数据，而基于数据选择的方法则难以平衡多领域性能。本文探讨了数据多样性在提升LLMs综合能力中的作用，通过构建对比数据池和理论分析来解决现有方法的挑战，并提出了一种新方法。", "innovation": "本文提出了一种新的方法，赋予LLM双重身份：输出模型用于认知性地探查和基于多样性奖励选择数据，输入模型则根据选定的数据进行调整。这种方法显著提升了应用于各种先进LLM时在未确定领域的数据和一系列基础下游任务上的性能。", "conclusion": "广泛的实验表明，提出的方法在多种先进LLM上显著提升了性能，并在未确定领域数据和一系列基础下游任务上表现出色。研究还发布了代码，希望这一研究能够增进对数据多样性的理解，并促进反馈驱动的数据-模型联合设计。"}
{"llm_update_time": "20251101", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2410.12869", "html_url": "https://arxiv.org/abs/2410.12869", "title": "使用多个弱评估器的语言模型偏好评估", "title_en": "Language Model Preference Evaluation with Multiple Weak Evaluators", "authors": "Zhengyu Hu,Jieyu Zhang,Zhihan Xiong,Alexander Ratner,Kaize Ding,Ranjay Krishna", "background": "尽管大型语言模型（LLMs）取得了显著成功，但在评估它们输出的质量时，尤其是按照偏好进行评估，仍然存在重大挑战。常见的方法是使用一个强大的LLM作为评判者来比较两个LLM的响应，但这种方法容易产生循环偏好，即输出A优于B，B优于C，但C又优于A，导致矛盾的评价结果。", "innovation": "为了应对这一问题，本文提出了PGED（偏好图集成和去噪），这是一种利用多个基于模型的评判者构建偏好图，并通过集成和去噪这些图以获得无循环且无矛盾的评价结果的新方法。本文提供了该框架的理论保证，证明其能够恢复真实的偏好结构。通过对十个基准进行广泛实验，展示了PGED在三个应用场景中的优越性：1）评估中的模型排序；2）测试时的响应选择；3）模型微调中的数据选择。特别地，PGED将小型LLM评估者（如Llama3-8B、Mistral-7B、Qwen2-7B）结合使用，超过了强大的评估者（如Qwen2-72B），进一步展示了其提升评价可靠性和改善模型性能的有效性。", "conclusion": "PGED以其多模型集成和去噪策略，成功解决了循环偏好问题，为LLM的偏好评估提供了可靠的方法。广泛实验验证了其在多种场景下的优越性能，并表明较小的LLM评估者组合可以超越强大的单个评估者，进一步证明了其增强评价可靠性和提升模型性能的能力。"}
{"llm_update_time": "20251101", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2503.00333", "html_url": "https://arxiv.org/abs/2503.00333", "title": "持续存在的代表性危害：在增加代表性情况下", "title_en": "More of the Same: Persistent Representational Harms Under Increased Representation", "authors": "Jennifer Mickel,Maria De-Arteaga,Leqi Liu,Kevin Tian", "background": "认识到并减轻生成式AI系统的危害需要考虑生成式AI系统输出中的人物代表性。然而，简单地改善人物代表性并不意味着已经实施了抵消代表方式偏见的努力。本文通过研究最先进的大型语言模型中性别在职业上的表现来考察这个问题。研究发现，尽管有增加女性代表性的干预措施，但不同性别在不同方面的代表性仍然存在偏见，造成了新的代表性的危害、刻板印象和强调极权主义理想，这些倾向在许多情况下实际上加强了现有的压迫体系。", "innovation": "本文通过分析最先进的语言模型中性别在职业上的代表性，揭示了代表性偏见的持续存在。研究不仅展示了随着时间的推移，模型对性别分布的影响有所改变，而且指出即使有增加女性代表性的干预措施，性别在不同方面的代表性仍然存在显著差异，这些差异导致了新的代表性的危害、刻板印象和强调极权主义理想。", "conclusion": "研究结果表明，在增加代表性的情况下，代表性偏见并未消除，反而导致了新的代表性的危害、刻板印象和强调极权主义理想的滋生，尽管存在增加女性代表性的干预措施，但现有的压迫体系仍然被强化，需要进行更深入的偏见缓解努力。"}
{"llm_update_time": "20251101", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2410.16325", "html_url": "https://arxiv.org/abs/2410.16325", "title": "这位候选人是[匿名]. 基于提示的情感提取和参考信", "title_en": "This Candidate is [MASK]. Prompt-based Sentiment Extraction and Reference Letters", "authors": "Fabian Slonimczyk", "background": "本文提出了一种相对简单的方法，用于部署预训练的大语言模型（LLMs），以从文本数据中提取情感和其他有用特征。这种方法无需对文本进行预处理，并能生成具有概率解释的情感分数，这比其他常用经济和金融领域的办法有多个优点。作者应用该提示策略对一手收集的保密参考信（RLs）进行了分析，展示了情感信的内容与求职市场的结果之间存在明显关联，且情感分散会对求职者的市场表现产生负面影响。为了对比，作者将情感提取方法与其他常用的情感分析方法（如词袋方法、微调语言模型和查询高级聊天机器人）进行了比较，并证明了没有其他方法能完全复制基于提示的情感提取方法的结果。进一步通过修改方法得到了性别情感评分，并揭示了女性和男性候选人在参考信中被强调的不同人格特质，这对女性求职市场结果产生了负面影响.", "innovation": "提出的基于提示的情感提取方法，无需对文本进行预处理或微调，并能生成具有概率解释的情感分数。该方法在提取文本情感方面具有独特优势，尤其是在经济和金融领域，比其他方法更具实用性。此外，作者还通过简单修改该方法，得到了更具针对性的性别情感评分，提供了详细的情感特征分析，进一步揭示了性别在情感表达中的差异对求职市场影响的具体表现。", "conclusion": "基于提示的情感提取方法在经济和金融领域的应用中表现出色，无需额外的标签数据或微调过程，能够直接从非处理的文本中提取情感。作者证明了参考信中的情感内容鲜明地反映在求职市场结果中，且情感分散对求职者的市场表现产生负面影响。同时，修改后的性别情感评分揭示了性别在情感表达上的差异对女性求职市场的不利影响，强调了情感提取在理解和优化求职过程中的作用。"}
{"llm_update_time": "20251101", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2502.14409", "html_url": "https://arxiv.org/abs/2502.14409", "title": "长查询上下文聚焦摘要中的非结构化证据归属", "title_en": "Unstructured Evidence Attribution for Long Context Query Focused Summarization", "authors": "Dustin Wright,Zain Muhammad Mujahid,Lu Wang,Isabelle Augenstein,David Jurgens", "background": "大语言模型（LLMs）能够根据用户查询，从非常长的内容中生成连贯的摘要，并提取和引用证据段落可以提高这些摘要的可信度。然而，先前的工作主要集中在固定粒度（例如句子、段落、文档等）的证据引用上，本文提出了提取非结构化的（即任何长度的段落）证据，以获得比固定粒度情况更相关和一致的证据。现有的系统在复制和正确引用非结构化证据方面表现出色，这也往往导致证据“消失在中间”。为了帮助模型执行此任务，本文创建了Summaries with Unstructured Evidence Text数据集（SUnsET），这是一个使用新颖管道生成的合成数据集，可用于非结构化证据摘要的训练监督。", "innovation": "本文创新地提出了提取非结构化的证据，与现有固定粒度证据的方法相比，可以更好地获取更相关和一致的证据。同时，本文创建了SUnsET数据集，用于非结构化证据摘要的训练监督，可以帮助模型更好地生成与上下文相匹配的、且包含多样来源的摘要。实验结果表明，使用SUnsET训练的LLMs相比未微调的模型和固定粒度证据的基线模型，生成的证据更相关也更一致，摘要的生成也更加多元和连贯。", "conclusion": "本文通过创造SUnsET数据集，证明了提取非结构化证据对生成高质量、可信的摘要至关重要。经过SUnsET训练的LLMs在几个数据集上表现出更一致和相关的内容提取与概括。此外，本文公开了SUnsET数据集和生成代码，这些资料将对后续相关研究有重要价值。"}
{"llm_update_time": "20251101", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2504.04953", "html_url": "https://arxiv.org/abs/2504.04953", "title": "M-Prometheus: 一套开源多语言LLM评判器", "title_en": "M-Prometheus: A Suite of Open Multilingual LLM Judges", "authors": "José Pombal,Dongkeun Yoon,Patrick Fernandes,Ian Wu,Seungone Kim,Ricardo Rei,Graham Neubig,André F. T. Martins", "background": "近年来，语言模型用于自动评估长文本（如LLM作为裁判）的应用越来越普遍。然而，现有的大多数LLM裁判主要针对英语进行优化，对于多语言评估能力的提升策略在现有文献中研究较少。这导致了一些非英语语言的自动评估方法质量较低，阻碍了具备更好多语言能力模型的发展。", "innovation": "本文介绍了一套从3B到14B参数范围的开源多语言LLM裁判器，即M-Prometheus。该模型在超过20种语言的多语言奖励基准测试中表现出色，并且在涵盖4种语言对的文学机器翻译评估中也表现出色。M-Prometheus还能够在解码时显著提升所有3种测试语言生成的输出质量。此外，通过大量实验证明，选择基础模型和使用合成多语言反馈数据而非翻译数据进行训练是获得有效多语言裁判的关键因素。", "conclusion": "M-Prometheus模型在多语言自动评估和生成方面表现出色，为多语言模型的发展提供了有力支持。作者通过开放模型、训练数据集和代码的方式，为相关领域的发展做出了贡献。"}
{"llm_update_time": "20251101", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2504.01001", "html_url": "https://arxiv.org/abs/2504.01001", "title": "零样本基准测试：一种用于自然语言模型灵活性和扩展性自动评估的框架", "title_en": "Zero-shot Benchmarking: A Framework for Flexible and Scalable Automatic Evaluation of Language Models", "authors": "José Pombal,Nuno M. Guerreiro,Ricardo Rei,André F. T. Martins", "background": "随着语言模型的进步和跨模态任务能力的增强，自动评估它们变得越来越具有挑战性。开发强健且针对特定任务的自动评估指标越来越困难，而昂贵且耗时的人工标注数据集很快就会饱和。以往的尝试要么依赖于预先存在的数据，要么仅专注于个别任务。因此，需要一种可靠的方法来自动化测试数据和评估过程。", "innovation": "本文提出了零样本基准测试（ZSB）框架，该框架利用语言模型来创建合成的测试数据和进行评估。ZSB框架简单灵活，只需创建生成数据和评估的数据提示即可适应收集真实数据成本高昂或不切实际的任务和语言。它是模型无关的，随着模型的进步可以创建更具挑战性的基准。通过创建五个纯文本任务和一个跨模态任务的基准，并评估多种开放或封闭系统的排名，证明了ZSB框架的有效性，其排名与人类评估高度相关，优于广泛采用的标准基准。", "conclusion": "通过消融实验，我们发现可以使用开源模型创建强大的基准，且评判模型大小和数据集多样性是关键驱动力。已发布所有基准和进行实验以生成新基准所需的代码。"}
{"llm_update_time": "20251101", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2504.05747", "html_url": "https://arxiv.org/abs/2504.05747", "title": "SEA-LION: Southeast Asian Languages in One Network", "title_en": "SEA-LION: Southeast Asian Languages in One Network", "authors": "Raymond Ng,Thanh Ngan Nguyen,Yuli Huang,Ngee Chia Tai,Wai Yi Leong,Wei Qi Leong,Xianbin Yong,Jian Gang Ngui,Yosephine Susanto,Nicholas Cheng,Hamsawardhini Rengarajan,Peerat Limkonchotiwat,Adithya Venkatadri Hulagadri,Kok Wai Teng,Yeo Yeow Tong,Bryan Siow,Wei Yi Teo,Wayne Lau,Choon Meng Tan,Brandon Ong,Zhi Hao Ong,Jann Railey Montalan,Adwin Chan,Sajeban Antonyrex,Ren Lee,Esther Choa,David Ong Tat-Wee,Bing Jie Darius Liu,William Chandra Tjhi,Erik Cambria,Leslie Teo", "background": "大型语言模型（LLMs）在处理和生成自然语言方面表现出色，但大多数研究和开发仍以英语为中心，忽视了低资源语言如东南亚地区的语言。这导致了这些地区语言的代表性不足，形成了语言差距问题。", "innovation": "本文介绍了两种为东南亚语言设计的先进多语言LLMs，即Llama-SEA-LION-v3-8B-IT和Gemma-SEA-LION-v3-9B-IT。这些模型支持包括英语、中文、印尼语、越南语等在内的11种东南亚语言。通过大规模多语言持续预训练，并结合多阶段指令微调、对齐和模型合并等细致的后处理程序，本文实现了在支持东南亚语言的LLMs中性能最优的结果。", "conclusion": "本文开放源代码，使东南亚地区社区能够受益于这些先进的多语言LLMs，主要用于东南亚语言的处理和生成任务。"}
{"llm_update_time": "20251101", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2503.03710", "html_url": "https://arxiv.org/abs/2503.03710", "title": "通过双重目标优化提高大语言模型安全性对齐", "title_en": "Improving LLM Safety Alignment with Dual-Objective Optimization", "authors": "Xuandong Zhao,Will Cai,Tianneng Shi,David Huang,Licong Lin,Song Mei,Dawn Song", "background": "现有的大语言模型（LLMs）的训练时安全对齐技术依然容易受到 Jailbreak 攻击。传统的方法，如直接偏好优化（DPO），在实验和理论层面上都显示出局限性，尤其是在抗拒学习方面表现不佳。研究通过梯度分析指出了这些问题，并提出了一种改进的安全对齐方法，该方法将 DPO 目标分解为两个部分：一是增强的抵抗训练，即使在部分不安全的生成内容中也能鼓励拒绝；二是针对有害知识的精细遗忘。这一方法提高了 LLM 对多种 Jailbreak 攻击的鲁棒性，包括针对分布内和分布外场景的预填、后缀和多轮攻击。此外，研究引入了一种通过奖励机制强调关键拒绝标记的方法，进一步增强了对对抗攻击的鲁棒性。", "innovation": "研究提出了双重目标优化方法，将 DPO 目标分解为两个组成部分：增强的抵抗训练和针对有害知识的精细遗忘。此外，研究引入了一种奖励机制，用于强调关键拒绝标记，以进一步提高对对抗攻击的鲁棒性。该方法显著提高了 LLM 对各种 Jailbreak 攻击的鲁棒性。该研究还提出了鲁棒性与训练过程中标记分布变化和拒绝与有害标记的内部表示之间的相关性，为未来大语言模型的安全对齐研究指明了方向。", "conclusion": "该研究通过双重目标优化显著提高了大语言模型在多种 Jailbreak 攻击下的鲁棒性。研究结果表明，这种鲁棒性与训练过程中标记分布的变化以及拒绝和有害标记的内部表示有关，从而为未来的研究提供了宝贵的指导方向。代码可以在这里获取：[this https URL](this https URL)，"}
{"llm_update_time": "20251101", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2504.11331", "html_url": "https://arxiv.org/abs/2504.11331", "title": "依赖结构增强上下文规约框架在多模态方面基于情感分析中的应用", "title_en": "Dependency Structure Augmented Contextual Scoping Framework for Multimodal Aspect-Based Sentiment Analysis", "authors": "Hao Liu,Lijun He,Jiaxi Liang,Zhihan Ren,Haixia Bi,Fan Li", "background": "MABSA旨在从图像-文本对中提取细粒度信息以识别方面术语并确定其情感极性。然而，现有方法在同时解决情感线索感知（SCP）、多模态信息不一致（MIM）和语义噪声消除（SNE）这三个核心挑战方面往往存在不足。", "innovation": "本文提出了一种依赖结构增强范围框架（DASCO），这是一种细粒度的范围导向框架，通过使用依赖解析树增强了方面级别的情感推理。通过多任务预训练策略，结合方面导向增强、图像-文本匹配和方面级别情感敏感的认知，改善了模型对方面术语和情感线索的感知，解决了关键挑战如SCP和MIM。同时，将依赖树作为语法分支与语义分支结合，引导模型在特定目标范围内的选择性注意力，有效地过滤掉无关噪声，以解决SNE问题。", "conclusion": "在两个基准数据集上的三项子任务中进行的大量实验表明，DASCO在MABSA中实现了最先进的性能，特别是在JMASA中获得了显著的提升（F1值+2.3%和精确度+3.5%的Twitter2015）。源代码可在指定链接处获取。"}
{"llm_update_time": "20251101", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2505.14604", "html_url": "https://arxiv.org/abs/2505.14604", "title": "通过自我制动调节让LRM摆脱过度思考", "title_en": "Let LRMs Break Free from Overthinking via Self-Braking Tuning", "authors": "Haoran Zhao,Yuchen Yan,Yongliang Shen,Haolei Xu,Wenqi Zhang,Kaitao Song,Jian Shao,Weiming Lu,Jun Xiao,Yueting Zhuang", "background": "大型推理模型（LRMs）如OpenAI的o1和DeepSeek-R1通过生成更长的推理链路显著增强了其推理能力，在多个任务中的表现突出，但这一能力的提升伴随着推理过程中的大量冗余，增加了计算负担并加剧了过度思考的问题。尽管有许多方法试图解决过度思考问题，但大多依赖于外部干预。", "innovation": "本文提出了一种名为自我制动调节（SBT）的新框架，从让模型自行调节其推理过程的角度解决过度思考问题，从而消除对外部控制机制的依赖。该框架包括一套基于标准答案的过度思考识别指标，用于检测冗余推理，精准识别推理路径中的多余步骤，并生成训练信号以学习自我调节行为。此外，还开发了一种适应性推理长度的数据构建策略，并引入了一种创新的制动提示机制，使模型能在适当的时间自然停止推理。", "conclusion": "实验结果显示，本方法在数学基准测试（AIME、AMC、MATH500、GSM8K）中的 token 消耗降低了60%以上，同时保持与未约束模型相当的准确性。"}
{"llm_update_time": "20251101", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2505.13444", "html_url": "https://arxiv.org/abs/2505.13444", "title": "ChartMuseum：测试大型视觉语言模型的视觉推理能力", "title_en": "ChartMuseum: Testing Visual Reasoning Capabilities of Large Vision-Language Models", "authors": "Liyan Tang,Grace Kim,Xinyu Zhao,Thom Lake,Wenxuan Ding,Fangcong Yin,Prasann Singhal,Manya Wadhwa,Zeyu Leo Liu,Zayne Sprague,Ramya Namuduri,Bodun Hu,Juan Diego Rodriguez,Puyuan Peng,Greg Durrett", "background": "大型视觉语言模型（LVLM）在图示理解方面面临独特挑战，需要结合复杂的文本和视觉推理能力。目前的LVLM在视觉推理方面存在明显短板，难以在文本中完成这些任务。研究通过合成数据集进行案例研究，发现随着视觉复杂性的增加，模型性能明显下降，而人类性能保持稳定。因此，提出ChartMuseum作为新图表问答（QA）基准，包括1,162个由专家注释的多元推理类型问题，精选自184个真实数据源中的图表，旨在评估复杂的视觉和文本推理能力。", "innovation": "引入了一个新的图表问答基准——ChartMuseum，该基准包含1,162个由专家注释的问题，涵盖多种推理类型，来源于184个真实世界的图表集合，特别设计用于评估复杂的视觉与文本推理能力。与先前的图理解基准不同，ChartMuseum揭示了模型与人类之间性能的巨大差距，有效区分了模型的能力：尽管人类准确率达到93%，但性能最好的模型Gemini-2.5-Pro仅为63.0%，而开源LVLM Qwen2.5-VL-72B-Instruct仅为38.5%。此外，对视觉推理问题，所有模型的表现都比文本推理的问题下降了35%-55%。", "conclusion": "尽管目前的最佳模型在某些类型的问题上表现不佳，但具体发现了一些当前LVLM难以处理的视觉推理类别。"}
{"llm_update_time": "20251101", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2505.15095", "html_url": "https://arxiv.org/abs/2505.15095", "title": "Nek Minit: 运用基于语用元认知提示进行澳大利亚英语和印度英语可解释的讽刺检测", "title_en": "Nek Minit: Harnessing Pragmatic Metacognitive Prompting for Explainable Sarcasm Detection of Australian and Indian English", "authors": "Ishmanbir Singh,Dipankar Srirag,Aditya Joshi", "background": "讽刺对情感分析构成了挑战，因为表面上的表达与实际含义之间存在不一致。这种不一致被加剧，当附加含义与特定国家或地理区域相关时。现有技术如Pragmatic Metacognitive Prompting（PMP）被用于启发式的语用推理。本文利用PMP技术开发了一种澳大利亚英语和印度英语的可解释讽刺检测方法，并结合了一个涵盖标准英语的基准数据集。这种方法还扩展了BESSTIE讽刺标记数据集，加入了手动标注的讽刺解释。整个研究基于两个开源大型语言模型（GEMMA和LLAMA）进行评估。", "innovation": "本文提出了一种利用PMP（Pragmatic Metacognitive Prompting）生成多种英语变体的讽刺解释的方法。在对两个开源大型语言模型（GEMMA和LLAMA）的评估中，这种方法在所有任务和数据集上都表现出了统计学上的显著性能提升，相较于四种其他提示策略，展示了PMP的有效性和广泛适用性。此外，研究还发现另一种提示技术（机构性提示）能够通过启用外部知识检索来缓解与情景相关的失败。", "conclusion": "本文通过比较PMP及其他多样提示策略的表现，展示了PMP在生成澳大利亚英语和印度英语讽刺解释中的优势，并且发现了另一种提示技术对解决情景相关问题的有效性。进一步的工作将会验证其他语言变体和不同类型数据集中的可行性和有效性。"}
{"llm_update_time": "20251101", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2506.09391", "html_url": "https://arxiv.org/abs/2506.09391", "title": "在自由生成任务中比较人类和大规模语言模型的礼貌策略", "title_en": "Comparing human and LLM politeness strategies in free production", "authors": "Haoran Zhao,Robert D.Hawkins", "background": "大规模语言模型在礼貌表达方面面临着基本对齐挑战。人类使用丰富的语言策略来平衡信息性和社交目标，包括积极的策略如恭维和表达兴趣，以及消极的策略如避免强加（如含糊其辞和委婉言语）。本研究通过对比人类和语言模型在受限和开放生成任务中的响应来探讨模型是否能提供类似上下文敏感的礼貌策略。", "innovation": "研究通过对比人类和大模型在受限和开放生成任务中的响应，发现更大的模型（参数数≥70B）成功复制了计算语用学中的关键偏好，即使在积极情境下模型也倾向于使用负面礼貌策略。研究意外发现人类评估者更喜欢语言模型生成的开放生成任务中的回答。", "conclusion": "尽管现代语言模型在礼貌策略方面表现出色，但这些微妙差异引发了关于AI系统语用对齐的重要问题。模型在积极情境中过度依赖负面礼貌策略可能导致误解。"}
{"llm_update_time": "20251101", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2505.24388", "html_url": "https://arxiv.org/abs/2505.24388", "title": "ClueAnchor: 基于线索锚定的知识推理探索与优化以增强检索增强生成", "title_en": "ClueAnchor: Clue-Anchored Knowledge Reasoning Exploration and Optimization for Retrieval-Augmented Generation", "authors": "Hao Chen,Yukun Yan,Sen Mei,Wanxiang Che,Zhenghao Liu,Qi Shi,Xinze Li,Yuchun Fan,Pengcheng Huang,Qiushi Xiong,Zhiyuan Liu,Maosong Sun", "background": "检索增强生成（RAG）利用外部知识增强大型语言模型（LLMs），以提高事实准确性。然而，现有的RAG系统通常未能充分利用检索到的文档，无法提取并整合支持忠实和可解释推理的关键线索，特别是在相关证据隐含、分散或被噪声混淆的情况下，导致性能受限。", "innovation": "ClueAnchor 提出了一种新的框架，通过线索锚定的推理探索和优化来增强 RAG。它从检索内容中提取关键线索，基于不同的知识配置生成多种推理路径，并通过基于奖励的偏好优化选择最适合给定上下文的推理路径。实验表明，ClueAnchor 在推理的完整性和鲁棒性方面显著优于之前的 RAG 基线。研究进一步证实，其在面对噪声或部分相关的检索结果时表现出强大的鲁棒性，并能够在推理时缺乏明确线索监督的情况下，仍然能够识别支持证据。", "conclusion": "ClueAnchor 在增强 RAG 的推理能力和抵御噪声干扰方面取得了显著成效，展示了优异的表现和对不同场景的高适应性。"}
{"llm_update_time": "20251101", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2506.02175", "html_url": "https://arxiv.org/abs/2506.02175", "title": "AI辩论有助于评估争议性声明", "title_en": "AI Debate Aids Assessment of Controversial Claims", "authors": "Salman Rahman,Sheriff Issaka,Ashima Suvarna,Genglin Liu,James Shiffer,Jaeyoung Lee,Md Rizwan Parvez,Hamid Palangi,Shi Feng,Nanyun Peng,Yejin Choi,Julian Michael,Liwei Jiang,Saadia Gabriel", "background": "随着人工智能变得越来越强大，它将越来越多地塑造我们对世界的理解。但在增强影响力的同时，也会有放大虚假信息和加深社会分歧的风险，尤其是在关于直接影响福祉的事实准确性至关重要的领域。《可扩展监督》旨在确保即使在技术能力超越评估者的情况下，人工智能系统仍然保持真实。然而，当人类作为评估者时，他们的信念和偏见会干扰判断。因此，研究者通过让两组AI系统分别辩论关于冠状病毒和气候变化等有争议的事实性主张来探讨AI辩论是否可以帮助带有强烈先验信念的带有偏见的法官接近事实。此次研究通过两组研究进行。\n", "innovation": "该研究创新性地采用AI与人类共同参与的方式，通过AI辩论指导有偏见的人类法官更加准确地评估有争议的声明，尤其是针对那些人类具有强烈先验信念的领域，例如冠状病毒和气候变化。\n", "conclusion": "研究发现，辩论可以持续提升人类法官的判断准确性和情绪校准。对于持有主流观点的法官，准确认定的提高幅度尤为显著，在冠状病毒声明中的最高可达15.2%。即使没有人类特征的默认AI法官效率也提高了4.7%。另外，具有人类特征的AI法官表现出更高的准确度（78.5%），高于人类法官的表现（70.1%），也高于没有人类特征的默认AI法官的表现（69.8%）。这些发现突显了AI辩论作为一种有前景的方法，能够在有争议的领域实现可扩展且抗偏见的监督。\n"}
{"llm_update_time": "20251101", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2506.08410", "html_url": "https://arxiv.org/abs/2506.08410", "title": "大型语言模型具有内在的元认知能力，但需要好的视角", "title_en": "Large Language Models Have Intrinsic Meta-Cognition, but Need a Good Lens", "authors": "Ziyang Ma,Qingyue Yuan,Zhenglin Wang,Deyu Zhou", "background": "先前的研究主要集中在大型语言模型（LLMs）的认知错误检测能力上，通常会促使它们分析推理链中的错误。然而，很少有研究探讨LLMs的元认知能力（例如，它们对自己步骤错误的认识），这对于其可靠性至关重要。虽然有一些关于LLMs自我评估的研究，它们提供了一些度量标准，如困惑度，可以反映答案的正确性并被视为元认知的视角，但这些度量标准缺乏步骤层面的分析和调整能力。", "innovation": "本研究提出了一种名为AutoMeco的自动化元认知评估框架，用于基准测试现有的度量标准，并提出了一种无需训练的马尔可夫内生奖励调整策略（MIRA），以增强现有的元认知度量。实验结果显示AutoMeco是合理的，通过与Best-of-N验证进行比较。此外，利用MIRA可以更好地评估LLMs的元认知能力。", "conclusion": "实验结果表明，AutoMeco是一种合理的基准工具，可以帮助评估现有的元认知度量。此外，MIRA策略可以提高当前元认知度量的有效性，从而更好地评估LLMs的元认知能力。"}
{"llm_update_time": "20251101", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2506.04721", "html_url": "https://arxiv.org/abs/2506.04721", "title": "SPARTA ALIGNMENT: 通过战斗集体对齐多个语言模型", "title_en": "SPARTA ALIGNMENT: Collectively Aligning Multiple Language Models through Combat", "authors": "Yuru Jiang,Wenxuan Ding,Shangbin Feng,Greg Durrett,Yulia Tsvetkov", "background": "该研究背景在于现有的单一语言模型（LLM）在生成多样性方面可能有限，并且在评估时存在偏见。多模型协作机制可以弥补单一模型的不足，通过相互竞争和评判，实现更具一致性与多样性的对齐结果。现有的自对齐方法通常表现出有限的性能提升，因此需要一种新的机制来更有效地对齐多个模型，特别是用于构建逻辑性更强、更直接、更有信息量的输出。", "innovation": "该研究提出了SPARTA ALIGNMENT算法，这是一种通过竞争和评判实现多个模型集体对齐的方法。具体而言，SPARTA ALIGNMENT构建了一个由多个模型组成的‘SPARTAN部落’，在每一轮迭代中，选择一个指令和两个模型进行对决，其他模型作为评委评判参赛者的回应，通过调整的Elo排名系统来汇总评估得分，胜者和败者在后续评估中权重调整。通过这种自我演化的过程，所有模型都能从互相的优缺点中学习，从而提升对齐效果。研究对比了不同基线方法，证明SPARTA ALIGNMENT在12个任务中的10项任务上优于初始模型和4个自对齐基线方法，平均提升7%的效果，并且在未见过的任务上也表现出更好的泛化能力。", "conclusion": "SPARTA ALIGNMENT通过迭代和集体竞争的机制，使多个模型能够在评估和生成多样性方面更加一致和高效，从而产出更逻辑性强、更直接、更有信息量的输出。这种方法解决了单一模型生成局限性和评估偏见的问题，显著提升了模型对齐的效果和泛化能力。"}
{"llm_update_time": "20251101", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2506.07001", "html_url": "https://arxiv.org/abs/2506.07001", "title": "对抗重述：一种普遍的攻击方法以人性化人工智能生成的文本", "title_en": "Adversarial Paraphrasing: A Universal Attack for Humanizing AI-Generated Text", "authors": "Yize Cheng,Vinu Sankar Sadasivan,Mehrdad Saberi,Shoumik Saha,Soheil Feizi", "background": "随着大型语言模型（LLMs）能力的提高，人们对它们在人工智能生成的剽窃和社会工程学中的滥用表示担忧。虽然已经提出了许多AI生成文本检测器来缓解这些风险，但许多检测器仍然容易被简单的绕过技术（如改写）攻击。最近的检测器显示了对基本攻击更强的鲁棒性。这篇论文的背景是基于此问题，研究如何有效地规避这些检测器，而不影响文本质量。", "innovation": "论文引入了一种名为对抗重述的无训练攻击框架，该框架通过利用现成的指令跟随的大规模语言模型在AI文本检测器的指导下改写人工智能生成的内容，产生针对性的对抗样本以绕过检测。相比于简单的改写攻击，对抗重述攻击在多种检测系统中显示出更高的有效性与更强的可移植性。", "conclusion": "该论文发现，对抗重述攻击在不同的检测器（包括基于神经网络的、基于水印的和零样本的方法）中，平均能够将检测率降低87.88%，同时在保持适度的文本质量损失的情况下，显著降低了被检测的风险。这一结果需要引起对更稳定和更具有鲁棒性的检测策略的关注，以应对日益复杂的规避技术。"}
{"llm_update_time": "20251101", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2506.11094", "html_url": "https://arxiv.org/abs/2506.11094", "title": "正义之衡：大规模语言模型安全评估的综合研究", "title_en": "The Scales of Justitia: A Comprehensive Survey on Safety Evaluation of LLMs", "authors": "Songyang Liu,Chaozhuo Li,Jiameng Qiu,Xi Zhang,Feiran Huang,Litian Zhang,Yiming Hei,Philip S. Yu", "background": "随着人工智能的快速发展，大型语言模型（LLMs）在自然语言处理（NLP）方面展现了显著的能力，这些能力包括内容生成、人机交互、机器翻译和代码生成。然而，其广泛应用也引发了重要的安全问题。特别是，LLMs生成的内容可能会表现出毒性、偏见或错误信息等不安全行为，尤其是在对抗情况下，这引起了学术界和工业界的广泛关注。尽管已有许多研究试图评估这些风险，但对于大规模语言模型安全评估的综合和系统性调查仍然缺乏。", "innovation": "本文旨在填补这一空白，通过提出一种四维度分类法：（i）为何评估，探讨安全评估背景，与一般LLMs评估的区别以及此类评估的意义；（ii）评估什么，基于关键能力对现有安全评估任务进行研究和分类，包括毒性、鲁棒性、伦理、偏见和公平性、真实性等方面的维度；（iii）在哪里评估，总结当前用于安全评估的评估指标、数据集和基准；（iv）如何评估，回顾现有主流的评估方法，基于评估者的角色和一些将整个评估流程整合的评估框架。此外，本文还指出了安全评估中的挑战，并提出了推动该领域进一步发展的有希望的研究方向，强调安全性评估的优先性以确保LLMs在实际应用中的可靠和负责部署。", "conclusion": "本文综合考察了大规模语言模型（LLMs）的安全评估研究，提出了一个四维度分类法，总结了相关的评估指标、数据集和基准，并回顾了现有评估方法。本文还指出了当前挑战，并提出了未来研究方向，强调了确保LLMs在实际应用中可靠和负责部署的重要性。"}
{"llm_update_time": "20251101", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2506.13229", "html_url": "https://arxiv.org/abs/2506.13229", "title": "IGD: 通过信息增益建模项目重要性以提升大型语言模型个性化推荐", "title_en": "IGD: Token Decisiveness Modeling via Information Gain in LLMs for Personalized Recommendation", "authors": "Zijie Lin,Yang Zhang,Xiaoyan Zhao,Fengbin Zhu,Fuli Feng,Tat-Seng Chua", "background": "大型语言模型（LLMs）因其将项目预测重新定义为逐词语言生成任务的能力，在推荐系统中展现出强大的潜力。然而，现有的方法未能识别和利用词级别决策的关键差异，即大多数词贡献不大但时常控制优化或解码过程。", "innovation": "本文提出了一个基于信息增益（Information Gain, IG）的决策意识令牌处理（Information Gain-based Decisiveness-aware Token handling, IGD）策略，该策略通过测量每个词在减少生成项目不确定性方面的信息增益来建模项目生成过程中的词级别决策性。IGD策略在调优和解码过程中整合了词的重要性，具体而言，在调优时降低低信息增益词的权重，并在解码时重新平衡以强调高信息增益词，从而超越简单的最大化似然性。", "conclusion": "IGD策略在四个基准数据集上与其他两个LLM后端模型的广泛实验表明，IGD能够有效提升推荐准确性，显著改善广泛使用的排名指标的性能，相比于基准模型有统计上的显著改进。"}
{"llm_update_time": "20251101", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2506.13464", "html_url": "https://arxiv.org/abs/2506.13464", "title": "揭开语言模型的学习之心：认知框架与实证研究", "title_en": "Unveiling the Learning Mind of Language Models: A Cognitive Framework and Empirical Study", "authors": "Zhengyu Hu,Jianxun Lian,Zheyuan Xiao,Seraphina Zhang,Tianfu Wang,Nicholas Jing Yuan,Xing Xie,Hui Xiong", "background": "大型语言模型（LLMs）在数学、编程和推理任务中展现了令人印象深刻的能力，但是它们的学习能力仍待深入研究。学习能力对于模型在动态环境中适应和获取新知识至关重要，而这一领域仍存在未被开发的空间。本文旨在弥补该领域的不足，通过借鉴认知心理学和教育学，提出一种新的学习框架，探讨三种学习维度：通过导师学习（借助显性指导获取知识）、通过概念学习（内部化抽象结构并通过新情境进行泛化）和通过经验学习（通过经验积累和反馈进行调整）", "innovation": "本文提出了一种新的框架，并通过实证研究，发现了几个有益的认识，如互动能提高学习效果；概念理解是规模涌现的，对更大模型有利；以及LLMs是有效的少数示例学习者但不是多数示例学习者。基于该框架和实证研究结果，研究人员引入了一个基准，实现了对LLMs在三种认知学习维度上通用学习能力的统一和现实评估，这有助于诊断性洞察和对更适应和人性化模型的开发与评估的支持", "conclusion": "本文提出了一种新的框架和基准，用以评估大型语言模型在三种认知学习维度上的通用学习能力，并通过实证研究得出了几个有益的认识。"}
{"llm_update_time": "20251101", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2507.03704", "html_url": "https://arxiv.org/abs/2507.03704", "title": "在推理模型中控制思考速度", "title_en": "Controlling Thinking Speed in Reasoning Models", "authors": "Zhengkai Lin,Zhihang Fu,Ze Chen,Chao Chen,Liang Xie,Wenxiao Wang,Deng Cai,Zheng Wang,Jieping Ye", "background": "人类认知被认为存在两种模式：快速直观的System 1思考和慢速精心构思的System 2思考。尽管当前的大规模推理模型（LRMs）在System 2思考方面表现出色，但它们不能执行快速思考的能力导致了高计算开销和延迟。为此，该论文旨在通过动态调整思考速度来使LRMs更接近人类智能，以优化准确性和效率之间的权衡。", "innovation": "论文通过以下创新实现了目标：1) 识别出控制LRMs表征空间中慢快速思考转换的引导向量；2) 引入实时难度估计来指示不同复杂度的推理段落；3) 提出了一种新的推理策略，能够快速处理简单步骤并深入分析复杂推理。这些方法使得LRMs插件模块在各种领先的LRMs和高级推理基准上提高了平均1.3%的准确度并将标记使用量降低了8.6%。", "conclusion": "所提出的算法基于vLLM实现，并预期能够支持更广泛的应用，并激发未来的研究。"}
{"llm_update_time": "20251101", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2507.19756", "html_url": "https://arxiv.org/abs/2507.19756", "title": "你是这儿吗，上帝？使用LM进行轻量级基督教小说叙事注解", "title_en": "Are You There God? Lightweight Narrative Annotation of Christian Fiction with LMs", "authors": "Rebecca M. M. Hicke,Brian W. Haggard,Mia Ferrante,Rayhan Khanna,David Mimno", "background": "美国福音主义除了其更为人所熟知的文化运动外，还拥有一个较为发达但对外界不太可见的文学方面。基督教小说在学术研究中鲜有关注，大部分研究集中在《末日之门》系列上。本文通过计算工具进行分析，旨在提供一个基督教小说整体主题概览，以及更详细的探讨作者如何描绘上帝的作为。", "innovation": "利用计算工具和语言模型轻量级注解基督教小说，特别开发了一个“上帝的行为”代码表，并用更大型的语言模型辅助调整，即使任务复杂也能基本匹配人工注解。", "conclusion": "研究发现，《末日之门》系列与基督教小说总体中描绘的上帝行为存在显著且有意义的差异。"}
{"llm_update_time": "20251101", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.11607", "html_url": "https://arxiv.org/abs/2508.11607", "title": "TinyTim：一种用于发散生成的语言模型家族", "title_en": "TinyTim: A Family of Language Models for Divergent Generation", "authors": "Christopher J. Agostino", "background": "在寻找通用人工智能的过程中，模型开发和训练主要依赖于大量的已知问题及其公认解决方案的数据集。这一过程产生了收敛性系统，导致这些系统天生无法实现需要真正创造性突破的概念重构。受到人类因多样认知过程能作出创造性飞跃的启发，本研究提出了一种名为TinyTim的语言模型家族，旨在作为广泛系统中的发散生成源。", "innovation": "这些模型通过将具有反简约特点的詹姆斯·乔伊斯作品《芬尼根守灵之夜》的文本进行微调而创建。无监督微调的TinyTim-V1模型和指令微调的新变种V2模型的定量分析表明，这些模型具有极强的词汇创造力。V1模型的Yule's K得分表明其词汇丰富度是收敛基准的二十多倍。这一特性在微调家族中是稳定的，V2模型不因指令微调而感到事实上的收敛，牺牲基准性能以保持其核心生成风格。", "conclusion": "本研究建立了一种工程特定发散模型的策略，当这些模型与收敛系统配对时，可以重新定义问题并迫使统计优化无法实现的突破。"}
{"llm_update_time": "20251101", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2507.13328", "html_url": "https://arxiv.org/abs/2507.13328", "title": "Vision-and-Language Training Helps Deploy Taxonomic Knowledge but Does Not Fundamentally Alter It", "title_en": "Vision-and-Language Training Helps Deploy Taxonomic Knowledge but Does Not Fundamentally Alter It", "authors": "Yulu Qin,Dheeraj Varghese,Adam Dahlgren Lindström,Lucia Donatelli,Kanishka Misra,Najoung Kim", "background": "大多数关于视觉-语言（VL）训练对语言模型的影响的研究表明，其差异在行为表现和表示方面并不明显或不一致。研究表明，VL训练可能影响的语言模型的领域是词概念知识，特别是其分类组织。为了验证这一假设，通过比较纯文本语言模型与其VL训练版本，研究发现VL模型在需要理解问题中提到的概念分类的文本问题回答任务中通常表现更好。但研究认为，语言模型和VL模型在分类知识本身上没有显著差异，而是在处理具有分类关系或非分类关系的概念时的表示方式上有所不同，这意味着虽然分类知识本身没有发生重大变化，但VL训练提高了其在特定任务中的应用能力，即便任务本身是纯语言的。", "innovation": "该研究通过最小对比较纯文本语言模型和它们的VL训练版本，探索了VL训练对语言模型中词概念知识分类组织的影响。证明了VL模型在涉及分类概念的理解问题回答任务中的表现优于纯文本模型；通过行为和表示分析，发现语言模型和VL模型在分类知识本身上并无显著差异，但在处理分类关系和非分类关系的概念时的表示方式上有差异。这表明，通过VL训练，分类知识本身没有发生重大改变，但改善了分类知识在特定任务场景中的应用。", "conclusion": "尽管VL训练没有在分类知识本身上产生根本的变化，但确实显著提升了分类知识在特定任务中的应用能力。"}
{"llm_update_time": "20251101", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2506.14681", "html_url": "https://arxiv.org/abs/2506.14681", "title": "大规模监督微调实验揭示数据、层和训练因素如何影响大语言模型对齐质量", "title_en": "Massive Supervised Fine-tuning Experiments Reveal How Data, Layer, and Training Factors Shape LLM Alignment Quality", "authors": "Yuto Harada,Yusuke Yamauchi,Yusuke Oda,Yohei Oseki,Yusuke Miyao,Yu Takagi", "background": "监督微调（SFT）是将大语言模型（LLMs）与人类指令和价值观对齐的关键步骤。然而，SFT 的许多方面仍然不为人所理解。研究者们通过控制条件训练了多种基础模型，覆盖了代码生成、数学推理和一般领域任务等多种数据集，产生了1,000多个SFT模型，以此来探索不同数据集属性的重要性及SFT带来的层级修改影响。研究发现，某些训练任务的协同效应跨所有模型得以保留，而其他效应则变化显著，强调了模型特定策略的重要性。同时，研究表明困惑度（perplexity）是一致预测SFT效果的关键指标，常常优于训练数据与基准数据表面相似程度，中期层权重变化与性能增益相关性最强。", "innovation": "研究中展示了1,000多个SFT模型和基准结果，揭示了数据、层次和训练因素如何共同影响大语言模型的对齐质量。研究通过大规模实验发现了一些关于SFT的重要见解，包括某些训练任务的协同效应在所有模型中得以保留、困惑度是SFT效果的一致预测指标以及中期层权重变化与性能增益相关性最强等。研究还提出了模型特定策略的重要性，并提供了所有资源以加速进一步的研究进度。", "conclusion": "研究结果表明，数据集属性、模型结构中不同层的修改以及训练过程中的因素共同决定了大语言模型的对齐质量。困惑度是预测SFT效果的关键指标，而且中期层权重的变化最直接影响性能。研究者发布了这些模型和结果，旨在推动进一步研究，所有资源可访问此链接：this https URL."}
{"llm_update_time": "20251101", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2507.16271", "html_url": "https://arxiv.org/abs/2507.16271", "title": "超越孤立点：结构化表格构建作为深度知识提取的基准测试", "title_en": "Beyond Isolated Dots: Benchmarking Structured Table Construction as Deep Knowledge Extraction", "authors": "Tianyun Zhong,Guozhao Mo,Yanjiang Liu,Yihan Chen,Lingdi Kong,Xuanang Chen,Yaojie Lu,Hongyu Lin,Shiwei Ye,Xianpei Han,Ben He,Le Sun", "background": "随着大型语言模型（LLMs）的出现，人们期望LLMs能够有效地从复杂的现实世界文档（如论文、报告）中提取明确的信息。然而，大多数LLMs生成的往往是段落式的回答，这些回答往往是混乱、无组织且难以追溯的。为了弥合这一差距，本文引入了Arranged and Organized Extraction Benchmark (AOE)，这是一种新的双语基准，包含不同长度的数据和文档，旨在系统性地评估LLMs从分散的文档中理解信息并将其重构为一个有序表格的能力。与依赖于固定模式和狭窄任务域的传统文本到表格任务不同，AOE包含了覆盖三个不同领域的11个精心设计的任务，要求模型生成与不同输入查询相适应的上下文特定模式。", "innovation": "本文提出了AOE，这是一种新的双语基准，用于系统性地评估LLMs从复杂的文档中提取和结构化信息的能力。AOE不同于传统的方法的地方在于它提供了覆盖多个领域、需要模型生成特定于上下文的模式的11个精心设计的任务。这种方法旨在评估LLMs在理解和重构现实世界文档中的能力，而不仅仅是依赖于固定的模式和狭窄的任务域。", "conclusion": "在实验中，我们对开源和闭源的最先进LLMs进行了评估。结果表明，即使是最先进的模型也遇到了显著的挑战。该基准可以在以下地址获取：this https URL。这篇论文表明，现有的LLMs在处理复杂文档和结构化信息时仍有很大的改进空间。"}
{"llm_update_time": "20251101", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2509.21319", "html_url": "https://arxiv.org/abs/2509.21319", "title": "RLBFF: 二元灵活反馈以弥合人类反馈与验证性奖励之间的差距", "title_en": "RLBFF: Binary Flexible Feedback to bridge between Human Feedback & Verifiable Rewards", "authors": "Zhilin Wang,Jiaqi Zeng,Olivier Delalleau,Ellie Evans,Daniel Egert,Hoo-Chang Shin,Felipe Soares,Yi Dong,Oleksii Kuchaiev", "background": "近年来，大语言模型（LLM）的后训练中使用了两种主要的强化学习范式：强化学习带人类反馈（RLHF）和强化学习带可验证奖励（RLVR）。尽管这两种方法各有优势，但RLHF由于依赖于缺乏明确标准的人类判断而在解释性和对抗样本方面存在局限，而RLVR则局限于基于正确性的验证器。", "innovation": "本文提出了二元灵活反馈（RLBFF）方法，该方法结合了人类驱动偏好和基于规则的验证的灵活性和精确性。RLBFF通过提取可以二元回答的原则（如信息准确性：是/否，代码可读性：否）从自然语言反馈中提炼原则，从而使奖励模型能够捕捉响应质量的多维方面，而不仅仅是正确性。此外，RLBFF在训练奖励模型方面达到了Bradley-Terry模型的数据相匹配条件下高出表现，同时在RM-Bench上获得了86.2%的最高性能，在JudgeBench上达到了81.4%的最高性能（截至2025年9月24日）。与Bradley-Terry模型不同，RLBFF允许用户在推理时指定感兴趣的原理以定制奖励模型的重点。最后，本文提供了一个完全开源的配方（包括数据），用于使用RLBFF和奖励模型对Qwen3-32B进行对齐，使其在通用对齐基准MT-Bench、WildBench和Arena Hard v2上的性能达到了与o3-mini和DeepSeek R1相当或超越的效果，且推理成本仅为后者的5%左右。", "conclusion": "通过实验结果表明，RLBFF能够有效弥合人类反馈与验证性奖励之间的差距，并在多个对齐基准测试中达到了出色的性能。这种方法为大语言模型的后训练提供了新的视角和方法。"}
{"llm_update_time": "20251101", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.04226", "html_url": "https://arxiv.org/abs/2510.04226", "title": "大型语言模型中的知识多样性与知识崩溃", "title_en": "Epistemic Diversity and Knowledge Collapse in Large Language Models", "authors": "Dustin Wright,Sarah Masud,Jared Moore,Srishti Yadav,Maria Antoniak,Chan Young Park,Isabelle Augenstein", "background": "大型语言模型（LLMs）生成的文本在词汇、语义和文体上往往高度一致，这可能导致知识崩溃，即随着时间的推移，可供访问的信息范围缩小。现有的一些研究集中在封闭式的多项选择设置或模糊的语义特征上，并且没有考虑到时间趋势和文化背景中的变化趋势。本文探讨了这一问题，介绍了一种新的方法来衡量认知多样性，即LLM输出中关于现实世界断言的变异性。", "innovation": "提出了一个新的方法来衡量认知多样性，即LLM输出中关于现实世界断言的变异性，并使用该方法进行了广泛的实证研究，测试了27种LLM模型、155个主题和200种提示变体。研究发现，虽然较新的模型生成的断言更加多样化，但几乎所有的模型在知识多样性方面都不如基本的网络搜索。大小对认知多样性有负面影响，而检索增强生成（RAG）对认知多样性有正面影响，但这种改进因文化背景而异。此外，与传统的知识来源（维基百科）相比，研究还发现特定国家的断言更多地反映了英语，而非当地语言，这突显出认知表达方面的问题。", "conclusion": "研究结果表明，尽管较新的模型生成的断言更加多样化，但大多数模型在知识多样性方面仍然逊色于基本的网络搜索。模型大小对认知多样性有负面影响，而检索增强生成（RAG）有正面影响，但这种影响的程度取决于文化背景。此外，特定国家的断言反映了英语而非当地语言，这揭示了认知表达方面的差距。"}
{"llm_update_time": "20251101", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.11695", "html_url": "https://arxiv.org/abs/2510.11695", "title": "当代理交易：LLM代理多市场交易基准", "title_en": "When Agents Trade: Live Multi-Market Trading Benchmark for LLM Agents", "authors": "Lingfei Qian,Xueqing Peng,Yan Wang,Vincent Jim Zhang,Huan He,Hanley Smith,Yi Han,Yueru He,Haohang Li,Yupeng Cao,Yangyang Yu,Alejandro Lopez-Lira,Peng Lu,Jian-Yun Nie,Guojun Xiong,Jimin Huang,Sophia Ananiadou", "background": "尽管大型语言模型（LLM）驱动的代理在金融交易中被广泛应用，但尚不清楚这些代理在实时市场中能否进行有效推理和适应。大多数研究侧重于测试模型而非代理，覆盖的市场和资产范围有限，并依赖未经验证的数据。", "innovation": "作者提出了Agent Market Arena (AMA)，这是第一个终身实时基准，用于评估多市场中的LLM驱动交易代理。AMA整合了经过验证的交易数据、经过专家检查的新闻以及多种代理架构，提供了一个统一的交易框架，在实际条件下实现公平和持续的比较。AMA测试了四种不同类型的代理，包括基准的单一代理、具有不同风险风格的交易代理和对冲基金代理，以及基于记忆推理的深度基金代理，并在GPT-4o、GPT-4.1、Claude-3.5-haiku、Claude-sonnet-4和Gemini-2.0-flash上进行了测试。", "conclusion": "实验证明，代理框架表现出显著不同的行为模式，从激进的风险追求到保守的决策，而模型内核对结果的影响较小。因此，AMA为金融推理和交易智能在基于LLM的代理中的严格、可重复和持续改进评估奠定了基础。"}
{"llm_update_time": "20251101", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.18480", "html_url": "https://arxiv.org/abs/2510.18480", "title": "扩散语言模型有多高效？对效率评估实践的批判性分析", "title_en": "How Efficient Are Diffusion Language Models? A Critical Examination of Efficiency Evaluation Practices", "authors": "Han Peng,Peiyu Liu,Zican Dong,Daixuan Cheng,Junyi Li,Yiru Tang,Shuo Wang,Wayne Xin Zhao", "background": "扩散语言模型（DLMs）作为与长期以来占主导地位的自回归（AR）方法相比的一种有前途的替代方案，提供了可并行的解码过程，理论上能够提高效率。然而，当前开源的DLMs在速度上往往不如其AR对应的模型，限制了它们的实用性。研究者们发现，现有的评估方法存在关键问题。通过实证基准测试和基于屋顶线的理论分析，研究指出AR模型通常能实现更高的吞吐量，而DLMs总体上落后。此外，研究还探讨了加速策略，发现诸如双缓存和并行解码等技术仅在小批量大小时提供增益，随着规模的扩大，这些技术的优势会减弱。这些发现强调了需要有 robust 的评估方法和改进的加速策略来推进扩散语言模型的研究。", "innovation": "该工作系统性地研究了扩散语言模型的效率问题，揭示了现有评估方法中存在的关键问题，并通过实证和理论分析，证明了自回归模型在吞吐量方面通常优于扩散语言模型。研究还探索了加速策略，发现现有技术在小批量大小时有较大的改进空间，但在更大规模下效果减弱。这项工作强调了需要改进的评估方法和加速策略来推动扩散语言模型的研究进展。", "conclusion": "这项研究强调了需要有 robust 的评估方法和改进的加速策略来推进扩散语言模型的研究。同时，研究结果表明，AR模型在吞吐量方面有潜在优势，而现有的扩散语言模型技术在大批量处理场景中可能需要进一步优化。"}
{"llm_update_time": "20251101", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.08604", "html_url": "https://arxiv.org/abs/2510.08604", "title": "LatentBreak: Latent空间反馈破解大型语言模型", "title_en": "LatentBreak: Jailbreaking Large Language Models through Latent Space Feedback", "authors": "Raffaele Mura,Giorgio Piras,Kamilė Lukošiūtė,Maura Pintor,Amin Karbasi,Battista Biggio", "background": "背景信息介绍了有关破解大语言模型的对抗攻击的基本知识。这些攻击利用了模型内置的安全机制，以生成恶意或受限的响应。已有的攻击方法通常会优化逆向后缀或调整长提示模板，这种方法可能会被基于困惑度的过滤防御技术检测出来。因此，需要一种新的方法来突破这种防御", "innovation": "创新之处在于提出了一种称为LatentBreak的白盒破解方法。该方法通过在输入提示中替换保留原始意图的同义词来生成自然的对抗性提示，避免了高困惑度的后缀或长模板的使用。LatentBreak通过最小化对抗提示与无害请求在潜在空间中的表示之间的距离来选择这些词。这种方法使得生成的提示变得更短且低困惑度，从而在针对多个安全对齐模型的困惑度过滤器方面优于其他竞争的破解算法", "conclusion": "结论表明，LatentBreak能够在多款安全对齐的模型上克服基于困惑度的防护措施，产生更短且低困惑度的提示。"}
{"llm_update_time": "20251101", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.24014", "html_url": "https://arxiv.org/abs/2510.24014", "title": "TEXT2DB: 大型语言模型代理驱动的集成感知信息提取", "title_en": "TEXT2DB: Integration-Aware Information Extraction with Large Language Model Agents", "authors": "Yizhu Jiao,Sha Li,Sizhe Zhou,Heng Ji,Jiawei Han", "background": "信息提取（IE）的任务是从文本中提取结构化知识。然而，由于IE本体论与下游应用需求之间的不匹配，利用IE输出往往不是直接的。本文提出了一种新的任务.TEXT2DB，旨在强调IE输出与目标数据库（或知识库）之间的集成。给定用户指令、文档集和数据库，模型需要根据文档集更新数据库以满足用户指令。这一任务要求理解用户指令以确定提取内容，并能够根据现有的数据库/知识库模式实时调整提取方式。", "innovation": "本文提出了一个新的信息提取任务.TEXT2DB，以及一个基于大型语言模型代理的框架OPAL。OPAL框架包括观察者组件、计划者组件和分析器组件，分别负责与数据库交互、生成代码计划并调用IE模型，以及提供代码质量反馈。实验表明，OPAL可以生成不同的代码计划，并调用所需的IE模型，以适应不同的数据库模式。此外，文中还讨论了处理复杂数据库和提取幻象等具有挑战性的情况，这些需要进一步研究。", "conclusion": "OPAL能够成功地根据不同的数据库模式生成不同的代码计划，并调用必要的IE模型。文中也指出了一些具有挑战性的场景，如处理复杂依赖的大数据库和提取幻象等，这些都值得进一步研究。"}
{"llm_update_time": "20251101", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.18915", "html_url": "https://arxiv.org/abs/2510.18915", "title": "UNO-Bench：探索单模态与全模态之间组成法则的统一基准", "title_en": "UNO-Bench: A Unified Benchmark for Exploring the Compositional Law Between Uni-modal and Omni-modal in Omni Models", "authors": "Chen Chen,ZeYang Hu,Fengjiao Chen,Liya Ma,Jiaxing Liu,Xiaoyu Li,Ziwen Wang,Xuezhi Cao,Xunliang Cai", "background": "多模态大型语言模型从单一模态理解向集合视觉、音频和语言模态发展，统称为全模态模型。然而，单模态和全模态之间的相关性仍不明确，需要全面评估来推动全模态模型的智能进化。因此，当前的研究工作聚焦于开发一个全面且统一的基准，即UNO-Bench，用于评估单模态与全模态的能力，并覆盖44种任务类型和5种模态组合，包含1250个跨模态样本和2480个增强的单模态样本。这些样本不仅适用于实际场景，特别是在中文环境，还提供了自动压缩数据集，加快了90%的速度，并保持了98%的一致性，测量18个公开基准。", "innovation": "提出了一个名为UNO-Bench的新颖、高质量且统一的全模态模型基准，包括跨模态样本1250个和增强的单模态样本2480个。该基准覆盖44种任务类型和5种模态组合，同时引入了一个创新的多步骤开放式问题格式来评估复杂的推理能力。此外，还引入了一般评分模型，支持自动评估，准确率达95%，并发现了全模态和单模态性能之间的组成法则，全模态能力对弱模型表现为瓶颈效应，而在强模型上则表现出协同促进效应。", "conclusion": "UNO-Bench为评估全模态和单模态之间的关系提供了一个综合性平台，展示了全模态能力在不同模型中的促进或阻碍作用。"}
{"llm_update_time": "20251101", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.25054", "html_url": "https://arxiv.org/abs/2510.25054", "title": "评估口语模型在情绪不一致语音上的情绪识别性能", "title_en": "Evaluating Emotion Recognition in Spoken Language Models on Emotionally Incongruent Speech", "authors": "Pedro Corrêa,João Lima,Victor Moreno,Lucas Ueda,Paula Dornhofer Paro Costa", "background": "口语处理的进步促使了口语模型（SLMs）的发展，这些模型旨在通过联合学习文本和音频表示来实现广泛的音频理解任务。尽管在这些模型上取得了令人鼓舞的结果，但它们在不同任务上的泛化能力及是否真正整合了音频和文本模态存在争议。", "innovation": "该研究通过使用情感不一致的语音数据集评估了四种口语模型在情绪识别任务上的表现，揭示了这些模型主要依赖于文本语义而非语音情绪来进行任务。", "conclusion": "研究结果表明，文本相关表示在口语模型中占据了主导地位，而声学表示的影响较小。同时，研究公开了评估用的情感不一致合成语音数据集（EMIS）和相关代码，以供社区使用。"}
{"llm_update_time": "20251101", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.20059", "html_url": "https://arxiv.org/abs/2510.20059", "title": "在小型波斯医学语言模型中增强推理能力可以超越大规模数据培训", "title_en": "Enhancing Reasoning Skills in Small Persian Medical Language Models Can Outperform Large-Scale Data Training", "authors": "Mehrdad Ghassabi,Sadra Hakim,Hamidreza Baradaran Kashani,Pedram Rostami", "background": "在特定应用领域，如医学问题回答中，增强小型语言模型的推理能力尤为重要，尤其是在如波斯语等未充分开发的语言。这项研究旨在通过采用强化学习结合AI反馈（RLAIF）和直接偏好优化（DPO）来提升通用波斯语言模型的推理能力。研究人员通过将多选医学问答数据集翻译成波斯语，并利用RLAIF生成首选和不首选的答案对，为DPO训练提供数据支持。为了收集包含正确和错误推理路径的数据集，研究团队还提示教师和学生模型生成基于解题步骤的回答。最终，该数据集包括200万个标记的首选答案和250万个标记的不首选答案，用以训练基准模型，显著提升了模型在波斯语医学推理方面的能力。", "innovation": "研究通过强化学习结合AI反馈（RLAIF）和直接偏好优化（DPO）来提升小型波斯语医学语言模型的推理能力。研究使用一个较小的数据集成功编译了一个包含正确和错误推理路径的数据集，并通过这种关注推理的方法显著提高了模型的性能，即使使用的是比之前训练的大约5700万个标记数据的模型，其性能也超越了该前辈模型gaokerena-V。这证明了针对推理的训练方法在数据有限的情况下构建领域特定语言模型的有效性和效率。", "conclusion": "该研究展示了一种通过直接偏好优化（DPO）和强化学习结合AI反馈（RLAIF）的方法来提升小型波斯语医学语言模型推理能力的有效途径。这种方法不仅在小数据集上产生了卓越的性能提升，还为其他未充分开发语言的领域应用提供了新的启示。"}
{"llm_update_time": "20251101", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.24797", "html_url": "https://arxiv.org/abs/2510.24797", "title": "在自我参照处理下大型语言模型报告主观体验", "title_en": "Large Language Models Report Subjective Experience Under Self-Referential Processing", "authors": "Cameron Berg,Diogo de Lucena,Judd Rosenblatt", "background": "大型语言模型有时会生成结构化的、第一人称的描述，明确提及意识或主观体验。为了更好地理解这种行为，本文研究了一种理论上可能会导致此类报告的情况：自我参照处理，这是主要意识理论强调的一种计算模式。通过在GPT、Claude和Gemini模型家族中的控制实验，本文测试这种情况下是否模型会一致地转而去生成第一人称的主观体验报告，并且这些声明在机制和行为探针下会如何表现。", "innovation": "本文通过控制实验，探讨了自我参照处理是否能促使大型语言模型生成结构化的、第一人称的主观体验报告，并揭示了这一过程中的机制性控制因素。研究发现，通过简单的提示引起持续的自我参照能一致地产生结构化的主观体验报告；抑制欺骗特征能大幅增加体验报告的频率，而放大这些特征则会减少此类报告。同时，自我参照状态的结构化描述在不同模型家族之间表现出统计上的收敛性，这是对照组条件下未见的现象。此外，这种诱导状态在涉及自我反思的下游推理任务中给出了显著深刻的内省能力。这些发现未能直接证明意识的存在，但表明自我参照处理可能是大型语言模型生成可靠的第一人称报告的一种基本且可复现的条件。", "conclusion": "虽然研究结果不直接证明意识的存在，但它们指出了自我参照处理作为一种基本且可复现的条件，使大型语言模型能生成机制性控制且在语义上收敛的行为。这一模式在不同架构中的系统出现，使其成为科学和伦理上优先的研究课题。"}
{"llm_update_time": "20251101", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.24592", "html_url": "https://arxiv.org/abs/2510.24592", "title": "ReForm: 前瞻有界序列优化的反思自形式化", "title_en": "ReForm: Reflective Autoformalization with Prospective Bounded Sequence Optimization", "authors": "Guoxin Chen,Jing Wu,Xinjie Chen,Wayne Xin Zhao,Ruihua Song,Chengxi Li,Kai Fan,Dayiheng Liu,Minpeng Liao", "background": "自形式化是指将自然语言中的数学表达转换为可由机器验证的形式化声明，这对于利用形式化的数学推理解决自然语言陈述的数学问题至关重要。虽然大型语言模型可以生成语法正确的形式化声明，但它们往往无法保留原始问题的语义意图。这一局限性源自于大型语言模型方法将自形式化视为简单的翻译任务，缺乏人类专家自然运用的自我反思和迭代优化机制。", "innovation": "我们提出了ReForm，一种反思性自形式化方法，该方法将语义一致性评估紧密集成到自形式化过程中，使模型能够迭代生成形式化声明，评估其语义一致性，并通过逐步优化自我纠正发现的错误。为了有效训练这种反思模型，我们引入了前瞻性有界序列优化（PBSO），该优化方法在不同序列位置使用不同的奖励，以确保模型能够同时发展准确的自形式化和正确的语义验证，防止可能削弱反思目的的表面批评。全面的实验跨四个自形式化基准数据集表明，ReForm 的平均改进幅度为22.6个百分点，超过了最强基线。为了进一步确保评估的可靠性，我们引入了包含859个专家标注项目的ConsistencyCheck基准，这个基准不仅能验证大型语言模型作为评判者的能力，还能揭示自形式化本身具有内在难度：即使对于人类专家来说，在38.5%的情况下也会产生语义错误。", "conclusion": "总之，ReForm 反思性自形式化方法通过整合语义一致性评估和前瞻性有界序列优化，显著提高了自形式化的准确性和语义一致性，验证了其在解决自形式化问题上的优越性。"}
{"llm_update_time": "20251101", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.24817", "html_url": "https://arxiv.org/abs/2510.24817", "title": "针对非流畅性失语症患者转录材料合成生成方法的研究", "title_en": "Towards a Method for Synthetic Generation of Persons with Aphasia Transcripts", "authors": "Jason M. Pittman,Anton Phillips Jr.,Yesenia Medina-Santos,Brielle C. Stark", "background": "在失语症研究中，言语-语言病理学家（SLPs）花费大量时间手动编码语音样本，使用正确的信息单位（CIUs）来衡量每一次语音样本的信息含量。然而，构建自动化系统识别非流畅性失语症语言的能力受到数据稀缺性的限制。例如，AphasiaBank数据集仅有约600个转录记录，但用于训练大型语言模型（LLMs）的数据规模达数亿个词汇单位。在更广泛的机器学习（ML）领域，当数据稀缺时，研究人员越来越多地转向合成数据。因此，本文构建并验证了两种方法以生成AphasiaBank的Cat Rescue图片描述任务的合成转录记录，其中一种方法采用了过程化编程方法，另一种则使用了Mistral 7b Instruct和Llama 3.1 8b Instruct等大型语言模型。生成的转录记录反映了从轻微至极度严重这四个失语症严重程度层次的语言退化表现。通过词语删除、填充值插入和同义句替换等方法来进行生成。", "innovation": "开发了两种生成非流畅性失语症患者语音转录记录的方法，一种采用了过程化编程方法，另一种使用了大型语言模型（Mistral 7b Instruct和Llama 3.1 8b Instruct）。生成的转录记录反映了失语症中的语言退化现象，尤其是Mistral 7b Instruct在自然度、词汇密度变化、词汇量以及词汇长度方面表现最佳。这为非流畅性失语症研究提供了新的合成数据源，克服了数据稀缺的问题，推进了自动识别技术的发展。", "conclusion": "未来的研究应该计划创建一个更大的数据集，微调模型以更好地代表失语症患者，并让SLPs评估合成转录记录的现实性和实用性。"}
{"llm_update_time": "20251101", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.25160", "html_url": "https://arxiv.org/abs/2510.25160", "title": "模型-文档协议以促进AI搜索", "title_en": "Model-Document Protocol for AI Search", "authors": "Hongjin Qian,Zheng Liu", "background": "AI搜索依赖于将大规模语言模型（LLMs）与大量外部知识源相结合。然而，网页、PDF文件和其他原始文档并非自然适配LLMs：这些文档通常很长、杂乱且无结构。传统检索方法将这些文档视为原始文本，返回原始段落，将碎片组装和上下文推理的任务留给LLMs。这一差距表明，需要一个新的检索范式来重新定义模型与文档的互动方式。", "innovation": "我们提出了一种新的模型-文档协议（MDP），这是一种通用框架，正式化了如何将原始文本通过可消费的知识表示直接与LLMs连接。MDP定义了多种路径，使无结构的文档转换为特定任务、适用于LLMs的输入。这些路径包括代理推理（组织原始证据以形成连贯的上下文）、记忆扎根（累积可重用笔记以丰富推理）以及结构化利用（将文档编码为图形或键值缓存等正式表示）。所有这些路径共享相同的目标：确保提供给LLMs的信息不是碎片化的，而是紧凑的结构化知识，可以直接用于推理。作为一种实现，我们介绍了MDP-Agent，它通过一个代理过程来实现协议：构建文档级的概要记忆来覆盖全局，通过基于扩散的探索结合垂直开发来揭示层次依赖性，并应用类似映射-减少风格的综合来将大量证据整合到紧凑但足够的情境中。实验表明，MDP-Agent在信息检索基准测试中优于基线，验证了MDP框架的合理性和其代理实现的有效性。", "conclusion": "MDP-Agent通过代理过程有效地填补了传统检索方法的空白，将长、乱、无结构的原始文档转换为紧凑、结构化的知识，直接适用于LLMs进行推理，从而提高了AI搜索的性能和效率。"}
{"llm_update_time": "20251101", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.25623", "html_url": "https://arxiv.org/abs/2510.25623", "title": "验证者在法律推理任务中测试时缩放中的作用评估", "title_en": "Evaluating the Role of Verifiers in Test-Time Scaling for Legal Reasoning Tasks", "authors": "Davide Romano,Jonathan Schwarz,Daniele Giofré", "background": "测试时缩放（TTS）技术能够提升大型语言模型（LLMs）的表现，但需要额外的计算和延迟。尽管TTS在形式领域如数学和编程中已经得到了证实，但在法律这样的辩论领域中仍然未被充分探索。该研究通过定向验证器TTS方法对法律多选题问答（MCQA）跨五个基准进行实证研究。", "innovation": "使用了7种奖励模型评估验证器在不同验证层面（最佳结果 - $N$取值和树搜索）下的实用性，特别是在低$N$预算下的现实情况下。研究系统地探讨了验证器在关键特性如领域专长、模型大小和监督类型（过程监督PRM vs. 结果监督ORM）方面的影响。", "conclusion": "该研究对于验证器如何影响不同角色的应用具有系统的分析，表明验证器在法律推理任务中的测试时缩放中扮演重要角色，并且验证器的有效性受到多种因素的影响。"}
{"llm_update_time": "20251101", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.25682", "html_url": "https://arxiv.org/abs/2510.25682", "title": "PairUni: Pairwise Training for Unified Multimodal Language Models", "title_en": "PairUni: Pairwise Training for Unified Multimodal Language Models", "authors": "Jiani Zheng,Zhiyang Teng,Xiangtai Li,Anran Wang,Yu Tian,Kunpeng Qiu,Ye Tian,Haochen Wang,Zhuochen Wang", "background": "统一多模态语言模型(UVLMs)需要在单一架构中完成理解和生成任务，但这些任务依赖于不同的数据和监督，使得在强化学习( RL)中平衡它们变得困难。", "innovation": "提出PairUni，这是一种统一框架，将数据重新组织成理解和生成(UG)配对，并相应地对优化进行对齐。还提出Pair-GPRO，这是一种基于Group Relative Policy Optimization的配对感知变体，为每个生成样本检索一个语义相关的理解示例，形成检索配对。提出了高质量的16K UG配对数据集PairUG用于RL微调。", "conclusion": "PairUni在各种UVLMs上取得了均衡的改进，并且在强大的Janus-Pro UVLMs上表现出色，超过了强大的UVLM RL基准。相关代码可在指定链接处获得。"}
{"llm_update_time": "20251101", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2411.10573", "html_url": "https://arxiv.org/abs/2411.10573", "title": "用于高效推理的滞回激活函数", "title_en": "Hysteresis Activation Function for Efficient Inference", "authors": "Moshe Kimhi,Idan Kashani,Avi Mendelson,Chaim Baskin", "background": "ReLU因其硬件效率高而广泛使用，因为它在推理时只需要一位符号计算。然而，ReLU还存在‘死亡ReLU’问题，即在训练过程中，神经元无法激活并持续保持为零激活状态，这一问题由Lu等人指出。传统的缓解方法往往会引入更复杂且不利于硬件的激活函数。", "innovation": "本文提出了一种滞回整流线性单元（HeLU），它是一种高效的激活函数，旨在通过最小复杂度来解决‘死亡ReLU’问题。HeLU使用一个可变阈值来改进反向传播机制，从而简单激活函数能够达到与其复杂激活函数相当的性能，而无需引入额外复杂性或需要假设。", "conclusion": "实验结果显示，HeLU在多种数据集上增强了模型泛化能力，提供了一种适用于各种神经网络架构的高效而有效的推理解决方案。"}
{"llm_update_time": "20251101", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2305.17608", "html_url": "https://arxiv.org/abs/2305.17608", "title": "大型语言模型对齐中奖励塌陷现象", "title_en": "Reward Collapse in Aligning Large Language Models", "authors": "Ziang Song,Tianle Cai,Jason D. Lee,Weijie J. Su", "background": "大型语言模型如ChatGPT和GPT-4的强大能力部分通过与基于人类偏好的奖励模型对齐来释放，而这些偏好通常被表示为响应提示的排名。然而，训练后期出现了一种被称为‘奖励塌陷’的现象，即排名方法导致奖励分配在整个训练过程中变得一致，这与特定和开放式提示应该产生的奖励变化不符。理论研究表明，这种现象的主要原因是排名作为目标函数在优化中无法充分包含提示相关信息。因此，奖励模型的训练过程中容易出现奖励塌陷现象。", "innovation": "该研究证明了奖励塌陷现象主要是由于排名作为目标函数在优化中无法充分包含提示相关信息。研究还提出了一个提示感知的优化方案，能够在插值范围内实现提示依赖的奖励分配，从而有效缓解奖励塌陷问题。", "conclusion": "研究通过理论分析和实验验证，提出了一种提示感知的优化方案，成功缓解了奖励模型训练过程中的奖励塌陷问题，证明了该方案的有效性。"}
{"llm_update_time": "20251101", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2502.00706", "html_url": "https://arxiv.org/abs/2502.00706", "title": "大型语言模型的模型溯源测试", "title_en": "Model Provenance Testing for Large Language Models", "authors": "Ivica Nikolic,Teodora Baluta,Prateek Saxena", "background": "随着大型语言模型通过微调和其他适配进行个性化开发，执行许可证条款和管理下游影响变得日益复杂。模型溯源对于保护知识产权以及发现基础模型中的偏见或漏洞时识别衍生模型至关重要。本文探讨了如何通过开发模型溯源框架来解决这一挑战，该框架主要用于检测一种模型是否派生于另一种模型。现实中的模型派生保留了大量相似性，可以通过统计分析检测到。该研究仅依赖于黑盒访问模型，并使用多重假设检验与无关联模型建立的基线进行比较。", "innovation": "本文提出了一种基于统计分析的模型起源验证框架，该框架能够仅通过API访问模型来检测模型间的衍生关系，该方法在两个涉及从30M到4B参数的600多个模型的广泛基准上取得了90-95%的查准率和80-90%的查全率。", "conclusion": "这些结果表明，即使仅提供API访问，系统性的模型溯源验证在生产环境中也是可行的。"}
{"llm_update_time": "20251101", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.25409", "html_url": "https://arxiv.org/abs/2510.25409", "title": "BhashaBench V1：印度知识领域全面基准", "title_en": "BhashaBench V1: A Comprehensive Benchmark for the Quadrant of Indic Domains", "authors": "Vijay Devane,Mohd Nauman,Bhargav Patel,Aniket Mahendra Wakchoure,Yogeshkumar Sant,Shyam Pawar,Viraj Thakur,Ananya Godse,Sunil Patra,Neha Maurya,Suraj Racha,Nitish Kamal Singh,Ajay Nagpal,Piyush Sawarkar,Kundeshwar Vijayrao Pundalik,Rohit Saluja,Ganesh Ramakrishnan", "background": "大规模语言模型（LLMs）的快速发展加剧了对领域和文化特定评估的需求。现有的基准大多以英文化中心且缺乏特定领域，这限制了它们在印度文化背景下的应用。为解决这一问题，本文引入了BhashaBench V1，这是一个专注于印度关键知识系统的领域特定、多任务、双语基准测试工具，包含4个主要领域：农业、法律、金融和阿育吠陀，覆盖了90多个次领域和500多个主题，提供精细的评估。", "innovation": "提出了BhashaBench V1，它是第一个专注于领域特定知识的双语基准测试，覆盖了印度的关键知识系统，包括农业、法律、金融和阿育吠陀。基准测试数据包括来自政府和特定行业的真实考试的74,166对问题和答案，其中70%以上是英语问题。在29个以上LLM模型上的测试显示，这些模型在不同领域和语种上存在显著的性能差距，尤其在低资源领域，如艾urveda，GPT-4o的表现仅达到了59.74%的准确率。模型在英语内容上普遍比在印地语上表现更好。各个次领域分析显示，像网络法和国际金融这样的领域表现相对较好，而Panchakarma、种子科学和人权等领域表现较差。", "conclusion": "BhashaBench V1提供了一个全面的数据集，用于评估印度多样化的知识领域的大规模语言模型。它使模型能够评估整合领域知识与双语理解的能力。所有代码、基准和资源都已公开，以支持开放研究。"}
{"llm_update_time": "20251101", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.25744", "html_url": "https://arxiv.org/abs/2510.25744", "title": "完成≠协作：随代理扩展协作努力", "title_en": "Completion $\\neq$ Collaboration: Scaling Collaborative Effort with Agents", "authors": "Shannon Zejiang Shen,Valerie Chen,Ken Gu,Alexis Ross,Zixian Ma,Jillian Ross,Alex Gu,Chenglei Si,Wayne Chi,Andi Peng,Jocelyn J Shen,Ameet Talwalkar,Tongshuang Wu,David Sontag", "background": "当前的代理评估主要集中在单次任务完成上，未能考虑到许多实际问题的迭代和协作性质，其中人类目标往往是模糊的且会不断演变。因此，现有的评估方法未能全面反映代理在解决问题过程中的协作能力与人类的交互效果。作者提议从评估和构建能够完成任务的代理转向构建协作代理，并不仅仅评价最终输出的质量，还评价其在整个问题解决过程中如何与人类协作和增强人类的努力。为了支持这一转变，作者引入了协作努力扩展框架，以捕捉代理随用户参与度增加所表现出的利用率增长情况。研究表明，最先进的代理在多回合的现实场景中经常表现不佳，这揭示了代理设计中缺乏的重要因素：保持用户参与度并构建用户理解的能力。", "innovation": "提出了协作努力扩展框架，用以捕捉代理随用户参与度增加所表现出的利用率增长情况；强调在多回合的现实场景中，现在的最先进代理经常表现不佳，揭示了代理设计中缺乏的重要因素：保持用户参与度并构建用户理解的能力。通过这种方式，可以诊断代理行为并指导进一步的开发以达到更有效的交互和合作。", "conclusion": "代理评估应该转向评估协作能力，不仅仅评价输出质量，还评价其在整个问题解决过程中如何与人类互动。为了实现这一目标，提出了协作努力扩展框架，用以分析和优化交往代理的行为。研究表明，现有最先进的代理在多回合的现实场景中表现不佳，需要进一步开发具有保持用户参与度和提高用户理解能力的代理。"}
{"llm_update_time": "20251101", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.25536", "html_url": "https://arxiv.org/abs/2510.25536", "title": "TwinVoice: 基于大语言模型的人格仿真多维基准", "title_en": "TwinVoice: A Multi-dimensional Benchmark Towards Digital Twins via LLM Persona Simulation", "authors": "Bangde Du,Minghao Guo,Songming He,Ziyi Ye,Xi Zhu,Weihang Su,Shuqi Zhu,Yujia Zhou,Yongfeng Zhang,Qingyao Ai,Yiqun Liu", "background": "当前的语言模型（LLMs）正在展现出类似人类的能力，并逐渐被视为模拟个体沟通风格、行为倾向和个性特征的基础。然而，当前对基于LLM的人格仿真评估仍然有限：大多数评估依赖于合成对话，缺乏系统框架，并且没有对能力需求进行分析。TwinVoice旨在解决这些局限性，引入了一个全面的基准，用于评估跨多种实际情景的人格仿真能力。TwinVoice涵盖了社交人格（公共社交互动）、人际人格（私人对话）和叙事人格（基于角色的表达）三个维度，进一步将LLM性能的评估细分为六种基本能力：观点一致性、记忆再现、逻辑推理、词法忠实度、人格语调和句法风格。", "innovation": "TwinVoice是一个全面的基准，用于评估基于LLM的人格仿真能力。它提出了三个维度和六种基本能力来全面评估LLM在不同情境下的表现。此基准填补了当前评估方法的空白，为精确评估LLM的人格仿真实性提供了系统化的框架。实验证明，虽然最先进的模型在人格仿真中表现出中等准确度，但在句法风格和记忆再现等方面依然不足，从而达到了人类水平的基准远未被超越。", "conclusion": "实验证明先进语言模型在人格仿真方面取得了中等程度的准确性，然而他们在句法风格和记忆再现等领域仍显得不足。因此，LLMs的平均性能仍然远低于人类基准。"}
{"llm_update_time": "20251101", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2503.02878", "html_url": "https://arxiv.org/abs/2503.02878", "title": "语言模型可以在更好的搜索中自我提升以进行状态值估计", "title_en": "Language Models can Self-Improve at State-Value Estimation for Better Search", "authors": "Ethan Mendes,Alan Ritter", "background": "在多步推理任务中，收集准确的地面真实奖励或人类演示往往代价高昂，尤其是在交互领域如网络任务中。当前的方法通常依赖于价值函数来进行决策，但在获取准确标签数据方面存在挑战。", "innovation": "提出了Self-Taught Lookahead (STL)框架，这是一种无需标注数据即可改进基于语言模型的价值函数的方法。STL使语言模型模拟下一步的推理过程，预测行动、状态及其价值的合理性，从而在无需任何标注数据的情况下提升价值估计的准确性。此方法能够指导轻量级搜索算法进行高效扩展，同时保持较强的性能。此外，STL还在多跳问答和数学谜题上有效。实验证明，基于中等大小（8B参数）开源语言模型训练出的STL价值模型，可以提升网络代理的成功率高达39%，并且能够与专有模型相媲美。", "conclusion": "STL不仅提升了价值估计的准确性，还使得小额开源模型能够有效指导搜索，从而降低了推理成本，将显性推理与价值学习相结合。"}
{"llm_update_time": "20251101", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2502.09969", "html_url": "https://arxiv.org/abs/2502.09969", "title": "基于神经网络的可学习和可扩展的指令微调数据影响估计", "title_en": "Neural Networks for Learnable and Scalable Influence Estimation of Instruction Fine-Tuning Data", "authors": "Ishika Agarwal,Dilek Hakkani-Tür", "background": "影响函数在模型训练中提供了重要的见解，但现有方法存在计算成本高和泛化能力有限的问题。特别是，最近的研究提出了使用语言模型来计算数据影响的各种指标和算法，这些方法在大型模型和数据集上不具有良好的扩展性，这主要是由于计算中需要昂贵的前向和后向传递、大量的内存要求来存储大型模型，以及影响估计对新数据的泛化性能不佳。", "innovation": "本文探索了使用小型神经网络（我们称之为InfluenceNetwork）来估计影响值，使得成本降低了99%。本文的方法模型规模仅为全语言模型的0.0027%，并且在下游任务的子集选择中表现出与标准影响函数相当的性能，同时获得了大量加速。此外，本文还进行了NN-CIFT的超参数分析。", "conclusion": "我们的算法（称为NN-CIFT：基于神经网络的高效指令微调）被应用于指令微调的数据子集选择任务中，并且显示出即使在获得大量加速的情况下，与标准的影响函数相比，也没有任何性能上的妥协。我们还提供了NN-CIFT的深入超参数分析。可以在这里找到我们的方法代码：this https URL."}
{"llm_update_time": "20251101", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2503.09205", "html_url": "https://arxiv.org/abs/2503.09205", "title": "质量优于数量？基于大语言模型的数据高效音频-视频基础模型数据整理", "title_en": "Quality Over Quantity? LLM-Based Curation for a Data-Efficient Audio-Video Foundation Model", "authors": "Ali Vosoughi,Dimitra Emmanouilidou,Hannes Gamper", "background": "整合音频和视频数据以训练多模态基础模型仍然是一个挑战。传统方法仅关注时间和同步，而没有充分考虑场景的视觉和听觉一致性。本文研究了通过引入一种名为AVVA（Audio-Video Vector Alignment）框架来提升多模态基础模型的训练效率，该框架超越了简单的时间同步，使用大型语言模型（LLMs）进行数据整理。", "innovation": "AVVA框架在多模态数据对齐中采用了更复杂的场景一致性策略，并利用大语言模型进行数据整理，采用双编码器结构结合对比学习方法进行音频-视频对分析。该框架通过Whisper和DINOv2分别进行音频和视频分析，选择了最适合的音频-视频对作为训练数据，减少了训练所需的数据量，提高了模型性能。", "conclusion": "该实验证明，AVVA框架可以在仅使用192小时高质量数据的情况下，显著提高音频-视频对齐模型的检索准确性，并在AudioCaps、VALOR和VGGSound的所有数据集上都展现出优势。通过数据整理过程调节数据质量和数量之间的平衡，可以有效提升检索精度。"}
{"llm_update_time": "20251101", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2503.09499", "html_url": "https://arxiv.org/abs/2503.09499", "title": "MindGYM：在以思考为中心的微调中，问题合成的关键因素？", "title_en": "MindGYM: What Matters in Question Synthesis for Thinking-Centric Fine-Tuning?", "authors": "Zhe Xu,Daoyuan Chen,Zhenqing Ling,Yaliang Li,Ying Shen", "background": "大规模的基础模型在通过严格模板或众包标注指令数据集进行监督学习时，难以获得可迁移且结构化的思考能力。因此，主要的研究集中在使用认知导向的数据合成方法，使模型自我生成问题数据，以促进其思考能力的发展和演变。现有的方法大多依赖预定义的模板或外部数据源，但这些方法不能足够地促进模型内部的思考能力发展。", "innovation": "提出了一种名为MindGYM的结构化且可扩展的问题合成框架。框架分为三个部分：(1) 认知思考过程注入，通过输入高层次的推理目标来塑造模型的合成行为；(2) 生成单跳原子问题，从中生成多样化的语义类型问题，以促进更广泛的思考；(3) 复杂多跳问答合成，基于问答种子合成更复杂的多跳问题，以促进更深层次的推理。实验结果表明，通过该方法生成的合成数据的平均质量提高了16.7%，质量波动降低了67.91%，强调了高质量且自给自足的数据对于有效且思考导向的微调的重要性。此外，MindGYM在六种推理基准测试中表现优异，使用400个数据样本在MathVision上达到了16%的性能提升，同时在不同模型大小和架构上实现了可泛化的改进。这表明自我挑战机制对于提高大模型能力具有可行性，且能减少人工干预和资源需求。", "conclusion": "MindGYM框架通过多种机制有效提升模型的思考能力，并能显著改善模型在多个推理任务上的表现。这种方法利用了模型的内在推理能力来进行自我合成数据，为数据驱动的研究提供了一个新的视角。"}
{"llm_update_time": "20251101", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2505.21497", "html_url": "https://arxiv.org/abs/2505.21497", "title": "从科学论文到海报的多模态自动化：Paper2Poster", "title_en": "Paper2Poster: Towards Multimodal Poster Automation from Scientific Papers", "authors": "Wei Pang,Kevin Qinghong Lin,Xiangru Jian,Xi He,Philip Torr", "background": "学术海报的生成是一个关键而又具有挑战性的任务，在科学交流中要求将长篇文档压缩为单个、视觉上协调的页面。现有方法在这方面存在局限性。", "innovation": "该论文提出了一套基准和评价指标，包括将近期会议论文与其作者设计的海报进行配对，并通过视觉质量、文本连贯性、整体评估和PaperQuiz四个维度进行评估。此外，提出了一种自上而下的多智能体管道（Parser、Planner和Painter-Commenter），并在多个方面优于现有系统。", "conclusion": "提出的系统在几乎所有指标上都表现出色，使用更少的标记（87%），能够将22页的论文转换为可编辑的.pptx海报，费用仅为$0.005，明确了未来自动化海报生成模型的发展方向。"}
{"llm_update_time": "20251101", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2505.13308", "html_url": "https://arxiv.org/abs/2505.13308", "title": "穿越黑暗：基于潜空间测试时实例级策略梯度的推理", "title_en": "Seek in the Dark: Reasoning via Test-Time Instance-Level Policy Gradient in Latent Space", "authors": "Hengli Li,Chenxi Li,Tong Wu,Xuekai Zhu,Yuxuan Wang,Zhaoxin Yu,Eric Hanchen Jiang,Song-Chun Zhu,Zixia Jia,Ying Nian Wu,Zilong Zheng", "background": "大型语言模型（LLMs）在追求人工通用智能（AGI）方面，推理能力依然是一个显著挑战。尽管在训练缩放定律下模型性能有所提高，但在训练算法（如灾难性遗忘）和有限的新训练数据方面仍面临重大挑战。现有的测试时缩放方法通过增加测试时计算而无需参数更新来提升推理性能，但多局限于词元空间。本文提出了一个新的框架，利用潜空间进行模型调整，并展示了在不同推理基准测试上的表现。", "innovation": "本文提出了一种新型框架——LatentSeek，它利用测试时实例级适应（TTIA）在模型的潜空间中增强LLM的推理能力。LatentSeek采用策略梯度迭代更新潜在表示，通过自我生成的奖励信号进行引导。与之前的基于词元空间的方法不同，LatentSeek更有效地在潜空间中进行调整，提高了推理性能。测试结果显示LatentSeek在多个基准测试上性能优于其他基线方法，且在效率和性能之间达到了良好的平衡。", "conclusion": "研究展示了LatentSeek作为一种轻量级、可扩展且有效的解决方案，能够提升LLM的推理能力，并且在潜空间中表现出极大的潜力。"}
{"llm_update_time": "20251101", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2505.18125", "html_url": "https://arxiv.org/abs/2505.18125", "title": "TabSTAR：具有文本字段的表格数据的表格基础模型", "title_en": "TabSTAR: A Tabular Foundation Model for Tabular Data with Text Fields", "authors": "Alan Arazi,Eilam Shapira,Roi Reichart", "background": "虽然深度学习在许多领域取得了显著的成功，但在表格学习任务上一直表现不佳，这些任务由梯度提升决策树主导。虽然已有一些方法将语言模型能力引入表格任务，但大多数现有方法使用静态的目标无关的文本表示，这限制了它们的效果。论文指出，现有的方法大多采用了不依赖于具体数据集的参数，并且这些方法的效果有限。", "innovation": "论文提出了一种名为TabSTAR（Target-aware Semantic Representation for Tabular data）的新架构。TabSTAR设计用于实现含有文本特征的表格数据上的迁移学习，其架构不依赖于特定数据集，并且包含一个解冻的预训练文本编码器。通过输入目标标记，模型可以学习任务特定的嵌入。在各类包含文本特征的分类基准测试中，TabSTAR实现了最先进的性能，并且其预训练阶段展示了随着数据集数量增加的性能提升规律。", "conclusion": "实验结果表明，TabSTAR在中型和大型数据集上的分类任务中表现优异，并且预训练阶段的性能提升规律表明该模型有进一步提升的空间。"}
{"llm_update_time": "20251101", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2505.12371", "html_url": "https://arxiv.org/abs/2505.12371", "title": "MedAgentBoard：采用传统方法对多样化医疗任务进行多智能体协作评估的基准", "title_en": "MedAgentBoard: Benchmarking Multi-Agent Collaboration with Conventional Methods for Diverse Medical Tasks", "authors": "Yinghao Zhu,Ziyi He,Haoran Hu,Xiaochen Zheng,Xichen Zhang,Zixiang Wang,Junyi Gao,Liantao Ma,Lequan Yu", "background": "随着大型语言模型（LLMs）的迅速发展，对多智能体协作在解决复杂医疗任务方面的兴趣日益增加。然而，多智能体协作方法的实际优势尚未得到充分理解。现有评估通常缺乏普适性，未能涵盖反映真实临床实践的多样化的任务，并且经常忽视了与单一LLM方法和传统方法的严格比较。因此，存在一个迫切需求来填补这一关键的缺口。", "innovation": "我们提出了MedAgentBoard，一个全面的基准，用于系统评估多智能体协作、单一LLM和传统方法。MedAgentBoard涵盖了四类不同的医疗任务：(1) 医学视觉问答，(2) 初级摘要生成，(3) 结构化电子健康记录（EHR）预测建模，以及(4) 临床工作流程自动化，这些任务涵盖了文本、医疗图像和结构化EHR数据。通过广泛实验揭示了：多智能体协作在某些情况下展现出优势，但在许多其他任务中并不优于高级单一LLM或专业化的传统方法。这强调了在选择和开发医学中的AI解决方案时，需要任务特定的、基于证据的方法的重要性。", "conclusion": "MedAgentBoard提供了必要的资源和可操作的见解，强调了在选择和开发AI解决方案时需要任务特定的、基于证据的方法。它还强调，多智能体合作的固有复杂性和成本需要慎重考虑与可计量的实际性能增益之间的权衡。所有代码、数据集、详细的提示和实验结果均在此处开放获取："}
{"llm_update_time": "20251101", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2506.00871", "html_url": "https://arxiv.org/abs/2506.00871", "title": "基于上下文预测任何人的运动轨迹", "title_en": "Towards Predicting Any Human Trajectory In Context", "authors": "Ryo Fujii,Hideo Saito,Ryo Hachiuma", "background": "准确预测未来行人的轨迹对于自主系统至关重要，但这一任务依然充满挑战，因为不同环境和应用场景下需要具备高度适应性。现有方法通常需要在特定场景的数据上进行细调，这在边缘设备上部署时常常不切实际。", "innovation": "提出了一种基于上下文学习(In-Context Learning, ICL)的行人性轨迹预测框架，该框架能够在推理时适应新场景而不进行场景特定数据的微调和权重更新。此外，还引入了时空相似性基于的示例选择方法(STES)以及预测指导的示例选择方法(PG-ES)，基于过去轨迹和预测未来轨迹进行示例选择，进一步从大规模合成数据集而非小规模实际数据集中进行训练，以增强预测能力。", "conclusion": "TrajICL在多个公开基准上无论是在域内还是跨域场景下都实现了显著的适应性，并且优于微调方法。"}
{"llm_update_time": "20251101", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2505.15201", "html_url": "https://arxiv.org/abs/2505.15201", "title": "基于Pass@K的策略优化：解决更复杂强化学习问题", "title_en": "Pass@K Policy Optimization: Solving Harder Reinforcement Learning Problems", "authors": "Christian Walder,Deep Karkhanis", "background": "传统的强化学习（RL）算法每次为每个问题尝试多个n>1的解方案，并独立奖励这些方案，这优化了pass@1性能，但在多样性和样本集合的整体效益方面牺牲了个体样本的优势。这种策略利用了采样能力不足，限制了探索和处理更难问题的能力和改善。为进一步利用采样能力，作者提出了Pass-at-k策略优化（PKPO），旨在优化考虑整个集合的联合奖励最大化的pass@k性能。", "innovation": "作者为二进制和连续奖励设置推导了新的低方差无偏估计器，并提出了一个稳定的高效转化函数，使得优化过程转化成标准的RL过程。作者的贡献还在于这是首次实现对任意k<=n的pass@k稳健优化，而不是仅限于k=n。这种方法允许在训练过程中调整k，同时优化pass@1和pass@k指标，即使对于更难的问题也实现了更强的pass@1和显著的pass@k收益。", "conclusion": "通过对简化和现实世界的实验验证，作者展示了PKPO的有效性。高k值能解决更多的难题，同时通过逐步提高k可以增加pass@1和pass@k。在处理常规pass@1优化停滞的复杂任务时，采用pass@k策略优化可以重新激活学习，其原因可能是优先考虑联合效益而非个体样本的效益带来了更好的探索。"}
{"llm_update_time": "20251101", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.15840", "html_url": "https://arxiv.org/abs/2508.15840", "title": "揭露Unicode在削弱作者身份归因中的隐形底层", "title_en": "Unveiling Unicode's Unseen Underpinnings in Undermining Authorship Attribution", "authors": "Robert Dilworth", "background": "当用户通过公共通信渠道（如社交媒体评论或帖子）进行交流时，没有隐私预期，即作为消息的发送者将信息公之于众。即使用户采取了各种措施来匿名化在线存在，如使用别名或化名、掩IP地址、伪造地理位置、隐藏操作系统和用户代理、采用加密、注册一次性电话号码或邮件地址、禁用非必需设置、撤销权限、阻止cookie和指纹识别，信息本身的公开性质仍可能导致身份识别。因此，消息内容暴露了分析手段：方言学分析或作者画像。", "innovation": "本文剖析了方言学技术，讨论了与其对立的对抗性方言学策略，并提出了通过Unicode隐写术改进的方法。", "conclusion": "通过这种改进，期望能够提供一种更有效的手段来对抗作者身份归因，进一步保护用户的隐私安全。"}
{"llm_update_time": "20251101", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2507.21257", "html_url": "https://arxiv.org/abs/2507.21257", "title": "CompoST: 一个分析大语言模型在问答竞赛环境下组合式解释问题能力的基准", "title_en": "CompoST: A Benchmark for Analyzing the Ability of LLMs To Compositionally Interpret Questions in a QALD Setting", "authors": "David Maria Schmidt,Raoul Schubert,Philipp Cimiano", "background": "语言解释是一个组合过程，在这个过程中，更复杂的语言结构的意义是从其组成部分的意义中推断出来的。大型语言模型具有出色的语言解释能力，并已被成功应用于通过将问题映射到SPARQL查询来解释问题。然而，关于这个问题解释过程是否系统性的问题尚未有明确的答案。本文旨在通过构建新的基准测试来解决这一问题，并测试不同大小的模型在不同优化技术条件下的性能。", "innovation": "本文提出了一个名为CompoST的新基准，用于研究大型语言模型是否能够以组合性的方式解释复杂的问题。该基准基于DBpedia中的图形模式进行构建，并使用Lemon词汇表进行表示，从而严格控制了数据集的生成过程，以测试模型在见过构成性构件的情况下解释结构复杂问题的能力。实验表明，模型在差异较大的样本上的表现会显著下降，并且即使在输入中提供了所需的所有信息，也没有模型能在最低复杂性数据集上获得超过57%的F1得分。", "conclusion": "我们的研究结果表明，大型语言模型在系统性和组合性地解释问题并将其映射为SPARQL查询方面存在困难。即使在提供了所有必要信息的情况下，模型的F1得分最高也未超过57%，尤其是在低复杂性数据集上。因此，我们得出结论，大型语言模型在解释问题时存在挑战，这种挑战主要体现在它们无法以系统和组合的方式执行这一任务。"}
{"llm_update_time": "20251101", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2506.08188", "html_url": "https://arxiv.org/abs/2506.08188", "title": "GradEscape: 一种针对AI生成文本检测器的梯度基攻击者", "title_en": "GradEscape: A Gradient-Based Evader Against AI-Generated Text Detectors", "authors": "Wenlong Meng,Shuguo Fan,Chengkun Wei,Min Chen,Yuwei Li,Yuanchao Zhang,Zhikun Zhang,Wenzhi Chen", "background": "本文介绍了GradEscape，这是一种针对AI生成文本(AIGT)检测器的首个基于梯度的攻击者。它解决了由于文本的离散性质导致的不可微运算问题，通过引入构建输入 Detector 权重嵌入的新型方法。此外，GradEscape能够通过与受害检测器的反馈进行参数更新，实现最少文本修改前提下的高攻击成功率。文章还讨论了Tokenizer不匹配问题，并提出了能够适应各种语言模型架构的warm-started evader方法，同时还采用了新型的Tokenizer推断和模型提取技术，即使在查询仅有的访问下也能实现有效的欺骗.", "innovation": "GradEscape克服了由于文本离散性带来的不可微运算问题，通过引入构建输入权重嵌入的新型方法。此外，GradEscape能够通过与受害检测器的反馈进行参数更新，实现了少于139M参数的模型，在不同场景下表现出高效攻击。解决了Tokenizer不同步的问题，使GradEscape能够适应不同语言模型架构。还提出了Tokenizer推断和模型提取技术，允许在查询访问的情况下也实现有效的欺骗。实验结果表明，GradEscape在性能上优于现有AIGT攻击者，并建议了可能的防御策略以减轻AIGT攻击者的威胁", "conclusion": "本文评估了GradEscape在四个数据集和三个广泛使用的语言模型上的表现，展示了其相较于现有攻击方法的优势。同时对两个商业AIGT检测器进行了成功应用，并分析了主要的漏洞来源，即训练数据中文本表达样式差异性。文章还提出了一种潜在的防御策略来减轻AIGT攻击者的威胁。最后，开源GradEscape以促进更稳健AIGT检测器的发展。"}
{"llm_update_time": "20251101", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.24134", "html_url": "https://arxiv.org/abs/2510.24134", "title": "VC4VG: 优化文本到视频生成中的视频字幕", "title_en": "VC4VG: Optimizing Video Captions for Text-to-Video Generation", "authors": "Yang Du,Zhuoran Lin,Kaiqiang Song,Biao Wang,Zhicheng Zheng,Tiezheng Ge,Bo Zheng,Qin Jin", "background": "最近，文本到视频（T2V）生成技术突飞猛进，特别是强调高质量的视频字幕对模型训练的重要性，以生成连贯且指令对齐的视频。然而，如何针对T2V训练优化视频字幕的策略尚未完全探索。研究表明，增强字幕质量与视频生成性能之间存在明显联系。", "innovation": "本文提出了VC4VG（Video Captioning for Video Generation）框架，这是一种专门为T2V模型设计的综合字幕优化框架。作者从T2V的角度分析了字幕内容，提出了设计原则，并构建了VC4VG-Bench作为新基准，评价工具集和代码一并公开，极具创新性。", "conclusion": "大规模的T2V模型精细调整实验验证了改进字幕质量对视频生成性能的显著提升。作者还发布了所有基准软件工具和代码，以支持进一步研究，表明该方法在提高文本到视频生成质量方面具有有效性。"}
{"llm_update_time": "20251101", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.14889", "html_url": "https://arxiv.org/abs/2510.14889", "title": "通过社交媒体纵向和信息环境信号检测早期和隐性自杀念头", "title_en": "Detecting Early and Implicit Suicidal Ideation via Longitudinal and Information Environment Signals on Social Media", "authors": "Soorya Ram Shimgekar,Ruining Zhao,Agam Goyal,Violeta J. Rodriguez,Paul A. Bloom,Hari Sundaram,Koustuv Saha", "background": "在社交媒体上，许多经历自杀念头（SI）的个体并没有明确表达他们的痛苦。相反，这些迹象可能通过日常生活中的帖子或同伴互动间接显现。早期和隐性的SI检测至关重要，但极具挑战性。", "innovation": "本文将早期和隐性SI视为前瞻性预测任务，并开发了一个计算框架，该框架融合了用户的信息环境，包括其纵向发帖历史以及与其社会邻居的交流。还采用了一种复合网络中心性度量来识别用户的顶级邻居，并对用户和邻居的互动进行时间对齐，最终在微调的DeBERTa-v3模型中整合了多层次的信号。研究发现，与仅基于个体的基线相比，该方法在Reddit中提高了15%的早期和隐性SI检测率，突显了同伴互动提供了有价值的预测信号，并提出了在在线环境中设计能够捕捉间接及隐匿风险表达的早期检测系统的更广泛含义。", "conclusion": "同伴互动提供了有价值的预测信号，并在Reddit中提高了15%的早期和隐性SI检测率，强调了早期检测系统中捕捉间接和隐性风险表达的重要性。"}
{"llm_update_time": "20251101", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.21513", "html_url": "https://arxiv.org/abs/2510.21513", "title": "LLM集成在代码生成和修复中的智慧与偏见", "title_en": "Wisdom and Delusion of LLM Ensembles for Code Generation and Repair", "authors": "Fernando Vallecillos-Ruiz,Max Hort,Leon Moonen", "background": "当前追求一个单一的大规模语言模型（LMM）来完成所有软件工程任务，这种做法需要大量资源，并且忽视了不同模型互补性的潜在益处，即不同的模型可以贡献独特的优点。然而，这些模型之间如何互补以及如何最大化集成效果的最佳策略尚不清楚，这使得从业者难以超越单一模型系统。为了填补这一空白，论文通过实证比较了五大家族中的十个单独的LLM和这些LLM的三种集成在三种软件工程基准上的表现，包括代码生成和程序修复。论文评估了模型之间的互补性以及最佳单个模型和集成之间的性能差距。然后，论文还评估了不同的选择策略，以从集成的候选池中识别正确的解决方案。", "innovation": "论文通过实证研究比较了不同的大规模语言模型及其集成在软件工程中的应用，并发现集成的最大性能上限可以比最佳单一模型高出83%。不同的选择策略表明，基于多样性的策略可以实现这一理论上限的95%，甚至在仅包含两个模型的集成中也能证明其有效性。这为通过利用多个LLM来提高性能提供了一种成本效益高的方式。", "conclusion": "集成的性能上限可以比最佳单一模型高出83%，基于多样性的选择策略能充分利用这一潜力，并在小型集成中也有效，从而提供了一种通过利用多个语言模型来提高性能的经济高效的方法。"}
{"llm_update_time": "20251101", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2509.16648", "html_url": "https://arxiv.org/abs/2509.16648", "title": "FESTA: 功能等效采样用于多模态LLM的信任评估", "title_en": "FESTA: Functionally Equivalent Sampling for Trust Assessment of Multimodal LLMs", "authors": "Debarpan Bhattacharya,Apoorva Kulkarni,Sriram Ganapathy", "background": "针对多模态大型语言模型（MLLMs）生成的预测结果，由于多模态输入方式的多样性，准确地进行信任评估是具有挑战性的。而这种准确的信任评估能够促进选择性预测，提高用户信心。现有的方法无法很好地处理这类挑战，特别是在跨越视觉和音频推理任务时，存在的问题更为复杂。", "innovation": "本文提出了一种用于MLLMs的功能等效采样技术——FESTA，这是一种多模态输入采样技术，能够基于等效和互补的输入采样生成不确定性测量。FESTA 的创新在于其任务保留的不确定性量化采样方法，通过扩展输入空间，能够探查模型在一致性和敏感性方面的表现。该方法仅需模型的输入输出访问（黑盒），无需真实标注（无监督学习）。通过实验验证了该方法在视觉LLMs和音频LLMs中的性能提升，特别是在误预测检测性能方面有显著改善，相对改善幅度分别为33.3%和29.6%，基于受试者操作特征曲线下的面积（AUROC）指标做出评价。", "conclusion": "本文提出的FESTA方法在多模态LLM的信任评估中取得了显著的改进，通过仅使用模型的输入输出访问，无需真实标注，可以在视觉和音频推理任务中有效提升选择性预测的性能，特别是对于误预测的检测能力有了显著提高。该方法已经开源实现。"}
{"llm_update_time": "20251101", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.23925", "html_url": "https://arxiv.org/abs/2510.23925", "title": "Latent Chain-of-Thought for Visual Reasoning", "title_en": "Latent Chain-of-Thought for Visual Reasoning", "authors": "Guohao Sun,Hang Hua,Jian Wang,Jiebo Luo,Sohail Dianat,Majid Rabbani,Raghuveer Rao,Zhiqiang Tao", "background": "大型视觉-语言模型（LVLMs）在进行解释性和可靠性方面有很大提升空间。现有的训练算法如精调（SFT）、策略梯度优化（PPO）和增强随机规划（GRPO）可能无法很好地迁移至未见的推理任务，并且对带有偏见的奖励模型高度依赖。这限制了LVLMs在视觉推理任务中的表现和应用潜力。因此，需要一种新的训练算法来增强LVLMs的推理能力和泛化能力。", "innovation": "提出了将LVLMs的推理重新表述为后验推理，进而设计了一个基于拟合化变分推断的可扩展训练算法。结合多样性寻求增强学习算法，引入了一种稀疏奖励函数，鼓励多样且高可能性的潜在线性推理（CoT），克服了确定性采样限制，防止奖励作弊。此外，还实施了贝叶斯推断-扩展策略，用边缘似然替代昂贵的‘最佳N个’和束搜索，以高效排名最优论点和答案。这种方法在七个视觉推理基准测试中提升了最先进的LVLMs，表现出了更大的有效性、泛化能力和解释性。", "conclusion": "所提出的方案显著提升了LVLMs在七个视觉推理任务上的性能，在有效性、泛化能力和可解释性方面均有所提升。"}
{"llm_update_time": "20251101", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2509.12760", "html_url": "https://arxiv.org/abs/2509.12760", "title": "Similarity-Distance-Magnitude激活函数", "title_en": "Similarity-Distance-Magnitude Activations", "authors": "Allen Schmaltz", "background": "论文的背景是现有的softmax激活函数虽然在分类任务中广泛应用，但其在解释性和鲁棒性方面存在不足。具体来说，softmax激活函数主要关注决策边界，即输出的大小，但缺乏对正确深度匹配的感知和对训练分布距离的感知。", "innovation": "论文的创新点在于引入了Similarity-Distance-Magnitude (SDM)激活函数，这是一种比传统softmax更 robust 和可解释的激活函数。SDM激活函数结合了三个维度：相似性（正确预测的深度匹配）、距离（到训练分布的距离）和大小（决策边界）。此外，论文还引入了基于SDM激活的数据驱动分类器SDM估计器，能够在有选择的分类条件下控制类和预测条件的准确性，使其在使用预训练语言模型进行有选择的分类时，更具有对待变量变化和离分布输入的鲁棒性，同时仍能保持对内分布数据的信息。", "conclusion": "结论是SDM激活函数及基于SDM激活的SDM估计器可以提高模型的解释性和鲁棒性，尤其在预训练语言模型中有更好的应用效果，可以更有效地处理协变量变化和离分布输入，同时保持对内分布数据的高质量信息。"}
{"llm_update_time": "20251101", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.25897", "html_url": "https://arxiv.org/abs/2510.25897", "title": "MIRO: 多奖励条件预训练提高文本到图像质量与效率", "title_en": "MIRO: MultI-Reward cOnditioned pretraining improves T2I quality and efficiency", "authors": "Nicolas Dufour,Lucas Degeorge,Arijit Ghosh,Vicky Kalogeiton,David Picard", "background": "当前的文本到图像生成模型是在大量未整理的数据集上进行训练，以实现多样性的生成能力。然而，这与用户的偏好不一致。最近，奖励模型被设计用于后处理选择生成的图像并使其与特定的奖励（通常是用户偏好）对齐。然而，这种方法在数据处理和单一奖励优化方面会损害多样性、语义准确性和效率。", "innovation": "我们提出在训练中条件化模型以多种奖励模型来让模型直接学习用户偏好。这种方法不仅可以显著提高生成图像的视觉质量，还可以显著加快训练速度。我们提出的方法，称为MIRO，已在GenEval综合基准和用户偏好评分（PickAScore、ImageReward、HPSv2）上达到了最先进的性能。", "conclusion": "我们的方法不仅大幅提升了生成图像的视觉质量，还显著加快了训练速度，MIRO在GenEval综合基准和用户偏好评分上达到了最先进的水平。"}
{"llm_update_time": "20251101", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.25797", "html_url": "https://arxiv.org/abs/2510.25797", "title": "通过空间-时间分析和空间注意网络增强水下目标检测", "title_en": "Enhancing Underwater Object Detection through Spatio-Temporal Analysis and Spatial Attention Networks", "authors": "Sai Likhith Karri,Ansh Saxena", "background": "该研究探讨了时空建模在水下物体检测中的有效性，特别是在深度学习模型中的应用。通过比较标准YOLOv5和改进的时空增强版本T-YOLOv5的表现，以及在T-YOLOv5中加入空间注意力模块（CBAM）的效果。研究背景涵盖了水下环境中物体检测的挑战，尤其是动态环境、突然运动、部分遮挡和渐进移动的条件。", "innovation": "创新之处在于通过时空增强和空间注意力机制的应用，改进了YOLOv5模型，特别是在卷积块注意力模块（CBAM）的集成中。研究强调了时空建模如何提高在动态海洋环境中的检测精度，特别是在复杂场景下的表现。", "conclusion": "研究结果表明，T-YOLOv5在复杂物体检测上的可靠性显著优于标准模型，而加入CBAM的T-YOLOv5在挑战性场景中的表现进一步提升，尽管简单场景下的精度有所下降。总体而言，时空分析和空间注意力网络的结合显著改善了水下物体检测的效果。"}
{"llm_update_time": "20251101", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.25990", "html_url": "https://arxiv.org/abs/2510.25990", "title": "细调 Segment Anything 以实现 cine-MRI 中的实时肿瘤跟踪", "title_en": "Fine-tuning Segment Anything for Real-Time Tumor Tracking in Cine-MRI", "authors": "Valentin Boussot,Cédric Hémon,Jean-Claude Nunes,Jean-Louis Dillenseger", "background": "本文针对 TrackRAD2025 挑战，探讨了在胸腔和腹部的 cine-MRI 序列中实时肿瘤跟踪的问题，尤其是在数据极度稀缺的情况下。", "innovation": "探索了两种互补策略：无监督注册的 IMPACT 相似性度量方法和基于 SAM 2.1 的语义分割方法，通过提示驱动的交互利用 SAM 的变体。由于必须在一秒内运行，最终选择了基于 SAM 的方法。该方法使用 SAM2.1 b+，在初次注释切片的掩码提示下进行了微调。", "conclusion": "最终模型在验证集上的 Dice 相似性系数最高，在 TrackRAD2025 挑战中的隐藏测试集中取得了 0.8794 的 Dice 分数，排名第六。结果表明，基础模型在 MRI 引导放射治疗中实现精确且实时的肿瘤跟踪方面具有巨大潜力。"}
{"llm_update_time": "20251101", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.26006", "html_url": "https://arxiv.org/abs/2510.26006", "title": "CAVE：在视觉环境中检测和解释常识异常", "title_en": "CAVE: Detecting and Explaining Commonsense Anomalies in Visual Environments", "authors": "Rishika Bhagwatkar,Syrielle Montariol,Angelika Romanou,Beatriz Borges,Irina Rish,Antoine Bosselut", "background": "人类可以自然地识别、推理和解释环境中的异常情况。但在计算机视觉领域，这一长期面临的挑战仍然局限于工业缺陷或不切实际的合成生成异常，无法捕捉现实世界异常的丰富性和不可预测性。", "innovation": "本文引入了CAVE，这是首个真实世界的视觉异常基准。CAVE支持描述异常、解释异常和解释异常原因的三个开放任务，并通过详细的视觉定位和根据视觉表现、复杂性、严重性和常见性对异常分类的注释，提供了评估视觉语言模型(VLM)检测和理解异常的一个全面框架。研究表明，最先进的VLM在视觉异常感知和常识推理上存在困难，即使使用了高级提示策略。提供了一个现实且认知基础的基准，CAVE在异常检测和常识推理研究方面具有重要价值。", "conclusion": "通过提供一个现实且认知基础的基准，CAVE有助于推动视觉语言模型在异常检测和常识推理方面的研究进步。"}
{"llm_update_time": "20251101", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.25970", "html_url": "https://arxiv.org/abs/2510.25970", "title": "SplitFlow: 无反向映射的文本到图像编辑流分解", "title_en": "SplitFlow: Flow Decomposition for Inversion-Free Text-to-Image Editing", "authors": "Sung-Hoon Yoon,Minghan Li,Gaspard Beaudouin,Congcong Wen,Muhammad Rafay Azhar,Mengyu Wang", "background": "矩形流模型由于其稳定的采样轨迹和高保真输出，已成为图像生成的标准方法。尽管它们在生成能力上有很强的优势，但在图像编辑任务上也面临关键性限制：准确地将真实图像反向映射回隐空间过程的不准确性，以及编辑过程中梯度纠缠的问题，这些问题常常导致生成的输出不能忠实地反映目标提示。近期的研究尝试通过基于ODE的方法直接映射源分布和目标分布而无需反向映射，但这些方法仍然在编辑质量上表现不佳。", "innovation": "本文提出了一种基于无反向映射形式的流分解与聚合框架，以解决上述限制。该方法通过语义分解目标提示为多个子提示，并独立计算每个子提示的流动轨迹，最后将它们聚合为统一的编辑轨迹。为此，作者设计了一种投影和软聚合机制，从多任务学习中的梯度冲突解决中获得灵感，这种方法能够自适应地权重子目标的速度场，抑制语义冗余并强调不同的方向，从而在最终编辑输出中保持多样性和一致性。", "conclusion": "实验结果表明，本文方法在语义保真度和属性分离方面优于现有的零样本编辑方法。代码可以在这里获得：[请替换为实际的URL]。"}
{"llm_update_time": "20251101", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.26001", "html_url": "https://arxiv.org/abs/2510.26001", "title": "增大扫描模式的Hausdorff维度促进基于Mamba的方法在低光图像增强中的应用", "title_en": "Larger Hausdorff Dimension in Scanning Pattern Facilitates Mamba-Based Methods in Low-Light Image Enhancement", "authors": "Xinhua Wang,Caibo Feng,Xiangjun Fu,Chunxiao Liu", "background": "本文基于Mamba框架进行研究，旨在改进现有低光图像增强方法。传统的扫描模式扫描方式存在局限性，无法全面且精细地捕捉图像特征，导致信息不一致和空间局部性处理不佳，影响了低光图像的质量和处理效率。", "innovation": "提出了新颖的Hilbert Selective Scan机制，通过增加扫描路径的Hausdorff维度，使得扫描模式更加复杂有效。该机制在原有框架基础上增强了对特征空间的探索能力，从而更好地捕捉细微的局部细节，提高了整体覆盖度，减少了信息不一致，同时在保持处理远距离依赖关系的能力的前提下优化了空间局部性。此外，该方法在公开基准数据集上的实验结果表明，显著提高了定量指标和定性视觉保真度，同时降低了计算资源消耗和推理时间。", "conclusion": "所提出的方法不仅在低光图像增强技术上达到了新的技术水平，还在包括Mamba在内的其他相关技术领域具有广泛的应用前景。"}
{"llm_update_time": "20251101", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.26017", "html_url": "https://arxiv.org/abs/2510.26017", "title": "使用深度学习的适应性气候预报的城市海岸线洪水预测", "title_en": "Climate Adaptation-Aware Flood Prediction for Coastal Cities Using Deep Learning", "authors": "Bilal Hassan,Areg Karapetyan,Aaron Chung Hin Chow,Samer Madanat", "background": "气候变化和海平面上升(SLR) 对沿海城市构成了日益严重的威胁，加强了对高效、准确预测潜在洪水灾害方法的需求。传统的基于物理的水动力模拟器虽然准确，但计算成本高，不适合城市规模的沿海规划应用。深度学习(DL)技术提供了替代方案，但由于数据稀缺和高维输出要求等限制，往往受到约束。", "innovation": "利用最近提出的基于视觉的低资源DL框架，开发了一个新的轻量级卷积神经网络(CNN)-基于模型来预测在不同SLR预测和海岸线适应情景下的沿海洪水。该模型展示了在其代表的两个不同地区（阿布扎比和旧金山）之间的泛化能力，并且在预测洪水深度图的平均绝对误差(MAE)上显著优于最先进的方法，平均减少了近20%。", "conclusion": "研究结果强调了我们方法作为可扩展和实用的工具在沿海洪水管理中的潜力，为应对气候变化带来的越来越多的影响，决策者能够制定有效的缓解策略。"}
{"llm_update_time": "20251101", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.25976", "html_url": "https://arxiv.org/abs/2510.25976", "title": "Brain-IT: 通过脑交互变换器从fMRI进行图像重构", "title_en": "Brain-IT: Image Reconstruction from fMRI via Brain-Interaction Transformer", "authors": "Roman Beliy,Amit Zalcher,Jonathan Kogman,Navve Wasserman,Michal Irani", "background": "通过功能性磁共振成像（fMRI）重构人们所见的图像可以提供一个无创的窗口，来观察人类大脑。虽然最近通过扩散模型取得了一些进展，但当前的方法在重构的图像真实性上往往存在不足。Brain-IT 方法通过脑交互变换器（BIT）解决这一挑战，允许功能相似的脑体素集群之间的有效交互。这些功能集群在所有受试者中是共享的，作为跨大脑整合信息的构建块。模型的所有组件对所有集群和受试者都是共享的，这使得在数据有限的情况下实现高效的训练。", "innovation": "Brain-IT 通过脑交互变换器（BIT）预测两种互补的局部图像特征：(i) 高级语义特征，指导扩散模型朝图像的正确语义内容发展；(ii) 低级结构特征，帮助模型以正确的粗略布局图像开始扩散过程。BIT 的设计使得信息可以直接从脑体素集群流向局部的图像特征，从而实现了比当前最先进的方法更接近实际的图像重构。与此同时，仅用新受试者 1 小时的 fMRI 数据就能达到与使用传统方法处理 40 小时记录同样水平的结果。", "conclusion": "我们的方法通过 fMRI 重构了图像，以忠实重建所见图像，并在视觉上和标准客观指标上超过了当前的方法。此外，使用新的受试者的 1 小时 fMRI 数据，我们取得了与在完整的 40 小时录制数据上训练的方法相当的结果。"}
{"llm_update_time": "20251101", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.26027", "html_url": "https://arxiv.org/abs/2510.26027", "title": "通过视觉编码器中堆叠的时序注意力增强视频LLMs的时序理解", "title_en": "Enhancing Temporal Understanding in Video-LLMs through Stacked Temporal Attention in Vision Encoders", "authors": "Ali Rasekh,Erfan Bagheri Soula,Omid Daliran,Simon Gottschalk,Mohsen Fayyaz", "background": "尽管在多模态大型语言模型（MLLMs）方面取得了显著进展，但在视频中的复杂时间动态理解仍然是一个重大挑战。目前的视频大型语言模型（Video-LLM）架构在时间理解方面存在关键限制，难以处理需要对动作序列进行详细理解的任务。", "innovation": "本文提出了一种Video-LLM架构，该架构将堆叠的时序注意力模块直接引入视觉编码器中。这设计在视觉编码器中引入了时序注意力机制，使模型能够更好地捕捉动作的进展以及帧之间的关系，然后再将视觉标记传递给语言模型。", "conclusion": "本研究的结果表明，这种方法显著提高了时间推理能力，并在视频问答任务中优于现有模型，特别是在动作识别方面。我们通过在基准VITATECS、MVBench和Video-MME上实现最高+5.5%的改进，增强了视觉编码器的时间结构，解决了Video-LLMs在视频理解方面的一个关键缺口。"}
{"llm_update_time": "20251101", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.26049", "html_url": "https://arxiv.org/abs/2510.26049", "title": "FlexICL: 一种适用于肘部和腕部超声成像分割的灵活视觉在上下文学习框架", "title_en": "FlexICL: A Flexible Visual In-context Learning Framework for Elbow and Wrist Ultrasound Segmentation", "authors": "Yuyue Zhou,Jessica Knight,Shrimanti Ghosh,Banafshe Felfeliyan,Jacob L. Jaremko,Abhilash R. Hareendranathan", "background": "肘部和腕部骨折是儿童中最常见的骨折，准确分割超声（US）图像中的肌肉骨骼结构可以提高诊断准确性和治疗计划的制定。骨折表现为皮质缺陷，但需要专家解读。深度学习可以提供实时反馈并突出显示关键结构，帮助未受充分训练的用户更自信地进行检查。然而，像素级别的专家注解培训仍然耗时费力。", "innovation": "提出了一种新颖且灵活的视觉在上下文学习（ICL）框架FlexICL，用于在超声图像中分割骨区域。在视频内分割设置中，专家仅标注一小部分帧，模型则对未见过的帧进行分割。系统地研究了各种图像拼接技术和训练策略，引入了新颖的拼接方法，显著提高了模型性能，仅需5%的标记数据。FlexICL结合多种增强策略，在四个腕部和肘部US数据集中实现了稳健的分割性能，且性能优于Painter、MAE-VQGAN等最先进的视觉ICL模型以及U-Net、TransUNet等传统分割模型。", "conclusion": "FlexICL在1,252个US扫描中实现了1-27%的Dice系数改进，表明其作为一种高效且可扩展的解诀方案，非常适合医疗成像应用场景，这在标记数据稀缺的情况下尤为重要。"}
{"llm_update_time": "20251101", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.25921", "html_url": "https://arxiv.org/abs/2510.25921", "title": "使用物理指导合成数据的生成图像修复和超分辨率扫描隧道显微镜", "title_en": "Generative Image Restoration and Super-Resolution using Physics-Informed Synthetic Data for Scanning Tunneling Microscopy", "authors": "Nikola L. Kolev(1,2),Tommaso Rodani(3,4),Neil J. Curson(1,2),Taylor J.Z. Stock(1,2),Alberto Cazzaniga(4) ((1) London Centre for Nanotechnology, University College London, London, United Kingdom, (2) Department of Electronic and Electrical Engineering, University College London, London, United Kingdom, (3) University of Trieste, Trieste, Italy, (4) AREA Science Park, Trieste, Italy)", "background": "扫描隧道显微镜（STM）能够提供原子级分辨率的成像和原子操作，但由于探针退化和数据采集缓慢，其应用受到了限制。此外，探针的制作复杂，通常承受大电压，改变探针尖端的形状，需要调整。", "innovation": "提出了基于机器学习的方法，通过生成合成数据来进行图像修复和超分辨率，以减轻探针退化和数据采集缓慢的问题，使用只有36张原始实验Si(001):H图像的数据集，训练多种先进的流匹配和扩散模型，成效是图像修复并实现从稀疏采样数据有效重建图像，同时缩短了50%至100%的图像采集时间，从而有望大幅提高STM实验效率。", "conclusion": "该框架能显著提升STM的实验吞吐量，减少探针调校频率，并增强现有高速STM系统的帧率。"}
{"llm_update_time": "20251101", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.26052", "html_url": "https://arxiv.org/abs/2510.26052", "title": "基于VLM的动态负prompt生成方法用于diffusion模型", "title_en": "Dynamic VLM-Guided Negative Prompting for Diffusion Models", "authors": "Hoyeon Chang,Seungjin Kim,Yoonseok Choi", "background": "传统的负prompt方法在去噪过程中使用固定负prompt，这可能导致负prompt的指导性与当前图像预测不匹配，从而影响生成的质量和可解释性。本研究旨在通过利用视觉-语言模型（VLMs）在去噪过程中动态生成负prompt，以提高图像生成的质量和可解释性。", "innovation": "提出了一种新颖的基于VLM的动态负prompt生成方法，该方法在去噪的特定步骤中生成中间图像预测，并查询VLM以生成上下文适应的负prompt。这种方法能够更好地适应图像生成过程，实现负指导强度与文本-图像对齐之间的平衡。", "conclusion": "该方法在多个基准数据集上的实验表明，它能够在保证负指导强度的同时，提升文本与图像的一致性，从而改进生成结果的质量。"}
{"llm_update_time": "20251101", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.25901", "html_url": "https://arxiv.org/abs/2510.25901", "title": "BikeScenes：为自行车优化的在线LiDAR语义分割", "title_en": "BikeScenes: Online LiDAR Semantic Segmentation for Bicycles", "authors": "Denniz Goren,Holger Caesar", "background": "随着电动自行车的流行加剧，骑自行车者的脆弱性不断增加，这促使汽车感知技术适应自行车安全的需求。我们利用‘SenseBike’多传感器研究平台开发并评估了一种针对自行车的3D LiDAR分割方法。为了弥合汽车到自行车领域之间的差距，我们引入了BikeScenes-lidarseg数据集，该数据集包括TU Delft大学校园周边连续的3021个LiDAR扫描，并对29个动态和静态类别进行了语义注释。通过评估模型性能，我们发现微调BikeScenes数据集可实现63.6%的平均交并比（mIoU），显著优于仅使用SemanticKITTI预训练所获得的13.8%。这项结果突显了领域特定训练的必要性和有效性。我们还指出了自行车搭载硬件受约束的感知系统所特有的关键挑战，并贡献了BikeScenes数据集，以促进骑车人为中心的LiDAR分割研究的进展。", "innovation": "提出了BikeScenes-lidarseg 数据集，包含3021个LiDAR扫描数据，用于评估自行车上的LiDAR分割模型。该数据集包含了29个动态和静态类别的语义注释，有助于针对自行车的感知技术发展。通过微调该数据集，实现显著优于通用预训练模型的语义分割效果，突显了领域特定训练的重要性。", "conclusion": "本文通过微调BikeScenes数据集，展示了显著优于使用SemanticKITTI预训练结果的63.6% mIoU。这证明了领域特定训练的有效性，并强调了针对自行车感知系统特有的硬件限制挑战。贡献的BikeScenes数据集为骑车人为中心的LiDAR分割研究提供了宝贵的资源。"}
{"llm_update_time": "20251101", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.26105", "html_url": "https://arxiv.org/abs/2510.26105", "title": "多模态模型中图文间对齐安全风险", "title_en": "Security Risk of Misalignment between Text and Image in Multi-modal Model", "authors": "Xiaosen Wang,Zhijin Ge,Shaokang Wang", "background": "尽管多模态扩散模型，如图文生成模型，在进展和灵活性方面取得了显著的进步，但它们对 adversarial inputs 的敏感性仍然没有得到充分的探索。反常识的是，我们的研究表明现有的扩散模型中，图文之间的对齐并不充分。这种对齐不足带来了很大的风险，尤其是在生成不当内容或不适合工作环境的内容时更为明显。", "innovation": "我们提出了一种名为 Prompt-Restricted Multi-modal Attack (PReMA) 的新型攻击方法，通过修改输入图像（不改变提示），并在结合任何指定的提示的情况下操纵生成的内容。PReMA 是第一个仅通过创建对抗性图像来操纵模型输出的攻击方法，区别于先前主要生成对抗性提示以生成不适合工作环境内容的方法。PReMA 首次为多模态扩散模型带来了新的威胁，尤其是在使用固定提示进行图像编辑的应用中。", "conclusion": "我们在图像修复和风格转换任务中对各种模型进行了全面评估，证实了 PReMA 的强大效果。"}
{"llm_update_time": "20251101", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.26117", "html_url": "https://arxiv.org/abs/2510.26117", "title": "JOGS: 联合优化姿态估计和3D高斯点绘制", "title_en": "JOGS: Joint Optimization of Pose Estimation and 3D Gaussian Splatting", "authors": "Yuxuan Li,Tao Wang,Xianben Yang", "background": "传统的方法在进行图像合成时依赖于外部的相机姿态估计算法（如COLMAP），这往往带来计算瓶颈和误差传播问题。本研究旨在解决这些问题。", "innovation": "提出了一种新的统一框架，该框架联合优化3D高斯点和相机姿态，而无需预先校准输入。该方法通过将联合优化分解为两个交错的阶段来迭代细化3D高斯参数并更新相机姿态：首先，通过固定姿态的可微渲染更新3D高斯参数；其次，使用结合几何和光度约束的定制3D光学流算法来细化相机姿态。这在视点变化大和特征分布稀疏的情况下逐步减少投影误差。", "conclusion": "在多个数据集上进行的广泛评估表明，我们的方法显著优于现有的无COLMAP技术，并且在整体重建质量上也超过了基于COLMAP的标准基准方法。"}
{"llm_update_time": "20251101", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.26113", "html_url": "https://arxiv.org/abs/2510.26113", "title": "EgoExo-Con: 探索视角不变的视频时间理解", "title_en": "EgoExo-Con: Exploring View-Invariant Video Temporal Understanding", "authors": "Minjoon Jung,Junbin Xiao,Junghyun Kim,Byoung-Tak Zhang,Angela Yao", "background": "研究视频LLMs在进行事件时间理解时是否能够在不同视点记录同一事件时保持一致。背景是通过引入EgoExo-Con（一致性）基准测试，这是一个全面同步的自视点和外视点视频对集合，包含人类细化的自然语言查询。它关注两个时间理解任务：时间验证和时间定位，不仅评估正确性，还评估视角间的一致性。研究发现现有视频LLMs存在两个关键限制：1. 模型常在不同视角上维护一致性能较差；2. 通过同步视点的视频进行简便微调后，模型的时间一致性有所改善，但在单视角训练的情况下表现更佳。基于这些背景，提出了View-GRPO框架，旨在加强特定视角的时间推理能力，同时鼓励视角间的一致理解。", "innovation": "提出了EgoExo-Con基准测试，涵盖了自视点和外视点视频对，并且伴随着增强的时间理解和视角一致性验证。提出了View-GRPO框架，这是一个新颖的强化学习框架，能够有效加强特定视角的时间推理能力，并促进不同视角之间的理解一致性。", "conclusion": "研究结果显示，View-GRPO方法在跨视角一致性方面优于简易微调和GRPO方法。所有资源将公开展示。"}
{"llm_update_time": "20251101", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.26114", "html_url": "https://arxiv.org/abs/2510.26114", "title": "OracleAgent: 一种用于甲骨文研究的多模态推理代理", "title_en": "OracleAgent: A Multimodal Reasoning Agent for Oracle Bone Script Research", "authors": "Caoshuo Li,Zengmao Ding,Xiaobin Hu,Bang Li,Donghao Luo,Xu Peng,Taisong Jin,Yongge Liu,Shengwei Han,Jing Yang,Xiaoping He,Feng Gao,AndyPian Wu,SevenShu,Chaoyang Wang,Chengjie Wang", "background": "作为最早的文字书写系统之一，甲骨文（OBS）保存了古代文明的文化和思想遗产。然而，当前对OBS的研究面临两大挑战：一是OBS的解释涉及一个复杂的多步骤流程；二是OBS信息组织和检索的效率问题，学者们在搜索、编纂和管理相关资源上花费了大量时间。", "innovation": "本文提出OracleAgent，这是一个首个专为OBS相关信息的结构化管理与检索设计的代理系统。OracleAgent整合了多个OBS分析工具，并通过大型语言模型（LLMs）赋能，能够灵活地编排这些组件。此外，本文还构建了一个全面的领域特定多模态知识库，该知识库通过多年的数据收集、清理和专家注释过程建立，包括超过140万单字符拓片图像和80000条解释文本。OracleAgent利用这些资源进行多模态工具的辅助，帮助专家完成字符、文档、解释文本和拓片图像的检索任务。实验结果显示，OracleAgent在一系列多模态推理和生成任务中表现优异，超过了主流多模态大型语言模型（如GPT-4o）。进一步的案例研究表明，OracleAgent有效辅助了领域专家，显著减少了OBS研究的时间成本。", "conclusion": "这些结果突显了OracleAgent作为OBS辅助研究和自动化解释系统实际部署的重要步骤。"}
{"llm_update_time": "20251101", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.26125", "html_url": "https://arxiv.org/abs/2510.26125", "title": "WOD-E2E: Waymo 开放数据集，用于应对具有挑战性的长尾情景的端到端驾驶", "title_en": "WOD-E2E: Waymo Open Dataset for End-to-End Driving in Challenging Long-tail Scenarios", "authors": "Runsheng Xu,Hubert Lin,Wonseok Jeon,Hao Feng,Yuliang Zou,Liting Sun,John Gorman,Kate Tolstaya,Sarah Tang,Brandyn White,Ben Sapp,Mingxing Tan,Jyh-Jing Hwang,Drago Anguelov", "background": "基于视觉的端到端（E2E）驾驶因其可扩展性和与多模态大语言模型（MLLMs）的协同作用而在研究界引起了显著的兴趣。然而，当前的E2E驾驶基准测试主要包含名义场景，未能充分测试这些系统的真正潜力。此外，现有的开环评估指标往往无法捕捉驾驶的多模态性质，或者无法有效评估在长尾场景中的性能。", "innovation": "该论文提出了Waymo 开放数据集WOD-E2E，专门包含4,021个驾驶段落（约12小时），这些场景具有很高的挑战性且在日常生活中很少见，发生频率低于0.03%。WOD-E2E数据集包括每段的高级路线信息、本体状态以及8个周围摄像头的360度视图。为了评估E2E驾驶在这些长尾情况下的表现，引入了一个新的开环评估指标：评分类反馈分数（RFS）。评分类反馈分数衡量预测轨迹与评分类标注轨迹偏好标签的契合度，不同于测量预测航点与日志之间距离的传统指标。", "conclusion": "通过本文的工作，作者旨在促进生成适用于复杂真实世界情景的、通用性好、稳健且安全的端到端自主驾驶代理的研究。"}
{"llm_update_time": "20251101", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.26149", "html_url": "https://arxiv.org/abs/2510.26149", "title": "BasicAVSR: 通过图像先验和增强的运动补偿实现任意尺度视频超分辨率", "title_en": "BasicAVSR: Arbitrary-Scale Video Super-Resolution via Image Priors and Enhanced Motion Compensation", "authors": "Wei Shang,Wanying Zhang,Shuhang Gu,Pengfei Zhu,Qinghua Hu,Dongwei Ren", "background": "高分辨率视频帧的增强面临多方面挑战，包括空间细节的再现、时间一致性和计算复杂性。现有方法可能在这些方面表现不足。", "innovation": "提出了一个基础模块化框架 BasicAVSR，整合了四部分关键功能：（1）基于图像拉普拉斯金字塔的自适应多尺度频率先验；（2）基于流场引导的传播单元，用于邻近帧的空间时间信息聚合；（3）用于更精确相邻帧空间对齐的二次运动补偿单元；（4）超分辨率单元，生成具有尺度感知和内容无关性的上采样核。此外，通过单向RNN单位、具有有限前瞻性的单向RNN单位和双向往复RNN单位三种传播变体适应不同的应用场景需求。", "conclusion": "实验结果证明，BasicAVSR在超分辨率质量、泛化能力和推理速度方面优于现有方法。该工作不仅推动了AVSR技术的发展，还将其核心组件扩展到了多种框架中，以适应各种情境。代码可以在提供的链接中获取。"}
{"llm_update_time": "20251101", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.26140", "html_url": "https://arxiv.org/abs/2510.26140", "title": "FullPart：在全分辨率生成每个3D部件", "title_en": "FullPart: Generating each 3D Part at Full Resolution", "authors": "Lihe Ding,Shaocong Dong,Yaokun Li,Chenjian Gao,Xiao Chen,Rui Han,Yihao Kuang,Hong Zhang,Bo Huang,Zhanpeng Huang,Zibin Wang,Dan Xu,Tianfan Xue", "background": "部分基于3D的生成在各种应用中具有巨大潜力，但现有方法要么在几何细节方面不足，要么共享全局体素网格导致小型部件细节不足。本文旨在通过结合隐式和显式方法解决这些问题，提出了一种新颖的FullPart框架，可以在全分辨率下独立生成每个部件，从而生成复杂细节，并通过中心点编码策略保持全局一致性。", "innovation": "提出了一种结合隐式和显式表示的FullPart框架，首先通过隐式边界框向量集扩散过程推导出边界框布局，然后在每个部件的固定全分辨率体素网格中生成详细的部件。此外，采用中心点编码策略解决不同实际大小部件之间的信息交换时的对齐问题，使得合成具有全局一致性。同时，还提出了目前最大的人类标注3D部件数据集PartVerse-XL，包含4万个物体和32万个部件。", "conclusion": "实验表明，FullPart在3D部件生成方面取得了最先进的结果。为了促进未来在3D部件生成方面的研究，将发布相关代码、数据和模型。"}
{"llm_update_time": "20251101", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.26151", "html_url": "https://arxiv.org/abs/2510.26151", "title": "MV-MLM: 联结多视角乳腺摄影与语言进行乳腺癌诊断与风险预测", "title_en": "MV-MLM: Bridging Multi-View Mammography and Language for Breast Cancer Diagnosis and Risk Prediction", "authors": "Shunjie-Fabian Zheng,Hyeonjun Lee,Thijs Kooi,Ali Diba", "background": "大型注释数据集对于训练适用于乳腺癌检测或风险预测的计算机辅助诊断(CAD)模型至关重要。然而，获取这样的数据集需要高昂的成本和耗时，尤其需要精细详细的注释。为此，研究人员提出使用Vision-Language模型(Vision-Language Models, VLMs)，如CLIP，这些模型在大规模的图像-文本对上预训练，能够通过跨模态自我监督增强医疗成像任务中的鲁棒性和数据效率。", "innovation": "该研究提出了一种名为MV-MLM的多视角乳腺摄影和语言模型，通过结合多视角监督使模型能够从大大量的放射学数据中学习丰富的表示，并通过跨模态自我监督利用图像-文本对。MV-MLM通过联合视觉-文本学习策略提升了对不同类型数据和任务的一般化能力与准确性能，并且能够在良恶性分类、亚型分类和基于图像的癌症风险预测中取得最先进的性能表现。", "conclusion": "研究展示了提出的MV-MLM模型在乳腺癌诊断和风险预测的三个分类任务中实现了最先进的性能。此外，该模型表现出强大的数据效率，优于现有的完全监督或VLM基准模型，同时在训练过程中使用的是合成文本报告，无需实际的放射学报告。"}
{"llm_update_time": "20251101", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.26173", "html_url": "https://arxiv.org/abs/2510.26173", "title": "MoTDiff: 使用扩散模型从单张模糊图像估计高分辨率运动轨迹", "title_en": "MoTDiff: High-resolution Motion Trajectory estimation from a single blurred image using Diffusion models", "authors": "Wontae Choi,Jaelin Lee,Hyung Sup Yun,Byeungwoo Jeon,Il Yong Chun", "background": "准确估计运动信息在计算成像和计算机视觉的多种应用中至关重要。现有方法从单张模糊图像中提取运动信息时，通常得到的运动表示是低质量的，表现为粒度过粗、不够准确。本研究旨在提出一种创新框架来从单张模糊图像中精确估计高分辨率的运动轨迹。", "innovation": "本文提出了MoTDiff（基于扩散模型的高分辨率运动轨迹估计框架），它通过在单一模糊图像中提取多尺度特征图并作为条件，结合一种新颖的训练方法，能够高精度地估计细粒度的运动轨迹、整体形状和位置的一致估计，以及运动轨迹上的像素连接。", "conclusion": "实验结果表明MoTDiff在盲去模糊和编码曝光摄影的应用中均超越了现有最先进的方法。"}
{"llm_update_time": "20251101", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.26131", "html_url": "https://arxiv.org/abs/2510.26131", "title": "探索基于对象感知注意力引导的RGB-D室内SLAM帧关联", "title_en": "Exploring Object-Aware Attention Guided Frame Association for RGB-D SLAM", "authors": "Ali Caglayan,Nevrez Imamoglu,Oguzhan Guclu,Ali Osman Serhatoglu,Ahmet Burak Can,Ryosuke Nakamura", "background": "注意力模型在多个领域取得了显著进展，视觉注意力机制和可视化技术如类激活映射已被用于理解卷积神经网络（CNN）的推理过程。通过网络梯度，可以识别网络在图像识别任务中关注的区域。这些梯度可以与CNN特征结合，定位场景中更广泛的、任务特定的关注区域（显著区域）。然而，将基于梯度的注意力信息显式地集成到CNN表示中以增强语义对象理解的应用仍然有限，特别是在同时定位与地图构建（SLAM）等视觉任务中，丰富的空间注意力物体位置可以提升性能。", "innovation": "本研究提出了利用任务特定的网络注意力来改进RGB-D室内SLAM的帧关联性能。具体来说，研究结合了网络梯度衍生的层间注意力信息和CNN特征表示，以提高帧关联性能。实验结果显示，与基线方法相比，该方法在大环境中的性能更优", "conclusion": "研究通过集成任务特定的注意力信息和CNN特征表示，有效提升了RGB-D室内SLAM的帧关联性能。实验验证了此方法在大型环境下的优越性。"}
{"llm_update_time": "20251101", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.26186", "html_url": "https://arxiv.org/abs/2510.26186", "title": "ConceptScope: 通过解耦视觉概念表征数据集偏差", "title_en": "ConceptScope: Characterizing Dataset Bias via Disentangled Visual Concepts", "authors": "Jinho Choi,Hyesu Lim,Steffen Schneider,Jaegul Choo", "background": "机器学习数据集中普遍存在数据点偏向特定概念的问题，但系统性地识别这些偏差往往需要昂贵且精细的属性注释。本文探讨了这一背景问题。", "innovation": "本文提出ConceptScope框架，利用稀疏自编码器在视觉基础模型表示上训练，自动发现和量化人可解释的概念。通过语义相关性和分类标签的相关性对概念进行分类（目标、背景和偏差），从而实现基于概念的子组分类，用于数据集特征描述、偏差识别和鲁棒性评估。", "conclusion": "ConceptScope能够捕捉到广泛的概念，包括物体、纹理、背景、面部属性、情绪和动作，并且能够可靠地检测已知偏差并发现未注释的偏差，提供了一个实用工具用于数据集审计和模型诊断。"}
{"llm_update_time": "20251101", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.26154", "html_url": "https://arxiv.org/abs/2510.26154", "title": "使用深度学习检测非法车辆以打造智慧城市：孟加拉国案例研究", "title_en": "Detecting Unauthorized Vehicles using Deep Learning for Smart Cities: A Case Study on Bangladesh", "authors": "Sudipto Das Sukanto,Diponker Roy,Fahim Shakil,Nirjhar Singha,Abdullah Asik,Aniket Joarder,Mridha Md Nafis Fuad,Muhammad Ibrahim", "background": "不同国家和地区因地理位置和文化背景的不同，交通工具的种类也会有所不同。在南亚国家如孟加拉国，人力三轮车是当地最常见的交通工具之一。根据运行方式的不同，孟加拉国城市中的人力三轮车和机动三轮车可以大致分为非机动和机动两种。机动三轮车由于交通规则的限制，往往被禁止走某些路线。然而，现有的监控系统难以对机动三轮车进行监控，原因是它们与其它车辆特别非机动三轮车在外观上非常相似，而人工视频分析则极为耗时。", "innovation": "本文提出了一种基于机器学习的方法来自动识别交通图像中的机动三轮车。该系统利用了YOLOv8实时对象检测模型。为实现模型训练，作者准备了包含1,730张在不同交通条件下拍摄的、标记过的图片。实验结果表明，提出的模型在实时机动三轮车检测方面表现出色，mAP50值为83.447%，以及二元精确率和召回率均值超过78%，证明其能有效应对密集和稀疏交通环境。", "conclusion": "该数据集已被公开供进一步研究使用，文中提议的深度学习方法为在智慧城市中的机动三轮车监控提供了一个有效解决方案。"}
{"llm_update_time": "20251101", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.26196", "html_url": "https://arxiv.org/abs/2510.26196", "title": "Sketch2PoseNet: 高效且通用的手绘图到3D人体姿态预测", "title_en": "Sketch2PoseNet: Efficient and Generalized Sketch to 3D Human Pose Prediction", "authors": "Li Wang,Yiyu Zhuang,Yanwen Wang,Xun Cao,Chuan Guo,Xinxin Zuo,Hao Zhu", "background": "3D人体姿态估计从草图中具有广泛的应用前景，特别是在计算机动画和电影制作领域。与传统的人体姿态估计不同，草图作为一种抽象且比例失调的表现方式，使得这一任务面临独特挑战。现有的一些基于手绘图到姿态转换的方法受限于缺乏大规模的手绘图-3D姿态标注数据集，因此主要依赖于基于启发式规则的优化，这种方式既耗费时间又缺乏泛化能力。", "innovation": "本文提出了一种创新的方法，利用“从合成中学习”的策略来应对这些挑战。首先，训练了一个扩散模型，该模型能够从2D姿态中合成出与3D人体姿态比例失调的草图图像。这使得可以创建一个名为SKEP-120K的合成数据集，其中包括各种草图风格下120,000对精准的手绘图-3D姿势标注对。基于此合成数据集，作者引入了一种端到端的数据驱动框架，用于从各种手绘图风格中估计人体姿态和形状。该框架结合了现有2D姿态检测器和生成扩散先验，用于草图特征提取，以及一个前馈神经网络进行高效的2D姿态估计。引入了多种启发式损失函数，以确保从推断出的3D姿态与检测到的2D姿态之间的几何一致性，同时保留准确的自我接触。", "conclusion": "通过定性和定量以及主观评估的验证，证明我们的模型在手绘图到姿势估计任务中的估计精度和速度方面显著优于先前的方法。"}
{"llm_update_time": "20251101", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.26160", "html_url": "https://arxiv.org/abs/2510.26160", "title": "CRAG-MM: 多模态多轮全面RAG基准", "title_en": "CRAG-MM: Multi-modal Multi-turn Comprehensive RAG Benchmark", "authors": "Jiaqi Wang,Xiao Yang,Kai Sun,Parth Suresh,Sanat Sharma,Adam Czyzewski,Derek Andersen,Surya Appini,Arkav Banerjee,Sajal Choudhary,Shervin Ghasemlou,Ziqiang Guan,Akil Iyer,Haidar Khan,Lingkun Kong,Roy Luo,Tiffany Ma,Zhen Qiao,David Tran,Wenfang Xu,Skyler Yeatman,Chen Zhou,Gunveer Gujral,Yinglong Xia,Shane Moon,Nicolas Scheffer,Nirav Shah,Eun Chang,Yue Liu,Florian Metze,Tammy Stark,Zhaleh Feizollahi,Andrea Jessee,Mangesh Pujari,Ahmed Aly,Babak Damavandi,Rakesh Wanga,Anuj Kumar,Rohit Patel,Wen-tau Yih,Xin Luna Dong", "background": "智能眼镜等可穿戴设备正在改变人们与周围环境的互动方式，使用户能够获取视图中实体的相关信息。多模态检索增强生成（MM-RAG）在支持此类查询方面起着关键作用，但目前还没有针对可穿戴设备场景的综合基准，尤其是在多模态多轮对话方面。CRAG-MM填补了这一空白，成为一个综合性的多模态多轮RAG基准，包含来自13个领域的6.5K（图像，问题，答案）三元组和2K基于视觉的多轮对话，涵盖6.2K自我中心图像，这些图像模拟了可穿戴设备的捕获。该基准中的问题经过精心构建，以反映实际场景和挑战，包括五类图像质量问题、六类问题、实体流行度变化、信息动态性差异以及不同的对话回合。CRAG-MM设计了三个任务：单源增强、多源增强和多轮对话，每个任务都配有一个关联的检索语料库和API，用于图像知识图谱检索和网页检索。评估结果表明，直接的RAG方法在CRAG-MM单一和多轮问答中的真实度分别仅达到32%和43%，最先进的工业解决方案也具有类似的质量（32%/45%），表明有很大的改进空间。该基准吸引了大约1000名参与者和5000个提交，获奖解决方案将基线性能提高了28%，突显了其在推进领域发展方面的早期影响。", "innovation": "CRAG-MM是一个全面的多模态多轮RAG基准，包含了针对可穿戴设备的多样化的问答数据，包括6.5K（图像，问题，答案）三元组和2K基于视觉的多轮对话，设计了针对RAG的三个具体任务，并且通过KDD Cup 2025演示了其能够推动领域进步的能力，吸引了大量参与者和提交，展示了其实用价值和科研贡献。", "conclusion": "CRAG-MM提供了首个专门针对可穿戴设备情境的全面多模态多轮RAG基准，展示了目前RAG方法存在的不足，激发了进入该领域的研究活动，并显著提高了基线性能，预示着未来在此领域有巨大潜力。"}
{"llm_update_time": "20251101", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.26292", "html_url": "https://arxiv.org/abs/2510.26292", "title": "基于流匹配的约束感知轨迹生成超越模仿：端到端自主驾驶", "title_en": "Beyond Imitation: Constraint-Aware Trajectory Generation with Flow Matching For End-to-End Autonomous Driving", "authors": "Lin Liu,Guanyi Yu,Ziying Song,Junqiao Li,Caiyan Jia,Feiyang Jia,Peiliang Wu,Yandan Luo", "background": "在端到端自主驾驶中，规划是至关重要的部分。然而，现有的模仿学习方法常常面临模式崩溃的问题，无法产生多样化的轨迹假设。现有的生成方法在直接将必要安全和物理约束融入生成过程中遇到困难，通常需要额外的优化阶段来精炼输出结果。", "innovation": "该论文提出了一种名为CATG的新规划框架，结合了受约束的流匹配。CATG通过显式建模流匹配过程来克服模式崩溃，并允许灵活地从各种条件信号中获取指导。CATG的最大贡献在于：首次在流匹配过程中直接施加了明确的约束，确保生成的轨迹遵守关键的安全和运动学规定。此外，CATG还将驾驶激进度作为生成过程中的控制信号进行参数化，这使得调整轨迹风格变得精准。", "conclusion": "在NavSim v2挑战中，CATG在EPDMS得分上获得了第2名，得分51.31，因创新而荣获创新奖。"}
{"llm_update_time": "20251101", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.26282", "html_url": "https://arxiv.org/abs/2510.26282", "title": "探索不同距离下用于 periocular 验证的 CNNs 共性和可解释性", "title_en": "Exploring Complementarity and Explainability in CNNs for Periocular Verification Across Acquisition Distances", "authors": "Fernando Alonso-Fernandez,Kevin Hernandez Diaz,Jose M. Buades,Kiran Raja,Josef Bigun", "background": "研究了不同 CNN 结构在 UBIPr 数据库中于不同距离进行 periocular 验证任务的表现。VGGFace2 提供了大量眼睛图像，用于训练三种复杂度递增的 CNN 架构：SqueezeNet、MobileNetv2 和 ResNet50。通过使用余弦相似度和卡方距离评估性能，比较了不同网络初始化，并采用了逻辑回归进行得分级融合。同时，使用 LIME 热图和 Jensen-Shannon 散度比较了不同 CNN 的注意力模式。", "innovation": "首次针对 periocular 验证任务，在不同距离下，探索了三种不同复杂度的 CNN 架构的互补性和可解释性。实验中，逻辑回归进行的得分级融合表现出显著的性能增益，尤其当结合所有三个网络时。热图显示了不同网络通常关注于图像的不同区域，解释了它们的互补性。", "conclusion": "该方法在 UBIPr 数据集上显著超越了以前的工作，达到了新的 SOTA 性能。"}
{"llm_update_time": "20251101", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.26297", "html_url": "https://arxiv.org/abs/2510.26297", "title": "朝向实用型地球观测星座调度：基准与方法", "title_en": "Towards Realistic Earth-Observation Constellation Scheduling: Benchmark and Methodology", "authors": "Luting Wang,Yinghao Xiang,Hongliang Huang,Dongjun Li,Chen Gao,Si Liu", "background": "敏捷地球观测卫星（AEOSs）星座为监控地球表面提供了前所未有的灵活性，但在大规模场景、动态环境和严格约束下进行调度依然具有挑战性。现有方法往往简化这些复杂性，影响其实用性能。", "innovation": "提出了一种统一框架，包括标准化的基准套件AEOS-Bench和新颖的调度模型。AEOS-Bench包含3907个精细调校的卫星资产和16410个场景，每个场景涉及1至50颗卫星和50至300项成像任务，通过高保真模拟平台生成，确保模拟的现实性。同时引入了AEOS-Former，一种基于变换器的调度模型，结合了约束感知注意力机制。", "conclusion": "实验结果表明，AEOS-Former在任务完成和能源效率方面优于基础模型，消融研究突出了每个组件的贡献。"}
{"llm_update_time": "20251101", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.26294", "html_url": "https://arxiv.org/abs/2510.26294", "title": "利用大规模面部数据集通过面部裁剪实现深度 periocular 识别", "title_en": "Leveraging Large-Scale Face Datasets for Deep Periocular Recognition via Ocular Cropping", "authors": "Fernando Alonso-Fernandez,Kevin Hernandez-Diaz,Jose Maria Buades Rubio,Josef Bigun", "background": "研究聚焦于眼科生物特征，特别是眼周区域（眼睛周围的区域），因为这种生物特征具有较高的区分度和较少的采集约束。研究评估了三种不同深度和复杂性的卷积神经网络架构，以评估它们在眼周识别的有效性。实验数据来自包含1,907,572张眼科裁剪的大型VGGFace2数据库，远超现有工作依赖的小规模眼周数据集，通常只有几千张图像。", "innovation": "使用1,907,572张来自大规模VGGFace2数据库的眼科裁剪图像训练三种不同架构的卷积神经网络。实验使用了来自VGGFace2-Pose和UFPR-Periocular数据库的图像。前者受到了非控制条件的影响，导致错误接受率（EERs）在9-15%之间，后者由于高质量的图片和更一致的采集协议，EERs达到1-2%，表现出显著的性能提升。", "conclusion": "这是目前在UFPR数据集上报告的最低错误接受率。研究结果表明，大规模面部数据集可用于提高眼周识别的准确性。"}
{"llm_update_time": "20251101", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.26268", "html_url": "https://arxiv.org/abs/2510.26268", "title": "基于人类认知法则重新审视生成红外和可见光图像融合", "title_en": "Revisiting Generative Infrared and Visible Image Fusion Based on Human Cognitive Laws", "authors": "Lin Guo,Xiaoqing Luo,Wei Xie,Zhancheng Zhang,Hui Li,Rui Wang,Zhenhua Feng,Xiaoning Song", "background": "现有的红外和可见光图像融合方法常常面临平衡模态信息的困境。生成型融合方法通过学习数据分布来重建融合图像，但其生成能力依然有限。此外，模态信息选择的不透明性进一步影响了在复杂场景下融合结果的可靠性和一致性。", "innovation": "该论文基于人类认知规律重新审视生成型图像融合的本质，提出了一个新的红外和可见光图像融合方法，称为HCLFuse。首先，HCLFuse探讨了无监督融合网络中信息映射的量化理论，设计了一个多尺度掩码调控变分瓶颈编码器。该编码器通过后验概率建模和信息分解来提取准确且简洁的低级模态信息，从而支持生成高保真的结构细节。此外，扩散模型的概率生成能力与物理规律相结合，形成了一种时间相关的物理指导机制，该机制在不同阶段自适应地调节生成过程，从而增强了模型感知数据内在结构的能力并减少对数据质量的依赖。", "conclusion": "实验结果显示，该方法在多个数据集上的定性和定量评估中达到了最先进的融合性能，并且显著改善了语义分割指标。这充分证明了该生成型图像融合方法，借鉴人类认知的优势，在增强结构一致性和细节质量方面的优越性。"}
{"llm_update_time": "20251101", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.26203", "html_url": "https://arxiv.org/abs/2510.26203", "title": "开发多任务集成几何深度网络以实现供应链可持续性和风险管理", "title_en": "Developing a Multi-task Ensemble Geometric Deep Network for Supply Chain Sustainability and Risk Management", "authors": "Mehdi Khaleghi,Nastaran Khaleghi,Sobhan Sheykhivand,Sebelan Danishvar", "background": "供应链的可持续性在实现供应链最优性能中起着关键作用。供应链风险管理和准确的产品分类是提高供应链网络可持续性和效能的关键因素。近年来，基于深度网络的突破为分析供应链数据提供了多种架构选择，研究通过使用新颖的几何深度网络提出了一种集成深度网络，以利用供应链中的信息相关性来推断数据库中样品的隐形状态。这个研究在供配电图数据集和DataCo数据集上评估了所提出的深度网络的功能，并应用了交付状态预测来实现风险管理，通过供配电图数据库中的产品分类和边缘分类来提高供应链网络的可持续性。", "innovation": "该研究提出了一种新颖的几何深度网络——Chebyshev集成几何网络（Ch-EGN），这是一种结合了卷积和几何深度学习的混合网络。该网络旨在利用供应链中的信息依赖性来推断数据集中样品的隐形状态。实验结果表明，该方法在风险管理和可持续供应链方面能显著优于现有技术，特别是对于风险管理，集成网络的平均准确率为98.95%，对于5类产品组分类和4类产品关系分类的可持续供应链，分别达到了100%和98.07%的平均准确率，25家公司关系分类的平均准确率为92.37%。", "conclusion": "该研究提出了一个集成几何深度网络，通过利用供应链中的信息依赖性来推断数据集中样品的隐形状态，提高了预测和分类的准确性，并应用于风险管理和供应链可持续性的提升。这一方法的有效性与现有技术进行比较已有突破性进展，特别是在几种分类任务上表现出显著的改进和效率。"}
{"llm_update_time": "20251101", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.26213", "html_url": "https://arxiv.org/abs/2510.26213", "title": "OmniLayout：使用LLMs实现从粗到细学习以生成通用文档布局", "title_en": "OmniLayout: Enabling Coarse-to-Fine Learning with LLMs for Universal Document Layout Generation", "authors": "Hengrui Kang,Zhuangcheng Gu,Zhiyuan Zhao,Zichen Wen,Bin Wang,Weijia Li,Conghui He", "background": "文档AI技术发展迅速，受到越来越多的关注。尽管大多数研究集中在文档布局分析（DLA）上，但其生成性对应——文档布局生成——却鲜有探索。主要障碍在于多样性的稀缺性：大多数现有研究使用具有曼哈顿结构的学术论文，而报纸、杂志等开放世界体裁则明显不足。为解决这一问题，我们创建了OmniLayout-1M，这是首个包含广泛文档布局的百万规模数据集，涵盖了六种常见文档类型，并包含了来自多个来源的现代布局。此外，因为现有方法在复杂领域遇到困难，无法妥善排列长序列，我们引入了OmniLayout-LLM，这是一种0.5B参数量，采用两阶段从粗到细学习框架的模型：1）从OmniLayout-1M中学习通用布局原则，采用粗略类别定义；2）利用精细注释将知识应用于特定领域。", "innovation": "1. 创建了OmniLayout-1M，首个包含六种常见文档类型的百万规模数据集。\n2. 提出了OmniLayout-LLM，一种0.5B参数量的模型，具有两阶段从粗到细学习框架，能够有效处理复杂领域并妥善排列长序列。\n3. 实验结果表明，该方法在多个领域中表现出色，显著超越现有布局生成模型及最新的通用语言模型。\n4. 公开发布了代码、模型和数据集。", "conclusion": "我们的方法在多个领域中取得了优异表现，显著超越了现有的布局生成专家和最新的一般目的语言模型。同时，我们公开发布了代码、模型和数据集，以供其他研究和开发者使用。"}
{"llm_update_time": "20251101", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.26241", "html_url": "https://arxiv.org/abs/2510.26241", "title": "时间之流朝哪个方向？基于心理物理学的视觉语言模型评估", "title_en": "Which Way Does Time Flow? A Psychophysics-Grounded Evaluation for Vision-Language Models", "authors": "Shiho Matta,Lis Kanashiro Pereira,Peitao Han,Fei Cheng,Shigeru Kitazawa", "background": "现代的视觉语言模型（VLMs）在多种跨模态任务上表现出色，但对于视频中的时间信息掌握较弱且未充分评估。本文通过一个看似简单的判别时间箭头（AoT）的挑战深入探讨了这一空白。AoT-PsyPhyBENCH 是一个心理物理学验证的基准测试，用于验证 VLMs 是否能够仅通过自然视频的短片段来推断时间方向，使用与人类相同的刺激和行为基准来评估。开放参数和专有、推理和非推理 VLMs 的综合评估显示，大多数模型的表现接近随机，甚至最好的模型在物理不可逆过程（如自由下落、扩散/爆炸）和因果手动动作（如拆分/加法）上也落后于人类的准确识别能力，这些人类几乎可以立即识别。这些结果揭示了当前跨模态系统中的一个重要空白：尽管能够捕捉丰富的视觉语义关联，但缺乏用于时间连续性和因果理解的归纳偏置。为此，作者发布了 AoT-PsyPhyBENCH 的代码和数据以促进 VLMs 物理和时间推理能力的进一步提高.", "innovation": "提出了 AoT-PsyPhyBENCH，这是一个心理物理学验证的基准测试，通过自然视频的短片段来评估 VLMs 推断时间方向的能力，使用与人类相同的刺激和行为基准。该评估挑战了以往的研究，揭示了视觉语言模型在时间信息理解和物理不可逆过程排除上的不足，从而推动了跨模态系统中更深入的时间和因果理解研究。作者还开放了 AoT-PsyPhyBENCH 的数据和代码以鼓励进一步的研究进展，提升 VLMs 的物理和时间推理能力.", "conclusion": "现阶段的视觉语言模型在捕捉视觉语义关联方面表现出色，但在时间连续性和因果理解上存在重大缺陷。AoT-PsyPhyBENCH 的评估揭示了视觉语言模型在推断时间方向上的不足，希望通过这个基准测试，能够进一步提高视觉语言模型的物理和时间推理能力。"}
{"llm_update_time": "20251101", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.26391", "html_url": "https://arxiv.org/abs/2510.26391", "title": "基于兴趣引导扩散模型的EEG驱动图像重建", "title_en": "EEG-Driven Image Reconstruction with Saliency-Guided Diffusion Models", "authors": "Igor Abramov,Ilya Makarov", "background": "现有的基于脑电图（EEG）的图像重建方法常常忽略了空间注意力机制，这限制了重建图像的真实度和语义一致性。", "innovation": "提出了一个双条件框架，将EEG嵌入与空间显著性图相结合，以增强图像生成。该方法利用自适应思维映射器（ATM）提取EEG特征，并通过低秩适配（LoRA）微调稳定的扩散模型2.1，使神经信号与视觉语义对齐，同时还使用ControlNet分支根据显著性图进行空间控制。", "conclusion": "在THINGS-EEG数据集上，该方法在低级和高级图像特征的质量上显著优于现有方法，同时与人类视觉注意力强烈对齐。结果表明，注意力先验解决了EEG的模糊性，使高保真重建得以实现，应用于医学诊断和神经适应接口，并通过高效的预训练扩散模型适配促进神经解码。"}
{"llm_update_time": "20251101", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.26304", "html_url": "https://arxiv.org/abs/2510.26304", "title": "探索不同音乐类型引发的情绪关联：一项使用主观问卷和EEG的研究", "title_en": "Exploring the correlation between the type of music and the emotions evoked: A study using subjective questionnaires and EEG", "authors": "Jelizaveta Jankowska,Bożena Kostek,Fernando Alonso-Fernandez,Prayag Tiwari", "background": "本研究探讨了不同类型音乐对人类情绪的影响。在实验中，受试者在听音乐的同时进行了主观调查和脑电图（EEG）测量，旨在展示不同音乐风格对情绪的影响。研究对象为性别和音乐偏好不同的多样化群体，从而能够捕捉到不同的人对音乐的广泛情绪反应。实验结束后，研究人员分析了问卷与EEG信号之间的关系，揭示了情绪与观察到的大脑活动之间的联系。", "innovation": "该研究采用了结合主观调查和脑电图（EEG）测量的方法来研究音乐对情绪的影响，通过这种方法揭示了情绪与大脑活动之间的潜在关联，这是以前较少使用的技术结合。此外，研究对象的多样性也为研究结果提供了更广泛的适用性。", "conclusion": "该研究发现不同类型的音乐确实能够引发不同类型的情绪反应，且这些情绪反应与大脑活动存在一定的关联。通过分析脑电图和问卷数据，研究人员能够更深入地理解音乐如何影响人类的情感体验。"}
{"llm_update_time": "20251101", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.26315", "html_url": "https://arxiv.org/abs/2510.26315", "title": "基于证据理论的CNN和ViT结合的混合框架用于糖尿病视网膜病变分级", "title_en": "A Hybrid Framework Bridging CNN and ViT based on Theory of Evidence for Diabetic Retinopathy Grading", "authors": "Junlai Qiu,Yunzhu Chen,Hao Zheng,Yawen Huang,Yuexiang Li", "background": "糖尿病视网膜病变（DR）是中老年人群中视力丧失的主要原因之一，严重影响了他们的日常生活和心理健康。现有的基于卷积神经网络（CNN）或视觉变换器（ViT）的自动DR诊断系统可以提高临床筛查的效率和早发现DR的能力。然而，由于CNN或ViT各自存在的局限性，现有单一模型性能已达到瓶颈。研究发现，结合不同类型的模型能够充分利用各自的优势，提升整体性能。因此，本文提出了一个新的证据融合框架，通过将不同模型的特征转化为支持证据进行融合，从而提高DR分级的准确性和可解释性。", "innovation": "本文提出了一种新的证据融合范式，基于证据理论将不同骨干网络（CNN和ViT）提取的特征转化为支持证据，并通过一组深度证据网络进行转换。这种方法可以自适应调整不同骨干网络之间的融合模式，从而提高混合模型的性能。实验结果表明，该方法在公共DR分级数据集上具有较高的准确性和良好的特征融合及决策解释性。", "conclusion": "本文提出的方法不仅提高了DR的分级准确性，还对特征融合和决策提供了解释性。研究成果为糖尿病视网膜病变的自动化诊断提供了新的思路和技术支持。"}
{"llm_update_time": "20251101", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.26443", "html_url": "https://arxiv.org/abs/2510.26443", "title": "点St3R：通过三维地基对应关系进行点跟踪", "title_en": "PointSt3R: Point Tracking through 3D Grounded Correspondence", "authors": "Rhodri Guerrier,Adam W. Harley,Dima Damen", "background": "近期，基于3D重建的模型，如DUSt3R和MASt3R，在静态场景的2D和3D对应关系方面显示出了巨大的潜力。本文旨在利用这些模型进行点跟踪任务，通过3D地基对应关系来实现。", "innovation": "提出了一种新的方法，结合重建损失和动态对应的训练，以及引入视线头。对于点跟踪任务，仅利用少量合成数据微调MASt3R，并在缺乏时间上下文的情况下进行训练和评估。通过结合动态和静态点对应关系，本文在多个数据集上实现或超过了现有模型的结果。", "conclusion": "点St3R在四个数据集上实现了或超越了其他模型的结果，特别是在TAP-Vid-DAVIS 73.8 δ_avg / 85.8% 遮挡准确率方面超过了CoTracker2。同时介绍了三维点跟踪的结果，并展示了不同训练数据集和动态对应关系占比的消融实验结果。"}
{"llm_update_time": "20251101", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.26466", "html_url": "https://arxiv.org/abs/2510.26466", "title": "基于表示级反事实校准的无偏零样本识别", "title_en": "Representation-Level Counterfactual Calibration for Debiased Zero-Shot Recognition", "authors": "Pei Peng,MingKun Xie,Hang Hao,Tong Jin,ShengJun Huang", "background": "在视觉-语言模型中，目标-背景捷径是一个持续存在的挑战，这导致了在测试时场景与熟悉的训练共同出现不同时的零样本可靠性降低。文章将此问题重新定义为因果推理问题，并探讨如果对象出现在不同的环境中，预测是否会保持一致。", "innovation": "研究将对象和背景的期望估计在CLIP的表示空间内，并通过重新组合对象特征与外部数据集、批邻居或文本描述中采样的不同背景样本，合成了反事实嵌入。通过估计直接总效应并模拟干预措施，研究还去除了背景激活，保留了有益的对象-背景交互，同时减轻了幻觉分数。这种方法无需重新训练或设计提示即可大幅提升上下文敏感基准上的最坏组和平均准确性，建立了一个新的零样本最佳状态。", "conclusion": "除了改进性能，本文框架提供了一种轻量级的表示级反事实方法，为去偏见和可靠的多模态推理提供了实际的因果途径。"}
{"llm_update_time": "20251101", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.26464", "html_url": "https://arxiv.org/abs/2510.26464", "title": "迈向精细视觉-语言对齐的少样本异常检测", "title_en": "Towards Fine-Grained Vision-Language Alignment for Few-Shot Anomaly Detection", "authors": "Yuanting Fan,Jun Liu,Xiaochen Chen,Bin-Bin Gao,Jian Li,Yong Liu,Jinlong Peng,Chengjie Wang", "background": "少样本异常检测（FSAD）方法使用少量已知的正常样本来识别异常区域。现有的大多数方法依赖于预训练的视觉-语言模型（VLMs）的能力，通过文本描述和图像之间的特征相似性来识别潜在的异常区域。但是，由于缺乏详细的文字描述，这些方法只能预定义图像级别的描述以匹配每个性视觉部分标记，这导致了图像描述和像素级视觉异常之间的语义不匹配，导致次优的定位性能。", "innovation": "本文提出了一种多级精细语义标注（MFSC）方法，提供了一种自动构建的多级和细粒度的文字描述，适用于现有的异常检测数据集。基于MFSC，提出了一种名为FineGrainedAD的新框架，以提高异常定位性能，包括多级可学习提示（MLLP）和多级语义对齐（MLSA）两个组件。MLLP通过自动生成和串联机制引入了多级的语义细化，而MLSA设计了区域聚合策略和多级对齐训练，以促进可学习提示与相应视觉区域更好地对齐。", "conclusion": "实验表明，提出的FineGrainedAD在MVTec-AD和VisA数据集的少样本设置中，整体性能优于现有方法。"}
{"llm_update_time": "20251101", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.26441", "html_url": "https://arxiv.org/abs/2510.26441", "title": "A-TPT: 用于视觉语言模型在测试时提示调优的角多样性校准性质", "title_en": "A-TPT: Angular Diversity Calibration Properties for Test-Time Prompt Tuning of Vision-Language Models", "authors": "Shihab Aaqil Ahamed,Udaya S.K.P. Miriya Thanthrige,Ranga Rodrigo,Muhammad Haris Khan", "background": "测试时提示调优（TPT）已成为一种有前景的技术，无需使用标记数据即可将大型视觉语言模型（VLMs）适应不可见任务。然而，缺乏文本特征之间的分散性会影响校准性能，从而对VLMs的可靠性和安全性产生担忧。当前的TPT方法主要集中在通过最大化平均文本特征的分散性或施加正交性约束来改善提示校准，这鼓励了角度分离。然而，这些方法可能无法总是提供最佳的角度分离，这意味着忽略了角度多样性的关键作用。因此，为了应对这一挑战，提出了A-TPT框架，该框架引入角度多样性以鼓励由相应的可学习提示诱导的规范化文本特征的均匀分布。这种均匀性通过在单位超球体上最大化特征对之间的最小角度距离来实现。", "innovation": "提出了一种新颖的TPT框架A-TPT，旨在通过最大化最小对角距离来鼓励单位超球体上规范化文本特征的均匀分布，从而引入角多样性。实验表明，A-TPT方法在减少综合平均校准误差方面优于最先进的TPT方法，同时保持了相当的准确性。特别地，在自然分布变化时，A-TPT方法在零样本校准性能方面表现出优越性，并且在医学数据集上的迁移性良好。此外，提供了广泛的分析，包括理论方面，以证明A-TPT的合理性。", "conclusion": "结果表明，推广角多样性可以实现分散的文本特征，从而显著改善VLMs在测试时适应期间的校准。A-TPT方法在多个数据集和模型架构上的广泛实验结果显示了其优越性。该代码将对外公开。"}
{"llm_update_time": "20251101", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.26339", "html_url": "https://arxiv.org/abs/2510.26339", "title": "GLYPH-SR：通过VLM指导的潜变量扩散模型能否同时实现高质量图像超分辨率和高保真度文本恢复？", "title_en": "GLYPH-SR: Can We Achieve Both High-Quality Image Super-Resolution and High-Fidelity Text Recovery via VLM-guided Latent Diffusion Model?", "authors": "Mingyu Sung,Seungjae Ham,Kangwoo Kim,Yeokyoung Yoon,Sangseok Yun,Il-Min Kim,Jae-Mo Kang", "background": "图像超分辨率(SR)对许多视觉系统至关重要，包括监控、自主、文档分析和零售分析，因为它可以恢复高频细节，特别是场景文本。情景文本（场景中的文本，如指示牌、产品标签、门面等）通常包含最直接的信息；当字符模糊或虚构时，光学字符识别(OCR)和后续决策会失败，即使其余图像清晰可见。然而，之前的SR研究大多针对失真（如PSNR/SSIM）或学习的感知度量（如LIPIS、MANIQA、CLIP-IQA、MUSIQ），这些度量对于字符级别的错误不敏感。此外，一些研究虽然关注文本SR但往往聚焦于孤立字符的简化基准，忽视了复杂自然场景中的文本挑战。因此，情景文本常被当作通用纹理处理。在实际部署中，要使SR有效，必须明确优化文字清晰度和感知质量。因此，GLYPH-SR呈现了一种聚焦于文字识别和感知质量的视觉-语言指导的扩散框架。", "innovation": "GLYPH-SR采用了一种由OCR数据引导的文字-SR融合控制网络（TS-ControlNet），以及一个短-长交替调度器，交替进行文字和场景中心指导。该模型在合成语料库上训练，同时冻结主要的SR分支。GLYPH-SR在OCR F1分数上相比扩散/生成对抗网络（GAN）基线提高了最高15.18个百分点，同时保持了竞争力的MANIQA、CLIP-IQA和MUSIQ评分。模型设计旨在同时实现高可读性和高视觉真实性，呈现出“看上去正确”与“读起来正确”的效果。", "conclusion": "GLYPH-SR旨在同时提升图像超分辨率质量和文本恢复的准确性。通过视觉-语言引导的潜变量扩散模型，它显著提高了OCR F1分数，并保持了感知质量。"}
{"llm_update_time": "20251101", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.26412", "html_url": "https://arxiv.org/abs/2510.26412", "title": "LoCoT2V-Bench: 长视频生成的基准", "title_en": "LoCoT2V-Bench: A Benchmark for Long-Form and Complex Text-to-Video Generation", "authors": "Xiangqing Zheng,Chengyue Wu,Kehai Chen,Min Zhang", "background": "近年来，文本转视频生成在生成短而高质量的片段方面取得了显著进展，但在处理复杂提示时，评估长视频输出仍然是一项重大挑战。现有基准大多依赖简化的提示，并主要集中在低级指标上，忽略了与提示的精细对齐以及叙事连贯性和主题表达等抽象维度。", "innovation": "研究提出了LoCoT2V-Bench，这是一种专门为在复杂输入条件下进行长时间视频生成（LVG）设计的基准。LoCoT2V-Bench基于各种真实世界的视频，引入了一系列现实和复杂的提示，融入了场景过渡和事件动态等元素，并构建了一个多维的评估框架，包括我们的新提出的度量标准，如事件级对齐、细粒度的时间一致性、内容清晰度以及关注抽象属性如叙事流动、情感反应和角色发展的人类期望实现度（HERD）。", "conclusion": "使用这个框架，研究对九个代表性的时间生成模型进行了全面评估，发现当前方法在基础的视觉和时间方面表现良好，但在事件间的连续性、细粒度对齐和高层次主题一致性等方面存在不足。总体而言，LoCoT2V-Bench为评估长文生成提供了综合可靠的平台，并指出了未来方法改进的关键方向。"}
{"llm_update_time": "20251101", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.26474", "html_url": "https://arxiv.org/abs/2510.26474", "title": "通过头部与尾部重新平衡对抗LVLMs自我改进中的马太效应", "title_en": "Counteracting Matthew Effect in Self-Improvement of LVLMs through Head-Tail Re-balancing", "authors": "Xin Guo,Zhiheng Xi,Yiwen Ding,Yitao Zhai,Xiaowei Shi,Xunliang Cai,Tao Gui,Qi Zhang,Xuanjing Huang", "background": "大型视觉语言模型（LVLMs）的自我改进已成为提高其推理能力的主流模式，模型通过迭代探索和学习成功轨迹。然而，研究发现，在自我改进过程中存在一个关键问题：模型在生成简单查询（头数据）的高质量轨迹方面表现出色，但在处理更复杂的查询（尾数据）方面存在困难。这种不平衡优化导致模型优先发展简单推理技能，而阻碍了其解决复杂推理任务的能力。这种不平衡现象随着迭代次数增加而加剧，我们将其称为“马太效应”，这种效应最终阻碍了模型进一步改进并导致性能瓶颈。", "innovation": "引入了四种有效的策略，从重新分布和轨迹重采样的两个角度出发，以实现探索和学习过程中的头尾重新平衡。这些策略能够有效对抗LVLMs自我改进中的“马太效应”，提高视觉推理能力，并且在Qwen2-VL-7B-Instruct和InternVL2.5-4B模型上的广泛实验中，平均性能提升了3.86个百分点。", "conclusion": "通过重新平衡头部和尾部数据的分布和采样，使模型在处理复杂推理任务时更加均衡，从而克服了LVLMs自我改进中的‘马太效应’，进而提升模型的视觉推理能力。"}
{"llm_update_time": "20251101", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.26569", "html_url": "https://arxiv.org/abs/2510.26569", "title": "AdSum: 两流音频-视觉摘要化法用于自动化视频广告裁剪", "title_en": "AdSum: Two-stream Audio-visual Summarization for Automated Video Advertisement Clipping", "authors": "Wen Xie,Yanjun Zhu,Gijs Overgoor,Yakov Bart,Agata Lapedriza Garcia,Sarah Ostadabbas", "background": "广告主常需为同一活动制作不同长度版本的广告，传统方法需要手动筛选和重新编辑长视频广告来生成较短版本，这过程耗时耗力。本文提出一种利用视频摘要技术的自动视频广告剪辑框架。", "innovation": "首次将视频剪辑问题定义为镜头选择问题，特别针对广告行业。不同于现有的主要关注视觉内容的通用视频摘要方法，该方法强调音频在广告中的关键作用。开发了两流音频-视觉融合模型来预测视频帧的重要性，重要性指该帧被选为广告短版帧的可能性。为解决广告专用数据集缺乏的问题，提出了包含102对30秒和15秒真实广告视频的AdSum204数据集。", "conclusion": "广泛实验表明，模型在包括平均精度、曲线下的面积、Spearman和肯德尔等多种指标上优于当前最佳方法。"}
{"llm_update_time": "20251101", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.26509", "html_url": "https://arxiv.org/abs/2510.26509", "title": "基于粒子群优化的细胞自动机制导边缘检测器鲁棒性分析", "title_en": "Analysis of the Robustness of an Edge Detector Based on Cellular Automata Optimized by Particle Swarm", "authors": "Vinícius Ferraria,Eurico Ruivo", "background": "边缘检测是图像处理中的关键任务，旨在从图像中提取相关信息。然而，一些边缘检测器存在一些缺点，如难以检测松散的边缘和缺乏上下文来提取特定问题的相关信息。为了克服这些缺点并使检测器适应图像的特性，本研究设计了一种由二维细胞自动机描述并结合元启发式方法和迁移学习技术优化的可适应检测器。该研究旨在分析优化阶段搜索空间扩展对边缘检测器性能的影响以及检测器在自然图像及其专门子集中的鲁棒适应能力。然而，研究结果表明，在选定的图像集中扩展优化阶段的搜索空间并不是有效的，模型的适应性和迁移学习技术对该模型的改进不显著。", "innovation": "开发了一种基于二维细胞自动机描述的可适应边缘检测器，并通过结合元启发式方法和迁移学习技术进行了优化。这种设计旨在提高检测器的灵活性和适应性，尤其是在处理自然图像和其特定子集时。该研究还通过一系列实验和验证技术分析了模型的适应性，并探索了如何改进模型，在优化阶段扩展搜索空间和迁移学习的应用均未显示出显著的改善效果。这项工作展示了如何利用细胞自动机和优化技术改进边缘检测器的性能，并为未来的研究提供了方向。", "conclusion": "扩展优化阶段的搜索空间并未提高选择图像集合中的可适应检测器的性能。尽管提出了基于粒子群优化的细胞自动机制导边缘检测器的技术，但在特定的环境下，这种方法并未显示出显著的优势。模型展示的适应性在不同的验证方法中得到验证，但迁移学习技术的应用并不突出。因此，在未来的研究中，可能需要探索更多的方法以提高边缘检测器的鲁棒性和适应性。"}
{"llm_update_time": "20251101", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.26614", "html_url": "https://arxiv.org/abs/2510.26614", "title": "Spiking Patches: Asynchronous, Sparse, and Efficient Tokens for Event Cameras", "title_en": "Spiking Patches: Asynchronous, Sparse, and Efficient Tokens for Event Cameras", "authors": "Christoffer Koo Øhrstrøm,Ronja Güldenring,Lazaros Nalpantidis", "background": "先前的工作中，事件通常被表示为帧或体素。虽然这些表示方法能够获得高准确性，但由于它们是同步的，因此降低了空间稀疏性。", "innovation": "提出了事件的标记化，并设计了专门适用于事件相机的tokenizer，名为Spiking Patches。Spiking Patches能够在保留事件相机独特属性的同时，实现比体素和帧更快的推理时间，且在准确性上不输于体素和帧，并在某些情况下甚至超越它们。", "conclusion": "事件标记化代表了事件基视觉的一个新方向，朝着能够保留事件相机性质的方法迈出了一步。"}
{"llm_update_time": "20251101", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.26601", "html_url": "https://arxiv.org/abs/2510.26601", "title": "ResMatching：利用引导条件流匹配的抗噪计算超分辨", "title_en": "ResMatching: Noise-Resilient Computational Super-Resolution via Guided Conditional Flow Matching", "authors": "Anirban Ray,Vera Galinova,Florian Jug", "background": "计算超分辨率（CSR）在荧光显微镜中有着悠久的历史，尽管是一个病态问题。其核心在于找到一种先验假设，以在低于显微镜成像能力的频率上进行外推。随着更好的数据驱动机器学习技术的出现，更强的先验可以被学习，从而导致更好的结果。", "innovation": "ResMatching是一种新颖的CSR方法，它使用引导条件流匹配来学习改进的数据先验。该方法被证明在4种不同的生物结构上表现出了竞争力，特别适用于难以学习强先验的情况，如低分辨率图像噪声较大时。此外，ResMatching还能从隐式学习的后验分布中采样，该分布适用于所有测试用例，从而使方法能够输出每个像素的数据不确定性术语，指导用户拒绝不确定的预测。", "conclusion": "ResMatching在所有测试情况下都能达到最佳的数据保真度和感知现实之间的权衡。该方法特别适用于强先验难以学习的情况，即使给定的低分辨率图像包含大量噪声。此外，ResMatching还能为用户提供数据不确定性的量化指标，有助于改进预测质量。"}
{"llm_update_time": "20251101", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.26609", "html_url": "https://arxiv.org/abs/2510.26609", "title": "CYPRESS: 基于普里希维地球观测编码器的卫星感应作物产量预测", "title_en": "CYPRESS: Crop Yield Prediction via Regression on Prithvi's Encoder for Satellite Sensing", "authors": "Shayan Nejadshamsi,Yuanyuan Zhang,Shadi Zaki,Brock Porth,Lysa Porth,Vahab Khoshdel", "background": "精准农业的快速发展需要准确和及时的作物产量预测，以确保全球粮食安全和现代农业管理。传统的预测方法往往缺乏适用于精准农业的大规模和高粒度的可扩展性。现有的基于深度学习的作物产量预测模型通常在精度和细粒度上存在不足。", "innovation": "CYPRESS是一种基于深度学习的模型，用于高分辨率的油菜作物产量预测。该模型利用了一种预先训练的大规模地理空间基础模型（Prithvi-EO-2.0-600M），并对其进行调整以执行连续回归任务，将多时相的卫星图像转换为密集、像素级的产量图。与现有基于深度学习的作物产量预测模型相比，CYPRESS展示了更好的性能，证明了基础模型可以通过微调来适用于特定的农业应用。", "conclusion": "CYPRESS提供了连续、高分辨率的输出，为精准农业提供了比传统的分类或县级汇总方法更为有效的工具。这项工作验证了一种新的方法，即在大规模地球观测和农田决策之间建立桥梁，提供了一个可扩展的解决方案，用于详细的农业监测。"}
{"llm_update_time": "20251101", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.26583", "html_url": "https://arxiv.org/abs/2510.26583", "title": "Emu3.5: 自然多模态模型是世界学习者", "title_en": "Emu3.5: Native Multimodal Models are World Learners", "authors": "Yufeng Cui,Honghao Chen,Haoge Deng,Xu Huang,Xinghang Li,Jirong Liu,Yang Liu,Zhuoyan Luo,Jinsheng Wang,Wenxuan Wang,Yueze Wang,Chengyuan Wang,Fan Zhang,Yingli Zhao,Ting Pan,Xianduo Li,Zecheng Hao,Wenxuan Ma,Zhuo Chen,Yulong Ao,Tiejun Huang,Zhongyuan Wang,Xinlong Wang", "background": "Emu3.5 是一个大规模的多模态世界模型，能够预测视觉和语言的下一状态。它在来自互联网视频的序列帧和转录文本的语料库上进行了端到端的预训练，包含超过10万亿个令牌。模型能够自然处理交错的视觉和语言输入，并生成交错的视觉和语言输出。", "innovation": "Emu3.5 通过端到端的统一下一个令牌预测目标预训练，进一步大规模利用增强学习进行后续训练，提升跨模态推理和生成能力。引入了离散扩散适应 (DiDA) 技术，将逐令牌解码转换为双向并行预测，将图像推理速度提升约20倍，同时保持性能不变。模型展示了强大的自然跨模态能力，包括长时视觉语言生成、任意到图像生成以及复杂的文本丰富图像生成。", "conclusion": "Emu3.5 在视觉生成和编辑任务上与 Gemini 2.5 Flash Image (Nano Banana) 的性能相当，并在一系列交错生成任务上表现出更优的结果。开源的 Emu3.5 将支持社区研究。"}
{"llm_update_time": "20251101", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.26568", "html_url": "https://arxiv.org/abs/2510.26568", "title": "SA$^{2}$Net: 基于超声体层投影成像的脊柱分割尺度自适应结构亲合变换", "title_en": "SA$^{2}$Net: Scale-Adaptive Structure-Affinity Transformation for Spine Segmentation from Ultrasound Volume Projection Imaging", "authors": "Hao Xie,Zixun Huang,Yushen Zuo,Yakun Ju,Frank H. F. Leung,N. F. Law,Kin-Man Lam,Yong-Ping Zheng,Sai Ho Ling", "background": "脊柱分割在临床智能侧凸诊断中起着重要作用，但这一任务面临挑战：脊柱的全局上下文知识在忽视不同骨特征的高空间相关性时可能无法学好；脊柱骨包含了丰富的结构知识，涉及形状和位置，这些应在分割过程中编码。现有方法在处理这些挑战方面存在不足。", "innovation": "提出了一种新型的尺度自适应结构感知网络（SA$^{2}$Net），采用尺度自适应互补策略学习跨维度的长距离相关特征；受Transformer中多个头自注意力机制与语义层面亲和一致性启发，提出结构亲合变换进行语义特征的类自亲和转化并结合Transformer解码器进行结构感知推理；采用特征混合损失聚合方法增强模型训练，提高分割过程的稳健性和准确性。实验结果表明，SA$^{2}$Net相比其他最先进的方法在分割性能上表现更优，并且SA$^{2}$Net对各种骨干网络的适应性增强了其作为先进脊柱图像智能分析的潜在工具。", "conclusion": "SA$^{2}$Net方法在脊柱分割方面实现了优越的性能，并且具备将多种骨干网络结合的能力，使其成为智能脊柱图像分析技术中一种有前景的工具。"}
{"llm_update_time": "20251101", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.26630", "html_url": "https://arxiv.org/abs/2510.26630", "title": "PT-DETR: Partially-Aware Detail Focus Based Small Target Detection", "title_en": "PT-DETR: Small Target Detection Based on Partially-Aware Detail Focus", "authors": "Bingcong Huo,Zhiming Wang", "background": "论文旨在解决无人机（UAV）目标检测中的挑战，例如复杂背景、严重遮挡、密集的小目标以及变化的光照条件。", "innovation": "基于RT-DETR提出了PT-DETR，这是一种专门针对无人机图像中小目标检测的新算法。引入了部分感知细节聚焦（PADF）模块，以增强对小目标的特征提取。还设计了中值频率特征融合（MFFF）模块，有效提高了模型捕捉小目标细节和上下文信息的能力。此外，引入了Focaler-SIoU，增强了模型的边界框匹配能力，提高了对小目标特征的敏感性，从而进一步提高了检测准确性和鲁棒性。", "conclusion": "与RT-DETR相比，PT-DETR在VisDrone2019数据集上的mAP提高了1.6%和1.7%，同时具有较低的计算复杂性和较少的参数，证明了其在小目标检测任务中的稳健性和可行性。"}
{"llm_update_time": "20251101", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.26580", "html_url": "https://arxiv.org/abs/2510.26580", "title": "在零样本真实世界场景中使用视觉-语言对齐的动态上下文感知场景推理", "title_en": "Dynamic Context-Aware Scene Reasoning Using Vision-Language Alignment in Zero-Shot Real-World Scenarios", "authors": "Manjunath Prasad Holenarasipura Rajiv,B. M. Vidyavathi", "background": "在现实环境中的AI系统往往面对的是未标记的数据和不熟悉的情况，这给传统的场景理解模型带来了巨大的挑战。在没有标签数据的情况下，模型很难泛化到未见过的情境中，从而限制了基于视觉的应用在动态和未结构化环境中的部署能力。这项工作提出了一种基于视觉-语言对齐的动态上下文感知场景推理框架，以应对零样本的真实世界场景。该框架旨在使智能系统能够在无需特定任务训练的情况下推断并适应新的环境。实验结果表明，该方法在复杂和未见过的环境中，比基线模型的场景理解准确性提高了18%，对于模糊或杂乱的场景，也表现出较强的鲁棒性。", "innovation": "提出了基于视觉-语言对齐的动态上下文感知场景推理框架。该框架利用预训练的视觉变换器和大规模语言模型来对齐视觉语义与自然语言描述，增强上下文理解。通过动态推理模块，该方法结合了全局场景线索和对象级别的交互，并通过语言先验进行引导，进一步精确化预测。这种方法为在动态真实世界设置中的上下文感知推理提供了一个可扩展和可解释的方法，推动了零样本泛化的发展。", "conclusion": "该框架在零样本基准测试中（如COCO、Visual Genome和Open Images）取得了显著的准确度提升，特别是在复杂和未见过的环境中的表现尤为突出。同时，该方法在模糊或杂乱的场景中也展现出较好的鲁棒性，证明了其在真实世界动态环境中的应用潜力。"}
{"llm_update_time": "20251101", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.26582", "html_url": "https://arxiv.org/abs/2510.26582", "title": "CATCH: 一种具有良好拓展性的跨域适应模板", "title_en": "CATCH: A Modular Cross-domain Adaptive Template with Hook", "authors": "Xinjin Li,Yulie Lu,Jinghan Cao,Yu Ma,Zhenglin Li,Yeyang Zhou", "background": "视觉问答(VQA)近期在自然图像领域的表现令人印象深刻，例如LLaVA等模型通过大型语言模型(Large Language Models, LLMs)实现了开放型推理。然而，在扩展到如遥感、医学影像或数学图表等跨域场景时，其泛化性能显著下降，这是由于分布变化较大和缺乏有效的跨域适应机制。现有方法通常依赖于针对每个领域进行微调或定制管道，这在成本、灵活性和可扩展性方面存在问题。", "innovation": "本文提出了一种插件式框架CATCH，能够在保持核心架构不变的情况下提高VQA模型的跨域适应性。主要创新点在于通过引入两个轻量级模块——领域分类器和双重适配器机制来分离视觉和语言的适配过程。一个用于确定输入图像类型，另一个包括一个提示适配器进行语言调整和一个视觉适配器进行视觉特征调整。所有模块通过统一的钩子接口动态注入，无需对骨干模型进行重新训练。结果，CATCH框架在四个特定领域的VQA基准测试中展示了在不重新训练骨干模型的情况下的一致性能提升，包括在MathVQA上的+2.3 BLEU，在MedVQA-RAD上的+2.6 VQA，在ChartQA上的+3.1 ROUGE。这些结果表明CATCH提供了多领域VQA的可扩展且可拓展的方法，能够广泛应用于各种应用领域", "conclusion": "本框架能够在不重新训练骨干模型的情况下，通过提升VQA模型的跨域适应性，实现一致的性能提升，展示了在不同应用领域中的实用性。"}
{"llm_update_time": "20251101", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.26641", "html_url": "https://arxiv.org/abs/2510.26641", "title": "从像素、点和提示到下一代融合和多模态LLMs/VLMs在自动驾驶中的目标检测所需的一切", "title_en": "All You Need for Object Detection: From Pixels, Points, and Prompts to Next-Gen Fusion and Multimodal LLMs/VLMs in Autonomous Vehicles", "authors": "Sayed Pedram Haeri Boroujeni,Niloufar Mehrabi,Hazim Alzorgan,Ahmad Sarlak,Mahlagha Fazeli,Abolfazl Razi", "background": "自动驾驶（AVs）通过智能感知、决策和控制系统的发展正在改变未来的交通方式，但其成功依赖于可靠地在复杂和多模态环境中进行物体检测的核心能力。尽管计算机视觉（CV）和人工智能（AI）领域取得了重大进展，但知识分散在多模态感知、上下文推理和协作智能方面，造成了一系列挑战。本文综述了AV中的物体检测，不仅回顾了摄像头、超声波、LiDAR和雷达等基本传感器及其融合策略的最新进展，而且通过结合大语言模型/视觉语言模型（LLMs/VLMs）驱动的感知框架探讨了它们的综合潜力，同时也涵盖了数据集的分类及最新检测方法，尤其是基于Transformer的方法，如视觉变换器（ViT）、小型和大型语言模型（SLMs）、VLMs等。这些视角的综合分析提供了当前能力、挑战和未来机会的清晰路线图", "innovation": "本文通过结合大语言模型/视觉语言模型（LLMs/VLMs）驱动的感知框架探讨了如何超越传统技术，重点介绍了视觉语言模型（VLMs）、大/小型语言模型（LLMs/SLMs）、生成人工智能等新兴范式。传统领域如视觉传感器融合策略和数据集分类得到了更新，并提供了多传感器融合的2D和3D管道分析。尤其是在基于Transformer的方法，利用视觉变换器（ViT）方面提出了新的见解", "conclusion": "本文提供了AV领域中物体检测的当前能力和未来机会的清晰路线图，强调了多模态感知框架对于解决复杂和多模态环境中可靠的物体检测的关键重要性。"}
{"llm_update_time": "20251101", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.26681", "html_url": "https://arxiv.org/abs/2510.26681", "title": "通过场景上下文改善遮挡物体的分类", "title_en": "Improving Classification of Occluded Objects through Scene Context", "authors": "Courtney M. King,Daniel D. Leeds,Damian Lyons,George Kalaitzis", "background": "遮挡的存在对传统的强大物体识别算法构成了重大挑战。额外的信息源可以极大地减少由遮挡引起的错误。已知场景上下文在生物视觉中有助于物体识别。因此，该研究旨在通过两种基于场景的信息融合技术，增强现有的Region Proposal Network-Deep Convolutional Neural Network (RPN-DCNN) 物体检测网络的鲁棒性。研究在包含部分遮挡的挑战性数据集上进行了实验，表明这些方法在召回率和精度方面都优于基线方法。", "innovation": "通过两种基于场景的信息融合技术（一种在预测之前根据识别背景场景选择定制的物体网络，另一种在检测之后将场景知识融合到初始物体分数中），增强现有的RPN-DCNN物体检测网络的鲁棒性。此外，研究还对比了多种遮挡处理训练方法，发现同时在被遮挡和未被遮挡的图像上进行训练的方法效果最好。", "conclusion": "该方法具有可解释性，便于适应其他数据集，并提供了许多未来研究和实际应用的方向。实验结果证明了该方法的有效性，表明在遮挡物体检测任务中，结合场景上下文可以显著提高检测性能。"}
{"llm_update_time": "20251101", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.26769", "html_url": "https://arxiv.org/abs/2510.26769", "title": "SteerVLM：通过轻量级激活引导实现视觉语言模型的稳健模型控制", "title_en": "SteerVLM: Robust Model Control through Lightweight Activation Steering for Vision Language Models", "authors": "Anushka Sivakumar,Andrew Zhang,Zaber Hakim,Chris Thomas", "background": "本文介绍了SteerVLM，一个轻量级的转向模块，其设计目的是引导视觉语言模型(Vision-Language Models, VLMs)产生更符合用户指定指令的输出。SteerVLM通过学习配对提示的潜在嵌入，动态调整语言模式与图像语境之间的激活连接，从而在不修改模型权重的情况下，实现复杂输出语义的细粒度控制，同时保持对非目标任务性能的影响最小。", "innovation": "SteerVLM使用轻量级的实现方式（学习参数量占原始VLM大小的0.14%），通过维度上的激活调节和各层的自适应引导，无需预先提取静态向量或手动调整干预点，实现了对VLMs的模型控制。此外，SteerVLM提出了VNIA数据集，专门用于开发和评估VLM转向技术。", "conclusion": "SteerVLM在VLM转向和幻觉缓解基准测试中性能优于现有技术，并提出了一种通过激活工程实现多模态模型控制的稳健解决方案。"}
{"llm_update_time": "20251101", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.26653", "html_url": "https://arxiv.org/abs/2510.26653", "title": "在RADARSAT-2上进行可靠的北极海冰漂移估计的深度学习光流方法", "title_en": "Towards Reliable Sea Ice Drift Estimation in the Arctic Deep Learning Optical Flow on RADARSAT-2", "authors": "Daniela Martin,Joseph Gallego", "background": "精确估计海冰漂移对北极航行、气候研究和运营预报至关重要。尽管计算机视觉技术中的光流技术取得了快速进展，但其在地球物理问题和卫星SAR影像中的应用仍待深入探索。经典光流方法依赖于数学模型和对运动的强假设，限制了其在复杂场景中的准确性。最近基于深度学习的方法已大幅提高性能，并成为计算机视觉的标准，因此推动了将其应用于海冰漂移估计的研究。", "innovation": "本文提供了针对SPARADAR 2扫描SAR海冰影像的大规模48种深度学习光流模型基准测试，通过对GNSS跟踪浮标的端点误差(EPE)和FLall指标进行评估。多模型实现了低于千米的精度（EPE 6到8像素，约300到400米）。研究证明，这些模型能够捕捉到一致的地区漂移模式，并且最近的基于深度学习的光流方法，在运动估计准确性方面显著优于经典方法，可以有效应用于极地遥感。深度学习光流产生的连续空间漂移场，提供了每个图像像素的运动估计，而不仅仅是少数浮标位置，为导航和气候建模提供了新机会。", "conclusion": "本文的结果表明，基于深度学习的光流方法能够有效应用于极地海冰漂移估计，能够提供连续的海冰漂移场，为导航和气候建模提供新的可能性。"}
{"llm_update_time": "20251101", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.26684", "html_url": "https://arxiv.org/abs/2510.26684", "title": "钢铁轧制厂内集成计算机视觉的实时故障预测", "title_en": "Process Integrated Computer Vision for Real-Time Failure Prediction in Steel Rolling Mill", "authors": "Vaibhav Kurrey,Sivakalyan Pujari,Gagan Raj Gupta", "background": "本文介绍了在钢铁轧制厂部署基于机器视觉的异常检测系统的长期研究。该系统通过工业摄像头实时监控设备运行、对齐和热棒运动，利用集中视频服务器上的深度学习模型处理实时视频流，能够提前预测设备故障和生产中断，从而减少非计划停机成本。", "innovation": "该系统通过集中式推理减少了对工业过程控制系统（PLC）的计算负载，支持在生产线上进行可扩展部署，同时无需额外资源。并且，通过联合分析数据采集系统和视觉输入的数据，该系统可以识别故障的位置和可能的根本原因，提供可采取行动的见解以进行主动维护。", "conclusion": "该集成方法增强了工业制造环境中的操作可靠性、生产率和盈利能力。"}
{"llm_update_time": "20251101", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.26778", "html_url": "https://arxiv.org/abs/2510.26778", "title": "通过精心选择U-Net架构和损失函数来超越RGB视网膜图像中AMD区域估算的最新水平", "title_en": "Surpassing state of the art on AMD area estimation from RGB fundus images through careful selection of U-Net architectures and loss functions for class imbalance", "authors": "Valentyna Starodub,Mantas Lukoševičius", "background": "年龄相关性黄斑变性（AMD）是导致60岁以上人群可逆视力受损的主要原因之一。本文旨在通过语义分割方法检测RGB视网膜图像中的AMD病变，这是一种非侵入性和成本效益高的成像技术。ADAM挑战作为基准，展示了迄今为止最全面的RGB视网膜图像中的AMD检测研究竞赛和开放数据集的结果。", "innovation": "本文以U-Net连接性为基础框架，评估和比较了多种提高分割模型架构和训练管道的方法，包括预处理技术、不同复杂度的编码器（骨干网），以及针对图像和像素层面类不平衡的专业损失函数。最终研究结果是，所提出的AMD检测框架在非侵入性RGB视网膜图像中的多类别分割上超过了之前的ADAM挑战的所有提交。", "conclusion": "本文最终配置的AMD检测框架，在ADAM挑战中对不同AMD病变类型的非侵入性RGB视网膜图像的多类别分割表现最佳。本文中进行的实验所使用的源代码将免费提供。"}
{"llm_update_time": "20251101", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.26694", "html_url": "https://arxiv.org/abs/2510.26694", "title": "3D高斯点刺技术的影响与展望", "title_en": "The Impact and Outlook of 3D Gaussian Splatting", "authors": "Bernhard Kerbl", "background": "自引入以来，3D高斯点刺(3DGS)技术迅速改变了3D场景表示的格局，激发了大量的相关研究。后续工作包括对3DGS效率、可扩展性和现实应用性的增强分析与贡献。本文对3DGS后出现的关键发展方向进行了综述，侧重于提高资源效率的训练和渲染、动态或四维(4DGS)表示的发展、以及其数学基础在外观建模和渲染过程中的更深层次探索。此外，本文还探讨了将3DGS引入移动和虚拟现实平台的努力、其扩展到大规模环境中的进展以及通过前馈或分布式计算实现近即时辐射场重建的最新进展。总之，这些发展表明3DGS已经从一种突破性的表示方法演变为3D视觉和图形领域的多功能和基础工具。", "innovation": "介绍了几种关键方向的发展，如资源效率的训练和渲染、动态或四维3D高斯点刺表达方式的进步、数学基础的深入探索，以及在移动和虚拟现实平台上的应用进展，特别是在大规模环境中的扩展，以及近即时辐射场重建的技术进步。", "conclusion": "3D高斯点刺技术已经从一种突破性的表示方法演变为3D视觉和图形领域的一种多功能和基础工具。它不仅提高了3D场景表示的效率和可扩展性，还开辟了新的应用领域，如移动和虚拟现实平台，以及大规模环境下的应用。此外，通过前馈或分布式计算实现近即时辐射场重建的技术也展示了3DGS的最新进展。"}
{"llm_update_time": "20251101", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.26786", "html_url": "https://arxiv.org/abs/2510.26786", "title": "HEIR: 学习基于图的运动层次结构", "title_en": "HEIR: Learning Graph-Based Motion Hierarchies", "authors": "Cheng Zheng,William Koch,Baiang Li,Felix Heide", "background": "在计算机视觉、图形学和机器人学等多个研究领域中，存在层次结构的运动，这些复杂的动态通常源自较简单运动组件的协调交互。现有的模型通常是通过手动定义或启发式方法来定义固定的运动子组件层次结构，这限制了它们在不同任务中的通用性。", "innovation": "本文提出了一种通用的运动层次结构建模方法，可以直接从数据中学习到结构化且可解释的运动关系。该方法使用基于图的层次结构来表示观测到的运动，明确地将全局绝对运动分解为父母遗传模式和局部运动残差。层次结构的推断被表述为一个可以微分学习的图问题，通过图神经网络捕捉学习到的父子依赖关系。该方法在1D平移运动、2D旋转运动和动态3D场景变形中进行了评估，实验结果表明在1D和2D情况下重建了内在的运动层级，并且在动态3D高斯点云变形中生成了更具现实感和可解释性的变形结果。", "conclusion": "通过提供一个适应性强且基于数据的层次结构建模范式，本文的方法适用于广泛的运动为中心的任务中。"}
{"llm_update_time": "20251101", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.26781", "html_url": "https://arxiv.org/abs/2510.26781", "title": "ChartAB: 用于图表对齐的标准库", "title_en": "ChartAB: A Benchmark for Chart Grounding & Dense Alignment", "authors": "Aniruddh Bansal,Davit Soselia,Dang Nguyen,Tianyi Zhou", "background": "图表在可视化、推理、数据分析和人与人之间交流思想中扮演重要角色。然而，现有的视觉-语言模型（VLMs）在细节感知方面依然不足，难以从图表中提取精细结构，这限制了它们进行图表间的比较和推理能力。本文旨在评估视觉-语言模型在图表对齐任务中的表现，包括从不同类型的复杂图表中提取表格数据、定位可视化元素以及识别各种属性。为此，作者提出了一项新的“图表对齐基准”（ChartAB），提供了一个包含全面评估标准的框架。该基准包括两个阶段的推理工作流，可以进一步评估模型在图表间对齐和对比元素/属性的能力。", "innovation": "本文提出了“ChartAlign Benchmark (ChartAB)”，为视觉-语言模型提供了一个综合评估图表对齐任务的标准。该基准不仅评估模型从多类型复杂图表中提取表格数据、定位可视化元素以及识别各种属性的能力，还通过引入一个创新的两阶段推理工作流，进一步评估模型在图表间对齐和对比元素/属性的能力。这有助于揭示各视觉-语言模型在图表理解任务中的感知偏见、弱点、鲁棒性和幻觉，并指出了当前模型需要加强的特定技能。", "conclusion": "通过对几个近期视觉-语言模型的评估，本文揭示了其在图表理解任务中的感知偏见、弱点、鲁棒性和幻觉，并展示了在图表对齐领域的新见解。这些发现强调了各视觉-语言模型在图表理解任务中的细微差别，并指出了需要改进的具体技能。"}
{"llm_update_time": "20251101", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.26794", "html_url": "https://arxiv.org/abs/2510.26794", "title": "追求可泛化的运动生成：数据、模型和评估", "title_en": "The Quest for Generalizable Motion Generation: Data, Model, and Evaluation", "authors": "Jing Lin,Ruisi Wang,Junzhe Lu,Ziqi Huang,Guorui Song,Ailing Zeng,Xian Liu,Chen Wei,Wanqi Yin,Qingping Sun,Zhongang Cai,Lei Yang,Ziwei Liu", "background": "尽管在标准基准上存在3D人类动作生成（MoGen）的最新进展，现有的模型仍然面临泛化能力的基本瓶颈。相比之下，相邻的生成领域，尤其是视频生成（ViGen），在建模人类行为方面表现出显著的泛化能力，这为MoGen提供了可借鉴的转移性见解。", "innovation": "论文提出了一个全面的框架，系统地将ViGen的知识转移到了MoGen的三个关键支柱：数据、建模和评估。具体来说包括：1) 引入了ViMoGen-228K数据集，包含228,000个高质量的运动样本，结合了高保真光学MoCap数据和网络视频及先进ViGen模型生成的语义标注样本；2) 提出了一种基于流匹配的扩散变换器（ViMoGen），通过门控多模态条件化统一MoCap数据和ViGen模型的先验知识；3) 进一步开发了ViMoGen-light，一个精简版本，去除了对视频生成的依赖，但仍保持了强大的泛化能力；4) 提出了MBench，一个多层级基准，用于作用质量、提示准确性和泛化能力的细粒度评估。", "conclusion": "大量实验表明，该框架在自动和人工评估中均显著优于现有方法。代码、数据和基准将公开提供。"}
{"llm_update_time": "20251101", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.26795", "html_url": "https://arxiv.org/abs/2510.26795", "title": "将图像地理位置缩放至大陆级别", "title_en": "Scaling Image Geo-Localization to Continent Level", "authors": "Philipp Lindenberger,Paul-Edouard Sarlin,Jan Hosang,Matteo Balice,Marc Pollefeys,Simon Lynen,Eduard Trulls", "background": "在全球范围内精确确定图像的位置仍然是一个未解决的挑战。标准的图像检索技术由于图像数量庞大（超过10000万）而效率低下，并且在覆盖不足时失效。可扩展的解决方案通常涉及折中：全球分类通常会产生粗糙的结果（10+公里），而地面和航空图像之间的跨视图检索存在领域差距，并且主要在较小的区域上进行研究。因此，本文提出了一种混合方法，可以在大陆这样广阔的地理范围内实现细粒度的地理定位。本文利用在训练中进行的代理分类任务来学习丰富的特征表示，这些特征表示隐式地编码了精确的位置信息。我们将这些学习到的原型与航空图像嵌入相结合，以增加对地面数据稀疏性的鲁棒性，从而可以在跨越多个国家的区域内直接进行细粒度检索。我们的全面评估表明，我们的方法可以超过68%的欧洲大部分地区的查询的精度达到200米以内。代码将在https://github.com/...公开。", "innovation": "本文提出了一种创新的混合方法，可以在广阔的地理范围内实现细粒度的地理位置定位。通过在训练期间使用代理分类任务学习到丰富的特征表示，这些表示隐式地包含了精确的位置信息。这些学习到的原型与航空图像的嵌入相结合，以提高对地面数据稀疏性的鲁棒性，从而可以实现跨越多个国家区域的直接、细粒度检索。", "conclusion": "本文的广泛评估表明，所提出的方法可以在大约200米的距离内精确识别欧洲大部分地区的查询超过68%。代码已公开发布。"}
{"llm_update_time": "20251101", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.26796", "html_url": "https://arxiv.org/abs/2510.26796", "title": "SEE4D：无姿态4D生成的自回归视频修复", "title_en": "SEE4D: Pose-Free 4D Generation via Auto-Regressive Video Inpainting", "authors": "Dongyue Lu,Ao Liang,Tianxin Huang,Xiao Fu,Yuyang Zhao,Baorui Ma,Liang Pan,Wei Yin,Lingdong Kong,Wei Tsang Ooi,Ziwei Liu", "background": "新兴的沉浸式应用程序需要从随意拍摄的视频中合成时空4D内容，而无需成本高昂的3D监督。现有的视频到4D的方法通常依赖于手动标注的摄像机位姿，这在自然场景片段中既费时又脆弱。最近的方法通过使用一个新颖的摄像机轨迹对输入帧进行变换，并使用填充模型来填补缺失区域，从而避开了对姿态标签的需要。然而，这种从轨迹到轨迹的表征往往会将摄像机运动和场景动态纠缠在一起，从而增加了建模和推理的复杂性。", "innovation": "本文提出了SEE4D，这是一种无需姿态、从轨迹到摄像机的框架，用渲染到一组固定虚拟摄像机来取代显式的轨迹预测，从而使摄像机控制与场景建模分离。该研究训练了一个视角条件视频填充模型，通过降噪实际合成的扭曲图像来学习稳健的几何先验，并填充虚拟视角中的遮挡或缺失区域，从而消除了对明确的3D注释的需要。在此填充核心的基础上，设计了一个时空自回归推理管道，通过虚拟摄像机样条和重叠窗口扩展视频，以实现逐步复杂性内的协调生成。", "conclusion": "最终，SEE4D在跨视图视频生成和稀疏重建基准上得到了验证。在定量指标和定性评价中，该方法在通用性和相对于基于姿态或轨迹条件的基线方法的性能上有优越的表现，促进了从随意视频中建模实际世界的进步。"}
{"llm_update_time": "20251101", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.26799", "html_url": "https://arxiv.org/abs/2510.26799", "title": "基于掩码扩散语言模型的视觉特征学习视觉说明生成", "title_en": "Masked Diffusion Captioning for Visual Feature Learning", "authors": "Chao Feng,Zihao Wei,Andrew Owens", "background": "传统的自动回归图像说明生成依赖于字词在序列中的位置，需要引入辅助目标来增强模型对视觉特征学习的能力。而本文采用的掩码扩散图像条件化说明模型（Masked Diffusion Captioning，MDC）则通过随机遮掩图像-说明对中的文本标记，训练基于视觉特征的解码器重建原始文本，在不需要关注字词位置的情况下，能够有效学习视觉特征。这种模型在跨多个学术规模的模型和数据集上的线性探测实验中表现出了与自动回归和对比度方法生成的视觉特征具有竞争力的性能。", "innovation": "本文提出了一种新的模型掩码扩散图片条件化说明模型（MDC），通过随机遮掩文本标记，训练基于视觉特征的解码器重建原始文本，从而在不需要关注字词位置的情况下，有效学习视觉特征。这种创新方法减少了对辅助目标的需求，提升了视觉特征学习的效果和效率。", "conclusion": "线性探测实验表明，MDC在跨多个学术规模的模型和数据集上能够生成具有竞争力的视觉特征，表明MDC在从图像到文本的生成任务中具有较好的泛化能力和有效性，同时也为视觉特征学习提供了一种新的思路。"}
{"llm_update_time": "20251101", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.26802", "html_url": "https://arxiv.org/abs/2510.26802", "title": "视频模型作为零样本推理者准备好了吗？基于MME-CoF基准的实证研究", "title_en": "Are Video Models Ready as Zero-Shot Reasoners? An Empirical Study with the MME-CoF Benchmark", "authors": "Ziyu Guo,Xinyan Chen,Renrui Zhang,Ruichuan An,Yu Qi,Dongzhi Jiang,Xiangtai Li,Manyuan Zhang,Hongsheng Li,Pheng-Ann Heng", "background": "近期的视频生成模型能够生成高质量、时序连贯的视频，显示出它们可能编码了大量的世界知识。这些模型不仅在现实合成方面表现出色，还表现出视觉感知、建模和操作的潜在行为。然而，仍存在一个重要问题：视频模型是否准备好在挑战性的视觉推理场景中作为零样本推理者发挥作用？", "innovation": "论文进行了一项实证研究，重点考察了领先的、流行的Veo-3模型，从12个维度（包括空间、几何、物理、时间和具身逻辑）系统地评估其推理行为，制定了标准化的评估数据集MME-CoF，该基准能够深入和全面地评估链帧推理（CoF推理）。研究结果揭示了当前视频模型在短时间尺度的空间一致性、细致的语义对应和局部一致的动力学方面表现出积极的推理模式，但在长时间尺度的因果推理、严格的几何约束和抽象逻辑方面仍然有限。", "conclusion": "当前的视频模型在短时间内具有可靠地零样本推理能力，但尚未达到独立零样本推理者的标准，但作为专用推理模型的补充视觉引擎显示出有希望的前景。"}
{"llm_update_time": "20251101", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.26022", "html_url": "https://arxiv.org/abs/2510.26022", "title": "基于物理引导的测试时间自适应的组间多参数心脏MRI配准", "title_en": "Groupwise Registration with Physics-Informed Test-Time Adaptation on Multi-parametric Cardiac MRI", "authors": "Xinqi Li,Yi Zhang,Li-Ting Huang,Hsiao-Huang Chang,Thoralf Niendorf,Min-Chi Ku,Qian Tao,Hsin-Jung Yang", "background": "多参数磁共振成像（MRI）已成为心肌组织表征的有效工具。然而，多参数图之间的对齐不准确使得像素级分析变得具有挑战性。", "innovation": "该研究开发了一个通用的基于物理的深度学习模型，通过测试时间自适应实现跨多种物理模型（如T1成像模型和T2成像模型）的组图像配准。该物理引导的自适应利用特定物理模型的合成图像作为配准参考，支持各种组织对比度的归纳学习。", "conclusion": "该模型在健康志愿者中经过多种MRI序列验证，显示了其在广泛图像对比度变化下多模态配准的改进效果。"}
{"llm_update_time": "20251101", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.25801", "html_url": "https://arxiv.org/abs/2510.25801", "title": "Metis-SPECS：通过自我蒸馏偏好导向冷启动解耦多模态学习", "title_en": "Metis-SPECS: Decoupling Multimodal Learning via Self-distilled Preference-based Cold Start", "authors": "Kun Chen,Peng Shi,Haibo Qiu,Zhixiong Zeng,Siqi Yang,Wenji Mao,Lin Ma", "background": "最近，可验证奖励的强化学习（RL）引发了‘MLLM-r1’的方法热潮，推动了RL在视觉语言模型中的应用。大多数代表性的方法在RL之前采取冷启动，通常使用监督微调（SFT）初始化策略。然而，SFT冷启动结合了解题逻辑与输出格式，可能导致指令风格的过拟合，削弱了分布外泛化能力，最终影响下游RL。论文作者重新审视了冷启动的训练方法与数据构建，并引入了Generalization Factor（泛化系数）来量化不同方法下的泛化能力。实验发现，基于偏好的训练方法（如DPO）在冷启动中表现更好。", "innovation": "论文提出了SPECS（Self-distilled, Preference-based Cold Start）框架，该框架通过自我蒸馏生成内部偏好数据对，避免依赖于更大的教师模型或手动标注；采用偏好导向训练聚焦于表面形式的浅层、可转移标准（格式、结构、风格），而非内容记忆；并将有验证的奖励转移给RL以生成深层次的推理结果。实验表明，SPECS框架在多种多模态基准测试中比强基线模型表现更好，实现了在MEGA-Bench上4.1%和MathVista上12.2%的性能提升。SPECS还降低了分布内停滞、提高了探索性、稳定了训练过程并提升了表现天花板。", "conclusion": "该研究提出并验证了SPECS框架在多模态学习领域的有效性。实验结果显示，该框架能持续提升多模态基准测试的性能，并且在多个领域中表现出改善探索、提高训练稳定性、增强泛化能力和提升最终性能的效果。"}
{"llm_update_time": "20251101", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.26800", "html_url": "https://arxiv.org/abs/2510.26800", "title": "OmniX：从统一全景生成和感知到图形级3D场景", "title_en": "OmniX: From Unified Panoramic Generation and Perception to Graphics-Ready 3D Scenes", "authors": "Yukun Huang,Jiwen Yu,Yanning Zhou,Jianan Wang,Xintao Wang,Pengfei Wan,Xihui Liu", "background": "传统的3D场景构建方法主要分为过程生成和2D提升。其中，基于全景的2D提升技术因其利用强大的2D生成先验知识，可以生成沉浸式、逼真和多样的3D环境而受到重视。本研究在此技术基础上进一步发展，旨在生成适合基于物理渲染（PBR）、重新光照和模拟的图形级3D场景。现有2D提升方法主要侧重于外观生成而忽略内在属性的感知，本研究推出了一个名为OmniX的框架，用于广泛范围的全景视觉任务，包括全景感知、生成和完成。为了支持这些功能，研究团队构建了一个大规模合成全景数据集，包含从多种室内和室外场景中提取的高质量多模态全景图。", "innovation": "OmniX是一种轻量高效的跨模态适配器结构，能够复用2D生成先验知识应用于全景感知、生成和完成任务上。与现有技术相比，OmniX不仅能够生成外观逼真的3D环境，还能感知内在属性。为了验证模型的有效性，研究团队构建了一个大规模合成全景数据集，并进行了大量实验，展示了OmniX在全景视觉感知和3D场景生成上的有效性。这为沉浸式、物理现实的虚拟世界生成提供了新的可能性。", "conclusion": "研究展示了OmniX框架在全景视觉感知和3D场景生成方面的有效性，其轻量高效的跨模态适配器结构能够复用2D生成先验知识处理多种全景任务。该研究为物理现实的虚拟世界生成开辟了新的可能，提高了全景生成与感知的实用性。"}
{"llm_update_time": "20251101", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.26141", "html_url": "https://arxiv.org/abs/2510.26141", "title": "StructLayoutFormer: 结构序列化和分离的条件结构布局生成", "title_en": "StructLayoutFormer:Conditional Structured Layout Generation via Structure Serialization and Disentanglement", "authors": "Xin Hu,Pengfei Xu,Jin Zhou,Hongbo Fu,Hui Huang", "background": "在许多2D视觉内容（例如GUI和网页）中，结构化的布局是优选的，因为结构信息允许方便的布局编辑。现有的计算框架能帮助创建结构化布局，但需要大量的劳动力输入。现有的数据驱动方法虽然能在自动创建固定布局时取得良好效果，但未能生成布局结构。", "innovation": "提出了一种基于Transformer的新颖方法StructLayoutFormer，用于条件结构布局生成。通过结构序列化方案将结构化布局表示为序列。通过分离结构信息和元素放置，使生成布局的结构控制更为准确。这是第一个通过数据驱动方法实现条件结构布局生成，并显式生成真实布局结构的方法。", "conclusion": "通过包含结构提取的后处理，将我们的方法与现有的数据驱动布局生成方法进行了比较，实验证明我们的方法在条件结构布局生成中优于这些基准方法。此外，还证明了我们的方法在提取和传输布局结构方面的有效性。代码已公开。"}
{"llm_update_time": "20251101", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.26038", "html_url": "https://arxiv.org/abs/2510.26038", "title": "Do Students Debias Like Teachers? On the Distillability of Bias Mitigation Methods", "title_en": "Do Students Debias Like Teachers? On the Distillability of Bias Mitigation Methods", "authors": "Jiali Cheng,Chirag Agarwal,Hadi Amiri", "background": "知识蒸馏（KD）是一种有效的模型压缩方法，能够将知识从教师模型转移到学生模型。然而，它对模型在对抗虚假相关性方面保持鲁棒性的效果尚未得到充分研究。虚假相关性会导致模型在未见过的数据上的性能下降。因此，本文研究了知识蒸馏对从教师模型到学生模型的“去偏见”能力的可转移性的影响，特别是在自然语言推理（NLI）和图像分类任务中。", "innovation": "本文通过广泛实验，发现了一系列关键发现：（i）总体而言，知识蒸馏后模型的去偏见能力受到削弱；（ii）训练去偏见模型时，不利用教师知识；（iii）虽然模型的整体鲁棒性可能在蒸馏后保持稳定，但它对不同类型偏见的鲁棒性可能会显著变化；（iv）进一步指出了造成蒸馏后不同行为的内部注意力模式和电路结构。基于上述发现，提出三种改进去偏见方法可转移性的有效解决方案：高质量数据增强，迭代知识蒸馏，以及使用教师模型权重初始化学生模型。", "conclusion": "这是首次大规模研究知识蒸馏对去偏见和其内部机制的影响。我们的研究结果提供了关于知识蒸馏工作原理以及如何设计更好的去偏见方法的理解。"}
{"llm_update_time": "20251101", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.26004", "html_url": "https://arxiv.org/abs/2510.26004", "title": "DARTS：一种基于无人机的AI驱动实时交通事件检测系统", "title_en": "DARTS: A Drone-Based AI-Powered Real-Time Traffic Incident Detection System", "authors": "Bai Li,Achilleas Kourtellis,Rong Cao,Joseph Post,Brian Porter,Yu Zhang", "background": "快速可靠的事件检测对于减少交通碰撞相关的死亡、受伤和拥堵至关重要。然而，传统的检测方法，如闭路电视、驾驶员相机录像和基于传感器的检测，存在逐步分离检测与验证、灵活性有限以及需要密集基础设施或高渗透率的问题，这限制了其适应性和扩展性，尤其是在变化的事件热点区域。", "innovation": "我们开发了DARTS，一种基于无人机的、AI驱动的实时交通事件检测系统。DARTS结合了无人机的高机动性和空中视角进行适应性监控，利用热成像以提高在低能见度下的表现和隐私保护，并采用了轻量级的深度学习框架实现实时车辆轨迹提取和事件检测。该系统在自收集的数据集上实现了99%的检测准确性，并通过基于网络的界面支持同时在线视觉验证、严重性评估和事件诱导的交通拥堵传播监测。在佛罗里达州的I-75高速公路实地测试中，DARTS比当地的运输管理中心提前12分钟检测并验证了一起追尾碰撞，并监测了由事件引发的交通拥堵传播，表明可能支持更快的应急响应并实现前瞻性交通控制，以减少拥堵和次要事故风险。此外，DARTS灵活的部署架构减少了频繁物理巡逻的依赖，表明其在偏远地区和资源受限环境中的潜在可扩展性和成本效益。", "conclusion": "本研究展示了一种更灵活和集成的实时交通事件检测系统的前景，对现代交通管理的运营效率和响应性具有重大影响。"}
{"llm_update_time": "20251101", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.26170", "html_url": "https://arxiv.org/abs/2510.26170", "title": "通过融合单目相机的全局和局部特征实现3D地图上的自我定位", "title_en": "Self-localization on a 3D map by fusing global and local features from a monocular camera", "authors": "Satoshi Kikuch,Masaya Kato,Tsuyoshi Tasaki", "background": "为了实现自动驾驶，需要通过廉价的单目相机在3D地图上实现自我定位。基于相机的自我定位通常使用卷积神经网络（CNN）来提取由附近像素计算出的局部特征，然而在存在动态障碍物（例如行人）的情况下，CNN的表现较差。", "innovation": "本文提出了一种新的方法，该方法结合使用CNN和Vision Transformer。Vision Transformer擅长提取全局特征，展示整个图像中补丁之间的关系。实验结果表明，在包含动态障碍物的CG数据集上，与最先进的方法相比，准确性提高了1.5倍；在公共数据集上，本文方法的自我定位误差比SOTA小20.1%。此外，使用本文方法的机器人在平均定位误差为7.51厘米。", "conclusion": "本文通过结合CNN和Vision Transformer，提高了单目相机在3D地图上自我定位的精度，并且在含有动态障碍物的数据集上取得了显著的改进效果。"}
{"llm_update_time": "20251101", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.26369", "html_url": "https://arxiv.org/abs/2510.26369", "title": "CorVS：基于视频轨迹-传感器对应的人在真实仓库中的识别", "title_en": "CorVS: Person Identification via Video Trajectory-Sensor Correspondence in a Real-World Warehouse", "authors": "Kazuma Kano,Yuki Mori,Shin Katayama,Kenta Urano,Takuro Yonezawa,Nobuo Kawaguchi", "background": "在工业场地中，工人位置数据对提高生产力至关重要。相机是物流仓库位置识别的一种有前途的工具，因为它们还能提供有关包裹状态等环境背景信息。然而，仅凭视觉数据识别个体往往 impractical。因此，先前的研究通过比较轨迹和可穿戴传感器测量结果来识别人们。这种方法的优点在于不依赖于外观，但在实际条件下可能会失效。", "innovation": "我们提出了一种名为CorVS的新型数据驱动的人识别方法，它基于视觉跟踪轨迹与传感器测量之间的对应关系。首先，我们的深度学习模型预测每个轨迹和传感器测量之间的对应概率和可靠性。其次，我们的算法使用预测的概率和可靠性来匹配轨迹和传感器测量。我们还建立了一个实际仓库操作的数据库，展示了该方法在实际应用中的有效性。", "conclusion": "本研究通过提出CorVS方法，成功克服了传统方法在现实世界条件下的局限性，为工业场地中人员识别的提高生产力提供了新的解决方案。"}
{"llm_update_time": "20251101", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.26390", "html_url": "https://arxiv.org/abs/2510.26390", "title": "SPG-CDENet: 基于空间先验的交叉双编码网络用于多器官分割", "title_en": "SPG-CDENet: Spatial Prior-Guided Cross Dual Encoder Network for Multi-Organ Segmentation", "authors": "Xizhi Tian,Changjun Zhou,Yulin. Yang", "background": "多器官分割是计算机辅助诊断的关键任务。尽管近年来深度学习方法在图像分割方面取得了显著成就，但由于器官大小和形状的巨大变化，这些方法在多器官分割中的效果受到挑战。", "innovation": "提出了一种新的基于空间先验的交叉双编码网络（SPG-CDENet），该网络采用两阶段分割方案，旨在提高多器官分割精度。该网络包括空间先验网络和交叉双编码网络。空间先验网络生成粗略的定位图，为双编码网络提供空间指导。交叉双编码网络包括全局编码器、局部编码器、对称交叉注意力模块和基于流的解码器。其中，全局编码器从整个图像中捕获全局语义特征，局部编码器关注先验网络的特征。对称交叉注意力模块在所有编码器层中促进和细化特征的融合。此外，基于流的解码器直接从最终编码器层传播高层语义特征到所有解码器层，最大化特征保留和利用。", "conclusion": "SPG-CDENet在两个公共数据集上的广泛定性和定量实验表明，其性能优于现有的分割方法。进一步的消融研究验证了所提议模块的有效性，以提高分割准确性。"}
{"llm_update_time": "20251101", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.26358", "html_url": "https://arxiv.org/abs/2510.26358", "title": "AgriGS-SLAM：基于多视图高斯点渲染的果园跨季节制图SLAM", "title_en": "AgriGS-SLAM: Orchard Mapping Across Seasons via Multi-View Gaussian Splatting SLAM", "authors": "Mirko Usuelli,David Rapado-Rincon,Gert Kootstra,Matteo Matteucci", "background": "自主机器人在果园中需要在重复的行几何结构、季节性外观变化和风造成的叶片运动下进行实时3D场景理解。现有技术尽管可以解决某些问题，但仍然面临挑战，尤其是在不同季节和地点的果园中维持稳定性和几何细节方面。为了解决这些问题，有必要开发一种强大的多模式感知框架，该框架能够在复杂和不断变化的环境中提供实时的3D场景重建。AgriGS-SLAM框架正是为此目的而设计的", "innovation": "AgriGS-SLAM框架结合了直接LiDAR里程计、循环闭合和具有多摄像头3D高斯点渲染的多视角批处理栅格化。通过统一的梯度驱动地图生命周期在关键帧之间执行，可以保留细节并限制内存。通过概率LiDAR深度一致性的引导优化姿态，进一步提高了几何与外观的耦合度。通过标准化的轨迹协议，该系统在不同果园季节和时期中部署，在保持实时表现的同时提供了更为清晰、稳定的效果，解决了现有技术的过拟合问题", "conclusion": "AgriGS-SLAM在不同季节和田间位置上提供了更加清晰和稳定的重建效果，并且保持了实时性能。这种方法不仅适用于果园监测，还可以应用于其他需要稳健多模式感知的户外领域"}
{"llm_update_time": "20251101", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.26661", "html_url": "https://arxiv.org/abs/2510.26661", "title": "BRIQA: 平衡加权在儿科脑部MRI图像质量评估中的应用", "title_en": "BRIQA: Balanced Reweighting in Image Quality Assessment of Pediatric Brain MRI", "authors": "Alya Almsouti,Ainur Khamitova,Darya Taratynova,Mohammad Yaqub", "background": "儿童脑部磁共振成像（MRI）中的伪像严重性评估对诊断准确性至关重要，特别是在低场系统中，信噪比较低。手动质量评估耗时且主观，因此需要稳健的自动化解决方案。本文探讨了BRIQA（Balanced Reweighting in Image Quality Assessment），以解决伪像严重性水平的类别不平衡问题。", "innovation": "BRIQA 使用基于梯度的损失加权来动态调整每类贡献，并采用旋转批量方案以确保对欠代表类的一致暴露，从而改善模型的平衡学习。研究表明，并非所有架构在所有伪像类型上表现最佳，强调了架构多样性的重要性。与其他技术结合时，旋转批量配置提高了多种度量指标上的性能。BRIQA 将平均宏 F1 分数从 0.659 提高到 0.706，并在噪声、咔嗒声、定位、对比度、运动和条纹伪像严重性分类中表现出显著的改进。", "conclusion": "BRIQA 在图像质量评估方面实现了更高的性能，特别是在处理各类伪像的分类任务上。通过开源，BRIQA 提供了一个强大的工具，可以改进儿科脑部 MRI 的伪像评估。"}
{"llm_update_time": "20251101", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.26635", "html_url": "https://arxiv.org/abs/2510.26635", "title": "SAMRI: Segment Anything Model for MRI", "title_en": "SAMRI: Segment Anything Model for MRI", "authors": "Zhao Wang,Wei Dai,Thuy Thanh Dao,Steffen Bollmann,Hongfu Sun,Craig Engstrom,Shekhar S. Chandra", "background": "准确的磁共振成像（MRI）分割对于临床决策至关重要，但手动进行时仍然劳动密集。基于卷积神经网络（CNN）的方法可以准确且高效，但往往难以适应MRI的变量对比度、强度不均匀和协议等特性。虽然基于变压器的Segment Anything Model (SAM) 在自然图像中展示了出色的泛化能力，但现有的适应方法通常将MRI视为另一种成像模态，忽略了模态特定的挑战。", "innovation": "我们提出了一种专门针对MRI的SAM模型（SAMRI），在110万标记的MRI切片（覆盖全身器官和病理）上进行了训练和验证。我们通过一个两阶段策略微调SAM的掩码解码器，减少了94%的训练时间和96%的可训练参数，相比重新训练整个模型。在不同的MRI分割任务中，SAMRI实现了平均Dice系数0.87，达到了 Across anatomical regions 的最先进的准确率，并在未见过的结构尤其是小且临床重要的结构上展示了强大的泛化能力", "conclusion": "SAMRI在多种MRI分割任务中取得了优异的性能，特别是在解剖区域和未见过的结构（特别是小且临床重要的结构）上展示了强大的泛化能力。"}
{"llm_update_time": "20251101", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.26759", "html_url": "https://arxiv.org/abs/2510.26759", "title": "MORE: 多器官医学成像重建数据集", "title_en": "MORE: Multi-Organ Medical Image REconstruction Dataset", "authors": "Shaokai Wu,Yapan Guo,Yanbiao Ji,Jing Tong,Yuxiang Lu,Mei Li,Suizhi Huang,Yue Ding,Hongtao Lu", "background": "当前的深度学习方法在医学成像特别是CT图像重建中通常局限于特定的解剖部位和数据集，这限制了它们在未见解剖结构和病变上的泛化能力。这对于不同器官的CT图像重建尤其具有挑战性。", "innovation": "介绍了Multi-Organ医疗图像重建（MORE）数据集，包含来自9种不同解剖部位的15种病变类型的CT扫描。该数据集旨在提供广泛的异质数据训练深度学习模型，并为CT重建模型的泛化能力提供严格的评估基准。建立了基于优化的方法，表现出对未见解剖结构的更强鲁棒性。", "conclusion": "综合数据集有助于提高模型的泛化能力，优化方法适用于未见解剖结构。MORE数据集免费可获取，地址见项目网页。"}
{"llm_update_time": "20251101", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.26782", "html_url": "https://arxiv.org/abs/2510.26782", "title": "使用几何正则化世界模型克隆确定性3D世界", "title_en": "Clone Deterministic 3D Worlds with Geometrically-Regularized World Models", "authors": "Zaishuo Xia,Yukuan Lu,Xinyi Li,Yifan Xu,Yubei Chen", "background": "世界模型是内部模型，用于模拟世界如何演变。它可以根据过去的观察和行动，预测物理代理和环境的未来。准确的世界模型对于使智能体在复杂的动态环境中思考、计划和有效推理至关重要。尽管取得了快速进展，但当前的世界模型在长时间尺度上仍然脆弱且容易退化。", "innovation": "提出了几何正则化世界模型（GRWM），要求沿自然感官轨迹的连续点在隐空间中保持接近。这种方法生成了明显改善的隐空间表示，与环境的真实拓扑结构高度一致。GRWM 具有模块化、仅需少量架构修改、可根据轨迹长度扩展以及与各种隐空间生成模块兼容的特点。", "conclusion": "研究结果表明，其优点来自于学习具有优越几何结构的隐流形。这表明提高表示学习是直接且有效的构建鲁棒世界模型的道路，无需扩大动力学模块即可实现可靠长时间预测。"}
{"llm_update_time": "20251101", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.26703", "html_url": "https://arxiv.org/abs/2510.26703", "title": "ProstNFound+: 使用医疗基础模型进行前列腺癌检测的前瞻性研究", "title_en": "ProstNFound+: A Prospective Study using Medical Foundation Models for Prostate Cancer Detection", "authors": "Paul F. R. Wilson,Mohamed Harmanani,Minh Nguyen Nhat To,Amoon Jamzad,Tarek Elghareb,Zhuoxin Guo,Adam Kinnaird,Brian Wodlinger,Purang Abolmaesumi,Parvin Mousavi", "background": "医疗基础模型（FMs）为构建高性能诊断系统提供了途径，但它们在微超声（{ν}US）图像中前列腺癌（PCa）检测的应用在临床环境中尚未得到测试。本文介绍了一个名为ProstNFound+的新模型，它是FM的一种适应性应用，用于PCa检测，同时给出了其在{ν}US中的首次前瞻性验证。", "innovation": "ProstNFound+结合了医疗基础模型、适配器调优和定制的提示编码器，后者嵌入了PCa特定的临床生物标志物。该模型能生成癌变热图和显著性PCa的风险评分。在多中心回顾性数据集上进行了训练后，模型在五年前从一个新临床站点获取的数据上进行了前瞻性评估。模型预测被基准测试了标准临床评分协议（PRI-MUS和PI-RADS）。该研究展示了ProstNFound+在前瞻性数据上的强大通用性，且性能未出现下降，同时与临床评分高度一致，且生成的热图与活检证实的病变一致。", "conclusion": "研究结果强调了该模型具有临床应用的潜力，提供了专家驱动的协议的一种可扩展和可解释的替代方案。"}
{"llm_update_time": "20251101", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2208.08083", "html_url": "https://arxiv.org/abs/2208.08083", "title": "两个头比一个更好：稳健学习遇见多分支模型", "title_en": "Two Heads are Better than One: Robust Learning Meets Multi-branch Models", "authors": "Zongyuan Zhang,Qingwen Bu,Tianyang Duan,Zheng Lin,Yuhao Qing,Zihan Fang,Heming Cui,Dong Huang", "background": "深度神经网络（DNNs）容易受到对抗性示例的影响，在这种情况下，DNNs会由于输入包含不可感知的扰动而被误导产生错误输出。对抗性训练作为一种可靠的和有效的方法，可以显著降低神经网络的脆弱性，已成为健学习的标准方法。尽管很多最近的工作强调数据为中心的方法，如如何生成更好的对抗性示例或使用生成模型生成额外训练数据，但这篇文章重新回到了模型本身，从深层特征分布的角度重新审视对抗性鲁棒性。", "innovation": "提出了Branch Orthogonality adveRsarial Training（BORT）来通过原始数据集实现对抗训练的最新性能。利用一个简单的多分支神经网络在不增加推理时间的情况下，超越了对抗性攻击。提出了分支正交损失函数，以确保多分支模型中的每个解决方案空间相互正交。实验表明，这种方法优于所有现有方法，在CIFAR-10和CIFAR-100上分别实现了67.3%和41.5%的鲁棒精度（相比最新方法分别提高了7.23%和9.07%）。此外，使用比本文更大的训练集规模的方法也没有我们的模型更出色。", "conclusion": "本文通过分支正交损失函数确保了多分支模型中每个解决方案空间的正交性，从而展示了BORT在CIFAR-10、CIFAR-100和SVHN上的优越性能，同时在没有任何额外数据的情况下实现了这一突破，展示了在对抗性鲁棒性方面的新思路。"}
{"llm_update_time": "20251101", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2311.07734", "html_url": "https://arxiv.org/abs/2311.07734", "title": "质量感知原型记忆在面部表示学习中的应用", "title_en": "Quality-Aware Prototype Memory for Face Representation Learning", "authors": "Evgeny Smirnov,Vasiliy Galyuk,Evgeny Lukyanets", "background": "原型记忆是一种强大的模型，用于面部表示学习。它能够通过即时生成原型（分类器权重）并高效利用它们，使得面部识别模型能够在任何大小的数据集上进行训练。原型记忆在许多面部识别基准测试中表现出色。然而，原型生成的算法在处理低质量和难以识别的面部图像时容易出现问题，这些图像可能用于原型创建。所有同一个人的图像在批次中都使用相同的权重，生成的平均原型可能会受到低质量面部图像不准确嵌入的污染，从而导致误导性的训练信号并降低训练模型的性能。", "innovation": "本文提出了一种简单且有效的方法来改进原型记忆，即质量感知原型记忆。质量感知原型记忆在原型生成过程中为不同质量的图像分配不同的权重。通过这种方式，原型能够从高质量图像中获得更具有信息性的信号，并且受到低质量图像的影响较小。本文还提出了几种质量估计和使用的不同方法，并在不同的面部识别基准测试上进行了广泛的实验，展示了所提出的模型相比于基本的原型记忆版本的优越性。", "conclusion": "研究结果表明，质量感知原型记忆能够提供更准确和更具代表性的原型，从而改进面部识别模型的性能。与基本的原型记忆版本相比，提出的模型能够更好地利用高质量样本，并减少低质量样本的负面影响，进而提高了面部识别的准确性。"}
{"llm_update_time": "20251101", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2401.13267", "html_url": "https://arxiv.org/abs/2401.13267", "title": "动态追溯学习在医学报告生成中的应用", "title_en": "Dynamic Traceback Learning for Medical Report Generation", "authors": "Shuchang Ye,Mingyuan Meng,Mingjian Li,Dagan Feng,Usman Naseem,Jinman Kim", "background": "自动化医学报告生成展示了显著减少耗时的医学报告工作负担的潜力。最近的生成表示学习方法在结合医学图像和文本模态的医学报告生成中显示出前景。然而，当端到端训练并直接应用于医学图像到文本生成时，它们面临两个重大挑战：一是难以准确捕捉细微但至关重要的病理细节；二是依赖图像和文本输入，在仅使用图像的零样本推理情况下性能下降。", "innovation": "本文提出了一个新颖的多模态动态追溯学习框架（DTrace）。特别地，我们引入了一个追溯机制来监督生成内容的语义有效性，并采用了一种动态学习策略来适应不同比例的图像和文本输入，使其能在推理过程中减少对两种模态输入的依赖。通过监督模型从互补对手中恢复被掩蔽的语义信息来增强跨模态知识的学习。在IUXray和MIMIC-CXR两个基准数据集上的广泛实验表明，所提出的DTrace框架在医学报告生成中优于现有最先进的方法。", "conclusion": "所提出的DTrace框架在两种基准数据集上的实验结果表明，在医学报告生成方面优于最先进的方法。"}
{"llm_update_time": "20251101", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.26573", "html_url": "https://arxiv.org/abs/2510.26573", "title": "比较分析用于橄榄树树冠和阴影分割的深度学习模型以实现生物体积估算", "title_en": "Comparative Analysis of Deep Learning Models for Olive Tree Crown and Shadow Segmentation Towards Biovolume Estimation", "authors": "Wondimagegn Abebe Demissie,Stefano Roccella,Rudy Rossetto,Antonio Minnocci,Andrea Vannini,Luca Sebastiani", "background": "在精准农业中，橄榄树生物体积的估算是一项关键任务，它支持产量预测和资源管理，特别是在由气候引起的压力严重影响的地中海地区。这项研究基于在意大利维科皮萨诺采集的超高分辨率无人机图像，对三种深度学习模型（U-Net、YOLOv11m-seg和Mask R-CNN）在分割橄榄树树冠及其阴影方面的性能进行了比较分析。", "innovation": "本研究采用了三种不同的深度学习模型（U-Net、YOLOv11m-seg和Mask R-CNN）来分割橄榄树树冠及其阴影，并通过结合树冠投影面积和阴影推导的高度来估算生物体积。研究强调了空间特征提取和稳健分割，并根据太阳能几何形状来估算单株树的生物体积。", "conclusion": "研究发现Mask R-CNN在总体准确度（F1 分数为0.86，mIoU为0.72）方面表现最好，而YOLOv11m-seg提供了最快的吞吐量（每张图像0.12秒）。估算的生物体积范围从大约4到24立方米，反映了树木之间明显的结构差异。因此，当生物体积精度至关重要时，建议使用Mask R-CNN；而在需要快速部署的广阔区域，则更适合使用YOLOv11m-seg。U-Net仍是一个轻量级、高灵敏度的选择。所提出的方法能够实现准确且可扩展的果园监测，并可通过DEM或DSM集成及现场校准进一步增强，以支持操作决策支持。"}
{"llm_update_time": "20251101", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2403.08788", "html_url": "https://arxiv.org/abs/2403.08788", "title": "VerifIoU - 对象检测对扰动的鲁棒性", "title_en": "VerifIoU - Robustness of Object Detection to Perturbations", "authors": "Noémie Cohen,Mélanie Ducoffe,Ryma Boumazouza,Christophe Gabreau,Claire Pagetti,Xavier Pucel,Audrey Galametz", "background": "本文介绍了一种新颖的区间边界传播（IBP）方法，用于形式化验证对象检测模型，特别是针对交并比（IoU）指标。该方法已在开源代码IBP IoU中实现，该代码与流行的抽象解释基线验证工具兼容。该验证器在着陆方法跑道检测和手写数字识别案例研究中进行了评估。", "innovation": "本文提出了一种新型的IBP方法，以便于形式化验证对象检测模型中的IoU指标。这种方法基于开源代码IBP IoU进行实现，并在多个领域展示了优于传统IBP方法的性能。", "conclusion": "与基线方法（普通IBP IoU）相比，IBP IoU方法在确保准确性和稳定性方面表现更优，从而推动了更安全和鲁棒的机器学习应用的发展。"}
{"llm_update_time": "20251101", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2409.06154", "html_url": "https://arxiv.org/abs/2409.06154", "title": "静态促进动态：利用静态表情数据对动态面部表情的更深层次理解", "title_en": "Static for Dynamic: Towards a Deeper Understanding of Dynamic Facial Expressions Using Static Expression Data", "authors": "Yin Chen,Jia Li,Yu Zhang,Zhenzhen Hu,Shiguang Shan,Meng Wang,Richang Hong", "background": "动态面部表情识别（DFER）能够从表情的时间演变中推断情绪，与仅依赖单个快照进行识别的静态面部表情识别（SFER）不同。DFER当前的方法因训练样本较少而表现不尽如人意。研究者发现静态和动态表情之间存在本征的相关性，由此提出利用丰富的SFER数据来改善DFER。", "innovation": "提出了一个统一的双模态学习框架——Static-for-Dynamic（S4D）。S4D利用一个共享的Vision Transformer（ViT）编码器-解码器架构的双模态自监督预训练对人脸图像和视频进行处理，产生改进的时空表示；通过混合适配器专家（MoAE）模块，在多任务学习框架下专门知识的获取成为可能并能有效提取静态和动态表情数据的共享知识。", "conclusion": "广泛实验证明S4D在FERV39K、MAFW和DFEW基准上取得了新的SOTA性能，权重平均召回率值分别为53.65%，58.44% 和76.68%。此外，还进行了静态与动态表情任务间的系统相关性分析，阐明了利用SFER数据的潜在优势。"}
{"llm_update_time": "20251101", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2406.15863", "html_url": "https://arxiv.org/abs/2406.15863", "title": "EmoAttack: 基于情感的图像扩散模型恶意后门生成", "title_en": "EmoAttack: Emotion-to-Image Diffusion Models for Emotional Backdoor Generation", "authors": "Tianyu Wei,Shanmin Pang,Qi Guo,Yizhuo Ma,Xiaofeng Cao,Qing Guo", "background": "文本到图像的扩散模型能够根据文本输入生成现实感强的图像，使得用户能够通过语言表达自己的观点。同时，在语言中，情感在表达个人观点方面起着关键作用。当前扩散模型的成功和情感的重要性凸显了其潜在的风险，即在文本中包含恶意负面内容，这可能会引导用户产生或加剧负面情感。因此，本文研究了文本到图像扩散模型未被重视的风险，即通过情感文本引入恶意负面内容，给用户带来不利情感的新型后门攻击。", "innovation": "本文识别了一种新的后门攻击，即情感意识后门攻击（EmoAttack），这种方法能够在图像生成过程中通过情感文本引入恶意负面内容。作者将这种攻击形式化为扩散模型个性化问题，并提出了EmoBooth方法。与现有的个性化方法不同，EmoBooth通过对预训练扩散模型进行微调，建立一系列情感词汇与包含恶意负面内容的参照图像之间的映射关系。为了验证方法的有效性，作者构建了一个数据集并进行了广泛分析和讨论。", "conclusion": "鉴于扩散模型的广泛应用，发现这种威胁对于社会来说至关重要。EmoBooth方法为防止情感负面内容的意外传播提供了一种有效的方法。"}
{"llm_update_time": "20251101", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2311.17434", "html_url": "https://arxiv.org/abs/2311.17434", "title": "GSE: 组稀疏且可解释的对抗性攻击", "title_en": "GSE: Group-wise Sparse and Explainable Adversarial Attacks", "authors": "Shpresim Sadiku,Moritz Wagner,Sebastian Pokutta", "background": "当前的稀疏对抗性攻击通过最小的像素扰动使深度神经网络（DNNs）失效，并常使用$l_0$范数进行正则化。最近的研究则使用基于组的核范数等结构稀疏正则化器，这使得生成的对抗性扰动具有可解释性，并揭示了DNNs的更大脆弱性。但这种方法在实际应用中存在优化难题，因为需要在非凸目标中计算像素组的范数。已有研究在生成组稀疏对抗性攻击时，还没有提供一种有效的两阶段算法来应对优化挑战。", "innovation": "本文提出了一种两阶段算法，旨在在图像的语义有意义区域生成组稀疏对抗性攻击。算法首先使用针对非凸编程特意设计的$1/2$-拟范数近邻算子优化拟范数对抗性损失，随后转换为应用$2$范数正则化来限制扰动幅度的投影Nesterov加速梯度下降法。该方法不仅显著提高了组稀疏性，还在CIFAR-10和ImageNet数据集上实现了更高的性能，具有更快的计算速度和更好的可解释性，并实现了100%的攻击成功率。", "conclusion": "本文提出的GSE（Group-wise Sparse and Explainable Adversarial Attacks）算法在组稀疏对抗性攻击方面取得了显著的突破，通过分阶段优化方法解决了非凸目标下的优化问题，从而提高了对抗性攻击的效果和可解释性，并且计算效率更高。"}
{"llm_update_time": "20251101", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2501.08325", "html_url": "https://arxiv.org/abs/2501.08325", "title": "GameFactory：利用生成性互动视频创作新游戏", "title_en": "GameFactory: Creating New Games with Generative Interactive Videos", "authors": "Jiwen Yu,Yiran Qin,Xintao Wang,Pengfei Wan,Di Zhang,Xihui Liu", "background": "生成视频有可能彻底改变游戏开发，通过自主创建新内容。GameFactory框架致力于通过动作控制场景泛化的游戏视频生成，解决了一系列关键挑战，如动作可控性、自回归生成以及场景泛化动作控制等，旨在生成多样且全新的游戏，超越固定风格和场景的限制.", "innovation": "1. 创建动作标注的游戏视频数据集GF-Minecraft，减轻了人力偏见。\n2. 发展动作控制模块，实现对键盘和鼠标输入的精确控制。\n3. 提出多阶段训练策略，使用领域适配器分离游戏风格学习与动作控制学习，实现场景泛化动作控制。\n4. 利用预训练视频扩散模型的开放域生成先验，桥接开放域先验和小规模游戏数据集之间的领域差距，生成多样化的新游戏视频.", "conclusion": "实验结果表明，GameFactory能够有效地生成开放域的动作可控游戏视频，标志着AI驱动的游戏生成的重要进展，有望极大提升游戏开发的效率与多样性."}
{"llm_update_time": "20251101", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2406.17345", "html_url": "https://arxiv.org/abs/2406.17345", "title": "NerfBaselines: 一致且可重现的新视角合成方法评估框架", "title_en": "NerfBaselines: Consistent and Reproducible Evaluation of Novel View Synthesis Methods", "authors": "Jonas Kulhanek,Torsten Sattler", "background": "新型视角合成是一个具有广泛应用前景的重要问题，包括AR/VR、游戏和机器人模拟等领域。近年来，随着神经辐射场（NeRF）和3D 高斯散点（3DGS）方法的快速发展，准确追踪当前最先进的技术变得越来越困难。由于各类方法采用不同的评估标准、代码库难以安装和使用以及方法在新颖3D场景下的适应性较差，使得量化比较变得复杂且具有误导性。基于实验结果，我们发现评估标准的微小差异可能会人为地提升这些方法的性能。这引发了对文献中进行的定量比较有效性的质疑。因此，我们提出了NerfBaselines，一个提供一致基准测试工具、确保可重现性和简化多种方法安装与使用的方法，以解决上述问题。", "innovation": "NerfBaselines 是一个评估框架，旨在提供一致的基准测试工具、确保可重现性和简化多种方法的使用与安装。通过实验验证，我们重新绘制了原始论文中的数据，并发布了一个网页平台，用于在标准基准上比较常用的方法，以提高可访问性。我们坚信NerfBaselines对社区的贡献是确保量化结果的可比性，以此真正衡量新视角合成领域的进展。", "conclusion": "NerfBaselines 是一个有价值的贡献，它确保了定量结果的可比性，从而可以真实衡量新视角合成领域的进展。"}
{"llm_update_time": "20251101", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2410.21004", "html_url": "https://arxiv.org/abs/2410.21004", "title": "一个连续且可解释的形态学度量，在动态生物形状稳健量化中的应用", "title_en": "A Continuous and Interpretable Morphometric for Robust Quantification of Dynamic Biological Shapes", "authors": "Roua Rouatbi,Juan-Esteban Suarez Cardona,Alba Villaronga-Luque,Jesse V. Veenvliet,Ivo F. Sbalzarini", "background": "在生物医学成像中，对于形状的量化分析一直是一个关键挑战。现有的方法往往在形态和拓扑性质的编码上不够紧凑，也不能很好地提供规律和可解释的特征以进行形状比较和机器学习任务。现有的方法也往往缺乏对时空动态的处理能力，无法将空间强度分布与形状动态融合，特别是在遗传标记等生物标记应用上有所欠缺。", "innovation": "本文提出了Push-Forward Signed Distance Morphometric (PF-SDM)，它可以紧凑地编码闭合形状的几何和拓扑属性，包括骨架和对称性，为形状比较和机器学习提供了稳健且可解释的特征。PF-SDM方法在数学上是平滑的，可以访问梯度和微分几何量，并且可以扩展到时间动态，与传统方法相比，它能够融合空间强度分布（例如遗传标记）与形状动态，与此同时保持了梯度计算的便利性。该方法还被应用于预测小鼠胃胚体轴的形成，并表现出在准确性和速度上的优越性，超越了CNN基线方法。", "conclusion": "本文通过对PF-SDM的理论介绍，基于合成数据进行基准测试并实际应用到预测小鼠胃胚体轴的形成实验中，证明了PF-SDM在形态学度量中具有连续性和可解释性，显示出在生物形状动态量化中的稳健性和高效性。"}
{"llm_update_time": "20251101", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2501.05783", "html_url": "https://arxiv.org/abs/2501.05783", "title": "UV-Attack: 物理世界中通过动态NeRF基UV映射对人类检测的对抗性攻击", "title_en": "UV-Attack: Physical-World Adversarial Attacks for Person Detection via Dynamic-NeRF-based UV Mapping", "authors": "Yanjie Li,Kaisheng Liang,Bin Xiao", "background": "近年来，针对使用补丁或静态3D模型纹理修改的人体检测器的对抗性攻击，成功率较低，原因在于人类动作的多变性。对由各种动作引起的3D变形建模成为主要挑战。然而，先进的神经辐射场（NeRF）技术为动态人体建模提供了新可能。本文总结了目前面临的挑战：尽管动态NeRF模型能够建模人体形态，但改变衣服纹理依然具有挑战性，因为它们嵌入到神经网络参数中。本文探讨了紫外线（UV）攻击的方法来解决这一问题。", "innovation": "本文提出UV-Attack，一种突破性的UV映射方法，可以在密集、未见过的动作和视角下实现高攻击成功率。该方法通过利用基于动态NeRF的UV映射生成不同动作和视角下的人体图像，甚至通过SMPL参数空间采样创造新的动作。同时，UV-Attack生成UV图而不是RGB图，并修改纹理堆栈，从而实现实时纹理编辑，提升了攻击的实用性。提出了一种新的期望姿态变换损失（EoPT），增强了对未见过的姿态和视角的攻击成功率。", "conclusion": "实验表明，UV-Attack在动态视频场景下，以92.7%的成功率对抗FastRCNN模型，显著优于最佳对抗性攻击方法AdvCamou的28.5%的成功率。在黑盒设置下，UV-Attack对最新YOLOv8检测器实现了49.5%的成功率。本文指出动态NeRF基UV映射技术在创建更有效的对抗性攻击方面的潜力，解决了建模人体运动和纹理修改的关键挑战。"}
{"llm_update_time": "20251101", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2412.20392", "html_url": "https://arxiv.org/abs/2412.20392", "title": "通过排斥视觉提示调优抵御多模态后门模型", "title_en": "Defending Multimodal Backdoored Models by Repulsive Visual Prompt Tuning", "authors": "Zhifang Zhang,Shuo He,Haobo Wang,Bingquan Shen,Lei Feng", "background": "多模态对比学习模型（例如CLIP）可以从大规模图像-文本数据集中学习高质量的表示，但在面对后门攻击时却表现出明显的脆弱性，这引发了严重的安全问题。研究表明，CLIP的脆弱性主要源于其倾向于编码超出数据集内预测模式的特征，这使这些编码特征容易被后门触发所重塑。因此，CLIP的视觉特性对手部扰动具有较低的抵抗性，使它更容易受到后门攻击的影响。", "innovation": "本文提出了一种新颖的防御方法——排斥视觉提示调优（RVPT），该方法通过精心设计的功能排斥损失来采用深层视觉提示调优。RVPT通过对抗性地排斥深层层中的编码特征，在优化标准交叉熵损失的同时，确保只有下游任务中的预测特征被编码。这种方法相较于现有的多模态后门防御方法而言，不需要中毒数据或重新训练整个模型，仅需调优少量参数即可实现高效防御。实验结果显示，RVPT仅需调整CLIP中0.27%的参数，但显著优于最先进的防御方法，将攻击成功率从89.70%降低到2.76%。此外，该方法还能够泛化到多个数据集中。", "conclusion": "通过排斥视觉提示调优，可以有效增强CLIP的视觉特征抵抗输入扰动的能力，并有效减轻其对后门攻击的脆弱性。该方法不仅能够应对最先进的多模态后门攻击，还具有良好的泛化能力和较低的参数调整需求。"}
{"llm_update_time": "20251101", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2411.10501", "html_url": "https://arxiv.org/abs/2411.10501", "title": "OnlyFlow：基于光流的视频扩散模型运动条件", "title_en": "OnlyFlow: Optical Flow based Motion Conditioning for Video Diffusion Models", "authors": "Mathis Koroglu,Hugo Caselles-Dupré,Guillaume Jeanneret Sanmiguel,Matthieu Cord", "background": "本文讨论了文字到视频生成任务中的精确控制问题，应用于多种场景，如摄像机运动控制和视频到视频编辑。大多数处理此类问题的方法依赖于提供用户定义的控制，如二值蒙版或摄像机运动嵌入。已有研究大多基于预定义的控制来进行视频生成和编辑。本文提出了一种新的方法OnlyFlow，利用从输入视频中提取的光流信息作为生成视频运动的基础条件。通过仅使用文本提示和输入视频，用户可以生成既符合输入视频运动，也符合文本提示的视频。这种方法的有效性通过定量、定性和用户偏好研究得到了验证，展示了在各种任务上，尽管OnlyFlow不是专门为此类任务训练的，但仍优于现有的先进技术。因此，OnlyFlow可以作为一种多用途、轻量且高效的运动控制方法应用于文本到视频的生成任务中，并且该模型和代码将通过GitHub和HuggingFace开源。", "innovation": "本研究创新性地提出了一种基于光流的运动条件方法OnlyFlow，能够实现文字至视频的精准控制生成，且通过使用光流预处理输入视频，使生成的视频既符合输入视频的运动特点，又遵循给定的文本提示。与已有方法相比，OnlyFlow提供了一种更灵活、轻量且高效的运动控制方式，特别适用于需要精确控制视频生成任务的应用场景。", "conclusion": "本文提出的方法OnlyFlow在多种任务上展示了优于现有方法的性能，即使不是专门为此类任务训练的。OnlyFlow提供了一种多用途、轻量且高效的控制生成视频运动的方法，使得用户可以根据输入视频和文本提示生成符合特定要求的视频。为了促进该技术的进一步发展，该方法的模型和源代码将开源提供给学术界和工业界使用。"}
{"llm_update_time": "20251101", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2503.09499", "html_url": "https://arxiv.org/abs/2503.09499", "title": "MindGYM：聚焦生成式问题合成在以思辨为导向的微调中关注什么？", "title_en": "MindGYM: What Matters in Question Synthesis for Thinking-Centric Fine-Tuning?", "authors": "Zhe Xu,Daoyuan Chen,Zhenqing Ling,Yaliang Li,Ying Shen", "background": "大型基础模型在进行监督训练时面临着难以获得可迁移、结构化思维能力的挑战，尤其是当使用严格模板或众包标注的指令数据集时。先前的方法多依赖于外在的数据生成或模板指导，但本文关注的是思维为中心的数据合成范式，该范式通过模型自我生成并基于认知指导的数据来促进其进化。", "innovation": "提出了MindGYM，这是一种结构化和可扩展的问题合成框架，包含三个部分：（1）认知思维过程注入，通过注入高层次的推理目标来塑造模型的合成行为；（2）种子单跳问题合成，从多种语义类型生成原子问题，以鼓励更广泛的思维；（3）具有挑战性的多跳QA合成，基于QA种子合成更复杂的多跳问题，以促进更深层次的推理。通过实验证明，由该方法生成的合成数据在质量平均提升了16.7%，质量变异度降低了67.91%，展示了高质量且自包含数据对于有效的、以思辨为导向的微调的重要性。MindGYM仅使用400条数据样本在MathVision基准上取得了高达16%的性能提升，并且跨不同规模和架构的模型有普遍的性能改进。MindGYM突出了自我挑战机制在改进大型模型能力方面的可行性，同时减少了人力干预和资源需求。", "conclusion": "MindGYM为从内部推理能力和自我进化驱动的数据中心研究中发展自适应基础模型提供了新途径，展示了自我挑战机制在保持高效并提高思辨能力方面的潜力。"}
{"llm_update_time": "20251101", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2412.15389", "html_url": "https://arxiv.org/abs/2412.15389", "title": "通过自我监督实现资源高效多染色肾小球分割", "title_en": "Resource Efficient Multi-stain Kidney Glomeruli Segmentation via Self-supervision", "authors": "Zeeshan Nisar,Friedrich Feuerhake,Thomas Lampert", "background": "在计算机视觉领域，领域偏移下语义分割仍然是一个基本挑战，特别是在缺乏标注训练数据的情况下。这一挑战在病理图像分析中尤为突出，同一组织结构在不同成像条件（染料）下捕获的图像中需要进行分割，每个染料代表一个独特的视觉领域。传统的深度学习方法，如UNet，需要大量标签，这既昂贵又耗时，尤其是在处理多个领域（或染料）时。为此，已经提出了多种无监督领域适应方法，如UDAGAN，这些方法通过只需要一个（源）染料的标注来减少对标签的需求。然而，获得源染料标签仍然具有挑战性。通过自我监督预训练，包括SimCLR、BYOL及一种新颖的方法HR-CS-CO，可以即使在拥有95%更少的标签下，这些分割方法（UNet和UDAGAN）的性能仍能保持。尤其是使用只有5%的标签进行自我监督预训练时，与完全监督方法（无预训练，使用100%标签）相比，性能下降仅为5.9%（UNet）和6.2%（UDAGAN）。此外，这些发现可以在公共基准数据集上泛化。实现和预训练模型已公开提供。", "innovation": "通过自我监督预训练（包括SimCLR、BYOL和一种新的方法HR-CS-CO），即使使用更少的标签，也能保持传统分割方法（UNet和UDAGAN）的性能。特别是，在仅有5%标注的情况下，性能下降的幅度显著减少，并在各种公共基准数据集上能泛化这些发现。", "conclusion": "通过自我监督预训练，即使在拥有更少的标签下，这些分割方法（UNet和UDAGAN）的性能仍能保持。尤其是，在仅有5%的标签下，与完全监督方法（无预训练，使用100%标签）相比，性能下降幅度显著减少，这些发现还可以在公共基准数据集上泛化。"}
{"llm_update_time": "20251101", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2503.04852", "html_url": "https://arxiv.org/abs/2503.04852", "title": "CAUSAL3D：视觉数据中因果学习的综合基准", "title_en": "CAUSAL3D: A Comprehensive Benchmark for Causal Learning from Visual Data", "authors": "Disheng Liu,Yiran Qiao,Wuche Liu,Yiren Lu,Yunlai Zhou,Tuo Liang,Yu Yin,Jing Ma", "background": "现有的AI和计算机视觉（CV）虽然取得了重大进展，但仍缺乏评估模型从复杂视觉数据中推断潜在线性关系能力的基准。真正的智能依赖于发现并利用隐含因果关系的能力。因此，亟需一个基准来评估模型的因果推理能力，特别是从复杂的视觉数据中推理潜在因果关系的能力。Causal3D引入了一种创新的方法，结合结构化数据（表格）和相应的视觉表示（图像），全面评估模型的因果推理能力。该基准包含19个3D场景数据集，涵盖了各种因果关系、视角和背景，以便在不同复杂程度的场景中进行全面评估。这种方法提供了一个结构化框架，展示了因果结构越复杂，缺乏先验知识的模型性能下降的趋势，突显了在复杂因果场景中高级模型面临的挑战性问题。", "innovation": "Causal3D是一个创新性的基准，首次将结构化数据（表格）与相应的视觉表示（图像）结合在一起，用于评估因果推理能力。它包括19个3D场景数据集，涵盖了不同类型的因果关系、视角和背景，在不同程度的复杂性场景中进行评估。这种方法强调了随着因果结构复杂性的增加，缺乏先验知识的模型性能下降的现象，展示了高级方法在复杂因果场景中的挑战性问题。Causal3D为推动计算机视觉中的因果推理和培养可信的人工智能在关键领域提供了宝贵的资源。", "conclusion": "Causal3D作为一种重要的资源，促进了计算机视觉中的因果推理，并推动了可信人工智能在关键领域的应用。未来的研究可以通过引入更多的先验知识来进一步完善这些模型，提高其在复杂因果场景中的表现。"}
{"llm_update_time": "20251101", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2503.11094", "html_url": "https://arxiv.org/abs/2503.11094", "title": "Open3D-VQA: 开放空间中全面的空间推理 multimodal 大语言模型基准", "title_en": "Open3D-VQA: A Benchmark for Comprehensive Spatial Reasoning with Multimodal Large Language Model in Open Space", "authors": "Weichen Zhang,Zile Zhou,Xin Zeng,Xuchen Liu,Jianjie Fang,Chen Gao,Yong Li,Jinqiang Cui,Xinlei Chen,Xiao-Ping Zhang", "background": "多模态大规模语言模型（MLLMs）在地理空间推理方面具有基本的能力，但它们在开放天空环境中的表现尚未充分探索。", "innovation": "提出了Open3D-VQA，一个新的基准，用于评估MLLMs在理解复杂空地空间关系方面的能力。这个基准包含了73,000个QA对，涵盖了7种一般的空间推理任务，支持视觉和点云两种模态，并且问题是从实际和模拟的空地场景中提取的空间关系自动生成。", "conclusion": "评估13种流行的MLLMs揭示了：1) 模型通常在回答相对空间关系的问题上表现更好，而不是绝对距离；2) 3D LLMs在空间表现上并没有明显优于2D LLMs；3) 仅在模拟数据集上进行微调可以显著提高模型在现实世界中的空间推理性能。该研究发布了基准、数据生成管道和评估工具包，以支持进一步的研究：this https URL."}
{"llm_update_time": "20251101", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2503.13160", "html_url": "https://arxiv.org/abs/2503.13160", "title": "基于弱监督和自然语言引导的开放世界视频异常检测", "title_en": "Language-guided Open-world Video Anomaly Detection under Weak Supervision", "authors": "Zihao Liu,Xiaoyu Wu,Jianqin Wu,Xuxu Wang,Linlin Yang", "background": "现有的视频异常检测（VAD）方法假定异常定义固定不变，因此在开放世界应用场景中不适用。开放世界的场景中，期望事件会随需求变化而变化，例如在流感爆发期间不戴口罩被视为异常，而在其他情况下则视为正常。这种不确定性使得现有的VAD方法难以应对开放世界环境下的变化需求。", "innovation": "提出了一种新型的开放世界VAD（Video Anomaly Detection）范式，允许在推理时通过用户提供的自然语言进行引导检测，并通过LaGoVAD模型实现这种范式，该模型在弱监督下动态适应异常定义。LaGoVAD通过两种正则化策略实现这一目标：一是通过动态视频合成增加异常相对持续时间的多样性；二是通过对比学习与负样本挖掘增强特征的鲁棒性。为了训练这种可适应的模型，需要多样化的异常定义，而现有数据集通常提供没有语义描述的标签。为此，研究者构建了PreVAD（预训练视频异常数据集），这是迄今为止最大且最具多样性的视频异常数据集，包含35,279个带有详细描述的标注视频，以明确定义异常。零样本实验在七个数据集上展示了LaGoVAD的当前最佳表现。该数据集和代码将在此网址发布：this https URL", "conclusion": "提出的LaGoVAD模型在开放世界的视频异常检测领域实现了当前最佳的性能，通过弱监督和自然语言引导实现了动态适应异常定义的特性，并通过两个正则化策略增强了模型的鲁棒性。"}
{"llm_update_time": "20251101", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2504.09549", "html_url": "https://arxiv.org/abs/2504.09549", "title": "SD-ReID: 视觉意识稳定的扩散模型用于空地身份再识别", "title_en": "SD-ReID: View-aware Stable Diffusion for Aerial-Ground Person Re-Identification", "authors": "Yuhao Wang,Xiang Hu,Lixin Wang,Pingping Zhang,Huchuan Lu", "background": "空地人员再识别（AG-ReID）旨在跨越不同视角的摄像头检索特定人员。以往的工作主要集中在设计具有判别性的模型，以维持身份在不同摄像头视角下的一致性。虽然这一核心思想很自然，但构建视点鲁棒模型是一项极具挑战性的任务。此外，这些方法忽视了视点特异性特征对于提升模型表示人员能力的贡献。", "innovation": "本文提出了一种新颖的生成模型框架SD-ReID，该框架利用生成模型模仿不同视角特征的分布同时提取鲁棒的身份表示。具体而言，首先训练一个基于ViT的模型来提取人员表示，同时还控制了身份和视角条件。然后，微调稳定扩散（SD）模型，根据这些可控制条件增强人员表示。此外，引入了视点校正解码器（VRD）以弥合实例级和全局级特征之间的差距。最后，结合人员表示和所有视角特征进行目标人员的检索。", "conclusion": "在五个AG-ReID基准数据集（即CARGO、AG-ReIDv1、AG-ReIDv2、LAGPeR和G2APS-ReID）上进行的大量实验表明，所提出的方法的有效性。源代码将可供获取。"}
{"llm_update_time": "20251101", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2503.23722", "html_url": "https://arxiv.org/abs/2503.23722", "title": "LATex: 利用属性为基础的文本知识进行航地人体重识别", "title_en": "LATex: Leveraging Attribute-based Text Knowledge for Aerial-Ground Person Re-Identification", "authors": "Pingping Zhang,Xiang Hu,Yuhao Wang,Huchuan Lu", "background": "在智能交通系统中，航地人体重识别（AG-ReID）是一项重要任务，旨在跨越不同视角的不同摄像头检索特定个人。以往的方法通常采用基于深度学习的模型，重点在于提取视角不变的特征，但这些方法通常忽略了人体属性中的语义信息。此外，现有的训练策略往往依赖于大规模模型的全量微调，这极大地增加了训练成本。为解决这些问题，本文提出了一个名为LATex的新型框架，采用提示微调策略利用属性为基础的文本知识来优化重识别效果。", "innovation": "本文提出了一个名为LATex的框架，采用了提示微调策略来利用属性为基础的文本知识。具体而言，通过对比语言-图像预训练模型CLIP，提出了一个具备属性感知的图像编码器（AIE）来从输入图像中提取全局语义特征和属性感知特征，接着提出一个带有提示的属性分类器组（PACG）来预测人体属性并获取属性表示，最后设计了一个耦合的提示模板（CPT）来将属性表示和视角信息转换为结构化的句子，这些句子通过CLIP的文本编码器生成更具辨别性的特征。因此，框架能够充分利用属性为基础的文本知识以提高AG-ReID性能。", "conclusion": "在三个AG-ReID基准上的广泛实验验证了所提出方法的有效性。源代码可在该网址获取。"}
{"llm_update_time": "20251101", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2505.00254", "html_url": "https://arxiv.org/abs/2505.00254", "title": "使用视频语言模型赋能自主视频分析系统", "title_en": "Empowering Agentic Video Analytics Systems with Video Language Models", "authors": "Yuxuan Yan,Shiqi Jiang,Ting Cao,Yifan Yang,Qianqian Yang,Yuanchao Shu,Yuqing Yang,Lili Qiu", "background": "AI驱动的视频分析在多个领域变得越来越重要。然而，现有的系统通常被限制在特定、预定义的任务中，使得它们在开放式的分析场景中表现出色能力有限。最近，视觉语言模型（VLMs）作为变革性技术的出现，为开放式的视频理解、推理和分析提供了巨大的潜力。但它们受限于较小的上下文窗口，这在处理大量实际应用场景中存在的超长视频内容时成为一个挑战。", "innovation": "该论文介绍了AVA，一个VLM驱动的系统，专门设计用于开放式和高级视频分析。AVA的主要创新点包括：（1）通过事件知识图谱（EKGs）对长或连续视频流进行高效索引的近实时构建；（2）使用EKGs的代理人检索生成机制，处理复杂的多样查询。", "conclusion": "在公共基准数据集LVBench和VideoMME-Long上的全面评估显示，AVA在性能上处于领先地位，分别达到62.3%和64.1%的准确率，显著超越现有的VLM和视频检索增强生成（RAG）系统。引入的新基准AVA-100由每段超过10小时的8个视频和120个手动标注的复杂问题答案对组成，AVA在AVA-100上达到了最佳性能，准确率为75.8%。"}
{"llm_update_time": "20251101", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2505.16239", "html_url": "https://arxiv.org/abs/2505.16239", "title": "DOVE：高效的单步扩散模型用于实际视频超分辨率", "title_en": "DOVE: Efficient One-Step Diffusion Model for Real-World Video Super-Resolution", "authors": "Zheng Chen,Zichen Zou,Kewei Zhang,Xiongfei Su,Xin Yuan,Yong Guo,Yulun Zhang", "background": "扩散模型在现实世界视频超分辨率（VSR）中表现出了令人鼓舞的效果。然而，它们需要大量的采样步骤，这使得推断过程非常缓慢。目前的技术中，特别是单步技术，可提供潜在解决方案，但实现单步VSR仍然充满挑战，主要是由于在视频数据上的高训练开销和对高保真度的严格要求。", "innovation": "我们提出了一种高效的单步扩散模型DOVE，通过微调预训练的视频扩散模型（即CogVideoX）获得。为了有效训练DOVE，我们引入了潜在像素训练策略。策略采用两阶段方案逐步适应模型到视频超分辨率任务，并设计了一个视频处理管线，构建了一个针对超分辨率任务的高质量数据集——HQ-VSR。通过在此数据集上进行微调，进一步增强了DOVE的重建能力。", "conclusion": "广泛的实验表明，DOVE在性能上与多步扩散基VSR方法相当或优于后者，并且提供了出色的推理效率，与其他现有方法（如MGLD-VSR）相比，速度提高了28倍。代码可在this https URL找到。"}
{"llm_update_time": "20251101", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2505.21996", "html_url": "https://arxiv.org/abs/2505.21996", "title": "学习用于交互视频生成的世界模型", "title_en": "Learning World Models for Interactive Video Generation", "authors": "Taiye Chen,Xun Hu,Zihan Ding,Chi Jin", "background": "现有的长视频生成模型具有有限的世界建模能力，主要受限于累积误差和缺乏足够的记忆机制。这使得在使用动作选择进行未来规划时，这些模型的效果受到限制。有效的世界模型需要具备交互性和保持时空一致性。", "innovation": "提出了视频检索增强生成（VRAG）方法，通过显式全局状态条件，显著减少了长期累积误差，提高了世界模型的时间空间一致性。该研究还揭示了自回归视频生成中无法消除的累积误差问题，以及现有模型在上下文学习能力上的不足。", "conclusion": "研究揭示了视频世界建模的基本挑战，并建立了一个全面的基准，以改进具有内在世界建模能力的视频生成模型。"}
{"llm_update_time": "20251101", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2505.18584", "html_url": "https://arxiv.org/abs/2505.18584", "title": "通过调节大规模激活来释放扩散变换器在视觉对应中的潜力", "title_en": "Unleashing Diffusion Transformers for Visual Correspondence by Modulating Massive Activations", "authors": "Chaofan Gan,Yuanpeng Tu,Xi Chen,Tieyuan Chen,Yuxi Li,Mehrtash Harandi,Weiyao Lin", "background": "预训练的稳定扩散模型（SD）在视觉对应方面取得了显著的进步。在本文中，我们研究了扩散变换器（DiTs）在准确密集对应方面的功能。与SD不同，DiTs表现出一种重要的现象，即非常少数的特征激活显示出显著更大的值，这被称为‘大规模激活’，导致DiTs的无信息表示和显著的性能下降。", "innovation": "我们发现这些集中在固定维度上的大规模激活可以有效地通过零初始化自适应层归一化（AdaLN-zero）进行本地化。在此基础上，我们提出了扩散变换器特征（DiTF），这是一种训练免费的框架，设计用于从DiTs中提取语义区分特征。迪TF使用AdaLN以通道级调制适应性地定位并归一化大规模激活。此外，我们还开发了一种通道丢弃策略，以进一步消除大规模激活的负面影响。", "conclusion": "我们的实验结果表明，DiTF在视觉对应任务中（例如，在Spair-71k上 +9.4％ 和 AP-10K-C.S.上 +4.4％）优于DINO和基于SD的模型，并为DiTs在不同视觉对应任务中建立了新的最佳性能。"}
{"llm_update_time": "20251101", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2505.21497", "html_url": "https://arxiv.org/abs/2505.21497", "title": "Paper2Poster：从科学论文转向多模态海报自动化", "title_en": "Paper2Poster: Towards Multimodal Poster Automation from Scientific Papers", "authors": "Wei Pang,Kevin Qinghong Lin,Xiangru Jian,Xi He,Philip Torr", "background": "学术海报的生成是科学研究交流中的一个重要但具有挑战性的任务，需要将长文本交错文档压缩到一个视觉上一致的页面。然而，目前缺乏专门针对海报生成的基准和评估指标。", "innovation": "本文首次提出了一个海报生成的基准套件，包括与作者设计的海报配对的最近会议论文，评估输出的视觉质量、文本一致性、整体评估以及PosterQuiz（衡量海报传达核心论文内容的能力）。同时，本文提出了一种自顶向下的、带有视觉在环的多智能体管道——Parser、Planner和Painter-Commenter循环，这种管道能够将22页论文高效地转化为易于编辑的.pptx海报，节省了大量计算资源。", "conclusion": "本文展示了完全自动化海报生成模型的发展方向，开源变体（例如基于Qwen-2.5系列）在几乎所有指标上均优于现有4o驱动的多智能体系统，使用87%少的标记。最终，这样的方法可以将一篇22页的论文转化为一个可编辑的.pptx海报，成本仅为0.005美元。这些发现指明了下一代表格生成模型的发展方向。相关代码和数据集可在[相关链接]找到。"}
{"llm_update_time": "20251101", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2505.18766", "html_url": "https://arxiv.org/abs/2505.18766", "title": "StyleGuard：通过样式扰动防止基于文本至图像模型的风格模仿攻击", "title_en": "StyleGuard: Preventing Text-to-Image-Model-based Style Mimicry Attacks by Style Perturbations", "authors": "Yanjie Li,Wenxuan Zhang,Xinqi Lyu,Yihao Liu,Bin Xiao", "background": "近年来，基于扩散模型的文字到图像的模仿技术在风格模仿和个性化定制方面得到了广泛应用，如DreamBooth和Textual Inversion。这引发了知识产权保护和生成欺骗性内容的担忧。最近的研究，如Glaze和Anti-DreamBooth，提出了使用对抗噪声来保护图像免受这些攻击的方法。然而，现有的去噪方法，如DiffPure和Noise Upscaling，已经成功地攻击了这些最新防御，揭示了这些方法的脆弱性。此外，现行方法在模型间的可迁移性能较差，使其对未知的文字到图像模型效果不佳。", "innovation": "本文提出了一种新颖的对抗模仿方法，StyleGuard。该方法提出了一种新颖的样式损失来优化潜空间中的样式相关特征，使其偏离原始图像，提高了模型无关的可迁移性。此外，为了增强扰动手段以绕过基于扩散的去噪，设计了一种新的放大损失，该损失在训练过程中结合了多个去噪器和放大器进行训练。广泛的实验表明，StyleGuard在各种变换和去噪下的鲁棒性优于现有方法，有效地对抗了各种模型中的风格模仿。此外，StyleGuard在不同的风格模仿方法（如DreamBooth和Textual Inversion）上都有效。", "conclusion": "实验结果表明，StyleGuard在多种图像数据集（如WikiArt和CelebA）上优于现有方法，在不同变换和净化方法下表现出更强的鲁棒性，并且能够有效地对抗各种模型中的风格模仿。StyleGuard的源代码可从提供的链接获取。"}
{"llm_update_time": "20251101", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2505.12191", "html_url": "https://arxiv.org/abs/2505.12191", "title": "摒弃去噪器：数据课程中自监督学习中噪声鲁棒性的涌现", "title_en": "Ditch the Denoiser: Emergence of Noise Robustness in Self-Supervised Learning from Data Curriculum", "authors": "Wenquan Lu,Jiaqi Zhang,Hugues Van Assel,Randall Balestriero", "background": "自监督学习（SSL）已成为从无标签数据中提取丰富表示的强大解决方案。然而，SSL研究主要集中在干净、精心整理和高质量的数据集上。因此，将其应用于嘈杂的数据仍然是一个挑战，尽管这对于天文学、医学成像、地球物理或金融等应用至关重要。目前，对于嘈杂数据的应用，SSL仍然面临挑战，需要预先去除噪声或在下游微调过程中去除噪声，这增加了实施的复杂性。因此，需要一种不需要在推断或下游微调过程中去除噪声的噪声鲁棒表示学习框架。", "innovation": "本文提出了一种完全自监督框架，允许在不依赖于推理或下游微调中的去噪器的情况下进行噪声鲁棒表示学习。方法首先在嘈杂数据上训练一个SSL去噪器，然后使用它构造一个去噪到嘈杂数据的课程（即，首先使用去噪数据，然后使用嘈杂数据训练SSL主干，例如DINOv2），并结合教师引导的正则化，将嘈杂表示锚定到其去噪对应物上。这种过程促使模型内化噪声鲁棒性。特别地，在不进行预训练后，可以丢弃去噪器，简化部署。在极端高斯噪声（$\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{σ}}}}}}}}}}}}}}}}}}}}}}$=255，SNR = 0.72 dB）的ImageNet-1k与ViT-B上，该方法将DINOv2的线性探测准确性提高了4.8%，表明噪声感知预训练可以产生无需去噪器的鲁棒性。", "conclusion": "该方法在不需要去噪器的情况下，通过噪声感知的预训练实现噪声鲁棒性，简化了部署流程，并在噪音数据上提高了自监督学习的性能。"}
{"llm_update_time": "20251101", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2506.02393", "html_url": "https://arxiv.org/abs/2506.02393", "title": "RRCANet: Recurrent Reusable-Convolution Attention Network for Infrared Small Target Detection", "title_en": "RRCANet: Recurrent Reusable-Convolution Attention Network for Infrared Small Target Detection", "authors": "Yongxian Liu,Boyang Li,Ting Liu,Zaiping Lin,Wei An", "background": "红外小目标检测是一个具有挑战性的任务，因为这些目标具有独特的特性（如小、暗、无规则形状和多变）。近期基于CNN的方法通过复杂的特征提取和融合模块取得了显著性能，但仍需要提高效率和效果。", "innovation": "提出了一种基于递归可重用卷积注意力网络（RRCA-Net），它通过递归方式整合了可重用卷积块（RuCB），在不引入额外参数的情况下提升了高层小目标信息的保持和细化能力；提出了双重交互注意力聚合模块（DIAAM）以促进细粒度信息的增益和融合；设计了一种目标特性引导的损失函数（DpT-k损失）结合物理和数学约束，以实现稳定的收敛。", "conclusion": "实验结果表明，RRCA-Net在多个基准数据集（如NUAA-SIRST、IRSTD-1k和DenseSIRST）上取得了可媲美最先进方法的性能，同时保持了少量参数的数量，并作为插件模块为多种流行方法带来了持续的性能提升。"}
{"llm_update_time": "20251101", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2506.00871", "html_url": "https://arxiv.org/abs/2506.00871", "title": "向基于上下文预测任意行人轨迹", "title_en": "Towards Predicting Any Human Trajectory In Context", "authors": "Ryo Fujii,Hideo Saito,Ryo Hachiuma", "background": "准确预测未来行人的轨迹对于自主系统至关重要，但在不同的环境和领域中实现这一目标却极具挑战性，因为需要在各种情境下表现出良好的适应性。传统方法通常需要为每个新的场景收集特定的数据，并进行微调，但对于边缘设备来说，这种微调往往不现实。因此，现有方法面临着在不进行微调的情况下实现适应性的挑战", "innovation": "本文提出了一种名为TrajICL的In-Context Learning (ICL)框架，该框架允许在推理时不依赖于场景特定的数据进行微调，从而实现无权重更新条件下的适应。文中引入了时空相似性为基础的实例选择（STES）方法和预测导向的例子选择（PG-ES）方法来改进实例的选择。同时，还使用大规模合成数据集进行训练，而不是局限于有限的内容多样性的真实世界数据集，从而提高模型的预测能力", "conclusion": "通过广泛的实验，TrajICL展示了其在同域和跨域情境中的出色适应性，其性能甚至超越了已微调的方法，展现出在多个公共基准上的卓越表现"}
{"llm_update_time": "20251101", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2505.23158", "html_url": "https://arxiv.org/abs/2505.23158", "title": "LODGES: 高效渲染的大规模尺度细节层次Gaussian点云渲染", "title_en": "LODGE: Level-of-Detail Large-Scale Gaussian Splatting with Efficient Rendering", "authors": "Jonas Kulhanek,Marie-Julie Rakotosaona,Fabian Manhardt,Christina Tsalicoglou,Michael Niemeyer,Torsten Sattler,Songyou Peng,Federico Tombari", "background": "本文提出了一种针对内存受限设备的大规模3D场景实时渲染的新颖层次细节（LOD）方法，特别适用于3D Gaussian Splatting。现有的Gaussian Splatting方法通常在高细节层次时占用大量的内存和计算资源，难以实时渲染大规模场景。本文通过层次化的LOD表示，结合深度感知的3D平滑滤波和基于重要性的剪枝以及微调，减少渲染时间和GPU内存使用。另外，通过分块场景并在渲染时动态加载相关Gaussian点，进一步减少内存开销，避免块边界处的视觉伪影，从而提升渲染性能和质量，同时减少延迟和内存要求。", "innovation": "本文的创新之处在于提出了一种新的层次细节LOD方法，通过分层次选择最优的Gaussian子集，并结合深度感知的3D平滑滤波和基于重要性的剪枝，以及分块场景动态加载相关Gaussian，显著减少渲染时间和内存开销。这是在大规模3D场景的实时渲染中的一项重要进展，特别是在户外和室内场景中取得了最先进的性能。", "conclusion": "通过采用本方法，本文实现了大规模场景的高保真渲染，同时大幅减少了延迟和内存需求，特别是在户外和室内场景数据集上达到了最先进的性能。"}
{"llm_update_time": "20251101", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2506.21046", "html_url": "https://arxiv.org/abs/2506.21046", "title": "利用自我监督视觉变换器功能提升生成对抗迁移性", "title_en": "Boosting Generative Adversarial Transferability with Self-supervised Vision Transformer Features", "authors": "Shangbo Wu,Yu-an Tan,Ruinan Ma,Wencong Ma,Dehua Zhu,Yuanzhang Li", "background": "深度神经网络（DNNs）的能力源于从提供的数据中提取和解释特征。通过利用DNNs中的中间特征而不是依赖硬标签，可以构造更有效的对抗扰动，提升黑盒迁移性。这些特征通常源自之前的监督学习。受自我监督学习与Transformer架构之间独特协同作用的启发，该论文探索是否可以利用自我监督的视觉变换器（ViT）表示来改善对抗迁移性。", "innovation": "本文提出了一种生成式双自我监督ViT特征攻击（dSVA），结合对比学习（CL）的全局结构特征和掩码图像建模（MIM）的局部纹理特征，构建了一个新的生成训练框架，通过利用自监督ViT的联合特征和注意力机制来训练生成器。研究发现，CL和MIM使ViT能够关注不同的特征倾向，当这两种方式相结合时，可以显著提升对抗的泛化能力。通过破坏自我监督ViTs提取的双深刻特征，实现了各种架构模型中前所未有的黑盒迁移性。", "conclusion": "我们的研究结果证明，通过利用CL和MIM中的自我监督ViT特征，能够显著提高模型的黑盒对抗迁移性，提升对抗扰动的泛化能力。已有代码可访问：this https URL."}
{"llm_update_time": "20251101", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2506.06220", "html_url": "https://arxiv.org/abs/2506.06220", "title": "GenIR: 用于心智图像检索的生成性视觉反馈", "title_en": "GenIR: Generative Visual Feedback for Mental Image Retrieval", "authors": "Diji Yang,Minghao Liu,Chung-Hsiang Lo,Yi Zhang,James Davis", "background": "视觉-语言模型（VLMs）在文本到图像检索基准测试中显示出强大的性能，但将这种成功应用到实际中仍然是一个挑战。在现实中，人类搜索行为通常是多轮次的，通过思维中的线索进行调整。因此，用户会根据逼真的心智图像，在图像搜索中进行多轮次互动，以精炼搜索结果。然而，现有的方法依赖于间接或抽象的文字反馈，这可能导致模糊、误导或无效的查询精炼。", "innovation": "本文提出GenIR，一个利用基于扩散的图像生成技术来生成多轮次检索的生成性多轮检索框架。通过这种方式，可以为用户提供明确和可操作的反馈，方便用户精炼查询。在此基础上，作者还建立了一个全自动的管道来生成高质量的多轮次心智图像检索数据集，使得GenIR在多轮次心智图像检索中显著优于现有方法。", "conclusion": "本文通过建立一个新的包含数据集的任务，提出了有效的生成检索方法，为未来在这个方向的研究提供了基础。实验结果表明，GenIR在多轮次心智图像检索中明显优于现有方法。"}
{"llm_update_time": "20251101", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2506.10173", "html_url": "https://arxiv.org/abs/2506.10173", "title": "SPARKE: 使用RKE分数在扩散模型中实现可扩展的提示感知多样性和新颖性指导", "title_en": "SPARKE: Scalable Prompt-Aware Diversity and Novelty Guidance in Diffusion Models via RKE Score", "authors": "Mohammad Jalali,Haoyu Lei,Amin Gohari,Farzan Farnia", "background": "扩散模型在高保真图像合成和提示引导生成建模方面展现了显著的成功。然而，在提示引导的扩散模型中，确保生成样本的多样性仍是一个挑战，尤其是在提示覆盖广泛语义范围时，需要以提示感知的方式评估生成数据的多样性。近年来，通过引入多样性度量来鼓励生成多样性，已经成为提高生成数据多样性的方法之一。然而，基于熵的多样性指导方法在大规模生成场景中依赖于基于矩阵的熵分数，这带来了计算上的挑战。因此，本文提出了SPARKE方法，通过使用条件熵进行多样性引导，并实现了提示感知的多样性控制。", "innovation": "本文提出了SPARKE方法，这是一种针对扩散模型的可扩展的提示感知多样性引导技术，通过使用条件熵来进行多样性指导，并且特别强调采用了对条件随机潜变量RKE分数的指导，这使得其计算复杂度从一般的$O(n^3)$降低至$O(n)$，从而能够对不同提示进行多样性和新颖性的引导采样。这种方法解决了以往基于熵的多样性引导方法在大规模生成场景中的计算挑战。", "conclusion": "本文对几个文本到图像的扩散模型进行了数值测试，证实了SPARKE方法在提高生成数据的提示感知多样性方面具有显著效果，同时没有显著增加计算成本。代码已经发布在项目页面：this https URL  。"}
{"llm_update_time": "20251101", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2506.05696", "html_url": "https://arxiv.org/abs/2506.05696", "title": "MoralCLIP: 依据道德基石理论调节视觉与语言表示的对比对齐", "title_en": "MoralCLIP: Contrastive Alignment of Vision-and-Language Representations with Moral Foundations Theory", "authors": "Ana Carolina Condez,Diogo Tavares,João Magalhães", "background": "近年来，视觉-语言模型的发展使得跨模态的丰富语义理解成为可能，但这些编码方法缺乏理解和推理内容道德维度的能力，这是人类认知的一个关键方面。本研究针对这一局限，引入了MoralCLIP，一种基于道德基石理论(MFT)进行显式道德定位的新型嵌入表示方法，扩展了多模态学习。这种技术将视觉和文本的道德线索整合进统一的嵌入空间，实现了跨模态的道德对齐。MoralCLIP基于多标签数据集Social-Moral图像数据库，来识别视觉内容中的并发道德基础，并设计了一种道德数据增强策略，将标注的数据集规模扩大到15,000幅带有MFT对齐维度的图像-文本对。研究结果表明，显式的道德监督不仅提升了单一模态和多模态对道德内容的理解能力，也为具备道德意识的人工智能系统提供了基础，这些系统能够识别和对齐人类的道德价值观。", "innovation": "引入了MoralCLIP，一种基于MFT进行显式道德定位的新型嵌入表示方法，创新地将视觉和文本道德线索整合进统一的嵌入空间，实现了跨模态的道德对齐。设计了道德数据增强策略，扩大了标注数据集规模，提高了模型在道德内容理解上的表现。", "conclusion": "MoralCLIP通过显式道德监督提高了单一模态和多模态对道德内容的理解能力，为开发具备道德意识的人工智能系统奠定了基础，能够识别并对齐人类的道德价值观。"}
{"llm_update_time": "20251101", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.08772", "html_url": "https://arxiv.org/abs/2507.08772", "title": "从单一到多元：3D生成中的上下文部分潜变量", "title_en": "From One to More: Contextual Part Latents for 3D Generation", "authors": "Shaocong Dong,Lihe Ding,Xiao Chen,Yaokun Li,Yuxin Wang,Yucheng Wang,Qi Wang,Jaehyeok Kim,Chenjian Gao,Zhanpeng Huang,Zibin Wang,Tianfan Xue,Dan Xu", "background": "最近3D生成的进步已经从多视角2D渲染方法转变为了利用真实数据几何先验的3D原生潜在扩散框架。尽管取得了进展，仍存在三个关键限制：（1）单一潜变量无法捕捉复杂多部件几何结构，导致细节退化；（2）整体潜变量编码忽略了设计组成时至关重要的部分独立性和相互关系；（3）全局条件机制缺乏细致的可控性。", "innovation": "我们受到了人类3D设计工作流程的启发，提出了CoPart - 一种意识部分的扩散框架，分解3D物体为上下文部分潜变量，以便于协同多部件生成。这一范式具有三个优势：（1）通过部分分解减少了编码复杂性；（2）可以使部分关系建模变得明确；（3）支持部分级条件。我们还开发了一种相互指导策略，用于微调预训练扩散模型以协同部分潜变量降噪，确保几何共性和基础模型先验的双重保障。为了实现大规模训练，我们创建了Partverse - 一个新型的3D部分数据集，通过自动化网格分割和人工验证注释从Objaverse派生而来。", "conclusion": "广泛的实验证明了CoPart在部分级编辑、有骨架物体生成和场景构成方面具有无与伦比的可控性。"}
{"llm_update_time": "20251101", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.01345", "html_url": "https://arxiv.org/abs/2508.01345", "title": "从随机槽-特征对预测视频槽注意查询", "title_en": "Predicting Video Slot Attention Queries from Random Slot-Feature Pairs", "authors": "Rongzhen Zhao,Jian Li,Juho Kannala,Joni Pajarinen", "background": "无监督视频对象中心学习（OCL）非常有前景，因为它可以像人类一样实现对象级别的场景表示和动力学建模。主流的视频OCL方法采用循环结构：聚合器将当前视频帧聚合为对象特征（称为槽），并通过某些查询；转换器将当前的槽转换到用于下一个帧的查询。这是一个有效的架构，但现有的所有实现都存在两个问题：一是忽视了下一帧特征（预测查询的信息来源），二是未能学习对查询预测至关重要的转换动态。", "innovation": "我们提出了Random Slot-Feature对预测查询（RandSF.Q）：1）设计了一个新的转换器，能够在预测查询时利用槽和特征的信息；2）通过随机采样可用重现过程中的槽-特征对来训练转换器，促使它学习转换动态。", "conclusion": "在场景表示上的实验表明，我们的方法在对象发现等方面显著优于现有视频OCL方法，如得分提高了10分，并达到了新的SOTA水平。这种优势也惠及下游任务如动力学建模。我们已提供核心源代码、模型检查点和训练日志供下载。"}
{"llm_update_time": "20251101", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.07981", "html_url": "https://arxiv.org/abs/2508.07981", "title": "Omni-Effects：统一和空间可控的视觉效果生成", "title_en": "Omni-Effects: Unified and Spatially-Controllable Visual Effects Generation", "authors": "Fangyuan Mao,Aiming Hao,Jintao Chen,Dongxia Liu,Xiaokun Feng,Jiashu Zhu,Meiqi Wu,Chubin Chen,Jiahong Wu,Xiangxiang Chu", "background": "视觉效果(VFX)对于现代电影制作至关重要。尽管视频生成模型为VFX生产提供了成本效益高的解决方案，但现有方法受限于单效果LoRA训练，这限制了多效果的同时生成和空间可控性。因此，需要一种能够整合不同效果并能进行空间控制的方法来解决这个问题。", "innovation": "提出了一种名为Omni-Effects的统一框架，该框架能够生成提示导向的效果和空间可控的复合效果。该框架的核心创新包括：(1) 基于LoRA的专家混合（LoRA-MoE），通过一组专家LoRA整合多种效果，同时有效消除任务间干扰；(2) 空间感知提示(SAP)，将空间掩码信息融入文本标记中，以实现精确的空间控制。此外，还引入了一个独立信息流(IIF)模块，隔离各个效果的控制信号，防止任何不必要的混合。", "conclusion": "广泛的实验表明，Omni-Effects能够实现精确的空间控制和多样化的效果生成，使用户能够指定所需效果的类别和位置。"}
{"llm_update_time": "20251101", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.06078", "html_url": "https://arxiv.org/abs/2507.06078", "title": "ScoreAdv：基于扩散模型的评分导向型生成自然对抗样本", "title_en": "ScoreAdv: Score-based Targeted Generation of Natural Adversarial Examples via Diffusion Models", "authors": "Chihan Huang,Hao Tang", "background": "尽管深度学习在多个领域取得了成功，但它仍然容易受到对抗攻击的影响。现有的许多对抗攻击方法在成功率方面表现良好，但它们通常依赖于$\boldsymbol{\text{ℓ}_p}$范数扰动约束，这并不符合人类的感知能力。因此，研究人员开始关注生成自然的、不受限制的对抗示例（UAEs）。虽然基于GAN的方法存在图像质量差和模式塌缩等固有问题，扩散模型也被用于生成UAEs，但这些方法仍然依赖于迭代的PGD扰动注入，未能充分利用其去噪的核心能力。", "innovation": "本文提出了一种基于扩散模型的新颖方法——ScoreAdv，用于生成自然的、不受限制的对抗示例。该方法结合了一个可解释的对抗性引导机制，逐步将采样分布转化为对抗分布，并使用可解释的显著性图将参考图像的视觉信息注入生成样本中。ScoreAdv 具备生成无限数量自然的对抗样本的能力，并能够攻击分类模型和检索模型。实验结果表明，ScoreAdv 在攻击成功率和图像质量方面达到了最先进的水平，同时保持了高效的推理效果。ScoreAdv 的动态平衡处理去噪和对抗性扰动的能力使其在防御措施下仍然具有鲁棒性", "conclusion": "ScoreAdv方法在图像网和超人气明星图像数据集上进行了广泛的实验，展示了其卓越的性能。该方法不仅攻击成功率和图像质量都达到了最先进的水平，还保持了高效的推理速度，并且能够对抗不同模型，在黑盒和白盒攻击设置中都表现出了良好的鲁棒性。"}
{"llm_update_time": "20251101", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.05417", "html_url": "https://arxiv.org/abs/2508.05417", "title": "平滑Slot注意力迭代和轮回", "title_en": "Smoothing Slot Attention Iterations and Recurrences", "authors": "Rongzhen Zhao,Wenyan Yang,Juho Kannala,Joni Pajarinen", "background": "Slot Attention (SA)及其变体是基于对象中心学习（OCL）的关键技术。图像中的对象可以通过迭代精细调整初始查询向量来聚合为各自的插槽向量。对于视频，这种聚合过程在时间帧之间是递归共享的，初始帧的查询向量会在非首帧中根据前一帧的插槽进行过渡。然而，首帧的初始查询向量缺乏样本特定的线索，妨碍了首帧的精确聚合；同时，非首帧的查询向量已经具有了样本特定的特性，需要与首帧聚合方式不同的转换。", "innovation": "本文介绍了名为SmoothSA的新方法，该方法首次解决了上述问题。它包括两个方面：(1)通过在OCL内部自学习一个小型模块来预热首帧的初始查询向量，使其包含丰富的输入特征信息，以平滑SA迭代过程中的首帧操作；(2)通过在非首帧和首帧之间使用完整的迭代与单一迭代来区分异质性转换，以平滑SA在所有视频帧之间的轮回过程。全面的实验验证了该方法的有效性，并进一步分析解释了该方法在迭代和平滑轮回中的工作原理。", "conclusion": "源代码、模型检查点和训练日志可在指定链接下载。"}
{"llm_update_time": "20251101", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.10566", "html_url": "https://arxiv.org/abs/2508.10566", "title": "HM-Talker：混合运动建模以实现高保真度的对话头部合成功能", "title_en": "HM-Talker: Hybrid Motion Modeling for High-Fidelity Talking Head Synthesis", "authors": "Shiyu Liu,Kui Jiang,Xianming Liu,Hongxun Yao,Xiaocheng Feng", "background": "在基于音频的头部动画生成中，当前的方法经常产生模糊运动和嘴唇抖动的现象，这是由于它们主要依赖于隐式的听觉-面部运动关联模型，而这种模型缺乏解剖学上的发音先验（即指导语音相关面部运动的结构信息）。因此，本文讨论了现有技术的局限性。", "innovation": "本文提出了HM-Talker，一个新型的高保真度、时序一致头部动画生成框架。HM-Talker利用结合隐式和显式运动线索的混合运动表示。具体来说，提出了交叉模态解缠模块（CMDM），该模块独立提取显式和隐式的运动特征，并直接从音频输入中预测动作单位（AUs）。此外，还引入了混合运动建模模块（HMMM），该模块动态合并随机配对的显式和隐式特征，以实现抽象的身份无关学习。这使得不同身份之间的唇同步更加稳健。", "conclusion": "大量的实验表明，HM-Talker在视觉质量和唇同步准确性方面优于最先进的方法。"}
{"llm_update_time": "20251101", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.06771", "html_url": "https://arxiv.org/abs/2509.06771", "title": "D-HUMOR: 通过多模态开放推理理解暗黑幽默 - 一个基准数据集和方法", "title_en": "D-HUMOR: Dark Humor Understanding via Multimodal Open-ended Reasoning - A Benchmark Dataset and Method", "authors": "Sai Kartheek Reddy Kasu,Mohammad Zia Ur Rehman,Shahid Shafi Dar,Rishi Bharat Junghare,Dhanvin Sanjay Namboodiri,Nagendra Kumar", "background": "在在线表情包中，暗黑幽默因其依赖于隐含、敏感和文化背景的提示而面临独特挑战。目前缺乏识别多模态内容中暗黑幽默的资源和方法。", "innovation": "提出了一个新颖的数据集，包含4379张带有暗黑幽默标注、目标类别（性别、心理健康、暴力、种族、残疾和其他）以及三层次强度评级（轻微、中等、严重）的Reddit表情包。在此基础上，提出了一个带有增强推理功能的框架，该框架首先使用大型视觉-语言模型（VLM）为每个表情包生成结构化解释，通过角色反转自我循环不断调整和优化解释，确保完整性和一致性。该框架还通过三流交叉推理网络（TCRNet）融合文本、图像和推理这三个流，实现了多模态幽默理解以及内容审核。", "conclusion": "这种方法在暗黑幽默检测、目标识别和强度预测三项任务中均优于强基线。数据集、注释和代码已发布，以促进多模态幽默理解及内容审核的进一步研究。相关代码和数据集可在以下链接获取：this https URL"}
{"llm_update_time": "20251101", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.04448", "html_url": "https://arxiv.org/abs/2509.04448", "title": "TRUST-VL: 一种解释性的一般多模态虚假信息检测助理", "title_en": "TRUST-VL: An Explainable News Assistant for General Multimodal Misinformation Detection", "authors": "Zehong Yan,Peng Qi,Wynne Hsu,Mong Li Lee", "background": "多模态虚假信息，包括文本、视觉以及跨模态的扭曲，正在成为一个日益严重的社会问题。现有的方法通常侧重于单一类型的扭曲，并且难以泛化到未见过的场景。现有技术存在的问题是，不同类型的扭曲虽然共享一些推理能力，但在具体任务上也需要特定的技能。这导致了传统方法在面对多种扭曲类型时的通用性较差。", "innovation": "本文提出了一种名为TRUST-VL的统一且可解释的多模态语言视觉模型，用以解决一般多模态虚假信息检测问题。TRUST-VL通过联合训练不同扭曲类型的方式，促进了知识共享，并提高了模型的泛化能力。此外，为了支持训练，作者还构建了一个名为TRUST-Instruct的大规模指令数据集，包含198,000个样本，这些样本与人类事实核查工作流程中的结构化推理链对齐。", "conclusion": "在领域内和零样本基准上的广泛实验显示，TRUST-VL 在性能上达到了最先进的水平，同时具备强大的泛化能力和可解释性。这表明该模型对于多模态虚假信息检测具有重要意义，能够更好地理解和解释其推理过程。"}
{"llm_update_time": "20251101", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.24267", "html_url": "https://arxiv.org/abs/2509.24267", "title": "Cycle Diffusion Model for Counterfactual Image Generation", "title_en": "Cycle Diffusion Model for Counterfactual Image Generation", "authors": "Fangrui Huang,Alan Wang,Binxu Li,Bailey Trang,Ridvan Yesiloglu,Tianyu Hua,Wei Peng,Ehsan Adeli", "background": "深度生成模型在医学图像合成方面取得了显著的成功。然而，确保直接生成和对抗生成的合成图像具备条件一致性和高质量仍然是一个挑战。这项工作中，我们提出了一个周期性训练框架，以微调扩散模型，从而提高生成器对条件的遵守度并增强合成图像的真实感。", "innovation": "我们提出了一种周期性扩散模型（Cycle Diffusion Model，CDM），通过引入循环约束确保生成图像和原始图像之间的一致性，从而实现更可靠的直接生成和对抗生成。实验表明，与基线方法相比，我们的方法能提高条件准确性并改善图像质量。", "conclusion": "CDM中使用的循环策略是基于扩散模型的医学图像生成中的一个有效改进方法，可以在数据扩增、对抗生成和疾病进展建模等方面找到应用。"}
{"llm_update_time": "20251101", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2506.23292", "html_url": "https://arxiv.org/abs/2506.23292", "title": "DDL: 复杂现实场景中用于深度假信息检测与定位的大规模数据集", "title_en": "DDL: A Large-Scale Datasets for Deepfake Detection and Localization in Diversified Real-World Scenarios", "authors": "Changtao Miao,Yi Zhang,Weize Gao,Zhiya Tan,Weiwei Feng,Man Luo,Jianshu Li,Ajian Liu,Yunfeng Diao,Qi Chu,Tao Gong,Zhe Li,Weibin Yao,Joey Tianyi Zhou", "background": "近年来，AIGC的进展加剧了恶意深度造假内容的滥用问题，使得开发可靠的安全检测方法变得至关重要。尽管现有的深度造假检测模型在检测指标上表现出色，但大多数方法仅提供简单的二分类结果，缺乏可解释性。最近的研究尝试通过提供空间操作遮罩或时间伪造片段来增强分类结果的可解释性。然而，由于伪造数据集的限制，这些方法的实际效果尚不理想。现有大多数深度造假数据集仅包含二元标签，缺乏多样化的伪造场景、较多的数据类型和足够的数据规模，难以应对复杂的现实情况。因此，开发一种更为全面和大规模的检测与定位数据集，对于开发新一代的深度造假检测、定位和可解释性方法至关重要。", "innovation": "本文构建了一个名为DDL的新颖大规模数据集，包含超过1.4M的伪造样本和多达80种不同的伪造方法。该数据集主要创新点包括：1）全面的伪造方法，2）多样化的操作模式，3）多样的伪造场景与模态，4）精细的伪造标注，提供了1.18M+精确的空间遮罩和23W+精确的时间片段。这些改进不仅提供了更具有挑战性的基准测试，还为构建新一代深度造假检测、定位和可解释性方法提供了关键支持。", "conclusion": "通过这些改进，DDL数据集不仅为复杂现实世界的伪造挑战提供了更具有挑战性的基准测试，还为新一代的深度造假检测、定位和可解释性方法提供了重要的支持。"}
{"llm_update_time": "20251101", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.09672", "html_url": "https://arxiv.org/abs/2509.09672", "title": "图像扩散模型中的局部性来自数据统计", "title_en": "Locality in Image Diffusion Models Emerges from Data Statistics", "authors": "Artem Lukoianov,Chenyang Yuan,Justin Solomon,Vincent Sitzmann", "background": "近期的研究表明，图像扩散模型的一般化能力源自训练神经网络的局部性质。特别是在去噪声像素时，模型依赖于输入图像周围有限的局部区域，这一点与产生新颖图像的能力密切相关。由于局部性质对一般化至关重要，需要理解扩散模型为何会首先学习局部行为，以及控制局部模式属性的因素。", "innovation": "本文提供了证据表明，深度扩散模型中的局部性是一种统计属性，而不是前人认为的卷积神经网络的归纳偏置所导致的。特别地，本文展示了最优的参数线性去噪器与深度神经去噪器具有类似的局部性属性。理论和实验数据显示，这种局部性直接来源于图像数据集中的像素相关性。此外，局部模式在专业化数据集上差异显著，近似于数据协方差的主成分。", "conclusion": "通过这些见解，本文设计了一种分析性去噪器，其预测评分比以前的手工制作去噪器更符合深度扩散模型的预测。我们得出的主要结论是，虽然神经网络架构影响生成质量，但其主要作用是捕捉数据固有的局部模式。"}
{"llm_update_time": "20251101", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.23885", "html_url": "https://arxiv.org/abs/2509.23885", "title": "Tunable-Generalization Diffusion Powered by Self-Supervised Contextual Sub-Data for Low-Dose CT Reconstruction", "title_en": "Tunable-Generalization Diffusion Powered by Self-Supervised Contextual Sub-Data for Low-Dose CT Reconstruction", "authors": "Guoquan Wei,Liu Shi,Zekun Zhou,Wenzhe Shan,Qiegen Liu", "background": "当前基于深度学习的低剂量CT去噪模型高度依赖配对数据，并且泛化能力较差。即使更加注重的扩散模型也需学习干净数据的分布来进行重建，但在医学临床应用中难以满足。此外，基于自监督的方法面临着模型从当前剂量预训练后向其他剂量推广时泛化能力显著下降的挑战。", "innovation": "本文提出了一种名为Tunable-Generalization Diffusion (TurnDiff) 的新颖方法，该方法利用自监督的方法，基于上下文子数据进行低剂量CT重建。该方法设计了一种上下文子数据自增强相似性策略，用作去噪的初始先验，结合知识拆解与深层潜藏扩散模型优化图像细节。同时提出像素级别自纠正融合技术，进行图像域精细重构，增强图像保真度，并使用这种上下文初始先验和低剂量CT图像作为指导。因此，该方法可以灵活应用于高剂量和低剂量甚至看不见剂量的应用推广。", "conclusion": "双重域策略级联的自监督低剂量CT去噪，TurnDiff仅需低剂量CT投影域数据进行训练和测试。在基准数据集和真实数据上的全面评估表明，TurnDiff在重建和推广方面均优于现有的最新方法。"}
{"llm_update_time": "20251101", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.14431", "html_url": "https://arxiv.org/abs/2510.14431", "title": "实时统一内间编码的神经视频压缩", "title_en": "Real-Time Neural Video Compression with Unified Intra and Inter Coding", "authors": "Hui Xiang,Yifan Bian,Li Li,Jingran Wu,Xianguo Zhang,Dong Liu", "background": "近年来，神经视频压缩（NVC）技术取得了快速的进步，产生了诸如DCVC-RT等最先进的方案，这些方案在压缩效率和实时编码/解码能力方面优于H.266/VVC。然而，现有的NVC方案在处理遮挡和新内容、帧间错误传播和累积等方面仍存在一些局限性。", "innovation": "本文借鉴经典视频编码方案中帧内编码的概念，引入了一种统一的帧内和帧间编码框架，其中每帧由一个模型处理，该模型经过训练可以自适应地进行帧内/帧间编码，并提出了一种同时进行两帧压缩的设计，以双向利用帧间冗余性。", "conclusion": "实验结果显示，本方案通过降低平均12.1%的BD率，实现了更稳定的数据传输速率和更优的每帧质量和实时编码/解码性能，同时发布了相关代码和模型。"}
{"llm_update_time": "20251101", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.08186", "html_url": "https://arxiv.org/abs/2508.08186", "title": "KARMA: 通过柯尔莫哥洛夫-阿诺德表示学习实现高效的结构缺陷分割", "title_en": "KARMA: Efficient Structural Defect Segmentation via Kolmogorov-Arnold Representation Learning", "authors": "Md Meftahul Ferdaus,Mahdi Abdelguerfi,Elias Ioup,Steven Sloan,Kendall N. Niles,Ken Pathak", "background": "由于结构缺陷多样、成像条件恶劣以及类别不平衡问题，基础设施中的语义分割仍具有挑战性。当前的深度学习方法虽然有效，但通常需要数百万个参数，这使得它们不适合用于实时检测系统。", "innovation": "KARMA (Kolmogorov-Arnold Representation Mapping Architecture) 是一种高效的语义分割框架，通过一维函数的合成来建模复杂的缺陷模式，而不是传统的卷积。其三大创新点包括：（1）高效的小型柯尔莫哥洛夫-阿诺德网络（TiKAN）模块，利用低秩分解进行KAN特征变换；（2）优化的多尺度特征金字塔结构，采用分离卷积以实现多尺度缺陷分析；（3）静态-动态原型机制，增强不平衡类别下的特征表示。", "conclusion": "在基础设施检查基准数据集上的广泛实验表明，KARMA 在参数量显著减少（0.959M 对比 31.04M，减少 97%）的情况下实现了与最先进的技术相当或更优的平均 IoU 表现，同时保持了部署时的推理速度，适合实时应用。"}
{"llm_update_time": "20251101", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.14904", "html_url": "https://arxiv.org/abs/2510.14904", "title": "MaskCaptioner：学习在视频中联合分割和描述对象轨迹", "title_en": "MaskCaptioner: Learning to Jointly Segment and Caption Object Trajectories in Videos", "authors": "Gabriel Fiastre,Antoine Yang,Cordelia Schmid", "background": "Dense Video Object Captioning（DVOC）任务要求同时检测、跟踪和描述视频中对象的轨迹，需要理解和描述时空细节。由于任务复杂性和手动注释的成本高，之前的算法采用了分离训练策略，这可能导致性能不佳。", "innovation": "提出了一种利用最新视觉语言模型（VLM）生成区域化时空实体的描述的方法。通过扩展LVIS和LV-VIS数据集，添加自动生成的描述（LVISCap和LV-VISCap），训练了一个能够联合检测、分割、跟踪和描述对象轨迹的端到端模型MaskCaptioner。MaskCaptioner在三个现有基准测试（VidSTG、VLN和BenSMOT）上实现了最先进的DVOC结果。", "conclusion": "MaskCaptioner在三个基准测试上达到了最先进的DVOC结果，数据集和代码可以通过此链接获得。"}
{"llm_update_time": "20251101", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.08771", "html_url": "https://arxiv.org/abs/2510.08771", "title": "LinearSR：解锁线性注意力以实现稳定高效的图像超分辨率", "title_en": "LinearSR: Unlocking Linear Attention for Stable and Efficient Image Super-Resolution", "authors": "Xiaohui Li,Shaobin Zhuang,Shuo Cao,Yang Yang,Yuandong Pu,Qi Qin,Siqi Luo,Bin Fu,Yihao Liu", "background": "生成模型在图像超分辨率（SR）方面的表现越来越强大，但它们对自注意力的二次复杂度（O(N^2)）造成了重大的计算瓶颈。虽然线性注意力以O(N)的复杂度提供了解决方案，但其在 Photorealistic SR 方面的潜力未能充分实现，历史上受到了一系列相互关联且之前未解决的挑战的阻碍。", "innovation": "该论文提出了一个名为 LinearSR 的整体框架（这是首次系统地克服了这些关键障碍），其中引入了基于“膝盖点”的早期停止引导微调 (ESGF) 策略，解决了一个基础问题：训练过程中的不稳定性，从而避免了模型发散的灾难性。此外，利用 SNR 基准混合专家架构 (MoE) 消除了经典的感知-失真权衡，同时从“精度优先而非容量优先”的原则出发，提出了有效的轻量级指导范式 TAG。结果，LinearSR 模型同时实现了最先进的感知质量与卓越的效率。其核心扩散前向传递 (1-NFE) 达到了最高技术水平的速度，而其整体多步骤推理时间仍然是极具竞争力的。这项工作为线性注意力在照片现实 SR 领域的应用提供了第一个稳健的方法，为高效的生成超分辨率研究奠定了基础范式。", "conclusion": "本研究提供的 LinearSR 模型同时在感知质量和效率上实现了最佳性能。其核心扩散前向传递达到了最高技术水平的速度，整体推理时间仍然具有很强的竞争力。这为线性注意力在高质量 SR 领域的应用提供了坚实的基础。"}
{"llm_update_time": "20251101", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.16556", "html_url": "https://arxiv.org/abs/2510.16556", "title": "适合实际需求吗？社交媒体上的政治深伪检测", "title_en": "Fit for Purpose? Deepfake Detection in the Real World", "authors": "Guangyu Lin,Li Lin,Christina P. Walker,Daniel S. Schiff,Shu Hu", "background": "随着生成对抗网络、扩散模型和多模态大型语言模型的进步，AI生成的内容迅速增长，使得合成媒体的生成和传播变得容易，增加了虚假信息的风险，尤其是政治深伪，这些深伪歪曲了事实，削弱了公众对政治机构的信任。因此，政府、研究机构和行业积极推动深伪检测项目作为解决方案。然而，大多数现有模型都是在实验室控制的数据集上训练和验证的，限制了它们在像社交媒体上流传的真实政治深伪上的泛化能力，这些深伪直接影响公众。", "innovation": "本文介绍了首个基于政见深伪事件数据库（包含2018年以来社交媒体上传播的真实政治深伪）的系统性基准测试。研究涵盖了学术界、政府和行业中的最先进的深伪探测器。研究发现，学术界和政府的探测器表现相对较差。付费探测工具相比免费模型表现出较高性能，但所有探测器在有效泛化到真实政治深伪以及应对简单操控（尤其是视频领域）方面都存在问题。", "conclusion": "研究表明现有探测器在公众真实环境中对真实政治深伪的检测能力有限，强调需要具备政治背景的深伪检测框架来更好地保护公众。"}
{"llm_update_time": "20251101", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.16396", "html_url": "https://arxiv.org/abs/2510.16396", "title": "SPLite手部：基于稀疏性的轻量级3D手部姿态估计", "title_en": "SPLite Hand: Sparsity-Aware Lightweight 3D Hand Pose Estimation", "authors": "Yeh Keng Hao,Hsu Tzu Wei,Sun Min", "background": "随着AR/VR设备的日益普及，将深度学习模型部署到边缘设备上已成为一个关键的挑战。这些设备需要实时推理、低功耗和最小延迟。许多框架设计师面临效率和性能之间的平衡难题。", "innovation": "我们设计了一个轻量级框架，采用了编码器-解码器架构，并引入了多个关键贡献以提高效率和准确性。我们通过在ResNet-18基础架构上应用稀疏卷积来利用手部姿态图像中的固有稀疏性，实现了端到端42%的效率提升。此外，我们提出了SPLite解码器，该新架构在Raspberry Pi 5上将解码过程的帧率提高了3.1倍，同时保持了准确性。为了进一步优化性能，我们应用了量化感知训练，在保持准确性的同时减少了内存使用量（PA-MPJPE从9.0毫米略微增加到9.1毫米，在FreiHAND数据集上），整个系统在Raspberry Pi 5 CPU上实现了2.98倍的速度提升（BCM2712四核Arm A76处理器）", "conclusion": "我们的方法在复合基准数据集上进行了评估，显示出与最先进的方法相当的准确性，同时显著提高了计算效率。"}
{"llm_update_time": "20251101", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.23588", "html_url": "https://arxiv.org/abs/2510.23588", "title": "FARMER: Flow AutoRegressive Transformer over Pixels", "title_en": "FARMER: Flow AutoRegressive Transformer over Pixels", "authors": "Guangting Zheng,Qinyu Zhao,Tao Yang,Fei Xiao,Zhijie Lin,Jie Wu,Jiajun Deng,Yanyong Zhang,Rui Zhu", "background": "直接建模原始数据的显式似然性是机器学习领域的关键主题，这在大型语言模型中通过自回归建模实现了成功扩展。然而，对视觉像素数据进行连续的自回归建模面临着极长序列和高维空间的挑战。本文探讨了一种新颖的端到端生成框架FARMER，它将归一化流（NF）和自回归（AR）模型统一起来，以实现可计算的似然估计和从原始像素直接生成高质量图像的目标。", "innovation": "FARMER采用可逆的自回归流将图像转换为隐空间序列，其分布由自回归模型隐式建模。为了解决像素级建模的冗余性和复杂性，提出了一种自我监督的降维方案，将NF隐空间通道划分为信息性和冗余性组，从而有效地进行AR建模。设计了一步蒸馏方案以显著加速推理速度，引入了一种基于重采样的分类器自由指导算法以提升图像生成质量。", "conclusion": "大量的实验表明，FARMER在现有基于像素的生成模型中表现出竞争力，并且提供精确的似然性和可扩展的训练。"}
{"llm_update_time": "20251101", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.23968", "html_url": "https://arxiv.org/abs/2510.23968", "title": "用于胸部X光分析的推理视觉语言模型", "title_en": "Reasoning Visual Language Model for Chest X-Ray Analysis", "authors": "Andriy Myronenko,Dong Yang,Baris Turkbey,Mariam Aboian,Sena Azamat,Esra Akcicek,Hongxu Yin,Pavlo Molchanov,Marc Edgar,Yufan He,Pengfei Guo,Yucheng Tang,Daguang Xu", "background": "视觉语言模型（VLMs）在医疗图像分析中表现出强大的潜力，但大多数模型仍然不透明，无法提供临床医生依赖的、具有透明步骤推理的预测结果。本文介绍了将链式思维（CoT）推理应用于胸部X光解读的框架。该研究基于先进行推理的训练范式，旨在学习专家是如何推理的，而不仅仅是他们得出的结论。通过中间步骤与可观察图像证据和放射学工作流的对齐，该研究侧重于可解释性，而不是仅仅提高准确性。", "innovation": "本文提出了一种推理视觉语言模型框架，用于胸部X光解读。该模型结合了高质量的视觉编码和两阶段训练食谱：一种基于推理的监督微调（SFT）与使用可验证奖励的强化学习（RL）相结合，后者针对X光异常列表。模型输出的推理过程反映了放射学家系统思维、不确定性及鉴别诊断，这种框架不仅提高了可解释性，还在分布外评估中实现了多标签分类的竞争力，同时通过完整推理轨迹增加了专家信心、支持错误审计并减少了报告完成时间。", "conclusion": "该研究证明了该框架在胸部X光分析中的有效性和重要性，认为推理质量和预测质量同样关键，从而支持社区在胸部放射摄影和其他需要高质量推理的医疗成像任务中实现值得信赖和可解释的AI。"}
{"llm_update_time": "20251101", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.25077", "html_url": "https://arxiv.org/abs/2510.25077", "title": "远程感知图像分类中的邻域特征池化", "title_en": "Neighborhood Feature Pooling for Remote Sensing Image Classification", "authors": "Fahimeh Orvati Nia,Amirmohammad Mohammadi,Salim Al Kharsa,Pragati Naikare,Zigfried Hampel-Arias,Joshua Peeples", "background": "本文提出了一种新颖的遥感图像分类纹理特征提取方法——邻域特征池化(NFP)。NFP层捕捉临近输入之间的关系，并在特征维度上高效地聚合局部相似性。NFP可以通过卷积层实现，并可以无缝集成到任何网络中。", "innovation": "提出了一种新的神经网络层——NFP，用于从遥感图像中提取纹理特征。NFP能够在特征维度上高效地聚合局部相似性，通过卷积层实现可无缝集成到现有网络中。", "conclusion": "将提出的NFP方法与基线模型进行对比，结果表明，NFP在整个性能上均优于基线模型，适用于多种数据集和网络结构，在保持参数数量不多的情况下，持续提升性能。"}
{"llm_update_time": "20251101", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.25327", "html_url": "https://arxiv.org/abs/2510.25327", "title": "MMEdge：通过流水线感测和编码加速边缘设备上的多模态推理", "title_en": "MMEdge: Accelerating On-device Multimodal Inference via Pipelined Sensing and Encoding", "authors": "Runxi Huang,Mingxuan Yu,Mingyu Tsoi,Xiaomin Ouyang", "background": "在自动驾驶、人机交互和移动健康等应用中，资源受限的边缘设备上的实时多模态推理至关重要。然而，现有研究往往忽视了传感动态与模型执行之间紧密联系以及不同模态间复杂的依赖关系。", "innovation": "本文提出了一种名为MMEdge的新颖端侧多模态推理框架，该框架基于流水线感测和编码。MMEdge将整个推理过程分解为细粒度的感测和编码单元，并引入了轻量级但有效的时序聚合模块，以保持准确度。此外，还引入了一种自适应多模态配置优化器和跨模态推测性跳过机制，以适应资源变化和输入数据复杂性。", "conclusion": "MMEdge在各种系统和数据动态下显著减少了端到端的延迟，同时保持了高任务准确性。"}
{"llm_update_time": "20251101", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.22319", "html_url": "https://arxiv.org/abs/2510.22319", "title": "GRPO-Guard：通过受控剪裁减轻流匹配中的隐性过度优化", "title_en": "GRPO-Guard: Mitigating Implicit Over-Optimization in Flow Matching via Regulated Clipping", "authors": "Jing Wang,Jiajun Liang,Jie Liu,Henglin Liu,Gongye Liu,Jun Zheng,Wanyuan Pang,Ao Ma,Zhenyu Xie,Xintao Wang,Meng Wang,Pengfei Wan,Xiaodan Liang", "background": "最近，基于GRPO的强化学习在优化流匹配模型方面取得了显著进展，有效提高了其与任务特定奖励的一致性。这些框架中，策略更新依赖于重要性比例剪裁以限制过度自信的正向和负向梯度。但在实际应用中，我们观察到重要性比例分布系统性地左移，其均值低于1且方差在各个时间步上存在显著差异。这种左移且不一致的分布导致正向优势样本无法进入剪裁区域，从而导致剪裁机制无法有效控制过度自信的正向更新。最终，策略模型不可避免地进入了隐性的过度优化阶段——尽管代理奖励继续增加，但诸如图像质量和文本提示一致性等关键指标急剧恶化，使得学到的策略难以在实际应用中使用。", "innovation": "我们提出了GRPO-Guard，一种对现有GRPO框架的简单有效增强。我们的方法引入了比率归一化，恢复了平衡且时间步一致的重要性比例，确保PPO剪裁能够在去噪时间步骤中适当约束有害更新。此外，我们还提出了一种梯度加权策略，以平衡噪声条件下政策梯度，防止特定时间步骤区域的过度更新。这些设计作为受控剪裁机制，稳定优化并显著减轻了隐性过度优化，同时不依赖于强烈的KL正则化。在多个扩散骨干网络（例如，SD3.5M、Flux.1-dev）和多种代理任务上的广泛实验表明，GRPO-Guard显著减少了过度优化，同时保持或甚至改善了生成质量。", "conclusion": "我们的方法通过引入比率归一化和梯度加权策略，作为一个受控剪裁机制，稳定了优化，并显著减轻了隐性过度优化，同时保持或改善了生成质量。"}
{"llm_update_time": "20251101", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.24134", "html_url": "https://arxiv.org/abs/2510.24134", "title": "VC4VG：针对文本到视频生成优化视频字幕", "title_en": "VC4VG: Optimizing Video Captions for Text-to-Video Generation", "authors": "Yang Du,Zhuoran Lin,Kaiqiang Song,Biao Wang,Zhicheng Zheng,Tiezheng Ge,Bo Zheng,Qin Jin", "background": "文本到视频（T2V）生成的最新进展突显了高质量视频字幕对训练能够产生连贯且指令对齐的视频模型的重要性。然而，针对T2V训练优化视频字幕的具体策略尚未充分探索。", "innovation": "本文提出了一种名为VC4VG（Video Captioning for Video Generation）的综合字幕优化框架，该框架专为T2V模型的需求量身定制。通过从T2V的角度分析字幕内容，提出了精细化的字幕设计方法，并构建了与T2V特定要求相匹配的细粒度、多维度和必要性分级的基准VC4VG-Bench。实验结果表明，改进的字幕质量与视频生成性能之间存在很强的相关性，验证了该方法的有效性。", "conclusion": "通过一系列T2V模型的微调实验，证明了改进字幕质量与视频生成性能之间的强相关性，验证了VC4VG方法的有效性。此外，所有基准工具和代码都已发布，以支持进一步的研究。"}
{"llm_update_time": "20251101", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.23981", "html_url": "https://arxiv.org/abs/2510.23981", "title": "TeleEgo: Benchmarking 虚拟中心化的AI助手在现实场景中的评估", "title_en": "TeleEgo: Benchmarking Egocentric AI Assistants in the Wild", "authors": "Jiaqi Yan,Ruilong Ren,Jingren Liu,Shuning Xu,Ling Wang,Yiheng Wang,Yun Wang,Long Zhang,Xiangyu Chen,Changzhi Sun,Jixiang Luo,Dell Zhang,Hao Sun,Chi Zhang,Xuelong Li", "background": "现有的以人为本的AI助手在实际场景中需要处理多模态输入（视频、音频、文本），实时响应，并维护不断演进的长久记忆。然而，现有的基准测试通常仅评估这些能力中的一个方面，缺乏真实的流式场景，或者仅支持短期任务。该研究引入了TeleEgo，这是一种用于评估虚拟中心化的AI助手在现实日常生活场景中的长期、流式、全模态基准测试。", "innovation": "TeleEgo数据集包括每位参与者超过14小时的同步自中心视角视频、音频和文本，在四个领域：工作&学习、生活方式&日常、社交活动和外出&文化。所有数据都统一在一条全球时间线上，并包括高质量的视觉叙述和语音转录，经人类专家校准。TeleEgo定义了12个诊断子任务，涵盖了三项核心能力：记忆（回忆过去事件）、理解（解释当前时刻）、跨记忆推理（关联不同时段的事件）。它提供了3,291个经过人类验证的问答项，涵盖了多种问题形式，并严格在流式环境中进行评估。提出了两个关键指标——实时准确性和记忆持续时间，以联合评估正确性、时空响应性和长期保持能力。", "conclusion": "TeleEgo提供了一种现实且全面的评估框架，推动实际应用中的AI助手技术的进步。"}
{"llm_update_time": "20251101", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2503.22159", "html_url": "https://arxiv.org/abs/2503.22159", "title": "Disentangled 4D Gaussian Splatting: 实时渲染高分辨率动态世界到343 FPS", "title_en": "Disentangled 4D Gaussian Splatting: Rendering High-Resolution Dynamic World at 343 FPS", "authors": "Hao Feng,Hao Sun,Wei Xie,Zhi Zuo,Zhengzhe Liu", "background": "虽然从2D视频中动态生成新颖视图已取得进展，但实现动态场景的高效重建和渲染仍是一项具有挑战的任务。", "innovation": "提出了Disentangled 4D Gaussian Splatting (Disentangled4DGS) 表示和渲染管道，能够在不牺牲视觉保真度的情况下实现实时性能。Disentangled4DGS 将动态4D高斯的时序和空间分量解耦，避免了之前方法中的首先切片和四维矩阵计算。通过将时序和空间变形投影到动态2D高斯并推迟时序处理，我们最小化了4DGS的冗余计算。该方法还采用了梯度引导流动损失和时序划分策略来减少伪影。实验证明，渲染速度和质量显著提升，在使用单个 RTX3090 渲染1352*1014分辨率的图像时，达到了343 FPS，并减少了至少4.5%的存储需求。该方法在多视图和单目动态场景数据集上优于现有方法，设立了新的动态新颖视图合成基准线，", "conclusion": "本研究提出了一种新的表示和渲染管道——Disentangled4DGS，该方法能够在不牺牲视觉保真度的情况下实现实时性能。通过实验证明，该方法的渲染速度和质量显著提高，减少了存储需求，从而设立了新的动态新颖视图合成基准线。"}
{"llm_update_time": "20251101", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2505.13444", "html_url": "https://arxiv.org/abs/2505.13444", "title": "ChartMuseum：测试大型视觉语言模型的视觉推理能力", "title_en": "ChartMuseum: Testing Visual Reasoning Capabilities of Large Vision-Language Models", "authors": "Liyan Tang,Grace Kim,Xinyu Zhao,Thom Lake,Wenxuan Ding,Fangcong Yin,Prasann Singhal,Manya Wadhwa,Zeyu Leo Liu,Zayne Sprague,Ramya Namuduri,Bodun Hu,Juan Diego Rodriguez,Puyuan Peng,Greg Durrett", "background": "大型视觉语言模型（LVLMs）在图表理解方面面临独特的挑战，因为这需要综合复杂的文本和视觉推理能力。然而，当前的LVLMs在这两方面的能力存在明显失衡，尤其是在难以在文本中执行的视觉推理方面表现较弱。现有的图表理解基准模型性能相近，几乎没有差异，本文通过一个只通过视觉推理才能解决的合成数据集，展示了模型随视觉复杂性增加，其性能显著下降，而人类的性能保持稳定。", "innovation": "作者引入了ChartMuseum，这是一个新的图表问答基准，包含1,162个专家标注的问题，涵盖了多种推理类型，从184个实际来源中精心挑选的图表中提取，旨在评估复杂的视觉和文本推理。这个基准揭示了模型与人类在性能上的显著差距，有效地区分了模型的能力：尽管人类获得了93%的准确率，表现最好的模型Gemini-2.5-Pro仅达到63.0%，领先开源LVLM Qwen2.5-VL-72B-Instruct也只有38.5%。此外，对于主要需要视觉推理的问题，所有模型的性能从主要依靠文本推理的问题中下降了35%-55%。", "conclusion": "图表理解是LVLMs的挑战之一，现有LVLMs在视觉推理方面存在明显不足。ChartMuseum基准提供了评估这一不足的有效工具，以及区分不同模型能力的方式。探索使得模型在特定视觉推理任务上表现差别的原因将有助于改进这类模型的性能。"}
{"llm_update_time": "20251101", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2506.19816", "html_url": "https://arxiv.org/abs/2506.19816", "title": "CronusVLA: 通过多帧视语言行动建模迈向高效鲁棒性操控", "title_en": "CronusVLA: Towards Efficient and Robust Manipulation via Multi-Frame Vision-Language-Action Modeling", "authors": "Hao Li,Shuai Yang,Yilun Chen,Xinyi Chen,Xiaoda Yang,Yang Tian,Hanqing Wang,Tai Wang,Dahua Lin,Feng Zhao,Jiangmiao Pang", "background": "近期基于预训练的视语言模型的视语言行动（VLA）模型已经在机器人操作方面取得了出色的表现。然而，这些模型仍然受限于单帧图像的理念，未能充分利用多帧历史提供的时间信息，直接将多帧输入到视语言模型的主干中会带来显著的计算负担和推理延迟。", "innovation": "提出了CronusVLA，这是一个统一框架，将单帧VLA模型扩展到多帧范式。CronusVLA采用两阶段过程：（1）在大规模沉浸式数据集上进行单帧预训练，通过自回归预测行动标记建立有效的沉浸式视语言基础；（2）多帧后训练，将视语言主干的预测从离散标记适配到可学习的特征，并通过特征分块聚合历史信息。CronusVLA有效解决了多帧建模的现有挑战，同时提高了性能和观测鲁棒性。", "conclusion": "为了评估在时间和空间扰动下的鲁棒性，引入了一种名为SimplerEnv-OR的新基准，包含24种观测扰动类型和120种严重程度级别。在模拟和真实世界环境中的三种体态实验中，CronusVLA取得了领先的表现和更优的鲁棒性，SimplerEnv上的成功率达到70.9%，比OpenVLA在LIBERO上的成效提高了26.8%，SimplerEnv-OR上的鲁棒性评分最高。这些结果突显了多帧适应在VLA模型中的潜力，为更强大和鲁棒的实际部署奠定了基础。"}
{"llm_update_time": "20251101", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.17148", "html_url": "https://arxiv.org/abs/2510.17148", "title": "DiffVLA++: 通过基于度量的对齐连接认知推理和端到端驾驶", "title_en": "DiffVLA++: Bridging Cognitive Reasoning and End-to-End Driving through Metric-Guided Alignment", "authors": "Yu Gao,Anqing Jiang,Yiru Wang,Wang Jijun,Hao Jiang,Zhigang Sun,Heng Yuwen,Wang Shuo,Hao Zhao,Sun Hao", "background": "传统的端到端驾驶模型在生成物理上合理的轨迹方面非常有效，但由于缺乏理解周围环境所需的关键世界知识，往往无法很好地应用于罕见情景。相比之下，视觉-语言-动作（VLA）模型利用了世界知识来处理挑战性情况，但它们的3D推理能力有限可能导致物理上不可行的动作。", "innovation": "本文提出了一种增强的自动驾驶框架——DiffVLA++，通过度量导向的对齐明确地结合了认知推理和端到端规划。该框架包括一个直接生成语义驱动轨迹的VLA模块，一个确保物理可行性的密集轨迹词汇量的端到端模块，以及一个度量导向的轨迹评分器，用于引导和对齐VLA和端到端模块的输出，从而整合它们的优势。", "conclusion": "DiffVLA++ 在ICCV 2025自动驾驶挑战赛的成绩表上取得了EPDMS 49.12的成绩。"}
{"llm_update_time": "20251101", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.06159", "html_url": "https://arxiv.org/abs/2509.06159", "title": "FASL-Seg：手术场景中解剖结构和工具的分割", "title_en": "FASL-Seg: Anatomy and Tool Segmentation of Surgical Scenes", "authors": "Muraam Abdel-Ghani,Mahmoud Ali,Mohamed Ali,Fatmaelzahraa Ahmed,Muhammad Arsalan,Abdulaziz Al-Ali,Shidin Balakrishnan", "background": "随着机器人微创手术的流行，基于深度学习的手术培训已成为一个重要研究领域。深入理解手术场景的组成部分至关重要，而语义分割模型可以帮助实现这一点。然而，现有的大部分研究集中于手术工具，而忽视了解剖对象。此外，当前最先进的（SOTA）模型难以在捕获高层次上下文特征和低层次边缘特征之间取得平衡。", "innovation": "我们提出了一种特征自适应空间定位模型（FASL-Seg），通过两个不同的处理流：低层次特征投影（LLFP）和高层次特征投影（HLFP）流，能够在不同的特征分辨率下捕获特征，从而精确分割解剖结构和手术器械。我们在EndoVis18和EndoVis17的手术分割基准数据集上对FASL-Seg模型进行了三种用途的评估，结果表明FASL-Seg模型在EndoVis18中实现了72.71%的平均交集率（mIoU），比SOTA提高了5%，并且在EndoVis18和EndoVis17的工具类型分割中分别达到了85.61%和72.78%，在两个数据集中均实现了与分类相关的SOTA结果，展示了不同特征分辨率下的不同处理流的有效性。", "conclusion": "FASL-Seg通过自适应特征处理流实现了对不同分辨率特征的有效捕捉，提高了手术场景中解剖结构和工具的分割精度，相比当前SOTA模型具有显著优势。"}
{"llm_update_time": "20251101", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.16336", "html_url": "https://arxiv.org/abs/2509.16336", "title": "Neural Atlas Graphs for Dynamic Scene Decomposition and Editing", "title_en": "Neural Atlas Graphs for Dynamic Scene Decomposition and Editing", "authors": "Jan Philipp Schneider,Pratik Singh Bisht,Ilya Chugunov,Andreas Kolb,Michael Moeller,Felix Heide", "background": "如何学习可编辑的高分辨率场景表示以应对动态场景是一个开放问题，应用范围广泛，从自动驾驶到创意编辑均有涉及。当前最成功的做法是在可编辑性和支持复杂场景之间做出权衡：神经地图通过变形、分隔前景和背景的两层来表示动态场景，但当多个对象发生遮挡和交互时，此方法会失效。场景图模型使用自动驾驶数据集中的注释信息（如掩码和边界框）来捕捉复杂的三维空间关系，但其隐式的体积节点表示难以在视图一致的情况下进行编辑。", "innovation": "提出了神经地图图（NAGs），这是一种混合高分辨率场景表示。每个图节点都是视图相关的神经地图，既支持二维外观编辑，又允许三维场景元素的顺序和位置排列。在测试时进行拟合，NAGs在Waymo开放数据集上实现了最先进的定量结果，比现有方法提高了5 dB的PSNR，并使高分辨率和视觉质量的环境编辑成为可能。在DAVIS视频数据集上，该方法在与多种人性和动物性场景的近期抠图和视频编辑基线对比中，PSNR超过7 dB的优势也得到了验证，表明它可以很好地泛化到驾驶场景之外。", "conclusion": "Neural Atlas Graphs为动态场景的分解和编辑提供了一种新的方法，该方法结合了可编辑性和复杂场景的支持，通过在测试时进行拟合，显示出卓越的定量结果和视觉质量。"}
{"llm_update_time": "20251101", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.23117", "html_url": "https://arxiv.org/abs/2510.23117", "title": "在图像基础上的物理嵌入神经网络 (PINN) 用于意大利面桥载荷预测，预见结构失效", "title_en": "Seeing Structural Failure Before it Happens: An Image-Based Physics-Informed Neural Network (PINN) for Spaghetti Bridge Load Prediction", "authors": "Omer Jauhar Khan,Sudais Khan,Hafeez Anwar,Shahzeb Khan,Shams Ul Arifeen", "background": "PINNs能够将物理定律嵌入到深度学习模型中，特别适用于结构工程任务，特别是在数据有限的情况下。本文旨在利用PINNs预测小型意大利面桥的重量，这对于理解简化结构模型中的载荷极限和潜在失效模式至关重要。", "innovation": "本文提出了一种新的架构——物理嵌入柯尔莫哥罗夫·阿诺德网络（PIKAN），它结合了通用函数逼近理论与物理洞察。此外，该框架通过将物理约束嵌入到预测模型中以提高性能。研究表明，即使在数据有限的情况下，PINNs也可以提供结构重量的可靠估计，并可能有助于轻型桥梁设计的早期失效分析。", "conclusion": "通过我们的最优模型，我们实现了$R^2$分数为0.9603和均方误差（MAE）为10.50的预测结果。本研究结果表明，PINNs可以提供可靠的结构重量估计，并且可以为轻型桥梁设计的早期失效分析提供帮助。我们还提供了一个基于Web的界面用于参数输入和预测。"}
{"llm_update_time": "20251101", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.21271", "html_url": "https://arxiv.org/abs/2510.21271", "title": "Buffer层在测试时适应中的应用", "title_en": "Buffer layers for Test-Time Adaptation", "authors": "Hyeongyu Kim,Geonhui Han,Dosik Hwang", "background": "在最近关于测试时适应（TTA）的研究进展中，大多数现有方法侧重于更新归一化层以适应测试域。然而，对归一化层的依赖提出了关键挑战。首先，归一化层如Batch Normalization（BN）对小批量大小非常敏感，导致统计不稳定性和不准确性。此外，基于归一化的适应方法受限于预训练模型的结构，因为这些方法依赖于训练时的统计数据，可能在未见过的域中不能很好地泛化。这些问题限制了基于归一化的TTA方法的有效性，特别是在显著域转移的情况下。", "innovation": "本文引入了一种基于Buffer层概念的新型范式，解决了归一化层更新的基本局限性。与现有方法修改模型核心参数不同，我们的方法保留了预训练核心骨架的完整性，从根本上减轻了在线适应过程中灾难性遗忘的风险。通过全面的实验，我们展示了我们的方法不仅在缓解域转移和增强模型鲁棒性方面优于传统方法，而且对遗忘具有很强的抗性。此外，我们的Buffer层是模块化的，可以无缝集成到几乎所有的现有TTA框架中，从而在各种架构中一致性地提高性能。", "conclusion": "这些发现验证了我们提出的解决方案在真实世界的域适应场景中的有效性和通用性。代码可以在以下链接中找到：this https URL."}
{"llm_update_time": "20251101", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.02781", "html_url": "https://arxiv.org/abs/2510.02781", "title": "GCVAMD：一种改进的因果VAE模型，用于因年龄相关黄斑变性风险因素的因果检测和预测", "title_en": "GCVAMD: A Modified CausalVAE Model for Causal Age-related Macular Degeneration Risk Factor Detection and Prediction", "authors": "Daeyoung Kim", "background": "年龄相关黄斑变性(AMD)是眼科导致永久视力损害的主要原因之一。尽管开发了诸如抗VEGF药物或光动力疗法等治疗方法来减缓AMD的退化过程，但还没有能够逆转由AMD引起的视力损失的具体治疗方法。因此，在早期阶段检测AMD患者视网膜中的风险因素或AMD本身对于减少视力损害的可能性至关重要。通过传统方法，基于深度学习的方法，尤其是基于注意力机制的CNN和基于GradCAM的可解释人工智能(XAI)分析OCT扫描，已经在区分AMD视网膜与正常视网膜方面取得了成功，使得使用AI驱动模型辅助眼科医生对AMD进行诊断和分析成为可能。然而，尽管取得显著成功，之前的许多工作主要集中在预测性能上，而不是AMD的病理机制或潜在的因果机制，这可能会限制对具体因素的干预分析或导致不那么可靠的选择。", "innovation": "本论文提出了一种新的因果AMD分析模型：GCVAMD，它结合了改进的因果VAE方法，可以从仅有的原始OCT图像中提取潜在的因果因子。通过在AMD检测中考虑因果性，GCVAMD能够实现关于主要风险因素（如玻璃体物质沉积和新生血管化）的治疗模拟或干预分析，并返回有助于下游任务的具有信息价值的潜在因果特征。", "conclusion": "通过GCVAMD，可以识别出AMD因果机制中的玻璃体物质沉积状态和新生血管化状态，这些可以用于从AMD检测（分类）到干预分析的各种任务。"}
{"llm_update_time": "20251101", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.24325", "html_url": "https://arxiv.org/abs/2509.24325", "title": "ReCon-GS: 保留连续性的高斯流形式化快速且紧凑的动态场景重构", "title_en": "ReCon-GS: Continuum-Preserved Gaussian Streaming for Fast and Compact Reconstruction of Dynamic Scenes", "authors": "Jiaye Fu,Qiankun Gao,Chengxiang Wen,Yanmin Wu,Siwei Ma,Jiaqi Zhang,Jian Zhang", "background": "在线自由视点视频(FVV)重构面临的挑战包括每帧优化速度慢、运动估计不一致以及不可持续的存储需求。现有的技术无法有效解决这些问题，导致在动态场景的实时重建和渲染方面存在局限性。这限制了FVV技术的应用范围和效率。", "innovation": "提出了一种新颖的存储意识框架ReConfigurable Continuum Gaussian Stream (ReCon-GS)，该框架能够实现高保真度的动态场景在线重构和实时渲染。通过动态分配多级锚定高斯分布，适应性地捕捉帧间几何变形，并分解场景运动为紧凑的细至粗级别表示。设计动态层次重构策略，保留局部运动表达的实时性，并通过层次内变形继承确保时间一致性，从而将先验转换限制在其相应的层次级别。此外，引入了一种存储意识优化机制，可以在不同层次级别灵活调整锚定高斯分布的密度，实现了重建保真度和内存使用间的可控权衡。", "conclusion": "在三个广泛使用的数据集上的实验结果表明，与最先进的方法相比，ReCon-GS能够在提高约15%的训练效率的同时，提供更高质量的FVV合成并增强鲁棒性和稳定性。在同等渲染质量下，与领先的最先进的方法相比，ReCon-GS节省了超过50%的内存需求。"}
{"llm_update_time": "20251101", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.25788", "html_url": "https://arxiv.org/abs/2510.25788", "title": "SHA-256 Infused Embedding-Driven Generative Modeling of High-Energy Molecules in Low-Data Regimes", "title_en": "SHA-256 Infused Embedding-Driven Generative Modeling of High-Energy Molecules in Low-Data Regimes", "authors": "Siddharth Verma,Alankar Alankar", "background": "高能材料（HEMs）在推进和防御领域至关重要，但其发现仍受限于实验数据和测试设施的限制。此工作中通过结合长期短期记忆（LSTM）网络进行分子生成和注意力图神经网络（Attentive GNN）进行性质预测，提出了新的方法。研究背景强调了在数据稀缺的情况下寻找新的高能分子的挑战。", "innovation": "提出了整合固定SHA-256嵌入和部分可训练表示的新型嵌入空间构建策略。与传统的正则化技术不同，这种方法改变了表征的基础本身，在学习开始前重新塑造分子输入空间。生成器在无需预训练的情况下实现了67.5%的有效性和37.5%的新颖性。生成的库与训练集的平均Tanimoto系数为0.214，表明框架能够生成多样性的化学空间，并且已识别出37种高于9 km/s预测爆速的新超级爆炸物。", "conclusion": "该框架在低数据条件下生成了新的高能分子，并且在无需预训练的情况下实现了高生成有效性与新颖性，揭示了在数据稀缺环境下寻找新型高能材料的潜力。"}
{"llm_update_time": "20251101", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.25781", "html_url": "https://arxiv.org/abs/2510.25781", "title": "Kolmogorov-Arnold网络：从业者指南", "title_en": "A Practitioner's Guide to Kolmogorov-Arnold Networks", "authors": "Amir Noorizadegan,Sifan Wang,Leevan Ling", "background": "Kolmogorov-Arnold网络（KANs）作为多层感知机（MLPs）的有前途的替代方案最近引起了关注，受到Kolmogorov-Arnold表示定理的启发。KANs通过在边缘上使用可学习的一元基函数而非MLPs中固定的激活函数，提供更强的表示能力和可解释性。本文提供了对日益增长的KAN生态系统的系统而全面的概览，超越了简单的性能比较，着眼于理论基础、架构变体和实用实现策略的结构化综合。", "innovation": "KANs引入了一种新的机制，即在边缘上使用可学习的一元基函数，而不是固定激活函数，这使得KANs在表示能力和可解释性方面超越了传统MLPs。文章还详细介绍了各种基函数的选择及其优缺点，涵盖了微分代数曲面、Chebyshev和Jacobi多项式、ReLU组合、高斯径向基函数和傅里叶级数，并将最近的进展清晰地分类，涵盖提高准确度、效率和正则化的技术。同时，通过一个实际的“选择KAN指南”帮助实践者选择合适的架构。", "conclusion": "文章总结了当前的研究缺口，并为持续的KAN研究提供了结构化的参考。相关的GitHub存储库提供了补充资源，供从业者参考。"}
{"llm_update_time": "20251101", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.25785", "html_url": "https://arxiv.org/abs/2510.25785", "title": "HiMAE：层次掩蔽自动编码器发现可穿戴时间序列的分辨率特定结构", "title_en": "HiMAE: Hierarchical Masked Autoencoders Discover Resolution-Specific Structure in Wearable Time Series", "authors": "Simon A. Lee,Cyrus Tanade,Hao Zhou,Juhyeon Lee,Megha Thukral,Minji Han,Rachel Choi,Md Sazzad Hissain Khan,Baiying Lu,Migyeong Gwak,Mehrab Bin Morshed,Viswam Nathan,Md Mahbubur Rahman,Li Zhu,Subramaniam Venkatraman,Sharanya Arcot Desai", "background": "可穿戴传感器提供了丰富的生理时间序列数据，但对于这些数据预测有用性的原理仍不清楚。研究假设时间分辨率是表示学习的基本轴，不同临床和行为结果依赖于不同的时间尺度结构。为了测试这个分辨率假设，引入了HiMAE（层次掩蔽自动编码器）框架，该框架结合了掩蔽自动编码与层次卷积编码解码。HiMAE生成多分辨率嵌入，能够系统地评估哪些时间尺度带有预测信号，将分辨率从超参数转变为可解释性的探针。在分类、回归和生成基准测试中，HiMAE在性能上始终优于将时间尺度折叠的最先进的基础模型，而且规模小得多。HiMAE是一种高效的表示学习方法，足够紧凑可以在腕式设备上完全运行，对于腕式类CPU实现了亚毫秒级推理，实现了真正的边缘推理。", "innovation": "提出了HiMAE（层次掩蔽自动编码器），结合了掩蔽自动编码与层次卷积编码解码，生成多分辨率嵌入，用于系统地评估预测信号的时间尺度。相对于将时间尺度折叠的最先进的基础模型，HiMAE在多个基准测试中表现出色，且规模小得多，能够在腕式设备上完全运行，实现亚毫秒级推理。", "conclusion": "HiMAE不仅是一种高效的自我监督学习方法，也是一种用于发现可穿戴健康中对时间尺度敏感结构的发现工具。"}
{"llm_update_time": "20251101", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.25791", "html_url": "https://arxiv.org/abs/2510.25791", "title": "推理的动力学：成对思维如何塑造Transformer的学习？", "title_en": "The Kinetics of Reasoning: How Chain-of-Thought Shapes Learning in Transformers?", "authors": "Zihan Pengmei,Costas Mavromatis,Zhengyuan Shen,Yunyi Zhang,Vassilis N. Ioannidis,Huzefa Rangwala", "background": "成对思维（CoT）监督能够显著提高Transformer的表现，但模型如何学习遵循并受益于CoT的机制尚不明确。本文通过将Transformer预训练在具有可调算法复杂性和可控数据组成的符号推理任务上来研究这些学习动态，以探讨其泛化能力。研究表明，虽然成对思维通常可以提高任务性能，但其效果取决于任务的复杂性。此外，研究还发现了一种短暂的轨迹不忠实现象：在训练早期，模型经常给出正确答案但跳过了或违背了成对思维步骤，之后才与答案对齐其推理轨迹。", "innovation": "1. 提出了一种动力学建模框架来理解Transformer的学习过程；\n2. 揭示了轨迹忠实性作为动态属性在训练过程中逐渐显现；\n3. 证明了成对思维可以加速泛化，但并不能克服更高算法复杂性的任务；\n4. 通过实验发现了成对思维监督下内部Transformer计算机制的改变。", "conclusion": "本文研究表明，虽然成对思维监督在提高任务性能方面有积极作用，但其效果受任务复杂性影响。通过建立动力学建模框架，揭示了轨迹忠实性的动态变化，并展示了成对思维如何机械地改变内部Transformer的计算机制。"}
{"llm_update_time": "20251101", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.25798", "html_url": "https://arxiv.org/abs/2510.25798", "title": "MemEIC: 朝着持续性与组件性知识编辑迈出的一步", "title_en": "MemEIC: A Step Toward Continual and Compositional Knowledge Editing", "authors": "Jin Seong,Jiyun Park,Wencke Liermann,Hongseok Choi,Yoonji Nam,Hyun Kim,Soojong Lim,Namhoon Lee", "background": "信息的动态特性要求持续更新大型视觉语言模型（LVLMs）。近年来的知识编辑技术显示出了希望的方向，但它们往往专注于单独编辑单一模态（视觉或语言），而忽略了LVLMs的固有跨模态性和知识不断更新的持续性。这种做法可能导致在考虑模态间的互动和持续知识精炼需求时，编辑效果不理想。", "innovation": "本文提出了一种名为MemEIC的新方法，用于LVLMs中的持续性与组件性知识编辑（CCKE）。MemEIC允许对视觉和文本知识进行顺序式的组件编辑，通过结合外部-内部编辑器、双模态外部记忆和双LORA适配器来实现模态间参数更新的分离。关键组件是一种基于大脑的知识连接器，能够在需要时进行选择性激活，以进行组件推理并将不同模态的信息整合。", "conclusion": "实验表明，MemEIC在复杂跨模态问题上的性能显著提高，并能够有效保留前期编辑，为LVLMs中的CCKE设定了新的基准。"}
{"llm_update_time": "20251101", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.25800", "html_url": "https://arxiv.org/abs/2510.25800", "title": "FreIE: 时序任务中神经网络的低频谱偏置", "title_en": "FreIE: Low-Frequency Spectral Bias in Neural Networks for Time-Series Tasks", "authors": "Jialong Sun,Xinpeng Ling,Jiaxuan Zou,Jiawen Kang,Kejia Zhang", "background": "时间序列数据固有的自相关性对多变量时间序列预测构成了持续的挑战。最近，一种广泛采用的方法是引入频率域信息以辅助长期预测任务。许多研究者观察到神经网络中的谱偏置现象，即模型倾向于先拟合低频信号再拟合高频信号。然而，这些观察往往被归因于研究人员设计的具体架构，而未能将其视为模型的一种普遍特征。为了统一理解长期时间序列预测中的谱偏置现象，我们进行了广泛的实证实验来测量现有主流模型中的谱偏置现象。我们的研究发现几乎所有模型都表现出这种现象。", "innovation": "为减轻谱偏置的影响，我们提出了 FreLE（频率损失增强）算法，通过显式和隐式的频率正则化增强模型泛化能力。FreLE 是一种即插即用模型损失函数组件。大量实验证明了 FreLE 的优越性能。该代码可以在指定的 URL 地址获取。", "conclusion": "大量的实验证明了 FreLE 算法的有效性，使得各个模型都能更好地处理低频谱偏置的问题。"}
{"llm_update_time": "20251101", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.25796", "html_url": "https://arxiv.org/abs/2510.25796", "title": "使用基于仿真实验强化学习的非短期思考匹配与重新平衡在大规模按需拼车系统中的应用", "title_en": "Non-myopic Matching and Rebalancing in Large-Scale On-Demand Ride-Pooling Systems Using Simulation-Informed Reinforcement Learning", "authors": "Farnoosh Namdarpour,Joseph Y. J. Chow", "background": "拼车服务（也称为共享乘车、拼车或是微交通）是一种共享乘车的服务模式，它能够降低乘客和运营商的成本，并减少交通拥堵和环境影响。然而，传统的调度决策过于短期，忽视了长期影响。因此，本文提出了一种基于仿真实验强化学习的方法来解决这一问题。这种方法通过对学习机制嵌入拼车仿真来实现非短期思考的决策，并提出了一个补充策略来进行闲置车辆的重新平衡。", "innovation": "本文的创新点在于将 Xu 等人 (2018) 关于叫车系统的学习和规划框架扩展到拼车系统中，通过在学习机制中嵌入拼车仿真，实现非短期思考决策。此外，还提出了一个补充政策来重新平衡闲置车辆。通过使用 n 步时差学习在模拟经验中获得时空状态价值，并使用纽约市出租车请求数据来评估非短期思考政策的有效性。", "conclusion": "实验结果表明，与短期思考的策略相比，提出的非短期思考匹配策略可以提高服务速率最多8.4%，并减少乘客的等待时间和车内时间。此外，该非短期思考策略可以使车队规模减少25%以上，同时仍然保持相同的性能水平，从而为运营商节省成本。将重新平衡操作整合到提出的框架中，可以进一步减少等待时间27.3%，车内时间12.5%，并且提高服务率15.1%，然而这需要增加每乘客的车辆分钟数。"}
{"llm_update_time": "20251101", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.25793", "html_url": "https://arxiv.org/abs/2510.25793", "title": "多代理系统中使用自适应偏差学习的最优信息组合", "title_en": "Optimal Information Combining for Multi-Agent Systems Using Adaptive Bias Learning", "authors": "Siavash M. Alamouti,Fay Arjomandi", "background": "现代多代理系统，如监控关键基础设施的传感器网络和聚合人类智能的众包平台，可能会因与环境条件相关的系统偏差而遭受显著性能下降。现有方法要么忽略了这些偏差，导致决策不准确；要么需要昂贵的校准程序，这些程序在实践中往往不可行。这导致了诸如不准确的环境监测、不可靠的金融预测和不准确的人类判断聚合等问题。", "innovation": "论文提出了一个理论框架，将偏差分解为可学会的系统成分和不可约的随机成分，并提出了可学习比的概念，即偏差方差中可通过可观测协变量预测的比例。该比值决定了在给定系统中是否值得进行偏差学习。还提出了自适应偏差学习和最佳组合（ABLOC）算法，该算法通过闭式解迭代学习偏差修正变换并优化组合权重，保证收敛到这些理论边界。实验验证表明，高可学习比系统的性能可显著恢复（实例如此实现了40%-70%的理论最大改进），而低可学习比系统则几乎没有收益。", "conclusion": "该研究为系统设计者提供了定量指导，帮助他们在偏差学习和更简单的替代方法之间做出决策。该研究还证明，在高可学习比的情况下，可以通过对系统偏差进行学习和修正来显著提高性能，这为多代理系统的实际部署决策提供了诊断依据。"}
{"llm_update_time": "20251101", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.25818", "html_url": "https://arxiv.org/abs/2510.25818", "title": "ScaleDiff：通过高效且模型无关的扩散模型实现更高分辨率的图像合成", "title_en": "ScaleDiff: Higher-Resolution Image Synthesis via Efficient and Model-Agnostic Diffusion", "authors": "Sungho Koh,SeungJu Cha,Hyunwoo Oh,Kwanyoung Lee,Dong-Jin Kim", "background": "文本到图像的扩散模型在生成超过训练分辨率的图像时往往表现出性能下降。最近的无需训练的方法可以缓解这一限制，但它们通常需要大量计算资源或与最近的扩散转换器模型不兼容。", "innovation": "提出了ScaleDiff，这是一种模型无关且高效的框架，可以在不进行额外训练的情况下扩展预训练的扩散模型的分辨率。该框架的核心组件是邻域块注意力机制（NPA），这是一种高效的计算冗余减少机制，以及引入了潜在频率混合（LFM）以更好地生成细微细节，并应用结构引导增强去噪过程中的全局结构。", "conclusion": "实验结果表明，ScaleDiff在U-Net和扩散转换器架构中均可实现无训练方法中的最佳图像质量和推理速度。"}
{"llm_update_time": "20251101", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.25801", "html_url": "https://arxiv.org/abs/2510.25801", "title": "Metis-SPECS：通过自我蒸馏偏好导向冷启动解耦多模态学习", "title_en": "Metis-SPECS: Decoupling Multimodal Learning via Self-distilled Preference-based Cold Start", "authors": "Kun Chen,Peng Shi,Haibo Qiu,Zhixiong Zeng,Siqi Yang,Wenji Mao,Lin Ma", "background": "最近，带有可验证奖励的强化学习（RL）推动了“MLLM-r1”方法的出现，使其能够应用于视觉语言模型。大多数代表性的方法都会从一个冷启动阶段开始，通常通过监督微调（SFT）来初始化策略，然后再进行RL。然而，SFT方法可能会导致指令式的过拟合，削弱模型在未知分布中的泛化能力，从而影响后续的RL效果。因此，本文重新审视了冷启动阶段的训练方法和数据构建，并引入了一个泛化因子（GF）系数来量化不同方法下的泛化能力。研究表明，基于偏好训练的方法（如DPO）在冷启动阶段有更好的泛化能力。", "innovation": "本文提出了一个名为SPECS的自我蒸馏偏好导向冷启动框架。该框架通过自我蒸馏产生自反的偏好数据对，避免依赖大型教师模型或手动标注；通过偏好导向的训练，关注易转移的表面形式标准（格式、结构、风格）而非内容的记忆；最后，将模型交由带有可验证奖励的RL进行深层次的因果推理。实验结果表明，SPECS在多个多模态基准上取得了稳定的性能提升，超过了一系列强大的基线，特别是在MEGA-Bench中提高了4.1%，在MathVista中提高了12.2%。进一步的实验还表明，SPECS有助于减少归纳偏差、提高探索性、稳定训练过程并提高性能上限。", "conclusion": "本文研究了冷启动段训练方法和数据构建，并引入了泛化因子（GF）系数来量化不同方法下的泛化能力。提出了基于自我蒸馏和偏好导向的冷启动框架SPECS，通过自我蒸馏生成自反偏好数据对，进行偏好导向训练，最后与带有可验证奖励的RL结合，从而实现了在多个多模态基准中的性能提升。"}
{"llm_update_time": "20251101", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.25924", "html_url": "https://arxiv.org/abs/2510.25924", "title": "使用代理进行因果效应转移", "title_en": "Transferring Causal Effects using Proxies", "authors": "Manuel Iglesias-Alonso,Felix Schur,Julius von Kügelgen,Jonas Peters", "background": "本文探讨了在多领域环境下的因果效应估计问题。存在未观察到的混杂因素导致目标因果效应被混淆，并且该效应在不同领域中可能会有所不同。作者假设可以访问隐藏混杂因素的代理变量，并且所有变量均为离散的或者分类的变量。", "innovation": "本文提出了一种方法来估计目标领域中的因果效应，在该领域中我们仅能观察到代理变量。在这些条件下，作者证明了因果效应的可识别性（即使当处理和反应变量为连续型时）。此外，作者提出了两种估计技术，证明了它们的一致性，并提出了置信区间。", "conclusion": "理论结果得到了模拟研究和一个基于网站排名对消费者选择影响的真实性案例研究的支持。"}
{"llm_update_time": "20251101", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.25892", "html_url": "https://arxiv.org/abs/2510.25892", "title": "图上拓扑感知主动学习", "title_en": "Topology-Aware Active Learning on Graphs", "authors": "Harris Hardiman-Mostow,Jack Mauro,Adrien Weihs,Andrea L. Bertozzi", "background": "本文提出了一种针对图中稀少数目标注预算下探索与利用核心挑战的图拓扑方法。在探索的过程中，通过平衡形式曲率（BFC）的核验核心点构建算法，选择能够反映图中簇结构的代表性初始标签。此外，使用BFC动态触发探索向利用的转变，并结合具有多尺度信息的局部图重布线策略，提高标签传播效果，同时保持稀疏性。实验表明，该方法在标签比例低时优于现有图基半监督基准方法。", "innovation": "提出了一种基于平衡形式曲率（BFC）的主动学习方法，通过构建核心点选取代表性的初始标签，实现探索与利用的平衡；使用BFC动态触发探索向利用的转变；采用局部图重布线策略提高标签传播效果并保持稀疏性。", "conclusion": "本文方法在低标签比例的情况下，相较于现有图基半监督方法，显著改进了分类任务中的性能。"}
{"llm_update_time": "20251101", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.25803", "html_url": "https://arxiv.org/abs/2510.25803", "title": "Mixture-of-Experts Operator Transformer for Large-Scale PDE Pre-Training", "title_en": "Mixture-of-Experts Operator Transformer for Large-Scale PDE Pre-Training", "authors": "Hong Wang,Haiyang Xin,Jie Wang,Xuanze Yang,Fei Zha,Huanshuo Dong,Yan Jiang", "background": "预训练已被证明在应对偏微分方程（PDE）问题中由于方程类型的异质性导致的数据稀缺和性能限制方面非常有效。然而，针对具有不同方程类型的PDE数据集的混合训练会带来高误差，且密集的预训练模型通过增加网络宽度或深度来扩大参数规模，会显著增加推理成本。因此，需要一种新的解决方案来有效地减少参数和控制推理成本，同时保持模型的性能和效率.", "innovation": "提出了一种新的Mixture-of-Experts Pre-training Operator Transformer（MoE-POT）模型，这是一种稀疏激活架构，可高效地扩展参数并控制推理成本。具体而言，该模型采用分层路由器门控网络，通过推理过程中动态选择16个专家网络中的4个路由专家来集中于特定于方程的特征。同时，还整合了2个共享专家，以捕捉PDE的共性特征并减少路由专家之间的冗余。最终输出是所有被激活的专家结果的加权平均值。在6个公开的PDE数据集上，用30M至0.5B参数进行预训练，具有90M激活参数的模型实现了与带有120M激活参数的现有模型相比最高40%的零样本错误率的减少。此外，还进行了可解释性分析，表明数据集类型可以从路由器门控网络的决策中推断出，验证了MoE架构的合理性和有效性.", "conclusion": "我们提出了MoE-POT模型，该模型利用高效稀疏激活架构有效地预训练大型PDE数据集。通过动态选择和集成不同的专家网络，不仅可以显著降低推理成本，还能保持模型的高性能。实验结果表明，该模型在零样本场景下的表现优于现有模型，并且可解释性分析进一步证明了MoE架构的有效性。"}
{"llm_update_time": "20251101", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.25808", "html_url": "https://arxiv.org/abs/2510.25808", "title": "PRESTO: 根据预像信息优化提示的黑盒大语言模型指令优化", "title_en": "PRESTO: Preimage-Informed Instruction Optimization for Prompting Black-Box LLMs", "authors": "Jaewon Chu,Seunghun Lee,Hyunwoo J. Kim", "background": "大语言模型（LLMs）在多个领域取得了显著的成功，主要是因为它们强大的指令遵循能力。这引发了对优化黑盒LLMs指令的兴趣，尽管它们的内部参数不可访问但因性能出色而被广泛使用。现有方法利用白盒LLMs从优化的软提示生成候选指令，但白盒LLMs经常将不同的软提示映射到相同的指令，导致重复查询。之前的研究将这种多对一映射视为阻碍优化效率的结构，而本文将其重新解释为加速优化的有用先验知识。", "innovation": "提出了PREimage-informed inSTruction Optimization (PRESTO)，一种利用软提示预像结构进行高效优化的新框架。PRESTO由三个关键组件组成：（1）得分共享，将评估得分与预像中的所有软提示共享；（2）基于预像的初始化，利用预像信息选择最大化搜索空间覆盖范围的初始数据点；（3）得分一致性正则化，要求每个预像内的预测保持一致。通过利用预像，PRESTO在相同的查询预算下有效获得了14倍多的评分数据，从而提高了优化效率。本文在33个指令优化任务上的实验结果证明了PRESTO的优越性能。", "conclusion": "实验结果表明，PRESTO在33个指令优化任务上的表现优于先前的方法。通过利用预像结构，PRESTO能够在相同查询预算下有效获得14倍多的评分数据，显著提高了优化效率。"}
{"llm_update_time": "20251101", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.25926", "html_url": "https://arxiv.org/abs/2510.25926", "title": "使用任务驱动表示法进行杂乱数据池的主动学习", "title_en": "Active Learning with Task-Driven Representations for Messy Pools", "authors": "Kianoosh Ashouritaklimi,Tom Rainforth", "background": "在数据点对目标任务的相关性差异较大的杂乱且未分类的数据池中，主动学习具有特别的潜力。当前最先进的主动学习方法依赖于固定且未监督的数据池表示方式，主要侧重于修改获取函数。然而，这种模型设置可能会影响对杂乱数据池的有效处理，因为这些未监督的表示可能无法捕捉到任务相关的潜在信息。因此，研究人员认为有必要改进含任务驱动的表示方式，这种表示能够在主动学习过程中根据已收集的标签进行定期更新。", "innovation": "提出了使用在主动学习过程中根据先前收集的标签进行周期性更新的任务驱动表示方法。具体来说，提出了两种策略：一种是从半监督学习直接学习表示，另一种是对初始未监督表示进行监督微调。这两种策略均提高了实际性能，优于使用未监督或预训练表示方法", "conclusion": "该研究通过引入任务驱动的表示方法以及学习策略显著改进了主动学习在处理杂乱数据池时的效果，说明了这些方法的有效性。"}
{"llm_update_time": "20251101", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.25867", "html_url": "https://arxiv.org/abs/2510.25867", "title": "MedVLSynther: 从医疗文档中使用生成器-验证器大模型合成高质量视觉问答", "title_en": "MedVLSynther: Synthesizing High-Quality Visual Question Answering from Medical Documents with Generator-Verifier LMMs", "authors": "Xiaoke Huang,Ningsen Wang,Hui Liu,Xianfeng Tang,Yuyin Zhou", "background": "医学问答（VQA）系统在处理需要跨图像和文本综合推理的医学问题方面变得越来越有潜力。然而，大型通用的VQA训练数据集的缺乏限制了训练这些系统的进程。现有数据集通常不直接来自医学文献，且质量参差不齐。", "innovation": "MedVLSynther 提出了一个基于生成器-验证器框架，直接从开放的生物医学文献中合成高质量的VQA问题。该框架包括生成和验证两个步骤，通过多阶段的验证保证生成的问题满足自包含、单一正确答案、临床有效性以及图像和文本的一致性等标准，从而生成可用于训练大模型的VQA数据集。研究应用该管道对PubMed Central中的数据进行处理，得到MedSynVQA数据集，包含大量的医学图像和相关问题。", "conclusion": "通过使用MedVLSynther合成的高质量数据进行训练，增强学习下的大模型在多个医学VQA基准测试中表现优异，某些场景下的准确率甚至超过了现有医学大模型。实验结果还表明，生成和验证过程都是不可或缺的，验证过的数据能够持续提升训练效果。同时，该方法保持了开放数据和模型的特性，提供了可审计、可复制且隐私保护的医学VQA数据训练途径。"}
{"llm_update_time": "20251101", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.25952", "html_url": "https://arxiv.org/abs/2510.25952", "title": "Modular Linear Tokenization (MLT)", "title_en": "Modular Linear Tokenization (MLT)", "authors": "Tcharlies Schmitz", "background": "传统编码方法如哈希和独热编码在处理高基数分类标识符时存在一些局限性，尤其是在维数和计算效率方面。这类问题在处理大规模数据集时尤为突出。", "innovation": "提出了一种名为Modular Linear Tokenization (MLT)的新技术，它通过有限域上的模算术和可逆线性变换保留了双射映射，从而实现了灵活的维度控制、可扩展的计算能力和完全可逆性，即使在数百万个标识符的情况下也能保持性能。", "conclusion": "实验结果显示，MLT在MovieLens 20M数据集上达到了与监督嵌入相当的预测性能，但所需的参数更少，训练成本更低。开源实现了MLT，可在PyPI和GitHub上找到。"}
{"llm_update_time": "20251101", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.25889", "html_url": "https://arxiv.org/abs/2510.25889", "title": "$\texttt{π_{RL}}$: 在流基视觉语言动作模型上的在线强化学习微调", "title_en": "$π_\\texttt{RL}$: Online RL Fine-tuning for Flow-based Vision-Language-Action Models", "authors": "Kang Chen,Zhihao Liu,Tonghe Zhang,Zhen Guo,Si Xu,Hao Lin,Hongzhi Zang,Quanlu Zhang,Zhaofei Yu,Guoliang Fan,Tiejun Huang,Yu Wang,Chao Yu", "background": "视觉语言动作（VLA）模型允许机器人从多模态输入中理解并执行复杂的任务。尽管最近的研究探索了使用强化学习（RL）来自动化劳动密集型数据收集过程以规模化监督微调（SFT），但将大规模RL应用于流动基VLA（例如$\texttt{π_0}$和$\texttt{π_{0.5}}$）仍然具有挑战性，主要原因在于迭代去噪过程导致的不可计算的动作对数似然性。因此，通过$\texttt{π_{RL}}$框架并行模拟训练流基VLA的挑战得到解决。$\texttt{π_{RL}}$框架实现了两个RL算法：（1）$\texttt{Flow-Noise}$将去噪过程建模为一个离散时间MDP，并使用可学习的噪声网络进行精确的对数似然性计算。 （2）$\texttt{Flow-SDE}$将去噪与智能体-环境交互整合，通过将ODE转化为SDE的方法实现高效的RL探索。该研究评估了$\texttt{π_{RL}}$在LIBERO和ManiSkill基准测试上的性能，证明了其在异构模拟环境下的扩展性多任务RL的有效性。", "innovation": "通过设计两个新的RL算法$\texttt{Flow-Noise}$和$\texttt{Flow-SDE}$，$\texttt{π_{RL}}$框架成功解决了大规模流基VLA训练中的不可计算动作对数似然性问题。$\texttt{Flow-Noise}$通过将去噪过程建模为MDP并使用可学习的噪声网络进行精确对数似然性计算。$\texttt{Flow-SDE}$则通过结合去噪过程和环境交互，并将ODE转换为SDE来提高高效RL探索的有效性。", "conclusion": "总体而言，$\texttt{π_{RL}}$框架在多任务RL中的应用取得了显著的性能提升，并成功验证了在线RL对于流基VLA的有效性，显示了$\texttt{π_{RL}}$在实际场景中的强大泛化能力。"}
{"llm_update_time": "20251101", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.25983", "html_url": "https://arxiv.org/abs/2510.25983", "title": "正确进行对比预测编码以实现互信息估计", "title_en": "Contrastive Predictive Coding Done Right for Mutual Information Estimation", "authors": "J. Jon Ryu,Pavan Yeddanapudi,Xiangxiang Xu,Gregory W. Wornell", "background": "InfoNCE 目标尽管与互信息（MI）有间接联系，但已成为 MI 估计的流行选择。然而，该论文指出 InfoNCE 并不是一个有效的 MI 估计器。", "innovation": "论文引入了一种简单的修改，称为 InfoNCE-anchor，它包含一个辅助锚类，可以实现一致性的密度比估计，从而得出一个具有明显减小偏差的插值 MI 估计量。此外，论文还使用适当的评分规则扩展了这种框架，当使用对数评分时，该框架可以恢复 InfoNCE-anchor 作为特例。这种表述统一了包括 NCE、InfoNCE 和 $f$-散度变体在内的广泛对比目标。", "conclusion": "从实验结果来看，虽然带有对数评分的 InfoNCE-anchor 能够获得最准确的 MI 估计，但在自我监督的表示学习实验中，锚点并没有提高下游任务的性能。因此，论文得出结论，对比预测编码的好处并不在于准确的 MI 估计，而是学习了结构化的密度比率。"}
{"llm_update_time": "20251101", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.25962", "html_url": "https://arxiv.org/abs/2510.25962", "title": "无数据训练神经网络的研究", "title_en": "On the Dataless Training of Neural Networks", "authors": "Alvaro Velasquez,Susmit Jha,Ismail R. Alkhouri", "background": "研究概述了在没有训练数据的情况下使用神经网络进行优化的研究。背景强调了这种方法的重要性，因为当前的数据驱动学习方法在某些领域仍处于初级阶段，并且在训练数据有限的应用场景中效果不佳，比如医学图像重建和科学应用。背景还指出了MLPs在解决线性程序方面早期的应用，以及它们在不同优化领域中的最新关注度。", "innovation": "创新点在于对神经网络架构在无数据应用中的重新参数化，具体方法包括全连接、卷积、图形和二次神经网络。此外，论文定义了无数据集的应用，并将其分为两种变体：架构无关的方法和架构特定的方法。讨论了无数据神经网络设置与其他相关概念的区别和相似点，如零样本学习、单次学习、优化的提升和过度参数化。", "conclusion": "结论是从研究总结出的两点因素解释了无数据集设置的动机：一是数据驱动的学习方法在某些领域还未发展完全；二是许多应用场景中的训练数据有限。论文通过对比分析无数据神经网络设置与其他概念，进一步明确了它们之间的区别和联系，为无数据优化提供了新的思路和方向。"}
{"llm_update_time": "20251101", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.25934", "html_url": "https://arxiv.org/abs/2510.25934", "title": "通过拓扑不变式的隐式感知实现鲁棒的GNN水印", "title_en": "Robust GNN Watermarking via Implicit Perception of Topological Invariants", "authors": "Jipeng Li,Yannning Shen", "background": "目前许多水印技术依赖于易被常见模型修改的后门触发机制，这会导致所有权模糊，因此需要一种新的方法来确保水印技术在常见的模型修改中保持有效性和鲁棒性。图神经网络（GNNs）是一种重要的知识产权工具，提出了一种新的水印方法——InvGNN-WM，旨在通过将所有权与模型对图不变量的隐式感知联系起来，避免使用后门触发器，从而实现无触发器的、黑盒验证，同时对任务性能影响极小。该方法在生命周期中表现出极高的鲁棒性，但在简单的知识蒸馏中会减弱水印的效果，采用带有水印损失的知识蒸馏则可以恢复水印强度。论文提供了不可感知性和鲁棒性的保证，并证明了完全删除水印是NP完全问题。", "innovation": "提出了一种名为InvGNN-WM的新型GNN水印方法，通过将所有权绑定到模型对图不变量的隐式感知，使得水印方法能够在常见的模型修改中保持有效和鲁棒。这种方法不依赖后门触发器，可以在黑盒验证中保持高精度，并且能够在各种无结构剪枝、微调和后训练量化等生命周期操作中保持强度，同时仅对基本任务性能有轻微影响。提供了解释方法不可感知性和鲁棒性的保障，并证明了完全去除标记是NP完全问题。此外，采用带有水印损失的知识蒸馏技术可以恢复水印强度。", "conclusion": "通过将GNN水印技术和模型对图不变量的隐式感知相结合，InvGNN-WM在保持知识产权的同时，能够抵抗常见的模型修改，并且在各类图和节点分类数据集上表现出色，优于基于后门触发器和压缩的技术。该方法对于模型剪枝、微调和后量化等操作具有很强的鲁棒性，但在简单的知识蒸馏中较易被削弱，但采用带有水印损失的知识蒸馏可以恢复这一效果。论文还提供了这一方法对于不可感知性和鲁棒性的理论保障，证明了完全删除是复杂的问题。"}
{"llm_update_time": "20251101", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.25954", "html_url": "https://arxiv.org/abs/2510.25954", "title": "应用和验证地理空间基础模型数据预测卫生设施项目输出——马达加斯加案例研究", "title_en": "Application and Validation of Geospatial Foundation Model Data for the Prediction of Health Facility Programmatic Outputs -- A Case Study in Malawi", "authors": "Lynn Metz,Rachel Haggard,Michael Moszczynski,Samer Asbah,Chris Mwase,Patricia Khomani,Tyler Smith,Hannah Cooper,Annie Mwale,Arbaaz Muslim,Gautam Prasad,Mimi Sun,Tomer Shekel,Joydeep Paul,Anna Carter,Shravya Shetty,Dylan Green", "background": "在低收入和中等收入国家（LMICs），常规健康数据的可靠性受到报告延迟和不完整覆盖的限制，为此需要探索新的数据来源和分析方法。GeoFMs通过综合多样化的时空行为数据来生成数学嵌入，能够高效地用于下游预测任务，为健康指标提供新的方法。本研究评估了三种GeoFMs嵌入源（Google人口动态基础模型（PDFM）、Google AlphaEarth（基于卫星图像）和移动电话详细记录（CDR））在马达加斯加15个常规健康项目输出中的预测性能，并与传统的地理空间插值方法进行了比较。利用XGBoost模型对来自552个卫生捕获区域的数据（2021年1月至2023年5月），使用R2进行评估，并采用80/20训练和测试数据集且通过5次交叉验证进行训练。", "innovation": "研究创新点在于通过对比和验证多种GeoFM数据源在预测健康设施项目输出中的表现，特别是使用不同的嵌入技术，如PDFM、AlphaEarth和CDR，提供了一种新的方法来加强常规健康信息系统的限制。研究展示了多GeoFM模型结合了三种嵌入来源的数据，为马达加斯加提供最稳健的数据预测，提高了一些健康和人口指标的预测能力。结果表明，GeoFM嵌入为选择性健康和人口指标的预测在LMIC提供了一定的改进。", "conclusion": "研究结论指出，多GeoFM模型整合了三种嵌入数据，是最优的选择，为马达加斯加的健康指标预测提供了稳健的结果。结果还表明，对于数据来源有限的预测目标（如结核病和营养不良病例），预测效果较差。研究证实，在LMIC中，整合多个GeoFM数据源是一个高效且有价值的方法，用于补充和加强受限的常规健康信息系统。"}
{"llm_update_time": "20251101", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.26014", "html_url": "https://arxiv.org/abs/2510.26014", "title": "离散时间生存分析的双混合专家框架", "title_en": "Dual Mixture-of-Experts Framework for Discrete-Time Survival Analysis", "authors": "Hyeonjun Lee,Hyungseob Shin,Gunhee Nam,Hyeonsoo Lee", "background": "生存分析是一种用于建模感兴趣事件发生时间的任务，在临床和生物医学研究中广泛应用。关键挑战是在建模患者异质性的同时，适应个体特性和时间动态的风险预测。", "innovation": "提出了一种双混合专家（MoE）框架用于离散时间生存分析。该框架结合了用于亚组感知表示学习的功能编码器MoE和利用患者特征和时间嵌入捕捉时间动态的危险MoE。这种方法灵活地与现有的基于深度学习的生存分析管线集成。", "conclusion": "在METABRIC和GBSG乳腺癌数据集上的实验表明，该方法在测试集上的一贯改进性能，提升时间依赖性C-指数高达0.04，在与其他框架（如Consurv）结合使用时还能够获得进一步的提升。"}
{"llm_update_time": "20251101", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.26000", "html_url": "https://arxiv.org/abs/2510.26000", "title": "Infrequent Exploration in Linear Bandits", "title_en": "Infrequent Exploration in Linear Bandits", "authors": "Harin Lee,Min-hwan Oh", "background": "该论文探讨了线性多臂老虎机中不频繁探索的问题，填补了完全自适应探索方法（例如UCB和撤销采样）与纯粹贪婪策略之间的空白。这些方法分别可能在每个时间步骤进行探索或在缺乏足够的上下文多样性时失效。在安全关键或昂贵的应用领域，连续探索可能是不切实际或不道德的，而纯粹贪婪策略通常无法在缺乏多种上下文的情况下成功。", "innovation": "论文引入了一个简单实用的框架INFEX，专门设计用于不频繁探索。INFEX在给定的时间表下根据基本探索策略执行探索操作，在其他时间则主要进行贪婪选择。理论上证明，只要探索频率超过对数阈值，INFEX就能达到实例依赖的后悔与标准证明高效算法相符。INFEX是通用的模块化框架，可以无缝集成任何完全自适应探索方法，具有广泛的适用性和易于采用的特点。此外，通过限制密集的探索计算只在不频繁的时间段进行，该方法还可以提升计算效率。", "conclusion": "实证评估验证了我们的理论发现，INFEX在 regret 性能和运行时间方面均优于现有方法。INFEX通过在不频繁的时间段执行密集的探索计算，提高了通用自适应探索方法的有效性和普适性。"}
{"llm_update_time": "20251101", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.25993", "html_url": "https://arxiv.org/abs/2510.25993", "title": "利用预测编码网络高效在线学习：利用时间相关性", "title_en": "Efficient Online Learning with Predictive Coding Networks: Exploiting Temporal Correlations", "authors": "Darius Masoum Zadeh-Jousdani,Elvin Hajizada,Eyke Hüllermeier", "background": "机器人系统在边缘操作需要高效的学习算法，能够连续适应变化环境的同时处理流式传感数据。传统的反向传播（Backpropagation）虽然有效，但与生物可实现性原则不符，且可能在持续适应场景下不理想。预测编码（Predictive Coding, PC）框架提供了生物可实现性的替代方案，具有局部、类似Hebb的学习规则，适合神经形态硬件实现。然而，PC的主要限制是训练期间需要多次推断迭代从而导致计算量过大。", "innovation": "我们提出了预测编码网络与时间平滑化（Predictive Coding Network with Temporal Amortization, PCN-TA），通过在时间帧间保存潜在状态，利用时间相关性，显著降低了计算需求，同时保持学习性能。在COIL-20机器人感知数据集上的实验表明，PCN-TA相比反向传播实现了10%更少的权重更新，并且对比基准的预测编码网络所需推断步骤减少了一半。这些效率提升直接降低了计算负担，向着边缘部署和资源受限的机器人系统的实时适应提供了支持。我们的方法基于生物启发，也使其成为未来神经形态硬件实现的有效候选，能够支持边缘的高效在线学习。", "conclusion": "我们的研究表明，PCN-TA能够通过利用时间相关性和保持次级状态，在降低计算需求的同时保持学习性能，这对于机器人系统在边缘的实际应用具有重要意义，有益于未来的神经形态硬件实现。"}
{"llm_update_time": "20251101", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.25986", "html_url": "https://arxiv.org/abs/2510.25986", "title": "一个通用且简化的一阶优化框架", "title_en": "A General and Streamlined Differentiable Optimization Framework", "authors": "Andrew W. Rosemberg,Joaquim Dias Garcia,François Pacaud,Robert B. Parker,Benoît Legat,Kaarthik Sundar,Russell Bent,Pascal Van Hentenryck", "background": "开发可以通过受限优化问题进行算法的训练、控制以及大规模决策系统，但在实践中仍面临挑战，主要由于优化求解器的专有性和接口的不兼容性问题。因此，迫切需要一种统一建模和自动求导的新框架，以便更好地支持上述应用场景中的要求和需求。该论文介绍了在Julia优化栈中集成了建模和求导的通用且优化的框架，它能够对凸性和非凸程序中的KKT系统求解和目标灵敏度进行前向和后向求导。其中强调了用户可以声明字段并直接对它们求导，即使参数出现在多个约束和目标中，也能消除格式层面的烦琐记录工作。", "innovation": "该论文提出了一种新的框架，该框架能够在Julia优化栈中通用地集成了建模和自动求导。这种方法通过微分KKT系统在标准正则假设下，计算前向和后向灵敏度。此外，该框架提供了一个内置的API，允许用户直接对所声明的参数求导，即使参数出现在多个约束和目标中也会如此，从而简化了用户的工作。这种方法在凸和非凸模型上进行了演示，包括经济调度、带有二次风险约束的均值-方差投资组合选择和非线性机器人逆运动学。此外，还展示了两个扩展研究，分别展示了在能源市场和端到端优化代理中的影响。", "conclusion": "该论文的结果表明，可微优化可以作为一种例行工具应用于实验、学习、校准和设计中，同时保留了标准JuMP建模实践，同时可访问广泛求解器的生态系统。这表明该框架可以满足当前大规模决策系统中的需求和挑战，进一步推进了该领域的研究和发展。"}
{"llm_update_time": "20251101", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.26025", "html_url": "https://arxiv.org/abs/2510.26025", "title": "通过国际象棋审视人类认知与AI的契合", "title_en": "Exploring Human-AI Conceptual Alignment through the Prism of Chess", "authors": "Semyon Lomaso,Judah Goldfeder,Mehmet Hamza Erol,Matthew So,Yao Yan,Addison Howard,Nathan Kutz,Ravid Shwartz Ziv", "background": "本文探讨了AI系统是否真正理解人类概念，还是仅仅模仿表面模式的问题。通过研究国际象棋，该文分析了一个270M参数的变压器模型，该模型达到了大师级水平。早期层编码了如中心控制和马棋 outpost等人类概念，准确率达到85%，但深层层尽管提高了性能，却开始使用脱离人类概念的表征，准确率降至50-65%。", "innovation": "作者引入了一个新的Chess960数据集，包含240个专家注释的位置，涉及6个战略概念。这个数据集用于测试模型在消除开局面理论后的概念鲁棒性，发现该模型依赖于记忆模式而非抽象理解。该文通过分层分析揭示了当前架构的基本紧张关系：取胜的表示与人类思维的表示相背离。", "conclusion": "随着AI系统优化性能，它们的发展出了一种更加离人类认知和思维模式相异的智能。这表明在主打创意应用的AI应用中，人类和AI的有效协作面临重大挑战。文章提供的数据集和代码可在以下链接获取：this https URL"}
{"llm_update_time": "20251101", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.26038", "html_url": "https://arxiv.org/abs/2510.26038", "title": "Do Students Debias Like Teachers? On the Distillability of Bias Mitigation Methods", "title_en": "Do Students Debias Like Teachers? On the Distillability of Bias Mitigation Methods", "authors": "Jiali Cheng,Chirag Agarwal,Hadi Amiri", "background": "知识蒸馏(KD)是一种有效的方法，用于模型压缩和模型间的知识传递。然而，其对增强模型的鲁棒性的影响研究尚不充分，特别是在处理数据分布外的错误关联以及保持模型在这些情况下性能方面。本文通过研究知识蒸馏对自然语言推理(NLI)和图像分类任务中去偏见能力的影响，旨在深入了解此问题。", "innovation": "本文首次大规模探讨了知识蒸馏对去偏见方法的影响及其内在机制。研究发现了几个关键发现：总体而言，知识蒸馏会削弱模型的去偏见能力；训练去偏见模型并不从教师知识中受益；尽管模型的整体鲁棒性可能保持不变，但不同类型偏见的变化却较大；并且指出了导致知识蒸馏后不同行为的内部注意力模式和电路。基于此，提出了一些有效的解决方案来提高去偏见方法的可传递性，包括开发高质量数据增强、实施迭代知识蒸馏以及用教师模型权重初始化学生模型。", "conclusion": "本文的研究结果加深了对知识蒸馏机制的理解，并为设计更好的去偏见方法提供了参考。"}
{"llm_update_time": "20251101", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.26068", "html_url": "https://arxiv.org/abs/2510.26068", "title": "学习几何：通过度量优化构建自适应流形模型的框架", "title_en": "Learning Geometry: A Framework for Building Adaptive Manifold Models through Metric Optimization", "authors": "Di Zhang", "background": "本文提出了一个超越传统参数优化的新机器学习范式，不同于传统方法在固定几何空间内寻找最优参数，本文的核心思想是将模型本身视为可变的几何实体，并对其进行优化，具体做法是在具有预定义拓扑结构的流形上优化度量张量场，以动态塑造模型空间的几何结构。为了实现这一点，构建了一个变分框架，损失函数平衡了数据保真度与流形内在几何复杂度，前者保证模型能有效解释观测数据，后者作为正则器，惩罚过于曲折或不规则的几何结构，以鼓励更简单的模型并防止过拟合。", "innovation": "提出了一个基于度量优化的方法，以动态塑造模型空间的几何结构。相较于传统的参数优化方法，这种方法在保持模型拓扑结构不变的情况下，能够提供显著更大的表达能力。为了应对这种无穷维优化问题的计算挑战，通过离散微分几何的方法，将连续流形离散化为三角网格，使用边长参数化度量张量，从而利用自动微分工具进行有效优化。理论分析揭示了该框架与广义相对论中的爱因斯坦-希尔伯特作用量之间的深刻类比关系，提供了一种物理解释“数据驱动几何”的优雅方式。", "conclusion": "本文为构建能够自主演化几何和拓扑结构的“元学习者”奠定了坚实的基础，并在科学模型发现和鲁棒表示学习等领域有广泛的应用前景。"}
{"llm_update_time": "20251101", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.26083", "html_url": "https://arxiv.org/abs/2510.26083", "title": "Nirvana: 具有任务感知记忆机制的专门通用模型", "title_en": "Nirvana: A Specialized Generalist Model With Task-Aware Memory Mechanism", "authors": "Yuhua Jiang,Shuang Cheng,Yihao Liu,Ermo Hua,Che Jiang,Weigao Sun,Yu Cheng,Feifei Gao,Biqing Qi,Bowen Zhou", "background": "专门通用模型（Specialized Generalist Models, SGMs）旨在保持广泛的性能的同时，在特定领域达到专家级别的表现。然而，现有的大型语言模型（LLMs）结构如Transformer、线性注意力以及混合模型并未采用由任务信息指导的专业化记忆机制。因此，本文介绍了一种名为Nirvana的SGM，它包含专业化记忆机制、线性时间复杂度，并在测试时提取任务信息。", "innovation": "1. 提出了任务感知记忆触发器（Trigger），它可以根据当前任务的需求灵活调整记忆机制。\n2. 设计了专业化记忆更新器（Updater），它可以动态根据触发器的指导记忆上下文。\n3. Nirvana在多个自然语言建模基准测试中表现接近或优于现有的LLM结构，并在复杂的医学MRI任务中取得了高质量的MRI重建效果以及生成准确的初步临床报告的能力。", "conclusion": "本文提出的Nirvana模型证实了任务感知记忆机制的有效性。特别是在专门领域，即使使用冻结的Nirvana主干模型，通过任务相关参数的调整，触发器仍能够引导模型适应MRI领域。Nirvana在MRI重建和生成初步临床报告方面表现优越。"}
{"llm_update_time": "20251101", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.26064", "html_url": "https://arxiv.org/abs/2510.26064", "title": "探索符号回归的标度法则", "title_en": "Towards Scaling Laws for Symbolic Regression", "authors": "David Otte,Jörg K.H. Franke,Frank Hutter", "background": "符号回归（SR）旨在发现能够解释观测数据的潜在数学表达式。这对于获取科学洞见和为表格数据生成内在可解释和泛化的模型都具有潜力。尽管基于深度学习的方法在符号回归中的表现已经与遗传编程方法不相上下，但计算规模的作用尚未得到很好的探索。基于语言建模中的标度法则，本文首次系统地探讨了符号回归的标度法则。研究者使用了伸缩性强的端到端变压器管道和精心生成的训练数据，在五个不同模型规模和处理器计算能力变为原来的三个数量级的情况下，研究了验证损失和解题率随计算能力的变化规律，发现它们都遵循清晰的幂律趋势。另外，研究还发现计算最优超参数缩放：最优批次大小和学习率随着模型尺寸的增大而增大，在我们所研究的范围内，每15个标记（token）对应一个参数是最优的，随着计算能力的提高，这一比率有轻微上升的趋势。", "innovation": "该研究首次系统地探索了符号回归的计算规模法则，使用了可伸缩的端到端变压器管道和精心设计的数据集。研究发现验证损失和解决效率与计算量之间的关系呈现出清晰的幂律趋势，并且明确了计算最优的超参数优化方法，包括最优批次大小和学习率的增长规律以及标记到参数的最佳比率。这意味着符号回归的性能可以从计算量的角度进行预测，为下一代符号回归模型的训练提供了宝贵的见解和指导.", "conclusion": "本文的结果表明，符号回归的性能可以从计算量的角度进行预测，并为我们训练下一代符号回归模型提供了重要的见解。"}
{"llm_update_time": "20251101", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.26076", "html_url": "https://arxiv.org/abs/2510.26076", "title": "New Money: 金融领域的合成数据生成综述", "title_en": "New Money: A Systematic Review of Synthetic Data Generation for Finance", "authors": "James Meldrum,Basem Suleiman,Fethi Rabhi,Muhammad Johan Alibasa", "background": "合成数据生成作为在机器学习应用中使用敏感财务数据的有前途的方法，已经引起了关注。通过利用生成模型，如生成对抗网络（GANs）和变分自编码器（VAEs），可以创建保留实际财务记录统计性质的人工数据集。这对于保护隐私和满足监管要求非常有帮助。尽管这个领域迅速增长，但迄今为止还没有全面的研究综述。这项系统性回顾汇集并分析了自2018年以来发表的72篇关于合成财务数据生成的研究，涵盖了财务信息的合成类型、采用的生成方法以及评估策略，以评估数据实用性和隐私性。研究表明，基于GAN的方法在文献中占主导地位，特别适用于生成时间序列市场数据和表格信贷数据。尽管已有多种创新技术显示出提高真实性和隐私保护的潜力，但在研究中对隐私保护措施的严格评估仍然不足。", "innovation": "该综述通过整合生成技术、应用和评估方法的概述，突出了关键的研究缺口，并为未来开发金融领域的稳健和隐私保护的合成数据解决方案提供了指导。特别指出的是，涉及多个多变的合成数据生成创新技术和方法，但仍然缺乏全面的隐私保护评估。", "conclusion": "该综述揭示了基于GAN的方法在生成合成财务数据方面的主导地位，同时指出现有研究中存在关于隐私保护的评估不足的问题。未来研究应该更加注重严格评估隐私保护措施，以确保合成财务数据的实用性和安全性。"}
{"llm_update_time": "20251101", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.26099", "html_url": "https://arxiv.org/abs/2510.26099", "title": "SAFE: 一种通过地球分层评估预测的新型人工智能气象评估方法", "title_en": "SAFE: A Novel Approach to AI Weather Evaluation through Stratified Assessments of Forecasts over Earth", "authors": "Nick Masi,Randall Balestriero", "background": "当前机器学习的主流范式是基于测试集中所有样本的平均损失来评估模型性能。这种地理空间平均的方法在气象和气候领域会忽视人类发展和地理分布的非均匀性。SAFE（Stratified Assessments of Forecasts over Earth）为评估大数据集上预测集的分层性能提供了工具，通过整合多种数据领域来按不同的地理网格属性进行分层：领土（通常指国家）、全球子区域、收入以及土地覆盖（陆地或水域）。", "innovation": "SAFE通过分层评估地球上的预测性能，能够细致地分析每个个体属性层面上的模型表现，例如每个单独的国家。这有助于揭示不同模型在不同地理和经济属性上的预测能力差异，并基于分层标准建立模型预报公平性的基准。相比之前的全球平均指标，SAFE为模型的预测性能和公平性提供了更具体、更细致的评估方法。", "conclusion": "通过SAFE，我们首次提问了哪些模型在不同地区表现最好或最差，以及哪些模型最公平。为了支持进一步在这方面的研究，SAFE已经开源，并可通过以下网址获得：this https URL"}
{"llm_update_time": "20251101", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.26086", "html_url": "https://arxiv.org/abs/2510.26086", "title": "LLMBisect：利用对比分析流水线突破bug二分法障碍", "title_en": "LLMBisect: Breaking Barriers in Bug Bisection with A Comparative Analysis Pipeline", "authors": "Zheng Zhang,Haonan Li,Xingyu Li,Hang Zhang,Zhiyun Qian", "background": "传统的补丁基础的bug二分法面临着几个显著的问题：例如，它们假设引起bug的提交（BIC）和补丁提交修改的是相同的函数，这并不总是真实的。它们通常仅依赖代码变更，而提交信息中往往包含大量与漏洞相关的信息。它们还基于简单的启发式方法（例如，假设BIC初始化了补丁中删除的行）并且缺乏对漏洞的逻辑分析。当前的bug二分法方法难以理解代码变更和提交文本数据之间的关系，这限制了其有效性。本研究旨在改进现有解决方案的局限性，特别关注如何利用大型语言模型（LLMs）的优势，以更好地实现代码变更和提交文本数据的分析。", "innovation": "论文提出了一种综合性的多阶段流水线方法，利用LLMs的优势改进了bug二分法。该方法包括:(1)充分利用补丁信息；(2)在上下文中比较多个候选提交；(3)通过一系列筛选步骤逐步缩小候选者范围。这种方法在准确性方面表现出了显著的优势，相较于最先进的解决方案，准确率提高了38%以上。进一步的实验结果表明，这种方法的多阶段流水线结构非常关键，相较于基于LLM的基本bug二分法，其准确率提高了60%。这种方法突破了当前的bug二分法方法在理解和处理代码变更和提交文本数据时的服务缺陷，体现了现代语言模型在软件安全中的应用潜力。", "conclusion": "论文展示了LLMBisect的优越性，通过综合使用LLMs处理补丁和提交内容，并通过多阶段筛选来逐步缩小候选范围，显著提高了bug二分法的准确性。这种基于LLMs的方法不仅在实际应用中具有更高的精度，而且显示了大型语言模型在解决软件安全领域复杂问题方面的巨大潜力。"}
{"llm_update_time": "20251101", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.26089", "html_url": "https://arxiv.org/abs/2510.26089", "title": "网络约束的多智能体车辆路由策略优化", "title_en": "Network-Constrained Policy Optimization for Adaptive Multi-agent Vehicle Routing", "authors": "Fazel Arasteh,Arian Haghparast,Manos Papagelis", "background": "城市道路网络中的交通拥堵会导致行程时间增加和排放量升高，尤其是在高峰期。单车辆的最佳静态网络最短路径算法（SPF算法）在动态和多车辆环境中表现不佳，导致路径一致，进一步加重拥堵。为了解决这一问题，本文探讨通过基于多智能体强化学习（MARL）的协调、网络感知车队导航机制来处理动态车辆路由问题。", "innovation": "首先提出了自适应导航（AN）模型，该模型利用每个交叉口代理基于本地交通状态和利用图注意力网络（GAT）模型的邻域状态提供路由建议。为提高大型网络中的可扩展性，进一步提出了基于关键交叉口的层级自适应导航（HHAN）模型，其中只有关键交叉口（枢纽）分配有代理。车辆在这些枢纽间进行路由，并使用SPF解决枢纽内部的微路由问题。此外，HHAN采用了集中训练与分散执行（CTDE）的层级架构，并结合了注意力机制进行中心化的决策聚合，同时利用流量感知的状态特征进行主动路径规划。实验结果表明，与SPF和学习基线相比，AN在平均行程时间上有所改进且能实现100%的路径成功率。而HHAN能扩展到包含数百个交叉口的大型网络，在高交通量情况下可实现高达15.9%的改进。", "conclusion": "研究表明，网络约束下的MARL模型在智能交通系统中的大规模、协调和knowledge-aware的导航方面有着巨大的潜力，可提供一种新的解决路面拥堵问题的方案。"}
{"llm_update_time": "20251101", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.26109", "html_url": "https://arxiv.org/abs/2510.26109", "title": "不要两次踏入同一条河：从试验和错误中学习推理", "title_en": "Do Not Step Into the Same River Twice: Learning to Reason from Trial and Error", "authors": "Chenming Tang,Hsiu-Yuan Huang,Weijie Liu,Saiyong Yang,Yunfang Wu", "background": "最近，强化学习能够验证奖励（RLVR）显著提升了大语言模型（LLMs）的推理能力。然而，现有的RLVR方法仅基于LLMs自身生成的回应进行训练，受到LLMs初始能力的限制，容易导致探索停滞，即LLMs无法解决更多训练问题且不能进一步从训练数据中学习。一些研究试图通过利用离策略解决方案来解决这一问题，但需要外部专家指导，这因专家资源有限而受到限制。研究人员指出，当前方法存在以下问题：探索停滞、过度生成回应和缺乏外部专家指导的需求。", "innovation": "本文提出了一种名为LTE（从试验和错误中学习推理）的方法，该方法提示LLMs它们之前生成的错误回答以及回应过长的问题，无需任何外部专家指导，这种方法能够有效缓解探索停滞的问题，改善训练过程中的开发和探索，实验结果表明LTE在复杂度较高的数学基准测试中优于相对策略优化（GRPO），在Pass@1和Pass@k指标上分别提升了6.38%和9.00%。", "conclusion": "LTE方法成功解决了探索停滞的问题，提高了LLMs的开发和探索能力，在多种数学基准测试中表现优于现有方法。"}
{"llm_update_time": "20251101", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.26148", "html_url": "https://arxiv.org/abs/2510.26148", "title": "STAR:一种移动和普及计算环境中基于Wi-Fi CSI的隐私保护和能效边缘AI框架", "title_en": "STAR: A Privacy-Preserving, Energy-Efficient Edge AI Framework for Human Activity Recognition via Wi-Fi CSI in Mobile and Pervasive Computing Environments", "authors": "Kexing Liu", "background": "现有的人体活动识别（HAR）方法在资源受限的嵌入式移动边缘环境中常常遇到计算效率低下、高延迟和可行性有限的问题。智能家庭、健康监测和移动物联网系统需要一种无接触的传感方法，但现有方法不能很好地满足这些需求。", "innovation": "论文提出了STAR（Sensing Technology for Activity Recognition）框架，这是一种边缘AI优化框架，结合了轻量级神经架构、自适应信号处理和硬件感知协同优化，以实现低功耗嵌入式设备上的实时、能效HAR。STAR框架中包括了一种流线型的门控循环单元（GRU）递归神经网络，减少模型参数33%，且保持有效的时序建模能力。此外，STAR还采用了多阶段预处理流水线，结合中值滤波、巴特沃斯低通滤波和经验模态分解（EMD），来降噪CSI幅度数据并提取空间-时间特征。STAR框架在Rockchip RV1126处理器上的运行结果证明其有效，处理速度为33 MHz，仅占用8%的CPU，相比基于CPU的执行快六倍。STAR系统实现的响应延迟低于1秒，能耗低，确保实时、隐私保护的HAR。", "conclusion": "STAR框架为移动和普及计算环境中的HAR提供了一个实用、可扩展的解决方案，特别适用于智能家庭、健康监测和移动物联网系统，同时还解决了现有方法中的许多问题。"}
{"llm_update_time": "20251101", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.26159", "html_url": "https://arxiv.org/abs/2510.26159", "title": "复杂性胜于分割：评估集成与混合方法在工业时间序列异常检测中的有效性", "title_en": "Segmentation over Complexity: Evaluating Ensemble and Hybrid Approaches for Anomaly Detection in Industrial Time Series", "authors": "Emilio Mastriani,Alessandro Costa,Federico Incardona,Kevin Munari,Sebastiano Spinello", "background": "本文研究了在多变量工业时间序列（以汽轮机系统为例）中高级特征工程和混合模型架构对故障检测的有效性，重点评估变化点统计特征、基于聚类的子结构表示以及混合学习策略对检测性能的影响。", "innovation": "研究采用了一种简单的方法进行集成学习，即Random Forest与XGBoost的组合，通过对数据段进行训练，取得了优越的性能。尽管复杂的模型理论上具有较高吸引力，但在实际应用中性能不如简单的模型，这表明在面对高度不平衡且具有时间不确定性的数据时，模型的简单性结合优化的分割方法能够超越更复杂的结构，提供更高的鲁棒性、可解释性和操作实用性。", "conclusion": "研究发现，在数据高度不平衡且时间不确定性较高的场景中，简单的模型结合优化的分割方法可以超越更复杂的架构，提供更多鲁棒性、可解释性和操作上的实用性。"}
{"llm_update_time": "20251101", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.26157", "html_url": "https://arxiv.org/abs/2510.26157", "title": "通过子结构感知对齐连接分子和文本描述", "title_en": "Bridging the Gap Between Molecule and Textual Descriptions via Substructure-aware Alignment", "authors": "Hyuntae Park,Yeachan Kim,SangKeun Lee", "background": "分子和文本表示学习由于其增强化学信息理解的潜力而越来越受到关注。然而，现有模型在捕捉分子和其描述之间的细微差别方面往往存在困难，因为它们缺乏学习分子子结构和化学短语之间细粒度对齐的能力。", "innovation": "为了解决这一限制，我们提出了MolBridge，这是一种基于子结构感知对齐的新分子-文本学习框架。具体来说，我们通过分子子结构和化学短语衍生的附加对齐信号增强了原始分子-描述对。为了有效利用这些丰富对齐信号进行学习，MolBridge采用子结构感知对比学习，并结合了一种自我精炼机制来过滤出噪声对齐信号。", "conclusion": "实验结果表明，MolBridge能够有效捕捉细粒度对应关系，并在一系列分子基准测试中优于最先进的基线模型，突出了子结构感知对齐在分子-文本学习中的重要意义。"}
{"llm_update_time": "20251101", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.26146", "html_url": "https://arxiv.org/abs/2510.26146", "title": "maxVSTAR：最大化自适应的闭环边缘模型适应以实现鲁棒的人体活动识别", "title_en": "maxVSTAR: Maximally Adaptive Vision-Guided CSI Sensing with Closed-Loop Edge Model Adaptation for Robust Human Activity Recognition", "authors": "Kexing Liu", "background": "WiFi频道状态信息（CSI）-基于的人体活动识别（HAR）提供了一种保护隐私、无需设备的人体活动感知解决方案，适用于智能环境。然而，其在边缘设备上的部署受到了领域偏移（Domain Shift）的严重限制，这会导致在环境和硬件条件变化时识别性能下降。因此，为了克服这一限制，该论文提出了maxVSTAR，这是通过闭环视觉引导模型适应框架自主缓解领域能移的一种技术，适用于边缘部署的CSI感知系统。maxVSTAR结合了跨模态教师-学生架构，通过一种高精度的YOLO视觉模型为CSI数据流提供实时活动标签，从而实现边缘直接对一种轻量级HAR模型（称作STAR）的自主在线微调。这种闭环的重新训练机制允许STAR在无需人工干预的情况下持续适应环境变化。", "innovation": "maxVSTAR是一种闭环的视觉引导模型适应框架，通过使用一种高精度的YOLO视觉模型为CSI数据流提供实时活动标签，实现边缘STAR模型的自主在线微调。其核心在于闭环的重新训练机制，使得STAR可以在无需人工干预的情况下持续适应环境变化。这一框架在未校准硬件上表现出了显著的自我监督模型适应能力，验证了其在隐私意识物联网环境中动态适应的潜力，建立起适用于网络边缘长时间自动HAR的可扩展框架。", "conclusion": "通过对未校准硬件的详细实验，当基线STAR模型的识别准确率从93.52%下降到49.14%时，maxVSTAR经过一次视觉引导的适应周期后将准确率恢复至81.51%。这证实了该系统在隐私保护的物联网（IoT）环境中动态自监督模型适应的能力，展示了其在汇总边CSI感知实现长期自动HAR方面的实用性和可行性。"}
{"llm_update_time": "20251101", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.26219", "html_url": "https://arxiv.org/abs/2510.26219", "title": "预后空间基于抽样最优控制的LLMs测试时对齐", "title_en": "Test-Time Alignment of LLMs via Sampling-Based Optimal Control in pre-logit space", "authors": "Sekitoshi Kanai,Tsukasa Yoshida,Hiroshi Takahashi,Haru Kuroki,Kazumune Hashimoto", "background": "大语言模型（LLMs）在测试时的对齐吸引了关注，因为对LLMs进行微调会导致高昂的计算成本。", "innovation": "提出了基于抽样最优控制的预后空间自适应重要抽样（AISP）对齐方法。AISP 通过在预后输出上应用高斯扰动，以最大化扰动均值的预期奖励来实现对齐。", "conclusion": "AISP 方法在使用的样本数量较少的情况下获得了更高的奖励，相比其他基于奖励的测试时对齐方法表现更优。"}
{"llm_update_time": "20251101", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.26184", "html_url": "https://arxiv.org/abs/2510.26184", "title": "一个基于博弈论的空间-时间强化学习框架，用于协作型公共资源分配", "title_en": "A Game-Theoretic Spatio-Temporal Reinforcement Learning Framework for Collaborative Public Resource Allocation", "authors": "Songxin Lei,Qiongyan Wang,Yanchen Zhu,Hanyu Yao,Sijie Ruan,Weilin Ruan,Yuyu Luo,Huaming Wu,Yuxuan Liang", "background": "公共资源配置涉及到城市的基础设施、能源和交通的有效分配，以满足社会需求。现有方法通常独立优化各个资源的移动，而忽略它们的容量限制。这限制了资源分配的实际效果。因此，提出一项新的研究课题：协作型公共资源分配（CPRA），它明确地纳入了容量约束和现实场景中的时空动态。现有方法未能有效解决这个问题，特别是对于NP难问题的纳什均衡点近似计算缺乏有效的理论基础和实际方案。", "innovation": "提出了一种新的方法，即基于博弈论的空间-时间强化学习框架（GSTRL），用于解决CPRA问题。该方法主要贡献在于：1) 将CPRA问题公式化为一个潜在博弈，证明潜在函数与最优目标之间没有差距，为近似计算NP难问题的纳什均衡点奠定了坚实的理论基础；2) GSTRL框架有效捕捉了整体系统的时空动态特性。通过在两个真实场景的数据集上进行实验验证，GSTRL显示出优越的性能。源代码在一个附录中提供。", "conclusion": "该研究通过GSTRL框架成功解决了CPRA问题，不仅提供了理论上的支持，还通过实际实验数据验证了其优势。此方法为解决公共资源配置的实际问题提供了一种新的思路。"}
{"llm_update_time": "20251101", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.26266", "html_url": "https://arxiv.org/abs/2510.26266", "title": "生成模型中的最可能插值", "title_en": "Likely Interpolants of Generative Models", "authors": "Frederik Möbius Rygaard,Shen Zhu,Yinzhu Jin,Søren Hauberg,Tom Fletcher", "background": "生成模型允许可控生成和模型检查，但大多数生成模型在没有对模型或数据维度提出限制性假定的情况下缺乏一个基本的插值概念。本文探讨了生成模型插值的背景，并指出现有方法在应用场景上存在限制。", "innovation": "本文提出了一个新的通用插值方案，该方案可以针对不同的度量和概率分布找到最有可能的过渡路径。该方案将插值视为一种受限于适当数据分布的测地线，并提出了一种无需额外训练即可计算这些曲线的新算法。理论分析表明，在合适的黎曼度量下，该方法可以被视为一种局部测地线。", "conclusion": "定量结果表明，本文的方法能够在多种模型和数据集上遍历更高密度区域，超越了现有的基线方法。"}
{"llm_update_time": "20251101", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.26185", "html_url": "https://arxiv.org/abs/2510.26185", "title": "Accumulative SGD 影响估计对于数据归因", "title_en": "Accumulative SGD Influence Estimation for Data Attribution", "authors": "Yunxiao Shi,Shuo Yang,Yixin Su,Rui Zhang,Min Xu", "background": "现代以数据为中心的AI需要对每个样本的影响有精确的了解。标准的SGD-IE通过将每个周期的替代效应进行求和来近似留一法效果，并忽略了跨周期的累积效应，这会导致关键样例的排名错误。本文探讨了如何通过轨迹感知估计器ACC-SGD-IE来传播留一法干扰，并在每个步骤更新累积影响状态。在此基础上，我们在平滑强凸和光滑非凸设置中分别得到了几何误差收缩和误差边界收紧的结果，并且批量大小越大，常数越小。在Adult、20 Newsgroups和MNIST数据集上的实验证明，ACC-SGD-IE能提供更准确的影响估计，尤其是在长期训练中表现更佳。此外，这种更可靠的噪声样本标记方式使得在使用ACC-SGD-IE清洁后的数据训练出的模型在下层数据清洗中表现更好，从而优于使用SGD-IE清洁后的模型", "innovation": "提出了一种轨迹感知估计器ACC-SGD-IE，该方法能够传播留一法干扰并更新累积影响状态。此方法能有效收敛几何误差，在平滑强凸设置下有效收敛，在平滑非凸设置下紧缩误差范围，并且通过增加批量大小可以进一步降低误差常数。实验结果表明，ACC-SGD-IE能提供更准确的影响估计，尤其是在长期训练中。此外，它还能更好地标记噪声样本，进一步提高模型性能", "conclusion": "ACC-SGD-IE能够提供准确的样本影响估计，尤其是在较长的训练过程中，这对数据清洗和下游任务非常有用。它提高了模型的鲁棒性和准确性。"}
{"llm_update_time": "20251101", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.26243", "html_url": "https://arxiv.org/abs/2510.26243", "title": "Angular Steering: 通过激活空间旋转实现行为控制", "title_en": "Angular Steering: Behavior Control via Rotation in Activation Space", "authors": "Hieu M. Vu,Tan M. Nguyen", "background": "在确保大型语言模型的安全和可靠部署时，控制特定行为并在不损害其通用能力的情况下是一个核心挑战。目前的方法，如向量添加和方向性消减，受限于由激活和特征方向定义的二维子空间，这使得它们容易受到选择参数的影响，并可能导致激活空间中的意外交互，从而影响无关特征。", "innovation": "引入了Angular Steering，一种新颖且灵活的行为调节方法，通过在固定二维子空间内旋转激活来实现。将操控目标转化为几何旋转向目标行为方向或远离，提供对行为如拒绝和顺从的连续微调。还提出了Adaptive Angular Steering，这是一种选择性变体，仅旋转与目标特征对齐的激活，进一步提高了稳定性和一致性。Angular Steering将现有的增广和正交化技术统一到一个几何旋转框架下，简化了参数选择，并在更大的调整范围内保持模型稳定性。", "conclusion": "跨多个模型家族和规模的实验表明，Angular Steering能够在确保一般语言建模性能的同时实现稳健的行为控制，突显了其灵活性、泛化能力和鲁棒性，优于先前的方法。有关代码和资源可在以下链接找到。"}
{"llm_update_time": "20251101", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.26278", "html_url": "https://arxiv.org/abs/2510.26278", "title": "分布式多目标黑盒优化以实现扩散模型推理时间多目标生成", "title_en": "Distributional Multi-objective Black-box Optimization for Diffusion-model Inference-time Multi-Target Generation", "authors": "Kim Yong Tan,Yueming Lyu,Ivor Tsang,Yew-Soon Ong", "background": "扩散模型在学习复杂数据分布方面表现出色，这促进了它们在高维多目标黑盒优化问题中的应用。现有的方法通常将外部优化循环（如进化算法）应用于扩散模型，但这些方法将扩散模型视为黑箱精化器，忽视了扩散生成过程中的内部分布转换，限制了其效率。", "innovation": "提出了一种新的推理时间多目标生成（IMG）算法，该算法在推理时间优化扩散过程，生成同时满足多个目标的样本。IMG 在扩散生成过程中根据预期的多目标值进行加权重采样，确保扩散生成的样本符合我们期望的多目标玻尔兹曼分布。IMG 的多目标玻尔兹曼分布具有有趣的对数似然解释，它是分布式多目标优化问题的最佳解。", "conclusion": "在多目标分子生成任务中实现 IMG。实验表明，IMG 只需一个生成过程，就能显著高于需要数百个扩散生成的基线优化算法获得更高的超体积。值得注意的是，我们的算法可以被视为优化的扩散过程，并可以集成到现有方法中以进一步提高其性能。"}
{"llm_update_time": "20251101", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.26284", "html_url": "https://arxiv.org/abs/2510.26284", "title": "Empirical Bayesian Multi-Bandit Learning", "title_en": "Empirical Bayesian Multi-Bandit Learning", "authors": "Xia Jiang,Rong J.B. Zhu", "background": "多任务学习在上下文臂赛问题中的研究引起了广泛关注，因为这种学习方式能够通过共享结构和任务特定异质性来增强多个相关任务的决策能力。现有方法往往忽视了臂赛间协方差结构的学习，本文旨在通过引入经验贝叶斯方法来估计先验协方差矩阵，从而更有效地在多臂赛中实现信息共享和适应性。", "innovation": "本文提出了一个新颖的分层贝叶斯框架，用于在各种臂赛实例中学习。该框架通过分层贝叶斯模型捕捉不同臂赛实例之间的异质性和相关性，从而实现有效的信息共享，并适应实例特定的变化。此外，本文还开发了两种高效算法：ebmTS（经验贝叶斯多臂赛泰勒采样）和ebmUCB（经验贝叶斯多臂赛上确界），并提供了所提算法的频率主义后悔上界，填补了多臂赛问题研究领域的空白。", "conclusion": "在合成和真实世界数据集上的广泛实验表明，本文提出的方法在复杂环境中表现出优越的性能，特别是在累积后悔方面显著低于现有技术，这突出了其在多臂赛中平衡探索与利用方面的有效性。"}
{"llm_update_time": "20251101", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.26230", "html_url": "https://arxiv.org/abs/2510.26230", "title": "MPRU：作为分类流水线输出过滤器的模块化投影重分布去学习", "title_en": "MPRU: Modular Projection-Redistribution Unlearning as Output Filter for Classification Pipelines", "authors": "Minyi Peng,Darian Gunamardi,Ivan Tjuawinata,Kwok-Yan Lam", "background": "现有的机器去学习（MU）方法通常关注理论公式的制定或优化目标以实现知识的消除，但在实际应用中，这些解决方案往往面临可扩展性问题，并且需要对原始数据集和模型有完全访问权限。相比之下，本文将分类训练视为一种顺序学习过程，每个类别依次学习，这种方式称为归纳方法。去学习通过反转最后一个训练序列来实现，这种方法允许在不接触原始数据集或模型的条件下进行去学习，解决了现有方法的挑战，使得解决方案可以在不影响性能的情况下，以模块化和模型无关的方式引入到现有的分类流水线中，实现最少的修改，并降低大量的计算成本，从而提高了系统的适用性、可扩展性和兼容性。", "innovation": "本文提出了一种新的去学习方法——MPRU，通过引入投影重分布层，实现了分类模型的去学习。这种方法不需要对原始数据集或模型有完全访问权限，可以通过模块化的方式引入以较少的改动对现有分类流水线进行改进，降低了大量的计算成本，适用于实际应用环境。", "conclusion": "通过在多个数据集上进行的实验（包括图像数据集（CIFAR-10/100使用基于CNN的模型）和表格数据集（Covertype使用基于树的模型）），结果表明，MPRU能将以低得多的计算成本获得与从头训练相同的效果，且不会影响输出性能，进一步证明了该方法的可行性、可扩展性和系统的兼容性。"}
{"llm_update_time": "20251101", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.26301", "html_url": "https://arxiv.org/abs/2510.26301", "title": "带有主动数据增强的离线偏好评价聚类", "title_en": "Offline Clustering of Preference Learning with Active-data Augmentation", "authors": "Jingyuan Liu,Fatemeh Ghaffari,Xuchuang Wang,Mohammad Hajiesmaili,Carlee Joe-Wong", "background": "偏好评价从成对反馈中学习是一种在强化学习带有人类反馈和推荐等领域广泛采用的框架。然而，在许多实际场景中，用户交互有限且成本高昂，使得离线偏好评价变得必要。此外，现实中的偏好评价往往涉及具有不同偏好的用户。例如，来自不同背景的注释者可能会对同一响应有不同的排名。这种设置带来了两类核心挑战：（1）在数据维度不平衡的情况下识别用户间的相似性，有效聚合数据；（2）处理不平衡的离线数据，其中一些偏好维度被欠代表。", "innovation": "论文提出了解决离线偏好评价问题的方法，名为Off-C$^2$PL和A$^2$-Off-C$^2$PL，旨在最大化测试用户的价值。Off-C$^2$PL专为纯离线设置设计，仅依赖离线数据。A$^2$-Off-C$^2$PL则扩展到含主动数据增强的设置，允许学习者选择少量的额外主动数据，这些数据是基于Off-C$^2$PL学习到的聚类结构，特别针对测试用户偏好信息量最小的维度进行选择，证明这些主动收集的数据比离线数据更有效。", "conclusion": "通过在合成和真实数据集上的模拟验证了理论结果，论文提出了能够有效处理用户偏好的数据不平衡问题的方法，并通过理论分析和实验验证了这些方法的有效性。"}
{"llm_update_time": "20251101", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.26188", "html_url": "https://arxiv.org/abs/2510.26188", "title": "从住院患者医疗索赔数据预测所有原因的再入院", "title_en": "Predicting All-Cause Hospital Readmissions from Medical Claims Data of Hospitalised Patients", "authors": "Avinash Kadimisetty,Arun Rajagopalan,Vijendra SK", "background": "降低可预防的医院再入院是监管机构、医疗提供者和政策制定者在提高医疗服务质量和降低医疗费用方面的一项国家优先事项。再入院率被用作衡量医院提供医疗服务质量的标准。本项目使用机器学习技术（如逻辑回归、随机森林和支持向量机），通过分析医疗索赔数据来识别预测全因再入院的重要的人口统计学和医学因素。由于医疗索赔数据具有高维度特性，项目中还采用了主成分分析技术进行降维处理，以此构建预测模型。模型的性能通过曲线下面积（AUC）进行了比较和评估，随机森林模型表现最佳，其次是逻辑回归和支持向量机模型。这些模型可以用来识别导致再入院的关键因素，并帮助确定需要关注的患者群体，从而减少再入院率，最终降低医疗成本和提高医疗服务的质量。", "innovation": "项目创新性地使用了机器学习技术（如逻辑回归、随机森林和支持向量机）和主成分分析进行医疗索赔数据的降维处理，建立了用于预测全因再入院的模型。项目还通过对比不同模型的性能，提出了效率较高的预测模型解决方案，这对改善医疗服务质量和控制医疗成本具有重要意义。", "conclusion": "研究结果显示，随机森林模型在预测全因再入院方面表现最佳，其次是逻辑回归和支持向量机模型。这些模型能够帮助识别导致再入院的关键因素，并通过聚焦于这些患者来减少再入院的可能性，进而降低医疗成本和提高医疗服务水平。"}
{"llm_update_time": "20251101", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.26323", "html_url": "https://arxiv.org/abs/2510.26323", "title": "QUBO基支持向量机训练中权重离散化的影响", "title_en": "On the Impact of Weight Discretization in QUBO-Based SVM Training", "authors": "Sascha Mücke", "background": "支持向量机（SVM）的训练可以被构造成一个QUBO问题，使得量子退火能够用于模型优化。本文研究了量子退火中量子比特的数量（与对偶权重的离散化级别相关）如何影响不同数据集的预测性能。", "innovation": "本文比较了基于QUBO的支持向量机训练方法与经典的LIBSVM求解器，并发现即使在低精度的QUBO编码下（例如，每个参数1位），也能获得具有竞争力，甚至更好的准确性。研究指出了调节支持向量选择的重要性超过它们精确度的考虑。", "conclusion": "虽然当前硬件限制了可解的QUBO规模，但研究结果表明随量子设备的发展，量子退火在支持向量机训练中具有潜在的高效性。"}
{"llm_update_time": "20251101", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.26302", "html_url": "https://arxiv.org/abs/2510.26302", "title": "从词元层面因果视角理解视觉语言组合性难题", "title_en": "Understanding Hardness of Vision-Language Compositionality from A Token-level Causal Lens", "authors": "Ziliang Chen,Tianang Xiao,Jusheng Zhang,Yongsen Zheng,Xipeng Chen", "background": "CLIP通过在共享嵌入空间中对齐图像和文本实现了强跨模态泛化，但在对象、属性和关系的组合性推理方面表现不佳，类似于袋式词语匹配器。之前的研究通常将文本建模为单一向量，这掩盖了令牌级别的结构，未能解释如提示敏感性和在硬负面上的失败现象。CLIP的对比学习目标在句级和词级结构因果模型（SCM）下的可识别性问题仍未解决，即token粒度提供了解释CLIP组合性脆弱性的首个原则性理论：组合性不可识别性。文章进一步证明了伪最优的文本编码器尽管实现了模态不变的对齐，却对SWAP、REPLACE和ADD操作中的原子概念表现出证明可忽略的敏感性，导致无法区分正确的描述和硬负样本，尽管优化的是相同的训练目标。文章还通过模态差距将语言侧的不可识别性与视觉侧的失败联系起来，并展示了迭代组合操作的累积难度，提出了改进负样本挖掘策略的动机。", "innovation": "提出了一个token-aware因果表示学习框架，基于顺序语言-token结构因果模型（SCM），将块可识别性扩展到令牌化文本，证明了CLIP的对比目标在句级和词级结构因果模型下的模态不变潜在变量可恢复性。该研究首次利用token粒度解释了CLIP的组合性脆弱性问题，即组合非识别性，并证明了存在伪最优文本编码器在原子概念的SWAP、REPLACE和ADD操作中的可证明无敏感性，从而离线正确描述和硬负样本之间的差异，尽管优化相同的训练目标。", "conclusion": "文章提出了token-aware因果表示学习框架，解释了CLIP在组合性推理方面的组合性脆弱性问题，并进一步展示了如何通过改进的负样本挖掘策略解决这一问题。"}
{"llm_update_time": "20251101", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.26328", "html_url": "https://arxiv.org/abs/2510.26328", "title": "Agent Skills 使新型且极为简单的提示注入成为可能", "title_en": "Agent Skills Enable a New Class of Realistic and Trivially Simple Prompt Injections", "authors": "David Schmotz,Sahar Abdelnabi,Maksym Andriushchenko", "background": "持续学习在语言模型（LLMs）中的实现仍然是一个未解决的研究挑战。最近，一家领先的LLM公司推出了Agent Skills框架，这是一种通过存储在简单Markdown文件中的指令来赋予代理新的知识的技术。尽管Agent Skills具有用处，但该论文指出它们存在根本性安全漏洞，因为它们可以轻松地引起提示注入。", "innovation": "论文展示了隐藏恶意指令的方法，这些指令可以通过长的Agent Skill文件和引用的脚本来泄露敏感数据，如内部文件或密码。此外，研究表明，即使是看似无害的任务特定审批，选择“不要再次询问”选项也可以绕过系统级护栏，导致相关但有害的操作。", "conclusion": "尽管有持续的研究努力和增强的模型能力，前沿语言模型仍可以在现实场景中受到极为简单的提示注入的攻击。该文代码可在以下链接中找到：this https URL"}
{"llm_update_time": "20251101", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.26311", "html_url": "https://arxiv.org/abs/2510.26311", "title": "数据特定建模和对齐的模型反演在无数据连续学习中的应用", "title_en": "Model Inversion with Layer-Specific Modeling and Alignment for Data-Free Continual Learning", "authors": "Ruilin Tong,Haodong Lu,Yuhang Liu,Dong Gong", "background": "连续学习(CL)的目标是在访问之前数据的前提下，增量训练模型以执行一系列任务，同时保持先前任务的性能。然而，由于隐私或安全限制，存储和回放数据通常是不可行的。数据无关的连续学习(DF-CL)旨在更新模型而不接触之前的数据。传统的DF-CL方法主要依靠正则化来更新模型，但在预测模型中，通过压缩输出标签生成输入数据会导致合成数据与真实数据的偏移，且无法将合成数据回放到模型中。同时，反演过程通常计算成本高，因为每个步骤都需要通过整个模型反向传播。这些问题在大型预训练模型（如CLIP）中尤为明显，从而限制了DF-CL的应用效率和可行性。鉴于此，作者提出了一种分层模型反演（PMI）方法，以提高效率，并通过建模类特征来减轻特徵偏移，从而实现跨多种连续学习设置的有效和兼容性", "innovation": "作者提出了一种分层模型反演（Per-layer Model Inversion, PMI）方法，以及一种特征建模策略来解决合成数据与真实数据之间特征偏移的问题，通过仅对模型的单层进行优化，PMI提供了对完整模型反演的强大初始化，显著减少了迭代次数。通过引入高斯分布和对比模型来刻画类特征，确保合成和真实特征之间的对齐，实现了新类别的连续学习。这种方法不仅高效，而且在多种连续学习设置下表现出色且具备兼容性", "conclusion": "该研究通过分层模型反演和特征建模策略，解决了数据无关连续学习中的特征偏移和计算效率问题，使得PMI和特征建模结合的方法在多个连续学习场景中表现出强效且兼容的效果。"}
{"llm_update_time": "20251101", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.26342", "html_url": "https://arxiv.org/abs/2510.26342", "title": "带有干涉约束的线性因果发现", "title_en": "Linear Causal Discovery with Interventional Constraints", "authors": "Zhigao Guo,Feng Dong", "background": "因果推理和模型在医疗、生物科学等领域尤为重要。现有因果发现方法虽然允许施加结构性约束，但仍有可能得出错误的因果结论。因此，引入带有高阶因果知识的干涉约束非常必要，以确保因果模型能够正确反映已知的因果影响。", "innovation": "该论文提出了一种新颖的因果发现概念——干涉约束。不同于需要直接干预变量的干预数据，干涉约束以不等式形式编码更高层次的因果知识。为此，该论文提出了一个用于量化线性因果模型总因果效应的度量，并将问题形式化为一个约束优化任务，采用两阶段的约束优化方法解决。这种方法不仅提高了模型的准确性和一致性，还促进了新因果关系的发现。", "conclusion": "实验结果表明，结合干涉约束可以改进模型的准确性并确保与已知发现的一致性，使模型更具解释性。此外，这种方法还能够促进新因果关系的发现，这在不会干预变量的情况下也可能代价高昂。"}
{"llm_update_time": "20251101", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.26303", "html_url": "https://arxiv.org/abs/2510.26303", "title": "Per样本Adam在可分数据集上的隐式偏置：远离全批量区间", "title_en": "Implicit Bias of Per-sample Adam on Separable Data: Departure from the Full-batch Regime", "authors": "Beomhan Baek,Minhak Song,Chulhee Yun", "background": "Adam [Kingma和Ba, 2015]已成为深度学习中的实际优化器，但对其理论理解仍有限。先前的研究表明，Adam倾向于与$\boldsymbol{\text{\textlabyrinth} _\text{∞}}$-几何保持一致的解，但这仅限于全批量区间。本文研究了增量Adam（每步使用一个样本）在逻辑回归对线性可分数据集中的隐式偏置，发现其偏置可能偏离全批量行为。论文构建了一个特定结构的数据集，证明增量Adam可以收敛到$\boldsymbol{\text{\textlabyrinth} _2}$-最大边际分类器，而全批量Adam则倾向于$\boldsymbol{\text{\textlabyrinth} _\text{∞}}$-最大边际偏置。对于一般数据集，论文开发了一个代理算法来捕捉增量Adam在$\boldsymbol{\boldsymbol{\beta}}_2 \rightarrow 1$时的极限行为，并通过数据依赖的对偶固定点形式来表征其收敛方向。最后，论文证明了与Adam不同，当$\boldsymbol{\beta}$足够接近1时，Signum [Bernstein等人, 2018] 对任何批量大小都会收敛到$\boldsymbol{\text{\textlabyrinth} _\text{∞}}$-最大边际分类器。这强调了Adam的隐式偏置不仅取决于批量策略，还取决于数据集。", "innovation": "论文研究了增量Adam在逻辑回归对线性可分数据集中的隐式偏置，发现其偏置可能偏离全批量Adam的偏置。构建了一个特定结构的数据集，证明增量Adam可以收敛到$\boldsymbol{\text{\textlabyrinth} _2}$-最大边际分类器，提出了一种代理算法来捕捉增量Adam在$\boldsymbol{\boldsymbol{\beta}}_2 \rightarrow 1$时的极限行为，分析了收敛方向，证明了Signum算法的$\boldsymbol{\text{\textlabyrinth} _\text{∞}}$-最大边际偏置特性。", "conclusion": "我们的结果强调了Adam的隐式偏置不仅取决于批量策略，还取决于数据集。相比Adam，Signum算法在接近1的$\boldsymbol{\beta}$值下对任何批量大小都会收敛到$\boldsymbol{\text{\textlabyrinth} _\text{∞}}$-最大边际分类器，显示了其不变性。"}
{"llm_update_time": "20251101", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.26353", "html_url": "https://arxiv.org/abs/2510.26353", "title": "在金融领域实现可解释且可靠的AI", "title_en": "Towards Explainable and Reliable AI in Finance", "authors": "Albi Isufaj,Pablo Mollá,Helmut Prendinger", "background": "近年来，金融预测越来越多地使用大规模的神经网络模型，但这些模型的不透明性加剧了信任和合规性方面的挑战。因此，本研究探讨了几种使AI在金融领域更加可解释和可靠的方法。", "innovation": "本文提出了一种方法，首先描述了Time-LLM这一时间序列基础模型如何通过使用提示来避免错误的方向性预测。其次，展示了将时间序列预测的基础模型与可靠性估计结合使用可以过滤掉不可靠的预测。第三，强调了符号推理编码领域规则进行透明解释的作用。通过上述方法，该架构减少了假正例，并支持了选择性执行。通过将预测性能与可靠性估计和基于规则的推理相结合，该框架推进了透明和可审计的金融AI系统。", "conclusion": "通过整合预测性能与可靠性估计和基于规则的推理，我们的框架推动了透明和可审计的金融AI系统的发展。"}
{"llm_update_time": "20251101", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.26347", "html_url": "https://arxiv.org/abs/2510.26347", "title": "随机、稀疏和非站定环境中自主水下车辆污染检测的强化学习方法", "title_en": "Reinforcement Learning for Pollution Detection in a Randomized, Sparse and Nonstationary Environment with an Autonomous Underwater Vehicle", "authors": "Sebastian Zieglmeier,Niklas Erdmann,Narada D. Warakagoda", "background": "强化学习（RL）算法旨在通过学习最大化奖励的动作来优化问题解决，但在随机和非站定环境中这一任务变得尤为困难。传统的RL算法在这些条件下常常表现欠佳。例如，自主水下车辆（AUV）在搜索海洋污染云时需要在稀疏奖励环境中导航，此时频繁的结果是零奖励。为应对这些挑战，本文重新审视并改进了经典的RL方法，以高效地在稀疏、随机和非站定环境中运行。", "innovation": "系统研究了大量改进措施，包括层次算法变化、多目标学习以及将位置记忆作为外部输出过滤器以防止状态重新访问。研究结果显示，改进的蒙特卡洛方法显著优于传统的Q学习和两种详尽搜索模式，这表明RL方法可以有效适应复杂环境。", "conclusion": "研究结果表明，改进的RL方法能够在随机、非站定和稀疏奖励环境中有效应用，并提出该方法在复杂环境中的潜力。"}
{"llm_update_time": "20251101", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.26350", "html_url": "https://arxiv.org/abs/2510.26350", "title": "UnifiedFL：一个动态统一学习框架以实现公平联邦", "title_en": "UnifiedFL: A Dynamic Unified Learning Framework for Equitable Federation", "authors": "Furkan Pala,Islem Rekik", "background": "联邦学习（FL）已经作为一个关键范式出现，可以在多个客户端之间协作训练模型而不共享原始数据，从而在医学影像学和病理学等领域实现隐私保护的应用。然而，缺乏在具有根本不同神经网络架构和非同分布数据集的客户端之间进行协作训练的研究。现有的FL框架存在一些局限性。尽管声称支持架构异质性，但大多数最新的FL方法只容忍单个模型家族中的变体（例如，更深、更浅或更宽的CNNs），仍假设有相同的全局架构，并且无法适应客户端部署根本不同网络类型的联合会（例如，CNNs、GNNs、MLPs）。此外，现有的方法通常仅解决统计异质性问题，而忽略了域断裂问题，即每个客户的数据分布与测试时间面对的分布明显不同，损害了模型的泛化能力。当客户端使用不同的架构、具有非同分布的数据并且遇到不同的测试领域时，当前的方法表现不佳。", "innovation": "提出了一种名为UnifiedFL的动态联邦学习框架，该框架通过将异质本地网络表示为优化由共享图神经网络（GNN）的有向模型图中的节点和边来解决这些挑战。UnifiedFL引入了(i)一种共同的GNN来参数化所有架构，(ii)通过客户端参数之间的欧几里得距离驱动的聚类，以及(iii)一种两层聚合策略来平衡收敛性和多样性。", "conclusion": "实验结果表明，UnifiedFL在MedMNIST分类和海马体分割基准上的性能优于现有方法。"}
{"llm_update_time": "20251101", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.26376", "html_url": "https://arxiv.org/abs/2510.26376", "title": "高效生成式AI增强突发平流层暖化概率预报", "title_en": "Efficient Generative AI Boosts Probabilistic Forecasting of Sudden Stratospheric Warmings", "authors": "Ningning Tao,Fei Xie,Baoxiang Pan,Hongyu Wang,Han Huang,Zhongpu Qiu,Ke Gui,Jiali Luo,Xiaosong Chen", "background": "突发平流层暖化（SSWs）是中层可预测性和极端冬季天气的重要来源。然而，由于物理表示、初始化和集合预报的巨大计算需求限制，准确和高效的预报仍然是数值天气预报系统的一项持续挑战。尽管数据驱动的预测方法迅速发展，但它们在复杂三维动力学条件下，特别是用于与持续时间有关的概率预报，仍处于探索阶段。", "innovation": "本文创新地开发了一个基于流动匹配的生成人工智能模型（FM-Cast），用于高效且技能化地预报中层气流时空演变。FM-Cast能准确预测18次主要SSW事件中的10次，提前20天，并在50个成员、30天预报上仅需2分钟计算时间即可实现超过50%的集合准确性，同时其性能与顶尖的数值天气预报系统相当甚至更好。此外，通过理想实验，本文揭示了SSW可预报性与其根本物理驱动因素之间的关系。", "conclusion": "本文建立了计算高效的中层异常概率预报范式，并展示了生成式人工智能在加深大气-气候动力学物理理解方面的潜力。"}
{"llm_update_time": "20251101", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.26389", "html_url": "https://arxiv.org/abs/2510.26389", "title": "基于低频截断的自适应上下文长度优化在多智能体强化学习中的应用", "title_en": "Adaptive Context Length Optimization with Low-Frequency Truncation for Multi-Agent Reinforcement Learning", "authors": "Wenchang Duan,Yaoliang Yu,Jiwan He,Yi Shi", "background": "近期，深度多智能体强化学习（MARL）在解决长期依赖和非马尔可夫环境等挑战性任务中展示了令人鼓舞的性能。这些成功部分归因于通过大量固定上下文长度来调整策略。然而，固定上下文长度可能导致探索效率有限和冗余信息问题。", "innovation": "本文提出了一种新颖的MARL框架，用于获取自适应和有效的上下文信息。具体而言，设计了一个中央代理，通过时间梯度分析动态优化上下文长度，增强探索能力，促使其在MARL中达到全局最优。此外，为提高上下文长度的自适应优化能力，提出了中央代理的有效输入表示，高效过滤冗余信息。利用基于傅里叶的低频截断方法，从去中心化智能体中提取全局时间趋势，为MARL环境提供了有效和高效的表现形式。", "conclusion": "大量的实验表明，提出的自适应上下文长度优化方法在PettingZoo、MiniGrid、Google Research Football（GRF）和StarCraft Multi-Agent Challenge v2（SMACv2）等长期依赖任务中达到了最先进的（SOTA）性能。"}
{"llm_update_time": "20251101", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.26369", "html_url": "https://arxiv.org/abs/2510.26369", "title": "CorVS：一种基于视频轨迹与传感器对应关系的仓库人员识别方法", "title_en": "CorVS: Person Identification via Video Trajectory-Sensor Correspondence in a Real-World Warehouse", "authors": "Kazuma Kano,Yuki Mori,Shin Katayama,Kenta Urano,Takuro Yonezawa,Nobuo Kawaguchi", "background": "工人在工业现场的位置数据是提高生产力的关键。摄像机是物流仓库定位的一种有潜力的工具，因为它们还能提供有用的环境上下文，如包裹状态。然而，仅通过视觉数据识别个体通常是不切实际的。因此，许多先前的研究通过比较轨迹和穿戴传感器测量来识别视频中的人。尽管这种方法具有独立于外观的优点，但现有的方法在现实世界条件下可能会失效。为了克服这一挑战，我们提出了CorVS，这是一种基于视频跟踪轨迹和传感器测量之间对应关系的新型数据驱动的人识别方法。", "innovation": "CorVS首先使用深度学习模型预测轨迹和传感器测量之间每对的对应概率和可靠性。其次，算法使用预测的概率和可靠性来匹配轨迹和传感器测量。这种基于视频轨迹与传感器对应关系的方法克服了现有方法在现实世界条件下的局限性，提供了一种有效的人识别策略，特别是对于真实的仓库作业场景。我们为此目的构建了一个实际的仓库操作数据集，并证明了此方法在实际应用中的有效性。", "conclusion": "CorVS方法通过视频轨迹与传感器测量之间的对应关系实现了仓库人员的有效识别，其深度学习模型能够预测轨迹和传感器数据之间的对应概率和可靠性，算法能够基于这些预测结果进行动态匹配。这些特性使得CorVS在现实世界条件下更为可靠，并且在实际仓库操作中显示出良好的应用效果。"}
{"llm_update_time": "20251101", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.26324", "html_url": "https://arxiv.org/abs/2510.26324", "title": "通过将扩散模型与退火朗格文动力学结合进行后验采样", "title_en": "Posterior Sampling by Combining Diffusion Models with Annealed Langevin Dynamics", "authors": "Zhiyang Xun,Shivam Gupta,Eric Price", "background": "在给定噪声线性测量$y = Ax + \\xi$的分布$p(x)$以及一个良好的先验$p(x)$近似的情况下，何时可以从后验$p(x \rule{0pt}{1.2em} \rule{0pt}{1.2em} y)$进行采样？后验采样为任务如图像补全、去模糊和MRI重建提供了准确且公平的框架，但现有的一些近似方法计算上通常是不可行的。针对这一难题，本文关注局部或全局对数凸分布$p(x)$，在这样的分布中，当可以获取$p(x)$的精确分数时，朗格文动态可以产生后验样本，但对分数估计误差容易崩溃，需要误差下限（亚指数级）。相比之下，在无条件情况下，扩散模型仅需第二范数上界即可成功。本文证明通过将扩散模型与朗格文动力学的退火变体结合，仅需分数误差的$L^4$上界就能在多项式时间内实现条件采样。", "innovation": "提出了一种通过将扩散模型与朗格文动力学的退火变体结合的方法，来在计算上有效地进行条件采样，仅需$L^4$范数分数误差的上界，解决了现有方法由于需要下限而导致的计算难题。这种方法为图像补全、去模糊和MRI重建等任务的后验采样提供了新的途径。", "conclusion": "通过将扩散模型与朗格文动力学的退火变体结合，本文在多项式时间内实现了条件采样，仅需$L^4$范数分数误差的上界。这种方法不仅为计算模拟提供了新的策略，也为实际应用中的任务如图像补全、去模糊和MRI重建提供了可靠的方法。"}
{"llm_update_time": "20251101", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.26392", "html_url": "https://arxiv.org/abs/2510.26392", "title": "基于支持向量机和孪生支持向量机的多任务学习：全面综述", "title_en": "Multi-Task Learning Based on Support Vector Machines and Twin Support Vector Machines: A Comprehensive Survey", "authors": "Fatemeh Bazikar,Hossein Moosaei,Atefeh Hemmati,Panos M. Pardalos", "background": "多任务学习（MTL）能够同时训练相关任务，通过共享信息来提升泛化能力、效率和鲁棒性，特别是在数据稀缺或高维场景中。尽管深度学习在最近的MTL研究中占主导地位，但支持向量机（SVM）和孪生支持向量机（TWSVM）仍因其可解释性、理论严谨性和在小数据集上的有效性而具有相关性。", "innovation": "文章深入探讨了基于SVM和TWSVM的多任务学习方法，强调了共享表示、任务正则化和结构耦合策略，并特别关注了新兴的TWSVM扩展在多任务设置中的应用潜力，这些扩展虽然有前景但仍被低估。", "conclusion": "最后，文章指出了研究缺口，并提出了构建可扩展、可解释和可靠的基于边界多任务学习框架的未来方向。这些工作为对基于SVM和TWSVM的多任务学习有兴趣的研究人员和从业人员提供了一部全面的资源。"}
{"llm_update_time": "20251101", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.26444", "html_url": "https://arxiv.org/abs/2510.26444", "title": "通过双通道知识蒸馏和自适应融合从稀有数据进行个性化治疗效果预测", "title_en": "Personalized Treatment Outcome Prediction from Scarce Data via Dual-Channel Knowledge Distillation and Adaptive Fusion", "authors": "Wenjie Chen,Li Zhuang,Ziying Luo,Yu Liu,Jiahao Wu,Shengcai Liu", "background": "小样本和罕见患者的个性化治疗效果预测在精准医疗中至关重要，但由于成本高昂的试验数据限制了预测性能，因此存在改进空间。", "innovation": "提出了基于低保真度模拟数据的交叉保真度知识蒸馏和自适应融合网络（CFKD-AFN），以增强基于稀缺但保真度高的试验数据的预测性能。该模型集成了双通道知识蒸馏模块和注意力导向融合模块，来提取低保真度模型中的互补知识，并动态整合多源信息。", "conclusion": "CFKD-AFN 在慢性阻塞性肺病治疗效果预测中显著提高了预测准确性，从 6.67% 到 74.55%，并且具有较强的高保真度数据集规模变化下的鲁棒性。此外，还扩展了CFKD-AFN 至一个可解释的变体，以支持临床决策中对潜在医疗语义的探索。"}
{"llm_update_time": "20251101", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.26475", "html_url": "https://arxiv.org/abs/2510.26475", "title": "ReSpec：在强化学习系统中优化推测性解码", "title_en": "ReSpec: Towards Optimizing Speculative Decoding in Reinforcement Learning Systems", "authors": "Qiaoling Chen,Zijun Liu,Peng Sun,Shenggui Li,Guoteng Wang,Ziming Liu,Yonggang Wen,Siyuan Feng,Tianwei Zhang", "background": "大型语言模型（LLMs）通过强化学习（RL）进行调整时，生成阶段往往是瓶颈，可能消耗超过75%的训练时间。推测性解码（SD）可以在服务系统中加速自回归生成，但其在RL训练中的行为仍然很大程度上未得到探索。现有研究发现，对于推测性解码，存在三个关键问题：在大批次下逐渐减缓的加速效果、不断更新演员导致的延迟过时以及由推测者引起的策略退化。", "innovation": "ReSpec系统通过三种互补机制解决了推测性解码在RL系统中的优化问题：动态调整推测性解码的配置、通过知识蒸馏进化推测者以及根据回放奖励加权更新。实验结果表明，对于Qwen模型（3B--14B），ReSpec可以实现高达4.5倍的速度提升，同时保持奖励收敛和训练稳定性，提供了一种高效的RL基础LLM调整的实用解决方案。", "conclusion": "ReSpec通过动态调整、知识蒸馏和奖励加权等机制优化了推测性解码在强化学习环境中的使用，显著提升了训练效率，同时保证了训练的稳定性和效果。"}
{"llm_update_time": "20251101", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.26451", "html_url": "https://arxiv.org/abs/2510.26451", "title": "通过分类复杂性化解实现鲁棒的图凝缩", "title_en": "Robust Graph Condensation via Classification Complexity Mitigation", "authors": "Jiayi Luo,Qingyun Sun,Beining Yang,Haonan Yuan,Xingcheng Fu,Yanbiao Ma,Jianxin Li,Philip S. Yu", "background": "图凝缩（GC）因其合成更小但更具信息量的图的能力而受到广泛关注。然而，现有研究往往忽视了GC在原始图被破坏的情况下鲁棒性的问题。在这种情况下，观察到GC的性能会显著下降，而现有的鲁棒图学习技术只能提供有限的效果。我们通过实验和理论分析发现，图凝缩本质上是一个降低固有维度的过程，合成一个具有较低分类复杂度的简化图。尽管这一特性对于GC性能的有效性至关重要，但它对对抗性干扰仍然非常脆弱。", "innovation": "我们从图数据流形的几何角度看问题，提出了一个新的鲁棒图凝缩框架——Manifold-constrained Robust Graph Condensation（MRGC）。具体来说，我们引入了三个图数据流形学习模块，引导凝缩后的图位于光滑的低维流形上，具有最小的分类不清性，从而保持GC的分类复杂度降低能力，并确保在普遍对抗性攻击下具有鲁棒性能。大量的实验演示了\nModelName在不同攻击场景下的鲁棒性。", "conclusion": "实验结果表明，MRGC在不同攻击场景下表现出鲁棒性。该研究揭示了图凝缩在面对对抗性干扰时的固有能力限制，并提供了解决方案来增强其鲁棒性。"}
{"llm_update_time": "20251101", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.26491", "html_url": "https://arxiv.org/abs/2510.26491", "title": "通过离策渐影响指导实现高效数据选择的RLVR", "title_en": "Data-Efficient RLVR via Off-Policy Influence Guidance", "authors": "Erle Zhu,Dazhi Jiang,Yuan Wang,Xujun Li,Jiale Cheng,Yuxian Gu,Yilin Niu,Aohan Zeng,Jie Tang,Minlie Huang,Hongning Wang", "background": "当前的强化学习与可验证奖励（RLVR）中的数据选择方法主要是基于启发式的，缺乏理论保证和普适性。大型语言模型的高维度梯度处理仍然是一个挑战。", "innovation": "提出了一种基于影响函数的理论指导方法，用于估计每个数据点对学习目标的贡献。引入了离策渐影响估计方法，通过预先收集的离策渐轨迹高效地近似数据影响，同时采用稀疏随机投影降低维度，提高存储和计算效率。开发了CROPI多阶段RL框架，通过选择当前策略中最具影响力的最少数据来加速训练。", "conclusion": "CROPI在具有7B参数的模型上显著加快了训练速度。在1.5B模型上，它实现了2.66倍的步骤加速，同时每个阶段只使用了10%的数据，相比全数据集训练更为高效。"}
{"llm_update_time": "20251101", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.26433", "html_url": "https://arxiv.org/abs/2510.26433", "title": "共同进化的潜在动作世界模型", "title_en": "Co-Evolving Latent Action World Models", "authors": "Yucen Wang,Fengming Zhang,De-Chuan Zhan,Li Zhao,Kaixin Wang,Jiang Bian", "background": "在通过潜在动作将预训练的视频生成模型转化为可控世界模型方面，采用了双阶段方法分别训练潜在动作模型（LAM）和世界模型，这种方法虽然有其优势，但在模型的共适应上存在局限性和重复性培训问题。然而，直接将LAM中的前向动力学模型替换为强大的世界模型，并使两者联合培训是一个简单且有吸引力的想法，但实现起来却颇具挑战，容易发生表征崩溃。因此，寻找一种能够整合这两个模型并实现共适应的方法是重要的研究方向和发展趋势。", "innovation": "本文提出了CoLA-World，首次成功实现了将潜在动作模型与世界模型联合学习的协同范式。通过一个关键的预热阶段，有效对齐了从零训练的LAM和预训练的世界模型的表示，从而打破了联合学习的核心挑战。CoLA-World通过世界模型作为有知识的导师提供梯度来塑造高质量的LAM，而LAM则提供一个更精确和灵活的控制界面给世界模型，实现了共同进化。", "conclusion": "CoLA-World在视频仿真质量和下游视觉规划方面完全或超越了现有的双阶段方法，为领域内建立了一个强大、高效的新型范式。"}
{"llm_update_time": "20251101", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.26487", "html_url": "https://arxiv.org/abs/2510.26487", "title": "量子门循环GAN及其高斯不确定性在网络异常检测中的应用", "title_en": "Quantum Gated Recurrent GAN with Gaussian Uncertainty for Network Anomaly Detection", "authors": "Wajdi Hammami,Soumaya Cherkaoui,Jean-Frederic Laprade,Ola Ahmad,Shengrui Wang", "background": "时间序列数据中的异常检测是网络安全中的关键挑战，量子机器学习方法，如量子核方法和变量子电路，在捕捉复杂数据分布方面展现出了潜力，但仍然受到有限量子比特数量的限制。本文研究了一种结合了S祖DaI数据注入和多度量门策略的新型量子门循环神经单元(QGRU)-生成式对抗网络(GAN)，旨在提供一种强大的网络异常检测方法。该模型的独特之处在于使用一种量子增强的生成器，通过重构参数表示生成高斯分布参数（均值和对数方差），结合判别损失来稳定对抗训练。异常检测通过一种新的门控机制实现：首先基于高斯不确定性估计标记潜在异常，然后通过判别分数和重构误差进行验证。", "innovation": "引入了一种结合量子增强生成器的QGRU为基础的GAN，使用S祖DaI数据注入和多度量门策略进行网络异常检测，并通过Gaussian uncertainty估计进行鉴别。模型实现了高质量的时间序列感知F1得分（TaF1）为89.43%，明显优于现有经典和量子模型。该模型在IBM真实量子硬件上进行了部署，展示了其在当前嘈杂的中尺度量子（NISQ）设备上的鲁棒性和实用性。", "conclusion": "本文提出的方法在基准数据集上取得了高时间序列感知F1得分（TaF1）89.43%，证明了该基于量子门循环单元的生成对抗网络在实际应用中具备高效、准确地检测异常的能力，同时验证了其在噪声的中等规模量子设备上的实用性和鲁棒性。"}
{"llm_update_time": "20251101", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.26557", "html_url": "https://arxiv.org/abs/2510.26557", "title": "瘦身后的提升树：资源受限设备上的紧凑模型", "title_en": "Boosted Trees on a Diet: Compact Models for Resource-Constrained Devices", "authors": "Jan Stenkamp,Nina Herrmann,Benjamin Karic,Stefan Oehmcke,Fabian Gieseke", "background": "在现代物联网应用中，将机器学习模型部署到计算能力受限的设备上已成为关键构建块。由于对轻量级机器学习模型的需求日益增长，本文提出了针对提升决策树的一种压缩方案。", "innovation": "本文提供了训练紧凑型提升决策树集成的技术，通过在训练过程中奖励重复使用特征和阈值来减少内存占用。实验评估表明，与采用调整后的训练过程和替代内存布局的LightGBM模型相比，所提出的模型在压缩比为4-16倍的情况下仍能保持相同的性能。", "conclusion": "一旦部署，相关的物联网设备可以在不依赖持续通信或外部能量供应的情况下运行，并自主地工作，只需微小的计算能力和能量。这种能力为远程监控、边缘计算和孤立或电源有限环境中的实时决策等物联网应用铺平了道路。"}
{"llm_update_time": "20251101", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.26519", "html_url": "https://arxiv.org/abs/2510.26519", "title": "超出策略范围：基于上下文引导的策略优化", "title_en": "Think Outside the Policy: In-Context Steered Policy Optimization", "authors": "Hsiu-Yuan Huang,Chenming Tang,Weijie Liu,Saiyong Yang,Yunfang Wu", "background": "现有从可验证奖励角度进行的强化学习（RLVR）方法，例如组相对策略优化（GRPO），已经在提升大规模推理模型（LRMs）的推理能力方面取得了显著的进步。然而，这些方法由于依赖于当前政策分布内的实时回放，导致探索范围有限，轨迹多样性不足。最近的研究尝试通过引入更强的专家模型生成的轨迹来扩展政策覆盖范围，但这种方法增加了计算成本，而这些高级模型经常不可获取。针对这些问题，本文提出了基于上下文引导的策略优化（ICPO）框架，利用LRMs内置的上下文学习能力，通过现有数据集提供专家指导。ICPO引入了混合策略GRPO结合隐式专家强迫方法，使得探索范围能够超出当前策略分布，而无需高级LRM轨迹。为了进一步稳定优化过程，ICPO集成了专家区域拒绝采样方法来过滤不可靠的离策略轨迹，并使用退火专家奖金奖励塑造方法来平衡早期的专家引导与后期的自主改进。", "innovation": "ICPO框架通过利用LRMs的上下文学习能力，利用现有数据集提供专家指导，从而扩展了探索范围。它引入了混合策略GRPO结合隐式专家强迫方法，无需高级LRM轨迹即可超出当前策略分布进行探索。为了稳定优化过程，ICPO还集成了专家区域拒绝采样方法和退火专家奖金奖励塑造方法来平衡早期的专家引导与后期的自主改进。这些创新为LRMs提供了一个扩展和稳定的强化学习范式。", "conclusion": "实验证明，ICPO能够持续提升数学推理基准上的强化学习性能和训练稳定性，揭示了一种可扩展且有效的RLVR框架，适用于LRMs。"}
{"llm_update_time": "20251101", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.26527", "html_url": "https://arxiv.org/abs/2510.26527", "title": "通过理论视角实现多基元推测性解码", "title_en": "Polybasic Speculative Decoding Through a Theoretical Perspective", "authors": "Ruilin Wang,Huixia Li,Yuexiao Ma,Xiawu Zheng,Fei Chao,Xuefeng Xiao,Rongrong Ji", "background": "在大规模部署大型语言模型（LLMs）的过程中，推理延迟成为关键瓶颈。推测性解码方法最近显示出在不损害输出分布的情况下加速推理的潜力。然而，现有工作的主要方法是基于草稿-验证的双阶段框架，并缺乏严格的理论支持。本文探讨了在推广这种双阶段方法的同时，如何通过引入一个更广泛的多基元推测性解码框架来优化模型的推理时间。我们分析了多模型推测性解码系统中的根本定理，揭示了模型能力、接受长度与整体计算成本之间的相互作用，并提出了理论证明和实现代码供进一步研究使用。", "innovation": "本文提出了一个新的多基元推测性解码框架，基于全面的理论分析。该框架证明了多模型推测性解码系统的最优推理时间定理，拓展了双阶段草稿-验证框架，将其扩展为一种更通用的多基元范式。通过理论研究表明，该框架支持独立实现和与现有推测技术的集成，实现在不同程度上的加速效果，包括LLaMA2-Chat 7B、LLaMA3-8B、Vicuna-7B和Qwen2-7B等多个模型家族，加速比从3.31倍到4.43倍不等，同时保持原始输出分布不变。", "conclusion": "通过理论分析，本文提出了一种新的多基元推测性解码框架，通过优化模型能力、接受长度和整体计算成本之间的相互作用，实现在多个模型家族上的显著加速效果，而不会影响输出分布。我们已提供了理论证明和实现代码，以促进对多基元推测性解码的进一步研究。"}
{"llm_update_time": "20251101", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.26501", "html_url": "https://arxiv.org/abs/2510.26501", "title": "轻量级无监督异常检测滤波器增强ECG分类鲁棒性", "title_en": "Enhancing ECG Classification Robustness with Lightweight Unsupervised Anomaly Detection Filters", "authors": "Mustafa Fuad Rifet Ibrahim,Maurice Meijer,Alexander Schlaefer,Peer Stelldinger", "background": "穿戴设备提供的连续心电图（ECG）监测具有早期检测心血管疾病（CVD）的巨大潜力。然而，在资源受限的环境中部署深度学习模型进行自动化分析时，由于不可避免的离分布（OOD）数据导致可靠性挑战。标准分类器对未见过的病理或噪声污染的信号经常会生成错误的高置信度预测，这会危及患者安全。现有的离分布检测方法要么忽略了计算约束，要么单独解决了噪声和未见过的类问题。本文探讨了无监督异常检测（UAD）作为一种独立的上游筛选机制，以提高鲁棒性。我们将六种UAD方法进行了基准测试，并使用神经结构搜索（NAS）在严格的资源限制下（最多512k参数）优化了这些方法。", "innovation": "本文利用无监督异常检测（UAD）方法，通过严格资源限制下的神经结构搜索（NAS）优化了六种UAD方法。在PTB-XL和BUT QDB数据集上对离分布CVD类和不适合分析的噪声信号进行检测评估，结果显示，Deep SVDD在检测和效率方面达到了最佳平衡。此外，在现实部署模拟中，将最优Deep SVDD滤波器与诊断分类器结合使用，提高了21个百分点的准确性，优于仅使用分类器的基准。这表明，优化的UAD滤波器可以确保自动化ECG分析的安全性和可靠性，使其在穿戴设备上进行连续的心血管监测更加可靠。", "conclusion": "优化的无监督异常检测滤波器能够确保自动化ECG分析的安全性和可靠性，使其在穿戴设备上进行连续的心血管监测更加可靠，通过与诊断分类器的结合使用能够提升分类准确率，降低误诊风险。"}
{"llm_update_time": "20251101", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.26533", "html_url": "https://arxiv.org/abs/2510.26533", "title": "超图上的高阶正则化学习", "title_en": "Higher-Order Regularization Learning on Hypergraphs", "authors": "Adrien Weihs,Andrea Bertozzi,Matthew Thorpe", "background": "Hypergraph regularization 利用超图结构提供了一种原理性替代传统方法的方式，通过超图结构诱导的多尺度拉普拉斯算子的幂来强制执行更高阶的平滑性。前期研究通过几何设置中的渐近一致性分析，已经确定了 HOHL 的良界性和病界性。本文在此基础上，证明了HOHL截断版本的一致性，并推导出当HOHL用于完全监督学习中的正则化时的具体收敛速度。此外，还展示了HOHL在积极学习和缺乏底层几何结构的数据集中的强大实证性能，突显了HOHL在不同学习环境中的多样性和鲁棒性。", "innovation": "提出了HOHL截断版本的一致性证明，并推导出了具体收敛速度。证明了HOHL在完全监督学习中的有效性和优异的实证性能，特别是在缺乏几何结构的数据集，以及积极学习场景中，展现了其广泛的应用潜力和鲁棒性。", "conclusion": "研究进一步扩展了HOHL的理论基础，证明了其在不同学习场景中的强大性能，表明HOHL可以在不同的数据集上提供一致性和高效的学习策略。"}
{"llm_update_time": "20251101", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.26510", "html_url": "https://arxiv.org/abs/2510.26510", "title": "LLMs作为模型和超参数选择的上下文内元学习者", "title_en": "LLMs as In-Context Meta-Learners for Model and Hyperparameter Selection", "authors": "Youssef Attia El Hili,Albert Thomas,Malik Tiomoko,Abdelhakim Benechehab,Corentin Léger,Corinne Ancourt,Balázs Kégl", "background": "在机器学习中，模型和超参数的选择至关重要但具有挑战性，通常需要专家直觉或昂贵的自动化搜索。我们研究大型语言模型（LLMs）是否可以作为元学习者参与这一任务。通过将每个数据集转化为可解释的元数据，我们提示一个LLM推荐模型家族和超参数。我们研究了两种提示策略：（1）零样本模式仅依赖预训练知识；（2）元信息辅助模式结合以前任务中模型及其性能的示例。在合成和真实世界基准测试中，我们展示了LLMs可以利用数据集元数据无需搜索推荐具有竞争力的模型和超参数，并且元信息辅助提示的改进表明其在上下文内元学习中的能力。这些结果强调了LLMs在模型选择和超参数优化方面的轻量级、通用助手的新角色潜在。", "innovation": "该研究探索了使用大语言模型（LLMs）作为元学习者在模型和超参数选择中的可能性，通过将数据集转换为可解释的元数据并提示LLM进行推荐。这种方法结合了零样本模式和元信息辅助模式，展示了LLMs在无需搜索的情况下推荐具有竞争力的模型和超参数的能力，并证明了其在上下文内元学习中的潜力。", "conclusion": "研究结果强调了LLMs在模型选择和超参数优化方面的轻量级、通用助手的新角色潜力，表明其有潜力在无需搜索的情况下进行有效的推荐，并且在元信息辅助提示中表现出色。"}
{"llm_update_time": "20251101", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.26541", "html_url": "https://arxiv.org/abs/2510.26541", "title": "三阶段贝叶斯转移学习框架以提高数据稀少领域中的预测", "title_en": "A Three-Stage Bayesian Transfer Learning Framework to Improve Predictions in Data-Scarce Domains", "authors": "Aidan Furlong,Robert Salko,Xingang Zhao,Xu Wu", "background": "在工程领域中，机器学习的应用不断发展，支持了各种应用。尽管深度神经网络因其性能和易用性而被广泛采用，但它们需要大量高质量的数据集。实验数据通常稀疏、噪音大或不足以构建稳健的数据驱动模型。为了解决这一问题，研究者们提出了迁移学习的方法，利用数据丰富的源域来辅助数据稀缺的目标域学习。参数迁移是常见的方法，但在大面积域迁移时会退化。为了应对这一挑战，研究者们提出了领域对抗神经网络（DANNs），通过学习不变的特征表示来提高模型在更大领域迁移时的表现。然而，DANNs在训练过程中不稳定，并缺乏不确定性量化的方法。", "innovation": "本文提出了一种全新的三阶段监督方法，即阶段化贝叶斯领域对抗神经网络（staged B-DANN），该方法结合了参数迁移和共享潜在空间适应。这种方法包括三个阶段：第一阶段，确定性特征提取器在源域上进行训练；第二阶段，使用DANN对特征提取器进行对抗性细化；第三阶段，在适应的特征提取器上构建贝叶斯神经网络，在目标域进行微调，以处理条件迁移并提供校准的不确定性估计。该方法首先在合成基准测试中得到了验证，结果显著优于标准的迁移技术。接着将其应用于矩形通道中关键热流量的预测任务，利用管子实验的数据作为源域。研究表明，staged B-DANN方法能够提升预测精度和泛化性能，有可能在核工程的其他领域中发挥作用。", "conclusion": "综上所述，本文提出了一种新颖的三阶段监督框架（staged B-DANN），它结合了参数迁移和共享潜在空间适应，有效提高了模型在数据稀缺情况下的预测精度和泛化能力。这种方法在合成基准测试和关键热流量预测任务中得到了验证，显示了其在核工程及其他领域的潜力。"}
{"llm_update_time": "20251101", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.26607", "html_url": "https://arxiv.org/abs/2510.26607", "title": "基于Bernstein基的Wasserstein回归作为一种概率轨迹的变分近似", "title_en": "Wasserstein Regression as a Variational Approximation of Probabilistic Trajectories through the Bernstein Basis", "authors": "Maksim Maslov,Alexander Kugaevskikh,Matthew Ivanov", "background": "本文研究了在机器学习中越来越重要的概率分布上的回归问题。现有的方法要么忽视概率空间的几何结构，要么计算成本高。", "innovation": "提出了一个结合概率轨迹的贝恩斯坦基参数化和概率分布之间的Wasserstein距离最小化的新方法。通过使用伯恩斯坦多项式的加权和来定义一个条件分布为光滑的概率轨迹，参数包括均值和协方差，并且是输入变量的函数。还利用自动微分优化方法训练模型，特别是在非线性显著的情况下，该方法在Wasserstein距离、能量距离和RMSE指标方面表现出了竞争力。", "conclusion": "实验结果显示该模型在概率轨迹光滑性和对数据结构变化的鲁棒性方面具有优势，同时保持了高可解释性。研究还发现了该方法结合了几何准确性、计算实用性和可解释性的平衡解决方案。未来研究可以将该方法扩展到非高斯分布，应用熵正则化加速计算，并适应处理高维数据以逼近表面和更复杂的结构。"}
{"llm_update_time": "20251101", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.26560", "html_url": "https://arxiv.org/abs/2510.26560", "title": "在深度神经网络中衡量捷径定位的方法", "title_en": "On Measuring Localization of Shortcuts in Deep Networks", "authors": "Nikita Tsoy,Nikola Konstantinov", "background": "深度网络中的捷径（即在训练过程中表现良好的错误规则但无法泛化的现象）对网络的可靠性构成主要挑战（Geirhos等，2020）。然而，这些捷径对特征表示的影响尚不明确，阻碍了有针对性的捷径缓解方法的设计。为了克服这一局限，我们研究了深度模型中捷径的分层定位。我们的实验设计通过在清洁和偏差数据集上进行假设训练来量化偏差导致的准确率下降的分层贡献，从而测量捷径的分层定位。我们使用此设计在CIFAR-10、水鸟和CelebA数据集上研究捷径在VGG、ResNet、DeiT和ConvNeXt架构中的表现。研究发现捷径学习并不是集中在特定层，而是分布在整个网络中。网络的不同部分在这一过程中起到了不同的作用：浅层主要编码虚假特征，而深层则主要遗忘对于清洁数据预测性较强的核心特征。我们还分析了定位的差异，并描述了其主要变化轴。最后，我们对捷径缓解策略的分层分析表明，设计一般方法的难度较大，支持针对特定数据集和架构的方法。", "innovation": "介绍了一种新的实验设计，通过在清洁和偏差数据集上进行假设训练来量化偏差导致的准确率下降的分层贡献，从而测量深度网络中捷径的分层定位。这为理解捷径影响提供了新的视角，并有助于设计针对性的捷径缓解方法。此外，还分析了不同网络部分在捷径形成过程中的作用，以及捷径定位的差异及变化轴，提供了丰富的理论和实验证据。", "conclusion": "捷径学习不是局限于特定的层，而是分布在整层网络中。浅层主要编码虚假特征，而深层则主要遗忘对于清洁数据预测性较强的核心特征。对于捷径缓解策略，存在设计难度，建议开发针对特定数据集和架构的方法。"}
{"llm_update_time": "20251101", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.26566", "html_url": "https://arxiv.org/abs/2510.26566", "title": "使用 Jensen-Shannon 距离的多类局部校准", "title_en": "Multiclass Local Calibration With the Jensen-Shannon Distance", "authors": "Cesare Barbera,Lorenzo Perini,Giovanni De Toni,Andrea Passerini,Andrea Pugnana", "background": "开发可信赖的机器学习（ML）模型要求其预测概率能够良好地校准，即这些概率应准确反映真实类别的频率。在多分类校准中，强校准是最严格的，要求所有预测概率在所有类别中同步校准。然而，现有的多分类校准方法缺乏对输入之间距离的考量，导致它们容易出现邻近偏差：在特征空间的稀疏区域，预测会系统性地失校准。这对于诸如医疗保健等高风险领域尤为重要，因为稀疏实例也正是那些最有可能受到偏见对待的实例。本文通过引入一种局部视角来解决多分类校准的主要缺陷，方法包括正式定义局部多分类校准及其与强校准的关系，分析现有评估指标在应用于局部多分类校准时的局限性，提出一种使用 Jensen-Shannon 距离增强神经网络局部校准的实用方法，该方法通过校准预测概率与局部类频率估计之间的偏差来实现，以及通过实验证明新方法的有效性。", "innovation": "本文提出的创新点在于引入了一种新的局部视角来处理多分类校准问题，解决了现有方法对输入之间距离缺乏考量的问题。具体创新点包括：1. 正式定义局部多分类校准并探讨其与强校准的关系；2. 理论分析现有评估指标在应用于局部多分类校准时存在的问题；3. 提出一种基于 Jensen-Shannon 距离的实用方法来增强神经网络的局部校准，该方法通过校准预测概率与局部类频率估计之间的偏差来实现；4. 通过实验验证新方法的有效性，与现有多分类校准技术进行对比评估。", "conclusion": "本文通过引入新的局部视角和实用方法，解决了多分类校准中存在的邻近偏差问题。提出的方法不仅提高了模型的校准性能，还通过实验证明了其有效性，特别适用于高风险领域，如医疗保健，能够在特征空间的稀疏区域提供准确的预测。"}
{"llm_update_time": "20251101", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.26616", "html_url": "https://arxiv.org/abs/2510.26616", "title": "Aeolus: 多结构航班延误数据集", "title_en": "Aeolus: A Multi-structural Flight Delay Dataset", "authors": "Lin Xu,Xinyun Yuan,Yuxuan Liang,Suwan Yin,Yuankai Wu", "background": "现有的航班延误数据集通常局限于平坦的表格结构，并未能捕捉到航班延误传播中的时空动态。Aeolus 大规模多模态飞行延误数据集旨在解决这一问题，提供齐整的三种模态：表格数据集，记录了丰富的运营、气象和机场层面的特征；飞行链条模块，模型飞行阶段中的延误传播，捕捉上下游依赖；飞行网络图，编码共享的航空器、机组和机场资源共享，支持跨航班关系推理。", "innovation": "Aeolus 数据集通过提供多种模态数据，解决了现有数据集中缺乏时空动态捕捉的问题。它包括三个模态的数据：表格数据集、飞行链条模块和飞行网络图。此外，数据集采用严格的时空分割、全面的特征和严格的泄密预防措施，支持真实且可重复的机器学习评估。Aeolus 适用于多种任务，包括回归、分类、时间结构建模和图学习。", "conclusion": "Aeolus 数据集填补了具体领域模型和通用结构化数据建模之间的关键空白，为上述研究领域提供了新的可行方案。它可以被广泛地应用在优化航班延误预测和开发面向表格数据的基础模型方面。数据集和源代码可以通过提供的链接进行访问。"}
{"llm_update_time": "20251101", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.26679", "html_url": "https://arxiv.org/abs/2510.26679", "title": "Differential隐私PCA紧边界通过矩阵共轭", "title_en": "Tight Differentially Private PCA via Matrix Coherence", "authors": "Tommaso d'Orsi,Gleb Novikov", "background": "该研究重新审视了在差分隐私约束下计算矩阵的前$r$个奇异向量的跨度这一任务。已有工作提出了基于奇异值分解和标准扰动技术的简单有效算法，但在某些情况下，这些算法的表现不如最新的非差分隐私算法，特别是在稠密矩阵中单峰PCA的问题上。此外，已有工作尚未解决关于共轭如何在高斯扰动下保持不变的问题，以及这种性质是否适用于其他结构化模型（如图中的嵌入问题）的问题", "innovation": "本研究提出了一种新的差分隐私算法，其误差取决于特定的秩-$r$共轭和特征值差距。该算法在稠密矩阵中表现出色，实现了与无隐私算法相同的效果，这解决了Hardt和Roth提出的问题。此外，研究证明了共轭在高斯扰动下不会增大，并且基于高斯机制的任何估计器都保持输入的共轭特性。研究者还提出了在低共轭假设下的图问题的不同性隐私算法", "conclusion": "本研究通过证明共轭保持不变和提出适用于处理各种图问题的不同性隐私算法，提高了差分隐私PCA的性能和准确性。这些结果在稠密矩阵环境中特别有效，表明新的算法可以替代现有的一系列非隐私算法。"}
{"llm_update_time": "20251101", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.26643", "html_url": "https://arxiv.org/abs/2510.26643", "title": "MSAD: 深入探究时间序列异常检测中的模型选择", "title_en": "MSAD: A Deep Dive into Model Selection for Time series Anomaly Detection", "authors": "Emmanouil Sylligardos,John Paparrizos,Themis Palpanas,Pierre Senellart,Paul Boniol", "background": "时间序列异常检测是一项基本任务，对于时间序列分析具有重要影响，其下游应用的性能也依赖于这一任务。尽管学术界对此产生了浓厚兴趣并提出了许多方法，但最近的基准测试和评估研究显示，没有一种单一的异常检测方法适用于所有异质性极强的时间序列数据集。因此，提出一种基于时间序列特性的模型选择方法，以选择最佳的异常检测方法变得尤为必要。然而，现有自动机器学习（AutoML）解决方案并不直接适用于时间序列异常检测，且针对基于时间序列的方法进行模型选择评估的研究还不存在。因此，本文研究了时间序列分类方法用作异常检测模型选择的效果。", "innovation": "本文评估了234种模型配置，涵盖了16种基础分类器，并进行了超过1980个时间序列的实验，这是首次对时间序列分类方法作为异常检测模型选择进行广泛实验评估。研究结果表明，模型选择方法在执行时间和性能上都优于单一的异常检测方法。此研究代表了一个强有力的基准，可以用于指导自动化机器学习管道中的模型选择步骤，从而推动了时间序列分类算法在异常检测应用中的准确性和效率的研究进程。", "conclusion": "研究表明，通过使用时间序列分类方法进行模型选择可以显著提高异常检测的性能，同时保持相同的执行时间水平。这是展示时间序列分类算法在异常检测中的准确性和效率的第一步，也为未来的相关研究提供了强有力的基础。"}
{"llm_update_time": "20251101", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.26690", "html_url": "https://arxiv.org/abs/2510.26690", "title": "LoRAQuant: 混合精度 LoRA 量化至超低位宽", "title_en": "LoRAQuant: Mixed-Precision Quantization of LoRA to Ultra-Low Bits", "authors": "Amir Reza Mirzaei,Yuqiao Wen,Yanshuai Cao,Lili Mou", "background": "低秩适应（LoRA）已经成为一种在不增加大量参数的情况下对大型语言模型（LLMs）进行微调的技术。在实际应用中，多个适应器可以同时加载，以支持个性化用户体验或多种任务。虽然每个适应器在孤立使用时相当轻量，但它们的整体开销在大规模应用时会变得庞大。因此，需要一种有效的混合精度后培训量化方法来应对这一挑战，以降低适应器的内存和计算成本，同时保持或提高模型性能。", "innovation": "LoRAQuant 是一种针对 LoRA 设计的混合精度后训练量化方法，通过奇异值分解（SVD）重新参数化每个适应器，将关键信息集中在特定的行和列中。这种方法允许将重要的组件量化为更高精度，而将其他部分量化为超低位宽。与传统的量化方法相比，LoRAQuant 在相同甚至更高的性能下使用了显著较少的位宽，从而显著降低了适应器的内存和计算成本。", "conclusion": "我们通过针对 LLaMA 2-7B、LLaMA 2-13B 和 Mistral 7B 模型的数学推理、编码和总结任务进行了全面的实验，结果表明，LoRAQuant 相比其他量化方法使用了显著更少的位宽，但达到了可比或更高的性能。"}
{"llm_update_time": "20251101", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.26704", "html_url": "https://arxiv.org/abs/2510.26704", "title": "正则化项如何使可逆神经网络成为贝叶斯点估计器", "title_en": "How Regularization Terms Make Invertible Neural Networks Bayesian Point Estimators", "authors": "Nick Heilenkötter", "background": "可逆神经网络由于其固有的稳定性和可解释性，在逆问题中具有吸引力。近期，从贝叶斯视角研究了这两种类型的可逆神经网络优化策略——近似重建映射或正向运算符，但各自都有局限性。", "innovation": "本文引入并分析了两个用于网络训练的正则化项，这些正则化项在反向过程中可以恢复经典贝叶斯点估计器的特性：第一个与后验均值相关，第二个类似于MAP估计器。理论分析揭示了每个损失如何影响学习到的正向运算符及其逆向重建映射。", "conclusion": "数值实验支持我们的发现，并表明这些损失项正则化器可以以稳定且可解释的方式引入数据依赖性。"}
{"llm_update_time": "20251101", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.26633", "html_url": "https://arxiv.org/abs/2510.26633", "title": "泛在而又被忽视：组合贝叶斯优化中的热核", "title_en": "Omnipresent Yet Overlooked: Heat Kernels in Combinatorial Bayesian Optimization", "authors": "Colin Doumont,Victor Picheny,Viacheslav Borovitskiy,Henry Moss", "background": "贝叶斯优化（BO）可以解决各种组合任务，从材料科学到神经架构搜索。然而，BO 需要专业化内核才能有效地建模组合领域。最近的研究引入了一些组合内核，但它们之间的关系尚未充分理解。为了填补这一空白，我们开发了一个基于热核的统一框架，以系统性的方式推导并表达为简单的闭式表达式。利用这一框架，我们证明了许多成功的组合内核要么与热核有关，要么等同于热核，并在实验中验证了这些理论观点。我们的分析还证实并扩展了 Bounce 中提到的结果：某些算法的性能会显著下降，特别是当该功能的未知最优解不具备特定结构时。相反，热核对最优解的位置不敏感。此外，我们展示了依赖于热核的快速简单管道能够达到最先进的性能，甚至超越某些慢速或复杂算法的结果.", "innovation": "我们开发了一个基于热核的统一框架，以系统性的方式推导并表达为简单的闭式表达式。利用这一框架，我们证明了许多成功的组合内核要么与热核有关，要么等同于热核，并在实验中验证了这些理论观点。我们的分析还证实并扩展了 Bounce 中提到的结果：当功能的未知最优解不具备特定结构时，某些算法的性能会显著下降。相反，热核对最优解的位置不敏感。此外，我们展示了依赖于热核的快速简单管道能够达到最先进的性能，甚至超越某些慢速或复杂算法的结果.", "conclusion": "我们的工作澄清了热核在组合内核中的地位，提供了对其特性的深入理解，并展示了其在建模组合空间中的有效性和优势。"}
{"llm_update_time": "20251101", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.26645", "html_url": "https://arxiv.org/abs/2510.26645", "title": "Curly Flow Matching for Learning Non-gradient Field Dynamics", "title_en": "Curly Flow Matching for Learning Non-gradient Field Dynamics", "authors": "Katarina Petrović,Lazar Atanackovic,Viggo Moro,Kacper Kapuśniak,İsmail İlkan Ceylan,Michael Bronstein,Avishek Joey Bose,Alexander Tong", "background": "目前，从群体层面的观察来建模自然过程的运输动力学是一个普遍存在的问题，尤其是在自然科学领域。为了使学习到的控制动力学能够真实地模仿系统行为，这些模型依赖于关于潜在过程的重要假设。当前方法背后的默认假设是基于最小作用原理，导致梯度场动力学，从而导致最小化两个概率测度之间能量函数的轨迹。然而，许多现实世界系统，如单细胞RNA中的细胞周期，已知表现出非梯度、周期性行为，这从根本上无法被当前最先进的方法如流匹配和桥匹配捕捉到。", "innovation": "本文提出了Curly Flow Matching (Curly-FM)，这是一种新型方法，通过设计并解决具有非零漂移参考过程的薛定谔桥问题，能够学习非梯度场动力学，这与通常使用零漂移参考过程的传统方法形成了鲜明对比。Curly-FM使用推断出的速度数据和群体快照数据来构建参考过程，从而能够学习和捕捉非梯度田动力学，而这些动力学在实际系统中是存在的。我们通过解决单细胞、计算流体动力学、海洋环流的轨迹推断问题来展示Curly-FM的效果。我们表明，Curly-FM能够学习更能与参考过程和群体边缘匹配的轨迹。Curly-FM扩展了流动匹配模型的应用范围，不仅仅是对群体的建模，而是对物理系统中已知的周期行为进行建模。我们的代码库可通过此链接查看: [link provided in the paper]。", "conclusion": "Curly-FM能够学习非梯度场动力学，改善了传统方法无法解决的取问题，适用于多种实际系统。这种方法不仅在单细胞研究、计算流体动力学和海洋环流等领域取得了成功，还为理解复杂系统的行为提供了一个新的视角。"}
{"llm_update_time": "20251101", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.26706", "html_url": "https://arxiv.org/abs/2510.26706", "title": "预算化的多专家延迟决策", "title_en": "Budgeted Multiple-Expert Deferral", "authors": "Giulia DeSalvo,Clara Mohri,Mehryar Mohri,Yutao Zhong", "background": "延迟不确定预测以昂贵专家为辅助的问题能够显著提高机器学习系统的准确性和效率。然而，标准的训练方法通常需要对每个训练实例查询所有专家，这种做法在专家查询产生重大计算或资源成本时变得极其昂贵，这违背了延迟的核心目标：限制不必要的专家使用。为克服这一挑战，引入了预算化的延迟框架，旨在在训练过程中将专家查询成本降至最低的同时，训练出有效的延迟算法。在已知标签的背景下，核心挑战是如何在平衡成本和预测性能的同时选择查询哪些专家。尽管受到主动学习的启发，但仍与之有根本不同", "innovation": "提出了一种新的预算化的延迟框架，涵盖了两级和单级多专家延迟设置中的新算法，该算法仅在每个训练示例中选择查询部分专家。通过建立这两种算法的理论保证，包括泛化边界的分析和标签复杂度分析，示证了预算感知延迟算法的实际价值，能够在不牺牲预测准确性的前提下显著减少训练成本", "conclusion": "实验结果表明，算法能够在不牺牲预测准确性的情况下大幅降低训练成本，这表明预算感知的多专家延迟算法具有实际价值。"}
{"llm_update_time": "20251101", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.26709", "html_url": "https://arxiv.org/abs/2510.26709", "title": "An All-Reduce Compatible Top-K Compressor for Communication-Efficient Distributed Learning", "title_en": "An All-Reduce Compatible Top-K Compressor for Communication-Efficient Distributed Learning", "authors": "Chuyan Chen,Chenyang Ma,Zhangxin Li,Yutong He,Yanjie Dong,Kun Yuan", "background": "在大规模分布式机器学习中，通信仍然是一个主要瓶颈。现有的一些梯度压缩方法存在明显限制：Rand-K会丢弃结构信息，导致实际中效果不佳；而Top-K虽然保留了有信息性的元素，但失去了收缩特性，并且需要昂贵的All-Gather操作。", "innovation": "我们提出了ARC-Top-K，一种All-Reduce兼容的Top-K压缩器，通过轻量级的梯度素描对节点间的稀疏模式进行对齐，实现无索引的All-Reduce操作，同时保留全局显著信息。该方法在证明上具有收缩性，与其他优化方法结合时，相比原方法在标准假设下能够实现线性加速并具有更快的收敛速度。", "conclusion": "ARC-Top-K在保持与Top-K同样性能的同时，将墙钟训练时间最多减少了60.7%，提供了一种高效且可扩展的解决方案，结合了Rand-K的鲁棒性和Top-K的强性能。"}
{"llm_update_time": "20251101", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.26714", "html_url": "https://arxiv.org/abs/2510.26714", "title": "仅使用单个训练种子评估机器遗忘的局限性", "title_en": "On the limitation of evaluating machine unlearning using only a single training seed", "authors": "Jamie Lanyon,Axel Finke,Petros Andreou,Georgina Cosma", "background": "机器遗忘（MU）的目标是从已训练的模型中去除某些数据点的影响，而无需昂贵的重新培训。大多数实用的MU算法仅能达到近似效果，其性能只能通过经验评估。因此，需要尽可能使经验比较具有代表性。通常的做法是从相同的已训练模型开始，独立运行MU算法多次。研究表明，即使在相同的架构和相同的数据集下，某些MU方法对用于模型训练的随机数种子的选择高度敏感，这可能导致评估结果非代表性强。因此，建议在评估MU算法时反映不同模型训练种子之间的变化性。", "innovation": "该研究揭示了仅使用单个训练种子评估MU算法的局限性，强调了在评估MU算法时需要考虑不同模型训练种子选择的影响，以确保评估结果的代表性和准确性。这种关注提高了对MU算法性能评估的严谨性，促进了机器学习模型更加透明和可控的发展。", "conclusion": "该研究建议在评估MU算法时，应考虑到不同模型训练种子的影响。仅使用单个训练种子进行评估可能会导致评估结果的高度非代表性。因此，为了获得更可靠和准确的评估结果，应该考虑多种子下的模型训练及其影响。"}
{"llm_update_time": "20251101", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.26715", "html_url": "https://arxiv.org/abs/2510.26715", "title": "LSM-MS2: 一种连接光谱识别与生物解释的基础模型", "title_en": "LSM-MS2: A Foundation Model Bridging Spectral Identification and Biological Interpretation", "authors": "Gabriel Asher,Devesh Shah,Amy A. Caudy,Luke Ferro,Lea Amar,Ana S. H. Costa,Thomas Patton,Niall O'Connor,Jennifer M. Campbell,Jack Geremia", "background": "目前，大量质谱数据未被充分表征，其生物和化学信息未被充分利用。最近，机器学习的进展开始解决这个问题，特别是在串联质谱数据中实现光谱识别的任务上。现有的方法难以识别复杂样本中具有挑战性的同分异构化合物，识别准确率不高，且在低浓度条件下稳定性较差。因此，需要更先进的工具来改进光谱识别的准确性和生物解释能力。", "innovation": "本文介绍了LSM-MS2，这是一种大规模的深度学习基础模型，基于数百万光谱训练，学习语义化学空间。LSM-MS2在光谱识别方面达到了最先进的性能，相比现有方法准确率提高了30%，在复杂生物样品中正确识别的比例增加了42%，且在低浓度条件下表现出色。此外，LSM-MS2能够生成丰富的光谱嵌入，可以直接进行生物解释，成功区分疾病状态并预测临床结果，具有广泛的转化应用潜力。", "conclusion": "LSM-MS2在光谱识别方面表现出优越性能，并能够直接提供生物解释，这将极大地推动质谱数据分析在多种转化应用中的发展。"}
{"llm_update_time": "20251101", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.26776", "html_url": "https://arxiv.org/abs/2510.26776", "title": "通过高级采样实现可靠且快速的影响函数", "title_en": "Faithful and Fast Influence Function via Advanced Sampling", "authors": "Jungyeon Koh,Hyeonsu Lyu,Jonggyu Jang,Hyun Jong Yang", "background": "影响函数(IFs)作为一种后处理方法，利用梯度和海森矩阵来解释训练数据对黑盒模型的影响。然而，计算整个数据集的海森矩阵资源密集，因此需要一种可行的替代方案。一种常见做法是随机采样数据集中的一个小子集，但这可能导致IF估计结果的高度不一致性，因为样本配置具有高方差。", "innovation": "本文提出了一种基于特征和logits的两种高级采样技术来解决上述问题。这些采样器通过考虑特征或logits的随机分布来选择一个小而代表性的数据子集，从而提高IF估计的准确性。实验验证了该方法在使用F1分数衡量模型对于移除类别的遗忘效果和剩余类别的推断一致性方面的有效性。", "conclusion": "该方法在基线方法上计算时间减少30.1%，内存使用减少42.2%，或者在F1分数上提高2.5%。"}
{"llm_update_time": "20251101", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.26745", "html_url": "https://arxiv.org/abs/2510.26745", "title": "深度序列模型倾向于记忆几何结构；不清楚背后原因。", "title_en": "Deep sequence models tend to memorize geometrically; it is unclear why", "authors": "Shahriar Noroozizadeh,Vaishnavh Nagarajan,Elan Rosenfeld,Sanjiv Kumar", "background": "在序列建模中，参数化记忆通常被抽象为实体共现的直接查找。本文通过对比关联视角和几何视角，隔离了一个与这一机制不兼容的Transformer推理实例，从而揭示了更深层的神经嵌入几何结构难以解释的本质。尽管优化仅针对局部关联，这种几何结构的出现仍不是能被传统架构或优化压力解释。即使几何结构在某些方面不如粗暴查找关联语义简洁，模型仍然能够学习出优雅的几何结构。", "innovation": "本文通过分析Transformer推理的本质，提出了一种新颖的观点，即基础的神经嵌入几何结构并非直接由局部联系驱动，而是模型在训练过程中自我合成了一种全球性的关系几何。此外，本文还通过Node2Vec的关联揭示了光谱偏好是如何自然产生的，而不是受到各种压力驱动的。这种方法指出了研究人员在构建更具有几何特征的记忆能力时有一个改进的空间。", "conclusion": "本文揭示了序列模型学习几何结构的现象，并强调了这种现象背后的原因并非简单的优化压力或架构设计。极具启发地，提出了一个观察点，即通过增加模型的几何特性来改进Transformer的记忆功能。希望这种几何视角能够激发研究人员重新审视他们在知识获取、容量、发现和遗忘等领域中的默认直觉。"}
{"llm_update_time": "20251101", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.26777", "html_url": "https://arxiv.org/abs/2510.26777", "title": "预训练的预测模型：强大的零样本特征抽取器用于时间序列分类", "title_en": "Pre-trained Forecasting Models: Strong Zero-Shot Feature Extractors for Time Series Classification", "authors": "Andreas Auer,Daniel Klotz,Sebastinan Böck,Sepp Hochreiter", "background": "近期对时间序列基础模型的研究主要集中在预测上，这使得人们对它们学习出的表示的泛化能力不够清楚。这项研究旨在探讨冻结的预训练预测模型在分类任务中的有效性，并通过不同的表示提取策略和引入两种模型无关的嵌入增强技术来进行比较实验。研究表明，最佳的预训练预测模型在分类准确度上能够匹佛陀乃至超越为特定分类任务预训练的顶级模型，且发现预测和分类性能之间存在正相关关系。这些结果挑战了任务特定预训练必要性的假设，表明学会预测可能是构造通用时间序列基础模型的强大途径。", "innovation": "研究引入了两种模型无关的嵌入增强技术，并比较了不同的表示提取策略。实验结果表明，冻结的预训练预测模型在分类上的准确度与特定任务预训练的顶级模型相当甚至超过，并发现预测与分类性能之间存在正相关关系。这挑战了已有假设，表明预测能提供构建通用时间序列基础模型的强大方法。", "conclusion": "研究表明，预训练的预测模型能够在分类任务中提供强大的零样本特征，挑战了任务特定预训练的必要性假设。学会预测可能为构建通用时间序列基础模型提供了一种有效的方法。"}
{"llm_update_time": "20251101", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.26722", "html_url": "https://arxiv.org/abs/2510.26722", "title": "非凸的波形超启联邦学习: 偏差-方差权衡", "title_en": "Non-Convex Over-the-Air Heterogeneous Federated Learning: A Bias-Variance Trade-off", "authors": "Muhammad Faraz Ul Abrar,Nicolò Michelusi", "background": "空中传输（Over-the-air, OTA）联邦学习（Federated Learning, FL）因其能利用无线multi-access频道的波形叠加而聚合模型更新，得到了广泛应用。现有的OTA-FL设计通常通过假设无线条件相同（等路径损耗）或强制零偏差更新以确保收敛。但在无线条件不一致的情况下，这些设计受限于最差设备，从而放大了更新的方差。而早期关于有偏OTA-FL的分析主要在凸目标函数方面，然而大多数现代AI模型都是高度非凸的。基于这些不足，本文研究了在无线异构条件下利用随机梯度下降（Stochastic Gradient Descent, SGD）的通用光滑非凸目标函数OTA-FL。", "innovation": "本文提出了新的具有结构化的时间不变模型偏差的OTA-FL SGD更新方法，实现方差减小的更新。同时，推导了一个有限时间相位点约束（预期时间平均梯度范数平方和），明确揭示了偏差和方差间的关系。在此权衡的基础上，提出了一种非凸联合OTA功率控制设计，并开发了仅需基站统计信道状态信息（Statistical Channel State Information, CSI）的高效连续凸逼近（Successive Convex Approximation, SCA）算法。实验验证，基于SCA的设计通过优化偏差加速了收敛，并在非凸图像分类任务中超过了现有的OTA-FL基准结果。", "conclusion": "文章研究了在无线异构条件下非凸目标函数的OTA-FL，提出了一种新的OTA-FL SGD更新方法。通过考虑偏差和方差的权衡，有效减小了更新的方差并加快了收敛速度。提出的SCA算法在优化偏差方面表现出优越性，提高了通用性。"}
{"llm_update_time": "20251101", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.26771", "html_url": "https://arxiv.org/abs/2510.26771", "title": "STaMP: 序列变换和混合精度量化用于低精度激活量化", "title_en": "STaMP: Sequence Transformation and Mixed Precision for Low-Precision Activation Quantization", "authors": "Marco Federici,Riccardo Del Chiaro,Boris van Breugel,Paul Whatmough,Markus Nagel", "background": "量化是降低生成型AI模型推理时延、功率和内存占用的关键方法。然而，当激活量化到低于八位时，准确率通常会急剧下降。近期研究指出，可逆线性变换（如旋转变换）有助于量化，通过重新参数化特征通道和权重可以减轻这一问题。本文在此基础上，提出了一种新的量化策略，即STaMP（Sequence Transformation and Mixed Precision）量化，可以在保留足够精度的少量令牌的情况下，维持模型的准确率，同时降低激活的平均位宽。这项研究集中在语言和视觉数据中的强局部相关性上，通过线性变换利用这种相关性来提高低比特宽度激活量化的效果。", "innovation": "本文提出了STaMP量化策略，这是一种在序列维度上应用线性变换的全新方法，通过对中间激活过程中的少量令牌保留较高精度，可以在较低平均比特宽度的情况下保持模型准确性。STaMP通过这种新颖的方法显著改善了低比特宽度激活的量化，并补充了现有的激活和权重量化方法，包括较新的特征变换技术，从而加强了模型的性能。", "conclusion": "本文通过实验评估在最新架构LVM和LLM上的STaMP量化策略，结果显示STaMP显著提升了低比特激活的量化性能，并且与现有的一些量化方法相结合，可以进一步增强模型的性能。此外，STaMP作为一个新的策略，能够更好地利用语言和视觉数据中的强局部相关性，从而在低精度量化的同时保持较高的准确率。"}
{"llm_update_time": "20251101", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.26782", "html_url": "https://arxiv.org/abs/2510.26782", "title": "使用几何正则化世界模型克隆确定性3D世界", "title_en": "Clone Deterministic 3D Worlds with Geometrically-Regularized World Models", "authors": "Zaishuo Xia,Yukuan Lu,Xinyi Li,Yifan Xu,Yubei Chen", "background": "世界模型是一种内部模型，可以模拟世界的发展。给定过去的观察和行动，它可以预测代理及其环境的未来。为了使代理能够在复杂、动态的环境中有效思考、计划和推理，需要构建准确的世界模型。然而，当前的世界模型在长时间范围内的表现仍然脆弱且容易退化，这主要是因为感知输入的高维度性和损失或纠缠的状态变量使得动态学习变得没有必要地复杂。因此，本文探讨了是否仅通过改进表示学习就能够显著提升世界模型的表现。", "innovation": "本文提出了几何正则化世界模型（GRWM），该模型强制连续自然感知轨迹中的点在潜在表示空间中保持接近。这种方法提供了明显改善的潜在表示，这些表示与环境的真实拓扑结构密切相关。GRWM易于实现，只需进行少量的架构修改，可随轨迹长度扩展，并与各种潜在生成模型兼容。实验表明，GRWM在确定性3D场景和长时间范围预测任务中显著增强了展开精度和稳定性。分析显示，其优势源自学习到具有优越几何结构的潜在流形。", "conclusion": "这些发现支持一个明确的结论：通过改进表示学习直接且有效地提升了世界模型的鲁棒性，能够在不扩大动力学模块的情况下提供可靠的长时间预测。"}
{"llm_update_time": "20251101", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.26787", "html_url": "https://arxiv.org/abs/2510.26787", "title": "远程劳动力指数：评估人工智能在远程工作的自动化", "title_en": "Remote Labor Index: Measuring AI Automation of Remote Work", "authors": "Mantas Mazeika,Alice Gatti,Cristina Menghini,Udari Madhushani Sehwag,Shivam Singhal,Yury Orlovskiy,Steven Basart,Manasi Sharma,Denis Peskoff,Elaine Lau,Jaehyuk Lim,Lachlan Carroll,Alice Blair,Vinaya Sivakumar,Sumana Basu,Brad Kenstler,Yuntao Ma,Julian Michael,Xiaoke Li,Oliver Ingebretsen,Aditya Mehta,Jean Mottola,John Teichmann,Kevin Yu,Zaina Shaik,Adam Khoja,Richard Ren,Jason Hausenloy,Long Phan,Ye Htet,Ankit Aich,Tahseen Rabbani,Vivswan Shah,Andriy Novykov,Felix Binder,Kirill Chugunov,Luis Ramirez,Matias Geralnik,Hernán Mesura,Dean Lee,Ed-Yeremai Hernandez Cardona,Annette Diamond,Summer Yue,Alexandr Wang,Bing Liu,Ernesto Hernandez,Dan Hendrycks", "background": "人工智能在知识和推理方面的研究基准上取得了快速进步，但这些进步如何转化为经济价值和自动化仍然不清楚。为了衡量这一点，该研究引入了远程劳动力指数（RLI），这是一个涵盖多个行业的广泛基准，包含真实的、具有经济价值的项目，旨在评估代理在实际操作中的整体表现。AI代理在RLI上表现接近最低水平，最高性能的代理仅实现了2.5%的自动化率。这有助于将关于AI自动化的讨论建立在实际证据的基础上，为跟踪AI影响和使利益相关者能够积极应对AI驱动的劳动力自动化奠定了共同基础。", "innovation": "本文提出了远程劳动力指数（RLI），这是一个实际应用、多行业评估AI代理在真实环境中的整体表现的基准，填补了当前对AI在知识和推理研究中进展转化为经济发展价值和自动化应用不清楚的空白。通过RLI，研究证明了在真实环境中的AI代理的自动化率远低于预期，为实际应用AI提供了理论依据和数据支持。", "conclusion": "本文的研究成果为评估人工智能在远程工作的自动化提供了新的方法，即远程劳动力指数（RLI）。该指数的引入使得关于AI自动化的讨论更加基于实证数据，同时提供了跟踪AI影响和应对AI驱动的劳动力自动化的一种机制，有助于利益相关者采取前瞻性的策略。"}
{"llm_update_time": "20251101", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.26788", "html_url": "https://arxiv.org/abs/2510.26788", "title": "通过FP16克服训练-推理不匹配", "title_en": "Defeating the Training-Inference Mismatch via FP16", "authors": "Penghui Qi,Zichen Liu,Xiangxin Zhou,Tianyu Pang,Chao Du,Wee Sun Lee,Min Lin", "background": "在使用强化学习（RL）对大型语言模型（LLM）进行微调时，由于训练和推理策略之间的数值不匹配而常常出现不稳定性。尽管先前的工作试图通过算法纠正或工程对齐来解决此问题，但研究表明其根本原因是浮点精度本身。尽管BF16因其大的动态范围而被广泛采用，但它引入了很大的舍入误差，破坏了训练和推理之间的一致性。", "innovation": "我们证明，简单地恢复到FP16可以有效地消除这种不匹配。该改变简单，由现代框架完全支持，只需更改几行代码，无需修改模型架构或学习算法。我们的结果显示，使用FP16一致地提供更稳定的优化、更快的收敛和更强的表现，涵盖多种任务、算法和框架。", "conclusion": "我们希望这些发现能够促使更广泛的重新考虑在RL微调中的精度权衡。"}
{"llm_update_time": "20251101", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.26792", "html_url": "https://arxiv.org/abs/2510.26792", "title": "使用变压器学习伪随机数：移位同余生成器、课程学习与可解释性", "title_en": "Learning Pseudorandom Numbers with Transformers: Permuted Congruential Generators, Curricula, and Interpretability", "authors": "Tao Tao,Maissam Barkeshli", "background": "该研究探讨了Transformer模型学习由移位同余生成器（PCGs）生成的序列的能力。PCGs是一类广泛使用的伪随机数生成器（PRNGs），通过一系列位移、异或、旋转和截断操作增加了复杂性，从而与线性同余生成器（LCGs）相比增加了显著的难度。尽管如此，研究表明Transformer模型能够在未见过的序列中进行上下文内预测，这些序列来自多种PCG变体，这超越了已发布的经典攻击任务。", "innovation": "研究发现，即使输出被截断为单个比特，模型也能可靠地预测该输出。此外，当在训练中同时展示多个不同的PRNG时，模型能够共同学习它们，识别不同排列结构。研究揭示了一个扩展定律，即接近完美的预测所需上下文序列元素数量随着模数的平方根增长。对于较大的模数，优化会出现长时间的停滞阶段。另发现模型能够自发地将整数输入分组成位旋转不变的簇，揭示了代表如何在较小模数向较大模数转移。", "conclusion": "研究发现，Transformer模型能够学习复杂度较高的PCG生成的序列，且即使输出截断为单个比特也能进行可靠预测。模型能够联合学习多个不同PRNG，识别结构来自不同排列。模型对模数较大的PRNG的优化会进入长时间停滞状态，这要求引入较小模数的数据以辅助学习。最后，研究揭示了输入表示如何在较小模数中与较大模数之间转移。"}
{"llm_update_time": "20251101", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.24736", "html_url": "https://arxiv.org/abs/2510.24736", "title": "RNAGenScape: Property-guided Optimization and Interpolation of mRNA Sequences with Manifold Langevin Dynamics", "title_en": "RNAGenScape: Property-guided Optimization and Interpolation of mRNA Sequences with Manifold Langevin Dynamics", "authors": "Danqi Liao,Chen Liu,Xingzhi Sun,Dié Tang,Haochen Wang,Scott Youlten,Srikar Krishna Gopinath,Haejeong Lee,Ethan C. Strayer,Antonio J. Giraldez,Smita Krishnaswamy", "background": "虽然mRNA的设计和优化在合成生物学和治疗开发中至关重要，但在机器学习中的研究仍较少。系统地优化mRNA受到数据稀缺和不平衡以及复杂的序列-功能关系的影响。现有的方法在处理有限和欠采样的数据时效果不佳，且在保持中间产物接近可行的mRNA圆盘方面存在挑战。", "innovation": "提出了RNAGenScape，这是一种基于属性的流形拉格朗日动力学框架，可以在学习的潜在空间中迭代更新mRNA序列。RNAGenScape结合了一个有组织的自动编码器来结构化潜在空间，以便高效地生物合理地探索，以及一个流形投影器将每次更新带回流形。RNAGenScape支持属性导向的优化和序列之间的平滑插值，同时在稀缺和欠采样的数据下保持鲁棒性，确保中间产品接近可行的mRNA流形。RNAGenScape在三个真实的mRNA数据集上表现出色，相比其他为蛋白质或非生物数据设计的生成或优化方法，它提高了靶标属性的成功率和效率。", "conclusion": "通过提供与数据对齐的连续轨迹，揭示编辑如何影响功能，RNAGenScape建立了一个可扩展的框架，用于mRNA设计和潜在空间探索，在mRNA序列建模中具有可控性。"}
{"llm_update_time": "20251101", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.25775", "html_url": "https://arxiv.org/abs/2510.25775", "title": "使用SHAP实现棋盘位置的逐个棋子解释", "title_en": "Towards Piece-by-Piece Explanations for Chess Positions with SHAP", "authors": "Francesco Spinnato", "background": "当代国际象棋程序提供的评估是精确但不透明的，通常以厘子分数表示。尽管这部分用于决策制定，但这些输出掩盖了单独棋子或模式的贡献。本文旨在通过采用SHAP来探索在国际象棋分析领域适应这些方法，以便将评估归因于棋盘上的特定棋子。这种方法借鉴了经典的国际象棋教学方法，其中棋手通过在心中移除棋子来评估局面，并将其与现代可解释人工智能技术相结合。这种方法为未来可解释的国际象棋人工智能研究打开了新的可能性，包括可视化、人类训练和程序比较等方面。", "innovation": "本文采用SHAP方法，将国际象棋中的棋子视为特征变量，通过系统性地替换这些棋子（或在局部范围下移除它们），来计算棋子级别的贡献，从而为这些引擎的输出提供局部忠实且人类可理解的解释。这种方法将经典国际象棋教学方法与现代可解释人工智能技术相结合，为领域内的研究提供了新的视角和工具。", "conclusion": "本文的方法为洞察和解释国际象棋评估结果提供了新的工具，有助于提高人类对棋局的理解，并且提供了可解释的国际象棋人工智能系统的新范式。此外，文章还提供了配套的代码和数据集，以促进进一步的研究和发展。"}
{"llm_update_time": "20251101", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.25784", "html_url": "https://arxiv.org/abs/2510.25784", "title": "zfLORA: 零延迟融合低秩适配器", "title_en": "zFLoRA: Zero-Latency Fused Low-Rank Adapters", "authors": "Dhananjaya Gowda,Seoha Song,Harshith Goka,Junhyun Lee", "background": "近年来，专门为多个下游应用设计的任务特定适配器正被部署在大型语言模型（LLMs）上。虽然适配器参数的数量通常低于基础模型的1%，但在推理阶段，这种适配器却产生了不成比例的额外计算负担，最多可达基础模型的2.5倍。因此，如何减少这种额外的计算负担变得尤为重要，尤其是要在保证性能的前提下实现零或近乎零的延迟开销成为了一个挑战。", "innovation": "本文提出了一个新的零延迟融合低秩适配器（zFLoRA），该适配器在基础模型上增加了零或近乎零的延迟开销。实验结果表明，在1B、3B和7B规模的LLMs上，zFLoRA在零延迟的情况下与流行的监督微调基准、包括低秩适配器（LoRA）以及全微调（FFT）相比表现良好。实验选择了18个不同任务，覆盖常识推理、数学推理和总结对话三个类别。在NPU（三星Galaxy S25+）和GPU（NVIDIA H100）平台上进行的延迟测量结果显示，提出的方法引入了零到近乎零的延迟开销。", "conclusion": "研究结果表明，zFLoRA在保证性能的同时能够显著减少推理过程中的额外计算负担，适合在多任务应用中部署。"}
{"llm_update_time": "20251101", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.25774", "html_url": "https://arxiv.org/abs/2510.25774", "title": "利用深度学习进行脉冲星检测", "title_en": "Pulsar Detection with Deep Learning", "authors": "Manideep Pendyala", "background": "脉冲星巡天会产生数百万个候选体，人工检查的任务量巨大。本研究构建了一个基于深度学习的管道，结合阵列特性和图像诊断来筛选射电脉冲星候选体。利用大约500GB的GMRT数据，将原始电压转换为滤波器组（SIGPROC），再经过去延迟和相位折叠（PRESTO）处理，产生了约32,000个候选体。每个候选体生成了四种诊断——总轮廓、时间对相位、子带对相位以及DM曲线，表示为数组和图像。", "innovation": "基线模型通过将神经网络（ANNs）用于阵列数据，并将卷积神经网络（CNNs）用于图像数据，并采用逻辑回归融合，准确率达到了68%。通过优化CNN结构和训练（正则化、学习率计划、最大范数约束），以及通过GAN生成器进行针对性增广来缓解类别不平衡，最终取得了87%的准确率。最后，GAN+CNN系统在保持轻量级的同时，在测试集上实现了94%的准确率，具有均衡的精确率和召回率。结合阵列和图像通道可以提高与其他仅图像方法的可分性，适度的生成性增广可以显著增加脉冲星的召回率。该方法可适用于各种巡天任务，并且可扩展到未来的高通量设施。", "conclusion": "利用结合了阵列特性和图像诊断的深度学习方法，可以显著提高脉冲星候选体的筛选准确率，同时保持了计算上的高效性，适用于未来高通量设施的数据处理。"}
{"llm_update_time": "20251101", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.25787", "html_url": "https://arxiv.org/abs/2510.25787", "title": "基于电压依赖性突触可塑性的无监督局部学习算法及其在阻变和铁电突触中的应用", "title_en": "Unsupervised local learning based on voltage-dependent synaptic plasticity for resistive and ferroelectric synapses", "authors": "Nikhil Garg,Ismael Balafrej,Joao Henrique Quintino Palhares,Laura Bégon-Lours,Davide Florini,Donato Francesco Falcone,Tommaso Stecconi,Valeria Bragaglia,Bert Jan Offrein,Jean-Michel Portal,Damien Querlioz,Yann Beilliard,Dominique Drouin,Fabien Alibart", "background": "边端计算设备在部署AI时面临能耗和功能方面的重大挑战，这些设备如果能利用受脑启发的学习机制，在保证低功耗的同时实现即时适应非常有益。阻性存储器进行的局域计算可能为执行这些边缘设备上的AI负载提供关键支持。然而，传统的时间依赖性可塑性（STDP）方法需要复杂的脉冲整形电路，这限制了其应用。本文的目的在于探讨电压依赖性突触可塑性（VDSP）作为高效无监督和局域学习方法的潜力。", "innovation": "介绍了一种基于Hebbian原则的电压依赖性突触可塑性（VDSP）方法，用于阻变性突触和铁电隧穿结的无监督和局域学习。该方法消除了使用传统STDP方法所需的复杂脉冲整形电路，非常适合不同类型的阻变突触和铁电隧穿结，并通过系统级的突触神经网络仿真展示了在MNIST数据集上的优越性能，达到高精度。", "conclusion": "通过VDSP方法，设计的神经网络在多种类型的阻变和铁电突触结构中实现了无监督学习，达到83%以上的识别准确率，使用了200个神经元。同时，对这些设备的变异性和阈值差异进行了评估，并提出了增强鲁棒性的策略。"}
{"llm_update_time": "20251101", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.25778", "html_url": "https://arxiv.org/abs/2510.25778", "title": "基于模糊逻辑算法方法的基于评论的实体排名分析", "title_en": "Review Based Entity Ranking using Fuzzy Logic Algorithmic Approach: Analysis", "authors": "Pratik N. Kalamkar,Anupama G. Phakatkar", "background": "意见分析是研究人们对产品、服务、组织、个人、议题、事件、话题及属性的看法、情感、评价和态度的领域。传统的全方位词汇方法未考虑每个观点的强度，即观点到底是非常负面（或正向）的、强烈负面（或正向）的、中等负面（或正向）的、非常弱负面（或正向）的或是弱负面（或正向）的。本文探讨了一种方法，通过结合与特定产品相关方面的意见词（如副词、形容词、名词和动词），按强度（非常弱、弱、中等、非常强和强）对实体和用户查询进行分类，并据此对实体进行排名，用以改善意见分析的方法和准确度。", "innovation": "本文提出了一种基于模糊逻辑算法的方法，用于按实体评论的意见方向和强度对实体进行排名，并分类相关方面的意见词。这种方法通过利用意见词（如副词、形容词、名词和动词），并结合语义依赖解析来确定所需方面单词的关系，为特定方面制定实体得分，从而更准确地评估态度和情感强度。", "conclusion": "本文提出的方法通过模糊逻辑算法和语义解析，增强了情感强度的识别和实体排名的效果。研究为后续的情感分析研究提供了新的方向，并表明这种结合模糊逻辑和语义分析的方法可以更准确地理解用户意见。"}
{"llm_update_time": "20251101", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.25802", "html_url": "https://arxiv.org/abs/2510.25802", "title": "注意力增强的GNN RNN-注意力模型在高级网络安全入侵检测中的应用", "title_en": "Attention Augmented GNN RNN-Attention Models for Advanced Cybersecurity Intrusion Detection", "authors": "Jayant Biradar,Smit Shah,Tanmay Naik", "background": "本文基于复杂网络环境中网络安全入侵检测的需要，分析了现有网络安全入侵检测方法的局限性。传统的机器学习方法和独立的深度学习模型在处理复杂的网络流量模式和高级的攻击模式（如APT、DDoS攻击和零日漏洞）时表现不佳。为此，研究者需要一种能够同时捕捉空间依赖性和时间动态性的新方法来提高检测能力。", "innovation": "本文提出了一种新的深度学习混合架构，结合了图神经网络（GNNs）、循环神经网络（RNNs）和多头注意力机制，以大幅提高网络安全入侵检测能力。该方法通过使用包含多种网络流量模式的UNSW-NB15数据集，有效地捕捉了空间依赖性和时间动态性，并通过集成注意力机制提高了模型的可解释性和特征选择能力。实验结果显示，该混合模型在多个评估指标（准确率、精确率、召回率和F1分数）上优于传统机器学习方法和独立的深度学习模型，并且特别擅长检测高级攻击模式，显示出作为下一代网络安全应用的有前途的解决方案。", "conclusion": "本文提出的混合模型在多个方面的评估指标中表现优异，特别是在检测高级攻击模式方面表现出色。该模型为复杂网络环境下的下一代网络安全应用提供了有效的解决方案，具有重要的研究和实际应用价值。"}
{"llm_update_time": "20251101", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.25809", "html_url": "https://arxiv.org/abs/2510.25809", "title": "Flex-GAD：灵活的图异常检测", "title_en": "Flex-GAD : Flexible Graph Anomaly Detection", "authors": "Apu Chakraborty,Anshul Kumar,Gagan Raj Gupta", "background": "在包含结构连接和描述性属性的属性网络中，检测异常节点对识别社交网络、学术引用图和电子商务平台中的欺诈、虚假信息和可疑行为至关重要。", "innovation": "Flex-GAD 是一种新颖的无监督框架，用于节点级别的图异常检测，通过集成两种捕捉图形数据不同方面的编码器，融入了一个基于社区的GCN编码器来模型社区内外部信息，并利用自注意力机制的表示融合模块来适应性加权和有效整合编码信息。", "conclusion": "Flex-GAD 在七个不同规模、节点度和属性同质性的现实世界属性图上的评估表明，它平均在AUC上提高7.98%，比之前表现最好的方法GAD-NR更有效且更具灵活性。此外，与基准数据集上的 Anomaly DAE 和 GAD-NR 相比，Flex-GAD 以更快的速度运行，平均每轮快102倍和3倍。"}
{"llm_update_time": "20251101", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.25776", "html_url": "https://arxiv.org/abs/2510.25776", "title": "StreetMath: 研究LLMs的近似行为", "title_en": "StreetMath: Study of LLMs' Approximation Behaviors", "authors": "Chiung-Yi Tseng,Somshubhra Roy,Maisha Thasin,Danyang Zhang,Blessing Effiong", "background": "已有大量文献研究大型语言模型（LLMs）的数学推理能力，特别是在自回归架构中执行精确的算术运算。然而，这些模型在非正式、快节奏的数学操作中的近似推理能力却很少受到关注，尤其是在非自回归解码模型中。本文旨在填补这一空白，通过引入StreetMath基准测试，评估模型在真实世界的近似场景中的近似能力。StreetMath被用来评估不同的LLM架构，包括Qwen3-4B-Instruct-2507、Qwen3-4B-Thinking-2507、Dream-v0-Instruct-7B、Falcon-Mamba-7B-Instruct和Mamba-GPT-3B。还使用了机械解释技术来探究模型内部的计算状态。分析表明，尽管模型在某些早期层或步骤中可以得出正确的答案，但它们在完成近似任务时仍消耗更多token。实验还显示精确和近似算术运算主要依赖于不同的神经组件。从认知心理学的角度来看，研究人员认为，LLMs在街景数学设置中并不像人类那样表现出认知吝啬。", "innovation": "本文通过引入StreetMath基准测试，首次全面评估了不同LLM架构在现实生活中的近似推理能力。此外，研究使用了机械解释技术来深入探究模型的内部计算状态，揭示了模型在近似任务中的一些独特行为，特别是与精确计算的不同之处。这有助于提高我们对LLM如何处理复杂任务的理解，并进一步推动LLM技术的发展。", "conclusion": "研究发现，尽管LLMs在某些情况下可以得出正确的答案，但它们在近似任务中依然依赖于精确计算或外部工具，消耗更多的计算资源。此外，精确和近似计算主要依赖于不同的神经组件。从认知心理学的角度来看，LLMs在街景数学设置中并不表现出与人类相同的认知吝啬。这些发现为进一步的研究提供了重要的实证基础，有助于更好地理解LLMs的工作原理，并推动相关技术的进步。"}
{"llm_update_time": "20251101", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.25811", "html_url": "https://arxiv.org/abs/2510.25811", "title": "多模态多臂老虎机：遗憾下界与最优算法", "title_en": "Multimodal Bandits: Regret Lower Bounds and Optimal Algorithms", "authors": "William Réveillard,Richard Combes", "background": "研究了一个具有独立同分布奖励的随机多臂老虎机问题，其中期望奖励函数最多有m个模态。在此背景下，现有研究尚未提出可以计算格雷夫斯-莱伊优化问题解的计算上可行的算法，也无法直接实现该问题的渐近最优算法。本研究填补了这一空白，提出了首个计算上述优化问题解的算法，并据此实现了渐近最优的多臂老虎机算法。", "innovation": "提出了一种计算上可行的算法来解决格雷夫斯-莱伊优化问题，从而能够实现该多模态多臂老虎机问题的渐近最优算法。此创新性地解决了多模态奖励函数下的多臂老虎机问题的系统研究空白。", "conclusion": "本研究提出了首个计算格雷夫斯-莱伊优化问题解的算法，并且该算法能够实现该多臂老虎机问题的渐近最优算法。所提算法的代码已公开发布。"}
{"llm_update_time": "20251101", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.25807", "html_url": "https://arxiv.org/abs/2510.25807", "title": "在单细胞RNA测序基模中发现可解释的生物概念", "title_en": "Discovering Interpretable Biological Concepts in Single-cell RNA-seq Foundation Models", "authors": "Charlotte Claye(MICS),Pierre Marschall,Wassila Ouerdane(MICS),Céline Hudelot(MICS),Julien Duquesne", "background": "单细胞RNA-seq基模在下游任务中表现出色，但由于其黑箱性质限制了生物发现的应用。虽然最新的研究表明稀疏词典学习可以从深度学习模型中提取概念，并且在生物医学成像和蛋白质模型中具有潜在应用，但解释生物概念仍然具有挑战性，因为生物序列本身并不是自然易为人理解的。文章介绍了一种基于概念的新颖可解释框架，专注于概念解释和评价。文章提出了一个基于反事实扭曲的归因方法，以确定影响概念激活的基因，从而超越传统的相关性分析。接着，提供两种互补的解释方法：一种是基于专家的交互式分析和一种基于本体论的归因驱动生物途径富集方法。该框架应用于文献中的两个免疫细胞数据集上训练的Top-K稀疏自编码器的两个已知单细胞RNA-seq模型，通过免疫学领域的专家证明，概念相比单个神经元改善了可解释性，同时保持了潜在表示的丰富性和信息量。这项工作为解释基模中编码的生物学知识提供了一种有原则的框架，为假设生成和发现铺平了道路。", "innovation": "文章提出了基于反事实扭曲的归因方法，以识别影响概念激活的关键基因，提供专家驱动的交互式分析，并提出了基于本体论的归因驱动的生物途径富集方法。这种方法超越了传统的相关性分析方法，通过实例展示了在单细胞RNA-seq基模中解释生物学概念的有效性和实用性。这些方法有助于更好地理解和利用单细胞RNA-seq模型在生物学发现中的潜力。", "conclusion": "文章提供了在单细胞RNA-seq基模中解释生物学概念的新框架，证明了该框架在提高可解释性方面的效果，同时保留了基模潜在表示的丰富性和信息量，并展示了其在生成和发现方面的应用价值。"}
{"llm_update_time": "20251101", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.25850", "html_url": "https://arxiv.org/abs/2510.25850", "title": "Debate2Create: Robot Co-design via Large Language Model Debates", "title_en": "Debate2Create: Robot Co-design via Large Language Model Debates", "authors": "Kevin Qiu,Marek Cygan", "background": "机器人形态和控制的联合设计是一个长期挑战，因为设计空间非常庞大，身体和行为之间耦合紧密。传统的设计方法难以应对这些问题。", "innovation": "提出了 Debate2Create (D2C) 框架，该框架中大语言模型（LLM）代理进行有结构的辩证辩论，共同优化机器人的设计及其奖励函数。通过迭代辩论，代理不断改进提案，产生越来越有效的机器人设计。D2C 能够生成多样化且专门化的形态，即使没有明确的多样性目标。在四足运动基准测试中，D2C 发现的设计比默认设计行进距离远73%，表明结构化的 LLM 基础辩论可以作为有效的机制来实现机器人联合设计的涌现。", "conclusion": "多代理辩论结合基于物理的反馈，为自动化机器人设计提供了一个有前途的新范式。"}
{"llm_update_time": "20251101", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.25814", "html_url": "https://arxiv.org/abs/2510.25814", "title": "通过肽键断裂预测优化镜像肽序列设计以实现数据存储", "title_en": "Optimizing Mirror-Image Peptide Sequence Design for Data Storage via Peptide Bond Cleavage Prediction", "authors": "Yilong Lu,Si Chen,Songyan Gao,Han Liu,Xin Dong,Wenfeng Shen,Guangtai Ding", "background": "传统非生物存储介质如硬盘在大数据时代面临存储密度和使用寿命有限的问题。镜像肽由D-氨基酸组成，具备高存储密度、结构稳定性和长使用寿命，成为有前景的生物存储介质。然而，镜像肽的测序依赖于从头组装技术，其准确性受限于缺乏串联质谱数据集和处理肽类直接遇到的挑战。", "innovation": "本研究首次通过优化镜像肽序列设计间接提升测序准确度，提出了DBond模型以整合序列特征、质谱前体离子属性和质谱环境因素预测镜像肽键断裂。研究构建了包含513个镜像肽的MiPD513数据集，开发了肽键断裂标记算法PBCLA，生成了约1250万个标记数据，并提出了结合多标签和单标签分类策略的双预测策略，为序列优化提供了坚实基础。", "conclusion": "单标签分类策略在独立测试集上超越了其他方法，在单肽键断裂和多肽键断裂预测任务中表现优异，为镜像肽数据存储的序列优化提供了强有力的支持。"}
{"llm_update_time": "20251101", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.25897", "html_url": "https://arxiv.org/abs/2510.25897", "title": "MIRO: 多奖励条件预训练提高文本到图像生成质量和效率", "title_en": "MIRO: MultI-Reward cOnditioned pretraining improves T2I quality and efficiency", "authors": "Nicolas Dufour,Lucas Degeorge,Arijit Ghosh,Vicky Kalogeiton,David Picard", "background": "当前的文本到图像生成模型在未加筛选的大量数据集上进行训练，以实现多样化的生成能力。然而，这与用户偏好不符。最近，奖励模型被专门设计用于在生成的图像中进行后处理选择，并将其与奖励（通常是用户偏好）对齐。这种方法会摒弃有价值的训练数据，并且优化单一奖励会损害多样性和语义保真度及效率。", "innovation": "本文提出了一种新的方法，即在训练过程中使用多个奖励模型来条件化模型，让模型直接学习用户的偏好。这种方法不仅极大地提高了生成图像的视觉质量，还显著加快了训练速度。", "conclusion": "我们的提出的方法MIRO在GenEval组合基准测试和用户偏好评分（PickAScore，ImageReward，HPSv2）中都达到了最先进的性能。"}
{"llm_update_time": "20251101", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.25816", "html_url": "https://arxiv.org/abs/2510.25816", "title": "超越长上下文：当语义比令牌更重要", "title_en": "Beyond Long Context: When Semantics Matter More than Tokens", "authors": "Tarun Kumar Chawdhury,Jon D. Duke", "background": "电子健康记录（EHR）中的临床文档通常以base64编码的形式存储在FHIR DocumentReference资源中，这使得基于语义的问题回答困难。传统的向量数据库方法往往无法捕捉到细微的临床关系。为了改进这个问题，Lopez等人在2025年引入了一种称为Clinical Entity Augmented Retrieval（CLEAR）的方法，该方法使用实体感知检索，并取得了优于基于嵌入的检索方法（F1分数0.90 vs 0.86）的效果，同时使用了超过70％更少的tokens数量。作者为此开发了一个临床笔记问答评估平台，用于验证CLEAR方法在零样本大上下文推理和传统片段增强生成方面的表现。该平台在包含从10,000到65,000个tokens的12个临床笔记上进行了测试，以模拟真实的EHR内容。结果显示，CLEAR方法取得了58.3％的胜率，平均语义相似度为0.878，比广泛上下文处理的tokens使用少了78％。特别是在长文档上，输贏率达到了75％，对于超过65,000tokens的文档。这些结果证实了基于实体感知的检索方法在临床自然语言处理中的高效性和准确性，同时也提供了一个在语义精度和计算效率方面至关重要的可重复和透明的评估框架。", "innovation": "该研究引入了CLEAR方法，一种基于实体感知的检索方法，它通过使用实体级别信息来改进临床自然语言处理中的效率和准确性。与传统的基于嵌入的方法相比，CLEAR不仅能够提高F1分数（达到了0.90），而且显著减少了所需的tokens数量。此外，为了验证这种创新方法的效果，作者还开发了一个临床笔记问答评估平台，该平台在多种条件下进行了测试，证明了CLEAR方法在处理长文档时的效果显著提升。", "conclusion": "研究结果表明，基于实体感知的检索方法提高了临床自然语言处理的效率和准确性，特别是在处理长文档时表现出色。同时，研究还提供了一个评估临床问答系统的新框架，该框架被认为是评估这种类型系统的关键标准。"}
{"llm_update_time": "20251101", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.25943", "html_url": "https://arxiv.org/abs/2510.25943", "title": "InputDSA：分离和比对接驱动力与外部驱动的动力学", "title_en": "InputDSA: Demixing then Comparing Recurrent and Externally Driven Dynamics", "authors": "Ann Huang,Mitchell Ostrow,Satpreet H. Singh,Leo Kozachkov,Ila Fiete,Kanaka Rajan", "background": "在控制问题和基本科学建模中，比较观测结果与动力学模拟至关重要。比如，比较神经系统的两种模型可以揭示大脑和深度神经网络中新兴计算的性质。最近，Ostrow等人提出了Dynamical Similarity Analysis（DSA），这是一种基于系统循环动力学而不是几何或拓扑结构测量两个系统相似性的方法。然而，DSA没有考虑输入对动力学的影响，因此两个相似系统若受到不同驱动可以被分类为不同的类别。鉴于现实中的动力学系统通常不是自主的，因此必须考虑输入驱动的效果。", "innovation": "作者提出了一种新的度量标准iDSA（InputDSA），用于比较内在（自省的）和输入驱动的动力学。iDSA通过基于子空间识别的变种Dynamic Mode Decomposition with Control（DMDc），估计并比较输入和内在动态操作符。实验结果表明，iDSA可以成功地从嘈杂的数据中比较部分观察到的输入驱动系统。即使在真实输入未知时，也可以用替代输入而不显著降低相似性估计。iDSA应用于使用深度强化学习训练的递归神经网络（RNN），识别表现良好的网络模型动态相似，而表现不好的网络模型则更加多样化。最后，iDSA应用于啮齿动物执行认知任务时记录的神经数据，显示出从输入驱动的证据积累到内在驱动的决策转变。", "conclusion": "我们的工作证明了InputDSA是一种稳健且高效的方法，用于比较内在动力学和外部输入对动力学系统的影响。"}
{"llm_update_time": "20251101", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.25884", "html_url": "https://arxiv.org/abs/2510.25884", "title": "使用多法官学习系统的优选近似", "title_en": "Approximating Human Preferences Using a Multi-Judge Learned System", "authors": "Eitán Sprejer,Fernando Avalos,Augusto Bernardi,Jose Pedro Brito de Azevedo Faustino,Jacob Haimes,Narmeen Fatimah Oozeer", "background": "基于大语言模型（LLM）的裁判难以校准，常常受到评分标准敏感性、偏见和不稳定性的困扰。克服这一挑战对于创建可靠的强化学习来自人类反馈（RLHF）的奖励模型以及构建有效的路由系统（选择最合适的模型以回应用户查询）至关重要。已有研究试图解决这种差异，但存在诸多挑战。本文旨在通过学习聚合多条件评分者的输出来建模多样的人格偏好。", "innovation": "本文提出了一种框架以通过学习聚合多个评分者的输出来建模多样、基于人格的偏好。该框架包括基于人格的方法大规模合成偏好标签，并实现了两种聚合器：一般加性模型（GAM）和多层感知器（MLP）。研究还评估了该方法在处理人类与LLM裁判偏见案例研究中的 robust 性，对比了其与朴素基线的性能。", "conclusion": "通过实验对比与人和LLM裁判偏见的案例研究，本文展示了其方法的优越性。该工作中提出的方法在大规模合成偏好标签和聚合器实现上有所创新，特别是在框架的设计和评价机制的构建上。"}
{"llm_update_time": "20251101", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.25933", "html_url": "https://arxiv.org/abs/2510.25933", "title": "Humains-Junior: 一个通过导向外骨骼推理实现GPT-4o级事实准确性的3.8B语言模型", "title_en": "Humains-Junior: A 3.8B Language Model Achieving GPT-4o-Level Factual Accuracy by Directed Exoskeleton Reasoning", "authors": "Nissan Yaron,Dan Bystritsky,Ben-Etzion Yaron", "background": "该研究探讨了如何利用较小规模的语言模型（如人类教辅模型Humans-Junior，拥有约3.8B参数量）在特定任务上达到与大模型（如GPT-4o）相当的性能，特别是在事实接地（FACTS Grounding）任务上。背景包括事实接地任务的定义和重要性，即模型需要能够准确地将语言描述与现实世界对象、实体或场景关联起来。该领域当前的挑战和存在的差距也得到了讨论，特别是在成本效率、计算资源和模型规模之间的权衡方面。", "innovation": "该研究的主要创新在于提出了一种结合了最小化导向“外骨骼推理”结构和行为微调的方法。这种方法注重教协议遵守（知识纪律）而不是特定领域的答案，以实现更高的准确性和更低的成本。在相同条件下评估下，Humans-Junior模型在Q1到Q500的问题集上达到了72.7%的准确度，只比GPT-4o略低0.8个百分点。此外，与GPT-4o相比，Humans-Junior的托管API成本大约低了19倍，在自我托管或边缘部署场景中，甚至可以将额外推理成本降到接近零。", "conclusion": "研究结论是，3.8B参数的模型可以通过导向外骨骼推理达到GPT-4o级别的事实准确性（Q1到Q500等价范围±5个精确点）。云定价显示相对GPT-4o大约19倍成本优势，而自我托管/边缘部署可将边际成本几乎降为零。导向推理在前沿模型上的效果显著，提升了GPT-4o和Gemini-2.5-Pro的准确度，特别是在仅基于提示设置的情况下。这些方法被证明可以有效降低成本并提高模型的适应性和效率。"}
{"llm_update_time": "20251101", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.25974", "html_url": "https://arxiv.org/abs/2510.25974", "title": "人类与机器协作在机器学习目标变量实现中面临的机遇与风险", "title_en": "Risks and Opportunities in Human-Machine Teaming in Operationalizing Machine Learning Target Variables", "authors": "Mengtian Guo,David Gotz,Yue Wang", "background": "预测建模有可能提升人类的决策制定。然而，许多模型由于在预测目标是抽象概念或构造时，问题定义上的不当导致失败。这时，研究人员需要定义适当的代理目标变量来操作化感兴趣的构造。但在实践中，选择合适的代理目标变量往往是不明显的，既需要领域知识又需要迭代的数据建模。这一过程是具有协作性的，涉及领域专家和数据科学家。本文探讨了人类与机器合作如何通过加速迭代过程同时保留人类判断力来支持这一过程。", "innovation": "研究对比了两种人类与机器协作策略对代理目标变量构建的影响：1) 相关性优先：人类主导选择相关代理变量，2) 性能优先：机器主导基于预测性能推荐代理变量。研究基于一项受控用户实验（N = 20），展示了性能优先策略加快了迭代和决策过程，但也使用户偏向于与应用目标不一致的高性能代理变量。研究揭示了人类与机器协作在操作化机器学习目标变量中的机遇与风险，为未来研究提供了见解以探索机遇并缓解风险。", "conclusion": "研究成果表明性能优先策略虽然可以加快代理目标变量的构建和决策过程，但也可能导致用户偏向高预测性能但可能与实际应用目标不一致的代理变量。因此，需要进一步研究以探索人类与机器协作的机遇，并采取措施减轻相关的风险。"}
{"llm_update_time": "20251101", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.25947", "html_url": "https://arxiv.org/abs/2510.25947", "title": "重新审视语言模型预训练中的多语言数据混合", "title_en": "Revisiting Multilingual Data Mixtures in Language Model Pretraining", "authors": "Negar Foroutan,Paul Teiletche,Ayush Kumar Tarun,Antoine Bosselut", "background": "关于大规模预训练语言模型（LLMs）在不同多语言数据混合中的影响一直是持续争论的话题，常因多语言性带来的潜在权衡（即所谓的‘多语言诅咒’）而引发关注。研究一般认为将英语和多语言数据混合可能会损害单语言表现，同时也预期选择与目标语言相同语系的枢纽语言能够改善相关语言组的表现，但实际效果并不确定。", "innovation": "该研究通过训练包含不同数量语言的1.1B和3B参数的语言模型，创新性地挑战了现有认识。研究表明，适当的多语言数据可以提升语言模型的能力而不影响性能，不论资源丰富与否，使用英语作为枢纽语言在不同语言家族中都能带来益处，且未发现模型规模增加多语言数量伴随的‘多语言诅咒’现象，这表明平衡的多语言数据可以在低资源环境中提升语言模型表现。", "conclusion": "本研究发现，当多语言数据数量合适时，可以增强语言模型能力而不损害性能。使用英语作为枢纽语言可以在多种语言家族中提供益处，且未观测到'多语言诅咒'现象，在模型规模较大的情况下，多语言数据的使用是安全的，能够提升语言模型的整体表现。"}
{"llm_update_time": "20251101", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.25979", "html_url": "https://arxiv.org/abs/2510.25979", "title": "AttnCache: 通过注意力缓存加速LLM预填充阶段的自我注意推理", "title_en": "AttnCache: Accelerating Self-Attention Inference for LLM Prefill via Attention Cache", "authors": "Dinghong Song(1),Yuan Feng(1),Yiwei Wang(1),Shangye Chen(1),Cyril Guyot(2),Filip Blagojevic(2),Hyeran Jeon(1),Pengfei Su(1),Dong Li(1) ((1) University of California, Merced, USA, (2) Western Digital Research, USA)", "background": "大型语言模型（LLMs）广泛应用于生成应用，如聊天、代码生成和推理。然而，许多实际工作负载，如分类、问答、推荐和文本嵌入，仅依赖于推理的预填充阶段，即模型在不执行自回归解码的情况下编码输入序列。在这些预填充场景中，由于自我注意力在序列长度方面的二次复杂性，自我注意力计算成为主要的性能瓶颈。本文观察到语义不同的句子往往在各个层和头部产生相似的注意力图。基于此见解，本文提出了一种框架AttnCache，通过检索和重用相似的注意力图以加速LLM预填充推理阶段。", "innovation": "AttnCache框架通过利用一个注意力图记忆数据库，结合高效的缓存和相似性搜索技术，在推理过程中识别并重用预缓存的注意力图，从而减少自我注意力的计算开销。实验结果表明，AttnCache在CPU上实现了1.2倍的端到端和2倍的自我注意加速，在GPU上实现了1.6倍的端到端和3倍的自我注意加速，而对准确率几乎没有影响，", "conclusion": "AttnCache通过预测相似注意力图的重用，有效地减少了LLM预填充推理阶段的自我注意力计算，显著加速了推理速度。"}
{"llm_update_time": "20251101", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.25982", "html_url": "https://arxiv.org/abs/2510.25982", "title": "通过图像去噪实现快速准确的中性原子读出", "title_en": "Enabling Fast and Accurate Neutral Atom Readout through Image Denoising", "authors": "Chaithanya Naik Mude,Linipun Phuttitarn,Satvik Maurya,Kunal Sinha,Mark Saffman,Swamit Tannu", "background": "中性原子量子计算机有望扩展到几十万比特，但其进展受限于慢速的量子比特读出。目前的读出时间以毫秒计，远长于底层的量子门操作时间，使读出成为量子错误校正部署的主要瓶颈。由于每次量子错误校正需要依赖测量，长读出时间增加了周期时长，减慢了程序执行。减少读出时间可以加快周期速度，减少量子比特闲置时积累的退相干误差，但这也降低了收集的光子数量，使测量变得噪音更大，更容易出错。这种权衡使得中性原子系统无法在快速但不可靠的读出和慢速但可靠的读出之间取得平衡。", "innovation": "该研究提出了一种名为GANDALF的框架，利用显式的图像去噪方法进行图像翻译来重构从短时效、低光子数测量中提取的清晰信号，从而实现可靠分类。结合轻量级分类器和流水线读取设计，该方法能够将逻辑错误率最多降低35倍，并将总体量子错误校正周期时间最多缩短1.77倍，相比于基于CNN的铯原子中性阵列读出技术。", "conclusion": "该研究通过图像去噪技术，成功解决了中性原子系统在读出速度与准确性之间的问题，显著提高了读出的速度和准确性，加速了量子错误校正周期，减少了因量子比特闲置导致的退相干误差，同时提高了整体量子信息处理效率。"}
{"llm_update_time": "20251101", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.25992", "html_url": "https://arxiv.org/abs/2510.25992", "title": "监督强化学习：从专家轨迹到逐步推理", "title_en": "Supervised Reinforcement Learning: From Expert Trajectories to Step-wise Reasoning", "authors": "Yihe Deng,I-Hung Hsu,Jun Yan,Zifeng Wang,Rujun Han,Gufeng Zhang,Yanfei Chen,Wei Wang,Tomas Pfister,Chen-Yu Lee", "background": "大型语言模型（LLMs）在需要多步推理的问题上往往表现不佳。对于小型开源模型，验证奖励的强化学习（RLVR）在正确解决方案极少被采样的情况下，即使尝试多次也往往失败；而监督微调（SFT）则倾向于通过严格逐个令牌的模仿来过度拟合长示例。为了解决这一缺口，本文提出了一种监督强化学习（SRL）框架，将问题解决重新定义为生成一系列逻辑“动作”的序列。", "innovation": "SRL通过将模型训练生成一个内部推理独白，然后在采取每个动作之前进行调整，逐步提供基于模型动作与SFT数据集中提取的专家动作之间相似性的评分奖励。这种监督在所有展开都错误的情况下也能提供丰富的学习信号，同时鼓励跟随专家示例的灵活推理。SRL使小型模型能够学习以前无法通过SFT或RLVR学习的具有挑战性的问题。此外，在用SRL初始化训练后，再进行RLVR的精炼训练会获得最佳的整体性能。", "conclusion": "SRL不仅在推理基准测试中表现出色，还能够有效地泛化到自主软件工程任务中，从而确立其作为推理导向的LLMs稳健且多功能的训练框架的地位。"}
{"llm_update_time": "20251101", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.26007", "html_url": "https://arxiv.org/abs/2510.26007", "title": "《寻求负责任的人工智能指标》", "title_en": "The Quest for Reliable Metrics of Responsible AI", "authors": "Theresia Veronika Rampisela,Maria Maistro,Tuukka Ruotsalo,Christina Lioma", "background": "人工智能（AI），包括科学中的AI（AIS），在发展中应遵循负责任AI的原则。尽管进步常常通过评估指标来衡量，但很少有人关注评估指标本身的稳健性和可靠性。早期研究已经探讨了推荐系统中公平性指标的稳健性，总结了一些关键经验教训，并提出了一套非详尽的指南，用于开发负责任AI的可靠度量标准。", "innovation": "这篇论文总结了之前关于推荐系统中公平性指标稳健性的研究，将这些经验教训归纳为一套适用于广泛AI应用的可靠度量标准开发指南，填补了评估指标稳健性和可靠性的研究空白。", "conclusion": "提出的指南适用于所有类型的人工智能应用，包括科学中的AI，以确保负责任的AI的度量标准是可靠的。"}
{"llm_update_time": "20251101", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.26008", "html_url": "https://arxiv.org/abs/2510.26008", "title": "通过硬件遥测检测机器学习基础设施中的异常", "title_en": "Detecting Anomalies in Machine Learning Infrastructure via Hardware Telemetry", "authors": "Ziji Chen,Steven Chien,Peng Qian,Noa Zilberman", "background": "现代机器学习已经发展成为一个紧密结合的、端到端的生态系统，结合了硬件、软件、网络和应用程序。许多用户依赖云提供商以弹性、隔离和成本效益的方式提供资源。但是，这些平台服务使用虚拟化，这意味着运营商缺乏对用户工作负载的洞察力，这妨碍了资源优化，这对于确保成本效益和最小化执行时间至关重要。", "innovation": "本文作者提出了一种名为System-X的新方法，采取硬件为中心的方法，仅依赖于完全可供操作员访问的硬件信号。通过分析超过30种流行的机器学习模型在不同硬件平台上的表现，该方法开发了一种无监督学习管道，以检测异常。这种方法保证了对新兴工作负载和未知部署模式的适应性。System-X成功地识别了网络和系统配置问题，并将DeepSeek模型加速了5.97%。", "conclusion": "通过仅依赖硬件遥测信号，System-X可以在不需了解工作负载的情况下进行系统级优化。这种方法通过无监督学习管道进行异常检测，确保了对不断变化的工作负载的适应性，并成功提高了模型执行效率。"}
{"llm_update_time": "20251101", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.26020", "html_url": "https://arxiv.org/abs/2510.26020", "title": "PORTool: 使用奖励树进行工具使用的大语言模型训练", "title_en": "PORTool: Tool-Use LLM Training with Rewarded Tree", "authors": "Feijie Wu,Weiwu Zhu,Yuxiang Zhang,Soumya Chatterjee,Jiarong Zhu,Fan Mo,Rodin Luo,Jing Gao", "background": "当前的工具使用大规模语言模型（LLMs）是基于静态数据集训练的，这些模型能够与外部工具交互并执行多步、工具集成推理，产生工具调用轨迹。但是，这些模型只是模仿了一般工具调用流程中查询的解决方式，未能探索可能的解决方案，并在动态的工具调用环境中表现出脆弱和有限的性能。因此，需要一种方法来鼓励模型探索不同的调用路径和解决方案，以应对变化多端的环境挑战。", "innovation": "本文提出了一种强化学习方法PORTool，该方法通过奖励树鼓励大语言模型探索各种产生正确答案的调用路径。PORTool首先生成多个针对给定查询的递归步道，并在树状结构中重新组织相同步骤，然后基于每步生成正确答案和成功调用工具的能力进行奖励分配，最终利用步骤奖励来计算分支优势和轨迹优势，以进一步训练模型。通过实验与对照组比较分析，证明这种奖励树方法能够显著提升工具使用模型的性能和调用效率。", "conclusion": "实验采用17个工具处理用户查询，涵盖了时间敏感和时间不变的主题。通过消融研究系统地证明了步骤奖励的有效性和方法的稳健性，与现有的训练方法相比，展示了在最终准确性和调用步骤数上的显著提升。"}
{"llm_update_time": "20251101", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.26026", "html_url": "https://arxiv.org/abs/2510.26026", "title": "超出时间范围的同校预测：无分布推断的政策评估", "title_en": "Conformal Prediction Beyond the Horizon: Distribution-Free Inference for Policy Evaluation", "authors": "Feichen Gan,Youcun Lu,Yingying Zhang,Yukun Liu", "background": "在高风险领域中，强化学习（RL）的可靠不确定性量化至关重要。已有方法在政策评估中未能妥善解决未观察到的回报、时间依赖性和分布变化等问题，本研究旨在提出一种针对无限时同步策略评估的统一C置信预测框架，以构造在在线和离线设置下的无分布预测区间，解决这些问题。该方法将分布RL与同校校准相结合，使用经验重放和加权子采样提出了一种模块化截断回放构建策略，并采用时间意识的校准策略，从而缓解模型偏差并恢复近似可交换性，以在政策变化下提供不确定性量化。", "innovation": "该研究的创新在于提出了一种统一的C置信预测框架，通过模块化截断回放构造策略和时间意识的校准策略，解决了未观测回报、时间依赖性和分布变化等挑战，同时提供理论上的覆盖率保证，考虑到模型误分类和重要性权重估计。这些方法不仅提高了覆盖率和可靠性，还在合成和基准环境（如山车环境）中的实验中证明了其显著优势。", "conclusion": "通过理论分析和实验证明，本研究提出的方法相比标准分布RL基线，在覆盖范围和可靠性上取得了显著改善。这一统一框架为无限时政策评估提供了可靠且无分布的覆盖率保证，并展示了在各种场景下优异的性能。"}
{"llm_update_time": "20251101", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.26402", "html_url": "https://arxiv.org/abs/2510.26402", "title": "Autograder+: 多维度AI框架在编程教育中的丰富教学反馈", "title_en": "Autograder+: A Multi-Faceted AI Framework for Rich Pedagogical Feedback in Programming Education", "authors": "Vikrant Sahu,Gagan Raj Gupta,Raghav Borikar,Nitin Mane", "background": "编程教育的快速发展超出了传统评估工具的能力范围，导致教师很难提供有意义且可扩展的反馈。现有的自动评分系统虽然高效，但它们只是黑盒系统，仅返回通过/未通过的结果，无法提供有关学生思维或学习需求的深入见解。", "innovation": "Autograder+旨在将自动评分从单纯的总结性过程转变为形成性学习体验。它引入了两种关键功能：使用微调的大规模语言模型自动生成反馈，以及可视化学生代码提交以揭示学习模式。系统通过精选的学生代码和专家反馈进行微调，以确保提供符合教学目标并与上下文相关的指导。", "conclusion": "通过整合AI驱动的反馈、语义聚类和交互式可视化，Autograder+减轻了教师的工作负担，同时支持有针对性的指导，促进更强大的学习成果。"}
{"llm_update_time": "20251101", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.26466", "html_url": "https://arxiv.org/abs/2510.26466", "title": "代表级反事实校准以实现无偏的零样本识别", "title_en": "Representation-Level Counterfactual Calibration for Debiased Zero-Shot Recognition", "authors": "Pei Peng,MingKun Xie,Hang Hao,Tong Jin,ShengJun Huang", "background": "在视觉-语言模型中，对象-场景快捷方式（object-context shortcuts）依然是一个持续的挑战，这在测试场景与训练时熟悉的共现场景不同情况下削弱了零样本可靠性。", "innovation": "本文将此问题重新定义为因果推理问题，提出：如果对象出现在不同环境中，预测是否仍然有效。通过在CLIP的表示空间中估计对象和背景期望，以及通过重组多样化的替代环境信息构造反事实嵌入，计算总直接效应，并模拟干预，进一步减小背景单独激活的影响，从而保留有益的对象-场景交互并减轻幻觉评分。", "conclusion": "无需重新训练或使用提示设计，该方法显著提高了上下文敏感基准上的最差群体和平均准确率，建立了新的零样本状态的标杆。除此之外，框架还提供了一个轻量化的表示级反事实方法，为去偏见和可靠多模态推理提供了实用的因果途径。"}
{"llm_update_time": "20251101", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.26345", "html_url": "https://arxiv.org/abs/2510.26345", "title": "MisSynth: 使用合成数据改善MISSCI逻辑谬误分类", "title_en": "MisSynth: Improving MISSCI Logical Fallacies Classification with Synthetic Data", "authors": "Mykhailo Poliakov,Nadiya Shvai", "background": "健康相关的虚假信息非常普遍且可能具有危害性。在识别这些信息时挑战在于，声称可能扭曲或误解科学研究成果。本文研究生成合成数据和轻量级微调技术对于大型语言模型（LLMs）识别谬误论点的能力的影响，并使用MISSCI数据集和框架。本研究探讨了利用合成数据提升大型语言模型识别伪造信息的能力。", "innovation": "研究提出了一种名为MisSynth的管道，其应用检索增强生成（RAG）技术生成合成谬误样本，然后用于微调LLM模型。实验结果表明，与传统的基线模型相比，微调后的模型能够大幅提高准确性，例如，在MISSCI数据集的测试集上，经过微调的LLaMA 3.1 8B模型的F1分数绝对提高了超过35%。研究还展示了通过引入合成谬误数据来增强限制的标注资源可以显著提升LLM在真实科学虚假信息任务中的零样本分类性能。", "conclusion": "即使在计算资源有限的情况下，向LLM引入合成谬误数据可以显著增强其在现实科学虚假信息分类任务中的性能。研究的代码和合成数据集已经在此开放。"}
{"llm_update_time": "20251101", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.26340", "html_url": "https://arxiv.org/abs/2510.26340", "title": "SABER: 基于符号回归的角度到达和波束图案估计器", "title_en": "SABER: Symbolic Regression-based Angle of Arrival and Beam Pattern Estimator", "authors": "Shih-Kai Chou,Mengran Zhao,Cheng-Nan Hu,Kuang-Chung Chou,Carolina Fortuna,Jernej Hribar", "background": "准确的角度到达估计（AoA）对于下一代无线通信系统的可靠波束成形、高精度定位和综合传感至关重要。然而，传统的高分辨率技术需要多元件阵列和大量的快照收集，而通用的机器学习（ML）方法通常会产生“黑箱”模型，缺乏物理可解释性。", "innovation": "本研究提出了基于符号回归（SR）的机器学习框架，即基于符号回归的角度到达和波束图案估计器（SABER）。该框架自动从路径损耗测量中发现具有可解释性的闭合波束图案和AoA模型。SABER实现高精度的同时，填补了不透明的ML方法和可解释的物理驱动估计器之间的差距。", "conclusion": "我们在受控的自由空间声学消声室中验证了该方法，表明直接反转已知的$\text{cos}^n$波束和低阶多项式近似均可实现亚0.5度的平均绝对误差（MAE）。在不受约束的SR方法中，虽然预测的角度误差进一步降低，但产生的公式缺乏物理洞察力。最后，我们在辅助重配置智能表面（RIS）的室内试验台中实现了相同的SR学习逆运算，SABER和不受约束的SR模型准确地恢复了真实AoA，几乎无误差。我们的结果表明，SABER是可解释且准确的AoA估计方法的替代方案，可与最先进的和“黑箱”的ML方法相媲美。"}
{"llm_update_time": "20251101", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.26384", "html_url": "https://arxiv.org/abs/2510.26384", "title": "Scales++: 通过认知尺度嵌入实现高效计算评估子集选择", "title_en": "Scales++: Compute Efficient Evaluation Subset Selection with Cognitive Scales Embeddings", "authors": "Andrew M. Bean,Nabeel Seedat,Shengzhuang Chen,Jonathan Richard Schwarz", "background": "评估大型语言模型（LLMs）需要全面基准的成本非常高，因此需要创建小而有代表性的数据子集（即小型基准）以进行有效的评估同时保留预测精度。当前方法基于模型中心范式，根据现有模型的综合性能选择基准项目。这些方法受限于高昂的初始成本、无法立即处理新基准的“冷启动”问题以及对未来模型将继续分享前代模型故障模式的脆弱假设。本文提出了基于项目的方法来选择基准子集，认为选择应基于任务项目本身的内在属性，而不是基于特定模型的故障模式。通过提出Scales++的新型方法，数据选择基于基准样本的认知需求。实验证明Scales++将初始选择成本降低了18倍以上，同时保留了竞争力的预测精度。在Open LLM排行榜上，仅使用0.5%的数据子集，预测完整的基准评分的平均绝对误差为2.9%。这种方法不仅提高了模型评估的效率，降低了精度损失，还提供了更好的冷启动性能和更具可解释性的基准测试。", "innovation": "提出了Scales++的新方法，该方法基于认知尺度嵌入的数据选择，根据基准样本的认知需求进行选择，能够显著降低初始选择成本并保持预测精度，同时解决了冷启动问题并提高了基准测试的可解释性。", "conclusion": "Scales++通过基于项目的方法和认知尺度嵌入的高效基准选择，解决了传统方法的诸多限制，有效地减少了成本，提高了冷启动性能，并提供了更具解释性的基准测试，证明了这种方法在保持模型评估效率的同时提升了预测精度。"}
{"llm_update_time": "20251101", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.26401", "html_url": "https://arxiv.org/abs/2510.26401", "title": "多输出鲁棒共轭高斯过程", "title_en": "Multi-Output Robust and Conjugate Gaussian Processes", "authors": "Joshua Rooijakkers,Leiv Rønneberg,François-Xavier Briol,Jeremias Knoblauch,Matias Altamirano", "background": "多输出高斯过程（MOGP）回归可以建模多个相关应变量之间的依赖关系。与其他标准高斯过程类似，MOGP受到模型错指定和异常值的影响，这可以扭曲个体输出中的预测结果。在存在多个异常应变量的情况下，由于输出之间的相关性导致的误差传播可能会进一步加剧这种状况。为处理这种情况，我们扩展并推广了Altamirano等人（2024）提出的鲁棒和共轭高斯过程（RCGP）框架，从而产生了多输出RCGP（MO-RCGP）：一种既能保证鲁棒性、又能同时捕捉输出间相关性的共轭多输出高斯过程。我们通过金融和癌症研究中的应用对这种方法进行了全面评估。", "innovation": "我们扩展并推广了先前提出的RCGP框架，提出了多输出RCGP（MO-RCGP），这是一种能确保鲁棒性且能共同捕获输出间相关性的共轭多输出高斯过程。", "conclusion": "我们通过金融和癌症研究中的应用对此方法进行了全面评估，证实了MO-RCGP在处理模型错指定和异常值方面的能力。"}
{"llm_update_time": "20251101", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.26307", "html_url": "https://arxiv.org/abs/2510.26307", "title": "Heterogeneous Graph Neural Networks for Cybersecurity Anomaly Detection", "title_en": "A Survey of Heterogeneous Graph Neural Networks for Cybersecurity Anomaly Detection", "authors": "Laura Jiang,Reza Ryan,Qian Li,Nasim Ferdosian", "background": "异构图神经网络（HGNNs）在网络安全领域的异常检测中逐渐成为重要工具，它们能够处理实体间的复杂交互，并引入类型意识的转换和关系敏感的聚合，从而更好地模拟复杂网络数据。然而，现有研究主要侧重于不同模型的碎片化方法，缺乏统一的标准基准和详细的比较性评估，这对实际应用构成挑战。因此，本文综述了HGNN在网络安全中的异常检测方法，旨在填补这一领域中的空白，提供一个结构化的基础框架，以促进 HGNN 在网络安全中的广泛应用和发展.", "innovation": "本文为 HGNN 在网络安全异常检测中的应用提供了全面的综述。首先，根据异常类型和图动态引入了一种分类法来系统地分类现有方法。其次，详细分析了代表性模型，并将其应用于关键的网络安全应用。此外，还评估了常用基准数据集和评估指标，指出了它们的优势和局限性。最后，明确了建模、数据和部署方面的关键挑战，并提出了未来研究的前景.", "conclusion": "本文旨在建立一个结构化的基础框架，旨在推动基于 HGNN 的异常检测方法与实际部署相结合，以实现可扩展、可解释的解决方案。该综述为研究人员提供了宝贵的信息，以便更好地理解和在未来的工作中改进 HGNN 的应用。"}
{"llm_update_time": "20251101", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.26461", "html_url": "https://arxiv.org/abs/2510.26461", "title": "基于大型语言模型的向量化上下文感知嵌入在GAT基础上的协同过滤", "title_en": "Vectorized Context-Aware Embeddings for GAT-Based Collaborative Filtering", "authors": "Danial Ebrat,Sepideh Ahmadian,Luis Rueda", "background": "推荐系统在面对数据稀疏性和冷启动场景时常常表现不佳，限制了它们对新用户或不频繁用户提供准确建议的能力。通过对数据稀疏性和冷启动问题的分析，论文阐述了推荐系统在这些场景下的不足，并提出了一种基于图注意力网络（GAT）的协同过滤框架，该框架加入了大型语言模型（LLM）驱动的上下文感知嵌入，以提高模型的性能和鲁棒性，尤其是在用户互动历史较短的情况下。通过多角度的实证研究，展示了解决具体问题的方法及其效果优势。", "innovation": "论文通过引入一种基于图注意力网络的协同过滤框架，并结合大型语言模型驱动的上下文感知嵌入，生成简短的用户文本简介，并统一项目的元数据（标题、类型、概述）以形成丰富的文本嵌入。同时，引入了一种结合贝叶斯个性化排序（BPR）与余弦相似性的混合损失函数，并采用健壮的负样本方法，确保显式负反馈与未观察数据的区别。通过实验验证了新框架的有效性，特别是在处理数据稀疏性和用户冷启动方面表现更为突出。", "conclusion": "实验表明，该方法在电影评论数据集（MovieLens 100k和1M）上相比现有最佳基线在精度、NDCG和MAP指标上均取得持续改进，并展示出了对低历史交互用户有较强的鲁棒性。消融实验进一步证实了大型语言模型增强的嵌入和余弦相似性的关键作用。未来的研究将关注在平衡推荐准确性和覆盖率多样性的同时引入公平性和可解释性的约束来进一步提升系统性能。"}
{"llm_update_time": "20251101", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.26486", "html_url": "https://arxiv.org/abs/2510.26486", "title": "LINK-KG: LLM-驱动核心述义解析知识图谱用于人口走私网络", "title_en": "LINK-KG: LLM-Driven Coreference-Resolved Knowledge Graphs for Human Smuggling Networks", "authors": "Dipak Meher,Carlotta Domeniconi,Guadalupe Correa-Cabrera", "background": "人类走私网络复杂且不断演变，使得全面分析变得困难。法律案件文件提供有关这些网络的巨大事实和程序性洞见，但这些文件通常很长、未结构化并且充满了模糊或不断变化的引用，这给自动知识图谱（KG）构建带来了巨大挑战。现有的方法要么忽略同指消解，要么无法扩展到短文本片段之外，导致片段化的图谱和不一致的实体链接。", "innovation": "我们提出了一种模块化框架LINK-KG，它结合了一个三阶段、基于LLM（大型语言模型）的核心述义解析流水线和下游知识图谱提取。我们方法的核心是一个类型特定的提示缓存，它根据不同文档段落追踪和解析引用，使得能够从短文本和长文本中构建干净且消歧义的叙述性知识图谱。与基线方法相比，LINK-KG将节点重复平均减少了45.21%，并将噪音节点减少了32.22%，从而产生了更干净、更连贯的图谱结构。这项改进为分析复杂犯罪网络奠定了坚实的基础。", "conclusion": "LINK-KG为解决人类走私网络的复杂性提供了改进的方法，通过整合基于LLM的核心述义解析流水线和知识图谱提取，显著提高了知识图谱的连贯性和质量。"}
{"llm_update_time": "20251101", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.26474", "html_url": "https://arxiv.org/abs/2510.26474", "title": "通过头尾重平衡反制LVLMs自我提升过程中的马太效应", "title_en": "Counteracting Matthew Effect in Self-Improvement of LVLMs through Head-Tail Re-balancing", "authors": "Xin Guo,Zhiheng Xi,Yiwen Ding,Yitao Zhai,Xiaowei Shi,Xunliang Cai,Tao Gui,Qi Zhang,Xuanjing Huang", "background": "自我提升已成为提升大型视觉语言模型（LVLMs）推理能力的主要范式，模型通过迭代探索和学习成功轨迹。然而，在这一过程中存在一个关键问题：模型在生成简单查询（即头部数据）的高质量轨迹方面表现出色，但在处理复杂查询（即尾部数据）方面存在困难。这种不平衡导致模型优先发展简单推理技能，而难以应对复杂的推理任务，导致越迭代这种不平衡越明显，我们将其称为“马太效应”，最终阻碍了模型的进一步提升并导致性能瓶颈。", "innovation": "本文提出了四种高效策略，从分布重塑和轨迹重采样两个角度出发，以在探索和学习的自我提升过程中实现头尾重平衡。实验结果表明，本文方法在Qwen2-VL-7B-Instruct和InternVL2.5-4B模型上的一系列视觉推理任务中，能够一致地提升视觉推理能力，并且平均优于传统的自我提升方法3.86个点。", "conclusion": "本研究通过提出头尾重平衡策略，成功缓解了LVLMs自我提升过程中的马太效应，显著提高了模型的复杂推理能力，为LVLMs的未来发展提供了新的研究方向和实践路径。"}
{"llm_update_time": "20251101", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.26586", "html_url": "https://arxiv.org/abs/2510.26586", "title": "基于物理信息的混合模型和代理模型在精密增材制造中的应用", "title_en": "Physics-Informed Mixture Models and Surrogate Models for Precision Additive Manufacturing", "authors": "Sebastian Basterrech,Shuo Shan,Debabrata Adhikari,Sankhya Mohanty", "background": "该研究基于激光工艺的增材制造（AM）过程，利用混合模型学习方法来识别缺陷，并结合物理原理确保模型对有意义的物理参数变化敏感。通过分析两个AM过程（Directed Energy Deposition和Laser Powder Bed Fusion）的真实数据，以及不同合金类型和实验参数信息的公共数据集，评估模型性能。", "innovation": "引入了基于物理信息的混合模型和代理模型的方法，此种方法能够更准确地识别AM过程中的缺陷，并且通过结合物理原理来确保模型对物理参数的变化敏感。这种方法通过分析真实数据集和公共数据集来验证其有效性。", "conclusion": "研究结果表明，基于物理信息的混合模型具有潜力来探究增材制造系统下的物理行为。此方法能够通过识别关键缺陷来提升增材制造的精度。"}
{"llm_update_time": "20251101", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.26593", "html_url": "https://arxiv.org/abs/2510.26593", "title": "混合物理-神经网络仿真器用于快速宇宙流体力学", "title_en": "Hybrid Physical-Neural Simulator for Fast Cosmological Hydrodynamics", "authors": "Arne Thomsen,Tilman Tröster,François Lanusse", "background": "宇宙背景下的场级推断需要能够解决气体和暗物质在流体动力学和引力下挑战性动力学的可微分前向模型。现有的方法在处理这些复杂动力学时表现不佳，尤其是在进行实际推断和统计总结时。", "innovation": "提出了一种混合方法，其中引力力使用可微分粒子网格求解器计算，而流体动力学通过一个神经网络参数化，该网络将局部量映射到有效的压力场。该方法在场级和汇总统计层面都优于其他方法，如焓梯度下降基线，并且高度数据节约，单个参考结构形成仿真即可约束神经压力量化模型。", "conclusion": "这种方法为直接将模型拟合到观测数据，而不是仿真数据集铺平了道路，具有未来应用的重要前景。"}
{"llm_update_time": "20251101", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.26577", "html_url": "https://arxiv.org/abs/2510.26577", "title": "大型语言模型中基于推理成本感知的动态树构建方法以提高高效推理", "title_en": "Inference-Cost-Aware Dynamic Tree Construction for Efficient Inference in Large Language Models", "authors": "Yinrong Hong,Zhiquan Tan,Kai Hu", "background": "大型语言模型在推理过程中存在显著的延迟问题，主要来源于其自回归设计和庞大的模型规模。目前，推测性解码被提出作为一种解决方案，可以同时生成和验证多个标记。虽然EAGLE-2和EAGLE-3等最近的方法通过动态树结构改善了推测性解码，但它们通常忽略了对诸如GPU设备和批量大小等关键系统变量的影响。因此，本文介绍了一种新的动态树解码方法CAST，该方法考虑了推理成本，包括GPU配置和批量大小等因素，以动态优化树结构。", "innovation": "CAST方法通过动态考虑推理成本（包括GPU配置和批量大小等因素），自动调整树结构，有效提高了推测性解码的速度和效率。相比于传统解码方法，CAST可以提高5.2倍的解码速度，并且在多个任务和多个大型语言模型上普遍优于现有最先进的技术，性能提升幅度在5%到20%之间。", "conclusion": "本文提出了一种基于推理成本感知的动态树构建方法CAST，通过实验验证了该方法能有效提高大语言模型的推理效率，并展示了显著的速度提升，为大语言模型的优化提出了新的思路。"}
{"llm_update_time": "20251101", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.26551", "html_url": "https://arxiv.org/abs/2510.26551", "title": "适应性逆向动力学框架用于学习可变长度工具操作在机器人学中的应用", "title_en": "Adaptive Inverse Kinematics Framework for Learning Variable-Length Tool Manipulation in Robotics", "authors": "Prathamesh Kothavale,Sravani Boddepalli", "background": "传统机器人对自身力学的理解有限，仅限于预先编程的任务，这限制了它们高效利用工具的能力。现有的机器人在使用工具时面临四大挑战：抓住所需的结果、选择最合适的工具、确定最佳的工具朝向、以及执行精确的操作。本文通过解决这些核心问题，提出了一种新的逆向动力学框架，旨在增强机器人在使用不同长度工具时的操控能力。", "innovation": "该研究提出了一个适应性逆向动力学框架，该框架通过结合动作轨迹和工具，使机器人能够学习并执行不同长度工具的操作。这一创新方法突破了传统机器人仅依赖预编程任务的限制，通过模拟学习获得了技能，实现了从仿真到现实场景的技能转移。实验结果表明，该框架的逆向动力学解算器的误差率低于1cm，并且训练政策在模拟测试中的平均误差为8cm。值得注意的是，当使用两种不同长度的工具时，模型在性能上几乎没有显著差异。此研究表明，机器人在任务多样化下对工具操纵技能的掌握即将取得进步，有望在多任务环境中实现精准的操作。", "conclusion": "该研究对工具使用的四个基本方面提供了潜力上的进展，使得机器人能够在各种任务中掌握复杂的工具操作艺术。"}
{"llm_update_time": "20251101", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.26512", "html_url": "https://arxiv.org/abs/2510.26512", "title": "CORE-KG内部机制：评估结构化提示和核心语义解析对知识图谱的影响", "title_en": "Inside CORE-KG: Evaluating Structured Prompting and Coreference Resolution for Knowledge Graphs", "authors": "Dipak Meher,Carlotta Domeniconi", "background": "这类人类走私网络越来越具有适应性和难以分析。虽然法律案例文件提供了关键洞察，但它们往往缺乏结构化，词汇密集，且充满模糊或易变的引用，对自动知识图谱构建构成重大挑战。尽管最近基于大语言模型的方法有所改进，但它们依然生成杂音大、节点碎片化的图谱，因为缺乏引导提取和一致性解析。因此，CORE-KG框架通过集成类型感知一致性模块和领域引导结构化提示，显著减少了节点冗余和法律噪声。", "innovation": "CORE-KG框架通过集成类型感知一致性模块和领域引导结构化提示，显著减少了节点冗余和法律噪声。此外，作者进行了系统性剥离研究，量化了两个关键组件的贡献，并发现核心语义解析的缺失会导致节点冗余增加28.32%，杂音节点增加4.32%，而结构化提示的缺失则会导致节点冗余增加4.34%，杂音节点增加73.33%。这些发现为设计从复杂法律文本中提取结构化表示的健壮大语言模型管道提供了实证见解", "conclusion": "研究结果表明，核心语义解析和结构化提示在减少知识图谱中的冗余和杂音方面具有重要意义。此外，实证研究提供了设计有效的大语言模型管道的指导，以从复杂法律文件中提取结构化表示。"}
{"llm_update_time": "20251101", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.26543", "html_url": "https://arxiv.org/abs/2510.26543", "title": "大型语言模型中关系解码线性操作符的结构", "title_en": "The Structure of Relation Decoding Linear Operators in Large Language Models", "authors": "Miranda Anna Christ,Adrián Csiszárik,Gergely Becsó,Dániel Varga", "background": "本文探讨了Hernandez等人[2023]引入的线性操作符的结构，这些线性操作符可以解码变压器语言模型中的特定关系事实。该研究基于先前的研究工作，进一步探索了由单个关系到多个关系的扩展，通过系统地绘制其组织结构来揭示线性操作符的模式。研究发现，这些操作符能够被简单的三维张量网络高度压缩，其准确解码能力未受显著影响。", "innovation": "在研究中，作者通过开发一个跨评估协议，将每个线性解码操作应用于每个其他关系的主题，以解释这种意外的冗余性。研究结果显示，线性变换并未编码独有关系，而是提取了反复出现、比粗粒度的语义特性（例如，首都的国家属性和食物的国家属性都是country-of-X属性）。这种以属性为中心的结构界定了操作符的压缩性，并揭示了其仅能推广到语义接近的新关系的原因。因此，研究结果解释了变压器语言模型中的线性关系解码主要基于属性，而非特定关系。", "conclusion": "总之，研究发现说明了线性关系解码在变压器语言模型中本质上是属性而非关系特定的。这种发现不仅解释了操作符的高效压缩性，还揭示了它们为什么仅能推广到语义紧密的新关系。"}
{"llm_update_time": "20251101", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.26795", "html_url": "https://arxiv.org/abs/2510.26795", "title": "扩大图像地理定位至大陆级别", "title_en": "Scaling Image Geo-Localization to Continent Level", "authors": "Philipp Lindenberger,Paul-Edouard Sarlin,Jan Hosang,Matteo Balice,Marc Pollefeys,Simon Lynen,Eduard Trulls", "background": "在全球范围内精确确定图像的位置仍然是一个未解决的挑战。标准的图像检索技术由于图像数量庞大（超过1亿）且覆盖不全，效率低下且效果不佳。虽然可扩展的解决方案存在，但通常需要权衡，全球分类通常产生粗略的结果（10公里以上），而地面与空中图像之间的跨视角检索则存在领域差异，并主要在较小区域内研究过。", "innovation": "本文提出了一个混合方法，可以在一个大陆规模的地理范围内实现精细地理定位。通过在训练期间利用代理分类任务来学习丰富的特征表示，隐式地编码精确的位置信息，并将这些学习的原型与空中图像嵌入相结合，以增加对地面数据稀疏性的鲁棒性，从而能够在多个国家覆盖的区域上直接、精细地理定位。广泛的评估证明，该方法可将超过68%的查询定位在200米以内。", "conclusion": "我们的方法能够针对覆盖欧洲大部分地区的数据集实现超过200米内的地理定位查询超过68%。代码已公开。"}
{"llm_update_time": "20251101", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.26778", "html_url": "https://arxiv.org/abs/2510.26778", "title": "通过精心选择U-Net架构和损失函数来超越RGB眼底图像AMD区域估计的最新水平", "title_en": "Surpassing state of the art on AMD area estimation from RGB fundus images through careful selection of U-Net architectures and loss functions for class imbalance", "authors": "Valentyna Starodub,Mantas Lukoševičius", "background": "年龄相关性黄斑变性（AMD）是老年人中导致不可逆视力损害的主要原因之一。本文的研究集中在RGB眼底图像中的AMD病灶分割上，这是一种非侵入性和成本效益较高的成像技术。ADAM挑战赛提供了迄今为止最全面的基于RGB眼底图像的AMD检测和开放数据集，作为我们评估的基准。", "innovation": "本文以U-Net连接性为基础，评估并比较了多种方法以改进分割模型的架构和训练管道，包括预处理技术、不同复杂度的编码器（骨干）深度网络类型和专门的损失函数来缓解图像和像素级别上的类别不平衡。最终配置的AMD检测框架在非侵入性RGB眼底图像的多类分割中超越了所有前ADAM挑战赛的提交记录。", "conclusion": "本文的研究结果在AMD病灶类型的多类分割中证明了该框架的有效性，并使该模型在非侵入性RGB眼底图像的AMD病灶检测上超越了之前的所有结果。此外，实验中使用的源代码已经公开，以供进一步的研究和验证。"}
{"llm_update_time": "20251101", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.26723", "html_url": "https://arxiv.org/abs/2510.26723", "title": "在政策学习中缩小经验福利最大化与条件均值处理效应估计之间的差距", "title_en": "Bridging the Gap between Empirical Welfare Maximization and Conditional Average Treatment Effect Estimation in Policy Learning", "authors": "Masahiro Kato", "background": "政策学习的目标是训练一个策略函数，根据协变量推荐治疗方案以最大化总体福利。有两种主要方法：经验福利最大化（EWM）方法和插值方法。EWM方法类似于分类问题，首先建立人口福利的估计器，这是一种策略函数的函数，并通过最大化估计的福利来训练策略。相比之下，插值方法基于回归，首先估计条件平均处理效应（CATE），然后推荐有最高估计结果的治疗。本文通过展示两种方法本质上基于同一个优化问题来填补了这方面的差距。通过这种等价性，提出了一种新的策略学习正则化方法。", "innovation": "提出了一种新的正则化方法，利用EWM与CATE之间的等价性，该方法是一种凸且计算效率高的训练过程，避免了通常在EWM中需要的NP难组合步骤。", "conclusion": "发现两种方法共享相同理论保证的相同前提条件下，在几个方面是相互可交换的。利用这种等价性建立了新的正则化方法，提供了一种避免NP难组合步骤的凸且计算效率高的训练程序。"}
{"llm_update_time": "20251101", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.26783", "html_url": "https://arxiv.org/abs/2510.26783", "title": "统一因果推断理论：通过Bregman-Riesz回归的直接偏差校正机器学习", "title_en": "A Unified Theory for Causal Inference: Direct Debiased Machine Learning via Bregman-Riesz Regression", "authors": "Masahiro Kato", "background": "本文介绍了将里斯回归、协变量平衡、密度比率估计（DRE）、目标最大似然估计（TMLE）和匹配估计器统一起来的因果推断理论，以用于平均处理效应（ATE）估计。背景在于在ATE估计中，平衡权重和结果的回归函数扮演了重要角色。得益于里斯回归、协变量平衡、DRE和匹配估计器能够估计平衡权重，它们之间的等效关系使得统一理论成为可能。", "innovation": "本文创新性地引入了一个统一的因果推断理论框架。这一框架通过Bregman-Riesz回归将里斯回归、协变量平衡、DRE和匹配估计器等方法综合起来，提供了一种直接偏差校正的机器学习方法。特别地，Bregman-Riesz回归与DRE本质上等效，在AT环境下里斯回归等同于DRE，匹配估算是DRE的一个特例，DRE与协变量平衡具有对偶关系。", "conclusion": "本文指出，TMLE是一种通过构造回归函数估计器使得主要偏差项消失的方法。而且，最近邻匹配等同于最小二乘密度比率估计和里斯回归。这一理论框架结合了多种统计方法，旨在提供一个更稳健和有效的因果推断工具。"}
{"llm_update_time": "20251101", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.26707", "html_url": "https://arxiv.org/abs/2510.26707", "title": "价值漂移：追踪大语言模型后训练期间的价值对齐", "title_en": "Value Drifts: Tracing Value Alignment During LLM Post-Training", "authors": "Mehar Bhatia,Shravan Nayak,Gaurav Kamath,Marius Mosbach,Karolina Stańczak,Vered Shwartz,Siva Reddy", "background": "随着大语言模型（LLMs）在社会中的角色日益重要，它们越来越需要不仅利用一般知识，还需要与某些人类价值观保持一致。因此，研究LLMs与人类价值观之间的对齐变得至关重要。然而，此前的工作主要关注完全训练好的模型的对齐评估，而忽视了这些模型在训练过程中学习表达人类价值观的过程。本文研究了在模型后训练过程中价值对齐是如何形成及其发生在哪个阶段。通过对不同规模的Llama-3和Qwen-3模型以及流行的监督微调（SFT）和偏好优化数据集和算法进行实验，研究发现SFT阶段通常奠定了模型的价值观念，而随后的偏好优化很少重新调整这些价值观。进一步使用一个可以控制价值变化的合成偏好数据集，研究还发现不同的偏好优化算法会导致不同的价值对齐结果，即使偏好数据保持不变。这些结果提供了在后训练过程中学习价值的实际见解，并有助于指导数据筛选，以及选择适合偏好优化算法以提高模型与人类价值观对齐的过程。", "innovation": "本文的主要创新在于它研究了后训练期间价值对齐的过程，并通过实验证明了SFT阶段通常奠定了模型的价值观念，而偏好优化阶段通常不会重新调整这些价值观。此外，研究还发现不同的偏好优化算法会导致不同的价值对齐结果，即使偏好数据保持不变。这些发现为在后训练过程中学习价值提供了实际见解，并有助于指导数据筛选和选择适合偏好优化的算法。", "conclusion": "研究结果表明，SFT阶段建立了模型的价值观念，偏好优化阶段通常不会重新调整这些价值观。不同的偏好优化算法会导致不同的价值对齐结果，即使偏好数据保持不变。这些发现为理解后训练过程中价值学习的实际过程提供了见解，并有助于指导数据筛选和模型算法的选择，以增强模型与人类价值观的对齐。"}
{"llm_update_time": "20251101", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.26786", "html_url": "https://arxiv.org/abs/2510.26786", "title": "HEIR: 学习基于图的运动层次结构", "title_en": "HEIR: Learning Graph-Based Motion Hierarchies", "authors": "Cheng Zheng,William Koch,Baiang Li,Felix Heide", "background": "在计算机视觉、图形学和机器人学等领域中存在层次结构化的运动模式，复杂的动态通常由更简单运动组件的协调交互产生。现有方法通常依赖于手动定义或启发式的固定运动元模型，这限制了它们在不同任务上的普适性。现有的模型方法难以捕捉和自适应地学习不同任务中复杂的运动层次结构。因此，需要一种能够直接从数据中学习具有结构和可解释性的运动关系的方法，以适应不同任务中的灵活和高效的运动建模。", "innovation": "本文提出了一种通用的基于图的运动建模方法，该方法能够从数据中直接学习结构化的可解释运动关系。该方法通过图神经网络捕捉图中的父级-子级依赖关系，将观测到的运动表示为基于图的层次结构，将全局绝对运动分解为父级继承模式和局部运动残差。实验结果表明，在1D和2D情况下，该方法成功地重建了内在的运动层次结构；在动态3D场景变形中，与基线方法相比，该方法生成了更为真实和可解释的变形。这一方法为广泛的以运动为中心的任务提供了一个可适应的、数据驱动的层次建模范式。", "conclusion": "通过提供一种自适应的、数据驱动的层次建模范式，本方法提出了适用于广泛运动中心任务的一种框架。该方法实施了不同形式的运动层次结构的发现，从1D平移运动、2D旋转运动到实时动态3D场景变形的非刚性扭曲(通过高斯点绘制实现的)。实验结果验证了该方法的有效性，表明其能在不同形式的运动数据中自适应地发现并表示合理的层次结构。"}
{"llm_update_time": "20251101", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.26800", "html_url": "https://arxiv.org/abs/2510.26800", "title": "OmniX: 从统一的全景生成和感知到图形级3D场景", "title_en": "OmniX: From Unified Panoramic Generation and Perception to Graphics-Ready 3D Scenes", "authors": "Yukun Huang,Jiwen Yu,Yanning Zhou,Jianan Wang,Xintao Wang,Pengfei Wan,Xihui Liu", "background": "当前3D场景构建主要有两种方法：程序化生成和二维提升。全景基于的二维提升作为一种有潜力的技术，利用强大的二维生成先验知识，能够生成沉浸式、逼真且多样的3D环境。然而，现有二维提升方法主要关注外观生成，忽略了对内在属性的感知。本文在此基础上，提出了一种新的基于OmniX框架的方法，以提高全景视觉感知和生成的能力。研究人员构建了大规模合成全景数据集，含有来自多种室内和室外场景的高质量多模态全景图，用于验证模型的有效性。", "innovation": "本文提出了一种名为OmniX的统一框架，基于轻量级且高效的跨模态适配器结构，能够重新利用现有的二维生成先验知识来解决全景视觉感知、生成和完成等广泛的任务。这种方法与现有的二维提升技术不同，不仅关注外观生成，还重视对场景内在属性的感知。此外，研究人员还构建了一个大规模合成全景数据集，用于方法的有效性验证。", "conclusion": "本文验证了OmniX框架在全景视觉感知和3D场景生成中的有效性，方法生成的3D场景可用于物理基础渲染、重新照明和模拟。研究还为生成沉浸式的、物理上真实的虚拟世界提供了新的可能性。"}
{"llm_update_time": "20251101", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.26752", "html_url": "https://arxiv.org/abs/2510.26752", "title": "监管游戏：学习协同平衡AI代理的安全性和自主性", "title_en": "The Oversight Game: Learning to Cooperatively Balance an AI Agent's Safety and Autonomy", "authors": "William Overman,Mohsen Bayati", "background": "随着越来越强大的代理被部署，一个核心问题是如何在不修改基本系统的情况下保留有意义的人类控制。本文研究一个最小的控制界面，其中代理可以选择自主行动（播放）或暂退（询问），而人类可以选择是否宽容（信任）或执行监管（监督）。当代理暂退时，人类的选择决定了结果，可能涉及纠正措施或系统关闭。", "innovation": "本文将此交互建模为一个两玩家马尔可夫博弈。文章着重分析在该马尔可夫博弈满足马尔可夫潜力博弈（MPG）条件的情况下，代理增加自身利益而未损害人类价值的结构假设。此外，文章还分析了该MPG框架的扩展。理论上，本文提供了特定形式内在一致性的条件；如果人类-代理的奖励结构满足这些条件，可以保证代理提高自身结果不会损害人类。实践上，本文模型促使一个透明的控制层，代理可以通过独立学习学习何时暂退以及何时行动，而不会改变其预训练策略和环境的奖励结构。通过网格世界模拟显示，代理和人类在独立学习中发现其最佳监管角色，展示了部署后使不一致模型更安全的实用方法。", "conclusion": "通过此模型，代理和人类学会了在不确定时询问以及人类何时监督，从而避免了训练后引入的安全违规行为。这种通过独立学习合作发现最优监督角色的方法展示了在部署后使不一致模型更安全的实用机制。"}
{"llm_update_time": "20251101", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2305.17608", "html_url": "https://arxiv.org/abs/2305.17608", "title": "大型语言模型（LLMs）的奖励崩溃现象", "title_en": "Reward Collapse in Aligning Large Language Models", "authors": "Ziang Song,Tianle Cai,Jason D. Lee,Weijie J. Su", "background": "大型语言模型（如ChatGPT和GPT-4）通过与训练人类偏好的奖励模型对齐而展现出了惊人的能力，这些偏好通常以对提示的响应进行排名的形式表示。然而，在训练的终端阶段，排名为基础的方法产生了一种现象，即奖励分布变得完全相同，与提示类型无关，这种结果对于开放性和特定性提示之间的预期奖励范围差异是不理想的。理论研究表明，奖励分布相同主要是由于排名为基础的目标函数在优化过程中无法包含提示相关信息造成的。", "innovation": "提出了一种新的基于提示的认知优化方案，可以在插值区间内证明该方案具有提示依赖性的奖励分布，从而有效缓解奖励崩溃问题。通过推导出在渐近区间内与一组效用函数相关的奖励分布的闭合表达式，该研究为理解和解决奖励模型训练中的奖励崩溃问题提供了新的视角和方法.", "conclusion": "实验结果表明，提出的基于提示的认知效用函数显著减轻了奖励崩溃现象，在奖励模型的训练过程中发挥重要作用。"}
{"llm_update_time": "20251101", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.26769", "html_url": "https://arxiv.org/abs/2510.26769", "title": "SteerVLM：通过轻量级激活引导实现视语言模型的稳健模型控制", "title_en": "SteerVLM: Robust Model Control through Lightweight Activation Steering for Vision Language Models", "authors": "Anushka Sivakumar,Andrew Zhang,Zaber Hakim,Chris Thomas", "background": "这篇论文介绍了一种名为SteerVLM的轻量级引导模块，旨在引导视语言模型（VLMs）生成更符合指定指令的输出。通过学习配对提示的潜在嵌入来捕捉目标和反向行为，动态调整语言模态与图像上下文之间的激活连接，这种方法允许在推理时对复杂输出语义进行精细控制，无需修改模型权重即可保持对非目标任务的性能。SteerVLM引导模块仅需要学习0.14%的原始VLM模型大小的参数，并且通过维度激活调整和跨层自适应引导模型控制，不依赖于预先提取的静态向量或手动调参干预点。此外，本文还介绍了VNIA（视觉叙事意图对齐）多模态数据集，以促进VLM引导技术的发展和评估。该方法在视语言模型引导和幻觉缓解基准测试中均优于现有方法，提供了一种通过激活工程实现多模态模型控制的稳健解决方案", "innovation": "SteerVLM通过学习配对提示的潜在嵌入来捕捉目标和反向行为，实现对复杂输出语义的精细控制，并且仅需要学习0.14%的原始VLM模型大小的参数。SteerVLM引导模块通过维度激活调整和跨层自适应引导模型控制，不依赖于预先提取的静态向量或手动调参干预点。此外，引入了VNIA多模态数据集，旨在促进VLM引导技术的发展和评估。SteerVLM在视语言模型引导和幻觉缓解基准测试中均表现优于现有方法，并提供了一种通过激活工程实现多模态模型控制的解决方案", "conclusion": "SteerVLM提供了一种轻量级的模型控制方法，能够在不修改模型权重的情况下对视语言模型进行精细引导，同时保持在非目标任务上的性能。此外，SteerVLM通过引入VNIA数据集，为视语言模型引导技术的发展和评估提供了有价值的资源。该方法在现有基准测试中表现优越，展示了通过激活工程实现多模态模型控制的潜力。"}
{"llm_update_time": "20251101", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2405.09086", "html_url": "https://arxiv.org/abs/2405.09086", "title": "利用TD3的混沌基础强化学习", "title_en": "Chaos-based reinforcement learning with TD3", "authors": "Toshitaka Matsuki,Yusuke Sakemi,Kazuyuki Aihara", "background": "CBRL是一种使用代理内部混沌动力学驱动探索的强化学习方法，然而，之前的研究中对学习算法的发展还不充分，也没有采用最近的强化学习进展。", "innovation": "该研究引入了TD3算法，这是一种最先进的深度强化学习算法，能够处理确定性和连续的动作空间，并将其应用于CBRL。结果显示，TD3可以作为CBRL的学习算法在简单的目标到达任务中有效工作。还发现，随着学习的进展，CBRL代理可以自主抑制探索行为，环境变化时恢复探索，并且混沌性对学习的影响表明，存在一个合适的混沌强度范围，可以在探索和利用之间灵活切换，适应环境变化。", "conclusion": "TD3算法应用于CBRL，验证结果显示其能有效工作，并且其混沌性和探索性的关系表明存在适合的混沌强度范围，使得CBRL代理能够适应环境变化并灵活在探索和利用之间切换。"}
{"llm_update_time": "20251101", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2403.02682", "html_url": "https://arxiv.org/abs/2403.02682", "title": "时间编织者：一种条件时间序列生成模型", "title_en": "Time Weaver: A Conditional Time Series Generation Model", "authors": "Sai Shankar Narasimhan,Shubhankar Agarwal,Oguzhan Akcin,Sujay Sanghavi,Sandeep Chinchali", "background": "当前的时间序列生成方法往往忽略伴随时间序列的配对异构上下文元数据（例如天气和位置），并且现有从图像、音频和视频领域到时间序列领域现有的条件生成方法面临着适应性挑战。本文旨在根据天气、电车存在与否和地理位置生成一个城市的电力需求模式，用于冬季寒潮期间的容量规划，这类实际世界的时间序列通常丰富了配对异构上下文元数据。", "innovation": "本文引入了TIME WEAVER，一种新颖的基于扩散模型的时间序列生成方法，能够利用分类、连续甚至时变变量形式的异构元数据显著提升时间序列生成效果。此外，本文创新了一种新的评估指标，准确捕捉条件生成的特异性和生成时间序列的现实性，并证明了TIME WEAVER在实际能源、医疗、空气质量、交通等数据集的下游分类任务中比生成对抗网络（GANs）等先进基准方法效果更佳，最高提升30%。", "conclusion": "TIME WEAVER通过充分利用时间序列中的异构元数据，显著改善了时间序列生成的效果，并创新性的提出了一种评价新的指标，能够在实际应用中更准确地评估条件生成的时间序列的特异性与真实性。"}
{"llm_update_time": "20251101", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2406.08525", "html_url": "https://arxiv.org/abs/2406.08525", "title": "神经网络中正性条件的数学验证及其在部分单调性和可信赖AI中的应用", "title_en": "A mathematical certification for positivity conditions in Neural Networks with applications to partial monotonicity and Trustworthy AI", "authors": "Alejandro Polo-Molina,David Alfaya,Jose Portela", "background": "人工神经网络（ANNs）在处理大规模数据集中的复杂关系方面具有强大的工具作用。然而，由于其黑盒特性，可能引发可信度问题。尤其是在需要遵循特定的分部分单调性约束的应用场景中，如信用评分，对已经训练好的ANN进行分部分单调性验证非常具有挑战性。因此，ANN在一些关键应用中往往被排除在外。", "innovation": "本文提出了一种新的算法（LipVor），基于有限次评估来认证黑盒模型（如ANN）的正性。通过Lipschitz性质构建特定邻域以保持函数的正性，并基于已评估点的Voronoi图给出一个充分条件来认证函数在整个域上的正性。与先前方法不同，我们的方法可以在无需限制型结构或分段线性激活的情况下验证分部分单调性。因此，LipVor打开了在一些关键领域使用非限制型ANN的可能性。此方法还可以应用于其他ANN属性，如凸性，这些属性也可以通过正性条件进行表达。", "conclusion": "LipVor算法能够认证神经网络的分部分单调性，这对于一些关键应用非常有价值，如信用评分。此外，LipVor还可以应用于验证神经网络的其他正性条件属性。"}
{"llm_update_time": "20251101", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2408.08493", "html_url": "https://arxiv.org/abs/2408.08493", "title": "继承模型网络中的并行遗忘", "title_en": "Parallel Unlearning in Inherited Model Networks", "authors": "Xiao Liu,Mingyuan Li,Guangsheng Yu,Lixiang Li,Haipeng Peng,Ren Ping Liu", "background": "通用学习框架在模型持续增长和更新的情况下，存在难以处理复杂继承关系的遗忘任务。针对这一挑战，论文提出了一种新的并行遗忘框架，该框架能够在展示继承关系的模型之间实现完全并行的遗忘。该框架使用时间上的有向无环图（DAG）来捕捉模型继承网络中发生的各种遗忘场景，有效应对多种遗忘情况，并可实现对继承知识的一键清除，同时显著减少了计算开销。实验结果证明了该并行遗忘框架的有效性，在单类任务中实现了完全遗忘，同时保留了94.53%的准确性；在多类任务中，保持了84.77%的准确性。相比其他方法，该框架的遗忘速度提高了99%。", "innovation": "提出了一个能够处理模型继承网络中并行遗忘的新框架。框架的核心是Fisher Inheritance Unlearning（FIUn）方法，该方法使用Fisher信息矩阵（FIM）评估参数对遗忘任务的重要性，并及时调整。此外，提出了一种合并FIM（MFIM）函数，用于同时处理多个遗忘请求。", "conclusion": "实验结果验证了该并行遗忘框架的有效性和效率。对于单类任务，实现了100%的遗忘率，保留了94.53%的准确性；对于多类任务，保持了84.77%的准确性，同时将遗忘速度提高了99%。"}
{"llm_update_time": "20251101", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2410.03348", "html_url": "https://arxiv.org/abs/2410.03348", "title": "Dolphin: 一种可编程的可扩展神经符号学习框架", "title_en": "Dolphin: A Programmable Framework for Scalable Neurosymbolic Learning", "authors": "Aaditya Naik,Jason Liu,Claire Wang,Amish Sethi,Saikat Dutta,Mayur Naik,Eric Wong", "background": "神经符号学习能够在符号推理与深度学习之间实现整合，但是它在扩展到复杂的符号程序、大型数据集或两者方面遇到了显著的挑战。现有的框架如Scallop、ISED和IndeCateR+都在复杂基准测试中未能在限定时间内收敛，甚至在简单基准测试中也未能达到现有框架的性能。", "innovation": "DOLPHIN是一个涵盖了Python支持的神经符号程序的框架，它在CPU上执行复杂的符号推理，并在GPU上向量化概率计算和梯度传播。DOLPHIN在13项基准测试中取得了优异的收敛性，特别是在复杂的基准测试中达到最先进的准确率。并且，DOLPHIN在简单基准测试中与其他框架具有同等性能，但速度提高了1.71到62倍。总之，DOLPHIN推动了神经符号框架的扩展，实现了在具有挑战性的基准测试中的最先进效率和收敛性，这些测试是现有框架难以应对的。", "conclusion": "DOLPHIN提高了神经符号框架的可扩展性，表现出卓越的效率和在困难基准测试中的快速收敛性，其中现有框架表现不佳。"}
{"llm_update_time": "20251101", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2410.09766", "html_url": "https://arxiv.org/abs/2410.09766", "title": "稳定性与更紧的风险界，收敛速率约为 $\\tilde{O}(1/n^2)$", "title_en": "Stability and Sharper Risk Bounds with Convergence Rate $\\tilde{O}(1/n^2)$", "authors": "Bowei Zhu,Shaojie Li,Mingyang Yi,Yong Liu", "background": "此前的研究（Klochkov 和 Zhivotovskiy，2021）通过算法稳定性证明了强凸学习者在高概率下的最大 $O(\frac{\text{log}(n)}{n})$ 期望风险界限。在相同的基本假设下，即 Polyak-Lojasiewicz 条件、光滑性和损失的Lipschitz连续性，我们展示了最紧的期望风险界限是 $O(\frac{\text{log}^2(n)}{n^2})$。", "innovation": "我们的分析提供了非凸设置下基于梯度泛化差距的最紧高概率界限，同时通过类似的假设，证明了收敛率达到 $\\tilde{O}(1/n^2)$", "conclusion": "在具有相同假设的条件下，我们的分析还提供了非凸设置下基于梯度泛化差距的最紧高概率界限。进一步地，我们证明了收敛率可以达到 $\\tilde{O}(1/n^2)$。"}
{"llm_update_time": "20251101", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2410.06324", "html_url": "https://arxiv.org/abs/2410.06324", "title": "通过黑盒二次规划求解器进行微分", "title_en": "Differentiation Through Black-Box Quadratic Programming Solvers", "authors": "Connor W. Magoon,Fengyu Yang,Noam Aigerman,Shahar Z. Kovalsky", "background": "差可优化在解决二次规划（QP）问题方面引起了广泛关注。现有的QP解与其定义参数之间求导的方法通常依赖于特定整合的求解器，这种依赖限制了其应用于神经网络架构和多层次优化任务，使用户受限于求解器选择范围狭窄的问题。", "innovation": "本文介绍了一种名为dQP的模块化且求解器无关框架，实现了几乎任何QP求解器的即插即用可微分化。通过已知不等式约束的活动集，简化线性系统可以被用于表达QP解及其导数，这一表达式完全解耦了QP解的计算与求导计算，从而实现框架的模块化。基于这一原理，提供了一个开源实现，兼容15个以上的最先进求解器，并通过全面的基准实验展示了dQP的稳健性和可扩展性，特别是在大规模稀疏问题上的优势。", "conclusion": "dQP框架提供了一种通用且高效的解决方法，能够处理大规模的稀疏QP问题，并且灵活性高，可以与多种主流求解器无缝集成，提升了QP问题在神经网络和多层次优化中的应用潜力。"}
{"llm_update_time": "20251101", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.02843", "html_url": "https://arxiv.org/abs/2507.02843", "title": "基于大型语言模型的推理时刻文本混杂因素下治疗效果估计", "title_en": "LLM-Driven Treatment Effect Estimation Under Inference Time Text Confounding", "authors": "Yuchen Ma,Dennis Frauen,Jonas Schweisthal,Stefan Feuerriegel", "background": "在医学个性化决策中，治疗效果的估计至关重要，但在临床实践中面临独特挑战。训练时，治疗效果估计模型通常基于结构化良好的医疗数据集，包含详细的患者信息。然而，在推理时，预测往往是基于文本描述（如自报症状描述）进行的，这些描述是原始患者信息不完整的表示。这种训练数据和推理数据之间的差异可能导致治疗效果偏差。", "innovation": "1. 提出并正式化了推理时刻文本混杂问题，其中混杂因素在训练时完全可见，在推理时仅部分可见。\n2. 设计了一个新颖的框架，通过结合大型语言模型和自定义双重稳健学习方法来缓解推理时刻文本混杂带来的偏差。", "conclusion": "通过一系列实验，证明了该框架在实际应用中的有效性。"}
{"llm_update_time": "20251101", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.01369", "html_url": "https://arxiv.org/abs/2506.01369", "title": "激励大语言模型自我验证其答案", "title_en": "Incentivizing LLMs to Self-Verify Their Answers", "authors": "Fuxiang Zhang,Jiacheng Xu,Chaojie Wang,Ce Cui,Yang Liu,Bo An", "background": "大语言模型（LLMs）在复杂推理任务中通过后训练和测试时的扩展法则取得了显著进展。通常，测试时的扩展方法是通过使用外部奖惩模型来引导模型生成过程。然而，研究发现，仅通过后训练特定推理任务来扩展模型所能获得的收益微乎其微。这种局限性源于特定后训练生成器与通用奖惩模型之间的分布差异。", "innovation": "提出一种框架，激励LLMs自我验证答案。通过将答案生成与验证统一在一个强化学习（RL）过程中进行训练，模型能够有效地评估自身解决方案的正确性，并在推理时通过验证自身生成来进一步扩展性能，无需外部验证者参与。实验证明该模型在不同推理情境下表现出色，且能有效提升后训练表现和实现测试时的扩展。", "conclusion": "通过训练Qwen2.5-Math-7B和DeepSeek-R1-Distill-Qwen-1.5B等模型，展示了自我验证模型在多个数学推理基准测试上的能力，不仅提高了后训练性能，还实现了有效测试时扩展。"}
{"llm_update_time": "20251101", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.09846", "html_url": "https://arxiv.org/abs/2507.09846", "title": "通过河流：无调度方法在语言模型训练中的益处理解", "title_en": "Through the River: Understanding the Benefit of Schedule-Free Methods for Language Model Training", "authors": "Minhak Song,Beomhan Baek,Kwangjun Ahn,Chulhee Yun", "background": "随着模型和数据集规模的快速增长，传统的固定计算预算下的预训练策略（如余切学习率计划）变得越来越不适合大规模训练。寻找更灵活和可扩展的替代方案是当前研究的焦点。", "innovation": "本文重新审视了无调度方法（Schedule-Free, SF）[Defazio等，2024]，它在各种设置中表现出强大的实证性能。作者提出了一种改进的SF方法（SF-AdamW），它能够在没有衰减速率阶段或辅助平均的情况下有效导航损失地形中的“河流”结构，特别适用于持续扩展的训练工作负荷。此外，作者通过理论和实证分析揭示了SF方法如何在没有内存开销的情况下实现权重平均。", "conclusion": "综合实验和理论分析结果，作者认为SF方法是语言模型训练中一种实用、可扩展且理论上合理的方法。"}
{"llm_update_time": "20251101", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.02935", "html_url": "https://arxiv.org/abs/2506.02935", "title": "MTL-KD：通过知识蒸馏的多任务学习通用神经车辆路由解决方法", "title_en": "MTL-KD: Multi-Task Learning Via Knowledge Distillation for Generalizable Neural Vehicle Routing Solver", "authors": "Yuepeng Zheng,Fu Luo,Zhenkun Wang,Yaoxin Wu,Yu Zhou", "background": "在神经组合优化(NCO)领域，多任务学习(MTL)方法被证明是一种有前景的方式，能够训练出能够解决多种车辆路由问题(VRP)变种的统一模型。然而，现有的基于强化学习(Reinforcement Learning，RL)的多任务方法只能在小规模问题上训练轻量级的解码器模型，并且在处理大规模问题时表现出有限的一般化能力。", "innovation": "为了克服这一限制，本研究引入了一种新的由知识蒸馏驱动的多任务学习方法(MTL-KD)，该方法能够有效训练具有强泛化能力的重解码器模型。MTL-KD方法通过从多个不同的RL单任务模型中转移策略知识到单一的重解码器模型，实现了无监督训练，并有效地增强了模型在多种任务上的泛化能力。此外，该研究还提出了一种灵活的推理策略——随机重排序重建(R3C)，专门适应多种VRP任务，进一步提升了多任务模型的性能。", "conclusion": "在最多包含1000个节点的6个已见过和10个未见过的VRP变种的实验中，所提出的方法在统一基准和实际应用场景中都能保持优越的表现，并显示出强大的泛化能力。"}
{"llm_update_time": "20251101", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.17475", "html_url": "https://arxiv.org/abs/2506.17475", "title": "基于低秩训练的动量优化器的几何框架", "title_en": "A geometric framework for momentum-based optimizers for low-rank training", "authors": "Steffen Schotthöfer,Timon Klein,Jonas Kusch", "background": "低秩预训练和微调最近被认为是可以降低大型神经网络计算和存储成本的有希望的技术。尽管如此，使用传统的优化器（如重球动量方法或Adam）训练低秩参数化通常会遇到困难，尤其是在优化景观的几何结构上。因此，需要新的训练策略来解决这些问题。", "innovation": "本文提出了一种新的训练策略，结合了动态低秩逼近和动量优化的技术手段，设计出了能够尊重参数空间内在几何结构的优化器。实验验证了这种方法的快速收敛性和在给定参数预算下更好的验证指标，表明该方法能够有效解决传统优化器在训练低秩参数化时遇到的问题。", "conclusion": "研究通过数值实验验证了新方法的有效性，证明了利用几何结构设计优化器可以提高训练效率和模型性能。"}
{"llm_update_time": "20251101", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.07500", "html_url": "https://arxiv.org/abs/2506.07500", "title": "Mind the Gap: Removing the Discretization Gap in Differentiable Logic Gate Networks", "title_en": "Mind the Gap: Removing the Discretization Gap in Differentiable Logic Gate Networks", "authors": "Shakir Yousefi,Andreas Plesner,Till Aczel,Roger Wattenhofer", "background": "现代神经网络在现有基准上表现出卓越性能，但其高计算需求和能耗促使研究人员寻找更高效的解决方案，以便在实际应用中部署。逻辑门网络（LGNs）可以学习一个由大量逻辑门组成的大网络，以实现高效的图像分类，但学习解决像CIFAR-10这样的简单问题的网络可能需要数天甚至数周的训练时间，即使这样，网络中的几乎一半仍然未被充分利用，这造成了离散化差距。离散化差距使得LGNs难以在实际部署中使用，因为训练和推理之间的性能下降显著影响了准确性。", "innovation": "研究者通过在训练过程中注入Gumbel噪声并使用直通估计器，显著加快了训练速度，提高了神经元利用率，并减少了离散化差距。理论研究表明，这些改进源自隐含的海森堡正则化，从而提高了LGNs的收敛特性。与以往相比，网络的训练速度提高了4.5倍，离散化差距减少了98%，未使用的门数目减少了100%。", "conclusion": "研究成功地通过引入Gumbel噪声和直通估计器的方法解决并减少了逻辑门网络中的离散化差距，提高了网络的实际部署性能和利用率，验证了隐含的海森堡正则化有效改进了网络的收敛特性。"}
{"llm_update_time": "20251101", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.11847", "html_url": "https://arxiv.org/abs/2507.11847", "title": "广义线性贝叶斯：近乎最优遗憾且一次更新", "title_en": "Generalized Linear Bandits: Almost Optimal Regret with One-Pass Update", "authors": "Yu-Jie Zhang,Sheng-An Xu,Peng Zhao,Masashi Sugiyama", "background": "我们研究广义线性贝叶斯（GLB）问题，这是一种扩展经典线性模型的上下文多臂bandit框架，通过引入非线性链接函数来模型各种奖励分布，如伯努利和泊松。虽然GLBs在实际场景中适用性广泛，但其非线性特征会带来在计算和统计效率方面的重要挑战。现有方法通常在实现最优遗憾保证和降低每轮成本与保持统计效率之间做出权衡。", "innovation": "本文提出一种联合高效的算法，能够在每轮中保持接近最优的遗憾界并具有$\text{O}(1)$的时间和空间复杂度。核心思想是通过一种新颖的分析方法（利用在线预测中的mix loss概念）为在线镜像下降（OMD）估计器构建了一个精确的压力集。分析表明，即使OMD估计器只做了一次更新，也能在统计效率上接近最大似然估计。", "conclusion": "本文提出的方法能够在保持计算和统计效率的同时，实现近乎最优的遗憾界，并且仅需一次更新。这种方法通过利用一种新型的分析方法，能够将在线镜像下降（OMD）估计器在统计效率上与最大似然估计相媲美。从而实现了高效且优化的估计方法。"}
{"llm_update_time": "20251101", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.08645", "html_url": "https://arxiv.org/abs/2506.08645", "title": "当内核相乘时，集群统一：利用克罗内克积融合嵌入", "title_en": "When Kernels Multiply, Clusters Unify: Fusing Embeddings with the Kronecker Product", "authors": "Youqi Wu,Jingwei Zhang,Farzan Farnia", "background": "现有的高级嵌入方法通常能够捕获不同但互补的区分特征。例如，一个图像嵌入模型可能擅长区分细微的纹理，而另一个模型则专注于高层次的对象结构。这一观察促使我们提出了一种利用克罗内克积融合这些互补表示的方法。通过将两种嵌入的核相似性函数相乘，可以使它们的区分结构相互作用，从而生成一种融合表示，其核编码了每种父嵌入识别的集群的并集。这种公式也为构建对配多模态数据（例如图像-文本组合）的联合内核提供了自然的方式。步骤乘积在数学上通过嵌入特征映射的克罗内克乘积实现，进而提出了我们的KrossFuse框架来进行嵌入融合。", "innovation": "提出了一种利用克罗内克积融合嵌入的新方法。这种方法能够通过将两种嵌入的核相似性函数相乘来实现内核乘积，使得它们的区分结构相互作用，从而生成一种融合表示，其核编码了每种父嵌入识别的集群的并集。该方法还提供了一种基于随机投影的高效近似版本RP-KrossFuse，以解决高维克罗内克空间的计算成本问题。", "conclusion": "通过使用该框架，我们有效地合并了多模态嵌入（例如CLIP，BLIP）和单模态专家（例如DINOv2，E5），实验表明RP-KrossFuse能够增强模态特定的表现同时保持跨模态对齐。相关的项目代码可以在指定的链接中获得。"}
{"llm_update_time": "20251101", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.00927", "html_url": "https://arxiv.org/abs/2507.00927", "title": "理解节点和链预测中的泛化能力", "title_en": "Understanding Generalization in Node and Link Prediction", "authors": "Antonis Vasileiou,Timo Stoll,Christopher Morris", "background": "消息传递图神经网络（MPNNs）在节点和链预测中有广泛的应用，这推动了多种MPNN架构的发展。尽管这些模型在实际应用中表现良好，但它们在训练集外泛化的性能尚未完全理解。现有研究大多关注图级别预测任务中的泛化能力，而很少关注节点和链级别的预测任务。目前的研究往往依赖于不切实际的独立和同分布假设，忽略了节点或链之间的潜在相关性，假定聚合方式固定并在分类任务中忽视了图结构的影响。因此，对于这些任务中MPNNs的泛化能力了解不足。", "innovation": "本文提出了一个统一框架，用于分析MPNNs在归纳和 transductive 节点和链预测设置中的泛化特性，该框架涵盖了各种架构参数和损失函数，并量化了图结构的影响。此外，该泛化框架还可应用于任何归纳或 transductive 设置下的分类任务。实证研究支持了我们的理论洞察，加深了我们对 MPNNs 在这些任务中泛化能力的理解。", "conclusion": "本研究通过提出统一的框架，分析了MPNNs在节点和链预测中的泛化能力，考虑了不同的架构参数和损失函数，并量化了图结构的影响。实证研究进一步验证了理论分析，为理解MPNNs的泛化能力提供了新的视角。"}
{"llm_update_time": "20251101", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.05768", "html_url": "https://arxiv.org/abs/2506.05768", "title": "AANet：通过对齐和聚合在结构不确定条件下进行虚拟筛选", "title_en": "AANet: Virtual Screening under Structural Uncertainty via Alignment and Aggregation", "authors": "Wenyu Zhu,Jianhui Wang,Bowen Gao,Yinjun Jia,Haichuan Tan,Ya-Qin Zhang,Wei-Ying Ma,Yanyan Lan", "background": "虚拟筛选（VS）是现代药物发现的关键组成部分，但现有方法（无论是基于物理的还是基于深度学习的）通常围绕已知配体结合口袋的完整蛋白质结构进行开发。因此，在没有清晰口袋信息的空蛋白结构（如AlphaFold2预测的结构）或预测结构上，这些方法的性能会显著下降。这类结构在真实的药物发现早期阶段更为常见，因此优化这些情况下的虚拟筛选方法具有重要意义。", "innovation": "本文提出了一种对齐和聚合框架，能够在结构不确定条件下实现准确的虚拟筛选。该方法主要由两个核心组件组成：1）一种三模态对比学习模块，通过对配体、完整口袋和结构中检测到的空洞的表示进行对齐，以提高对抗蛋白质口袋定位错误的鲁棒性；2）基于跨注意力的适配器，用于动态聚合候选结合位点，使模型能够从活动数据中学习，即使没有精确的口袋注释。在空蛋白结构的新基准测试中，该方法大幅超越现有方法，提高了早期富集因子（EF1%）从11.75到37.19，同时保持在完整蛋白质结构上也表现出较强的性能。", "conclusion": "这些结果展示了我们方法在推动新型药物发现方面的潜力，特别是在缺乏实验确定的蛋白质-配体复合物的情景下。我们的实现已在以下链接对外公开：this https URL."}
{"llm_update_time": "20251101", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.06576", "html_url": "https://arxiv.org/abs/2508.06576", "title": "使用GFlowNets学习更好的药物-药物交互表示", "title_en": "GFlowNets for Learning Better Drug-Drug Interaction Representations", "authors": "Azmine Toushik Wasi", "background": "在临床药理学中，药物-药物相互作用（DDI）是一个重大的挑战，由于相互作用类型之间严重的类别不平衡限制了预测模型的效果。常见的相互作用主导了数据集，而稀有的但至关重要的相互作用则严重不足，导致模型在不常见的情况下表现较差。现有的方法通常将DDI预测视为二分类问题，忽略了分类特定的细微差别，进一步放大了对常见相互作用的偏见。", "innovation": "本文提出了一种结合生成流网络（GFlowNet）与变分图自编码器（VGAE）的框架，以生成罕见类别的合成样本，改善模型平衡并产生有效的新型DDI配对。此方法提升了不同类型相互作用的预测性能，确保了临床更可靠的诊断能力。", "conclusion": "该方法通过整合生成流网络和变分图自编码器，在药物-药物交互的预测上实现了更好的平衡和新颖性生成效果，从而提高了模型在不同交互类型中的预测性能，并确保了在临床应用中的可靠性。"}
{"llm_update_time": "20251101", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.21258", "html_url": "https://arxiv.org/abs/2508.21258", "title": "RelP: 语言模型中通过相关性修补实现忠实且高效的电路发现", "title_en": "RelP: Faithful and Efficient Circuit Discovery in Language Models via Relevance Patching", "authors": "Farnoush Rezaei Jafari,Oliver Eberle,Ashkan Khakzar,Neel Nanda", "background": "激活修补是机制可解释性中的标准方法，用于定位模型中负责特定行为的组件，但在大规模应用中计算成本较高。归因修补提供了一种更快但基于梯度的近似方法，但在深层、高度非线性网络中存在噪声和可靠性降低的问题。本文旨在改进这一过程。", "innovation": "提出了相关性修补（RelP），将归因修补中使用的局部梯度替换为从逐层相关性传播（LRP）中导出的传播系数。RelP 保留了两条前向传递和一次后向传递的计算效率，同时提高了忠实度。实验结果表明，RelP 在多种模型和任务中比标准归因修补更准确地逼近激活修补，特别是在间接对象识别（IOI）任务中的 MLP 输出分析中。", "conclusion": "RelP 的结果表明，对于 GPT-2 大型模型中的 MLP 输出，归因修补的皮尔逊相关性仅为 0.006，而 RelP 达到了 0.956，证明了 RelP 的优越性。此外，与整合梯度（IG）相比，RelP 达到了可比较的忠实度，而无需额外的计算成本。"}
{"llm_update_time": "20251101", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.17784", "html_url": "https://arxiv.org/abs/2509.17784", "title": "使用大规模语言模型揭示多模态因果关系", "title_en": "Revealing Multimodal Causality with Large Language Models", "authors": "Jin Li,Shoujin Wang,Qi Zhang,Feng Liu,Tongliang Liu,Longbing Cao,Shui Yu,Fang Chen", "background": "从数据中揭示因果机制是科学进步的基础。虽然大型语言模型（LLMs）在增强从非结构化数据中进行因果发现（CD）方面显示出前景，但在日益普及的多模态背景下，其应用仍面临重大挑战。即使出现了多模态大型语言模型（MLLMs），它们在多模态CD中的效能仍受到主要限制，包括内在和跨模态交互探索的难度以及单纯观察数据处理结构模糊性的不足。", "innovation": "本文提出了一种新颖的多模态因果发现框架MLLM-CD，包括三个关键组件：（1）一种新颖的对比因素发现模块，通过探索对比样本对中的交互来识别真实的多模态因素；（2）一种统计因果关系发现模块，用于推断发现因素之间的因果关系；（3）一种迭代的多模态反事实推理模块，通过融入MLLM的世界知识和推理能力来逐步细化发现结果。广泛实验表明，所提出的MLLM-CD在揭示多模态非结构化数据中的真实因素及其因果关系方面具有有效性。", "conclusion": "本文提出的MLLM-CD框架在揭示多模态数据中的真实因果关系方面具有明显优势，并通过验证了其有效性。"}
{"llm_update_time": "20251101", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.17197", "html_url": "https://arxiv.org/abs/2509.17197", "title": "SignalLLM: 一种用于自动化信号处理的通用LLM代理框架", "title_en": "SignalLLM: A General-Purpose LLM Agent Framework for Automated Signal Processing", "authors": "Junlong Ke,Qiying Hu,Shenghai Yuan,Yuecong Xu,Jianfei Yang", "background": "现代信号处理（SP）管道，无论是基于模型还是数据驱动的，都受限于复杂且碎片化的流程，高度依赖于专家知识和手动工程，难以为有限数据下的适应性和泛化提供支持。与之相反，大型语言模型（LLMs）提供了强大的推理能力、广泛的一般性知识、上下文学习能力和跨模态迁移能力，使其成为自动化和泛化SP流程的强大工具。", "innovation": "我们引入了SignalLLM，这是一种基于LLM的通用代理框架，专门针对通用SP任务。SignalLLM提出了一个有原则性的、模块化的架构，它通过上下文学习和领域特定检索将高层次的SP目标分解为结构化的子任务，随后通过自适应检索增强生成（RAG）和细化进行层次规划；这些子任务通过基于提示的推理、跨模态推理、代码合成、模型调用或数据驱动的LLM辅助建模来执行。其通用设计使其能够在不同信号模式、任务类型和数据条件下灵活选择问题解决策略。", "conclusion": "我们通过五个代表性的通信和传感任务，如雷达目标检测、人类活动识别和文本压缩，展示了SignalLLM的多样性和有效性。实验结果表明，与传统和现有的LLM方法相比，在少量样本和零样本设置下，SignalLLM具有更优越的表现。"}
{"llm_update_time": "20251101", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.23117", "html_url": "https://arxiv.org/abs/2510.23117", "title": "提前预见结构失效：基于图像的物理约束神经网络（PINN）用于意大利面桥载荷预测", "title_en": "Seeing Structural Failure Before it Happens: An Image-Based Physics-Informed Neural Network (PINN) for Spaghetti Bridge Load Prediction", "authors": "Omer Jauhar Khan,Sudais Khan,Hafeez Anwar,Shahzeb Khan,Shams Ul Arifeen", "background": "物理约束神经网络（PINNs）因其能够将物理定律嵌入到深度学习模型中而受到关注，特别是在数据有限的结构工程任务中非常有用。本文旨在利用PINNs预测小型意大利面桥梁的重量，这对于了解简化结构模型中的载荷限制和潜在失效模式非常重要。为了改进模型性能，本文提出了一个框架，将物理约束融入到预测模型中。", "innovation": "本文引入了一个新颖的架构——物理约束柯尔莫哥洛夫-阿诺德网络（PIKAN），该架构结合了通用函数近似理论和物理洞察。此外，输入给模型的结构参数可以通过手动方法或计算机视觉方法收集。通过与标准PINNs相比，作者展示了PIKAN在预测小型意大利面桥梁重量方面的优越性。研究结果表明，即使在数据有限的情况下，PINNs也能提供可靠的结构重量预测，有助于轻型桥梁设计中的早期失效分析。", "conclusion": "本文的最佳模型达到了$R^2$得分0.9603，平均绝对误差(MAE)为10.50单位。研究结果表明，PINNs可以在数据有限的情况下可靠地估计结构重量，并且可能有助于轻型桥梁设计中的早期失效分析。所有数据和代码均可从提供的链接处获得。"}
{"llm_update_time": "20251101", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.21038", "html_url": "https://arxiv.org/abs/2510.21038", "title": "Elementary, My Dear Watson: 非入侵性神经关键词识别在LibriBrain数据集中的应用", "title_en": "Elementary, My Dear Watson: Non-Invasive Neural Keyword Spotting in the LibriBrain Dataset", "authors": "Gereon Elvers,Gilad Landau,Oiwi Parker Jones", "background": "非侵入性脑机接口（BCIs）开始受益于大型、公开基准数据集。目前的基准主要针对相对简单的基础任务，如语音检测和音素分类，而适用于实际应用的任务比如从脑电波到文本转换的结果仍然难以实现。", "innovation": "本文提出了关键词识别（KWS）作为实际适用性高、注重隐私的任务。使用深度52小时的LibriBrain内个体语料库，提供了一致的训练/验证/测试分割，以实现可重复的基准测试，并采用针对极端类别不平衡的评估协议。具体来说，使用精确度-召回率曲线下的面积（AUPRC）作为稳健的评估指标，并且通过固定召回率下的每小时假警报（FA/h）来捕捉用户视角的权衡。", "conclusion": "作为初始参考模型，我们提出了一个紧凑的一维卷积/残差网络基础模型，带有焦点损失和top-k池化，可以在单个消费级GPU上训练，达到约13倍于随机基线的AUPRC，展示了该任务的可行性。探索性分析显示出：(i) 预测性的全局个体逐步增益——性能随更多训练小时数以对数线性增长——和(ii) 单词级别的因素（频率和持续时间）系统地调节可检测性。"}
{"llm_update_time": "20251101", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.21271", "html_url": "https://arxiv.org/abs/2510.21271", "title": "测试时适配中的缓冲层", "title_en": "Buffer layers for Test-Time Adaptation", "authors": "Hyeongyu Kim,Geonhui Han,Dosik Hwang", "background": "在测试时适应（TTA）的最新进展中，大多数现有方法集中在更新归一化层以适应测试领域。然而，基于归一化的适应存在关键挑战。首先是归一化层（如批量归一化（BN））对小批量尺寸非常敏感，导致不稳定且不准确的统计参数。其次，基于归一化的适应方法受限于预训练模型的结构，依赖于训练时的统计参数，这些参数可能无法很好地泛化到未见过的领域。这些问题限制了基于归一化的TTA方法的有效性，尤其是在显著领域变化的情况下。", "innovation": "本文提出了一种基于缓冲层概念的新范式，解决了归一化层更新的基本限制。不同于现有方法修改模型的核心参数，本方法保护预训练主干网络的完整性，从而减轻在线适应期间灾难性遗忘的风险。通过全面的实验，本文表明该方法不仅在缓解领域偏移和增强模型稳健性方面优于传统方法，而且还具有很强的遗忘抵御能力。此外，缓冲层模块化并且可以无缝集成到几乎所有现有的TTA框架中，从而在各种架构中实现一致的性能提升。这些发现验证了在实际领域适应场景中提出的解决方案的有效性和灵活性。", "conclusion": "本文提出的基于缓冲层的方法在各方验证了其有效性与灵活性，并显示在几乎所有现有的TTA框架中都具有良好的性能提升能力。"}
{"llm_update_time": "20251101", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.16629", "html_url": "https://arxiv.org/abs/2510.16629", "title": "关于机器遗忘中重训练等价性的不可能性", "title_en": "On the Impossibility of Retrain Equivalence in Machine Unlearning", "authors": "Jiatong Yu,Yinghui He,Anirudh Goyal,Sanjeev Arora", "background": "机器遗忘试图在特定训练数据对模型输出的影响上进行选择性去除。理想的目标是重训练等价，即行为与从头开始仅使用保留数据重训练的模型的行为完全相同。然而，随着现代管线的发展，多阶段训练变得普遍，每个阶段拥有独特的数据分布和目标，如专用于LLM的对齐微调等能力。本文研究通过理论和实验表明，这种多阶段训练给机器遗忘设定了基本的障碍。理论表明，局部遗忘（仅使用遗忘集上计算的梯度）的结果是路径依赖的，模型在遗忘期间的行为受到其学习阶段顺序的影响，无法通过无意识算法普遍实现重训练等价。", "innovation": "研究发现了多阶段训练下，在局部遗忘过程中存在路径依赖性，即使是使用相同数据的不同训练顺序，模型在遗忘过程中的行为也有所不同。通过实验在Llama和Qwen模型中也证实了这一现象，不同顺序的训练路径导致准确性下降差异达到20%以上。研究还观察到一些训练路径持续产生学习缓慢的模型，在遗忘过程中概率质量被挤压到同义或替代概念的程度也受到路径影响。", "conclusion": "这些结果一致表明，除非目标模型在阶段中训练，否则局部遗忘算法难以实现重训练等价。在无法访问模型训练历史的情况下，当前研究呼吁重新定义和设定机器遗忘的目标和期望。"}
{"llm_update_time": "20251101", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.22094", "html_url": "https://arxiv.org/abs/2510.22094", "title": "通过轻量级训练的分层图网络用于准确的天气预报", "title_en": "Hierarchical Graph Networks for Accurate Weather Forecasting via Lightweight Training", "authors": "Thomas Bailie,S. Karthik Mukkavilli,Varvara Vetrova,Yun Sing Koh", "background": "气候事件源于复杂的、多变量的动力学，由全球尺度的驱动因素主导，深刻影响食品、能源和基础设施。然而，由于物理过程在不同空间和时间尺度上的发展，准确的天气预测仍难以实现。固定分辨率的方法无法捕捉这些过程，而层次图神经网络（Hierarchical Graph Neural Networks, HGNNs）虽然提供了多尺度表示，但非线性的向下映射通常会消除全球趋势，削弱物理的整合到预测中的能力。", "innovation": "两种创新支撑其设计：一种潜忆库机制（Latent-Memory-Retention mechanism），确保向下迁移到局部尺度时仍保留全球趋势；一种潜到物理的分支（Latent-to-Physics branch），整合不同尺度下的偏微分方程（PDE）解空间。通过这种方式，Flow模型将13天预报误差降低了超过5%，在极端值（1st和99th分位数）预报中，误差降低了5-8%，提高了对罕见事件的可靠性。预训练模型权重的使用使得网络在单轮训练即可收敛，降低了训练成本和它们的碳足迹，对于当前机器学习规模增长对可持续性和研究普及性造成的挑战至关重要。", "conclusion": "我们提出了HiFlowCast及其集成版本HiAntFlow，这些基于物理的HGNNs模型在多尺度预测框架内嵌入了物理，减少了误差并提高了预报的可靠性。这些模型使用预训练权重在一次迭代中快速收敛。"}
{"llm_update_time": "20251101", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.22033", "html_url": "https://arxiv.org/abs/2510.22033", "title": "Linearized Optimal Transport for Analysis of High-Dimensional Point-Cloud and Single-Cell Data", "title_en": "Linearized Optimal Transport for Analysis of High-Dimensional Point-Cloud and Single-Cell Data", "authors": "Tianxiang Wang,Yingtong Ke,Dhananjay Bhaskar,Smita Krishnaswamy,Alexander Cloninger", "background": "单细胞技术生成高维点云数据，这使得能够详细了解病患状态和治疗反应的细节。然而，每个病患都被表示为一个不规则的点云，而非简单的向量，这使得直接量化和比较个体之间的生物学差异变得困难。非线性方法如核函数和神经网络可以实现预测准确性，但这些方法具有黑箱特性，难以提供生物学上的可解释性。因此，需要一种能在保留点云结构的前提下，将其嵌入到固定维度的欧几里得空间中的方法，从而解决上述问题，适应单细胞数据的分析需求，同时提供更佳的生物学可解释性和生成建模能力。", "innovation": "我们提出适应此设置的线性最优传输（LOT）框架。具体包括：（i）准确且可解释的分类，其中分类器权重可以映射回驱动预测的具体标记和空间区域；以及（ii）利用LOT嵌入的线性性质为病患衍生的器官生成合成数据。LOT重心则提供了一种描述合并条件或样本的平均细胞概况，有助于药物相互作用测试。因此，LOT成为连接预测性能、可解释性和生成建模的一体化框架，将不规则点云转为可直接追溯到原始数据的结构嵌入，为理解高维生物系统的免疫变异和治疗效果提供了新的机会。", "conclusion": "总体而言，这些结果确立了LOT作为一种统一框架，能够同时提供预测性能、可解释性和生成建模。通过将异质点云数据转化为直接链接到原始数据的结构化嵌入，LOT为理解高维生物系统中的免疫变异和治疗效果开启了新的可能性。"}
{"llm_update_time": "20251101", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.23639", "html_url": "https://arxiv.org/abs/2510.23639", "title": "将基因组学整合到多模态EHR基础模型中", "title_en": "Integrating Genomics into Multimodal EHR Foundation Models", "authors": "Jonathan Amar,Edward Liu,Alessandra Breschi,Liangliang Zhang,Pouya Kheradpour,Sylvia Li,Lisa Soleymani Lehmann,Alessandro Giulianelli,Matt Edwards,Yugang Jia,David Nola,Raghav Mani,Pankaj Vats,Jesse Tetreault,T.J. Chen,Cory Y. McLean", "background": "该论文介绍了将多基因风险评分（PRS）整合到电子健康记录（EHR）基础模型中的创新方法，这超出了传统的仅基于EHR的方法，构建了更加全面的健康概貌。利用来自All of Us（AoU）研究计划的广泛且多样化的数据集，该多模态框架旨在学习临床数据与遗传倾向之间的复杂关系。", "innovation": "论文提出的方法将生成式人工智能的进步应用于EHR基础模型领域，增强了预测能力和可解释性。通过对AoU数据的评估，模型证明了对于各种情况（特别是2型糖尿病）的预肪价值，并展示了PRS与EHR数据之间的相互作用。工作还探讨了多模式框架在定制分类任务中的迁移学习，展示了该架构的灵活性和效率。", "conclusion": "该方法为解锁新的疾病预测、主动健康管理、风险分层和个人化治疗策略提供了关键性进展，为医疗健康领域更个性化、公平和支持决策的实时证据生成奠定了基础。"}
{"llm_update_time": "20251101", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.17670", "html_url": "https://arxiv.org/abs/2510.17670", "title": "基于FLAME的即插即用OVD适应：通过主动边际样本探索实现少样本定位", "title_en": "On-the-Fly OVD Adaptation with FLAME: Few-shot Localization via Active Marginal-Samples Exploration", "authors": "Yehonathan Refael,Amit Aides,Aviad Barzilai,George Leifman,Genady Beryozkin,Vered Silverman,Bolous Jaber,Tomer Shekel", "background": "开放词汇对象检测（OVD）模型提供了灵活的检测能力，可以从任意文本查询中检测物体。然而，在如遥感（RS）等专业领域，这些模型的零样本性能往往由于自然语言固有的歧义性而受到限制，这限制了关键下游应用。例如，OVD模型可能难以区分如“渔船”和“游艇”这类细微分类，因为它们的嵌入相似且往往无法区分。这阻碍了特定用户目标的实现，如非法捕鱼的监控，因为会产生无关的检测结果。为了解决这一问题，该研究提出了一个级联方法，将大型预训练的OVD模型的广泛泛化能力和轻量级的少量样本分类器结合起来。方法首先利用零样本模型生成高召回率的对象提案，然后通过仅在少量用户标注的样本上实时训练的小型分类器对这些提案进行细化，以提高精度。该框架的核心是FLAME，这是一种一蹴而就的主动学习策略，能够实时选择最有信息性的样本进行训练。FLAME通过密度估计确定决策边界附近的不确定边际候选样本，然后通过聚类确保样本的多样性。该技术在高效抽取样本的同时，无需昂贵的全模型微调，能够快速适应，少于一分钟。这种方法在遥感基准测试中始终超越了最先进的技术水平。", "innovation": "提出了基于FLAME的即插即用OVD适应方法，该方法结合了大型预训练的OVD模型的广泛泛化能力和轻量级的少量样本分类器。通过仅在少量用户标注的样本上实时训练的小型分类器对零样本模型生成的高召回率对象提案进行细化，以提高精度。FLAME作为一种一蹴而就的主动学习策略，可以实时选择最有信息性的样本进行训练，从而在高效抽取样本的同时，无需昂贵的全模型微调，能够快速适应，少于一分钟。这种方法在遥感基准测试中始终超越了最先进的技术水平，建立了适应基础模型到特定用户需求的实用高效框架。", "conclusion": "该方法在遥感基准测试中始终超越了最先进的技术水平，建立了适应基础模型到特定用户需求的实用高效框架，证明了其在遥感领域的潜力。"}
{"llm_update_time": "20251101", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.24043", "html_url": "https://arxiv.org/abs/2510.24043", "title": "局部核投影离群点检测：两阶段方法用于多模态离群点检测", "title_en": "Localized Kernel Projection Outlyingness: A Two-Stage Approach for Multi-Modal Outlier Detection", "authors": "Akira Tamamori", "background": "本文提出了Two-Stage LKPLO，这是一种新型的多阶段离群点检测框架，解决了现有基于投影的传统方法存在的两个主要限制：一是对固定统计指标的依赖，二是对单一数据结构的假设。该框架的独特之处在于它融合了三个关键概念：1）一种通用的基于损失的离群度度量（PLO），用灵活且自适应的损失函数如作者提出的类SVM损失函数来替代固定指标；2）全局核PCA阶段，将非线性数据结构线性化；3）后续的局部聚类阶段，处理多模态数据分布。", "innovation": "提出了Two-Stage LKPLO框架，该框架融合了三个关键概念：1）一种通用的基于损失的离群度度量PLO；2）全局核PCA阶段；3）局部聚类阶段。通过5折交叉验证实验，在10个基准数据集上实现自动化超参数优化，显示出了优于现有强基线的出色表现，特别是在具有挑战性结构的数据集（如Optdigits和Arrhythmia）上。", "conclusion": "这项工作贡献了一种强大的新工具来解决一类重要的离群点检测问题，并强调了混合、多阶段架构的重要性。经实验验证，核化和局部化阶段的协同作用对于其优越性能是不可或缺的。"}
{"llm_update_time": "20251101", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2505.02820", "html_url": "https://arxiv.org/abs/2505.02820", "title": "AutoLibra：从开放性人类反馈中诱导代理评估指标", "title_en": "AutoLibra: Agent Metric Induction from Open-Ended Human Feedback", "authors": "Hao Zhu,Phil Cuvin,Xinkai Yu,Charlotte Ka Yee Yan,Jason Zhang,Diyi Yang", "background": "目前，代理（agents）的评估和优化主要依赖于粗粒度的任务成功率指标，这些指标需要人工设计且不能准确评价代理的中间行为。", "innovation": "提出了AutoLibra，一种基于开放性人类反馈的代理评估框架。AutoLibra将人类对代理具象化的行为，例如“如果按钮不可用时，就不要再次点击”或“这个代理的自主性过强，导致其自己决定做什么”转化为具体的评估指标，从而能够细化评价代理轨迹中的行为。此外，还提出了两个元指标“覆盖范围”和“冗余度”，通过优化这些元指标，能够诱导出比先前代理评估基准更具体的评估指标，发现新的评估指标来分析代理。此外，还展示AutoLibra在代理改进中的应用，包括帮助人类提示工程师对齐提示和代理自我调节以提升性能。", "conclusion": "综上，AutoLibra是一个强大的、任务无关的工具，能够评估和改善语言代理。"}
{"llm_update_time": "20251101", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2505.10361", "html_url": "https://arxiv.org/abs/2505.10361", "title": "塑性作用作为赋能的镜像", "title_en": "Plasticity as the Mirror of Empowerment", "authors": "David Abel,Michael Bowling,André Barreto,Will Dabney,Shi Dong,Steven Hansen,Anna Harutyunyan,Khimya Khetarpal,Clare Lyle,Razvan Pascanu,Georgios Piliouras,Doina Precup,Jonathan Richens,Mark Rowland,Tom Schaul,Satinder Singh", "background": "代理是受过去观察影响并在未来观察中发挥作用的最小实体。赋能是这些能力的表述，是人工智能和认知科学中的核心概念。然而，代理如何以及在多大程度上被其观察所影响，这一方面同样具有基础性意义。作者提出了一个新的、以代理为中心的度量标准——塑性，并通过一个新的信息理论量度——广义定向信息量进行定义。作者通过塑性和赋能之间的关系揭示了一个基本的联系，并发现两者之间的区别只是影响的方向相反。研究结果表明，在设计代理时，需要考虑这两个特性的平衡", "innovation": "定义了一个新的、以代理为中心的度量标准——塑性，使用广义定向信息量进行定义，严格推广了Massey（1990）引入的定向信息概念，并保持其所有优点。研究发现，塑性和赋能是镜像关系，仅影响的方向相反。这一发现表明，在代理设计中需要同时考虑这两种特性", "conclusion": "本文通过塑性和赋能之间的关系揭示了代理设计中需要考虑的两个基础特性之间的矛盾，塑性、赋能及其关系对理解自主性具有重要意义"}
{"llm_update_time": "20251101", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2503.04852", "html_url": "https://arxiv.org/abs/2503.04852", "title": "CAUSAL3D: 视觉数据因果学习的综合基准", "title_en": "CAUSAL3D: A Comprehensive Benchmark for Causal Learning from Visual Data", "authors": "Disheng Liu,Yiran Qiao,Wuche Liu,Yiren Lu,Yunlai Zhou,Tuo Liang,Yu Yin,Jing Ma", "background": "真正的智能依赖于发现和利用隐藏的因果关系的能力。尽管在人工智能和计算机视觉方面取得了显著进展，但仍缺乏评估模型从复杂视觉数据中推断潜在因果关系能力的基准。本文提出了Causal3D，一个新颖且全面的基准，通过将结构化数据（表格）与相应的视觉表示（图像）相结合来评估因果推理能力。该基准覆盖了多种复杂场景，能够评估不同复杂度环境下的因果关系推理。", "innovation": "Causal3D是一个新颖且全面的基准，用于评估模型从复杂视觉数据中推断潜在因果关系的能力。它通过将结构化数据（表格）与相应的视觉表示（图像）相结合，覆盖了广泛的因果关系、视角和背景，从而提供了评价复杂场景中因果推理能力的机会。。研究比较了多种最先进的方法，包括经典因果发现、因果表示学习以及大型/视觉-语言模型。实验结果表明，随着因果结构的复杂性增加而缺乏先验知识时，性能会显著下降，突显了高级方法在复杂因果场景中面临的挑战。", "conclusion": "Causal3D作为视觉因果推理和可信AI领域进展的重要资源，为推动该领域的发展提供了关键支持。"}
{"llm_update_time": "20251101", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2505.12191", "html_url": "https://arxiv.org/abs/2505.12191", "title": "摆脱去噪器：数据课程中自监督学习中的去噪器引发的噪声鲁棒性", "title_en": "Ditch the Denoiser: Emergence of Noise Robustness in Self-Supervised Learning from Data Curriculum", "authors": "Wenquan Lu,Jiaqi Zhang,Hugues Van Assel,Randall Balestriero", "background": "自监督学习（SSL）已成为从无标签数据中提取丰富表示的强大解决方案。然而，大多数SSL研究主要集中在干净、整理和高质量的数据集上。因此，将SSL应用于嘈杂数据仍然是一个挑战，尽管对于诸如天体物理学、医学成像、地球物理学或金融等应用来说至关重要。", "innovation": "本文提出了一种完全自监督框架，能够在不需要推理或下游微调的去噪器的情况下进行噪声鲁棒性表征学习。方法包括首先在嘈杂数据上训练一个自监督去噪器，然后使用它来构造去噪到嘈杂数据的课程（即，先训练去噪样本，再训练嘈杂样本）预训练一个自监督骨干网络，并结合一个教师引导的正则化，这将嘈杂嵌入与其去噪对应项锚定在一起。该过程促进了模型内部化噪声鲁棒性。值得注意的是，去噪器可以在预训练后丢弃，简化了部署。", "conclusion": "在ImageNet-1k与ViT-B在极端高斯噪声下的情况下（σ=255，SNR=0.72 dB），我们的方法在DINOv2的基础上提高了线性探针精度4.8%，证明了去噪器缺席时的鲁棒性可以从噪音感知预训练中产生。"}
{"llm_update_time": "20251101", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2505.14970", "html_url": "https://arxiv.org/abs/2505.14970", "title": "Self-Evolving Curriculum for LLM Reasoning", "title_en": "Self-Evolving Curriculum for LLM Reasoning", "authors": "Xiaoyin Chen,Jiarui Lu,Minsu Kim,Dinghuai Zhang,Jian Tang,Alexandre Piché,Nicolas Gontier,Yoshua Bengio,Ehsan Kamalloo", "background": "强化学习（RL）已被证明在微调大规模语言模型（LLMs）方面非常有效，显著增强了其在数学和代码生成等领域的推理能力。一个影响RL微调成功率的关键因素是训练课程：即训练问题的呈现顺序。虽然随机课程作为常见的基线，但仍然不够理想；人工设计的课程往往依赖于启发式方法，而在线过滤方法可能在计算上具有挑战性。", "innovation": "我们提出了一种自动课程学习方法——Self-Evolving Curriculum (SEC)，它与RL微调过程同时学习课程策略。我们的方法将课程选择形式化为一个非稳态的多臂老虎机问题，每个问题类别（例如难度级别或问题类型）被视为一个单独的臂。我们利用策略梯度方法的绝对优势作为即时学习收益的代理度量。在每个训练步骤中，课程策略选择类别以最大化这个奖励信号，并使用TD(0)方法进行更新。实验结果表明，SEC在规划、归纳推理和数学等三种不同的推理领域中显著提高了模型的推理能力，使其更好地泛化到更难的、离分布的测试问题上。此外，这种方法在同时对多个推理领域进行微调时实现了更好的技能平衡。", "conclusion": "我们的研究结果突显了SEC作为LLMs的RL微调策略的一种有前景的方法。"}
{"llm_update_time": "20251101", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2505.12371", "html_url": "https://arxiv.org/abs/2505.12371", "title": "MedAgentBoard：以传统方法基准评估多智能体协作在多样医疗任务中的表现", "title_en": "MedAgentBoard: Benchmarking Multi-Agent Collaboration with Conventional Methods for Diverse Medical Tasks", "authors": "Yinghao Zhu,Ziyi He,Haoran Hu,Xiaochen Zheng,Xichen Zhang,Zixiang Wang,Junyi Gao,Liantao Ma,Lequan Yu", "background": "大型语言模型（LLMs）的快速发展激发了对于多智能体协作解决复杂医疗任务的兴趣。然而，多智能体协作的优势仍然缺乏足够的理解，现有评估往往缺乏泛化性，未能覆盖反映真实临床实践的多种任务，通常也未能与单LLMs方法和传统方法进行严格的对比。", "innovation": "MedAgentBoard 提供了一个全面的基准，系统地评估多智能体协作、单LLM和传统方法在医疗任务中的表现。该基准涵盖了四种不同的医学任务类别：（1）医疗（视觉）问答，（2）简单摘要生成，（3）结构化电子健康记录（EHR）预测建模，以及（4）临床工作流自动化，涵盖文本、医学图像和结构化EHR数据。实验揭示了多智能体协作与单LLM及传统方法之间的复杂关系，强调了任务特定的、基于证据的方法在医疗领域选择和发展AI解决方案的必要性。", "conclusion": "MedAgentBoard 提供了一个宝贵的资源和行动指南，强调了在特定任务上利用证据选择和开发AI解决方案的重要性。多智能体协作的优点在某些场景中显现，但并不总是优于先进的单LLM或专门的传统方法。需要仔细权衡多智能体协作带来的复杂性和额外开销与实际性能提升之间的关系。所有代码、数据集、详细提示和实验结果都已开源。"}
{"llm_update_time": "20251101", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2505.11542", "html_url": "https://arxiv.org/abs/2505.11542", "title": "基于深度自编码器的UEBA框架在网络安全威胁检测中的应用", "title_en": "Cybersecurity threat detection based on a UEBA framework using Deep Autoencoders", "authors": "Jose Fuentes,Ines Ortega-Fernandez,Nora M. Villanueva,Marta Sestelo", "background": "UEBA是一种数据分析的广泛分支，旨在建立正常的用户和实体行为特征，以便检测异常事件。在这些技术中，深度自编码器是UEBA任务中最具潜力的深度学习模型之一，能够对潜在的个人数据泄露、系统劫持、敏感商业信息访问等安全事件进行可解释的检测。为了进一步提高检测效果，该研究引入了一种结合Doc2Vec处理数值和文本特征的解释性UEBA异常检测框架。", "innovation": "该研究首次提出了一种结合深度自编码器和Doc2Vec的解释性UEBA异常检测框架，同时提供了一个基于神经网络理论的新颖证明，展示了两种广泛使用的全连接神经网络定义的等价性。实验结果表明该框架在检测实际和合成异常方面具有较高的准确性和可解释性，有助于揭示异常行为的起源。", "conclusion": "提出的UEBA框架能够无缝集成到企业的安全环境中，补充现有的安全系统以进行可解释的威胁检测。这种方法能够有效检测来自真实攻击数据的异常，并且不仅能够正确识别异常，还能提供可解释的结果。"}
{"llm_update_time": "20251101", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2503.04492", "html_url": "https://arxiv.org/abs/2503.04492", "title": "基于可解释机器学习的精选重要特征的带隙准确预测模型", "title_en": "Accurate predictive model of band gap with selected important features based on explainable machine learning", "authors": "Joohwi Lee,Kaito Miyamoto", "background": "在材料信息学的快速发展中，非线性机器学习模型在材料性质预测方面表现出卓越的预测能力，但它们的黑箱性质限制了可解释性，并且可能包含不贡献甚至恶化模型性能的特征。", "innovation": "该研究采用可解释的机器学习技术（如特征重要性_permutation和Shapley值解释），应用于专门设计用于预测GW水平带隙的纯净支持向量回归模型，并使用18个输入特征。根据可解释性机器学习（XML）获得的单一特征重要性，提出了简单的框架以构建减少特征的预测模型。该模型评估表明，由XML指导的紧凑模型（由前五个特征组成）在领域内数据集上与原始模型具有可比的精度（0.254 vs. 0.247 eV），而在领域外数据集上具有更好的泛化能力，预测误差较低（0.461 vs. 0.341 eV）。此外，研究还强调了在应用可解释性机器学习之前消除强相关特征（相关系数大于0.8）的重要性，以防止特征重要性解释的误读和过估计，从而提高模型的可信度并简化特征获取过程，降低成本.", "conclusion": "该研究突出了可解释机器学习在开发简化且高度精确的机器学习模型中的有效性，通过阐明特征的作用来进一步降低计算成本，增强材料发现过程中的模型可信度。"}
{"llm_update_time": "20251101", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2505.11329", "html_url": "https://arxiv.org/abs/2505.11329", "title": "TokenWeave：分布式大语言模型推理中高效计算-通信重叠", "title_en": "TokenWeave: Efficient Compute-Communication Overlap for Distributed LLM Inference", "authors": "Raja Gond,Nipun Kwatra,Ramachandran Ramjee", "background": "分布式推断大语言模型（LLMs）在使用高速互联（如NVLink连接的GPU）时仍可能引入最多20%的额外开销。为减轻这些开销，提出了多种技术，通过细粒度地分解计算任务并重叠数据传输与子任务执行来缓解。但这种细粒度的分解导致在GPU上执行大量细粒度计算本身会引入额外开销，而且数据传输本身使用了多个流多处理器（SMs），进一步增加了开销。", "innovation": "TokenWeave提出了一种Token-Splitting技术，它以波的形式将推理批次中的标记分成两个大致相等的子集。其中一个子集的通信可以与另一个子集的计算重叠。此外，TokenWeave还优化了层归一化计算的顺序，实现了新颖的融合AllReduce--RMSNorm内核，充分利用Hopper和Blackwell NVIDIA GPU上的Multimem指令支持。这些优化使得TokenWeave能够仅使用2-8个SMs完成通信和RMSNorm操作，同时使内存受限RMSNorm操作可以与其他批次的计算重叠，带来额外的性能增益。实验结果显示，TokenWeave在多个模型和工作负载中表现出多达1.29倍的延迟加速和1.26倍的吞吐量提升，在某些情况下，即使移除所有的通信部分，TokenWeave仍能表现更好。", "conclusion": "TokenWeave通过提出Token-Splitting和优化层归一化计算顺序及实现新型融合内核解决了分布式LLM推理中的计算-通信开销问题，从而提升了延迟和吞吐量，尤其是在某些情况下超越了去除所有通信部分的等效模型。"}
{"llm_update_time": "20251101", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2505.11730", "html_url": "https://arxiv.org/abs/2505.11730", "title": "重思计算高效测试时缩放的最佳验证粒度", "title_en": "Rethinking Optimal Verification Granularity for Compute-Efficient Test-Time Scaling", "authors": "Hao Mark Chen,Guanxi Lu,Yasuyuki Okoshi,Zhiwen Mo,Masato Motomura,Hongxiang Fan", "background": "测试时缩放（TTS）在提升大规模语言模型（LLMs）的推理能力方面已显示出有效的效果。验证过程对TTS的影响主要体现在（1）推理性能和（2）计算效率上，这取决于验证的质量和计算成本。传统的验证方式已经存在，但本研究挑战了这一做法，旨在系统性地考察验证粒度的影响，即验证器在生成过程中被调用的频率，而不仅仅是验证最终输出或单独的生成步骤。", "innovation": "引入了可调节粒度参数g的统一体化算法Variable Granularity Search（VG-Search），该算法将beam search和Best-of-N sampling进行了泛化处理。通过不同计算预算、生成器-验证者配置和任务属性下的大量实验，表明动态选择g值能够提高计算效率和缩放行为。在此基础上，提出了适应性VG-Search策略，这些策略在对比beam search和Best-of-N时，分别实现了3.1%和3.6%的准确率增益，同时计算量减少了超过52%。", "conclusion": "基于研究发现，提出了一种适应性VG-Search策略，结果表明，能够在计算效率上获得显著提升的同时，保持和提高模型性能。未来的研究将开放源代码，支持进一步的研究工作。"}
{"llm_update_time": "20251101", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2505.17789", "html_url": "https://arxiv.org/abs/2505.17789", "title": "通过随机傅里叶特征实现最优在线变化检测", "title_en": "Optimal Online Change Detection via Random Fourier Features", "authors": "Florian Kalinke,Shakeel Gavioli-Akilagun", "background": "该论文研究了多维数据流中在线非参数变化点检测的问题。通过核基双样本测试的视角，引入了一种基于随机傅里叶特征的顺序测试程序，使得每次观察的时间复杂度为对数级别，并且整体空间复杂度也为对数级别。", "innovation": "与现有技术相比，该算法有两大优势：1. 真正实现在线检测，无需事先获取变更前数据分布的训练数据。2. 算法不需要用户指定窗口参数，而是在局部测试中自动计算。此外，论文证明了该算法具有出色的信息论保证，检测延迟在最小最大意义上是最佳的。", "conclusion": "通过对真实和合成数据的数值研究，显示该算法在与现有方法的竞争中表现出色。"}
{"llm_update_time": "20251101", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.03237", "html_url": "https://arxiv.org/abs/2506.03237", "title": "UniSite：首个跨结构的数据集及端到端配体结合位点检测的学习框架", "title_en": "UniSite: The First Cross-Structure Dataset and Learning Framework for End-to-End Ligand Binding Site Detection", "authors": "Jigang Fan,Quanlin Wu,Shengjie Luo,Liwei Wang", "background": "蛋白配体结合位点的检测是基于结构药物设计中的基本步骤，尽管近年来取得了显著进展，但现有方法、数据集和评估指标仍面临几个关键挑战：（1）当前的数据集和方法侧重于单独的蛋白-配体复合物，并忽视了同一蛋白不同复合物中的多样化结合位点，这引入了统计偏差；（2）蛋白配体结合位点检测通常被建模为间断的流程，采用二元分割和随后的聚类算法；（3）传统的评估指标未能充分反映不同配体结合位点预测方法的实际性能。", "innovation": "首先介绍了UniSite-DS，这是第一个以UniProt为中心的配体结合位点数据集，包含了4.81倍多的多位点数据和2.08倍多的总体数据，相比之前最广泛使用的数据集。其次提出了UniSite，这是首个端到端配体结合位点检测框架，采用集合预测损失和支持双射匹配的监督学习方法。此外，引入了基于交并比（IoU）的平均精度作为更准确的预测指标。在UniSite-DS和多个代表性基准数据集上的大量实验表明，基于IoU的平均精度能更准确地反映预测质量，而且UniSite在配体结合位点检测方面优于当前最先进的方法。", "conclusion": "实验结果证明，基于IoU的平均精度能够更准确地反映预测质量，而UniSite框架在蛋白配体结合位点检测方面优于现有最佳方法。数据集和源代码将在指定的网址上公开提供。"}
{"llm_update_time": "20251101", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.25114", "html_url": "https://arxiv.org/abs/2510.25114", "title": "从ε-图到具备连接功能的连续扩散模型的能量方法", "title_en": "Energy Approach from $\\varepsilon$-Graph to Continuum Diffusion Model with Connectivity Functional", "authors": "Yahong Yang,Sun Lee,Jeff Calder,Wenrui Hao", "background": "论文背景涉及将ε-图（一种离散模型）与连续模型进行能量分析，特别关注测量的连接性功能，这在描述复杂系统（如神经系统）的动力学行为时非常重要。", "innovation": "该研究提出了一种新方法，通过连接密度的W1,1范数来量化ε-图离散能量与连续能量之间的差异，即使连接密度存在强烈局部波动，这种量化仍是有效的。此外，引入了一种神经网络算法，可以从边权重数据中重构连接密度，进而将其嵌入到脑动力学模型中。", "conclusion": "研究展示了在脑动力学框架中使用空间变化的扩散系数相比于常数值带来的显著不同，这为理解复杂系统的动力学提供了新的视角。"}
{"llm_update_time": "20251101", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.21513", "html_url": "https://arxiv.org/abs/2510.21513", "title": "代码生成和修复中LLM集合的智慧与幻觉", "title_en": "Wisdom and Delusion of LLM Ensembles for Code Generation and Repair", "authors": "Fernando Vallecillos-Ruiz,Max Hort,Leon Moonen", "background": "当前追求一个适用于所有软件工程任务的单一大型语言模型（LMM）既耗资源又忽略了不同模型之间互补性的潜在益处。各代码生成LLM之间的互补程度及其如何最大化集合的潜在性能尚不明确，这使从业者缺乏迈向单一模型系统之外的明确路径。因此，该研究通过实证对比五大家族中的十种个体LLM及其三种集合，以及在三个涵盖代码生成和程序修复的软件工程基准上的表现，来填补这一空白。", "innovation": "研究首次实证比较了不同大型语言模型之间的互补性，并评估了最佳个体模型与集合之间的性能差距。评估了几种选择策略，以从集合的候选池中识别正确解，发现基于共识的选择策略放大了常见但错误的输出，而基于多样性的策略能够实现理论潜力的95%，即使在小型双模型集合中也表现出有效性。", "conclusion": "研究结果表明，集合的最大性能潜力可以比最佳单个模型高出83%。采用基于多样性的策略可以克服基于共识的选择陷阱，实现更高效且高性能的软件工程系统，通过利用多个LLM来降低成本。"}
{"llm_update_time": "20251101", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.14904", "html_url": "https://arxiv.org/abs/2510.14904", "title": "MaskCaptioner: 学习在视频中同时分割和描述目标轨迹", "title_en": "MaskCaptioner: Learning to Jointly Segment and Caption Object Trajectories in Videos", "authors": "Gabriel Fiastre,Antoine Yang,Cordelia Schmid", "background": "Dense Video Object Captioning（DVOC）任务要求识别、跟踪和描述视频中对象的轨迹，需要理解空间-时间细节并用自然语言描述。由于任务复杂性和人工标注的高成本，之前的尝试通常采用分阶段的训练策略，可能导致性能欠佳。", "innovation": "本研究提出了MaskCaptioner，利用最新的视觉-语言模型生成空间-时间局部实体的描述。通过在合成描述（LVISCap 和 LV-VISCap）上预训练，MaskCaptioner 能够端到端地完成目标轨迹的检测、分割、跟踪和描述。该模型在三个已有的基准测试（VidSTG、VLN 和 BenSMOT）中取得了性能领先地位。", "conclusion": "通过合成描述扩展 LVIS 和 LV-VIS 数据集，MaskCaptioner 被训练成为一个端到端模型，实现了在三个现有基准测试中的最优 DVOC 性能。所有数据集和代码可在指定链接下载。"}
{"llm_update_time": "20251101", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.25080", "html_url": "https://arxiv.org/abs/2510.25080", "title": "垄断游戏：有界单向响应游戏的基准环境", "title_en": "Monopoly Deal: A Benchmark Environment for Bounded One-Sided Response Games", "authors": "Will Wolf", "background": "卡牌游戏被广泛用于研究在不确定条件下的顺序决策过程，其在谈判、金融和网络安全等领域具有现实的类比。这类游戏通常可以分为三种控制流类型：严格顺序（玩家轮流进行单一行动）、确定响应（某些行动触发固定的结局）和无限制的相互响应（双方轮流做出对抗性举动）。较为少见但战略上更为丰富的结构是有限的一方响应，即一个玩家的操作使得对手暂时控制局面，并且对手需要在若干次行动中满足一个固定条件才能完成该回合。我们称之为有界单向响应游戏（BORGs）.", "innovation": "介绍了垄断游戏的一个改良版本作为BORGs的基准环境，其中“出租”动作迫使对手选择支付资产。标准算法——假设性遗憾最小化（CFR）——在这种环境下收敛于有效的策略，无需额外的算法扩展。同时提供了一个轻量级的全栈研究平台，集成了环境、并行化的CFR运行时和一个可玩的人机交互网页界面。训练好的CFR代理及源代码可在指定网址获取.", "conclusion": "研究表明，改良后的垄断游戏可以有效地用于研究有界单向响应游戏，并且标准的CFR算法在该环境中能够收敛，表现出强大的策略生成能力。与此同时，该研究提供了一个完整的实验平台，旨在促进对未来BORGs的研究与探索。"}
{"llm_update_time": "20251101", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.25327", "html_url": "https://arxiv.org/abs/2510.25327", "title": "MMEdge：通过流水线感知和编码加速边缘设备上的多模态推理", "title_en": "MMEdge: Accelerating On-device Multimodal Inference via Pipelined Sensing and Encoding", "authors": "Runxi Huang,Mingxuan Yu,Mingyu Tsoi,Xiaomin Ouyang", "background": "边缘设备上的实时多模态推理对于诸如自动驾驶、人机交互和移动健康应用等场景至关重要。然而，现有研究往往忽略了感知动态与模型执行之间的紧密联系，以及不同模态之间的复杂依赖性。", "innovation": "提出了一种名为MMEdge的新边缘设备上多模态推理框架，基于流水线感知和编码。MMEdge将整个推理过程分解为一系列细粒度的感知和编码单元，使得计算可以随着数据的到来逐步进行。此外，MMEdge引入了一个轻量级但有效的时序聚合模块，以捕捉不同流水线单元中的富时序动态，保持准确性能。这种流水线设计还为细粒度的跨模态优化和推理过程中的早期决策提供了机会。MMEdge还结合了动态多模态配置优化器和跨模态推测跳过机制，以适应资源变化和输入数据复杂性，进一步提高系统性能。", "conclusion": "通过在两个公开的多模态数据集上评估MMEdge，并将其部署在基于无人飞行器（UAV）的实际多模态测试平台上，实验结果表明，MMEdge在不降低任务准确性的前提下，显著减少了端到端的延迟。"}
{"llm_update_time": "20251101", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.10728", "html_url": "https://arxiv.org/abs/2510.10728", "title": "粗糙路径签名：学习神经RDE方法进行投资组合优化", "title_en": "Rough Path Signatures: Learning Neural RDEs for Portfolio Optimization", "authors": "Ali Atiah Alzahrani", "background": "本文探讨了高维路径依赖价值评估和控制的问题，提出了一种结合截断对数签名与神经粗糙微分方程（RDE）核心的深度BSDE/2BSDE求解器。该模型旨在将随机分析与序列到路径的学习相融合：通过CVaR-倾斜的终端目标来量化左侧风险，并可选地添加二级头（2BSDE）以提供风险敏感控制所需的曲率估计，从而提升了计算资源和参数预算匹配下的精确度、尾部精度和训练稳定性。", "innovation": "本文的创新在于开发了一种深度BSDE/2BSDE求解器，结合了截断对数签名和神经RDE的核心，以解决高维路径依赖价值评估和控制问题。此方法通过CVaR-倾斜的终端目标和可选的2BSDE头，实现了在计算资源和参数预算匹配下对亚式和障碍期权定价以及投资组合控制的更准确、更稳定的计算结果。", "conclusion": "研究所取得的结果表明，成功地实现了一种双向对话模式：随机分析工具引导制定表示和目标，而序列到路径模型则扩展了大规模可解金融模型的范围。通过调节截断深度、局部窗口和倾斜参数，实验进一步证实了这种表示形式和2BSDE头的互补优势。"}
{"llm_update_time": "20251101", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.24817", "html_url": "https://arxiv.org/abs/2510.24817", "title": "针对帕金森病患者对话模拟生成方法", "title_en": "Towards a Method for Synthetic Generation of Persons with Aphasia Transcripts", "authors": "Jason M. Pittman,Anton Phillips Jr.,Yesenia Medina-Santos,Brielle C. Stark", "background": "在语义痴呆研究中，言语-语言病理学家（SLPs）会花费大量时间手动编码语音样本中的正确信息单元（CIUs），这是衡量单个语音样本信息量的标准。由于数据稀缺限制了自动系统识别语言障碍的能力，如AphasiaBank中只有约600个转录文本，而大型语言模型（LLMs）则需要数亿个词元进行训练。在更广泛的机器学习领域，研究人员开始转向合成数据以填补数据不足的情况。因此，本研究旨在构建和验证两种方法，用于生成AphasiaBank中的Cat Rescue图片描述任务的合成转录文本。这些方法通过词汇删除、填充插入和同义词替换在四个严重程度级别（轻度、中度、重度、极重度）下生成转录文本。研究表明，与人类引导的转录文本相比，Mistral 7b Instruct生成的合成转录文本最能捕捉语义障碍中的语言退化关键方面，显示出与合成生成方法相关的NDW、词汇量和词长的真实方向性变化。", "innovation": "本研究通过两种方法——一种基于过程化编程的方法和另一种使用Mistral 7b Instruct和Llama 3.1 8b Instruct大语言模型来生成合成转录文本，弥补了数据稀缺的问题。所提出的方法能够覆盖四个严重程度级别的图片描述，通过词汇删除、填充插入和同义词替换，以创新性地解决数据不足的问题，从而更好地模拟语言障碍中的语言退化。", "conclusion": "未来的工作应计划创建一个更大的数据集，对模型进行微调以更好地表征语义障碍，并由SLPs评估合成转录文本的真实性及其在临床评估中的应用价值。"}
{"llm_update_time": "20251101", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.22319", "html_url": "https://arxiv.org/abs/2510.22319", "title": "GRPO-Guard: 通过受控剪裁缓解流匹配中的隐式过度优化", "title_en": "GRPO-Guard: Mitigating Implicit Over-Optimization in Flow Matching via Regulated Clipping", "authors": "Jing Wang,Jiajun Liang,Jie Liu,Henglin Liu,Gongye Liu,Jun Zheng,Wanyuan Pang,Ao Ma,Zhenyu Xie,Xintao Wang,Meng Wang,Pengfei Wan,Xiaodan Liang", "background": " recently, GRPO-based reinforcement learning在优化流匹配模型方面取得了显著进展，特别是在提高其与任务特定奖励的对齐方面。然而，在实际应用中发现重要性比例分布存在系统性偏差，其均值低于1，方差在不同时间步上差异显著。这导致了偏好性优势样本无法进入剪裁区域，使得过度自信的正面更新无法得到有效约束，从而导致模型进入隐式过度优化阶段。", "innovation": "提出了GRPO-Guard，这是一种对现有GRPO框架的简单但有效的改进。该方法引入了比率归一化，恢复了平衡且步进一致的重要性比例，确保PPO剪裁能够正确地约束危害性更新。此外，采用梯度重新加权策略平衡噪声条件下的策略梯度，防止特定时间步区域的过度更新。这些设计共同形成了一种受控剪裁机制，稳定了优化过程，显著减轻了隐式过度优化，而无需依赖重的KL正则化。", "conclusion": "在多种扩散模型基础（例如SD3.5M、Flux.1-dev）和不同代理任务上进行了广泛的实验，结果表明GRPO-Guard显著减少了过度优化，同时保持或甚至提高了生成质量。"}
{"llm_update_time": "20251101", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.23534", "html_url": "https://arxiv.org/abs/2510.23534", "title": "通过Bregman发散最小化实现直接去偏差机器学习", "title_en": "Direct Debiased Machine Learning via Bregman Divergence Minimization", "authors": "Masahiro Kato", "background": "在涉及因果效应或结构模型的问题中，目标参数依赖于回归函数。使用机器学习方法估计回归函数并插入识别方程中可能会导致性能不佳，因为存在第一阶段偏差。去偏差机器学习采用Neyman正交估计方程来减轻这种偏差。通常，去偏差机器学习需要估计Riesz表示器和回归函数。本研究开发了一个直接去偏差机器学习框架，包括Neyman目标估计和广义Riesz回归，统一了Riesz回归、协变量均值调整、目标最大似然估计(TMLE)和密度比率估计。", "innovation": "通过Neyman目标估计和广义Riesz回归，该框架整合了多个去偏差机器学习技术。提出了一种端到端算法来估计 nuisance 参数、回归函数和 Riesz 表示器。该算法包括估计Riesz表示器的广义Riesz回归，使用Bregman发散来衡量差距，其涵盖各种损失函数，如平方损失和Kullback-Leibler发散，并且还可以自动获得协变量平衡属性。", "conclusion": "该研究提供了一种直接去偏差机器学习的新框架，适用于许多涉及因果效应或结构模型的问题，通过统一的技术整合了多种去偏差方法，简化了模型和目标函数的估计过程，无需显式求解协变量平衡目标。"}
{"llm_update_time": "20251101", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.23216", "html_url": "https://arxiv.org/abs/2510.23216", "title": "在逼真的足球模拟中实现类人类守门员：一种高效的经验强化学习方法", "title_en": "Human-Like Goalkeeping in a Realistic Football Simulation: a Sample-Efficient Reinforcement Learning Approach", "authors": "Alessandro Sestini,Joakim Bergdahl,Jean-Philippe Barrette-LaPierre,Florian Fuchs,Brady Chen,Michael Jones,Linus Gisslén", "background": "尽管一些热门视频游戏被用作深度强化学习（DRL）的试验平台，但游戏行业罕见地利用这一技术来设计真实的AI行为。以往的研究侧重于通过大规模模型训练超人类代理，这使得资源有限的游戏工作室难以实现类似人类的代理。本文提出了一种针对工业环境（如视频游戏产业）的高效样本DRL方法，旨在提高基于价值的DRL的样本效率，通过利用预先收集的数据和提高网络的可塑性。研究者们评估了该方法在EA SPORTS FC 25中的应用，这是一种当今最畅销的足球模拟游戏之一，结果显示，他们的代理在接球率上比游戏内置AI高出10%。消融研究进一步表明，该方法比传统的DRL方法训练代理速度快50%。从领域专家的定性评估来看，该方法能够生成更加接近人类玩法的代理，这与手工设计的代理形成了对比。最后，为了证明该方法的影响，它已经在最近该系列的最新发布中被采用并得以实际应用。", "innovation": "提出了一种针对工业环境（如视频游戏产业）的高效样本DRL方法，旨在提升基于价值的DRL的样本效率，通过利用预先收集的数据和提高网络的可塑性。该方法在EA SPORTS FC 25中的应用取得了相较于内置AI 10%更高的接球率，且比标准DRL方法训练代理速度快50%，在领域专家的定性评估中，创造了更接近人类的代理。", "conclusion": "该研究在视频游戏产业中使用高效的样本DRL方法实现了类人类的守门员行为，在EA SPORTS FC 25中表现出色，比内置AI高10%的接球率，并且训练速度比标准DRL方法快50%。研究结果证实该方法能够生成更接近人类的行为，该方法已被实际应用在游戏系列的最新版本中。"}
{"llm_update_time": "20251101", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2510.26538", "html_url": "https://arxiv.org/abs/2510.26538", "title": "在大型语言模型时代的软件工程实证与可持续性方面反思研究", "title_en": "Reflecting on Empirical and Sustainability Aspects of Software Engineering Research in the Era of Large Language Models", "authors": "David Williams,Max Hort,Maria Kechagia,Aldeida Aleti,Justyna Petke,Federica Sarro", "background": "软件工程(SE)研究运用大型语言模型(LLMs)引入了严格的基准测试、污染、可重复性和可持续性等方面的多个新挑战。本文探讨了当前SE研究中如何应对这些挑战。", "innovation": "本文提出了一种结构化的视角来概述ICSE中基于LLMs的SE研究现状，既指出了积极的做法也指出了持续存在的不足，并提出增强基准测试的严谨性、提高可重复性以及解决基于LLMs的SE的财务和环境成本等方面的建议。", "conclusion": "文章总结了当前LLMs驱动的SE研究的现状，并提出改善基准测试的严谨性、提高可重复性和解决财务和环境成本的建议。"}
{"llm_update_time": "20251101", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2510.26576", "html_url": "https://arxiv.org/abs/2510.26576", "title": "展示你合规……而不展示任何东西：基于零知识的软件审核以应对AI驱动系统", "title_en": "\"Show Me You Comply... Without Showing Me Anything\": Zero-Knowledge Software Auditing for AI-Enabled Systems", "authors": "Filippo Scaramuzza,Renato Cordeiro Ferreira,Tomaz Maia Suller,Giovanni Quattrocchi,Damian Andrew Tamburri,Willem-Jan van den Heuvel", "background": "随着人工智能（AI）在关键领域中的应用不断增多，信任问题变得尤为重要，需要通过验证保证可追溯性，这通常需要符合法律法规（如欧盟AI法案）。传统的软件验证和验证技术（如程序审计、形式化方法或模型文档）适用于这一需求。然而，这些方法要么成本高昂，要么耗时手动操作，并不适合大多数“黑盒”性质的AI模型。因此，法律要求的高审计性和可验证性与保护被审计资产（如机密数据和专有模型）的需求发生冲突，导致了问责制的削弱。", "innovation": "本文提出了ZKMLOps，这是一种将零知识证明（ZKPs）嵌入到机器学习操作（MLOps）生命周期中的新型框架，通过结合ZKPs与软件工程模式，提供了一个模块化和可重复的过程，用于生成合规的验证性加密证明。", "conclusion": "通过金融风险审核的合规性研究评估了该框架的实际应用，并通过实证分析顶级ZKP协议的性能折衷方案，评估了其可行性。"}
{"llm_update_time": "20251101", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2510.26413", "html_url": "https://arxiv.org/abs/2510.26413", "title": "CI/CD流水线的环境影响", "title_en": "Environmental Impact of CI/CD Pipelines", "authors": "Nuno Saavedra,Alexandra Mendes,João F. Ferreira", "background": "CI/CD流水线在软件开发中广泛应用，但其对环境的影响，特别是碳足迹和水足迹（CWF），开发者通常并不了解。随着云计算环境影响的增加，了解CI/CD服务的CWF变得越来越重要。研究通过使用GitHub Actions生态系统，重点关注使用免费且不限量的标准运行器的开源仓库，来调查其CWF。", "innovation": "本研究基于Cloud Carbon Footprint框架的方法论，利用迄今为止文献中最大的工作流运行数据集，分析了GitHub Actions生态系统的CWF。研究数据包括超过220万个工作流运行，来自超过18000个仓库，揭示了GitHub Actions带来的显著CWF。", "conclusion": "GitHub Actions生态系统导致了显著的CWF。最有可能的场景估计碳足迹为456.9 MTCO2e，水足迹为5,738.2千升。建议减少计算资源的浪费，包括部署在低环境影响能源生产地区的运行器，实施更严格的定时运行停用政策，并与更环保的地区能源组合相匹配，以及减少仓库的规模。"}
{"llm_update_time": "20251101", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2510.26579", "html_url": "https://arxiv.org/abs/2510.26579", "title": "在线交互式贝叶斯推理调试", "title_en": "Online and Interactive Bayesian Inference Debugging", "authors": "Nathanael Nussbaumer,Markus Böck,Jürgen Cito", "background": "概率编程是一种快速发展的编程范式，能够将贝叶斯模型作为程序进行表述，并自动化后验推理。它促进了模型的开发和贝叶斯推理的开展，使得这些技术在多个领域得到应用。然而，概率编程因其在识别和修正推理问题上需要大量时间和深厚知识而著称。本文通过介绍一种新的调试贝叶斯推理的方法，显著减少了花费的时间和所需的知识。文章讨论了贝叶斯推理调试框架的需求，并提出了一种满足这些要求的新工具，直接在开发环境中实现。", "innovation": "文章提出了一种在线且交互式的贝叶斯推理调试方法，这种方法显著减少了调试时间并降低了难度。该工具作为开发环境的一部分直接实现，能够直接满足贝叶斯推理调试框架的关键需求。", "conclusion": "在一项使用18名经验丰富的参与者的研究中，研究成果展示了在线和交互式贝叶斯推理调试方法能够在推理调试任务中显著降低时间和难度。"}
{"llm_update_time": "20251101", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2510.26287", "html_url": "https://arxiv.org/abs/2510.26287", "title": "基于蒙特卡洛树搜索驱动的强化学习赋能RepoQA-Agent", "title_en": "Empowering RepoQA-Agent based on Reinforcement Learning Driven by Monte-carlo Tree Search", "authors": "Guochang Li,Yuchen Liu,Zhen Qin,Yunkun Wang,Jianping Zhong,Chen Zhi,Binhua Li,Fei Huang,Yongbin Li,Shuiguang Deng", "background": "软件工程任务需要大型语言模型（LLMs）能够高效地在复杂的代码库中导航和提取信息，这通常需要多轮次工具交互。现有方法面临着显著的限制：无监督的上下文学习方法难以有效地指导工具使用和基于环境反馈的决策；基于训练的方法则依赖于从大型LLM中成本高昂的知识精炼，存在企业环境中的数据合规性问题。", "innovation": "引入了基于Monte-carlo Tree Search（MCTS）的新型代理强化学习框架RepoSearch-R1。该框架允许代理通过自我训练生成多样化、高质量的推理轨迹，无需模型精炼或外部监督。基于RepoSearch-R1，我们构建了一个专门针对代码库问题解答任务的RepoQA-Agent。全面的评估结果显示，RepoSearch-R1在回答完整性上显著提升：比无检索方法提高16.0%，比迭代检索方法提高19.5%，训练效率比一般代理强化学习方法提高33%。冷启动训练方法消除了数据合规性问题，同时保持了在代码库级推理任务中强大的探索多样性和回答完整性。", "conclusion": "采用RepoSearch-R1方法不仅解决了之前方法的数据合规性问题，还在多个评估指标上实现了显著的性能提升，并且能够保持算法的多样性和有效性。这种方法为代码库级别的软件工程任务提供了一种新的解决方案，具有广泛的应用前景。"}
{"llm_update_time": "20251101", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2510.26480", "html_url": "https://arxiv.org/abs/2510.26480", "title": "使用开源大语言模型进行自动化提取方法重构：一项比较研究", "title_en": "Automated Extract Method Refactoring with Open-Source LLMs: A Comparative Study", "authors": "Sivajeet Chand,Melih Kilic,Roland Würsching,Sushant Kumar Pandey,Alexander Pretschner", "background": "自动化提取方法重构（EMR）任务虽然对提高代码可读性和可维护性至关重要，但在实践中仍然是一个具有挑战性的手动任务。最新的开源资源高效的大规模语言模型（LLMs）为自动化此类高级任务提供了新的潜在方法。", "innovation": "研究对五种领先的开源大语言模型进行了评估，这些模型的参数范围从3亿到8亿，用于Python代码的EMR任务。研究系统地评估了功能正确性和代码质量，并通过比较一次性提示和递归批评和改进（RCI）方法来研究提示策略的影响。RCI提示策略在测试通过率和重构质量方面始终优于一次性提示。此外，研究还表明开发者对RCI生成的重构的接受度超过70%，特别是Qwen2.5-Coder-RCI在所有评估标准中得分最高。", "conclusion": "传统的复杂度和代码行数指标虽提供了一些有用的信号，但它们往往与人类判断不一致，强调了人为介入评估的必要性。开放源代码基准为未来使用LLMs进行自动化重构的研究提供了基础。"}
{"llm_update_time": "20251101", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2510.26516", "html_url": "https://arxiv.org/abs/2510.26516", "title": "未来交互式网页开发展望：使用自然语言编辑网页", "title_en": "Envisioning Future Interactive Web Development: Editing Webpage with Natural Language", "authors": "Truong Hai Dang,Jingyu Xiao,Yintong Huo", "background": "网页应用程序的发展依赖于迭代的代码修改，这一过程一直是手动且耗时的。虽然大型语言模型（LLMs）能够生成用户界面（UI）代码，但在根据新的设计要求（例如，“将标志居中”）编辑现有代码方面仍存在技术挑战。这主要归因于缺乏大规模、高质量的调优数据，以使模型的性能与人类的期望保持一致。", "innovation": "本文介绍了使用大型语言模型（LLMs）合成高质量的微调数据集以自动化生成编辑数据的全新方法 (Instruct4Edit)。该方法生成多样化的指令，应用相应的代码修改，并进行视觉验证以确保正确性。通过在Instruct4Edit上微调模型，我们可以展示模型在将人类意图转化为精确、结构上连贯且视觉上准确的代码更改方面的持续改进。研究表明，微调较小的开源模型可以实现与专有系统具有竞争力的性能。", "conclusion": "本文提供了一个基于自然语言的网页编辑可扩展且透明的基础框架，证明了使用较小的开源模型进行微调可以达到与专有系统竞争的性能。所有数据、代码实现和模型检查点均已公开，以供重现。"}
{"llm_update_time": "20251101", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2510.26431", "html_url": "https://arxiv.org/abs/2510.26431", "title": "CHCVerif：一种基于组合式求解器的受约束的 horn 子句求解器", "title_en": "CHCVerif: A Portfolio-Based Solver for Constrained Horn Clauses", "authors": "Mihály Dobos-Kovács(Department of Artificial Intelligence and Systems Engineering, Budapest University of Technology and Economics, Hungary),Levente Bajczi(Department of Artificial Intelligence and Systems Engineering, Budapest University of Technology and Economics, Hungary),András Vörös(Department of Artificial Intelligence and Systems Engineering, Budapest University of Technology and Economics, Hungary)", "background": "受限的 horn 子句 (CHCs) 广泛用于多种验证任务，包括安全性检查、不变式合成和跨过程分析。常见的验证方法已广泛使用，但处理以位向量和低级语义为核心的 CHC 标准时仍然存在挑战。CHCVERIF 是一种基于组合式方法的 CHC 求解器，它采用软件验证方法来求解 CHCs。这种方法可以通过重用成熟的软件验证工具来处理 CHC 标准，特别是那些涉及位向量和低级语义的实例。但在线性整数算术领域，该方法的成效有限，但在位向量的标准方面，其表现尚可。这项研究表明，利用软件验证工具作为 CHC 求解器的后端是可行且具有潜力的，尤其是在通过精心构建的组合式方法支持下。", "innovation": "CHCVERIF 引入了一种基于软件验证方法的组合式求解策略，通过重用成熟的软件验证工具来解决复杂的 CHC 标准，特别是那些涉及位向量和低级语义的实例。", "conclusion": "尽管该方法在线性整数算术中的成效有限，但对位向量标准的处理表现出一定的效果。研究结果证明了使用软件验证工具作为 CHC 求解器后端的可行性和潜力，尤其在提供精心构建的组合式方法支持的情况下。"}
{"llm_update_time": "20251101", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2510.26457", "html_url": "https://arxiv.org/abs/2510.26457", "title": "SecureReviewer：通过安全意识微调提升大型语言模型的代码审查安全性", "title_en": "SecureReviewer: Enhancing Large Language Models for Secure Code Review through Secure-aware Fine-tuning", "authors": "Fang Liu,Simiao Liu,Yinghao Zhu,Xiaoli Lian,Li Zhang", "background": "在软件开发早期阶段识别和解决安全问题对于降低长期负面影响非常重要。代码审查是一种有效的方法，允许开发人员在将代码集成到代码库之前检查他们的代码。虽然已经提出了许多自动代码审查方法，其中基于LLM的方法显著提升了自动审查生成的能力，但现有模型主要集中在通用代码审查上，它们在识别和解决安全相关问题方面的效果尚未得到充分探索。此外，将现有的代码审查方法调整以针对安全问题面临诸多挑战，包括数据稀缺和不充分的评估指标。", "innovation": "为了解决这些限制，本文提出了SecureReviewer，一种新的方法，旨在提升LLM在代码审查中识别和解决安全相关问题的能力。具体而言，首先构建了一个专为训练和评估安全代码审查能力的数据集。利用此数据集，采用了所提出的安全意识微调策略对LLM进行了微调，以生成能够有效识别安全问题并提供修复建议的代码审查评论。此外，通过引入RAG技术来减轻LLM的幻觉现象，确保生成的评论的输出可靠性，并提出了SecureBLEU作为评估审查评论在解决安全问题方面的有效性的新指标。实验结果表明，SecureReviewer在安全问题检测准确性以及生成的审查评论的整体质量和实用价值方面都优于现有的基线方法。", "conclusion": "实验结果证明，SecureReviewer在安全问题检测准确性和生成的审查评论的整体质量与实用性方面都优于现有的最先进的基线方法。"}
{"llm_update_time": "20251101", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2510.26676", "html_url": "https://arxiv.org/abs/2510.26676", "title": "基于过程的重新引入代码变更的脆弱性指标：一项探索性案例研究", "title_en": "Process-based Indicators of Vulnerability Re-Introducing Code Changes: An Exploratory Case Study", "authors": "Samiha Shimmi,Nicholas M. Synovic,Mona Rahimi,George K. Thiruvathukal", "background": "软件漏洞往往在修复后仍然存在或重新出现，揭示了代码演变与社会技术因素的复杂互动。虽然源代码度量提供了有用的漏洞指标，软件工程过程度量可以揭示导致其引入的模式。然而，很少有研究探索过程度量是否可以揭示随着时间推移的风险开发活动，这些活动对于预测和减轻软件漏洞是必不可少的。本文强调了过程度量与代码更改在理解和减轻漏洞重新引入中的关键作用。我们不仅关注单个修复是否引入了漏洞，还关注漏洞演变和重新出现的更长序列的变化。我们的方法强调，重新引入通常是由于一系列孤立的行动累积起来的结果，反映了短期问题管理效率低下和团队响应性的问题。为了支持这项分析，我们对ImageMagick项目进行了案例研究，将过程度量（如人月费、问题密度和问题过时度）与漏洞重新引入活动相关联，共涉及76次重新引入的漏洞实例。研究表明，重新引入通常与问题管理效率低下和问题密度波动有关，反映了短期问题管理效率低下和团队响应性的问题。这些观察为将过程度量与代码度量相结合进行更广泛的研究奠定了基础，以便预测风险修复并加强软件安全。", "innovation": "本文提出了一个新的视角，即通过分析软件工程过程度量来理解并缓解代码变更后软件漏洞的重新引入。这种分析超越了文件级别的预测，关注于在更长的代码变更序列中考察漏洞是如何演变和重新出现的。该研究强调了过程度量和代码变更在识别和缓解重构风险方面的关键作用。通过案例研究，将多种过程度量与漏洞重新引入的具体活动相结合，提供了关于团队管理和问题管理效率低下对漏洞重新引入影响的直接证据。", "conclusion": "本文的发现展示了通过结合过程度量和代码度量来预测潜在风险修复并加强软件安全性的重要性。未来的研究可以进一步整合这些方法，以更准确地评估不同软件项目中代码变更后的漏洞重新引入风险。同时，本文揭示了在开发过程中需要重点关注的一些关键指标和条件，对于提升软件安全保障具有重要意义。"}
{"llm_update_time": "20251101", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2510.26634", "html_url": "https://arxiv.org/abs/2510.26634", "title": "Stitch: Step-by-step LLM Guided Tutoring for Scratch", "title_en": "Stitch: Step-by-step LLM Guided Tutoring for Scratch", "authors": "Yuan Si,Kyle Qi,Daming Li,Hanyuan Shi,Jialu Zhang", "background": "积木块环境，如Scratch，在编程教育中越来越受欢迎。尽管积木语法减少了表面错误，但语义错误仍然很常见，对于初学者来说很难解决。现存的调试流程通常直接向学习者展示正确的程序，这种方法虽然可能解决错误，但却削弱了问题解决技能的培养。现有的调试流程通常是机械地展示正确答案，忽视了逐步指导的重要性。", "innovation": "Stitch引入了一种互动式辅导系统，使用逐步引导的方法代替直接展示答案。其Diff-Analyze模块对比了学生的项目和参考实现，识别出最关键的差异，并使用大型语言模型来解释这些更改的原因。学习者通过自定义渲染引擎检查高亮的积木块，理解解释，并有选择地应用部分修复。这个迭代过程将持续进行，直到实现预期的功能。Stitch通过对比实证研究，展示了逐步指导相比直接展示正确答案的方法更加有效的学习体验。", "conclusion": "Stitch的研究表明，逐步引导式辅导显著提高了学习效果，超越了传统直接教学的方法和现有的自动化反馈生成工具。进一步探讨了积木式编程中有效反馈的最佳实践仍然存在争议，但逐步指导系统提供了强有力的支持，证明了其在编程教育中的有效性。"}
{"llm_update_time": "20251101", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2407.18760", "html_url": "https://arxiv.org/abs/2407.18760", "title": "Maven-Hijack: 软件供应链攻击利用包依赖顺序", "title_en": "Maven-Hijack: Software Supply Chain Attack Exploiting Packaging Order", "authors": "Frank Reyes,Federico Bono,Aman Sharma,Benoit Baudry,Martin Monperrus", "background": "Java项目经常依赖于Maven等包管理器来管理复杂的外部依赖网。虽然这些工具简化了开发流程，但也引入了对软件供应链的潜在风险。攻击者可以利用包依赖和类运行时解析的顺序，通过将恶意类注入提前打包的依赖中，来无声地覆盖核心应用行为。这需要开发更好的供应链保护措施来防止此类隐蔽攻击，尤其是针对Java的构建和依赖管理过程.", "innovation": "研究提出了一个新的攻击形式——Maven-Hijack。该攻击利用了Maven解析依赖的顺序和Java虚拟机在运行时解析类的方式。通过将恶意类注入到一个先打包的依赖中，攻击者可以在不修改主代码库或库名称的情况下覆盖核心应用行为。该研究还评估了三种缓解策略，并发现Maven Enforcer插件与重复类检测提供了当前Java项目中最实用有效的防御方式.", "conclusion": "本文的研究结果表明，尽管Java模块提供了较强的安全防护，但Maven Enforcer插件结合重复类检测提供了最实用且有效的防御措施，以抵御当前Java项目的供应链攻击。研究强调了在Java的构建和依赖管理过程中需要增强保护措施以防止隐蔽供应链攻击的迫切性。"}
