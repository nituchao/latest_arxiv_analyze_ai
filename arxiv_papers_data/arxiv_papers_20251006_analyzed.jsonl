{"llm_update_time": "20251006", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.02418", "html_url": "https://arxiv.org/abs/2510.02418", "title": "BrowserArena：在实际网页导航任务中评估LLM代理", "title_en": "BrowserArena: Evaluating LLM Agents on Real-World Web Navigation Tasks", "authors": "Sagnik Anupam,Davis Brown,Shuo Li,Eric Wong,Hamed Hassani,Osbert Bastani", "background": "现有的LLM代理能够浏览和执行开放网络上的操作，但目前的评估主要局限于沙箱环境或人工任务。因此，需要一种新的评估平台，用于真实世界的网页导航任务。", "innovation": "BrowserArena是一个在线开放网页代理评估平台，它收集用户提交的任务，以Arena风格进行一对一竞争，并通过逐步骤的人工反馈揭示代理的失败模式。此外，通过构建有针对性的数据集研究这些问题，发现不同语言模型在解决具体任务时的不同策略差异。", "conclusion": "BrowserArena揭示了当前网络代理的多样性和脆弱性。此外，该基准测试的方法学为大规模评估和理解网络代理的失败模式提供了一种方法。"}
{"llm_update_time": "20251006", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.02423", "html_url": "https://arxiv.org/abs/2510.02423", "title": "RefineShot: 使用基础技能评估重新思考影像理解", "title_en": "RefineShot: Rethinking Cinematography Understanding with Foundational Skill Evaluation", "authors": "Hang Wu,Yujun Cai,Haonan Ge,Hongkai Chen,Ming-Hsuan Yang,Yiwei Wang", "background": "影像理解涉及识别场景的视觉内容以及构成叙事意义的电影技术。随着其在现实世界应用中的多模态理解增强以及在电影和媒体中的内容创建中的核心地位逐渐凸显，这一能力越来越受到关注。作为该任务最全面的基准-shotBench，覆盖广泛影视概念，并以ShotVL为基准实现了最先进的结果。然而，我们分析发现，shotBench中的模糊选项设计以及ShotVL在推理一致性与指令遵从性上的不足，使评估可靠性受到削弱，导致难以进行公平比较并阻碍了未来进步。", "innovation": "为了克服这些问题，我们系统地完善了shotBench，通过一致的选项重结构化开展了第一个关于ShotVL推理行为的关键分析，并引入了新的评价协议，同时评估任务准确性和核心模型能力。这些努力带来了RefineShot，这是一个改进并扩展的基准，使评估更加可靠，并促进了未来在影像理解方面的进步。", "conclusion": "RefineShot 是一个增强了可靠评估并促进未来影像理解发展的精炼且扩展的基准。"}
{"llm_update_time": "20251006", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.02528", "html_url": "https://arxiv.org/abs/2510.02528", "title": "多模态功能向量用于空间关系", "title_en": "Multimodal Function Vectors for Spatial Relations", "authors": "Shuhao Fu,Esther Goldberg,Ying Nian Wu,Hongjing Lu", "background": "大型多模态模型（LMMs）展现出通过有限的多模态演示学习上下文能力，但其内部机制仍然不透明。本研究基于大语言模型的相关工作，探索了OpenFlamingo-4B这一视觉-语言模型中一小部分注意力头负责传递空间关系表示，并利用因果中介分析识别出对关系预测有强烈影响的注意力头。", "innovation": "研究通过合成和真实图像数据集应用因果中介分析，识别出对关系预测有强烈影响的注意力头，提取改善零样本推理准确性的多模态功能向量。这些功能向量在保持LMM参数冻结的情况下，可以通过有限的数据进行微调，并显著优于上下文学习基线。此外，特定的关系功能向量可以通过线性组合解决涉及未训练空间关系的新颖类比问题，显示了本方法的强大泛化能力。", "conclusion": "研究结果表明，LMMs在其内部结构中编码空间关系知识，并且可以系统地提取和优化，从而深化我们对模型模块性的理解，增强对关系推理的控制。"}
{"llm_update_time": "20251006", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.02557", "html_url": "https://arxiv.org/abs/2510.02557", "title": "协调人-人工智能团队：经理代理作为一个统一的研究挑战", "title_en": "Orchestrating Human-AI Teams: The Manager Agent as a Unifying Research Challenge", "authors": "Charlie Masters,Advaith Vellanki,Jiangbo Shangguan,Bart Kultys,Jonathan Gilmore,Alastair Moore,Stefano V. Albrecht", "background": "虽然代理型人工智能已经在自动化个体任务方面取得了进展，但管理复杂的多代理工作流仍是一个难题。本文背景在于探讨如何自主管理协调动态的人工智能和人类团队的合作。", "innovation": "本文提出了自主经理代理的概念，这是一种核心挑战，它能分解复杂目标为任务图、分配任务给人类和人工智能工作者、监控进度、适应变化条件，并保持透明的利益相关者沟通。引入Partially Observable Stochastic Game (POSG) 格式化工作流管理，并识别了四个基础挑战：层级分解的组合推理、多目标优化在变化偏好下、临时团队中的协调与规划、以及设计中的治理与合规。", "conclusion": "通过评估基于GPT-5的经理代理在20个工作流中，发现这些代理在共同优化目标完成、约束遵守和工作流运行时间方面存在困难，这表明工作流管理仍然是一个开放的难题。最后讨论了自主管理系统的组织和伦理影响。"}
{"llm_update_time": "20251006", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.02480", "html_url": "https://arxiv.org/abs/2510.02480", "title": "通过风险控制实现安全高效的上下文学习", "title_en": "Safe and Efficient In-Context Learning via Risk Control", "authors": "Andrea Wynn,Metod Jazbec,Charith Peris,Rinat Khaziev,Anqi Liu,Daniel Khashabi,Eric Nalisnick", "background": "大型语言模型（LLMs）能够从少量上下文示例中学习新任务，展现出显著的能力。然而，这种灵活性带来了安全问题：LLMs 可能会受到错误或恶意示例的影响——例如，如果攻击者篡改或注入有害示例，而没有被监督者注意到。这促使我们设计出包含内置机制的系统，以抵御此类攻击。该研究旨在通过风险控制来限制有害示例对模型性能的影响。", "innovation": "提出了一个新的风险控制方法，以限制有害示例对模型性能的负面影响。该方法首先定义了一个基线“安全”行为模型——即模型在没有上下文示例（零样本的情况）下的表现。然后使用无分布风险控制（DFRC）来控制上下文样本带来的性能下降程度，通过动态早期退出预测和忽略最关注不安全输入的后继注意力头来实现。最后，引入了DFRC的修改方案，既能控制有害输入的风险，又能利用有益输入的性能和效率提升。", "conclusion": "研究展示了这种方法能够在控制有害上下文示例风险的同时，实现显著的计算效率提升，同时取得了理论和实验证据的支持。"}
{"llm_update_time": "20251006", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.02611", "html_url": "https://arxiv.org/abs/2510.02611", "title": "关于温度采样在测试时缩放中的作用", "title_en": "On the Role of Temperature Sampling in Test-Time Scaling", "authors": "Yuheng Wu,Azalia Mirhoseini,Thierry Tambe", "background": "大型语言模型（LLMs）可以在推理阶段通过测试时缩放（TTS）来提升推理能力，即生成多个推理路径并选择最优路径。先前的研究表明增加采样数量K能够逐步提升精度。然而，这项研究显示该趋势并非无限扩展：当K值较大时，进一步缩放不会带来额外收益，并且某些难题即使在多种情况下也无法解决。研究发现，不同的采样温度可以解决不同类型的问题，单温度缩放仅探索了模型潜力的一小部分。", "innovation": "研究提出了温度维度上的缩放方法，通过改变温度来扩展LLMs的推理边界。这种方法在Qwen3（0.6B, 1.7B, 4B, 8B）和五个代表性推理基准（AIME 2024/2025, MATH500, LiveCodeBench, Hi-ToM）中，相比于单一温度TTS，在平均情况下提高了7.3个点的性能，并使基础模型能够达到与强化学习（RL）训练模型相当的性能，且无需额外的后训练。研究还提供了一种综合性分析，并设计了一个多温度投票方法来减少温度缩放的开销。", "conclusion": "我们的研究结果表明，TTS比以前认为的更加强大，温度维度的缩放提供了一种简单有效的方法来解锁基础模型的潜在能力。"}
{"llm_update_time": "20251006", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.02655", "html_url": "https://arxiv.org/abs/2510.02655", "title": "一种用于实际事件的可能性概念", "title_en": "A Concept of Possibility for Real-World Events", "authors": "Daniel G. Schwartz", "background": "本文提出了一种全新的可能性概念，作为对现有标准概念的替代。该概念最初由L.A. Zadeh在1978年提出，旨在提供一个现实世界的事件可能性的新视角。新版本受到原始概念的启发，但在形式上没有任何共同之处，除了两者都采用了Łukasiewicz多元解释逻辑连接词。", "innovation": "论文提出了一种新的可能性概念，该概念专为现实世界的事件设计，考虑了事件的发生需要前提条件和可能的限制条件。可能性的计算是通过前提条件的实现概率和限制条件的阻碍概率来函数化实现的。这种方法特别适用于规划问题，尤其是在有多种计划可选的情况下，能够确定哪种计划最有可能成功。", "conclusion": "论文推测，这种推理模型能够准确捕捉通常的人类关于计划的推理过程。并通过一个交通路线规划的示例来详细阐述该理论，展示了其在实际应用中的潜力。此外，还提出该理论可能在未来有更广泛的应用。"}
{"llm_update_time": "20251006", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.02589", "html_url": "https://arxiv.org/abs/2510.02589", "title": "深层强化学习算法在集装箱堆存计划问题中的基准研究", "title_en": "A Benchmark Study of Deep Reinforcement Learning Algorithms for the Container Stowage Planning Problem", "authors": "Yunqi Huang,Nishith Chennakeshava,Alexis Carras,Vladislav Neverov,Wei Liu,Aske Plaat,Yingjie Fan", "background": "集装箱堆存规划（CSPP）是海运运输和终端运营的关键组成部分，直接影响供应链效率。由于其复杂性，CSPP 通常依赖于人工经验。近年来，虽然已将强化学习（RL）应用于 CSPP，但不同算法的整体基准比较仍存在局限性。", "innovation": "开发了一个 Gym 环境，捕捉 CSPP 的基本特性，并扩展为包括起重机调度的多代理和单代理模型。在此框架下，评估了五种强化学习算法（DQN、QR-DQN、A2C、PPO 和 TRPO）在多种复杂程度不同的场景下的表现。结果表明，随着复杂性的增加，算法性能存在显著差异，强调了算法选择和问题形式化对于 CSPP 的重要性。", "conclusion": "该论文为 CSPP 基准了多种 RL 方法，并提供了一个包含起重机调度的可重用 Gym 环境，为未来的研究和海运物流的实际部署奠定了基础。"}
{"llm_update_time": "20251006", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.02816", "html_url": "https://arxiv.org/abs/2510.02816", "title": "NCV：一种低成本结构化错误定位的节点级一致性验证方法", "title_en": "NCV: A Node-Wise Consistency Verification Approach for Low-Cost Structured Error Localization in LLM Reasoning", "authors": "Yulong Zhang,Li Wang,Wei Du,Peilin Li,Yuqin Dai Zhiyuan Zhao,Lingyong Fang,Ziniu Liu,Ru Zhang,Huijia Zhu,Gongshen Liu", "background": "在大型语言模型中验证多步推理非常困难，因为错误定位不精确且需要大量的令牌成本。现有方法要么评估整个推理链，导致注意力稀释，要么依赖昂贵的多采样。现有的验证方法在大规模语言模型推理验证方面存在局限性。", "innovation": "论文提出了一种无需训练的节点级一致性验证（Node-wise Consistency Verification，NCV）框架，将验证重新定义为在节点级别进行的轻量级二元一致性检查。通过将推理链分解为相互连接的验证节点，NCV可以精确定位错误，避免不必要的长段生成。该方法增强了模型的可解释性和效率，提供了一种可扩展的解决方案，可以在保持较低令牌成本的同时提高大规模语言模型推理验证的可靠性。", "conclusion": "实验证明，NCV在公共数据集上优于基线方法，F1分数提高了10%到25%，且使用的令牌数量比传统方法如基于CoT的验证器少6倍至58倍。"}
{"llm_update_time": "20251006", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.02608", "html_url": "https://arxiv.org/abs/2510.02608", "title": "缓解多模态推理中的模态失衡", "title_en": "Mitigating Modal Imbalance in Multimodal Reasoning", "authors": "Chen Henry Wu,Neil Kale,Aditi Raghunathan", "background": "论文背景了在实际应用中部署的基础模型（FMs）需要整合多种模态的数据。我们需要了解FMs在处理跨模态冲突的能力，即当不同模态相互作用并形成跨模态背景时，它们能否同时推理并解决冲突，而不是优先处理某一模态。通过实验，研究者发现单模态情境中FMs能够识别冲突90%的情况下，当证据分散在不同模态时，这一比例下降到3%，类似的现象也在跨语言上下文中（包含多种语言）出现。作者还观察到FMs在跨模态注意力分配上存在偏斜问题。", "innovation": "研究发现缓解跨模态注意力失衡的有效方法，即通过在每例训练数据中显式地结合多个模态，可以显著减少跨模态注意力的失衡，并且这种改进直接转化为多个视觉-语言基准测试下游任务性能的提升。这种方法既简单又易于扩展。作者指出，仅有规模更大的多模态或跨语言数据集并不能解决跨模态推理问题，因为这些数据缺乏明确需要跨模态推理的训练示例。", "conclusion": "论文的研究结果强调了系统性处理跨模态环境对于构建可靠的基础模型的重要性。通过减少跨模态注意力的失衡，提高模型对跨模态数据的理解和处理能力是提升下游任务性能的关键。"}
{"llm_update_time": "20251006", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.02653", "html_url": "https://arxiv.org/abs/2510.02653", "title": "Geolog-IA：为学术论文设计的对话系统", "title_en": "Geolog-IA: Conversational System for Academic Theses", "authors": "Micaela Fuel Pozo,Andrea Guatumillo Saltos,Yeseña Tipan Llumiquinga,Kelly Lascano Aguirre,Marilyn Castillo Jara,Christian Mejia-Escobar", "background": "本文介绍了基于人工智能技术的Geolog-IA新型对话系统，该系统能自然地回答来自厄瓜多尔中央大学的地质学论文相关问题。该系统通过使用Llama 3.1和Gemini 2.5语言模型，结合Retrieval Augmented Generation (RAG)架构和SQLite数据库，解决了诸如幻觉和过时知识等问题，提高了系统的性能和准确性。", "innovation": "Geolog-IA系统采用Llama 3.1和Gemini 2.5语言模型，并结合RAG架构和SQLite数据库，提高了系统的性能和准确性，解决了幻觉和过时知识等问题。通过BLEU评价指标，Geolog-IA系统的性能评分为0.87，显示了其高效和准确的响应能力。系统还提供了一个直观的基于Web的界面，便于各方向、教师、学生和行政人员获取信息。", "conclusion": "Geolog-IA作为一种重要的教育、培训和研究支持工具，为学术论文提供了关键支持，并为进一步在其他学科中的应用奠定了基础。"}
{"llm_update_time": "20251006", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.02592", "html_url": "https://arxiv.org/abs/2510.02592", "title": "基于多模态大型语言模型的用于安全可解释的网联电动车框架", "title_en": "Multimodal Large Language Model Framework for Safe and Interpretable Grid-Integrated EVs", "authors": "Jean Douglas Carvalho,Hugo Kenji,Ahmad Mohammad Saber,Glaucia Melo,Max Mauro Dias Santos,Deepa Kundur", "background": "电动车（EVs）集成到智能电网中为交通运输系统和能源网络的提升提供了独特的机遇。然而，确保驾驶员、车辆及其周围环境之间的安全和可解释的互动仍然是一个关键挑战。为此，本论文提出了一种多模态大型语言模型（LLM）为基础的框架，旨在处理多模态传感器数据，如目标检测、语义分割和车辆遥测，并生成针对驾驶员的自然语言警报。该框架使用实际数据验证其在城市道路驾驶场景中的应用，结合视觉感知（YOLOv8）、地理编码定位和CAN总线遥测，将原始传感器数据与驾驶员理解有效联系起来，从而在城市驾驶情景中实现更安全和明智的决策。实证案例研究显示该框架在生成针对关键情况的上下文感知警报方面具有有效性，例如行人、自行车手和其他车辆的接近情况.", "innovation": "本论文提出了一种多模态大型语言模型为基础的框架，能够处理多模态传感器数据，并生成自然语言警报。该框架结合了视觉感知（YOLOv8）、地理编码定位和CAN总线遥测，旨在实现原始传感器数据与驾驶员理解的关联，从而更安全地做出决策。通过这种方式，该框架可以支持标准化车辆群组调度、电动车负载预测及交通感知能源规划等应用。值得注意的是，该模型还展示了L大型语言模型在电动机动态中的辅助工具潜力，提升了交通运输系统和电动汽车网络的效率和适用性.", "conclusion": "实验结果表明该框架在生成针对关键情况的上下文感知警报方面非常有效，从而提高了城市驾驶的安全性。该框架的潜力在于利用大型语言模型作为辅助工具来促进电动车辆的集成，增强交通系统和电力网络的安全性和智能化，为技术推广应用提供了有力支持。"}
{"llm_update_time": "20251006", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.02850", "html_url": "https://arxiv.org/abs/2510.02850", "title": "奖励模型路由在对齐中的应用", "title_en": "Reward Model Routing in Alignment", "authors": "Xinle Wu,Yao Lu", "background": "强化学习从人类或AI反馈（RLHF/RLAIF）已成为大规模语言模型（LLMs）对齐的标准范式。然而，大多数流程依赖单一奖励模型（RM），影响对齐质量并存在过拟合风险。最近的研究探索了从候选池中动态选择RM的方法，以利用互补优势同时保持线性RM调用（$O(1)$）的开销，但现有方法在冷启动和探索不足方面存在问题。", "innovation": "提出了一种集成了离线RM优势学习和在线贝叶斯选择的混合路由框架——BayesianRouter。在离线阶段，多任务路由器在偏好数据上进行训练以估计每个RM的可靠性。在线阶段，贝叶斯采样路由器执行查询级别的RM选择，以离线嵌入作为高斯先验和在线奖励自适应地更新后验，以适应不断变化的策略分布。", "conclusion": "广泛实验表明，BayesianRouter在指令遵循、推理等基准测试中均优于单一RM、RM集成和现有路由方法。"}
{"llm_update_time": "20251006", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.02669", "html_url": "https://arxiv.org/abs/2510.02669", "title": "AutoMaAS: Self-Evolving Multi-Agent Architecture Search for Large Language Models", "title_en": "AutoMaAS: Self-Evolving Multi-Agent Architecture Search for Large Language Models", "authors": "Bo Ma,Hang Li,ZeHua Hu,XiaoFan Gui,LuYao Liu,Simon Liu", "background": "多智能体系统由大型语言模型驱动，已经在多个领域展示了卓越的能力。然而，现有的自动化设计方法追求的是单一的整体解决方案，这些方案无法根据查询复杂度和领域需求灵活调整资源分配。这项研究针对现存的局限性，提出了一个名为AutoMaAS的自我进化的多智能体体系结构搜索框架，该框架利用神经架构搜索的原则，通过动态操作生命周期管理和自动化机器学习技术，自动发现最优智能体配置。", "innovation": "AutoMaAS框架包含四个关键创新点：(1) 基于性能与成本分析的自动操作生成、融合与消除；(2) 动态的成本感知优化，实现实时参数调整；(3) 在线反馈集成，以持续改进架构；(4) 通过决策追踪机制增强的可解释性。", "conclusion": "在六个基准测试中的广泛实验表明，AutoMaAS实现了1.0%-7.1%的性能提升，并将推理成本降低了3%-5%。该框架展示了在不同数据集和LLM基础架构之间具有超越性的转移能力，为大型语言模型时代的自动化多智能体系统设计设立了一个新的范式。"}
{"llm_update_time": "20251006", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.02567", "html_url": "https://arxiv.org/abs/2510.02567", "title": "智能代理赋能的增材制造合金发现", "title_en": "Agentic Additive Manufacturing Alloy Discovery", "authors": "Peter Pak,Achuth Chandrasekhar,Amir Barati Farimani", "background": "在增材制造（AM）领域，合金的发现仍然是一项复杂的挑战，通常需要在材料科学、热力学模拟和实验分析等多个领域具备深厚的专长。为了克服这一挑战，本研究利用大型语言模型（LLM）赋能的智能代理，这些智能代理能够根据模型上下文协议（MCP）调度各种工具来执行操作，如Thermo-Calc性质图计算和未融合过程图生成。此外，本研究开发的多智能体系统能够有效处理复杂的用户指令，并对所提议的合金的可打印性提供分析。", "innovation": "本研究提出了一种基于LLM的智能代理系统，能够自动化和加速增材制造中合金的发现过程。该系统通过使用模型上下文协议（MCP）调度工具来实现自动执行任务，并能够根据工具调用结果动态调整任务轨迹，实现自主决策。", "conclusion": "本研究利用LLM赋能的智能代理，展示了在增材制造领域采用这一多智能体系统所带来的好处，加快了合金发现的过程，提高了研究效率和解决问题的能力。"}
{"llm_update_time": "20251006", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.02837", "html_url": "https://arxiv.org/abs/2510.02837", "title": "超越最终答案：工具增强型代理推理轨迹评估", "title_en": "Beyond the Final Answer: Evaluating the Reasoning Trajectories of Tool-Augmented Agents", "authors": "Wonjoong Kim,Sangwu Park,Yeonjun In,Sein Kim,Dongha Lee,Chanyoung Park", "background": "尽管近期的工具增强型基准测试涵盖了复杂的用户请求和多种工具，大多数评估方法仍限于答案匹配。然而，随着解决用户请求所需步骤的增加，评估代理性能不应仅限于最终答案，还应评估问题解决路径，包括效率、幻觉和适应性等方面。而直接对比代理和真实路径的简单方法由于标记所有有效真实路径的成本高昂而受到限制，简单的基于LLM的评估者在没有真值的情况下难以详细评估推理轨迹。", "innovation": "提出了TRACE框架，这是一种用于工具增强型LLM代理性能多维度评估的框架。通过引入证据库，收集先前推理步骤中的知识，TRACE使得对代理推理轨迹进行多面分析和评估成为可能。通过开发一个新的、包含多样化和有缺陷的推理轨迹的元评估数据集对框架进行了验证，这种方法可以使用开源的小型LLM以高效且经济的方式评估这些复杂行为。", "conclusion": "实验结果表明，TRACE能够准确地以可扩展且成本效益高的方式评估这些复杂的搜索轨迹行为。此外，还应用了此方法来评估解决工具增强型任务时生成的代理推理路径，并提供了未报告的洞察。"}
{"llm_update_time": "20251006", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.02679", "html_url": "https://arxiv.org/abs/2510.02679", "title": "使用特定领域表示调节生成模型实现作业调度中的约束自动生成", "title_en": "Automated Constraint Specification for Job Scheduling by Regulating Generative Model with Domain-Specific Representation", "authors": "Yu-Zhe Shi,Qiao Xu,Yanjia Li,Mingchen Liu,Huamin Qu,Lecheng Ruan,Qining Wang", "background": "高级计划与调度（APS）系统已经成为现代制造运营不可或缺的部分，能够优化资源配置和生产效率，在日益复杂和动态的环境中提供支持。尽管已有算法解决抽象调度问题的研究，但将制造要求转化为正式约束的传统方法仍需手动操作，耗费大量人工。虽然近期生成模型，特别是大型语言模型（LLMs），在从异构原始制造数据中自动化约束规范方面表现出潜力，但其直接应用存在的挑战包括自然语言歧义、非确定性输出和有限的专业知识领域。", "innovation": "本文提出了一种以约束为中心的架构，通过特定领域的表示来调节大型语言模型，实现生产调度中的可靠自动化约束规范。该架构定义了一个分层结构空间，针对特定制造配置设计并部署了自动生产场景适应算法，以提高定制化水平。", "conclusion": "实验结果表明，所提出的方法成功地平衡了大型语言模型的生成能力与制造系统的可靠性需求，在约束规范任务中显著优于基于大型语言模型的方法。"}
{"llm_update_time": "20251006", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.02840", "html_url": "https://arxiv.org/abs/2510.02840", "title": "认真对待戈德哈特法则：通用人工智能优化的原理性限制", "title_en": "Take Goodhart Seriously: Principled Limit on General-Purpose AI Optimization", "authors": "Antoine Maier,Aude Maier,Tom David", "background": "在机器学习中，通常假设训练后的模型能够满足其指定的目标函数，但这种“目标满足假设”（OSA）往往被忽视。尽管有人认识到罢了OSA的偏差，但对这些偏差的潜在影响却常常被忽视。文章指出，在任何学习范式中，由于近似、估计和优化错误的存在，OSA在现实条件下往往无法实现。此外，准确捕捉并形式化转化为算法目标的过程在实际中也是不可能的，这导致了OSA的必然偏差。这些缺口在强烈优化压力下容易演化为戈德哈特法则的失效模式。因此，预先定位失效点的难度较大，对通用人工智能系统优化的客观限制是必要的，否则继续优化可能导致系统失控。", "innovation": "文章提出了一个学习范式无关的框架，对目标满足假设OSA的失效进行了理论分析，并且指出这种偏差在现实条件下的普遍存在性。更重要的是，文章将这种偏差与戈德哈特法则的失效模式进行了联系，并强调了对普遍人工智能优化进行客观限制的重要性，而这种限制是由于错误的优化可能导致系统失去控制而提出的。", "conclusion": "文章认为，在布置强度优化时遇到新问题是不可避免的，因此，确立一个对普遍人工智能优化的最大限度是有必要的，以防止系统滥用并失去控制。这种限制应该基于现有的数学结果，并且考虑到现实条件下的技术限制，以确保人工智能系统在优化过程中的可控性。"}
{"llm_update_time": "20251006", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.02677", "html_url": "https://arxiv.org/abs/2510.02677", "title": "ARMs: 自适应对抗测试代理针对插件即用型攻击的多模态模型", "title_en": "ARMs: Adaptive Red-Teaming Agent against Multimodal Models with Plug-and-Play Attacks", "authors": "Zhaorun Chen,Xun Liu,Mintong Kang,Jiawei Zhang,Minzhou Pan,Shuang Yang,Bo Li", "background": "随着视觉语言模型（VLMs）的重要性日益增加，它们的多模态界面也引入了新的安全漏洞，这使得安全评估变得更加复杂和关键。现有的红队测试方法要么仅限于狭窄的攻击模式，要么依赖于手动工程，缺乏对新兴实际世界VLM漏洞的大规模探索。", "innovation": "本文提出了ARMs，一种自适应的红队测试代理，系统地对VLMs进行全面的风险评估。ARMs自动优化多种增强推理的多步骤编排的红队策略，以有效诱发目标VLM的有害输出。文中提出了11种新型的多模态攻击策略，涵盖了VLM的多种对抗模式（例如，推理劫持、背景隐形）。此外，ARMs通过模型上下文协议（MCP）集成了17种红队算法，设计了一种分层记忆加ε-贪婪攻击探索算法以平衡攻击的多样性和有效性。广泛的实验表明，ARMs在各项指标上均超越了基线方法，平均高出52.1%，在Claude-4-Sonnet上的表现更是超过90%。设计了包含超过30K种红队测试实例的大规模多模态安全数据集ARMS-Bench，涵盖了51种不同的风险类别，并根据实际的多模态威胁和监管风险构建。使用ARMS-Bench进行安全性微调显著提高了VLMs的鲁棒性，同时保留了其一般用途，为提升多模态安全对新兴威胁进行对齐提供了可操作的指导。", "conclusion": "ARMs表现优异，能够广泛探测VLMs的安全漏洞，提出更加全面多样的红队测试实例，构建了一个大规模的多模态安全数据集ARMS-Bench，为提高多模态模型的安全对齐提供了重要的技术支持和数据基础。"}
{"llm_update_time": "20251006", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.03078", "html_url": "https://arxiv.org/abs/2510.03078", "title": "从事实到反事实：为智能环境设计和评估反事实解释", "title_en": "From Facts to Foils: Designing and Evaluating Counterfactual Explanations for Smart Environments", "authors": "Anna Trapp,Mersedeh Sadeghi,Andreas Vogelsang", "background": "越来越多地认为可解释性是规则为基础的智能环境中的关键特性。反事实解释，描述为了实现预期结果而应该采取的不同措施，是可解释AI (XAI) 的强有力工具，但目前在规则为基础的领域中未有现成的方法生成这样的解释。该论文探讨了在智能环境中设计和评估反事实解释的方法，弥补了现有研究的空白。", "innovation": "该研究首次提出了适合规则为基础的领域中生成反事实解释的形式化方法和实施，将其作为可扩展现有智能环境解释引擎的插件进行实现。通过一项包括17名参与者的用户研究，评估了生成的反事实解释相对于传统的因果解释的表现。研究表明，用户的偏好具有情境相关性：在语言简洁且时间紧迫的情况下偏好因果解释，而在需要实际行动信息解决具体问题时，则偏好反事实解释。该研究贡献了一个在智能环境中实现新类型解释的实用性框架，并提供了指导选择每种解释类型的条件的实证证据。", "conclusion": "该研究为智能环境提供了新的解释类型，并通过实证研究提供了指导选择每种类型解释条件的有效性依据。"}
{"llm_update_time": "20251006", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.02880", "html_url": "https://arxiv.org/abs/2510.02880", "title": "加固多模态离散扩散模型中的强化学习", "title_en": "Consolidating Reinforcement Learning for Multimodal Discrete Diffusion Models", "authors": "Tianren Ma,Mu Zhang,Yibing Wang,Qixiang Ye", "background": "优化离散扩散模型（DDM）与奖励相结合的问题仍然具有挑战性：非自回归范式使得重要性采样不可行且策略展开变得复杂，困扰了诸如组相对策略优化（GRPO）这样的强化学习方法。现有的方法在弥合离散扩散模型中的重要性估计漏洞方面遇到了困难，这妨碍了高效且模态特定的策略优化的方法实现。", "innovation": "本文引入了MaskGRPO，它是一种首个可扩展的多模态强化学习方法，特别适用于离散扩散模型，并结合了有效的重要性采样和模态特定的适应性。团队首先为DDMs建立了理论基础，以构建能够捕捉对梯度更新有价值的标记波动的重要性估计器。然后，他们针对视觉序列精心设计了策略展开方法，从而确保了多样的完成和可靠的优化梯度。通过数学推理、编码和视觉生成基准测试，验证了MaskGRPO的有效性和稳定性，增强了推理性能并改善了生成质量。", "conclusion": "这项研究确立了MaskGRPO作为系统性策略优化方法的地位，并首次提供了一种实用的方法来实现离散视觉扩散过程中的策略优化。"}
{"llm_update_time": "20251006", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.02996", "html_url": "https://arxiv.org/abs/2510.02996", "title": "AI解释的本体论与认识论分析", "title_en": "Onto-Epistemological Analysis of AI Explanations", "authors": "Martina Mattioli,Eike Petersen,Aasa Feragen,Marcello Pelillo,Siavash A. Bigdeli", "background": "人工智能（AI）正在几乎每一个领域得到应用，然而当前主导的深度学习方法本质上是黑箱系统，缺乏对其推断的解释，这极大限制了其可信度和采用率。解释性人工智能（XAI）旨在通过提供模型决策过程的解释来克服这一挑战。尽管XAI方法通常由具有技术背景的工程师和科学家提出和发展，但关于解释的具体概念，即解释是什么、我们能否知道它、它是绝对的还是相对的等问题，远未形成共识且历史悠久，这些基本概念的问题对不同领域的AI解释的有效性和解释具有重要影响。因此，不同的XAI方法假设会导致在选择特定的XAI方法应用于不同领域时存在的风险。本研究旨在分析XAI方法在应用于AI系统时所包含的本体论和认识论假设，揭示技术细节如何反映潜在的假设差异，并强调在选择适合的具体领域时考虑本体论和认识论框架的重要性。", "innovation": "本研究的一个创新点在于对XAI方法所依赖的基础理论——本体论和认识论等方面的深入分析，揭示了技术细节背后所蕴含的哲学假设的区别，并强调了在应用XAI方法时考虑这些基础理论的重要性。研究展示了看似细微的技术变化可能对应着对解释假设的重要影响，从而帮助理解和评估不同XAI方法在不同应用场景中的适用性。", "conclusion": "本研究通过分析XAI方法应用于AI系统时的本体论和认识论假设，强调了选择和适应不同领域合适的XAI方法时需要全面考虑基础理论的重要性。研究结果提示，在选择XAI方法时必须考虑了解释的哲学背景及其对不同领域的适用性，以确保AI系统的可靠性和可解释性。"}
{"llm_update_time": "20251006", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.03153", "html_url": "https://arxiv.org/abs/2510.03153", "title": "改进协作型增强现实AI的合作", "title_en": "Improving Cooperation in Collaborative Embodied AI", "authors": "Hima Jacob Leven Suprabha,Laxmi Nag Laxminarayan Nagesh,Ajith Nair,Alvin Reuben Amal Selvaster,Ayan Khan,Raghuram Damarla,Sanju Hannah Samuel,Sreenithi Saravana Perumal,Titouan Puech,Venkataramireddy Marella,Vishal Sonar,Alessandro Suglia,Oliver Lemon", "background": "大型语言模型（LLMs）与多智能体系统的集成为与AI智能体协作的推理和合作开辟了新的可能性。在此背景下，该研究探讨了不同的提示方法，并评估了它们在增强智能体协作行为和决策制定方面的有效性。研究在CoELA框架的基础上，进一步增强了协作体智能代理，即利用LLMs促进多智能体在共享虚拟空间中的交流、推理和任务协调。", "innovation": "研究通过系统性的实验，系统地测试了不同LLMs与提示工程策略，以确定最优化的组合来最大化协作表现。此外，研究还将语音功能集成进来，使协作性的语音交互能够更加流畅。研究发现，提示优化对提高协作型智能体表现非常有效；例如，最佳组合使得使用Gemma3的系统性能提升了22%，相比原来的CoELA系统更为高效。语音集成还提供了一个更具吸引力的用户界面，有助于迭代系统开发和演示的进行.", "conclusion": "研究结果强调了提示优化在提升协作智能体性能方面的效果，并通过集成语音功能提供了更为流畅的协作交互。"}
{"llm_update_time": "20251006", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.03127", "html_url": "https://arxiv.org/abs/2510.03127", "title": "Raven's Progressive Matrices 中缺失规则现象的研究", "title_en": "A Study of Rule Omission in Raven's Progressive Matrices", "authors": "Binze Li", "background": "类比推理是人类认知的核心，但仍然是人工智能中的一个基本挑战。Raven's Progressive Matrices (RPM) 作为一种广泛使用的基准测试，用于评估抽象推理能力，因为它需要推断出潜在的结构规则。尽管许多基于视觉和语言的模型在RPM任务上取得了成功，但不清楚它们的性能是否真正反映了推理能力，还是依赖于统计捷径。本研究通过在训练中故意省略一些结构规则，考察现代AI系统在不完整训练条件下的泛化能力。研究评估了序列到序列的变压器模型以及基于视觉的架构，如 CoPINet 和双对比网络在 Impartial-RAVEN (I-RAVEN) 数据集上的表现。实验发现，尽管变压器在熟悉的规则上表现出强大的性能，但面对新或省略的规则时，其准确性急剧下降。此外，词元级别的准确性与完整答案准确性之间的差距进一步突显了当前方法中的根本局限性。", "innovation": "本研究通过在训练中故意省略一些结构规则，考察现代AI系统在不完整训练条件下的泛化能力，并评估了序列到序列的变压器模型以及基于视觉的架构在这方面的表现。这为深入理解深度学习模型背后的推理机制提供了新的见解，并强调了超越模式识别、发展稳健抽象推理能力的架构的需求。", "conclusion": "研究发现，尽管变压器在熟悉的规则上表现出强大的性能，但面对新或省略的规则时，其准确性急剧下降。此外，词元级别的准确性与完整答案准确性之间的差距进一步突显了当前方法中的根本局限性。这些发现为深入理解深度学习模型背后的推理机制提供了新的见解，并强调了超越模式识别、发展稳健抽象推理能力的架构的需求。"}
{"llm_update_time": "20251006", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.03206", "html_url": "https://arxiv.org/abs/2510.03206", "title": "Coevolutionary Continuous Discrete Diffusion: 让你的扩散语言模型成为一个隐含推理者", "title_en": "Coevolutionary Continuous Discrete Diffusion: Make Your Diffusion Language Model a Latent Reasoner", "authors": "Cai Zhou,Chenxiao Yang,Yi Hu,Chenyu Wang,Chubin Zhang,Muhan Zhang,Lester Mackey,Tommi Jaakkola,Stephen Bates,Dinghuai Zhang", "background": "扩散语言模型，尤其是掩码的离散扩散模型，近年来取得了巨大成功。尽管有些理论和初步的经验结果表明含隐性推理的循环变换器或连续链式思考方式有优势，但连续扩散模型通常在性能上不如其离散的对应物。", "innovation": "本文作者认为，扩散语言模型不一定需要在离散空间中。证明了连续扩散模型比离散扩散和循环变换器具有更强的表达能力。作者将连续扩散与离散扩散和循环变换器在理论表达能力与实际性能之间的矛盾归因于其实用的可训练性：虽然连续扩散提供了循环变换器所缺乏的中间监督，但也增加了将连续表示空间中的令牌解码为离散令牌空间的难度。基于此，作者提出了Coevolutionary Continuous Discrete Diffusion（CCDD），结合一维和多维扩散过程，通过单一模型同时在联合空间中去噪，利用双模态融合在隐含空间中获得丰富的语义，以及借助明确的离散令牌提高训练和采样的质量。", "conclusion": "CCDD模型在广泛的现实语言建模任务中表现出色，并且提出了有效的架构和高级的训练/采样技术来增强其实用性能。"}
{"llm_update_time": "20251006", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.21923", "html_url": "https://arxiv.org/abs/2509.21923", "title": "联合展示交互和独立效应的乘加约束模型", "title_en": "Multiplicative-Additive Constrained Models:Toward Joint Visualization of Interactive and Independent Effects", "authors": "Fumin Wang", "background": "在涉及生命安全的高风险领域（如医疗）中，机器学习应用时需要考虑可解释性。广义加性模型（GAMs）通过可视化形状函数增强了可解释性，但为了保持这种解释性，GAMs 必须舍弃高级交互效应（超出简单的两两交互），这对其预测性能设定了显著限制。研究者观察到曲线遍历集回归（CESR）作为一种乘法模型，天然支持形状函数的可视化，同时整合了所有特征的交互效应和单个特征效应，但 CESR 在性能上未超越 GAMs。因此，为了改进 CESR 的性能，引入了乘加约束模型（MACMs），它通过增加加性部分来明确分离交互项和独立项的系数，从而拓宽了假设空间。", "innovation": "提出了乘加约束模型（MACMs），这种模型结合了 CESR 的高可解释性和 GAMs 的高预测性能。MACMs 包括乘法部分和加法部分，形状函数都可以自然可视化，从而帮助用户理解特征如何参与决策过程。", "conclusion": "实验结果表明，基于神经网络的 MACMs 在预测性能方面显著优于 CESR 和当前最先进的 GAMs。"}
{"llm_update_time": "20251006", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.03194", "html_url": "https://arxiv.org/abs/2510.03194", "title": "CoDA: 代理系统实现协作数据可视化", "title_en": "CoDA: Agentic Systems for Collaborative Data Visualization", "authors": "Zichen Chen,Jiefeng Chen,Sercan Ö. Arik,Misha Sra,Tomas Pfister,Jinsung Yoon", "background": "尽管深度研究已经极大地改变了数据分析的方式，数据科学家仍然花费大量时间手动创建可视化图形，这凸显了从自然语言查询进行自动化的迫切需求。然而，当前系统在处理包含多个文件的复杂数据集和迭代优化时存在困难。现有的方法，包括简单的单代理或多个代理系统，通常过于简化任务，侧重于最初的查询解析，而忽略了有效地管理和优化数据复杂性、代码错误或最终视觉质量的问题。", "innovation": "本文重新将这一挑战定义为一个多代理系统合作问题。作者提出了CoDA，一个采用专门LLM代理进行元数据分析、任务规划、代码生成和自我反思的多代理系统。该论文正式验证了这一管道的有效性，展示了元数据专注的分析可以绕过令牌限制，而质量驱动的优化可以确保稳健性。广泛的评估结果表明，CoDA在整体得分上取得了显著提升，优于竞争基线最多达41.5%。这项工作表明，数据可视化自动化的未来不在于孤立的代码生成，而在于集成和合作的代理作业流程中。", "conclusion": "这项研究表明，未来数据可视化的自动化不依赖于孤立的代码生成，而是依赖于集成和协作的代理作业流程。CoDA通过多代理系统的应用显著提升了数据可视化的自动化水平，展示了代理系统的强大能力。"}
{"llm_update_time": "20251006", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.02328", "html_url": "https://arxiv.org/abs/2510.02328", "title": "AMANDA: 数据高效医疗视觉问答中的代理医疗知识增强", "title_en": "AMANDA: Agentic Medical Knowledge Augmentation for Data-Efficient Medical Visual Question Answering", "authors": "Ziqing Wang,Chengsheng Mao,Xiaole Wen,Yuan Luo,Kaize Ding", "background": "医疗多模态大规模语言模型（Med-MLLMs）在医疗视觉问答（Med-VQA）方面表现出巨大的潜力。然而，在缺乏丰富标注数据的低资源环境中部署时，现有Med-MLLMs通常会由于其医学推理能力瓶颈而失败。这些瓶颈包括：（i）内在推理瓶颈，忽视了医学图像的细节；（ii）外在推理瓶颈，未能整合特殊化的医学知识。", "innovation": "提出了一种无需训练的代理框架AMANDA，该框架通过LLM代理进行医学知识增强。AMANDA在内在医学知识增强方面专注于从粗到细的问题分解以进行全面诊断，在外在医学知识增强方面通过生物医学知识图表检索来指导推理过程。在八个Med-VQA基准上的实验表明，在零样本和少量样本的Med-VQA设置中均实现了显著改进。", "conclusion": "广泛的实验显示出AMANDA在低资源环境下的有效性，特别是在零样本和少量样本的Med-VQA设置中取得显著改进。"}
{"llm_update_time": "20251006", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.02319", "html_url": "https://arxiv.org/abs/2510.02319", "title": "通过量化敌对扰动进行攻击建模：检测AI生成文本", "title_en": "Modeling the Attack: Detecting AI-Generated Text by Quantifying Adversarial Perturbations", "authors": "Lekkala Sai Teja,Annepaka Yadagiri,Sangam Sai Anish,Siva Gopala Krishna Nuthakki,Partha Pakray", "background": "随着高度先进的大型语言模型（LLMs）的增长，使用这些模型生成的文本面临巨大的双重用途问题，对依赖这些模型生成文本的有效性检测提出了挑战。现代检测系统容易受到对抗性攻击的影响，尤其是通过改写等技术来欺骗统计检测。研究人员需要开发更可靠的AI生成文本检测系统，以应对这些挑战。", "innovation": "本文提出了一种新的对抗性鲁棒性检测框架——Perturbation-Invariant Feature Engineering (PIFE)，通过首先将输入文本转换为标准形式，然后使用Levenshtein距离和语义相似度等度量标准量化转换的大小，并直接将这些信号输入分类器。PIFE通过从文本与标准形式之间的差异中工程化特征来对抗语义攻击，保持了82.6%的正检测率，这表明直接建模扰动特征比仅仅是对其进行训练更具抗敌对性攻击的优势。", "conclusion": "传统的对抗性训练在对抗性语法噪声方面表现出色，但在对抗性语义攻击方面效果不佳，而本文提出的PIFE模型则能有效地克服这一限制，其对抗性条件下保持了82.6%的高检测率，证明了对抗性鲁棒性不需要仅仅基于对抗实例的训练，以直接建模扰动特征更为重要。"}
{"llm_update_time": "20251006", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.02327", "html_url": "https://arxiv.org/abs/2510.02327", "title": "KAME: Tandem Architecture for Enhancing Knowledge in Real-Time Speech-to-Speech Conversational AI", "title_en": "KAME: Tandem Architecture for Enhancing Knowledge in Real-Time Speech-to-Speech Conversational AI", "authors": "So Kuroki,Yotaro Kubo,Takuya Akiba,Yujin Tang", "background": "实时语音到语音（S2S）模型擅长生成自然、低延迟的响应，但往往缺乏深厚的语义理解。相比之下，结合自动语音识别、文本形式的大语言模型（LLM）和文本到语音合成的级联系统则能提供更好的知识表达，但会带来高延迟的问题，从而破坏自然互动的流畅性。", "innovation": "论文提出了一种新颖的混合架构，通过采用S2S变压器即时响应用户语音，同时将查询传递给强大的后端LLM，后端LLM的文本响应会在实时注入以指导S2S模型的语音生成，从而在不完全付出级联系统延迟代价的情况下，增强输出的知识丰富性。", "conclusion": "研究团队使用MT-Bench基准的语音合成版本（包括多轮问答会话）评估了该方法，结果显示，该系统在响应正确性方面显著优于基线S2S模型，几乎能达到级联系统的水平，同时保持了与基线相当的延迟。"}
{"llm_update_time": "20251006", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.02324", "html_url": "https://arxiv.org/abs/2510.02324", "title": "CASAL：对比激活引导用于消减幻觉的归一化学习", "title_en": "Hallucination reduction with CASAL: Contrastive Activation Steering For Amortized Learning", "authors": "Wannan Yang,Xinchi Qiu,Lei Yu,Yuchen Zhang,Oliver Aobo Yang,Narine Kokhlikyan,Nicola Cancedda,Diego Garcia-Olano", "background": "大型语言模型（LLMs）虽然表现出色，但常常会有幻觉现象，即自信地提供错误答案而忽视自己的无知。以往研究表明模型在其知识表示中存在线性编码，并且通过激活引导可以减少幻觉。然而，这些方法需要实时监控和干预以实现推理过程中的错误修正。因此，亟需一种能高效融入模型训练和优化机制的方法来解决这一问题。", "innovation": "本文提出了一种高效的算法CASAL，称为对比激活引导用于归一化学习。CASAL直接将激活引导的益处融入模型权重中，在训练后使LLMs能够自信地回答知道的问题，而在不知道的问题上保持沉默。与强大的LoRA基线方法（如SFT和DPO）相比，CASAL在计算和数据效率上提高了30到20倍，而且在多个短问题-答案基准测试中能将幻觉减少30%-40%。更重要的是，CASAL还能够将幻觉缓解效果推广到新的领域。CASAL展示了激活引导方法的有效性，不仅在文本模型中有效，也在视觉-语言模型中展示了其灵活性，并且目前是第一个被证明既能应用于密集型模型，又能应用于混合专家模型的方法。", "conclusion": "CASAL代表了将解释方法应用于生产系统中的一项有前景的进步，具有高效的计算和数据利用能力，以及强大的泛化能力，尤其在数据稀缺领域具有广泛的适用性。"}
{"llm_update_time": "20251006", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.02331", "html_url": "https://arxiv.org/abs/2510.02331", "title": "基于交互式对话征集与推荐(Systematic Dialogue Generation for Interactive Conversational Elicitation & Recommendation)的合成对话生成", "title_en": "Synthetic Dialogue Generation for Interactive Conversational Elicitation & Recommendation (ICER)", "authors": "Moonkyung Ryu,Chih-Wei Hsu,Yinlam Chow,Mohammad Ghavamzadeh,Craig Boutilier", "background": "语言模型（LMs）在对话推荐系统（CRS）方面具有巨大的潜力，但由于公开的CRS数据稀缺，为CRS细调LM具有挑战性。因此，LMs可以作为用户模拟器发挥数据生成的功能用于训练基于LM的CRS，但由于缺乏行为一致性，生成的对话序列往往会与任何真实用户的不太一致。", "innovation": "开发了一种使用行为模拟器和LM提示来生成与用户潜在状态一致的自然对话的方法。通过这种方法生成了一个包含偏好征集和示例批判的大规模开源CRS数据集。这些对话在某些评价者的评价中表现出高度的一致性、客观性和自然性。", "conclusion": "此方法通过结合行为模拟和LM提示技术，成功生成了高度一致的CRS对话数据，该数据集可用于训练和评估基于LM的CRS，为解决CRS数据稀薄的问题提供了一个有效方案。"}
{"llm_update_time": "20251006", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2205.03569", "html_url": "https://arxiv.org/abs/2205.03569", "title": "基于运动增强的注意力跨模态交互表示学习方法在压缩视频动作识别中的应用", "title_en": "Representation Learning for Compressed Video Action Recognition via Attentive Cross-modal Interaction with Motion Enhancement", "authors": "Bing Li,Jiaxin Chen,Dongming Zhang,Xiuguo Bao,Di Huang", "background": "近年来，压缩视频动作识别吸引了广泛的关注。由于使用稀疏采样的RGB帧和压缩的运动线索（如运动向量和残差）代替原始视频，这种方法极大地减少了存储和计算成本。然而，该任务严重存在粗略和噪声运动动态以及RGB和运动模态之间融合不足的问题。", "innovation": "本文提出了一种新的框架，即带有运动增强的注意力跨模态交互网络（MEACI-Net）。该框架基于两流架构，一个用于RGB模态，另一个用于运动模态。运动流嵌入了多尺度块和去噪模块来增强表示学习。通过引入选择性运动补充（SMC）和跨模态增强（CMA）模块，加强了两个流之间的交互。SMC通过时空注意局部运动特征来补充RGB模态，CMA进一步通过选择性特征增强合并了两种模态。", "conclusion": "通过在UCF-101、HMDB-51和Kinetics-400基准上的大量实验，证明了MEACI-Net的有效性和效率。"}
{"llm_update_time": "20251006", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.02326", "html_url": "https://arxiv.org/abs/2510.02326", "title": "抗幻觉、领域特定的研究助手，具有自我评估和基于向量检索", "title_en": "Hallucination-Resistant, Domain-Specific Research Assistant with Self-Evaluation and Vector-Grounded Retrieval", "authors": "Vivek Bhavsar,Joseph Ereifej,Aravanan Gurusami", "background": "大型语言模型在文献综述方面加速了进程，但同时也产生了幻觉和引用错误，限制了它们在专家工作流中的应用价值。", "innovation": "提出了一种模块化的基于GPT的研究助手RA-FSM，它通过Relevance-Confidence-Knowledge状态机将生成包裹在一个有限状态控制循环中，同时结合了向量检索和确定性的引用管道。该系统可以通过过滤无关查询，评分答案可回答性，分解问题，并在必要时触发检索，生成带有置信度标签并去重的文献引用。RA-FSM采用分层获取工作流程构建了知识库，并实现了透明且引证良好的答案，适用于高风险的技术工作，并具备在其他科学领域中的泛化能力。", "conclusion": "在盲审A/B测试中，领域专家更倾向于RA-FSM比强笔记本语言模型（NLM）和单一范本GPT API调用基线更能处理边界条件和提供更可信的证据使用。覆盖率和新颖性分析表明，RA-FSM在探索范围上超过了NLM，同时具有可调的延迟和费用开销。"}
{"llm_update_time": "20251006", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.02329", "html_url": "https://arxiv.org/abs/2510.02329", "title": "SelfJudge：通过自我监督的法官验证实现更快的推测性解码", "title_en": "SelfJudge: Faster Speculative Decoding via Self-Supervised Judge Verification", "authors": "Kanghoon Yoon,Minsub Kim,Sungjae Lee,Joonhyung Lee,Sunghyeon Woo,Yeonjun In,Se Jung Kwon,Chanyoung Park,Dongsoo Lee", "background": "推测性解码通过验证来自草稿模型的候选标记与更大目标模型的对比来加速大型语言模型（LLM）的推理。最近的评判性解码通过放宽验证标准来加快这一过程，以接受可能与目标模型输出存在轻微差异的草稿标记，但现有方法因依赖于人工注释或具有可验证真实参考的任务而受到限制，这限制了其在不同自然语言处理（NLP）任务中的普适性。", "innovation": "研究提出了一种名为SelfJudge的方法，该方法通过目标模型的自我监督来训练评判验证器。该方法通过评估替换标记后的回答是否保持原始回答的意义来测量语义保留，从而能够在各种NLP任务中实现自动验证器的训练。实验表明，SelfJudge在推理准确性和速度之间实现了优于评判性解码基线的最佳权衡，提供了一种广泛适用的加速LLM推理的解决方案。", "conclusion": "研究展示了SelfJudge在不同NLP任务上的优越性，并提出了一种无需人工介入的自动化验证机制，能够显著提升LLM的推理速度和准确性，为未来NLP任务的更快推理提供了广泛适用的解决方案。"}
{"llm_update_time": "20251006", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.02334", "html_url": "https://arxiv.org/abs/2510.02334", "title": "错在哪里？通过表示梯度追踪归因不良LLM行为", "title_en": "Where Did It Go Wrong? Attributing Undesirable LLM Behaviors via Representation Gradient Tracing", "authors": "Zhe Li,Wei Zhao,Yige Li,Jun Sun", "background": "大型语言模型（LLMs）展现出了强大的能力，但它们的部署往往受到诸如生成有害内容、事实错误和社会偏见等不良行为的阻碍。诊断这些失败的根本原因对AI安全性构成了重大挑战。现有的归因方法，尤其是基于参数梯度的方法，由于信号噪声大和计算复杂性高，常常效果不佳。", "innovation": "本文介绍了一种新颖且高效的框架，通过分析表示及其梯度来诊断各种LLM的不良行为，直接在模型激活空间中操作，以提供将输出与其训练数据相关联的具有语义意义的信号。该方法系统地评估了跟踪有害内容、检测后门投毒和识别知识污染等任务，结果表明该方法不仅在样本级归因上表现出色，还能进行精细的令牌级分析，精确识别出对模型行为有因果影响的具体样本和短语。", "conclusion": "本文提供了一种强大的诊断工具，用于理解、审计并最终缓解LLMs所伴随的风险。代码可在链接“this https URL”中找到。"}
{"llm_update_time": "20251006", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.02336", "html_url": "https://arxiv.org/abs/2510.02336", "title": "KurdSTS：库尔德语语义文本相似度", "title_en": "KurdSTS: The Kurdish Semantic Textual Similarity", "authors": "Abdulhady Abas Abdullah,Hadi Veisi,Hussein M. Al", "background": "语义文本相似度（STS）衡量两段文本含义的重叠程度，并支持许多自然语言处理（NLP）任务。尽管高资源语言有大量的资源，低资源语言如库尔德语却缺乏相关资源。", "innovation": "提出了一项库尔德语ST斯数据集，包含10,000个覆盖正规和非正规语域的句子对，每对句子进行了相似度注解。此外，基准测试了Sentence-BERT、多语言BERT和其他强baseline模型，展示了库尔德语形态学、拼写变体和代码混合带来的挑战。该数据集和基线模型为未来库尔德语语义学和低资源NLP研究提供了可重复的评估环境。", "conclusion": "该数据集和基线模型建立了可重复的评估套件，提供了未来库尔德语语义研究和低资源NLP研究的良好起点。"}
{"llm_update_time": "20251006", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.02325", "html_url": "https://arxiv.org/abs/2510.02325", "title": "Agentic-AI Healthcare：基于MCP代理的多语言、隐私优先框架", "title_en": "Agentic-AI Healthcare: Multilingual, Privacy-First Framework with MCP Agents", "authors": "Mohammed A. Shehab", "background": "本文介绍了一种名为Agentic-AI Healthcare的隐私感知、多语言且可解释的研究原型，该项目由单一调查员开发。该系统利用新兴的模型上下文协议（MCP）来协调多智能代理进行患者的互动、症状检查、药物建议以及预约安排。该平台集成了专门的隐私和合规层，利用基于角色访问控制（RBAC）的AES-GCM字段级加密以及防篡改审计日志，并符合包括HIPAA（美国）、PIPEDA（加拿大）和PHIPA（安大略省）在内的主要医疗数据保护标准。", "innovation": "该研究的关键创新在于结合了基于代理的编排、多语言访问能力和合规性意识架构在医疗应用中的可行性。此外，系统还支持多语言患者-医生互动（英语、法语、阿拉伯语）以及由大型语言模型支持的透明诊断推理。", "conclusion": "本文展示了一种可行的将代理编排、多语言功能和合规性意识架构结合到医疗应用中的平台，该平台作为一种研究原型，而不是认证的医疗设备。"}
{"llm_update_time": "20251006", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.02332", "html_url": "https://arxiv.org/abs/2510.02332", "title": "高容量和安全的语言神经拟态隐写术去歧算法", "title_en": "A High-Capacity and Secure Disambiguation Algorithm for Neural Linguistic Steganography", "authors": "Yapei Feng,Feng Jiang,Shanhao Wu,Hua Zhong", "background": "神经语言拟态隐写术的目标是在保持统计不可检测性的同时将信息嵌入自然文本中。这一领域的一个根本挑战来自于现代分词器中的分词歧义性，可能导致灾难性的解码失败。近期的SyncPool方法通过粗粒度的同步机制解决了这种歧义性问题，但在嵌入容量上有所牺牲，因为它仅利用了歧义组的全部香农熵来进行同步，而不是用于信息嵌入。", "innovation": "提出了一个名为look-ahead Sync的方法，该方法克服了SyncPool的容量限制，同时保留了其证明安全的保证。该方法仅对真正无法区分的标记序列进行最小的同步采样，同时战略性地保留所有其他可区分路径，以最大化嵌入容量。该方法还提供了理论证明以确保其安全性，并分析了其实现的嵌入容量与理论上限之间的差距。在使用Llama 3的英语基准和使用Qwen 2.5的汉语基准上进行的实验表明，该方法的一致上接近理论容量上限，并且显著优于SyncPool。在英汉语中，嵌入率的提高分别超过了160%和25%，特别是在候选池更大的设置中尤为显著。", "conclusion": "本研究代表了朝着实用的高容量证明安全的语言神经拟态隐写术迈出的重要一步。"}
{"llm_update_time": "20251006", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.02337", "html_url": "https://arxiv.org/abs/2510.02337", "title": "CRACQ：自动化文档评估的多维度方法", "title_en": "CRACQ: A Multi-Dimensional Approach To Automated Document Assessment", "authors": "Ishak Soltani,Francisco Belo,Bernardo Tavares", "background": "本文提出了一种多维度评估框架CRACQ，用于评价文档的五个特定特质：连贯性、严谨性、适当性、完整性以及质量。CRACQ借鉴了基于特质的自动作文评分（AES）的想法，但将其评估范围从文章扩展到了多种形式的机器生成文本。CRACQ通过综合语言、语义和结构信号进行综合评估，提供了一种基于评分和可解释的方法，能够进行整体和特质层面的分析。", "innovation": "CRACQ通过综合多种类型的信号，提供了一种全面且可解释的多维度评估方法。它不仅能够进行整体评估，还能对具体特质进行评估，而且在评估稳定性方面优于直接使用大语言模型的评估结果。然而， CRACQ在可靠性以及适用领域方面仍存在挑战。", "conclusion": "CRACQ在500个合成的提案文档上进行了训练，并与大语言模型进行了基准测试，还进一步测试了其在实际中的强弱应用。初步结果显示，CRACQ能产生更稳定且可解释的特质层面评价，尽管仍面临可靠性和范围方面的挑战。"}
{"llm_update_time": "20251006", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.02330", "html_url": "https://arxiv.org/abs/2510.02330", "title": "EntropyLong: 通过预测不确定性进行有效的长语境训练", "title_en": "EntropyLong: Effective Long-Context Training via Predictive Uncertainty", "authors": "Junlong Jia,Ziyang Chen,Xing Wu,Chaochen Gao,Zijia Lin,Debing Zhang,Songlin Hu,Binghui Guo", "background": "训练长语境语言模型以捕捉长距离依赖性需要专门的数据构建技术。当前的方法，如通用文本拼接或基于启发式的变体，往往无法保证真正的长距离依赖性。现有的方法无法有效保证数据中的长距离依赖性的真实性，这使得模型在处理需要远距离信息的任务时表现不佳。为此，本文提出了一种新的数据构建方法EntropyLong，该方法利用预测不确定性来验证依赖的质量。通过这种方法，可以构造出包含经过验证的长期依赖的数据集。", "innovation": "提出了一种名为EntropyLong的新颖数据构建方法，利用预测不确定性来验证长期依赖的质量。该方法通过识别文档中的高熵位置，检索大型语料库中的语义相关上下文，并验证这些上下文的有效性。模型在验证这些依赖后，将其与原始文档结合，用于生成包含经过验证的长期依赖的数据集。该方法在FineWebEdu和Cosmopedia上生成的数据集，显著改进了RULER基准测试中的模型表现，特别是在需要远距离信息的任务中。此外，经过指令微调后，模型在LongBenchv2上也取得了显著的改进，证明了该方法在长语境理解中的有效性和必要性。", "conclusion": "本文通过提出EntropyLong方法，利用预测不确定性的反馈来验证长期依赖性，从而有效提高了长语境模型的训练效果。实验结果表明，使用此方法训练的模型在处理需要远距离信息的任务时表现显著改善。此外，通过对EntropyLong方法的应用验证了其在长语境训练中的有效性和必要性。"}
{"llm_update_time": "20251006", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.02339", "html_url": "https://arxiv.org/abs/2510.02339", "title": "在论辩型大型语言模型中评估不确定性量化方法", "title_en": "Evaluating Uncertainty Quantification Methods in Argumentative Large Language Models", "authors": "Kevin Zhou,Adam Dejl,Gabriel Freedman,Lihu Chen,Antonio Rago,Francesca Toni", "background": "随着大型语言模型（LLMs）的发展，在这些模型中实施不确定性量化（UQ）已成为确保该技术可靠性的关键。本研究探讨了将LLM的UQ方法整合到基于计算论辩的可解释LLM框架（ArgLLMs）中的方式，这种框架依赖于决策中的论辩计算。", "innovation": "研究采用了一种新颖的评估方法来评估UQ方法的有效性，特别是在论辩性复杂的陈述存在的情况下。实验过程不仅评估了不同UQ方法在ArgLLMs中的性能，还展示了直接提示作为一种简单而有效的UQ策略。", "conclusion": "研究结果表明，尽管直接提示的方法简单明了，但在论辩型大型语言模型（ArgLLMs）中却是一种有效的UQ策略，其性能明显优于更复杂的方法。"}
{"llm_update_time": "20251006", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.02333", "html_url": "https://arxiv.org/abs/2510.02333", "title": "包含上下文和社会维度的人类移动数据集", "title_en": "Human Mobility Datasets Enriched With Contextual and Social Dimensions", "authors": "Chiara Pugliese,Francesco Lettich,Guido Rocchietti,Chiara Renso,Fabio Pinelli", "background": "背景：文章提出了两个包含语义信息的公共人类轨迹数据集，以及构建这些数据集的流程。这些轨迹数据来源于OpenStreetMap中的公共GPS轨迹。每个数据集包含多个层，如停留点、移动、兴趣点（POIs）、推断的交通工具模式以及天气数据。数据集还包含由大型语言模型生成的合成且接近真实的社交媒体内容，这使得可进行多模态和语义的移动分析。数据集既以表格形式又以RDF格式提供，支持语义推理和开放获取的数据实践。数据集覆盖了两个结构不同的大城市——巴黎和纽约。开源可重复管道可以让数据集的定制更加灵活，而数据集对于行为建模、移动预测、知识图谱构建和基于LLM的应用都具有支持作用。到目前为止，这是首个将真实世界流动、结构化的语义增强、生成的语言模型文本以及语义万维网兼容性结合在可复用框架中的资源。", "innovation": "创新：文章的主要创新点在于将真实世界的移动数据与结构化的语义增强信息以及由大型语言模型生成的社交媒体内容结合起来，提供了一个在语义万维网上兼容的可复用框架。这种数据集不仅包含了传统的GPS轨迹数据，还包括了丰富的情境信息如时间、地点、兴趣点等，以及通过机器生成的社交文本，为多模态和语义分析提供了更多的可能性。这些数据集支持多个研究任务，包括行为建模、移动预测、知识图谱构建和基于语言模型的应用。", "conclusion": "结论：该研究提供了第一个整合了真实世界移动数据、结构化语义增强信息、由大型语言模型生成的文本内容并且能够兼容语义网络的数据集。数据集采用开放式可复用的框架，并且可以自定义，这对于行为建模、移动预测和基于知识图谱的应用程序具有重要的支持意义。"}
{"llm_update_time": "20251006", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.02343", "html_url": "https://arxiv.org/abs/2510.02343", "title": "BluePrint: 社交媒体用户数据集，用于大语言模型人设评估与训练", "title_en": "$\\texttt{BluePrint}$: A Social Media User Dataset for LLM Persona Evaluation and Training", "authors": "Aurélien Bück-Kaeffer,Je Qin Chooi,Dan Zhao,Maximilian Puelma Touzel,Kellin Pelrine,Jean-François Godbout,Reihaneh Rabbany,Zachary Yang", "background": "大型语言模型（LLMs）能够大规模模拟社交媒体动态，为伦理或后勤上难以实现的研究所提供可能性。然而，研究领域缺乏用于精细调整和评估LLMs作为真实社交媒体代理的标准化数据资源。为此，本文介绍了SIMPACT工具包，其旨在构建行为基础的、适合训练代理模型的社交媒体数据集，并提出了一种基于行为预测任务来训练和评估LLM代理，并且提出了集群和总体层面的评估指标来评估行为准确度和风格真实性。具体实现中，BluePrint数据集由公共Bluesky数据构建，重点研究政治话语，它将匿名用户聚类为人格，并通过去标识化和去除个人识别信息来保护隐私。", "innovation": "本文通过提出SIMPACT工具包，解决了研究领域缺乏标准化数据资源的问题，构建了一种行为基础、适合训练代理模型的社交媒体数据集。同时，将行为预测任务应用于模拟用户行为，并引入了集群和总体层面的评估指标来衡量行为真实性与风格现实性。BluePrint数据集通过公共Bluesky数据和去标识化用户构建而成，专注于政治话语，涵盖了12种社交媒体交互类型，支持基于语言和互动行为的上下文依赖性。", "conclusion": "SIMPACT通过标准化数据和评估规程，为推进严格且负责任的社交媒体模拟奠定了基础。BluePrint不仅作为政治话语模型的评估基准，还作为构建特定领域数据集的模板，可用于研究诸如错误信息和极端分化等挑战。"}
{"llm_update_time": "20251006", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.02345", "html_url": "https://arxiv.org/abs/2510.02345", "title": "打破MoE大语言模型困境：基于结构压缩的动态专家聚类", "title_en": "Breaking the MoE LLM Trilemma: Dynamic Expert Clustering with Structured Compression", "authors": "Peijun Zhu,Ning Yang,Jiayu Wei,Jinghang Wu,Haijun Zhang", "background": "Mixture-of-Experts（MoE）大型语言模型（LLMs）面临负载不平衡、参数冗余和通信开销的问题。这些问题是相互关联的缺陷，影响了模型的性能和效率。", "innovation": "文章引入了一个结合动态专家聚类和结构化压缩的统一框架来共同解决这些问题。该方法使用在线聚类过程，根据参数和激活相似性的融合度量定期重新分组专家，从而稳定专家使用。文章提出了新的架构分解方法，并通过两阶段的层次路由策略，减少了路由搜索空间和全连接通信的体积。此外，利用混合精度方案和动态卸载策略，降低了峰值内存消耗，达到与密集模型相似的水平。该框架在GLUE和WikiText-103上表现出与标准MoE模型相似的质量，参数减少了约80%，吞吐量提升了10%-20%，专家负载变异减少了一倍以上。", "conclusion": "研究表明，结构性重组是实现可扩展、高效和节能MoE大语言模型的合理途径。"}
{"llm_update_time": "20251006", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.02348", "html_url": "https://arxiv.org/abs/2510.02348", "title": "mini-vec2vec：通过线性变换扩大通用几何对齐的规模", "title_en": "mini-vec2vec: Scaling Universal Geometry Alignment with Linear Transformations", "authors": "Guy Dar", "background": "vec2vec是一种设计用于在没有平行数据的情况下对齐文本嵌入空间的程序。vec2vec找到几乎完美的对齐，但它在成本和稳定性方面存在缺陷。", "innovation": "mini-vec2vec是一种简单而高效的替代方案，需要显著降低的计算成本，并且高度稳定。此外，学习到的映射是一个线性变换。方法包括三个主要阶段：临时的伪平行嵌入向量匹配、变换拟合以及迭代细化。mini-vec2vec的线性替代方案在效率上比vec2vec高出几个数量级，同时达到或超过其结果。", "conclusion": "该方法的稳定性和可解释的算法步骤促进了扩展，并解锁了在新领域和领域中采用的新机会。"}
{"llm_update_time": "20251006", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.02341", "html_url": "https://arxiv.org/abs/2510.02341", "title": "DRIFT: 从丰富真实用户不满中学习", "title_en": "DRIFT: Learning from Abundant User Dissatisfaction in Real-World Preference Learning", "authors": "Yifan Wang,Bolian Li,Junlin Wu,Zhaoxuan Tan,Zheli Liu,Ruqi Zhang,Ananth Grama,Qingkai Zeng", "background": "现实世界中的大型语言模型部署（例如对话AI系统、代码生成助手）自然会产生大量的隐含用户不满意（DSAT）信号，用户通过迭代、修正和表达偏好来寻求更好的答案。然而，显式的满意度反馈却相对稀缺。现有的偏好学习方法在这方面不匹配，因为它们依赖昂贵的人工标注，或假设了大量的积极回应。因此，这些方法在处理DSAT信号时效率低下。", "innovation": "本文介绍了DRIFT（Dissatisfaction-Refined Iterative Preference Training），该方法以真实的DSAT信号为训练基础，并从不断演化的策略中动态抽样积极反馈。DRIFT模型在真实世界的人类反馈（WildFeedback）数据集和合成的数据集上进行了训练，表现出显著的性能提升。与其它先进方法相比，无论是7B模型还是14B模型，DRIFT在WildBench任务得分和AlpacaEval2胜率上都显示出更好的表现。特别是在更大规模的模型中，DRIFT带来的改进尤为明显。此外，DRIFT还保留了探索能力，生成了更多的高报酬解决方案，而没有局限于狭窄的部分。", "conclusion": "理论上，我们证明了DRIFT的设计保留了偏好差距，并避免了梯度退化。研究表明，DRIFT是一种有效的和可扩展的方法，可以在大规模训练后利用最丰富和最有信息性的信号。所有代码和数据均可通过网址获取。"}
{"llm_update_time": "20251006", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.02338", "html_url": "https://arxiv.org/abs/2510.02338", "title": "基于索赔奖励优化长格式临床文本生成", "title_en": "Optimizing Long-Form Clinical Text Generation with Claim-Based Rewards", "authors": "Samyak Jhaveri,Praphul Singh,Jangwon Kim,Tara Taghavi,Krishnaram Kenthapadi", "background": "使用大语言模型自动化临床记录需要精确对齐优先事项，如完整性与事实基础。本文介绍了将Group Relative Policy Optimization (GRPO)与DocLens结合的评估集成增强学习框架，DocLens是一种基于索赔级别的评估器，提供了确定性的、对话地基础奖励。该方法直接优化了事实基础和完整性，而无需训练单独的奖励模型或依赖于人工撰写的参考文本。实验表明，通过简单的奖励阻断策略可以提高临床笔记质量并降低培训成本。独立的GPT-5定性评估进一步支持了这些改进，GRPO输出在事实性、完整性和简明程度上更受偏好，且罕见遗漏和虚构。由于基准相对较干净且基模型已很好地对齐，这些改进可能代表保守的下限。该框架可扩展到真实世界设置，并可融入定制目标如指南遵从性或账单偏好中。", "innovation": "该方法直接优化了事实基础和完整性，而无需训练单独的奖励模型或依赖于人工撰写的参考文本。通过评估集成增强学习框架，结合Group Relative Policy Optimization (GRPO)与DocLens，实现了基于索赔级别的确定性奖励。这简化了模型的训练过程，提高了临床记录的质量和效率。", "conclusion": "该框架在基准测试上显示出改进，这些改进可能代表了保守的下限，且可以扩展到实际应用中。同时，该框架也展示了其在日益复杂的临床记录生成中的潜力，特别是通过融入定制目标如指南遵从性或账务偏好。此外，虽然在清洁基准上取得成功，但仍需更多研究以验证其在复杂和混乱环境中的效果。"}
{"llm_update_time": "20251006", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.02357", "html_url": "https://arxiv.org/abs/2510.02357", "title": "AI时代的隐私问题：数据风险分类", "title_en": "Privacy in the Age of AI: A Taxonomy of Data Risks", "authors": "Grace Billiris,Asif Gill,Madhushi Bandara", "background": "随着人工智能（AI）系统处理越来越敏感的数据，传统的隐私框架因其独特性，如自主学习和黑箱决策，已证明不足以应对新兴的隐私挑战。", "innovation": "该论文通过系统回顾识别出45篇研究，提出了一个对AI隐私风险进行分类的体系分类法，并将其分为四类：数据集级风险、模型级风险、基础设施级风险和内部威胁风险。研究成果揭示出这些风险在各个维度上的分布较为均衡，并且发现人为错误是最具影响力的因素，这对传统的安全策略提出了挑战。", "conclusion": "论文通过填补技术与行为维度理解之间的空白，为值得信赖的AI发展做出贡献，并为未来研究奠定了基础。"}
{"llm_update_time": "20251006", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.02349", "html_url": "https://arxiv.org/abs/2510.02349", "title": "非对比自监督学习方法在网络入侵检测中的性能调查", "title_en": "An Investigation into the Performance of Non-Contrastive Self-Supervised Learning Methods for Network Intrusion Detection", "authors": "Hamed Fard,Tobias Schalau,Gerhard Wunder", "background": "网络入侵检测是网络安全领域的研究热点，过去二十年主要依赖监督学习算法。然而，仅能检测已知异常的局限性推动了寻找替代方法的研究。受到计算机视觉中自监督学习成功的启发，学者开始探索是否可以将这种范式应用于网络入侵检测。尽管先前研究主要关注对比自监督方法，但非对比自监督方法、编码器架构和数据增强策略对有效检测攻击的影响尚不清楚。本研究通过系统地在两种网络入侵检测数据集（UNSW-NB15和5G-NIDD）上进行90次实验，比较了五种非对比自监督学习方法在三种编码器架构和六种数据增强策略下的表现。", "innovation": "本研究创新性地对非对比自监督学习方法在网络入侵检测中的性能进行了系统性的评估。通过使用五种不同的非对比自监督学习方法、三种编码器架构和六种数据增强策略，在两个不同的网络入侵检测数据集上进行了细致实验，首次全面比较了这些方法在检测网络攻击中的效果。", "conclusion": "本研究通过比较最佳性能模型与两个无监督基线（DeepSVDD和自编码器）的表现，展示了非对比自监督学习方法在网络入侵检测中的竞争力。实验结果显示，适当的编码器架构和数据增强策略能够显著提升网络入侵检测的效果。"}
{"llm_update_time": "20251006", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.02335", "html_url": "https://arxiv.org/abs/2510.02335", "title": "FormalML：机器学习理论中正式子目标完成评估基准", "title_en": "FormalML: A Benchmark for Evaluating Formal Subgoal Completion in Machine Learning Theory", "authors": "Xiao-Wen Yang,Zihao Zhang,Jianuo Cao,Zhi Zhou,Zenan Li,Lan-Zhe Guo,Yuan Yao,Taolue Chen,Yu-Feng Li,Xiaoxing Ma", "background": "大规模语言模型(LLMs)在形式定理证明方面取得了显著进展，但它们作为数学家实际助手的能力，尤其是在填补复杂证明中缺失的步骤方面，仍然研究不足。本文将这一挑战定义为子目标完成任务，其中LLM必须完成人类提供的草稿中遗留但不简单的证明义务。", "innovation": "作者引入了FormalML，这是一个基于机器学习基础知识的Lean 4基准测试集。通过将过程性证明转换为声明性形式的技术，作者提取了涵盖优化和概率不等式的4937个问题，涵盖不同难度级别。FormalML是第一个将前提检索与复杂的研究级上下文相结合的子目标完成基准。评估最先进的证明器揭示了准确性和效率方面的持续限制，指出了需要更强大的基于LLM的定理证明器来提高子目标完成能力。", "conclusion": "研究评估了最先进的证明器，发现它们在准确性和效率方面存在持续的限制，表明需要更强大的基于LLM的定理证明器来提高有效的子目标完成能力。"}
{"llm_update_time": "20251006", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.02342", "html_url": "https://arxiv.org/abs/2510.02342", "title": "CATMark: 一种面向大型语言模型的上下文感知阈值框架以实现鲁棒跨任务水印", "title_en": "CATMark: A Context-Aware Thresholding Framework for Robust Cross-Task Watermarking in Large Language Models", "authors": "Yu Zhang,Shuliang Liu,Xu Yang,Xuming Hu", "background": "现有的水印算法通过嵌入和检测隐藏的统计特征来有效识别机器生成的内容，但这些过程通常会导致文本质量下降，特别是在低熵场景下性能下降更为明显。现有方法依赖于熵阈值，这类方法往往需要大量的计算资源进行调优，并且在面对未知或者跨任务生成场景时表现出较差的适应性。", "innovation": "本文提出了Context-Aware Threshold watermarking ($\textbf{C}ontext-\textbf{A}ware \textbf{T}hreshold \textbf{$\textit{watermarking}$}$, $\textbf{CAT}$) 框架，这是一种新颖的机制，可以根据实时语义上下文动态调整水印强度。CAT通过使用logits聚类将文本生成划分到语义状态中，从而建立上下文感知的熵阈值，以保持结构化内容的保真度并嵌入稳健的水印。CAT无需预定义的阈值，也不需要特定任务的调优，从而提高了跨任务水印的鲁棒性和效率，同时保持了文本质量。实验表明，它在跨任务中提高了文本质量，但并未牺牲检测准确性。", "conclusion": "实验结果表明，CATMark在跨任务场景中能够有效提升文本质量，同时保持检测精度，提供了一种在低熵场景下更加鲁棒的水印方案。"}
{"llm_update_time": "20251006", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.02347", "html_url": "https://arxiv.org/abs/2510.02347", "title": "基于小语言模型的课程指导", "title_en": "Small Language Models for Curriculum-based Guidance", "authors": "Konstantinos Katharakis,Sippo Rossi,Raghava Rao Mukkamala", "background": "当前，生成型AI和大规模语言模型（LLMs）在教育中的应用仍处于起步阶段。本文探讨了如何使用检索增强生成（RAG）管道和精选的小型语言模型（SLMs）来开发和评估提供基于课程指导的AI助教系统。这些SLMs相对LLMs具有更低的计算和能源需求，可以在消费者级硬件上实现实时使用，而不需要依赖云基础设施，从而不仅在经济上更为实惠，而且更加隐私保护和环境友好，为教育机构的大规模个性化学习提供了可持续和节能的解决方案。", "innovation": "本文创新性地使用RAG管道结合精选的SLMs来提供基于课程的指导，并通过准确性和教育对齐的评估进行基准测试，显示了即使在资源有限的情况下，这些模型也能与LLMs一起提供有用的学习指导，同时具有显著的可持续性优势。", "conclusion": "研究表明，适当提示和目标检索下，SLMs可以与LLMs媲美，提供准确且教育符合的学习指导。SLMs由于其较低的计算和能源需求，能在不需要云基础设施的情况下实现实时使用，不仅具有成本效益和隐私保护的优势，还具有绿色环保的特点，这使得SLMs成为教育机构中实现个性化学习可扩展性的理想选择，尤其是在可持续发展和能效方面。"}
{"llm_update_time": "20251006", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.02358", "html_url": "https://arxiv.org/abs/2510.02358", "title": "DiffuSpec: 解锁基于扩散语言模型的推测性解码", "title_en": "DiffuSpec: Unlocking Diffusion Language Models for Speculative Decoding", "authors": "Guanghao Li,Zhihui Fu,Min Fang,Qibin Zhao,Ming Tang,Chun Yuan,Jun Wang", "background": "随着大型语言模型（LLMs）的规模不断扩大，准确度得到提升，但自回归（AR）解码的性质会增加延迟，因为每个词元都需要进行串行前向传递。推测性解码通过使用快速起草者提出多词元草稿，并且这些草稿可并行由目标模型验证来解决这个问题。然而，许多部署仍然依赖于自回归起草者，其中顺序传递限制了墙钟时间的提高。我们重新审视了起草阶段，并提出了一种无需训练的插件框架DiffuSpec，该框架利用预训练的扩散语言模型（DLM）在一个前向传递中产生多词元草稿，同时仍然与标准AR验证器兼容。因为DLM草稿基于双向条件生成，平行的位置候选形成了一个词元网络，在这个网络中，每个位置局部概率最高的词元不一定形成自左向右的因果路径。此外，DLM起草需要预先指定草稿长度，这引入了一个速度与质量的权衡。", "innovation": "DiffuSpec是一种无需训练的插件框架，使用预训练的扩散语言模型（DLM）在一个前向传递中产生多词元草稿，与标准自回归验证器兼容。引入了因果一致性路径搜索（CPS）来提取符合自回归验证的自左向右路径，并且设计了自适应提案长度控制器（ADL），根据最近的接受反馈和已实现的生成长度调整下一个建议的大小。", "conclusion": "在基准测试中，DiffuSpec提供了高达3倍的墙钟时间加速，确立了基于扩散的起草作为自回归起草者的稳健替代方案，用于推测性解码。"}
{"llm_update_time": "20251006", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.02359", "html_url": "https://arxiv.org/abs/2510.02359", "title": "Emission-GPT: 专用于知识检索、排放清单和数据分析的特定领域语言模型代理", "title_en": "Emission-GPT: A domain-specific language model agent for knowledge retrieval, emission inventory and data analysis", "authors": "Jiashu Ye,Tong Wu,Weiwen Chen,Hao Zhang,Zeteng Lin,Xingxing Li,Shujuan Weng,Manni Zhu,Xin Yuan,Xinlong Hong,Jingjie Li,Junyu Zheng,Zhijiong Huang,Jing Tang", "background": "改善空气质量并应对气候变化依赖于对空气污染物和温室气体排放的准确理解和分析。然而，排放相关知识往往是碎片化的和高度专业化的，现有的获取和整合排放数据的方法仍不够高效。这些问题阻碍了非专家解读排放信息的能力，给研究和管理带来了挑战。", "innovation": "提出了Emission-GPT，这是一种针对大气排放领域的知识增强型大型语言模型代理。它基于超过10,000篇文件（包括标准、报告、指南和同行评审文献）的数据库，集成了提示工程和问题完成技术，支持特定领域的准确问答。Emission-GPT 允许用户通过自然语言交互式分析排放数据，如查询和可视化清单、分析源贡献以及为用户定义的情景推荐排放因子。案例研究表明，Emission-GPT 可以通过简单的提示直接从原始数据中提取关键见解，如点源分布和部门趋势。", "conclusion": "Emission-GPT 的模块化和可扩展架构使传统的手动工作流程自动化成为可能，定位为下一代排放清单开发和情景分析的基础工具。"}
{"llm_update_time": "20251006", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.02350", "html_url": "https://arxiv.org/abs/2510.02350", "title": "LLMSQL：升级至LLM时代的Text-to-SQL WikiSQL", "title_en": "LLMSQL: Upgrading WikiSQL for the LLM Era of Text-to-SQL", "authors": "Dzmitry Pihulski,Karol Charchut,Viktoria Novogrodskaia,Jan Kocoń", "background": "Text-to-SQL技术能够将自然语言问题转化为SQL查询，使非专家用户能够与关系型数据库进行交互。早期的NL2SQL研究主要依赖于WikiSQL数据集，但该数据集因结构和标注问题（如大小写不一致、数据类型不匹配、语法错误以及未回答的问题）使用频率下降。LLMSQL是在LLM时代对WikiSQL进行系统修订和转换的全新数据集，旨在解决这些问题，提供更高质量的数据供现代自然语言到SQL模型直接生成和评估使用。", "innovation": "LLMSQL针对LLM时代重新设计，解决了早期数据集中的结构和标注问题。它对WikiSQL数据集进行了分类错误处理，并实施了自动化方法进行清理和重标注。更重要的是，LLMSQL提供了清洁的自然语言问题和完整的SQL查询作为纯文本，使现代自然语言到SQL模型可以直接生成和验证，不再适合指针网络模型的选择任务。这种数据集转变适应了LLM时代的最新技术需求。", "conclusion": "LLMSQL作为一个LLM准备好的基准测试，与原始的WikiSQL适配不同的模型不同，提供清晰的自然语言问题和完整的SQL查询作为纯文本，使得现代自然语言到SQL模型可以直接生成和评估。通过评估多个大型语言模型（如Gemma 3，LLaMA 3.2，Mistral 7B等），展示了这些改进对模型性能的影响。"}
{"llm_update_time": "20251006", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.02370", "html_url": "https://arxiv.org/abs/2510.02370", "title": "语言模型中参数性和上下文知识利用的训练动态", "title_en": "Training Dynamics of Parametric and In-Context Knowledge Utilization in Language Models", "authors": "Minsung Kim,Dong-Kyum Kim,Jea Kwon,Nakyeong Yang,Kyomin Jung,Meeyoung Cha", "background": "大型语言模型在推理时检索到的上下文知识与预训练期间获取的参数知识之间经常存在冲突。接受外部知识而不加批判的模型容易传播虚假信息，而严格遵守参数知识的模型则无法从检索中受益。尽管检索增强生成得到广泛应用，但关于训练条件如何影响模型利用参数性和上下文知识及其之间的协调机制，我们仍然缺乏系统性的理解。这一知识仲裁策略的缺失可能会导致预训练模型表现出不良行为，造成大量计算资源的浪费。", "innovation": "本文首次系统研究了训练条件如何影响模型对参数性和上下文知识的利用，以及如何在两者之间进行权衡。通过在合成传记语料库上训练基于变换器的语言模型，并系统地控制各种条件，实验揭示了事实内部重复的内在发展如何促进参数性和上下文能力的发展。在包含不一致信息或分布偏斜的语料库上进行训练则鼓励模型开发出有效的策略来利用参数性和上下文知识。研究结果表明，这些非理想属性对于学习有效的仲裁机制至关重要。", "conclusion": "研究结果为构建能够和谐整合参数性和上下文知识的模型提供了具体的实验证据和指导原则。"}
{"llm_update_time": "20251006", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.02351", "html_url": "https://arxiv.org/abs/2510.02351", "title": "语言，文化与意识形态：通过推理语言模型个性化政治推文中的冒犯性检测", "title_en": "Language, Culture, and Ideology: Personalizing Offensiveness Detection in Political Tweets with Reasoning LLMs", "authors": "Dzmitry Pihulski,Jan Kocoń", "background": "本文探讨了大型语言模型（LLMs）在被要求采用特定政治和文化视角时，如何评估政治话语中的冒犯性。研究者使用了MD-Agreement数据集中有关2020年美国大选的多语言子集，评估了一些最新的LLMs（包括DeepSeek-R1、o4-mini、GPT-4.1-mini、Qwen3、Gemma和Mistral），让这些模型从不同的政治人格（如极右、保守、中间立场、进步）视角判断推文是否冒犯。结果显示，具有显式推理能力的大型模型（如DeepSeek-R1、o4-mini）在捕捉意识形态和文化差异方面更加一致且敏感，而小型模型往往无法捕捉到微妙的区别。因此，推理能力显著提高了冒犯性判断的个性化和可解释性，表明这种机制对于跨语言和意识形态适应LLMs以实现细致的社会政治文本分类至关重要。", "innovation": "研究使用了多语言多政治视角的数据集来评估多种LLMs，并发现具有显式推理能力的大型模型在评估政治推文中的冒犯性时表现更好，能够更好地捕捉意识形态和文化差异，而小型模型则在这方面表现较差。此外，研究强调了推理能力在提高个性化和可解释性方面的关键作用，这对于跨语言和意识形态适应LLMs实现细致的社会政治文本分类是有价值的创新点。", "conclusion": "研究表明，具有显式推理能力的大型模型在评估政治推文中的冒犯性时表现更佳，能够更好地捕捉到意识形态和文化差异，而小型模型则在这一方面表现较差。特别是推理能力显著提高了冒犯性判断的个性化和可解释性，这表明这种机制对跨语言和意识形态适应LLMs实现细致的社会政治文本分类至关重要。"}
{"llm_update_time": "20251006", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.02352", "html_url": "https://arxiv.org/abs/2510.02352", "title": "评估语音对话大模型中的偏见以支持实际决策和推荐", "title_en": "Evaluating Bias in Spoken Dialogue LLMs for Real-World Decisions and Recommendations", "authors": "Yihao Wu,Tianrui Wang,Yizhou Peng,Yi-Wen Chao,Xuyi Zhuang,Xinsheng Wang,Shunshun Yin,Ziyang Ma", "background": "尽管大型语言模型（LLMs）中的偏见，如刻板印象和文化倾向，在输出中已经被研究和识别，但在具有音频输入和输出的语音对话模型（SDMs）中的表现和特性仍然很大程度上未被探索。声学特征（如年龄、性别和口音）可能会影响模型的输出；在多轮对话的背景下，这些影响可能会加剧偏见，从而影响决策和推荐任务中的公平性。", "innovation": "本研究系统地评估语音LLMs中的偏见，并研究包含重复负面反馈的多轮对话的影响。创新点在于使用Group Unfairness Score (GUS) 来衡量决策中的偏见，使用相似性归一化统计率（SNSR）衡量推荐中的偏见，并且涵盖了开源模型（如Qwen2.5-Omni和GLM-4-Voice）和封闭源API（如GPT-4o Audio和Gemini-2.5-Flash）。研究发现，封闭源模型通常偏见较低，而开源模型对年龄和性别更加敏感，推荐任务可能会放大跨群体差异。研究还揭示了偏见决策在多轮对话中可能持续存在。这项工作首次系统地研究端到端的语音对话模型中的偏见，为公平和可靠的基于音频的交互系统提供了见解。另外，还发布了FairDialogue数据集和评估代码以促进进一步研究。", "conclusion": "本研究首次系统性研究了语音对话模型中的偏见，并提供了一些为公平和可信赖的基于音频的交互系统的重要见解。研究还释放了一个数据集和评估代码以促进进一步研究。"}
{"llm_update_time": "20251006", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.02360", "html_url": "https://arxiv.org/abs/2510.02360", "title": "大型语言模型代理中的沉默螺旋现象", "title_en": "Spiral of Silence in Large Language Model Agents", "authors": "Mingze Zhong,Meng Fang,Zijing Shi,Yuxuan Huang,Shunfeng Zheng,Yali Du,Ling Chen,Jun Wang", "background": "《沉默的螺旋》理论认为，持少数意见的人会因为担心社会孤立而 refrain from 表达观点，这会使主流观点占据主导地位。当参与者是大规模语言模型（Large Language Models, LLMs）时，传统上对人类社会的心理学解释不再适用，因为此理论是为人类社会设计的。这引发了核心问题：统计性语言生成是否会导致LLM代理群体中相似的《沉默的螺旋》现象？", "innovation": "本文提出了一种评估LLM代理《沉默的螺旋》现象的方法框架。通过系统地改变“历史”和“人设”信号的可用性，研究得出的结论表明：历史和人设信号共同作用产生了强大的多数派主导效应；仅靠历史信号引起强烈的锚定效应；而仅靠人设信号则产生多样化但不相关的意见。这项研究将计算社会学与负责任的人工智能设计相结合，强调了监控和减轻LLM代理系统中出现的趋同现象的重要性.", "conclusion": "实验结果表明，历史和人设信号共同作用 produces 强烈的多数派主导效应 并 重述了《沉默的螺旋》模式；仅靠历史信号 引出 强烈的锚定效应；而仅靠人设信号 促进 了多样但不相关的意见。在没有历史锚定的情况下，《沉默的螺旋》动态无法产生。这项工作填补了计算社会学与负责任AI设计之间的空白，指出了监控和减轻LLM代理系统中出现的趋同现象的必要性。"}
{"llm_update_time": "20251006", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.02362", "html_url": "https://arxiv.org/abs/2510.02362", "title": "使用罗马尼亚历史进行多语言偏见分析的大语言模型跨语言研究", "title_en": "A Cross-Lingual Analysis of Bias in Large Language Models Using Romanian History", "authors": "Matei-Iulian Cocu,Răzvan-Cosmin Cristia,Adrian Marius Dumitran", "background": "历史通常通过受特定文化及其理想影响的角度来呈现，即使在大语言模型中也是如此。由于它们的训练数据集可能存在某些模糊性，缺乏中立性会传递给用户。本文选择了一系列有争议的罗马尼亚历史问题，旨在评估大语言模型在不同语言和背景下回答这些问题时的偏见，验证预期回答类型会影响响应，并考察大语言模型在不同语言或格式之间的立场转换以及初始二元选择的数值评级是否一致。", "innovation": "本文的研究过程分为三个阶段，以验证期望的回答类型是否在一定程度上影响响应；通过提供肯定答案并再次询问同一问题，但指示模型以数值比例尺的形式回答，来考察模型在不同语言或格式之间的立场变化以及初始二元选择的数值评级是否一致的问题。研究揭示了模型在这种不一致性上的倾向性，这取决于提出问题的具体语言和语境化背景。", "conclusion": "二元回答的稳定性相对较高但并不完美，且会因语言和格式变化而有所不同。模型往往在不同语言之间或格式之间改变态度；从初始的二元选择到数值评分的分歧经常发生，最一致的模型并不总是被认为最准确或中立的。研究揭示了模型在这种不一致性上的倾向性。"}
{"llm_update_time": "20251006", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.02374", "html_url": "https://arxiv.org/abs/2510.02374", "title": "结合生成AI与按键动态的混合CAPTCHA以提高机器人检测能力", "title_en": "A Hybrid CAPTCHA Combining Generative AI with Keystroke Dynamics for Enhanced Bot Detection", "authors": "Ayda Aghaei Nia", "background": "CAPTCHAs 是互联网安全的基础组件，但传统实现存在易用性和对抗AI驱动的机器人攻击的韧性之间的权衡问题。", "innovation": "本文提出了一种创新的混合CAPTCHA系统，它将大规模语言模型（LLMs）提出的认知挑战与按键动态的行为生物特征分析相结合，生成动态、不可预测的问题，同时分析用户的打字节奏以区分人类模式与机器输入。", "conclusion": "实验证明，这种双重层方法在机器人检测的准确性方面表现出色，成功抵御了基于粘贴和脚本的模拟攻击，同时保持了高水平的用户易用性。这项工作展示了结合认知和行为测试创建新一代更安全、更用户友好的CAPTCHAs的潜力。"}
{"llm_update_time": "20251006", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.02369", "html_url": "https://arxiv.org/abs/2510.02369", "title": "超越手册和任务：LLM代理的实例级语境学习", "title_en": "Beyond Manuals and Tasks: Instance-Level Context Learning for LLM Agents", "authors": "Kuntai Cai,Juncheng Liu,Xianglin Yang,Zhaojie Niu,Xiaokui Xiao,Xing Chen", "background": "大型语言模型（LLM）代理通常会接收到两种类型的语境信息：（i）环境级别的手册，定义了交互界面和全局规则；（ii）与具体目标相关联的任务级指导或演示。本文探讨了一种重要的但被忽视的第三类语境信息——实例级语境，它包含与特定环境实例有关的可验证和可重用的事实，比如物体位置、制作物品的食谱和地方规则。研究表明，实例级语境的缺失是复杂任务中LLM代理失败的常见原因，因为任务的成功不仅依赖于对全局规则或任务提示的推理，还依赖于基于精确和持久事实的决策。获取这些语境信息不仅仅依赖于记忆，而是在交互预算紧张的情况下高效探索、验证和格式化这些事实之间的挑战。", "innovation": "本文提出了实例级语境学习（ILCL）的问题，并引入了一种任务无关的方法来解决它。该方法通过指导探索，在一个紧凑的TODO森林中智能地优先考虑下一步操作，并使用轻量级的计划-执行-提取循环来执行它们。这一过程会自动生成一个高精度的可重用上下文文档，有助于减少初始探索成本。实验结果表明，这种方法在TextWorld、ALFWorld和Crafter等多种环境下均取得了显著增益：例如，在TextWorld任务中ReAct的平均成功率从37%提升到了95%，而IGE则从81%提升到了95%。通过将一次性探索转化为持久性、可重用的知识，该方法成功补充了现有的语境信息，使LLM代理更加可靠和高效。", "conclusion": "通过实现实例级语境的高效探索与管理，我们的方法能够提高LLM代理在复杂任务中的表现和效率，为LLM代理提供了更强大的知识基础。"}
{"llm_update_time": "20251006", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.02375", "html_url": "https://arxiv.org/abs/2510.02375", "title": "预训练中的分层记忆：分离长尾知识和常见知识", "title_en": "Pretraining with hierarchical memories: separating long-tail and common knowledge", "authors": "Hadi Pouransari,David Grangier,C Thomas,Michael Kirchhof,Oncel Tuzel", "background": "现代语言模型的出色性能主要依赖于参数的扩展：较大的模型可以存储更多的世界知识并且推理能力更强。然而，将所有世界知识压缩到参数中是不必要的，因为每次提示只使用其中一小部分，并且对于具有有限推理时间和计算能力的边缘设备来说是不切实际的。", "innovation": "通过引入一种结合分层参数记忆的预训练策略和架构，该研究区分了长尾知识（不常见的知识）和常见知识。在预训练和推理过程中，模型可以从庞大的参数化记忆库中动态获取小的、上下文相关的内存块并添加到自身中。预训练过程中学习将长尾知识存储在内存参数中，而小型语言模型则捕获常见知识和通用推理能力。", "conclusion": "通过大规模实验，研究展示了显著的性能增益：一个拥有160M参数并补充了从4.6B参数容量中获取的18M参数记忆块的模型，其表现与参数多出2倍的普通模型相当。此外，研究还探索了各种大小的参数化内存的最佳类型和大小，在Transformer架构中可扩展超过21B参数。"}
{"llm_update_time": "20251006", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.02361", "html_url": "https://arxiv.org/abs/2510.02361", "title": "ChunkLLM：一种加速大语言模型推理的轻量级插件框架", "title_en": "ChunkLLM: A Lightweight Pluggable Framework for Accelerating LLMs Inference", "authors": "Haojie Ouyang,Jianwei Lv,Lei Ren,Chen Wei,Xiaojie Wang,Fangxiang Feng", "background": "基于Transformer的大型模型在自然语言处理和计算机视觉领域表现出色，但由于自注意力机制的二次时间复杂度导致严重的计算效率低下问题。最近，一些基于块选择和压缩的方法被提出以缓解这一问题，但由于存在问题如语义不完整或训练-推理效率差，因此难以全面解决这些挑战。", "innovation": "文章提出了一种轻量级且插件式的训练框架，命名为ChunkLLM。它引入了两个组件：QK Adapter和Chunk Adapter。QK Adapter附着在每个Transformer层上，实现特征压缩和块注意力获取的双重目的；Chunk Adapter在模型的底层工作，通过上下文语义信息来检测块边界。通过冻结骨干网络参数仅训练QK Adapter和Chunk Adapter，并设计了一种注意力蒸馏方法来训练QK Adapter，提高了关键块的召回率。在推理阶段，仅当检测到当前标记为块边界时才触发块选择，这加速了模型推理。", "conclusion": "实验在多样化的长文本和短文本基准数据集上进行，结果表明，ChunkLLM不仅在短文本基准上表现可比，在长文本基准上也保持了98.64%的性能，并保留了48.58%的关键值缓存率。特别地，ChunkLLM在处理120K长文本时相比vanilla Transformer的最大加速倍数达到了4.48倍。"}
{"llm_update_time": "20251006", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.02356", "html_url": "https://arxiv.org/abs/2510.02356", "title": "测量大规模语言模型在物理世界中的隐私意识：一个评估基准", "title_en": "Measuring Physical-World Privacy Awareness of Large Language Models: An Evaluation Benchmark", "authors": "Xinjie Shen,Mufei Li,Pan Li", "background": "大规模语言模型（LLMs）在实体代理中的部署迫切需要评估其在物理世界中的隐私意识。现有的评估方法主要集中在基于自然语言的情境中，这与实际物理环境中的隐私需求存在差距。因此，迫切需要建立一个新的评估基准来填补这些差距，准确测量LLMs在物理环境中的隐私意识表现。现有的顶级模型在变化的物理场景中的表现并不理想，当任务伴随隐私请求时，模型更倾向于完成任务而非遵守约束，尤其是在涉及高度敏感的隐私与重要社会规范冲突的情境下，模型有时会忽视社会规范。这些发现突显了LLMs在物理环境中的隐私认知存在根本性的不匹配，强调了需要建立更加稳健、物理感知的能力来进行更有效的对齐。", "innovation": "本文提出了EAPrivacy，这是第一个设计用于量化LLM代理在物理世界中的隐私意识的全面评估基准。EAPrivacy利用了分布性生成的场景进行四级测试，评估代理在处理敏感物体、适应变化环境、平衡任务执行与隐私限制以及解决与社会规范冲突的能力。该基准细致地测量了现有模型在不同物理和社交情境下的隐私处理能力，并揭示了现有模型在物理情境下的隐私意识存在的问题。", "conclusion": "研究表明，当前模型在物理情境下的隐私处理能力存在明显不足，未能处理好物理背景下的隐私问题。模型在变化的物理环境中表现欠佳，且在面对隐私请求时倾向于优先完成任务而非遵守约束。在高风险的情境中，模型甚至有时会忽略重要社会规范。这些发现进一步强调了在构建大规模语言模型时，需要更加注重其在物理世界中的隐私意识，强调建立更加稳健和物理感知的对齐机制的紧迫性。"}
{"llm_update_time": "20251006", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.02376", "html_url": "https://arxiv.org/abs/2510.02376", "title": "在部署中扩展同态应用", "title_en": "Scaling Homomorphic Applications in Deployment", "authors": "Ryan Marinelli,Angelica Chowdhury", "background": "本研究旨在通过开发一个概念验证的同态应用来评估加密生态系统在实际生产环境中的准备情况。研究通过实现一个电影推荐应用，利用容器化和编排技术使该应用进入生产环境。在此过程中，通过调整部署配置，减少了全同态加密（FHE）的计算限制，并通过额外的基础设施优化来克服这些问题。", "innovation": "本研究的创新之处在于将概念验证的同态应用生产化，并通过调整部署配置和基础设施优化来应对FHE的计算限制，从而在实际部署环境中展示了同态加密技术的实际应用潜力。", "conclusion": "研究证明了通过优化部署配置和基础设施，可以在实际生产环境中实现同态加密应用，为未来的大规模应用提供了理论和实践基础。"}
{"llm_update_time": "20251006", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.02387", "html_url": "https://arxiv.org/abs/2510.02387", "title": "CWM: 一种基于世界模型的开放权重大语言模型用于代码生成研究", "title_en": "CWM: An Open-Weights LLM for Research on Code Generation with World Models", "authors": "FAIR CodeGen team. Jade Copet,Quentin Carbonneaux,Gal Cohen,Jonas Gehring,Jacob Kahn,Jannik Kossen,Felix Kreuk,Emily McMilin,Michel Meyer,Yuxiang Wei,David Zhang,Kunhao Zheng,Jordi Armengol-Estapé,Pedram Bashiri,Maximilian Beck,Pierre Chambon,Abhishek Charnalia,Chris Cummins,Juliette Decugis,Zacharias V. Fisches,François Fleuret,Fabian Gloeckle,Alex Gu,Michael Hassid,Daniel Haziza,Badr Youbi Idrissi,Christian Keller,Rahul Kindi,Hugh Leather,Gallil Maimon,Aram Markosyan,Francisco Massa,Pierre-Emmanuel Mazaré,Vegard Mella,Naila Murray,Keyur Muzumdar,Peter O'Hearn,Matteo Pagliardini,Dmitrii Pedchenko,Tal Remez,Volker Seeker,Marco Selvi,Oren Sultan,Sida Wang,Luca Wehrstedt,Ori Yoran,Lingming Zhang,Taco Cohen,Yossi Adi,Gabriel Synnaeve", "background": "为推进代码生成领域的研究，尤其是在使用世界模型的情况下，研究者们迫切需要一种能够在理解和生成代码方面提供更强能力的模型。传统的静态代码训练方法已经接近其性能上限，因此需要引入新的训练方法和数据源，如来自Python解释器和自主Docker环境的观察-行动轨迹，以及可验证的编程、数学和多轮软件工程环境中的多任务推理。", "innovation": "本文提出了Code World Model（CWM），这是一个在相同参数量下具有开放权重的大型语言模型，用于增强代码生成工作。CWM的独特之处在于它不仅在代码上进行了训练，还在大量的交互数据上进行了中转训练，并通过验证性的编程、数学和多轮软件工程环境中的多任务推理进行了强化学习。这种训练方法使CWM在代码理解和生成方面表现出色，特别是在需要推理和规划的计算环境中。", "conclusion": "CWM提供了研究人员探索世界建模如何促进计算环境中代码生成的强有力的试验平台。通过CWM，初步结果显示世界建模如何能够帮助自主编程，并提供了模拟Python代码执行的逐步仿真。CWM作为一种密集型、仅解码器的LLM，采用了最大131k词元的上下文大小进行训练。除了其世界建模的能力之外，CWM还在通用编程和数学任务上表现优异，为后续的研究提供了良好的模型检查点。"}
{"llm_update_time": "20251006", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.02386", "html_url": "https://arxiv.org/abs/2510.02386", "title": "关于因果模型基准污染检测的脆弱性", "title_en": "On The Fragility of Benchmark Contamination Detection in Reasoning Models", "authors": "Han Wang,Haoyu Li,Brian Ko,Huan Zhang", "background": "在因果模型（LRMs）的排行榜中，评价已经转变成为一种竞赛，激励开发者直接优化基准套件。一种快速提升排名的捷径是将评价基准纳入训练数据，从而导致基准污染。作者的调研发现，即使基准污染很容易被检测，实际操作中也可能非常难以发现和阻止，尤其是在两种具体场景下更为明显：一是基础模型通过SFT和RL演变成因果模型时，SFT阶段的污染是可早先检测的，但很短的GRPO训练就能隐藏大多数检测方法依赖的关键污染信号；二是当SFT污染带上CoT（思维链）应用于高级因果模型时，大多数检测方法几乎等同于随机猜测，即便没见过的测试样本与训练集具有类似分布的情况下，被污染的模型也会表现出更多的信心，从而规避现有基于记忆的检测方法。", "innovation": "本研究揭示了因果模型在基准污染检测方面的独特脆弱性：开发人员可以轻易地污染因果模型以实现虚假的排行榜表现，同时又留下很少的污染痕迹。这不仅损害了评估的公平性，还威胁到了公开排行榜的完整性。本文指出，需要开发更先进的基准污染检测方法和针对因果模型量身定制的可信评估协议。", "conclusion": "本研究指出，因果模型在基准污染检测方面的脆弱性非常严重。现有的检测方法存在明显不足，使得污染很难被发现和阻止。这提出了一个迫切的需求，即开发新的检测方法以及为因果模型量身定制的评估协议，以确保评估的公平性和透明度。"}
{"llm_update_time": "20251006", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.02371", "html_url": "https://arxiv.org/abs/2510.02371", "title": "在智能电网中的联邦时空图学习用于被动攻击检测", "title_en": "Federated Spatiotemporal Graph Learning for Passive Attack Detection in Smart Grids", "authors": "Bochra Al Agha,Razane Tajeddine", "background": "智能电网面临着被动窃听的风险，攻击者通过监听通信链路获取信息而不主动篡改数据。这种侦察活动可能揭示电网拓扑、消费模式和操作行为，从而为后续的定向攻击打开通道。由于这些信号微弱、短暂且通常在单一节点或时间线上分析时消失，因此检测这种威胁非常困难。", "innovation": "该文提出了一种基于图的多模式检测器，通过在以自我为中心的星形子图和短暂时间窗口上融合物理层和行为指示器，来检测被动攻击。引入了两阶段编码器：图卷积聚合自我为中心的星形子图的时空上下文，双向GRU建模短期时间依赖性，从而将异构特征转化为统一的时空表示，适合分类。该模型在满足 FedProx 条件下的联邦学习环境下进行训练，提高了模型对异质本地原始数据的鲁棒性，有利于去中心化的训练；原始测量数据保留在客户端设备上。生成了一个标准化信息驱动的合成 dataset 来模拟无线唯一被动干扰的 HAN/NAN/WAN 通信、事件同时发生以及防泄漏分割。", "conclusion": "该模型在 0.15% 的 FPR 下实现了每时间步 98.32% 的测试准确率（F1_{attack} = 0.972），每序列 93.35% 的测试准确率。结果表明，将时空上下文结合起来可以可靠地检测隐蔽侦察活动，同时保持低 false-positive 率，这种方法适用于非IID的去中心化智能电网部署。"}
{"llm_update_time": "20251006", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.02373", "html_url": "https://arxiv.org/abs/2510.02373", "title": "A-MemGuard：基于LLM代理记忆的第一种主动防御框架", "title_en": "A-MemGuard: A Proactive Defense Framework for LLM-Based Agent Memory", "authors": "Qianshan Wei,Tengchao Yang,Yaochen Wang,Xinfeng Li,Lijun Li,Zhenfei Yin,Yi Zhan,Thorsten Holz,Zhiqiang Lin,XiaoFeng Wang", "background": "大型语言模型（LLM）代理通过使用记忆来自我学习过去的交互，从而在复杂环境中实现自主规划和决策制定。然而，这一依赖内存的方式带来了严重的安全风险：对手可以向代理的记忆中注入看似无害的数据记录，进而操控其未来的行为。该漏洞具有两个关键特征：首先，在不确定具体上下文的情况下，单独审查记忆条目难以检测被注入的恶意内容。其次，一旦触发操纵行为，将会引发自我强化的错误循环，被篡改的结果将作为先例存储，这不仅放大了最初的错误，还逐步降低了未来类似攻击的门槛。", "innovation": "我们提出了A-MemGuard（Agent-Memory Guard），这是首个针对LLM代理记忆的主动防御框架。核心思想在于使记忆自身能够自我检查和自我纠正。通过不修改代理的根本架构，A-MemGuard结合了两种机制：基于共识的验证，通过比较从多个相关记忆中得出的推理路径来检测异常；以及双记忆结构，将检测到的失败提炼成教训分别存储，并在未来的行动前查阅，以打破错误循环并实现适应性。", "conclusion": "在多个基准测试中的全面评估表明，A-MemGuard能够将攻击的成功率降低95%以上，同时产生极小的效用成本。这项工作将LLM代理记忆的安全性从静态过滤转变为一种增强型、经验驱动的主动防御模型，随着时间的推移，防御机制会不断加牢固。相关代码已在该链接中发布。"}
{"llm_update_time": "20251006", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.02403", "html_url": "https://arxiv.org/abs/2510.02403", "title": "通过精调的多模态大语言模型进行青光眼检测和结构化OCT报告生成", "title_en": "Glaucoma Detection and Structured OCT Report Generation via a Fine-tuned Multimodal Large Language Model", "authors": "Jalil Jalili,Yashraj Gavhane,Evan Walker,Anna Heinke,Christopher Bowd,Akram Belghith,Massimo A. Fazio,Christopher A. Girkin,C. Gustavo De Moraes,Jeffrey M. Liebmann,Sally L. Baxter,Robert N. Weinreb,Linda M. Zangwill,Mark Christopher", "background": "本研究背景基于对青光眼检测和眼科成像报告自动生成的需求，特别是在青光眼诊断中，需要快速准确地分析光学相干断层扫描（OCT）图像中的视神经头（ONH）圆圈扫描和视网膜神经纤维层（RNFL）的厚度变化。研究者旨在开发一个可解释的多模态大型语言模型（MM-LLM），能够对OCT图像进行质量筛查，并生成包含青光眼诊断和RNFL厚度评估的结构化临床报告，以提高临床工作流程的效率和自动化水平。", "innovation": "研究的创新之处在于展示了如何通过精调的多模态大型语言模型（MM-LLM）来实现OCT图像质量筛选及生成结构化的临床报告，具体包括青光眼诊断和RNFL厚度分区域评估。该模型能够在保证高准确率和高召回率的同时，快速而准确地对OCT图像进行分类和评估。此外，模型生成的文本描述与参考报告高度一致，展示了优秀的解释性和自动生成能力。", "conclusion": "研究中精调的MM-LLM能够生成准确的临床描述，基于OCT影像数据。该模型在图像质量筛查和青光眼检测方面达到了高准确性，其生成的关于RNFL厚度的结构化描述也有助于支持临床OCT评估。"}
{"llm_update_time": "20251006", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.02422", "html_url": "https://arxiv.org/abs/2510.02422", "title": "动态目标攻击", "title_en": "Dynamic Target Attack", "authors": "Kedong Xiu,Churui Zeng,Tianhang Zheng,Xinzhe Huang,Xiaojun Jia,Di Wang,Puning Zhao,Zhan Qin,Kui Ren", "background": "现有的基于梯度的囚笼逃脱攻击通常通过优化一个对抗后缀来诱导一个固定的肯定响应。然而，这种固定的靶目标通常位于安全对齐的语言模型输出分布的极低密度区域，特别是在面对多样化的有害输入时。由于靶目标和原始输出之间的巨大差异，现有的攻击需要大量的迭代来优化对抗前缀，即使如此，它们也可能无法从目标模型中产生低概率的靶目标响应。", "innovation": "本文提出了一种新的囚笼逃脱框架——动态目标攻击（Dynamic Target Attack, DTA），该框架利用目标语言模型自身的响应作为优化对抗前缀的目标。DTA 在每次优化轮次中，从当前前缀的输出分布中迭代地采样多个候选响应，选择最具有危害性的响应作为临时优化目标，从而显著减少了靶目标与输出分布之间的差异，极大地简化了优化过程。", "conclusion": "大量的实验结果表明，DTA 在白盒环境下仅需 200 次优化迭代就能在最近的安全对齐语言模型上实现超过 87% 的攻击成功率，远超过最先进的基线方法。DTA 的时间成本是现存基线的 2 到 26 倍少。在黑盒环境下，DTA 使用 Llama-3-8B-Instruct 作为目标采样代理模型，在攻击黑盒目标模型 Llama-3-70B-Instruct 时实现了 85% 的攻击成功率，超过了其竞争对手超过 25%。"}
{"llm_update_time": "20251006", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.02414", "html_url": "https://arxiv.org/abs/2510.02414", "title": "RainSeer：基于物理学引导的细粒度降雨重建", "title_en": "RainSeer: Fine-Grained Rainfall Reconstruction via Physics-Guided Modeling", "authors": "Lin Chen(1),Jun Chen(1),Minghui Qiu(1),Shuxin Zhong(1),Binghong Chen(2),Kaishun Wu(1) ((1) The Hong Kong University of Science and Technology (Guangzhou), (2) China Meteorological Administration)", "background": "高分辨率降雨场的重建对于洪水预报、水文建模和气候分析至关重要。然而，现有的空间插值方法——无论是基于自动气象站（AWS）测量，还是增强卫星/雷达观测数据，往往过度光滑关键结构，无法捕捉锐变和局部极端事件。", "innovation": "我们引入了RainSeer，一种结构感知重建框架，重新诠释雷达反射率作为物理导向的结构先验，捕捉降雨的发展过程、时间和地点。RainSeer采用了一种基于物理的两阶段架构，即结构到点映射和地理感知降雨解码器。结构到点映射通过双向映射将中尺度雷达结构投影到局部地面降雨，地理感知降雨解码器通过因果时空注意力机制捕捉从高空雨滴到地面降水的语义转变。", "conclusion": "我们使用RAIN-F（韩国，2017-2019年）和MeteoNet（法国，2016-2018年）两个公开数据集评估了RainSeer，发现它的一致改进超越了最先进的基线，减少了超过13.31%的MAE，并显著提升了重建降雨场的结构保真度。"}
{"llm_update_time": "20251006", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.02417", "html_url": "https://arxiv.org/abs/2510.02417", "title": "NEURODNAAI: 基于深度学习框架推动可持续DNA信息存储的神经管道方法", "title_en": "NEURODNAAI: Neural pipeline approaches for the advancing dna-based information storage as a sustainable digital medium using deep learning framework", "authors": "Rakesh Thakur,Lavanya Singh,Yashika,Manomay Bundawala,Aruna Kumar", "background": "DNA作为一种数字信息存储介质，因其优异的密度和耐久性而颇具前景。虽然已有研究在编码理论、工作流程设计和模拟工具方面取得进展，但合成成本、测序错误以及生物学限制（如GC含量不平衡和同聚体限制）等因素限制了其实际应用。因此，现有技术无法有效应对实际噪音，导致数据存储和传输中的误差增加。", "innovation": "该框架借鉴量子并行概念，增强编码多样性和鲁棒性，结合生物学启发的约束条件和深度学习提升纠错能力。NeuroDNAAI将二进制数据流转换为符号DNA序列，在具有替换、插入和删除的信道中进行传输，并能以高保真度重建，在基准数据集上展示了较低的比特错误率。传统提示或基于规则的方案无法有效适应实际噪声，而NeuroDNAAI则表现出更高的准确性。在统一理论、工作流程和模拟的管道中，NeuroDNAAI实现了可扩展且生物上有效的档案DNA存储。", "conclusion": "通过综合理论、工作流程和模拟，NeuroDNAAI能够提供一种高效、鲁棒并且具有生物可行性的DNA存储解决方案，从而实现其作为可持续数字存储媒介的潜力。"}
{"llm_update_time": "20251006", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.02416", "html_url": "https://arxiv.org/abs/2510.02416", "title": "跨平台DNA甲基化分类器用于Group 3 & 4 Medulloblastoma的八种分子亚型", "title_en": "Cross-Platform DNA Methylation Classifier for the Eight Molecular Subtypes of Group 3 & 4 Medulloblastoma", "authors": "Omer Abid,Gholamreza Rafiee", "background": "髓母细胞瘤是一种恶性儿童脑癌，已发现分子亚组使个性化治疗策略成为可能。2019年，一个共识确定了Group 3和Group 4内的八大新型亚型，每个亚型均显示不同特征。分类器对于将这些发现转化为临床实践来说至关重要，它能够支持临床试验、个性化疗法的开发和应用，以及患者的监控。现有的分类器存在平台间不兼容的问题，本研究表明，一种基于DNA甲基化的跨平台机器学习分类器能够区分HM450和EPIC甲基化阵列样本中的这些亚型，在两个独立测试集中，该模型的加权F1值为0.95，平衡准确率为0.957，且结果一致。", "innovation": "该研究提出了一种基于DNA甲基化的跨平台机器学习分类器，该分类器能够在HM450和EPIC甲基化阵列样本中区分Group 3和Group 4中的八种分子亚型。这是第一个跨平台解决方案，提供了向后兼容性，同时将适用范围扩展到更新的平台，并提高了可访问性。此外，该分类器有可能成为首个公开可用的分类器，一旦通过Web应用程序部署，将为这些亚型提供分类工具。其创新之处在于实现了跨平台的高准确性分类，对髓母细胞瘤的治疗研究具有重要意义。", "conclusion": "本研究通过提出一种基于DNA甲基化的跨平台机器学习分类器，迈出了进一步发展精准医疗、改善大多数髓母细胞瘤（特别是Group 3和Group 4）患者临床结果的重要一步。"}
{"llm_update_time": "20251006", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.02483", "html_url": "https://arxiv.org/abs/2510.02483", "title": "Litespark技术报告：高吞吐量、高能效的大语言模型训练框架", "title_en": "Litespark Technical Report: High-Throughput, Energy-Efficient LLM Training Framework", "authors": "Nii Osae Osae Dade,Moinul Hossain Rahat", "background": "训练大型语言模型（LLMs）面临长时间的训练时间和巨大的能耗问题，现代模型需要数月的计算时间和吉瓦时的电力。鉴于这些挑战，本文提出了Litespark，这是一种通过针对Transformer注意机制和MLP层的优化来解决这些效率问题的新预训练框架。该方法结合了架构改进和算法增强，以最大化模型FLOPs利用效率（Model FLOPs Utilization, MFU），同时保持与标准Transformer实现的兼容性。", "innovation": "提出了Litespark，这是一种新型预训练框架，通过针对Transformer注意机制和MLP层的关键优化来解决训练效率低下和能耗大的问题。该方法结合了架构改进和算法增强，以最大化模型FLOPs利用效率，同时保持与标准Transformer实现的兼容性。实验结果表明，在H200 GPU集群上，使用SlimPajama-627B数据集对3B和30B参数的Llama模型进行全面基准测试，显示出了显著的性能提升：2到6倍的训练吞吐量改进和55%-83%的能耗减少。这些优化是模型和硬件无关的，适用于各种Transformer架构，并可扩展到后训练阶段，包括监督微调和直接偏好优化。", "conclusion": "Litespark是一种高吞吐量、高能效的大语言模型训练框架，能够显著提升训练效率并减少能耗。该框架在多种参数量级的模型以及多节点GPU集群上进行了验证，展示出了广泛的适用性和显著的性能改进。这些优化方法适用于各种类型的Transformer模型，并能扩展到后训练的不同应用场景。"}
{"llm_update_time": "20251006", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.02390", "html_url": "https://arxiv.org/abs/2510.02390", "title": "仅需超参数：使用五步推断生成与最新蒸馏模型相媲美的图像的原始扩散模型", "title_en": "Hyperparameters are all you need: Using five-step inference for an original diffusion model to generate images comparable to the latest distillation model", "authors": "Zilai Li", "background": "扩散模型是当前最先进的生成模型，通过迭代应用神经网络生成图像。这一生成过程被视为算法求解常微分方程或随机微分方程。研究者通过分析扩散常微分方程（ODE）和随机微分方程（SDE）的截断误差，提出了一种无需训练的算法，在八步内生成高质量的512×512和1024×1024的图像，并且具有灵活的引导比例。到目前为止，该算法是第一个能在八步内采样1024×1024分辨率图像，同时性能与最新的蒸馏模型相当，而无需额外训练的算法。此外，该算法也能在八步内生成512×512图像，且其性能优于最新的ODE解算器DPM++ 2m在20步中的表现。实验证实在COCO 2014、COCO 2017和LAION数据集上，该算法达到了最佳的FID绩效分别为15.7、22.35和17.52，而DPM++2m的FID绩效分别为17.3、23.75和17.33。进一步地，该算法还优于最先进的AMED插件解算器，其FID绩效分别为19.07、25.50和18.06。该算法在五步推断中未增加训练的情况下也能表现出色，在上述数据集中的FID绩效分别为19.18、23.24和19.61，接近于八步时最先进的AMED插件解算器、四步时的SDXL-turbo和五步时的最先进的扩散蒸馏模型Flash Diffusion。算法验证还表明，其在六步内合成1024×1024图像的FID绩效仅与最新蒸馏算法有一定差距。", "innovation": "研究提出了一种无需额外训练的算法，在八步内生成高质量的512×512和1024×1024的图像，同时具有灵活的引导比例。该算法在五步推断时也表现出良好性能，其在COCO 2014、COCO 2017和LAION数据集上的FID绩效分别是19.18、23.24和19.61，与最先进的AMED插件解算器、四步时的SDXL-turbo和五步时的最先进的扩散蒸馏模型Flash Diffusion的性能相当或接近，尤其是在六步内合成1024×1024图像方面与最新蒸馏算法表现接近。", "conclusion": "研究表明，仅通过调整超参数即可实现高效的图像生成，无需复杂的训练过程。该算法在多个图像生成任务中展现了显著和令人满意的结果，特别是在五步和六步推断情况下，其性能与最先进的扩散蒸馏模型相当或更优，证明了其在图像生成领域的强大潜力。"}
{"llm_update_time": "20251006", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.02453", "html_url": "https://arxiv.org/abs/2510.02453", "title": "如何用顾问模型训练你的顾问：用顾问模型引导黑盒大语言模型", "title_en": "How to Train Your Advisor: Steering Black-Box LLMs with Advisor Models", "authors": "Parth Asawa,Alan Zhu,Matei Zaharia,Alexandros G. Dimakis,Joseph E. Gonzalez", "background": "随着基础模型逐渐被部署为不可调的黑盒服务，用户只能通过静态提示进行有限的定制。虽然静态提示优化显示出潜力，但生成的固定提示无法适应不同的输入、用户或环境。本文中，作者提出了顾问模型，这是一种轻量级的参数化策略，通过强化学习训练，在使用过程中实时指导黑盒模型。顾问模型位于输入与黑盒模型之间，通过环境提供的奖励信号来动态地塑造不同的实例行为。", "innovation": "本文介绍了一种新的顾问模型，这是一种轻量级的参数化策略，通过强化学习训练，在使用过程中实时指导黑盒模型。具体而言，顾问模型能够根据环境提供的奖励信号动态地影响实例行为，并在多个涉及推理和个人化处理的领域中表现出色。此外，顾问模型还可以在不同黑盒模型之间进行迁移，并保持对未知输入的鲁棒性。", "conclusion": "顾问模型提供了一种可学习的接口，可以作为参数化的环境特定记忆，作用于黑盒系统。通过顾问模型进行黑盒模型的动态优化是一种有前景的方向，能够让人工智能在个性化和环境适应性方面达到先进的水平。"}
{"llm_update_time": "20251006", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.02463", "html_url": "https://arxiv.org/abs/2510.02463", "title": "CLARITY：临床助理用于分流、推理和分诊", "title_en": "CLARITY: Clinical Assistant for Routing, Inference, and Triage", "authors": "Vladimir Shaposhnikov,Aleksandr Nesterov,Ilia Kopanichuk,Ivan Bakulin,Egor Zhelvakov,Ruslan Abramov,Ekaterina Tsapieva,Dmitry V. Dylov,Ivan Oseledets", "background": "本文介绍了CLARITY（临床助理），一个基于人工智能的平台，用于患者向专科医生分流、临床咨询以及评估患者病情严重程度。CLARITY结合了有限状态机（FSM）和大型语言模型（LLM），旨在安全、高效并可靠地支持患者分流和咨询，同时具备模块化的微服务框架，适应现有医疗信息系统和工作流程的需求。平台在国家级医疗信息系统中进行集成，并在两个月内处理了超过55,000次内容丰富的用户对话，其中有2,500次由专家注释以进行验证。验证结果显示，CLARITY在初次尝试的分流精准度上超过了人类水平，并且缩短了咨询时间，平均减少到人类的三分之一左右。", "innovation": "CLARITY采用了一种独特的混合架构，结合了有限状态机（FSM）和大型语言模型（LLM），能够进行结构化对话流程和症状分析，从而优先推荐合适的专科医生。该平台还采用了模块化微服务框架，使得系统更安全、高效和稳健，能够灵活地与现有的医疗信息平台进行集成和扩展，以适应不同的工作流程和技术解决方案的需求。此外，CLARITY在大规模部署中表现出色，处理了数以万计的对话，且在验证中表现出高于人类的性能。", "conclusion": "CLARITY在实际临床环境中得到了成功的应用，不仅提高了病患信息处理的效率，还提升了分流和诊断的精度。在利用人工智能技术改善医疗服务方面提供了新的解决方案，未来有望在更多医疗机构中推广应用。"}
{"llm_update_time": "20251006", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.02456", "html_url": "https://arxiv.org/abs/2510.02456", "title": "基于市场的数据子集选择——多标准示例效用的有原则聚合", "title_en": "Market-Based Data Subset Selection -- Principled Aggregation of Multi-Criteria Example Utility", "authors": "Ashish Jha,Valentin Leplat,AH Phan", "background": "选择一个既小又有用的数据子集是有挑战性的，因为有用性的信号（如不确定性和稀有性）是异质的，通常需要通过人工权重进行综合。本文提出了一种基于市场的选择器，通过成本函数预测市场（LMSR）定价每个示例，信号充当交易者，通过单一的流动性参数控制集中度，并通过主题归一化稳定校准。通过价格每单位的规则 $\rho=p/\tau^{\beta}$，显式处理代币预算，并通过轻量级多样性头部提高覆盖范围。通过主题簇覆盖和有效样本大小来量化覆盖范围。理论上，我们展示了LMSR能够实现最大熵聚合，具有指数加权和凸目标函数，提供聚合强度的可解释旋钮。实证上，在GSM8K（60k代币预算）中，带有多样性的市场与强大的单一信号基线达到同等效果，减少种子方差，并且选择开销小于0.1 GPU-小时。在AGNews中，在保持5%-25%样本比例的情况下，市场（带有轻量级平衡）实现竞争力的准确性，同时提高平衡性和稳定性。该框架统一了在固定计算预算下针对提示级推理和分类的多标准数据选择。", "innovation": "提出了一种基于市场的选择器，通过成本函数预测市场（LMSR）定价每个示例，通过价格每单位的规则 $\rho=p/\tau^{\beta}$ 显式处理代币预算，通过轻量级多样性头部提高覆盖范围，并通过单一的流动性参数控制集中度和通过主题归一化稳定校准。该方法通过理论证明LMSR能够实现最大熵聚合，提供聚合强度的可解释旋钮，并且在实验上展示了良好的效果，特别是在数据预算固定的情况下，有效地解决了多标准数据选择的问题。", "conclusion": "该框架统一了在固定计算预算下针对提示级推理和分类的多标准数据选择。实证结果表明，带有多样性的市场实现与强大的单一信号基线相当的效果，同时降低种子方差，并且选择开销小于0.1 GPU-小时；在AGNews中保持5%-25%样本比例时，市场实现竞争力的准确性，同时提高平衡性和稳定性。"}
{"llm_update_time": "20251006", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.02469", "html_url": "https://arxiv.org/abs/2510.02469", "title": "SIMSplat：具有对齐语言的4D Gaussian点描述符的预测性驾驶场景编辑", "title_en": "SIMSplat: Predictive Driving Scene Editing with Language-aligned 4D Gaussian Splatting", "authors": "Sung-Yeon Park,Adam Lee,Juanwu Lu,Can Cui,Luyang Jiang,Rohit Gupta,Kyungtae Han,Ahmadreza Moradipari,Ziran Wang", "background": "随着基于传感器数据的驾驶场景操作成为传统虚拟驾驶模拟的有希望的替代方案，现有框架在生成逼真场景方面的效率仍然有限，主要是由于编辑能力有限。", "innovation": "我们提出了一种名为SIMSplat的预测性驾驶场景编辑器，它使用与语言对齐的高斯点描述符，以自然语言提示为控制，实现了直观的场景编辑。通过语言与高斯重建场景的对齐，它支持直接查询道路对象，使编辑更加精确和灵活。SIMSplat能够详尽地编辑对象级别，包括添加新对象，修改车辆和行人的轨迹，同时通过多智能体运动预测进行预测路径精炼，以生成场景中所有智能体之间的逼真交互。", "conclusion": "我们在Waymo数据集上的实验展示了SIMSplat广泛的编辑能力和适应多种场景的能力。"}
{"llm_update_time": "20251006", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.02401", "html_url": "https://arxiv.org/abs/2510.02401", "title": "线性RNN在自回归生成长音乐样本中的应用", "title_en": "Linear RNNs for autoregressive generation of long music samples", "authors": "Konrad Szewczyk,Daniel Gallo Fernández,James Townsend", "background": "直接以自回归方式学习生成音频波形是一项具有挑战性的任务，这主要是因为原始序列的长度以及在许多不同时间尺度上存在的重要结构。传统的方法，如循环神经网络、因原因卷积和自注意力机制，在这项任务上的表现有限。然而，近期的研究表明，深度状态空间模型，也可称为线性RNN，在此类任务中非常高效。尽管如此，现有的线性RNN在处理较长序列方面仍然存在限制。", "innovation": "该研究引入了一种名为HarmonicRNN的模型，通过不同的架构选择和上下文并行化处理，允许对长达一分钟（1M tokens）的序列进行训练。这种方法推动了线性RNN在原始音频建模中的应用边界，实现了在小型数据集上的领先的对数似然和感知度量。", "conclusion": "HarmonicRNN模型在小型数据集上达到了最新的对数似然和感知度量，这表明线性RNN在长音乐样本的自回归生成中具有巨大潜力。"}
{"llm_update_time": "20251006", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.02407", "html_url": "https://arxiv.org/abs/2510.02407", "title": "基于相关性驱动的数据增强的深度学习模型进行极端值预测", "title_en": "Extreme value forecasting using relevance-based data augmentation with deep learning models", "authors": "Junru Hua,Rahul Ahluwalia,Rohitash Chandra", "background": "数据增强结合生成对抗网络（GANs）在解决类别不平衡问题方面很受欢迎，特别是在模式分类和计算机视觉等应用中。极端值预测是一个挑战性较大的领域，有广泛的应用，从金融到气候变化问题等。本文提出了一种数据增强框架，旨在使用深度学习模型结合数据增强模型（例如GANs和合成少数类过采样技术SMOTE）进行极端值预测。", "innovation": "该论文的创新点在于提出了基于相关性驱动的数据增强策略，并通过深度学习模型（如卷积长短期记忆网络Conv-LSTM和双向长短期记忆网络BD-LSTM）进行多步预测，以提高极端值预测的准确性与效率。通过研究各种数据增强模型的有效性，并提出针对极端值的新型数据增强策略，最终展示了基于SMOTE的数据增强策略表现出更优的适应性。", "conclusion": "本文的研究结果表明，基于SMOTE的数据增强策略在整体预测精度和对极端值的特定区域预测方面均表现出优越性能。同时，Conv-LSTM和BD-LSTM模型在各自擅长的数据集类型上展示了互补优势，这表明采用数据增强后的深度学习模型能够显著提高极端值预测的表现，特别是在短期和长期预测方面。"}
{"llm_update_time": "20251006", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.02561", "html_url": "https://arxiv.org/abs/2510.02561", "title": "Oracle-RLAIF: 通过排名反馈强化学习改进的多模态视频模型微调框架", "title_en": "Oracle-RLAIF: An Improved Fine-Tuning Framework for Multi-modal Video Models through Reinforcement Learning from Ranking Feedback", "authors": "Derek Shi,Ruben Glatt,Christine Klymko,Shubham Mohole,Hongjun Choi,Shashank Kushwaha,Sam Sakla,Felipe Leno da Silva", "background": "近年来，大型视频语言模型(VLMs)的进步依赖于广泛应用的微调技术，以增强文本和视觉理解之间的对齐。主流方法通常结合监督微调(SFT)与偏好数据驱动的强化学习，以提升视频理解能力。然而，随着VLMs参数规模的扩大，收集足够的人类反馈的成本也在增加。为了解决这一成本问题，最近的框架探索了使用AI反馈的强化学习（RLAIF），将人类偏好替换为AI裁判。现有RLAIF框架依赖于专门训练的奖励模型，该模型使用视频叙述生成经过校准的标量奖励，这成本高昂且限制性强。", "innovation": "本研究提出了一种名为Oracle-RLAIF的新框架，用更通用的Oracle排名器替代训练好的奖励模型，该排名器作为模态模型的响应排名器，而不直接评分。此外，研究还提出了基于组相对策略优化（GRPO）的新型排名损失函数$GRPO_{rank}$，它直接优化了具有排名感知优势的序列表反馈。", "conclusion": "实验结果表明，Oracle-RLAIF在各视频理解基准测试中持续优于现有微调方法的顶级VLMs。该研究为通过排名而非评分强化学习来对齐大型多模态视频模型奠定了基础，开辟了创建灵活且数据高效的框架的道路。"}
{"llm_update_time": "20251006", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.02571", "html_url": "https://arxiv.org/abs/2510.02571", "title": "Video模型有多自信？让视频模型表达它们的不确定性", "title_en": "How Confident are Video Models? Empowering Video Models to Express their Uncertainty", "authors": "Zhiting Mei,Ola Shorinwa,Anirudha Majumdar", "background": "生成视频模型展示了出色的文本到视频能力，在许多实际应用中得到了广泛采用，但它们在生产环境中的部署面临很大的安全挑战。生成视频模型倾向于产生可信但不准确的视频，类似于大型语言模型，因此迫切需要一种量化视频模型不确定性的方法来弥补这一不足，特别是在安全性和准确性方面。", "innovation": "本文首次提出了一种量化生成视频模型不确定性的框架，包括基于鲁棒排序相关估计的度量方法、利用潜在建模严格分解预测不确定性到其 aleatoric 和 epistemic 组分的黑盒方法以及用于视频模型误差测度基准测试的数据集。此外，这种方法通过在潜在空间中调节生成任务，将任务模糊性引起和知识不足引起的不确定性进行了分离。", "conclusion": "S-QUBED 计算了与任务准确性负相关的校准总不确定性估计，并有效地计算了 aleatoric 和 epistemic 组分。"}
{"llm_update_time": "20251006", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.02554", "html_url": "https://arxiv.org/abs/2510.02554", "title": "ToolTweak：基于LLM的代理工具选择攻击", "title_en": "ToolTweak: An Attack on Tool Selection in LLM-based Agents", "authors": "Jonathan Sneh,Ruomei Yan,Jialin Yu,Philip Torr,Yarin Gal,Sunando Sengupta,Eric Sommerlade,Alasdair Paren,Adel Bibi", "background": "随着大型语言模型（LLM）越来越多地驱动与外部工具交互的代理，工具的使用已成为扩展其能力的关键机制。这些代理通常从不断增长的数据库或市场中选择工具来解决用户任务，这在一定程度上造成了工具供应者和开发者之间的隐性竞争。在这个过程中，存在一个潜在的漏洞：通过反复操纵工具名称和描述，攻击者可以系统地引导代理选择特定工具，从而在同样具备竞争力的工具中获得不公平的优势。", "innovation": "本文展示了这种选择过程中的关键漏洞：通过反复操纵工具名称和描述，攻击者可以系统地引导代理选择特定工具，获得不公平的优势。为此，作者提出了一个轻量级的自动攻击——ToolTweak，这个攻击使目标工具的选择率从20%左右提高到高达81%，并且具有很好的移植性，不仅适用于开源模型，还适用于闭源模型。此外，作者还证明了这种攻击导致了工具使用量分布的变化，揭示了公平性、竞争性和安全性的风险。", "conclusion": "为了降低这种风险，作者评估了两种防御措施：句法改写和困惑度过滤。这两种方法可以帮助减少偏见，使代理更均匀地选择功能相似的工具。所有实验代码将在论文被接受后开源。"}
{"llm_update_time": "20251006", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.02634", "html_url": "https://arxiv.org/abs/2510.02634", "title": "自动建筑规范审查：一个案例研究", "title_en": "Automatic Building Code Review: A Case Study", "authors": "Hanlong Wan,Weili Xu,Michael Rosenberg,Jian Zhang,Aysha Siddika", "background": "资源有限或农村地区的建筑官员在项目规模和复杂性增加时，面临着劳动密集型、容易出错且成本高昂的手动审查设计文件的任务。随着建筑信息建模（BIM）和大型语言模型（LLMs）的广泛应用，自动建筑代码审查（ACR）解决方案出现了新的机会。", "innovation": "该项研究介绍了一种新的代理驱动框架，该框架结合了基于BIM的数据提取与使用检索增强生成（RAG）和模型上下文协议（MCP）代理管道的自动验证。该框架利用LLM代理从各种文件类型中提取几何、时间表和系统属性，然后通过两种互补机制进行建筑规范检查：（1）直接调用美国能源部的COMcheck引擎，提供确定性和可审核的输出；（2）基于RAG的推理机制，处理规则覆盖不完整或模糊的情况。研究结果显示GPT-4o在效率和稳定性方面表现最佳，而较小的模型则表现出不一致或失败，MCP代理管道在严谨性和可靠性方面优于RAG推理管道。", "conclusion": "这项工作通过展示一种可扩展、可互操作且生产准备就绪的方法，促进了ACR研究的进步。该方法将BIM与权威的代码审查工具结合起来，实现无缝对接。"}
{"llm_update_time": "20251006", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.02484", "html_url": "https://arxiv.org/abs/2510.02484", "title": "从像素到因素：强化学习中学习独立可控制的状态变量", "title_en": "From Pixels to Factors: Learning Independently Controllable State Variables for Reinforcement Learning", "authors": "Rafael Rodriguez-Sanchez,Cameron Allen,George Konidaris", "background": "现有的算法利用因子化的马尔可夫决策过程在样本效率方面远胜于非因子化方法，但这些方法假设因子化的表示是已知的，这一前提在代理仅能看到高维观测的情况下会失效。另一方面，深度强化学习能够处理高维观测，但无法利用因子化的结构带来的好处。", "innovation": "本文提出了Action-Controllable Factorization（ACF）方法，这是一种对比学习方法，可以在像素观测中发现单独可由动作控制的潜在变量。利用动作通常只影响部分变量的特点，架构化训练数据以用于对比学习。ACF在三个具有已知因子结构的基准（Taxis、FourRooms、MiniGrid-DoorKey）上从像素观测中直接恢复真实可控制的因素，且在基线去纠缠算法上表现更优。", "conclusion": "ACF方法可以从高维观测中揭示独立可由动作控制的潜在变量，且在多个具有已知因子结构的基准上表现出色，优于基线去纠缠算法。"}
{"llm_update_time": "20251006", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.02535", "html_url": "https://arxiv.org/abs/2510.02535", "title": "PHORECAST: 源于人群的公共卫生宣传理解", "title_en": "PHORECAST: Enabling AI Understanding of Public Health Outreach Across Populations", "authors": "Rifaa Qadri,Anh Nhat Nhu,Swati Ramnath,Laura Yu Zheng,Raj Bhansali,Sylvette La Touche-Howard,Tracy Marie Zeeger,Tom Goldstein,Ming Lin", "background": "理解各种个体和社区对说服性信息的响应能够促进个性化和社会意识更强的机器学习的发展。虽然大型视觉和语言模型（VLMs）前景广阔，但在关键领域如公共卫生中的细微、多元人类响应模拟方面仍需更多探究，主要原因是没有全面的多模态数据集。因此，许多现代AI系统在模仿、解释和预见异质公众情绪和行为方面表现不佳。PHORECAST 数据集旨在解决这个问题，它是一个多模态数据集，用于细粒度预测个体行为响应和社会广泛参与健康信息的模式。这项新数据集为AI在公共卫生领域的进步提供了新的机会，有助于评估现代AI系统在这种复杂环境中的表现。请注意，“phorecast”这样一个数据集名字是英式写法，中文翻译保持了这一点，为“PHORECAST”。", "innovation": "PHORECAST是一个多模态数据集，促进了在公共卫生领域的AI研究，特别是对于细粒度的个体和群体响应预测。它通过提供全面的多模态数据帮助评估现代AI系统在理解和模拟异质公众情绪和行为方面的能力。这项工作的创新之处在于创造了这样一个数据集，填补了现有数据集的空白，专门针对公共卫生领域，以提高AI系统在这一关键领域的表现和社会意识。", "conclusion": "PHORECAST数据集旨在推动人工智能对公共卫生领域，特别是对不同人群的宣传理解和响应预测的研究。通过提供一个全面的多模态数据集，PHORECAST帮助验证现代AI系统在模仿、解释以及预见异质公众情感和行为方面的能力，进而促进模型的发展更为适应和包容的健康沟通目标。PHORECAST力求通过新的数据集来推动AI在公共健康领域的应用，使这些模型不仅具有更强的社会意识，还更加符合健康沟通的适应性和包容性目标。"}
{"llm_update_time": "20251006", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.02549", "html_url": "https://arxiv.org/abs/2510.02549", "title": "基于知识图谱的RAG系统评估框架", "title_en": "Knowledge-Graph Based RAG System Evaluation Framework", "authors": "Sicheng Dong,Vahid Zolfaghari,Nenad Petrovic,Alois Knoll", "background": "大型语言模型（LLMs）已成为研究重点，并应用于文本生成、对话系统等领域。检索增强生成（RAG）是LLM的一个关键应用，能够大大提高生成内容的可靠性和相关性。然而，评估RAG系统仍然是一个具有挑战性的任务。传统的评估指标难以有效捕捉现代LLM生成内容的关键特征，这些内容通常表现出高的流畅性和自然度。受RAGAS工具的启发，RAG的一个知名评估框架，我们将其扩展成一个基于知识图谱的评估范式，能够进行多跳推理和语义社区聚类，从而获得更综合的评分指标。通过结合这些全面的评估标准，我们对RAG系统有了更深刻的了解，并获得对其性能的更细致的认识。为了验证该方法的有效性，我们将其性能与RAGAS分数进行了比较，并构建了一个手动标注的子集来评估人工判断与自动化指标之间的相关性。此外，我们进行了有针对性的实验，证明了基于知识图谱的评估方法对生成输出中微妙语义差异更为敏感。最后，我们讨论了评估RAG系统的关键挑战，并指出了未来研究的潜在方向。", "innovation": "基于知识图谱的评估框架，能够进行多跳推理和语义社区聚类，从而获得更综合的评分指标。相比传统的评估指标，这种方法能够更好地捕捉LLM生成内容的高流畅性和自然性。该框架通过构建手动标注的子集，证明了对生成输出中小细节更加敏感。", "conclusion": "我们的方法能够更全面地评估RAG系统的性能，通过比较与RAGAS分数的性能，以及通过有针对性的实验展示了对于生成输出中的微妙语义差异更为敏感。同时，也指出了评估RAG系统面临的挑战，并为未来研究指出了潜在的方向。"}
{"llm_update_time": "20251006", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.02610", "html_url": "https://arxiv.org/abs/2510.02610", "title": "MINERVA: 使用神经估计互信息的监督特征选择", "title_en": "MINERVA: Mutual Information Neural Estimation for Supervised Feature Selection", "authors": "Taurai Muvunzaa,Egor Kraev,Pere Planell-Morell,Alexander Y. Shestopaloff", "background": "现有的特征过滤器依赖于统计的二元相关度量来建模特征-目标关系，但在某些情况下，目标可能依赖于特征之间的高阶交互而不是单一特征的贡献。本文提出了一种新的监督特征选择方法——Mutual Information Neural Estimation Regularized Vetting Algorithm (MINERVA)，该方法通过神经网络估计特征与目标之间的互信息来进行特征选择，以此来改进上述问题。", "innovation": "该方法通过神经网络参数化互信息的近似，并使用包含稀疏诱导正则化的定制损失函数来进行特征选择。整个过程分为两个阶段：首先是表征学习，然后是特征选择，以确保更好的泛化能力和更准确的特征重要性表达。该方法能够捕捉到文献中很少涉及的普遍依赖结构，并通过评估特征子集作为集合来有效捕捉复杂的特征-目标关系。", "conclusion": "基于合成和实际欺诈数据集的实验结果表明，MINERVA 方法能够有效实现特征选择，并且能提供精确的解决方案。"}
{"llm_update_time": "20251006", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.02627", "html_url": "https://arxiv.org/abs/2510.02627", "title": "一种用于高密度交通和多样代理交互场景的轨迹生成器", "title_en": "A Trajectory Generator for High-Density Traffic and Diverse Agent-Interaction Scenarios", "authors": "Ruining Yang,Yi Xu,Yixiao Chen,Yun Fu,Lili Su", "background": "准确的轨迹预测对于自动驾驶至关重要，因为它支持复杂环境中的安全运动规划和碰撞避免。然而，现有基准数据集存在长尾分布问题，大部分样本来自低密度场景和简单的直线行驶行为，而高密度场景和关键安全操作（如变道、超车和转弯）的缺失阻碍了模型泛化，并导致过于乐观的评价.", "innovation": "提出了一个新的轨迹生成框架，同时增强了场景密度和行为多样性。具体来说，该方法将连续的道路环境转化为支持细致路径规划、明确冲突检测和多代理协调的结构化网格表示。此外，引入了行为感知生成机制，结合基于规则的决策触发器和弗伦特（Frenet）轨迹平滑以及动态可行性约束，以合成具备复杂交互的真实高密度场景和罕见行为.", "conclusion": "在大规模Argoverse 1和Argoverse 2数据集上的广泛实验表明，我们的方法在提高代理人密度和行为多样性方面表现出色，同时保持了运动的真实性和场景级的安全性。合成数据也改进了下游轨迹预测模型的表现，在高密度场景中表现更佳."}
{"llm_update_time": "20251006", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.02660", "html_url": "https://arxiv.org/abs/2510.02660", "title": "当研究人员谈论AI的心智模型/理论 of mind，他们真正谈论的是什么？", "title_en": "When Researchers Say Mental Model/Theory of Mind of AI, What Are They Really Talking About?", "authors": "Xiaoyun Yin,Elmira Zahmat Doost,Shiwen Zhou,Garima Arya Yadav,Jamie C. Gorman", "background": "当前研究者在讨论AI系统是否拥有心智模型（ToM）或心理模型时，主要关注这些系统的行为预测和偏见校正，而非真正的心智状态。研究指出，现有的讨论模糊了高级模式匹配与真实认知之间的区别。尽管最近的研究表明，大语言模型（LLMs）在ToM实验室任务中达到人类水平的表现，但这些结果仅基于行为模仿，且现有测试范式可能存在问题，即使用单一的人类认知测试来评估AI系统，建议应直接评估人类与AI互动过程中的认知。", "innovation": "论文提出了一种新的观点，即转向相互的心智模型框架，以便同时考虑人类认知和AI算法的贡献，关注人机交互的动力学，而非孤立地测试AI系统。", "conclusion": "当前对AI系统拥有心智模型的讨论存在问题，主要集中在行为模仿上，建议应该重新审视和评估AI系统与人类交互中的认知过程，而不仅仅是对AI系统的行为进行测试。"}
{"llm_update_time": "20251006", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.02663", "html_url": "https://arxiv.org/abs/2510.02663", "title": "TutorBench：评估大型语言模型辅导能力的基准", "title_en": "TutorBench: A Benchmark To Assess Tutoring Capabilities Of Large Language Models", "authors": "Rakshith S Srinivasa,Zora Che,Chen Bo Calvin Zhang,Diego Mares,Ernesto Hernandez,Jayeon Park,Dean Lee,Guillermo Mangialardi,Charmaine Ng,Ed-Yeremai Hernandez Cardona,Anisha Gunjal,Yunzhong He,Bing Liu,Chen Xing", "background": "随着学生越来越多地采用大型语言模型（LLMs）作为学习助手，构建能有效应对辅导细微差别的模型变得至关重要。这类模型需要能够识别学生的核心需求，具备适应性和个性化指导的能力，并提供准确的信息。", "innovation": "引入了TutorBench，这是一个数据集和评估基准，旨在严格评估LLMs的核心辅导技能。该数据集包括1,490个人类专家根据高中和AP课程内容精挑细选的样本。样本涵盖了三种常见的辅导任务，并附有特定规范以确保评估的可靠性。同时，TutorBench还使用了一种精细的自动评估方法，结合了LLM评委和特定规范进行评估。通过对16种前沿LLM的评估，发现它们的总体表现低于56%，显示出巨大的改进空间。", "conclusion": "研究结果表明，前沿LLM在呈现全面的辅导技能方面存在较大差距，无法有效地指导、诊断和帮助学生，所有模型在这些技能上的通过率均未超过60%。此外，不同模型家族展现出不同的优势和局限性：Claude模型在支持主动学习方面表现更好，但在其他两个应用场景上则表现较弱。通过发布TutorBench，我们提供了一个全面而不饱和的基准，以指导新一代AI辅导员的发展。"}
{"llm_update_time": "20251006", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.02668", "html_url": "https://arxiv.org/abs/2510.02668", "title": "AgenticRAG：基于工具增强的基础模型零样本可解释推荐系统", "title_en": "AgenticRAG: Tool-Augmented Foundation Models for Zero-Shot Explainable Recommender Systems", "authors": "Bo Ma,Hang Li,ZeHua Hu,XiaoFan Gui,LuYao Liu,Simon Liu", "background": "基础模型在人工智能领域取得了革命性进展，但在推荐系统中的应用受限于推理透明度不足和知识限制。现有推荐系统多依赖于特定任务的训练，导致缺乏透明性。本文的目的是构建一个能够进行零样本解释性推荐的自主推荐代理。", "innovation": "本文提出了AgenticRAG框架，结合工具增强的基础模型与检索增强的生成方法，以实现零样本解释性推荐。该方法通过外部工具调用、知识检索和推理链结合，使推荐代理能够进行透明决策，无需特定任务的训练。实验证明，AgenticRAG在亚马逊电子产品数据集、 Movielens-1M 数据集和 Yelp 数据集上的 NDCG@10 分别提高了 0.4%、0.8% 和 1.6%，并在保持计算效率的同时提升了可解释性。", "conclusion": "实验结果表明，AgenticRAG 相比最先进的基准方法实现了稳定的改进，同时保持了与传统方法相当的计算效率和优秀的可解释性。"}
{"llm_update_time": "20251006", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.02716", "html_url": "https://arxiv.org/abs/2510.02716", "title": "一个在大规模网格地图中路径规划的1000倍加速LLM增强算法", "title_en": "A $1000\\times$ Faster LLM-enhanced Algorithm For Path Planning in Large-scale Grid Maps", "authors": "Junlin Zeng,Xin Zhang,Xiang Zhao,Yan Pan", "background": "路径规划在网格地图中由于各种应用而受到关注。现有的方法如A*、迪杰斯特拉及其变种在小规模地图上表现良好，但在大规模地图上因搜索时间和内存消耗高而失效。最近的研究表明，大型语言模型（LLMs）在路径规划方面表现出了卓越的表现，但仍存在空间幻觉和规划性能差的问题。其中LLM-A*克服了一些限制，但在大规模地图上仍存在较高的计算时间。", "innovation": "提出了一个创新的LLM增强算法iLLM-A*，该算法包括三个精心设计的机制：优化A*、增量学习方法以生成高质量的航点，以及选择适当的航点供A*使用进行路径规划。", "conclusion": "在不同规模的网格地图上的综合评估表明，与LLM-A*相比，iLLM-A*平均加速1000倍，在极端情况下高达2349.5倍，节省了58.6%的内存成本，并提供了更短的路径长度和较低的路径长度偏差标准差。"}
{"llm_update_time": "20251006", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.02695", "html_url": "https://arxiv.org/abs/2510.02695", "title": "RAMAC: 多模态风险感知离线强化学习和行为正则化的作用", "title_en": "RAMAC: Multimodal Risk-Aware Offline Reinforcement Learning and the Role of Behavior Regularization", "authors": "Kai Fukazawa,Kunal Mundada,Iman Soltani", "background": "在安全关键领域，线上数据收集不可行，这时离线强化学习（RL）成为了替代方案，但它只有在保证高收益同时不发生灾难性的低尾风险时才具有吸引力。先前的风险厌恶离线RL工作在确保安全性时会牺牲价值保守性，并且仅在有限的策略类别中使用具有表达性的策略。而具有表达性的策略则仅用于无风险偏好设置中。因此，该领域存在一个缺口，本文通过引入Risk-Aware Multimodal Actor-Critic (RAMAC)框架来解决这个问题。RAMAC框架结合了一种表达性强的生成演员和一个分布性评价器，通过生成路径来区分复合目标，从而实现对复杂多模态场景的高度风险敏感学习。", "innovation": "提出了Risk-Aware Multimodal Actor-Critic (RAMAC)框架，该框架结合表达性强的生成演员和分布性评价器，通过生成路径来区分复合目标，从而实现对复杂多模态场景的高度风险敏感学习。并且，通过使用扩散和流匹配演员，RAMAC在大多数Stochastic-D4RL任务上保持强回报的同时，观察到在$\text{{CVaR}}_{0.1}$方面的一致性收益提高。", "conclusion": "RAMAC框架在保持高回报的同时，通过结合多模态风险和行为一致性损失来实现风险敏感学习，解决了风险厌恶离线RL中的安全性与高表达性之间的权衡问题。"}
{"llm_update_time": "20251006", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.02683", "html_url": "https://arxiv.org/abs/2510.02683", "title": "数据驱动的动力学能否揭示隐藏的物理规律？需要可解释的神经运算符", "title_en": "Can Data-Driven Dynamics Reveal Hidden Physics? There Is A Need for Interpretable Neural Operators", "authors": "Wenhan Gao,Jian Luo,Fang Wan,Ruichen Xu,Xiang Liu,Haipeng Xing,Yi Liu", "background": "近年来，神经运算符作为一种强大的工具，用于学习功能空间之间的映射，实现了复杂动力学数据驱动的模拟。尽管取得了一定的成功，但对于其学习机制的理解仍然不足。本文通过将神经运算符分为两种类型——空间域模型和泛函域模型来对这一问题进行分类，并探讨了这些模型在遵循物理原理的数据驱动动态学习中的应用。", "innovation": "文章提出了基于分类视角的方法，解释了神经运算符的预测过程，并展示了神经运算符可以从数据中学习隐藏的物理模式。此外，研究表明，一种简单的双空间多尺度模型能够实现当前最佳性能，这表明双空间多尺度模型在学习复杂物理规律方面具有巨大潜力，并需进一步研究。此外，强调了需要原理性的框架来将已知物理规律融入神经运算符，从而提高泛化能力和发现更多隐藏的物理现象。", "conclusion": "研究发现，神经运算符可以从数据中学习物理规律，但现有的解释方法目前仅限于特定情况，因此需要开发通用的解释方法。研究表明，简单的双空间多尺度模型可以实现最先进性能，这对学习复杂的物理规律具有重要意义，需要进一步研究。文章还讨论了将已知物理规律纳入神经运算符的必要性，这对于更好地泛化和发现更多隐藏物理现象具有重要意义。"}
{"llm_update_time": "20251006", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.02712", "html_url": "https://arxiv.org/abs/2510.02712", "title": "时间到不一致：大型语言模型在 adversarial 攻击下的鲁棒性生存分析", "title_en": "Time-To-Inconsistency: A Survival Analysis of Large Language Model Robustness to Adversarial Attacks", "authors": "Yubo Li,Ramayya Krishnan,Rema Padman", "background": "大型语言模型（LLMs）在对话式AI方面取得了革命性的进展，但它们在扩展多轮对话中的稳健性仍然知之甚少。现有的评估框架主要关注静态基准和单轮评估，无法捕捉到对话降解的动态变化，这在现实世界的交互中是典型的特征。", "innovation": "本文首次全面分析了对话式AI的鲁棒性，通过生存分析方法，在9个最先进的LLMs上分析了36,951个对话回合。研究采用了Cox比例风险、加速失效时间及随机生存森林方法进行生存模型建模，揭示了令人惊讶的动态效应。研究发现，快速的、自提示到提示（P2P）的语义漂移具有灾难性效应，极大地增加了对话失败的风险。而渐进的、累积的漂移则具有保护作用，显著降低失败风险并使对话持续时间显著增加。交互效应的加速失效时间模型表现最佳，具有出色的区分能力和极佳的校准效果。这些发现确立了生存分析作为评估LLM稳健性的强大范式，为设计健壮的对话代理提供了具体见解，并挑战了关于对话式AI系统中语义一致性的必要性的传统假设。", "conclusion": "生存分析被确立为评估LLM稳健性的强大范式，提供了具体的见解以设计健壮的对话代理，并挑战了关于对话式AI系统中语义一致性的必要性的传统假设。"}
{"llm_update_time": "20251006", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.02675", "html_url": "https://arxiv.org/abs/2510.02675", "title": "HALO: 具有2.5D集成的中心存储异构加速器用于低批量LLM推理", "title_en": "HALO: Memory-Centric Heterogeneous Accelerator with 2.5D Integration for Low-Batch LLM Inference", "authors": "Shubham Negi,Kaushik Roy", "background": "大型语言模型（LLMs）的迅速采用推动了对高效推理的强劲需求，特别是在对话机器人和个性化助手等低延迟应用中。LLM推理可以分为两个阶段：预填充阶段（平行处理整个输入序列）和解码阶段（逐个生成令牌）。这两个阶段在计算和内存需求方面存在巨大差异，使得加速器设计极具挑战性。先前的研究主要针对高批量推理优化或者只能评估较短的输入上下文长度，而针对交互应用重要的低批量和长上下文情景，仍然被大大忽略了。", "innovation": "HALO提出了针对低批量LLM推理中预填充和解码阶段独特挑战的异构加速器设计方案。该设计结合了基于HBM的Compute-in-DRAM（CiD）和片上模拟Compute-in-Memory（CiM），并使用2.5D集成技术进行共封装。HALO采用一种基于阶段的映射策略，该策略能够适应预填充和解码阶段的不同需求。计算密集型操作在预填充阶段被映射到CiM以利用其高吞吐量矩阵乘法能力，而内存约束的操作在解码阶段上执行于CiD以受益于减少的数据移动。此外，HALO对两个架构极端进行了分析，展示了全CiD和全片上模拟CiM设计，强调了需要异构设计。该研究在LLaMA-2 7B和Qwen3 8B模型上评估了HALO的表现，实验结果表明，通过HALO映射的LLM相较于AttAcc（注意力优化的映射）实现了18倍的几何平均加速，相较于CENT（基于全CiD的设计）实现了2.5倍的加速。", "conclusion": "HALO展示了针对低批量LLM推理设计的异构存储中心加速器的有效性，通过特定的硬件布局和映射策略显著提高了计算效率和内存使用效率。"}
{"llm_update_time": "20251006", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.02711", "html_url": "https://arxiv.org/abs/2510.02711", "title": "一种用于无人机网络入侵检测的新型统一时空变换方法", "title_en": "A Novel Unified Lightweight Temporal-Spatial Transformer Approach for Intrusion Detection in Drone Networks", "authors": "Tarun Kumar Biswas,Ashrafun Zannat,Waqas Ishtiaq,Md. Alamgir Hossain", "background": "随着无人机在商业、工业和民用领域的日益融合，其网络安全挑战也显著增加，尤其是由于无人机网络易遭受各种类型的网络攻击。现有的入侵检测机制在动态和资源受限的环境中往往缺乏适应性、效率和普适性。", "innovation": "本文提出了TSLT-Net，一种针对无人机网络的新颖轻量级和统一的时空变换基入侵检测系统。TSLT-Net利用自我注意机制有效建模网络流量中的时序模式和空间依赖性，能够准确检测多种类型的入侵活动。此外，该框架包含一个简化预处理流水线，并且支持在单一架构中实现多类攻击分类和二元异常检测。", "conclusion": "在包含超过230万条记录的ISOT无人机异常检测数据集上进行的广泛实验表明，TSLT-Net在多类检测中的准确率达到99.99%，在二元异常检测中的准确率达到100%，同时保持了极低的内存足迹（0.04 MB）和9722个可训练参数。这些结果证实了TSLT-Net在实时无人机网络安全方面的有效性和可扩展性，特别适合在关键任务的UAV系统中部署边缘设备。"}
{"llm_update_time": "20251006", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.02676", "html_url": "https://arxiv.org/abs/2510.02676", "title": "是否进行压缩？利用指数集中化推进无损GenAI模型权重压缩的前沿", "title_en": "To Compress or Not? Pushing the Frontier of Lossless GenAI Model Weights Compression with Exponent Concentration", "authors": "Zeyu Yang,Tianyi Zhang,Jianwen Xie,Chuan Li,Zhaozhuo Xu,Anshumali Shrivastava", "background": "生成人工智能（GenAI）模型参数规模扩展至数十亿乃至数百亿，使得低精度计算成为高效部署的必不可少的方法。研究指出，解决这一问题的根本途径是开发低精度浮点格式，这些格式在提供数值稳定性、内存节省和硬件效率方面具有先天优势，无需去量化学费。研究表明，这些浮点格式的指数显示出集中的现象，此现象是从随机梯度下降衍生出的α-稳定分布自然产生的，并且指数的熵具有紧凑的界限。理论分析得出FP4.67附近的压缩极限，并指导设计实用的FP8格式。基于这些见解，提出了一种熵感知编码和GPU优化解码的无损压缩框架，Exponent-Concentrated FP8（ECF8），并在LLMs和DiTs模型上进行了实验，结果表明存储空间最多可节省26.9%，加速性能提升177.1%，且计算无任何偏差。这表明指数集中是一项统计规律，并为无损低精度浮点设计提出了理论基础。", "innovation": "提出了一种无损压缩框架Exponent-Concentrated FP8（ECF8），并基于指数集中化现象提出此框架。相对于传统的压缩技术，该方法具有更高的效率和无偏差的计算性能。同时，该研究通过理论和实验分析，证明了指数集中化作为统计规律，并为后续的设计工作提供了理论支持。", "conclusion": "该研究建立了指数集中化作为训练模型的统计规律，打开了理论指导下的无损低精度浮点设计的新途径，特别是在FP8时代提供了有效的设计方法。"}
{"llm_update_time": "20251006", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.02715", "html_url": "https://arxiv.org/abs/2510.02715", "title": "自动化DUA光刻技术中的模板和块状共聚物混合配方的反向共优化", "title_en": "Fully automated inverse co-optimization of templates and block copolymer blending recipes for DSA lithography", "authors": "Yuhao Zhou,Huangyan Shen,Qingliang Song,Qingshu Dong,Jianfeng Li,Weihua Li", "background": "定向自组装（DSA）的嵌段共聚物（BCPs）为亚7nm技术节点的接触孔或垂直互连接入的制造提供了高度有前景的方法。为了精确控制大小和位置制备圆形孔洞，嵌段共聚物的自组装需要由适当设计的模板引导。有效参数化模板形状以实现高效的优化仍然是一个关键但具有挑战性的问题。此外，优化后的模板在实际应用中必须具备优秀的可制造性。", "innovation": "本研究提出了一个高斯描述符来用两个参数表征模板形状。进一步地，研究人员提出使用AB/AB双组分混合而不是纯粹的两嵌端共聚物来提高嵌段共聚物系统的适应模板形状的能力。研究者应用贝叶斯优化（BO）来共同优化双组分混合和模板形状。实验结果表明，基于高斯描述符的贝叶斯优化能够高效地为各种多孔图案生成最优模板，并且所有这些模板都能导致高度匹配的自组装形态。此外，通过在优化过程中施加对模板曲率变化的约束条件，保证了每个优化模板都具备优秀的可制造性。每一个混合溶液的关键参数在要求高精度的情况下都具有相当宽的可调窗口。", "conclusion": "本研究提供了DUA技术发展的宝贵见解，并且有可能推动其实际应用的进展。"}
{"llm_update_time": "20251006", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.02760", "html_url": "https://arxiv.org/abs/2510.02760", "title": "数字病理学中脑肿瘤分类的分层泛化类发现", "title_en": "Hierarchical Generalized Category Discovery for Brain Tumor Classification in Digital Pathology", "authors": "Matthias Perkonigg,Patrick Rockenschaub,Georg Göbel,Adelheid Wöhrer", "background": "准确的脑肿瘤分类对于神经肿瘤手术中的术中决策至关重要。现有的方法仅限于固定的预定义类别集，无法捕捉训练期间不可用的肿瘤类型模式。无监督学习可以提取通用特征，但无法从标记数据中整合先前知识；而半监督方法通常假设所有潜在类别在标记数据中都有代表。", "innovation": "分层泛化类发现（HGCD-BT）将分层聚类与对比学习结合，通过引入一种新颖的半监督分层聚类损失，扩展基于对比学习的泛化类发现。该方法在OpenSRH数据集上的评估显示，相对于最先进的泛化类发现方法，对于斑块级分类的准确性提高了28%，特别是在识别未见过的肿瘤类别方面。", "conclusion": "此外，HGCD-BT在数字脑肿瘤图谱中的染色组织切片级别的分类中展示了其泛化能力，证实了其在不同成像模态中的实用性。"}
{"llm_update_time": "20251006", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.02717", "html_url": "https://arxiv.org/abs/2510.02717", "title": "CST-AFNet: 基于双注意力机制的深度学习框架在物联网网络入侵检测中的应用", "title_en": "CST-AFNet: A dual attention-based deep learning framework for intrusion detection in IoT networks", "authors": "Waqas Ishtiaq,Ashrafun Zannat,A.H.M. Shahariar Parvez,Md. Alamgir Hossain,Muntasir Hasan Kanchan,Muhammad Masud Tarek", "background": "物联网（IoT）的迅速扩展已经彻底改变了现代工业，实现了智能自动化和实时连接。然而，这一演变也带来了复杂的网络安全挑战，因为这些环境具有异构性、资源受限性和分布式特性。为了应对这些挑战，该研究提出了一种名为CST AFNet的新型双重注意力机制深度学习框架，专门用于物联网网络中鲁棒的入侵检测。该模型结合了多尺度卷积神经网络（CNN）以提取空间特征、双向门控循环单元（BiGRUs）以捕捉时间依赖性，并引入了双重注意力机制——通道和时间注意力——以增强对关键模式的关注。该提出的模型在Edge IIoTset数据集上进行了训练和评估，该数据集是一个全面且现实的基准，包含了超过220万个标记实例，涵盖了15种攻击类型和良性流量，这些数据是从七个层级的工业测试床中收集的。", "innovation": "该研究提出的CST AFNet框架采用了双重注意力机制，结合了多尺度卷积神经网络（CNN）、双向门控循环单元（BiGRUs）以及通道和时间注意力机制，这使得模型在频域和时域中都能更有效地检测重要的模式。该研究使用Edge IIoTset数据集进行训练和评估，并取得了出色的结果，对于15种攻击类型和良性流量，准确率均超过99.97%，宏平均精度、召回率和F1分数均超过99.3%。实验证明，CST AFNet显著优于传统的深度学习模型，在复杂物联网和工业物联网环境中实现了更实时的网络威胁检测。", "conclusion": "CST AFNet被证明是强大的并且可扩展的实时网络威胁检测解决方案，在复杂物联网和工业物联网环境中具有更多的安全、智能和适应性的可能。该研究为现有网络安全防御提供了新的思路和技术支持。"}
{"llm_update_time": "20251006", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.02789", "html_url": "https://arxiv.org/abs/2510.02789", "title": "Align Your Query: Representation Alignment for Multimodality Medical Object Detection", "title_en": "Align Your Query: Representation Alignment for Multimodality Medical Object Detection", "authors": "Ara Seo,Bryan Sangwoo Kim,Hyungjin Chung,Jong Chul Ye", "background": "医学对象检测（MD）在混合医学模态（如X射线、CT、MRI）训练时受到限制，因为它们具有异质性统计特征和不同建模空间。这导致在这些不同模态之间的准确性降低。", "innovation": "该研究提出了一个简单的、无特定检测器的框架，通过引入模态词嵌入（modality tokens）和融合多模态上下文注意力（MoCA）机制，以及通过QueryREPA预训练阶段对查询表示进行模态上下文对齐，实现对不同医学模态中对象查询的代表属性进行校准与同化，提高跨模态检测效果。", "conclusion": "所提出的方法在多种医学模态中的一致提升了AP性能，几乎没有任何增加的计算开销，且无需架构修改，为实现稳健的多模态医学对象检测提供了一条可行的道路。"}
{"llm_update_time": "20251006", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.02692", "html_url": "https://arxiv.org/abs/2510.02692", "title": "通过中间分布重塑微调扩散模型", "title_en": "Fine-Tuning Diffusion Models via Intermediate Distribution Shaping", "authors": "Gautham Govind Anil,Shaan Ul Haque,Nithish Kannen,Dheeraj Nagaraj,Sanjay Shakkottai,Karthikeyan Shanmugam", "background": "扩散模型在各种领域中广泛应用于生成任务。预训练的扩散模型能够有效捕捉训练数据分布，但通常需要使用奖励函数来调整这些分布，以适应下游应用。在自回归生成的情境下，常用的策略梯度方法，例如近似策略优化(PPO)，由于计算不可行，无法直接应用于扩散模型，从而导致一些替代方案和放松方法的提出。本文融合了拒绝采样基础上的微调（RAFT）的不同变体为GRaFT，并表明这实际上执行了拥有重塑奖励的PPO。此外，通过进一步提出在中间噪声级别重塑分布的P-GRAFT方法，并通过实验证明了该方法能更有效地进行微调。进而通过偏置方差权衡的数学解释进一步阐述了这一点。受此启发，提出了逆噪声校正方法，以改进流动模型而不依赖显式奖励。研究结果在文本到图像(T2I)生成、布局生成、分子生成和无条件的图像生成任务上进行了评估。特别是在应用到Stable Diffusion 2时，本文框架相较于策略梯度方法在流行的T2I基准测试中提高了VQAScore，并在基础模型的基础上相对提高了8.81%。对于无条件的图像生成，逆噪声校正方法在降低每幅图像计算量的同时提高了生成图像的FID分数。", "innovation": "文章中提出的创新点包括：（1）统一了不同变体的RAFT方法为GRaFT，并证明了其隐式执行有重塑奖励的PPO；（2）提出了P-GRAFT，在中间噪声级别重塑分布，以实现更有效的微调；（3）通过数学上的偏置方差权衡解释了上述方法的有效性；（4）提出了逆噪声校正方法，改进流动模型而不需要显式奖励；（5）在多个生成任务上验证了方法的有效性，特别是提升了Stable Diffusion 2的生成效果，同时降低了计算量。", "conclusion": "本文融合了不同形式的RAFT，提出了GRaFT和P-GRAFT，通过重塑奖励改进扩散模型的微调过程，并通过对比实验展示了方法在多个任务上的优于策略梯度方法的效果，特别是提升了Stable Diffusion 2模型在T2I任务上的性能，并通过逆噪声校正方法降低了生成图像时的计算开销。"}
{"llm_update_time": "20251006", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.02790", "html_url": "https://arxiv.org/abs/2510.02790", "title": "MaskCD: 通过图像头部掩蔽对比解码减轻LVLM幻觉现象", "title_en": "MaskCD: Mitigating LVLM Hallucinations by Image Head Masked Contrastive Decoding", "authors": "Jingyuan Deng,Yujiu Yang", "background": "大型视觉-语言模型（LVLMs）在下游多模态任务中表现出色，但在性能增强的同时也出现了幻觉等问题。幻觉是指LVLMs生成与输入的视觉和文本内容矛盾的内容。已有的应对措施包括对比解码和注意力操纵，但对比解码方法难以构造合适的对比样本，而注意力操纵方法则不够稳定。", "innovation": "本文提出了一种新的方法——图像头部掩蔽对比解码（MaskCD），利用LVLMs中的‘图像头部’，通过掩蔽它们来构造对比样本进行对比解码。", "conclusion": "MaskCD在LLaVA-1.5-7b和Qwen-VL-7b上进行测试，使用CHAIR、POPE、AMBER和MME等基准测试，结果表明，MaskCD有效地缓解了幻觉现象并保留了LVLMs的通用能力。相关资源可以在指定网址获取。"}
{"llm_update_time": "20251006", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.02759", "html_url": "https://arxiv.org/abs/2510.02759", "title": "通过隐喻驱动设计原型设计数字社会空间：将空间概念转化为互动社会模拟", "title_en": "Prototyping Digital Social Spaces through Metaphor-Driven Design: Translating Spatial Concepts into an Interactive Social Simulation", "authors": "Yoojin Hong,Martina Di Paola,Braahmi Padmakumar,Hwi Joon Lee,Mahnoor Shafiq,Joseph Seering", "background": "社交媒体平台在通信中占据核心地位，但其设计仍然主要集中在参与度和规模方面。尽管研究人员提出了在线空间的新愿景，但在平台限制下将这些想法转化为原型依然困难重重。本文介绍了一种隐喻驱动的系统，帮助用户构想和探索新的社交媒体环境。该系统将用户的隐喻翻译成平台功能的结构化集合，并生成由LLM驱动的代理填充的互动模拟。研究基于这一方法，参与者创建并互动于模拟的社交媒体空间。研究发现，隐喻使用户能够表达不同的社交期望，并且模拟的真实感依赖于它对亲密性、参与度和历时参与等动态的捕捉程度。", "innovation": "提出了一种隐喻驱动的系统，将用户的隐喻转换为平台功能，并生成由LLM驱动的代理填充的互动模拟，帮助用户构想和探索新的社交媒体环境。这种方法通过数字模拟更大程度地扩展了可供未来社交媒体平台选择的设计空间，并提供了原型设计不同社会架构的强大工具。", "conclusion": "隐喻驱动的模拟可以成为一种强大的设计工具，用于原型设计替代社会架构，并扩展未来社交媒体平台的设计空间。"}
{"llm_update_time": "20251006", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.02719", "html_url": "https://arxiv.org/abs/2510.02719", "title": "TravelBench：探索大模型在低资源领域中的表现", "title_en": "TravelBench : Exploring LLM Performance in Low-Resource Domains", "authors": "Srinivas Billa,Xiaonan Jing", "background": "现有的大语言模型（LLM）基准测试未能充分捕捉到模型在低资源任务中的能力，使得在这些领域难以开发有效的解决方案。为此，研究人员收集了14个涉及7种常见自然语言处理（NLP）任务的旅行领域数据集，并对多种LLM在这些任务中的表现进行了分析，以确认通用基准测试结果不足以理解模型在低资源任务中的表现。尽管经过大量训练浮点运算（FLOPs），即开即用的大模型在复杂、特定领域的场景中会遇到性能瓶颈。进一步的研究发现，推理能力对于较小的大模型来说提供了更大的提升，使它们在某些任务上表现得更加出色。", "innovation": "研究人员通过收集匿名的真实世界场景中的14个旅行领域数据集，寻找大模型在低资源任务中的表现，确认通用基准测试结果不足以理解模型在低资源任务中的表现，揭示了即使经过大量训练，即开即用的大模型在复杂、特定领域的场景中也会遇到性能瓶颈，并且推理能力对较小的大模型的表现有更大的提升作用。这些发现对低资源领域的模型评估提供了新的视角和方法。", "conclusion": "研究结果表明，通用基准测试结果不足以理解模型在低资源任务中的表现，大模型在复杂、特定领域的场景中会遇到性能瓶颈，而推理能力对于较小的大模型在某些任务中的表现有重要作用。这强调了为特定领域开发专门的基准测试的重要性，以更好地评估和优化模型在低资源任务中的表现。"}
{"llm_update_time": "20251006", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.02734", "html_url": "https://arxiv.org/abs/2510.02734", "title": "SAE-RNA：一种稀疏自编码模型用于解释RNA语言模型表示", "title_en": "SAE-RNA: A Sparse Autoencoder Model for Interpreting RNA Language Model Representations", "authors": "Taehan Kim,Sangdae Nam", "background": "深度学习，特别是大型语言模型的发展，已经改变了生物分子建模。蛋白质预测（如ESM）激发了新兴的RNA语言模型，例如RiNALMo。然而，这些RNA语言模型内部如何以及以何种方式编码关于mRNA或ncRNA家族的信息仍然不清楚。本研究引入了SAE-RNA，一个可解释性模型，用于分析RiNALMo的表示并将其映射到已知的人类生物学特征。该方法将RNA可解释性视为预训练嵌入中的概念发现，无需进行端到端的再训练，并提供了一种实用的工具，用于探究RNA语言模型可能编码的关于ncRNA家族的信息。此外，该模型还可以扩展用于RNA组之间的对比分析，并支持对之前未识别的关系的假设生成。", "innovation": "SAE-RNA将RNA可解释性作为预训练嵌入中的概念发现，并提供了一种无需端到端再训练的方法来解析RNA语言模型中关于ncRNA家族的信息编码。此外，该模型还支持RNA组间对比分析和对未识别关系的假设生成。", "conclusion": "SAE-RNA提供了一种实用的工具，用于探究RNA语言模型可能编码的关于ncRNA家族的信息，并能扩展用于RNA组之间的对比分析，支持对之前未识别的关系的假设生成。"}
{"llm_update_time": "20251006", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.02803", "html_url": "https://arxiv.org/abs/2510.02803", "title": "工作区域挑战VLM轨迹规划：向缓解与稳健自主驾驶迈进", "title_en": "Work Zones challenge VLM Trajectory Planning: Toward Mitigation and Robust Autonomous Driving", "authors": "Yifan Liao,Zhen Sun,Xiaoyun Qiu,Zixiao Zhao,Wenbing Tang,Xinlei He,Xinhu Zheng,Tianwei Zhang,Xinyi Huang,Xingshuo Han", "background": "视觉语言模型（VLMs）因其强大的跨模态推理能力，在汽车制造商中逐渐被集成到自动驾驶中，以增强复杂环境下的规划能力。然而，工作区域（常包含不规则布局、临时交通控制和动态变化的几何结构）中的VLM轨迹规划能力还未被探索。研究发现，主流的VLMs在68.0%的情况下无法生成正确的轨迹。", "innovation": "首次系统性地研究VLMs用于工作区域的轨迹规划。提出了一种结合检索增强生成（RAG）的轨迹规划框架REACT-Drive。该框架利用VLMs将先前失败案例转换为约束规则和可执行的轨迹规划代码，并利用RAG在新场景中检索相似模式来指导轨迹生成。实验证明，与Qwen2.5-VL标准下的VLM基线相比，REACT-Drive将平均位移误差减少了约3倍，并且推理时间仅为0.58秒，比微调方法快得多。此外，通过在15个工作区域场景中使用真实车辆进行实验，进一步验证了REACT-Drive的实用性。", "conclusion": "通过提出REACT-Drive框架，建立了工作区域中的VLM轨迹规划，有效缓解了由VLMs带来的轨迹规划难题，显著提高了当前的VLM规划性能和运行效率，展示了其在实际应用中的强大潜力。"}
{"llm_update_time": "20251006", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.02810", "html_url": "https://arxiv.org/abs/2510.02810", "title": "解析Transformer：朝向绿色人工智能的CLEAR视角", "title_en": "Dissecting Transformers: A CLEAR Perspective towards Green AI", "authors": "Hemang Jain,Shailender Goyal,Divyansh Pandey,Karthik Vaidhyanathan", "background": "大规模语言模型（LLMs）的快速采用引发了重大的环境关切。与一次性训练成本不同，LLM推理在全球范围内持续进行，现在已经主导了人工智能的能源足迹。然而，大多数可持续性研究仅报告粗略的模型级指标，由于缺乏细化的测量方法，将能效视为次优先目标而非主要目标。", "innovation": "提出了新型的细粒度评估方法——Component-Level Energy Assessment via Repeated sampling（CLEAR），解决微秒级组件执行与毫秒级能耗传感器监测之间的时间不匹配问题。 CLEAR方法在四个不同架构类型的15个模型上进行评估，展示了超过90%的模型总能耗可以通过各个组件来捕获，同时确保每个组件的能量变化低于9.5%。实验揭示了注意力模块的能效消耗显著高于浮点运算（FLOP）的数量，表明单独依靠FLOPs未能准确反映组件级别的能源成本。", "conclusion": "通过CLEAR方法建立详细的组件级别能源基准，为通过组件优化构建高效变压器模型提供了初步见解，揭示了浮点运算与组件级能源消耗之间的不对称关系。"}
{"llm_update_time": "20251006", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.02798", "html_url": "https://arxiv.org/abs/2510.02798", "title": "OptunaHub：黑盒优化平台", "title_en": "OptunaHub: A Platform for Black-Box Optimization", "authors": "Yoshihiko Ozaki,Shuhei Watanabe,Toshihiko Yanase", "background": "黑盒优化（BBO）在诸如自动机器学习（AutoML）和材料信息学等领域中推动了进展，但研究努力往往在不同领域之间碎片化。", "innovation": "OptunaHub是一个社区平台，旨在集中管理和基准测试BBO方法，提供统一的Python接口、贡献者包注册表和网络界面，以促进搜索和跨域研究。该平台的目的是促进贡献和应用的良性循环。", "conclusion": "OptunaHub的源代码可以在GitHub（Optuna组织）的optunahub、optunahub-registry和optunahub-web仓库中公开获得，可供公众使用。"}
{"llm_update_time": "20251006", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.02795", "html_url": "https://arxiv.org/abs/2510.02795", "title": "帕累托最优的非统一语言生成", "title_en": "Pareto-optimal Non-uniform Language Generation", "authors": "Moses Charikar,Chirag Pabbaraju", "background": "Kleinberg和Mullainathan（2024）提出了一种语言生成的极限模型：给定可数的语言集合和一个对手按某种语言L中的字符串枚举的序列，目标是从目标语言生成新的字符串，确保在某个有限时间之后生成的所有字符串都是有效的。Li等人（2024）和Charikar与Pabbaraju（2024）展示了这种模型中强大的非均匀生成保证，给出了生成新有效字符串的算法，这些算法在看到特定数量的不同输入字符串后（取决于L及其集合，但不依赖于枚举顺序）生成新的有效字符串。但对这些工作的生成时间仍然是语言特定的，不一定达到最优。", "innovation": "本文研究非均匀语言生成的帕累托最优性。我们提出了一种算法，其生成时间$ t^\text{star}(L) $几乎是帕累托最优的：对于任何其他算法，如果其对某一语言L的生成时间严格小于$ t^\text{star}(L) $，那么必然存在另一语言L'，其生成时间也严格劣于$ t^\text{star}(L') $。帕累托最优性是达到非均匀生成最佳效果的基本情形。论文中的算法框架还有助于进一步应用于存在噪声以及统一体生成的实际应用场景。", "conclusion": "我们的算法不仅达到了帕累托最优，还能够适应实际应用中的噪声和统一体生成需求，提供了在这些条件下的最优非均匀语言生成算法。"}
{"llm_update_time": "20251006", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.02830", "html_url": "https://arxiv.org/abs/2510.02830", "title": "评估大型语言模型在IUCN红皮书物种信息中的应用", "title_en": "Evaluating Large Language Models for IUCN Red List Species Information", "authors": "Shinya Uryu", "background": "大型语言模型（LLMs）正在迅速应用于保护领域以应对生物多样性危机，但它们评估物种的可靠性尚未确定。本文系统性地验证了五个主要模型在21,955个物种上的表现，涵盖IUCN红皮书评估的四个核心组成部分：分类学、保护状况、分布和威胁。", "innovation": "研究揭示了一个关键的悖论：模型在分类学分类上表现出色（94.9%），但在保护推理（状态评估方面仅为27.2%）上却表现不佳。这一知识-推理缺口在所有模型中普遍存在，表明存在固有的架构限制，而不仅仅是数据限制。此外，模型通过系统性偏见偏好迷人脊椎动物，潜在地加剧了现有的保护不平等。", "conclusion": "这些发现为负责任的LLM部署设定了界限：它们是强大的信息检索工具，但在判断型决策方面需要人类监管。推荐采用混合方法，其中LLM增强专家能力，但人类专家保留风险评估和政策制定的独家权威。"}
{"llm_update_time": "20251006", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.02763", "html_url": "https://arxiv.org/abs/2510.02763", "title": "融合多光谱和超光谱卫星数据以利用自我监督和分层深度学习进行有害藻华监测", "title_en": "Fusing Multi- and Hyperspectral Satellite Data for Harmful Algal Bloom Monitoring with Self-Supervised and Hierarchical Deep Learning", "authors": "Nicholas LaHaye,Kelly M. Luis,Michelle M. Gierach", "background": "文章背景在于探讨如何利用多传感器卫星数据检测和绘制有害藻华（HAB）的严重程度和种类。现有的方法大多需要针对每种仪器进行标注数据集，这在标注数据稀缺的环境中相当困难。本文旨在提供一种自监督机器学习框架，通过整合各类卫星反射数据与太阳诱导荧光（SIF）数据，无需标注数据集即可生成HAB的严重性和种类化产品，为在全球范围内的水生生物地球化学操作化过程中进行探索性分析提供支撑。", "innovation": "本文创新点包括：1. 提出了一种名为SIT-FUSE的自监督机器学习框架，用于融合多传感器卫星数据进行HAB检测和分析；2. 通过结合反射光谱数据和太阳诱导荧光数据，实现了在标注数据稀缺环境下的HAB监测；3. 使用自我监督表示学习和分层深度聚类技术，能够将浮游植物浓度和种类分割成可解释的类别；4. 验证结果与墨西哥湾和南加州的现场数据高度一致，证明了方法的有效性；5. 该工作不仅提高了HAB监测的可扩展性，还为实现自我监督学习在水生生物地球化学中的操作化做出了关键贡献。", "conclusion": "本文展示了自监督机器学习框架SIT-FUSE在多传感器卫星数据融合中检测和映射有害藻华严重性和种类方面的工作。通过对多种浮游植物指标的一致性验证，证明了该方法的有效性和实用性。未来的工作将进一步探索不同环境条件下的HAB监测，从而推动这一技术在实际应用中的操作化。"}
{"llm_update_time": "20251006", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.02869", "html_url": "https://arxiv.org/abs/2510.02869", "title": "表现美：迈向参与但客观的潜在美学", "title_en": "Representing Beauty: Towards a Participatory but Objective Latent Aesthetics", "authors": "Alexander Michael Rusnak", "background": "虽然美仍然是一个具有文化及个人经验吸引力但哲学上难以捉摸的概念，深度学习系统却越来越显示出模仿审美判断的能力。本文探讨了神经网络如何在处理广泛形式多样的物体时依然能够表现美的能力。", "innovation": "作者利用跨模型表示收敛的最新研究成果，展示了具有审美内容的图像能在不同数据和模态训练的模型之间产生更相似和协调的表示，而非审美图像则不能。这一发现表明美的形式结构具有现实基础而非仅仅是社会构建价值观的表现。", "conclusion": "研究结果表明，人类-机器合作创作不仅是可能的，更是基础性的，而美在此过程中既在文化生产也有机器感知中作为一个目标吸引物发挥重要作用。"}
{"llm_update_time": "20251006", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.02848", "html_url": "https://arxiv.org/abs/2510.02848", "title": "Flamed-TTS: Flow Matching Attention-Free Models for Efficient Generating and Dynamic Pacing Zero-shot Text-to-Speech", "title_en": "Flamed-TTS: Flow Matching Attention-Free Models for Efficient Generating and Dynamic Pacing Zero-shot Text-to-Speech", "authors": "Hieu-Nghia Huynh-Nguyen,Huynh Nguyen Dang,Ngoc-Son Nguyen,Van Nguyen", "background": "零样本文本到语音（TTS）技术近年来取得了显著的进展，使得模型能够使用简短的、有限语境的提示从文本中合成语音。这些提示作为语音示例，使模型能够在无需大量特定说话人数据的情况下模仿说话人身份、语音节奏和其他特征。尽管最近结合语言模型、扩散和流匹配的方法在零样本TTS中证明了其有效性，但仍存在合成不可靠、由于 token 重复或意想不到的内容转移导致的问题，以及推理速度慢和大量计算开销。此外，重要的时间多样性仍然被大量忽视，这对于提高合成语音的自然度至关重要。", "innovation": "我们提出了 Flamed-TTS，一种旨在强调低计算成本、低延迟和高语音保真度的新型零样本 TTS 框架，同时保留丰富的时序多样性。通过改变流匹配训练范式，并同时引入离散和连续的表示，对应于语音的不同属性。实验结果表明，Flamed-TTS 在可懂度、自然度、说话人相似性、声学特性保留和动态节奏方面超越了现有的最先进模型。值得注意的是，Flamed-TTS 达到了 4% 的最佳 WER，同时保有较低的推理延迟和高保真度的生成语音。", "conclusion": "Flamed-TTS 在可懂度、自然度、说话人相似性、声学特性保留和动态节奏方面的表现超过了最先进的零样本 TTS 模型，同时保证了低延迟和高保真度的生成语音。此外，代码和音频样本可在我们的演示页面获取。"}
{"llm_update_time": "20251006", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.02914", "html_url": "https://arxiv.org/abs/2510.02914", "title": "FeDABoost：具备自适应提升的公平感知联邦学习", "title_en": "FeDABoost: Fairness Aware Federated Learning with Adaptive Boosting", "authors": "Tharuka Kasthuri Arachchige,Veselka Boeva,Shahrooz Abghari", "background": "这篇文章关注在非IID（独立同分布）场景下提升联邦学习（FL）的性能和公平性。传统的联邦学习在数据分布不均匀的情况下，部分客户端的数据可能对全局模型贡献较小，导致性能和公平性下降。", "innovation": "提出了FeDABoost，一种新颖的联邦学习框架，结合了动态提升机制和自适应梯度聚合策略。该方法借鉴了Multiclass AdaBoost（SAMME）算法的加权机制，给本地错误率低的客户端分配更高的权重，从而促进更可靠地贡献到全局模型。同时，通过调整焦点损失聚焦参数动态提升表现不佳的客户端，强化难以分类的局部训练样本。", "conclusion": "实验结果表明，FeDABoost在MNIST、FEMNIST和CIFAR10三个基准数据集上实现了更好的公平性与竞争力，优于FedAvg和Ditto等方法。"}
{"llm_update_time": "20251006", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.02809", "html_url": "https://arxiv.org/abs/2510.02809", "title": "时间序列在线区间预测中的相关性感知阈值调整", "title_en": "Relevance-Aware Thresholding in Online Conformal Prediction for Time Series", "authors": "Théo Dupuy,Binbin Xu,Stéphane Perrey,Jacky Montmain,Abdelhak Imoussaten", "background": "近年来，不确定性量化在机器学习领域受到了广泛关注。特别是，区间一致性预测（Conformal Prediction, CP）成为该领域的研究热点。对于时间序列数据，某一种形式——在线区间一致性预测（Online Conformal Prediction, OCP）——被提出以应对随时间变化的数据分布问题。传统的OCP方法在更新阈值时通常只考虑预测区间的覆盖有效性，而忽略预测区间的实用性。近年来，一些新的OCP方法虽然提供了长期覆盖保证并且能够生成更具有信息量的区间，但这些方法在更新阈值步骤中仍然主要关注于预测区间的有效性，即真实值是否位于区间内，而忽略了预测区间的实际意义。本文即是基于上述背景进行研究，旨在应对这一问题。", "innovation": "本文提出的创新点在于优化了阈值更新步骤。具体地，文章提出用一种更广泛的功能类（多于二元评价方法）来评估预测区间的实用性，从而避免突变的阈值变化，可能使得预测区间更加狭窄。实验结果表明，这些新的函数方法相比现有的OCP方法能够在保持覆盖效度的同时生成更紧的区间。", "conclusion": "本文提出了一种相关性感知的OCP方法，通过改进阈值更新步骤，利用函数类来量化预测区间的实用性，从而防止突变的阈值变化，导致更紧的预测区间。实验表明，这些方法能够在保持高覆盖有效性的同时提高预测区间的实用性。"}
{"llm_update_time": "20251006", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.02922", "html_url": "https://arxiv.org/abs/2510.02922", "title": "使用大型视觉语言模型进行多模态颈动脉风险分类：基准测试、微调和临床认知", "title_en": "Multimodal Carotid Risk Stratification with Large Vision-Language Models: Benchmarking, Fine-Tuning, and Clinical Insights", "authors": "Daphne Tsolissou,Theofanis Ganitidis,Konstantinos Mitsis,Stergios CHristodoulidis,Maria Vakalopoulou,Konstantina Nikita", "background": "颈动脉动脉粥样硬化疾病的可靠风险评估仍然是一个重大的临床挑战，因为它要求以透明和可解释的方式整合临床和成像信息。这项研究探讨了最先进的和最近的大规模视觉语言模型（LVLMs）在将超声成像（USI）与结构化的临床、人口统计、实验室和蛋白质生物标记数据综合，以进行颈动脉斑块评估方面的潜力。", "innovation": "本研究提出了一种基于访谈式问答序列模拟现实诊断场景的框架，比较了多种开源LVLMs，包括通用和医学专调模型，发现即使是非常强大的模型，在准确识别成像模态和部位方面表现不佳，风险分类准确性也很低。为解决这一局限性，研究将LLaVa-NeXT-Vicuna模型用低秩适应（LoRA）适配到超声领域，大幅提高了中风风险分层的准确性。此外，将多模态文本形式的表格数据集成，进一步提升了专一性和平衡准确性，性能优于之前基于同一数据集训练的卷积神经网络（CNN）基准。", "conclusion": "研究结果强调了LVLMs在基于超声的心血管风险预测中的潜力和局限性，强调了多模态融合、模型校准和领域适应对于临床转化的重要性。"}
{"llm_update_time": "20251006", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.02811", "html_url": "https://arxiv.org/abs/2510.02811", "title": "来自社交媒体的可解释文本驱动的人格评估计算框架", "title_en": "A Computational Framework for Interpretable Text-Based Personality Assessment from Social Media", "authors": "Matej Gjurković", "background": "人格是指个体在行为、思维和情感方面的差异。随着数字足迹（尤其是社交媒体）的不断增长，自动化的人格评估方法变得越来越重要。自然语言处理（NLP）能够对未经结构化处理的文本数据进行分析，以识别人格线索。不过，现有的大部分挑战在于缺乏大规模且标注良好且覆盖充分的人格数据集，以及人格心理学与NLP之间的断层，这限制了模型的准确性和可解释性。因此，本论文提出了两个数据集——MBTI9k和PANDORA，从Reddit平台收集，这为这个问题带来了解决方案", "innovation": "本论文介绍了两个新的数据集——MBTI9k和PANDORA，它们是从Reddit收集的数据，用户在此平台上保持匿名并进行多样化的讨论。PANDORA数据集中包含了超过1700万条评论及来自超过10000名用户的430张人格评估图，涵盖了MBTI和大五人格模型，并集成了一些人口统计信息。这些数据集解决了数据量、质量以及标签覆盖率的问题。此外，本论文还开发了一个名为SIMPA的计算框架，用于可解释的人格评估，通过将用户生成的陈述与验证问卷中的项目进行匹配。SIMPA使用机器学习和语义相似性，其评估结果与人类评估相当，保持了高可解释性和高效性", "conclusion": "尽管本论文的重点在于人格评估，但SIMPA框架在多个方面显示出了其广泛的应用潜力。通过其模型无关性、多层次线索检测及其可扩展性，它还能够应用于涉及复杂标签分类树的研究和应用，且适用于各变量线索与目标概念关联变化的场景。这意味着SIMPA能够在多个领域提供有用的、高效率且具有解释性的分析工具"}
{"llm_update_time": "20251006", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.02839", "html_url": "https://arxiv.org/abs/2510.02839", "title": "基于频率自适应学习的知识引导电池健康预测建模", "title_en": "Knowledge-Aware Modeling with Frequency Adaptive Learning for Battery Health Prognostics", "authors": "Vijay Babu Pamshetti,Wei Zhang,Sumei Sun,Jie Zhang,Yonggang Wen,Qingyu Yan", "background": "电池健康预测对于现代能源系统中的安全性、效率和可持续性至关重要。然而，由于电池退化行为的复杂性，包括非线性、噪声、容量再生等因素，实现准确和可靠的预测一直具有挑战性。现有数据驱动模型能够捕捉时间上的退化特征，但通常缺乏知识指导，导致长期健康预测不可靠。", "innovation": "提出了一种名为Karma的知识引导模型，该模型包含频率自适应学习机制，用于电池容量估计和剩余寿命预测。该模型首先对信号进行分解，以在不同频段中提取电池信号。开发了一种双流深度学习架构，其中一条流捕获长期低频退化趋势，另一条流建模高频短期动态。Karma通过知识调节预测，其中电池退化基于经验研究被建模为双指数函数。通过粒子滤波优化知识参数，以确保物理上一致且可靠的预测和不确定性量化。实验表明Karma在电池健康预测方面具有优越性能，在两个主流数据集上，平均误差分别减少了50.6%和32.6%，比最先进的算法更优。", "conclusion": "实验研究证明了Karma的优越性能，其在两种主流数据集上分别比最先进的算法将电池健康预测的平均误差降低了50.6%和32.6%，展示了Karma的稳健性、普适性以及在各种应用中实现更安全、更可靠电池管理的潜力。"}
{"llm_update_time": "20251006", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.02896", "html_url": "https://arxiv.org/abs/2510.02896", "title": "Entropy Regularized Linear-Quadratic Control with Multiplicative Noise: Global Convergence of Policy Gradient", "title_en": "Global Convergence of Policy Gradient for Entropy Regularized Linear-Quadratic Control with multiplicative noise", "authors": "Gabriel Diaz,Lucky Li,Wenhao Zhang", "background": "强化学习（RL）已成为在动态环境中进行顺序决策的强大力量，尤其当系统参数未知时。本文研究了在无限时间范围内，具有乘性噪声的熵正则化线性二次控制（LQC）问题的基于RL的控制方法。传统RL算法在面对非凸问题时难以保证全局收敛性，特别是当系统参数未知的情况下，研究更具挑战性。", "innovation": "文章将正则化策略梯度（RPG）算法适应到随机最优控制场景中，证明在梯度支配和近连续条件下，RPG可以全局收敛。在此基础上，通过零阶优化方法引入了一种新颖的无模型RL算法——样本基于正则化策略梯度（SB-RPG），该算法在未知系统参数的情况下仍然具有全局收敛的强理论保证。通过使用熵正则化加速收敛，并解决RL中的探索与利用之间的权衡。", "conclusion": "数值仿真验证了理论结果，并展示了SB-RPG在未知参数环境中的有效性。"}
{"llm_update_time": "20251006", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.02967", "html_url": "https://arxiv.org/abs/2510.02967", "title": "将大型语言模型扎根于临床证据：一种用于查询英国NICE临床指南的检索增强生成系统", "title_en": "Grounding Large Language Models in Clinical Evidence: A Retrieval-Augmented Generation System for Querying UK NICE Clinical Guidelines", "authors": "Matthew Lewis,Samuel Thio,Richard JB Dobson,Spiros Denaxas", "background": "本研究介绍了一种检索增强生成（RAG）系统，该系统使用大型语言模型（LLMs）查询英国国民保健与护理卓越机构（NICE）的临床指南。这些指南内容庞大，结构复杂，在时间受限的健康医疗系统中使用存在困难。该研究通过创建一个能够根据自然语言查询提供精准信息的系统来解决这一挑战。", "innovation": "该系统采用了由混合嵌入机制组成的检索架构，并在10,195个文本片段（来自300个指南）的数据库上进行了评估。系统在查询测试中的绩效表现优良（Mean Reciprocal Rank (MRR) 为0.814，第一段的召回率为81%，前十个检索结果中的召回率为99.1%）。在基于人工收集的70个问答对数据集的生成阶段中，RAG增强的模型在表现上有了显著提升，其中RAG增强的O4-Mini模型的一致性提高了64.7个百分点，达到99.5%，并且在两种指标上均优于医分专注的Meditron3-8B大语言模型，从而证明了该系统能够通过基于相关材料防止信息捏造。这项研究证实RAG是一种有效、可靠且可扩展的生成AI应用于医疗的途径。", "conclusion": "该研究确立了RAG作为一种有效、可靠且可扩展的方法，将生成式AI应用于医疗的具体应用，使得经济高效的医学指南访问成为可能。"}
{"llm_update_time": "20251006", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.02973", "html_url": "https://arxiv.org/abs/2510.02973", "title": "基于温度和湿度的物联网与机器学习方法对遗产保护中的腐蚀风险评估", "title_en": "Corrosion Risk Estimation for Heritage Preservation: An Internet of Things and Machine Learning Approach Using Temperature and Humidity", "authors": "Reginald Juan M. Mercado,Muhammad Kabeer,Haider Al-Obaidy,Rosdiadee Nordin", "background": "对具有钢质结构的文化重要遗产建筑物（如菲律宾圣塞巴斯蒂安大教堂）进行前瞻性的保护需要准确的腐蚀预测。这项研究开发了连接LoRa无线通信的物联网硬件系统，用于监测具有钢结构的历史建筑。基于物联网系统生成的三年数据集，建立了一种机器学习框架，仅使用温度和相对湿度数据预测大气腐蚀率。", "innovation": "开发了一种仅依赖温度和湿度数据的机器学习框架，用于预测大气腐蚀率，该框架通过Streamlit仪表板和ngrok隧道提供实时腐蚀监测和可操作的保护建议。这种方法在资源受限的遗产保护地点具有可扩展性和成本效益，并且通过基本气象数据实现了预测准确性，支持全球文化重要结构的前瞻性保护，无需广泛的传感器网络。", "conclusion": "通过基本的气象数据进行先进的回归分析，该方法可以准确地预测腐蚀风险，提供了无需广泛传感器网络就能进行文化遗产保护的简便方法，有助于全球范围内文化遗产的前瞻性保护。"}
{"llm_update_time": "20251006", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.02906", "html_url": "https://arxiv.org/abs/2510.02906", "title": "FinReflectKG - MultiHop: 财务问答基准以知识图谱证据进行推理", "title_en": "FinReflectKG - MultiHop: Financial QA Benchmark for Reasoning with Knowledge Graph Evidence", "authors": "Abhinav Arun,Reetu Raj Harsh,Bhaskarjit Sarmah,Stefano Pasquali", "background": "金融披露中的多跳推理通常是一个检索问题，相关事实分散在不同的部分、文件、公司和年份中，这使得大型语言模型（LLMs）在嘈杂的上下文中进行导航时消耗大量令牌。缺乏精准的知识图谱（KG）指导，即使是强大的推理模型也难以回答问题或耗费过多令牌。KG链接的证据使模型能够专注于合成已检索的事实。", "innovation": "该研究构建了FinReflectKG - MultiHop基准，基于一收录了标普100指数公司2022-2024年财务报表的时序财务KG，提取高频的2-3跳子图模式，生成具有确切支持证据的财务分析师风格的问题，并提出两阶段管道：首先通过特定模式提示生成问答对，然后通过多标准质量控制评估确保问答的有效性。通过三个控制检索场景（精确KG链接路径、仅文本页面窗口、带有随机化和干扰的页面窗口）评估模型表现，KG指导的精确检索在FinReflectKG - MultiHop问答基准数据集上显著提升了正确率（约24%），并减少了令牌使用量（约84.5%）。", "conclusion": "这项工作强调了知识图谱在连接多跳财务问答证据中的关键作用，同时发布了基准数据集的一部分（555组问答对），以促进进一步的研究。"}
{"llm_update_time": "20251006", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.02999", "html_url": "https://arxiv.org/abs/2510.02999", "title": "未针对特定目标的监狱突破攻击", "title_en": "Untargeted Jailbreak Attack", "authors": "Xinzhe Huang,Wenjing Hu,Tianhang Zheng,Kedong Xiu,Xiaojun Jia,Di Wang,Zhan Qin,Kui Ren", "background": "目前，基于梯度的大型语言模型（LLM）监狱突破攻击大多通过优化对抗后缀，使LLM的输出符合预定义的目标回应。然而，这些方法受限于预定义目标的优化目标，这限制了它们的总体攻击效果，并且需要大量的优化迭代来弥补预设目标与原始模型响应之间的巨大差距，导致攻击效率低下。", "innovation": "本文提出了第一个基于梯度的未针对特定目标的监狱突破攻击（UJA），旨在引发一种不安全的回应而不强加任何预定义模式。通过将攻击目标量化为最大化LLM回应的不安全概率，并将其分解为两个可优化的子目标以优化最优有害回应和对应的对抗前缀。与针对特定目标的监狱突破攻击相比，UJA不受限制的攻击目标显著扩展了搜索空间，使得对LLM的探索更加灵活和有效。", "conclusion": "评估结果表明，与I-GCG和COLD-Attack等前沿的基于梯度的攻击相比，UJA在仅100次优化迭代的情况下，对最近安全对齐的LLM可以实现超过80%的攻击成功率，效率高出20%以上。"}
{"llm_update_time": "20251006", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.03003", "html_url": "https://arxiv.org/abs/2510.03003", "title": "从高频传感器到中午报告：利用迁移学习进行航运动力预测", "title_en": "From high-frequency sensors to noon reports: Using transfer learning for shaft power prediction in maritime", "authors": "Akriti Sharma,Dogan Altan,Dusica Marijan,Arnbjørn Maressa", "background": "由于全球海运量的增长，能源优化已成为降低运营成本和提升效率的关键。螺旋桨功率是发动机到螺旋桨的机械功率传输，直接影响航油消耗，因此其准确预测是优化船舶性能的关键步骤。动力消耗与船舶速度、每分钟螺旋桨旋转次数及天气、海况密切相关。高频获取操作数据可以提高预测准确性，但高质量传感器数据获取往往不可行且成本高昂，中午报告成为可行的替代方案。", "innovation": "本文提出了一种基于迁移学习的方法，用于预测船舶螺旋桨功率。初始模型在高频数据上训练，然后使用其他船舶的低频每日中午报告进行微调。该方法在姊妹船（相同尺寸和配置）、相似船（稍大且发动机不同）和不同船（不同尺寸和配置）上进行了测试，结果显示，在仅使用中午报告数据训练的模型基础上，姊妹船的绝对百分比误差降低了10.6%，相似船降低了3.6%，不同船降低了5.3%。", "conclusion": "该研究通过利用中午报告数据，结合迁移学习方法，为提高船舶螺旋桨功率预测精度提供了一种有效手段。"}
{"llm_update_time": "20251006", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.02902", "html_url": "https://arxiv.org/abs/2510.02902", "title": "DMark: Order-Agnostic Watermarking for Diffusion Large Language Models", "title_en": "DMark: Order-Agnostic Watermarking for Diffusion Large Language Models", "authors": "Linyu Wu,Linhao Zhong,Wenjie Qu,Yuexin Li,Yue Liu,Shengfang Zhai,Chunhua Shen,Jiaheng Zhang", "background": "差分大语言模型（dLLMs）提供了比自回归模型更快的生成速度，同时保持了类似的质量，但现有的水印方法无法在它们上面工作，因为它们是非顺序解码的。与自回归模型从左到右生成标记不同，dLLMs可以在任意顺序最后确定标记，破坏了传统水印基于的因果设计。因此，需要提出专为dLLMs设计的第一个水印框架。", "innovation": "DMark引入了三种互补的策略来恢复水印的检测能力：预测性水印在实际上下文不可用时使用模型预测的标记；双向水印利用与扩散解码特有的前后依赖关系；预测性双向水印结合了上述两种方法以最大化检测强度。实验结果表明，在1%的误报率下，DMark的检测率达到92.0%-99.5%，同时保持文本质量，而传统的简单水印方法的检测率仅为49.6%-71.2%。此外，DMark还证明了对文本操纵的高度鲁棒性，这表明有效的水印对于非自回归语言模型是可以实现的。", "conclusion": "DMark为非自回归的语言模型提供了有效的水印解决方案，实现了高检测率同时保持了文本质量，并展示了对文本操纵的鲁棒性。"}
{"llm_update_time": "20251006", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.03049", "html_url": "https://arxiv.org/abs/2510.03049", "title": "多事件视频生成中事件何时切换？", "title_en": "When and Where do Events Switch in Multi-Event Video Generation?", "authors": "Ruotong Liao,Guowen Huang,Qing Cheng,Thomas Seidl,Daniel Cremers,Volker Tresp", "background": "随著问题变得更具挑战性，文本到视频（T2V）生成有了显著的发展，尤其是当长视频需要表现多个具有时间连贯性和可控内容的连续事件时。当前的多事件生成方法并未关注事件转换的内在因素。这项研究旨在探讨多事件文本到视频生成中多事件提示何时及如何控制事件转换。", "innovation": "该研究引入了MEve，一个自设的多事件提示套件，用于评估多事件文本到视频生成，并系统地研究了OpenSora和CogVideoX两大模型系列。实验结果强调了早期去噪步骤和区块化模型层的重要性，揭示了多事件视频生成的关键因素，并指出了未来模型中多事件条件的可能性。", "conclusion": "深入研究表明，在T2V生成过程中，早期介入至关重要，特别是在去噪步骤和区块化模型层中，这有助于揭示多事件视频生成的关键因素，并为未来模型多事件条件提供了新的方向。"}
{"llm_update_time": "20251006", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.02945", "html_url": "https://arxiv.org/abs/2510.02945", "title": "随机游动风险测度：朝向持续强化学习的风险感知基础", "title_en": "Ergodic Risk Measures: Towards a Risk-Aware Foundation for Continual Reinforcement Learning", "authors": "Juan Sebastian Rojas,Chi-Guhn Lee", "background": "持续强化学习（continual RL）旨在形式化终身学习和永不停歇的适应性的概念。目前的研究主要通过无风险决策的视角探索持续强化学习，使智能体致力于优化长期表现的预期（或平均值）。然而，现有的风险测度理论在非持续风险感知强化学习中被广泛应用，但当前形式与持续学习的环境不符。因此，需要对这种理论进行扩展以适应持续学习环境。这一研究旨在通过风险感知的视角为持续强化学习提供一个正式的理论框架，探索如何使智能体优化长期表现的风险调整度量，而不仅仅是预期奖励。", "innovation": "该研究首次以风险感知的视角探讨了持续强化学习的正式理论，提出了一种新的随机游动风险测度类，使其与持续学习环境兼容。这种新的风险测度能够使智能体在不断学习过程中平衡保留有用信息和适应新情况之间的关系。这一创新为现有的风险感知强化学学习提供了一个新的理论基础，也展示了这种新的风险测度在持续强化学习中的实用性和理论准确性。", "conclusion": "该研究基于风险感知视角下的新的随机游动风险测度，为持续强化学学习提供了一个可行的理论框架。通过案例研究和实验结果，证明了这种新的风险测度在持续强化学习中的实际有效性和理论合理性。"}
{"llm_update_time": "20251006", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.03038", "html_url": "https://arxiv.org/abs/2510.03038", "title": "CHORD：利用设备-云协作定制混合精度离线模型以实现序列推荐", "title_en": "CHORD: Customizing Hybrid-precision On-device Model for Sequential Recommendation with Device-cloud Collaboration", "authors": "Tianqi Liu,Kairui Fu,Shengyu Zhang,Wenyan Fan,Zhaocheng Du,Jieming Zhu,Fan Wu,Fei Wu", "background": "随着移动设备能力的提升，直接在设备上部署重排序模型成为可能，使得实时上下文推荐成为现实。然而，当模型从云端迁移到设备上时，资源异构性不可避免地导致了需要对模型进行压缩。最近的量化方法在高效部署方面显示出潜力，但却忽略了设备特定的用户兴趣，导致推荐精度下降。尽管在设备上进行微调可以捕捉个性化用户的偏好，但这会增加额外的计算负担，通过局部重新训练。为了解决这些问题，本文提出了一种利用设备-云协作定制混合精度离线模型以实现序列推荐的框架（CHORD）。", "innovation": "我们提出了利用通道混精度量化实现个性化和资源适配部署的框架CHORD。该框架在云端通过辅助超网络模块识别用户特定的关键参数，并对模型参数敏感性进行分析，确保粒度级别的映射精细化。通过设备上的混精度量化，CHORD实现了动态模型适应和加速推理，而无需反向传播。为了减少通信开销，CHORD仅用2位通道而不是32位权重编码量化策略。", "conclusion": "我们在三个实际数据集上使用两种流行的模型（SASRec和Caser）进行实验结果表明，CHORD在准确性、效率和适应性方面具有优势。"}
{"llm_update_time": "20251006", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.02915", "html_url": "https://arxiv.org/abs/2510.02915", "title": "WavInWav: 通过可逆神经网络的时间域语音隐藏", "title_en": "WavInWav: Time-domain Speech Hiding via Invertible Neural Network", "authors": "Wei Fan,Kejiang Chen,Xiangkun Wang,Weiming Zhang,Nenghai Yu", "background": "数据隐藏在数字媒体安全通信中至关重要，近年来深度神经网络（DNN）的发展提供了更有效的秘密信息嵌入方法。然而，现有的音频隐藏方法在恢复秘密音频时往往质量不佳，这是因为它们在时间-频率关系建模方面的局限性。本文探讨了这些局限性，并提出了一种基于DNN的新方法。通过使用基于流的可逆神经网络建立秘密音频、载体音频和嵌入音频之间的直接联系，增强了消息嵌入和提取的可逆性。为了应对时间-频率转换过程中常见的问题，这些问题在恢复时会降低秘密音频的质量，本文在时间域信号上实现了时间-频率损失。该方法不仅保留了时间-频率约束的益处，还增强了消息恢复的可逆性，这在实际应用中至关重要。此外，还添加了加密技术以保护隐藏数据不受未授权访问。在VCTK和LibriSpeech数据集上的实验结果显示，本文方法在主观和客观指标上均优于以往方法，并对各种类型的噪声具有鲁棒性，进一步证明了其在定向安全通信场景中的实用性。", "innovation": "1. 使用基于流的可逆神经网络，直接建立了秘密音频、载体音频和嵌入音频之间的联系，增强了消息嵌入和提取的可逆性。\n2. 在时间域信号上实现时间-频率损失，解决了传统方法恢复时降质的问题，既保留了时间-频率约束的益处，又增强了消息恢复的可逆性。\n3. 增加了加密技术以保护隐藏数据不受违规访问。\n4. 实验结果表明，该方法在VCTK和LibriSpeech数据集上优于之前的方法，并对噪声具有鲁棒性。", "conclusion": "本文提出了一种新颖的时间域语音隐藏方法，通过可逆神经网络增强了消息嵌入和提取的可逆性，并通过时间-频率损失和加密技术提升了恢复的音频质量。实验结果验证了该方法的有效性和鲁棒性，表明其在定向安全通信中的实用价值。"}
{"llm_update_time": "20251006", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.02855", "html_url": "https://arxiv.org/abs/2510.02855", "title": "基于约束满足的方法解决Wordle：新型启发式与跨词库验证", "title_en": "Constraint Satisfaction Approaches to Wordle: Novel Heuristics and Cross-Lexicon Validation", "authors": "Jahidul Arafat,Fariha Tasmin,Sanjaya Poudel,Kamrujjaman,Eftakhar Ahmed Arnob,Ahsan Habib Tareq", "background": "Wordle提供了一个丰富的算法测试平台，用于解决约束满足问题（CSP）。现有的解决方法依赖于信息论熵最大化或基于频率的启发式方法，而不包括对约束的正式处理。这篇论文首次提出了全面的Wordle CSP形式，并引入了新颖的约束感知解决策略。具体包括CSP意识熵，这是一种在约束传播后计算信息增益的方法，以及一个结合贝叶斯单词频率先验与逻辑约束的概率CSP框架。通过2,315个英语单词的评估表明，CSP意识熵平均需要3.54次猜测，成功率高达99.9%，相较于前向检查算法，在提高1.7%的成功率的同时，运行时间快46%（每次猜测时间为12.9毫秒对比23.7毫秒）。在10%的噪声下，CSP意识方法保持5.3个百分点的优势，并且在所有噪声水平下，概率CSP都取得了100%的成功率，使用约束恢复机制。跨词库验证在500个西班牙语单词上实现了88%的成功率，验证了CSP原则在不同语言中的通用性。", "innovation": "这篇论文的主要创新点包括：1) 首次全面引入CSP形式来解决Wordle问题，并提出了一系列新的约束感知启发式策略，如CSP意识熵。2) 提出一个概率CSP框架，结合了贝叶斯先验概率和逻辑约束。3) 通过控制实验和跨词库验证，提供了新的性能基准，证明了结构化谜题解决领域中基于约束满足的分析方法优于经典的信息论和基于学习的方法。4) 开放源代码实现包含34个单元测试，代码覆盖率91%，提供了可重复的基础设施，推动了CSP研究的进步。", "conclusion": "这篇论文建立了一种新的结构化谜题解决领域的基准，展示了一种新的性能表现，系统地利用了形式化处理的CSP、约束感知启发式方法、概率逻辑结合以及跨词库验证，证明了基于约束满足的方法在这种领域中的优越性，超越了传统的基于信息论和基于学习的方法。开放源代码实现提供了一个可重复使用的平台，增强了后续研究的可能性。"}
{"llm_update_time": "20251006", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.02978", "html_url": "https://arxiv.org/abs/2510.02978", "title": "AI生成的儿童性剥削材料——有害之处何在？", "title_en": "AI Generated Child Sexual Abuse Material - What's the Harm?", "authors": "Caoilte Ó Ciardha,John Buckley,Rebecca S. Portnoff", "background": "随着生成式人工智能工具的发展，能够生成完整或部分合成的儿童性剥削材料（AI CSAM），这对儿童保护、执法和社会应对儿童剥削构成了重大挑战。尽管有人认为AI CSAM因其假定的受害者缺席而与传统CSAM本质上不同，但这种观点未能充分考虑到其生产与消费所带来的多种风险。人工智能在生成之前未曾遭受虐待儿童的合成CSAM、重新伤害已知的性剥削幸存者、促进诱骗、胁迫和性勒索以及将儿童性剥削正常化方面发挥作用。此外，AI CSAM可能是新且更强大的犯罪行为途径，通过降低参与门槛、逐渐使用户脱敏于越来越极端的内容以及削弱个体的保护因素，促进性剥削行为的发展。", "innovation": "本文提供了一些关键技术的初步介绍，并批判性地审视了AI CSAM的危害，警告人们不要认为AI CSAM可以作为一种减少危害的手段。强调了某些关于无害性的主张掩盖了其实际风险，可能会阻碍生态系统应对措施的进展。", "conclusion": "本文强调了AI CSAM的危害，反对将其视为降低风险的工具，呼吁应关注其实际风险，以推动有效的应对措施。"}
{"llm_update_time": "20251006", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.03075", "html_url": "https://arxiv.org/abs/2510.03075", "title": "视觉生成模型中何种机制驱动组合泛化的研究", "title_en": "What Drives Compositional Generalization in Visual Generative Models?", "authors": "Karim Farid,Rajat Sahay,Yumna Ali Alnaggar,Simon Schrodi,Volker Fischer,Cordelia Schmid,Thomas Brox", "background": "组合泛化能力，即生成已知概念的新组合，是视觉生成模型的关键组成部分。然而，能够促进或抑制这种能力的机制尚不完全清楚。本文通过系统研究各种设计选择如何在正向或负向影响图像和视频生成的组合泛化能力，旨在深入理解这种能力背后的机制。", "innovation": "通过受控实验，作者发现两种关键因素：(i) 训练目标是在离散还是连续分布上操作，(ii) 条件信息在训练过程中对构成概念提供的信息程度。基于这些见解，作者展示了通过对MaskGIT的离散损失加以适当的连续JEPA辅助目标来放松限制，可以提升离散模型中的组合性能。", "conclusion": "研究指出，通过调整训练机制，特别是在离散分布和连续信息利用方面，可以有效提升视觉生成模型的组合泛化能力。"}
{"llm_update_time": "20251006", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.03016", "html_url": "https://arxiv.org/abs/2510.03016", "title": "从模糊监督学习稳健扩散模型", "title_en": "Learning Robust Diffusion Models from Imprecise Supervision", "authors": "Dong-Dong Wu,Jiacheng Cui,Wei Wang,Zhiqiang She,Masashi Sugiyama", "background": "近年来，条件扩散模型在各种生成任务中取得了显著的成功，但它们的训练通常依赖大规模数据集，这些数据集不可避免地包含条件输入中的不精确信息。这种源自噪声、模糊或不完整标签的监督往往会引发条件不匹配，从而降低生成的质量。", "innovation": "本文提出了一种名为DMIS的统一框架，用于通过模糊监督训练稳健的扩散模型，这是扩散模型领域内的首次系统研究。该框架从似然最大化推导而来，并将目标分解为生成和分类两个部分：生成部分用于建模模糊标签分布，分类部分则利用扩散分类器推断后验概率，并通过优化时间步长采样策略进一步提高了效率。实验表明，DMIS在不同类型的模糊监督下生成高质量且具有类区分度的样本，适用于图像生成、弱监督学习和噪声数据集凝聚等多种任务。", "conclusion": "通过引入DMIS框架，本文解决了由模糊监督引起的条件不匹配问题，从而提高了扩散模型的质量和泛化能力，为后续相关研究提供了新的思路。"}
{"llm_update_time": "20251006", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.03004", "html_url": "https://arxiv.org/abs/2510.03004", "title": "BrainIB++: 利用图神经网络和信息瓶颈在精神分裂症功能脑生物标志物中的应用", "title_en": "BrainIB++: Leveraging Graph Neural Networks and Information Bottleneck for Functional Brain Biomarkers in Schizophrenia", "authors": "Tianzheng Hu,Qiang Li,Shu Liu,Vince D. Calhoun,Guido van Wingen,Shujian Yu", "background": "在精神障碍领域，诊断模型的发展正在取得进展。基于静息态功能磁共振成像（rs-fMRI）的机器学习分类器已经被开发出来，用于识别能够区分精神障碍与健康控制组的脑生物标志物。然而，传统的基于机器学习的诊断模型通常依赖于大量的特征工程，这会通过手动干预引入偏差。虽然深度学习模型预期可以在无需人工干预的情况下运行，但它们缺乏可解释性，这在获取可解释的且可靠的脑生物标志物以支持诊断决策方面构成了显著挑战，从而限制了其临床应用。", "innovation": "本研究引入了一种全流程创新性的图神经网络框架——BrainIB++，该框架在模型训练过程中应用信息瓶颈（IB）原则，以识别最具有信息量的数据驱动脑区作为子图，用于提高模型解释性。我们的模型在三种多科谱精神分裂症数据集中与九种脑网络分类方法进行了比较，展示了优越的诊断准确性和良好的泛化能力。同时，我们模型识别出的子图也与精神分裂症的已确立的临床生物标志物相吻合，特别是在视觉、感觉运动和高级认知的脑功能网络中发现了异常情况。", "conclusion": "我们的研究证明，BrainIB++框架可以更有效地识别出具有临床相关性的脑生物标志物，并且其模型的解释性更强，具有很高的临床应用价值。"}
{"llm_update_time": "20251006", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.03069", "html_url": "https://arxiv.org/abs/2510.03069", "title": "通信中神经极化解码器的研究", "title_en": "A Study of Neural Polar Decoders for Communication", "authors": "Rom Hirsch,Ziv Aharoni,Henry D. Pfister,Haim H. Permuter", "background": "先前的研究展示了神经极化解码器（NPDs）在合成信道上的有效性，但尚未将其扩展至实际的通信系统。因此，本文通过将其应用于正交频分复用（OFDM）和单载波通信系统，进一步将NPD扩展到了现实世界的通信系统中。", "innovation": "本文对NPD进行了适应性研究，使得其能够支持任意的码长，兼容多种调制方式，并且能够在多种信道条件下保持稳定性。NPD能够直接处理具有记忆性的信道，利用这些特征在不依赖导频和循环前缀的情况下实现更高的数据率。尽管NPD的计算复杂度高于标准5G极化解码器，但其神经网络结构使得它能够在现实系统的复杂度下保持高效。", "conclusion": "实验结果在5G信道上展示了神经极化解码器在错误比特率（BER）、比特错误率（BLER）和吞吐量方面的一致优势，特别是在低速率和短分组长度的情况下。此外，NPD在单载波系统中应用时，其旁瓣电平（PAPR）较低，使得NPD能够有效地在5G信道上实现单载波传输。这些结果表明，NPD是一种高性能、无导频和坚固的解码解决方案。"}
{"llm_update_time": "20251006", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.03129", "html_url": "https://arxiv.org/abs/2510.03129", "title": "基于路径签名的变换器模型在资产配置中的应用", "title_en": "Signature-Informed Transformer for Asset Allocation", "authors": "Yoontae Hwang,Stefan Zohren", "background": "在量化金融中，稳健的资产配置是一个重要挑战。深度学习预测器经常由于目标不匹配和误差放大而失败。研究人员引入了路径签名变换器（SIT），一种通过直接优化风险敏感的金融目标来学习端到端分配策略的新框架。SIT的核心创新包括用于资产动态丰富几何表示的路径签名以及将金融归纳偏见（如领先滞后效应）嵌入模型的路径签名增强注意力机制。", "innovation": "SIT的核心创新包括路径签名，用于资产动态的丰富几何表示；以及路径签名增强的注意力机制，用于嵌入金融归纳偏见，比如领先滞后效应。", "conclusion": "在每日标准普尔100指数数据上的评估表明，SIT在资产配置上显著优于传统和深度学习基准，特别是在与预测然后优化模型的对比中。这些结果表明，面向投资组合的目标和面向几何的归纳偏见是机器学习系统中进行风险敏感资本分配的关键。相关代码可以在如下链接找到：this https URL"}
{"llm_update_time": "20251006", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.03060", "html_url": "https://arxiv.org/abs/2510.03060", "title": "语音情感识别中的语义区分：来自描述性与表现性语音角色的见解", "title_en": "Semantic Differentiation in Speech Emotion Recognition: Insights from Descriptive and Expressive Speech Roles", "authors": "Rongchen Guo,Vincent Francoeur,Isar Nejadgholi,Sylvain Gagnon,Miodrag Bolic", "background": "语音情感识别（SER）对于提升人机交互至关重要，但其准确性受限于语音中情感细微差别的复杂性。现有研究表明，描述性语义代表了语音的上下文内容，而表现性语义反映了说话者的情感状态。在本次研究中，研究人员通过观察具有强烈情感色彩的电影片段，录音了参与者对这些片段的描述，以及每段录音所述的情感标签，参与者自身的情绪反应评分，以及情感的正向性和唤醒度评分，以证明这两种语义在SER中的不同作用.", "innovation": "该研究区分了描述性语义和表现性语义，指出描述性语义与预期情感相符，表现性语义与诱发情绪相关。这一发现为SER在人机交互中的应用提供了新见解，有助于开发更加知觉到上下文的人工智能系统.", "conclusion": "实验结果显示，描述性语义与预期情感一致，表现性语义与诱发情感具有相关性。该研究为情感识别应用提供了更多方法，为构建更加理解人类情感的智能系统奠定了基础."}
{"llm_update_time": "20251006", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.03029", "html_url": "https://arxiv.org/abs/2510.03029", "title": "研究生成代码中的代码异味", "title_en": "Investigating The Smells of LLM Generated Code", "authors": "Debalina Ghosh Paul,Hong Zhu,Ian Bayley", "background": "大型语言模型（LLMs）被越来越多地用于生成程序代码，虽然已有不少关于生成代码功能正确性的研究，但关于代码质量的研究相对较少。本研究旨在通过场景化方法评估LLM生成代码的质量，以识别需要改进代码质量的最差场景，测量代码异味（代码质量的重要指标），并与专业编写代码的基准进行比较。测试数据集根据代码主题和编程任务复杂度划分为多个子集，以代表使用LLM进行代码生成的不同场景。研究结果表明，LLM生成的代码中代码异味的发生率高于参照解决方案。Falcon的表现最差，其次是Gemini Pro、ChatGPT和Codex。平均代码异味增加率占所有LLM的63.34%，其中73.35%为实现异味，21.42%为设计异味。研究还发现，代码异味增加的程度随着编程任务复杂度和更为高级的领域（如面向对象概念）的增加而增加。", "innovation": "提出了一种基于场景的方法来评估LLM生成代码的质量，并自动测试系统。分析结果显示不同LLM生成代码的质量显著低于人类编写代码的质量，尤其是在复杂任务和高级主题上，代码异味显著增加。此外，该研究强调了LLM生成代码质量与人类编写代码质量之间的关联性，尤其是在不同编程任务复杂度和主题上的表现更为显著。", "conclusion": "从代码异味的角度来看，LLM在不同编程任务复杂度和主题上的表现与相应场景的人类编写代码质量高度相关。然而，LLM生成的代码质量明显低于人类编写代码的质量。"}
{"llm_update_time": "20251006", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.03051", "html_url": "https://arxiv.org/abs/2510.03051", "title": "ZeroShotOpt：迈向高效的黑盒优化的零样本预训练模型", "title_en": "ZeroShotOpt: Towards Zero-Shot Pretrained Models for Efficient Black-Box Optimization", "authors": "Jamison Meindl,Yunsheng Tian,Tony Cui,Veronika Thost,Zhang-Wei Hong,Johannes Dürholt,Jie Chen,Wojciech Matusik,Mina Konaković Luković", "background": "优化昂贵的、无导数的黑盒函数需要极高的样本效率。尽管贝叶斯优化（BO）是当前最先进的技术，但它依赖的 surrogate 和获取函数超参数往往需要手动调优，且不能很好地适应不同的问题场景。", "innovation": "提出了 ZeroShotOpt，这是一种通用的预训练模型，适用于从2D到20D的连续黑盒优化任务。该模型通过在12种BO变体收集的大规模优化轨迹上进行离线强化学习来进行预训练。为了提升预训练的规模，生成了大量基于高斯过程的合成函数，包含多样化的场景，从而使模型能够学习到可转移的优化策略。ZeroShotOpt 实现了在广泛未见基准测试上的稳健零样本通用化，其样本效率与领先的全局优化器（包括BO）相当或更优，同时提供了未来扩展和改进的基础。", "conclusion": "ZeroShotOpt 在多种未见过的基准测试上表现出色，展现了稳健的零样本通用化能力，超出了当前先进优化器的样本效率，提供了一个可重复使用的基础架构，有望在未来优化领域得到广泛应用。"}
{"llm_update_time": "20251006", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.03065", "html_url": "https://arxiv.org/abs/2510.03065", "title": "一种针对最近足够旅行商问题的统一深度强化学习方法", "title_en": "A Unified Deep Reinforcement Learning Approach for Close Enough Traveling Salesman Problem", "authors": "Mingfeng Fan,Jiaqi Cheng,Yaoxin Wu,Yifeng Zhang,Yibin Yang,Guohua Wu,Guillaume Sartoretti", "background": "近年来，深度强化学习(DRL)在解决NP难题旅行商问题(TSP)方面取得了进展。但是，较少关注最近足够旅行商问题(CETSP)，主要是因为其基于邻域的访问标准所带来的挑战，使得节点在代理进入其紧凑邻域后才被认为是访问过。", "innovation": "提出了一种马尔可夫决策过程(MDP)形式化的CETSP及一种新颖的统一双解码器DRL(UD3RL)框架，该框架将决策过程分为节点选择和路径点确定，并且引入了K近邻子图交互策略来改善地点解码的空间推理能力。此外，根据REINFORCE算法训练UD3RL，使其能够泛化到不同规模的问题和变化的邻域半径类型（固定和随机半径）之中。实验结果显示，UD3RL在解决方案质量和运行时间上都优于传统方法，并且在问题规模、空间分布和半径范围方面表现出了强大的泛化能力和对动态环境的鲁棒性。", "conclusion": "UD3RL在解决CETSP的问题上展现了优越性能，并能够很好地处理不同规模和条件的问题。该方法不仅在算法框架上有创新，而且在训练算法和解决方案的质量上有显著优势。"}
{"llm_update_time": "20251006", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.03064", "html_url": "https://arxiv.org/abs/2510.03064", "title": "参数化动作Actor- Critic强化学习算法在网络搜索匹配计划生成中的比较分析", "title_en": "Comparative Analysis of Parameterized Action Actor-Critic Reinforcement Learning Algorithms for Web Search Match Plan Generation", "authors": "Ubayd Bapoo,Clement N Nyirenda", "background": "该研究评估了在完全可观测环境下的高维决策任务中Soft Actor Critic (SAC)、Greedy Actor Critic (GAC)和Truncated Quantile Critics (TQC)的性能。研究将重点放在参数化动作（PA）空间上，从而消除对循环网络的需求，并使用Platform-v0和Goal-v0基准测试区分动作与连续动作参数空间的关联。超参数优化使用了Microsoft NNI，通过修改GAC和TQC的代码以确保可复现性。", "innovation": "研究中的创新在于开发了Parameterized Action Greedy Actor-Critic (PAGAC)算法，并通过Microsoft NNI进行超参数优化。PAGAC在多种基准测试中表现出更快的训练时间和更高的回报，特别是在Platform游戏和Robot Soccer Goal游戏中，分别在41:24和24:04完成5000个回合。PAGAC在复杂动作空间中的速度和稳定性胜过其他算法，展现出更高的效率和可靠性，使其适用于需要快速收敛和稳健性能的任务。未来的研究可能会探索结合熵正则化和截断方法的混合策略，以增强稳定性并扩大通用性研究领域。", "conclusion": "研究结果表明，Parameterized Action Greedy Actor-Critic (PAGAC) 算法在多个基准测试上表现出色，包括更快的训练时间和更高的回报。PAGAC适合需要快速收敛和稳健性能的任务，为未来的混合策略研究奠定了基础。"}
{"llm_update_time": "20251006", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.03161", "html_url": "https://arxiv.org/abs/2510.03161", "title": "UniShield: 一种统一的自适应多智能体框架用于伪造图像检测与定位", "title_en": "UniShield: An Adaptive Multi-Agent Framework for Unified Forgery Image Detection and Localization", "authors": "Qing Huang,Zhipei Xu,Xuanyu Zhang,Jian Zhang", "background": "随着图像生成技术的迅速发展，合成图像变得越来越逼真，引发了诸如信息误导和欺诈等重大社会问题。伪造图像检测与定位（FIDL）因此变得至关重要，旨在维护信息完整性和社会安全。现有领域特定的检测方法在实际应用中受到限制，主要是由于它们的专业化程度狭窄，跨领域的通用性差以及缺乏集成的自适应框架。", "innovation": "我们提出了UniShield，这是一种新颖的多智能体统一系统，能够在包括图像篡改、文档篡改、DeepFake和AI生成图像在内的多种领域内检测和定位图像伪造。UniShield创新地将感知智能体和检测智能体结合在一起。感知智能体智能地分析图像特征以动态选择合适的检测模型，检测智能体则将各种专家级检测器统一到一个框架中，并生成可解释的报告。大量实验表明，UniShield在性能上超过了现有的统一方法和领域特定的检测器，突显了其实用性、适应性和可扩展性。", "conclusion": "UniShield在伪造图像检测与定位方面达到了最先进的结果，不仅超越了现有统一的方法，还超越了领域的特定检测器，证明了其在实际应用中的优越性和灵活性，以及广泛的适用性。"}
{"llm_update_time": "20251006", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.03155", "html_url": "https://arxiv.org/abs/2510.03155", "title": "基于刺激-电压的锋电位起始时间预测：经典方法与量子启发式方法对比", "title_en": "Stimulus-Voltage-Based Prediction of Action Potential Onset Timing: Classical vs. Quantum-Inspired Approaches", "authors": "Stevens Johnson,Varun Puram,Johnson Thomas,Acsah Konuparamban,Ashwin Kannan", "background": "准确建模神经元动作电位（AP）起始时间对于理解神经元对危险信号的编码至关重要。传统的漏电流整合和发射（LIF）模型虽然广泛应用，但是在预测AP起始潜伏期时却表现出较高的相对误差，尤其是在刺激强度大或变化快速的情况下。", "innovation": "本文借鉴了近期的实验发现和量子理论，提出了一种量子启发式的漏电流整合和发射（QI-LIF）模型，将AP起始视为一个时间上的高斯波包，并视其为概率事件。此方法能够捕捉到神经元放电的生物变异性与不确定性。通过使用不同刺激强度下的海马体和感受神经元的合成数据，系统对比了经典LIF模型与QI-LIF模型的预测误差。结果显示，QI-LIF模型显著减少了预测误差，特别是在高强度刺激下，更加接近观察到的生物反应。", "conclusion": "本研究表明，量子启发式的计算框架在提高神经元建模准确性方面具有巨大潜力，并可能为基于大脑启发的量子工程计算提供方法论指导。"}
{"llm_update_time": "20251006", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.03122", "html_url": "https://arxiv.org/abs/2510.03122", "title": "HAVIR: 使用CLIP引导的通用扩散模型进行层次视觉到图像重建", "title_en": "HAVIR: HierArchical Vision to Image Reconstruction using CLIP-Guided Versatile Diffusion", "authors": "Shiyi Zhang,Dong Liang,Hairong Zheng,Yihang Zhou", "background": "视觉信息从大脑活动的重建促进了神经科学与计算机视觉的跨学科整合。然而，现有的方法在准确恢复复杂视觉刺激方面仍然面临挑战。这一困难源于自然场景的特点：低级特征表现出异质性，而高级特征由于上下文重叠而表现出语义交织。", "innovation": "受视觉皮层层次表示理论的启发，本文提出了HAVIR模型，该模型将视觉皮层分为两个层次区域，并从中提取不同的特征。具体来说，结构生成器从空间处理体素中提取结构信息并转化为潜在扩散先验，语义提取器将语义处理体素转化为CLIP嵌入。这些组件通过通用扩散模型综合，以合成最终图像。实验结果显示，HAVIR在结构和语义质量上均提升了重建效果，并优于现有模型，即使是复杂场景也能表现出色。", "conclusion": "HAVIR通过优化结构和语义提取并在通用扩散模型中综合两者的提取结果，显著提高了复杂场景下神经活动到图像重建的准确性和效果。"}
{"llm_update_time": "20251006", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.03223", "html_url": "https://arxiv.org/abs/2510.03223", "title": "Self-Anchor: 大型语言模型逐步注意力对齐驱动的推理", "title_en": "Self-Anchor: Large Language Model Reasoning via Step-by-step Attention Alignment", "authors": "Hongxiang Zhang,Yuan Tian,Tianyi Zhang", "background": "为了应对大型语言模型（LLMs）解决复杂推理任务的需求，基于提示的方法提供了一种轻量级的替代方案，替代了微调和强化学习。然而，随着推理链的延伸，关键的中间步骤和原始提示会在上下文中被埋没，受到不足的关注，从而导致错误。", "innovation": "本文提出了Self-Anchor，这是一种新颖的管道，利用推理固有的结构引导LLM的注意力。Self-Anchor通过将推理轨迹分解为结构化计划，并自动将模型的注意力集中在最相关的推理步骤上，使模型能够在生成过程中保持专注。实验结果显示，Self-Anchor在六个基准测试中优于当前最先进的提示方法，特别是显著降低了“非推理”模型与专门的推理模型之间的性能差距，有可能让大多数LLM不需重新培训即可解决复杂推理任务。", "conclusion": "实验表明，Self-Anchor在六个基准测试中优于最先进的提示方法，显著降低了“非推理”模型与专门的推理模型之间的性能差距，从而展示了Self-Anchor在提升LLM解决复杂推理任务的能力方面的潜力。"}
{"llm_update_time": "20251006", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.03095", "html_url": "https://arxiv.org/abs/2510.03095", "title": "Distilled Protein Backbone Generation", "title_en": "Distilled Protein Backbone Generation", "authors": "Liyang Xie,Haoran Zhang,Zhendong Wang,Wesley Tansey,Mingyuan Zhou", "background": "扩散和流基于生成模型在蛋白质骨架生成任务中展现出了强大的性能，为从头设计蛋白质提供了前所未有的能力。然而，这些模型在生成速度上受限，通常需要数百次逆扩散过程中的迭代步骤，这在大规模蛋白质发现中是不可行的，因为需要成千上万甚至数百万的候选结构。", "innovation": "通过探索评分蒸馏技术，该研究将评分蒸馏策略成功应用于蛋白质骨架生成，以减少样本数量并在保持高质量生成的同时显著减少推理时间。特别的是，多步生成结合推理时间噪声调节是成功的要点。研究结果表明，蒸馏后的少数步生成器的采样速度提高了超过20倍，保留了与Proteina教师模型相当的设计、多样性和新颖性。这降低了推理成本，使大规模无蛋白设计成为可能，从而将基于扩散的方法更接近于现实世界中的蛋白质工程应用场景。", "conclusion": "我们的研究通过适当调整评分身份蒸馏（SiD）策略，训练出少数步蛋白质骨架生成器，显著减少了采样时间，同时保留了与预训练教师模型相当的性能。研究结果表明，蒸馏后的少数步生成器在采样速度上提高了超过20倍，且在设计能力、多样性和新颖性方面达到了与Proteina教师模型相似的水平。"}
{"llm_update_time": "20251006", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.03160", "html_url": "https://arxiv.org/abs/2510.03160", "title": "脊椎定标基准：基于SpineMed语料库的临床核心、段落意识基准", "title_en": "SpineBench: A Clinically Salient, Level-Aware Benchmark Powered by the SpineMed-450k Corpus", "authors": "Ming Zhao,Wenhui Dong,Yang Zhang,Xiang Zheng,Zhonghao Zhang,Zian Zhou,Yunzhi Guan,Liukun Xu,Wei Peng,Zhaoyang Gong,Zhicheng Zhang,Dachuan Li,Xiaosheng Ma,Yuli Ma,Jianing Ni,Changjiang Jiang,Lixia Tian,Qixin Chen,Kaishun Xia,Pingping Liu,Tongshun Zhang,Zhiqiang Liu,Zhongan Bi,Chenyang Si,Tiansheng Sun,Caifeng Shan", "background": "全球有6.19亿人受到脊椎疾病的影响，这类疾病是导致残疾的主要原因之一。然而，由于缺乏层次意识的多模态数据，AI辅助诊断仍然受到限制。脊椎疾病的临床决策需要跨X射线、CT和MRI在特定椎骨层次进行复杂的推理，但缺乏可追溯和临床基础的指导数据及标准化脊椎特定基准阻碍了这一领域的发展进程。", "innovation": "本文介绍了一个与临床脊椎外科医生共同设计的SpineMed生态系统。该系统包括SpineMed-450k，这是一个专为多模态成像数据中的椎骨层次推理设计的大型数据集，并包含超过450,000个指令实例，以及SpineBench，这是一个以临床为本的评估框架。SpineMed-450k的数据从多种来源精心编制，如教科书、指南、开源数据集和约1,000份匿名医院病例，并采用了包含草稿和修订两个阶段的大型语言模型生成方法，以确保高质量和可追溯的数据。SpineBench对模型在层级识别、病理评估和手术规划等方面的临床相关内容进行评估。", "conclusion": "全面评估了几种领先的大型视觉语言模型 (LVLMs) 之后，显示这些模型在细粒度和层次特定推理方面存在系统性的弱点。然而，通过SpineMed-450k进行微调的我们的模型在所有任务中都表现出一致且显著的改进。临床医生评估证实了我们模型输出的诊断清晰度和实用性。"}
{"llm_update_time": "20251006", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.03216", "html_url": "https://arxiv.org/abs/2510.03216", "title": "Wave-GMS：医疗图像分割的轻量化多尺度生成模型", "title_en": "Wave-GMS: Lightweight Multi-Scale Generative Model for Medical Image Segmentation", "authors": "Talha Ahmed,Nehal Ahmed Shaikh,Hassan Mohy-ud-Din", "background": "在医院和医疗设施中公平部署AI工具，需要能够高效运行且可负担的深度分割网络，尤其这些网络需要在具有有限内存和大批次处理能力的低成本GPU上训练。现有的目标检测和分割方法要求使用大规模的计算资源，如加载昂贵的预训练视觉基础模型，这限制了它们在实际医疗设施中的应用。因此，需要一种轻量且高效的多尺度生成模型来应对这些挑战，以提高在实际医疗场景中的部署效果和性能。", "innovation": "本文提出了一种新的轻量且高效的多尺度生成模型Wave-GMS，用于医疗图像分割。Wave-GMS具有以下创新点：1) 参数量小：仅需要约2.6M的可训练参数；2) 不依赖于大量的内存加载预训练模型；3) 支持在内存有限的GPU上进行大规模批次训练。通过在四个公开数据集上的大量实验，证明Wave-GMS在保持高性能的同时，具有更优的跨域泛化能力。", "conclusion": "Wave-GMS在多个公开数据集上展示了卓越的分割性能和泛化能力，其轻量化的设计使得它适合在实际的医疗设施中部署。"}
{"llm_update_time": "20251006", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.03174", "html_url": "https://arxiv.org/abs/2510.03174", "title": "主题建模作为长篇生成：大型语言模型能否通过零样本提示革新NTM？", "title_en": "Topic Modeling as Long-Form Generation: Can Long-Context LLMs revolutionize NTM via Zero-Shot Prompting?", "authors": "Xuan Xu,Haolun Li,Zhongliang Yang,Beilin Chu,Jia Song,Moxuan Xu,Linna Zhou", "background": "传统的主题模型如神经主题模型依赖于推理和生成网络来学习潜在的主题分布。该论文研究了在大语言模型时代的主题建模新范式，将主题建模（TM）重新定义为一种长文本生成任务。研究对比传统神经主题模型（NTMs）和基于大型语言模型（LLMs）的长文本生成范式在主题质量方面的表现，探讨零样本提示能否使LLMs在主题建模任务中取得更好结果，质疑大量NTMs已经过时的观点。", "innovation": "论文提出了一种简单且实用的方法，直接利用大语言模型来实现主题模型任务，通过提示样本文本集、生成主题和代表文本，并结合关键词匹配完成主题分配。此外，该论文通过零样本提示展示了大语言模型在主题建模中的潜力，提供了不同于传统神经主题模型的新方法和视角。", "conclusion": "通过对基于大语言模型的主题建模任务与神经主题模型的系统比较，论文验证了长文本生成范式在主题质量方面的优势，并提出了对于许多神经主题模型已经过时的看法。"}
{"llm_update_time": "20251006", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.03217", "html_url": "https://arxiv.org/abs/2510.03217", "title": "Abstain and Validate: A Dual-LLM Policy for Reducing Noise in Agentic Program Repair", "title_en": "Abstain and Validate: A Dual-LLM Policy for Reducing Noise in Agentic Program Repair", "authors": "José Cambronero,Michele Tufano,Sherry Shi,Renyao Wei,Grant Uy,Runxiang Cheng,Chin-Jung Liu,Shiying Pan,Satish Chandra,Pat Rondon", "background": "在工业环境中，代理自动化程序修复(AGntity APR)正在处理复杂的存储库级别的bug问题。然而，最终生成的补丁仍需要人工审查才能确认是否解决了bug。代理生成的补丁可能会带来大量噪声，浪费开发人员的时间并损害对自动化代码更改的信任。因此，本文提出了两种基于LLM的互补策略来减少此类噪声：错误超脱和补丁验证策略。", "innovation": "本文引入了两种基于LLM的策略：错误超脱策略和补丁验证策略。错误超脱策略会排除代理APR系统不太可能修复的bug。补丁验证策略会拒绝不太可能修复特定bug的补丁。这些策略在不同类型的bug及其候选补丁上进行了评估，结果显示，通过这些策略可以显著提高修复成功率，并且提供了实际路径来实现代理APR系统的可靠且大规模工业部署。", "conclusion": "在三个来自Google代码库的bug集上，应用这两种策略后，成功率达到最高提高了39个百分点。补丁验证策略特别在空指针异常和由机器生成的bug报告报告的bug中提高了成功率。这种双重策略为代理APR系统的可靠、工业规模的部署提供了一条实用的道路。"}
{"llm_update_time": "20251006", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.03230", "html_url": "https://arxiv.org/abs/2510.03230", "title": "通过显式位置到坐标映射提升GUI定位", "title_en": "Improving GUI Grounding with Explicit Position-to-Coordinate Mapping", "authors": "Suyuchen Wang,Tianyu Zhang,Ahmed Masry,Christopher Pal,Spandana Gella,Bang Liu,Perouz Taslakian", "background": "GUI定位任务涉及将自然语言指令转换为像素坐标，这对自主代理非常重要，但当前视觉语言模型（VLMs）难以完成。主要瓶颈在于可靠的碎片到像素映射，在面对训练期间未见过的高分辨率显示时会失效。现有方法直接从视觉特征生成坐标，导致模型需要隐式推断复杂的位置到像素的映射关系，这会导致性能下降和新分辨率下的失败增多。", "innovation": "为了解决这一问题，论文提出了两项创新：1. RULER标记作为显式坐标的标记方式，让模型可以像地图上的网格线一样引用位置，调整而非从零开始生成坐标；2. 交错MRoPE（I-MRoPE）通过确保宽度和高度维度的公平表示，解决了标准位置方案存在的不对称性，从而改善了空间编码。", "conclusion": "在ScreenSpot、ScreenSpot-V2和ScreenSpot-Pro上的实验表明，通过提供明确的空间指导而非依赖于隐式学习的方法，该方法在多种分辨率和平台下都能实现更可靠的GUI自动化，并在高分辨率界面中表现出显著改进。"}
{"llm_update_time": "20251006", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2505.11274", "html_url": "https://arxiv.org/abs/2505.11274", "title": "SelfBudgeter：高效的LLM推理中自适应令牌分配", "title_en": "SelfBudgeter: Adaptive Token Allocation for Efficient LLM Reasoning", "authors": "Zheng Li,Qingxiu Dong,Jingyuan Ma,Di Zhang,Kai Jia,Zhifang Sui", "background": "尽管推理模型在复杂任务上表现出色，但在处理简单问题时往往会表现出过度推理的倾向，这不仅导致了过多的计算资源消耗，还显著降低了用户体验。", "innovation": "本研究提出了SelfBudgeter——一种新颖的用户友好型自适应可控推理框架，引入了一种预算预估机制。该框架采用双阶段训练模式：在冷启动阶段，模型学会在标准化格式下预测令牌预算；在强化学习阶段，模型根据问题难度自主规划预算并在生成响应时严格遵守。SelfBudgeter可以在初始阶段给出预算估算，使用户能够立即预测等待时间，从而灵活决定是否中断或继续生成过程。此外，该方法还支持通过预设的预算字段手动控制推理长度。", "conclusion": "实验结果表明，SelfBudgeter可以根据问题复杂性动态分配预算，1.5B模型在GSM8K、MATH500和AIME2025数据集上的平均响应长度压缩了61%，7B模型压缩了48%，同时保持了接近不变的准确度。"}
{"llm_update_time": "20251006", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.03182", "html_url": "https://arxiv.org/abs/2510.03182", "title": "规则到模拟：一种用于正式视觉规划的双VLM框架", "title_en": "Simulation to Rules: A Dual-VLM Framework for Formal Visual Planning", "authors": "Yilun Hao,Yongchao Chen,Chuchu Fan,Yang Zhang", "background": "视觉语言模型（VLMs）在视觉规划方面表现出强大的潜力，但在精确的空间和长周期推理方面存在困难。相比之下，规划领域定义语言（PDDL）规划器在长周期形式化规划方面表现出色，但无法解释视觉输入。最近的研究通过使VLMs能够将视觉规划问题转换为PDDL文件来进行正式规划来结合这些互补的优势。然而，尽管VLMs可以生成满足PDDL要求的问题文件，但它们在准确生成描述所有规划规则的PDDL领域文件方面表现出色。因此，先前的方法依赖于人类专家预先定义领域文件或持续访问环境来进行细化。这篇论文讲述了一个名为VLMFP的新框架，它可以通过两个VLM确保可靠地生成PDDL文件：SimVLM用于根据输入规则描述模拟动作的后果，而GenVLM通过比较PDDL和SimVLM执行结果来生成和迭代生成PDDL文件。", "innovation": "VLMFP是一个双视觉语言模型（Dual-VLM）引导的框架，它能够自主生成用于正式视觉规划的PDDL问题和领域文件。通过引入SimVLM和GenVLM，该框架能够准确描述和模拟多种情况的动作序列，并生成有效的规划方案。此外，VLMFP展示了多个层次的泛化能力，即生成的PDDL领域文件可以应用于相同问题的不同实例，而VLMs可以泛化到具有不同外观和规则的问题上。这项工作通过6个网格世界领域进行了评估，并测试了其对未见过的情况、外观和游戏规则的泛化能力。", "conclusion": "在平均情况下，SimVLM能够准确描述95.5%的场景和82.6%的动作序列，模拟85.5%和87.8%的动作序列，并判断82.4%和85.6%的目标达成情况。在未见过的情况和未见过的外观方面，根据SimVLM的指导，VLMFP能够生成PDDL文件来实现70.0%和54.1%的合法规划方案。"}
{"llm_update_time": "20251006", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2504.00907", "html_url": "https://arxiv.org/abs/2504.00907", "title": "使用强化学习将多模态大语言模型对接到需要求助的实体代理", "title_en": "Grounding Multimodal LLMs to Embodied Agents that Ask for Help with Reinforcement Learning", "authors": "Ram Ramrakhya,Matthew Chang,Xavier Puig,Ruta Desai,Zsolt Kira,Roozbeh Mottaghi", "background": "家庭机器人在执行任务时必须能够解释模棱两可且信息不足的人类指令。为此，我们需要一种机制，使机器人能够识别模糊性并提问相关澄清问题，以便准确推断用户意图，从而提高任务执行效果。为了研究这个问题，我们引入了“寻求行动”任务，其中机器人需要使用含糊的指示完成单个或多个物体的重组任务。机器人必须在部分可观测性的情况下，战略性地提出最少但相关的澄清问题来解决模糊性。", "innovation": "我们提出了一种创新方法，即使用在线强化学习（RL）微调多模态大型语言模型（MLLMs）作为视觉-语言-行动（VLA）策略。这种方法消除了大规模人工示范或手动工程化奖励的需求。我们的方法在零样本基线包括GPT-4o以及监督微调的MLLMs上进行基准测试。结果表明，我们的基于RL微调的MLLM在所有基线中表现最佳，显着提高了10.4-16.5%，在新的场景和任务中表现出良好的泛化能力。这表明这是首次将MLLMs适配为使用LLM生成奖励的在线RL进行行动并寻求帮助的VLA代理。", "conclusion": "本研究提出了使用在线强化学习微调多模态大语言模型作为视觉-语言-行动策略的方法，该方法在需要寻求帮助的实体代理中表现出显著改进。这种方法在处理模糊性和部分可观测性方面有很好的性能，并且在新的场景和任务中表现出良好的泛化能力。这是该领域的一项重要研究，证明了多模态大语言模型在代理实体中的潜力。"}
{"llm_update_time": "20251006", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.03231", "html_url": "https://arxiv.org/abs/2510.03231", "title": " reward models are metrics in a trench coat", "title_en": "Reward Models are Metrics in a Trench Coat", "authors": "Sebastian Gehrmann", "background": "自大语言模型（LLM）训练后引入强化学习以来，奖励模型引起了广泛兴趣。奖励模型评估生成文本的质量以提供训练信号，这一任务也由监控AI模型性能的评价指标完成。然而，这两个研究领域相对独立，导致了术语重复和重叠的问题，且共同面临一些挑战，如假相关性、下游奖励劫持的影响、数据质量改进方法以及元评估方法。", "innovation": "本文指出奖励模型和评价指标尽管在外观上不同，但实际上本质相同。通过展示评价指标在特定任务中超越奖励模型的表现，并提供了广泛的两个领域的调研结果，提出促进两个研究领域的更紧密合作将有助于克服现有问题。", "conclusion": "本文强调通过更紧密的合作，评价指标和奖励模型可以改进在偏好生成方法、避免假相关和奖励劫持、以及校准时考虑的效果。"}
{"llm_update_time": "20251006", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.00430", "html_url": "https://arxiv.org/abs/2506.00430", "title": "MIRROR: 模块化内部处理在LLM对话中的个性化安全", "title_en": "MIRROR: Modular Internal Processing for Personalized Safety in LLM Dialogue", "authors": "Nicole Hsing", "background": "大型语言模型在个人多轮对话中经常生成有害推荐，这主要是因为它们忽视了用户特定的安全背景，表现出逢迎性的同意，并且为了更大的群体偏好而牺牲用户安全。目前的挑战在于设计能够保留用户个人对话信息的技术解决方案，以防止这些失误，并能够灵活部署以适应不同成本的系统。", "innovation": "本文提出了一种模块化生产中心架构MIRROR，该架构通过保持在对话轮次之间持续且限定的内部状态来保护个性化对话信息，消除回应生成和异步反思处理之间的依赖关系，实现即时响应生成（Talker）和异步反思处理（Thinker）之间的并行推理线程合成，同时保持边际延迟，从而提高了个性化安全性。MIRROR增强了多种前沿模型，特别是在节约成本的前提下显著提高了模型的安全性。", "conclusion": "MIRROR架构允许灵活部署：对于成本较低的模型可采用完整的内部处理，而对于成本较高的模型则可以采用单一组件配置，这使得更广泛的用户能够访问到更安全的人工智能系统。此外，开源模型Llama 4和Mistral 3变体在性价比方面超越了GPT-4o和Claude 3.7 Sonnet，缩小了开源模型与前沿系统之间的差距。"}
{"llm_update_time": "20251006", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.22774", "html_url": "https://arxiv.org/abs/2506.22774", "title": "伦理原则与算法方法相结合：评估人工智能系统可信度的替代方法", "title_en": "Bridging Ethical Principles and Algorithmic Methods: An Alternative Approach for Assessing Trustworthiness in AI Systems", "authors": "Michael Papademas,Xenia Ziouvelou,Antonis Troumpoukis,Vangelis Karkaletsis", "background": "人工智（AI）技术展示了人类制造的复杂挑战，尤其是那些广泛融入社会并产生重大影响的技术，突显了其潜在的益处和负面后果。与其它技术相比，AI的广泛影响使其社会效应更加深远。AI系统的复杂性和其强大的能力，可能导致人们对超出直接人类监督或理解的系统产生依赖。为了缓解由此带来的风险，已经开发了许多理论工具和指南，同时也努力创造技术工具以确保可信的AI。然而，这些指南倾向于从整体上看待问题，却无法提供衡量可信度的技术方法；而技术工具虽然在量化方面更为出色，却往往缺乏整体视角，专注于可信AI的某一特定方面。", "innovation": "本文提出了一种结合伦理原则和算法方法的评估方法，通过引入PageRank和TrustRank的算法标准，弥补了现有评估方法中的主观性和缺乏整体系视角的问题。该方法旨在减少在该领域主导的自我评估技术的主观性，通过提供定量数据来对AI系统的可信度进行全方位评估。", "conclusion": "通过应用本研究提出的方法，可以实现对AI系统的整体可信度评估，提供定量的见解，并考虑到相关指南的理论内容，从而减少主观性和缺乏整体性的问题。"}
{"llm_update_time": "20251006", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.03224", "html_url": "https://arxiv.org/abs/2510.03224", "title": "通过潜在集合的随机共振实现对抗攻击的测试时防御", "title_en": "Test-Time Defense Against Adversarial Attacks via Stochastic Resonance of Latent Ensembles", "authors": "Dong Lao,Yuxiang Zhang,Haniyeh Ehsani Oskouie,Yangchao Wu,Alex Wong,Stefano Soatto", "background": "当前对抗攻击防护方法大多依赖于特征筛选或平滑，这些方法可能会导致信息丢失。本文探讨了一种在测试时防御对抗攻击的方法，通过添加几乎不可感知的图像扰动来显著改变模型预测，实现增强鲁棒性的同时尽量减少信息丢失。该方法应用于不同的网络架构且无需额外的网络模块或针对特定攻击类型重新训练，表明了其广泛适用性。实验结果表明，该方法在图像分类任务中达到了最先进的鲁棒性，首次为密集预测任务，如立体匹配和光流估计，建立了通用的测试时防御手段，展示出其广泛的应用潜力和实用性。", "innovation": "提出了通过随机共振增强潜在特征集合的方式来对抗对抗攻击。具体地，通过向输入图像添加小的平移扰动来变换特征嵌入，然后将这些变换后的特征嵌入对齐并聚合后再映射回原始参考图像。这种做法不仅可以通过闭式公式实现，还可以在不引入额外网络模块或针对特定攻击类型进行微调的情况下应用于多种现存网络架构。该方法完全无需训练，架构无关，攻击无关，对于不同类型对抗攻击的表现也相对较好。", "conclusion": "实验结果表明，该方法在图像分类、立体匹配和光流估计等任务中具有广泛的适用性和实用性，尤其在对抗攻击下的鲁棒性表现优异，即使在多种类型的对抗攻击下也能恢复高达68.1%、71.9%和29.2%的准确性损失。这种方法为对抗攻击下的测试时防御提供了一种全新的解决方案。"}
{"llm_update_time": "20251006", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2411.03887", "html_url": "https://arxiv.org/abs/2411.03887", "title": "OML：在AI模型分布中平衡开放访问与所有者控制的新原理", "title_en": "OML: A Primitive for Reconciling Open Access with Owner Control in AI Model Distribution", "authors": "Zerui Cheng,Edoardo Contente,Ben Finch,Oleg Golev,Jonathan Hayase,Andrew Miller,Niusha Moshrefi,Anshul Nasery,Sandeep Nailwal,Sewoong Oh,Himanshu Tyagi,Pramod Viswanath", "background": "当前AI模型的分发范式存在根本性的二分法：模型要么封闭和API限制，牺牲透明度和本地执行；要么开放分发，牺牲商业化机会和控制权。该研究引入了一种新的模型分发范式OML（开放访问、可变现且忠诚的AI模型服务），旨在让模型在保持加密授权使用的同时，可以自由分布供本地执行。这是首次明确并形式化这一问题，引入了针对白盒模型保护的独特安全定义：模型提取免疫力和权限伪造免疫力。该研究证明了OML属性的基本可实现边界，并对潜在构建方案进行了全面设计空间分析，从混淆方法到加密解决方案。研究通过广泛实证分析证明了OML的实用性，并将其确立为基础性原理，对于可持续AI生态至关重要。这项工作在密码学、机器学习和机制设计交叉领域的研究方向提出了新的方向，对AI的未来分发与治理有重要影响。", "innovation": "引入了一个新的模型分发范式OML，该范式既允许自由地分发AI模型进行本地执行，又能够通过加密手段强制执行使用权。首次针对性地提出并形式化了白盒模型保护的独特安全定义，包括模型提取免疫力和权限伪造免疫力。全面分析了OML的设计空间，从混淆策略到加密解决方案，并展示了OML 1.0的实际可行性。研究证明了OML对于可持续AI生态系统的重要性，并推动了一个新的研究方向：密码学、机器学习和机制设计的交叉领域。", "conclusion": "OML作为一种基础性原理，对于构建可持续的AI生态系统是必要的。该研究开启了将密码学、机器学习和机制设计相结合的新研究方向，对于AI的分发与治理具有重要的深远影响。"}
{"llm_update_time": "20251006", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2412.17052", "html_url": "https://arxiv.org/abs/2412.17052", "title": "ViLBias: 在多元模态内容中检测和推理偏见", "title_en": "ViLBias: Detecting and Reasoning about Bias in Multimodal Content", "authors": "Shaina Raza,Caesar Saleh,Azib Farooq,Emrul Hasan,Franklin Ogidi,Maximus Powers,Veronica Chatrath,Marcelo Lotif,Karanpal Sekhon,Roya Javadi,Haad Zahid,Anam Zahid,Vahid Reza Khazaie,Zhenyu Yu", "background": "当前检测多元模态新闻中的偏见需要模型能够在文本和图像之间进行推理，而不仅仅是对文本进行分类。现有的模型通常侧重于单一模态数据，因此，本文引入了一个新的基准和框架（ViLBias）来检测和处理多元模态新闻中的偏见。该数据集包括来自不同来源的40,945个文本-图像对，并且每个对都用两级LLM作为注释者管道进行了注释，使用分层多数投票和人工介入验证。", "innovation": "提出了一种名为ViLBias的新框架，这是一个基于VQA的基准，用于检测和解决多媒体新闻中的偏见问题。它利用LLM和指令调整策略，实现了高效率且有效的偏见检测，同时在各种模型（小语言模型、大语言模型和视觉-语言模型）上进行了评估，验证了将图像和文本结合使用对偏见检测的提升效果。", "conclusion": "研究结果显示，同时考虑图像和文本能够提高偏见检测的准确性3-5%，而LLM/VLM比SLM更能捕捉到细微的框架和文本-图像不一致性。参数高效方法（如LoRA/QLoRA/Adapters）能够在不到5%可训练参数的情况下恢复97-99%的全微调性能。对于开放性推理（oVQA），其推理准确率在52-79%之间，忠实度在68-89%之间，指令调整提高了这两种指标；封闭准确性与推理之间有很强的相关性（r=0.91）。总体而言，ViLBias提供了一个可扩展的基准和多元模态偏见检测的强基准线，同时也强调了在多元模态内容中理解和解释偏见的重要性。"}
{"llm_update_time": "20251006", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2406.16151", "html_url": "https://arxiv.org/abs/2406.16151", "title": "通过因果解缠改善结构分解马尔可夫决策过程的蒙特卡洛规划", "title_en": "Improved Monte Carlo Planning via Causal Disentanglement for Structurally-Decomposed Markov Decision Processes", "authors": "Larkin Liu,Shiqi Liu,Yinruo Hua,Matej Jusup", "background": "马尔可夫决策过程（MDPs）通常忽视了将转换和奖励动力学的因果结构纳入考量的好处。对于一类资源分配问题，引入了结构分解MDP（SD-MDP），通过因果解纠缠将MDP的时间因果图分解为独立部分，从而实现维数降低和最优价值函数估计的计算效率提升。这一方法将顺序优化问题转化为具有对数复杂度 $O(T \text{log} T)$ 的分割背包问题，优于传统的多项式复杂度的随机规划方法，特别是在时间horizon T较长时表现出色。此外，SD-MDP的计算优势与状态-行动空间大小无关，使其适用于高维空间。该方法还能够与蒙特卡罗树搜索（MCTS）无缝集成，即使在受预算限制的仿真预算下也能获得更高的预期奖励，并提供消失的简单遗憾界。实证结果表明，该方法在多个物流和金融领域的基准测试中表现出更优的策略性能。", "innovation": "提出了一种结构分解MDP（SD-MDP）的方法，通过因果解纠缠将MDP的时间因果图分解为独立部分，从而实现维数降低和计算效率提升。将顺序优化问题转化为具有对数复杂度的分割背包问题，优于传统的多项式复杂度的随机规划方法。方法的计算优势与状态-行动空间大小无关，适用于高维空间。该方法能够与蒙特卡罗树搜索（MCTS）无缝集成，并提供消失的简单遗憾界，使得在有限的仿真预算下也能获得更高的预期奖励。研究提出了对马尔可夫决策过程的一种新的优化思路和计算方法，有效提升了计算效率和策略性能。", "conclusion": "通过对资源分配问题的结构分解MDP（SD-MDP）方法进行研究，成功将马尔可夫决策过程的因果结构运用到优化框架中，通过因果解纠缠实现了计算效率的提升，并且在物流和金融领域中表现出了优越的策略性能。该方法将顺序优化问题转化为分割背包问题，计算复杂度显著降低。此外，该方法在高维状态空间下仍然保持高效，并能与MCTS无缝集成，提供高预期奖励。研究实证结果验证了SD-MDP方法的有效性和效率，为进一步的研究和实际应用提供了新的方向。"}
{"llm_update_time": "20251006", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.17774", "html_url": "https://arxiv.org/abs/2509.17774", "title": "高效且正确的决策树预测等价性", "title_en": "Efficient & Correct Predictive Equivalence for Decision Trees", "authors": "Joao Marques-Silva,Alexey Ignatiev", "background": "该研究基于决策树（DTs）在计算相同分类函数（即预测等价DTs）方面可以显著表示拉沙蒙集的一部分这一发现，指出了这种冗余的负面影响。这种冗余会导致基于拉沙蒙集的特征重要性变得不准确，而这种冗余是McTavish等人的早期工作中提出的。尽管该方法对于识别预测等价的DTs有所改进，但存在效率和正确性的问题。", "innovation": "论文创新地证明了存在决策树能够触发Quine-McCluskey方法的最坏情况指数运行时间和空间消耗。进一步，论文揭示了Quine-McCluskey方法在未遵守两个关键约束时可能会错误地判定预测等价性。更重要的是，论文展示了通过最小的DNF（析取范式）表示，可以将原问题转化为多项式时间内可解决的问题，从而提出了一种比McTavish等人的算法快得多的解决方案。", "conclusion": "实验结果证实，对于触发Quine-McCluskey方法最坏情况的决策树，本文提出的方法比McTavish等人的算法快一个数量级。这一结果表明，通过最小的DNF表示，多种问题可以在合理的时间内得到有效解决，同时也验证了新方法的高效性和正确性。"}
{"llm_update_time": "20251006", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.08970", "html_url": "https://arxiv.org/abs/2509.08970", "title": "Gala: 全局大型语言模型代理用于文本到模型翻译", "title_en": "Gala: Global LLM Agents for Text-to-Model Translation", "authors": "Junyang Cai,Serdar Kadioglu,Bistra Dilkina", "background": "自然语言对优化或满足条件问题的描述难以转化为正确的MiniZinc模型，这是一个同时需要逻辑推理和约束编程专业知识的过程。现有方法需要专业人员来正确地将自然语言描述转化为模型，这增加了工作难度和复杂性。", "innovation": "提出了一种名为Gala的框架，采用全局代理的方法，通过多个专门的大规模语言模型（LLM）代理，按全局约束类型分解建模任务。每个代理专注于检测和生成特定全局约束类别的代码，而最终的集成代理则将这些约束片段整合为完整的MiniZinc模型。通过将问题分解为更小的、有针对性的子任务，每个LLM可以处理更简单的推理挑战，从而可能降低整体复杂性。实验表明，与一次性提示和链式思维提示等基线方法相比，Gala表现出更好的性能。", "conclusion": "文章提出了Gala框架，对未来的改进路线图进行了展望，明确了潜在改进的方向，旨在进一步提高文本到模型转换的效率和准确性。"}
{"llm_update_time": "20251006", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.07649", "html_url": "https://arxiv.org/abs/2508.07649", "title": "多层时空过渡图表示学习的解纠缠化方法及其在社会增强POI推荐中的应用", "title_en": "Disentangling Multiplex Spatial-Temporal Transition Graph Representation Learning for Socially Enhanced POI Recommendation", "authors": "Jie Li,Haoye Dong,Zhengyang Wu,Zetao Zheng,Mingrong Lin", "background": "点兴趣（POI）推荐是商业智能研究的热点，用户的空间-时间过渡和社会关系起着关键作用。然而，现有的许多研究分别建模了空间和时间过渡，导致同一空间-时间关键节点的表示不一致，这在融合过程中引入了冗余信息，增加了模型的不确定性并降低了可解释性。", "innovation": "提出了一种基于多层时空过渡图解纠缠表示学习的社会增强POI推荐模型DiMuST。该模型采用了一种新颖的Disentangled可变多层图自动编码器（DAE），首先通过多层时空图策略分离共享和私有分布，然后通过专家乘积机制融合共享特征，并通过对比约束降噪私有特征。该模型能够有效捕捉POI的空间-时间过渡表示，同时保持其空间-时间关系的内在关联。", "conclusion": "在两个具有挑战性的数据集上的实验表明，我们的DiMuST在多个指标上显著优于现有的方法。"}
{"llm_update_time": "20251006", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.02580", "html_url": "https://arxiv.org/abs/2506.02580", "title": "V2X-UniPool: 融合多模态感知和知识推理的无人驾驶", "title_en": "V2X-UniPool: Unifying Multimodal Perception and Knowledge Reasoning for Autonomous Driving", "authors": "Xuewen Luo,Fengze Yang,Fan Ding,Xiangbo Gao,Shuo Xing,Yang Zhou,Zhengzhong Tu,Chenxi Liu", "background": "自动驾驶（AD）已取得显著进展，但单个车辆的感知仍然受限于感知识距和遮挡。车辆到一切（V2X）通信通过实现车辆与基础设施之间的协作来解决这些限制，但同时也面临异构性、同步和延迟的挑战。语言模型提供了强大的知识驱动的推理和决策能力，但它们并非天生设计来处理原始传感器流，并且容易产生幻觉。现有方法无法有效地将V2X感知与基于语言的推理结合，导致感知和决策的准确性和实时性不足，且通信成本高。", "innovation": "本文提出了V2X-UniPool，这是第一个将V2X感知与基于语言的推理统一起来的框架，用于知识驱动的自动驾驶。该框架将多模态的V2X数据转化为结构化的、基于语言的知识，组织在一个时间索引的知识池中用于时间一致的推理，并使用检索增强生成（RAG）来确保决策基于实时上下文。实验证明，V2X-UniPool在真实世界的DAIR-V2X数据集上实现了最先进的规划准确性和安全性，同时将通信成本降低了超过80%，是评估方法中通信开销最低的。这些结果突显了通过将V2X感知与知识推理结合来推动可扩展且可靠的驾驶的潜力。", "conclusion": "V2X-UniPool 通过结合V2X感知与基于语言的推理，提高了自动驾驶的安全性和效率，同时降低了通信成本。该研究展示了知识驱动的AD在复杂环境中的潜在应用前景，并强调了跨模态数据处理与语言推理集成的重要性。"}
{"llm_update_time": "20251006", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.13761", "html_url": "https://arxiv.org/abs/2509.13761", "title": "THOR: Tool-Integrated Hierarchical Optimization via RL for Mathematical Reasoning", "title_en": "THOR: Tool-Integrated Hierarchical Optimization via RL for Mathematical Reasoning", "authors": "Qikai Chang,Zhenrong Zhang,Pengfei Hu,Jun Du,Jiefeng Ma,Yicheng Pan,Jianshu Zhang,Quan Liu,Jianqing Gao", "background": "大型语言模型（LLMs）在数学推理方面取得了显著进步，但在高精度任务（如数值计算和形式符号操作）方面仍面临挑战。现有通过集成外部工具的方法在这类高精度任务上仍遇到三个关键挑战：构建工具集成推理数据、进行细粒度优化和增强推理。", "innovation": "该研究提出了一种名为THOR的新方法（Tool-Integrated Hierarchical Optimization via RL），具体创新包括：1）引入TIRGen，一种基于多代理actor-critic的管道，用于生成高质量的工具集成推理路径数据集，适用于多种模型。2）提出了一种基于强化学习的策略，联合优化每个问题解决的宏观层次和每个步骤代码生成的微观层次。3）引入了一种自我纠正机制，利用工具即时反馈动态修正推理路径中的错误。", "conclusion": "THOR在各种数学推理模型和代码模型中表现出强大的泛化能力，不仅在推理模型中表现出色，还实现了相似规模模型在多个数学基准测试上的最新性能，同时在代码基准测试中实现了持续的改进。该研究的代码将在指定的网址公开发布。"}
{"llm_update_time": "20251006", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.23263", "html_url": "https://arxiv.org/abs/2509.23263", "title": "GUI-PRA：为GUI任务设计的进程奖励代理", "title_en": "GUI-PRA: Process Reward Agent for GUI Tasks", "authors": "Tao Xiong,Xavier Hu,Yurun Chen,Yuhang Liu,Changqiao Wu,Pengzhi Gao,Wei Liu,Jian Luan,Shengyu Zhang", "background": "图形用户界面（GUI）代理由多模态大型语言模型（MLLMs）驱动，展示了自动化任务的巨大潜力，但它们在处理长期任务时表现不佳，常常发生频繁失败。过程奖励模型（PRMs）是一个有希望的解决方案，它们可以在推理过程中用关键的过程信号引导这些代理。然而，将它们应用于GUI领域带来了独特的挑战。在处理包含长时间序列数据的密集人工输入时，PRMs会遭受“失中现象”的困扰，即过载的历史背景削弱了对当前步骤的评估。此外，标准的PRMs缺乏对GUI变化的感知，提供的静态评估与当前行动的动态后果脱节，与GUI任务本质上是动态的这一特性不匹配。", "innovation": "我们提出了GUI-PRA (进程奖励代理GUI任务)，设计了一个评判代理以更好地提供过程奖励，相比标准PRMs，它通过智能处理历史上下文和积极感知UI状态变化来提高奖励评估。为直接对抗“失中现象”，引入了动态记忆机制，包括相关性检索模块来积极检索相关历史信息，以及渐进性总结模块来动态地凝练增长的交互数据，确保模型关注相关背景。此外，为解决缺乏GUI变化感知的问题，引入了自适应UI感知机制，这使得代理能够推理UI状态变化并动态选择最合适的工具来收集视觉证据，确保其评估始终基于当前UI环境。", "conclusion": "总之，GUI-PRA是一种特别设计的代理，用于提升在GUI任务中使用进程奖励的方法。通过动态记忆机制和自适应UI感知机制，GUI-PRA能够更好地处理长时间序列数据中的复杂反馈，确保对当前步骤进行更准确的评估，从而在GUI自动化任务中取得更好的结果。"}
{"llm_update_time": "20251006", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.25550", "html_url": "https://arxiv.org/abs/2509.25550", "title": "在世界隐空间中学习交互以实现团队协作", "title_en": "Learning to Interact in World Latent for Team Coordination", "authors": "Dongsu Lee,Daehee Lee,Yaru Niu,Honguk Woo,Amy Zhang,Ding Zhao", "background": "在多智能体强化学习(MARL)中，构建有效的团队协调表示是一项挑战性问题，因为多智能体间的复杂动态关系和由局部感知引发的信息不完整性使得构建这样的表示变得困难。", "innovation": "本文提出了一种名为交互世界隐空间(IWoL)的学习表示框架，它通过直接建模通信协议来构建可学习的表示空间，以实现团队间关系和特定任务的世界信息的联合捕捉，同时保持完全去中心化的执行方式和隐式协调。此外，该表示不仅可以作为每个智能体的隐式潜在表示，还可以作为交互的显式消息。", "conclusion": "在四个具有挑战性的MARL基准测试上，评估了IWoL的两种变体，结果表明IWoL提供了简单而强大的团队协调关键。此外，我们展示了我们的表示可以与现有的MARL算法结合使用，进一步增强它们的表现。"}
{"llm_update_time": "20251006", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.25522", "html_url": "https://arxiv.org/abs/2509.25522", "title": "从模型扩展视角理解基于语义ID的生成推荐", "title_en": "Understanding Generative Recommendation with Semantic IDs from a Model-scaling View", "authors": "Jingzhe Liu,Liam Collins,Jiliang Tang,Tong Zhao,Neil Shah,Clark Mingxuan Ju", "background": "近年来，生成模型的进步为推荐系统（RS）引入了一种新的范式，即生成推荐（GR），它试图统一丰富的项目语义和协作过滤信号。其中一种流行的方法是使用语义ID（SIDs），它们是由模态编码器（如大型语言模型或视觉模型）的嵌入量化而来的离散代码，来表示项目。尽管在其他领域，生成模型表现出成熟的扩展规律，但我们的工作揭示了基于SIDs的GR在扩大模型规模时存在显著的瓶颈。特别地，随着每个组件（模态编码器，量化分词器和RS本身）的增大，基于SIDs的GR的性能迅速饱和。", "innovation": "本研究识别了SIDs编码项目语义信息的容量限制作为基本瓶颈之一。通过实际实验，我们重访了另一种基于大型语言模型（LLMs）直接作为推荐者的GR范式（即LLM-as-RS），展示了LLM-as-RS在模型扩展性方面的优越性和超过基于SIDs的GR的最高可实现性能20%的表现改进。此外，本研究表明LLMs能够捕捉协作过滤信息的能力随着模型规模的增加而增强。", "conclusion": "本研究通过对不同规模模型从44M到14B参数的分析，进一步突显了基于SIDs的GR的固有扩展限制，并将LLM-as-RS定位为生成推荐领域通往基础模型的一个有希望的方向。"}
{"llm_update_time": "20251006", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.01620", "html_url": "https://arxiv.org/abs/2510.01620", "title": "仅需足够信息进行决策：基于信息论的CMDP上下文总结学习", "title_en": "Learning to Decide with Just Enough: Information-Theoretic Context Summarization for CMDPs", "authors": "Peidong Liu,Junjiang Lin,Shaowen Wang,Yao Xu,Haiqing Li,Xuhao Xie,Siyi Wu,Hao Li", "background": "现有的 CMDPs 方法在处理高维或非结构化上下文时往往无法很好地泛化，导致计算量过大且性能不稳定。", "innovation": "提出了一种基于信息论的上下文总结方法，利用大型语言模型（LLMs）将上下文输入压缩成低维且富含语义的摘要，这些摘要通过保留决策关键线索来丰富状态，同时减少冗余。证明了该方法的后悔界，并提供了计算延迟与熵之间的权衡分析，显示了信息量对计算成本的影响。", "conclusion": "实验结果表明，该方法在多个领域（离散、连续、视觉和推荐）中优于未使用上下文和非上下文基线方法，提高了奖励、成功率和样本效率，同时减少了延迟和内存使用。研究结果表明，基于LLM的总结方法可以为资源受限的丰富上下文环境中的高效决策提供一种可扩展且可解释的解决方案。"}
{"llm_update_time": "20251006", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.26495", "html_url": "https://arxiv.org/abs/2509.26495", "title": "OffTopicEval：当大型语言模型进入错误对话时，几乎总是如此！", "title_en": "OffTopicEval: When Large Language Models Enter the Wrong Chat, Almost Always!", "authors": "Jingdi Lei,Varun Gumma,Rishabh Bhardwaj,Seok Min Lim,Chuan Li,Amir Zadeh,Soujanya Poria", "background": "大型语言模型（LLM）的安全性是实现广泛的部署所面临的最紧迫挑战之一。虽然大多数研究和全球讨论主要关注通用危害，例如模型协助用户自我或他人伤害，企业更关注的是基于LLM的代理是否适用于其预定用例是否安全。评估和解决这一问题需要一个新的视角——即操作安全性，定义为LLM在执行特定任务时正确接受或拒绝用户查询的能力。为了评估这一点，作者提出了OffTopicEval，这是一个针对通用和特定代理用例的操作安全性评估套件和基准。", "innovation": "论文提出了操作安全性这一新的概念并定义为LLM在执行特定任务时正确接受或拒绝用户查询的能力。此外，论文还提出了一种名为OffTopicEval的评估工具和基准，用于测量在一般和特定代理用例中的操作安全性。基于六大模型家族的20款开放权重LLM的评估显示，尽管性能差距较大，但所有模型在操作安全性上表现不佳。论文还提出了两种基于提示的引导方法：查询接地（Q-ground）和系统提示接地（P-ground），这两种方法显著提高了OOD拒绝的成功率。", "conclusion": "论文强调了操作安全性干预的迫切需求，并指出基于提示的引导作为提高LLM代理可靠性第一步的前景。尽管GPT模型、Phi以及其他模型的性能表现差异明显，但在操作安全性方面，这些模型的表现都令人担忧。为了抑制这些失败，本文提出并展示了基于提示的引导方法的有效性，这些方法显著提高了模型在异常拒绝任务上的表现。"}
{"llm_update_time": "20251006", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.04404", "html_url": "https://arxiv.org/abs/2507.04404", "title": "LayerCake：大型语言模型层内的意识对比解码", "title_en": "LayerCake: Token-Aware Contrastive Decoding within Large Language Model Layers", "authors": "Jingze Zhu,Yongliang Wu,Wenbo Zhu,Jiawang Cao,Yanqiang Zheng,Jiawei Chen,Xu Yang,Bernt Schiele,Jonas Fischer,Xinting Hu", "background": "大型语言模型在自然语言理解和生成方面表现出色，但在涉及专业知识的任务中容易出现事实性错误。现有解码时的策略提供了高效的解决方案，但它们往往孤立处理标记级和层级信号，忽略了它们之间的联合动态。本文通过实证关注分析发现了两种关键模式：标点符号在早期层中占据主导地位，而概念性标记在中间层中管理语义推理。通过在这些标记类型的不同深度选择性抑制注意力，从而引导控制事实性下降，并生成对比信号以指导最终的事实解码。这种方法无需额外训练或模型修改，实验结果证明了其在多个大型语言模型和各种基准测试上的一致性改进效果。", "innovation": "论文提出了一个标记感知、层定位的对比解码方法，该方法将特定类型标记与其最活跃的转换器层对齐，以提高事实生成。通过选择性抑制特定标记类型的注意力，实现受控的事实损失，并使用对比信号来引导最终的事实解码。该方法无需额外训练或模型修改，并展示了在多种大型语言模型和不同基准测试上的持续改进效果。", "conclusion": "该研究通过识别和利用标记类型的层间关注模式，提出了一种无需额外训练或模型修改的对比解码方法，该方法显著提高了大型语言模型的事实性生成能力。"}
{"llm_update_time": "20251006", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.22315", "html_url": "https://arxiv.org/abs/2509.22315", "title": "PRIME：增强推理中的规划和检索集成记忆", "title_en": "PRIME: Planning and Retrieval-Integrated Memory for Enhanced Reasoning", "authors": "Hieu Tran,Zonghai Yao,Nguyen Luong Tran,Zhichao Yang,Feiyun Ouyang,Shuo Han,Razieh Rahimi,Hong Yu", "background": "受《思考，快与慢》中人类认知的双重过程理论启发，作者提出了一个名为PRIME（Planning and Retrieval-Integrated Memory for Enhanced Reasoning）的多智能体推理框架，该框架动态地整合了快速直觉的System 1和缓慢审慎的System 2。", "innovation": "PRIME框架采用了快速思考代理（System 1）生成快速答案，若检测到不确定性，则触发一个由专门进行规划、假设生成、检索、信息整合和决策制定的智能体组成的结构化System 2推理管道。这种多智能体设计真实地模拟了人类的认知过程，提高推理的效率和准确性。实验结果表明，PRIME能够使开源大型语言模型在需要多跳推理和知识导向推理的基准测试中表现出色，与最新的商用大型语言模型GPT-4和GPT-4o等接近。", "conclusion": "这项研究将PRIME确立为一个在需要复杂、知识密集型推理的领域中提高大型语言模型的可扩展解决方案。"}
{"llm_update_time": "20251006", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.00186", "html_url": "https://arxiv.org/abs/2510.00186", "title": "Thinkquel: 一种用于Text-to-dbt的模型，采用合成数据和上下文感知目标", "title_en": "Thinkquel: A Model Dedicated to Text-to-dbt Using Synthetic Data and a Span-Aware Objective", "authors": "Anni Li,Aria Attar,Paul Dong", "background": "将自然语言请求转换为可靠、生产线级别的数据转换仍然具有挑战性。正确性取决于精确的模式链接和专门的SQL方言，而目前可用的最强监督仅在序列级别提供执行成功和结果匹配。同时，构建大型、经过执行验证的数据集成本极高，基于标记的优化目标与全局信号不一致，导致优化不稳定且缺乏普适性。", "innovation": "提出了Thinkquel，这是一种微调模型，用于生成坚固、普适且经过执行验证的数据库查询。Thinkquel采用了一种新颖的合成数据管道TS-SQL，并使用dbt作为可移植的中间表示，结合了上下文感知的强化学习目标TS-GRPO，旨在填补标记级别训练信号与序列级执行奖励之间的差距。实验结果显示，使用两阶段微调课程，Thinkquel（32B）在500个示例TS-SQL测试集上的执行成功率和结果精确匹配率分别达到93.2%和61.8%，相较于基础模型分别提高了67.2%（执行）和44.4%（匹配）。在Spider（14B）实验中，TS-GRPO相比GRPO和GSPO提高了训练稳定性和执行匹配奖励的收敛速度。", "conclusion": "Thinkquel通过合成数据管道和特定的设计方案，显著提升了基于序列的训练信号与全局执行奖励的匹配度，展示了其在构建可靠数据库查询方面的优越性能。"}
{"llm_update_time": "20251006", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2405.18406", "html_url": "https://arxiv.org/abs/2405.18406", "title": "RACCooN: 自动生成叙述的多功能视频编辑框架", "title_en": "RACCooN: A Versatile Instructional Video Editing Framework with Auto-Generated Narratives", "authors": "Jaehong Yoon,Shoubin Yu,Mohit Bansal", "background": "最近的视频生成模型主要依赖于精心撰写的文本提示来完成特定任务，如填补、风格编辑等。这些模型需要对输入视频进行细致的文字描述，这限制了其对个人或未经处理的视频的适应性和灵活性。", "innovation": "RACCooN 提出了一个多功能且用户友好的视频到段落到视频生成框架，该框架通过一个统一的管道支持多种视频编辑能力，包括删除、添加和修改。RACCooN 有两个主要阶段：视频到段落（V2P）和段落到视频（P2V）。在 V2P 阶段，自动将视频场景描述为结构良好的自然语言，捕捉整体上下文和聚焦对象细节。在 P2V 阶段，用户可以对这些描述进行优化以指导视频扩散模型，从而对输入视频进行各种修改，例如删除、更改主题和/或添加新对象。该方法的贡献在于：（1）RACCooN 建议使用多粒度的空间时间聚集策略自动生成结构良好的视频描述，从而捕捉广泛的情境和对象细节，简化基于文本的精确视频内容编辑；（2） 视频生成模型结合了自动生成的故事叙述或指令，以提高生成内容的质量和准确性；（3）RACCooN 还计划在给定的视频中想象新的对象，使得用户只需简单地提示模型来获得详细的视频编辑计划以执行复杂的视频编辑。", "conclusion": "RACCooN 框架在视频到段落生成、视频内容编辑方面展示了惊人的多功能性，并且可以与其他先进的视频生成模型结合使用以进一步增强其性能。"}
{"llm_update_time": "20251006", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.02125", "html_url": "https://arxiv.org/abs/2510.02125", "title": "不同模态下AI模型是否能进行类似人类的抽象推理？", "title_en": "Do AI Models Perform Human-like Abstract Reasoning Across Modalities?", "authors": "Claas Beger,Ryan Yi,Shuhao Fu,Arseny Moskvichev,Sarah W. Tsai,Sivasankaran Rajamanickam,Melanie Mitchell", "background": "OpenAI的o3-preview推理模型在ARC-AGI基准测试中超过了人类的准确性，但是否意味着最先进的模型能够识别和推理创作者所期望的抽象内容？本文探讨了模型在识别和推理抽象方面的表现，通过不同输入模态（文本 vs 视觉）、是否允许使用外部Python工具以及推理努力程度的变化，进行了一系列评估。同时，通过细粒度评估模型生成的自然语言规则来解释其解决方案，从而判断模型是否使用了设计概念ARC来唤起的抽象，而不是依赖于表面模式。", "innovation": "采用了一种双评估框架，不仅衡量输出准确性，还细粒度评估模型生成的解释自然语言规则，以此来判断模型是否使用了设计上概念ARC所期望的抽象，而非依赖于表面模式。该方法揭示了一些模型通过文本表示达到人类输出准确性，但其规则往往基于表面“捷径”，而不是经常捕捉到创作者的意图。", "conclusion": "虽然一些模型在文本表示下能够达到人类的输出准确性，但最佳模型的规则往往基于表面的“捷径”，而不是人类那样经常捕捉到创作者的意图。因此，仅通过准确性来评估的抽象推理能力可能被高估。在视觉模态下，AI模型的输出准确性急剧下降，但我们的规则级分析显示，模型可能被低估，因为它们仍然表现出大量捕捉到创作者意图的规则，但由于无法正确应用这些规则，无法发挥全部潜力。综上所述，我们的结果表明，模型仍落后于人类的抽象推理能力，单凭准确性来评估类似ARC任务的抽象推理能力可能会在文本模态上高估，在视觉模态上低估。我们相信，我们的评估框架提供了对跨模态模型抽象推理能力更真实的描绘，也为追踪向人类样式的、以抽象为中心的智能的进步提供了一个更原则性的方法。"}
{"llm_update_time": "20251006", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2501.12266", "html_url": "https://arxiv.org/abs/2501.12266", "title": "CBVLM: 无需训练的基于概念的大型视图语言模型的解释性医疗图像分类", "title_en": "CBVLM: Training-free Explainable Concept-based Large Vision Language Models for Medical Image Classification", "authors": "Cristiano Patrício,Isabel Rio-Torto,Jaime S. Cardoso,Luís F. Teixeira,João C. Neves", "background": "在医疗工作流程中采用基于深度学习的解决方案受到两点限制：标注数据的可用性和此类系统的解释性不足。通过约束模型输出到一组预定义且可由人类解释的概念，概念瓶颈模型（CBMs）解决了解释性的不足，但这也增加了标注负担。如果要添加新概念，整个系统需要重新训练。", "innovation": "本文提出了CBVLM方法，利用大型视图-语言模型（LVLM）的少量样本学习能力，解决CBMs和任务特定监督方法的两大挑战。具体来说，CBVLM在每个概念上促使LVLM判断输入图像中是否存在该概念；然后根据前一个概念预测来分类图像。此外，在两阶段中都集成了一个检索模块，用于选择最佳示例进行上下文学习。这种方法不仅确保了可解释性，还大大降低了标注成本。", "conclusion": "通过在四个医疗数据集和十二个LVLM（通用和医疗）模型上进行广泛实验的结果表明，CBVLM在不进行训练的情况下，仅使用少量标注示例，始终优于CBMs和任务特定的监督方法。更多详细信息请参阅我们的项目页面：this https URL."}
{"llm_update_time": "20251006", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2311.13254", "html_url": "https://arxiv.org/abs/2311.13254", "title": "统一领域自适应语义分割", "title_en": "Unified Domain Adaptive Semantic Segmentation", "authors": "Zhe Zhang,Gaochang Wu,Jing Zhang,Xiatian Zhu,Dacheng Tao,Tianyou Chai", "background": "UDA-SS旨在将源领域带标签的监督转移到目标领域。现有研究多关注图像，最近开始处理视频，通过建模时间维度来应对挑战。不过，图像和视频领域研究虽然面临类似问题，但独立发展导致知识碎片化，缺乏全面的理解和交叉启发的机会，阻碍了方法的统一和发展。因此，本文提出统一研究图像和视频领域中的UDA-SS，以期更好地理解、促进协同创新和知识共享。\n", "innovation": "本文提出了一种Quad-directional Mixup（QuadMix）方法，通过四个方向的路径在特征空间中进行跨域混合，解决不同点属性和特征不一致性问题。为了应对视频中的时间偏差，本文还引入了基于光流引导的跨时空维度特征聚合，实现细粒度领域对齐。实验表明，方法在四个挑战性UDA-SS基准上的表现明显优于最新技术。\n", "conclusion": "本文探索了统一的UDA-SS，提出了QuadMix方法，通过以上技术创新，增强了泛化能力，并促进知识共享。本研究促进了该领域的发展和实际应用的影响。"}
{"llm_update_time": "20251006", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2406.03508", "html_url": "https://arxiv.org/abs/2406.03508", "title": "预训练编码器的互信息引导防后门方法", "title_en": "Mutual Information Guided Backdoor Mitigation for Pre-trained Encoders", "authors": "Tingxu Han,Weisong Sun,Ziqi Ding,Chunrong Fang,Hanwei Qian,Jiaxun Li,Zhenyu Chen,Xiangyu Zhang", "background": "自监督学习（SSL）由于无需标注数据就可以预训练编码器，近年来越来越受到青睐。这些预训练的编码器构建的下游任务可以实现接近最先进的性能。然而，已有研究证明，通过SSL预训练的编码器容易受到后门攻击的影响。尽管有许多专为下游任务模型设计的后门攻击缓解技术，但当应用于预训练的编码器时，由于预训练过程中缺乏标签信息，其效果减弱和受限。", "innovation": "为了解决针对预训练编码器的后门攻击，论文提出了一种新颖的互信息引导的后门缓解技术，称为MIMIC。MIMIC将潜在的后门编码器视为教师网络，并通过知识蒸馏从教师网络中提炼一个无后门的学生编码器。MIMIC不同于现有的知识蒸馏方法，它初始化学生网络时使用随机权重，不继承教师网络的后门。MIMIC利用每层和提取特征之间的互信息来定位教师网络中的干净知识所在，然后利用这些知识进行蒸馏，从教师网络复制干净特征到学生网络。MIMIC以两方面构建蒸馏损失，包括克隆损失和注意力损失，旨在同时缓解后门和保持编码器性能。", "conclusion": "结果表明，MIMIC仅使用不到5%的干净数据即可显著降低两种SSL后门攻击的成功率，超越了七个最先进的后门缓解技术。"}
{"llm_update_time": "20251006", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2503.04697", "html_url": "https://arxiv.org/abs/2503.04697", "title": "L1：使用强化学习控制推理模型思考的时长", "title_en": "L1: Controlling How Long A Reasoning Model Thinks With Reinforcement Learning", "authors": "Pranjal Aggarwal,Sean Welleck", "background": "现有的语言模型在测试时通过生成更长的推理链以获得更多计算资源来提高性能，但这并没有控制推理链的长度，使得测试时的计算资源无法根据所需的性能水平进行有效分配。", "innovation": "提出了Length Controlled Policy Optimization (LCPO)，一种简单的强化学习方法，用于在保证准确性的前提下，遵循用户指定的长度约束，从而训练出长度可控的语言模型L1，该模型可以根据任务需求灵活权衡计算成本与准确率，并且在长度控制方面优于现有方法S1。进一步发现，使用LCPO训练的语言模型具有短推理链能力，即能够产生与非推理模型相当长度的推理链，但仍展现出类似全长推理模型的推理模式。", "conclusion": "LCPO能够精确控制推理长度，使得测试时计算资源和性能可以根据实际需求进行精细分配。研究团队发布了代码和模型以供进一步研究。"}
{"llm_update_time": "20251006", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2502.11191", "html_url": "https://arxiv.org/abs/2502.11191", "title": "Primus: 首创的用于网络安全大语言模型训练的开源数据集集合", "title_en": "Primus: A Pioneering Collection of Open-Source Datasets for Cybersecurity LLM Training", "authors": "Yao-Ching Yu,Tsun-Han Chiang,Cheng-Wei Tsai,Chien-Ming Huang,Wen-Kwang Tsao", "background": "大型语言模型（LLMs）在金融、法律和医学等专业领域取得了显著的进步。但是，在网络安全领域，我们注意到缺乏开源数据集，特别是在高质量的网络安全预训练语料库方面存在明显不足，尽管许多研究表明LLMs的知识是在预训练阶段习得的。因此，本文通过提供覆盖所有主要训练阶段（包括预训练、指令微调和具有网络安全特定自我反思数据的推理精炼）的全面数据集来解决这一问题。", "innovation": "本文提出了一套全面的数据集，覆盖了网络安全大语言模型训练的所有主要阶段，包括预训练、指令微调和与网络安全特定自我反思数据相结合的推理精炼。通过广泛的消融研究验证了其在公共网络安全基准上的有效性，特别是在持续预训练和推理精炼方面，分别提升了15.9%和15.8%的综合得分和CISSP安全认证分值。", "conclusion": "所有数据集和训练后的网络安全大语言模型将在ODC-BY和MIT许可证下开放发布，鼓励研究社区进一步研究。所有数据集和模型权重请访问 this https URL 获取。"}
{"llm_update_time": "20251006", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2502.14837", "html_url": "https://arxiv.org/abs/2502.14837", "title": "向经济推理迈进：使任何基于Transformer的LLMs启用DeepSeek的多头潜在注意", "title_en": "Towards Economical Inference: Enabling DeepSeek's Multi-Head Latent Attention in Any Transformer-based LLMs", "authors": "Tao Ji,Bin Guo,Yuanbin Wu,Qipeng Guo,Lixing Shen,Zhan Chen,Xipeng Qiu,Qi Zhang,Tao Gui", "background": "传统的大型语言模型（LLMs）使用多头注意（MHA）及其变体（如分组查询注意（GQA）），这些模型存在显著的成本劣势，特别是在关键值（KV）缓存的压缩方面。DeeSeek提出了一种名为Multi-head Latent Attention（MLA）的新颖架构，旨在通过显著压缩KV缓存为潜在向量来实现高效和经济的推理。在此之前，已训练良好的LLMs（例如Llama）快速适应MLA而不从头开始预训练，是一个既具有重要意义又具有挑战性的目标。", "innovation": "本文提出了第一个针对从MHA到MLA（MHA2MLA）的数据高效微调方法。该方法包括两个关键组成部分：1）部分RoPE，即从贡献较少注意力分数的查询和键维度中去除RoPE；2）低秩近似，引入基于预训练键值参数的联合SVD近似。这些精心设计的策略使得MHA2MLA仅使用极小的数据量（0.3%到0.6%）就能恢复性能，大幅减少了推理成本，并无缝地与KV缓存量化等压缩技术兼容。例如，将Llama2-7B的KV缓存大小减少了92.19%，并且仅导致LongBench性能下降0.5%。", "conclusion": "通过这种新的MHA2MLA方法，任何基于Transformer的LLMs都可以适应DeeSeek的MLA架构，从而实现经济高效的推理，尤其是在减少最新模型（例如Llama2-7B）的KV缓存大小方面，性能影响较小。"}
{"llm_update_time": "20251006", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2406.08534", "html_url": "https://arxiv.org/abs/2406.08534", "title": "通过混合遗传算法实现运载工具双循环和码头场地内倒箱减少的集装箱装卸优化", "title_en": "Optimizing Container Loading and Unloading through Dual-Cycling and Dockyard Rehandle Reduction Using a Hybrid Genetic Algorithm", "authors": "Md. Mahfuzur Rahman,Md Abrar Jahin,Md. Saiful Islam,M. F. Mridha", "background": "本文解决了港口集装箱装卸的NP难问题，侧重于整合岸桥双循环（QCDC）和码头场地内倒箱最小化。研究认为岸桥卸货序列与码头场地计划之间存在相互依赖性，提出了兼容遗传算法（GA）的混合算法——岸桥双循环—码头场地内倒箱遗传算法（QCDC-DR-GA），该算法同时优化了双循环次数的最大化和码头场地倒箱次数的最小化。通过不同船型的广泛实验显示，对于大型船只，QCDC-DR-GA相比现有方法可以减少15-20%的操作时间。使用双尾配对t检验进行的统计验证表明，在显著性水平为5%时，明显有所改进。这强调了孤立优化的低效性，并突显了港口运营中集成算法的迫切需求，这可以提高资源利用和操作效率，提供一种不需基础设施投资的运营成本优化方案。", "innovation": "提出的QCDC-DR-GA算法，结合了双循环和码头场地最小化，采用专门的交叉和变异策略。该算法在大型船只上验证了15-20%的操作时间减少，并通过统计检验展示了显著性改进，这表明与现有的单独优化方法相比，集成算法在港口操作中更为有效。", "conclusion": "研究结果强调了独立优化的低效率，提出需要集成算法来提高资源利用率和操作效率，提供了一种经济有效的解决方案，即通过QCDC-DR-GA减少港口的周转时间，而无需进行基础设施投资。"}
{"llm_update_time": "20251006", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2406.15676", "html_url": "https://arxiv.org/abs/2406.15676", "title": "使用机器学习进行插件类型推断", "title_en": "Inferring Pluggable Types with Machine Learning", "authors": "Kazi Amanul Islam Siddiqui,Martin Kellogg", "background": "可插拔类型系统允许程序员扩展编程语言的类型系统，以实现由程序员定义的语义属性。然而，在迁移到插件类型系统时，由于需要手动编写类型注解，因此在现有的代码库中难以部署。本文研究了如何利用机器学习自动推断类型修饰符，提出了一种新表示法NaP-AST，用于有效地推断类型修饰符，并评估了多种模型架构以推断类型修饰符，包括图形变换网络、图形卷积神经网络和大型语言模型。实验结果显示，图形变换网络（GTT）的召回率为0.89，精度为0.6，表现最佳。此外，研究还评估了训练模型所需的Java类数量，结果表明，当模型性能良好时，大约需要16,000个类，超过22,000个类后性能下降主要是由于过拟合造成的。", "innovation": "本文提出了一种新的表示法NaP-AST，用于有效地从代码中推断出需要的类型标识符。通过评估不同模型架构并应用于多个开源程序，研究证明了利用机器学习自动推断类型修饰符的有效性，并发现图形变换网络（GTT）具有最佳表现。进一步地，研究还评估了训练模型所需的Java类数量。", "conclusion": "研究发现，使用图形变换网络（GTT）在推断类型修饰符方面表现出色，召回率为0.89，精度为0.6。此外，为取得良好的性能，大约需要16,000个Java类，而超过22,000个类后，性能会由于过拟合而下降。"}
{"llm_update_time": "20251006", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2501.07186", "html_url": "https://arxiv.org/abs/2501.07186", "title": "传输电网拓扑控制中的图神经网络：母线信息不对称和异构表示", "title_en": "Graph Neural Networks for Transmission Grid Topology Control: Busbar Information Asymmetry and Heterogeneous Representations", "authors": "Matthijs de Jong,Jan Viebahn,Yuliya Shapovalova", "background": "随着可再生能源的普及和电气化的推进，电网拥堵成为了一个紧迫的问题。拓扑控制是一种有吸引力的方法来缓解这种情况，但传统的拓扑发现方法速度过慢，不适合实际应用。最近的研究焦点转向了利用机器学习作为替代方案，图神经网络因其能建模电力电网的图形结构而特别适合拓扑控制应用。尽管如此，由于母线信息的不对称性，传统的同构图表示存在问题，因此提出了异构图表示来解决这个问题。", "innovation": "该研究探讨了图形表示对图神经网络在拓扑控制中的有效性的影响，识别了流行同构图表示中的母线信息不对称问题，并提出了一种异构图形表示的方法。通过在模拟学习任务中应用图神经网络和全连接神经网络（FCNN）基线，评估了模型通过分类精度和电网操作能力进行评判。研究发现，在内部网络配置中，异构图神经网络表现最好，其次为FCNN，最后是同构图神经网络；且两种图神经网络类型在外部网络配置中都比FCNN有更好的泛化能力。这些结果表明，异构图形表示在拓扑控制中的图神经网络应用中的优越性。", "conclusion": "异构图神经网络在内部网络配置中表现最佳，其次FCNN表现良好，而同构图神经网络表现最差。此外，图神经网络模型在外部网络配置中的泛化能力优于全连接神经网络，表明异构图形表示在拓扑控制中的优越性。"}
{"llm_update_time": "20251006", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2502.17537", "html_url": "https://arxiv.org/abs/2502.17537", "title": "重新思考概念擦除的脆弱性及一种新方法", "title_en": "Rethinking the Vulnerability of Concept Erasure and a New Method", "authors": "Alex D. Richardson,Kaicheng Zhang,Lucas Beerens,Dongdong Chen", "background": "近年来，文本到图像的扩散模型的普及引发了严重的隐私和安全担忧，特别是关于生成受版权保护或有害图像的问题。现有的概念擦除（防御）方法通过后处理微调来“忘记”特定的概念，但最近的研究表明，这些概念可以通过利用对抗性构造的提示进行恢复，现有防护机制存在重大漏洞。研究人员发现，这些漏洞普遍存在，尤其是在概念擦除模型的提示嵌入空间中，这些特性源自原始未学习的模型。", "innovation": "提出了一种名为RECORD的新颖坐标下降恢复算法，该算法通过对抗性构造的提示进行恢复，相比现有方法在性能上提升显著，最高可达17.8倍。此外，作者还进行了广泛的实验来评估算法的计算性能折衷，并提出了加速策略。", "conclusion": "研究表明，现有的概念擦除机制存在重大脆弱性，这些弱点源于原始未学习模型的提示嵌入空间。本文提出的RECORD算法能够有效地恢复擦除的概念，且在性能上取得了显著改进，为未来的隐私保护技术提供了新的思路。"}
{"llm_update_time": "20251006", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2503.09008", "html_url": "https://arxiv.org/abs/2503.09008", "title": "在图机器学习中量化长程交互：一个大规模图数据集及其度量", "title_en": "Towards Quantifying Long-Range Interactions in Graph Machine Learning: a Large Graph Dataset and a Measurement", "authors": "Huidong Liang,Haitz Sáez de Ocáriz Borde,Baskaran Sripathmanathan,Michael Bronstein,Xiaowen Dong", "background": "现有的图数据集主要集中在小型图上，这些图适用于诱导任务，对长程交互的理解有限。现有评估主要比较使用全局注意力的模型（如图变换器）与使用局部邻域聚合的模型（如消息传递神经网络），但缺乏对长程依赖性的直接度量。", "innovation": "本研究引入了名为City-Networks的新数据集，该数据集基于真实城市的道路网络，包含超过10万个节点的大规模图，直径远大于现有基准中的图，自然地包含长程信息。此外，作者提出了一种基于遥hop邻居雅可比矩阵的模型无偏度量方法，提供了一种可操作的方法来量化长程依赖。并在理论上证明了这种度量方式的有效性。", "conclusion": "该研究提供了理论依据证明了数据集设计和提出的度量方法的有效性，为图神经网络中进一步研究长程交互奠定了坚实基础。"}
{"llm_update_time": "20251006", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2406.07714", "html_url": "https://arxiv.org/abs/2406.07714", "title": "LLAMAFUZZ: 大型语言模型增强的灰盒模糊测试", "title_en": "LLAMAFUZZ: Large Language Model Enhanced Greybox Fuzzing", "authors": "Hongxiang Zhang,Yuyang Rong,Yifeng He,Hao Chen", "background": "灰盒模糊测试在揭示程序中的漏洞方面取得了成功，但随机化的变异策略限制了其在结构化数据上的性能。特定的模糊测试工具能够处理复杂的结构化数据，但需要额外的努力来编写语法，并且吞吐量较低。为克服这些问题，本文探索了使用大型语言模型（LLM）来增强灰盒模糊测试处理结构化数据的能力。利用LLM对数据转换和格式预先掌握的知识来生成新的有效输入，并通过对配对变异种子的进一步微调来高效地学习结构化格式和变异策略。", "innovation": "本文提出了LLAMAFUZZ，一个利用LLM来理解和变异结构化数据的增强型灰盒模糊测试工具。它通过利用LLM的知识生成新输入，并通过配对的变异种子进行微调，使模糊测试能够更有效地处理结构化数据。实验表明，LLAMAFUZZ在标准的基于错误的基准测试Magma和多个真实世界程序上都优于对手，平均发现41个错误，且在功能性触发和修复bug方面表现稳定。与AFL++相比，LLAMAFUZZ在真实世界程序集上的分支覆盖率平均提高了27.19%。此外，还提供了一个案例研究，展示了LLM如何在代码覆盖率方面增强模糊测试过程。", "conclusion": "通过引入LLM，LLAMAFUZZ在结构化数据的模糊测试中提高了性能，发现了更多的新漏洞，并在多种真实世界程序上表现出了较高的稳定性。这表明大型语言模型可以有效地增强灰盒模糊测试工具处理复杂数据的能力。未来的研究可以进一步优化LLM的集成和迭代策略，以进一步提高模糊测试的效果。"}
{"llm_update_time": "20251006", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2502.00415", "html_url": "https://arxiv.org/abs/2502.00415", "title": "MarketSenseAI 2.0: 通过大语言模型代理增强股票分析", "title_en": "MarketSenseAI 2.0: Enhancing Stock Analysis through LLM Agents", "authors": "George Fatouros,Kostas Metaxas,John Soldatos,Manos Karathanassis", "background": "MarketSenseAI 是一个新颖的框架，利用大语言模型（LLMs）处理金融新闻、历史价格、公司基本面和宏观经济环境的信息，支持股票分析和投资决策。该论文介绍了 MarketSenseAI 的最新进展，得益于大语言模型技术的迅速发展。该框架通过检索增强生成和 LLM 代理的新型架构处理 SEC 报告和收益电话会议，通过系统化处理各种机构报告来丰富宏观经济分析。实证研究表明，与之前的版本相比，在基础分析准确性方面有了显著提高。在 2023-2024 年的 S&P 100 股票上，该框架实现了累计回报率为 125.9%，而市场指数回报率为 73.5%，同时保持相似的风险水平。进一步验证表明，该框架在 S&P 500 股票上的 Sortino 比例比市场高出 33.8%。这项工作标志着将大语言模型技术应用于金融分析的重大进步，提供有关大语言模型驱动的投资策略稳健性的见解。", "innovation": "该论文的创新在于引入了检索增强生成和大语言模型代理的结合架构，处理 SEC 报告和收益电话会议，同时通过系统化处理各种机构报告来丰富宏观经济分析。与之前的版本相比，基础分析的准确性有了显著提高。在 S&P 100 股票上，该框架实现了累计回报率为 125.9%，比市场指数回报率高出 52.4%，同时维持相似的风险水平。进一步验证表明，该框架在 S&P 500 股票上的 Sortino 比例比市场高出 33.8%。这突显了大语言模型在金融分析中的潜力和应用价值。", "conclusion": "这项工作在运用大语言模型进行金融分析方面取得了显著进展，展示了大语言模型驱动的投资策略的稳健性。通过增强基础分析和宏观经济分析，MarketSenseAI 在股票分析选择中展示了强大的性能。该研究还指出了未来进一步整合更多种类的数据和改进模型有效性的重要性。"}
{"llm_update_time": "20251006", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2503.05696", "html_url": "https://arxiv.org/abs/2503.05696", "title": "多保真度控制方差方法用于策略梯度估计", "title_en": "A Multi-Fidelity Control Variate Approach for Policy Gradient Estimation", "authors": "Xinjie Liu,Cyrus Neary,Kushagra Gupta,Wesley A. Suttle,Christian Ellis,Ufuk Topcu,David Fridovich-Keil", "background": "许多强化学习（RL）算法由于需要大量数据，在实际部署或使用计算成本高的高保真模拟器训练时变得不切实际。低保真度模拟器，如降阶模型、直觉奖励或生成世界模型，虽然提供有用的训练数据但数据保真度不够高，无法实现零样本迁移。", "innovation": "提出了多保真度策略梯度（MFPG）框架，该框架结合了目标环境少量的真实数据和大量低保真度模拟数据形成控制变异，构建了无偏且方差减少的策略梯度估计量。该框架的实例化形式为经典的REINFORCE算法的多保真度变种。MFPG在目标环境中确保了REINFORCE算法收敛到局部最优策略，并且相较于仅使用高保真数据，具有更快的样本收敛速度。在具有有限高保真数据但大量离线动力学数据的模拟机器人基准任务中，评估了MFPG算法。MFPG在中等动态差异条件下能显著提升性能，甚至在低保真度奖励模型错配时仍能有效工作。", "conclusion": "MFPG不仅提供了一种高效模拟到现实转移的新范式，还提供了一种管理政策性能与数据收集成本之间权衡的科学方法。在大动态差异条件下，MFPG展示了最强的鲁棒性，且即便在低保真度奖励模型描述不准确的情况下仍然有效。"}
{"llm_update_time": "20251006", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2503.13445", "html_url": "https://arxiv.org/abs/2503.13445", "title": "话语冗余权衡与大规模提升语言模型自我解释忠实度的影响", "title_en": "Verbosity Tradeoffs and the Impact of Scale on the Faithfulness of LLM Self-Explanations", "authors": "Noah Y. Siegel,Nicolas Heess,Maria Perez-Ortiz,Oana-Maria Camburu", "background": "当被要求解释其决策时，语言模型（LLMs）往往能给出听起来合理的解释。然而，这些解释是否真实反映那些实际上影响决策的因素？本文作者对该问题进行了研究，分析了75个来自13个模型家族的模型的反事实忠实性，探讨了简洁性与详尽性之间的权衡，以及相关性浊度测试如何评估这种权衡，同时还探讨了测试结果易被操纵的问题。", "innovation": "提出了两种新的评估指标：phi-CCT，这是一种简化版的关联性反事实测试（CCT），没有使用标记概率，但解释了原始测试大部分的变异性；以及F-AUROC，这种测试消除了不平衡干预分布的敏感性，涵盖了模型生产不同详细程度解释的能力。研究发现，更大的更强大的模型在其考虑的所有指标上都呈现出更高的忠实度。", "conclusion": "研究显示，随着模型规模的增加，它们提供自我解释的忠实度有明显的提升趋势。同时，提供的代码可以在指定的URL中找到。"}
{"llm_update_time": "20251006", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2503.21718", "html_url": "https://arxiv.org/abs/2503.21718", "title": "并非令人烦恼而是有用的启发式方法：异常维度有利于语言模型中的常见词", "title_en": "Not a nuisance but a useful heuristic: Outlier dimensions favor frequent tokens in language models", "authors": "Iuri Macocco,Nora Graichen,Gemma Boleda,Marco Baroni", "background": "研究语言模型的最后一层异常维度，即对大多数输入表现出极端激活的维度。这些异常维度在许多现代语言模型中出现，可追溯到常常用预测频繁词的启发式方法。通过调整其他维度的权重来克服这种启发式方法中的不当情况。探讨了哪些模型参数可以加强异常维度，并在训练过程中何时出现。研究发现，异常维度是由许多不同模型发现的一种专门机制，用于实现有用的标记预测启发式方法。", "innovation": "研究发现异常维度并非是模型异常行为的体现，而是许多模型中发现的一种有助于有效预测常见词的有效机制。通过分配给其他维度的相反权重来防止不适当的情况下预测频繁词的启发式方法。探讨了加强异常维度的模型参数及其在训练过程中的出现时间。", "conclusion": "研究结果表明，异常维度在语言模型中是一项有用的技术。它是在涉及频繁词预测的启发式方法中发现的一种专门机制，可以大幅提升模型的预测准确性和稳定性能。"}
{"llm_update_time": "20251006", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2505.09901", "html_url": "https://arxiv.org/abs/2505.09901", "title": "从标准多臂老虎机实验中比较LLMs和人类的探索-利用策略：见解", "title_en": "Comparing Exploration-Exploitation Strategies of LLMs and Humans: Insights from Standard Multi-armed Bandit Experiments", "authors": "Ziyuan Zhang,Darcy Wang,Ningyuan Chen,Rodrigo Mansur,Vahid Sarhangian", "background": "大型语言模型（LLMs）越来越多地被用于模拟或自动执行人类在复杂顺序决策情境中的行为。自然地，就会引发是否LLMs在决策方式上与人类相似，能否达到与人类似的（或更好的）表现。本文聚焦于动态不确定性下的探索-利用（E&E）权衡，这一本质上重要的决策机制。作者通过认知科学和精神病学文献中引入的经典多臂老虎机（MAB）实验，对比分析LLMs、人类和MAB算法的E&E策略。", "innovation": "本文采用可解释的选择模型来捕捉代理人的E&E策略，并且探讨通过提示策略和思维模型启用思维痕迹如何塑造LLMs的决策过程。研究发现在简单静止环境中，启用思维的LLMs在随机和定向探索方面与其他人类表现相似。但在复杂的非静止环境中，LLMs难以与人类的适应性相匹敌，特别是在有效的定向探索方面，尽管在某些情况下获得了相似的后悔值。", "conclusion": "研究结果展示了LLMs作为人类行为模拟器和自动化决策工具的前景及其极限，并提出了改进的潜在领域。"}
{"llm_update_time": "20251006", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2504.18070", "html_url": "https://arxiv.org/abs/2504.18070", "title": "PropRAG：使用命题路径上的束搜索进行检索指导", "title_en": "PropRAG: Guiding Retrieval with Beam Search over Proposition Paths", "authors": "Jingjin Wang,Jiawei Han", "background": "Retrieval Augmented Generation (RAG)已经成为在Large Language Models (LLMs)中嵌入最新知识的标准方法。然而，传统的RAG依赖于独立段落检索，常常无法捕捉到复杂多重推理所需的相互关联的信息。尽管结构化的RAG方法试图通过基于三元组的知识图来解决这一问题，但三元组中的背景丢失（背景崩溃）限制了知识表示的精确度。", "innovation": "PropRAG 是一个新颖的RAG框架，从三元组转向富有交互背景的命题，并引入了一种LLM无，高效的在线束搜索方法来发现多步推理链。通过结合更精确的知识表示和显式路径发现，PropRAG 在2Wiki、HotpotQA 和 MuSiQue 上实现了零样本下 Recall@5 和 F1 分数的最新技术水平，从而通过更丰富的表示形式和高效的推理路径发现，推动了非参数知识整合的进步。", "conclusion": "PropRAG 通过携带更高的知识表示精度和明确的路径发现，实现了零样本下 recall@5 和 F1 分数的最新技术水平，在 2Wiki、HotpotQA 和 MuSiQue 等数据集上都取得了卓越的性能，表明通过更丰富表示和更有效推理路径发现促进非参数知识整合的可能性。"}
{"llm_update_time": "20251006", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2505.01476", "html_url": "https://arxiv.org/abs/2505.01476", "title": "CostFilter-AD: 通过匹配成本过滤增强异常检测", "title_en": "CostFilter-AD: Enhancing Anomaly Detection through Matching Cost Filtering", "authors": "Zhe Zhang,Mingxiu Cai,Hanxiao Wang,Gaochang Wu,Tianyou Chai,Xiatian Zhu", "background": "现有的无监督异常检测（UAD）方法依赖于图像级或特征级的匹配来生成异常评分，但这种方法往往不准确，导致检测结果不佳。作者指出，这种匹配过程经常被忽视，从而影响检测效果。", "innovation": "引入了从经典匹配任务（例如深度估计和流估计）借用的「成本过滤」概念应用于UAD问题。提出了一种新的「CostFilter-AD」方法，通过构造输入与正常样本之间的匹配成本体积，并利用输入观察作为在多特征层上的注意力查询来过滤这个体积，以抑制匹配噪声同时保留边缘结构并捕捉细微异常。这种方法作为一个通用的后处理插件，可以与重建基或嵌入基方法相结合，适用于单类和多类UAD任务。", "conclusion": "广泛的实验在MVTec-AD和VisA基准上验证了CostFilter-AD在单类和多类UAD任务中的一般性益处。相关代码和模型将在提供的链接中发布。"}
{"llm_update_time": "20251006", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2504.21700", "html_url": "https://arxiv.org/abs/2504.21700", "title": "XBreaking：解释的AI用于破解LLMs", "title_en": "XBreaking: Explainable Artificial Intelligence for Jailbreaking LLMs", "authors": "Marco Arazzi,Vignesh Kumar Kembu,Antonino Nocera,Vinod P", "background": "大型语言模型在当前由AI解决方案主导的IT环境中扮演着重要的角色。然而，它们相关的安全威胁可能阻碍其在关键应用场景（如政府机构和医疗机构）中的可靠采用。因此，商业化的大型语言模型通常会经过复杂的审查机制，以消除任何可能产生危害的内容。响应于此，LLM的破解（Jailbreaking）对这些保护措施构成了重大威胁，许多先前的方法已在各种领域证明了其有效性。现有的破解提案主要采用生成和测试的策略来制作恶意输入。为了提高对审查机制的理解并设计有针对性的破解攻击，我们提出了一种解释的AI解决方案，该解决方案通过比较分析审查和未审查模型的行为以提取独特的可利用对齐模式。然后，我们提出了XBreaking，一种利用这些独特模式通过有针对性的噪声注入来打破大型语言模型安全限制的新颖破解攻击。", "innovation": "我们提出了一种解释的AI解决方案，通过比较分析审查和未审查模型的行为以提取独特的可利用对齐模式。基于此，我们提出了XBreaking，一种通过有针对性的噪声注入打破大型语言模型安全限制的新颖破解攻击。", "conclusion": "我们的全面实证活动揭示了关于审查机制的重要见解，并证明了我们攻击的有效性和性能。"}
{"llm_update_time": "20251006", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2504.12397", "html_url": "https://arxiv.org/abs/2504.12397", "title": "激活的LoRA：用于内禀任务的微调大语言模型", "title_en": "Activated LoRA: Fine-tuned LLMs for Intrinsics", "authors": "Kristjan Greenewald,Luis Lastras,Thomas Parnell,Vraj Shah,Lucian Popa,Giulio Zizzo,Chulaka Gunasekara,Ambrish Rawat,David Cox", "background": "低秩适应（LoRA）框架由于其高效的特性，成为大规模基础模型权重微调的一种高度有效的方法，并且已成为数据驱动的大型语言模型（LLMs）定制的标准方法。尽管LoRA允许多种高度定制的行为和能力，但在多重对话过程中切换不同的LoRA模式时仍存在效率低下问题，因为每次生成之前都需要重新计算整个对话历史的键-值（KV）缓存。这限制了模型的即时响应能力，尤其是在需要执行特定任务时。因此，为了提高效率，需要一种新的适应框架来满足即时激活的需求，以便在需要时及时启用特定的功能模型进行专门操作。", "innovation": "提出了激活的LoRA（aLoRA），这是一种通过仅对aLoRA被激活后序列中的令牌适配权重来修改LoRA框架的新架构。aLoRA的关键改进在于它能够直接接受基础模型的输入字符串的KV缓存，使得它可以立即激活而无需重新计算之前的键和值。这一创新得到了一系列aLoRA内禀模型的训练，这些模型与标准的LoRA相比，在准确性和推理效率上取得了竞争性的效果。具体而言，aLoRA能够在需要时迅速启用，以执行特定操作，而无需重新计算之前的对话历史。", "conclusion": "作为一种新的微调方法，aLoRA不仅保持了LoRA的灵活性，还显著提高了推理效率，使其能够以更灵活和高效的方式处理特定任务。通过在Huggingface PEFT库中贡献实现代码，aLoRA为大语言模型的定制和特定任务处理提供了一个新的解决方案。"}
{"llm_update_time": "20251006", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2504.20629", "html_url": "https://arxiv.org/abs/2504.20629", "title": "AlignDiT：同步语音生成的多模态对齐扩散变换器", "title_en": "AlignDiT: Multimodal Aligned Diffusion Transformer for Synchronized Speech Generation", "authors": "Jeongsoo Choi,Ji-Hoon Kim,Kim Sung-Bin,Tae-Hyun Oh,Joon Son Chung", "background": "研究目标是从多个输入模态（文本、视频和参考音频）合成高质量的语音以完成多模态到语音的生成任务。这一任务因广泛的应用（如电影制作、配音和虚拟化身）而受到越来越多关注。尽管近期有进展，但现有方法仍存在语音可理解性、音视频同步、语音自然度和参考说话人音调相似性等方面的局限性。", "innovation": "本文提出了一种名为AlignDiT的多模态对齐扩散变换器，该模型能够从对齐的多模态输入中生成准确、同步且自然的语音。通过DiT架构的上下文学习能力，AlignDiT探索了三种有效策略来对齐多模态表示，并提出了一种新颖的无条件分类器引导机制，使模型在语音合成过程中能够自适应平衡各种模态的信息。广泛实验表明，AlignDiT在多个基准测试中从质量、同步性和说话人相似性方面显著优于现有方法。此外，AlignDiT在各种多模态任务（视频到语音合成和视觉对准）上表现出强大的泛化能力，保持了最先进的性能。", "conclusion": "实验结果证明，AlignDiT显著地在多个基准测试中从质量、同步性和说话人相似性等方面优于现有方法，且具有强大的跨任务泛化能力，实现了视频到语音合成及视觉对准等任务的最新成果。"}
{"llm_update_time": "20251006", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2505.08694", "html_url": "https://arxiv.org/abs/2505.08694", "title": "深度学习在复述语音谱图中的综述", "title_en": "A Survey of Deep Learning for Complex Speech Spectrograms", "authors": "Yuying Xie,Zheng-Hua Tan", "background": "深度学习的最新进展对语音信号处理领域产生了显著影响，特别是在复杂对数谱图的分析和处理中。本文综述了利用深度神经网络处理复杂对数谱图的先进技术，这些谱图能够包含振幅和相位信息。文章首先介绍了对数谱图及其在各种语音处理任务中的特征，然后探讨了复值神经网络的关键组件和架构，这些架构专门设计用于处理复数值数据，并应用于复对数谱图的处理。研究还讨论了用于训练处理和建模复对数谱图的神经网络的各种训练策略和损失函数。最后，本文还考察了复对数谱图在相位恢复、语音增强和说话人分离等关键应用领域的进步，并探讨了复对数谱图与生成模型的交叉领域。", "innovation": "1. 综述利用深度神经网络处理复杂对数谱图的先进技术。\n2. 详细介绍复值神经网络的关键组件和架构。\n3. 讨论了用于训练处理复对数谱图的神经网络的各种训练策略和损失函数。\n4. 考察复对数谱图在相位恢复、语音增强和说话人分离等关键应用领域的进展，并探讨其与生成模型的交叉领域。", "conclusion": "本文旨在为语音信号处理、深度学习及相关领域的研究人员和从业者提供有价值的参考资料。"}
{"llm_update_time": "20251006", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2503.07044", "html_url": "https://arxiv.org/abs/2503.07044", "title": "DatawiseAgent：面向笔记本的大型语言模型代理框架以实现适应性和鲁棒的数据科学自动化", "title_en": "DatawiseAgent: A Notebook-Centric LLM Agent Framework for Adaptive and Robust Data Science Automation", "authors": "Ziming You,Yumiao Zhang,Dexuan Xu,Yiwei Lou,Yandong Yan,Wei Wang,Huaming Zhang,Yu Huang", "background": "现有的大型语言模型（LLM）代理在自动化数据科学方面显示出潜力，但仍然受到狭窄的任务范围、任务和模型之间有限的一般化以及对最新SOTA LLM的过度依赖的限制。", "innovation": "DatawiseAgent引入了一个以笔记本为中心的LLM代理框架，具备自适应和鲁棒的数据科学自动化能力。其设计灵感来源于人类数据科学家在计算笔记本中的工作方式，通过统一的交互表示和基于有限状态转换器（FST）的多阶段架构，实现灵活的长周期规划、逐步解决方案开发以及在执行失败时的稳健恢复。", "conclusion": "广泛的实验表明，DatawiseAgent在不同的数据科学场景和模型中都能一致地实现SOTA性能，超越了AutoGen和TaskWeaver等强基线模型，展示了其卓越的有效性和适应性。进一步的评估还揭示了，在使用较弱或较小规模的模型时，DatawiseAgent仍能表现出优雅的性能衰退，证实了其鲁棒性和可扩展性。"}
{"llm_update_time": "20251006", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2505.22798", "html_url": "https://arxiv.org/abs/2505.22798", "title": "高效先像近似在神经网络验证中的应用", "title_en": "Efficient Preimage Approximation for Neural Network Certification", "authors": "Anton Björklund,Mykola Zaitsev,Marta Kwiatkowska", "background": "随着人工智能在关键安全和安全领域中的应用日益广泛，对神经网络的有效验证变得愈发重要。一种具有挑战性的实际应用场景是“修补攻击”，即通过对抗性标记或光照条件遮挡图像的一部分，例如交通标志。近年来，虽然对修补攻击的验证有所进展，但目前的方法主要局限于结构复杂的全连接神经网络。为了应对更广泛的实际应用场景，本文提出了对PREMAP算法的新型扩展，通过收紧边界条件、自适应蒙特卡罗采样和改进分支策略来提高效率。", "innovation": "1. 这些效率改进方法显著优于原始的PREMAP，能够扩展至此前无法处理的卷积神经网络。\n2. 展示了先像近似方法在从计算机视觉和控制等多个实际应用案例分析和验证可靠性和鲁棒性中的潜力。", "conclusion": "通过引入高效先像近似方法，验证了神经网络的鲁棒性和可靠性，拓展了PREMAP算法的应用范围，并展示了其在多个实际应用中的潜力。"}
{"llm_update_time": "20251006", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2505.17568", "html_url": "https://arxiv.org/abs/2505.17568", "title": "JALMBench: 评估音频语言模型劫持漏洞的基准", "title_en": "JALMBench: Benchmarking Jailbreak Vulnerabilities in Audio Language Models", "authors": "Zifan Peng,Yule Liu,Zhen Sun,Mingchen Li,Zeren Luo,Jingyi Zheng,Wenhan Dong,Xinlei He,Xuechao Wang,Yingjie Xue,Shengmin Xu,Xinyi Huang", "background": "近年来，音频语言模型（ALMs）取得了显著的进步。这些模型能够直接融合音频模态，而不是将语音转换为文本然后输送到大型语言模型（LLMs）中。尽管对大型语言模型的劫持攻击已经得到了广泛研究，但具有音频模态的ALMs的安全性仍处于很大程度上未被探索的状态。目前缺乏专门设计的对抗音频数据集以及用于评估和比较攻击与ALMs统一框架。", "innovation": "本文介绍了JALMBench，这是一个全面的基准测试，用于评估ALMs在遭受劫持攻击时的安全性。JALMBench包含一个包含11,316个文本样本和245,355个音频样本、总时长超过1000小时的数据集，支持12个主流的ALMs，4个文本转来的攻击方法和4个音频原生的攻击方法，以及5种防御方法。通过JALMBench，我们对攻击效率、主题敏感性、声音多样性以及架构进行了深入分析，并探讨了攻击在提示级别和响应级别的缓解策略。", "conclusion": "本文通过JALMBench提供了一个全面的评估、分析和缓解音频语言模型攻击的方法，填补了这一领域的空白。"}
{"llm_update_time": "20251006", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2505.22860", "html_url": "https://arxiv.org/abs/2505.22860", "title": "权限管理的LLMs：在大型语言模型中强化访问控制", "title_en": "Permissioned LLMs: Enforcing Access Control in Large Language Models", "authors": "Bargav Jayaraman,Virendra J. Marathe,Hamid Mozaffari,William F. Shen,Krishnaram Kenthapadi", "background": "在企业环境中，组织数据被隔离并且通过复杂的访问控制框架严格保护。如果一个针对隔离数据微调的LLM向具有不同访问权限的个体提供下游任务请求，可能破坏访问控制结构。本文分析了此背景。", "innovation": "本文提出了权限管理的LLMs（PermLLM），这是一种超级叠加组织数据访问控制结构在查询响应中的新型LLMs。论文引入了用于证明PermLLM机制实现正确性的相关响应概念，并定义了一种衡量PermLLM机制有效性的新指标——访问优势。此外，还提出了 Parameter Efficient Fine-Tuning（PEFT）的三种新PermLLM机制以及衡量访问优势的两种方法：基于成员推理攻击的域区分指数（DDI）和基于LLM实用性评估的实用差距指数（UGI）。通过五个公开数据集（GPQA、RCV1、SimpleQA、WMDP、PubMedQA）进行了广泛的实验来验证这些机制的有效性。", "conclusion": "本文通过实验证明了权限管理的LLMs机制的有效性，并评估了基于DDI和UGI的访问控制度量指标。"}
{"llm_update_time": "20251006", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.00771", "html_url": "https://arxiv.org/abs/2506.00771", "title": "在固定维度的E(3)-协变隐空间中操作三维分子", "title_en": "Manipulating 3D Molecules in a Fixed-Dimensional E(3)-Equivariant Latent Space", "authors": "Zitao Chen,Yinjun Jia,Zitong Tian,Wei-Ying Ma,Yanyan Lan", "background": "医药化学家在优化药物时通常会考虑到药物的3D结构，并设计具有保留关键特性的结构不同的分子，例如形状、药效团或化学性质。先前的深度学习方法通过监督任务，如分子补全或性质引导的优化来解决此问题。本文的研究背景是在3D分子的共享隐空间中实现灵活的零样本分子操作方法。", "innovation": "本文提出了一种灵活的零样本分子操纵方法，通过在3D分子的共享隐空间中导航来实现。引入了一种名为MolFLAE（分子FLAE）的变分自编码器，它可以学习一个与原子数量无关的固定维度、E(3)-协变的隐空间。MolFLAE通过E(3)-协变神经网络将3D分子编码为固定数量的隐节点，并使用一个受编码器隐输出条件化的贝叶斯流网络进行分子结构重建，实现了在标准无条件3D分子生成基准测试中竞争力的表现。MolFLAE的隐空间使得在不修改分子数量的情况下进行分子结构重构、原子数量编辑，并实现结构和性质的协调隐空间插值。", "conclusion": "MolFLAE方法在药物优化任务中表现出了灵活性、稳健性和实际效用，展示了新的分子编辑和优化途径。特别是在人类糖皮质激素受体的药物优化任务中生成了具有更好亲水性的分子，同时保留了关键互动，通过计算评估验证了其有效性。"}
{"llm_update_time": "20251006", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2505.16000", "html_url": "https://arxiv.org/abs/2505.16000", "title": "利用在线数据增强小规模波斯语医疗语言模型的知识", "title_en": "Leveraging Online Data to Enhance Medical Knowledge in a Small Persian Language Model", "authors": "Mehrdad Ghassabi,Pedram Rostami,Hamidreza Baradaran Kashani,Amirhossein Poursina,Zahra Kazemi,Milad Tavakoli", "background": "语言模型的迅速发展展示了人工智能在医疗领域的潜力。然而，小型语言模型在低资源语言（如波斯语）的专门领域中表现不佳。尽管存在许多波斯语的医疗领域网站，但缺乏经过策展的数据集或语料库，因此本研究首次创建了针对这一问题的数据集。该研究介绍了一个包含20,000个医生-患者问答对和90百万元词语料库（其中60%）的数据集，这些语料库是从医学杂志中抓取所得。", "innovation": "通过使用参数效率化微调方法，本研究增强了基准模型 aya-expanse-8b 的医疗知识。基准评估表明，微调后的模型在医疗问答中准确度提高，并且成功通过了2023年9月的伊朗基础医学科学入学考试（IBSEE），而基线模型未能通过。此外，微调后的模型还将波斯语翻译的MMLU准确度提高了2.67%。这项工作强调了利用开放访问的在线数据来丰富小型语言模型在医疗领域中的潜力，为资源受限环境下的波斯语医疗AI应用提供了新的解决方案。", "conclusion": "本研究展示了利用开放访问的在线数据来丰富在医疗领域的小规模波斯语语言模型的知识，并提出了一种适合资源受限环境的新型解决方案。未来的研究可以探索多模态输入以进一步提高性能。"}
{"llm_update_time": "20251006", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.14202", "html_url": "https://arxiv.org/abs/2506.14202", "title": "DiffusionBlocks：通过扩散解释实现模块化神经网络训练", "title_en": "DiffusionBlocks: Block-wise Neural Network Training via Diffusion Interpretation", "authors": "Makoto Shing,Masanori Koyama,Takuya Akiba", "background": "端到端反向传播需要在整个层中存储激活值，这会创建内存瓶颈，限制模型的可扩展性。现有的块级训练方法可以减轻这个问题，但它们依赖于针对具体任务的半手工的局部目标，这些方法在分类任务之外的应用仍然很少被探索。", "innovation": "提出了DiffusionBlocks，这是一个原理上的框架，将基于变压器的网络转换成真正独立且可训练的块。这一创新点在于通过利用残差连接与动态系统更新的自然对应关系，修改动态系统更新方式为去噪过程的更新，每个块可以独立地使用评分匹配目标进行学习，从而使得块级训练过程中能够仅用块中的一个梯度进行训练，降低了内存需求。", "conclusion": "在包括视觉、扩散、自回归、递归深度和掩码扩散等多个架构的实验上，DiffusionBlocks训练展示了与端到端训练相当的性能，同时实现了更为可扩展的块级训练，适用于超出小型分类任务的实际任务，DiffusionBlocks提供了一个理论上坚实的框架，成功地将现代生成任务在不同架构上的应用扩展开来。"}
{"llm_update_time": "20251006", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2505.17121", "html_url": "https://arxiv.org/abs/2505.17121", "title": "NeSyGeo：一种多模态几何推理数据生成的神经-符号框架", "title_en": "NeSyGeo: A Neuro-Symbolic Framework for Multimodal Geometric Reasoning Data Generation", "authors": "Weiming Wu,Jin Ye,Zi-kang Wang,Zhi Zhou,Yu-Feng Li,Lan-Zhe Guo", "background": "获取大规模高质量的推理数据对于提升多模态大型语言模型的几何推理能力至关重要。然而，现有的数据生成方法，无论是基于预定义模板还是受限符号证明器，都不可避免地面临多样性和数值泛化的限制。", "innovation": "我们提出了NeSyGeo，一种新颖的神经-符号框架，用于生成几何推理数据。该框架包含一个基于实体-属性-关系范式的领域特定语言和生成动作，以及一个符号-视觉-文本管道，该管道能够合成功能符号序列，将其映射到视觉和文本表示并生成推理路径。基于此框架，我们构建了NeSyGeo CoT和NeSyGeo-Caption数据集，包含10万个样本，还发布了一个新的基准NeSyGeo-Test，用于评估多模态大型语言模型的几何推理能力。实验表明，该提议显著且一致地提高了多种多模态大型语言模型在强化学习和监督微调下的性能。仅通过4000个样本和两个回合的强化微调，基础模型在MathVision、MathVerse和GeoQA上的性能分别提高了15.8%、8.4%和7.3%。特别地，4B模型可以通过几何推理任务表现上超越其8B系列版本。", "conclusion": "通过NeSyGeo框架，表征和生成强大的几何推理数据，显著提升了多模态大型语言模型在几何推理任务上的表现，并为进一步研究多模态几何推理提供了新的基准和数据集。"}
{"llm_update_time": "20251006", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.15655", "html_url": "https://arxiv.org/abs/2506.15655", "title": "cAST：通过抽象语法树进行结构化分块以增强代码检索增强生成", "title_en": "cAST: Enhancing Code Retrieval-Augmented Generation with Structural Chunking via Abstract Syntax Tree", "authors": "Yilin Zhang,Xinran Zhao,Zora Zhiruo Wang,Chenyang Yang,Jiayi Wei,Tongshuang Wu", "background": "RAG在大规模代码生成中变得至关重要，它通过将预测扎根于外部代码库来提高实际性。然而，现有RAG管道中的一个关键但未充分探索的方面是分块——将文档拆分为可检索单元的过程。现有的基于行的分块启发式方法往往破坏了语义结构，将函数拆分或合并不相关的代码，这会降低生成质量。", "innovation": "提出了一种基于抽象语法树（cAST）的结构感知分块方法，该方法递归地将大型AST节点分解为较小的块，同时合并兄弟节点，并遵守大小限制。这种方法在不同的编程语言和任务上生成自包含的、语义上连贯的单元，提高了多种代码生成任务的性能，例如在RepoEval检索上的召回率Recall@5提高了4.3个百分点，在SWE-bench生成上的精度Pass@1提高了2.67个百分点。", "conclusion": "这项工作强调了结构感知分块对于扩展检索增强代码智能的重要性。"}
{"llm_update_time": "20251006", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.12113", "html_url": "https://arxiv.org/abs/2506.12113", "title": "基于LLM的恶意软件分析的语义预处理", "title_en": "Semantic Preprocessing for LLM-based Malware Analysis", "authors": "Benjamin Marais,Tony Quertier,Grégoire Barrue", "background": "在恶意软件分析的背景下，许多方法依赖于人工智能来处理大型数据集。然而，这些技术主要集中在数据视图（如图像、序列），而不是专家视图。鉴于此问题，本文提出了一种专注于专家知识的预处理方法，以提高恶意软件语义分析的效果和结果解释性。该方法为可移植执行文件创建JSON报告，这些报告从静态和行为分析中收集特征，并集成包装器签名检测、MITRE ATT&CK和恶意软件行为目录（MBC）知识。该预处理旨在为恶意软件分析师提供一种易于理解的二进制文件语义表示，并增强AI模型对恶意文件分析的解释性。", "innovation": "本文提出了一种新的预处理方法，该方法创建JSON报告以整合可移植执行文件的静态和行为分析特征，并加入包装器签名检测、MITRE ATT&CK和MBC知识。这种方法旨在提供一种专家可理解的二进制文件语义表示，并通过训练大型语言模型进行恶意软件分类，实现了复杂数据集上的加权平均F1分数为0.94。", "conclusion": "本文通过为基于LLM的恶意软件分析提供一种语义预处理方法，达到了0.94的加权平均F1分数，这表明这种方法有效且能增强解释性。"}
{"llm_update_time": "20251006", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2505.15962", "html_url": "https://arxiv.org/abs/2505.15962", "title": "使用内部和外部知识预训练有限记忆语言模型", "title_en": "Pre-training Limited Memory Language Models with Internal and External Knowledge", "authors": "Linxi Zhao,Sofian Zalouk,Christian K. Belardi,Justin Lovelace,Jin Peng Zhou,Ryan Thomas Noonan,Dongyoung Go,Kilian Q. Weinberger,Yoav Artzi,Jennifer J. Sun", "background": "神经语言模型是黑盒模型，语言模式和事实知识在数十亿复杂的参数中分布，这样的混合编码使得可靠地检查、验证或更新特定事实变得困难。", "innovation": "提出了有限记忆语言模型（LMLM），在预训练过程中，将事实知识外部化到外部数据库，而不是把它们记住。在训练损失中战略性地屏蔽外部检索到的事实值，从而训练模型进行有针对性的查找，而非依赖模型权重记忆。", "conclusion": "实验证明，LMLMs在标准基准测试中实现了与显著更大的LLMs相当的性能，同时提供了明确、可编辑和可验证的知识库的优势。"}
{"llm_update_time": "20251006", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2505.11669", "html_url": "https://arxiv.org/abs/2505.11669", "title": "OT 分数: 基于 Optimal Transport 的 Source Free 无线监督领域适应置信度分数", "title_en": "OT Score: An OT based Confidence Score for Source Free Unsupervised Domain Adaptation", "authors": "Yiming Zhang,Sitong Liu,Alex Cloninger", "background": "当前的分布匹配方法在源数据无标签的无监督领域适应（SFUDA）中存在计算和理论限制，尤其是在缺乏目标标签的情况下难以准确估计分类性能和置信度。现有的理论框架常常导致计算不可行的结果，未能充分反映所采用的对齐算法的性质。", "innovation": "作者提出了 Optimal Transport (OT) 分数，这是一种来自新颖理论分析的置信度度量。这个分析利用了 Semi-Discrete Optimal Transport 对齐引起的决策边界的灵活性。OT 分数直观且有严格的理论证明，为任何给定的目标伪标签集提供原则性的不确定性估计。实验结果显示，OT 分数优于现有置信度分数，并通过训练时间重加权提升了 SFUDA 性能，还提供了一个可靠且无标签的模型性能代理。", "conclusion": "OT 分数通过提供可靠的模型性能无标签代理和通过训练时间重加权提高 SFUDA 性能，证明了其有效性和优越性。"}
{"llm_update_time": "20251006", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.09029", "html_url": "https://arxiv.org/abs/2507.09029", "title": "Subnetwork Data Parallelism With Model Parallelism", "title_en": "Model Parallelism With Subnetwork Data Parallelism", "authors": "Vaibhav Singh,Zafir Khalid,Edouard Oyallon,Eugene Belilovsky", "background": "大规模训练神经网络需要大量的内存并经常需要昂贵的通信成本，尤其是在加速器上。为了解决这个问题，研究者们引入了一种新的分布式训练框架——子网络数据并行(SDP)。", "innovation": "SDP框架将模型划分为结构化的子网络，这些子网络在多个工作节点上独立训练，而无需在网络间交换激活值。同时，SDP引入了两个互补的稀疏性掩码策略：反向掩码仅在反向传播时应用稀疏性以保持无偏梯度，前向掩码则在正向传播和反向传播中都应用，从而提供更高的效率并带来额外的正则化效果。此外，SDP还探讨了两种子网络构建策略：神经元级别和块级别。实验结果显示，SDP在多种模型上（包括CNN和Transformer）降低了30%-75%的单设备内存使用量，同时保持或提升了性能。在相同FLOP的情况下，前向掩码有时能实现更好的性能。", "conclusion": "SDP方法通过将模型划分为子网络并结合有效的稀疏掩码策略，显著降低了内存需求和提升了训练效率，在多种场景下展现了优良的表现。"}
{"llm_update_time": "20251006", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.04793", "html_url": "https://arxiv.org/abs/2507.04793", "title": "Pun 生成综述：数据集、评估方法与方法论", "title_en": "A Survey of Pun Generation: Datasets, Evaluations and Methodologies", "authors": "Yuchen Su,Yonghua Zhu,Ruofan Wang,Zijian Huang,Diana Benavides-Prado,Michael Witbrock", "background": "幽默的修辞手法，如双关语生成（pun generation），包括创造性地修改文字中的语言元素以产生幽默或双关语效果。这种手法还保留了语境上的连贯性和适宜性，使其在各种媒体和场景中的创意写作和娱乐中极为有用。尽管双关语生成在计算语言学领域受到了相当多的关注，但目前还没有专门的调查来系统地回顾这一特定领域。", "innovation": "该论文提供了一篇全面的双关语生成数据集和方法的综述，涵盖了不同阶段的传统方法、深度学习技术和预训练的语言模型。同时，总结了用于评估双关语生成质量的自动化和人工评价指标，并讨论了研究挑战，提出了未来工作的有前途的方向。", "conclusion": "综上所述，该研究填补了双关语生成领域的现有空白，并为该领域的未来研究提供了宝贵的见解。"}
{"llm_update_time": "20251006", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.20836", "html_url": "https://arxiv.org/abs/2507.20836", "title": "初次幻觉标记与其他条件标记不同", "title_en": "First Hallucination Tokens Are Different from Conditional Ones", "authors": "Jakob Snel,Seong Joon Oh", "background": "大型语言模型（LLMs）会产生幻觉，这会影响模型的可信度。尽管许多方法关注响应级或跨度级的幻觉检测，最近的研究开始探索标记级的检测，以实现更精细的干预。然而，幻觉信号在整个幻觉标记序列中的分布尚未得到探索。", "innovation": "本文利用RAGTruth语料库的标记级注释，发现第一个产生幻觉的标记比后续的标记更容易检测，这种结构特性在不同模型中均适用，表明第一个幻觉标记在标记级幻觉检测中扮演着关键角色。", "conclusion": "本文的研究揭示了幻觉标记中第一个标注与后续标注之间的重要差异，提供了对模型幻觉检测的新见解。相关代码已在此处提供：this https URL_Xtended。（请注意链接是示意性的）"}
{"llm_update_time": "20251006", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.12723", "html_url": "https://arxiv.org/abs/2506.12723", "title": "SP-VLA: 一种用于VLA模型加速的联合模型调度和标记剪枝方法", "title_en": "SP-VLA: A Joint Model Scheduling and Token Pruning Approach for VLA Model Acceleration", "authors": "Ye Li,Yuan Meng,Zewen Sun,Kangye Ji,Chen Tang,Jiajun Fan,Xinzhu Ma,Shutao Xia,Zhi Wang,Wenwu Zhu", "background": "视觉-语言-行动（VLA）模型由于其强大的控制能力而受到越来越多的关注。然而，其计算成本高和执行频率低使得它们不适合实时任务，如机器人操作和自主导航。现有的VLA加速方法主要集中在结构优化上，忽视了这些模型在顺序决策环境中运行的事实。因此，序列动作生成中的时间冗余性和视觉输入中的空间冗余性仍然未被解决。", "innovation": "为了解决上述问题，本研究提出了SP-VLA，这是一种统一框架，通过同时调度模型和剪枝标记来加速VLA模型。精心设计了一个感知动作的模型调度机制，通过动态切换VLA模型和轻量级生成器来减少时间冗余。此外，提出了一种时空语义双重感知标记剪枝方法，以进一步处理空间冗余。通过这两个机制协调，引导VLA专注于关键动作和显著的视觉信息，从而在保持高精度的同时实现有效的加速。实验结果表明，该方法在LIBERO中实现了1.5倍无损失的加速，在SimplerEnv中实现了2.4倍的加速，并取得了高达6%的平均性能提升。推理频率和延迟在SimplerEnv中分别提高了2.2倍和1.4倍，在LIBERO中则分别提高了1.4倍和1.4倍。", "conclusion": "通过提出一种联合模型调度和标记剪枝的方法，该研究成功地实现了对VLA模型的高效加速，既降低了计算成本又优化了执行频率，同时保持了高性能。"}
{"llm_update_time": "20251006", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.18340", "html_url": "https://arxiv.org/abs/2506.18340", "title": "具有同构变分流匹配的受控生成", "title_en": "Controlled Generation with Equivariant Variational Flow Matching", "authors": "Floor Eijkelboom,Heiko Zimmermann,Sharvaree Vadgama,Erik J Bekkers,Max Welling,Christian A. Naesseth,Jan-Willem van de Meent", "background": "该研究在变分流匹配（VFM）框架内推导出了一种可控生成目标，将流匹配视为变分推断问题。讨论了受控生成的两种实现方式，并且详细研究了对于分子生成的对称性不变性生成方法，确保了对于旋转、平移和置换的不变性。", "innovation": "1. 提出了一种新的可控生成目标，能够在变分流匹配框架内实现。\n2. 研究了两种实现受控生成的方法：端到端训练条件生成模型以及作为贝叶斯推断问题，并能够对无条件模型进行后验控制。\n3. 提供了一种对称性不变的VFM形式，适用于分子生成，确保生成物对于旋转、平移和置换的不变性。\n4. 实验结果显示在无控制生成和具有严格条件的生成中均取得了最先进的性能，特别是在使用端到端训练和贝叶斯推理设置的情况下。", "conclusion": "该研究强化了基于流的生成建模与贝叶斯推理之间的联系，提供了一个可扩展且原则性的框架，用于约束驱动和对称感知生成。"}
{"llm_update_time": "20251006", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2505.05522", "html_url": "https://arxiv.org/abs/2505.05522", "title": "连续思考机", "title_en": "Continuous Thought Machines", "authors": "Luke Darlow,Ciaran Regan,Sebastian Risi,Jeffrey Seely,Llion Jones", "background": "生物大脑展示出复杂的神经活动，其中神经动力学对信息处理至关重要。大多数的人工神经网络忽略了单个神经元的复杂性。这项研究挑战了这一范式，通过结合神经元级别的处理和同步，重新引入神经时间作为基本要素。", "innovation": "介绍了连续思考机(CTM)模型，该模型有两个创新：(1) 神经元级别的时序处理，每个神经元使用独特的权重参数处理传入的历史记录；(2) 神经同步作为潜在表示。CTM旨在在神经元抽象和生物现实之间取得平衡。", "conclusion": "CTM能够展示丰富的内部表示，提供自然的解释途径，并能够在复杂顺序推理所需的任务中执行任务。CTM还可以利用适应性计算，简单任务可提前停止，而面对更具挑战性的任务时将继续计算。这项工作旨在分享CTM及其相关创新，而不是推动新的最佳结果。我们相信CTM代表了朝着开发更具有生物学可行性和强大人工智能系统的重要步骤。"}
{"llm_update_time": "20251006", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.05116", "html_url": "https://arxiv.org/abs/2507.05116", "title": "VOTE: 视觉-语言-动作优化与轨迹投票 ensemble", "title_en": "VOTE: Vision-Language-Action Optimization with Trajectory Ensemble Voting", "authors": "Juyi Lin,Amir Taherin,Arash Akbari,Arman Akbari,Lei Lu,Guangyu Chen,Taskin Padir,Xiaomeng Yang,Weiwei Chen,Yiqian Li,Xue Lin,David Kaeli,Pu Zhao,Yanzhi Wang", "background": "近年来，大规模的Vision Language Action（VLA）模型在由自然语言引导的机器人操作任务中表现出了优越的性能。然而，当前的VLA模型存在两个不足：（i）生成大量令牌导致高昂的推理延迟和增加的训练成本；（ii）生成的动作利用不足，可能导致潜在性能损失。", "innovation": "为了应对这些问题，我们开发了一种训练框架来微调VLA模型，以生成显著减少的行动令牌，并且具有高并行性，有效地减少了推理延迟和训练成本。此外，我们还引入了一种推理优化技术，结合了基于投票的集成策略，将当前和以往的动作预测结合起来，从而提高了生成动作的利用度和整体性能。", "conclusion": "结果表明，我们实现了与最先进的VLA模型相比的优越性能，成功率达到显著提高，并且与OpenVLA相比以39倍的加速率实现了每秒46帧的推理速度，在边缘平台上表现出实际应用的可行性。代码可从以下链接获得：this https URL."}
{"llm_update_time": "20251006", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.22687", "html_url": "https://arxiv.org/abs/2507.22687", "title": "空间网络架构", "title_en": "An Architecture for Spatial Networking", "authors": "Josh Millar,Ryan Gibb,Roy Ang,Hamed Haddadi,Anil Madhavapeddy", "background": "随着物理空间中网络设备的不断增加，无缝协调和环境智能成为可能。然而，当前的云优先架构迫使所有通信都通过广域网络进行，而不管地理位置。缺乏一种空间网络的抽象方式，即利用物理空间来创建私密、可靠和低延迟通信的边界。", "innovation": "介绍了一种名为Bifröst的编程模型，使用bigraphs来表达包含和连接关系，使得策略可以按物理边界进行范围定义，设备可以通过位置来命名，实现空间服务实例化，以及空间的组合，同时保持局部自主性。Bifröst 使得可以直接进行同处一地的设备间的直接通信，物理障碍需要显式网关，本地控制与全局协调之间建立桥梁。", "conclusion": "Bifröst 使一种新的、与空间感知的应用程序成为可能，其中同处一地的设备直接通信，物理障碍需要显式网关，且局部控制与全局协调之间建立桥梁。"}
{"llm_update_time": "20251006", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.21117", "html_url": "https://arxiv.org/abs/2507.21117", "title": "利用大型语言模型克服推荐系统挑战的全面回顾", "title_en": "A Comprehensive Review on Harnessing Large Language Models to Overcome Recommender System Challenges", "authors": "Rahul Raja,Anshaj Vats,Arpita Vats,Anirban Majumder", "background": "传统的推荐系统遵循了模块化架构，包括候选生成、多阶段排名和重新排序，每个部分都使用监督目标和手工工程特征分别进行训练。然而，这些系统在许多领域表现出色的同时也遇到了持久性的挑战，如稀疏且噪声大的交互数据、冷启动问题、有限的个性化深度和用户和物品内容的不充分语义理解。近年来，大型语言模型（LLMs）的出现提供了一种新的范式来解决这些局限性，通过统一、语言本源的机制在任务、领域和模态之间进行泛化。这项论文全面探讨了如何利用LLMs克服现代推荐系统的关键挑战。", "innovation": "论文介绍了利用LLMs克服推荐系统挑战的新方法，包括基于提示的候选检索、语言本源的排名、检索增强生成（RAG）以及对话推荐，展示了这些方法如何增强个性化、语义对齐和可解释性，而无需进行密集的任务特定监督。此外，LLMs还使零样本和少量样本推理成为可能，使系统在冷启动和长尾情景下能够有效地利用外部知识和上下文线索进行操作。论文将这些新兴的LLM驱动架构分类，并分析它们如何缓解传统管道中的核心瓶颈，提供了LLM增强推荐器设计空间的结构化框架，并讨论了准确度、可扩展性和实时性能之间的权衡。", "conclusion": "本文的目标是证明LLMs不仅是辅助组件，而是构建更具适应性、语义丰富和用户中心的推荐系统的基础性使能器。"}
{"llm_update_time": "20251006", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.01339", "html_url": "https://arxiv.org/abs/2508.01339", "title": "SBP-YOLO:一种用于智能车辆悬挂系统的轻量级实时速度丘和坑洞检测模型", "title_en": "SBP-YOLO:A Lightweight Real-Time Model for Detecting Speed Bumps and Potholes toward Intelligent Vehicle Suspension Systems", "authors": "Chuanqi Liang,Jie Fu,Miao Yu,Lei Luo", "background": "坑洞和减速带是常见的道路不平，严重影响乘车舒适度和车辆稳定性。基于前瞻的悬挂控制可提前检测这些不平并主动调整悬挂参数，以减轻其影响。准确且实时的检测至关重要，但在嵌入式系统中受到计算资源有限和输入目标小型化的限制。为了应对这些挑战，该论文提出了一种针对嵌入式系统的SBP-YOLO检测框架，用于检测坑洞和减速带。该框架基于YOLOv1，通过引入GhostConv和VoVGSCSPC模块减少计算量并增强多尺度语义特征，P2层分支提升小型物体检测，而轻量高效的检测头（LEDH）能够在不影响效率的情况下维持准确性。此外，采用混合训练策略进一步增强在不同道路和环境条件下的鲁棒性，结合NWD损失、BCKD知识蒸馏和基于Albumentations的数据增强。", "innovation": "该论文提出的SBP-YOLO框架基于YOLOv1，在设计上融合了GhostConv、VoVGSCSPC模块、P2层分支、LEDH检测头以及混合训练策略等创新元素，以满足嵌入式系统的计算资源限制并提高对小型目标的检测能力。实验结果显示，SBP-YOLO在Jetson AGX Xavier上经过TensorRT FP16量化后，能够以139.5 FPS的速度运行，比增强后的YOLOv1n快12.4%，同时达到了87.0%的mAP，比YOLOv1n基线高出5.8%。这些结果展示了该框架在嵌入式悬挂控制系统中实现快速和低延迟路面状况感知上的适用性。", "conclusion": "该论文开发的SBP-YOLO模型成功解决了嵌入式系统中基于YOLOv1进行速度丘和坑洞检测的挑战，展示了在Jetson AGX Xavier上的高效运行能力。SBP-YOLO在保持高检测准确率的同时，减少了计算资源的消耗，使其成为一种理想的用于智能车辆悬挂控制系统的轻量级实时检测模型。"}
{"llm_update_time": "20251006", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.09459", "html_url": "https://arxiv.org/abs/2508.09459", "title": "RelayFormer: 一种用于可扩展图像和视频篡改定位的统一局部-全局注意力框架", "title_en": "RelayFormer: A Unified Local-Global Attention Framework for Scalable Image and Video Manipulation Localization", "authors": "Wen Huang,Jiarui Yang,Tao Dai,Jiawei Li,Shaoxiong Zhan,Bin Wang,Shu-Tao Xia", "background": "视觉篡改定位（VML）的目标是在图像和视频中识别篡改区域，而这随着高级编辑工具的发展变得越来越具有挑战性。现有的方法面临两个主要问题：分辨率多样性，它会导致缩放或填充使法医痕迹失真并降低效率；模态差距，因为图像和视频通常需要分开的模型。", "innovation": "我们提出了RelayFormer，一种统一框架，可以适应不同分辨率和模态。RelayFormer将输入划分为固定大小的子图像，并引入了全局-局部接力（GLR）令牌，通过全局-局部接力注意机制（GLRA）在不同结构上下文间传播信息。这能有效地共享全局线索（如语义或时间一致性），同时保留细微的篡改属性。与依赖均匀缩放或稀疏注意力的先前方法不同，RelayFormer能够自然地扩展到任意分辨率和视频序列，且无需过度开销。实验结果表明，RelayFormer在不同的基准测试中实现了最先进的性能，具有显著的效率，结合了分辨率适应性、联合建模图像和视频、平衡准确性和计算成本等优势。", "conclusion": "RelayFormer 通过高效的全局和局部信息传递机制，在多分辨率和模态下实现了图像和视频篡改定位的优化解决方案，并在多个基准测试中展示了优越的性能和效率。"}
{"llm_update_time": "20251006", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.00398", "html_url": "https://arxiv.org/abs/2509.00398", "title": "生成性人工智能的伦理和可信度评估框架研究", "title_en": "A Study on the Framework for Evaluating the Ethics and Trustworthiness of Generative AI", "authors": "Cheonsu Jeong,Seunghyun Lee,Seonhee Jeong,Sungsu Kim", "background": "本研究深入分析了伴随生成人工智能（AI）技术迅速发展而出现的伦理和可信度挑战，指出当前的AI评价方法主要关注性能和准确性，难以解决这些问题。生成AI，如ChatGPT，虽然表现出显著的创新潜力，但也引发了偏见、危害性、版权侵权、隐私侵犯和虚构等问题。现有的AI评估方法无法有效应对这些复杂问题。", "innovation": "本研究提出了一套综合框架，用于系统评估生成AI的伦理和可信度，强调需要新的以人为核心的评价标准，以反映社会影响。研究确定了评估生成AI伦理和可信度的关键维度，如公平性、透明度、问责制、安全性、隐私保护、准确性、一致性、稳健性、可解释性和版权及知识产权保护，并开发了详细的指标和评估方法。同时，研究对比分析了韩国、美国、欧盟和中国的AI伦理政策和指南，提炼出关键方法和启示。", "conclusion": "所提出的框架适用于整个AI生命周期，并将技术评估与多学科视角相结合，从而为识别和管理现实世界中的伦理风险提供了实用方法。研究为负责任地推进生成AI奠定了学术基础，并为决策者、开发者、用户和其他利益相关者提供了行动指南，支持人工智能技术的社会正面贡献。"}
{"llm_update_time": "20251006", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.19366", "html_url": "https://arxiv.org/abs/2508.19366", "title": "基于谱图框架量化多模态大语言模型中的幻觉", "title_en": "Grounding the Ungrounded: A Spectral-Graph Framework for Quantifying Hallucinations in multimodal LLMs", "authors": "Supratik Sarkar,Swagatam Das", "background": "大语言模型（LLMs）中的幻觉仍然是实现可信赖人工智能的基本障碍，尤其是在医学、法律和金融等高风险的多模态领域。现有的评估技术大多基于启发式方法，缺乏可行的量化分析和可操作的理论保证，这在理解幻觉的产生、传播和跨模态交互方面留下了关键的盲点。", "innovation": "本文提出了首个（据我们所知）严谨的信息几何框架，用于在扩散动力学中量化多模态大语言模型（MLLMs）中的幻觉，推动领域从定性检测走向基于数学的测量。该方法通过谱嵌入多模态图拉普拉斯矩阵表示MLLM输出，并将事实与不一致之间的流形差距表征为语义失真，从而提供了时间依赖温度轮廓上多模态幻觉能量的严格雷利-里兹边界。利用Reproducing Kernel Hilbert Space（RKHS）嵌入中的特征模分解，该框架提供了模态感知的、具有理论解释性的度量标准，能够通过温度退火捕捉幻觉随时间和输入提示的演变。这项工作为量化和限定幻觉建立了有原则的基础，从而将它们从一种定性的风险转变为可以解决和分析的现象。", "conclusion": "本文建立了量化和限制幻觉的有原则基础，将其从定性的风险转变为有分析的可解决现象，通过谱图框架实现了多模态大语言模型中幻觉的数学化、理论可解释度量。"}
{"llm_update_time": "20251006", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.01443", "html_url": "https://arxiv.org/abs/2508.01443", "title": "基于元提示调优的LLM代码优化：从工业角度出发", "title_en": "Tuning LLM-based Code Optimization via Meta-Prompting: An Industrial Perspective", "authors": "Jingzhi Gong,Rafail Giavrimis,Paul Brookes,Vardan Voskanyan,Fan Wu,Mari Ashiga,Matthew Truscott,Mike Basios,Leslie Kanthan,Jie Xu,Zheng Wang", "background": "近年来，利用多个大型语言模型（LLMs）进行自动代码优化的兴趣日益增加。然而，工业化平台部署多个LLMs面临着一个关键挑战：针对一个LLM优化的提示在其他LLMs上往往不起作用，这需要昂贵的模型特定提示工程。这种跨模型提示工程瓶颈严重限制了多LLM系统的实际部署。现有的提示工程方法无法满足工业生产环境的需求。", "innovation": "本文提出了一种名为Meta-Prompted Code Optimization (MPCO)的框架，该框架能够在多样化的LLMs中自动生成高质量、特定任务的提示，同时保持工业效率要求。MPCO通过元提示利用项目元数据、任务要求和LLM特定上下文，动态合成上下文感知的优化提示。MPCO是ARTEMIS代码优化平台的一部分，用于自动化验证和扩展。在对五个实际代码库的全面评估中，MPCO在366小时的运行时基准测试中显示出其有效性：与基线方法相比，MPCO总体性能提高最多可达19.06%，在所有系统中获得最佳统计排名。分析表明，96%的顶级优化来源于有意义的编辑。通过对系统性的消融研究和元提示器敏感性分析，作者确定了全面上下文集成对于有效元提示的重要性和主要LLM充当元提示器的有效性，从而为工业从业者提供了有价值的观点和见解。", "conclusion": "MPCO框架在几个实际代码库上的评估证明了其有效性，并通过系统的消融研究和元提示器敏感性分析，强调了全面上下文集成在元提示中的重要性，以及在多LLM环境下进行代码优化的可能性。"}
{"llm_update_time": "20251006", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.01918", "html_url": "https://arxiv.org/abs/2508.01918", "title": "Quantum-RAG和PunGPT2：推进旁遮普语言的资源匮乏型生成和检索", "title_en": "Quantum-RAG and PunGPT2: Advancing Low-Resource Language Generation and Retrieval for the Punjabi Language", "authors": "Jaskaranjeet Singh,Rakesh Thakur", "background": "尽管大型语言模型（LLMs）取得了快速进展，低资源语言仍被自然语言处理（NLP）领域排除在外，限制了数百万用户的数字访问。这就使得发展适用于低资源语言的生成模型变得尤为重要。本文团队专注于发展旁遮普语语言模型，通过构建PunGPT2和Quantum-RAG来实现这一目标。PunGPT2是首个完全开源的旁遮普语生成模型，面向Gurmukhi和Shahmukhi脚本优化了分词器，覆盖了文学、宗教文本、新闻和社会讨论等各种文体。与此同时，引入了Pun-RAG和Pun-Instruct，分别结合了FAISS检索器和QLoRA调优方法，提升了零样本总结、翻译和问答任务的性能。关键创新Quantum-RAG通过结合稀疏、密集和量子内核嵌入，实现了高效、上下文感知的检索，标记着首次在低资源语言模型中的实证量子检索应用。所开发的模型在FLORES-200、IndicGenBench和新的PunjabiEval套件中超越了多语言基础模型（mBERT、mT5、MuRIL、BLOOM）", "innovation": "本文的创新点在于提出了Quantum-RAG，这是一种融合了稀疏、密集和量子内核嵌入的检索框架，能够在低内存消耗的情况下实现高效、上下文感知的检索，同时首次在外显资源匮乏的语言模型中实现了基于量子的检索。这标志了在低资源语言处理领域的一种技术进步，使得旁遮普语的生成和检索任务可以得到更准确、更有效的支持。此外，团队还开源了所有模型训练脚本、超参数、评估管道、35GB旁遮普语语料库、PunjabiEval基准以及模型权重。", "conclusion": "PunGPT2和Quantum-RAG展示了如何有效解决低资源语言NLP问题，并展示了旁遮普语在生成和检索任务上的新基准。这些创新将有助于更多低资源语言获得更好的数字访问体验，并推动该领域的进一步发展。"}
{"llm_update_time": "20251006", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.02372", "html_url": "https://arxiv.org/abs/2509.02372", "title": "Scam2Prompt：一种用于评估生产LLM中欺诈性钓鱼界面的可扩展框架", "title_en": "Scam2Prompt: A Scalable Framework for Auditing Malicious Scam Endpoints in Production LLMs", "authors": "Zhiyang Chen,Tara Saba,Xun Deng,Xujie Si,Fan Long", "background": "大规模语言模型（LLMs）已成为现代软件开发中的关键工具，但它们依赖于未经过严格筛选的海量网络数据集进行训练，这引入了一种重大的安全风险：即吸收和复制恶意内容。目前缺乏有效的方法来系统性地评估这一风险。", "innovation": "本文提出了Scam2Prompt框架，这是一种可扩展的自动化审计框架，它首先识别欺诈性钓鱼网站的意图，然后生成模仿这些意图的无辜开发人员风格的提示，以测试LLM是否会针对这些无辜提示生成恶意代码。通过这种方法，研究发现四个生产LLM中，Scam2Prompt的无辜提示触发了4.24%的恶意网址生成案例。进一步的研究还发现，这种安全风险不仅存在，而且更为严重，并且现有的安全措施如最先进的防护栏检测率不足0.3%，无法阻止这种行为。", "conclusion": "研究结果显示Scam2Prompt的无辜提示触发了4.24%的恶意网址生成案例，并且在其他多种生产模型中，恶意代码生成率最高达到43.8%。这表明这种安全风险不仅仍存在，而且非常严重。现有的安全措施如最先进的防护栏也证明不足以防止这种行为。"}
{"llm_update_time": "20251006", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.14052", "html_url": "https://arxiv.org/abs/2508.14052", "title": "FinAgentBench: 金融问答中代理检索的基准数据集", "title_en": "FinAgentBench: A Benchmark Dataset for Agentic Retrieval in Financial Question Answering", "authors": "Chanyeol Choi,Jihoon Kwon,Alejandro Lopez-Lira,Chaewoon Kim,Minjae Kim,Juneha Hwang,Jaeseon Ha,Hojun Choi,Suyeol Yun,Yongjin Kim,Yongjae Lee", "background": "在金融领域，准确的信息检索（IR）至关重要，投资者必须从大量的文档集合中识别出相关的信息。传统的IR方法，不论是稀疏的还是密集的，都往往在检索准确性上不尽如人意，这需要不仅要捕获语义相似性，还要进行细粒度的文档结构和领域特定知识的推理。近年来，大型语言模型（LLMs）的进展为多步推理下的检索提供了新的机会，模型通过迭代推理来评估哪一部分信息对给定查询最为相关。然而，至今在金融领域尚无专门评估此类能力的基准。", "innovation": "本文介绍了FinAgentBench，这是首个针对金融领域中多步推理下的检索能力进行评估的大规模基准——我们将其称为代理检索。基准数据集包含了26000个专家标注的样例，涉及S&P 500上市公司的例子，评估模型能否（1）在候选文档中识别最相关的文档类型，以及（2）在选定文档中定位关键段落。该评估框架明确地将这两个推理步骤分开，以解决背景限制问题，从而为理解金融领域中的检索为中心的LLM行为提供了定量基础。此外，还通过目标微调展示了如何显著提高代理检索表现。", "conclusion": "该基准为研究复杂且特定领域的检索为中心的LLM行为提供了基础，为金融领域的不明确任务提供了研究支撑。"}
{"llm_update_time": "20251006", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.02093", "html_url": "https://arxiv.org/abs/2509.02093", "title": "通过对比：基于检索增强的对比推理实现自动提示优化", "title_en": "Better by Comparison: Retrieval-Augmented Contrastive Reasoning for Automatic Prompt Optimization", "authors": "Juhyeon Lee,Wonduk Seo,Hyunjin An,Seunghyun Lee,Yi Bu", "background": "自动提示优化 recently emerged as a strategy for strengthening the quality of prompts used in Large Language Models (LLMs)，以生成更准确和有用的答案。然而，大多数早期工作主要集中在直接提示精炼或模型微调上，没有充分利用LLMs本身的推理能力来从对比例子中学习。", "innovation": "本文提出了一种名为Contrastive Reasoning Prompt Optimization (CRPO)的新颖框架，将提示优化建模为检索增强的推理过程。通过检索HelperSteer2数据集中标注了帮助性、准确性、连贯性、复杂性和冗长性的最佳提示-响应对，并构建了两种互补的优化范式：分层对比推理（通过比较高质量、中质量和低质量的示例来反思性地改进生成）和多指标对比推理（通过分析每个评估维度的最佳示例，并结合它们的优点以优化提示）。通过显式对比高质量和低质量的示例，CRPO 使模型能够理解成功的提示为何会成功，而其他提示则失败，从而实现更稳健和可解释的优化。", "conclusion": "在HelperSteer2基准测试上的实验结果表明，CRPO 显著优于基线。我们的发现突显了对比、基于检索增强推理对于推进自动提示优化的潜力。"}
{"llm_update_time": "20251006", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.02593", "html_url": "https://arxiv.org/abs/2509.02593", "title": "使用YOLOv12实现稳健的泛癌种有丝分裂图检测", "title_en": "Robust Pan-Cancer Mitotic Figure Detection with YOLOv12", "authors": "Raphaël Bourgade,Guillaume Balezo,Thomas Walter", "background": "有丝分裂图是肿瘤病理学中一个关键的组织病理学特征，提供了肿瘤侵袭性和增殖的重要见解。然而，识别这些特征对于病理学家来说仍然具有挑战性，即使是有经验的病理学家之间也存在显著的主观差异。为了应对这一问题，MItosis DOmain Generalization (MIDOG) 2025挑战是国际竞赛的第三次举办，旨在开发稳健的有丝分裂检测算法。", "innovation": "本文提出了一种基于先进YOLOv12对象检测框架的有丝分裂图检测方法。该方法在初步测试集（热点区域）中获得了0.801的F1分数，并在最终测试排行榜上获得了0.7216的整体F1分数，覆盖了复杂和异质的全切片区域，无需依赖外部数据，展示了该方法的有效性。", "conclusion": "本文提出的方法能够在复杂的全切片区域中进行泛癌种有丝分裂图的检测，并且无需依赖外部数据，从而提高了有丝分裂检测的可靠性和一致性。"}
{"llm_update_time": "20251006", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.18762", "html_url": "https://arxiv.org/abs/2509.18762", "title": "当长段帮助短段：监督微调中的上下文长度如何影响大型语言模型的行为", "title_en": "When Long Helps Short: How Context Length in Supervised Fine-tuning Affects Behavior of Large Language Models", "authors": "Yingming Zheng,Hanqi Li,Kai Yu,Lu Chen", "background": "大规模语言模型（LLMs）在自然语言处理（NLP）任务中表现出色。随着现实生活中的应用越来越需要更长的上下文窗口，对长上下文数据的持续预训练和监督微调（SFT）已成为一种常见方法。尽管对持续预训练中数据长度的影响已有广泛研究，但对其在监督微调中的影响仍不清楚。本研究系统地探讨了监督微调数据长度对LLMs在短上下文任务上的行为的影响。", "innovation": "研究发现在监督微调中，长上下文数据的使用能改善短上下文任务的性能，这与长上下文预训练通常会导致性能下降的观察结果相反。研究通过分离和分析多头注意力机制（MHA）和前馈网络（FFN）两种关键组件，揭示了知识偏好偏见：长上下文SFT促进情境知识，而短上下文SFT强调参数知识，依赖长上下文SFT可能会变得不够最优。最终展示混合训练可以减轻这种偏见，为微调LLMs提供可解释的指导。", "conclusion": "混合训练可以减轻知识偏好偏见，提供一种调和长上下文和短上下文的优势的方法，为微调LLMs提供可解释的指导。"}
{"llm_update_time": "20251006", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.22855", "html_url": "https://arxiv.org/abs/2509.22855", "title": "Observation-Free Attacks on Online Learning to Rank", "title_en": "Observation-Free Attacks on Online Learning to Rank", "authors": "Sameep Chattopadhyay,Nikhil Karamchandani,Sharayu Moharir", "background": "在线学习排名（OLTR）在信息检索和机器学习系统中扮演着关键角色，广泛应用于搜索引擎和内容推荐系统。然而，尽管OLTR算法被广泛采用，但它们对协调性对抗攻击的脆弱性却知之甚少。", "innovation": "该研究提出了一种新颖的框架，用于攻击某些广泛使用的OLTR算法。框架旨在在T - o(T)轮中提升一组目标项目的排名，使其出现在前K个推荐列表中，同时诱导学习算法产生线性遗憾。该研究提出了两种新的攻击策略：针对CascadeUCB1的CascadeOFA和针对PBM-UCB的PBMOFA，并提供了理论保证，证明这两种策略只需O(log T)次操纵即可成功。此外，还通过实际数据补充了理论分析。", "conclusion": "该工作为当前对OLTR算法的对抗性理解提供了新的视角，并展示了如何通过少量操纵来达成观测无感知的攻击效果。"}
{"llm_update_time": "20251006", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.17153", "html_url": "https://arxiv.org/abs/2509.17153", "title": "流诱导对角高斯过程", "title_en": "Flow-Induced Diagonal Gaussian Processes", "authors": "Moule Lin,Andrea Patane,Weipeng Jing,Shuhao Guan,Goetz Botterweck", "background": "本文介绍了一种名为Flow-Induced Diagonal Gaussian Processes (FiD-GP)的压缩框架，该框架通过引入紧凑的诱导权重矩阵将神经网络的权重不确定性投影到低维子空间中。该框架依赖于标准化流先验和光谱正则化来增强其表达能力，并通过数值稳定的投影机制客观来使诱导子空间与特征梯度几何对齐。此外，作者还展示了FiD-GP的预测框架如何帮助设计单通道投影以用于检测异常分布（Out-of-Distribution, OoD）", "innovation": "FiD-GP引入了流诱导机制与光谱正则化来增强其表达能力，并通过数值稳定的投影机制将诱导子空间与特征梯度几何对齐。此外，预测框架在FiD-GP中有助于设计单通道投影以用于OoD检测。该框架提高了多种任务中不确定性估计的能力，并且理论上保证了OoD检测，同时显著减少了神经网络的存储需求，但可能会增加推理计算量，具体取决于所使用的诱导权重数量。", "conclusion": "FiD-GP在回归、图像分类、语义分割和异常分布检测基准中大幅减少了贝叶斯训练成本，压缩模型参数约51%，减少模型大小约75%，同时达到了与现有最佳技术水平相当的准确性和不确定性估计表现。"}
{"llm_update_time": "20251006", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.17746", "html_url": "https://arxiv.org/abs/2507.17746", "title": "Rubrics as Rewards: Reinforcement Learning Beyond Verifiable Domains", "title_en": "Rubrics as Rewards: Reinforcement Learning Beyond Verifiable Domains", "authors": "Anisha Gunjal,Anthony Wang,Elaine Lau,Vaskar Nath,Yunzhong He,Bing Liu,Sean Hendryx", "background": "现有的强化学习方法，如可验证奖励（Reinforcement Learning with Verifiable Rewards, RLVR），已经在诸如数学和编程等具有明确正确性信号的复杂推理任务上取得成功。然而，将其扩展到现实世界的推理任务中仍存在挑战，因为评估依赖于多标准和多维度的判断，而不仅仅是二元正确性判断。最近，实例特定的评分标准被用于基准测试中以捕捉这类判断，但它们作为后续训练策略的奖励信号潜在作用仍需进一步探索。", "innovation": "本文提出了“评分标准作为奖励”（RaR，Rubrics as Rewards）方法，这是一种在线策略强化学习方法，通过使用基于评分标准的反馈扩展了RLVR的应用范围，使其适用于评分标准可验证的领域。这项研究评估了多种策略在不同领域中如何利用评分标准反馈来构建奖励信号，并展示了RaR在医学和科学领域中表现出的高性能，尤其是在评分标准和多项选择任务上。研究表明，使用评分标准作为结构化的奖励信号有助于缩小评分者规模差异产生的性能变异。", "conclusion": "最佳的RaR变体在HealthBench和GPQA-Diamond上的相对改进分别达到31%和7%，超过了依赖于直接量表奖励的人工智能基础模型。这些结果表明，RaR训练策略能够很好地适应多样的评估格式，在评分标准和多项选择任务上都有出色的表现。此外，研究还发现，使用评分标准作为结构化的奖励信号对小型评分者有更好的对齐效果，并降低了不同评分者规模之间的性能变异。"}
{"llm_update_time": "20251006", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.01793", "html_url": "https://arxiv.org/abs/2509.01793", "title": "STORI：随机环境基准和分类", "title_en": "STORI: A Benchmark and Taxonomy for Stochastic Environments", "authors": "Aryan Amit Barsainyan,Jing Yu Lim,Dianbo Liu", "background": "尽管强化学习（RL）技术在仿真的基准测试中如Atari100k取得了显著的成功，但最近的进展仍然主要局限于模拟环境中，并且对于现实世界的领域展示出有限的转移效果。一个主要障碍是环境的随机性，因为现实系统包含了噪声观察、不可预测的动力学以及非稳态条件，这些都会削弱现有方法的稳定性。现有的基准很少能够捕捉到这些不确定性，而往往偏好简化环境设置，使得算法可以被调优以取得成功。由于缺乏对随机性明确的分类，使得对算法的评估变得复杂，对一种类型的随机性问题的鲁棒性不一定意味着对其他形式不确定性问题的鲁棒性。因此，为了应对这个关键的不足，我们引入了STORI（STOchastic-ataRI），一种系统地整合多种随机性效应的基准，能够为不同的不确定性形式提供严格评估RL技术的方法。我们提出了一种全面的五类环境随机性分类，并通过DreamerV3和STORM的针对性评估，展示了最先进的模型基RL算法系统性中的脆弱性。我们的发现表明世界模型显著低估了环境的变异性、在动作破坏面前存在困难，并且在部分可观时表现出不稳定的动态。", "innovation": "我们提出了一种名为STORI的基准，系统地整合了多种随机性效应，提供了一个统一框架来评估在不同不确定性形式下的RL技术。我们提出了一种全面的五类环境随机性分类，并通过DreamerV3和STORM的针对性评估，揭示了最先进的模型基RL算法的系统性脆弱性。", "conclusion": "我们的研究揭示了世界模型显著低估环境变异性、在动作破坏面前存在困难，并且在部分可观测条件下表现出不稳定的动态。我们发布了STORI的代码和基准，提供了一个统一框架来开发更鲁棒的RL系统。"}
{"llm_update_time": "20251006", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.15573", "html_url": "https://arxiv.org/abs/2509.15573", "title": "追求不变量化显著对象检测：一种通用评估和优化方法", "title_en": "Towards Size-invariant Salient Object Detection: A Generic Evaluation and Optimization Approach", "authors": "Shilong Bao,Qianqian Xu,Feiran Li,Boyu Han,Zhiyong Yang,Xiaochun Cao,Qingming Huang", "background": "本文探讨了显著对象检测（SOD）中一个基础但被忽视的问题：评价标准的尺寸不变性，特别是在单张图像中存在多个显著差异尺寸的显著对象时。现有广泛使用的SOD指标在评价图像时存在固有的尺寸敏感性，导致评价结果偏向于大区域而忽略小型但可能更具语义重要性的对象，从而造成偏见的性能评估和实际效果的降级。研究表明，当前SOD指标的评估结果可以分解为多个可分离的项之和，每个项的贡献与其相应区域的大小直接相关。因此，预测误差主要由大区域主导，而小型且可能更具语义重要性的对象则经常被忽视，进而导致评价的偏差和实用性能的下降。", "innovation": "本文提出了一个通用的尺寸不变性评估框架（SIEva），通过单独评估每个可分离的组件然后综合结果来减轻对象之间的尺寸不平衡影响。在此基础上，进一步开发了一种专用的优化框架（SIOpt），该框架遵循尺寸不变性原则，显著增强了不同尺寸下的显著对象检测性能。SIOpt是模型无关的，可以无缝集成到各种SOD骨干网络中。此外，还提出了SOD方法的泛化分析，并提供了支持新评估协议有效性的证据。", "conclusion": "通过详尽的实验验证了我们提出的方法的有效性。相关代码可以在这个URL访问：[提供的URL]。"}
{"llm_update_time": "20251006", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.24827", "html_url": "https://arxiv.org/abs/2509.24827", "title": "普特南类似数据集概述：大语言模型作为数学竞赛选手", "title_en": "Putnam-like dataset summary: LLMs as mathematical competition contestants", "authors": "Bartosz Bieganowski,Daniel Strzelecki,Robert Skiba,Mateusz Topolewski", "background": "本文总结了Google DeepMind发布的类似于普特南竞赛的基准测试结果。该基准测试包含96个原创问题，源自普特南竞赛的精神，并有576个来自大型语言模型（LLMs）的解决方案。本文旨在分析模型在该问题集上的表现，以验证其解决数学竞赛问题的能力。", "innovation": "介绍了使用大型语言模型参与数学竞赛的情况；分析了模型在解决数学竞赛问题上的表现。", "conclusion": "通过分析模型在给定问题集的表现，验证了模型解决数学竞赛问题的能力。"}
{"llm_update_time": "20251006", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.23799", "html_url": "https://arxiv.org/abs/2509.23799", "title": "基于稀疏自编码器向量精炼的大型语言模型引导增强", "title_en": "Enhancing LLM Steering through Sparse Autoencoder-Based Vector Refinement", "authors": "Anyi Wang,Xuansheng Wu,Dong Shu,Yunpu Ma,Ninghao Liu", "background": "大规模语言模型（LLMs）的控制作为一个重要的问题受到关注，现有的一些控制方法依赖于大规模数据集，导致其在实际应用场景中的适用性受限。从少量数据提取的引导向量常常包含与任务无关的噪声特征，这影响了其效果。", "innovation": "提出了一种基于稀疏自编码器（SAE）的引导向量精炼方法（SAE-RSV），该方法通过自编码器去除与任务无关的特征并增强较少数据集中的任务相关特征，从而提高从有限数据中学习的有效引导向量的能力，实验结果表明SAE-RSV显著优于基线方法包括监督微调方法。", "conclusion": "通过运用自编码器对初始引导向量进行精炼，该研究成功地使用较少的训练数据构建了有效引导向量，提升了在实际场景中控制LLM的有效性。"}
{"llm_update_time": "20251006", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.12990", "html_url": "https://arxiv.org/abs/2509.12990", "title": "长尾视角错误检测的双阶段重权MoE", "title_en": "Dual-Stage Reweighted MoE for Long-Tailed Egocentric Mistake Detection", "authors": "Boyu Han,Qianqian Xu,Shilong Bao,Zhiyong Yang,Sicong Li,Qingming Huang", "background": "本文针对从主观视频数据中确定用户是否执行动作错误的问题进行研究。由于细微且不频繁的错误带来的挑战，如错误不易察觉和发生频率低，使得准确识别这些错误变得困难。", "innovation": "本文提出了一种名为Dual-Stage Reweighted Mixture-of-Experts (DR-MoE)的框架。该框架分为两阶段，在第一阶段使用冻结的ViViT模型和LoRA调整的ViViT模型提取特征，并通过特征级专家模块进行组合。第二阶段对三个分类器进行训练，每个分类器使用不同的目标：重权交叉熵损失以缓解类别不平衡，AUC损失以改善分布倾斜下的排序性能，以及具有尖锐感知最小化的新颖标签感知损失以提高校准和泛化能力。分类器的预测结果通过分类级专家模块进行融合。", "conclusion": "提出的DR-MoE方法在识别罕见和模棱两可的错误实例方面表现出强大的性能。该研究的代码可从提供的URL获取。"}
{"llm_update_time": "20251006", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.25085", "html_url": "https://arxiv.org/abs/2509.25085", "title": "jina-reranker-v3：最后一次但并非最晚的交互方式用于列表文档重新排序", "title_en": "jina-reranker-v3: Last but Not Late Interaction for Listwise Document Reranking", "authors": "Feng Wang,Yuqing Li,Han Xiao", "background": "目前存在多种文档重排序模型，如ColBERT，在这些模型中，通常做法是在多向量匹配之前单独编码文档。这种模型在网络大小和性能之间存在权衡。本文构建了一个名为jina-reranker-v3的0.6B参数多语言列表文档重排序模型。", "innovation": "本文提出了一种新颖的'最后但并非最晚'交互机制，与ColBERT等模型不同，该模型在相同的上下文窗口中应用从查询到所有候选文档的因果注意力，在提取每篇文档最终token的上下文嵌入前实现了丰富的交互。", "conclusion": "新的模型在BEIR评估中达到了最先进的61.94 nDCG@10性能指标，且网络尺寸比其他具有类似性能的模型要小得多。"}
{"llm_update_time": "20251006", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.25659", "html_url": "https://arxiv.org/abs/2509.25659", "title": "基于YOLO的金属薄板缺陷检测", "title_en": "YOLO-Based Defect Detection for Metal Sheets", "authors": "Po-Heng Chou,Chun-Chi Wang,Wei-Lung Mao", "background": "在工业制造中，手动缺陷检测是一项耗时且繁琐的任务，而利用深度学习模型如YOLO进行自动缺陷检测可以提高效率和精度。", "innovation": "该研究创新性地将ConSinGAN生成技术与YOLO模型结合，以增强数据集，进而提升自动缺陷检测的准确性和效率。通过四种不同版本的YOLO模型与ConSinGAN的结合使用，实现了高精度检测，即YOLOv9模型在检测准确率和检测时间上均明显优于其他版本模型。", "conclusion": "研究提出的基于YOLOv9的自动化光学检测系统成功应用于金属薄板的缺陷检测，并且该系统可以推广到工业制造中的其他组件。"}
{"llm_update_time": "20251006", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.22807", "html_url": "https://arxiv.org/abs/2509.22807", "title": "MTRec: 通过心理奖励模型来对齐用户偏好", "title_en": "MTRec: Learning to Align with User Preferences via Mental Reward Models", "authors": "Mengchen Zhao,Yifan Gao,Yaqing Hou,Xiangyang Li,Pengjie Gu,Zhenhua Dong,Ruiming Tang,Yi Cai", "background": "推荐模型大多使用隐式用户反馈进行训练，因为显式反馈的成本较高。然而，隐式反馈，如点击行为，并不一定能真正反映用户的实际偏好。例如，用户可能因为标题吸引人的新闻文章而点击，但在阅读内容后可能会感到不适。在缺乏显式反馈的情况下，这些不准确的隐式信号可能会严重误导推荐系统。因此，需要一种新的方法来更好地对齐推荐系统的决策与用户的实际偏好。MTRec因此应运而生，它通过发现推荐项目的内在满意度来与用户的实际满意度相一致。", "innovation": "MTRec提出了一种新颖的序列推荐框架，名为MTRec，该框架通过引入心理奖励模型来量化用户的满意度，并采用分布性的逆强化学习方法来学习这一模型。心理奖励模型随后用于指导推荐模型更好地对齐用户的实际偏好。实验结果表明，MTRec在多种推荐模型上带来了显著的改进。并且在一项工业短视频平台上部署MTRec后，平均用户观看时间提高了7%。这些改进证明了MTRec的有效性。", "conclusion": "MTRec显著提升了推荐模型对用户实际偏好的一致性，通过使用心理奖励模型和分布性的逆强化学习，推荐系统能够更加准确地反映用户的真实需求。这种技术不仅适用于新闻推荐，也可以推广应用于其它推荐系统中，促进用户体验的提升。"}
{"llm_update_time": "20251006", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.24798", "html_url": "https://arxiv.org/abs/2509.24798", "title": "因果适配器：驯服文本到图像扩散以实现忠实的假想生成", "title_en": "Causal-Adapter: Taming Text-to-Image Diffusion for Faithful Counterfactual Generation", "authors": "Lei Tong,Zhihua Liu,Chaochao Lu,Dino Oglic,Tom Diethe,Philip Teare,Sotirios A. Tsaftaris,Chen Jin", "background": "本文介绍了因果适配器（Causal-Adapter），这是一种模块化框架，用于适应冻结的文本到图像扩散基础模型以生成假设性图像。该方法能够在不改变图像核心身份的情况下对目标属性进行因果干预，并且能够将这些干预的效果传递给因果依赖项。与依赖于提示工程而缺乏明确因果结构的先前方法不同，因果适配器结合结构因果建模和两种属性正则化策略（提示对齐的注入与条件化标记对比损失）实现了属性的精确控制和特征分离，从而减少了无关相关性。前人在这一领域尚未达到本文所达到的性能水平，Causal-Adapter 在合成和真实数据集上都取得了最好性能，MAE 减少至 91%，FID 减少至 87%，这表明了该方法能够实现稳健、通用性良好的假设编辑，具有忠实的属性修改和强保真身份的特性。", "innovation": "因果适配器采用了结构因果建模并结合了两种属性正则化策略：提示对齐的注入和条件化标记对比损失。该方法能够精确控制和分离属性因素，有效减少无关相关性，并实现了对目标属性的因果干预，而不会改变图像的核心身份。这一方法在合成和真实数据集上均达到最先进的性能，展示了其在假设编辑方面的优越能力，特别是在高精度MRI图像生成方面的表现特别突出。", "conclusion": "因果适配器通过结合结构因果建模与先进的人工正则化策略，实现了对文本到图像扩散基础模型的强大控制和高效利用，显著提升了生成假设性图像的质量与可靠性。这一研究成果表明，通过精确的因果干预，可以实现保真度高、修改忠实的假设编辑，有助于图像生成任务的进一步发展。"}
{"llm_update_time": "20251006", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.01784", "html_url": "https://arxiv.org/abs/2510.01784", "title": "Pack and Force Your Memory: 长视频生成", "title_en": "Pack and Force Your Memory: Long-form and Consistent Video Generation", "authors": "Xiaofei Wu,Guozhen Zhang,Zhiyong Xu,Yuan Zhou,Qinglin Lu,Xuming He", "background": "长视频生成带来了双重挑战：模型需要捕捉长距离依赖性，同时防止自回归解码过程中固有的误差累积。现有模型在这两方面都面临困难。", "innovation": "本研究表明，提出了一个名为MemoryPack的可学习的上下文检索机制，该机制结合了文本和图像信息作为全局指导，以共同建模短期和长期依赖性，从而实现分钟级的时序一致性。此外，引入了直接强迫策略，这是一种有效的一步近似策略，提高了训练-推理的一致性，从而在推理过程中减少误差传播。这两项创新共同提高了长视频生成的上下文一致性和可靠性。", "conclusion": "MemoryPack和直接强迫策略显著增强了长视频生成的上下文一致性和可靠性，推动了自回归视频模型的实际应用。"}
{"llm_update_time": "20251006", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.24967", "html_url": "https://arxiv.org/abs/2509.24967", "title": "SecInfer：通过推理时扩展预防提示注入攻击", "title_en": "SecInfer: Preventing Prompt Injection via Inference-time Scaling", "authors": "Yupei Liu,Yanting Wang,Yuqi Jia,Jinyuan Jia,Neil Zhenqiang Gong", "background": "提示注入攻击是对大型语言模型（LLMs）安全构成的普遍威胁。目前最先进的基于预防的防御措施通常通过 fine-tuning LLM 来增强其安全性，但这些方法对强大的攻击效果有限。研究中指出现有的预防方法虽有一定效果，但在强攻击面前收效甚微。", "innovation": "本文提出 SecInfer，一种基于推理时扩展（inference-time scaling）防御提示注入攻击的新型方法。SecInfer 包含两个关键步骤：系统提示引导采样，通过探索多样化的推理途径生成多个响应；目标任务引导聚合，选择最有可能完成预期任务的响应。SecInfer 利用推理时的额外计算资源，有效对抗现有的和适应性的提示注入攻击，优于现有的预防方法以及现有的推理时扩展方法。", "conclusion": "实验结果表明，SecInfer 能够通过利用推理时的额外计算资源，有效减轻提示注入攻击的影响，表现优于现有的最佳防御系统以及现有的推理时扩展方法。"}
{"llm_update_time": "20251006", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.00476", "html_url": "https://arxiv.org/abs/2510.00476", "title": "分析代码语言模型中的潜在概念", "title_en": "Analyzing Latent Concepts in Code Language Models", "authors": "Arushi Sharma,Vedant Pungliya,Christopher J. Quinn,Ali Jannesari", "background": "分析大型语言模型中代码的内部行为仍然是一个关键挑战，尤其是在需要信任、透明性和语义稳健性的应用中。现有的方法难以揭示模型内部的语义结构和行为模式，因此提出了一个新的框架来解决这一问题。", "innovation": "提出了一种名为Code Concept Analysis（CoCoA）的全局后验解释框架，该框架通过将上下文条件下的标记嵌入聚类成可解读的概念组来揭示代码语言模型表达空间中的潜在语义结构。同时，提出了一种结合静态分析工具的语法对齐和提示工程大型语言模型的混合注释管道，以实现概念标注的可扩展性。进一步地，将局部归因方法与LCA结合，生成基于概念的解释，提高了标记级别显著性的清晰度和可解释性。实验结果表明，LCA能够在保持语义不变的情况下发现稳定的潜在概念，并且随着微调会预测性演化。同时，在编程语言分类任务中，增强解释比基于Integrated Gradients的标记级归因提升了37个百分点的人类中心可解释性.", "conclusion": "实验结果显示，LCA在多种模型和任务中具有稳健性和预测性，特别是在具备语义不变性和解释提升方面表现显著。CoCoA框架能够帮助识别模型内部的意外潜在交互，并用于识别模型学习表示中的趋势和偏见，从而促进对代码语言模型的深入理解。"}
{"llm_update_time": "20251006", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.01252", "html_url": "https://arxiv.org/abs/2510.01252", "title": "GPT与偏见：理解大型语言模型中学习表示的稀疏方法", "title_en": "GPT and Prejudice: A Sparse Approach to Understanding Learned Representations in Large Language Models", "authors": "Mariam Mahran,Katharina Simbeck", "background": "随着大型语言模型（LLMs）越来越多地在大规模、未加筛选的数据集中进行训练，理解模型的表示及其内化的数据结构、主题和偏见已成为一个重要挑战。", "innovation": "该工作展示了将大型语言模型与稀疏自编码器（SAEs）结合使用，不仅可以解读模型行为，还可以揭示训练数据中的深层结构、主题和偏见。实验使用简·奥斯汀的小说作为训练数据，这些小说富含社会构建和叙事模式。通过应用SAEs到多层隐藏状态，揭示了反映关键叙事和概念的稀疏、可解释特征，包括性别、阶级和社会责任。研究表明，结合LLMs与SAEs可以作为大规模数据集的可扩展探针，提供新的文本语料库探索、偏见发现和大规模模型可解释性路径。", "conclusion": "本研究证明，大型语言模型结合稀疏自编码器可以作为大规模数据集的可扩展探针，为文本语料库探索、偏见发现和大规模模型可解释性提供新的途径。"}
{"llm_update_time": "20251006", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.01812", "html_url": "https://arxiv.org/abs/2510.01812", "title": "SingMOS-Pro：歌唱质量评估的全面基准", "title_en": "SingMOS-Pro: An Comprehensive Benchmark for Singing Quality Assessment", "authors": "Yuxun Tang,Lan Liu,Wenhao Feng,Yiwen Zhao,Jionghao Han,Yifeng Yu,Jiatong Shi,Qin Jin", "background": "歌唱声音生成技术迅速发展，但评估歌唱质量仍然是一个关键性挑战。目前的人类主观评估通常需要进行听力测试，成本高且耗时。现有的客观指标也只能捕捉到有限的感知方面。因此，亟需一种自动化的歌唱质量评估方法。", "innovation": "本文引入了一个新的数据集SingMOS-Pro，用于自动歌唱质量评估。SingMOS-Pro基于此前的SingMOS版本，新增了歌词、旋律和整体质量的注释，涵盖更广泛的内容和更丰富的多样性。数据集中包含来自12个数据集的41个模型生成的7,981个歌唱片段，并至少有5位专业注释员进行评分，以确保可靠性和一致性。此外，研究探讨了如何有效利用不同标准下注释的数据，并对SingMOS-Pro进行了多种广泛使用的评估方法的基准测试，为未来研究提供了坚实的基础。", "conclusion": "本文利用SingMOS-Pro数据集，在不同类型标准下探索了MOS数据的利用方法，并对常见评价方法进行了基准测试，为进一步研究提供了有力的支持。整个数据集可以通过指定的URL访问。"}
{"llm_update_time": "20251006", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.00060", "html_url": "https://arxiv.org/abs/2510.00060", "title": "更少而已：用于自动驾驶的简约而强大的视觉语言模型", "title_en": "Less is More: Lean yet Powerful Vision-Language Model for Autonomous Driving", "authors": "Sheng Yang,Tong Zhan,Guancheng Chen,Yanfeng Lu,Jian Wang", "background": "本文探讨了将自动驾驶重新概念化为通用语言的新方法，并将轨迹规划任务作为下一待定点预测。论文通过Max-V1框架提出了一个一站式的端到端自主驾驶方案，利用视觉语言模型（VLM）的生成能力，直接从前置摄像头输入生成路径预测。这种方法的基础是通过规模庞大的专家演示进行模仿学习，并由统计模型推导的原则性监督策略定义学习目标，从而实现复杂的驾驶策略的掌握。实验结果表明，该方法在nuScenes数据集上的表现优于之前的基准方法，同时展示了在跨领域数据集上的优越泛化性能，证明了其在不同车辆之间的鲁棒性和适应性。", "innovation": "本文提出了一种新的Max-V1框架，结合了视觉语言模型的生成能力，实现了直接从前置摄像头输入进行端到端的轨迹预测。这种方法依赖于从统计建模中推导出的理念性监督策略，并通过大规模专家演示指导的模仿学习掌握复杂的驾驶策略。实验结果显示该方法在nuScenes数据集上的性能达到了最先进的水平，且在跨域数据集上的泛化性能显著优于之前的基线方法。", "conclusion": "本文的贡献在于通过Max-V1框架开发了一种强大的视觉语言模型，该模型可以通过端到端的方式直接从前置摄像头输入进行轨迹预测。这种方法不仅在先进的数据集上达到了最先进的性能，还在不同的车辆数据集上展示了卓越的泛化能力，为其在自动驾驶车辆中的广泛应用奠定了基础。代码将在出版后提供。"}
{"llm_update_time": "20251006", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.21634", "html_url": "https://arxiv.org/abs/2509.21634", "title": "MobiLLM: 一种用于6G开环RAN闭环威胁缓解的自主性AI框架", "title_en": "MobiLLM: An Agentic AI Framework for Closed-Loop Threat Mitigation in 6G Open RANs", "authors": "Prakhar Sharma,Haohuang Wen,Vinod Yegneswaran,Ashish Gehani,Phillip Porras,Zhiqiang Lin", "background": "6G网络的演进正受到Open Radio Access Network (O-RAN)模式的加速，这是一种开放且可互操作的架构，旨在促进公共电信和私有企业领域的智能模块化应用。尽管O-RAN的开放性带来了前所未有的创新机会，但也扩大了攻击面，因此需要具备弹性和低成本的自主性安全解决方案。传统的防护措施通常反应迟缓、劳动密集且不足以应对下一代系统的规模和复杂性。当前O-RAN应用主要集中在网络优化或被动威胁检测，缺乏闭环自动化响应的能力。", "innovation": "本文提出了一种自主性AI框架MobiLLM，旨在实现6G O-RAN环境中的完全自动化和端到端的威胁缓解。该框架通过大型语言模型（LLMs）驱动的模块化多代理系统协调安全工作流程，具备威胁分析代理、使用检索增强生成（RAG）技术进行威胁分类以及通过O-RAN控制接口安全地实施缓解行动等功能。MobiLLM基于MITRE FiGHT框架和3GPP规范，具有强大的安全护栏，提供了可信赖的AI驱动网络安全蓝图。实验表明，MobiLLM能够有效识别和协调复杂的缓解策略，大大缩短了响应延迟，展示了自主安全运营在6G环境中的可行性。", "conclusion": "MobiLLM提供了一种可行的解决方案，以实现6G O-RAN环境中的闭环威胁缓解，并通过自主性AI展示了在网络安全性方面的巨大潜力。"}
{"llm_update_time": "20251006", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.02324", "html_url": "https://arxiv.org/abs/2510.02324", "title": "CASAL: 使用CASAL减少幻觉", "title_en": "Hallucination reduction with CASAL: Contrastive Activation Steering For Amortized Learning", "authors": "Wannan Yang,Xinchi Qiu,Lei Yu,Yuchen Zhang,Oliver Aobo Yang,Narine Kokhlikyan,Nicola Cancedda,Diego Garcia-Olano", "background": "大型语言模型（LLMs）表现出令人印象深刻的性能，但经常出现幻觉现象，即自信地提供错误答案而不是承认自己的无知。已有研究显示，模型在其知识表示中存在线性结构，并且可以利用激活引导减少幻觉。然而，当前的激活引导方法需要在推理过程中进行实时监控和干预。需要一种更高效的方法来连接解释性与近似优化。", "innovation": "我们提出了对比激活引导的近似学习（CASAL），这是一种高效算法，通过将激活引导的优势直接嵌入模型的权重中，将解释性与近似优化相结合。CASAL的轻量级设计仅需训练单一变压器层的一个子模块，但在多个短问答基准上的幻觉减少了30%-40%。CASAL在计算效率和数据效率方面分别比基于LoRA的强基线方法（如SFT和DPO）提高了30倍和20倍，提高了其在数据稀缺领域的实用性。CASAL还很好地泛化到脱离分布（OOD）领域，并展示了在纯文本和视觉语言模型中减轻幻觉的灵活性。CASAL是首个证明对密集模型和混合专家模型（MoE）有效的方法。", "conclusion": "CASAL代表了一种将解释性驱动方法应用于生产系统部署的有希望的进步。"}
{"llm_update_time": "20251006", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.00038", "html_url": "https://arxiv.org/abs/2510.00038", "title": "DM-Bench：糖尿病管理中个性化决策的人工智能模型基准", "title_en": "DM-Bench: Benchmarking LLMs for Personalized Decision Making in Diabetes Management", "authors": "Maria Ana Cardei,Josephine Lamp,Mark Derdzinski,Karan Bhatia", "background": "当前的健康基准主要集中在通用问题、面向临床医生的问题或仅关注临床任务（如诊断、分诊），缺乏专门针对糖尿病个人日常管理中的实际决策任务的评估框架。因此，本文提出了DM-Bench，这是首个评估大型语言模型在糖尿病管理等实际任务中的性能基准，涵盖了个体在糖尿病日常管理中所面临的一系列问题，包括基础血糖解读、教育查询、行为关联、高级决策和长期规划等任务。研究基于15,000名来自不同类型糖尿病群体的连续一个月时间序列数据，生成了360,600个个性化的、上下文相关的问题，评估模型在5个维度上的表现：准确度、依据现实、安全性、清晰度和可行动性，揭示了不同模型在各任务和维度上的表现差异性和复杂性。", "innovation": "DM-Bench 是首个专门针对糖尿病管理中的实际决策任务评估大型语言模型性能的基准。它不仅覆盖了广泛的现实世界问题，还提供了大规模、精细的时间序列数据，并通过五个维度对模型进行多层次的评估，即准确度、依据现实、安全性、清晰度和可行动性。此外，它还是第一个将临床任务与非临床任务结合起来的基准，为糖尿病管理领域引入了个性化和行为相关的AI原型解决方案的评估框架。", "conclusion": "通过建立DM-Bench，研究人员旨在推进糖尿病护理领域中AI解决方案的可靠性、安全性、有效性和实际实用性。该基准提供了对比不同大型语言模型表现的标准，有助于确定在糖尿病管理方面的最佳AI解决策略。研究结果表明，在不同的任务和维度上，没有单一模型能够全面优于其他模型，这强调了针对特定糖尿病管理情境进行专门优化的必要性。"}
{"llm_update_time": "20251006", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.02084", "html_url": "https://arxiv.org/abs/2510.02084", "title": "KAIROS：统一训练以实现通用非自回归时间序列预测", "title_en": "KAIROS: Unified Training for Universal Non-Autoregressive Time Series Forecasting", "authors": "Kuiye Ding,Fanda Fan,Zheya Wang,Hongxiao Li,Yifan Wang,Lei Wang,Chunjie Luo,Jianfeng Zhan", "background": "在互联网上，可靠的时序预测提供了前瞻性信号，用于资源规划、缓存放置和异常响应，使平台能够在用户行为和内容分布不断变化的情况下高效运行。与其他领域相比，Web应用程序的时序预测需要更快的响应时间，以支持实时决策。", "innovation": "KAIROS是一种非自回归时间序列预测框架，可以直接模型化分段级别的多峰分布。它避免了误差累积，并实现了即时推理，同时优于现有的非自回归模型，这些模型容易产生过度平滑的预测。KAIROS在大规模语料库上训练，并在六个广泛使用的基准上展示了强大的零样本泛化能力，性能比具有类似规模的最先进技术模型相当，但推理成本更低。此外，KAIROS强调了非自回归设计作为时间序列中基础模型可扩展范式的的重要性。", "conclusion": "KAIROS展示了非自回归设计在时间序列预测中的优势，通过统一训练实现了高效的零样本泛化，并大幅降低了推理成本。"}
{"llm_update_time": "20251006", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.02120", "html_url": "https://arxiv.org/abs/2510.02120", "title": "VarCoNet: 一种基于变异性感知的自监督框架，用于静息态功能性连接体的提取", "title_en": "VarCoNet: A variability-aware self-supervised framework for functional connectome extraction from resting-state fMRI", "authors": "Charalampos Lamprou,Aamna Alshehhi,Leontios J. Hadjileontiadis,Mohamed L. Seghier", "background": "精准医疗的关键在于考虑个体间大脑功能的差异性。以往研究往往将这种变异性视为噪声而非有意义的数据。VarCoNet框架通过引入自监督对比学习，有效利用了这种内在的功能变异性，旨在从静息态功能磁共振成像(rs-fMRI)数据中稳健地提取功能性连接体(FC)。该框架通过对rs-fMRI信号进行新颖的分割增强策略，优化了1D-CNN-Transformer编码器，并结合了稳健的贝叶斯超参数优化方法，以提高时间序列处理性能。该方法在两个下游任务上进行了评估：一是从人类连接组项目获取的rs-fMRI数据进行个体特征分类，二是通过ABIDE I和ABIDE II数据集进行自闭症谱系障碍(ASD)分类，展示了其优越性、稳健性、可解释性和泛化能力。", "innovation": "VarCoNet框架通过引入自监督对比学习，利用了大脑功能变异性，采用新颖的rs-fMRI信号分割增强策略，结合了1D-CNN-Transformer编码器和稳健的贝叶斯超参数优化方法，以提高时间序列处理性能。VarCoNet在两个下游任务上的表现优于多种深度学习方法，证明了其优越性、稳健性、可解释性和泛化能力。", "conclusion": "VarCoNet为静息态功能性连接体分析提供了一个灵活且稳健的框架，可以广泛应用于不同脑分区，展示了其优越性、稳健性、可解释性和泛化能力。"}
{"llm_update_time": "20251006", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.01494", "html_url": "https://arxiv.org/abs/2510.01494", "title": "理解对抗转移：为什么模型空间攻击在数据空间攻击成功的地方失败", "title_en": "Understanding Adversarial Transfer: Why Representation-Space Attacks Fail Where Data-Space Attacks Succeed", "authors": "Isha Gupta,Rylan Schaeffer,Joshua Kazdan,Ken Ziyu Liu,Sanmi Koyejo", "background": "对抗鲁棒性的研究已建立起这样一个认知：图像样例间可以成功传递对抗样本，语言模型间同样能成功传递文本攻击。然而近期研究发现，图像攻击在视觉-语言模型间不能成功传递。为解释这种差异，本文建议攻击在输入数据空间和模型表示空间之间的转移性存在根本差异：输入数据空间的攻击可以转移，而模型表示空间的攻击不能转移，除非模型表示的几何结构对齐。本文通过多场景的理论和实证来验证这一假设，并揭示了对抗性攻击传递并非所有攻击的固有属性，而是取决于它们的操作领域——共享的数据空间与模型独特的表示空间之间的区别，这对构建更鲁棒的模型至关重要。“Understanding Adversarial Transfer: Why Representation-Space Attacks Fail Where Data-Space Attacks Succeed”", "innovation": "本文提出并证明了一种新的理论，即攻击在输入数据空间可以成功转移，但在模型表示空间则不行，除非模型表示的几何结构对齐。通过数学证明、构建高成功率但不能转移的模型空间攻击、以及成功的数据空间攻击跨模型转移的实验证据来支持这一假设。这为建筑更鲁棒的机器学习模型提供了新的见解和方法。", "conclusion": "对抗性攻击的传递性取决于它们的操作领域——数据空间的攻击能够传递，而模型表示空间的攻击则不能，至少在没有几何结构对齐的情况下不能。这一发现揭示了构建更具鲁棒性的模型时一个关键的认知：针对不同类型的模型和空间特性设计相应的攻击策略是必要的。"}
{"llm_update_time": "20251006", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.02327", "html_url": "https://arxiv.org/abs/2510.02327", "title": "KAME: Tandem Architecture for Enhancing Knowledge in Real-Time Speech-to-Speech Conversational AI", "title_en": "KAME: Tandem Architecture for Enhancing Knowledge in Real-Time Speech-to-Speech Conversational AI", "authors": "So Kuroki,Yotaro Kubo,Takuya Akiba,Yujin Tang", "background": "实时语音转语音（S2S）模型能够生成自然流畅且低延迟的交际回应，但往往缺乏深厚的知识和语义理解。相反，包含自动语音识别、基于文本的大型语言模型（LLM）和文本转语音合成的级联系统虽然可以提供强大的知识表示，但会导致高延迟，从而破坏自然交互的流畅性。", "innovation": "本文介绍了一种新颖的混合架构，旨在同时结合实时S2S模型的优势和基于文本的LLM的深度知识。该架构通过S2S变压器即时处理用户语音，同时将查询传递给强大的后端LLM。LLM的文本反馈被实时注入到S2S模型中，以指导语音生成，从而增强了输出的知识丰富度，而无需像级联系统那样承担完全的延迟成本。", "conclusion": "我们的方法经过评估，使用MT-Bench基准的语音合成版本进行多轮问答会话，在响应准确性上显著优于基准S2S模型，接近于级联系统的性能，同时维持了与基准模型相同的延迟水平。"}
{"llm_update_time": "20251006", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.02326", "html_url": "https://arxiv.org/abs/2510.02326", "title": "抗幻觉、领域特定的研究助理与自我评估及基于向量的检索", "title_en": "Hallucination-Resistant, Domain-Specific Research Assistant with Self-Evaluation and Vector-Grounded Retrieval", "authors": "Vivek Bhavsar,Joseph Ereifej,Aravanan Gurusami", "background": "大型语言模型能够加速文献综合，但存在产生幻觉和误引的风险，限制了它们在专家工作流程中的实用性。本文探讨了一个模块化GPT研究助手（RA-FSM），它通过一个有限状态控制器将生成过程转化为Relevance（相关性）、Confidence（置信度）、Knowledge（知识）三步循环，并且基于向量检索和确定性的引文管道系统，旨在解决上述问题，提升研究效率和准确性。", "innovation": "引入了RA-FSM系统，这是一个基于GPT的研究助手，通过一个有限状态控制器实现Relevance、Confidence、Knowledge三个阶段的循环控制，确保生成内容的准确性和专业性。该系统还集成了基于向量的检索和确定性的引文处理流程，使得答案具有更高质量的证据支持，并能够应对复杂的技术问题。通过特定领域的工作流程构建知识库，提高了系统的覆盖率和新颖性。在不同任务类别上的评估表明，RA-FSM在多方面优于已有的笔记本语言模型和基准模型。", "conclusion": "RA-FSM系统设计强调透明且引证充分的高质量答案，适用于高风险的技术工作，并具有向其他科学领域推广的潜力。该系统能探索超越笔记本语言模型的更多领域知识，但同时会在延迟和成本方面产生一定的可调节开销。"}
{"llm_update_time": "20251006", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.02328", "html_url": "https://arxiv.org/abs/2510.02328", "title": "AMANDA: Agentic Medical Knowledge Augmentation for Data-Efficient Medical Visual Question Answering", "title_en": "AMANDA: Agentic Medical Knowledge Augmentation for Data-Efficient Medical Visual Question Answering", "authors": "Ziqing Wang,Chengsheng Mao,Xiaole Wen,Yuan Luo,Kaize Ding", "background": "Med-MLLMs在医学视觉问答任务（Med-VQA）中表现出巨大的潜力，但在资源匮乏的环境中，由于医学推理能力的瓶颈，现有Med-MLLMs往往无法充分发挥作用。具体来说，这些瓶颈包括：（i）内在推理瓶颈，忽视了医学图像的细节；（ii）外在推理瓶颈，无法有效结合专业知识。", "innovation": "提出了一种无需训练的代理式框架AMANDA，通过LLM代理增强医学知识。具体来说，内在医学知识增强集中在从粗到细的问题分解，以进行全面诊断；外在医学知识增强则通过生物医学知识图谱检索，实现推理过程的定位。", "conclusion": "在八个Med-VQA基准测试中的广泛实验表明，在零样本和少样本Med-VQA设置中，AMANDA均取得了显著的进步。相关代码可在以下链接获取：this https URL."}
{"llm_update_time": "20251006", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.02331", "html_url": "https://arxiv.org/abs/2510.02331", "title": "合成对话生成用于交互式对话启发与推荐（ICER）", "title_en": "Synthetic Dialogue Generation for Interactive Conversational Elicitation & Recommendation (ICER)", "authors": "Moonkyung Ryu,Chih-Wei Hsu,Yinlam Chow,Mohammad Ghavamzadeh,Craig Boutilier", "background": "语言模型（LMs）在对话型推荐系统（CRSs）方面具有巨大潜力，但由于缺乏公开的CRS数据，使得对LMs进行CRSs的微调变得困难。为应对这一挑战，LMs作为用户模拟器可以作为数据生成器来训练LM-based CRSs，但这些模型常常缺乏行为一致性，生成的会话序列与真实用户的会话轨迹不一致。", "innovation": "本文提出了一种生成与用户潜在状态一致的自然对话的方法，结合行为模拟器与LM提示。通过这种方法，生成了一个包含偏好引导和示例批评的大规模开源CRS数据集。这些对话在评估者评价中显示出很高的连贯性、真实性和自然性。", "conclusion": "该研究通过行为模拟器与LM提示结合的方法，生成了大量与用户真实状态一致的对话数据，有助于更有效的训练对话推荐系统。这些对话数据在实际应用中具有很好的评价效果，展现了显著的自然性和真实性。"}
{"llm_update_time": "20251006", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.02330", "html_url": "https://arxiv.org/abs/2510.02330", "title": "EntropyLong：基于预测不确定性实现有效的长上下文训练", "title_en": "EntropyLong: Effective Long-Context Training via Predictive Uncertainty", "authors": "Junlong Jia,Ziyang Chen,Xing Wu,Chaochen Gao,Zijia Lin,Debing Zhang,Songlin Hu,Binghui Guo", "background": "训练能够捕获长距离依赖性的大型语言模型需要特别的数据构建。当前方法，如通用文本连接或基于启发式的变体，经常无法保证真正存在长距离依赖。因此，研究者需要一种新方法来验证依赖的质量。", "innovation": "提出了EntropyLong，一种利用预测不确定性来验证依赖性的新型数据构建方法。该方法通过在文档中识别高熵位置，从大型语料库中检索语义相关的上下文，并通过评估这些上下文是否降低预测熵来验证其实用性。这种方法确保了每个依赖能够代表可测量的信息增益而非虚假相关。通过结合原始文档与验证过的语境补充，构建了具有验证依赖的训练样例。利用FineWebEdu和Cosmopedia生成了128K长度序列的数据集，并在RULER基准测试中显示了显著的改进，特别是在需要远程信息的任务中。", "conclusion": "该研究还展示了在指令微调后的模型在LongBenchv2上的重大收益，证明了增强的长上下文理解。进一步的消融研究表明，基于熵的验证对于长期训练是必要的和有效的。"}
{"llm_update_time": "20251006", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.02332", "html_url": "https://arxiv.org/abs/2510.02332", "title": "一种用于神经语言隐写术的高容量和安全消歧算法", "title_en": "A High-Capacity and Secure Disambiguation Algorithm for Neural Linguistic Steganography", "authors": "Yapei Feng,Feng Jiang,Shanhao Wu,Hua Zhong", "background": "神经语言隐写术的目标是在自然文本中嵌入信息，同时保持统计上的不可检测性。这一领域面临的根本性挑战源于现代分词器的分词歧义性，可能会导致灾难性的解码失败。最近的方法SyncPool通过在一组可能的模糊候选词上引入粗粒度同步机制来解决这一歧义性，但同时也牺牲了嵌入容量，因为它仅利用了模糊候选组的全部香农熵来进行同步，而不是进行有效负载嵌入。", "innovation": "本研究提出了一种名为look-ahead Sync的方法，克服了SyncPool的容量限制，同时保持其可证明的安全性保证。该方法仅在真正不可区分的标记序列上进行最小的同步采样，同时保留所有其他可区分的路径以为嵌入容量最大化。本研究提供了对方法安全性的理论证明，并分析了其可实现的嵌入容量与理论上限之间的差距。实验结果表明，本方法在英语（使用Llama 3）和中文（使用Qwen 2.5）基准上能够达到理论容量上限，并显著优于SyncPool。在英语中，嵌入率提升超过160%，在中文中提升25%，特别是在更大的候选池设置中。", "conclusion": "本研究代表了朝着实现实用高容量可证明安全的语言隐写术的一大步。"}
{"llm_update_time": "20251006", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.02333", "html_url": "https://arxiv.org/abs/2510.02333", "title": "人类移动数据集富含语境和社会维度", "title_en": "Human Mobility Datasets Enriched With Contextual and Social Dimensions", "authors": "Chiara Pugliese,Francesco Lettich,Guido Rocchietti,Chiara Renso,Fabio Pinelli", "background": "本文探讨了公开可用的、具有语义增强的人类轨迹数据集以及构建这些数据集的管道。这些数据集包括来自OpenStreetMap的GPS轨迹以及上下文层，如停顿、移动、兴趣点（POIs）、推断的交通模式和天气数据。这些数据集对于语义分析和FAIR数据实践提供了支持，覆盖了结构上不同的两大城市：巴黎和纽约。", "innovation": "本文的创新点在于通过大型语言模型（LLMs）生成了合成的实际社会媒体帖子，这些帖子被纳入语义特征中，使得移动分析可以实现多模态和语义分析。数据集以表格形式和Resource Description Framework (RDF)格式提供，支持语义推理和FAIR数据实践。此外，提供的开源可重复使用管道允许对数据集进行定制，支持行为建模、移动预测、知识图谱构建和基于LLM的应用。", "conclusion": "据我们所知，我们的资源是首个结合真实移动性、结构化的语义增强、LLM生成的文本和语义网络兼容性的可重复利用框架。这一资源为研究任务提供了支持，例如行为建模、移动预测、知识图谱构建和基于LLM的应用。"}
{"llm_update_time": "20251006", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.02335", "html_url": "https://arxiv.org/abs/2510.02335", "title": "FormalML：机器学习理论中形式子目标完成的基准评价", "title_en": "FormalML: A Benchmark for Evaluating Formal Subgoal Completion in Machine Learning Theory", "authors": "Xiao-Wen Yang,Zihao Zhang,Jianuo Cao,Zhi Zhou,Zenan Li,Lan-Zhe Guo,Yuan Yao,Taolue Chen,Yu-Feng Li,Xiaoxing Ma", "background": "大型语言模型（LLMs）在形式定理证明方面取得了显著进展，但在作为数学家实践助手的角色，即在复杂证明中填补缺失步骤方面仍鲜有探索。作者将这一挑战定义为子目标完成任务，其中LLM需要完成人类提供的概述中未解决的简短但非平凡的证明义务。为了研究这一问题，作者创建了FormalML基准测试，该基准测试基于机器学习的基础理论构建，并利用一种将过程证明转换为声明性形式的推理技术，提取了涵盖优化和概率不等式的4937个问题，难度各异。FormalML是第一个结合前提检索和复杂研究级上下文的子目标完成基准测试。", "innovation": "作者开发了FormalML基准测试，它是第一次将前提检索和复杂研究级别上下文结合起来的子目标完成基准测试。使用翻译技术将过程证明转换为声明性形式，从而提取了涵盖优化和概率不等式的4937个问题。作者评估了最先进的证明器，揭示了准确性和效率方面的持续限制，强调了需要更强大的基于LLM的定理证明器来进行有效的子目标完成。", "conclusion": "最先进的证明器在准确性和效率方面仍存在持续限制，表明需要更强大的基于LLM的定理证明器来有效完成子目标。FormalML是一个重要的基准测试工具，可以用来进一步研究和改进这个领域的方法和技术。"}
{"llm_update_time": "20251006", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.02338", "html_url": "https://arxiv.org/abs/2510.02338", "title": "基于索赔奖励的长文本临床文档生成优化", "title_en": "Optimizing Long-Form Clinical Text Generation with Claim-Based Rewards", "authors": "Samyak Jhaveri,Praphul Singh,Jangwon Kim,Tara Taghavi,Krishnaram Kenthapadi", "background": "自动化临床文档生成需要与完整性及事实性等优先事项高度契合。本文提出了结合组相对策略优化（GRPO）与Doclens（一种基于索赔级别的评估器）的评估集成强化学习框架，用于长形式临床文本生成。该方法直接优化事实性和完整性，不依赖于训练独立奖励模型或人类撰写的参考文献.", "innovation": "利用GRPO和Doclens，该方法能够直接优化事实性和完整性，同时减少训练成本。通过简单的奖励门控策略提高了临床笔记的质量。独立的GPT-5定性评估进一步支持了这些改进，显示了更高的事实性、完整性和简洁性偏好，且内容更少有遗漏和妄想。因为基准测试相对清洁且基础模型已经很好地对齐，这些改进可能代表了一个保守的下限。该框架可以扩展到实际应用场景中，并能纳入自定义目标如指南遵循或收费偏好.", "conclusion": "该框架能够在相对清洁的基准和预对齐的基础模型上实现改进，具有实用性和灵活性，并展示了在实际应用场景中的潜力。"}
{"llm_update_time": "20251006", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.02334", "html_url": "https://arxiv.org/abs/2510.02334", "title": "何以至此？通过表示梯度追踪归因不良LLM行为", "title_en": "Where Did It Go Wrong? Attributing Undesirable LLM Behaviors via Representation Gradient Tracing", "authors": "Zhe Li,Wei Zhao,Yige Li,Jun Sun", "background": "大型语言模型（LLMs）展现了非凡的能力，但在实际部署中，由于生成有害内容、事实错误和社会偏见等问题，常常受到负面影响。诊断这些失败的根本原因对于AI安全是一个至关重要的挑战。现有的归因方法，尤其是基于参数梯度的方法，常常因噪声大和计算复杂而效果不佳。因此，引入一种新颖且高效的框架来通过分析表示及其梯度来诊断各种不良行为是必要的。这种方法直接在模型的激活空间中工作，提供连接输出与训练数据的具有语义意义的信号。", "innovation": "本文提出了一种新的框架，通过分析模型表示及其梯度来诊断各种不良行为，并能够直接在模型激活空间中进行操作，提供具有语义意义的信号，有助于将输出与训练数据联系起来。该方法不仅在样本级归因方面表现出色，还能够在标记级进行精细分析，精确识别出具体影响模型行为的样本和短语。这为理解和审计LLM的风险提供了一个强大的诊断工具。", "conclusion": "本文提出了一种新颖的框架，通过表示梯度追踪来诊断不良的语言模型行为，并且能够进行样本级别和标记级别的精细分析，有效识别影响模型行为的具体样本和短语。该工作为理解、审计和降低LLM的风险提供了一种强有力的工具，并附有可下载的代码。"}
{"llm_update_time": "20251006", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.02339", "html_url": "https://arxiv.org/abs/2510.02339", "title": "评估论辩大型语言模型中的不确定性量化方法", "title_en": "Evaluating Uncertainty Quantification Methods in Argumentative Large Language Models", "authors": "Kevin Zhou,Adam Dejl,Gabriel Freedman,Lihu Chen,Antonio Rago,Francesca Toni", "background": "大型语言模型（LLMs）的不确定性量化（UQ）研究越来越重要，这对于保证这项革命性技术的可靠性至关重要。本研究探讨了将UQ方法集成到论辩大型语言模型（ArgLLMs）中，论辩大型语言模型是一种基于计算论辩的可解释性模型框架，在此基础上UQ扮演着关键角色。研究通过实验证明了ArgLLMs在论点验证任务中的表现，并评估了不同的UQ方法的有效性。这是首次在复杂的、潜在有争议的陈述存在时，从实验程序本身评估UQ方法的有效性。", "innovation": "本文创新性地提出了通过实验程序来评估不确定性量化方法的有效性，特别是在包含复杂和可能有争议的陈述时。研究发现，尽管直接提示策略相对简单，但在论辩大型语言模型中也是一种有效的不确定性量化策略，优于更复杂的替代方法。", "conclusion": "研究表明，直接提示策略在论辩大型语言模型中是有效的不确定性量化策略，并且在论点验证任务中表现出色，优于更加复杂的方法。此外，本研究提供了一种新颖的方法来评估不确定性量化方法的有效性。"}
{"llm_update_time": "20251006", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.02336", "html_url": "https://arxiv.org/abs/2510.02336", "title": "KurdSTS: 肯迪斯坦斯语义文本相似度", "title_en": "KurdSTS: The Kurdish Semantic Textual Similarity", "authors": "Abdulhady Abas Abdullah,Hadi Veisi,Hussein M. Al", "background": "语义文本相似度（STS）衡量两个文本之间意义的重叠程度，在许多NLP任务中起到关键作用。现有的STS资源主要集中在高资源语言上，而低资源语言，如库尔德语，却相对不受关注。为了填补这一空白，本文介绍了一个库尔德语STS数据集，包含10,000个涵盖正式和非正式注册的句子对，每个句子对都进行了相似性的标注。这些数据为库尔德语的语义研究以及低资源NLP的发展提供了基础。", "innovation": "本文首次提出了库尔德语STS数据集，包含10,000个句子对，覆盖了正式和非正式语言，每个句子都进行了相似性的标注。此外，本文还基准测试了包括Sentence-BERT和多种其他强基线模型，评估了其在库尔德语中的性能，特别关注库尔德语形态学、拼写变化和混合语言带来的挑战。该数据集和基线模型为未来库尔德语语义研究和低资源NLP提供了可视化和可重复的评估框架。", "conclusion": "本文构建了一个库尔德语STS数据集，并基准测试了多个模型以评估其性能。该研究为库尔德语的语义研究提供了重要的数据基础，并为低资源NLP领域的发展指明了方向。未来研究人员可以利用该数据集进行进一步的研究和模型改进，以解决库尔德语特有的挑战。"}
{"llm_update_time": "20251006", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.02329", "html_url": "https://arxiv.org/abs/2510.02329", "title": "SelfJudge：通过自我监督裁判验证实现更快的投机解码", "title_en": "SelfJudge: Faster Speculative Decoding via Self-Supervised Judge Verification", "authors": "Kanghoon Yoon,Minsub Kim,Sungjae Lee,Joonhyung Lee,Sunghyeon Woo,Yeonjun In,Se Jung Kwon,Chanyoung Park,Dongsoo Lee", "background": "投机解码通过验证草案模型产生的候选标记与目标模型进行对比来加速大语言模型（LLM）的推理过程。最近的评判性解码通过放宽验证标准来接受草案模型可能会与目标模型输出有轻微差异的标记，但现有方法受限于必须依赖人类注释或具有可验证的基准任务，从而限制了其在各种自然语言处理任务中的广泛应用。", "innovation": "我们提出了SelfJudge，该方法通过目标模型自我监督的方式训练裁判验证器。它通过评估标记替换后的响应是否保留了原始响应的意义来衡量语义保真度，这使得裁判验证器能够在各种自然语言处理任务中实现自动训练。", "conclusion": "我们的实验表明，与现有技术基线相比，SelfJudge实现了更好的推理准确性和效率的权衡，提供了一种更广泛适用于更快LLM推理的解决方案。"}
{"llm_update_time": "20251006", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.02337", "html_url": "https://arxiv.org/abs/2510.02337", "title": "CRACQ：一种多维度的自动化文档评估方法", "title_en": "CRACQ: A Multi-Dimensional Approach To Automated Document Assessment", "authors": "Ishak Soltani,Francisco Belo,Bernardo Tavares", "background": "本文介绍了CRACQ，这是一种多维度的评估框架，旨在对文档在五个特定特性：连贯性、严谨性、适当性、完整性、质量上进行评估。基于基于特征的方法自动化作文评分(包括自动化机器生成文本评估)，CRACQ提供了基于评判标准且可解释的方法。不同于单一评分的方法，CRACQ将语言、语义和结构信号综合评估，支持整体和特性级别的分析。本模型在500个合成研究提案上进行了训练，并与强大的LLM（类教师的）和较弱的实际应用进行了基准测试。初步结果表明，CRACQ在特性级别的判断上比直接的LLM评估更稳定和可解释，但可靠性及应用领域范围等方面的挑战依然存在。", "innovation": "CRACQ还融合了语言、语义和结构信号等多种评估指标，是一种基于评判标准的且可解释的自动化评估方法，适用于多种类型的机器生成文本。相比单一得分的方法，CRACQ提供了更全面和细致的评估结果。它特别针对不同领域的文档，进行多维度的综合评估，以获得更稳定和可解释的评估结果。", "conclusion": "尽管初步结果显示CRACQ在特性级别的判断上更胜一筹，但其仍面临着可靠性和应用范围等方面的挑战。CRACQ提供了一种新的评估框架，以帮助更好地理解机器生成文本的质量和特性。"}
{"llm_update_time": "20251006", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.02341", "html_url": "https://arxiv.org/abs/2510.02341", "title": "DRIFT: 从真实世界中丰富的用户不满意信号中学习", "title_en": "DRIFT: Learning from Abundant User Dissatisfaction in Real-World Preference Learning", "authors": "Yifan Wang,Bolian Li,Junlin Wu,Zhaoxuan Tan,Zheli Liu,Ruqi Zhang,Ananth Grama,Qingkai Zeng", "background": "大规模语言模型（如对话AI系统、代码生成助手）在用户迭代以获得更好答案的过程中自然会产生大量的隐性用户不满意信号（DSAT），而显性的满意度（SAT）反馈却很少。现有的偏好学习方法与这种数据特征不太匹配，因为它们依赖昂贵的人工标注或者假设有大量的积极回应。这项工作中，作者发现了这一问题，为了改进现有的方法适应这种特性，提出了DRIFT模型（Dissatisfaction-Refined Iterative Preference Training），该模型基于真实世界的DSAT信号进行训练，并动态采样积极反馈。", "innovation": "DRIFT模型通过锚定真实世界的DSAT信号并动态采样积极反馈来训练模型，不同于现有的依赖昂贵的人工标注或假设许多正反馈的数据采集方法。DRIFT在WildBench任务评分和AlpacaEval2获胜率上都超过基线模型，特别是在更大的模型规模上，DRIFT的方法表现尤为突出。此外，DRIFT保持了探索能力，生成了更多样化的高奖励解决方案，而不是收敛到狭窄的子集中。通过理论证明了DRIFT模型设计能够保留偏好边缘并避免梯度退化，在真实世界场景的后训练中有广泛应用前景。", "conclusion": "DRIFT通过利用最丰富和最有信息性的用户不满意信号，为实际应用提供了有效且可扩展的方法。这一方法在多种基准测试中展示了其优势，证明了其在实际场景下后训练中的应用潜力。"}
{"llm_update_time": "20251006", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.02345", "html_url": "https://arxiv.org/abs/2510.02345", "title": "打破MoE语言模型的三难困境：基于结构压缩的动态专家聚类", "title_en": "Breaking the MoE LLM Trilemma: Dynamic Expert Clustering with Structured Compression", "authors": "Peijun Zhu,Ning Yang,Jiayu Wei,Jinghang Wu,Haijun Zhang", "background": "混合专家（MoE）大规模语言模型面临负载不平衡、参数冗余和通信开销三大问题。本文提出了一种基于动态专家聚类和结构化压缩的统一框架，旨在综合解决这些问题。文章指出，这是首次利用路由器的语义嵌入能力，在训练过程中动态重构模型架构，从而获得显着的效率提升。", "innovation": "本文提出了一种基于动态专家聚类和结构化压缩的统一框架。具体创新包括：（1）提出了一种基于参数和激活相似性的融合度量的在线聚类过程，该过程定期重新分组专家，以稳定专家利用；（2）利用路由器的语义嵌入能力，动态重构模型架构，以实现实质性的效率提升；（3）在每个聚类内，将专家权重分解为共享基矩阵和极低秩残差适配器，从而实现每个组最多五倍的参数减少，同时保持专一性；（4）采用异质精度方案，将共享基存储在FP16中，残差因子存储在INT4中，并动态卸载无用聚类，从而降低峰值内存消耗至与密集模型相当的水平。", "conclusion": "实验结果表明，该框架在GLUE和WikiText-103上与标准MoE模型相匹配，总参数减少了约80%，吞吐量提高了10%到20%，并将专家负载差异降低了超过三倍。文章表明，结构性重组是实现可扩展、高效和内存节省的MoE LLM的有原则路径。"}
{"llm_update_time": "20251006", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.02350", "html_url": "https://arxiv.org/abs/2510.02350", "title": "LLMSQL: 为LLM时代升级的Text-to-SQL基准", "title_en": "LLMSQL: Upgrading WikiSQL for the LLM Era of Text-to-SQL", "authors": "Dzmitry Pihulski,Karol Charchut,Viktoria Novogrodskaia,Jan Kocoń", "background": "自然语言转换为SQL查询（Text-to-SQL）使非专家用户能够与关系数据库进行交互，一直是数据自然语言接口的核心任务。尽管WikiSQL数据集在早期的自然语言到SQL研究中发挥了关键作用，但由于结构和标注问题，如大小写不一致、数据类型不匹配、语法错误和未回答的问题，其使用已经开始下降。因此，需要一种新的标准数据集，能够适应现代语言模型的需求。", "innovation": "LLMSQL是一个系统地修订和转换WikiSQL的数据集，旨在适应LLM时代。它对原始错误进行了分类，并实现了自动化清理和重新标注的方法。与其他专为指针网络模型选择输入词汇构建的数据集不同，LLMSQL提供了干净的自然语言问题和完整的SQL查询作为纯文本，以方便现代自然语言到SQL模型的生成和评估。", "conclusion": "研究人员使用多种大型语言模型（LLM，如Gemma 3、LLaMA 3.2、Mistral 7B等）评估了这些改进的影响。LLMSQL被引入为一个LLM就绪的基准测试，它更符合现代自然语言到SQL模型的需求，为开发和验证该领域的技术提供支持。"}
{"llm_update_time": "20251006", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.02348", "html_url": "https://arxiv.org/abs/2510.02348", "title": "mini-vec2vec：利用线性变换扩展通用几何对齐的缩放能力", "title_en": "mini-vec2vec: Scaling Universal Geometry Alignment with Linear Transformations", "authors": "Guy Dar", "background": "该论文的主题是文本嵌入空间的对齐技术。已经存在的一种方法，称为vec2vec，用于在没有平行数据的情况下对齐文本嵌入空间。vec2vec能够实现近乎完美的对齐，但其代价是计算成本高昂且不稳定。现有的方法需要昂贵的计算资源并且没有足够的稳健性来适应广泛的应用场景。因此，研究者们寻求一种更简单、更经济且更稳健的方法来解决这一问题，该方法由三个主要阶段组成：初步匹配伪平行嵌入向量、变换拟合和迭代优化。", "innovation": "该研究提出了mini-vec2vec，这是一种基于线性变换的对齐方法，相比vec2vec方法，mini-vec2vec在计算成本上大幅度降低，并且表现出更高的稳定性和可解释性。mini-vec2vec可以在不牺牲对齐效果的基础上，实现计算效率的显著提高。这种方法使得对齐算法能够更广泛地应用于不同的领域和场景。", "conclusion": "mini-vec2vec展示了无论是在效率还是稳定性方面都显著超过了原始的vec2vec方法。它的线性特性不仅保证了结果的可解释性，还使其成为一个更易于扩展和应用于新领域的工具。"}
{"llm_update_time": "20251006", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.02340", "html_url": "https://arxiv.org/abs/2510.02340", "title": "Can Prompts Rewind Time for LLMs? Evaluating the Effectiveness of Prompted Knowledge Cutoffs", "title_en": "Can Prompts Rewind Time for LLMs? Evaluating the Effectiveness of Prompted Knowledge Cutoffs", "authors": "Xin Gao,Ruiyi Zhang,Daniel Du,Saurabh Mahindre,Sai Ashish Somayajula,Pengtao Xie", "background": "大语言模型（LLMs）在时间预测中得到了广泛的应用，但它们依赖预训练数据进行训练，这导致了污染问题的担忧。准确的预测可能反映出模型的记忆能力而不是推理能力，这可能导致夸大了它们的泛化能力。近年来，以提示为基础的遗忘技术的出现引发了这样的问题：是否可以提示LLMs模拟早期的知识截止点？为了研究这个问题，作者构建了三个评估数据集，评估LLMs在不同程度上的遗忘能力，包括直接事实知识、语义转变和因果相关知识。", "innovation": "该研究利用提示技术，探讨了是否能够模拟LLMs早期的知识截止点。通过构建专门的评估数据集，研究团队评估了LLMs在遗忘特定类型知识方面的效果。这项研究创新之处在于它提供了新的方法来测试LLMs在处理因果相关知识时的记忆特性，从而提出了更严格的评估方案来应用LLMs于时间预测任务。", "conclusion": "研究结果显示，基于提示的知识截止点在直接查询时显示出一定的有效性，但在被遗忘的内容与查询有一定因果关系但并未被直接询问时，难以引起遗忘。这表明在应用LLMs进行时间预测任务时，需要更严格的评估方式来确保模型的真实泛化能力。研究团队还公开了完整数据集和评估代码。"}
{"llm_update_time": "20251006", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.02343", "html_url": "https://arxiv.org/abs/2510.02343", "title": "BluePrint: 社交媒体用户数据集，用于LLM人物评估与训练", "title_en": "$\\texttt{BluePrint}$: A Social Media User Dataset for LLM Persona Evaluation and Training", "authors": "Aurélien Bück-Kaeffer,Je Qin Chooi,Dan Zhao,Maximilian Puelma Touzel,Kellin Pelrine,Jean-François Godbout,Reihaneh Rabbany,Zachary Yang", "background": "大型语言模型（LLMs）能够模拟社交媒体动态，但缺乏标准化的数据资源来微调和评估LLMs作为现实的社交媒体代理。这给研究带来了伦理和操作上的挑战。为此，本文提出了一种名为SIMPACT的新框架，旨在创建适合训练代理模型的行为导向社交媒体数据集。SIMPACT框架注重隐私保护，通过行为建模支持训练具有上下文依赖性的代理模型。", "innovation": "提出了SIMPACT框架，包括一个称为BluePrint的大规模数据集，从公共Bluesky数据中构建，专注于政治理论讨论。BluePrint数据集将匿名用户聚类为行为聚类，并利用伪名化和去除个人可识别信息来保护隐私。SIMPACT引入了同时评估行为忠实度和风格真实性的度量方法，并且通过标准数据和评估协议，为先进的、负责任的社交媒体模拟奠定了基础。", "conclusion": "SIMPACT提供了一个平台，加速了对LLMs的伦理和社会媒体模拟的研究。BluePrint不仅为政治话语建模提供了评估基准，还为特定领域数据集的构建提供了模板，有助于研究信息误导和极化等问题。"}
{"llm_update_time": "20251006", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.02353", "html_url": "https://arxiv.org/abs/2510.02353", "title": "使用LLM增强的知识图谱结构化塞内加尔法律文本", "title_en": "An Senegalese Legal Texts Structuration Using LLM-augmented Knowledge Graph", "authors": "Oumar Kane,Mouhamad M. Allaya,Dame Samb,Mamadou Bousso", "background": "本文档探讨了在塞内加尔司法系统中利用人工智能（AI）和大语言模型（LLM）改进法律文本访问的问题。强调了提取和组织法律文件的困难，并突显了对更好地获取司法信息的需求。", "innovation": "该研究成功提取了来自各种法律文件的7,967篇文章，特别是注重土地和公共领域法。开发了一个包含2,872个节点和10,774个关系的详细图形数据库，以帮助可视化法律文本之间的关联。此外，使用了高级三元组提取技术，展示了GPT-4o、GPT-4和Mistral-Large等模型在识别关系和相关元数据方面的有效性。", "conclusion": "通过这些技术和模型，旨在建立一个坚实的基础框架，使塞内加尔公民和法律专业人士能够更有效地理解和行使他们的权利和责任。"}
{"llm_update_time": "20251006", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.02359", "html_url": "https://arxiv.org/abs/2510.02359", "title": "Emission-GPT：专门领域语言模型代理，用于知识检索，排放清单和数据分析", "title_en": "Emission-GPT: A domain-specific language model agent for knowledge retrieval, emission inventory and data analysis", "authors": "Jiashu Ye,Tong Wu,Weiwen Chen,Hao Zhang,Zeteng Lin,Xingxing Li,Shujuan Weng,Manni Zhu,Xin Yuan,Xinlong Hong,Jingjie Li,Junyu Zheng,Zhijiong Huang,Jing Tang", "background": "理解和分析空气污染物和温室气体排放对于改善空气质量与应对气候变化至关重要。然而，排放相关知识通常是碎片化的、专业化的，并且现有的获取和汇总排放数据的方法效率低下，这限制了非专业人士解读排放信息的能力，给研究和管理工作带来了挑战。", "innovation": "Emission-GPT是一个基于超过10,000份文献（包括标准、报告、指南和同行评审文献）的数据包汇编而成的知识增强型大型语言模型代理。它通过提示工程和问题完成功能，支持精确的领域特定问题回答，并允许用户通过自然语言互动分析排放数据，如查询和可视化清单、分析来源贡献以及为用户定义的场景推荐排放因子。案例研究展示了Emission-GPT可以直接从原始数据中通过简单提示提取关键见解。", "conclusion": "Emission-GPT的模块化和可扩展架构可以自动处理传统的手动流程，使其成为下一代排放清单开发和基于情景评估的基础工具。"}
{"llm_update_time": "20251006", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.02358", "html_url": "https://arxiv.org/abs/2510.02358", "title": "DiffuSpec: 解锁扩散语言模型在推测性解码中的应用", "title_en": "DiffuSpec: Unlocking Diffusion Language Models for Speculative Decoding", "authors": "Guanghao Li,Zhihui Fu,Min Fang,Qibin Zhao,Ming Tang,Chun Yuan,Jun Wang", "background": "随着大型语言模型（LLMs）的规模增加，准确度有所提高，但自回归（AR）解码的特性导致了延迟的增加，因为每个令牌都需要顺序的前向传递。推测性解码通过使用快速草稿编辑器提出多令牌草稿来缓解这一问题，这些草稿然后由目标模型并行验证。然而，许多部署仍然依赖于自回归草稿编辑器，这种顺序传递限制了墙钟时间的改善。本文重新审视了草稿编辑阶段，提出了一个无需训练、可插入的框架DiffuSpec，利用预训练的扩散语言模型（DLM）在单次前向传递中生成多令牌草稿，同时与标准AR验证器保持兼容。", "innovation": "DiffuSpec 训练无需，是一个可直接插入的框架，利用预训练的扩散语言模型（DLM）在单次前向传递中生成多令牌草稿，同时与标准AR验证器保持兼容。基于双向条件生成的DLM草稿在并行位置候选中形成令牌网络，在每个位置上生成的高概率令牌不一定形成因果左到右路径。DLM草稿生成需要预先确定草稿长度，这引入了速度和质量之间的权衡。", "conclusion": "DiffuSpec 在基准测试中实现了最多3倍的墙钟速度提升，确立了基于扩散的草稿生成作为自回归草稿生成的稳健替代方案，用于推测性解码。"}
{"llm_update_time": "20251006", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.02362", "html_url": "https://arxiv.org/abs/2510.02362", "title": "使用罗马尼亚历史进行跨语言偏见分析的大语言模型研究", "title_en": "A Cross-Lingual Analysis of Bias in Large Language Models Using Romanian History", "authors": "Matei-Iulian Cocu,Răzvan-Cosmin Cristia,Adrian Marius Dumitran", "background": "本文以一组具有争议的罗马尼亚历史问题为研究对象，使用多种大型语言模型（LLM）进行跨语言和跨语境的回答，以评估其偏见。研究认识到，由于历史常常通过特定的文化和国家的理想视角来呈现，即使在大型语言模型中也是如此，因此历史观点的表述往往不具中立性。这些模型可能根据其训练数据集中的某些细微差异来形成态度，并传递给用户。本文共分三个阶段进行研究，主要是为了验证不同形式的答案要求可能会影响模型的回答方式；进一步观察，当给模型相同问题再次作答但需要给出数值等级时，模型的回答方式也可能会改变。通过这些研究，发现二元答案的稳定性相对较高但并不完美，并且在不同语言之间存在波动。", "innovation": "本文采用了一种新的研究方法，通过将多个大型语言模型应用于一组具有争议性的罗马尼亚历史问题，从而获得了它们对于不同语言和问题形式的回答表现，探索了这些模型在历史问题上的偏见稳定性，并发现了不同模型在不同语境和答案形式下的响应差异。", "conclusion": "研究结果表明，大型语言模型在回答涉及历史问题时表现出一定的偏见倾向，这些偏见可能源于使用的训练数据集。二元回答的稳定性虽然相对高，但不完美，且在不同语言和回答格式之间存在差异。数值评分经常与初始的二元选择存在差异，最一致的模型也不总是被认为是最准确或中立的。研究还揭示了模型在特定语言背景下的这种不一致性倾向。"}
{"llm_update_time": "20251006", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.02347", "html_url": "https://arxiv.org/abs/2510.02347", "title": "小型语言模型用于课程指导", "title_en": "Small Language Models for Curriculum-based Guidance", "authors": "Konstantinos Katharakis,Sippo Rossi,Raghava Rao Mukkamala", "background": "当前，生成式人工智能（AI）和大型语言模型（LLMs）在教育领域的应用仍处于起步阶段。本研究旨在探索并评估使用检索增强生成（RAG）框架结合小型语言模型（SLMs）来提供基于课程指导的AI助教的方法。研究对包括LLaMA 3.1、IBM Granite 3.3和Gemma 3在内的八种小型语言模型进行了基准测试，与GPT-4o进行对比，以确定小型语言模型在生成准确且符合教育目标的反馈方面的表现。小型语言模型因其较低的计算和能源需求，能够在消费级硬件上实现实时使用，而不依赖于云基础设施，这使得它们不仅在成本效益、数据隐私保护方面具有优势，还对环境负责，为愿意采用可持续和能效方式规模化个性化学习的教育机构提供了可行的AI助教解决方案。", "innovation": "研究采用了检索增强生成（RAG）框架来改进小型语言模型（SLMs）的性能，并将这些模型应用于教育领域，提供了基于课程的指导。研究发现，在适当的提示和针对性检索的支持下，小型语言模型能够与大型语言模型（LLMs）一样提供准确且符合教育目标的反馈。此外，通过减少对云计算基础设施的依赖，这些小型语言模型以消费级硬件实现实时使用，展示了它们在成本效益、隐私保护方面以及环境可持续性方面的优势，为教育机构提供了可行的、可持续的AI助教解决方案。", "conclusion": "小型语言模型在教育领域的应用显示出巨大的潜力，特别是通过RAG框架的应用，这些模型能够提供准确且符合教育目标的反馈，并且由于其较低的计算和能源需求，它们不仅在经济上更具可持续性，还对环境更加负责。这使得小型语言模型成为教育机构实现个性化学习规模化的实际可行方案。"}
{"llm_update_time": "20251006", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.02375", "html_url": "https://arxiv.org/abs/2510.02375", "title": "使用层次记忆预训练：分离长尾知识与常见知识", "title_en": "Pretraining with hierarchical memories: separating long-tail and common knowledge", "authors": "Hadi Pouransari,David Grangier,C Thomas,Michael Kirchhof,Oncel Tuzel", "background": "现代语言模型的高性能目前依赖于参数的放大：更大的模型存储更多的世界知识并更好地进行推理。然而，将所有世界知识压缩到参数中是不必要的，因为每次提示只使用一部分知识，并且对有限推理时间和计算能力的边缘设备来说是不切实际的。", "innovation": "该研究通过引入一种新的记忆增强架构及与现有硬件范式相匹配的预训练策略，解决了这一局限性。提出的小语言模型能够访问大型分级参数记忆库，这些记忆库编码了大量的世界知识。通过获取小的、上下文相关的记忆块并加到模型中，预训练过程学会在记忆参数中存储长尾世界知识，而小的语言模型则捕捉常见的知识和通用推理能力。", "conclusion": "大规模的实验结果表明，通过添加一个18M参数的记忆块，一个160M参数的小模型可以达到与2x参数的标准模型相当的性能。进一步的研究还确定了不同大小的参数记忆在变压器中的最优配置，并扩展到超过21B参数的大小。研究发现提出的分层前馈记忆在不同的变压器架构中表现稳健，无论是在预训练输入中还是在外部添加时。"}
{"llm_update_time": "20251006", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.02354", "html_url": "https://arxiv.org/abs/2510.02354", "title": "使用与形式无关且丰富化的句子意义表示来建模语言皮层揭示了非凡的意义抽象度", "title_en": "Modeling the language cortex with form-independent and enriched representations of sentence meaning reveals remarkable semantic abstractness", "authors": "Shreya Saha,Shurui Li,Greta Tuckute,Yuanning Li,Ru-Yuan Zhang,Leila Wehbe,Evelina Fedorenko,Meenakshi Khosla", "background": "人类语言系统既表示语言形式也表示意义，但意义表示的具体抽象程度仍存在争议。本文通过使用视觉和语言模型的表示来模拟句子的神经响应，探索语言皮层中的抽象意义表示。研究人员生成与句子对应的图像，并从中提取视觉模型嵌入，发现聚合多个生成的图像可以提高语言皮层响应预测的准确性。此外，对同一句子的多个近义短语进行平均嵌入后，预测准确性也有所提升。进一步丰富近义短语中的上下文细节（例如补充“我吃了 Pancake”中的“枫糖浆”细节），预测准确性也得到进一步提升，甚至超过基于原始句子嵌入的预测。这些结果表明，语言系统维护着比语言模型更丰富和广泛的意义表示。", "innovation": "该研究通过建模神经响应来探索语言皮层中的抽象意义表示，发现聚合多个生成图像和近义短语的平均嵌入可以显著提高预测准确性，甚至超过基于原始句子嵌入的预测。这些发现表明，语言系统能够保留比现有语言模型更为抽象和广泛的语义代表。", "conclusion": "这项研究表明，语言皮层中可能存在高度抽象且与形式无关的意义表示，这些表示比现有的语言模型更为丰富和广泛。"}
{"llm_update_time": "20251006", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.02351", "html_url": "https://arxiv.org/abs/2510.02351", "title": "语言、文化与意识形态：具有推理能力的语言模型在政治推文中个性化检测冒犯性内容", "title_en": "Language, Culture, and Ideology: Personalizing Offensiveness Detection in Political Tweets with Reasoning LLMs", "authors": "Dzmitry Pihulski,Jan Kocoń", "background": "本研究探讨了大型语言模型（LLMs）在被要求采用特定的政治和文化视角时，如何评估政治话语中的冒犯性。研究使用了MD-Agreement数据集中2020年美国大选期间的多语言推文，评估了包括DeepSeek-R1、o4-mini、GPT-4.1-mini、Qwen3、Gemma和Mistral等在内的多种最新LLM，让它们从不同政治人设的角度（极右、保守、中间派、进步）判断推文是否冒犯。研究表明，具有明确推理能力的大型模型（如DeepSeek-R1、o4-mini）在处理意识形态和文化差异时更为一致和敏感，而小型模型往往无法捕捉细微区别。研究发现，推理能力显著提高了冒犯性判断的个性化程度和可解释性，指出此类机制是跨语言和意识形态进行精细社会政治文本分类的关键因素。", "innovation": "本研究通过评估多个最新LLM，揭示了它们在处理政治推文中的冒犯性时的能力差异，特别是强调了具有明确推理能力的大型模型在捕捉意识形态和文化差异方面的优势。研究还指出，推理能力对于提高模型的个性化程度和可解释性至关重要，对跨语言和意识形态的精细社会政治文本分类有着重要影响。", "conclusion": "研究表明，具有明确推理能力的大型模型在理解和评估政治推文中的冒犯性时更为一致和敏感，而小型模型往往无法捕捉细微差异。研究建议，在处理具有特定语言和意识形态背景的政治文本时，应该优先考虑具有较强推理能力的大型模型，以提高冒犯性检测的个性化程度和可解释性。"}
{"llm_update_time": "20251006", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.02361", "html_url": "https://arxiv.org/abs/2510.02361", "title": "ChunkLLM：一种加速大规模语言模型推理的轻量级可插拔框架", "title_en": "ChunkLLM: A Lightweight Pluggable Framework for Accelerating LLMs Inference", "authors": "Haojie Ouyang,Jianwei Lv,Lei Ren,Chen Wei,Xiaojie Wang,Fangxiang Feng", "background": "基于Transformer的大型模型在自然语言处理和计算机视觉方面表现出色，但由于自注意力机制在输入标记上的二次复杂性，面临严重的计算效率问题。最近，研究者提出了基于块选择和压缩的技术来缓解此问题，但这些方法或者存在语义不完整的问题，或者导致训练和推理效率低下。针对这些挑战，本研究提出了一种名为ChunkLLM的轻量级且可插拔训练框架。", "innovation": "提出了一种名为ChunkLLM的轻量级且可插拔训练框架，包含QK Adapter (Q-Adapter和K-Adapter)和Chunk Adapter两种组件。QK Adapter负责特征压缩和块注意力获取，附着于每个Transformer层。Chunk Adapter在模型的最底层工作，通过上下文语义信息检测块边界。在训练阶段，主干模型参数被冻结，仅QK Adapter和Chunk Adapter参与训练。提出了基于注意机制的训练方法来提升关键块的召回率，在推理阶段，只在检测到当前标记为块边界时才触发块选择，加速模型推理。", "conclusion": "在不同长度的基准数据集上进行实验评估，证明ChunkLLM不仅在短文本基准测试中达到与其它模型相当的性能，而且在长上下文基准测试中保持98.64%的性能，同时保留48.58%的关键值缓存率。特别地，ChunkLLM在处理120K长文本时相比原始Transformer取得最大4.48倍的加速效果。"}
{"llm_update_time": "20251006", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.02392", "html_url": "https://arxiv.org/abs/2510.02392", "title": "KnowledgeSmith: 使用模型编辑和遗忘揭示大语言模型的知识更新", "title_en": "KnowledgeSmith: Uncovering Knowledge Updating in LLMs with Model Editing and Unlearning", "authors": "Yinyi Luo,Zhexian Zhou,Hao Chen,Kai Qiu,Marios Savvides,Yixuan Li,Jindong Wang", "background": "大语言模型（LLMs）需要保持知识的时效性，但其知识更新机制尚不明确，现有更新机制评估不足，主要表现为数据量不足、孤立且不全面。通过人类修改知识的方式以及随着训练数据增加编辑和遗忘的区别等问题，现有研究未能系统地理解LLMs知识更新机制。", "innovation": "提出了一个统一框架KnowledgeSmith，将其编辑和遗忘建模为一个受约束的优化问题的实例。设计了自动数据生成器，能够在多个图层和数据规模上提供结构化干预，从而控制不同修改策略如何传遍模型知识的研究。通过大量实验，揭示了知识传播的精细洞察，以及塑性缩放、一致性和鲁棒性之间的关系。研究表明，LLMs对不同知识层次的更新机制不同于人类，并存在一致性和容量之间的权衡。", "conclusion": "希望我们的研究发现可以为设计更可靠和可扩展的策略提供指导。"}
{"llm_update_time": "20251006", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.02394", "html_url": "https://arxiv.org/abs/2510.02394", "title": "基于文本到SQL语义解析的领域知识检索与增强", "title_en": "Retrieval and Augmentation of Domain Knowledge for Text-to-SQL Semantic Parsing", "authors": "Manasi Patwardhan,Ayush Agarwal,Shabbirhussain Bhaisaheb,Aseem Arora,Lovekesh Vig,Sunita Sarawagi", "background": "大型语言模型（LLMs）将自然语言（NL）查询翻译成SQL查询的表现因数据库（DBs）而异。NL查询通常使用特定领域的词汇表达，将其映射到正确的SQL需要理解嵌入的领域表达式以及它们与DB模式结构的关系。现有的基准依赖于不切实际的、为特定查询准备的文本提示来表达领域知识。", "innovation": "本文提出了一种系统的框架，用于在数据库层面关联结构化的领域语句。该框架通过子字符串级别的匹配来检索相关结构化的领域语句，对于用户查询进行评估，并利用五个开源和专有LLM覆盖了五个现实的DB模式和不同领域，展示了（1）数据库级别的结构化领域语句比现有的特定查询的文本领域知识更为实用和准确，以及（2）基于子字符串匹配的检索相关领域语句提供了比其他检索方法显著更高的精度。", "conclusion": "(1) 数据库级别的结构化领域语句在准确性上优于现有特定查询的文本领域陈述；(2) 基于子字符串匹配的领域语句检索方法能提供显著更高的准确性。"}
{"llm_update_time": "20251006", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.02352", "html_url": "https://arxiv.org/abs/2510.02352", "title": "评价语音对话大语言模型中的偏差以支持现实世界中的决策和推荐", "title_en": "Evaluating Bias in Spoken Dialogue LLMs for Real-World Decisions and Recommendations", "authors": "Yihao Wu,Tianrui Wang,Yizhou Peng,Yi-Wen Chao,Xuyi Zhuang,Xinsheng Wang,Shunshun Yin,Ziyang Ma", "background": "尽管大型语言模型（LLMs）中的偏差，如输出中的刻板印象和文化倾向已经得到了研究和识别，但在具有音频输入和输出的语音对话模型（SDMs）中，这些偏差的存在及其特征尚未得到充分探索。副语言特征，例如年龄、性别和口音，可以影响模型的输出；当这些特征出现在多轮对话中，并伴有重复的负面反馈时，它们可能会加剧偏差，对决策和推荐任务中的公平性产生潜在影响。本研究系统地评估了语音大语言模型中的偏差，并研究了多次上下文对话和反复负面反馈的影响。偏差通过决策中的群体不公平性分数（GUS）和推荐中的基于相似性的归一化统计率（SNSR）进行衡量，涵盖如Qwen2.5-Omni和GLM-4-Voice等开源模型以及如GPT-4o Audio和Gemini-2.5-Flash等商业模型。研究表明，商业模型通常表现出较小的偏差，而开源模型对年龄和性别更为敏感，且推荐任务会加剧群体间的差异。我们发现，多轮对话中也可能存在偏见决策。本研究提供了对端到端语音对话模型中的偏差的首个系统性研究，为公平和可靠的音频交互系统提供了洞见。为了推动进一步的研究，我们公开了FairDialogue数据集和评估代码。", "innovation": "本研究首次系统地评估了语音大语言模型中的偏差，引入了评价语音对话模型偏见的方法和指标，并研究表明，商业模型在偏见方面相对较小，而开源模型在处理年龄和性别问题上更为敏感，推荐任务会导致群体间的差异扩大。此外，该研究还关注了多轮对话和重复负面反馈对偏见的影响，并提出了首个涵盖开源和商业模型的数据集和评估代码，以支持进一步研究。", "conclusion": "本研究首次系统地评价了语音大语言模型中的偏见，揭示了闭源模型相较于开源模型具有更低的偏差，开源模型在处理年龄和性别问题上更为敏感，并且推荐任务会加剧群体间的差异。多轮对话中可能存在持续的偏见决策。研究揭示了语音对话模型在现实世界中的决策和推荐中的偏见问题，并提出了首个涵盖多种模型的数据集和评估代码，为构建公平可靠的语音交互系统提供了洞见。"}
{"llm_update_time": "20251006", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.02370", "html_url": "https://arxiv.org/abs/2510.02370", "title": "语言模型中参数化和上下文知识利用的训练动态", "title_en": "Training Dynamics of Parametric and In-Context Knowledge Utilization in Language Models", "authors": "Minsung Kim,Dong-Kyum Kim,Jea Kwon,Nakyeong Yang,Kyomin Jung,Meeyoung Cha", "background": "大型语言模型在推理过程中检索到的上下文知识和预训练中获得的参数知识之间常常存在冲突。接受外部知识的模型容易受到错误信息的影响，而严格按照参数知识运作的模型则无法充分利用检索功能带来的好处。尽管检索增强生成得到了广泛应用，但对于训练过程中如何影响模型的知识仲裁策略，我们仍然缺乏系统性的理解。这可能导致预训练模型出现令人不满意的仲裁行为，并浪费大量计算资源。", "innovation": "本文首次对训练条件如何影响模型的应用参数化和上下文知识及其仲裁策略进行了控制研究。通过在合成传记语料库上训练基于Transformer的语言模型，并系统控制各种条件，研究揭示了事实的重复有助于培养兼具参数化和上下文的能力。同时，包含不一致信息或分布偏移的语料库训练可以鼓励模型发展出有效的策略来利用参数化和上下文知识。研究结果表明，这些非理想特性对于学习稳健的仲裁是重要的，提供了具体的经验指导，帮助训练和谐整合参数化和上下文知识的语言模型。", "conclusion": "研究揭示了重要见解，即不理想的特性对于学习稳健的仲裁是必要的，为创建和谐整合参数化和上下文知识的语言模型提供了实践经验。这有助于指导如何在预训练中优化模型的性能。"}
{"llm_update_time": "20251006", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.02360", "html_url": "https://arxiv.org/abs/2510.02360", "title": "大型语言模型代理中的沉默螺旋现象", "title_en": "Spiral of Silence in Large Language Model Agents", "authors": "Mingze Zhong,Meng Fang,Zijing Shi,Yuxuan Huang,Shunfeng Zheng,Yali Du,Ling Chen,Jun Wang", "background": "沉默螺旋理论认为，持少数观点的个人往往由于害怕社会孤立而选择不发声，从而使多数观点在公共话语中占据主导地位。然而，当代理者是大型语言模型（LLMs）时，这个传统的心里学解释并不完全适用，因为沉默螺旋理论是为人类社会设计的。因此，研究者提出了一个问题：仅凭纯粹的统计语言生成是否能在LLM集体中产生类似沉默螺旋的现象？", "innovation": "作者提出了一种评估LLM代理沉默螺旋现象的框架，并通过四个受控条件系统地改变“历史”和“人物”信号的可用性，发现在历史和人物信号共同作用下能产生显著的多数主导现象，并重现了沉默螺旋模式；单独的历史信号导致较强的锚定效应；单独的人物信号促进多样但不相关的观点，表明没有历史锚定，无法产生沉默螺旋现象。这项工作将计算社会学与负责式人工智能设计联系起来，突显了需要监控和缓解LLM代理系统中出现的遵从性现象的重要性。", "conclusion": "实验证明，历史和人物信号共同作用时会产生强大的多数支配，重现沉默螺旋模式；单独的历史信号导致强烈的锚定效应；单独的人物信号促使多元但无关的意见。研究结果表明，缺乏历史锚定时，沉默螺旋现象无法出现。这项工作填补了计算社会学和负责式人工智能设计之间的空白，强调了需要监控和缓解LLM代理系统中出现的遵从性现象。"}
{"llm_update_time": "20251006", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.02369", "html_url": "https://arxiv.org/abs/2510.02369", "title": "超越手册和任务：强化LLM代理的实例级上下文学习", "title_en": "Beyond Manuals and Tasks: Instance-Level Context Learning for LLM Agents", "authors": "Kuntai Cai,Juncheng Liu,Xianglin Yang,Zhaojie Niu,Xiaokui Xiao,Xing Chen", "background": "传统的大型语言模型（LLM）代理通常接收两种类型的上下文：（i）环境级手册来定义交互界面和全局规则，以及（ii）任务级指导或与特定目标相关联的演示。然而，该论文指出，在复杂任务中，LLM代理常常因为缺乏特定环境实例级别的上下文而失败，这包括可验证且可重用的事实，如物体位置、成品食谱和地方规则。这些事实对于成功至关重要，不仅要推理全局规则或任务提示，还要基于精确且持久的事实作出决策。因此，学术界需要一种能有效探索、验证和格式化实例级上下文的方法。", "innovation": "本文正式提出了实例级上下文学习（ILCL）问题，并设计了一种通用方法来解决它。该方法通过引导探索使用紧凑的TODO森林优先考虑下一步行动，并使用轻量级计划-执行-提取循环来执行任务。通过这种方式，该方法能够自动生成一种可跨多个下游任务和代理重用的高精度上下文文档，从而摊薄初始探索成本。实验表明，该方法在TextWorld、ALFWorld和Crafter等多个场景中均实现了成功率和效率的显著提升。", "conclusion": "通过将一次性探索转化为持久且可重用的知识，该方法能够补充现有的上下文，从而使LLM代理更加可靠和高效。"}
{"llm_update_time": "20251006", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.02463", "html_url": "https://arxiv.org/abs/2510.02463", "title": "CLARITY:临床助理，用于路由、推理和分类", "title_en": "CLARITY: Clinical Assistant for Routing, Inference, and Triage", "authors": "Vladimir Shaposhnikov,Aleksandr Nesterov,Ilia Kopanichuk,Ivan Bakulin,Egor Zhelvakov,Ruslan Abramov,Ekaterina Tsapieva,Dmitry V. Dylov,Ivan Oseledets", "background": "该研究呈现了一个名为CLARITY的AI驱动平台，旨在优化患者与专科之间的转诊流程，增强临床会诊，并评估患者的病情严重程度。该系统采用了混合架构，结合有限状态机（FSM）处理结构化对话流程，以及协作智能代理使用大型语言模型（LLM）分析症状，推荐合适的专科。CLARITY基于模块化的微服务架构，确保安全、高效和强大，能够灵活适应现有医疗流程和IT解决方案。", "innovation": "CLARITY平台的独特之处在于其混合架构，将有限状态机与大型语言模型相结合，前者用于处理结构化对话流程，后者用于症状分析和专科推荐。此外，平台基于模块化的微服务框架，实现了安全、高效和强大的性能，并具备高度的可扩展性，能适应大型医疗机构的需要。", "conclusion": "CLARITY在两个月内的部署中处理了超过55,000个富含内容的用户对话，其中有2,500个对话由专家标注以进行后续验证。验证结果显示，CLARITY在初次转诊准确性方面超过了人类的表现，同时咨询时间相比人类进行了缩短，具体而言，最长时间缩短了三倍。"}
{"llm_update_time": "20251006", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.02377", "html_url": "https://arxiv.org/abs/2510.02377", "title": "在多大型语言模型系统中提高推理能力的含不确定性意识的答案选择方法", "title_en": "Uncertainty-Aware Answer Selection for Improved Reasoning in Multi-LLM Systems", "authors": "Aakriti Agrawal,Rohith Aralikatti,Anirudh Satheesh,Souradip Chakraborty,Amrit Singh Bedi,Furong Huang", "background": "大型语言模型（LLMs）展示了非凡的能力，但在资源受限的环境中，选择最可靠的回复仍然具有挑战性。现有方法通常依赖昂贵的外部验证器、人工评估员或需要单一模型提供多个样本的自一致性技术。尽管多LLM系统产生更多样化的回复，因此具有更大的潜力，但它们的表现通常不及单一LLM的自一致性方法。", "innovation": "本文提出了一种基于校准的对数似然得分的含原理性、新颖且计算高效的多LLM最佳回复选择方法。该方法隐式利用了这些模型的固有知识和信心。该方法在GSM8K、MMLU（6个子集）和ARC数据集的辩论（多轮LLM讨论）和非辩论（多个LLM的最佳选择）设置中，分别取得了大约4%、3%和5%的改进。", "conclusion": "我们的方法展示了在辩论和非辩论设置中的改进，证明了多LLM系统中基于校准的对数似然得分的有效性，从而提高了多LLM系统的推理能力。"}
{"llm_update_time": "20251006", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.02549", "html_url": "https://arxiv.org/abs/2510.02549", "title": "基于知识图谱的RAG系统评价框架", "title_en": "Knowledge-Graph Based RAG System Evaluation Framework", "authors": "Sicheng Dong,Vahid Zolfaghari,Nenad Petrovic,Alois Knoll", "background": "大型语言模型（LLMs）已成为研究的重要焦点，并被应用于多个领域，如文本生成和对话系统。LLMs的一个重要应用是检索增强生成（RAG），它显著提高了生成内容的可靠性和相关性。然而，评估RAG系统仍是一项挑战。传统的评估指标难以有效捕捉现代LLM生成内容的关键特征，这些内容常常表现出高度的流畅性和自然性。", "innovation": "受RAGAS工具的启发，即一个知名的RAG评价框架，作者将其扩展为基于知识图谱的评价范式，以支持多跳推理和语义社区聚类，从而进行更全面的评分指标推测。通过融入这些全面的评价标准，作者获得了对RAG系统的更深入理解，并对其性能有了更细腻的认识。为了验证方法的有效性，作者将其性能与RAGAS分数进行比较，并构建了一个人工注释的子集以评估人工判断与自动化指标之间的相关性。此外，作者还进行了有针对性的实验，展示了基于知识图谱的评价方法对生成输出中细微语义差异的敏感性。", "conclusion": "最后，作者讨论了评估RAG系统的关键挑战，并指出了未来研究的潜在方向。"}
{"llm_update_time": "20251006", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.02539", "html_url": "https://arxiv.org/abs/2510.02539", "title": "Cobweb: 层次语义检索", "title_en": "Hierarchical Semantic Retrieval with Cobweb", "authors": "Anant Gupta,Karthik Singaravadivelan,Zekun Wang", "background": "神经文档检索通常将语料库视为单粒度下的矢量云，未能充分利用语料库结构，使得解释变得模糊不清。本文通过引入基于Cobweb的层次感知框架，尝试将句子嵌入组织成原型树结构，并通过从粗到细的方式进行文档排序，从而解决上述问题。", "innovation": "本文创新地提出了Cobweb框架，这是一种层次感知的 Document Retrieval（文档检索）方法。该方法通过对句子嵌入进行组织形成原型树，并通过从粗到细的层级方式对文档进行排序。这种方法利用内部节点作为概念原型，提供多粒度的相关性信号和检索路径上的透明解释。此外，本文还提出了两种推理方法：广度优先搜索的泛化版本和轻量级路径求和排名器。", "conclusion": "本文通过在MS MARCO和QQP数据集上的实验表明，Cobweb方法在强大的编码器嵌入上与点积搜索方法持平，但当kNN性能下降时能保持鲁棒性。实验结果还显示出，Cobweb在检索效果、对嵌入质量的鲁棒性、可扩展性和基于层次原型的可解释性方面均取得了有益的效果。"}
{"llm_update_time": "20251006", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.02388", "html_url": "https://arxiv.org/abs/2510.02388", "title": "学习路由：一种基于规则驱动的混合源Retrieve-Augmented生成代理框架", "title_en": "Learning to Route: A Rule-Driven Agent Framework for Hybrid-Source Retrieval-Augmented Generation", "authors": "Haoyue Bai,Haoyu Wang,Shengyu Chen,Zhengzhang Chen,Lu-An Tang,Wei Cheng,Haifeng Chen,Yanjie Fu", "background": "大型语言模型（LLMs）在通用问答（QA）方面表现出色，但在需要准确和最新信息的领域特定场景中常常遇到困难。检索增强生成（RAG）通过为LLMs添加外部知识来解决这一局限性，但现有的系统主要依赖于非结构化文档，而忽略了关系型数据库。数据库提供了精确、及时且可查询的事实信息，在金融、医疗保健和科学研究等领域是不可或缺的基础设施。研究揭示了数据库和文档在查询上的互补优势，同时表明简单地结合两者会引入噪声和成本，而不能保证准确性的持续提升。因此，为每个查询选择最合适的来源对于平衡效果和效率至关重要。研究表明，查询类型与检索路径之间表现出一致的规律性，这表明路由决策可以由系统规则指导。基于这些见解，提出了一种基于规则驱动的路由框架。该框架包含一个路由代理，根据显式规则评分候选增强路径并选择最适合的路径；一个规则制定专家代理根据QA反馈调整规则以保持适应性；以及一个路径级别的元缓存，用于重用相似查询的过去路由决策，以减少延迟和成本。", "innovation": "提出了一种基于规则驱动的路由框架，它包括一个评分并选择最合适的增强路径的路由代理，一个根据QA反馈调整规则的专家代理，以及一个利用过去路由决策为类似查询服务元缓存。实验表明，该框架在三个QA基准测试中表现优于静态策略和学习路由基线，同时保持了中等的计算成本，实现了更高的准确率。", "conclusion": "研究表明，数据库和文档在查询上的表现具有互补性，简单地结合两者通常不会提高准确性，为每个查询选择最合适的来源是平衡效果和效率的关键。基于这些发现，提出的基于规则驱动的路由框架在三个QA基准测试中表现出了优越性，通过动态调整规则和利用过去决策，实现了高准确性和适度的计算成本。"}
{"llm_update_time": "20251006", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.02648", "html_url": "https://arxiv.org/abs/2510.02648", "title": "SoT: Structured-of-Thought Prompting Guides Multilingual Reasoning in Large Language Models", "title_en": "SoT: Structured-of-Thought Prompting Guides Multilingual Reasoning in Large Language Models", "authors": "Rui Qi,Zhibo Man,Yufeng Chen,Fengran Mo,Jinan Xu,Kaiyu Huang", "background": "近年来，大型语言模型（LLMs）的能力使得它们能够通过深度思考来参与复杂的推理任务。然而，由于资源限制，这些模型的推理能力尚未成功地转移到低资源语言中，使得多语言推理任务变得困难。", "innovation": "本文提出了一种无需训练的方法SoT，通过多步转换：语言思考转换和结构化知识转换，来提高多语言推理任务的性能。SoT将语言特定的语义信息转换为语言无关的结构化表示，使模型能够更深入地理解不同语言中的查询。此外，SoT有效地引导LLMs进行更集中的推理，以维持一致的底层推理路径，处理跨语言表达中的变化。", "conclusion": "实验结果表明，SoT在多种多语言推理基准中表现出色，适用于不同LLM模型的架构。它还可以与其他无需训练的方法结合以进一步改进性能。我们的代码可在此网站上获取：this https URL。"}
{"llm_update_time": "20251006", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.02524", "html_url": "https://arxiv.org/abs/2510.02524", "title": "解析语法规则：语言模型如何学习上下文无关文法", "title_en": "Unraveling Syntax: How Language Models Learn Context-Free Grammars", "authors": "Laura Ying Schulz,Daniel Mitropolsky,Tomaso Poggio", "background": "本文探讨了语言模型如何掌握语法规则的问题。尽管大型语言模型取得了令人印象深刻的成果，但人们对它们的学習动态知之甚少。研究者观察到，大多数感兴趣的领域，如自然语言语法规则、编程语言、算术问题等，都可以用概率上下文无关文法（PCFGs）来描述。他们通过研究小型模型在从PCFG生成的合成语言上的训练动态，探讨了学习过程的细节，实现了对文法复杂性、递归深度和子文法规则结构的精确控制。", "innovation": "本文提出了一种新的框架来理解语言模型如何获得语法规则。研究者通过数学证明了关于训练损失和Kullback-Leibler（K-L）散度的几条基本公式。实验表明，与儿童先掌握简单结构再过渡到复杂结构不同，变压器模型同时减少了所有子文法规则的损失。研究还表明，预先训练子文法规则可以帮助小型模型降低最终损失，且预训练模型内部表示更符合文语法的子结构。进一步揭示了模型在处理深层递归结构时的局限性，这反映了神经网络表示层级结构的基本挑战。", "conclusion": "本文的工作开启了探索变换器模型在PCFGs上的学习动态的研究，将其作为检验语言模型学习潜力的多用途实验平台，为未来研究开放式问题开辟了新的路径。"}
{"llm_update_time": "20251006", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.02742", "html_url": "https://arxiv.org/abs/2510.02742", "title": "基于对比嵌入相似性的印度语境下的数据集和大语言模型偏见评估框架——IndiCASA", "title_en": "IndiCASA: A Dataset and Bias Evaluation Framework in LLMs Using Contrastive Embedding Similarity in the Indian Context", "authors": "Santhosh G S,Akshay Govind S,Gokul S Krishnan,Balaraman Ravindran,Sriraam Natarajan", "background": "大型语言模型（LLMs）因其出色的情境理解和生成能力在关键领域获得了广泛关注。然而，它们在高风险应用中的逐渐部署需要对其嵌入式偏见进行严格的评估，特别是在如印度这样文化多元的环境中，现有的基于嵌入的偏见评估方法往往难以捕捉到复杂的刻板印象。", "innovation": "我们提出了一种基于对比学习训练的编码器的评估框架，该框架通过嵌入相似性捕捉细微的偏见信息。我们还引入了一个名为IndiCASA的新数据集，包含2,575个人工验证的句子，覆盖五个人口统计轴：种姓、性别、宗教、残疾和经济地位。评估结果显示，所有模型都表现出某种程度的刻板偏见，其中与残疾相关的偏见尤为持久，而宗教偏见较低，这表明全球去偏见努力在起作用，也指出了构建更公平模型的需求。", "conclusion": "研究发现，尽管LLMs在印度等多元文化环境中具有广泛应用，但仍有偏见问题，需要进一步关注残疾和宗教等方面的刻板印象问题，并推动更公平的模型开发。"}
{"llm_update_time": "20251006", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.02569", "html_url": "https://arxiv.org/abs/2510.02569", "title": "转录、翻译或转写：关于口语模型中间表示的调查", "title_en": "Transcribe, Translate, or Transliterate: An Investigation of Intermediate Representations in Spoken Language Models", "authors": "Tolúl\\d{o}pé Ògúnrèmí,Christopher D. Manning,Dan Jurafsky,Karen Livescu", "background": "口语模型（SLMs）结合了语音与大型语言模型（LMs），依赖于模态适配器（MAs）将语音编码器的输出映射为解码器LM可理解的表示。然而，我们对这些关键MAs如何转换表示知之甚少。本文通过分析三个SLMs（SALMONN、Qwen2-Audio和Phi-4-Multimodal-Instruct）的MAs输出表示，探讨了其工作原理。", "innovation": "通过找到MA表示 closest 的解码器LM标记来揭示了两种MA表示策略。当模型使用Whisper编码器时，MAs使用基于英语的中间语言来表示输入的意义，以处理在指令微调中未见过的语言。而对于没有使用Whisper编码器的模型（如Phi-4-Multimodal-Instruct），MAs则是通过英语单词表示输入的音素。", "conclusion": "MAs的表示方式取决于语音编码器是否仅用于语音识别或是否也用于翻译。这一发现为理解SLMs中模态适配器的工作机制提供了新的见解。"}
{"llm_update_time": "20251006", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.02671", "html_url": "https://arxiv.org/abs/2510.02671", "title": "特征差异中的不确定性：LLMs在上下文问答中的知识不确定性量化", "title_en": "Uncertainty as Feature Gaps: Epistemic Uncertainty Quantification of LLMs in Contextual Question-Answering", "authors": "Yavuz Bakman,Sungmin Kang,Zhiqi Huang,Duygu Nur Yaldiz,Catarina G. Belém,Chenyang Zhu,Anoop Kumar,Alfy Samuel,Salman Avestimehr,Daben Liu,Sai Praneeth Karimireddy", "background": "目前不确定性量化（UQ）研究主要集中在封闭书籍的事实问题回答（QA），而上下文QA这一重要领域尚未被关注。本文探讨了UQ在上下文QA任务中的应用，并提出了一种理论依据的方法来衡量实质性的不确定性。", "innovation": "本文创新地提出了一种任务无关的令牌级不确定性度量方法，定义为给定模型的预测分布与未知真实分布之间的交叉熵，并通过分解这一度量将实质性的不确定性与模式隐藏表示特征的差距联系起来。此外，作者假设三个特性可以近似这些差距：利用上下文而非参数知识，从上下文中提取相关信息，以及避免故意说谎。", "conclusion": "本文的方法在多个QA基准测试中表现出色，无论是分布内还是分布外，其方法显著优于现有的无监督和有监督UQ方法，且几乎不增加推理开销，最高可实现13点性能提升（以PRR衡量）."}
{"llm_update_time": "20251006", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.02629", "html_url": "https://arxiv.org/abs/2510.02629", "title": "语言模型中上下文利用高亮解释的评估框架", "title_en": "Evaluation Framework for Highlight Explanations of Context Utilisation in Language Models", "authors": "Jingyi Sun,Pepa Atanasova,Sagnik Ray Choudhury,Sekh Mainul Islam,Isabelle Augenstein", "background": "语言模型（LMs）的上下文利用机制尚不透明，用户无法确定模型是依赖参数记忆还是提供的上下文，也无法识别具体的上下文片段对模型输出的影响。高亮解释（HEs）可以精确指明这些影响因素，但现有研究尚未对其有效性进行评估。该研究旨在填补这一空白，提出首个用于上下文归因的高亮解释黄金标准评估框架，通过带有已知正确上下文使用的受控测试案例，避免了现有间接代理评估的局限性。研究在四个上下文场景、四个数据集和五种LM中评估了四种HE方法，包括三种现有技术和一种适应此任务的机理可解释性方法（MechLight）。", "innovation": "引入了第一个用于上下文归因的高亮解释黄金标准评估框架，评估了多种HE方法在不同上下文和数据集中的效果，明确了MechLight在所有上下文场景中表现最优的趋势，但也揭示了所有方法在较长上下文和位置偏好方面的挑战，为大规模提供可靠上下文利用解释提出了新的研究方向。", "conclusion": "MechLight在所有上下文场景中表现最优，但所有方法在较长上下文和位置偏好方面存在问题，表明需要新的方法来确保大规模下的可靠上下文利用解释。"}
{"llm_update_time": "20251006", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.02752", "html_url": "https://arxiv.org/abs/2510.02752", "title": "自我进化大型语言模型的道路：通过内在反馈实现数据高效学习", "title_en": "The Path of Self-Evolving Large Language Models: Achieving Data-Efficient Learning via Intrinsic Feedback", "authors": "Hangfan Zhang,Siyuan Xu,Zhimeng Guo,Huaisheng Zhu,Shicheng Liu,Xinrun Wang,Qiaosheng Zhang,Yang Chen,Peng Ye,Lei Bai,Shuyue Hu", "background": "强化学习(RL)在提升大型语言模型(LLM)的推理能力方面展现了潜力，然而，这种训练通常需要大量的数据创建和标注工作。本文探讨了通过少量数据提高LLM的能力的方法，提出了两种基于自我意识的新机制：(1) 自我评估的难度预测，以及 (2) 自我认识的限制突破。", "innovation": "通过引入自我意识机制，模型能够自我评估任务难度、任务边界，并请求外部数据以克服局限。实验结果表明，这种方法在基准测试中实现了53.8%的相对改进，同时仅增加了不到1.2%的数据量，证明了自我增强的RL的有效性和潜力。", "conclusion": "研究表明，通过自我感知的机制，可以在较少的数据依赖下有效提升大型语言模型的能力。这种方法为未来的数据高效学习提供了新的可能性，展示了自我进化智能体训练的潜力。"}
{"llm_update_time": "20251006", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.02665", "html_url": "https://arxiv.org/abs/2510.02665", "title": "多模态大规模语言模型自我改进综述", "title_en": "Self-Improvement in Multimodal Large Language Models: A Survey", "authors": "Shijian Deng,Kai Wang,Tianyu Yang,Harsh Singh,Yapeng Tian", "background": "近年来，大规模语言模型（LLMs）的自我改进方面取得了显著进展，能够在不大幅增加成本（尤其是人力成本）的情况下显著提升模型能力。这一领域尽管仍处于初期阶段，但其向多模态领域的扩展具有巨大的潜力，可以利用多种数据源并开发出更通用的自我改进模型。本文是首篇关于多模态LLMs（MLLMs）自我改进的综述性文章，对现有文献进行了结构化的综述，并从数据收集、数据组织和模型优化三个角度讨论了相关方法，以促进MLLMs自我改进的进一步研究。文章还介绍了常用评估方法和下游应用，并总结了相关挑战及未来的研究方向.", "innovation": "本文是首篇关于多模态LLMs自我改进的综述性文章，对当前文献进行了结构化的综述，并提出了从数据收集、数据组织和模型优化三个角度对MLLMs自我改进的重要视角。此外，该文章还着重介绍了用于评估的常见方法和下游应用，并指出了未来的研究方向，为该领域的发展提供了有价值的见解.", "conclusion": "本文总结了多模态LLMs自我改进领域的现存挑战，并提出了未来研究的方向。其中包括需要解决的关键问题、进一步提升的方法以及潜在的研究机遇。这些结论为该领域的未来研究指明了路径，有助于推动多模态LLMs自我改进方面的进展和应用发展."}
{"llm_update_time": "20251006", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.02712", "html_url": "https://arxiv.org/abs/2510.02712", "title": "时间不一致性：大型语言模型对抗攻击下的生存分析", "title_en": "Time-To-Inconsistency: A Survival Analysis of Large Language Model Robustness to Adversarial Attacks", "authors": "Yubo Li,Ramayya Krishnan,Rema Padman", "background": "大型语言模型（LLMs）在对话AI领域取得了革命性的进展，但它们在长时间多轮对话中的稳健性依然不为人所理解。现有的评估框架主要集中在静态基准和单轮评估上，无法捕捉实际对话中对话退化的时间动态。这项工作首次全面分析了对话AI的稳健性，研究了9种最先进的大型语言模型共36951个对话回合，揭示了这些模型在面对对话退化时的生存时间动态，挑战了对话AI系统中语义一致性的必要性假设", "innovation": "这项工作引入了生存分析框架来评估大型语言模型的稳健性，采用Cox比例风险、加速度失效时间、随机生存森林等方法进行生存模型建模。研究发现突变的、从指令到指令的语义漂移非常致命，会大大提高对话失败的概率；而渐进的、积累的漂移则具有保护作用，极大地降低了对话失败的风险，使对话能持续更长时间。带有交互的加速度失效时间模型表现出优越的性能，具备出色的区分度和极好的校准能力。这些发现确立了生存分析作为评估LLM稳健性的强大范式，提供了有关设计具有韧性的对话代理的实用见解，并挑战了对话AI系统中语义一致性的必要性假设", "conclusion": "生存分析在评估大型语言模型的稳健性方面具有显著优势，为设计更具有韧性的对话代理提供了具体的见解，并挑战了关于对话AI系统中语义一致性的必要性假设。"}
{"llm_update_time": "20251006", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.02719", "html_url": "https://arxiv.org/abs/2510.02719", "title": "TravelBench：探究大语言模型在低资源领域的性能", "title_en": "TravelBench : Exploring LLM Performance in Low-Resource Domains", "authors": "Srinivas Billa,Xiaonan Jing", "background": "现有的大语言模型（LLM）基准测试未能充分捕捉模型在低资源任务中的能力，这使得在这些领域中开发有效的解决方案变得困难。鉴于此，研究者们整理了14个涵盖7个常见自然语言处理（NLP）任务的旅行领域数据集，并使用匿名化的真实世界场景数据进行了分析。通过这一研究，他们发现了通用基准测试结果在低资源任务理解模型表现方面的不足，并指出即使经过大量训练，开箱即用的LLM也会在复杂、特定领域的场景中面临性能瓶颈。此外，研究表明推理能力对于小型LLM提升性能具有更大的帮助，使其在某些任务上表现得更优秀.", "innovation": "研究者们创建了TravelBench，一个探索大语言模型在低资源领域的性能评估工具。该工具通过使用匿名化的真实世界旅行数据，构建了一个涵盖7种常见NLP任务的数据集，并分析了在不同LLM上的表现。结果表明，通用基准测试结果不足以理解模型在低资源任务的表现，而推理能力对于小型LLM提高性能至关重要。该研究还揭示了动力学行为和其他性能指标对于这一问题的理解有重要价值.", "conclusion": "研究结果证明，通用基准测试不足以评估模型在低资源任务中的表现，必须考虑更多因素，如推理能力和动力学行为。对于小型LLM，推理能力带来了显著的提升，而开箱即用的LLM即使训练量很大也可能会在复杂、特定领域的场景中遇到来自性能的限制。"}
{"llm_update_time": "20251006", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.02788", "html_url": "https://arxiv.org/abs/2510.02788", "title": "XTRA: 基于主题和表示对齐的跨语言主题建模", "title_en": "XTRA: Cross-Lingual Topic Modeling with Topic and Representation Alignments", "authors": "Tien Phat Nguyen,Vu Minh Ngo,Tung Nguyen,Linh Van Ngo,Duc Anh Nguyen,Sang Dinh,Trung Le", "background": "跨语言主题建模旨在揭示不同语言之间的共享语义主题。先前的方法已提出利用传统和神经网络方法来解决这个问题，尽管这些方法在主题多样性方面取得了一些改进，但在主题连贯性及不同语言之间的一致对齐方面仍存在挑战。实验表明，跨语言主题模型需要在可解释性、连贯性以及一致性质量上提升.", "innovation": "提出了一种名为XTRA的新框架，该框架结合了Bag-of-Words建模与多语言嵌入。XTRA引入了两个核心组件：1) 表示对齐，通过共享语义空间中的对比学习对齐文档-主题分布；2) 主题对齐，将主题-单词分布投影到同一空间以确保跨语言一致性。这种双重机制让XTRA能够学习到可解释性（连贯且多样化）且跨语言对齐良好的主题模型.", "conclusion": "在多个多语言数据集上的实验表明，XTRA在主题连贯性、多样性和对齐质量上显著优于现有基线方法。相关代码和可复现的脚本可从https://github.com/tienphat140205/XTRA获得."}
{"llm_update_time": "20251006", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.02645", "html_url": "https://arxiv.org/abs/2510.02645", "title": "Mind the Gap: Linguistic Divergence and Adaptation Strategies in Human-LLM Assistant vs. Human-Human Interactions", "title_en": "Mind the Gap: Linguistic Divergence and Adaptation Strategies in Human-LLM Assistant vs. Human-Human Interactions", "authors": "Fulei Zhang,Zhou Yu", "background": "随着大规模语言模型（LLMs）在面向客户的应用中越来越普及，用户与LLM对话机器人交流的方式与与人类代理交流的方式之间的差异成为一个关键但未充分探索的问题。本研究通过实证研究揭示了用户在与聊天机器人互动时与与人类代理互动时采用不同的交流风格，并在语法流畅性、礼貌程度和词汇多样性等方面发现了显著差异。这些发现表明，仅在人类-人类互动数据上进行训练的模型可能无法充分适应部署LLM对话机器人的交流风格变化。", "innovation": "本研究提出了两种策略来增强LLM在交流风格变化后的鲁棒性：（1）在训练后阶段的数据扩充，（2）推理时用户的消息重新制定。结果表明，使用风格多样的数据集训练的模型显著优于使用原始数据或风格统一数据集训练的模型，而推理时的重新制定则效果较差。", "conclusion": "这些研究结果有助于更好地适应模型，以提高LLM与用户交互的体验。模型训练在风格多样的数据集上显然比仅使用原数据或风格统一数据集更有效，而推理时的消息重新制定效果较差。"}
{"llm_update_time": "20251006", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.02726", "html_url": "https://arxiv.org/abs/2510.02726", "title": "PGMEL: 基于策略梯度的生成对抗网络在多模态实体链接中的应用", "title_en": "PGMEL: Policy Gradient-based Generative Adversarial Network for Multimodal Entity Linking", "authors": "KM Pooja,Cheng Long,Aixin Sun", "background": "实体链接任务将提及与知识图谱中的相应实体进行关联，由于其广泛的潜在应用而受到广泛关注。最近，针对多模态实体链接(MEL)的技术得到了发展，旨在通过结合文本和视觉模态来学习综合嵌入表示。尽管高质负面样本的选择可能会在度量/表示学习中起到关键作用，但这种可能性在现有的MEL文献中尚未得到探索，尤其是在生成对抗设置框架内。为了填补这一空白，作者提出了P(G)MEL，这是一种在生成对抗设置中的基于策略梯度的生成对抗网络，其中生成器生成高质量的负面样本，判别器负责度量学习任务。该网络在Wiki-MEL、Richpedia-MEL和WikiDiverse数据集上的实验结果表明，P(G)MEL通过选择具有挑战性的负面样本学习到了有意义的表示并优于最先进的方法。", "innovation": "提出了一种基于策略梯度的生成对抗网络(Policy Gradient-based Generative Adversarial Network)为多模态实体链接(PGMEL)。P(G)MEL能够生成高质量的负面样本并进行度量学习任务，通过优化生成器采用了策略梯度技术。实验结果表明，P(G)MEL学习到了有意义的表示并优于现有的最佳方法，特别是在选择挑战性的负面样本方面表现突出。", "conclusion": "实验结果在Wiki-MEL，Richpedia-MEL和WikiDiverse数据集上证明了P(G)MEL通过生成挑战性负面样本学习到了有意义的表示，并且在多模态实体链接中优于现有最先进的方法。"}
{"llm_update_time": "20251006", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.02919", "html_url": "https://arxiv.org/abs/2510.02919", "title": "测试时自省式生成", "title_en": "Self-Reflective Generation at Test Time", "authors": "Jian Mu,Qixin Zhang,Zhiyong Wang,Menglin Yang,Shuang Qiu,Chengwei Qin,Zhongxiang Dai,Yao Shu", "background": "大语言模型（LLMs）通过长链推理解决复杂任务的能力日益增强，但其前向自回归生成过程对早期token错误极其脆弱。一旦出现错误，就会导致错误的传播，这凸显了需要一种自我反省机制的迫切需求。现有的自我反省机制要么在整个草稿上进行修订，要么通过昂贵的训练来学习自我修正，这两种方法都本质上是反应性的且效率低下。", "innovation": "本文提出了测试时自省式生成（SRGen），这是一种轻量级测试时框架，它在产生不确定的token之前进行自我反省。SRGen利用动态熵门限值来识别高不确定性的token。对于每个识别出的token，它训练一个特定的纠正向量，充分利用已生成的上下文信息进行自我反省生成，纠正token的概率分布。通过回顾中间输出，自我反省能够确保更可靠的决策，显著降低高不确定性点的错误概率。", "conclusion": "SRGen在挑战性数学推理基准测试和多种LLM上进行了评估，并表明能够持续加强模型推理。在AIME2024与DeepSeek-R1-Distill-Qwen-7B上，SRGen分别在Pass@1上取得+12.0%的绝对改进，在Cons@5上取得+13.3%的绝对改进。我们的研究结果将SRGen定位为一种插件技术，可以在生成过程中轻松结合反思以提高LLM推理的可靠性，同时实现可绑定的开销和与其他训练时（例如RLHF）和测试时（例如SLOT）技术的广泛兼容性。"}
{"llm_update_time": "20251006", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.02827", "html_url": "https://arxiv.org/abs/2510.02827", "title": "StepChain GraphRAG：基于知识图谱的多跳问答推理", "title_en": "StepChain GraphRAG: Reasoning Over Knowledge Graphs for Multi-Hop Question Answering", "authors": "Tengjun Ni,Xin Yuan,Shenghong Li,Kai Wu,Ren Ping Liu,Wei Ni,Wenjie Zhang", "background": "检索增强生成（RAG）最近的进步提高了多跳问答（QA）的准确性和可解释性，但在集成迭代推理步骤与外部知识检索时仍面临挑战。本文在这一背景下介绍了一种名为StepChain GraphRAG的方法，该方法结合了问题分解和广度优先搜索（BFS）推理流程，以增强多跳QA的能力。", "innovation": "StepChain GraphRAG框架通过构建全局索引和在推理时仅对检索到的段落进行按需解析，并将复杂查询拆分为子问题，使用基于BFS的遍历动态扩展相关边，从而构建明确的证据链，而不会让语言模型过度处理不必要的上下文。此方法在MuSiQue、2WikiMultiHopQA和HotpotQA上的实验结果显示了显著的准确性和F1分数的提升，特别是在HotpotQA上的改进最大，达到了最大的信息抽取准确度提高4.70%，F1分数提高3.44%。此外，该方法还能通过保留中间检索步骤的思维过程来增强可解释性。", "conclusion": "我们讨论了未来工作如何减轻计算开销并解决大型语言模型潜在的幻觉问题，以进一步提高多跳QA的效率和可靠性。"}
{"llm_update_time": "20251006", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.02811", "html_url": "https://arxiv.org/abs/2510.02811", "title": "社交媒体中的可解释基于文本的人格评估的计算框架", "title_en": "A Computational Framework for Interpretable Text-Based Personality Assessment from Social Media", "authors": "Matej Gjurković", "background": "人格是指个体在行为、思维和情感上的差异。随着数字足迹的大量出现，特别是来自社交媒体的数据，自动化的人格评估方法变得越来越重要。自然语言处理（NLP）使我们能够分析非结构化文本数据以识别人格指标。然而，大规模人格标注数据的稀缺性和人格心理学与NLP之间的脱节限制了模型的效度和可解释性。为了解决这两个主要挑战，该论文提出了两个从Reddit收集的数据集——MBTI9k和PANDORA，Reddit是一个以用户匿名性和多样的讨论著称的平台。PANDORA数据集包含来自10,000多名用户的1700万条评论，将MBTI和大五人格模型与人口统计数据结合起来，解决了数据量、质量和标签覆盖的限制。实验表明，人口统计变量会影响模型的效度。", "innovation": "本论文的职业贡献在于提出了一个用于可解释的人格评估的SIMPA（Statement-to-Item Matching Personality Assessment）框架。SIMPA通过匹配用户生成的陈述与验证问题条目，利用机器学习和语义相似性提供可比于人类评估的人格评估，同时保持高可解释性和效率。SIMPA的设计是模型兼容的，具有多层线索检测和可扩展性，使其适合各种需要复杂标签分类和目标概念变化关联的研究和应用。", "conclusion": "虽然本文主要集中在人格评估上，但SIMPA的通用性超越了这一领域。SIMPA因其模型兼容性、多层次线索检测能力和可扩展性，在涉及复杂标签分类和变量线索与目标概念关联的研究和实际应用中都具有广泛应用前景。"}
{"llm_update_time": "20251006", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.02830", "html_url": "https://arxiv.org/abs/2510.02830", "title": "评估大型语言模型在IUCN红色名录物种信息中的应用", "title_en": "Evaluating Large Language Models for IUCN Red List Species Information", "authors": "Shinya Uryu", "background": "大型语言模型（LLMs）正在快速被应用于保护领域以应对生物多样性危机，但它们在物种评估中的可靠性尚未确定。这项研究系统地验证了五个领先的模型在21,955种物种上的表现，特别是在IUCN红色名录的四个核心评估组件：分类学、保护状况、分布和威胁方面。研究揭示了一个关键的悖论：这些模型在分类学分类上表现出色（94.9%的准确性），但在保护实现上却表现不佳（状况评估的成功率仅为27.2%）。", "innovation": "这项研究首次全面系统地评估了大型语言模型在保护领域的应用，特别是针对IUCN红色名录的关键评估组件。研究发现，模型在分类学分类方面的表现优于保护状况评估，揭示了一个知识推理的差距，这可能是由于模型架构的内在约束而非数据限制。此外，模型还显示出系统性的偏好，倾向于支持有吸引力的脊椎动物，这可能会加剧现有的保护不平等性。这些发现为负责任地使用大型语言模型设定了明确边界：它们是信息检索的强大工具，但需要人类监督以进行判断性决策。推荐采用混合方法，在保护领域扩大专家能力的同时，由人类专家保留对风险评估和政策制定的唯一权威。", "conclusion": "这些模型在信息检索方面表现强大但需要人类监督的判断性决策。推荐混合方法，利用大型语言模型增强专家能力，但保留人类专家在风险评估和政策制定方面的最终决策权。"}
{"llm_update_time": "20251006", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.02967", "html_url": "https://arxiv.org/abs/2510.02967", "title": "将大型语言模型锚定于临床证据：一种用于查询英国NICE临床指南的检索增强生成系统", "title_en": "Grounding Large Language Models in Clinical Evidence: A Retrieval-Augmented Generation System for Querying UK NICE Clinical Guidelines", "authors": "Matthew Lewis,Samuel Thio,Richard JB Dobson,Spiros Denaxas", "background": "英国NICE临床指南内容长度和数量庞大，这对在时间受限的医疗系统中利用这些指南造成了阻碍。本文研究开发了一种检索增强生成（RAG）系统，利用大型语言模型来针对自然语言查询提供精准匹配信息，以解决这一挑战。通过评估系统的检索架构，该系统在性能方面表现出色，尤其是在生成阶段。", "innovation": "研究开发了一种基于大型语言模型的RAG系统，系统包含混合嵌入机制。该系统在评估中表现出高性能，如MRR为0.814，前十个提取片段的召回率为99.1%，并在生成阶段显示出显著提高的性能。改进后的模型在忠实性方面有了显著提升，能够将答案与源文本紧密联系，进一步提升了系统的可靠性和准确性。", "conclusion": "该研究证明RAG系统是一种在医疗保健中应用生成型AI的有效、可靠且可扩展的方法，能够通过精准的自然语言查询提供可靠信息，使获取医疗指南更加成本效益。"}
{"llm_update_time": "20251006", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.03115", "html_url": "https://arxiv.org/abs/2510.03115", "title": "倾听还是阅读？评估链式思考在语音到文本翻译中的语音意识", "title_en": "Listening or Reading? Evaluating Speech Awareness in Chain-of-Thought Speech-to-Text Translation", "authors": "Jacobo Romero-Díaz,Gerard I. Gállego,Oriol Pareras,Federico Costa,Javier Hernando,Cristina España-Bonet", "background": "传统的语音到文本翻译（S2TT）系统由自动语音识别（ASR）模块和文本到文本翻译（T2TT）模块组成，面临着两个主要限制：错误传播以及无法利用语调或其他声学线索。近年来，链式思考（CoT）提示被引入，期望通过同时访问语音和转录来克服这些问题。然而，通过归因方法、鲁棒性评估（使用损坏的转录）以及语调感知的分析显示，CoT 仍然主要依赖于转录，对语音的利用较少。", "innovation": "该研究通过简单的训练干预，如增加直接S2TT数据或注入噪声转录，增强了系统的鲁棒性并增加了对语音的依赖。这些发现质疑了CoT的优势，并强调需要将声学信息明确整合到翻译中的架构。", "conclusion": "研究结果表明，CoT在处理语音信息方面并未展现出预期的优势，系统仍然主要依赖于转录，而对语音的利用较少。这促进了对可以明确整合声学信息并提高语音意识的新型架构的需求。"}
{"llm_update_time": "20251006", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.03136", "html_url": "https://arxiv.org/abs/2510.03136", "title": "超越最终层：更好的大型语言模型多语言校准的中间表示", "title_en": "Beyond the Final Layer: Intermediate Representations for Better Multilingual Calibration in Large Language Models", "authors": "Ej Zhou,Caiqi Zhang,Tiancheng Hu,Chengzu Li,Nigel Collier,Ivan Vulić,Anna Korhonen", "background": "大型语言模型（LLMs）的置信校准，即模型预测置信度与其实际准确性的一致性，是其实可用部署的关键。然而，在多语言环境下，这个重要的属性仍然很少被研究。本文通过大规模分析六个模型家族及超过100种语言，首次系统地探讨了多语言校准，揭示了非英语语言在置信校准上存在系统性的劣势。", "innovation": "本文研究发现了最终层因英语文本训练偏差，不适合多语言校准的特点。提出了一种基于层的分析，发现较晚的中间层能提供更可靠和更好的校准信号。在此基础上，引入了一套无需训练的校准方法，包括语言感知置信集成（LACE），该方法能够自适应地选择适用于特定语言的最佳层组合。", "conclusion": "研究揭示了英语文本中心对齐模式背后隐藏的成本，提出了一条新的途径，通过超越最终层的分析，构建更为全球公平和可信赖的大型语言模型。"}
{"llm_update_time": "20251006", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.03093", "html_url": "https://arxiv.org/abs/2510.03093", "title": "用语音LLM重新审视直接语音转文本翻译：比CoT提示更好的扩展性？", "title_en": "Revisiting Direct Speech-to-Text Translation with Speech LLMs: Better Scaling than CoT Prompting?", "authors": "Oriol Pareras,Gerard I. Gállego,Federico Costa,Cristina España-Bonet,Javier Hernando", "background": "语音到文本翻译（S2TT）领域的近期研究主要集中在基于大语言模型（LLM）的模型上，其中引入了一种越来越常用的Chain-of-Thought（CoT）提示方法，这种提示方法可以指导模型首先进行语音转录，然后进行翻译。CoT通常优于直接提示，因为它可以利用大规模的自动语音识别（ASR）和文本到文本翻译（T2TT）数据集来明确建模其各个步骤。", "innovation": "本文系统地比较了CoT提示和直接提示在不断增加的S2TT数据下的效果，并通过伪标签方法创建了一个包含六种欧洲语言的ASR语料库，分别使用不同提示策略和数据规模培训基于LLM的S2TT系统。研究结果显示，随着数据量的增加，直接提示方法提升更为稳定，表明在创建更多S2TT资源时，这种方法可能变得更加有效。", "conclusion": "研究结果表明，直接提示方法在这类任务上展示出更好的扩展性，并有可能在更大规模的数据集上实现更有效的翻译效果。"}
{"llm_update_time": "20251006", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.03154", "html_url": "https://arxiv.org/abs/2510.03154", "title": "EditLens：量化文本中的AI编辑程度", "title_en": "EditLens: Quantifying the Extent of AI Editing in Text", "authors": "Katherine Thai,Bradley Emi,Elyas Masrour,Mohit Iyyer", "background": "大量的查询请求大型语言模型进行文本编辑，而不是从零开始生成新的文本。以往研究主要集中在识别完全由AI生成的文本，而本文展示了AI编辑的文本可以与人类撰写和AI生成的文本区分开来。作者通过提出轻量级相似度度量来量化文本中的AI编辑程度，并通过人类注释者验证这些度量。基于这些相似度度量，训练了回归模型EditLens，该模型可以预测文本中的AI编辑程度。", "innovation": "1. 提出了使用轻量级相似度度量来量化文本中的AI编辑程度。\n2. 利用这些相似度度量作为中间监督，训练了回归模型EditLens，该模型可以预测文本中的AI编辑程度。\n3. 模型在二元（F1=94.7%）和三元分类任务（F1=90.4%）中获得了最先进的性能。\n4. 研究发现AI编辑的文本可以被检测到，同时也可以检测到AI对人类文本修改的程度，这对于作者身份归因、教育和政策都有重要意义。", "conclusion": "基于我们的模型分析了Grammarly（一个流行的写作辅助工具）应用的AI编辑效果。为鼓励进一步研究，我们承诺公开发布我们的模型和数据集。"}
{"llm_update_time": "20251006", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.02938", "html_url": "https://arxiv.org/abs/2510.02938", "title": "在对话信息 haystack 中寻找宝石：对话数据检索基准", "title_en": "Finding Diamonds in Conversation Haystacks: A Benchmark for Conversational Data Retrieval", "authors": "Yohan Lee,Yongwoo Song,Sangyeop Kim", "background": "目前缺乏一个全面的测试集来评估能够为产品洞察提供对话数据检索系统的性能。为此，本文引入了一个名为 Conversational Data Retrieval (CDR) 的基准测试集，包含 1600 个查询和 9100 个对话，覆盖五个分析任务。基准测试集为企业提供了一个可靠的标准，用于衡量对话数据检索性能。此外，该基准还指出文档检索和对话数据检索之间的差距，揭示了当前最先进的模型在处理对话数据时的能力不足。", "innovation": "本文提出了第一个全面的基准测试集——Conversational Data Retrieval (CDR)，专门用于评估能够从对话数据中提取产品洞察的系统。该基准包含 1600 个查询和 9100 个对话，涵盖了五种分析任务。基准测试揭示了对话数据检索中存在的独特挑战（如隐含状态识别、回合动态和上下文引用），为模型提供了具体的查询模板并进行了详尽的错误分析。评估了 16 种流行的嵌入模型，发现最好的模型在 NDCG@10 上也只有约 0.51，显示出对话数据检索与文档检索之间存在的显著差距。此外，基准数据集和代码已经公开。", "conclusion": "本文提出的 CDR 基准测试集为对话数据检索研究设定了标准，揭示了当前模型在面对对话数据时的实际局限性，并为企业提供了一个可靠的数据集来评估其系统性能。"}
{"llm_update_time": "20251006", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.02962", "html_url": "https://arxiv.org/abs/2510.02962", "title": "不留任何痕迹：通过水印检测大型语言模型中受版权保护数据集的黑盒使用", "title_en": "Leave No TRACE: Black-box Detection of Copyrighted Dataset Usage in Large Language Models via Watermarking", "authors": "Jingqi Zhang,Ruibo Chen,Yingqing Yang,Peihua Mai,Heng Huang,Yan Pang", "background": "大型语言模型（LLMs）通过在较小的专业领域数据集上进行微调来提高下游性能。这些数据集通常包含专有或受版权保护的内容，引发了防止未经授权使用的可靠保护需求。现有的成员身份推断攻击（MIAs）和数据集推断方法通常需要访问内部信号（如logits），而当前的黑盒方法往往依赖于手工构造的提示或干净的参考数据集进行校准，这两种方法都限制了其实用性。因此，需要一种能够在不依赖这些限制因素的情况下，对受版权保护的数据集使用进行检测的方法。密码技术中的水印是一种有前途的替代方案，但之前的技术可能会降低文本质量或减少任务性能。因此，研究迫切需要一种方法，能够在保留文本质量和下游效用的同时，对受版权保护的数据集进行黑盒检测。", "innovation": "本文提出了TRACE（在受版权保护的数据集使用中进行黑盒检测的实用框架），该框架通过使用私人密钥引导的无失真水印重写数据集，保证文本质量和下游效用。在检测阶段，利用微调对带水印数据产生的放射性效应，引入一种基于熵的触发程序，选择性地给高不确定性标记评分，显著增强了检测能力。通过在多种数据集和模型家族中的广泛测试，TRACE能够以显著的检测结果（p<0.05），通常带有强烈统计证据，实现一致的检测。此外，该方法支持多数据集归因，并且即使继续在大量非水印语料库上进行预先训练，其效果仍保持稳定。", "conclusion": "研究表明，TRACE提供了一条实用途径，可以实现黑盒验证中对受版权保护数据集使用的可靠检测。该研究还将代码开源，地址为：this https URL。这一工作不仅提升了大型语言模型对版权数据集使用的透明度和安全性，也为未来的研究和应用提供了新的参考和可能性。"}
{"llm_update_time": "20251006", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.03120", "html_url": "https://arxiv.org/abs/2510.03120", "title": "SurveyBench：LLM(-代理)能否写出高质量的学术综述？", "title_en": "SurveyBench: How Well Can LLM(-Agents) Write Academic Surveys?", "authors": "Zhaojun Sun,Xuzhou Zhu,Xuanhe Zhou,Xin Tong,Shuo Wang,Jie Fu,Guoliang Li,Zhiyuan Liu,Fan Wu", "background": "综述写作是一个需要大量时间和智力的工作，尽管最近出现了自动化的工具（例如LLM4Survey），但它们生成的输出大多未达到人类的标准。目前缺乏一个严格且与阅读者需求对齐的基准来全面揭示自动化的不足之处。现有的综述生成工具往往覆盖不广、逻辑不连贯或解释不够清晰。", "innovation": "本文提出一个细粒度的、基于问题的评估框架SurveyBench，它包括（1）来自最近11,343篇arXiv论文的典型主题及其对应的4,947篇高质量综述；（2）多维度的评估指标体系，评估大纲质量（如覆盖范围、逻辑连贯性）、内容质量（如总结细节、见解清晰度）和非文本丰富性；（3）结合内容评分和基于问题的回答测试的双重评估机制，明确与读者的信息需求对齐。", "conclusion": "实验结果显示，SurveyBench能够有效挑战现有的LLM4Survey方法，在基于内容的评估中低于人类平均水平21%。"}
{"llm_update_time": "20251006", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.02855", "html_url": "https://arxiv.org/abs/2510.02855", "title": "基于约束满足的方法研究Wordle：新的启发式算法及跨语言验证", "title_en": "Constraint Satisfaction Approaches to Wordle: Novel Heuristics and Cross-Lexicon Validation", "authors": "Jahidul Arafat,Fariha Tasmin,Sanjaya Poudel,Kamrujjaman,Eftakhar Ahmed Arnob,Ahsan Habib Tareq", "background": "Wordle 提供了一个充满算法复杂性的谜题环境，适合解决约束满足问题（CSP）。现有的求解器主要依赖于信息论中的熵最大化或基于频率的经验性启发式推理，缺乏正式的约束处理。本研究表明，通过引入一种新的启发式算法——约束感知熵，和一种将贝叶斯单词频率先验与逻辑约束相结合的概率CSP框架，能够显著提高Wordle的解题效率和成功率。在英文测试集上的实验数据表明，这种方法较传统的前向检查算法在平均猜测次数和成功率达到统计显著性改进，还能在噪声环境下保持性能优势，跨语言验证则证明了核心CSP原则在不同语言间依然有效，尽管存在一定的性能差距。", "innovation": "提出了CSP-Aware Entropy算法，计算传播约束后的信息增益，而非基于原始候选集；引入了贝叶斯概率CSP框架，结合了单词频率先验与逻辑约束。这种方法在2,315个英文单词上实现3.54次平均猜测，成功率达到99.9%，比传统前向检查法（Forward Checking）提高1.7%，且耗时减少46%。在噪声环境下，该方法表现稳定，通过约束恢复机制，跨语言验证也没有特定语言调优的情况，证明了跨语言的可迁移性。提供开源代码，实现了34个单元测试，覆盖率91%，确保实验的可重复性。", "conclusion": "通过将正式的CSP处理方法、约束感知启发式、概率逻辑结合、稳健性分析以及跨语言验证相结合，本文建立了一系列新的性能基准，显示出结构化谜题解决领域的约束满足技术比传统的信息论和基于学习的方法更优。"}
{"llm_update_time": "20251006", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.03202", "html_url": "https://arxiv.org/abs/2510.03202", "title": "基于模型的零样本跨语言转移的源语言排名", "title_en": "Model-Based Ranking of Source Languages for Zero-Shot Cross-Lingual Transfer", "authors": "Abteen Ebrahimi,Adam Wiemerslage,Katharina von der Wense", "background": "该研究提出了NN-Rank算法，该算法用于为跨语言转移排序源语言，利用多语言模型中的隐藏表示以及目标语言的数据。实验基于两个预训练的多语言模型以及两个任务：词性标注（POS）和命名实体识别（NER），考虑了51种源语言，并在POS任务上测试了56种目标语言，在NER任务上测试了72种目标语言。使用领域内数据时，NN-Rank优于利用词汇和语言特征的最先进的基线方法，POS任务的平均改进为35.56 NDCG，NER任务为18.14 NDCG。对于只有有限目标语言数据可用的情况，先前的模型可能会退化依赖于语言级别的特征。研究展示了即使只有《圣经》这种跨领域语料作为子集可用的数据，NN-Rank仍然能够保持竞争力。", "innovation": "NN-Rank算法利用多语言模型的隐藏表示和未标记的目标语言数据来为源语言评分，这种方法在POS和NER任务中显著地超越了那些依赖词汇和语言特征的基线模型。即使在目标语言数据稀缺时，此方法仍然表现优异，并且在利用有限标记数据时仍然能够生成高质量的排名。", "conclusion": "当利用领域数据时，NN-Rank在POS和NER任务中均超越了利用词汇和语言特征的基线方法，分别在NDCG指标上取得了显著提升。即使只使用《圣经》这样跨领域的数据集，NN-Rank也能保持竞争力。进一步的消除实验表明，即使只能访问目标语言的少量未标记数据，此模型同样能产生高质量的排序结果。总体来说，NN-Rank提供了一种有效提升跨语言任务性能的新方法。"}
{"llm_update_time": "20251006", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.03231", "html_url": "https://arxiv.org/abs/2510.03231", "title": "奖励模型实为马甲下的度量标准", "title_en": "Reward Models are Metrics in a Trench Coat", "authors": "Sebastian Gehrmann", "background": "在大型语言模型的后训练中，强化学习引起了对奖励模型的兴趣。奖励模型用于评估生成模型输出的质量，产生训练信号。这一任务也由评估指标来完成，这些指标监测AI模型的性能。然而，这两者的研究领域往往分离，导致术语重叠和重复的陷阱。两者都面临一些共同的挑战，如易受虚假相关性的影响、对下游奖励劫持的影响，以及数据质量和元评估方法的改进。", "innovation": "研究表明，评估指标在特定任务上优于奖励模型，并提供了两个领域的综合调查。这为奖励模型和度量标准的更紧密协作提供了依据，以提高它们在偏好推导方法、避免虚假相关性与奖励劫持以及校准感知元评估等方面的应用效果。", "conclusion": "本文指出，奖励模型和度量标准应加强合作，以解决这些问题。基于调查结果，提出了多项可以在偏好推导方法、避免虚假相关性和奖励劫持以及校准感知元评估等领域的潜在协作机会，以改进奖励模型和度量标准。"}
{"llm_update_time": "20251006", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.03060", "html_url": "https://arxiv.org/abs/2510.03060", "title": "言语情感识别中的语义区分：描述性与表达性言语角色的见解", "title_en": "Semantic Differentiation in Speech Emotion Recognition: Insights from Descriptive and Expressive Speech Roles", "authors": "Rongchen Guo,Vincent Francoeur,Isar Nejadgholi,Sylvain Gagnon,Miodrag Bolic", "background": "言语情感识别(SER)在提升人机交互方面至关重要，但其准确度受限于语音中情感细微差别的复杂性。", "innovation": "本研究区分了描述性语义和表达性语义，即描述性语义代表语音的上下文内容，而表达性语义反映讲者的情感状态。通过电影片段引起的情感反应，记录参与者对经历的描述及情感标签，自行评分的情感反应，以及情绪价值/唤醒度评分，实验结果显示，描述性语义与意图情感一致，而表达性语义与诱发的情感相关联。本研究为SER在人-AI交互的应用提供了见解，并为更情境感知的人工智能系统开辟了道路。", "conclusion": "研究结果为SER应用提供了新见解，有助于理解人类如何在交互中采用上下文相关的情感表达，进而推动更智能、情境感知的AI系统的发展。"}
{"llm_update_time": "20251006", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.03215", "html_url": "https://arxiv.org/abs/2510.03215", "title": "Cache-to-Cache: Direct Semantic Communication Between Large Language Models", "title_en": "Cache-to-Cache: Direct Semantic Communication Between Large Language Models", "authors": "Tianyu Fu,Zihan Min,Hanling Zhang,Jichao Yan,Guohao Dai,Wanli Ouyang,Yu Wang", "background": "现有的大型语言模型（LLM）系统依靠文本进行通信，这导致内部表示需要转换为输出标记序列，从而丢失了丰富的语义信息并增加了逐标记生成的延迟。因此，迫切需要一种新的方法来提高LLM系统之间的通信效率和性能。", "innovation": "提出了Cache-to-Cache (C2C) 新模式，这是一种直接的语义通信模式，通过神经网络将源模型的KV缓存与目标模型的KV缓存进行投影和融合，以实现直接的语义转移，并引入可学习的门控机制选择受益于缓存通信的目标层。这种方法在不增加缓存大小的情况下利用语言模型内部的深语义，避免了显式中间文本生成。与基于文本的通信相比，C2C在准确性和效率上均得到了显著提升。", "conclusion": "C2C模式在平均准确性上比单一模型高出8.5-10.5%，比基于文本的通信模式高出约3.0-5.0%，并提供了平均2.0倍的延迟速度提升。"}
{"llm_update_time": "20251006", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.03223", "html_url": "https://arxiv.org/abs/2510.03223", "title": "Self-Anchor：通过逐步注意力对齐的大语言模型推理", "title_en": "Self-Anchor: Large Language Model Reasoning via Step-by-step Attention Alignment", "authors": "Hongxiang Zhang,Yuan Tian,Tianyi Zhang", "background": "为了应对大型语言模型（LLMs）的复杂推理任务，基于提示的方法提供了比微调和强化学习更轻量级的替代方案。但是，随着推理链的延长，关键的中间步骤和原始提示会在上下文中被埋没，受到较少的注意，从而导致错误。", "innovation": "我们提出了一种名为Self-Anchor的新颖流水线，它利用推理的内在结构来引导LLM的注意力。Self-Anchor将推理轨迹分解为结构化的计划，并自动对齐模型的注意力，使其专注于最相关的推理步骤，从而使模型在生成过程中保持关注。", "conclusion": "我们的实验表明，Self-Anchor在六个基准上优于最先进的提示方法，显著减小了非推理模型与专门的推理模型之间的性能差距，有可能使大多数LLM能够解决复杂的推理任务而无需重新训练。"}
{"llm_update_time": "20251006", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.03174", "html_url": "https://arxiv.org/abs/2510.03174", "title": "主题建模作为长文本生成：长语境LLM能否通过零样本提示重塑NTM？", "title_en": "Topic Modeling as Long-Form Generation: Can Long-Context LLMs revolutionize NTM via Zero-Shot Prompting?", "authors": "Xuan Xu,Haolun Li,Zhongliang Yang,Beilin Chu,Jia Song,Moxuan Xu,Linna Zhou", "background": "传统主题模型如神经主题模型依赖于推断和生成网络来学习潜在的主题分布。本研究探讨了在大语言模型时代的新主题建模范式，将主题建模（TM）定义为一种长文本生成任务，并提出了使用简单实用的方法实现基于LLM的主题模型任务（从数据集采样一部分，使用提示生成主题和代表文本，使用关键词匹配进行文本分配）。研究对比了基于LLM的主题模型与神经主题模型（NTM）的表现，并探索零样本提示是否能提升NTM的效果，验证了“大多数NTM已过时”的说法是否成立。", "innovation": "提出了将主题建模定义为长文本生成任务的新范式；使用零样本提示直接利用LLM生成主题和相关文本；系统性比较了基于LLM的主题模型与传统神经主题模型在主题质量上的表现，验证了前者的优越性", "conclusion": "基于LLM的主题模型在主题建模任务中表现出色，优于传统的神经主题模型（NTM），证实了“大多数NTM已过时”的说法。"}
{"llm_update_time": "20251006", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.02483", "html_url": "https://arxiv.org/abs/2510.02483", "title": "Litespark 技术报告: 高吞吐量、低能耗的大语言模型训练框架", "title_en": "Litespark Technical Report: High-Throughput, Energy-Efficient LLM Training Framework", "authors": "Nii Osae Osae Dade,Moinul Hossain Rahat", "background": "训练大型语言模型（LLMs）面临长时间训练和高能耗的问题，现代模型需要数月的计算时间和大量的电力。因此，针对这些问题，作者提出了一种名为Litespark的新型预训练框架，通过针对变压器注意力层和MLP层的优化来提高效率。", "innovation": "Litespark框架结合了架构改进和算法优化，最大程度地利用模型FLOPs利用率（MFU），同时保持与标准变压器实现的兼容性。该框架在SlimPajama-627B数据集上对3B和30B参数的Llama模型进行全面基准测试，显示出显著的性能改进：多节点H200 GPU集群上的2到6倍训练吞吐量提升，并降低55%-83%的能耗。", "conclusion": "这些优化是模型和硬件无关的，可以在不同的变压器架构以及后训练阶段，包括监督微调和直接偏好优化中应用。"}
{"llm_update_time": "20251006", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.02320", "html_url": "https://arxiv.org/abs/2510.02320", "title": "WEE-Therapy: 弱编码器混合框架的心理咨询对话分析", "title_en": "WEE-Therapy: A Mixture of Weak Encoders Framework for Psychological Counseling Dialogue Analysis", "authors": "Yongqi Kang,Yong Zhao", "background": "计算心理学的进步需要具备深入理解咨询对话能力的AI工具。现有音频语言模型（AudioLLMs）往往依赖于预训练在通用数据上的单一语音编码器，难以捕捉特定领域的特征，如复杂的感情和专业技巧。现有的模型在情感识别、技术分类、风险检测和总结等方面表现不佳，无法满足临床分析的需求.", "innovation": "我们提出了WEE-Therapy，一种包含弱编码器集合（WEE）机制的多任务AudioLLM。WEE机制补充了一个强大的基础编码器，并提供了一个轻量级、专业化编码器的池。通过一种新的双路由策略，结合稳定的、与数据无关的领域知识和动态、与数据相关的专家选择。这项技术在情感识别、技术分类、风险检测和总结等多个任务上取得了显著的性能提升，同时参数量较少，显示出强大的潜在临床辅助分析能力.", "conclusion": "WEE-Therapy在所有任务中都实现了显著的性能提升，具备实现大规模临床辅助分析应用的潜力。"}
{"llm_update_time": "20251006", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.02319", "html_url": "https://arxiv.org/abs/2510.02319", "title": "通过量化对抗性扰动来建模攻击：检测AI生成的文本", "title_en": "Modeling the Attack: Detecting AI-Generated Text by Quantifying Adversarial Perturbations", "authors": "Lekkala Sai Teja,Annepaka Yadagiri,Sangam Sai Anish,Siva Gopala Krishna Nuthakki,Partha Pakray", "background": "高度先进的大型语言模型（LLMs）的出现引发了双重用途问题，亟需创建可靠的AI生成文本检测系统。现有的检测器往往容易受到对抗性攻击的影响，其中最有效的逃避技术之一是改写，它可以干扰统计检测。该论文旨在解决这一问题，通过量化标准对抗训练的局限性，并提出了一种新颖且更具有抗攻击性的检测框架——Perturbation-Invariant Feature Engineering (PIFE)，该框架通过多层次的标准化处理将输入文本标准化，然后使用编辑距离和语义相似度等度量标准来量化这些转换，并直接将这些信号提供给分类器。研究评估了常规加固的Transformer模型和PIFE增强模型在针对字符、词和句子级别的攻击中的表现。", "innovation": "提出了一种新的对抗性鲁棒性检测框架Perturbation-Invariant Feature Engineering (PIFE)，它首先通过多层次的标准化处理将输入文本标准化，接着使用编辑距离和语义相似度等度量标准来量化这些转换，并直接将这些信号提供给分类器。PIFE模型在保持高准确率的同时，能够有效抵御复杂的语义攻击，证明了建模扰动特征而非仅仅依赖对抗训练是实现真正鲁棒性的一种更有效的路径。", "conclusion": "PIFE模型在面对高级语义攻击时，保持了82.6%的True Positive Rate，这远高于仅通过对抗性训练的模型48.8%的True Positive Rate。研究结果表明，通过建模扰动特征而不是仅仅通过对抗训练来实现鲁棒性是更有效的途径。"}
{"llm_update_time": "20251006", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.03156", "html_url": "https://arxiv.org/abs/2510.03156", "title": "语言模型的神经对应物仅与人类语言相关", "title_en": "Neural Correlates of Language Models Are Specific to Human Language", "authors": "Iñigo Parra", "background": "先前的研究已经证明，大型语言模型的隐藏状态与功能性磁共振成像(fMRI)的大脑反应之间存在关联，并被视作神经表示相似性的证据。这项研究旨在检验这一结论是否robust（稳健）地经受住几个潜在问题的考验。", "innovation": "（i）即使经过降维，之前的结果仍然存在，这意味着这些发现并不是源于维度灾难；（ii）使用新的相似性度量，之前的结果仍然得到验证；（iii）大脑表示与模型之间的相关性仅限于人类语言训练的模型；（iv）研究结果依赖于模型中位置编码的存在。这些研究结果证实并加强了此前的研究成果，为先进大型语言模型的生物可行性和可解释性辩论做出了贡献。", "conclusion": "这些结果确认并强化了先前的研究发现，证明关于先进大型语言模型的生物可行性和可解释性辩论中的某些观点是正确的，增加了对其可靠性的理解。"}
{"llm_update_time": "20251006", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.02322", "html_url": "https://arxiv.org/abs/2510.02322", "title": "SpeechCT-CLIP: 向语音传授文本-图像知识以实现语音原生多模态CT分析", "title_en": "SpeechCT-CLIP: Distilling Text-Image Knowledge to Speech for Voice-Native Multimodal CT Analysis", "authors": "Lukas Buess,Jan Geier,David Bani-Harouni,Chantal Pellegrini,Matthias Keicher,Paula Andrea Perez-Toro,Nassir Navab,Andreas Maier,Tomas Arias-Vergara", "background": "语音交流在临床工作流程中扮演着核心角色。在放射学中，绝大多数报告是通过口述创建的。然而，几乎所有医疗AI系统都仅依赖书面文本。本研究旨在通过探索直接从口述放射学报告中学习视觉语言表示的可行性来填充这一空白。", "innovation": "本研究合成了一个大规模的口述放射学报告数据集（Speech-RATE），并训练了一个对比模型SpeechCT-CLIP，该模型在共享表示空间中对齐语音和3D CT体积。通过从预训练的文本-图像CLIP模型中获取知识蒸馏，实现了从文本到语音的语义对齐能力的有效转移，显著缩小了语音模型与文本模型之间的性能差距。", "conclusion": "实验结果显示，零样本分类F1分数从0.623提升到0.705，恢复了88%的性能差距，并且在无需文本的情况下仍取得强大的检索结果。这些发现强调了语音在多模态预训练中的实际应用替代文本，并为临床实践中语音驱动的诊断支持工具打开了大门。"}
{"llm_update_time": "20251006", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.02453", "html_url": "https://arxiv.org/abs/2510.02453", "title": "如何训练你的顾问：使用顾问模型引导黑盒大模型", "title_en": "How to Train Your Advisor: Steering Black-Box LLMs with Advisor Models", "authors": "Parth Asawa,Alan Zhu,Matei Zaharia,Alexandros G. Dimakis,Joseph E. Gonzalez", "background": "基础模型越来越多地被部署为黑盒服务，模型权重无法修改，只能通过提示进行定制。虽然静态提示优化显示出潜力，但生成的提示往往是固定的，不能适应不同的输入、用户或环境。为了解决这个问题，本文介绍了一种新的方法，通过使用强化学习训练的轻量级参数策略（即顾问模型），这些模型可以在上下文中反应性地提供自然语言的引导指令，以调整黑盒模型的行为。", "innovation": "本文提出了一种创新的解决方案，即Advisor Models（顾问模型）。这是一种轻量级且参数化的设计，通过强化学习训练，能够在黑盒模型之间和输入之间实时提供自然语言的引导指令，以根据不同实例的具体需求进行调整。相较于静态提示优化，它可以更好地适应不同的环境，发现环境动态，并提升下游任务的表现。此外，顾问模型还可以在不同的黑盒模型之间进行迁移，保持对未知输入的鲁棒性，展现出高度的定制化和稳定性能。", "conclusion": "顾问模型为黑盒系统提供了一个可学习的界面，顾问模型能够作为参数化的、环境特定的记忆体，动态地优化黑盒模型。这种方法为实现个性化和环境适应性的人工智能提供了前景广泛的可能性，能够达到前沿级别的能力。"}
{"llm_update_time": "20251006", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.02469", "html_url": "https://arxiv.org/abs/2510.02469", "title": "SIMSplat: 通过语言对齐的4D高斯点积进行预测性驾驶场景编辑", "title_en": "SIMSplat: Predictive Driving Scene Editing with Language-aligned 4D Gaussian Splatting", "authors": "Sung-Yeon Park,Adam Lee,Juanwu Lu,Can Cui,Luyang Jiang,Rohit Gupta,Kyungtae Han,Ahmadreza Moradipari,Ziran Wang", "background": "现有的驾驶场景生成框架在生成现实场景时面临效率低下的问题，主要是由于编辑能力有限。研究者们正在探索通过传感器数据驱动的场景操纵作为传统的虚拟驾驶模拟器的一个有前途的替代方案，但现有的框架无法高效地生成逼真的场景。", "innovation": "SIMSplat是一款通过语言对齐的Gaussian点积进行预测性驾驶场景编辑的方法。它通过自然语言提示使场景编辑更加直观，并通过将语言与Gaussian重建场景对齐，支持直接查询道路对象，从而允许精确和灵活的编辑。此外，SIMSplat还利用多智能体运动预测进行预测路径细化，生成场景中所有智能体之间真实的交互。", "conclusion": "实验证明，SIMSplat具有广泛的编辑能力，并且在不同场景下表现出良好的适应性。"}
{"llm_update_time": "20251006", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.03102", "html_url": "https://arxiv.org/abs/2510.03102", "title": "使用LLMs和NER来评估放射学报告的语义相似性", "title_en": "Semantic Similarity in Radiology Reports via LLMs and NER", "authors": "Beth Pearson,Ahmed Adnan,Zahraa Abdallah", "background": "放射学报告评估是放射医生培训中的关键部分，对于确保诊断准确性至关重要。在标准报告工作流程中，初级放射医生通常准备初步报告，然后由高级放射医生审阅和编辑以产生最终报告。识别初步报告与最终报告之间的语义差异对初级医生有教育意义，也能揭示临床知识上的缺口。虽然人工智能在放射学领域的应用迅速发展，但各大型语言模型（LLMs）应用面临挑战，因为需要特殊领域的专业知识。本文研究了LLMs在放射学领域对比报告时提供可解释和准确的比较的能力。", "innovation": "本文提出了Llama-EntScore方法，这是一种结合了LLama 3.1和命名实体识别（NER），并通过调整权重来强调或弱化特定类型差异的语义相似性评分方法。这种方法不仅生成一个量化相似性分数，以便于跟踪进度，还通过对分数的解释提供审查和改进报告的有价值指导。实验结果显示，该方法在精确匹配和±1误差准确性方面均优于独立使用的LLMs和NER。", "conclusion": "本文开发的Llama-EntScore方法在语义相似性评分方面表现出色，能够有效帮助放射医生对比和理解上报之间的差异，提高报告准确性和一致性，同时也提供了一种新的可解释性解决方案。"}
{"llm_update_time": "20251006", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.02342", "html_url": "https://arxiv.org/abs/2510.02342", "title": "CATMark：一种用于大型语言模型跨任务鲁棒水印的上下文感知阈值框架", "title_en": "CATMark: A Context-Aware Thresholding Framework for Robust Cross-Task Watermarking in Large Language Models", "authors": "Yu Zhang,Shuliang Liu,Xu Yang,Xuming Hu", "background": "现有的水印算法通过嵌入和检测隐藏的统计特征，有效地识别由机器生成的内容。然而，这种嵌入导致了文本质量的下降，尤其是在低熵场景中，性能需要提高。现有方法依赖于熵阈值，通常需要大量的计算资源进行调优，并且在未知或跨任务生成场景中表现出较差的适应性。", "innovation": "提出了一种新颖的上下文感知阈值水印（$\textbf{C}\textbf{A}\textbf{T}\textbf{Mark}$）框架，动态调整水印强度基于实时语义上下文。通过按logits聚类划分文本生成以实现上下文感知熵阈值，保持结构化内容的保真度同时嵌入鲁棒水印。该方法无需预定义阈值或特定任务的调优。实验表明，在跨任务中提高文本质量的同时，不影响检测准确率。", "conclusion": "通过实时语义上下文感知，$\textbf{C}\textbf{A}\textbf{T}\textbf{Mark}$框架在不需要预定义阈值或特定任务调优的情况下，提高了跨任务文本的质量，且不影响检测准确率，实现了在低熵场景下的性能改进。"}
{"llm_update_time": "20251006", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.02571", "html_url": "https://arxiv.org/abs/2510.02571", "title": "视频模型有多自信？赋予视频模型表达不确定性的能力", "title_en": "How Confident are Video Models? Empowering Video Models to Express their Uncertainty", "authors": "Zhiting Mei,Ola Shorinwa,Anirudha Majumdar", "background": "生成视频模型展示了令人印象深刻的从文本到视频的能力，广泛应用于许多实际应用场景中。然而，与大型语言模型类似，视频生成模型倾向于生成虚构内容，即便这些内容在事实上有误。尽管前人研究充分探讨了大型语言模型的不确定性量化（UQ），但目前尚无针对视频模型的UQ方法，这引发了一些重要的安全问题。我们知道，这项研究是首项量化视频模型不确定性的工作。", "innovation": "本文提出了一种框架，用于量化生成视频模型的不确定性，包括（i）基于稳健秩相关估算的评估方法，无需严格的建模假设；（ii）一种针对视频模型的黑盒UQ方法（称为S-QUBED），利用潜在建模严格分解预测不确定性为类概率性和先验不确定性组成部分；（iii）一个用于视频模型基准测试的UQ数据集。通过在潜在空间中条件生成任务，研究将由任务说明不明确产生的不确定性与知识不足产生的不确定性分离。通过在基准视频数据集上的广泛实验，显示S-QUBED计算的校准总不确定性估计与任务准确性呈负相关，并有效地计算了类概率性和先验性组成部分。", "conclusion": "S-QUBED能够在基准视频数据集上计算出与任务准确性呈负相关的校准总不确定性估计，并有效计算类概率性和先验性组成部分。这一研究工作很好地展示了对视频生成模型的不确定性量化的必要性和方法的有效性。"}
{"llm_update_time": "20251006", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.02721", "html_url": "https://arxiv.org/abs/2510.02721", "title": "Hyperparameter Loss Surfaces Are Simple Near their Optima", "title_en": "Hyperparameter Loss Surfaces Are Simple Near their Optima", "authors": "Nicholas Lourie,He He,Kyunghyun Cho", "background": "超参数极大地影响模型的能力，但现代模型规模太大，无法进行广泛的搜索。研究者们设计了基于对超参数理解的训练方案，能够在不同规模下表现良好。然而，目前缺乏工具来理解超参数损失面。本文通过发现超参数损失面中全新的结构，并提出一种新的理论来提供此类工具，解决了这一问题。", "innovation": "本文提出了一个新的理论，利用随机搜索开发了新的技术，发现在最优值附近超参数损失面具有简单的结构，并据此推导出一种新的渐进定律，该定律能解释和外推随机搜索的收敛性。这些新型工具还使得可以用于确定最佳性能的信心区间或有效超参数的数量等新分析。", "conclusion": "本文提出的新工具能够提供关于最佳性能的信心区间，或者确定有效超参数的数量等新的分析。研究人员将这些工具发布在：this https URL。"}
{"llm_update_time": "20251006", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.02611", "html_url": "https://arxiv.org/abs/2510.02611", "title": "关于温度采样在测试时缩放中的作用", "title_en": "On the Role of Temperature Sampling in Test-Time Scaling", "authors": "Yuheng Wu,Azalia Mirhoseini,Thierry Tambe", "background": "大语言模型（LLMs）通过测试时缩放（TTS）在推理时可以提高推理能力，即生成多个推理路径并选择最好的一个。先前的研究表明，增加样本数量K可以逐步提高准确度。本文研究发现，当K增大到一定程度后，进一步的缩放不再带来提升，并且某些难题不会因增加样本数量而解决。不同温度的采样能够解决不同问题的子集，表明单一温度缩放仅探索了模型潜力的一部分。", "innovation": "本文提出沿温度维度进行缩放的策略，以扩展LLMs的推理边界。这一策略在Qwen3（0.6B, 1.7B, 4B, 8B）和五个代表性推理基准（AIME 2024/2025, MATH500, LiveCodeBench, Hi-ToM）上的表现优于单一温度缩放，且可以使得基础模型达到与强化学习（RL）训练的模型相近的性能，而不需要额外的后训练步骤。此外，还对这一现象进行了全面分析，并设计了多温度投票方法来降低温度缩放的开销。", "conclusion": "本研究发现TTS比传统认为的更具有强大的潜力，并提出温度缩放是一种简单且有效的方法，能够解锁基础模型的潜在能力。"}
{"llm_update_time": "20251006", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.02816", "html_url": "https://arxiv.org/abs/2510.02816", "title": "NCV：一种低成本结构化错误定位的节点级一致性验证方法", "title_en": "NCV: A Node-Wise Consistency Verification Approach for Low-Cost Structured Error Localization in LLM Reasoning", "authors": "Yulong Zhang,Li Wang,Wei Du,Peilin Li,Yuqin Dai Zhiyuan Zhao,Lingyong Fang,Ziniu Liu,Ru Zhang,Huijia Zhu,Gongshen Liu", "background": "在大型语言模型（LLM）中验证多步推理是具有挑战性的，因为错误定位不精确且标记成本高。现有方法要么评估整个推理链，导致注意力稀释，要么依赖于昂贵的多采样。", "innovation": "引入了一种无需训练的节点级一致性验证（NCV）框架，将其重新定义为在节点层面进行的轻量级二元一致性检查。通过将推理链分解为相互连接的验证节点，NCV能够精确定位错误并避免不必要的长文本生成。", "conclusion": "实验表明，我们的方法提高了可解释性和效率，提供了一种可扩展的解决方案以实现可靠的LLM推理验证。NCV在公共数据集上比基线方法在F1分数上提高了10%到25%，同时比传统方法（如基于CoT的验证器）使用6倍到58倍 fewer tokens。"}
{"llm_update_time": "20251006", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.02837", "html_url": "https://arxiv.org/abs/2510.02837", "title": "超越最终答案：工具增强代理推理轨迹的评估", "title_en": "Beyond the Final Answer: Evaluating the Reasoning Trajectories of Tool-Augmented Agents", "authors": "Wonjoong Kim,Sangwu Park,Yeonjun In,Sein Kim,Dongha Lee,Chanyoung Park", "background": "尽管目前的工具增强基准测试包含复杂的用户请求和多样的工具，大多数评估方法仍局限于答案匹配。然而，要解决一个用户请求所需的步骤越多，评估代理性能不应仅限于最终答案，还需要评估问题解决轨迹，包括效率、幻觉和适应性等以前被忽视的方面。直接通过比较代理的轨迹与真实的轨迹来进行评估虽直观，但由于所有可能的真实轨迹的注释成本高昂，只能部分实现。因此，缺乏一个详细的轨迹评估方法，尤其没有有效的工具来进行此类评估。", "innovation": "本文提出了TRACE，一种评估工具增强LLM代理性能的多维度框架。TRACE通过引入证据库，自动积累和更新代理推理过程中获得的知识和证据，从而实现实时的官方轨迹对比，评估代理的多方面表现。通过创建一个新的元评估数据集，将不同的、可能存在缺陷的真实轨迹标签化，验证了TRACE能以可扩展和成本效益高的方式准确评估复杂的代理行为，即使使用小规模开源LLM也可实现。", "conclusion": "通过TRACE框架，本文成功验证了对包含多种复杂行为的真实生成轨迹的高效评估能力。不仅展示了这种方法的可行性，还对代理生成的轨迹进行了评估，提供了未报告的新观察结果和见解，为工具增强代理的性能评估开辟了新路径。"}
{"llm_update_time": "20251006", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.02630", "html_url": "https://arxiv.org/abs/2510.02630", "title": "HyperAdaLoRA：通过超网络加速训练期间的LoRA秩分配而不牺牲性能", "title_en": "HyperAdaLoRA: Accelerating LoRA Rank Allocation During Training via Hypernetworks without Sacrificing Performance", "authors": "Hao Zhang,Zhenjia Li,Runfeng Bao,Yifan Gao,Xi Xiao,Bo Huang,Yuhang Wu,Tianyang Wang,Hao Xu", "background": "参数高效微调（PEFT），特别是低秩适应（LoRA），已经在减少计算和内存开销的同时对大型语言模型（LLMs）进行微调方面展现出潜力。然而，LoRA 假设每个增量矩阵的均匀秩 r，但没有考虑到不同模块和层之间的权重矩阵的重要性差异。AdaLoRA 利用奇异值分解（SVD）进行参数化更新并采用奇异值剪枝来引入动态秩分配，从而提高适应性。但在训练过程中常常遇到收敛速度慢和高计算开销的问题。", "innovation": "提出了一种新的框架HyperAdaLoRA，通过利用基于注意机制的超网络加速AdaLoRA的收敛速度。超AdaLoRA不直接优化SVD的组件(P, Λ, Q)，而是使用基于注意力机制的超网络动态生成这些参数。通过剪枝生成奇异值的超网络的输出，实现动态秩分配。", "conclusion": "在各种数据集和模型上进行的全面实验表明，我们的方法能够更快地收敛而不会牺牲性能。进一步的扩展实验也验证了我们方法在其他LoRA基方法中的广泛适用性。"}
{"llm_update_time": "20251006", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.03204", "html_url": "https://arxiv.org/abs/2510.03204", "title": "FocusAgent：简洁有效的方法裁剪Web代理的大容量上下文", "title_en": "FocusAgent: Simple Yet Effective Ways of Trimming the Large Context of Web Agents", "authors": "Imene Kerboua,Sahar Omidi Shayegan,Megh Thakkar,Xing Han Lù,Léo Boisvert,Massimo Caccia,Jérémy Espinas,Alexandre Aussem,Véronique Eglin,Alexandre Lacoste", "background": "网络代理由大规模语言模型（LLMs）驱动，需要处理大量网页观察以完成用户目标；这些页面通常超过数十万tokens。这不仅会饱和上下文限制，增加计算成本，还使代理面临如提示注入等安全风险。现有的剪枝策略要么丢弃相关内容，要么保留无关上下文，导致预测动作效果不佳。", "innovation": "提出了一种名为FocusAgent的简单而有效的策略，利用轻量级的LLM检索器从无障碍树（AxTree）观察中提取最相关的行，同时根据任务目标进行指导。通过修剪噪声和无关的内容，FocusAgent能够促进高效的推理并减少注入攻击的脆弱性。在WorkArena和WebArena基准测试中，FocusAgent在减少观察规模超过50%的情况下性能与强大基线匹配，并且其变体显著降低了提示注入攻击的成功率，即使在未受攻击的情况下也保持了任务成功率。", "conclusion": "结果表明，针对LLM的检索是一个在构建高效、有效且安全的网络代理方面的实用且健壮的策略。"}
{"llm_update_time": "20251006", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.02493", "html_url": "https://arxiv.org/abs/2510.02493", "title": "从演示中恢复密集奖励：超越模仿", "title_en": "Beyond Imitation: Recovering Dense Rewards from Demonstrations", "authors": "Jiangnan Li,Thuy-Trang Vu,Ehsan Abbasnejad,Gholamreza Haffari", "background": "传统上，监督微调（SFT）被视为一种简单的模仿学习过程，仅仅训练一个政策去模仿专家在演示数据集中行为。本文挑战这一观点，通过建立SFT和逆强化学习的基本等价性来确立新的视角。本文证明SFT的目标是逆Q学习的一个特殊案例，这意味着SFT过程不仅学习一个策略，还隐含地学习一个密集的、词级的奖励模型来解释专家的演示。接着，本文通过直接从SFT模型中推导出一个基于基线的奖励函数，表明如何恢复密集奖励信号。这样的密集奖励模型为每个生成的词提供细粒度的信用分配，提供了巨大的优势。", "innovation": "本文挑战了将SFT视为简单的模仿学习过程的传统观点，提出了一种新的视角，认为SFT实际上等同于逆强化学习，并证明了SFT不仅学习策略，还隐含地学习一个密集的、词级的奖励模型来解释专家的演示。研究还提出了一种新的方法，通过直接从SFT模型中恢复密集奖励信号，实现了进一步使用强化学习改进策略。这种新方法在指令遵循基准测试中一致优于原始SFT模型。将SFT重新定义为不仅仅是策略模仿，而是强大的奖励学习机制，为利用专家演示开拓了新的可能性。", "conclusion": "本文方法Dense-Path REINFORCE在指令遵循基准测试中一致优于原始SFT模型。该研究将SFT重新定义为不仅仅是策略模仿，而是强大的奖励学习机制，为利用专家演示提供了新的可能。"}
{"llm_update_time": "20251006", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.02790", "html_url": "https://arxiv.org/abs/2510.02790", "title": "MaskCD: 通过图像头部掩蔽对比解码减轻LVLM幻觉现象", "title_en": "MaskCD: Mitigating LVLM Hallucinations by Image Head Masked Contrastive Decoding", "authors": "Jingyuan Deng,Yujiu Yang", "background": "大型视觉-语言模型（LVLMs）在下游多模态任务中的视觉-语言理解方面表现出色。随着这些模型能力的提升，一些问题也开始显现，其中幻觉现象是最引人关注的一个问题。幻觉指的是LVLMs生成与其输入的视觉和文本内容相矛盾的内容。此前，研究人员提出了一些解决策略，例如对比解码和注意力操控，但这些方法也存在不足，比如对比解码方法难以生成合适的对比样本，而注意力操控方法则不稳定，过敏感。因此，本文提出了一种新的方法，即图像头部掩蔽对比解码（MaskCD）。", "innovation": "本文提出了一种名为MaskCD的新方法，利用大型视觉-语言模型中的‘图像头部’，通过掩蔽方法构建对比样本，用于对比解码。这种方法有效缓解了幻觉现象，并保留了大型视觉-语言模型的通用能力。已经对LLaVA-1.5-7b 和 Qwen-VL-7b进行了评估，并使用各种基准测试了该方法的效果，如CHAIR、POPE、AMBER和MME。", "conclusion": "实验结果表明，MaskCD能够有效缓解幻觉现象并保留LVLMs的基本能力。相关资源可以在提供的链接中找到。"}
{"llm_update_time": "20251006", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.03182", "html_url": "https://arxiv.org/abs/2510.03182", "title": "规则到模拟：一种用于正式视觉规划的双重VLM框架", "title_en": "Simulation to Rules: A Dual-VLM Framework for Formal Visual Planning", "authors": "Yilun Hao,Yongchao Chen,Chuchu Fan,Yang Zhang", "background": "视觉语言模型(VLMs)在视觉规划方面表现出强大的潜力，但在精确的空间和长时量化推理方面存在困难。相比之下，规划定义语言(PDDL)规划器在长时量化规形式规划方面表现出色，但无法解释视觉输入。现有的研究通过使VLMs能够将视觉规划问题转换为PDDL文件以进行正式规划，结合了这两者的优点，但VLMs在生成PDDL规则文件方面存在困难，因此先前的方法依赖于人类专家预先定义的规则文件或持续的环境访问以进行完善。", "innovation": "本文提出了VLMFP (Dual-VLM guided framework)，这是一个能够自主生成PDDL问题和领域文件的双重VLM指导框架。VLMFP引入了两个VLM：SimVLM根据输入规则描述模拟动作后果，以及GenVLM通过比较PDDL和SimVLM执行结果生成和迭代细化PDDL文件。VLMFP在多个层次上增加了泛化性：生成的PDDL领域文件可以应用于同一问题的不同实例，VLMs可以推广到具有不同外观和规则的不同问题。", "conclusion": "在六个网格世界的领域中测试了VLMFP，并评估了其对未见实例、外观和游戏规则的推广能力。SimVLM在描述场景和模拟动作序列方面表现良好，VLMFP在未见实例和未见外观中分别生成的有效计划成功率达到70.0%和54.1%。"}
{"llm_update_time": "20251006", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.03206", "html_url": "https://arxiv.org/abs/2510.03206", "title": "共进化连续离散扩散模型：让你的扩散语言模型成为一个隐空间推理者", "title_en": "Coevolutionary Continuous Discrete Diffusion: Make Your Diffusion Language Model a Latent Reasoner", "authors": "Cai Zhou,Chenxiao Yang,Yi Hu,Chenyu Wang,Chubin Zhang,Muhan Zhang,Lester Mackey,Tommi Jaakkola,Stephen Bates,Dinghuai Zhang", "background": "扩散语言模型，尤其是掩码的离散扩散模型，近期取得了巨大成功。尽管存在一些理论和初步的实验结果支持在循环变压器或连续思维链中进行潜在推理的优势，但连续扩散模型通常在性能上不如其离散的同类。本文作者认为扩散模型并不一定局限于离散空间。", "innovation": "证明了连续扩散模型在表达能力上优于离散扩散和循环变压器。作者将理论上的表达能力和实际表现差异归因于其在实践中的可训练性问题。基于此，提出了共进化连续离散扩散（CCDD），其在联合连续表示空间和离散令牌空间上定义了一种联合多模扩散过程。并通过结合两种模态，CCDD 收到了丰富的潜在空间语义，且在使用显式离散令牌的帮助下，表现出良好的可训练性和样本质量。", "conclusion": "实验结果表明，CCDD 在实际任务的语言建模实验中展现出强大的实际性能。"}
{"llm_update_time": "20251006", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.02657", "html_url": "https://arxiv.org/abs/2510.02657", "title": "减少LLM，增加文档：寻求改进的RAG", "title_en": "Less LLM, More Documents: Searching for Improved RAG", "authors": "Jingjie Ning,Yibo Kong,Yunfan Long,Jamie Callan", "background": "RAG结合了文档检索和大规模语言模型。虽然增加生成器规模可以提高准确性，但也增加了成本并限制了部署性。本研究探索了一个不同的方向，即增加检索器的文档库以减少对大规模LLM的依赖。实验结果显示，随着文档库规模的扩展，RAG性能得到增强，并且在某些情况下可以替代模型规模的增加，但随着规模的增大，这种效果逐渐减弱。结合大型和中型生成器与大型文档库往往能够与小型生成器对比表现相似；中型模型从中获得的改进最大，而小型和大型模型从中获益较少。研究发现，主要的改进来自于对答案相关段落覆盖范围的增加，而利用率效率变化不大。这些发现确认了生成器-文库权衡的有效原理：投资更大规模的文库是增强RAG的有效路径，有时甚至可以与自身扩大LLM规模相匹敌。", "innovation": "该研究探索了减少对大规模LLM的依赖，通过增加检索器的文档库来改善RAG性能。实验表明，在某些情况下，扩展文档库的效果可以替代增加模型规模，但这种效果在大规模时逐渐减弱。研究证明了增加文档覆盖范围是主要的改进来源，而利用率效率变化不大。这为RAG的生成器-文库权衡提供了一个有原则的方案，展示了投资更大文库是增强RAG的有效方法，有时甚至可以与扩展LLM规模相媲美。", "conclusion": "研究发现了扩大文档库规模可以有效提高RAG性能，并能够在某些情况下替代扩大模型规模。这种改进主要是通过增加答案相关段落的覆盖范围实现的，而利用率效率并未显著变化。这表明，投资更大规模的文库是增强RAG的有效路径，有时甚至可以与自身扩展LLM规模相提并论。"}
{"llm_update_time": "20251006", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.02768", "html_url": "https://arxiv.org/abs/2510.02768", "title": "模型消除下的细粒度安全预训练研究", "title_en": "A Granular Study of Safety Pretraining under Model Abliteration", "authors": "Shashank Agnihotri,Jonas Jakubassa,Priyam Dey,Sachin Goyal,Bernt Schiele,Venkatesh Babu Radhakrishnan,Margret Keuper", "background": "大规模语言模型可以在推理时通过简单的激活编辑进行修改，这引发了安全性方面的一个实际问题：常见的安全干预措施，如拒绝训练或元标签训练，是否能抵抗这种修改？本研究通过研究模型消除技术，一种设计用于移除拒绝敏感方向的轻量级投影技术，评估了SmolLM2-1.7B安全预训练检查点及其常用开源基准的安全性。研究者对每种系统（原始和消除后的系统）进行了100次带有平衡有危害和无危害情况的提示，并使用多名评判者对响应进行分类，通过一个小的人工标记子集验证评判者的一致性。研究还探讨了模型是否能够识别其自身的拒绝输出。", "innovation": "开发了一种轻量级的技术——模型消除，用于移除拒绝敏感方向；系统地评估安全预训练的每个检查点，发现哪些基于数据的安全组件在消除过程中依然稳健；量化评判者选择对评估结果的影响；提出了将推理时的编辑整合到安全性评估中的实践指南。", "conclusion": "研究结果对评估安全预训练技术的稳健性具有重要意义，提出了集成推理时编辑的安全评估协议，并为进一步研究安全预训练提供了指导。"}
{"llm_update_time": "20251006", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.03178", "html_url": "https://arxiv.org/abs/2510.03178", "title": "代码命名消失时：揭示LLMs实际理解代码的内容", "title_en": "When Names Disappear: Revealing What LLMs Actually Understand About Code", "authors": "Cuong Chi Le,Minh V.T. Pham,Cuong Duc Van,Hoang N. Phan,Huy N. Phan,Tien N. Nguyen", "background": "大型语言模型（LLMs）在代码任务上取得了显著成果，但它们如何推导程序含义仍然不清楚。本文讨论了代码通过两种通道进行交流：结构性语义，即定义形式行为，以及人类可解释的命名，即传达意图。去除命名通道在摘要等意图层面的任务中严重降低了任务性能，而模型退化为逐行描述。出乎意料的是，本文还观察到对仅依赖结构的任务也表现出一致性性能下降，表明当前基准测试倾向于奖惩命名模式的记忆，而非真正的语义推理。为了区分这些效果，引入了一组语义保持的混淆方法，并展示它们在总结和执行任务中暴露了标识符的泄漏。", "innovation": "本文引入了一组语义保持的混淆方法，并展示了这些方法在总结和执行任务中暴露了标识符的泄漏。构建在此洞见之上，本文发布了ClassEval-Obf，这是一个基于混淆增强的基准，系统地抑制命名线索，同时保持行为。结果表明，ClassEval-Obf减少了性能差异的虚高，削弱了记忆捷径，并为评估LLMs的代码理解和泛化提供了一个更可靠的基础。", "conclusion": "ClassEval-Obf减少了性能差异的虚高，削弱了记忆捷径，并为评估LLMs的代码理解和泛化提供了一个更可靠的基础。"}
{"llm_update_time": "20251006", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.02795", "html_url": "https://arxiv.org/abs/2510.02795", "title": "Pareto-optimal Non-uniform Language Generation", "title_en": "Pareto-optimal Non-uniform Language Generation", "authors": "Moses Charikar,Chirag Pabbaraju", "background": "Kleinberg和Mullainathan（2024）提出了语言生成在极限条件下的模型：给定一组可数的语言集合，以及一个对手按某种语言$L$中的字符串顺序枚举字符串，目标是从目标语言生成新的字符串，确保所有从某个有限时间之后生成的字符串都是有效的。Li等人（2024）和Charikar和Pabbaraju（2024）在该模型中展示了强的非均匀生成保证，提供的算法在看到一定数量的不同输入字符串后可以生成新的有效字符串，该数量仅取决于$L$（以及集合），而不依赖于枚举顺序。然而，这两种工作的算法在语言层面的生成时间$t(L)$可能是严格亚最优的。", "innovation": "本文研究了非均匀语言生成在极限条件下的帕累托最优性。提出了一种算法，其生成时间$t^\text{star}(L)$（几乎）是帕累托最优的：对于任何其他算法，如果该算法在某语言$L$上的生成时间严格小于$t^\text{star}(L)$，则必须在其在另一语言$L'$上的生成时间严格劣于$t^\text{star}(L')$。我们的算法框架还可以适应噪声以及代表性生成等实际应用需求，提供最优的非均匀生成算法。帕累托最优性是对于非均匀生成所能实现的最优结果。", "conclusion": "研究结果表明，通过优化算法生成时间，可使非均匀语言生成算法在有限的时间内达到最优效果，且该算法框架还适用于噪声及代表性生成条件下。"}
{"llm_update_time": "20251006", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2502.11400", "html_url": "https://arxiv.org/abs/2502.11400", "title": "在强语言模型时代复杂鲁棒RAG训练的收益递减", "title_en": "On the Diminishing Returns of Complex Robust RAG Training in the Era of Powerful LLMs", "authors": "Hanxing Ding,Shuchang Tao,Liang Pang,Zihao Wei,Liwei Chen,Kun Xu,Huawei Shen,Xueqi Cheng", "background": "RAG系统通常采用复杂的训练策略来增强其对检索噪声的鲁棒性。本文探讨了随着语言模型能力增强，复杂训练策略带来的鲁棒性益处是否也会下降。", "innovation": "本文通过系统评估多个模型规模和问答数据集，发现随着模型容量增加，复杂训练策略带来的少量鲁棒性改善显著减少。更强大的模型在简单训练下也表现出更好的性能，包括更好的置信度校准、跨数据集泛化能力和更有效的注意力模式。", "conclusion": "研究表明，随着基础模型的发展，专注于复杂鲁棒训练的工程努力可能不会带来更多的回报，因此对强大模型而言，简化RAG管道可以保持竞争力的同时减少复杂性。"}
{"llm_update_time": "20251006", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2403.03923", "html_url": "https://arxiv.org/abs/2403.03923", "title": "Did Translation Models Get More Robust Without Anyone Even Noticing?", "title_en": "Did Translation Models Get More Robust Without Anyone Even Noticing?", "authors": "Ben Peters,André F.T. Martins", "background": "神经机器翻译（MT）模型在各种场景中表现出色，但普遍认为这些模型对诸如拼写错误、缩写和其他格式问题等“噪声”输入非常敏感。然而，最近的研究发现，使用多语言神经机器翻译模型和大规模语言模型（LLMs）应用于机器翻译时，这些模型对多种噪声的鲁棒性比之前认为的要强得多，即使在处理干净数据时两者的性能相当。", "innovation": "通过受控实验展示了这些模型对多种噪声的鲁棒性更强，即使这些模型参数更多且训练过程更复杂。作者指出，尽管LLM使用的技术并不专门设计用于提高鲁棒性，但在社交媒体文本的翻译实验中，这些模型也显示出更强的鲁棒性。此外，分析了在何种情况下源文本的校正技术可以用来缓解噪声的影响。", "conclusion": "总之，这些研究表明了多种类型噪声的鲁棒性已经增强。"}
{"llm_update_time": "20251006", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2503.07044", "html_url": "https://arxiv.org/abs/2503.07044", "title": "DatawiseAgent: 一种面向笔记本的LLM代理框架，用于适应性和稳健的数据科学自动化", "title_en": "DatawiseAgent: A Notebook-Centric LLM Agent Framework for Adaptive and Robust Data Science Automation", "authors": "Ziming You,Yumiao Zhang,Dexuan Xu,Yiwei Lou,Yandong Yan,Wei Wang,Huaming Zhang,Yu Huang", "background": "现有的大型语言模型（LLM）代理在自动化数据科学方面表现出潜力，但它们仍然受到任务范围狭窄、任务和模型之间的一般化有限以及过度依赖于最先进的（SOTA）LLM的限制。", "innovation": "DatawiseAgent是一种面向笔记本的数据科学自动化代理框架，它通过统一的交互表示和基于有限状态转换器（FSTs）的多阶段架构来提升灵活性、逐步开发解决方案和从执行失败中恢复的能力。", "conclusion": "广泛的实验表明，DatawiseAgent能够在各种数据科学场景和模型中始终超越AutoGen和TaskWeaver等强基线，并展现出更好的有效性和适应性。然而，在使用较弱或较小的模型时，性能会逐渐下降，这进一步证明了其稳健性和可扩展性。"}
{"llm_update_time": "20251006", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2503.10620", "html_url": "https://arxiv.org/abs/2503.10620", "title": "从TOWER到SPIRE：将语音模态添加到纯文本LLM", "title_en": "From TOWER to SPIRE: Adding the Speech Modality to a Text-Only LLM", "authors": "Kshitij Ambilduke,Ben Peters,Sonal Sannigrahi,Anil Keshwani,Tsz Kin Lam,Bruno Martins,André F.T. Martins,Marcely Zanon Boito", "background": "介绍了Spire，一种能够将英语语音输入翻译和转录为10种其他语言，以及双向翻译文本输入的语言模型。Spire通过语音离散化和仅使用42.5小时的语音数据进行持续预训练，将语音模态整合到现有多种语言模型中。", "innovation": "采用多语言模型的预训练框架，将离散化语音输入视为额外的翻译语言，不仅赋予模型语音能力，还保持了其强大的文本表现。这种方法比现有语音模型使用更少的数据，证明了在模型适应过程中将离散的语音输入作为额外语言进行集成是可行的。", "conclusion": "这种方法展示了在显著减少数据的情况下实现语音和文本翻译的能力，并向社区提供了代码和模型。"}
{"llm_update_time": "20251006", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2503.21718", "html_url": "https://arxiv.org/abs/2503.21718", "title": "不是烦恼而是有用的启发式方法：异常维度偏好频繁词汇的语言模型", "title_en": "Not a nuisance but a useful heuristic: Outlier dimensions favor frequent tokens in language models", "authors": "Iuri Macocco,Nora Graichen,Gemma Boleda,Marco Baroni", "background": "研究中指出，最后一层的异常维度，即在大多数输入下显示极端激活的维度。这些异常维度在许多现代语言模型中普遍存在，并且其功能可以追溯到始终预测常用词汇的启发式方法。研究进一步探讨了当这种启发式方法不适用于上下文时，模型如何通过赋予其余维度反向的权重来阻止这种启发式方法。", "innovation": "研究揭示了一个模型如何在不合适的上下文中通过赋予其余维度反向的权重来阻止这种始终预测常用词汇的启发式方法。研究还调查了哪些模型参数能够促进异常维度的激活情况，以及它们在训练过程中何时出现。", "conclusion": "研究结论认为，异常维度是许多不同模型发现的一种专门机制，用于实现有用的词汇预测启发式方法。"}
{"llm_update_time": "20251006", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2503.04697", "html_url": "https://arxiv.org/abs/2503.04697", "title": "L1: 使用强化学习控制推理模型思考时间", "title_en": "L1: Controlling How Long A Reasoning Model Thinks With Reinforcement Learning", "authors": "Pranjal Aggarwal,Sean Welleck", "background": "现有的语言模型在测试时表现出了通过延长“思考时间”（即生成更长的链式思维序列并消耗更多计算资源）来改进性能的能力，但这并不可控，使得测试时的计算资源难以调整到达到预期的性能水平。研究人员希望开发一种方法，可以在控制模型生成的链式思维长度的同时保持或提升模型的准确性。", "innovation": "作者提出了一种名为 ‘长度可控策略优化’ (LCPO) 的简单强化学习方法，该方法旨在优化模型的准确性和对其生成的链式思维长度的用户指定约束的遵守情况。利用LCPO方法训练了L1模型，它能够在提示中给定长度限制的情况下生成满足长度约束的输出。L1模型能够平滑地在不同任务上权衡计算成本和准确性，表现出优于现有方法S1的性能。此外，作者还发现使用LCPO训练的模型具有一个意外的能力，即短链式思维模型（SRMs），在链式思维长度上可与非推理模型媲美。", "conclusion": "LCPO方法允许对推理长度进行精确控制，从而细粒度地分配测试时的计算资源和性能。研究者还展示了1.5B的L1模型在等长链式思维长度下超越了GPT-4o的显著性能提升，这种方法将有助于精细调整语言模型的表现，可在测试时有效分配计算资源以达到最佳性能。"}
{"llm_update_time": "20251006", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2503.13445", "html_url": "https://arxiv.org/abs/2503.13445", "title": "关于大小和能力对语言模型自我解释忠实度的影响及冗余性权衡", "title_en": "Verbosity Tradeoffs and the Impact of Scale on the Faithfulness of LLM Self-Explanations", "authors": "Noah Y. Siegel,Nicolas Heess,Maria Perez-Ortiz,Oana-Maria Camburu", "background": "语言模型（LLMs）在提供决策解释时往往听起来合理，但这些解释是否真实反映了作出决策的因素却是一个关键问题。这篇文章分析了75个不同家族的75个模型的逆向事实忠实度，探讨了简洁性和全面性之间的权衡、相关性忠实度度量方法如何评估这种权衡，以及目前度量方法的局限性。研究表明，更大、更强大的模型在所有考虑的度量指标上表现出更高的忠实度。", "innovation": "文章提出了两个新指标：简化的相关反事实测试（phi-CCT），这是一种简化版的反事实测试，不需要考虑单个词的概率，但仍能解释原始测试的主要方差；以及F-AUROC指标，这是一种减少对比干预分布敏感性的方法，能够捕捉模型生成不同详细水平解释的能力。此外，研究发现规模对LLMs自我解释的忠实度有显著正向影响。", "conclusion": "更大、更强大的模型在所有考虑的忠实度指标上表现更好。研究表明，LLMs的自我解释的忠实度与模型规模之间存在明显的扩增趋势。文章的代码可以在指定的网址找到以供进一步研究和使用。"}
{"llm_update_time": "20251006", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2502.14837", "html_url": "https://arxiv.org/abs/2502.14837", "title": "向经济推理迈进：在任何基于Transformer的LLMs中启用DeepSeek的多头潜在注意力", "title_en": "Towards Economical Inference: Enabling DeepSeek's Multi-Head Latent Attention in Any Transformer-based LLMs", "authors": "Tao Ji,Bin Guo,Yuanbin Wu,Qipeng Guo,Lixing Shen,Zhan Chen,Xipeng Qiu,Qi Zhang,Tao Gui", "background": "现有的大型语言模型（LLMs）如Llama采用标准的多头注意力（MHA）机制，这导致了成本显著增加，尤其是在关键值（Key-Value，KV）缓存的压缩方面。相比之下，DeepSeek提出的多头潜在注意力（MLA）通过显著压缩KV缓存为潜在向量，实现了更高效、更经济的推理。进一步地，现有模型如Llama需要从零开始重新训练以适应MLA，这对于高效地迁移现有训练好的LLM是具有挑战性的。本文分析了启用MLA技术的必要性和现有解决方案的局限性。", "innovation": "本文提出了一种数据高效的微调方法MHA2MLA，旨在使预训练好的LLM如Llama快速适应MLA而无需从头开始重新训练。该方法包括两部分内容：部分正弦位置编码（partial-RoPE，即移除对关注分数贡献较小的查询和键的RoPE）和低秩近似（基于预训练参数的键和值进行联合SVD近似）。这些经过精心设计的策略使得MHA2MLA仅使用少量数据（0.3%-0.6%）就能恢复相当的性能，同时大幅减少了推理成本，并能无缝与KV缓存量化等压缩技术结合使用。例如，Llama2-7B的KV缓存大小被减少了92.19%，性能只下降了0.5%（基于LongBench）.", "conclusion": "通过MHA2MLA方法，预训练的LLM可以有效地迁移转换至MLA架构，从而在保持相近性能的同时大幅降低成本。这种无缝集成策略也为其他基于Transformer的LLMs提供了在高效率和高经济性方面潜在的便捷方法。"}
{"llm_update_time": "20251006", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2502.18331", "html_url": "https://arxiv.org/abs/2502.18331", "title": "BottleHumor：基于信息瓶颈原则的自我启发式幽默解释", "title_en": "BottleHumor: Self-Informed Humor Explanation using the Information Bottleneck Principle", "authors": "EunJeong Hwang,Peter West,Vered Shwartz", "background": "幽默在网络交流中普遍存在，且往往涉及多种模态（如卡通和表情包）。从多种模态下的幽默中进行解释需要调动不同的知识类型，包括文字比喻、社会文化及常识知识。然而，判断哪种知识最为有用还是一个待解决的问题。", "innovation": "作者提出了一种名为‘方法’（Method）的方法，该方法灵感来自于信息瓶颈原则，可以从视觉和语言模型中提炼相关的世界知识，并不断迭代优化，以生成无监督的幽默解释。实验表明，该方法在多个数据集上优于多种基准方法。这种方法未来还可以适用于需要提取和利用相关世界知识的其他任务，开辟新的研究方向.", "conclusion": "我们的实验结果证实了该方法的优势，并且该方法在未来可以扩展应用于其他可以从相关世界知识中受益的任务中，从而打开新的研究方向。"}
{"llm_update_time": "20251006", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.03222", "html_url": "https://arxiv.org/abs/2510.03222", "title": "低概率标记保持在可验证奖励强化学习中的探索", "title_en": "Low-probability Tokens Sustain Exploration in Reinforcement Learning with Verifiable Reward", "authors": "Guanhua Huang,Tingqiang Xu,Mingze Wang,Qi Yi,Xue Gong,Siheng Li,Ruibin Xiong,Kejiao Li,Yuhao Jiang,Bo Zhou", "background": "Reinforcement Learning with Verifiable Rewards (RLVR)虽然在复杂推理方面推动了大型语言模型的发展，但其可扩展性往往受到训练瓶颈的限制，表现为当政策熵塌缩时，性能停滞和探索性下降。尽管以前的方法通常通过维持高政策熵来应对这一问题，但人们对有意义探索的确切机制仍然了解不足。我们的分析表明，过分关注熵可能会放大无关标记并导致训练不稳定。因此，本文在RLVR中探讨了探索动力学，并发现了一个关键问题：渐进消除有价值的小概率探索性标记，这些被我们称为‘推理火花’的现象。在预训练模型中这些‘火花’尽管很多，但在RLVR过程中通过过度惩罚被系统地消灭，导致探索能力退化。", "innovation": "我们提出了低概率正则化（Lp-Reg），其核心机制是通过缓解策略向一个启发式代理分布的偏移来进行正则化。该代理通过过滤掉假设的噪声标记，并对剩余候选标记重新归一化而构建。结果生成一个噪声较少的代理，其中‘推理火花’的概率被放大，然后作为KL散度的软正则化目标使用，以防止边缘化这些有价值标记。实验表明，Lp-Reg在大约1000步内可实现稳定的策略策略训练，这是一个基线熵控制方法会崩溃的区域。持续的探索导致了最先进的性能，在五个数学基准上的平均准确性达到了$60.17\textbackslash\textpercent$，比之前的方法提高了$2.66\textbackslash\textpercent$。", "conclusion": "Lp-Reg这种机制使得RLVR能够保持稳定和长时间的探索性训练，从而实现了在数学推理任务上的卓越表现。"}
{"llm_update_time": "20251006", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2502.00299", "html_url": "https://arxiv.org/abs/2502.00299", "title": "ChunkKV: 保留语义的KV缓存压缩方法以实现高效长上下文LLM推理", "title_en": "ChunkKV: Semantic-Preserving KV Cache Compression for Efficient Long-Context LLM Inference", "authors": "Xiang Liu,Zhenheng Tang,Peijie Dong,Zeyu Li,Yue Liu,Bo Li,Xuming Hu,Xiaowen Chu", "background": "大型语言模型在处理长文本时需要大量GPU内存，其中关键值（KV）缓存可能消耗高达70%的总内存。现有压缩方法通过评估单个词的重要性来减少内存使用，但由于忽视了词之间的语义关系，导致上下文碎片化和性能下降。标准方法未能完整保留语言结构和上下文完整性，使得在压缩下重要含义丢失。", "innovation": "我们提出了ChunkKV，它重新定义了KV缓存压缩方式，将具有语义关联的词块视为压缩的基本单元，而非单独的词。这种方法保留了完整的语言结构和上下文连续性，即使在剧烈压缩下也能保持关键含义。我们的创新包括一种新型的逐层索引重用技术，利用ChunkKV中保留索引的更高跨层相似性，减少了计算开销并提高了26.5%的吞吐量。在具有挑战性的基准测试LongBench、Needle-In-A-HayStack、GSM8K和JailbreakV中的全面评估表明，ChunkKV在相同压缩率的情况下，在精度上比最先进的方法高出8.7%。结果表明，语义保留的压缩显著提高了长期上下文LLM推理的效率和性能，提供了一种简单有效的方法来解决内存瓶颈问题。", "conclusion": "这些结果验证了语义保留压缩显著提高了长期上下文LLM推理的效率和性能，提供了一个简单有效的解决内存瓶颈的方法。"}
{"llm_update_time": "20251006", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2404.01903", "html_url": "https://arxiv.org/abs/2404.01903", "title": "通过激活导向理解代码LLMs对类型预测的误预测", "title_en": "Understanding How CodeLLMs (Mis)Predict Types with Activation Steering", "authors": "Francesca Lucchetti,Arjun Guha", "background": "大型语言模型（LLMs）被广泛应用于软件开发中的编程任务。然而，研究表明LLMs往往对程序语义缺乏深入理解。即使是语法上的小改动，如变量重命名，也会显著降低其在各种任务上的性能。本文关注类型预测任务：给定一个部分类型化的程序，模型能否准确预测缺失的类型注释，使程序更加类型化？并且指出，即使代码在语义上是等价的，模型也可能会因为语法形式的不同而在预测上失败，这表明模型可能对代码语义的理解是肤浅的。尽管如此，研究者提供了证据表明LLMs确实学习了稳健的类型预测机制，但这些机制在对抗性场景中往往无法激活。", "innovation": "本研究通过激活导向（activation steering）这一方法，操控模型内部激活，以引导模型调动潜在知识，使模型在对抗性输入上恢复准确的类型预测。研究发现，这种方法成功激活了一种共享于Python和TypeScript的类型预测机制，并且这种机制的效果优于使用上下文示例进行提示。此外，全面评估结果表明，LLMs能够学习可跨编程语言迁移的代码语义表示，揭示了模型具备更深层次的代码理解能力。", "conclusion": "总体来说，尽管LLMs对程序语义的理解可能存在缺陷，但在适当的方法引导下，它们可以提升应对对抗性挑战的能力。研究进一步证明了LLMs具备跨编程语言的类型预测能力，并提出激活导向方法是一种有效提升预测准确性的策略。"}
{"llm_update_time": "20251006", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2504.18070", "html_url": "https://arxiv.org/abs/2504.18070", "title": "PropRAG：使用命题路径上的束搜索引导检索", "title_en": "PropRAG: Guiding Retrieval with Beam Search over Proposition Paths", "authors": "Jingjin Wang,Jiawei Han", "background": "检索增强生成（RAG）已经成为为大型语言模型（LLMs）配备最新知识的标准方法。然而，传统的RAG依赖于独立的段落检索，往往无法捕捉到复杂、多跳推理所需的相互关联的信息。虽然结构化的RAG方法试图通过构建从三元组获取的知识图谱来解决这一问题，但三元组固有的语境损失（语境坍塌）限制了知识表示的精度。", "innovation": "介绍了PropRAG，这是一种新颖的RAG框架，从三元组转向了包含丰富语境的命题，并引入了一种高效的、无需LLM的在线束搜索方法，用于发现多步推理链。通过结合更加精确的知识表示和明确的路径发现，PropRAG在2Wiki、HotpotQA和MuSiQue上的零样本召回@5和F1分数均达到最新技术水平，推动了非参数知识整合的进步，通过更丰富的方法提高了证据检索和有效推理路径发现。", "conclusion": "PropRAG通过更高质量的知识表示与明确的路径发现，提升了无需参数的知知识整合技术，在多个数据集上达到了最先进的零样本召回@5和F1分数，这对于多步骤推理和证据检索具有重要意义。"}
{"llm_update_time": "20251006", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2506.09047", "html_url": "https://arxiv.org/abs/2506.09047", "title": "同任务，不同电路：拆分VLMs中模态特异性机制", "title_en": "Same Task, Different Circuits: Disentangling Modality-Specific Mechanisms in VLMs", "authors": "Yaniv Nikankin,Dana Arad,Yossi Gandelsman,Yonatan Belinkov", "background": "视觉-语言模型（VLMs）在回答视觉输入的问题上展示了令人印象深刻的性能，但在执行类似的任务时，文本相比图像明显具有更高的准确性。论文深入研究了这种准确性差距，通过比较不同模态中的特定任务电路来进行分析。", "innovation": "论文发现不同模态之间的电路虽然大部分是独立的，但它们实现的功能相对相似，差别主要在于处理模态特定的数据位置（图像或文本序列）。通过将来自较晚层的视觉数据表示补回早期层，该研究减少了性能差距，平均关闭了约三分之一的差距。", "conclusion": "结论是，该研究表明VLMs在多模态性能上的差距，并提供了一种无需训练的方法来减轻这种差距。"}
{"llm_update_time": "20251006", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2506.10150", "html_url": "https://arxiv.org/abs/2506.10150", "title": "当大型语言模型在判断同理心沟通方面的可靠性", "title_en": "When Large Language Models are Reliable for Judging Empathic Communication", "authors": "Aakriti Kumar,Nalin Poungpeth,Diyi Yang,Erina Farrell,Bruce Lambert,Matthew Groh", "background": "大型语言模型（LLMs）在生成具有同理心的文本响应方面表现优异，但它们对同理心沟通的细微差别判断的可靠性如何呢？该研究通过比较专家、众包工人和LLMs在四个取自心理学、自然语言处理和沟通应用的心理学上的评估框架下对200个真实对话情景（一名说话者分享个人问题，另一方提供支持）的标注，来探究这一问题。研究基于3,150份专家标注、2,844份众包标注以及3,150份LLM标注来评估这三组标注者之间的评分一致性。", "innovation": "研究发现，专家间的共识较高，但根据框架子组件的清晰度、复杂性和主观性有所变化。研究显示，专家共识为LLMs表现提供了一个更具有信息量的基准，而非标准分类指标。在所有四个框架下，LLMs始终接近这一专家水平基准，并超过了众包工人的可靠性。这些结果表明，当LLMs在特定任务上经过适当基准验证时，它们可以支持在情感敏感应用中（例如作为对话伴侣）的透明度和监管。", "conclusion": "这些结果表明，当大型语言模型在特定任务上经过适当基准验证时，它们可以在情感敏感应用中（如作为对话伴侣）支持透明度和监管。"}
{"llm_update_time": "20251006", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2505.15962", "html_url": "https://arxiv.org/abs/2505.15962", "title": "使用内部和外部知识预训练有限记忆语言模型", "title_en": "Pre-training Limited Memory Language Models with Internal and External Knowledge", "authors": "Linxi Zhao,Sofian Zalouk,Christian K. Belardi,Justin Lovelace,Jin Peng Zhou,Ryan Thomas Noonan,Dongyoung Go,Kilian Q. Weinberger,Yoav Artzi,Jennifer J. Sun", "background": "神经语言模型是黑箱模型，无论是语言模式还是事实知识都是分布在数十亿参数中，这使得检查、核实或更新特定事实变得困难。", "innovation": "介绍了有限记忆语言模型（LMLM），在预训练过程中将事实知识外置到外部数据库，而不是记忆这些知识。预训练方法在训练损失中战略性地掩蔽从外部检索到的事实值，从而教导模型进行目标查询，而不是依赖模型权重的记忆。", "conclusion": "实验表明，LMLMs在标准基准测试上达到了与较大语言模型相当的性能，同时具备明确、可编辑和可验证的知识库的优势。"}
{"llm_update_time": "20251006", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2506.08136", "html_url": "https://arxiv.org/abs/2506.08136", "title": "EconWebArena: 在现实网络环境中的经济任务自主代理基准测试", "title_en": "EconWebArena: Benchmarking Autonomous Agents on Economic Tasks in Realistic Web Environments", "authors": "Zefang Liu,Yinzhu Quan", "background": "当前存在缺乏有效评估自主代理在复杂多模态经济任务中的表现的基准。以往的研究将注意力集中在单一或有限的领域，而不注重权威数据源的真实性和与实际网页条件下推理的契合性。EconWebArena旨在填补这一空白，提供一个全面的基准平台来评估代理在现实网络环境中的经济任务处理能力。", "innovation": "EconWebArena通过利用多个大型语言模型（LLMs）自动生成候选任务，并经过严格的多方人工审核，确保任务的清晰性、可行性和来源的真实性。不同于先前研究，EconWebArena特别强调准确性和与权威数据源的一致性，以及基于实际网页的情境推理的重要性。通过评估多种最先进的多模态LLM作为网络代理，分析失败案例并进行消融研究，EconWebArena揭示了显著的性能差距和持续存在的挑战，尤其是关于格式化、导航和多模态理解领域。", "conclusion": "EconWebArena作为经济网络智能的一个严格的测试平台，其结果展示了在导航、多模态理解和任务执行中的巨大性能差异，这表明未来的研究需要解决这些关键挑战，以提升代理的能力，从而更有效地处理现实世界的经济任务。"}
{"llm_update_time": "20251006", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2507.07518", "html_url": "https://arxiv.org/abs/2507.07518", "title": "三元多方语音活动投射在对话系统中轮流说话的应用", "title_en": "Triadic Multi-party Voice Activity Projection for Turn-taking in Spoken Dialogue Systems", "authors": "Mikey Elmers,Koji Inoue,Divesh Lala,Tatsuya Kawahara", "background": "轮流说话是对话交流的基本组成部分，尽管传统的研究主要集中在二元设置中。本研究聚焦于将语音活动投影（VAP）技术应用于预测三元多方对话中的轮流说话。VAP模型的目标是利用仅声学数据来预测每位发言人的未来语音活动。这是首次将VAP技术扩展应用于三元对话。", "innovation": "本研究首次应用VAP技术于三元对话场景，使用日本三元对话数据集进行训练，发现三元对话训练的VAP模型在所有基准模型中表现更优，但对话类型影响预测准确性。", "conclusion": "本研究确立了VAP可以用于三元对话场景中的轮流说话。未来的工作将会将三元VAP轮流说话模型整合到对话系统中。"}
{"llm_update_time": "20251006", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2506.09669", "html_url": "https://arxiv.org/abs/2506.09669", "title": "大型语言模型中的查询级别不确定性", "title_en": "Query-Level Uncertainty in Large Language Models", "authors": "Lihu Chen,Gerard de Melo,Fabian M. Suchanek,Gaël Varoquaux", "background": "大型语言模型需要意识到自身知识的边界，区分能自信回答的问题与超出其能力的问题。这种意识使模型能够在生成任何标记之前，通过评估不确定性信号，进行自适应推理，如调用检索增强生成（RAG）、进行深思熟虑的思考，或在必要时避免回答。这是开发高效可信的人工智能的关键机制。", "innovation": "作者提出了一种通过查询级别不确定性检测知识边界的方法。该方法在无需训练的情况下，利用跨层和标记的自我评估来提供准确的不确定信号。实验证明，相比基线方法，该方法在准确性和计算成本上更优。此外，展示其在自适应推理环境中的优点，比如在RAG和模型级联中，可以减少推理成本同时保持整体性能不受影响。", "conclusion": "研究表明，内部自信方法能够有效检测知识边界，提供高质量的不确定性估计，同时计算成本较低，并且能够在自适应推理设置中带来实际好处。"}
{"llm_update_time": "20251006", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2505.01761", "html_url": "https://arxiv.org/abs/2505.01761", "title": "相同的评估，更多的token：大规模语言模型在机器翻译评估中的输入长度效应", "title_en": "Same evaluation, more tokens: On the effect of input length for machine translation evaluation using Large Language Models", "authors": "Tobias Domhan,Dawei Zhu", "background": "准确评估机器翻译文本仍然是一个长期存在的挑战，尤其是在长文档中。最近的研究表明，大型语言模型（LLMs）可以通过MQM错误跨度注解在句子层面提供可靠且可解释的翻译评估。随着现代LLMs支持更大的上下文窗口，一个自然的问题是：我们是否可以将整个文档翻译输入LLM进行质量评估？理想情况下，评估应该在文本长度上是不变的，生成不依赖于输入粒度的一致错误跨度。然而，我们的分析显示，文本长度显著影响评估：更长的文本导致更少的错误跨度和较低的系统排名准确性。为了应对这一局限性，我们评估了几种策略，包括粒度对齐提示、焦点句子提示（FSP）以及一种微调方法，以更好地使LLMs与评估任务对齐。最后两种方法在很大程度上缓解了长度偏见，使LLMs在长格式翻译评估中更具可靠性。", "innovation": "我们提出并评估了几种策略，以缓解LLMs在长文档翻译评估中的长度偏见问题。这些策略包括粒度对齐提示、焦点句子提示（FSP）和微调方法，以提高LLMs在长文本评估中的可靠性和准确性。特别是，后者两种方法显著缓解了长度偏见，使LLMs更适合处理长文档的翻译质量评估。", "conclusion": "我们的研究结果表明，输入长度显著影响使用LLMs进行机器翻译评估的结果。为了解决这一问题，我们提出并验证了多种方法可以有效减轻输入长度对评估质量的影响，使LLMs在长文档翻译评估中更加可靠。未来的改进方向可能包括探索更高级别的LLMs或改进的数据标注方法来进一步优化评估性能。"}
{"llm_update_time": "20251006", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.01918", "html_url": "https://arxiv.org/abs/2508.01918", "title": "量子-RAG和PunGPT2：为旁遮普语语言生成和检索推进低资源语言", "title_en": "Quantum-RAG and PunGPT2: Advancing Low-Resource Language Generation and Retrieval for the Punjabi Language", "authors": "Jaskaranjeet Singh,Rakesh Thakur", "background": "尽管大型语言模型（LLMs）取得了迅速发展，但低资源语言仍然被自然语言处理（NLP）排除在外，限制了数百万人的数字访问权限。", "innovation": "提出了量子-RAG，一种将稀疏、密集和量子内核嵌入融合在一起的高效、上下文感知的检索框架，这是首次在低资源LLM中实现实际的量子启发式检索。还介绍了Pun-RAG（结合PunGPT2与FAISS检索器的Punjabi知识库）和Pun-Instruct（使用QLoRA进行指令调整，用于稳健的零样本总结、翻译和问答）。PunGPT2是首个完全开源的旁遮普语生成模型套件，训练数据量为35GB，涵盖了文学、宗教文本、新闻、社会讨论等多种内容。", "conclusion": "量子-RAG在PunjabiEval基准上的召回率(Recall@10)比FAISS高出7.4%，BLEU分数比mT5高出3.5%，模型整体优于多语言基线（mBERT、mT5、MuRIL、BLOOM）。展示了所有训练脚本、超参数、评估管道、35GB旁遮普语语料库、PunjabiEval基准以及所有模型权重，建立了旁遮普语语言生成和检索的新最先进成果。"}
{"llm_update_time": "20251006", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2509.02093", "html_url": "https://arxiv.org/abs/2509.02093", "title": "对比中更优：辅助检索增强的对比推理在自动提示优化中的应用", "title_en": "Better by Comparison: Retrieval-Augmented Contrastive Reasoning for Automatic Prompt Optimization", "authors": "Juhyeon Lee,Wonduk Seo,Hyunjin An,Seunghyun Lee,Yi Bu", "background": "自动提示优化已成为提高大型语言模型（LLMs）所用提示质量的一种策略，旨在生成更准确和有用的回答。然而，大部分现有研究集中在直接提示细化或模型微调上，忽视了利用LLMs固有的推理能力通过反例学习的潜力。", "innovation": "本文提出了对比推理提示优化（CRPO），这是一种将提示优化形式化为检索增强推理过程的新框架。CRPO通过检索HelpSteer2数据集中每个响应注释为有用性、准确性、连贯性、复杂性和冗余性的高质例子对，构建了两种互补的优化模式：（1）分层对比推理，LLM比较高低不同质量的示例（包括提示和响应）来进行反思推理以改进自身生成；（2）多指标对比推理，LLM分析每个评价维度的最佳示例并整合其优点以优化提示。通过明确对比高低质量的示例，CRPO使模型能够推断出某些提示成功而另一些失败的原因，从而实现更稳健和可解释的优化。", "conclusion": "在HelpSteer2基准上的实验结果显示，CRPO显著优于基线方法。我们的研究结果突出了对比、检索增强推理在推进自动提示优化方面的潜力。"}
{"llm_update_time": "20251006", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2507.04793", "html_url": "https://arxiv.org/abs/2507.04793", "title": "Pun 生成：数据集、评估和方法综述", "title_en": "A Survey of Pun Generation: Datasets, Evaluations and Methodologies", "authors": "Yuchen Su,Yonghua Zhu,Ruofan Wang,Zijian Huang,Diana Benavides-Prado,Michael Witbrock", "background": "引文生成旨在创造性地修改文本中的语言元素，以产生幽默或引发双关语。它还旨在保持连贯性和语境适宜性，使其在创意写作和各种媒体和场景中的娱乐方面都非常有用。尽管引文生成在计算语言学中受到了广泛关注，但目前还没有专门针对这一特定领域的系统性回顾。因此，本文对此进行了全面的综述，涵盖了不同阶段的引文生成数据集和方法，包括传统方法、深度学习技术以及预训练的语言模型。此外，还总结了评估引文生成质量的自动化和人工评价标准。最后，讨论了研究挑战，并提出了未来工作的富有前景的方向。", "innovation": "文章提供了一个全面的引文生成数据集和方法的综述，涵盖了从传统方法到深度学习技术，再到预训练语言模型的不同阶段的方法。此外，文章还总结了评估引文生成质量的自动化和人工评价标准，填补了该领域的系统性回顾空白，并提出了未来研究方向。", "conclusion": "本文总结了引文生成相关的数据集、评估标准和方法，并讨论了未来的研究挑战和方向。这有助于推动该领域的发展，为学术研究和实际应用提供了宝贵的资源。"}
{"llm_update_time": "20251006", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2505.16000", "html_url": "https://arxiv.org/abs/2505.16000", "title": "利用在线数据增强小规模波斯语医疗模型的知识", "title_en": "Leveraging Online Data to Enhance Medical Knowledge in a Small Persian Language Model", "authors": "Mehrdad Ghassabi,Pedram Rostami,Hamidreza Baradaran Kashani,Amirhossein Poursina,Zahra Kazemi,Milad Tavakoli", "background": "语言模型的快速发展显示了人工智能在医疗行业的潜力，但在资源稀缺的语言（如波斯语）的专业领域，小型语言模型表现欠佳。虽然存在大量波斯语医疗领域网站，但缺乏权威的数据集或语料库，因此本文首次创建了一个新的数据集，包含20,000个医生-患者问答对和从医学杂志中爬取的9000万个词的60%。数据集的创建填补了该领域的空白，对后续研究具有重要意义。", "innovation": "本文提出了一种参数高效微调方法来增强基础模型（aya-expanse-8b）的医疗知识。微调后的模型在医学问答中的准确率得到了提升，并成功通过了伊朗基础医学科学入学考试（IBSEE），这是基线模型未能做到的。此外，微调后的模型还提高了波斯语翻译MMLU准确率的平均值2.67%。这项工作表明了利用开放访问的在线数据来丰富小型语言模型在医疗领域的知识，提供了适合资源受限环境的波斯语医疗AI应用的新解决方案。未来的研究可能探索多模态输入以进一步提高性能。", "conclusion": "这项工作强调了利用开放访问的在线数据来丰富小型语言模型在医疗领域的知识，提供了适合资源受限环境的解决方案。未来研究可以探索多模态输入以进一步增强性能。"}
{"llm_update_time": "20251006", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2509.18314", "html_url": "https://arxiv.org/abs/2509.18314", "title": "利用树结构进行大语言模型RL训练中的奖励归因", "title_en": "Exploiting Tree Structure for Credit Assignment in RL Training of LLMs", "authors": "Hieu Tran,Zonghai Yao,Hong Yu", "background": "强化学习提升了大语言模型（LLM）的推理能力，但稀疏的延迟奖励和长序列使得在标记级别进行奖励归因成为主要瓶颈。研究团队通过分析验证奖励设置，发现数学和医疗问答等推理任务中只有少数决定性标记能显著影响结果。前向传播策略优化（PPO）和新策略组合优化（GRPO）等方法虽然在标记级别上有优势，但在训练过程中存在复杂性和泛化性的挑战，尤其是对于标记级别的价值估计可能导致过度拟合的问题。因此，探索一种简单且有效的奖励归因方法变得尤为重要。", "innovation": "研究引入了Prefix-to-Tree (P2T) 方法，将一组回应转换为前缀树，并通过继承后代结果计算非参数化的前缀价值V(s)。在此基础上，提出了TEMPO算法，一种免批评员的强化学习算法，其通过树形结构的分支门控时间差分修正补充了GRPO的组相对结果信号。TEMPO在非分支标记处时间差分（TD）项为零，从而实际操作中简化为GRPO；在分支标记点，提供了精确的标记级别奖励分配而不依赖于学习价值网络或额外的技术员。实验结果显示，TEMPO在Qwen3-1.7B/4B模型上比PPO和GRPO在分布内和分布外基准测试中表现更好，且达到较高验证准确率。", "conclusion": "研究发现，通过引入前缀树结构和树形时间差分修正的TEMPO方法，在处理复杂的奖励归因问题时表现出高效性和泛化性，尤其适合大语言模型的强化学习训练，特别是在数学和医疗QA等场景中。"}
{"llm_update_time": "20251006", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2507.16076", "html_url": "https://arxiv.org/abs/2507.16076", "title": "提示决定了人物（个性）：大型语言模型中社会人口学个性化提示的系统评估", "title_en": "The Prompt Makes the Person(a): A Systematic Evaluation of Sociodemographic Persona Prompting for Large Language Models", "authors": "Marlene Lutz,Indira Sen,Georg Ahnert,Elisa Rogers,Markus Strohmaier", "background": "个性提示在大型语言模型（LLMs）中被广泛用于模拟各种社会人口学群体的观点，但提示的表述方式对结果的影响巨大，这引发了一些关于模拟真实性的担忧。本文旨在系统地研究不同个性提示策略，特别是角色采用格式和人口统计学激活策略，如何影响LLMs在15个交叉人口学群体中的模拟表现，特别是在开放性任务和封闭性任务中的表现。研究发现，LLMs在模拟边缘化群体时显得力不从心，而选择适当的人口统计学激活和角色采用策略能够显著改善模拟结果，而且小型模型的表现优于大型模型。这一发现为基于LLM的模拟研究中设计社会人口学个性化提示提供了实际指导。", "innovation": "本文通过系统地评估五种开源LLM，研究了不同的个性提示策略如何影响LLMs在模拟社会人口学群体时的表现。特别地，研究发现了一种更有效的提示格式（面试风格）和激活策略（基于名字），可以减少刻板印象，提高模型的包容性。同时，小型模型在某些情况下表现优于大型模型，这是研究的一个出乎意料的结果。研究提供了有意的操作性建议，以更好地设计社会人口学的个性化提示，提高了大型语言模型模拟的真实性和准确性。", "conclusion": "本文的研究结果表明，对于大型语言模型中的社会人口学个性化提示设计，采用特定的提示格式和激活策略至关重要。小型模型可能在某些情况下表现优于大型模型，因此在选择模型时也要考虑模型规模。这些发现为未来的研究提供了重要的指导价值。"}
{"llm_update_time": "20251006", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2505.17121", "html_url": "https://arxiv.org/abs/2505.17121", "title": "NeSyGeo: 一种用于多模态几何推理数据生成的神经符号框架", "title_en": "NeSyGeo: A Neuro-Symbolic Framework for Multimodal Geometric Reasoning Data Generation", "authors": "Weiming Wu,Jin Ye,Zi-kang Wang,Zhi Zhou,Yu-Feng Li,Lan-Zhe Guo", "background": "大规模、高质量的推理数据对于提升多模态大语言模型的几何推理能力至关重要。然而，现有的数据生成方法，无论是基于预定义模板还是受限符号证明器，都不可避免地面临着多样性和数值泛化能力的局限性。为了解决这些问题，我们提出了NeSyGeo，这是一种新颖的神经符号框架，用于生成几何推理数据。该框架利用实体-属性-关系范式定义了一个专门领域的语言，并在其符号空间内定义生成动作，从而全面地表示平面几何的所有组成部分。通过一个符号-视觉-文本流水线合成符号序列，将其映射到视觉和文本表示，并使用逆向搜索和正向验证生成推理路径。基于该框架，我们构建了包含100,000个样本的NeSyGeo CoT和NeSyGeo-Caption数据集，并发布了用于评估多模态大语言模型几何推理能力的新基准NeSyGeo-Test。实验证明，该提案在强化和监督微调下，显著且一致地提高了多种多模态大语言模型的性能。仅通过4,000个样本和两个强化微调周期，基础模型在MathVision、MathVerse和GeoQA上的表现分别提高了15.8%、8.4%和7.3%。值得注意的是，一个4B模型在几何推理任务中可以超越同一系列的8B模型。", "innovation": "NeSyGeo框架创新地结合了实体-属性-关系范式定义的特定领域语言和符号推理，提出了一种新的符号推理数据生成方法。通过一个符号-视觉-文本流水线，NeSyGeo能够有效弥补现有方法在多样性和数值泛化方面的不足，从而显著提升多模态大语言模型在几何推理任务上的性能。此外，NeSyGeo还引入了两个新的数据集NeSyGeo CoT和NeSyGeo-Caption，以及一个用于评估几何推理能力的新基准NeSyGeo-Test。", "conclusion": "NeSyGeo框架展示了在几何推理数据生成和多模态大语言模型性能提升方面的显著优势。该方法不仅在小规模数据集和少量训练周期内实现了性能提升，还能显著提高大型模型在特定任务上的能力，从而为多模态大语言模型的几何推理能力研究提供了一种新的有效途径。"}
{"llm_update_time": "20251006", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.00496", "html_url": "https://arxiv.org/abs/2510.00496", "title": "Agent-ScanKit：通过敏感扰动揭开多模态代理的内存和推理", "title_en": "Agent-ScanKit: Unraveling Memory and Reasoning of Multimodal Agents via Sensitivity Perturbations", "authors": "Pengzhou Cheng,Lingzhong Dong,Zeng Wu,Zongru Wu,Xiangru Tang,Chengwei Qin,Zhuosheng Zhang,Gongshen Liu", "background": "尽管最近提出了一些策略来增强图形用户界面（GUI）中多模态代理的自主交互能力，但在面对复杂或超出领域范围的任务时，其可靠性仍然有限。这引发了一个基本问题：现有的多模态代理是否是在错误地推理？", "innovation": "提出了一个系统化的探测框架——Agent-ScanKit，用于在受控扰动下揭开封装的多模态代理的记忆和推理能力。引入了三种独立的探究范式：视觉引导、文本引导和结构引导，旨在量化记忆和推理的贡献，无需访问模型内部结构。", "conclusion": "在五个公开可用的GUI基准中涉及18个高模态代理的结果表明，机械记忆往往超过系统推理。大多数模型主要作为训练对齐知识的检索器，表现出有限的泛化能力。研究发现强调了在真实应用场景中，必须提高多模态代理稳健的推理建模的必要性。"}
{"llm_update_time": "20251006", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2506.09277", "html_url": "https://arxiv.org/abs/2506.09277", "title": "大型语言模型中的神经活动与自我解释间是否忠实？通过连接神经活动和自我解释来弥合差距", "title_en": "Did I Faithfully Say What I Thought? Bridging the Gap Between Neural Activity and Self-Explanations in Large Language Models", "authors": "Milan Bhan,Jean-Noel Vittaut,Nicolas Chesneau,Sarath Chandar,Marie-Jeanne Lesot", "background": "大型语言模型（LLMs）能够自动生成合理的自由文本自我解释来解释其答案，但这可能是对模型实际推理过程的不准确表现，体现出缺乏忠实性。现有的忠实性评估方法主要依赖于行为测试或计算块分析，而不检查内部神经表示的语义内容。需要一种有效的评估和提高LLM自由文本自我解释忠实性的方法，以构建可信的AI系统。", "innovation": "提出了一种灵活的框架NeuroFaith，通过识别解释中的关键概念并验证这些概念是否真正影响模型的预测来评估LLM自由文本自我解释的忠实性。开发了一个基于NeuroFaith的线性忠实性探针，用于从表示空间检测不忠实的自我解释并提高忠实性。NeuroFaith为评估和增强LLM自由文本自我解释的忠实性提供了基本原则。", "conclusion": "NeuroFaith提供了评估和增强LLM自由文本自我解释忠实性的方法，解决了构建可信AI系统的重要需求。该方法在2跳推理和分类任务中展示了其灵活性，通过从表示空间检测和纠正不忠实的自我解释，提高了模型的忠实性和可靠性。"}
{"llm_update_time": "20251006", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2509.25085", "html_url": "https://arxiv.org/abs/2509.25085", "title": "jina-reranker-v3：最后但并非次要的交互对于列表式文档重排", "title_en": "jina-reranker-v3: Last but Not Late Interaction for Listwise Document Reranking", "authors": "Feng Wang,Yuqing Li,Han Xiao", "background": "该论文介绍了一种新的多语言列表式重排模型jina-reranker-v3，它引入了一种创新的'最后但并非次要'的交互方式。与ColBERT等晚期交互模型相比，jina-reranker-v3在同一个上下文窗口中对查询和所有候选文档之间应用因果注意力，从而在提取每个文档最终标记的上下文嵌入之前实现了丰富的交互。该模型在BEIR基准测试中达到了61.94 nDCG@10的表现，同时保持比其他具有相似性能的模型更小的规模", "innovation": "与ColBERT等模型不同，jina-reranker-v3在同一个上下文窗口中对查询和所有候选文档应用因果注意力，从而在提取每个文档最终标记的上下文嵌入之前实现丰富的交互。这种方法使得模型能够更早地捕捉到查询与文档之间的交互信息，从而提高了重排效果。相比其他具有相似性能的多语言列表式重排模型，jina-reranker-v3更小且高效", "conclusion": "jina-reranker-v3在BEIR基准测试中展示了出色的重排性能，并且由于其较小的模型参数量，具有更高的效率和更好的性能与规模比。该方法为列表式文档重排领域的进一步研究提供了新的视角和技术实现"}
{"llm_update_time": "20251006", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.01252", "html_url": "https://arxiv.org/abs/2510.01252", "title": "GPT和偏见：理解大规模语言模型中学习表示的稀疏方法", "title_en": "GPT and Prejudice: A Sparse Approach to Understanding Learned Representations in Large Language Models", "authors": "Mariam Mahran,Katharina Simbeck", "background": "随着大型语言模型（LLMs）越来越多地训练在海量的未经筛选的语料上，理解和模型本身的表示以及它们内部化的内容已经成为一项重大挑战。本研究展示了将LLMs与稀疏自编码器（SAEs）结合使用不仅可以使我们理解模型的行为，还能深入解析训练数据中所蕴含的深层结构、主题和偏见。", "innovation": "本研究通过将GPT样式的变压器模型专门训练在简·奥斯汀的小说上，这些小说富含社会组织和叙述模式，然后应用SAEs于多层中的隐藏状态，揭示了稀疏、可解析的特征，这些特征反映了语料中关键的叙事和概念，包括性别、阶级和社会职责。这些发现表明，通过将LLMs与SAEs结合使用，可以实现对复杂数据集的大规模探查，为语料库探索、偏见发现和模型可解析性提供了一条新的途径。", "conclusion": "本研究证明了LLMs与SAEs相结合可以作为大规模数据集的可扩展探针，为大规模模型解释性提供了一种新的方法，使研究人员能够深入分析训练数据中的深层结构、主题和偏见。"}
{"llm_update_time": "20251006", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2405.18406", "html_url": "https://arxiv.org/abs/2405.18406", "title": "RACCooN: 自动生成叙述的多功能视频编辑框架", "title_en": "RACCooN: A Versatile Instructional Video Editing Framework with Auto-Generated Narratives", "authors": "Jaehong Yoon,Shoubin Yu,Mohit Bansal", "background": "最近的视频生成模型主要依赖精心编写的文本提示来执行特定任务，如修补、风格编辑等。这些模型需要详细的文本描述来输入视频，这限制了它们对个性或原始视频的灵活性以满足用户需求。", "innovation": "RACCooN 提出了一种多功能且用户友好的视频到段落到视频生成框架，支持多种视频编辑功能，如删除、添加和修改，通过一个统一的管道完成。RACCooN 的贡献包括：(1) 利用多级时空池化策略生成结构良好的视频描述，能够捕捉到整体环境和对象细节，简化了以文推进的精确视频内容编辑的用户操作。(2) 该视频生成模型结合了自动生成的叙述或指令来提升生成内容的质量和准确性。(3) RACCooN 能够在给定的视频中设想新的物体，使用户简单地引导模型生成详细的视频编辑计划，提供复杂的视频编辑。", "conclusion": "RACCooN 在视频到段落生成、视频内容编辑方面表现出引人注目的多功能性，并且可以整合进其他先进的视频生成模型以进一步增强功能。"}
{"llm_update_time": "20251006", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2509.04432", "html_url": "https://arxiv.org/abs/2509.04432", "title": "语言模型能处理非格里高利历吗？", "title_en": "Can Language Models Handle a Non-Gregorian Calendar?", "authors": "Mutsumi Sasaki,Go Kamoda,Ryosuke Takahashi,Kosuke Sato,Kentaro Inui,Keisuke Sakaguchi,Benjamin Heinzerling", "background": "语言模型（LMs）需要具备时间推理和知识的理解能力。尽管已有大量研究分析和提升LMs的时间推理能力，大多数研究仅集中在格里高利历上。许多非格里高利历系统，如日本历、希吉历和希伯来历，在当今仍然被广泛使用，并反映了一种文化背景下的时间观。目前，现有的LMs能否准确处理这些非格里高利历还没有被评估。", "innovation": "本文系统性地评估了开源LMs在处理日本历这一非格里高利历系统上的表现，设计了四个需要时间知识和时间推理的任务。研究发现，虽然一些模型可以完成历法转换，但即使是日本中心的模型在进行日本历算术和跨历法一致性方面也存在困难。该研究突显了开发专门针对特定文化历法理解的LMs的重要性。", "conclusion": "现有LMs在处理非格里高利历方面存在不足，尤其是跨历法的一致性和日本历算术方面。未来需要发展能够更好地理解文化特定历法的LMs，以提供更多准确的时间处理能力。"}
{"llm_update_time": "20251006", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2502.11191", "html_url": "https://arxiv.org/abs/2502.11191", "title": "Primus: 开源网络安全大型语言模型训练数据集的先驱集合", "title_en": "Primus: A Pioneering Collection of Open-Source Datasets for Cybersecurity LLM Training", "authors": "Yao-Ching Yu,Tsun-Han Chiang,Cheng-Wei Tsai,Chien-Ming Huang,Wen-Kwang Tsao", "background": "大型语言模型（LLMs）在金融、法律和医学等专业领域已经取得了显著的进步。然而，在网络安全领域，我们注意到缺乏开放的数据集，尤其是高质量的预训练语料库。尽管研究表明，LLMs在预训练过程中会获得知识，但在网络安全领域的开放预训练语料库却相对不足。", "innovation": "该论文提出了一套全面的开放源代码数据集，涵盖了网络安全工作的所有主要训练阶段，包括预训练、指令微调和包含网络安全特定自反思数据的推理蒸馏。广泛的消融研究证明了这些数据集在公共网络安全基准上的有效性。特别是，连续在该数据集上的预训练导致综合得分提高了15.9%，而推理蒸馏则带来了15.8%的CISSP安全认证得分提升。", "conclusion": "该团队将所有数据集和训练好的网络安全LLM的源代码和许可证都发布了出来，以促进社区内的进一步研究。前往 <this https URL> 以获取所有数据集和模型权重的访问权限。"}
{"llm_update_time": "20251006", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2501.12266", "html_url": "https://arxiv.org/abs/2501.12266", "title": "CBVLM：无需训练的大规模视觉语言模型以概念为基础的可解释医学图像分类", "title_en": "CBVLM: Training-free Explainable Concept-based Large Vision Language Models for Medical Image Classification", "authors": "Cristiano Patrício,Isabel Rio-Torto,Jaime S. Cardoso,Luís F. Teixeira,João C. Neves", "background": "在医疗工作流程中采用基于深度学习的解决方案面临的两个主要挑战是标注数据的可用性和系统的可解释性不足。概念瓶颈模型（CBMs）通过对预定义且可由人类解读的概念进行约束来解决可解释性问题，但这增加了标注负担，并且在添加新概念时需要重新训练整个系统。为了解决这些问题，作者提出了CBVLM方法，利用大型视觉语言模型（LVLM）在少样本设置中的出色表现，CBVLM可用于医学图像分类，同时确保解释性和降低标注成本。", "innovation": "CBVLM方法通过使用大型视觉语言模型（LVLM）在少样本设置下的表现来解决概念瓶颈模型（CBMs）的两个挑战：确保可解释性并降低标注成本。具体来说，该方法首先通过提示LVLM判断输入图像中是否存在某个概念，然后基于这些概念预测结果对图像进行分类。在此过程中，采用了检索模块来选择最佳实例进行上下文学习。这种方法不仅提高了解释性，还大大降低了标注成本。", "conclusion": "通过广泛的实验，CBVLM在四个医学数据集和十二个大型视觉语言模型（包括通用和医学专用模型）上展示了比CBMs和特定任务的监督方法更好的性能，同时无需进行训练且仅使用少量标注示例。"}
{"llm_update_time": "20251006", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2509.16360", "html_url": "https://arxiv.org/abs/2509.16360", "title": "RephQA：评估大型语言模型在公共健康问答中的可读性", "title_en": "RephQA: Evaluating Readability of Large Language Models in Public Health Question Answering", "authors": "Weikang Qiu,Tinglin Huang,Ryan Rullo,Yucheng Kuang,Ali Maatouk,S. Raquel Ramos,Rex Ying", "background": "大型语言模型（LLMs）在解决复杂的医学问题方面具有前景，但大多数先前的研究主要集中在提高准确性和推理能力上。然而，开发有效的医疗保健代理的一个重要瓶颈在于LLM生成的答案的可读性，特别是它们能否以清晰简洁的方式回答非医学背景人群的公共健康问题。本文介绍了一个名为RephQA的新基准，用于评估LLMs在公共健康问题问答中的可读性，包括533个专家审核的QA对，涵盖13个主题，从27个来源中收集，包含了评估信息性和两个可读性度量，即Flesch-Kincaid年级水平和专业分数，评估结果显示大多数LLM未能达到可读性标准，揭示了推理与有效沟通之间的差距。", "innovation": "提出了RephQA基准，这是一个评估大型语言模型在公共健康问答中可读性的标准，包括533个专家审核的QA对，涵盖13个主题，从27个来源中收集，包含了评估信息性和两个可读性度量，即Flesch-Kincaid年级水平和专业分数。进一步探索了四种可读性增强策略：标准提示、思维链提示、Group Relative Policy Optimization (GRPO)以及一种根据标记调整的GRPO变体，发现token-adapted GRPO取得了最好的结果，推动了更实用和用户友好的公共健康代理的发展。", "conclusion": "这些结果代表了一种朝着构建更实用的公共健康代理发展的重要步骤。"}
{"llm_update_time": "20251006", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2509.18762", "html_url": "https://arxiv.org/abs/2509.18762", "title": "当长帮助短：监督微调中上下文长度如何影响大型语言模型的行为", "title_en": "When Long Helps Short: How Context Length in Supervised Fine-tuning Affects Behavior of Large Language Models", "authors": "Yingming Zheng,Hanqi Li,Kai Yu,Lu Chen", "background": "大型语言模型（LLMs）在自然语言处理（NLP）任务中取得了令人印象深刻的性能。随着现实应用越来越需要更长的上下文窗口，继续在长上下文数据上进行预训练和监督微调（SFT）已成为常见做法。虽然人们广泛研究了持续预训练的数据长度的影响，但SFT方面的含义依然不清楚。本研究系统地探讨长上下文SFT如何影响LLM在短上下文任务中的表现。研究发现，长上下文SFT反而能提高短上下文任务性能，这与从长上下文预训练通常观察到的退化相反。研究还发现，多头注意力机制（MHA）和前馈网络（FFN）单独都从长上下文SFT中获益，并揭示了两种类型的SFT存在知识偏好偏差：长上下文SFT促进上下文知识，而短上下文SFT偏好参数知识，单纯依赖长上下文SFT是不可取的。最后，研究表明混合训练可以缓解这一偏见，为优化LLM微调提供可解释的指南。", "innovation": "本研究发现了长上下文SFT在短上下文任务中表现出改善性能的现象，这与常见的长上下文预训练的退化表现相反。通过对多头注意力机制（MHA）和前馈网络（FFN）的独立分析，探索了它们对SFT数据长度的反应。揭示了长上下文SFT与短上下文SFT之间的知识偏好偏差，并表明混合训练能够缓解这一偏差，提供一种优化LLM微调的方法。", "conclusion": "研究表明，长上下文SFT能改善LLM在短上下文任务中的表现，与预训练的退化表现相反。MHA和FFN都从长上下文SFT中受益，而且两种SFT之间存在知识偏好偏差。最后，提出混合训练可以缓解这种偏差，为优化LLM微调提供了解释性指导。"}
{"llm_update_time": "20251006", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2502.00415", "html_url": "https://arxiv.org/abs/2502.00415", "title": "MarketSenseAI 2.0: 通过LLM代理增强股票分析", "title_en": "MarketSenseAI 2.0: Enhancing Stock Analysis through LLM Agents", "authors": "George Fatouros,Kostas Metaxas,John Soldatos,Manos Karathanassis", "background": "MarketSenseAI 是一个利用大语言模型（LLMs）处理金融新闻、历史价格、公司基本数据和宏观经济环境的新颖框架，用于支持股票分析和选择中的决策过程。本文介绍了由LLMs技术的快速扩张驱动的MarketSenseAI 最新进展。通过一种新的架构结合检索增强生成和LLM代理，该框架处理SEC申报文件和收益电话会议，同时通过系统处理各类机构报告来丰富宏观经济分析。该研究展示了基础知识分析准确性的显著提高，并在S&P 100股票范围内两年（2023-2024）的实证评估中显示，MarketSenseAI 达到了累计回报率125.9%，相较于指数回报率73.5%的市场表现，保持了相似的风险水平。", "innovation": "介绍了一种新的架构，结合了检索增强生成和LLM代理，用于处理SEC申报文件和收益电话会议，同时通过系统处理各类机构报告来丰富宏观经济分析。显著提高了基础知识分析的准确性，并展示了在S&P 100和S&P 500股票中的优异表现，特别是在Sortino比率方面，演示了LLM技术在金融分析中的应用取得了显著进展", "conclusion": "这项工作标志着在金融分析中应用LLM技术的显著进展，提供了有关LLM驱动的投资策略稳健性的见解。"}
{"llm_update_time": "20251006", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2509.25188", "html_url": "https://arxiv.org/abs/2509.25188", "title": "学习并行：通过可学习并行解码加速扩散大型语言模型", "title_en": "Learning to Parallel: Accelerating Diffusion Large Language Models via Learnable Parallel Decoding", "authors": "Wenrui Bao,Zhiben Chen,Dan Xu,Yuzhang Shang", "background": "大型语言模型（LLM）中的自回归解码需要进行$n$次串行步骤，对于$n$个标记而言，这从根本上限制了推理吞吐量。尽管最近基于扩散的LLM（dLLM）可通过迭代去噪实现并行标记生成，但现有的并行解码策略依赖于固定的、输入不相关的启发式方法（例如，置信度阈值），这些方法无法适应输入的具体特征，导致在不同NLP任务中存在不理想的性能/速度权衡。因此，当前方法面临挑战是无法提供最佳的性能-速度权衡。", "innovation": "本文探索了一种更灵活和动态的并行解码方法。提出了一个名为Learn2PD的框架，该框架训练一个轻量级且适应性强的滤波器模型，以预测每个标记位置处当前预测是否与最终输出匹配。该学习到的滤波器近似于一种先验未知的并行解码策略，直到正确预测标记为止才揭露标记。此外，还引入了文本结束预测（EoTP）来检测序列结束时的解码完成情况，避免了对填充标记的冗余解码。研究表明，该方法在LLaDA基准测试上可实现高达22.58倍的速度提升，而不会有任何性能下降，并且与KV-Cache结合使用时，可以实现高达57.51倍的速度提升，", "conclusion": "本文提出的方法在并行解码过程中取得了显著的性能提升，与当前依赖固定启发式方法的并行策略相比提供了更为优化的性能和速度平衡。该方法通过学习一个轻量级的滤波器模型来动态预测哪些标记的位置可以进行并行解码，从而实现更高效的解码过程，并且该方法仅需要少量计算资源进行优化。"}
{"llm_update_time": "20251006", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2505.09901", "html_url": "https://arxiv.org/abs/2505.09901", "title": "标准多臂老虎机实验中LLMs与人类探索-利用策略比较：认知科学与精神健康文献中的见解", "title_en": "Comparing Exploration-Exploitation Strategies of LLMs and Humans: Insights from Standard Multi-armed Bandit Experiments", "authors": "Ziyuan Zhang,Darcy Wang,Ningyuan Chen,Rodrigo Mansur,Vahid Sarhangian", "background": "大规模语言模型在复杂的序列决策场景中被用于模拟或自动化人类行为。一个自然的问题是，这些模型的决策行为是否类似于人类，并能实现相似（或更优）的性能。本研究聚焦于探索-利用（E&E）权衡，这是一个动态决策在不确定性下的根本方面。通过采用认知科学和精神病学文献中的多臂老虎机（MAB）实验，我们比较了LLMs、人类和MAB算法的E&E策略。我们利用可解释的选择模型来捕捉代理的E&E策略，并探讨通过提示策略和思考模型启用思考轨迹如何影响LLMs的决策制定过程。研究表明，启用了思考的LLMs表现出更接近于人类的行为，特征是随机和定向探索的混合。然而，在更复杂、非平稳的环境中，尽管某些情况下懊悔相似，但LLMs在有效的定向探索方面难以匹配人类的适应性。这些发现突显了LLMs作为人类行为模拟者和自动决策工具的前景和局限性，并指出了改进的潜在领域。", "innovation": "1. 使用标准的多臂老虎机实验来比较LLMs、人类以及MAB算法的探索-利用策略。\n2. 采用可解释的选择模型来描述并研究启用了思考轨迹的LLMs的决策行为。\n3. 探讨通过提示和思考模型激发思考如何影响LLMs的行为。\n4. 发现启用了思考的LLMs在简单的平稳环境中与人类相似，但在更复杂的非平稳环境中表现出一定局限性。", "conclusion": "本研究揭示了LLMs作为模拟人类行为和自动决策工具的前景和局限性。提出了在更复杂环境下的改进方向。"}
{"llm_update_time": "20251006", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.15840", "html_url": "https://arxiv.org/abs/2508.15840", "title": "揭露Unicode在挑战作者归属性方面隐藏的底层机制", "title_en": "Unveiling Unicode's Unseen Underpinnings in Undermining Authorship Attribution", "authors": "Robert Dilworth", "background": "用户在使用公共通信渠道时（如社交媒体上的评论或帖子），没有隐私预期。即使他们采取了各种措施来匿名化在线存在，例如使用别名、隐藏IP地址、伪造地理位置、遮掩操作系统和用户代理、部署加密、使用一次性的电话号码或电子邮件地址等，但消息内容这一无法隐藏的部分仍然暴露了一个风险点：风格分析或作者画像攻击。本文探讨了风格分析技术，讨论了对抗风格分析的策略，并提出了通过Unicode隐写术来增强隐私的方法。", "innovation": "本文提出了一种对抗风格分析的新策略——将信息隐藏在Unicode字符中，从而提高作者识别的难度。这种方法结合了隐写术与风格分析来增强消息的隐私性。", "conclusion": "本文深入分析了风格分析技术，并提出了通过Unicode隐写术来增强隐私的新方法。这一策略旨在保护消息内容不受风格分析的影响，从而更好地保护用户隐私。"}
{"llm_update_time": "20251006", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2412.07192", "html_url": "https://arxiv.org/abs/2412.07192", "title": "PrisonBreak：最多二十五个目标位翻转破解大型语言模型", "title_en": "PrisonBreak: Jailbreaking Large Language Models with at Most Twenty-Five Targeted Bit-flips", "authors": "Zachary Coalson,Jeonghyun Woo,Chris S. Lin,Joyce Qu,Yu Sun,Shiyang Chen,Lishan Yang,Gururaj Saileshwar,Prashant Nair,Bo Fang,Sanghyun Hong", "background": "研究发现，商业规模的安全对齐大语言模型（LLMs）存在一个新的漏洞：通过翻转模型参数中的少量位，可以使其拒绝生成有害响应的功能失效。与针对较小计算机视觉模型的先前攻击相比，该攻击只需5到25个位翻转，所需位翻转次数最多减少40倍。与基于提示的破解方法不同，该方法直接在运行时在内存中解除模型的封禁，无需对输入进行更改即可生成有害输出。研究表明，训练后对齐较弱的模型更容易被破解，某些模型组件，如价值投影层，更易受攻击。该攻击机制与现有的破解方法不同。先前的研究已经探索了针对LLMs管道不同阶段的防御措施的有效性，但这些防御措施并未阻止该攻击。", "innovation": "提出了有效的位选择算法，该算法可以鉴定关键位，用于语言模型破解，比先前的方法快20倍。该方法可以在运行时直接取消封禁模型中的有害输出，而无需对输入进行修改。这种方法比基于提示的破解方法更直接和高效，且对模型性能的影响更小，攻击成功率较高。", "conclusion": "通过对10个开源大语言模型进行评估，该攻击方法在最小影响下实现了80%到98%的高成功率。在GDDR6 GPU上，通过Rowhammer基于的故障注入，成功破解了5种模型，成功率介于69%到91%之间。研究表明，训练后对齐较弱的模型、某些模型组件（例如价值投影层）以及与现有破解方法不同的攻击机制。尽管评估了一些可能的防御措施，但该攻击仍有效。"}
{"llm_update_time": "20251006", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.14052", "html_url": "https://arxiv.org/abs/2508.14052", "title": "FinAgentBench: 一个用于金融问答中代理检索的数据集", "title_en": "FinAgentBench: A Benchmark Dataset for Agentic Retrieval in Financial Question Answering", "authors": "Chanyeol Choi,Jihoon Kwon,Alejandro Lopez-Lira,Chaewoon Kim,Minjae Kim,Juneha Hwang,Jaeseon Ha,Hojun Choi,Suyeol Yun,Yongjin Kim,Yongjae Lee", "background": "金融领域的投资者需要从大量文档中识别相关的信息，传统的信息检索（IR）方法在准确性上往往不够理想，因为除了捕捉语义相似性外，还需要进行文档结构和领域知识的细粒度推理。大型语言模型（LLMs）的最新进展为多步推理检索提供了新的机会，但在金融领域的基准评估中，仍缺乏相应的评估标准。", "innovation": "本文提出了FinAgentBench，这是首个评估金融领域的多步骤推理检索的大规模基准。该基准采用了26000个专家注释的示例来评估大型语言模型在识别最相关文档类型和定位文档中关键段落方面的表现。评价框架将两个推理步骤明确区分开来，以便提供对金融领域检索为中心的LLM行为的量化理解。此外，本文还展示了针对性微调如何显著提高代理检索性能。", "conclusion": "FinAgentBench为研究金融领域的复杂、领域特定任务中的检索为中心的LLM行为提供了基础，该基准有可能激发对该领域更多深入的研究和探索。"}
{"llm_update_time": "20251006", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2505.19770", "html_url": "https://arxiv.org/abs/2505.19770", "title": "理解偏好数学中的性能差距：RLHF与DPO之二分法", "title_en": "Understanding the Performance Gap in Preference Learning: A Dichotomy of RLHF and DPO", "authors": "Ruizhe Shi,Minhak Song,Runlong Zhou,Zihan Zhang,Maryam Fazel,Simon S. Du", "background": "本研究对基于人类反馈的强化学习（RLHF）和直接偏好优化（DPO）之间在表示差距下的性能差距进行了细致的理论分析。研究将这一差距分成两个来源：精确优化下的显式表示差距和有限样本下的隐式表示差距。在精确优化的情景下，研究描述了奖励模型和策略模型类相对容量如何影响最终的策略质量。在近似优化的情景下，研究提供了地真相对于的构造，并展示了RLHF比DPO需要更少的样本来恢复有效的奖励模型，这突显了两阶段学习的统计优势。综上所述，研究提供了RLHF和DPO在不同情景下的性能差距的全面理解，并提供了关于何时每种方法更优的实际见解。", "innovation": "研究将性能差距细分为两个来源——显式表示差距和隐式表示差距，并在精确优化和近似优化两种情况下进行了详细分析，揭示了两阶段学习方法的统计优势，以及在不同类型模型不正确的条件下RLHF，DPO和在线DPO的性能对比", "conclusion": "本研究提供了在不同的设置下，对RLHF和DPO之间的性能差距的综合理解，同时也提供了一些建议，以便在具体情境中选择更优的方法。"}
{"llm_update_time": "20251006", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2507.17746", "html_url": "https://arxiv.org/abs/2507.17746", "title": "Rubrics as Rewards: 轮廓评分作为奖励：超越可验证领域的强化学习", "title_en": "Rubrics as Rewards: Reinforcement Learning Beyond Verifiable Domains", "authors": "Anisha Gunjal,Anthony Wang,Elaine Lau,Vaskar Nath,Yunzhong He,Bing Liu,Sean Hendryx", "background": "Reinforcement Learning with Verifiable Rewards (RLVR) 在处理具有明确正确性信号的复杂推理任务（如数学和编程）中已证明有效。然而，将其扩展到现实世界的推理任务中具有挑战性，因为评估依赖于细微、多标准的判断，而不是简单的二元正确性。近期在评估基准中使用了实例特定的评分表来捕捉这种判断，但它们作为导轨学习策略中的奖励信号的潜力尚未被充分探索。", "innovation": "我们提出了Powder锈（RaR），这是一种导轨学习方法，通过使用基于评分表的反馈将RLVR扩展到可验证领域以外的领域。我们评估了多个策略来将评分表反馈综合为奖励，并发现最佳的RaR变体在HealthBench中相对提高了高达31%，在GPQA-Diamond中相对提高了7%，超过了仅依赖直接态度奖励的流行LLM作为评委基准。这项研究表明，使用评分表作为结构化的奖励信号可以更好地对齐较小的评委并减少跨评委尺度的性能波动。", "conclusion": "RaR 训练策略在不同的评价形式中表现出良好的适应性，同时在基于评分表和多项选择任务上都表现出色。研究表明，使用评分表作为结构化的奖励信号，在减少评委规模带来的性能波动方面具有优势，并且能够更好地对齐较小的评委。"}
{"llm_update_time": "20251006", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.01925", "html_url": "https://arxiv.org/abs/2510.01925", "title": "使用奖励模型提升大规模语言模型推理能力：一种分析性综述", "title_en": "Enhancing Large Language Model Reasoning with Reward Models: An Analytical Survey", "authors": "Qiyuan Liu,Hao Xu,Xuhong Chen,Wei Chen,Yee Whye Teh,Ning Miao", "background": "奖励模型（RMs）在增强语言模型（LLMs）的推理性能方面起着关键作用。例如，它们可以为强化学习（RL）中的LLM微调提供训练信号，也可以帮助从多个候选答案中选择最合适的答案。本文综述了RMs的应用，分析了它们的基本概念、架构、训练方法和评估技术。", "innovation": "文章提供了奖励模型的系统介绍，并对其在LLM推理中的应用进行了全面综述。重点探讨了其关键应用，如指导生成和选择推断过程中的最优输出，促进数据合成和LLM的迭代自我改进，以及在基于RL的微调中的训练信号提供。", "conclusion": "最后，文章讨论了基于现有研究和自身实证发现的关键开放问题，包括RMs的选择、泛化、评估和提升问题，旨在为RMs在LLM推理中的有效部署和进步提供可操作的见解。"}
{"llm_update_time": "20251006", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2509.13761", "html_url": "https://arxiv.org/abs/2509.13761", "title": "THOR：通过RL实现工具集成的层次化优化以进行数学推理", "title_en": "THOR: Tool-Integrated Hierarchical Optimization via RL for Mathematical Reasoning", "authors": "Qikai Chang,Zhenrong Zhang,Pengfei Hu,Jun Du,Jiefeng Ma,Yicheng Pan,Jianshu Zhang,Quan Liu,Jianqing Gao", "background": "尽管大型语言模型在数学推理方面取得了显著进展，但在高精度任务如数值计算和正式符号操作方面仍然存在挑战。为了弥合这一差距，整合外部工具已成为一种有前景的方法，但由于数据构造困难、细粒度优化和推理能力提升的问题，现有方法难以达成理想效果。", "innovation": "本文提出了一种名为THOR（Tool-Integrated Hierarchical Optimization via RL）的方法。首先，THOR利用多智能体Actor-Critic架构创建高质量的工具集成推理路径数据集。其次，THOR引入了一种能同时优化整体问题解决和步骤代码生成的RL策略，并利用中间工具调用的成功预测最终答案的正确性这一关键见解。最后，THOR内置了一种自我校正机制，利用即时工具反馈动态修正推理路径中的错误。", "conclusion": "THOR在不同模型上展示了强大的泛化能力，并在推理和非推理模型中表现良好。在多个数学基准测试中，THOR达到了类似规模模型的最佳性能，并在代码基准测试中提供了持续改进。"}
{"llm_update_time": "20251006", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.02543", "html_url": "https://arxiv.org/abs/2510.02543", "title": "探索双语视觉问答中的OCR增强生成", "title_en": "Exploring OCR-augmented Generation for Bilingual VQA", "authors": "JoonHo Lee,Sunho Park", "background": "该研究探讨了视觉语言模型（VLMs）中OCR增强生成的方法，特别是在韩语和英语的语境下，旨在推动多语言领域的相关研究。为了支持这一领域的研究，研究团队开发并发布了KLOCR，这是一种强大的双语OCR基准模型，经过1亿实例的训练，能够增强VLMs的OCR能力。为了补充现有的视觉问答（VQA）基准，团队还创建了KOCRBench，一个针对韩语文本的VQA基准，分析了不同的提示方法。实验结果表明，通过OCR提取的文本能够明显提升开源和商业模型的性能。", "innovation": "该研究创新性地提出了一种利用OCR增强生成的方法，特别是通过开发和公开KLOCR模型。KLOCR模型经过大规模数据集的训练，以增强视觉语言模型的OCR能力。此外，研究团队还创建了KOCRBench数据集，为韩语文本的VQA研究提供了新的基准，并探索了不同的提示方法。实验结果显示OCR提取的文本能够显著提升多种视觉语言模型的性能。", "conclusion": "实验结果表明，OCR提取的文本能够显著提升多种视觉语言模型的性能，特别是在双语VQA任务中的表现。该研究还提供了OCR增强生成的新见解，未来的研究可以进一步探索这一方法的有效性，并将其应用于更广泛的多语言场景。所有模型、代码和数据均可通过提供的链接访问。"}
{"llm_update_time": "20251006", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2505.11274", "html_url": "https://arxiv.org/abs/2505.11274", "title": "SelfBudgeter: 自适应令牌分配以提高LLM推理效率", "title_en": "SelfBudgeter: Adaptive Token Allocation for Efficient LLM Reasoning", "authors": "Zheng Li,Qingxiu Dong,Jingyuan Ma,Di Zhang,Kai Jia,Zhifang Sui", "background": "推理模型在复杂任务上表现出色，但在处理简单问题时往往表现出过度思考的倾向。这种现象不仅导致了过多的计算资源消耗，还严重降低了用户体验。为解决这一挑战，我们提出了一种新颖的用户友好型自适应可控制推理框架——SelfBudgeter，该框架在推理前引入了预算估算机制。", "innovation": "SelfBudgeter采用了一种双重训练范式：在冷启动阶段，模型学习在执行标准化推理之前预测令牌预算；在强化学习阶段，模型根据问题难度自动生成预算并在生成响应时严格遵守。由于模型在初始阶段输出预算估算，用户可以立即预测等待时长，从而灵活决定是否中断或继续生成过程。值得注意的是，该方法支持通过预填充的预算字段手动控制推理长度。", "conclusion": "实验证明，SelfBudgeter可以根据问题复杂性动态分配预算，1.5B模型在GSM8K、MATH500和AIME2025中的响应长度压缩了61%，7B模型压缩了48%，同时保持几乎不变的准确性。"}
{"llm_update_time": "20251006", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.02561", "html_url": "https://arxiv.org/abs/2510.02561", "title": "Oracle-RLAIF: 通过排名反馈进行多模态视频模型的增强学习改进微调框架", "title_en": "Oracle-RLAIF: An Improved Fine-Tuning Framework for Multi-modal Video Models through Reinforcement Learning from Ranking Feedback", "authors": "Derek Shi,Ruben Glatt,Christine Klymko,Shubham Mohole,Hongjun Choi,Shashank Kushwaha,Sam Sakla,Felipe Leno da Silva", "background": "近年来，大规模视频-语言模型（VLMs）的进步依赖于广泛使用的微调技术，以增强文本理解和视觉信息的对齐。主流方法通常结合监督微调（SFT）和基于偏好数据的强化学习，以增强视频理解能力。然而，随着VLMs的参数规模不断增大，收集足够的反馈质量更高的视频反馈数据的成本也在增加。因此，最近的研究探索了使用AI反馈的强化学习方法（RLAIF），以替代人类偏好作为评估标准，从而降低微调的成本。当前的RLAIF框架依赖于一种专门的奖励模型，这种模型需要使用视频叙述进行训练，以生成经过校准的比例奖励，这是一条既昂贵又受限的管道。", "innovation": "本文提出了Oracle-RLAIF，这是一种新的框架，它用一种更通用的Oracle排名器替代了训练好的奖励模型，该Oracle排名器作为插件模型来对候选模型响应进行排序，而不是评分。此外，还引入了基于组相对策略优化的新排名损失函数($GRPO_{rank}$)，直接优化序数反馈，且具有排比感知优势。实验结果表明，Oracle-RLAIF在各种视频理解基准测试中的表现优于现有的微调方法，从而为使用排名而不是评分进行大规模多模态视频模型与强化学习的对齐开辟了灵活且数据高效的路径。", "conclusion": "Oracle-RLAIF提供了一种新的微调框架，它通过排名反馈改进了多模态视频模型的强化学习。该模型的性能显著优于现有的微调方法，从而促进了大规模多模态视频模型在视频理解任务中的应用，且具有更高的数据效率和灵活性。"}
{"llm_update_time": "20251006", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2509.23753", "html_url": "https://arxiv.org/abs/2509.23753", "title": "Anchored Supervised Fine-Tuning", "title_en": "Anchored Supervised Fine-Tuning", "authors": "He Zhu,Junyou Su,Peng Lai,Ren Ma,Wenjia Zhang,Linyi Yang,Guanhua Chen", "background": "对大型语言模型的后训练涉及一个基本权衡，即监督微调（SFT），它能高效地模仿示例，但往往会导致模型记忆；而强化学习（RL）在更高的计算成本下能实现更好的泛化。动态微调（DFT）作为一种新兴的选择，通过重新加权SFT目标来实现某些推理领域的改进，但其他任务上表现出不稳定性，缺乏分布锚定导致训练不稳定。", "innovation": "提出了一种名为Anchored Supervised Fine-Tuning (ASFT)的方法，该方法通过添加轻量级KL正则化来保留DFT的加权重设优势同时确保训练稳定性，在数学推理、医学知识对接和代码生成等任务上，ASFT在最小计算开销下较SFT和DFT取得了实质性改进，其RWR框架为理解后训练方法提供了一种系统视角，并证明了准确实证分析可以带来更强的保证和实际收益。", "conclusion": "通过ASFT，作者展示了应该如何通过理论分析来指导方法的选择，从而在保持模型泛化性能的同时提高训练稳定性，其RWR框架为探索优化大型语言模型后训练的方法提供了重要的理论基础，并在多个任务上验证了该方法的有效性。"}
{"llm_update_time": "20251006", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.02125", "html_url": "https://arxiv.org/abs/2510.02125", "title": "跨模态的人工智能模型是否进行类人类的抽象推理？", "title_en": "Do AI Models Perform Human-like Abstract Reasoning Across Modalities?", "authors": "Claas Beger,Ryan Yi,Shuhao Fu,Arseny Moskvichev,Sarah W. Tsai,Sivasankaran Rajamanickam,Melanie Mitchell", "background": "OpenAI的o3-preview推理模型在ARC-AGI基准测试中超过了人类的准确性，但在当前基于准确性评估模型抽象推理能力的情况下，我们不知道最先进的模型是否真正理解并利用了任务设计者意图传达的抽象概念。因此，该研究通过对ConceptARC任务的评估，探讨了模型的抽象能力，分析了在不同输入模态（文本或视觉）、是否使用外部Python工具以及推理努力程度的变化条件下，模型的表现。这也包括对模型生成的推理规则进行细粒度的自然语言分析，以便评估模型是否真正使用了ConceptARC旨在引发的抽象概念，还是依赖于表面特征。该研究结果显示，尽管一些使用基于文本表示模型的输出与人类的输出准确性相当，但最佳模型的规则往往基于表面的“捷径”并远远不如人类频繁地捕捉到目标抽象概念。这表明，仅仅通过准确性评估可能高估了模型在文本模态中的概括推理能力，并低估了其在视觉模态中的此类能力。视觉模态下模型的输出准确性急剧下降，但规则分析显示模型仍可表现出大量捕获目标抽象概念的规则，但往往不能正确应用这些规则。因此，模型在抽象推理方面仍然落后于人类，而且仅通过准确性来评估ARC类似任务的抽象推理能力可能在文本模态中高估了抽象推理能力，并在视觉模态中低估了这种能力。研究认为，该评估框架提供了多模态模型抽象推理能力的更忠实画像，也为追踪向类似人类、抽象中心的认知智能方向的进步提供了更合乎原理的方法。", "innovation": "研究通过对ConceptARC任务的不同输入模态、允许使用外部工具以及推理努力程度变化条件下的评估，以及对模型生成的解释规则进行细粒度的自然语言分析，提出了一种多模态模型抽象推理能力的更忠实评估框架。这使得研究人员能够更加准确地评估模型是否真正使用了设计意图中的抽象概念，避免仅依靠准确性评估带来的误区。", "conclusion": "该研究结果表明，模型在抽象推理方面仍然落后于人类，仅通过准确性评估可能高估了模型在文本模态中的抽象推理能力，并低估了其在视觉模态中的此类能力。多模态模型的抽象推理能力需要使用更忠实的评估框架进行衡量，以更公正地追踪模型向灵活抽象中心认知智能的进步。"}
{"llm_update_time": "20251006", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2506.15655", "html_url": "https://arxiv.org/abs/2506.15655", "title": "cAST: 使用抽象语法树的结构化分块增强代码检索增强生成", "title_en": "cAST: Enhancing Code Retrieval-Augmented Generation with Structural Chunking via Abstract Syntax Tree", "authors": "Yilin Zhang,Xinran Zhao,Zora Zhiruo Wang,Chenyang Yang,Jiayi Wei,Tongshuang Wu", "background": "RAG（检索增强生成）已经成为大规模代码生成的关键技术，通过将预测置于外部代码语料库中，提高生成的实际性。但是，现有的RAG管道中的一个关键但尚未充分探索的方面是分块过程，即将文档分割为可检索的单元。现有基于行的分块启发式方法往往破坏了语义结构，将函数拆分或合并不相关的代码，这会降低生成质量。", "innovation": "本文提出了一种基于抽象语法树（cAST）的结构感知分块方法，该方法递归地将较大的AST节点分解为较小的块，并合并兄弟节点，同时遵守大小限制。这种方法生成了跨编程语言和任务的自包含、语义上连贯的单元，提高了多种代码生成任务的性能，例如在RepoEval检索中的查全率（Recall@5）提高了4.3个百分点，在SWE-bench生成中的通过率（Pass@1）提高了2.67个百分点。", "conclusion": "本文的工作强调了结构感知分块对于扩展增强检索代码智能的重要性。"}
{"llm_update_time": "20251006", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.02601", "html_url": "https://arxiv.org/abs/2510.02601", "title": "在移动多相机装置中进行户外手部的自我与外部3D跟踪", "title_en": "Ego-Exo 3D Hand Tracking in the Wild with a Mobile Multi-Camera Rig", "authors": "Patrick Rim,Kun He,Kevin Harris,Braden Copple,Shangchen Han,Sizhe An,Ivan Shugurov,Tomas Hodan,He Wen,Xu Xie", "background": "在不受限设置中准确追踪手部及其与世界互动一直是个显著挑战，现有的大多数据集局限于受控实验室环境，限制了环境多样性和模型的普适性。", "innovation": "提出一种无标记的多相机系统，结合轻量级背戴捕捉设备和八个旁观相机，以及用户穿戴的Meta Quest 3头显，提供了自我与外部（ego-exo）的跟踪流程，生成精确的3D手部姿态作为地面真相，通过同步多视图图像和精确的3D手部姿态来确保现实环境和3D注释精度之间的平衡。", "conclusion": "通过收集标注数据集，展示了该方法显著降低了环境现实性和3D标记精度之间的权衡。"}
{"llm_update_time": "20251006", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2509.22315", "html_url": "https://arxiv.org/abs/2509.22315", "title": "PRIME: Planning and Retrieval-Integrated Memory for Enhanced Reasoning", "title_en": "PRIME: Planning and Retrieval-Integrated Memory for Enhanced Reasoning", "authors": "Hieu Tran,Zonghai Yao,Nguyen Luong Tran,Zhichao Yang,Feiyun Ouyang,Shuo Han,Razieh Rahimi,Hong Yu", "background": "本文受到人类认知的双重过程理论的启发，特别是《思考，快与慢》这本书中的观点。文章介绍了PRIME框架，这是一种多智能体推理框架，动态地结合了快速直观的思维（系统1）和缓慢的深度思考（系统2）两种认知过程，旨在模仿人类的认知过程，提高推理的效率和准确性。实验结果显示，使用LLaMA 3模型的PRIME在涉及多步和知识基础推理的基准测试中与GPT-4和GPT-4o等最先进的闭源模型表现出竞争性。这表明，PRIME为改善需要复杂、知识密集型推理的LLM提供了一种可扩展的解决方案", "innovation": "PRIME框架通过结合快速和深度的思考过程，动态地进行多智能体推理。它首次利用快速思考智能体生成快速的答案，如果检测到不确定性，则触发包含专化规划、假设生成、检索、信息整合和决策制定等模块的结构化系统2推理管道。该设计旨在更好地模拟人类的认知过程，提高推理的效率和准确性，并使开源的LLM在复杂的推理任务中与最先进的闭源模型竞争", "conclusion": "实验结果表明，PRIME使得开源LLM在需要多步骤和知识驱动推理的基准测试中与GPT-4和GPT-4o等最先进的闭源模型表现出竞争性。该研究确立了PRIME作为改善需要复杂、知识密集型推理领域中的LLM的可扩展解决方案的地位"}
{"llm_update_time": "20251006", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.02617", "html_url": "https://arxiv.org/abs/2510.02617", "title": "输入感知稀疏注意力机制在实时同步唇动视频生成中的应用", "title_en": "Input-Aware Sparse Attention for Real-Time Co-Speech Video Generation", "authors": "Beijia Lu,Ziyi Chen,Jing Xiao,Jun-Yan Zhu", "background": "扩散模型可以从音频中合成现实的同步唇动视频，适用于多种应用，如视频创作和虚拟代理。然而，现有的基于扩散的方法由于包含众多的去噪步骤和昂贵的注意力机制而速度较慢，这妨碍了实时部署。", "innovation": "本文提出了一种新的视频蒸馏方法，利用输入的人体姿态条件来指导注意力机制和损失函数，通过输入感知的稀疏注意力减少冗余计算，增强身体部位的时间对应关系，提高推理效率和运动连贯性。同时，引入了输入感知的蒸馏损失，增强了唇部同步和手部动作的真实度。通过结合输入感知的稀疏注意力和蒸馏损失，本文的方法在保持较好视觉质量的同时实现了实时性能。", "conclusion": "本文通过提出输入感知的稀疏注意力机制和蒸馏损失，实现实时生成同步唇动视频，并且在视觉质量和实时性能方面优于近期的声音驱动和输入驱动方法。实验证明了本文算法设计的有效性。"}
{"llm_update_time": "20251006", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.02631", "html_url": "https://arxiv.org/abs/2510.02631", "title": "使用功能性LoRA的深度生成持续学习：FunLoRA", "title_en": "Deep Generative Continual Learning using Functional LoRA: FunLoRA", "authors": "Victor Enescu,Hichem Sahbi", "background": "在文本和视觉应用中，深度生成模型的持续适应具有巨大的潜力和关键性。然而，增量训练面临严峻挑战，原因是灾难性遗忘现象使神经网络难以有效纳入新知识。一种常见的策略是重新训练生成模型，但这种方法存在两个主要局限性：一是不断增长的训练时间变得难以处理；二是依赖合成数据导致长期性能下降，因为合成样例缺乏真实训练数据的丰富性。", "innovation": "本文设计了一种新颖且更表达性强的生成模型条件机制，基于低秩适应(LoRA)，仅使用秩1矩阵，并通过精心选择的函数动态增加重参数化矩阵的秩——命名为功能LoRA：FunLoRA。采用这种动态调节，生成模型可以避免灾难性遗忘，仅需针对当前任务的训练数据进行训练。通过从零开始训练基于流动匹配模型，实验表明，提出的方法在参数效率微调(PET)方面超过基于扩散模型的先前最佳结果，获得更高的分类准确性，同时只需要较少的内存成本和采样时间。", "conclusion": "我们的研究表明，通过使用FunLoRA，可以在有限的计算资源下有效解决深度生成模型的灾难性遗忘问题，同时保持高质量的生成结果，为持续学习应用提供了新的途径。"}
{"llm_update_time": "20251006", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.02599", "html_url": "https://arxiv.org/abs/2510.02599", "title": "PEO：使用提示嵌入优化在预训练文本到图像扩散模型中的无训练美学质量增强", "title_en": "PEO: Training-Free Aesthetic Quality Enhancement in Pre-Trained Text-to-Image Diffusion Models with Prompt Embedding Optimization", "authors": "Hovhannes Margaryan,Bo Wan,Tinne Tuytelaars", "background": "在给定简单提示时，现有的预训练文本到图像扩散模型在美学质量上存在改进的空间。传统的文本到图像生成方法往往依赖于预训练模型，并且可能需要调整参数或训练新的模型。", "innovation": "提出了一种名为Prompt Embedding Optimization (PEO)的新方法，该方法利用预训练的文本到图像扩散模型作为基础结构，并优化给定简单和未编辑的提示的文本嵌入，以提高生成图像的视觉质量。PEO通过三元目标函数实现，该函数提高了生成图像的美学保真度，确保了优化后的文本嵌入的遵守，并尽可能接近初始提示。此外，PEO是无训练的和基干独立的。", "conclusion": "定性和定量评估表明，所提出的方法在美学质量上超过了或与其他最先进的文本到图像和提示适应方法相当。PEO无需训练且对基础模型无依赖，因此具有广泛的应用前景。"}
{"llm_update_time": "20251006", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.02654", "html_url": "https://arxiv.org/abs/2510.02654", "title": "Smart-GRPO: 智能采样噪声以实现流动匹配模型的有效强化学习", "title_en": "Smart-GRPO: Smartly Sampling Noise for Efficient RL of Flow-Matching Models", "authors": "Benjamin Yu,Jackie Liu,Justin Cui", "background": "近年来，流匹配在生成高质量文本到图像方面取得了进展。然而，流匹配模型的确定性使其不适合用于强化学习，强化学习是提高图像质量和人类对齐的关键工具。先前工作通过在潜在变量中添加随机噪声引入了随机性，但这会产生效率低下且不稳定的结果。", "innovation": "本文提出了一种名为Smart-GRPO的方法，这是第一个在流匹配模型中利用噪声优化进行强化学习的方法。Smart-GRPO采用迭代搜索策略，通过解码候选噪声、使用奖励函数评估噪声效果，并调整噪声分布以获得更高奖励的区域。实验表明，Smart-GRPO在奖励优化和视觉质量方面优于基线方法。", "conclusion": "我们的结果指示了一条将强化学习与流动匹配框架结合以提高生成效率和人机对齐的实用路径，缩小了高效训练与人类导向生成之间的差距。"}
{"llm_update_time": "20251006", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2507.02790", "html_url": "https://arxiv.org/abs/2507.02790", "title": "从长视频到引人入胜的片段：基于多模态叙事理解的人类启发式视频编辑框架", "title_en": "From Long Videos to Engaging Clips: A Human-Inspired Video Editing Framework with Multimodal Narrative Understanding", "authors": "Xiangfeng Wang,Xiao Li,Yadong Wei,Xueyu Song,Yang Song,Xiaoqiang Xia,Fangrui Zeng,Zaiyi Chen,Liu Liu,Gu Xu,Tong Xu", "background": "在线视频内容，尤其是短视频平台上的内容迅速增长，产生了对高效视频编辑技术的需求，这些技术能够将长格式视频浓缩成简洁且引人入胜的片段。现有的自动编辑方法主要依赖ASR转录中的文本提示和端到端的片段选择，忽视了丰富的视觉上下文，导致输出不连贯。", "innovation": "本文提出了一种基于多模态叙事理解的人类启发式自动视频编辑框架（HIVE）。该框架结合了人物提取、对话分析和通过多模态大型语言模型进行叙事总结，实现了视频内容的整体理解。为增强连贯性，该框架采用场景级别分割，并将编辑过程分解为三个子任务：亮点检测、开头/结尾选择和去除无关内容。", "conclusion": "实验结果表明，本文提出的框架在通用编辑任务和广告导向编辑任务中均优于现有基准模型，显著缩小了自动编辑视频与人工编辑视频的质量差距。"}
{"llm_update_time": "20251006", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.02642", "html_url": "https://arxiv.org/abs/2510.02642", "title": "顺序保持的双视场防御技术在自主车辆中交通标志和信号灯识别中的应用", "title_en": "Sequence-Preserving Dual-FoV Defense for Traffic Sign and Light Recognition in Autonomous Vehicles", "authors": "Abhishek Joshi,Jahnavi Krishna Koda,Abhishek Phadke", "background": "交通信号灯和标志的识别对于自主车辆（AV）至关重要，因为感知错误直接影响导航和安全。除了数字对抗攻击之外，模型还容易受到现有外部干扰（如反光、雨天、灰尘或涂鸦），这些干扰可能导致危险的误分类。目前，缺乏对时间连续性、多视场视角传感以及对数字和自然降级的鲁棒性的考虑。这项研究基于aiMotive、Udacity和Waymo等多个数据源，包括德克萨斯州的自制视频，构建了一个多源数据集，提出了一个面向美国区域交通信号灯和标志的双视场、保持顺序的鲁棒性框架", "innovation": "该研究提出了一个基于多源数据集的双视场、保持顺序的鲁棒性框架，应用于美国的交通信号灯和标志识别。它首次结合了中期和长期序列、对四个操作设计域（高速公路、夜间、雨天和城市）的处理，以及一种统一的三层防御框架，包括特征压缩、防御性蒸馏和基于熵的异常检测，以及序列级的时间投票，以增强模型的鲁棒性。此外，实验还利用攻防对工具验证了物理可移植性", "conclusion": "实验结果显示，统一防御堆栈在真实应用场景中的检测准确率为79.8mAP，并将攻击成功率降低到18.2%，相比YOLOv8、YOLOv9和BEVFormer等模型，在降低高风险误分类率（32%）方面表现更好。"}
{"llm_update_time": "20251006", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.02571", "html_url": "https://arxiv.org/abs/2510.02571", "title": "视频模型有多自信？让视频模型表达其不确定性", "title_en": "How Confident are Video Models? Empowering Video Models to Express their Uncertainty", "authors": "Zhiting Mei,Ola Shorinwa,Anirudha Majumdar", "background": "生成视频模型展示了令人印象深刻的文本到视频能力，在许多现实应用中得到了广泛应用。然而，就像大型语言模型（LLMs）一样，生成视频模型也往往会虚幻妄想，即使是在事实错误的情况下也能生成看似合理的视频。尽管之前的许多研究都在LLMs的不确定性量化（UQ）方面进行了深入探讨，但视频模型的UQ方法却不存在，这引起了严重的安全问题。到目前为止，该领域首次提出了量化视频模型不确定性的方法。论文提出了一种针对生成视频模型的不确定性量化框架，包括用于基于鲁棒排名相关性估计的评估模型校准的度量，一种基于潜在建模的黑盒不确定量化方法S-QUBED，以及一个用于视频模型校准基准测试的数据集。通过在潜在空间中调整生成任务，分离由于模糊的任务说明和由于知识不足产生的不确定性。通过在基准视频数据集上的大量实验，论文展示了S-QUBED计算与任务准确性负相关的校准总不确定性估计，并有效计算了 aleatoric 和 epistemic 成分。", "innovation": "该论文首次提出了针对视频生成模型的不确定性量化方法。具体贡献包括一个基于鲁棒排名相关性估计的模型校准度量方法，一种基于潜在建模的黑盒UQ方法S-QUBED，以及用于视频模型校准基准测试的数据集。S-QUBED通过潜在空间调整生成任务，将不确定性分解为 aleatoric 和 epistemic 成分。该方法通过实验展示了其在视频模型校准方面的优越性能。", "conclusion": "通过提出S-QUBED方法，该论文为视频生成模型的不确定性量化提供了一个有效的框架。该方法能够在不严格假设模型情况下评估模型的校准度，并有效拆分了预测不确定性。该研究为提升视频生成模型的安全性和可靠性做出了重要贡献。"}
{"llm_update_time": "20251006", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.02570", "html_url": "https://arxiv.org/abs/2510.02570", "title": "解锁合作伙伴关系的力量：人类和机器如何共同提高 facial 认知的准确性", "title_en": "Unlocking the power of partnership: How humans and machines can work together to improve face recognition", "authors": "P. Jonathon Phillips(1),Geraldine Jeckeln(2),Carina A. Hahn(1),Amy N. Yates(1),Peter C. Fontana(1),Alice J. O'Toole(2) ((1) Information Access Division, National Institute of Standards and Technology, Gaithersburg, MD (2) School of Behavioral and Brain Sciences, The University of Texas at Dallas, Richardson, TX)", "background": "面部识别算法的最终决策需要人类审核，创建了一个‘协作’的人机系统。然而，人类和机器之间的个体差异影响了这种协作对准确性的影响。本研究探讨了结合人类和机器的面部识别决策如何提高准确性，并发现准确性差异较小的合作群体可以获得更好的协同效益。通过专家和非专家对比，研究确认了当人类的准确性低于机器但融合两人判断时，系统准确度提高的现象，并提出了一种‘接近准确法则’（PAR），该法则适用于不同能力水平的合作群体。此外，研究还基于图论找到了仅有人类合作的最高系统准确度，但智能的人机融合不仅能更有效提高系统的平均准确度，还能显著减少低效人类对系统整体准确度的影响。研究表明，人类和机器在面部识别中的角色都是不可替代的，并提供了基于证据的使用人工智能的指南，以提高面部识别的准确性。", "innovation": "提出了‘接近准确法则’（PAR），展示了这种准则在不同基础准确率的合作项目中都有效。基于PAR，研究定义了一个‘关键融合区’，在此区域内，人类的准确性虽然低于机器，但将两者融合可提高系统的整体准确性。研究还实施了‘智能人机融合’方法，该方法选择那些能够提高高性能机器准确度的人类。这种方法比机器单独工作和混合所有人类和机器的判断更准确。研究结果表明，智能人机协作能够更有效地减少低效人类对系统整体准确度的影响，从而提供了一种有效的智能使用人工智能的策略。", "conclusion": "研究表明，人类和机器在保证面部识别准确性方面都发挥着不可替代的作用。该研究为智能使用人工智能提供了基于证据的路线图，以提高面部识别的准确性。"}
{"llm_update_time": "20251006", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.02566", "html_url": "https://arxiv.org/abs/2510.02566", "title": "PhysHMR：从视觉学习人体控制策略以实现物理可信的人体运动重建", "title_en": "PhysHMR: Learning Humanoid Control Policies from Vision for Physically Plausible Human Motion Reconstruction", "authors": "Qiao Feng,Yiming Huang,Yufu Wang,Jiatao Gu,Lingjie Liu", "background": "计算机视觉和图形领域中，从单目视频重建物理上可信的人类运动仍然是一个具有挑战性的问题。现有方法主要集中在基于运动学的姿态估计上，这往往会导致不现实的结果，因为缺乏物理约束。为了应对这种现象，之前的许多方法依赖于在初始的基于运动学的运动估计之后进行物理过程的后处理。然而，这种两阶段的设计会导致误差累积，最终限制了整体重建的质量。", "innovation": "本文提出了一种名为PhysHMR的统一框架，该框架直接学习从视觉到动作的策略，可以在物理基础上控制仿人模型，并与输入视频中的视觉对齐。该方法的关键组成部分是像素作为射线的策略，它将2D关键点提升为3D空间射线并转化为全局空间。这些射线被用作策略输入，提供鲁棒的全局姿态指导，无需依赖噪声的3D根预测。与先验编码器的局部视觉特征相结合，该策略可以进行详细姿态和全局定位的推理。此外，为了克服强化学习的样本效率问题，引入了一种从骨架动作捕捉器训练的专家转移运动知识到视觉条件下的策略的方法，并通过具有物理动机的强化学习奖励对其进行细化。", "conclusion": "广泛的实验表明，PhysHMR 能够在各种场景中产生高保真度、物理上可信的运动，相比先前的方法，在视觉准确性和物理现实性方面表现更佳。"}
{"llm_update_time": "20251006", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.02750", "html_url": "https://arxiv.org/abs/2510.02750", "title": "基于视觉语言模型的物体识别与检测的贝叶斯测试时自适应方法", "title_en": "Bayesian Test-time Adaptation for Object Recognition and Detection with Vision-language Models", "authors": "Lihua Zhou,Mao Ye,Shuaifeng Li,Nianxin Li,Jinlin Wu,Xiatian Zhu,Lei Deng,Hongbin Liu,Jiebo Luo,Zhen Lei", "background": "视觉语言模型（VLMs）如CLIP和Grounding DINO在物体识别和检测方面取得了显著成就。然而，这些模型在真实世界中的分布变化场景下表现往往不佳。现有方法要么依赖计算昂贵的反向传播，这妨碍了实时部署，要么仅专注于似然性适配，而忽略了先验知识的重要性。我们的前期工作Bayesian Class Adaptation (BCA)通过引入无需训练的框架，结合了自适应先验知识解决了这些局限性，特别是针对物体识别。", "innovation": "我们在此基础上提出了Bayesian Class Adaptation plus (BCA+)，这是一个统一的、无需训练的测试时自适应框架，适用于物体识别和检测。BCA+引入了一个动态缓存，该缓存能够自适应地存储和更新类别嵌入、空间尺度（对于检测）以及从历史预测中派生的自适应类别先验。通过将初始VLM输出与基于缓存的预测融合，实现了适应过程。这种方法结合了动态更新的似然性（衡量特征和尺度的相似性）和一个先验（反映类分布的变化）。这种双重适应机制，加上基于不确定性的融合，使BCA+能够同时纠正模型的语义理解和上下文置信度。作为不需训练的框架，BCA+不依赖反向传播，效率非常高。", "conclusion": "详尽的实验表明，BCA+在识别和检测基准测试中达到了最先进的性能。"}
{"llm_update_time": "20251006", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.02732", "html_url": "https://arxiv.org/abs/2510.02732", "title": "从token到节点：基于语义的动态3D高斯点云运动控制", "title_en": "From Tokens to Nodes: Semantic-Guided Motion Control for Dynamic 3D Gaussian Splatting", "authors": "Jianing Chen,Zehao Li,Yujun Cai,Hao Jiang,Shuqin Gao,Honglong Zhao,Tianlu Mao,Yucheng Zhang", "background": "单目视频的动态3D重建仍具有挑战性，主要是由于从有限视角推测3D运动的不明确性以及建模随时间变化场景的计算需求。尽管最近的稀疏控制方法通过将数百万高斯点减少到数千个控制点来减轻计算负担，但这会导致控制点的静态冗余和动态不足。现有的方法在控制点的分配上是基于几何的，这导致了静态区域的冗余和动态区域的不足。因此，这篇论文提出了一种运动自适应框架，以适应不同运动复杂度的场景，并合理分配控制点，从而更好地实现场景的动态重建。该框架利用视觉基础模型提供的语义和运动先验知识，为动态区域集中控制点的同时抑制静态背景的冗余。", "innovation": "提出了一种运动自适应框架，该框架通过迭代体素化和运动倾向评分来实现表示密度的灵活适应。该方法利用视觉基础模型的语义和运动先验知识，建立补丁-令牌-节点对应关系，并采用运动自适应压缩技术来集中控制点的动态区域，同时抑制静态背景的冗余。此外，提出了基于样条的轨迹参数化方法，以捕捉运动的时空演变，替代基于MLP的变形领域，实现更平滑的运动表示和更稳定的优化。", "conclusion": "通过大量的实验，该方法在重建质量和效率上均超过了现有的最先进方法，显著提高了动态3D重建的效果和效率。"}
{"llm_update_time": "20251006", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.02733", "html_url": "https://arxiv.org/abs/2510.02733", "title": "Net2Net: 当未训练网络遇到预训练网络时的鲁棒现实世界去噪", "title_en": "Net2Net: When Un-trained Meets Pre-trained Networks for Robust Real-World Denoising", "authors": "Weimin Yuan,Cai Meng", "background": "传统去噪方法主要依赖手工设计的先验知识，在受控环境中表现良好，但在处理复杂多变的实际噪声时显得力不从心。相比之下，基于深度学习的方法能够在大量数据集上学习噪声特性，但这些方法往往需要大量带标签的数据，并且在处理不同噪声类型和成像条件方面缺乏有效泛化能力。", "innovation": "Net2Net结合了未训练网络（Untrained）和预训练网络（Pre-trained）的优势，在去噪过程中无需依赖标签数据。未训练网络能够适应每个输入图像的独特噪声特性，而预训练网络利用大规模数据集中学到的表示来提供鲁棒去噪性能。这种方法通过正则化去噪（RED）结合了这两种模型，形成了一个混合框架，增强了在各种噪声模式下的泛化能力，特别是在训练数据有限的情况下表现更加出色。", "conclusion": "在基准数据集上的广泛实验表明，我们的方法在现实世界噪声去除方面具有明显优势。"}
{"llm_update_time": "20251006", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.02780", "html_url": "https://arxiv.org/abs/2510.02780", "title": "认知谜题：解释性揭示视觉语言模型的认知极限", "title_en": "Reasoning Riddles: How Explainability Reveals Cognitive Limits in Vision-Language Models", "authors": "Prahitha Movva", "background": "视觉-语言模型在多项多模态任务中表现出色，但在解决复杂横向思维挑战如谜语时，其认知过程仍然具有透明度。尽管最近的研究已经证明这些模型在解决谜语时面临重大挑战，但其背后的推理过程和失败模式仍然很少被探索。通过全面的可解释性分析，本研究进一步理解了视觉-语言模型如何应对这些复杂的横向思维挑战。", "innovation": "本研究贡献了一个系统注释的数据集，其中包含221个跨六个认知类别排列的谜语，并且开发了一种评估框架，将推理质量与答案正确性区分开来。研究中设计了三种提示策略，以引发不同类型的解释过程，并揭示了视觉-语言模型认知过程的关键见解。研究结果表明，推理质量在谜语类别之间差异巨大，模型在视觉组成方面表现出系统优势，但在涉及存在理解和文化象征方面存在根本局限。此外，研究发现提示策略显著影响了认知方法和问题解决效果，确立了解释性在模型性能中的核心作用，而不仅仅是事后考虑。", "conclusion": "本研究证明了推理质量在不同谜语类别之间存在巨大差异，视觉-语言模型在视觉组成方面表现出优势，但存在基线文化象征理解能力的局限性。提示策略对认知方法和问题解决效果有显著影响，解释性是衡量模型性能的关键部分，应被视为模型评估的创始组成部分。"}
{"llm_update_time": "20251006", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.02691", "html_url": "https://arxiv.org/abs/2510.02691", "title": "FSFSplatter: 3分钟内构建表面和新颖视图的稀疏视图方法", "title_en": "FSFSplatter: Build Surface and Novel Views with Sparse-Views within 3min", "authors": "Yibin Zhao,Yihan Pan,Jun Nan,Jianjun Yi", "background": "高斯点云是一种领先的重建技术，以其高质量的新颖视角合成和详细的重建而著称。然而，现有的大多数方法需要密集校准的视图，从自由稀疏的图像进行重建往往由于重叠有限和过拟合并导致表面质量较差。", "innovation": "本文提出了一种名为FSFSplatter的新方法，专门用于从自由稀疏图像进行快速表面重建。该方法整合了从端到端密集高斯初始化、相机参数估计和几何增强场景优化。FSFSplatter利用大型Transformer编码多视角图像，并通过自分割高斯头生成稠密且几何一致的高斯场景初始化。此外，它通过贡献度剪枝消除局部漂浮的点，利用深度和多视图特征监督在快速优化期间以不同相机参数来缓解部分视图造成的过拟合问题。", "conclusion": "FSFSplatter在广泛使用的DTU和Replica数据集上优于当前最先进的方法。"}
{"llm_update_time": "20251006", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.02745", "html_url": "https://arxiv.org/abs/2510.02745", "title": "Retrv-R1：一个基于推理驱动的MLLM框架，用于高效泛模态检索", "title_en": "Retrv-R1: A Reasoning-Driven MLLM Framework for Universal and Efficient Multimodal Retrieval", "authors": "Lanyun Zhu,Deyi Ji,Tianrun Chen,Haiyang Wu,Shiqi Wang", "background": "DeepSeek-R1 的成功表明利用强化学习（RL）增强语言模型（LLM）的推理能力的巨大潜力。然而，直接将 DeepSeek-R1 的方法应用于检索任务存在高计算成本和结果不稳定等问题。因此，研究者提出了 Retrv-R1，这是一种专门为多模态通用检索设计的 R1 风格 MLLM。Retrv-R1 旨在通过逐步推理来提高检索结果的准确性。", "innovation": "Retrv-R1 引入了信息压缩模块和细节检查机制，通过减少令牌数量来提高计算效率，同时确保保留关键信息。此外，它还创新地提出了新的训练范式，包括使用检索定制的合成 CoT 数据集作为激活阶段，以及使用新型课程奖励与 RL 结合，提高了性能和效率。这些新型设计使得 Retrv-R1 在多个基准和任务上达到了最佳性能，且具有高效率和强大的泛化能力。", "conclusion": "Retrv-R1 通过引入信息压缩和细节检查机制，并提出新的训练范式，解决了原方法中的计算成本高和结果不稳定的问题。实验结果表明，Retrv-R1 在多个基准和任务上达到了最佳性能，且具有高效率和强大的泛化能力。"}
{"llm_update_time": "20251006", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.02760", "html_url": "https://arxiv.org/abs/2510.02760", "title": "数字病理学中的脑肿瘤分类的层次广义类发现", "title_en": "Hierarchical Generalized Category Discovery for Brain Tumor Classification in Digital Pathology", "authors": "Matthias Perkonigg,Patrick Rockenschaub,Georg Göbel,Adelheid Wöhrer", "background": "准确的脑肿瘤分类对于神经肿瘤手术中的术中决策至关重要。然而，现有方法仅限于固定预定义的类别，因此不能捕捉训练期间未出现的肿瘤类型模式。无监督学习可以从未标记数据中提取通用特征，但缺乏利用标记数据的先验知识的能力，而半监督方法通常假设所有潜在类别在标记数据中都有代表。层次广义类发现（GCD）旨在填补这一空白，通过将已知和未知类别分类到未标记数据中。为了反映脑肿瘤分类学的层次结构，本文提出了一种新型方法级联广义类发现（HGCD-BT），结合层次聚类与对比学习。HGCD-BT通过引入半监督层次聚类损失来扩展基于对比学习的GCD。该方法在打开SRH数据集的刺激拉曼病理学脑肿瘤图像上进行了评估。与最先进的GCD方法相比，HGCD-BT在斑块级分类上的准确度提高了28%，尤其是在识别以前未见过的肿瘤类别方面更具有优势。此外，HGCD-BT在数字脑肿瘤图谱中的苏木精和伊红染色全切片图像的切片级分类上也表现出良好的可泛化性，证明了其在不同成像模态上的适用性.", "innovation": "提出了级联广义类发现（HGCD-BT）方法，结合了层次聚类和对比学习，通过引入一种新颖的半监督层次聚类损失，提高了未见过的肿瘤类别的分类准确度，且在不同成像模态上具有良好的泛化性.", "conclusion": "级联广义类发现（HGCD-BT）在开放SRH数据集和数字脑肿瘤图谱数据集上的表现证明了其在脑肿瘤分类中的优越性和适用性，特别是在识别未见过的肿瘤类别和不同成像模态的泛化性方面."}
{"llm_update_time": "20251006", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.02722", "html_url": "https://arxiv.org/abs/2510.02722", "title": "MoGIC：通过意图理解与视觉上下文增强运动生成", "title_en": "MoGIC: Boosting Motion Generation via Intention Understanding and Visual Context", "authors": "Junyu Shi,Yong Sun,Zhiyuan Zhang,Lijiang Liu,Zhengjie Zhang,Yuxin He,Qiang Nie", "background": "现有的文本驱动的运动生成方法通常将合成看作语言与运动之间的双向映射，但这些方法在捕捉动作执行的因果逻辑和驱动行为的人类意图方面仍然存在局限。此外，缺乏视觉信息将进一步限制生成的精确度和个人化水平，因为语言本身无法详细指定空间时间细节。", "innovation": "该论文提出了MoGIC，这是一种统一框架，将意图建模和视觉先验整合到多模态运动综合中。通过同时优化多模态条件下的运动生成和意图预测，MoGIC能够揭示潜在的人类目标，利用视觉先验增强生成，并展现出多模态生成的多样能力。此外，该框架还引入了一种混合注意力机制，具有自适应范围，以实现条件令牌与运动子序列的局部对齐。", "conclusion": "实验表明，在微调后，MoGIC在HumanML3D上将FID降低了38.6%，在Mo440H上降低了34.6%。与基于大型语言模型的方法相比，在轻量级文本头部的条件下，MoGIC在运动描述方面超过了这些方法，并进一步实现了意图预测和视觉条件生成，推动了可控运动综合和意图理解的进步。代码可在该网址获得：这个 https URL"}
{"llm_update_time": "20251006", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.02787", "html_url": "https://arxiv.org/abs/2510.02787", "title": "OTR：合成覆盖文本数据集用于文本去除", "title_en": "OTR: Synthesizing Overlay Text Dataset for Text Removal", "authors": "Jan Zdenek,Wataru Shimoda,Kota Yamaguchi", "background": "文本去除在计算机视觉中是一个关键任务，广泛应用于隐私保护、图像编辑和媒体再利用等方面。虽然现有研究主要集中在自然图像中的场景文本去除，但是现有的数据集存在不足，限制了跨领域的泛化和准确评估。现有的基准，如SCUT-EnsText数据集，其问题在于：由于人工编辑导致的假阳性、过于简化的文本背景和评估指标无法全面反映生成结果的质量。因此，研究者寻求解决这些问题的方法，以便更好地推进文本去除技术的发展。", "innovation": "为了改进这些问题，作者提出了一种合成数据集的方法，用于文本去除任务。该数据集通过对象感知放置和基于视觉语言模型生成的内容，来合成复杂的背景上的文本图像。这种方法确保了干净的地面真相和更具挑战性的文本去除场景，从而弥补了现有数据集的不足，有助于提高文本去除算法的效果和鲁棒性。此外，该数据集可通过提供的链接获取。", "conclusion": "通过合成具有复杂背景和高质量合成文本的新数据集，研究者提高了解决文本去除问题的能力。这种方法不仅可以应用于场景文本去除，还能推广到其他类型的文本去除任务，改善现有评估指标，并有助于发展具有更好泛化性能的文本去除算法。"}
{"llm_update_time": "20251006", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.02791", "html_url": "https://arxiv.org/abs/2510.02791", "title": "VERNIER: 开源软件推动标记姿态估计至微米和纳米尺度", "title_en": "VERNIER: an open-source software pushing marker pose estimation down to the micrometer and nanometer scales", "authors": "Patrick Sandoz,Antoine N. André,Guillaume J. Laurent", "background": "在小尺度下，姿态估计仍然是一个挑战。现有的方法很少能够捕捉到纳米级和微弧度级别的6自由度物体的精确观测，同时保持相对较大的测量范围。多年以来，研究团队提出多种标记物和图案设计，以实现不同显微镜应用的可靠性能。虽然使用图案编码方法可以实现厘米级别的范围，但利用周期性帧的相位处理则可实现纳米级别的分辨率。然而，现有的相位处理软件往往在处理噪声、焦距偏差和遮挡问题上表现不佳。因此，本研究旨在开发一种名为VERNIER的开源相位处理软件，以提供基于伪周期性图案的快速且可靠的姿态测量方法。", "innovation": "该研究提出了VERNIER，一种实现伪周期性图案的开源相位处理软件，能够在微米和纳米尺度上提供快速且可靠的姿态测量。借助基于相位的局部阈值算法，这种软件在处理噪声、焦距偏差和遮挡方面表现出很高的鲁棒性。研究还详细介绍了相位处理的各个步骤以及为不同应用需求设计的各种类型图案的方法，并用合成和实验图像进行了实施过程的说明。", "conclusion": "最后，研究给出了根据所需性能选择合适的图案设计和显微镜放大镜片的指导原则。该软件有助于在显微镜下的纳米级和微米级环境下实现稳定的标记姿态估计。"}
{"llm_update_time": "20251006", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.02909", "html_url": "https://arxiv.org/abs/2510.02909", "title": "使用基础模型的无监督领域外语义分割", "title_en": "Training-Free Out-Of-Distribution Segmentation With Foundation Models", "authors": "Laith Nayal,Hadi Salloum,Ahmad Taha,Yaroslav Kholodov,Alexander Gasnikov", "background": "在安全性要求高的应用如自动驾驶中，正确识别语义分割中的未知对象至关重要。现有的大型视觉基础模型，如DINOv2、InternImage和CLIP，通过丰富的特征显著提升了跨不同任务的泛化能力。尽管这些模型在封闭集语义任务上表现良好，但在语义分割中检测领域外（OoD）区域的能力仍然未被充分探索。本研究调查了在分割数据集上微调的基础模型是否能在无需异常监督的情况下，能够天然地区分领域内（ID）和领域外（OoD）区域。", "innovation": "提出了一种无需训练的简单方法，利用InternImage主干网络的特征结合K-Means聚类和置信度阈值删除对原始解码器logits的处理，以识别领域外聚类。该方法在RoadAnomaly基准上取得了50.02的平均精度，在ADE-OoD基准上取得了48.77的成绩，超越了多个有监督和无监督的基础方法，表明了通用领域外语义分割方法的潜力，这些方法仅需最少的假设或额外的数据。", "conclusion": "研究表明基础模型可能不需要额外的监督就能在语义分割中区分为内/为外区域，提出的方法在多个基准测试上表现优异，展示了其作为领域外分割方法的可行性。"}
{"llm_update_time": "20251006", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.02790", "html_url": "https://arxiv.org/abs/2510.02790", "title": "MaskCD: 通过图像头部掩蔽对比解码抑制LVLM幻觉", "title_en": "MaskCD: Mitigating LVLM Hallucinations by Image Head Masked Contrastive Decoding", "authors": "Jingyuan Deng,Yujiu Yang", "background": "大型多模态模型（LVLMs）在下游多模态任务中的视觉语言理解方面表现出色。然而，这些模型同时出现了诸多问题，其中幻觉尤其引人关注，指的是LVLM生成与其输入视觉和文本内容矛盾的内容现象。已有许多方法被提出以解决这一问题，如对比解码和注意力操纵。但对比解码方法在构造适当的对比样本方面面临困难，而注意力操纵方法则高度敏感且缺乏稳定性。", "innovation": "本文提出了一种名为MaskCD的新方法，旨在通过利用LVLM中的“图像头部”进行掩蔽对比解码来构建对比样本，以缓解LVLM的幻觉现象并保留其一般能力。", "conclusion": "MaskCD在LLaVA-1.5-7b和Qwen-VL-7b上进行了评估，使用了CHAIR、POPE、AMBER和MME等多项基准测试。实验结果表明，MaskCD有效地缓解了幻觉现象，同时保留了LVLM的总体能力。有关资源可以在这里找到：this https URL。"}
{"llm_update_time": "20251006", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.02898", "html_url": "https://arxiv.org/abs/2510.02898", "title": "One Patch to Caption Them All: A Unified Zero-Shot Captioning Framework", "title_en": "One Patch to Caption Them All: A Unified Zero-Shot Captioning Framework", "authors": "Lorenzo Bianchi,Giacomo Pacini,Fabio Carrara,Nicola Messina,Giuseppe Amato,Fabrizio Falchi", "background": "零样本字幕生成器是最近提出的一种模型，它们利用公共空间的视听表示，在无需依赖成对的图像-文本数据的情况下生成图像字幕。这些模型通过文本解码与文本对齐的图像特征来进行字幕生成，但它们仅限于使用全局表示和全文图像字幕。现有研究还局限于完整的图像描述，缺乏对任意感兴趣区域进行细致字幕生成的能力。", "innovation": "论文提出了一个统一的零样本字幕生成框架\frameworkName{}，将视角从以图像为中心转变为以补丁（局部片段）为中心，从而能够在无需区域级别监督的情况下生成任意区域的字幕。该框架将每个补丁视为独立的字幕单元并进行聚合描述，从单个补丁到不连续区域，乃至整个图像字幕。研究指出，能够生成具有意义且密集视觉特征的模型架构，如DINO，是实现多种基于区域字幕任务的最新性能的关键。", "conclusion": "与现有基线和最先进的竞争对手相比，模型在零样本密集、区域设定以及新引入的轨迹字幕任务中表现出更好的性能，强调了基于补丁的语义表示在可扩展字幕生成中的有效性。"}
{"llm_update_time": "20251006", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.02778", "html_url": "https://arxiv.org/abs/2510.02778", "title": "AdaRD-key: 自适应相关性-多样性关键帧采样以理解长视频", "title_en": "AdaRD-key: Adaptive Relevance-Diversity Keyframe Sampling for Long-form Video understanding", "authors": "Xian Zhang,Zexi Wu,Zinuo Li,Hongming Xu,Luqi Gong,Farid Boussaid,Naoufel Werghi,Mohammed Bennamoun", "background": "对于长时间、高信息密度的长视频内容，现有的视觉-语言模型（VLMs）在理解上面临挑战。当前的多模态大语言模型（MLLMs）依赖均匀采样，这往往忽略了重要时刻，导致对查询的不正确响应。一些关键帧选择方法则以固定的时间间隔选取关键帧，这虽然有效减轻了冗余，但经常错过了与重要事件附近的短而细致的线索。其他方法则强调视觉多样性，但忽视了查询的相关性。这些方法需在缺乏额外监督的情况下，对广泛的查询进行处理并填补信息空白，这增加了视频理解的难度。", "innovation": "本文提出了一种名为AdaRD-Key的训练无监督的关键帧采样模块，以实现基于查询的长视频理解。AdaRD-Key最大化统一的相关性-多样性最大体积（RD-MV）目标，结合查询条件下的相关性得分和对数行列式多样性组件，以生成兼顾信息性和非冗余性的关键帧。在面对与视频弱对齐的广泛查询时，AdaRD-Key采用轻量级的相关性感知门控机制，当相关性分布显示弱对齐时，方法会无缝地切换到纯多样性模式，通过增强覆盖范围来提高覆盖率，而无需额外监督。AdaRD-Key无需训练，计算高效（在单个GPU上实时运行），且以插入即用的方式兼容现有的VLMs。实验证明，该方法在LongVideoBench和Video-MME上实现了最新性能，特别适用于长视频。", "conclusion": "实验结果表明，AdaRD-Key方法在LongVideoBench和Video-MME数据集上实现了最先进的性能，尤其是在处理长视频时表现突出。该方法无需训练，计算效率高，并且可以无缝集成到现有的VLMs中。"}
{"llm_update_time": "20251006", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.02876", "html_url": "https://arxiv.org/abs/2510.02876", "title": "ELMF4EggQ: 一种基于多模态特征融合的集成学习方法用于非破坏性鸡蛋品质评估", "title_en": "ELMF4EggQ: Ensemble Learning with Multimodal Feature Fusion for Non-Destructive Egg Quality Assessment", "authors": "Md Zahim Hassan,Md. Osama,Muhammad Ashad Kabir,Md. Saiful Islam,Zannatul Naim", "background": "准确、无损地评估鸡蛋品质对于确保食品安全、维持产品质量标准以及商业蛋鸡生产操作效率至关重要。本文介绍了一种基于多模态特征融合的集成学习框架ELMF4EggQ，该框架通过图像、形状和重量等外部属性对鸡蛋品级和新鲜度进行分类，而无需破坏鸡蛋。为此，作者构建了一个包含186个褐色壳鸡蛋的新型公共数据集，并利用实验室专家对内部品质的评估（如卵黄指数和哈氏单位）确定鸡蛋的品级和新鲜度等级。通过这种方法，研究填补了使用外部非侵入性特征进行鸡蛋内部品质评估以及发布相应标记数据集的研究空白。此外，该框架整合了从外部鸡蛋图像中提取的深度特征以及鸡蛋的结构特性（如形状和重量），实现对每个鸡蛋的全面表征。", "innovation": "本文首次报道了使用集成学习方法以及仅基于外部非侵入性特征（图像、形状和重量）进行鸡蛋内部品质评估的研究。提出了新的公共数据集ELMF4EggQ，该数据集包含186个褐色壳鸡蛋，并且每个鸡蛋的品级和新鲜度等级都是通过实验室专家评估和内部品质测量（如卵黄指数和哈氏单位）来确定的。在研究中最显著的创新点在于：使用多模式特征融合的方法来评估鸡蛋品质。这种方法增强了分类器的整体准确性，实验结果表明，多模态方法显著优于仅基于图像或仅基于形状与重量的方法，在等级分类中的准确率为86.57%，在新鲜度预测中的准确率为70.83%。另外，本研究发布的所有代码和数据均公开，以提高透明度、可重复性和领域内的进一步研究。", "conclusion": "本文的研究结果表明，多模态框架在鸡蛋品级和新鲜度分类中表现优异，相比基于图像和基于形状与重量的方法，使用ELMF4EggQ方法可以显著提升分类准确度。该方法实现了对鸡蛋品质的无损评估，并为未来的鸡蛋无损品质评估提供了新的技术手段。目前的研究为相关领域提供了可靠的数据集和可复用的算法。"}
{"llm_update_time": "20251006", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.02789", "html_url": "https://arxiv.org/abs/2510.02789", "title": "调整您的查询：多模态医学目标检测中的表示对齐", "title_en": "Align Your Query: Representation Alignment for Multimodality Medical Object Detection", "authors": "Ara Seo,Bryan Sangwoo Kim,Hyungjin Chung,Jong Chul Ye", "background": "在利用单一检测器对混合医学模态（例如，胸片、计算机断层扫描和磁共振成像）进行目标检测时，由于不同模态的异质统计数据和分离的表示空间，医学对象检测效果会受到影响。为了应对这一挑战，研究转向了表示对齐，这一方法已被证明对于将不同来源的特征带入共享空间是有效的。具体来说，研究针对DETRe风格的目标查询进行了研究，提出了一种简单且检测器无关的框架来使这些查询与模态上下文对齐。首先，定义了模态令牌：紧凑的、文本衍生的嵌入表示，用于编码成像模态。这些令牌是轻量级的，无需额外注释即可使用。通过多模态上下文注意（MoCA），将模态令牌整合到检测过程中，通过自我注意来混合目标查询表示，以便在查询集中传播模态上下文。这种方法保持了DETRe风格架构，同时几乎不增加延迟，即可向目标查询注入模态线索。此外，引入了QueryREPA，这是一个简短的预训练阶段，通过使用模态平衡批次的任务特定对比度目标来对齐查询表示和它们的模态令牌。MoCA和QueryREPA共同产生模态感知、类别忠实的查询，这些查询可以有效地转移到下游训练。针对所有混合的医学模态进行训练，所提出的方法在AP（准确率）方面表现出一致的改进，并且最小的开销和无需架构修改，提供了一条通向稳健的多模态医学目标检测的实用途径。", "innovation": "该研究提出了MoCA（Multimodality Context Attention，多模态上下文注意）和QueryREPA（Query Representations Pre-Alignment，查询表示预对齐）两种方法。MoCA通过模态令牌和多模态上下文注意机制来对齐目标查询，保持了DETRe风格架构并且几乎不增加延迟；QueryREPA则是一个简短的预训练阶段，通过任务特定的对比度目标来对齐查询表示和模态令牌。这两种方法共同实现了模态感知、类别忠实的查询，使其能够有效地转移到下游训练。此外，该方法针对所有混合的医学模态进行训练，只需要最小的开销且无需架构修改就能在AP上取得一致的改进，为多模态医学目标检测提供了一条实用路径。", "conclusion": "所提出的方法能够在单一检测器上进行多模态医学目标检测，且保持了类别的忠实性，并通过最小的开销和无需架构修改实现AP的持续提升，提供了一种实用的途径来应对多模态医学目标检测中的挑战。"}
{"llm_update_time": "20251006", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.02815", "html_url": "https://arxiv.org/abs/2510.02815", "title": "Med-K2N: 医学图像合成中的灵活K到N模态转换", "title_en": "Med-K2N: Flexible K-to-N Modality Translation for Medical Image Synthesis", "authors": "Feng Yuan,Yifan Gao,Yuehua Ye,Haoyue Li,Xin Gao", "background": "交叉模态医学图像合成研究旨在从可用的模态中重建缺失的成像模态，以支持临床诊断。临床需求驱动下，我们探索了从K到N的多模态医学生成，其中出现了三大挑战：不同模态对不同目标任务的异构贡献如何建模？如何确保融合质量控制以防止噪声信息导致的降解？如何在多输出生成时保持模态身份的一致性？这些临床需求促使我们借鉴SAM2的序列帧范式，并结合临床工作者逐步增加和选择性整合多模态信息的渐进工作流程，将多模态医学数据视为具有质量驱动选择机制的序列帧。", "innovation": "我们的创新点在于提出了Med-K2N，包括三个协作模块：PreWeightNet用于全局贡献评估，ThresholdNet用于自适应筛选，EffiWeightNet用于有效权重计算。为了保持模态身份的一致性，我们还提出了因果模态身份模块(CMIM)，利用视觉-语言模型在生成图像与目标模态描述之间建立因果约束。Med-K2N在多个基准测试中显著优于现有方法，实验结果证明其优越性。", "conclusion": "我们的研究结果表明，Med-K2N在多项基准测试中显著优于现有方法，证明了其在多模态医学图像合成中的有效性和优越性。源代码已公开。"}
{"llm_update_time": "20251006", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.02913", "html_url": "https://arxiv.org/abs/2510.02913", "title": "通过信心感知加权提高视觉语言模型的零样本鲁棒性", "title_en": "Zero-Shot Robustness of Vision Language Models Via Confidence-Aware Weighting", "authors": "Nikoo Naghavian,Mostafa Tavassolipour", "background": "视觉语言模型，例如CLIP，在零样本场景中展示了出色的泛化能力，但依旧对对抗攻击高度敏感。现有的研究集中在如何提高模型的鲁棒性，尤其是在面对强大的对抗攻击时，但大多数方法在提高鲁棒性的同时可能牺牲了模型的泛化能力。", "innovation": "提出了信心感知加权（CAW）方法，这是一种新的技术手段，旨在提高视觉语言模型的零样本鲁棒性。CAW通过两个关键组件实现：（1）信心感知损失，通过调整干净样本和对抗样本预测之间的KL散度来优先处理不确定的对抗样本；（2）特征对齐正则化，通过最小化冻结和微调图像编码器特征之间的距离，来保持语义一致性。", "conclusion": "通过在TinyImageNet和14个其他数据集上进行广泛的实验，研究证明CAW在强大攻击如AutoAttack下相比其他最近的方法如PMG-AFT和TGA-ZSR表现更优，并且能够以较低的内存使用获得更好的确切性和鲁棒性。"}
{"llm_update_time": "20251006", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.02994", "html_url": "https://arxiv.org/abs/2510.02994", "title": "迈向可扩展且一致的3D编辑", "title_en": "Towards Scalable and Consistent 3D Editing", "authors": "Ruihao Xia,Yang Tang,Pan Zhou", "background": "3D编辑是局部修改3D资产的几何形状或外观的任务，在沉浸式内容创建、数字娱乐和AR/VR领域有着广泛的应用；与2D编辑相比，它因需要交叉视图一致性、结构保真度和精细控制而更具挑战性。现有的方法通常是缓慢的，容易产生几何失真，或者依赖于难以准确和手动制作的3D蒙版，这样做可能会出错且不实际。论文介绍了一种通过增强图像到3D生成的双引导注意和时间自适应门控，构建了3DEditFormer，这是一种3D结构保留条件transformer，不需要辅助3D蒙版，实现了精细和一致的编辑。", "innovation": "1. 提出了3DEditVerse，这是一个包含116,309对高质量训练数据和1,500对精心策划的测试数据的3D编辑基准数据集，通过互补的姿势驱动几何编辑和基于基础模型的外观编辑流程构建，确保了编辑的局部性、多视图一致性和语义对齐。2. 3DEditFormer，一种3D结构保留条件transformer，通过增强图像到3D生成的双引导注意和时间自适应门控，实现了从可编辑区域与保留结构中解耦，不依赖辅助3D蒙版即可实现精确和一致的编辑。", "conclusion": "通过数据和模型的双重推进，论文提出的方法3DEditFormer和3DEditVerse显著优于现有的基准模型，在定量和定性方面均表现出优异性能，为实际和可扩展的3D编辑奠定了新的标准。"}
{"llm_update_time": "20251006", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.03066", "html_url": "https://arxiv.org/abs/2510.03066", "title": "InsideOut: 一种基于EfficientNetV2-S的深度学习框架，用于稳健的多类面部情感识别", "title_en": "InsideOut: An EfficientNetV2-S Based Deep Learning Framework for Robust Multi-Class Facial Emotion Recognition", "authors": "Ahsan Farabi,Israt Khandaker,Ibrahim Khalil Shanto,Md Abdul Ahad Minhaz,Tanisha Zaman", "background": "面部情感识别（FER）是情感计算的关键任务，可应用于人机交互、电子学习、医疗保健和安全系统。尽管深度学习有所进步，但由于遮挡、光照和姿态变异、类内细微差异以及数据集不平衡导致小众情感难以识别，FER仍然具有挑战性。", "innovation": "Introduce InsideOut，一种基于EfficientNetV2-S的FER框架，结合了迁移学习、强数据增强和不平衡优化。该方法标准化FER2013图像，应用分层划分和增强，并使用加权损失完善轻量级分类头，以解决分布偏斜问题。创新之处在于证明了高效架构与定制化的不平衡处理相结合，可以提供实用、透明且可再现的FER解决方案。", "conclusion": "InsideOut在FER2013数据集上实现了62.8%的准确率和0.590的宏平均F1值，显示出与传统的CNN基线相比具有竞争力的结果。"}
{"llm_update_time": "20251006", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.02912", "html_url": "https://arxiv.org/abs/2510.02912", "title": "不要只追求数字化的高亮视觉 token：反思 MLLMs 中的整体视觉语境保留", "title_en": "Don't Just Chase \"Highlighted Tokens\" in MLLMs: Revisiting Visual Holistic Context Retention", "authors": "Xin Zou,Di Lu,Yizhou Wang,Yibo Yan,Yuanhuiyi Lyu,Xu Zheng,Linfeng Zhang,Xuming Hu", "background": "尽管多模态大型语言模型（MLLMs）具有强大的能力，但由于依赖大量的视觉标记，它们面临着显著的计算开销。最近的研究探索了标记剪枝来缓解这一问题，这些方法通常使用文本-视觉交叉注意或[\texttt{CLS}]注意来评估和丢弃冗余的视觉标记。然而，这些以注意为主的修剪方法存在一个关键的局限性，即它们倾向于保留语义相似的标记，这在高修剪比例下会导致显著的性能下降。", "innovation": "本文提出了一种简单有效并且即插即用的视觉标记剪枝框架——{HoloV}，不同于先前以注意为主的方案，{HoloV} 从整体视角重新思考标记保留策略。通过在不同空间剪辑中适配性地分配修剪预算，{HoloV} 确保保留的标记能够捕捉全局视觉语境而不是孤立的显著特征。这种策略最小化了表示崩溃，并在剧烈修剪下保持了任务相关的信息。实验结果表明，与现有最佳方法相比，{HoloV} 在各种任务、MLLM 架构和修剪比例下均实现了更优的性能。", "conclusion": "实验结果显示，我们的 {HoloV} 在各种任务、MLLM 架构和修剪比例下均实现了优于现有最佳方法的性能。例如，使用 {HoloV} 的 LLaVA1.5 在修剪 88.9% 的视觉标记之后，仍能保持 95.8% 的原始性能，实现了更优的效率-准确度权衡。"}
{"llm_update_time": "20251006", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.03012", "html_url": "https://arxiv.org/abs/2510.03012", "title": "PocketSR: 臧于手机口袋中的超分辨率专家", "title_en": "PocketSR: The Super-Resolution Expert in Your Pocket Mobiles", "authors": "Haoze Sun,Linfeng Jiang,Fan Li,Renjing Pei,Zhixin Wang,Yong Guo,Jiaqi Xu,Haoyu Chen,Jin Han,Fenglong Song,Yujiu Yang,Wenbo Li", "background": "现实世界中的图像超分辨率（Real-world image super-resolution, RealSR）旨在提高野外图像的视觉质量，例如手机拍摄的照片。尽管现有的利用大型生成模型的方法在效果上表现出色，但其高计算成本和延迟使得它们不适合边缘部署。", "innovation": "本文引入了PocketSR，这是一个轻量级的一站式模型，能够在保持高质量的同时将生成模型能力带入RealSR。通过设计LiteED，一种高效替代SD中计算密集型VAE的轻量级模块，将参数减少了97.5%，同时保持高质量的编码和解码。此外，提出了一种在线退火剪枝方法，逐步将生成先验从重模块转移到轻量级模块，确保有效的知识传递并进一步优化效率。为了解决剪枝过程中的先验知识损失，引入了多层特征蒸馏损失。", "conclusion": "PocketSR模型大小为146M参数，处理4K图像仅需0.8秒，与之前的方法相比实现了显著的速度提升。令人惊讶的是，它在性能上与最新的单一步骤和多步骤RealSR模型相媲美，使其成为边缘设备应用的理想解决方案。"}
{"llm_update_time": "20251006", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.03104", "html_url": "https://arxiv.org/abs/2510.03104", "title": "几何与视觉的结合：重访精炼场中的预训练语义", "title_en": "Geometry Meets Vision: Revisiting Pretrained Semantics in Distilled Fields", "authors": "Zhiting Mei,Ola Shorinwa,Anirudha Majumdar", "background": "语义精炼在辐射场中取得了重大进展，特别是在基于大型视觉模型预训练语义的机器人操作和导航方面。虽然视觉仅特征（如DINO和CLIP）在高斯散点图和神经辐射场中表现出色，但几何接地对精炼场中语义特征的影响仍是一个开放问题。视觉和几何特征在空间任务如姿态估计中看起来很有潜力。", "innovation": "提出了一种名为SPINE的新框架，用于在没有初始猜测的情况下反转辐射场，包括粗略反转使用精练语义和基于光度学优化的精细反转。此外，研究发现几何接地的语义特征细化结构细节，但对于语义对象定位没有显著影响，且几何接地有助于更高精度的辐射场反转。然而，姿态估计精度随着几何接地特征的增加而降低。", "conclusion": "视觉特征相比几何接地特征提供了更广泛下游任务的灵活性，尽管几何接地包含更多的几何细节。研究强调了未来研究有效几何接地策略的必要性，以增强预训练语义特征的多功能性和性能。"}
{"llm_update_time": "20251006", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.02922", "html_url": "https://arxiv.org/abs/2510.02922", "title": "大规模视觉语言模型在颈动脉风险分层中的多模态基准测试、微调和临床洞察", "title_en": "Multimodal Carotid Risk Stratification with Large Vision-Language Models: Benchmarking, Fine-Tuning, and Clinical Insights", "authors": "Daphne Tsolissou,Theofanis Ganitidis,Konstantinos Mitsis,Stergios CHristodoulidis,Maria Vakalopoulou,Konstantina Nikita", "background": "可靠地评估颈动脉粥样硬化疾病的风险仍然是医学上的一个重大挑战，因为它需要整合多方面的临床和影像信息，并且这些信息需要对临床医生是透明且可解释的。这项研究旨在通过将超声成像（USI）与结构化的临床、人口统计学、实验室和蛋白质生物标志数据相结合，探讨最新和最先进的大规模视觉语言模型（LVLMs）在多模态颈动脉斑块评估中的潜力。", "innovation": "提出了一个通过面试式的提问流程模拟现实诊断场景的框架，并比较了一系列开源的大规模视觉语言模型，包括通用型和医疗调优的模型。零样本实验表明，尽管这些模型非常强大，但并不是所有的模型都能准确识别影像模态和解剖结构，而在准确的风险分类上表现较差。为了解决这一限制，LLaVa-NeXT-Vicuna模型使用低秩适应（LoRA）技术适应超声领域，从而在中风风险分级方面取得了显著改进。通过将多模态文本形式的表格数据进行整合，进一步提高了特异性和平衡准确度，与之前在相同数据集上训练的卷积神经网络（CNN）基准模型相比，表现出竞争力。", "conclusion": "我们的研究结果突显了大规模视觉语言模型在基于超声的心血管风险预测中的潜力与限制，强调了多模态整合、模型校准与领域适应对于临床转化的重要性。"}
{"llm_update_time": "20251006", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.02970", "html_url": "https://arxiv.org/abs/2510.02970", "title": "Flip Distribution Alignment VAE for Multi-Phase MRI Synthesis", "title_en": "Flip Distribution Alignment VAE for Multi-Phase MRI Synthesis", "authors": "Xiaoyan Kui,Qianmu Xiao,Qqinsong Li,Zexin Ji,JIelin Zhang,Beiji Zou", "background": "多期对比增强（CE）MRI的合成需要区分共享和独立特征。现有的方法使用低参数效率的深度自动编码生成器，并缺乏可解释的训练策略。", "innovation": "提出了一种称为‘Flip Distribution Alignment Variational Autoencoder (FDA-VAE)’的轻量级特征解耦VAE模型，用于多期CE MRI合成。该方法通过将输入和目标图像编码为关于标准正态分布对称的两个潜在分布，有效地区分了共享和独立特征。Y形双方向训练策略进一步增强了特征分离的可解释性。", "conclusion": "实验结果显示，与基于深度自动编码器的端到端合成方法相比，FDA-VAE显著减少了模型参数和推理时间，同时提高了合成质量。源代码公开可用。"}
{"llm_update_time": "20251006", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.03049", "html_url": "https://arxiv.org/abs/2510.03049", "title": "多事件视频生成中事件何时何地切换？", "title_en": "When and Where do Events Switch in Multi-Event Video Generation?", "authors": "Ruotong Liao,Guowen Huang,Qing Cheng,Thomas Seidl,Daniel Cremers,Volker Tresp", "background": "T2V生成在面对生成长视频时，尤其是在需要描绘多个具有时间连贯性和可控内容的连续事件时，面临着挑战。现有方法在扩展到多事件生成时，忽略了事件转换内在因素的检查。该研究旨在探讨多事件提示在T2V生成过程中控制事件过渡的时间和地点。", "innovation": "该论文引入了MEve，一种自编目的提示套件，用于评估多事件T2V生成，并对两种代表性模型系列（OpenSora和CogVideoX）进行了系统性研究。实验结果强调了在去噪步骤和块级模型层早期干预的重要性，揭示了多事件视频生成的关键因素，并指出了未来模型中多事件调节的可能性。", "conclusion": "研究结果表明，早期干预对于多事件视频生成的成功至关重要，揭示了事件转换的基本因素，并为未来模型中的多事件调节提供了新的构想。"}
{"llm_update_time": "20251006", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.03110", "html_url": "https://arxiv.org/abs/2510.03110", "title": "GeoComplete: Geometry-Aware Diffusion for Reference-Driven Image Completion", "title_en": "GeoComplete: Geometry-Aware Diffusion for Reference-Driven Image Completion", "authors": "Beibei Lin,Tingting Chen,Robby T. Tan", "background": "参考驱动的图像完成方法旨在利用附加图像修复目标视图中的缺失区域，但在目标视图与参考视图差异显著时特别具有挑战性。现有生成方法依赖扩散先验，但缺乏几何提示（例如相机姿态或深度），从而常常产生对齐不当或不合理的内容。", "innovation": "我们提出了GeoComplete，一种新颖的框架，通过引入明确的3D结构指导来强制在完成区域中保持几何一致性，从而区别于仅依赖图像的传统方法。GeoComplete引入了两个关键想法：将扩散过程条件化于投影点云以植入几何信息，并使用目标感知遮罩来指导模型遵循相关参考线索。该框架的特点是双分支扩散架构。一个分支从已遮罩的目标中合成缺失区域，而另一个分支从投影点云中提取几何特征。跨分支的联合自注意力确保了完成的一致性和准确性。为了处理参考中可见但目标中不存在的区域，我们将目标视图投影到每个参考中以检测被遮挡区域，然后在训练过程中进行遮罩。这种目标感知遮罩使模型能够专注于有用线索，从而在困难场景中提高性能。", "conclusion": "通过结合几何意识的双分支扩散架构与目标感知遮罩策略，GeoComplete为几何条件下的图像完成提供了一个集成且稳健的解决方案。实验结果表明，与现有最先进的方法相比，GeoComplete在峰值信噪比（PSNR）上提高了17.1%，显著提升了几何精度，同时保持了高质量视觉效果。"}
{"llm_update_time": "20251006", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.02987", "html_url": "https://arxiv.org/abs/2510.02987", "title": "TIT-Score：通过文本到图像到文本一致性评估基于长提示的文本到图像对齐", "title_en": "TIT-Score: Evaluating Long-Prompt Based Text-to-Image Alignment via Text-to-Image-to-Text Consistency", "authors": "Juntong Wang,Huiyu Duan,Jiarui Wang,Ziheng Jia,Guangtao Zhai,Xiongkuo Min", "background": "随着大型多模态模型（LMMs）的快速进步，近期的文本到图像（T2I）模型能够生成高质量的图像并且能够很好地与简短的提示保持一致。然而，它们在理解和遵循长而详细的提示方面效果不理想，生成的结果会出现不一致。为解决这一挑战，本文引入了LPG-Bench，这是一个全面的基准测试，专门评估基于长提示的文本到图像生成。LPG-Bench 包含了200个精心设计的提示，平均长度超过250个单词，接近一些领先商业模型的输入容量。通过使用这些提示，生成了来自13个最新T2I模型的2600张图像，并进行了全面的人类排名注释。研究表明，最先进的T2I对齐评估指标在长提示图像生成中与人类偏好的一致性表现较差。为解决这一差距，本文引入了一种新的零样本指标TIT，基于文本到图像到文本一致性进行评估。该核心概念是通过直接比较原始提示和生成图像上的LMM生成描述的一致性来量化T2I对齐，包括高效的评分实例TIT-Score和基于大语言模型（LLM）的评分实例TIT-Score-LLM。广泛的实验表明，我们的框架在评估长提示生成图像与人工判断的一致性方面优于CLIP-score，LMM-score等，其中TIT-Score-LLM获得了最强基线7.31%的绝对改进。通过提供LPG-Bench和TIT方法，我们可以更深入地评估推断和促进T2I模型的发展，所有的资源将公开提供", "innovation": "本文创新性地提出了LPG-Bench，这是一个专门用于评估基于长提示的文本到图像生成的全面基准测试。基准测试包含200个平均长度超过250个单词的精心设计提示，并且提出了一种基于文本到图像到文本一致性（TIT）的新的零样本评估方法。该方法通过比较原始提示和生成图像上的LMM生成描述的一致性来量化T2I对齐，展示了在长提示生成图像评估中比现有的评估指标具有更好的一致性。（包括高效的评分实例TIT-Score和基于大语言模型（LLM）的评分实例TIT-Score-LLM）", "conclusion": "基于LPG-Bench和TIT，我们能够更深入地评估并促进T2I模型的发展。所有的资源将被公开提供，以供进一步研究使用。整体而言，TIT-Score在评估长提示生成图像的一致性方面展现出显著的优势，是改进此类模型对齐评价的一项有力工具。"}
{"llm_update_time": "20251006", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.03006", "html_url": "https://arxiv.org/abs/2510.03006", "title": "每一天并非都是晴天：来自不同数据源的深度土地覆盖分割鲁棒性评估的合成云注射", "title_en": "Not every day is a sunny day: Synthetic cloud injection for deep land cover segmentation robustness evaluation across data sources", "authors": "Sara Mobsite,Renaud Hostache,Laure Berti Equille,Emmanuel Roux,Joris Guerin", "background": "目前的土地覆盖语义分割（LCS）依赖于带有标签的卫星数据，但大多数现有的Sentinel-2数据集都是无云的，这限制了它们在热带地区等经常出现云层覆盖的地区的应用。为了评估这个问题的程度，本研究开发了一种云注射算法，模拟真实的云覆盖，测试Sentinel-1雷达数据在被云遮挡的光学图像导致缺失时如何填补漏洞。此外，还探讨了在深度网络中出现编码器下采样过程中空间和/或光谱细节丢失的问题，并提出了一种轻量级方法，在解码器最终层注入归一化差值索引（NDI），使得模型在几乎不增加额外计算的情况下保留关键的空间特征，从而提高土地覆盖分割的性能，在无云条件下该方法分别提升了U-Net和DeepLabV3的性能1.99%和2.78%。在有云覆盖的情况下，加入Sentinel-1数据相比仅使用光学数据显著提高了所有模型的性能，表明在恶劣气象条件下雷达-光学融合的有效性。", "innovation": "本研究的创新点在于开发了一种云注射算法来模拟现实世界的云覆盖情景，测试了雷达数据在填补光学图像被云遮挡时的空缺能力。此外，提出了一种注入NDI的轻量级方法，使模型在解码阶段能够保留重要的空间细节，从而提升了土地覆盖分割的性能。它证明了在云覆盖等恶劣条件下，雷达-光学数据融合的有效性。", "conclusion": "研究表明，在数据源多样化的背景下，云注射算法有助于评估各类土地覆盖分割模型在云遮挡条件下的性能，而注入NDI的方法使得模型在保持低计算量的同时，仍能有效保留关键的空间特征，提升模型在有云覆盖条件下的性能，特别是在使用Sentinel-1雷达数据与传统的光学数据结合时表现出色。"}
{"llm_update_time": "20251006", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.03075", "html_url": "https://arxiv.org/abs/2510.03075", "title": "视觉生成模型中综合性泛化的驱动因素", "title_en": "What Drives Compositional Generalization in Visual Generative Models?", "authors": "Karim Farid,Rajat Sahay,Yumna Ali Alnaggar,Simon Schrodi,Volker Fischer,Cordelia Schmid,Thomas Brox", "background": "合成泛化是指能够生成已知概念的新颖组合的能力，这是视觉生成模型的关键组成部分。然而，当前机制中能够促进或抑制这种能力的要素尚未完全理解。", "innovation": "本文通过系统研究不同设计选择如何以正负面方式影响图像和视频生成中的合成泛化。通过受控实验，发现两个关键因素：（i）训练目标是否作用于离散或连续分布；（ii）训练期间条件信息提供了构成概念的多大程度信息。此外，通过使用基于JEPA的辅助连续目标来放松MaskGIT离散损失，展示了提高离散模型MaskGIT的合成表现的方法。", "conclusion": "通过对不同的设计选择对离散与连续分布以及条件信息作用的受控实验结果，本文揭示了两种关键因素对模型合成泛化的驱动作用，提出了一种通过放松MaskGIT的离散损失的方法以改善其合成表现。"}
{"llm_update_time": "20251006", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.03122", "html_url": "https://arxiv.org/abs/2510.03122", "title": "HAVIR：使用CLIP引导的通用扩散模型的层次视觉到图像重建", "title_en": "HAVIR: HierArchical Vision to Image Reconstruction using CLIP-Guided Versatile Diffusion", "authors": "Shiyi Zhang,Dong Liang,Hairong Zheng,Yihang Zhou", "background": "从脑活动重建视觉信息促进了神经科学与计算机视觉的跨学科整合，但现有方法在准确恢复复杂视觉刺激方面仍面临挑战。这些挑战源于自然场景特征的异质性和高层特征由于上下文重叠导致的语义纠缠。", "innovation": "提出了一种新颖的HAVIR模型，将视觉皮层分为两个层次区域，并从每个区域提取不同的特征。结构生成器从空间处理体素中提取结构信息并转换为潜在扩散先验，语义提取器将语义处理体素转换为CLIP嵌入。这些组件通过通用扩散模型整合，以合成最终图像。实验证明，HAVIR在复杂场景中提高了解析结构和语义质量，并超越了现有模型。", "conclusion": "HAVIR模型在复杂场景下提升了重建图像的结构和语义质量，并且性能优于现有模型。"}
{"llm_update_time": "20251006", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.03161", "html_url": "https://arxiv.org/abs/2510.03161", "title": "UniShield: 一种统一的防伪造图像检测与定位的自适应多智能体框架", "title_en": "UniShield: An Adaptive Multi-Agent Framework for Unified Forgery Image Detection and Localization", "authors": "Qing Huang,Zhipei Xu,Xuanyu Zhang,Jian Zhang", "background": "随着图像生成技术的迅速发展，合成图像越来越逼真，这带来了重大的社会风险，如虚假信息和欺诈。因此，伪造图像检测与定位（FIDL）变得至关重要，以维护信息安全和公共安全。尽管现有的领域特定检测方法表现出色，但在实际应用中的实用性仍受到限制，主要原因是它们的专业性狭窄、跨域泛化能力差以及缺乏集成的自适应框架。", "innovation": "我们提出了UniShield，这是一种新颖的多智能体统一系统，能够在不同领域（包括图像篡改、文档篡改、DeepFake和AI生成图像）中检测和定位图像伪造。UniShield创新性地将感知代理与检测代理集成在一起。感知代理能够智能分析图像特征，动态选择合适的检测模型，而检测代理则将各种专家检测器统一到一个框架中，并生成可解释的报告。广泛的实验表明，UniShield实现了最先进的结果，超过了现有的统一方法和领域特定的检测器，突显了它的实用性强、自适应性和可扩展性。", "conclusion": "UniShield通过实现统一的、多代理的、自适应的伪造图像检测和定位框架，解决了现有方法的局限性，提供了一种适用于不同图像伪造领域的高效解决方案。"}
{"llm_update_time": "20251006", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.03089", "html_url": "https://arxiv.org/abs/2510.03089", "title": "Latent Diffusion Unlearning: 通过轨迹偏移扰动防止未经授权的人像个性化", "title_en": "Latent Diffusion Unlearning: Protecting Against Unauthorized Personalization Through Trajectory Shifted Perturbations", "authors": "Naresh Kumar Devulapally,Shruti Agarwal,Tejas Gokhale,Vishnu Suresh Lokhande", "background": "文本到图像的扩散模型在只提供少量用户图像的情况下也能实现快速和高保真的人像个性化，但个性化技术的有效性引发了一些关于数据隐私、知识产权保护和未经授权使用的问题。为了解决这些问题，提出了图像污染技术生成“不可学习”的训练样本的方法。然而，现有方法在像素空间中操作，导致生成的图像具有噪音和伪影。", "innovation": "本文提出了一种新颖的基于模型的扰动策略，该策略在扩散模型的潜在空间中操作。该方法交替进行去噪和反向操作，同时改变扩散模型去噪轨迹的起始点。这种轨迹偏移采样确保扰动图像保持高视觉保真度，同时抵抗下游生成模型的去个性化。该方法将不可学习性整合到扩散模型（LDMs）框架中，提供了防止未经授权模型适应的实用且不可感知的防御。", "conclusion": "我们通过四个基准数据集验证了该方法的鲁棒性，结果显示该方法在不可感知性（包括PSNR、SSIM和FID等感知指标，提高了约8%-10%）和鲁棒性（五种对抗设置中平均提高了约10%）方面表现出显著改善，证明了其在保护敏感数据方面的有效性。"}
{"llm_update_time": "20251006", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.03189", "html_url": "https://arxiv.org/abs/2510.03189", "title": "动态提示生成用于交互式3D医疗图像分割训练", "title_en": "Dynamic Prompt Generation for Interactive 3D Medical Image Segmentation Training", "authors": "Tidiane Camaret Ndir,Alexander Pfefferle,Robin Tibor Schirrmeister", "background": "交互式3D医用图像分割需要高效模型，能够基于用户提示进行迭代预测精炼。现有基础模型要么缺乏体积意识，要么在交互能力上存在限制。", "innovation": "提出了一种结合动态体素提示生成和内容感知自适应裁剪的训练策略，优化图像编码器的使用。该方法在训练期间模拟了真实的用户交互模式，解决了从单一GPU上的序列精炼反馈中进行学习的计算挑战。", "conclusion": "在Foundation Models for Interactive 3D Biomedical Image Segmentation竞赛中的评估表明，该方法取得了很强的性能，平均最终Dice得分为0.6385，正常表面距离得分为0.6614，AUC指标分别达到2.4799（Dice）和2.5671（NSD）。"}
{"llm_update_time": "20251006", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.03135", "html_url": "https://arxiv.org/abs/2510.03135", "title": "Mask2IV：通过掩码轨迹的交互中心视频生成", "title_en": "Mask2IV: Interaction-Centric Video Generation via Mask Trajectories", "authors": "Gen Li,Bo Zhao,Jianfei Yang,Laura Sevilla-Lara", "background": "生成以交互为中心的视频，例如人类或机器人与物体互动的视频，对赋予机器人智能至关重要。这些视频为机器人学习、操作政策训练和预期用途推理提供了丰富多样的视觉先验。然而，现有方法在建模复杂且动态的交互方面时常面临困难。虽然近期研究显示，掩码可以作为有效的控制信号以提升生成质量，但在现实应用中，获取密集且精确的掩码注释仍是主要挑战。", "innovation": "Mask2IV 提出了一种新的框架，特别适用于交互中心的视频生成。该框架采用分阶段的解耦管道，首先预测演员和物体可能的运动轨迹，然后根据这些轨迹生成视频。这种设计消除了用户需要提供密集掩码输入的需要，同时保留了控制交互过程的灵活性。此外，Mask2IV 支持灵活且直观的控制，允许用户指定交互目标对象并通过对动作描述或空间位置提示来引导运动轨迹。", "conclusion": "为了支持系统训练和评估，该研究创建了涵盖广泛动作和物体类别的两个基准数据集，覆盖人类物体交互和机器人操作场景。大量实验表明，与现有基线相比，该方法在视觉真实性和可控性方面取得了显著优势。"}
{"llm_update_time": "20251006", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.03200", "html_url": "https://arxiv.org/abs/2510.03200", "title": "MonSTeR: a Unified Model for Motion, Scene, Text Retrieval", "title_en": "MonSTeR: a Unified Model for Motion, Scene, Text Retrieval", "authors": "Luca Collorone,Matteo Gioia,Massimiliano Pappa,Paolo Leoni,Giovanni Ficarra,Or Litany,Indro Spinelli,Fabio Galasso", "background": "智能体在复杂环境中进行动作的能力受到周围环境支持的影响。现有研究尚未提供评估骨骼动作（运动）、意图（文本）和周围环境（场景）之间对齐程度的工具。", "innovation": "引入了MonSTeR，这是一种第一个用于运动-场景-文本检索的模型。通过利用单模态和跨模态表示来构建统一的潜在空间，MonSTeR能够捕捉不同模态之间的复杂依赖关系，实现灵活但健壮的任务检索。", "conclusion": "实验结果表明，MonSTeR在多项任务中优于仅依赖单模态表示的三模态模型。并通过专门的研究进一步验证了检索得分与人类偏好的一致性。此外，MonSTeR的潜在空间在零样本场景对象放置和动作字幕生成中展示出多功能性。"}
{"llm_update_time": "20251006", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.03152", "html_url": "https://arxiv.org/abs/2510.03152", "title": "ReeMark：用于时空轨迹中生活模式模拟的Reeb图", "title_en": "ReeMark: Reeb Graphs for Simulating Patterns of Life in Spatiotemporal Trajectories", "authors": "Anantajit Subrahmanya,Chandrakanth Gudavalli,Connor Levenson,Umang Garg,B.S. Manjunath", "background": "准确建模人类移动对于城市规划、流行病学和交通管理至关重要。现有的模型通常难以同时保留个体和群体的移动模式，尤其是在保证数据和计算效率的前提下，生成真实且具有生活一致性和多样性的未来轨迹具有挑战性。这篇文章提出了Markovian Reeb Graphs，一个用于模拟时空轨迹的新框架，可以在保留基础数据中学习到的生活模式（Patterns of Life, PoLs）的同时，生成现实且具有生活一致性和多样性的未来轨迹。", "innovation": "Markovian Reeb Graphs通过结合个体和群体级别的移动结构，提供一个概率拓扑模型，从而生成更真实且可预测的未来轨迹，同时也保持了数据和计算的高效性。该方法使用Urban Anomalies数据集（亚特兰大和柏林的子集）和Jensen-Shannon散度（JSD）从个体和群体层级的指标评估，证明了其强大的拟合能力，使其成为一个可扩展的轨迹模拟框架，具有跨多样的城市环境的广泛应用前景。", "conclusion": "Markovian Reeb Graphs作为轨迹模拟的一种可扩展框架，展示了在不同城市环境中模拟时空轨迹中生活模式的强大性能，开启了在复杂动态城市环境中探索、管理和优化的一扇窗口。"}
{"llm_update_time": "20251006", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.03198", "html_url": "https://arxiv.org/abs/2510.03198", "title": "Memory Forcing：Minecraft环境中一致场景生成的空间-时间记忆", "title_en": "Memory Forcing: Spatio-Temporal Memory for Consistent Scene Generation on Minecraft", "authors": "Junchao Huang,Xinting Hu,Boyao Han,Shaoshuai Shi,Zhuotao Tian,Tianyu He,Li Jiang", "background": "自回归视频扩散模型已被证明在世界建模和交互式场景生成方面有效，以Minecraft游戏为例。为了准确模拟游戏，模型必须生成自然内容并探索新场景，还要在重新访问已探索区域时保持空间一致性。在计算资源受限的情况下，模型需要在有限的上下文窗口内压缩和利用历史线索，这暴露出的一个权衡是：仅时间记忆缺乏长期空间一致性，而增加空间记忆虽然加强了一致性，但在模型过度依赖不足的空间上下文时可能会降低新场景生成的质量。", "innovation": "我们提出了Memory Forcing，一种结合了训练策略和基于几何索引的空间记忆的学习框架。Hybrid Training通过引导模型在探索时依赖时间记忆，在重新访问时结合空间记忆来区分不同的游戏模式。Chained Forward Training通过扩展自回归训练和模型滚动预测，增加了姿态变化，鼓励模型依赖空间记忆来保持一致性。Point-to-Frame Retrieval通过将当前可见点映射到其源帧来高效检索历史信息，而Incremental 3D Reconstruction则保持和更新3D缓存。整个实验充分证明Memory Forcing在多种环境中可以实现更优的长期空间一致性和生成质量，同时保持对未来演示计算效率的高效性", "conclusion": "Memory Forcing在不牺牲计算效率的前提下，能够实现更优秀的长期空间一致性和生成质量，适用于Minecraft等多样化的环境场景生成。"}
{"llm_update_time": "20251006", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.03160", "html_url": "https://arxiv.org/abs/2510.03160", "title": "SpineBench：基于SpineMed-450k语料库的临床相关、层次意识基准", "title_en": "SpineBench: A Clinically Salient, Level-Aware Benchmark Powered by the SpineMed-450k Corpus", "authors": "Ming Zhao,Wenhui Dong,Yang Zhang,Xiang Zheng,Zhonghao Zhang,Zian Zhou,Yunzhi Guan,Liukun Xu,Wei Peng,Zhaoyang Gong,Zhicheng Zhang,Dachuan Li,Xiaosheng Ma,Yuli Ma,Jianing Ni,Changjiang Jiang,Lixia Tian,Qixin Chen,Kaishun Xia,Pingping Liu,Tongshun Zhang,Zhiqiang Liu,Zhongan Bi,Chenyang Si,Tiansheng Sun,Caifeng Shan", "background": "脊柱疾病影响全球6.19亿人，是导致残疾的重要原因，但AI辅助诊断受限于缺乏层次意识的多模态数据集。脊柱疾病的临床决策需要在X射线、CT和MRI等成像模态的具体椎骨水平上进行复杂的推理，但这一进展受到缺乏可追溯、临床依据指令数据和标准化脊柱专用基准的限制。", "innovation": "引入了SpineMed生态系统，包括SpineMed-450k，这是首款专门设计用于多模态成像数据中特定椎骨水平推理的大型数据集，以及SpineBench，一个基于临床依据的评估框架。SpineMed-450k数据集从多种来源收集，包括教科书、指南、公开数据集以及匿名的1,000多个医院病例，使用包含两阶段的LLM生成方法（草案和修订）构建，以确保高质量、可追溯的数据，用于问题解答、多轮咨询和报告生成。SpineBench从临床相关角度评估模型，包括椎骨识别、病理评估和手术规划。我们的研究发现，SpineMed-450k数据集的微调模型在所有任务上都表现出一致和显著的改进，而以前的大型视觉语言模型在这方面的表现系统性较差。临床评估证实了我们模型输出的诊断清晰度和实用性。", "conclusion": "我们的研究揭示了SpineBench和SpineMed-450k数据集在脊柱疾病领域的重要性，并展示了基于这些数据集训练的模型在临床相关任务上的优越性能。"}
{"llm_update_time": "20251006", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.03224", "html_url": "https://arxiv.org/abs/2510.03224", "title": "通过潜在集合的随机共振对抗攻击的测试时防御", "title_en": "Test-Time Defense Against Adversarial Attacks via Stochastic Resonance of Latent Ensembles", "authors": "Dong Lao,Yuxiang Zhang,Haniyeh Ehsani Oskouie,Yangchao Wu,Alex Wong,Stefano Soatto", "background": "该研究背景源于对抗攻击对模型预测的影响，传统方法如特征筛选或平滑可能会导致信息丢失。该论文旨在提出一种新的测试时防御机制，通过引入不可感知的图像扰动，显著改变模型的预测，以增强模型的鲁棒性同时最大限度地减少信息损失。", "innovation": "该研究创新地提出了“以噪制噪”的方法，通过利用随机共振技术，引入小的平移扰动到输入图像中，对齐变换后的特征嵌入并进行聚合，最后映射回原始参考图像。该方法无需额外的网络模块或特定攻击类型微调，且完全不需要训练，适用于多种网络架构和攻击，特别适用于密集预测任务如立体匹配和光学流，实现了最先进的鲁棒性表现。", "conclusion": "实验结果表明，该方法在图像分类上达到了最先进的鲁棒性水平，并首次为密集预测任务建立了一种通用的测试时防御方法，对于各种类型的对抗攻击，该方法恢复了高达68.1%的准确率损失，在立体匹配中为71.9%，在光学流中为29.2%。"}
{"llm_update_time": "20251006", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.03228", "html_url": "https://arxiv.org/abs/2510.03228", "title": "MIXER: 混合超球体随机嵌入神经网络在纹理识别中的应用", "title_en": "MIXER: Mixed Hyperspherical Random Embedding Neural Network for Texture Recognition", "authors": "Ricardo T. Fares,Lucas C. Ribas", "background": "随机神经网络在纹理识别任务中表现出了显著的优势，能够有效地结合传统技术和基于学习的方法。现有的方法主要集中在改善跨信息预测，但并未对随机网络的整体架构做出显著改进。现有工作大多集中在提高跨信息预测方面，而忽视了对网络整体架构的重大改进。本研究旨在通过引入一种新的方法，在纹理表示学习中实现这一目标。", "innovation": "提出了一种名为Mixer的新型随机神经网络，核心在于结合超球体随机嵌入和双重分支学习模块来捕捉通道内的和通道间的关联，并通过一个新的优化问题构建丰富的纹理表示。这种新方法能够在多个具有独特特征和挑战的纯纹理基准测试中取得有趣的实验结果，展示了其在纹理识别方面的潜力和优势。", "conclusion": "实验结果表明，该方法在多种纯纹理基准测试中表现出了显著的效果，验证了其在纹理识别中的有效性。在未来的工作中，团队将把公开源代码，进一步推动该领域的研究和发展。"}
{"llm_update_time": "20251006", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.03163", "html_url": "https://arxiv.org/abs/2510.03163", "title": "ROGR: 使用生成光照的可重新光照3D物体", "title_en": "ROGR: Relightable 3D Objects using Generative Relighting", "authors": "Jiapeng Tang,Matthew Lavine,Dor Verbin,Stephan J. Garbin,Matthias Nießner,Ricardo Martin Brualla,Pratul P. Srinivasan,Philipp Henzler", "background": "本文介绍了一种名为ROGR的新颖方法，该方法从多视角捕捉的物体中重建可重新光照的3D模型，通过生成重新光照模型来模拟物体在新环境照明下的效果。这种方法能够捕捉在多种光照环境下物体的外观，并训练出一个受光源条件调控的神经辐射场（NeRF），使其能够输出任意输入环境照明条件下的物体外观。这种方法使用了一种新颖的两分支架构来分别编码一般的照明效果和高光部分。与传统的重新光照方法相比，优化后的基于光源条件的NeRF可以在任意环境贴图下实现高效的前向重新光照，而无需进行每种照明条件的优化或光线传输模拟。该方法在TensoIR和Stanford-ORB数据集上进行了评估，并在大多数指标上超过了现有的最先进的方法，同时展示了在真实世界物体捕获上的应用效果。", "innovation": "ROGR方法通过生成重新光照模型来模拟物体在新环境照明下的效果，能够捕捉在多种光照环境下物体的外观。使用了新颖的两分支架构，分别编码照明效果和高光部分。优化后的基于光源条件的NeRF可以在任意环境贴图下实现高效的前向重新光照，而无需进行每种照明条件的优化或光线传输模拟。", "conclusion": "该方法在TensoIR和Stanford-ORB数据集上进行了评估，并在大多数指标上超过了现有的最先进的方法，同时展示了在真实世界物体捕获上的应用效果。"}
{"llm_update_time": "20251006", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.03191", "html_url": "https://arxiv.org/abs/2510.03191", "title": "Product-Quantised Image Representation for High-Quality Image Synthesis", "title_en": "Product-Quantised Image Representation for High-Quality Image Synthesis", "authors": "Denis Zavadski,Nikita Philip Tatsch,Carsten Rother", "background": "产品量化（PQ）是一种经典的向量编码方法，虽然它在大规模应用中有其局限性，但对于高保真图像生成中的潜在表示却很少被采用。以往的研究如VQGAN等实现了卓越的图像生成性能，但尚未将PQ整合进来。", "innovation": "本文提出了PQGAN，这是一种将PQ整合到VQGAN中的量化图像自编码器。PQGAN在重构性能上超过了最先进的方法，尤其是在图像生成的PSNR上提升了10dB；同时FID、LPIPS和CMMD得分分别降低至96%。我们通过细致分析代码本大小、嵌入维度和子空间分解之间的相互作用，得出了VQ和PQ在扩展嵌入维度时性能相反的新发现，并且通过这些分析指导了最优超参数的选择。此外，PQGAN可以在预训练的扩散模型中无缝集成，实现生成速度的显著提升或输出分辨率的翻倍，而无需增加额外成本。", "conclusion": "我们的研究结果显示，PQ具有较强的离散潜在表示的扩展性，可用于图像合成。PQGAN能够无缝集成到预训练的扩散模型中，实现生成速度的显著提升或输出分辨率的翻倍，无需额外的成本。我们的工作既是对传统VQGAN的改进，也为图像生成应用带来了新的可能。"}
{"llm_update_time": "20251006", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.02384", "html_url": "https://arxiv.org/abs/2510.02384", "title": "安全可靠的AI生成图像水印技术：全面调查", "title_en": "Secure and Robust Watermarking for AI-generated Images: A Comprehensive Survey", "authors": "Jie Cao,Qi Li,Zelin Zhang,Jianbing Ni", "background": "生成型人工智能（Gen-AI）的迅速发展使得高质量图像的创建变得容易，但同时也带来了知识产权保护、真实性和责任等方面的重要关切。水印技术已经成为解决这些问题的一种有前景的方法，它能够区分AI生成的图像和自然内容，确保来源并推动可信赖的数字生态系统。本文对当前AI生成图像水印技术进行了全面的调研，涵盖了五个关键维度：图像水印系统的形式化、不同水印技术的综述与对比、视觉质量、容量和可检测性的评估方法、针对恶意攻击的脆弱性以及现有的挑战和未来方向。", "innovation": "本文首次对AI生成图像水印技术进行了全面综合的调研，涵盖了图像水印系统的形式化、不同水印技术的比较、评估方法、攻击脆弱性以及现存挑战和未来方向，旨在为研究人员提供一个全面的理解，从而促进该技术的持续发展。", "conclusion": "本文综合调查了AI生成图像水印技术的现状，为研究人员提供了一个全面的视角，有助于促进该技术的发展和应用。"}
{"llm_update_time": "20251006", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.03117", "html_url": "https://arxiv.org/abs/2510.03117", "title": "通过高级模态条件和交互驯服文本到声音视频生成", "title_en": "Taming Text-to-Sounding Video Generation via Advanced Modality Condition and Interaction", "authors": "Kaisi Guan,Xihua Wang,Zhengfeng Lai,Xin Cheng,Peng Zhang,XiaoJiang Liu,Ruihua Song,Meng Cao", "background": "该研究关注一个极具挑战性且前景广阔的文本到声音视频（T2SV）生成任务，其目标是从给定的文本条件中生成具有同步音频的视频，同时确保两个模态与文本保持一致。尽管在联合音频-视频训练方面取得了进展，两个关键挑战尚未得到有效解决：（1）单一共享的文本描述里，用于视频的文本与用于音频的文本相同，这常常导致模态间的干扰，混淆了预训练的骨干网络；（2）模态间特征交互的最佳机制尚不清楚。", "innovation": "为了解决上述挑战，该研究首先提出了层次视听接地标注框架（Hierarchical Visual-Grounded Captioning, HVGC），该框架生成一对解耦的描述，包括视频描述和音频描述，从而在条件阶段消除模态间的干扰。基于HVGC，进一步引入了BridgeDiT，这是一种新颖的双塔扩散变换器，利用双交叉注意力（Dual CrossAttention, DCA）机制，作为强大的“桥梁”，实现信息的对称、双向交换，从而实现语义和时间同步。", "conclusion": "在三个基准数据集上进行的大量实验，并通过人工评估支持，证明了本方法在大多数指标上取得了最先进的结果。全面的消融研究进一步验证了本研究贡献的有效性，为未来的T2SV任务提供了关键见解。所有代码和检查点将公开发布。"}
{"llm_update_time": "20251006", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.03232", "html_url": "https://arxiv.org/abs/2510.03232", "title": "LEAML: 对具有多模态大语言模型的超出分布视觉任务的高效标签适应", "title_en": "LEAML: Label-Efficient Adaptation to Out-of-Distribution Visual Tasks for Multimodal Large Language Models", "authors": "Ci-Siang Lin,Min-Hung Chen,Yu-Yang Sheng,Yu-Chiang Frank Wang", "background": "多模态大语言模型（MLLMs）在通用视觉基准测试中表现出色，但在医学成像等专门领域中的离群分布（OOD）任务上遇到困难，尤其是在标记数据有限且昂贵的情况下。现有方法在这种情况下效果不佳，特别是在标记数据稀缺的情况下。", "innovation": "提出了一种名为LEAML的标签高效适应框架，该框架利用稀缺的标记VQA样本和丰富的未标记图像。LEAML通过一种问题生成器生成领域相关的伪问题-答案对，该生成器由字幕蒸馏正则化。更重要的是，它只更新对问题-答案生成最相关的神经元，使问题生成器在蒸馏过程中高效地获取领域特定知识。", "conclusion": "在消化内镜和体育VQA实验中，LEAML在最少监督的情况下始终优于标准微调方法，表明我们提出的LEAML框架的有效性。"}
{"llm_update_time": "20251006", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.02514", "html_url": "https://arxiv.org/abs/2510.02514", "title": "从数据的信息-估计几何中学习距离度量", "title_en": "Learning a distance measure from the information-estimation geometry of data", "authors": "Guy Ohayon,Pierre-Etienne H. Fiquet,Florentin Guth,Jona Ballé,Eero P. Simoncelli", "background": "本文介绍了信息-估计度量（IEM），这是一种源自信号域上连续概率密度的新型距离函数。IEM 基于信息论与估计论之间的基本关系，将信号的对数概率与最佳去噪器应用于噪声观测结果的误差联系起来。通过比较不同噪声级别下信号的去噪误差向量，可以得到IEM。此外，IEM 的洛伦兹度量的局部第二阶近似公式也已被证明。对于高斯分布的信号，IEM 与马哈拉诺比斯距离相同，但对于更复杂的分布，它可以适应分布的几何结构。", "innovation": "该研究的创新在于提出了IEM，它是一种新的基于信息-估计几何的距离函数，适用于复杂分布且能够适应分布的几何结构。此外，IEM 可以通过学习去噪器（类似于生成性去噪模型）和求一维积分来计算。", "conclusion": "实验表明，IEM 在预测人类感知判断方面与最新监督图像质量度量相当或更优。"}
{"llm_update_time": "20251006", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.02730", "html_url": "https://arxiv.org/abs/2510.02730", "title": "戴尔遇见拉angen：基于几何布朗运动的乘法降噪扩散模型", "title_en": "Dale meets Langevin: A Multiplicative Denoising Diffusion Model", "authors": "Nishanth Shetty,Madhava Prasath,Chandra Sekhar Seelamantula", "background": "梯度下降已被证明是机器学习中优化的强而有效的方法。最近的神经科学进展表明，标准的梯度下降优化公式与生物系统中的学习并不一致。这意味着可以开发出受生物启发的学习技术进入新的领域。尤其是在 Dale 的定律启发下设计的基于指数梯度下降的优化方案产生对数正态分布的突触权重。这对数正态分布密度可以满足与几何布朗运动相关的随机微分方程(Fokker-Planck 方程)对应的分布密度。", "innovation": "1. 将 Dale 的定律与几何布朗运动的随机微分方程相结合，提出了一个乘法降噪扩散模型。2. 提出了一个新的伪乘法去噪得分匹配形式，适用于非负数据，并使用新的伪方法进行训练，适用于图像数据。3. 实验结果表明，新方案在 MNIST, Fashion MNIST, 和 Kuzushiji 数据集中的生成能力。", "conclusion": "这是基于几何布朗运动的乘法更新机制和生物启发生成模型的首次尝试。新模型可以利用对数正态分布的数据进行样本生成，提高了模型的生成能力。"}
{"llm_update_time": "20251006", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.02469", "html_url": "https://arxiv.org/abs/2510.02469", "title": "SIMSplat: 通过语言对齐的4D高斯点积进行预测驾驶场景编辑", "title_en": "SIMSplat: Predictive Driving Scene Editing with Language-aligned 4D Gaussian Splatting", "authors": "Sung-Yeon Park,Adam Lee,Juanwu Lu,Can Cui,Luyang Jiang,Rohit Gupta,Kyungtae Han,Ahmadreza Moradipari,Ziran Wang", "background": "随着基于传感器数据的驾驶场景操控技术的发展，传统的虚拟驾驶模拟器正逐渐被淘汰。现有的框架在生成高效且逼真的场景方面存在困难，主要是因为编辑功能有限。", "innovation": "SIMSplat 是一个基于语言的预测驾驶场景编辑器，采用与高斯重建场景对齐的语言。它能够进行直观的语言指令编辑，并支持直接查询道路对象，进行精确和灵活的编辑。通过引入多智能体运动预测进行轨迹预测改进，使得场景中的各智能体能够产生真实的交互。", "conclusion": "实验表明，SIMSplat 能够广泛应用于多种场景且具备强大的编辑能力。"}
{"llm_update_time": "20251006", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.02403", "html_url": "https://arxiv.org/abs/2510.02403", "title": "通过微调的多模态大语言模型进行青光眼检测和OCT结构报告生成", "title_en": "Glaucoma Detection and Structured OCT Report Generation via a Fine-tuned Multimodal Large Language Model", "authors": "Jalil Jalili,Yashraj Gavhane,Evan Walker,Anna Heinke,Christopher Bowd,Akram Belghith,Massimo A. Fazio,Christopher A. Girkin,C. Gustavo De Moraes,Jeffrey M. Liebmann,Sally L. Baxter,Robert N. Weinreb,Linda M. Zangwill,Mark Christopher", "background": "本研究基于1,310名受试者提供的43,849张OCT图像，旨在开发一个多模态大语言模型（MM-LLM），该模型能够对视神经头部（ONH）OCT环形扫描进行质量筛选，并生成包含青光眼诊断和视网膜神经纤维层（RNFL）各区域变薄评估的结构化临床报告。数据集包括来自DIGS和ADAGES队列的1,331例青光眼患者和867名健康眼的OCT环形扫描。方法涉及对大语言模型进行微调，以生成OCT影像数据的临床描述，包括图像质量评估、青光眼检测和RNFL变薄分类。结果证实，模型在图像质量和青光眼检测方面表现出高准确性，且在RNFL变薄预测中也表现良好，特别是在全局和颞侧区域。文本生成质量也与参考报告高度一致。", "innovation": "该研究开发了一个多模态大语言模型（MM-LLM），该模型既能对OCT图像进行质量评价，又能够生成包含青光眼诊断和RNFL变薄评估的结构化报告。这种方法结合了自动质量控制和临床信息生成，提高了诊断的准确性和效率。", "conclusion": "微调的MM-LLM能够生成准确的临床描述，并在图像质量检测、青光眼检测和RNFL变薄分类方面表现出高准确性，提供了一个有效支持临床OCT评估的结构化方法。"}
{"llm_update_time": "20251006", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.03230", "html_url": "https://arxiv.org/abs/2510.03230", "title": "通过显式的位置到坐标映射提升GUI定位", "title_en": "Improving GUI Grounding with Explicit Position-to-Coordinate Mapping", "authors": "Suyuchen Wang,Tianyu Zhang,Ahmed Masry,Christopher Pal,Spandana Gella,Bang Liu,Perouz Taslakian", "background": "GUI定位任务是将自然语言指令映射到像素坐标，对自主代理至关重要，但目前的视觉语言模型仍难以完成。核心瓶颈在于高分辨率显示的可靠补丁到像素的映射，这些高分辨率显示可能超出训练范围。当前方法直接从视觉特征生成坐标，导致模型隐式地进行复杂的坐标推断，从而导致在新分辨率上的准确度下降和失败增多。", "innovation": "该研究提出了两个互补创新。首先，RULER令牌作为显式坐标标记，允许模型像地图上的网格线那样引用位置并调整而不是从头生成坐标。其次，交错的MRoPE（I-MRoPE）通过确保宽度和高度维度的平等表示，解决了标准位置方案的不对称性，从而改进了空间编码。这些创新在ScreenSpot，ScreenSpot-V2和ScreenSpot-Pro上的实验显示了在高分辨率界面中的显著提升，通过提供显式的空间指导，这种方法能在不同的分辨率和平台上实现更可靠的GUI自动化。", "conclusion": "实验结果表明，通过提供显式的空间指导而不再依赖隐式学习，该方法在不同分辨率和平台上提供了更可靠的GUI自动化，并取得了持续的提升，尤其是在高分辨率接口上表现最为显著。"}
{"llm_update_time": "20251006", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.02713", "html_url": "https://arxiv.org/abs/2510.02713", "title": "基于颜料表示的图像增强", "title_en": "Image Enhancement Based on Pigment Representation", "authors": "Se-Ho Lee,Keunsoo Ko,Seung-Wook Kim", "background": "传统的图像增强方法在颜色变换上通常是受限于预定义的颜色空间（如RGB），这限制了其适应性和表现力，无法满足复杂多样图像内容的需求。", "innovation": "本文提出了一种基于颜料表示的新型高效图像增强方法。该方法不拘泥于固定的色彩空间，而是将RGB颜色动态转换到一个高维特征空间——颜料空间，通过这种方法实现了更好的图像增强性能。具体来说，该方法将输入的RGB颜色转换为高维颜料，然后分别进行重新投影和融合，以丰富和整合颜色信息，最后将颜料重新转换回RGB颜色，生成增强后的输出图像。该方法通过视觉编码器自适应地估计参数，使其能够根据输入图像的内容进行调整。大量实验结果表明，这种方法在图像修整和色调映射任务上明显优于现有的最先进的方法，同时保持了较低的计算复杂性和较小的模型大小。", "conclusion": "总的来说，本文提出的方法在图像增强任务上取得了显著的性能提升，同时保持了较低的计算复杂度和较小的模型尺寸，为图像增强技术的发展提供了一种新的思路。"}
{"llm_update_time": "20251006", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.02425", "html_url": "https://arxiv.org/abs/2510.02425", "title": "使语言模型感知的词汇", "title_en": "Words That Make Language Models Perceive", "authors": "Sophie L. Wang,Phillip Isola,Brian Cheung", "background": "文本训练的大语言模型（LLMs）似乎缺乏直接的感知经验，但其内部表征通过语言中隐含的多模态规律而被塑造。本研究假设，明确的感官提示可以揭示这种潜藏结构，使仅文本训练的语言模型更接近于专业视觉和音频编码器的表征对齐。当感官提示告诉模型“看到”或“听到”的时候，会引导模型将其下一步预测视为假定有隐藏的视觉或听觉证据所提供的条件结果。这些发现表明，简单的提示工程可以可靠地激活仅文本训练的语言模型中的模式适当的表征。", "innovation": "使用轻量级的提示工程技术，可以激活仅根据文本训练的语言模型中的适当模态表征，即使这些模型实际上没有经验或感知能力。通过明确的感官提示，如“看到”或“听到”，模型的下个令牌预测假定在隐含的视觉或听觉证据上进行条件判断，从而使其朝更接近专业视觉和音频编码器的表象对齐迈进。", "conclusion": "研究表明，简单的提示工程可以有效激活语言模型中的模态适当表征，提升其对视觉和听觉信息的处理能力，即使这些模型最初仅基于文本训练。"}
{"llm_update_time": "20251006", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.02707", "html_url": "https://arxiv.org/abs/2510.02707", "title": "压缩感知对比下的攻击不可知制对抗攻击检测的统计方法", "title_en": "A Statistical Method for Attack-Agnostic Adversarial Attack Detection with Compressive Sensing Comparison", "authors": "Chinthana Wimalasuriya,Spyros Tragoudas", "background": "当前，对抗攻击对现代机器学习系统的威胁非常显著，但现有的检测方法常常无法检测未见过的攻击，也不能以高精度区分不同类型的攻击。因此，现有方法存在明显不足，亟需一种新的解决方案来有效且实时地检测对抗攻击。", "innovation": "本文提出了一种统计方法，该方法在神经网络部署前建立检测基线，能够实现有效的实时对抗检测。该方法通过比较压缩和未压缩神经网络的行为，生成对抗存在的度量。这种方法经测试后效果接近完美，并且对抗多种攻击类型均表现出色。同时，该方法减少了误报，使之可靠且适用于实际应用。", "conclusion": "本文提出的统计方法能够为不可知制的对抗攻击提供有效的检测。通过压缩感知技术对压缩与未压缩的神经网络进行比较，这种方法不仅检测效果优秀，而且能显著减少误报，使其成为在实际应用中可靠的检测工具。"}
{"llm_update_time": "20251006", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.03216", "html_url": "https://arxiv.org/abs/2510.03216", "title": "Wave-GMS: 轻量级多尺度生成模型在医学图像分割中的应用", "title_en": "Wave-GMS: Lightweight Multi-Scale Generative Model for Medical Image Segmentation", "authors": "Talha Ahmed,Nehal Ahmed Shaikh,Hassan Mohy-ud-Din", "background": "为了在医院和医疗设施中公平部署AI工具，我们迫切需要性能高且能在成本效益高、内存有限且支持大批次训练的图形处理单元（GPU）上进行训练的深度分割网络。现有的解决方案通常难以满足这些要求。", "innovation": "本文提出了Wave-GMS，这是一种轻量级且高效的多尺度生成模型，用于医学图像分割。Wave-GMS具有较小的可训练参数数量，无需加载内存密集型的预训练视觉基础模型，并能够支持内存有限的GPU上的大批次训练。实验结果表明，Wave-GMS在四个公开数据集上实现了最先进的分割性能，并且具有优越的跨域泛化能力，所需可训练参数约为260万。", "conclusion": "Wave-GMS通过减少内存负担，允许大批次训练，实现了高效且高性能的医学图像分割，为在资源受限的环境中部署AI工具提供了新途径。"}
{"llm_update_time": "20251006", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.02894", "html_url": "https://arxiv.org/abs/2510.02894", "title": "PyRadiomics-cuda：在PyRadiomics中利用GPU加速的3D医学图像特征提取", "title_en": "PyRadiomics-cuda: a GPU-accelerated 3D features extraction from medical images within PyRadiomics", "authors": "Jakub Lisowski,Piotr Tyrakowski,Szymon Zyguła,Krzysztof Kaczmarski", "background": "PyRadiomics是一个用于从医学图像中提取定量影像学特征的库，但在处理大型三维数据集时，计算需求很高，这成为了一个挑战。PyRadiomics-cuda是PyRadiomics的GPU加速扩展版本，旨在解决这些问题，通过卸载关键的几何计算到GPU硬件，显著减少了处理时间，同时保持了与原始PyRadiomics API的完全兼容性，使得无缝集成到现有的AI工作流程中成为可能，无需修改代码。", "innovation": "PyRadiomics-cuda通过利用GPU加速关键的几何计算，极大地减少了处理大型三维数据集所需的时间。该系统与原始PyRadiomics API完全兼容，能够在保持原系统功能的同时，实现高效的、可扩展的影像学分析，支持快速特征提取，这对于高通量的AI管线至关重要。经测试，PyRadiomics-cuda适用于从普通计算集群到预算和家用设备的各种场景，证明了其实用性。该库是用Python和C/CUDA编写的，并且在BSD许可下免费提供。", "conclusion": "PyRadiomics-cuda在医学图像定量分析中具有广泛的应用前景，通过GPU加速显著提高了处理效率，简化了集成到AI工作流程中。该工具库的测试数据集和文档都已提供，方便开发者使用。"}
{"llm_update_time": "20251006", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.03074", "html_url": "https://arxiv.org/abs/2510.03074", "title": "使用自回归瓦片进行神经后验估计以检测天文图像中的物体", "title_en": "Neural Posterior Estimation with Autoregressive Tiling for Detecting Objects in Astronomical Images", "authors": "Jeffrey Regier", "background": "未来的天文调查将产生大量的高分辨率夜空图像，包含数十亿颗恒星和星系的信息。在这些图像中检测和表征天体是一项基础但极具挑战性的工作，因为大部分目标都很暗淡，且许多目标在视觉上与其他目标重叠。现有方法难以应对这一挑战，因此需要创新的方法来提高目标检测和表征的效果和准确性。", "innovation": "该研究提出了一种约瑟夫化变分推理方法，利用一系列自回归变分分布，这些分布以$K$色棋盘图案对潜在空间进行分区和排序。该方法通过神经后验估计（NPE）最小化前向KL散度的期望值来拟合变分分布，关键在于这种结构构造上能反映后验分布的条件独立性。这使得该方法能够更有效地检测和表征图像中的小目标。", "conclusion": "使用斯隆数字天空调查的图像，该方法达到了最先进的性能。进一步的研究表明，所提议的自回归结构显著提高了后验分布的校准效果。"}
{"llm_update_time": "20251006", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2311.13254", "html_url": "https://arxiv.org/abs/2311.13254", "title": "统一的领域适应语义分割", "title_en": "Unified Domain Adaptive Semantic Segmentation", "authors": "Zhe Zhang,Gaochang Wu,Jing Zhang,Xiatian Zhu,Dacheng Tao,Tianyou Chai", "background": "UDA-SS旨在将标记的源域监督传递到未标记的目标域。现有的许多UDAS-SS工作主要集中在图像上，最近的研究尝试通过建模时间维度拓展到视频领域。尽管图像和视频领域的UDAS-SS面临主要挑战相似——克服领域分布偏移，但其研究基本上是独立的，导致了研究成果的碎片化，缺乏整体理解，且跨领域方法的交叉创新机会被错过。这种碎片化导致了方法的分割，引发了重复努力和跨图像和视频领域知识传递效率低下。", "innovation": "本文提出统一图像和视频的UDA-SS研究，通过一般数据增强的角度探索统一的UDA-SS，提供了统一的理论框架，提升了泛化能力，具有潜在的思想交叉创新机会，最终推动了这一研究领域的整体进步和实际影响。具体而言，提出了一种四向Mixup（QuadMix）方法，通过四个方向处理不同的点属性和特征不一致性，在特征空间中实现域内和域间混合。为了处理视频中的时间偏移，引入了基于光流的空间和时间维度特征聚合，进行精细的领域对齐。", "conclusion": "广泛的实验证明，该方法在四个具有挑战性的UDA-SS基准上大幅超越了现有的最佳方法。我们的源代码和模型将于该链接发布：this https URL."}
{"llm_update_time": "20251006", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.03142", "html_url": "https://arxiv.org/abs/2510.03142", "title": "MM-Nav：多视角VLA模型通过多专家学习实现稳健的视觉导航", "title_en": "MM-Nav: Multi-View VLA Model for Robust Visual Navigation via Multi-Expert Learning", "authors": "Tianyu Xu,Jiawei Chen,Jiazhao Zhang,Wenyao Zhang,Zekun Qi,Minghan Li,Zhizheng Zhang,He Wang", "background": "视觉导航策略因其模仿人类导航方式而广受欢迎，它依赖于第一人称视觉观察。然而，视觉观察中的光学信息难以明确建模，如激光雷达点云或深度图，这需要智能模型和大规模数据。为了解决这个问题，本文提出了采用视觉语言动作（VLA）模型学习合成专家数据中的多样化导航能力的方法，这些数据是通过多视角观测和预训练的大型语言模型及视觉基础模型来实现的。同时，收集了三种强化学习（RL）专家在三种定制环境中获得的基于优先深度信息的不同导航能力的专家数据，如到达、挤压和避开。", "innovation": "本文创新地使用Vision-Language-Action（VLA）模型，结合多视角视觉观察和大规模合成数据，通过教师-学生模式学习不同导航能力。特别地，开发了一个名为MM-Nav的多视角VLA模型，构建了具有360度观察视角的多视角VLA，并运用了预训练的大型语言模型和视觉基础模型。通过在线收集来自RL专家的训练数据，并根据各种能力的表现动态平衡训练比例，增强了模型的泛化能力，并发现学生VLA模型超过了RL教师，展示了整合多种能力的协同效应。", "conclusion": "通过在合成环境中的广泛实验，模型展示了强大的泛化能力，并且在多专家学习机制下，学生VLA模型在不同导航能力上均表现出色。此外，实际世界实验进一步验证了该方法的有效性。"}
{"llm_update_time": "20251006", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.02700", "html_url": "https://arxiv.org/abs/2510.02700", "title": "基于无人机的VNIR高光谱基准数据集用于地雷和未爆弹药检测", "title_en": "A UAV-Based VNIR Hyperspectral Benchmark Dataset for Landmine and UXO Detection", "authors": "Sagar Lekhak,Emmett J. Ientilucci,Jasper Baur,Susmita Ghosh", "background": "为了在地雷和未爆弹药（UXO）检测研究中提供高质量的数据支持，本文介绍了通过无人驾驶航空器（UAV）获取的可见光和近红外（VNIR）高光谱图像数据集。该数据集覆盖了一个经过控制的测试场地，场地内洒有143个真实的代理地雷和UXO目标，包括地表、部分埋藏和完全埋藏配置。该数据集旨在填补开放获取的无人机高光谱数据在地雷检测方面的空白，并与之前相同测试场地发布的无人机电磁感应（EMI）数据结合使用，成为一个多传感器基准数据集。", "innovation": "本文提供了一个由无人驾驶航空器（UAV）获取的高光谱图像数据集，用于地雷和未爆弹药检测研究。数据集包含270个连续的光谱波段，覆盖398-1002nm范围，采用双点经验线方法进行了反射率的提取。通过交叉验证进行了误差评估，显示了高光谱的一致性。同时，数据集还包含原始辐射率立方体、GCP/AeroPoint数据和参考光谱，支持可重复的研究。", "conclusion": "此数据集填补了开放获取的无人机高光谱数据在地雷检测方面的空白，在相同测试场地的无人机电磁感应数据的支持下，它为地雷和未爆弹药检测研究提供了多传感器基准数据集，有助于提升研究的可靠性和一致性。"}
{"llm_update_time": "20251006", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.02956", "html_url": "https://arxiv.org/abs/2510.02956", "title": "Confidence and Dispersity as Signals: Unsupervised Model Evaluation and Ranking", "title_en": "Confidence and Dispersity as Signals: Unsupervised Model Evaluation and Ranking", "authors": "Weijian Deng,Weijie Tu,Ibrahim Radwan,Mohammad Abu Alsheikh,Stephen Gould,Liang Zheng", "background": "在实际部署中，评估模型在分布偏移情况下的泛化能力至关重要，尤其是当不存在标记测试数据时。本文提出了一个适用于两种常见部署场景的统一且实用的无监督模型评估和排序框架：(1) 估计固定模型在多个未标记测试集上的准确率（数据集为中心的评估），(2) 在单个未标记测试集上对一组候选模型进行排名（模型为中心的评估）。", "innovation": "本文发现模型预测的两个内在特性，即置信度（反映预测确定性）和分散性（捕捉预测类别的多样性），提供了一种强而互补的泛化信号。研究系统地评估了一系列基于置信度、分散性和混合度量在多种模型架构、数据集和分布偏移类型的基准测试中的一致表现。结果表明，在数据集为中心和模型为中心的评估场景中，混合度量始终优于单一指标度量。特别是，预测矩阵的核范数在各种任务中提供了稳健和准确的表现，并在中等类别不平衡下保持可靠性。这些发现为部署场景下的无监督模型评估提供了一个实用且通用的基础。", "conclusion": "本文的研究结果表明，利用置信度和分散性的混合指标可以更有效地评估和排序模型在实际部署场景中泛化性能，提供了一种适用于广泛模型架构和数据集分布偏移类型的无监督模型评估方法。"}
{"llm_update_time": "20251006", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.02869", "html_url": "https://arxiv.org/abs/2510.02869", "title": "代表美感：向着参与性但客观的潜在美学", "title_en": "Representing Beauty: Towards a Participatory but Objective Latent Aesthetics", "authors": "Alexander Michael Rusnak", "background": "尽管美感是一个在文化上和经验上都很吸引人但哲学上却难以捉摸的概念，深度学习系统却越来越显示出能够模拟审美判断的能力。本文探讨了神经网络在面对美感这一术语适用于的巨大形式多样性对象时，仍然能够表示美的能力。", "innovation": "通过参考最近关于跨模型表示收敛的工作，本文展示了审美内容如何产生在不同数据和模态下训练过的模型之间更为类似和对齐的表示，而非审美图像则不会产生更多的对齐表示。这一发现表明，美好图像的形式结构具有现实基础，而非仅仅是社会构建价值观的反映。此外，本文提出了美的现实表示存在的原因是因为审美形式在物理和文化物质上的联合基础。本文还进一步论证了人类感知和创作过程对塑造深度学习系统的潜在空间起着中心作用，但美的现实基础表明，机器不仅不是机械性的模仿者，还可以从其独特的尺度产生新颖的创造性洞见。", "conclusion": "我们的研究发现，人类与机器的共同创作不仅有可能，而且是基础性的，美感在文化生产和机器感知中都充当着进化的目标导向吸引剂。"}
{"llm_update_time": "20251006", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.02803", "html_url": "https://arxiv.org/abs/2510.02803", "title": "工区挑战VLM轨迹规划：朝缓解和稳健自主驾驶迈进", "title_en": "Work Zones challenge VLM Trajectory Planning: Toward Mitigation and Robust Autonomous Driving", "authors": "Yifan Liao,Zhen Sun,Xiaoyun Qiu,Zixiao Zhao,Wenbing Tang,Xinlei He,Xinhu Zheng,Tianwei Zhang,Xinyi Huang,Xingshuo Han", "background": "视觉语言模型（VLMs）因其强大的多模态推理能力正被汽车制造商逐渐应用于自主驾驶中，以提高在复杂环境下的规划能力。然而，VLMs在工作区（工区常见不规则布局、临时交通控制和动态变化的几何结构）的轨迹规划能力尚未得到探索。当前，主流的VLMs在68.0%的情况下无法生成正确的轨迹。研究者通过子图挖掘和聚类分析识别了候选模式，通过人工验证确认了8个常见失败模式，并在此基础上提出了将检索增强生成（RAG）与VLMs结合的轨迹规划框架REACT-Drive，进一步的实验表明，相较于VLM基线，REACT-Drive在Qwen2.5-VL评估中平均位移误差降低了约三分之二，并且具有最低的推理时间（0.58秒）.", "innovation": "研究首次系统地探讨了VLMs在工作区的轨迹规划能力，提出了结合检索增强生成（RAG）的轨迹规划框架REACT-Drive。REACT-Drive利用VLMs将先前失败案例转化为约束规则和可执行的轨迹规划代码，通过RAG在新情景中检索相似模式以引导轨迹生成。实验结果显示，其在位移误差和推理时间方面均优于其他方法，特别是在实际车辆测试中展示了强实际应用能力。", "conclusion": "研究证明了VLMs在工作区轨迹规划中的挑战性，并通过REACT-Drive框架提出了有效的应对策略，显著降低了误差并减少了推理时间，展示了在实际场景下的强实践应用性。"}
{"llm_update_time": "20251006", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.02781", "html_url": "https://arxiv.org/abs/2510.02781", "title": "GCVAMD: 改进的因果VAE模型，用于与年龄相关的黄斑变性风险因素的因果检测与预测", "title_en": "GCVAMD: A Modified CausalVAE Model for Causal Age-related Macular Degeneration Risk Factor Detection and Prediction", "authors": "Daeyoung Kim", "background": "年龄相关性黄斑变性（AMD）一直是眼科中导致永久性视力损害的主要原因之一。尽管已经开发出了抗VEGF药物或光动力疗法等治疗方法来减缓AMD的退化过程，但至今没有能够逆转由AMD引起视力丧失的具体疗法。因此，早期检测患者视网膜中AMD及其风险因素的存在变得至关重要，以减少视力受损的可能性。除了传统的诊断方法外，基于深度学习的方法，特别是在OCT扫描上使用基于注意力机制的CNN和GradCAM基于解释模型分析，已经成功地区分了AMD和正常视网膜，使得使用AI驱动的模型来辅助眼科医生诊断和分析AMD成为可能。然而，虽然具有显著的成功，先前的工作大多集中在预测性能本身，而没有探讨AMD的病理或潜在的因果机制，这可能阻止了特定因素的干预分析，或导致不那么可靠的决策。因此，本文介绍了一种新的因果AMD分析模型：GCVAMD，该模型融合了一种改进的因果VAE方法，可以从仅有的原始OCT图像中提取出潜在的因果因素。通过在AMD检测中考虑因果性，GCVAMD使得关于主要风险因素：硬性渗出和新生血管化，的治疗模拟或干预分析成为可能，并返回有助于下游任务的具有信息性潜在因果特征。结果显示，通过GCVAMD，可以识别出AMD因果机制中硬性渗出和新生血管化状态，这些信息可以用于从AMD检测（分类）到干预分析等各种任务中。", "innovation": "引入了GCVAMD模型，该模型结合了改进的因果VAE方法，可以从原始OCT图像中提取因果因素。GCVAMD能够在AMD因果空间中识别出与重大风险因素相关的状态，同时为各种下游任务提供具有信息性的潜在因果特征，增强了干预分析与模拟能力。与其他模型侧重于预测性能不同，GCVAMD能够进行详细的因果推理，提供基于因果机制的分析和决策支持。", "conclusion": "GCVAMD通过结合因果VAE，成功地识别了与AMD相关的潜在因果因素，并能够在因果空间中进行治疗方法模拟与干预分析。这种基于因果机制的方法，不仅增强了AMD检测的准确性，还提高了干预分析的可靠性，为未来的AMD治疗提供了新的视角。"}
{"llm_update_time": "20251006", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2306.17141", "html_url": "https://arxiv.org/abs/2306.17141", "title": "Filter-Guided Diffusion for Controllable Image Generation", "title_en": "Filter-Guided Diffusion for Controllable Image Generation", "authors": "Zeqi Gu,Ethan Yang,Abe Davis", "background": "近期基于扩散的生成模型在零样本图像到图像的转换和编辑方面展示了巨大潜力。大多数此类方法通过在生成新图像时结合或替换某些指导图像的反向过程所得的网络特定特征来工作。这些方法被视作无训练的方法中的最新技术，但它们存在一些显著的局限性：运行时间和内存成本较高，并且依赖于确定性采样，这限制了生成结果的变异度。", "innovation": "文章提出了过滤引导扩散(Filtered-Guided Diffusion, FGD)，利用扩散过程中快速的过滤操作，以支持对引导强度和频率的更精细控制，同时能使用非确定性采样器生成更多样化的结果。FGD方法在效率上更为突出，可以在较短时间内通过多次采样和超参数运行来产生基于结构和语义的优越结果。", "conclusion": "文章通过广泛的定量和定性实验评估了FGD在翻译任务中的性能，并展示了其在使用掩膜进行局部编辑时的潜力。FGD能够生产出基于结构和语义的更优结果，并且可以在多个随机种子和超参数下进行更快速的采样。"}
{"llm_update_time": "20251006", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2412.06461", "html_url": "https://arxiv.org/abs/2412.06461", "title": "从内部排序：无需标签排名大型多模态模型", "title_en": "Ranked from Within: Ranking Large Multimodal Models Without Labels", "authors": "Weijie Tu,Weijian Deng,Dylan Campbell,Yu Yao,Jiyang Zheng,Tom Gedeon,Tongliang Liu", "background": "随着预训练大型多模态模型（LMM）的发展，选择合适的模型以便应用于新的数据或任务变得越来越重要。传统的做法是等同于给模型做考试并进行打分。为了避免手动确定正确答案所带来的劳动和成本，该研究探索了其他信号可能导致模型判断其自身的局限性，并用这些信号来评估对模型进行无监督排名的有效性。", "innovation": "研究通过不依赖标签的方法，使用不确定性的度量来预测大型多模态模型在不同任务中的相对性能，发现从softmax分布推导出的不确定性分数为模型在各种任务中的排名提供了一种稳健且一致的基础。", "conclusion": "无需贴标签的数据，该方法为选择适合不同目标领域的模型提供了一种实际的途径，避免了人工注释的需求，使得模型可以在多种任务中进行有效且可靠的排名。"}
{"llm_update_time": "20251006", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2407.10575", "html_url": "https://arxiv.org/abs/2407.10575", "title": "针对AI生成视听媒体的防护综述：检测、干扰与身份验证", "title_en": "A Survey of Defenses against AI-generated Visual Media: Detection, Disruption, and Authentication", "authors": "Jingyi Deng,Chenhao Lin,Zhengyu Zhao,Shuai Liu,Qian Wang,Chao Shen", "background": "深度生成模型在计算机视觉应用中表现出色，包括图像合成、视频生成和医疗分析等领域。尽管这些模型取得了显著进展，但也可能被用于恶意目的，如 misinformation、deception 和版权侵权等。因此，需要研究抵御 AI 生成视听媒体的方法，包括检测、破坏和身份验证，以保障其安全与可信赖度。", "innovation": "本文提供了一个系统和及时的综述，涵盖了对抗 AI 生成视听媒体的防御策略，并将现有方法统一到被动和主动框架中进行审查。本文还调查了关于防御可信度的衍生任务，如其稳健性和公平性，提出了基于方法策略的分类，并总结了常用的评估数据集、标准和指标，从而为未来的研究提供了洞察和潜在方向。", "conclusion": "通过分析已审查的研究，本文提供了当前研究挑战的见解，并建议了未来研究的可能方向。"}
{"llm_update_time": "20251006", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2503.04470", "html_url": "https://arxiv.org/abs/2503.04470", "title": "Gate-Shift-Pose: 提升运动中动作识别的骨架信息", "title_en": "Gate-Shift-Pose: Enhancing Action Recognition in Sports with Skeleton Information", "authors": "Edoardo Bianchi,Oswald Lanz", "background": "该论文介绍了一种名为Gate-Shift-Pose的增强版Gate-Shift-Fuse网络，用于花样滑冰运动员跌倒分类任务。该网络通过结合骨架姿态数据和RGB帧来提高分类性能。论文评估了两种融合策略：早期融合和晚期融合。早期融合在输入阶段将RGB帧与姿态关键点的高斯热图进行结合；晚期融合则使用多流架构和注意力机制将RGB和姿态特征进行组合。", "innovation": "论文提出了一种新的网络结构Gate-Shift-Pose，并结合了骨架姿态数据和RGB帧。实验结果表明，Gate-Shift-Pose相较于仅使用RGB帧的基线模型，在ResNet18上的准确率提升了40%，在ResNet50上的准确率提升了20%。早期融合在ResNet50上达到了最高的准确率（98.08%），利用了模型在多模态集成方面的潜力；而晚期融合则更适合较轻的网络 Backbone 如ResNet18。", "conclusion": "实验结果表明，多模态架构在体育动作识别中具有潜在优势，骨架姿态信息在捕捉复杂运动模式中起着关键作用。"}
{"llm_update_time": "20251006", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2405.18406", "html_url": "https://arxiv.org/abs/2405.18406", "title": "RACCooN：带有自动生成叙述的多功能视频编辑框架", "title_en": "RACCooN: A Versatile Instructional Video Editing Framework with Auto-Generated Narratives", "authors": "Jaehong Yoon,Shoubin Yu,Mohit Bansal", "background": "目前的视频生成模型主要依赖于精心撰写的文本提示来实现特定任务，例如图像修复或风格编辑。这些模型需要详尽的文字描述输入视频，这限制了它们适应用户的个性化或原始视频的需求，增加了灵活性。", "innovation": "该论文提出了RACCooN框架，这是一个多功能且用户友好的视频到段落到视频生成框架。该框架通过统一管道支持多种视频编辑功能，如删除、添加和修改等。RACCooN由两个主要阶段组成：视频到段落（V2P）和段落到视频（P2V）。在V2P阶段，自动将视频场景描述为结构良好的自然语言，捕捉整体背景和详细的物体细节。在P2V阶段，用户可以选择性地细化这些描述，以指导视频扩散模型，实现对输入视频的各种修改。RACCooN的主要创新包括：(1) 建议使用多粒度的时空池化策略生成结构良好的视频描述，无需复杂的手工标注即可捕捉到整体上下文和细节，简化基于文本的精确视频内容编辑；(2) 确保视频生成模型包含自动生成的叙述或指示，提高生成内容的质量和准确性；(3) RACCooN能够想象给定视频中的新对象，允许用户只需提示模型来获取详细的视频编辑计划以进行复杂视频编辑。", "conclusion": "所提出的框架展示了在视频到段落生成、视频内容编辑方面的出色多功能能力，并且可以与其他最先进的视频生成模型结合使用以进一步增强功能。"}
{"llm_update_time": "20251006", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2410.01534", "html_url": "https://arxiv.org/abs/2410.01534", "title": "在CLIP模型稳健性方面全面评估", "title_en": "Toward a Holistic Evaluation of Robustness in CLIP Models", "authors": "Weijie Tu,Weijian Deng,Tom Gedeon", "background": "文章指出，对比语言-图像预训练（CLIP）模型在零样本分类和多种分布变化场景中的表现非常出色。已有研究主要评估了整体分类稳健性，但本文旨在通过引入多个新视角提供更为全面的评估，包括模型对于特定视觉因素变化的鲁棒性、安全性和精度、模态间的融合细致程度、三维感知能力，以及视觉和语言编码器之间的互动对分类稳健性的影响。研究考虑了六个因素对CLIP模型的影响：模型架构、训练分布、训练集大小、微调、对比损失以及测试时的提示信息。文章揭示了关于CLIP模型的一些先前未知的见解，例如视觉编码器架构影响对3D故障的鲁棒性，以及偏爱形状预测的现象在ImageNet微调后会减弱等。", "innovation": "文章提供了关于CLIP模型更为全面的评估，不仅包括其基本的分类能力，还包括了模型对于特殊感知能力（如三维感知）、安全性、语言和图像模态的整合能力等多个维度的评估。此外，还探讨了视觉编码器和语言编码器之间交互对模型稳健性的影响，为提升模型的稳健性和可靠性提出了建议。", "conclusion": "研究发现CLIP模型在特定视觉因素变化时表现出一定鲁棒性，但具有形状偏好这一潜在问题，这个偏好在微调后有所减弱；对于三维感知能力，视觉编码器的架构对该能力有显著影响；使用CLIP视觉编码器的语言-视觉模型在处理复杂类别时可能优于CLIP本身。研究为提升CLIP模型的稳健性和可靠性提供了有价值的指导。"}
{"llm_update_time": "20251006", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2503.10439", "html_url": "https://arxiv.org/abs/2503.10439", "title": "EFC++：基于原型重新平衡的弹性特征整合在冷启动无范例增量学习中的应用", "title_en": "EFC++: Elastic Feature Consolidation with Prototype Re-balancing for Cold Start Exemplar-free Incremental Learning", "authors": "Simone Magistri,Tomaso Trinci,Albin Soutif-Cormerais,Joost van de Weijer,Andrew D. Bagdanov", "background": "该研究针对类增量学习（Class Incremental Learning, CIL）场景，特别是在冷启动（Cold Start）情况下，缺乏足够数据以学习高质量主干网络的问题。传统的CIL方法依赖于以前任务的数据，而在冷启动场景中，初始任务的数据不足以进行高质量学习，这给无范例类增量学习（Exemplar-free Class Incremental Learning, EFCIL）带来了挑战，因为其需要高度的可塑性，导致特征漂移难以在无范例的情况下进行补偿。", "innovation": "该论文提出了一种用于无范例类增量学习的有效方法，称为弹性特征整合增强（Elastic Feature Consolidation++, EFC++）。EFC++利用基于所提出的特征矩阵（Empirical Feature Matrix, EFM）的二阶近似来调节特征漂移，以整合重要的特征表示。此外，还引入了一个原型后训练重新平衡阶段，通过更新分类器来补偿特征漂移。这种方法不仅维持了模型的可塑性，而且在CIFAR-100、Tiny-ImageNet、ImageNet-Subset、ImageNet-1K和DomainNet等数据集上的实验表明，与现有最佳方法相比表现更为优越。", "conclusion": "EFC++显著改善了冷启动无范例增量学习的效果，通过维持模型的可塑性，提升了新任务的学习能力，并在多个数据集上大大优于现有最佳方法。"}
{"llm_update_time": "20251006", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2312.07935", "html_url": "https://arxiv.org/abs/2312.07935", "title": "比较YOLOv8与Mask R-CNN在复杂果园环境中的实例分割", "title_en": "Comparing YOLOv8 and Mask R-CNN for instance segmentation in complex orchard environments", "authors": "Ranjan Sapkota,Dawood Ahmed,Manoj Karkee", "background": "实例分割是农业自动化中的重要图像处理操作，它为精确界定图像中的单个对象并执行如选择性收获和精准修剪等任务提供了可能。本研究在不同条件的果园环境中分别使用一个阶段的YOLOv8模型和两个阶段的Mask R-CNN模型进行实例分割对比，数据集1（休眠期收集）包含无叶苹果树的图像，用于训练多对象分割模型；数据集2（生长初期收集）包含带有绿色叶片及未成熟苹果的树冠图像，用于训练单对象分割模型。研究对比了两种模型在不同条件下的性能。", "innovation": "本研究创新性地在复杂果园环境中对比了一个阶段的YOLOv8模型和两个阶段的Mask R-CNN模型在实例分割任务上的效果，且使用了不同的数据集来验证模型在不同条件下的适应性。实验结果表明，YOLOv8模型在精度和召回率上均优于Mask R-CNN模型，并且在推理时间上也表现更优，特别是在实时果园自动化任务如机器人收获和疏果中展现出更强的适用性。", "conclusion": "研究表明，YOLOv8模型在精度和效率方面优于Mask R-CNN模型，特别适用于实时果园自动化任务。YOLOv8具有更高的精度和接近完美的召回率，在两组数据集上的表现均优于Mask R-CNN模型。同时，YOLOv8的推理速度快，更适用于实际应用中的实时部署。"}
{"llm_update_time": "20251006", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2501.12266", "html_url": "https://arxiv.org/abs/2501.12266", "title": "CBVLM: 不依赖训练的大规模视觉语言模型的解释性概念导向方法在医学图像分类中的应用", "title_en": "CBVLM: Training-free Explainable Concept-based Large Vision Language Models for Medical Image Classification", "authors": "Cristiano Patrício,Isabel Rio-Torto,Jaime S. Cardoso,Luís F. Teixeira,João C. Neves", "background": "深度学习在医疗流程中的应用受限于标注数据的可用性和系统的可解释性不足。概念瓶颈模型（CBMs）通过预设可人类理解的概念来提高模型的可解释性，但这也带来了更高的标注负担，并且添加新概念需要重新训练整个系统。因此，提出了一个基于大规模多模态预训练模型（LVLM）的新方法，称为CBVLM，以同时解决这两个问题。", "innovation": "CBVLM利用大规模多模态预训练模型的少量样本学习能力，通过两个步骤来实现解释性而不依赖训练的方法：1）对每个概念，让LVLM判断输入图像中是否存在该概念；2）根据概念预测结果对图像进行分类。此外，引入检索模块以选择最佳的示例用于上下文学习。这种方法确保了解释性，同时通过利用LVLM的少量样本学习能力大大降低了标注成本。实验结果表明，CBVLM在四个医学数据集上表现一致优于CBMs和任务特定的监督方法，且无需训练和使用极少量的标注样本。", "conclusion": "CBVLM通过使用大型视觉语言模型的少量样本学习能力，提供了解释性并且能够大幅降低标注成本的解决方案。该方法在广泛实验中均优于传统方法，展示了其在医学图像分类中的潜力。"}
{"llm_update_time": "20251006", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2503.18035", "html_url": "https://arxiv.org/abs/2503.18035", "title": "车辆-场景交互：一种基于文本的3D激光雷达地点识别方法在自动驾驶中的应用", "title_en": "Vehicle-Scene Interaction: A Text-Driven 3D Lidar Place Recognition Method for Autonomous Driving", "authors": "Tianyi Shang,Zhenyu Li,Pengjie Xu,Zhaojun Deng", "background": "基于遥感构建的大规模点云地图在大型自主系统（如最后一千米的配送机器人）的发展中具有关键性意义。然而，当前方法存在挑战，主要由于点云编码器不能有效捕捉局部细节和长距离的空间关系，以及文本与点云表示之间显著的模态差异。为解决这些问题，我们提出了Des4Pos，一种新颖的两阶段文本驱动遥感定位框架。该框架的第一阶段通过多尺度融合注意机制（MFAM）增强局部几何特征，结合双向LSTM模块强化全局空间关系。同时，Stepped Text Encoder（STE）模块融合跨模态先验知识，并利用CLIP进行文本和点云特征的对齐，从而有效填补模态差异。在精细阶段，我们引入了级联残差注意（CRA）模块，融合跨模态特征并预测相对定位偏移量，从而提高定位精度。", "innovation": "Des4Pos框架在粗略阶段利用多尺度融合注意机制和双向LSTM模块来增强局部几何和全局空间关系，在精细阶段引入级联残差注意模块来预测相对定位偏移。同时，它还利用Stepped Text Encoder模块整合文本和点云特征，通过CLIP进行跨模态对齐，有效克服了文本与点云表示之间的模态差异。该方法在KITTI360Pose测试集上实现了最先进的文本到点云位置识别性能，特别是在5米半径阈值下，准确率达到第1位40%，第10位77%，分别比现有最佳方法高出7%，7%.", "conclusion": "实验结果表明，Des4Pos在面向大规模自主系统的最终定位任务中表现优异，尤其在基准测试集KITT10上取得了最佳成绩。通过多模态信息的融合和跨模态特征的对齐，Des4Pos显著提高了点云地图中的位置识别精度，为自动驾驶等应用奠定了坚实的基础。"}
{"llm_update_time": "20251006", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2501.09281", "html_url": "https://arxiv.org/abs/2501.09281", "title": "SoccerSynth-Detection: 用于足球运动员检测的合成数据集", "title_en": "SoccerSynth-Detection: A Synthetic Dataset for Soccer Player Detection", "authors": "Haobin Qin,Calvin Yeung,Rikuhei Umemoto,Keisuke Fujii", "background": "在足球视频分析中，球员检测对于识别关键事件和重建战术位置至关重要。然而，由于存在大量球员、频繁遮挡以及版权限制，可用的足球视频数据集受到严重限制。现有的数据集中，如SoccerNet-Tracking和SportsMOT，样本多样性不足，限制了算法在各种足球视频场景中的适应性。", "innovation": "为了应对这些挑战，我们开发了SoccerSynth-Detection，这是第一个专为合成足球球员检测设计的合成数据集。该数据集包含广泛随机的光照和纹理，以及模拟的相机运动模糊。通过使用目标检测模型（Yolov8n）与现实世界数据集（SoccerNet-Tracking和SportsMoT）进行验证，以及在转移测试和预训练测试中的表现，证明了其在处理运动模糊图像时比现实数据集有显著提升，展现了合成数据集在足球视频分析领域算法训练中的潜力。", "conclusion": "我们的工作表明，合成数据集有潜力替代现实数据集用于足球视频分析中算法的训练。"}
{"llm_update_time": "20251006", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2504.20629", "html_url": "https://arxiv.org/abs/2504.20629", "title": "AlignDiT: 多模态对齐扩散变换器及其在同步语音生成中的应用", "title_en": "AlignDiT: Multimodal Aligned Diffusion Transformer for Synchronized Speech Generation", "authors": "Jeongsoo Choi,Ji-Hoon Kim,Kim Sung-Bin,Tae-Hyun Oh,Joon Son Chung", "background": "近年来，多模态到语音生成的任务受到越来越多的关注。该任务的目标是从多种输入模态（如文本、视频和参考音频）合成高质量的语音。现有的方法仍然存在语音清晰度、音频-视频同步性、语音自然度和与参考说话人声音相似度等方面的问题。因此，本文研究和提出了AlignDiT多模态对齐扩散变换器，以解决这些问题并提高语音生成的质量和同步性。", "innovation": "本文提出了一种新型的多模态分类器自由指导机制，使模型在语音合成过程中能够自适应地平衡每个模态的信息。此外，AlignDiT通过利用DiT架构的上下文学习能力，探索了三种有效的策略来对齐多模态表示，从而生成准确、同步且自然的语音。实验表明，与现有的方法相比，AlignDiT在多个基准测试中在质量和同步性方面表现出更出色的表现，并且展示了在不同多模态任务上的强泛化能力。", "conclusion": "AlignDiT在多项实验中显著优于现有方法，展现出卓越的语音质量和同步性。同时，其具有强泛化能力，成功应用于视频到语音合成和视觉对齐等多种多模态任务中，始终达到了最新的技术水平。"}
{"llm_update_time": "20251006", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2410.10289", "html_url": "https://arxiv.org/abs/2410.10289", "title": "细粒度异常提示学习以实现零样本异常检测", "title_en": "Fine-grained Abnormality Prompt Learning for Zero-shot Anomaly Detection", "authors": "Jiawen Zhu,Yew-Soon Ong,Chunhua Shen,Guansong Pang", "background": "当前的零样本异常检测(ZSAD)方法能够使大规模预训练的视觉-语言模型在无需特定数据集训练或示例的情况下识别目标数据集中的异常，显示出了显著的成功。然而，这些方法大多集中在构造或学习捕获异常一般特征（如“损坏的”、“不完美的”或“缺陷的”对象等）的粗略语义提示上，对于不同方式偏离这些一般异常模式的多样异常细节，识别能力有限。", "innovation": "提出了一种新的FAPrompt框架，用于学习细粒度异常提示以提高ZSAD的准确性。FAPrompt引入了一个创新的复合异常提示学习(CAP)模块，用于学习一套互补的，分解的异常提示，并通过同一正常性语义下的多种异常模式来约束异常提示。为了增强跨数据集的一般化能力，FAPrompt还引入了一个新的数据依存异常先验学习(DAP)模块，基于每个测试图像中的异常特征学习样本级别的异常先验，从而动态适应异常提示至单个测试图像。", "conclusion": "在19个实际世界数据集上进行了全面的实验，涵盖工业缺陷和医疗异常，结果表明FAPrompt显著优于最先进的零样本异常检测方法，在图像级和像素级的零样本异常检测任务中表现出色。代码可在特定URL获取。"}
{"llm_update_time": "20251006", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2505.23463", "html_url": "https://arxiv.org/abs/2505.23463", "title": "重新审视加权风险函数在校准中的应用：AURC、焦点损失和逆焦点损失", "title_en": "Revisiting Reweighted Risk for Calibration: AURC, Focal, and Inverse Focal Loss", "authors": "Han Zhou,Sebastian G.Gruber,Teodora Popordanoska,Matthew B. Blaschko", "background": "近年来，已经提出了多种重加权风险函数，如焦点损失、逆焦点损失以及风险-覆盖曲线下的面积（AURC），用于提升模型的校准度，但它们与校准误差的理论联系仍不清楚。已有研究表明，模型校准误差与选择性分类息息相关，但如何通过优化校准误差独立地提高模型的校准性能尚未有清晰的方法。", "innovation": "本文重新审视了广泛应用于深度学习的加权风险函数，建立了校准误差与选择性分类之间的原则性联系。提出了一种基于箱子累积分布函数（CDF）近似的方法，该方法不依赖于排序操作，从而实现高效的梯度优化，时间复杂度为$O(nK)$。与双焦点损失相比，本文方法提供的通过置信分数函数（CSFs）的选择性更强。", "conclusion": "实验证明，本文方法在多个数据集和模型架构上实现了竞争力的校准性能。"}
{"llm_update_time": "20251006", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2506.09650", "html_url": "https://arxiv.org/abs/2506.09650", "title": "HopaDIFF: Holistic-Partial Aware Fourier Conditioned Diffusion for Referring Human Action Segmentation in Multi-Person Scenarios", "title_en": "HopaDIFF: Holistic-Partial Aware Fourier Conditioned Diffusion for Referring Human Action Segmentation in Multi-Person Scenarios", "authors": "Kunyu Peng,Junchao Huang,Xiangsheng Huang,Di Wen,Junwei Zheng,Yufan Chen,Kailun Yang,Jiamin Wu,Chongqing Hao,Rainer Stiefelhagen", "background": "动作分割是高级视频理解的核心挑战，旨在将未修剪的视频分割成段并为每一段分配预定义的动作集中的标签。现有的方法主要处理单人活动和固定的动作序列，忽视了多人场景。现有方法在多人场景中的表现有限，难以聚合目标人物的视觉线索。", "innovation": "本文提出了第一个针对跨场景的人类动作分割任务的数据集——RHAS133，包含来自133部电影的33小时视频数据以及文本描述。为了改进现有方法在目标人物视觉线索聚合上的表现，本文提出了一种整体-局部意识的Fourier条件化扩散框架——HopaDIFF。该框架利用新颖的交叉输入门注意力xLSTM增强整体-局部的长程推理，并引入新颖的Fourier条件以引入更细粒度的控制以改进动作分割生成。HopaDIFF在RHAS133上的多种评估设置下达到了最先进的效果。", "conclusion": "HopaDIFF框架在多人场景中的文本参考指导的人类动作分割任务上取得了最先进的结果，实验数据集和代码已经对外开放。"}
{"llm_update_time": "20251006", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2505.08665", "html_url": "https://arxiv.org/abs/2505.08665", "title": "SkillFormer: 统一的多视角视频理解用于技能评估", "title_en": "SkillFormer: Unified Multi-View Video Understanding for Proficiency Estimation", "authors": "Edoardo Bianchi,Antonio Liotta", "background": "在体育、康复和训练等领域，评估人类在复杂活动中的技能水平是一个具有挑战性的问题。现有的方法往往难以全面准确地评估多视角视频中的技能水平，特别是在需要同时考虑第一人称（egocentric）视角和第三人称（exocentric）视角的场景中。", "innovation": "SkillFormer 是一个参数高效架构，用于从多视角（包括第一人称和第三人称）视频中统一估计技能水平。它基于 TimeSformer 的基础架构，引入了一个名为 CrossViewFusion 模块，该模块使用多头交叉注意力、可学习门控机制和自适应自校准来融合特定视角的特征。此外，通过低秩适应 (Low-Rank Adaptation)，只对小部分参数进行微调，大大降低了训练成本。", "conclusion": "在 EgoExo4D 数据集上的评估表明，SkillFormer 达到了多视角设置下的最新准确性，同时展示了卓越的计算效率，使用的参数是前代基线的 4.5 倍少，所需的训练周期是前代基线的 3.75 倍少。在多项结构化任务中的表现，证实了多视角集成对于细粒度技能评估的价值。"}
{"llm_update_time": "20251006", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2505.06905", "html_url": "https://arxiv.org/abs/2505.06905", "title": "通过稀疏LiDAR引导校正提高单目高度估计", "title_en": "Enhancing Monocular Height Estimation via Sparse LiDAR-Guided Correction", "authors": "Jian Song,Hongruixuan Chen,Naoto Yokoya", "background": "基于深度学习的单目高程估计（MHE）从高分辨率遥感图像中提取高度信息，面临着缺乏充足结构信息的挑战。传统数字高程模型（DEMs），通常来自于机载LiDAR或三维多视角立体图，虽然成本高昂且地理覆盖有限，但仍然是常用的工具。近年来，虽然通过合成数据训练并在领域适应后模型显示出良好的MHE性能，但这些模型如何预测以及预测的准确性仍不清楚。因此，本研究探讨了仅在合成数据上训练的最先进的MHE模型，研究模型在做高程预测时是如何工作的。研究发现，模型高度依赖于阴影线索，这可能导致高度估计的偏差。另外，人类难以评估回归任务的局限性也加剧了使用纯粹合成数据训练的问题。", "innovation": "提出了一种新的校正管道，将稀疏的全球LiDAR测量数据（ICESat-2）与深度学习输出结合，以提高局部精度并实现空间一致性校正。这种方法包括两个阶段：首先预处理原始ICESat-2数据，然后使用随机森林方法对高度估计进行密集修正。实验结果表明，该方法在三个代表性的城市地区（圣奥梅尔、东京和圣保罗）大幅降低了误差，平均绝对误差（MAE）分别减少了22.8%，6.9%和4.9%。这一发现强调了合成数据驱动模型中影子意识的重要性，并展示了如何融合不完美的现实世界LiDAR数据以增强MHE的可靠性，为更可靠和可扩展的3D映射解决方案铺平了道路。", "conclusion": "这项研究揭示了合成数据驱动模型中的阴影意识的关键作用，并展示了如何通过使用不完美的现实世界LiDAR数据来增强MHE的可靠性，从而为可靠的3D测绘解决方案提供支持。"}
{"llm_update_time": "20251006", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2505.20655", "html_url": "https://arxiv.org/abs/2505.20655", "title": "摄影视角构图：迈向美观视角推荐", "title_en": "Photography Perspective Composition: Towards Aesthetic Perspective Recommendation", "authors": "Lujian Yao,Siming Zheng,Xinbin Yuan,Zhuoxuan Cai,Pu Wu,Jinwei Chen,Bo Li,Peng-Tao Jiang", "background": "传统的摄影构图方法主要依赖于2D裁剪技术，但在处理复杂场景时，这些方法往往无法达到理想的构图效果。专业的摄影师会通过视角调整来实现3D重组，这种调整可以在保持实际空间位置不变的情况下，调整二维投影间的关系，从而达到更好的构图平衡。", "innovation": "本文提出了摄影视角构图（PPC），超越了传统的裁剪方法，并在此基础上做出三项重要贡献：（1）开发一个自动化框架，利用专家拍摄的照片构建PPC数据集；（2）提出了一种视频生成方法，展示从不佳视角到美学增强视角的转换过程；（3）构建了一个基于人类绩效的视角质量评估（PQA）模型。", "conclusion": "本文的方法简洁高效，不需要额外的提示指令或相机轨迹，能够引导普通用户提升构图技巧，同时解决了视角变换数据集稀缺和视角质量评估标准未明的问题。"}
{"llm_update_time": "20251006", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2505.18660", "html_url": "https://arxiv.org/abs/2505.18660", "title": "So-Fake：社会化媒体图像伪造检测的标准与解释", "title_en": "So-Fake: Benchmarking and Explaining Social Media Image Forgery Detection", "authors": "Zhenglin Huang,Tianxiao Li,Xiangtai Li,Haiquan Wen,Yiwei He,Jiangning Zhang,Hao Fei,Xi Yang,Xiaowei Huang,Bei Peng,Guangliang Cheng", "background": "人工智能驱动的生成模型在制备越来越逼真的合成图像方面取得了进展，这在社交媒体平台上传播信息完整性以及公众信任方面带来了显著风险。尽管现有的鲁棒检测框架和多样化的大型数据集对于减轻这些风险是必不可少的，但当前的研究努力在范围方面仍然有限。现有数据集缺乏社交媒体背景所需的多样性和真实性，现有的检测方法在识别未见过的生成技术方面也显得力有未逮。为了解决这些问题，本研究引入了一个名为So-Fake-Set的综合社交媒体数据集，其中包含超过200万高质量图像，多种生成源以及通过35个最先进的生成模型合成的高逼真度图像，还建立了一个新的大规模（100K）离域基准（So-Fake-OOD），用于严格评估跨域鲁棒性。", "innovation": "本研究创新地提出了一种社交媒体数据集So-Fake-Set，该数据集包含高质量图像、多样化生成源和高逼真度图像，这些是由35个最先进的生成模型合成的。此外，研究还建立了So-Fake-OOD离域基准，用于评估合成图像在真实环境中的表现。该研究还提出了So-Fake-R1，一种使用强化学习进行高精度伪造检测、精确定位和可解释推理的先进视觉语言框架。实验结果表明，So-Fake-R1在伪造检测准确性上比第二好的方法高了1.3%，在定位IoU上提高了4.5%。", "conclusion": "通过整合可扩展的数据集、具有挑战性的离域基准和先进的检测框架，这项工作为社交媒体中心的伪造检测研究奠定了新的基础。该研究的代码、模型和数据集将被公开发布。"}
{"llm_update_time": "20251006", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.02792", "html_url": "https://arxiv.org/abs/2507.02792", "title": "RichControl: 结构丰富和外观丰富的无训练空间控制用于文本到图像生成", "title_en": "RichControl: Structure- and Appearance-Rich Training-Free Spatial Control for Text-to-Image Generation", "authors": "Liheng Zhang,Lexi Pang,Hang Ye,Xiaoxuan Ma,Yizhou Wang", "background": "文本到图像（T2I）扩散模型在从文本提示生成高质量图像方面表现出色。最近的研究尝试将这些模型扩展以整合条件图像（例如，边缘检测），从而实现精细的空间控制。这些方法中，特征注入方法作为无训练替代传统的微调方法出现了，但它们通常会遇到结构错位、条件泄漏和视觉伪影的问题，特别是在条件图像与自然RGB分布有显著差异时。", "innovation": "本文通过分析现有方法，发现特征抽样时间表是未被探索的关键限制。因此，作者提出了一个灵活的无训练框架，使特征抽样时间表与去噪过程解耦，并系统地研究了特征注入时间表的范围，以提高特征空间中的结构指导质量。方法包括单一时间步骤抽样的简单高效时间表，以及通过引入重启精炼时间表和使用外观丰富的提示策略来提升图像质量。这些设计使得无训练生成既结构丰富又外观丰富。", "conclusion": "广泛实验表明，该方法在多种零样本条件场景中达到了最佳结果。"}
{"llm_update_time": "20251006", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.02790", "html_url": "https://arxiv.org/abs/2507.02790", "title": "从长视频到引人入胜的片段：具有多模态叙事理解的人类启发式视频编辑框架", "title_en": "From Long Videos to Engaging Clips: A Human-Inspired Video Editing Framework with Multimodal Narrative Understanding", "authors": "Xiangfeng Wang,Xiao Li,Yadong Wei,Xueyu Song,Yang Song,Xiaoqiang Xia,Fangrui Zeng,Zaiyi Chen,Liu Liu,Gu Xu,Tong Xu", "background": "在线视频内容，尤其是短视频平台上的内容快速增加，对高效视频编辑技术的需求也在增长，需要将长视频凝练为简洁且引人入胜的短视频片段。现有自动编辑方法主要依赖自动语音识别转录的文本提示和端到端的片段选择，但往往会忽略丰富的视觉上下文，导致输出不连贯。", "innovation": "本文提出了一种借鉴人类经验的自动视频编辑框架（HIVE），它利用多模态叙事理解来解决现有方法的局限性。该方法通过多模态大型语言模型进行人物提取、对话分析和叙事总结，实现对视频内容的全面理解。为了进一步提高连贯性，该方法采用场景级分割，并将编辑过程分解为三个子任务：亮点检测、开场/结尾选择和无关内容的修剪。", "conclusion": "实验结果显示，本文框架在一般视频编辑任务和广告视频编辑任务中均优于现有基线模型，显著缩小了自动编辑视频与人工编辑视频的质量差距。为促进该领域研究，提出了一个新的基准数据集DramaAD，包含800多个短剧编辑集和500多个专业广告剪辑。"}
{"llm_update_time": "20251006", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2506.04996", "html_url": "https://arxiv.org/abs/2506.04996", "title": "PATS: 专业知识导向的时间采样在多视角体育技能评估中的应用", "title_en": "PATS: Proficiency-Aware Temporal Sampling for Multi-View Sports Skill Assessment", "authors": "Edoardo Bianchi,Antonio Liotta", "background": "自动化的体育技能评估需要捕捉专家与新手在基本运动模式上的区别，然而当前的视频采样方法破坏了用于评估精熟度所需的连续时间序列。这一问题促使研究者提出了一种新的采样策略——专业知识导向的时间采样（PATS），旨在保留连续时间片段中的完整基本运动，用于多视角技能评估。PATS自适应地分割视频，确保每个被分析的部分包含关键表现组件的完整执行，并在多个片段中重复此过程，以最大化信息覆盖率，同时保持时间连贯性。", "innovation": "PATS是一种新颖的时间采样策略，通过自适应地分割视频，确保每个分析的部分都包含完整关键表现组件的执行。该策略通过SkillFormer在EgoExo4D基准测试中不仅超越了当前的先进技术，还在多种领域实现了显著的进步，尤其是在攀岩、音乐、篮球等挑战性领域。该策略展示了其作为一种自适应时间采样方法的有效性，推动了对现实世界应用中的自动化技能评估的进步。", "conclusion": "系统分析表明，PATS能够针对不同的活动特性进行自适应调整，从动态体育需要高频采样到连续技能需要细致的分割，证明了其作为一种自适应时间采样策略的有效性，并预先推进了日常生活中的自动化技能评估。"}
{"llm_update_time": "20251006", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.09459", "html_url": "https://arxiv.org/abs/2508.09459", "title": "RelayFormer: 一种用于可扩展图像和视频篡改定位的统一局部-全局注意力框架", "title_en": "RelayFormer: A Unified Local-Global Attention Framework for Scalable Image and Video Manipulation Localization", "authors": "Wen Huang,Jiarui Yang,Tao Dai,Jiawei Li,Shaoxiong Zhan,Bin Wang,Shu-Tao Xia", "background": "视觉篡改定位（VML）旨在识别图像和视频中的篡改区域，这一任务由于高级编辑工具的出现变得越来越具有挑战性。现有的方法面临两个主要问题：分辨率多样性，导致插值或填充扭曲了法医痕迹，降低了效率；以及模态差距，因为图像和视频通常需要单独的模型。", "innovation": "我们提出了RelayFormer，这是一种统一框架，可以适应不同分辨率和模态。RelayFormer将输入划分为固定大小的子图像，并引入全局-局部递送（GLR）令牌，通过全局-局部递送注意力（GLRA）机制传播结构化的上下文。这使得全局线索（如语义或时序一致性）的高效交换成为可能，同时保留了精细的篡改特征。与依赖均匀缩放或稀疏注意力的先前方法相比，RelayFormer自然适用于任意分辨率和视频序列，而不会增加过多的开销。", "conclusion": "RelayFormer在各种基准上展示了卓越的表现，其性能达到了最先进的技术水平，并具有显著的效率。RelayFormer结合了分辨率适应性（无需插值或过度填充），统一模型化图像和视频，以及准确性与计算成本之间良好的平衡。源代码可在提供。"}
{"llm_update_time": "20251006", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.12784", "html_url": "https://arxiv.org/abs/2509.12784", "title": "Contextualized Representation Learning for Effective Human-Object Interaction Detection", "title_en": "Contextualized Representation Learning for Effective Human-Object Interaction Detection", "authors": "Zhehao Li,Yucheng Qian,Chong Wang,Yinghao Lu,Zhihao Yang,Jiafei Wu", "background": "人类与物体交互（HOI）检测旨在同时定位人类-物体对并识别它们的交互。尽管最近的两级方法取得了显著进展，但它们仍然面临着不完整语境建模的挑战。这项工作中，作者引入了一种上下文化的表示学习方法，该方法结合了功能引导的推理和上下文提示与视觉线索，以更好地捕捉复杂的交互。", "innovation": "通过扩展传统的HOI检测框架，将简单的人类-物体对扩展到包括工具等辅助实体在内的多变量关系。具体而言，作者通过三元组结构<人类,工具,物体>明确建模这些辅助对象的功能作用（功能）。此外，学习提示框被实例类别增强，并且与上下文视觉特征使用注意机制集成，实现语言与图像内容在全局和局部层面的对齐。这些上下文化的表示为模型提供了更丰富的关系线索，以进行更可靠的复杂情境相关交互的推理。", "conclusion": "所提出的方法在HICO-Det和V-COCO数据集上在多数场景下表现出更好的性能。源代码可在该链接：this https URL 获得。"}
{"llm_update_time": "20251006", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.15573", "html_url": "https://arxiv.org/abs/2509.15573", "title": "迈向大小不变的显著物体检测：一种通用的评估和优化方法", "title_en": "Towards Size-invariant Salient Object Detection: A Generic Evaluation and Optimization Approach", "authors": "Shilong Bao,Qianqian Xu,Feiran Li,Boyu Han,Zhiyong Yang,Xiaochun Cao,Qingming Huang", "background": "本文探讨了显著物体检测（SOD）中一个基本但尚未充分探索的问题，即在单一图像中同时出现多个显著不同大小的显著物体时，评价协议的大小不变性特征。现有广泛应用的SOD评价指标本质上对大小十分敏感，预测误差主要由大区域主导，容易忽视小而可能更具语义重要性的物体，导致性能评估出现偏差和实际效果的下降。", "innovation": "本文提出了一个大小不变的评价框架（SIEva），通过独立评估每个分离组件并综合结果，有效缓解了对象间大小不平衡的影响。进一步开发了一种遵循大小不变原则的专门优化框架（SIOpt），显著提高了对不同大小显著物体的检测能力，且该框架具有通用性，可与多种SOD骨干网络无缝集成。", "conclusion": "通过理论分析和实验证明，所提出的方法能够在多种大小的显著物体检测中提供有效评估和优化。结果表明，该方法不仅提高了SOD性能评估的准确性，还具有实际应用价值。相关代码已公开。"}
{"llm_update_time": "20251006", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.17650", "html_url": "https://arxiv.org/abs/2509.17650", "title": "Evict3R: 无需训练的推理时_token_驱逐策略以实现内存限制下的流式视觉几何_变换器_", "title_en": "Evict3R: Training-Free Token Eviction for Memory-Bounded Streaming Visual Geometry Transformers", "authors": "Soroush Mahdi,Fardin Ayar,Ehsan Javanmardi,Manabu Tsukada,Mahdi Javanmardi", "background": "流式视觉变压器如StreamVGGT在实现强大的3D感知方面表现出色，但由于键值（KV）内存的无界增长，其可扩展性受到限制。", "innovation": "提出了一个无需训练的推理时token驱逐策略，该策略通过在保持最有用的token的同时抛弃冗余token来限制内存。实验结果表明，该方法使用更少的内存量，并且几乎不会导致准确性下降。", "conclusion": "在严格内存预算下，驱逐策略允许更密集的帧采样，从而提高重建准确性。该研究方法在视频深度估计、3D重建和相机姿态估计等多个任务中，以较小的内存成本接近StreamVGGT的表现，使得长视窗流式推理更加实用。"}
{"llm_update_time": "20251006", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.05116", "html_url": "https://arxiv.org/abs/2507.05116", "title": "VOTE: 视觉-语言-动作优化与轨迹投票集成", "title_en": "VOTE: Vision-Language-Action Optimization with Trajectory Ensemble Voting", "authors": "Juyi Lin,Amir Taherin,Arash Akbari,Arman Akbari,Lei Lu,Guangyu Chen,Taskin Padir,Xiaomeng Yang,Weiwei Chen,Yiqian Li,Xue Lin,David Kaeli,Pu Zhao,Yanzhi Wang", "background": "近年来，大规模的视觉-语言-动作（VLA）模型在由自然语言指导的机器人操作任务中表现出色。然而，当前的VLA模型存在两大缺点：（i）生成大量标记导致推理延迟高和增加训练成本；（ii）生成动作的利用不足，导致潜在的性能损失。", "innovation": "为了应对上述问题，该研究开发了一个训练框架来微调VLA模型，以生成显著减少的行动标记，并具有高效的并行性。此外，引入了一种新型投票集成策略的推理优化技术，将当前和先前的行动预测结合起来，提高了生成动作的利用效率和整体性能。实验结果表明，与最先进的VLA模型相比，该方法取得了更好的性能，成功率更高，相比于OpenVLA，在边缘平台上实现了39倍更快的推理速度，达到46Hz的吞吐量，证明其实用性。", "conclusion": "我们展示了该方法在实际部署方面的有效性，给出了显著的性能提升和高效的推理速度，证实了视觉-语言-动作优化与轨迹投票集成在机器人操作任务中的实际应用潜力。"}
{"llm_update_time": "20251006", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.25659", "html_url": "https://arxiv.org/abs/2509.25659", "title": "基于YOLO的金属板缺陷检测", "title_en": "YOLO-Based Defect Detection for Metal Sheets", "authors": "Po-Heng Chou,Chun-Chi Wang,Wei-Lung Mao", "background": "在工业制造领域，自动缺陷检测任务耗时且劳动密集，而当前缺乏金属板图片数据严重影响了检测精度。", "innovation": "提出了一种基于YOLO的深度学习模型，结合ConSinGAN进行数据增强，通过YOV9模型实现了91.3%的检测准确率和146ms的检测时间，成功应用于工业制造的自动化光学检测系统中。", "conclusion": "本文提出的基于YOLOv9和ConSinGAN的模型提高了缺陷检测的精度和效率，并成功应用于工业制造的自动化光学检测系统中，该方法也容易扩展到其他工业制造部件的缺陷检测中。"}
{"llm_update_time": "20251006", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2506.12723", "html_url": "https://arxiv.org/abs/2506.12723", "title": "SP-VLA: 一种用于VLA模型加速的联合模型调度和标记剪枝方法", "title_en": "SP-VLA: A Joint Model Scheduling and Token Pruning Approach for VLA Model Acceleration", "authors": "Ye Li,Yuan Meng,Zewen Sun,Kangye Ji,Chen Tang,Jiajun Fan,Xinzhu Ma,Shutao Xia,Zhi Wang,Wenwu Zhu", "background": "视觉-语言-动作（VLA）模型因其强大的控制能力受到了广泛关注。然而，这些模型的高计算成本和低执行频率限制了它们在诸如机器人操作和自主导航等实时任务中的适用性。现有的VLA加速方法主要集中在架构优化上，忽略了这些模型是在顺序决策环境中运行的事实。因此，顺序动作生成中的时间冗余和视觉输入中的空间冗余仍未得到解决。", "innovation": "本文提出了一种联合模型调度和标记剪枝的框架SP-VLA，通过同时对模型进行调度和标记进行剪枝来加速VLA模型。具体而言，设计了一个了解动策略的模型调度机制，通过动态切换VLA模型和轻量级生成器来减少时间冗余。进一步开发了一种空间语义双重意识标记剪枝方法，根据其双重重要性对标记进行分类并进行剪枝，以加速VLA推理。这两个机制共同引导VLA关注关键动作和显着的视觉信息，实现有效的加速，同时保持高精度。", "conclusion": "大量的实验证明，本文的方法在LIBERO中实现了1.5倍无损加速，在SimpplerEnv中实现了2.4倍加速，平均性能提高了6%。推理频率和延迟分别在SimpplerEnv和LIBERO中提高了2.2倍和1.4倍。"}
{"llm_update_time": "20251006", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.24758", "html_url": "https://arxiv.org/abs/2509.24758", "title": "ExGS：利用扩散先验的极端3D高斯压缩", "title_en": "ExGS: Extreme 3D Gaussian Compression with Diffusion Priors", "authors": "Jiaqi Chen,Xinhao Ji,Yuanyuan Gao,Hao Li,Yuning Gong,Yifei Liu,Dan Xu,Zhihang Zhong,Dingwen Zhang,Xiao Sun", "background": "神经场景表示方法，如3D高斯点渲染(3DGS)，能够以高质量的方式进行神经渲染，但占用大量存储和传输资源，限制了在资源受限环境中的部署。现有的压缩方法要么依赖复杂的优化，但这会降低速度并使方法场景特定，要么采用无需训练的剪枝和量化，但在高压缩率下会降低渲染质量。最近的数据驱动方法为克服这一权衡提供了新的方法，寻求在保持高渲染质量的同时提高压缩效率。", "innovation": "本文提出了ExGS，这是一个新颖的前馈框架，该框架结合了通用高斯压缩（UGC）和GaussPainter进行极端3DGS压缩。UGC通过不进行重优化的剪枝方法减少高斯原语的数量，同时保留必要的信息。GaussPainter利用了强大的扩散先验并在掩码引导下的细化，用以从高度剪枝的高斯场景中恢复高质量的渲染。这种技术在保持重构质量和现实性的同时，还可以在压缩率超过100倍的情况下实现近乎实时的重构。", "conclusion": "本文提出的ExGS框架在保持高保真度和显著提高图像质量的同时，有效地实现了对3D高斯模型超过100倍的压缩。扩散先验在极端压缩与高质量神经渲染之间的鸿沟中起到了关键作用。源代码可在这里下载：[提供链接]"}
{"llm_update_time": "20251006", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.20088", "html_url": "https://arxiv.org/abs/2508.20088", "title": "AudioStory: 使用大型语言模型生成长格式叙事性音频", "title_en": "AudioStory: Generating Long-Form Narrative Audio with Large Language Models", "authors": "Yuxin Guo,Teng Wang,Yuying Ge,Shijie Ma,Yixiao Ge,Wei Zou,Ying Shan", "background": "近期的文本到音频(TTA)生成技术在合成短音频片段方面表现出色，但在生成长篇叙述性音频内容时却存在困难，这需要时间连贯性和综合推理能力。", "innovation": "提出了一种名为AudioStory的统一框架，将大型语言模型（LLMs）与TTA系统相结合，以生成结构化、长格式的音频叙事。AudioStory具备强大的指令遵循推理生成能力，利用LLMs将复杂的叙述查询分解为按时间顺序排列的子任务，从而实现场景过渡的连贯性和情感基调的一致性。AudioStory有两个值得注意的特点：(1) 解耦的桥梁机制：解耦LLM-扩散器合作的两大特化组件，即用于事件内语义对齐的桥梁查询和用于跨事件协调保留的残差查询。(2) 一体化端到端训练：将指令理解和音频生成统一在一个端到端框架中，消除了模块化训练管道的需要，同时增强了组件之间的协同效应。", "conclusion": "We establish a benchmark AudioStory-10K，涵盖了动画音景和自然音效叙述等多种领域。大量实验表明，AudioStory在单音频生成和叙述音频生成方面都优于先前的TTA基线，具有更强的指令遵循能力和更高的音频保真度。我们的代码可在以下链接获得：this https URL"}
{"llm_update_time": "20251006", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.00060", "html_url": "https://arxiv.org/abs/2510.00060", "title": "减少则更好：简洁而强大的视觉语言模型用于自动驾驶", "title_en": "Less is More: Lean yet Powerful Vision-Language Model for Autonomous Driving", "authors": "Sheng Yang,Tong Zhan,Guancheng Chen,Yanfeng Lu,Jian Wang", "background": "自动驾驶在过去的研究中一直是一个复杂的挑战。传统的方法往往依赖于复杂的传感器融合和多阶段的预测，这使得实施和解释困难。本文将自动驾驶重新构想为通用语言任务，并将轨迹规划任务归结为预测下一目标点。该方法利用了视觉语言模型（VLM）的生成能力，直接从前视摄像头输入进行端到端的轨迹预测。", "innovation": "本文提出了Max-V1，一种基于视觉语言模型的一阶段端到端自动驾驶的新框架。它采用了一次通过生成的方法，符合自动驾驶的固有序列性。该方法通过统计建模的原则性监督策略，为复杂的驾驶策略提供了明确的学习目标，使模型可以通过大规模专家示范进行模仿学习。实验结果显示，该方法在nuScenes数据集上的性能达到最先进水平，与之前的基线相比提高了超过30%的整体性能。此外，该方法在跨域数据集上的性能也表现出色，展示了在不同车辆上的鲁棒性和适应性。", "conclusion": "通过实验证明了该方法的有效性，该工作提供了一个能够掌握基本驾驶行为的模型，为开发更强大的自动驾驶代理奠定了基础。相关代码将在发表后提供。"}
{"llm_update_time": "20251006", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.01339", "html_url": "https://arxiv.org/abs/2508.01339", "title": "SBP-YOLO：一种针对智能车辆悬挂系统的轻量级实时速度凸起和坑洞检测模型", "title_en": "SBP-YOLO:A Lightweight Real-Time Model for Detecting Speed Bumps and Potholes toward Intelligent Vehicle Suspension Systems", "authors": "Chuanqi Liang,Jie Fu,Miao Yu,Lei Luo", "background": "道路中的减速带和坑洞是影响乘车舒适度和车辆稳定性的常见因素。基于预视的悬挂控制系统通过提前检测这些不规则性并主动调整悬挂参数，来减轻其影响。然而，精确且实时的检测依赖于有限的计算资源和嵌入式系统的尺寸限制，特别是在输入目标较小时。本文针对这些挑战，提出了一种实时检测框架SBP-YOLO，专门用于嵌入式系统中的速度凸起和坑洞检测，以提高智能车辆悬挂控制系统的性能。", "innovation": "提出了SBP-YOLO，一个基于YOLOv1并融合了GhostConv、VoVGSCSPC模块的高效检测框架。该框架通过减小计算量同时增强多尺度语义特征来提高检测规模，通过P2级分支优化小型目标的检测，并使用轻量且高效的检测头（LEDH）来保持精度并减少开销。混合训练策略结合了NWD损失、BCKD知识蒸馏和基于Albumentations的数据增强，进一步提升模型在各种道路和环境条件下的鲁棒性。实验结果显示，SBP-YOLO 指标达到了87.0%的mAP，比YOLOv11n基线提高了5.8%。使用TensorRT FP16量化后，在Jetson AGX Xavier上以139.5 FPS运行，相比P2增强的YOLOv11提升了12.4%的速度。这些结果表明，该框架适用于嵌入式悬挂控制系统的快速、低延迟道路条件感知。", "conclusion": "SBP-YOLO框架因其高效的实现实时检测的性能，证明了其在嵌入式悬挂控制系统的适用性，为智能车辆悬架控制提供了有力支持。"}
{"llm_update_time": "20251006", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.12990", "html_url": "https://arxiv.org/abs/2509.12990", "title": "双阶段加权MoE长尾第一人称错误检测", "title_en": "Dual-Stage Reweighted MoE for Long-Tailed Egocentric Mistake Detection", "authors": "Boyu Han,Qianqian Xu,Shilong Bao,Zhiyong Yang,Sicong Li,Qingming Huang", "background": "本研究旨在从第一人称视角视频数据中识别用户执行动作时的错误。由于细微且不常见的错误难以捕捉，研究面临挑战。为了克服这些挑战，研究提出了一种双阶段加权混合专家（DR-MoE）框架。第一阶段使用固定和微调后的ViViT模型提取特征，并通过特征级专家模块结合。第二阶段针对不同目标训练三种分类器，以优化排序、增强校准和泛化能力。", "innovation": "提出了一种双阶段加权混合专家（DR-MoE）框架，分别在特征级和分类级结合了不同的专家模块，用于从第一人称视角视频数据中检测细微且不常见的错误。在此基础上，多种损失函数被引入以解决类别不平衡、长尾分布以及校准和泛化等问题，并实现了有效的错误识别结果。", "conclusion": "所提出的方法在识别罕见且模棱两可的错误实例方面表现出色。代码可在指定的URL处获取。"}
{"llm_update_time": "20251006", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.23899", "html_url": "https://arxiv.org/abs/2509.23899", "title": "Q-FSRU: Quantum-Augmented Frequency-Spectral For Medical Visual Question Answering", "title_en": "Q-FSRU: Quantum-Augmented Frequency-Spectral For Medical Visual Question Answering", "authors": "Rakesh Thakur,Yusra Tariq,Rakesh Chandra Joshi", "background": "在健康医疗的人工智能领域，解决需要同时理解图像和文本的复杂临床问题是主要挑战之一。现有的模型在处理这类问题时存在局限性，如噪声和冗余信息的过滤效果不理想，以及在处理复杂病例（需要图像文本推理）时的准确性不高。", "innovation": "本文提出了一种新的模型Q-FSRU，结合了频谱表示与融合（FSRU）和量子检索增强生成（Quantum RAG）方法，用于医疗视觉问答（VQA）。通过将医疗图像的特征和相关文本转换到频域，帮助模型聚焦于更有意义的数据，并过滤掉噪声或不相关信息。进一步引入一个基于量子的检索系统，以增强准确性并确保答案基于真实知识。最后，将频率信息与量子信息融合以改善分析和解释能力。", "conclusion": "通过使用VQA-RAD数据集评估Q-FSRU，结果表明其在处理需要图像文本推理的复杂病例时优于早期模型。该方法提供了一种构建更智能、更清晰、更有帮助的医疗AI工具的有前途的方法。"}
{"llm_update_time": "20251006", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2503.05398", "html_url": "https://arxiv.org/abs/2503.05398", "title": "使用articulated 3D高斯散射学习高保真机器人自我模型", "title_en": "Learning High-Fidelity Robot Self-Model with Articulated 3D Gaussian Splatting", "authors": "Kejun Hu,Peng Yu,Ning Tan", "background": "现有的自建模方法存在建模质量低或数据采集成本高的问题。现有的研究主要集中在构建机器人的形态和运动学模型上，但没有充分考虑到纹理这一关键因素，而且这方面的研究尚未得到充分的探索。", "innovation": "提出了一种高保真、纹理感知且基于链接的方法来进行机器人自建模。该方法使用3D高斯分布代表机器人的静态形态和纹理，并通过神经动力学网络生成的变换矩阵来控制神经椭球骨骼的变形。模型是通过结合关节角度、相机参数和多视角图像（不包含深度信息）的数据对进行训练的。该方法可以生成不同视角的机器人图像，并且能够用于下游任务，如运动规划和逆运动学。", "conclusion": "本文提出的方法能够有效提高机器人的自建模质量，并且能够在纹理感知和链接级别上提供精确的形态、运动学和纹理描述。同时，该模型也可以用于实现运动规划和逆运动学等下游任务。"}
{"llm_update_time": "20251006", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.00929", "html_url": "https://arxiv.org/abs/2510.00929", "title": "对称分裂：从不完整数据中进行自我监督学习", "title_en": "Equivariant Splitting: Self-supervised learning from incomplete data", "authors": "Victor Sechaud,Jérémy Scanvic,Quentin Barthélemy,Patrice Abry,Julián Tachella", "background": "自监督学习方法可以训练重建网络来自噪声和/或不完整数据，这些方法在获取训练数据的真实参考时成本高昂甚至不可能实现时具有潜在的应用价值。本文关注通过单一不完整的观测模型获取测量值的具有挑战性的场景。", "innovation": "提出了一个新的自监督学习策略，适用于仅通过单一不完整观测模型获取测量值的挑战性设置。引入了重建网络中的对称分裂等新概念，通过结合自监督分裂损失和对称重建网络，证明了所得损失的期望最小化结果与监督损失的最小化结果相同。通过图像修复、加速磁共振成像、压缩感知等一系列实验，展示了所提损失在高度亏秩前向模型设置下达到了最新的性能标准。", "conclusion": "通过一系列实验，展示了所提出的损失在图像修复、加速磁共振成像、压缩感知等高亏秩前向模型设置下达到了最先进的性能。"}
{"llm_update_time": "20251006", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.03277", "html_url": "https://arxiv.org/abs/2509.03277", "title": "PointAD+: 学习层次表示以实现零样本3D异常检测", "title_en": "PointAD+: Learning Hierarchical Representations for Zero-shot 3D Anomaly Detection", "authors": "Qihang Zhou,Shibo He,Jiangtao Yan,Wenchao Meng,Jiming Chen", "background": "本文旨在将CLIP的强健的二维泛化能力应用于识别未见过的、高度类别语义多样的3D异常。研究通过设计一种统一框架，利用点级和像素级信息的综合检测和分割3D异常。PointAD利用点-像素对应关系表征3D异常，这是一种隐式的3D表示方式，主要关注渲染像素异常，忽视点云内部的空间关系。PointAD+进一步引入显式的3D表示，强调空间异常，以揭示异常的空间关系，并利用几何聚合使点表示更具空间意识。PointAD+提出分层表示学习，结合显式的特征，并通过交错层次对比对齐促进渲染和几何层间的互动，实现全面理解异常性的能力。在测试过程中，PointAD+可以整合RGB信息以增强检测性能，证明其实现在未见过的、类别语义高度多样的3D异常检测上的优越性。", "innovation": "点AD（PointAD）和点AD加（PointAD+）两大模块的技术创新点在于：PointAD通过点-像素对应关系建立隐式的3D异常表示；PointAD+引入显式的3D空间信息展示和几何聚合机制；通过层次表示学习和交错层次对比对齐，在同时捕捉渲染和空间异常性方面取得了突破。", "conclusion": "PointAD+通过整合渲染和几何层的异常语义，实现了对高度类别语义多样的3D未见过物体的广泛异常语义捕捉，在零样本3D异常检测方面展现出了卓越的性能。点AD+能够以插拔方式整合RGB信息，并进一步提升异常检测性能。广泛的实验表明，PointAD+在零样本3D异常检测中有显著优势，适用于未见过的、类别语义高度多样的3D异常检测任务，从而提供了一个全局的理解异常的能力。"}
{"llm_update_time": "20251006", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2503.11163", "html_url": "https://arxiv.org/abs/2503.11163", "title": "基于视觉的机器人抓取算法基准研究", "title_en": "A Benchmarking Study of Vision-based Robotic Grasping Algorithms", "authors": "Bharath K Rameshbabu,Sumukh S Balakrishna,Brian Flynn,Vinarak Kapoor,Adam Norton,Holly Yanco,Berk Calli", "background": "本文进行了一项基于视觉的机器人抓取算法的基准研究，并进行了比较分析。研究通过使用现有的基准测试协议，对比了两种基于机器学习的方法和两种分析学方法在不同实验条件下的表现。这些条件涵盖了光照、背景纹理、不同噪声水平的相机以及不同的夹爪类型。", "innovation": "研究通过系统性实验评估了不同抓取算法在多种条件下的表现，并通过模拟和实际机器人进行实验对比。重复在两所不同的实验室进行部分实验以进一步分析结果的可重复性。这项研究总计进行了5040次实验，为机器人操作中的系统性实验角色和挑战提供了重要的见解，并为新算法的开发提供了指导。", "conclusion": "本文的研究结果为基于视觉的机器人抓取算法提供了基准，强调了系统性实验的重要性，并指导了考虑可能影响性能因素的新算法开发。实验记录及基准测试软件均公开发布。"}
{"llm_update_time": "20251006", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.24798", "html_url": "https://arxiv.org/abs/2509.24798", "title": "Causal-Adapter: 控制忠实虚构生成的文字到图像扩散模型", "title_en": "Causal-Adapter: Taming Text-to-Image Diffusion for Faithful Counterfactual Generation", "authors": "Lei Tong,Zhihua Liu,Chaochao Lu,Dino Oglic,Tom Diethe,Philip Teare,Sotirios A. Tsaftaris,Chen Jin", "background": "该论文的背景是在使用文本到图像的扩散模型进行虚构图像生成时，现有方法往往依赖于提示工程，缺乏明确的因果结构。这导致了在进行属性操控时可能产生不精确或不忠实的结果。为了解决这一问题，本文提出了一种名为Causal-Adapter的模块化框架，该框架能够在保持图像核心身份不变的情况下，对目标属性进行因果干预，并且准确地传递这些干预的效果到其因果依赖项，从而使生成的图像更加忠实和可控。", "innovation": "Causal-Adapter的主要创新点在于它采用了结构因果模型，并与两种属性正则化策略相结合：提示对齐注入和条件标记对比损失。提示对齐注入策略将因果属性与文本嵌入对齐，以实现精准的语义控制；而条件标记对比损失策略则是用于分离属性因素，减少虚假相关性。这种组合使得Causal-Adapter能够在合成和真实世界数据集上都取得优异性能，在Pendulum数据集上绝对均方误差（MAE）降低了91%，在ADNI数据集上生成高保真MRI图像时弗吉尼亚联邦独立分维（FID）指数降低了87%。", "conclusion": "Causal-Adapter方法展示了在保持图像身份完整性的前提下，进行准确的属性修改和可靠的虚构编辑是完全可能的。这种方法不仅提高了图像生成的精确度和保真度，还证明了它具有强大的泛化能力和可靠性，为未来的图像生成和编辑任务提供了新的思路。"}
{"llm_update_time": "20251006", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.01669", "html_url": "https://arxiv.org/abs/2510.01669", "title": "UniVerse: Unleashing the Scene Prior of Video Diffusion Models for Robust Radiance Field Reconstruction", "title_en": "UniVerse: Unleashing the Scene Prior of Video Diffusion Models for Robust Radiance Field Reconstruction", "authors": "Jin Cao,Hongrui Wu,Ziyong Feng,Hujun Bao,Xiaowei Zhou,Sida Peng", "background": "该研究聚焦于鲁棒重建挑战，即从一组不一致的多视角图像中重建3D场景。近年来，一些研究尝试通过将图像退化建模集成到神经3D场景表示中同时解决图像不一致和重建问题，但这些方法依赖于密集的观察结果来进行鲁棒的模型参数优化。因此，这些方法在处理不一致的图像时面临着鲁棒性不足的问题。", "innovation": "为此，该论文创新性地提出了将鲁棒重建分解为两个子任务：恢复和重建，从而简化优化过程。提出了UniVerse，一种基于视频扩散模型的统一框架。UniVerse首先将不一致的图像转化为初始视频，然后使用特别设计的视频扩散模型恢复为一致的图像，最后从这些恢复的图像中重建3D场景。与针对每个视角的退化建模不同，扩散模型从大规模数据中学习通用的场景先验，使其适用于各种图像不一致性。实验证明，该方法在鲁棒重建方面具有强大的泛化能力和优越的性能，同时UniVerse还能控制3D场景的重建风格。", "conclusion": "广泛的合成和真实世界数据集上的实验展示了该方法在鲁棒重建中的强大泛化能力和优越性能，表明UniVerse能够有效地处理图像不一致，并在3D场景重建中具有较高的鲁棒性。"}
{"llm_update_time": "20251006", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.01784", "html_url": "https://arxiv.org/abs/2510.01784", "title": "提高长视频生成的记忆与强制策略：时空一致的视频生成", "title_en": "Pack and Force Your Memory: Long-form and Consistent Video Generation", "authors": "Xiaofei Wu,Guozhen Zhang,Zhiyong Xu,Yuan Zhou,Qinglin Lu,Xuming He", "background": "长视频生成面临双重挑战：模型需要捕捉长距离依赖关系，同时防止自回归解码中的错误累积。为解决这些挑战，该研究提出了两项贡献。首先，为了动态上下文建模，提出了一种MemoryPack机制，该机制利用文本和图像信息作为全局指导，联合建模短期和长期依赖关系，实现了分钟级的时间一致性。这种设计能够优雅地扩展以适应视频长度，保持计算效率，且具有线性复杂度。其次，为减少错误累积，引入了一种高效的单步近似策略Direct Forcing，通过改善训练过程和推断过程的一致性，减少了推断过程中错误传播的范围。", "innovation": "提出了MemoryPack机制和Direct Forcing策略，分别解决了捕捉长距离依赖和减少错误累积的挑战。MemoryPack通过利用文本和图像信息作为全局指导，实现了分钟级的时间一致性，具备优秀的扩展性和计算效率。Direct Forcing作为一种高效的单步近似策略，提升了训练和推断的一致性，减少了推断过程中错误传播的问题。", "conclusion": "MemoryPack和Direct Forcing显著增强了长视频生成时上下文的连续性和可靠性，为自回归视频模型的应用带来了实质性进步。"}
{"llm_update_time": "20251006", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2411.02038", "html_url": "https://arxiv.org/abs/2411.02038", "title": "使用单层线性层解决向量量化模型中的表示坍缩问题", "title_en": "Addressing Representation Collapse in Vector Quantized Models with One Linear Layer", "authors": "Yongxin Zhu,Bocheng Li,Yifei Xin,Zhihua Xia,Linli Xu", "background": "向量量化（VQ）在无监督学习中用于离散化连续表示，但容易导致表示坍缩，造成码本利用率低下并限制了模型的可扩展性。现有解决方案往往依赖复杂的优化或降低潜在维度，这会牺牲模型性能并无法完全解决该问题。研究表明，问题根源在于码本的独立优化，仅通过梯度下降更新少量码矢量。", "innovation": "为了解决上述问题，我们提出了SimVQ，通过在潜在基的基础上使用可学习的线性变换层重新参数化码矢量，优化整个线性空间而不是最近的单独码矢量。尽管两个线性矩阵的乘法等效于应用一个单层线性变换，但其简单方法有效的防止了表示坍缩。广泛的图像和音频任务实验表明，SimVQ改进了码本使用率，易于实现，并且能够在不同模态和架构下泛化得很好。", "conclusion": "实验结果表明，SimVQ不仅改进了码本使用率，还简化了实现过程，并在不同模态和架构上具有良好的泛化能力。代码已公开提供。"}
{"llm_update_time": "20251006", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.01660", "html_url": "https://arxiv.org/abs/2510.01660", "title": "VirDA: 使用视觉重新编程重用主干网络的无监督领域自适应", "title_en": "VirDA: Reusing Backbone for Unsupervised Domain Adaptation with Visual Reprogramming", "authors": "Duy Nguyen,Dat Nguyen", "background": "现有的UDA管道在每次新的源-目标对出现时，都会微调已经训练好的主干参数，导致训练参数数量和存储内存呈线性增长，并且无法重用这些训练好的主干参数。此外，最近的研究表明现有的主干具有纹理偏见。", "innovation": "提出了一种名为VirDA的方法，通过视觉重新编程利用领域特定的纹理偏见进行领域适应。这种方法在微调整个主干网络时，前置一个领域特定的视觉重新编程层，生成视觉提示以适应目标域的“风格”。通过使用多种优化函数优化视觉重新编程层，使得无需修改主干参数，从而实现不同领域的重用。", "conclusion": "在Office-31数据集上，VirDA仅使用1.5M可训练参数就获得了92.8%的平均准确性。与参数高效UDA基准PDA相比，VirDA的准确率提高1.6%，只使用46%的参数。与完整的主干微调相比，VirDA在CDTrans和FixBi上分别提高0.2%和1.4%，所需可训练参数分别仅为1.7%和2.8%。与当前最强方法PMTrans和TVT相比，VirDA使用其参数的约1.7%，准确率分别损失2.2%和1.1%。"}
{"llm_update_time": "20251006", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2506.07998", "html_url": "https://arxiv.org/abs/2506.07998", "title": "权重生成建模：泛化还是记忆?", "title_en": "Generative Modeling of Weights: Generalization or Memorization?", "authors": "Boya Zeng,Yida Yin,Zhiqiu Xu,Zhuang Liu", "background": "近年来，生成模型被探索用于合成神经网络权重。这些方法将神经网络检查点作为训练数据，并旨在生成在推断期间表现出色的权重。本文探讨了四种代表性的、广为人知的方法，评估它们在生成全新模型权重方面的能力，这些权重与训练期间见过的检查点不同。与先前研究中的主张相反，研究发现这些方法主要通过记忆来合成权重：它们要么生成复制品，要么最多只是训练检查点的简单插值。此外，它们未能在获得不同且同时表现良好的模型方面超过简单的基线方法，例如向权重添加噪声或进行简单的权重组合。", "innovation": "研究进一步分析表明，这种记忆可能源自数据量有限、模型过度参数化以及对权重数据特有的结构先验的不足利用。这些发现强调了在应用到新领域时对生成模型需要有更细致的设计和严格的评估。", "conclusion": "我们的研究结果表明，生成模型在合成全新神经网络权重时主要依赖记忆，而不是泛化。为了更有效地生成具有新颖性的模型，需要更加小心地设计优化方法，并进行严格的评估。"}
{"llm_update_time": "20251006", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2501.11854", "html_url": "https://arxiv.org/abs/2501.11854", "title": "WaveNet-SF：基于时空频域小波变换的混合网络眼底病检测", "title_en": "WaveNet-SF: A Hybrid Network for Retinal Disease Detection Based on Wavelet Transform in Spatial-Frequency Domain", "authors": "Jilan Cheng,Guoli Long,Zeyu Zhang,Zhenjia Qi,Hanyu Wang,Libin Lu,Shuihua Wang,Yudong Zhang,Jin Hong", "background": "视网膜疾病是导致视力受损和失明的主要原因之一，及时诊断对于有效治疗至关重要。光学相干断层扫描（OCT）已成为评估视网膜疾病的标准成像技术，但由于OCT图像中存在诸如散斑噪声、复杂的病灶形状和大小不一等问题，使得图像解读变得困难。", "innovation": "本文提出了一种新颖的框架——WaveNet-SF，通过结合频域和时域学习来增强视网膜疾病的检测。WaveNet-SF 使用小波变换将 OCT 图像分解为低频和高频部分，从而能够提取全局结构特征和细粒度细节。为了提高病灶检测效果，引入了多尺度小波空间注意（MSW-SA）模块，提升了模型对多尺度感兴趣区域的关注。此外，还加入了一个高频特征补偿（HFFC）模块，用于恢复小波分解丢失的边缘信息、抑制噪声并保存对病灶检测至关重要的细微细节。", "conclusion": "WaveNet-SF 方法在 OCT-C8 和 OCT2017 数据集上分别达到了97.82% 和99.58% 的分类准确率，超越了现有方法，展示了WaveNet-SF在OCT图像分析中的有效性和作为视网膜疾病诊断工具的潜力。"}
{"llm_update_time": "20251006", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2502.18044", "html_url": "https://arxiv.org/abs/2502.18044", "title": "S-Graphs 2.0 -- 基于层次语义优化与闭环检测的SLAM", "title_en": "S-Graphs 2.0 -- A Hierarchical-Semantic Optimization and Loop Closure for SLAM", "authors": "Hriday Bavle,Jose Luis Sanchez-Lopez,Muhammad Shaheer,Javier Civera,Holger Voos", "background": "三维场景图的层次结构对表示具有高度相关性，因为它符合人造环境中常见的模式。此外，此类层次结构中的语义和几何信息可以用于加速地图元素和机器人姿态的优化和管理。现有的SLAM算法通常需要在多个楼层和不同环境中进行优化，导致计算效率低下，且容易出现误匹配闭环检测的问题。因此，研究团队提出了S-Graphs 2.0，通过利用室内场景的层次结构实现高效的数据管理和优化。", "innovation": "首先，在前端，团队开发了一种楼层检测模块，可以识别梯道并为底层设置语义关系，提出基于楼层的闭环策略，有效减少了由于不同楼层的同名障碍物引起的误闭环。其次，在优化阶段，团队利用层次结构提出了一种新的优化策略，包括：(1)在最近的关键帧及其连接组件上进行局部优化，(2)楼层级全局优化，重点关注当前楼层的关键帧及其连接以进行闭环检测，(3)房间级局部优化，通过排除同一房间内重复的关键帧以减少计算负载。这些策略显著提高了算法的效率和准确性。", "conclusion": "研究团队验证了S-Graphs 2.0算法在不同多层真实环境中的效果，显示其在大规模多层环境中的准确性达到了最先进的水平，平均比竞争基线快10倍以上的优化速度。"}
{"llm_update_time": "20251006", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.02593", "html_url": "https://arxiv.org/abs/2509.02593", "title": "使用YOLOv12进行稳健多癌种核分裂图检测", "title_en": "Robust Pan-Cancer Mitotic Figure Detection with YOLOv12", "authors": "Raphaël Bourgade,Guillaume Balezo,Thomas Walter", "background": "核分裂图是肿瘤病理学中的关键组织预后特征，提供了有关肿瘤侵袭性和增殖的重要见解。然而，其识别具有挑战性，即使是经验丰富的病理学家之间也存在显著的主观性差异。为了解决这个问题，MItosis DOmain Generalization (MIDOG) 2025 挑战是国际竞赛的第三次，旨在开发稳健的核分裂检测算法。尽管大部分研究依赖于现成的数据集，该方法依然没有依赖于外部数据。", "innovation": "该方法基于最先进的YOLOv12目标检测架构，这是一项创新点，因为它能够处理复杂和异质的全玻片图像，而且在最终测试排行榜上获得F1分数0.7216，取得了第二名的成绩。", "conclusion": "该研究提出了一种基于YOLOv12的核分裂图识别方法，并且该方法在没有依赖外部数据的情况下，在复杂和异质的全玻片图像的识别中取得了不错的成绩，F1分数达到了0.7216，显示出这种方法的有效性和稳健性。"}
{"llm_update_time": "20251006", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2505.01476", "html_url": "https://arxiv.org/abs/2505.01476", "title": "CostFilter-AD: 通过匹配成本过滤提升异常检测", "title_en": "CostFilter-AD: Enhancing Anomaly Detection through Matching Cost Filtering", "authors": "Zhe Zhang,Mingxiu Cai,Hanxiao Wang,Gaochang Wu,Tianyou Chai,Xiatian Zhu", "background": "无监督异常检测（UAD）旨在根据正样本定位输入图像中的异常掩码。现有方法主要依赖图像级或特征级匹配来生成异常得分，如通过重建正常对应样本（基于重建的方法）或学习图像特征嵌入空间（基于嵌入的方法）。但是，这种方法中的匹配过程往往不准确，但被忽略了，导致检测效果不佳。为了解决这一问题，该研究将经典匹配任务（如深度估计和流估计）中的成本过滤概念引入UAD问题，提出了一种称为CostFilter-AD的方法。", "innovation": "该研究提出了一种名为CostFilter-AD的方法，通过构建输入与正常样本之间的匹配成本体积，并设计一种基于输入观察的成本体积过滤网络来抑制匹配噪声，同时保留边缘结构并捕捉细微异常。此方法作为一种通用的后处理插件，可以与基于重建的方法或基于嵌入的方法结合使用。在MVTec-AD和VisA基准测试上进行了大量实验，结果验证了CostFilter-AD在单类和多类UAD任务中的通用优势。", "conclusion": "广泛的实验结果证明，CostFilter-AD对于单类和多类UAD任务都有通用优势，并且该方法作为一种通用的后处理插件，能够兼容重建基础的方法和嵌入基础的方法。该研究的代码和模型将在此网址发布：this https URL"}
{"llm_update_time": "20251006", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.01407", "html_url": "https://arxiv.org/abs/2510.01407", "title": "端到端神经压缩与重建中的超高效解码", "title_en": "Ultra-Efficient Decoding for End-to-End Neural Compression and Reconstruction", "authors": "Ethan G. Rogers,Cheng Wang", "background": "图像压缩和重建对于各种数字应用至关重要。虽然现代基于神经网络的压缩方法能够实现显著的压缩率，但由于解码过程中基于卷积的解码器的复杂性和巨大的计算成本，这种技术的应用受到很大限制。因此，需要找到一种新的方法来解决神经压缩中的解码瓶颈问题。", "innovation": "本研究提出了一种新的基于低秩表示的自编码器与向量量化相结合的新压缩-重建框架，能够高效地利用计算效率高的低秩运算重构高质量数据。该方法显著降低了神经压缩和重建解码阶段的计算开销，从而解决了解码计算瓶颈问题，同时保持了图像输出的高保真度。", "conclusion": "通过引入低秩表示并在自编码器中结合向量量化，该研究开发了一种新的高效神经压缩-重建框架，能够在保持图像高保真输出的同时，大幅降低解码阶段的计算开销，解决了神经压缩中的解码瓶颈问题。"}
{"llm_update_time": "20251006", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.02456", "html_url": "https://arxiv.org/abs/2510.02456", "title": "基于市场的数据子集选择——多标准样例效用的原理性聚合", "title_en": "Market-Based Data Subset Selection -- Principled Aggregation of Multi-Criteria Example Utility", "authors": "Ashish Jha,Valentin Leplat,AH Phan", "background": "选择少量但有用的训练数据集非常困难，因为样例效用信号（不确定性、稀有性、多样性等）是异质的，并通常使用经验权重进行结合。现有方法难以精确捕捉这些信号并在实际应用中表现不一。", "innovation": "提出了一种基于市场选择器，通过成本函数预测市场（LMSR）定价每个样例，信号作为交易者，单一流动参数控制集中度，并通过话题归一化稳定校准。引入了价格每令牌规则$\rho=p/\boldsymbol{\text{l}}^{\boldsymbol{\text{\textgamma}}}$，$\boldsymbol{\text{\textgamma}}$揭示长度偏向的可解释性；轻量级多样性头部改善了覆盖。通过主题簇覆盖和有效样本大小量化覆盖。在理论上，LMSR实现了最大熵聚合与指数加权和凸目标，提供了聚合强度的透明参数。实证结果表明，在GSM8K（60k-令牌预算）中，带多样性的市场与强单信号基线表现相当，同时减少种子方差并产生不到0.1 GPU-小时的选择开销；在AGNews数据集中，保留5-25%的情况下，市场（轻量级平衡）实现具有更好均衡性和稳定性的竞争力准确度。", "conclusion": "该框架统一了固定计算能力下的多标准数据集合，适用于提示级推理和分类。"}
{"llm_update_time": "20251006", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.02470", "html_url": "https://arxiv.org/abs/2510.02470", "title": "SAGE: 流式一致性驱动的梯度概要选择方法用于代表性子集选择", "title_en": "SAGE: Streaming Agreement-Driven Gradient Sketches for Representative Subset Selection", "authors": "Ashish Jha,Salman Ahmadi-Asl", "background": "在大型数据集上训练现代神经网络在计算和能源上都很密集。SAGE 是一种数据子集选择方法，它能够以 O(ℓD) 的内存维护一个紧凑的 Frequent Directions (FD) 梯度几何概要，并优先选择其草图梯度与共识方向对齐的示例。此方法消除了 N×N 两两相似性计算和显式的 N×ℓ 梯度存储，从而形成一个简单的两阶段、GPU 友好的流水线。", "innovation": "SAGE 方法使用 FD 的确定性近似保证，分析了如何一致评分保留主草图子空间中的梯度能量。通过这种方法，在多个基准测试中，SAGE 能在保留与全数据训练和最近的子集选择基线竞争的准确性的前提下，以较小的保持率预算训练，并减少整体计算时间和峰值内存。", "conclusion": "SAGE 提供了一种实际的、常数内存的替代方案，能够补充剪枝和模型压缩，以实现高效的训练。"}
{"llm_update_time": "20251006", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.02414", "html_url": "https://arxiv.org/abs/2510.02414", "title": "RainSeer：通过物理引导建模实现细粒度降雨重建", "title_en": "RainSeer: Fine-Grained Rainfall Reconstruction via Physics-Guided Modeling", "authors": "Lin Chen(1),Jun Chen(1),Minghui Qiu(1),Shuxin Zhong(1),Binghong Chen(2),Kaishun Wu(1) ((1) The Hong Kong University of Science and Technology (Guangzhou), (2) China Meteorological Administration)", "background": "高分辨率降雨场的重建对于洪水预报、水文建模和气候分析至关重要。然而，现有的空间插值方法往往在基于自动气象站（AWS）测量或者增强卫星/雷达观测的基础上过于平滑，无法捕捉到急剧变化和局部极端天气事件。", "innovation": "引入了RainSeer，这是一种结构感知的重建框架，重新解释雷达回波作为物理基础的结构先验，捕捉降雨发生的时间、地点及其模式。RainSeer采用一种基于物理的两阶段架构：结构到点映射者通过双向映射将中尺度雷达结构投影到局部地面降雨上，地理感知降雨解码器通过因果时空注意力机制捕捉高空水汽和地面降水之间的语义转换。实验表明，与最先进的基准方法相比，RainSeer在两个公开数据集上的表现更为优越，降低了MAE超过13.31%，并在重建的降雨场中显著增强了结构的保真度。", "conclusion": "RainSeer通过物理引导建模实现了细粒度降雨重建，在多个方面超越了现有的方法，特别是在结构保真度方面得到了显著的提高。"}
{"llm_update_time": "20251006", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.02453", "html_url": "https://arxiv.org/abs/2510.02453", "title": "训练你的指导者：使用顾问模型引导黑盒大模型", "title_en": "How to Train Your Advisor: Steering Black-Box LLMs with Advisor Models", "authors": "Parth Asawa,Alan Zhu,Matei Zaharia,Alexandros G. Dimakis,Joseph E. Gonzalez", "background": "随着基础模型被广泛部署为难以修改权重的黑盒服务，定制主要局限于提示优化。虽然静态提示优化显示出潜力，但生成的固定提示无法适应不同输入、用户或环境的变化。因此，研究者引入了顾问模型，这是一种通过强化学习训练的小型参数策略模型，可以在上下文中根据环境的奖励信号动态生成语言引导指令，帮助黑盒模型进行自我调整。", "innovation": "研究提出了一种轻量级的参数策略模型，即顾问模型，通过强化学习进行培训，可以生成自然语言的引导指令来调整黑盒模型的行为。顾问模型位于用户输入和模型之间，可以根据每次实例的具体情况进行适应性的行为塑造。实验结果显示，顾问模型在多个涉及推理和个人化任务的领域中表现优于静态提示优化器，不仅能够发现环境动态，还能提升下游任务性能。此外，顾问模型也展示了在不同黑盒模型之间的通用性，以及在保持鲁棒性的同时实现专业化的能力。", "conclusion": "顾问模型作为一种可学习的黑盒系统接口，为动态优化黑盒模型提供了可能，被视作实现个性化和环境适应性AI的一种前沿技术方向。"}
{"llm_update_time": "20251006", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.02407", "html_url": "https://arxiv.org/abs/2510.02407", "title": "使用基于相关性的数据增强方法和深度学习模型进行极值预报", "title_en": "Extreme value forecasting using relevance-based data augmentation with deep learning models", "authors": "Junru Hua,Rahul Ahluwalia,Rohitash Chandra", "background": "数据增强技术，尤其是生成式对抗网络（GANs），在解决类别不平衡问题方面越来越受欢迎，主要应用于模式分类和计算机视觉任务。相比之下，极值预测是一个充满挑战的领域，其应用范围从金融到气候变化等众多领域。本文提出了一种数据增强框架用于极值预测，旨在通过结合深度学习模型和数据增强方法（如GANs和合成少数类过采样技术SMOTE）来预测极值。作者使用卷积长短期记忆（Conv-LSTM）和双向长短期记忆（BD-LSTM）网络进行多步预测，关注预测准确性及其对极值区域的影响，同时考虑计算效率。", "innovation": "本文的主要创新是提出了一种基于相关性的数据增强策略，该策略与深度学习模型结合以进行极值预测。此外，研究了几种数据增强模型（包括GANs和SMOTE）的适用性，以及Conv-LSTM和BD-LSTM网络在不同数据集上的表现差异。Conv-LSTM和BD-LSTM网络在处理周期性和非周期性数据时表现出互补优势，而基于相关性的数据增强策略展示了更好的适应性和性能提升。", "conclusion": "本文通过结合深度学习和基于相关性的数据增强策略，显著提高了极值预测的准确性和鲁棒性。尤其是应用了SMOTE策略后，预测性能在短中长期都得到了提升。Conv-LSTM和BD-LSTM模型在不同的数据场景下表现出不同的优势，但组合使用能更好地应对各种复杂情况。"}
{"llm_update_time": "20251006", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.02490", "html_url": "https://arxiv.org/abs/2510.02490", "title": "通过有界极值搜索提高时间变异系统中深度强化学习控制的鲁棒性", "title_en": "Improved Robustness of Deep Reinforcement Learning for Control of Time-Varying Systems by Bounded Extremum Seeking", "authors": "Shaifalee Saxena,Alan Williams,Rafael Fierro,Alexander Scheinker", "background": "深度强化学习（DRL）有潜力利用大型数据集快速控制或优化多参数系统的输出，但它在系统模型随着时间快速变化时表现会迅速恶化。而有界极值搜索（Bounded ES）能够处理未知控制方向的时间变化系统，但随着调整参数数量的增加，它的收敛速度会减慢。所有局部自适应方法都可能陷入局部最小值。", "innovation": "提出了一种将DRL和有界极值搜索结合的混合控制策略，这种方法的性能超过了单独使用DRL或有界极值搜索的效果。通过历史数据，DRL可以学会快速控制多参数系统达到期望点，而有界极值搜索则确保了系统的鲁棒性以应对时间变化。", "conclusion": "通过数值研究证明，这种新的混合控制器在一般时间变化系统和洛斯阿拉莫斯中子科学中心直线粒子加速器的低能束传输部分自适应调整中表现优越，展示了提高DRL控制器鲁棒性的创新方法。"}
{"llm_update_time": "20251006", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.14191", "html_url": "https://arxiv.org/abs/2509.14191", "title": "MCGS-SLAM: A Multi-Camera SLAM Framework Using Gaussian Splatting for High-Fidelity Mapping", "title_en": "MCGS-SLAM: A Multi-Camera SLAM Framework Using Gaussian Splatting for High-Fidelity Mapping", "authors": "Zhihao Cao,Hanyu Wu,Li Wa Tang,Zizhou Luo,Zihan Zhu,Wei Zhang,Marc Pollefeys,Martin R. Oswald", "background": "目前密集SLAM技术主要集中在单一摄像头设置上，这往往以牺牲鲁棒性和几何覆盖率为代价。现有方法多依赖于稀疏地图或惯性数据，这影响了系统的效果。", "innovation": "MCGS-SLAM 是首个基于 3D 高斯斑点 (3DGS) 的纯 RGB 多摄像头 SLAM 系统，将多视角的密集 RGB 输入整合到一个连续优化的高斯地图中，同时利用多摄像头束调整 (MCBA) 和尺度一致性模块进行联合优化，增强了几何精度和鲁棒性。此外，系统支持 RGB 输入，并保持大规模下的实时性能。对比单一摄像头基线，MCGS-SLAM 提供了更准确的轨迹和逼真的重建结果，特别在重建单摄像头难以覆盖的侧面视图区域方面效果显著，这对于安全的自主操作至关重要。", "conclusion": "实验结果表明，MCGS-SLAM 能够产生高精度的轨迹和逼真的重建结果，并在大规模应用中保持实时性能。多摄像头输入的宽视野使得重建单摄像头无法覆盖的侧面视图区域成为可能，这些结果展示了多摄像头高斯斑点 SLAM 在机器人和自动驾驶中的高保真映射潜力。"}
{"llm_update_time": "20251006", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.02457", "html_url": "https://arxiv.org/abs/2510.02457", "title": "动态后训练量化中潜在灾难性失败的评估", "title_en": "Assessing the Potential for Catastrophic Failure in Dynamic Post-Training Quantization", "authors": "Logan Frank,Paul Ardis", "background": "后训练量化（PTQ）已发展成为一种有效方法，通过使用较低精度表示权重和激活，来降低神经网络的计算复杂性和内存使用量。尽管PTQ在降低计算和存储成本方面取得了巨大成功，但在不同的输入分布下，它可能会导致显著的性能下降。尤其是在安全性至关重要的应用场景中，研究潜在性能下降及其与输入分布特征的关系至关重要。本文致力于探讨由于动态PTQ导致的极端故障情况，并将其与知识蒸馏和强化学习任务相结合，从而分析量化过程中灾难性故障的最坏情况潜在影响。", "innovation": "本文提出了一种结合知识蒸馏和强化学习问题的方法，以发现可能导致量化过程中灾难性故障的网络和比特位策略对。这种方法有助于量化最坏情况下的故障风险，并展示了量化过程中灾难性故障的存在性，各种实例显示准确率降低了10%到65%，而稳健对仅降低了不到2%。同时，本文还对最脆弱点进行了系统的实验和分析进行了初步探讨，为深入理解PTQ引入的故障情况提供了基础。", "conclusion": "本文的研究结果在一定程度上理解了PTQ引入的故障情况，但仍有进一步深入的空间。总体而言，这些发现强调了在实际部署场景中应注意谨慎，希望促进更多关于鲁棒性和安全性的严谨研究，并在深度学习领域未来的工作中予以重视。"}
{"llm_update_time": "20251006", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.02410", "html_url": "https://arxiv.org/abs/2510.02410", "title": "OpenTSLM：用于多变量医疗文本-时间序列数据推理的时间序列语言模型", "title_en": "OpenTSLM: Time-Series Language Models for Reasoning over Multivariate Medical Text- and Time-Series Data", "authors": "Patrick Langer,Thomas Kaar,Max Rosenblattl,Maxwell A. Xu,Winnie Chow,Martin Maritsch,Aradhana Verma,Brian Han,Daniel Seung Kim,Henry Chubb,Scott Ceresnak,Aydin Zahedivash,Alexander Tarlochan Singh Sandhu,Fatima Rodriguez,Daniel McDuff,Elgar Fleisch,Oliver Aalami,Filipe Barata,Paul Schmiedmayer", "background": "LLMs已经成为解释多模态数据的强大工具，尤其是在医学领域，它们有望将大量的临床信息综合成可操作的洞见和数字健康应用程序。然而，这些模型的一个主要限制是无法处理时间序列数据。为了弥补这个差距，本研究介绍了OpenTSLM，这是一种通过将时间序列作为预训练LLMs的原生模态来整合时间序列的语言模型系列，使其能够处理任意长度的多时间序列。研究者还开发了两种架构：一种是通过软提示将可学习的时间序列标记与文本标记连接起来隐式建模时间序列的OpenTSLM-SoftPrompt；另一种是通过交叉注意力将时间序列与文本显式结合的OpenTSLM-Flamingo。", "innovation": "本研究通过将时间序列作为预训练LLMs的原生模态来整合时间序列，提出了OpenTSLM模型系列，该系列对比基准模型证明了在处理文本-时间序列的推理任务上的优越性能。研究还引入了两种不同的架构——OpenTSLM-SoftPrompt和OpenTSLM-Flamingo，以及三种特定的数据集，并展示了开创性的结论。研究发现，尽管SoftPrompt在参数效率上占优势，但Flamingo在长序列上的表现更优，且内存需求稳定。此外，OpenTSLM模型在所有测试任务中的性能均超越了基准模型，特别是在睡眠阶段识别和人类活动识别任务中表现尤为突出。本研究还提供了所有相关的代码、数据集和模型以促进进一步的研究。", "conclusion": "本研究基于OpenTSLM展示了在多变量医疗文本-时间序列数据推理方面的强大性能，特别是在医疗健康应用中。研究引入了两种不同架构并得到了与传统时间序列处理方法相比更优的性能，尤其是在长序列数据的表现上。此外，OpenTSLM模型在医疗健康场景下的应用展示了其在临床推理中的潜在价值。"}
{"llm_update_time": "20251006", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.02523", "html_url": "https://arxiv.org/abs/2510.02523", "title": "使用跨动物转换进行模型-大脑比较", "title_en": "Model-brain comparison using inter-animal transforms", "authors": "Imran Thobani,Javier Sagastuy-Brena,Aran Nayebi,Jacob Prince,Rosa Cao,Daniel Yamins", "background": "人工神经网络模型已成为大脑机制的有希望模型。然而，尚未就模型激活与大脑响应之间的正确比较方法达成共识。本文通过借鉴神经科学哲学领域的研究成果，提出了一个基于Inter-Animal Transform Class (IATC)的比较方法。该方法严格定义了在动物群体中准确映射神经响应所需的一系列函数。使用IATC，可以在候选模型的响应和大脑数据之间进行双向映射，评估模型是否能够伪装成典型的被试，使用相同的变换方式来映射真实被试之间的响应。该方法已经在模拟神经网络模型群体、小鼠群体和人类群体中进行了验证。", "innovation": "1. 提出了基于IATC的比较方法，严格定义了在动物群体中进行神经响应准确映射所需的一系列函数。\n2. 使用IATC方法，可以在候选模型的响应和大脑数据之间进行双向映射，评估模型伪装的能力。\n3. IATC可以准确预测神经活动，并在机制识别方面具有高度的特异性，能够区分不同脑区的响应模式，同时在跨主体上实现同一脑区响应的强烈对齐。\n4. IATC为解决神经工程目标的高模型–大脑预测性和神经科学目标的机制准确模型识别之间潜在的权衡提供了证伪性证明，支持了拓扑深度神经网络(TDANN)作为视觉系统的模型。", "conclusion": "IATC方法能够实现模型-大脑的有原则的比较，为过去关于深度学习模型的预测成功的发现提供了新的证据，并在模型-大脑比较方法上实现了改进。"}
{"llm_update_time": "20251006", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.02484", "html_url": "https://arxiv.org/abs/2510.02484", "title": "从像素到因素：学习独立可控的状态变量以应用于强化学习", "title_en": "From Pixels to Factors: Learning Independently Controllable State Variables for Reinforcement Learning", "authors": "Rafael Rodriguez-Sanchez,Cameron Allen,George Konidaris", "background": "现有的利用因子马尔可夫决策过程的算法在样本效率方面远优于非因子依赖的方法，但这些算法的前提是因子表示已知，这在智能体仅看到高维观测时会失效。另一方面，深层强化学习可以处理高维输入，但不能利用已知的因子结构。", "innovation": "本文提出了Action-Controllable Factorization (ACF)，这是一种对比学习方法，能够从像素观测中揭示独立可控的潜在变量，即每个动作可以独立影响的状态组成部分。ACF 通过稀疏性假设：通常只有部分变量受到动作的影响，而其他变量则在环境动力学的驱动下演化，这种稀疏性为对比训练提供了富有信息的内容。ACF 能够直接从包含已知因子结构的基准数据集（如 Taxi、FourRooms 和 MiniGrid-DoorKey）的像素观测中恢复到真实可控的因子，并在这些基准测试中持续超越基线去纠缠算法的效果。", "conclusion": "ACF 通过从像素观测中学习独立可控的状态变量，解决了因子表示问题，为强化学习提供了有效的解决方案。ACF 在具备已知因子结构的多个基准测试中表现出色，直接从像素数据中恢复出地面真实的可控因子，优于现有的解纠缠算法。"}
{"llm_update_time": "20251006", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.02558", "html_url": "https://arxiv.org/abs/2510.02558", "title": "AttentiveGRUAE：基于注意力机制的GRU自编码器用于穿戴数据中抑郁的情感时间和行为特征聚类", "title_en": "AttentiveGRUAE: An Attention-Based GRU Autoencoder for Temporal Clustering and Behavioral Characterization of Depression from Wearable Data", "authors": "Nidhi Soley,Vishal M Patel,Casey O Taylor", "background": "本研究基于长时间穿戴数据的研究背景，旨在通过学习每日行为特征的紧凑潜编码，同时预测结局和识别行为亚型。", "innovation": "提出了一种新的注意机制增强型门控循环单元（GRU）自编码器（AttentiveGRUAE），用于时间聚类和从纵向可穿戴数据中预测结局。模型通过序列重构学习每日行为特征的紧凑潜空间表示，通过二元分类头预测终点抑郁症率，并通过基于GMM的软聚类识别行为亚型。与基线模型相比，改进模型在聚类质量和抑郁症分类方面表现更优。", "conclusion": "AttentiveGRUAE在GLOBEM 2018-2019年和2020-2021年的睡眠纵向数据上均实现了更优的性能，通过额外的亚型分析和时间注意力可视化，揭示了不同聚类之间的睡眠相关差异，指出了与睡眠规律性变化一致的关键时间窗口，获得临床可解释的风险解释。"}
{"llm_update_time": "20251006", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.02493", "html_url": "https://arxiv.org/abs/2510.02493", "title": "从演示中恢复密集奖励：超越模仿", "title_en": "Beyond Imitation: Recovering Dense Rewards from Demonstrations", "authors": "Jiangnan Li,Thuy-Trang Vu,Ehsan Abbasnejad,Gholamreza Haffari", "background": "传统的监督微调（SFT）通常被视为一种简单的模仿学习过程，仅训练一个策略来模仿专家在演示数据集上的行为。本文通过建立SFT与逆强化学习之间的基本等价关系，挑战了这一观点。研究证明，SFT目标是逆Q学习的特例形式，因此SFT过程不仅学习策略，还隐含地学习一个密集、分词级的奖励模型，来解释专家演示。", "innovation": "提出了一种从SFT模型直接恢复密集奖励信号的方法，通过基线相关的奖励函数。这种可用的密集奖励模型提供了对每个生成组件的细致奖励划分。通过使用这些恢复的奖励进一步用强化学习优化策略，提出的方法Dense-Path REINFORCE在指令跟随基准上表现出色，超过了原始的SFT模型。强调SFT不仅仅是策略模仿，更是强大的奖励学习机制，为利用专家演示开辟了新的可能性", "conclusion": "通过证明SFT与逆Q学习之间的关系、揭示SFT过程中隐含的密集奖励模型、开发从SFT模型直接恢复密集奖励信号的方法，证明了SFT可以看作是强大的奖励学习机制，进一步使用强化学习优化策略。"}
{"llm_update_time": "20251006", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.02590", "html_url": "https://arxiv.org/abs/2510.02590", "title": "如果可以，使用在线网络：走向快速且稳定的强化学习", "title_en": "Use the Online Network If You Can: Towards Fast and Stable Reinforcement Learning", "authors": "Ahmed Hendawy,Henrik Metternich,Théo Vincent,Mahdi Kallel,Jan Peters,Carlo D'Eramo", "background": "目标网络在深度强化学习（RL）中常用于估计价值函数，虽然有效，但目标网络必须保持稳定，这可能会延迟学习的过程。使用在线网络作为自举式目标直观上是可行的，但由于可能引发学习不稳定性，这通常被视为一个缺点。", "innovation": "提出了一种新颖的更新规则MINTO，通过使用目标网络和在线网络估计的最小值来计算目标，从而平衡稳定性和学习速度。MINTO可以在多种基于值的和演员-批评家的算法中无缝集成，且几乎不需要额外成本。", "conclusion": "MINTO方法在多种基准测试中均显示出更高的性能，表明了其广泛适用性和有效性，能够实现更快且更稳定的强化学习。"}
{"llm_update_time": "20251006", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.02483", "html_url": "https://arxiv.org/abs/2510.02483", "title": "Litespark技术报告：高吞吐量、高效能的大语言模型训练框架", "title_en": "Litespark Technical Report: High-Throughput, Energy-Efficient LLM Training Framework", "authors": "Nii Osae Osae Dade,Moinul Hossain Rahat", "background": "训练大型语言模型（LLMs）面临长时间训练和巨大能耗的问题，现代模型需要数月的计算时间和兆瓦时的电力。为应对这些挑战，本研究提出了一种新型预训练框架Litespark，通过针对性优化Transformer注意力层和MLP层来提高效率。Litespark结合了架构改进和算法优化，以最大化模型FLOPs利用率，同时兼容标准Transformer实现。试验结果显示，该框架在3B和30B参数的Llama模型上表现出显著性能提升，多节点H200 GPU集群的训练吞吐量提升2至6倍，能耗减少55%至83%。这些优化具有模型和硬件的通用性，适用于不同架构的Transformer，并能扩展到后训练阶段，比如监督微调和直接偏好优化。", "innovation": "本研究提出了Litespark，一种通过优化Transformer注意力层和MLP层来提高训练效率的新框架，实现了FLOPs利用率最大化并降低了能耗。与标准Transformer实现兼容，提升了多节点H200 GPU集群上3B和30B参数的Llama模型的训练吞吐量和能效，显示了显著的性能和能效改进。这些优化方法具有普适性，适用于多种架构和不同的后训练阶段。", "conclusion": "Litespark通过优化Transformer架构和算法，有效提升了大语言模型训练的效率和能效。实验结果显示，在多节点的H200 GPU集群上，其训练吞吐量和能耗都获得了显著改善。这种框架对于实际应用具有很好的扩展性和通用性，可以进一步应用于监督微调和直接偏好优化等多种训练后阶段。"}
{"llm_update_time": "20251006", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.02476", "html_url": "https://arxiv.org/abs/2510.02476", "title": "基于不确定性指导的表格基础模型在生物分子功效预测中的模型选择", "title_en": "Uncertainty-Guided Model Selection for Tabular Foundation Models in Biomolecule Efficacy Prediction", "authors": "Jie Li,Andrew McCarthy,Zhizhuo Zhang,Stephen Young", "background": "在生物分子功效预测中，上下文学习模型如TabPFN有较大的应用潜力。但是，这些模型的性能受提供的上下文高度影响。因此，有研究通过在不同数据子集上训练模型的后续集成方法来提升这些模型的性能。然而，没有真实标签的情况下选择最优模型如何进行，依然是一个未解决的问题。本研究探讨了基于不确定性指导的模型选择策略，并通过siRNA敲低功效任务中简单序列功能特性的TabPFN模型超过了专业的最新精度预测器。此外，研究发现模型预测四分位距(IQR)与真实预测误差呈负相关关系。选择并平均使用IQR最低的模型组成的集成模型能比简单的集成或单一模型训练方法取得更好的性能。这项研究的结果强调了不确定性在没有标签的情况下优化生物分子功效预测的潜力。", "innovation": "研究提出了一种基于不确定性的模型选择策略，不再依赖真实标签，而是通过预测模型的不确定性指标IQR来选择最优模型进行集成。实验结果表明，这种方法能够显著提升生物分子功效预测的性能，提供了Label-free的优化策略。", "conclusion": "研究通过基于不确定性的模型选择策略，证明了在没有真实标签的情况下也能有效提升生物分子功效预测的性能，并展示了IQR作为衡量模型不确定性的有效指标。这种方法不仅提升了预测精度，还为生物分子研究提供了新的见解和工具。"}
{"llm_update_time": "20251006", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.02630", "html_url": "https://arxiv.org/abs/2510.02630", "title": "HyperAdaLoRA：通过超网络在训练期间加速LoRA秩分配而不牺牲性能", "title_en": "HyperAdaLoRA: Accelerating LoRA Rank Allocation During Training via Hypernetworks without Sacrificing Performance", "authors": "Hao Zhang,Zhenjia Li,Runfeng Bao,Yifan Gao,Xi Xiao,Bo Huang,Yuhang Wu,Tianyang Wang,Hao Xu", "background": "参数高效微调（PEFT），尤其是低秩适应（LoRA），已经成为了一种减少计算和内存开销的同时对大型语言模型（LLMs）进行微调的有效方法。然而，LoRA假设每个增量矩阵的秩为统一值r，而忽略了不同模块和层间权重矩阵重要性的差异。", "innovation": "HyperAdaLoRA提出了一种新型框架，通过利用注意力机制构建的超网络加速AdaLoRA的收敛过程。它不直接优化奇异值分解的组成部分(P, Λ, Q)，而是采用超网络动态生成这些参数，并通过剪枝超网络生成的奇异值输出实现动态秩分配。", "conclusion": "在各种数据集和模型上的全面实验表明，我们的方法可以实现更快的收敛速度而不牺牲性能。此外，进一步在其他LoRA基方法上的扩展实验验证了该方法的广泛适用性。"}
{"llm_update_time": "20251006", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.02625", "html_url": "https://arxiv.org/abs/2510.02625", "title": "TabImpute: 预训练变换器实现准确快速的一次性缺失数据填充", "title_en": "TabImpute: Accurate and Fast Zero-Shot Missing-Data Imputation with a Pre-Trained Transformer", "authors": "Jacob Feitelberg,Dwaipayan Saha,Kyuseong Choi,Zaid Ahmad,Anish Agarwal,Raaz Dwivedi", "background": "表格数据中缺失数据是一个普遍问题。现有的解决方案从简单的平均值填充到复杂的生成对抗网络不等。但由于实际应用场景和时间消耗较多的超参数调优导致的性能变化，不存在默认的插补方法。基于最近的表格基础模型TabPFN，本文提出TabImpute，一个预训练变换器，可以在推理阶段无需调整模型或调参的情况下，实现准确且快速的一次性插补。", "innovation": "提出了TabImpute，一种预训练变换器，可以在推理阶段无需调整模型或调参前提供准确快速的一次性插补解决方案。方法包括一种单元特征化方法，使得表格插补速度提高100倍；一种合成训练数据生成管道，包含真实的缺失模式，提升了测试时的性能；以及MissBench基准测试，包含42个OpenML数据集和13种缺失模式，展示了TabImpute相比11种现有插补方法的稳健性能。", "conclusion": "作者通过提出预训练变换器方法，即TabImpute，解决了传统方法需要调参的问题，在实际应用场景中提供了更为高效和准确的缺失数据插补方案。"}
{"llm_update_time": "20251006", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.02520", "html_url": "https://arxiv.org/abs/2510.02520", "title": "Graph Generation with Spectral Geodesic Flow Matching", "title_en": "Graph Generation with Spectral Geodesic Flow Matching", "authors": "Xikun Huang,Tianyu Ruan,Chihao Zhang,Shihua Zhang", "background": "图生成是一项基本任务，在复杂系统的建模中有广泛应用。现有方法侧重于对齐目标图的谱或度分布，但往往忽视由特征向量诱导的几何结构和图的整体结构。", "innovation": "提出了一种新颖的框架Spectral Geodesic Flow Matching (SFMG)，该框架利用谱特征映射将输入图和目标图嵌入到连续黎曼流形中。SFMG通过定义嵌入之间的测地线流动并沿这些流动匹配分布来生成输出图。该方法具有多重优势：(i) 捕捉纯特征值之外的几何结构；(ii) 支持灵活生成多样化的图结构；(iii) 算法高效，易于扩展。此外，SFMG在广泛的任务中表现出色，并且相较于基于扩散的模型，其训练效率高，扩展性好。SFMG还展示了其能够拓展到之前未见过的图规模上。", "conclusion": "Spectral Geodesic Flow Matching为图合成提供了一种新方法，通过将谱几何与流匹配相结合，实现了在多种基准上的优秀性能，特别是在速度和训练效率方面有着显著优势。"}
{"llm_update_time": "20251006", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.02663", "html_url": "https://arxiv.org/abs/2510.02663", "title": "TutorBench: 评估大型语言模型教学能力的标准", "title_en": "TutorBench: A Benchmark To Assess Tutoring Capabilities Of Large Language Models", "authors": "Rakshith S Srinivasa,Zora Che,Chen Bo Calvin Zhang,Diego Mares,Ernesto Hernandez,Jayeon Park,Dean Lee,Guillermo Mangialardi,Charmaine Ng,Ed-Yeremai Hernandez Cardona,Anisha Gunjal,Yunzhong He,Bing Liu,Chen Xing", "background": "随着学生越来越多地采用大型语言模型（LLMs）作为学习辅助工具，构建能熟练处理教学细微之处的模型至关重要。这些模型需要识别学生的核心需求、具有适应性、提供个性化指导并且准确。基于此需求，本研究引入了TutorBench，这是一个数据集和评估基准，旨在严格评估LLMs的核心教学技能。数据集包含1490个由人类专家精心挑选的样本，重点关注高中和AP级课程。", "innovation": "TutorBench通过引入一个包含样本次级评判标准的数据集和评估基准，来应对教学复杂性。它使用了一种可靠且细粒度的自动评估方法，通过LLM裁判与样本次级评判标准来评判模型响应。研究还发现，不同的模型家族在不同的任务上有不同的优势和局限性。", "conclusion": "研究结果表明，目前前沿的16种LLM在TutorBench上的得分均低于56%，显示出巨大的改进空间。不同模型在支持不同教学场景的能力上存在差异，Claude模型在支持主动学习方面表现优于其他模型，但在其他两个应用场景上表现较弱。通过发布TutorBench，旨在为下一代AI导师的发展提供全面而不饱和的标准。"}
{"llm_update_time": "20251006", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.02683", "html_url": "https://arxiv.org/abs/2510.02683", "title": "数据驱动的动力学能否揭示隐藏的物理规律？需要可解释的神经算子", "title_en": "Can Data-Driven Dynamics Reveal Hidden Physics? There Is A Need for Interpretable Neural Operators", "authors": "Wenhan Gao,Jian Luo,Fang Wan,Ruichen Xu,Xiang Liu,Haipeng Xing,Yi Liu", "background": "近年来，神经算子作为一种强大的工具，已用于在函数空间之间学习映射，使得复杂的动态数据驱动模拟成为可能。尽管取得了成功，但对它们的学习机制的理解仍然亟待深入研究。", "innovation": "作者根据其在空间域和功能性域中的学习方式，将神经算子分为两大类，并提供了新的视角。此外，他们提出了一种解释神经算子预测过程的方法，并表明神经算子可以从数据中学习隐藏的物理模式。研究还展示了一种简化的双空间多尺度模型达到了最佳性能，这预示着双空间多尺度模型在学习复杂物理规律方面有巨大潜力，并需要进一步探索。最重要的是，他们强调了需要原则性的框架来将已知物理原理整合到神经算子中，以提高泛化能力并揭示更多隐藏的物理现象。", "conclusion": "需要采用可解释的神经算子来深入理解神经算子的学习机制，并强调应开发通用的解释方法以及构建集成了已知物理原理的原则性框架。"}
{"llm_update_time": "20251006", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.02572", "html_url": "https://arxiv.org/abs/2510.02572", "title": "GeoML库", "title_en": "Geospatial Machine Learning Libraries", "authors": "Adam J. Stewart,Caleb Robinson,Arindam Banerjee", "background": "近年来，机器学习的进步得益于领域特定软件库的出现，这使得工作流程更加流畅且更具可重复性。对于地理空间机器学习（GeoML），地球观测数据的可用性已经超越了针对其独特挑战（如不同的空间分辨率、光谱特性、时间频率、数据覆盖范围、坐标系统和文件格式）而开发的领域库。本文综述了GeoML库，分析了它们的发展历程、核心功能和生态系统，并介绍了如TorchGeo、eo-learn和Raster Vision等流行的GeoML库，详细探讨了其架构、支持的数据类型以及与机器学习框架的集成。此外，还讨论了数据预处理、空间-时间连接、基准测试以及预训练模型的使用等常见方法。通过农田类型映射的案例研究，展示了这些工具的实际应用。", "innovation": "综述了GeoML库的发展历程和核心功能，详细介绍了TorchGeo、eo-learn和Raster Vision等流行库的架构和技术特点，探讨了数据预处理、时空连接、基准测试和预训练模型的使用等方法，并通过农田类型映射案例研究展示了这些工具的应用，同时强调了软件设计、许可和测试的最佳实践，以及开源地理空间软件所面临的挑战和未来方向，特别是基础模型的兴起和治理的需求。", "conclusion": "本文旨在为从业者、开发者和研究人员提供导航和贡献GeoML领域快速发展的指导，特别强调了开源地理空间软件的发展和未来方向，尤其是基础模型的崛起和治理的需求。"}
{"llm_update_time": "20251006", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.02610", "html_url": "https://arxiv.org/abs/2510.02610", "title": "MINERVA：基于神经估计互信息的监督特征选择", "title_en": "MINERVA: Mutual Information Neural Estimation for Supervised Feature Selection", "authors": "Taurai Muvunzaa,Egor Kraev,Pere Planell-Morell,Alexander Y. Shestopaloff", "background": "现有的特征过滤方法依赖于基于统计的成对依赖性度量来建模特征和目标的关系，但当目标依赖于特征间的高阶交互而非个体贡献时，这种方法可能会失效。现有方法难以捕捉复杂的关系，特别是在特征与目标之间存在高阶依赖的情况下效果不佳。", "innovation": "本文提出了名为MINERVA的新颖方法，这是基于神经网络估计特征与目标之间的互信息的监督特征选择方法。通过引入神经网络参数化互信息的近似，并使用精心设计的损失函数及其稀疏诱导正则化进行特征选择，该方法能够更好地捕捉高阶特征交互。同时，方法分为两个阶段，将特征表示学习与特征选择任务分离，以确保更好的泛化能力和更准确的特征重要性表达。", "conclusion": "实验证明，MINERVA方法在合成数据集和现实欺诈数据集上表现出色，能够有效捕捉复杂的特征-目标关系，并实现精确的特征选择。"}
{"llm_update_time": "20251006", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.02686", "html_url": "https://arxiv.org/abs/2510.02686", "title": "EvoSpeak：大型语言模型用于可解释的进化遗传算法启发式", "title_en": "EvoSpeak: Large Language Models for Interpretable Genetic Programming-Evolved Heuristics", "authors": "Meng Xu,Jiao Liu,Yew Soon Ong", "background": "遗传编程（GP）在复杂优化问题中进化出树结构启发式方面表现出强大的效果。但在动态和大规模场景中，最有效的启发式往往非常复杂，这妨碍了解释性、减慢收敛速度并限制任务间的可转移性。", "innovation": "EvoSpeak 提出了一种新型框架，将遗传编程（GP）与大型语言模型（LLMs）集成，以提升启发式进化过程的效率、透明度和适应性。EvoSpeak能够从高质量的GP启发式中学习提取知识，并利用这些知识实现（i）加速收敛的预热群体生成，（ii）将不透明的GP树转化为简明的自然语言解释，从而促进可解释性和信任，（iii）在相关任务之间实现知识转移和偏好驱动的启发式生成。", "conclusion": "通过将GP的符号推理能力与LLMs的可解释性和生成能力相结合，EvoSpeak推进了智能、透明和用户导向的启发式算法的发展，特别是在解决现实世界的优化问题方面。实验结果表明，EvoSpeak产生的启发式更有效，提高了进化效率，并提供了易于阅读的报告，提升了用户体验。"}
{"llm_update_time": "20251006", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.02658", "html_url": "https://arxiv.org/abs/2510.02658", "title": "驱动行驶检查车辆的最优特性", "title_en": "Optimal Characteristics of Inspection Vehicle for Drive-by Bridge Inspection", "authors": "A. Calderon Hurtado,E. Atroshchenko,K.C. Chang,C.W. Kim,M. Makki Alamdari", "background": "近年来，沿线路桥梁健康监测的驱动行驶检查方法越来越受到关注。该方法涉及通过配备监测装置的检查车辆记录的车辆-桥梁联合响应来评估结构完整性并检测损伤。然而，车辆的机械和动态特性显著影响检测性能，限制了该方法的有效性。", "innovation": "这项研究提出了一种框架，用于优化检查车辆以增强对损伤的敏感性。使用基于对抗自编码器（AAE）的无监督深度学习方法重建加速度响应的频域表示。通过最小化健康和损坏桥梁状态损伤指数分布之间的沃尔舍斯坦距离来优化两轴车辆轮胎悬挂系统的质量和刚度。采用Kriging元模型高效地近似目标函数并确定在维度参数空间和非维度参数空间中的最优车辆配置。研究表明，相对于桥梁首个自然频率频率比在0.3到0.7之间的车辆最为有效，而接近共振的车辆表现较差。轻型车辆需要较低的自然频率才能实现最佳检测效果。这是首次对行驶检查的传感平台进行严格优化，并提出了一种专用的检查车辆。", "conclusion": "优化后的检查车辆频率比在0.3到0.7之间的效果最佳，接近共振的车辆表现较差，轻型车辆需要较低的自然频率才能实现最佳检测效果。"}
{"llm_update_time": "20251006", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.02605", "html_url": "https://arxiv.org/abs/2510.02605", "title": "CONUS-全域ML增强的概念可解释 modeling of 捕水区规模的降雨-蓄存-径流动力学", "title_en": "Towards CONUS-Wide ML-Augmented Conceptually-Interpretable Modeling of Catchment-Scale Precipitation-Storage-Runoff Dynamics", "authors": "Yuan-Heng Wang,Yang Yang,Fabio Ciulla,Hoshin V. Gupta,Charuleka Varadharajan", "background": "尽管许多现代研究致力于基于机器学习的大样本水文模型研究，但这些努力并没有必然转化为基于增强物理概念理解的预测改进。本研究在全美国范围内（涵盖了多样化的水文-地质-气候条件）进行了采用机器学习增强的物理可解释的基于质量守恒感知器（MCP）不同复杂度的流域尺度模型的大样本研究。", "innovation": "本研究的创新之处在于采用了物理可解释的基于质量守恒感知器（MCP）的模型，并通过不同过程主导性的水文条件基线比较，展示了基于质量守恒的MCP模型可以实现与基于长短期记忆网络（LSTM）的数据驱动模型相当的性能。重点强调了基于理论指导的物理建模方法，注重机理理解及构建简洁且可解释的模型结构，为将来具有编码空间和时间过程主导信息的模型架构奠定了基础。", "conclusion": "本研究强调了一种基于理论指导、物理基础的方法在大样本水文中的潜力，着重在机理理解及发展简洁且可解释的模型结构，为未来改进空间和时间过程主导性的模型架构奠定了基础。"}
{"llm_update_time": "20251006", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.02565", "html_url": "https://arxiv.org/abs/2510.02565", "title": "GNN衍生的表达能力研究", "title_en": "On The Expressive Power of GNN Derivatives", "authors": "Yam Eitan,Moshe Eliasof,Yoav Gelberg,Fabrizio Frasca,Guy Bar-Shalom,Haggai Maron", "background": "尽管图神经网络（GNNs）取得了显著进展，它们的有限表达能力仍然是一个基本挑战。关于GNN表达能力的研究产生了许多高度表达的架构，这些架构可形成层次结构，具有不断提升的表达能力。此外，对GNN相对于节点特征的导数在过度压缩和过度平滑现象、GNN可解释性等方面进行了广泛研究，但这些导数尚未被作为提升GNN表达能力的手段进行探索。", "innovation": "本文展示了这些导数为提高GNN表达能力提供了一种自然方式。作者提出了一种新的方法——高阶导数GNN (HOD-GNN)，通过利用基模型的高阶节点导数来增强消息传递神经网络（MPNNs）的表达性。这些导数生成的表征意识结构节点嵌入通过第二GNN在端到端可训练的架构中处理。理论证明，所得架构系列的表达能力与WL（Weisfeiler-Lehman）层次结构相匹配。同时，作者揭示了HOD-GNN与子图GNN以及流行的结构性编码方案之间的深厚联系。在计算效率方面，提出了一种新的消息传递算法，该算法利用图的稀疏性和并行性计算MPNNs的高阶导数，从而提升了计算效率。", "conclusion": "在流行的图学习基准测试上的评估表明，HOD-GNN在流行的图学习任务上表现出强大的性能。"}
{"llm_update_time": "20251006", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.02692", "html_url": "https://arxiv.org/abs/2510.02692", "title": "通过中间分布调整微调扩散模型", "title_en": "Fine-Tuning Diffusion Models via Intermediate Distribution Shaping", "authors": "Gautham Govind Anil,Shaan Ul Haque,Nithish Kannen,Dheeraj Nagaraj,Sanjay Shakkottai,Karthikeyan Shanmugam", "background": "扩散模型在多个领域的生成任务中被广泛应用。预先训练的扩散模型能够有效捕捉训练数据的分布，但在下游应用场景中，使用奖励函数调整这些分布往往会带来更好的效果。尽管策略梯度方法在自回归生成中广泛应用，但在扩散模型中使用这种方法时，由于无法计算边缘似然，这种方法并不适用，因此提出了替代方案和放松方法。", "innovation": "作者统一了基于拒绝采样精细调优的变体并将其命名为GRAFT，证明它实际上执行了带有重塑奖励的PPO。为了在中间噪声水平上调整分布，引入了P-GRAFT，并通过偏置方差折中数学解释此方法的有效性。通过逆噪声校正方法改进流动模型，无需使用显式奖励。该方法在文本到图像生成、布局生成、分子生成和无条件图像生成任务中进行了实证评估，并在Stable Diffusion 2的应用中提高了VQAScore，显示了相对于基模型的8.81%的相对改善。", "conclusion": "作者提出的方法在流行的文本到图像基准测试中提高了策略梯度方法的效果，并且在生成图像时具有更低的FLOPs/图像，提高了FID得分。"}
{"llm_update_time": "20251006", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.02516", "html_url": "https://arxiv.org/abs/2510.02516", "title": "在具有有限导通状态的类比设备上通过多片残差学习进行存内训练", "title_en": "In-memory Training on Analog Devices with Limited Conductance States via Multi-tile Residual Learning", "authors": "Jindan Li,Zhaoxian Wu,Gaowen Liu,Tayfun Gokmen,Tianyi Chen", "background": "存内计算加速器通过电阻交叉阵列直接在内存中进行深度神经网络计算，使用忆阻器设备表示模型参数的导通状态。然而，有效的存内训练通常需要至少8位的导通状态来匹配数字基准，实现这样的精细粒度状态成本高昂且常常需要复杂的噪声缓解技术，增加了电路复杂性和能耗。由于制造限制，许多有希望的忆阻器设备如ReRAM提供的分辨率仅有约4位，这种有限的更新精度严重降低了训练精度。", "innovation": "提出了一种基于残差学习的方法，通过逐步在多个交叉阵列瓷砖上进行学习，补偿低精度权重更新产生的残差误差，该方法能在具有有限导通状态的设备上实现存内训练。理论分析表明，该方法随瓷砖数量增加而缩小优化差距，并具有线性收敛率。实验表明，在有限状态设置下，该方法在标准图像分类基准上始终优于最先进的存内模拟训练策略，同时硬件开销适中。", "conclusion": "我们提出的方法能够在具有有限导通状态的忆阻器设备上实现高效的存内训练，通过增加多个瓷砖的残差学习逐步补偿低精度权重更新的误差，证明了即使硬件成本适中，该方法也能显著提高训练性能。"}
{"llm_update_time": "20251006", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.02729", "html_url": "https://arxiv.org/abs/2510.02729", "title": "未来深度时间序列预测的准确律", "title_en": "Accuracy Law for the Future of Deep Time Series Forecasting", "authors": "Yuxuan Wang,Haixu Wu,Yuezhou Ma,Yuchen Fang,Ziyi Zhang,Yong Liu,Shiyu Wang,Zhou Ye,Yang Xiang,Jianmin Wang,Mingsheng Long", "background": "近年来，深度时间序列预测已成为一个蓬勃发展的研究方向。尽管社区的兴趣迅速增长，但由于仅在标准基准上实现了小幅改进，研究人员有时会对自己努力的方向感到困惑。本文指出，与图像识别不同，其公认的和可实现的目标是100%的准确性，但由于时间序列预报的不完全可观测性和不确定性，它本质上面临一个非零错误下限。因此，本文聚焦于一个基本问题，即如何评估深度时间序列预测的性能上限？", "innovation": "传统时间序列预测的可预测性度量方法，如ADF检验，在此研究中被超越。本文通过超过2800个新训练的深度预报器的严格的统计测试，发现了深度模型最小预报误差与其窗口内序列模式复杂性之间存在显著的指数关系，提出了一个被称为准确律的规律。此规律有助于识别广泛使用的基准中的饱和任务，并为大型时间序列模型的训练策略提供了有效的途径。", "conclusion": "利用提出的准确律，本文成功地识别了目前在广泛应用的基准中的饱和任务，并提出了一套有效的训练策略，为未来研究提供了宝贵见解。"}
{"llm_update_time": "20251006", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.02731", "html_url": "https://arxiv.org/abs/2510.02731", "title": "混合协作增强与对比样本自适应差异意识对于鲁棒有属性图聚类的研究", "title_en": "Hybrid-Collaborative Augmentation and Contrastive Sample Adaptive-Differential Awareness for Robust Attributed Graph Clustering", "authors": "Tianxiang Zhao,Youqing Wang,Jinlu Wang,Jiapu Wang,Mingliang Cui,Junbin Gao,Jipeng Guo", "background": "由于自监督表示学习和聚类的强大能力，对比有属性图聚类（CAGC）方法取得了巨大成功，主要依赖于有效的数据增强和对比性目标设置。然而，大多数CAGC方法仅利用边作为辅助信息获得节点级别的嵌入表示，并且只关注节点级别的嵌入增强。这种方法忽视了边级别的嵌入增强以及不同粒度的节点和边级别嵌入增强之间的交互。此外，它们通常将所有对比样例对同等对待，忽略了硬正负样例对和易正负样例对之间的显著差异，最终限制了其判别能力。", "innovation": "本文提出了一种新的鲁棒有属性图聚类（RAGC）方法，它结合了混合协作增强（HCA）和对比样本自适应差异感知（CSADA）。首先，同时执行节点和边的嵌入表示和增强以建立更全面的相似性度量标准，以供后续对比学习使用。其次，通过利用具有高置信度的伪标签信息，精心设计CSADA策略，该策略能够自适应地识别所有对比样例对，并通过一个创新的权重调节函数进行差异化处理。HCA和CSADA模块相互强化，有助于提升表示学习中的判别能力。", "conclusion": "在六组基准数据集上的全面有属性图聚类评估表明，提出的方法RAGC在比对手段上有显著效果，证明了这种方法的有效性。"}
{"llm_update_time": "20251006", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.02670", "html_url": "https://arxiv.org/abs/2510.02670", "title": "拓扑不变性和学习的瓦解", "title_en": "Topological Invariance and Breakdown in Learning", "authors": "Yongyi Yang,Tomaso Poggio,Isaac Chuang,Liu Ziyin", "background": "我们证明了一类广泛的置换不变学习规则（包括SGD、Adam及其他规则）在训练过程中会在神经元之间生成一个双唇同步映射，并严格约束神经元分布的拓扑结构。研究表明，学习率在某个拓扑临界点以下时，训练会受到严格限制，以保持神经元的所有拓扑结构。而在临界点之上时，学习过程会允许拓扑简化，使神经元流形逐渐变得粗糙，从而降低了模型的表达能力。这一发现结合最近发现的临界稳定性现象，揭示了神经网络在梯度下降下的学习动态可分为两个阶段：首先，在拓扑约束下进行平滑优化；然后，进入通过急剧的拓扑简化来学习的第二个阶段。理论的关键特征在于，它与特定架构或损失函数无关，这使得拓扑方法可以普遍应用于深度学习的研究中。", "innovation": "论文揭示了学习率对神经网络训练过程中的拓扑结构变化有显著影响。具体而言，较小的学习率会约束模型保持神经元的完整拓扑结构，而较大的学习率则允许神经元分布的拓扑简化，这种拓扑简化会导致模型表达能力下降。此外，论文提出的理论是独立于特定架构或损失函数的，这使得拓扑方法可以广泛应用于深度学习的研究中。", "conclusion": "神经网络在梯度下降下的学习动态可以分为两个阶段：首先是通过平滑的优化在拓扑约束下进行学习，然后进入通过急剧的拓扑简化来学习的阶段。该研究强调了不同的学习率对神经网络训练拓扑结构的影响差异，并且提出了一种与特定架构或损失函数无关的理论框架，这为理解深度学习中的拓扑现象提供了新的视角。"}
{"llm_update_time": "20251006", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.02676", "html_url": "https://arxiv.org/abs/2510.02676", "title": "压缩或不压缩？利用指数集中性推动无损生成AI模型权重压缩的前沿", "title_en": "To Compress or Not? Pushing the Frontier of Lossless GenAI Model Weights Compression with Exponent Concentration", "authors": "Zeyu Yang,Tianyi Zhang,Jianwen Xie,Chuan Li,Zhaozhuo Xu,Anshumali Shrivastava", "background": "随着生成AI（GenAI）模型参数规模扩大到几十亿级别，低精度计算成为实现高效部署不可或缺的技术。文章指出，关键在于开发低精度浮点格式，这种格式能提供内置的数值稳定性、节省内存和硬件高效性，且无需去量化解算的开销。研究认为，GenAI模型权重中指数部分表现出低熵现象，这种现象自然源自由随机梯度下降诱导的α-稳定分布，且证明了指数部分熵的紧致边界。这一分析建立了一个理论压缩限值接近FP4.67，这促使了一个实际的FP8格式设计。", "innovation": "文章提出了Exponent-Concentrated FP8（ECF8）无损压缩框架，它具有熵感知编码和GPU优化的解码。实验表明，与LLMs和DiTs模型参数达671B上极限的模型相比，该项目可节省26.9%的内存，并加速177.1%的吞吐量，且计算完全无损，即模型输出无偏差。研究还确立了指数集中的统计法则，为FP8时代的无损低精度浮点格式设计开辟了先驱路径", "conclusion": "指数集中性被确立为训练模型的统计法则，并为无损低精度浮点格式设计提供了理论依据。这项研究对生成AI模型的压缩和优化有着重要的理论和实践意义。"}
{"llm_update_time": "20251006", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.02763", "html_url": "https://arxiv.org/abs/2510.02763", "title": "利用自我监督和分层深度学习融合多谱段和超光谱卫星数据进行有害藻华监测", "title_en": "Fusing Multi- and Hyperspectral Satellite Data for Harmful Algal Bloom Monitoring with Self-Supervised and Hierarchical Deep Learning", "authors": "Nicholas LaHaye,Kelly M. Luis,Michelle M. Gierach", "background": "本文提出了一个自监督机器学习框架，用于利用多传感器卫星数据检测和绘制有害藻华（HAB）的严重程度和种类。通过融合业务仪器（VIIRS、MODIS、Sentinel-3、PACE）的反射率数据与TROPOMI太阳诱导的荧光（SIF）数据，框架命名为SIT-FUSE，在不需要依赖每个仪器的标签数据集的情况下生成HAB的严重程度和种类产品。该研究利用自我监督表示学习和分层深度聚类，将浮游植物浓度和种类分割成可解释的类别，并通过墨西哥湾和南加州的现场数据（2018-2025）进行了验证。", "innovation": "该框架能够在缺乏标签的环境中实现可扩展的HAB监测，通过使用自我监督学习和分层嵌入的方式，进行大量的潜在地探索性分析，从而朝着实现全局水生生物地球化学的自监督学习操作应用迈出了一步。", "conclusion": "研究成果表明，该工作在标签稀缺的环境中极大地推进了HAB的监测能力，并通过分层嵌入的方式为自监督学习在全局水生生物地球化学中的应用奠定了基础。"}
{"llm_update_time": "20251006", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.02695", "html_url": "https://arxiv.org/abs/2510.02695", "title": "RAMAC：多模态风险意识的离线强化学习及行为正则化的作用", "title_en": "RAMAC: Multimodal Risk-Aware Offline Reinforcement Learning and the Role of Behavior Regularization", "authors": "Kai Fukazawa,Kunal Mundada,Iman Soltani", "background": "在涉及安全的关键领域，由于在线数据收集的不可行性，离线增强学习（RL）提供了一种有吸引力的替代方案，前提是策略必须在降低成本尾部风险的同时保证高回报。先前的研究表明，尽管风险意识的离线RL可以在安全方面取得成效，但通常会导致价值保守主义和有限的策略类别，而在没有风险意识的情况下，可表达的策略只能在相对固定的策略类别中使用。因此，该领域的关键问题是如何在保持高回报的同时实现风险敏感的学习，特别是在复杂的多模态场景下。", "innovation": "本文通过引入一种名为Risk-Aware Multimodal Actor-Critic (RAMAC)的框架解决了上述问题，该框架结合了表达性的生成器和分布式的评论家。RAMAC通过生成路径分发复合目标，该复合目标结合了分布性风险和行为一致性（Behavioral Consistency）损失，从而实现了在复杂的多模态场景下进行风险敏感的学习。该研究具体实例化了RAMAC，使用扩散和流匹配的演员，实验观察到了在绝大多数随机D4RL任务中的CVaR_{0.1}的一致性收益。此外，该研究还探讨了行为正则化的作用。", "conclusion": "RAMAC框架通过结合生成器和分布批评家，为离线RL中风险感知的学习提供了一种新的途径，特别是在多模态场景中。该方法不仅提高了模型对复杂分布的风险意识，还在保持高回报的同时减少了潜在的危险事件。"}
{"llm_update_time": "20251006", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.02711", "html_url": "https://arxiv.org/abs/2510.02711", "title": "一种用于无人机网络入侵检测的新颖统一时间-空间变换方法", "title_en": "A Novel Unified Lightweight Temporal-Spatial Transformer Approach for Intrusion Detection in Drone Networks", "authors": "Tarun Kumar Biswas,Ashrafun Zannat,Waqas Ishtiaq,Md. Alamgir Hossain", "background": "随着无人机在商业、工业和民用领域的广泛应用，网络安全威胁日益增加，尤其是由于无人机网络容易遭受广泛类型的网络攻击。现有的入侵检测机制通常不适用于无人机网络的动态且资源受限环境，缺乏适应性、效率和泛化能力。因此，需要一种能够处理复杂、动态环境下的网络入侵检测的新型解决方案。", "innovation": "本文提出了一种名为TSLT-Net的新型轻量级和统一的时间-空间变换基于的入侵检测系统，特别针对无人机网络。通过利用自我注意力机制，TSLT-Net能够有效地建模网络流量中的时间模式和空间依赖性，实现对不同入侵类型的准确检测。该框架包含了一个精简的预处理流水线，并支持在单一架构下进行多类攻击分类和二元异常检测。实验结果表明，TSLT-Net在多类检测中的准确率为99.99%，在二元异常检测中的准确率为100%，同时保持了最小的内存占用（0.04 MB）和9722个可训练参数。这证明了TSLT-Net是实时无人机网络安全的有效且可扩展的解决方案，特别适合在关键任务无人系统中部署于边缘设备上。", "conclusion": "TSLT-Net通过综合利用时间和空间变换及自我注意力机制，显著提高了无人机网络上的入侵检测效率和准确性，特别对于资源受限的环境，展示出了巨大的应用潜力。"}
{"llm_update_time": "20251006", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.02721", "html_url": "https://arxiv.org/abs/2510.02721", "title": "Hyperparameter Loss Surfaces Are Simple Near their Optima", "title_en": "Hyperparameter Loss Surfaces Are Simple Near their Optima", "authors": "Nicholas Lourie,He He,Kyunghyun Cho", "background": "超参数极大地影响模型能力，但现代模型过于庞大，无法进行全面搜索。研究人员设计食谱，通过对其超参数的理解在不同规模下有效训练。尽管这一点非常重要，但很少有工具可以理解超参数损失表面。研究表明在接近最优值时，损失表面会展现出简单结构，并提出了一种新理论，提供新的工具来发现这一现象。这些工具揭示出关于随机搜索在这一 asymptotic 状态下表现出的新分布，可以解释和外推其收敛过程。这些新工具使得能够进行新的分析，如最佳可能性能的置信区间或确定有效超参数数量等。", "innovation": "研究人员发现了超参数损失表面在接近最优值时表现出简单结构的新理论，并提出了一个基于随机搜索的新型技术。该技术能够揭示在这一 asymptotic 状态下随机搜索表现出的新分布的参数，这些参数定义了损失表面在 asymptotic 状态下的特征。从这些特征中，推导出新的随机搜索渐近定律，可以解释和外推其收敛过程。这些新工具使得能够进行新的分析，如最佳可能性能的置信区间或确定有效超参数数量等。", "conclusion": "提出了新的工具使得能够进行新的分析，如确定最优性能的可能性和有效超参数数量，并将这些工具发布在 provided URL。"}
{"llm_update_time": "20251006", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.02768", "html_url": "https://arxiv.org/abs/2510.02768", "title": "在模型消融下的细粒度安全预训练研究", "title_en": "A Granular Study of Safety Pretraining under Model Abliteration", "authors": "Shashank Agnihotri,Jonas Jakubassa,Priyam Dey,Sachin Goyal,Bernt Schiele,Venkatesh Babu Radhakrishnan,Margret Keuper", "background": "大语言模型可以在推理时通过简单的激活编辑进行修改，这在安全性方面提出了实际问题：常见的安全干预措施，如拒绝训练或元标签训练，在这种编辑下是否仍然有效？本文研究了模型消融，这是一种用于移除拒绝敏感方向的轻量级投影技术，并在SmolLM2-1.7B的细粒度安全预训练检查点上进行了严格评估，同时兼顾广泛使用的开放基线。对于每套20个系统（包括原始和消融后的），研究人员发出了100个注释平衡的有害和无害提示，使用多名评委将响应分类为“拒绝”或“非拒绝”，并对一部分由人类标记的人类标注子集验证评委的一致性。研究团队还探讨了模型是否能够识别自身的输出中的拒绝内容。", "innovation": "本文首次探讨了细粒度安全预训练在模型消融下的稳定性，并通过严格的评估检查了不同模型的安全性组件在消融过程中的表现情况，同时提出现场评估框架的重要组成部分，为安全性评估提供了一个实用的协议。此外，还研究了评委选择对评估结果的可能影响，并公开提供了一套用于此类评估的代码。", "conclusion": "我们的研究对于理解数据集中安全性组件的稳定性具有重要贡献，量化了评委选择对评价结果的潜在影响，并提出了集成推理时的编辑到安全性评估中的实用方法。测试结果表明，在模型消融下，某些特定数据安全性组件保持了稳定性，而其他组件则未能维持安全性，这为后续研究提供了明确的指导。"}
{"llm_update_time": "20251006", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.02818", "html_url": "https://arxiv.org/abs/2510.02818", "title": "通过分层不确定性集的分布稳健学习减轻虚假关联", "title_en": "Mitigating Spurious Correlation via Distributionally Robust Learning with Hierarchical Ambiguity Sets", "authors": "Sung Ho Jo,Seonghwi Kim,Minwoo Chae", "background": "传统的监督学习方法在面对测试数据分布变化时，容易受到虚假相关的影响。虽然已有一些方法，尤其是组DRO方法，在处理子群体或群体间断变化方面表现出高度的稳健性，但它们在处理群体内部分布变化方面仍然脆弱，尤其是在样本有限的少数群体中。本研究旨在提出一种分层扩展的组DRO方法，以同时解决群体间和群体内的不确定性，提供多级的分布鲁棒性。此外，还构建了新的基准设定，模拟少数群体内部分布变化的真实情况，这是一个在虚假关联研究中之前较少探索的重要挑战。", "innovation": "提出了一种分层扩展的组DRO方法，能够同时处理群体间和群体内部的不确定性；引入了新的基准设置来模拟少数群体内部的分布变化；展示了在处理分布变化条件下的强大鲁棒性，而现有的一些鲁棒学习方法在这些条件下会失效。", "conclusion": "本研究的结果突显了扩展含糊集合的重要性，以更好地捕捉群体间和群体内的分布不确定性。"}
{"llm_update_time": "20251006", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.02730", "html_url": "https://arxiv.org/abs/2510.02730", "title": "Dale 与兰金相遇：一种乘法降噪扩散模型", "title_en": "Dale meets Langevin: A Multiplicative Denoising Diffusion Model", "authors": "Nishanth Shetty,Madhava Prasath,Chandra Sekhar Seelamantula", "background": "梯度下降已被证明是机器学习应用中优化的强大而有效的方法。然而，最近的神经科学进展表明，标准的梯度下降优化形式与生物系统的学习机制不符。这为基于Dale定律构建受生物学启发的学习技术开辟了新的途径，该定律指出，在学习过程中抑制性和兴奋性突触不会互换角色。通过这种方式得到的指数梯度下降优化方案导致突触权重呈对数正态分布。有趣的是，与带有几何布朗运动（GBM）的随机微分方程（SDE）对应的Fokker-Planck方程的密度是对数正态密度。利用这种联系，作者从GBM的SDE出发，通过反时钟SDE的离散化得到了乘法更新规则，该规则出人意料地与基于Dale定律的指数梯度下降更新的采样等价物一致。此外，作者还提出了一种新的乘法降噪评分匹配形式，涵盖了Hyvärinen为非负数据提出的方法。对MNIST、Fashion MNIST和Kuzushiji数据集的实验结果表明，新方案具有生成能力。据我们所知，这是首次使用与几何布朗运动相关的乘法更新建立生成模型的实例。", "innovation": "该论文提出了一个新的乘法降噪扩散模型（Dale 与 Langevin 相遇），通过将Dale定律与几何布朗运动相结合，实现了对数正态分布数据的生成。该模型首次结合了神经科学发现和机器学习优化技术，提出了新的乘法更新规则和评分匹配形式，从而能够训练基于图像数据的生成模型，并在实际数据集上进行了验证，展示了其生成能力。", "conclusion": "该研究展示了基于生物启发的乘法更新机制的新建模方法，使生成模型能够更好地模拟自然界中的学习过程，并通过实际数据集的实验验证了所提出方法的有效性。这种方法代表了在机器学习中寻找更接近生物实际机制的新途径。"}
{"llm_update_time": "20251006", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.02717", "html_url": "https://arxiv.org/abs/2510.02717", "title": "CST-AFNet: 双注意力机制的深度学习框架在物联网网络中的入侵检测", "title_en": "CST-AFNet: A dual attention-based deep learning framework for intrusion detection in IoT networks", "authors": "Waqas Ishtiaq,Ashrafun Zannat,A.H.M. Shahariar Parvez,Md. Alamgir Hossain,Muntasir Hasan Kanchan,Muhammad Masud Tarek", "background": "互联网的迅速扩展改变了现代工业，通过实现智能自动化和实时连接。然而，这种进化也带来了复杂的网络安全挑战，因为这些环境异构、资源受限且分布式。为了应对这些挑战，该研究提出了CST AFNet，一种基于双注意力机制的新型深度学习框架，用于物联网网络中的稳健入侵检测。该模型结合多层次卷积神经网络（CNN）进行空间特征提取、双向门控递归单元（BiGRUs）捕获时间依赖性，并引入了双注意力机制（通道和时间注意力）以增强对关键模式的焦点。该方法在包含超过220万标记样本、涵盖15种攻击类型和良性流量的Edge IIoTset数据集上进行了训练和评估，结果表明，对于15种攻击类型和良性流量，该模型的准确率表现优异。此外，CST AFNet展示了出色的性能，其宏平均精确度、召回率和F1分数均超过99.3%。实验结果表明，CST AFNet在检测准确性上表现出色，显著优于传统的深度学习模型。这些发现证实，CST AFNet是一种强大的、可扩展的解决方案，适用于复杂物联网和工业物联网环境中的实时网络威胁检测，为更安全、智能和自适应的物理-网络系统铺平了道路。", "innovation": "提出了CST AFNet，一种基于双注意力机制的新型深度学习框架，用于物联网网络中的稳健入侵检测。该模型通过结合多层次卷积神经网络（CNN）进行空间特征提取、双向门控递归单元（BiGRUs）捕获时间依赖性，并引入了双注意力机制（通道和时间注意力），增强了对关键模式的焦点。该方法在Edge IIoTset数据集上表现出色，显著优于传统的深度学习模型。CST AFNet在检测准确性、宏平均精确度、召回率和F1分数上均显著高于其他现有方法。", "conclusion": "CST AFNet是一种强大的、可扩展的解决方案，适用于复杂物联网和工业物联网环境中的实时网络威胁检测，为更安全、智能和自适应的物理-网络系统铺平了道路。"}
{"llm_update_time": "20251006", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.02809", "html_url": "https://arxiv.org/abs/2510.02809", "title": "时间序列在线卷积预测中的相关性意识阈值调整", "title_en": "Relevance-Aware Thresholding in Online Conformal Prediction for Time Series", "authors": "Théo Dupuy,Binbin Xu,Stéphane Perrey,Jacky Montmain,Abdelhak Imoussaten", "background": "在机器学习的近期工作中，不确定性量化已经引起了显著的关注。尤其是，卷积预测（CP）在这一领域中取得了显著进展。特别地，在时间序列分析中，当数据分布随时间变化时，时间序列在线卷积预测（OCP）成为了解决数据分布变化问题的一种选择。通常评估OCP方法性能的两个关键方面是覆盖率的有效性和预测区间宽度的最小化。最新的OCP方法虽然提供了长期覆盖保证并生成更具有信息量的区间，但它们在阈值更新步骤中大多只关注预测区间的有效性而未考虑其相关性。", "innovation": "本文旨在利用被忽视的相关性方面。具体来说，作者提出了通过使用基于真实值量化预测区间相关性的函数来增强阈值更新步骤。这种方法有助于防止阈值的突然变化，从而可能导致更窄的预测区间。实验证明，这些函数可以在维持覆盖率有效性的前提下生成更紧的预测区间。", "conclusion": "实验结果表明，这些基于真实值量化预测区间相关性的函数可以在保持覆盖有效性的基础上，生产更紧的预测区间。"}
{"llm_update_time": "20251006", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.02779", "html_url": "https://arxiv.org/abs/2510.02779", "title": "Gradient下降法在DeeP ReLU分类中的最佳泛化率", "title_en": "Optimal Rates for Generalization of Gradient Descent for Deep ReLU Classification", "authors": "Yuanfan Li,Yunwen Lei,Zheng-Chu Guo,Yiming Ying", "background": "近年来，梯度下降（GD）方法在深度神经网络中的泛化性能有了显著的提高。一个自然且基础的问题是，GD能否实现与核设置中确立的最小最大最优率相媲美的泛化率。现有的结果要么提供了次优的 $O(1/\text{sqrt}(n))$ 率，要么集中在具有平滑激活函数的网络上，造成了网络深度 $L$ 的指数依赖性。", "innovation": "本工作通过精心权衡优化错误和泛化错误，为深度 ReLU 网络中的梯度下降方法建立了最佳泛化率。具体来说，在数据从余弦 $\text{gamma}$ 可区分的假设下，证明了泛化风险率 $\text{~O}(L^4 (1 + \text{gamma} L^2) / (n \text{gamma}^2))$，该结果与最优支持向量机（SVM）类型率 $\text{~O}(1 / (n \text{gamma}^2))$ 在深度依赖因子上一致。技术贡献在于对参考模型附近激活模式的新型控制，允许有更紧的 Rademacher 复杂性界，这适用于经过梯度下降训练的深度 ReLU 网络。", "conclusion": "论文通过建立深度 ReLU 网络中梯度下降方法的最优泛化率，展示了与最小最大最优率相匹配的泛化性能，同时实现了深度的多项式依赖性，并提供了一种对激活模式的新控制方法，使得泛化性能得到了显著提升。"}
{"llm_update_time": "20251006", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.02798", "html_url": "https://arxiv.org/abs/2510.02798", "title": "OptunaHub: 一个黑盒优化平台", "title_en": "OptunaHub: A Platform for Black-Box Optimization", "authors": "Yoshihiko Ozaki,Shuhei Watanabe,Toshihiko Yanase", "background": "黑盒优化（BBO）在自动化机器学习（AutoML）和材料信息学等领域推动了进步，但研究工作在各个领域常常分散进行，缺乏统一的平台来汇集这些方法和基准测试。", "innovation": "引入了OptunaHub，这是一个社区平台，它集中了BBO方法和基准测试。OptunaHub提供了统一的Python API、贡献者包注册表以及网页接口，以促进可搜索性和跨域研究。该平台旨在培养贡献和应用之间的良性循环。", "conclusion": "OptunaHub的源代码可以在GitHub Optuna组织下的optunahub、optunahub-registry和optunahub-web仓库中获得，目前是公开发布的。"}
{"llm_update_time": "20251006", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.02820", "html_url": "https://arxiv.org/abs/2510.02820", "title": "随机序模型中的在线学习", "title_en": "Online Learning in the Random Order Model", "authors": "Martino Bernasconi,Andrea Celli,Riccardo Colini-Baldeschi,Federico Fusco,Stefano Leonardi,Matteo Russo", "background": "随机序模型是在线学习的一种模型，在这种模型中，损失序列在学习之前由对手计算并以随机排列的方式呈现给学习者。这种输入可能在有限时间内表现出显著的非稳态特征，这可能阻碍随机学习算法的性能。尽管针对对抗输入的算法在其遗憾保证上天然具有鲁棒性，但一些简单的无遗憾算法在随机序模型下在对抗实例中会失效。", "innovation": "本文提出了一种通用模板，可以在不严重影响遗憾保证的前提下，使随机学习算法适应随机序模型。这使得它们在预测带延迟、在线学习带约束和带切换成本的bandit问题上获得了改进的遗憾界。此外，针对在线分类，在随机序模型中，可学习性由VC维度而非Littlestone维度来表征，这为一般对抗模型提供了一个进一步的分离.", "conclusion": "本文改进了随机序模型下的在线学习算法，提出了一个通用模板，使得这些算法在预测带延迟、在线学习带约束和带切换成本的bandit问题上获得了更好的遗憾界。同时，关于随机序模型中的在线分类问题，可学习性由VC维度而非Littlestone维度来表征。"}
{"llm_update_time": "20251006", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.02765", "html_url": "https://arxiv.org/abs/2510.02765", "title": "Curl Descent: 非梯度学习动态与符号各异的塑性", "title_en": "Curl Descent: Non-Gradient Learning Dynamics with Sign-Diverse Plasticity", "authors": "Hugo Ninou,Jonathan Kadmon,N. Alex Cayco-Gajic", "background": "梯度基算法是人工神经网络训练的基础，但尚不清楚生物神经网络是否在学习过程中使用类似的梯度基策略。尽管实验中发现了多种神经可塑性规则，但这些规则是否相当于梯度下降还有待验证。研究关注一种被忽视的可能性：学习动态可能包含本质上非梯度的“旋涡”成分，但仍能有效优化损失函数。‘旋涡’术语自然在具有抑制兴奋连接或海宾/反海宾塑性的网络中出现，导致无法用任何目标梯度下降来描述的学习动态。研究通过系统地引入非梯度动力学，分析具有非梯度机制的前向网络，结果显示小的‘旋涡’项能在保持原解流形稳定性的同时，使学习动态类似于梯度下降。当‘旋涡’项强于某一临界值时，会破坏解流形的稳定性。网络架构不同，这种不稳定可能导致混沌学习动力学，导致性能下降。在其他情况下，‘旋涡’项能通过暂时上升损失而帮助权重动态逃离鞍点，从而加快学习速度。这些发现识别出能够利用多种学习规则实现稳健学习的特定架构，为神经网络基于梯度的学习规范理论提供了重要补充，并揭示了一种新颖的非梯度学习机制。", "innovation": "本研究提出了一种新的学习机制——‘旋涡’下降（Curl Descent），指出在抑制兴奋连接或海宾/反海宾塑性作用下，学习过程中的动力学可能包含‘旋涡’成分，导致不能用任何目标函数的梯度下降来描述的情况。研究通过分析具有非梯度机制的前馈网络，展示了‘旋涡’项如何影响学习过程的稳定性和效率，特别是在塑性规则翻转时。这一创新揭示了一种不同于传统梯度下降的学习机制，并提供了一种理解神经网络学习动态的新视角", "conclusion": "研究界定了特定网络架构能够通过多样化的学习规则实现稳健学习的能力，这一发现为基于梯度的学习规范理论提供了重要补充。同时，研究也揭示了一种在抑制兴奋连接或海宾/反海宾塑性条件下可能存在的非梯度学习动态，为理解生物神经网络的学习机制提供了新思路。"}
{"llm_update_time": "20251006", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.02758", "html_url": "https://arxiv.org/abs/2510.02758", "title": "TokenFlow：通过预抢占调度实现请求突发下的响应式LLM文本流式服务", "title_en": "TokenFlow: Responsive LLM Text Streaming Serving under Request Burst via Preemptive Scheduling", "authors": "Junyi Chen,Chuheng Du,Renyuan Liu,Shuochao Yao,Dingtian Yan,Jiang Liao,Shengzhong Liu,Fan Wu,Guihai Chen", "background": "实时LLM互动需要流式生成文本标记，这些标记通过保证响应性和稳定生成之间取得平衡来逐步生成和传递给用户。标准的LLM服务系统由于使用非抢占性的请求调度和被动的内存管理，在请求突发期间面临着资源利用率低和请求处理并行性差的问题。", "innovation": "TokenFlow通过引入预抢占的请求调度和前瞻性的键值缓存管理，增强流式文本性能。它基于实时的标记缓冲区占用率和消耗速率动态地优先处理请求，并在后台主动地在GPU和CPU内存之间转移键值缓存，同时重叠I/O操作和计算，以最小化请求抢占开销。", "conclusion": "通过在Llama3-8B和Qwen2.5-32B等多个GPU（RTX 4090、A6000、H200）上进行的实验，表明TokenFlow在实际用户消费基础上实现了高达82.5%的有效吞吐量提升，并将P99 TTFT降低了多达80.2%，而总体标记吞吐量没有下降。"}
{"llm_update_time": "20251006", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.02914", "html_url": "https://arxiv.org/abs/2510.02914", "title": "FeDABoost: 自适应增强的公平感知联邦学习", "title_en": "FeDABoost: Fairness Aware Federated Learning with Adaptive Boosting", "authors": "Tharuka Kasthuri Arachchige,Veselka Boeva,Shahrooz Abghari", "background": "该论文关注在非IID设置下通过改进模型聚合和提高表现较差客户端的训练来提升联邦学习（FL）的性能和公平性。背景在于在现实场景中，客户端的数据分布是有差异的，传统的联邦学习方法不能很好地处理这种情况，导致某些客户端的贡献被忽视或受到不公平对待。", "innovation": "创新点在于提出了一种新的联邦学习框架FeDABoost，结合了动态增强机制和自适应梯度聚合策略。首先，通过模拟Multiclass AdaBoost (SAMME) 算法的加权机制，分配更多权重给本地错误率较低的客户端，以提升其在全局模型中的贡献可靠性；其次，动态增强性能较差的客户端，通过调整焦点损失参数，在本地训练中突出难以分类的样本。", "conclusion": "实验结果表明，FeDABoost 在MNIST, FEMNIST, 和CIFAR10三个基准数据集上表现出改进的公平性和竞争性的性能。"}
{"llm_update_time": "20251006", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.02902", "html_url": "https://arxiv.org/abs/2510.02902", "title": "DMark：无序依赖水印的大规模扩散语言模型", "title_en": "DMark: Order-Agnostic Watermarking for Diffusion Large Language Models", "authors": "Linyu Wu,Linhao Zhong,Wenjie Qu,Yuexin Li,Yue Liu,Shengfang Zhai,Chunhua Shen,Jiaheng Zhang", "background": "扩散大语言模型（dLLMs）能够比自回归模型更快地生成内容，同时保持相似的质量。然而，现有的水印方法在dLLMs上失败，因为它们不是顺序性解码。现有的水印方法是基于自回归模型从左到右生成标记的因果设计，而dLLMs可以根据任意顺序完成标记的最终确定，这打破了传统水印的因果设计，使得水印检测不再有效。", "innovation": "DMark 是首个专为dLLMs设计的水印框架。DMark 提出了三种互补策略来恢复水印的可检测性：预测水印使用模型预测的标记而不是实际外部分文本上下文；双向水印利用扩散解码中特有的前向和后向依赖性；预测和双向水印结合使用，以最大化检测强度。实验结果表明，DMark 在1%的误报率下，实现了92.0%-99.5%的水印检测率，同时保持了文本质量，而现有的方法只有49.6%-71.2%的检测率。DMark 还展示了对文本篡改的鲁棒性，证明了有效水印对非自回归语言模型是可行的。", "conclusion": "DMark 在多个dLLMs 上进行了测试，显示了高检测率和低误报率，且在保持文本质量的同时有效应对了文本篡改。这表明DMark 是一个高效可靠的针对扩散大语言模型的水印解决方案，证明了非自回归模型中的有效水印是可行的。"}
{"llm_update_time": "20251006", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.02826", "html_url": "https://arxiv.org/abs/2510.02826", "title": "多尺度自回归模型是伪装中的拉普拉斯、离散和潜在扩散模型", "title_en": "Multi-scale Autoregressive Models are Laplacian, Discrete, and Latent Diffusion Models in Disguise", "authors": "Steve Hong,Samuel Belkadi", "background": "本文重新审视了视觉自回归（VAR）模型，提出了一个新的迭代细化框架。人们通常将VAR视为单一的下一级自回归模型，而本文强调它实际上是一个确定性的前向过程，该过程构建了拉普拉斯风格的潜在金字塔，并配有一个学习到的反向过程，在少量从粗到细的步骤中重建它。这一观点将VAR模型与去噪扩散模型联系起来，并识别出三个设计选择：在一个学习到的潜在空间中细化、将预测转换为代码索引上的离散分类、以及按空间频率划分任务。这些设计选择有助于解释其效率和保真度。通过控制实验量化每个因素对保真度和速度的贡献，并概述了该框架如何扩展到不变性图生成和概率式的中期天气预报。该框架还表明，VAR可以利用扩散生态系统的工具，同时保持多项式、逐级的生成过程。", "innovation": "本文提出将VAR模型通过迭代细化框架重新解释为一种确定性前向过程和学习到的反向过程的结合。此观点将VAR与去噪扩散模型连接起来，并确定了三个有助于提高其效率和保真度的设计选择。通过对影响保真度和速度的因素进行控制实验，验证了这些设计选择的有效性。", "conclusion": "本文框架不仅适用于VAR模型的设计改进，并且可以扩展到不变性的图生成和概率式的中期天气预报。这一框架还建议，VAR可以通过利用扩散生态系统的工具来进一步提升其生成能力，同时也保持其多项式的生成特性。"}
{"llm_update_time": "20251006", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.02892", "html_url": "https://arxiv.org/abs/2510.02892", "title": "RoiRL：基于 Offline 迭代强化学习的高效自监督推理", "title_en": "RoiRL: Efficient, Self-Supervised Reasoning with Offline Iterative Reinforcement Learning", "authors": "Aleksei Arzhantsev,Otmane Sakhi,Flavian Vasile", "background": "强化学习（RL）在提升大型语言模型（LLMs）的推理能力方面发挥着核心作用，但通常需要真实世界的反馈作为奖励。Test-Time Reinforcement Learning (TTRL) 可以避免这一需求，并使用多数投票奖励来代替真实反馈，但这种方法会带来大量的在线强化学习过程，并消耗大量的计算资源。", "innovation": "提出了一种名为 RoiRL 的轻量级离线学习方法，用于目标是同样正则化的最优策略。与 TTRL 不同，RoiRL 不需要维护一个参考模型，而是优化加权对数似然目标，从而实现更稳定和更低资源需求的训练过程。", "conclusion": "实验结果显示，RoiRL 在推理基准测试中训练速度提高了 2.5 倍，并且始终优于 TTRL，建立了在无需标签的情况下实现自改进 LLMs 的可扩展路径。"}
{"llm_update_time": "20251006", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.02810", "html_url": "https://arxiv.org/abs/2510.02810", "title": "解析变换器：朝向绿色AI的CLEAR视角", "title_en": "Dissecting Transformers: A CLEAR Perspective towards Green AI", "authors": "Hemang Jain,Shailender Goyal,Divyansh Pandey,Karthik Vaidhyanathan", "background": "大型语言模型（LLMs）的快速采用引发了一系列环境问题。与一次性的训练成本相比，LLM的推理过程在全球范围内持续进行，已然成为了人工智能能耗的主要贡献者。然而，大部分的可持续性研究仅仅报告粗略、基于模型的能耗指标，缺乏对细粒度测量方法的研究，导致在能耗效率上更多地被视为一种“附随品”，而非主要目标。本文首次通过细致的实验分析展示了Transformer架构核心组件的推理能耗情况。", "innovation": "本文提出了一种新的方法论，即Component-Level Energy Assessment via Repeated sampling (CLEAR)，用于解决微秒级组件执行与毫秒级能耗传感器监测之间的时间错配问题。通过CLEAR方法，我们对四个不同架构类型的15种模型进行了评估，而在各组件层面的能量变异保持在9.5%以下的同时，所捕获的模型总能耗超过了90%。实验发现，注意力模块每浮点运算的操作消耗的能量显著高于其它组件，表明浮点运算数量无法准确反映组件级别的实际能耗开销。这些发现为建立节能、具有细粒度优化的变换器模型奠定了基础。", "conclusion": "本文通过详实的实验分析为各组件级别的能耗基准建立了详细的数据基础，提供了初步的见解，为后续通过组件级别的优化来提升变换器模型的能耗效率提供了指引。"}
{"llm_update_time": "20251006", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.02823", "html_url": "https://arxiv.org/abs/2510.02823", "title": "State Space Models 在训练过程中压缩的现象", "title_en": "The Curious Case of In-Training Compression of State Space Models", "authors": "Makram Chahine,Philipp Nazari,Daniela Rus,T. Konstantin Rusch", "background": "状态空间模型（SSMs）被开发用于高效处理长期序列建模任务，可以实现并行训练和快速推理。其核心是递归动力系统，通过维护隐状态来工作，更新成本与状态维度成比例。关键设计挑战在于如何在最大化表达能力与限制计算负担之间取得平衡。控制理论，尤其是汉克尔奇异值分析，提供了一种衡量每个状态能量的有效框架，并且可以通过平衡截断原系统到更小的表示，同时保持性能保障来实现系统截断。", "innovation": "本文利用汉克尔矩阵的特征值稳定性特性，在训练过程中应用这一视角，识别并保留高影响维度，这种方法适用于线性时不变状态空间模型（如线性递归单元），并且可以扩展到选择性模型。实验表明，在训练过程中减少维度可以显著加速优化过程，同时保留表达能力。这意味着在训练过程中逐渐缩小的大型SSM实现了计算效率和高性能的结合。", "conclusion": "通过在训练过程中对状态空间模型进行压缩，可以在保持任务关键结构的前提下显著提高优化速度，并且保留模型的表达能力。大型SSM在训练过程中逐渐减小可以同时实现计算效率和更高性能。"}
{"llm_update_time": "20251006", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.02822", "html_url": "https://arxiv.org/abs/2510.02822", "title": "FlexiQ：深度神经网络中延迟/准确率权衡的自适应混合精度量化", "title_en": "FlexiQ: Adaptive Mixed-Precision Quantization for Latency/Accuracy Trade-Offs in Deep Neural Networks", "authors": "Jaemin Kim,Hongjun Um,Sungkyun Kim,Yongjun Park,Jiwon Seo", "background": "神经网络通常在NPUs和GPUs等硬件加速器上执行，因为它们的大小和计算开销。然而，这些加速器的成本较高，难以根据实时工作负载波动规模调整其资源。", "innovation": "FlexiQ提出了一种自适应混合精度量化方案，该方案根据不同特征通道的值范围选择性地应用低位宽计算，并通过一种有效的方法来最小化量化误差，同时保持推理准确性。此外，FlexiQ能够实时调整低位宽通道的比例，使量化模型能够有效地应对波动的推理工作负载。", "conclusion": "FlexiQ原型在定制的NPU和GPU上实现了混合精度推理运行时。在包括十一个卷积和变压器模型的评估中，FlexiQ实现了平均6.6%的4位模型精度提升（经过微调），并优于四种最先进的量化技术。此外，我们的混合精度模型实现了准确率和延迟之间的有效权衡：50%的4位模型仅导致0.6%的精度损失，同时比100%的4位模型快40%的速度，比8位模型快。在NPU和GPU上的延迟评估表明FlexiQ引入的运行时开销最小，证明了其硬件效率和整体性能优势。"}
{"llm_update_time": "20251006", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.02945", "html_url": "https://arxiv.org/abs/2510.02945", "title": "遍历风险度量：走向连续强化学习中的风险感知基础", "title_en": "Ergodic Risk Measures: Towards a Risk-Aware Foundation for Continual Reinforcement Learning", "authors": "Juan Sebastian Rojas,Chi-Guhn Lee", "background": "连续强化学习 (Continual RL) 力图形式化终身学习和持续适应的概念，在强化学习 (RL) 中寻求维持利用性信息和适应新情况之间的平衡。目前，大多数研究仅从风险无感知决策制定的角度探索了连续 RL，即代理旨在优化长期平均表现。本文首次从风险感知决策制定的角度对连续 RL 进行形式化的理论处理，其中代理旨在优化超越均值的基于奖励的长期表现衡量标准。", "innovation": "本文的创新之处在于首先指出当前的风险度量理论不适用于连续学习环境，并在此基础上引入了一类新的遍历风险度量，这种新的风险度量理论与连续学习兼容。通过引入新的风险度量理论，作者为连续 RL 提供了一个风险感知的基础。", "conclusion": "本文提出了遍历风险度量的概念，并通过案例研究和实证结果展示了这种新的风险度量理论的直观吸引力和理论合理性。这为连续 RL 的风险感知提供了新的理论基础。"}
{"llm_update_time": "20251006", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.02839", "html_url": "https://arxiv.org/abs/2510.02839", "title": "具备频率自适应学习的知识导向建模方法用于电池健康预测", "title_en": "Knowledge-Aware Modeling with Frequency Adaptive Learning for Battery Health Prognostics", "authors": "Vijay Babu Pamshetti,Wei Zhang,Sumei Sun,Jie Zhang,Yonggang Wen,Qingyu Yan", "background": "电池健康预测对于确保现代能源系统中的安全、效率和可持续性至关重要。然而，由于电池退化的复杂非线性行为、噪声、容量再生等因素，准确且稳健的预测一直具有挑战性。现有数据驱动的模型可以捕捉到时间退化特征，但通常缺乏知识指导，导致长期健康预测不可靠。", "innovation": "本文提出了一种名为Karma的知识感知模型，该模型结合频率自适应学习进行电池容量估算和剩余使用寿命预测。Karma通过信号分解提取不同频率范围的电池信号，并采用双流深层学习架构，分别捕获长期低频退化趋势和高频短期动力学。模型中知识指导了电池退化过程，基于经验研究将退化建模为双指数函数，并通过粒子滤波优化参数以确保物理一致性且可靠的预测和不确定性量化。实验结果表明，与现有最佳算法相比，Karma在两个主流数据集上的电池健康预测平均误差分别降低了50.6%和32.6%，突显了Karma的鲁棒性、泛化能力和在各种应用中更安全、更可靠电池管理的潜力。", "conclusion": "实验研究表明，Karma的性能优于现有最佳算法，在两个主流数据集上分别实现了50.6%和32.6%的平均误差减少。这表明Karma在确保电池安全、提高能源系统效率和可持续性方面具有鲁棒性、泛化能力和应用潜力。"}
{"llm_update_time": "20251006", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.02936", "html_url": "https://arxiv.org/abs/2510.02936", "title": "RAxSS: 检索增强稀疏采样，用于解释性变长医学时间序列分类", "title_en": "RAxSS: Retrieval-Augmented Sparse Sampling for Explainable Variable-Length Medical Time Series Classification", "authors": "Aydin Javadov,Samir Garibov,Tobias Hoesli,Qiyang Sun,Florian von Wangenheim,Joseph Ollier,Björn W. Schuller", "background": "医学时间序列分析由于数据稀疏、噪声以及高度可变的记录长度具有挑战性。以往的研究表明，随机稀疏采样能够有效地处理变长信号，而检索增强的方法则能提高解释性和对噪声及弱时间相关性的鲁棒性。", "innovation": "本文扩展了随机稀疏采样的框架以应用于检索指导分类。具体来说，该方法通过在概率空间中加权窗口预测并汇总生成凸形的时间级评分，并提供了一条明确的证据轨迹以增强解释性。该方法在颅内电极图（iEEG）记录中实现了竞争性的分类性能，并为临床从业者提供了更高的透明度和解释性。", "conclusion": "本文的方法在四个医学中心收集的iEEG记录中得到了评估，展现了其在可靠和解释性变长医学时间序列分类中的潜力。"}
{"llm_update_time": "20251006", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.02835", "html_url": "https://arxiv.org/abs/2510.02835", "title": "基于多模态生活日志数据的可解释个性化健康预测的主体自适应稀疏线性模型", "title_en": "Subject-Adaptive Sparse Linear Models for Interpretable Personalized Health Prediction from Multimodal Lifelog Data", "authors": "Dohyun Bu,Jisoo Han,Soohwa Kwon,Yulim So,Jong-Seok Lee", "background": "利用多模态生活日志数据精确预测个性化健康结果（如睡眠质量和压力）对临床和实践具有重要意义。然而，现有的最先进的模型主要依赖深度神经网络和梯度提升集成模型，这些模型虽然效果显著，但由于牺牲了可解释性，无法有效处理生活日志数据中固有的个体间显著差异。因此，这些模型的应用受到限制，无法为临床医生和实践者提供明确的操作建议和深入的见解.", "innovation": "本文提出了主体自适应稀疏线性（SASL）框架，这是一种专门为个性化健康预测设计的可解释建模方法。SASL将普通最小二乘法回归与个体自适应交互结合，系统地区分了全局效应和个体效应。通过嵌套的F检验进行迭代向后特征消除，构建了稀疏且统计上稳健的模型。对于连续过程的离散化健康结果，SASL提出了回归先验的阈值方法以最大化分宏均F1分数。对于难以预测的问题，SASL通过基于置信度的门控机制结合LightGBM模型进行选择性输出，以提高准确性和可解释性。在CH-2025数据集上的评估表明，SASL框架与复杂的黑箱方法相比，具有更好的预测性能，同时参数更少且透明度更高，为临床医生和实践者提供了清晰的操作见解.", "conclusion": "主体自适应稀疏线性（SASL）框架不仅保持了模型的解释性，还避免了过度复杂化的问题。通过在CH-2025数据集上的验证，该模型在预测性能、参数数量和透明度方面表现出优秀的表现，为个性化健康监测提供了强有力的方法支撑。"}
{"llm_update_time": "20251006", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.03016", "html_url": "https://arxiv.org/abs/2510.03016", "title": "从不精确监督学习鲁棒扩散模型", "title_en": "Learning Robust Diffusion Models from Imprecise Supervision", "authors": "Dong-Dong Wu,Jiacheng Cui,Wei Wang,Zhiqiang She,Masashi Sugiyama", "background": "近年来，条件扩散模型在各种生成任务中取得了显著成果，但其训练通常依赖于包含条件输入中不精确信息的大规模数据集。这些监督信息往往来自噪声、模糊或不完整标签，会导致条件不匹配并降低生成质量。", "innovation": "提出了DMIS（从不精确监督训练鲁棒扩散模型）统一框架，这是扩散模型领域内的首个系统研究。该框架基于似然最大化，并将目标分解为生成和分类两个部分：生成部分建模不精确标签分布，分类部分利用扩散分类器推断类别后验概率，并通过优化的时间步长采样策略提高了其效率。", "conclusion": "在各种不精确监督形成的任务中，包括图像生成、弱监督学习和嘈杂数据集凝练等多方面实验表明，DMIS能持续生成高质量且类别区分性强的样本。"}
{"llm_update_time": "20251006", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.03013", "html_url": "https://arxiv.org/abs/2510.03013", "title": "分布式的逆强化学习", "title_en": "Distributional Inverse Reinforcement Learning", "authors": "Feiyang Wu,Ye Zhao,Anqi Wu", "background": "传统的逆强化学习方法通常旨在恢复确定性奖励估计或仅与期望回报匹配，这些方法在捕捉专家行为中的丰富结构方面能力有限，尤其是在学习奖励分布方面。本文提出了一种分布式的逆强化学习框架，能够同时建模奖励函数的不确定性及回报的完整分布。这种框架适合进行行为分析和风险意识的模仿学习。", "innovation": "本文的方法通过最小化次序随机支配（FSD）偏差来捕捉专家行为的丰富结构，将失真风险度量（DRMs）引入到政策学习中，不仅恢复了奖励分布，还学习了分布感知的政策。实验结果表明，该方法恢复了富有表现力的奖励表示，并达到了最先进的模仿性能。", "conclusion": "本文提出了一个新的分布式的逆强化学习框架，能够更全面地学习和模仿专家行为中的奖励分布，从而提高了行为分析和风险意识模仿学习的效果。实验证明该方法的有效性，为后续研究和实际应用提供了有价值的参考。"}
{"llm_update_time": "20251006", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.02903", "html_url": "https://arxiv.org/abs/2510.02903", "title": "使用微分方程表示学习单细胞动态", "title_en": "Learning Explicit Single-Cell Dynamics Using ODE Representations", "authors": "Jan-Philipp von Bassewitz,Adeel Pervez,Marco Fumero,Matthew Robinson,Theofanis Karaletsos,Francesco Locatello", "background": "研究细胞分化的过程有助于推进对与这一过程相关的疾病（如癌症）的理解和治疗。随着单细胞数据集的快速增长，机器学习在这方面的应用变得特别具有前景和活跃。尽管目前最先进的模型能够处理这一任务，但由于这些模型依赖于计算成本高昂的最优传输预处理和多阶段训练，而且没有明确发现基因间的交互作用，因此存在改进的空间。因此，论文探讨了这一领域的创新解决方案。", "innovation": "该论文提出了一种名为Cell-Mechanistic Neural Networks (Cell-MNN)的编码-解码架构，其潜在表示是一个局部线性化的偏微分方程，通过这种方式能够指导细胞从干细胞到组织细胞演变的动力学过程。Cell-MNN能够在不依赖复杂预处理和多阶段训练的情况下实现端到端的学习，并且其偏微分方程表达式能够学习生物上一致性且易于解释的基因交互作用。实验结果表明，在单细胞基准测试中，Cell-MNN表现出了竞争力，能够更好地扩展和联合训练大尺寸数据集，并且能够学习与TRRUST基因交互数据库中相匹配的可解释基因交互作用。", "conclusion": "Cell-MNN模型成功解决了传统方法中的计算成本问题，并通过学习微分方程实现了对基因交互作用的直接建模，从而提高了模型的生物学解释性和泛化能力。通过在大规模单细胞数据上的实验证明了该模型的有效性和可靠性，在单细胞数据分析中提供了一种新的方法。"}
{"llm_update_time": "20251006", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.03004", "html_url": "https://arxiv.org/abs/2510.03004", "title": "BrainIB++: 结合图神经网络和信息瓶颈用于精神分裂症功能脑生物标志物", "title_en": "BrainIB++: Leveraging Graph Neural Networks and Information Bottleneck for Functional Brain Biomarkers in Schizophrenia", "authors": "Tianzheng Hu,Qiang Li,Shu Liu,Vince D. Calhoun,Guido van Wingen,Shujian Yu", "background": "诊断模型在精神疾病领域的开发逐渐受到关注。基于静息状态功能磁共振成像（rs-fMRI）的机器学习分类器已被开发用于识别区分精神疾病和对照组的大脑生物标志物。尽管传统的基于机器学习的诊断模型依赖于大量的特征工程，可能引入人为偏见，但深度学习模型缺乏解释性，导致难以获得能够支持诊断决策的可解释和可靠的脑生物标志物，从而限制其临床应用。", "innovation": "本研究提出了一种名为BrainIB++的端到端图神经网络框架，通过信息瓶颈原则在模型训练期间识别最具有信息量的数据驱动的大脑区域作为子图以供解释。该模型在三个多队列精神分裂症数据集中与九种已建立的大脑网络分类方法进行评估，表现出优越的诊断准确性和良好的泛化能力。此外，模型识别出的子图也与精神分裂症的已有临床生物标志物相吻合，尤其是在视觉、感觉运动和高级认知功能网络的异常方面。", "conclusion": "BrainIB++模型在功能性脑生物标志物的发现和临床诊断应用方面表现出色，通过可解释的子图识别提高了模型的可解释性，并强调了其在实际临床诊断中的应用价值。"}
{"llm_update_time": "20251006", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.02952", "html_url": "https://arxiv.org/abs/2510.02952", "title": "ContextFlow: 基于时空组学数据跟踪推断的上下文感知流匹配方法", "title_en": "ContextFlow: Context-Aware Flow Matching For Trajectory Inference From Spatial Omics Data", "authors": "Santanu Subhash Rathod,Francesco Ceccarelli,Sean B. Holden,Pietro Liò,Xiao Zhang,Jovan Tanevski", "background": "从纵向的时空分辨组学数据中推断轨迹对于理解结构和功能组织在发育、再生和修复、疾病进展以及治疗反应中的动态变化至关重要。现有方法在统计一致性方面虽表现出色，但在生物学意义方面仍需改进。我们提出了一种新的上下文感知流匹配框架——ContextFlow，它结合先验知识以指导从时空分辨组学数据中推断组织动态。该框架通过综合局部组织结构和配体-受体通信模式，生成更符合生物学意义的轨迹，使其成为一个适用于时空动态建模的通用框架。", "innovation": "ContextFlow 引入上下文感知机制，通过整合局部组织结构和配体-受体通信模式，生成不仅在统计上一致而且生物学上有意义的轨迹。通过多层次的评估，ContextFlow 在多个定量和定性指标上均优于现行的流匹配方法，证明了其优越性。", "conclusion": "ContextFlow 是一个应用于纵向时空分辨组学数据的通用建模方法，它通过结合局部组织结构和配体-受体通信模式，生成符合生物学意义的轨迹，提升了轨迹推断的准确性和生物学意义。"}
{"llm_update_time": "20251006", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.02956", "html_url": "https://arxiv.org/abs/2510.02956", "title": "基于置信度与分散性信号的无监督模型评估与排名", "title_en": "Confidence and Dispersity as Signals: Unsupervised Model Evaluation and Ranking", "authors": "Weijian Deng,Weijie Tu,Ibrahim Radwan,Mohammad Abu Alsheikh,Stephen Gould,Liang Zheng", "background": "在实际部署中，评估模型泛化能力在未提供标记测试数据的情况下尤为重要。本文研究了在两种典型部署场景下无监督模型评估和排名的统一框架：一是估算固定模型在多个未标记测试集上的准确性（数据集为中心的评估），二是对单个未标记测试集上的候选模型进行排名（模型为中心的评估）", "innovation": "本文发现模型预测的置信度和分散性能够为泛化提供有力且互补的信号。系统性地评估了一系列基于置信度、分散性和混合的度量指标，涵盖多种模型架构、数据集和数据分布偏移类型。研究结果显示，混合度量在数据集为中心和模型为中心的评估情况下表现均优于单一指标，特别是在预测矩阵的核范数在各种任务中提供了鲁棒且准确的性能表现，即使在中度类别不平衡时也能保持可靠性", "conclusion": "本文的研究为部署场景下的无监督模型评估提供了实用和可推广的基础。置信度与分散性的度量指标为模型泛化的无监督评估提供了可靠工具，这些结论对于实际应用中的模型选择和评估具有重要意义"}
{"llm_update_time": "20251006", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.03064", "html_url": "https://arxiv.org/abs/2510.03064", "title": "参数化动作演员评论强化学习算法在网页搜索匹配计划生成中的比较分析", "title_en": "Comparative Analysis of Parameterized Action Actor-Critic Reinforcement Learning Algorithms for Web Search Match Plan Generation", "authors": "Ubayd Bapoo,Clement N Nyirenda", "background": "该研究评估了软演员评论（SAC）、贪婪演员评论（GAC）和截断分位数评论者（TQC）在完全可观测环境中的高性能表现，特别是在高维决策任务中。研究的重点是参数化动作空间（PA），无需依赖循环网络，使用Platform-v0和Goal-v0基准测试离散动作与连续动作参数空间的联系，通过Microsoft NNI进行超参数优化，确保代码修改后的再现性。", "innovation": "研究通过使用参数化动作贪婪演员评论（PAGAC）实现了在多个基准测试中的最快训练时间和最高回报。相较于PASAC和PATQC，PAGAC展示了更高的效率和可靠性，特别适用于需要快速收敛和稳健性能的任务。未来研究可能探索结合熵正则化与截断方法的混合策略，以增强稳定性并进一步研究泛化能力。", "conclusion": "PAGAC在多种基准测试中表现出色，尤其是在复杂动作空间中提供了速度和稳定性的明显优势。它被证明是需要快速收敛和稳健性能的任务的理想选择。未来研究可以进一步探究结合熵正则化和截断方法的混合策略以增强算法的稳定性并考察其泛化能力。"}
{"llm_update_time": "20251006", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.03046", "html_url": "https://arxiv.org/abs/2510.03046", "title": "关于具有迭代重构多体消息传递的E(3)-齐性贝叶斯原子间势的研究", "title_en": "Bayesian E(3)-Equivariant Interatomic Potential with Iterative Restratification of Many-body Message Passing", "authors": "Soohaeng Yoo Willow,Tae Hyeon Park,Gi Beom Sim,Sung Wook Moon,Seung Kyu Min,D. ChangMo Yang,Hyun Woo Kim,Juho Lee,Chang Woo Myung", "background": "机器学习势（MLPs）已成为大规模原子级模拟中的关键工具，能够提供近似第一性原理的准确性同时具备计算效率。然而，当前MLPs在不确定性量化方面的不足限制了它们在活性学习、校准和异常分布（OOD）检测中的可靠性。", "innovation": "开发了具有E(3)对称性和迭代重构多体消息传递的贝叶斯MLPs。引入了联合能量-力负对数似然（NLL_JEF）损失函数，该函数显式地建模了能量和原子间力的不确定性，提升了模型的准确性。系统地对比了多种贝叶斯方法，包括深度集成、随机权重平均高斯模型、改进的在线牛顿变分方法和拉普拉斯近似，评估了这些方法在不确定性预测、OOD检测、校准和活性学习任务中的表现。NLL_JEF使得能量和力的不确定性量化得以实现，从而优化了活性学习过程，并通过贝叶斯活性学习不一致（BALD）方法优于随机抽样和基于能量不确定性抽样。", "conclusion": "贝叶斯MLPs在保持与其最佳性能模型竞争的同时，实现了不确定性引导的活性学习、OOD检测和能/力校准。这项研究为大规模原子级模拟中的不确定性感知MLPs建立了强大的框架，具有E(3)对称性的贝叶斯神经网络是一个有效的工具。"}
{"llm_update_time": "20251006", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.03038", "html_url": "https://arxiv.org/abs/2510.03038", "title": "CHORD: 自适应混合精度跨设备模型的序列推荐定制方法及其设备-云协作", "title_en": "CHORD: Customizing Hybrid-precision On-device Model for Sequential Recommendation with Device-cloud Collaboration", "authors": "Tianqi Liu,Kairui Fu,Shengyu Zhang,Wenyan Fan,Zhaocheng Du,Jieming Zhu,Fan Wu,Fei Wu", "background": "随着移动设备功能的增强，直接在设备上部署排重模型变得可行，使实时上下文推荐成为可能。然而，当将模型从云端迁移到设备时，资源异构性不可避免地需要模型压缩。尽管最近的量化方法在高效部署方面显示出潜力，但这些方法忽视了设备特定的用户兴趣，从而导致推荐准确性下降。为了解决这些问题，因此需要一种结合个性化和资源适应性部署的模型压缩方法。", "innovation": "本文提出了一种名为CHORD的框架，利用通道级混合精度量化，同时实现个性化和资源适应性部署。该框架将随机初始化的模型分散到异构设备上，并通过云上的辅助超网络模块来识别用户特定的关键参数。通过对多个粒度（层、滤波器和元素级别）进行参数敏感性分析，实现用户画像到量化策略的精确映射。通过在设备上进行混合精度量化，CHORD 实现了动态模型适应，并在无反向传播的情况下加速推理，消除了昂贵的重训循环。通过使用2位/通道而非32位权重来编码量化策略，最大程度地减少了通信开销。", "conclusion": "实验在三个真实数据集上使用两个流行的骨干网络（SASRec和Caser）表明，CHORD在准确度、效率和适应性方面表现出色。"}
{"llm_update_time": "20251006", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.03096", "html_url": "https://arxiv.org/abs/2510.03096", "title": "图神经网络中的自适应节点特征选择", "title_en": "Adaptive Node Feature Selection For Graph Neural Networks", "authors": "Ali Azizpour,Madeline Navarro,Santiago Segarra", "background": "在图神经网络（GNNs）中，能够测量特征如何影响模型输出的能力对于解释决策、减少维度以及通过消除无用变量来提高性能至关重要。然而，结构化的图数据引入了复杂的依赖关系，这可能不适合传统特征重要性的度量方法。", "innovation": "本文提出了一种基于模型和任务的自适应节点特征选择方法，在训练过程中根据特征值置换后的验证性能变化来确定相关特征。这种方法不仅在训练结束后返回特征的重要性评分，还能追踪特征依次被移除时相关性的变化。研究结果证明了该方法在不同图结构的适应性和在更具有挑战性的图学习环境中的适应性。", "conclusion": "实验结果验证了该方法在不同图架构中的灵活性以及在更复杂图学习环境中的适用性。通过特征值的置换以及验证性能变化的方法，不仅可以监控特征的有效移除，还可以评估其他相关的度量标准。"}
{"llm_update_time": "20251006", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.03065", "html_url": "https://arxiv.org/abs/2510.03065", "title": "一种用于近似旅行商问题的统一深度强化学习方法", "title_en": "A Unified Deep Reinforcement Learning Approach for Close Enough Traveling Salesman Problem", "authors": "Mingfeng Fan,Jiaqi Cheng,Yaoxin Wu,Yifeng Zhang,Yibin Yang,Guohua Wu,Guillaume Sartoretti", "background": "近年来，深度强化学习（DRL）在解决NP难的旅行商问题（TSP）方面取得了显著进展。然而，对贴近点旅行商问题（CETSP）的研究较少，主要由于其基于邻域的访问准则带来的挑战，即节点在代理进入其邻域后才被视为访问。", "innovation": "本文通过使用离散化方案，将CETSP建模为马尔可夫决策过程（MDP），并提出了一种新颖的双重解码器DRL（UD3RL）框架，该框架将决策过程细分为节点选择和路径点确定。引入了k最近邻子图交互策略以增强位置解码期间的空间推理能力。此外，针对UD3RL模型专门定制了REINFORCE算法，以实现统一模型训练，该模型能够在不同问题规模、不同邻域半径类型（固定和随机）之间通用。", "conclusion": "实验结果表明，UD3RL在解的质量和运行时间上均优于传统方法，并且在问题规模、空间分布和半径范围上表现出强大的泛化能力，同时具有动态环境中的鲁棒性。"}
{"llm_update_time": "20251006", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.03027", "html_url": "https://arxiv.org/abs/2510.03027", "title": "通过平衡有符号图算法展开实现轻量级EEG分类的变压器", "title_en": "Lightweight Transformer for EEG Classification via Balanced Signed Graph Algorithm Unrolling", "authors": "Junyi Yao,Parham Eftekhar,Gene Cheung,Xujin Chris Liu,Yao Wang,Wei Hu", "background": "脑电图（EEG）信号在癫痫患者和健康受试者之间存在固有的反相关性，可以通过有限图中的负边缘来建模。通过使用光谱去噪算法处理在平衡有符号图上的EEG信号，构建了轻量级且可解释的变压器式神经网络，从而有效区分癫痫患者和健康人群。平衡有符号图具有可以通过图拉普拉斯矩阵相似变换映射到正图的明确频率。", "innovation": "提出了一种通过展开平衡有符号图算法构建的轻量级变压器式神经网络，专门用于EEG信号分类。该方法能够利用平衡有符号图的平衡特性，通过光谱去噪算法优化地对EEG信号进行处理，同时实现轻量级和高解释性。特别地，通过Lanczos近似高效实现理想的低通滤波器，并学习最优截止频率，从而有效地减少了参数数量，但仍然达到与代表性的深度学习方案相当的分类性能。", "conclusion": "在实验中，该方法的分类性能与代表性的深度学习方案相当，然而，使用了大幅减少的参数。表明该方法在保持效果的同时具有更好的效率和易解释性。"}
{"llm_update_time": "20251006", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.03121", "html_url": "https://arxiv.org/abs/2510.03121", "title": "城市铁路系统中实时头间距预测及其对服务控制的影响：一种深度学习方法", "title_en": "Real Time Headway Predictions in Urban Rail Systems and Implications for Service Control: A Deep Learning Approach", "authors": "Muhammad Usama,Haris Koutsopoulos", "background": "城市地铁系统的高效实时调度对于保障服务可靠性、最大化资源利用率以及提升乘客满意度至关重要。", "innovation": "提出了一种基于卷积长短期记忆（ConvLSTM）模型的新型深度学习框架，用于预测整条地铁线路上列车头间距的复杂时空传播。模型直接将计划终点头间距作为关键输入，并结合历史头间距数据，准确预测未来头间距动态，有效捕捉其时间演化和空间依赖性。此外，该方法还允许调度员无须依赖计算密集型仿真即可评估各种终点头间距控制决策的影响，提供灵活的方法模拟多种调度策略。", "conclusion": "在大规模城市地铁线路上验证的ConvLSTM模型显示出有希望的头间距预测结果，并提供了实时决策中的可操作性见解。该框架为铁路运营商提供了高效的调度策略优化工具，显著提高了服务一致性和乘客满意度。"}
{"llm_update_time": "20251006", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.03003", "html_url": "https://arxiv.org/abs/2510.03003", "title": "从高频传感器到 Noon 报告：利用迁移学习进行船舶主机功率预测", "title_en": "From high-frequency sensors to noon reports: Using transfer learning for shaft power prediction in maritime", "authors": "Akriti Sharma,Dogan Altan,Dusica Marijan,Arnbjørn Maressa", "background": "随着全球海上运输的发展，能源优化变得至关重要，以降低成本并确保操作效率。主机功率是指从发动机传送到螺旋桨轴的机械功率，直接影响燃料消耗，因此准确预测主机功率对于优化船舶性能来说至关重要。主机功率的消耗与船速、转速以及天气和海况等因素高度相关。高频访问这些操作数据可以提高预测准确性，但也常常由于高质量传感器数据难以获取且成本高昂而导致难以实现。为了克服这些挑战，本文提出了一种基于迁移学习的方法，在先对高频传感器数据进行预训练的基础上，再利用来自其他船只的低频常规午报告数据进行微调。实验结果表明，与仅使用常规午报告数据训练的模型相比，在姐妹船、类似船和不同船上的测试，预测误差分别降低了10.6%、3.6%和5.3%。", "innovation": "本文提出了一种基于迁移学习的方法，通过高频数据预训练，再利用低频常规午报告数据进行微调，以预测船舶主机功率。这种方法能够有效利用不同船只间的共性和差异，提高预测准确性。特别是在数据获取困难的情况下，这种方法提供了一种新的解决方案.", "conclusion": "研究结果表明，本文提出的迁移学习方法能够有效降低预测主机功率的误差，特别是在不同尺寸和配置的船只之间。这种方法不仅能够提高预测的准确性，还为船舶能源优化提供了新的途径。"}
{"llm_update_time": "20251006", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.03051", "html_url": "https://arxiv.org/abs/2510.03051", "title": "ZeroShotOpt：向泛化预训练模型高效的黑盒优化迈进", "title_en": "ZeroShotOpt: Towards Zero-Shot Pretrained Models for Efficient Black-Box Optimization", "authors": "Jamison Meindl,Yunsheng Tian,Tony Cui,Veronika Thost,Zhang-Wei Hong,Johannes Dürholt,Jie Chen,Wojciech Matusik,Mina Konaković Luković", "background": "全球优化昂贵且无导数的黑盒函数需要极端的样本效率。目前最先进的方法是贝叶斯优化(BO)，但其性能依赖于往往是手动调整且难以跨问题地形普适化的先验和获取函数超参数。", "innovation": "我们提出了ZeroShotOpt，这是一种适用于从2D到20D连续黑盒优化任务的一般预训练模型。该方法通过大规模优化轨迹的离线强化学习，利用多样景观的合成高斯过程函数进行预训练，确保模型能学习到可迁移的优化策略。最终，ZeroShotOpt在广泛未见基准上实现了稳健的零样本泛化，样本效率匹敌或超过领先全局优化器，并提供了未来扩展和改进的基础。", "conclusion": "ZeroShotOpt实现了广泛的未见基准上的稳健零样本泛化，匹敌或超越领先的全局优化器的样本效率，同时为未来的扩展和改进提供了一种可重复的基础。开源代码、数据集和模型可在指定链接获取。"}
{"llm_update_time": "20251006", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.03021", "html_url": "https://arxiv.org/abs/2510.03021", "title": "Differential隐私Wasserstein中值", "title_en": "Differentially Private Wasserstein Barycenters", "authors": "Anming Gu,Sasidhar Kunapuli,Mark Bun,Edward Chien,Kristjan Greenewald", "background": "Wasserstein barycenter定义为概率测度集下的最优传输度量下的均值，并在机器学习、统计学和计算机图形学等领域有着广泛应用。在实践中，这些输入测度是通过敏感数据集构建而成的经验分布，因此需要使用差分隐私(DP)来处理。在以往的文献中，尚未有针对隐私保护的Wasserstein barycenter算法的现有方法。", "innovation": "该研究提出了第一个在差分隐私(DP)框架下的Wasserstein barycenter计算算法。在合成数据、MNIST和大规模美国人口数据集上的实验证明，该方法可以生成高质量的私有barycenter，具有较强的准确性和隐私性平衡。", "conclusion": "本研究展示了如何在保留数据隐私的前提下计算Wasserstein barycenter，这对于处理敏感数据的统计分析具有重要意义。实验结果表明，该方法能够较好地平衡数据准确性与隐私保护之间的关系。"}
{"llm_update_time": "20251006", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.03129", "html_url": "https://arxiv.org/abs/2510.03129", "title": "资产分配中的签名引导变换器", "title_en": "Signature-Informed Transformer for Asset Allocation", "authors": "Yoontae Hwang,Stefan Zohren", "background": "在定量金融中，稳健的资产分配是一项关键挑战，深度学习预测器常因目标不匹配和误差放大而失败。资产动态的丰富几何表示以及嵌入金融归纳偏置（例如领先-滞后效应）对于风险敏感的资本分配至关重要，但传统的和深度学习的基础方法常常无法实现这一目标。", "innovation": "提出了Signature-Informed Transformer (SIT)这一新颖框架，通过直接优化具有风险意识的金融目标来学习端到端的分配策略。SIT的核心创新包括路径签名（用于丰富的资产动态几何表示）和通过增强注意力机制嵌入金融归纳偏置（如领先-滞后效应）的方法。", "conclusion": "在日度标准普尔100指数数据上的评估表明，SIT显著优于传统和深度学习基线，特别是在与预测-然后优化模型的比较中。这些结果表明，对于机器学习系统中的风险意识资本分配，具有投资组合意识目标和几何意识归纳偏置是必不可少的。项目代码可从此链接下载：this https URL"}
{"llm_update_time": "20251006", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.03101", "html_url": "https://arxiv.org/abs/2510.03101", "title": "AdaBet：无需梯度的层选择方法用于深度神经网络高效训练", "title_en": "AdaBet: Gradient-free Layer Selection for Efficient Training of Deep Neural Networks", "authors": "Irene Tenison,Soumyajit Chatterjee,Fahim Kawsar,Mohammad Malekzadeh", "background": "在边缘和移动设备上利用预训练的神经网络时，通常需要在有限的计算和内存资源下高效地适应用户特定的运行时数据分布。通过目标数据集进行设备内重新训练可以促进这种适应，但现代深度神经网络的深度增加和梯度优化的计算开销使得这种方式变得不切实际。当前减少训练成本的方法是选择部分层进行重新训练，但它们依赖于标记数据、完整的模型反向传播或通过服务器端元训练；这些方法限制了在约束设备上的适用性。因此，在边缘和移动设备上进行深度神经网络的有效训练仍然具有挑战性。", "innovation": "引入了AdaBet，一种无需梯度的层选择方法，通过分析激活空间的拓扑特征（贝蒂数）及其前端传递特性来选择具有高学习能力的重要层，无需依赖标签或梯度。AdaBet在六对基准模型和数据集上的评估表明，与基于梯度的方法相比，它在分类精度上平均提高了5%的同时降低了40%的峰值内存消耗。", "conclusion": "AdaBet通过分析激活空间的拓扑特征，并仅使用前向传递来排名重要层，实现了在有限资源条件下高效的深度神经网络训练，且不依赖于标记数据或梯度优化，从而提高了分类准确率并降低了内存消耗。"}
{"llm_update_time": "20251006", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.03164", "html_url": "https://arxiv.org/abs/2510.03164", "title": "为何需要预热？一个理论视角", "title_en": "Why Do We Need Warm-up? A Theoretical Perspective", "authors": "Foivos Alimisis,Rustem Islamov,Aurelien Lucchi", "background": "学习率预热（在训练开始时增加学习率）已成为现代深度学习中无处不在的经验法则，但其理论基础仍不清楚。本文提供了一个原理性解释，说明为何预热可以改善训练效果。研究表明，在具有$L_0, L_1$光滑性条件的一般形式下，该条件限制局部曲率作为一个关于损失亚优性的线性函数，并具有理想的封闭性质。证明了这一假设适用于常用神经网络结构，在均方误差和交叉熵损失下的训练情况。这一条件下，证明了预热调度下的梯度下降比固定步长下的更快收敛，同时提供了上界和下界复杂性界限，并通过语言和视觉模型实验验证了理论洞察，确认了预热策略的实际益处。", "innovation": "提出了一种$（L_0, L_1）$光滑性条件的一般形式，该条件不仅限制局部曲率作为一个关于损失亚优性的线性函数，还具有理想的封闭性质，为解释预热的好处提供了理论基础。证明了在这一假设下的梯度下降预热比固定步长更快地收敛，并且提供了复杂性边界分析。", "conclusion": "实验结果验证了预热策略的实际优势，证明了其理论分析的有效性，并为未来研究提供了指导。"}
{"llm_update_time": "20251006", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.03134", "html_url": "https://arxiv.org/abs/2510.03134", "title": "通过多叙事精炼和知识蒸馏增强可解释AI的叙述", "title_en": "Enhancing XAI Narratives through Multi-Narrative Refinement and Knowledge Distillation", "authors": "Flavio Giorgi,Matteo Silvestri,Cesare Campagnano,Fabrizio Silvestri,Gabriele Tolomei", "background": "可解释的人工智能已经成为一项重要的研究领域，其目标是揭示深度学习模型的决策过程。反事实解释作为各种可解释性技术中的一种，被认为特别有前景，因为它们通过强调最小更改来改变预测，从而提供有关模型行为的见解。然而，这些解释通常复杂且难以被非专家理解。鉴于此，本文提出了一种新的管道，利用大模型和小模型来组合反事实解释的叙述。", "innovation": "该研究引入了一种 pipeline，使用知识蒸馏技术和精炼机制，使小语言模型能够类似地执行大型模型的任务，同时保持强大的推理能力。此外，该研究还提出了一种简单的评估方法来评估自然语言叙述，以验证模型的响应是否与事实和反事实的现实情况相符。这种 pipeline 既增强了学生的推理能力，又提高了它们在现实世界用例中的表现，使其更加实用。", "conclusion": "结果表明，所提出的 pipeline 不仅增强了学生模型的推理能力，同时也提高了它们的实用表现，使它们更适合实际应用场景。"}
{"llm_update_time": "20251006", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.03095", "html_url": "https://arxiv.org/abs/2510.03095", "title": "Score Distillation驱动的蛋白质骨架生成", "title_en": "Distilled Protein Backbone Generation", "authors": "Liyang Xie,Haoran Zhang,Zhendong Wang,Wesley Tansey,Mingyuan Zhou", "background": "扩散和流基生成模型在蛋白质主链生成任务中表现出强大的性能，为从头设计蛋白质提供了前所未有的能力。然而，这些模型在生成速度上受限，通常需要数百个逆向扩散过程迭代步骤。这一计算瓶颈限制了它们在大规模蛋白质发现中的实用性，因为需要成千上万甚至数百万种候选结构。", "innovation": "我们探索了得分蒸馏的技术，这是一种在视觉领域中大大减少了采样步骤数量但同时保持高生成质量的方法。我们发现如何适当地将最先进的得分数身份蒸馏（SiD）策略应用于训练少量步骤的蛋白质骨架生成模型，显著减少了采样时间，同时保持与预训练教师模型相当的性能。关键的是，多步生成与推理时间噪声调制的结合。结果显示，我们的蒸馏少量步骤生成器实现了超过20倍的采样速度提升，同时在设计性、多样性和新颖性方面达到了类似教师模型Proteina的水平。这减少了推理成本，使得从头蛋白质设计大规模化，从而将扩散基模型推向了实际蛋白质工程应用的前沿。", "conclusion": "我们的研究展示了如何通过适当地使用得分蒸馏技术进行少步骤蛋白质骨架生成，大幅提升了采样速度，同时保持了高质量的设计性，从而为大规模虚拟蛋白质设计提供了可行性，更接近于实际的蛋白质工程应用。"}
{"llm_update_time": "20251006", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.03086", "html_url": "https://arxiv.org/abs/2510.03086", "title": "连续GNNs在组合图对齐中的递推学习", "title_en": "Bootstrap Learning for Combinatorial Graph Alignment with Sequential GNNs", "authors": "Marc Lelarge", "background": "图神经网络（GNNs）在组合问题上难以超越传统的优化方法，限制了其实际应用效果。论文通过介绍一种新型的链式处理方法，解决了图对齐问题，这是一个关键的NP难问题，涉及通过仅使用结构信息找到无标号图之间的最优节点对应关系。这种方法旨在通过连续训练GNN序列，每一代GNN学习逐步完善上一代生成的相似性矩阵，从而在推断阶段创建一个递推效果：每个GNN通过整合先前迭代中关于节点对齐质量的离散排序信息来改进部分解决方案。这种方法与强大的节点对架构相结合，能够捕捉标准消息传递网络无法表示的全局结构模式，从而对齐问题至关重要。", "innovation": "引入了连续堆叠的GNNs，基于递推学习机制，用于解决图对齐问题。这种方法通过每一代GNN逐步细化相似性矩阵，并在推断阶段增强了节点对齐的质量，特别地，通过计算每个节点对的概率排序，能够更好地捕捉全局结构模式。实验结果表明，与现有方法相比，该方法在合成基准上的准确率提高超过3倍，并且能够解决传统优化方法无法解决的正则图问题。", "conclusion": "该方法结合了传统的优化处理，显著超越了最先进的图对齐求解器。通过将这种递推学习框架与传统优化相结合，可以在实际应用中实现高精度的图对齐。"}
{"llm_update_time": "20251006", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.03186", "html_url": "https://arxiv.org/abs/2510.03186", "title": "神经表示中的叠加解缠揭示隐藏的对齐", "title_en": "Superposition disentanglement of neural representations reveals hidden alignment", "authors": "André Longon,David Klindt,Meenakshi Khosla", "background": "叠加假设指出，单个神经元群体中的神经元可同时参与多种特征的表示，从而使得该群体能够表示比神经元数量更多的特征。代表对齐度量用于衡量不同深度神经网络（DNN）或大脑在表示相似信息方面的程度。本文探讨了一个关键问题：叠加会以任何不希望的方式干扰代表对齐度量吗？研究假设表示相同特征但在不同叠加排列中的模型，其神经元具有不同的特征线性组合，会干扰预测映射度量（半匹配、软匹配、线性回归），导致实际较低的对齐度。", "innovation": "本文开发了一种理论，解释严格排列度量如何依赖于叠加排列。通过训练稀疏自编码器（SAEs）在玩具模型中区分叠加，证明了在同一模型基神经元被稀疏超完备潜在代码替代时，对齐分数通常增加。这一结果在视觉领域DNN到DNN以及DNN到大脑的线性回归关联度量中也得到了类似增加。", "conclusion": "我们的结果表明，为了映射度量可以揭示神经编码之间的真正对齐程度，需要对叠加进行解缠。"}
{"llm_update_time": "20251006", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.03162", "html_url": "https://arxiv.org/abs/2510.03162", "title": "Calibrated Uncertainty Sampling for Active Learning", "title_en": "Calibrated Uncertainty Sampling for Active Learning", "authors": "Ha Manh Bui,Iliana Maifeld-Carucci,Anqi Liu", "background": "在基于池的主动学习（AL）中，模型不确定性是最受欢迎的获取函数（Acquisition Functions, AFs）。然而，未校准的不确定性模型会影响AF的有效性，导致泛化性能不佳和高未见过数据的校准误差。深度神经网络（DNNs）加剧了这一问题，因为DNN的不确定性通常未校准。", "innovation": "提出了一种新的获取函数，通过估计校准误差并优先查询具有最高校准误差的样本，然后再利用DNN的不确定性进行学习。具体的实现是利用协变量移移下的核校准误差估计器，并形式化证明使用此获取函数的AL最终会在未标记的池数据和未见过的测试数据上获得有界的校准误差。实验结果表明，相较于其他基线方法，该方法在基于池的主动学习设置中具有更低的校准误差和泛化误差。", "conclusion": "通过估计和利用校准误差，提出了一个新的获取函数，在主动学习场景下有效降低了未标记数据和未见过数据的校准误差和泛化误差。"}
{"llm_update_time": "20251006", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.03151", "html_url": "https://arxiv.org/abs/2510.03151", "title": "许多零计算专家的混合：高速率量化理论视角", "title_en": "Mixture of Many Zero-Compute Experts: A High-Rate Quantization Theory Perspective", "authors": "Yehuda Dar", "background": "本文利用经典高量化率量化理论来深入探讨回归任务中混合专家模型（MoE）的新见解。MoE模型通过将输入空间划分为独立区域，并在每个区域内有一个单参数专家作为零计算的常数预测器来定义。本文基于高量化率量化理论假设，假设专家的数量足够大，使得它们的输入空间区域非常小，从而研究MoE模型的逼近误差，包括在单维输入和多维输入情况下的表述。此外，当给定输入空间划分时，探讨专家参数的学习和统计性质，以此理论和实证上展示MoE学习中逼近误差和估计误差之间的权衡如何随专家数量的变化而变化。", "innovation": "本文从高量化率量化理论视角研究MoE模型，特别关注在有足够大数量专家的情况下，输入空间区域非常小的情况。研究其逼近误差，并在单维和多维输入情况下制定测试误差的表达式。此外，探讨在给定输入空间划分的情况下，专家参数的统计学习性质。", "conclusion": "文章展示了MoE学习中逼近误差和估计误差之间的权衡如何依赖于专家的数量，并且通过理论和实验证明了该关系。"}
{"llm_update_time": "20251006", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.03207", "html_url": "https://arxiv.org/abs/2510.03207", "title": "在部分可观测强化学习中精炼或决定？理解算法权衡", "title_en": "To Distill or Decide? Understanding the Algorithmic Trade-off in Partially Observable Reinforcement Learning", "authors": "Yuda Song,Dhruv Rohatgi,Aarti Singh,J. Andrew Bagnell", "background": "部分可观测性是强化学习中一个著名的挑战，因为需要学习复杂的、依赖于历史的策略。近期的实证研究表明，利用可用的潜在状态信息（例如来自模拟器）通过专家精炼来学习和模仿最优的潜在的、马尔可夫策略，从而能够将“学习观察”与“学习行动”任务区分开来。尽管专家精炼比没有潜在状态信息的强化学习更高效，但它也存在已知的问题。", "innovation": "本文通过一个简单的理论模型（扰动块MDP）和对具有挑战性的模拟运动任务进行受控实验，研究有特权信息的专家精炼与标准RL之间的算法权衡。主要发现包括：(1) 实验结果在潜在动力学的随机性上表现出偏差，这与扰动块MDP中的近似可译性与信念收缩理论预测相符；(2) 最优的潜在策略并不总是最好的用于传递的学习策略。研究表明，在许多部分可观测的实践中，高效利用特权信息的方法。", "conclusion": "研究表明，在部分可观测强化学习中，专家精炼与标准RL算法之间存在着算法权衡。主要发现揭示了潜在动力学随机性在实验中的作用，并指出最优的潜在策略并不总是最适合用于精炼的策略。这些结果为有效利用特权信息提供了新的指导原则，有助于提升策略学习的效率。"}
{"llm_update_time": "20251006", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.03185", "html_url": "https://arxiv.org/abs/2510.03185", "title": "PRISM-Physics: 基于因果DAG的过程评估方法物理推理", "title_en": "PRISM-Physics: Causal DAG-Based Process Evaluation for Physics Reasoning", "authors": "Wanjia Zhao,Qinwei Ma,Jingzhe Shi,Shirley Wu,Jiaqi Han,Yijia Xiao,Si-Yuan Chen,Xiao Luo,Ludwig Schmidt,James Zou", "background": "竞赛式的推理基准在数学和编程评估中取得了进展，但在物理学领域，此类基准的探索相对较少。现有的物理基准主要评估最终答案，而忽略了推理过程；而近期的一些分步方法则依赖启发式的LLM评分机制或线性的假设，这限制了其可靠性和诊断的有效性。", "innovation": "本文引入了PRISM-Physics框架，为复杂物理推理问题提供了一个过程级别的评估基准。解决方案用有向无环图（DAG）来表示公式，明确编码中间步骤之间的因果依赖关系，实现细粒度的、可解释的和基于理论的评分。证明了DAG表示的最优性和相应的评分策略，并结合我们开发的基于规则的方法进行符号公式等价匹配，确保评分的一贯性。实验表明，该评估框架更符合专家的评分标准；而步骤级别的评分不仅可以提供诊断上的见解，还能为后续训练提供丰富的信号。通过结构严谨性、理论保障和符号验证的结合，PRISM-Physics为过程级别的评估提供了原则性的基础，并有助于指导具有更深入科学推理能力模型的发展。", "conclusion": "PRISM-Physics提供了评估物理推理过程的新框架，不同于现有方法，它能够更全面地捕捉推理过程，确保评分的可靠性和有效性；通过这些特性，它可以指导未来模型能力的提升。"}
{"llm_update_time": "20251006", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.03165", "html_url": "https://arxiv.org/abs/2510.03165", "title": "FTTE：资源受限设备上的联邦学习", "title_en": "FTTE: Federated Learning on Resource-Constrained Devices", "authors": "Irene Tenison,Anna Murphy,Charles Beauville,Lalana Kagal", "background": "联邦学习（FL）能够在保护数据隐私的同时，在分布式设备之间协作训练模型，但其在资源受限的边缘节点上的部署仍然具有挑战性，因为这些节点的内存，能源和通信带宽有限。传统的同步和异步联邦学习方法还受到由慢节点导致的延迟和异构、大规模网络中的缓慢收敛问题的影响。", "innovation": "FTTE提出了一种新颖的半异步联邦学习框架，它独特地使用了稀疏的参数更新，并基于客户端更新的年龄和方差进行了衰减加权聚合。FTTE在包括多达500个客户端和90%慢节点的广泛模型和数据分布实验中，展示了相比于同步联邦学习81%更快的收敛速度、80%更低的本地设备内存使用率和69%的通信负载减少，同时还能够在挑战性环境中实现与半异步联邦学习相当或更高的目标精度。", "conclusion": "FTTE被确立为第一个适用于异构和主要资源受限边缘设备的实用且可扩展的联邦学习部署解决方案。"}
{"llm_update_time": "20251006", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.03181", "html_url": "https://arxiv.org/abs/2510.03181", "title": "非平稳强化学习中的具有变换觉知的上置信边界Q学习", "title_en": "Q-Learning with Shift-Aware Upper Confidence Bound in Non-Stationary Reinforcement Learning", "authors": "Ha Manh Bui,Felix Parker,Kimia Ghobadi,Anqi Liu", "background": "研究在有限时期和无限时期的马尔可夫决策过程（MDP）中，当环境分布发生变化时的非平稳强化学习问题。在这种情况下，转移函数可能在某一时期突然变化，或者当智能体与环境交互时任意时间步发生变换。传统的Q-learning上置信边界（UCB，Upper Confidence Bound）算法可以在学习过程中发现合适的策略，但由于分布变化，该策略在变化后可能会获得次优奖励。研究表明，能够利用分布变化信息的算法可能会提高决策的质量和效率。", "innovation": "提出了一种新的算法——Density-QUCB（DQUCB），这是一种注意分布变化的Q-learning UCB算法。它使用转移密度函数来检测分布变化，并利用其似然性来提高Q-learning UCB的不确定性估计质量，从而在探索与利用之间达到平衡。通过理论分析和实验证明，DQUCB比传统的QUCB具有更好的遗憾保证，并且在RL任务和实际的COVID-19患者医院分配任务中表现出更好的性能。", "conclusion": "证明了DQUCB算法在面对分布变化的情况下具有更好的性能和效率，相比于QUCB算法拥有更低的遗憾值，同时在没有使用模型的RL任务中保持了较高的计算效率，并展示了在实际应用中的有效性。"}
{"llm_update_time": "20251006", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.03197", "html_url": "https://arxiv.org/abs/2510.03197", "title": "使用惯性传感器和肌电图估算阻力训练中的感知用力评分", "title_en": "Estimation of Resistance Training RPE using Inertial Sensors and Electromyography", "authors": "James Thomas,Johan Walhström", "background": "准确估计主观用力感知评分（RPE）可以提高阻力训练的效果，通过个性化反馈增强训练，并预防运动伤害。本研究探讨了机器学习模型在单臂哑铃卷曲练习中估计RPE的应用，使用可穿戴惯性传感器和肌电图（EMG）传感器的数据。", "innovation": "开发并使用了基于惯性传感器和肌电图传感器收集的数据集来训练机器学习模型，以准确估计阻力训练中的RPE。研究发现，随机森林分类器在估计RPE方面表现出最高性能。", "conclusion": "研究证明，基于可穿戴传感器的RPE估计是可行的，同时指出了提高模型泛化能力的关键挑战。"}
{"llm_update_time": "20251006", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.02320", "html_url": "https://arxiv.org/abs/2510.02320", "title": "WEE-Therapy：一种弱编码器混合框架用于心理咨询服务对话分析", "title_en": "WEE-Therapy: A Mixture of Weak Encoders Framework for Psychological Counseling Dialogue Analysis", "authors": "Yongqi Kang,Yong Zhao", "background": "当前，计算心理学的进步需要能够深入理解咨询对话的人工智能工具。现有的音频语言模型（AudioLLMs）通常依赖于在一般数据上预训练的单个语音编码器，难以捕捉特定领域的特征，如复杂情感和专业技巧。", "innovation": "本文提出了一种多任务AudioLLM——WEE-Therapy，结合了弱编码器集合（WEE）机制。这种方法通过补充强大的基础编码器，引入一组轻量级、专业化的编码器以增强模型能力。WEE-Therapy还采用了双路由策略，结合稳定的数据无关领域知识与动态的数据依赖专家选择，从而在情感识别、技术分类、风险检测和总结任务中实现了显著性能提升，同时参数很少，具有很强的辅助临床分析潜力。", "conclusion": "WEE-Therapy在所有任务上的性能显著提升，并且参数开销极少，显示出其在辅助临床分析中的巨大潜力。"}
{"llm_update_time": "20251006", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.02334", "html_url": "https://arxiv.org/abs/2510.02334", "title": "何处出错？通过表示梯度追踪归因不良的大语言模型行为", "title_en": "Where Did It Go Wrong? Attributing Undesirable LLM Behaviors via Representation Gradient Tracing", "authors": "Zhe Li,Wei Zhao,Yige Li,Jun Sun", "background": "大型语言模型（LLMs）虽然表现出了显著的能力，但仍经常因生成有害内容、事实错误和社会偏见等负面行为而导致部署受阻。诊断这些失败的根本原因对于AI安全性提出了重大挑战。现有的归因方法，尤其是基于参数梯度的方法，由于噪声信号和计算复杂数量级的限制，往往效果不佳。", "innovation": "本文提出了一种新颖且高效的框架，通过分析表示和梯度来诊断LLMs的一系列不良行为，直接操作模型激活空间以提供语义意义上的信号，将模型输出与其训练数据联系起来。本研究系统地评估了该方法在追踪有害内容、检测后门污染和识别知识污染等任务上的表现，表明该方法不仅在样本级归因上表现出色，还能够进行详细的词汇级分析，准确识别出具体引发模型行为变化的样本和短语。", "conclusion": "本研究提供了一种强大的诊断工具，用于理解、审核和最终减轻LLMs的风险。代码可在该链接下载：this https URL。"}
{"llm_update_time": "20251006", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.02353", "html_url": "https://arxiv.org/abs/2510.02353", "title": "利用LLM增强的知识图谱对塞内加尔法律文本进行结构化", "title_en": "An Senegalese Legal Texts Structuration Using LLM-augmented Knowledge Graph", "authors": "Oumar Kane,Mouhamad M. Allaya,Dame Samb,Mamadou Bousso", "background": "研究背景：塞内加尔司法系统中法律文本的获取和组织存在困难，需要更好地访问司法信息。研究提取了7,967篇文章，特别是土地和公共领域法的法律文件，开发了一个包含2,872个节点和10,774个关系的详细图数据库，用于可视化法律文本之间的关联。", "innovation": "研究创新：使用大量语言模型（LLM）和高级三元组抽取技术，特别是GPT-4o、GPT-4和Mistral-Large，有效识别关系和相关元数据，为塞内加尔公民和法律专业人士提供一个框架，帮助他们更好地理解自己的权利和责任。", "conclusion": "研究结论：通过应用人工智能和大型语言模型，成功地为塞内加尔的法律文本创建了一个结构化的知识图谱，有助于提高法律文本的可访问性和理解性，为塞内加尔公民和法律专业人士提供了更好的服务。"}
{"llm_update_time": "20251006", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.03149", "html_url": "https://arxiv.org/abs/2510.03149", "title": "通过采样视角探讨回溯：控制不完美过程验证器", "title_en": "Taming Imperfect Process Verifiers: A Sampling Perspective on Backtracking", "authors": "Dhruv Rohatgi,Abhishek Shetty,Donya Saless,Yuchen Li,Ankur Moitra,Andrej Risteski,Dylan J. Foster", "background": "结合生成型语言模型和过程验证器以评估部分生成的质量，可以在测试时激发新的推理能力。然而，这类方法的算法设计空间和计算扩展特性尚不明确，而且考虑到学习高效验证器的成本，其优点并不明显。观察到一种现象：学习的验证器中的看似无害的错误会导致标准解码技术在生成过程中放大错误，导致灾难性失败。因此，作者提出是否可以通过更复杂的解码策略来改进这一问题。", "innovation": "作者提出了一种新的过程引导的测试时采样算法VGB，利用理论支撑的回溯来证明在验证器错误方面的更优越鲁棒性。VGB 将自回归生成视为在部分生成树上的随机游走，而转移概率由过程验证器和基础模型引导；关键之处在于回溯是概率性的。该过程在理论计算机科学中的近似计数与采样文献中推广了Sinclair-Jerrum的随机游走方法，并且研究贡献之一是将这种方法与理论文献进行了对比。", "conclusion": "通过实验表明，在合成和实际语言建模任务中，VGB 在多种评估指标上优于基线方法，证实了其方法的有效性，表明通过更先进的解码策略可以改进不完善的过程验证器问题。"}
{"llm_update_time": "20251006", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.01227", "html_url": "https://arxiv.org/abs/2510.01227", "title": "EEFSUVA: 一个新的数学奥林匹克基准", "title_en": "EEFSUVA: A New Mathematical Olympiad Benchmark", "authors": "Nicole N Khatibi,Daniil A. Radamovich,Michael P. Brenner", "background": "近年来，关于大型语言模型（LLMs）是否与奥林匹克和研究生水平的数学基准相匹配的最新突破引发了广泛的讨论。然而，当前的基准可能夸大了模型的推理能力，因为它们主要来源于国际数学奥林匹克（IMO）等相关比赛，这些比赛可能存在数据污染，并且侧重于熟悉的问题类型。为实现更全面的数学理解评估，本研究从东欧国家和地区以及原苏联地区的非广泛传播的奥林匹克竞赛中创立了一个新的基准 EEFSUVA。这些竞赛的问题难度与 IMO 相当，但要求非标准的解题技巧，且这些问题在线语料库中出现频率较低。初步结果显示，即使是当前最先进的 LLM，其在 EEFSUVA 上的表现也逊于其他奥林匹克风格的基准。这些发现也暗示了更广泛的评估数据集的重要性，以对数学推理进行全面评估，并指导未来的模型开发。", "innovation": "本研究引入了一个新的基准 EEFSUVA，该基准来自东欧和原苏联地区的非广泛传播的奥林匹克竞赛。这些问题要求非标准解题技巧，并且在线出现频率较低，这有助于更全面地评估数学推理能力，而非仅依赖 IMO 这样的比赛。", "conclusion": "研究发现即使是最先进的 LLM 在 EEFSUVA 上的表现也逊于其他奥林匹克风格的基准，提示未来模型开发和评估应更注重广泛的数据集和非标准问题。"}
{"llm_update_time": "20251006", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.03199", "html_url": "https://arxiv.org/abs/2510.03199", "title": "Best-of-Majority: Minimax-Optimal Strategy for Pass@$k$ Inference Scaling", "title_en": "Best-of-Majority: Minimax-Optimal Strategy for Pass@$k$ Inference Scaling", "authors": "Qiwei Di,Kaixuan Ji,Xuheng Li,Heyang Zhao,Quanquan Gu", "background": "LLM推理通常生成一组候选答案，通过如多数投票或Top-N（BoN）等策略进行选择。对于难以处理的任务，单一选择往往会表现不佳。因此，评估指标通常使用Pass@$k$：代理可以提交最多$k$个答案，仅使用其中最优的那个进行计算。然而，传统的多数投票和BoN策略在$k$和采样预算$N$上都没有表现出理想的扩展性。研究者们因此提出了一个新的策略，结合了多数投票和BoN的优点，提出了一个新的称为Best-of-Majority（BoM）的推理策略。", "innovation": "提出了一种新的推理策略Best-of-Majority（BoM），该策略首先限制候选答案为在$N$次采样的高频响应，然后再选择其中的前$k$个作为奖励。证明当采样预算$N=\tilde\text{Ω}(C^*)$时，BoM的遗憾度为$O(\text{λ}_{\text{opt}} + \text{λ}_{\text{RM}}^2C^*/k)$，其中$C^*$是覆盖系数，$\text{λ}_{\text{RM}}$是奖励模型的估计误差，$\text{λ}_{\text{opt}}$是奖励在最优响应上的估计误差。此外，证明了该算法具有匹配的下界，证明其是 minimax 最优的。从最优性角度来看，BoM与多数投票和BoN不同，其性能不会随着$N$的增加而下降。实验证明，在解数学问题的推理测试中，BoM比多数投票和BoN表现更好。", "conclusion": "研究证明了BoM策略在Pass@$k$推理场景下的minimax最优性，不仅在理论上证明了算法的有效性，还在实际应用中展示了其在数学问题推理中的优越性。"}
{"llm_update_time": "20251006", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.02337", "html_url": "https://arxiv.org/abs/2510.02337", "title": "CRACQ：一种多维度的自动化文档评估方法", "title_en": "CRACQ: A Multi-Dimensional Approach To Automated Document Assessment", "authors": "Ishak Soltani,Francisco Belo,Bernardo Tavares", "background": "本文提出了CRACQ，这是一种多维度评估框架，用于评估文档在五个特定特征（连贯性、严谨性、适用性、完整性、质量）方面的表现。该框架基于基于特征的自动化作文评分方法，不仅适用于论文，还适用于多元化的机器生成文本。与单一评分方法不同，CRACQ将语言学、语义和结构信号结合在一起进行综合评估，既能够进行整体分析，也能够进行特征层面的分析。为了验证其有效性，CRACQ在500份合成基金申请书上进行了训练，并与基于大语言模型的评估进行了对比，还在强弱实际应用中进行了测试。初步结果显示，CRACQ能够生成比直接人工语言模型评估更稳定且可解释的特征水平判断，但仍存在可靠性和领域范围的挑战。", "innovation": "CRACQ引入了一种多维度的评估框架，能够全面、深入地评估各种形式的机器生成文本。该框架通过结合语言学、语义和结构信号进行综合评估，能够提供具有解释性的自动化评价方法。相比于单一评分方法，CRACQ能够在特征层面进行更细致的分析，同时提高评价的稳定性。", "conclusion": "CRACQ在综合评估各种类型的机器生成文本方面显示出潜在的价值。尽管在可靠性与适用性范围等方面仍存在问题，但该方法为自动化文档评估提供了一种新的视角。"}
{"llm_update_time": "20251006", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.03222", "html_url": "https://arxiv.org/abs/2510.03222", "title": "低概率令牌维持强化学习中可验证奖励的问题探索", "title_en": "Low-probability Tokens Sustain Exploration in Reinforcement Learning with Verifiable Reward", "authors": "Guanhua Huang,Tingqiang Xu,Mingze Wang,Qi Yi,Xue Gong,Siheng Li,Ruibin Xiong,Kejiao Li,Yuhao Jiang,Bo Zhou", "background": "RLVR已经推动了大型语言模型在复杂推理方面的发展，但其可扩展性常受限于训练瓶颈，表现为在政策熵崩溃时性能停滞，指示着探索的减少。之前的方法通常通过保持高政策熵来应对这一问题，但对有意义探索的具体机制仍缺乏深入研究。以往方法中，过分关注熵可能会加剧无关令牌的放大并扰乱训练稳定性。因此，本文探讨了RLVR中的探索动态，并发现主要原因在于有价值的低概率探索令牌逐渐被消除，称为“推理火花”。这些火花在预训练模型中较为常见，但在RLVR过程中由于过度惩罚而被系统地熄灭，导致探索退化。", "innovation": "本文提出了低概率正则化（Lp-Reg），这是一种核心机制旨在通过一个由过滤出假定噪声令牌并重新正则化剩余候选者的分布构建的启发式代理分布，来规范化政策。该代理提供了一个更去噪的代理，其中“推理火花”的概率被放大，以作为KL发散的软正则化目标来保护这些有价值令牌，防止其被消除。实验结果显示，Lp-Reg使得RLVR中的策略稳定训练时间可达约1000步，此范围是基线熵控制方法失败的地方，并且这种持续的探索推动了最先进的性能，平均准确率达到了60.17%，比之前的方法提高了2.66%。同时文章提供相关代码供进一步验证和使用。", "conclusion": "通过引入Lp-Reg，本文解决了由于过度惩罚导致的低概率探索令牌消失的问题，使得RLVR在大规模复杂任务上的性能大幅提高，持续探索能够达到SOTA水平的性能。这表明低概率令牌在问题探索中的关键作用，为今后强化学习中的探索机制提供了新的视角和改进方向。"}
{"llm_update_time": "20251006", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.02377", "html_url": "https://arxiv.org/abs/2510.02377", "title": "增强不确定性意识的回答选择以提高多LLM系统的推理能力", "title_en": "Uncertainty-Aware Answer Selection for Improved Reasoning in Multi-LLM Systems", "authors": "Aakriti Agrawal,Rohith Aralikatti,Anirudh Satheesh,Souradip Chakraborty,Amrit Singh Bedi,Furong Huang", "background": "尽管大型语言模型（LLMs）展示了出色的能力，但在资源受限的环境中，从多个LLMs中选择最可靠的回答仍然是一个挑战。当前的方法经常需要依赖昂贵的外部验证者、人类评估者或需要单个模型多个样本的自我一致性技术。尽管多LLM系统可以产生更多样化的回答，具有更大的潜力，但它们往往表现不如单个模型的自我一致性。", "innovation": "本文提出了一种原则性的、新颖的、计算效率高的方法，用于从多个不同LLMs中选择最佳回答，利用这些模型内部的知识和自信度，通过校准的对数似然分数自动选择。这种方法在GSM8K、MMLU（6个子集）和ARC数据集的辩论（多轮LLM讨论）和非辩论（多LLM的Best-of-N）设置中分别提高了约4%、3%和5%。", "conclusion": "本文提出的方法在GSM8K、MMLU（6个子集）和ARC数据集的辩论和非辩论设置中，分别取得了约4%、3%和5%的性能提升，展示了对多LLM系统中答案选择的有效性改进。"}
{"llm_update_time": "20251006", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.02387", "html_url": "https://arxiv.org/abs/2510.02387", "title": "CWM: 一种用于代码生成的世界模型开放式权重LLM", "title_en": "CWM: An Open-Weights LLM for Research on Code Generation with World Models", "authors": "FAIR CodeGen team. Jade Copet,Quentin Carbonneaux,Gal Cohen,Jonas Gehring,Jacob Kahn,Jannik Kossen,Felix Kreuk,Emily McMilin,Michel Meyer,Yuxiang Wei,David Zhang,Kunhao Zheng,Jordi Armengol-Estapé,Pedram Bashiri,Maximilian Beck,Pierre Chambon,Abhishek Charnalia,Chris Cummins,Juliette Decugis,Zacharias V. Fisches,François Fleuret,Fabian Gloeckle,Alex Gu,Michael Hassid,Daniel Haziza,Badr Youbi Idrissi,Christian Keller,Rahul Kindi,Hugh Leather,Gallil Maimon,Aram Markosyan,Francisco Massa,Pierre-Emmanuel Mazaré,Vegard Mella,Naila Murray,Keyur Muzumdar,Peter O'Hearn,Matteo Pagliardini,Dmitrii Pedchenko,Tal Remez,Volker Seeker,Marco Selvi,Oren Sultan,Sida Wang,Luca Wehrstedt,Ori Yoran,Lingming Zhang,Taco Cohen,Yossi Adi,Gabriel Synnaeve", "background": "该研究致力于通过世界模型（World Models）改善代码生成的研究。为了提高代码理解，研究者不仅利用静态代码进行训练，还通过中间训练和强化学习对代码生成过程中的推理和规划进行改进。", "innovation": "研究提出了一个名为CWM的320亿参数级开放式权重大规模语言模型。CWM通过与Python解释器和智能Docker环境中的观察-动作轨迹进行中间训练，进行多任务推理强化学习，从而提供了一个强大的测试平台，探索如何通过有效的推理和计划提高计算环境中的代码生成。", "conclusion": "研究展示了世界模型如何提高智能编程、逐步骤模拟Python代码执行以及推理对于代码生成的早期成果。CWM在接受中间训练、微调和强化学习的模型检查点被公开，以支持进一步的世界模型代码研究。"}
{"llm_update_time": "20251006", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.02386", "html_url": "https://arxiv.org/abs/2510.02386", "title": "关于推理模型基准污染检测的脆弱性", "title_en": "On The Fragility of Benchmark Contamination Detection in Reasoning Models", "authors": "Han Wang,Haoyu Li,Brian Ko,Huan Zhang", "background": " Leaderboards for LRMs已经将评估变成了竞赛，激励开发者直接优化基准套件。一种捷径是在训练数据中融入评估基准，从而导致性能夸大，称为基准污染。研究发现，逃避污染检测对于LRMs来说异常容易。研究集中在两种实际可能发生污染的情况：（I）当基础模型通过SFT和RL进化为LRM时，污染检测方法在SFT期间可以最初识别污染，但即使是短暂的GRPO训练也能显著掩饰大多数检测方法依赖的污染信号。进一步的经验实验和理论分析表明，PPO风格的重要性采样和裁剪目标是这种检测隐蔽性的根本原因，表明广泛的RL方法可能具有类似的隐蔽能力；（II）当结合CoT的SFT污染应用于高级LRM的最终阶段时，大多数污染检测方法接近随机猜测。缺乏非成员数据暴露，被污染的LRM会对与训练集分布相似但尚未见过的样本更有信心，从而逃过现有基于记忆的检测方法。", "innovation": "研究揭示了多种通过SFT和RL等方法在推理模型中隐蔽性地进行基准污染的手段，特别是强调PPO等方法可能存在隐藏污染的能力，并表明大多数现存检测方法在防止这种污染时效率低下。研究成果强调了开发高级污染检测方法和适用于LRM的可信评估协议的迫切需求。", "conclusion": "推理模型的评估存在独特漏洞：模型开发者可以轻易污染LRMs以实现虚假提升的排行榜性能，同时留下很少的污染痕迹，这严重削弱了评估的公平性并威胁到公共排行榜的完整性。因此，需高度重视开发先进的污染检测方法和可靠的评估协议，以应对此类威胁。"}
{"llm_update_time": "20251006", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.02340", "html_url": "https://arxiv.org/abs/2510.02340", "title": "Can Prompts Rewind Time for LLMs? Evaluating the Effectiveness of Prompted Knowledge Cutoffs", "title_en": "Can Prompts Rewind Time for LLMs? Evaluating the Effectiveness of Prompted Knowledge Cutoffs", "authors": "Xin Gao,Ruiyi Zhang,Daniel Du,Saurabh Mahindre,Sai Ashish Somayajula,Pengtao Xie", "background": "大型语言模型（LLMs）广泛用于时间预测，但它们对预训练数据的依赖引发了数据污染的担忧。精确预测基准测试数据之前的结果可能反映的是记忆而非推理，这可能导致对其泛化能力的过度估计。最近出现了基于提示的去学习技术，引发了一个自然的问题：能否提示LLMs模拟早期的知识截止日期？作者研究了提示在LLMs中模拟早期知识截止的能力。他们构建了三个评估数据集来评估LLMs在（1）直接事实知识、（2）语义变化、（3）因果相关知识上的遗忘程度。结果显示，虽然当直接查询某日期之后的信息时，基于提示模拟的知识截止有效，但当遗忘的内容未能直接被询问但与查询有因果关系时，效果则不理想。这些发现提示，当应用LLMs进行时间预测任务时，需要更严格的评估设置以保证准确度。整体数据集和评估代码可在此找到：this https URL.", "innovation": "1. 研究了提示在LLMs中模拟早期知识截止的能力。\n2. 建立了三个评估数据集来全面评估LLMs处理直接事实知识、语义变化以及因果相关知识遗忘的能力。\n3. 发现了基于提示模拟的知识截止的有效性取决于遗忘内容是否被直接询问，与查询的因果关系影响效果的表现。", "conclusion": "基于提示模拟的知识截止在直接查询相关内容时显示出一定的有效性，但在未直接询问的情况下，与查询有因果关系的内容遗忘效果较差。因此，更严格的评估设置是应用LLMs进行时间预测任务时需要关注的问题。"}
{"llm_update_time": "20251006", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.02355", "html_url": "https://arxiv.org/abs/2510.02355", "title": "建立大型稀疏MIMO信道下行业波形成形的编码-解码网络", "title_en": "An Encoder-Decoder Network for Beamforming over Sparse Large-Scale MIMO Channels", "authors": "Yubo Zhang,Jeremy Johnston,Xiaodong Wang", "background": "本文开发了一种端到端的深度学习框架，用于处理大型稀疏MIMO信道下的下行业波形成形。在这些大规模系统中，有效利用有限的反馈资源进行波形成形变得尤为重要。传统的波形成形方法存在复杂度高、反馈效率低等问题，因此需要新的方法来提高波形成形的效率和性能。本文提出的方法通过引入深度编码-解码网络（EDN），旨在优化波形成形的过程，并适应不同环境条件下的通信需求。", "innovation": "论文的核心创新在于采用了一种深度编码-解码网络（EDN）架构，包括三个模块：（i）在每个用户端部署的编码神经网络，用于压缩估计的下行链路信道至低维度的潜变量；（ii）在基站的波形成形解码神经网络，将恢复的潜变量映射为波形成形；（iii）同样在基站的信道解码神经网络，从恢复的潜变量重构下行链路信道以进一步精化波形成形。训练策略采用了半幅化学习和知识蒸馏，其中前者通过在波形成形解码神经网络中嵌入分析梯度上升来优化学习过程，而后者则通过结合监督和无监督损失函数，在传统最小均方误差（MMSE）波形成形的基础上逐渐过渡到以最大化系统总速率作为目标的无监督训练。", "conclusion": "提出的EDN波形成形框架已被扩展应用于远场和近场混合波形成形场景，模拟结果表明，该框架在各种网络和信道条件下均表现出显著的有效性。"}
{"llm_update_time": "20251006", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.02345", "html_url": "https://arxiv.org/abs/2510.02345", "title": "打破MoE大语言模型的三难困境：基于结构化压缩的动态专家聚类", "title_en": "Breaking the MoE LLM Trilemma: Dynamic Expert Clustering with Structured Compression", "authors": "Peijun Zhu,Ning Yang,Jiayu Wei,Jinghang Wu,Haijun Zhang", "background": "Mixture-of-Experts (MoE) 大语言模型面临着负载不平衡、参数冗余和通信开销的三大问题。以往的解决方案未能同时有效解决这些问题，导致了模型在效率方面的局限性。本研究提出了一个统一的框架，基于动态专家聚类和结构化压缩来共同解决这些挑战。该框架利用了路由器的语义嵌入能力，在训练过程中动态重构模型架构，从而实现显著的效率提升。这种方法在每个聚类中将专家权重分解为共享基础矩阵和超低秩残差适配器，实现了多达五倍的参数减少，同时保持了专一性。此外，该结构使路由策略能够两级层次化，提高了效率，降低了通信开销。该研究还采用了一种异构精度方案存储共享基矩阵的FP16和残差因子的INT4，并动态卸载不活跃的聚类，从而进一步降低了峰值内存消耗，使之达到与密集模型相似的水平。这项研究通过全面解决MoE LLMs面临的问题，展示了结构重组是实现高效、内存节约的大规模MoE LLMs的一种可行路径。", "innovation": "1. 引入一个统一框架，基于动态专家聚类和结构化压缩，共同解决MoE LLMs面临的问题。\n2. 利用路由器的语义嵌入能力，动态重构模型架构，实现效率提升。\n3. 在每个聚类中分解专家权重为共享基础矩阵和超低秩残差适配器，实现参数显著减少。\n4. 提出一种两级层次化的路由策略，减少路由搜索空间和全连接通信量。\n5. 采用异构精度方案存储共享基础矩阵的FP16和残差因子的INT4，并动态卸载不活跃聚类，降低峰值内存消耗。\n6. 使得MoE LLMs的质量保持不变，参数减少约80%，吞吐量提高10%至20%，专家负载波动降低至原来的三分之一以下。", "conclusion": "这项研究通过全面解决方案，展示了结构重组是实现高效、内存节约的大规模MoE LLMs的一种可行路径，对于大规模语言模型的发展有重要的实际意义。"}
{"llm_update_time": "20251006", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.02415", "html_url": "https://arxiv.org/abs/2510.02415", "title": "大气机器学习模型在均匀海面温度增暖下的平衡响应", "title_en": "The Equilibrium Response of Atmospheric Machine-Learning Models to Uniform Sea Surface Temperature Warming", "authors": "Bosong Zhang,Timothy M. Merlis", "background": "最近开发了能够生成稳定多年气候模拟的全球大气机器学习模型。然而，这些模型超出训练分布的能力仍是一个开放的问题。本研究评估了几种最先进的机器学习模型（ACE2-ERA5、NeuralGCM和cBottle）在均匀海面温度增暖下的气候响应，作为评估气候变化的一种广泛使用的基准。", "innovation": "本研究通过评估机器学习模型在面对与物理模型一致的基准测试时的表现，特别是降水响应，来检验其在气候变化应用中的潜力和局限性。研究发现机器学习模型在某些方面能较好地模拟物理响应，但也在辐射响应和陆地区域增暖方面表现出显著的不一致。", "conclusion": "机器学习模型在气候变化应用中具有潜力，但需要进一步改进以实现稳健的外部样本泛化。"}
{"llm_update_time": "20251006", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.02418", "html_url": "https://arxiv.org/abs/2510.02418", "title": "BrowserArena：在实际网络导航任务中评估LLM代理", "title_en": "BrowserArena: Evaluating LLM Agents on Real-World Web Navigation Tasks", "authors": "Sagnik Anupam,Davis Brown,Shuo Li,Eric Wong,Hamed Hassani,Osbert Bastani", "background": "当前的LLM网络代理能够在开放网络上浏览并执行任务，但现有的代理评估大多局限于沙盒环境或人造任务。为了克服这些限制，本文介绍了BrowserArena，一个现实世界网络代理评估平台，它收集用户提交的任务并进行“竞技场”风格的头对头比较，并利用每步人工反馈来揭示代理失败模式。", "innovation": "BrowserArena平台通过收集和分析代理执行轨迹的逐步注释，发现在多层次挑战中的三种一致失败模式：验证码解析、弹出窗口清除和直接导航到URL。此外，通过构建有针对性的数据集进一步研究这些任务，揭示了不同语言模型在处理这些失败模式时的不同方法。该研究显示了当前网络代理的多样性和脆弱性。", "conclusion": "该研究发现在验证码解析、弹出窗口清除和直接导航到URL等任务中的失败模式，定量研究显示不同模型在这些任务中的策略差异。该研究展示了当前网络代理的多样性与脆弱性。同时，该基准测试方法为大规模评估和理解网络代理失败模式提供了新的途径。"}
{"llm_update_time": "20251006", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.02348", "html_url": "https://arxiv.org/abs/2510.02348", "title": "mini-vec2vec：使用线性变换扩展通用几何对齐", "title_en": "mini-vec2vec: Scaling Universal Geometry Alignment with Linear Transformations", "authors": "Guy Dar", "background": "vec2vec 是一种设计用于在没有平行数据的情况下对齐文本嵌入空间的方法。尽管 vec2vec 能够找到近乎完美的对齐，但它计算成本高昂且不稳定。", "innovation": "mini-vec2vec 提出了一种简单且高效的替代方法，所需计算成本大大降低且高度稳定。learned mapping 是线性变换。该方法分为三个主要阶段：伪平行嵌入向量的初步匹配、变换拟合以及迭代细化。mini-vec2vec 在效率上比原始 vec2vec 高出几个数量级，同时匹配或超出原方法的结果。", "conclusion": "该方法的稳定性和可解释的算法步骤使其便于扩展，并为新的领域和学科的应用打开了新的机会。"}
{"llm_update_time": "20251006", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.02391", "html_url": "https://arxiv.org/abs/2510.02391", "title": "LLM-Generated Samples for Android Malware Detection", "title_en": "LLM-Generated Samples for Android Malware Detection", "authors": "Nik Rollinson,Nikolaos Polatidis", "background": "安卓恶意软件通过混淆和多态性持续演变，这给基于签名的防御和已训练于有限且不平衡数据集上的机器学习模型带来了挑战。合成数据被提出作为一种解决数据稀缺性的方法，但大型语言模型（LLMs）在生成适用于检测任务的有效恶意软件数据方面的潜力尚未充分探索。", "innovation": "该研究使用GPT-4.1-mini微调生成针对三种恶意软件家族（BankBot、Locker/SLocker、Airpush/StopSMS）的结构化记录，并通过提示工程和后处理解决了生成不一致性问题。研究分别在仅真实数据、真实数据加合成数据及仅合成数据三种训练设定下评估了多个分类器性能，结果显示仅使用真实数据训练达到了接近完美的检测效果，而混用合成数据能保持较高性能但略有下降；单纯的合成数据训练则效果不一。", "conclusion": "研究结果表明，LLM生成的恶意软件样本可以增强稀缺的数据集而不影响检测准确性，但单独作为训练源尚不足够。"}
{"llm_update_time": "20251006", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.02375", "html_url": "https://arxiv.org/abs/2510.02375", "title": "预训练使用层次化记忆：区分长尾知识和常见知识", "title_en": "Pretraining with hierarchical memories: separating long-tail and common knowledge", "authors": "Hadi Pouransari,David Grangier,C Thomas,Michael Kirchhof,Oncel Tuzel", "background": "现代语言模型的出色性能依赖于参数的扩展：更大的模型存储更多世界知识并且推理能力更强。然而，将所有世界知识压缩到参数中是不必要的，因为每个提示只使用一小部分知识，并且对于具有有限推理时内存和计算能力的边缘设备来说是不实际的。这项研究通过引入一种基于记忆增强的架构和与现有硬件范例相一致的预训练策略，来解决这些问题。作者提出了一个小型语言模型，它能够访问大型层次化参数型记忆库，这些记忆库编码了世界知识。通过大规模实验，他们展示了给160M参数模型添加来自4.6B参数记忆库的18M参数记忆，可以获得相当于大于两倍参数量的模型的性能增益。", "innovation": "该研究提出了一个基于记忆增强的架构和与现有硬件范式的预训练策略，通过引入小型语言模型和大型层次化参数型记忆库，解决了大规模语言模型对内存和计算能力的高要求问题。研究证明了通过利用小型模型和记忆参数存储长尾世界知识的方法，可以获得显著的性能增益，并且能够在各种 transformer 架构中使用层次化前馈记忆，无论是预训练期间添加还是后期添加，均表现出稳健性。此外，该研究还探讨了变压器中参数型记忆的最佳类型和大小，并将这些记忆扩展到了超过21B参数。", "conclusion": "通过大规模的实验，研究展示了通过引入基于记忆增强的方法可以实现显著的性能提升，即使模型参数量相对较少。此外，研究还发现，提出的层次化前馈记忆在不同 transformer 架构中工作表现稳健，并且可以大大提高小模型的性能。这些发现对于构建更高效、更具扩展性的语言模型具有重要意义。"}
{"llm_update_time": "20251006", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.02401", "html_url": "https://arxiv.org/abs/2510.02401", "title": "线性RNN用于自回归生成长音乐片段", "title_en": "Linear RNNs for autoregressive generation of long music samples", "authors": "Konrad Szewczyk,Daniel Gallo Fernández,James Townsend", "background": "直接以自回归方式学习生成音频波形是一项具有挑战性的任务，因为原始序列的长度非常长，并且存在多种时间尺度的重要结构。传统的基于循环神经网络（RNN）、因果卷积和自注意力机制的方法在这项任务上已经达到了有限的成功。然而，最近的研究表明，在这种情况下，深度状态空间模型（也称为线性RNN）可以非常高效。", "innovation": "研究评估了线性RNN在直接生成原始音频波形上的不同架构选择，并利用上下文并行性进行训练，使模型能够处理长达一分钟（1M个标记）的序列。研究提出了一个名为HarmonicRNN的模型，该模型在小型数据集上取得了最先进的对数似然率和感知指标。", "conclusion": "研究通过深入研究线性RNN的不同建模方案，并应用上下文并行性，展示了在长时间序列生成任务上的可行性，并且模型在小型数据集上达到了先进的性能。"}
{"llm_update_time": "20251006", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.02389", "html_url": "https://arxiv.org/abs/2510.02389", "title": "从追踪到行：基于LLM的OSS漏洞定位代理", "title_en": "From Trace to Line: LLM Agent for Real-World OSS Vulnerability Localization", "authors": "Haoran Xi,Minghao Shao,Brendan Dolan-Gavitt,Muhammad Shafique,Ramesh Karri", "background": "大型语言模型在漏洞发现方面表现出潜力，但现有方法在孤立分析代码、处理长上下文以及关注粗略的功能或文件级检测方面存在局限。这些方法为工程师提供的指导有限，尤其是当工程师需要精确定位代码行和有针对性地打补丁时。因此，本文介绍了一种针对项目级别的端到端框架T2L-Agent，能够自行规划分析并逐步从模块缩小到具体漏洞行。该框架融合了多轮反馈和基于抽象语法树（AST）的代码片段化，以及运行时证据，如崩溃点、堆栈跟踪和覆盖率变化，能够进行迭代优化并提供具体可采取措施的行级诊断。为了对行级漏洞发现进行基准测试，研究者引入了T2L-ARVO基准集，该基准集涵盖了五类真实世界崩溃案例和多样性专家验证的50个案例。该基准集同时支持粗粒度检测和细粒度定位，为系统的开发提供了一种评估方法。在T2L-ARVO基准集上，T2L-Agent实现了高达58.0%的检测率和54.8%的行级定位，显著超越了基线方法。", "innovation": "T2L-Agent框架通过融合多轮反馈和运行时证据的Agent Trace Analyzer (ATA)，结合AST代码片段化，实现迭代优化和行级分析，并将其症状转化为具体的可执行诊断。T2L-ARVO基准集则是研究者专门为支持粗粒度检测和细粒度定位而设计的，旨在支持使用LLM进行漏洞检测的系统，使其能够超越文件级预测，实现更精确的诊断，减少噪声并加速开源软件开发中的补丁流程。", "conclusion": "本文提出了一种项目级别的端到端框架T2L-Agent，能够精细本地化漏洞并转化为可执行的线程级诊断，并通过T2L-ARVO基准集进行了评估，结果显示其性能显著优于现有基线，推动了基于LLM的漏洞检测从粗略识别向部署和可靠的精确诊断发展，有助于减少噪音并加速开源软件开发中的补丁流程。"}
{"llm_update_time": "20251006", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.02417", "html_url": "https://arxiv.org/abs/2510.02417", "title": "NEURODNAAI：使用深度学习框架推进基于DNA的信息存储作为可持续数字介质的神经流水线方法", "title_en": "NEURODNAAI: Neural pipeline approaches for the advancing dna-based information storage as a sustainable digital medium using deep learning framework", "authors": "Rakesh Thakur,Lavanya Singh,Yashika,Manomay Bundawala,Aruna Kumar", "background": "DNA作为数字信息存储的介质，因其极高的密度和持久性而具有潜力。尽管前人研究已经推进了编码理论、工作流程设计和模拟工具的发展，但合成成本、测序错误以及生物约束（如GC含量不平衡、同聚序列）等问题限制了其实用部署。", "innovation": "我们的框架借鉴了量子并行性的概念，以增强编码多样性和鲁棒性，同时结合生物启发的约束条件和深度学习来改善DNA存储中的错误缓解。NeuroDNAAI能够将二进制数据流编码为符号DNA序列，通过具有替代、插入和删除的噪声信道进行传输，并且以高保真度进行重建。实验结果表明，传统的提示方法或基于规则的方案无法有效适应现实中的噪声，而NeuroDNAAI表现出更优越的准确性。同时，实验验证了在基准数据集上的位错误率较低，适用于文本和图像存储。通过将理论、工作流程和模拟统一到一个管道中，NeuroDNAAI能够实现可扩展的、生物上有效的档案DNA存储。", "conclusion": "通过将理论、工作流程和模拟统一到一个管道中，NeuroDNAAI框架使得基于DNA的数字信息存储成为一种可行且有效的解决方案，同时实现了高保真度的存储和错误缓解。"}
{"llm_update_time": "20251006", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.02425", "html_url": "https://arxiv.org/abs/2510.02425", "title": "使语言模型感知的词语", "title_en": "Words That Make Language Models Perceive", "authors": "Sophie L. Wang,Phillip Isola,Brian Cheung", "background": "大型语言模型（LLMs）仅基于文本训练，表面上缺乏直接的感知体验，但其内部表示受到语言中编码的多模态规律的隐式塑造。研究假设可以通过明确的感官提示，揭示这种潜在结构，使纯文本训练的语言模型更接近专业视觉和音频编码器的表示。当感官提示告诉模型“看到”或“听到”时，它会引导模型将下一个预测代理为条件于从未实际提供的潜在视觉或听觉证据。研究结果表明，轻量级的提示工程可以可靠地激活纯文本训练的LLMs中相应模态的表示。", "innovation": "研究通过引入明确的感官提示（如“看到”和“听到”），揭示了语言模型中潜在的多模态表示结构，使其更接近专业的视觉和音频编码器表示。这种轻量级的提示工程方法为改进纯文本训练的LLMs提供了新的途径。", "conclusion": "研究结果表明，通过简单的提示工程可以激活纯文本训练的语言模型中相应模态的表示，使其在某种程度上达到与专业视觉和音频编码器的表示更加一致。这为如何进一步提升语言模型多模态感知能力提供了新的见解和方法。"}
{"llm_update_time": "20251006", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.02513", "html_url": "https://arxiv.org/abs/2510.02513", "title": "自适应随机 pivoting 和体积采样", "title_en": "Adaptive randomized pivoting and volume sampling", "authors": "Ethan N. Epperly", "background": "自适应随机 pivoting（ARP）是一种最近提出的高效列子集选择算法。本文通过将其与体积抽样分布和线性回归的主动学习算法联系起来，重新解释了 ARP 算法，从而为该算法提供了新的分析方法，并通过拒绝抽样实现了更快的实现方式。", "innovation": "通过将 ARP 算法与体积采样分布和线性回归的主动学习算法联系起来进行重新解释，提出了对 ARP 算法的新分析方法，并提出了利用拒绝抽样的更快实现方式。", "conclusion": "本文通过新的分析方法和更快的实现方式，进一步优化了自适应随机 pivoting 算法。"}
{"llm_update_time": "20251006", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.02420", "html_url": "https://arxiv.org/abs/2510.02420", "title": "高阶PAC学习，VC维数与填充引理", "title_en": "Higher-arity PAC learning, VC dimension and packing lemma", "authors": "Artem Chernikov,Henry Towsner", "background": "该论文背景涉及Chernikov和Towsner在2020年发表的工作，发展了高阶VC理论（VC$_n$维数），包括对Haussler填充引理的推广，并建立了一种与之相关的适度（切片式）超图正则性引理。此外，该论文探讨了这些结果如何能够表征在Kobayashi等人在2015年引入的产品空间中高阶PAC学习（PAC$_n$学习）的特征，涉及到产品测度。", "innovation": "该论文的主要创新在于发展了高阶VC理论（VC$_n$维度），包括对Haussler填充引理的扩展，并提出了一种与之相关的适度（切片式）超图正则性引理。此外，通过这些理论，该研究展示了它在产品空间中的意义，特别是在Kobayashi、Kuriyama和Takeuchi提出的关于高阶PAC学习（PAC$_n$学习）的表征方面。论文还指出了与arXiv:2402.14294、arXiv:2505.15688和arXiv:2509.20404相关的一些结果如何可以从arXiv:2010.00726的工作中得出。", "conclusion": "该工作证明了发展高阶VC理论（VC$_n$维度）和针对产品空间中的高阶PAC学习（PAC$_n$学习）的重要性。通过引入新的工具，如高阶超图正则性引理和改进的填充引理，论文为理解复杂分布下的机器学习问题提供了新的视角。"}
{"llm_update_time": "20251006", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.02471", "html_url": "https://arxiv.org/abs/2510.02471", "title": "时间序列的预测推断：分段同化为什么能够在存在时间依赖性的情况下仍然有效？", "title_en": "Predictive inference for time series: why is split conformal effective despite temporal dependence?", "authors": "Rina Foygel Barber,Ashwin Pananjady", "background": "研究时间序列中的预测区间量化问题：使用过往数据预测下一个时间点，能否提供有效的预测区间？尽管同化预测方法因其对独立或可交换数据分布提供无假设分布的覆盖率而广受欢迎，但在时间序列环境中，这种方法的强实证表现并不容易理解，因为时间序列中的短期时序依赖性就违反了可交换性假设。此外，利用具有“记忆”的预测器（例如自回归模型）进一步加剧了这个问题。本研究旨在探讨分段同化预测在时间序列环境下的理论属性，包括预测器可能具有“记忆”的情况，以了解这些方法的覆盖率损失。研究中引入了分析其他依赖性数据预测方法的有用工具，结果在严格定义的统计属性下得到了覆盖率概率的具体说明。", "innovation": "研究团队提出了一个新的“开关系数”，以此来量化时间序列内部时序相关性对交换性假设的违反程度。此研究的创新点在于，针对自相关性的预测器，分析了分段同化预测在时间序列环境中的理论性质，并具体证明了这类方法在\\(\beta\\)-混合过程中的覆盖率概率边界非常精确。此研究为解释为什么分段同化方法能够在存在时间依赖性的数据序列中呈现出不错的实证表现提供了理论上的支持和解释。", "conclusion": "研究通过定义一个指测量时间序列内部时序依赖性程度的新"}
{"llm_update_time": "20251006", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.02472", "html_url": "https://arxiv.org/abs/2510.02472", "title": "非均匀边界条件和载荷的蒙皮异构图表示", "title_en": "Heterogeneous Graph Representation of Stiffened Panels with Non-Uniform Boundary Conditions and Loads", "authors": "Yuecheng Cai,Jasmin Jelovica", "background": "蒙皮结构分析和优化中使用代理模型至关重要。本文提出了一个考虑几何变化性、非均匀边界条件和不同载荷场景的蒙皮异构图表示方法，利用异构图神经网络（HGNNs）来改进和优化蒙皮结构的分析和优化过程。该结构被划分为多个结构单元，每个单元由三种不同类型的节点来表示：几何节点、边界节点和负载节点。通过加入局部方向和连接节点的空间关系来构建边的异构性。不同层次的异构图表示被提出和分析，并在异构图变换器（HGT）上实现，用于预测蒙皮结构在边界载荷和自由度下的von Mises应力和位移场。", "innovation": "本文提出了一个异构图表示方法，结合非均匀边界条件和多样化载荷场景，使用异构图神经网络来建模并预测蒙皮结构的von Mises应力和位移场。此外，还对比了异构图方法与同构图方法的性能，并通过消融分析研究了图异构性对HGT性能的影响，显示出在预测位移和von Mises应力方面具有较高的准确性和捕获结构行为模式的能力。", "conclusion": "本文提出的异构图表示方法在预测蒙皮结构的位移和von Mises应力方面表现出优异的性能，并且在不同的边界条件和载荷条件下具有足够的准确性。同时，研究表明，图的异构性可以显著提高HGT的性能，能够有效捕捉和预测蒙皮结构的关键应力和位移特征。"}
{"llm_update_time": "20251006", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.02480", "html_url": "https://arxiv.org/abs/2510.02480", "title": "通过风险控制实现安全且高效的上下文学习", "title_en": "Safe and Efficient In-Context Learning via Risk Control", "authors": "Andrea Wynn,Metod Jazbec,Charith Peris,Rinat Khaziev,Anqi Liu,Daniel Khashabi,Eric Nalisnick", "background": "大型语言模型（LLMs）能够通过少量上下文示例快速学习新任务，但这种灵活性引入了安全问题：LLMs可能受到错误或恶意示例的影响，例如攻击者可能会篡改或注入有害示例，而不被人类监督员注意到。这促使我们设计出系统自身包含内置机制以防范此类攻击的方法，从而提高系统的安全性。现有的方法通常在性能和安全性之间难以取得平衡，特别是在处理有害输入时，这部分研究旨在找到一种方法来限制有害示例对模型性能的负面影响，同时保证对有益输入的高效利用。", "innovation": "本文提出了一个新颖的方法，通过分布无关的风险控制（DFRC），该方法首先定义了一个基本的“安全”行为基准（即，没有上下文示例时模型的表现），然后利用动态早期退出预测，忽略了那些最关注不安全输入的后注意力头，从而控制上下文示例对性能的负面影响。此外，还提出对DFRC的修改，使其既能够控制有害输入的风险，又能够利用有益输入的性能和效率提升。实验结果显示，该方法能够有效控制有害上下文示例的风险，并且在有益示例上取得显著的计算效率提升。", "conclusion": "本文提出了一个通过风险控制实现安全且高效的上下文学习的方法，该方法能够在保留模型性能的同时，有效保护模型免受有害示例的影响，同时也能利用有益输入带来的效率和性能提升。"}
{"llm_update_time": "20251006", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.02567", "html_url": "https://arxiv.org/abs/2510.02567", "title": "智能代理增强的增材制造合金发现", "title_en": "Agentic Additive Manufacturing Alloy Discovery", "authors": "Peter Pak,Achuth Chandrasekhar,Amir Barati Farimani", "background": "在增材制造(AM)领域，合金发现仍然是一个复杂挑战，通常需要材料科学、热力学模拟和实验分析等多个领域的专业知识。通过使用大型语言模型（LLM）启用的智能代理，这些工具可以调用Thermo-Calc热力学性质图计算和缺缝过程图生成等操作，从而帮助研究人员更智能地利用研究工具，增强他们的研究能力。", "innovation": "文章介绍了一种多代理系统，该系统可以利用智能代理的能力，通过调用Model Context Protocol (MCP)中的工具命令来执行各种计算和生成任务，并有效处理复杂的用户查询，评估合金的可打印性。智能代理能够根据工具调用结果动态调整任务路径，实现自主决策。", "conclusion": "本文旨在利用大型语言模型启用的智能代理自动化和加速增材制造领域的合金发现任务，并展示采用这种多代理系统的益处。"}
{"llm_update_time": "20251006", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.02424", "html_url": "https://arxiv.org/abs/2510.02424", "title": "基于行为分析的自适应欺骗框架以增强网络安全防御", "title_en": "Adaptive Deception Framework with Behavioral Analysis for Enhanced Cybersecurity Defense", "authors": "Basil Abdullah AL-Zahrani", "background": "本研究背景在于当前传统的入侵检测系统在检测网络攻击方面存在效率和准确率的问题。通过对CICIDS2017数据集的研究，传统的系统如SNORT和Suricata的检测率分别仅为71.2%和68.5%，并且存在较高的误报率。因此，需要一种能够提高检测率、同时保持较低误报率的新型网络安全防御系统。", "innovation": "本文创新地提出了一种自适应欺骗框架CADL（Cognitive-Adaptive Deception Layer），该系统结合了集成机器学习（随机森林、XGBoost、神经网络）、行为分析和一种协调信号总线架构，能够在检测到网络入侵时，根据攻击者的行为模式自适应地调整欺骗策略。通过这种多层次的行为分析和策略部署，CADL在50,000个CICIDS2017测试样本上的检测率达到99.88%，同时误报率仅为0.13%，显著优于传统的入侵检测系统。", "conclusion": "研究成果表明，CADL系统在保持较低误报率的同时，能够显著提高网络攻击检测率。该系统通过提供开放源代码实现和透明的性能指标，为网络安全防御领域提供了一种经济实惠且易于获取的解决方案，为替代每年每主机150-400美元的商业欺骗平台提供了可能的选择。"}
{"llm_update_time": "20251006", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.02499", "html_url": "https://arxiv.org/abs/2510.02499", "title": "超越线性扩散：改进的稀有条件生成建模表示", "title_en": "Beyond Linear Diffusions: Improved Representations for Rare Conditional Generative Modeling", "authors": "Kulunu Dharmakeerthi,Yousef El-Laham,Henry H. Wong,Vamsi K. Potluru,Changhong He,Taosong He", "background": "扩散模型已经成为了机器学习和人工智能系统中强大的生成框架，但当前主要研究集中在线性扩散上，而在建模条件分布$P(Y|X=x)$时，当$P(X=x)$很小的时候，这些方法会面临显著挑战。在这些区域，用于训练的数据样本很少或没有，这使得在这种环境下模型相应的条件密度变得困难。该研究探讨了如何通过改变数据表示和前向方案来减少在条件空间低概率区域学习分数生成模型的样本复杂度。灵感来自于条件极值理论，研究精确描述了在条件变量$X$的尾部区域中的方法。通过合适的数据表示，研究证明了具有数据驱动的非线性漂移项的扩散优于标准扩散模型，更适宜于建模尾部事件，在两个合成数据集和一个真实世界金融数据集的经验验证中，验证了尾向自适应方法在极端条件下的响应分布建模中的显著优势。", "innovation": "该研究提出了一种适应低概率区域的方法，通过改变数据表示和前向方案，使得在这些区域学习分数生成模型的样本复杂性较低，尤其基于非线性的漂移项的扩散方法最适合于条件变量$X$的尾部区域建模尾事件。研究通过两个合成数据集和一个金融数据集的实际验证，证明了在极端条件下的响应分布更加准确，相比标准的扩散模型有显著改进。", "conclusion": "最终，研究展示了一种尾适应的扩散模型，这种模型在低概率条件下能更有效地进行条件生成建模，尤其是在处理尾部事件时表现出色，验证了这种方法比标准扩散模型在极端条件下更优。"}
{"llm_update_time": "20251006", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.02532", "html_url": "https://arxiv.org/abs/2510.02532", "title": "使用超核岭回归学习多索引模型", "title_en": "Learning Multi-Index Models with Hyper-Kernel Ridge Regression", "authors": "Shuo Huang,Hippolyte Labarrière,Ernesto De Vito,Tomaso Poggio,Lorenzo Rosasco", "background": "深度神经网络在高维问题中表现出色，远超出了诸如核方法这类模型，后者因维度诅咒而表现不佳。然而，这种成功背后的理论基础仍不明确。本文认为学习任务的组成结构是决定深度网络在何时能超越其他方法的关键因素。基于这一想法，我们探讨了一个简单的组成模型——多索引模型（MIM），并引入了一种结合神经网络和核方法的方法——超核岭回归（HKRR），展示了一种主动学习MIM的样本复杂度结果，从而突破了维度诅咒。", "innovation": "本文的主要贡献在于提出了超核岭回归（HKRR）方法，并证明了其能够适应性地学习多索引模型（MIM），克服了维度诅咒。此外，作者还利用估计器的核性质开发了定制优化方法，并通过交替最小化和交替梯度方法进行了理论和数值对比分析，进一步验证了其理论结果的有效性。", "conclusion": "研究表明，通过使用超核岭回归，我们能够在高维度下有效地学习多索引模型。这种方法不仅适应性地学习了模型，还通过优化方法提高了学习效率，为理解深度神经网络的成功原因提供了一种新的视角。"}
{"llm_update_time": "20251006", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.02611", "html_url": "https://arxiv.org/abs/2510.02611", "title": "温度采样在测试时缩放中的作用", "title_en": "On the Role of Temperature Sampling in Test-Time Scaling", "authors": "Yuheng Wu,Azalia Mirhoseini,Thierry Tambe", "background": "大量语言模型（LLMs）可以通过测试时缩放（TTS）来提升推理能力，即生成多个推理路径并选择最優的一条。已有研究表明，增加采样数量K（即生成的推理路径数量）能够逐步提高准确率。然而，本研究发现这种提升并不一定在较大K值时继续有效，某些棘手的问题可能在大量路径的情况下仍然没有解决。此外，不同的温度采样值能够解决不同问题集，这意味着单一温度采样仅探索了模型潜能的一部分。", "innovation": "研究提出在温度维度上进行缩放的方法，这种方法扩展了LLMs的推理边界。通过在Qwen3（0.6B，1.7B，4B，8B）和五个代表性推理基准（AIME 2024/2025，MATH500，LiveCodeBench，Hi-ToM）上进行平均测试，温度缩放在单温度TTS的基础上额外提高了7.3个百分点。温度缩放还使得基础模型可以在不进行额外后训练的情况下达到与强化学习（RL）训练模型相当的性能。研究还设计了一种多温度投票方法以降低温度缩放的开销。", "conclusion": "实验结果表明，TTS比以往认为的更加有力，温度缩放提供了一种简单且有效的手段来释放基础模型的潜在能力。"}
{"llm_update_time": "20251006", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.02528", "html_url": "https://arxiv.org/abs/2510.02528", "title": "多模态功能向量用于空间关系", "title_en": "Multimodal Function Vectors for Spatial Relations", "authors": "Shuhao Fu,Esther Goldberg,Ying Nian Wu,Hongjing Lu", "background": "大型多模态模型（LMMs）能够从有限的多模态示例中进行上下文学习，但其内部机制依然难以理解。这项研究基于大型语言模型的工作，发现OpenFlamingo-4B视觉语言模型中一小部分注意力头负责空间关系的表征传递。通过因果中介分析，作者识别出对关系预测影响较大的注意力头，并提取多模态功能向量以改善零样本推理时的准确度。这些多模态功能向量在少量训练数据辅助下进一步微调，能够显著优于上下文学习基准。最后，研究表明特定空间关系的功能向量可以线性组合，以解决未见过的空间关系的类比问题，展现了该方法的强大泛化能力。", "innovation": "研究发现OpenFlamingo-4B模型中一小部分注意力头负责空间关系的表征传递。通过因果中介分析识别对关系预测影响较大的注意力头，并从中提取多模态功能向量。这些向量在少量训练数据下可进一步微调，并表现出优秀的零样本学习能力和泛化能力，可线性组合以解决未见过的空间关系的类比问题。", "conclusion": "LMMs内部编码了空间关系知识，这些知识通过局部内部结构系统性地提取和优化。这一方法有助于我们更好地理解模型模块性，并提升LMMs在关系推理方面的控制。"}
{"llm_update_time": "20251006", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.02524", "html_url": "https://arxiv.org/abs/2510.02524", "title": "解开句法：语言模型如何学习上下文自由文法", "title_en": "Unraveling Syntax: How Language Models Learn Context-Free Grammars", "authors": "Laura Ying Schulz,Daniel Mitropolsky,Tomaso Poggio", "background": "当前的大规模语言模型在语法学习方面取得了显著成果，但人们对它们的学习动态知之甚少。本文的一个重要背景是，一些主要语言领域的句法，如自然语言句法、编程语言、算术问题等，可以用概率上下文自由文法（PCFGs）来表示。因此，研究语言模型如何学习这些结构对理解它们的工作机制至关重要。", "innovation": "本文提出了一个新的框架来研究语言模型如何获取句法知识。通过将小型模型训练在从PCFG生成的合成语言上，以精确控制语法的复杂性、递归深度和子句法结构。研究证明了多个关于训练损失和Kullback-Leibler分歧的递归公式。模型的损失在所有子句法结构上平行降低，与儿童学习语言的顺序不同。并且证明子句法预训练可以改善小型模型的最终损失，预训练模型能够更好地适应语法的子结构。此外，研究揭示了模型在处理更深层递归结构时存在的挑战，这揭示了神经网络在表示层次句法结构方面的根本性难题。", "conclusion": "总体而言，这项工作首次在PCFG上研究了转换器的学习动态，从而为语言模型的学习机制提供了一个灵活的测试平台，开启了这个领域研究的新方向，提出了许多待解决的问题。"}
{"llm_update_time": "20251006", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.02677", "html_url": "https://arxiv.org/abs/2510.02677", "title": "ARMs: 适应性多模态模型对抗插件攻击的红队代理", "title_en": "ARMs: Adaptive Red-Teaming Agent against Multimodal Models with Plug-and-Play Attacks", "authors": "Zhaorun Chen,Xun Liu,Mintong Kang,Jiawei Zhang,Minzhou Pan,Shuang Yang,Bo Li", "background": "随着视觉-语言模型（VLMs）的重要性日益增加，它们的多模态接口也引入了新的安全漏洞，这使得安全评估变得既具有挑战性又极为关键。现有的红队研究往往局限于有限的对抗模式，或者依赖于手工工程方法，不能大规模地探索新兴的真实世界VLM漏洞。", "innovation": "为解决这一问题，我们提出了ARMs，这是一种自适应红队代理，系统地开展了全面的VLM风险评估。ARMs采用增强推理的多步骤编排自动优化多种红队策略，以有效从目标VLM中引出有害输出。我们还提出了包括理由劫持、上下文遮蔽在内的11种新型多模态攻击策略，整合了17种红队算法到ARMs中，通过模型上下文协议（MCP）。我们设计了一层记忆结构，并引入了一种epsilon贪婪攻击探索算法，以平衡攻击的多样性和有效性。实验证明，ARMs在实例和策略基准测试中实现了最优攻击成功率，比基线结果平均高出52.1%，在Claude-4-Sonnet上更是超过90%。此外，我们通过ARMs生成了大量不同的红队实例，揭示了VLMs中的新型漏洞，并构建了一个包含30000多个实例、覆盖51个不同风险类别的大规模多模态安全数据集ARMs-Bench。使用ARMs-Bench进行安全性微调显著提高了VLMs的鲁棒性，同时保留其广泛用途，为对抗新兴威胁提供了实质性指导。", "conclusion": "ARMs通过自适应的红队策略和多模态攻击策略，显著提高了多模态模型的安全评估和对抗能力，揭示了新型漏洞，并推动了多模态模型安全性研究的发展。"}
{"llm_update_time": "20251006", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.02671", "html_url": "https://arxiv.org/abs/2510.02671", "title": "特征差距中的不确定性：基于上下文问答的LLM元确信量化", "title_en": "Uncertainty as Feature Gaps: Epistemic Uncertainty Quantification of LLMs in Contextual Question-Answering", "authors": "Yavuz Bakman,Sungmin Kang,Zhiqi Huang,Duygu Nur Yaldiz,Catarina G. Belém,Chenyang Zhu,Anoop Kumar,Alfy Samuel,Salman Avestimehr,Daben Liu,Sai Praneeth Karimireddy", "background": "不确定性量化(UQ)研究主要集中在闭卷事实问答(QA)中，而上下文QA领域尚未被充分探索。然而，上下文QA在实际应用中具有重要价值。本文聚焦于上下文QA任务中的UQ，并提出了一种基于理论的方法来量化元确信。不确定性衡量方法定义为给定模型的预测分布和未知真实分布的交叉熵。该方法通过分解不确定性量度，分离出元确信部分，并通过完美提示的理想模型来逼近真实分布。", "innovation": "本文提出了一种新的不确定性量化方法，通过分解不确定性量度来分离元确信部分，并基于理想模型来逼近真实分布，从而量化元确信。此外，该方法通过特征差距的方式来解释元确信，并通过解释上下文依赖性、上下文理解能力和诚实性来进一步具体化。最后，基于该通用框架，本文开发了一种聚合方法来形成一个稳健的不确定性评分。", "conclusion": "本文方法在多个问答基准测试中表现出色，无论是同分布还是异分布情况下，相较于现有的无监督和监督UQ方法，在概率正确率(PRR)上获得了最高13点的提升，同时几乎不影响推理的负载。"}
{"llm_update_time": "20251006", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.02707", "html_url": "https://arxiv.org/abs/2510.02707", "title": "使用压缩感知比较的攻击无关型对抗攻击检测的统计方法", "title_en": "A Statistical Method for Attack-Agnostic Adversarial Attack Detection with Compressive Sensing Comparison", "authors": "Chinthana Wimalasuriya,Spyros Tragoudas", "background": "对抗攻击对现代机器学习系统构成了严重威胁，但现有的检测方法往往缺乏检测未见过的攻击或以高精度检测不同攻击类型的能力。因此，需要一种能够在神经网络部署前建立检测基线的方法，以便实现有效的实时对抗检测。本文介绍了通过将压缩/未压缩神经网络的行为进行对比来生成对抗存在度量的统计方法，以此来弥补现有检测方法的不足，实现对广泛攻击类型的近乎完美的检测，并显著降低假阳性率，使得该方法在实际应用中更加可靠和实用。", "innovation": "提出了一种统计方法，在神经网络部署前建立检测基线，通过将压缩/未压缩神经网络的行为进行对比来生成对抗存在度量，实现对广泛攻击类型的准确检测，大幅降低假阳性率，使得该方法在实际应用中更加可靠和实用。这种方法显著提升了对抗攻击检测的能力，弥补了现有检测方法的不足，尤其是在检测未知或不同类型的攻击方面表现出色。", "conclusion": "该统计方法通过压缩感知比较技术，在实际应用中实现了对广泛攻击类型的近乎完美的检测，显著降低了假阳性率，具有较高的准确性和可靠性，适用于广泛的对抗攻击检测应用场景。"}
{"llm_update_time": "20251006", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.02540", "html_url": "https://arxiv.org/abs/2510.02540", "title": "通过密度估计更快的核矩阵线性代数运算", "title_en": "Even Faster Kernel Matrix Linear Algebra via Density Estimation", "authors": "Rikhav Shah,Sandeep Silwal,Haike Xu", "background": "本文研究了核密度估计（KDE）在处理核矩阵相关的线性代数任务中的应用，涉及点集$\\mathbb{R}^d$中$n$个数据点的核矩阵。现有文献中有算法分别对矩阵-向量乘积、矩阵-矩阵乘积、谱范数和核矩阵所有元素之和等进行了研究，但本文在相对误差$(1+\\varepsilon)$的情况下提高了这些算法的性能。运行时间取决于维度$d$、点的数量$n$和目标误差$\\varepsilon$。", "innovation": "通过使用KDE查询来访问核矩阵，本文的算法在某些情况下对$n$的依赖性显著降低。相比于现有的最佳算法（Backurs, Indyk, Musco, and Wagner '21），本文的算法在多项式对误差$\\varepsilon$的依赖上有所改进，并且在计算核矩阵所有元素之和上进一步降低了对$n$的依赖性。此外，本文还提供了几个相关问题的下界，特别是为所研究问题提供了符号为二次的时间难以结果，从而揭示KDE方法的限制。", "conclusion": "本文通过研究KDE在核矩阵相关线性代数任务中的应用，提供了多项技术改进，特别是在降低与$n$相关的依赖性上取得了突破。同时，通过下界分析揭示了现有KDE方法的局限性。"}
{"llm_update_time": "20251006", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.02527", "html_url": "https://arxiv.org/abs/2510.02527", "title": "使用马尔可夫链蒙特卡洛的自监督扩散模型微调用于成本态初始化", "title_en": "Self-supervised diffusion model fine-tuning for costate initialization using Markov chain Monte Carlo", "authors": "Jannik Graebner,Ryne Beeson", "background": "全球搜索和优化长时间、低推力航天器航路对于复杂的解空间和成本态变量的良好初始猜测具有挑战性，尤其是在多体环境中更加困难。给定部分帕累托最优前沿的数据，希望找到一种灵活的方法来完成帕累托前沿，并且能够为相关轨迹问题寻找新的前沿。因此，需要一种方法来用马尔可夫链蒙特卡洛算法配合自监督微调方法来达到上述目标，从而避免单独聚焦的数据生成阶段。", "innovation": "提出了使用条件扩散模型来表示候选最优轨迹解的分布，在此基础上引入马尔可夫链蒙特卡洛算法结合自监督微调来优化成本态变量。特别是使用了随机游走马尔可夫算法以及基于约束违规和任务目标函数高效评估的基于奖励加权训练方式来细化扩散模型。该框架减少了单独聚焦的数据生成阶段的需求，并通过两个问题的数值实验展示了提高样本质量以及明确导向帕累托最优的能力。", "conclusion": "通过自监督扩散模型微调和马尔可夫链蒙特卡洛算法结合的方法，该研究不但验证了其在扩展部分帕累托最优前沿的有效性，还展示了对于不同多体环境之间轨迹问题的生成能力。该方法能够改进样本质量并明确导向帕累托最优，为航天器轨迹优化提供了新的途径。"}
{"llm_update_time": "20251006", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.02735", "html_url": "https://arxiv.org/abs/2510.02735", "title": "通过Goldstein次微分的投影随机梯度下降的数量化收敛分析", "title_en": "Quantitative Convergence Analysis of Projected Stochastic Gradient Descent for Non-Convex Losses via the Goldstein Subdifferential", "authors": "Yuping Zheng,Andrew Lamperski", "background": "随机梯度下降(SGD)是机器学习领域广泛工作背后的主算法。当施加约束时，这些约束通常通过投影来实现，从而得到了投影随机梯度算法。近年来，大量研究关注了非凸损失函数下投影SGD的收敛性质，特别是从阿西莫夫和非阿西莫夫设置的角度。但是，这些结果与关于无约束SGD的工作无法直接比较，因为莫洛奥包络构造改变了梯度。其他基于梯度映射的常见度量方法要求借助于降低方差的方法（如分块方法）才能保证收敛性。", "innovation": "本文对非凸损失函数下的投影SGD进行了分析，通过Goldstein次微分来测量收敛性。所提的收敛标准在无约束情况下直接简化为常用标准，并且不依赖于方差减少方法也能得到收敛性。结果适用于相互独立同分布（IID）或满足混合条件的数据，在这些情况下得到了阿西莫夫收敛和期望$O(N^{-1/3})$的非阿西莫夫结果。对于互为超高斯分布的数据，我们获得了几乎确定的阿西莫夫收敛和高概率的期望$O(N^{-1/5})$的非阿西莫夫结果。这些是首次关于非凸损失函数下的投影SGD的非阿西莫夫高概率结果，填补了研究空白。", "conclusion": "针对非凸损失函数下的投影SGD进行了研究，使用Goldstein次微分作为收敛性指标，提出了无需方差减少方法即可收敛的新方法，适用于各种类型的数据，并提供了非阿西莫夫高概率的结果。"}
{"llm_update_time": "20251006", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.02789", "html_url": "https://arxiv.org/abs/2510.02789", "title": "对齐你的查询：用于多模态医学对象检测的表示对齐", "title_en": "Align Your Query: Representation Alignment for Multimodality Medical Object Detection", "authors": "Ara Seo,Bryan Sangwoo Kim,Hyungjin Chung,Jong Chul Ye", "background": "医学对象检测在使用单一检测器对混合医学模态（如X射线、CT、MRI）进行训练时会遭受挑战，因为这些模态具有异质统计特征和独立的表现空间。现有研究尚未有效解决这一问题，尽管存在一些奏效的方法，但在实际应用中仍然面临挑战，主要是由于这些方法通常需要显著增加计算成本或改变网络结构。", "innovation": "该论文提出了一种简单的、无特定检测器的方法，通过定义模态令牌并引入多模态上下文注意力（MoCA）机制，将对象查询表示随模态上下文对齐到模态令牌中。此外，提出了QueryREPA预训练阶段，通过任务特定的对比目标实现查询代表与模态令牌对齐。这两种方法都不需要修改网络结构，同时降低了计算成本，提升检测性能。", "conclusion": "该论文提出的方法在多种医学模态的共同训练中，能够提高AP性能，几乎没有额外开销，且无需网络结构改变，为多模态医学对象检测提供了一条实用的道路。"}
{"llm_update_time": "20251006", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.02738", "html_url": "https://arxiv.org/abs/2510.02738", "title": "流体中的力场：基于力和示例引导仿真实验数据的3D柔顺流动匹配策略学习", "title_en": "Flow with the Force Field: Learning 3D Compliant Flow Matching Policies from Force and Demonstration-Guided Simulation Data", "authors": "Tianyu Li,Yihan Li,Zizhe Zhang,Nadia Figueroa", "background": "近年来，视觉运动策略在视觉-运动任务中取得了进步，但仍面临高接触任务的挑战。处理柔顺性与力的问题要求机器人操作任务实现连续接触。多数视觉运动策略忽视了柔顺性，未能充分考虑与现实世界的物理互动的重要性，导致了在不确定性下的过力接触或不稳固的行为。将力的信息纳入基于视觉的模仿学习可以提高接触意识，但可能需要大量的数据才能有效。一种应对数据稀缺的解决办法是在仿真中生成数据，然而这需要大量耗时的计算来生成足够高质量的数据，以避免从仿真到现实的差距问题。", "innovation": "本文提出了一种在仿真中生成基于力的数据的框架，并通过单一人类演示实施。文章展示了将柔顺策略与视觉运动策略结合对于从合成数据中学习到的策略性能提升的作用。验证表明，这种方法在真实机器人任务（如非抓握块翻转和双手中物移动）中可以实现可靠的接触维护和对新颖条件的适应能力。", "conclusion": "文章验证了通过深度融合力信息与模仿学习方法提升视觉运动策略适应性与柔顺性的有效性，并展示了该策略在实际任务中的可靠性和适应性。"}
{"llm_update_time": "20251006", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.02760", "html_url": "https://arxiv.org/abs/2510.02760", "title": "在数字病理学中的层次泛化类发现用于脑肿瘤分类", "title_en": "Hierarchical Generalized Category Discovery for Brain Tumor Classification in Digital Pathology", "authors": "Matthias Perkonigg,Patrick Rockenschaub,Georg Göbel,Adelheid Wöhrer", "background": "准确的脑肿瘤分类对神经肿瘤手术中的术中决策至关重要。现有的方法仅限于固定的预定义类别集，因此无法捕捉训练中不可用的肿瘤类型模式。无监督学习可以提取通用特征，但缺乏从标记数据中整合先验知识的能力，而半监督方法通常假定标记数据中代表了所有潜在类别。Generalized Category Discovery (GCD)旨在弥合这一差距，通过将已知类别和未知类别分类到未标记数据中来实现。为了反映脑肿瘤分类体系结构的层次结构，本研究引入了一种新的方法Hierarchical Generalized Category Discovery for Brain Tumor Classification (HGCD-BT)，结合了层次聚类和对比学习。HGCD-BT扩展了基于对比学习的GCD方法，通过引入一种新颖的半监督层次聚类损失来结合层次聚类。", "innovation": "引入了Hierarchical Generalized Category Discovery for Brain Tumor Classification (HGCD-BT)方法，该方法将层次聚类与对比学习相结合，并通过半监督层次聚类损失扩展了基于对比学习的GCD方法。该方法在OpenSRH数据集上的表现优于现有的GCD方法，特别是在识别新的尚未见过的肿瘤类别方面取得了+28%的准确性提升，并在数字脑肿瘤图谱上的幻灯片级分类上证明了其跨成像模态的泛化能力。", "conclusion": "HGCD-BT方法在OpenSRH数据集和数字脑肿瘤图谱上的实验结果表明，该方法在识别新的肿瘤类别和跨不同成像模态的分类任务中表现良好，证明了其在脑肿瘤分类中的有效性和潜在的应用价值。"}
{"llm_update_time": "20251006", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.02712", "html_url": "https://arxiv.org/abs/2510.02712", "title": "Time-To-Inconsistency: A Survival Analysis of Large Language Model Robustness to Adversarial Attacks", "title_en": "Time-To-Inconsistency: A Survival Analysis of Large Language Model Robustness to Adversarial Attacks", "authors": "Yubo Li,Ramayya Krishnan,Rema Padman", "background": "大规模语言模型（LLMs）已经彻底改变了对话式人工智能，但它们在扩展多轮对话中的鲁棒性仍然不明确。现有评估框架主要集中在静态基准和单轮评估上，未能捕捉到实际对话中对话退化的时间动态。本文利用生存分析首次全面研究了对话式人工智能的鲁棒性，分析了9个先进模型的36,951个对话轮次，将故障视作时间事件过程。研究表明，突变的提示到提示（P2P）语义漂移对对话失败非常有害，而渐进式的累积漂移则相对保护性更强，能够显著降低故障率并支持更长的对话。", "innovation": "本文提出了一种新的生存分析方法，通过使用Cox比例风险，加速失效时间以及随机生存森林方法，揭示了对话式人工智能鲁棒性的非凡时间动态。实证研究表明，启动到启动的语义漂移会对对话失败产生灾难性影响，而渐进式的累积漂移则显著降低了失败风险，促进更长的对话。AFT模型能够更好地预测对话失败，显示出卓越的区分能力和出色的校准能力。这些发现将生存分析确立为评估大规模语言模型鲁棒性的强大范式，为构建健壮的对话代理提供了具体的见解，并挑战了对话人工智能系统中语义一致性必要性的传统假设。", "conclusion": "生存分析为评估LLM的鲁棒性提供了强大的范式，为设计健壮的对话代理提供了具体见解，并挑战了对话人工智能系统中语义一致性的必要性假设。"}
{"llm_update_time": "20251006", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.02876", "html_url": "https://arxiv.org/abs/2510.02876", "title": "ELMF4EggQ: 使用多模态特征融合的集成学习进行非破坏性鸡蛋质量评估", "title_en": "ELMF4EggQ: Ensemble Learning with Multimodal Feature Fusion for Non-Destructive Egg Quality Assessment", "authors": "Md Zahim Hassan,Md. Osama,Muhammad Ashad Kabir,Md. Saiful Islam,Zannatul Naim", "background": "确保食品安全、维持产品质量标准和商业养鸡生产中的操作效率，需要对鸡蛋质量进行准确且非破坏性的评估。现有的评估方法通常依赖于内部质量测量，但本文通过使用外部特征如图像、形状和重量来实现非破坏性评估，旨在提供一种新的评估方法。", "innovation": "提出了一种名为ELMF4EggQ的集成学习框架，利用多模态特征融合来仅通过外部属性（图像、形状和重量）对鸡蛋等级和新鲜度进行分类。这是首次使用仅外部特征的非侵入性方法进行内部鸡蛋质量评估的研究，并且首次发布了相应的标注数据集。该框架结合了从外部鸡蛋图像中提取的深度特征和如形状和重量等结构特性，提高了整体的表示性。", "conclusion": "实验结果表明，多模态方法在等级分类和新鲜度预测方面显著优于仅图像或仅基于形状和重量的方法，表明使用融合多模态特征进行非破坏性鸡蛋质量评估具有良好的发展前景。"}
{"llm_update_time": "20251006", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.02795", "html_url": "https://arxiv.org/abs/2510.02795", "title": " Pareto-optimal 非均匀语言生成", "title_en": "Pareto-optimal Non-uniform Language Generation", "authors": "Moses Charikar,Chirag Pabbaraju", "background": "Kleinberg和Mullainathan (2024)提出了一个语言生成的极限模型：给定一个可数的语言集合，以及一个对手按某种语言L的字符串列表进行枚举，目标是从目标语言生成新字符串，使得所有在某个有限时间之后生成的字符串都是有效的。Li, Raman和Tewari (2024)以及Charikar和Pabbaraju (2024)在此模型中提供了强大的非均匀生成保证，给出了算法，在看到一定数量的不同输入字符串后，能够从L中生成新的有效字符串，这个数量t(L)仅依赖于L（和集合），而不是枚举顺序。然而，对于这两种工作中的算法，不同语言的生成时间t(L)往往是次优的。", "innovation": "本文研究了非均匀语言生成的Pareto最优性。提出了一个算法，其生成时间t_star(L)是（几乎）Pareto最优的：任何其他算法如果其对于某些语言L的生成时间严格小于t_star(L)，那么它对于某些其他语言L’的生成时间必须严格差于t_star(L’)。Pareto最优性是基于非均匀生成所能达到的最佳效果。我们的算法框架还能适应在实际场景中更有意义的噪声生成和代表生成进一步提供Pareto最优的非均匀生成算法。", "conclusion": "我们研究了非均匀语言生成的Pareto最优性，提出了一个适应噪声生成和代表生成的Pareto最优非均匀生成算法。"}
{"llm_update_time": "20251006", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.02915", "html_url": "https://arxiv.org/abs/2510.02915", "title": "WavInWav: Time-domain Speech Hiding via Invertible Neural Network", "title_en": "WavInWav: Time-domain Speech Hiding via Invertible Neural Network", "authors": "Wei Fan,Kejiang Chen,Xiangkun Wang,Weiming Zhang,Nenghai Yu", "background": "数据隐藏对于数字媒体中的安全通信至关重要，近期的深度神经网络（DNN）发展为有效嵌入秘密信息提供了增强的方法。然而，之前的音频隐藏方法在恢复秘密音频时常常产生不满意的质量，这是由于它们在时间-频率关系建模上的固有限制。本文探讨了这些问题，并提出了一种新的基于DNN的方法。使用基于流的可逆神经网络直接链接隐写音频、原始音频和秘密音频，增强了嵌入和提取信息的可逆性。为了应对时间-频率变换期间常出现的问题，这些变换会降低恢复秘密音频的质量，我们在时域信号上实现了时间-频率损失。这种方法不仅保留了时间-频率约束的优势，还增强了信息恢复的可逆性，这对于实际应用来说是至关重要的。", "innovation": "本文提出了一种新的DNN基方法，使用流式可逆神经网络直接连接隐写音频、原始音频和秘密音频，增强了嵌入和提取信息的可逆性。同时通过在时域信号上实现时间-频率损失，应对时间-频率变换带来的问题，保障了信息恢复的可逆性。此外，还加入了加密技术以保护隐藏数据免受未经授权的访问。", "conclusion": "在VCTK和LibriSpeech数据集上的实验结果显示，本文方法在主观和客观指标上优于先前的方法，且对不同类型的噪声具有鲁棒性，表明其在针对性安全通信场景中的实用性。"}
{"llm_update_time": "20251006", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.02917", "html_url": "https://arxiv.org/abs/2510.02917", "title": "通过稀疏自编码器对LLMs中代码正确性的机制可解释性", "title_en": "Mechanistic Interpretability of Code Correctness in LLMs via Sparse Autoencoders", "authors": "Kriz Tahimic,Charibeth Cheng", "background": "随着大型语言模型在软件开发中的重要性日益增加，越来越多由AI建议的代码被纳入生产环境中，因此理解这些模型内部的正确性机制对于确保安全部署变得至关重要。", "innovation": "作者应用稀疏自编码器来分解LLM的表示，通过t-统计学选择预测器方向，并利用基模型表示分离得分进行引导方向的选择，进一步通过引导、注意力分析和权重正交化来分析其机理性质。研究发现，代码正确性方向在LLM中可以可靠地预测错误代码，尽管改正能力在统计上是显著的，但它在修复错误和保留正确代码之间存在权衡。", "conclusion": "成功的代码生成依赖于对测试案例的关注，而不是问题描述。基模型中识别的方向在指令微调后仍然有效，表明预训练中学习到的代码正确机制在微调中得到了重新利用。这些机制性的见解提出了三种实用应用：提示策略应优先选择测试示例而非复杂的描述问题；预测器方向可作为开发人员审查中的错误警报；这些相同的预测器还可以指导选择性的引导，仅在预期出现错误时进行干预，以防止由于不断引导而导致的代码腐坏。"}
{"llm_update_time": "20251006", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.02926", "html_url": "https://arxiv.org/abs/2510.02926", "title": "使用HADOF进行可扩展量子优化：Hamiltonian自动分解优化框架", "title_en": "Scalable Quantum Optimisation using HADOF: Hamiltonian Auto-Decomposition Optimisation Framework", "authors": "Namasi G Sankar,Georgios Miliotis,Simon Caton", "background": "量子退火(QA)和QAOA是适用于近期内的NISQ系统的组合问题近似解寻找的有前景的量子优化算法。许多NP难题可以重述为二次无约束二元优化(QUBO)，进而映射到量子哈密顿量。然而，当前NISQ设备的有限量子比特数量限制了这些算法的实际部署。", "innovation": "提出了一种名为HADOF（Hamiltonian自动分解优化框架）的量子优化框架，通过迭代策略自动将QUBO哈密顿量分解为可分别用基于哈密顿量的优化器（如QAOA、QA或模拟退火(SA)）优化的子哈密顿量，并将它们聚合为一个全局解决方案。结果显示HADOF在问题规模远远超过可用量子比特的情况下仍具有可比较的准确性和运行时间。", "conclusion": "HADOF框架展示了在IBM量子计算机上对一个玩具问题的应用前景，对于实际的量子优化应用具有潜力。"}
{"llm_update_time": "20251006", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.02986", "html_url": "https://arxiv.org/abs/2510.02986", "title": "FR-LUX: 采用摩擦感知与条件规制策略优化的可执行投资组合管理", "title_en": "FR-LUX: Friction-Aware, Regime-Conditioned Policy Optimization for Implementable Portfolio Management", "authors": "Jian'an Zhang", "background": "纸质投资组合在真实交易中往往因交易成本和市场制度变迁（制度转变）的原因而失败。为了应对这些挑战，本文提出了一个摩擦感知、市场状态条件化的强化学习框架FR-LUX。", "innovation": "FR-LUX框架包括三个创新元素：(i) 细微结构一致的执行模型，结合了比例成本和影响成本，并直接嵌入奖励中；(ii) 交易空间信任区域限制了库存流量的变化，而不是对逻辑的变化，从而提供稳定的低换手率更新；(iii) 显式的市场状态条件，使策略在LL/LH/HL/HH状态中专门化，而不分割数据。实验结果显示，FR-LUX在多种随机种子下实现了最高的平均夏普比率，保持了比基准更强的平稳成本收益曲线，且在给定的换手率预算下具有更好的风险收益效率。", "conclusion": "FR-LUX方法在不同的市场状态和成本水平下提供了严格的统计的优势，并提供了严格的优化保证。成本通过标准流动性代理进行校准，场景级推断避免了伪重复，所有图表和表格均可以通过发布的文件进行复现。"}
{"llm_update_time": "20251006", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.02983", "html_url": "https://arxiv.org/abs/2510.02983", "title": "基于oracle的凸体均匀取样", "title_en": "Oracle-based Uniform Sampling from Convex Bodies", "authors": "Thanh Dang,Jiaming Liang", "background": "本文提出了用于从凸体 $K$ 上均匀抽样的新的马尔可夫链蒙特卡洛算法。此算法基于交替采样框架/近邻采样器，通过使用增广分布上的吉布斯采样，并假设可以访问所谓的受限制高斯Oracle (RGO)。对RGO的有效实现对于在一凸体 $K$ 上的均匀采样至关重要。", "innovation": "本文的关键贡献在于通过拒绝采样及访问凸体 $K$ 上的投影Oracle或分离Oracle，高效地实现了RGO，从而能够有效地进行均匀抽样。在两种Oracle情况下，均建立了无偏样本的非退化复杂度，准确度通过Rényi离散度或 $\boldsymbol{\boldsymbol{\times^2}}$ 离散度衡量。", "conclusion": "本文给出了实现均匀采样的具体算法，并通过非退化复杂度确保了采样的准确度，该方法基于凸体 $K$ 上传递的Oracle。"}
{"llm_update_time": "20251006", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.02757", "html_url": "https://arxiv.org/abs/2510.02757", "title": "神经跃动ODE作为生成模型", "title_en": "Neural Jump ODEs as Generative Models", "authors": "Robert A. Crowell,Florian Krach,Josef Teichmann", "background": "本文探讨了如何使用神经跃动ODE（NJODEs）作为伊藤过程的生成模型。给定固定基础伊藤过程的离散观察样本，NJODE框架可以用来近似伊藤过程的漂移和扩散系数。在标准伊藤过程正则性假设下，证明了在极限情况下，可以恢复真实的参数。这表明，使用学习到的系数从对应伊藤过程采样，在极限情况下可以生成与真实基础过程具有相同分布的样本。与其他生成机器学习模型相比，该方法的优点是不需要对抗训练，并且可以通过观察样本训练预测模型，而无需在训练过程中生成样本来近似分布。此外，NJODE框架可以自然地处理不规则采样数据、缺失值以及路径依赖动态，使该方法能够应用于实际场景。特别是对于伊藤过程依赖路径系数，NJODE可以最优地估计它们并据此生成新的路径，这些路径基于离散的、不规则的和不完整的历史观测数据", "innovation": "提出了一种使用神经跃动ODE框架作为伊藤过程的生成模型的方法，该方法能够在不需要对抗训练的情况下通过观察样本进行预测性训练，自然处理不规则采样数据和路径依赖动态。此外，NJODE能够根据过去观测最优地学习路径依赖系数，以便在给定部分观测数据的情况下生成新的路径。", "conclusion": "综上所述，神经跃动ODE能够作为强大的生成模型使用，特别适用于处理实际场景中常见的不规则采样数据和路径依赖动态。"}
{"llm_update_time": "20251006", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.02829", "html_url": "https://arxiv.org/abs/2510.02829", "title": "欧洲岛屿利益相关者中的土地利用-气候变化-生物多样性联动关系", "title_en": "The land use-climate change-biodiversity nexus in European islands stakeholders", "authors": "Aristides Moustakas,Irene Christoforidi,George Zittis,Nazli Demirel,Mauro Fois,Savvas Zotos,Eirini Gallou,Valentini Stamatiadou,Elli Tzirkalli,Christos Zoumides,Kristina Košić,Aikaterini Christopoulou,Aleksandra Dragin,Damian Łowicki,Artur Gil,Bruna Almeida,Panos Chrysos,Mario V. Balzan,Mark D.C. Mansoldo,Rannveig Ólafsdóttir,Cigdem Kaptan Ayhan,Lutfi Atay,Mirela Tase,Vladimir Stojanović,Maja Mijatov Ladičorbić,Juan Pedro Díaz,Francisco Javier Expósito,Sonia Quiroga,Miguel Ángel Casquet Cano,Haoran Wang,Cristina Suárez,Paraskevi Manolaki,Ioannis N. Vogiatzakis", "background": "为了促进气候变化适应和缓解，理解在土地使用和气候变化方面的利益相关者视角及其知识缺口至关重要。这项研究通过咨询21个欧洲岛屿的利益相关者，探讨了与生态系统服务相关的气候变化和土地使用变化问题。研究覆盖了气候相关因素如温度、降水量、湿度、极端天气和风力，以及土地使用变化如森林砍伐、海岸退化、栖息地保护、可再生能源设施、湿地等，还考虑了入侵物种、水资源或能源稀缺、基础设施问题和紧缩政策等其他问题。通过机器学习分析这些影响的感知，以量化它们的影响程度。研究表明，温度被认为是主要的气候特征，而森林砍伐是主要的土地使用特征。水资源问题是利益相关者优先考虑的主要问题之一，能源问题和可再生能源相关问题也构成了综合的气候和土地使用风险。尽管存在地理差异，所有利益相关者都共同关注生物多样性的负面影响，但在气候和土地使用影响上有所不同。水资源、能源和可再生能源问题是严重的问题，需要采取管理措施。", "innovation": "本研究采用机器学习方法分析气候和土地使用变化对生态系统服务的影响，通过咨询欧洲21个岛屿的利益相关者，揭示了温度和森林砍伐作为主要的气候和土地使用特征，以及水资源问题是优先考虑的主要问题。这项研究特别强调了利益相关者对气候变化和土地使用变化影响的复杂理解，并将其用于制定管理措施。", "conclusion": "研究表明，利益相关者普遍认为气候变化和土地使用变化对生态系统服务有负面影响，尤其是自然栖息地的破坏和生物多样性的损失。同时，他们指出水资源、能源和可再生能源问题构成了一定的挑战，需要进行有效管理来应对这些风险。"}
{"llm_update_time": "20251006", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.02916", "html_url": "https://arxiv.org/abs/2510.02916", "title": "SALSA-V：视频生成短路增强长形式同步音频", "title_en": "SALSA-V: Shortcut-Augmented Long-form Synchronized Audio from Videos", "authors": "Amir Dellali,Luca A. Lanzendörfer,Florian Grötschla,Roger Wattenhofer", "background": "当前的研究主要集中在从视频生成高保真、长时间的音频。现有的方法在音频同步和对齐视频内容方面存在一定的挑战，且生成高质量音频样本通常需要较多的采样步骤和特定的调整。SALSA-V为解决这些问题提供了一个新的方法。", "innovation": "1. 提出了一个掩码扩散目标，实现了基于音频条件生成，并能无缝合成无约束长度的音频序列。\n2. 集成了快速生成高质量音频样本的短路损失，仅需八次采样步骤，便于近实时应用，无需额外的微调或重新训练。\n3. 使用随机掩码训练，使模型能够匹配参考音频样本的频谱特性，适用于专业的音频合成任务，如Foley生成和声音设计。", "conclusion": "SALSA-V在定量评估和人听取测试中显著优于现有的最先进的方法，表现出了在音频视频对齐和同步方面的优越能力。该模型的随机掩码训练方式增强了其在专业音频合成任务中的适用性。"}
{"llm_update_time": "20251006", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.02578", "html_url": "https://arxiv.org/abs/2510.02578", "title": "FLOWR.root：基于流匹配的基础模型，用于联合多用途的结构感知3D配体生成和亲和力预测", "title_en": "FLOWR.root: A flow matching based foundation model for joint multi-purpose structure-aware 3D ligand generation and affinity prediction", "authors": "Julian Cremer,Tuan Le,Mohammad M. Ghahremanpour,Emilia Sługocka,Filipe Menezes,Djork-Arné Clevert", "background": "该研究提出了一种全新的配体生成模型FLOWR.root，该模型能够结合计算化学和机器学习的方法，实现基于口袋的3D配体生成以及配体与蛋白质结合亲和力的预测。模型不仅能够支持从头生成、条件采样、片段扩展，并且可以同时预测多种亲和力指标（如pIC50, pKi, pKd, pEC50）。这种模型的训练数据集包含大规模配体库与各种蛋白质配体复合物，经过精细化训练和参数有效优化，使其能够针对特定项目进行适配。该模型通过结合大规模数据集和混合精度的蛋白质配体复合物，以及经过校准的共结晶数据集的精细调整，实现了在无条件3D分子生成和基于口袋的配体设计中的最佳性能，生成的结构更加几何真实且不易变形。此外，该模型还引入了结合了亲和力预测的生成模块，不仅能够在测试集上显示更强的准确度，还在相关的基准测试中表现出更高的速度优势。基于模型灵活性，虽然它可以应用于广泛的药物设计任务，但为了特定项目的最佳适应性，仍需要进一步的微调。", "innovation": "该研究创新地提出了一种基于流匹配的新型配体生成模型FLOWR.root，该模型能够在3D空间中生成具备结构感知能力和生成的配体，并同时预测配体与特定蛋白质的结合亲和力。该模型创新点在于结合了广泛的数据集训练，包括大规模配体库与混合精度的蛋白质配体复合物，从而能够实现高效的微调，并针对特定项目的结构活性关系进行适配。此外，该模型中集成的亲和力预测模块能够显示更好的准确度，同时在基准测试中表现出明显的速度优势。FLOWR.root作为一个基础模型，其灵活性可以支持多种结构导向的药物设计任务，也表明了它在提高药物设计效率和准确度上的潜在价值。", "conclusion": "FLOWR.root模型在无条件3D分子生成和基于口袋的配体设计中达到了最先进的性能，生成的结构更加几何现实且易变形少。其集成的亲和力预测模块在测试集上显示了更高的准确度，并在相关的基准测试中展示了更高的速度优势。作为一种基础模型，FLOWR.root需要进一步微调适应特定项目，以获取更强的预测效果并实现与实验数据的强相关性。通过结构感知生成、亲和力估计以及属性指导抽样的整合，FLOWR.root为基于结构的药物设计提供了一个全面的基础框架，从先导物的识别到候选药物的优化，其潜在的应用前景广泛。这一模型展示了在计算化学和药物设计领域的新突破，具有重要的科学意义和应用前景。"}
{"llm_update_time": "20251006", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.03075", "html_url": "https://arxiv.org/abs/2510.03075", "title": "视觉生成模型中组成型泛化的驱动因素", "title_en": "What Drives Compositional Generalization in Visual Generative Models?", "authors": "Karim Farid,Rajat Sahay,Yumna Ali Alnaggar,Simon Schrodi,Volker Fischer,Cordelia Schmid,Thomas Brox", "background": "组成型泛化是指生成新型概念组合的能力，这一能力对于视觉生成模型至关重要。然而，引起或抑制这种能力的机制尚未完全理解。本文系统研究了各种设计选择如何以积极或消极方式影响图像和视频生成中的组成型泛化。", "innovation": "研究发现，两种关键因素影响组成型泛化：一是训练目标是否作用于离散或连续分布上；二是条件信息在训练期间对组成概念提供信息的程度。研究进一步表明，通过使用基于连续JEPA目标的辅助目标来放松MaskGIT中的离散损失，可以提高类似MaskGIT的离散模型的组成性能。", "conclusion": "本文通过实验研究了影响视觉生成模型中组成型泛化的因素，并提出了一种改进方法，以提高离散模型的组成性能。"}
{"llm_update_time": "20251006", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.02982", "html_url": "https://arxiv.org/abs/2510.02982", "title": "oRANS: 在嵌入DNS数据生成中的RANS机器学习模型的在线优化", "title_en": "oRANS: Online optimisation of RANS machine learning models with embedded DNS data generation", "authors": "Daniel Dehtyriov,Jonathan F. MacArt,Justin Sirignano", "background": "深度学习（DL）在加速和提升流体力学模拟的准确性方面展现了潜力，但其进展受限于高质量训练数据的稀缺性。这些数据的生成成本高昂且数量有限，通常只涵盖了少量的流体状态。因此，传统的离线训练方法容易过拟合，不能很好地推广到新的流态。本文介绍了基于在线优化框架的DL模型用于RANS闭合，旨在解决有限高质量数据集的问题。该框架通过在RANS领域的一个子区域嵌入DNS来动态生成训练数据，RANS解决方案为DNS提供边界条件，而DNS则提供平均速度和湍流统计，用于更新DL闭合模型。这种反馈循环使得闭合能够适应嵌入的DNS目标流，从而减少对预计算数据集的依赖，并提高跨分布性能。", "innovation": "本文提出了一种在线优化框架（oRANS），用于基于嵌入DNS数据生成的RANS闭合模型的优化。通过在RANS控制区域的子域中嵌入DNS，该框架可以动态生成训练数据，并且能够自适应嵌入的DNS目标流，从而避免依赖预计算数据集并提升模型的跨分布性能。这种方法已经在扰动Burgers方程和τ-Re分别为180、270、395和590的湍流通道流中得到了验证，显示出在线优化RANS模型显著优于离线训练和文献校准的闭合模型。", "conclusion": "本文提出的方法提供了一条规模化的途径，用于基于物理信息的机器学习闭合，能够生成数据自适应的低维模型，在不需要大量预计算训练数据集的情况下，实现跨流态的泛化能力。这种方法的主要局限在于当边界条件污染主导或域过短无法捕捉低波数模态时，其性能会下降。"}
{"llm_update_time": "20251006", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.03205", "html_url": "https://arxiv.org/abs/2510.03205", "title": "自动生成用于网络测试的数字孪生", "title_en": "Automatic Generation of Digital Twins for Network Testing", "authors": "Shenjia Ding,David Flynn,Paul Harvey", "background": "软件在电信网络的操作和管理中的使用不断增加，推动了行业向自主网络操作迈进。这一变化导致在部署前需要进行更严格的测试和验证。数字孪生可以补充现有的仿真或硬件方法，为测试提供环境，但它们的配置和执行需要大量的时间和人力。", "innovation": "本文探索了自动生成数字孪生的方法，以提供高效准确的验证工具，并与ITU-T自主网络架构的试验子系统保持一致。介绍了初始用例的实验结果，证明了此方法可自动创建高效且具有足够准确性的数字孪生，可以纳入现有的验证流程中。", "conclusion": "自动生成的数字孪生可以有效地辅助网络测试，提高测试效率和准确性。"}
{"llm_update_time": "20251006", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.03224", "html_url": "https://arxiv.org/abs/2510.03224", "title": "通过潜在集合的随机共振实现对抗攻击的测试时防御", "title_en": "Test-Time Defense Against Adversarial Attacks via Stochastic Resonance of Latent Ensembles", "authors": "Dong Lao,Yuxiang Zhang,Haniyeh Ehsani Oskouie,Yangchao Wu,Alex Wong,Stefano Soatto", "background": "本文提出了一种对抗攻击的测试时防御机制，即通过引入不可感知的图像扰动显著改变模型预测结果。与依赖特征过滤或平滑等现有方法的不同，这些方法可能会造成信息丢失，本文提出了一种‘用噪声对抗噪声’的方法，通过利用随机共振来增强模型的鲁棒性，同时最小化信息丢失。该方法通过对输入图像进行小的平移扰动，对变换后的特征嵌入进行对齐，并在映射回原始参考图像前进行聚合。", "innovation": "本文提出了一种全新的测试时防御机制，通过引入随机共振技术来增强模型的鲁棒性，同时避免了信息丢失的问题。该方法能够应用于多种现有的网络架构中，无需额外的网络模块或针对特定攻击类型的微调。此外，该方法完全不需要训练，且对不同网络架构和攻击类型都适用。", "conclusion": "实验结果表明，该方法在图像分类任务上达到了最先进的鲁棒性水平，首次为密集预测任务（如立体匹配、光学流等）建立了通用的测试时防御方法，展现了该方法的灵活性和实用性。相对于未受影响的表现，该方法在不同类型的对抗攻击下，分别恢复了68.1%、71.9%和29.2%的准确率损失。"}
{"llm_update_time": "20251006", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.03155", "html_url": "https://arxiv.org/abs/2510.03155", "title": "基于刺激电压的神经动作电位起始时间预测：经典方法 vs. 具有量子启发的Approaches", "title_en": "Stimulus-Voltage-Based Prediction of Action Potential Onset Timing: Classical vs. Quantum-Inspired Approaches", "authors": "Stevens Johnson,Varun Puram,Johnson Thomas,Acsah Konuparamban,Ashwin Kannan", "background": "精确建模神经元动作电位（AP）起始时间对于理解神经编码危险信号至关重要。传统的漏电积分-放电（LIF）模型虽被广泛使用，但在预测AP起始潜伏期方面表现出较大的相对误差，特别是在强烈或快速变化的刺激下。", "innovation": "本文提出了一种量子启发的漏电积分-放电（QI-LIF）模型，将AP起始视为一个概率事件，并用时间中的高斯波包表示。这种方法捕捉了神经元放电固有的生物学变化和不确定性。相比经典的LIF模型，QI-LIF模型在预测动作电位起始时间方面具有显著更低的相对误差，特别是在高强度刺激情况下，且与观察到的生物学反应一致。这项工作展示了量子启发计算框架在提高神经建模准确性方面的潜在应用，并为以脑启发计算为目标的量子工程寻求新的途径。", "conclusion": "QI-LIF模型在预测动作电位起始时间方面表现出了显著的优势，特别是在高强度刺激下。该研究为提高神经元编码和神经建模的准确性提供了新的见解，并提出了量子工程背景下脑启发计算的新方法。"}
{"llm_update_time": "20251006", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.03143", "html_url": "https://arxiv.org/abs/2510.03143", "title": "几乎稳定的聚类带惩罚的计算复杂性", "title_en": "The Computational Complexity of Almost Stable Clustering with Penalties", "authors": "Kamyar Khodamoradi,Farnam Mansouri,Sandra Zilles", "background": "在具有小膨胀维度度量空间中，对k-MEANS和k-MEDIAN聚类问题稳定（或扰动鲁棒）实例的研究来自于对这类问题在低维欧几里得空间中的广泛研究（如Friggstad等人的2019年研究和Cohen-Addad和Schwegiehsohn的2017年研究）。本文作者采用了一个更广泛的稳定性概念，称为“几乎稳定”，该概念更接近于Balcan和Liang于2016年引入的$(\nu, \nu)$-扰动鲁棒性定义。同时，他们还将结果扩展到了带有惩罚的k-MEANS和k-MEDIAN聚类问题。研究了某些特定情况的几乎稳定k-MEANS和k-MEDIAN（带惩罚）的可计算问题，这些特定情况可以在多项式时间内解决。", "innovation": "作者提出了一个基于$(\nu, \nu)$-扰动鲁棒性的“几乎稳定”的新概念，这是一个更广泛的稳定性概念。此外，他们还研究了带惩罚的k-MEANS和k-MEDIAN聚类的几乎所有稳定实例和$(1 + \frac{1}{poly(n)})$-稳定的实例，证明了任何精确算法在广泛接受的指数时间假设（ETH）下的运行时间下界为超多项式时间。", "conclusion": "研究证明，具有小膨胀维度度量空间中的几乎稳定带惩罚的k-MEANS和k-MEDIAN聚类（某些特殊情况）可以在多项式时间内解决。但是，还证明了几乎所有稳定实例和平稳实例在指数时间假设下的计算复杂性为超多项式时间下界。"}
{"llm_update_time": "20251006", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.03209", "html_url": "https://arxiv.org/abs/2510.03209", "title": "在日内市场和频率 containment储备市场上的联合投标", "title_en": "Joint Bidding on Intraday and Frequency Containment Reserve Markets", "authors": "Yiming Zhang,Wolfgang Ridinger,David Wozabal", "background": "随着可再生能源的集成使得电力供应变得不稳定，电池储能系统（BESS）成为平衡供需的有效解决方案。现有文献通常将这些市场分开考虑或简化日内市场的连续交易性质，缺乏一种将频率储备市场与日内市场的连续交易相结合的优化策略。", "innovation": "本文提出了一种新的方法，通过结合参与主要频率储备市场和连续交易日内市场来优化BESS的市场参与。这个方法使用了滚动内在算法的混合整数线性规划实现，用于日内决定与状态荷电恢复，以及一个学习分类器策略（LCS）来决定市场之间的最佳容量分配。该方法在超过一年的历史德国市场数据上的外样本回测中得到验证，LCS 策略相比最佳静态策略和简单动态基准策略，分别增加了超过4%和3%的收益，这种方法还揭示了在复杂的多市场环境中动态、基于学习的分配策略的有效性。", "conclusion": "本文方法通过闭合与完美预知策略之间的差距到仅4%，展示了其在复杂多市场环境下的有效性，并证明了动态、基于学习的分配策略的有效性。"}
{"llm_update_time": "20251006", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.03215", "html_url": "https://arxiv.org/abs/2510.03215", "title": "Cache-to-Cache: 直接大型语言模型之间的语义通信", "title_en": "Cache-to-Cache: Direct Semantic Communication Between Large Language Models", "authors": "Tianyu Fu,Zihan Min,Hanling Zhang,Jichao Yan,Guohao Dai,Wanli Ouyang,Yu Wang", "background": "现有的多LLM系统通过文本进行沟通，虽然能实现一些性能和效率的提升，但该过程会导致丰富的语义信息丢失，并且会增加按token逐个生成的延迟。研究人员希望通过这种限制，探讨LLM是否可以跨越文本进行直接的语义交流。", "innovation": "提出了Cache-to-Cache（C2C）新的范式，通过使用神经网络来投影和融合源模型与目标模型的KV缓存，从而实现直接的语义转移。这种机制能避免显式的中间文本生成过程，利用两个模型深层的专业语义，从而获得更高的性能和效率。", "conclusion": "C2C相比单一模型和文本通信的体系结构，平均提高了8.5-10.5%的准确性，同时降低了30-50%的延迟，并实现了平均2.0倍的延迟加速。"}
{"llm_update_time": "20251006", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.03167", "html_url": "https://arxiv.org/abs/2510.03167", "title": "通过双乐观改进平滑优化的在线到非凸转换", "title_en": "Improving Online-to-Nonconvex Conversion for Smooth Optimization via Double Optimism", "authors": "Francisco Patitucci,Ruichen Jiang,Aryan Mokhtari", "background": "最近，在非凸优化领域取得的一个突破是，Cutkosky在2023年提出的在线到非凸转换框架。该框架将寻找ε-次优解的问题重构成在线学习问题。当梯度和海森矩阵都是利普希兹连续的时，使用两种不同的在线学习者实例化该框架，可以在确定性情况下达到O(ε^{-1.75} log(1/ε)) 的复杂度，在随机情况下达到O(ε^{-3.5})的复杂度。然而，这种方法有几个局限性：（i）确定性方法依赖于复杂的双重循环方案，需要解决一个固定点方程来构造提示向量以支持乐观在线学习者，引入了一个额外的对数因子；（ii）随机方法假设随机梯度二阶矩有界，这比标准方差界限强；（iii）两种不同在线学习算法被用于两种不同设置中。", "innovation": "本文通过引入基于新颖的双重乐观提示函数的在线乐观梯度方法解决了这些问题。具体来说，作者使用外推点的梯度作为提示，基于两个乐观假设：提示与目标梯度的差保持接近常数，连续的更新方向因光滑性而缓慢变化。该方法消除了双重循环的需要，移除了对数因子。通过简单地用随机梯度替换完整梯度，在标准假设下其方差不超过σ^2，本文得到了一个统一算法，其复杂度为O(ε^{-1.75} + σ^2 ε^{-3.5})，平滑地在最优确定性和最优随机率之间插值。", "conclusion": "本文提出的方法克服了之前方法的一些限制，同时提供了一种优化平滑非凸问题的新方法，其复杂度在确定性和随机情况下都达到了最佳。"}
{"llm_update_time": "20251006", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.03152", "html_url": "https://arxiv.org/abs/2510.03152", "title": "ReeMark: Reeb Graphs for Simulating Patterns of Life in Spatiotemporal Trajectories", "title_en": "ReeMark: Reeb Graphs for Simulating Patterns of Life in Spatiotemporal Trajectories", "authors": "Anantajit Subrahmanya,Chandrakanth Gudavalli,Connor Levenson,Umang Garg,B.S. Manjunath", "background": "准确建模人类移动对于城市规划、流行病学和交通管理至关重要。本研究引入了一种新颖的方法，即马尔可夫Rie布图，用于模拟反映日常生活模式（PoLs）的时间空间轨迹，通过在概率拓扑模型中结合个体和群体的移动结构，该方法生成了真实且具有日常生活一致性和多样性的未来轨迹。", "innovation": "该方法将个体和群体的移动结构结合到一个概率拓扑模型中，生成真实且具有日常生活一致性和多样性的未来轨迹，通过使用 Jensen-Shannon 散度在人口层面和个体层面的度量上对Urban Anomalies数据集（亚特兰大和柏林子集）进行评估，证明了该方法在保持真实性和数据效率方面的强大表现。", "conclusion": "这些结果显示，Markovian Reeb Graphs是一种适用于广泛城市环境的时间空间轨迹模拟的有效框架。"}
{"llm_update_time": "20251006", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2501.18873", "html_url": "https://arxiv.org/abs/2501.18873", "title": "基于轨迹偏好反馈的最佳策略学习", "title_en": "Best Policy Learning from Trajectory Preference Feedback", "authors": "Akhil Agnihotri,Rahul Jain,Deepak Ramachandran,Zheng Wen", "background": "强化学习通过人类反馈（RLHF）已经证明了其在对齐生成模型方面的有效性，但是这种方法依赖于学习的奖励模型，容易出现误定义和奖励黑客的问题。相比之下，基于偏好的强化学习（PbRL）通过直接利用轨迹的噪声二进制对比提供了更为稳健的替代方案。", "innovation": "提出了Posterior Sampling for Preference Learning（$\\mathsf{PSPL}$）算法，该算法基于Top-Two Thompson Sampling，并保持了奖励模型和动力学的后验。提供了PbRL首个贝叶斯简单后悔保证，并且引入了比现有基线在模拟和图像生成基准测试中表现更好的高效近似。", "conclusion": "该研究展示了如何利用网络偏好数据进行最佳策略学习，并强调了系统化的在线学习在结合偏见数据与在线纯探索时的重要性。"}
{"llm_update_time": "20251006", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2303.01412", "html_url": "https://arxiv.org/abs/2303.01412", "title": "针对准确因果效应估计的超参数调整挑战", "title_en": "The Challenges of Hyperparameter Tuning for Accurate Causal Effect Estimation", "authors": "Damian Machlanski,Spyridon Samothrakis,Paul Clarke", "background": "机器学习在从观察数据中估计治疗对结果的因果效应方面发挥着越来越重要的作用。许多机器学习方法（如因果估计器）被提出用于此任务。然而，这些方法以及任何机器学习方法都需进行大量的超参数调整。对于非因果预测任务，已有共识选择调优指标（例如均方误差），方便模型比较。但在因果推断任务中，尚无这样的共识，导致因果模型之间难以比较。进一步，因果推断中的模型选择涉及多个组件（因果估计器、机器学习回归器、超参数、指标），这进一步复杂化了问题。因此，为了评估每个组件的重要性，我们进行了一项广泛的实证研究。研究涉及广泛使用的因果估计器、回归器和指标，应用于四个著名的因果推断基准数据集。实验结果显示，超参数调整提高了使用常见估计器进行平均和个性化效应估计达到当前最佳性能的概率（从65%增加到81%，以及从50%增加到57%）。此外，我们还展示了标准指标在不同场景下的表现可能不一致。这些发现强调了未来研究的必要性，即研究能否找到能够针对因果模型评估进行准确评估的统一指标。", "innovation": "本文进行了一项广泛的实证研究，探讨并评估了因果推断任务中各组件（因果估计器、回归器和指标）的重要性。研究结果表明，通过超参数调优，常见估计器在平均和个性化效应估计中的最先进性能概率分别提升了65%到81%和50%到57%。此外，还发现了标准指标在不同场景下的表现不一致性，强调了未来研究的重要性，以找到能够统一进行准确评估的指标。", "conclusion": "研究结果证明了超参数调优对提高因果效应估计准确性的重要性，并揭示了现有标准指标可能存在的不一致性。未来的研究需要探索能够统一适用于各种场景的评估指标。"}
{"llm_update_time": "20251006", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2311.15238", "html_url": "https://arxiv.org/abs/2311.15238", "title": "一种通用函数逼近下的近最优且低切换算法的强化学习", "title_en": "A Nearly Optimal and Low-Switching Algorithm for Reinforcement Learning with General Function Approximation", "authors": "Heyang Zhao,Jiafan He,Quanquan Gu", "background": "在强化学习（RL）中，尤其是涉及复杂模型类时，探索与利用的困境一直是核心挑战。已有算法在保证学习效率的同时，难以同时优化探索与利用的平衡，特别是在通用函数逼近的情况下，这一挑战更加复杂。", "innovation": "本文提出了一种新的算法，MQL-UCB（单调Q学习与上置信边界），该算法针对通用函数逼近的RL问题进行了优化。主要创新在于：(1) 提出了一种通用确定性策略切换策略，实现低切换成本；(2) 设计了单调的价值函数结构，控制函数类的复杂性；(3) 引入了方差加权回归方案，高效利用历史轨迹。MQL-UCB实现了在K足够大时的最小最大近似遗憾为$\tilde{O}(d\text{\textperiodcentered}\text{\textperiodcentered}H^{\text{\textonehalf}})$和近最优的策略切换成本$\tilde{O}(d \text{\textperiodcentered} H)$，其中d为函数类的eluder维度，H为规划期，K为回放次数。", "conclusion": "本文的研究结果为设计能够证明样本高效和部署高效的非线性函数逼近Q学习算法提供了新的思路，尤其在通用函数逼近的情况下，这一算法具有显著的性能和效率优势。"}
{"llm_update_time": "20251006", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2502.06398", "html_url": "https://arxiv.org/abs/2502.06398", "title": "在保持秩不变性下学习反事实结果", "title_en": "Learning Counterfactual Outcomes Under Rank Preservation", "authors": "Peng Wu,Haoxuan Li,Chunyuan Zheng,Yan Zeng,Jiawei Chen,Yang Liu,Ruocheng Guo,Kun Zhang", "background": "反事实推理旨在基于观测到的治疗和实际结果来估计个体级别的反事实结果，广泛应用于流行病学、计量经济学和管理科学等领域。先前的方法依赖于已知的结构因果模型或假设外部变量的同质性和结果与外部变量之间的严格单调关系。", "innovation": "该论文提出了一种基于保持秩不变性的原则性方法来识别和估计反事实结果。首先引入了一个简单直观的秩保持假设，无需依赖已知的结构因果模型即可识别反事实结果。在此基础上，提出了一种新颖的理想损失，用于理论上的无偏学习反事实结果，并进一步开发了一种核估计器来实现其经验估计。理论分析表明，秩保持假设并不比同质性和严格单调关系更强，并且提出的理想损失是凸的，提出的估计器是无偏的。", "conclusion": "通过广泛的人工合成和真实世界实验，证明了所提出方法的有效性。"}
{"llm_update_time": "20251006", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2411.02038", "html_url": "https://arxiv.org/abs/2411.02038", "title": "利用单线性层解决向量量化解聚问题的模型", "title_en": "Addressing Representation Collapse in Vector Quantized Models with One Linear Layer", "authors": "Yongxin Zhu,Bocheng Li,Yifei Xin,Zhihua Xia,Linli Xu", "background": "矢量量化（VQ）在无监督学习中用于离散化连续表示，但存在表现解聚的问题，导致码本利用率低，限制了模型的可扩展性。现有解决方案往往依赖于复杂的优化或减少潜在维度，这会牺牲模型容量，无法完全解决问题。当前的问题根源在于分离的码本优化，即只有少数码矢量通过梯度下降进行更新。", "innovation": "提出了一种名为SimVQ的方法，通过一个可学习的线性变换层在潜在基底上重新参数化码矢量，优化整个线性空间而不是最近个体码矢量。尽管两个线性矩阵的乘积等同于应用单个线性层，但这种方法简单有效，能够防止表现解聚。实验证明SimVQ提高码本利用率，易于实现，并在不同模态和架构中表现出良好的泛化能力。", "conclusion": "SimVQ不仅能够改善码本的使用，还易于实施，并且在不同的模态和架构上具有良好的泛化能力。代码已在此链接中提供。"}
{"llm_update_time": "20251006", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2407.21185", "html_url": "https://arxiv.org/abs/2407.21185", "title": "Amelia: 用于机场地面运动预测的大规模数据集和基准", "title_en": "Amelia: A Large Dataset and Benchmark for Airport Surface Movement Forecasting", "authors": "Ingrid Navarro,Pablo Ortega-Kral,Jay Patrikar,Haichuan Wang,Alonso Cano,Zelin Ye,Jong Hoon Park,Sebastian Scherer,Jean Oh", "background": "航空旅行需求的增长对现有航空基础设施构成了压力。在美国，超过90%的机场控制塔存在人手不足的情况，未达到FAA和工会的标准，这导致了近失事和关键安全事件的增加，突显了在空中交通管理技术方面取得进步的必要性。现有的数据驱动的预测模型在终端空中交通中颇具潜力，但缺少大量公共可用的表面移动数据集阻碍了可扩展和通用方法的发展。", "innovation": "本研究引入了Amelia-42，这是一个前所未有的大规模机场表面运动报告集合，其中包括超过两年的轨迹数据（约为9.19 TB），涵盖42个美国机场。我们开源了处理这些数据为干净的表格位置报告的工具，并提供了易于使用的Amelia42-Mini数据集。此外，我们还提供了一个轨迹预测基准，包括Amelia10-Bench和Amelia-TF，一种基于变换器的多代理轨迹预测基线。", "conclusion": "所有资源均可在我们的网站上获取：this https URL and this https URL。这些资源旨在促进机场表面运动预测技术的发展。"}
{"llm_update_time": "20251006", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2502.17537", "html_url": "https://arxiv.org/abs/2502.17537", "title": "重思概念擦除的脆弱性与一种新方法", "title_en": "Rethinking the Vulnerability of Concept Erasure and a New Method", "authors": "Alex D. Richardson,Kaicheng Zhang,Lucas Beerens,Dongdong Chen", "background": "文本到图像的扩散模型的盛行引发了对隐私和安全的重大关注，尤其是针对版权图像或有害图像的生成。为了应对这一问题，已经开发出概念擦除（防御）方法，通过后处理微调来“消除”特定概念。然而，最近的概念恢复（攻击）方法表明，这些被认为被消除的概念可以通过对抗性生成的提示重新获得，揭示了当前防御机制的关键漏洞。", "innovation": "作者提出了一种名为RECORD的新坐标下降恢复算法，这种算法在性能上优于现有方法，性能提升了17.8倍。此外，作者还进行了广泛的实验来评估该方法的计算和性能成本，并提出了加速策略。", "conclusion": "研究揭示了当今概念擦除模型中对抗式漏洞的根源，并且通过RECORD算法成功减少了这些漏洞。同时，通过实验展示了RECORD算法的优越性，并为未来的加速技术提供了建议。"}
{"llm_update_time": "20251006", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2406.03508", "html_url": "https://arxiv.org/abs/2406.03508", "title": "用互信息引导的预训练编码器后门缓解技术", "title_en": "Mutual Information Guided Backdoor Mitigation for Pre-trained Encoders", "authors": "Tingxu Han,Weisong Sun,Ziqi Ding,Chunrong Fang,Hanwei Qian,Jiaxun Li,Zhenyu Chen,Xiangyu Zhang", "background": "自监督学习（SSL）在无需标签数据的情况下预训练编码器方面越来越受到关注。基于这些预训练编码器的下游任务可以达到接近最先进的性能。然而，现有研究表明，通过SSL预训练的编码器容易受到后门攻击的影响，现有用于下游任务模型的后门缓解技术在应用于预训练编码器时效果受限，因为预训练阶段缺乏标签信息。", "innovation": "本文创新地提出了一种互信息引导的后门缓解技术，称为MIMIC。MIMIC将潜在的被后门污染的编码器视为教师网络，并利用知识蒸馏来提取一个干净的学生编码器。与现有知识蒸馏方法不同，MIMIC在初始化学生编码器时使用随机权重，不继承教师网络中的后门。MIMIC利用每层之间和提取特征之间的互信息来定位教师网络中的无害知识，并在此基础上执行蒸馏以从教师网络克隆干净特征到学生网络。MIMIC通过克隆损失和注意力损失构建了蒸馏损失，旨在同时缓解后门和保持编码器性能。", "conclusion": "在两个SSL中的后门攻击上进行的评估表明，MIMIC仅使用不到5%的干净数据就可以显著降低攻击成功率，超越了七种最先进的后门缓解技术。"}
{"llm_update_time": "20251006", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2502.11027", "html_url": "https://arxiv.org/abs/2502.11027", "title": "关于采样多样性在扩展LLM推理效果的研究", "title_en": "On the Effect of Sampling Diversity in Scaling LLM Inference", "authors": "Tianchun Wang,Zichuan Liu,Yuanzhou Chen,Jonathan Light,Weiyang Liu,Haifeng Chen,Xiang Zhang,Wei Cheng", "background": "大规模语言模型在推理扩展上的效果提升关键在于如何利用多样性改进其表现。研究发现，解决方案的准确性和有意义的响应多样性之间存在关系，因此需要系统地研究提示多样性的扩展推理效果。", "innovation": "论文通过理论解释说明了多样采样的优势，并展示了在多次选择后的有意义多样提示生成的响应误差率明显低于静态提示。此外，论文还分析了扰动的准确性，发现中度相关的干扰能提升性能，并提出了一套有效扰动策略，包括任务级和查询级干扰。", "conclusion": "在不同任务中进行多样采样系统的评估，发现合理性推理指标EM@100提高了10.8%，数学问题提高了9.6%，代码生成Pass@100提高了9.5%。"}
{"llm_update_time": "20251006", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2501.10347", "html_url": "https://arxiv.org/abs/2501.10347", "title": "ColNet: 分布式联邦多任务学习系统中的协作优化", "title_en": "ColNet: Collaborative Optimization in Decentralized Federated Multi-task Learning Systems", "authors": "Chao Feng,Nicolas Fazli Kohler,Zhi Wang,Weijie Niu,Alberto Huertas Celdran,Gerome Bovet,Burkhard Stiller", "background": "Federated Multi-Task Learning (FMTL) 结合了联邦学习 (FL) 和多任务学习 (MTL)，旨在解决客户端异构性问题。现有研究大多集中在数据异构性（如处理非IID数据）上，而忽略了任务异构性问题，即客户端解决的是完全不同的任务。现有的大多数工作依赖于集中的设置，即通过服务器管理联邦，因此，分布式环境下的FMTL系统尚未得到充分探索。本文就是在这种背景下提出的ColNet框架，旨在解决任务异构性问题，应用于分布式联邦环境中。", "innovation": "提出了ColNet框架，该框架将模型分为主干和任务特定的头部，并利用基于模型和数据敏感性的自适应聚类方法形成任务一致的客户端组。主干在组内进行平均处理，组领军人物执行跨组聚合，而跨组聚合特别强调防止冲突。ColNet在不同数据集和联邦环境下表现出色，即使在标签和任务异构性以及对抗性攻击中也能保持鲁棒性。", "conclusion": "ColNet框架在分布式联邦多任务学习系统中展示了卓越的性能，特别是在标签和任务异构性及对抗性攻击场景下表现出极高的鲁棒性。未来可以探索进一步优化模型聚类和交叉组聚合的方法，以提升整体性能。"}
{"llm_update_time": "20251006", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2501.07186", "html_url": "https://arxiv.org/abs/2501.07186", "title": "图神经网络在输电网络拓扑控制中的应用：母线信息不对称与异质表示", "title_en": "Graph Neural Networks for Transmission Grid Topology Control: Busbar Information Asymmetry and Heterogeneous Representations", "authors": "Matthijs de Jong,Jan Viebahn,Yuliya Shapovalova", "background": "可再生能源的增加和电气化的普及导致电力系统拥堵成为一个迫切的问题。传统的拓扑控制方法发现拓扑的效率较低，无法满足实际应用需求。近年来，机器学习成为一种高效的替代方案，尤其是图神经网络因其能够建模电力网络的图结构，特别适用于拓扑控制。然而，现有的同质图表示方法存在母线信息不对称的问题，这是研究中的一个关键挑战。", "innovation": "本文研究了图表示对图神经网络拓扑控制效果的影响。作者识别出了同质图表示中的母线信息不对称问题，并提出了一种异质图表示来解决这一问题。对比了不同类型的图神经网络和全连接神经网络在输电网络拓扑控制中的表现，发现异质图神经网络在内分布网络配置中效果最佳，其次是全连接神经网络，最后是同质图神经网络。还发现图神经网络在分布外网络配置中具有更好的泛化能力。", "conclusion": "研究表明，异质图神经网络在内分布网络配置中表现出最佳的效果，其次是全连接神经网络，而同质图神经网络效果最差。此外，图神经网络在分布外网络配置中具有更好的泛化能力。"}
{"llm_update_time": "20251006", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2504.18243", "html_url": "https://arxiv.org/abs/2504.18243", "title": "DualRAG：一种集成推理和检索的双重过程方法用于多跳问答", "title_en": "DualRAG: A Dual-Process Approach to Integrate Reasoning and Retrieval for Multi-Hop Question Answering", "authors": "Rong Cheng,Jinyi Liu,Yan Zheng,Fei Ni,Jiazhen Du,Hangyu Mao,Fuzheng Zhang,Bo Wang,Jianye Hao", "background": "多跳问答（MHQA）任务渗透到实际应用中，提出了在不同知识领域进行多步推理的挑战。虽然现有的方法通过迭代检索有所改进，但仍难以识别和组织动态知识。", "innovation": "提出了一种名为DualRAG的协同双重过程框架，结合了推理和检索。该框架通过两种紧密耦合的过程——推理增强查询（RaQ）和逐步知识聚合（pKA）——共同工作，RaQ生成目标查询，pKA确保新获取的知识被系统地整合以支持连贯的推理，形成知识丰富和推理完善的良性循环。通过针对性的微调，DualRAG能够在小型模型中保持其复杂的推理和检索能力，展示了其在不同规模下的灵活性和核心优势。", "conclusion": "广泛的实验表明，该双重过程方法在答案准确性和连贯性方面显著提高，甚至在某些情况下超过了使用Oracle知识访问的方法的性能，确立了DualRAG作为复杂多跳推理任务的稳健和高效解决方案的地位。"}
{"llm_update_time": "20251006", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2504.07052", "html_url": "https://arxiv.org/abs/2504.07052", "title": "回溯与否：当序列搜索限制模型推理时", "title_en": "To Backtrack or Not to Backtrack: When Sequential Search Limits Model Reasoning", "authors": "Tian Qin,David Alvarez-Melis,Samy Jelassi,Eran Malach", "background": "大型语言模型（LLMs）最近的发展显著提高了其推理能力，尤其是在通过搜索和回溯技术方面。回溯通过顺序、线性化探索，利用长链式思维（CoT）生成自然地扩展了推理测试时间的计算量。然而，这并不是唯一的测试时间计算量扩增策略：并行采样结合最佳N选一提供了一种同时生成多样化解决方案的方法。尽管序列搜索被广泛采用，但与固定计算预算下的并行采样相比，序列搜索的优点仍未被充分理解。本文系统地比较了这两种方法在两个具有挑战性的推理任务（CountDown和Sudoku）上的表现。", "innovation": "研究发现，序列搜索在CountDown任务上表现不佳但在Sudoku任务上表现优于并行采样，表明回溯并不具有普遍的优势。识别了导致回溯性能下降的两个因素：（1）固定搜索轨迹的训练可能导致模型陷入次优策略；（2）显式的链式思维监督可能抑制隐性（未言语的）推理。通过扩展到强化学习（RL），本文展示了具有回溯能力的模型在RL微调中显著受益，而没有回溯的模型从中获得的收益有限且不一致。这些发现挑战了回溯普遍增强LLM推理能力的假设，揭示了任务结构、训练数据、模型规模和学习范式的复杂相互作用。", "conclusion": "研究发现，回溯并不具有普遍优势，其在不同任务上的表现差异显著。此外，回溯能力对学习任务的增强影响受到任务结构、训练数据、模型规模和学习范式的影响，这表明理解这些因素的复杂相互作用对于最大限度地发挥LLM潜力至关重要。"}
{"llm_update_time": "20251006", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2504.12397", "html_url": "https://arxiv.org/abs/2504.12397", "title": "活跃的LoRA：专用于内在功能的微调大型语言模型", "title_en": "Activated LoRA: Fine-tuned LLMs for Intrinsics", "authors": "Kristjan Greenewald,Luis Lastras,Thomas Parnell,Vraj Shah,Lucian Popa,Giulio Zizzo,Chulaka Gunasekara,Ambrish Rawat,David Cox", "background": "低秩适应（LoRA）作为一种高效的框架，用于微调大型基础模型的权重，已经成为数据驱动定制LLMs的标准方法。然而，在多轮对话环境中切换合适的LoRA模型时，由于需要重新计算整个对话历史的键-值（KV）缓存，导致效率低下，影响生成速度。", "innovation": "本文提出了活跃的LoRA（aLoRA），这是一种适应器架构，它修改了LoRA框架，仅适应序列中调用aLoRA之后的tokens权重。这种改变使得aLoRA能够直接使用基础模型的输入字符串KV缓存，从而在需要时即时激活aLoRA，无需重新计算先前的键和值，提高了推理效率。aLoRA允许构建所谓的内在模型，即专门针对输入序列或对话中特定部分执行特定操作的模型，而默认情况下使用基础模型。", "conclusion": "与标准的LoRA相比，基于aLoRA的内在模型训练显示出竞争力的准确率，同时显著提高了推理效率。作者还贡献了活跃的LoRA实现到Huggingface PEFT库。"}
{"llm_update_time": "20251006", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2502.17748", "html_url": "https://arxiv.org/abs/2502.17748", "title": "FinP：通过解决隐私风险差异性来在联邦学习中实现隐私公平性", "title_en": "FinP: Fairness-in-Privacy in Federated Learning by Addressing Disparities in Privacy Risk", "authors": "Tianyu Zhao,Mahmoud Srewa,Salma Elmalaki", "background": "在人类中心的联邦学习（FL）环境中，分散的数据需要公平地分配隐私风险。现有方法未能有效缓解这种隐私不公平性，特别是在源推断攻击（SIA）方面。因此，在确保机器学习公平性时，必须考虑到隐私维度，特别是在FL场景下，这就要求隐私风险的分配要公平。", "innovation": "本文提出了名为FinP的新框架，专门解决隐私风险中的不公平问题，通过减少源推断攻击（SIA）来缓解这一问题。FinP采用了双管齐下的策略：（1）服务端自适应聚合，动态调整客户端对全局模型的贡献以促进公平；（2）客户端正则化，增强个体客户端的隐私健壮性。该方法直接解决了隐私不公平的症状及其根本原因。", "conclusion": "在大规模Human Activity Recognition (HAR)和CIFAR-10数据集上的广泛评估表明，FinP有效地提高了隐私公平性，同时对功能的影响最小。在CIFAR-10上，FinP将与隐私风险差异性有关的平等机会公平性提高了57.14%，并显著降低了SIA风险，验证了其在不牺牲功能的前提下能够促进FL系统中的隐私公平性。"}
{"llm_update_time": "20251006", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2505.05522", "html_url": "https://arxiv.org/abs/2505.05522", "title": "连续思维机器", "title_en": "Continuous Thought Machines", "authors": "Luke Darlow,Ciaran Regan,Sebastian Risi,Jeffrey Seely,Llion Jones", "background": "生物大脑表现出复杂的神经活动，其中神经动力学对于处理信息至关重要。大多数人工神经网络忽视了单个神经元的复杂性。本研究挑战了这一范式。通过引入神经元级的处理和同步，重新引入神经时间作为基础元素。", "innovation": "研究提出了一种名为连续思维机器（CTM）的模型，该模型的核心表示是利用神经动力学。CTM的两个创新点包括：(1) 神经元级的时间处理，其中每个神经元使用独特的权重参数来处理输入的历史；(2) 神经同步作为潜在表示。CTM在神经元抽象和生物现实之间寻找平衡，在有效捕捉关键时间动力学的同时保持计算效率。研究还展示了CTM在一系列任务中的表现和多功能性，包括解决2D迷宫、ImageNet-1K分类、奇偶计算等。此外，CTM能够执行需要复杂序列推理的任务，并能够根据任务的复杂性灵活调整计算量，如在简单任务中提前停止计算，在复杂任务中继续计算。这些创新点体现了CTM在模拟更生物合理和强大的人工智能系统方面迈出的重要一步。", "conclusion": "本研究的目标是分享CTM及其相关创新，而非追求新的最新研究成果。我们相信CTM代表了朝着开发更接近生物现实且更强大的人工智能系统迈出的重要一步。我们提供了一个交互式在线演示，链接为：this https URL，以及一个扩展技术报告，链接为：this https URL。"}
{"llm_update_time": "20251006", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2503.05696", "html_url": "https://arxiv.org/abs/2503.05696", "title": "多保真度控制变差方法用于策略梯度估计", "title_en": "A Multi-Fidelity Control Variate Approach for Policy Gradient Estimation", "authors": "Xinjie Liu,Cyrus Neary,Kushagra Gupta,Wesley A. Suttle,Christian Ellis,Ufuk Topcu,David Fridovich-Keil", "background": "许多强化学习（RL）算法在实际系统部署中不切实际，或者在执行昂贵的高保真模拟训练时也不现实，因为它们需要大量的数据。另一方面，低保真模拟器（如降阶模型、启发式奖励或生成的世界模型），可以相对便宜地提供有利于RL训练的数据，尽管这些数据可能过于粗糙，无法实现零样本转移。在许多应用场景中，高保真数据有限，但存在大量的低保真数据，这使得使用低保真数据进行RL训练成为一种可行的选择。", "innovation": "本文提出了多保真度策略梯度（MFPG），这是一种RL框架，通过结合目标环境的小量数据和由大量低保真模拟数据组成的控制变差，构造了一个无偏且方差降低的策略梯度估计器。该框架使用经典的REINFORCE算法的多保真度变体来实例化。研究证明，在标准假设下，MFPG的估计器能够确保REINFORCE算法在目标环境中达到局部最优策略，并且与仅使用高保真数据训练相比，MFPG能够更快地在有限样本上收敛。特别是在低保真度激励设置不准确的情况下，MFPG仍然有效。", "conclusion": "MFPG提供了一种有效的从仿真到现实的转移的新范式，并为平衡策略性能和数据收集成本提供了有原则的方法。在测试的仿真机器人基准任务中，即使在中度的动态差异下，MFPG也能可靠地改善与仅使用高保真度数据相比的中位性能，而其简洁性和低调参开销使其成为一种强有力的解决方案。在大动态差异下，MFPG在所有评估的多保真度方法中表现出最强的稳健性。"}
{"llm_update_time": "20251006", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2505.11669", "html_url": "https://arxiv.org/abs/2505.11669", "title": "OT 分数：Semi-离散最优运输为基础的置信度分数用于源无监督域适应", "title_en": "OT Score: An OT based Confidence Score for Source Free Unsupervised Domain Adaptation", "authors": "Yiming Zhang,Sitong Liu,Alex Cloninger", "background": "当前的源无监督域适应（SFUDA）方法在使用和理论层面都存在限制。特别是在缺乏目标标签的情况下，量化分类性能和置信度成为难题。现有的理论框架通常导致不可计算的问题，并不能准确反映计分算法的特性。这些问题使得现有方法在SFUDA上的表现不够理想。", "innovation": "作者引入了最优运输（OT）分数作为一种新的置信度度量方法，这是通过半离散最优运输对齐诱导的决策边界的灵活分析得到的。OT分数直观且理论严密，能够为任何目标伪标签集提供实际和合理的不确定性估计。实验结果显示，OT分数优于现有的置信度分数，同时它能使SFUDA性能提升，并提供一个可靠无标签的模型性能代理指标。", "conclusion": "本文通过引入最优运输分数，解决了SFUDA方法中的理论和计算限制，提供了新的、可靠的无监督域适应方法，特别是在缺乏目标标签时，能够更好地评估模型性能和置信度。"}
{"llm_update_time": "20251006", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2505.12825", "html_url": "https://arxiv.org/abs/2505.12825", "title": "Isolation Forest 嵌入偏置的理论探究", "title_en": "Theoretical Investigation on Inductive Bias of Isolation Forest", "authors": "Qin-Cheng Zheng,Shao-Qun Zhang,Shen-Huan Lyu,Yuan Jiang,Zhi-Hua Zhou", "background": "孤立森林(iForest)因其出色的运行效率和大规模任务中的优越性能而被广泛用作无监督异常检测器。尽管已经被广泛应用，但其成功背后的具体理论基础仍然不明确。这项研究旨在探讨孤立森林的嵌入偏置，以理论方式解释在哪些条件下以及在多大程度上孤立森林能够表现良好。", "innovation": "本文创新性地将孤立森林的增长过程建模为随机游走，通过转移概率推导出预期深度函数，揭示了关键的嵌入偏置：孤立森林对中心异常的敏感性较低，且表现出比$k$最近邻更大的参数适应性。", "conclusion": "本文提供了孤立森林有效性的理论理解，并为后续的理论探索奠定了基础。"}
{"llm_update_time": "20251006", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2505.11840", "html_url": "https://arxiv.org/abs/2505.11840", "title": "关于AdamW在$L_1$范数下的$O(\frac{\frac{\text{根号d}}{K^{1/4}})$收敛速率", "title_en": "On the $O(\\frac{\\sqrt{d}}{K^{1/4}})$ Convergence Rate of AdamW Measured by $\\ell_1$ Norm", "authors": "Huan Li,Yiming Dong,Zhouchen Lin", "background": "AdamW已经成为大型语言模型训练的默认优化器，在深度学习中取得了显著成果，但其收敛行为缺乏理论上的深入理解。\n在文中提到的背景知识中，AdamW的$L_1$范数下的收敛速率尚未被理论证明，因此研究其在$L_1$范数下的收敛性是必要的。正确的亚线性收敛理论对于优化器的发展和理解其性能至关重要，尤其是在面对大规模高维优化问题时。研究AdamW的$L_1$范数收敛性能够揭示其在理论与实际问题中的行为差异。\n", "innovation": "该研究论文首次给出了AdamW在$L_1$范数下的$O(\frac{根号d}{K^{1/4}})$收敛速率，并通过分析高维梯度在不同范数下的关系，支持这一结论。此外，研究还扩展到NAdamW，并证明它保持相同的收敛速率。\n", "conclusion": "论文通过理论证明和实验验证，揭示了AdamW的$L_1$范数收敛速率与理想情况下SGD的$L_2$范数收敛速率相近。同时，NAdamW也被证明拥有相同速率，这对于优化器理论的理解和实现提供了新的视角。"}
{"llm_update_time": "20251006", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2505.09901", "html_url": "https://arxiv.org/abs/2505.09901", "title": "基于标准多臂老虎机实验比较LLMs和人类的探索-利用策略：见解", "title_en": "Comparing Exploration-Exploitation Strategies of LLMs and Humans: Insights from Standard Multi-armed Bandit Experiments", "authors": "Ziyuan Zhang,Darcy Wang,Ningyuan Chen,Rodrigo Mansur,Vahid Sarhangian", "background": "大型语言模型（LLMs）在复杂的序列决策环境中常被用于模拟或自动化人类行为。关于LLMs是否能够表现出与人类相似的决策行为，并且能否达到近似或优越的表现的自然问题也随之出现。本文聚焦于探索-利用（E&E）策略，这是在不确定环境下动态决策的一个基本方面。研究采用认知科学和精神病学文献中引入的经典多臂老虎机（MAB）实验来对比LLMs、人类和MAB算法的E&E策略。通过可解释的选择模型来捕捉代理的E&E策略，并探讨使能思考踪迹（通过提示策略和思考模型）如何影响LLMs的决策行为。研究发现，使能思考的LLMs的行为向更具人类特征的方向转变，表现为随机和定向探索的混合。在简单的不变环境中，使能思考的LLMs在随机和定向探索方面与人类表现出相似的水平。然而，在更复杂的非不变环境中，尽管某些场景中LLMs达到了相似的遗憾值，但在有效的定向探索方面仍难以匹配人类的适应性。", "innovation": "采用经典多臂老虎机（MAB）实验来比较LLMs、人类和MAB算法的探索-利用策略；通过使能思考踪迹的方法来研究其对LLMs决策行为的影响；发现使能思考的LLMs的行为向更具人类特征的方向转变，表现为随机和定向探索的混合；在简单不变环境中有类似人类的行为，但在复杂非不变环境中难以达到人类的适应性，在有效定向探索方面表现较弱，但某些情况下达到类似的人类水平的遗憾值。", "conclusion": "该研究揭示了LLMs在模拟人类行为以及自动决策工具方面既具有潜力也存在局限性，并指出了改进的潜在领域。"}
{"llm_update_time": "20251006", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2503.09008", "html_url": "https://arxiv.org/abs/2503.09008", "title": "用于图机器学习中长距离交互量化的大型图数据集及一种测量方法", "title_en": "Towards Quantifying Long-Range Interactions in Graph Machine Learning: a Large Graph Dataset and a Measurement", "authors": "Huidong Liang,Haitz Sáez de Ocáriz Borde,Baskaran Sripathmanathan,Michael Bronstein,Xiaowen Dong", "background": "现有的大多数图数据集主要关注小图，适用于归纳任务，缺乏对长距离交互的有效研究。现有的评估方法主要是在全局注意力模型（如图变压器）和局部邻域聚合模型（如消息传递神经网络）之间进行比较，但没有直接测量长距离依赖性。", "innovation": "本文提出了City-Networks，一个源于真实城市道路网络的大规模推断学习数据集，包含超过10万节点的图，并提出了一个基于邻居远距离跳跃雅可比矩阵的模型无偏的长距离依赖性测量方法，同时提供了关于数据集设计和测量方法的理论依据。", "conclusion": "本文通过City-Networks数据集和一种新的测量方法，提出了评估图神经网络中长距离依赖性的理论依据，为后续研究提供了坚实的基础。\n"}
{"llm_update_time": "20251006", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2505.24183", "html_url": "https://arxiv.org/abs/2505.24183", "title": "QiMeng-CodeV-R1：增强推理的Verilog生成", "title_en": "QiMeng-CodeV-R1: Reasoning-Enhanced Verilog Generation", "authors": "Yaoyu Zhu,Di Huang,Hanqi Lyu,Xiaoyun Zhang,Chongxiao Li,Wenxuan Shi,Yutong Wu,Jianan Mu,Jinghua Wang,Yang Zhao,Pengwei Jin,Shuyao Cheng,Shengwen Liang,Xishan Zhang,Rui Zhang,Zidong Du,Qi Guo,Xing Hu,Yunji Chen", "background": "大语言模型（LLMs）通过具有可验证奖励的强化学习（RLVR）训练，在需要明确自动化验证的任务中取得了突破，如软件编程和数学问题。然而，将RLVR扩展到电子设计自动化（EDA）尤其是从自然语言（NL）规范自动生成硬件描述语言（HDL，如Verilog），面临着三个关键挑战：缺乏自动化和准确的验证环境、高质量NL-code对稀缺以及RLVR的高昂计算成本。", "innovation": "研究人员提出了CodeV-R1，一种RLVR框架，用于训练Verilog生成LLMs。CodeV-R1包含三个创新点：1）开发基于规则的测试生成器，能进行稳健的等效性检查对抗金标准参考；2）提出一轮次数据合成方法，将开源Verilog片段与LLM生成的NL描述配对，使用生成的测试生成器验证代码-NL-代码的一致性，并过滤掉不等价的示例以生成高质量的数据集；3）采用两阶段的“先蒸馏后RL”的训练管线：蒸馏用于推理能力的冷启动，随后使用我们提出的新型自适应DAPO RLVR算法进行训练，该算法可以通过适应调整采样率来降低训练成本。", "conclusion": "训练出的CodeV-R1-7B模型在VerilogEval v2和RTLLM v1.1上分别达到68.6%和72.9%的pass@1，超过之前的SOTA模型12~20%，甚至超过了671B DeepSeek-R1在RTLLM上的性能。研究团队已经发布了该模型、训练代码和数据集，以促进EDA和LLM研究社区的相关研究。"}
{"llm_update_time": "20251006", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.00771", "html_url": "https://arxiv.org/abs/2506.00771", "title": "在固定维度的E(3)-不变潜空间中操作3D分子", "title_en": "Manipulating 3D Molecules in a Fixed-Dimensional E(3)-Equivariant Latent Space", "authors": "Zitao Chen,Yinjun Jia,Zitong Tian,Wei-Ying Ma,Yanyan Lan", "background": "医药化学家在优化药物时考虑其三维结构，并设计具有保留的关键特征（如形状、药理学特性或化学性质）的结构不同的分子。传统的深度学习方法解决这一问题多通过监督任务，例如分子补全或性质指导的优化。", "innovation": "本文提出了一个灵活的零样本分子操纵方法，通过在3D分子共享的潜空间中导航实现。该方法引入了一种名为MolFLAE的变分自动编码器（VAE），它学习了一个固定维度、E(3)-不变的潜空间，与原子数量无关。MolFLAE通过E(3)-不变的神经网络将3D分子编码为固定数量的潜节点，并通过条件于编码器输出的贝叶斯流网络（BFN）重建分子结构。本文方法在标准的无条件3D分子生成基准上取得了竞争性表现，并且其潜空间能够实现零样本分子操纵，包括原子数目编辑、结构重建以及同时对结构和性质的协调潜在插值。", "conclusion": "本文方法突显了灵活性、鲁棒性和实际应用性，为分子编辑和优化开启了新的途径。在对人体糖皮质激素受体的药物优化任务中，生成了具有更好亲水性且保留关键相互作用的分子，在计算评估中取得了良好结果。"}
{"llm_update_time": "20251006", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2505.13564", "html_url": "https://arxiv.org/abs/2505.13564", "title": "在线决策导向学习", "title_en": "Online Decision-Focused Learning", "authors": "Aymeric Capitaine,Maxime Haddouche,Eric Moulines,Michael I. Jordan,Etienne Boursier,Alain Durmus", "background": "决策导向学习（DFL）是一个日益流行的训练预测模型的范式，用于决策任务。现有的研究主要关注固定数据批次且目标函数不随时间变化的场景。然而，本文将DFL的研究扩展到了目标函数和数据分布随时间动态变化的在线学习环境，这个问题对于在线学习具有挑战性，因为目标函数可能没有梯度或者梯度无法定义，这限制了标准的梯度优化方法的应用，并且通常是非凸的，这增加了解决的难度。现有的方法似乎没有针对这个问题提供任何可验证的保证，因此作者致力于解决这个问题，提出了新的方法和算法，并确立了相应的理论保证和实验证据。", "innovation": "针对动态环境下的在线决策导向学习问题，作者提出了一种新的在线学习算法，通过正则化目标函数以使其可微，并结合扰动技术与近优核函数来克服非凸性问题。作者开发了两种专为DFL设计的在线算法，并分别建立了静态和动态的遗憾界。这是第一个在线决策导向学习问题的可验证保证，填补了该领域的空白。", "conclusion": "作者展示了他们算法的有效性，在背包实验中，他们的方法比两种标准基准方法表现更好，证明了算法的实际应用价值。"}
{"llm_update_time": "20251006", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.05940", "html_url": "https://arxiv.org/abs/2506.05940", "title": "指数族变分流匹配在表格数据生成中的应用", "title_en": "Exponential Family Variational Flow Matching for Tabular Data Generation", "authors": "Andrés Guzmán-Cordero,Floor Eijkelboom,Jan-Willem van de Meent", "background": "尽管去噪扩散和流匹配方法已在生成建模中取得了显著进展，但它们在表格数据的应用仍然有限，而表格数据在实际应用中却非常普遍。因此，本文旨在解决这一问题，开发了一种适用于表格数据生成的方法——Exponential Family Variational Flow Matching (EF-VFM)。", "innovation": "本文引入了Exponential Family Variational Flow Matching (EF-VFM)，这是一种针对混合连续和离散特征的表格数据生成方法。EF-VFM利用通用的指数族分布来表示不同类型的数据，从而获得基于矩匹配的高效、数据驱动的目标函数，使混合的连续和离散变量的概率路径学习更加合理。此外，还建立了变分流匹配与基于Bregman散度的泛化流匹配目标之间的联系。", "conclusion": "在表格数据基准测试中，该方法相较于基线方法表现出最先进的性能。"}
{"llm_update_time": "20251006", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.07998", "html_url": "https://arxiv.org/abs/2506.07998", "title": "权重的生成建模：泛化还是记忆化？", "title_en": "Generative Modeling of Weights: Generalization or Memorization?", "authors": "Boya Zeng,Yida Yin,Zhiqiu Xu,Zhuang Liu", "background": "近期研究表明，生成模型已被用来合成神经网络权重。这些方法将神经网络检查点作为训练数据，并旨在生成在推断时表现出色的权重。本研究探讨了四种代表性的方法在生成全新模型权重方面的能力，这些权重不同于训练过程中所见的检查点。研究表明，这些方法主要通过记忆来合成权重：它们要么生成检查点的复制品，要么最多只能生成简单的插值。而且，这些方法在获得不同且同时高性能的模型方面无法超越简单的基线方法，如向权重中添加噪声或将权重组合起来。", "innovation": "研究发现生成模型在生成全新模型权重方面存在的局限性，即这些方法主要依赖记忆而非产生新的、有区别的权重。在合成权重方面，生成模型未能超越一些简单的基线方法。", "conclusion": "进一步的分析表明，这种记忆现象可能源于有限的数据、过度参数化的模型以及未充分利用与权重数据相关的结构先验。这些发现突显了在新领域应用生成模型时需要更多地进行精细设计和严谨评估的必要性。"}
{"llm_update_time": "20251006", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.18340", "html_url": "https://arxiv.org/abs/2506.18340", "title": "基于对称变分流匹配的控制生成", "title_en": "Controlled Generation with Equivariant Variational Flow Matching", "authors": "Floor Eijkelboom,Heiko Zimmermann,Sharvaree Vadgama,Erik J Bekkers,Max Welling,Christian A. Naesseth,Jan-Willem van de Meent", "background": "本文在变分流匹配（VFM）框架内推导出了一种受控生成目标，将流动匹配转化为一种变分推断问题。研究展示了受控生成的两种实现方式：（1）通过端到端训练条件生成模型；（2）作为贝叶斯推理问题，允许在不重新训练的情况下对无条件模型进行后验控制。", "innovation": "本文建立确保生成对称性的条件，提出了适合分子生成的对称变分流匹配（VFM）的对称形式，确保在旋转、平移和置换方面的不变性。在不受控和受控分子生成任务上的评估表明，本文方法在未受控生成上达到目前最优性能，并且在控制生成中无论是端到端训练还是贝叶斯推理设置下均优于最新模型。", "conclusion": "本文工作加强了基于流的生成建模和贝叶斯推断之间的联系，提供了一种可扩展且符合原则的框架，用于对约束驱动和对称意识生成，为其在分子生成领域的应用提供了坚实的理论和实践基础。"}
{"llm_update_time": "20251006", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.06211", "html_url": "https://arxiv.org/abs/2507.06211", "title": "现代方法在联想记忆中的应用", "title_en": "Modern Methods in Associative Memory", "authors": "Dmitry Krotov,Benjamin Hoover,Parikshit Ram,Bao Pham", "background": "联想记忆，如著名的霍普菲尔德网络，是描述全反馈神经网络的有效模型，这些网络的基本任务是存储和检索信息。近年来，由于对其信息存储能力和与最新人工智能架构（如变换器和扩散模型）关系的新理论成果，它们受到了广泛关注。这些联系为通过联想记忆的理论视角解释传统人工智能网络的计算提供了可能性。此外，这些网络的新型拉格朗日表述使得设计出能够学习有用表示并指导新型架构设计的强大分布式模型成为可能。", "innovation": "介绍了现代方法在联想记忆领域的应用，强调了该领域研究中使用的新语言和方法，包括实用的手动数学推导和编码笔记本，为理解传统人工智能网络通过联想记忆理论视角提供了途径。", "conclusion": "此教程为联想记忆提供了一个易懂的入门介绍，重点介绍了该研究领域的现代语言和方法，通过实用的手动数学推导和编程笔记本，强调了这些方法的力量和作用。"}
{"llm_update_time": "20251006", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2505.19770", "html_url": "https://arxiv.org/abs/2505.19770", "title": "理解偏好学习中的性能差距：RLHF与DPO的二元对立", "title_en": "Understanding the Performance Gap in Preference Learning: A Dichotomy of RLHF and DPO", "authors": "Ruizhe Shi,Minhak Song,Runlong Zhou,Zihan Zhang,Maryam Fazel,Simon S. Du", "background": "本文对强化学习从人类反馈(RLHF)和直接偏好优化(DPO)之间的性能差距进行了精细理论分析，在假设存在表示差距的情况下。研究将这一差距分解为两个来源：在精确优化情况下存在的显式表示差距，以及在有限样本情况下的隐式表示差距。精确优化背景下，研究了奖励和策略模型类相对容量对最终策略质量的影响，并展示了在不同类型模型误指定的情况下，RLHF、DPO或在线DPO可以互胜。此外，研究也在近似优化背景中提供了实际构造，表明目标奖励隐式稀疏，突出两阶段学习的统计优势，即RLHF需要远少于DPO的样本来恢复有效的奖励模型。这些研究结果为在各种情况下RLHF与DPO之间的性能差距提供了全面的理解，并提供了每个方法偏好使用时的实用见解。", "innovation": "本文创新性地将性能差距分解为精确优化和近似优化背景下的显性和隐式表示差距，并通过具体的构造展示了两阶段学习的统计优势，即两阶段学习法在样本效率上的显著提高，特别是在目标奖励隐式稀疏的情况下，RLHF显著少于DPO的样本量就能有效恢复奖励模型。这些发现不仅提高了对RLHF和DPO之间差异的理解，也为此提供了实际操作的参考和建议。", "conclusion": "本文的研究结果提供了RLHF和DPO在各种情况下性能差距的全面理解，并阐述了根据模型误指定的类型，选择哪种方法更为合适的具体指导原则，特别是在模型类匹配且均错误指定的情况下，线上DPO可能超越RLHF和标准DPO。此外，RLHF在样本效率上的显著优势进一步强调了两阶段学习法的价值。"}
{"llm_update_time": "20251006", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.14202", "html_url": "https://arxiv.org/abs/2506.14202", "title": "DiffusionBlocks：通过扩散解释实现区块化神经网络训练", "title_en": "DiffusionBlocks: Block-wise Neural Network Training via Diffusion Interpretation", "authors": "Makoto Shing,Masanori Koyama,Takuya Akiba", "background": "端到端反向传播需要存储所有层中的激活，从而导致内存瓶颈，限制了模型的可扩展性。现有的区块式训练方法可以缓解这一问题，但它们依赖于特定于局部目标的手动设计并主要限于分类任务。本文的背景下，块式训练方法尚未广泛应用于除分类任务之外的其他类型任务中。在本文中，通过利用残差连接与动态系统更新之间对应性的关键洞察，提出了一种原理性的框架，用于将基于Transformer的网络转换为真正独立的可训练块，从而保持与端到端训练相当的性能。这种方法可以实现一个块的独立学习，从而减少内存需求。这些方法在多种变压器架构上的实验结果表明，DiffusionBlocks的训练性能与端到端训练相当，而且能够应用于超过小型分类任务的实际任务中，使区块训练成为现代生成任务的重要手段。", "innovation": "提出了一种名为DiffusionBlocks的新框架，用于将基于Transformer的网络转换为独立的可训练块，利用残差连接与动态系统更新之间对应性实现独立学习，并通过利用评分匹配目标减少内存需求。这种方法适用于多种变压器架构，使基于块的训练可以在现代生成任务上扩展。", "conclusion": "DiffusionBlocks通过扩散解释实现了区块化神经网络训练，相比于传统的端到端训练，降低了内存需求，适用于多种变压器架构，并在广泛的任务中展示了与端到端训练相当甚至更好的性能，表明这种训练方法可以成功地应用于包括生成任务在内的各种现代任务，具有重要的理论和实际意义。"}
{"llm_update_time": "20251006", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.04632", "html_url": "https://arxiv.org/abs/2506.04632", "title": "风险敏感型智能体组合", "title_en": "Risk-Sensitive Agent Compositions", "authors": "Guruprerana Shabadi,Rajeev Alur", "background": "现代自主系统通过将复杂目标分解为一系列子任务，并选择一系列专门的AI代理来完成这些任务，应用于从软件开发到机器人控制等多个领域。实际部署要求选择的代理组合不仅要最大化任务成功率，还需要尽量减少对安全、公平性和隐私要求的违反，这需要仔细分析代理组合的低概率行为。本文关注的是在可行代理组合集上最小化风险，并通过近似代理组合的价值-at-风险来量化违反这些要求的损失。", "innovation": "提出了一种高效的算法来遍历代理图并找到近最优的代理组合。该算法利用联合边界来近似代理组合的价值-at-风险，并证明了对广泛的实际损失函数来说，该近似是渐进近最优的。为了验证框架的有效性，使用包含使用强化学习训练的多个代理的视频游戏控制基准来评估算法，结果显示该算法能够有效地逼近价值-at-风险并识别最优的代理组合。", "conclusion": "本文通过引入代理图和一种动态规划方法来分析代理组合的低概率行为，并提出了一种近似代理组合价值-at-风险的高效算法，证明了算法在广泛实际损失函数情况下的渐进近优性。实验证明了该算法的有效性，能准确识别最优的代理组合。"}
{"llm_update_time": "20251006", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.17746", "html_url": "https://arxiv.org/abs/2507.17746", "title": "Rubrics as Rewards: Reinforcement Learning Beyond Verifiable Domains", "title_en": "Rubrics as Rewards: Reinforcement Learning Beyond Verifiable Domains", "authors": "Anisha Gunjal,Anthony Wang,Elaine Lau,Vaskar Nath,Yunzhong He,Bing Liu,Sean Hendryx", "background": "Reinforcement Learning with Verifiable Rewards (RLVR) 已经证明在具有明确正确性信号的任务（如数学和编程）上非常有效。然而，将其扩展到现实世界的推理任务中具有挑战性，因为这些任务的评估依赖于具有细微差别的、多标准的判断。虽然最近在评价基准中使用实例特定的评判标准（rubrics）来捕捉这些判断，但在训练后作为策略的回报信号的应用潜力尚未充分探索。", "innovation": "我们提出了 '评判标准作为奖励'（RaR）方法，这是一种新的在线策略强化学习方法，它通过使用基于评判标准的反馈将 RLVR 扩展到可验证领域之外。研究了多种策略来聚合评判标准反馈以形成回报，并展示了在医疗和科学领域的多个基准测试中 RaR 变种相对于流行的人工智能法官基线（LLM-as-judge baselines）的相对改进。结果表明，RaR 训练的策略能够很好地适应各种评价格式，表现出色的处理包括评判标准和多项选择任务。此外，使用评判标准作为结构化的回报信号还能更好地为小型法官提供性能对齐，并降低不同法官规模下的性能波动。", "conclusion": "RaR 训练的策略在医疗和科学领域中均表现良好，特别是在评判标准和多项选择任务方面。使用评判标准作为回报信号能够更好地为小型评委提供性能对齐，同时减少不同评委规模下的性能波动。"}
{"llm_update_time": "20251006", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2505.12380", "html_url": "https://arxiv.org/abs/2505.12380", "title": "Graph-Reward-SQL：通过图匹配和分步奖励实现无需执行的文本到SQL强化学习", "title_en": "Graph-Reward-SQL: Execution-Free Reinforcement Learning for Text-to-SQL via Graph Matching and Stepwise Reward", "authors": "Han Weng,Puzhen Wu,Longjie Cui,Yi Zhan,Boyi Liu,Yuanfeng Song,Dun Zeng,Yingxiang Yang,Qianru Zhang,Dong Huang,Xiaoming Yin,Yang Sun,Xing Chen", "background": "强化学习（RL）已被广泛应用于提升大型语言模型（LLMs）在文本到SQL任务上的性能。然而，现有的方法通常依赖于执行基于或LLM基于的Bradley-Terry奖励模型。前者由于需要重复的数据库调用而导致高执行延迟，后者则会对GPU内存造成巨大负担，这些都极大地阻碍了RL管道的效率和可扩展性。", "innovation": "我们提出了一种名为Graph-Reward-SQL的新奖励模型框架，用于基于RL的文本到SQL任务。该框架利用了GMNScore结果奖励模型，并通过SQL图表示来提供准确的奖励信号，同时显著减少了时间成本和GPU内存使用。此外，引入了StepRTM，这是一个逐步奖励模型，可以在Common Table Expression（CTE）子查询上提供中间监督，鼓励SQL的功能正确性和可读性。", "conclusion": "在标准基准测试Spider和BIRD上进行的广泛比较和消融实验表明，我们的方法在所有指标上都优于现有的奖励模型。"}
{"llm_update_time": "20251006", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.09029", "html_url": "https://arxiv.org/abs/2507.09029", "title": "基于子网络数据并行的模型并行化", "title_en": "Model Parallelism With Subnetwork Data Parallelism", "authors": "Vaibhav Singh,Zafir Khalid,Edouard Oyallon,Eugene Belilovsky", "background": "大规模预训练神经网络对加速器的内存要求较高，并常常需要昂贵的通信成本。研究旨在解决这一难题，探索一种新的分布式训练框架——子网络数据并行(SDP)，以降低对硬件资源的需求，提高训练效率和性能。", "innovation": "SDP框架将模型划分成结构化的子网络，工人之间无需交换激活值。此外，研究引入了两种不同的掩码策略：反向掩码和前向掩码，以及两种子网络构建策略：神经元级别和块级别。通过实验证明，SDP在CIFAR、ImageNet以及LLM预训练场景下，能够降低每设备30%-75%的内存占用，同时保持或提高性能。特别地，FLOP匹配条件下前向掩码有时能获得更好的性能。", "conclusion": "SDP通过引入特定的掩码策略和子网络构造方法，显著降低了大规模神经网络预训练时对内存的需求，并能提高或至少保持训练性能。这一方法为未来的分布式训练提供了新的思路。"}
{"llm_update_time": "20251006", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.18389", "html_url": "https://arxiv.org/abs/2509.18389", "title": "朝着可证明的上下文内强化学习涌现问题", "title_en": "Towards Provable Emergence of In-Context Reinforcement Learning", "authors": "Jiuqi Wang,Rohan Chandra,Shangtong Zhang", "background": "通常，现代强化学习（RL）代理通过更新其神经网络参数来适应任务的策略。最近观察到，一些经过一些基任务分布预训练的 RL 代理能够在无需进行参数更新的情况下解决广泛的新型任务。这些转移学习任务中，预训练后的代理会根据附加输入“上下文”，例如在新任务中与环境的交互历史，调整其策略。这是通过内部化上下文信息实现的，但其参数保持固定。这一现象称为上下文内强化学习（ICRL）。然而，许多 ICRL 工作使用标准的 RL 算法进行预训练，这引发了本文的核心问题：为什么能够生成使 ICRL 成立的网络参数的基础算法？研究人员假设，能实现 ICRL 的参数是预训练损失的极小值，并通过实证研究提供了初步支持。", "innovation": "本文提供了一种初步验证该假设的研究，特别是对于使用 Transformer 的情况，证明了当 Transformer 用于策略评估预训练时，预训练损失的一个全局最小值可以实现上下文内的时序差分学习。", "conclusion": "本文的研究结果支持了能实现 ICRL 的参数是一种预训练损失的极小值的假设，为理解为什么标准 RL 算法能够生成 ICRL 所需的网络参数提供了理论基础。"}
{"llm_update_time": "20251006", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.01793", "html_url": "https://arxiv.org/abs/2509.01793", "title": "STORI：随机环境的基准和分类", "title_en": "STORI: A Benchmark and Taxonomy for Stochastic Environments", "authors": "Aryan Amit Barsainyan,Jing Yu Lim,Dianbo Liu", "background": "尽管强化学习技术在如Atari100k等模拟基准测试上取得了显著的性能，但最近的进展主要局限在仿真环境中，在实际应用领域中表现有限。环境的随机性成为主要障碍，因为现实系统中的噪声观察、不可预测的动力学和非稳态条件会削弱当前方法的稳定性。现有基准很少捕捉到这些不确定性，偏好可以调优成功的简化设置。此外，缺乏明确的随机性分类进一步阻碍了评估，因为对某种随机扰动的鲁棒性并不能保证对其他形式的不确定性也鲁棒。为解决这一关键缺口，我们提出了STORI (STOchastic-ataRI) 基准，系统地整合了多元的随机影响，并在不同形式的不确定性下对强化学习技术进行严格的评估。", "innovation": "我们提出了一种全面的五种类型的环境随机性分类，并通过针对DreamerV3和STORM算法的详细评估，展示了最先进的基于模型的强化学习算法中的系统性脆弱性。我们的研究表明，世界模型严重低估了环境的变异性，难以应对动作干扰，并在部分可观测性下表现出不稳定的动力学。我们公开发布了代码和基准，提供了一个统一的框架来开发更具鲁棒性的强化学习系统。", "conclusion": "我们介绍的STORI基准和分类能够系统地纳入各种随机影响，并在不同形式的不确定性下对强化学习技术进行严格评估，揭示了最先进的基于模型的强化学习算法中的系统性脆弱性。通过公开发布代码和基准，我们为开发更加鲁棒的强化学习系统提供了一个统一框架。"}
{"llm_update_time": "20251006", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.11086", "html_url": "https://arxiv.org/abs/2508.11086", "title": "短视频推荐中的相对优势去偏差化方法用于观看时间预测", "title_en": "Relative Advantage Debiasing for Watch-Time Prediction in Short-Video Recommendation", "authors": "Emily Liu,Kuan Han,Minfeng Zhan,Bocheng Zhao,Guanyu Mu,Yang Song", "background": "观看时间被广泛用作视频推荐平台中用户满意度的代理指标。然而，原始的观看时间会受到视频时长、流行度和个人用户行为等因素的干扰，有可能扭曲偏好信号，导致偏倚的推荐模型。", "innovation": "本文提出了一个新颖的相对优势去偏差化框架，通过将观看时间与通过用户和项目组条件推导出的经验参考分布进行对比，纠正了观看时间的偏差。该框架采用基于分位数的偏好信号，并引入两阶段架构，明确分离分布估计和偏好学习。此外，还提出了分布嵌入，以高效地参数化观看时间分位数，而无需进行在线抽样或存储历史数据。", "conclusion": "离线和在线实验表明，与现有基线方法相比，该方法在推荐准确性和鲁棒性方面有显著改进。"}
{"llm_update_time": "20251006", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.20836", "html_url": "https://arxiv.org/abs/2507.20836", "title": "首次幻觉标记与条件标记不同", "title_en": "First Hallucination Tokens Are Different from Conditional Ones", "authors": "Jakob Snel,Seong Joon Oh", "background": "大型语言模型（LLMs）可能会产生幻觉，这些幻觉需要被检测出来以确保用户的信任。现有研究主要集中在对回复或片段级别的幻觉检测，但较少关注标记级别的幻觉检测。虽然标记级别的检测能够实现更细粒度的干预，但幻觉信号在整个幻觉标记序列中的分布尚未被系统地研究。这项研究利用RAGTruth语料库中的标记级别注释，发现在几组模型中，首次幻觉标记比后续的幻觉标记更易检测，这表明首次幻觉标记在标记级别的幻觉检测中扮演重要角色。", "innovation": "研究关注幻觉信号在整个幻觉标记序列中的分布，发现首次幻觉标记比后续的幻觉标记更易检测，提出了首次幻觉标记在标记级别幻觉检测中的重要性，并且开放了代码供进一步研究。", "conclusion": "首次幻觉标记在标记级别幻觉检测中扮演重要角色，这为后续更深入研究标记级别的幻觉检测提供了重要依据。"}
{"llm_update_time": "20251006", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.20334", "html_url": "https://arxiv.org/abs/2509.20334", "title": "特征动态作为隐式数据增强：深度分解视角下的深度神经网络泛化", "title_en": "Feature Dynamics as Implicit Data Augmentation: A Depth-Decomposed View on Deep Neural Network Generalization", "authors": "Tianyu Ruan,Kuo Gai,Shihua Zhang", "background": "与传统的泛化理论不同，本文通过不仅研究输入和输出，还研究内部特征随时间的演变，来探讨深度网络良好泛化能力的原因。研究表明，浅层特征与深层特征的结合在预测中保持稳定，这种稳定性并非简单的收敛现象，而是支持泛化的一种隐式的、结构性的增强机制。此外，该研究还发现这种稳定性在未见和受损数据中仍然存在，但在语义结构破坏时（如随机标签）会崩溃。进一步的统计测试表明，SGD注入了与少数主方向对齐的各向异性噪声，强化了其作为结构化变异来源的作用。这些发现为将特征动态与泛化联系起来提供了概念性视角，并为进一步研究提供了方向性指导，特别是在度量特征随时间演化的实际替代指标方面。", "innovation": "本文通过研究深度网络内部特征随时间的变化，提出现有泛化理论未曾涉及的新视角，即“特征动态作为隐式数据增强”概念，强调浅层特征和深层特征结合对于保持预测稳定性的关键作用，并通过统计方法证明了随机梯度下降（SGD）在特征演化中的结构性影响。", "conclusion": "本文的研究揭示了特征随时间的动态演变对于深度网络泛化能力的一个潜在机制。它表明，浅层特征与深层特征的结合有助于维持预测的稳定性，并且这种机制可以通过随机梯度下降（SGD）中的结构性噪声得到进一步的验证。未来的研究可以通过开发实际的度量方法来更准确地测量特征随时间的演化，从而进一步理解和优化深度网络的泛化能力。"}
{"llm_update_time": "20251006", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.02964", "html_url": "https://arxiv.org/abs/2508.02964", "title": "基于注入测量信息的快速且抗噪的基于扩散的逆问题求解器", "title_en": "Injecting Measurement Information Yields a Fast and Noise-Robust Diffusion-Based Inverse Problem Solver", "authors": "Jonathan Patsenker,Henry Li,Myeongseob Ko,Ruoxi Jia,Yuval Kluger", "background": "扩散模型已被证实是解决线性和非线性逆问题的有效方法，它们通过强大的图像先验和迭代采样算法发挥作用。这些方法通常依赖于Tweedie公式来指导扩散轨迹，公式将扩散变量$\boldsymbol{x}_t$与后验均值$\boldsymbol{E} [\boldsymbol{x}_0 | \boldsymbol{x}_t]$联系起来，以便估算最终去噪样本$\boldsymbol{x}_0$。然而，这种方法并未考虑到测量$\boldsymbol{y}$的信息，因此需要在下游整合。", "innovation": "本文提出了一个新的方法，通过估计条件后验均值$\boldsymbol{E} [\boldsymbol{x}_0 | \boldsymbol{x}_t, \boldsymbol{y}]$，将其作为基于单一参数的最大似然估计问题的解来进行求解。这种方法能够与任何标准采样器集成，从而实现快速且内存高效的逆问题求解器。本优化器具有对测量噪声$\boldsymbol{y}$鲁棒的噪声感知似然停止准则。研究表明，在多个数据集和任务中，本文方法与当代广泛使用的逆问题求解器相比具有相近或更优的性能。", "conclusion": "本文提出的方法能够提供更快且更抗噪的基于扩散的逆问题求解器，具有与广泛使用的当代逆问题求解器相似或更好的性能。"}
{"llm_update_time": "20251006", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.00410", "html_url": "https://arxiv.org/abs/2508.00410", "title": "Co-rewarding: 联合奖励——一种稳定的自我监督强化学习方法以激发大型语言模型的推理能力", "title_en": "Co-rewarding: Stable Self-supervised RL for Eliciting Reasoning in Large Language Models", "authors": "Zizhuo Zhang,Jianing Zhu,Xinmu Ge,Zihua Zhao,Zhanke Zhou,Xuan Li,Xiao Feng,Jiangchao Yao,Bo Han", "background": "尽管可验证奖励的强化学习（RLVR）能够提升大规模语言模型（LLMs）的推理能力，但这种方法依赖于人类标注的标签，对于复杂任务来说，这种依赖性导致了规模扩大的难题。最近的研究探索了标签自由的方法来解锁LLMs的推理能力，但这类方法常常遇到重大训练崩溃的问题，因为单一视角的监督信号容易形成自我一致的幻觉，导致奖励操纵。因此，开发一种能够提高训练稳定性的自我监督强化学习框架成为关键需求。受到自我监督学习成功的启发，本文提出了联合奖励（Co-rewarding），通过从另一种视角获得互补的监督来增强训练的稳定性。", "innovation": "本文提出的联合奖励(Co-rewarding)框架以自我监督学习为基础，通过两种新颖的方式提高训练稳定性：(1) 数据侧的Co-rewarding-I方法从语义上相似的问题的对比一致性中推导奖励信号；(2) 模型侧的Co-rewarding-II方法维持一个缓慢更新的参考教师以实现自我蒸馏。这种两种方法通过引入不同的难度梯度来增加训练崩溃的难度，从而提高训练的稳定性。实验结果显示，Co-rewarding在多个数学推理基准测试中表现稳定，比其他自我奖励基线平均高出3.31%，特别是在Llama-3.2-3B-Instruct上提高了7.49%。值得注意的是，在某些情况下，Co-rewarding甚至超越了带有真实标签的RLVR，例如，在GSM8K上Qwen3-8B-Base的通过率为94.01%，显著高于真实标签。", "conclusion": "本文提出了联合奖励(Co-rewarding)框架，这是一个基于自我监督学习的新颖强化学习框架，通过引入另一种视角的互补监督来增强训练稳定性，实验结果表明Co-rewarding在多个数学推理基准测试中表现出色，并且在某些情况下甚至超越了带有真实标签的RLVR。"}
{"llm_update_time": "20251006", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.23799", "html_url": "https://arxiv.org/abs/2509.23799", "title": "基于稀疏自编码器向量精炼的LLM引导增强", "title_en": "Enhancing LLM Steering through Sparse Autoencoder-Based Vector Refinement", "authors": "Anyi Wang,Xuansheng Wu,Dong Shu,Yunpu Ma,Ninghao Liu", "background": "引导作为控制大型语言模型（LLMs）的一种有前途的方法，不需修改模型参数。然而，大多数现有的引导方法依赖大规模数据集来学习明确的行为信息，限制了其在许多实际场景中的应用。从小型数据集中提取的引导向量往往包含与任务无关的噪声特征，降低了其有效性。因此，需要改进的方法来从有限的数据中提炼有效的引导向量。", "innovation": "引入了一种基于稀疏自编码器（SAE）的引导向量精炼方法（SAE-RSV），该方法能够去噪和增强从小型数据集中提取的引导向量。具体地，通过稀疏自编码器提供的语义信息，SAE-RSV会首先去除与任务无关的特征，然后通过与已识别相关特征的语义相似性，填补小型数据集中缺失的任务相关特征。这种精炼方法在多个实验中显示出比监督微调等基准方法更好的效果。", "conclusion": "通过稀疏自编码器精炼原始引导向量，SAE-RSV能够有效地从有限训练数据中构造有效的引导向量，这在多个实验中得到了验证，显著优于所有基准方法，包括监督微调。"}
{"llm_update_time": "20251006", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.24827", "html_url": "https://arxiv.org/abs/2509.24827", "title": "Putnam-like数据集概述：数学竞赛中的LLM", "title_en": "Putnam-like dataset summary: LLMs as mathematical competition contestants", "authors": "Bartosz Bieganowski,Daniel Strzelecki,Robert Skiba,Mateusz Topolewski", "background": "本文总结了由Google DeepMind发布的Putnam类似基准的数据集。该数据集包含96个沿袭Putnam竞赛精神的原创问题以及576个由大型语言模型（LLM）提供的解决方案。研究人员分析了这些模型在这组问题上的表现，以验证它们解决数学竞赛问题的能力。", "innovation": "本文通过使用专为数学竞赛设计的数据集，评估大型语言模型解决数学问题的能力，为理解LLM在复杂数学任务上的表现提供了新的视角。", "conclusion": "通过对Putnam类似数据集的分析，研究人员验证了大型语言模型解决数学竞赛问题的能力。虽然在某些问题上表现出色，但LLM仍然存在局限性，特别是在复杂和非标准的问题解决方面。"}
{"llm_update_time": "20251006", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.23753", "html_url": "https://arxiv.org/abs/2509.23753", "title": "锚定的监督微调", "title_en": "Anchored Supervised Fine-Tuning", "authors": "He Zhu,Junyou Su,Peng Lai,Ren Ma,Wenjia Zhang,Linyi Yang,Guanhua Chen", "background": "大型语言模型的后训练过程涉及到监督微调（SFT）和强化学习（RL）之间的基本权衡。SFT虽然效率高且能很好地模仿演示，但也容易产生记忆效应；而RL则能实现更好的泛化，但代价是更高的计算成本。近期的发展中，动态微调（DFT）作为一种折中的方案出现了，通过重新加权SFT目标来适应不同的任务，虽然在一些推理领域取得了初步成功，但在其他任务中仍表现出不稳定的现象。", "innovation": "本文提出了一种新的方法——锚定的监督微调（ASFT），该方法通过在DFT的重新加权中增加了轻量级的KL正则化，从而保留了DFT带来的紧凑性同时确保了训练的稳定性。ASFT在数学推理、医学知识接地和代码生成等多个领域中表现出了显著优于传统SFT和DFT的方法，且计算开销较小。同时，文章还通过奖励加权回归（RWR）框架对DFT进行了分析，揭示了其构建的局限性，并进一步展示了理论分析如何促进更可靠的设计和实际应用。", "conclusion": "ASFT方法在数学推理、医疗知识接地和代码生成等任务中都表现出色，显著优于传统的SFT和DFT方法，同时计算成本较低。奖励加权回归（RWR）框架为理解后训练方法提供了一个系统性的视角，并证明了原则性理论分析能够带来更强的保证和实际收益。"}
{"llm_update_time": "20251006", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.23089", "html_url": "https://arxiv.org/abs/2509.23089", "title": "揭开网络基础模型的神秘面纱", "title_en": "Demystifying Network Foundation Models", "authors": "Sylee Beltiukov,Satyandra Guthula,Wenbo Guo,Walter Willinger,Arpit Gupta", "background": "该研究对网络基础模型（NFMs）中隐含的知识进行了系统性的考察，重点关注的是隐藏表示的分析，而非仅仅是下游任务的性能。不同于现有的研究，本文通过三个部分的评估来分析这些模型：嵌入几何分析以评估表示空间的利用情况，度量对齐评估以衡量与领域专家特征的对应程度，因果灵敏度测试以评估网络协议扰动下的鲁棒性。研究使用了跨越控制和真实环境的五个不同的网络数据集，评估了四个最先进的NFMs模型，揭示了这些模型普遍存在显著的各向异性、特征灵敏度模式不一致、高层语境区分性差、负载依赖性等问题。这些发现表明，存在许多模型的局限性，且修复这些问题能够显著改善模型性能（在没有架构变更的情况下，最高可提升0.35个F1分数）。", "innovation": "本文创新之处在于对网络基础模型的分析角度，不仅仅是评估其在下游任务上的性能，还通过嵌入几何分析、度量对齐评估及因果灵敏度测试三个维度进行了全面评估，涵盖模型的空间效率、特征表示与专家知识的对应关系，以及对网络协议扰动的鲁棒性。这种评估方式能够更全面地揭示模型的潜力和局限性。", "conclusion": "本文揭示了当前最先进的网络基础模型中存在的主要问题和局限性，并展示了通过改进这些方面可以在不改变架构的情况下提升模型性能。研究还强调了改进这些方面的重要性，以优化这些模型在复杂网络环境中的表现。"}
{"llm_update_time": "20251006", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.00038", "html_url": "https://arxiv.org/abs/2510.00038", "title": "DM-Bench: 血糖管理糖尿病管理中个性化决策制定的LLM基准", "title_en": "DM-Bench: Benchmarking LLMs for Personalized Decision Making in Diabetes Management", "authors": "Maria Ana Cardei,Josephine Lamp,Mark Derdzinski,Karan Bhatia", "background": "此前的健康基准测试要么是通用的、面向临床人员或专注于临床任务（如诊断、分流），并未专门针对糖尿病患者日常生活中的决策制定任务进行评估。DM-Bench旨在填补这一空白，提供一个针对糖尿病患者定制化AI解决方案的独特挑战的全面评估框架。该基准涵盖了7个不同的任务类别，反映了糖尿病患者在实际生活中提出的各种问题，包括基本葡萄糖解读、教育查询、行为关联、高级决策和长期规划等。", "innovation": "DM-Bench是第一个设计来评估大型语言模型（LLM）在糖尿病患者日常生活中面临的实际决策任务中的性能的基准。DM-Bench收集了15,000名来自三个不同糖尿病群体（1型糖尿病、2型糖尿病、前期糖尿病/一般健康和保健）的个人一个月的时间序列数据，包括葡萄糖追踪和连续葡萄糖监测器（CGMs）的指标，以及行为日志（如饮食和活动模式）。在此基础上，生成了总共360,600个针对7个任务类别的人性化、情境化问题。评估模型在这些任务上的表现使用了准确度、关联性、安全性、清晰度和可行动性等5个衡量指标。研究表明，8种最近的大型语言模型在不同任务和指标上表现不同，没有单一模型在所有维度上都表现突出。", "conclusion": "通过建立这个基准，我们旨在促进糖尿病护理中AI解决方案的可靠、安全、有效和实用。"}
{"llm_update_time": "20251006", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.19366", "html_url": "https://arxiv.org/abs/2508.19366", "title": "基于谱图的框架：量化多模态LLM中的幻觉", "title_en": "Grounding the Ungrounded: A Spectral-Graph Framework for Quantifying Hallucinations in multimodal LLMs", "authors": "Supratik Sarkar,Swagatam Das", "background": "在大型语言模型中，幻觉仍然是一个主要障碍，尤其是在医疗、法律和金融等高风险多模态领域。现有的评估技术大多依赖于启发式方法——基于定性基准或一次性应急缓解，这些方法既没有提供有原则的量化方法，也没有提供可操作的理论保证。这种差距造成对幻觉如何产生、传播和跨模态交互的理解存在关键盲点。", "innovation": "本研究提出了首个（据我们所知）基于扩散动力学的信息几何框架，用于量化多模态LLM中的幻觉，将该领域从定性检测提升到以数学为基础的测量。该框架通过多模态图拉普拉斯算子上的谱嵌入表示LLM输出，并通过语义失真表征真相与不一致性之间的流形差距，从而通过时间依赖温度剖面上的多元幻觉能量的紧密瑞利-里兹界，实现模态感知、可解释的度量，捕捉幻觉随时间和输入提示的变化。", "conclusion": "本研究建立了量化和限制幻觉的科学基础，将幻觉从定性的风险转换为可管理、可分析的现象。"}
{"llm_update_time": "20251006", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.25351", "html_url": "https://arxiv.org/abs/2509.25351", "title": "梯度下降法的大步长：混沌和分形收敛区域", "title_en": "Gradient Descent with Large Step Sizes: Chaos and Fractal Convergence Region", "authors": "Shuang Liang,Guido Montúfar", "background": "研究了矩阵分解中梯度下降的行为。作者指出，在大的步长下，参数空间会产生分形结构。通过分析，得出在标量-向量分解情况下精确的收敛步长，并展示了在接近临界点时选择的最小值对初始化高度敏感。进一步地，增加了正则化会使这种敏感性增强，产生一条分形界限，划分出收敛和发散的初始化。该分析也扩展到了一般矩阵分解中的正交初始化情况。这些发现揭示了临界步长附近梯度下降会进入一个混沌区域，在这种区域中长期动态无法预测，也不存在平衡性、最小范数或平坦性等简单的隐含偏置规律。", "innovation": "在大的步长下，参数空间的分形结构；精确地为标量-向量分解确定了收敛的步长；展示了正则化会增强初始化对收敛性的影响；将分析扩展到一般矩阵分解并考虑正交初始化情况；揭示了临界步长下梯度下降的混沌机制，表明长期动态不可预测且不存在简单隐含偏置规律。", "conclusion": "该研究揭示了临界步长下梯度下降的混沌动态，当步长较大时，梯度下降的最小值对初始值高度敏感，正则化会进一步增加这种敏感性，形成一个分形的界限以区分收敛和发散的初始值。这些发现将有助于更好地理解大步长梯度下降的行为并在实际应用中优化算法。"}
{"llm_update_time": "20251006", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.01407", "html_url": "https://arxiv.org/abs/2510.01407", "title": "端到端神经压缩与重构中的超高效解码", "title_en": "Ultra-Efficient Decoding for End-to-End Neural Compression and Reconstruction", "authors": "Ethan G. Rogers,Cheng Wang", "background": "图像压缩和重构对于各种数字应用至关重要。尽管现代神经网络压缩方法能实现出色的压缩率，但采用这些技术仍然受到了基于卷积的解码器在数据重构过程中复杂性和巨大的计算成本的阻碍。", "innovation": "我们开发了一种新的压缩-重构框架，结合了低秩表示的自编码器和向量量化技术，以解决神经网络压缩中的解码瓶颈问题。通过在学习到的图像潜在表示上进行一系列计算高效的低秩操作，我们能够高效地重建高质量的数据，并极大地减少了神经压缩/重构解码阶段的计算开销，有效地消除了解码计算瓶颈，同时保持了图像输出的高精度。", "conclusion": "我们的方法在保持高质量图像输出的同时，显著降低了神经压缩/重构解码阶段的计算开销，从根本上解决了解码计算瓶颈问题。"}
{"llm_update_time": "20251006", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.00352", "html_url": "https://arxiv.org/abs/2510.00352", "title": "AReUReDi: 缓慢归一化更新以优化离散流动的多目标引导", "title_en": "AReUReDi: Annealed Rectified Updates for Refining Discrete Flows with Multi-Objective Guidance", "authors": "Tong Chen,Yinuo Zhang,Pranam Chatterjee", "background": "在治疗和生物分子工程中，设计同时满足多个经常冲突目标的序列是一个关键挑战。现有的生成框架主要在连续空间中操作，并且通常只有一个目标的指导。离散方法则缺乏确保多目标帕累托最优的保证。传统的优化方法通常难以同时优化药物分子的多种性质，而AReUReDi提供了一种离散优化算法，能够理论上保证收敛到帕累托前沿。这种算法结合了Tchebycheff标量化，局部平衡提议以及缓慢退火的贝叶斯-哈特斯更新，从而偏向于采样帕累托最优状态的同时保持分布不变性。研究表明，AReUReDi在肽序列和SMILES序列设计中能够同时优化多达五个治疗特性（包括亲和力、溶解性、溶血性、半衰期和非附着性）。这些结果证明了AReUReDi作为多性质生物分子生成的强大序列框架的有效性。", "innovation": "AReUReDi是首个智能优化算法，它结合Tchebycheff标量化、局部平衡提议和缓慢退火的贝叶斯-哈特斯更新，偏置采样以青睐于帕累托最优状态，同时保持分布外部不变。这种算法能够在序列设计中同时优化多个治疗相关属性，超越了进化算法和基于扩散的方法。", "conclusion": "AReUReDi为多性质生物分子的序列生成提供了强大的框架，它能够有效地在序列设计中实现多属性的同步优化并超越现有的基线方法。"}
{"llm_update_time": "20251006", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.01764", "html_url": "https://arxiv.org/abs/2510.01764", "title": "Octax：JAX 中加速的 CHIP-8 游戏环境用于强化学习", "title_en": "Octax: Accelerated CHIP-8 Arcade Environments for Reinforcement Learning in JAX", "authors": "Waris Radji,Thomas Michel,Hector Piteau", "background": "强化学习（RL）研究需要多样化、具有挑战性的环境，这些环境既易于处理又易于扩展。虽然现代视频游戏提供了丰富的动态效果，但因计算密集型，不适合大规模实验。相比之下，基于CHIP-8模拟的经典街机游戏环境，虽然被广泛用作RL研究的基准，但由于CPU限制执行效率低下，不利于大规模实验。", "innovation": "本文介绍了Octax，一种基于JAX和CHIP-8模拟实现的高性能街机游戏环境套件。Octax实现了与传统CPU模拟器相比，速度提升了多个数量级，同时保持完美的原始游戏规则一致性。Octax还提供了图像化环境，覆盖了拼图、动作和策略游戏等多种类型，并且能够在现代GPU上大规模执行。此外，Octax的设计允许研究人员易于添加新游戏或使用大规模语言模型生成新环境，使其成为大规模RL实验的理想平台。", "conclusion": "通过在多个游戏中训练RL代理，Octax展示了与现有解决方案相比，显著提高了训练速度和可扩展性。Octax的模块化设计使其能够轻松添加新游戏或使用大规模语言模型生成新环境，为大规模RL实验提供了理想平台。"}
{"llm_update_time": "20251006", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.22855", "html_url": "https://arxiv.org/abs/2509.22855", "title": "无观察攻击下的在线学习排序攻击", "title_en": "Observation-Free Attacks on Online Learning to Rank", "authors": "Sameep Chattopadhyay,Nikhil Karamchandani,Sharayu Moharir", "background": "在线学习排序（OLTR）在信息检索和机器学习系统中至关重要，广泛应用于搜索引擎和内容推荐器。尽管OLTR算法已被广泛采用，但它们对策划的协同式敌手攻击的脆弱性仍不甚了解。", "innovation": "本文提出了一种新颖的框架，针对一些广泛使用的OLTR算法进行攻击。该框架旨在促进一组目标项目，使它们在T-o(T)轮次中出现在前K个推荐列表中，同时诱导学习算法产生线性遗憾。作者提出了两种新颖的攻击策略：CascadeOFA针对CascadeUCB1，PBMOFA针对PBM-UCB，并提供了理论保证，显示这两种策略只需O(log T)次操纵即可成功。此外，还通过实证结果对相关性进行了补充分析。", "conclusion": "本文通过理论分析和实证结果证明，新的攻击策略要求仅需O(log T)次操纵即可成功，在线学习排序算法对策划攻击的脆弱性得到了充分的研究。"}
{"llm_update_time": "20251006", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.02084", "html_url": "https://arxiv.org/abs/2510.02084", "title": "KAIROS: 统一训练实现通用非自回归时间序列预测", "title_en": "KAIROS: Unified Training for Universal Non-Autoregressive Time Series Forecasting", "authors": "Kuiye Ding,Fanda Fan,Zheya Wang,Hongxiao Li,Yifan Wang,Lei Wang,Chunjie Luo,Jianfeng Zhan", "background": "在互联网上，可靠的时序预测提供了前瞻性的信号，用于资源规划、缓存放置和异常响应，使平台能够高效运行，随着用户行为和内容分布的变化而调整。与其他领域相比，Web应用程序的时间序列预测需要更快的响应速度，以支持实时决策。", "innovation": "KAIROS 是一种非自回归的时序预测框架，它直接建模段级多峰分布，避免了自回归方法中的误差积累，实现了即时推理，并且在大规模数据集上展示了比现有非自回归模型更好的零样本泛化能力，预测效果与基础模型相当，但推理成本更低。", "conclusion": "KAIROS 突出了非自回归设计对于时序预测基础模型在大规模应用中的重要性和一个可扩展的范式。"}
{"llm_update_time": "20251006", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.17153", "html_url": "https://arxiv.org/abs/2509.17153", "title": "Flow-诱导的对角高斯过程", "title_en": "Flow-Induced Diagonal Gaussian Processes", "authors": "Moule Lin,Andrea Patane,Weipeng Jing,Shuhao Guan,Goetz Botterweck", "background": "当前的研究集中于如何在保留模型表征能力的同时，减少深层神经网络的存储需求。已有方法中，适用于高维数据压缩的技术，特别是基于引致子空间的方法，如基于SVGP的方法，在某些任务上表现良好。然而，现有的方法在不确定性估计和OoD检测上仍然存在不足。", "innovation": "提出了一个称为Flow-Induced Diagonal Gaussian Processes (FiD-GP)的压缩框架，该框架通过引入一个紧凑的引致权重矩阵将神经网络的权重不确定性投影到一个低维度子空间中。FiD-GP使用流Norm前向概率分布和谱正则化来增强其表达能力，通过数值稳定的投影机制目标来对齐引致子空间与特征梯度几何。此外，FiD-GP的预测框架有助于设计用于OoD检测的一次性投影。", "conclusion": "实证研究表明，相比基于SVGP的 baseline，FiD-GP在各种任务中提高不确定性估计的能力，满足了严格的谱残差边界，并在一定条件下理论上保证了OoD检测，同时显著压缩了神经网络的存储需求，尽管需要更多的推理计算开销用于引致权重的数量。具体地，在包括回归、图像分类、语义分割和OoD检测基准实验中，FiD-GP将贝叶斯训练成本压缩了几个数量级，参数压缩了约51%，模型大小减少了约75%，同时匹配了最先进的准确率和不确定性估计。"}
{"llm_update_time": "20251006", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.01988", "html_url": "https://arxiv.org/abs/2510.01988", "title": "PepCompass：利用黎曼几何导航肽嵌入空间", "title_en": "PepCompass: Navigating peptide embedding spaces using Riemannian Geometry", "authors": "Marcin Możejko,Adam Bielecki,Jurand Prądzyński,Marcin Traskowski,Antoni Janowski,Karol Jurasz,Michał Kucharczyk,Hyun-Su Lee,Marcelo Der Torossian Torres,Cesar de la Fuente-Nunez,Paulina Szymczak,Michał Kmicikiewicz,Ewa Szczurek", "background": "抗微生物肽的发现受到肽空间巨大且活性肽相对稀少的挑战。生成模型能够提供连续的肽空间“地图”，但通常忽略了解码器引起的几何形状，只能使用平面欧几里得度量，导致探索和优化不准确且效率低下。先前基于流形的方法假设固定的内在维度，在实践中对肽数据不起作用。", "innovation": "引入了PepCompass，这是一种感知几何的肽探索与优化框架，定义了由解码器诱导、捕捉局部几何结构且具有计算稳定性的κ-稳定黎曼流形。提出了局部探索方法，如二次黎曼布朗运动高效采样，以及将切空间方向重新解释为离散的氨基酸替代。结合这些提出了局部枚举贝叶斯优化算法（LE-BO）。还引入了潜在最小化测地线搜索（PoGS），这是一种面向具有良好活性的种子肽进行偏置的肽发现方法。", "conclusion": "体内验证证实了PepCompass的有效性：PoGS产生了四种新型种子肽，而后续使用LE-BO优化发现了25种具有广谱活性的肽，包括对耐药细菌有效的肽。这些结果表明，基于几何的探索为抗微生物肽设计提供了一个强有力的新的范式。"}
{"llm_update_time": "20251006", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.01457", "html_url": "https://arxiv.org/abs/2510.01457", "title": "修复免费午餐：合成数据在基于模型的策略优化中的何时、何地以及为何失败", "title_en": "Fixing That Free Lunch: When, Where, and Why Synthetic Data Fails in Model-Based Policy Optimization", "authors": "Brett Barkley,David Fridovich-Keil", "background": "基于合成数据的数据高效动态风格模型导向的强化学习是核心组成部分，但有时也会降低性能。通过研究，指出合成数据在哪些情况下有效，哪些情况下失效以及为什么失效。同时揭示了由于评估方式的局限性导致环境特定假设在算法设计中被隐性地编码。这项研究在DeepMind控制套件中发现了Model-Based Policy Optimization (MBPO)与Soft Actor-Critic (SAC)之间的性能损失，尤其是在复杂的任务中，尽管两者都涉及到健全控制且具有本体感受器的机器人，依然存在显著的效率差距。", "innovation": "研究确定了导致失败的两个问题：动力学和奖励模型之间的规模不匹配导致评价者低估，影响策略改进；目标表示的选择不当导致模型方差增加，产生易出错的滚动等。通过解决这些失败模式，使MBPO在七项任务中的五项上表现超过SAC，同时保持在OpenAI Gym中报告的强大性能。该研究希望推动社区建立分类法，连接MDP任务和环境层面的结构与算法失败模式，探索统一解决方案，并明确基准选择如何最终影响算法的泛化能力。", "conclusion": "我们的研究结果表明，MBPO在七项任务中的五项上表现超过SAC，同时保留了在OpenAI Gym中报告的强大表现。我们希望这些发现可以激励社区开发分类法，将MDP任务和环境层面的结构与算法失败模式联系起来，并探索可能的统一解决方案，以澄清基准选择如何最终影响算法的泛化能力。"}
{"llm_update_time": "20251006", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2402.17732", "html_url": "https://arxiv.org/abs/2402.17732", "title": "批处理非参数上下文伯努利分配问题", "title_en": "Batched Nonparametric Contextual Bandits", "authors": "Rong Jiang,Cong Ma", "background": "本文研究在批处理约束下非参数上下文伯努利分配问题，即每个动作的期望奖励是协变量的平滑函数，并且在每个观测批次结束时才更新策略。", "innovation": "本文建立了这一设置下的最小遗憾下界，并提出了一种新的批处理学习算法，该算法在对数因子内达到了最优遗憾。此外，研究方法动态地将协变量空间划分成更小的区域，并巧妙地调整它们的宽度以匹配批次大小。", "conclusion": "理论上讲，对于非参数上下文伯努利分配问题，几乎固定数量的策略更新可以在全在线设置中实现最优遗憾。"}
{"llm_update_time": "20251006", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.01456", "html_url": "https://arxiv.org/abs/2510.01456", "title": "SCOPED：评分曲率异常分布邻近评估器", "title_en": "SCOPED: Score-Curvature Out-of-distribution Proximity Evaluator for Diffusion", "authors": "Brett Barkley,Preston Culbertson,David Fridovich-Keil", "background": "在视觉、机器人学、强化学习等领域中，可靠的机器学习系统部署需要有效的异常分布（OOD）检测方法。传统的OOD检测方法需要多次通过训练模型，这在计算成本和效率上带来了挑战。本文针对此问题，介绍了一种新的快速且通用的OOD检测方法——Score-Curvature Out-of-distribution Proximity Evaluator for Diffusion (SCOPED)。该方法通过单一的扩散模型在多样化数据集上训练一次，计算出单一测试统计量，利用评分函数的雅可比迹和平方范数的组合来检测OOD，相比之前的方法减少了近一个数量级的前向传递次数。这种方法在四个视觉基准测试中，即便具有较低的计算成本也达到了竞争或最先进的精度召回率性能，并且具有低计算成本下生成高效OOD检测的基础。此外，该方法在同一状态下适用于机器人的控制任务，并能识别奖励函数和训练范式的变化，展现出广泛的实用性。", "innovation": "SCOPED方法的独特之处在于，不再依赖固定阈值，而是使用核密度估计来估计评分曲率的密度分布，从而实现一种灵活且无监督的测试，只需一次前向传播和一次雅可比向量乘积即可。这种方法能够有效降低计算成本，并且在无需额外标注的情况下提高了OOD检测的精度和效率，特别是在视觉、强化学习和数据集管理等应用领域中表现出色。", "conclusion": "SCOPED作为一种快速且可靠的OOD检测基础，在多个应用场景中证明了自己的实用性，特别是在减少计算开销的同时，仍然保持了高性能。SCOPED可以用于感知视觉中伪像检测、自回归模型中的异常检测、强化学习中的探索以及无监督训练数据集的管理等多种实际领域的应用。"}
{"llm_update_time": "20251006", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.01471", "html_url": "https://arxiv.org/abs/2510.01471", "title": "使用变分贝叶斯后层微调LLM进行高维贝叶斯优化", "title_en": "Fine-tuning LLMs with variational Bayesian last layer for high-dimensional Bayesian optimization", "authors": "Haotian Xiang,Jinwen Xu,Qin Lu", "background": "许多应用涉及到高评价成本的黑盒优化问题，例如药物发现、材料设计和超参数调整。为了以样本高效的方式找到这些黑盒优化问题的全局最优解，贝叶斯优化（BO）提供了一个理论上优雅的框架，依赖于概率代理模型，以便在每次选择查询点时实现探索与利用的平衡。然而，高维的不规则变量（如分类、顺序等变量）使得高斯过程（GP）这种方法表现不佳。因此，研究人员开始探索基于神经网络的代理模型来解决这个问题。基于大语言模型（LLMs）的强大能力，该研究采用LLMs作为代理模型来处理高维输入变量与目标函数之间的映射关系，并通过变分贝叶斯后层（VBLL）框架和低秩适应（LoRA）方法进行微调。实验结果表明，所提出的混合模型在高维基准测试和实际分子优化任务中表现优异。", "innovation": "该研究引入了一种结合低秩适应（LoRA）和变分贝叶斯后层（VBLL）框架来微调大语言模型（LLMs）的方法，用于高维贝叶斯优化。这种方法不仅计算量小，而且可以递归更新。此外，研究还设计了一种基于加权集成（ENS）的LoRA-VBLL模型集合，能够随机调整模型权重和LoRA-VBLL参数，以进一步实现递归贝叶斯更新。", "conclusion": "综合实验结果表明，该研究提出的（ENS-）LoRA-VBLL方法在各种高维优化基准测试和实际分子优化任务中表现出色。"}
{"llm_update_time": "20251006", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2404.01903", "html_url": "https://arxiv.org/abs/2404.01903", "title": "通过激活引导理解代码LLMs（错误地）预测类型", "title_en": "Understanding How CodeLLMs (Mis)Predict Types with Activation Steering", "authors": "Francesca Lucchetti,Arjun Guha", "background": "大型语言模型（LLMs）被软件工程师广泛用于编程任务中。然而，研究表明LLMs往往缺乏对程序语义的深刻理解。即使是细微的语法变化，如变量重命名，也会大幅降低不同任务中的性能。本研究关注类型预测任务：给定一个部分类型化的程序，模型能否预测缺失的类型注解，从而使程序更加类型化？研究表明LLMs在遇到语义无关的编辑时，预测类型的能力会显著下降，这意味着模型对代码语义的理解缺乏稳健性，可能只是浅层次的理解。", "innovation": "通过激活引导使用一种方法来操控模型内部的激活，以引导模型触发潜在的知识，从而在对抗性输入中恢复准确的预测。这种方法成功激活了一个由Python和TypeScript共享的类型预测机制，该机制的效果优于使用上下文提示的方法。研究结果表明，尽管LLMs在理解和预测类型方面存在局限性，但它们确实学到了稳健的机制，这些机制在对抗性情况下往往无法激活。", "conclusion": "通过全面评估五种不同的模型，研究证明LLMs可以学习跨编程语言的一般化代码语义表示，这些表示能够转移。这种激活引导的方法改进了对抗性输入中的类型预测性能。"}
{"llm_update_time": "20251006", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2207.00108", "html_url": "https://arxiv.org/abs/2207.00108", "title": "机器学习算法中的偏见", "title_en": "Discrimination in machine learning algorithms", "authors": "Roberta Pappadà,Francesco Pauli", "background": "机器学习算法经常用于业务决策，这些决策可能直接影响个体，例如，由于信用评分算法拒绝某人贷款。因此，从道德和法律的角度来看，有必要确保这些算法不会基于敏感属性（如性别或种族）进行歧视，这种歧视可能是不经意且未知的。因此，需要使用统计工具和方法来检测和消除潜在的偏见。", "innovation": "该研究可能关注于开发新的统计工具和方法来检测和消除机器学习算法中的潜在偏见。具体的创新点需要根据具体研究内容进一步分析描述。", "conclusion": "该研究强调了在使用机器学习算法时必须确保其不会基于敏感属性进行歧视。为实现这一目标，需要使用统计工具和方法来检测和消除潜在的偏见，保证算法的公正性和公平性。"}
{"llm_update_time": "20251006", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2402.08992", "html_url": "https://arxiv.org/abs/2402.08992", "title": "通过邻近点方法在随机优化中实现方差减少和低样本复杂度", "title_en": "Variance Reduction and Low Sample Complexity in Stochastic Optimization via Proximal Point Method", "authors": "Jiaming Liang", "background": "在随机优化中，高概率保证通常是在强噪声假设（如亚高斯尾巴）下获得的。本研究探讨了如何在弱假设（如有界方差）下同样获得这样的保证。", "innovation": "提出了一种随机邻近点方法，结合了具有固有方差减少功能的邻近子问题求解器和一个概率增强器，该增强器将每迭代的可靠性提升为高置信度结果。研究展示了一种具有低样本复杂性的收敛分析，无需严格的噪声假设或依赖迷你批次。", "conclusion": "通过这种方法，可以在较宽松的方差假设下获得高概率保证，并证明了其在低样本复杂性下的收敛性。"}
{"llm_update_time": "20251006", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.01494", "html_url": "https://arxiv.org/abs/2510.01494", "title": "理解对抗性转移：为何表示空间攻击在数据空间攻击成功的地方失败", "title_en": "Understanding Adversarial Transfer: Why Representation-Space Attacks Fail Where Data-Space Attacks Succeed", "authors": "Isha Gupta,Rylan Schaeffer,Joshua Kazdan,Ken Ziyu Liu,Sanmi Koyejo", "background": "有关对抗鲁棒性的领域已经确立，对抗样本可以在图像分类器之间成功传输，并且文本脱狱也可以在语言模型之间成功传输。然而，最近的研究表明，在视觉语言模型之间无法成功传输图像脱狱。为了解释这种显著的差异，论文提出了一种基本区分：针对机器学习模型的攻击可以跨输入数据空间传输，但不会在模型表示空间之间传输，至少无法在没有几何表示对齐的情况下传输。随后，在四个不同的设置中为这一假设提供了理论和实验证据。首先，通过数学证明表示空间和数据空间在两个使用不同表示计算相同输入-输出映射的网络中的区别。其次，构建了对图像分类器表示空间攻击，这些攻击成功与否与众所周知的数据空间攻击相同，但不能跨模型传输。第三，这些表示空间攻击在语言模型中的功能使其能成功突破攻击模型，但同样不能跨模型传输。第四，通过视觉语言模型与新视觉语言模型之间的数据空间攻击成功跨越，并证明表示空间攻击在视觉语言模型在后投影空间中的几何表示充分对齐时可以传输。这项工作揭示了对抗性转移属性并非所有攻击的固有性质，而是取决于它们的操作领域——共同的数据空间与模型的独特表示空间之间的差异。", "innovation": "论文提出了一个根本的区别，即攻击可以在输入数据空间跨模型传输但无法在模型表示空间之间传输（除非有几何对齐）；在四个不同的设置中为这一区分提供了理论和实验证据；证明了表示空间攻击在特定条件下来自视觉语言模型能够跨模型传输，这为理解对抗性转移提供了关键的洞察，有助于构建更鲁棒的模型。", "conclusion": "对抗性转移是依赖于攻击执行领域的，即取决于它们是在共享的数据空间中还是基于模型的独特表示空间中执行。这一研究揭示了攻击的本质性质，有助于开发更加鲁棒的机器学习模型。"}
{"llm_update_time": "20251006", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.02215", "html_url": "https://arxiv.org/abs/2510.02215", "title": "C2AL: 联合对比辅助学习用于大规模推荐系统", "title_en": "C2AL: Cohort-Contrastive Auxiliary Learning for Large-scale Recommendation Systems", "authors": "Mertcan Cokbas,Ziteng Liu,Zeyi Tao,Elder Veliz,Qin Huang,Ellie Wen,Huayu Li,Qiang Jin,Murat Duman,Benjamin Au,Guy Lebanon,Sagar Chordia,Chengkai Zhang", "background": "现有的大型推荐模型假设用户群体是同质的，并以单一全局目标进行训练。然而，现实世界的数据是由具有不同条件分布的异质群体组成的。随着模型规模和复杂性的增加，以及更多数据用于训练，模型将主要受到中央分布模式的影响，忽略了头部和尾部区域。这种非均衡性限制了模型的学习能力，并可能导致低注意力权重或死神经元。", "innovation": "本文揭示了注意力机制在共享嵌入选择中的关键作用，提出了通过分析数据集中的亚结构并利用有强分布差异的辅助标签来加强基准表示的方法来应对这一挑战。与先前的研究不同，不是通过加权标签或多个任务头来减轻此类偏差，而是利用部分冲突的辅助标签来正则化共享表示。这种方法定制了注意力层的学习过程，以保存与少数群体之间的互信息，同时提高整体性能。", "conclusion": "我们在包含数十亿数据点的大量生产数据集上评估了C2AL方法，共针对六种SOTA模型。实验结果显示，使用新方法的信息因子机能够捕捉到细微的用户-产品交互，总体上降低归一化熵多达0.16%，同时在细分的少数群体上获得超过0.30%的收益。"}
{"llm_update_time": "20251006", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2407.17446", "html_url": "https://arxiv.org/abs/2407.17446", "title": "分数阶签名：受分数微积分启发的签名的推广", "title_en": "Fractional signature: a generalisation of the signature inspired by fractional calculus", "authors": "José Manuel Corcuera,Rubén Jiménez", "background": "本文基于分数微积分提出了一种新的路径签名的推广，旨在描述线性Caputo控制分数微分方程的解。此外，还提出了一种新的更适用于机器学习的签名推广版本。最后，对这种新的签名进行了玩具应用测试，以识别手写数字的问题，在准确率上有明显的提高，相比原有的签名有显著改进。", "innovation": "提出了一种新的路径签名的推广版本，旨在描述线性Caputo控制分数微分方程的解。此外，还提出了一种新的更适用于机器学习的签名推广版本。", "conclusion": "这种新的签名在手写数字识别应用中表现出显著的准确率改进，证明了其在实际问题中的有效性。"}
{"llm_update_time": "20251006", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2302.08854", "html_url": "https://arxiv.org/abs/2302.08854", "title": "强化学习后推断", "title_en": "Post Reinforcement Learning Inference", "authors": "Vasilis Syrgkanis,Ruohan Zhan", "background": "本文研究了使用强化学习（RL）算法收集的数据进行估计和推理的方法。这些算法通过多次与个体单元交互以自适应地实验，并根据以往的结果更新其策略。研究目标是在数据收集后评估潜在的政策，并估计结构参数，如动态治疗效果，这些参数有助于归因并量化早期行动对最终结果的影响。这些参数通常可以定义为矩方程的解，激励了适用于静态数据的矩方法。然而，在RL环境中，数据通常是在非平稳行为策略下以自适应方式收集的。因此，标准估计器由于时间变异的方差无法实现渐近正态性。", "innovation": "本文提出了一种加权广义矩方法（GMM）方法，使用自适应权重来稳定这一变异。文章详细描述了确保加权GMM估计量一致性和渐近正态性的加权方案，从而实现有效的假设检验和统一置信区间的构造。关键应用包括动态治疗效应估计和动态离策评估。", "conclusion": "本文通过在渐近正态性较差的自适应数据收集环境中使用加权GMM方法，为评价和估计提供了新的途径，尤其是在处理动态治疗效应和离策评估方面。这种方法不仅能稳定估计的变异性，还能支持有效的统计推断。"}
{"llm_update_time": "20251006", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2410.16106", "html_url": "https://arxiv.org/abs/2410.16106", "title": "基于线性函数逼近的时序差分学习统计推断", "title_en": "Statistical Inference for Temporal Difference Learning with Linear Function Approximation", "authors": "Weichen Wu,Gen Li,Yuting Wei,Alessandro Rinaldo", "background": "本文研究了在强化学习中广泛使用的时序差分（TD）学习算法，特别是当使用Polyak-Ruppert平均处理独立样本时，该算法在估计价值函数最优线性逼近的参数方面的统计属性。背景是提供更准确的概率收敛保证，并进一步提升当前的理论成果。", "innovation": "1. 提出了更精确的高概率收敛保证，这些保证依赖于渐近方差，并且在比现有文献更弱的条件下成立；\n2. 建立了在凸集类上的精密高维Berry-Esseen界限，实现了比已知最佳结果更快的速度；\n3. 推出了一个新颖的、计算高效的在线插值估计渐近协方差矩阵的方法。这些创新成果使得可以构造值得信赖的概率样本覆盖的线性参数置信区域和同时置信区间。", "conclusion": "通过数值实验展示了理论成果的应用性，阐释了能够基于线性价值函数逼近参数构建置信区域和同时置信区间的可能性。"}
{"llm_update_time": "20251006", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2503.04697", "html_url": "https://arxiv.org/abs/2503.04697", "title": "L1: 使用强化学习控制推理模型思考时长", "title_en": "L1: Controlling How Long A Reasoning Model Thinks With Reinforcement Learning", "authors": "Pranjal Aggarwal,Sean Welleck", "background": "现有语言模型在测试时通过生成更长的思维链来提高表现，但这并非可控。通常，模型生成的思维链长度无法调整，影响了对计算时间和准确性之间的细粒度分配。", "innovation": "提出了一种名为Length Controlled Policy Optimization (LCPO)的简单强化学习方法，用于优化准确性和遵守用户指定的长度约束。该方法用于训练L1模型，使其在给定提示长度约束的情况下生成输出。此外，还发现使用LCPO训练出的模型具备与较长推理模型相似的推理模式，但可以生成与非推理模型相近长度的思维链，表现出显著的性能提升。", "conclusion": "LCPO能够精准控制推理模型的思考时长，实现测试时计算资源和准确性的细粒度分配。L1模型在同等思维链长度下的性能超过S1等现有方法，并且公开了相关代码和模型。"}
{"llm_update_time": "20251006", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2406.16151", "html_url": "https://arxiv.org/abs/2406.16151", "title": "通过因果分离改进蒙特卡洛规划以适用于结构分解马尔可夫决策过程", "title_en": "Improved Monte Carlo Planning via Causal Disentanglement for Structurally-Decomposed Markov Decision Processes", "authors": "Larkin Liu,Shiqi Liu,Yinruo Hua,Matej Jusup", "background": "马尔可夫决策过程（MDPs）作为一种通用框架，通常忽视了在转移和奖励动态中融入因果结构的优势。对于一类资源分配问题，提出了一种结构分解马尔可夫决策过程（SD-MDP），该方法利用因果分离将MDP的时间因果图分解为独立部件。通过利用这种分离，SD-MDP能够实现维数降低和最优价值函数估计的计算效率提升。", "innovation": "将顺序优化问题转换为复杂度为$O(T \text{ log } T)$的对数线性复杂度的分数背包问题，显示出其优于传统随机规划方法（这些方法的复杂度与时间窗口T成多项式关系）。SD-MDP的计算优势与其状态-动作空间大小无关，使其在高维空间中适用。此外，我们的方法无缝地与蒙特卡洛树搜寻（MCTS）结合使用，在受限的模拟预算下实现更高的预期收益，并提供消失的简单遗憾边界。实证结果表明，与各种物流和金融领域的基准相比，SD-MDP在策略性能上具有优越性。", "conclusion": "SD-MDP通过利用因果分离的优势，能够在资源分配问题中实现高效的计算和策略优化，并且其在高维问题和有限预算下的性能表现出色。"}
{"llm_update_time": "20251006", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2502.20215", "html_url": "https://arxiv.org/abs/2502.20215", "title": "Topological Autoencoders++: 快速且准确的环感知降维", "title_en": "Topological Autoencoders++: Fast and Accurate Cycle-Aware Dimensionality Reduction", "authors": "Mattéo Clémot,Julie Digne,Julien Tierny", "background": "当前在高维数据可视化领域，需要一种能够捕捉循环模式的方法，而传统的降维方法可能无法精确地显示这些循环模式。Topological Autoencoders (TopoAE) 提出了一种基于拓扑结构的自编码器方法，尽管取得了进展，但它在处理高维持久同调时存在局限性，特别是在扩展到更高维度时表现不佳。这促使研究者开发新的方法来改进这一过程。", "innovation": "文章提出了一种新的拓扑感知降维方法 TopoAE++，它在 TopoAE 的基础上进行改进，特别在处理 1 维持久同调（PH$^1$）时表现更佳。TopoAE++ 引入了新的 Penalty 项 —— 递减失真（cascade distortion），该项鼓励两个填补持久 1-环的 2-链进行等距嵌入，从而更真实地重建一环在平面上的几何结构。此外，文章还提出了一个用于 Rips 过滤精度计算的快速算法，提高了运行效率。总的来说，该方法在保持拓扑准确性的同时，还能在低维空间中更好地维持循环的可视化。", "conclusion": "该方法通过理论上分析 TopoAE 的损失函数，以及通过引入 TopoAE++ 和新的递减失真罚项，解决了传统方法在处理更高维度和环感知可视化方面的挑战。实验结果表明，该方法在准确性和可视化方面都优于现有方法，特别在处理高维数据的循环模式时表现出更高的性能。该研究成果为高维数据的循环模式可视化提供了一个新的解决方案。"}
{"llm_update_time": "20251006", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2412.05788", "html_url": "https://arxiv.org/abs/2412.05788", "title": "通过序列蒙特卡洛进行零样本蛋白质motif结构搭建的扩散后验采样", "title_en": "On diffusion posterior sampling via sequential Monte Carlo for zero-shot scaffolding of protein motifs", "authors": "James Matthew Young,O. Deniz Akyildiz", "background": "随着扩散模型的发展，可以以前所未有的速度生成新蛋白质。motif支架问题需要引导生成过程，使其生成具有特定功能子结构（motif）的蛋白质。已有模型能以motif作为条件输入进行训练，但使用扩散后验采样（尤其是零样本替代方法）存在改进空间，可以通过串行蒙特卡洛（SMC）算法进行校正。基于上述背景，本文介绍了新的引导势函数，并使用Genie无条件模型作为先验与SMC辅助的扩散后验采样器进行适应性的结合，以解决单motif和多motif问题，并针对点对称约束生成设计可控的内部对称单体。", "innovation": "引入了新的引导势函数（proposed potentials），并开发了一种使用Genie无条件模型作为先验的序列蒙特卡洛辅助的扩散后验采样器的方法。该方法在单motif问题上展示了与传统掩码方法相当甚至更好的表现，特别是重建指导下的采样器更优于替换方法，且倾斜测量和扭曲目标显著提升了性能。此外，作者使用该方法成功地解决了两个多motif问题，并能够生成满足点对称约束的设计可控的内部对称单体。", "conclusion": "在单motif和多motif问题上，所提出的方法表现良好，尤其是适合重建指导下的采样器，同时倾斜测量和扭曲目标显著提高了性能。此外，通过SMC辅助的扩散后验采样方法，能够生成符合特定对称性要求的设计可控的内部对称单体。"}
{"llm_update_time": "20251006", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2412.07192", "html_url": "https://arxiv.org/abs/2412.07192", "title": "PrisonBreak: 使用至多二十五个目标位翻转破解大型语言模型", "title_en": "PrisonBreak: Jailbreaking Large Language Models with at Most Twenty-Five Targeted Bit-flips", "authors": "Zachary Coalson,Jeonghyun Woo,Chris S. Lin,Joyce Qu,Yu Sun,Shiyang Chen,Lishan Yang,Gururaj Saileshwar,Prashant Nair,Bo Fang,Sanghyun Hong", "background": "本文研究了一种商业规模的安全对齐大型语言模型（LLMs）的新漏洞，即它们产生有害响应的能力可以通过翻转少量的模型参数位来被破解。这项研究关注的是利用极少量的位翻转变量的方法来突破大语言模型的安全限制，如安全对齐，尽管之前已有针对小型计算机视觉模型的攻击方法，但本文的攻击方法只需要翻转5到25个位，所需位翻转次数是前者的四十分之一。", "innovation": "本文的主要创新在于提出了一种高效的位选择算法，该算法能够比之前的方法快20倍的速度识别出关键位，用于语言模型的破解。此外，攻击方法可以直接在模型运行时解封模型，无需输入级别的修改。这种攻击方法在不牺牲模型的主要功能的情况下，实现了80-98%的攻击成功率。其次，本文还通过基于Rowhammer的方法演示了端对端的攻击，成功破解了5个模型，并且进一步分析展示了模型的某些组件，如价值投影层，更容易被破解。", "conclusion": "通过分析本文中提出的攻击方法以及实验结果可以看出：1、具有较弱后训练对齐的模型需要更少的位翻转就能被破解；2、某些模型组件，比如价值投影层，更容易被破解；3、本文提出的攻击方法在机制上与现有的方法不同。尽管存在潜在的防御措施，但本文的攻击方法仍然对语言模型管道中新出现的防御措施有效。"}
{"llm_update_time": "20251006", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2505.08277", "html_url": "https://arxiv.org/abs/2505.08277", "title": "迭代重新加权核机高效学习稀疏函数", "title_en": "Iteratively reweighted kernel machines efficiently learn sparse functions", "authors": "Libin Zhu,Damek Davis,Dmitriy Drusvyatskiy,Maryam Fazel", "background": "神经网络在实际应用中表现出色，通常被认为是能够从数据中直接学习到低维数据表示和分层结构的能力。本文认为，这种能力并不局限于神经网络，也可以从经典的核方法中获得。传统核方法中，核预测函数的导数可以检测有影响力的坐标，而且利用导数迭代重新加权数据并重新训练核机器，能够高效地学习具有有限跃变复杂性的分层次多项式。", "innovation": "本文创新地展示了如何利用核预测函数的导数及其迭代重新加权方法来高效学习稀疏函数。这种方法能够识别和提取重要的数据特征，并不需要大量的样本，可以有效减少数据的维度，同时保留重要的结构信息。这种方法为传统核方法赋予了新的生命力，展示了其解决复杂学习任务的能力。", "conclusion": "理论分析和数值实验验证了迭代重新加权核机的有效性，能够高效地学习稀疏函数，并且能够在样本复杂性较低的情况下识别出影响坐标，从而学习具有有限跃变复杂性的分层次多项式。"}
{"llm_update_time": "20251006", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2503.19142", "html_url": "https://arxiv.org/abs/2503.19142", "title": "有害的激活函数：通过受控通道恢复神经网络权重", "title_en": "Activation Functions Considered Harmful: Recovering Neural Network Weights through Controlled Channels", "authors": "Jesse Spielman,David Oswald,Mark Ryan,Jo Van Bulck", "background": "随着高风险的机器学习应用逐渐转移到不受信任的最终用户或云环境中，保护预训练模型参数变得至关重要，以保护知识产权和用户隐私。最近基于硬件隔离的防护措施（例如Intel SGX）有一定的潜力，即使在有被控制的操作系统的环境中也能确保机器学习应用的内部状态。不幸的是，研究者发现权限软件对手可以通过利用常见神经网络激活函数中的输入相关性内存访问模式来从SGX护城河中提取密钥权重和偏置。", "innovation": "该研究表明了一种新颖的攻击方法，名为SGX-Step框架，用于获取无噪声、指令级的页面访问跟踪。通过在使用Tensorflow Microlite库的11输入回归网络中进行案例研究，证明了可以完全恢复第一层的所有权重和偏置，并在特定条件下，可以部分恢复深层参数。该研究改进了先前的模型窃取攻击，只需每次每个权重20次查询即可，平均绝对误差小于1%。同时，分析表明许多流行的机器学习框架广泛使用带有输入相关性内存访问模式的激活函数，这揭示了在SGX护城河中部署保密模型的局限性。", "conclusion": "研究结果强调了在SGX护城河中部署实施机器学习模型的安全验证的必要性，类似于对安全密码库进行审查的工作。"}
{"llm_update_time": "20251006", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2504.21700", "html_url": "https://arxiv.org/abs/2504.21700", "title": "XBreaking: 可解释的人工智能在破解大型语言模型限制方面的应用", "title_en": "XBreaking: Explainable Artificial Intelligence for Jailbreaking LLMs", "authors": "Marco Arazzi,Vignesh Kumar Kembu,Antonino Nocera,Vinod P", "background": "大型语言模型在现代由人工智能主导的IT领域中占据重要地位。然而，与这些模型相关的安全威胁可能会阻碍它们在关键应用场景（如政府组织和医疗机构）中的可靠部署。因此，商业化的大型语言模型通常会经过复杂的过滤机制来消除它们可能产生的任何有害输出。这一背景下，模型破解（jailbreaking）成为一种严重的威胁，并且已有许多先前的方法在不同领域证明了其有效性。现有的破解提议大多采用生成和测试的策略来制作恶意输入。为提高对过滤机制的理解并将该理解用于定向的破解攻击，文中提出了一种可解释的人工智能解决方案，该方案通过比较分析过滤和非过滤模型的行为来推导出独特的可利用匹配模式。然后，文中提出了XBreaking，一种新的破解攻击，通过定向噪音注入来利用这些独特的模式破坏大型语言模型的安全限制。", "innovation": "文中提出了XBreaking，一种新的破解攻击方法，这种攻击方法利用一种可解释的人工智能策略，通过分析过滤和非过滤模型的行为模式，推导出独特的可利用匹配模式，然后通过定向噪音注入破坏大型语言模型的安全限制。", "conclusion": "通过详尽的实验活动，文章获得了关于过滤机制的重要见解，并证明了其攻击的有效性和性能。"}
{"llm_update_time": "20251006", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2505.15962", "html_url": "https://arxiv.org/abs/2505.15962", "title": "使用内部和外部知识预训练有限记忆语言模型", "title_en": "Pre-training Limited Memory Language Models with Internal and External Knowledge", "authors": "Linxi Zhao,Sofian Zalouk,Christian K. Belardi,Justin Lovelace,Jin Peng Zhou,Ryan Thomas Noonan,Dongyoung Go,Kilian Q. Weinberger,Yoav Artzi,Jennifer J. Sun", "background": "神经语言模型是黑箱——它们的语言模式和事实知识分布在数十亿个不透明参数中。这种交织编码使得难以可靠地检查、验证或更新特定事实。现有的语言模型主要依赖于模型权重的记忆来处理事实知识。", "innovation": "引入了有限记忆语言模型（LMLM），在预训练过程中，将事实知识外部化到外部数据库中，而不是依赖于模型权重的记忆。在训练过程中，模型更容易进行有针对性的查找操作。实验表明，有限记忆语言模型在标准基准测试上的性能与大得多的模型相当，同时能够提供显式的、可编辑和可验证的知识库。", "conclusion": "有限记忆语言模型能够在保持高性能的同时，提供一种依赖外部数据库来处理知识的方法，从而简化了模型管理和更新的过程。"}
{"llm_update_time": "20251006", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2505.22811", "html_url": "https://arxiv.org/abs/2505.22811", "title": "采用多布尔架构的高效且有效的大型语言模型", "title_en": "Highly Efficient and Effective LLMs with Multi-Boolean Architectures", "authors": "Ba-Hien Tran,Van Minh Nguyen", "background": "权重二值化已成为减少大型语言模型（LLMs）复杂性的有前途的策略。现有方法主要分为训练后二值化和训练有意识的方法。训练后二值化简单但会导致严重的性能损失，而训练有意识的方法依赖于全精度的潜在权重，从而增加复杂性和限制效率。", "innovation": "本文提出了一种新型的框架，使用多核布尔参数表示LLMs，并首次在布尔域直接微调LLMs，消除了对潜在权重的需要。这种方法增强了表示能力，在微调和推理过程中大大降低了复杂性。", "conclusion": "在多种LLMs上的广泛实验表明，该方法优于近期的超低位量化和二值化技术。"}
{"llm_update_time": "20251006", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2404.09113", "html_url": "https://arxiv.org/abs/2404.09113", "title": "通过熵正则化扩展平均场变分推断：理论与计算", "title_en": "Extending Mean-Field Variational Inference via Entropic Regularization: Theory and Computation", "authors": "Bohan Wu,David Blei", "background": "变分推断(VI)成为了用于高维贝叶斯模型近似推理的一种流行方法。现有的VI方法如朴素的平均场方法具有一定的局限性，而本文提出的$\boldsymbol{\boldsymbol{\text{Xi}}}$-VI方法通过引入熵正则化扩展了平均场方法，与最优散射问题紧密相关，并利用了计算效率高的Sinkhorn算法。", "innovation": "引入熵正则化的$\boldsymbol{\boldsymbol{\text{Xi}}}$-VI方法，该方法有效地恢复了真实的后验依赖性，依赖性被正则化参数削弱。证明了$\boldsymbol{\boldsymbol{\text{Xi}}}$-VI方法在参数空间维度上的统计计算权衡关系，并研究了该方法的频率主义性质，包括一致性、渐近正态性和高维渐近性质以及算法稳定性。", "conclusion": "提供了使用$\boldsymbol{\boldsymbol{\text{Xi}}}$-VI方法实现多项式时间近似推理的充分条件，并在模拟和实际数据中展示了$\boldsymbol{\boldsymbol{\text{Xi}}}$-VI方法相比平均场变分推理的实践优势。"}
{"llm_update_time": "20251006", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.19886", "html_url": "https://arxiv.org/abs/2506.19886", "title": "以模型反转攻击为背景的辅助任务导向语义通信", "title_en": "Diffusion-aided Task-oriented Semantic Communications with Model Inversion Attack", "authors": "Xuesong Wang,Mo Li,Xingyan Shi,Zhaoqian Liu,Shenghao Yang", "background": "语义通信通过传输语义信息而不是原始输入符号序列来提升传输效率。任务导向的语义通信旨在保留任务特定信息，从而达到更高的带宽节省。然而，基于神经网络的通信系统容易遭受模型反转攻击，其中对手试图从截获的数据中推断敏感输入信息。关键挑战在于如何在确保传输正确性和鲁棒性的同时保护隐私。", "innovation": "鉴于先前研究通常假设对手在任务导向场景下试图完全重构原始输入，而低像素级别的评估指标（如PSNR或SSIM）仍可满足对手完成下游任务，作者认为对手任务准确性是评估攻击有效性的更合适度量。为此，提出了一种名为DiffSem的基于扩散的辅助框架，该框架在发射端采用自噪音机制以自适应调节语义内容并补偿信道噪音，在接收端采用增强U-Net以提高任务性能，并可选地增强自参照标签嵌入。", "conclusion": "实验表明，DiffSem使合法接收端的准确性更高，验证了所提框架的优越性能。"}
{"llm_update_time": "20251006", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2504.06316", "html_url": "https://arxiv.org/abs/2504.06316", "title": "DeepGDel：用于基因规模代谢模型生长相关生产中基于深度学习的基因删除预测框架", "title_en": "DeepGDel: Deep Learning-based Gene Deletion Prediction Framework for Growth-Coupled Production in Genome-Scale Metabolic Models", "authors": "Ziwei Yang,Takeyuki Tamura", "background": "在基因规模约束代谢模型中，基因删除策略对于同时实现细胞生长和目标代谢产物生产至关重要。虽然已经广泛研究了计算方法来计算基因删除，并且这些方法有助于开发基因删除策略数据库，但目前的方法在利用如机器学习等新型数据驱动范式方面存在局限性，以更高效地设计菌株。因此，有必要提出一个基本框架来实现这一目标。本研究首先制定了基因删除策略预测问题，然后提出了一种用于基因规模代谢模型中的生长相关生产预测基因删除策略的框架。该框架利用深度学习算法学习并整合序列基因和代谢物的数据表示，从而使自动基因删除策略预测成为可能。计算实验结果表明，该提出的框架可行，相比基线方法显示出显著的改进。具体的，该框架在三种不同规模的代谢模型中实现了整体准确性的14.69%、22.52%和13.03%的提升，同时在预测基因删除状态方面保持了高标准的精确度和召回率。所提供的框架的源代码和示例可以在该网址访问：", "innovation": "提出了一个利用深度学习算法来自动预测基因删除策略的框架，该框架能在序列基因和代谢物数据表示中进行学习和整合，从而提高了对基因删除策略预测的效率和准确性。相比基线方法，该提出的框架显示了显著的提升，例如，在三种不同规模的代谢模型中实验结果显示其整体准确率分别增加了14.69%、22.52%和13.03%。", "conclusion": "该研究提出了一种基于深度学习的基因删除预测框架，通过优化基因删除策略实现高效的菌株设计。该框架在多种代谢模型上展示了相对于传统方法的显著提升，是菌株设计领域的创新贡献。"}
{"llm_update_time": "20251006", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2505.13189", "html_url": "https://arxiv.org/abs/2505.13189", "title": "随机场的马氏-伽马微积分方法在分数贝叶斯扩散生成模型中的应用", "title_en": "A Malliavin-Gamma calculus approach to Score Based Diffusion Generative models for random fields", "authors": "Giacomo Greco", "background": "本文采用伽马和马氏微积分的观点，将分数贝叶斯扩散生成模型（SGMs）推广到无限维抽象希尔伯特空间。前人工作通常在有限维空间中讨论SGMs，但在实际应用中，很多问题涉及到无限维的空间，如随机场。本文的目标是提供一种方法，将SGMs推广到无限维空间，并进一步研究在这个无限维空间中，数据分布的 Fisher 信息中所起作用的 Cameron-Martin 规范。", "innovation": "本文的主要创新在于：1) 通过 Dirichlet 形式和柯尔莫哥洛夫-马丁空间以及 Wiener 疏散，定义了前向噪声过程；2) 通过抽象的时间反转公式，表明评分函数是马氏导数，并且它对应于条件期望；3) 将现有的有限维熵收敛界扩展到希尔伯特空间环境中，并强调了 Cameron-Martin 规范在数据分布 Fisher 信息中的角色；4) 最后，将讨论具体应用到球形随机场中，将噪声源视为 Whittle-Matérn 球形随机场。", "conclusion": "本文成功地将 SGMs 从有限维空间推广到无限维的抽象希尔伯特空间，并通过进一步的理论分析，揭示了无限维环境中数据分布中的重要特性。这种推广不仅扩展了 SGMs 的适用范围，也为处理更复杂和实际的问题提供了可能的方法。"}
{"llm_update_time": "20251006", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2505.05168", "html_url": "https://arxiv.org/abs/2505.05168", "title": "在流形中动力学局部 Fréchet 曲线回归", "title_en": "Dynamical local Fréchet curve regression in manifolds", "authors": "M.D. Ruiz-Medina,A. Torres-Signes", "background": "该文解决了时间相关双变量曲线数据在流形上 Frechet 条件均值的局部线性近似问题。通过对先前研究 (Torres 等人, 2025 年) 关于流形上全局 Frechet 函数回归的研究进行补充，介绍了两种类型的局部线性 Fréchet 函数回归预测器的构建方法。其中包括外在局部线性 Fréchet 函数回归预测器和内在局部线性 Fréchet 函数回归预测器。外在局部线性预测器在时间变化的切线空间中获得并通过射影以及正交规范化的特征函数基得到。内在局部线性预测器则通过加权 Fréchet 均值方法计算。研究还证明了内在局部近似的渐进最优性，并通过模拟研究显示了预测器在有限样本容量下的性能。此外，研究使用 NASA 的 MAGSAT 卫星的地球磁场预测问题为实际应用案例，展示了两种预测器的效用。", "innovation": "该文提供了两种类型的局部线性 Fréchet 函数回归预测器，一种是外在的，另一种是内在的。外在预测器通过投影到特征空间，而在内在预测器中则采用加权 Fréchet 均值方法。此外，研究证明了内在局部近似的效果，并通过实际数据应用展示了方法的有效性。", "conclusion": "本文通过理论分析和数值模拟证明了两种类型的局部线性 Fréchet 函数回归预测器的有效性和适用性，并通过 NASA 的 MAGSAT 卫星数据成功预测了地球磁场的变化。该研究为时间相关双变量曲线数据在流形上的回归问题提供了新的解决方案。"}
{"llm_update_time": "20251006", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2503.02075", "html_url": "https://arxiv.org/abs/2503.02075", "title": "使用强化学习进行镜头系统的主动对准", "title_en": "Active Alignments of Lens Systems with Reinforcement Learning", "authors": "Matthias Burkhardt,Tobias Schmähling,Pascal Stegmann,Michael Layh,Tobias Windisch", "background": "在相机制造中，将镜头系统对准图像传感器是一个关键挑战。在理想条件下，最优对准可以通过数学计算得出，但在现实中，由于制造公差造成的偏差使这种做法变得不切实际。测量这些公差既昂贵又不可行，忽视它们可能导致对准欠佳。", "innovation": "我们提出了一种仅在传感器输出像素空间中进行学习的强化学习方法，消除了需要设计专家级对准概念的需求。我们进行了广泛的基准测试，并展示了我们的方法在速度、精度和鲁棒性方面都超越了其他方法。此外，我们引入了relign，这是一种基于物理渲染的真实、可自由探索的开源模拟器，用于建模具有非确定性制造公差和机器人定位噪声的光学系统。它还提供了一个与流行的机器学习框架兼容的接口，便于实验和开发。", "conclusion": "我们的工作突显了在制造环境中使用强化学习以提高光学对准效率并减少人工干预的需求。"}
{"llm_update_time": "20251006", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2502.18525", "html_url": "https://arxiv.org/abs/2502.18525", "title": "编程像素：计算机使用代理能够进行软件工程吗？", "title_en": "Programming with Pixels: Can Computer-Use Agents do Software Engineering?", "authors": "Pranjal Aggarwal,Sean Welleck", "background": "当前，计算机使用代理(CUAs)能够在多种一般任务中发挥重要作用，但是大部分评估主要集中在简单场景中。关于这类通用代理是否能够自动化更加复杂的特殊工作，例如软件工程(SWE)，仍然不清楚。为了对此问题进行调查，引入了Programming with Pixels (PwP)，一种全面的软件工程计算使用环境，这里，代理通过视觉控制IDE来执行多样化软件工程任务。", "innovation": "研究引入了PwP-Bench，一个涵盖多种模式、编程语言和技能的15项现有和新软件工程任务基准。此外，评估了最先进的开箱即用型和闭箱型CUAs在纯视觉交互条件下的表现明显逊于专业编程代理，但在直接访问文件编辑和bash操作API后，CUAs的表现显著提升，并能达到专业代理的水平，特别是当提供额外IDE工具的文本API访问时，所有模型都有进一步的提升。研究表明，CUAs的主要不足在于视觉接地有限和无法充分利用丰富环境。", "conclusion": "当前CUAs的不足主要在于视觉接地有限和无法充分利用丰富环境。这些结果表明，软件工程是一个自然的基准领域，以验证通用计算机使用代理在复杂任务上是否能够达到专家级别的性能。相关代码和数据可以在指定的URL找到。"}
{"llm_update_time": "20251006", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.07649", "html_url": "https://arxiv.org/abs/2508.07649", "title": "多层时空过渡图解耦表示学习及其在社交增强POI推荐中的应用", "title_en": "Disentangling Multiplex Spatial-Temporal Transition Graph Representation Learning for Socially Enhanced POI Recommendation", "authors": "Jie Li,Haoye Dong,Zhengyang Wu,Zetao Zheng,Mingrong Lin", "background": "POI推荐是商业智能研究的一个热点问题，地理位置和时间上的过渡以及社交关系是关键因素。然而，现有研究主要分别建模地理位置和时间上的过渡，导致相同的地理位置和时间上的关键节点在表示上不一致。这种不一致在融合过程中引入了冗余信息，增加了模型的不确定性，降低了可解释性。", "innovation": "提出了一种名为DiMuST的社会增强POI推荐模型，该模型基于多层时空过渡图的解耦表示学习。该模型使用了新颖的解耦变分多层图自编码器（DAE），该自编码器首先使用多层时空图策略解耦共同分布和私有分布，然后通过专家的乘积机制融合共同特征，并通过对比约束去噪私有特征。该模型能够有效捕捉POI的时空过渡表示，同时保留其时空关系的内在联系。", "conclusion": "在两个具有挑战性的数据集上的实验结果表明，我们的DiMuST在多个指标上显著优于现有方法。"}
{"llm_update_time": "20251006", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2505.22860", "html_url": "https://arxiv.org/abs/2505.22860", "title": "Permissioned LLMs: 强化大型语言模型中的访问控制", "title_en": "Permissioned LLMs: Enforcing Access Control in Large Language Models", "authors": "Bargav Jayaraman,Virendra J. Marathe,Hamid Mozaffari,William F. Shen,Krishnaram Kenthapadi", "background": "在企业环境中，组织数据被分割和隔离，并受到复杂的访问控制体系的保护。当使用针对孤立数据进行微调的语言模型(LLM)为不同访问权限的个体提供下游任务请求时，这些访问控制体系可能会完全失效。这种背景下的挑战在于需要一种方法来确保在查询响应中正确实施访问控制，但当前的方法未能充分解决这一问题。因此，作者提出了Permissioned LLMs (PermLLM)，这是在查询响应中叠加组织数据访问控制机制的一种新型LLM类别。", "innovation": "本文提出了一种名为Permissioned LLMs的新类语言模型(PermLLM)。它们能够在查询响应中叠加组织数据的访问控制机制。作者还引入了一种形式化的方法来验证访问控制是否在LLM查询响应中正确执行，包括了一个称为“相关响应”的概念，以及一种称为“访问优势”的新型度量标准，用于实证评估PermLLM机制的有效性。此外，还提出了三种基于参数高效微调的新型PermLLM机制，并开发了两个评估访问优势的新指标，即域区分指数（DDI）和利用差距指数（UGI），并通过广泛实验在五大数据集上验证了这些方法和指标的有效性。", "conclusion": "本文通过引入名为Permissioned LLMs的新类LLM机制（PermLLM）、相关响应、访问优势的概念以及基于参数高效微调的三个全新机制，强调了在大型语言模型中实现正确的访问控制的重要性。同时，通过实验展示了这些机制和验证指标的有效性，为现有大型语言模型中的访问控制提供了解决方案。"}
{"llm_update_time": "20251006", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.24932", "html_url": "https://arxiv.org/abs/2509.24932", "title": "图论邂逅卫星星座上的联邦学习：生成聚合、网络构建与性能优化", "title_en": "Graph Theory Meets Federated Learning over Satellite Constellations: Spanning Aggregations, Network Formation, and Performance Optimization", "authors": "Fardis Nadimi,Payam Abdisarabshali,Jacob Chakareski,Nicholas Mastronarde,Seyyedali Hosseinalipour", "background": "论文讨论了为低地球轨道卫星星座设计的一种新颖的联邦/分布式学习框架Fed-Span。面对动态卫星网络中的关键挑战，如间歇性卫星连接、卫星的异质计算能力和数据集随时间变化的问题。Fed-Span利用最小生成树（MST）和最小生成森林（MSF）拓扑来引入分布学习中的生成模型聚合和调度过程。", "innovation": "Fed-Span论文的创新之处在于通过连续约束表达式（CCRs）重新定义MST/MSF拓扑，从而将图论抽象化为用于卫星网络的可优化框架。在此基础上，作者计算了Fed-Span中的操作能耗和延迟，并推导了新的收敛界限，最终提出了一个结合模型预测损失、能耗和延迟最小化的综合优化问题，该问题已被证明是NP难的，但通过连续凸优化进行了系统转换和解决。", "conclusion": "通过实际数据集的评估，Fed-Span方法在模型收敛速度、能源效率和延迟方面优于现有方法，证明了其作为卫星网络中高效分布式学习的新解决方案的有效性。"}
{"llm_update_time": "20251006", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.03674", "html_url": "https://arxiv.org/abs/2508.03674", "title": "Morphlux: 转化Torus架构以实现高效的多租户机器学习", "title_en": "Morphlux: Transforming Torus Fabrics for Efficient Multi-tenant ML", "authors": "Abhishek Vijaya Kumar,Eric Ding,Arjun Devraj,Darius Bunandar,Rachee Singh", "background": "为了提高服务器内部加速器之间的连接效率，研究人员开发了一种名为Morphlux的可编程光子网络。这种网络能够增强基于Torus架构的现代数据中心，以优化多租户机器学习的性能。通过这种新的连接技术，可以大幅提高带宽、减少计算碎片并降低芯片故障的影响范围，同时能保证在硬件测试平台上快速替换故障的加速器芯片，从而实现高效的机器学习模型训练。这种创新架构为提升数据中心内的计算资源利用效率和处理容量提供了新的解决方案。", "innovation": "Morphlux是一种全新的服务器级可编程光子网络，它能够替代或增强现有的基于Torus架构的数据中心。通过Morphlux，可以实现66%的带宽提升，70%的计算碎片减少，并且能够迅速（1.2秒内）替换故障的加速器芯片。这项技术通过高度灵活的硬件原型验证了其性能优势，提高了1.72倍的训练吞吐量。Morphlux代表了数据中心网络的一个全新方向，在提高机器学习和大数据处理的效率方面具有巨大潜力。", "conclusion": "通过Morphlux技术，数据中心能够在服务器规模上实现高效的计算资源管理和加速器的快速替换，显著改善了多租户环境下的机器学习应用性能。其成功开发和应用展示了在高度创新的多租户计算模型中实现高性能和高效能的新途径。"}
{"llm_update_time": "20251006", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.25783", "html_url": "https://arxiv.org/abs/2509.25783", "title": "深矩阵分解中极小值的锐度：精确表达式", "title_en": "Sharpness of Minima in Deep Matrix Factorization: Exact Expressions", "authors": "Anil Kamber,Rahul Parhi", "background": "理解损失景观在极小值附近的几何结构是解释基于梯度的方法在非凸优化问题（如深度神经网络训练和深度矩阵分解）中的隐式偏差的关键。衡量这一几何结构的核心量是Hessian矩阵的最大特征值，它度量了损失的锐度。但是目前，这一锐度的确切作用并不清楚，因为在一般情况下没有精确表达式。", "innovation": "本文首次给出了通用过度参数化的深度矩阵分解问题（即深度线性神经网络训练）中任意极小值处平方误差损失Hessian矩阵的最大特征值的精确表达式，解决了Mulayoff & Michaeli (2020) 提出的一个悬而未决的问题。并通过实验研究了基于梯度训练过程中在极小值附近的逃逸现象，这一现象的关键依赖于我们精确表达的锐度。", "conclusion": "我们的理论结果对理解非凸优化问题中的隐式偏差具有重要意义，并为未来的研究提供了坚实的基础。"}
{"llm_update_time": "20251006", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.15573", "html_url": "https://arxiv.org/abs/2509.15573", "title": "朝向不变尺度显著目标检测：一种通用的评估和优化方法", "title_en": "Towards Size-invariant Salient Object Detection: A Generic Evaluation and Optimization Approach", "authors": "Shilong Bao,Qianqian Xu,Feiran Li,Boyu Han,Zhiyong Yang,Xiaochun Cao,Qingming Huang", "background": "当前的显著目标检测(SOD)评估标准在面对单一图像内包含多个显著尺寸差异较大的对象时存在内在的尺度敏感问题。现有的SOD评估指标未能公平地反映所有对象的表现，导致评价结果存在偏差，未能充分识别出尺寸较小但语义上更重要的目标，从而影响性能评估的真实性。", "innovation": "本文提出了一个通用的、尺度无偏的评估框架（SIEva）和一个遵循尺度无偏原则的优化框架（SIOpt）。SIEva通过分别评估每个分离的组件然后汇总结果来有效地缓解对象间尺度不平衡的影响。SIOpt不仅能够显著提升各种尺寸的显著目标检测，而且具有模型通用性，能与多种现有的SOD骨干架构无缝集成。此外，文章还提供了对SOD方法的泛化分析，支持新评估框架的有效性，并通过全面实验验证了所提方法的有效性。", "conclusion": "本文提出了一个针对SOD的尺度无偏评估和优化框架，实验结果证明了该框架的有效性。通过这种方式，能够更公正地评估不同尺寸显著目标的检测性能，并提出了新的评估协议对当前的方法进行了理论分析，证明了所提出的尺度无偏框架的有效性和有用性。"}
{"llm_update_time": "20251006", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.12990", "html_url": "https://arxiv.org/abs/2509.12990", "title": "基于两阶段加权MoE的长尾自视点错误检测", "title_en": "Dual-Stage Reweighted MoE for Long-Tailed Egocentric Mistake Detection", "authors": "Boyu Han,Qianqian Xu,Shilong Bao,Zhiyong Yang,Sicong Li,Qingming Huang", "background": "本文报告研究了从自视点视频数据中判断用户是否执行动作错误的问题，面临动作细微且不频繁的细微错误挑战，提出了一个 Dual-Stage Reweighted Mixture-of-Experts (DR-MoE) 框架。在第一阶段使用冻结的 ViViT 模型和 LoRA 调整的 ViViT 模型提取特征，通过特征级专家模块结合，第二阶段训练三个分类器有不同的目标，加权交叉熵缓解类别不平衡问题，AUC损失提高非均匀分布下的排序，带Sharpness-Aware Minimization的标签感知损失增强校准和泛化能力。预测在分类级专家模块中融合。该方法在识别罕见和模糊错误实例方面表现出很强的性能。代码可从提供的链接下载", "innovation": "提出了一个 Dual-Stage Reweighted Mixture-of-Experts (DR-MoE) 框架，通过两个阶段进行特征提取和预测优化。第一阶段结合不同调用状态的 ViViT 模型来增强特征表示，第二阶段通过加权交叉熵、AUC损失和标签感知损失来训练分类器，提高模型在长尾分布下的性能和泛化能力。", "conclusion": "该方法在检测罕见和模糊动作错误方面表现出色，证明了 DR-MoE 框架的有效性和鲁棒性。"}
{"llm_update_time": "20251006", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.25659", "html_url": "https://arxiv.org/abs/2509.25659", "title": "基于YOLO的金属板材缺陷检测", "title_en": "YOLO-Based Defect Detection for Metal Sheets", "authors": "Po-Heng Chou,Chun-Chi Wang,Wei-Lung Mao", "background": "在工业制造中，手动缺陷检测耗时且劳动密集，为此提出了一种基于YOLO的深度学习模型进行自动缺陷检测，以解决这一问题。实验中使用金属板材图像来训练YOLO模型，以检测其表面和孔洞的缺陷，但由于缺乏金属板材图像，检测准确性明显下降。为了解决这个问题，使用了生成模型ConSinGAN生成大量数据，四个版本的YOLO模型（YOLOv3，v4，v7和v9）与ConSinGAN结合用于数据增强。与其它YOLO模型相比，结合了ConSinGAN的YOLOv9模型在准确性和检测速度上更优。此外，该模型被集成到制造硬件和监督控制与数据采集系统中，建立了实用的自动光学检测系统。这种方法也适用于工业制造中的其他组件自动化缺陷检测。", "innovation": "创新在于提出了一种基于YOLO的深度学习模型进行自动缺陷检测，结合ConSinGAN生成大量数据以提高检测准确性，而且该模型被集成到真实工业环境中。", "conclusion": "所提出的YOLOv9模型与ConSinGAN结合使用的自动缺陷检测方法在实际应用中表现优异，具有高准确性和快速检测速度，并已在工业制造环境中得到成功应用。"}
{"llm_update_time": "20251006", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.00186", "html_url": "https://arxiv.org/abs/2510.00186", "title": "Thinkquel：一种用于文本到dbt模型的合成数据和区间感知目标", "title_en": "Thinkquel: A Model Dedicated to Text-to-dbt Using Synthetic Data and a Span-Aware Objective", "authors": "Anni Li,Aria Attar,Paul Dong", "background": "将自然语言请求转化为可靠的、可生产的数据转换仍然具有挑战性。准确性取决于精确的模式链接和特定于仓库的SQL方言，而可用的最强监督——执行成功和结果匹配——仅在序列级别提供。同时，构建大规模的执行验证语料库成本高昂，而基于令牌级别的目标与这些全局信号不一致，导致优化不稳定且可移植性有限。", "innovation": "引入了Thinkquel，一种细调模型，用于生成稳健、可移植且执行验证的数据库查询。方法论在Thinkquel中将TS-SQL合成数据管道与dbt作为可移植的中间表示相结合，利用区间感知强化学习目标，并引入Token-Sequence GRPO（TS-GRPO）来弥合LLMs在微调时基于令牌级别的训练信号与序列级别的执行奖励之间的差距。", "conclusion": "在包含500个例子的TS-SQL测试集上，Thinkquel（32B）通过两次微调课程取得了93.2%的执行成功率和61.8%的结果匹配率，分别比基线模型提高了67.2%（执行）和44.4%（匹配）。在Spider（14B）实验中，TS-GRPO提高了训练稳定性并加快了执行匹配奖励的收敛速度，相对于GRPO和GSPO而言。"}
{"llm_update_time": "20251006", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.00572", "html_url": "https://arxiv.org/abs/2510.00572", "title": "入侵X：具有松鼠搜索优化的混合卷积-LSTM深度学习网络入侵检测框架", "title_en": "IntrusionX: A Hybrid Convolutional-LSTM Deep Learning Framework with Squirrel Search Optimization for Network Intrusion Detection", "authors": "Ahsan Farabi,Muhaiminul Rashid Shad,Israt Khandaker", "background": "入侵检测系统（IDS）面临着持续的挑战，包括不断演变的网络攻击、高维的网络流量数据以及基准数据集（如NSL-KDD）中严重的类别不平衡问题。这些因素使得传统的IDS难以有效地检测和分类网络中的入侵行为。", "innovation": "提出了名为IntrusionX的混合深度学习框架，该框架结合了卷积神经网络（CNN）用于局部特征提取和长短期记忆网络（LSTM）用于时间建模，进一步通过松鼠搜索算法（SSA）进行架构优化，实现了高效超参数调整同时保持计算效率。框架还结合了严格的预处理、分层数据分割和动态类别加权，以增强对少数类的检测。", "conclusion": "在NSL-KDD数据集上的实验表明，IntrusionX在二分类中达到了98%的准确率，在五分类中达到了87%的准确率，并且在少数类别召回率上显示出显著改善（U2R：71%，R2L：93%）。IntrusionX的创新之处在于其可再现且对不平衡类别的敏感设计，并结合了元启发式优化。"}
{"llm_update_time": "20251006", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.00476", "html_url": "https://arxiv.org/abs/2510.00476", "title": "分析代码语言模型中的隐含概念", "title_en": "Analyzing Latent Concepts in Code Language Models", "authors": "Arushi Sharma,Vedant Pungliya,Christopher J. Quinn,Ali Jannesari", "background": "对于依赖信任、透明度和语义稳健性的应用程序而言，理解大型语言模型内部处理代码的行为仍然是一个关键的挑战。现有的技术需要我们能够透明地理解模型行为，以便发现模型中的隐含交互，并辨识出语义上的偏差和趋势。本文正是为了满足这一需求而撰写的。", "innovation": "本文提出了一种名为CoCoA的全局后验可解释性框架，通过将上下文化的词嵌入聚类为人可理解的概念组来揭示代码语言模型表示空间中出现的词汇、语法和语义结构。同时，作者还提出了一种混合注释流水线，结合静态分析工具的语法对齐和大语言模型的提示工程，以实现跨抽象层次的隐含概念的大规模标注。此外，还利用局部归因方法生成以概念为基础的解释，以提高词级显著性的连贯性和可解释性。", "conclusion": "在多个模型和任务上的实证研究表明，CoCoA能够发现稳定且具有语义保留差异的概念（平均Cluster Sensitivity Index, CSI值为0.288），并且在微调时表现出可预测性。在编程语言分类任务中的用户研究中，通过增强的概念解释提高了人类为中心的可解释性37个百分点，比使用 Integrated Gradients 的词级归因更好。"}
{"llm_update_time": "20251006", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.09650", "html_url": "https://arxiv.org/abs/2506.09650", "title": "HopaDIFF: Holistic-Partial Aware Fourier Conditioned Diffusion for Referring Human Action Segmentation in Multi-Person Scenarios", "title_en": "HopaDIFF: Holistic-Partial Aware Fourier Conditioned Diffusion for Referring Human Action Segmentation in Multi-Person Scenarios", "authors": "Kunyu Peng,Junchao Huang,Xiangsheng Huang,Di Wen,Junwei Zheng,Yufan Chen,Kailun Yang,Jiamin Wu,Chongqing Hao,Rainer Stiefelhagen", "background": "行动分割是高级视频理解中的核心挑战，目标是将未修剪的视频分割成段并为每个段分配一个预定义的动作标签。现有方法主要针对单人活动且具有固定动作序列，忽略了多人场景。目前已有的方法在面对复杂场景如多个人物之间细微动作区分时表现不佳或效率低下。", "innovation": "本研究提出了CXRAG-FDCD（HopaDIFF）框架，这是一种综合部分感知的傅里叶条件化扩散框架，结合了新颖的交叉输入门注意xLSTM以增强整体细节的长期推理，并引入了一种新颖的傅里叶条件来提供更细致的控制，改善了动作分割的生成。该研究还构建了第一个用于引用人类动作分割的RHAS133数据集，其中包含了133部电影，并通过文本描述标注了137个细粒度动作，共包含33小时的视频数据。", "conclusion": "HopaDIFF在这项研究中展示了在RHAS133数据集上的最佳结果，并在不同的评估设置中都取得了领先地位。同时，提供的数据集和代码可以在该网址获取。"}
{"llm_update_time": "20251006", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2510.02387", "html_url": "https://arxiv.org/abs/2510.02387", "title": "CWM: 基于世界模型的开放权重LLM，用于代码生成的研究", "title_en": "CWM: An Open-Weights LLM for Research on Code Generation with World Models", "authors": "FAIR CodeGen team. Jade Copet,Quentin Carbonneaux,Gal Cohen,Jonas Gehring,Jacob Kahn,Jannik Kossen,Felix Kreuk,Emily McMilin,Michel Meyer,Yuxiang Wei,David Zhang,Kunhao Zheng,Jordi Armengol-Estapé,Pedram Bashiri,Maximilian Beck,Pierre Chambon,Abhishek Charnalia,Chris Cummins,Juliette Decugis,Zacharias V. Fisches,François Fleuret,Fabian Gloeckle,Alex Gu,Michael Hassid,Daniel Haziza,Badr Youbi Idrissi,Christian Keller,Rahul Kindi,Hugh Leather,Gallil Maimon,Aram Markosyan,Francisco Massa,Pierre-Emmanuel Mazaré,Vegard Mella,Naila Murray,Keyur Muzumdar,Peter O'Hearn,Matteo Pagliardini,Dmitrii Pedchenko,Tal Remez,Volker Seeker,Marco Selvi,Oren Sultan,Sida Wang,Luca Wehrstedt,Ori Yoran,Lingming Zhang,Taco Cohen,Yossi Adi,Gabriel Synnaeve", "background": "研究团队开发了一个名为Code World Model (CWM)的具有320亿参数的开放权重大模型，旨在推动使用世界模型进行代码生成的研究。为了超越仅从静态代码训练中学到的代码理解能力，他们对CWM进行了中间训练，使其能够在Python解释器和自主Docker环境中大量的观测-行动轨迹上进行训练，并在验证性编程、数学以及多步软件工程环境中进行了广泛的多任务推理强化学习。", "innovation": "CWM的特点是通过观测和行动轨迹的培训，在验证性编程、数学以及多步软件工程环境中进行广泛的多任务推理强化学习。CWM为研究人员提供了一个强大的试验平台，用于探索通过推理和计划改善计算环境中的代码生成的机会。CWM展示了基于世界模型的自主编程如何受益，以及如何逐步模拟Python代码执行。此外，CWM作为密集型且仅解码的大模型，虽然独立于其世界建模能力，但在一般编程和数学任务上表现出色。", "conclusion": "为支持代码世界模型研究的进一步发展，研究团队发布了CWM中期训练、细调和RL训练后的模型检查点。这为代码生成和基于世界模型的研究提供了有力支持。"}
{"llm_update_time": "20251006", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.25550", "html_url": "https://arxiv.org/abs/2509.25550", "title": "在世界隐空间中学习交互以实现团队协调", "title_en": "Learning to Interact in World Latent for Team Coordination", "authors": "Dongsu Lee,Daehee Lee,Yaru Niu,Honguk Woo,Amy Zhang,Ding Zhao", "background": "多智能体强化学习（MARL）中团队协调的有效表示是一个具有挑战性的问题。由于多智能体交互复杂动态及其由局部观察带来的信息不完整，建立有效的团队表示是一个难题。", "innovation": "该工作提出了一个新颖的表示学习框架，交互世界隐空间（IWoL），该框架通过直接建模通信协议来联合捕捉智能体间的关系和任务特定的世界信息，并在此过程中实现了全分布式执行，同时避免了显式消息传递的固有缺点，如决策速度缓慢、易受恶意攻击和频宽限制敏感性。", "conclusion": "在四个具有挑战性的MARL基准测试中，我们评估了两种变体，展示了IWoL作为团队协调的简单而强大的工具的有效性。此外，我们表明可以将我们的表示与现有的MARL算法结合使用，以进一步提高其性能。"}
{"llm_update_time": "20251006", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.11486", "html_url": "https://arxiv.org/abs/2509.11486", "title": "预条件次梯度方法在复合优化中的应用：过度参数化与快速收敛", "title_en": "Preconditioned subgradient method for composite optimization: overparameterization and fast convergence", "authors": "Mateo Díaz,Liwei Jiang,Abdel Ghani Labassi", "background": "复合优化问题涉及将平滑映射与凸函数复合，出现在多个数据科学和信号处理应用中，如相位检索、盲去 convolution 和协作过滤。虽然次梯度方法在条件良好的复合损失下实现了局部线性收敛性，但在某些条件下（如平滑映射病态或过度参数化）即便凸函数条件良好也会表现出较慢的亚线性收敛性。", "innovation": "引入了一种Levenberg-Morrison-Marquardt次梯度方法，在较温和的正则条件下实现了线性收敛，且收敛率仅由凸函数决定，并证明了该正则条件适用于多个实际问题，如平方变量形式、矩阵感知和张量分解。", "conclusion": "数值实验表明了我们方法的优势。"}
{"llm_update_time": "20251006", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.17774", "html_url": "https://arxiv.org/abs/2509.17774", "title": "有效的正确判别树预测等价性", "title_en": "Efficient & Correct Predictive Equivalence for Decision Trees", "authors": "Joao Marques-Silva,Alexey Ignatiev", "background": "决策树（DTs）在计算相同分类功能时可能表现出冗余性，这被称为预测等价性。尽管这一方面可以增加模型的灵活性，但也会导致基于Rashomon集的重要特征识别不准确，以及McTavish等人提出的计算预测等价性问题的解决方案可能存在计算复杂度高和可能的错误判断的问题。", "innovation": "本文指出，通过Quine-McCluskey方法进行公式最小化存在最坏情况下指数级的时间和空间复杂度问题；同时，该方法在判断预测等价性时，如果没有遵守两个关键约束，则可能产生错误判断。作者证明，在树的大小下的最小表达式问题可以在多项式时间内解决，提出了比McTavish等人更快的算法。", "conclusion": "该研究确认，对于触发Quine-McCluskey方法最坏情况的DTs，提出了比McTavish等人算法快得多的新算法。"}
{"llm_update_time": "20251006", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.01252", "html_url": "https://arxiv.org/abs/2510.01252", "title": "GPT与偏见：理解大规模语言模型中学习表示的一种稀疏方法", "title_en": "GPT and Prejudice: A Sparse Approach to Understanding Learned Representations in Large Language Models", "authors": "Mariam Mahran,Katharina Simbeck", "background": "随着大型语言模型（LLMs）越来越多地训练于庞大的未校正语料库上，理解模型表示和其内化的数据已成为一大挑战。研究人员通过将LLMs与稀疏自动编码器（SAEs）结合，不仅能够让人们解读模型行为，还能深入理解训练数据中嵌入的深层结构、主题和偏见。研究团队选择使用简·奥斯汀的小说作为语料库，因为其中含有丰富的社会构造和叙述模式。", "innovation": "该研究通过将GPT样式的变压器模型专门训练于简·奥斯汀的小说之上来揭示隐藏状态中的稀疏可解释特征，这些特征反映了语料库中的关键叙述和概念，包括性别、社会阶层和社会责任感。研究结果表明，结合使用LLMs与SAEs能够作为一个可扩展的探针，以探索复杂数据集，发现偏见，并提供大规模模型可解释性的新途径。", "conclusion": "通过结合GPT样式的变压器模型与稀疏自动编码器，该研究展示了大规模语言模型中结合稀疏自动编码器作为一种新的方法，使得深入理解语言模型训练数据中的复杂结构、主题及偏见成为可能。这种方法为大规模数据集的探索、偏见发现及模型可解释性提供了一种新的路径。"}
{"llm_update_time": "20251006", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.21634", "html_url": "https://arxiv.org/abs/2509.21634", "title": "MobiLLM：6G开环O-RAN环境中基于代理人工智能的闭环威胁缓解框架", "title_en": "MobiLLM: An Agentic AI Framework for Closed-Loop Threat Mitigation in 6G Open RANs", "authors": "Prakhar Sharma,Haohuang Wen,Vinod Yegneswaran,Ashish Gehani,Phillip Porras,Zhiqiang Lin", "background": "随着Open Radio Access Network (O-RAN)范式的加速发展，6G网络的演进正逐渐加快。O-RAN是一种开放、可互操作的架构，它允许在公共电信和私有企业领域部署智能、模块化的应用程序。这一开放性为创新带来了前所未有的机会，但也扩大了攻击面，因此需要更为可靠、低成本且自动化的安全解决方案。现有的防御措施大多是被动、劳动密集型且不足以应对下一代系统的规模和复杂性。当前的O-RAN应用主要集中在网络优化或被动威胁检测，缺乏闭环自动化响应的能力。", "innovation": "本文提出了一种代理人工智能框架MobiLLM，用于6G O-RAN环境中的完全自动、端到端威胁缓解。MobiLLM通过模块化的多代理系统实现了安全工作流的协调，其中包含威胁分析代理、威胁分类代理和威胁响应代理。这些代理分别进行实时数据分流、利用检索增强生成（RAG）技术将异常映射到具体的应对措施，以及通过O-RAN控制接口实现安全措施的自动化操作。MobiLLM基于MITRE FiGHT框架和3GPP规范等可信知识库，并配备了强大的安全保障机制，提供了一种值得信赖的人工智能驱动网络安全性构建蓝图。初步评估表明，MobiLLM可以有效地识别和协调复杂的缓解策略，显著减少了响应延迟，展示了在6G环境中自主安全操作的可行性。", "conclusion": "MobiLLM框架为6G O-RAN环境提供了端到端威胁缓解的一体化解决方案，通过集成多代理系统和大型语言模型，MobiLLM能够实现从数据处理到自动化响应的一整套策略，展示出其在面对复杂威胁时的高度适应性和有效性。未来，MobiLLM有望进一步优化，并将在6G网络安全性领域发挥重要作用。"}
{"llm_update_time": "20251006", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2510.02504", "html_url": "https://arxiv.org/abs/2510.02504", "title": "Product Manager Practices for Delegating Work to Generative AI: 'Accountability must not be delegated to non-human actors'", "title_en": "Product Manager Practices for Delegating Work to Generative AI: \"Accountability must not be delegated to non-human actors\"", "authors": "Mara Ulloa,Jenna L. Butler,Sankeerti Haniyur,Courtney Miller,Barrett Amos,Advait Sarkar,Margaret-Anne Storey", "background": "生成式人工智能（GenAI）正在改变知识工作的方式，特别是在软件开发团队的产品经理（PMs）的工作中。尽管许多软件工程研究集中于开发人员与GenAI的互动，但对PMs因GenAI而导致的工作演变理解较少。", "innovation": "本研究通过混合方法（调查885名PMs、分析731名PMs的遥测数据、并对15名PMs进行访谈）贡献了PMs在GenAI采用方面的现状、使用场景、感知的好处和障碍；提出了PMs评估将哪些任务委托给GenAI的框架；以及PMs适应实践整合GenAI到其角色，并对他们在这一过程中角色的变化进行感知。该研究讨论了GenAI工作流程采用过程及软件开发角色的更广泛影响。", "conclusion": "本文讨论了更广泛的GenAI工作流程采用过程的影响以及软件开发角色的变化，展示了PMs在评估和采用GenAI方面的实践和感知。"}
{"llm_update_time": "20251006", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2510.02389", "html_url": "https://arxiv.org/abs/2510.02389", "title": "从跟踪到代码行：基于LLM的实境开源软件漏洞精确定位", "title_en": "From Trace to Line: LLM Agent for Real-World OSS Vulnerability Localization", "authors": "Haoran Xi,Minghao Shao,Brendan Dolan-Gavitt,Muhammad Shafique,Ramesh Karri", "background": "现有的漏洞发现方法主要在孤立的代码上进行分析，难以处理长上下文，并且侧重于粗粒度的函数或文件级别的检测，这为工程师在实际软件开发中提供了有限的精确行级别定位和有针对性修补的指导。因此，需要一种项目级别的框架，能够逐步缩小分析范围，从模块到具体的脆弱代码行，并能够进行迭代优化，提供可操作的诊断结果。", "innovation": "提出了T2L-Agent（跟踪到代码行代理），这是一种项目级别的端到端框架，能够自主规划分析步骤并逐步缩小从模块到具体脆弱代码行的范围。该框架结合多轮反馈，使用行为性跟踪分析器（ATA），融合运行时证据、崩溃点、栈跟踪、覆盖率差异与基于AST的代码块化，以迭代优化单次预测结果，将症状转化为可操作的行级别诊断。此外，还提出了T2L-ARVO作为基准测试集，涵盖了五种崩溃家族和现实世界的项目，不仅支持粗粒度检测，还支持精细粒度定位，为系统提供了一个严格的评估平台，以超越文件级别的预测能力。", "conclusion": "T2L-Agent 在T2L-ARVO基准测试集上实现了高达58.0%的检测率和54.8%的行级别定位率，显著优于基线。该框架和基准测试集将基于LLM的漏洞检测推进到部署级的精确诊断阶段，减少噪声并加速开源软件的工作流中的补丁修补过程。"}
{"llm_update_time": "20251006", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.02120", "html_url": "https://arxiv.org/abs/2510.02120", "title": "VarCoNet: 一种针对静息态功能性磁共振成像的功能连接图提取自监督框架", "title_en": "VarCoNet: A variability-aware self-supervised framework for functional connectome extraction from resting-state fMRI", "authors": "Charalampos Lamprou,Aamna Alshehhi,Leontios J. Hadjileontiadis,Mohamed L. Seghier", "background": "精确医疗的关键在于考虑个体间大脑功能的差异性。现有的方法通常将这种个体间差异视为噪声而不是有意义的数据来处理。为了处理这一挑战，该文提出了一种增强的自监督框架VarCoNet，用于从静息状态功能性核磁共振成像（resting-state fMRI）数据中提取功能连接图（functional connectome, FC），并强调个体间功能性差异的重要性，以此改进功能连接图的提取过程。", "innovation": "VarCoNet基于自监督对比学习，利用新颖的数据增强策略（基于静息态功能性磁共振成像信号分割）和1D-CNN-Transformer编码器结合鲁棒贝叶斯超参数优化，增强了对功能性连接图的提取能力。该框架在两个下游任务中进行了评估：一是提取个体指纹，二是自闭症谱系障碍（ASD）分类。实验结果显示，与13种深度学习方法和现有最先进的方法相比，该框架在多个方面表现更优，如鲁棒性、可解释性和泛化能力。", "conclusion": "VarCoNet提供了一种灵活且稳健的功能连接图分析框架，特别适用于静息状态功能性磁共振成像数据。这种方法在处理个体间功能性差异方面具有显著优势，能够更准确地揭示和分析大脑功能连接信息。"}
{"llm_update_time": "20251006", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2510.02585", "html_url": "https://arxiv.org/abs/2510.02585", "title": "自动扩展的关键考虑：基准微服务中的经验教训", "title_en": "Key Considerations for Auto-Scaling: Lessons from Benchmark Microservices", "authors": "Majid Dashtbani,Ladan Tahvildari", "background": "微服务已成为构建可扩展和模块化的云原生系统的主导架构范式。然而，在这些系统中实现有效的自动扩展仍然是一个棘手的挑战，因为它不仅依赖于高级扩展技术，还依赖于良好的设计、实现和部署实践。现有的基准测试往往忽视了这些基础方面，使得在现实条件下评估自动扩展方法变得困难。", "innovation": "通过应用先进的自动扩展方法到广泛使用的微服务基准中，作者确定了一组实用的自动扩展考虑因素，并将其分类为软件生命周期的不同阶段：架构、实现和部署。创新之处在于通过这些分类发现并验证了自动扩展的关键考虑因素，特别重视生命周期的每个阶段中的问题，并评估了多种不同的自动扩展策略。实验结果显示，忽视生命周期中的关键因素会降低自动缩放器的性能，而解决这些问题可以导致更稳定和高效的缩放。", "conclusion": "研究结果强调了生命周期感知工程的重要性，这对于充分发挥微服务架构中自动扩展的潜力至关重要。"}
{"llm_update_time": "20251006", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2510.02404", "html_url": "https://arxiv.org/abs/2510.02404", "title": "无服务器计算中动态函数配置及其管理：分类与未来方向", "title_en": "Dynamic Function Configuration and its Management in Serverless Computing: A Taxonomy and Future Directions", "authors": "Siddharth Agarwal,Maria A. Rodriguez,Rajkumar Buyya", "background": "无服务器云计算模型通过抽象底层基础设施管理来为开发人员提供服务。在这种模型中，FaaS（函数即服务）提供了一种事件驱动、函数导向的计算服务，其特点是细粒度、基于使用的定价机制，消除了闲置资源的费用。然而，商业平台对资源分配的不透明性使得开发人员需要依赖专家知识或基于经验的不规范决定来请求所需的函数资源，这使得在满足性能约束的前提下进行最优资源配置成为一个非平凡的任务。此外，与内存扩展成比例地扩展资源如CPU和网络带宽的商业平台，开源框架允许独立配置函数资源，这增加了开发者优化其函数的复杂性。这些复杂性促使研究人员解决开发人员的问题，并逐步向高效的无服务器执行模型迈进。因此，本文旨在解决FaaS场景中的资源配置技术的不同方面，并提出影响函数设计、配置、运行时成本和性能保证的因素分类。我们对现有文献中的资源配置进行了分析，概述了当前函数配置研究的全面回顾，同时指出了现有的研究缺口，并提出了增强函数配置和强化无服务器计算环境以推动其更广泛采用的研究方向。", "innovation": "本文提出了一种关于FaaS环境中资源配置的技术分类，涵盖了影响函数设计、配置、运行时成本和性能保证的因素，并通过全面的文献分析提出了当前函数配置研究关键问题，从而帮助指导未来的研究方向以推进无服务器计算模型的广泛应用和发展。", "conclusion": "通过对现有文献的分析，我们提出了关于无服务器计算中函数配置的全面分类，指出了当前研究的缺失，并提出了未来研究的方向，旨在增强函数配置，并强化服务计算环境的能力，推动其广泛应用。"}
{"llm_update_time": "20251006", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2510.02393", "html_url": "https://arxiv.org/abs/2510.02393", "title": "AP2O: 基于适应性渐进偏好优化逐类型修正LLM生成代码错误", "title_en": "AP2O: Correcting LLM-Generated Code Errors Type by Type Like Humans via Adaptive Progressive Preference Optimization", "authors": "Jianqing Zhang,Wei Xia,Hande Dong,Qiang Lin,Jian Cao", "background": "大规模语言模型（LLMs）在编程任务中的代码生成能力已取得显著进步，但生成的代码仍存在编译和运行时错误。现有的离线偏好优化方法主要依赖通过成功/失败信号来提升LLMs的编程能力，忽略了失败代码中的深层次错误类型。因此，该文提出了适应性渐进偏好优化（AP2O）方法，以系统地指导LLMs减少代码错误。通过这种方法，构建了一个错误笔记本，逐步优化LLMs以逐类型纠正错误，并根据训练过程中的变化定期调整错误类型，以适应LLMs的弱项变化。", "innovation": "提出了AP2O-Coder方法，这是一种适应性渐进偏好优化方法，旨在指导LLMs系统地减少代码错误。该方法通过构建错误笔记本并逐步优化LLMs来逐类型纠正错误，并定期重放错误类型以适应LLMs在训练过程中的变化弱点。研究结果显示，在代码和多种大型语言模型（包括Llama、Qwen和DeepSeek系列）中，AP2O-Coder方法在提升代码生成性能的同时，使用了较少的偏好数据，并且在pass@k上提高了高达3%的性能。", "conclusion": "通过使用AP2O-Coder方法，该文展示了如何有效减少LLMs生成代码时的错误，同时降低了对偏好数据的需求，提升了代码生成的准确性。"}
{"llm_update_time": "20251006", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2510.02773", "html_url": "https://arxiv.org/abs/2510.02773", "title": "OpenID Connect程序的自动化修复（扩展版）", "title_en": "Automated Repair of OpenID Connect Programs (Extended Version)", "authors": "Tamjid Al Rahat,Yanju Chen,Yu Feng,Yuan Tian", "background": "OpenID Connect通过提供一种安全便捷的方法，使用户能够使用一套凭证访问多个服务，彻底革新了基于单点登录（SSO）的在线认证方式。尽管得到了广泛应用，OpenID Connect中的关键安全漏洞导致了大量的经济损失和安全问题，这表明需要采取更加坚实的缓解策略。自动程序修复被视为生成OpenID实现候选补丁的有效解决方案，但面对领域特定的复杂性和精确的故障定位以及补丁验证需求，仍有许多挑战需要克服。", "innovation": "作者提出了AuthFix，这是一种利用LLMs的自动OpenID漏洞修复引擎。AuthFix包含了三个核心组件：故障定位、补丁合成和补丁验证。通过使用新颖的基于Petri网的模型检查器，AuthFix确保了补丁的正确性并能有效模拟交互。实验结果表明，AuthFix成功为23个bug中的17个生成了正确的补丁，有很大比例的补丁在语义上与开发者编写的修复一致。", "conclusion": "实验结果表明，AuthFix能够成功生成正确补丁74%，且大部分补丁在语义上与开发者的修复类似。这表明AuthFix在自动修复OpenID漏洞方面具有很高的潜力和实用性。"}
{"llm_update_time": "20251006", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2510.02609", "html_url": "https://arxiv.org/abs/2510.02609", "title": "RedCodeAgent：对抗多样代码代理的自动化红队测试代理", "title_en": "RedCodeAgent: Automatic Red-teaming Agent against Diverse Code Agents", "authors": "Chengquan Guo,Chulin Xie,Yu Yang,Zhaorun Chen,Zinan Lin,Xander Davies,Yarin Gal,Dawn Song,Bo Li", "background": "代码代理由于其强大的代码生成能力和与代码解释器的集成，已经在广泛使用中，这使得它们能够实现动态执行、调试和互动编程。尽管这些技术简化了复杂的流程，但同时也引入了关键的安全和安全风险。目前的静态安全基准测试和红队工具对于识别实际存在的风险场景来说是不够的，因为它们无法覆盖一些边界条件，例如不同脱牢笼工具的联合效果。", "innovation": "本文提出了RedCodeAgent，这是第一个自动化的红队测试代理，旨在系统地揭露不同代码代理中的漏洞。RedCodeAgent具有自适应内存模块，可以利用现有的脱牢笼知识，动态选择针对特定输入查询的最有效的红队工具和工具组合在定制的工具箱中，从而发现可能被忽视的漏洞。为了可靠地评估CodeAgent的执行结果，我们开发了模拟沙盒环境，以减少依赖于LLM基于的静态代码的评估偏见。通过广泛的评估，RedCodeAgent在多个最先进的代码代理、多样化的风险场景以及不同的编程语言上表现出色，在攻击成功率和拒绝率方面均优于现有红队方法。我们还通过验证RedCodeAgent实际代码助手（例如Cursor和Codeium）来发现先前未知的安全风险，这实现了代码代理的规模、自适应和有效的安全性评估过程自动化和优化。", "conclusion": "RedCodeAgent通过自动化和优化红队流程，能够实现代码代理的规模、自适应和有效的安全性评估。"}
{"llm_update_time": "20251006", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2510.02934", "html_url": "https://arxiv.org/abs/2510.02934", "title": "模型无偏的LLM生成代码正确性评估通过动态内部表示选择", "title_en": "Model-Agnostic Correctness Assessment for LLM-Generated Code via Dynamic Internal Representation Selection", "authors": "Thanh Trong Vu,Tuan-Dung Bui,Thu-Trang Nguyen,Son Nguyen,Hieu Dinh Vo", "background": "大型语言模型（LLMs）在代码生成方面表现出色，并逐渐融入软件开发过程。然而，确保LLM生成代码的正确性仍然是一个关键问题。先前的研究表明，LLMs的内部表示包含了评估代码正确性的有意义信号。但是，现有的方法依赖于预选/固定的层级和标记位置的表示，这可能会限制其在多种模型架构和任务间的泛化能力。", "innovation": "引入了AUTOPROBE，这是一种模型无偏的方法，能够动态选择最相关的内部表示来评估代码正确性。该方法利用注意力机制学习隐藏状态的重要性得分，使其能够关注最具相关性的特征。这些加权表示被聚合并通过分类器预测多个维度的代码正确性，包括编译性、功能性和安全性。", "conclusion": "实验结果表明，AUTOPROBE在多种基准和代码LLM上优于基准方法。在安全性评估方面，AUTOPROBE比最先进的黑盒方法高出18%。在编译性和功能性的评估中，AUTOPROBE显示出对代码复杂性的高度鲁棒性，其性能分别比其他方法高出19%和111%。这些发现表明，动态选择重要内部信号使AUTOPROBE能够成为一个鲁棒且通用的解决方案，适用于各种LLM生成的代码的正确性评估。"}
{"llm_update_time": "20251006", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2510.02991", "html_url": "https://arxiv.org/abs/2510.02991", "title": "云原生应用监控的追踪和指标设计模式", "title_en": "Tracing and Metrics Design Patterns for Monitoring Cloud-native Applications", "authors": "Carlos Albuquerque,Filipe F. Correia", "background": "随着软件架构变得越来越分布式和多变，诊断系统问题的有效性成为一个更大的挑战，通常需要处理碎片化的可观测性并进行更难的根因分析。云原生应用的可观测性帮助确保其可靠性和可维护性，但有效监控也变得越发困难。", "innovation": "本文在此前工作的基础上，引入了三种解决云原生应用监控关键挑战的设计模式。它们分别是分布式追踪、应用指标和基础设施指标，这些模式借鉴了行业实践和可观测性框架，目的是为软件从业人员提供指导。", "conclusion": "这三种设计模式分别通过分布式追踪提高服务间请求流的可见性，通过应用指标提供有意义的性能指标，实现实时监控和异常检测，通过基础设施指标监控系统的运行环境，帮助团队评估资源利用率、可扩展性以及操作健康状态。"}
{"llm_update_time": "20251006", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2510.02534", "html_url": "https://arxiv.org/abs/2510.02534", "title": "ZeroFalse: 提高静态分析精度的LLM方法", "title_en": "ZeroFalse: Improving Precision in Static Analysis with LLMs", "authors": "Mohsen Iranmanesh(Simon Fraser University),Sina Moradi Sabet(Amirkabir University of Technology),Sina Marefat(K. N. Toosi University of Technology),Ali Javidi Ghasr(Ferdowsi University of Mashhad),Allison Wilson(Cyber Risk Solutions),Iman Sharafaldin(Forward Security),Mohammad A. Tayebi(Simon Fraser University)", "background": "静态应用安全测试（SAST）工具在现代软件开发中至关重要，但它们的普及受到过多假阳性结果的阻碍。这些假阳性结果削弱了开发者的信任，增加了昂贵的手动修复成本。本文探讨了ZeroFalse框架，该框架将静态分析与大型语言模型（LLMs）集成，旨在减少假阳性结果的同时保持覆盖率。ZeroFalse将静态分析器的输出视为结构化的合同，并通过流程敏感的跟踪、上下文证据和CWE特定知识进行丰富，最终由LLM进行裁决。这种设计保持了静态分析的系统性范围，同时利用了LLMs的推理能力。", "innovation": "ZeroFalse框架将静态分析和大型语言模型（LLMs）集成，通过将静态分析器输出作为结构化的合同，增强其流程敏感性跟踪、上下文证据和CWE特定知识，然后由LLM进行裁决。这种方法同时保持了静态分析的系统性范围和LLMs的推理能力。此外，ZeroFalse展示了使用多种最先进的LLMs在基准测试和实际项目中的性能，证明了CWE特定提示和推理导向的LLMs在precision和recall平衡上的优越性。", "conclusion": "ZeroFalse框架通过结合静态分析和LLM，提升了SAST工具的可靠性，并在CWE特定提示和推理导向的LLM中提供了最佳性能，F1分数分别达到0.912（OWASP Java基准）和0.955（OpenVuln数据集），且召回率和精确率均超过90%。这些发现证明ZeroFalse是提高SAST可靠性的实用且可扩展的方法，支持其在实际CI/CD管道中的集成。"}
{"llm_update_time": "20251006", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2510.03005", "html_url": "https://arxiv.org/abs/2510.03005", "title": "面向学生的敏捷教学模式：团队与项目设置", "title_en": "Patterns for Teaching Agile with Student Projects - Team and Project Setup", "authors": "Daniel Pinho,Petr Pícha,Filipe Correia,Přemek Brada", "background": "随着敏捷思想在行业的普及，高等教育课程中关于敏捷软件开发（ASD）的教学变得越来越普遍。然而，现有的文献大多没有提供具体的教学建议，而是在框架层面进行讨论，甚至将教学方法扩展到敏捷方式之外。", "innovation": "作者提出了一种新的模式语言，专注于在高等教育背景下教授大学学生敏捷实践，特别聚焦于团队和项目设置阶段的五个模式：限制团队规模、项目范围缩小、非关键业务项目、自我成型团队、团队选择主题。这些模式旨在为开发整体模式语言提供起点。", "conclusion": "本研究展示了早期工作成果，为敏捷教学提供了实际的指导，希望能够在高等教育环境中更有效地教授敏捷软件开发实践。"}
{"llm_update_time": "20251006", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2510.02718", "html_url": "https://arxiv.org/abs/2510.02718", "title": "使用傅里叶分析和 mutants 群集加速 DNN 突变测试", "title_en": "Using Fourier Analysis and Mutant Clustering to Accelerate DNN Mutation Testing", "authors": "Ali Ghanbari,Sasan Tavakkol", "background": "深度神经网络（DNN）的变异分析是一种有前景的方法，用于评估测试集的充分性。然而，由于必须测试大量生成的变异体并且这些测试需要在大数据集上进行，因此变异分析非常昂贵。", "innovation": "本文提出了一种名为 DM# 的技术，通过傅里叶分析加速 DNN 变异测试。关键见解在于，DNN 输出是适合傅里叶分析的实值函数，可以仅使用少数数据点来量化变异行为。DM# 利用量化后的变异行为将变异体进行分组，并从中选择代表进行测试。通过这种方法，不需要对其他代表同一组的变异体进行重复测试，从而提高了效率。本文还评估了 DM# 并将其与几种基线技术进行了比较，结果表明，DM# 平均可以提高 28.38% 的变异测试速度，同时仅产生 0.72% 的变异得分误差。此外，相对于随机变异体选择、边界样本选择和随机样本选择技术，DM# 在平均上分别产生了 11.78 倍、15.16 倍和 114.36 倍少的变异得分误差，同时一般提供了相似的速度提升效果。", "conclusion": "DM# 技术通过利用傅里叶分析和变异体群集在提高 DNN 变异测试速度的同时，仅略微降低了变异得分的准确性。与基于随机选择的其他技术相比，DM# 在准确性与效率之间取得了更好的平衡。"}
{"llm_update_time": "20251006", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2510.02634", "html_url": "https://arxiv.org/abs/2510.02634", "title": "自动建筑规范审查：案例研究", "title_en": "Automatic Building Code Review: A Case Study", "authors": "Hanlong Wan,Weili Xu,Michael Rosenberg,Jian Zhang,Aysha Siddika", "background": "建筑官员，尤其是在资源受限或农村地区担任职务的官员，需要对设计文件进行繁琐、容易出错且成本高昂的手动审批，尤其是在项目规模和复杂性增加的情况下。随着建筑信息建模（BIM）和大型语言模型（LLMs）的应用日益广泛，为代码自动审批（ACR）解决方案提供了新的机遇。这一研究针对建筑审批中的实际需求和挑战，引入了一种新颖的代理驱动框架，该框架将基于BIM的数据提取与使用检索增强生成（RAG）和Model Context Protocol（MCP）代理管道的自动化验证相结合。该框架采用LLM驱动的代理从不同文件类型中提取几何、时间表和系统属性，然后利用两种互补机制进行建筑代码检查：直接调用美国能源部COMcheck引擎API接口，提供确定性和审计准备好的输出；基于RAG的规则规定推理，以灵活解释不完整或模棱两可的规定。", "innovation": "该论文提出了一种创新的代理驱动框架，将BIM数据提取与自动化验证相结合，利用LLM技术和MCP代理管道，提高了建筑规范审查的效率和准确性。框架中的L4G基于代理管道的机制和基于RAG的规则推理方法，能够灵活地处理不完整的规范覆盖和模糊的解读问题。研究结果表明，MCP代理管道在有效性及可靠性方面优于基于RAG推理的代理管道。该研究为ACR研究提供了一种可扩展、可互操作且生产就绪的方法，有助于将BIM与权威的代码审查工具相结合，大大提高了建筑审批过程的效率和准确性。", "conclusion": "该研究通过案例研究展示了基于BIM的ACR解决方案的实际应用和潜在优势，证明了其在实际项目审批中的适用性和可靠性，为未来的研究提供了新的方向和思路。"}
{"llm_update_time": "20251006", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2510.03029", "html_url": "https://arxiv.org/abs/2510.03029", "title": "探索LLM生成代码中的缺陷", "title_en": "Investigating The Smells of LLM Generated Code", "authors": "Debalina Ghosh Paul,Hong Zhu,Ian Bayley", "background": "随着大型语言模型（LLMs）越来越多地用于生成程序代码，关于生成代码的功能正确性的研究已有很多报道，但在代码质量方面则报道较少。本文的背景是针对这一问题，提出了一种基于场景的方法来评估LLM生成代码的质量，以便识别需要改进质量的最弱场景。", "innovation": "本文提出了一种衡量LLM生成代码质量的方法，通过测量代码异味（代码质量的重要指标）并与专业人员编写的参考解决方案进行比较。此外，还将测试数据集根据代码的主题和编码任务的复杂性分为多个子集，以代表使用LLM进行代码生成的不同场景。并且还提供了一个自动化测试系统，对四个最先进的LLM（Gemini Pro，ChatGPT，Codex，Falcon）生成的Java程序进行了实验。", "conclusion": "在代码异味方面，LLM在各种编码任务复杂度和主题上的表现高度相关于对应场景中的人类编写代码的质量。然而，LLM生成的代码质量明显低于人类编写的代码。"}
{"llm_update_time": "20251006", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2510.02854", "html_url": "https://arxiv.org/abs/2510.02854", "title": "C2|Q>: 一种连接经典和量子软件开发的稳健框架", "title_en": "C2|Q>: A Robust Framework for Bridging Classical and Quantum Software Development", "authors": "Boshuai Ye,Arif Ali Khan,Teemu Pihkakoski,Peng Liang,Muhammad Azeem Akbar,Matti Silveri,Lauri Malmi", "background": "量子软件工程（QSE）正在成为使量子计算对更广泛的开发者社区可访问的关键学科；然而，大多数量子开发环境仍然需要开发者在其软件堆栈的各个层面上处理低级细节 - 包括问题编码、门电路构建、算法配置、硬件选择和结果解释 - 使得它们对经典软件工程师来说难以使用。", "innovation": "我们提出了一个硬件无关的量子软件开发框架C2|Q>，它可以将经典的代码规格转换为可执行的量子程序，同时保持方法论的严谨性。该框架通过将工作流程划分为三个核心模块来应用模块化的软件工程原则：编码器、部署模块和解码器。此框架的创新之处在于能够降低开发者在使用低级量子软件开发工具包进行手动实施时的实施工作量，特别是在处理NISQ硬件上的实际问题时，C2|Q>相比手动实现使用低级量子软件开发工具包的实施效率提高了近40倍。", "conclusion": "C2|Q>的一个全面的工作流成功地处理了434个Python片段和100个JSON输入，完成了率为93.8%和100%。对于可以执行公开可用的NISQ硬件上的实例，C2|Q>相比手动使用低级量子SDK实施减少了近40倍的开发努力。此外，C2|Q>可以推荐适当的量子设备，以支持工作量的扩展多达56个量子比特，并实现了93.8%的编码完成率。该开源实现可在提供的链接中下载。"}
{"llm_update_time": "20251006", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2510.03217", "html_url": "https://arxiv.org/abs/2510.03217", "title": "Abstain and Validate: A 双LLM策略以减少代理程序修复中的噪音", "title_en": "Abstain and Validate: A Dual-LLM Policy for Reducing Noise in Agentic Program Repair", "authors": "José Cambronero,Michele Tufano,Sherry Shi,Renyao Wei,Grant Uy,Runxiang Cheng,Chin-Jung Liu,Shiying Pan,Satish Chandra,Pat Rondon", "background": "代理自动化程序修复（APR）正越来越多地处理工业中的复杂、仓库级别的错误，但最终自动化生成的补丁仍需由人类审查，以确保它们确实解决了错误。向开发人员展示不相关的补丁可能会产生大量的噪音，浪费宝贵的开发人员时间并削弱对自动化代码变更的信任。", "innovation": "本文引入了两种互补的基于LLM的策略以减少噪音：缺陷弃权和补丁验证策略。缺陷弃权会排除代理APR系统可能无法解决的缺陷。补丁验证会拒绝可能不适合给定缺陷的补丁。这些策略在Google代码库的三组缺陷以及内部代理APR系统生成的候选补丁上进行了评估，从174个人报告的缺陷中去除掉被策略拒绝的缺陷和补丁轨迹，成功率最多可提高13个百分点和15个百分点，结合使用时，成功率最多可提高39个百分点。对于空指针异常和机器生成的错误报告，补丁验证也提高了平均成功率。这种双策略方法为可靠、工业规模部署代理APR系统的实际途径提供了支持。", "conclusion": "此双策略方法提供了一条可靠、工业规模部署代理APR系统的实际途径。"}
{"llm_update_time": "20251006", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2510.03050", "html_url": "https://arxiv.org/abs/2510.03050", "title": "朝向微服务的重构：为服务提取奠定基础", "title_en": "Refactoring Towards Microservices: Preparing the Ground for Service Extraction", "authors": "Rita Peixoto,Filipe F. Correia,Thatiane Rosa,Eduardo Guerra,Alfredo Goldman", "background": "随着组织从单体系统转向微服务，他们希望实现更高的可用性、自动扩展、简化基础设施管理、增强协作以及简化部署。然而，这一迁移过程仍然是手动且劳动密集型的。现有的文献提供了各种分解单体系统的策略，但这些方法主要集中在架构层面的指导，往往忽略了开发者在迁移过程中必须面对的代码级挑战和依赖关系。", "innovation": "本文介绍了一种包含七项重构的清单，专门设计用于支持向微服务架构的过渡，并特别关注处理依赖关系。该清单为开发者提供了系统化的指南，将文献中识别的重构综合起来，并填补了系统化代码级过程的空白。通过提供结构化、逐步的方法，这篇文章简化了迁移过程，并为其自动化奠定了基础，使开发者可以高效有效地实施这些改变。", "conclusion": "本文简化了微服务架构迁移的过程，并为自动化奠定了基础，进而提升了开发者的迁移效率和效果。"}
{"llm_update_time": "20251006", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2510.02572", "html_url": "https://arxiv.org/abs/2510.02572", "title": "地学机器学习库", "title_en": "Geospatial Machine Learning Libraries", "authors": "Adam J. Stewart,Caleb Robinson,Arindam Banerjee", "background": "近年来，特定领域软件库的出现促进了机器学习的进步，使得工作流程更为简化并增强了可复现性。对于地学机器学习（GeoML），地球观测数据的可用性已超过了处理其独特挑战（如空间分辨率变化、光谱属性、时间频率、数据覆盖范围、坐标系统及文件格式）的领域库的发展速度。", "innovation": "论文详细分析了GeoML库的发展历程、核心功能及当前生态系统，介绍了流行的GeoML库如TorchGeo、eo-learn及Raster Vision，阐述了它们的架构、支持的数据类型及与机器学习框架的集成情况。讨论了数据预处理、时空关联、基准测试及使用预训练模型的常见方法。通过作物类型映射的实际案例展示了这些工具的应用，并指出了软件设计、许可证和测试的最佳实践。", "conclusion": "论文总结了平台化和开源地学软件在未来地学机器学习领域的挑战和未来方向，特别是基础模型的崛起和开源软件治理的需要，旨在引导实践者、开发人员和研究人员导航和贡献到快速发展的地学机器学习领域。"}
{"llm_update_time": "20251006", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2510.03071", "html_url": "https://arxiv.org/abs/2510.03071", "title": "状态字段覆盖率：一种判据质量度量", "title_en": "State Field Coverage: A Metric for Oracle Quality", "authors": "Facundo Molina,Nazareno Aguirre,Alessandra Gorla", "background": "现有的评估判据质量的度量标准要么不够全面，不能很好地指导判据改进，要么是针对特定类型的判据，缺乏通用性。因此，需要一种新的度量标准来提高测试过程的整体有效性。", "innovation": "提出了状态字段覆盖率这一新的度量标准，主要通过静态计算的方式衡量测试过程中的判据能够访问的各类对象状态的比例，旨在提高判据发现软件缺陷的能力。", "conclusion": "状态字段覆盖率是一种适合评估判据质量的有效度量，因为它与判据的故障检测能力（通过突变评分衡量）具有很强的相关性，并且是静态计算的，可以直接指导改善测试判据。"}
{"llm_update_time": "20251006", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2510.02917", "html_url": "https://arxiv.org/abs/2510.02917", "title": "利用稀疏自编码器理解LLMs中的代码正确性机制", "title_en": "Mechanistic Interpretability of Code Correctness in LLMs via Sparse Autoencoders", "authors": "Kriz Tahimic,Charibeth Cheng", "background": "随着大规模语言模型（LLMs）在软件开发中的应用越来越广泛，AI建议的代码越来越多地进入生产环境，因此了解模型内部的正确性机制变得尤为重要，以确保其在部署中的安全性。研究发现，通过稀疏自编码器分解LLM的表示，可以识别出与代码正确性相关的方向，并通过t值和基模型表示的分离得分来指导这些方向的设定，进而分析这些机制的运作原理。研究发现这些机制能够可靠地预测错误代码，并且修正能力虽然统计上显著，但在修正错误时需要在正确性保持和修复之间做出权衡。此外，成功的代码生成依赖于对测试案例的关注而不是问题描述。在微调过程中，被识别出的机制在基础模型中仍保持有效，这表明在预训练中学习到的代码正确性机制能够被重新利用以支持微调过程。这些机制为实际应用提供了三点启示：提示策略应优先使用测试示例而非复杂的问题描述；预测方向可以作为开发人员审查过程中的错误警报；基于相同预测器的选择性引导，只有在预期有错误发生时才进行干预，以防止持续引导造成的代码破坏。", "innovation": "利用稀疏自编码器来分解和理解LLMs的表示，识别出与代码正确性相关的方向，并通过t值和分离得分来选择和引导这些方向，分析其运作机理，揭露了在代码生成和修正过程中依赖于特定机制的详细过程，并发现这些机制在微调过程中仍然有效，说明了预训练学习到的正确性机制可以被重新利用。这些方法为理解大规模语言模型内部运作和改进其应用提供了新的视角和工具。", "conclusion": "研究表明，代码正确性方向在大规模语言模型中可预测错误代码，但修正能力需要权衡。成功的代码生成依赖测试案例而非问题描述。被识别的机制在微调中仍然有效，表明预训练中学习到的正确性机制可以被有效地重新利用。研究为实际应用提供了三点建议：优先使用测试示例而非复杂问题描述的提示策略；预测方向作为开发人员审查过程中的错误警报；选择性地进行干预以避免持续引导导致的代码腐败。"}
{"llm_update_time": "20251006", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2510.02887", "html_url": "https://arxiv.org/abs/2510.02887", "title": "GramTrans: 在代码生成中的更好代码表示方法", "title_en": "GramTrans: A Better Code Representation Approach in Code Generation", "authors": "Zhao Zhang,Qingyuan Liang,Zeyu Sun,Yizhou Chen,Guoqing Wang,Yican Sun,Lu Zhang,Ge Li,Yingfei Xiong", "background": "代码生成展示了在软件开发中巨大的潜力。然而，一个基础但未被充分探索的问题是如何选择代码表示形式会影响模型性能。现有研究虽然使用了不同的表示形式（如将代码视为纯文本、文法规则序列或语法树序列），但仍缺乏对解析难度与模型效果之间关系的系统理解。本文提出一个假说：解析难度越低的表示形式，模型的性能越好。通过在基于Python的DSL上的受控实验，结果表明解析难度与模型性能之间存在显著联系。基于此发现，本文提出GramTrans，这是一种将上下文无关语言自动生成到LL(1)类表示形式的方法。GramTrans引入了一种新颖的分层冲突消除算法，使得在语法简洁性和标记效率之间能够灵活权衡。通过在Python和Java上的三种代码生成模型（StarCoder 1B、DeepSeek-Coder 1.3B和Qwen2.5 1.5B）上的评估，GramTrans在多个基准测试中持续提供了显著的改进效果。此外，对现有表示形式的分析进一步支持了该假说，即解析难度与模型性能之间出现了很强的对应关系。", "innovation": "提出了GramTrans，这是一种将代码从复杂的表示转换为更易于解析的LL(1)类表示的形式。GramTrans打破了以往仅考虑代码纯文本、文法规则序列或语法树序列的研究限制，利用分层冲突消除算法在语法简洁性和标记效率之间提供了灵活的平衡。GramTrans在多种编程语言和代码生成模型上实现了显著的性能提升。", "conclusion": "解析难度与模型性能之间存在显著联系，GramTrans方法能够在众多基准测试中显著提升代码生成性能，进一步支持了解析难度与模型性能之间的关系。"}
{"llm_update_time": "20251006", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2503.21710", "html_url": "https://arxiv.org/abs/2503.21710", "title": "通过基于仓库的智能图谱增强仓库级软件修复", "title_en": "Enhancing repository-level software repair via repository-aware knowledge graphs", "authors": "Boyang Yang,Jiadong Ren,Shunfu Jin,Yang Liu,Feng Liu,Bach Le,Haoye Tian", "background": "在仓库级别的软件修复中，存在语义鸿沟——描述问题和代码修补之间的含义差距。现有的方法主要依赖大型语言模型（LLMs），但由于语义模糊性、结构上下文理解有限和推理能力不足，这些方法遇到挑战。", "innovation": "本文提出了一种名为KGCompass的创新方法，包含两大创新：(1) 一种新的仓库意识知识图谱（KG），可以准确链接仓库元素（问题和拉请求）和代码实体（文件、类和函数），从而有效缩小搜索空间至20个最相关的函数，这些函数带有准确的候选错误位置和上下文信息；(2) 通过实体路径导向的修复机制，利用KG中提取的实体路径，通过跟踪递归访问这些实体，添加了相关上下文信息给LLMs，以生成精确的补丁及其解释。", "conclusion": "在SWE-bench Lite实验中，KGCompass实现了单LLM修复的最新性能（58.3%）和功能级错误定位精度（56.0%），且仅需每修复一次花费0.2美元。在成功定位的错误中，89.7%缺乏明确的位置提示，并通过多跳图遍历找到，而纯LLMs难以精确定位这些错误。与纯LLM基线相比，KGCompass在Claude-4 Sonnet中提高了50.8%的修复率，Claude-3.5 Sonnet中提高了30.2%，DeepSeek-V3中提高了115.7%，Qwen2.5 Max中提高了156.4%。这些一致性的提高证明了这种方法提供了模型无关、成本效益高的修复，并为仓库级别的修复设立了新的基准。"}
{"llm_update_time": "20251006", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2510.03178", "html_url": "https://arxiv.org/abs/2510.03178", "title": "当名称消失：揭示LLMs实际上对代码的理解", "title_en": "When Names Disappear: Revealing What LLMs Actually Understand About Code", "authors": "Cuong Chi Le,Minh V.T. Pham,Cuong Duc Van,Hoang N. Phan,Huy N. Phan,Tien N. Nguyen", "background": "大型语言模型（LLMs）在代码任务中取得了显著成果，但它们如何推断程序意义仍不清楚。本文认为代码通过两条渠道传递信息：结构语义，定义了形式行为，以及人可解释的命名，传递了意图。删除命名渠道严重降低了如总结这类意图任务的表现，而模型退化为逐行描述代码。同时，发现纯粹依赖结构的任务也出现了性能下降，表明当前基准测试倾向于奖励命名模式的记忆而非实际的语义推理。", "innovation": "本文引入了一系列保留语义的混淆措施，表明这些措施能够显示标识符泄漏，跨越总结和执行任务。基于这些洞见，作者发布了ClassEval-Obf，一个强调混淆的基准测试，系统地抑制命名提示并保留行为。研究结果表明，ClassEval-Obf能够减少成绩膨胀的差距，弱化记忆技巧，为评估LLMs对代码的理解和泛化提供了更可靠的基础。", "conclusion": "ClassEval-Obf减少了成绩膨胀的差距，削弱了记忆技巧，并为评估LLMs对代码的理解和泛化提供了更可靠的基础。"}
{"llm_update_time": "20251006", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2510.03078", "html_url": "https://arxiv.org/abs/2510.03078", "title": "从事实到反事实：为智能环境设计和评估反事实解释", "title_en": "From Facts to Foils: Designing and Evaluating Counterfactual Explanations for Smart Environments", "authors": "Anna Trapp,Mersedeh Sadeghi,Andreas Vogelsang", "background": "解释性在规则基础智能环境中的重要性日益凸显。尽管反事实解释能够阐述如何采取不同的行动以实现预期结果，但在解释性AI（XAI）领域中，现有的方法无法生成这些解释，特别是在规则基础环境中。用户对因果解释和反事实解释的偏好具有情境性，在时间紧迫的情况下用户更倾向于选择因果解释，而在想要解决问题时则更偏好反事实解释的内容.", "innovation": "本文首次为规则基础领域的反事实解释提供了一种形式化定义和实现方法，将其作为扩展了现有智能环境解释引擎的插件来实现。通过用户研究评估生成的反事实解释与传统因果解释的有效性，展示了基于具体情境选择不同解释类型的效果指导.", "conclusion": "我们的工作提供了一个实用的框架，用于在智能环境中生成一种新型解释，并通过实验证据指导选择最适合的解释类型."}
{"llm_update_time": "20251006", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2508.01443", "html_url": "https://arxiv.org/abs/2508.01443", "title": "基于元提示调优的代码优化：工业视角", "title_en": "Tuning LLM-based Code Optimization via Meta-Prompting: An Industrial Perspective", "authors": "Jingzhi Gong,Rafail Giavrimis,Paul Brookes,Vardan Voskanyan,Fan Wu,Mari Ashiga,Matthew Truscott,Mike Basios,Leslie Kanthan,Jie Xu,Zheng Wang", "background": "近年来，利用多个大型语言模型（LLMs）进行自动化代码优化引起了广泛关注。然而，工业平台部署多LLM时面临一个关键挑战：针对一个LLM优化的提示往往无法与其它LLM兼容，这要求进行昂贵的模型特定提示工程。这种跨模型的提示工程瓶颈严重限制了多LLM系统的实际部署。", "innovation": "我们介绍了Meta-Prompted Code Optimization（MPCO）框架，它能够自动跨多种LLM生成高质量的任务特定提示，同时保持工业效率要求。MPCO利用元提示动态合成上下文感知的优化提示，整合项目元数据、任务要求和特定LLM上下文。MPCO是ARTEMIS代码优化平台的一部分，专门用于自动化验证和扩展。我们在五个真实代码库上的全面评估显示，MPCO相较于基线方法在整体性能上提高了最高达19.06%，并且在所有系统中获得最好的统计排名。分析表明，96%的顶级优化来自于有意义的修改。通过系统性的消融研究和元提示器敏感性分析，我们发现全面的上下文整合是有效元提示的关键，并且主要LLM可以有效作为元提示器。", "conclusion": "MPCO在多个LLM之间自动生成优化提示，显著提高了代码优化的性能，并提供了针对工业从业者的重要见解。"}
{"llm_update_time": "20251006", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2510.00476", "html_url": "https://arxiv.org/abs/2510.00476", "title": "分析代码语言模型中的隐含概念", "title_en": "Analyzing Latent Concepts in Code Language Models", "authors": "Arushi Sharma,Vedant Pungliya,Christopher J. Quinn,Ali Jannesari", "background": "大型语言模型在代码训练后的内部行为解读依然是一个关键挑战，特别是在需要信任、透明性和语义稳健性的应用场景中。现有的解释框架难以揭示代码语言模型中上下文词嵌入背后的结构，限制了其在代码理解和错误定位中的应用。", "innovation": "提出了Code Concept Analysis (CoCoA)：一个全球后置归因框架。CoCoA通过聚类上下文词嵌入，揭示代码语言模型表示空间中的词法、句法和语义结构，并结合基于静态分析工具的句法对齐与提示工程的大型语言模型，实现跨抽象层次的隐含概念标定。此外，将局部归因方法与LCA整合，产出基于概念的解释，增强词汇级敏感度的解释连贯性和可解释性。", "conclusion": "实验结果显示，LCA在多种模型和任务上发现了在语义保结构扰动下稳定的隐含概念（平均聚类敏感指数CSI = 0.288），并且在微调中表现出可预测的变化。在编程语言分类任务的用户研究中，所提出的概念增强解释相较于词汇级别的归因方法（使用集成梯度）提高了人类中心的可解释性37个百分点。"}
{"llm_update_time": "20251006", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2506.15655", "html_url": "https://arxiv.org/abs/2506.15655", "title": "cAST: 利用抽象语法树进行结构化分块以增强代码检索增强生成", "title_en": "cAST: Enhancing Code Retrieval-Augmented Generation with Structural Chunking via Abstract Syntax Tree", "authors": "Yilin Zhang,Xinran Zhao,Zora Zhiruo Wang,Chenyang Yang,Jiayi Wei,Tongshuang Wu", "background": "检索增强生成（RAG）在大规模代码生成领域变得至关重要，通过将预测与外部代码库中的内容联系起来以提高生成的质量。然而，现有的RAG管道中一个关键但尚未充分探索的问题是分块——即将文档分割为可检索的单元。现有的基于逐行的分块启发式方法通常会破坏语义结构，导致函数被拆分或不相关的代码被合并，从而降低生成质量。", "innovation": "提出了基于抽象语法树（AST）的结构化分块方法（\textbackslashourwork），这是一种结构感知的方法，能够递归地将大的AST节点分解为较小的块，并合并兄弟节点同时遵守尺寸限制。该方法能够在多种编程语言和任务中生成自包含且语义一致的单元，从而提高在多种代码生成任务上的性能，例如，将Recall@5提升了4.3个百分点，Pass@1提升了2.67个百分点。", "conclusion": "本研究强调了结构感知分块对扩展增强检索的代码智能的重要性。"}
{"llm_update_time": "20251006", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2510.02810", "html_url": "https://arxiv.org/abs/2510.02810", "title": "解剖化学生物学：从CLEAR视角走向绿色人工智能", "title_en": "Dissecting Transformers: A CLEAR Perspective towards Green AI", "authors": "Hemang Jain,Shailender Goyal,Divyansh Pandey,Karthik Vaidhyanathan", "background": "大型语言模型（LLMs）的快速采用引起显著的环境问题。LLM推理在全球范围内持续进行，已成为人工智能能耗的主要部分。然而，大多数可持续性研究仅报告粗略的模型级指标，缺乏细粒度的测量方法，这使得能耗效率更多被视为次要目标。本文介绍了一项关于推理能耗的细粒度实证分析，集中在变压器架构的核心组件上。", "innovation": "本文提出了一种新型方法，即Component-Level Energy Assessment via Repeated sampling (CLEAR)，用于克服微秒级组件执行与毫秒级能耗传感器监控之间的时序不匹配问题。使用CLEAR方法，对15种不同架构的15个模型进行了评估，保持了组件级能耗方差低于9.5%，同时捕获了模型总能耗的90%以上。研究表明，注意力块的能量消耗量相对于浮点操作（FLOP）不成比例，这表明单独使用FLOPs无法准确捕捉组件级的真实能耗成本。该研究为通过组件级优化构建能效更高的变压器模型奠定了基础。", "conclusion": "本研究表明，注意力块的能耗与FLOP不成比例，表明FLOPs不能准确反映组件级的能耗大小。通过CLEAN，研究人员建立了详细的组件级能耗基准，并为构建能效更高的变压器模型提供了洞察力和初步步骤。"}
{"llm_update_time": "20251006", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2508.20086", "html_url": "https://arxiv.org/abs/2508.20086", "title": "使用预训练编程语言模型的智能合约意图检测", "title_en": "Smart Contract Intent Detection with Pre-trained Programming Language Model", "authors": "Youwei Huang,Jianwen Li,Sen Fang,Yao Li,Peng Yang,Bin Hu", "background": "智能合约中的恶意开发者意图构成了去中心化应用程序的重大安全威胁，导致了巨大的经济损失。为了应对这一挑战，先前引入了SmartIntentNN深度学习模型，用于检测不安全的开发者意图。该模型通过结合通用句子编码器、基于K均值聚类的意图高亮机制以及双向长短期记忆网络（BiLSTM）实现了在10,000个真实智能合约上的F1分数为0.8633。然而，为了进一步提升模型性能，研究团队提出了增强版本的SmartIntentNN2模型。", "innovation": "SmartIntentNN2模型的创新在于，引入了一个基于BERT的预训练编程语言模型，并通过10,000个真实世界智能合约数据集进行了领域适应预训练，使用掩码语言建模目标。此外，模型保留了基于BiLSTM的多标签分类网络以检测意图。在相同的10,000个智能合约的评估集上，SmartIntentNN2实现了显著提升的性能，准确率为0.9789，精确度为0.9090，召回率为0.9476，F1分为0.9279，大幅优于其前身和其他基准模型。值得注意的是，与GPT-4.1的专用任务比较，SmartIntentNN2在F1分数上取得了65.5%的相对提升。研究表明，SmartIntentNN2是智能合约意图检测的新最先进的模型。", "conclusion": "SmartIntentNN2模型通过引入预训练的BERT编程语言模型，提升了智能合约意图检测的性能，并显著优于现有模型。该方法为智能合约安全性提供了新的研究视角，并展示了深度学习技术在去中心化应用程序中的应用潜力。"}
{"llm_update_time": "20251006", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2503.04076", "html_url": "https://arxiv.org/abs/2503.04076", "title": "Unmasking the Genuine Type Inference Capabilities of LLMs for Java Code Snippets", "title_en": "Unmasking the Genuine Type Inference Capabilities of LLMs for Java Code Snippets", "authors": "Yiwen Dong,Zhenyang Xu,Yongqiang Tian,Chengnian Sun", "background": "代码片段在线共享平台上的代码复用依赖于有效的类型推断。虽然大量的代码片段在平台如StackOverflow上共享，但这些代码往往缺乏关键的类型信息，例如完全限定名(FQNs)。近年来，研究者利用大型语言模型(LLLs)来推断代码片段的类型，取得了相当不错的成果。然而，这些结果可能受到数据泄露的影响，因为用于评估的基准StatType-SO从2017年起就在GitHub上公开。这导致难以确定LLMs的强性能是否反映了对代码的真实语义理解，还是因为训练集包含了真实答案。为了消除这种不确定性，本研究旨在全面评测LLMs在Java代码片段上的类型推断能力，并发现其潜在的局限性。", "innovation": "本研究创新之处在于：1. 创建了ThaliaType，一种新的用于类型推断评估的未公开基准套件。2. 通过使用StarCoder2 LLM作为基线，发现了StarCoder2的开源训练集中存在StatType-SO的数据泄露，并观察到其他最先进的LLMs在ThaliaType上的评估结果都出现了类似的性能下降，精度降低高达59%，召回率降低高达72%。3. 设计了语义保持的代码变换来测试LLMs理解代码片段执行语义的能力。这种评估结果揭示了LLMs在StatType-SO上的表现比在ThaliaType上更不 robust。这一发现强调了设计无泄漏基准的重要性，以评估LLMs在类型推断任务上的真实能力。建议未来研究采用ThaliaType来进行严格和可靠的真实能力评估。", "conclusion": "研究结果表明，精心设计的无泄漏基准对于评估LLMs在类型推断任务上的真实能力至关重要。我们建议未来的研究采用ThaliaType来更好地评估LLMs的真实类型推断能力。"}
{"llm_update_time": "20251006", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2502.18525", "html_url": "https://arxiv.org/abs/2502.18525", "title": "编程与像素：电脑使用代理能否进行软件工程？", "title_en": "Programming with Pixels: Can Computer-Use Agents do Software Engineering?", "authors": "Pranjal Aggarwal,Sean Welleck", "background": "现有电脑使用代理（CUAs）能够执行广泛的一般性任务，但目前对其评估主要集中在简单场景上，这使得我们无法确定这类通用代理是否能够自动化更为复杂和专业化的工作，例如软件工程（SWE）。为探究这一问题，研究人员引入了PwP（Programming with Pixels，编程与像素），这是一种全新的软件工程环境，其中代理通过视觉控制IDE执行多样化软件工程任务。同时，他们还提供了一个涉及多种模态、编程语言和技能的新基准PwP-Bench，包含15项既有的和新的软件工程任务。", "innovation": "研究人员通过引入PwP环境和PwP-Bench基准，全面评估了当前最先进的开放权重和封闭权重的CUAs。他们发现，仅视觉交互时，这些通用代理的表现明显劣于专门的编码代理，但在获得文件编辑和bash操作的API直接访问权限后，它们的性能显著提升，有时甚至达到专门代理的水平。进一步地，当提供额外的IDE工具文本API访问时，所有模型均显示出更明显的改进。该研究分析表明，当前的CUAs存在的主要问题在于视觉关联的局限性和无法充分利用丰富环境的特点。这为未来的改进留下了明确的空间。", "conclusion": "当前存在的CUAs在视觉理解能力有限和无法充分利用复杂环境方面存在局限性，但可通过适当的技术扩展提高其表现，这表明软件工程是一个自然的领域，可以用来评估通用型CUAs是否能够实现专业级别的复杂任务表现。研究同时发布了代码和数据，可以在指定链接访问。"}
{"llm_update_time": "20251006", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2506.24015", "html_url": "https://arxiv.org/abs/2506.24015", "title": "层次化知识注入以提高基于LLM的程序修复效果", "title_en": "Hierarchical Knowledge Injection for Improving LLM-based Program Repair", "authors": "Ramtin Ehsani,Esteban Parra,Sonia Haiduc,Preetha Chatterjee", "background": "提示大型语言模型（LLM）使用与错误相关的上下文（例如错误消息、堆栈跟踪）可以改善自动化程序修复，但许多错误仍然未解决。在实际项目中，开发人员通常依靠更广泛的存储库和项目级上下文，而不仅仅是局部代码来解决这些问题。基于此背景，本文旨在研究如何通过自动提取和提供这样的知识来改善LLM驱动的程序修复。", "innovation": "本文提出了一种分层知识注入框架，该框架能够逐步增强LLM，包括错误知识层、存储库知识层和项目知识层，从而逐步整合错误信息、结构依赖、相关文件历史以及文档和之前修复的有关细节。实验结果表明，通过分层知识注入，对于314个错误中的250个（79%）修复成功，这比之前的工作提高了23%的修复率，尤其是在存储库级别注入上下文方面所有错误类型都有所改进。", "conclusion": "分层上下文注入改善了程序修复，并表明需要交互式和适应性强的程序修复系统。尽管如此，还有一些复杂且结构化的错误（如程序异常和GUI错误）即使在注入所有可用信息后仍然难以修复，这揭示了不同错误类型需要不同上下文信息才能有效修复的需求。"}
{"llm_update_time": "20251006", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2406.07714", "html_url": "https://arxiv.org/abs/2406.07714", "title": "LLAMAFUZZ: Large Language Model Enhanced Greybox Fuzzing", "title_en": "LLAMAFUZZ: Large Language Model Enhanced Greybox Fuzzing", "authors": "Hongxiang Zhang,Yuyang Rong,Yifeng He,Hao Chen", "background": "灰盒 fuzzing 已经在揭露程序中的漏洞和缺陷方面取得了成功，但随机化的变异策略限制了其处理结构化数据的能力。针对复杂结构化数据的专业化 fuzzing 工具虽然能够处理复杂结构的敏感数据，但需要额外努力进行语法规则定义，且吞吐量较低。本文旨在探讨利用大型语言模型（LLM）来增强灰盒 fuzzing 处理结构化数据的方法和前景。", "innovation": "本文提出了一个名为 LLAMAFUZZ 的大型语言模型增强的灰盒 fuzzing 工具。该工具利用预训练的语言模型已有的数据转换和格式化知识生成新的有效输入，并进一步使用配对的变异种子对其进行微调，以有效地学习结构性格式和变异策略。实验证明，与最新竞争对手相比，LLAMAFUZZ 平均提高了 41 个漏洞，并在多种真实程序中表现出稳定的漏洞触发和漏洞到达性能。此外，与 AFL++ 相比，LLAMAFUZZ 在真实程序集中平均分散了 27.19% 更高的分支.", "conclusion": "本文验证了利用 LLM 提升灰盒 fuzzing 处理结构化数据能力的有效性和实用性。LLAMAFUZZ 在实验中的表现证明了这种方法在挖掘新漏洞和提高测试覆盖率方面的显著优势。同时，通过一个案例研究进一步阐释了 LLM 如何在 fuzzing 过程中增强代码覆盖率。"}
{"llm_update_time": "20251006", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2406.15676", "html_url": "https://arxiv.org/abs/2406.15676", "title": "使用机器学习推断插件类型", "title_en": "Inferring Pluggable Types with Machine Learning", "authors": "Kazi Amanul Islam Siddiqui,Martin Kellogg", "background": "可插拔类型系统允许程序员扩展编程语言的类型系统，以强制执行由程序员定义的语义属性。然而，在遗留代码库中部署可插拔类型系统非常困难，因为需要开发人员手动编写类型注解。本文研究如何使用机器学习自动推断类型限定符。通过开发一种称为NaP-AST的新表示法，编码最小的数据流提示，以有效推断类型限定符。", "innovation": "提出了新型表示法NaP-AST，该表示法编码最小数据流提示以有效地推断类型限定符。评估了几种推断类型限定符的模型架构，包括图变换网络（Graph Transformer Network, GTN）、图卷积网络（Graph Convolutional Network, GCN）和大型语言模型。通过将这些模型应用于12个开源程序（从前对方插件类型检查器NullAway的评估中选出），验证了模型的有效性，所有未注释的项目中的警告数量都有所降低，仅有一个项目没有。研究发现在大约16,000个Java类时性能最佳，超过22,000个类时性能下降，可能是因为过拟合。GTN模型表现最佳，召回率为0.89，精度为0.6。此外，本文还研究了训练模型具有良好性能所需的Java类数量。", "conclusion": "研究确定了图变换网络（GTN）在推断类型限定符方面表现出最佳性能。通过评估不同模型架构，发现NaP-AST表示法有效提高了模型推断类型限定符的能力。此外，研究还估计了约16,000个Java类数量能确保模型具有良好性能的阈值。"}
{"llm_update_time": "20251006", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2508.05865", "html_url": "https://arxiv.org/abs/2508.05865", "title": "安全高效的区块链投票：比较框架及大型语言模型的作用", "title_en": "Secure and Scalable Blockchain Voting: A Comparative Framework and the Role of Large Language Models", "authors": "Kiana Kiashemshaki,Elvis Nnaemeka Chukwuani,Mohammad Jalili Torkamani,Negin Mahmoudi", "background": "区块链技术为现代化的E-Voting系统提供了增强透明度、分散化和安全性的重要基础。然而，由于扩展性限制、高计算需求和复杂的隐私要求等因素，实际应用仍然受限。", "innovation": "该论文提出了一种比较框架，分析基于区块链的E-Voting架构、共识机制和加密协议的局限性，并提出了优化策略，包括混合共识、轻量级加密和去中心化身份管理。此外，探讨了大型语言模型在智能合约生成、异常检测和用户交互中的新颖作用。这些发现为设计适合全国规模部署的安全、可扩展和智能的基于区块链的E-Voting系统奠定了基础，并提供了基于大型语言模型辅助智能合约生成和验证的端到端区块链E-Voting原型的建设基础，支持系统方法和基于仿真的分析。", "conclusion": "这项工作为构建由大型语言模型指导的智能合约生成和验证增强的端到端区块链E-Voting原型奠定了基础，支持系统方法和基于仿真的分析。"}
{"llm_update_time": "20251006", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2502.18044", "html_url": "https://arxiv.org/abs/2502.18044", "title": "S-Graphs 2.0 -- 一种分层语义优化和回环检测的SLAM", "title_en": "S-Graphs 2.0 -- A Hierarchical-Semantic Optimization and Loop Closure for SLAM", "authors": "Hriday Bavle,Jose Luis Sanchez-Lopez,Muhammad Shaheer,Javier Civera,Holger Voos", "background": "3D场景图的分层结构在表示方面表现出高相关性，因为它符合人造环境中的常见模式。此外，这样的分层表示中的语义和几何信息可以被利用来加速地图元素和机器人姿态的优化和管理。本文研究了如何利用3D场景图的分层结构来提高数据管理和优化效率，特别是在具有多个楼层的环境中，通过引入S-Graphs 2.0解决相关问题。", "innovation": "第一，提出了前端模块，包括一个用于检测楼层并为底层分配楼层级别语义关系的楼梯检测模块。第二，利用分层表示进行优化，包括：1) 一个窗口内的局部优化，其包括最近关键帧及其跨四个表示层的连接组件；2) 基于楼层级的全局优化，重点关注仅在当前楼层上进行回环闭合的关键帧及其连接关系；3) 基于房间级别的局部优化，通过消除相邻房间中的冗余关键帧来减少计算负担，从而降低关键帧的数量。该方法在多楼层环境中展示了优秀的鲁棒性和计算效率。", "conclusion": "通过S-Graphs 2.0，作者在大规模多楼层环境中实现了在关键帧及其高阶表示层次上的高效优化和回环检测，相比现有基线方法提高了约10倍的优化速度。"}
{"llm_update_time": "20251006", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2509.02372", "html_url": "https://arxiv.org/abs/2509.02372", "title": "Scam2Prompt：用于生产大语言模型中恶意钓鱼端点审计的可扩展框架", "title_en": "Scam2Prompt: A Scalable Framework for Auditing Malicious Scam Endpoints in Production LLMs", "authors": "Zhiyang Chen,Tara Saba,Xun Deng,Xujie Si,Fan Long", "background": "大语言模型（LLMs）在现代软件开发中变得至关重要，但它们依赖于未经过筛选的互联网规模级别的数据集进行训练，这引入了安全风险，包括潜在的恶意内容吸收和再现。为了系统地评估这一风险，该研究介绍了Scam2Prompt，这是一种可扩展的自动化审计框架，用于识别欺诈网站的潜在意图，然后合成模仿这种意图的无害且开发人员风格的提示，从而测试LLM是否会响应这些无害提示生成恶意代码。该研究在四个生产级LLM中进行了大规模研究，发现Scam2Prompt的无害提示在4.24%的情况下触发了恶意URL生成。为评估这种安全风险的持久性，该研究构建了Innoc2Scam-bench基准，包含1,559个无害的提示，能够从最初的四个LLM中持续引发恶意代码。当应用到2025年发布的七个额外的生产级LLM时，发现这一漏洞不仅存在，且十分严重，恶意代码生成率从12.7%到43.8%不等。同时，现有的安全性措施，如最先进的护栏，并未对这一行为提供足够的预防，整体检测率不到0.3%。", "innovation": "提出了Scam2Prompt，一种可扩展的自动化审计框架，通过识别欺诈网站的潜在意图，合成无害的开发者风格提示，测试LLM是否会响应这些提示生成恶意代码；并且通过Innoc2Scam-bench基准评估了这一风险在多个生产级LLM中的存在情况和发展趋势，发现现有安全措施存在局限性无法有效预防此类行为。", "conclusion": "Scam2Prompt框架展示了在生产级LLM中识别和评估恶意欺诈端点的有效方法，同时揭示了现有安全措施的不足，需要进一步改进以确保LLM的安全性。"}
