# 20260108
[![Subscribe_Visitors](https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss)](https://github.com/nituchao/latest_arxiv_analyze_ai)

## 1. `cs.AI` - 通过交互学习用户偏好以实现长期协作 [PDF](https://arxiv.org/pdf/2601.02702), [HTML](https://arxiv.org/abs/2601.02702)
### Authors
Shuhaib Mehri,Priyanka Kargupta,Tal August,Dilek Hakkani-Tür
### Background
随着对话代理与用户合作的经验积累，适应用户偏好对于建立长期关系和随着时间的推移提高协作质量至关重要。
### Innovation
提出了一个名为MultiSessionCollab的基准测试，旨在评估代理如何学习用户偏好并在多个会话中利用这些偏好来提高协作质量。还介绍了具有持久性和随着互动经验积累而改进用户偏好的记忆功能的长期协作代理，并证明可以从用户模拟器行为中学习信号来训练代理生成更全面的反思并更有效地更新记忆。
### Conclusion
广泛的实验表明，配备记忆功能可以改善长期协作，提高任务成功率，提高活动效率并减少用户努力。最终，还进行了一项用户研究，证明记忆在实际场景中也能够提升用户体验。
## 2. `cs.AI` - 为强化学习策略提供文本解释及其评估 [PDF](https://arxiv.org/pdf/2601.02514), [HTML](https://arxiv.org/abs/2601.02514)
### Authors
Ahmad Terra,Mohit Ahmed,Rafia Inam,Elena Fersman,Martin Törngren
### Background
理解强化学习（RL）策略对于确保自主代理按人类预期行为至关重要。虽然使用可解释的强化学习（XRL）技术可以实现这一目标，但文本解释的正确性难以保证，并且最先进的评估方法仍有限制。
### Innovation
本文提出了一种新型XRL框架，用于生成文本解释、将其转换为透明规则、提高解释质量并进行评估。框架还纳入专家知识，提出自动谓词生成器以确定状态的语义信息，并通过大型语言模型（LLM）和聚类技术生成文本解释。此外，还提出了两种改进技术来提高解释质量并减少矛盾信息。
### Conclusion
该框架解决了现有方法（自主策略解释）的局限性，并生成的透明规则在某些任务上表现良好。该框架还提供了对文本解释进行系统和定量评估的方法，为XRL领域的研究提供了有价值的见解。
## 3. `cs.AI` - SimpleMem：LLM代理的高效终身记忆 [PDF](https://arxiv.org/pdf/2601.02553), [HTML](https://arxiv.org/abs/2601.02553)
### Authors
Jiaqi Liu,Yaofeng Su,Peng Xia,Siwei Han,Zeyu Zheng,Cihang Xie,Mingyu Ding,Huaxiu Yao
### Background
为了在复杂环境中支持可靠的长期交互，LLM代理需要有效的记忆系统来管理历史经验。现有的方法要么通过被动上下文扩展保留完整的交互历史，带来了大量的冗余，要么依赖迭代推理过滤噪声，导致高token成本。
### Innovation
我们引入了SimpleMem，一种基于语义无损压缩的高效记忆框架。它提出了一种三阶段管道，旨在最大化信息密度和token利用率：(1) 语义结构化压缩，应用熵感知过滤将无结构的交互提炼成紧凑的、多视角索引的记忆单元；(2) 递归记忆汇集，一种异步过程，将相关的单元整合成高层的抽象表示以减少冗余；(3) 适应性查询感知检索，根据查询复杂性动态调整检索范围以高效构建精确语境。
### Conclusion
在基准数据集上的实验显示，我们的方法在准确度、检索效率和推理成本方面始终优于基线方法，平均F1改进了26.4%，而推断时间的token消耗降低了高达30倍，展示了在性能和效率之间优越的平衡。
## 4. `cs.AI` - AWARE-US: 基于个性特征的偏好意识解决基准 [PDF](https://arxiv.org/pdf/2601.02643), [HTML](https://arxiv.org/abs/2601.02643)
### Authors
Mehmet Kurmaz
### Background
调用工具的对话型代理查询结构化数据库时常遇到两个相关的问题：欠定性（缺少运行精确查询所需的约束条件）和不可行性（完全指定的查询返回结果集为空，因为没有条目能满足所有约束条件）。现有工作的处理方式通常是返回“无结果”，或者通过拙劣的规则放宽约束条件，但这种方式可能会违背用户的意图，舍弃用户最关心的需求。
### Innovation
将不可行性处理作为偏好感知查询修复问题：当查询不可满足时，代理应放宽用户最不重要的约束。提出了三种基于大语言模型的方法来从对话中推断相对约束的重要性：（1）局部加权，（2）全局一次性加权，（3）成对排名。实验表明局部加权在偏好对齐方面表现最佳，而全局加权在约束松弛正确性方面表现最佳。还引入了AWARE-US基准，包含基于个性特征的查询，需要代理通过对话进行消歧和按与个性暗示偏好的一致性方式解决不可行性。
### Conclusion
AWARE-US基准验证了三种基于大语言模型的方法的有效性，并展示了如何通过对话解决工具调用代理的不可行性问题，从而更好地维护用户意图。
## 5. `cs.AI` - 面向自主AI的未来之路：挑战与机遇 [PDF](https://arxiv.org/pdf/2601.02749), [HTML](https://arxiv.org/abs/2601.02749)
### Authors
Nadia Sibai,Yara Ahmed,Serry Sibaee,Sawsan AlHalawani,Adel Ammar,Wadii Boulila
### Background
大型语言模型（LLMs）从被动文本生成器进化为自主、目标导向的系统，代表了人工智能领域的一个根本性转变。本文探讨了集成规划、记忆、工具使用和迭代推理的自主智能系统的发展，这些系统能够在复杂环境中自主操作。文章追溯了从统计模型到变压器基系统的技术架构演进，强调了使能自治行为的能力：长距推理、上下文意识和适应性决策。
### Innovation
文章的主要创新在于：(1) 合成LLM能力扩展到自主性的推理-行动-反思循环；(2) 提出一个综合框架，描述感知、记忆、规划和工具执行的核心组件，连接LLM与自主行为；(3) 对应用和持续性的安全、对齐、可靠性和可持续性的关键评估。不同于现有的综述，本文侧重于从语言理解到自主行动的技术架构转变，强调部署前必须解决的技术差距。
### Conclusion
本文指出了关键的研究优先事项，包括可验证的规划、可扩展的多智能体协调、持久性记忆架构和治理框架。负责任的发展需要同时在技术稳健性、解释性和伦理保护方面取得进展，以实现潜力同时减少偏差和未预见后果的风险。
## 6. `cs.AI` - Orchestral AI: 一个代理编排框架 [PDF](https://arxiv.org/pdf/2601.02577), [HTML](https://arxiv.org/abs/2601.02577)
### Authors
Alexander Roman,Jacob Roman
### Background
随着大规模语言模型（LLM）代理框架的迅速增长，开发者在系统开发过程中面临着两个选择：一种是使用特定供应商的软件开发工具包（SDK）从而实现锁定，但缺乏灵活性；另一种则是采用复杂的多包生态系统，这种系统虽然可以提供更多的控制，但也难以确保代码的可复现性和流程控制的清晰性。跨多个LLM供应商集成工具调用成为了一个核心工程挑战，因为各个供应商的API不统一，消息格式不兼容，以及行为的不一致使得构建可移植且可靠的代理系统变得困难。
### Innovation
介绍了一个名为Orchestral的轻量级Python框架，它提供了一个统一且类型安全的接口，用于构建跨多个主要提供商的LLM代理，同时保留了适用于科学研究和生产部署的简单性。Orchestral定义了一个通用的消息、工具和LLM使用表示方法，可以在不同供应商之间无缝工作，消除了手动格式翻译的需求并减少了框架带来的复杂性。此外，自动从Python类型提示生成工具方案描述符，同时保持跨提供商的类型安全性。一个同步执行模型结合了流式支持，提供了确定性行为、简便的调试和实时交互，不会引入服务器依赖。框架的模块化架构清晰地分离了供应商集成、工具执行、对话编排和用户界面，使扩展成为可能而不牵涉到架构混乱。Orchestral支持大型框架中找到的高级代理能力，包括丰富的工具调用、上下文提炼、工作区沙盒、用户审批工作流、子代理、内存管理以及MCP集成。
### Conclusion
Orchestral通过提供一个通用且类型安全的编程接口、自动工具方案生成、同步执行模型和模块化架构，简化了跨多个LLM供应商开发代理系统的复杂性，支持丰富的代理功能，促进了便携且可靠代理系统的构建。
## 7. `cs.AI` - 移动设备上实时直播聊天翻译的实证研究 [PDF](https://arxiv.org/pdf/2601.02641), [HTML](https://arxiv.org/abs/2601.02641)
### Authors
Jeiyoon Park,Daehwan Lee,Changmin Yeo,Yongshin Han,Minseop Kim
### Background
尽管设备上的AI模型在效率上有优势，但在实际部署中对其CPU利用率、热条件等实际问题的研究仍然不足。本文通过大量实验，探讨部署设备上的模型时必须解决的两个关键问题：(i) 选择设备上的模型及其资源消耗，(ii) 设备上模型在领域适应方面的能力和潜力。研究聚焦于直播聊天消息即时翻译任务，并手动构建LiveChatBench基准数据库。
### Innovation
本文的创新之处在于通过构建LiveChatBench基准数据库，进行详细的实验研究，评估设备上AI模型在实时直播聊天翻译任务中的表现，同时提出的方法在具体的任务上达到了与商用模型如GPT-5.1相当的性能。
### Conclusion
实验结果表明，尽管为大规模且异构的用户基础提供服务需要仔细考虑资源限制和模型选择等约束条件，但本文提出的方法仍然能够在此特定任务上达到与商业模型相当的性能。我们的发现有望为设备上AI社区提供有意义的见解。
## 8. `cs.AI` - 通过推断因果图形时序逻辑公式来加速长时间任务中的强化学习 [PDF](https://arxiv.org/pdf/2601.02666), [HTML](https://arxiv.org/abs/2601.02666)
### Authors
Hadi Partovi Aria,Zhe Xu
### Background
决策任务经常在具有时空动态的图形上展开。黑盒强化学习往往忽视了局部变化如何通过网络结构传播，这对于采样效率和可解释性是个限制。该研究介绍了一种名为GTL-CIRL的闭环框架，它同时学习策略并挖掘因果图形时序逻辑（Causal GTL）规范。
### Innovation
该方法通过鲁棒性塑形奖励，收集效果失败时的反例，并使用基于高斯过程（GP）的贝叶斯优化来改进参数化的因果模板。GP模型捕捉系统动力学中的空间和时间相关性，使探索复杂的参数空间更有效率。
### Conclusion
在基因网络和电力网络中的案例研究显示，与标准的RL基线相比，这种方法能够更快地学习并展现出更加清晰可验证的行为。
## 9. `cs.AI` - 自身学习的层次性归因提示优化 [PDF](https://arxiv.org/pdf/2601.02683), [HTML](https://arxiv.org/abs/2601.02683)
### Authors
Dongyu Chen,Jian Ma,Xianpeng Zhang,Lei Zhang,Haonan Lu,Chen Chen,Chuangchuang Wang,Kai Tang
### Background
优化在众多学科中都是基础性的，通常遵循一个迭代的过程，通过逐步改进初始解决方案以提升性能。在提示工程中，设计有效提示语以提高大型语言模型的性能也是一项复杂的优化挑战。现有的优化方法往往会导致新的提示破坏之前的成功任务，而重新生成提示则会损害可解释性。
### Innovation
提出了层次归因提示优化（HAPO）框架，包含三大创新：（1）动态归因机制，针对训练数据和提示历史中的错误模式；（2）基于语义单元的优化来编辑功能提示段；（3）多模态友好进步，支持端到端LLM和LLM-MLLM工作流程。
### Conclusion
HAPO在单/多张图像问答（例如OCRV2）和复杂任务分析（例如BBH）等场景中展示了更高的优化效率，并显著优于类似的自动提示优化方法，为可扩展的提示工程提供了可扩展的框架。
## 10. `cs.AI` - Time-Scaling Is What Agents Need Now [PDF](https://arxiv.org/pdf/2601.02714), [HTML](https://arxiv.org/abs/2601.02714)
### Authors
Zhi Liu,Guangzhi Wang
### Background
早期的人工智能范式将认知功能分离为三个部分：神经网络专注于“感知-表示”，强化学习关注“决策-行为”，而符号人工智能则关注“知识-推理”。基于Transformer的大型模型和世界模型使这些范式朝着具备闭环“感知-决策-行动”能力的认知代理收敛。人类在有限的认知资源下，通过时序化序列推理解决复杂问题。语言依赖于问题空间搜索进行深层次的语义推理。尽管早些时候的大型语言模型（LLMs）能够生成流畅的文本，但缺乏持续强大的语义推理能力。通过提示技术如Chain-of-Thought（CoT）和Tree-of-Thought（ToT），这些方法通过使中间步骤显式化扩展了推理路径。然而，这些方法在搜索的完整性和效率方面存在问题。
### Innovation
该研究强调了“时间规标”（Time-Scaling）原则，即通过扩展和优化代理随时间展开推理的能力来进行系统的设计和优化。时间规标是一种利用延长的时间路径的架构设计，能够促进深层次的问题空间探索、动态策略调整和增强元认知控制，类似于在认知限制下人类的序列推理。这代表了增强深度推理和解决问题的关键前沿，无需随着静态模型参数的增加而增加。该研究认为，要提升智能代理的能力，必须将时间规标原则置于核心位置，将显式的暂态推理管理定位为基础。
### Conclusion
时间规标是当前智能代理所需的关键原则，应该是增强智能代理能力的核心框架，通过优化时间管理来提升智能代理的推理和解决问题的能力，而无需依赖于庞大的固定模型参数的增加。
## 11. `cs.CL` - 大型语言模型可以实现社会平衡 [PDF](https://arxiv.org/pdf/2410.04054), [HTML](https://arxiv.org/abs/2410.04054)
### Authors
Pedro Cisneros-Velarde
### Background
大型语言模型（LLMs）能够在与其他代理进行正负互动时被部署。本文在社会学框架下的社会平衡概念下研究了这一现象，该框架解释了代理中集团的形成或多个对抗集团的出现。
### Innovation
研究发现社会平衡依赖于（i）互动类型，（ii）更新机制，和（iii）群体规模。作者通过这些因素分析了实现社会平衡的频率，社会动态的理由，以及互动的多样性与稳定性。
### Conclusion
研究结果表明，这些发现对于代理系统的设计和部署具有指导意义。
## 12. `cs.CL` - 无线网络中增强型多模态数据基础模型的预测与控制：综述 [PDF](https://arxiv.org/pdf/2601.03181), [HTML](https://arxiv.org/abs/2601.03181)
### Authors
Han Zhang,Mohammad Farzanullah,Mohammad Ghassemi,Akram Bin Sediq,Ali Afana,Melike Erol-Kantarci
### Background
基础模型（FMs）被认为是人工智能（AI）未来的重要变革，正在重塑学术界和工业界的未来。将FMs集成到无线网络中，有望实现能够处理多样化的网络管理请求和高度复杂的与多模态数据相关的无线任务的通用AI代理。
### Innovation
本文讨论了在无线网络中利用FMs，尤其是多模态FMs的应用。文章重点介绍了无线网络管理中的两类重要任务：预测任务和控制任务，并详细说明了FMs如何分别应用于这两种任务。文章还从可用的数据集开发和所采用的方法论两个角度，介绍了无线专用FMs的发展。
### Conclusion
最后，本文总结了FM增强无线网络的挑战和未来方向。
## 13. `cs.CL` - 揭示自回归大模型在事件表示中的主题契合知识 [PDF](https://arxiv.org/pdf/2410.15173), [HTML](https://arxiv.org/abs/2410.15173)
### Authors
Safeyah Khaled Alshemali,Daniel Bauer,Yuval Marton
### Background
该研究背景在于探讨自回归语言模型（LLM）在处理事件表示时的主题契合知识的掌握情况。研究对比了封闭模型和开放模型在这方面的表现，并分析了多步推理、生成句子以及输出形式等因素对模型性能的影响。
### Innovation
研究发现封闭模型在主题契合知识方面表现较好，并创新性地揭示了多步推理仅对封闭模型有所帮助，生成的句子反而降低了封闭模型的性能，模型的表现形式对性能影响较小。此外，该研究还设定了新的性能基准。
### Conclusion
研究结论指出，单一的大语言模型要在所有任务中表现最优还需要更多的基本研究工作，并且难以进一步提升结果。未来需要更多基础研究来优化大语言模型的任务表现。
## 14. `cs.CL` - 生成式AI系统行为的提示反事实解释 [PDF](https://arxiv.org/pdf/2601.03156), [HTML](https://arxiv.org/abs/2601.03156)
### Authors
Sofie Goethals,Foster Provost,João Sedoc
### Background
随着生成式AI系统被集成到实际应用中，组织越来越需要理解并解释这些系统的运行方式。决策者需要了解是什么因素导致生成式AI系统表现出特定的输出特征，而这些因素主要源自于输入提示的内容。但由于生成式AI系统的工作原理不同于传统系统，传统的反事实解释方法无法直接应用于生成式AI系统。为了研究这个问题，作者提出了一种灵活的框架，将反事实解释适应于非确定性生成式AI系统，并展示了生成提示反事实解释（PCE）的算法。
### Innovation
作者提出了一个适应于非确定性生成式AI系统的反事实解释框架，并基于此框架开发了生成提示反事实解释（PCE）的算法。作者还通过三个案例研究展示了PCE在抑制不良输出特征和增强红队演练以揭示不良输出中的新提示方面的作用。这项研究为生成式AI的提示焦点可解释性奠定了基础，有望成为这些模型承担更高风险任务且受到透明度和问责制监管时的重要能力。
### Conclusion
最终，这项研究为生成式AI模型开发了一种提示聚焦的可解释性方法，该方法可以降低其在承担高风险任务及面临透明度和问责制监管要求时的复杂性。
## 15. `cs.CL` - 使用可获取的大模型进行准确的表格问答 [PDF](https://arxiv.org/pdf/2601.03137), [HTML](https://arxiv.org/abs/2601.03137)
### Authors
Yangfan Jiang,Fei Wei,Ergute Bao,Yaliang Li,Bolin Ding,Yin Yang,Xiaokui Xiao
### Background
给定数据库中的表格T和自然语言问题Q，表格问答(TQA)任务旨在根据表格T的内容返回一个准确的答案。最近的先进解决方案利用了大型语言模型(LLMs)，以获取高质量的答案。然而，大多数系统依赖于商业化的、大规模的LLMs，这些模型访问成本高昂，会带来显著的财务障碍。因此，本论文转而关注使用较小的、可开放使用的LLMs进行TQA，这类模型可以在桌面或笔记本电脑上运行。这一设置极具挑战性，因为这类LLMs的性能通常远逊于大型专有模型，使用现有方法时会导致显著的表现下降。
### Innovation
本文提出了一种多代理方法Orchestra，通过协调一组负责相对简单任务的语言模型代理，以结构化的分层工作流程解决复杂的TQA问题，从而显著提高输出的可靠性，并在使用较小到中型模型时实现了强大的性能。Orchestra在开源的多代理框架AgentScope上实现，并在多种TQA基准上使用广泛的开放重量LLMs进行了评估。实验结果表明，即使使用小型模型，Orchestra的表现也与较大的专有模型相当或更优，从而在所有基准上确立了新的最佳性能。
### Conclusion
实验结果表明，Orchestra即使使用小型到中型模型也能达到强大的性能。例如，使用Qwen2.5-14B，Orchestra在WikiTQ上的准确率达到了72.1%，接近使用GPT-4获得的最佳结果75.3%；对于更大的Qwen、Llama或DeepSeek模型，Orchestra超越了所有先前的方法，并在所有基准上建立了新的最佳性能。
## 16. `cs.CL` - Whose story is it? 通过推断作者风格个性化故事生成 [PDF](https://arxiv.org/pdf/2502.13028), [HTML](https://arxiv.org/abs/2502.13028)
### Authors
Nischal Ashok Kumar,Chau Minh Pham,Mohit Iyyer,Andrew Lan
### Background
个性化对于提高交互写作和教育应用程序中的用户体验至关重要，却在故事情节生成方面研究不足。本文研究个性化故事情节生成任务，目标是根据作者的其他作品模仿其写作风格。研究人员收集了来自112位作者的3600个故事，分布于五个不同来源，每个作者平均创作16个故事。通过两个阶段的流水线进行个性化故事情节生成：首先推断作者的隐性写作风格并整理为作者写作表，其次利用定制的个性描述和技术生成个性化的故事情节。实验结果显示，使用作者写作表生成的故事情节优于未个性化的方法，在捕捉作者过去写作风格和与真实作者故事相似度方面分别达到78%和59%的胜率。人类评价进一步支持并突出了某些趋势，例如Reddit故事更易于个性化，以及内容创意性和语言使用比故事情节更容易个性化。
### Innovation
本文创新性地提出了一种两阶段的个性化故事生成方法。首先，通过推断作者的隐性写作风格构建作者写作表，该表经过人工验证确定质量高；其次，使用特定的个性描述和技术生成个性化的故事情节。该方法显著提高了故事情节的个性化程度和相似度。
### Conclusion
使用作者写作表生成的故事情节优于未个性化的方法，在捕捉作者写作风格和提高相似度方面表现优异，人类评价验证了实验结果并发现了一些进一步的个性化趋势。
## 17. `cs.CL` - 无需任务线索和调整的自动提示工程 [PDF](https://arxiv.org/pdf/2601.03130), [HTML](https://arxiv.org/abs/2601.03130)
### Authors
Faisal Chowdhury,Nandana Mihindukulasooriya,Niharika S D'Souza,Horst Samulowitz,Neeru Gupta,Tomasz Hanusiak,Michal Kapitonow
### Background
本文介绍了用于数据库表中晦涩列名扩展（CNE）任务的自动提示工程系统。CNE任务对于表格数据的搜索、访问和理解至关重要，但现有文献对此任务的研究非常有限，尚未有专门应用于CNE任务的自动化提示工程方法的研究成果。
### Innovation
提出了一种设计简单、应用简便的自动提示工程系统，无需调整参数或明确的任务线索即可达到现有的有效程度。该创新方法首次将自动提示工程应用于CNE任务，且首次尝试了除英语之外的其他语言（本研究使用了英语和德语数据集）。
### Conclusion
本文是首次报道将自动化提示工程应用于CNE任务的工作。通过使用双重语言数据集的实验验证，展示了自动化提示工程在处理非英语语言中的潜力和有效性。
## 18. `cs.CL` - 使用大型语言模型预测在线言论的 limit [PDF](https://arxiv.org/pdf/2407.12850), [HTML](https://arxiv.org/abs/2407.12850)
### Authors
Mina Remeli,Moritz Hardt,Robert C. Williamson
### Background
本文研究了在线言论的可预测性，即语言模型能否准确模型化用户生成内容于X（以前的Twitter）的分布。研究基于收集的10M条推文和额外的6.25M条帖子展开。
### Innovation
研究发现了预测个人用户帖子的挑战性，特别是使用用户自身的上下文比使用社交圈的上下文更有效。研究还验证了结果在四个不同规模的语言模型上取得一致，并且发现20%左右的“上下文内学习内容”来自于@提及和标签的使用。此外，研究结果在不同的 demographic 组群中保持了一致。
### Conclusion
预测在线言论的可预测性有限，尤其是针对个人用户。使用用户的自己的历史上下文比社交圈的上下文能更好地预测用户的帖子。研究结果在大型语言模型规模上是可重复的，并且发现20%的“上下文内学习内容”来自于@提及和标签的使用。主要结论在研究的不同 demographic 组群中一致适用。
## 19. `cs.CL` - 使用高效小型语言模型作为企业搜索相关性标签器的微调 [PDF](https://arxiv.org/pdf/2601.03211), [HTML](https://arxiv.org/abs/2601.03211)
### Authors
Yue Kang,Zhuoyi Huang,Benji Schussheim,Diana Licon,Dina Atia,Shixing Cao,Jacob Danovitch,Kunho Kim,Billy Norcilien,Jonah Karpman,Mahmound Sayed,Mike Taylor,Tao Sun,Pavel Metrikov,Vipul Agarwal,Chris Quirk,Ye-Yi Wang,Nick Craswell,Irene Shaffer,Tianwei Chen,Sulaiman Vesal,Soundar Srinivasan
### Background
在企业搜索中，构建大规模的高质量数据集仍然是一个核心挑战，因为难以获得标注数据。由于缺乏高质量且易于访问的企业领域数据集，通过生成合成数据来克服这一挑战。该方法利用大型语言模型（LLM）从示例文档生成现实的企业查询，使用BM25检索硬负例，并利用教师语言模型分配相关性分数。生成的数据集被精简成小型语言模型（SLM），从而高效地进行相关性标注。
### Innovation
本文提出了一种高效的方法，通过微调小型语言模型（SLM）来进行准确的相关性标注。该方法使用基于大规模语言模型的合成数据生成，克服了企业领域缺乏高质量数据集的问题。该方法生成的小型语言模型能够以与最新大型语言模型相媲美的高质量实现高吞吐量、领域特定的相关性标注，同时具有更高的效率和经济性。
### Conclusion
本文的方法对于企业规模检索应用中的可扩展和成本效益高的相关性标注具有重要意义，能够在真实场景中实现快速离线评估和迭代。实验证明，微调后的小型语言模型在企业查询-文档对上达到了与教师语言模型相当甚至更好的相关性标注一致性和评估效率。
## 20. `cs.CL` - 一切系于一例：在RL扩展中的极高标准数据效率 [PDF](https://arxiv.org/pdf/2601.03111), [HTML](https://arxiv.org/abs/2601.03111)
### Authors
Yiyuan Li,Zhen Huang,Yanan Wu,Weixun Wang,Xuefeng Li,Yijia Luo,Wenbo Su,Bo Zheng,Pengfei Liu
### Background
大型语言模型（LLMs）的推理能力可以通过强化学习（RL）得到提升（OpenAI, 2024；DeepSeek-AI等, 2025a；Zeng等, 2025）。现有RL方法在LLMs中的成功通常依赖于成千上万乃至更多的高质量样本。本文挑战了RL对LLMs的数据需求假设，通过展示一-shot学习的有效性来进行挑战。研究表明，通过精心选择一个训练样本，可以在多个跨学科领域中显著提升推理性能，特别是采用数学推理作为指导，设计最优的多学科样本合成件，从而在不同推理基准测试中实现了优于更大数据集训练的表现。
### Innovation
文章创新地提出了多才多艺的学习框架，该框架设计了一种能够触发多学科影响的单个训练样本，并通过以下发现展示了其价值：（1）一个精心挑选的数学推理样本可以在多个领域，包括物理学、化学和生物学中显著提升RL驱动的推理性能；（2）相关推理领域的数学技能揭示了最佳多元博学家样本的特性；（3）一个综合多重学科元素的工程合成样本，在训练表现上优于使用自然出现的单一样本进行训练的表现。此研究证明了样本质量和设计的重要性，而非仅是增加数据量。
### Conclusion
本文研究表明，高质量和设计良好的训练样本是增强语言模型推理能力的关键，而非仅仅增加数据量，这一发现推动了所谓的样本工程概念，即对训练样本进行精准工程设计，从而在不同推理基准测试中实现了优越的表现。
