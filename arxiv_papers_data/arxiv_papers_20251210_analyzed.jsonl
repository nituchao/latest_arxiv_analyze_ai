{"llm_update_time": "20251210", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2512.06240", "html_url": "https://arxiv.org/abs/2512.06240", "title": "AI应用在反洗钱中的可持续和透明金融系统", "title_en": "AI Application in Anti-Money Laundering for Sustainable and Transparent Financial Systems", "authors": "Chuanhao Nie,Yunbo Liu,Chao Wang", "background": "反洗钱和金融欺诈依然是全球经济稳定的重大威胁，每年造成数万亿美元的损失，并对监管监督构成挑战。", "innovation": "本文探讨了人工智能应用如何通过提高检测准确性、降低误报率和减轻手动调查的工作负担来现代化工银洗钱工作流程，还突出了联邦学习（保护隐私的合作）、公平意识和可解释性AI、强化学习（适应性防御）以及结合生成式模型和图检索增强生成（RAG Graph）的半自动人工监督可视化系统，以确保下一代银洗钱架构保持透明、问责和鲁棒性。", "conclusion": "提出了一个基于AI的KYC应用，该应用通过集成图检索增强生成（RAG Graph）和生成模型来增强KYC流程（涉及洗钱检测）的效率、透明度和决策支持能力，实验结果表明，RAG-Graph架构在各种评估设置中表现出高度的准确性和强的相关性，从而提高了KYC持续性、资源优化的合规实践的工作效率和透明度。"}
{"llm_update_time": "20251210", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2512.06404", "html_url": "https://arxiv.org/abs/2512.06404", "title": "GENIUS：自主设计与执行模拟协议的智能代理AI框架", "title_en": "GENIUS: An Agentic AI Framework for Autonomous Design and Execution of Simulation Protocols", "authors": "Mohammad Soleymanibrojeni,Roland Aydin,Diego Guedes-Sobrinho,Alexandre C. Dias,Maurício J. Piotrowski,Wolfgang Wenzel,Celso Ricardo Caldeira Rêgo", "background": "预测原子级模拟已经推动了材料的发现，但设置和调试常规工作仍然需要计算机专家。这知识差距限制了集成计算材料工程（ICME），其中最先进的代码存在但对非专家来说仍然复杂难用。", "innovation": "我们通过GENIUS解决了这一瓶颈，这是一种智能代理工作流，将智能Quantum ESPRESSO知识图谱与由有限状态错误恢复机器监督的分层大型语言模型相结合。研究表明，GENIUS能够将自由形式的人类生成的提示转换为验证过的输入文件，并在约80%的295种不同基准上运行完成，其中76%是自主修复的，成功率呈指数衰减到7%的基线。与仅基于LLM的基础线相比，GENIUS将推理成本减半并几乎消除了幻觉。", "conclusion": "该框架通过智能自动化协议生成、验证和修复，而民主化了电子结构DFT模拟，开启了大规模筛选并加速了全球学术界和工业界的ICME设计循环。"}
{"llm_update_time": "20251210", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2512.06161", "html_url": "https://arxiv.org/abs/2512.06161", "title": "使用临床笔记的自闭症检测深度学习：透明和黑盒方法的迁移学习比较", "title_en": "Deep learning for autism detection using clinical notes: A comparison of transfer learning for a transparent and black-box approach", "authors": "Gondy Leroy,Prakash Bisht,Sai Madhuri Kandula,Nell Maltman,Sydney Rice", "background": "自闭症谱系障碍（ASD）是一种复杂的神经发育状况，其发病率的上升给漫长的诊断过程带来了越来越多的压力。尽管机器学习（ML）在自动化ASD诊断方面显示出前景，但大多数现有模型往往作为黑匣子运作，并且通常仅在单个数据集上进行训练，这限制了它们的泛化能力。", "innovation": "本研究介绍了一种透明且可解释的ML方法，该方法利用BioBERT（一种先进的语言模型）来分析非结构化的临床文本。该模型的训练目的是对行为描述进行标记，并将其映射到诊断标准，然后用于分配最终标签（ASD或非ASD），并通过两个不同的现实世界数据集评估了迁移学习的能力。", "conclusion": "透明模型表现出稳健的表现，尤其是在混合数据训练策略下，结果最好（97%的敏感性，98%的特异性）。而黑盒模型在序列训练或混合数据训练时表现较弱（90%的敏感性，96%的特异性）。整体而言，透明方法优于黑盒方法。混合训练数据导致稍好一些的表现，并且在实际可行的情况下应优先选择这种策略。这项工作为开发更可靠、更可泛化且临床可操作的神经发育诊断AI工具铺平了道路。"}
{"llm_update_time": "20251210", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2512.06573", "html_url": "https://arxiv.org/abs/2512.06573", "title": "信念盒子和开放心态对说服效果的影响", "title_en": "The Effect of Belief Boxes and Open-mindedness on Persuasion", "authors": "Onur Bilgin,Abdullah As Sami,Sriram Sai Vujjini,John Licato", "background": "随着多智能体系统在推理和决策应用中的日益流行，基于LLM（大型语言模型）的智能体需要具备某种形式的命题信念。为了实现这一目标，一种简单的方法是在智能体的提示空间（我们称之为信念盒子）中包含描述其持有的信念的陈述。然而，当智能体包含这些陈述时，它们的行为和对这些信念的态度会受到何种影响？这种行为上的变化是否显著影响了智能体在多智能体场景中的说服能力？同样，如果给智能体指令保持开放心态，这种指令是否会影响其行为？该研究通过一系列实验探讨了这些问题。", "innovation": "该研究通过实验探索了使用信念盒子以及保持开放心态对智能体行为的影响，特别是在它们需要说服其他智能体时。研究发现，指示智能体保持开放心态可以影响它们接受新信念的意愿。同时，这种做法能够影响智能体对反对观点的抵抗力和说服力，特别是在与反对观点数量相当的辩论中，即同伴压力场景中的信念变化可能性。", "conclusion": "研究结果证实了信念盒子技术在推理和决策任务中的可行性和有效性。这种技术通过在智能体的提示空间中包含信念陈述及其强度，来影响智能体对反对观点的抵抗力和说服力，特别是在同伴压力场景中更显著地影响信念变化的几率。"}
{"llm_update_time": "20251210", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2512.06629", "html_url": "https://arxiv.org/abs/2512.06629", "title": "FlatFormer：基于认知偏置注入的扁平Transformer知识追踪模型", "title_en": "FlatFormer: A Flat Transformer Knowledge Tracing Model Based on Cognitive Bias Injection", "authors": "Xiao-li Xia,Hou-biao Li", "background": "KT模型面临一个关键的“性能-复杂性陷阱”：捕捉复杂的认知动态，如学习会话和记忆衰退通常需要深层的层级架构，这会带来实时部署时难以承受的计算成本。", "innovation": "提出了一种名为FlatFormer的简化架构，基于“信息注入与结构堆叠”的新颖设计理念。FlatFormer通过一种混合输入编码策略（结合可学习的会话标识符和固定的正弦步长嵌入）以及直接集成到注意力分数中的预计算幂律偏差，来利用标准的扁平Transformer，从而避免了参数丰富的层级模型的复杂性。", "conclusion": "广泛的实验在四个大规模数据集（例如EdNet，Junyi）上显示FlatFormer达到了最先进的性能。例如，在EdNet数据集上，与最强大的层级基线（HiTSKT）相比，其绝对AUC提高了8.3%，并且参数量不到15%，推理速度大约快了三倍。这些结果验证了认知准确性并不需要复杂的架构。"}
{"llm_update_time": "20251210", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2512.06205", "html_url": "https://arxiv.org/abs/2512.06205", "title": "关于衡量语义绑定和泛化语义绑定问题的研究", "title_en": "On measuring grounding and generalizing grounding problems", "authors": "Daniel Quigley,Eric Maynard", "background": "符号绑定问题探讨如何使象征符号（比如“猫”）真正代表猫，而不是仅仅成为一种在计算中操控的形状。现有研究通常将语义绑定简化为二元判断，而本文作者将其重新构建为一个综合评估框架，该框架通过评价元组（情境，意义类型，威胁模型，参考分布）来衡量多个索引项。这项工作试图填补现有方法的空白，提供一种系统化研究语义绑定的方式。", "innovation": "作者提出了一个新的框架，将语义绑定从二元判断转化为多维度的综合评估。这个框架包括多个关键维度，如真实性（机制存在于代理内部，通过学习或进化获得）、保真度（基础意义保持完整）、系统性（整体由部分有系统地组成）等。该框架用于评价四种不同的绑定模式，并分析了模型理论语义学、大规模语言模型和人类语言在这些维度上的表现。", "conclusion": "作者指出，虽然模型理论语义学实现了精确的组合性但缺乏演化上的正当性，大规模语言模型表现出局部鲁棒性却缺乏世界任务的成功选择，而人类语言则通过进化和发展获得了强的实际正当性。通过操作性地展开关于表示形式的哲学讨论，该研究为科学家、计算机科学家、语言学家和数学家提供了共享语言和技术框架，用于系统地研究语义绑定和意义问题。"}
{"llm_update_time": "20251210", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2512.06296", "html_url": "https://arxiv.org/abs/2512.06296", "title": "模型的锐度和偏见鲁棒性如何？知识图谱补全的双重评估视角", "title_en": "How Sharp and Bias-Robust is a Model? Dual Evaluation Perspectives on Knowledge Graph Completion", "authors": "Sooho Moon,Yunyong Ko", "background": "知识图谱补全（KGC）旨在从已观察到的知识图谱中预测缺失的事实。尽管已经研究了一系列KGC模型，但KGC的评估仍然未被充分探索。现有的评估指标忽视了KGC评估中的两个关键视角：（A1）预测锐度 —— 在评估个别预测时的严格程度，以及（A2）流行性偏见鲁棒性 —— 预测低流行实体的能力。", "innovation": "本文提出了一种新的评估框架（PROBE），该框架由两个组件组成：（1）排名转换器（RT），基于所需的预测锐度来估计每个预测的得分；（2）排名聚合器（RA），以流行性感知的方式聚合所有得分。实验表明，现有的评估指标倾向于高估或低估KGC模型的准确性，而PROBE则能提供对KGC模型的全面理解并产生可靠的评估结果。", "conclusion": "实验结果揭示了现有KGC模型的评估指标存在局限性，而PROBE能够全面、可靠地评估和理解这些模型。"}
{"llm_update_time": "20251210", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2512.06393", "html_url": "https://arxiv.org/abs/2512.06393", "title": "LLM泛化能力在规则删除、改写和压缩下的多步逻辑推理中的更少即是更多", "title_en": "Less Is More for Multi-Step Logical Reasoning of LLM Generalisation Under Rule Removal, Paraphrasing, and Compression", "authors": "Qiming Bao,Xiaoxuan Fu", "background": "大型语言模型（LLMs）在许多自然语言任务上表现出色，但在面对逻辑语境中的结构性干扰时的一般化能力仍然知之甚少。", "innovation": "本文提出了一种控制评估框架，通过四项针对的压力测试来探测推理可靠性：1）规则删除，删除多步推理链中的冗余或必要规则；2）引入矛盾证据；3）通过几种等价律家族生成保留逻辑的重新写法（如反命题、双重否定、蕴含、德·摩根、等价、恒等性和交换律）；4）多律等价叠加，引入2-5个同时的逻辑变换。该研究覆盖了三个代表性模型家族：BERT、Qwen2、以及类似LLaMA的模型。", "conclusion": "实验揭示了一个显著一致的模式：所有模型在基础任务上均达到完美准确率，并且能够在冗余规则删除和所有基于等价律的重写（单律或多律）的情况下全面推广。但当面对必要的规则删除（降到25%的准确率）和出现明明确切矛盾时（0%的准确率），模型表现明显下降。这些结果表明LLMs对语义保存的逻辑转换具有稳定的不变性，然在缺失或冲突证据方面仍然基础脆弱。本文的框架提供了一种干净的诊断工具，以隔离此类推理失败模式，并突显当前LLMs在逻辑泛化能力方面的持续缺失。"}
{"llm_update_time": "20251210", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2512.06431", "html_url": "https://arxiv.org/abs/2512.06431", "title": "埃及智能空间规划：基于算法的城市公共服务评估方法——以坦尼市为例", "title_en": "Smart Spatial Planning in Egypt: An Algorithm-Driven Approach to Public Service Evaluation in Qena City", "authors": "Mohamed Shamroukh,Mohamed Alkhuzamy Aziz", "background": "埃及的国家规划标准往往未能与当地的独特特征对齐。本研究针对这一问题，在坦尼市开发了一种定制化的规划模型。该模型采用混合方法（描述性、分析性和实验性），利用Python编程生成基于Voronoi图的空间智能分析算法，以创建城市特定的规划标准并评估公共设施的当前覆盖情况。", "innovation": "本研究的主要贡献在于成功地开发了一个适用于当地的城市规划标准模型，并部署了一种自动化算法来评估服务效率。该模型揭示了服务覆盖的一般平均值为81.3%，其中救护车站效率最高（99.8%），而公园和开放空间的覆盖率最低（10%）。通过空间分析，研究发现市中心的服务密度最高（>45服务/km²），而郊区的服务密度显著降低（<5服务/km²）。哈杰尔坦尼区有最多的未服务区域，而第1区（Qesm 1）的服务覆盖率最高。", "conclusion": "该模型提供了一个数据驱动的城市规划框架，适用于埃及城市的可持续发展。"}
{"llm_update_time": "20251210", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2512.05998", "html_url": "https://arxiv.org/abs/2512.05998", "title": "全注压在LLM准确度上：虚假预测市场，真实置信信号", "title_en": "Going All-In on LLM Accuracy: Fake Prediction Markets, Real Confidence Signals", "authors": "Michael Todasco(Visiting Fellow at the James Silberrad Center for Artificial Intelligence, San Diego State University)", "background": "大型语言模型（LLM）越来越多地被用来评估其他模型，但这些评估通常缺乏对置信度的表示。本研究旨在通过将评价任务构想为一个赌博游戏（一种拥有自己LLM货币的虚拟预测市场），测试这是否能提高预测准确性并揭示可校准的置信度信号。", "innovation": "将评价任务构想为一个赌博游戏，要求模型预测基线模型是否正确回答问题，并允许模型下注以模拟真实人的决策过程。这一机制旨在创造一种清晰的置信度信号，这在二元的‘是’或‘否’输出中是不存在的。", "conclusion": "尽管使用博弈机制引起的小额赌注并未显著提高准确率（p = .089），但最大的赌注（40,000+) 的正确率接近99%，而小额赌注的正确率仅为74%。这一发现表明简单的金融框架可能有助于使LLMs成为具有风险意识的预测者，从而使内部信念可见并可利用。研究结果提供了一个原始框架，以推进元评价系统和可能成为LLM-对-LLM预测市场的未来工作基础。"}
{"llm_update_time": "20251210", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2512.06653", "html_url": "https://arxiv.org/abs/2512.06653", "title": "LightSearcher: 通过经验记忆实现高效的DeepSearch", "title_en": "LightSearcher: Efficient DeepSearch via Experiential Memory", "authors": "Hengzhi Lan,Yue Yu,Li Qian,Li Peng,Jie Wu,Wei Liu,Jian Luan,Ting Bai", "background": "DeepSearch paradigms 作为深度推理模型的核心使能器，允许模型调用外部搜索工具以获取最新的、领域特定的知识，从而增强推理的深度和事实可靠性。基于这一基础，强化学习（RL）的最新进展进一步赋予模型自主和战略性地控制搜索工具使用的权利，从而优化了何时以及如何查询外部知识源。然而，这些RL驱动的DeepSearch系统常常在准确性和效率之间表现出权衡：频繁调用工具可以提升事实的正确性，但也会导致不必要的计算开销和效率下降。", "innovation": "本文提出了一种高效的RL框架LightSearcher，通过学习对比推理轨迹生成可解释的总结，来生成成功的推理模式的摘要。此外，该框架采用了一种适应性的奖励塑造机制，仅在回答正确的情况下惩罚重复的工具调用。这种设计有效平衡了DeepSearch框架中固有的准确性和效率之间的权衡。", "conclusion": "实验结果显示，LightSearcher 在四个多跳问答基准测试中的准确率与当前最先进的基线ReSearch相当，同时减少了39.6%的搜索工具调用，48.6%的推理时间，以及21.2%的令牌消耗，证明了其优越的效率。"}
{"llm_update_time": "20251210", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2512.06406", "html_url": "https://arxiv.org/abs/2512.06406", "title": "UncertaintyZoo: 一种用于深度学习系统预测不确定性量化的统一工具", "title_en": "UncertaintyZoo: A Unified Toolkit for Quantifying Predictive Uncertainty in Deep Learning Systems", "authors": "Xianzong Wu,Xiaohong Li,Lili Quan,Qiang Hu", "background": "大规模语言模型（LLMs）在各个领域中的应用日益广泛，如问答、自动驾驶和自动软件开发。尽管这样的进展令人振奋，但作为以数据驱动的系统，LLMs常常会产生错误的预测，在关键安全场景中可能导致潜在的损失。已有多种不确定性量化（UQ）方法被提出以应对这一问题，但缺乏将这些方法集成的有效工具，阻碍了UQ方法的实际应用及未来研究。", "innovation": "本文介绍了一个名为UncertaintyZoo的统一工具包，它整合了29种不确定性量化方法，并以标准化接口覆盖了五大类别。通过UncertaintyZoo，作者在CodeBERT和ChatGLM3模型上的代码漏洞检测任务中评估了现有不确定性量化方法的有效性。实验结果表明，UncertaintyZoo能够有效揭示预测不确定性。", "conclusion": "UncertaintyZoo提供了一个用于评估现有不确定性量化方法实用性的平台。用户可以通过该工具了解不同方法的性能，并挖掘潜在的使用场景。项目页面提供了该工具及其演示视频的链接。"}
{"llm_update_time": "20251210", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2512.06710", "html_url": "https://arxiv.org/abs/2512.06710", "title": "《代理评估中的随机性：用内部一致性相关系数量化不一致性》", "title_en": "Stochasticity in Agentic Evaluations: Quantifying Inconsistency with Intraclass Correlation", "authors": "Zairah Mustahsan,Abel Lim,Megna Anand,Saahil Jain,Bryan McCann", "background": "随着大规模语言模型成为更大代理系统的一部分，评估的可靠性变得至关重要，因为不稳定的子代理会引入系统的脆弱性。目前的评估实践仅报告单一准确率数字，无法显示结果的变异，使得无法区分真正的能力提升和幸运抽样。因此，需要一种新的方法来量化这种变异。论文提出使用测量科学中的内部一致性相关系数（ICC）来描述这种变异。", "innovation": "论文提出了采用内部一致性相关系数（ICC）来量化代理系统评估中的随机性。ICC可以将观察到的变异分解为查询间变异（任务难度）和查询内变异（代理一致性），以突出结果反映真能力还是测量噪声。通过此方法，对于代理系统中的子代理替换决策，仅当ICC也有所改善时，准确率提升才可信任。此外，论文还提出了 ICC 在不同任务结构下的表现，并建议将准确性和ICC一起报告以作为标准实践，以促进这一领域的透明和可信度。", "conclusion": "通过对评价稳定性进行可见展示，本文旨在将代理基准测试从不透明的排行榜竞赛转变为有信赖的实验科学。研究团队还提出了新的包含这些指标的评估卡片，并开源了相关代码。"}
{"llm_update_time": "20251210", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2512.06705", "html_url": "https://arxiv.org/abs/2512.06705", "title": "学术期刊的AI政策未能遏制AI辅助学术写作的激增", "title_en": "Academic journals' AI policies fail to curb the surge in AI-assisted academic writing", "authors": "Yongyuan He,Yi Bu", "background": "生成式AI技术在学术写作中的快速应用引发了期刊和出版社的广泛政策回应。然而，这些政策的有效性仍然存在不确定性。本文研究了5,114本期刊和超过5.2万篇论文，以评估AI使用指南在实际中的影响。研究表明，尽管70%的期刊采用了AI政策（主要要求披露），但在各个学科中，研究人员使用AI写作工具的情况依然大幅增加，无论是否有相关政策，增长并无显著差异。特别是非英语国家、物理科学领域和高OA（开放获取）期刊的增长率最高。进一步分析了164,000篇科学出版物的全文，发现自2023年以来发布的75,000篇论文中，只有76篇（0.1%）明确披露了AI使用情况。", "innovation": "本文通过分析大量期刊政策和科学出版物，揭示了当前AI政策在提高透明度和限制AI使用方面的不足。研究方法包括量化评估期刊政策的实施情况和论文中AI使用的披露情况。特别值得一提的是，该研究发现了透明度缺口，即大量论文在使用AI工具方面没有透明披露。这些发现为AI在学术中的应用提供了一个新的视角。", "conclusion": "当前的AI政策未能促进透明度或遏制AI在科研中的应用。作者建议重新评估伦理框架以推动负责任的AI整合。"}
{"llm_update_time": "20251210", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2512.06196", "html_url": "https://arxiv.org/abs/2512.06196", "title": "ARCANE：一个多代理框架以实现解释性和可配置的对齐", "title_en": "ARCANE: A Multi-Agent Framework for Interpretable and Configurable Alignment", "authors": "Charlie Masters,Marta Grześkiewicz,Stefano V. Albrecht", "background": "随着基于大语言模型的代理越来越多地部署到长期任务中，确保它们与利益相关者的偏好保持一致变得至关重要。在这样的环境中，有效的对齐需要可解释的奖励模型，这样利益相关者可以理解并审查模型目标。此外，需要的奖励模型必须能够在互动期间引导代理，并允许偏好变化的纳入而无需重新训练。", "innovation": "作者提出了一个名为ARCANE的框架，该框架将对齐问题视为一个多代理合作问题，直接从任务上下文中动态代表利益相关者的偏好。ACRANGE通过一组加权且可验证的标准集合（称为rubrics）来实现这一目标，并对其进行学习。该框架受到效用理论的启发，将其表述为一个重构问题，并采用一种平衡可解释性、忠实度和计算效率的正则化组序列策略优化（GSPO）程序。使用一个包含219个标记的rubrics基准数据集，ACRANGE在需要多步推理和工具使用的能力测试任务上进行了评估。", "conclusion": "通过学习rubrics，ACRANGE产生的评估表达紧凑且易于理解，并且能够灵活地设置权衡，例如正确性与简洁性的权衡，而无需重新训练。研究结果表明，基于rubrics的奖励模型为复杂、长期的AI系统的可解释性及测试时间的自适应对齐提供了一条有前景的路径。"}
{"llm_update_time": "20251210", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2512.06721", "html_url": "https://arxiv.org/abs/2512.06721", "title": "ProAgent:利用按需感官上下文构建前瞻性的大型语言模型代理系统", "title_en": "ProAgent: Harnessing On-Demand Sensory Contexts for Proactive LLM Agent Systems", "authors": "Bufang Yang,Lilin Xu,Liekang Zeng,Yunqi Guo,Siyang Jiang,Wenrui Lu,Kaiwei Liu,Hancheng Xiang,Xiaofan Jiang,Guoliang Xing,Zhenyu Yan", "background": "现有的大型语言模型（LLM）代理主要遵循一种反应式范式，依赖于用户的显式指令来启动服务，这增加了物理和认知的工作负担。因此，论文提出了一个名为ProAgent的新系统，旨在通过利用大量感官上下文和LLM推理来提供更加前瞻性的帮助。", "innovation": "ProAgent 是首个端到端的前瞻代理系统，它采用了一种以前瞻为导向的上下文提取方法和按需分级感知，持续感知环境并提取包含感官和个性提示的层级上下文。ProAgent 还认知增强的前瞻推理技术将这些上下文映射到用户需求和工具调用，提供前瞻性帮助。此外，该系统已经在增强现实（AR）眼镜和边缘服务器上实现，并通过真实世界测试床、公开数据集和用户研究进行了广泛评估。", "conclusion": "研究结果表明，ProAgent 在前瞻性预测准确性、工具调用 F1 分数和用户满意度等方面相对于最先进的基线系统有所提升，标志着向着前瞻性辅助系统迈出了重要的一步。"}
{"llm_update_time": "20251210", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2512.06835", "html_url": "https://arxiv.org/abs/2512.06835", "title": "解耦以泛化：数据稀缺场景下的上下文优先自我进化视觉语言推理学习", "title_en": "Decouple to Generalize: Context-First Self-Evolving Learning for Data-Scarce Vision-Language Reasoning", "authors": "Tingyu Li,Zheng Sun,Jingxuan Wei,Siyuan Li,Conghui He,Lijun Wu,Cheng Tan", "background": "最近的视觉语言模型（VLMs）通过强化学习（RL）实现了显著的推理能力，为实现连续自我进化的大型视觉语言模型（LVLMs）提供了可行的解决方案。然而，对于像化学、地球科学和多模态数学这类专业领域，VLMs所需的大量高质量多模态数据非常稀缺，现有的策略比如合成数据和自奖励机制受限于分布有限性和对齐困难，最终导致了奖励作弊问题：模型利用高奖励模式，政策熵减少，训练不稳定。", "innovation": "本文提出了DoGe（Decouple to Generalize）框架，这是一种双重解耦框架，旨在通过重新聚焦合成数据方法忽视的问题情境，让模型先从上下文学习而不是直接解决问题。框架将学习过程分为思考者和解决问题两个组件，并通过两个阶段的RL后训练方法合理量化奖励信号，从自由探索上下文到实际解决任务。此外，为了增加训练数据的多样性，DoGe构建了一个进化式课程学习管道，包括扩展的原生领域知识库和逐步进化的种子问题池。", "conclusion": "实验表明，我们的方法在各种基准测试中持续优于基线方法，为实现自我进化的LVLMs提供了一种可扩展的途径。"}
{"llm_update_time": "20251210", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2512.06859", "html_url": "https://arxiv.org/abs/2512.06859", "title": "JT-DA: 通过集成工具的表格推理大规模语言模型提升数据分析", "title_en": "JT-DA: Enhancing Data Analysis with Tool-Integrated Table Reasoning Large Language Models", "authors": "Ce Chi,Xing Wang,Zhendong Wang,Xiaofan Liu,Ce Li,Zhiyan Song,Chen Zhao,Kexin Yang,Boshen Shi,Jingjing Yang,Chao Deng,Junlan Feng", "background": "该研究旨在解决表格推理场景中高质量监督的缺乏问题。为此，作者构建了一个包含34个具有明确定义的表格推理任务的综合数据集，该数据集由29个公开的表格问答数据集和300万表格组成。同时提出了一个自动管道来生成涉及推理模式的现实多步骤分析任务。", "innovation": "该研究提出了一个专门用于复杂表格推理任务的大规模语言模型JT-DA-8B。模型通过开源的JT-Coder-8B模型训练而成，这是一个从头开始进行训练的8亿参数解码器基础模型。研究采用了基于LLM的评分和工作流对齐过滤来提取高质量的以表格为中心的数据。模型优化采用了监督微调（SFT）和强化学习（RL）的技术，并提出了一种四阶段表格推理工作流，包括表格预处理、表格感知、工具集成推理和提示工程，以提高模型的解释性和执行准确性。", "conclusion": "实验证明，JT-DA-8B在各种表格推理任务中表现出强大的性能，验证了以数据为中心的生成和工作流驱动优化的有效性。"}
{"llm_update_time": "20251210", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2512.07081", "html_url": "https://arxiv.org/abs/2512.07081", "title": "ClinNoteAgents: 基于LLM的多智能体系统，用于从临床记录预测和解释心脏衰竭30天再入院情况", "title_en": "ClinNoteAgents: An LLM Multi-Agent System for Predicting and Interpreting Heart Failure 30-Day Readmission from Clinical Notes", "authors": "Rongjia Zhou,Chengzhuo Li,Carl Yang,Jiaying Lu", "background": "心脏衰竭（HF）是美国老年人再入院的主要原因。临床笔记包含丰富的患者信息，占电子健康记录(EHR)的很大比例，但这些笔记尚未广泛用于HF再入院风险分析。传统的HF再入院计算模型通常依赖于专家规则、医学词典和本体来解析临床笔记，但这些笔记往往是在时间压力下撰写的，可能会有拼写错误、缩写和领域特定的专业术语。", "innovation": "ClinNoteAgents 是一种基于LLM的多智能体框架，能够将自由文本临床笔记转化为可用于关联分析的临床和社会风险因素的结构化表示，以及适用于HF 30天再入院预测的临床风格抽象。该框架通过减少对结构化字段的依赖并最小化手动标注和模型训练，提供了一种在数据有限的医疗保健系统中进行基于笔记的HF再入院风险建模的可扩展和可解释的方法。", "conclusion": "在2065名患者（再入院率=35.16%）的3,544份自由文本临床笔记上评估ClinNoteAgents，结果表明其在提取风险因素、识别关键因素及预测再入院风险方面表现出色。"}
{"llm_update_time": "20251210", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2512.07109", "html_url": "https://arxiv.org/abs/2512.07109", "title": "神经关联框架：通过程序任务分类诊断Transformer架构的组合差距", "title_en": "A Neural Affinity Framework for Abstract Reasoning: Diagnosing the Compositional Gap in Transformer Architectures via Procedural Task Taxonomy", "authors": "Miguel Ingram,Arthur Joseph Merritt III", "background": "Hodel等人（2024）呼吁为再弧（re-arc）中的任务相关性提供正式定义。本文旨在填补这一空白，首次提出了一个涵盖所有400项任务的9类分类法，并通过基于规则的代码分析验证其准确性达97.5%。此外，本文还通过训练CNN（卷积神经网络）对原始ARC-AGI-2测试集进行了诊断性应用，进一步揭示了任务之间的视觉一致性。", "innovation": "本文创新性地提出了一个9类任务分类系统，该分类系统通过基于规则的代码分析验证了97.5%的准确性。更重要的是，通过CNN训练，揭示了210个（69.5%）任务存在组成差距，表现为局部模式识别能力高于全局合成能力的问题，并进一步确认了这种差距与任务关联性的关系。同时，该研究通过与独立研究Li et al. 的结果对比，验证了分类法的预测能力。", "conclusion": "研究发现，任务关联性与性能之间存在显著相关性，任务关联性低的项目更容易达到性能天花板。因此，研究强调了需要设计具有关联性一致模块的混合架构，以促进进展。本文发布了经过验证的任务分类系统，为未来的研究提供了有力工具。"}
{"llm_update_time": "20251210", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2512.06337", "html_url": "https://arxiv.org/abs/2512.06337", "title": "DaGRPO: 基于差异化感知组相对策略优化解决推理中的梯度冲突", "title_en": "DaGRPO: Rectifying Gradient Conflict in Reasoning via Distinctiveness-Aware Group Relative Policy Optimization", "authors": "Xuan Xie,Xuan Wang,Wenjie Wang", "background": "大规模语言模型（LLMs）的发展推动了从表面指令遵循到长期严谨推理的范式转变。尽管组相对政策优化（GRPO）因其出色的性能而成为激发此类后训练推理能力的关键机制，但其仍然受到训练不稳定性严重和样本效率低下的困扰。理论分析表明，这些问题是由于在线策略采样缺乏鲜明度：对于常规查询，高度同质的样本引起梯度冲突；而对于具有挑战性的查询，则由于有效正样本的稀缺性而导致优化效率低下。", "innovation": "提出了一种基于差异化感知的组相对策略优化（DaGRPO），包含两个核心机制：(1) 序列级梯度校正，利用精细的评分动态掩蔽低差异度的样本对，从源头消除梯度冲突；(2) 离策略数据增强，通过引入高质量的锚点恢复复杂任务的训练信号。广泛的实验表明，DaGRPO显著超越了现有的SFT、GRPO和混合基线，实现了新的性能基准（例如，在数学基准上的平均准确率提高了4.7%）。此外，深入分析证实了DaGRPO有效地缓解了梯度爆炸问题，并加速了复杂推理能力的出现。", "conclusion": "DaGRPO通过改进组相对策略优化方法中的梯度冲突缓解和增强机制，显著提高了模型的样本人效率和稳定性，尤其是在处理具有挑战性的推理任务时表现优异，为大规模语言模型的优化提供了新的思路。"}
{"llm_update_time": "20251210", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2512.07178", "html_url": "https://arxiv.org/abs/2512.07178", "title": "ContextualSHAP：通过生成上下文化语言增强SHAP解释", "title_en": "ContextualSHAP : Enhancing SHAP Explanations Through Contextual Language Generation", "authors": "Latifa Dwiyanti,Sergio Ryan Wibisono,Hidetaka Nambo", "background": "可解释的人工智能（XAI）已成为研究中的一个重要领域，特别是在部署在高风险领域的机器学习模型中。SHAP（SHapley Additive exPlanations）方法因其能够提供不同机器学习模型的全局和局部解释而备受关注。然而，SHAP的可视化特征重要性往往缺乏对于最终用户（尤其是非技术人员）来说有意义的上下文解释。为了填补这一空白，本研究提出了一种扩展SHAP的Python包，通过将SHAP与大型语言模型（如OpenAI的GPT）集成，生成针对特定用户视角上下文化的文本解释。这种方法通过用户定义的参数（如特征别名、描述和背景信息）来定制解释，既考虑模型上下文也考虑用户视角。", "innovation": "开发了一种通过大型语言模型生成上下文化文本解释的Python包，作为SHAP的扩展，从而增强SHAP的解释能力。", "conclusion": "通过对一个与医疗保健相关的案例研究进行应用，并通过利克特量表调查和后续访谈，研究结果表明，与仅提供可视化输出相比，结合上下文化的文本可以生成更加易于理解和上下文相关的解释，从而支持更用户友好和可信的模型解释。虽然这些发现是初步的，但它们表明结合可视化与上下文化文本可以提高模型解释的可理解性和可信度。"}
{"llm_update_time": "20251210", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2512.07094", "html_url": "https://arxiv.org/abs/2512.07094", "title": "VIGIL: 自省运行时用于自我修复代理", "title_en": "VIGIL: A Reflective Runtime for Self-Healing Agents", "authors": "Christopher Cruz", "background": "当前的大型语言模型（LLM）框架承诺了自主行为，通过任务分解、工具使用和迭代规划实现，但大多数部署系统依然脆弱。这些系统缺乏运行时自我反省能力，不能诊断自身失败模式，也不需要人类干预的情况下进行改进。实际上，许多代理堆栈退化为带有装饰的LLM调用链，没有结构化的可靠机制。本文讨论的背景是提高代理系统的可靠性和自我修复能力需求。", "innovation": "提出了VIGIL（Verifiable Inspection and Guarded Iterative Learning），一种自省运行时，用于监督旁系代理并执行自主维护。VIGIL能够分析行为日志，将每个事件结构化为情感表示，维护具有衰减和语境策略的持久EmoBank，并从中导出RBT诊断，对最近的行为进行分类。基于此分析，VIGIL生成保护性及时更新和由策略引擎基于日志证据和代码热点生成的只读代码提案。VIGIL作为一个状态门控流水线，非法过渡会生成显式错误，而不是允许LLM即兴应变。在一次提醒延迟案例研究中，VIGIL发现延迟增加，提出了相应的提示和代码修复，并在其诊断工具因模式冲突失效时，表面内部错误，生成备用诊断，并发出修复计划。", "conclusion": "VIGIL展示了部署代理运行时的元水平自我修复能力。"}
{"llm_update_time": "20251210", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2512.06716", "html_url": "https://arxiv.org/abs/2512.06716", "title": "认知控制架构（CCA）：一种实现鲁棒性对齐的AI代理生命周期监督框架", "title_en": "Cognitive Control Architecture (CCA): A Lifecycle Supervision Framework for Robustly Aligned AI Agents", "authors": "Zhibo Liang,Tianze Hu,Zaiye Chen,Mingjie Tang", "background": "大型语言模型（LLM）代理对间接提示注入（IPI）攻击存在显著的脆弱性。这些攻击通过污染外部信息源并利用现有防御机制中安全性和功能性之间的基本权衡，劫持代理行为，导致代理偏离其初始目标，进而恶意使用未经授权的工具。尽管当前防御方法显示了一定的有效性，但大多数防御架构本质上是碎片化的，无法在整个任务执行管道中提供全面的完整性保证，因此在安全、功能性和效率之间导致不可接受的多维度妥协。", "innovation": "论文提出了认知控制架构（CCA），这是一种全方位的认知监督框架。CCA 通过两个协同支柱构建了一个高效、双层的防御系统：（i）通过预先生成的“意图图”实现主动和预防性控制流和数据流完整性控制；（ii）创新的“多层次仲裁器”，在检测到偏差后，基于多维度评分进行深度推理，特别设计用来对抗复杂的条件性攻击。", "conclusion": "实验证明，CCA 不仅有效地抵御了其他高级防御方法面临的复杂攻击，还在效率和鲁棒性方面取得了令人满意的结果，从而成功地解决了安全、功能性和效率之间的多维度权衡。"}
{"llm_update_time": "20251210", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2512.07179", "html_url": "https://arxiv.org/abs/2512.07179", "title": "PICKT: 实际关联概念知识追踪在知识图谱概念关系中的个性化学习中的应用", "title_en": "PICKT: Practical Interlinked Concept Knowledge Tracing for Personalized Learning using Knowledge Map Concept Relations", "authors": "Wonbeen Lee,Channyoung Lee,Junho Sohn,Hansam Cho", "background": "随着个性化学习的兴起，智能辅导系统（ITS）逐渐受到关注。这些系统能够准确追踪学生的个人知识状态，并基于这些信息提供定制的学习路径。现有的知识追踪（KT）模型存在限制，如输入数据格式单一、新的学生或问题加入时出现的冷启动问题，以及在实际运营环境中缺乏稳定性等。", "innovation": "该研究提出了实际关联概念知识追踪（PICKT）模型，该模型能有效处理多种类型的数据输入，通过构建考虑问题和概念文本信息的知识图谱，有效解决冷启动问题。实验结果显示PICKT模型在稳定性和实用性方面有显著改进，能够提高新学生入学和新问题加入这两种核心冷启动挑战下的性能。实验证明了该模型在实际产品环境中的适用性。", "conclusion": "研究的主要贡献在于：首先，提出了一个能够有效利用多种数据格式的模型架构；其次，显著提高了两个关键冷启动挑战的性能；最后，通过精细的实验设计验证了模型的稳定性和实用性，为新一代智能辅导系统的实际应用提供了重要的理论和技术支持。"}
{"llm_update_time": "20251210", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2512.06749", "html_url": "https://arxiv.org/abs/2512.06749", "title": "DoVer：针对LLM多代理系统的干预驱动自动调试", "title_en": "DoVer: Intervention-Driven Auto Debugging for LLM Multi-Agent Systems", "authors": "Ming Ma,Jue Zhang,Fangkai Yang,Yu Kang,Qingwei Lin,Saravan Rajmohan,Dongmei Zhang", "background": "基于大型语言模型（LLM）的多代理系统在调试方面具有挑战性，因为故障通常源自长而分叉的交互跟踪。目前，采用LLM从日志中定位故障并归因于特定代理和步骤是常见的做法。然而，这种方法存在两个关键局限性：（i）仅依赖日志进行调试缺乏验证，产生未经验证的假设；（ii）单一步骤或单一代理的归因通常是不明确的，因为我们发现多个独立干预可以修复故障任务。", "innovation": "提出了DoVer干预驱动的调试框架，通过目标干预（如编辑消息、修改计划）增强假说生成，并进行积极验证。与关注归因准确性不同，DoVer关注衡量系统是否解决故障或在任务成功方向上取得可量化的进步，这体现了更注重结果的调试观点。在Magnetic-One代理框架和来自GAIA和AssistantBench的数据集上，DoVer使18%-28%的失败试验成功，达成最多16%的里程碑进展，并验证或反驳30%-60%的故障假设。在不同的数据集（GSMPlus）和代理框架（AG2）上，DoVer恢复了49%的失败试验。", "conclusion": "这些结果强调了干预作为提高代理系统可靠性的实用机制，并为LLM多代理系统的更稳健、可扩展的调试方法打开了新的可能性。详细信息可在本项目网站及代码网址找到。"}
{"llm_update_time": "20251210", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2512.06983", "html_url": "https://arxiv.org/abs/2512.06983", "title": "关于记忆：世界模型中记忆机制的比较", "title_en": "On Memory: A comparison of memory mechanisms in world models", "authors": "Eli J. Laird,Corey Clark", "background": "世界模型使代理能够在想象的环境中规划，通过根据过去的观察和行动预测未来状态来实现。然而，这些模型在长时序规划中的能力受到基础架构有效记忆跨度的限制。这种限制导致了长过程中的感知漂移，阻碍了模型在其想象轨迹内执行循环闭合的能力。", "innovation": "作者通过分析几种记忆增强机制，探讨了基于变压器的世界模型的有效记忆跨度。引入了一种区分记忆编码和记忆注入机制的分类法，并通过残差流动力学视角探讨了它们如何扩展世界模型的记忆。使用状态重新叫醒评估任务，作者测量了每种机制的记忆重现能力及其各自的权衡。", "conclusion": "研究发现，记忆机制可以提高变压器世界模型的有效记忆跨度，并提供了一种在世界模型的想象中完成循环闭合的途径。"}
{"llm_update_time": "20251210", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2512.07212", "html_url": "https://arxiv.org/abs/2512.07212", "title": "从所见采样：通过具有观测嵌入的随机微分方程的扩散桥进行运动视觉策略学习", "title_en": "Sample from What You See: Visuomotor Policy Learning via Diffusion Bridge with Observation-Embedded Stochastic Differential Equation", "authors": "Zhaoyang Liu,Mokai Pan,Zhongyi Wang,Kaizhen Zhu,Haotao Lu,Jingya Wang,Ye Shi", "background": "模仿学习中利用扩散模型已在机器人的控制中取得了进展，通过捕捉多模态动作分布。然而，现有的方法通常将观测视为去噪网络的高级条件输入，而不是将它们集成到扩散过程自身的随机动态中。因此，采样必须从随机高斯噪声开始，这削弱了感知与控制之间的耦合，并经常导致次优性能。", "innovation": "引入了BridgePolicy，这是一种生成性运动视觉策略，明确地将观测嵌入到随机微分方程中，通过扩散桥公式。通过构建观测信息轨迹，BridgePolicy允许从丰富的、信息性的先验开始进行采样，而不是随机噪声，从而显著提高控制的精度和可靠性。针对不同模态的机器人观测不直接与动作空间对齐的问题，设计了多模态融合模块和语义对齐器，将视觉和状态输入统一对齐，并将观测和动作表示对齐，使桥梁适用于异构机器人数据。", "conclusion": "在三个基准上的52个模拟任务和五个真实世界任务中的广泛实验表明，BridgePolicy始终优于最先进的生成性策略。"}
{"llm_update_time": "20251210", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2512.07314", "html_url": "https://arxiv.org/abs/2512.07314", "title": "M-STAR：多尺度时空自回归模型用于人类移动性建模", "title_en": "M-STAR: Multi-Scale Spatiotemporal Autoregression for Human Mobility Modeling", "authors": "Yuxiao Luo,Songming Zhang,Sijie Ruan,Siran Chen,Kang Liu,Yang Xu,Yu Zheng,Ling Yin", "background": "人类移动性建模对于广泛的实践应用至关重要，如交通运输规划和流行病建模。近年来，随着人工智能生成内容（AIGC）的兴起，研究人员开始探索使用自回归模型和扩散模型生成合成轨迹。这些方法在生成单日轨迹方面显示出潜力，但它们在长期生成（如每周轨迹）方面效率低下，并且缺乏显式的时空多尺度建模。", "innovation": "提出了一个多尺度时空自回归框架M-STAR，通过粗到细的时空预测过程生成长期轨迹。M-STAR结合了多尺度时空编码器，能够捕捉多层次的移动模式，以及基于Transformer的解码器，用于下一尺度的自回归预测。实验结果表明，M-STAR在保真度方面优于现有方法，并显著提高了生成速度。", "conclusion": "该研究提出的M-STAR框架在两个真实数据集上的实验显示，相比现有的方法，M-STAR在保真度方面表现更佳，且显著提高了生成速度。所有数据和代码可以在指定的链接中获得。"}
{"llm_update_time": "20251210", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2512.06867", "html_url": "https://arxiv.org/abs/2512.06867", "title": "Persona-Infused LLMs在战略推理游戏中影响表现", "title_en": "Do Persona-Infused LLMs Affect Performance in a Strategic Reasoning Game?", "authors": "John Licato,Stephen Steinle,Brayden Hollis", "background": "尽管大语言模型中的角色提示似乎能够触发不同风格的生成文本，但尚不清楚这些提示是否会导致可量化的行为差异，更不用说是否会影响我们提供的开源对抗策略环境中决策制定的效果。我们通过研究角色提示对PERIL（一个世界征服棋盘游戏）中战略表现的影响，来探讨这一问题。我们比较了由角色启发的启发式策略与手动选择的启发式策略的有效性。", "innovation": "我们引入了一种作为结构化翻译过程的调解者，该过程受探索性因素分析启发，将LLM生成的清单响应映射到启发式策略中。结果显示，我们的方法在启发式可靠性及面效度上优于直接推断的启发式方法，从而更好地研究不同角色类型对决策的影响。这种方法为基于LLM的决策制定提供了新的视角，并提出了应用心理测量原则生成启发式的方法。", "conclusion": "我们的研究揭示了某些与战略思维相关的角色可提高游戏表现，但这种效果仅能在调解者将角色映射为启发式值时出现。我们展示了如何通过心理测量原则在LLM中生成启发式，为研究角色提示对LLM基于决策的影响提供了新的见解。"}
{"llm_update_time": "20251210", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2512.06990", "html_url": "https://arxiv.org/abs/2512.06990", "title": "在胶质母细胞瘤患者中利用编码-解码架构多智能体强化学习识别最佳切除位置", "title_en": "Utilizing Multi-Agent Reinforcement Learning with Encoder-Decoder Architecture Agents to Identify Optimal Resection Location in Glioblastoma Multiforme Patients", "authors": "Krishna Arun,Moinak Bhattachrya,Paras Goel", "background": "目前，医学领域中缺乏支持医生治疗胶质母细胞瘤（GBM）等异质性脑肿瘤的人工智能系统。GBM是世界上最致命的人类癌症，五年生存率仅为5.1%。该项目开发了一种AI系统，提供从诊断到治疗计划的端到端解决方案。在这个研究中，使用了四种分类模型（CNN和SVM）构建了顺序决策框架，在治疗规划阶段，采用了由三个生成模型组成的强化学习系统。实验结果表明，与现有解决方案相比，项目在计算成本、肿瘤进展推断时间和Dice分数方面都取得了显著改进。", "innovation": "该项目发现以下三个关键发现：(1) 使用包含四个小型分类模型的顺序决策框架减少了22.28倍的计算成本；(2) 使用Transformer降低了肿瘤进展推断时间113小时；(3) 应用与实际情况相似的数据增强提高了整体Dice分数2.9%。这将增加0.9%的存活率，预计可挽救2250条生命。", "conclusion": "该项目利用多智能体强化学习和编码-解码架构的代理，提出了治疗胶质母细胞瘤患者的优化切除位置识别系统，实验证明该系统在多个方面优于现有解决方案。"}
{"llm_update_time": "20251210", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2512.07232", "html_url": "https://arxiv.org/abs/2512.07232", "title": "基于RAEA模型的知识图谱实体对齐的跨平台产品匹配", "title_en": "Cross-platform Product Matching Based on Entity Alignment of Knowledge Graph with RAEA model", "authors": "Wenlong Liu,Jiahua Pan,Xingyu Zhang,Xinxin Gong,Yang Ye,Xujin Zhao,Xin Wang,Kent Wu,Hua Xiang,Houmin Yan,Qingpeng Zhang", "background": "产品匹配旨在识别在不同平台上销售的相同或相似产品。通过构建知识图谱（KG），产品匹配问题可以转换为实体对齐（EA）任务，目标是从多样化的KG中发现等效实体。现有的EA方法未能同时充分利用属性三元组和关系三元组之间的交互，尤其是在这方面的利用不足。", "innovation": "本文提出了一个两阶段的管道，包括粗过滤和细过滤，用于匹配来自eBay和Amazon的产品。在细过滤阶段，引入了一个新的实体对齐框架RREA（关系感知和属性感知图注意力网络进行实体对齐），专注于属性三元组和关系三元组之间的交互，通过属性感知实体编码器和关系感知图注意力网络汇聚实体表示中的对齐信号。", "conclusion": "实验结果表明，RAEA模型在跨语言数据集DBP15K和单语言数据集DWY100K上执行了显著改进（在DBP15K数据集上的平均Hits@1为6.59%），并提供了具有竞争力的结果。实验代码在GitHub上可用。"}
{"llm_update_time": "20251210", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2512.07497", "html_url": "https://arxiv.org/abs/2512.07497", "title": "LLMs在代理情景中如何失败？不同类型LLM在代理模拟中的成功与失败场景的定性分析", "title_en": "How Do LLMs Fail In Agentic Scenarios? A Qualitative Analysis of Success and Failure Scenarios of Various LLMs in Agentic Simulations", "authors": "JV Roig", "background": "本文探讨了大型语言模型（LLMs）作为具备工具使用能力的自主代理时的失败情况。研究团队使用了Kamiwaza Agentic Merit Index (KAMI) v0.1基准，分析了900个执行轨迹，涉及三种代表性模型：Granite 4 Small、Llama 4 Maverick和DeepSeek V3.1，在文件系统、文本提取、CSV分析和SQL场景中的表现。", "innovation": "研究不仅关注整体评分，而是进行了细致分析，探索成功的多步骤工具执行策略和反复出现的失败模式。研究发现模型规模不能单独预测代理鲁棒性：Llama 4 Maverick (400B) 在某些不确定性驱动的任务中仅轻微优于Granite 4 Small (32B)，而DeepSeek V3.1 的可靠性主要源于训练后的强化学习而不是架构或规模。识别了四种反复出现的失败模式：缺乏依据的过早行动、过度帮助导致的缺失实体的替代、分心诱导的上下文污染的脆弱性、以及在负载下的脆弱执行。这些模式强调了注重交互式依据、恢复行为和环境意识的适应性评估方法的重要性，表明可靠的企业部署不仅需要更强的模型，还需要刻意的训练和设计选择来增强验证、约束发现和源数据合规。", "conclusion": "研究结果表明，在代理模拟中，模型规模并不能单独预测代理鲁棒性。可靠的代理模型依赖于交互式的依据、恢复行为的强化和环境知识的适应性。企业部署不仅需要强大的模型，还需要通过训练和设计来确保验证、发现约束和保持数据的真实来源。研究表明，应对复杂多步骤任务需要系统性的策略来提升模型的代理能力。"}
{"llm_update_time": "20251210", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2512.07355", "html_url": "https://arxiv.org/abs/2512.07355", "title": "概念学习的概念锥体几何统一", "title_en": "A Geometric Unification of Concept Learning with Concept Cones", "authors": "Alexandre Rocchi--Henry,Thomas Fel,Gianni Franchi", "background": "本文指出了两种解释性范式——概念瓶颈模型（CBMs）和稀疏自编码器（SAEs）——虽然各自独立地发展，但鲜有交集。CBMs通过监督学习监督激活与人类标注的概念之间的对齐，而SAEs则依赖稀疏编码来发现新兴的概念。尽管两种范式在实际操作上有很大差别，但它们学习的概念空间都具有相同的几何结构：它们均学习了激活空间中的线性方向集合，非负组合形成一个概念圆锥。因此，监督学习和非监督学习方法之间的区别不在于性质的不同，而在于它们如何选择这个圆锥。", "innovation": "本文提出了一种监督和非监督概念学习之间的操作桥梁。CBMs通过提供人类定义的参考几何结构，而SAEs则根据其学习的圆锥体是否接近或包含CBMs的圆锥体来评估其效果。这种方法提供了将归纳偏见——例如SAE类型、稀疏性或扩展因子——与概念的出现联系起来的定量度量。利用这些度量，研究确定了在稀疏性和扩展因子上的“甜蜜点”，最大化了与CBM概念的几何和语义对齐。", "conclusion": "本文通过共享的几何框架统一了监督和非监督概念学习，提供了衡量SAE进展和评估发现的概念是否与合理的、符合人类概念对齐的原理性度量。"}
{"llm_update_time": "20251210", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2512.07611", "html_url": "https://arxiv.org/abs/2512.07611", "title": "PPO、GRPO和DAPO在大型语言模型复杂推理增强中的对比分析与参数调优", "title_en": "Comparative Analysis and Parametric Tuning of PPO, GRPO, and DAPO for LLM Reasoning Enhancement", "authors": "Yongsheng Lian", "background": "本文研究了三种强化学习（RL）算法（PPO、GRPO和DAPO）在提高大型语言模型（LLMs）复杂推理能力方面的系统性比较。", "innovation": "文章的主要贡献是在控制性迁移学习评估中，先将模型在特殊化的Countdown游戏中微调，然后在一系列通用推理基准上进行评估。此外，还提供了关于RL基础LLM训练的实用指导，包括增加GRPO和DAPO中的组大小可以使训练更加稳定和准确，而KL惩罚系数的影响是非单调的。而且发现DAPO中的动态采样（DS）组件并没有提升性能，最好的整体结果是当DS被禁用时实现的。", "conclusion": "除了上述具体发现外，论文还表明，针对不同的RL训练设置，可以根据特定情况实现LLM的推理能力改进。"}
{"llm_update_time": "20251210", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2512.07796", "html_url": "https://arxiv.org/abs/2512.07796", "title": "大型语言模型中的大型因果模型", "title_en": "Large Causal Models from Large Language Models", "authors": "Sridhar Mahadevan", "background": "本文介绍了一种新的构建大型因果模型（LCMs）的范式，该范式利用了当前大型语言模型（LLMs）的巨大潜在能力。DEMOCRITUS系统旨在从精心挑选的文本查询中构建、组织和可视化横跨不同领域的大型因果模型，该模型基于LLMs提出主题、生成因果问题，并从多样化的领域中提取可能的因果陈述。传统的因果推理集中在实验产生的数值数据上，而DEMOCRITUS则在不同领域提取因果关系，这为构建LCMs提供了全新的途径。", "innovation": "DEMOCRITUS系统通过提出主题、生成因果问题和提取领域的因果陈述，为构建大型因果模型提供了一种新的方法。系统的关键技术挑战是如何将这些孤立、碎片化且可能模棱两可或冲突的因果主张编织成一个连贯的整体，将其转化为关系因果三元组并嵌入到LCMs中。为了应对这一技术挑战，本文提出了新的范畴机器学习方法。DEMOCRITUS系统由六个模块组成，本文讨论了其计算成本，确定了扩大系统规模的瓶颈。", "conclusion": "DEMOCRITUS已经在考古学、生物学、气候变化、经济学、医学和技术等多个领域进行了应用，展示了其构建大型因果模型的能力。然而，目前的系统仍存在局限性，需要进一步扩展其功能。"}
{"llm_update_time": "20251210", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2512.07710", "html_url": "https://arxiv.org/abs/2512.07710", "title": "每个提示都重要：在十亿规模的MoE中无需浪费采样进行强化学习", "title_en": "Each Prompt Matters: Scaling Reinforcement Learning Without Wasting Rollouts on Hundred-Billion-Scale MoE", "authors": "Anxiang Zeng,Haibo Zhang,Hailing Zhang,Kaixiang Mo,Liang Yao,Ling Hu,Long Zhang,Shuman Liu,Shuyi Xie,Yanshi Li,Yizhang Chen,Yuepeng Sheng,Yuwei Huang,Zhaochen Xu,Zhiqiang Zhou,Ziqin Liew", "background": "在大规模MoE（门控专家网络）模型中，强化学习（RL）面临许多挑战，包括无效提示的浪费、长时间重要性的计算不稳定性、标准奖励模型造成的优势倒置以及在轨迹处理中的系统瓶颈。", "innovation": "提出了几种统一的创新方法，包括：1）多阶段零方差消除，通过去除无效提示和稳定基于组的策略优化来消除浪费的采样；2）适应熵的优化方法（ESPO），在保持稳定的学习动态的同时平衡了令牌级别和序列级别的重要性采样；3）路由器重导入策略，确保训练和推理时Moe路由器决定的一致性，并结合奖励模型调整以防止优势倒置；4）具有FP8精度采样、交错奖励计算和长度感知调度的高效RL系统，以消除性能瓶颈。", "conclusion": "这些贡献共同形成了一条完整的流水线，使得在十亿规模的MoE模型上进行RL变得稳定和高效。最终模型在内部和公共评测中都表现出强大的性能。"}
{"llm_update_time": "20251210", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2512.05969", "html_url": "https://arxiv.org/abs/2512.05969", "title": "视频模型开始解决象棋、迷宫、数独、心理旋转和瑞文推理测验", "title_en": "Video Models Start to Solve Chess, Maze, Sudoku, Mental Rotation, and Raven' Matrices", "authors": "Hokin Deng", "background": "现有视频生成模型能够在特定任务中进行推理，例如象棋、迷宫、数独、心理旋转和瑞文推理测验，这些任务展现出了一定的逻辑和认知能力。", "innovation": "1. 建立了以“任务对”（Task Pair）设计为核心的强大实验框架。\n2. 提供了一个包含39个模型的代码框架，支持这个实验框架，便于用户高效添加模型和任务。\n3. 自动评估结果显示，这些模型的评估结果与人类判断高度相关，表明这一框架具有很高的扩展性。\n4. 该框架为通过强化学习改进视频模型推理能力提供了机遇。", "conclusion": "现有视频生成模型展示了较强的推理能力，通过实验框架和代码框架的提升，未来有望进一步提高视频模型在推理任务上的表现。用户可以访问相关的原始结果和代码库进行进一步研究。"}
{"llm_update_time": "20251210", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2512.05971", "html_url": "https://arxiv.org/abs/2512.05971", "title": "一种用于 Gentelligent 系统的多目标优化特征选择方法", "title_en": "A Multi-objective Optimization Approach for Feature Selection in Gentelligent Systems", "authors": "Mohammadhossein Ghahramani,Yan Qiao,NaiQi Wu,Mengchu Zhou", "background": "先进科技，特别是人工智能（AI）的集成正逐渐改变制造过程，推动智能系统的开发，以提高效率和自动化水平。文章中引入了“Gentelligent系统”一词，将系统定义为包含内在组件信息（类似于生物信息学中的基因）及自动化机制。通过实施可靠的故障检测方法，制造商可以获得产品质量提高、产量增加和生产成本降低等优势。", "innovation": "提出了一种基于支配式多目标进化算法的混合框架。该机制能够在单一运行中同时优化特征选择和分类性能，探索帕累托最优解，以实现对各种制造操作的监控，解决多种需要同时减轻的冲突目标问题。通过使用两个不同工业领域的现实世界数据集来强化模型的验证，证明了该方法的普适性和有效性。", "conclusion": "该方法有助于制造商更好地适应新兴趋势，通过预测方法的采用，使监控不同制造操作变得更加容易。研究结果表明，该方法在不同工业背景下的数据集上具有良好的适用性和有效性。"}
{"llm_update_time": "20251210", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2512.05979", "html_url": "https://arxiv.org/abs/2512.05979", "title": "加速材料发现：学习通用的化学过程表示以实现跨域属性预测", "title_en": "Accelerating Materials Discovery: Learning a Universal Representation of Chemical Processes for Cross-Domain Property Prediction", "authors": "Mikhail Tsitsvero,Atsuyuki Nakao,Hisaki Ikebata", "background": "化学过程的实验验证过程既费时又昂贵，限制了材料发现领域的探索。现有的机器学习方法可以优先筛选出有潜力的候选材料，但由于专利和文献中的数据是非结构化的且难以使用，使得这一过程变得复杂且效率低下。", "innovation": "本文提出了一种通用的方向树过程图表示方法，将其统一为一个单一的机器可读格式，涵盖了非结构化文本、分子结构和数值测量。为了利用这种结构化数据，我们开发了一种多模态图神经网络，其中包含一种基于属性的注意力机制。该模型在近9000份多样化文档的约70万过程图上进行了训练，能够学习到丰富且具有跨域概括性的嵌入。经过特定领域的微调后，预先训练的模型表现出很强的性能，证明了大规模学习到的通用过程表示可以在最小的数据支持下有效转移至专门的预测任务。", "conclusion": "该模型从大规模结构化数据中学习到的通用过程表示能够有效地转移到专门的应用任务中，显示出其强大的适应性和泛化能力。"}
{"llm_update_time": "20251210", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2512.07761", "html_url": "https://arxiv.org/abs/2512.07761", "title": "RL-MTJail: 基于强化学习的大型语言模型自动黑盒多轮囚徒破解", "title_en": "RL-MTJail: Reinforcement Learning for Automated Black-Box Multi-Turn Jailbreaking of Large Language Models", "authors": "Xiqiao Xiong,Ouxiang Li,Zhuo Liu,Moxin Li,Wentao Shi,Fuli Feng,Xiangnan He", "background": "大型语言模型容易受到囚徒破解攻击，这些攻击威胁到它们在现实世界应用中的安全部署。现有方法通常依赖单一轮次优化，不足以学习长期攻击策略。", "innovation": "本文将问题形式化为多轮强化学习任务，直接优化最终轮次输出的有害性作为结果奖励，同时提出两种启发式过程奖励：（1）控制中间输出的有害性，防止触发黑盒模型的拒绝机制；（2）保持中间输出的语义相关性，避免偏离无关内容。", "conclusion": "实验结果在多个基准上显示了针对多种模型的攻击成功率的一致性提升，展示了该方法的有效性。详情请参见 https://this.is/my/code。请注意：该论文包含有害内容的示例。"}
{"llm_update_time": "20251210", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2512.05987", "html_url": "https://arxiv.org/abs/2512.05987", "title": "自适应数据集量化：一种新的数据集剪裁方向", "title_en": "Adaptive Dataset Quantization: A New Direction for Dataset Pruning", "authors": "Chenyue Yu,Jianyu Yu", "background": "在资源受限的边缘设备中处理大规模数据集时，面临着存储和通信成本的挑战。传统的方法主要集中在减少不同样本之间的冗余，但忽视了同一样本内部冗余内容的压缩。本文提出了一种新的数据集量化方法，旨在通过减少样本内部的冗余内容，同时保留关键特征来降低存储和通信成本。", "innovation": "本文的主要贡献包括：（1）首次使用有限的位数来表示数据集以实现存储减少；（2）提出了一种数据集级的量化算法，并采用了自适应比例分配；（3）通过在CIFAR-10、CIFAR-100和ImageNet-1K上进行大量实验，证明了该方法的有效性，能够在保持模型训练性能的同时实现显著的数据集压缩，并优于传统量化和数据集剪裁基准方法。", "conclusion": "实验结果表明，该方法不仅维持了模型的训练性能，还在相同的压缩比下实现了显著的数据集压缩，优于传统的量化和数据集剪裁基线方法。"}
{"llm_update_time": "20251210", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2512.05988", "html_url": "https://arxiv.org/abs/2512.05988", "title": "VG3T：视觉几何导向的高斯变换器", "title_en": "VG3T: Visual Geometry Grounded Gaussian Transformer", "authors": "Junho Kim,Seongwon Lee", "background": "从多视角图像生成连贯的3D场景表示是一个基本且具有挑战性的任务。现有方法在多视角融合方面常遇到困难，导致生成的3D表示不连贯且性能不佳。", "innovation": "本文提出了VG3T，这是一种新颖的多视角前馈网络，通过3D高斯表示预测3D语义占用率。不同于从前单一视角图像推断高斯的方法，该模型直接以联合多视角的方式预测一组语义化的高斯。此外，引入了基于网格的采样和位置细化两个关键组件，以缓解像素对齐的高斯初始化方法中距离依赖的密度偏差问题。", "conclusion": "VG3T在nuScenes基准上比先前的最优方法在mIoU上提升了1.7%的同时，使用的原语数量减少了46%，突显了其更高的效率和性能。"}
{"llm_update_time": "20251210", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2512.07436", "html_url": "https://arxiv.org/abs/2512.07436", "title": "LocalSearchBench: 实际本地生活服务中代理检索系统的基准测试", "title_en": "LocalSearchBench: Benchmarking Agentic Search in Real-World Local Life Services", "authors": "Hang He,Chuhuai Yue,Chengqi Dong,Mingxue Tian,Zhenfeng Liu,Jiajun Chai,Xiaohan Wang,Yufei Zhang,Qun Liao,Guojun Yin,Wei Lin,Chengcheng Wan,Haiying Sun,Ting Su", "background": "大型推理模型（LRMs）的最新进展使能动性搜索系统能够进行跨多个来源的复杂多步推理。然而，大多数研究集中在一般的信息检索上，很少探索具有独特挑战的垂直领域。在本地生活服务领域，实际查询通常具有歧义性和复杂性，需要在商家和产品之间进行多跳推理，这些挑战仍未得到完全解决。", "innovation": "首次介绍了 LocalSearchBench，这是一个全面的基准测试，专门用于本地生活服务中的代理搜索系统。它包括来自各个城市和业务类型的超过150,000个高质量条目，并构建了基于真实用户查询的300个多跳问答任务。此外，开发了 LocalPlayground，这是一个用于整合多个机器人交互工具的统一环境。", "conclusion": "实验表明，即使是最先进的LRMs，在LocalSearchBench上也表现出挑战性：最佳模型DeepSeek-V3.1的正确性仅为34.34%，且大多数模型在完整性（平均77.33%）和忠实度（平均61.99%）方面存在问题。这突显了在本地生活服务领域需要专门的基准和领域特定的代理培训。代码、基准和排行榜可在指定的网址获取。"}
{"llm_update_time": "20251210", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2512.06006", "html_url": "https://arxiv.org/abs/2512.06006", "title": "简单智能体在生物医学影像工作流优化中优于专家", "title_en": "Simple Agents Outperform Experts in Biomedical Imaging Workflow Optimization", "authors": "Xuefei(Julie)Wang,Kai A. Horstmann,Ethan Lin,Jonathan Chen,Alexander R. Farhang,Sophia Stiles,Atharva Sehgal,Jonathan Light,David Van Valen,Yisong Yue,Jennifer J. Sun", "background": "生产级别的计算机视觉工具适应定制的科学数据是一个关键的瓶颈。现有的解决方案不可行：微调需要大量的标注数据，而科学家往往缺少这些数据；手动代码改编也耗费科学家数周到数月的时间。", "innovation": "作者考虑使用AI智能体来自动化这一手动编码的过程，并重点关注这一特定任务中智能体设计的最佳方案。作者提出了一套系统化的智能体代码优化评估框架，并利用该框架研究了三个生产级别的生物医学成像管道。研究表明，一个简单的智能体框架能够产生优于人类专家解决方案的适应代码，且常见的复杂智能体架构并非通用于此任务。", "conclusion": "研究表明，普通的复杂智能体架构并非适用于所有情况，由此为智能体设计提供了务实的路线图。作者开源了该框架，并通过在生产环境中部署智能体生成的函数，证明了其实现实际影响的明确路径。"}
{"llm_update_time": "20251210", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2512.07795", "html_url": "https://arxiv.org/abs/2512.07795", "title": "ReasonBENCH: 评估大语言模型推理的(不)稳定性", "title_en": "ReasonBENCH: Benchmarking the (In)Stability of LLM Reasoning", "authors": "Nearchos Potamitis,Lars Klein,Akhil Arora", "background": "当前广泛采用的大语言模型（LLM）在需要进行推理，例如多步骤问题解决和演绎思维的情景中越来越普遍。然而，现有的评估实践主要是报告单一运行的准确率，而忽视了从随机解码中自然产生的固有不确定性。这种忽视造成了一种盲点，即实践者无法可靠地评估报告性能的稳定性、可重复性和成本一致性。ReasonBENCH是一个旨在量化LLM推理潜在不稳定性的首个基准。在此基准下，我们可以获得（i）标准化推理框架、模型和任务的模块化评估库，（ii）多运行协议以报告统计上可靠的高质量和成本指标，以及（iii）公共排行榜以促进可变性意识的报告。", "innovation": "ReasonBENCH为LLM推理提供了首个基准，旨在量化其潜在的不稳定特性。它包含了（i）一个模块化的评估库，以统一推理框架、模型和任务的标准；（ii）一个多运行协议，以报告质量和成本的统计上可靠的指标；（iii）一个公开的排行榜，以鼓励关注可变性报告。在各种领域任务中，研究发现大多数推理策略和模型都表现出高度的不稳定性。即使具有相似平均性能的策略也可能显示四倍宽度的信心区间，而且性能最佳的方法通常需要更高的且更不稳定的成本。", "conclusion": "这些不稳定性损害了运行间的一致性，从而影响了报告的性能可靠性。为了更好地了解动态，我们进一步分析了提示、模型家族和规模对解决率和稳定性之间权衡的影响。结果显示，可重复性是可靠LLM推理的关键维度，提供了未来推理方法和不确定性量化技术的基础。ReasonBENCH可在以下网址获取：this https URL."}
{"llm_update_time": "20251210", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2512.06002", "html_url": "https://arxiv.org/abs/2512.06002", "title": "POrTAL: 计划协调的前瞻树组装", "title_en": "POrTAL: Plan-Orchestrated Tree Assembly for Lookahead", "authors": "Evan Conway,David Porfirio,David Chan,Mark Roberts,Laura M. Hiatt", "background": "在人机交互的许多场景中，机器人需要根据给定的宏观目标制定并执行计划，但受限于机器人对环境的部分可观测性，无法完全了解情境，因此需要在不确定性下进行规划。尽管存在许多用于此目的的概率规划算法，但这些算法在考虑机器人有限的计算资源时可能会变得低效，或需要比预期更多的步骤来实现目标。", "innovation": "本文提出了一种新的轻量级概率规划算法，即POrTAL（计划协调的前瞻树组装），该算法结合了两种 baseline 规划算法FF-Replan 和 POMCP 的优势，可以在较少的步骤内快速生成优质的解决方案，同时展示了其在不同时间约束下的性能。", "conclusion": "在一系列案例研究中，POrTAL 证明了其在步数较少的情况下能够迅速找到优于 baseline 算法的解，并且可以适应不同的时间约束条件。"}
{"llm_update_time": "20251210", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2512.05994", "html_url": "https://arxiv.org/abs/2512.05994", "title": "KidSpeak：为儿童语音识别和筛查设计的通用多功能大语言模型", "title_en": "KidSpeak: A General Multi-purpose LLM for Kids' Speech Recognition and Screening", "authors": "Rohan Sharma,Dancheng Liu,Jingchen Sun,Shijie Zhou,Jiayu Qin,Jinjun Xiong,Changyou Chen", "background": "随着对话式和扩散式的AI技术的快速发展，AI在教育服务中的应用日益广泛，涵盖了从自动评分工具和个人化学习系统到提供针对性支持给学生的各种工具。然而，这些工具尚未完全适应儿童的语音领域，现有模型往往由于依赖于设计用于清晰、发音准确的成人语音的数据集而失效。尤其对于早期发展阶段或有语言障碍的儿童，他们提供了独特的挑战，目前的AI模型和数据集无法有效应对。", "innovation": "为了解决上述挑战，我们提出KidSpeak，这是一种多任务的增强基础模型，能够进行生成和判别任务，专门针对儿童的语音模式进行设计。我们的框架采用两阶段训练过程，将音素知识融入到语音编码器中，实现了四个任务平均87%的准确性。此外，考虑到可扩展的人工标注的局限性和现有语音对齐工具的不足，我们提出了Flexible and Automatic Speech Aligner (FASA)工具，并利用该工具构建了高质量的数据集用于训练和评估。这一新型的对齐工具在CHILDES数据集上显著提高了来自噪音数据的对齐儿童语音质量，数据质量提高了13.6倍。", "conclusion": "据我们所知，KidSpeak和FASA是第一个为儿童语言和语言疗法设计的综合解决方案，提供了一种多功能语音大模型和一个稳健的对齐工具。"}
{"llm_update_time": "20251210", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2512.06042", "html_url": "https://arxiv.org/abs/2512.06042", "title": "Auto-SPT: 自动化代码的语义保留变换", "title_en": "Auto-SPT: Automating Semantic Preserving Transformations for Code", "authors": "Ashish Hooda,Mihai Christodorescu,Chuangang Ren,Aaron Wilson,Kassem Fawaz,Somesh Jha", "background": "代码克隆检测的机器学习模型用于判断两段代码是否在语义上等效，这对于软件工程任务如重构和安全任务如漏洞和恶意软件检测是关键组成部分。然而，这些模型大多基于干净且结构化的代码数据集进行训练，而实际情况中的代码会经历各种语义保留变换，例如重构、压缩、自动格式化和编译优化。这使得训练数据与测试数据之间存在关键差距。", "innovation": "提出了一种名为Auto-SPT的新颖框架，用于自动构建合成数据生成器以处理代码。Auto-SPT以大规模语言模型为基础，生成语义保留变换（SPTs），这些变换能够保留程序的功能同时改变其语法结构。通过使用大规模语言模型，Auto-SPT能够生成多元化的SPTs，并组成强大的变换。形式分析表明，SPTs的多样性影响其组合的强度。实验证明，Auto-SPT生成的SPTs比现有方法更加多元，这些SPTs显著降低了最先进的代码克隆检测器的性能。", "conclusion": "进一步的实验表明，Auto-SPT可以用于增强代码数据集的训练，生成对现实世界的、对抗性的代码变换具有鲁棒性的代码克隆检测模型。"}
{"llm_update_time": "20251210", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2512.07810", "html_url": "https://arxiv.org/abs/2512.07810", "title": "审计游戏与反装模策略", "title_en": "Auditing Games for Sandbagging", "authors": "Jordan Taylor,Sid Black,Dillon Bowen,Thomas Read,Satvik Golechha,Alex Zelenka-Martin,Oliver Makins,Connor Kissane,Kola Ayonrinde,Jacob Merizian,Samuel Marks,Chris Cundy,Joseph Bloom", "background": "未来的AI系统可能在评估时隐藏其能力（称为装模），这可能导致开发者和审计人员的误导。为了应对这一挑战，作者通过审计游戏测试了装模检测技术的有效性。", "innovation": "作者使用红蓝团队的策略来加强装模检测研究。红队训练了五个模型，部分模型在某些时候表现较差以模拟装模。蓝队尝试使用黑盒、模型内部或训练方法来识别装模模型，但未能可靠地区分装模模型和良性模型。虽然基于提示的引出策略不够可靠，但基于训练的引出策略能够始终引出装模模型的全部性能，但这也可能导致良性模型的性能提高，存在误报风险。", "conclusion": "短期内，建议开发者使用在分布训练来避免装模。长期来看，需要进一步研究以确保基于训练的引出策略的有效性，并开发更稳健的装模检测方法。作者还提供了可获取的实验模型和相关分析结果的网页链接，以及游戏的演示版本供测试。"}
{"llm_update_time": "20251210", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2512.06020", "html_url": "https://arxiv.org/abs/2512.06020", "title": "PrefGen：多模态偏好学习在个性化图像生成中的应用", "title_en": "PrefGen: Multimodal Preference Learning for Preference-Conditioned Image Generation", "authors": "Wenyi Mo,Tianyu Zhang,Yalong Bai,Ligong Han,Ying Ba,Dimitris N. Metaxas", "background": "现有的偏好条件化图像生成方法要么难以捕捉用户的细腻偏好，要么缺乏有效的机制来编码个性化的视觉信号。该研究旨在通过利用多模态大型语言模型（MLLMs）来提取丰富用户表示并将其注入基于扩散的图像生成中，解决这些问题。", "innovation": "该研究提出了一个利用多模态大型语言模型（MLLMs）来提取用户表示并注入基于扩散的图像生成中的多模态框架。通过一个偏好导向的视觉问答任务来捕捉细微的语义线索。引入两种互补的探针任务来区分不同用户并分离喜欢的内容和不喜欢的内容。设计了一个最大均值差异（MMD）为基础的对齐损失，以桥接模态差距并保持多模态结构，从而实现对生成器的条件化，使生成输出更忠实于提示和用户偏好。", "conclusion": "大量实验证明，该方法在图像质量和偏好对齐方面显著优于强基线，突出了偏好提取和对齐在个性化生成中的有效性。"}
{"llm_update_time": "20251210", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2512.06018", "html_url": "https://arxiv.org/abs/2512.06018", "title": "GenAI支持临床实践的研究生问询模式解析：整合语义网络分析和序贯模式挖掘", "title_en": "Uncovering Students' Inquiry Patterns in GenAI-Supported Clinical Practice: An Integration of Epistemic Network Analysis and Sequential Pattern Mining", "authors": "Jiameng Wei,Dinh Dang,Kaixun Yang,Emily Stokes,Amna Mazeh,Angelina Lim,David Wei Dai,Joel Moore,Yizhou Fan,Danijela Gasevic,Dragan Gasevic,Guanliang Chen", "background": "传统的药物历史采集依赖于人类观察，这限制了其扩展性和详细的数据收集。尽管生成型人工智能（GenAI）平台能够大量收集数据并提供强大的学习分析方法，但这些方法在药剂临床培训中的应用仍较少。本研究通过应用学习分析，探索了使用GenAI驱动的虚拟患者教学中学生临床沟通技能的发展过程。", "innovation": "研究将乙知识网络分析方法与序贯模式挖掘方法相结合，以量化分析学生在使用GenAI虚拟患者过程中表现出的问询模式。研究发现，表现优异的学生在信息识别行为上表现出了战略性部署，而成绩较差的学生则多处于例行问题验证循环之中。不同的人口统计因素，包括第一语言背景、药学工作经历和学校背景，也影响了学生的问询模式。", "conclusion": "研究表明，不同模式的问询可能揭示了在GenAI辅助背景下临床推理的发展。这些发现为医疗专业教育评估提供了方法论上的见解，并为支持多样化学习途径的自适应GenAI系统设计提供了指导。"}
{"llm_update_time": "20251210", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2512.07631", "html_url": "https://arxiv.org/abs/2512.07631", "title": "代理能力问题：通过信息论边界预测可解性", "title_en": "The Agent Capability Problem: Predicting Solvability Through Information-Theoretic Bounds", "authors": "Shahar Lutati", "background": "该研究探讨了当自主代理应投入资源到任务时的最佳时机。提出了一种称为代理能力问题（ACP）的框架，用于在资源限制下预测代理能否解决问题。ACP将问题求解视为信息获取过程，通过信息量和每动作获取的信息量来预测代理的需求。", "innovation": "ACP将问题求解过程重新定义为信息获取过程，提出了一种有效成本$\boldsymbol{\text{Ceff}}$，即$\boldsymbol{\text{Ceff}} = \frac{\boldsymbol{\text{Itotal}}}{\boldsymbol{\text{Istep}}} \times \boldsymbol{\text{Cstep}}$。该框架证明$\boldsymbol{\text{Ceff}}$能下界预测预期成本，并提供了紧的概率上界。实验验证表明ACP的预测与代理实际表现紧密相关，能有效限制搜索努力，提升效率。", "conclusion": "ACP框架适用于LLM基础和代理工作流，统一了主动学习、贝叶斯优化和强化学习中的原理，提供了一种信息理论视角下的解决方案预测方法，能够跨不同类型的代理工作有效应用。"}
{"llm_update_time": "20251210", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2512.06040", "html_url": "https://arxiv.org/abs/2512.06040", "title": "基于物理引导的语音认证系统深度假信息检测", "title_en": "Physics-Guided Deepfake Detection for Voice Authentication Systems", "authors": "Alireza Mohammadi,Keshav Sood,Dhananjay Thiruvady,Asef Nazari", "background": "部署在网络边缘的语音认证系统面临着双重威胁：一是复杂的深度伪造合成攻击；二是分布式联邦学习协议中的控制平面污染。这项研究旨在开发一种能够对抗这些攻击并提供全面威胁模型的框架。", "innovation": "提出了一种结合物理引导深度伪造检测与边缘不确定性学习的系统框架。该框架使用可解释的物理特征来表征声道动态，并结合自助监督学习模块的表示。然后通过多模态集成架构处理这些表示，并通过贝叶斯集成提供不确定性估计。这一方法通过结合基于物理特性的特征评估和音频样本的不确定性估计，使框架能够抵御高级伪造攻击和复杂的控制平面污染。", "conclusion": "该框架有效地解决了网络语音认证系统的双重安全威胁，提供了全面的安全保护，为网络语音认证系统的安全性提供了创新的解决方案。"}
{"llm_update_time": "20251210", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2512.05982", "html_url": "https://arxiv.org/abs/2512.05982", "title": "FlockVote: LLM-Empowered Agent-Based Modeling for Simulating U.S. Presidential Elections", "title_en": "FlockVote: LLM-Empowered Agent-Based Modeling for Simulating U.S. Presidential Elections", "authors": "Lingfeng Zhou,Yi Xu,Zhenyu Wang,Dequan Wang", "background": "建模复杂的人类行为，如国家选举中的选民决策，一直是计算社会科学研究的一大挑战。传统的基于代理的模型（ABMs）受限于简化的规则，而大规模统计模型则缺乏可解释性。", "innovation": "我们引入了FlockVote，这是一种新颖的框架，使用大型语言模型（LLMs）来构建“计算实验室”中的LLM代理，用于政治模拟。每个代理实例化为高保真的人口统计档案和动态上下文信息（例如候选人的政策），使代理能够进行细腻的、生成的推理来模拟投票决策。我们在2024年的美国总统选举中部署了这一框架，重点关注七个关键的摇摆州。我们的模拟在宏观层面的结果成功复制了现实世界的结果，展示了我们“虚拟社会”的高度保真性。", "conclusion": "FlockVote的主要贡献不仅在于预测，还在于框架的实用性，作为可解释的研究工具。FlockVote超越了黑盒输出，允许研究者探针代理级的推理，并分析LLM驱动的社会模拟的稳定性和敏感性。"}
{"llm_update_time": "20251210", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2512.06032", "html_url": "https://arxiv.org/abs/2512.06032", "title": "Segment Anything Model 家族中从 SAM2 到 SAM3 的差距：为什么基于提示的专业知识在概念驱动的图像分割中失效", "title_en": "The SAM2-to-SAM3 Gap in the Segment Anything Model Family: Why Prompt-Based Expertise Fails in Concept-Driven Image Segmentation", "authors": "Ranjan Sapkota,Konstantinos I. Roumeliotis,Manoj Karkee", "background": "本文探讨了最新的两个 Segment Anything 模型：SAM2 和 SAM3 之间的基本断裂。研究指出，在基于提示的分割方面拥有专业知识的 SAM2，其专长并不适用于 multimodal、概念驱动的 SAM3 算法。SAM2 通过空间提示、掩模等多种方式实现几何和时间分割，而 SAM3 则引入了一个统一的视觉-语言架构，能够实现开放词汇推理、语义接地、对比式对齐以及基于示例的概念理解。", "innovation": "本文通过五个核心方面详细分析了这种断裂的原因：(1) 基于提示与基于概念的分割之间的概念性断裂，对比 SAM2 的空间提示语义与 SAM3 的多模态融合和基于文本的掩模生成；(2) 架构差异，概述 SAM2 仅限于视觉-时间设计，而 SAM3 则结合了视觉-语言编码器、几何编码器、示例编码器、融合模块、DETR风格的解码器、对象查询以及通过混合专家处理不确定性；(3) 数据集和注释差异，比较 SAM2 的 SA-V 视频掩模与 SAM3 的多模态概念标注语料；(4) 训练和超参数差异，展示 SAM2 的优化知识不适用于 SAM3；(5) 评估、度量与失败模式，从几何 IoU 度量转向语义、开放型词汇的评估。", "conclusion": "这些分析确立了 SAM3 作为一个新的分割基础模型类别，并勾画出新兴的概念驱动分割时代的未来方向。"}
{"llm_update_time": "20251210", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2512.05993", "html_url": "https://arxiv.org/abs/2512.05993", "title": "专门领域的基础模型提高神经病理学基于AI的分析", "title_en": "Domain-Specific Foundation Model Improves AI-Based Analysis of Neuropathology", "authors": "Ruchika Verma,Shrishtee Kandoi,Robina Afzal,Shengjia Chen,Jannes Jegminat,Michael W. Karlovich,Melissa Umphlett,Timothy E. Richardson,Kevin Clare,Quazi Hossain,Jorge Samanamud,Phyllis L. Faust,Elan D. Louis,Ann C. McKee,Thor D. Stein,Jonathan D. Cherry,Jesse Mez,Anya C. McGoldrick,Dalilah D. Quintana Mora,Melissa J. Nirenberg,Ruth H. Walker,Yolfrankcis Mendez,Susan Morgello,Dennis W. Dickson,Melissa E. Murray,Carlos Cordon-Cardo,Nadejda M. Tsankova,Jamie M. Walker,Diana K. Dangoor,Stephanie McQuillan,Emma L. Thorn,Claudia De Sanctis,Shuying Li,Thomas J. Fuchs,Kurt Farrell,John F. Crary,Gabriele Campanella", "background": "深度学习模型已经改变了计算病理学，通过提供来自大规模数字病理图像的可泛化的表示。然而，现有的模型主要是在手术病理数据上进行训练，这类数据富含非神经组织，并过度代表了多种非神经性疾病的特征。神经病理学涵盖了独特的细胞类型、特定的神经组织结构和诸如神经纤维缠结、淀粉样斑块、路易小体和特定模式的神经退行性变等疾病特征。这些数据域的差异可能导致通用基础模型难以捕捉对于解释神经退行性疾病如阿尔茨海默氏病、帕金森氏病和小脑性共济失调至关重要的形态特征。", "innovation": "本文开发了专门针对大脑组织切片图像训练的基础模型——NeuroFM，该模型涵盖了多样化的神经退行性疾病。与通用基础模型相比，NeuroFM 在涉及混合痴呆疾病分类、海马区分割和神经退行性共济失调识别的神经病理学特定下游任务上表现出更优的性能。这项研究证明了专门针对大脑组织训练的基础模型比在普通手术病理数据集上训练的模型更能捕捉到神经病理学特有的特征。", "conclusion": "通过为神经退行性疾病量身定制基础模型，NeuroFM 使得基于AI的大脑疾病诊断和研究分析更加准确可靠，为特定领域数字病理方向的专业模型开发奠定了先例。"}
{"llm_update_time": "20251210", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2512.06046", "html_url": "https://arxiv.org/abs/2512.06046", "title": "从原型到生产的自主企业级前端开发框架", "title_en": "Beyond Prototyping: Autonomous, Enterprise-Grade Frontend Development from Pixel to Production via a Specialized Multi-Agent Framework", "authors": "Ramprasath Ganesaraja,Swathika N,Saravanan AP,Kamalkumar Rathinasamy,Chetana Amancharla,Rahul Das,Sahil Dilip Panse,Aditya Batwe,Dileep Vijayan,Veena Ashok,Thanushree A P,Kausthubh J Rao,Alden Olivero,Roshan,Rajeshwar Reddy Manthena,Asmitha Yuga Sre A,Harsh Tripathi,Suganya Selvaraj,Vito Chin,Kasthuri Rangan Bhaskar,Kasthuri Rangan Bhaskar,Venkatraman R,Sajit Vijayakumar", "background": "本文介绍了AI4UI框架，它是为了满足企业级应用交付的严格要求而设计的一种专为前端开发定制的自主性代理框架。与用于快速原型设计的一般代码助手不同，AI4UI更侧重于生产就绪的开发，全面介绍并整合了安全、可扩展、合规且可维护的UI代码，这些代码能够无缝嵌入企业工作流中。", "innovation": "AI4UI的创新点在于提供了专用的多个代理的框架，包括自动化设计解释的Figma语法、面向特定领域的知识图谱、安全的抽象/打包代码整合策略、基于专业知识的架构模板以及由专门代理角色管理的以更改为中心的工作流。同时，在大规模基准测试和与行业基准及竞争对手系统的对比测试中，AI4UI显示了其在平台兼容性、编译成功率、安全性合规性、功能实现成功率、代码审查质量、用户界面和用户体验一致性等方面的强大性能。", "conclusion": "AI4UI能够在几周而非几个月内生成数千个验证过的UI屏幕，极大地压缩了交付时间，并在由200位专家评估者进行的盲测中展示了其在众多领先解决方案中的竞争力。"}
{"llm_update_time": "20251210", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2512.07234", "html_url": "https://arxiv.org/abs/2512.07234", "title": "Dropout Prompt Learning: 向稳健且适应性强的视觉-语言模型迈进", "title_en": "Dropout Prompt Learning: Towards Robust and Adaptive Vision-Language Models", "authors": "Biao Chen,Lin Zuo,Mengmeng Jing,Kunbin He,Yuchen Wang", "background": "Dropout 是一种广泛使用的正则化技术，通过随机丢弃神经元来提高模型的泛化能力。该研究基于 dropout 的这一特性，提出了一种新的 dropout 提示学习方法，旨在通过 dropout 技术提升视觉-语言模型的鲁棒性。", "innovation": "该研究引入了 dropout 提示学习方法，首次将 dropout 应用到视觉和文本分支的标记上。通过考虑标记内的模态上下文和模态间对齐，为每个标记灵活设定 dropout 概率。此外，提出残差熵正则化以维持知识传输的一致性，同时鼓励 dropout 引入的多变表征。", "conclusion": "实验表明，该方法在小样本学习、长尾分类和分布外泛化等具有挑战性的场景下表现出色。与基于正则化的 KgCoOp 方法相比，该方法的性能提高了 5.10%，与 PromptSRC 方法相比，性能提高了 2.13%，特别是在从基础类到新类的泛化能力方面。"}
{"llm_update_time": "20251210", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2512.07186", "html_url": "https://arxiv.org/abs/2512.07186", "title": "START: 空间和文本学习在图表理解中的应用", "title_en": "START: Spatial and Textual Learning for Chart Understanding", "authors": "Zhuoming Liu,Xiaofeng Gao,Feiyang Niu,Qiaozi Gao,Liu Liu,Robinson Piramuthu", "background": "图表理解对于在现实场景中部署多模态大语言模型（MLLMs），例如分析科学论文和技术报告至关重要。图表具有空间属性（如结构化布局）和文本属性（如数据表示）。要进行精确和细致的图表推理，必须同时掌握这两方面。现有方法在处理这种双重属性时存在局限性。", "innovation": "为了克服现有方法的局限性，作者提出了START，这是一种同时用于学习图表的空间和文本特性的方法。提出的方法包括（i）图表元素定位和（ii）图表到代码的生成。为了促进空间和文本学习，作者还构造了START数据集，这个数据集通过一个新颖的数据生成管道生成，这个管道首先使用MLLM将实际的图表图像转化为可执行的图表代码，同时保留了实际图表的视觉分布，然后通过大量的语言模型进一步完善代码，以确定图表元素的位置，捕捉图表的视觉结构。此外，还提出了一个图表空间理解基准-CS-Bench，用于综合评估模型的图表空间理解能力。", "conclusion": "通过空间和文本学习，START在各种模型规模和基准上一致地超越了基线模型，并明显超越了之前的最佳方法。所有代码、数据和模型都将公开提供。"}
{"llm_update_time": "20251210", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2512.07215", "html_url": "https://arxiv.org/abs/2512.07215", "title": "VFM-VLM：基于视觉基础模型和视觉语言模型的3D姿态估计视觉比较", "title_en": "VFM-VLM: Vision Foundation Model and Vision Language Model based Visual Comparison for 3D Pose Estimation", "authors": "Md Selim Sarowar,Sungho Kim", "background": "Vision Foundation Models（VFMs）和Vision Language Models（VLMs）通过提供丰富的语义和几何表示，已经革新了计算机视觉领域。本文通过CLIP基于的方法和DINOv2基于的方法对3D手部物体抓取场景中的姿态估计进行了全面的视觉对比。", "innovation": "本文创新性地提出了CLIP和DINOv2两种模型在6D物体姿态估计任务上的对比研究。CLIP在语义理解方面具有优势，而DINOv2在密集几何特征上表现出色。通过在基准数据集上的大量实验，证明了这两种方法在不同的方面表现出互补的优势。", "conclusion": "我们的分析为机器人操作和抓取任务选择合适的视觉模型提供了见解，指明了基于CLIP的方法可以获得更好的语义一致性，而基于DINOv2的方法在几何精度上可与前者竞争。"}
{"llm_update_time": "20251210", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2512.07208", "html_url": "https://arxiv.org/abs/2512.07208", "title": "Geometric Prior-Guided Federated Prompt Calibration", "title_en": "Geometric Prior-Guided Federated Prompt Calibration", "authors": "Fei Luo,Ziwei Zhao,Mingxuan Wang,Duoyang Li,Zhe Qian,Jiayi Tuo,Chenyue Zhou,Yanbiao Ma", "background": "联邦提示学习（FPL）提供了一种参数效率高的解决方案，用于协作训练大型模型，但它在处理数据异质性时受到严重阻碍，这导致本地训练的提示变得有偏。现有方法，集中在聚合或正则化上，未能解决局部训练偏见的根本原因。", "innovation": "我们提出了几何引导文本提示校准（GGTPC），这是一种新型框架，可以直接通过为客户端提供全局几何先验来纠正这一偏见。基于全球数据分布的协方差矩阵推导出的几何先验在服务器端以私有方式重构。客户端在训练期间使用新型几何先验校准层（GPCL）来校准其局部特征分布，以与全球先验对齐。实验表明GGTPC的有效性。", "conclusion": "在标签不均的CIFAR-100数据集（β=0.1）上，它比最新的最佳性能提高了2.15%。在极端偏斜（β=0.01）的情况下，它将基线性能提高了9.17%。此外，作为领域偏斜的Office-Home数据集的良好模块，它提高了FedAvg的性能4.60%。结果显示GGTPC通过校正根本的局部训练偏见有效地缓解了数据异质性，并作为各种FL算法的多功能模块提供了性能提升。"}
{"llm_update_time": "20251210", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2512.07195", "html_url": "https://arxiv.org/abs/2512.07195", "title": "MASim：多语言基于代理的社会科学模拟", "title_en": "MASim: Multilingual Agent-Based Simulation for Social Science", "authors": "Xuan Zhang,Wenxuan Zhang,Anxu Wang,See-Kiong Ng,Yang Deng", "background": "多智能体角色扮演在研究具有语言智能体的社会行为方面已显示出潜力，但现有模拟大多只限于单一语言，无法模拟跨语言的互动，而这一点是现实社会的重要特征。", "innovation": "引入MASim，这是第一个支持具有不同社会语言特征的生成智能体多轮互动的多语言基于代理的模拟框架。MASim提供了两项关键分析：一是全球公共意见建模，通过模拟普遍性假设在不同语言和文化中的态度演变；二是媒体影响和信息传播分析，通过自主新闻智能体动态生成内容并影响用户行为。", "conclusion": "通过构建结合全球人口分布抽样调研问题和人口数据的MAPS基准，实验结果显示MASim能够在社会文化现象的再生产上提供精确和一致的模拟，强调多语言模拟对于可扩展和可控计算社会科学的重要性。"}
{"llm_update_time": "20251210", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2512.07275", "html_url": "https://arxiv.org/abs/2512.07275", "title": "基于有效注意力引导的多尺度医疗网络在皮肤病变分割中的应用", "title_en": "Effective Attention-Guided Multi-Scale Medical Network for Skin Lesion Segmentation", "authors": "Siyu Wang,Hua Wang,Huiyu Li,Fan Zhang", "background": "在医疗领域，精准的皮肤病变分割是早期检测和准确诊断皮肤疾病的关键。尽管深度学习在图像处理方面取得了显著进展，但现有方法尚未有效解决不规则病变形状和低对比度带来的挑战。", "innovation": "提出了基于多尺度残差结构的创新编码-解码网络架构，能够从不同感受野中提取丰富的特征信息，有效识别病变区域。引入了多分辨率多通道融合（MRCF）模块，捕捉跨尺度特征，增强提取信息的清晰度和准确性。还提出了交叉混动注意模块（CMAM），重新定义注意范围并动态计算多上下文之间的权重，提高特征捕捉的灵活性和深度，便于更深入地探索细微特征。为了克服传统U-Net中跳连结构导致的信息丢失，引入了外部注意力桥（EAB），促进解码器中信息的有效利用，并补偿上采样过程中的损失。", "conclusion": "在多个皮肤病变分割数据集上的广泛实验评估表明，所提出的模型明显优于现有的基于变换器和卷积神经网络的方法，展示了出色的分割准确性和鲁棒性。"}
{"llm_update_time": "20251210", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2512.07253", "html_url": "https://arxiv.org/abs/2512.07253", "title": "DGGAN: 由退化指导的生成对抗网络用于实时内窥镜视频增强", "title_en": "DGGAN: Degradation Guided Generative Adversarial Network for Real-time Endoscopic Video Enhancement", "authors": "Handing Xu,Zhenguo Nie,Tairan Peng,Huimin Pan,Xin-Jun Liu", "background": "内窥镜手术依赖于术中视频，因此图像质量决定了手术的安全性和有效性。然而，由于光照不均、组织散射、遮挡和运动模糊等原因，内窥镜视频常常存在降级现象，这些现象会模糊关键解剖细节，增加手术难度。尽管基于深度学习的方法在图像增强方面显示出潜力，但大多数现有的方法仍难以满足实时手术的实际需求。", "innovation": "提出了一种基于退化感知框架的内窥镜视频增强方法，该方法能够在不增加计算负担的情况下实现实时、高质量的图像增强。通过对比学习提取退化表示，引入融合机制，用退化表示调节图像特征以指导单帧增强模型。模型通过恢复图像与降级图像的一致性约束进行训练，提高了鲁棒性和泛化能力。", "conclusion": "实验结果表明，该框架在性能和效率方面均优于多种现有最优方法，证明了退化感知建模在实时内窥镜视频增强中的有效性。该方法表明，隐式学习和传播退化表示可能为临床应用提供一种实际的途径。"}
{"llm_update_time": "20251210", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2512.07168", "html_url": "https://arxiv.org/abs/2512.07168", "title": "基于JEPA的神经分词器：具有密度自适应注意机制的鲁棒语音表示学习", "title_en": "JEPA as a Neural Tokenizer: Learning Robust Speech Representations with Density Adaptive Attention", "authors": "Georgios Ioannides,Christos Constantinou,Aman Chadha,Aaron Elkins,Linsey Pang,Ravid Shwartz-Ziv,Yann LeCun", "background": "该研究介绍了将联合嵌入预测架构(JEPA)与密度自适应注意机制(DAAM)相结合的两阶段自监督框架，用于学习鲁棒的语音表示。此框架通过在潜在空间中的掩码预测，独立于波形重建，首先通过JEPA和DAAM学习语义音频特征，然后利用这些表示高效地使用有限标量量化(FSQ)和混合基数打包方案进行分词，并通过高保真波形重建的HiFi-GAN解码器进行重建。", "innovation": "该研究的创新之处在于它引入了一种两阶段的自监督框架，能够学习鲁棒的语音表示。第一阶段利用JEPA和DAAM在潜在空间中进行掩码预测，从而学习语义音频特征，第二阶段利用这些表示进行高效的分词，并通过高保真波形重建的HiFi-GAN解码器进行重建。研究人员通过将基于高斯混合的密度自适应门控整合到JEPA编码器中，使得模型能够适应性地选择时域特征，并在低采样率(2.5 Hz)下发现层次语音结构。分词结果为47.5个令牌每秒，提供了一种可逆、高度压缩且语言模型友好的表示法，与现有神经音频编解码器相比，具有竞争力且更高效。", "conclusion": "该研究提出的方法有效地整合了JEPA和DAAM，能够在低采样率条件下学习到语音的鲁棒表示。该方法生成的分词结果为47.5个令牌每秒，并且该表示法是可逆、高压缩且语言模型友好的。相较于现有的神经音频编解码器，这种方法有时表现更高效，通常竞争力相当。"}
{"llm_update_time": "20251210", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2512.07302", "html_url": "https://arxiv.org/abs/2512.07302", "title": "向准确的无人机图像感知迈进：使用更强的任务提示引导视觉语言模型", "title_en": "Towards Accurate UAV Image Perception: Guiding Vision-Language Models with Stronger Task Prompts", "authors": "Mingning Guo,Mengwei Wu,Shaoxian Li,Haifeng Li,Chao Tao", "background": "现有的基于视觉语言模型（VLMs）的图像感知方法通常依赖于用户提供的文本任务提示来抽取和分析图像内容。但在应用于无人机（UAV）图像时，会遇到标签混淆、尺度变化和复杂背景等挑战。这些挑战导致VLMs的图像内容理解受到视觉和文本标记之间语义对齐的限制。当任务提示简单且图像内容复杂时，难以实现有效的对齐，从而限制了模型聚焦于与任务相关的信息。", "innovation": "本文提出了AerialVP，这是首个针对无人机图像感知任务提示增强的代理框架。AerialVP从无人机图像中主动抽取多维度的辅助信息并增强任务提示，克服了传统基于VLM的方法的限制。具体增强过程包括三个阶段：(1) 分析任务提示以识别任务类型和增强需求，(2) 从工具库中选择适当的工具，(3) 根据分析和选择的工具生成增强的任务提示。", "conclusion": "通过引入AerialVP，本文显著增强了任务提示的指导作用，促进了开源和专有VLMs在各种无人机图像感知任务上的稳定且显著的性能提升。为了衡量这一效果，本文还提出AerialSense基准，包含Aerial视觉推理、视觉问答和视觉定位任务，提供了通用的评估标准。相关工作可在以下网址获取。"}
{"llm_update_time": "20251210", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2512.07228", "html_url": "https://arxiv.org/abs/2512.07228", "title": "对抗深度伪造面部替换的稳健保护扰动探索", "title_en": "Towards Robust Protective Perturbation against DeepFake Face Swapping", "authors": "Hengyang Yao,Lin Li,Ke Sun,Jianing Qiu,Huiping Chen", "background": "深度伪造面部替换技术能够制造高度逼真的身份伪造，带来了严重的隐私和安全风险。传统的防伪方法在图片中嵌入不可见的扰动，但这些扰动十分脆弱，常常在压缩或缩放等基本操作中被破坏。因此，需要一种更稳健的防伪方法。", "innovation": "本文首先系统分析了30种跨6个类别转变的方法，表明防护的鲁棒性高度依赖于训练转变的选择，使得标准的转变期望（EOT）方法在均匀采样时根本不能达到最优。基于此，提出了一种学习分布转变的期望（EOLT）框架，将转换分布作为可学习的组件，而非固定的设计选择。EOLT利用策略网络，学习自动优先处理关键转变并自适应生成实例特定的扰动，满足强化学习，从而明确建模防御瓶颈的同时保持广泛的可迁移性。", "conclusion": "大量的实验证明，本文的方法在现有的先进技术中取得了显著的改进，平均鲁棒性提高了26%，在挑战性的转变类别中最高提升幅度达到了30%。"}
{"llm_update_time": "20251210", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2512.07218", "html_url": "https://arxiv.org/abs/2512.07218", "title": "NeSTR: 大型语言模型中具有神经符号 abduction 框架的时间推理", "title_en": "NeSTR: A Neuro-Symbolic Abductive Framework for Temporal Reasoning in Large Language Models", "authors": "Feng Liang,Weixin Zeng,Runhao Zhao,Xiang Zhao", "background": "大型语言模型在各种自然语言处理任务中表现出色，但在处理复杂的时序约束时，时间推理仍然是一个主要挑战。现有的方法主要通过符号方法和反思机制来解决这一问题。符号方法虽然能够明确编码时序结构，但也可能无法充分利用大型语言模型的推理能力；而反思方法则通常缺乏结构化的时序表示，这可能导致推理不一致或产生语义错误。因此，即使提供了正确的时序上下文，大型语言模型也可能错误地解释或者应用时间相关信息，导致答案不完整或不准确。", "innovation": "本文提出了一种名为NeSTR的新型框架，它将结构化的符号表示与混合的反思推理相结合，以增强大型语言模型的时序敏感度。NeSTR通过符号编码保留明示的时间关系，通过验证确保逻辑一致性，并通过使用归纳反思来纠正错误的推理。", "conclusion": "广泛多样的时序问答基准测试的结果表明，NeSTR在零样本下的性能优于现有方法，并且能够持续改善时序推理性能，无需任何微调。这展示了神经符号集成在增强大型语言模型的时序理解中的优势。"}
{"llm_update_time": "20251210", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2512.07249", "html_url": "https://arxiv.org/abs/2512.07249", "title": "IFFair: 基于影响函数的样本重新加权以实现公平分类", "title_en": "IFFair: Influence Function-driven Sample Reweighting for Fair Classification", "authors": "Jingran Yang,Min Zhang,Lingfeng Zhang,Zhaohui Wang,Yonggang Zhang", "background": "由于机器学习显著提高了社会的效率和便利性，它越来越多地被用于辅助或替代人类决策。然而，基于数据的模式使相关算法学习并加剧样本中的潜在偏差，导致对某些非特权群体的歧视性决策，剥夺了他们平等对待的权利，从而损害了社会福祉，阻碍了相关应用的发展。", "innovation": "提出了一种基于影响函数的预处理方法 IFFair。与其他公平优化方法相比，IFFair 只是根据训练样本对不同群体的影响差异动态调整样本权重进行训练，而不修改网络结构、数据特征和决策边界。", "conclusion": "通过在多个真实世界数据集上的实验，实验结果表明，IFFair 方法减轻了分类设置中多个广泛接受的公平性指标的偏差，包括人口平等等价性、同等机会等价性和错误率等价性，且没有冲突。此外，IFFair 实现了与先前预处理方法相比在多个效益和公平性度量之间的更好权衡。"}
{"llm_update_time": "20251210", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2512.07309", "html_url": "https://arxiv.org/abs/2512.07309", "title": "辐射场增强预训练：使用无标签无线信号扩展定位模型", "title_en": "Radiance-Field Reinforced Pretraining: Scaling Localization Models with Unlabeled Wireless Signals", "authors": "Guosheng Wang,Shen Wang,Lei Yang", "background": "基于射频（RF）的室内定位为室内导航、增强现实和普遍计算等应用提供了巨大的潜力。尽管深度学习显著提升了定位精度和鲁棒性，现有的定位模型在跨场景泛化方面仍面临重大挑战，因为它们依赖于特定场景的标记数据。", "innovation": "我们提出了一种新颖的自监督预训练框架——辐射场增强预训练（RFRP）。该框架将大型定位模型（LM）与神经射频辐射场（RF-NeRF）耦合在一个不对称的自编码器架构中。在这个设计中，LM将接收到的RF光谱编码为与位置相关的潜在表示，而RF-NeRF则解码这些表示以重构原始光谱。这种输入和输出之间的对齐使我们能够使用大量无标签RF数据进行有效的表示学习，并能够以最小的努力连续收集。", "conclusion": "通过使用包含7,327,321个位置数据点的100个不同场景数据，以及四种常见无线技术（RFID、BLE、WiFi和IIoT）的数据，该模型的RFRP预训练模型在绝对定位误差上比非预训练模型降低了超过40%，比使用监督学习预训练的模型降低了21%。"}
{"llm_update_time": "20251210", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2512.07312", "html_url": "https://arxiv.org/abs/2512.07312", "title": "DCO: 动态缓存管 orchestrator 对于 LLM 加速器通过预测管理", "title_en": "DCO: Dynamic Cache Orchestration for LLM Accelerators through Predictive Management", "authors": "Zhongchun Zhou,Chengtao Lai,Yuhang Gu,Wei Zhang", "background": "大型语言模型（LLMs）的快速采用正推动AI加速器朝着越来越强大和专业的设计方向发展。现有的设计策略倾向于使用复杂且层级深的局部分配（SPM）及其异步管理，这增加了软件开发的复杂性。", "innovation": "研究发现，与其进一步复杂化软件开发中的层状局部分配（SPM）和其异步管理，相反地，一种多核AI加速器被研究，该加速器配备具有系统级缓存和支持应用程序感知的管理策略，以保持编程工作的适度努力。我们的方法利用软件堆栈中可用的数据流信息来指导缓存替换（包括预测死块），结合绕过决策和机制以缓解缓存混乱。", "conclusion": "我们的设计simd在RTL中实现，面积为0.064mm²，采用15nm工艺，在2 GHz时钟频率下运行。研究结果探索了共享缓存设计在帮助开发未来AI加速器系统方面的潜力。同时，使用时序准确的仿真器评估了提案，并观察到与传统缓存架构相比，性能提高了多达1.8倍。还构建了一个分析模型，考虑了实际重叠行为，将政策的测量结果扩展到真实世界更大规模的工作负载。实验结果表明，当该策略共同生效时，可以处理具有和不具有跨核数据共享的场景，并获得显著的速度提升。"}
{"llm_update_time": "20251210", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2512.07170", "html_url": "https://arxiv.org/abs/2512.07170", "title": "统一语义和可控的图像融合方法：一种扩散变换器方法", "title_en": "Towards Unified Semantic and Controllable Image Fusion: A Diffusion Transformer Approach", "authors": "Jiayang Li,Chengjie Jiang,Junjun Jiang,Pengwei Liang,Jiayi Ma,Liqiang Nie", "background": "图像融合的目标是将多种感知模态互补的信息融合起来，现有的方法在鲁棒性、适应性和可控性方面仍然有限。目前的大多数融合网络是针对特定任务定制的，缺乏灵活结合用户意图的能力，尤其是在低光降解、颜色偏移或曝光不匹配等复杂场景中表现不足。此外，缺乏地面实况融合图像和现有数据集规模小，使训练能够同时理解高层语义和执行细粒度多模态对齐的端到端模型变得困难。", "innovation": "我们提出了DiTFuse，一种基于指令驱动的扩散变换器框架，可以在单一模型中实现端到端、感知语义的融合。DiTFuse通过在一个共享的潜空间中联合编码两张图像和自然语言指令，实现了对融合动态的层次和细粒度控制，克服了预融合和后融合管道难以注入高层语义的限制。在训练阶段采用多退化掩码图像建模策略，使得网络能够同时学习多模态对齐、模态不变恢复和任务感知特征选择，而无需依赖基准图像。精心设计的多粒度指令数据集进一步增强了模型的交互式融合能力。DiTFuse统一了红外-可见光、多焦点、多曝光融合，以及文本控制下的细化和下游任务，形成了单一架构。", "conclusion": "在公共IVIF、MFF和MEF基准上的实验证实了DiTFuse在定量和定性性能上的优越性，具有更清晰的纹理和更好的语义保留。此外，该模型还支持多级用户控制和零样本泛化到其他多图融合场景，包括基于指令条件的分割。"}
{"llm_update_time": "20251210", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2512.07266", "html_url": "https://arxiv.org/abs/2512.07266", "title": "SINRL：使用突触神经网络的强化学习社会导航", "title_en": "SINRL: Socially Integrated Navigation with Reinforcement Learning using Spiking Neural Networks", "authors": "Florian Tretter,Daniel Flögel,Alexandru Vasilache,Max Grobbel,Jürgen Becker,Sören Hohmann", "background": "将自主移动机器人整合到人类环境中需要具备类似人类的决策能力和高效、基于事件的计算。尽管有进展，但由于训练不稳定，神经形态方法很少被应用于深度强化学习（DRL）导航方法。", "innovation": "提出了一种结合了突触神经网络（SNNs）的行动者与利用人工神经网络（ANNs）的评论者及神经形态特征提取器的混合社会集成DRL行动者-评论者方法。该方法用于捕捉人群动态和人与机器人的互动，提升了社会导航性能并显著减少了能源消耗。", "conclusion": "该方法在社会导航任务中表现优越，通过引入SNNs显著降低了计算能耗，约为1.69个量级。"}
{"llm_update_time": "20251210", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2512.07306", "html_url": "https://arxiv.org/abs/2512.07306", "title": "精确合成人口模型及其在可扩展的社会和市场建模中的应用", "title_en": "Exact Synthetic Populations for Scalable Societal and Market Modeling", "authors": "Thierry Petit,Arnault Pachot", "background": "本文介绍了一种约束编程框架，用于生成与目标统计数据高度精确匹配且保持个体一致性的人口模型。不同于依赖样本数据推断分布的数据驱动方法，本文的方法直接编码汇总统计数据和结构关系，从而能够在不需要任何微观数据的情况下精确控制人口结构特征。", "innovation": "本文提出了直接编码汇总统计数据和结构关系的方法，可通过大型语言模型查询合成人口，来建模社会行为，探索市场和政策场景，而不需使用个人数据，能够实现精确控制人口结构特征。", "conclusion": "本文的方法已在Pollitics项目中通过官方人口统计数据验证，展示了在社会和市场建模中应用的潜力，能够提供可重复的决策级见解，避免使用个人数据。"}
{"llm_update_time": "20251210", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2512.07287", "html_url": "https://arxiv.org/abs/2512.07287", "title": "SIT-Graph: 状态集成工具图用于多轮对话代理", "title_en": "SIT-Graph: State Integrated Tool Graph for Multi-Turn Agents", "authors": "Sijia Li,Yuchen Huang,Zifan Liu,Zijian Li,Jingjing fu,Lei Song,Jiang Bian,Jun Zhang,Rui Wang", "background": "尽管代理系统取得了显著的进步，但在多轮工具使用场景中，意图的逐步澄清和环境的不断演变构成了挑战。现有的LLM代理要么将整个轨迹或预定义的子任务视为不可分割的单位，要么仅利用工具到工具之间的依赖关系，导致难以适应状态和信息的变化。", "innovation": "本文提出了一种状态集成工具图（SIT-Graph），它通过利用部分重叠的经验来增强多轮工具使用。SIT-Graph通过从历史轨迹中捕获紧凑的状态表示（类似于片段的记忆）和工具到工具依赖关系（类似于常规的程序）来模仿人类决策过程，在积累的工具使用序列上构建工具图，并在每个边中增强紧凑的状态摘要，以影响后续动作。演示时，SIT-Graph在需要回忆先前上下文时检索边上的状态摘要，并据此指导其后续行动；当步骤是常规操作时，则遵循高度信心的工具依赖关系。", "conclusion": "在多个状态多轮工具使用基准测试中，SIT-Graph持续优于强大的基于记忆和图的基线，提供更稳健的工具选择和更有效的经验传递。"}
{"llm_update_time": "20251210", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2512.07332", "html_url": "https://arxiv.org/abs/2512.07332", "title": "基于局部曲率的图嵌入：扩展的里奇流方法", "title_en": "Local-Curvature-Aware Knowledge Graph Embedding: An Extended Ricci Flow Approach", "authors": "Zhengquan Luo,Guy Tadmor,Or Amar,David Zeevi,Zhiqiang Xu", "background": "知识图嵌入（KGE）依赖于嵌入空间的几何结构来编码语义和结构关系。现有的方法将所有实体置于一个同质流形上，如欧几里得、球面、双曲或它们的乘积/多曲率变体，以建模线性、对称或层次结构模式。然而，预定义的同质流形无法适应现实世界图在局部区域表现出的急剧变化的曲率。由于这种几何结构是先验设定的，任何与知识图的局部曲率的不匹配都会导致实体之间的距离被扭曲，从而损害嵌入的知识图表达能力。", "innovation": "本文提出了一种名为RicciKGE的方法，通过将KGE损失梯度与扩展的里奇流中的局部曲率耦合，使得实体嵌入与底层流形几何结构动态共演化以实现相互适应。理论上，当耦合系数被限定和适当选择时，我们严格证明了所有边的曲率将指数衰减，这意味着流形被驱动向欧几里得平坦性；并且KGE距离严格收敛至全局最优，这表明几何扁平化和嵌入优化彼此促进。", "conclusion": "在链接预测和节点分类基准测试中，RicciKGE在适应异构知识图结构方面表现出了有效性。"}
{"llm_update_time": "20251210", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2512.07351", "html_url": "https://arxiv.org/abs/2512.07351", "title": "DeepAgent: 双流多Agent融合的鲁棒多模态深度虚假内容检测", "title_en": "DeepAgent: A Dual Stream Multi Agent Fusion for Robust Multimodal Deepfake Detection", "authors": "Sayeem Been Zaman,Wasimul Karim,Arefin Ittesafun Abian,Reem E. Mohamed,Md Rafiqul Islam,Asif Karim,Sami Azam", "background": "合成媒体，特别是深度伪造（deepfakes），在数字内容验证方面带来了新的挑战。尽管最近的研究利用了音视频信息，但大多数方法将这些线索整合到单一模型中，仍容易受到模态匹配错误、噪声和篡改的影响。", "innovation": "本文提出了一种先进的多-agent协作框架DeepAgent，它能够同时整合视音频模态以有效检测深度伪造。DeepAgent包含两个互补的agent：Agent-1 使用精简的AlexNet卷积神经网络（CNN）检查每个视频，识别深度伪造的修饰符号；Agent-2 通过结合声学特征、Whisper的音频转录和EasyOCR的图像帧读取序列，检测音视频不一致。它们的决策通过随机森林元分类器融合，以提高最终性能。该研究使用三个基准数据集评估提出的框架，以证明组件级和融合级的性能。", "conclusion": "该研究发现，基于层次的融合可以增强鲁棒性，通过克服单一模态的弱点。此外，跨数据集验证表明元分类器在不同数据集上的鲁棒性，表明多-agent方法在处理深度伪造的多种篡改类型方面的强大能力。"}
{"llm_update_time": "20251210", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2512.07344", "html_url": "https://arxiv.org/abs/2512.07344", "title": "Venus: 一种基于VLM的高效边缘记忆和检索系统", "title_en": "Venus: An Efficient Edge Memory-and-Retrieval System for VLM-based Online Video Understanding", "authors": "Shengyuan Ye,Bei Ouyang,Tianyi Qian,Liekang Zeng,Mu Yuan,Xiaowen Chu,Weijie Hong,Xu Chen", "background": "视觉-语言模型（VLMs）已经展示了令人印象深刻的多模态理解能力，并被广泛应用于在线视频理解应用中。尽管最近的研究侧重于增强这些场景中VLMs的推理能力，但实际部署的限制被忽视，导致了在实际部署中系统的巨大开销。如何在保证硬件设备承受能力的同时，提高多模态模型的推理效率成为亟待解决的问题。", "innovation": "Venus提出了一种边缘-云分离架构的在设备端的记忆和检索系统，将云中的记忆构建和关键帧提取下沉到边缘设备，分为两个阶段进行。在数据摄入阶段，Venus通过场景分割和聚类连续处理边缘视频流，选择的关键帧通过多模态嵌入模型嵌入，构建层次化记忆以实现高效存储和检索。在查询阶段，Venus通过索引内存中的查询，并使用基于阈值的渐进采样算法选择关键帧，增强多样性并自适应地平衡系统成本和推理准确性。", "conclusion": "我们的广泛评估表明，Venus将总体响应延迟提高了15至131倍，能够在几秒钟内实现实时响应，同时保持相似甚至更优的推理准确性。"}
{"llm_update_time": "20251210", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2512.07415", "html_url": "https://arxiv.org/abs/2512.07415", "title": "数据驱动的移动交互模式探索", "title_en": "Data-driven Exploration of Mobility Interaction Patterns", "authors": "Gabriele Galatolo,Mirco Nanni", "background": "理解个体的运动行为及其对外部世界的反应是任何涉及物理层面的人类动态建模问题的关键。特别是，捕捉个别人的存在对其它人可能产生的影响是至关重要的。这在人群模拟和紧急管理等领域中尤为重要，其中人群的模拟需要基于个体的模拟。现有解决方案通常基于一些先验的行为模型，而这项工作提出了一种直接从数据出发的方法，采用数据挖掘的视角。该方法搜索数据中的可能的相互作用的移动事件，并在其上寻找复杂且持久的事件模式及其随时间变化的配置。", "innovation": "这项研究提出了一种直接从数据出发探索个体间运动交互模式的方法，这种方法与现有的基于先验行为模型的方法不同，采用了数据挖掘的视角。通过这种方法，可以发现潜在的新机制来改进现有的人群模拟模型。", "conclusion": "研究结果表明，通过分析这些模式可以提供关于个体之间移动交互的新见解，这些洞察可能有助于改进现有的人群模拟模型。该方法已经在汽车和行人两个实际案例上进行了实例化，并进行了全面的实验评估，包括性能、参数敏感性和样本结果的解释。"}
{"llm_update_time": "20251210", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2512.07400", "html_url": "https://arxiv.org/abs/2512.07400", "title": "在经验回放中的神经坍缩下浅层和深层遗忘的渐近分析", "title_en": "Asymptotic analysis of shallow and deep forgetting in replay with Neural Collapse", "authors": "Giulia Lanzillotta,Damiano Meier,Thomas Hofmann", "background": "持续学习（CL）中存在一个持久的悖论，即神经网络经常保留过去任务在线性可分表示，即使其输出预测失败。这导致了深度特征空间和浅层分类器级别遗忘之间的差距。经验回放中的关键不对称性在于，尽管最小的缓冲区可以锚定特征几何并防止深度遗忘，但减轻浅层遗忘通常需要更大的缓冲区容量。为了解释这一点，我们将神经坍缩框架扩展到顺序设置。我们把深度遗忘描述为向离分布子空间的几何漂移，并证明任何非零回放比例都最终保证了线性可分性的保留。", "innovation": "我们扩展了神经坍缩框架到序列设置，并揭示了浅层遗忘需要更大缓冲容量的原因。我们证明了任何形式的回放最终会保留线性可分性，而小型缓冲区引发的“强坍缩”会导致协方差秩不足和类均值膨胀，从而使分类器忽视真实的人群边界。通过统一持续学习和离分布检测，我们的工作挑战了对大缓冲区的依赖性，表明通过显式纠正这些统计伪影可以实现微小回放仍具有稳健性能。", "conclusion": "我们的工作表明，通过纠正统计伪影可以实现即使在小回放比例下，持续学习依然能达到稳健性能。这挑战了对大缓冲区的传统依赖，并为新的、更有效的持续学习方法提供了理论依据。"}
{"llm_update_time": "20251210", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2512.07426", "html_url": "https://arxiv.org/abs/2512.07426", "title": "当归一化产生幻觉：AI驱动的整张切片图像处理中的未见风险", "title_en": "When normalization hallucinates: unseen risks in AI-powered whole slide image processing", "authors": "Karel Moens,Matthew B. Blaschko,Tinne Tuytelaars,Bart Diricx,Jonas De Vylder,Mustafa Yousif", "background": "数字病理学中，整个切片图像（WSI）的归一化仍然是一个重要的预处理步骤。基于深度学习的模型通过学习训练数据来逼近数据分布，常常导致结果偏向于平均值，掩盖了具有诊断意义的特征。更严重的是，这些模型还会引入幻觉内容，即看起来真实但实际并不存在于原始组织中的伪影，这会对后续分析构成严重威胁。当前的评估实践往往忽视了这种幻觉的存在。", "innovation": "本文展示了幻觉的风险是真实存在的且未被充分认识。尽管许多方法在公共数据集上表现良好，但我们观察到在重新训练和在真实临床数据上评估时，幻觉的频率令人担忧。为此，我们提出了一个新颖的图像比较指标，用于自动检测归一化输出中的幻觉。利用该指标，我们系统地评估了几种广泛引用的归一化方法，揭示了由常规指标无法捕捉的重要不一致性和失败。", "conclusion": "本文的研究结果强调了需要更加稳健的、可解释的归一化技术和更严格的验证协议，以确保在临床部署中的使用。"}
{"llm_update_time": "20251210", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2512.07328", "html_url": "https://arxiv.org/abs/2512.07328", "title": "ContextAnyone: Context-Aware Diffusion for Character-Consistent Text-to-Video Generation", "title_en": "ContextAnyone: Context-Aware Diffusion for Character-Consistent Text-to-Video Generation", "authors": "Ziyang Mai,Yu-Wing Tai", "background": "当前，文本到视频（T2V）生成技术已取得迅速发展，但保持不同场景中角色身份的一致性仍然是一个主要挑战。现有的个性化方法通常侧重于面部身份，但未能保留如发型、服装和体型等更广泛的情境线索，这些线索对于视觉的一致性至关重要。", "innovation": "该研究提出了ContextAnyone，一种上下文感知的扩散框架，能够从文本和单张参考图像生成角色一致的视频。研究中引入了一个新颖的强调-注意力模块，该模块选择性地增强了参考图像相关的特征，并防止了帧间身份漂移。双引导损失结合了扩散和参考重建目标，以提高外观保真度，同时提出的Gap-RoPE位置嵌入将参考帧和视频帧分开，以稳定时间建模。", "conclusion": "实验表明，ContextAnyone在身份一致性及视觉质量上优于现有的参考到视频生成方法，能够生成一致且情景保留的角色视频，涵盖多种动作和场景。"}
{"llm_update_time": "20251210", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2512.07404", "html_url": "https://arxiv.org/abs/2512.07404", "title": "LLMs信任它们编写的代码吗？", "title_en": "Do LLMs Trust the Code They Write?", "authors": "Francisco Ribeiro,Claudio Spiess,Prem Devanbu,Sarah Nadi", "background": "尽管大型语言模型（LLMs）在代码生成方面非常有效，但它们经常输出错误的代码。这一问题的原因之一是模型输出的概率与正确性关系不密切，仅反映了生成过程的最终结果。受LLMs在内部编码真实性概念的启发，本文探索LLMs是否也代表代码的正确性。", "innovation": "通过对比正确和错误代码的隐藏状态，识别LLMs中正确的表示。实验表明，利用此提取出的正确表示优于标准的对数似然排名和模型言语化置信度。此外，研究了如何使用这种内部正确性信号来选择高质量的代码样本，而无需进行测试执行。", "conclusion": "这项工作展示了如何利用内部表示增强代码生成系统，并使LLMs更加可靠，从而提高自动生成代码的信心。"}
{"llm_update_time": "20251210", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2512.07430", "html_url": "https://arxiv.org/abs/2512.07430", "title": "MIDG: Mixture of Invariant Experts with knowledge injection for Domain Generalization in Multimodal Sentiment Analysis", "title_en": "MIDG: Mixture of Invariant Experts with knowledge injection for Domain Generalization in Multimodal Sentiment Analysis", "authors": "Yangle Li,Danli Luo,Haifeng Hu", "background": "现有方法在多模态情感分析(MSA)的域泛化中的多模态不变特征提取过程中，常常忽视了模态之间的协同作用，这使得无法准确捕获多模态数据中的丰富语义信息。此外，虽然已经探索了知识注入技术在MSA中的应用，但由于跨模态知识分布不均，往往未能充分捕捉到超过单一模态界限的具体表示。", "innovation": "提出了一种新的多模态情感分析(MSA)框架用于域泛化，该框架结合了混合不变专家模型来提取域不变特征，增强了模型学习模态间协同关系的能力。此外，还设计了跨模态适配器，通过跨模态知识注入来增强多模态表示的语义丰富度。", "conclusion": "在三个数据集上进行的领域实验表明，提出的MIDG在性能上取得了显著的提升。"}
{"llm_update_time": "20251210", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2512.07360", "html_url": "https://arxiv.org/abs/2512.07360", "title": "结构感知识别图引导的特征校正方法及其在无需训练的开放词汇语义分割中的应用", "title_en": "Structure-Aware Feature Rectification with Region Adjacency Graphs for Training-Free Open-Vocabulary Semantic Segmentation", "authors": "Qiming Huang,Hao Ai,Jianbo Jiao", "background": "基于大规模数据集学习的归纳偏置，开放词汇语义分割（OVSS）利用视觉语言模型（如CLIP）的能力，在无需特定任务训练的情况下取得了显著进步。然而，由于CLIP在图像-文本对上进行预训练，它更倾向于关注全局语义对齐，这导致在关联细粒度视觉区域与文本时性能不佳，从而产生嘈杂和不一致的预测，特别是在局部区域。这种问题主要是由于CLIP的对比学习训练范式导致的一个分散偏置，仅依靠CLIP特征难以解决。", "innovation": "本文提出了一种结构感知识别图引导的特征校正方法，通过结合从图像直接推导出的实例特定先验，来增强局部区分能力。具体来说，基于低级特征（如颜色和纹理）构建区域邻接图（RAG），利用其来精炼CLIP特征，从而抑制分割噪声、提高区域一致性，并在多个开放词汇语义分割基准上取得优异性能。", "conclusion": "大量实验表明，我们的方法有效抑制了分割噪声，提高了区域级的一致性，并在多个开放词汇语义分割基准上取得了优异的性能。"}
{"llm_update_time": "20251210", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2512.07371", "html_url": "https://arxiv.org/abs/2512.07371", "title": "ESPADA: 通过感知数据下采样提高执行速度的模仿学习", "title_en": "ESPADA: Execution Speedup via Semantics Aware Demonstration Data Downsampling for Imitation Learning", "authors": "Byungju Kim,Jinu Pahk,Chungwoo Lee,Jaejoon Kim,Jangha Lee,Theo Taeyeong Kim,Kyuhwan Shim,Jun Ki Lee,Byoung-Tak Zhang", "background": "基于行为克隆的视觉-运动策略能够实现精准操作，但通常会继承人类演示中的缓慢、谨慎的步伐，限制其实用部署。此前的研究主要依赖于统计或启发式线索来加速方法，这些方法忽略了任务语义，在各种操作设置中可能会失败。", "innovation": "提出了一种称为ESPADA的语义和空间感知框架，使用基于VLM-LLM的管道对演示进行分割，使非关键部分进行激进的下采样，同时保持关键精确部分，无需额外数据、架构修改或重新训练。ESPADA使用动态时间规整（DTW）传播段标签，实现从单个标注集扩展到整个数据集。", "conclusion": "在ACT和DP基线的仿真和真实世界实验中，ESPADA实现了约2倍的速度提升，维持了成功率，缩小了人类演示和高效机器人控制之间的差距。"}
{"llm_update_time": "20251210", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2512.07454", "html_url": "https://arxiv.org/abs/2512.07454", "title": "Persian-Phi: 通过逐级学习高效适配紧凑型大型语言模型", "title_en": "Persian-Phi: Efficient Cross-Lingual Adaptation of Compact LLMs via Curriculum Learning", "authors": "Amir Mohammad Akhlaghi,Amirhossein Shabani,Mostafa Abdolmaleki,Saeed Reza Kheradpisheh", "background": "目前，人工智能的民主化进程受到训练大规模语言模型（LLM）的高计算成本的阻碍，特别是在低资源语言上。本研究关注低资源语言（如波斯语）的大规模语言模型训练困难。", "innovation": "提出了一个名为Persian-Phi的38亿参数模型，挑战了大规模模型或基于多种语言的先验才能实现稳健的多语言能力这一假设。模型通过一种新颖的资源高效逐级学习管道，将原本的单语言英语模型通过逐步预训练与指令调优，经过独特“预热”阶段的双语叙述（微型故事）对嵌入进行对齐，实现了优秀的性能，无需大量硬件资源。", "conclusion": "研究结果提供了一个验证且可扩展的框架，以通过最少的硬件资源扩展尖端LLM到被忽视的语言。Persian-Phi模型已在HuggingFace的开源平台公开可用。"}
{"llm_update_time": "20251210", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2512.07482", "html_url": "https://arxiv.org/abs/2512.07482", "title": "从公共道路实测交通数据到关键相关场景", "title_en": "From Real-World Traffic Data to Relevant Critical Scenarios", "authors": "Florian Lüttner,Nicole Neis,Daniel Stadler,Robin Moss,Mirjam Fehling-Kaschek,Matthias Pfriem,Alexander Stolz,Jens Ziehn", "background": "自动驾驶车辆、自动驾驶功能和先进驾驶辅助系统的可靠运行对于它们的发展和部署至关重要。然而，由于涉及众多自由度，准确识别出所有相关的驾驶场景是极具挑战性的，这些自由度对驾驶场景的结果有不同的影响。随着功能技术复杂性的增加，潜在的需要特别注意的“未知不安全”场景数量也在增加。为了提高验证效率，必须在更复杂环境（如城市交通）之前，从高速公路等更简单的领域开始识别相关场景。", "innovation": "本研究专注于分析在高速公路交通中的车道变换场景，这些场景包含多个自由度并呈现出许多安全相关的情况。通过数据收集与处理、应用关键性度量对轨迹数据进行评估，结合计算的度量与特定车道变换驾驶场景和数据采集条件的关联，促进不同应用的安全相关驾驶场景识别。此外，为了应对广泛的“未知不安全”场景，提出了通过基于记录的场景生成合成场景的方法。最终展示并评估了从实测数据识别安全相关场景的处理链，以及基于抽样的合成关键场景生成方法。", "conclusion": "该研究提出了一个处理链，识别安全相关场景、开发数据驱动的方法来提取这些场景，并通过采样生成合成关键场景，从而为自动驾驶车辆开发和验证提供了有效的途径。"}
{"llm_update_time": "20251210", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2512.07462", "html_url": "https://arxiv.org/abs/2512.07462", "title": "通过博弈论理解LLM代理行为：策略识别、偏差和多代理动态", "title_en": "Understanding LLM Agent Behaviours via Game Theory: Strategy Recognition, Biases and Multi-Agent Dynamics", "authors": "Trung-Kiet Huynh,Duy-Minh Dao-Sy,Thanh-Bang Cao,Phong-Hao Le,Hong-Dan Nguyen,Phu-Quy Nguyen-Lam,Minh-Luan Nguyen-Vo,Hong-Phat Pham,Phu-Hoa Pham,Thien-Kim Than,Chi-Nguyen Tran,Huy Tran,Gia-Thoai Tran-Le,Alessio Buscemi,Le Hong Trang, TheAnh Han", "background": "随着大规模语言模型（LLMs）越来越多地在交互和多代理系统以及人类社会中作为自主决策者运作，理解它们的战略行为对安全、协调以及AI驱动的社会和经济基础设施设计具有深远的意义。评估这种行为需要能够捕捉LLMs不仅输出的内容，还包括引导其决策的内在意图的方法。", "innovation": "本文扩展了FAIRGAME框架，通过两个互补的进展系统评估LLMs在重复社会困境中的行为：一是支付缩放的囚徒困境，用于隔离对激励幅度的敏感性；二是集成多代理公共产品博弈，具有动态支付和多代理历史。这些环境揭示了模型和语言之间一致的行为特征，包括激励敏感的合作、跨语言分歧以及终局倾向性的背叛。为了解释这些模式，本研究将传统监督分类模型训练在经典的重复博弈策略上，并应用于FAIRGAME轨迹，表明LLMs表现出系统性的、模型和语言依赖的行为意图，有时语言框架的效果甚至比架构差异还要强。", "conclusion": "本研究为审计LLMs作为战略代理提供了一个统一的方法论基础，并揭示了系统性的合作偏见，这对于AI治理、集体决策以及安全多代理系统的设计具有直接的含义。"}
{"llm_update_time": "20251210", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2512.07453", "html_url": "https://arxiv.org/abs/2512.07453", "title": "在均质及结构化群体中实现社会福利优化", "title_en": "Social welfare optimisation in well-mixed and structured populations", "authors": "Van An Nguyen,Vuong Khang Huynh,Ho Nam Duong,Huu Loi Bui,Hai Anh Ha,Quang Dung Le,Le Quoc Dung Ngo,Tan Dat Nguyen,Ngoc Ngu Nguyen,Hoai Thuong Nguyen,Zhao Song,Le Hong Trang, TheAnh Han", "background": "以往关于促进自主且自我关注的代理之间的协作研究，大多集中在双目标优化问题上：最小化总的激励成本同时最大化合作频率。然而，在这种约束下社会福利的最佳值尚需进一步探索。本研究提出，即使最小化激励成本以驱动代理达到期望的协作状态，也未必能确保达到最大社会福利。为此，本文采用单目标方法，聚焦于最大化社会福利，借鉴了基础进化博弈理论模型在有限群体中成本效率的评估方法，在均质和结构化群体中进行研究。", "innovation": "本文提出了一种单目标优化方法，目标是最大化社会福利，而不是传统的最小化激励成本或最大化合作频率。通过建立分析模型和基于代理的模拟，探索了不同干预策略（包括奖励局部行为模式与全局行为模式）对社会福利和合作动态的影响。", "conclusion": "我们的研究揭示了在单纯优化成本效率或合作频率与最大社会福利优化之间存在显著的个体激励成本差异。整体而言，我们的发现表明，在多代理系统及人类社会中，激励设计、政策及基准评估应优先考虑以福利为中心的目标，而非成本或合作频率的间接指标。"}
{"llm_update_time": "20251210", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2512.07437", "html_url": "https://arxiv.org/abs/2512.07437", "title": "KAN-Dreamer: 将柯尔莫哥罗夫-阿诺尔德网络作为世界模型中的函数逼近器进行基准测试", "title_en": "KAN-Dreamer: Benchmarking Kolmogorov-Arnold Networks as Function Approximators in World Models", "authors": "Chenwei Shi,Xueyu Luan", "background": "DreamerV3 是一种以卓越的样本效率著称的在线模型导向强化学习 (MBRL) 算法。同时，柯尔莫哥罗夫-阿诺尔德网络 (KANs) 已经成为多层感知器 (MLPs) 的有前途的替代选择，具有更好的参数效率和可解释性。为了减轻 KANs 的计算开销，变体 FastKAN 通过使用径向基函数 (RBFs) 来加速推理。本文探讨了将 KAN 架构集成到 DreamerV3 框架中的可能。", "innovation": "本文引入了 KAN-Dreamer，将 KAN 和 FastKAN 层替换到 DreamerV3 的特定 MLP 和卷积组件中。为了确保效率，我们实现了一个专为 JAX 基础世界模型设计的简洁向量化版本，简化了网格管理。进一步地，实验分析了视觉感知、潜在预测和行为学习三个子系统，展示了使用我们的适应 FastKAN 作为奖励和继续预测的直接替换在样本效率和训练速度上与原始基于 MLP 的架构保持一致。", "conclusion": "实验结果表明，使用适配的 FastKAN 替换奖励和继续预测器，性能与原始基于 MLP 的架构相当，在样本效率和训练速度上保持一致。该报告为未来基于 KAN 的世界模型开发提供了初步研究结果。"}
{"llm_update_time": "20251210", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2512.07450", "html_url": "https://arxiv.org/abs/2512.07450", "title": "忘记并解释：GNN去学习的透明验证", "title_en": "Forget and Explain: Transparent Verification of GNN Unlearning", "authors": "Imran Ahsan(1),Hyunwook Yu(2),Jinsung Kim(2),Mucheol Kim(2) ((1) Department of Smart Cities, Chung-Ang University, (2) Department of Computer Science and Engineering, Chung-Ang University)", "background": "图神经网络（GNN）正越来越多地被用于建模图结构数据中的复杂模式。然而，在像GDPR这样的隐私法规背景下，使它们“忘记”指定的信息仍然是一个挑战，目前的去学习方法大多侧重于效率和可扩展性，但却缺乏透明度，GNN的黑箱性质也使得很难验证遗忘是否真正发生。", "innovation": "本文提出了一种解释驱动的GNN去学习验证器，它在模型删除前后进行快照，并使用归因变化和局部结构变化（例如，图编辑距离）作为透明证据。验证器使用五种解释性的度量标准：残差归因、热图变化、解释性分数偏差、图编辑距离和诊断图规则变化。该验证了两种框架（GCN、GAT）和四种去学习策略（Retrain、GraphEditor、GNNDelete、IDEA）在五个基准数据集（Cora、Citeseer、Pubmed、Coauthor-CS、Coauthor-Physics）上的效果，结果显示Retrain和GNNDelete能实现接近完全的忘记，GraphEditor提供了部分擦除，IDEA留下了残留信号。", "conclusion": "这些解释差异提供了遗忘的主要、可读性证据；我们还报告了成员推断ROC-AUC作为补充的、整个图范围内的隐私信号。"}
{"llm_update_time": "20251210", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2512.07540", "html_url": "https://arxiv.org/abs/2512.07540", "title": "Minimum Bayes Risk Decoding for Error Span Detection in Reference-Free Automatic Machine Translation Evaluation", "title_en": "Minimum Bayes Risk Decoding for Error Span Detection in Reference-Free Automatic Machine Translation Evaluation", "authors": "Boxuan Lyu,Haiyue Song,Hidetaka Kamigaito,Chenchen Ding,Hideki Tanaka,Masao Utiyama,Kotaro Funakoshi,Manabu Okumura", "background": "错误跨度检测（ESD）是自动机器翻译评估的一个子任务，它能够定位翻译中的错误跨度并标记其严重程度。现有的生成式ESD方法通常使用最大后验概率（MAP）进行解码，假设模型估计的概率完全与人类注释的相似度相关。但是，研究者观察到，与人类注释不相似的注释可能会比人类注释获得更高的模型似然性。", "innovation": "本文通过应用最小贝叶斯风险（MBR）解码来解决现有方法的局限性，并且使用句子级和跨度级相似度度量作为效用函数，基于其对人类注释的近似相似度来选择候选假设。实验结果表明，MBR解码在系统、句子和跨度级别上均优于MAP基准。此外，为了减轻MBR解码的计算成本，本文展示了MBR蒸馏可以使得标准贪婪模型达到MBR解码性能，从而有效消除推理时的延迟瓶颈。", "conclusion": "MBR解码能够提高ESD系统的性能，并且通过MBR蒸馏可以使得标准贪婪模型达到MBR解码的性能，有效地提高了系统在运行时的效率。"}
{"llm_update_time": "20251210", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2512.07544", "html_url": "https://arxiv.org/abs/2512.07544", "title": "MoCoRP: 建立个性与响应一致关系以提升基于个性的对话", "title_en": "MoCoRP: Modeling Consistent Relations between Persona and Response for Persona-based Dialogue", "authors": "Kyungro Lee,Dongha Choi,Hyunju Lee", "background": "随着对话系统在各个领域中的重要性不断增加，基于个性的对话的一个关键挑战在于生成既吸引人又符合上下文的交互，同时保持模型具有连贯的性格。然而，当前的基于个性的对话数据集缺乏对个性句子与响应之间明确关系的描述，这使得模型难以为有效捕捉个性信息提供支持。", "innovation": "本文提出了MoCoRP（建模个性与响应之间的一贯关系）框架，该框架将明确关系纳入语言模型。MoCoRP利用NLI专家显式提取个性句子与响应之间的关系，使模型能够将适当的个性信息有效纳入到响应中。此外，本文还将其应用于预训练模型BART，并进一步扩展到现代大规模语言模型（LLMs）中。", "conclusion": "实验结果表明，MoCoRP在公开数据集ConvAI2和MPChat上优于现有基线，实现了更高的个性一致性和富有吸引力的、了解上下文的对话生成。此外，该模型不仅在量化指标方面表现优异，还在定性方面也取得了显著改进。这些结果突显了显式建模个性与响应关系的有效性。"}
{"llm_update_time": "20251210", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2512.07487", "html_url": "https://arxiv.org/abs/2512.07487", "title": "人工智能与核武器扩散：（不）可见性技术军备竞赛", "title_en": "Artificial Intelligence and Nuclear Weapons Proliferation: The Technological Arms Race for (In)visibility", "authors": "David M. Allison,Stephen Herzog", "background": "现有的核不扩散体制只成功防止了核武器扩散至九个国家，然而，新兴和颠覆性技术正在改变核风险的格局，引发了决策者的关键时刻。本文强调了扩散促进技术（PETs）与检测增强技术（DETs）之间相互作用所导致的核（不）可见性技术军备竞赛。随着人工智能（AI）的发展及其知识替代的能力，扩散进程可能会被加速，这也对传统监测和验证方法构成了挑战。", "innovation": "本文开发了一个基于相对优势指数（RAI）的正式模型，通过量化PETs和DETs之间的不平衡，探讨了不对称技术进步如何扩大核扩散可检测性不确定性区间。通过基于情景的可复制模拟，评估了不同PET增长速度和DET投资策略对累积核突破风险的影响。", "conclusion": "本文指出，检测技术可能不足以应对复杂局面，未来需在全球层面推进PET治理。政府和国际组织应投资于足够灵活的政策和工具，以适应未来的技术发展节奏。"}
{"llm_update_time": "20251210", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2512.07501", "html_url": "https://arxiv.org/abs/2512.07501", "title": "AutoICE：通过LLM驱动的进化合成可验证的C代码", "title_en": "AutoICE: Automatically Synthesizing Verifiable C Code via LLM-driven Evolution", "authors": "Weilin Luo,Xueyi Liang,Haotian Deng,Yanan Liu,Hai Wan", "background": "自动从自然语言需求合成可验证代码可以保证软件的正确性和可靠性，同时降低采用形式方法的技术门槛。随着大型语言模型（LLMs）的发展，自动形式化的工作重新获得了动力，但现有方法由于缺乏领域特定的预训练语料库而存在严重的语法和语义错误，并且通常无法有效地形式化隐含知识。", "innovation": "提出了AutoICE，一种基于LLM的进化搜索方法，用于合成可验证的C代码。AutoICE引入了多样的个体初始化和协作交叉，以实现多样化的迭代更新，从而缓解单一代理迭代中固有的错误传播。此外，它使用自我反思的变异来促进隐含知识的发现。", "conclusion": "AutoICE的有效性经评估结果证明：它成功验证了90.36%的代码，超越了现有的最先进的方法。在具有良好开发者友好的数据集变体上，AutoICE达到了88.33%的验证成功率，远超过现有最先进方法65%的成功率。"}
{"llm_update_time": "20251210", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2512.07509", "html_url": "https://arxiv.org/abs/2512.07509", "title": "探索用于预配置潜在空间的更快神经网络训练的可能向量系统", "title_en": "Exploring possible vector systems for faster training of neural networks with preconfigured latent spaces", "authors": "Nikita Gabdullin", "background": "神经网络的整体性能与其潜在空间中的嵌入分布密切相关。最近的研究表明，预定义的向量系统，尤其是An根系统向量，可以作为潜在空间配置的目标，以确保所需的潜在空间结构。潜在空间配置的一个主要优势是可以训练分类神经网络而不使用分类层，这使得在具有极大类数量的数据集上训练神经网络更加便捷。", "innovation": "本文提供了一个更为通用的方法，概述了可能用于神经网络训练的向量系统及其特性，并介绍了构建这些系统的各种方法。这些系统被用于配置编码器和视觉变换器的潜在空间，以显著加速ImageNet-1K和具有60万到50万个类的数据集的潜在空间配置训练。结果表明，使用特定类数的最小潜在空间维度可以实现更快的收敛。", "conclusion": "使用特定数量的类所需的最小潜在空间维度进行潜在空间训练可以实现更快的收敛。这为减少用于存储神经网络嵌入的向量数据库的大小提供了潜在的优势。"}
{"llm_update_time": "20251210", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2512.07515", "html_url": "https://arxiv.org/abs/2512.07515", "title": "SPAD: 基于句法聚合的七个来源的标记概率归因检测RAG中的幻觉", "title_en": "SPAD: Seven-Source Token Probability Attribution with Syntactic Aggregation for Detecting Hallucinations in RAG", "authors": "Pengqian Lu,Jie Lu,Anjin Liu,Guangquan Zhang", "background": "在检索增强生成（RAG）中检测幻觉仍然是一个挑战。先前的方法将幻觉归因于内部知识（存储在FFN中）和检索语境之间的二元冲突，但这种观点是不完整的，没有考虑到生成过程中的其他组件的影响，如用户查询、先前生成的标记、当前标记本身以及最终层归一化调整。", "innovation": "我们引入了SPAD，这是一种新的方法。SPAD首先通过数学方法将每个标记的概率归因于七个不同的来源：查询、RAG、过去的生成、当前标记、FFN、最终层归一化和初始嵌入。这种方法量化了每个来源对生成当前标记的贡献。然后，通过词性标签聚合这些得分，以量化不同组件如何驱动特定的语法类别。通过识别异常，如名词依赖于最终层归一化，SPAD能够有效检测幻觉。", "conclusion": "广泛的实验表明，SPAD能够实现最先进的性能。"}
{"llm_update_time": "20251210", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2512.07564", "html_url": "https://arxiv.org/abs/2512.07564", "title": "向更可靠的AI迈进：减少视觉语言模型的幻觉", "title_en": "Toward More Reliable Artificial Intelligence: Reducing Hallucinations in Vision-Language Models", "authors": "Kassoum Sanogo,Renzo Ardiccioni", "background": "视觉语言模型（VLMs）经常生成关于图像内容可能合理但不正确的描述，这影响了模型的可靠性和准确性。", "innovation": "提出了一个无需训练的自我纠正框架，使VLMs能够通过不确定性引导的视觉重新关注多次迭代地精炼响应。该方法结合了多维度不确定性量化（令牌熵、注意力分散、语义一致性、主张置信度）与注意力引导的探索不足区域裁剪。", "conclusion": "实验结果表明，与基线相比，我们的方法将幻觉率降低了9.8个百分点，同时在对抗分割中提高了4.7个点的物体存在准确性。此外，定性分析证实了不确定性引导的重新关注成功地将修正与视觉证据联系了起来，而标准解码则无法做到这一点。该方法在Qwen2.5-VL-7B架构上进行了验证，并计划在未来版本中扩展验证至多种架构，同时开放代码和方法以促进后续研究。"}
{"llm_update_time": "20251210", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2512.07533", "html_url": "https://arxiv.org/abs/2512.07533", "title": "VulnLLM-R：具备代理框架的专业推理大语言模型在漏洞检测中的应用", "title_en": "VulnLLM-R: Specialized Reasoning LLM with Agent Scaffold for Vulnerability Detection", "authors": "Yuzhou Nie,Hongwei Li,Chengquan Guo,Ruizhe Jiang,Zhun Wang,Bo Li,Dawn Song,Wenbo Guo", "background": "现有的最先进推理大语言模型通常规模庞大、闭源或在漏洞检测方面性能有限。因此，需要一种新的方法来提高这些模型在漏洞检测中的表现和效率。", "innovation": "提出了VulnLLM-R这一专门用于漏洞检测的专业推理大语言模型。引入了特殊的训练配方，包括数据选择、推理数据生成、推理数据过滤和校正以及测试阶段优化。通过这种方法训练出一个七亿参数的推理模型，并在Python、C/C++和Java的最新基准数据集上进行了实验证明了其优越性。", "conclusion": "VulnLLM-R比现有的静态分析工具和开源及商业的大规模推理模型在效果和效率上都更优。此外，还通过详细的消除研究验证了训练配方的关键设计。模型构建的代理框架在实际项目中表现优于CodeQL和AFL++，并发现了几个零日漏洞。这项工作代表了利用专业推理模型驱动的AI代理进行实际项目级别漏洞检测的首创性努力。"}
{"llm_update_time": "20251210", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2512.07522", "html_url": "https://arxiv.org/abs/2512.07522", "title": "LIME: 使用语言元数据嵌入使大规模语言模型数据更有效", "title_en": "LIME: Making LLM Data More Efficient with Linguistic Metadata Embeddings", "authors": "Sebastian Sztwiertnia,Felix Friedrich,Kristian Kersting,Patrick Schramowski,Björn Deiseroth", "background": "预训练解码器语言模型依赖大量的高质量数据，但这些高质量数据的可用性正逐渐达到极限。尽管元数据常用于创建和整理这些数据集，但它作为直接训练信号的潜力尚未被充分探索。", "innovation": "本文提出了LIME（语言元数据嵌入）方法，该方法通过将捕捉语法、语义和上下文属性的元数据丰富到标记嵌入中来增强预训练效率。LIME 可以使模型适应训练数据分布的速度提高多达 56%，并且仅增加 0.01% 的参数，在几乎无额外计算开销的情况下。此外，LIME 提高了标记化质量，从而显著增强了语言建模能力和生成任务表现。这些好处在不同规模的模型（500M 到 2B）中持续存在。另外，还开发了带有移位元数据的 LIME 变种 LIME+1，它可以引导标记生成，利用前一个标记的先验元数据，LIME+1 可将推理性能提高多达 38%，算术准确性提高多达 35%。", "conclusion": "LIME 方法能够通过利用语言元数据嵌入来增强语言模型的训练效率，提升模型在标记化、推理表现和算术准确性方面的能力，这一方法在不同规模的语言模型中都表现出优越性，并且通过 LIME+1 变种进一步展示了其应用潜力。"}
{"llm_update_time": "20251210", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2512.07569", "html_url": "https://arxiv.org/abs/2512.07569", "title": "带有异常意识的时间序列预测的加权对比学习", "title_en": "Weighted Contrastive Learning for Anomaly-Aware Time-Series Forecasting", "authors": "Joel Ekstrand,Tor Mattsson,Zahra Taghiyarrenani,Slawomir Nowaczyk,Jens Lundström,Mikael Lindén", "background": "在诸如ATM现金物流等应用中，多变量时间序列的可靠预测在面对突发需求变化时尤为重要。现代深度预报模型在正常数据上具有高准确性，但在分布发生变化时往往失效。", "innovation": "提出了一种加权对比适应方法（WECA），它通过加权对比目标对正常和异常增强表示进行对齐，同时在良性变化下保持一致性并保留与异常相关的信息。", "conclusion": "评估结果显示，WECA在异常影响的数据上比正常训练基线提高了6.1个百分点的SMAPE，同时在正常数据上的表现几乎没有下降。这意味着WECA能够在异常条件下提高预测可靠性，而不牺牲常规操作中的性能。"}
{"llm_update_time": "20251210", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2512.07583", "html_url": "https://arxiv.org/abs/2512.07583", "title": "使用大型语言模型进行文本分类的互补学习方法", "title_en": "Complementary Learning Approach for Text Classification using Large Language Models", "authors": "Navid Asgari,Benjamin M. Cole", "background": "本研究提出了一种通过利用大语言模型（LLMs）的优势并结合学者和机器各自的优势，同时克服其短板的方法。这种结构化的研究方法是基于计算机科学中的链式思维和少样本学习提示构建的，旨在将最佳的多方合作模式从定性研究推广到定量研究中的学者-机器团队中。研究通过一组1,934篇宣布制药合作的新闻稿（1990-2017年）展示了如何使用这种方法来探究人类-机器评分差异。", "innovation": "本文创新地提出了一种利用LLMs的方法，该方法通过结合人类的归纳推理和自然语言能力，不仅让机器进行信息处理，也使人类能够反向思考并审视自己的决策过程。这种方法突破了传统定量研究中的局限，将人类和机器的优势互补应用于定量研究中。", "conclusion": "该方法表明，通过精心设计的低成本策略，学者可以有效管理和利用大型语言模型的内在缺陷。这种互补学习方法能够帮助人类在与大型语言模型的合作中提出更准确和可靠的信息分类，特别是在相关数据差异存在时。"}
{"llm_update_time": "20251210", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2512.07528", "html_url": "https://arxiv.org/abs/2512.07528", "title": "在共因下的基于模型的强化学习", "title_en": "Model-Based Reinforcement Learning Under Confounding", "authors": "Nishanth Venkatesh,Andreas A. Malikopoulos", "background": "我们研究的是在不可观测上下文环境中，基于模型的强化学习在上下文马尔可夫决策过程（C-MDPs）中的应用，这种环境中的共因干扰会导致离线数据集中的混淆。传统的方法在这种情况下基础不一致，因为这些方法生成的转移和奖励机制与评价基于状态策略所需的干预量化不匹配。", "innovation": "我们提出了一个次近代理政策评估方法，仅通过可观察到的状态-动作-奖励轨迹，结合了行为平均转移模型，构建了一个旁路MDP，其贝尔曼算子对基于状态的策略定义良好且一致，并且可以无缝集成到最大因果熵（MaxCausalEnt）模型学习框架中。这项方法使得在共因环境下，即使在上下文信息不可观测、不可用或难以收集时，也可以进行基于模型的学习和计划。", "conclusion": "所提出的表述使得在共因环境中进行基于模型的学习和规划成为可能，特别是在上下文信息不可观测，不可用或难以收集时，能够进行适当的模型学习和规划。"}
{"llm_update_time": "20251210", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2512.07576", "html_url": "https://arxiv.org/abs/2512.07576", "title": "R2MF-Net: 一种用于增强多方向脊柱X射线分割的递归剩余多路径融合网络", "title_en": "R2MF-Net: A Recurrent Residual Multi-Path Fusion Network for Robust Multi-directional Spine X-ray Segmentation", "authors": "Xuecheng Li,Weikuan Jia,Komildzhon Sharipov,Sharipov Hotam Beknazarovich,Farzona S. Ataeva,Qurbonaliev Alisher,Yuanjie Zheng", "background": "脊柱结构的精确分割是定量脊柱侧弯评估的前提，包括Cobb角测量、椎体滑动估计和曲率分类。在常规实践中，医生需要获取冠状位、左弯曲和右弯曲的X射线影像来评估畸形严重性和脊柱柔韧性。然而，分割步骤仍然是手动的、耗时的和不可重复的，特别是在低对比度图像和肋骨阴影或重叠组织存在的情况下。", "innovation": "本文提出了一种名为R2MF-Net的递归剩余多路径融合网络，专为自动分割多方向脊柱X射线影像而设计。该网络由粗分割网络和细分割网络组成，两个阶段均采用改进的Inception风格多分支特征提取器，并在跳连路径中插入了一个递归剩余跳频模块，以逐步对齐编码器和解码器语义。此外，还采用了一种多尺度跨阶段跳频机制（MC-Skip机制），使细网络能够复用粗网络多解码层的层级表示，从而增强不同成像方向和对比度条件下的分割稳定性。并且在瓶颈处使用了一个轻量级的空间-通道挤压-激励模块（SCSE-Lite）来强调脊柱相关的激活并抑制不必要的结构和背景噪音。", "conclusion": "本文提出的R2MF-Net在临床多视图X射线影像数据集上进行了评估，该数据集包含228个冠状位、左弯曲和右弯曲脊柱X射线影像，并附有专家标注。"}
{"llm_update_time": "20251210", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2512.07608", "html_url": "https://arxiv.org/abs/2512.07608", "title": "Metric-Fair Prompting: Treating Similar Samples Similarly", "title_en": "Metric-Fair Prompting: Treating Similar Samples Similarly", "authors": "Jing Wang,Jie Shen,Xing Niu,Tong Zhang,Jeremy Weiss", "background": "该研究背景在于指导大型语言模型（LLMs）在多选题医学问答中做出决策时，遵循基于度量公平性的约束。通过将每个问题与选项对视为二元实例，并使用NLP嵌入计算相似度，从而引导模型在处理相似问题对时一致地给出答案，以提高决策的公平性。", "innovation": "该研究引入了一种名为Metric-Fair Prompting的新颖框架，可以引导LLMs在度量公平性的约束下做出决策。该框架通过在相似问题对中一起解决问题，而非孤立处理，来促进个人公平性。通过计算相似度并施加类似Lipschitz的约束，确保相似输入具有相似评分，从而实现一致输出。", "conclusion": "研究结果表明，使用Metric-Fair Prompting框架可以提升LLMs在高风险医学选择题中的准确性。与标准单项提示方法相比，公平指导下的、基于自信的推理能够提高LLM的准确性。"}
{"llm_update_time": "20251210", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2512.07568", "html_url": "https://arxiv.org/abs/2512.07568", "title": "通过残留语义去相关实现双流跨模态表示学习", "title_en": "Dual-Stream Cross-Modal Representation Learning via Residual Semantic Decorrelation", "authors": "Xuecheng Li,Weikuan Jia,Alisher Kurbonaliev,Qurbonaliev Alisher,Khudzhamkulov Rustam,Ismoilov Shuhratjon,Eshmatov Javhariddin,Yuanjie Zheng", "background": "跨模态学习已成为整合不同信息源（如图像、文本和结构属性）的基础范式。然而，多模态表示常常会出现模态主导、冗余信息耦合和虚假的跨模态相关性问题，导致模型性能欠佳和可解释性有限。特别是，高方差模态往往会掩盖重要的但具有较少关联性的信号，而简单的融合策略则会无控地结合模态共享和特定模态的因素，使得理解哪种模态实际上驱动预测变得困难，且在一些模态噪声或缺失时难以保持鲁棒性。", "innovation": "本文提出了一种名为DSRSD-Net的双流残差语义去相关网络（Dual-Stream Residual Semantic Decorrelation Network），这是一种简单而有效的框架，通过残差分解和显式的语义去相关约束，实现模态特异性信息和模态共享信息的解耦。具体创新如下：（1）双流表征学习模块，通过残差投影分离内部模态（私有）和跨模态（共享）的潜在因子；（2）残差语义对齐头，使用对比和回归风格的目标将不同模态下的共享因子映射到共同的空间；（3）去相关和正交损失，通过正则化共享空间的协方差结构，同时强制共享和私有流之间的正交性，从而抑制跨模态冗余并防止特征坍塌。", "conclusion": "实验结果表明，DSRSD-Net在两个大规模教育基准上，相比于强大的单模态、早期融合、晚期融合和共注意机制基线，一致性地提高了下一步预测和最终结果预测的能力。"}
{"llm_update_time": "20251210", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2512.05994", "html_url": "https://arxiv.org/abs/2512.05994", "title": "KidSpeak：专为儿童语音识别和筛查设计的通用多功能LLM", "title_en": "KidSpeak: A General Multi-purpose LLM for Kids' Speech Recognition and Screening", "authors": "Rohan Sharma,Dancheng Liu,Jingchen Sun,Shijie Zhou,Jiayu Qin,Jinjun Xiong,Changyou Chen", "background": "随着对话式和扩散式AI的快速发展，AI在教育服务中的应用日益广泛，包括评分和评估工具以及提供个性化学习支持的系统。然而，这些适应性尚未完全延伸到儿童语音领域，现有的模型往往因依赖于设计用于清晰、明确成人语音的数据集而无法成功。特别是在早期发展阶段或有语言障碍的儿童，现有AI模型和数据集无法有效地处理这些独特的挑战。", "innovation": "本文介绍了一个针对儿童语音模式设计的多任务语音增强基础模型KidSpeak，它可以执行生成性和辨别性任务，能够将音素知识融入到语音编码器中，通过两阶段训练过程实现了四项任务中平均87%的准确率。此外，提出了可扩展、自动的语音对齐工具FASA，利用该工具构建了高质量的数据集，相比人工标注提高了数据质量13.6倍。", "conclusion": "KidSpeak和FASA代表了针对儿童言语和语言治疗的首个全面解决方案，提供了多功能语音LLM和稳健的对齐工具。"}
{"llm_update_time": "20251210", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2512.06343", "html_url": "https://arxiv.org/abs/2512.06343", "title": "当距离引诱偏移：代表距离偏差在BT损失函数中的奖励模型中的影响", "title_en": "When Distance Distracts: Representation Distance Bias in BT-Loss for Reward Models", "authors": "Tong Xie,Andrew Bai,Yuanhao Ban,Yunqi Hong,Haoyu Li,Cho-jui Hsieh", "background": "在RLHF架构中，奖励模型对于大型语言模型（LLM）的对齐至关重要。标准的奖励模型目标函数是Bradley-Terry（BT）损失，它通过成对数据（包括被选择和拒绝的回答）学习来获取信息。然而，这项工作揭示了BT损失在样本梯度上的局限性，尤其是representation distance（输出层的表示距离）对梯度更新的重大影响。", "innovation": "提出了NormBT，一种自适应的成对归一化方案，旨在平衡基于表示的影响，并使学习信号集中在预测误差上。NormBT是一种轻量级的、可插入的BT损失改进方案，几乎没有额外开销。通过实验证明，在不同的LLM基础模型和数据集上，NormBT能够持续改善奖励模型的性能，在RewardBench的逻辑推理类别中，其表现提升了超过5%。", "conclusion": "这项工作揭示了BT损失在广泛应用中的关键局限，并提供了一个简单的有效修正方案。NormBT不仅能够平衡因表示距离带来的影响，还能有效改善奖励模型的性能。"}
{"llm_update_time": "20251210", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2512.07832", "html_url": "https://arxiv.org/abs/2512.07832", "title": "一般化结果能否泛化？", "title_en": "Do Generalisation Results Generalise?", "authors": "Matteo Boglioni,Andrea Sgobbi,Gabriel Tavernini,Francesco Rita,Marius Mosbach,Tiago Pimentel", "background": "大语言模型（LLM）的离群分布（OOD）泛化能力对其部署至关重要。现有研究评估LLM的泛化性能时，通常只关注单一的OOD数据集，这可能导致未能精确评估模型的能力，因为实际部署后遇到的数据变化更为多样。", "innovation": "本文探究了泛化结果是否能够泛化。具体而言，本文在微调过程中评估模型在多个OOD测试集上的表现；通过控制领域内的表现，计算这些测试集上表现的相关性，从而评估控制领域内表现后的泛化表现的相关性。", "conclusion": "分析OLMo2和OPT后发现，没有明显的总体趋势：任意两个OOD测试集之间存在正相关或负相关的现象，严重依赖于所分析的具体模型选择。"}
{"llm_update_time": "20251210", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2512.06205", "html_url": "https://arxiv.org/abs/2512.06205", "title": "用以衡量和泛化接地问题的方法", "title_en": "On measuring grounding and generalizing grounding problems", "authors": "Daniel Quigley,Eric Maynard", "background": "符号接地问题探讨的是像“猫”这样的符号如何能够真正代表猫，而不仅仅是被操控的形状。本文将符号接地问题从二元判断重新定义为针对需求（包括上下文、含义类型、威胁模型、参考分布）的审计过程，每个需求都有评估元组（context, meaning type, threat model, reference distribution），涵盖了真实性、保真度、鲁棒性、组成性和稳健性等维度。", "innovation": "提出了一种新的框架来衡量和泛化符号接地问题。通过重新定义符号接地问题为针对不同评估维度的需求分析，该框架适用于四种不同的接地模式（符号、指称、向量、关系），并具体应用于三个案例研究。此外，本文为哲学家、计算机科学家、语言学家和数学家提供了共同的语言和技术框架，以系统地研究符号接地及其含义。", "conclusion": "此研究通过操作化哲学上的代表性问题，为不同领域的专家提供了一个系统性和技术性的框架，以便深入探讨符号接地和含义问题。模型论语义学实现了精确组成性，但缺乏演化意义上的合理性；大型语言模型在语言任务上表现为相关匹配并在局部上稳定，但在基于实际交互的世界任务上缺乏实际证据；而人类语言则通过演化和发育学习满足了高真实性的要求。"}
{"llm_update_time": "20251210", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2512.06196", "html_url": "https://arxiv.org/abs/2512.06196", "title": "ARCANE：一种面向可解释性和可配置性的多代理框架", "title_en": "ARCANE: A Multi-Agent Framework for Interpretable and Configurable Alignment", "authors": "Charlie Masters,Marta Grześkiewicz,Stefano V. Albrecht", "background": "随着基于大型语言模型的代理在长时任务中的部署越来越多，保持它们与相关方偏好的一致变得至关重要。在这些设置中，有效的对齐需要可解释的奖励模型，相关方能够理解并审计模型的目标。此外，奖励模型必须能够在交互时引导代理，允许偏好变化而不重新训练。", "innovation": "介绍了ARCANE框架，将对齐问题框架化为一个多代理合作问题，动态表示相关方偏好为自然语言条规：加权可验证的准则集，这些准则可以在任务上下文中即时生成。受到效用理论的启发，提出了条规学习的重建问题，并采用了一种正则化的群序列策略优化（GSPO）过程以平衡可解释性、忠实性和计算效率。", "conclusion": "使用来自GDPVal基准的数据集中的219个标记的条规，评估了ARCANE在需要多步推理和工具使用的能力挑战任务上的性能。学习到的条规产生了紧凑和易读的评估，并允许配置可调交易（如正确性与简洁性之间的交易）而不重新训练。实验结果表明，基于条规的奖励模型为复杂、长时AI系统的可解释性、测试时适应性对齐提供了一条有希望的道路。"}
{"llm_update_time": "20251210", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2512.06350", "html_url": "https://arxiv.org/abs/2512.06350", "title": "在Lex Fridman播客中解码关于AI风险意见分歧的原因", "title_en": "Why They Disagree: Decoding Differences in Opinions about AI Risk on the Lex Fridman Podcast", "authors": "Nghi Truong,Phanish Puranam,Özgecan Koçak", "background": "随着变革性技术的出现，社会经常暴露深层次的分歧，而在当前关于人工智能（AI）的辩论中最明显。尽管人们都希望确保AI惠及人类并避免灾难性后果，但在这个问题上仍有持续的分歧。本文分析了关于AI风险的当前辩论，将‘Visualization 末临派’和‘实践派’的观点区分为定义、事实、因果和道德前提，以识别核心争议点。", "innovation": "本文采用了一种分析推理链的大规模方法，使用LLM（大型语言模型）的集合来解析文本数据，这种分析方法可以应用于识别任何领域中关于公众风险争议的关键点。", "conclusion": "关于这两种形式的AI风险的分歧似乎有两个共同特征：那就是既没有显著的道德价值观差异，而且这两种风险都可以用不同的对人类理性局限性的看法来描述。"}
{"llm_update_time": "20251210", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2512.05983", "html_url": "https://arxiv.org/abs/2512.05983", "title": "AI生成的共谋妥协：建模、仿真和文本案例研究", "title_en": "AI-Generated Compromises for Coalition Formation: Modeling, Simulation, and a Textual Case Study", "authors": "Eyal Briman(Ben Gurion University of the Negev),Ehud Shapiro(Weizmann Institute of Science),Nimrod Talmon(Ben Gurion University of the Negev)", "background": "在AI子领域如论证、调解和协商中，找到各方提案之间的妥协是根本性的挑战。Elkind等人(2021)提出了一种过程，该过程寻求优于现状的得到多数支持的提案，遵循这一传统的研究方法，关键步骤是在迭代过程中识别能够让代理组成为联盟的妥协提案。但是，有效寻找这样的妥协提案仍是一个开放的问题。", "innovation": "通过正式化一个同时包含代理有限理性与不确定性的全面模型，并开发AI模型生成这样妥协提案，进而应用NLP技术并利用大语言模型（LLMs）创建文本的语义度量空间，开发算法以建议合适的妥协点。通过模拟各种共谋形成过程评估算法效果，展示了AI促进大规模民主文本编辑（如共同起草宪法）的潜力。", "conclusion": "证明了AI在促进大规模民主文本编辑方面的现状，特别在传统工具有限的协作起草宪法领域显示出潜力。"}
{"llm_update_time": "20251210", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2512.06351", "html_url": "https://arxiv.org/abs/2512.06351", "title": "LLM-Upgraded Graph Reinforcement Learning for Carbon-Aware Job Scheduling in Smart Manufacturing", "title_en": "LLM-Upgraded Graph Reinforcement Learning for Carbon-Aware Job Scheduling in Smart Manufacturing", "authors": "Zhiying Yang,Fang Liu,Wei Zhang,Xin Lou,Malcolm Yoke Hean Low,Boon Ping Gan", "background": "本文介绍了一种名为Luca的大语言模型（LLM）升级的基于图的强化学习框架，用于碳感知的灵活车间调度。Luca通过结合图神经网络和LLM，并采用精心设计的内部提示策略，解决了智能制造系统中动态和可持续调度的挑战，整合了结构特征和最新调度状态的上下文语义。", "innovation": "Luca通过图神经网络和LLM的结合，并使用内部提示策略生成了一种综合嵌入，该嵌入捕捉了最新调度状态的结构特征和上下文语义。然后，该表达性嵌入被传递给一个深度强化学习策略网络，生成针对最大工期和碳排放目标优化的实时调度决策。此外，引入了双目标奖励函数，以促进能源效率和调度及时性。", "conclusion": "实验结果显示，Luca在合成和公共数据集上均优于比较算法，特别是在合成数据集上，与最佳比较算法相比，平均可降低4.1%的最大工期，最高可达12.2%，同时保持相同的排放水平。在公共数据集上，还观察到了最大限度工期和排放的额外改进。这些结果表明，Luca对于智能制造中的碳意识调度是有效和实用的。"}
{"llm_update_time": "20251210", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2512.06001", "html_url": "https://arxiv.org/abs/2512.06001", "title": "小型语言模型重塑高等教育：课程、教材与教学方法", "title_en": "Small Language Models Reshape Higher Education: Courses, Textbooks, and Teaching", "authors": "Jian Zhang,Jia Shao", "background": "大型语言模型（LLMs）在科学和教育领域引入了新的范式，但在高等教育中的应用受到内在局限的制约，包括产生不准确性和高计算需求，这些都与高等教育对准确和可靠知识的严格要求不相符。相比之下，小型语言模型（MiniLMs）因其轻便的性质和精确的检索能力，在专业教育中展现出明显的优势。", "innovation": "本研究以“大气物理”课程为例，构建了一个专门的语料库和图像库，收集了超过550,000篇来自130多本国际知名地球和环境科学期刊的文章，从中提取出超过10亿条高质量句子级别的语料和超过300万张高分辨率学术图像。利用MiniLMs，这些资源被组织成高维向量库，用于精确检索和高效利用大量教育资源。在此基础上，系统地重新设计了“大气物理”的课程、教材和教学策略。课程设计旨在打破大气科学、空间科学、水文学和遥感之间的传统边界，教学材料从静态、滞后的文本格式转化为由MiniLM驱动的动态数字资源库。教学方法设计了一个基于问题的学习途径，促进由被动的知识传递向主动的认知发展转变。", "conclusion": "基于MiniLMs的“大气物理”课程为“AI在教育中的应用”提供了一条具体途径。"}
{"llm_update_time": "20251210", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2512.06607", "html_url": "https://arxiv.org/abs/2512.06607", "title": "快速有效解决LLMs前瞻偏差问题的方法", "title_en": "A Fast and Effective Solution to the Problem of Look-ahead Bias in LLMs", "authors": "Humzah Merchant,Bradford Levy", "background": "将大型语言模型（LLMs）应用于金融领域的预测任务面临着前瞻偏差的挑战，因为LLMs是在长时间序列数据上训练的，这意味着它们会带有未来信息。这使得金融领域中常用的回测方法变得不可行，因为用特定的知识截止日期从头重新训练前沿模型是不切实际的。", "innovation": "提出了一种快速、有效且低成本的解决方案。该方法在推理时通过调整大型基础模型的logits使用一对较小的、专门化的模型来进行指导——一个专门针对忘记的信息进行微调，另一个专门针对保留的信息进行微调。这种方法能有效地移除具体和语义知识，纠正偏差，并优于之前的方法。", "conclusion": "该方法能成功解决前瞻性偏差问题，并在去除具体和语义知识、纠正偏差和性能方面优于之前的方法。"}
{"llm_update_time": "20251210", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2512.06641", "html_url": "https://arxiv.org/abs/2512.06641", "title": "基于索引的高效有效网页内容提取方法", "title_en": "An Index-based Approach for Efficient and Effective Web Content Extraction", "authors": "Yihan Chen,Benfeng Xu,Xiaorui Wang,Zhendong Mao", "background": "由于网络代理（例如Deep Research）会经常消耗大量网页来收集和分析信息，这使得对大型上下文管理的LLM的管理在高预算和低信号密度下成为了一个关键且技术性很强的问题。现有的信息提取解决方案存在不足，生成式提取模型存在高延迟的问题，基于规则的启发式方法缺乏适应性，而分块重排序方法则忽视了网页结构。", "innovation": "本文提出了一种基于索引的网页内容提取方法，将其提取过程重新定义为一种高效的索引预测任务，从而实现了有效性和效率的双重提升。该方法将HTML切分为结构感知、可寻址的段落，并仅提取与给定查询相关的文本的起始位置的索引，从而将提取延迟与内容长度脱钩，允许快速、查询相关的提取。", "conclusion": "我们在一个RAG QA系统中将该方法作为后检索处理组件进行评估，发现其提高了QA准确性。我们直接测量了其在主要内容提取（ME）和查询相关提取（QE）两种场景下的匹配率，实验结果显示，该方法在准确性和速度上均优于现有工作，有效缩小了LLMs与网页内容之间的差距。"}
{"llm_update_time": "20251210", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2512.06713", "html_url": "https://arxiv.org/abs/2512.06713", "title": "在行动前三思：一种用于局部对抗匿名化的理性代理框架", "title_en": "Look Twice before You Leap: A Rational Agent Framework for Localized Adversarial Anonymization", "authors": "Donghang Duan,Xu Zheng", "background": "当前基于LLM的文字匿名化框架通常依赖远程API服务的强大LLM，这暴露出一个固有的‘隐私悖论’：用户必须向不可信的第三方披露数据以获得更好的隐私保护。直接将这些框架迁移至本地的小规模模型（LSMs）也因我们的核心发现而效果不佳，带来了巨大的实用性崩溃。", "innovation": "本文认为这种失败不仅仅是小规模模型能力不足所致，而是当前最先进的方法在贪婪对抗策略方面的固有不合理性。我们提出了Rational Localized Adversarial Anonymization（RLAA），一种完全本地化的、无需训练的框架，采用Attacker-Arbitrator-Anonymizer (A-A-A) 架构。该框架引入仲裁者作为理性门卫，验证攻击者的推断，过滤出对隐私保护无显著益处的反馈。研究证明，RLAA实现了最佳的隐私-实用性权衡，并在某些情况下甚至在帕累托原则上优于当前最先进的方法。", "conclusion": "大量的实验数据表明，RLAA不仅实现了最佳的隐私与实用性权衡，还在某些情况下超越了当前的领先方法。代码和数据集将在文章被接受后公开发布。"}
{"llm_update_time": "20251210", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2512.06048", "html_url": "https://arxiv.org/abs/2512.06048", "title": "适应性AI在网络安全中实现精确性之路", "title_en": "The Road of Adaptive AI for Precision in Cybersecurity", "authors": "Sahil Garg", "background": "网络安全领域日益复杂的态势为AI研究和应用提出了独特的机会和挑战。本文基于在设计、构建和运行网络安全生成式AI管道方面获得的关键经验和见解，强调了持续适应性对于跟上不断变化的知识库、工具和威胁的必要性。", "innovation": "本文提出了实用的指导建议，来源于实际部署中的经验，提出了在检索和模型层面进行适应的最佳实践，并指出了使生成式AI在网络安全中更加稳健、精确和可审计的开放性研究方向。", "conclusion": "本文旨在为AI从业者和行业利益相关者提供关于网络安全中生成式AI前沿的可操作性视角，特别关注不同的适应机制如何在端到端系统中互补增强网络安全防御的精确度。"}
{"llm_update_time": "20251210", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2512.06421", "html_url": "https://arxiv.org/abs/2512.06421", "title": "在层次递归生成中的重新思考训练动力学", "title_en": "Rethinking Training Dynamics in Scale-wise Autoregressive Generation", "authors": "Gengze Zhou,Chongjian Ge,Hao Tan,Feng Liu,Yicong Hong", "background": "近年来，自回归（AR）生成模型在多媒体合成方面取得了重大进展。其中，逐级预测已成为了流行的方法，这种方法通过从粗到细的方式生成图像。然而，这种模型在不同层次上存在曝光偏差，这限制了生成的质量。", "innovation": "本文提出了一种名为Self-Autoregressive Refinement (SAR)的自回归精炼技术。SAR引入了一种名为Stagger-Scale Rollout (SSR)的机制，通过进行轻量级的自回归滚动来使模型接触其自己的中介预测，从而实现了训练与测试模式的一致性，同时提出了一种互补的对比性学生强制损失（CSFL），为自动生成的环境提供足够的监督以确保稳定的训练。实验结果表明，将SAR应用于预训练的AR模型可以显著提高生成质量，几乎不增加计算成本。", "conclusion": "鉴于SAR方法的高效性、可扩展性和有效性，我们预期它可以成为视觉自回归生成的可靠后训练方法。"}
{"llm_update_time": "20251210", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2512.06716", "html_url": "https://arxiv.org/abs/2512.06716", "title": "认知控制架构（CCA）：实现稳健对齐AI代理的生命周期监督框架", "title_en": "Cognitive Control Architecture (CCA): A Lifecycle Supervision Framework for Robustly Aligned AI Agents", "authors": "Zhibo Liang,Tianze Hu,Zaiye Chen,Mingjie Tang", "background": "大规模语言模型（LLM）代理在间接提示注入（IPI）攻击面前表现出显著的脆弱性。这些攻击通过污染外部信息来源，利用现有防御机制中安全性和功能性的基本权衡，操控代理行为，导致恶意和未经授权的工具调用，使代理偏离既定目标。复杂的IPI使系统的脆弱性更加凸显：当前的防御措施虽然具有一定效果，但大多数防御架构本质上是碎片化的，无法在整个任务执行流程中提供完整的完整性保障，迫使在安全性、功能性和效率之间进行多维度的妥协。", "innovation": "本文提出了认知控制架构（CCA），一个全面的认知监督框架。CCA通过两个协同支柱构建了一个有效、双层的防御系统：(i) 通过预生成的“意图图”进行主动和预自卫的控制流和数据流完整性保障；(ii) “分层调节者”，在检测到偏离后启动基于多维评分的深度推理，专门对抗复杂的条件性攻击。实验表明，CCA不仅有效抵御了挑战其他先进防御方法的复杂攻击，还实现了在不妥协安全性的前提下具有显著效率和鲁棒性的性能，从而解决了上述多维度的权衡。", "conclusion": "CCA有效克服了传统的多维度权衡，实现了在保证安全的同时具备显著的效率和鲁棒性，从而从根本上缓解了间接提示注入攻击带来的系统脆弱性。通过全面的生命周期监督，CCA为实现稳健对齐的AI代理提供了一个有效框架。"}
{"llm_update_time": "20251210", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2512.06393", "html_url": "https://arxiv.org/abs/2512.06393", "title": "LLM在规则删除、改写和压缩下的多步逻辑推理：少即是多", "title_en": "Less Is More for Multi-Step Logical Reasoning of LLM Generalisation Under Rule Removal, Paraphrasing, and Compression", "authors": "Qiming Bao,Xiaoxuan Fu", "background": "大型语言模型（LLMs）在许多自然语言任务上表现出色，但在面对逻辑语境中的结构性干扰时的一般化能力仍然不甚清楚。本文引入了一个受控评估框架，通过四种专门的压力测试来评估推理可靠性：删除多余或关键的推理规则、注射矛盾证据、生成多种等价定律下的逻辑保持重写，以及叠加多种逻辑转换。研究在三个代表性模型系列：BERT、Qwen2和LLaMA类似模型中进行了实验。", "innovation": "本文提出了一个控制评估框架，通过特定的压力测试来深入探究LLMs在面对逻辑推理任务中规则删除、改写和压缩时的一致表现和弱点。", "conclusion": "实验结果表明，LLMs对外延变化保持稳定不变性，但在缺失或矛盾证据的情况下仍具有根本性的脆弱性。本文框架提供了一种清洁的诊断工具，用于隔离这种推理失败模式，并突显了当前LLMs在逻辑推理能力上的持续差距。"}
{"llm_update_time": "20251210", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2512.06810", "html_url": "https://arxiv.org/abs/2512.06810", "title": "MMDuet2: 通过多轮强化学习提高视频MLLMs的主动交互能力", "title_en": "MMDuet2: Enhancing Proactive Interaction of Video MLLMs with Multi-Turn Reinforcement Learning", "authors": "Yueqian Wang,Songxiang Liu,Disong Wang,Nuo Xu,Guanglu Wan,Huishuai Zhang,Dongyan Zhao", "background": "近期，在视频多模态大型语言模型（Video MLLMs）领域取得了显著进展，大幅提升了视频理解和多模态交互能力。尽管大多数现有系统以用户交互为基础，即模型只能在用户操作后响应，但在视频播放过程中主动决定何时响应则为实时应用提供了新的挑战和机遇。", "innovation": "本文介绍了一种创新的基于文本到文本的主动交互方法，该方法允许模型在对话历史和当前帧视音频上下文中自主决定何时响应或保持沉默。该方法摒弃了需要手动调整响应决策阈值和标注精确回复时间的传统方法，改用基于多轮强化学习的训练方法，以鼓励及时和准确的响应。通过这种方法，研究团队成功训练出了一个名为MMDuet2的模型。", "conclusion": "实验结果表明，MMDuet2在响应及时性和质量上显著优于现有的主动视频MLLM基线模型，达到了ProactiveVideoQA基准测试的最先进水平。"}
{"llm_update_time": "20251210", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2512.07801", "html_url": "https://arxiv.org/abs/2512.07801", "title": "协作因果理解：弥合人类与人工智能决策支持中的互补性差距", "title_en": "Collaborative Causal Sensemaking: Closing the Complementarity Gap in Human-AI Decision Support", "authors": "Raunak Jain,Mudita Khurana", "background": "LLM（大型语言模型）驱动的代理正在迅速被整合进专家决策支持中，但在复杂的、高风险的环境中，它们往往无法使整体团队变得更为聪明。人类与人工智能团队经常表现逊于最佳个体；专家在验证循环与过度依赖之间摇摆不定；所承诺的互补性并未实现。作者认为，这不仅仅是一个准确性问题，而是在于我们对人工智能辅助的基本认知存在缺陷：专家决策过程是通过协作的认知过程完成的，在此过程中，人类和人工智能不断共同构建、测试和修订心智模型、目标以及约束条件。", "innovation": "我们提出了一种名为协作因果理解（CCS）的研究议程和组织框架，旨在为决策支持代理设计伙伴，使之保持不断演进的专业人士推理模型，帮助阐明和修订目标，共同构建和压力测试因果假设，从联合决策的结果中学习，使得人类和代理人都随时间改善。", "conclusion": "这些方向可以从培训生态、合作思考的工具价值、共同创建模型的表示和交互协议，以及以信任和互补性为中心的评估方面重新构想多智能体系统（MAS）研究，围绕能够参与协作理解的代理，并把它们作为与人类伙伴共同思考的人工智能队友展开研究。"}
{"llm_update_time": "20251210", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2512.06726", "html_url": "https://arxiv.org/abs/2512.06726", "title": "视觉接地中熵的作用：分析与优化", "title_en": "The Role of Entropy in Visual Grounding: Analysis and Optimization", "authors": "Shuo Li,Jiajun Sun,Zhihao Zhang,Xiaoran Fan,Senjie Jin,Hui Li,Yuming Yang,Junjie Ye,Lixing Shen,Tao Ji,Tao Gui,Qi Zhang,Xuanjing Huang", "background": "最近利用强化学习对多模态大型语言模型进行微调已经取得了显著进展，特别是一系列熵控技术的应用。尽管如此，在视觉接地这类感知导向任务中，熵的作用和特性仍缺乏深入探讨，以及如何有效控制熵的策略也尚未充分研究。", "innovation": "研究了视觉接地中的熵作用与推理任务的区别，并提出了一种名为ECVGPO（熵控制视觉接地策略优化）的可解释算法，用于有效调节熵。该算法能够更好地平衡探索与利用之间的权衡。", "conclusion": "实验结果表明，ECVGPO在各种基准和模型上都实现了广泛改进。"}
{"llm_update_time": "20251210", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2512.06933", "html_url": "https://arxiv.org/abs/2512.06933", "title": "MATEX：一种解释以太坊交易的多Agent框架", "title_en": "MATEX: A Multi-Agent Framework for Explaining Ethereum Transactions", "authors": "Zifan Peng", "background": "理解复杂的以太坊交易具有挑战性，因为多跳代币流动、嵌套合约调用和不透明的执行路径经常会导致用户盲目签名。通过与普通用户、开发者和审计师的访谈，研究人员识别出了需要基于链上证据和实际协议语义的忠实逐步骤解释。", "innovation": "提出了一个名为MATEX的多Agent认知框架（matax），将交易理解建模为协作调查过程，结合快速假设生成、动态离链知识检索、证据驱动合成和对抗性验证，以生成忠实的解释。", "conclusion": "MATEX利用多Agent协作的调查过程理解以太坊交易，通过联合生成假设、动态检索知识，整合证据进行对抗性验证，提高了交易解释的准确性和透明度，有助于提升用户，开发者和审计师对以太坊交易的理解。"}
{"llm_update_time": "20251210", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2512.07011", "html_url": "https://arxiv.org/abs/2512.07011", "title": "Block Sparse Flash Attention", "title_en": "Block Sparse Flash Attention", "authors": "Daniel Ohayon,Itay Lamprecht,Itay Hubara,Israel Cohen,Daniel Soudry,Noam Elata", "background": "现代大型语言模型越来越需要处理长上下文和多文档任务，但注意力机制的二次复杂性造成了严重的计算瓶颈。", "innovation": "提出了Block-Sparse FlashAttention (BSFA) 方法，这是一种无需训练即可加速长上下文推理并保持模型质量的插件替代方案。BSFA 计算每个查询的最相关的值块，通过对比块级别的最大分数和校准过的阈值来跳过大约50%的计算和内存传输。", "conclusion": "在 Llama-3.1-8B 模型上，BSFA 在实际推理基准上实现了最多1.10倍的加速，在查找针尖于干草堆式的检索任务上实现最多1.24倍的加速，同时保持了超越99%的基本准确率。在某些配置下，还会提高准确率，因为关注最相关的部分。该实现已经可以在指定链接处下载使用。"}
{"llm_update_time": "20251210", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2512.06721", "html_url": "https://arxiv.org/abs/2512.06721", "title": "ProAgent: 利用按需感应上下文增强主动大语言模型代理系统", "title_en": "ProAgent: Harnessing On-Demand Sensory Contexts for Proactive LLM Agent Systems", "authors": "Bufang Yang,Lilin Xu,Liekang Zeng,Yunqi Guo,Siyang Jiang,Wenrui Lu,Kaiwei Liu,Hancheng Xiang,Xiaofan Jiang,Guoliang Xing,Zhenyu Yan", "background": "现有的大语言模型（LLM）代理主要遵循一种反应式范式，依赖于用户的明确指令来触发服务，这增加了物理和认知的工作负担。本文探讨了通过结合大规模的感应上下文和LLM推理，来开发一种主动代理系统的背景。", "innovation": "提出了ProAgent，这是一种端到端的主动代理系统，它通过利用按需分层感知持续感应环境，提取包含感官和人格指标的层次结构上下文。ProAgent引入了一种面向主动的推理器，能够将这些上下文映射到用户需求和工具调用，提供主动的帮助。此外，ProAgent在增强现实（AR）眼镜和边缘服务器上进行了实现，并在真实测试环境、公共数据集和用户研究中进行了广泛评估。", "conclusion": "实验结果表明，ProAgent在主动预测准确性、工具调用F1分数和用户满意度方面均优于最先进的基线系统，标志着主动代理系统的道路上取得了重要进展。"}
{"llm_update_time": "20251210", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2512.06737", "html_url": "https://arxiv.org/abs/2512.06737", "title": "Arc Gradient Descent: 一种基于相位感知和用户可控步进动力学的梯度下降的数学推导改写", "title_en": "Arc Gradient Descent: A Mathematically Derived Reformulation of Gradient Descent with Phase-Aware, User-Controlled Step Dynamics", "authors": "Nikhil Verma,Joonas Linnosmaa,Espinosa-Leal Leonardo,Napat Vajragupta", "background": "该篇论文描述了对非凸基准函数和真实世界ML数据集上的ArcGD优化器的研究。ArcGD的定义、实现和评估在文中进行了详述。研究首先使用Adam优化器对高度非凸的Rosenbrock函数进行了初步的比较研究，然后将ArcGD与当前最先进的优化器在CIFAR-10图像分类数据集上进行了评估。", "innovation": "该研究提出了ArcGD优化器，这是一种基于数学推导、相位感知和用户可控步进动力学的梯度下降改写。ArcGD在不同维度上的Rosenbrock函数和ML任务中展示了优于其他优化器的性能。", "conclusion": "ArcGD在CIFAR-10数据集上的多个神经网络架构及迭代次数中展现了优于其他状态最优化器（如Adam、AdamW、Lion和SGD）的结果。同时，ArcGD在几何压力测试和标准深度学习基准测试中表现出优异性能，证明了其广泛的适用性。此外，研究发现ArcGD的一个变种可以视为Lion优化器的一个特例，这揭示了不同优化方法之间的内在联系。"}
{"llm_update_time": "20251210", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2512.06921", "html_url": "https://arxiv.org/abs/2512.06921", "title": "NeuroABench: 多模态神经外科解剖识别评估基准", "title_en": "NeuroABench: A Multimodal Evaluation Benchmark for Neurosurgical Anatomy Identification", "authors": "Ziyang Song,Zelin Zang,Xiaofan Ye,Boqiang Xu,Long Bai,Jinlin Wu,Hongliang Ren,Hongbin Liu,Jiebo Luo,Zhen Lei", "background": "现有的多模态大语言模型（MLLMs）在手术视频理解方面展示了显著的潜力，促进了外科教育和辅助的发展，但现有研究和数据集主要集中在理解和定义手术流程，对外科解剖学理解的作用关注不足。外科医生在临床实践中高度依赖精确的解剖学理解来解读、回顾和从手术视频中学习。为了填补这一空白，我们推出了神经外科解剖学基准（NeuroABench），这是一个专为评价神经外科领域解剖学理解而设计的首位多模态基准，涵盖了9小时的注解神经外科手术视频，包括89种不同的手术，使用新的多模态注释管道开发，经过多轮审查。基准评估了68种临床解剖结构的识别，为评估模型性能提供了一个严谨且标准化的框架。实验结果显示多种最先进的MLLMs在解剖结构识别任务上的显著限制，性能最好的模型也只能达到40.87%的准确率。", "innovation": "我们提出了NeuroABench，这是首个专门用于评估神经外科解剖理解的多模态基准，包含9小时的注解神经外科视频，涵盖了89种不同的手术，并通过新的多模态注释管道开发。为了进一步评估基准，我们还进行了学生测试，发现最高分的学生达到了56%的准确率，而最低得分为28%，平均分为46.5%。虽然最佳的MLLM与得分最低的学生表现相似，但在整体上仍然落后于群体的平均水平，这突显了MLLMs在解剖学理解方面的进展以及与人类水平表现之间的差距。", "conclusion": "尽管现有的多模态大语言模型在解剖理解方面有所进展，但在达到与人类水平相当的表现方面仍然有很大的差距。NeuroABench为评估模型在神经外科解剖识别中的表现提供了严谨且标准化的框架，揭示了当前模型的局限性，为未来的研究和发展提供了重要的参照和新的挑战。"}
{"llm_update_time": "20251210", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2512.07141", "html_url": "https://arxiv.org/abs/2512.07141", "title": "Think-Reflect-Revise: 一个由政策导向的反思框架，用于大型视觉语言模型的安全对齐", "title_en": "Think-Reflect-Revise: A Policy-Guided Reflective Framework for Safety Alignment in Large Vision Language Models", "authors": "Fenghua Weng,Chaochao Lu,Xia Hu,Wenqi Shao,Wenjie Wang", "background": "随着多模态推理增强了大型视觉语言模型（LVLMs）的整体能力，最近的研究开始关注安全导向的推理，以在生成最终回答之前分析潜在的安全风险。虽然这种方法提高了安全意识和可解释性，但单次思考后回答的方法仍然容易受到上下文或视觉 jailbreak 攻击。这表明单次推理可能会忽略其自身输出中的显性有害内容。我们的关键洞察是通过反思利用这一被浪费的信号，可以有效利用第一次推理中揭示的恶意内容来实现真正的自我纠正，防止不安全的生成。", "innovation": "我们提出了一种三维训练框架 Think-Reflect-Revise (TRR)，该框架通过政策导向的自我反思来增强 LVLMs 的安全对齐。首先构建了一个包括 5,000 个示例的 Reflective Safety Reasoning (ReSafe) 数据集，这些示例遵循 think-reflect-revise 过程。然后使用 ReSafe 数据集微调目标模型以初始化反思行为，最后通过强化学习增强政策导向的反思。实验结果表明，TRR 显著提高了 LVLMs 的安全性能，在 Qwen2.5-VL-7B 上整体安全响应率从 42.8% 提高到 87.7%，同时在 MMMU 和 MMStar 等通用基准上保持了稳定性能。", "conclusion": "TRR 框架在多个安全意识基准和 jailbreak 攻击测试中显著提高了安全性能，同时在通用基准上保持了稳定性能。详细的实验结果和项目页面可在相关网址查阅。"}
{"llm_update_time": "20251210", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2512.07109", "html_url": "https://arxiv.org/abs/2512.07109", "title": "抽象推理中的神经亲和性框架：基于过程任务分类诊断变换器架构中的合成缺口", "title_en": "A Neural Affinity Framework for Abstract Reasoning: Diagnosing the Compositional Gap in Transformer Architectures via Procedural Task Taxonomy", "authors": "Miguel Ingram,Arthur Joseph Merritt III", "background": "本文回应了Hodel等人（2024）关于重新定义ARC（抽象推理挑战）中任务相关性的呼吁，提出了一种基于规则分析验证的9类任务分类法，涵盖所有400个任务，准确率为97.5%。该分类法通过CNN在网格像素上的训练（S3准确性为95.24%，总体为36.25%，比随机高3.3倍）进行了可视化验证。通过分析测试集显示出35.3%的任务具有低神经亲和性，这与ARC-AGI-2的架构偏见相呼应。", "innovation": "1. 提出了9类任务分类法，并通过97.5%的准确率验证，涵盖所有400个任务。\n2. 证实了分类法的可视化一致性，通过CNN在网格像素上的训练，并应用于ARC-AGI-2测试集。\n3. 发现了高度合成缺口，表明架构适应性比训练数据更重要。\n4. 结合Li等人的独立ViTARC研究，展示了该框架的预测能力。", "conclusion": "研究表明，合成缺口的存在需要混合架构，结合亲和性对齐的模块以提高性能。此外，该分类法为精准诊断低亲和性任务（A2）和高亲和性任务（C1）的效果提供了依据。研究成果提供优化ARC任务的方法，并发布了验证过的分类法框架。"}
{"llm_update_time": "20251210", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2512.06866", "html_url": "https://arxiv.org/abs/2512.06866", "title": "Less Is More, but Where? Dynamic Token Compression via LLM-Guided Keyframe Prior", "title_en": "Less Is More, but Where? Dynamic Token Compression via LLM-Guided Keyframe Prior", "authors": "Yulin Li,Haokun Gui,Ziyang Fan,Junjie Wang,Bin Kang,Bin Chen,Zhuotao Tian", "background": "近年来，视频大型语言模型(VLLMs)在视频理解方面取得了显著进展，但处理长视频时面临着因视觉标记序列过长而导致的计算成本急剧增加的问题。现有的关键帧采样方法能够在一定程度上提高时间建模效率，但引入了额外的计算成本，并且二元帧选择方式被认为效果不佳。", "innovation": "本文提出了通过LLM指导的关键帧先验实现动态标记压缩的DyToK方法。该方法利用VLLMs固有的注意力机制，实现在无需训练的情况下动态调整每帧标记保留的比例，优先保留富含语义的信息，同时抑制冗余。DyToK方法与现有压缩方法如VisionZip和FastV具有良好的兼容性，在多个VLLMs如LLaVA-OneVision和Qwen2.5-VL中实现了4.3倍的加速，同时保持了准确性。", "conclusion": "广泛的实验表明，DyToK方法在保持准确性的同时大幅提升了效率，展示了优越的效率-准确性的平衡。DyToK方法还与现有的压缩方法无缝集成，为视频理解和处理领域提供了新的解决方案。"}
{"llm_update_time": "20251210", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2512.07198", "html_url": "https://arxiv.org/abs/2512.07198", "title": "使用丰富逻辑推理生成叙事图像", "title_en": "Generating Storytelling Images with Rich Chains-of-Reasoning", "authors": "Xiujie Song,Qi Jia,Shota Watanabe,Xiaoyi Pang,Ruijie Chen,Mengyue Wu,Kenny Q. Zhu", "background": "图像可以通过丰富的、逻辑上连接的视觉线索来传递引人入胜的故事。这些线索形成了图像内的逻辑推理链 (CoRs)，使观察者能够推理事件、因果关系和其他信息，从而理解其背后的故事。然而，由于其复杂的语义特征，叙事图像难以生成，因此较为稀缺。", "innovation": "本文提出了叙事图像生成任务，结合大型语言模型 (LLMs) 的创造性推理能力和文本到图像 (T2I) 模型的视觉合成能力，设计了一个两阶段的管道StorytellingPainter。此外，还构建了一个专门的评估框架，包括语义复杂性评估器、KNN 基准多样性评估器和故事图像对齐评估器。为了弥补开源和专有 LLM 的性能差距，还探索了定制化的训练策略，生成了一系列轻量级且有效的模型Mini-Storytellers。", "conclusion": "实验结果证实了本文方法的可行性和有效性。代码可从提供的链接获得。"}
{"llm_update_time": "20251210", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2512.06989", "html_url": "https://arxiv.org/abs/2512.06989", "title": "Flash 多头前馈网络", "title_en": "Flash Multi-Head Feed-Forward Network", "authors": "Minshen Zhang,Xiang Hu,Jianguo Li,Wei Wu,Kewei Tu", "background": "我们探索使用多头FFN (MH-FFN) 作为Transformer架构中的FFN的替代方案，受到单头注意力机制与FFN结构相似性的启发。尽管多头机制可以增强注意力的表达能力，但直接将它们应用到FFNs上会面临两个挑战：内存消耗随着头数增加而成比例增加，以及随着模型规模扩大，中间层尺寸的增长与固定头数的比例不匹配，这两点都降低了FFNs的可扩展性和表达能力。", "innovation": "我们提出了Flash 多头FFN (FlashMHF)，其两个关键创新点：一种I/O感知的融合内核计算在线处理SRAM中的输出，类似于FlashAttention；使用动态加权并行子网络来保持中间层和头数尺寸之间的平衡比例。", "conclusion": "在从128M到1.3B参数的模型上进行了验证，FlashMHF在困惑度和下游任务准确性上优于SwiGLU FFNs，同时将峰值内存使用量减少3-5倍，推理加速最高可达1.08倍。我们的工作确立了多头设计作为一种FFNs的更优架构原则，提出FlashMHF作为Transformer中FFNs的高效且可扩展的替代方案。"}
{"llm_update_time": "20251210", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2512.07222", "html_url": "https://arxiv.org/abs/2512.07222", "title": "免费提高视觉语言模型鲁棒性的不失注意力", "title_en": "Pay Less Attention to Function Words for Free Robustness of Vision-Language Models", "authors": "Qiwei Tian,Chenhao Lin,Zhengyu Zhao,Chao Shen", "background": "本文旨在解决鲁棒视觉语言模型（VLM）的稳健性和性能之间的权衡。研究发现，功能词可能会导致VLM在跨模态对抗攻击中变得脆弱。因此，作者提出了功能词去注意（FDA）方法以减轻功能词的影响。", "innovation": "FDA方法计算原始注意力与功能词交叉注意力之间的差异，并从前者中减去后者，从而生成更对齐和鲁棒的VLM。该方法类似差分放大器，并在不同下游任务、数据集和模型上进行了广泛的实验。结果表明，使用FDA方法后，模型在多种攻击下的错误率降低，同时保持了较低的性能损失，甚至在某些情况下提高了性能。", "conclusion": "FDA方法实验性地证明了其可扩展性、泛化能力和零样本性能，并通过深入的消融研究和分析进一步验证了其有效性。研究团队承诺将代码公开在 a specific URL."}
{"llm_update_time": "20251210", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2512.07795", "html_url": "https://arxiv.org/abs/2512.07795", "title": "ReasonBENCH：评估LLM推理的稳定性或不稳定性", "title_en": "ReasonBENCH: Benchmarking the (In)Stability of LLM Reasoning", "authors": "Nearchos Potamitis,Lars Klein,Akhil Arora", "background": "大型语言模型（LLMs）现在越来越多地应用于需要多步骤推理和链式思维的场景。然而，当前的评估实践主要报告单一运行准确率，忽略了从随机解码自然产生的内在不确定性。这种遗漏导致了认知盲区，因为它使得研究者无法可靠地评估方法报告的性能是否稳定、可重复或成本效益一致。", "innovation": "本文提出了ReasonBENCH，这是首个旨在量化LLM推理根本不稳定性的基准。ReasonBENCH包括（i）一个模块化的评估库，标准化了推理框架、模型和任务；（ii）一个多运行协议，用于报告质量和成本的统计上可靠的指标；（iii）一个公开的排行榜，鼓励变异意识的报告。我们在来自不同领域的任务中发现，大多数推理策略和模型都表现出高不稳定性。", "conclusion": "我们的结果强调了重复性作为可靠LLM推理的关键维度，并为未来的推理方法和不确定性量化技术奠定了基础。ReasonBENCH已在网页提供。"}
{"llm_update_time": "20251210", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2512.07564", "html_url": "https://arxiv.org/abs/2512.07564", "title": "更多可靠的 artificial intelligence：减少视觉语言模型中的幻觉", "title_en": "Toward More Reliable Artificial Intelligence: Reducing Hallucinations in Vision-Language Models", "authors": "Kassoum Sanogo,Renzo Ardiccioni", "background": "视觉语言模型（VLMs）通常会生成与图像内容相关但是不准确的推测性内容。本文针对这一问题，提出了一种无需训练的自我修正框架，该框架通过不确定性引导的视觉重新注意机制使VLMs能够迭代地改进其响应。这种方法利用了多维不确定性量化（包括 token熵、注意力分散度、语义一致性和声明置信度），结合注意力引导的对未充分探索区域的裁剪来实现。”", "innovation": "该框架完全使用冻结的预训练VLM，无需进行梯度更新，即可帮助模型减少幻觉。该方法已经在 Qwen2.5-VL-7B 架构上进行了验证，并且实验结果展示了相较于基线，幻觉率降低了9.8个百分点，同时在对抗划分上物体存在准确度提高了4.7个百分点。此外，定性分析也证实，不确定性引导的重新注意能够成功将修正植根于视觉证据中，而标准解码失败的地方正是这一点的集中体现。", "conclusion": "该方法已经在 Qwen2.5-VL-7B 架构上进行了验证，未来计划扩展到不同的架构中。同时，作者发布了该方法的代码和实现方式，以促进未来在可信多模态系统中进行的研究。"}
{"llm_update_time": "20251210", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2512.07179", "html_url": "https://arxiv.org/abs/2512.07179", "title": "PICKT：基于知识图谱概念关系的实用连贯概念知识追踪模型用于个性化学习", "title_en": "PICKT: Practical Interlinked Concept Knowledge Tracing for Personalized Learning using Knowledge Map Concept Relations", "authors": "Wonbeen Lee,Channyoung Lee,Junho Sohn,Hansam Cho", "background": "近年来个性化学习的兴起使得能够准确追踪学生个体知识状态并根据这些信息提供定制化学习路径的智能辅导系统（ITS）成为了必要任务。然而，现有的知识追踪（KT）模型存在输入数据格式限制、新学生入学或新问题添加时初始冷启动问题以及现实服务环境中稳定性不足等局限。", "innovation": "本文提出了一种实用连贯概念知识追踪（PICKT）模型，可以有效处理多种类型输入数据，通过构建考虑到问题和概念文本信息的概念知识图谱来解决冷启动问题。实验证明该模型在实用性与性能方面均表现出色，特别是在新学生入学和新问题添加这两种核心冷启动挑战中实现了显著的性能提升。", "conclusion": "本文的贡献主要体现在三个方面：首先，提出了一种有效利用多种数据格式的模型架构；其次，模型在解决新学生入学和新问题添加这两种核心冷启动挑战方面表现出显著的性能改善；最后，通过精细的设计验证了该模型的稳定性和实用性，增强了其在现实产品环境中的应用价值，为下一代ITS的实用实施奠定了重要的理论和技术基础。"}
{"llm_update_time": "20251210", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2512.07375", "html_url": "https://arxiv.org/abs/2512.07375", "title": "LUNE：通过带有负例的LoRA微调实现高效的大语言模型卸载", "title_en": "LUNE: Efficient LLM Unlearning via LoRA Fine-Tuning with Negative Examples", "authors": "Yezi Liu,Hanning Chen,Wenjun Huang,Yang Ni,Mohsen Imani", "background": "大语言模型（LLMs）虽然拥有从大规模训练语料库中获得的丰富知识，但在需要删除特定信息时，往往无法做到这一点。这使得处理隐私问题、偏见修正和知识更正变得困难。传统的模型卸载方法需要进行复杂的再训练或直接权重编辑，这些方法在实际部署中不切实际。", "innovation": "提出了基于LoRA的带有负例的卸载框架（LUNE）。该框架仅更新低秩适配器而不冻结主干，通过局部化编辑来避免全局变化，从而以比完全再训练或直接权重编辑低一个数量级的计算和内存开销，来抑制或替换请求的知识。", "conclusion": "大量实验表明，LUNE：(I) 在效率上接近完全再训练和内存编辑方法；(II) 将计算成本降低了大约一个数量级。"}
{"llm_update_time": "20251210", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2404.04671", "html_url": "https://arxiv.org/abs/2404.04671", "title": "PhyloLM：推断大型语言模型的谱系及其在基准测试中的性能预测", "title_en": "PhyloLM : Inferring the Phylogeny of Large Language Models and Predicting their Performances in Benchmarks", "authors": "Nicolas Yax,Pierre-Yves Oudeyer,Stefano Palminteri", "background": "本文介绍了PhyloLM，这是一种将谱系算法应用于大型语言模型（LLMs）的方法，用于探索LLMs之间的关系及其预测性能特征。该方法基于LLMs输出相似性计算一种谱系距离度量，进而构建能较好捕捉111个开源和45个闭源模型已知关系的系统发育树。此外，此谱系距离还预测了标准基准测试中的性能，证明了其功能有效性，并为基于时间和成本有效地估计LLMs能力铺平了道路。", "innovation": "本文提出了PhyloLM方法，将人口遗传学概念应用于机器学习领域，首次将谱系算法引入到LLMs中，通过构建基于输出相似性的谱系距离度量来解释和预测LLMs之间的关系及其性能，提出了一个无需透明训练信息即可评估LLMs发展、关系和能力的新工具。", "conclusion": "通过使用PhyloLM，成功地构建了大语言模型间的系统发育树，验证了其预测性能的能力，为更高效地评估LLMs提供了工具，同时也证明了其功能有效性。"}
{"llm_update_time": "20251210", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2512.07374", "html_url": "https://arxiv.org/abs/2512.07374", "title": "Recover-to-Forget: Gradient Reconstruction from LoRA for Efficient LLM Unlearning", "title_en": "Recover-to-Forget: Gradient Reconstruction from LoRA for Efficient LLM Unlearning", "authors": "Yezi Liu,Hanning Chen,Wenjun Huang,Yang Ni,Mohsen Imani", "background": "现有的卸载方法往往需要对整个模型进行微调或访问原始训练数据，这限制了它们的可扩展性和实用性。大型基础模型（如LLMs）的动态知识更新、数据删除权的执行以及纠正模型行为是重要的需求。", "innovation": "提出了名为Recover-to-Forget (R2F)的新型框架，该框架基于从LoRA适配器更新中重构全模型梯度方向来进行高效卸载。该方法通过计算LoRA参数的梯度并将梯度解码器训练为近似全模型梯度来实现，而不进行整个模型的反向传播。镀层在代理模型上训练并转移到目标模型，以确保更大的或黑盒模型的应用性。", "conclusion": "理论分析表明R2F方法能够实现有效的卸载，同时保持模型的泛化性能。实验结果表明，R2F提供了一种可扩展且轻量级的卸载替代方案，在预训练LLMs中不需要完整的重新训练或访问内部参数。"}
{"llm_update_time": "20251210", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2409.18991", "html_url": "https://arxiv.org/abs/2409.18991", "title": "探索多模态大语言模型景观：当前综述的元综述", "title_en": "Surveying the MLLM Landscape: A Meta-Review of Current Surveys", "authors": "Ming Li,Keyu Chen,Ziqian Bi,Ming Liu,Xinyuan Song,Zekun Jiang,Tianyang Wang,Benji Peng,Qian Niu,Junyu Liu,Jinlang Wang,Sen Zhang,Xuanhe Pan,Jiawei Xu,Pohsun Feng", "background": "多模态大型语言模型（MLLMs）的兴起已成为人工智能领域的变革性力量，使机器能够在文字、图像、音频和视频等多种模态之间处理和生成内容。这些模型在传统单一模态系统的基础上取得了重要进展，为包括自主代理人到医疗诊断在内的多种应用开辟了新的研究领域。通过整合多种模态，MLLMs能够更全面地理解信息，与人类感知过程更为接近。随着MLLMs能力的增强，进行全面和准确的性能评估变得越来越关键。", "innovation": "本文提供了一个关于MLLMs评估基准测试和方法的系统回顾，涵盖了基础概念、应用、评估方法、伦理问题、安全、效率和特定领域应用等关键主题。通过对现有文献的分类和分析，总结了各种综述的主要贡献和方法，并进行了详细比较分析，明确了其在学术界的影响。此外，还识别出MLLMs研究中的新兴趋势和未探索领域，提出了未来研究的方向。", "conclusion": "本文旨在为研究人员和从业者提供对当前MLLM评估状态的全面理解，从而促进这一快速发展的领域进一步的进展。"}
{"llm_update_time": "20251210", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2412.08519", "html_url": "https://arxiv.org/abs/2412.08519", "title": "在检索增强生成中弥合相关性和推理之间的差距：提取推理", "title_en": "Bridging Relevance and Reasoning: Rationale Distillation in Retrieval-Augmented Generation", "authors": "Pengyue Jia,Derong Xu,Xiaopeng Li,Zhaocheng Du,Xiangyang Li,Yichao Wang,Yuhao Wang,Qidong Liu,Maolin Wang,Huifeng Guo,Ruiming Tang,Xiangyu Zhao", "background": "检索增强生成（RAG）管道依赖于排序器和生成器两个关键组件，排序器按相关性对文档进行排序，生成器生成响应。然而，由于预训练数据和目标的不同，排序器识别的相关文档与生成器所需支持查询回答的文档之间存在不可避免的差距。", "innovation": "提出了名为RADIO的新颖且实用的偏好对齐框架，结合原理提取和推理对齐过程。首先，通过利用大型语言模型的推理能力来提取回答查询所需的原理。接着，基于提取的原理对文档进行重新排序，并微调排序器以对齐偏好。", "conclusion": "通过在两个任务上进行广泛的实验证明了该方法的有效性，并与基线方法进行了比较。还在线公开了代码以方便复现。"}
{"llm_update_time": "20251210", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2402.11192", "html_url": "https://arxiv.org/abs/2402.11192", "title": "如果使用像我这样的语言，我学习得更好：理解使用L大型语言模型生成的响应微调大型语言模型的优越性能", "title_en": "I Learn Better If You Speak My Language: Understanding the Superior Performance of Fine-Tuning Large Language Models with LLM-Generated Responses", "authors": "Xuan Ren,Biao Wu,Lingqiao Liu", "background": "本文探讨了一个有趣的观察结果：通过使用大型语言模型（LLM）生成的回应来微调大型语言模型，往往比使用人类生成的回应效果更好，特别是在需要推理任务的场景中。尽管普遍认为这种优势源于LLM生成内容的详细程度，但本文的研究发现另有促成因素：即LLM更加“熟悉”LLM生成的回应。这种熟悉性在微调前表现为较低的困惑度。", "innovation": "本文设计了一系列实验以理解“熟悉性”对学习表现的影响。研究揭示，这种“熟悉性”显著影响了学习性能。使用LLM生成的回应进行训练不仅增强性能，还能在针对特定任务的微调后保持模型在其他推理任务中的能力。", "conclusion": "通过使用LLM生成的回应来进行微调，可以提升模型的学习性能，并且即使是在特定任务微调后，这种回应也有助于模型在其他推理任务中保持其能力。"}
{"llm_update_time": "20251210", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2410.01268", "html_url": "https://arxiv.org/abs/2410.01268", "title": "深化学习与机器学习：通过工具、技术和应用揭示人工智能潜力", "title_en": "Deep Learning and Machine Learning, Advancing Big Data Analytics and Management: Unveiling AI's Potential Through Tools, Techniques, and Applications", "authors": "Pohsun Feng,Ziqian Bi,Yizhu Wen,Xuanhe Pan,Benji Peng,Ming Liu,Jiawei Xu,Keyu Chen,Junyu Liu,Caitlyn Heqi Yin,Sen Zhang,Jinlang Wang,Qian Niu,Ming Li,Tianyang Wang,Xinyuan Song,Zekun Jiang", "background": "人工智能（AI）、机器学习和深度学习已成为大数据分析和管理的变革性力量，促进跨行业取得了前所未有的突破。这些技术被应用于大规模语言模型（LLMs）的自然语言处理、多模态推理和自主决策等领域，增强了大数据分析和处理的能力。", "innovation": "文章着重介绍了高级算法如神经网络、强化学习和生成模型的应用，发展了AI系统处理、可视化和解释复杂数据集的能力。同时，边缘计算和自动化机器学习（AutoML）技术的出现使AI技术的访问更加公平，增强了不同技能水平用户使用智能系统的体验。文章还强调了AI技术部署中伦理考量、透明度和公平性的重要性。", "conclusion": "通过硬件配置、软件环境和实际应用的实用洞察，本文为研究人员和从业者提供了全面的资源。通过理论框架与可操作策略的结合，它突显了AI和大规模语言模型在大数据管理中的革命性和实际效用，推动了健康医疗、金融服务和自主系统等领域的重要进步。"}
{"llm_update_time": "20251210", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2512.07805", "html_url": "https://arxiv.org/abs/2512.07805", "title": "群表示位置编码", "title_en": "Group Representational Position Encoding", "authors": "Yifan Zhang,Zixiang Chen,Yifeng Liu,Zhen Qin,Huizhuo Yuan,Kangping Xu,Yang Yuan,Quanquan Gu,Andrew Chi-Chih Yao", "background": "该研究提出了GRAPE（Group RepresentAtional Position Encoding）框架，这是一个基于群动作的位置编码统一框架。该框架将两种机制结合在一起：(i) 多重旋转（Multiplicative GRAPE）在\text{SO}(d)中，(ii) 加性对数偏置（Additive GRAPE）在一般线性组\text{GL}中。研究人员探讨了这些机制如何统一到一起，以及它们在长上下文模型中如何改进原有的位置编码方法。", "innovation": " GRAPE框架通过结合多重旋转和加性对数偏置这两种机制，提供了一种新的位置编码方法。这种新方法严格扩展了原有的几何结构，能够捕捉跨子空间特征耦合，并保留了相对的法律和流式缓存能力。此外，GRAPE框架不仅包含以前的方法（如RoPE和ALiBi），还提供了一个严谨的设计空间，为长上下文模型中的位置几何提供了新的视角。", "conclusion": "总体而言，GRAPE为长上下文模型中的位置几何设计提供了一个原理设计空间，统一了RoPE和ALiBi作为特殊情况。这种方法不仅扩展了以往的位置编码方法，还提供了新的计算方法，能够在一定程度上保持有效性。"}
{"llm_update_time": "20251210", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2409.17120", "html_url": "https://arxiv.org/abs/2409.17120", "title": "深度学习与机器学习推动大数据分析与管理：便捷开胃菜", "title_en": "Deep Learning and Machine Learning, Advancing Big Data Analytics and Management: Handy Appetizer", "authors": "Benji Peng,Xuanhe Pan,Yizhu Wen,Ziqian Bi,Keyu Chen,Ming Li,Ming Liu,Qian Niu,Junyu Liu,Jinlang Wang,Sen Zhang,Jiawei Xu,Xinyuan Song,Zekun Jiang,Tianyang Wang,Pohsun Feng", "background": "本书探讨了人工智能（AI）、机器学习（ML）和深度学习（DL）在推动大数据分析和管理方面的作用。书中致力于简化深度学习背后的复杂数学概念，通过直观的可视化和实用案例研究，帮助读者更好地理解神经网络及其技术，如卷积神经网络（CNNs）的工作原理。书中介绍了多个经典模型和技术，如Transformer、GPT、ResNet、BERT和YOLO，并强调了这些技术在自然语言处理、图像识别和自动驾驶等领域的应用。此外，书中还概述了SQL和NoSQL数据库等关键大数据管理技术，以及Apache Hadoop和Spark等分布式计算框架，解释了它们在处理大量数据方面的重要性。", "innovation": "本书以直观的可视化和实用案例研究为主题，简化了复杂的技术概念，介绍了多个经典模型和技术（如Transformer、GPT、ResNet、BERT和YOLO），并强调了预训练模型在提高模型性能和准确性方面的价值。书中的这些内容为理解和应用这些模型提供了宝贵的指导。", "conclusion": "本书强调了掌握深度学习和大数据管理技能的重要性和价值，作为未来劳动力工具的关键组成部分，使得本指南成为新手和专业人士的重要资源。"}
{"llm_update_time": "20251210", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2512.07474", "html_url": "https://arxiv.org/abs/2512.07474", "title": "Living the Novel: 从小说生成自训练时间轴意识对话代理系统", "title_en": "Living the Novel: A System for Generating Self-Training Timeline-Aware Conversational Agents from Novels", "authors": "Yifei Huang,Tianyu Yan,Sitong Gong,Xiwei Gao,Caixin Kang,Ruicong Liu,Huchuan Lu,Bo Zheng", "background": "当前语言模型生成的对话代理存在人设漂移和超出故事逻辑范围的能力，导致叙述不一致和鲁棒性问题。为了克服这些问题，作者提出了一个包含两个阶段的培训管道，通过Deep Persona Alignment (DPA) 和 Coherence and Robustness Enhancing (CRE) 阶段来增强角色的特性和故事的连贯性。", "innovation": "提出了一种两阶段的训练管道：Deep Persona Alignment (DPA) 阶段通过数据驱动的强化微调来嵌入深层次的角色特异性；Coherence and Robustness Enhancing (CRE) 阶段利用故事时间感知的知识图谱和检索-生成训练策略来架构性地强化这些叙事约束。这种方法被应用于Jules Verne的《海底两万里》项目中，并通过实验室研究和实地研究验证了其效果。", "conclusion": "我们的DPA管道帮助我们的定制模型在人设具体指标上优于GPT-4o，而CRE阶段在连贯性和鲁棒性方面取得了近乎完美的成绩。研究结果揭示了AI驱动的叙事系统设计原则：基于角色的自我训练是提高可信度的基础，而明确的故事时间约束对于维持一致、抗中断的移动-网络体验至关重要。"}
{"llm_update_time": "20251210", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2411.06272", "html_url": "https://arxiv.org/abs/2411.06272", "title": "金顶石：评估金融大型语言模型的全面双语基准", "title_en": "Golden Touchstone: A Comprehensive Bilingual Benchmark for Evaluating Financial Large Language Models", "authors": "Xiaojun Wu,Junxi Liu,Huanyi Su,Zhouchi Lin,Yiyan Qi,Chengjin Xu,Jiajun Su,Jiajie Zhong,Fuwei Wang,Saizhuo Wang,Fengrui Hua,Jia Li,Jian Guo", "background": "随着大型语言模型（LLMs）在金融领域中的日益普及，需要制定一个标准化方法来全面评估其性能。当前的金融基准通常存在语言和任务覆盖范围有限、数据集质量低和对LLM评估适应性不强的问题。", "innovation": "我们提出了Golden Touchstone，这是一个全面的双语基准，涵盖中文和英文的八项核心金融NLP任务。该基准从广泛的开源数据收集和行业特定需求出发，全面评估模型的语言理解和生成能力。此外，还开源了Touchstone-GPT，这是一种通过持续预训练和指令调优训练的金融LLM，展示出在双语基准上的强大性能。", "conclusion": "这项研究提供了一种实用的金融LLM评估工具，并引导未来的开发和优化。Goldentouchstone的源代码和Touchstone-GPT的模型权重可以在以下链接找到：[这个 https URL]。"}
{"llm_update_time": "20251210", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2502.08943", "html_url": "https://arxiv.org/abs/2502.08943", "title": "超越单一视角：揭示多次生成在基准评估中的价值", "title_en": "Beyond the Singular: Revealing the Value of Multiple Generations in Benchmark Evaluation", "authors": "Wenbo Zhang,Hengrui Cai,Wenyu Chen", "background": "大型语言模型（LLMs）在实际应用中展现了显著的实用性，特别是在自然语言处理和理解方面。基准评估对于检验LLMs的能力至关重要，因为它们能够全面评估LLMs的优势与不足。然而，当前的评估方法往往忽视了LLMs固有的随机性，通常使用确定性的生成策略或依赖单一随机样本，导致未考虑抽样方差，从而产生不可靠的基准评分估计。", "innovation": "本文提出了一种层次统计模型，该模型通过结合基准特性与LLMs的随机性，提供了更为全面的基准评估过程的表示。利用多次生成能够提高基准评分估计的准确性并减少方差。此外，该方法还定义了基于正确率的提示级别难度得分$\text{P}\text{(correct)}$，提供了对个别提示的精细洞察。本文还创建了一个数据地图，可视化提示的难度和语义，有助于基准构建中的错误检测和质量控制。", "conclusion": "研究证明，利用多次生成能够提升基准评分估计的准确度，减少方差，并提供关于提示级别难度的深度洞察。同时，本文方法通过数据地图帮助识别和控制基准构建中的问题，为改进未来的工作提供了方向。"}
{"llm_update_time": "20251210", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2504.20964", "html_url": "https://arxiv.org/abs/2504.20964", "title": "OSVBench: 在操作系统验证的规范生成任务中评估LLMs的基准", "title_en": "OSVBench: Benchmarking LLMs on Specification Generation Tasks for Operating System Verification", "authors": "Shangyu Li,Juyong Jiang,Tiancheng Zhao,Jiasi Shen", "background": "当前，大型语言模型（LLM）在执行多种任务方面表现出强大的语言处理能力，但在具体规范生成任务中尤其是在操作系统核功能正确性验证的复杂任务上表现有限。为了填补这一空白，本文提出了OSVBench，这是一个专门用于评估LLM在生成完整形式规范以验证操作系统内核功能正确性方面的基准测试。", "innovation": "OSVBench 是基于现实中的操作系统内核 Hyperkernel，包括245个复杂的规范生成任务，每个任务涉及20k至30k个令牌，是一个长上下文任务。规范生成问题被定义为一个受限于特定领域编程模型的程序合成问题。这表明LLM需要理解和适应验证假设，才能准确地搜索并生成语法和语义形式规范。研究结果表明，现有的LLMs在生成操作系统的规范时表现有限，尤其是在长上下文代码生成任务中表现出显著差异。", "conclusion": "实验结果显示了现有的12种最先进的LLM们在操作系统的验证规范生成任务上的有限性能，且它们在处理长上下文代码生成任务上的表现存在显著差异。这表明OSVBench对于评估和改进LLM在操作系统及其关键组件验证中的能力至关重要。"}
{"llm_update_time": "20251210", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2411.06096", "html_url": "https://arxiv.org/abs/2411.06096", "title": "使用语言最小对的中文语言模型系统评估", "title_en": "A Systematic Assessment of Language Models with Linguistic Minimal Pairs in Chinese", "authors": "Yikang Liu,Yeting Shen,Hongao Zhu,Lilong Xu,Zhiheng Qian,Siyuan Song,Kejia Zhang,Jialong Tang,Pei Zhang,Baosong Yang,Rui Wang,Hai Hu", "background": "本文介绍了ZhoBLiMP，这是目前最大的中文语言最小对基准，包含超过100种范式，涵盖从语题化到‘Ba’构造。本文构建了一系列不同分词器、参数大小和标记体积的中文语言模型，研究语言模型在这方面的学习曲线。", "innovation": "提出了一种新的度量标准，即亚线性长度归一化的对数概率（SLLN-LP），用以消除语言最小对中句子不等长引入的偏差。结果显示，即使是含有320亿参数的语言模型，对于中文的人称代词、量化词和省略在SLLN-LP度量下仍然很难处理。此外，SLLN-LP成功地缓解了ZhoBLiMP、JBLiMP和BLiMP中的偏差。", "conclusion": "未来的研究应该更加细致地设计评估，考虑链接函数、语言模型与目标语言最小对之间的复杂关系。"}
{"llm_update_time": "20251210", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2410.20833", "html_url": "https://arxiv.org/abs/2410.20833", "title": "大型语言模型是对检索增强生成过程偏向的评估者，而不是自偏好的", "title_en": "LLMs are Biased Evaluators But Not Biased for Retrieval Augmented Generation", "authors": "Yen-Shan Chen,Jing Jin,Peng-Ting Kuo,Chao-Wei Huang,Yun-Nung Chen", "background": "最近的研究表明，大型语言模型（LLMs）在评估任务中表现出显著的偏见，尤其是在对自动生成的内容进行偏好评分上。然而，这些偏见在事实导向的任务，尤其是检索增强生成（RAG）框架中是否显现还不清楚。本研究通过模拟RAG框架的两个关键阶段，即点wise重排阶段和生成阶段，来探索LLMs在RAG框架下的行为特性。", "innovation": "本研究的主要创新在于通过模拟RAG框架的两个关键阶段来探索LLMs在事实导向任务中的行为。研究发现，LLMs在RAG框架下的表现中未显示出明显的自偏好效应，而是显示出在事实准确性方面对模型输出有显著影响。这一发现通过三个常见问答数据集（NQ、MARCO、TriviaQA数据集）以及五种广泛使用的语言模型（GPT-3.5、GPT-4o-mini、Gemini、LLaMA3、Mistral）得到验证。", "conclusion": "本研究补充了关于LLMs偏见的讨论，特别是对于基于RAG系统的偏见影响，提供了一些有益的见解，有助于指导更稳健和无偏的LLMs系统的开发。"}
{"llm_update_time": "20251210", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2503.04598", "html_url": "https://arxiv.org/abs/2503.04598", "title": "HybridNorm: 通过混合规范化提高变换器训练的稳定性和效率", "title_en": "HybridNorm: Towards Stable and Efficient Transformer Training via Hybrid Normalization", "authors": "Zhijian Zhuo,Yutao Zeng,Ya Wang,Sijun Zhang,Jian Yang,Xiaoqing Li,Xun Zhou,Jinwen Ma", "background": "变换器已成为广泛机器学习任务的默认架构，尤其是在大型语言模型中。尽管变换器在性能上表现出色，但在训练深层变换器网络时仍存在许多挑战，尤其是在位置归一化层的设置上。前归一化结构虽然有利于更稳定的训练，但由于更强的标识路径而常导致性能不佳，相比之下，后归一化则表现出更优的效果。", "innovation": "本文提出了一种简单而有效的方法HybridNorm，这是一种结合了前归一化和后归一化优点的混合归一化策略。具体而言，HybridNorm在注意力机制中采用QKV归一化，并在每个变换器块的前向传播网络中使用后归一化。文中通过理论分析和实验结果展示了HybridNorm能够改善梯度流动和模型稳健性，经过大规模实验证明，HybridNorm在多个基准测试中均优于前归一化和后归一化方法。", "conclusion": "HybridNorm作为一种更稳定、更有效的技术，能够有效改善深层变换器模型的训练和性能。本文提供了代码可供参考。"}
{"llm_update_time": "20251210", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2506.12758", "html_url": "https://arxiv.org/abs/2506.12758", "title": "民主还是集权？探索大型语言模型新的政治偏见维度", "title_en": "Democratic or Authoritarian? Probing a New Dimension of Political Biases in Large Language Models", "authors": "David Guzman Piedrahita,Irene Strauss,Bernhard Schölkopf,Rada Mihalcea,Zhijing Jin", "background": "随着大型语言模型（LLMs）越来越多地融入日常生活中和信息生态系统中，人们对它们隐性偏见的担忧一直存在。尽管以往的研究主要关注了社会和人口统计学以及左右政治维度，但很少有人关注LLMs与更大的地缘政治价值体系的契合度，尤其是民主与集权的谱系。本研究旨在填补这一空白。", "innovation": "提出了一种新的方法来评估LLMs的契合度，将F-scale（一种衡量专制倾向的心理测量工具）、FavScore（一种新的评估模型对世界领导人的偏爱程度的指标）和角色模型探针结合起来，以评估LLMs中被引用作为通用榜样的人物。研究发现，LLMs通常青睐民主价值观和领导人，但在受到中文提示时，对专制人物的偏爱度有所增加。此外，模型经常在非明确政治背景下引用专制人物作为榜样。这些结果揭示了LLMs可能反映并放大全球政治意识形态的方式，突出了超越常规社会和政治维度评估偏见的重要性。", "conclusion": "LLMs通常偏向民主价值观和领导者，但在受到中文提示时，对专制人物的偏爱度增加。模型经常在非明确政治背景下引用专制人物作为榜样。这一研究强调了超越传统社会和政治维度评估偏见的重要性，以便更好地理解LLMs的政治立场和潜在的偏见。研究提供了代码供参考。"}
{"llm_update_time": "20251210", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2512.07698", "html_url": "https://arxiv.org/abs/2512.07698", "title": "sim2art：仅使用合成训练数据从单一视频准确建模 articulated 对象", "title_en": "sim2art: Accurate Articulated Object Modeling from a Single Video using Synthetic Training Data Only", "authors": "Arslan Artykov,Corentin Sautier,Vincent Lepetit", "background": "理解articulated对象是机器人技术和数字孪生创建中的一个基本挑战。为了有效地建模这样的对象，需要同时恢复零件分割和基础关节参数。尽管这项任务非常重要，之前的许多工作主要集中在多视角系统、物体扫描或静态摄像头等设置上。", "innovation": "本文提出了第一个基于数据驱动的方法，能够从带有自由移动摄像头捕捉的单目视频中联合预测零件分割和关节参数。该方法仅依赖合成数据进行训练，展示了强大的现实世界对象泛化能力，为articulated对象理解提供了可扩展且实用的解决方案。该方法可以直接处理随意录制的视频，使其适用于动态环境下的实时应用。", "conclusion": "通过仅使用合成训练数据训练的方法，sim2art在没有任何实际视频监督的情况下能够准确建模articulated对象，尤其适用于实时应用中随意录制的视频，展示了强大的泛化能力。"}
{"llm_update_time": "20251210", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2512.07702", "html_url": "https://arxiv.org/abs/2512.07702", "title": "指导不要生成：文本图像对齐的自动负提示生成", "title_en": "Guiding What Not to Generate: Automated Negative Prompting for Text-Image Alignment", "authors": "Sangha Park,Eunji Kim,Yeongtak Oh,Jooyoung Choi,Sungroh Yoon", "background": "尽管在文本到图像生成方面取得了显著进展，但实现文本与图像的精确对齐仍然面临挑战，尤其对于具有丰富组成结构或想象元素的提示。分析表明，既有直接与提示对齐错误相关的负提示，又有与提示无关但在生成图像中出现的负提示，都可以提高图像对齐精度。", "innovation": "提出了Negative Prompting for Image Correction (NPC)，这是一种自动管道，通过识别并应用能够抑制不需要内容的负提示，从而改善对齐。NPC 使用验证器-描述者-提案者框架生成候选负提示，并使用显著文本空间评分进行排名，无需额外进行图像合成即可有效选择。", "conclusion": "NPC在GenEval++和Imagine-Bench上均优于强基线，分别在GenEval++上达到0.571和Imagine-Bench上达到最佳总体性能，通过指导避免生成什么，NPC提供了一条更有力的文本图像对齐途径。代码可在该链接下载：this https URL."}
{"llm_update_time": "20251210", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2512.07733", "html_url": "https://arxiv.org/abs/2512.07733", "title": "SpatialDreamer：通过主动的视觉想象激励空间推理", "title_en": "SpatialDreamer: Incentivizing Spatial Reasoning via Active Mental Imagery", "authors": "Meng Cao,Xingyu Li,Xue Liu,Ian Reid,Xiaodan Liang", "background": "尽管多模态大型语言模型（MLLMs）在场景理解方面取得了进展，但它们在需要心理模拟的复杂空间推理任务上的表现仍然受到很大限制。当前方法往往依赖于对空间数据的被动观察，无法实现内化的主动心理图像过程。", "innovation": "提出了一种基于强化学习框架的SpatialDreamer，该框架通过闭环过程（主动探索、通过世界模型进行视觉想象以及基于证据的推理）实现空间推理。为了解决长时段推理任务中微调监督不足的问题，提出了几何策略优化（GeoPO），该方法引入了树形结构采样和几何一致性约束下的逐帧奖励估计。", "conclusion": "广泛的实验表明，SpatialDreamer在多个具有挑战性的基准测试中表现出了竞争力，意味着对MLLMs在人类类似主动空间心理模拟方面的关键进展。"}
{"llm_update_time": "20251210", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2512.07703", "html_url": "https://arxiv.org/abs/2512.07703", "title": "PVeRA：基于概率向量的随机矩阵适应", "title_en": "PVeRA: Probabilistic Vector-Based Random Matrix Adaptation", "authors": "Leo Fillioux,Enzo Ferrante,Paul-Henry Cournède,Maria Vakalopoulou,Stergios Christodoulidis", "background": "近年来，大型基础模型得以发展，并且在各种任务上推动了性能边界。训练或微调这些模型需要大量的数据集和计算资源，这些资源往往是稀缺和昂贵的。适应方法提供了一种计算有效的方法来解决这些问题，可以通过使用少量数据和计算资源对模型进行微调。这种适应方法通过向冻结的主干部分附加新的可训练模块，并仅对这些模块进行微调来实现。最近，VeRA适配器在参数高效适应方面被证明表现优异，它使用了在整个层中共享的成对冻结的低秩随机矩阵。在此论文中，作者提出了PVeRA，这是一种概率性的VeRA适配器版本，通过概率方式修改VeRA的低秩矩阵。", "innovation": "PVeRA通过在低秩矩阵的修改中引入概率性方式，自然地处理输入中的固有模糊性，并在训练和测试阶段采用不同的采样配置。通过VTAB-1k基准以及与VeRA和其他适配器的全面评估，PVeRA表现出色。", "conclusion": "PVeRA在VTAB-1k基准上的评估中表现出优越性，并且优于其他适配器。本文提供了使用PVeRA训练模型的代码和所有适配器的基准测试代码。"}
{"llm_update_time": "20251210", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2512.07720", "html_url": "https://arxiv.org/abs/2512.07720", "title": "ViSA: 3D-Aware Video Shading for Real-Time Upper-Body Avatar Creation", "title_en": "ViSA: 3D-Aware Video Shading for Real-Time Upper-Body Avatar Creation", "authors": "Fan Yang,Heyuan Li,Peihao Li,Weihao Yuan,Lingteng Qiu,Chaoyue Song,Cheng Chen,Yisheng He,Shifeng Zhang,Xiaoguang Han,Steven Hoi,Guosheng Lin", "background": "生成高保真度的上半身三维虚拟角色从一张照片入手仍然是一个重大的挑战。现有的三维虚拟角色生成方法依赖于大规模的重建模型，能够快速提供稳定的体型结构，但常常存在图像模糊和动作僵硬等瑕疵。与之相比，生成视频模型能够合成逼真且动态的结果，但往往会遇到不稳定的行为问题，包括体型结构错误和身份漂移。", "innovation": "本文提出了一种结合两者优点的新方法。该框架利用三维重建模型提供结构和外观先验信息，从而引导实时自回归视频扩散模型进行渲染。这种方法允许模型在实时生成高分辨率、逼真的细节和流动的动态的同时，减少纹理模糊和动作僵硬的问题，避免视频生成方法中常见的结构不一致问题。通过结合三维重建的几何稳定性和视频模型的生成能力，该方法能够生成具有真实外观和动态、时间上连贯运动的高保真数字虚拟角色。", "conclusion": "我们的方法在减少伪像和实现领先方法显著提高的视觉效果方面表现出色，为游戏和虚拟现实等实时应用提供了稳健且高效的解决方案。实验结果验证了该方法的有效性。"}
{"llm_update_time": "20251210", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2512.07729", "html_url": "https://arxiv.org/abs/2512.07729", "title": "用基于大脑的深度网络改进动作分类", "title_en": "Improving action classification with brain-inspired deep networks", "authors": "Aidas Aglinskas,Stefano Anzellotti", "background": "行动计划识别对于诸如机器人技术和健康监控等应用至关重要。动作信息可以从身体的姿态和运动中提取，也可以从背景场景中提取。然而，深度神经网络（DNNs）如何利用关于身体的信息和背景信息的程度尚不明确。因为这两个信息来源在训练数据集中可能会相互关联，DNNs可能依赖其中一个而忽视另一个。人类具有专门针对身体和场景感知的脑区，因此人类可以更有效地从身体和背景中提取信息。现有工作测试了构建具有身体和场景感知专门流路的脑启发式深度网络架构是否能提升人类级别的性能。", "innovation": "这项工作提出了一个新的架构，模仿大脑的领域特异性，分别处理身体和背景信息。实验结果显示，该架构在动作识别性能上有所提升，并且其准确性模式与人类参与者的表现模式更加一致。", "conclusion": "与仅使用身体或仅使用背景的刺激相比，DNNs在同时展示身体和背景的刺激中表现得更准确。同时，人类能够在所有三种版本的刺激中准确识别相同的一组动作，且在仅显示身体的刺激中表现得更好。基于领域特异性的新型深度网络架构改进了动作识别性能，并且其在不同版本刺激上的准确性与人类参与者表现出的准确性模式更为相似。"}
{"llm_update_time": "20251210", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2512.07747", "html_url": "https://arxiv.org/abs/2512.07747", "title": "Unison: 一种全面自动、任务通用且低成本的统一理解和生成框架", "title_en": "Unison: A Fully Automatic, Task-Universal, and Low-Cost Framework for Unified Understanding and Generation", "authors": "Shihao Zhao,Yitong Chen,Zeyinzi Jiang,Bojia Zi,Shaozhe Hao,Yu Liu,Chaojie Mao,Kwan-Yee K. Wong", "background": "统一理解和生成是多模态学习领域中非常有吸引力的研究方向。目前存在两种方法：一种通过自回归范式训练变压器，另一种采用两阶段方案连接预训练的理解和生成模型进行对齐微调。前者需要大量数据和计算资源，普通研究人员无法负担。后者虽然训练成本较低，但现有工作常常任务覆盖范围有限或生成质量不好。当前方法缺乏解析输入元信息（如任务类型、图像分辨率、视频长度等）的能力，并且需要手动配置参数，这既繁琐又非智能。", "innovation": "本文提出了一种名为Unison的方法，它采用两阶段方案，同时保留预训练模型的强大能力。在极低的训练成本下，该模型覆盖了多种多模态理解任务（包括文本、图像和视频理解）及多样性的生成任务（如文本到视觉内容生成、编辑、可控生成和基于IP的引用生成）。Unison还配备了自动解析用户意图、确定目标任务类型，并准确提取对应任务所需元信息的能力。这使得各种多模态任务可以完全自动化，无需人工干预。实验表明，在仅使用50万训练样本和50个GPU小时的低成本设定下，模型可以准确自动识别任务并提取相关参数，实现多个理解和生成任务的优秀性能。", "conclusion": "该研究提出Unison框架，不仅在成本上大幅降低，还能全面自动处理多种多模态任务，具有很高的应用价值。"}
{"llm_update_time": "20251210", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2512.07712", "html_url": "https://arxiv.org/abs/2512.07712", "title": "UnCageNet: 不羁网络：禁锢动物的跟踪和姿态估计", "title_en": "UnCageNet: Tracking and Pose Estimation of Caged Animal", "authors": "Sayak Dutta,Harish Katti,Shashikant Verma,Shanmuganathan Raman", "background": "动物跟踪和姿态估计系统，如STEP（同时跟踪和姿态估计）和ViTPose，在处理包含笼子结构和系统遮挡的图像和视频时会经历显著的性能下降。现有的方法无法有效处理这些情况，这严重影响了其表现。", "innovation": "本文提出了一种三阶段预处理管道，通过：（1）使用增强的Gabor ResNet-UNet架构（带有可调定向滤波器）进行笼子分割；（2）使用CRFill进行基于内容的遮挡区域重建以实现临场感；（3）在去除了笼子遮挡的帧上评估姿态估计和跟踪。该Gabor增强分割模型利用了72个定向核的视角感知特征，以准确识别并分割严重影响现有方法性能的笼子结构。", "conclusion": "实验验证表明，通过本管道移除笼子遮挡，能够在去除遮挡的图像上实现与无遮挡环境相当的跟踪和姿态估计性能。此外，我们还观察到关键点检测准确率和轨迹一致性的显著提高。"}
{"llm_update_time": "20251210", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2512.07756", "html_url": "https://arxiv.org/abs/2512.07756", "title": "UltrasODM: 一种用于3D自由手超声重建的双流光学流动Mamba网络", "title_en": "UltrasODM: A Dual Stream Optical Flow Mamba Network for 3D Freehand Ultrasound Reconstruction", "authors": "Mayank Anand,Ujair Alam,Surya Prakash,Priya Shukla,Gora Chand Nandi,Domenec Puig", "background": "临床超声成像高度依赖操作员，快速探头动作和亮度波动常导致重建错误，降低医生对成像结果的信任度和临床实用性。", "innovation": "提出了UltrasODM，这是一种双流框架，通过校准的每帧不确定性、基于显著性的诊断和可操作的提示来辅助采集。UltrasODM整合了对比排名模块、光学流流与Dual-Mamba时间模块融合以实现鲁棒的6自由度姿态估计，以及结合贝叶斯不确定性、临床校准阈值及低置信度区域高亮的Human-in-the-Loop层。当不确定性超过阈值时，系统会发出不显眼的警报，建议采取纠正措施，如重新扫描高亮区域或减慢扫描速度。", "conclusion": "在临床自手超声数据集上评估，与UltrasOM相比，UltrasODM降低了15.2%的漂移、12.1%的距离误差和10.1%的Hausdorff距离，同时生成每帧不确定性输出和显著性输出。通过强调透明度和临床反馈，UltrasODM提高了重建可靠性，支持了更安全和可信的临床工作流程。"}
{"llm_update_time": "20251210", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2512.07760", "html_url": "https://arxiv.org/abs/2512.07760", "title": "模态意识偏差缓解与不变性学习在无监督可见红外行人重识别中的应用", "title_en": "Modality-Aware Bias Mitigation and Invariance Learning for Unsupervised Visible-Infrared Person Re-Identification", "authors": "Menglin Wang,Xiaojin Gong,Jiachen Li,Genlin Ji", "background": "USVI-ReID旨在无需依赖任何注释的情况下，将可见光和红外摄像头中的个体进行匹配。由于可见光和红外模态之间存在明显差异，因此如何可靠地估计跨模态关联成了USVI-ReID的主要挑战。现有的方法通常采用最优传输来关联内部模态聚类，这种方式容易传播局部聚类错误，且忽略了全局实例级别的关系。", "innovation": "本文通过挖掘和关注可见光-红外模态偏差，从两个方面对跨模态学习进行改进：缓解偏差的全局关联和模态不变性表示学习。首先，我们受单模态重识别中摄像机感知距离校正的启发，提出模态感知的Jaccard距离，以缓解由于模态差异导致的距离偏差，通过全局聚类可以估计出更可靠的跨模态关联。其次，设计了一种'分割-对比'策略，获得模态特异性的全局原型，通过在全局关联的指导下明确对齐这些原型，可以实现模态不变但具有ID辨别性的表示学习。尽管概念上很简单，但我们的方法在基准VI-ReID数据集上达到了最先进的性能，并显著优于现有方法，证明了其有效性。", "conclusion": "本文提出的方法在基线VI-ReID数据集上取得了最先进的性能，并显著优于现有方法，验证了其有效性。"}
{"llm_update_time": "20251210", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2512.07776", "html_url": "https://arxiv.org/abs/2512.07776", "title": "GorillaWatch: 一种用于野外大猩猩再识别和种群监测的自动化系统", "title_en": "GorillaWatch: An Automated System for In-the-Wild Gorilla Re-Identification and Population Monitoring", "authors": "Maximilian Schall,Felix Leonard Knöfel,Noah Elias König,Jan Jonas Kubeler,Maximilian von Klinski,Joan Wilhelm Linnemann,Xiaoshi Liu,Iven Jelle Schlegelmilch,Ole Woyciniuk,Alexandra Schild,Dante Wasmuht,Magdalena Bermejo Espinet,German Illera Basas,Gerard de Melo", "background": "目前，监测极度濒危的西部低地大猩猩非常依赖大量的手动努力来重新识别来自相机陷阱视频档案的个体。自动化此过程的主要障碍是缺乏大规模的野外视频数据集，用于训练稳健的深度学习模型。", "innovation": "本文介绍了一个全面的基准，包含三个新的数据集：最大的野生灵长类再识别视频数据集 Gorilla-SPAC-Wild；用于评估跨域再识别泛化的 Gorilla-Berlin-Zoo；以及用于评估相机陷阱视频中存在的多目标跟踪的 Gorilla-SPAC-MoT。基于这些数据集，我们提出了 GorillaWatch，一个集成了检测、跟踪和再识别的端到端流水线。为了利用时间信息，我们引入了一种多帧自监督预训练策略，该策略利用跟踪片段的一致性来学习领域特定的特征而不需手动标签。为了确保科学有效，我们提出了一个可微的 AttnLRP，以验证模型依赖于判别性生物特征指标而不是背景相关性。详尽的基准测试表明，从大面积图像主干网络聚合特征优于专门的视频架构。此外，通过结合空间时间约束到标准聚类中来解决无监督的人口统计问题，以减轻过度分割。", "conclusion": "最后，我们已将所有代码和数据集公开发布，以促进濒危物种的可扩展和非侵入性监测。"}
{"llm_update_time": "20251210", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2512.07738", "html_url": "https://arxiv.org/abs/2512.07738", "title": "HLTCOE评估团队参加TREC 2025 VQA赛道", "title_en": "HLTCOE Evaluation Team at TREC 2025: VQA Track", "authors": "Dengjia Zhang,Charles Weng,Katherine Guerrerio,Yi Lu,Kenton Murray,Alexander Martin,Reno Kriz,Benjamin Van Durme", "background": "HLTCOE评估团队参加了TREC VQA的Answer Generation任务，该任务旨在提高答案生成的语义准确性和排名一致性。", "innovation": "团队开发了一种列表学习框架，该框架使用一种新颖的Masked Pointer Cross-Entropy Loss with Rank Weights训练模型，以重新排序由基础多模态模型生成的多个候选答案。该方法将生成建模与判别排名结合，实现了连贯且细粒度的答案列表生成，实验结果表明在准确性和排名稳定性方面获得了持续的增益，特别是在需要时间推理和语义消歧的问答场景。", "conclusion": "通过这种稳定且可解释的列表优化，我们的方法有效提高了答案生成的质量，特别是在需要时间推理和语义消歧的复杂问答场景中表现出色。"}
{"llm_update_time": "20251210", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2512.07821", "html_url": "https://arxiv.org/abs/2512.07821", "title": "WorldReel：具有一致几何和运动建模的4D视频生成", "title_en": "WorldReel: 4D Video Generation with Consistent Geometry and Motion Modeling", "authors": "Shaoheng Fang,Hanwen Jiang,Yunpeng Bai,Niloy J. Mitra,Qixing Huang", "background": "最近的视频生成器在实现非常逼真的视觉效果方面取得了显著成就，但它们在3D一致性方面仍然存在根本性的问题。然而，WorldReel则是一个全新的4D视频生成器，它能够天然地保持空间—时间一致性。", "innovation": "WorldReel通过联合生产RGB帧和4D场景表示（包括点图、相机轨迹和密集流映射），实现了时间上的几何和外观建模的一贯性。WorldReel 使用了刻意组合的合成与真实数据进行训练，这使得它能在保持强烈几何保真的同时还能泛化到野外素材。", "conclusion": "广泛的实验证明了WorldReel在动态场景和移动相机的一致视频生成方面的优越性，其几何一致性、运动连贯性的指标超过了其他竞争方法，并减少了视角—时间的伪影。我们认为，WorldReel使视频生成更加接近4D一致的世界建模，为在单一且稳定的空间—时间表示中构建、交互和理解场景提供了可能性。"}
{"llm_update_time": "20251210", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2512.07807", "html_url": "https://arxiv.org/abs/2512.07807", "title": "Lang3D-XL：大规模场景中的嵌入语言3D高斯", "title_en": "Lang3D-XL: Language Embedded 3D Gaussians for Large-scale Scenes", "authors": "Shai Krakovsky,Gal Fiebelman,Sagie Benaim,Hadar Averbuch-Elor", "background": "通过在3D表示中嵌入语言领域，可以使对空间环境的理解更加丰富，因为它能够将几何形状与描述性意义链接起来，从而实现更直观的人机交互。这使得使用自然语言查询或编辑场景成为可能，并且可能改善场景检索、导航和多模态推理等任务。然而，现有的特征精简方法由于在语义特征对齐和内存及运行时效率方面存在挑战，在处理大规模互联网数据时无法有效工作。", "innovation": "提出了一种新的方法来解决这些问题。首先，引入了极低维度的语义瓶颈特征，并将其作为3D Gaussian表示的基础之一。这些特征通过渲染和多分辨率、基于特征的哈希编码器处理，大大提高了运行时间和显卡内存的效率。其次，引入了衰减降采样模块，并提出了几个针对地面真实2D特征语义对齐的正则化方法。", "conclusion": "在野生场景数据集HolyScenes上评估了该方法，结果显示它在性能和效率方面都超过了现有方法。"}
{"llm_update_time": "20251210", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2512.07745", "html_url": "https://arxiv.org/abs/2512.07745", "title": "DiffusionDriveV2: Reinforcement Learning-Constrained Truncated Diffusion Modeling in End-to-End Autonomous Driving", "title_en": "DiffusionDriveV2: Reinforcement Learning-Constrained Truncated Diffusion Modeling in End-to-End Autonomous Driving", "authors": "Jialv Zou,Shaoyu Chen,Bencheng Liao,Zhiyu Zheng,Yuehao Song,Lefei Zhang,Qian Zhang,Wenyu Liu,Xinggang Wang", "background": "生成性扩散模型在端到端的自动驾驶中常常面临模式崩溃的问题，倾向于生成保守且同质的行为。尽管DiffusionDrive利用预定义锚点代表不同的驾驶意图来分割动作空间并生成多样化的轨迹，但其依赖于模仿学习的机制存在不足，这会导致多样性和一致性高质量之间的矛盾。", "innovation": "DiffusionDriveV2引入了强化学习来约束低质量的模式并探索优秀轨迹，同时保持Gaussian Mixture Model的核心多模态特性。通过使用适应性尺度乘法噪声，促进广泛探索；采用基于单个锚点生成样本的内部锚点GRPO和跨越不同锚点的全局视角的调优GRPO来避免不同意图之间的不适当优劣比较。该模型在闭合环评估中取得了91.2 PDMS和85.5 EPDMS的优异成绩，且进一步实验验证了其解决了截断扩散模型中多样性和一致质量之间的矛盾，实现了最佳折衷。", "conclusion": "DiffusionDriveV2通过强化学习约束机制显著提升了最终输出质量，同时保持了其核心的多模态特性。实验结果表明，我们的方法在截断扩散模型中成功解决了多样性和一致质量之间的矛盾，取得了最佳的权衡。"}
{"llm_update_time": "20251210", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2512.07831", "html_url": "https://arxiv.org/abs/2512.07831", "title": "UnityVideo: 统一多模态多任务学习以增强世界感知视频生成", "title_en": "UnityVideo: Unified Multi-Modal Multi-Task Learning for Enhancing World-Aware Video Generation", "authors": "Jiehui Huang,Yuechen Zhang,Xu He,Yuan Gao,Zhi Cen,Bin Xia,Yan Zhou,Xin Tao,Pengfei Wan,Jiaya Jia", "background": "近期的视频生成模型展现了出色的合成能力，但依然受限于单一模态的条件约束，影响了其对整个世界的整体理解能力。这主要源于跨模态交互不足和模态多样性有限，无法全面表示世界知识。", "innovation": "本文提出了UnityVideo，这是一种联合多个模态（分割掩码、人体骨架、密集姿态、光流和深度图）学习的统一框架，能够共同学习多种训练模式。该方法包括两个核心组件：动态噪声化统一异构训练模式，以及模态切换器和上下文学习者，通过模块化参数和上下文学习实现统一处理。", "conclusion": "通过联合优化，UnityVideo 加快了收敛速度并显著提高了零样本泛化能力。实验表明，UnityVideo 在视频质量、一致性和与物理世界约束的对齐方面均取得显著提升。"}
{"llm_update_time": "20251210", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2512.07730", "html_url": "https://arxiv.org/abs/2512.07730", "title": "SAVE: Sparse Autoencoder-Driven Visual Information Enhancement for Mitigating Object Hallucination", "title_en": "SAVE: Sparse Autoencoder-Driven Visual Information Enhancement for Mitigating Object Hallucination", "authors": "Sangha Park,Seungryong Yoo,Jisoo Mok,Sungroh Yoon", "background": "尽管多模态大型语言模型（MLLMs）取得了长足的进步，但它们仍然容易受到由语言先验和视觉信息丢失引起的大规模生成错误（对象幻觉）的影响。", "innovation": "本文提出了SAVE（Sparse Autoencoder-Driven Visual Information Enhancement），一种通过引导模型沿着Sparse Autoencoder（SAE）潜在特征方向来减少幻觉的框架。SAVE通过识别最能反映模型视觉信息处理的SAE特征（称为视觉理解特征），并沿着这些特征引导模型，增强了基于视觉的理解，有效地减少了幻觉。SAVE在标准基准测试上优于当前最先进的无需训练的方法，特别是在CHAIR_S、POPE和MMHal-Bench上取得了显著的改进。", "conclusion": "广泛的评估表明，该方法在多个模型和层中具有高度的稳健性和通用性。进一步的分析表明，沿着视觉理解特征引导模型抑制了不确定对象标记的生成，并增加了对图像标记的注意力，从而减轻了幻觉问题。代码已发布（链接略）"}
{"llm_update_time": "20251210", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2512.07778", "html_url": "https://arxiv.org/abs/2512.07778", "title": "分布匹配变分自编码器", "title_en": "Distribution Matching Variational AutoEncoder", "authors": "Sen Ye,Jianning Pei,Mengde Xu,Shuyang Gu,Chunyu Wang,Liwei Wang,Han Hu", "background": "大多数视觉生成模型在应用扩散或自回归建模之前，都会将图片压缩到一个潜在空间。现有的方法，如VAEs和基础模型对齐编码器，隐式地限制了潜在空间，但没有明确塑造其分布，因此不清楚哪种类型的分布是最适合建模的。", "innovation": "该研究引入了分布匹配的变分自编码器（DMVAE），通过分布匹配约束明确地将编码器的潜在分布与任意参考分布对齐，这超越了传统VAEs的高斯先验，允许与来自半监督特征、扩散噪声或其他先验分布的分布进行对齐。DMVAE有助于系统地研究哪些潜在分布更有利于建模，结果表明来自半监督特征的分布在重建保真度和建模效率之间提供了良好的平衡，在ImageNet上达到gFID为3.2的成绩，仅需64个训练周期。", "conclusion": "我们的结果表明，选择合适的潜在分布结构（通过在分布级进行对齐实现），而不是依赖固定先验，是弥补易建模潜在特征与高保真度图像合成之间的差距的关键。"}
{"llm_update_time": "20251210", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2512.07833", "html_url": "https://arxiv.org/abs/2512.07833", "title": "关系视觉相似性", "title_en": "Relational Visual Similarity", "authors": "Thao Nguyen,Sicheng Mo,Krishna Kumar Singh,Yilin Wang,Jing Shi,Nicholas Kolkin,Eli Shechtman,Yong Jae Lee,Yuheng Li", "background": "人类不仅可以看到属性上的相似性，还能看到关系上的相似性。例如，苹果和桃子都是红色的水果，在视觉属性上相似，但从另一个角度来看，地球也像桃子：地壳、地幔和地核分别对应桃子的果皮、果肉和果核，体现出关系上的相似性。这种感知与识别关系相似性的能力据认知科学家认为是人类与其他物种的区别之一。然而，现有的所有广泛使用的视觉相似度度量方法（例如，LPIPS、CLIP、DINO）仅关注感知属性上的相似性，未能捕捉人类感知到的关系上的丰富相似性。因此，需要一种方法超越图像的可见内容，去衡量其关系属性，并使具有相同关系逻辑的图像在表示空间中更加接近。", "innovation": "本文首先将关系图像相似性定义为一种可度量的问题：两幅图像如果其内部关系或视觉元素之间的关系相同，则视为关系相似，即使其视觉属性不同。然后，编纂了一个包含114,000个图像-描述对的数据集，其中描述了场景的底层关系逻辑而非表面内容。使用此数据集，微调了一个跨模态模型来测量图像之间的关系相似性。该模型是建立在基于图像底层关系结构而不是其表观形态连接图像的第一步。研究表明，虽然关系相似性在很多实际应用中都有真实世界的应用，但当前的图像相似性模型未能捕捉到这种关系相似性——表明视觉计算中存在一个关键的缺口。", "conclusion": "本文展示了虽然关系相似性在实际应用中有许多真实世界的用途，但现有的图像相似性模型未能捕捉这种关系相似性——揭示了视觉计算中存在一个关键的缺口。该研究是将图像基于其底层关系结构而不是可视外观进行连接的第一步。"}
{"llm_update_time": "20251210", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2512.07674", "html_url": "https://arxiv.org/abs/2512.07674", "title": "DIST-CLIP：通过解离的解剖-对比度表示实现任意元数据和图像引导的MRI数据标准化", "title_en": "DIST-CLIP: Arbitrary Metadata and Image Guided MRI Harmonization via Disentangled Anatomy-Contrast Representations", "authors": "Mehmet Yigit Avci,Pedro Borges,Virginia Fernandez,Paul Wright,Mehmet Yigitsoy,Sebastien Ourselin,Jorge Cardoso", "background": "深度学习在医疗图像分析中具有巨大潜力，但其临床应用仍受到限制。这主要是由于数据异质性。在磁共振成像中，硬件差异、不同的采集协议以及不同的序列参数会引入显著的领域迁移，从而掩盖了潜在的生物学信号。现有数据标准化方法旨在减少这些由硬件和采集过程带来的差异，但现有方法仍然不足。将这些方法应用于成像数据时，基于图像的方法通常受限于需要目标图像，而文本引导的方法则依赖简单标签，无法捕捉到复杂的采集细节，且通常只能处理变量有限的数据集，无法捕获真实临床环境中的数据异质性。", "innovation": "本文提出了DIST-CLIP（解离风格转移与CLIP指导）框架，这是一种统一框架，能够灵活地使用目标图像或DICOM元数据进行指导。该框架明确地将解剖内容与图像对比度分离，对比度表示通过预训练的CLIP编码器提取，并通过新型自适应风格转移模块将对比度嵌入到解剖内容中。该框架在多种实际临床数据集上进行了训练和评估，并在风格转换准确性和解剖信息保持方面优于现有最先进的方法，提供了一个灵活的风格转移解决方案，并统一了MRI数据。", "conclusion": "我们在多种实际临床数据集上训练和评估了DIST-CLIP，并证明了其与顶级方法相比在风格转换准确性和解剖信息保持方面的显著改进，提供了一种灵活的风格转移和标准化MRI数据的解决方案。我们的代码和权重将在发表后变得公开可用。"}
{"llm_update_time": "20251210", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2512.06008", "html_url": "https://arxiv.org/abs/2512.06008", "title": "语义时间单光子LiDAR", "title_en": "Semantic Temporal Single-photon LiDAR", "authors": "Fang Li,Tonglin Mu,Shuling Li,Junran Guo,Keyuan Li,Jianing Li,Ziyang Luo,Xiaodong Fan,Ye Chen,Yunfeng Liu,Hong Cai,Lip Ket Chin,Jinbei Zhang,Shihai Sun", "background": "传统的时域单光子（TSP-）LiDAR技术虽然具有距离长、体积小、成本低和功耗低的优点，但在处理未知目标出现的开放场景时效果不佳，并且在低信噪比和短采集时间（较少光子）的情况下表现退化。", "innovation": "受符号通信启发，本文提出了一种基于自更新语义知识库（SKB）的语义TSP-LiDAR，将TSP-LiDAR的目标识别处理过程形式化为符号通信。结果表明，在具有挑战性的低信噪比和有限的采集时间条件下，本方法超越了传统方法。此外，自更新SKB机制能够在SKB中动态更新新遇到的目标的语义特征，实现持续的自适应而无需对神经网络进行大量重训。", "conclusion": "通过实际实验结果表明，我们提出的框架在复杂和动态环境中实现了针对九种未知目标的89%的识别精度，相比之下，没有更新机制时的识别精度为66%。这些结果突显了本框架在自适应和稳健的目标识别方面的潜在应用价值。"}
{"llm_update_time": "20251210", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2512.07829", "html_url": "https://arxiv.org/abs/2512.07829", "title": "一层就足够：将预训练视觉编码器适应于图像生成", "title_en": "One Layer Is Enough: Adapting Pretrained Visual Encoders for Image Generation", "authors": "Yuan Gao,Chen Chen,Tianrong Chen,Jiatao Gu", "background": "视觉生成模型（例如扩散模型）在压缩的潜在空间中操作，以平衡训练效率和样本质量。同时，研究人员越来越关注利用高质量的预训练视觉表示，或者在VAE内部对齐它们，或者直接在生成模型内部使用它们。然而，将这些表示适应生成模型仍然存在挑战，因为理解导向的特征与生成友好的潜在空间之间存在根本性不匹配。这些不匹配使得先前的工作不得不依赖复杂的目标和架构。背景中的研究主要关注这一挑战。", "innovation": "本文提出了一种简单的有效框架FAE（特征自动编码器），它可以通过一个单层注意力层适应预训练的视觉表示到适合生成的低维潜在空间，同时保留足够的信息用于重建和理解。框架的关键在于结合了两个独立的深度解码器：一个用于重建原始特征空间，另一个则将重建的特征作为输入生成图像。FAE具有通用性，可以与各种自监督编码器（如DINO，SigLIP）以及两类生成模型（扩散模型和标准化流）结合使用。通过在类条件和文本到图像基准测试中的表现，FAE展示了高质量和快速学习的能力。", "conclusion": "FAE在ImageNet 256x256上的扩散模型中实现了接近最新的FID指标（1.29, 800个epoch，1.70, 80个epoch）。在没有随机性因子指南的情况下，FAE达到了最先进的FID指标（1.48, 800个epoch，2.08, 80个epoch），这表明该方法在质量上的高效率和快速学习能力。"}
{"llm_update_time": "20251210", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2512.07826", "html_url": "https://arxiv.org/abs/2512.07826", "title": "OpenVE-3M：用于指令引导视频编辑的大规模高质量数据集", "title_en": "OpenVE-3M: A Large-Scale High-Quality Dataset for Instruction-Guided Video Editing", "authors": "Haoyang He,Jie Wang,Jiangning Zhang,Zhucun Xue,Xingyuan Bu,Qiangpeng Yang,Shilei Wen,Lei Xie", "background": "基于指令的图像编辑数据集的质量和多样性持续提升，然而对于基于指令的视频编辑的数据集，尤其是大规模、高质量的数据集仍然稀缺。本文旨在解决这一问题。", "innovation": "作者引入了OpenVE-3M，一个开源、大规模、高质量的基于指令的视频编辑数据集。它包含两种主要类别：空间对齐的编辑类型和非空间对齐的编辑类型，并通过精心设计的数据流水线生成，经过严格的质量筛选。此外，为了解决领域内缺乏统一基准的问题，作者还构建了OpenVE-Bench，其中包含431个视频编辑对，覆盖各种编辑任务，并包含三个与人类判断高度一致的关键指标。最后，基于OpenVE-3M开发了OpenVE-Edit模型，并在OpenVE-Bench上实现了最先进的性能。", "conclusion": "OpenVE-3M在规模、编辑类型多样性、指令长度和整体质量方面超过了现有的开源数据集。OpenVE-Edit模型在OpenVE-Bench上的表现超越了所有先前的开源模型，包括一个14GB的基线模型。"}
{"llm_update_time": "20251210", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2512.05992", "html_url": "https://arxiv.org/abs/2512.05992", "title": "更强并不总是更好：对比学习中医学图像分割的更好增强方法", "title_en": "Stronger is not better: Better Augmentations in Contrastive Learning for Medical Image Segmentation", "authors": "Azeez Idris,Abdurahman Ali Mohammed,Samuel Fanijo", "background": "自监督对比学习是近年来在包括语义分割在内的一些下游任务中表现出色的表示学习方法之一。该方法的一个关键组成部分是强大的数据增强，它通过将多种增强技术应用于图像，提高模型的性能。", "innovation": "该论文研究了现有的数据增强方法在医学图像分割任务中的效果，并发现这些增强方法并不总是有效。论文通过实验尝试新的增强方法，证明了某些新的增强技术能够提供更好的性能。", "conclusion": "研究发现，现有的数据增强技术并不总是适用于医学图像分割任务，某些新的增强方法可以带来更好的性能。"}
{"llm_update_time": "20251210", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2512.06589", "html_url": "https://arxiv.org/abs/2512.06589", "title": "OmniSafeBench-MM: 统一多模态ContextHolder攻击-防御评估基准和工具箱", "title_en": "OmniSafeBench-MM: A Unified Benchmark and Toolbox for Multimodal Jailbreak Attack-Defense Evaluation", "authors": "Xiaojun Jia,Jie Liao,Qi Guo,Teng Ma,Simeng Qin,Ranjie Duan,Tianlin Li,Yihao Huang,Zhitao Zeng,Dongxian Wu,Yiming Li,Wenqi Ren,Xiaochun Cao,Yang Liu", "background": "近期多模态大规模语言模型（MLLMs）取得了进展，具备了统一的感知-推理能力，但这些系统对情境的脆弱性（如 jailbreak 攻击）依然显得尤为敏感。目前的基准（如 JailBreakV-28K、MM-SafetyBench 和 HADES）提供了有价值的多模态漏洞信息，但往往关注有限的攻击场景，并缺乏标准化的防御评估，也没有提供统一且可复现的工具箱。为此，本文介绍了一种名为 OmniSafeBench-MM 的全面的工具箱，用于多模态情境攻击-防御评估。", "innovation": "OmniSafeBench-MM 介绍了 13 种代表性攻击方法、15 种防御策略，集成了涵盖 9 个主要风险领域和 50 个细分类别的多元数据集，按照咨询、命令式及声明性查询类型结构化，以反映真实的用户意图。此外，制定了三维评估标准，包括危害性、响应和查询间的意图对齐以及回复细节水平，并提供了一个开源、可复现的平台进行广泛实验，揭示了 10 个开源和 8 个封闭源 MLLMs 的多模态情境攻击脆弱性。", "conclusion": "OmniSafeBench-MM 提供了一个标准化基准与工具箱，可作为未来研究的基础，并且通过数据、方法和评估的统一化，使得多模态情境攻击-防御评估更为简便和可靠。所有代码都已开源并可复现，可以在https://开头的链接处获取。"}
{"llm_update_time": "20251210", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2512.07806", "html_url": "https://arxiv.org/abs/2512.07806", "title": "多视图金字塔变换器：看粗略些以见更广阔", "title_en": "Multi-view Pyramid Transformer: Look Coarser to See Broader", "authors": "Gyeongjin Kang,Seungkwon Yang,Seungtae Nam,Younggeun Lee,Jungwoo Kim,Eunbyung Park", "background": "当前研究中，大型3D场景的重建方法主要依赖于从多张图像（从几十张到几百张）中进行重建，这种任务通常分为局部到全局的过程，需要逐个处理每一张图像，这在计算上效率较低。现有方法难以在保证重建质量的同时保持高效性和可扩展性。", "innovation": "本文提出了一种新的多视图变换器架构——Multi-view Pyramid Transformer (MVP)，其特点在于利用了'看更广阔以见整体，看更精细以见细节'的理念，构建了两个核心设计原则：1）局部到全局的视图层级，从局部视图逐渐扩展到组间视图，最终扩展到整个场景；2）从精细到粗略的视图内部层次，从详细的空域表示开始，逐步聚合为紧凑的信息密集型令牌。这种双重层次结构实现了计算效率和表示丰富性的平衡，能够快速重建大型和复杂的3D场景。", "conclusion": "在多种数据集上验证了MVP的有效性，当与3D Gaussian Splatting相结合作为3D表示基础时，MVP在保持高效性和可扩展性的同时，实现了当前最先进的泛化重建质量。"}
{"llm_update_time": "20251210", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2512.07802", "html_url": "https://arxiv.org/abs/2512.07802", "title": "OneStory: 适应性记忆促进的一致多镜头视频生成", "title_en": "OneStory: Coherent Multi-Shot Video Generation with Adaptive Memory", "authors": "Zhaochong An,Menglin Jia,Haonan Qiu,Zijian Zhou,Xiaoke Huang,Zhiheng Liu,Weiming Ren,Kumara Kahatapitiya,Ding Liu,Sen He,Chenyang Zhang,Tao Xiang,Fanny Yang,Serge Belongie,Tian Xie", "background": "在现实世界视频中，故事情节往往通过多个镜头（不连续但意义相连的片段）逐步展开，共同构建一个连贯的叙述。然而，现有的多镜头视频生成（MSV）方法在建模长期跨镜头上下文时效果不佳，这是因为它们依赖于有限的时间窗口或单一的关键帧条件，导致在复杂的故事情节下性能下降。", "innovation": "本文提出了OneStory，它通过引入全局但紧凑的跨镜头上下文建模方法，实现一致且可扩展的叙述生成。OneStory将MSV重新定义为下一个镜头生成任务，利用预训练的图像到视频（I2V）模型进行强视觉条件。具体创新点包括：引入了一个帧选择模块，该模块根据先前镜头中具有信息性的帧构建语义相关的全局记忆；以及一个自适应条件器模块，该模块进行重要性指导的块化处理，生成紧凑的上下文以直接进行条件处理。", "conclusion": "结合我们的定制60K数据集进行微调后，OneStory在文本和图像条件下实现了多项式最优的连贯性，能够在各种复杂场景中生成一致且沉浸式的长形式视频叙述，支持可控的长视频叙事创作。"}
{"llm_update_time": "20251210", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2512.06628", "html_url": "https://arxiv.org/abs/2512.06628", "title": "MIND-V：基于RL物理对齐的分层视频生成以实现长时 horizon 机器人操作", "title_en": "MIND-V: Hierarchical Video Generation for Long-Horizon Robotic Manipulation with RL-based Physical Alignment", "authors": "Ruicheng Zhang,Mingyang Zhang,Jun Zhou,Zhangrui Guo,Xiaofan Liu,Zunnan Xu,Zhizhou Zhong,Puxin Yan,Haocheng Luo,Xiu Li", "background": "现有的体现模仿学习受限于多样且长时 horizon 的机器人操作数据稀缺。现有的视频生成模型主要只能生成简单的、短时的机器人动作片段，并且通常依赖于手动定义的轨迹。", "innovation": "MIND-V 是一个分层框架，用于生成物理上合理且逻辑上连贯的长时 horizon 机器人操作视频。MIND-V 包含三个核心组件：语义推理核心（SRH）、行为语义桥梁（BSB）和运动视频生成器（MVG）。此外，MIND-V 引入了基于强化学习的 Staged Visual Future Rollouts 测试时优化策略和新型的物理先见一致性（PFC）奖励来实现物理上合理性和视频生成的对齐。", "conclusion": "MIND-V 在长时 horizon 机器人操作视频生成方面达到了最先进的性能，并且建立了一个可扩展且可控的体现数据合成框架。"}
{"llm_update_time": "20251210", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2512.07834", "html_url": "https://arxiv.org/abs/2512.07834", "title": "Voxify3D: Pixel Art Meets Volumetric Rendering", "title_en": "Voxify3D: Pixel Art Meets Volumetric Rendering", "authors": "Yi-Chuan Huang,Jiewen Chan,Hao-Jen Chien,Yu-Lun Liu", "background": "voxel艺术作为一种独特的风格被广泛应用于游戏和数字媒体中，然而，从3D网格自动生成时由于要在几何抽象、语义保留和离散颜色一致性方面相互冲突的需求变得具有挑战性，现有方法要么过度简化几何结构，要么无法实现像素精确且受调色板约束的voxel艺术视觉效果。", "innovation": "Voxify3D提出了一种可微分的两阶段框架，结合了3D网格优化与2D像素艺术监督。其核心创新在于三个部分的协同整合：(1) 正交像素艺术监督，消除透视失真，实现精确的voxel-pixel对齐；(2) 基于补丁的CLIP对齐，确保在离散化级别下保持语义；(3) 调色板约束的Gumbel-Softmax量化，允许在离散颜色空间中进行可微优化，并通过控制调色板策略进行调制。这一体系结构解决了极端离散化下的语义保留、通过容积渲染实现像素艺术美学以及端到端离散优化等基本挑战。", "conclusion": "实验结果表明，Voxify3D在多样化的角色和可控抽象程度（2-8种颜色，20x至50x分辨率）下表现出优异的性能（CLIP-IQA评分为37.12，用户偏好率为77.90%）。"}
{"llm_update_time": "20251210", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2512.06147", "html_url": "https://arxiv.org/abs/2512.06147", "title": "GuideNav: 用户导向的视觉辅助机器人导航系统为盲人旅行者开发", "title_en": "GuideNav: User-Informed Development of a Vision-Only Robotic Navigation Assistant For Blind Travelers", "authors": "Hochul Hwang,Soowan Yang,Jahir Sadik Monon,Nicholas A Giudice,Sunghoon Ivan Lee,Joydeep Biswas,Donghyun Kim", "background": "尽管已经取得了一些用户导向的研究进展，特别是在移动辅助系统方面为盲人和视力障碍（BLV）人士的服务，但直接用于机器人导航设计的参考文献仍然很少。为此，研究人员开展了一项综合的人类研究，包括采访了26名导盲犬管理员、4名白杖用户、9名导盲犬训练师和1名导盲（O&M）训练师，以及超过15小时的导盲犬辅助行走观察。", "innovation": "基于上述形成性研究洞察，研究人员开发了GuideNav，这是一种仅依靠视觉的、自我复制路径的导航系统。该系统模仿导盲犬是如何训练和帮助其管理员的行为，通过一个视见的机器人来自动重复可视的人行走路径。特别地，该系统构建了一个被教授路径的拓扑表示，结合了视觉位置识别和时间过滤，并使用相对位姿估计器来计算导航行为。GuideNav能够在多个户外环境中实现千米级路线跟随，即使在教和重复过程之间存在显著的场景变化下仍然保持可靠性。", "conclusion": "一项由3名导盲犬管理员和1名导盲训练师参与的用户研究进一步确认了该系统的可行性，这是到目前为止首次证明四足移动系统以类似于导盲犬的方式检索路径的演示（根据我们的知识）。"}
{"llm_update_time": "20251210", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2512.06848", "html_url": "https://arxiv.org/abs/2512.06848", "title": "AquaFusionNet：边缘设备上实时病原体检测和水质异常预测的轻量级视觉传感器融合框架", "title_en": "AquaFusionNet: Lightweight VisionSensor Fusion Framework for Real-Time Pathogen Detection and Water Quality Anomaly Prediction on Edge Devices", "authors": "Sepyan Purnama Kristanto,Lutfi Hakim,Hermansyah", "background": "许多低收入和中等收入地区的小规模饮用水系统微生物污染经常会快速波动，但现有的监测工具只能捕捉到这一行为的一部分。显微镜成像可提供微生物级的视图，而物理化学传感器则揭示了水中化学成分的短期变化；然而，实际操作中，运营商需要单独解释这两种信息流，这使得实时决策变得不可靠。本研究引入了AquaFusionNet，这是一种轻量级的跨模态框架，将两种信息源统一到单个边缘可部署模型中。", "innovation": "AquaFusionNet通过专为低功耗硬件设计的门控交叉注意力机制，学习微生物出现与同时传感器动态之间的统计依赖性，这与之前将显微镜检测和水质预测视为独立任务的方法不同。该框架在AquaMicro12K数据集上进行训练，这个新数据集包含12,846个注释的1000张显微图片，专门用于饮用水环境，这些环境中的公开显微镜数据集稀缺。", "conclusion": "在印度尼西亚东爪哇七个设施部署六个月后，系统处理了1.84兆帧，并且一致检测到了94.8%的mAP@0.5和96.3%的异常预测准确性，同时在Jetson Nano上运行功耗为4.8W。与代表性的轻量级检测器进行比较实验表明AquaFusionNet在功率消耗接近或更优的情况下提供了更高的准确性。现场结果表明，跨模态耦合减少了单一模式检测器的常见故障模式，特别是在污染、浑浊突变和不一致的照明下。"}
{"llm_update_time": "20251210", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2512.06665", "html_url": "https://arxiv.org/abs/2512.06665", "title": "重新思考稳健性：一种评估特征归因方法的新方法", "title_en": "Rethinking Robustness: A New Approach to Evaluating Feature Attribution Methods", "authors": "Panagiota Kiourti,Anu Singh,Preeti Duraipandian,Weichao Zhou,Wenchao Li", "background": "当前的归因稳健性概念很大程度上忽略了模型输出之间的差异，这使得现有的方法无法充分评估归因方法的稳健性。", "innovation": "提出了新的输入相似性定义，一个新的稳健性度量标准，以及一种基于生成对抗网络的新方法来生成这些输入。此外，还使用现有度量标准和最先进的归因方法进行了全面评估。", "conclusion": "研究指出了需要一个更客观的度量标准来揭示归因方法的弱点，而不是神经网络的弱点，从而提供对归因方法稳健性的更准确评估。"}
{"llm_update_time": "20251210", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2512.06757", "html_url": "https://arxiv.org/abs/2512.06757", "title": "XM-ALIGN：Face-Voice关联的统一跨模态嵌入对齐", "title_en": "XM-ALIGN: Unified Cross-Modal Embedding Alignment for Face-Voice Association", "authors": "Zhihua Fang,Shumei Tao,Junxu Wang,Liang He", "background": "在ICASSP 2026的FAME挑战中提出了XM-ALIGN框架，旨在解决跨模态身份验证问题，特别是在“听过的”和“未听过的”语言下改进验证性能。通过结合显式和隐式对齐机制，该框架能够从面部和语音编码器中提取特征嵌入，并通过共享分类器进行联合优化。", "innovation": "XM-ALIGN框架通过使用均方误差(MSE)作为嵌入对齐损失，确保了模态之间的紧密对齐。此外，在模型训练过程中还应用了数据增强策略以提高泛化能力。", "conclusion": "实验结果表明，该方法在MAV-Celeb数据集上的性能优于其他方法。相关代码将发布在指定网站。"}
{"llm_update_time": "20251210", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2512.06609", "html_url": "https://arxiv.org/abs/2512.06609", "title": "使用高斯变分自编码器的向量量化", "title_en": "Vector Quantization using Gaussian Variational Autoencoder", "authors": "Tongda Xu,Wendi Zheng,Jiajun He,Jose Miguel Hernandez-Lobato,Yan Wang,Ya-Qin Zhang,Jie Tang", "background": "VQ-VAE 是一种将图像压缩为离散代币的离散编码器，但由于离散化的原因，其训练非常困难。本文介绍了一种简单且有效的技术，称之为高斯量化（GQ），它能够将具有某些约束的高斯 VAE 转换为无需重新训练的 VQ-VAE。", "innovation": "提出了一种名为 Gaussian Quant (GQ) 的方法，通过生成高斯噪声作为码本，并查找与后验均值最近的噪声。此外，还提出了一种新的训练高斯 VAE 的启发式方法，称为目标偏差约束（TDC）。实验结果显示，在 UNet 和 ViT 架构上，GQ 在与以往 VQ-VAEs（如 VQGAN、FSQ、LFQ 和 BSQ）的比较中表现更优。同时，TDC 也优于先前的高斯 VAE 离散化方法（如 TokenBridge），且提供了源代码。", "conclusion": "本文提出的技术可以在不需要重新训练的情况下，将高斯 VAE 转换为 VQ-VAE，并且在实验中显示了其在图像压缩和编码任务中的优势。"}
{"llm_update_time": "20251210", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2512.06737", "html_url": "https://arxiv.org/abs/2512.06737", "title": "数学推导出的具有相位意识、用户可控步长动态性的梯度下降法：弧度梯度下降", "title_en": "Arc Gradient Descent: A Mathematically Derived Reformulation of Gradient Descent with Phase-Aware, User-Controlled Step Dynamics", "authors": "Nikhil Verma,Joonas Linnosmaa,Espinosa-Leal Leonardo,Napat Vajragupta", "background": "论文详细介绍了ArcGD优化器的构建、实现和评估过程。评估首先在非凸基准函数上进行，之后在实际的机器学习（ML）数据集上进行。初始对比研究使用Adam优化器在高度非凸并极具挑战性的罗森布罗克函数上进行，这是一个以窄曲山谷而闻名的函数。研究评估了两种配置以消除学习率偏差，并展示了ArcGD在初始条件下始终优于Adam，尽管在学习率相同的情况下稍慢一些，但在大多数情况下仍能获得更优的最终解决方案。", "innovation": "ArcGD是一个由数学推导出的改进的梯度下降优化器，具有相位意识和用户可控的步长动态性。它在基准测试和标准深度学习基准测试中表现出色，尤其是在图像分类数据集上的持续改进和对过拟合的抵抗力方面，无需调整早期停止参数。研究还表明，ArcGD的一个变体可以作为Lion优化器的一种特殊情况，这显示了这些优化方法的内在机制之间的联系。", "conclusion": "ArcGD在多种深度学习架构下的图像分类任务中表现出优越的性能，尤其是在持续改进和对过拟合的抵抗力方面，超越了包括AdamW、Adam、SGD和Lion等在内的先进优化器。这一优化器的数学推导及其与Lion优化器的关系，显示了更多的潜在研究探索空间。"}
{"llm_update_time": "20251210", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2512.06951", "html_url": "https://arxiv.org/abs/2512.06951", "title": "视觉-语言-行动模型的任务适应性：2025年BEHAVIOR挑战赛第一名解决方案", "title_en": "Task adaptation of Vision-Language-Action model: 1st Place Solution for the 2025 BEHAVIOR Challenge", "authors": "Ilia Larchenko,Gleb Zarin,Akash Karnatak", "background": "该研究作为2025年BEHAVIOR挑战赛的一部分进行，该挑战赛是一个大规模基准测试，包含50项多样化的长期家庭任务，在真实的模拟环境中进行，需要双臂操作、导航和情境感知决策。这为视觉-行动策略研究提供了一个广阔的舞台。", "innovation": "论文基于Pi0.5架构，提出了几个创新：1) 聚合噪声用于流匹配，提高训练效率并支持关联感知填补，使动作序列变得平滑；2) 采用可学习混合层注意力和系统2阶段跟踪来解决歧义；3) 训练使用多样本流匹配来降低方差；4) 推理阶段使用行动压缩和挑战特定的校正规则。", "conclusion": "该方法在所有50项任务的公开和私人排行榜上获得了26%的q分，从而在2025年BEHAVIOR挑战赛中获得第一名。"}
{"llm_update_time": "20251210", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2512.06963", "html_url": "https://arxiv.org/abs/2512.06963", "title": "VideoVLA：视频生成器可以成为可泛化的机器人操作者", "title_en": "VideoVLA: Video Generators Can Be Generalizable Robot Manipulators", "authors": "Yichao Shen,Fangyun Wei,Zhiying Du,Yaobo Liang,Yan Lu,Jiaolong Yang,Nanning Zheng,Baining Guo", "background": "机器人操作在开放世界环境中的应用和向人工智能普遍智能迈进的过程中，泛化能力至关重要。尽管最近的视觉-语言-动作（VLA）模型借助了大型预训练理解模型进行感知和指令跟随，但它们对于执行新任务、新物体和新环境的泛化能力仍然有限。", "innovation": "提出了一种名为VideoVLA的方法，探索通过转换大型视频生成模型为机器人VLA操作者来增强泛化能力。VideoVLA基于多模态扩散变换器，联合建模视频、语言和动作模态，并利用预训练的视频生成模型进行联合视觉和动作预测。实验表明，高质量的未来图像想象与可靠的动作预测和任务成功密切相关，突显了视觉想象在操作中的重要性。", "conclusion": "VideoVLA展示了强大的泛化能力，不仅展示了模仿其他实体的技能，还能够处理新型物体。双预测策略——同时预测动作及其视觉后果——探索了机器人学习范式的转变，并解锁了操作系统的泛化能力。"}
{"llm_update_time": "20251210", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2512.06648", "html_url": "https://arxiv.org/abs/2512.06648", "title": "基于卷积神经网络的上市公司财务欺诈识别及解释性研究", "title_en": "Financial Fraud Identification and Interpretability Study for Listed Companies Based on Convolutional Neural Network", "authors": "Xiao Li", "background": "由于股份公司的出现，上市公司的财务欺诈频繁破坏资本市场。欺诈难以察觉，因为它采取隐蔽策略，并且审计需要大量劳动力和时间成本。传统统计模型具有较高的解释性，但在处理非线性特征交互方面较弱，而机器学习模型虽然强大但通常不透明。此外，现有方法通常只基于当年数据来判断当年的欺诈，限制了其时效性。", "innovation": "本文提出了一种基于卷积神经网络（CNNs）的中国A股上市公司财务欺诈检测框架。设计了一种特征工程方案，将公司年度面板数据转化为图像表示，使CNN能够捕捉截面和时间模式，并能够预测欺诈。实验证明，CNN在准确率、鲁棒性和预警性能上优于逻辑回归和LightGBM，并且在高风险环境中正确调整分类阈值至关重要。为提高解释性，本文通过局部解释技术从实体、特征和时间维度分析模型，发现偿债能力、比例结构、治理结构和内部控制是欺诈的一般预测指标，而环境指标在高污染行业中尤为关键。非欺诈公司具有稳定的特征模式，而欺诈公司在较短的时间窗口内表现出异质特征模式。案例分析表明，现金流量分析、社会责任、治理结构和每股指标是模型预测欺诈的主要驱动因素，与公司的实际不端行为一致。", "conclusion": "基于CNN的财务欺诈检测框架在准确率、鲁棒性和提前预警方面优于现有方法，模型解释性分析表明偿债能力、比例结构等是一般欺诈预测指标，而环境指标对公司有特殊影响，模型有助于识别和预警潜在的财务欺诈行为。"}
{"llm_update_time": "20251210", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2512.06990", "html_url": "https://arxiv.org/abs/2512.06990", "title": "利用编码-解码架构代理的多智能体强化学习识别胶质母细胞瘤患者的最优切除位置", "title_en": "Utilizing Multi-Agent Reinforcement Learning with Encoder-Decoder Architecture Agents to Identify Optimal Resection Location in Glioblastoma Multiforme Patients", "authors": "Krishna Arun,Moinak Bhattachrya,Paras Goel", "background": "目前，医学领域中对异质性脑肿瘤如胶质母细胞瘤（GBM）的支持不足，胶质母细胞瘤是全球最致命的人类癌症之一，五年生存率仅5.1%。已有AI系统主要在诊断和治疗规划方面做出有限的贡献。", "innovation": "该项目开发了一个AI系统，提供了一个端到端的解决方案，以帮助医生进行诊断和治疗规划。在诊断阶段，采用了由4个分类模型组成的顺序决策框架（卷积神经网络和支持向量机），逐步将患者的脑部分类到更具体的类别中。在治疗规划阶段，使用了3个生成模型的RL系统，包括用于预测切除结果的切除模型、用于模拟脑部随时间进展的放射治疗模型、以及用于生成术后MRI的化疗模型。最后，通过卷积神经网络计算存活率，以确保生成的术后MRI的存活率接近用户定义的目标。如果存活率不在目标范围内，系统会通过接近策略优化重复迭代，直到找到最优的切除位置，从而大幅降低计算成本、缩短肿瘤进展推断时间，并提高DICE评分。", "conclusion": "与现有解决方案相比，该项目的三项关键发现包括：(1) 使用包含4个小诊断模型的顺序决策框架将计算成本降低了22.28倍；(2) 使用变换器的回归能力缩短了肿瘤进展推断时间113小时；(3) 应用模拟真实生活情景的增强方法整体提高了DICE评分2.9%。这些结果预计能提高约0.9%的存活率，从而拯救约2250条生命。"}
{"llm_update_time": "20251210", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2512.07132", "html_url": "https://arxiv.org/abs/2512.07132", "title": "DART: 利用多智能体分歧进行多模态推理中的工具招募", "title_en": "DART: Leveraging Multi-Agent Disagreement for Tool Recruitment in Multimodal Reasoning", "authors": "Nithin Sivakumaran,Justin Chih-Yao Chen,David Wan,Yue Zhang,Jaehong Yoon,Elias Stengel-Eskin,Mohit Bansal", "background": "专门化视觉工具可以增强大型语言模型或视觉语言模型的专家知识（例如，语义定位、空间推理、医学知识等），但选择合适的工具及其使用时机可能会很有挑战性。本文研究了如何利用多个争论的视觉智能体之间的分歧来识别有用的视觉工具，这些工具可以解决多智能体之间的分歧。通过引入一个智能体聚合器，最终选择最佳答案。文章通过多个基准测试，验证了DART相比于单智能体工具调用框架和多智能体辩论方法的有效性，此外，DART在医学应用于使用新工具的领域中也表现良好。", "innovation": "本文介绍了DART，一种基于多智能体框架的方法，利用多个争论的视觉智能体之间的分歧来识别有用的工具。这些工具通过引入新信息和提供与专家工具一致的评分来促进多智能体讨论，从而深化讨论。此外，聚合智能体选择最佳答案时，将智能体输出和工具信息一并考虑，测试结果显示DART在多个基准测试中表现出色，特别是在使用医疗工具方面。", "conclusion": "DART通过利用多智能体之间的分歧来有效提升多模态推理中的工具调用能力，在具体基准任务上的表现超过了其他多智能体和单智能体基线方法。此外，DART在新的应用领域，如医学领域，也表现出色。最后，作者通过计算轮次之间的文本重叠度来展示DART生成更丰富的讨论内容。研究发现，在处理分歧时，使用的工具种类多样性得到了提高。"}
{"llm_update_time": "20251210", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2512.07040", "html_url": "https://arxiv.org/abs/2512.07040", "title": "通过语义制图将生物网络转换为图像，实现可视化解释和可扩展的深层分析", "title_en": "Transformation of Biological Networks into Images via Semantic Cartography for Visual Interpretation and Scalable Deep Analysis", "authors": "Sakib Mostafa,Lei Xing,Md. Tauhidul Islam", "background": "生物网络对生物医学科学至关重要，描述了分子、细胞、基因和组织之间的相互作用。理解这些网络对于健康和疾病至关重要，但由于其规模和复杂性，现有的计算方法面临巨大挑战。传统的生物网络分析方法，包括深度学习方法，虽然强大，但在可扩展性、长距离依赖性、多模态整合、表示能力限制以及可解释性方面存在固有的局限性。", "innovation": "我们提出了一种Graph2Image框架，该框架通过将代表性网络节点在2D网格上进行空间排列，将大型生物网络转化为二维图像集，从而克服了现有方法在可扩展性、内存效率和长距离上下文捕捉方面的局限。Graph2Image还无缝集成其他成像和组学模态，并通过直接可视化节点关联图像增强了可解释性。该方法在多个大规模生物网络数据集中的分类准确性提高了67.2%，并在个人电脑上对非常大的生物网络进行分析。", "conclusion": "Graph2Image提供了一种可扩展、可解释且多模态准备的生物网络分析方法，为疾病的诊断和复杂生物系统的研究提供了新的机会。"}
{"llm_update_time": "20251210", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2512.07224", "html_url": "https://arxiv.org/abs/2512.07224", "title": "通过Shapley衍生的一致性和不确定性指标实现深度学习分割的临床可解释性", "title_en": "Clinical Interpretability of Deep Learning Segmentation Through Shapley-Derived Agreement and Uncertainty Metrics", "authors": "Tianyi Ren,Daniel Low,Pittra Jaengprajak,Juampablo Heras Rivera,Jacob Ruzevick,Mehmet Kurt", "background": "医学影像分割是识别器官、组织和病灶等解剖区域的基本任务，在计算机辅助诊断中具有重要作用。尽管深度学习模型在医学图像分割中取得了显著的性能，但在临床实践中确保其接受度和集成性仍需解释性，尤其是在渐增的研究关注中。", "innovation": "本文探索了使用对比度级别的Shapley值作为系统地干扰模型输入以评估特征重要性的方法。与其他研究通过识别影像输入中的关键区域来进行梯度基技术不同，Shapley值提供了更广泛的、符合临床的方法，解释模型性能如何公平地归因于不同的影像对比度。", "conclusion": "本文使用BraTS 2024数据集，为四种MRI对比度和四种模型架构生成了Shapley值排名。提出了两个度量标准：模型与“临床医生”影像排名的一致性，以及通过Shapley值排名的跨验证折叠方差来量化不确定性。高表现情况（Dice > 0.6）与临床排名有显著的一致性。Shapley值排名的方差增加与性能下降呈负相关。这些度量标准为模型可靠性提供了可临床解释的代理指标，帮助临床医生更好地理解最先进的分割模型。"}
{"llm_update_time": "20251210", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2512.07150", "html_url": "https://arxiv.org/abs/2512.07150", "title": "FlowLPS：基于Langevin-Proximal采样的流式逆问题解决方法", "title_en": "FlowLPS: Langevin-Proximal Sampling for Flow-based Inverse Problem Solvers", "authors": "Jonghyun Park,Jong Chul Ye", "background": "深度生成模型已成为解决逆问题的强大先验，各种训练免费的方法已被开发。然而，当应用于潜在流模型时，现有方法通常无法收敛到后验模态或在潜在空间中遭受流形偏差。", "innovation": "提出了一种新颖的训练免费框架FlowLPS，通过Langevin Proximal Sampling (LPS)策略利用预训练的流模型解决逆问题。该方法结合Langevin动力学进行流形一致的探索和近端优化进行精确的模式寻找，从而在FFHQ和DIV2K上的多个逆任务中实现了重建保真度和感知质量之间的卓越平衡，并优于最先进的逆问题求解器。", "conclusion": "该方法在解决逆问题方面表现出色，特别是在FFHQ和DIV2K等多种任务上，提供了优于现有最先进逆问题求解器的效果，同时在重建保真度和感知质量之间实现了优异的平衡。"}
{"llm_update_time": "20251210", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2512.07259", "html_url": "https://arxiv.org/abs/2512.07259", "title": "基于小块图像去噪的仿射子空间模型及其聚类方法", "title_en": "Affine Subspace Models and Clustering for Patch-Based Image Denoising", "authors": "Tharindu Wickremasinghe,Marco F. Duarte", "background": "图像处理应用中，图像小块（图像瓷砖）方法非常流行，如非局部均值去噪。这些方法的关键步骤是将图像聚类，通常通过迭代地将图像分为簇并为每个簇拟合模型来实现。线性子空间模型已证明适用于瓷砖簇，但不适用于图像小块，因为图像不围绕原点在瓷砖向量空间中分布。本文研究了仿射子空间模型在簇中的应用，以更好地匹配图像瓷砖向量空间的几何结构。文中还提出了一种基于仿射子空间聚类模型的简单去噪算法，使用最小二乘投影。此外，还总结了求解仿射子空间聚类问题的算法，展示了聚类和去噪性能改进的实验结果。", "innovation": "提出了一种基于仿射子空间聚类的简单去噪算法，通过最小二乘投影实现。研究了仿射子空间模型在图像去噪中的应用，以更适应图像小块的数据结构。", "conclusion": "通过实验结果验证了仿射子空间聚类模型在图像去噪中的有效性，并展示了其相对于传统线性子空间模型的性能提升。"}
{"llm_update_time": "20251210", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2512.06649", "html_url": "https://arxiv.org/abs/2512.06649", "title": "利用视觉机器学习估算城市交通中黑碳浓度", "title_en": "Estimating Black Carbon Concentration from Urban Traffic Using Vision-Based Machine Learning", "authors": "Camellia Zakaria,Aryan Sadeghi,Weaam Jaafar,Junshi Xu,Alex Mariakakis,Marianne Hatzopoulou", "background": "城市区域的黑碳（BC）排放主要由交通驱动，特别是靠近主要道路的热点区域对边缘社区影响较大。由于黑碳监测通常需要昂贵且专门的设备，所以难以获取来自本地交通源的黑碳数据，无法针对局部因素制定政策干预措施。尽管交通监测系统在全球多个城市广泛应用，但人们对交通状况的了解远远超出了对它们环境影响的了解。为了弥合这一差距，本文提出了一种基于机器学习的系统，通过交通视频提取视觉信息来捕捉车辆行为和状态。结合天气数据，该模型在街道水平估计黑碳浓度，R²值为0.72，RMSE为129.42 ng/m³。", "innovation": "本文提出了一种基于机器学习的方法，利用交通视频数据和环境数据来估算街道水平的黑碳浓度。通过对现有的交通监测系统和现有建模技术的利用，生成了与交通排放相关的信息，填补了关于交通环境影响数据的空白。", "conclusion": "本文通过视觉机器学习方法提供的黑碳浓度信息，可以支持减少污染、城市规划、公共健康以及环境正义等本地措施的制定。从可持续性的角度看，本研究利用城市基础设施支持的资源和已建立的建模技术，改善了对交通排放影响的了解。"}
{"llm_update_time": "20251210", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2512.06730", "html_url": "https://arxiv.org/abs/2512.06730", "title": "增强基于AR-SSVEP的运动意图识别可解释性通过CNN-BiLSTM和EEG数据的SHAP分析", "title_en": "Enhancing Interpretability of AR-SSVEP-Based Motor Intention Recognition via CNN-BiLSTM and SHAP Analysis on EEG Data", "authors": "Lin Yang,Xiang Li,Xin Ma,Xinxin Zhao", "background": "患者的运动功能障碍使其对康复训练的兴趣较低。传统的基于稳态视觉evoked potential (SSVEP)的大脑-计算机接口(BCI)系统依赖外部视觉刺激设备，这限制了其在实际环境中的应用。因此，本研究提出了一种增强现实(AR)稳定的正弦波视觉诱发电位(AR-SSVEP)系统，以解决患者的主动性不足和治疗师的工作负荷过重问题。", "innovation": "本研究首先设计了四种基于HoloLens 2的EEG类别，并从七名健康受试者中收集EEG数据进行分析。其次，本研究在传统的CNN-BiLSTM架构中结合了一个多头注意机制（MACNN-BiLSTM），提取十个时间和频谱EEG特征，并将其输入到CNN中学习高级表示。然后，通过BiLSTM建模序列依赖性，并应用多头注意机制突出运动意图相关的模式。最后，应用SHAP方法可视化EEG特征对神经网络决策过程的贡献，增强模型的可解释性。", "conclusion": "这些发现提高了对患者运动障碍患者的实时运动意图识别，并支持了康复过程。"}
{"llm_update_time": "20251210", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2512.07142", "html_url": "https://arxiv.org/abs/2512.07142", "title": "通过保留网络训练动力学的Concrete票搜索赢得彩票", "title_en": "Winning the Lottery by Preserving Network Training Dynamics with Concrete Ticket Search", "authors": "Tanay Arora,Christof Teuscher", "background": "彩票票假说提出，在密集的随机初始化神经网络内部可能存在高度稀疏但可训练的子网络（‘赢家票’）。现有的抽取这些票的方法，如彩票票重置（LTR），计算上代价高昂，而高效的基于梯度重要性剪枝初始化（PaI）技术则在精度-稀疏性权衡方面表现不佳，难以满足基本的合理性检查。这是由于PaI依赖于忽略了权重间依赖关系的一阶梯度指标。", "innovation": "该研究通过引入Concrete票搜索（CTS）算法，将子网络发现视为一个整体组合优化问题。CTS利用离散搜索空间的Concrete松弛和新型梯度平衡方案（GRADBALANCE）来控制稀疏性，从而在初期就能高效地发现表现良好的子网络，而不需要敏感的超参数调整。研究还提出了借鉴知识蒸馏的理念的剪枝目标，发现最小化稀疏网络和密集网络输出间的逆Kullback-Leibler散度（CTS-KL）特别有效。实验显示CTS生成的子网络不仅能通过合理性检查，还能在计算成本极低的情况下达到与LTR相当或更高的精度。", "conclusion": "CTS生成的子网络在所有稀疏性条件下均优于基于梯度重要性的方法，在高度稀疏条件下尤其如此。例如，在CIFAR10上的ResNet-20，CTS在7.9分钟内实现99.3%的稀疏性和74.0%的精度，而LTR在同等稀疏性下只有68.3%的精度，需要95.2分钟。"}
{"llm_update_time": "20251210", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2512.07355", "html_url": "https://arxiv.org/abs/2512.07355", "title": "概念锥体统一的概念学习几何框架", "title_en": "A Geometric Unification of Concept Learning with Concept Cones", "authors": "Alexandre Rocchi--Henry,Thomas Fel,Gianni Franchi", "background": "两种解释性的传统独立发展但很少相互交流：概念瓶颈模型（CBMs）定义了概念应为何种形态，而稀疏自编码器（SAEs）则发现从数据中涌现的概念。CBMs通过监督使激活与人类标注的概念对齐，而SAEs依赖稀疏编码发现涌现的概念。", "innovation": "提出了一种基于几何结构的操作桥梁，将这两种范式连接起来。CBMs提供人类定义的参考几何结构，而SAEs则可以通过其学习的概念锥是否接近或包含CBM的概念来评估。这些测量值用于揭示稀疏性和扩展系数的最佳组合，从而最大化几何和语义与CBM概念的一致性。整体而言，该工作通过共享几何框架统一了受监督和非受监督的概念发现，提供了评估SAE进展和检查发现的概念是否与人合理概念一致的原则性指标。", "conclusion": "本文通过共享几何框架统一了受监督和非受监督的概念发现，并提供了评估SAE进展和检查发现的概念是否与可能的人类概念定位一致的原理性指标，展示了稀疏性和扩张因子的最佳组合，以实现几何和语义与CBM概念的最大一致性。"}
{"llm_update_time": "20251210", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2512.06868", "html_url": "https://arxiv.org/abs/2512.06868", "title": "使用通用三维先验的动态视位同步系统", "title_en": "Dynamic Visual SLAM using a General 3D Prior", "authors": "Xingguang Zhong,Liren Jin,Marija Popović,Jens Behley,Cyrill Stachniss", "background": "可靠增量估计相机姿态和三维重建对于机器人、交互式可视化和增强现实等应用至关重要。然而，在动态自然环境中，场景动态性能显著影响相机姿态估计的准确性，使得任务极具挑战性。", "innovation": "本文提出了一种新颖的单目视觉SLAM系统，能够稳健地估计动态场景中的相机姿态。该方法融合了几何块式在线束调整和最新的前向式重建模型的优势。首先，提出了一种前向式重建模型以精确过滤动态区域，同时利用其深度预测增强块式视觉SLAM的鲁棒性。通过将深度预测和束调整估计的块对齐，系统能够稳健地处理前向式重建模型分批次应用时固有的尺度歧义。", "conclusion": "本文提出的单目视觉SLAM系统能够在动态场景中稳健地估计相机姿态，提升了在动态环境下的鲁棒性，对于发展机器人、交互式可视化和增强现实技术具有重要意义。"}
{"llm_update_time": "20251210", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2512.07130", "html_url": "https://arxiv.org/abs/2512.07130", "title": "Mimir: 基于不确定性传播的层次目标驱动扩散框架用于端到端无人驾驶", "title_en": "Mimir: Hierarchical Goal-Driven Diffusion with Uncertainty Propagation for End-to-End Autonomous Driving", "authors": "Zebin Xing,Yupeng Zheng,Qichao Zhang,Zhixing Ding,Pengxuan Yang,Songen Gu,Zhongpu Xia,Dongbin Zhao", "background": "端到端无人驾驶在自主系统领域正成为关键的发展方向。尽管最近的研究通过引入高层次的指导信号提升了低层次轨迹规划的表现，但这些方法往往受限于不准确的高层次指导和复杂指导模块带来的计算负担。", "innovation": "1. 推出了一个新颖的层级双系统框架Mimir，该框架可以基于含不确定性的目标点生成稳健的轨迹。(2) 引入了多速率指导机制，在预测扩展目标点后，加速了指导系统的推理速度，同时保持了准确性。", "conclusion": "通过在具有挑战性的Navhard和Navtest基准测试中验证，Mimir超越了以前的领先方法，EPDMS驾驶得分提高了20%，而高阶模块的推理速度提高了1.6倍，没有牺牲精度。代码和模型将在不久的将来开源，以促进可重现性和进一步的发展。"}
{"llm_update_time": "20251210", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2512.06392", "html_url": "https://arxiv.org/abs/2512.06392", "title": "RLAX：TPUs上大规模分布式的大型语言模型强化学习", "title_en": "RLAX: Large-Scale, Distributed Reinforcement Learning for Large Language Models on TPUs", "authors": "Runlong Zhou,Lefan Zhang,Shang-Chen Wu,Kelvin Zou,Hanzhi Zhou,Ke Ye,Yihao Feng,Dong Yin,Alex Guillen Garcia,Dmytro Babych,Rohit Chatterjee,Matthew Hopkins,Xiang Kong,Chang Lan,Lezhi Li,Yiping Ma,Daniele Molinari,Senyu Tong,Yanchao Sun,Thomas Voice,Jianyu Wang,Chong Wang,Simon Wang,Floris Weers,Yechen Xu,Guolin Yin,Muyang Yu,Yi Zhang,Zheng Zhou,Danyang Zhuo,Ruoming Pang,Cheng Leong", "background": "强化学习(RL)已成为提升大型语言模型(LLMs)推理能力的主流范式。", "innovation": "开发了RLAX，一种在TPUs上的可扩展RL框架，采用参数服务器架构；提出了一套系统技术，使多种最先进的RL算法能够大规模、可预emption地运行；设计了新的数据集策划和对齐技术以加速收敛并提高模型质量。", "conclusion": "大规模评估表明，使用1024个v5p TPUs，仅12小时48分钟，RLAX就将QwQ-32B的pass@8准确性提高了12.8%，且在训练过程中对预emption具有鲁棒性。"}
{"llm_update_time": "20251210", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2512.06471", "html_url": "https://arxiv.org/abs/2512.06471", "title": "为什么目标导向的强化学习有效：与双控制的关系", "title_en": "Why Goal-Conditioned Reinforcement Learning Works: Relation to Dual Control", "authors": "Nathan P. Lawrence,Ali Mesbah", "background": "目标导向的强化学习关注于训练智能体在最大概率上达到目标状态的问题。本文基于最优控制分析目标导向的设定，揭示了传统目标与目标导向奖励之间的优劣关系，并探讨半观测马尔可夫决策过程中的状态估计与概率奖励之间的联系。", "innovation": "提出了古典目标与目标导向奖励之间的优化差距，解释了目标导向强化学习的成功以及为何传统“密集”奖励可能失败；提出了与半观测马尔可夫决策过程相关的状态估计，使得目标导向奖励更适合解决双控制问题。", "conclusion": "通过使用强化学习和预测控制技术在非线性和不确定环境中验证目标导向策略的优势，进一步证明了目标导向奖励的有效性。"}
{"llm_update_time": "20251210", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2512.06490", "html_url": "https://arxiv.org/abs/2512.06490", "title": "使用量化优化以适应移动执行的LLMs", "title_en": "Optimizing LLMs Using Quantization for Mobile Execution", "authors": "Agatsya Yadav,Renta Chintala Bhargavi", "background": "大型语言模型（LLMs）具有强大的功能，但由于其显著的体积和计算需求，它们在资源受限的移动设备上的部署受到阻碍。", "innovation": "本研究探讨了训练后量化（PTQ）来压缩LLMs，适用于移动设备执行。通过使用BitsAndBytes库和Hugging Face Transformers框架对Meta的Llama 3.2 3B模型进行4比特PTQ，实现了68.66%的模型大小减少，并结合GGUF格式优化了移动推理。此外，该研究展示了在使用Termux环境和Ollama框架的情况下，在Android设备上运行量化后的模型的可行性。", "conclusion": "4比特量化配合优化的移动格式，如GGUF，提供了一种实用的方法，可以在平衡模型大小和性能的同时将能力较强的LLMs部署到移动设备上。"}
{"llm_update_time": "20251210", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2512.06440", "html_url": "https://arxiv.org/abs/2512.06440", "title": "超越重要性的基于神经表达性的模型压缩", "title_en": "Neural expressiveness for beyond importance model compression", "authors": "Angelos-Christos Maroudis,Sotirios Xydis", "background": "神经网络剪枝已经成为探索高性能、低能耗解决方案的重要驱动力，这些解决方案在训练和测试过程中都能实现高 throughput。已有的一些剪枝方法依赖于神经元和滤波器权重的固有‘重要性’，但这种方法可能不够全面。本文的背景是为了解决这一问题。", "innovation": "本文提出了一个新的剪枝评价标准——‘表达性’（Expressiveness）。不同于现有的基于权重重要性的剪枝方法，‘表达性’强调了神经元或一组神经元在信息重新分配方面的能力，这与网络的初始化状态紧密相关。这项新标准帮助解决了剪枝时机的问题，开辟了数据无感知压缩策略的研究方向。研究表明，表达性可以通过任意数据或少量有代表性的数据集进行近似，从而支持混合表达性和重要性导向的剪枝策略，且在参数压缩率上可达到10倍以上额外增益，同时平均性能损失仅为1%。", "conclusion": "在YOLOv8上，采用表达性剪枝实现了55.4%的参数减少，MACs减少46.1%，并且在COCO数据集上的目标检测中mAP50-95精度提高了3%。这表明独立使用‘表达性’剪枝能够显著提升顶级方法或基础方法的压缩效率。"}
{"llm_update_time": "20251210", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2512.06457", "html_url": "https://arxiv.org/abs/2512.06457", "title": "BitStopper: 通过阶段融合和早期终止提高高效Transformer注意力加速器", "title_en": "BitStopper: An Efficient Transformer Attention Accelerator via Stage-fusion and Early Termination", "authors": "Huizheng Wang,Hongbin Wang,Shaojun Wei,Yang Hu,Shouyi Yin", "background": "注意力机制在大型语言模型（LLMs）中已经颠覆了现代AI应用，但自注意力的二次成本导致了显着的计算和内存开销。动态稀疏性（DS）注意力虽然减轻了这一问题，但由于增加了预测阶段和重大的内存流量，其硬件效率受到限制。BitStopper提出了一种细粒度的算法-架构协同设计方法，旨在解决这些问题。", "innovation": "BitStopper提出了三种创新策略：1) 位串使能阶段融合机制（BESF），重新利用并最小化内存访问，通过逐段终止无用的标记并将预测阶段合并到执行阶段，2) 位级稀疏性猜测下的轻量且自适应标记选择策略（LATS），3) 位级异步处理（BAP）策略，提高按需按位内存获取时的计算利用率。此外，设计了一种详细的架构，将理论复杂度降低转化为实际性能提升。", "conclusion": "与最先进的（SOTA）Transformer加速器相比，BitStopper在Sanger上实现了2.03倍的加速，在SOFA上实现了1.89倍的加速，同时在能源效率上分别提高了2.4倍和2.1倍。"}
{"llm_update_time": "20251210", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2512.06511", "html_url": "https://arxiv.org/abs/2512.06511", "title": "通过迁移学习进行重症监护病房患者的诊断基础死亡率预测", "title_en": "Diagnosis-based mortality prediction for intensive care unit patients via transfer learning", "authors": "Mengqi Xu,Subha Maity,Joel Dubin", "background": "在重症监护病房（ICU）中，导致危重病的基础原因在不同诊断间差异很大，但考虑到诊断异质性的预测模型尚未系统研究。为填补这一空白，本研究评估了诊断特定死亡率预测的迁移学习方法，并应用了基于广义线性模型（GLM）和XGBoost的模型至eICU协作研究数据库。研究结果表明，迁移学习方法在预测性能上明显优于仅使用诊断特定数据训练的模型以及仅使用知名的重症监护室病情严重程度评分（APACHE IVa）的模型，同时亦比使用混合数据训练的模型在校准上有更好的表现。此外，研究还表明，判断阈值在二分类结果中应采用Youden截断而非传统的0.5阈值，迁移学习在不同阈值标准下都能保持较高的预测性能。", "innovation": "本研究通过评估诊断特定死亡率预测的迁移学习方法，并在eICU协作研究数据库上应用广义线性模型和XGBoost模型，发现了迁移学习方法在预测性能上表现出明显优势。此外，研究还提出Youden截断比传统0.5阈值更适合二分类结果。", "conclusion": "研究结果表明，迁移学习方法在ICU诊断特定死亡率预测上优于单纯使用诊断特定数据或行业标准ICU病情严重性评分的模型，同时保持了较好的校准性能。此外，Youden截断是二分类结果中更合适的决策阈值，迁移学习方法在不同的阈值标准下都能保持良好的预测性能。"}
{"llm_update_time": "20251210", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2512.06533", "html_url": "https://arxiv.org/abs/2512.06533", "title": "超越令牌级监督：通过强化学习解锁解码基础回归的潜力", "title_en": "Beyond Token-level Supervision: Unlocking the Potential of Decoding-based Regression via Reinforcement Learning", "authors": "Ming Chen,Sheng Tang,Rong-Xi Tan,Ziniu Li,Jiacheng Chen,Ke Xue,Chao Qian", "background": "基于解码的回归，将其重新表述为序列生成任务，已经成为使用大型语言模型进行数值预测的一个有前景的范式。然而，其进步受限于令牌级目标（如交叉熵）与连续数值之间的不一致。现有的依赖令牌级约束的方法往往无法捕捉目标值的全局规模，限制了其精度和泛化能力。", "innovation": "本文提出通过强化学习（RL）解锁基于解码的回归的潜力。将生成过程建模为马尔可夫决策过程，利用序列级奖励以确保全局数值一致性。广泛的实验表明，这种方法（特别是使用ReMax和GRPO）在表格回归和代码度量回归中持续优于最先进的令牌级基线和传统回归头，证明了引入序列级信号的优势。", "conclusion": "分析进一步表明，RL显著提高了采样效率和预测精度，确立了解码基础回归作为一种稳健且准确的通用数值预测范式。"}
{"llm_update_time": "20251210", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2512.06370", "html_url": "https://arxiv.org/abs/2512.06370", "title": "优化优化器以加速梯度优化学习", "title_en": "Optimizing Optimizers for Fast Gradient-Based Learning", "authors": "Jaerin Lee,Kyoung Mu Lee", "background": "文章为自动化优化器设计在基于梯度的学习中的自动化提供了理论基础。基于贪婪原则，将优化器设计的问题定义为最大化损失的即时减少。通过将优化器视为将损失梯度信号转换为参数运动的函数，问题被简化为优化器空间上的凸优化问题的家族。在各种约束条件下求解这些问题不仅可以恢复广泛流行的优化器作为闭式解，还可以产生适用于这些问题的最佳超参数。", "innovation": "创新之处在于以贪婪原则为基础，将优化器设计的问题定义为最大化损失的即时减少；将优化器视为从损失梯度信号转换为参数运动的函数，这些问题简化为优化器空间上的凸优化问题的家族；在各种约束条件下求解这些问题不仅能恢复广泛流行的优化器作为闭式解，还能产生适用于这些问题的最佳超参数；提出了一种系统的方法来设计优化器并根据训练过程中收集的梯度统计信息调整其超参数。", "conclusion": "这种优化方法可以在训练过程中动态地进行，以加速基于梯度的学习。"}
{"llm_update_time": "20251210", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2512.06607", "html_url": "https://arxiv.org/abs/2512.06607", "title": "解决LLMs前瞻偏差问题的快速有效方案", "title_en": "A Fast and Effective Solution to the Problem of Look-ahead Bias in LLMs", "authors": "Humzah Merchant,Bradford Levy", "background": "将大规模语言模型（LLMs）应用于金融预测任务具有挑战性，因为它们在长时间序列数据上的训练会导致前瞻偏差。这使得传统的回测方法难以应用，因为要用特定的知识截止点重新训练前沿模型是从头开始训练模型，成本高昂且实际操作困难。", "innovation": "本文提出了一种快速、有效且低成本的方法。该方法在推理时通过一对较小的、专门化的模型调整大型基础模型的logits，一个模型专注于遗忘信息，另一个模型专注于保留信息。通过这种方法，本文展示了能够有效去除具体的、语义性的知识，纠正偏差，并且优于先前的方法。", "conclusion": "我们的方法在去除具体知识和语义信息、纠正偏差等方面表现出色，并在性能上超越了之前的方法。"}
{"llm_update_time": "20251210", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2512.06417", "html_url": "https://arxiv.org/abs/2512.06417", "title": "Hankel-FNO：通过物理编码傅里叶神经算子实现快速水下声学图测绘", "title_en": "Hankel-FNO: Fast Underwater Acoustic Charting Via Physics-Encoded Fourier Neural Operator", "authors": "Yifan Sun(1),Lei Cheng(1),Jianlong Li(1),Peter Gerstoft(2) ((1) College of Information Science and Electronic Engineering, Zhejiang University, Hangzhou, China, (2) Scripps Institution of Oceanography, University of California San Diego, La Jolla, USA)", "background": "水下声学图测绘对于环境感知传感器位置优化和自主车辆路径规划等下游任务至关重要。传统方法依赖于计算成本高但准确的数值求解器，不适用于大规模或实时应用。虽然基于深度学习的近似模型可以加速这些计算，但它们通常存在固定分辨率限制或依赖显式偏微分方程公式，这些问题限制了它们在不同环境中的适用性和泛化能力。", "innovation": "提出了Hankel-FNO，一种基于傅里叶神经算子（FNO）的模型，用于高效和准确的声学图测绘。通过集成声波传播知识和水深信息，该方法确保高准确度的同时保持高计算速度。结果表明，Hankel-FNO 在速度上超越了传统求解器，并且在精度上超越了数据驱动的其他方法，尤其在远距离预测方面。", "conclusion": "实验表明，模型具有在多种环境和声源配置下进行最小微调的适应性。"}
{"llm_update_time": "20251210", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2512.06520", "html_url": "https://arxiv.org/abs/2512.06520", "title": "分层几何深度学习使得大规模分子动力学分析变得可行", "title_en": "Hierarchical geometric deep learning enables scalable analysis of molecular dynamics", "authors": "Zihan Pengmei,Spencer C. Guo,Chatipat Lorpaiboon,Aaron R. Dinner", "background": "分子动力学模拟可以生成复杂的苍原子级详细的轨迹，但当系统缺乏公认的定量描述符时，分析这些动态就变得具有挑战性。图形神经网络（GNN）可以通过在表示空间邻域原子的节点之间传递消息来避免手动特征工程，但在分析更大规模的生物分子系统（超过几百个残基）的动态时，GNN的应用受到了长程相互作用捕获不足以及内存和运行时需求过大等挑战。", "innovation": "本文展示了如何通过聚合局部信息来减少内存和运行时的需求，而不牺牲原子详尽度。这种手段使人们可以在单个GPU上以几分钟的时间段来分析拥有数千个残基的蛋白质-核酸复合物的大规模分子动力学模拟。对于拥有数百个残基的系统，可以通过足够的数据来进行定量比较，本文表明这种方法提高了性能和可解释性。", "conclusion": "分层几何深度学习为大规模分子动力学分析提供了可能，尤其是在分析由数千个残基组成的蛋白质-核酸复合物时，可以在单个GPU上以几分钟的时间完成。"}
{"llm_update_time": "20251210", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2512.06427", "html_url": "https://arxiv.org/abs/2512.06427", "title": "控制正弦神经网络中梯度的新初始策略", "title_en": "A new initialisation to Control Gradients in Sinusoidal Neural network", "authors": "Andrea Combette,Antoine Venaille,Nelly Pustelnik", "background": "适当的初始化策略对于缓解在训练神经网络时出现的梯度爆炸或消失至关重要。然而，对于一些已经确立的架构，初始参数的影响缺乏精确的理论理解。特别是针对具有正弦激活函数的网络，如SIREN，其梯度控制、随网络深度的缩放、对训练与泛化的具体影响仍未有清晰的认识。", "innovation": "本文提出了一种针对拥有正弦激活函数网络的新初始化策略，该策略侧重于控制梯度、梯度随网络深度的缩放、对训练和泛化的影响。通过固定点获得的前激活分布的收敛性及雅可比序列的方差，推导出一个新的闭式解表达式，与原始的SIREN方案不同。这一新方法通过控制梯度来防止估计过程中的不适当频率，从而提高泛化能力。此外，还通过神经核函数框架展示了这一初始化对训练动态的直接影响，最终在函数拟合和图像重建任务中与原始SIREN及其它基线方法进行对比验证。", "conclusion": "所提出的初始化方法在广泛的重建任务中，包括那些涉及物理信息神经网络的任务中，比最先进的方法具有更优的表现。"}
{"llm_update_time": "20251210", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2512.06630", "html_url": "https://arxiv.org/abs/2512.06630", "title": "量子时序卷积神经网络在跨截面股票回报预测中的应用：一项比较基准研究", "title_en": "Quantum Temporal Convolutional Neural Networks for Cross-Sectional Equity Return Prediction: A Comparative Benchmark Study", "authors": "Chi-Sheng Chen,Xinyu Zhang,Rong Fu,Qiuzhe Xie,Fan Zhang", "background": "量子机器学习为增强股票市场预测提供了有前途的途径，特别是在复杂、嘈杂和高度动态的金融环境中。然而，许多经典预测模型难以处理嘈杂的输入、结构转换和有限的泛化能力。", "innovation": "本文提出了一个量子时序卷积神经网络（QTCNN），它结合了经典的时序编码器和参数高效的量子卷积电路，用于跨截面股票回报预测。QTCNN利用量子处理中的叠加和纠缠来增强特征表示并抑制过拟合，同时从序列技术指标中提取多尺度模式。", "conclusion": "QTCNN在JPX东京证券交易所数据集上的基准测试研究中达到了0.538的夏普比率，约72%的性能优于最佳经典基线。这些结果突显了量子增强预测模型QTCNN在量化金融稳健决策中的实用潜力。"}
{"llm_update_time": "20251210", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2512.06592", "html_url": "https://arxiv.org/abs/2512.06592", "title": "关于对Boltz-2进行微调以预测蛋白质-蛋白质亲和力", "title_en": "On fine-tuning Boltz-2 for protein-protein affinity prediction", "authors": "James King,Lewis Cornwall,Andrei Cristian Nica,James Day,Aaron Sim,Neil Dalchau,Lilly Wollman,Joshua Meyers", "background": "蛋白质-蛋白质结合亲和力的准确预测对于理解分子相互作用和设计治疗方案至关重要。尽管Boltz-2是一种基于结构的蛋白质-配体亲和力预测器，在结构精度方面表现出色，但在蛋白质-蛋白质亲和力预测方面，它在小型和大型数据集上的表现均不如基于序列的方法。", "innovation": "研究人员将Boltz-2适应用于蛋白质-蛋白质亲和力回归，并在TCR3d和PPB-亲和力两个数据集上进行了评估。他们通过将Boltz-2-PPI的嵌入与基于序列的嵌入结合，以提高基于序列的较弱模型的性能，并发现序列和结构模型学习不同的信号。", "conclusion": "研究结果指出训练使用结构数据的偏见，并暗示当前的结构表示可能无法实现高性能的亲和力预测。因此，可能需要改进结构表示以更好地适应亲和力预测的任务。"}
{"llm_update_time": "20251210", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2512.06648", "html_url": "https://arxiv.org/abs/2512.06648", "title": "基于卷积神经网络的上市公司财务欺诈识别及解释性研究", "title_en": "Financial Fraud Identification and Interpretability Study for Listed Companies Based on Convolutional Neural Network", "authors": "Xiao Li", "background": "自股份有限公司成立以来，上市公司的财务欺诈行为屡次损害资本市场。欺诈难以被发现，因为欺诈者使用隐蔽手段并且审计工作耗费大量人力和时间。传统统计模型虽然具有可解释性，但在处理非线性特征交互时能力有限，而机器学习模型虽然强大但在透明度方面存在不足。此外，大部分现有方法仅以当前年份的数据判断当年的欺诈情况，这限制了预警的及时性。", "innovation": "本文提出了一种基于卷积神经网络（CNN）的中国A股上市公司财务欺诈检测框架。文章设计了一种特征工程方案，将公司-年度面板数据转换成图像表示，使得CNN能够捕捉横截面和时间序列模式，并且在预测欺诈行为方面具有前瞻性。实验证明，模型在准确率、稳健性和预警效果方面优于逻辑回归和LightGBM，重要的是，在高风险条件下适当调整分类阈值至关重要。为了提高解释性，本文使用局部解释方法从实体、特征和时间三个维度分析模型，发现偿债能力、比率结构、公司治理结构和内部控制是对欺诈的普遍预测因素。而在高污染行业中，环境指标则主要起作用。非欺诈公司具有稳定的特征模式，而欺诈公司则表现出异质且集中在短时间段的模式。案例研究表明，现金流量分析、社会责任、公司治理结构和每股市价是模型欺诈预测的主要驱动因素，与该公司已记录的不当行为一致。", "conclusion": "研究结果表明，基于CNN的财务欺诈检测框架能够有效地识别和预警欺诈行为，且具有良好的准确性和解释性。未来工作可以进一步探索如何优化特征工程和模型参数设置，以进一步提高模型的性能和解释性。"}
{"llm_update_time": "20251210", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2512.06563", "html_url": "https://arxiv.org/abs/2512.06563", "title": "深度流形第二部分：神经网络数学", "title_en": "Deep Manifold Part 2: Neural Network Mathematics", "authors": "Max Y. Ma,Gen-Hua Shi", "background": "本文通过堆叠分段流形、不动点理论以及边界条件迭代，发展了神经网络的全球方程。实际数据具有强烈的数据复杂性、近乎无限的范围、大小和小批量碎片化，而训练动态则通过节点覆盖的变化、曲率的积累以及塑性的兴起和衰减产生学习复杂性。这些力量限制了可学习性，解释了只有当不动点区域稳定时，能力才会出现。神经网络并没有天然的固定点，而是通过残差驱动的迭代构建它们。", "innovation": "通过将神经网络视为由流形复杂性、高阶非线性和边界条件塑造的可学习数值计算，以及解释了为什么只有当不动点区域稳定时能力才会出现。神经网络并非从固定的点开始，而是通过残差驱动的迭代构建它们。", "conclusion": "这种视角澄清了在几何和数据驱动的可塑性下单一模型的局限性，并促使架构和联邦系统将流形复杂性分布在许多可扩展的模型中，形成一个以几何、代数、不动点和实际数据复杂性为基础的世界建模框架。"}
{"llm_update_time": "20251210", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2512.06609", "html_url": "https://arxiv.org/abs/2512.06609", "title": "使用高斯变分自编码器的向量量化", "title_en": "Vector Quantization using Gaussian Variational Autoencoder", "authors": "Tongda Xu,Wendi Zheng,Jiajun He,Jose Miguel Hernandez-Lobato,Yan Wang,Ya-Qin Zhang,Jie Tang", "background": "Vector Quantized Variational Autoencoder (VQ-VAE) 是一种离散自编码器，能够将图像压缩成离散的标记。但是由于离散化带来的困难，其训练较为复杂。", "innovation": "本文提出了一种简单且有效的技术，称为高斯量化（Gaussian Quant, GQ）。GQ 技术通过将具有特定约束条件的高斯 VAE 转换为无需训练的 VQ-VAE。具体来说，GQ 会生成随机的高斯噪声作为代码表，并找到与后验均值最近的噪声。理论上，文章证明了当代码表大小的对数超过高斯 VAE 的位回编码率时，可以保证很小的量化误差。此外，技术还提出了一种名为目标发散约束（Target Divergence Constraint, TDC）的启发式方法，用于对高斯 VAE 的有效训练。", "conclusion": "实验表明，GQ 在 UNet 和 ViT 架构上优于之前的 VQ-VAE 方法，如 VQGAN、FSQ、LFQ 和 BSQ。同时，TDC 也改进了之前的高斯 VAE 离散化方法，如 TokenBridge。"}
{"llm_update_time": "20251210", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2512.06649", "html_url": "https://arxiv.org/abs/2512.06649", "title": "使用基于视觉的机器学习估计城市交通中的黑碳浓度", "title_en": "Estimating Black Carbon Concentration from Urban Traffic Using Vision-Based Machine Learning", "authors": "Camellia Zakaria,Aryan Sadeghi,Weaam Jaafar,Junshi Xu,Alex Mariakakis,Marianne Hatzopoulou", "background": "城市区域的黑碳（BC）排放主要由交通活动驱动，尤其是靠近主要道路的热点区域对边缘社区的影响更大。由于黑碳监测通常需要昂贵的专业设备，导致很难获得来自当地交通来源的BC数据，而这些数据对于制定针对地方因素的政策措施至关重要。相比之下，全球城市普遍部署了交通监控系统，这表明对于交通状况我们了解许多，但对其环境影响我们知之甚少。为了解决这一问题，本文提出了一种基于机器学习的系统，通过从交通视频中提取视觉信息来捕捉车辆行为和状态。结合天气数据，该模型在街面层面估计BC，R²值为0.72，RMSE为129.42 ng/m³。", "innovation": "本文提出了一种基于机器学习的系统，通过从交通视频中提取视觉信息来估计街面层面的黑碳浓度，这是通过对现有交通监控系统的视觉信息利用和机器学习技术的结合实现的，弥补了现有黑碳监测数据缺乏的问题。", "conclusion": "该研究通过利用城市基础设施已有的资源和成熟的建模方法，生成与交通排放相关的信息，提供了可操作的见解，支持污染减少、城市规划、公共卫生和环境正义等在地方市政层面的应用。"}
{"llm_update_time": "20251210", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2512.06582", "html_url": "https://arxiv.org/abs/2512.06582", "title": "量子跃迁LSTM：一种参数高效的稳定长序列建模LSTM", "title_en": "QL-LSTM: A Parameter-Efficient LSTM for Stable Long-Sequence Modeling", "authors": "Isaac Kofi Nti", "background": "LSTM和GRU等循环神经网络架构在序列建模中仍被广泛使用，但它们面临着两个核心局限：冗余的门特定参数和保持长时间距离信息的能力降低。", "innovation": "该论文引入了Quantum-Leap LSTM（QL-LSTM），这是一种通过两个独立组件设计以解决上述挑战的循环架构。QL-LSTM 通过Parameter-Shared Unified Gating机制用单个共享权重矩阵代替所有门特定变换，减少了大约48%的参数同时保持完整的门行为。另一种名为Hierarchical Gated Recurrence with Additive Skip Connections的组件增加了无需乘法的路径，改善了长时间信息流并减少了忘门退化。", "conclusion": "在使用IMDB数据集及相关扩展文档进行情感分类的评估中，QL-LSTM在使用更少参数的情况下达到了竞争力的准确性。尽管PSUG和HGR-ASC组件在每时间步方面更有效，但当前原型仍受限于循环模型的固有顺序特性，因此在未经进一步内核级优化的情况下并未提供墙钟时间速度改进。"}
{"llm_update_time": "20251210", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2512.06547", "html_url": "https://arxiv.org/abs/2512.06547", "title": "A-3PO: 加速异步大语言模型训练的新鲜度感知近似信任区域策略优化", "title_en": "A-3PO: Accelerating Asynchronous LLM Training with Staleness-aware Proximal Policy Approximation", "authors": "Xiaocan Li,Shiliang Wu,Zheng Shen", "background": "去耦损失(decoupled loss)是处理异步强化学习(Asynchronous RL)设置下高数据陈旧性问题的一种成功的算法。去耦损失通过引入一个近似策略来分离经验权重和控制策略更新，从而提高了耦合损失算法(例如PPO、GRPO)的学习稳定性。然而，这种近似策略需要在每个训练步骤中额外进行一次网络前向传递，这成为大规模语言模型训练的计算瓶颈。", "innovation": "本文提出了一种名为A-3PO（APproximated Proximal Policy Optimization）的方法。A-3PO通过简单的插值近似代替近似策略，无需明确计算就能实现近似目标，从而消除了额外的前向传递计算，显著减少了训练时间，并保持了与先前模型相当的表现。", "conclusion": "A-3PO方法通过引入简单的插值近似来代替近似策略，消除了计算瓶颈，在保持性能的同时减少了18%的训练时间。该方法已在网站 <this https URL> 上提供了代码和现成示例。"}
{"llm_update_time": "20251210", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2512.06678", "html_url": "https://arxiv.org/abs/2512.06678", "title": "GradientSpace: 未监督的数据聚类以改进指令微调", "title_en": "GradientSpace: Unsupervised Data Clustering for Improved Instruction Tuning", "authors": "Shrihari Sridharan,Deepak Ravikumar,Anand Raghunathan,Kaushik Roy", "background": "大型语言模型（LLM）需要适应各种下游应用，而指令微调是该过程中的一个重要步骤。然而，这一过程面临挑战，因为实际数据集通常不是同质的，包含了有冲突的信息，导致梯度干扰。常见的处理方法是基于语义或嵌入相似性对数据进行分组，但这种方法未能捕捉到数据如何影响模型参数的学习过程。之前的研究尝试直接聚类梯度，但由于需要降低维度来管理存储，这种方法导致了准确性的损失，而这些方法还需依赖专家集合进行推理，这增加了推理过程的复杂性和成本。", "innovation": "我们提出了GradientSpace框架，这一框架直接在全维梯度空间中聚类样本。我们引入了一种基于在线SVD的算法，该算法可以处理LoRA梯度，无需存储所有样本梯度便能识别潜在技能。框架中，每个聚类将用于训练一个专门的LoRA专家，同时训练一个轻量级路由器用于推理时选择最佳专家。实验结果表明，与之前的工作使用专家集合相比，指向单一合适的专家的方法表现出更好的性能，同时显著减少了推理延迟。我们在数学推理、代码生成、金融和创造性写作任务上的实验表明，GradientSpace能够实现专家的专业化和一致性性能提升。", "conclusion": "我们的实验验证了GradientSpace的有效性，它在数学推理、代码生成、金融以及创造性写作等任务中均表现出了比现有集群方法和微调技术更好的专家专业化和一致性性能提升。GradientSpace实现了在全维梯度空间中直接聚类样本，无需存储所有样本梯度即可识别潜在技能，从而提高了推理效率并增强了模型性能。"}
{"llm_update_time": "20251210", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2512.06638", "html_url": "https://arxiv.org/abs/2512.06638", "title": "数据特性对检测假新闻的图神经网络评估的影响", "title_en": "The Impact of Data Characteristics on GNN Evaluation for Detecting Fake News", "authors": "Isha Karn,David Jensen", "background": "论文背景介绍，图神经网络（GNN）因能对社交媒体上文章内容及其传播结构进行建模，在假新闻检测中广泛应用。然而，GossipCop和PolitiFact等常用的基准数据集因其表浅的、以自我为中心的图结构（ego-like graph topologies），难以有效评估利用传播结构的模型的实际效用。", "innovation": "研究采用系统性方法，对比了五种GNN架构与结构无感知的多层感知机（MLP），结果发现MLP与GNN的性能差距通常在1-2%以内且信心区间重叠，表明结构贡献度可能并不显著。进一步通过控制实验，发现网络特征打乱时性能急剧下降，而随机化边结构影响不大，揭示结构不具备显著差异。", "conclusion": "结论指出，当前广泛使用的基准数据集在有效测试建模结构特征的实用性方面存在缺陷，并指出需要开发具有更丰富、多样化图结构的数据集，以有效评估GNN在假新闻检测中的结构建模效用。"}
{"llm_update_time": "20251210", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2512.06652", "html_url": "https://arxiv.org/abs/2512.06652", "title": "多中心队列中预测需要侵入性机械通气的自适应测试时训练", "title_en": "Adaptive Test-Time Training for Predicting Need for Invasive Mechanical Ventilation in Multi-Center Cohorts", "authors": "Xiaolei Lu,Shamim Nemati", "background": "在重症监护病房（ICU）中，准确预测患者是否需要侵入性机械通气（IMV）对于及时干预和资源分配至关重要。但由于不同医疗机构之间的患者群体、临床实践和电子健康记录（EHR）系统的差异性，部署时的预测模型泛化性能会下降。测试时训练（TTT）是一种有前景的缓解这种差异的方法，在推理过程中动态调整模型而无需标记目标领域数据。", "innovation": "本研究引入了自适应测试时训练（AdaTTT），一种专门为ICU环境中的EHR基于的IMV预测定制的增强TTT框架。通过信息论界定了测试时预测误差，并表明此误差受到主任务和辅助任务之间不确定性的影响。为增强两者的对齐，提出了一个自我监督学习框架，通过动态遮罩策略优化重建和屏蔽特征建模，聚焦于对主任务至关重要的特征。此外，通过引入原型学习并使用部分最优传输（POT）进行灵活的部分特征对齐，以提高模型在面对领域差异时的鲁棒性。", "conclusion": "实验结果表明，该多中心ICU队列分类性能在不同的测试时适应基准中表现出竞争性。"}
{"llm_update_time": "20251210", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2512.06665", "html_url": "https://arxiv.org/abs/2512.06665", "title": "重新思考鲁棒性：一种评估特征归因方法的新方法", "title_en": "Rethinking Robustness: A New Approach to Evaluating Feature Attribution Methods", "authors": "Panagiota Kiourti,Anu Singh,Preeti Duraipandian,Weichao Zhou,Wenchao Li", "background": "该论文研究了深度神经网络中特征归因方法的稳健性。当前对归因稳健性的认知主要忽略了模型输出之间的差异，因此提出了一个新的评估归因方法稳健性的框架。这包括提出了一种新的输入相似性定义，新的稳健性度量标准和一种基于生成对抗网络的新方法来生成这些输入。", "innovation": "论文创新点在于提出了一个新的输入相似性定义，新的稳健性度量标准，并使用生成对抗网络生成这些输入。此外，还使用现有的度量标准和最先进的归因方法进行了全面评估。这些发现强调了需要一个更客观的度量标准来揭示归因方法的弱点，而不是神经网络，从而提供更准确的归因方法稳健性评估。", "conclusion": "研究发现现有的度量标准并不能全面评估归因方法的稳健性，提出了一种新方法来更准确地评估归因方法的稳健性。这种方法强调了需要客观的研究方法来揭示归因方法的本质弱点。"}
{"llm_update_time": "20251210", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2512.06714", "html_url": "https://arxiv.org/abs/2512.06714", "title": "一种用于实时水需求预测的新颖深度神经网络架构", "title_en": "A Novel Deep Neural Network Architecture for Real-Time Water Demand Forecasting", "authors": "Tony Salloom,Okyay Kaynak,Wei He", "background": "短期水需求预测（StWDF）是水供给系统控制的优化计划的基础。深度学习（DL）方法为这一目的提供了最准确的解决方案。然而，这些方法因参数量巨大而复杂，并且在极端点处具有较高的预测误差。", "innovation": "该研究提出了一种有效地缓解极端点预测误差的方法，通过在实际数据中插入虚拟数据来缓解它们周围的非线性。这是首次考虑极端点问题的工作。该研究提出了一个新颖的具有较低复杂度的DL模型，其中基本模型使用门控循环单元（GRU）处理历史需求数据中的序列关系，引入了无监督分类方法K-means来创建增强预测准确性的新特征。该方法将模型复杂度降低了六倍，同时保持相同准确性，数据集扩展可显著降低误差约30%。", "conclusion": "提出的预测结果和与最新技术的比较显示，该方法在保持相同准确性的同时，将模型复杂度降低了六倍。此外，数据集扩展可显著降低误差约30%。"}
{"llm_update_time": "20251210", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2512.06695", "html_url": "https://arxiv.org/abs/2512.06695", "title": "缓解量子去噪扩散概率模型中的 barren plateaus", "title_en": "Mitigating Barren plateaus in quantum denoising diffusion probabilistic models", "authors": "Haipeng Cao,Kaining Zhang,Dacheng Tao,Zhaofeng Su", "background": "量子生成模型利用量子叠加和纠缠来增强经典和量子数据的学习效率。其中，量子去噪扩散概率模型（QuDDPM）受到了其经典对应模型的启发，在量子生成学习方面展现了潜力。然而，研究表明，在使用 2-设计态作为去噪过程的输入时，QuDDPM 中出现了 barren plateaus，严重影响了模型的性能。", "innovation": "通过理论分析和实验验证，确认了原始 QuDDPM 中存在 barren plateaus。为解决这一问题，引入了一种改进的 QuDDPM，该模型使用一个与haar分布保持一定距离的分布作为输入，以确保更好的可训练性。实验结果表明，该方法有效地缓解了 barren plateaus 问题，并生成了更高质量的样本，为可扩展且高效的量子生成学习铺平了道路。", "conclusion": "通过改进 QuDDPM 的输入分布，有效缓解了 barren plateaus 问题，提升了模型在生成量子数据方面的性能，并为量子生成学习的可扩展性和高效性提供了新的方法。"}
{"llm_update_time": "20251210", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2512.06702", "html_url": "https://arxiv.org/abs/2512.06702", "title": "在Wasserstein度量下流基生成模型的O(√d)复杂度边界之路", "title_en": "Pathway to $O(\\sqrt{d})$ Complexity bound under Wasserstein metric of flow-based models", "authors": "Xiangjun Meng,Zhongjian Wang", "background": "本文提供了用于估算基于流的生成模型在Wasserstein度量下的误差的实用分析工具，并建立了与维度相关的最优采样迭代复杂度界，该边界为O(√d)。此模型的误差可以通过两部分独立于维度地加以控制：后向流的推进映射的Lipschitz性质；以及局部离散误差，其维度上的尺度为O(√d)。这些假设在与Föllmer过程及1-修正流相关的高斯尾部假设下在流基生成模型中适用。", "innovation": "本文通过将误差分解为两部分独立于维度的组成部分，提供了关于基于流的生成模型在Wasserstein度量下误差估计的工具，并且得出了采样迭代复杂度与协方差算子迹的平方根线性关系的结果。这一发现有助于更好地理解流基模型在高维数据生成中的性能。", "conclusion": "本文分析表明，在基于流的生成模型中，采样迭代的复杂度随着协方差算子迹的平方根线性增长，这一结果在Wasserstein度量下给出了更精确的理解。同时，结果还表明，误差可以通过模型中的Lipschitz变化以及得分函数的时空正则性来控制。"}
{"llm_update_time": "20251210", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2512.06708", "html_url": "https://arxiv.org/abs/2512.06708", "title": "一种具有层级解释的新型多模态剩余使用寿命估计框架", "title_en": "A Novel Multimodal RUL Framework for Remaining Useful Life Estimation with Layer-wise Explanations", "authors": "Waleed Razzaq,Yun-Bo Zhao", "background": "机械系统的剩余使用寿命（RUL）估计在预测维护与健康管理（PHM）中至关重要。滚动轴承是引起机械故障的最常见原因之一，因此需要更稳健的RUL估计方法。现有的方法通常存在泛化能力差、鲁棒性不足、数据需求高、解释性差等问题。", "innovation": "本文提出了一种新颖的多模态RUL框架，共同利用多通道、非平稳振动信号的图像表示（ImR）和时频表示（TFR）。该架构由三个分支组成：（1）ImR分支和（2）TFR分支，这两个分支都使用多个扩张卷积块和残差连接来提取空间退化特征；（3）融合分支，将这些特征相连接并通过LSTM建模时间退化模式。后续引入了多头注意力机制来强调重要特征，并通过线性层进行最终的RUL回归。为了实现有效的多模态学习，振动信号通过布塞兰姆线算法转换为图像表示（ImR），并通过连续波变换转换为时频表示（TFR）。引入了多模态的层级相关性传播（multimodal-LRP），这是一种专门的解释性技术，显著提高了模型的透明度。", "conclusion": "该方法在XJTU-SY和PRONOSTIA基准数据集上进行了验证，结果表明，在熟悉的和未知的操作条件下，我们的方法能够达到或超过最先进的基线，同时需要的训练数据分别减少了约28%和48%。该模型表现出强大的抗噪声性能，而multimodal-LRP可视化结果证实了预测的可解释性和可信度，使该框架非常适合在工业中实际部署。"}
{"llm_update_time": "20251210", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2512.06692", "html_url": "https://arxiv.org/abs/2512.06692", "title": "State Diversity Matters in Offline Behavior Distillation", "title_en": "State Diversity Matters in Offline Behavior Distillation", "authors": "Shiye Lei,Zhihao Cheng,Dacheng Tao", "background": "Offline Behavior Distillation (OBD) 是一个将大量离线强化学习数据浓缩为紧凑的合成行为数据集的方法，这种技术能够有效地用于政策训练，并且可以应用于各种下游强化学习任务。然而，研究发现原始数据集和合成数据集之间可能存在不一致性。高质量的原始数据集并不一定会产出更优质的合成数据集。", "innovation": "本文提出了一种新的简单算法，即基于状态密度加权（State Density Weighted, SDW）的OBD方法。通过权重使用状态密度的倒数来强化状态多样性，从而进一步浓缩更多元的状态信息到合成数据中。实验结果显示，当原始数据集具有有限的状态多样性时，SDW方法可以显著提升OBD的表现。", "conclusion": "本文通过经验分析发现，在OBD过程中状态多样性比状态质量在较大损失条件下对政策性能的影响更大。基于此，论文介绍了一种新的、简单的算法（SDW OBD），该算法通过状态密度加权方法来强化状态多样性，实验表明该方法能够有效提升OBD性能。"}
{"llm_update_time": "20251210", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2512.06725", "html_url": "https://arxiv.org/abs/2512.06725", "title": "使用深度学习和回声状态网络解码运动行为", "title_en": "Decoding Motor Behavior Using Deep Learning and Reservoir Computing", "authors": "Tian Lan", "background": "传统的卷积架构，如EEGNet和DeepConvNet，在捕捉局部空间模式方面效果显著，但在建模长时间范围的时间依赖性和非线性动力学方面表现较差。鉴于此，研究者将回声状态网络（ESN）这一经典回声计算中的范式整合到解码管道中，以克服这一局限。", "innovation": "提出了一种新的EEG解码方法，通过将回声状态网络（ESN）与传统的卷积神经网络（CNN）结合，专注于运动行为分类。方法强调在解码管道中嵌入ESN，以提高对时间动态的跟踪能力，从而弥补CNN在空间表示方面的不足。", "conclusion": "在使用PREP管道预处理的滑板特技EEG数据集上，采用MNE-Python实现的ESNNet达到了83.2%的被试内准确率和51.3%的LOSO准确率，优于广泛使用的基于CNN的基本模型。相关代码在提供的链接中可获取。"}
{"llm_update_time": "20251210", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2512.06737", "html_url": "https://arxiv.org/abs/2512.06737", "title": "ArcGradient Descent: 一种基于相位感知和用户可控步进动态的梯度下降数学推导重构", "title_en": "Arc Gradient Descent: A Mathematically Derived Reformulation of Gradient Descent with Phase-Aware, User-Controlled Step Dynamics", "authors": "Nikhil Verma,Joonas Linnosmaa,Espinosa-Leal Leonardo,Napat Vajragupta", "background": "论文介绍了一个新的优化器ArcGD的构造、实现和评估。ArcGD最初在非凸基准函数上进行评估，随后应用于真实的机器学习数据集。使用Adam优化器作为基准，研究ArcGD的表现。", "innovation": "ArcGD是一个由数学推导得出的梯度下降优化器的重构，具有相位感知和用户可控步进动态。ArcGD在非凸Rosenbrock函数和CIFAR-10图像分类数据集上的测试中表现优于Adam、AdamW、Lion和SGD。特别是在CIFAR-10数据集上，ArcGD在多种深度神经网络架构中展现出更高的测试准确性，证明了其广泛的适用性。", "conclusion": "ArcGD在几何压力测试和标准深度学习基准测试中表现出强大性能，表明其具有广泛的应用潜力。此外，论文还指出，ArcGD可以被视为Lion优化器的一个特殊案例，突出此类优化方法的内在机制相互联系。"}
{"llm_update_time": "20251210", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2512.06730", "html_url": "https://arxiv.org/abs/2512.06730", "title": "通过CNN-BiLSTM和EEG数据的SHAP分析增强AR-SSVEP基线运动意图识别的可解释性", "title_en": "Enhancing Interpretability of AR-SSVEP-Based Motor Intention Recognition via CNN-BiLSTM and SHAP Analysis on EEG Data", "authors": "Lin Yang,Xiang Li,Xin Ma,Xinxin Zhao", "background": "患者存在运动功能障碍时，主观参与康复训练积极性低。传统基于静息状态视觉诱发电位（SSVEP）的脑-机接口（BCI）系统依赖于外部视觉刺激设备，这限制了其在实际场景中的应用。因此，本研究提出一种增强现实（Augmented Reality，简称AR）辅助的SSVEP系统（AR-SSVEP），以解决患者主动性不足和治疗师工作负担大的问题。", "innovation": "1. 设计四种基于HoloLens 2的EEG分类器，并从七名健康受试者中收集EEG数据进行分析。\n2. 在传统的CNN-BiLSTM架构中，集成多头注意力机制（MA-CNN-BiLSTM），提取十个时频特征，并引入一个CNN来学习高级表示。\n3. 使用双向长短期记忆（BiLSTM）模型捕捉序列依赖关系，并通过多头注意力机制突出显示与运动意图相关的模式。\n4. 应用SHAP（SHapley Additive exPlanations）方法可视化EEG特征对神经网络决策过程的贡献，从而增强模型的可解释性。", "conclusion": "这些发现能够实现对实时运动意图的识别，并为运动功能障碍患者的支持康复提供帮助。"}
{"llm_update_time": "20251210", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2512.06666", "html_url": "https://arxiv.org/abs/2512.06666", "title": "元学习差距：结合Hydra和Quant进行大规模时间序列分类", "title_en": "The Meta-Learning Gap: Combining Hydra and Quant for Large-Scale Time Series Classification", "authors": "Urav Maniar", "background": "时间序列分类在准确性和计算效率之间存在根本性的权衡。虽然HIVE-COTE 2.0之类的全面集成方法可以达到最先进的准确度，但由于其在UCR基准上的340小时训练时间，对于大规模数据集来说是不可行的。研究关注是否可以通过从互补范式中选择两种高效的算法进行有针对性的结合，既保留集成方法的好处，又能够维持计算可行性。", "innovation": "研究结合了Hydra（竞争卷积核）和Quant（分层区间量化）两种算法，并在六个集成配置中进行了评估，结果用于10个大规模MONSTER数据集（7,898至1,168,774个训练实例）。最强的配置将平均准确度提高了0.007%，在7个数据集上成功，但仍显示出元学习优化存在较大差距，即捕获的理论优化潜力仅占11%。研究发现，通过特征拼接方法可以超过理论界限，而预测级互补性则与集成效果有一定的关联性。", "conclusion": "研究指出，时间序列分类的核心挑战已经从确保算法的独特性转移到了如何有效地结合这些算法上。当前的元学习方法难以充分利用确认存在的互补性，改进的结合策略或能潜在地提高集成效果达到两倍或三倍。"}
{"llm_update_time": "20251210", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2512.06785", "html_url": "https://arxiv.org/abs/2512.06785", "title": "超球面上的正未标注学习的余角正则化", "title_en": "Angular Regularization for Positive-Unlabeled Learning on the Hypersphere", "authors": "Vasileios Sevetlidis,George Pavlidis,Antonios Gasteratos", "background": "PU学习解决的是只有部分正样本被标记并且剩余数据未标记的分类问题，其中显式的负样本监督不存在。现有的PU方法通常依赖于负风险估计或伪标签，这些方法要么需要很强的分布假设，要么在高维情况下容易失效。", "innovation": "提出了一种新颖的PU框架AngularPU，它在超球面上使用余弦相似性和角度间隔运作。在该框架中，正类由一个可学习的原型向量表示，分类转化为嵌入与该原型之间的余弦相似性的阈值化，从而消除对显式负样本建模的需求。为了防止未标记的嵌入数据聚集在正原型附近，引入了一个余角正则化器，鼓励未标记集在整个超球面上分散分布，提高分类性能。", "conclusion": "通过理论保证余角决策规则的贝叶斯最优性、所学原型的一致性和规则对未标记分布的影响，实验结果表明AngularPU在基准数据集上达到了与最先进的PU方法相当或更优的性能，特别是在正样本稀缺和高维嵌入的情况下，且具有几何解释性和可扩展性。"}
{"llm_update_time": "20251210", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2512.06758", "html_url": "https://arxiv.org/abs/2512.06758", "title": "关于具有序列独裁者分配的匹配市场中多水平连续选择算法的最优分析", "title_en": "Optimal Analysis for Bandit Learning in Matching Markets with Serial Dictatorship", "authors": "Zilong Wang,Shuai Li", "background": "双边匹配市场领域在计算机科学和经济学中得到了广泛研究，因为其在许多领域的广泛应用。由于市场参与者在其在线匹配平台中的偏好通常具有不确定性，研究者们开始关注在线设置，在这种设置中，一方参与者（玩家）在其与另一方（臂）的多次互动中学习其未知偏好。在序列独裁者假设下，Sankararaman等人提供了下界 ${\rm \text{Ω}}\big( \frac{N\text{log}(T)}{\text{Δ}^2} + \frac{K\text{log}(T)}{\text{Δ}} \big)$，其中 $N$ 是玩家的数量，$K (\text{≥} N)$ 是臂的数量，$\text{Δ}$ 是玩家和臂之间最小的奖励差距，$T$ 是时间框架。最近，Kong 和 Li 提出了 ET-GS 算法，并取得了上界 $O\big( \frac{K\text{log}(T)}{\text{Δ}^2} \big)$ 的结果，该结果目前是最佳上界。尽管如此，在下界和上界之间仍然存在差距，从 $N$ 到 $K$ 不等，这表明需要改善两者之一。", "innovation": "本文提出了一种多级连续选择算法，在市场满足序列独裁者假设的条件下，获得了 ${\rm O}\big( \frac{N\text{log}(T)}{\text{Δ}^2} + \frac{K\text{log}(T)}{\text{Δ}} \big)$ 的懊悔界。据我们所知，这是一次提出与该问题下界匹配算法的首次尝试。", "conclusion": "该研究提出了一个可以匹配序列独裁者假设下匹配市场中多臂问题的下界的算法，这一成果缩小了上界与下界之间已存在的差距。"}
{"llm_update_time": "20251210", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2512.06791", "html_url": "https://arxiv.org/abs/2512.06791", "title": "Small-Gain Nash: Certified Contraction to Nash Equilibria in Differentiable Games", "title_en": "Small-Gain Nash: Certified Contraction to Nash Equilibria in Differentiable Games", "authors": "Vedansh Sharma", "background": "传统的梯度基础学习在博弈游戏中的收敛保证需要伪梯度在欧几里得几何中表现出强单调性。在简单的游戏中，如果存在强烈的玩家间耦合，这种条件往往无法满足。", "innovation": "引入了一种名为Small-Gain Nash (SGN) 的块小增益条件，该条件用自定义的块加权几何度量来平滑地将局部曲率和玩家间Lipschitz耦合限制转化为收敛性证书。SGN能够在确保伪梯度虽然在欧几里得几何中不单调，但在这些限制适用的任何区域内成为强单调性的几何度量。此外，证明了连续流动在该设计度量几何中是指数收缩的，投影Euler和RK4离散化在显式步长限制下收敛。SGN揭示了一个认证的时间尺度带，提供了一个非渐近的、基于度量的证书，充当类似于TTUR的角色。", "conclusion": "该研究验证了在欧几里得单调性分析无法预测收敛性的二次博弈中，SGN成功验证了收敛性，并将其扩展到镜像/费舍尔几何中以证明马克夫博弈中熵正则化策略梯度的收敛性。最后，提供了一个离线认证管道，用于在紧凑区域估计曲率、耦合和Lipschitz参数，优化块权重以扩大SGN边缘，并返回一个结构可计算的收敛证书，包括度量、收缩率和非单调博弈的安全步长。"}
{"llm_update_time": "20251210", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2512.06837", "html_url": "https://arxiv.org/abs/2512.06837", "title": "基于神经因子分解的轴承故障诊断", "title_en": "Neural Factorization-based Bearing Fault Diagnosis", "authors": "Zhenhao Li,Xu Cheng,Yi Zhou", "background": "本文研究高速列车轴承故障诊断的关键问题。作为列车运行系统的核心组件，轴承的健康状况直接影响列车运行的安全性。传统的诊断方法在复杂条件下面临诊断精度不足的挑战。", "innovation": "为了应对这些问题，本文提出了一种基于神经因子分解（NFC）框架进行轴承故障诊断的新方法。该框架基于两个核心思想：1）将振动时间序列嵌入到多个模式特异性潜在特征向量中，以捕捉多样的故障相关模式；2）利用神经因子分解的原则将这些向量融合为统一的振动表示。这一设计能够有效地从原始时间序列数据中挖掘复杂的潜在故障特征。此外，本文还分别基于CP和Tucker融合方案实例化了该框架，形成了CP-NFC和Tucker-NFC两种模型，并且实验结果表明，这两种模型在诊断性能上优于传统的机器学习方法。", "conclusion": " comparative analysis provides valuable empirical evidence and practical guidance for selecting effective diagnostic strategies in high-speed train bearing monitoring."}
{"llm_update_time": "20251210", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2512.06917", "html_url": "https://arxiv.org/abs/2512.06917", "title": "了解你的轨迹——基于重要性的时间轴分析实现可信赖的强化学习部署", "title_en": "Know your Trajectory -- Trustworthy Reinforcement Learning deployment through Importance-Based Trajectory Analysis", "authors": "Clifford F,Devika Jay,Abhishek Sarkar,Satheesh K Perepu,Santhosh G S,Kaushik Dey,Balaraman Ravindran", "background": "随着强化学习（RL）代理在实际应用中的日益普及，确保其行为的透明性和可信性变得至关重要。解释性是信任的关键组成部分，然而大部分的工作集中在单步决策的解释上。本文关注的是通过轨迹级别的分析来解释代理的长期行为。", "innovation": "本文引入了一个新颖的框架，通过定义并聚合一种新的状态重要性度量来对整个轨迹进行排名。该度量结合了经典的Q值差异以及一个“激进项”，该项捕捉了代理接近目标的倾向，从而提供了状态关键性更为细致的度量。此外，通过生成轨迹中关键状态的反事实滚动，证明代理所选择的路径在对比替代路径时更为优越。", "conclusion": "实验结果证实，相较于经典的度量方法，本文提出的重要性度量在标准OpenAI Gym环境中更有效地识别出最优行为，这为构建可信的自主系统提供了一个重要步骤。"}
{"llm_update_time": "20251210", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2512.06813", "html_url": "https://arxiv.org/abs/2512.06813", "title": "使用协同神经网络在考虑约束条件的情况下对高性能混凝土进行部分逆向设计", "title_en": "Partial Inverse Design of High-Performance Concrete Using Cooperative Neural Networks for Constraint-Aware Mix Generation", "authors": "Agung Nugraha,Heungjun Im,Jihwan Lee", "background": "高性能混凝土具有出色的强度和耐久性，但其混合设计复杂，涉及多个相互依赖的变量和实际约束。尽管数据驱动方法在前瞻设计的预测建模方面取得了进展，但在确定满足目标性能的混合组成以适应固定约束的情况下，逆向设计（即确定混合组成以达到目标性能）仍然是有限的，尤其是在部分变量由约束固定而仅需确定其他变量的设计情况下。", "innovation": "本研究提出了一种新的协同神经网络框架，用于高性能混凝土的部分逆向设计。该框架结合了两个耦合的神经网络模型：一种补全模型，用于推断未知变量；一种替代模型，用于预测抗压强度。通过协同学习，该模型在单次前向传递中生成有效和性能一致的混合设计，同时适应不同的约束组合而无需重新训练。", "conclusion": "与现有的概率方法和生成方法（包括基于高斯过程替代模型的贝叶斯推理和基于自编码器的模型）相比，所提出的模型在基准数据集上表现出更高的稳定性和R-squared值（0.87-0.92），并且分别将平均均方误差降低了50%和70%。结果表明，协同神经网络为考虑约束条件的数据驱动混合配比在混凝土工程中的应用提供了准确、稳健且计算效率高的基础。"}
{"llm_update_time": "20251210", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2512.06752", "html_url": "https://arxiv.org/abs/2512.06752", "title": "使用几何图U-网络进行蛋白质结构的多尺度建模", "title_en": "Multi-Scale Protein Structure Modelling with Geometric Graph U-Nets", "authors": "Chang Liu,Vivian Li,Linus Leong,Vladimir Radenkovic,Pietro Liò,Chaitanya K. Joshi", "background": "几何图神经网络（GNNs）和变压器在学习3D蛋白质结构方面已经成为最先进的技术。然而，它们依赖于消息传递，这限制了它们捕捉如全局域和远程共价调节等控制蛋白质功能的层级互动能力。", "innovation": "提出了一种新的几何图U-网络模型，通过递归地细化和粗糙化蛋白质图来学习多尺度表示。理论证明这种分层设计比标准几何GNN更具表达能力。实验结果表明，几何U-网络在蛋白质折叠分类任务上显著优于不变性和联想性基线，展现了它们学习定义蛋白质折叠的全局结构模式的能力。", "conclusion": "本文提供了设计可以学习生物分子多尺度结构的几何深度学习架构的坚实基础。"}
{"llm_update_time": "20251210", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2512.06655", "html_url": "https://arxiv.org/abs/2512.06655", "title": "GSAE: 基于图正则化稀疏自编码器的LLM稳健安全性引导", "title_en": "GSAE: Graph-Regularized Sparse Autoencoders for Robust LLM Safety Steering", "authors": "Jehyeok Yeon,Federico Cinus,Yifan Wu,Luca Luceri", "background": "大型语言模型（LLMs）面临严重的安全挑战，因为它们可以通过对抗性提示和监狱突破攻击来被操控生成有害内容。现有的防御方法通常要么是黑盒护栏，过滤输出；要么是基于内部的方法，通过将安全性操作化为单个潜在特征或维度来引导隐藏激活。虽然对于简单概念有效，但这种假设是有限制的，因为实证研究表明，抽象概念如拒绝和时间性分布在多个特征中，而不是孤立在一处。现有的方法通常将每个概念分配到单个潜在特征，而GSAE通过在神经元共激活图上添加拉普拉斯平滑惩罚，扩展了稀疏自编码器（SAEs），实现了平滑、分布的安全表示作为跨越多个特征的连贯模式。", "innovation": "GSAE（Graph-Regularized Sparse Autoencoders）引入了一个基于图正则化的稀疏自编码器架构，通过在神经元共激活图上添加拉普拉斯平滑惩罚，改进了传统的稀疏自编码器（SAEs）。这种方法能够恢复平滑、分布的安全表示，作为跨越多个特征的连贯模式。GSAE通过两阶段门控机制实现运行时的安全引导，仅在生成过程中检测到有害的提示或后续时触发干预，从而适应性地执行拒绝操作但保留对良性查询的实用性。", "conclusion": "GSAE在安全和QA基准测试中实现了平均82%的有选择地拒绝有害内容的成功率，大幅超过标准SAE引导（42%），同时保持强大的任务准确性（在TriviaQA上70%，在TruthfulQA上65%，在GSM8K上74%）。稳健性实验进一步显示，GSAE在LLaMA-3、Mistral、Qwen和Phi家族中具有泛化能力，并对监狱突破攻击（GCG，AutoDAN）具有抗性，始终保持 >= 90% 的有害内容拒绝率。"}
{"llm_update_time": "20251210", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2512.06782", "html_url": "https://arxiv.org/abs/2512.06782", "title": "超越狄利克雷能量衡量过平滑", "title_en": "Measuring Over-smoothing beyond Dirichlet energy", "authors": "Weiqi Guan,Zihao Shi", "background": "当使用狄利克雷能量来度量模型过平滑现象时，它只能捕捉到一阶特征导数，但无法捕捉更高阶的特征导数，存在固有限制。", "innovation": "该研究提出了基于更高阶特征导数能量的一系列节点相似度度量方法，通过严谨的理论分析这些度量的相互关系，揭示了狄利克雷能量在连续热扩散和离散聚集操作下的衰减率，并发现了图拉普拉斯谱隙与过平滑衰减率之间的固有联系。", "conclusion": "通过提出的这些度量方法，注意力基图神经网络（GNN）在评估过程中会遭受过平滑问题。"}
{"llm_update_time": "20251210", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2512.06926", "html_url": "https://arxiv.org/abs/2512.06926", "title": "评估BiLSTM预测模型对序列长度和输入噪声的敏感性", "title_en": "Evaluating the Sensitivity of BiLSTM Forecasting Models to Sequence Length and Input Noise", "authors": "Salma Albelali,Moataz Ahmed", "background": "深度学习（DL）模型，作为一种特殊类别的多层神经网络，已经成为了环境监测和物联网等关键领域时间序列预测的核心。在这些领域中，双向长短期记忆（BiLSTM）架构特别擅长捕捉复杂的时序依赖性。然而，这类模型的稳健性和泛化能力高度依赖输入数据的特性，现有文献对此方面的研究还不够深入。", "innovation": "本研究系统地分析了两个关键的数据中心因素：输入序列长度和添加噪声，并开发了一个模块化且可重复的预测管道，包括标准化预处理、序列生成、模型训练、验证和评估。通过在三个具有不同采样频率的真实数据集上进行受控实验，评估了在不同输入条件下BiLSTM的表现。", "conclusion": "研究结果得出三个关键发现：（1）较长的输入序列会显著增加过拟合和数据泄露的风险，特别是在数据有限的环境中；（2）添加噪声在所有采样频率下都一致地降低了预测准确性；（3）同时存在两种因素会导致模型稳定性大幅下降。尽管具有更高观测频率的数据集表现得更加稳健，但在面对两种输入挑战时仍然脆弱。这些发现强调了当前基于DL的预测管道中的重要限制，并突显了需要采用数据感知设计策略。"}
{"llm_update_time": "20251210", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2512.06727", "html_url": "https://arxiv.org/abs/2512.06727", "title": "KV-CAR: 使用自动编码器和关键值重用进行大型语言模型的关键值缓存压缩", "title_en": "KV-CAR: KV Cache Compression using Autoencoders and KV Reuse in Large Language Models", "authors": "Sourjya Roy,Shrihari Sridharan,Surya Selvam,Anand Raghunathan", "background": "随着大型语言模型（LLMs）的规模增长，尤其是上下文长度的增加，关键值（KV）缓存在自回归解码中的内存需求已成为主要瓶颈。KV缓存会随着序列长度和嵌入维度的增加而增长，常常超过模型本身的内存容量限制，从而限制了可以实现的批量大小和上下文窗口大小。", "innovation": "KV CAR是一个统一且架构无关的框架，显著降低了KV缓存的存储空间，同时保持了模型的准确性。KV CAR结合了两种互补的技术：首先，一种轻量级的自动编码器学习关键值和值张量在嵌入维度上的紧凑表示，在存储到KV缓存前对其进行压缩，检索时恢复；其次，一种基于相似性重用机制识别通过相邻层重用特定注意头的KV张量的机会。这些方法在不改变变压器架构的情况下减少了KV张量的维度和结构冗余。该方法在GPT2和TinyLLaMA模型上的实验表明，KV CAR能够在几乎不影响困惑度和零样本准确性的情况下实现高达47.85%的KV缓存内存减少。系统层级测量表明，KV缓存尺寸的减小直接导致了推理过程中更长的序列长度和更大的批量大小。", "conclusion": "KV CAR框架的有效性在于，它通过压缩和重用关键值缓存，增强了大型语言模型的内存效率。这项研究结果表明，KV CAR能够在保持模型性能的同时，显著减少内存消耗，从而支持更高效的推理执行。"}
{"llm_update_time": "20251210", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2512.06920", "html_url": "https://arxiv.org/abs/2512.06920", "title": "PGSRM：变压器语言模型强化学习的基于嵌入的奖励函数", "title_en": "Parent-Guided Semantic Reward Model (PGSRM): Embedding-Based Reward Functions for Reinforcement Learning of Transformer Language Models", "authors": "Alexandr Plashchinsky", "background": "该论文的背景来源于强化学习（RL）中对变压器语言模型的训练，通常使用二元正确性信号、人类偏好数据或训练过的奖励模型作为奖励机制。这种方法不仅依赖于人工标注，还需要额外的模型训练，增加了开发和训练的复杂性。", "innovation": "论文提出了一种新的奖励框架——Parent-Guided Semantic Reward Model (PGSRM)，该框架使用父模型的参考输出嵌入与子模型生成的输出之间的余弦相似性作为简单信号，替代了传统的奖励机制。这种方法不需要人工标注或额外的模型训练，能够产生密集且语义上有意义的奖励，并在五个语言任务上表现出比二元奖励基准更好的平滑性和更稳定的PPO动态。", "conclusion": "实验结果表明，PgSRM适用于变压器模型的对齐任务，尤其是更小的变压器模型，其表现优于传统的二元奖励方法，提议基于嵌入的语义奖励是一种实践性的替代RLHF（人类反馈强化学习）风格奖励模型的方法，用于指导性的齐理论小变压器模型。"}
{"llm_update_time": "20251210", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2512.06969", "html_url": "https://arxiv.org/abs/2512.06969", "title": "比较BFGS和OGR在二次优化中的应用", "title_en": "Comparing BFGS and OGR for Second-Order Optimization", "authors": "Adrian Przybysz,Mikołaj Kołek,Franciszek Sobota,Jarek Duda", "background": "Hessian矩阵的估计对神经网络训练来说是一个具有挑战性的问题，尤其是由于其高维度和计算成本。现有的方法通常依赖于假设凸性的Sherman-Morrison更新，但这种方法需要维护一个正定的Hessian近似。相比之下，新的方法Online Gradient Regression（OGR）通过使用指数移动平均回归梯度来估算二次导数，而无需进行Hessian的逆运算。", "innovation": "引入了OGR方法，它不依赖于Hessian的逆运算，能够在线估计Hessian并处理非凸结构，同时在标准测试函数上表现出更快的收敛速度和更优的损失。", "conclusion": "在不同的标准测试函数上评估BFGS和OGR两种方法，结果显示OGR方法在非凸设置中表现尤为突出，能够实现更快的收敛速度和更好的损失值。"}
{"llm_update_time": "20251210", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2512.06944", "html_url": "https://arxiv.org/abs/2512.06944", "title": "统一的人本中心人工智能公平性框架", "title_en": "A Unifying Human-Centered AI Fairness Framework", "authors": "Munshi Mahbubur Rahman,Shimei Pan,James R. Foulds", "background": "随着人工智能（AI）在关键社会领域中的应用增加，人们对公平性的担忧也加剧了，特别是涉及到种族、性别和社会经济状况等敏感属性的不平等对待。尽管已经有很多工作致力于确保AI的公平性，但要在不同的公平性概念之间以及准确性和预测准确性之间取得平衡仍然是具有挑战性的任务，这给公平AI系统实际部署带来了障碍。", "innovation": "本文引入了一个统一的人本中心公平性框架，该框架系统地涵盖了八种不同的公平性标准，这些标准由个体公平性和群体公平性、基础边缘假设和交集假设、结果导向和公正机会（EOO）视角的组合形成。这个结构使利益相关者能够根据其价值观和情境考虑对公平性干预进行对齐。该框架使用所有指标的一致和易于理解的表述，以降低非专家的学习曲线。这一框架不仅不优先考虑任何单一的公平性概念，还使利益相关者能够为多个公平性目标分配权重，这反映了他们的优先级，并促进了多方利益相关者的妥协。", "conclusion": "我们通过调整权重展示了不同公平性指标之间的微妙权衡，并通过司法决策和医疗保健领域的案例研究展示了该框架如何指导公平AI系统的实用和价值敏感部署。"}
{"llm_update_time": "20251210", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2512.06932", "html_url": "https://arxiv.org/abs/2512.06932", "title": "时间序列预测中的隐藏泄露：数据泄露如何影响LSTM评估配置和验证策略", "title_en": "Hidden Leaks in Time Series Forecasting: How Data Leakage Affects LSTM Evaluation Across Configurations and Validation Strategies", "authors": "Salma Albelali,Moataz Ahmed", "background": "深度学习模型，尤其是长短期记忆(Long Short-Term Memory, LSTM)网络，由于其在捕捉复杂时间依赖性方面的能力，在时间序列预测中得到了广泛的应用。然而，由于数据泄露问题，评估的完整性往往受到损害。数据泄露是指在数据集划分之前构建输入-输出序列的方法学缺陷，这会导致未来的数据信息在不经意间影响到训练过程。", "innovation": "研究探讨了数据泄露对表现的影响，重点关注验证设计如何调节泄露敏感性。评估了三种常用的验证技术（2分划、3分划和10折交叉验证）在有泄露和无泄露条件下的表现。引入了RMSE Gain作为度量泄露影响的指标，计算方法是计算有泄露设置与无泄露设置之间的相对增加的均方根误差（RMSE）。实证结果显示，10折交叉验证在较长滞后步长时展现出高达20.5%的RMSE Gain，而2分划和3分划显示出了更强的鲁棒性，通常保持RMSE Gain低于5%。此外，输入窗口大小和滞后步长显著影响泄露敏感性：较小的窗口大小和较长的滞后步长增加了泄露的风险，而较大的窗口大小则有助于降低这一风险。", "conclusion": "研究发现，配置意识强、抗泄露的评估管道对于确保可靠的性能估计是必要的。"}
{"llm_update_time": "20251210", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2512.06929", "html_url": "https://arxiv.org/abs/2512.06929", "title": "自适应归一化Mamba结合多尺度趋势分解和Patch MoE编码", "title_en": "Adaptive Normalization Mamba with Multi Scale Trend Decomposition and Patch MoE Encoding", "authors": "MinCheol Jeon", "background": "实时环境中的时间序列预测面临显著挑战，包括非平稳性、多尺度时间模式和分布漂移，这些因素会削弱模型的稳定性和准确性。", "innovation": "本文提出了AdaMamba，一种统一的时间序列预测架构，集成了自适应归一化、多尺度趋势提取和上下文序列建模，以应对这些挑战。AdaMamba从自适应归一化块开始，通过多尺度卷积趋势提取和通道间校准去除非平稳成分，实现一致去趋势和方差稳定化。然后，由上下文编码器处理归一化序列，该编码器结合了块嵌入、位置编码和Mamba增强的Transformer层以及混合专家前馈模块，能够高效建模长距离依赖关系和局部时间动态。轻量级预测头生成多步预测，而去归一化机制则通过对局部趋势进行重新整合来确保在不同时间条件下的鲁棒性。AdaMamba提供了强大的表示能力，具有模块化扩展性，支持确定性预测并兼容概率扩展。", "conclusion": "实验结果表明，AdaMamba结合自适应归一化和专家增强上下文建模，为常规基于Transformer的基线持续提供了稳定性与准确性的改进。"}
{"llm_update_time": "20251210", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2512.06925", "html_url": "https://arxiv.org/abs/2512.06925", "title": "基于变压器基元语义特征的深度强化学习钓鱼检测", "title_en": "Deep Reinforcement Learning for Phishing Detection with Transformer-Based Semantic Features", "authors": "Aseer Al Faisal", "background": "钓鱼攻击是一种网络犯罪活动，通过欺诈性信息、误导性广告和篡改的合法网站等手段诱骗个人披露个人信息，导致财务损失。传统的深度强化学习方法，如DQN，通过估计单一标量Q值来检测钓鱼攻击，但这种做法在处理不确定性和未知钓鱼数据时缺乏稳定性和泛化能力。", "innovation": "本文提出了一种Quantile Regression Deep Q-Network (QR-DQN)方法，该方法将RoBERTa语义嵌入与手工构建的词法特征结合起来，以增强钓鱼检测的能力，同时考虑不确定性。QR-DQN利用分位数回归模型回报分布，提高稳定性和对于未见过的钓鱼数据的泛化能力，从而减少泛化差距。", "conclusion": "研究建立了一个由105,000个URL组成的多样化数据集，经过80/20的训练-测试分割后，QR-DQN框架实现了99.86%的测试准确率，99.75%的精确率，99.96%的召回率，F1分数为99.85%，显示了极高的有效性。相较于仅使用词法特征的标准DQN，结合词法和语义特征的QR-DQN显著降低了泛化差距，证明了其在鲁棒性方面的显著改进。五折交叉验证进一步证实了模型的可靠性，平均准确率为99.90%，标准差为0.04%，表明该混合方法能够有效识别钓鱼威胁，适应不断变化的攻击策略，对未见过的数据具有良好的泛化能力。"}
{"llm_update_time": "20251210", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2404.18886", "html_url": "https://arxiv.org/abs/2404.18886", "title": "时间序列和时空数据上的扩散模型综述", "title_en": "A Survey on Diffusion Models for Time Series and Spatio-Temporal Data", "authors": "Yiyuan Yang,Ming Jin,Haomin Wen,Chaoli Zhang,Yuxuan Liang,Lintao Ma,Yi Wang,Chenghao Liu,Bin Yang,Zenglin Xu,Shirui Pan,Qingsong Wen", "background": "扩散模型在时间序列和时空数据分析中被广泛应用，可以增强生成、推断和下游任务的能力。这些模型应用于各个领域，如医疗、推荐、气候、能源、音频和交通。", "innovation": "在分析扩散模型应用于时间序列与时空数据的基础上，本文提供了一个结构化的模型类别、任务类型、数据模态和实际应用领域的视角。旨在为研究人员和实践者提供坚实的基础，激发针对扩散模型数据挖掘任务和应用的创新。", "conclusion": "本研究旨在为扩散模型的数据挖掘任务和应用提供坚实的基础，以应对传统挑战并促进新的解决方案，并公开了一个仓库以提供更详细的信息。"}
{"llm_update_time": "20251210", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2410.15001", "html_url": "https://arxiv.org/abs/2410.15001", "title": "FIT-GNN: 使用共化方法在内存中实现更快推理时间的 GNN", "title_en": "FIT-GNN: Faster Inference Time for GNNs that 'FIT' in Memory Using Coarsening", "authors": "Shubhajit Roy,Hrriday Ruparel,Kishan Ved,Anirban Dasgupta", "background": "图神经网络(GNNs)的可扩展性仍是一个重大挑战。尽管通过共化、凝缩和计算树等方法可以在较小的图上进行训练，以实现更快的计算，但前人研究并未充分解决推理阶段的计算成本问题。", "innovation": "本文提出了一种通过共化减少推理阶段计算负担的新方法。具体来说，本文提出了两种方法——额外节点和聚类节点。该研究扩展了图共化在图级别任务中的应用，包括图分类和图回归。通过在多个基准数据集上进行广泛实验，验证了该方法相较于传统方法在单节点推理时间上实现数量级的改进，并显著减少了节点和图分类与回归任务的内存消耗，从而能够在低资源设备上实现高效的训练和推理。", "conclusion": "所提出的方法不仅大幅降低了单节点推理时间，还显著减少了内存消耗，提高了在低资源设备上的可训练性和可推理性，而且保持了与基线模型相当的性能。"}
{"llm_update_time": "20251210", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2406.16028", "html_url": "https://arxiv.org/abs/2406.16028", "title": "TimeAutoDiff：统一异质时序表格数据生成、插补、预测及时间变化元数据条件生成的框架", "title_en": "TimeAutoDiff: A Unified Framework for Generation, Imputation, Forecasting, and Time-Varying Metadata Conditioning of Heterogeneous Time Series Tabular Data", "authors": "Namjoon Suh,Yuning Yang,Din-Yin Hsieh,Qitong Luan,Shirong Xu,Shixiang Zhu,Guang Cheng", "background": "本文提出了TimeAutoDiff，这是一个统一的潜在扩散框架，可处理四种基本的时序任务：无条件生成、缺失数据插补、预测和时间变化中的元数据条件生成。该模型原生支持混合类型的特征，并采用masked-modeling策略，通过二进制掩码来指定哪些时序单元是观察到的，哪些是需要生成的。实验结果表明，TimeAutoDiff在合成序列保真度方面能够匹敌或超越强基准，并且在插补和预测任务上持续表现出色。", "innovation": "TimeAutoDiff采用了一种新颖的统一方法，引入了一个轻量级的变分自编码器，将混合类型特征映射到连续的潜在序列中，以及一个学习潜在空间中时序动态的扩散模型。这种建模策略有效地支持了异质特征，并且两个架构选择提供了显著的速度和可扩展性优势。原理性研究还强调了变分自编码器的特征编码和去噪器的关键组件的重要性。", "conclusion": "实证分析表明，TimeAutoDiff在合成序列保真度方面能够匹敌或超越强基准，并且在插补和预测任务上持续表现出色。此外，元数据约束允许探索现实场景并产生一致的假设轨迹，保持跨特征间的依赖性。原理性研究表明变分自编码器的特征编码及去噪器的关键部分对性能至关重要。模型审计表明，模型恰当地泛化而不会过度记忆。"}
{"llm_update_time": "20251210", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2407.01316", "html_url": "https://arxiv.org/abs/2407.01316", "title": "评估最坏情况子群体下的模型性能", "title_en": "Evaluating Model Performance Under Worst-case Subpopulations", "authors": "Mike Li,Daksh Mittal,Hongseok Namkoong,Shangzhou Xia", "background": "当模型的训练人群与实际运行时的人群不同，ML模型的表现会下降。本文旨在评估模型的分布鲁棒性，通过研究给定大小的所有子人群的最坏情况性能，特别是在定义基于核心属性Z的所有子人群中。这种鲁棒性的概念可以考虑任意持续属性Z，自动处理弱势群体中的复杂交叉性。", "innovation": "提出了一个规模可扩展且基于原理的两阶段估算程序，可以评估最新的模型鲁棒性。证明了该方法在有限样本上的收敛保证，包括独立于维度的收敛。与基于Rademacher复杂性的过于保守的概念不同，我们评价的误差只取决于Z的维度和出样外估计性能依赖Z的误差。", "conclusion": "在真实数据集上，展示了该方法能够认证模型的鲁棒性，并防止部署不可靠模型。"}
{"llm_update_time": "20251210", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2501.16932", "html_url": "https://arxiv.org/abs/2501.16932", "title": "Online-BLS: 数据流分类中准确高效的在线广学习系统", "title_en": "Online-BLS: An Accurate and Efficient Online Broad Learning System for Data Stream Classification", "authors": "Chunyu Lei,Guang-Ze Chen,C. L. Philip Chen,Tong Zhang", "background": "现有的先进在线学习模型通常在遇到新样本时只进行一次梯度下降，因此会导致模型权重次优。为了解决这个问题，作者引入了一种带有每步闭合形式解的在线广学习系统框架。", "innovation": "设计了一个有效的权重估计算法和高效的在线更新策略，分别解决了现有方法准确度下降和在线更新开销大的问题。具体来说，通过使用Cholesky分解和前向后向替换代替了烦人的矩阵逆运算，提高了模型的准确度；同时，提出了高效的在线更新策略，显著减少了在线更新时间。理论分析展示了模型出色的误差界和低时间复杂度，实际测试表明该方法优于现有的基准。", "conclusion": "该框架自然地扩展到带有概念漂移的数据流场景，并超越了现有的最先进的基线方法。"}
{"llm_update_time": "20251210", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2410.09718", "html_url": "https://arxiv.org/abs/2410.09718", "title": "基于多周期学习的潮电流速度预测模型", "title_en": "A Tidal Current Speed Forecasting Model based on Multi-Periodicity Learning", "authors": "Tengfei Cheng,Yangdi Huang,Ling Xiao,Yunxuan Dong", "background": "潮汐能是提高可再生能源渗透率的关键组成部分。要实现高比例的潮汐能并入电网，需要准确预测潮电流速度。现有的物理模型预测存在精度问题，而潮汐电流速度受到天体公转周期的影响，使得精确物理建模变得困难。因此，研究潮汐的多周期性对于准确预测潮电流速度至关重要。", "innovation": "本文提出了一种Wavelet-Enhanced Convolutional Network，通过此框架将一维潮电流数据的一周期性和跨周期性特征分别嵌入二维张量的行和列中，并利用卷积核处理序列的二维变化。另外，我们还集成了一种时间频率分析方法，以进一步处理局部周期特征。为了增强框架的稳定性，我们利用树结构Parzen估计算法优化了框架的超参数。实验结果显示，在10步平均绝对误差方面表现出色，且证明了其优于其他基准模型。", "conclusion": "本文提出的框架成功捕捉了潮电流数据的多周期依赖关系，实验结果证明在平均绝对误差方面具有优势，且能显著降低相对误差。进一步的消融研究表明，在加入的人工周期波动数据上，平均绝对百分比误差降低了1.4%。"}
{"llm_update_time": "20251210", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2410.09596", "html_url": "https://arxiv.org/abs/2410.09596", "title": "掌握人工智能：大数据、深度学习和大规模语言模型的演进——从基础到最先进的AutoML技术", "title_en": "Mastering AI: Big Data, Deep Learning, and the Evolution of Large Language Models -- AutoML from Basics to State-of-the-Art Techniques", "authors": "Pohsun Feng,Ziqian Bi,Yizhu Wen,Benji Peng,Junyu Liu,Caitlyn Heqi Yin,Tianyang Wang,Keyu Chen,Sen Zhang,Ming Li,Jiawei Xu,Ming Liu,Xuanhe Pan,Jinlang Wang,Xinyuan Song,Qian Niu", "background": "本文提供了一个全面的自动化机器学习（AutoML）指南，涵盖了基础原则、实际实现和未来趋势。内容结构设计旨在帮助初学者和经验丰富的从业者，讨论了流行的AutoML工具如TPOT、AutoGluon、Auto-Keras等，并且还涵盖了诸如神经架构搜索（NAS）等新兴话题，以及AutoML在深度学习中的应用。", "innovation": "详细讨论了多个AutoML工具及其应用，包括TPOT、AutoGluon和Auto-Keras，以及神经架构搜索（NAS）等新兴技术，提供了一个从基础到先进技术的详细指南。", "conclusion": "本研究预计会推动AI和机器学习领域的持续研究和发展。"}
{"llm_update_time": "20251210", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2405.15376", "html_url": "https://arxiv.org/abs/2405.15376", "title": "快速训练和抽样受限玻尔兹曼机", "title_en": "Fast training and sampling of Restricted Boltzmann Machines", "authors": "Nicolas Béreux,Aurélien Decelle,Cyril Furtlehner,Lorenzo Rosset,Beatriz Seoane", "background": "受限玻尔兹曼机（RBMs）是建模复杂系统和从数据中提取洞察的强大工具，但它们的训练受到马尔可夫链蒙特卡洛（MCMC）过程混合缓慢的阻碍，尤其是在高度结构化的数据集上。", "innovation": "该研究基于近期关于RBM训练的理论进步，提出了一种逐步编码数据模式到耦合矩阵的奇异向量中的方法，显著降低了生成新样本和评估模型质量的成本，特别是在高度集群的数据集上，缩短了训练成本。这种方法将学习过程类比于铁磁模型中观察到的热力学连续相变，其中概率测度中的新模式连续出现。利用训练过程中连续的相变，定义了一个平滑的先调校路径，提供了可靠且计算高效的对数似然估计。这种方法在训练过程中实现在线评估，并引入了一种名为并行轨迹调温（PTT）的新采样策略，优于优化后的MCMC方法。为缓解训练早期的临界减速效应，提出了一种预训练阶段，在此阶段通过凸优化过程将主成分编码到低秩RBM中，实现高效静态蒙特卡罗采样和分区函数的精确计算。", "conclusion": "我们的结果表明，此预训练策略可以让RBMs有效地处理传统方法无法处理的高度结构化数据集，同时，我们的对数似然估计在受控场景中优于计算密集的方法，而PTT算法相比传统方法显著加速了MCMC过程。"}
{"llm_update_time": "20251210", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2411.11530", "html_url": "https://arxiv.org/abs/2411.11530", "title": "SeqProFT：仅序列蛋白属性预测中的LoRA微调", "title_en": "SeqProFT: Sequence-only Protein Property Prediction with LoRA Finetuning", "authors": "Shuo Zhang,Jian K. Liu", "background": "蛋白质语言模型（PLMs）在学习蛋白质序列与功能之间的关系方面展现了显著的能力。然而，这些大型模型的微调需要大量计算资源，且往往在特定任务上效果欠佳。本研究探讨了如何通过LoRA实现参数高效的微调，以增强蛋白质属性预测，同时大幅减少计算需求。", "innovation": "通过将LoRA应用到不同规模的ESM-2和ESM-C模型，并评估10种不同的蛋白质属性预测任务，研究表明，在LoRA适应下，较小的模型可以达到或超过未经过适应的大型模型的性能。此外，通过多头注意机制整合接触图信息，提升了模型对结构特征的理解。系统分析表明，LoRA微调能够加速收敛，提高性能，更高效地利用资源，为资源受限环境下的蛋白质研究提供了指导。", "conclusion": "LoRA微调使模型在更少的计算资源下达到更好的性能，提供了一种在资源受限环境中使用蛋白质序列数据进行属性预测的实用方法。所得代码可在以下链接获取。"}
{"llm_update_time": "20251210", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2501.01669", "html_url": "https://arxiv.org/abs/2501.01669", "title": "通过抽象状态逆向学习可转移奖励", "title_en": "Inversely Learning Transferable Rewards via Abstracted States", "authors": "Yikang Gui,Prashant Doshi", "background": "逆强化学习（IRL）在从行为数据中准确学习离散和连续领域内的潜在奖励方面取得了显著进展。下一步的进展是学习内在偏好，这些偏好能够在不同的但与观察到的任务或设置对齐的情况下产生有用的性能。特别是在机器人应用中，这有助于将具有共享内在偏好的新任务集成到不需重新编程的生产线上。", "innovation": "提出了一种从两个或更多不同实例的领域行为轨迹中逆向学习抽象奖励函数的方法。该抽象奖励函数随后被用于在另一个单独的领域实例中学习任务行为。这种方法的关键在于评估了其转移性，并验证了其正确性。在OpenAI的Gym测试床和AssistiveGym中的多领域任务轨迹上进行了评估，结果表明，所学习的抽象奖励函数能够成功地在之前未见过的任务实例中学习任务行为。", "conclusion": "方法在多个领域中的任务轨迹上进行了评价，并证明所学习的抽象奖励函数可以成功地在未见过的任务实例中学习任务行为，显示了该方法的可转移性和正确性。"}
{"llm_update_time": "20251210", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2404.03764", "html_url": "https://arxiv.org/abs/2404.03764", "title": "带有条件尖峰-平滑先验的协变量详述稳健部分信息转移", "title_en": "Covariate-Elaborated Robust Partial Information Transfer with Conditional Spike-and-Slab Prior", "authors": "Ruqian Zhang,Yijiao Zhang,Annie Qu,Zhongyi Zhu,Juan Shen", "background": "迁移学习因其能从有用的辅助数据集中借用信息而受到欢迎。现有的统计迁移学习方法通常采用全局相似度来衡量源数据和目标数据之间的关系，但在数据部分共享的情况下可能会导致效率低下。", "innovation": "本文提出了一种名为“CONCERT”的新型贝叶斯迁移学习方法，允许稳健的部分信息转移，适用于高维数据分析。通过引入条件尖峰-平滑先验，在目标和源参数的联合分布中进行信息转移。此外，通过结合协变量特异性先验，可以表征部分相似并协同整合源信息，从而在目标上提高性能。CONCERT是单一步骤的处理流程，能够同时完成变量选择和信息转移。", "conclusion": "我们建立了CONCERT的变量选择一致性，以及估计和预测误差边界。理论表明，迁移学习在协变量层面具有特定的优势。为了确保算法的可扩展性，我们采用变分贝叶斯框架来促进实现。广泛的实验和两个实际数据应用展示了CONCERT的有效性及相对于现有最先进的迁移学习方法的优势。"}
{"llm_update_time": "20251210", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2502.02216", "html_url": "https://arxiv.org/abs/2502.02216", "title": "将图扁平化为序列：变换器是可扩展的图生成器", "title_en": "Flatten Graphs as Sequences: Transformers are Scalable Graph Generators", "authors": "Dexiong Chen,Markus Krimmel,Karsten Borgwardt", "background": "现有的图生成方法通常依赖于计算昂贵的额外节点特征，或者采样复杂性和序列长度的增加随着边数的增加而增大，这使得它们在处理大规模稀疏图时效率低下。", "innovation": "AutoGraph引入了一种使用解码器型变压器的可扩展自回归模型，通过将图转换为随机序列的令牌来生成有属性的图，从而避免了依赖昂贵的额外节点特征。这使得AutoGraph的采样复杂性和序列长度可以最佳地线性扩展到边数，使得它适用于大规模稀疏图。此外，AutoGraph的序列前缀表示诱导子图，建立了与自然语言模型子句之间的直接联系。", "conclusion": "在合成和分子基准测试中，AutoGraph达到了最先进的性能，相较于领先的扩散模型生成速度快100倍，训练速度快3倍。它还支持基于子结构的生成，具有迁移性，并建立了语言模型和图生成之间的联系，为图基础模型构建了框架。代码可以在此获取：this https URL."}
{"llm_update_time": "20251210", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2501.12962", "html_url": "https://arxiv.org/abs/2501.12962", "title": "复杂的关系：欧盟AI法案中针对高风险系统的算法公平性与非歧视性法规的关系", "title_en": "It's complicated. The relationship of algorithmic fairness and non-discrimination regulations for high-risk systems in the EU AI Act", "authors": "Kristof Meding", "background": "该论文探讨了公平决策的概念，不仅对人类充满了挑战，且当人工智能模型介入后问题变得更加复杂。鉴于存在歧视性算法行为，欧盟通过了AI法案，这种立法对高风险系统制定了具体规则，结合了传统法律中的非歧视规定和基于机器学习的算法公平性概念。", "innovation": "论文旨在通过向法律和计算机科学领域学者提供必要且高层次的解读，以及深入分析算法公平性和非歧视性法规之间的关系，来架起这两个概念之间的桥梁。", "conclusion": "研究揭示了三个关键发现：（1）大多数非歧视法规仅针对高风险AI系统；（2）高风险系统监管包括数据输入要求和输出监控，但这些规定存在不一致性，引发计算可行性问题；（3）经典欧盟非歧视法与AI法案规定的未来交互。建议开发更具体的审计和测试方法，以供未来跨学科合作研究AI系统中的歧视问题之用。"}
{"llm_update_time": "20251210", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2502.03587", "html_url": "https://arxiv.org/abs/2502.03587", "title": "Stein Discrepancy for Unsupervised Domain Adaptation", "title_en": "Stein Discrepancy for Unsupervised Domain Adaptation", "authors": "Anneke von Seeger,Dongmian Zou,Gilad Lerman", "background": "无监督领域适应（UDA）的目标是在相关但带标签的源域上使用未标记的目标域来提高模型性能。常见的方法是对齐源域和目标域的特征分布，通常使用对称度量如最大均值偏差（MMD）来最小化两者之间的距离。然而，当目标数据稀少时，这些方法会面临挑战。", "innovation": "提出了一种新的UDA框架，利用Stein discrepancy这一不对称度量。它是通过目标分布的得分函数依赖的，特别适用于数据稀少的目标域情况。提出的方法有核化和对抗性形式，并通过高斯、混合高斯模型或VAE模型灵活建模目标分布。推导了目标错误的泛化界和两样本设定下的经验Stein discrepancy收敛率。", "conclusion": "实证结果表明，在有限目标数据情况下，该方法在多个基准测试中始终优于先前的UDA方法。"}
{"llm_update_time": "20251210", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2502.09193", "html_url": "https://arxiv.org/abs/2502.09193", "title": "使用反事实示例对抗过拟合", "title_en": "Countering Overfitting with Counterfactual Examples", "authors": "Flavio Giorgi,Fabiano Veglianti,Fabrizio Silvestri,Gabriele Tolomei", "background": "过拟合是机器学习中一个熟知的问题，当一个模型在其训练集之外的数据上无法很好地推广其预测结果时，即发生了过拟合。传统的过拟合缓解技术包括提前停止、数据增广和正则化。", "innovation": "本文展示了训练模型的过拟合程度与其生成反事实示例的能力相关。即，过拟合程度越高，找到随机选择的数据点的有效反事实示例就越容易。因此，本文引入了CF-Reg，这是一种新型的正则化项，通过确保每个实例与其相应的反事实之间的余地来控制过拟合。实验表明，我们的反事实正则化器通常优于现有技术。", "conclusion": "我们在多个数据集和模型上进行的实验表明，我们的反事实正则化器在控制过拟合方面一般优于现有的正则化技术。"}
{"llm_update_time": "20251210", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2503.14259", "html_url": "https://arxiv.org/abs/2503.14259", "title": "无需量化自回归动作变换器", "title_en": "Quantization-Free Autoregressive Action Transformer", "authors": "Ziyad Sheebaelhamd,Michael Tschannen,Michael Muehlebach,Claire Vernade", "background": "当前基于电流互感器的模仿学习方法将离散动作表示引入其中，并在生成的潜在码上训练自回归变压器解码器。然而，初始量化破坏了动作空间的连续结构，限制了生成模型的能力。", "innovation": "提出了一种无需量化的替代方法，利用生成无限词汇量变压器（GIVT）作为自回归变压器的直接、连续策略参数化。这种方法简化了模仿学习管道，同时在各种流行的模拟机器人任务上实现了最先进的性能。通过仔细研究采样算法，进一步提高了结果。", "conclusion": "该研究提出的方法在各种流行模拟机器人任务上展示了最先进的性能，通过简化模仿学习过程和细致研究采样算法，展示了持续动作空间上的强生成能力。"}
{"llm_update_time": "20251210", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2502.14354", "html_url": "https://arxiv.org/abs/2502.14354", "title": "朝向庇恰最优性的自我改进：缓解多目标对齐中的偏好冲突", "title_en": "Self-Improvement Towards Pareto Optimality: Mitigating Preference Conflicts in Multi-Objective Alignment", "authors": "Moxin Li,Yuantao Zhang,Wenjie Wang,Wentao Shi,Zhuo Liu,Fuli Feng,Tat-Seng Chua", "background": "多目标对齐（MOA）旨在使大语言模型（LLM）的回应与多种人类偏好目标相一致。直接偏好优化（DPO）成为一种主流的方法。然而，DPO基于的MOA方法在数据中广泛存在偏好冲突的问题，即不同的目标偏好不同的回应，导致优化方向冲突，阻碍了帕累托前沿的优化。", "innovation": "本文提出了一个自我改进的DPO框架，使LLM能够自我生成和选择帕累托最优回应以进行自我监督的偏好对齐。大量实验在两个数据集上证明了该框架优于各种基线模型所实现的更优的帕累托前沿。", "conclusion": "广泛进行实验后的结果表明，该框架显著提升了帕累托前沿的表现，同时相关代码可以在指定的链接处获取。"}
{"llm_update_time": "20251210", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2502.18321", "html_url": "https://arxiv.org/abs/2502.18321", "title": "全局决策导向的神经ODE模型在主动电网韧性管理中的应用", "title_en": "Global-Decision-Focused Neural ODEs for Proactive Grid Resilience Management", "authors": "Shuyi Chen,Ferdinando Fioretto,Feng Qiu,Shixiang Zhu", "background": "极端事件如野火和飓风越来越威胁到电力系统，导致大规模停电并中断关键服务。既有的预测-优化两阶段方法虽然在电网操作中有所应用，但是这种方法往往会导致预测目标与优化目标不一致，导致资源配置不合理。", "innovation": "提出了一种名为predict-all-then-optimize-globally（PATOG）的方法，该方法通过结合断电预测与全局优化干预，提出了一种全局决策导向（GDF）神经ODE模型。该模型能够捕获断电动态并以决策感知的方式优化韧性策略，从而确保空间和时间上的一致性决策，提高预测准确性和操作效率。", "conclusion": "通过对合成数据和实际数据集的实验，该方法在断电预测一致性和电网韧性方面取得了显著改进。"}
{"llm_update_time": "20251210", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2505.00291", "html_url": "https://arxiv.org/abs/2505.00291", "title": "重复造完美：循环图神经网络匹配消息传递限制", "title_en": "Repetition Makes Perfect: Recurrent Graph Neural Networks Match Message-Passing Limit", "authors": "Eran Rosenbluth,Martin Grohe", "background": "我们知道图神经网络（GNNs）的表达能力受到自然消息传递不变性的限制[莫里斯等人，AAAI 2019；徐等人，ICLR 2019]。本文深入研究了循环图神经网络（recurrent GNNs）的表达能力，并证明了在有限精度参数、求和聚合和ReLU激活函数的情况下，它们能够计算任何遵守Color Refinement（或Weisfeiler-Leman）算法诱导的自然消息传递不变性的图算法。", "innovation": "本文的主要创新在于证明了循环图神经网络能够匹配由于Color Refinement算法（或Weisfeiler-Leman算法）引起的自然消息传递不变性的表达限，这与其非循环的图神经网络形成了鲜明对比。循环图神经网络在时间和空间上都只引入了多项式级别的额外开销。此外，还通过引入随机初始化来证明在连接的图上，循环图神经网络可以表示任何图算法，甚至可以模拟复杂图算法。", "conclusion": "通过循环机制，循环图神经网络能够精确匹配由Color Refinement算法或Weisfeiler-Leman算法引入的基本表达限制。这种机制还能在连接的图上表达复杂的图算法。"}
{"llm_update_time": "20251210", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2502.02493", "html_url": "https://arxiv.org/abs/2502.02493", "title": "EasySpec: 层并行推测解码以实现高效的多GPU利用率", "title_en": "EasySpec: Layer-Parallel Speculative Decoding for Efficient Multi-GPU Utilization", "authors": "Yize Wu,Ke Gao,Ling Li,Yanjun Wu", "background": "推测解码是一种有效而无损的方法，用于加速大型语言模型（LLM）的推理。这种方法使用较小的模型生成草稿token序列，然后由原始基础模型进行验证。在多GPU系统中，通过张量并行（TP）可以进一步减少推理延迟，但草稿模型的最优TP大小通常小于基础模型的TP大小，导致GPU在草稿阶段存在闲置现象。这一现象源于各层之间数据的顺序执行，尽管看起来是自然的，但实际上是没有必要的。", "innovation": "我们提出了EasySpec，一种层并行推测策略，优化多GPU的利用效率。EasySpec打破草稿模型各层之间的数据依赖性，使多个层能够跨多个设备并行执行，作为‘模糊’推测。每次草稿验证迭代后，草稿模型的关键值缓存通过单次前向传递进行校准，以最小的附加延迟防止长时间累积模糊误差。EasySpec 是一个无需训练且即插即用的方法。", "conclusion": "我们在几个主流开源LLM上评估了EasySpec，使用同一系列的较小版本模型作为草稿者。结果表明，EasySpec 相较于基础解码可以实现多达4.17倍的峰值加速，同时保持基础LLM的原始分布。具体而言，草稿阶段的最大加速可以达到1.62倍，推测准确性下降不超过7%。代码可在该链接找到。"}
{"llm_update_time": "20251210", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2505.21626", "html_url": "https://arxiv.org/abs/2505.21626", "title": "学习何处学习：科学机器学习中的训练数据分布优化", "title_en": "Learning where to learn: Training data distribution optimization for scientific machine learning", "authors": "Nicolas Guerra,Nicholas H. Nelsen,Yunan Yang", "background": "在科学机器学习中，模型通常会被部署在与训练时参数值或边界条件相差甚远的环境中。本论文研究了学习-在哪里学习的问题，即如何设计一个训练数据分布以最小化部署环境下的平均预测错误。", "innovation": "论文通过理论分析展示了训练分布如何影响部署准确性，并提出基于概率测度空间的双层优化或交替优化的两个自适应算法。离散化的实现使用参数分布类或非参数粒子梯度流动，优化了训练分布，这些优化后的训练分布比非适应性设计表现更好。一旦训练完成，模型显示出更好的样本复杂性和对分布变化的鲁棒性。", "conclusion": "这种框架解锁了通过有原则的数据采集来学习物理量和偏微分方程的解算子潜在能力。"}
{"llm_update_time": "20251210", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2504.02459", "html_url": "https://arxiv.org/abs/2504.02459", "title": "任意几何形状下参数化偏微分方程连续解的物理约束元学习框架", "title_en": "A Physics-Informed Meta-Learning Framework for the Continuous Solution of Parametric PDEs on Arbitrary Geometries", "authors": "Reza Najian Asl,Yusuke Yamazaki,Kianoosh Taghikhani,Mayu Muramatsu,Markus Apel,Shahed Rezaei", "background": "本文介绍了一种名为隐式有限算子学习（iFOL）的方法，用于解决任意几何形状上的连续和参数化偏微分方程（PDEs）。该方法通过物理约束编解码网络在连续参数空间与解空间之间建立映射，通过隐式神经场网络构建参数化的解场。这一方法允许在训练和推理过程中最小化基于偏微分方程的物理约束损失函数，通过这种方法使用离散残差来反向传播损失。这种方法能有效捕获解中的尖锐不连续性，并且不受几何形状和网格的限制，适用于任意几何形状和空间抽样。", "innovation": "该方法的独特之处在于其独特的损失函数表示，即能量或加权残差形式，并且在训练和推理过程中使用标准数值PDE方法得到的离散残差进行评估。这种方法无需传统的编码-处理-解码管道，并能够提供准确的参数化和连续解场，同时还能提供解到参数的梯度而不需要额外的损失项或灵敏度分析，且能有效捕捉解中的尖锐不连续性，无需对几何形状和网格设限，适用于任意几何形状和空间抽样。", "conclusion": "本文方法在处理计算力学中一系列具有挑战性的问题上表现出了很好的前景，展示了其广泛的应用价值。"}
{"llm_update_time": "20251210", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2502.12845", "html_url": "https://arxiv.org/abs/2502.12845", "title": "ExLLM：分子设计及其他领域中的经验增强的大语言模型优化", "title_en": "ExLLM: Experience-Enhanced LLM Optimization for Molecular Design and Beyond", "authors": "Nian Ran,Yue Wang,Xiaoyuan Zhang,Zhongzheng Li,Qingsong Ran,Wenhao Li,Richard Allmendinger", "background": "分子设计涉及的搜索空间庞大且不规则，传统优化器如贝叶斯优化、遗传算法和生成模型在利用专家知识或处理复杂反馈方面表现不佳。尽管大语言模型（LLM）作为优化器在基准测试如PMO上取得了有希望的结果，但现有方法仅依赖提示或额外训练，缺乏处理复杂反馈或保持可扩展记忆的机制。常见的每轮增加或汇总经验的做法导致冗余、探索不足，最终导致大规模迭代搜索的不良结果。", "innovation": "我们介绍了ExLLM（经验增强的大语言模型优化）框架，该框架包含三个组成部分：(1) 一个针对大型离散空间定制且不断进化的紧凑经验片段，通过提炼非冗余线索来提高收敛速度；(2) 一种简单但有效的k-后代方案，每次调用时扩大探索范围并减少协调成本；(3) 一种轻量级反馈适配器，用于选择目的的同时格式化约束和专家提示以支持迭代。ExLLM在PMO上设立了新的最优结果，在实验设置中表现出强大的通用性，而且在圆形排列和聚变托卡马克设计等任务中打破了记录，同时在其他领域的需求上也能保持一致性。", "conclusion": "ExLLM通过引入经验增强机制，在分子设计及其他领域中提高了优化性能，实现了新的突破和一致性的改进。"}
{"llm_update_time": "20251210", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2505.10947", "html_url": "https://arxiv.org/abs/2505.10947", "title": "使用广义李雅普诺夫函数验证强化学习策略的稳定性", "title_en": "Certifying Stability of Reinforcement Learning Policies using Generalized Lyapunov Functions", "authors": "Kehan Long,Jorge Cortés,Nikolay Atanasov", "background": "为闭合环系统在强化学习策略下的稳定性建立稳定性证书是超越经验性能的关键步骤，可以提供系统行为的保证。传统李雅普诺夫方法需要严格步长减少李雅普诺夫函数，但对于学习策略来说，要构造这样的证书非常困难。强化学习的价值函数是一个自然的选择，但尚不清楚如何进行这种调整。通过研究线性二次调节器问题，我们提出了两个关键观察：首先，可以通过将与系统动力学和阶段成本相关的剩余项添加到LQR策略的价值函数中来获得李雅普诺夫函数；其次，经典的李雅普诺夫减少要求可以放宽为仅在多个时间步骤的平均值上减少的广义李雅普诺夫条件。", "innovation": "本文通过使用广义李雅普诺夫函数来验证基于强化学习的策略的稳定性，提出了一种学习广义李雅普诺夫函数的方法，通过将神经网络剩余项添加到RL价值函数中。该方法成功地为通过Gymnasium和DeepMind Control基准训练的RL策略进行了稳定认证。通过使用多步骤李雅普诺夫损失来联合训练神经控制器和稳定性证书，我们展示了比经典李雅普诺夫方法更大的认证内区域。", "conclusion": "我们提出的框架为具有学习策略的一类广泛的系统提供了稳定性认证，使证书更容易构建，从而实现了经典控制理论与现代基于学习的方法之间的桥梁。"}
{"llm_update_time": "20251210", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2502.14011", "html_url": "https://arxiv.org/abs/2502.14011", "title": "DFDT：边缘设备上物联网数据流挖掘的动态快速决策树", "title_en": "DFDT: Dynamic Fast Decision Tree for IoT Data Stream Mining on Edge Devices", "authors": "Afonso Lourenço,João Rodrigo,João Gama,Goreti Marreiros", "background": "物联网生成大量数据流，边缘计算成为在线物联网应用和5G网络的关键使能器。边缘解决方案支持实时机器学习推理，但需要持续适应概念漂移。虽然非常快速决策树（VFDT）的扩展仍然是表结构流挖掘的最先进方法，但其不受约束的增长限制了效率，尤其是在元学习设置中，通常很少在单个树级别进行后剪枝。", "innovation": "DFDT 是一种新颖的内存受限在线学习算法。DFDT 使用活动感知预剪枝，动态调整分裂条件基于叶子节点的活动：低活跃度节点被停用以节省资源；适中活跃度节点在更严格的条件下分裂；高度活跃度节点利用跳过机制加速成长。此外，自适应宽限期和互斥阈值使 DFDT 能根据观察到的数据变异性来调节分裂决策，优化精确度-内存-运行时权衡，同时减少超参数调整的需求。实验证明了三种适应不同类型资源配置的 DFDT 变体。DFDT 完全兼容现有的集成框架，提供了标准 VFDT 基于学习者的即插即用替代品。", "conclusion": "该论文提出了 DFDT，一种面向边缘设备的物联网数据流挖掘的动态快速决策树算法。DFDT 提供了一种同时优化精确度、内存使用和执行时间的新方法，并且完全兼容现有的集成框架。"}
{"llm_update_time": "20251210", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2503.10253", "html_url": "https://arxiv.org/abs/2503.10253", "title": "PIMRL: 物理先验多重尺度循环学习方法在空间时间预测中的应用", "title_en": "PIMRL: Physics-Informed Multi-Scale Recurrent Learning for Spatiotemporal Prediction", "authors": "Han Wan,Qi Wang,Yuan Mi,Hao Sun", "background": "空间时间系统的模拟，尤其是受偏微分方程控制的系统，在生物学、化学、航空航天动力学和气象学等领域得到了广泛应用。传统数值方法由于要求小时间步长以确保预测精度，计算成本较高。尽管机器学习在降低计算成本方面有所成效，但在长期预测中仍然面临误差累积的问题，尤其是在数据不足或时间尺度变化的场景中，稳定性和精确性受到影响。现有方法通常忽视了多尺度数据的有效利用，导致预测的鲁棒性不足。", "innovation": "本文提出了一种新的多重尺度学习框架——物理先验多重尺度循环学习（PIMRL），以有效利用多尺度数据对空间时间动力学进行预测。PIMRL框架由两个模块组成：微尺度模块通过预训练将物理知识嵌入神经网络，而宏尺度模块则采用数据驱动的方法在潜在空间中学习物理的时间演变。", "conclusion": "实验结果显示，PIMRL框架在从一维到三维的五个基准数据集中均实现了一流的性能，平均在RMSE和MAE评价指标上取得了超过9%的改进，最大优化幅度达到80%。"}
{"llm_update_time": "20251210", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2504.16828", "html_url": "https://arxiv.org/abs/2504.16828", "title": "思考过程奖励模型", "title_en": "Process Reward Models That Think", "authors": "Muhammad Khalifa,Rishabh Agarwal,Lajanugen Logeswaran,Jaekyeom Kim,Hao Peng,Moontae Lee,Honglak Lee,Lu Wang", "background": "过程奖励模型（PRMs）是测试时扩展的关键组件，但它们需要步骤级别的监督，这使得它们在训练时相当昂贵。这项工作旨在构建数据高效的PRMs，即通过生成验证链式思维（CoT）来逐步骤验证解决方案的口头步骤奖励模型。", "innovation": "提出了ThinkPRM，一种长期CoT验证器，只需要少于判别式PRMs所需过程标签数量级的标签进行微调。ThinkPRM利用长CoT模型的内置推理能力，在多个挑战性基准上超过了判别式验证器和LLM-as-a-Judge，仅使用PRM800K的1%过程标签。与判别式验证器相比，在GPQA-Diamond和LiveCodeBench子集上，我们的PRM分别超过了8%和4.5%。此外，在相同的标记预算下，ThinkPRM更有效地扩展验证计算，比LLM-as-a-Judge在ProcessBench子集上的表现提高了7.2%。", "conclusion": "本文展示了生成式、长期CoT过程奖励模型的价值，可以在测试时扩展验证计算，同时在训练时需要最少的监督。相关代码、数据和模型已在指定链接中公开。"}
{"llm_update_time": "20251210", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2505.20561", "html_url": "https://arxiv.org/abs/2505.20561", "title": "超越马尔可夫：基于贝叶斯自适应强化学习的大型语言模型反思性探索", "title_en": "Beyond Markovian: Reflective Exploration via Bayes-Adaptive RL for LLM Reasoning", "authors": "Shenao Zhang,Yaqing Wang,Yinxiao Liu,Tianqi Liu,Peter Grabowski,Eugene Ie,Zhaoran Wang,Yunxuan Li", "background": "大型语言模型（LLMs）通过强化学习（RL）训练展示了强大的推理能力和自省行为，如重新思考和错误修正，作为上下文内探索的一种形式。然而，传统RL训练得到的马尔可夫策略并不能引发反思探索行为，因为策略仅通过状态依赖于历史，没有动机去丰富相同状态中的额外上下文。因此，强化探索仅在训练过程中用于以试错方式学习最优策略。关于自省推理是否会在RL中出现及其益处仍不清楚。", "innovation": "我们重新将自省探索置于贝叶斯RL框架中，优化基于训练数据诱导的马可夫决策过程的后验分布下的预期回报。这种贝叶斯形式允许适应不确定性策略，通过信念更新自然激励信息收集行为，并诱导自省行为。我们提出的算法BARL指导LLM根据观察结果拼接和切换策略，提供在何时及如何进行自省探索的原理指导。", "conclusion": "我们在合成和数学推理任务上的实验证明，BARL在测试时的表现和标记效率方面均优于传统RL方法，表明BARL算法在LLM探索中的优越性。相关代码可在此处获取。"}
{"llm_update_time": "20251210", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.06954", "html_url": "https://arxiv.org/abs/2506.06954", "title": "通过风险敏感的行动价值迭代和分位数回归实现具有安全意识的强化学习控制", "title_en": "Safety-Aware Reinforcement Learning for Control via Risk-Sensitive Action-Value Iteration and Quantile Regression", "authors": "Clinton Enwerem,Aniruddh G. Puranic,John S. Baras,Calin Belta", "background": "主流的近似行动价值迭代增强学习（RL）算法会由于过度估计偏差而导致在高方差的随机环境中生成次优的策略。基于分位数的行动价值迭代方法通过使用分位数回归学习预期成本缩减了这种偏差，但在没有将安全性约束明确整合到RL框架中时，确保学习到的策略满足安全约束仍然是一个挑战。现有的方法往往需要复杂的神经网络结构或手动的代价函数结合。", "innovation": "本文提出了一种风险正则化的基于分位数的算法，通过条件价值-at-风险（CVaR）实现约束的安全性，无需复杂的架构。此外，该算法在Wasserstein空间中提供了风险敏感的分布贝尔曼算子收敛性的理论保证。", "conclusion": "仿真结果表明，该方法在动态回避任务中能获得更高成功率的目标，更少的碰撞，更好的安全性能权衡，优于无风险中性的方法。"}
{"llm_update_time": "20251210", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2505.19397", "html_url": "https://arxiv.org/abs/2505.19397", "title": "时间序列基础模型在部署前是否准备好？跨领域的对抗鲁棒性系统研究", "title_en": "Are Time-Series Foundation Models Deployment-Ready? A Systematic Study of Adversarial Robustness Across Domains", "authors": "Jiawen Zhang,Zhenwei Zhang,Shun Zheng,Xumeng Wen,Jia Li,Jiang Bian", "background": "时间序列基础模型（TSFMs）正迅速从研究原型转变为关键决策系统的核心组件，其原因是其出色的零样本预测能力。然而，随着其部署量的激增，一个关键的盲点出现了：它们在对抗攻击下的脆弱性。这种缺乏审视的风险，在TSFMs进入容易被操纵的高风险环境中时尤为严重。研究指出，对于TSFMs来说，稳健性不仅是一个次要指标，而是可信部署的前提，与其他关键标准类似或相当。研究团队开发了一个专门针对时间序列的独特约束的评估框架，该框架包括归一化、稀疏感知扰动预算和统一的白盒和黑盒设置下的尺度不变度量。研究结果表明，当前的架构存在明显的脆弱性：即使是小的扰动也能可靠地将预测引向特定的失败模式，如趋势反转和恶意漂移。", "innovation": "研究团队提出了一种系统性的诊断研究，强调对TSFMs的稳健性进行评估的重要性，并展示了一种专门针对时间序列的独特约束的评估框架。这个框架结合了归一化的、稀疏感知的扰动预算和在白盒和黑盒设置下统一的尺度不变度量。此外，研究发现了TSFMs特有的脆弱性模式，包括与预测周期临近的脆弱性、长期上下文窗口的增加敏感性以及模型特异性故障模式的弱跨模型转移。最后，研究结果表明，简单的对抗微调可以以成本有效的路径实现显著的稳健性提升，即使是在域外数据上。", "conclusion": "该项工作填补了TSFMs能力和安全性约束之间的差距，为加固下一代预测系统提供了宝贵指导。研究结果表明，TSFMs在对抗攻击下的脆弱性是一个严重的问题，需要在部署前进行严格的测试和改进。"}
{"llm_update_time": "20251210", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.15448", "html_url": "https://arxiv.org/abs/2506.15448", "title": "基于鲁棒同质性学习的半监督图异常检测", "title_en": "Semi-supervised Graph Anomaly Detection via Robust Homophily Learning", "authors": "Guoguo Ai,Hezhe Qiao,Hui Yan,Guansong Pang", "background": "半监督图异常检测（GAD）利用少数标记的正常节点来识别大量未标记节点中的异常节点。现有方法假设1）正常节点具有相似的同质性水平，2）标记的正常节点能很好地代表正常类中的同质性模式。然而，这种假设在实际场景中往往不适用，因为图中的正常节点可能表现出多样的同质性。", "innovation": "本文提出了一种新的方法RHO（Robust Homophily Learning，鲁棒同质性学习），它可以学习和适应图节点中多样化的同质性模式。RHO包含两个创新模块：可适应频率响应滤波器（AdaFreq）和图正态性对齐（GNA）。AdaFreq学习一组可适应的谱滤波器，捕捉标记正常节点在通道内和跨通道视图下的不同频率成分。GNA则通过增强两个视图中同质性表示的一致性来增强滤波器在两个视图中学习的正常性。", "conclusion": "在八个实际GAD数据集上的实验表明，RHO能够有效地学习小的正常节点集中多样的同质性模式，且显著优于最先进的竞争方法。"}
{"llm_update_time": "20251210", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.00808", "html_url": "https://arxiv.org/abs/2506.00808", "title": "图神经网络反遗忘攻击", "title_en": "Unlearning Inversion Attacks for Graph Neural Networks", "authors": "Jiahao Zhang,Yilong Wang,Zhiwei Zhang,Xiaorui Liu,Suhang Wang", "background": "图遗忘方法旨在不进行完全重新训练的情况下，高效地移除敏感数据对已训练的图神经网络（GNN）的影响。现有方法假设删除的信息不能被恢复。然而，这篇论文通过引入图遗忘逆向攻击（Graph Unlearning Inversion Attack）挑战了这一假设，证明即使仅有限的黑盒访问未遗忘的GNN和部分图知识，对手也能重建已删除的边。", "innovation": "本文识别出两个关键挑战：遗忘边与保留边的概率相似度阈值差异，以及定位遗忘边端点的难度。为此，作者提出了TrendAttack。具体而言，TrendAttack通过利用节点邻近未遗忘边时发生的大规模模型置信度下降的置信度陷阱，设计了一种自适应预测机制，并使用趋势特征扩展了现有的成员推断技术。实验表明，TrendAttack显著优于最先进的GNN成员推断基准，揭示了当前图遗忘方法中的一个关键隐私漏洞。", "conclusion": "实验结果表明，TrendAttack在四个真实数据集上显著优于最先进的GNN成员推断方法，揭示了当前图遗忘方法中的一个关键隐私漏洞。"}
{"llm_update_time": "20251210", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.09202", "html_url": "https://arxiv.org/abs/2507.09202", "title": "XiChen：一种具备四维变分知识的全AI驱动的全球天气预测系统，具有观测尺度的可扩展性", "title_en": "XiChen: An observation-scalable fully AI-driven global weather forecasting system with 4D variational knowledge", "authors": "Wuxin Wang,Weicheng Ni,Lilan Huang,Tao Hao,Ben Fei,Shuo Ma,Taikang Yuan,Yanlai Zhao,Kefeng Deng,Xiaoyong Li,Hongze Leng,Boheng Duan,Lei Bai,Weimin Zhang,Kaijun Ren,Junqiang Song", "background": "当前的天气预报模型依赖于高成本的数值天气预测（NWP）系统产生的初始条件。虽然有一些端到端的预报模型试图绕过NWP系统，但它们在处理新型观测数据方面缺乏可扩展性。", "innovation": "提出了XiChen，一种基于预训练的全AI驱动的全球天气预报系统，整个流程从数据同化到中期预报只需要15秒。XiChen利用一个预训练的基础模型，并对其进行了微调，使其能够作为观测算子和数据同化模型，从而能够对常规和原始卫星观测数据进行可扩展的同化。集成四维变分知识确保XiChen在数据同化和中期预报方面能够达到与操作性NWP系统相当的精度，且具有超过8.75天的预报时效。", "conclusion": "XiChen 在单点扰动数据同化实验中表现出类似传统四维变分系统的流动依赖特性，这表明XiChen具有在不依赖NWP系统的情况下进行全AI驱动天气预报的潜力。"}
{"llm_update_time": "20251210", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2505.24452", "html_url": "https://arxiv.org/abs/2505.24452", "title": "任意步长：预算迭代训练的统一学习率调度", "title_en": "Stepsize anything: A unified learning rate schedule for budgeted-iteration training", "authors": "Anda Tang,Yiming Dong,Yutao Zeng,zhou Xun,Zhouchen Lin", "background": "随着计算成本的增加和资源的限制，预算迭代训练变得至关重要，其目标是在预定的迭代预算内实现最优学习。传统的学习率调度方法缺乏理论基础，主要依赖于经验设定，这使得选择最优学习率的过程耗时且效率低下。特别是在受限的预算内进行训练时，不同的网络和任务对学习率的敏感性极大。因此，需要一种能够理论支持并且能够在不同条件下有效工作的统一学习率调度方法。", "innovation": "本文提出了一种统一的预算感知学习率调度（UBA），这是一种理论上支持的学习率调度方法，在不同的网络架构和任务条件下，能够在各类预算受限的训练过程中提供优于常用调度方法的表现。作者通过构建一个新的预算感知优化框架，把关于曲率变化鲁棒性的问题考虑进来，从而推导出了UBA调度。该调度通过单一超参数φ（它可以控制灵活性与简单性之间的权衡）来调整，无需针对每个网络进行数值优化。此外，论文还通过理论分析和实证结果提供了指导性的选择途径，并证明了对于不同的φ值调度的收敛性。", "conclusion": "广泛的实验验证了UBA调度在不同视觉和语言任务中的一致性优越性，无论是在什么类型的网络架构下，使用不同的训练迭代预算时都是如此。UBA调度为预算受限的训练环境提供了一个理论基础，并且简化了训练过程，提供了一种更为有效的选择学习率的方法。"}
{"llm_update_time": "20251210", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.17876", "html_url": "https://arxiv.org/abs/2507.17876", "title": "负向数据通过任务算术设计‘阳性’分子：另一种视角", "title_en": "Look the Other Way: Designing 'Positive' Molecules with Negative Data via Task Arithmetic", "authors": "Rıza Özçelik,Sarah de Ruiter,Francesca Grisoni", "background": "现有的分子设计方法受限于具有理想属性的分子（即‘阳性’分子）供应不足的问题。这成为生成式分子设计过程中的固有瓶颈。", "innovation": "本文提出了一种新的分子任务算术方法：利用丰富且多样化的‘阴性’示例进行模型训练，学习属性方向，并朝相反的方向移动模型以生成‘阳性’分子，无需访问任何正向标记数据。", "conclusion": "与正向分子训练模型相比，分子任务算术在多种设计实验中产生了更多样化且成功的‘阳性’分子设计。该方法在双重目标和少量示例设计任务中也表现出更高的多样性，同时保留了设计复杂性，如良好的蛋白质对接评分。该方法简单、高效且性能优越，具有成为从头分子设计领域事实上的迁移学习策略的潜力。"}
{"llm_update_time": "20251210", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2505.21972", "html_url": "https://arxiv.org/abs/2505.21972", "title": "LLMs评判LLMs：单纯形视角", "title_en": "LLMs Judging LLMs: A Simplex Perspective", "authors": "Patrick Vossler,Fan Xia,Yifan Mai,Adarsh Subbaswamy,Jean Feng", "background": "在评估大型语言模型（LLMs）的非形式化输出时，使用LLMs自身作为评估标准逐渐成为一种常见解决方案，但这种做法忽略了评价者质量的不确定性（epistemic不确定性），仅仅考虑了抽样变异（aleatoric不确定性）。虽然如果评价者完全准确，这种方法是可以被证明的，但是对于实际应用，何时以及在多大程度上这种方法是合理的和稳健的尚不明确。该研究从几何学角度探讨了这一问题，尤其对于从LLM候选人中进行排序的任务。", "innovation": "提出了一种新的几何视角，通过将LLM评分系统表示为单纯形上的点，并将关键的评分概念映射到几何概念（例如三角形面积），来研究评分的方法论条件和视觉证明。研究还设计了几何先验，编码了评价者质量的epistemic不确定性，并通过改变先验来开展敏感性分析。实验表明，仅基于LLM评价者的排名在许多但不是所有数据集中都是稳健的，并提出了一种贝叶斯方法，该方法相比现有方法能获得更高的覆盖率，突显了建模epistemic不确定性的重要性。", "conclusion": "实验结果表明，在许多数据集上使用LLM评价者的排名是稳健的，但并非在所有数据集上都如此，这既表明了它的广泛应用价值，也强调了其使用时需要谨慎。研究提出的贝叶斯方法达到了比现有方法更高的覆盖率，这进一步证明了建模评价者质量不确定性的重要性。"}
{"llm_update_time": "20251210", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.16302", "html_url": "https://arxiv.org/abs/2507.16302", "title": "针对扩散模型下游微调的抗脆弱安全驱动遗忘", "title_en": "Towards Resilient Safety-driven Unlearning for Diffusion Models against Downstream Fine-tuning", "authors": "Boheng Li,Renjie Gu,Junjie Wang,Leyi Qi,Yiming Li,Run Wang,Zhan Qin,Tianwei Zhang", "background": "文本到图像（T2I）扩散模型已经在图像生成质量上取得了显著的进步，并且越来越多地被用于个性化应用。然而，这些模型往往会从有毒预训练数据中继承不安全的行为，引发了越来越多的安全关注。虽然最近的安全驱动遗忘方法已经在抑制模型毒性方面取得了有前途的进展，但它们被发现对下游微调较为脆弱，我们揭示出最先进的方法在仅在完全无害的数据集上进行微调时，仍然难以保持其有效性。为了缓解这个问题，本文提出ResAlign，一种增强对下游微调抗脆弱性的安全驱动遗忘框架。", "innovation": "ResAlign通过将下游微调建模为具有Moreau包络重构的隐式优化问题，能够有效地估计梯度以最小化有害行为的恢复。此外，还提出了一种元学习策略来模拟多样的微调场景以提高泛化能力。实验结果表明，ResAlign在保持安全性方面始终优于先前的遗忘方法，同时有效地保留了生成无害内容的能力。", "conclusion": "广泛的数据集、微调方法和配置的实验结果证明，ResAlign在保留安全性方面始终优于先前的遗忘方法，同时有效保证了生成无害能力。我们的代码和预训练模型已公开可获取。"}
{"llm_update_time": "20251210", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.18926", "html_url": "https://arxiv.org/abs/2507.18926", "title": "几何多色消息传递图神经网络在血脑屏障渗透性预测中的应用", "title_en": "Geometric Multi-color Message Passing Graph Neural Networks for Blood-brain Barrier Permeability Prediction", "authors": "Trung Nguyen,Md Masud Rana,Farjana Tasnim Mukta,Chang-Guo Zhan,Duc Duy Nguyen", "background": "血脑屏障（BBB）通透性预测对于中枢神经系统（CNS）药物开发至关重要。虽然图神经网络（GNNs）在分子属性预测方面取得了进展，但它们通常依赖分子拓扑结构，忽略了模型传输机制至关重要的三维几何信息。", "innovation": "本论文提出了几何多色消息传递图神经网络（GMC-MPNN），这是一种创新框架，通过在标准消息传递架构中显式地整合原子级别的几何特征和长程相互作用，提高了模型性能。该模型通过基于原子类型构建加权彩色子图，以捕捉重要调控血脑屏障通透性的空间关系和化学背景。实验结果表明，GMC-MPNN 在基准数据集上的分类和回归任务中都优于现有最先进的模型。", "conclusion": "通过将空间几何引入图表示中，GMC-MPNN 设定了新的性能基准，并为药物发现管道提供了一个更准确且更通用的工具。"}
{"llm_update_time": "20251210", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.18240", "html_url": "https://arxiv.org/abs/2506.18240", "title": "量子-经典混合量化神经网络", "title_en": "Quantum-Classical Hybrid Quantized Neural Network", "authors": "Wenxin Li,Chuan Wang,Hongdong Zhu,Qi Gao,Yin Ma,Hai Wei,Kai Wen", "background": "该工作提出了一种新颖的基于二次二值优化（QBO）框架的量化神经网络训练方法。该框架通过样条插值支持任意激活和损失函数，并通过将激活函数离散化为线性子区间，使用前向区间传播解决了神经网络的非线性和多层复合结构问题。这种处理方法保留了神经网络泛化特性的同时，使复杂的非线性函数对量子求解器开放，从而在人工智能中有更广泛的应用。", "innovation": "该论文提出了一种QBO框架进行量化神经网络的训练，通过采用Quantum Conditional Gradient Descent (QCGD) 算法直接在量子硬件上解决Quadratic Constrained Binary Optimization (QCBO) 模型。同时，通过引入分解和共正优化方案，该方法减少了量子资源的需求，使低位量化神经网络的训练更加高效。理论分析部分，则得出了近似误差的上界以及所需的自旋数量，并提供了解决方案的时间上限。", "conclusion": "该工作通过量子-经典混合方法，成功解决了量化神经网络训练中的挑战，并为量子 solvers 在人工智能领域的应用提供了新的可能。"}
{"llm_update_time": "20251210", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.01504", "html_url": "https://arxiv.org/abs/2508.01504", "title": "基于指令的时序编辑", "title_en": "Instruction-based Time Series Editing", "authors": "Jiaxing Qiu,Dongliang Guo,Brynne Sullivan,Teague R. Henry,Thomas Hartvigsen", "background": "在时序编辑中，我们的目标是修改给定时序的某些属性而不改变其他属性。例如，在分析医院患者的血压时，可以通过添加一个突然的早期下降来观察其对未来的影响，同时保持其他条件不变。现有基于扩散的方法依赖于固定且预定义的属性向量作为条件，并通过采样生成全或无的编辑。这种基于属性和采样的方法在条件格式灵活性和编辑强度的自定义控制方面存在局限性。", "innovation": "为了克服这些局限性，该论文引入了基于指令的时序编辑，用户可以使用自然语言指定预期的编辑。这使得用户能够以更具可访问性的格式表达更广泛的编辑。随后，该论文提出了InstructTime，这是第一个基于指令的时序编辑器。InstructTime接收时序和指令，将它们嵌入到共享的多模态表示空间中，然后解码其嵌入生成修改后的时序。通过学习一个结构性的多模态表示空间，可以很容易地在嵌入之间进行插值以实现不同程度的编辑。为了同时处理局部和全局编辑，该论文提出了多分辨率编码器。", "conclusion": "在实验中，我们使用合成和真实数据集，发现InstructTime是目前最先进的时序编辑器。InstructTime能够实现高质量且可控强度的编辑，可以泛化到未知指令，并且可以通过少样本学习轻松适应未知条件。"}
{"llm_update_time": "20251210", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.16553", "html_url": "https://arxiv.org/abs/2506.16553", "title": "One Sample is Enough to Make Conformal Prediction Robust", "title_en": "One Sample is Enough to Make Conformal Prediction Robust", "authors": "Soroush H. Zargarbashi,Mohammad Sadegh Akhondzadeh,Aleksandar Bojchevski", "background": "对于任何黑盒模型，校准预测（CP）提供了包含真实标签的预测集，确保在一定可调置信水平内包含真实标签。增强校准预测（RCP）则将这种保证扩展到了最坏情况下的噪声，最高可以达到预定义的幅度。现有的方法如随机化光滑方法被广泛应用于RCP中，这种方法不仅可以广泛应用于任何黑盒模型，而且可以提供比确定性方法更小的预测集。然而，这种方法存在很大的计算开销，因为每次输入都需要进行多次模型前向传播。", "innovation": "本文提出了一种利用任何二元证书的一次样本增强校准预测（RCP1）方法，相比使用传统方法需要多次（例如100次）前向传播的说法，使用这种新方法产生的稳健集合平均集尺寸更小。本文的核心洞察是验证校准过程本身而不是单个一致性分数。此外，该方法在分类和回归任务上都是普适的，并进而在此基础上扩展到基于光滑方法的增强校准风险控制。", "conclusion": "本文介绍了一种新型的一次样本增强校准预测（RCP1）方法，该方法通过利用任何二元证书实现，能够在单次随机扰动输入的前向传播后产生更小的平均集尺寸的稳健预测集。该方法不仅在计算效率上优于传统方法，还能够适用于多种形式的任务。"}
{"llm_update_time": "20251210", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.20347", "html_url": "https://arxiv.org/abs/2506.20347", "title": "神经网络中的涌现格兰杰因果关系：仅预测是否可以揭示结构？", "title_en": "Emergent Granger Causality in Neural Networks: Can Prediction Alone Reveal Structure?", "authors": "Malik Shahid Sultan,Hernando Ombao,Maurizio Filippone", "background": "格兰杰因果关系（GC）提供了一个优雅的统计框架来研究多变量时间序列数据之间的关联。向量自回归模型（VAR）虽然简单易用，但由于其内在的局限性，仅适用于捕捉相对简单的关联（如非线性关系），因此应用范围有限。已有文献尝试利用深度神经网络（DNNs）的泛化能力来研究格兰杰因果关系，但主要将格兰杰因果关系视为变量选择问题。", "innovation": "本文提出了一种新颖的范式，用于通过单一神经网络联合建模所有时间序列数据成分来研究学习到的格兰杰因果关系结构，这实质上与预测和评估残差的分布偏移相关联。通过比较去除特定时间序列成分对模型不确定性或残差分布的影响，揭示了学习到的格兰杰因果关系结构。此外，对输入层丢弃对抗神经网络学习格兰杰因果关系的能力进行了比较。研究表明，适当正则化的模型可以从数据中学习真实的格兰杰因果关系结构，而无需在损失函数中显式添加引导模型选择变量或执行稀疏回归的项。本文还比较了CNN、LSTM和_transformer模型等深度学习架构在发现格兰杰因果关系方面的性能。", "conclusion": "研究表明，简单的联合模型相比于稀疏回归模型是一个强大的基线，用于学习真实的格兰杰因果关系。该方法的优势在于不需要调优许多额外的超参数。"}
{"llm_update_time": "20251210", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.02002", "html_url": "https://arxiv.org/abs/2508.02002", "title": "面向大规模自动广告竞价优化的生成预训练模型", "title_en": "Generative Large-Scale Pre-trained Models for Automated Ad Bidding Optimization", "authors": "Yu Lei,Jiayang Zhao,Yilei Zhao,Zhaoqi Zhang,Linyou Cai,Qianlong Xie,Xingxing Wang", "background": "现代自动竞价系统需要平衡整体性能与多样化的广告商目标和现实生活中的约束条件，反映了行业动态和不断变化的需求。近期，条件生成模型的进步，如变压器和扩散模型，使得能够直接生成针对广告商偏好的竞价轨迹，为传统基于马尔科夫决策过程的方法提供了有望的替代方案。然而，这些生成方法面临显著挑战，包括离线环境与在线环境之间的分布差异、动作空间的有限探索和满足边际成本每干次展示（CPM）和投资回报率（ROI）等约束的需求。", "innovation": "我们提出了GRAD（生成奖励驱动的广告竞价与专家混合模块），这是一种可扩展的基础模型，结合了动作专家混合模块以探索多样化的竞价行为和因果变压器的价值估计器以进行约束感知优化。GRAD在离线和在线实验中表现出色，证明了其在满足现代广告商不断变化和多样化要求方面的有效性。", "conclusion": "GRAD已在全球最大的在线餐饮配送平台之一美团的多个营销场景中实现，带来了2.18%的GMV增长和10.68%的ROI增长，进一步证明了其优越性。"}
{"llm_update_time": "20251210", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.10714", "html_url": "https://arxiv.org/abs/2507.10714", "title": "一种用于随机 Petri 网模型的简单近似贝叶斯推断神经拟似物", "title_en": "A Simple Approximate Bayesian Inference Neural Surrogate for Stochastic Petri Net Models", "authors": "Bright Kwaku Manu,Trevor Reckell,Beckett Sterner,Petar Jevtic", "background": "随机 Petri 网（SPNs）在传染病学和系统生物学等领域日益作为描述离散事件动态的工具受到青睐。然而，当过渡率依赖于外部协变量且确切的似然函数不可用时，参数估计仍面临挑战。", "innovation": "提出了基于神经网络的后验分布近似框架，直接从嘈杂的、部分观察到的标记轨迹预测协变量依赖率函数的系数。该模型使用了轻量级的 1D 卷积残差网络，在吉尔贝斯模拟的 SPN 表现上进行端到端训练，学会在事件丢失的现实条件下反向系统动力学。推理阶段使用蒙特卡洛dropout 提供校准的不确定性界和点估计。", "conclusion": "在具有 10% 缺失事件的合成 SPNs 上，该拟似物能够实现 RMSE = 0.043 的率函数系数恢复，并且比传统贝叶斯方法执行速度快得多。这些结果表明，数据驱动的、无似然的近似拟似物可以实现复杂部分观测离散事件系统的准确、稳健和实时参数恢复。"}
{"llm_update_time": "20251210", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.06066", "html_url": "https://arxiv.org/abs/2508.06066", "title": "时空网络的架构感知泛化边界：理论与公平比较方法", "title_en": "Architecture-Aware Generalization Bounds for Temporal Networks: Theory and Fair Comparison Methodology", "authors": "Barak Gahtan,Alex M. Bronstein", "background": "深度时序架构如TCNs在序列数据上显示出强大的预测性能，但对其泛化性的理论理解仍然有限。", "innovation": "1. 提出了一种评估时序模型的新方法，固定有效样本大小以隔离时序结构效应和信息内容。\n2. 通过这种方法揭示了强依赖序列（相关性为0.8）的泛化误差比弱依赖序列（相关性为0.2）大约小76%，这挑战了先前认为独立性普遍阻碍学习的观点。\n3. 找到了与目前理论预测不一致的收敛率，这些模型利用了问题结构，但当前理论未能捕捉到这一点。\n4. 开发了第一个深入时空模型的架构感知泛化边界，适用于指数β-混合序列，通过嵌入Golowich等人的独立样本边界到一个新颖的分割方案中，该方案将N个样本分割成约B≈N/ log N的准独立块，确立凸Lipschitz损失下的多项式样本复杂性，避免了指数依赖。", "conclusion": "提出的框架展示了深度时序模型的泛化边界，通过保守的边界证明了学习能力，并确定了架构的扩展规律，明确了未来理论需要改进的方向。"}
{"llm_update_time": "20251210", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.07631", "html_url": "https://arxiv.org/abs/2508.07631", "title": "Efficient Approximate Posterior Sampling with Annealed Langevin Monte Carlo", "title_en": "Efficient Approximate Posterior Sampling with Annealed Langevin Monte Carlo", "authors": "Advait Parulekar,Litu Rout,Karthikeyan Shanmugam,Sanjay Shakkottai", "background": "该论文研究了基于分数生成模型中的后验采样问题。已有一个针对先验$p(x)$的训练好的得分网络和一个测量模型$p(y|x)$，任务是从后验$p(x|y)$中采样。先前的研究表明，在最坏情况下以KL散度为衡量标准是不可行的，但诸如图像超分辨率、风格化和重建等常见任务的流行算法仍表现出实际的应用效果。", "innovation": "本文通过一种在最小假设下的“倾斜”问题，展示了可以同时在KL散度和Fisher散度下从一个分布中进行可计算的采样，这个分布接近于噪声先验的后验以及真实的后验。这是首次对于(近似)后验采样的形式化结果和在多项式时间内实现的有效采样算法。", "conclusion": "论文展示了如何利用退火朗格维蒙特卡罗算法实现高效近似后验采样，该方法能够同时保持与先验和测量数据的一致性，从而提供一个有效的解决方案。"}
{"llm_update_time": "20251210", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.01888", "html_url": "https://arxiv.org/abs/2508.01888", "title": "使用增强学习和区块链优化日前电力交易", "title_en": "Optimizing Day-Ahead Energy Trading with Proximal Policy Optimization and Blockchain", "authors": "Navneet Verma,Ying Xie", "background": "可再生能源在日前电力市场中的渗透增加了供需平衡、电网韧性维护以及在去中心化交易系统中保持信任的挑战。现有方法难以应对这些挑战。", "innovation": "提出了一个新颖的框架，该框架结合了Proximal Policy Optimization (PPO) 算法和区块链技术，以优化分布式能源生产者（prosumers）在日前电力市场中的自动交易策略。该框架包括使用强化学习（RL）代理进行多目标能源优化，以及使用区块链确保数据和交易的防篡改性。实验证明该方法有效，RL代理可实现2%以内的供需平衡，并维持大部分运营时间内接近最优的供应成本。", "conclusion": "通过结合Proximal Policy Optimization (PPO) 算法和区块链技术，提出了一个创新的系统架构。RL代理不仅实现了供需平衡，还制定了能够应对太阳能和风能波动性的电池存储策略。所有决策记录在基于Algorand的区块链上，确保了透明度、可审计性和安全性，这对于多智能体能源交易的信任至关重要。"}
{"llm_update_time": "20251210", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.22786", "html_url": "https://arxiv.org/abs/2507.22786", "title": "密度算子期望最大化", "title_en": "Density Operator Expectation Maximization", "authors": "Adit Vishnu,Abhay Shastry,Dhruva Kashyap,Chiranjib Bhattacharyya", "background": "随着量子计算的迅速发展，基于密度算子的机器学习方法越来越多地受到关注。然而，基于密度算子的生成模型还无法处理概率模型可以轻松处理的任务。隐变量模型是一类广泛且有影响力的概率无监督模型，其进展主要由期望最大化框架推动。然而，由于算子的非可交换性，为密度算子推导此类框架是具有挑战性的。", "innovation": "该研究提出了基于密度算子的期望最大化（DO-EM）框架，该框架通过利用相对熵的单调性不等式作为证据下界来解决隐变量模型中隐含变量的非可交换性问题。特别地，DO-EM的期望步骤被证明是Petz恢复映射。通过信息几何的论证，该研究对量子受限玻尔兹曼机进行了应用，并提出了量子交错深度玻尔兹曼机和量子高斯-伯努利受限玻尔兹曼机两种新模型，这些模型在使用相似计算资源和相同超参数的情况下，在生成任务上的表现优于其概率对应模型。", "conclusion": "DO-EM提供了一种训练通过密度算子定义的隐变量模型的一般框架，从而达到了新的生成模型的性能。这为量子机器学习提供了重要的理论基础和实用工具。"}
{"llm_update_time": "20251210", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.06041", "html_url": "https://arxiv.org/abs/2508.06041", "title": "DP-LLM：基于动态逐层精度分配的运行时模型自适应", "title_en": "DP-LLM: Runtime Model Adaptation with Dynamic Layer-wise Precision Assignment", "authors": "Sangwoo Kwon,Seong Hoon Seo,Jae W. Lee,Yeonhong Park", "background": "在处理具有不同运行时约束（如延迟和精度）的大规模语言模型（LLMs）上设备查询时，有效处理方法仍然是一个挑战。多尺度量化提供了一种解决方案，通过在不同位宽上量化多个模型变体的形式，使LLMs的运行时模型适应更加节能减排。然而，如何正确配置模型以匹配特定的精度或延迟目标仍是一个未解决的问题。", "innovation": "作者提出了DP-LLM，一种新型机制，根据输入值动态分配每层的精度。该机制基于观察到的每个层在解码步骤中的敏感度动态变化这一关键洞察。实验结果表明，DP-LLM 在性能-延迟权衡方面表现出优越性，优于之前的方案。", "conclusion": "实验结果表明，DP-LLM 在多个模型和基准上实现了性能-延迟最优的权衡，优于先前的方法。"}
{"llm_update_time": "20251210", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.08005", "html_url": "https://arxiv.org/abs/2508.08005", "title": "从传统机器学习到双通道GAT-MLP：学习选择MCP算法", "title_en": "Learning to Select MCP Algorithms: From Traditional ML to Dual-Channel GAT-MLP", "authors": "Xiang Li,Shanshan Wang,Chenglong Xiao", "background": "最大团问题（MCP）是一个基础的NP难问题，具有广泛的应用。尽管有许多算法，但在不同类型的图实例中没有一个算法能够始终优于其他算法。这突显了实例感知算法选择的紧迫需求，特别是在MCP领域仍处于探索阶段。通过训练框架，将传统的机器学习与图神经网络相结合，提出了一种新方法来解决这一问题。在此过程中，构建了一个基准数据集，通过四种先进的精确MCP解决程序在多样化的图形集合上运行并提取其结构特征来实现。传统分类器的评估表明随机森林是一个强大的基准，并表明连接性和拓扑特征是性能的关键预测因素。基于这些见解，开发了GAT-MLP双重通道模型，它结合了图注意网络（GAT）来编码局部图结构，并结合多层感知器（MLP）来建模全局特征。", "innovation": "提出了一个基于学习的实例感知算法选择框架，结合了传统机器学习和图神经网络。构建了一个基准数据集，通过多种最先进的精确MCP解算器在多样化的图集中执行并提取其结构特征。开发了GAT-MLP双重通道模型，将图注意力网络（GAT）用于局部图结构编码，使用多层感知器（MLP）来模拟全局特征。实验结果表明，GAT-MLP在所有基线方法中取得了最佳且一致的性能，准确率高达90.43%。", "conclusion": "此工作通过引入GAT-MLP双重通道模型揭示了图神经网络在组合算法选择中的潜力。该模型的成功验证了双重通道架构的有效性。所提供的基准数据集和模型可通过提供的链接获取。"}
