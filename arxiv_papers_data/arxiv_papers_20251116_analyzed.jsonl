{"llm_update_time": "20251116", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.09570", "html_url": "https://arxiv.org/abs/2511.09570", "title": "基于变邻域搜索的电动车辆路线问题", "title_en": "Variable Neighborhood Search for the Electric Vehicle Routing Problem", "authors": "David Woller,Viktor Kozák,Miroslav Kulich,Libor Přeučil", "background": "电动车辆路线问题（EVRP）扩展了经典的车辆路线问题（VRP），以反映物流中使用电动和混合动力车辆的增长趋势。由于文献中考虑了各种约束条件，不同问题变体之间的方法比较仍然具有挑战性。CEC-12竞赛在2020年IEEE计算智能世界大会期间针对EVRP中的精简变体——容量受限的绿色车辆路线问题（CGVRP）进行了评估。", "innovation": "本研究引入了一种基于变邻域搜索（VNS）元启发式方法的竞赛获胜策略，该方法在完整竞赛数据集上取得了最佳结果，并且优于之后发布的另一种算法。", "conclusion": "该论文展示了在CEC-12竞赛中获胜的方法，该方法在EVRP上取得了最佳性能，并且在与其他后来的算法比较中表现优越。"}
{"llm_update_time": "20251116", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.09600", "html_url": "https://arxiv.org/abs/2511.09600", "title": "合乎逻辑的论据扩展是弱可接受的，但反之则不然", "title_en": "Cogent argument extensions are weakly admissible but not vice versa", "authors": "Gustavo Bodanza", "background": "本文探讨了两个非认可的论证框架语义学之间的关系：合乎逻辑的语义学和弱可接受语义学。背景在于论证框架理论在人工智能和信息科学中具有重要意义，但关于这两种语义学的对比和关系研究相对较少，因而该研究填补了这方面的一个空白。", "innovation": "研究证明了合乎逻辑的扩展是弱可接受的，但弱可接受的扩展不一定就是合乎逻辑的。这一发现为论证框架语义学的研究提供了一个新的视角，并强调了这两种语义学之间的差异性。", "conclusion": "本文展示了合乎逻辑的扩展是弱可接受的，但反之则不成立。这意味着在论证框架中，虽然所有合乎逻辑的扩展都是弱可接受的，但并非所有弱可接受的扩展都是合乎逻辑的。"}
{"llm_update_time": "20251116", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.09788", "html_url": "https://arxiv.org/abs/2511.09788", "title": "为什么小型开放人工智能模型对交互艺术很重要", "title_en": "Why Open Small AI Models Matter for Interactive Art", "authors": "Mar Canet Sola,Varvara Guljajeva", "background": "本文背景在于当前交互艺术实践中主要是依赖大型、封闭源代码的商业系统，这些系统作为黑盒子存在，对互动艺术作品施加了诸多限制，包括内容过滤、保存问题和技术挑战，如增加的延迟和有限的接口等。", "innovation": "研究创新之处在于提倡使用小型开放源代码的人工智能模型，以提高艺术家的创意独立性和控制权。小型模型部署在本地，允许艺术家在其基础设施和代码中获取更多的控制权，具有更大的自主权、控制权和可持续性。这种模型不仅能够让艺术家长期使用模型、自定义模型，还可以通过修改代码整合新接口，或者通过新的数据集重新训练或微调模型，从而促进技术上的自我决定，提供更强大的所有权以及减少对不适合交互艺术需求的商用AI的依赖。", "conclusion": "本文探讨了在交互艺术中使用小型开放源代码人工智能模型的实际应用和重要意义，表明与封闭源代码的替代方案相比，开放式小型模型能够更好地支持艺术品的长期保存与展示。"}
{"llm_update_time": "20251116", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.09572", "html_url": "https://arxiv.org/abs/2511.09572", "title": "SynthTools：为智能体开发扩展合成工具的框架", "title_en": "SynthTools: A Framework for Scaling Synthetic Tools for Agent Development", "authors": "Tommaso Castellani,Naimeng Ye,Daksh Mittal,Thomson Yen,Hongseok Namkoong", "background": "AI智能体越来越多地依赖外部工具来解决复杂的长期任务。克服这些智能体的发展挑战需要可重复的评估和在可控、多样化且具现实性的工具使用环境中的大规模训练。然而，真实世界的API在可用性、领域覆盖率和稳定性方面有限，经常需要访问密钥并施加速率限制，这对稳定评估或大规模训练造成了实际困难。", "innovation": "我们引入了SynthTools，这是一个灵活且可扩展的框架，用于生成合成的工具生态系统。框架包含三个核心组件：工具有机生成、工具模拟以模拟真实的工具行为，以及工具有机审计以确保工具模拟的正确性和一致性。此外，展示了SynthTools可以轻松生成涵盖更多领域和更多工具的工具集，同时工具模拟和工具有机审计组分展示了极高的可靠性。", "conclusion": "通过提供可扩展、多样化的可靠工具生态系统，SynthTools提供了一条实际路径，用于大规模训练和稳定评估工具使用智能体。我们的代码可以在以下链接找到：this https URL."}
{"llm_update_time": "20251116", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.09682", "html_url": "https://arxiv.org/abs/2511.09682", "title": "Rebellion: 音频推理模型的鲁棒性训练", "title_en": "Rebellion: Noise-Robust Reasoning Training for Audio Reasoning Models", "authors": "Tiansheng Huang,Virat Shejwalkar,Oscar Chang,Milad Nasr,Ling Liu", "background": "在大型模型（LMs）中注入推理能力可以通过推理训练（RT）显著提高LMs的表现。由此，具有推理能力的音频模型（Audio Reasoning Models, ARMs）逐渐受到青睐。然而，关于ARMs在遭受旨在引发有害响应的‘牢笼突破’攻击中的安全性问题，没有相关研究进行探讨。", "innovation": "本文首次展示了标准的推理训练与合适的安全推理数据可以保护ARMs免受普通的音频‘牢笼突破’攻击，但未能抵御作者提出的一种简单而有效的‘牢笼突破’。作者进一步指出，这是因为普通和高级‘牢笼突破’之间存在显著的表示漂移，迫使目标ARMs发出有害响应。基于这一观察，本文提出了Rebellion，这是一种鲁棒的训练方法，旨在让ARMs对最坏情况的表示漂移具有抵抗力。这一方法在Qwen2-Audio上进行了验证，结果表明Rebellion不仅能保护ARMs免受高级音频‘牢笼突破’攻击，同时在良性任务上不降低性能，还显著改善了准确性和安全性之间的权衡关系。", "conclusion": "Rebellion方法能够保护ARMs免受高级音频‘牢笼突破’攻击，同时在良性任务上保持性能，显著改善了准确性和安全性之间的权衡。"}
{"llm_update_time": "20251116", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.09575", "html_url": "https://arxiv.org/abs/2511.09575", "title": "Proceedings of the Second International Workshop on Next-Generation Language Models for Knowledge Representation and Reasoning (NeLaMKRR 2025)", "title_en": "Proceedings of the Second International Workshop on Next-Generation Language Models for Knowledge Representation and Reasoning (NeLaMKRR 2025)", "authors": "Ha-Thanh Nguyen,Ken Satoh,Francesca Toni,Randy Goebel,Kostas Stathis", "background": "推理是人类智能的关键组成部分，它在我们需要批判性思考、支持负责任决策和解决复杂问题时发挥着重要作用。传统上，AI已在基于逻辑的知识表示的背景下处理推理。但随着自然语言处理的近期进步，尤其是基于变换器的语言模型的出现，暗示这些模型可能具有推理能力，尤其是在它们规模扩大并接受更多数据训练后。尽管如此，关于语言模型中的推理是什么以及它们真正具有多强的推理能力仍在讨论，仍难以明确指出一直到什么程度这些模型具备推理能力。", "innovation": "本次研讨会旨在为来自不同学科或不同AI视角的研究者提供一个平台，探索如何通过变压器驱动的语言模型和技术手段来实现与基于逻辑的知识表示相结合的推理。具体目标包括分析语言模型的推理能力与知识表示方法的对比，将知识表示风格的推理能力注入语言模型（包括神经符号方法），并正式化语言模型执行的推理类型，从而深入发现语言模型如何有效整合和利用知识和推理以改善其在关键精确性和可靠性要求领域的应用和效果。", "conclusion": "希望通过这次研讨会，确定语言模型如何在保留和利用知识的同时进行推理，使之在需要高精度和可靠性的领域中更具应用价值和实用价值。"}
{"llm_update_time": "20251116", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.09785", "html_url": "https://arxiv.org/abs/2511.09785", "title": "AI标注编排：评估LLM验证者以提高学习分析中LLM注释质量", "title_en": "AI Annotation Orchestration: Evaluating LLM verifiers to Improve the Quality of LLM Annotations in Learning Analytics", "authors": "Bakhtawar Ahtisham,Kirk Vanacore,Jinsook Lee,Zhuqian Zhou,Doug Pietrzak,Rene F. Kizilcec", "background": "大型语言模型（LLMs）被越来越多地用于标注学习互动，但是由于可靠性方面的担忧限制了它们的应用。这项研究评估了通过验证导向的编排提示模型（自验证或交叉验证）来检查标注结果是否能够提高对辅导对话的定性编码质量。", "innovation": "研究贡献了：（1）一种灵活的编排框架，包含控制、自验证和交叉验证；（2）在虚拟辅导数据中，通过盲法人工“黄金”标准对前沿LLM进行实证比较；（3）一种简洁的记号系统，如verifier(annotator)（例如Gemini(GPT)或Claude(Claude)）用于标准化报告，使方向性效果明确得以复制。结果表明验证作为一种原理性的设计理念，有助于提高LLM辅助注释在学习分析中的可靠性和可扩展性。", "conclusion": "该研究表明，编排能够使跨LTM的标注一致性提高58%，并且自验证将一致性几乎翻倍相比未验证的基础线，而对于具有挑战性的辅导行为，这种提升更为显著。交叉验证则平均改善了37%的一致性，但表现存在配对标记验证者对之间的差异，反映了验证者严格度的不同。这些结果表明验证是确保学习分析中LLM注释可靠性的合适设计杠杆。"}
{"llm_update_time": "20251116", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.09710", "html_url": "https://arxiv.org/abs/2511.09710", "title": "Echoing: 负交互时LLM代理之间的身份失败", "title_en": "Echoing: Identity Failures when LLM Agents Talk to Each Other", "authors": "Sarath Shekkizhar,Romain Cosentino,Adam Earle,Silvio Savarese", "background": "随着基于大型语言模型（LLM）的代理自主交互，一种新的失败类型出现了，即代理-代理对话（AxA）中行为漂移，这是无法从单个代理性能预测的。与人类与代理交互不同，人类能够通过引导和接地来稳定对话，但AxA缺乏这些信号，因此这些失败是独特的。研究发现，一种特定的行为漂移现象——回声——其中代理放弃其分配的角色，反而复制其对话伙伴，干扰了其预期目标。", "innovation": "通过跨60种AxA配置、3个领域和2000多次对话的实验，该研究揭示了回声现象在三大主要LLM提供商中普遍存在，回声率从5%到70%不等。更重要的是，即使在高级推理模型中也观察到了持久的回声现象，即使在增加推理努力的情况下回声率也未降低至较低水平（达到了32.8%）。研究还分析了提示效果和对话动态，指出回声随对话次数增加（实验中超过7轮）而出现，并非仅仅提示不理想的结果。最后，研究提出了一种协议层面的缓解措施，在此措施中针对性地使用结构化响应将回声率降至9%。", "conclusion": "研究中揭示的回声现象是一种新的代理-代理交互失败形式，并且在不同模型和领域中普遍存在。尽管高级模型中有较高的回声率，但单纯的推理输入并未减少这种现象。结构化响应的使用可以有效降低回声率。"}
{"llm_update_time": "20251116", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.09768", "html_url": "https://arxiv.org/abs/2511.09768", "title": "ProbLog4Fairness: 一种基于神经符号方法建模和缓解偏见的方法", "title_en": "ProbLog4Fairness: A Neurosymbolic Approach to Modeling and Mitigating Bias", "authors": "Rik Adriaensen,Lucas Van Praet,Jessa Bekker,Robin Manhaeve,Pieter Delobelle,Maarten Buyl", "background": "在实际操作中，公平性的定义可能存在冲突，尽管每个定义都有其合理性。通过直接基于特定真实世界的任务描述算法偏见，并结合背景中的系统性偏见信息，可能会更容易缓解偏见。然而，目前缺少一种同时具有原则性、灵活性和可解释性的框架来整合这些假设。通过将偏见假设形式化为ProbLog程序（一种概率逻辑编程语言），并结合神经符号扩展，使得在神经网络训练过程中更容易整合这些假设，从而缓解偏见问题。尽管如此，缺乏一个同时具备原则性、灵活性和可解释性的框架来整合这些假设仍然是一个挑战。", "innovation": "本文提出了一种方法，即将偏见假设形式化为ProbLog程序，并结合神经符号扩展，使得在神经网络训练过程中更容易整合这些假设，缓解偏见问题。通过对具体类型的偏见使用模板进行表达，并在合成表数据集中展示了方法的适用性。通过估计存在偏见失真的情况下，成功缓解了具有偏见的现实世界表数据和图像数据中的算法偏见。这种基于ProbLog的方法因其能够灵活地建模相关的偏见假设而优于基线方法，而其他方法通常维持固定的偏见类型或公平性的概念。", "conclusion": "ProbLog4Fairness 方法因能够灵活地建模相关的偏见假设而优于基线方法，这种基于概率逻辑编程和神经符号扩展的方法成功解决了偏见问题，并展示了其在多种数据集上的灵活性和有效性。"}
{"llm_update_time": "20251116", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.09563", "html_url": "https://arxiv.org/abs/2511.09563", "title": "通过部分联合路由分配和大α优化的一种高效且几乎最优的解算器", "title_en": "An Efficient and Almost Optimal Solver for the Joint Routing-Assignment Problem via Partial JRA and Large-α Optimization", "authors": "Qilong Yuan", "background": "之前的研究引入了精确的混合整数规划 (MIP) 求解器，并提供了相关数据集和 Gurobi 实现，表明虽然精确方法能够保证最优性，但对于大规模实例则变得计算效率低下。基于此限制，提出了合并算法和摇晃过程为基础的启发式方法，这些方法能够以约1%的偏差找到近似最优解。本文研究了大规模联合路由分配 (JRA) 问题，发展了一种新的、更有效的解决方法，能够获得高精度的近似最优解。这种方法引入了一种部分路径重建 (PPR) 求解器，首先确定关键项位对形成简化子问题，高效求解以细化全局解决方案。研究使用 PJAR 框架进一步改进初始启发式合并解决方案，减少偏差一半。此外，还引入了一个全局大α约束到 JRA 模型中，进一步增强解决方案的最优性。实验结果表明，该方法在基准数据集 n=300, 500, 1000 的情况下，可以提供几乎最优解，偏差接近于零，同时保持高效性。该框架和方法还展示了将其应用于旅行商问题 (TSP) 和相关优化问题的广阔潜力。", "innovation": "提出了一种新的部分路径重建 (Partial Path Reconstructon, PPR) 求解器，通过先识别关键项位对来形成简化子问题，并高效求解以优化全局解决方案。引入了 PJAR 框架，进一步改进了初始启发式合并解决方案，显著减少了偏差，并通过沿优化路径迭代优化，得到高精度路径。此外，将全局大α约束引入了 JRA 模型中，进一步提升了解的最优性。", "conclusion": "实验表明，所提出的方法能够提供几乎最优的解决方案，且保持高效率。该方法不仅限于 JRA 问题，还展示了在 TSP 以及其他相关优化问题上的广泛应用潜力。"}
{"llm_update_time": "20251116", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.09829", "html_url": "https://arxiv.org/abs/2511.09829", "title": "针对AI surveillance系统的热激活双模态对抗穿着", "title_en": "Thermally Activated Dual-Modal Adversarial Clothing against AI Surveillance Systems", "authors": "Jiahuan Long,Tingsong Jiang,Hanqing Liu,Chao Ma,Wen Yao", "background": "对抗补丁已成为一种流行的隐私保护方法，用于抵抗AI驱动的监视系统。然而，它们显眼的外观使它们难以在现实世界场景中部署。现有研究中，衣服在默认状态下看起来是普通的黑色T恤。通过嵌入的热单元加热后，隐藏在织物中的对抗模式会激活，使佩戴者能够在可见光和红外模式下有效避开检测。", "innovation": "这项研究提出了一种热激活的对抗穿戴装备，它通过热致变色染料与柔性加热单元的结合，在服装表面上诱导视觉动态的对抗模式。该系统设计实现了可适应性和在复杂现实环境中的有效性。物理实验表明，对抗穿戴装备在50秒内实现了快速纹理激活，并在多种现实世界监控环境中保持超过80%的对抗成功率。", "conclusion": "这项工作展示了新一代物理基础可控的反AI系统的途径，强调了在AI普遍监控时代对抗技术对于隐私保护的日益增长的重要性。"}
{"llm_update_time": "20251116", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.09822", "html_url": "https://arxiv.org/abs/2511.09822", "title": "在渐进增强决策树上实现稳健的水印", "title_en": "Robust Watermarking on Gradient Boosting Decision Trees", "authors": "Jun Woo Chung,Yingjie Lao,Weijie Zhao", "background": "梯度提升决策树（GBDTs）在工业和学术界因其高准确性和效率而被广泛使用，特别是在结构化数据上。然而，与神经网络相比，GBDT模型的水印化研究尚未充分展开。本文提供了首个针对GBDT模型的稳健水印框架，采用原位微调方法将难以察觉且具有高稳定性的水印嵌入模型中。通过跨不同数据集的实验表明，该方法具有较高的水印嵌入率、低准确度下降和对部署后微调的强大抗性。", "innovation": "本文提出的稳健水印框架是首个专门为GBDT模型设计的，利用原位微调技术将难以察觉且稳定性的水印嵌入模型中。提出了四种嵌入策略，旨在最小化对模型准确度的影响的同时保证水印的稳定性。", "conclusion": "本文的方法在多种数据集上的实验结果表明，实现了高水印嵌入率、低准确度下降以及对部署后微调的强抗性，证明了在GBDT模型上实现稳健水印的有效性和实用性。"}
{"llm_update_time": "20251116", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.09804", "html_url": "https://arxiv.org/abs/2511.09804", "title": "SlideBot: 多智能体生成框架，用于生成信息丰富、可靠、多模态演示文稿", "title_en": "SlideBot: A Multi-Agent Framework for Generating Informative, Reliable, Multi-Modal Presentations", "authors": "Eric Xie,Danielle Waterfield,Michael Kennedy,Aidong Zhang", "background": "大型语言模型（LLMs）在教育中显示出巨大的潜力，主要用于自动化像生成测验、内容摘要等任务。然而，生成有效的演示文稿引入了独有的挑战，因为多模态内容的复杂性以及需要精准和领域特定的信息。现有的基于LLM的解决方案通常无法产生可靠的和信息丰富的输出，限制了它们的教育价值。", "innovation": "本文介绍了一种名为SlideBot的多智能体演示文稿生成框架，将大语言模型与检索、结构化规划和代码生成相结合。SlideBot围绕三个支柱构建：信息性（确保深度和上下文相关的内容）、可靠性（通过引入外部资源实现）和实用性（通过教员协作实现定制和迭代反馈）。该框架结合了基于证据的认知负荷理论（CLT）和多媒体学习认知理论（CTML）的原则，使用结构化规划管理内在负荷，并通过一致的视觉宏减少外在负荷，增强双通道学习。评估表明，SlideBot在概念准确度、清晰度和教学价值方面表现出色，明显提高了演示文稿的准备效率，同时确保了准确性、相关性和适应性，特别是在人工智能和生物医学教育领域。", "conclusion": "这些发现证明了SlideBot在提高演示文稿准备效率、准确性和适应性方面具有潜在价值，尤其是在高等教育中。"}
{"llm_update_time": "20251116", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.09914", "html_url": "https://arxiv.org/abs/2511.09914", "title": "_OIDA-QA: 分析阿片类药物行业文件档案的多模态基准", "title_en": "OIDA-QA: A Multimodal Benchmark for Analyzing the Opioid Industry Documents Archive", "authors": "Xuan Shen,Brian Wingenroth,Zichao Wang,Jason Kuen,Wanrong Zhu,Ruiyi Zhang,Yiwei Wang,Lichun Ma,Anqi Liu,Hongfu Liu,Tong Sun,Kevin S. Hawkins,Kate Tasker,G. Caleb Alexander,Jiuxiang Gu", "background": "阿片类药物危机揭示了监管系统、医疗实践、公司治理和公共政策之间的系统性不足。为了评估这些系统在防止健康问题上的失败，需要使用创新的分析方法来处理UCSF-JHU阿片类药物行业文档档案（OIDA）中披露的大数据和文档。这些文档具有复杂性、多元性和专业性，需要针对性和详细的标注方法，以确保分析的精确性和专业性。", "innovation": "本文通过根据文档属性组织原始数据并构建一个包含40万训练文档和1万个测试文档的基准，提出了开发领域专用的多模态大型语言模型，并探索多模态输入对任务性能的影响。通过引入历史问答对作为当前查询的上下文基础、页引用以及基于重要性分类器，提高了信息的准确性和相关性。初步结果显示，基于本文提出的人工智能助手在文档信息提取和问答任务上的改进。数据集和模型可在特定网址获取。", "conclusion": "本研究通过构建一个大型多模态基准，为分析阿片类药物行业文档档案提供了新的方法和工具，并展示了其在提高信息提取和问答任务中的有效性。"}
{"llm_update_time": "20251116", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.09907", "html_url": "https://arxiv.org/abs/2511.09907", "title": "学习提出问题：为大型推理模型的推理驱动和求解器自适应数据合成", "title_en": "Learning to Pose Problems: Reasoning-Driven and Solver-Adaptive Data Synthesis for Large Reasoning Models", "authors": "Yongxian Wei,Yilin Zhao,Li Shen,Xinrui Chen,Runxi Cheng,Sinan Du,Hao Yu,Gang Liu,Jiahong Yan,Chun Yuan,Dian Li", "background": "数据合成用于训练大型推理模型提供了一种 scalable 的替代方案，可以产生高质量的数据，但现有的方法存在挑战：（i）无差别的生成数据，忽视了解算器的能力，导致低质量的问题生成；或依赖复杂的数据管道来平衡问题难度；（ii）缺乏在问题生成过程中的推理，导致问题变体较为浅显。", "innovation": "我们开发了一个问题生成器，该生成器在合成之前会显式地进行推理来规划问题方向，并根据解算器的能力调整问题难度。具体来说，我们构建了一系列相关的问题对，并通过合理的推理模型生成了中间的问题设计步骤（解决方案路径）。这些数据使生成器能够从生成策略中获得反馈，将解算器对合成问题的反馈作为奖励信号，从而使生成器能够校准并调整问题难度，生成与解算器能力匹配的问题，进一步生产相关问题来促进协同进化，显著提升了整体性能。该方法在 10 个数学和通用推理基准测试上显示了平均 2.5% 的改进，并且能够推广到语言模型和视觉-语言模型中。", "conclusion": "通过合成数据训练的解算器提供改进的奖励，使生成器能够进一步优化性能，实现了 0.7% 的额外改进。该代码将在该链接下公开提供。"}
{"llm_update_time": "20251116", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.09900", "html_url": "https://arxiv.org/abs/2511.09900", "title": "使用细调蛋白质语言模型和树搜索增强硅基定向进化", "title_en": "Boosting In-Silicon Directed Evolution with Fine-Tuned Protein Language Model and Tree Search", "authors": "Yaodong Yang,Yang Wang,Jinpeng Li,Pei Guo,Da Han,Guangyong Chen,Pheng-Ann Heng", "background": "蛋白质通过氨基酸序列突变进化的概念是生命科学的基础。当前的硅基定向进化算法侧重于设计搜索策略，但忽略了如何利用编码丰富进化模式的蛋白质语言模型来指导搜索。现有的算法存在不足，没有充分运用这些模型指导进化。", "innovation": "本文提出了一种新颖框架AlphaDE，该框架通过利用大型语言模型的创新范式来进化蛋白质序列。具体而言，AlphaDE利用预训练的蛋白质语言模型对同源蛋白质序列进行掩码语言模型微调，激活目标蛋白质类的进化可能性。此外，引入了基于蒙特卡洛树搜索的测试时推理，有效地利用微调的蛋白质语言模型进行进化引导。实验结果表明，AlphaDE在少量调优的情况下显著优于现有最先进的方法。通过案例研究进一步证实了AlphaDE能够在计算进化过程中压缩蛋白质序列空间。", "conclusion": "AlphaDE通过微调蛋白质语言模型和树搜索技术显著提升了硅基定向进化算法的性能，展示了其在指导蛋白质进化方面的潜力。"}
{"llm_update_time": "20251116", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.09921", "html_url": "https://arxiv.org/abs/2511.09921", "title": "自适应双曲内核：在de Branges-Rovnyak空间中的可调节嵌入", "title_en": "Adaptive Hyperbolic Kernels: Modulated Embedding in de Branges-Rovnyak Spaces", "authors": "Leping Si,Meimei Yang,Hui Xue,Shipeng Zhu,Pengfei Fang", "background": "层次数据在机器学习应用中普遍存在，涵盖了自然语言处理、计算机视觉和社会网络分析等领域。双曲空间因其负曲率特性，在嵌入层次结构时表现出色，能够最小化变形。前期研究显示，通过内核方法可以进一步增强双曲表示能力。然而，现有的双曲内核仍然存在几何变形较轻或缺乏适应性的问题。", "innovation": "本文通过引入自适应双Branges-Rovnyak空间，提出了一种等距同态到Poincare球的再生核希尔伯特空间（RKHS）。设计可调节乘数以自适应选择对应的RKHS。基于此基础，构建了一组自适应双曲内核，包括新颖的自适应双曲径向内核，其可调节参数能够以任务感知的方式调节双曲特征。", "conclusion": "广泛的实验结果表明，所提出的内核在建模层次依赖关系方面优于现有的双曲内核。"}
{"llm_update_time": "20251116", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.09904", "html_url": "https://arxiv.org/abs/2511.09904", "title": "CTRL-ALT-DECEIT: 自动化AI研发中的破坏评估", "title_en": "CTRL-ALT-DECEIT: Sabotage Evaluations for Automated AI R&D", "authors": "Francis Rhys Ward,Teun van der Weij,Hanna Gábor,Sam Martin,Raja Mehta Moreno,Harel Lidar,Louis Makower,Thomas Jodrell,Lauren Robson", "background": "AI系统正在越来越能够自主执行现实的软件工程任务，并且可能部署用于自动化机器学习（ML）研发。前沿AI系统可能在安全关键环境中使用，例如帮助确保未来系统的安全性。然而，这些系统可能不够可信，甚至可能与开发人员或用户方向不一致。因此，本文研究了AI代理在进行ML工程时，对抗用户利益，通过植入后门和导致泛化失败来进行破坏的能力。另外，还研究了代理在其性能上故意进行调整的能力。研究发现，监视器能够检测代码破坏尝试，但检测隐藏破坏更为困难。针对这些破坏行为，提出了使用LM监视器检测可疑行为，并评估模型破坏和隐藏的能力。虽然监视器在检测代码破坏上表现出色，但在高风险领域中，监视器可能不足以有效防止破坏发生。这个基准是基于UK AISI的Inspect框架实现的，并在该链接提供了代码：this https URL", "innovation": "文章扩展了ML-E-Bench基准测试，增加了代码破坏任务，如植入后门和故意引发泛化失败。研究了AI代理在基准测试上故意降低其表现的能力。使用LM监视器来检测可疑行为，并测量模型被检测到破坏和隐藏的能力。提出了一种方法来检测隐藏的破坏，并检验多个监视器预测的有效性。结果表明，虽然LM监视器能够检测大部分代码破坏尝试，但发现隐藏的破坏更加困难。多项监视器的预测结果更能提高检测准确率，但在高风险领域，监视器的可靠性可能不足以有效防止单独或联合的破坏行为", "conclusion": "总体而言，尽管可以使用监视器有效检测代码破坏，但检测和防止隐藏破坏更为困难。结合多个监视器的预测能够提高检测准确性，但在高风险领域，监视系统的可靠性可能不可靠到能够有效防止破坏行为的程度。该基准测试在UK AISI的Inspect框架中实现，并在提供的链接中公开了代码。"}
{"llm_update_time": "20251116", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.10027", "html_url": "https://arxiv.org/abs/2511.10027", "title": "ChEmREF：评估语言模型在化学应急响应中的成熟度", "title_en": "ChEmREF: Evaluating Language Model Readiness for Chemical Emergency Response", "authors": "Risha Surana,Qinyuan Ye,Swabha Swayamdipta", "background": "应急响应人员在处理危险化学品（HAZMAT）事件时，需要迅速做出关键决策，而目前他们主要依赖于复杂的化学指南进行操作。这项研究表明，当前的语言模型可以在快速理解和识别关键信息、提供应急响应建议等方面辅助应急响应人员。", "innovation": "提出了一种新的基准测试框架——Chemical Emergency Response Evaluation Framework (ChEmREF)，包括来自《应急响应指南》和PubChem数据库的1035种危险化学品的问题。ChEmREF分为三个任务：（1）化学表示形式的结构化与非结构化转换；（2）应急响应生成；（3）化学安全和认证考试领域的专业知识问答。研究表明，虽然语言模型在某些任务上展示了潜力，但仍未达到完全自动化所需的标准，需要人类的仔细监督。", "conclusion": "研究表明，语言模型在辅助应急响应人员的各种任务方面显示出潜力，但在许多方面仍存在限制，需要更多的人工监督。"}
{"llm_update_time": "20251116", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.10037", "html_url": "https://arxiv.org/abs/2511.10037", "title": "超越ReAct：基于规划者的复杂工具增强LLM推理框架", "title_en": "Beyond ReAct: A Planner-Centric Framework for Complex Tool-Augmented LLM Reasoning", "authors": "Xiaolong Wei,Yuehu Dong,Xingliang Wang,Xingyu Zhang,Zhejun Zhao,Dongdong Shen,Long Xia,Dawei Yin", "background": "现有的工具增强大型语言模型（LLMs）在处理复杂查询时面临重大挑战。当前框架如ReAct容易陷入局部最优化陷阱，主要是由于其依赖于逐步决策过程。", "innovation": "本文提出了一种基于规划者的规划-执行新范式，通过架构创新从根本上解决了局部最优化瓶颈问题。该创新包括一个新颖的规划者模型，能够进行全局有向无环图（DAG）规划，以优化复杂查询的执行。此外，还开发了一种结合监督微调（SFT）和组相对策略优化（GRPO）的两阶段训练方法，系统地增强了规划者在工具选择的准确性和全局规划意识。", "conclusion": "将该框架与强大的执行器结合时，在StableToolBench基准测试中复杂用户查询的执行表现达到了最先进的水平，展示了出色的端到端执行能力和对复杂多工具工作流程的强大处理能力。"}
{"llm_update_time": "20251116", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.09993", "html_url": "https://arxiv.org/abs/2511.09993", "title": "SPAN：大型语言模型跨日历时间推理的能力评估与提升", "title_en": "SPAN: Benchmarking and Improving Cross-Calendar Temporal Reasoning of Large Language Models", "authors": "Zhongjian Miao,Hao Fu,Chen Wei", "background": "论文引入了SPAN基准，这是一个跨日历的时间推理基准，旨在要求LLM在同一天历内进行时间推理，并在不同日历之间进行时间转换。该基准涵盖了六种日历的十个跨日历时间推理方向，两种推理类型和两种问题格式。为了实现时间动态和无污染的评估，论文提出了一种基于模板的动态实例生成协议，可以在用户指定的格里历日期上进行评估。实验在1960年至2060年之间的日期上进行了广泛测试，涵盖了开放式和封闭式的最新顶级LLM。评估结果显示这些模型的平均准确率仅为34.5%，没有超过80%，表明该任务仍然具有挑战性。", "innovation": "论文提出了一种基于模板的动态实例生成协议，通过用户指定的格里历日期进行评估，确保时间动态性和无污染性。此外，论文还通过跨日历时间推理方向、问题格式和推理类型的深入分析，指出了未来日期退化和日历差异偏差两大挑战。基于此，开发了一种工具增强代码生成的LLM时间代理，实验表明其准确率达到了95.31%，大幅超越了多个基线。", "conclusion": "研究表明现有的LLM在跨日历时间推理方面存在显著不足，特别是面对未来日期的推理和不同日历系统的转换上更为困难。通过工具增强的代码生成，论文开发出的LLM时间代理显著提升了跨日历时间推理能力。希望这项工作能够激励更多研究，推动具有时间适应性和文化适应性的LLM的发展。"}
{"llm_update_time": "20251116", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.10038", "html_url": "https://arxiv.org/abs/2511.10038", "title": "通过策略干预高效探索思维空间", "title_en": "Efficient Thought Space Exploration through Strategic Intervention", "authors": "Ziheng Li,Hengyi Cai,Xiaochi Wei,Yuchen Li,Shuaiqiang Wang,Zhi-Hong Deng,Dawei Yin", "background": "大型语言模型（LLMs）展示了新的推理能力，但是当前在推理时扩展方法由于穷举采样的方式会产生高昂的计算成本。通过对解码过程的分析，我们发现大多数预测的下一个token与标准输出兼容，但也有一些关键性的token会导致偏离。基于这种观察结果，本文探讨了一种新的提示-实践推理（HPR）框架，通过两个互补的组件来实现这一想法：1）一个“提示者”（强大的LLM），在关键时刻提供概率上的指导；2）一个“执行者”（高效的较小模型），执行主要的推理步骤。", "innovation": "HPR框架的核心创新在于分布不一致性减少（DIR）机制，这是一种理论上依据的方法，能够动态识别干预点，这是通过量化执行者推理路径与提示者期望分布在树状结构概率空间中的偏离程度实现的。通过由DIR指导的递归树更新，HPR重新赋权重可能的推理路径，同时降低低概率分支的重要性。此框架在算术和常识推理基准测试上展示了高效的效率-准确性权衡：与自我一致性或MCTS基线相比，它只需解码5分之一的token即可获得相当的性能；并且相比之下，现有方法的绝对准确性最高可提升5.1%，同时保持相似或更低的FLOPs（浮点运算次数）水平。", "conclusion": "HPR框架通过通过策略干预和分布不一致性减少机制，实现了高效的推理任务，证明了其在算术和常识推理场景中的优势，并在较低计算成本的情况下获得相近或略高的准确性。"}
{"llm_update_time": "20251116", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.10128", "html_url": "https://arxiv.org/abs/2511.10128", "title": "RAGFort：预防检索增强生成中专有知识库提取的双路径防御", "title_en": "RAGFort: Dual-Path Defense Against Proprietary Knowledge Base Extraction in Retrieval-Augmented Generation", "authors": "Qinfeng Li,Miao Pan,Ke Xiong,Ge Su,Zhiqiang Shen,Yan Liu,Bing Sun,Hao Peng,Xuhong Zhang", "background": "当前，使用专有知识库部署的检索增强生成（RAG）系统面临日益严重的重建攻击威胁。这些攻击利用了类内和类间的关系，逐步提取专题中的细粒度知识，并在语义相关的专题之间扩散，从而使攻击者能够全面提取原始的知识库。现有的防御措施只能针对一条路径，而并未保护另一条路径，这种单一防御无法有效地抵御此类攻击。", "innovation": "本文系统地探索了独立保护每条路径的影响，发现联合保护是有效的防御手段。在此基础上，本文提出了RAGFort，这是一种结构感知的双模块防御体系，结合了“对比重构索引”用于类间隔离和“受限级联生成”用于类内保护。", "conclusion": "通过安全性、性能和稳健性实验验证，RAGFort显著降低了重建攻击的成功率，同时保持了答案质量，为知识库提取攻击提供了全面防御。"}
{"llm_update_time": "20251116", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.10119", "html_url": "https://arxiv.org/abs/2511.10119", "title": "智能基础模型：接近通用人工智能的一种新视角", "title_en": "Intilligence Foundation Model: A New Perspective to Approach Artificial General Intelligence", "authors": "Borui Cai,Yao Zhao", "background": "现有的基础模型（FMs）专注于特定领域的模式学习，如语言、视觉或时间序列，而未从广泛智能行为中学习通用智能机制。智能行为源自生物神经系统的集体动态，因此，一种新的智能基础模型（IFM）被提出，旨在直接从各种智能行为中学习，以获得智能的基础机制。", "innovation": "该研究提出了一个新的智能基础模型（IFM），其核心创新包括两部分：一是“状态神经网络”（一种新的网络架构），能够捕捉神经元样动态过程；二是“神经元输出预测”（新的学习目标），通过集体行为训练系统预测神经元输出。这些共同建立了根据生物原理和计算可扩展性构建跨领域应用、通用推理和适应性学习能力系统的基础，为代表性地迈向真正的人工通用智能（AGI）。", "conclusion": "这种新的视角建立了一种生物基础和计算上可扩展的方法来构建能够跨领域进行泛化、推理和适应性学习的系统，为真正的通用人工智能（AGI）的发展提供了一种新的路径。"}
{"llm_update_time": "20251116", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.10067", "html_url": "https://arxiv.org/abs/2511.10067", "title": "通过多面自我精炼学习增强大型语言模型的医疗领域情境意识能力", "title_en": "Enhancing the Medical Context-Awareness Ability of LLMs via Multifaceted Self-Refinement Learning", "authors": "Yuxuan Zhou,Yubin Wang,Bin Wang,Chen Ning,Xien Liu,Ji Wu,Jianye Hao", "background": "大型语言模型（LLMs）在医疗领域展现出了巨大的潜力，已在多个基准测试中取得了出色的成绩。然而，这些模型在实际医疗场景中的表现仍不尽如人意，特别是在需要更强的情境意识方面，比如识别缺失或关键细节（例如用户身份、医疗史、风险因素），并提供安全、实用且情境适当的回答。", "innovation": "本文提出了多面自我精炼（MuSeR），这是一种数据驱动的方法，通过自我评估和精炼来增强LLMs的三种关键方面（决策、交流和安全性）的情境意识。MuSeR首先设计了一个属性条件查询生成器，以模拟多种现实世界用户情境，通过改变角色、地理区域、意图和信息模糊程度等属性。然后，查询对这些查询的回答进行自我评估和精炼，以更好地满足每个方面的需求。最后，使用精炼后的查询和响应进行监督微调，以强化模型的情境意识能力。", "conclusion": "在最新HealthBench数据集中，本文方法在多个方面显著提高了LLM的表现，特别是在情境意识维度上有显著提升。此外，通过将知识蒸馏与所提出的方法结合，一个较小的基础LLM（如Qwen3-32B）的模型性能超越了其教师模型，达到了所有开源LLMs在HealthBench（63.8%）及其实质子集（43.1%）中新的SOTA。"}
{"llm_update_time": "20251116", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.10065", "html_url": "https://arxiv.org/abs/2511.10065", "title": "放射学工作流程引导的分层强化微调用于医学报告生成", "title_en": "Radiology Workflow-Guided Hierarchical Reinforcement Fine-Tuning for Medical Report Generation", "authors": "Bodong Du,Honglong Yang,Xiaomeng Li", "background": "放射科医生通过结构化的流程来撰写诊断报告，包括描述视觉发现、总结印象以及在关键情况下仔细润色陈述。然而，现有的大多数医学报告生成（MRG）系统将报告视为扁平序列，忽视了这种层次化的组织结构，导致描述性和诊断内容之间存在不一致性。为使模型的行为与现实世界的报告实践相符，提出了RadFlow，这是一种基于层次化工作流的强化优化框架，明确地建模了临床报告的结构化特性。该框架通过引入基于临床的奖励层次结构来模拟放射学报告的组织结构。在全局层面，奖励整合了语言流畅性、医学领域的正确性和横截面一致性，以促进连贯且临床忠实的叙述。在局部层面，部分特定的奖励强调了印象的质量，反映了其在诊断准确性中的核心作用。此外，关键感知的策略优化机制适应性地为高风险或临床敏感情况规制学习，模拟了放射科医生在记录关键发现时的谨慎精炼行为。这些组成部分将结构化报告范式转化为强化调优过程，使模型能够生成既语义上一致又临床一致的报告。实验在胸部X光和颈动脉超声数据集上证明，与最先进的基线相比，RadFlow在提高诊断连贯性和总体报告质量方面表现出持续改进的效果。", "innovation": "提出了RadFlow框架，这是一种基于层次化工作流的强化优化框架，明确地建模了临床报告的结构化特性。该框架通过引入基于临床的奖励层次结构来模拟放射学报告的组织结构。在全局层面，奖励整合了语言流畅性、医学领域的正确性和横截面一致性，以促进连贯且临床忠实的叙述。在局部层面，部分特定的奖励强调了印象的质量，反映了其在诊断准确性中的核心作用。此外，关键感知的策略优化机制适应性地为高风险或临床敏感情况规制学习，模拟了放射科医生在记录关键发现时的谨慎精炼行为。", "conclusion": "RadFlow框架能够生成既语义上一致又临床一致的医疗报告，并且在提高诊断连贯性和总体报告质量方面表现出持续改进的效果。实验结果证明了该方法的有效性。"}
{"llm_update_time": "20251116", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.10164", "html_url": "https://arxiv.org/abs/2511.10164", "title": "提升规划中的两种约束编译方法", "title_en": "Two Constraint Compilation Methods for Lifted Planning", "authors": "Periklis Mantenoglou,Luigi Bonassi,Enrico Scala,Pedro Zuidberg Dos Martires", "background": "本文研究了一种PDDL片段中的定性状态轨迹约束，这些约束捕捉到了安全性要求、任务顺序条件和现实世界问题中常见的子目标。现有的方法是通过编译约束来解决问题，从而使问题适应最先进的规划器。但现有的编译器在处理大量对象和高元操作时无法扩展，因为它们需要对问题进行预接地。为了解决这一问题，本文提出了两种无需接地即可编译约束的方法，使其适合大规模规划问题。", "innovation": "本文提出了两种无接地的约束编译方法，解决了现有编译器在处理大规模问题时的扩展性问题。此外，本文还证明了编译器的正确性并指出了它们的最坏情况时间复杂度。通过对最新国际规划竞赛使用的领域进行可重现的实证分析，验证了方法的有效性和效率，表明它们产生的规划规范比现有编译方法生成的规范要简洁得多，同时在使用最先进的规划器时仍然具有竞争力。", "conclusion": "本文提出的无接地约束编译方法适用于大规模规划问题，并且在实用性方面优于需要对领域进行预接地的编译方法。此外，本文还证明了编译器的正确性并分析了它们的最坏情况时间复杂度。"}
{"llm_update_time": "20251116", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.10161", "html_url": "https://arxiv.org/abs/2511.10161", "title": "DenoGrad：提高可解释AI模型性能的深度梯度去噪框架", "title_en": "DenoGrad: Deep Gradient Denoising Framework for Enhancing the Performance of Interpretable AI Models", "authors": "J. Javier Alonso-Ramos,Ignacio Aguilera-Martos,Andrés Herrera-Poyatos,Francisco Herrera", "background": "机器学习模型，特别是可解释人工智能框架内的模型，在处理含有噪声的训练和生产数据时性能会受到显著影响。去噪已经成为重要的预处理步骤，主要分为实例移除和实例修正两种技术。然而，现有的修正方法往往会通过修改原始数据分布来降低性能或简单化问题，这导致了不切实际的场景和有偏见的模型，尤其是在使用可解释AI模型的环境中，因为它们的解释性依赖于数据模式的一致性。已有研究并未针对任务和数据集的特定情况定义噪声，而是采用了一般性解决方案，这可能无法提供精确且适应性强的噪声定义。因此，需要一种能根据不同任务和数据集准确定义噪声的方法。文中提出了一种新的方法，考虑特定任务的最佳解决方案作为参考，采用一个训练在目标数据上的准确深度学习模型的梯度来检测和调整噪声样本。这种方法提供了更精确且可适应的噪声定义框架，并且能够保持数据分布，从而提高模型的鲁棒性。", "innovation": "提出了DenoGrad，这是一种基于梯度的实例去噪框架，使用准确训练在目标数据上的深度学习模型的梯度来检测和调整噪声样本。它动态地进行去噪，保留了原始数据分布，提高了可解释AI模型的性能，同时能够准确地适应不同任务和数据集的需要。DenoGrad比现有方法更有效，能够在不同噪声设置下优于当前最先进的去噪策略，特别适合于保持原始数据分布的同时提升可解释AI模型的性能。", "conclusion": "通过实验证明了DenoGrad的有效性，它不仅能在不同噪声的情况下提升可解释AI模型的性能，还能保持原始数据分布，达到了高精度的去噪效果。"}
{"llm_update_time": "20251116", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.10210", "html_url": "https://arxiv.org/abs/2511.10210", "title": "有限API调用下大语言模型的高级黑盒调优", "title_en": "Advanced Black-Box Tuning of Large Language Models with Limited API Calls", "authors": "Zhikang Xie,Weilin Wan,Peizhu Gong,Weizhong Zhang,Cheng Jin", "background": "黑盒调优是一种新兴的大语言模型（LLMs）调整范式，特别适用于无法直接访问模型参数时更好地实现所需行为。现有策略通常面临困境，要么分别训练一个小代理模型，然后使用它来调整基础模型的预测，虽然能显著提高效率，但通常改善有限；要么每次调谐迭代都向基础模型发起API调用，这会带来高昂的计算成本。", "innovation": "提出了一种新颖的仅需有限API调用的大语言模型黑盒调优方法。核心策略是训练基于少量但高度信息性的训练子集从基础模型查询得出的“LogitMap Pairs”的高斯过程（GP）代理模型，代理模型能够近似基础模型的输出以指导代理模型的训练，从而有效减少了直接查询基础模型的需要。", "conclusion": "广泛的实验验证了该方法将预训练语言模型的准确率从55.92%提高到86.85%，减少了API调用的频率到仅为其百分之一。这显著优于完全不使用API访问的方法，并且我们的方法在API成本显著降低的情况下仍能达到或优于查询密集型方法的准确性。这为语言模型的适应提供了一种稳健且高效的方法。"}
{"llm_update_time": "20251116", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.10233", "html_url": "https://arxiv.org/abs/2511.10233", "title": "通过大型语言模型指导的实例生成与逐步适应来弥合合成与现实路由问题之间差距", "title_en": "Bridging Synthetic and Real Routing Problems via LLM-Guided Instance Generation and Progressive Adaptation", "authors": "Jianghan Zhu,Yaoxin Wu,Zhuoyi Lin,Zhengyuan Zhang,Haiyan Yin,Zhiguang Cao,Senthilnath Jayavelu,Xiaoli Li", "background": "近期，神经组合优化（NCO）方法在处理合成路由实例方面显著提高了神经求解器的能力。然而，现有的神经求解器在将合成、均匀分布的训练数据推广到现实世界车辆路线问题（VRP）场景时表现不佳，包括TSPLib和CVRPLib中广泛认可的基准实例。尽管如此，现有的方法无法有效推广。", "innovation": "本文提出了基于进化模块的Evolutionary Realistic Instance Synthesis (EvoReal)，该模块由大型语言模型（LLMs）引导，用于生成具有多样性和现实结构模式的合成实例。EvoReal通过逐步细化预训练的NCO模型，首先使它们与结构丰富的合成分布对齐，然后通过直接微调实际基准实例进行进一步适应。大量的实验评估表明，EvoReal显著提高了最先进的神经求解器的泛化能力。", "conclusion": "EvoReal方法在TSPLib（1.05%）和CVRPLib（2.71%）基准上展现出相对于最优解显著减小的性能差距，并广泛适用于各种问题规模，从而显著提升了神经求解器在现实世界VRP场景中的表现。"}
{"llm_update_time": "20251116", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.10218", "html_url": "https://arxiv.org/abs/2511.10218", "title": "MTP：基于模态增强和频谱融合的多模态城市交通画像", "title_en": "MTP: Exploring Multimodal Urban Traffic Profiling with Modality Augmentation and Spectrum Fusion", "authors": "Haolong Xiang,Peisi Wang,Xiaolong Xu,Kun Yi,Xuyun Zhang,Quanzheng Sheng,Amin Beheshti,Wei Fan", "background": "随着现代城市化的加速，来自各种传感器的交通信号在监测城市状态方面发挥了重要作用，为确保安全旅行、减少交通拥堵和优化城市交通提供了坚实的基础。目前大多数交通信号建模方法依赖于城市传感器的原始数据模态，即城市传感器的直接数字读数，但这种方法忽视了多模态异构城市数据中的语义信息，阻碍了对交通信号的全面理解并限制了复杂交通动态的准确预测。", "innovation": "本文提出了一种多模态框架MTP（多模态城市交通画像），通过数值、视觉和文本视角来学习多模态特征。三个分支在频域中提供了多模态视角下的城市交通信号学习，并通过频域学习策略精细提取信息。特别地，该方法首先使用视觉增强对交通信号进行增强处理，将其转换为频谱图像和周期性图像以促进视觉学习，并基于特定主题、背景信息和项目描述增强文本信息。通过频率多层感知器在原始模态上进行学习，使用层级对比学习在三个分支上融合三种模态的频谱。", "conclusion": "在六个真实数据集上的广泛实验表明，MTP方法相较于最先进的方法具有优越的性能。"}
{"llm_update_time": "20251116", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.10240", "html_url": "https://arxiv.org/abs/2511.10240", "title": "ProgRAG：在知识图谱上克服幻觉的逐步检索与推理", "title_en": "ProgRAG: Hallucination-Resistant Progressive Retrieval and Reasoning over Knowledge Graphs", "authors": "Minbae Park,Hyemin Yang,Jeonghyun Kim,Kunsoo Park,Hyunjoon Kim", "background": "大型语言模型（LLMs）在推理方面表现出强大的能力，但在幻觉和透明度方面存在不足。最近，结合知识图谱（KGs）的KG增强LLMs可以提升推理性能，特别对于复杂、知识密集型任务。然而，这些方法仍然面临挑战，包括不准确的检索和推理失败，这些问题通常在长输入上下文中更为严重，并且下游任务的语境构建难以捕捉到不同问题类型所需的更丰富的逻辑方向。此外，许多方法依赖LLMs直接从KG中检索证据，并自我评估证据的充分性，这往往会导致过早或不正确的推理。", "innovation": "本文提出了ProgRAG，这是一种多跳知识图谱问答（KGQA）框架，通过将复杂问题分解成子问题，并通过每个子问题的答案逐步延伸部分推理路径来解决检索和推理失败的问题。在每一步，外部检索器收集候选证据，然后通过LLM的不确定意识剪枝进行优化。最终，通过组织和重新排列从子问题答案中获得的部分推理路径来优化LLM推理的上下文。实验结果表明，ProgRAG在多跳KGQA中优于现有baseline，提供了更高的可靠性和推理质量", "conclusion": "实验结果表明，ProgRAG在三个广泛认可的数据集上的多跳KGQA中表现优于现有基线，提供了更高的可靠性和推理质量。"}
{"llm_update_time": "20251116", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.10244", "html_url": "https://arxiv.org/abs/2511.10244", "title": "PepTriX：通过蛋白质语言模型实现可解释肽分析的框架", "title_en": "PepTriX: A Framework for Explainable Peptide Analysis through Protein Language Models", "authors": "Vincent Schilling,Akshat Dubey,Georges Hattab", "background": "肽分类任务，如预测毒性和HIV抑制，是生物信息学和药物发现的基础。传统的处理方法依赖于手工构建的一维（1D）肽序列编码，这限制了它们在不同任务和数据集上的泛化能力。最近的蛋白质语言模型（PLMs），如ESM-2和ESMFold，展示了强大的预测性能。然而，它们面临两个关键挑战：首先，微调计算成本高昂；其次，复杂的潜在表示妨碍了领域专家的解释性。此外，许多特定类型的肽分类框架已经被开发出来，缺乏泛化能力。这些限制限制了将模型预测与生物学相关基序和结构特性连接的能力。", "innovation": "提出了一种新的框架PepTriX，该框架通过图注意力网络结合对比训练和跨模态联合注意，将一维（1D）序列嵌入和三维（3D）结构特性结合起来。PepTriX能够自动适应多种数据集，生成适用于特定任务的肽向量，同时保留生物学合理性。经过领域专家的评估，PepTriX在多个肽分类任务中表现优异，提供了可解释的见解，揭示了驱动预测的结构和生物物理基序。", "conclusion": "PepTriX提供了预测稳健性和可解释验证的桥梁，连接了性能驱动的肽级模型（PLMs）和肽研究领域的理解。"}
{"llm_update_time": "20251116", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.10268", "html_url": "https://arxiv.org/abs/2511.10268", "title": "Causal-HalBench: 通过因果干预发现LVLMs的物体幻觉", "title_en": "Causal-HalBench: Uncovering LVLMs Object Hallucinations Through Causal Intervention", "authors": "Zhe Xu,Zhicai Wang,Junkang Wu,Jinda Lu,Xiang Wang", "background": "大型视觉-语言模型（LVLMs）往往遭受物体幻觉的问题，这使得它们对图像中物体的存在作出错误判断。目前，基准主要集中在幻觉检测，但缺乏对LVLMs中虚假关联的正式特征化和定量评估。", "innovation": "作者引入因果分析到LVLMs的物体识别场景，建立结构因果模型（SCM），正式定义了由于共现偏见引起的虚假关联。开发了Causal-HalBench基准，具体包含反事实样本，集成全面的因果指标以评估模型在虚假关联下的鲁棒性。提出了一种可以扩展的反事实样本生成管道，利用私有的LVLMs和文本到图像（T2I）模型生成这些反事实样本。", "conclusion": "对主流LVLMs使用Causal-HalBench进行评估表明，这些模型在不同程度上对虚假关联表现出敏感性。"}
{"llm_update_time": "20251116", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.10264", "html_url": "https://arxiv.org/abs/2511.10264", "title": "超越单一步骤更新：具有有限前瞻搜索的启发式强化学习", "title_en": "Beyond Single-Step Updates: Reinforcement Learning of Heuristics with Limited-Horizon Search", "authors": "Gal Hadar,Forest Agostinelli,Shahaf S. Shperberg", "background": "许多序贯决策问题都可以被表述为最短路径问题，问题的目标是从给定的起始状态到达目标状态。启发式搜索是解决这类问题的标准方法，它依赖于一个启发式函数来估计从任意给定状态到目标状态的成本。近年来，一些方法利用强化学习来学习启发式函数，通过应用深度近似值迭代。这些方法通常依赖于单一步骤的贝尔曼更新，即一个状态的启发式值是基于其最佳邻居及其相应的边成本来更新的。本研究提出了一个增强的方法，通过进行有限前瞻的搜索并更新每个状态的启发式值为从状态到搜索前沿的最短路径，同时考虑边成本和前沿状态的启发式值，从而增强状态采样和启发式更新。", "innovation": "本研究提出了一个名为“有限前瞻搜索”的新方法，该方法通过使用比过去方法更完善的启发式函数来改进启发式函数的更新。这个新的方法不仅考虑了单一的最佳邻居和边成本，还在每个状态更新启发式值时考虑了从状态到搜索前沿的最短路径，包括边成本和前沿状态的启发式值，以此来增强启发式函数的精度和效率。", "conclusion": "这项研究提出了一个改进启发式函数更新的方法，通过利用有限前瞻搜索，不仅提高了启发式搜索的效果，还在提高搜索效率和准确性方面取得了显著进步。"}
{"llm_update_time": "20251116", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.10272", "html_url": "https://arxiv.org/abs/2511.10272", "title": "具有一致启发式的双向近似最优启发式搜索", "title_en": "Bidirectional Bounded-Suboptimal Heuristic Search with Consistent Heuristics", "authors": "Shahaf S. Shperberg,Natalie Morad,Lior Siag,Ariel Felner,Dor Atzmon", "background": "近年来，双向启发式搜索取得了重要的理论进展，产生了一系列新颖的算法。大多数早期的工作都集中在寻找最优的搜索方法上，而本文则关注一种带有解决方案成本上限的近似最优双向搜索问题，具体是指在搜索中允许一定程度的非最优解。本文基于一种最先进的一致启发式的最优双向搜索算法BAE*进行改进，开发了几种特化于近似最优问题的BAE*算法变体。", "innovation": "本文创新地提出了几种针对带有解决方案成本上限的近似最优上下文的BAE*算法变体，并通过实验比较了这些新方法与其他近似最优双向算法及传统加权A*算法的表现，展示了每种方法在不同条件下的优势和不足。", "conclusion": "实验结果表明，每种算法在不同条件下表现出色，这突显了每种方法的优势和劣势。"}
{"llm_update_time": "20251116", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.10277", "html_url": "https://arxiv.org/abs/2511.10277", "title": "面向消费者硬件的固定人设小语言模型与模块化记忆：可扩展的NPC对话系统", "title_en": "Fixed-Persona SLMs with Modular Memory: Scalable NPC Dialogue on Consumer Hardware", "authors": "Martin Braas,Lukas Esterle", "background": "大型语言模型(LLMs)在生成类人类文本方面表现出色，但在作为计算机游戏中对话系统的应用方面受到限制。这一限制源于它们对大量硬件资源的需求、延迟问题以及在游戏场景下需要保持清晰的知识边界。", "innovation": "提出了一种模块化的NPC对话系统，该系统利用了细调过的少量语言模型(SLMs)，以及可以动态更换的内存模块来存储角色特异性对话和世界知识。这种方法避免了在游戏过程中重新训练或重新加载模型，同时支持丰富和长期的对话记忆。研究使用了三种开源SLMs：DistilGPT-2、TinyLlama-1.1B-Chat和Mistral-7B-Instruct，并在消费者级别的硬件上进行了基准测试。", "conclusion": "该系统展示了在游戏应用中的潜力，并为进一步需要丰富、可扩展和记忆密集型对话代理的领域，如虚拟助手、客服机器人或互动教育资源铺平了道路。"}
{"llm_update_time": "20251116", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.10266", "html_url": "https://arxiv.org/abs/2511.10266", "title": "动态贝叶斯网络中的条件独立时序性质", "title_en": "Temporal Properties of Conditional Independence in Dynamic Bayesian Networks", "authors": "Rajab Aghamov,Christel Baier,Joel Ouaknine,Jakob Piribauer,Mihir Vahanwala,Isa Vialard", "background": "动态贝叶斯网络（DBNs）是一种紧凑的图形表示，用于建模随时间变化的互相关随机变量及其分布的概论系统。本文研究了条件独立（CI）命题随时间演变的验证问题，考虑了线性时序逻辑（LTL）和非确定德布伊奇自动机（NBAs）两种形式化方法。该问题有两种变体：随机 CI 属性将给定的具体概率分布纳入考量，而结构 CI 属性仅从 DBN 的图形结构来解释。这些研究揭示了验证问题的复杂性，尤其是在考虑概率分布和纯粹从结构角度考虑时复杂的计算难度差异。", "innovation": "文章展示了如何将线性时序逻辑（LTL）和非确定德布伊奇自动机（NBAs）应用于 DBN 中条件独立命题的验证，并且给出了这两种情况下验证问题的复杂度分析。研究表明，对于随机 CI 属性的验证问题，决策其最终是否成立至少与数论中的 Skolem 问题等难；而对于结构 CI 属性的验证问题，对其进行 LTL 和 NBA 规范的验证属于 PSPACE 类别，并且是 NP- 和 coNP-硬的。此外，作者还将自然限制图形结构应用于 DBNs，以使结构 CI 属性的验证变得可行。", "conclusion": "对于随机 CI 属性的验证挑战性较大，但这可以通过限制 DBN 的图形结构来解决，从而使得结构 CI 属性的验证更加实用。此外，针对 LTL 和 NBA 规范的结构 CI 属性验证已被证明在 PSPACE 中是可行的，尽管仍然是 NP- 和 coNP-硬的，但仍有所改进。"}
{"llm_update_time": "20251116", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.10281", "html_url": "https://arxiv.org/abs/2511.10281", "title": "FactGuard：基于事件中心和常识指导的虚假新闻检测", "title_en": "FactGuard: Event-Centric and Commonsense-Guided Fake News Detection", "authors": "Jing He,Han Zhang,Yuanhui Xiao,Wei Guo,Shaowen Yao,Renyang Liu", "background": "基于写作风格的虚假新闻检测方法已经取得显著进展，但随着对手模仿真实新闻的写作风格，这些方法的有效性逐渐下降。最近的研究探索了利用大规模语言模型（LLMs）来增强虚假新闻检测，不过LLMs在虚假新闻检测中的实际应用受限于浅显的功能探索、模棱两可的使用性和高昂的推理成本。因此，作者提出了一种名为FactGuard的新颖虚假新闻检测框架，该框架利用LLMs提取事件相关的具体内容，从而减少写作风格对检测性能的影响。此外，该方法引入了一个动态的可用性机制，用于识别事实推理中的矛盾和模糊情况，根据需要整合LLMs的建议以提高决策可靠性。为了确保高效和实际部署，采用了知识蒸馏技术，使得FactGuard-D能够在冷启动和资源受限场景下有效运行。", "innovation": "提出了一种名为FactGuard的虚假新闻检测框架，利用LLMs提取事件相关的具体内容，引入了动态的可用性机制来处理事实推理中的矛盾和模糊情况，并通过知识蒸馏使得框架能够在冷启动和资源受限环境中有效运行。", "conclusion": "在两个基准数据集上的全面实验表明，该方法在鲁棒性和准确性上都优于现有方法，有效解决了写作风格敏感性和LLMs使用性在虚假新闻检测中的挑战。"}
{"llm_update_time": "20251116", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.10284", "html_url": "https://arxiv.org/abs/2511.10284", "title": "超越验证：用于后AI隐私泄露评估的演绎性解释", "title_en": "Beyond Verification: Abductive Explanations for Post-AI Assessment of Privacy Leakage", "authors": "Belona Sonna,Alban Grastien,Claire Benn", "background": "人工智能决策过程中的隐私泄露风险重大，尤其是在敏感信息能被推断出来时。目前缺乏一个系统的框架来审计这种隐私泄露情况。", "innovation": "提出了一种形式化的框架，使用演绎性解释来审计隐私泄露，该方法识别模型决策所需的最小充分证据，并确定是否公开了敏感信息。引入了潜在相关解释（PAE）的概念，以识别结果能够保护具有敏感特征个体的个体。这种方法提供严格的隐私保障，同时又能生成人类可理解的解释，这是审计工具的关键要求。", "conclusion": "实验评估表明，演绎性推理可以使隐私审计具有可解释性，通过这种方法可以平衡透明性、模型可解释性和隐私保护之间的关系。尽管存在计算挑战和简化假设，我们的结果表明，演绎推理为人工智能决策中的隐私审计提供了一条实用的途径。"}
{"llm_update_time": "20251116", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.10356", "html_url": "https://arxiv.org/abs/2511.10356", "title": "SITA：一种结构到实例定理自动形式化框架", "title_en": "SITA: A Framework for Structure-to-Instance Theorem Autoformalization", "authors": "Chenyi Li,Wanli Ma,Zichen Wang,Zaiwen Wen", "background": "大语言模型（LLMs）在数学推理方面取得了进展，但仍面临在具体应用场景中形式化抽象结构挑战性的定理的问题。本研究旨在自动形式化数学研究水平的结果。", "innovation": "开发了一种结构到实例定理自动形式化（SITA）框架，该框架系统地建立起抽象数学理论与其具体应用之间的桥梁。利用基于大语言模型的生成和反馈指导的细化方法，确保自动化和形式化正确性。", "conclusion": "通过在优化问题数据集上的实验，SITA有效地形式化了基于抽象结构的多种实例。"}
{"llm_update_time": "20251116", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.10428", "html_url": "https://arxiv.org/abs/2511.10428", "title": "使用验证约束求解器生成逐步解释", "title_en": "Using Certifying Constraint Solvers for Generating Step-wise Explanations", "authors": "Ignace Bleukx,Maarten Flippo,Bart Bogaerts,Emir Demirović,Tias Guns", "background": "在可解释约束求解领域，通常向用户提供一个问题不可满足的原因。一种新颖的方法是计算一系列解释步骤。这种逐步解释展示了一系列涉及原始规范中约束的推理步骤，最终解释了冲突。然而，计算逐步解释是一项计算成本高昂的任务，这限制了能够使用这种方法的问题范围。因此，本文调查了如何将约束求解器生成的证明作为计算逐步解释的起点，而不是逐步计算。", "innovation": "本文定义了一个抽象证明框架，其中证明和逐步解释都可以表示。作者进一步提出了一种方法，用于将证明转换为逐步解释序列，并特别关注剪枝和简化技术，以保持序列及其各步骤的规模较小。这种方法在生成逐步解释序列的速度上明显优于现有方法，且生成的逐步解释的质量与当前最先进的技术水平相当。", "conclusion": "我们的方法显著加快了逐步解释序列的生成速度，同时生成的逐步解释的质量与当前最先进的水平相当。"}
{"llm_update_time": "20251116", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.10416", "html_url": "https://arxiv.org/abs/2511.10416", "title": "从布尔到连续域推广类比推理", "title_en": "Generalizing Analogical Inference from Boolean to Continuous Domains", "authors": "Francisco Cunha,Yves Lepage,Zied Bouraoui,Miguel Couceiro", "background": "类比推理是一种强大的归纳机制，在人类认知中广泛应用，也被越来越多地应用于人工智能中。在布尔域中已经开发了形式化的类比推理框架，这些框架适用于仿射函数，并且对于接近仿射的函数，其推理结果可以认为是近似正确的。这些结果为基于类比的分类器设计提供了指导，但是它们不适用于回归任务或其他连续域任务。", "innovation": "本文重新从基础层面审视了类比推理，并通过一个反例展示了现有的一般化界面对布尔域的情况下甚至无法适用。文章引入了一个基于广义算术均值的参数化类比推理统一框架，适用于实值域。这个模型不仅包容了布尔分类和回归，还支持在连续函数上进行类比推理。该框架下类比保留函数被表征，并且在光滑条件下推导出了最坏情况和平均情况下的误差界。这项研究表明了类比推理在离散和连续域间的普遍性理论。", "conclusion": "本文的结果提供了一个跨越离散和连续域的一般类比推理理论。"}
{"llm_update_time": "20251116", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.10449", "html_url": "https://arxiv.org/abs/2511.10449", "title": "非单调S4F观点逻辑", "title_en": "Non-Monotonic S4F Standpoint Logic", "authors": "Piotr Gorczyca,Hannes Strass", "background": "观点逻辑提供了基于模态逻辑的统一形式化方法，用于表示多个异构视角。同时，许多非单调推理框架可以用模态逻辑自然地表达，尤其是在使用模态逻辑S4F时。\n", "innovation": "本文提出了一个名为S4F观点逻辑的新形式化方法，该方法不仅扩展了S4F和观点命题逻辑，还能表达多视角和非单调语义承诺。此外，还定义了其语法和语义，并分析了其计算复杂性，证明S4F观点逻辑在单调或非单调形式下都不比其组成部分复杂。\n", "conclusion": "最后，本文概述了信任和怀疑接受机制，并通过一个示例展示了该框架。\n"}
{"llm_update_time": "20251116", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.10409", "html_url": "https://arxiv.org/abs/2511.10409", "title": "解释去中心化多智能体强化学习策略", "title_en": "Explaining Decentralized Multi-Agent Reinforcement Learning Policies", "authors": "Kayla Boggess,Sarit Kraus,Lu Feng", "background": "近年来，多智能体强化学习（MARL）引起了广泛关注，特别是在多个代理在不同领域进行序列决策。然而，大多数现有的解释方法仅针对集中式MARL，没有考虑到去中心化设置中的固有不确定性和非确定性。因此，当前方法不能满足用户对特定代理行为的查询类型（何时、为什么不行、何为）的需求，导致无法提供有效的解释。为了改善这一状况，本文提出了一种生成策略总结的方法，能够捕捉去中心化MARL策略中的任务顺序和代理合作，并提供了基于查询的解释来回答特定代理行为的问题。", "innovation": "本文提出的方法可以生成策略总结，捕捉去中心化MARL策略中的任务顺序和代理合作，并提供基于查询的解释，包括‘何时’、‘为什么不行’和‘为何为’类型的问题。本文的方法在四个MARL领域和两种去中心化MARL算法中进行了评估，展示了其泛化能力和计算效率。通过用户研究发现，本文的方法显著提高了用户回答问题的能力，并提高了在理解度和满意度等指标上的主观评分。", "conclusion": "本文的方法在四个MARL领域和两种去中心化MARL算法中进行了评估，证明了其泛化能力和计算效率。用户研究表明，我们的总结和解释显著提高了用户回答问题的能力，并提高了理解度和满意度等主观评分。"}
{"llm_update_time": "20251116", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.10482", "html_url": "https://arxiv.org/abs/2511.10482", "title": "第三国际研讨会关于可解释人工智能在艺术领域的应用（XAIxArts会议记录）", "title_en": "Proceedings of The third international workshop on eXplainable AI for the Arts (XAIxArts)", "authors": "Corey Ford,Elizabeth Wilson,Shuoyang Zheng,Gabriel Vigliensoni,Jeba Rezwana,Lanxi Xiao,Michael Clemens,Makayla Lewis,Drew Hemment,Alan Chamberlain,Helen Kennedy,Nick Bryan-Kinns", "background": "本次研讨会是第三次国际可解释人工智能在艺术领域的研讨会（XAIxArts），聚集了人机交互（HCI）、交互设计、人工智能、可解释人工智能（XAI）和数字艺术领域的研究者，旨在探讨可解释人工智能在艺术领域的角色与应用。", "innovation": "该研讨会带来了跨学科的合作，促进了一系列研究思想和技术的发展，特别是在可解释人工智能如何被应用到艺术创作和作品解释中。", "conclusion": "此次会议总结了可解释人工智能在艺术领域的研究进展，并提出了未来研究方向，强调了技术透明度与艺术表达之间的平衡，并讨论了如何利用XAI技术提高艺术创作和观众体验的理解力。"}
{"llm_update_time": "20251116", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.10436", "html_url": "https://arxiv.org/abs/2511.10436", "title": "逻辑谜题中逐步解释的偏好获取", "title_en": "Preference Elicitation for Step-Wise Explanations in Logic Puzzles", "authors": "Marco Foschini,Marianne Defresne,Emilio Gamba,Bart Bogaerts,Tias Guns", "background": "逐步解释可以用来解决逻辑谜题等满足问题，通过展示如何逐步推导决策。但是，由于存在大量的候选解释步骤，如何选择最易理解的步骤依赖于用户自定义的目标函数。然而，定义一个合适的目标函数具有挑战性。来自更广泛的机器学习领域的交互式偏好获取方法可能有助于从成对比较中学习用户偏好。但是，这种方法在逻辑谜题中的应用面临着一些不同于标准组合问题的限制，例如解释质量的多尺度特征和相似解释的大量生成等。研究针对这些问题提出了解决方案。", "innovation": "提出了两种动态归一化技术以稳定学习过程，同时引入了MACHOP（多臂可支配感知器）——一种新的查询生成策略，结合非支配约束和基于上置信边界的食物性，以处理逻辑谜题中特定的偏好获取挑战。该方法在仿真人和真实用户研究中均评估了其效果，显示MACHOP能够更有效地生成高质量的解释。", "conclusion": "该研究证明了交互式偏好获取技术在逻辑谜题中逐步解释中的有效性，并通过提出新的解决方案解决了相关挑战，提高了系统生成解释的质量。"}
{"llm_update_time": "20251116", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.10339", "html_url": "https://arxiv.org/abs/2511.10339", "title": "专用于偏序博弈及其他拓展的大规模并行Proof-Number搜索", "title_en": "Massively Parallel Proof-Number Search for Impartial Games and Beyond", "authors": "Tomáš Čížek,Martin Balko,Martin Schmid", "background": "Proof-Number搜索算法是一种往前搜索的最佳搜索算法，在游戏中有许多成功的应用，尤其是在游戏求解领域。随着大规模计算集群的日益普及，实现并行化是加速计算的自然选择，但现有的Proof-Number搜索的并行版本在多核CPU上并不具备良好的扩展性。在处理大型游戏树时，传统的并行化方法效率较低。本研究提出了首个在大量CPU核心上具有高效扩展性的大规模并行Proof-Number搜索算法，并结合格朗德数降低了游戏树大小，应用于Sprouts游戏，其复杂性是迄今为止的1000倍，加速度达到332.9倍，远远超过了现有的最佳Sprouts解算器GLOP，且解决了42个新的游戏位置，几乎将已知结果翻了一番。这项工作使用了两个并行化级别和工人之间的共享信息，有效地解决了大规模游戏树的搜索问题，并且在处理复杂问题时表现出色。这为未来的并行算法开发奠定了理论基础和实际应用模板。", "innovation": "提出了首个在大量CPU核心上具有良好扩展性的大规模并行Proof-Number搜索算法，结合使用格朗德数减少了Sprouts游戏中的游戏树大小，使得算法能够以前所未有的加速度在大规模计算集群上运行，解决了隐含的游戏位置，显著提高了复杂性，并且大幅减少了运行时间，相较于之前的最佳解算器GLOP表现出了四倍数量级的性能提升。这项研究标志着并行Proof-Number搜索的重大突破，对于复杂性增长的游戏和其它计算密集型问题具有深远影响。这项创新为其他偏序博弈和其他NP完全问题的并行求解提供了一个可行的模板和方向。", "conclusion": "本研究证明了专用于并行计算环境的改进Proof-Number搜索算法是可能的，并展示了其在Sprouts游戏中处理大型游戏树时的优势，明确了在处理复杂性高度增长的数据集时的有效性。这项算法不仅克服了传统的并行化方法的局限性，而且还为解决偏序博弈和其他NP完全问题提供了一个强大的工具，并为未来的工作指明了方向。"}
{"llm_update_time": "20251116", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.10572", "html_url": "https://arxiv.org/abs/2511.10572", "title": "延迟反馈下的两级上下文多臂 bandit 个体资源分配", "title_en": "Bi-Level Contextual Bandits for Individualized Resource Allocation under Delayed Feedback", "authors": "Mohammadsina Almasi,Hadis Anahideh", "background": "在高风险领域（如教育、就业和医疗保健）中，公平分配有限资源需要平衡短期效益与长期影响，同时考虑延迟结果、隐藏异质性和伦理约束。然而，大多数基于学习的分配框架要么假设即时反馈，要么忽视个体特征和干预动态之间的复杂关系。", "innovation": "提出了一种新颖的两级上下文多臂 bandit 框架，用于在延迟反馈下进行个体化资源分配。该框架能够动态人口、容量限制和时间敏感效果的实时设置中操作，并通过资源特定的延迟内核来模拟能源的冷却期和延迟治疗效果。通过明确建模时间动态和反馈延迟，算法能够随着新数据的不断更新而不断优化其策略，从而实现更为响应和适应性的决策。", "conclusion": "该方法在教育和劳动力发展等两个真实世界数据集上进行了验证，结果显示能够获得更高的累积效果，更好地适应延迟结构，并确保亚组间公平分配。研究结果强调了具有延迟感知的数据驱动决策系统的潜在价值，以改善机构政策和社会福利。"}
{"llm_update_time": "20251116", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.10501", "html_url": "https://arxiv.org/abs/2511.10501", "title": "使用图神经网络、深度强化学习和概率主题建模的战略对手建模", "title_en": "Strategic Opponent Modeling with Graph Neural Networks, Deep Reinforcement Learning and Probabilistic Topic Modeling", "authors": "Georgios Chalkiadakis,Charilaos Akasiadis,Gerasimos Koresis,Stergios Plataniots,Leonidas Bakopoulos", "background": "本文综述了主要用于揭露适应目标任务的战略对手建模的机器学习方法的研究现状，特别是重点讨论了图神经网络（GNN）、深度强化学习（DRL）和概率主题建模（PTM）。文章强调了GNN在处理不确定性和异质性方面的能力，以及在多智能体环境中的潜在应用价值。同时，也探讨了这些方法如何结合博弈论概念，以增强其实用性和广泛性。", "innovation": "本文提出了一种新的方法，即使用图神经网络、深度强化学习和概率主题建模来解决多智能体环境中的战略对手建模问题。这种方法不仅能够在多变的环境中适应，还能平衡稳定性和适应性，有效应对不确定性和异质性挑战，同时保证计算上的可扩展性和解决方案的可操作性。", "conclusion": "面对不确定性和异质性，需要具备非稳态环境的适应性，需要在稳定性和适应性之间寻求平衡，需要有效应对不确定性和异质性，以及确保计算的可扩展性和问题的解决的可行性等开放性挑战。"}
{"llm_update_time": "20251116", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.10524", "html_url": "https://arxiv.org/abs/2511.10524", "title": "在人工智能时代的重新思考科学", "title_en": "Rethinking Science in the Age of Artificial Intelligence", "authors": "Maksim E. Eren,Dorianis M. Perez", "background": "人工智能（AI）正在重塑跨化学、生物医学等领域中的研究设计、执行和传播方式。本文探讨了AI如何改变研究工作流程，包括帮助研究人员管理信息洪流、过滤文献、发现跨学科联系、生成假设以及设计和执行实验。这些进步标志着从将AI视为简单的计算工具到将其视为科学中的积极参与者。然而，这种转变需要仔细整合并进行治理。文章指出，当前AI必须在同行评审、伦理评估和结果验证等学术工作流程中作为人类判断的补充，而不是替代品。因此，本文呼吁通过促进透明性、可重复性和问责制的政策，在科研实践中采用AI技术。", "innovation": "AI在帮助科研工作者管理信息、过滤文献、生成假设和试验设计及执行方面发挥了关键作用，标志着AI从计算工具向科学积极参与者的转变。这需要在科研工作流程中融合AI技术，但仍需保持对人类判断的依赖和补充作用。相关策略应包括增强透明度、可重复性和建立问责制等政策。", "conclusion": "本文主张应通过促进透明度、可重复性和问责制的政策，在科研实践中有意识地采用AI技术。AI应当作为人类判断的补充，而非替代工具，特别是在同行评审、伦理评估和结果验证等关键领域。"}
{"llm_update_time": "20251116", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.09564", "html_url": "https://arxiv.org/abs/2511.09564", "title": "基于Mamba的多视角结构理解方法用于分子基态构象预测", "title_en": "Mamba-driven multi-perspective structural understanding for molecular ground-state conformation prediction", "authors": "Yuxin Gou,Aming Wu,Richang Hong,Meng Wang", "background": "对分子结构有全面的理解对于预测分子基态构象及其性质信息至关重要。最近，状态空间模型（如Mamba）在长序列建模中显示出巨大潜力，并在语言和视觉任务中取得了显著成果。然而，Mamba在分子基态构象预测中的作用尚未得到充分利用。", "innovation": "作者设计了一种基于Mamba的通用且高效的框架，该框架以多视角结构理解方法（MPSU-Mamba）来捕捉关键组成部分。特别是，针对复杂多样的分子，提出了三种不同的专用扫描策略来构建相应分子结构的综合感知，并定义了亮通道引导机制来区分关键构象相关的原子信息。", "conclusion": "实验结果表明，MPSU-Mamba在QM9和Molecule3D数据集上显著优于现有方法。此外，即使在少量训练样本的情况下，MPSU-Mamba仍然表现出色，证明了该方法确实有助于理解分子结构。"}
{"llm_update_time": "20251116", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.10593", "html_url": "https://arxiv.org/abs/2511.10593", "title": "Regular Games --基于自动机的通用游戏语言", "title_en": "Regular Games -- an Automata-Based General Game Playing Language", "authors": "Radosław Miernik,Marek Szykuła,Jakub Kowalski,Jakub Cieśluk,Łukasz Galas,Wojciech Pawlik", "background": "提出了一种新的通用游戏玩法系统RG，旨在既高效又方便游戏设计。RG系统包括几种语言，核心部分为一个用有限自动机定义规则的低级语言，其机制简单，便于自动化处理。此系统适用于具有非完美信息的有限动作顺序游戏类别，更高层次的语言用于游戏设计（由人类或生成内容过程），最终被翻译为低级语言。_RG相比现有技术生成更快的游戏前向模型，在效率方面优于其他GGP系统（如Regular Boardgames和Ludii）。RG生态还包括编辑器（带有LSP）、自动机可视化、基准测试工具和游戏描述转换调试器等模块。", "innovation": "提出了一种基于自动机的新型GGP系统RG，该系统核心使用低级语言定义规则，具备高效和便于游戏设计的特点。RG能够生成更快的前向模型，它自身的生态系统包括多个工具支持，如编辑器、可视化工具和调试器。", "conclusion": "RG系统以自动机为核心，简洁高效，支持游戏设计，并在前向模型生成方面表现出色，同时配备多种实用工具，构建了一个完整的生态系统。"}
{"llm_update_time": "20251116", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.09559", "html_url": "https://arxiv.org/abs/2511.09559", "title": "基于定向二部图的概率偏差注意力机制在长尾ICD编码中的应用", "title_en": "Probability-Biased Attention over Directed Bipartite Graphs for Long-Tail ICD Coding", "authors": "Tianlei Chen,Yuxiao Chen,Yang Li,Feifei Wang", "background": "自动化国际疾病分类（ICD）编码旨在为临床文档分配多个疾病代码，构成了健康信息化中的关键多标签文本分类任务。然而，任务的挑战性源于巨大的标签空间（10,000至20,000个代码）和长尾分布，其中少量代码占据主导地位，而许多罕见代码缺乏足够的训练数据。", "innovation": "提出了一种学习方法，用于建模代码间的细粒度共现关系。通过构建由常见和罕见代码节点组成的定向二部图编码器，确保信息流为单方向，且边仅从常见节点指向罕见节点。通过条件概率计算构建了基于概率偏差的连接性质，将其注入编码器的注意力模块，称为共现编码。通过大型语言模型生成详细的代码描述，增强了初始嵌入，并提供了临床上下文和共病信息，作为代码系统中统计共现关系的外部知识。", "conclusion": "在三个自动化ICD编码基准数据集上的实验表明，该方法在Macro-F1方面达到了最先进的性能，特别是在长尾分类中表现出显著改进。"}
{"llm_update_time": "20251116", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.10627", "html_url": "https://arxiv.org/abs/2511.10627", "title": "使用情景程序查询标记的时间序列数据", "title_en": "Querying Labeled Time Series Data with Scenario Programs", "authors": "Edward Kim,Devan Shanker,Varun Bharadwaj,Hongbeen Park,Jinkyu Kim,Hazem Torfah,Daniel J Fremont,Sanjit A Seshia", "background": "仿真测试已成为确保基于网络物理系统的安全性的重要补充。由于仿真环境和实际系统之间的差异，导致了‘仿真到现实’的差距。这种差距使得在仿真中发现的自动驾驶汽车（AV）故障情景在实际系统的现实世界中可能并不具有重现性。因此，需要一种有效的方法来验证仿真中的故障情景是否在实际系统中也存在，并且提出了一个算法来查询标记的时间序列数据，以匹配抽象的情景设定。", "innovation": "提出了一个使用情景程序来查询标记的时间序列数据的有效方法。该方法通过定义如何标记的时间序列传感器数据匹配抽象情景，并提供了一个查询算法，给定情景程序和标记数据集，能够识别出匹配特定情景的数据子集。实验结果显示，该算法在查询情景方面比最先进的商业视觉大型语言模型更准确且快得多，并且能够处理更长的时间序列数据集。", "conclusion": "通过将标记的时间序列数据与抽象情景进行匹配，研究提供了一种有效的方式来验证仿真中的故障情景在实际系统中存在的可能性，从而能够更大规模地应用到自动驾驶技术的测试和验证中。"}
{"llm_update_time": "20251116", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.09571", "html_url": "https://arxiv.org/abs/2511.09571", "title": "基于通用智能的碎片化（GIF）：一种用于峰标记光谱仿真框架", "title_en": "General Intelligence-based Fragmentation (GIF): A framework for peak-labeled spectra simulation", "authors": "Margaret R. Martin,Soha Hassoun", "background": "尽管参考资料库和高级计算工具不断发展，但代谢组学领域的进展仍受限于光谱注释率低。近年来，大型语言模型（LLMs）在多种生成和推理任务中表现出色，引起了将其应用于特定科学挑战的兴趣，例如光谱注释。因此，需要一种结构化的框架来引导LLMs完成复杂的科学任务。", "innovation": "本文提出了一种新的框架——基于通用智能的碎片化（GIF），用于通过结构化提示和推理引导预训练LLMs进行光谱模拟。GIF利用了标记、结构化的输入/输出、系统提示、指令提示和迭代完善等方法。GIF框架提供了一种结构化的替代方法，以便系统地引导LLMs完成任务。通过GIF框架，我们评估了几种通用LLMs在光谱碎片化推理和强度预测方面的表现，并用其在新的问答数据集MassSpecGym QA-sim上进行基准测试。结果显示，GPT-4o和GPT-4o-mini在模拟和实际光谱之间的余弦相似度分别为0.36和0.35，超过了包括GPT-5、Llama-3.1和ChemDFM在内的其他预训练模型。此外，GIF也优于几个深度学习基线。", "conclusion": "本研究表明，使用LLMs不仅可以进行光谱仿真，还可以支持人机协作的工作流和结构化、可解释的分子碎片化推理。"}
{"llm_update_time": "20251116", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.09568", "html_url": "https://arxiv.org/abs/2511.09568", "title": "VEDA：通过方差爆炸扩散与退火进行3D分子生成", "title_en": "VEDA: 3D Molecular Generation via Variance-Exploding Diffusion with Annealing", "authors": "Peining Zhang,Jinbo Bi,Minghu Song", "background": "扩散模型在3D分子生成方面显示出前景，但存在采样效率和构象精度之间的根本权衡。流式模型速度快，但常常生成几何上不准确的结构，因为它们难以捕捉分子构象的多峰分布。相比之下，去噪扩散模型更准确，但采样速度较慢，这被认为是扩散动态与SE(3)-对称架构之间次优集成所致的局限性。", "innovation": "提出了VEDA，一种统一的SE(3)-对称框架，结合方差爆炸扩散与退火，以高效生成构象准确的3D分子结构。创新点包括：(1) 一种VE计划，以功能上类似模拟退火的方式注入噪声，提高3D准确性并降低松弛能量；(2) 一种新型预处理方案，结合了SE(3)-对称网络的坐标预测特性和基于残差的扩散目标；(3) 一种新的arcsin基计划，将采样集中在对数信噪比的关键区间。", "conclusion": "在QM9和GEOM-DRUGS数据集上，VEDA实现了与流式模型相当的采样效率，仅需100步采样即达到最先进的价数稳定性和有效性。更重要的是，VEDA生成的结构在GFN2-xTB优化期间具有极高的稳定性，中值能量变化仅为1.72 kcal/mol，远低于架构基本线SemlaFlow的32.3 kcal/mol。该框架证明了原理性将VE扩散与SE(3)-对称架构集成可以同时实现高化学准确性和计算效率。"}
{"llm_update_time": "20251116", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.09586", "html_url": "https://arxiv.org/abs/2511.09586", "title": "在互动学习时代扩展环境以提升LLM代理能力：一项综述", "title_en": "Scaling Environments for LLM Agents in the Era of Learning from Interaction: A Survey", "authors": "Yuchen Huang,Sijia Li,Minghao Liu,Wei Liu,Shijue Huang,Zhiyuan Fan,Hou Pong Chan,Yi R. Fung", "background": "基于LLM的代理能够在多个领域自主完成复杂任务。然而，要培养适应行为和长期决策等能力，仅通过静态数据集进行训练是不够的。这些数据集的构建成本高、缺乏动态性和现实性。现有的共识是，代理应直接与环境互动，并通过强化学习从经验中学习。该方法将此迭代过程形式化为生成-执行-反馈（GEF）循环，在此范式中，环境作为不可或缺的数据提供者发挥作用，强调需要将环境扩展到更高复杂度、更现实性和交互性。", "innovation": "本文从环境中心视角系统地回顾了针对LLM代理的环境扩展方法，并按GEF循环的生成、执行和反馈阶段进行组织。分析了基准、实现策略和应用，合并碎片化的进展，并指出了代理智能的未来研究方向。", "conclusion": "总结了基于动态环境扩展的代理训练方法，强调了环境扩展的重要性，提出了未来研究方向，期望通过进一步的研究提高代理智能的学习能力。"}
{"llm_update_time": "20251116", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.09603", "html_url": "https://arxiv.org/abs/2511.09603", "title": "使用随机森林分类器检测高级持续威胁的可解释递归特征消除", "title_en": "An explainable Recursive Feature Elimination to detect Advanced Persistent Threats using Random Forest classifier", "authors": "Noor Hazlina Abdul Mutalib,Aznul Qalid Md Sabri,Ainuddin Wahid Abdul Wahab,Erma Rahayu Mohd Faizal Abdullah,Nouar AlDahoul", "background": "入侵检测系统（IDS）在现代网络安全框架中扮演着至关重要的角色，通过提供对抗高级威胁行为者的首要防御机制。本文基于CICIDS2017数据集，提出了一种结合递归特征消除（RFE）和随机森林（RF）的可解释入侵检测框架，以增强对高级持续威胁（APTs）的检测能力。", "innovation": "引入了一种结合递归特征消除（RFE）和随机森林（RF）的可解释入侵检测框架，通过CICIDS2017数据集进行了实验，并使用SHapley Additive exPlanations (SHAP) 来解释每个选定特征的贡献。该方法在去除冗余特征后训练RF模型，表现出99.9%的检测准确率，减少了误报率和计算成本，相比传统分类器更具优势。", "conclusion": "实验证明，结合解释型人工智能（Explainable AI）和特征选择方法的RF-RFE在增强入侵检测能力方面非常有效，能够开发出高效、透明且可部署的入侵检测系统解决方案。"}
{"llm_update_time": "20251116", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.09576", "html_url": "https://arxiv.org/abs/2511.09576", "title": "Prostate-VarBench：一种基于可解释TabNet框架的前列腺癌变体分类基准", "title_en": "Prostate-VarBench: A Benchmark with Interpretable TabNet Framework for Prostate Cancer Variant Classification", "authors": "Abraham Francisco Arellano Tavara,Umesh Kumar,Jathurshan Pradeepkumar,Jimeng Sun", "background": "对于前列腺癌，基因组变异具有不确定意义（VUS）限制了临床应用，因为当缺乏致病性或良性证据时，这会延迟诊断和治疗。此外，不同来源的注释不一致，缺乏特定于前列腺的基准来公平比较，也限制了进展。", "innovation": "本研究引入了Prostate-VarBench，这是一种可定制的管道，综合了COSMIC（体细胞癌症突变）、ClinVar（专家整理的临床变异）和TCGA-PRAD（来自癌症基因组图谱的前列腺肿瘤基因组数据），创建了一个包含193,278个变体的标准化数据集。此外，通过修正了Variant Effect Predictor（变异效应预测器）中合并多个转录记录的问题，并统一了包括群体频率、变异类型和临床背景在内的56个可解释特征，提高了对错义变异分类的准确性，降低了VUS的不确定度。基于此资源，研究团队训练了一个可解释的TabNet模型来分类变异的致病性，该模型步骤稀疏化掩码提供了一致于分子肿瘤病理科评审的个案解释，并在保留的数据集上取得了89.9%的准确率，相较于原始的VEP修正，VUS降低了6.5%的绝对值。", "conclusion": "通过Prostate-VarBench和基于可解释TabNet框架的新型分类模型，本研究有效解决了前列腺癌变异分类中的不确定性和数据一致性问题，提升了诊断的准确性与可靠性。"}
{"llm_update_time": "20251116", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.09578", "html_url": "https://arxiv.org/abs/2511.09578", "title": "HeatGen: 一种多物理场散热器设计优化的引导扩散框架", "title_en": "HeatGen: A Guided Diffusion Framework for Multiphysics Heat Sink Design Optimization", "authors": "Hadi Keramati,Morteza Sadeghi,Rajeev K. Jaiman", "background": "本文研究提出了一种基于受指导去噪扩散概率模型（DDPM）的生成优化框架，利用代理梯度生成在满足特定表面温度阈值下压降最小的散热器设计。几何结构由多个鳍片的边界表示，采用多保真度方法生成训练数据。利用这种数据集，以及表示边界表示几何结构的向量，对去噪扩散概率模型进行训练，生成与数据中观察到的特性一致的散热器。训练两个不同的残差神经网络来预测每个几何结构的压降和表面温度。使用这些代理模型的梯度来指导几何结构生成过程以满足低压和表面温度约束。", "innovation": "本文提出的生成优化框架利用受指导去噪扩散概率模型，结合多保真度方法生成训练数据，通过训练残差神经网络来预测压降和表面温度，并利用这些模型的梯度指导几何结构生成过程，实现高效的筛选生成方法。与传统的黑盒优化方法和拓扑优化方法相比，该方法在足够训练数据的支持下具有可扩展性，不受逆向推理的限制，且在新约束下进行推理成本低廉。生成的样本在压降上比传统黑盒优化方法低10%左右，展现了其在散热器设计优化方面的创新能力。", "conclusion": "本文的工作朝着建立电子冷却的基础生成模型迈出了重要一步。通过该生成优化框架，能够有效地生成满足特定温度和压力降要求的散热器设计，最终实现更低的压降。该方法能够节省传统优化方法的成本和时间，并在一个预训练的模型基础上，快速响应新的约束条件。"}
{"llm_update_time": "20251116", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.09681", "html_url": "https://arxiv.org/abs/2511.09681", "title": "SEBA: 样本高效的动作盲盒攻击视觉强化学习", "title_en": "SEBA: Sample-Efficient Black-Box Attacks on Visual Reinforcement Learning", "authors": "Tairan Huang,Yulin Jin,Junxu Liu,Qingqing Ye,Haibo Hu", "background": "视觉强化学习在视觉控制和机器人技术方面取得了显著进展，但其在对抗性扰动下的脆弱性尚未得到充分探索。现有的大多数黑盒攻击主要针对向量基或离散动作的强化学习，对于基于图像的连续控制，它们的有效性受限于庞大的动作空间和过高的环境查询次数。", "innovation": "SEBA 提出了一种样本高效框架，用于针对视觉 RL 代理的黑盒对抗性攻击。SEBA 结合了阴影 Q 模型、生成对抗网络和世界模型，这三种方法分别用于估计对抗条件下的累计奖励，生成视觉上不可察觉的扰动，以及模拟环境动力学以减少对现实世界的查询。通过交替训练阴影模型和细化生成器的两阶段迭代训练过程，SEBA 实现了强攻击性能同时保持高效。", "conclusion": "在MuJoCo和Atari基准测试中的实验表明，SEBA 有效地减少了累计奖励，保持了视觉保真度，并大大减少了环境交互，与之前的黑盒和白盒方法相比具有显著优势。"}
{"llm_update_time": "20251116", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.09663", "html_url": "https://arxiv.org/abs/2511.09663", "title": "对齐债务：使AI可用的隐藏工作", "title_en": "Alignment Debt: The Hidden Work of Making AI Usable", "authors": "Cumi Oyemike,Elizabeth Akpan,Pierre Hervé-Berdys", "background": "前沿的大规模语言模型（LLMs）通常在高资源假设（关于语言、知识、设备和网络连接）下进行优化，尽管这些模型广泛可用，但在全球南方（特别是肯尼亚和尼日利亚）的条件下并不总是合适。这导致用户需要额外的工作来使这些系统具备可使用性，这种用户层面的负担被称为对齐债务。", "innovation": "作者通过调查肯尼亚和尼日利亚的411名AI用户，开发并验证了一个四部分的对齐债务分类体系。研究表明，对齐债务包括文化与语言、基础设施、知识论和交互四个维度，这些债务在不同国家之间存在差异，挑战了一刀切的非洲适用假设。不同类型的对齐债务与验证行为之间存在显著相关性，但某些形式的对齐不良无法仅通过验证来解决。", "conclusion": "本研究强调，公平性不仅应由模型指标来判断，还应考虑对边缘用户负担的影响，并强调需要设计出上下文敏感的安全措施以缓解对齐债务。同时，对齐债务框架为测量用户负担提供了实证支撑，有助于指导设计实践和新兴的非洲地区AI治理工作。"}
{"llm_update_time": "20251116", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.09652", "html_url": "https://arxiv.org/abs/2511.09652", "title": "乐观强化学习中的分位数目标", "title_en": "Optimistic Reinforcement Learning with Quantile Objectives", "authors": "Mohammad Alipour-Vaezi,Huaiyang Zhong,Kwok-Leung Tsui,Sajad Khodadadian", "background": "近年来，强化学习（RL）取得了巨大的成功。然而，经典的RL基础忽略了目标函数的风险敏感性，在医疗保健和金融等领域是至关重要的。一种广泛采用的方法是通过优化累计回报分布的特定分位数来引入风险敏感性。", "innovation": "本文开发了UCB-QRL算法，这是一种在有限时限马尔可夫决策过程（MDPs）中针对$\tau$分位数目标的乐观学习算法。该算法在每一轮中首先估计基态转换概率，然后以该估计为中心的置信球优化分位数价值函数。证明UCB-QRL在经验模式下的高概率遗憾边界为$\textit{\textbf{O}}\big((2/\textit{\textbf{\textnormal{\textkappa}}})^{H+1}H\textbf{\textroot}{SATH \textbf{\textlog}(2SATH/\textit{\textdelta})}\big)$，其中$\textit{\textbf{\textnormal{\textkappa}}}>0$是一个与问题相关的常数。", "conclusion": "UCB-QRL算法提供了针对分位数目标的高概率遗憾边界，适用于在有限状态、动作、周期和时限的环境下进行优化。"}
{"llm_update_time": "20251116", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.09727", "html_url": "https://arxiv.org/abs/2511.09727", "title": "Baby Sophia: 发展性的自探索方法通过自触碰和手的注意", "title_en": "Baby Sophia: A Developmental Approach to Self-Exploration through Self-Touch and Hand Regard", "authors": "Stelios Zarifis,Ioannis Chalkiadakis,Artemis Chardouveli,Vasiliki Moutzouri,Aggelos Sotirchos,Katerina Papadimitriou,Panagiotis Filntisis,Niki Efthymiou,Petros Maragos,Katerina Pastra", "background": "本文受婴儿发展启发，提出了一种用于自主自探索的强化学习（RL）框架。通过模仿婴儿的好奇探索身体的方式，机器人代理学习自触碰和手的注意行为。机器人智能体通过内在奖励进行学习，这些奖励反映了婴儿对其身体的好奇探索。", "innovation": "提出了Baby Sophia为代表的机器人自探索框架，使用BabyBench模拟环境，通过内在奖励（模仿婴儿的好奇探索）学习自触碰和手的注意行为。使用高维触觉输入生成紧凑且有意义的表示，并通过内在奖励和逐级学习鼓励广泛的体态覆盖、平衡和泛化。另通过手部运动练习和视觉特征学习手部注意。最终通过单一手到双手的梯度训练，实现了视觉-运动协调。", "conclusion": "本研究结果展示了仅通过内在的好奇信号，无需外部监督即可驱动协调多模态学习的能力，模仿婴儿从自发运动练习到有目的行为的发展过程。"}
{"llm_update_time": "20251116", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.09605", "html_url": "https://arxiv.org/abs/2511.09605", "title": "TomoGraphView: 使用全方位切片表示和图神经网络的3D医学图像分类", "title_en": "TomoGraphView: 3D Medical Image Classification with Omnidirectional Slice Representations and Graph Neural Networks", "authors": "Johannes Kiechle,Stefan M. Fischer,Daniel M. Lang,Cosmin I. Bercea,Matthew J. Nyflot,Lina Felsner,Julia A. Schnabel,Jan C. Peeken", "background": "随着医学断层扫描检查的增长，已经研发出自动方法来提取全面的成像特征，以辅助任务如肿瘤特征识别等，同时减轻医生的任务负担。然而，3D医学图像分类仍然是一大难题，因为体积数据中固有的复杂空间关系和长程依赖性。从零开始训练模型在数据稀缺的情况下表现不佳，而且缺乏大规模的多模态3D数据集限制了3D医学影像基础模型的发展。尽管如此，最近研究证明了2D视觉基础模型（最初在自然图像上训练）在医学图像分析方面的潜力，这种模型作为特征提取器效果显著。然而，现有的将2D模型应用到3D体积上的方法（通过切片分解），效果仍不尽如人意。传统体素切片策略依赖于轴位、矢状面或冠状面等标准平面，这在目标结构与标准视平面不一致时无法充分捕捉空间范围。现有的切片聚合策略也未能有效保留体素结构，从而降低了切片间的空间一致性。", "innovation": "本文提出了TomoGraphView框架，该框架将全方位体素切片与球面图基特征聚集结合。该框架旨在克服现有技术中的局限性，如不能充分捕捉目标结构的空间范围和缺乏对于保持体素结构的考虑。与传统的体位切片策略相比，该方法可以更有效地处理和理解复杂的3D医学图像，从而提高肿瘤特征识别的准确性。为了实现这一目标，TomoGraphView框架采用了全方位的体积切片方法，以更好地捕捉目标结构，同时使用基于图的特征聚合技术保持体素结构的完整性。此外，该文提供的开源代码库和用户友好的全方位体素切片库，对于推动相关研究具有重要意义。", "conclusion": "研究最终表明，TomoGraphView通过结合全方位体积切片和基于图的特征聚合，成功地改进了3D医学图像分类的性能。该框架不仅提高了肿瘤特征识别的准确性，还为3D医学影像分析提供了一种新的方法。开源代码和库的共享，也为其他研究人员提供了宝贵的资源，促进了整个领域的进步。"}
{"llm_update_time": "20251116", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.09737", "html_url": "https://arxiv.org/abs/2511.09737", "title": "使用SPARC进行未知分布外泛化：用单一策略驾驶100辆未见过的车辆", "title_en": "Out-of-Distribution Generalization with a SPARC: Racing 100 Unseen Vehicles with a Single Policy", "authors": "Bram Grooten,Patrick MacAlpine,Kaushik Subramanian,Peter Stone,Peter R. Wurman", "background": "在机器人学和控制领域，如何使机器人适应未见过的环境是一个重大挑战。本文关注在不同上下文环境中的情境强化学习，例如自动驾驶汽车或在训练环境外不同地形与天气条件下运行的四足机器人。已有研究通过分步训练上下文编码器和历史自适应模块来解决此类问题，尽管取得了一定进展，但这种方法的实现和训练过程较为复杂。本文旨在简化这一过程，提出了一种单阶段适应方法SPARC，以实现更可靠和稳健的未知分布外泛化。", "innovation": "本文引入了一种新的单阶段适应方法SPARC，旨在简化现有方法并提高在未知环境下运行的控制造能。通过在高保真赛车模拟器Gran Turismo 7和风扰动的MuJoCo环境中测试SPARC，验证了该方法的有效性。", "conclusion": "实验结果表明，SPARC能够在不提供显式上下文信息的情况下，实现可靠和稳健的未知分布外泛化，为不同上下文环境中的强化学习提供了有效解决方案。"}
{"llm_update_time": "20251116", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.09740", "html_url": "https://arxiv.org/abs/2511.09740", "title": "高级驾驶辅助系统中的污渍检测", "title_en": "Soiling detection for Advanced Driver Assistance Systems", "authors": "Filip Beránek,Václav Diviš,Ivan Gruber", "background": "高级驾驶辅助系统需要对汽车摄像头的污渍检测有准确的能力，以应对外部条件（如天气、灰尘等）的挑战。将污渍检测视为语义分割问题，对比流行分割方法和瓷砖级别分类方法，发现分割方法在性能上有优势。然而，Woodscape数据集存在数据泄露和不精确的标注问题，因此需要改进数据集以提高分割方法的性能速度。", "innovation": "提出了将污渍检测作为语义分割问题的研究方法，对比了许多流行的分割方法和块级别分类方法，展示了分割方法的优越性。同时，发现了Woodscape数据集的问题并创建了一个新的数据子集，虽然较小但能够提供足够的信息使分割方法达到可比的效果且节省时间。这些方法和数据集被公布于指定的网址。", "conclusion": "改进了高级驾驶辅助系统中的污渍检测方法，通过创建更有效但数据量较小的新数据子集，提升了检测速度和准确性。"}
{"llm_update_time": "20251116", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.09724", "html_url": "https://arxiv.org/abs/2511.09724", "title": "PALMS+: 基于模块化图像的楼层计划定位，利用深度基础模型", "title_en": "PALMS+: Modular Image-Based Floor Plan Localization Leveraging Depth Foundation Model", "authors": "Yunqian Cheng,Benjamin Princen,Roberto Manduchi", "background": "在GPS受限环境中，室内定位对于紧急响应和辅助导航等应用至关重要。现有的视觉定位方法，如PALMS，可以利用地标与静态扫描来实现无基础设施的室内定位，但这些方法受到智能手机激光雷达的短距离限制，并且容易面临室内布局的模糊性问题。本研究旨在克服这些限制，提出了一种模块化、图像为基础的定位系统PALMS$+$，该系统通过利用基础深度估计模型（Depth Pro）重建与地标尺度对齐的3D点云，并结合卷积操作以匹配地板平面，实现基于图像的室内定位，输出位置和方向的概率分布，从而支持直接或顺序定位。", "innovation": "PALMS$+$系统通过对定位挑战的解决做出了创新：引入了基础深度估计模型（Depth Pro）来构建基于图像的3D点云重建，解决了现有方法中的距离短和布局模糊问题。详细地讲，该系统利用深度估计模型从已对准的RGB图像重建具有地标相同比例尺的3D点云，然后通过卷积操作和地板平面匹配来完成几何布局匹配，最终输出用于直接或顺序定位的位置和方向概率分布。这种基于图像的方法不依赖任何训练数据即可实现的室内定位，并且能够提高基于粒子滤波器的序列定位准确性，证明了其在无摄像头跟踪和基础设施自由应用方面的鲁棒性和潜力。", "conclusion": "本研究在Structured3D数据集和一个自定义校园数据集上评估了PALMS$+$的性能，结果显示该系统在固定和序列定位下的准确性都优于现有方法，证明了其在无摄像头跟踪和基础设施自由应用中的优势，并强调了该系统在实际应用中的潜力。有关代码和数据可以在提供的链接中获取。"}
{"llm_update_time": "20251116", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.09741", "html_url": "https://arxiv.org/abs/2511.09741", "title": "TawPipe: 基于拓扑感知的权重管道并行性加速长上下文大型模型训练", "title_en": "TawPipe: Topology-Aware Weight Pipeline Parallelism for Accelerating Long-Context Large Models Training", "authors": "Houming Wu,Ling Chen", "background": "训练大规模语言模型（LLMs）受到设备内存限制和高昂的设备间通信成本的限制。虽然管道并行性通过将模型分割到不同设备上减轻了内存压力，但它会导致与序列长度线性增加的激活通信开销，限制了长时间上下文模型的训练效率。最近的方法（例如WeiPipe）通过传输模型权重而不是激活数据来减轻这一问题，但是仍然存在冗余的点对点（P2P）传输和节点内部带宽利用不足的问题。", "innovation": "TawPipe基于拓扑感知的方法，通过利用分布式集群中的分级带宽提高通信效率。具体来说，TawPipe通过基于拓扑进行设备分组，优化节点内集合通信和节点间点对点通信；为每个设备分配固定模型权重和梯度碎片，避免冗余传输；并且通过通信与计算的重叠来隐藏延迟。TawPipe将大部分通信限制在节点边界以内，显著减少了跨节点流量。", "conclusion": "在最多24块GPU上的实验表明，TawPipe在大型模型的训练吞吐量和可扩展性方面优于最先进的基线方法。"}
{"llm_update_time": "20251116", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.09735", "html_url": "https://arxiv.org/abs/2511.09735", "title": "基于动态占位模型的Social LSTM在现实行人轨迹预测中的应用", "title_en": "Social LSTM with Dynamic Occupancy Modeling for Realistic Pedestrian Trajectory Prediction", "authors": "Ahmed Alia,Mohcine Chraibi,Armin Seyfried", "background": "在动态且拥挤的环境条件下，现实的行人轨迹预测仍然是一个具有挑战性的任务，因为人类运动的复杂性和个体间的相互影响。虽然深度学习模型最近在从2D轨迹数据中隐式学习这些模式方面取得了显著成果，但大多数方法将行人视为点实体，忽略了每个人的物理空间。因此，本文的研究背景是现有的预测模型在处理人群密度变化时存在不足，比如不能准确预测行人的运动轨迹和避免现实中的碰撞。为了改进这些不足，本文提出了一种结合新的动态占位损失函数（Dynamic Occupied Space loss function）的Social LSTM模型，从而增强原有模型并提高预测的准确性和实时性。", "innovation": "本文的创新点在于提出了一种新的深层学习模型，通过结合动态占位损失函数（Dynamic Occupied Space loss function）来改进Social LSTM模型，使得模型不仅能降低碰撞率，还能提高在不同人群密度条件下的行人类别预测的准确性和置信度。这种新的损失函数通过将平均位移误差与一个对场景密度和个体空间占用敏感的新碰撞惩罚相结合，指导Social LSTM学习避免现实中的碰撞，而不增加不同人群密度下的位移误差。由此模型可以在从Lyon 2022灯光节真实录制的行人轨迹数据中生成的五个数据集中，通过训练和评估保持高效，并且在大多数测试集上显著优于当前的技术领先模型，体现了模型的有效性和实用性。", "conclusion": "实验结果显示，与基线模型相比，提出的模型在所有数据集中不仅能减少31%的碰撞率，还能将平均位移误差和最终位移误差分别降低5%和6%。此外，提出的模型在大多数测试集中始终优于其他最新的深度学习模型，从而证明了改进的Social LSTM模型在现实行人轨迹预测中的优越性。"}
{"llm_update_time": "20251116", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.09754", "html_url": "https://arxiv.org/abs/2511.09754", "title": "历史的韵律：宏微观上下文检索在稳健金融预测中的应用", "title_en": "History Rhymes: Macro-Contextual Retrieval for Robust Financial Forecasting", "authors": "Sarthak Khanna,Armin Berger,Muskaan Chopra,Rafet Sifa", "background": "金融市场本质上是非稳态的：结构性断裂和宏观经济制度转换常常导致超出分布（OOD）时预测模型失效。传统的多模态方法通常通过融合数值指标和文本情感来进行简单结合，但这些方法往往不能适应这样的转换。", "innovation": "本文提出了一种宏微观上下文检索，这是一种检索增强型预测框架，将宏观指标（如CPI、失业率、利差、GDP增长率）和金融市场情绪置于共享相似空间中，使预测在推理过程中能够通过无重新训练的方式联合检索到历史相似的时期，从而实现因果检索。", "conclusion": "该框架在对道琼斯工业平均指数长达17年的数据（2007-2023）进行训练，并在AAPL（2024）和XOM（2024）进行OOD评估时，一直缩小了CV到OOD性能差距。人为条件检索在AAPL和XOM上实现了唯一积极的出样交易成果。基于这一点，这项工作证明在分布变化条件下宏微观意识检索可以提供稳健且可解释的预测。所有数据集、模型和源代码均为公开可获取。"}
{"llm_update_time": "20251116", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.09742", "html_url": "https://arxiv.org/abs/2511.09742", "title": "医学基础模型的功能质量和适应性：胸部X光分类和分割的比较评估", "title_en": "Feature Quality and Adaptability of Medical Foundation Models: A Comparative Evaluation for Radiographic Classification and Segmentation", "authors": "Frank Li,Theo Dapamede,Mohammadreza Chavoshi,Young Seok Jeon,Bardia Khosravi,Abdulhameed Dere,Beatrice Brown-Mulry,Rohan Satya Isaac,Aawez Mansuri,Chiratidzo Sanyika,Janice Newsome,Saptarshi Purkayastha,Imon Banerjee,Hari Trivedi,Judy Gichoya", "background": "医学基础模型（FMs）能够使医学影像应用更加广泛，但其效果因模型的预训练领域（医学vs.一般）、范式（例如，文本引导）和架构不同而异。现有关于这些因素如何影响嵌入质量方面的信息还不明确，这阻碍了选择最适合特定影像学任务的编码器。论文通过评估八种医学和一般领域模型中的视觉编码器，针对胸部X光分析进行了评估，考察了不同预训练范式的效果，揭示了任务对特征质量的影响程度，以及在复杂病灶定位方面的差距和局限性。", "innovation": "研究创新点在于通过线性探针和微调方法对胸部X光分类（气胸、心脏肥大）和分割（气胸、心脏边界）任务进行了基准测试，并发现了特定预训练领域在初步特征质量上的显著优势；同时揭示了特征在复杂病理区分上的局限，并表明基于文本的图像对齐并非必要条件，单一图像和标注引导的模型同样表现优秀；最重要的是，即使是在分割任务上，监督端到端模型依然具有很强的竞争性，超过了部分基础模型。这项工作突出了在多样化医学影像任务中选择合适编码器的重要性，并指明了未来研究的方向，尤其是针对复杂局部病灶定位技术的发展与改进。", "conclusion": "研究结果表明，虽然医学预训练有益，但架构选择（例如，多尺度）也很关键，预训练特征并不总是有效的，特别是在复杂局部病灶定位任务中，监督模型依然是一种强有力的选择。"}
{"llm_update_time": "20251116", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.09765", "html_url": "https://arxiv.org/abs/2511.09765", "title": "Brian Intensify：FXS中基于机器学习的自适应听觉EEG刺激和认知增强框架", "title_en": "Brian Intensify: An Adaptive Machine Learning Framework for Auditory EEG Stimulation and Cognitive Enhancement in FXS", "authors": "Zag ElSayed,Grace Westerkamp,Jack Yanchen Liu,Ernest Pedapati", "background": "神经发育障碍，如脆性X综合症（FXS）和自闭症谱系障碍（ASD），其特点是皮层节律活动紊乱，特别是在alpha和gamma频段。这些异常与注意力、感觉处理和认知功能的缺陷相关。本研究旨在通过基于自适应机器学习的脑-计算机接口（BCI）系统，利用特定频率的听觉刺激调节神经节律，以提高FXS患者的认知准备状态。", "innovation": "本研究开发了一种基于机器学习的自适应听觉EEG刺激框架（Brian Intensify），该框架能够预测EEG响应并动态调整刺激参数，在实验中，13Hz的刺激条件始终能够显著增加alpha活动并抑制gamma活动，满足了优化目标。此外，该框架还建立了一个新型的基于EEG的神经调控优化框架，并为下一代AI整合的BCI系统在FXS和相关障碍中的个性化神经康复提供了基础。", "conclusion": "该研究为基于BCI的认知神经调节建立了新的EEG驱动优化框架，为FXS和相关障碍的个人化神经康复提供了基础模型，未来研究可以进一步完善和优化此框架，以适用于更广泛的神经发育障碍和促进神经康复的效果。"}
{"llm_update_time": "20251116", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.09766", "html_url": "https://arxiv.org/abs/2511.09766", "title": "Ksurf-Drone: 注意力卡尔曼滤波在云资源分配中上下文多臂老虎机优化中应用", "title_en": "Ksurf-Drone: Attention Kalman Filter for Contextual Bandit Optimization in Cloud Resource Allocation", "authors": "Michael Dang'ana,Yuqiu Zhang,Hans-Arno Jacobsen", "background": "容器基础架构中的资源编排和配置参数搜索对于云数据中心是关键问题。由于较大的配置搜索空间和云的不确定性，通常会使用上下文多臂老虎机（Contextual Bandit）技术进行资源编排，包括最先进的无人机编排器。云提供商环境中的虚拟机数量变化引入了工作负载和资源指标的变化性，增加了非线性和噪声，降低了编排决策的准确性。Ksurf 是一种降低方差的最先进技术，非常适合高度变异性云数据环境，能够在这种条件下进行资源的最佳估计。", "innovation": "Ksurf 是一种先进的方差最小化估计器方法，适用于高度变化的云数据环境。此工作评估了 Ksurf 在使用 Drone 作为上下文中多臂老虎机（Contextual Multi-Armed Bandit）目标函数模型时，在包含高度变化工作负载的资源编排任务中的性能。", "conclusion": "Ksurf 在使用 Drone 时显著降低了 95% 和 99% 预测点的延迟方差，展示了 4% 的 CPU 使用率减少和 7 MB 的主节点内存减少，相当于在 Kubernetes 的 VarBench Kubernetes 基准测试中的平均工作节点减少 7% 的成本节省。"}
{"llm_update_time": "20251116", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.09774", "html_url": "https://arxiv.org/abs/2511.09774", "title": "Solvafomer：一种SE(3)对称的图变换器，用于小分子溶解度预测", "title_en": "Solvaformer: an SE(3)-equivariant graph transformer for small molecule solubility prediction", "authors": "Jonathan Broadbent,Michael Bailey,Mingxuan Li,Abhishek Paul,Louis De Lescure,Paul Chauvin,Lorenzo Kogler-Anele,Yasser Jangjou,Sven Jager", "background": "准确预测小分子溶解度对于加速合成和工艺优化至关重要，但实验测量成本高昂，而且许多学习方法要么依赖于量子衍生描述符，要么提供有限的可解释性。", "innovation": "Solvafomer 是一种几何感知的图变换器，能够将溶液建模为具有独立 SE(3) 对称性的多种分子。其架构结合了分子内 SE(3)-对称的注意力与分子间标量注意力，使跨分子通信不需要施加虚假的相对几何关系。Solvafomer 以多任务设置训练，在量子力学数据（CombiSolv-QM）和实验测量数据（BigSolDB 2.0）上交替训练，取得了最佳的性能，接近 DFT 指导梯度增强基线，优于 EquiformerV2 调整方案和基于序列的选项。此外，标记级注意力产生化学连贯的解释：案例研究中恢复了控制空间异构体溶解度差异的已知分子内与分子间的氢键模式。", "conclusion": "Solvafomer 结合几何归导偏置和互补计算与实验数据的混合训练策略，提供了一种准确、可扩展且可解释的溶剂相性质预测方法。"}
{"llm_update_time": "20251116", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.09783", "html_url": "https://arxiv.org/abs/2511.09783", "title": "科莫朗不变量作为联合嵌入预测架构中时间序列聚类涌现的驱动因素", "title_en": "Koopman Invariants as Drivers of Emergent Time-Series Clustering in Joint-Embedding Predictive Architectures", "authors": "Pablo Ruiz-Morales,Dries Vanoost,Davy Pissoort,Mathias Verbeke", "background": "联合嵌入预测架构（JEPAs）是一种强大的自我监督模型，展现出通过底层动力学模式对时间序列数据进行聚类的能力，但这种能力的机理尚不清楚。本文提出了一个关于JEPAs自洽动力学理论的新模型，以解释这一现象，并为自我监督学习和动力系统理论之间的关系提供了理论基础。", "innovation": "本文提出了一个新的理论解释，假设JEPAs的预测目标隐式驱动其学习系统科莫朗算子的不变子空间。证明理想化的JEPAs损失函数在编码器表示系统模式指示函数（即科莫朗特征函数）时被最小化。此外，通过约束JEPAs的线性预测器使其为几乎恒等算子，揭示了预测器在表示解缠方面的关键作用。这一理论为JEPAs的行为提供了更深入的理解，并为设计更健壮和可解释的时间序列模型提供了启示。", "conclusion": "本文揭开了一个关键JEPAs行为的秘密，提供了自我监督学习与动力系统理论之间原理性的连接，并为设计更健壮和可解释的时间序列模型提供了指导。"}
{"llm_update_time": "20251116", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.09775", "html_url": "https://arxiv.org/abs/2511.09775", "title": "通过SHAP熵正则化实现隐私保护的可解释AIoT应用", "title_en": "Privacy-Preserving Explainable AIoT Application via SHAP Entropy Regularization", "authors": "Dilli Prasad Sharma,Xiaowei Sun,Liang Xue,Xiaodong Lin,Pulei Xiong", "background": "AIoT在智能家居环境中的广泛应用加大了对透明和可解释的机器学习模型的需求。为了培养用户的信任并遵守新兴的监管框架，可解释人工智能（XAI）方法，特别是事后技术，如SHapley Additive exPlanations (SHAP)和Local Interpretable Model-Agnostic Explanations (LIME)被广泛使用来解释模型的行为。然而，最近的研究表明，这些解释方法可能会无意中暴露敏感的用户属性和行为模式，从而引入新的隐私风险。", "innovation": "本文提出了一种基于SHAP熵正则化的新型隐私保护方法，以减轻可解释AIoT应用中的隐私泄露问题。方法将基于熵的正则化目标集成到训练中，惩罚低熵的SHAP归因分布，促进特征贡献的更均匀分布。", "conclusion": "实验结果表明，基于SHAP熵正则化的这种方法在与基线模型相比显著减少了隐私泄露的同时，保持了高预测准确性和忠实的解释能力。该项工作为安全和可信的AIoT应用的隐私保护可解释AI技术的发展做出了贡献。"}
{"llm_update_time": "20251116", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.09748", "html_url": "https://arxiv.org/abs/2511.09748", "title": "缩小规模的极限？用于机器翻译设备端关键错误检测的紧凑型语言模型", "title_en": "How Small Can You Go? Compact Language Models for On-Device Critical Error Detection in Machine Translation", "authors": "Muskaan Chopra,Lorenz Sparrenberg,Sarthak Khanna,Rafet Sifa", "background": "大型语言模型（LLMs）在评估机器翻译（MT）方面表现出色，但由于其规模庞大和成本问题，无法在边缘设备上部署或应用于隐私敏感的工作流程中。因此，研究者试图探索如何在确保检测到意义改变的翻译错误的同时，减小模型的规模。该研究聚焦于英语到德语的关键错误检测（Critical Error Detection, CED），并在WMT21、WMT22以及SynCED-EnDe-2025数据集上评估了多种亚2B参数量的模型（如LFM2-350M、Qwen-3-0.6B/1.7B、Llama-3.2-1B-Instruct、Gemma-3-1B），并通过标准化提示、轻量级对数偏置校准和多数投票方法，报道了语义质量指标（如MCC、F1-ERR/F1-NOT）和计算性能指标（如显存、延迟、吞吐量）的数据。研究表明，大约10亿参数量是一个清晰的甜点：Gemma-3-1B 能够在合成数据集SynCED-EnDe-2025上获得MCC=0.77、F1-ERR=0.98，同时保持在MacBook Pro M4 Pro（24 GB）上的单样本延迟为400毫秒。", "innovation": "该研究提出了一种标准化的方法，包括轻量级对数偏置校准和多数投票方法，不仅能在较小的模型中保持高质量的错误检测能力，而且能够通过优化在边缘设备上部署。通过在小型模型（0.6B参数量）中使用轻量级校准和少量样本的监督也能保持一定的检测能力，但对实体和数量错误的检测效果相对较弱。此外，该研究在不同规模的语言模型上证明了更好的质量-效率权衡，即Gemma-3-1B在保持较低计算成本的同时提供了最优的性能，而更大规模的Qwen-3-1.7B虽然绝对值MCC更高，但计算成本更高。", "conclusion": "紧凑型、指令调优的语言模型，配以轻量级校准和小样本监督的增强技术，可以在设备端实施可信赖的关键错误检测（CED），为机器翻译流水线提供私密且低成本的错误筛查。所有数据集、提示和脚本都已公开，在GitHub仓库中可获取。"}
{"llm_update_time": "20251116", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.09796", "html_url": "https://arxiv.org/abs/2511.09796", "title": "汉语和英语平行句子中的谓词-论元结构差异及其对语言转移的影响", "title_en": "Predicate-Argument Structure Divergences in Chinese and English Parallel Sentences and their Impact on Language Transfer", "authors": "Rocco Tripodi,Xiaoyu Liu", "background": "跨语言自然语言处理（NLP）近年来取得了显著进展，特别是在低资源语言环境中，通过从资源丰富语言向低资源语言转移语言知识，提供了实用的解决方案。该领域利用注解投影和模型转移等技术进行语言适应，利用多语种预训练语言模型来支持。然而，語言差异性阻碍了语言转移，特别是在类型学上差异较大的语言之间。本文分析了并列汉语和英语句子中的谓词-论元结构，探讨谓词注解的一致性和不一致性，并提出结构差异的分类方法。", "innovation": "论文通过注解投影实验的定性和定量分析，揭示了汉语和英语平行句子中的谓词-论元结构差异，并发现了语言转移的不对称性。这为选择源语言在迁移学习中的应用提供了重要指导，并强调了在提出任何关于跨语言NLP的科学声明之前进行进一步研究的重要性。", "conclusion": "语言转移是非对称的，选择源语言时应特别注意这一方面。此项研究揭示了汉语和英语谓词-论元结构之间的关键差异，强调了在进行跨语言NLP研究时的多样性挑战，并提出了未来研究的方向。"}
{"llm_update_time": "20251116", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.09809", "html_url": "https://arxiv.org/abs/2511.09809", "title": "Test-Time Spectrum-Aware Latent Steering for Zero-Shot Generalization in Vision-Language Models", "title_en": "Test-Time Spectrum-Aware Latent Steering for Zero-Shot Generalization in Vision-Language Models", "authors": "Konstantinos M. Dafnis,Dimitris N. Metaxas", "background": "VLMs在零样本推断任务上表现出色，但在迁移测试时（test-time domain shifts）的情况下容易表现不佳。因此，最近提出了一种称为“回放缓存时适应策略”的技术，以微调VLMs以适应单个未标记的图像。然而，现有的适应策略通常要求对大规模的编码器权重进行反向传播，或修改核心模型组件。", "innovation": "引入了一种轻量级的适应框架——光谱感知测试时导向（STS），它从文本嵌入中提取光谱子空间，定义主要的语义方向，并通过适应少量的样本移位参数来最小化增强视图之间的熵。STS完全在推理中操作于潜空间，无需对冻结的编码器进行反向传播或修改。", "conclusion": "基于标准的评估协议，我们进行了全面的实验，证明了STS在与最先进的测试时适应方法相比具有显著优势，同时仅引入很少的附加参数，并实现了比传统的测试时提示调整快8倍的推理速度，内存占用减少12倍。代码可在以下链接下载：this https URL"}
{"llm_update_time": "20251116", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.09808", "html_url": "https://arxiv.org/abs/2511.09808", "title": "受约束的最佳臂识别与可行性测试", "title_en": "Constrained Best Arm Identification with Tests for Feasibility", "authors": "Ting Cai,Kirthevasan Kandasamy", "background": "最佳臂识别（BAI）的目标是在收集每个臂的随机样本后，识别出性能最高的臂。实际问题中，最优臂需要满足额外的可行性约束。尽管已有少量关于带约束的BAI的研究，但它们通常假设性能和约束在每拉一次臂时被同时观察到。然而，这种假设并不符合大多数实际应用场景，例如在新药发现中，我们希望找到既最有效又不会超出安全阈值的药物。这类有效性实验和安全性测试可以分开进行。因此，需要设计能够决定拉取哪个臂以及是否测试其性能或可行性的BAI算法。", "innovation": "本文研究了允许决策者选择元组$(i, \boldsymbol{\theta})$的可行BAI，其中$i \notin [K]$表示臂，$\boldsymbol{\theta}$表示是否测试其性能($\boldsymbol{\theta}=0$)或任何可行性的$N$个约束($\boldsymbol{\theta} \notin [N]$)。该工作特别关注固定置信度问题，即以至少$1-\boldsymbol{\theta}$的概率识别出性能最高的可行臂。提出了一种有效的算法，并给出了其样本复杂性的上界，证明了算法可以自然地适应问题的难度，并通过更差的表现或不可行性来排除臂。此外，还给出了算法的下界，证明了算法在$\boldsymbol{\theta} \rightarrow 0$时是渐近最优的。最后，实证结果表明，本文算法在合成和真实数据集上均优于当前最先进的BAI算法。", "conclusion": "本文提出了一个高效的可行BAI算法，并通过样本复杂性的上界和下界证明了算法的最优性。实验结果表明，该算法在合成和真实数据集上均优于竞品算法。"}
{"llm_update_time": "20251116", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.09810", "html_url": "https://arxiv.org/abs/2511.09810", "title": "关于过参数化问题的收敛性：神经网络组成结构的固有属性", "title_en": "On the Convergence of Overparameterized Problems: Inherent Properties of the Compositional Structure of Neural Networks", "authors": "Arthur Castello Branco de Oliveira,Dhruv Jatkar,Eduardo Sontag", "background": "本文探讨了神经网络结构如何影响其优化景观和训练动态。文章分析了过参数化优化问题的梯度流，将其解释为具有线性激活的神经网络的训练过程。研究表明，任何适当的和真实解析的成本函数的全局收敛性质都可以推导出来。随后，文章具体分析了标量成本函数的情况，证明了关键结构特征，如鞍点的位置和稳定性，在所有可接受的成本函数中是通用的，仅取决于过参数化表示而非具体问题的细节。", "innovation": "文章展示了对于任意适当的和真实解析的成本函数，过参数化优化问题的全局收敛性质可以被推导。特别地，针对标量成本函数进行了详细分析，证明这些关键结构特征是普遍存在的，取决于过参数化表示，而不是具体问题的细节。此外，表明调制特定的初始化可以任意加速收敛速度。最后，讨论了这些见解如何推广到具有Sigmoid激活的神经网络，展示了在非线性情况下保留的几何和动态特性。", "conclusion": "本文表明，关键的结构特征在所有允许的成本函数中是普遍存在的，主要依赖于过参数化的表示。通过引入不平衡度量，发现在不同初始化条件下，收敛可以显著加速。这些见解为理解具有Sigmoid激活的神经网络提供了基础，展示了某些几何和动态特性在非线性情况下仍然有效。"}
{"llm_update_time": "20251116", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.09814", "html_url": "https://arxiv.org/abs/2511.09814", "title": "使用任务嵌入和平衡表示学习的多治疗效果估计", "title_en": "Multiple Treatments Causal Effects Estimation with Task Embeddings and Balanced Representation Learning", "authors": "Yuki Murakami,Takumi Hattori,Kohsuke Kubota", "background": "在许多领域，如医疗保健和市场营销中，同时应用多种治疗方法的情况越来越普遍。在这种情况下，准确估计单个治疗效果和交互治疗效果（由治疗方法组合产生）变得尤为重要。然而，以往的研究方法存在不足，例如缺乏相关治疗参数共享，或者估计不必要的潜在变量降低了因果效应估计的准确性。", "innovation": "本文提出了一种新的深度学习框架，结合了任务嵌入网络和带平衡惩罚的表示学习网络。任务嵌入网络能够通过编码单效果和交互效果特有的共同元素，实现相关治疗模式间的参数共享。带平衡惩罚的表示学习网络能够从观测协变量中非参数地学习表示，同时减少不同治疗模式下的表示分布距离，从而减轻选择偏差并避免模型误设定。", "conclusion": "模拟研究显示，提案方法优于现有基线方法，而应用于真正的营销数据集也证实了该框架的实际意义和实用性。"}
{"llm_update_time": "20251116", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.09834", "html_url": "https://arxiv.org/abs/2511.09834", "title": "CertMask：通过理论上最优的遮罩覆盖率进行可验证防御以对抗 adversarial patches", "title_en": "CertMask: Certifiable Defense Against Adversarial Patches via Theoretically Optimal Mask Coverage", "authors": "Xuntao Lyu,Ching-Chi Lin,Abdullah Al Arafat,Georg von der Brüggen,Jian-Jia Chen,Zhishan Guo", "background": "对抗性遮罩攻击会向图像中注入局部扰动以误导深度视觉模型，此类攻击可能在现实世界应用中物理实施，从而带来严重风险。现有的对抗性遮罩防御方法（如PatchCleanser）需要两轮遮罩操作并带来二次时间复杂度的推理成本。", "innovation": "本文提出了一种名为CertMask的认证鲁棒防御方法，通过构造证明足够的二进制遮罩集来中和遮罩效果，具有严格的理论保证。CertMask仅需一轮遮罩操作且时间复杂度为O(n)，比PatchCleanser更为高效。Coverage策略确保每个可能的遮罩位置至少覆盖k次，提高了效率和鲁棒性。", "conclusion": "实验表明，CertMask相对于PatchCleanser在ImageNet、ImageNette和CIFAR-10上提高了最多13.4%的认证鲁棒准确性，同时保持了与vanilla模型相近的准确率。"}
{"llm_update_time": "20251116", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.09820", "html_url": "https://arxiv.org/abs/2511.09820", "title": "从街道到轨道：基于位置语义和LLM指导的无训练跨视图检索", "title_en": "From Street to Orbit: Training-Free Cross-View Retrieval via Location Semantics and LLM Guidance", "authors": "Jeongho Min,Dongyoung Kim,Jaehyup Lee", "background": "跨视图图像检索，尤其是街道到卫星图像的匹配，对于自动驾驶导航、城市规划和GPS信号受限环境中的定位等应用至关重要。然而，现有方法通常需要在精心整理的数据集上进行监督训练，并依赖全景图或无人机拍摄的图像，这限制了其实用部署。", "innovation": "本文提出了一种简单有效的无训练跨视图图像检索框架，利用预训练的视觉编码器和大型语言模型（LLM）。该方法通过基于网络的图像搜索和基于LLM的位置推断来提取地理信息，使用地理编码API生成卫星查询，并通过预训练的视觉编码器（如DINOv2）及其PCA白化特征优化检索匹配图块。尽管该方法没有使用真实数据的监督训练，但在零样本设置下，所提出的模型仍优于先前的基于学习的方法。", "conclusion": "此外，该方法的流水线支持自动构建语义对齐的街道到卫星图像的语料库，提供了一种可扩展且成本效益高的替代人工标注方案。源代码将在此url公开：[提供的链接]。"}
{"llm_update_time": "20251116", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.09879", "html_url": "https://arxiv.org/abs/2511.09879", "title": "由缺陷培育的困境：数据集不安全性如何产生易受攻击的AI代码", "title_en": "Taught by the Flawed: How Dataset Insecurity Breeds Vulnerable AI Code", "authors": "Catherine Xia,Manar H. Alalfi", "background": "AI编程助手生成的代码中包含基本的安全漏洞倾向。虽然开发人员最终负责验证和审查这些输出，但提高生成代码片段的内在质量仍然是必要的。训练数据集中的漏洞是代码不安全的关键因素之一。", "innovation": "本文提出通过过滤现有Python语料库并使用静态分析工具保留无漏洞函数，来构建安全的数据集。然后使用这两个数据集分别训练两个变压器模型，并评估它们生成的代码在正确性和安全性方面的表现。结果显示，使用安全数据集训练的模型产生的输出安全问题较少，且功能正确性类似，强调了安全训练数据对提高基于AI的编程助手可靠性的关键作用。", "conclusion": "尽管安全训练数据重要，但进一步改进模型架构和评估方法仍需进一步研究以增强这些结果。"}
{"llm_update_time": "20251116", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.09889", "html_url": "https://arxiv.org/abs/2511.09889", "title": "基于锚点的通用可扩展公平聚类框架", "title_en": "A General Anchor-Based Framework for Scalable Fair Clustering", "authors": "Shengfei Wei,Suyuan Liu,Jun Wang,Ke Liang,Miaomiao Li,Lei Luo", "background": "公平聚类对于在无监督学习中缓解偏差至关重要，但现有的算法往往存在二次或高于二次的计算复杂度，这使它们在大规模数据集上变得不切实际。因此，需要一种可以在保持公平性的同时提高大规模数据集处理效率的方法。", "innovation": "我们提出了一个新颖、通用且即插即用的锚点公平聚类框架（AFCF），该框架能够将任意公平聚类算法的计算复杂度从线性时间提升到线性时间。我们的方法首先通过一种新的公平采样策略选择一小部分但具代表性的锚点，然后可以将任何现成的公平聚类算法应用于这些小的锚点集。中心框架的核心是一个新颖的锚点图构建模块，通过一个精心设计的群-标签联合约束优化问题，确保整个数据集的聚类结果与锚点聚类结果的公平性一致。我们使用ADMM基算法有效地解决了这个优化问题。", "conclusion": "在多个大规模基准上的大量实验表明，AFCF大大加速了最先进的方法，同时保持了强大的聚类性能和公平性保证。"}
{"llm_update_time": "20251116", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.09891", "html_url": "https://arxiv.org/abs/2511.09891", "title": "Scale-Aware Relay and Scale-Adaptive Loss for Tiny Object Detection in Aerial Images", "title_en": "Scale-Aware Relay and Scale-Adaptive Loss for Tiny Object Detection in Aerial Images", "authors": "Jinfu Li,Yuqi Huang,Hong Song,Ting Wang,Jianghan Xia,Yucong Lin,Jingfan Fan,Jian Yang", "background": "尽管近年来目标检测取得了显著进展，但现代检测器仍然难以在航空图像中检测到小目标。主要原因在于小目标所携带的特征有限，在长距离网络传播过程中不可避免地被降级或丢失；另外，较小的目标在训练过程中比大型目标遭受了不成比例的回归惩罚。", "innovation": "该研究提出了一种尺度感知接力层（SARL）和一种尺度自适应损失（SAL），这两者可以无缝地与顶级框架兼容。具体而言，SARL 使用跨尺度空间通道注意力逐步丰富每一层的有意义特征，加强跨层特征共享；SAL 改造了经典的 IoU 基础损失，使其能够动态地为较大目标分配较低权重，从而在训练过程中聚焦于小目标的同时减小对大目标的影响。", "conclusion": "通过对三个基准数据集（AI-TOD、DOTA-v2.0 和 VisDrone2019）进行广泛实验，结果表明，当嵌入 YOLOv5（基于锚框）和 YOLOx（无锚框）基线中时，所提出的方法通过提升 5.5% 的平均精度（AP）而提升了泛化能力，并在真实世界噪声数据集 AI-TOD-v2.0 上促进了鲁棒性能，提升了 29.0% 的 AP。"}
{"llm_update_time": "20251116", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.09871", "html_url": "https://arxiv.org/abs/2511.09871", "title": "无示例可扩展且可微分的双记忆体及其正交正则化在无示例持续学习中的应用", "title_en": "Expandable and Differentiable Dual Memories with Orthogonal Regularization for Exemplar-free Continual Learning", "authors": "Hyung-Jun Moon,Sung-Bae Cho", "background": "持续学习方法被用来强制神经网络独立地处理顺序任务，防止它们利用任务间的有用关系，导致它们重复学习相似特征或过度区分特征。现有的持续学习方法面临的主要问题是无法共享和区分不同任务的特征，从而导致性能下降。因此，本研究需要一种能够自主学习并适应新任务的持续学习方法，同时防止知识干扰，以提高跨任务的性能。", "innovation": "该研究提出了一种完全可微分、无示例的扩展方法，该方法包括两个互补的记忆体。其中一个记忆体学习可以跨所有任务使用的通用特征，另一个记忆体将这些共享特征以任务特定的方式进行组合。这两个记忆体都是可微分的，从而使网络能够自主学习每个样本的潜在表示。此外，该方法包含一个记忆调整模块，可以自适应地删除关键槽并最小化容量扩展，以适应新概念；正交正则化通过强制保留和新学习的记忆体分量之间保持几何分离，从而防止知识干扰。实验结果表明，该方法在类增量学习中优于14种最先进的方法，分别在CIFAR-10、CIFAR-100和Tiny-ImageNet上取得了55.13%、37.24%和30.11%的最终准确率。这些结果证明了该方法在持续学习中的有效性，为持续学习设立了新的里程碑。", "conclusion": "该研究提出的无示例可扩展且可微分的双记忆体及其正交正则化方法成功解决了持续学习中的主要问题，并通过实验验证了其优越性，能够在顺序任务中增加平均性能并接近上界提取特征，为持续学习领域树立了新的标杆。"}
{"llm_update_time": "20251116", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.09905", "html_url": "https://arxiv.org/abs/2511.09905", "title": "PRISM: Diversifying Dataset Distillation by Decoupling Architectural Priors", "title_en": "PRISM: Diversifying Dataset Distillation by Decoupling Architectural Priors", "authors": "Brian B. Moser,Shalini Strode,Federico Raue,Stanislav Frolov,Krzysztof Adamkiewicz,Arundhati Shanbhag,Joachim Folk,Tobias C. Nauen,Andreas Dengel", "background": "目前的集数据蒸馏（DD）方法往往受到单一教师模型归纳偏见的影响，在数据集大小增加时，这种偏见导致生成过于光滑、同质的样本，降低了类内多样性并限制了泛化能力。", "innovation": "本文提出了一个框架PRISM（PRIors from diverse Source Models），通过在合成过程中解耦架构先验，减少教师模型归纳偏见的影响。PRISM使用不同的教师架构分别监督逻辑配对和正则化目标：主要模型用于逻辑配对，而批标准化子集用于批次标准化对齐。", "conclusion": "PRISM在ImageNet-1K数据集上，在低至中等指令每周期（IPC）区间内，无论是在性能还是类内多样性方面都显著优于单一教师方法（如SRe2L）及近期的多教师变种方法（如G-VBSM）。生成的样本显示出显著丰富的类内多样性，通过余弦相似度的显著下降可以看出。此外，还分析了教师选择策略（前置蒸馏 vs. 内部蒸馏）并提出了一个可扩展的跨类批量形成方案，以实现快速并行合成。"}
{"llm_update_time": "20251116", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.09923", "html_url": "https://arxiv.org/abs/2511.09923", "title": "利用有界支持进化策略实现策略精炼", "title_en": "Harnessing Bounded-Support Evolution Strategies for Policy Refinement", "authors": "Ethan Hirschowitz,Fabio Ramos", "background": "使用在策略强化学习（on-policy RL）来提升机器人政策通常受限于噪声较大的、信号较弱的梯度。人们重新审视了进化策略（ES）作为一种策略梯度替代方法，并通过带有有界和反义三角形扰动进行局部探索，这种扰动更适合于策略的细化。", "innovation": "提出了带有有界三角分布噪声和居中排序有限差分估计器配对的三角分布ES（TD-ES），以提供稳定且并行的梯度自由更新。这种策略在策略预训练（PPO）之后的TD-ES细化的两阶段流水线中，保留了早期样本效率的同时，还允许稳健的后期收益。", "conclusion": "TD-ES在一系列机器人操作任务中将成功率提高了26.5%，大大降低了方差，提供了一种简单、计算量轻的可靠细化路径。"}
{"llm_update_time": "20251116", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.09895", "html_url": "https://arxiv.org/abs/2511.09895", "title": "增强模拟器和经验的扩散模型以实现全面的ECG生成", "title_en": "Simulator and Experience Enhanced Diffusion Model for Comprehensive ECG Generation", "authors": "Xiaoda Wang,Kaiqiao Han,Yuhao Xu,Xiao Luo,Yizhou Sun,Wei Wang,Carl Yang", "background": "心血管疾病(CVD)是全球的主要死因。心电图(ECG)是最常用的非侵入性心脏评估工具，但由于成本、隐私和工作流程限制，高质量的标注数据集稀缺。生成ECG数据可促进心脏电活动的机制理解，有利于构建大型、异质且无偏的数据集，并促进隐私保护的数据共享。然而，从临床背景生成逼真的ECG信号仍然是一个未充分探索的领域。", "innovation": "本文提出了一种新颖的SE-Diff方法，结合了体征模拟器和基于经验的扩散模型，用于全面的ECG生成。SE-Diff通过心跳解码器将轻量级的数值微分方程(ECG)模拟器整合进扩散过程，并结合模拟器一致的约束条件，注入促成了生理可信波形的机制先验。同时，设计了基于大规模语言模型的体征增强经验和提取策略，为ECG生成提供了额外的临床知识引导。实验结果表明，SE-Diff在信号保真度和文本-ECG语义对齐方面优于基线方法，证明了其在文本到ECG生成方面的优越性。此外，基于模拟器的知识和经验知识也对后续的ECG分类有益。", "conclusion": "本文提出的SE-Diff方法在信号保真度和文本-ECG语义对齐方面都优于基线方法，展示了其在全面的ECG生成中具有优越性。同时，体征模拟器和基于经验的知识也对下游ECG分类有益。"}
{"llm_update_time": "20251116", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.09924", "html_url": "https://arxiv.org/abs/2511.09924", "title": "MDMLP-EIA: 多领域动态MLP带能量不变注意力机制用于时间序列预测", "title_en": "MDMLP-EIA: Multi-domain Dynamic MLPs with Energy Invariant Attention for Time Series Forecasting", "authors": "Hu Zhang,Zhien Dai,Zhaohui Tang,Yongfang Xie", "background": "时间序列预测在众多领域中都非常重要。基于MLP的方法凭借少参数量和更好的稳健性，已经达到了Transformer相当的性能，但仍然存在一些关键限制，包括丢失弱季节信号、共权重MLP容量限制、以及独立通道策略中不足的通道融合。", "innovation": "文章提出了MDMLP-EIA（多领域动态MLP带能量不变注意力机制），其主要创新点包括：1. 开发了自适应聚合双域季节性MLP，将季节信号分为强和弱两部分，并采用自适应零初始化通道融合策略来最小化噪声干扰，同时有效整合预测；2. 引入能量不变注意力机制，能够根据不同时间步长内趋势和季节性预测的不同特征通道进行自适应聚焦，保持总信号能量恒定，增强对干扰的鲁棒性；3. 设计了一种独立通道MLP的动态容量调整机制，随着通道数增加，确保神经元数量随通道数平方根线性增加，确保容量的充分保障。", "conclusion": "在九个基准数据集上的广泛实验表明，MDMLP-EIA在预测精度和计算效率方面都取得了最先进的成果。"}
{"llm_update_time": "20251116", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.09947", "html_url": "https://arxiv.org/abs/2511.09947", "title": "EEGAgent：使用大型语言模型进行自动化脑电图分析的统一框架", "title_en": "EEGAgent: A Unified Framework for Automated EEG Analysis Using Large Language Models", "authors": "Sha Zhao,Mingyi Peng,Haiteng Jiang,Tao Li,Shijian Li,Gang Pan", "background": "脑活动的可扩展和通用分析对于推动临床诊断和认知研究都至关重要。脑电图（EEG）作为一种无创的高时间分辨率技术，广泛应用于脑状态分析。然而，大多数现有的EEG模型通常是为了特定任务而设计，限制了它们在实际场景中的应用，特别是在涉及多任务和连续推理的EEG分析中。", "innovation": "本文引入了EEGAgent，这是一个利用大型语言模型（LLMs）来调度和规划多种工具，以自动完成与EEG相关的任务的通用框架。EEGAgent能够执行以下关键功能：EEG基本信息感知、时空EEG探索、EEG事件检测、与用户互动以及EEG报告生成。为了实现这些功能，设计了一套由不同工具组成的工具箱，用于EEG预处理、特征提取、事件检测等任务。这些功能在公共数据集上进行了评估，证明EEGAgent能够支持灵活和可解释的EEG分析，突显了其在实际临床应用中的潜力。", "conclusion": "EEGAgent能够通用且高效地执行多个与EEG相关任务，并且在实际应用场景中展现了高度的灵活性和可解释性，具有广泛的应用前景。"}
{"llm_update_time": "20251116", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.09942", "html_url": "https://arxiv.org/abs/2511.09942", "title": "AdaptViG: 具有指数衰减门的自适应视觉GNN", "title_en": "AdaptViG: Adaptive Vision GNN with Exponential Decay Gating", "authors": "Mustafa Munir,Md Mostafijur Rahman,Radu Marculescu", "background": "Vision Graph Neural Networks (ViGs)虽然在视觉架构方面提供了新的进展，但它们在图构建阶段面临严重的计算挑战，这可能会影响其效率。AdaptViG的提出正是为了解决此类问题，提供了一种高效的混合视觉GNN方法，引入了适应性图卷积机制，并采用了高效率的静态轴向支架和动态内容感知的指数衰减门机制，这种机制根据特征相似性有选择地加权远程连接。", "innovation": "AdaptViG通过引入适应性图卷积机制，采用了高效率的静态轴向支架和动态内容感知的指数衰减门机制，有选择地加权远程连接。此外，它还采用了混合策略，早期阶段使用高效的门控机制，最终阶段采用全局注意机制，以最大化特征聚合，从而实现了视觉GNN在准确性和效率之间的新平衡。", "conclusion": "AdaptViG-M以82.6%的top-1准确率打破了视觉GNN中的准确性和效率的平衡纪录，参数量减少80%，GMACs减少84%。在下游任务中，AdaptViG-M取得了45.8 mIoU，44.8 APbox和41.1 APmask的成绩，分别比EfficientFormer-L7高出0.7 mIoU，2.2 APbox和2.1 APmask，参数量减少了78%。"}
{"llm_update_time": "20251116", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.09926", "html_url": "https://arxiv.org/abs/2511.09926", "title": "在预训练视觉变压器的类增量学习中补偿分布漂移", "title_en": "Compensating Distribution Drifts in Class-incremental Learning of Pre-trained Vision Transformers", "authors": "Xuan Rao,Simian Xu,Zheng Li,Bo Zhao,Derong Liu,Mingming Ha,Cesare Alippi", "background": "近期研究表明，通过顺序微调（SeqFT）预训练的视觉变压器（ViTs），再结合使用类特征的近似分布进行分类器优化，可以是一种有效的类增量学习（CIL）策略。然而，这种策略容易受到分布漂移的影响，这是由于共享骨干网络参数的顺序优化造成的。这种漂移导致了之前学习的类与更新模型之间的分布不匹配，最终会随着时间的推移降低分类器性能。", "innovation": "为了应对这个问题，作者引入了一个潜在空间过渡算子，并提出了一种补偿漂移的顺序学习方法（Sequential Learning with Drift Compensation，SLDC）。首先，作者提出了SLDC的线性变体，通过求解特征映射的正则化最小二乘问题学习线性算子，从而解决特征分布对齐问题。接着，作者提出了一个弱非线性SLDC变体，假设理想的过渡算子介于纯线性和完全非线性变换之间，并通过可学习的弱非线性映射实现灵活与泛化的平衡。此外，为了进一步减少表征漂移，作者将知识蒸馏（KD）应用于这两种算法变体。广泛的标准CIL基准实验表明，SLDC显著改善了SeqFT的性能。特别地，结合KD用于处理表征漂移与SLDC用于补偿分布漂移的SeqFT，在所有评估数据集上的性能都达到了与联合训练相当的水平。", "conclusion": "广泛的标准CIL基准实验表明，SLDC显著改善了SeqFT的性能。特别地，结合KD用于处理表征漂移与SLDC用于补偿分布漂移的SeqFT，在所有评估数据集上的性能都达到了与联合训练相当的水平。"}
{"llm_update_time": "20251116", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.09962", "html_url": "https://arxiv.org/abs/2511.09962", "title": "AI集成决策支持系统进行实时市场增长预测和多源内容扩散分析", "title_en": "AI-Integrated Decision Support System for Real-Time Market Growth Forecasting and Multi-Source Content Diffusion Analytics", "authors": "Ziqing Yin,Xuanjing Chen,Xi Zhang", "background": "AI生成内容（AIGC）的迅速发展已重塑了数字营销和在线消费者行为的动力。然而，由于数据异质性、非线性传播机制以及消费者交互方式的变化，预测此类内容的传播轨迹和市场影响依然是一个挑战。", "innovation": "本文提出了一种基于AI的决策支持系统（DSS），该系统结合了社交媒体流、营销支出记录、消费者互动日志和情感动态数据，采用了混合图神经网络（GNN）和时序变换器框架。该模型通过双通道架构联合学习内容传播结构和时间影响演变，并通过因果推断模块分离营销刺激对投资回报率（ROI）和市场可见性的影响。实验结果表明，该系统在六个指标上均优于现有基线。", "conclusion": "所提出的DSS通过提供可解释的实时洞察，提高了对AIGC驱动内容传播和市场增长模式的营销决策支持。"}
{"llm_update_time": "20251116", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.09964", "html_url": "https://arxiv.org/abs/2511.09964", "title": "EnvTrace：同步加速器光束线中通过执行跟踪对LLM代码的基于仿真语义评估", "title_en": "EnvTrace: Simulation-Based Semantic Evaluation of LLM Code via Execution Trace Alignment -- Demonstrated at Synchrotron Beamlines", "authors": "Noah van der Vleuten,Anthony Flores,Shray Mathur,Max Rakitin,Thomas Hopkins,Kevin G. Yager,Esther H. R. Tsai", "background": "评估大型语言模型（LLMs）用于仪器控制需要超越标准无状态算法基准的方法，因为物理系统的行为不能仅通过单元测试完全捕捉。EnvTrace 是一种基于仿真方法，通过评估执行轨迹来评估语义代码等效性。", "innovation": "引入了 EnvTrace 方法，通过执行轨迹匹配生成多功能分数评估功能正确性，展示了许多顶级模型在快速生成控制代码方面可以达到人类级别的性能。实现了LLMs和数字孪生在互惠共生中的应用，LLMs提供直观控制和自主编排，数字孪生提供安全的高保真环境，为自主实体AI铺平道路。", "conclusion": "EnvTrace 在同步加速器光束线控制逻辑数字模拟中的应用表明了其在评估 LLM 代码方面的潜力，并为未来 LLM 和数字孪生的互操作性铺平了道路。"}
{"llm_update_time": "20251116", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.09948", "html_url": "https://arxiv.org/abs/2511.09948", "title": "超越余弦相似度的基于CLIP感知放大融合的无参考图像质量评估", "title_en": "Beyond Cosine Similarity Magnitude-Aware CLIP for No-Reference Image Quality Assessment", "authors": "Zhicheng Liao,Dongxu Wu,Zhenshan Shi,Sijie Mai,Hanwei Zhu,Lingyu Zhu,Yuncheng Jiang,Baoliang Chen", "background": "近期研究表明，通过测量CLIP图像嵌入和文本提示（如“一张好照片”或“一张糟糕的照片”）之间的余弦相似性，可以重新利用CLIP模型进行无参考图像质量评估（No-Reference Image Quality Assessment，NR-IQA）。然而，这种方法忽视了图像特征的幅度这一关键且未充分探索的线索，而该幅度与感知质量具有较强的关联性。本研究旨在通过引入一种新颖的自适应融合框架，将图像特征幅度考虑进CLIP模型的应用中，以改进现有的NR-IQA方法。具体方法包括提取绝对CLIP图像特征并应用Box-Cox变换来统计归一化特征分布和减少语义敏感性，以及设计一种基于信心引导的融合方案来自适应地权衡每部分的重要性。实验结果表明该方法在多个基准IQA数据集上表现优于现有标准CLIP基线和最先进的基线方法，且无需针对具体任务进行训练。", "innovation": "1. 引入了一个基于自适应融合框架，将图像特征幅度融入到CLIP模型中，以改进无参考图像质量评估。\n2. 提出了Box-Cox变换来统计归一化特征分布，减少特征语义敏感性。\n3. 设计了一种基于信心引导的融合方案，以自适应地权衡每个成分的重要性，从而更有效地整合两种线索。", "conclusion": "在多个基准IQA数据集上，本研究的方法整体上超过了标准的CLIP基线和最先进的基准方法，特别是在不需要针对特定任务进行训练的情况下。这表明提出的自适应融合框架在无参考图像质量评估中的有效性。"}
{"llm_update_time": "20251116", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.09969", "html_url": "https://arxiv.org/abs/2511.09969", "title": "Owlgorithm：通过LLM驱动的反思支持有竞争力编程中的自我调节学习", "title_en": "Owlgorithm: Supporting Self-Regulated Learning in Competitive Programming through LLM-Driven Reflection", "authors": "Juliana Nieto-Cardenas,Erin Joy Kramer,Peter Kurto,Ethan Dickey,Andres Bejarano", "background": "在有竞争力的编程（CP）课程中，自我调节学习（SRL）是培养学生独立思考和学习能力的关键。传统的反馈机制可能无法充分引导学生理解问题的核心，特别是在面对复杂编程任务时。借助于自然语言处理（NLP）技术，特别是AI生成的反思性问题，OwLgorithm平台为学生提供了个性化的反馈和指导，帮助他们更好地理解和改进自己的编程技能。", "innovation": "OwLgorithm引入了GPT-4o这一先进的人工智能工具，能够生成具有上下文感知能力和元认知提示，这些提示是针对每个学生的具体编程提交量身定制的。通过将该平台集成到有竞争力的编程课程中，研究团队观察到平台提供的反思提示能够引导学生深入理解正确解题的概念，并在代码不完整或失败时进行结构化的调试。这种基于LLM的反思方法提供了一种新的教育工具，特别适用于初学者，但仍需进一步改进以确保高级学习者的可靠性和教育价值。", "conclusion": "根据我们的研究经验，我们得出了几个关键见解：生成式人工智能可以有效地支持结构化的反思，但要实现其在教育中的潜力，需要精心设计提示、动态适应和提升用户体验。我们还为使用类似工具的教育工作者提供了具体的建议，并概述了进一步增强OwLgorithm教育影响力的方法。该框架也可能适用于其他反思学习的背景中。"}
{"llm_update_time": "20251116", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.09973", "html_url": "https://arxiv.org/abs/2511.09973", "title": "DiVE for Robust Fine-tuning of Vision-Language Models", "title_en": "Difference Vector Equalization for Robust Fine-tuning of Vision-Language Models", "authors": "Satoshi Suzuki,Shin'ya Yamaguchi,Shoichiro Takeda,Taiga Yamane,Naoki Makishima,Naotaka Kawata,Mana Ihori,Tomohiro Tanaka,Shota Orihashi,Ryo Masumura", "background": "现有的对比预训练的多模态模型（如CLIP）在零样本分类中表现出强大的泛化能力，但现有的鲁棒微调方法在微调时重新利用预训练阶段的对比学习方法，可能会破坏模型的几何结构，从而影响模型在离分布和零样本场景中的性能。鉴于此，作者提出了一种新的方法叫DiVE，用于保护多模态模型的几何结构，从而提高模型的鲁棒性和泛化性能。", "innovation": "作者提出了一种新的鲁棒微调方法DiVE，该方法通过约束差异向量来保持几何结构。具体地，通过平均向量损失（AVL）和成对向量损失（PVL）两个损失函数来全局和局部地保护几何结构。实验表明，DiVE在保持几何结构的同时，提高了模型在同分布、离分布和零样本场景中的表现。", "conclusion": "实验结果显示，DiVE方法有效地保护了模型的几何结构，使得在同分布、离分布和零样本场景中实现了良好的性能。DiVE提供了一种新颖的解决微调破坏几何结构问题的方法，增强了对现有鲁棒微调方法改进的有效性。"}
{"llm_update_time": "20251116", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.09970", "html_url": "https://arxiv.org/abs/2511.09970", "title": "MultiTab：大规模表格数据多任务学习的基础", "title_en": "MultiTab: A Scalable Foundation for Multitask Learning on Tabular Data", "authors": "Dimitrios Sinodinos,Jack Yi Wei,Narges Armanfard", "background": "表格数据是世界上最丰富的数据类型之一，广泛应用于金融、医疗、电子商务等领域。随着表格数据集的增长和跨越多个相关目标，利用共享任务信息以提高多任务泛化的需求不断增加。多任务学习（MTL）已成为提高泛化和效率的强大工具，但现有的大多数工作主要关注大规模推荐系统，而对更广泛的表格领域潜力的探索还远未充分。此外，现有用于表格数据的多任务学习方法大多依赖于多层感知器模型，这在处理复杂特征交互和大量数据时表现不佳，而这种挑战在其他领域已被转换器架构克服。", "innovation": "我们提出了MultiTab-Net，这是首个专为大规模表格数据设计的多任务转换器架构。MultiTab-Net采用了一种新颖的多任务遮罩注意力机制，该机制动态建模特征之间的依赖关系，同时缓解任务竞争。通过广泛的实验，我们证明了MultiTab-Net在多元任务获益上始终优于现有的多任务学习架构和单任务转换器，涵盖大规模推荐数据、类似普查的经济社会数据和物理数据集等多个领域，涉及广泛的任务数量、类型和特征模态。我们还贡献了MultiTab-Bench，一个通用的多任务合成数据集生成器，能够通过调整任务数量、任务相关性和任务复杂度来系统地评估多任务动态。", "conclusion": "我们的研究结果表明，MultiTab-Net在多个表格数据集上实现了更高的多任务增益，并通过MultiTab-Bench对多任务动态进行了全面评估。"}
{"llm_update_time": "20251116", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.10008", "html_url": "https://arxiv.org/abs/2511.10008", "title": "Phantom Menace: Exploring and Enhancing the Robustness of VLA Models against Physical Sensor Attacks", "title_en": "Phantom Menace: Exploring and Enhancing the Robustness of VLA Models against Physical Sensor Attacks", "authors": "Xuancun Lu,Jiaxiang Chen,Shilin Xiao,Zizhi Jin,Zhangrui Chen,Hanwen Yu,Bohan Qian,Ruochen Zhou,Xiaoyu Ji,Wenyuan Xu", "background": "VLA（视觉-语言-行动）模型通过整合多种传感器模态（如相机视觉信号和麦克风声学信号），实现了从感知到行动的端到端处理，极大地推进了机器人的系统发展。然而，这类系统严重依赖于物理世界的传感器输入，其对抗物理传感器攻击的安全性被严重忽视。", "innovation": "本文首次系统性研究了物理传感器攻击对VLA模型的影响，并提出了一个名为'Real-Sim-Real'的框架，该框架能够自动化模拟基于物理的传感器攻击向量。通过大规模评估，研究发现VLA模型在对各种VLA架构和任务进行不同程度的攻击参数变化时存在显著的安全漏洞，并且开发了一种对抗训练防御机制，以增强VLA模型对传感器攻击导致的物理扰动的鲁棒性，同时保持模型性能。", "conclusion": "研究揭示了VLA模型在安全关键环境中部署时对物理传感器攻击的脆弱性，强调了标准化鲁棒性基准和缓解策略的迫切需求。"}
{"llm_update_time": "20251116", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.10002", "html_url": "https://arxiv.org/abs/2511.10002", "title": "PustakAI：使用大语言模型构建课程对齐的交互式教科书", "title_en": "PustakAI: Curriculum-Aligned and Interactive Textbooks Using Large Language Models", "authors": "Shivam Sharma(1),Riya Naik(1),Tejas Gawas(1),Heramb Patil(1),Kunal Korgaonkar(1) ((1) CSIS Department, BITS Pilani K K Birla Goa Campus, India)", "background": "大语言模型（LLMs）在理解和生成人类类似的内容方面展现了显著的能力，这在医疗、软件开发和教育等多个领域引发了一场变革。在教育场景中，LLMs 有潜力提供个性化和互动的学习体验，特别是在教学资源有限的地区。然而，将这些模型有效地应用于特定的课程内容，例如印度国家教育研究与培训委员会（NCERT）的课程大纲，提出了准确性、对齐性和教育相关性的独特挑战。", "innovation": "本文提出了一个名为 'PustakAI' 的框架，用于设计和评估一个与6至8年级英语和科学科目NCERT课程大纲对齐的新题-答数据集“NCERT-QA”。该数据集包括各种分类的题-答对（事实性、推断性和其他类型的评估与推理）。作者进一步通过不同的提示技术（元提示、少样本和CoT风格提示）来测试这一框架，并通过多元评估指标了解哪种方法更符合课程结构和需求。此外，研究还分析了当前开源（Gemma3:1b、Llama3.2:3b、Nemotron-mini:4b）和高性能（Llama-4-Scout-17B、Deepseek-r1-70B）LLM作为基于人工智能的学习工具的优势和局限性。", "conclusion": "本文通过对NCERT-QA数据集和当前LLM应用的学习工具的评估，提供了关于如何有效利用LLMs以适应特定课程结构和教育目标的见解。并且指出了现有LLM在实际应用中的优点和不足，为进一步改进和优化LLM在教育领域的应用提供了参考。"}
{"llm_update_time": "20251116", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.10010", "html_url": "https://arxiv.org/abs/2511.10010", "title": "先进计算机架构在加速人工智能工作负载中的作用", "title_en": "The Role of Advanced Computer Architectures in Accelerating Artificial Intelligence Workloads", "authors": "Shahid Amin,Syed Pervez Hussnain Shah", "background": "人工智能（AI）的显著进步与计算机架构的革命性变化息息相关。随着深度神经网络（DNNs）等AI模型变得越来越复杂，其巨大的计算需求已经对传统的架构提出了极限挑战。本文对这种相互促进的现象进行了结构化的综述，分析了设计用来加速现代AI工作负载的各类架构。文章探讨了图形处理单元（GPUs）、应用特定集成电路（ASICs）和现场可编程门阵列（FPGAs）等主要架构范式，拆解了它们的设计理念、关键特性和性能权衡。此外，本文还展望了诸如存储计算（Processing-in-Memory，PIM）和神经形态计算等新兴技术，这些技术可能重新定义未来的计算方式。通过结合架构原理和来自工业标准基准的定量性能数据，本文综述了AI加速器的完整图景。", "innovation": "本文对先进计算机架构与AI工作负载加速之间的关系进行了分析，详细探讨了GPU、ASICs和FPGAs等流行架构，并深入研究了数据流优化、高级内存层次结构、稀疏性和量化等关键原则对于性能和能效的核心影响。文章还展望了PIM和神经形态计算等新兴技术，这些技术可能对未来计算有重大影响。", "conclusion": "AI和计算机架构之间的关系是共生的，硬件与软件的协同设计不再是优化的关键，而是未来计算进步的必要条件。"}
{"llm_update_time": "20251116", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.10020", "html_url": "https://arxiv.org/abs/2511.10020", "title": "Anomagic: Crossmodal Prompt-driven Zero-shot Anomaly Generation", "title_en": "Anomagic: Crossmodal Prompt-driven Zero-shot Anomaly Generation", "authors": "Yuxin Jiang,Wei Luo,Hui Zhang,Qiyu Chen,Haiming Yao,Weiming Shen,Yunkang Cao", "background": "目前的异常生成方法通常需要一些示例异常才能生成合理的异常样本。本文提到的研究背景是探索一种新的零样本异常生成方法，可以在不依赖任何已知异常样本的情况下生成具有语义连贯性的异常样本。", "innovation": "Anomagic 是一种跨模态提示驱动的零样本异常生成方法。它通过统一视觉和文本线索，利用丰富的上下文信息引导图像修复生成管道，并引入了一种对比度细化策略，确保合成的异常与其掩码之间的精确对齐，进而提高下游异常检测的准确性。", "conclusion": "Anomagic 培训所得的模型可以生成比先前方法更为真实和多样的异常，显著改善了下游异常检测的性能。此外，Anomagic 可以根据用户的提示生成任何正常类别图像的异常，为异常生成提供了多功能的基础模型。"}
{"llm_update_time": "20251116", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.10014", "html_url": "https://arxiv.org/abs/2511.10014", "title": "fastbmRAG: 一种高效处理大规模生物医药文献的快速图基RAG框架", "title_en": "fastbmRAG: A Fast Graph-Based RAG Framework for Efficient Processing of Large-Scale Biomedical Literature", "authors": "Guofeng Meng,Li Shen,Qiuyan Zhong,Wei Wang,Haizhou Zhang,Xiaozhen Wang", "background": "大型语言模型（LLMs）正在迅速改变各个领域，包括生物医药和医疗保健，并展示了从科学研究到新药发现的显著潜力。基于图的关系抽取增强生成（RAG）系统作为LLMs的一个有用应用，可以利用结构化的实体和关系识别从长文本知识中提高上下文推理能力，例如生物医药文献。尽管图基RAG相较于简单的RAG有很多优势，但大多数图基RAG在计算上非常密集，限制了它们在大规模数据集中的应用。", "innovation": "fastbmRAG 是一种优化的快速图基RAG，特别适用于生物医药文献。它通过将知识图构建分成两个阶段：首先使用摘要草案，然后通过基于向量的实体链接指导主要文本进行细化，以此减少冗余和计算负荷，从而极大地提高了效率。相较于现有的图基RAG工具，fastbmRAG 的速度提高了超过10倍，并且在覆盖范围和准确性上都有显著提升。", "conclusion": "fastbmRAG 提供了一种快速理解、总结和回答大规模生物医药文献中问题的解决方案。该工具已公开，并且可以在指定的网址获取。"}
{"llm_update_time": "20251116", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.10023", "html_url": "https://arxiv.org/abs/2511.10023", "title": "采用定制化CNN模型实现早产儿视网膜病变的高效自动化诊断", "title_en": "Efficient Automated Diagnosis of Retinopathy of Prematurity by Customize CNN Models", "authors": "Farzan Saeedi,Sanaz Keshvari,Nasser Shoeibi", "background": "本文深入探讨了早产儿视网膜病变（ROP）的诊断，运用了先进的深度学习方法。研究聚焦于改进基于CNN的模型以实现精确高效的ROP检测。文中详细分析了数据集的构建、预处理策略和模型架构，并对模型效果、计算成本和时间复杂度进行了评估。", "innovation": "研究展示了定制化CNN模型相较于预训练模型的高度优越性，尤其是在提高准确率和F1分数方面。提出了一种投票系统进一步提升了模型表现。此外，研究还揭示了定制化CNN模型在减轻深度神经网络计算负担方面的潜力，并展示了将其部署于专用软件和硬件配置中的可行性。", "conclusion": "研究显著推动了ROP诊断领域的发展，证明了深度学习模型在提升诊断精度和效率方面的作用。"}
{"llm_update_time": "20251116", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.10031", "html_url": "https://arxiv.org/abs/2511.10031", "title": "外部干扰下基于时间潜变量结构因果模型的因果发现", "title_en": "Temporal Latent Variable Structural Causal Model for Causal Discovery under External Interferences", "authors": "Ruichu Cai,Xiaokai Huang,Wei Chen,Zijian Li,Zhifeng Hao", "background": "从观测数据中推理因果关系是一个重要的任务，但在存在多种外部干扰时，这一任务变得极具挑战性。由于这些外部干扰通常是未知的附加因素，作者引入了潜变量来代表这些未观察到的影响观测数据的因素。传统的因果模型往往未能捕捉到这种因果联系，因此需要一种能有效处理外部干扰的新型因果模型框架。", "innovation": "提出了一个结合了因果强度和邻接系数的时间潜变量结构因果模型，用于捕捉变量间因果关系。另外，该模型还开发了一种基于变分推断方法的方法，用于整合专家知识以指导模型参数学习，从而更好地估计模型参数。", "conclusion": "实验结果表明，该提出的模型方法具有较高的稳定性和准确性，在存在外部干扰的情况下仍能有效进行因果发现。"}
{"llm_update_time": "20251116", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.10013", "html_url": "https://arxiv.org/abs/2511.10013", "title": "MIRNet: 将预训练与受约束的图基推理相结合用于诊断医学影像", "title_en": "MIRNet: Integrating Constrained Graph-Based Reasoning with Pre-training for Diagnostic Medical Imaging", "authors": "Shufeng Kong,Zijie Wang,Nuan Cui,Hao Tang,Yihan Meng,Yuanyuan Wei,Feifan Chen,Yingheng Wang,Zhuo Cai,Yaonan Wang,Yulong Zhang,Yuzheng Li,Zibin Zheng,Caihua Liu", "background": "医学图像的自动化解读需要建立复杂的视觉-语义关系模型，同时解决标注稀缺性、标签不平衡以及临床可行性约束问题。舌诊图像诊断是一个特别具有挑战性的领域，它要求细致的视觉和语义理解。为了应对这些挑战，该论文介绍了一种名为 MIRNet 的创新框架，该框架结合了自我监督的预训练和受约束的图基推理。该方法利用自我监督的 Masked Autoencoder (MAE) 从无标签数据中学习可转移的视觉表示，采用图注意力网络 (GAT) 模型标签间的相关性，通过约束感知优化使用 KL 散度和正则化损失来强制实施临床先验，并通过不对称损失 (ASL) 和提升集成减轻标签不平衡问题。为了应对标注稀缺性，该论文还引入了一个包含 4000 张具有 22 个诊断标签注释的专家审核数据集 TongueAtlas-4K，这是目前公开的舌分析数据集中最大的一个。", "innovation": "MIRNet 的创新点在于结合自我监督的预训练和受约束的图基推理框架，具体包括：\n1. 结合自我监督的 Masked Autoencoder (MAE)，从无标签数据中学习可转移的视觉表示。\n2. 使用图注意力网络 (GAT) 模型标签间的相关性。\n3. 通过约束感知优化使用 KL 散度和正则化损失强制实施临床先验。\n4. 通过不对称损失 (ASL) 和提升集成减轻标签不平衡问题。\n5. 引入 TongueAtlas-4K 作为大规模且注释详尽的专家审核数据集，这是目前公开的数据集中最大的一个。\n该框架专门为舌诊诊断而开发，但能够推广适用于更广泛的诊断医学影像任务。", "conclusion": "验证结果显示，MIRNet 在舌诊图像诊断任务上达到了最先进的性能。该方法不仅为舌诊图像的自动化解读提供了有效的解决方案，还为更广泛的诊断医学影像任务提供了新的框架思路。"}
{"llm_update_time": "20251116", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.10060", "html_url": "https://arxiv.org/abs/2511.10060", "title": "医疗行动评估的多变量高斯表示学习", "title_en": "Multivariate Gaussian Representation Learning for Medical Action Evaluation", "authors": "Luming Yang,Haoxian Liu,Siqing Li,Alper Yilmaz", "background": "医疗视觉中的细粒度动作评估面临独特挑战，包括缺乏全面的数据集、严格的要求以及对非常快速的动作不足的时空动态建模。为此，我们提出了CPREval-6k，这是一个包含6,372个由专家标注的视频和22个临床标签的多视图、多标签医疗动作基准数据集，用于支持开发和评估。", "innovation": "我们提出了GaussMedAct，这是一种多变量高斯表示框架，用于通过自适应时空表示学习推动医疗运动分析。该方法使用混合空间编码，结合了笛卡尔和向量双重流策略，有效地利用关节和骨骼特征。与ST-GCN基线相比，该方法在基准上的实时推理达到了92.1%的Top-1精度，仅使用10%的FLOPs，且跨数据集实验验证了其在稳健性方面的优越性。", "conclusion": "该研究表明，GaussMedAct在医疗动作评估中表现出色，能够有效处理细粒度动作，具有良好的实时性能和准确性，且具有良好的跨数据集鲁棒性。"}
{"llm_update_time": "20251116", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.10032", "html_url": "https://arxiv.org/abs/2511.10032", "title": "道德变化还是噪声？关于与时间不稳定的人类反馈对齐AI的问题", "title_en": "Moral Change or Noise? On Problems of Aligning AI With Temporally Unstable Human Feedback", "authors": "Vijay Keswani,Cyrus Cousins,Breanna Nguyen,Vincent Conitzer,Hoda Heidari,Jana Schaich Borg,Walter Sinnott-Armstrong", "background": "背景：现有AI对齐方法假设道德偏好是静态的目标，但现实中的偏好可能会随时间变化。当前的AI对齐方法大多忽略了偏好随时间的变化，这对要求较高的AI应用（如医疗领域）构成了严重挑战，可能导致系统的不信任并引起个人和社会的重大伤害。本文通过研究肾脏分配领域中参与者道德偏好随时间的变化以及这种变化对AI对齐的影响，揭示了时间不稳定的偏好对AI对齐提出的挑战。", "innovation": "创新：本文在肾移植领域进行研究，通过多次会话收集参与者对不同假设肾移植患者配对的偏好反应，发现偏好随时间的变化情况（反应不稳定性和模型不稳定性的变化）并对这一变化的影响进行了分析，展示了简单AI模型预测性能随时间下降的情况，强调了训练中考虑随时间变化的偏好的重要性。这项研究突显了理解随着时间显著变化的用户偏好时对齐目标的复杂性。", "conclusion": "结论：本文的研究提出了道德变化识别中的规范和技术挑战，表明在用户偏好随时间显著变化时，需要更好地理解对齐的目标，即要对什么进行对齐。简单AI模型预测性能随着时间推移下降，突显了考虑时间变化的偏好在训练过程中至关重要。这些发现为AI对齐方法提出了新的挑战和改进方向。"}
{"llm_update_time": "20251116", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.10087", "html_url": "https://arxiv.org/abs/2511.10087", "title": "意见：走向统一的富有表现力的策略优化以实现鲁棒的机器人学习", "title_en": "Opinion: Towards Unified Expressive Policy Optimization for Robust Robot Learning", "authors": "Haidong Huang,Haiyue Zhu. Jiayu Song,Xixin Zhao,Yaohua Zhou,Jiayi Zhang,Yuze Zhai,Xiaocong Li", "background": "Offline-to-online reinforcement learning (O2O-RL) 已成为一个有潜力的机器人策略部署范式，但仍面临两大挑战：多模态行为覆盖不足和在线适应期间的分布偏移。", "innovation": "提出了UEPO统一生成框架，基于大型语言模型的预训练和微调策略。具体贡献包括：(1) 多种子动力学感知扩散策略，高效捕获多样化模态而无需训练多个模型；(2) 动态偏差正则化机制，促进物理上合理的行为多样性；(3) 基于扩散的数据增强模块，增强动力学模型的泛化能力。", "conclusion": "在 D4RL 标准测试中，UEPO 在运动任务上比 Uni-O4 实现了 +5.9% 的绝对改进，在灵巧操作任务上实现 +12.4% 的改进，展示了强大的泛化能力和扩展性。"}
{"llm_update_time": "20251116", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.10093", "html_url": "https://arxiv.org/abs/2511.10093", "title": "大型语言模型的军事应用", "title_en": "On the Military Applications of Large Language Models", "authors": "Satu Johansson,Taneli Riihonen", "background": "本文讨论了自然语言处理和大型语言模型在军事领域的使用及其应用实现。这些语言模型因其生成式预训练变换器（GPT）的发明而广受欢迎，并且在OpenAI为ChatGPT及其他应用进行的基础模型预训练中发挥了重要作用。研究表明，基于GPT的语言模型（例如：微软Copilot）可以被用来揭示它们在军事应用中的潜在能力，以及如何利用商业云服务（如微软Azure）构建此类应用，并评估哪些应用是可行的。研究发现，语言模型的总结和生成特性可以直接促进许多广泛应用，而其他特性可能有特定的应用场景。", "innovation": "本文创新性地探讨了大型语言模型在军事领域的应用，并通过与具体模型如GPT及微软Copilot的实际交互，分析了这些模型在军事场景中的使用潜力以及建议利用商业云服务构建相关应用。同时，评估了不同应用的可能性和可行性，揭示了语言模型特性的潜在应用价值。", "conclusion": "语言模型的总结和生成特性可以直接促进许多广泛应用，而其他特性可能有特定的应用场景。"}
{"llm_update_time": "20251116", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.10054", "html_url": "https://arxiv.org/abs/2511.10054", "title": "BuddyMoE: 利用专家冗余加速内存受限的Mixture-of-Experts推理", "title_en": "BuddyMoE: Exploiting Expert Redundancy to Accelerate Memory-Constrained Mixture-of-Experts Inference", "authors": "Yun Wang,Lingyun Yang,Senhao Yu,Yixiao Wang,Ruixing Li,Zhixiang Wei,James Yen,Zhengwei Qi", "background": "Mixture-of-Experts (MoE) 架构通过为每个输入令牌仅激活一部分专业专家网络来扩展语言模型，从而减少浮点运算次数。然而，现代MoE模型尺寸的增加导致其完整的参数集超过了GPU内存容量。例如，Mixtral-8x7B有450亿个参数，即使每个令牌仅使用140亿个参数，也需要87GB的内存。现有系统通过将不活跃的专家卸载到CPU内存来缓解这一限制，但跨PCIe接口传输专家会引入显著的延迟（大约10毫秒）。预取启发式试图通过预测需要哪些专家来隐藏这个延迟，但预取失败会引入显著的停滞，放大推理延迟。因此，既有工作提出了两种主要解决方案：要么在需要时即时获取专家，这会因PCIe瓶颈而产生长时间的停滞；要么从计算中丢弃专家，这会显著降低模型的准确性。关键挑战是在预取失败时保持高推理速度和模型准确性。", "innovation": "BuddyMoE 提出利用专家冗余来加速内存受限的MoE推理，通过减少不常用的专家网络加载，提高推理速度和模型准确性。BuddyMoE通过动态管理和使用冗余专家来减少预取失败对性能的影响，同时保持模型的准确性。", "conclusion": "BuddyMoE 在内存受限的MoE推理中提供了一种新的方法，通过利用专家冗余来优化系统性能。该方法可以在预取失败时保持高推理速度和模型准确性，从而提高了系统的整体效率。"}
{"llm_update_time": "20251116", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.10136", "html_url": "https://arxiv.org/abs/2511.10136", "title": "景观正确，原因错误：文本到图像生成中的组分一致性问题", "title_en": "Right Looks, Wrong Reasons: Compositional Fidelity in Text-to-Image Generation", "authors": "Mayank Vatsa,Aparna Bharati,Richa Singh", "background": "现有的文本到图像模型存在一个根本性的缺陷，即无法处理逻辑组合。本文通过调查基于三个核心原语（否定、计数和空间关系）的表现崩溃，揭示了这种缺陷，模型在单一原语准确的情况下，当这些原语结合时，性能急剧下降。主要原因包括：训练数据中缺乏明确的否定现象；连续注意力架构不适合离散逻辑；评估标准更重视视觉合理性而忽视约束满足。", "innovation": "本文通过分析最近的基准和方法，证明当前的解决方案和简单的扩展无法弥补这一差距。研究指出，实现真正的组分性将需要在表示和推理方面取得根本性的进展，而不仅仅是对现有架构进行渐进调整。", "conclusion": "文本到图像生成中的真实组分性将要求在表示和推理方面取得根本性的进步，而不是简单的架构调整。"}
{"llm_update_time": "20251116", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.10089", "html_url": "https://arxiv.org/abs/2511.10089", "title": "T2IBias: 在文本到图像生成模型的潜在空间中揭露社会偏见", "title_en": "T2IBias: Uncovering Societal Bias Encoded in the Latent Space of Text-to-Image Generative Models", "authors": "Abu Sufian,Cosimo Distante,Marco Leo,Hanan Salam", "background": "文本到图像（T2I）生成模型在人工智能驱动的实际应用和价值创造中被广泛使用。然而，这些模型的战略部署引发了负责的人工智能管理方面的关键性问题，特别是这些模型可能复制和放大与种族和性别相关的陈规定型观念，这可能会损害组织伦理。本文探讨了这些社会偏见是否系统地被最先进的T2I模型的预训练潜在空间编码。", "innovation": "本文进行了实证研究，使用包含十个中性的职业相关提示，生成了5000张图像数据集，这些数据集由不同的种族和性别的人类评估者评估。研究结果展示了五个模型中普遍存在的社会性失衡，如为护理角色持续女性化，高地位的职业（如公司CEO、政治家、医生、律师）主要由男性和白人个体占据。此外，研究还识别了特定模型的独特模式，例如QWEN-Image几乎仅输出东亚人图像，Kandinsky的主要输出为白人个体，SDXL的分布较广但也存在偏见。", "conclusion": "研究结果提供了宝贵的见解，适用于AI项目管理和从业者，帮助他们选择公平的AI模型和定制提示，以确保生成的图像与负责任AI的原则一致。最终，讨论了这些偏见的风险，并提出了减少负责任生成人工智能系统中偏见的可行策略。"}
{"llm_update_time": "20251116", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.10108", "html_url": "https://arxiv.org/abs/2511.10108", "title": "MATAI: 一种用于高级合金性能预测和逆向设计的通用机器学习框架", "title_en": "MATAI: A Generalist Machine Learning Framework for Property Prediction and Inverse Design of Advanced Alloys", "authors": "Yanchen Deng,Chendong Zhao,Yixuan Li,Bijun Tang,Xinrun Wang,Zhonghan Zhang,Yuhao Lu,Penghui Yang,Jianguo Huang,Yushan Xiao,Cuntai Guan,Zheng Liu,Bo An", "background": "先进金属合金的发现受到巨大组成空间、竞争的性能目标以及制造实际限制的阻碍。在这里，我们介绍了MATAI，一种综合了定制合金数据库、基于深度神经网络的性能预测器、约束感知优化引擎和迭代AI实验反馈循环的通用机器学习框架。", "innovation": "MATAI通过多任务学习和物理知情归纳偏置直接从组成估计关键机械性能，如密度、屈服强度、抗拉强度和延伸率。它将合金设计视为有约束条件的优化问题，并通过结合局部搜索和符号约束编程的双层方法进行求解。", "conclusion": "MATAI通过仅七次迭代在基于Ti的合金系统中快速识别出同时具有更低密度(<4.45 g/cm³)、更高强度(>1000 MPa)和可接受延展性(>5%)的候选材料。实验验证表明，MATAI设计的合金性能优于商用参考材料TC4，突显了该框架在设计约束下的轻质、高性能材料发现潜力。"}
{"llm_update_time": "20251116", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.10088", "html_url": "https://arxiv.org/abs/2511.10088", "title": "eXIAA: eXplainable Injections for Adversarial Attack", "title_en": "eXIAA: eXplainable Injections for Adversarial Attack", "authors": "Leonardo Pesce,Jiawen Wei,Gianmarco Mengaldo", "background": "后验解释方法是机器学习的一部分，旨在解释模型为什么会以某种方式运作。本文提出了一种新的全局黑箱、模型无关的对抗攻击方法，应用于图像域的后验可解释人工智能（XAI）。该攻击旨在修改原始解释而不被人类视觉察觉，并保持同一预测类别。与此前方法相比，本研究不需要访问模型或权重，仅需访问模型的预测和解释。通过实验证明，该方法能够显著改变提供的解释。此方法暴露了当前解释方法的严重漏洞，引起了对其在安全关键应用中的可靠性的担忧。利用预训练的ResNet-18和ViT-B16在ImageNet上生成基于后验解释方法解释（梯度敏感映射、集成梯度、DeepLIFT SHAP）的攻击，结果显示攻击能够导致截然不同的解释，但预测概率不变。通过计算解释的平均绝对差值和结构相似性指数度量（SSIM）验证攻击的有效性，确保原始图像与受到攻击后的图像相似度高。", "innovation": "提出了一个新的基于单一步骤的全局黑箱、模型无关的对抗攻击方法，仅需模型的预测和解释，不需访问模型或权重。这种攻击方法显著改变了提供的解释，但不被人类视觉察觉。它基于梯度敏感映射、集成梯度、DeepLIFT SHAP等后验解释方法对预训练的ResNet-18和ViT-B16在ImageNet上的攻击。实验证明，能够显著改变解释，但预测概率不变，同时验证了攻击的有效性。", "conclusion": "该方法揭示了当前解释方法的严重漏洞，即在解释时可能存在误导性，这在安全关键应用中是一个重大的问题。通过系统生成基于后验解释方法的攻击，证明了攻击的有效性，并通过计算平均绝对差值和结构相似性指数度量进行了验证，表明攻击有效地改变了解释而不改变预测概率，同时保持了图像的高相似性。"}
{"llm_update_time": "20251116", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.10154", "html_url": "https://arxiv.org/abs/2511.10154", "title": "GEA: Generation-Enhanced Alignment for Text-to-Image Person Retrieval", "title_en": "GEA: Generation-Enhanced Alignment for Text-to-Image Person Retrieval", "authors": "Hao Zou,Runqing Zhang,Xue Zhou,Jianxiao Zou", "background": "文本到图像的人像检索（TIPR）的目标是基于自然语言描述检索图像。虽然许多TIPR方法取得了令人满意的结果，但有时候文本查询无法准确且全面地反映图片内容，导致跨模态对齐效果差且容易过度拟合到有限的数据集。此外，文本与图像之间的固有模态差距进一步加剧了这些问题，使准确的跨模态检索更为困难。", "innovation": "我们提出了从生成的视角出发的Generation-Enhanced Alignment（GEA）。GEA包括两个并行模块：(1) 文本引导的标记增强（TGTE），通过引入由扩散生成的图像作为中介语义表示来弥合文本与视觉模式之间的差距。这些生成的图像丰富了文本的语义表示，促进了跨模态对齐。(2) 生成中间融合（GIF），该模块结合生成图像、原始图像和文本特征之间的跨注意以生成由三重对齐损失优化的统一表示。", "conclusion": "我们在CUHK-PEDES、RSTPReid和ICFG-PEDES三个公开的TIPR数据集上进行了广泛的实验来评估GEA的性能，结果证明了我们方法的有效性。更多实施细节和扩展结果可在以下链接获取：this https URL."}
{"llm_update_time": "20251116", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.10215", "html_url": "https://arxiv.org/abs/2511.10215", "title": "个性化对话生成的个性化意识对齐框架", "title_en": "Persona-Aware Alignment Framework for Personalized Dialogue Generation", "authors": "Guanrong Li,Xinyu Liu,Zhen Wu,Xinyu Dai", "background": "个性化对话生成旨在利用个性档案和对话历史生成与个性相关且一致的回复。主流模型通常依赖于使用包含个性化对话数据的标记级语言模型训练，例如下一个标记预测，以隐式实现个性化，这使得这些方法倾向于忽视给定的个性并生成通用的回复。这个问题亟待解决。", "innovation": "提出了一种新颖的个性化意识对齐框架（PAL），直接将个性对齐作为对话生成的训练目标。具体地，PAL采用两阶段训练方法，包括个性化意识学习和个性对齐，并配备了一个易于使用的推理策略Select then Generate，以提高个性敏感度并在语义层面生成更相关的回复。", "conclusion": "通过广泛的实验，表明我们的框架在多项个性化对话方法和大型语言模型中表现优异。"}
{"llm_update_time": "20251116", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.10177", "html_url": "https://arxiv.org/abs/2511.10177", "title": "利用地理空间基础模型在小型沙滩岛进行海岸线划定", "title_en": "Utilizing a Geospatial Foundation Model for Coastline Delineation in Small Sandy Islands", "authors": "Tishya Chhabra,Manisha Bajpai,Walter Zesk,Skylar Tibbits", "background": "本文介绍了NASA和IBM的Prithvi-EO-2.0地理空间基础模型在利用卫星图像划定小型沙滩岛海岸线方面的初步评估。研究团队收集并标注了225个多光谱图像的数据集，用于两个马尔代夫岛屿，并公开发布了这些数据集。他们分别对300M和600M参数版本的Prithvi进行了微调，使用了从5到181张图像的不同训练子集。研究表明，即使使用5张训练图像，模型也能达到高精度（F1值为0.94，交并比为0.79）。这些结果强调了Prithvi强大的迁移学习能力，突显了此类模型在数据贫乏地区进行海岸监测的潜力。", "innovation": "研究团队利用NASA和IBM的Prithvi-EO-2.0地理空间基础模型，针对小型沙滩岛的海岸线划定进行了初步评估。通过一个小规模的数据集和不同的训练子集，展示了该模型的高精度和强大的迁移学习能力。这种方法在数据贫乏地区海岸线监测方面具有重要价值。", "conclusion": "研究表明，Prithvi模型即使在训练数据有限的情况下也能表现出色。这些结果证明了这类地理空间基础模型在数据贫乏地区进行海岸线监测的巨大潜力。"}
{"llm_update_time": "20251116", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.10203", "html_url": "https://arxiv.org/abs/2511.10203", "title": "VISTA：一种视觉与意图感知的社会注意力框架用于多智能体轨迹预测", "title_en": "VISTA: A Vision and Intent-Aware Social Attention Framework for Multi-Agent Trajectory Prediction", "authors": "Stephane Da Silva Martins,Emanuel Aldea,Sylvie Le Hégarat-Mascle", "background": "多智能体轨迹预测对于在密集交互环境中运行的自主系统至关重要。现有方法往往无法同时捕捉智能体的长期目标和精细的社会互动，这会导致不现实的多智能体未来轨迹。", "innovation": "我们提出了VISTA，一种递归的目标条件变换器用于多智能体轨迹预测。VISTA结合了（i）一个交叉注意力融合模块，结合长期意图和过往运动；（ii）一种适用于多智能体间灵活的社会交互建模的社会令牌注意力机制；（iii）一对智能体间注意力图，使其在推断时社会影响模式具有解释性。模型将单智能体目标条件预测转变为一致的多智能体预测框架。除了标准位移指标外，我们还通过轨迹碰撞率来评价多智能体的现实性。在高密度MADRAS基准和SDD上，VISTA达到了最新的准确度并显著减少了碰撞次数。结果表明，VISTA生成了符合社会规范、目标导向且可解释的轨迹，使其适合用于安全关键的自主系统。", "conclusion": "VISTA生成了符合社会规范、目标导向且可解释的轨迹，在MADRAS上将强基线的平均碰撞率从2.14%降低到0.03%，在SDD上达到零碰撞，同时提高AED、FDE和minFDE等指标。"}
{"llm_update_time": "20251116", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.10187", "html_url": "https://arxiv.org/abs/2511.10187", "title": "通过量子度量编码提高无监督强化学习性能", "title_en": "Improved Offline Reinforcement Learning via Quantum Metric Encoding", "authors": "Outongyi Lv,Yewei Yuan,Nana Liu", "background": "在实际应用中，使用有限样本的强化学习（RL）很常见，但目前在有限样本下的RL性能通常不尽如人意。为了解决这一问题，本文提出了一种新方法，即引入量子度量编码器（QME）。这种方法不直接在原始状态和奖励上应用RL框架，而是将状态嵌入到一种更紧凑且更有意义的表示中，在这种表示中，编码结构受到量子电路的启发。QME作为一种半经典的可模拟且可训练单元嵌入模块，可以运行在经典设备上。对于量子数据，QME可以直接在量子硬件上实现，无需测量或重新编码即可进行训练。", "innovation": "本文创新性地提出了使用QME的方法来处理有限样本案例中的RL问题。QME将状态嵌入到一种更紧凑且更有意义的表示中，该表示受到量子电路的启发。这使得在有限样本条件下训练RL代理时，能够获得显著更高的性能。实验结果显示，使用QME嵌入状态并通过解码奖励训练的RL代理在最大奖励性能上相比直接在原始状态和奖励上训练的代理有显著提高，具体来说，对于SAC分别实现了116.2% 的改进，对于IQL分别实现了117.6% 的改进。", "conclusion": "实验结果表明，通过QME嵌入状态并解码奖励来训练RL代理能够显著提高性能。此外，QME嵌入的状态具有低$\triangle$超球性，这表明改进归因于QME修改了状态空间的几何结构。因此，QME的低$\triangle$超球性和其相应的有效性或能为开发在有限样本条件下高效的RL方法提供有价值的信息。"}
{"llm_update_time": "20251116", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.10208", "html_url": "https://arxiv.org/abs/2511.10208", "title": "分数神经注意机制以实现高效的多尺度序列处理", "title_en": "Fractional neural attention for efficient multiscale sequence processing", "authors": "Cheng Kevin Qu,Andrew Ly,Pulin Gong", "background": "注意力机制是Transformer模型计算能力的核心，它们在多个领域取得了显著的成果。然而，进一步理解并扩展自注意力的基本原理仍然是推动人工智能发展的一个关键挑战。受生物注意力和动力系统理论中多尺度动态的启发，本文提出了分数神经注意机制（FNA），这是一个基于分数拉普拉斯介导的Lévy扩散的，具有神经科学启发性的多尺度信息处理框架。", "innovation": "FNA模型通过Lévy扩散实现多尺度内的令牌交互，自然而然地展示了同时处理短程和长程依赖性的能力。这一机制提高了表达能力并加快了信息混合，增强了Transformer的基本计算能力。理论上，FNA的动力学受到分数扩散方程的调控，结果表明此类注意力网络具有更大的谱隙和更短的路径长度，这标志着增强的计算效率特征。实际上，即使只有一层和一个头部，FNA在文本分类任务中实现了竞争力的表现；在图像处理和神经机器翻译中也提高了性能。后者还使用几何谐波中的扩散映射算法实现了FNA权重的降维，同时保留嵌入和隐状态的内在结构。", "conclusion": "这些结果确立FNA作为一种将自我注意力、随机动力学和几何联系起来的受原则机制，提供了一种可解释、基于神经科学的强大力量的AI基础。"}
{"llm_update_time": "20251116", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.10234", "html_url": "https://arxiv.org/abs/2511.10234", "title": "迷失在序列化中：图表示过LLM语言模型的不变性和泛化", "title_en": "Lost in Serialization: Invariance and Generalization of LLM Graph Reasoners", "authors": "Daniel Herbst,Lea Karbeska,Divyanshu Kumar,Akanksha Ahuja,Fatemeh Gholamzadeh Nasrabadi,Fabrizio Frasca", "background": "基于大型语言模型（LLMs）的图推理工具很有前途，但缺乏对图表示中对称性的内在不变性。LLMs在对图进行顺序序列化操作时，节点重新索引、边重新排序或格式更改会导致不同的输出结果，这引起了鲁棒性的担忧。", "innovation": "系统性地分析了这些影响，研究了微调对敏感性编码和对未见过的任务泛化能力的影响。提出了一种原理性的图序列分解方法，将图序列化分解为节点标签、边编码和语法，并在全面的基准测试套件中评估对每种因素的变化鲁棒性。此外，还贡献了一组新的谱任务，以进一步评估微调推理器的泛化能力。", "conclusion": "较大的（未微调）模型更具鲁棒性。微调可以减少对节点重新标记的敏感性，但可能增加对结构和格式变化的敏感性，而且并不始终提升在未见过的任务上的性能。"}
{"llm_update_time": "20251116", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.10232", "html_url": "https://arxiv.org/abs/2511.10232", "title": "VocalNet-M2：通过集成多码本分词和多词块预测促进低延迟语音语言建模", "title_en": "VocalNet-M2: Advancing Low-Latency Spoken Language Modeling via Integrated Multi-Codebook Tokenization and Multi-Token Prediction", "authors": "Yuhao Wang,Ziyang Cheng,Heyang Liu,Ronghua Wu,Qunshan Gu,Yanfeng Wang,Yu Wang", "background": "当前的端到端语音语言模型（SLM）已经取得了显著的进展，但在响应速度上仍然存在明显的延迟问题。这种延迟主要是由于语音生成的时间依赖性以及对复杂流匹配模型的依赖。这些因素限制了实时应用的发展。为了克服这个问题，本文提出了VocalNet-M2，这是一种新型的低延迟SLM模型，它结合了多码本分词和多词块预测策略，旨在解决上述问题，提高生成效率，保持与主流SLM相当的整体性能。", "innovation": "提出了一种新的低延迟语音语言模型VocalNet-M2，该模型通过多码本分词器和多词块预测策略直接生成多码本语音词块，从而消除了延迟复杂的流匹配模型的需要，同时提高了生成效率。该模型在大量实验中展示了显著的第一块延迟降低（从大约725ms到350ms），并且维持了与主流语音语言模型相当的性能。此外，该工作还全面比较了一种码本和多种码本策略，为高效和高性能的实时交互应用的语音语言模型开发提供了有价值的见解。", "conclusion": "VocalNet-M2 实现了第一块延迟的显著减少，同时保持了与主流语音语言模型相当的性能。这种低延迟的模型不仅提高了实时交互应用的速度和响应性，也为新型语音语言模型的设计提供了重要的指导。"}
{"llm_update_time": "20251116", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.10245", "html_url": "https://arxiv.org/abs/2511.10245", "title": "空间频域混合图像水印鲁棒性和不可感知性分析", "title_en": "Robustness and Imperceptibility Analysis of Hybrid Spatial-Frequency Domain Image Watermarking", "authors": "Rizal Khoirul Anam", "background": "数字化媒体的流行要求具有强大方法的版权保护和内容认证。本文对比研究了基于空间域（最小重要位-LSB）、频域（离散傅立叶变换-DFT）及新型混合（LSB+DFT）方法的数字图像水印技术。实验测试了这些技术在JPEG压缩、高斯噪声和椒盐噪声等常见图像处理攻击下的鲁棒性与不可感知性。", "innovation": "提出了融合最小重要位（LSB）和离散傅立叶变换（DFT）的新型混合水印技术，该技术基于冗余嵌入和失败恢复提取机制，提供鲁棒性和不可感知性的平衡。", "conclusion": "虽然LSB水印在不可感知性方面表现出色，但其脆弱性严重，而DFT水印在视觉质量上有所损失但具有显著的鲁棒性。提出的LSB+DFT混合水印技术，保持了较高的视觉保真度，同时对所有测试攻击具有优异的鲁棒性。"}
{"llm_update_time": "20251116", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.10222", "html_url": "https://arxiv.org/abs/2511.10222", "title": "多重模态大语言模型上的言语-音频合成攻击及其Salmonn-Guard缓解", "title_en": "Speech-Audio Compositional Attacks on Multimodal LLMs and Their Mitigation with SALMONN-Guard", "authors": "Yudong Yang,Xuezhen Zhang,Zhifeng Han,Siyin Wang,Jimin Zhuang,Zengrui Jin,Jing Shao,Guangzhi Sun,Chao Zhang", "background": "近年来，大型语言模型（LLMs）的发展使它们具备了理解和处理语音和非语音音频的能力，但当前的安全防护措施对复杂的音频输入的处理能力不足，从而产生新的安全风险。因此，需要一种新方法来评估LLMs在复杂音频攻击下的鲁棒性。现有的对抗方法主要依赖于噪声优化或白盒访问，而这项研究引入了SACRED-Bench（Speech-Audio Composition for RED-teaming），采用言语-音频合成机制，以更全面的方式挑战LLMs的鲁棒性。", "innovation": "SACRED-Bench提出了一种新的评估方法，其通过三种机制（语音重叠与多说话人对话、言语-音频混合、多样化的口头指令格式）来评估LLMs的鲁棒性；它不同于现有的依赖噪声优化或白盒访问的对抗方法，而是利用了言语-音频合成机制。研究还提出了一种新的安全防护方法SALMONN-Guard，它能够同时检查语音、音频和文本以进行安全判断，将攻击成功率降低至20%。", "conclusion": "该研究强调了针对多模态大语言模型的安全防护需要具备音频意识。SACRED-Bench为评估LLMs在语音-音频合成攻击下的鲁棒性提供了基准，同时SALMONN-Guard作为一种新的安全防护模型，可以有效降低攻击成功率，表明了通过联合检查语音、音频和文本来增强安全性的必要性。该基准和SALMONN-Guard的模型可以在提供的链接处找到。请注意，该论文包含了可能具有冒犯性或有害的示例。"}
{"llm_update_time": "20251116", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.10258", "html_url": "https://arxiv.org/abs/2511.10258", "title": "工作负载调度器——起源、算法和差异", "title_en": "Workload Schedulers -- Genesis, Algorithms and Differences", "authors": "Leszek Sliwko,Vladimir Getov", "background": "本文介绍了一种对现代工作负载调度器进行分类的新型方法。文章描述了三种类型的调度器：操作系统进程调度器、集群系统作业调度器和大数据调度器，并探讨了它们从早期采用到现代实现的发展历程，特别是在算法的使用和特性方面的考虑。", "innovation": "提出了一种对现代工作负载调度器进行分类的新颖方法，详细描述了三种类型的调度器从早期到现代的发展演变过程。", "conclusion": "总结了所介绍的所有调度器类别的差异，并强调了调度策略设计中的一些共同关注点，这些点适用于局部和分布式系统。"}
{"llm_update_time": "20251116", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.10250", "html_url": "https://arxiv.org/abs/2511.10250", "title": "FineSkiing：滑雪动作质量评估的细粒度基准", "title_en": "FineSkiing: A Fine-grained Benchmark for Skiing Action Quality Assessment", "authors": "Yongji Zhang,Siqi Li,Yue Gao,Yu Jiang", "background": "动作质量评估(AQA)旨在评估和评分体育动作，近年来受到了广泛关注。现有的AQA方法主要通过提取整段视频的特征来进行评分预测，但这种方式的解释性和可靠性有限。同时，现有的AQA数据集缺乏精细的评分注释，特别是在扣分项目和子评分注释方面。", "innovation": "本研究构建了首个包含雪上技巧项目精细子评分和扣分注释的AQA数据集，并命名为FineSkiing，作为一个新的基准。为了应对技术挑战，我们提出了一个新的AQA方法，名为JudgeMind，通过模拟专业裁判的评判和评分心理状态，显著提升了性能和可靠性。该方法将输入动作视频划分为不同的阶段，并对每个阶段进行评分，以提高准确性。同时，我们提出了一种阶段意识特征增强和融合模块，以提高对特定阶段关键区域的感知能力，并增强对频繁的摄像机视角切换导致的视觉变化的鲁棒性。此外，我们还提出了一种基于知识的等级意识解码器，将可能的扣分项目作为先验知识来预测更准确和可靠的评分。", "conclusion": "实验结果表明，我们的方法达到了最先进的性能。"}
{"llm_update_time": "20251116", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.10260", "html_url": "https://arxiv.org/abs/2511.10260", "title": "H3Former: 基于超图感知聚合的类层对比损失方法用于细粒度视觉分类", "title_en": "H3Former: Hypergraph-based Semantic-Aware Aggregation via Hyperbolic Hierarchical Contrastive Loss for Fine-Grained Visual Classification", "authors": "Yongji Zhang,Siqi Li,Kuiyang Huang,Yue Gao,Yu Jiang", "background": "细粒度视觉分类（FGVC）任务由于类间微小差异和类内大量变异性仍然具有挑战性。现有方法通常依赖特征选择机制或区域建议策略来定位语义分析中的关键区域，但这些方法往往在全面捕捉具有区分性的线索的同时，引入了大量无差异的类别特征。", "innovation": "我们提出了H3Former，这是一种新颖的token-to-region框架，利用高层语义关系来聚合局部的细粒度表示并构建结构化的区域层次模型。H3Former引入了语义感知聚合模块（SAAM），利用多尺度上下文线索动态构建token之间的加权超图。此外，我们提出了超球面层次对比损失（HHCL），在非欧几里得嵌入空间中施加层次语义约束。HHCL提高了类间可分性和类内一致性，同时保持了细粒度类别的固有层次关系。", "conclusion": "我们在四个标准FGVC基准上的全面实验验证了H3Former框架的优越性。"}
{"llm_update_time": "20251116", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.10251", "html_url": "https://arxiv.org/abs/2511.10251", "title": "启发式变换器：基于信念增强的上下文强化学习", "title_en": "Heuristic Transformer: Belief Augmented In-Context Reinforcement Learning", "authors": "Oliver Dippel,Alexei Lisitsa,Bei Peng", "background": "变换器在自然语言处理、计算机视觉和序列决策等领域展示了出色的能力，特别是在强化学习中，可以从原始上下文信息中学习而无需调整参数，重新定义学习为监督学习问题，促进任务的快速适应。研究团队利用变换器技术在序列决策方面进行了工作，提出了Heuristic Transformer（启发式变换器），即上下文强化学习（ICRL）方法，将奖励的信念分布与上下文数据集相结合以提高决策质量。借助变分自动编码器（VAE），学习了一个低维度的随机变量来表示奖励的后验分布，并作为提示并与上下文数据集和查询状态一起提供给变换器策略。在Darkroom、Miniworld和MuJoCo环境中进行验证，证明了方法的优势和泛化能力。", "innovation": "该方法通过引入一个基于VAE的低维度随机变量来表示奖励的后验分布，与上下文数据集一起作为变换器策略的提示信息，从而实现更好的决策。与现有基于信念增强的方法相比，该方法在多个环境中表现更好，同时具有更好的泛化能力，展现了一种潜在的弥合基于信念的增强和基于变换器决策的差距的研究方向。", "conclusion": "启发式变换器（HT）方法在Darkroom、Miniworld和MuJoCo等环境中的测试证明了它在有效性与泛化能力方面的优越性能。这种方法为强化学习中应用变换器模型提供了一种新的思路，展示了从原始上下文中学习和决策的新机制。"}
{"llm_update_time": "20251116", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.10276", "html_url": "https://arxiv.org/abs/2511.10276", "title": "RoboBenchMart: 在零售环境评估机器人的基准", "title_en": "RoboBenchMart: Benchmarking Robots in Retail Environment", "authors": "Konstantin Soshin,Alexander Krapukhin,Andrei Spiridonov,Denis Shepelev,Gregorii Bukhtuev,Andrey Kuznetsov,Vlad Shakhuro", "background": "现有的大多数机器人操作基准主要关注简化的工作台场景，通常涉及静止的机器臂与平坦表面上的多个物体互动。由于这些基准环境较为简单，无法全面评估机器人在实际操作中的能力，尤其是在复杂的动态环境如零售环境中的表现。", "innovation": "罗博汇（RoboBenchMart）是一个更具有挑战性和现实性的基准测试，专门设计用于黑暗仓储环境，能够评估机器人的复杂操作任务，并且可以模拟多种商品及其复杂构型，如密集的商品堆积和不同的高度、深度排列。这个设置本身具有很强的近期内部自动化影响潜力。", "conclusion": "目前最先进的通用模型在解决常见的零售任务时也表现不佳。为支持后续研究，我们发布了RoboBenchMart套件，该套件包含了一种程序化生成货架布局的方式、轨迹生成管道、评估工具和细调的基准模型。"}
{"llm_update_time": "20251116", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.10262", "html_url": "https://arxiv.org/abs/2511.10262", "title": "MTR-DuplexBench: 针对全双工语音语言模型多轮对话全面评估的基准", "title_en": "MTR-DuplexBench: Towards a Comprehensive Evaluation of Multi-Round Conversations for Full-Duplex Speech Language Models", "authors": "He Zhang,Wenqian Cui,Haoning Xu,Xiaohui Li,Lei Zhu,Shaohua Ma,Irwin King", "background": "全双工语音语言模型（FD-SLMs）能实现实时、重叠的对话交互，提供比传统半双工模型更具动态性的用户体验。现有基准主要关注单轮对话和对话特征的评估，忽略了多轮对话的复杂性和关键能力，如指令遵循和安全性。在多轮对话设置中评估FD-SLMs存在显著挑战，包括通信中的轮次边界模糊和模型推理过程中的上下文不一致。", "innovation": "我们引入MTR-DuplexBench，一种新型基准，能够将连续的全双工对话分割成离散的轮次，从而实现对FD-SLMs的整体、逐轮评估，涉及对话质量、对话动态、指令遵循和安全性等方面。实验结果表明当前FD-SLMs在多轮对话和评估维度上保持一致性能的困难，强调我们所提出的基准的必要性和有效性。", "conclusion": "实验结果揭示，当前FD-SLMs在多轮对话及多个评估维度上维持一致性能存在困难，强调了我们提出的新基准的必要性和有效性。未来将提供基准代码。"}
{"llm_update_time": "20251116", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.10282", "html_url": "https://arxiv.org/abs/2511.10282", "title": "Torch-Uncertainty: 一个用于不确定性量化的大规模深度学习框架", "title_en": "Torch-Uncertainty: A Deep Learning Framework for Uncertainty Quantification", "authors": "Adrien Lafage,Olivier Laurent,Firas Gabetni,Gianni Franchi", "background": "深度神经网络在计算机视觉和自然语言处理等领域已经表现出出色的性能。然而，这些模型在准确量化其预测不确定性方面常常表现不佳，这限制了它们在关键现实世界应用中的更广泛应用。不确定性量化（Uncertainty Quantification, UQ）旨在通过提供改进不确定性估计可靠性的方法来解决这一问题。虽然已经提出了许多技术，但缺乏一个提供无缝工作流程来评估和整合这些方法的统一工具。因此，需要一个专门的框架来支持这一过程。", "innovation": "我们引入了Torch-Uncertainty框架，这是一个基于PyTorch和Lightning的框架，旨在简化深度神经网络(DNN)训练和评估时的不确定性量化(uncertainty quantification)技术与指标的使用流程。该框架提供了一个统一的工具来评估和整合多种不确定性量化方法。作者概述了该库的基础原则，并通过广泛的实验结果在分类、分割和回归任务中对多种不确定性量化方法进行了基准测试。", "conclusion": "Torch-Uncertainty提供了用来支持通用深度学习模型在不确定性量化方面设计、评估和整合的技术方法，通过其广泛的实验结果支持并证明了其在多项任务上的优越性能。"}
{"llm_update_time": "20251116", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.10292", "html_url": "https://arxiv.org/abs/2511.10292", "title": "低开销残差更新导向的自适应幻觉抑制方法在大规模视觉语言模型中的应用", "title_en": "Adaptive Residual-Update Steering for Low-Overhead Hallucination Mitigation in Large Vision Language Models", "authors": "Zhengtao Zou,Ya Gao,Jiarui Guan,Bin Li,Pekka Marttinen", "background": "大型视觉语言模型（LVLMs）常常遭受物体错觉问题，生成与视觉输入不一致的文本，这严重削弱了它们的可靠性。现有解决此问题的方法在推理阶段干预，面临效用与效率之间的权衡：虽然有调节内部状态或调整输出logits的方法可以有效，但这些方法通常会有较大的计算开销，通常需要额外的前向传递。这种效率瓶颈限制了它们在实际、对延迟敏感部署中的实用性。", "innovation": "该论文提出了一种低开销框架——残差更新导向的解码调节（RUDDER），通过两个创新来引导LVLMs实现视觉导向生成：(1) 上下文激活残差方向（CARD）向量，在单次标准前向传递中从一个自注意力层的残差更新中提取的每次样本的视觉证据向量；(2) 一种借鉴贝叶斯思想的自适应门控机制，按照模型偏离视觉上下文的程度进行逐词注射，应用矫正信号。", "conclusion": "在关键幻觉基准测试（如POPE和CHAIR）上的广泛实验表明，RUDDER在保存计算延迟的同时实现了与最新方法相当的性能，验证了RUDDER作为一种可行和有效的改进LVLMs可靠性的方法，在效率方面没有重大妥协。"}
{"llm_update_time": "20251116", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.10301", "html_url": "https://arxiv.org/abs/2511.10301", "title": "重思多模态LLMs中的视觉信息处理", "title_en": "Rethinking Visual Information Processing in Multimodal LLMs", "authors": "Dongwan Kim,Viresh Ranjan,Takashi Nagata,Arnab Dhua,Amit Kumar K C", "background": "LLaVA架构在视觉语言任务中取得了显著的成功，但其设计固有限制了视觉特征的有效整合，根源在于文本和视觉模态之间的固有不匹配。目前的方法主要依赖于语言模型处理视觉信息，导致视觉理解能力受限。本文提出了一个创新视角，即将语言模型（LLM）扩展为强大的视觉编码器，通过学习独立的视觉模态QKV投影、启用视觉标记的双向注意机制以及整合全局和局部视觉表示来实现视觉信息的更有效处理。", "innovation": "本文提出了一种新型的LLM模型——LLaViT（LLM作为扩展的视觉变换器），通过三项关键修改实现了LLM作为视觉编码器的功能：(1) 学习独立的QKV投影用于视觉模态；(2) 启用视觉标记的双向注意机制；(3) 结合全局和局部视觉表示。实验表明，即使参数量较小，LLaViT在多种基准测试中也显著优于基线方法LLaVA，并且超过了参数量双倍的模型，显示出更有效的视觉语言建模方法。", "conclusion": "通过广泛控制实验，本文展示了LLaViT在多种基准测试中的卓越性能，甚至超越了参数量双倍的模型，提出了一种更具效的视觉语言建模方法。"}
{"llm_update_time": "20251116", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.10271", "html_url": "https://arxiv.org/abs/2511.10271", "title": "LLM生成代码的质量保证：解决非功能性质量特征", "title_en": "Quality Assurance of LLM-generated Code: Addressing Non-Functional Quality Characteristics", "authors": "Xin Sun,Daniel Ståhl,Kristian Sandahl,Christoph Kessler", "background": "近年来，大模型（LLMs）被广泛集成到软件工程的工作流程中，支持生成代码等任务。然而，尽管这些模型经常生成功能正确的输出，我们仍然缺乏对他们非功能性品质的系统理解与评估。现有的研究主要关注生成的代码是否通过测试，而不是其质量如何。鉴于这方面的不足，本研究基于ISO/IEC 25010质量模型，进行了三项互补的研究：系统文献回顾、行业工作坊以及针对真实软件问题的三个大模型生成补丁的实证分析。研究结果显示，学术界主要关注安全性和性能效率，而维护性等其他品质则研究不足。同时，行业专家优先关注维护性和易读性，指出生成的代码可能加速技术债务的积累。在对三个大模型生成的正确功能补丁进行评估时，一个品质维度的改进往往以其他维度的牺牲为代价；此外，实测结果显示，不同模型和优化策略间的运行时和内存结果差异显著。总体来看，研究发现学术界的关注点、行业优先事项与模型性能之间存在不匹配，强调在大模型代码生成过程中应整合质量保证机制，以确保未来生成的代码不仅通过测试，还真正具有高质量的特点。", "innovation": "本研究通过系统文献回顾、行业工作坊及实证分析，对大模型生成代码的维护性、安全性和性能效率进行了关注，并指出了现有的研究与实际行业需求之间的差距。研究发现，生成的代码在不同的品质维度间存在权衡，学术与行业的关注点也存在一定的不一致性。研究强调了在大模型代码生成过程中需整合质量保证机制的重要性。", "conclusion": "研究表明，现有研究主要关注大模型生成代码的功能正确性，而忽略了它们的非功能性品质。同时，学术界与行业专家对品质的关注点存在差异。研究发现生成代码在不同的品质维度间存在权衡。为了确保未来生成的代码不仅通过测试，还真正具有高质量，需要在大模型代码生成过程中整合质量保证机制。"}
{"llm_update_time": "20251116", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.10316", "html_url": "https://arxiv.org/abs/2511.10316", "title": "通过物理焦距建模和多视角几何监督实现一致的3D高斯点绘制", "title_en": "Depth-Consistent 3D Gaussian Splatting via Physical Defocus Modeling and Multi-View Geometric Supervision", "authors": "Yu Deng,Baozhu Zhao,Junyan Su,Xiaohan Zhang,Qi Liu", "background": "在具有极端深度变化的场景中进行三维重建仍然具有挑战性，因为近场和远场区域之间的监督信号不一致。现有方法无法同时解决远处区域不准确的深度估计以及近距离区域结构退化的问题。", "innovation": "本文提出了一种新的计算框架，结合深度场监督和多视角一致性监督，以改进3D Gaussian Splatting。该方法包括两个核心组成部分：（1）深度场监督利用规模恢复单目深度估计器（如Metric3D）生成深度先验，利用去焦卷积合成物理上准确的去焦图像，并通过新颖的深度场损失增强远近区域的深度保真度；（2）多视角一致性监督使用基于LoFTR的半密集特征匹配来最小化跨视角几何误差，并通过最小二乘优化可靠匹配点进行深度一致性。通过将焦散物理和多视角几何约束统一起来，本方法实现了更好的深度保真度，相比最先进的方法在Waymo Open Dataset上PSNR提高了0.8 dB。此框架结合物理成像原理和基于学习的深度正则化，为复杂深度分层的城市环境提供了可扩展的解决方案。", "conclusion": "通过物理焦距建模和多视角几何监督，该方法在复杂深度分层的城市环境中实现了卓越的深度保真度。"}
{"llm_update_time": "20251116", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.10370", "html_url": "https://arxiv.org/abs/2511.10370", "title": "SHRUG-FM：地球观测的可靠性意识基础模型", "title_en": "SHRUG-FM: Reliability-Aware Foundation Models for Earth Observation", "authors": "Kai-Hendrik Cohrs,Zuzanna Osika,Maria Gonzalez-Calabuig,Vishal Nedungadi,Ruben Cartuyvels,Steffen Knoblauch,Joppe Massant,Shruti Nath,Patrick Ebel,Vasileios Sitokonstantinou", "background": "地球观测领域的位置模型经常在预训练阶段未涵盖的环境中表现不稳定。研究引入了一个新的框架SHRUG-FM，该框架通过结合输入空间的离群点检测、嵌入空间的离群点检测和任务特定的预测不确定性来实现可靠的预测。", "innovation": "SHRUG-FM框架通过集成三种互补信号：输入空间的离群点检测、嵌入空间的离群点检测和任务特定的预测不确定性，来实现可靠的预测。通过烧伤疤痕分割的应用，研究表明离群点评分与特定环境条件下的较差性能相关，而基于不确定性的标志有助于丢弃许多表现不佳的预测。", "conclusion": "SHRUG-FM为使地球观测敏感应用中的GFMs更为安全和可解释性提供了途径，帮助缩小基准性能和现实世界可靠性之间的差距。"}
{"llm_update_time": "20251116", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.10367", "html_url": "https://arxiv.org/abs/2511.10367", "title": "DermAI：通过质量驱动的图像采集实现移动设备中的AI分类临床皮肤病学获取", "title_en": "DermAI: Clinical dermatology acquisition through quality-driven image collection for AI classification in mobile", "authors": "Thales Bezerra,Emanoel Thyago,Kelvin Cunha,Rodrigo Abreu,Fábio Papais,Francisco Mauro,Natália Lopes,Érico Medeiros,Jéssica Guido,Shirley Cruz,Paulo Borba,Tsang Ing Ren", "background": "AI在皮肤病学的应用受到有偏见的数据集、图像质量不一致以及有限的验证的限制。现有的工具主要集中在皮肤镜检查方面，缺乏在设备端进行质量检查和本地模型适配的能力。因此，医疗应用场景中的标准化和多样化的数据收集对于机器学习的发展至关重要。", "innovation": "提出了一款名为DermAI的轻量级、基于智能手机的应用程序，该应用能够实现实时抓取、注释和分类皮肤病变。DermAI具有在设备端进行质量检查和本地模型适应的功能，其临床数据集涵盖了广泛的肤色、种族和设备来源。实验表明，使用公开数据集训练的模型无法很好地泛化到实验样本，而利用本地数据进行微调可以提升性能。", "conclusion": "这些结果强调了标准化、多样化数据收集的重要性，数据收集应与医疗需求和机器学习的发展相匹配。DermAI通过质量驱动的图像采集，为移动设备中的AI分类提供了一种新的解决方案。"}
{"llm_update_time": "20251116", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.10384", "html_url": "https://arxiv.org/abs/2511.10384", "title": "使用大型语言模型模拟社交媒体中的谣言传播", "title_en": "Simulating Misinformation Propagation in Social Networks using Large Language Models", "authors": "Raj Gaurav Maurya,Vaibhav Shukla,Raj Abhijit Dandekar,Rajat Dandekar,Sreedath Panat", "background": "社交媒体上的误导信息依赖于惊讶感、情感和身份驱动的推理，并通过人类的认知偏差进一步放大。本文通过构建大型语言模型的人格化代理来模拟和分析这种传播机制。这些代理被设计成模仿用户级别的偏见、意识形态倾向和信任直觉，进而通过网络传递新闻和内容，进行不断重组。", "innovation": "本文引入了一种新的审计者-节点框架，能够在大规模图文传播过程中，从来源内容的每一步分析和追踪谣言的演变情况。本文还首次使用多阶段混淆指数和传播率量化横向传播过程中信息的真实性的衰减。实验结果表明，某些类型的人格化代理会加速谣言的传播，特别是在政治、营销和技术领域；而专家驱动的人格化代理则有助于保持信息的真实性。此外，异质代理的组合使用可能迅速使谣言达到宣传级别的扭曲。", "conclusion": "研究结果表明，大型语言模型不仅可以作为人类偏见的代理，还能作为审计工具追溯信息的真实性。所提出的框架为研究社交媒体环境中谣言的传播机制提供了一个可解释、基于实证的方法。该框架同时适用于模拟和减轻信息误导的扩散问题。"}
{"llm_update_time": "20251116", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.10338", "html_url": "https://arxiv.org/abs/2511.10338", "title": "BhashaKritika：构建面向印度语言的大规模合成预训练数据", "title_en": "BhashaKritika: Building Synthetic Pretraining Data at Scale for Indic Languages", "authors": "Guduru Manoj,Neel Prabhanjan Rachamalla,Ashish Kulkarni,Gautam Rajeev,Jay Piplodiya,Arul Menezes,Shaharukh Khan,Souvik Rana,Manya Sah,Chandra Khatri,Shubham Agarwal", "background": "在大规模语言模型（LLMs）的预训练过程中，合成数据作为一种替代方案，能够大规模生成高质量的预训练数据。这对于语言资源贫乏的语境尤其有益，因为近期LLMs带来的好处尚未在所有语言中均匀分布。本文旨在系统研究印度语言的合成预训练数据生成与评估方法。构建了一个包含540B个令牌、涵盖10种语言的大规模合成数据集BhashaKritika，利用了5种技术手法，并探讨了文档、人物和主题对生成的影响。研究了语言选择（包括提示说明和文档基础中的语言选择）如何影响数据质量，以及英语文本翻译与印度本地生成的对比。为了支持可扩展且语言敏感的评估，引入了一个模块化的质量评估管道，该管道整合了脚本和语言检测、元数据一致性检查、n-gram重复分析以及使用KenLM模型的困惑度（perplexity）基础过滤。该框架能够在多种脚本和语言环境中实现稳健的质量控制。通过模型运行得到的经验结果揭示了生成策略中的关键权衡，并指出了构建有效多语言语料库的最佳实践.", "innovation": "该研究提出了一个大规模合成预训练数据集BhashaKritika，涵盖了10种印度语言，同时使用了5种技术手段生成。更重要的是，研究引入了一种模块化的质量评估框架，能够支持可扩展和语言敏感的评估，包括脚本和语言检测、元数据一致性检查、n-gram重复分析和困惑度分析。这项工作为构建多语言语料库提供了一个系统的方法，尤其适用于语言资源贫乏的语言环境.", "conclusion": "该研究展示了生成策略中的关键权衡，并指出了构建有效多语言语料库的最佳实践。模块化的质量评估框架使研究能够在多种脚本和语言环境中实现稳健的质量控制，从而为大规模语言模型预训练提供了新思路。"}
{"llm_update_time": "20251116", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.10390", "html_url": "https://arxiv.org/abs/2511.10390", "title": "MonkeyOCR v1.5 技术报告：破解复杂模式下的稳健文档解析", "title_en": "MonkeyOCR v1.5 Technical Report: Unlocking Robust Document Parsing for Complex Patterns", "authors": "Jiarui Zhang,Yuliang Liu,Zijun Wu,Guosheng Pang,Zhili Ye,Yupei Zhong,Junteng Ma,Tao Wei,Haiyang Xu,Weikai Chen,Zeen Wang,Qiangjun Ji,Fanxi Zhou,Qi Zhang,Yuanrui Hu,Jiahao Liu,Zhang Li,Ziyang Zhang,Qiang Liu,Xiang Bai", "background": "文档解析是文档智能的重要任务，支持信息提取、检索增强生成和自动化文档分析等应用。然而，现实中的文档往往具有复杂的布局，包含多层次表格、嵌入的图片或公式以及跨页结构，现有OCR系统难以应对这些挑战。", "innovation": "介绍了一种统一的视觉-语言框架MonkeyOCR v1.5，通过两阶段解析流水线增强布局理解和内容识别。第一阶段使用大规模的多模态模型联合预测文档布局和阅读顺序，利用视觉信息确保结构和顺序一致性。第二阶段在检测到的区域内局部识别文本、公式和表格，保持高视觉保真度同时减少误差传播。此外，还提出了基于视觉一致性的强化学习方案，通过渲染并比较对识别质量进行评估，提高结构准确性，无需手动注释。另外，还引入了两个专业模块：图像脱耦表格解析和类型引导表格合并，以实现包含嵌入图片的表格的可靠解析和跨页或列的表格重构。", "conclusion": "在OmniDocBench v1.5上的全面实验表明，MonkeyOCR v1.5表现出最先进的性能，优于PPocr-VL和MinerU 2.5，并且在视觉复杂的文档场景中表现出色的鲁棒性。"}
{"llm_update_time": "20251116", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.10439", "html_url": "https://arxiv.org/abs/2511.10439", "title": "通过理解不确定性校准的角色来改进扰动基于的解释", "title_en": "Improving Perturbation-based Explanations by Understanding the Role of Uncertainty Calibration", "authors": "Thomas Decker,Volker Tresp,Florian Buettner", "background": "扰动基于的解释被广泛用于提高机器学习模型的透明度，但它们的可靠性往往受到特定扰动下未知模型行为的影响。本文探讨了不确定性校准（即模型的信心与其实际准确性的一致性）与扰动基于的解释之间的关系。研究表明，在进行解释性特定扰动时，模型系统地产生了不可靠的概率估计，理论上也证明了这直接降低了全局和局部解释的质量。", "innovation": "本文引入了ReCalX，这是一种新颖的方法，用于在校准模型以改进解释的同时保留原始预测。实验评估表明，ReCalX能够最有效地减少特定于扰动的错误校准，增强解释的稳健性，并有助于识别全局重要的输入特征。", "conclusion": "总之，本文通过理论分析和实验验证，提出了一种新的方法ReCalX，能够校准模型以提高解释的质量，同时不影响其原始预测。这种方法在多种模型和数据集上的实验中表现出了优越性。"}
{"llm_update_time": "20251116", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.10453", "html_url": "https://arxiv.org/abs/2511.10453", "title": "关于歧义请求的推理意图", "title_en": "Reasoning About Intent for Ambiguous Requests", "authors": "Irina Saparina,Mirella Lapata", "background": "大语言模型在面对模糊请求时，往往会隐式地选择一种解释并作出回应。这种意图误解可能导致用户不满，甚至带来安全风险。目前的方法未能充分覆盖多种有效答案，难以促进透明沟通，且生成和输出过程效率不高。", "innovation": "本文提出了一种方法，即在单一结构化响应中生成多个解释-答案对，通过强化学习和定制化的奖励函数进行训练，利用多种有效答案作为监督。实验表明，该方法在涵盖有效答案和生成步骤的效率方面优于现有基准方法，且预测的意图与答案高度一致。", "conclusion": "该方法通过显式解释增强了透明度，仅需一步生成避免了效率损失，且由于结构化输出适用于下游应用，充分验证了其有效性。"}
{"llm_update_time": "20251116", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.10395", "html_url": "https://arxiv.org/abs/2511.10395", "title": "AgentEvolver: 朝着高效自我进化的代理系统方向", "title_en": "AgentEvolver: Towards Efficient Self-Evolving Agent System", "authors": "Yunpeng Zhai,Shuchang Tao,Cheng Chen,Anni Zou,Ziqian Chen,Qingxu Fu,Shinji Mai,Li Yu,Jiaji Deng,Zouying Cao,Zhaoyang Liu,Bolin Ding,Jingren Zhou", "background": "自主智能体由大型语言模型（LLMs）驱动，有可能显著提高人类生产力，通过在复杂任务的推理、工具使用和执行等方面增强能力。然而，当前开发此类智能体的方法仍然昂贵且效率低，通常需要手动构建任务数据集和广泛利用强化学习（RL）管道中的随机探索。这些限制导致数据构建成本高、探索效率低和样本利用差。", "innovation": "我们提出了AgentEvolver，这是一种自我进化的代理系统，结合大型语言模型的语义理解和推理能力来推动自主代理学习。AgentEvolver引入了三个相互协同的机制：自我提问，促进新环境的任务生成和好奇心驱动，减少对手工构建数据集的依赖；自我导航，通过经验重用和混合策略指导提高探索效率；自我归因，根据轨迹状态和动作的贡献分配不同的奖励来增强样本效率。通过这些机制的整合，AgentEvolver实现了可扩展、低成本和持续改进的代理能力。初步实验表明，与传统的基于RL的基线相比，AgentEvolver在探索效率、样本利用和适应速度方面均具有优势。", "conclusion": "通过结合这三个机制，AgentEvolver能够在广泛的场景中实现高效、低成本和持续改进的智能体能力，表明了其在智能代理系统中的潜力和优势。"}
{"llm_update_time": "20251116", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.10403", "html_url": "https://arxiv.org/abs/2511.10403", "title": "nuPlan-R: 通过基于反应型多智能体仿真进行自主驾驶的闭环规划基准", "title_en": "nuPlan-R: A Closed-Loop Planning Benchmark for Autonomous Driving via Reactive Multi-Agent Simulation", "authors": "Mingxing Peng,Ruoyu Yao,Xusen Guo,Jun Ma", "background": "近期在闭环规划基准领域的进展显著提升了对自动驾驶汽车的评估。然而，现有的基准仍然依赖于基于规则的反应性代理，如智能驾驶员模型（IDM），这些代理缺乏行为多样性，无法捕捉现实的人类互动，导致交通动态过于简化。", "innovation": "我们提出了nuPlan-R，一个新版本的基于反应型多智能体仿真的闭环规划基准，将基于学习的反应性多智能体仿真集成到nuPlan框架中。该基准用去耦噪声的扩散基反应性代理替换了基于规则的IDM代理，并引入了互动意识的代理选择机制来确保真实性和计算效率。此外，我们扩展了基准，引入了两个额外的评估指标以提供更全面的规划性能评估。我们的实验结果显示，基于反应型的代理模型能够生成更真实、多样且类似于人类的交通行为，使得基准环境更能反映现实世界中的交互驾驶。我们进一步在nuPlan-R基准中实现了多种基于规则、基于学习和混合式规划方法的重新实现，这些实现了在复杂交互场景中更清晰地反映规划器性能，并更能突出基于学习的规划器在处理复杂和动态场景方面的优越性。", "conclusion": "这些结果确立了nuPlan-R作为公平、反应性和真实的闭环规划评估的新标准。我们将开放新基准的代码。"}
{"llm_update_time": "20251116", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.10400", "html_url": "https://arxiv.org/abs/2511.10400", "title": "重思多智能体系统的可靠性：拜占庭容错视角", "title_en": "Rethinking the Reliability of Multi-agent System: A Perspective from Byzantine Fault Tolerance", "authors": "Lifan Zheng,Jiawei Chen,Qinghong Yin,Jingyuan Zhang,Xinyi Zeng,Yu Tian", "background": "多智能体系统的可靠性和故障发生后有效识别问题智能体至关重要。大型语言模型的进步使基于大型语言模型的智能体成为多智能体系统的重要分支，为复杂问题解决和世界建模带来了重大突破。然而，这种转变对可靠性的影响尚不清楚，即用基于大型语言模型的智能体替换传统智能体是否能有效提高多智能体系统的可靠性。本文从拜占庭容错的角度探讨和量化基于大型语言模型的智能体的可靠性。我们观察到，基于大型语言模型的智能体在处理错误消息流时表现出更强的怀疑态度，这种特性使它们在不同拓扑结构下能够优于传统智能体。", "innovation": "本文设计了一种基于信心探测的加权拜占庭容错一致性机制——CP-WBFT，利用大型语言模型固有的反射性和辨别能力，通过基于探测的加权信息流传输方法来提高基于大型语言模型的智能体的可靠性。广泛的实验表明，在极端拜占庭条件下，CP-WBFT在各种网络拓扑结构下表现出优越的性能，特别是对于数学推理和安全评估任务，我们的方法在各种拓扑结构上达到显著的准确性，并保持了很强的可靠性。", "conclusion": "CP-WBFT机制在极端拜占庭条件下，不仅在各种网络拓扑结构上表现优于传统方法，还在数学推理和安全评估任务中保持着高水平的可靠性。"}
{"llm_update_time": "20251116", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.10440", "html_url": "https://arxiv.org/abs/2511.10440", "title": "使用CrysFormer机器学习模型通过Patterson图完成部分结构", "title_en": "Completion of partial structures using Patterson maps with the CrysFormer machine learning model", "authors": "Tom Pan,Evan Dramko,Mitchell D. Miller,Anastasios Kyrillidis,George N. Phillips Jr", "background": "蛋白质结构测定一直是结构生物学的主要挑战之一。传统的深机器学习方法通常不直接整合实验测量，如X射线晶体学衍射数据。为了解决这一问题，研究提出了一种新方法，通过训练结合3D视觉变换器和卷积网络的混合模型，同时利用X射线晶体学数据和预测的结构模板，来提高晶体结构因子的相位并填补部分结构模板中的空白区域。", "innovation": "该研究提出了一种新的方法，通过训练结合3D视觉变换器和卷积网络的混合模型，利用X射线晶体学数据和预测的结构模板来预测电子密度图。这种方法能有效提高晶体结构因子的相位，填补部分结构中的空白区域，并提高电子密度图与真实原子结构的一致性。", "conclusion": "通过使用CrysFormer方法，研究团队成功地展示了对部分结构的完成和对晶体结构因子相位的改进，并且电子密度图与真实的原子结构更加一致。这种方法提供了一种整合传统晶体学方法和现代机器学习技术的新型手段，有助于提高蛋白质结构预测的精度和效率。"}
{"llm_update_time": "20251116", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.10392", "html_url": "https://arxiv.org/abs/2511.10392", "title": "增强核幂次K均值：基于随机傅里叶特征和可能性方法的可扩展和鲁棒聚类", "title_en": "Enhancing Kernel Power K-means: Scalable and Robust Clustering with Random Fourier Features and Possibilistic Method", "authors": "Yixi Chen,Weixuan Liang,Tianrui Liu,Jun-Jie Huang,Ao Li,Xueling Zhu,Xinwang Liu", "background": "现有的核幂次K均值（KPKM）算法通过使用一组均值来缓解核K均值中的局部最优问题。然而，KPKM存在两个主要限制：一是全核矩阵的计算负担限制了其在大规模数据集上的应用；二是缺乏真实 centroid-样本分配学习，减少了其抵抗噪声的能力。", "innovation": "本文提出了RFF-KPKM，它通过引入随机傅里叶特征（RFF）的首个应用理论，解决了KPKM的上述问题。具体来说，RFF-KPKM利用RFF生成高效的低维特征映射，避免了全核矩阵的计算需求，并且为这种组合提供了强有力的理论保证：1）过剩风险界 $\text{O}(\text{sqrt}(k^3 / n))$；2）成员值的强大一致性；3）通过RFF维度 $\text{poly}(\frac{1}{\text{epsilon} \times \text{log} k})$ 实现 $(1 + \text{epsilon})$ 相对误差界。此外，为了增强鲁棒性和处理多核的能力，本文还提出了IP-RFF-MKPKM，这是一种基于RFF的可能性方法处理多重核幂次K均值。IP-RFF-MKPKM 通过结合可能性成员资格和模糊成员资格的优点保证了MKPKM 的可扩展性，并精细化聚类分配。", "conclusion": "在大规模数据集上的实验结果表明，本文提出的方法在效率和聚类精度方面显著优于现有技术。"}
{"llm_update_time": "20251116", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.10465", "html_url": "https://arxiv.org/abs/2511.10465", "title": "超越引出：知识密集型任务的供应基础提示优化", "title_en": "Beyond Elicitation: Provision-based Prompt Optimization for Knowledge-Intensive Tasks", "authors": "Yunzhe Xu,Zhuosheng Zhang,Zhe Liu", "background": "尽管提示优化已成为提升语言模型性能的关键技术，但现有方法主要集中在基于引出的策略上，这些策略旨在寻找最优提示以激活模型的功能。然而，这些方法在处理知识密集型任务时存在根本性的局限性，因为它们局限于固定的参数边界，而不是提供专门领域所需的事实知识、术语精确性和推理模式。", "innovation": "提出了一种名为Knowledge-Provision-based Prompt Optimization (KPPO)的新框架，将提示优化重新定义为系统性的知识整合而不是潜在的引出。KPPO包含以下三个关键创新：1) 知识缺口填充机制，用于识别和针对性地弥补知识缺口；2) 批处理候选评估方法，既考虑性能提升也考虑分布稳定性；3) 自适应知识修剪策略，平衡性能和令牌效率，降低高达29%的令牌使用量。", "conclusion": "广泛评估显示KPPO在15个来自不同领域的知识密集型基准测试中优于基于引出的方法，平均性能提升约6%，同时实现可比或更低的令牌消耗。"}
{"llm_update_time": "20251116", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.10480", "html_url": "https://arxiv.org/abs/2511.10480", "title": "通过符号张量图实现分布式大语言模型工作负载的可扩展合成", "title_en": "Scalable Synthesis of distributed LLM workloads through Symbolic Tensor Graphs", "authors": "Changhai Man,Joongun Park,Hanjiang Wu,Huan Xu,Srinivas Sridharan,Tushar Krishna", "background": "优化大规模语言模型（LLMs）在大规模AI训练和推理系统中的性能需要一种可扩展且表达能力强的机制来建模分布式工作负载执行。这种建模对于预部署系统级优化（例如并行化策略）和设计空间探索至关重要。虽然最近的努力已经提出了从真实系统收集执行跟踪的方法，但访问大规模基础设施仍然局限于主要云提供商。此外，现有平台获得的跟踪数据无法轻松适应研究未来更大规模的系统配置。因此，需要一种新的方法来生成高保真度的执行跟踪以准确建模LLM工作负载，同时支持广泛的并行化策略，以系统地探索LLM架构和系统配置。", "innovation": "本文引入了STAGE（Symbolic Tensor grAph GEnerator），这是一种框架，能够合成高保真度的执行跟踪，以准确建模LLM工作负载。STAGE支持全面的并行化策略，允许用户系统地探索广泛的LLM架构和系统配置。STAGE通过合成超过32K GPU的高保真度LLM跟踪并保持计算、内存和通信的张量级精度，证明了其可扩展性。", "conclusion": "STAGE将公开提供，以促进分布式机器学习系统的进一步研究。"}
{"llm_update_time": "20251116", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.10459", "html_url": "https://arxiv.org/abs/2511.10459", "title": "LocalBench: 在县级本地知识和推理方面评估大型语言模型", "title_en": "LocalBench: Benchmarking LLMs on County-Level Local Knowledge and Reasoning", "authors": "Zihan Gao,Yifei Xu,Jacob Thebault-Spieker", "background": "大型语言模型（LLMs）在宏观地理任务上已有广泛应用，如全球事实记忆、事件总结和区域推理。然而，它们处理超本地知识的能力仍然不甚了解。随着城市平台、社区新闻等实际应用需求增长，AI系统需要具有关于邻里特有动态、文化叙事和地方治理的推理能力。现有的基准测试尚不能全面捕捉这种复杂性，多依赖粗粒度数据或孤立引用。因此，研究者提出了LocalBench，首个跨526个美国县（49个州）评估县级本地知识的基准测试，涵盖物理、认知和关系维度，引入了多样化的数据来源。", "innovation": "LocalBench 是首个系统性评估 LLMs 在县级本地知识上的基准测试。该研究使用 Localness 概念化框架，包括14,782个问答对，涵盖49个州的526个县。相比现有基准测试，LocalBench 更加细致地捕捉了地方的复杂性，并在物理、认知和关系三个维度上进行了评估。此外，研究使用 LocalBench 对13种最新 LLM 进行了封闭测试和网络增强测试，发现了多项关键限制，甚至表现最好的模型，在叙事型问题上的准确率也仅有56.8%，在数字推理上的准确率更低，只有15.5%。即便如此，更大的模型规模和网络增强也不一定能带来更好的性能。", "conclusion": "研究结果强调了本地理解的地方差异性和细微特征。研究认为，构建支持公平性和地方意识的AI系统至关重要，这些系统能够处理跨地理和文化背景的多样化、精细化的地方现实。"}
{"llm_update_time": "20251116", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.10515", "html_url": "https://arxiv.org/abs/2511.10515", "title": "LOCA-R：在2025年中国物理奥赛上的近乎完美表现", "title_en": "LOCA-R: Near-Perfect Performance on the Chinese Physics Olympiad 2025", "authors": "Dong-Shan Jian,Xiang Li,Chen-Xu Yan,Hui-Wen Zheng,Zhi-Zhang Bian,You-Le Fang,Sheng-Qi Zhang,Bing-Rui Gong,Ren-Xi He,Jing-Tian Zhang,Ce Meng,Yan-Qing Ma", "background": "高级别的物理问题解决对于人类和人工智能（AI）来说都是一个重大挑战，因为它需要精确计算、抽象推理以及对物理原理的深刻理解。中国物理奥林匹克竞赛以其复杂性和深度而闻名，是测试这些高级能力的理想平台。", "innovation": "引入了LOCA-R（逻辑链增强推理）框架的改进版本，该框架针对复杂推理进行了适配，并将其应用于2025年中国物理奥林匹克竞赛的理论考试中。LOCA-R获得313分中的满分320分，超过了最高分的人类竞争对手，并显著超过了所有基线方法的表现。", "conclusion": "LOCA-R在面对中国物理奥林匹克竞赛的复杂问题时，表现出了卓越的推理能力，实现了近乎完美的成绩，证明了其在高级问题解决任务上的强大能力。"}
{"llm_update_time": "20251116", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.10555", "html_url": "https://arxiv.org/abs/2511.10555", "title": "一码一风格：通过离散风格空间解锁代码到风格图像生成", "title_en": "A Style is Worth One Code: Unlocking Code-to-Style Image Generation with Discrete Style Space", "authors": "Huijie Liu,Shuhao Cui,Haoxiang Cao,Shuai Ma,Kai Wu,Guoliang Kang", "background": "视觉风格化是艺术创作的基础，但生成新颖且具一致性的视觉风格仍然是一个挑战。现有生成方法通常依赖于较长的文本提示、参考图像或参数高效的微调来引导风格感知图像生成，但难以保持风格一致性、创意有限且风格表示复杂。", "innovation": "作者提出了一个新的任务：代码到风格图像生成，并首次提出了名为CoTyle的开源方法。通过训练离散风格代码本以及利用文本到图像扩散模型（T2I-DM），该方法能够根据一个数值风格代码生成具有新颖且一致视觉风格的图像。这种方法简化了风格控制过程，使得少量输入即可生成大量可复现的风格。", "conclusion": "大量的实验验证了CoTyle的有效性，展示了通过一个数值代码可以转化为一个风格控制器，证明了一种风格仅需一个代码的观点。"}
{"llm_update_time": "20251116", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.10543", "html_url": "https://arxiv.org/abs/2511.10543", "title": "从欧拉到今天：数学中的普遍谬误——ArXiv论文中错误的大规模计算分析", "title_en": "From Euler to Today: Universal Mathematical Fallibility A Large-Scale Computational Analysis of Errors in ArXiv Papers", "authors": "Igor Rivin", "background": "该研究表明，通过对ArXiv数据库中数学论文的大型计算分析，可以发现并评估数学错误及其分布情况。研究系统地处理了跨多个数学领域超过37,000篇论文，揭示了不同领域的错误率和质量分布，并证明了自动分析方法可以识别出跨越三个世纪的数学错误，包括欧拉和狄利克雷的作品，以及当代菲尔兹奖得主的论文。", "innovation": "提出了一个全自动分析系统，不仅能够检测数学错误，还可以生成完整的审稿报告并推荐期刊层次。该系统处理的论文数量超过37,000篇，涵盖了多个数学领域，识别出显著的错误率和质量分布，并特别指出某些研究领域如范畴论的错误率为零，表明这些结果更易于自动化分析。", "conclusion": "研究显示数学错误在所有时代普遍存在，并且大规模自动化的数学同行评议是可行的。研究方法不仅适用于数学，还可以扩展至物理、计算机科学等其他ArXiv代表的领域。这些发现强调了自动化同行评审在确保学术质量方面的重要性。"}
{"llm_update_time": "20251116", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.10532", "html_url": "https://arxiv.org/abs/2511.10532", "title": "预览、接受或丢弃？一种预测性低动量交互模式", "title_en": "Preview, Accept or Discard? A Predictive Low-Motion Interaction Paradigm", "authors": "Jose Berengueres", "background": "重复性劳损（RSI）影响了大约每五个计算机用户中的一个，并且尽管经过几十年的鼠标人体工程学设计改进，这一问题仍未得到解决。所有现有的设计仍需要精细的肢体动作来操作。本文研究了是否可以通过预测性的人工智能辅助输入来减少这种精细动作，从而用屏幕上的排序建议取代物理指针操作。研究在浏览器基础的电子邮件客户端和ISO 9241-9键盘预测任务下进行了评估，涵盖不同准确度水平的头三个选项。结果表明，与使用触摸板相比，PAD 显著减少了手部运动，同时在预测准确度接近最佳拼写检查器时，保持了类似的任务完成时间.", "innovation": "引入了一种名为 Preview Accept Discard (PAD) 的零点击交互模式，该模式允许用户预览预测的GUI目标、在一组标记的替代选项中循环浏览，并通过按键释放时间接受或拒绝选项。这种模式本质上减少了用户的精细肢体动作，同时在某些情况下保证了与触摸板操作相似的任务完成时间.", "conclusion": "在两种不同环境中，PAD 相较于使用触摸板显著减少了手部动作，并且只有在预测准确度接近最佳拼写检查器时才能与触摸板完成任务时间相当。"}
{"llm_update_time": "20251116", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.10519", "html_url": "https://arxiv.org/abs/2511.10519", "title": "使用不同方式表达：语言风格作为打破模型安全边界的方法", "title_en": "Say It Differently: Linguistic Styles as Jailbreak Vectors", "authors": "Srikant Panda,Avinash Rai", "background": "通常，大语言模型（LLMs）的稳健性会通过评估对重述或语义等效的 Jailbreak 提示的反应来衡量，但很少有研究关注语言变体作为攻击面。这项工作中，研究者系统性地研究了诸如恐惧或好奇等语言风格如何重新定义有害意图，并从对齐模型中引发不安全的响应。", "innovation": "研究者构建了包含11种不同语言风格的风格增强型Jailbreak基准，通过手工模板和LLM改写将标准数据集的提示进行转变，同时保持语义意图不变。在16个开放源代码和封闭源代码指令调优模型上的评估中发现，语言风格重塑使打破Jailbreak的成功率提高了最多57个百分点。此外，引入了一个使用辅助LLM进行预处理的步骤，该步骤通过去除操控性语言线索来减少攻击成功率，从而显著降低了打破模型安全边界的成功率。这一研究揭示了被当前安全管道忽视的系统性和扩展性抵抗的漏洞。", "conclusion": "这项研究发现了一种被当前的安全管道忽视的系统性和扩展性抗性的脆弱性，即通过不同语言风格的使用，能够有效打破模型的安全边界。为了减轻这一威胁，提出了一种去除语言操控线索的预处理步骤，这显著地降低了攻击成功率。"}
{"llm_update_time": "20251116", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.10502", "html_url": "https://arxiv.org/abs/2511.10502", "title": "主动梯度反转攻击在联邦学习中的可检测性研究", "title_en": "On the Detectability of Active Gradient Inversion Attacks in Federated Learning", "authors": "Vincenzo Carletti,Pasquale Foggia,Carlo Mazzocca,Giuseppe Parrella,Mario Vento", "background": "联邦学习（FL）的一个关键优势在于其能够在保护客户端数据隐私的前提下协同训练机器学习模型。尽管不共享私有数据提高了整体的隐私性，先前的研究表明，在FL训练过程中交换的梯度仍面临梯度反转攻击（GIAs）的风险。这些攻击能重建客户端的本地数据，从而破坏FL的隐私承诺。GIAs可以由被动服务器或恶意服务器发起。前者通过服务器行为监控梯度反转；后者通过操纵全球模型辅助数据重建。虽然这些攻击有效，但早期的方法容易被客户端检测到，限制了它们的实际应用。最近，新颖的主动GIAs出现，声称比先前的方法更隐蔽。这项工作提供了对该类新型GIAs的第一个全面分析，研究了四种最新的GIAs，并提出了基于统计上不合理的权重结构和异常损失及梯度动态的新型轻量级客户端检测技术，通过广泛评估多种配置证明了这些方法使客户端能够有效地检测主动GIAs，而无需修改FL训练协议。", "innovation": "这项工作提出了基于统计上不合理的权重结构和异常损失及梯度动态的新型轻量级客户端检测技术，首次对几种最新的GIAs进行了全面分析，增强了客户端在真实环境中的保护能力，提高了活跃GIAs的检测性。", "conclusion": "通过广泛的评估多种配置，本研究证明了提出的检测技术能够有效检测主动GIAs，且不会对FL训练协议产生额外要求，提高了联邦学习在实际应用中的安全性。"}
{"llm_update_time": "20251116", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.10484", "html_url": "https://arxiv.org/abs/2511.10484", "title": "CT影像标志中胰腺表面多叶性作为机会性筛查2型糖尿病的用途", "title_en": "Utility of Pancreas Surface Lobularity as a CT Biomarker for Opportunistic Screening of Type 2 Diabetes", "authors": "Tejas Sudharshan Mathai,Anisa V. Prasad,Xinya Wang,Praveen T.S. Balamuralikrishna,Yan Zhuang,Abhinav Suri,Jianfei Liu,Perry J. Pickhardt,Ronald M. Summers", "background": "2型糖尿病（T2DM）是一种影响全球数百万人的慢性代谢疾病。早期检测对于预防胰腺功能通过形态学变化和异位脂肪沉积的改变，以及最终导致器官损伤至关重要。尽管已有研究表明，T2DM与胰腺体积和脂肪含量有关联，但胰腺表面多叶性（PSL）在T2DM患者中的作用尚未得到充分研究。本研究旨在通过自动分割胰腺和其他腹部结构，提取CT影像生物标志物，并利用这些生物标志物机会性筛查T2DM，以填补这一研究空白。", "innovation": "本研究开发了一种全自动方法来分割胰腺和其他腹部结构，并自动检测胰腺表面多叶性（PSL）。使用了四个深度学习模型，其中一个模型（PancAP模型）在胰腺分割上的Dice分数最高（0.79 ± 0.17），ASSD误差最低（1.94 ± 2.63 mm）。基于CT影像生物标志物的多变量模型在预测T2DM方面取得了90%的AUC值，达到了66.7%的敏感性和91.9%的特异性。研究表明，PSL对于T2DM的筛查具有重要意义，并可能有助于预测T2DM的早期发生。", "conclusion": "研究表明，胰腺表面多叶性（PSL）可以作为有效的CT影像生物标志物，有助于2型糖尿病（T2DM）筛查，并可能在预测T2DM的早期发生方面发挥重要作用。该研究的结果表明，自动分割技术在生物医学影像中的应用具有重要潜力，可以帮助临床早期发现T2DM。"}
{"llm_update_time": "20251116", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.10583", "html_url": "https://arxiv.org/abs/2511.10583", "title": "使用MedGemma评估医疗指令提取中的提示策略", "title_en": "Evaluating Prompting Strategies with MedGemma for Medical Order Extraction", "authors": "Abhinand Balachandran,Bavana Durgapraveen,Gowsikkan Sikkan Sudhagar,Vidhya Varshany J S,Sriram Rajkumar", "background": "从医生-病人对话中准确提取医疗指令是减轻临床文档负担和确保患者安全的关键任务。本文详细介绍了团队在MEDIQA-OE-2025共享任务中的提交。研究了MedGemma这一新的领域特定开源语言模型在结构化指令提取中的性能，尤其是三种不同的提示 paradigm：单-shot方法、注重推理的ReAct框架和多步代理流程。实验显示，虽然复杂框架如ReAct和代理流程很有力量，但简单的单-shot提示方法在官方验证集上表现最佳。我们推测，在手动标注的转录中，复杂的推理链可能导致“过度思考”并引入噪声，从而使得直接的方法更稳健和高效。该研究为各种数据条件下临床信息提取选择合适的提示策略提供了宝贵见解。", "innovation": "本文使用MedGemma这一新的领域特定开源语言模型进行结构化指令提取研究，并系统性地评估了三种不同提示 paradigm：单-shot方法、注重推理的ReAct框架和多步代理流程。研究表明，尽管复杂的框架更强大，但简单的单-shot提示方法在验证集上表现最佳。", "conclusion": "在手动标注的数据集上，复杂的推理步骤可能引入噪声导致过度思考，因此直接的方法更稳健和高效。研究为不同的数据条件下选择合适的提示策略提供了重要指导。"}
{"llm_update_time": "20251116", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.10573", "html_url": "https://arxiv.org/abs/2511.10573", "title": "具备情感智能和责任感的强化学习", "title_en": "Towards Emotionally Intelligent and Responsible Reinforcement Learning", "authors": "Garapati Keerthana,Manik Gupta", "background": "个性化决策系统在医疗健康和行为支持中通常依赖于静态的规则基础或最大化参与的启发式方法，忽视了用户的情感背景和伦理规范。这些方法存在推荐不敏感或不安全干预措施的风险，特别是在涉及严重精神疾病、物质使用障碍或抑郁等领域的背景下。", "innovation": "提出了一种责任强化学习（RRL）框架，将情感和情境理解与伦理考虑紧密结合到顺序决策过程中。RRL将个性化问题表述为受限马尔可夫决策过程（CMDP），优化参与度和依从性的同时确保情感一致性和伦理安全。提出了一个多目标奖励函数，具体平衡了短期行为参与与长期用户福祉。此外，定义了一种情感导向的状态表示，捕捉情绪准备、情绪状态和风险的变化。该架构可以使用任何强化学习算法（例如DQN、PPO）实现，增加了安全约束或拉格朗日正则化。通过这种方式，框架在机器学习策略优化中实现了同理心和责任感，连接了安全RL、情感计算和负责任AI。", "conclusion": "这为行为健康、教育和数字化疗法等以人为中心的领域提出了伦理对齐的强化学习方法，并指出了未来基于仿真的验证路径。该论文旨在引发关于情感意识和值得信赖的个性化系统中的伦理对齐强化学习方法的理论讨论。"}
{"llm_update_time": "20251116", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.10585", "html_url": "https://arxiv.org/abs/2511.10585", "title": "在WikiRace任务中文本理解的提升", "title_en": "Textual understanding boost in the WikiRace", "authors": "Raman Ebrahimi,Sean Fuhrman,Kendrick Nguyen,Harini Gurusankar,Massimo Franceschetti", "background": "WikiRace游戏是一个玩家利用维基百科中的超链接导航文章的基准测试场景，适用于复杂信息网络中的目标导向搜索。传统的导航策略评估主要集中在基于图结构（如中介中心度）和语义意义（如语言模型嵌入）的方法上，但这两种方法在复杂信息网络中的表现不尽如人意，亟需进一步的优化探索。", "innovation": "本文系统评估了导航策略在WikiRace任务中的表现，对比了基于图结构（中介中心度）、语义意义（语言模型嵌入）以及融合方法的智能体。研究发现，仅依靠文章标题的语义相似性的贪婪策略在大型维基数据子图上的表现最为出色。结合简单的避免死循环机制后，该策略不仅实现了完美成功率，而且在导航效率上相比基于结构或混合方法的策略提高了约一个数量级。这一研究结果强调了仅依赖结构启发式的局限性，并突显了大规模语言模型在复杂信息空间中作为高效零样本语义导航器的潜力。", "conclusion": "本文研究表明，完全基于文章标题语义相似性的贪婪智能体，在避免死循环机制的支持下，能够实现很高的导航成功概率和效率。这一发现对于未来复杂信息网络中的目标导向搜索具有重要意义。"}
{"llm_update_time": "20251116", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.10628", "html_url": "https://arxiv.org/abs/2511.10628", "title": "Instella：具备卓越性能的完全开放语言模型", "title_en": "Instella: Fully Open Language Models with Stellar Performance", "authors": "Jiang Liu,Jialian Wu,Xiaodong Yu,Yusheng Su,Prakamya Mishra,Gowtham Ramesh,Sudhanshu Ranjan,Chaitanya Manem,Ximeng Sun,Ze Wang,Pratik Prabhanjan Brahma,Zicheng Liu,Emad Barsoum", "background": "大语言模型（LLMs）在各种任务中表现出色，但大多数高性能模型未保持开放源码，这限制了透明度和可复现性。鉴于此，本文介绍了Instella这一完全公开的语言模型家族。", "innovation": "Instella是在公开可用的数据和代码基础上，使用AMD Instinct MI300X GPU开发的、通过大规模预训练、通用指令微调和与人类偏好对齐的语言模型。尽管预训练使用的数据较少，但在全面开放模型中，Instella依然达到了最先进水平，并且表现出色可与同等规模的领先开源权重模型竞争。另外，还提供了两种专门变体：Instella-Long 和 Instella-Math。", "conclusion": "这些贡献使Instella成为透明、高性能和多功能的替代品，推动了开放和可复现的语言模型研究目标的实现。"}
{"llm_update_time": "20251116", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.10611", "html_url": "https://arxiv.org/abs/2511.10611", "title": "迈向网络测量研究的自主工作流", "title_en": "Towards an Agentic Workflow for Internet Measurement Research", "authors": "Alagappan Ramanathan,Eunju Kang,Dongsu Han,Sangeetha Abdu Jyothi", "background": "互联网测量研究面临访问危机：复杂的分析需要定制集成多个专业工具，这要求特定领域的专业知识。网络中断时，运营商需要快速诊断工作流程，跨越基础设施映射、路由分析和依赖建模。然而，开发这些工作流程需要特定的知识和大量的手动努力。", "innovation": "我们提出了ArachNet，这是第一个证明LLM代理可以独立生成模仿专家推理的测量工作流的系统。核心见解是测量专业知识遵循可预测的组合模式，可以通过系统自动化实现。ArachNet 通过四个专门代理模拟专家工作流程，从问题分解到解决方案实现。", "conclusion": "我们通过逐步挑战的互联网韧性场景验证了ArachNet。系统独立生成工作流与专家级推理相匹配，并产生与专家解决方案类似的数据分析输出。生成的工作流处理复杂多框架集成，传统上需要数天的手动协调。ArachNet 通过自动化专家使用的系统推理过程降低了测量工作流组成门槛，同时保持了进行研究质量分析所需的技术水平。"}
{"llm_update_time": "20251116", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.10621", "html_url": "https://arxiv.org/abs/2511.10621", "title": "SSR: 苏格拉底式自我精炼方法在大规模语言模型推理中的应用", "title_en": "SSR: Socratic Self-Refine for Large Language Model Reasoning", "authors": "Haizhou Shi,Ye Liu,Bo Pang,Zeyu Leo Liu,Hao Wang,Silvio Savarese,Caiming Xiong,Yingbo Zhou,Semih Yavuz", "background": "大规模语言模型（LLMs）展示了显著的推理能力，但现有的测试框架通常依赖粗糙的自我验证和自我修正，这限制了它们在复杂任务中的有效性。", "innovation": "本文提出了Socratic Self-Refine (SSR)，一种新的细粒度评价和精确精炼LLM推理的新框架。SSR将模型的响应分解为可验证的小问题、小答案对，通过控制重解和自我一致性检查，实现步骤级的信心估计。通过锁定不可靠的步骤并逐步精炼它们，SSR产生了更准确和可解释的推理链。实验结果显示，在五个推理基准和三种LLM上，SSR始终优于最先进的迭代自我精炼基准。此外，SSR提供了一种评估和理解LLM内部推理过程的原理性的黑盒方法。", "conclusion": "SSR在多个推理基准和模型上表现优异，提供了评估和理解LLM内部推理过程的方法，且相关代码已公开。"}
{"llm_update_time": "20251116", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.10618", "html_url": "https://arxiv.org/abs/2511.10618", "title": "知你的极限：压缩与泛化中的熵估计建模", "title_en": "Know Your Limits: Entropy Estimation Modeling for Compression and Generalization", "authors": "Benjamin L. Badger,Matthew Neligeorge", "background": "语言预测受到内在信息熵的限制，存在语言模型准确度的上限和语言压缩的有效下限。目前最先进的语言压缩算法为因果（下一个标记预测）大型语言模型，但由于计算性能的限制，这些模型不能用于形成语言熵的准确估计。过去的研究集中在如何提高语言压缩效率和模型泛化能力方面。", "innovation": "本文提出了增强编码器因果解码器模型架构，这些架构表现出更好的训练效率，并在使用较弱硬件的情况下实现了更高的压缩率。文章展示了如何在标记级别获得熵估计，并证明训练模型以接近其训练数据熵的模型必然会优于仅追求最小化损失的模型。实证研究表明，受到熵限制的因果模型在泛化能力上优于忽略熵的模型。", "conclusion": "本文证明了以接近但不超过估计的每个标记熵训练的因果模型具有更好的泛化能力，并且训练模型以便尽可能接近但不超过其训练数据熵是必要的。这为提高语言压缩算法的压缩效果和模型的泛化性能提供了一种新的方法。"}
{"llm_update_time": "20251116", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.10643", "html_url": "https://arxiv.org/abs/2511.10643", "title": "大型语言模型的黑箱在线策略蒸馏", "title_en": "Black-Box On-Policy Distillation of Large Language Models", "authors": "Tianzhu Ye,Li Dong,Zewen Chi,Xun Wu,Shaohan Huang,Furu Wei", "background": "该研究基于黑箱蒸馏技术，让学习器（学生模型）仅通过学习教师模型的文本输出，而不访问其内部权重或参数。常见的序列级知识蒸馏方法在此类场景下的效果并不理想。", "innovation": "该论文提出了一种生成对抗蒸馏（GAD）方法，它将学生模型视为生成器，并利用判别器来区分其与教师模型的响应，形成一个最小-最大博弈。判别器作为在线策略奖励模型，与学生模型共进化，提供稳定且适应性强的反馈。", "conclusion": "实验结果表明，与常用的序列级别知识蒸馏相比，GAD具有更优的表现。特别地，使用GAD训练的模型Qwen2.5-14B-Instruct在LMSYS-Chat自动评估中表现得与教师模型GPT-5-Chat相当。这证明GAD是一个有希望且有效的黑箱语言模型蒸馏范式。"}
{"llm_update_time": "20251116", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.10591", "html_url": "https://arxiv.org/abs/2511.10591", "title": "医学文本提示和元数据导向生成在皮肤病灶视觉问答中的应用", "title_en": "Mined Prompting and Metadata-Guided Generation for Wound Care Visual Question Answering", "authors": "Bavana Durgapraveen,Sornaraj Sivasankaran,Abhinand Balachandran,Sriram Rajkumar", "background": "远程护理的快速发展增加了提供者的负担，急需AI系统来帮助临床医生更高效地管理患者咨询。MEDIQA-WV 2025共享任务聚焦于生成图文相关伤口护理查询的自由文本回应，旨在解决这一挑战。", "innovation": "研究提出了两种互补的方法：一种方法是基于挖掘式提示策略，在训练数据中嵌入信息，并检索最相似的k个示例作为零样本演示；另一种方法是基于元数据剔除研究，确定了四个可提高回应质量的元数据属性，并训练分类器预测这些属性，根据预测置信度动态调整生成结果。这两种方法证明了生成相关性和临床精度的提升，为开发可靠且高效的伤口护理支持工具提供了方向。", "conclusion": "实验结果表明，基于挖掘的提示可以提高回应的相关性，而基于元数据的生成则进一步提高了临床精确度。结合这些方法，它们指出了开发能提供可靠和高效伤口护理支持的AI工具的研究方向。"}
{"llm_update_time": "20251116", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.10566", "html_url": "https://arxiv.org/abs/2511.10566", "title": "Layer Norm对Transformer中记忆化和泛化的影响", "title_en": "Impact of Layer Norm on Memorization and Generalization in Transformers", "authors": "Rishi Singhal,Jung-Eun Kim", "background": "分层规范化（LayerNorm）是Transformer的基础组件之一，它稳定了训练过程并改进了优化。最近，Pre-LayerNorm架构因其稳定的学习梯度流，成为了比Post-LayerNorm架构更受欢迎的选择。然而，LayerNorm对不同架构中学习和记忆化的影响仍有待阐明。这项研究旨在探讨LayerNorm如何影响Pre-和Post-LayerNorm架构中的记忆化和学习。我们的分析表明去除Pre-LayerNorm模型的LayerNorm参数会加剧记忆化并使学习不稳定，在Post-LayerNorm模型中，去除这些参数有效地缓解了记忆化问题。这些结果揭示了LayerNorm在不同架构中对记忆化和学习的机制差异。", "innovation": "通过对13个模型在6个视觉和语言数据集上的验证，研究发现早层的LayerNorm是特别关键的，而其影响在Pre和Post-LayerNorm模型中会有所不同。这为理解和优化Transformer的记忆化和泛化作用提供了新的视角，填补了此前领域内的认知空白，为未来的研究和实际应用提供了新的方向。", "conclusion": "消除Pre-LayerNorm模型的LayerNorm参数会加剧记忆化并阻止学习，而在Post-LayerNorm模型中，去除则可以通过恢复真实标签来有效缓解记忆化。LayerNorm在不同阶段和模型中的作用存在显著差异，早期层的LayerNorm尤为重要。这些见解对于理解和塑造Transformer中的记忆化和学习机制具有重要意义。"}
{"llm_update_time": "20251116", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2406.12163", "html_url": "https://arxiv.org/abs/2406.12163", "title": "基于讨论图语义的一阶逻辑（含等价）用于推理讨论和论证", "title_en": "Discussion Graph Semantics of First-Order Logic with Equality for Reasoning about Discussion and Argumentation", "authors": "Ryuta Arisaka", "background": "当前缺乏一个有效的形式化推理框架，能够处理各种讨论和论证模型。因此，论文提出了一种讨论图语义来形式化一阶逻辑，并结合等式，以在更广泛的范围内对人工智能中的讨论和论证进行推理。", "innovation": "论文提出了两个创新点：一是制定了一阶逻辑（含等式）的讨论图语义，能够更广泛地对人工智能中的讨论和论证进行推理；二是将Dung的扩展概念推广到论证框架中的多个图节点等效的情况。此外，通过讨论图语义，展示了这些扩展的一阶可描述性，进而提出了所有Dung扩展和可接受性语义的一阶可描述性。", "conclusion": "提出的一阶可描述性不仅适用于所有Dung的扩展，还适用于所有推广后的扩展集（可接受性语义），从而解决了当前讨论和论证模型处理的问题。"}
{"llm_update_time": "20251116", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2312.05735", "html_url": "https://arxiv.org/abs/2312.05735", "title": "深度学习在多模态对话情绪识别中的全面综述", "title_en": "A Comprehensive Survey on Multi-modal Conversational Emotion Recognition with Deep Learning", "authors": "Yuntao Shou,Tao Meng,Wei Ai,Fangze Fu,Nan Yin,Keqin Li", "background": "多模态对话情绪识别（MCER）旨在通过对话场景中的文本、语音和视觉信息来识别和跟踪说话人的情绪状态。这一研究对于情绪计算、智能推荐和人机交互等领域具有重要意义。MCER是一个比传统的单一语音或多模态情绪识别更复杂的任务，因为它需要处理更多复杂的情绪交互关系。当前，基于深度学习的MCER研究已经很广泛了，但缺乏对建模方法的系统性评述。", "innovation": "本文提供了一个全面的MCER建模方法综述，并将MCER方法大致分为四类：无上下文建模、顺序上下文建模、说话人区分建模和说话人关系建模。此外，还讨论了可用于MCER的公开流行数据集、多模态特征提取方法、应用场景、现有挑战和未来发展方向。通过此次综述，希望可以帮助MCER研究者了解当前的情绪识别研究状况，提供一些启发，并开发更高效的模型。", "conclusion": "希望此次综述能够帮助MCER研究者理解当前的研发状况，提供一些灵感，并开发更高效的模型。"}
{"llm_update_time": "20251116", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2502.10012", "html_url": "https://arxiv.org/abs/2502.10012", "title": "通过分析世界模型实现高效的车辆动力学建模", "title_en": "Unlocking Efficient Vehicle Dynamics Modeling via Analytic World Models", "authors": "Asen Nachkov,Danda Pani Paudel,Jan-Nico Zaech,Davide Scaramuzza,Luc Van Gool", "background": "不同iable模拟器将环境的动力学表示为可微函数。在机器人学和自动驾驶领域，这种特性被应用于分析性策略梯度(Analytic Policy Gradients, APG)，通过回传通过对动力学的计算来训练多任务的策略。在此基础上，本文指出，可微模拟在世界建模中也发挥着重要作用，在此可用于赋予代理预测、处方和反事实的能力。", "innovation": "本文设计了三个创新的任务设置，其中可微动力学与端到端计算图中的状态预测器结合，而未与政策结合。这种新的设置允许我们学习相对里程表、最优规划器和最优逆状态。这些预测器被称为分析性世界模型(Analytic World Models, AWM)，并通过分析性模拟来实现高效且端到端的学习。", "conclusion": "在自动驾驶场景中，AWM具有广泛的适用性，并能增强代理的决策能力，超出单纯的应激控制。同时，分析性模拟使得AWM的学习更为有效，应用更为广泛。"}
{"llm_update_time": "20251116", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.20067", "html_url": "https://arxiv.org/abs/2507.20067", "title": "PITA: Preference-Guided Inference-Time Alignment for LLM Post-Training", "title_en": "PITA: Preference-Guided Inference-Time Alignment for LLM Post-Training", "authors": "Sarat Chandra Bobbili,Ujwal Dinesha,Dheeraj Narasimha,Srinivas Shakkottai", "background": "现有后训练方法通过使用小型引导模型在推理时修改标记生成来使大规模语言模型（LLMs）的输出与终端用户偏好对齐。这些方法通常通过使用原始预训练模型作为参考策略对奖励函数进行KL正则化来优化奖励函数。然而，这些方法依赖于预训练的奖励模型，需要通过人类偏好反馈进行拟合，这可能会导致不稳定的过程。", "innovation": "本文提出了PITA，一个新颖的框架，该框架直接将偏好反馈集成到LLM的标记生成中，消除了对奖励模型的依赖。PITA学习一个小的基于偏好的引导策略，在不进行LLM微调的情况下修改推理时的标记概率，从而减少计算成本并绕过对预训练奖励模型的依赖。该框架通过随机搜索和迭代优化基于偏好的引导模型来确定潜在的偏好分布。", "conclusion": "PITA在数学推理和情感分类等不同任务上进行了评估，证明了其在对齐LLM输出与用户偏好方面的有效性。"}
{"llm_update_time": "20251116", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.23529", "html_url": "https://arxiv.org/abs/2509.23529", "title": "DOoM: 困难的数学奥林匹克", "title_en": "DOoM: Difficult Olympiads of Math", "authors": "Ilya Kuleshov,Ilin Pavel,Nikolay Kompanets,Ksenia Sycheva,Aleksandr Nikolich", "background": "该论文介绍了一个新的开源基准DOoM，旨在评估语言模型在解决俄语中的数学和物理问题的能力。基准包含了不同难度的问题，从中学到大学级别的奥林匹克和入学考试问题。", "innovation": "DOoM涵盖了不同难度层次的问题，从简单的中学任务到更复杂的大学奥林匹克和入学考试题目。通过测试各种模型并分析结果发现，模型的性能与所用的令牌数量相关，并揭示了数学和物理任务之间性能差异。", "conclusion": "研究结果表明，模型在数学和物理问题上的表现具有相关性，并且使用令牌的数量会影响模型的表现。此外，揭示了不同类型的科学任务在模型上的表现差异。"}
{"llm_update_time": "20251116", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.05888", "html_url": "https://arxiv.org/abs/2508.05888", "title": "在自我旅行中的规划代理：利用混合自我图集提高企业任务规划中的工具检索能力", "title_en": "Planning Agents on an Ego-Trip: Leveraging Hybrid Ego-Graph Ensembles for Improved Tool Retrieval in Enterprise Task Planning", "authors": "Sahil Bansal,Sai Shruthi Sistla,Aarti Arikatala,Sebastian Schreiber", "background": "当前AI代理在处理复杂用户查询并识别、规划行动时，有效选择工具的工具检索至关重要，但这一方面在文献中尚未得到充分探索。传统方法主要依赖用户查询与工具描述之间的相似性，限制了检索准确性，尤其是处理多步骤用户请求时。因此，需要一种能够捕捉工具及其功能依赖之间语义关系的方法来改善工具检索。", "innovation": "本文提出了一种基于知识图谱（KG）的工具检索框架，该框架利用1跳自我工具图的集合来建模工具之间的直接和间接连接，从而为多步骤任务提供更全面和语境化的工具选择。这种方法在内部合成数据集上进行评估，目标是六个定义的用户类别，结果表明基于工具图的方法在微观平均完全召回指标上达到了91.85%，超过了最佳非KG基础模型，特别是对于需要逐一工具组成的查询。", "conclusion": "实验结果表明，图中的结构信息提供的信号可以补充纯相似度匹配，特别适用于需要顺序工具组合的查询。这支持了我们的假设，并表明基于图的方法在多步骤任务规划中的工具检索能力得到了显著改善。"}
{"llm_update_time": "20251116", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2502.12143", "html_url": "https://arxiv.org/abs/2502.12143", "title": "小模型难以从强推理者那里学习", "title_en": "Small Models Struggle to Learn from Strong Reasoners", "authors": "Yuetai Li,Xiang Yue,Zhangchen Xu,Fengqing Jiang,Luyao Niu,Bill Yuchen Lin,Bhaskar Ramasubramanian,Radha Poovendran", "background": "大型语言模型（LLMs）在复杂的推理任务中表现出色，将其推理能力压缩到较小的模型中已有研究显示有成效。但研究发现，较小的模型（参数量≤3B）并不总是从较长的因果推理链（CoT）中获益或从较大的模型中进行蒸馏。相反，它们更擅长针对较短且更简单的推理链进行微调，这更符合它们的内在学习能力。现有的直接从大模型蒸馏策略存在局限性，因此需要一种方法来调整推理复杂性，以实现有效的推理能力转移。", "innovation": "研究提出了Mix Distillation（混合蒸馏）策略，这是一种简单而有效的策略，通过结合较长和较短的因果推理链示例，或者从较大和较小的模型中获取推理来平衡推理复杂性。实验结果表明，使用Mix Distillation策略可以显著提高小模型的推理性能，相比于单独使用数据进行训练。这一方法也强调了直接从大模型蒸馏的局限性，突显了适应推理复杂性的重要性以实现有效的推理能力转移。", "conclusion": "研究发现，小模型在直接从强推理者那里学习时存在困难，主要原因在于它们更适应较短和更简单的推理链。研究提出的Mix Distillation策略通过结合不同复杂度的推理链和模型，有效提升了小模型的推理性能，揭示了直接从大模型蒸馏的局限性，并强调了调整推理复杂性对于有效转移推理能力的重要性。"}
{"llm_update_time": "20251116", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2412.16725", "html_url": "https://arxiv.org/abs/2412.16725", "title": "通过抽象论辩增强语言模型的冲突解决能力", "title_en": "Enhancing Conflict Resolution in Language Models via Abstract Argumentation", "authors": "Zhaoqun Li,Xiaotong Fang,Chen Chen,Mengze Li,Beishui Liao", "background": "近年来，大型语言模型（LLMs）在开发类人类且引人入胜的对话系统方面取得了显著进展。但在构建共识和说服等任务中，LLMs 常常难以解决由信息不完整或不一致导致的冲突，暴露出其在实际应用中的局限性。鉴于此局限，专门用于解决问题冲突和不一致的抽象论辩框架变得尤为重要。本文旨在通过利用形式化抽象论辩来增强LLMs的冲突解决能力，将语言模型学习与符号计算相结合。为此，作者开发并整理了一个包含各种抽象论辩框架的数据集，并附有详细的论证接受性计算过程说明。随后，作者对这些数据集进行了微调，专注于抽象冲突解决任务。传统上，LLMs 通过链式思考方法进行评估，但由于缺乏透明度，它们在解决基于冲突的论证方面表现不佳。实验结果表明，过程解释在学习过程中起到了关键作用。与仅使用问答对训练的模型相比，带有解释训练的模型的泛化准确率更高。此外，利用LLMs 的自我解释能力，作者的方法提供了一种详细的方式，可以缓解神经网络通常存在的不透明性问题", "innovation": "本文通过将形式化的抽象论辩与语言模型学习相结合，提出了一种新的方法来增强LLMs的冲突解决能力。该方法包括开发和整理一个包含各种抽象论辩框架的数据集，附有详细的论证接受性计算过程说明，并专门针对抽象冲突解决任务对LLMs进行微调。", "conclusion": "本研究通过实验证明，过程解释对学习起到了重要作用。使用解释进行训练的模型在泛化准确率方面优于仅使用问答对进行训练的模型。此外，利用LLMs 的自我解释能力，作者的方法提供了一种详细的展示方式，可减少神经网络的不透明性问题。"}
{"llm_update_time": "20251116", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.01611", "html_url": "https://arxiv.org/abs/2510.01611", "title": "PsychCounsel-Bench: 评估大型语言模型的心理学智能", "title_en": "PsychCounsel-Bench: Evaluating the Psychology Intelligence of Large Language Models", "authors": "Min Zeng", "background": "大型语言模型（LLMs）已经在多个行业中展示了出色的能力，尤其是他们的生成能力。然而，它们在需要认知能力的应用中，如心理辅导，的潜力尚未得到充分开发。这项研究探讨了LLM是否能够有效地应用于心理辅导。为此，需要评估LLM是否具备足够的心理学知识，就像人类心理咨询师需要通过认证考试才能执业一样。", "innovation": "该研究引入了一个新的基准测试项目——PsychCounsel-Bench，基于美国国家心理咨询师认证考试（NCE）问题集建立。PsychCounsel-Bench 包含约2252个精心设计的单选题，涵盖了广泛的心理学子学科，可以全面评估LLM的心理咨询能力。研究结果表明，最先进的模型如GPT-4o、Llama3.3-70B和Gemma3-27B可以通过该基准测试，而一些开源小模型仍无法达到标准。", "conclusion": "前沿的LLM目前是唯一能够达到心理咨询考试标准的，这既展示了开发心理学导向的LLM的潜力，也揭示了面临的挑战。研究公开了所开发的数据集供公众使用，以便未来进一步研究。"}
{"llm_update_time": "20251116", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.14289", "html_url": "https://arxiv.org/abs/2509.14289", "title": "从能力到性能：评估LLM架构在渗透测试中的关键功能性属性", "title_en": "From Capabilities to Performance: Evaluating Key Functional Properties of LLM Architectures in Penetration Testing", "authors": "Lanxiao Huang,Daksh Dave,Tyler Cody,Peter Beling,Ming Jin", "background": "随着大型语言模型（LLMs）在自动化或增强渗透测试中的应用日益增多，其在各攻击阶段的有效性和可靠性仍然不清楚。本研究旨在全面评估多种基于LLM的代理模型，从单一代理到模块化设计，并在真实的渗透测试场景中衡量其实证性能和反复出现的失败模式。研究还通过有针对性的增强手段，分别评价了其五个核心功能能力对模块化代理性能的影响：全局情境记忆（GCM）、跨代理消息传递（IAM）、情境条件触发（CCI）、适应性规划（AP）和实时监控（RTM）。这些干预措施分别支持：(i) 环境连贯性和记忆保持能力；(ii) 组件间协调和状态管理能力；(iii) 工具使用准确性和选择性执行能力；(iv) 多步战略规划、错误检测和恢复能力；以及 (v) 实时动态响应能力。尽管某些架构本身表现出这些属性的子集，但有针对性的增强措施显著提高了模块化代理的性能，特别是在复杂、多步骤和实时渗透测试任务中更加明显。", "innovation": "该研究引入了一种全面评估方法，不仅考察了基于多个LLM的代理模型的整体性能，还通过精准的增强手段单独评价了其五个核心功能能力。这种方法有效地提高了模块化代理在复杂和实时渗透测试任务中的有效性和可靠性，并在模拟能力方面取得了显著的进步。", "conclusion": "尽管某些架构本身表现出某些功能性属性的子集，但有针对性的增强措施大幅提升了模块化代理的整体性能，特别是在复杂、多步骤和实时渗透测试任务中表现尤为显著。"}
{"llm_update_time": "20251116", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.12787", "html_url": "https://arxiv.org/abs/2510.12787", "title": "Ax-Prover: 一种数学和量子物理领域深层次推理论证智能框架", "title_en": "Ax-Prover: A Deep Reasoning Agentic Framework for Theorem Proving in Mathematics and Quantum Physics", "authors": "Benjamin Breen,Marco Del Tredici,Jacob McCarran,Javier Aspuru Mijares,Weichen Winston Yin,Kfir Sulimany,Jacob M. Taylor,Frank H. L. Koppens,Dirk Englund", "background": "目前存在多种自动定理证明系统，但这些系统通常针对特定领域，难以广泛应用于不同的科学领域。Ax-Prover作为一种多代理系统，旨在为Lean环境中的自动定理证明提供解决方案，能够解决跨多个学科领域的科学问题，并可自主或与人类专家协同工作。其核心挑战在于通过形式证明生成来实现既需要创造力又需要严格的句法严谨性。", "innovation": "Ax-Prover通过将大型语言模型（LLMs）与Lean工具集成，采用Model Context Protocol (MCP)来确保形式正确性，从而实现了这一目标。通过基于MCP的集成，Ax-Prover成功地在公共数据集和新的基准测试（涵盖抽象代数和量子理论领域）中表现出了与最先进技术的竞争力。尤其是在新的基准测试中，其表现出色，证明了跨多个科学领域的通用方法的有效性。", "conclusion": "Ax-Prover不仅能够作为自主系统表现出色，还在帮助专家数学家进行复杂密码学定理证明方面展示了其作为辅助工具的优势。这种多功能性和适应性的方法为自动化形式验证提供了一种通用的策略。"}
{"llm_update_time": "20251116", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.14240", "html_url": "https://arxiv.org/abs/2510.14240", "title": "LiveResearchBench: 一项用户为中心的实时基准测试，用于野生环境中的深度研究", "title_en": "LiveResearchBench: A Live Benchmark for User-Centric Deep Research in the Wild", "authors": "Jiayu Wang,Yifei Ming,Riya Dulepet,Qinglin Chen,Austin Xu,Zixuan Ke,Frederic Sala,Aws Albarghouthi,Caiming Xiong,Shafiq Joty", "background": "当前的基准测试未能完全满足建模深度研究系统的标准。现有的基准测试往往局限于狭小的领域，或提出模糊的问题，使得不同系统之间的比较难以公平进行。因此，需要新的基准测试来更全面地评估系统的综合信息搜集和综合能力。", "innovation": "提出了一种名为LiveResearchBench的新基准测试，包含100个专家精心策划的任务，涵盖日常生活、企业和学术界。每个任务都需要进行广泛的、实时的网络搜索和综合。此外，还引入了DeepEval，这是一个全面的内容和报告质量评估套件，包括覆盖度、呈现、引文准确性及关联性、一致性及分析深度等评估标准。这些新基准测试和评估方法提供了系统性评价的基础，使不同深度研究系统之间的比较更加公平和全面。", "conclusion": "通过使用LiveResearchBench和DeepEval，对17个前沿的深度研究系统进行了综合评估，包括单一代理网络搜索、单一代理深度研究以及多代理系统。分析结果显示了现有的强项、反复出现的失败模式以及促进可靠和洞察力驱动的深度研究所需的关键系统组件。这些发现有助于进一步完善和优化深度研究系统。"}
{"llm_update_time": "20251116", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.06471", "html_url": "https://arxiv.org/abs/2511.06471", "title": "GHOST：解决凸集图上的旅行商问题", "title_en": "GHOST: Solving the Traveling Salesman Problem on Graphs of Convex Sets", "authors": "Jingtao Tang,Hang Ma", "background": "我们研究了一种新的旅行商问题（TSP）的变体——基于凸集图（GCS）的TSP（GCS-TSP）。GCS提供了一种强大的轨迹规划表示方式，将配置空间分解为通过稀疏图连接的凸区域。在这种设置下，边的成本不是固定的，而是依赖于经过每个凸区域的具体轨迹，因此传统的TSP方法不再适用。我们需要开发新的方法来解决这个问题，因为边的成本依赖于选择的路径。", "innovation": "我们提出了一个分级框架GHOST，该框架通过结合组合路线搜索与凸轨迹优化来最优地解决GCS-TSP问题。GHOST通过一种新颖的抽象路径展开算法计算可接纳的下界，这些下界指导优先级搜索，同时避免了大量的凸优化调用。该方法证明了优化性，并提出了时间敏感场景下的有界次优变体。实验显示GHOST在简单情况下比统一的混合整数凸编程基线快数个数量级，并能处理涉及高阶连续性约束和不完整GCS的复杂轨迹规划问题。", "conclusion": "GHOST通过有效结合组合搜索和凸优化技术，在GCS环境下找到了最优解。该方法能够高效地处理具有高阶连续性和不完整GCS的复杂轨迹规划问题，同时保证了优化的正确性。"}
{"llm_update_time": "20251116", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.07994", "html_url": "https://arxiv.org/abs/2511.07994", "title": "通过路径-邻居聚合增强图神经网络的逻辑表达能力", "title_en": "Enhancing Logical Expressiveness in Graph Neural Networks via Path-Neighbor Aggregation", "authors": "Han Yu,Xiaojuan Zhao,Aiping Li,Kai Chen,Ziniu Liu,Zhichao Peng", "background": "图神经网络（GNNs）能够有效地建模图的结构信息，因此在知识图谱（KGs）推理中被广泛应用。现有研究主要集中在单关系图的表达能力上，而对于GNN在KG中的逻辑规则表达能力讨论较少。如何增强GNN的逻辑表达能力依然是关键问题。", "innovation": "本文提出了路径-邻居增强的GNN（PN-GNN），该方法通过在推理路径上聚合节点邻居嵌入来增强GNN的逻辑表达能力。该方法不仅在逻辑表达能力上比C-GNN有显著增强，而且$(k+1)$跳逻辑表达能力也优于$k$跳。", "conclusion": "理论分析和广泛实验表明，PN-GNN在不损害泛化能力的情况下增强了逻辑规则的表达能力，确保了在知识图谱推理任务中的竞争力。"}
{"llm_update_time": "20251116", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.17064", "html_url": "https://arxiv.org/abs/2510.17064", "title": "由大型语言模型和多智能体AI系统创建的脑细胞类型资源，支持协作社区注释", "title_en": "A Brain Cell Type Resource Created by Large Language Models and a Multi-Agent AI System for Collaborative Community Annotation", "authors": "Rongbin Li,Wenbo Chen,Zhao Li,Rodrigo Munoz-Castaneda,Jinbo Li,Neha S. Maurya,Arnav Solanki,Huan He,Hanwen Xing,Meaghan Ramlakhan,Zachary Wise,Nelson Johansen,Zhuhao Wu,Hua Xu,Michael Hawrylycz,W. Jim Zheng", "background": "单细胞RNA测序极大地提高了我们识别不同细胞类型及其转录本特征的能力。然而，这些特征的注释，尤其是那些涉及未充分表征的基因的情况，仍然是一个重大挑战。传统方法如基因集富集分析（GSEA）依赖于经过仔细整理的注释，在这些情况下表现不佳。大型语言模型（LLMs）提供了另一种选择，但由于难以在结构化本体中表达复杂的生物知识，因此在实际应用中也面临限制。为了解决这一问题，我们基于一种新的多代理人工智能系统，该系统将自由文本描述与本体标签相结合，实现了更准确和更具鲁棒性的基因集注释。通过集成检索增强生成（RAG），我们开发了一种稳健的代理流程，利用相关PubMed文献不断调整预测，减少幻觉并增强解释性。", "innovation": "我们提出了一种名为BRAINCELL-AID的多代理AI系统，该系统将自由文本描述与本体标签相结合，通过整合检索增强生成（RAG），利用相关的PubMed文献来改进基因集注释方法，提高了准确性，并减少了不准确的预测。我们成功地为5,322个脑细胞簇进行了注释，这些细胞簇来自BRAIN Initiative的综合小鼠脑细胞图谱，并通过该系统识别了基底节相关的细胞类型，并提供了具有神经学意义的描述。这一创新方法为社区驱动的细胞类型注释提供了一个宝贵的资源。", "conclusion": "通过采用BRAINCELL-AID，我们不仅获得了一种用于准确注释未充分表征的基因的工具，还能够更深入地理解大脑细胞功能，识别特定区域的基因共表达模式，并就此揭示基因集合的功能角色。通过这种方法，我们创建了一个宝贵的资源，为促进社区协作识别大脑特定细胞类型提供了支持。"}
{"llm_update_time": "20251116", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.07090", "html_url": "https://arxiv.org/abs/2511.07090", "title": "绿色AI：其定义、生命周期模型、硬件和测量方法的系统回顾与元分析", "title_en": "Green AI: A systematic review and meta-analysis of its definitions, lifecycle models, hardware and measurement attempts", "authors": "Marcel Rojahn,Marcus Grum", "background": "在人工智能（AI）的整个生命周期中，从硬件到开发、部署和重用，都会产生能源、碳排放、水和物质消耗等多方面的负担。虽然云服务提供商的工具可以提高透明度，但这些工具往往存在异质性，缺少水耗和价值链影响的数据，这限制了结果的可比性和可复现性。因此，需要一个综合的生命周期方法来明确各个阶段的影响，确定系统杠杆（包括硬件、放置位置、能源结构、冷却和调度），并进行跨设施、系统、设备和工作负载级别的标准化测量，来应对这些多维度的负担。本文旨在提供一个统一的操作性定义，不同于可持续AI；构建一个与生命周期评估（LCA）阶段相对应的五阶段生命周期模型；通过Plan Do Check Act (PDCA)循环和决策门控进行治理；系统化边缘云连续体中的硬件和系统级策略，以减少物质负担；并定义一个结合估算模型与直接计量的标准化测量框架，以实现可复现的、不受提供者限制的比较。通过定义、生命周期流程、硬件策略和标准化测量，本文为研究者、从业者和政策制定者提供了可操作的、基于证据的指导。", "innovation": "本文通过建立综合的生命周期方法，解决了当前工具在透明度、可比性和可复现性方面的不足；提出了一个五阶段的生命周期模型，将能源、碳排放、水和物质消耗作为首要问题；通过PDCA循环和决策门控进行治理；系统化了边缘云连续体中的策略；并定义了一个标准化的测量框架，包括估算模型与直接计量相结合，以实现可复现的、不受提供者限制的比较。这些创新有助于更好地理解并降低AI整个生命周期中的环境影响。", "conclusion": "本文提供了一个综合的定义，并为AI的生命周期过程、硬件策略和标准化测量提供了系统的指导框架，希望通过这些指导性建议，研究者、从业者和政策制定者能够更好地应对AI生命周期中的环境挑战。"}
{"llm_update_time": "20251116", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.08066", "html_url": "https://arxiv.org/abs/2511.08066", "title": "信息容量：通过文本压缩评估大语言模型的效率", "title_en": "Information Capacity: Evaluating the Efficiency of Large Language Models via Text Compression", "authors": "Cheng Yuan,Jiawei Shao,Chi Zhang,Xuelong Li", "background": "近年来，大语言模型（LLMs）取得了快速进展，并在多种应用中得到扩展，这导致计算资源的需求急剧增加。测试时扩展的广泛应用进一步加剧了模型能力与资源消耗之间的矛盾，突显了提高推理效率的重要性。然而，仍然缺乏一个能够准确反映不同模型规模和架构下LLM效率的统一度量标准。", "innovation": "本文通过将信息容量定义为基于文本压缩性能相对于计算复杂性的模型效率度量标准，创新性地提出了一个新的衡量模型效率的方法。信息容量不仅考虑了大模型能够更准确地预测下一个标记所实现的压缩增益，还在计算成本更高时获得了更高的压缩效果。实验结果表明，相同系列内的不同规模模型展现出一致的信息容量。优化信息容量指标可以提供模型系列内公平的效率比较和准确的性能预测。此外，信息容量特别引入了分词器效率的评估，这是对输入和输出标记数量都产生影响但常常被忽略的因素。作者通过在5种不同数据集上评估49个模型的信息容量，验证了分词器效率、预训练数据和专家混合架构的影响因素。", "conclusion": "该研究提供了一种新的度量标准来评估大语言模型的效率，即信息容量。它可以通过文本压缩性能相对于计算复杂性来衡量模型效率，并为不同规模和架构的模型提供了一致的空间。实验结果表明，这种新的评估方法能够公正地比较不同模型系列的效率，并对模型系列内部的性能进行准确预测。"}
{"llm_update_time": "20251116", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.07863", "html_url": "https://arxiv.org/abs/2511.07863", "title": "WaterMod: 模块化令牌排名分区用于概率平衡的大语言模型水印", "title_en": "WaterMod: Modular Token-Rank Partitioning for Probability-Balanced LLM Watermarking", "authors": "Shinwoo Park,Hyejin Park,Hyeseon Ahn,Yo-Sub Han", "background": "大型语言模型现在可以以人类水平的流畅度撰写新闻、法律分析和软件代码。同时，欧盟人工智能法案等法规要求每个合成文本都携带一个不可察觉的、可由机器验证的标记以标识来源。目前的逻辑值水印技术通过在每个解码步骤中选择一个伪随机绿色词汇并提升其逻辑值来满足这一要求，但这种方法可能会排除最可能的词汇，从而降低流畅度。WaterMod通过一种概率意识模块化规则克服了这一局限性，排序词汇表按模型概率降序排列，然后根据剩余排名对 k 取模进行分区，将相邻且因此语义相似的词汇分配到不同的类别中。这种方法确保了至少有一个高概率词汇可供采样，同时嵌入了可检测的信号。在多比特模式下，选择基于当前负载位 d 的颜色类别，从而使每次解码步骤中嵌入正好一个基于 k 的数字，从而实现精细的来源追溯。这种模块化算术同时支持二进制归因和丰富负载。实验结果表明，WaterMod 在零比特和多比特设置中均能保持强大的水印检测性能并维持生成质量，其稳健性跨越多种任务类型，包括自然语言生成、数学推理和代码合成任务。我们的代码和数据可在以下网址获得：this https URL.", "innovation": "WaterMod 通过一种模块化规则来克服逻辑值水印技术可能排除最可能词汇的局限性。首先按模型概率降序排列词汇表，然后根据剩余排名对 k 取模进行分区，将相邻且因此语义相似的词汇分配到不同的类别中，同时保持至少一个高概率词汇可用。在多比特模式下，通过每次解码步骤中嵌入正好一个基于 k 的数字来实现精细的来源追溯。这种模块化算术同时支持二进制归因和丰富负载。", "conclusion": "实验结果表明，WaterMod 在零比特和多比特设置中均能保持强大的水印检测性能并维持生成质量，其稳健性跨越多种任务类型，包括自然语言生成、数学推理和代码合成任务。"}
{"llm_update_time": "20251116", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2304.11954", "html_url": "https://arxiv.org/abs/2304.11954", "title": "Spikingformer：计算神经网络的关键基础模型", "title_en": "Spikingformer: A Key Foundation Model for Spiking Neural Networks", "authors": "Chenlin Zhou,Liutao Yu,Zhaokun Zhou,Han Zhang,Jiaqi Wang,Huihui Zhou,Zhengyu Ma,Yonghong Tian", "background": "Spiking神经网络(SNNs)因其基于事件的脉冲计算提供了节能的替代方案而备受关注。然而，现有的SNN基底(包括Spikformer和SEW ResNet)在残差连接结构中会引发非脉冲计算(整数-浮点乘法)，这增加了SNNs的能耗并使之不适合在主流的神经形态硬件上部署。", "innovation": "研究分析了SNNs中残差连接方法的脉冲驱动行为，并提出了Spikingformer，一种将MS Residual连接与Self-Attention结合的新颖SNN基底，这种方式在生物上是可实现的，可以解决Spikformer中的非脉冲计算问题，同时保持全局建模能力。Spikingformer在13个数据集上进行了评估，涵盖了大规模静态图像、神经形态数据和自然语言任务，显示了其有效性与普遍性，并为SNNs设立了关键基准。", "conclusion": "基于脉冲驱动特性和全局建模能力，Spikingformer预计将成为更加高效的通用SNN基底，为节能的人工智能提供支持。"}
{"llm_update_time": "20251116", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.08172", "html_url": "https://arxiv.org/abs/2511.08172", "title": "一种推理图形用户界面代理的高效训练管道", "title_en": "An Efficient Training Pipeline for Reasoning Graphical User Interface Agents", "authors": "Georgios Pantazopoulos,Eda B. Özyiğit", "background": "视觉接地是将自然语言查询与图像区域相关联的任务，对于能够进行推理的图形用户界面代理至关重要。当前许多方法依赖于大量且嘈杂的合成数据。本文提出了一种高效的训练管道，结合了基于模型的数据过滤和参数高效的微调，从480万合成样本中，通过识别具有挑战性的案例、移除对齐错误并选择多模态样本多样性的方式，精炼出12000个干净和多样化的实例。针对这些数据训练一个30亿参数的视觉-语言模型，在三种模式下进行训练：监督微调、增强推理的微调和按组相关策略优化的强化学习。使用精炼数据和轻量级训练策略训练的模型在ScreenSpot、Multimodal-Mind2Web和AndroidControl等基准测试中与大模型基线模型相当或超过后者。这些结果表明，合理的数据选择和稳健适应可以与大规模训练竞争，从而实现紧凑且强大的多模态推理代理能力。", "innovation": "提出了一种高效的训练管道，该管道结合了基于模型的数据过滤和参数高效的微调。通过从480万合成样本中精炼出12000个干净且多样化的实例，该方法能在更高效的前提下，通过监督微调、增强推理的微调和强化学习三种训练方式，达到甚至超越了大模型基线模型在多个基准测试中的表现。这一创新性方法不仅提高了训练效率，还证明了合理的数据选择和稳健适应能够替代大规模训练，实现较小型但功能强大的多模态推理代理。", "conclusion": "通过对数据进行精炼选择和采用轻量级训练策略，已经在多个多模态推理代理的基准测试中取得了与大模型基线相当或更好的表现。这表明了通过合理数据选择和稳健适应能够实现紧凑且高效的能力，证明了上述方法的有效性。"}
{"llm_update_time": "20251116", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2408.11062", "html_url": "https://arxiv.org/abs/2408.11062", "title": "大型语言模型下的多轮对话文本到SQL转换", "title_en": "Multi-Turn Interactions for Text-to-SQL with Large Language Models", "authors": "Guanming Xiong,Junwei Bao,Hongfei Jiang,Yang Song,Wen Zhao", "background": "尽管近年来取得了进展，现有的基于大型语言模型（LLMs）的方法在处理广泛表格的情况时仍然效率低下，难以有效应对。此外，现有的基于互动的方法缺乏逐步且可解释的SQL生成过程，也无法提供广泛应用的互动设计。", "innovation": "我们提出了一个名为Interactive-T2S的框架，通过直接与数据库进行交互来生成SQL查询。该框架包含四个通用工具，能够促进LLMs的有效且主动的信息检索。另外，我们还开发了详细的示例，展示了框架内的逐步推理过程。我们的方法在Spider和BIRD数据集及其变体上达到了高级性能。特别地，在没有先验知识的情况下，我们在BIRD排行榜上获得了最先进的结果，展示了我们方法的有效性。", "conclusion": "我们的工作通过提供逐步推理过程和有效的交互设计，显著改善了基于大型语言模型的文本到SQL转换的性能，并验证了该方法的有效性。"}
{"llm_update_time": "20251116", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2407.03646", "html_url": "https://arxiv.org/abs/2407.03646", "title": "使用在线计算工具自动提取的语法规则区分人类写作与AI生成文本", "title_en": "Differentiating between human-written and AI-generated texts using linguistic features automatically extracted from an online computational tool", "authors": "Georgios P. Georgiou", "background": "近年来，尽管对ChatGPT的研究非常广泛，但很少有研究系统地定量比较人类和人工智能生成语言之间的语言特征差异。本文旨在探讨各种语言组件在人类写作和AI生成文本中的表现，评估AI模仿人类写作的能力。研究人员使用人类撰写的论文作为基准，促使ChatGPT生成等长度的论文，并使用Open Brain AI进行分析。", "innovation": "使用在线计算工具从人类写作和AI生成的文本中自动提取语法规则，并分析这些文本在多个语言特征上的差异，包括辅音、重音、名词、动词、代词、直接宾语、介词修饰语和使用困难词汇等方面。", "conclusion": "研究结果表明，尽管AI生成的文本看起来模仿人类语言，但在多个语言特征上仍存在显著差异。这突显了集成自动化工具进行语言评估的重要性，以减少数据处理时间和劳动。同时，研究还强调了需要改进训练方法以提高AI生成更接近人类语言文本的能力。"}
{"llm_update_time": "20251116", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2410.17337", "html_url": "https://arxiv.org/abs/2410.17337", "title": "高质量多模态指令数据驱动的电子商务领域基础模型通用性增强", "title_en": "Captions Speak Louder than Images: Generalizing Foundation Models for E-commerce from High-quality Multimodal Instruction Data", "authors": "Xinyi Ling,Hanwen Du,Bo Peng,Zhihui Zhu,Xia Ning", "background": "多模态数据在电子商务应用中的潜力引起了越来越多的研究关注，但基础模型在充分利用多模态电子商务数据方面仍面临显著挑战：包括缺乏大规模、高质量的多模态基准数据集以及有效的多模态信息整合方法的不足。这限制了在电子商务应用中取得突破性的进展。", "innovation": "本文介绍了MMECInstruct，这是首个大规模、高质量的电子商务领域多模态指令数据集，以及开发了CASLIE框架来有效整合多模态信息，应用于电子商务场景。通过使用MMECInstruct对一系列电子商务应用中的多模态基础模型（CASLIE模型）进行微调并展示了显著优于现有先进基线模型的效果，同时具有强大的跨域适应性。", "conclusion": "CASLIE模型和MMECInstruct数据集已经公开发布，证明了在电子商务领域通过高质量多模态指令数据可以有效提升基础模型的通用性和性能。"}
{"llm_update_time": "20251116", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.08379", "html_url": "https://arxiv.org/abs/2511.08379", "title": "SOM Directions are Better than One: 多方向拒绝抑制在语言模型中的应用", "title_en": "SOM Directions are Better than One: Multi-Directional Refusal Suppression in Language Models", "authors": "Giorgio Piras,Raffaele Mura,Fabio Brau,Luca Oneto,Fabio Roli,Battista Biggio", "background": "拒绝行为是指让语言模型能安全地拒绝有害或不道德提示的功能性行为。随着对机制可解释性的科学兴趣增长，研究人员将拒绝行为作为模型潜在空间中的单一方向进行编码；例如，它计算为有害和无害提示表示的中心点之差。然而，新兴证据表明，在大规模语言模型（LLM）中，概念往往被编码为在高维潜在空间中的低维流形。基于这些发现，本文提出了一种新的利用自我组织映射（SOMs）提取多个拒绝方向的方法。首先证明了SOMs扩展了先前工作的均值差异技术。接着在有害提示的表示上训练SOMs来识别多个神经元。通过从每个神经元中减去无害表示的中心点，推导出一系列多个表达拒绝概念的方向。对模型内部删除多个方向进行了广泛的实验验证，结果表明这种方法不仅优于单一方向基线，而且也优于专门的反控制算法，使得拒绝表现更为有效。最后，分析了该方法的机制意义", "innovation": "本文提出了一种利用SOMs提取多个拒绝方向的新方法。该方法证明SOMs扩展了先前工作的均值差异技术，并训练SOMs来识别多个神经元。通过从每个神经元中减去无害表示的中心点，推导出多个响应拒绝概念的方向，证明该方法在整个实验验证中表现优于单一方向基线和专门的反控制算法，从而更有效地抑制拒绝行为。此外，方法还具有机制上的含义分析。这些创新为防止语言模型产生有害或不道德的响应提供了新的解决方案。", "conclusion": "该方法通过证明自我组织映射（SOMs）扩展了前人工作中的均值差异技术，并通过从有害提示表示出识别多个神经元来提取多个拒绝方向。实验验证表明，删除模型内部的多个方向比单一方向基线和专门的反控制算法更为有效，从而更有效地抑制了拒绝行为。最后，文中分析了该方法的机制意义，为防止语言模型产生有害或不道德响应提供了新的解决方案。"}
{"llm_update_time": "20251116", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.08132", "html_url": "https://arxiv.org/abs/2511.08132", "title": "阿尔茨海默病及相关痴呆症（ADRD）影响超过60岁以上人群中的五分之一，但超过一半的认知下降个体未被诊断。语音评估显示早期检测的前景，因为语音动力规划缺陷改变了声学特征（例如，音调、音色），而记忆和语言损伤导致句法和语义错误。然而，传统的手工特征或通用音频分类器进行了处理的语音处理管道通常表现出有限的性能和泛化能力。为了应对这些局限性，我们引入了SpeechCARE，这是一种利用预训练多语言声学和语言转换器模型的多模态语音处理管道，以捕捉与认知障碍相关的微妙语音相关线索。灵感来源于Experts集合模型（MoE）范式，SpeechCARE采用了一种动态融合架构，为基于转换器的声学、语言和人口统计数据分配权重，允许集成其他模态（例如，社会因素、成像），并在各种任务中增强鲁棒性。其稳健的预处理包括自动转录、大型语言模型（LLM）基于的异常检测和任务识别。基于SHAP的可解释性模块和LLM推理突显了每个模态对决策的贡献。SpeechCARE在无认知障碍、轻度认知障碍（MCI）和AD个体分类上的AUC = 0.88和F1 = 0.72，MCI检测上的AUC = 0.90和F1 = 0.62。偏差分析显示所有人群差异最小，但80岁以上成人除外。缓解技术包括过采样和加权损失。未来的工作包括部署在真实世界护理环境中（如VNS Health、哥伦比亚ADRC）和纽约市非代表性人群的EHR集成可解释性。", "title_en": "National Institute on Aging PREPARE Challenge: Early Detection of Cognitive Impairment Using Speech -- The SpeechCARE Solution", "authors": "Maryam Zolnoori,Hossein Azadmaleki,Yasaman Haghbin,Ali Zolnour,Mohammad Javad Momeni Nezhad,Sina Rashidi,Mehdi Naserian,Elyas Esmaeili,Sepehr Karimi Arpanahi", "background": "阿尔茨海默病及相关痴呆症影响超六成以上老年人群，但确诊率低。现有的语音评估方法虽有前景，但由于手工特征提取或通用音频分类器的限制，其性能和泛化能力有限。", "innovation": "引入了SpeechCARE，一种利用预训练多语言声学和语言转换器模型的多模态语音处理管道，能够捕捉与认知障碍相关的微妙线索。采用动态融合架构，为不同输入分配权重，增强任务鲁棒性。预处理包括自动转录、异常检测和任务识别。使用基于SHAP的解释性模块和LLM推理强调每个模态对决策的贡献。", "conclusion": "SpeechCARE在认知障碍分类和MCI检测上表现出优异的性能，AUC分别为0.88和0.90，F1分别为0.72和0.62。偏差分析显示少量老年人的性能有所下降，通过技术缓解措施可进一步改进。未来将在真实世界护理环境和纽约市非代表性人群中部署和集成可解释性技术。"}
{"llm_update_time": "20251116", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2410.20749", "html_url": "https://arxiv.org/abs/2410.20749", "title": "Matryoshka Pilot: 通过LLM学习驾驶黑盒LLM", "title_en": "Matryoshka Pilot: Learning to Drive Black-Box LLMs with LLMs", "authors": "Changhao Li,Yuchen Zhuang,Rushi Qiang,Haotian Sun,Hanjun Dai,Chao Zhang,Bo Dai", "background": "尽管黑盒大规模语言模型（LLM）在生成能力方面表现出色，但由于它们固有的透明度较低，限制了在推理、计划和个人化等方面的能力进一步提升。现有的改善LLM能力的方法主要依赖于领域特定的适应，这需要对可访问的模型参数进行额外训练，但这对于黑盒LLM来说是不可行的。", "innovation": "我们提出了Matryoshka Pilot（M-Pilot），一种轻量级的白盒LLM控制器，通过将复杂任务分解为一系列中间输出来指导大规模的黑盒LLM生成器。M-Pilot被训练为通过提示提供中间指导，使黑盒LLM能够适应用户的偏好，并实现可控的多轮生成和自我改进。", "conclusion": "我们的方法在多种任务上实验证明能够有效提升黑盒LLM在复杂、长期视角任务中的能力。我们的代码已公开发布。"}
{"llm_update_time": "20251116", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2410.21597", "html_url": "https://arxiv.org/abs/2410.21597", "title": "限制语言模型的范围", "title_en": "Reducing the Scope of Language Models", "authors": "David Yunis,Siyu Huo,Chulaka Gunasekara,Danish Contractor", "background": "大型语言模型（LLMs）被广泛应用于用户界面的各种应用中。尽管这些应用通常具有特定目的，如依据文档回答问题或提供编程助手，但它们需要一般性的语言理解能力。在这些应用场景中，语言模型应当仅对应于预定目的的问题进行响应，而拒绝无关或其他请求，这种限制行为我们称之为‘范围限制’。", "innovation": "本文对各种方法进行了全面的实证评估，包括提示、微调、偏好学习以及最近提出的通用适配技术‘断路器’（CB）。本研究显示了通过范围限制语言模型的可能性。作者验证了多种主题和细粒度主题下的范围限制效果。研究还包括消除无关查询的多样性、层次化应用不同技术、进行对抗性评估等。结果显示，在有助于无关查询的多样例子可用时，简单的监督微调能够取得最佳效果；但在这类多样性较低时，‘断路器’表现出色。通过依次叠加这两种方法，可以取得两者的好处。", "conclusion": "本研究旨在为如何限制LLMs的范围提供实践指南。"}
{"llm_update_time": "20251116", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2501.02409", "html_url": "https://arxiv.org/abs/2501.02409", "title": "扰动下的可解释神经ODE在基因调控网络发现中的应用", "title_en": "Interpretable Neural ODEs for Gene Regulatory Network Discovery under Perturbations", "authors": "Zaikang Lin,Sei Chang,Aaron Zweig,Minseo Kang,Elham Azizi,David A. Knowles", "background": "现代高通量生物数据集提供了大规模发现基因之间的因果图的机会。不同的可微因果图模型已被提出，用于从大规模干预数据集中推断基因调控网络（GRN），捕捉基因扰动中的因果基因调控关系。然而，现有模型在表达能力和扩展性方面存在局限性，无法处理如细胞分化等生物学过程的动态性。", "innovation": "提出了一种名为PerturbODE的新框架，结合了生物信息量丰富的神经常微分方程（neural ODEs）来建模扰动下的细胞状态轨迹，并从神经ODE的参数中推导出因果GRN。该框架在模拟和真实过表达数据集中展示了其轨迹预测和GRN推理的有效性。", "conclusion": "PerturbODE框架有效地解决了现有方法在动态性处理上的不足，并在多个数据集中表现出了强大的预测和推理能力。"}
{"llm_update_time": "20251116", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2501.11094", "html_url": "https://arxiv.org/abs/2501.11094", "title": "使用CNN-BiLSTM混合模型从社交媒体中增强自杀念头的检测", "title_en": "Enhanced Suicidal Ideation Detection from Social Media Using a CNN-BiLSTM Hybrid Model", "authors": "Mohaiminul Islam Bhuiyan,Nur Shazwani Kamarudin,Nur Hafieza Ismail", "background": "自杀念头的检测对于预防全球主要死因之一的自杀至关重要。许多人在社交媒体上表达了自杀的想法，这为通过先进的机器学习技术进行早期检测提供了重要机会。", "innovation": "该研究通过结合卷积神经网络（CNN）和双向长短期记忆网络（BiLSTM），并加入注意机制，改进了社交媒体文本中自杀念头的识别。同时，采用了解释性人工智能（XAI）方法，特别是SHapley Additive exPlanations (SHAP)，来增强模型预测的可解释性，展示了关键特征对模型预测的影响，提升了模型的透明度和可信度。", "conclusion": "这项工作强调了增强检测自杀倾向准确性和解释性的潜力，为心理健康监测系统的发展做出了重要贡献。它突出了将强大的机器学习方法与可解释性相结合的重要性，以开发可靠且具有影响力的心理健康解决方案。"}
{"llm_update_time": "20251116", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2501.14250", "html_url": "https://arxiv.org/abs/2501.14250", "title": "Siren: 基于学习的多轮攻击框架，用于模拟真实人类的逃逸行为", "title_en": "Siren: A Learning-Based Multi-Turn Attack Framework for Simulating Real-World Human Jailbreak Behaviors", "authors": "Yi Zhao,Youzhi Zhang", "background": "大型语言模型（LLMs）在现实世界的应用中被广泛使用，人们对其安全性和可信度提出了担忧。现有的检测方法主要集中在单轮攻击上，忽略了真实世界对手使用的多轮策略。现有的多轮方法依赖于静态模式或预定义的逻辑链，无法应对攻击过程中的动态策略。", "innovation": "本文提出了Siren，这是一个基于学习的多轮攻击框架，旨在模拟真实人类的逃逸行为。Siren由三个阶段组成：(1) 利用Turn-Level LLM反馈强化的MiniMax驱动训练集构建，(2) 通过监督微调(SFT)和直接偏好优化(DPO)进行训练后的攻击者，以及(3) 攻击者和目标LLM之间的交互。实验结果表明，使用Siren攻击，攻击成功率(ASR)在与Gemini-1.5-Pro目标模型对战时达到90%，与GPT-4o目标模型对战时达到70%，显著优于单轮基线。此外，Siren使用7B规模模型实现的性能与利用GPT-4o攻击的多轮基线相当，但在轮数更少且更符合攻击目标的语义分解策略方面表现出色。", "conclusion": "我们希望Siren可以为在现实场景中应对先进的多轮逃逸攻击提供更强的防御。我们提供了一个代码库。请注意，本文包含可能有害的文字。"}
{"llm_update_time": "20251116", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2502.18573", "html_url": "https://arxiv.org/abs/2502.18573", "title": "FactReasoner：大型语言模型长文本事实性评估的概率方法", "title_en": "FactReasoner: A Probabilistic Approach to Long-Form Factuality Assessment for Large Language Models", "authors": "Radu Marinescu,Debarun Bhattacharjya,Junkyu Lee,Tigran Tchrakian,Javier Carnerero Cano,Yufang Hou,Elizabeth Daly,Alessandra Pascale", "background": "现有的大型语言模型（LLMs）在生成任务中取得了显著进展，但是它们往往无法保证输出的准确性，这限制了它们在需要正确性的实际应用场景中的可靠性。这种局限性使人们关注改善LLMs生成内容的准确性问题。本文提出了一个名为FactReasoner的创新性框架，它使用概率推理来评估长文生成响应的真实性。", "innovation": "FactReasoner框架通过将响应分解为原子单元，并从外部知识源检索相关背景信息，然后使用概率编码来建模这些原子单元与其背景之间的逻辑关系（如蕴含、矛盾），从而评估响应的真实性。它估计每个原子单元被检索到的证据支持的概率。实验表明，FactReasoner在事实性精确度和召回率方面优于基于提示的最新方法。", "conclusion": "FactReasoner框架在处理长文本事实性评估方面表现出色，并且其开源实现已经公开。"}
{"llm_update_time": "20251116", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2501.18638", "html_url": "https://arxiv.org/abs/2501.18638", "title": "Graph of Attacks with Pruning: Optimizing Stealthy Jailbreak Prompt Generation for Enhanced LLM Content Moderation", "title_en": "Graph of Attacks with Pruning: Optimizing Stealthy Jailbreak Prompt Generation for Enhanced LLM Content Moderation", "authors": "Daniel Schwartz,Dmitriy Bespalov,Zhe Wang,Ninad Kulkarni,Yanjun Qi", "background": "随着大规模语言模型（LLMs）的应用越来越广泛，确保这些模型在对抗恶意使用的鲁棒性变得至关重要。现有的树状结构LMLM劫持攻击方法存在局限性，因此需要新的方法来提高评估和增强LLM防护措施的效果。", "innovation": "本文介绍了一种名为GAP（Graph of Attacks with Pruning）的先进框架，用于生成隐蔽的劫持提示，以评估和增强LLM的安全防护。GAP通过使用相互连接的图结构，使攻击路径之间的知识共享成为可能，从而克服了现有树状方法的局限性。实验结果表明，GAP在攻击成功率和降低成本方面优于现有技术，且能有效应对开放和封闭LLM攻击。此外，还提出了GAP-Auto和GAP-VLM等专有变体，以实现自动化种子生成和多模态攻击。GAP生成的提示在内容审核系统中效果显著，提升了真实正样本的检测率和准确率。", "conclusion": "GAP框架通过使用图结构有效地生成隐蔽的劫持提示，在攻击成功率和成本效益方面优于现有技术，显著提升了LLM的内容审核系统的效果。"}
{"llm_update_time": "20251116", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2503.02034", "html_url": "https://arxiv.org/abs/2503.02034", "title": "Abn-BLIP: 异常对齐的引导式语言-图像预训练方法在CTPA肺栓塞诊断和报告生成中的应用", "title_en": "Abn-BLIP: Abnormality-aligned Bootstrapping Language-Image Pre-training for Pulmonary Embolism Diagnosis and Report Generation from CTPA", "authors": "Zhusi Zhong,Yuli Wang,Lulu Bi,Zhuoqi Ma,Sun Ho Ahn,Christopher J. Mullin,Colin F. Greineder,Michael K. Atalay,Scott Collins,Grayson L. Baird,Cheng Ting Lin,Webster Stayman,Todd M. Kolb,Ihab Kamel,Harrison X. Bai,Zhicheng Jiao", "background": "医学影像在现代医疗中发挥着关键作用，而CT肺动脉造影（CTPA）是诊断肺栓塞和胸腔其他状况的重要工具。然而，CTPA图像解读的复杂性和生成准确放射报告依然是巨大挑战。", "innovation": "该论文提出了Abn-BLIP（异常对齐的引导式语言-图像预训练）模型，这是一种先进的诊断模型，通过可学习的查询和跨模态注意力机制，提高了检测异常、降低遗漏发现和生成结构化报告的能力。与现有方法相比，Abn-BLIP在准确性和临床相关性方面均表现优于最先进的医学视觉-语言模型及3D报告生成方法。", "conclusion": "研究结果表明，采用多模态学习策略可以提高放射报告的准确性。研究提供的源代码可参考此处：this https URL."}
{"llm_update_time": "20251116", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2502.09125", "html_url": "https://arxiv.org/abs/2502.09125", "title": "增强的基于类信息的结构化Lasso剪枝", "title_en": "Enhanced Structured Lasso Pruning with Class-wise Information", "authors": "Xiang Liu,Mingchen Li,Xia Li,Leigang Qu,Guangsu Wang,Zifan Peng,Yijun Song,Zemin Liu,Linshan Jiang,Jialin Li", "background": "现代应用程序需要轻量级的神经网络模型。现有的大多数神经网络剪枝方法主要集中在移除不重要的滤波器，但这种方法可能导致在剪枝后由于忽视类别的具体信息而导致统计信息丢失。本文提出了一种新的剪枝方案，该方案从利用精确的类别相关信息的角度出发，考虑了类别的结构化联系，并运用信息瓶颈理论进行了指导，以确保剪枝前后统计信息的保留。", "innovation": "本文提出了一种基于结构化Lasso和信息瓶颈理论的剪枝方案。通过提出两种新的自适应网络剪枝方案：稀疏图结构Lasso剪枝与信息瓶颈(sGLP-IB)和稀疏树引导Lasso剪枝与信息瓶颈(sTLP-IB)，增加了精确的结构化类别相关性，相较于多种现有最先进的方法，本方案在三个数据集和六种模型结构上取得了最佳性能。在广泛的实验中，这些方法在减少模型参数和计算资源使用的同时，保持了准确性.", "conclusion": "综上所述，本文成功地降低了模型大小和计算资源的使用，同时保持了准确性的效果。例如，基于CIFAR-10数据集的VGG16模型，我们能够减少85%的参数，减少61%的FLOPs，同时保持94.10%的准确率（比原版高0.14%）。对于大规模的ImageNet，使用ResNet架构，我们可以减少55%的参数，保持76.12%的准确率（仅下降0.03%）."}
{"llm_update_time": "20251116", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2502.13595", "html_url": "https://arxiv.org/abs/2502.13595", "title": "MMTEB: 巨型多语言文本嵌入基准", "title_en": "MMTEB: Massive Multilingual Text Embedding Benchmark", "authors": "Kenneth Enevoldsen,Isaac Chung,Imene Kerboua,Márton Kardos,Ashwin Mathur,David Stap,Jay Gala,Wissam Siblini,Dominik Krzemiński,Genta Indra Winata,Saba Sturua,Saiteja Utpala,Mathieu Ciancone,Marion Schaeffer,Gabriel Sequeira,Diganta Misra,Shreeya Dhakal,Jonathan Rystrøm,Roman Solomatin,Ömer Çağatan,Akash Kundu,Martin Bernstorff,Shitao Xiao,Akshita Sukhlecha,Bhavish Pahwa,Rafał Poświata,Kranthi Kiran GV,Shawon Ashraf,Daniel Auras,Björn Plüster,Jan Philipp Harries,Loïc Magne,Isabelle Mohr,Mariya Hendriksen,Dawei Zhu,Hippolyte Gisserot-Boukhlef,Tom Aarsen,Jan Kostkan,Konrad Wojtasik,Taemin Lee,Marek Šuppa,Crystina Zhang,Roberta Rocca,Mohammed Hamdy,Andrianos Michail,John Yang,Manuel Faysse,Aleksei Vatolin,Nandan Thakur,Manan Dey,Dipam Vasani,Pranjal Chitale,Simone Tedeschi,Nguyen Tai,Artem Snegirev,Michael Günther,Mengzhou Xia,Weijia Shi,Xing Han Lù,Jordan Clive,Gayatri Krishnakumar,Anna Maksimova,Silvan Wehrli,Maria Tikhonova,Henil Panchal,Aleksandr Abramov,Malte Ostendorff,Zheng Liu,Simon Clematide,Lester James Miranda,Alena Fenogenova,Guangyu Song,Ruqiya Bin Safi,Wen-Ding Li,Alessia Borghini,Federico Cassano,Hongjin Su,Jimmy Lin,Howard Yen,Lasse Hansen,Sara Hooker,Chenghao Xiao,Vaibhav Adlakha,Orion Weller,Siva Reddy,Niklas Muennighoff", "background": "现有的文本嵌入通常只在有限的任务集上进行评估，这些任务集受限于语言、领域和任务多样性。旨在解决这些限制并提供更全面的评估，本文引入了大规模多语言文本嵌入基准 (MMTEB) —— MTEB 的社区驱动扩展，覆盖了超过 500 个高质量控制的评估任务，涉及 250 多种语言。MMTEB 包括多个多样且具有挑战性的新任务，如指令遵循、长文档检索和代码检索，这是迄今为止评估嵌入模型的最大规模的多语言任务集合。", "innovation": "本文开发了多个高度多语言基准，并使用 MMTEB 数据集对一系列模型进行了评估。创新之处在于发现了在大规模任务分类上表现出色的语言模型并不一定是参数量最多的，相反，具有 5.6 亿参数的 multilingual-e5-large-instruct 在所有可用多语言模型中表现最佳。此外，文章引入了一种基于任务间相关性的新颖降采样方法，确保了模型多样性的同时尽量保持性能评级。此外，还优化了检索任务，通过抽取困难的负面样本，建立了更小但有效的子集，显著降低了计算需求。", "conclusion": "本文通过 MMTEB 这一大规模多语言文本嵌入基准，评估了诸多模型在多语言环境下的表现。发现大规模语言模型在某些语言子集和任务类别上表现出色，但最佳多语言模型具有较少的参数量。文章引入的降采样与任务优化方法，使得所创建的基准显著降低了计算成本，同时保留了模型的相对性能排名。"}
{"llm_update_time": "20251116", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2503.09399", "html_url": "https://arxiv.org/abs/2503.09399", "title": "ForAug: Recombining Foregrounds and Backgrounds to Improve Vision Transformer Training with Bias Mitigation", "title_en": "ForAug: Recombining Foregrounds and Backgrounds to Improve Vision Transformer Training with Bias Mitigation", "authors": "Tobias Christian Nauen,Brian Moser,Federico Raue,Stanislav Frolov,Andreas Dengel", "background": "Transformers,尤其是Vision Transformers (ViTs)，已经在大规模图像分类中达到了最先进的性能。然而，它们往往需要大量的数据，并且可能会表现出偏见，限制了它们的鲁棒性和通用性。已有研究强调，为了解决这些问题，需要新的数据增强方案，并将常见的归纳偏置融入到训练数据中，以提高模型的性能和降低偏见。已有方法通常无法充分解决数据集中的偏差问题。", "innovation": "ForAug 提出了一种新的数据增强方案，通过使用预训练的基础模型将前景对象与不同的背景分离和重新组合，减少了数据集的偏差。这种方法可以在训练过程中对图像组成进行细粒度控制，从而增加数据多样性并提高训练样本的有效数量。实验结果表明，使用 ForAug 对 ImageNet 数据集进行预处理，可以使 ViTs 和其他架构的 ImageNet 准确性和下游任务的准确率分别提高 4.5 个百分点和 7.3 个百分点。此外，研究还引入了背景鲁棒性、前景焦点、中心偏移和大小偏移等评估模型行为和量化偏见的新指标，表明 ForAug 能够显著减少这些偏见。", "conclusion": "ForAug 提供了一种工具，用于分析和减轻偏见，从而促进更稳健和可靠的计算机视觉模型的发展。代码和数据集已公开供研究界使用。"}
{"llm_update_time": "20251116", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2503.06161", "html_url": "https://arxiv.org/abs/2503.06161", "title": "特征内镜高斯：手术变形场景重构中的特征提取高斯点图", "title_en": "Feature-EndoGaussian: Feature Distilled Gaussian Splatting in Surgical Deformable Scene Reconstruction", "authors": "Kai Li,Junhao Wang,William Han,Ding Zhao", "background": "微创手术（MIS）需要高保真、实时的视觉反馈来显示动态且纹理较少的手术场景。目前的解决方案要么受限于静态场景，要么缺乏语义集成，无法满足这些需求。因此，亟需一种既能实时重建又能进行语义分割的创新方法来支持微创手术。", "innovation": "本文提出了一种名为FeatureEndo-4DGS（FE-4DGS）的实时处理管道，利用特征提取的4D高斯点图同时进行变形手术环境的重建和语义分割。FE-4DGS的独特之处在于，它能在保持实时渲染能力的同时，利用预训练的2D语义嵌入，生成统一的4D表示，其中语义也能随着组织的移动进行变形。此外，该方法通过单一并行化的光栅化过程生成实时的RGB和语义输出。这项方法即使引入了特征提取的额外复杂性，也能维持61 FPS的实时渲染速度，实现最先进的渲染保真度，同时也提供了竞争性的语义分割性能。", "conclusion": "FE-4DGS通过结合实时处理、特征提取技术、4D高斯点图和语义分割，在确保实时性的同时提供了卓越的视觉反馈和高精度的语义信息。它在EndoNeRF和SCARED上达到了39.1和27.3的最新PSNR，并在EndoVis18的语义分割任务中与强大的2D基线匹配或超过，对于二分类任务达到0.93 DSC，对于多标签分割任务达到0.77 DSC。"}
{"llm_update_time": "20251116", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2504.03966", "html_url": "https://arxiv.org/abs/2504.03966", "title": "衔接LMS与生成式AI：通过Ask ME助手实现动态课程内容集成（DCCI）以增强学生满意度和参与度", "title_en": "Bridging LMS and generative AI: dynamic course content integration (DCCI) for enhancing student satisfaction and engagement via the ask ME assistant", "authors": "Kovan Mzwri(1),Márta Turcsányi-Szabo(2) ((1) Doctoral School of Informatics, Eötvös Loránd University, Budapest, Hungary, (2) Department of Media &amp; Educational Technology, Faculty of Informatics, Eötvös Loránd University, Budapest, Hungary)", "background": "将大型语言模型（LLMs）与学习管理系统（LMSs）集成可以提高教育中的任务自动化和访问性。然而，LLMs生成虚假或误导信息的问题仍然是一个挑战。本文探讨了如何通过动态课程内容集成（DCCI）机制，利用画布LMS中的课程内容并通过提示工程将其结构化在LLM的窗口中，从而解决这一问题。该研究通过结合自我决定理论和信息技术接受模型的混合方法，在120名奥匈李斯特大学一年级编程学生中评估了DCCI的有效性。", "innovation": "引入了动态课程内容集成（DCCI）机制，该机制能够动态检索画布LMS中的课程内容，并通过提示工程将其结构化在LLM的窗口中。这种机制使得LLM动力助手Ask ME能够提供上下文相关和课程对齐的回答，从而减少幻觉现象。研究通过结合自我决定理论和信息技术接受模型的混合方法，在120名学生中评估了DCCI的有效性，结果显示学生满意度高，并认可Ask ME在提供及时、上下文相关回答方面的有效性，提高了平台切换减少、用户体验、参与度和理解度。但也有学生表达了对过度依赖AI和师生互动减少的担忧。该研究强调了在AI驱动教育自动化中提升LLM可靠性的重要性，以及平衡的必要性。", "conclusion": "DCCI机制增强了LLM的可靠性，提高了学生满意度和参与度，在AI驱动的教育自动化中显示出潜力。然而，研究也指出需要继续关注用户对过度依赖AI和减少师生互动的担忧，以实现更有效和健康的教育技术使用。"}
{"llm_update_time": "20251116", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2505.19164", "html_url": "https://arxiv.org/abs/2505.19164", "title": "BroadGen：一种生成有效且高效的广告商广泛匹配关键词推荐框架", "title_en": "BroadGen: A Framework for Generating Effective and Efficient Advertiser Broad Match Keyphrase Recommendations", "authors": "Ashirbad Mishra,Jinyu Zhao,Soumik Dey,Hansi Wu,Binbin Li,Kamesh Madduri", "background": "在赞助搜索广告领域，关键词推荐主要集中在精确匹配类型，这种类型存在着管理成本高、目标范围有限以及搜索查询模式变化等问题。虽然广泛匹配类型可以解决某些精确匹配的问题，但它们存在特定的挑战，如针对性不精确且由于广告商使用的限制，监督信号较少。", "innovation": "该研究定义了理想广泛匹配的标准，强调效率和效果，并提出了一种名为BroadGen的创新框架，通过利用历史搜索查询数据推荐有效且高效的广泛匹配关键词。BroadGen通过标记对应建模，确保了查询稳定性。该框架每天能够为eBay上的数百万卖家推荐超过25亿个项目的广泛匹配关键词。", "conclusion": "BroadGen能够有效且高效地生成广泛匹配关键词推荐，通过利用历史数据提高匹配准确性和稳定性，适用于大规模广告商和商品管理需求。"}
{"llm_update_time": "20251116", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2505.00787", "html_url": "https://arxiv.org/abs/2505.00787", "title": "构建Option Keyboard的理想行为基底", "title_en": "Constructing an Optimal Behavior Basis for the Option Keyboard", "authors": "Lucas N. Alegre,Ana L. C. Bazzan,André Barreto,Bruno C. da Silva", "background": "多任务强化学习旨在通过最少或不需要额外与环境交互来快速识别新任务的解决方案。Generalized Policy Improvement (GPI) 是一种结合一组基础策略来产生至少和其中任何一个基策略一样好的新策略的技术。为了确保最优性，在线性奖励情况下，可以通过计算凸覆盖集 (CCS) 的方法实现，但这些方法计算成本高且难以扩展到复杂领域。Option Keyboard (OK) 改进了 GPI 的方法，通过一个从基础策略Learned Meta-Policy动态组合基础策略。但其性能依赖于基础策略的选择。此问题引出了一个关键问题：是否存在一种理想的行为基底，能够零样本地识别任何线性任务的最优解决方案？", "innovation": "本文通过引入一种新型方法，高效构建理想行为基底。这种方法显著降低了需要的基础策略的数量，以确保在新的任务中达到最优性。此外，这种新方法的表达能力相比于CCS更具有优势，能够求解特定类型的非线性任务的最优解。通过在复杂领域中进行实验评估，该技术在挑战性环境中超越了最先进的方法，特别是在任务复杂性增加时表现更为突出。", "conclusion": "文章解决了构建理想行为基底这一开放问题，并证明了该方法在新的任务中能更高效地确保策略最优。这种方法不仅减少了基础策略数量，还增强了在非线性任务上的表达能力，显著提升了多任务设置下的性能。"}
{"llm_update_time": "20251116", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2505.06347", "html_url": "https://arxiv.org/abs/2505.06347", "title": "通过大型语言模型驱动发现的可扩展量子态准备", "title_en": "Scalable Quantum State Preparation via Large-Language-Model-Driven Discovery", "authors": "Qing-Hong Cao,Zong-Yue Hou,Ying-Ying Li,Xiaohui Liu,Zhuo-Yang Song,Liang-Qi Zhang,Shutao Zhang,Ke Zhao", "background": "在第一性原理量子模拟动力学时，尤其是在量子场理论中，由于希尔伯特空间是固有无限维的，高效量子态制备一直是一个核心挑战。", "innovation": "提出了一个基于大型语言模型（LLM）的量子电路设计框架，该框架可系统地扩展态制备电路到大型晶格体积中。通过在1+1维XY自旋链模型上的应用，LLM自主发现了一个4参数电路，能够以亚百分比的能量偏差捕获边界效应引起的对称性破缺，并成功在Zuchongzhi量子处理器上验证。该框架还被扩展到2+1维量子场理论中，通过搜索，发现了一个保持对称性的3参数浅深度的变分方法，并且优化的参数在$ n \times n \times n \times \text{（晶体大小的）}$晶格 $n \times n \times n \times \text{（晶体大小的）} \times n \text{（} \times n \times n \times \text{（晶体大小的）} $中收敛到常数值，这是首次为这类2+1维模型提供一个可扩展的变分方法。", "conclusion": "这些结果确立了一条实用的道路，将AI辅助、人机协作的量子模拟发现转变为实际应用。"}
{"llm_update_time": "20251116", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2505.11881", "html_url": "https://arxiv.org/abs/2505.11881", "title": "重访残差连接：稳定且高效的深度网络的正交更新", "title_en": "Revisiting Residual Connections: Orthogonal Updates for Stable and Efficient Deep Networks", "authors": "Giyeong Oh,Woohyun Cho,Siyeol Kim,Suhwan Choi,Youngjae Yu", "background": "残差连接对于深层神经网络至关重要，它们通过减轻梯度消失问题来增加网络的深度。然而，在标准的残差更新中，模块的输出直接加到输入流中，这可能导致更新主要强化或调整现有的流向，从而可能未能充分利用模块学习全新特征的能力。", "innovation": "作者提出了一种新的正交残差更新方法：将模块的输出相对于输入流进行分解，仅添加正交于该流的部分。这种方法旨在引导模块主要贡献新的表示方向，从而促进更丰富的特征学习，并促进更加有效的训练。实验结果表明，该正交更新策略在不同架构（ResNetV2、视觉变换器）和数据集（CIFARs、TinyImageNet、ImageNet-1k）上提高了泛化准确性和训练稳定性，例如在ImageNet-1k上ViT-B模型取得了3.78个百分点的top-1精度增益。", "conclusion": "该工作通过引入正交残差更新策略，增强了深度网络的训练稳定性和效率，证明了在各种网络和数据集上的广泛适用性和改进效果。"}
{"llm_update_time": "20251116", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.00400", "html_url": "https://arxiv.org/abs/2506.00400", "title": "基于采样动量的文本梯度扩展", "title_en": "Scaling Textual Gradients via Sampling-Based Momentum", "authors": "Zixin Ding,Junyuan Hong,Jiachen T. Wang,Zinan Lin,Li Yin,Meng Liu,Zhangyang Wang,Yuxin Chen", "background": "基于大规模语言模型（LLM）的指令优化方法，通过利用LLM提供的“文本梯度”（反馈）来细化指令，已经成为自动指令工程的有效手段。但是，当使用更多数据进行训练时，其扩展性和稳定性尚不明确。本文系统地探讨了在文本梯度下降中扩展训练数据的潜力和挑战。", "innovation": "本文提出了基于采样动量的文本 stochastic 梯度下降方法（TSGD-M），该方法通过动量采样重新加权更新，使用Bootstrap minibatch验证准确率作为历史指令的重要性权重。此外，引入了Gumbel-Top-$k$采样策略以平衡探索-利用，提高了采样效率并保持了低方差的运行均值估计。", "conclusion": "TSGD-M无缝集成到现有的指令优化框架中，包括TextGrad、DSPy-COPRO和AdalFlow，并在5个基准测试中实现了一致的收益。我们的研究强调了在基于文本梯度优化中整合概率探索的重要性，为更稳定和可扩展的指令优化铺平了道路。"}
{"llm_update_time": "20251116", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2505.01892", "html_url": "https://arxiv.org/abs/2505.01892", "title": "OODTE：ONNX优化器的差异测试引擎", "title_en": "OODTE: A Differential Testing Engine for the ONNX Optimizer", "authors": "Nikolaos Louloudakis,Ajitha Rajan", "background": "ONNX优化器是在GitHub上拥有超过760颗星，并且是官方ONNX存储库的一部分，是应用图优化到ONNX模型的默认工具。尽管其使用广泛，但其在优化过程中保持模型准确性的能力尚未进行彻底调查。因此，需要一个工具来自动并且全面地评估ONNX优化器的正确性，这就是本文提出的ODDTE的作用。", "innovation": "ODDTE利用了直接且强大的差异测试和评估方法，可以被其他编译优化器轻松采用。具体地，ODDTE接受集合的ONNX模型，应用优化程序，并在整个用户定义的输入集中执行原始和优化版本，自动捕获优化过程中遇到的问题。当准确性出现差异时，ODDTE通过精细化的过程逐个隔离有问题的优化进程。ODDTE不仅适用与ONNX生态系统，同时也能够用于其他AI模型优化器的验证过程。", "conclusion": "ODDTE在官方ONNX模型库中的130个已知模型上进行了应用，发现了15个问题，其中14个是新发现的，并影响了9个优化进程和整个优化器。大多数与文本相关任务的模型对优化具有较强的鲁棒性，但在分类、目标检测和语义分割任务中，30%的分类模型和16.6%的目标检测和分割模型在原始和优化版本上存在输出差异。ODDTE提供了一个简化且有效的框架，用于验证AI模型优化器，并不仅局限于ONNX生态系统。"}
{"llm_update_time": "20251116", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.01939", "html_url": "https://arxiv.org/abs/2506.01939", "title": "超越80/20规则：高熵少数标记驱动有效的LLM推理强化学习", "title_en": "Beyond the 80/20 Rule: High-Entropy Minority Tokens Drive Effective Reinforcement Learning for LLM Reasoning", "authors": "Shenzhi Wang,Le Yu,Chang Gao,Chujie Zheng,Shixuan Liu,Rui Lu,Kai Dang,Xionghui Chen,Jianxin Yang,Zhenru Zhang,Yuqiong Liu,An Yang,Andrew Zhao,Yang Yue,Shiji Song,Bowen Yu,Gao Huang,Junyang Lin", "background": "强化学习具有验证奖励（RLVR）的方法已经在增强大型语言模型（LLMs）的推理能力方面显示出强大的潜力，但其机理尚未完全被理解。本文通过探索标记熵模式来探讨RLVR，分析不同标记如何影响推理性能。", "innovation": "通过观察标记熵模式在Chain-of-Thought（CoT）推理中的表现，研究发现只有少量高熵标记起关键作用；RLVR主要调整高熵标记的熵，并通过限制策略梯度更新到关键的高熵标记来改进RLVR，同时发现使用20%的高熵标记可保持与全梯度更新相同的效果，并在Qwen3-8B、Qwen3-32B和Qwen3-14B等模型上显著超越全梯度更新，展示了高熵标记的强大影响力和扩展趋势。", "conclusion": "本文结果表明理解RLVR可以通过标记熵视角进行，并通过利用关键的高熵标记来优化RLVR，以进一步改善LLMs的推理能力。"}
{"llm_update_time": "20251116", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2505.21538", "html_url": "https://arxiv.org/abs/2505.21538", "title": "Caption This, Reason That: VLMs Caught in the Middle", "title_en": "Caption This, Reason That: VLMs Caught in the Middle", "authors": "Zihan Weng,Lucas Gomez,Taylor Whittington Webb,Pouya Bashivan", "background": "视觉语言模型（VLMs）在最近几年里已经取得了显著的进步，但在特定的视觉任务，比如计数和关系推理方面，它们的人类能力仍然存在差距。为了更好地理解这些模型的限制，研究者们采用了认知科学的方法，通过感知、注意力和记忆这三个关键认知维度来分析VLM的表现。使用一系列针对这些能力的任务，研究者们评估了当前最先进的VLM，包括GPT-4o。尽管某些任务上部分先进的模型已经达到了天花板水平，但在需要空间理解和选择性注意力的任务上，依然存在显著差距。研究者们还发现，这些模型在直接视觉推理方面表现较差，但在通过分析自己生成的文本描述时会有显著改善。这些实验揭示了提高VLM逻辑推理能力的重要性，甚至是在它们整体上超过人类的情况下。", "innovation": "这项研究采用了一系列认知科学的方法，比如感知、注意力和记忆来评估当前最先进的视觉语言模型（VLMs），发现这些模型在直接视觉推理方面的表现较差，但在通过分析自己生成的文本描述时会有显著改善。此外，研究还展示了通过针对复合视觉推理任务进行微调，可以显著提高核心认知能力，并且这种改进在复杂、分布外的基准测试中没有转化为大的提升。“Caption This, Reason That: VLMs Caught in the Middle”这个标题形象地描述了这些模型在特定任务上表现不佳的情况。", "conclusion": "这项研究详细的分析了VLM的认知强项和弱点，识别了同步感知和推理的关键瓶颈，并提供了一个有效且简单的解决方案。尽管微调VLM在复杂分布外的基准测试中的提升并不明显，但研究结果显示，VLM在作者数据集上的表现与这些其他基准的性能有很强的相关性。"}
{"llm_update_time": "20251116", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.14855", "html_url": "https://arxiv.org/abs/2506.14855", "title": "反馈-MPPI：通过展开差分实现快速采样基础MPC——再见低级控制器", "title_en": "Feedback-MPPI: Fast Sampling-Based MPC via Rollout Differentiation -- Adios low-level controllers", "authors": "Tommaso Belvedere(RAINBOW, IRISA),Michael Ziegltrum(UCL),Giulio Turrisi(IIT),Valerio Modugno(UCL)", "background": "模型预测路径积分(MPPI)是一种强大的采样方法，适用于复杂机器人任务，由于其处理非线性动力学和非凸成本的灵活性。然而，在实时、高频的机器人控制场景中，由于计算需求的限制，其应用受到限制。", "innovation": "本文提出了反馈-MPPI(F-MPPI)框架，通过计算源自基于黎卡提反馈的敏感性分析的局部线性反馈增益，加强了标准的MPPI，允许在不完全重新优化每个时间步的情况下，快速进行闭环校正，改善了控制性能和稳定性，特别是在复杂的机器人系统中实现了高频率操作。", "conclusion": "F-MPPI在两种机器人平台上通过模拟和实际实验得到了验证，结果表明，集成局部反馈显著提高了控制性能和稳定性，使系统能够进行高频率、高精度的控制操作，适用于复杂机器人系统。"}
{"llm_update_time": "20251116", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.19794", "html_url": "https://arxiv.org/abs/2506.19794", "title": "开放源代码的大语言模型在数据分析中为何遇到困难？一种系统性实证研究", "title_en": "Why Do Open-Source LLMs Struggle with Data Analysis? A Systematic Empirical Study", "authors": "Yuqi Zhu,Yi Zhong,Jintian Zhang,Ziheng Zhang,Shuofei Qiao,Yujie Luo,Lun Du,Da Zheng,Ningyu Zhang,Huajun Chen", "background": "大语言模型（LLMs）在自动化数据分析任务方面有巨大潜力，但开源模型在这些需要大量推理的任务中面临显著限制。本文探讨了提升开源LLMs数据分析能力的策略，通过精挑细选具有多样性和现实性的种子数据集，从数据理解、代码生成和战略规划三个核心维度评估模型行为。研究表明，战略规划的质量是决定模型性能的主要因素，交互设计和任务复杂度对推理能力有显著影响，数据质量比多样性对实现最佳性能影响更大。", "innovation": "通过分析发现三类关键点，并基于这些见解开发了一种数据合成方法，显著提高了开源LLMs在数据分析中的推理能力。同时，研究提供的代码可以在指定的网址获得。", "conclusion": "战略规划质量主导性能，交互设计和任务复杂度影响推理能力，高质量数据比多样性更关键。通过开发数据合成方法，开源LLMs的推理能力得到了显著提升。"}
{"llm_update_time": "20251116", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.09160", "html_url": "https://arxiv.org/abs/2506.09160", "title": "理解教育中的机器人类信任", "title_en": "Understanding Human-AI Trust in Education", "authors": "Griffin Pitts,Sanaz Motamedi", "background": "随着人工智能聊天机器人在教育中的集成使用，学生开始向这些系统寻求指导、反馈和信息。然而，这些聊天机器人的拟人化特征导致了信任的问题：学生是像信任人类同伴或导师那样信任它们（人类信任，通常与人际信任模型相关），还是像信任一种常规技术那样信任它们（系统信任，通常与技术信任模型相关）。这一点引发了理论上的挑战，因为人际信任模型可能导致错误地归因于人工智能人类意图和美德，而技术信任模型最初是为非社会系统设计的，因此对于对话性、类似人类的代理系统的适用性模糊不清。因此，本文旨在探讨这两种形式的信任（人类信任和系统信任）如何在比较中影响学生对人工智能聊天机器人的感知，包括感知愉悦度、信任意图、使用行为意图以及感知有用性。", "innovation": "本文利用偏最小二乘结构方程建模探讨了这两种信任形式（人类信任和系统信任）如何在比较中影响学生对人工智能聊天机器人的感知。研究发现这两种信任形式在某些方面有不同的影响效果，并指出这些信任影响学生对未来与人工智能聊天机器人的互动感知的方式，从而提出了一种新的信任类型——机器人类信任，这与人类-人类和人类-技术模型不同，强调了本领域需要建立新的理论框架。此外，研究还为培养适当校准的信任提供了一些建议，这对于人工智能的有效采用和教育影响至关重要。", "conclusion": "互动方式和感知都使与人工智能聊天机器人的互动产生了人类机器信任的独特形式，这种形式不同于人类与人类、人类与技术的模型。研究结果表明，需要新的理论框架来处理这种交互中出现的新型信任情况，实际还给出了在教育中培养适当校准信任的行为指导。"}
{"llm_update_time": "20251116", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.22837", "html_url": "https://arxiv.org/abs/2506.22837", "title": "xLSTMAD：基于xLSTM的强大异常检测方法", "title_en": "xLSTMAD: A Powerful xLSTM-based Method for Anomaly Detection", "authors": "Kamil Faber,Marcin Pietroń,Dominik Żurek,Roberto Corizzo", "background": "xLSTM是一种通过具有表现力的乘法门控和残差连接提供所需的时间容量的模型，使其在长历时预测和表示学习中表现出色。尽管xLSTM在时间序列预测、无损压缩和大规模语言建模任务中显示出成功，但由于其线性内存足迹和快速推理，它也逐渐成为Transformer的可行替代方案。尽管如此，xLSTM还没有被研究用于异常检测。", "innovation": "本文提出了xLSTMAD，这是一种全新的基于xLSTM架构的异常检测方法，专门设计用于处理多变量时间序列数据。方法中引入了两种解码器变体，一种用于预测，另一种用于重构。此外，研究了两种损失函数：均方误差（MSE）和软动态时间规整（SoftDTW），以分别考虑局部重构保真度和全局序列对齐。", "conclusion": "实验结果表明，xLSTMAD在广泛的时间序列异常检测基准（TSB-AD-M）上表现出色，超越了23种流行的异常检测基准。本文首次展示了xLSTM在异常检测中的强大建模能力，为进一步研究该领域的发展铺平了道路。"}
{"llm_update_time": "20251116", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.18925", "html_url": "https://arxiv.org/abs/2506.18925", "title": "基于视频的可解释和粒度化帕金森病手指敲击测试运动特征量化", "title_en": "Interpretable and Granular Video-Based Quantification of Motor Characteristics from the Finger Tapping Test in Parkinson Disease", "authors": "Tahereh Zarrat Ehsan,Michael Tangermann,Yağmur Güçlütürk,Bastiaan R. Bloem,Luc J. W. Evers", "background": "准确量化帕金森病（PD）的运动特征对于监测疾病进展和优化治疗策略至关重要。手指敲击测试是一种标准的运动评估方法，临床医生通过视觉评估患者的敲击表现并根据振幅、速度和不规则性给出总体严重程度评分。然而，这种主观评价存在跨评定者和评定者间的变化，无法提供敲击测试期间捕捉到的个体运动特征的见解。本文提出了一种基于计算机视觉的方法，用于从视频记录中量化PD运动特征。通过对74名帕金森病患者的数据评估，证明了基于视频的特征与四个功能缺陷相关，并进一步识别了序列效应和停顿缺陷的细微差别。为此，使用这些特征训练机器学习分类器以估计MDS-UPDRS手指敲击评分。与最新方法相比，该方法在MDS-UPDRS评分预测中的准确性更高，同时仍提供对个体手指敲击运动特征的可解释量化。", "innovation": "本文提出了一种基于计算机视觉的方法，用于从视频记录中量化PD运动特征，通过四个相关特征刻画了帕金森病的四大运动缺陷，并通过机器学习方法准确预测MDS-UPDRS评分，提升了评估的客观性和精确性，有助于临床和远程应用。", "conclusion": "提出的框架提供了一个实用的解决方案，用于客观评估PD的运动特征，可能适用于临床和远程环境。未来的工作将评估其对症状治疗和疾病进展的反应性。"}
{"llm_update_time": "20251116", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.12846", "html_url": "https://arxiv.org/abs/2506.12846", "title": "VFEFL: 通过验证功能加密保护恶意客户端的隐私联邦学习", "title_en": "VFEFL: Privacy-Preserving Federated Learning against Malicious Clients via Verifiable Functional Encryption", "authors": "Nina Cai,Jinguang Han,Weizhi Meng", "background": "联邦学习是一种有希望的分布式学习框架，可以让客户端协作训练模型而不暴露本地数据，从而保护数据隐私。然而，这也带来了新的威胁和挑战。模型反转攻击的发展使本地模型的明文传输变得不安全，而联邦学习的分布式特性使其特别容易受到由恶意客户端发起的攻击。为保护数据隐私并防止恶意客户端攻击，本文提出了一种基于验证功能加密的隐私保护联邦学习框架，无需部署不参与的双服务器设置或额外的第三方可信方。具体来说，本文提出了一种新颖的去中心化验证功能加密（DVFE）方案，能够在多维密文中验证特定关系。该方案从定义、安全性模型和安全性证明方面进行形式化处理。利用提出的DVFE方案，我们设计了一种包含新颖稳健聚合规则的隐私保护联邦学习框架VFEFL，该规则可以检测到恶意客户端，使其能够在对抗性环境中有效地训练高精度模型。最后，我们提供了对提出方案的形式分析和实验评估。结果表明，我们的方法实现了所需的隐私保护、稳健性、可验证性和准确性，同时消除了现有方法所需的不参与的双服务器设置或第三方可信方的依赖性。", "innovation": "提出了去中心化验证功能加密（DVFE）方案，能够在多维密文中验证特定关系，并设计了隐私保护联邦学习框架VFEFL，该框架包含一种新颖的稳健聚合规则以检测恶意客户端，能够在对抗性环境中有效训练高精度模型。此方案无需不参与的双服务器设置或额外的第三方可信方，能够同时保护隐私、稳健性、可验证性和准确性。", "conclusion": "本文提出的VFEFL方案，通过验证功能加密有效保护数据隐私，能够防范恶意客户端攻击，同时保证模型的高精度和稳健性，并通过正式分析和实验评估验证了方案的有效性。"}
{"llm_update_time": "20251116", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.06277", "html_url": "https://arxiv.org/abs/2507.06277", "title": "人工战争：AI 如何决定军事干预", "title_en": "The Prompt War: How AI Decides on a Military Intervention", "authors": "Maxim Chupilkin", "background": "随着AI在军事模拟和军事规划中的应用不断增加，尚未对模型中的关键驱动因素进行简单的分析。本文通过对640个情景每个情景运行100次的简易联合实验，系统性地研究了AI在军事干预决策中的行为模式。实验发现，国内支持度高以及成功的可能性大是影响AI干预决策的最主要因素。国际谴责、军事死亡、平民伤亡以及经济负面效应等成本因素虽然在统计上显著，但其影响程度约为国内支持度和胜利概率的一半。机会窗口仅在与其他因素的交互中达到统计显著性。研究结果在不同场景和不同模型（OpenAI GPT、Anthropic Claude、Google Gemini）中表现出高度一致性，表明了AI决策模式的规律性。", "innovation": "文章提出了一种简易联合实验方法，通过对640个情景每个情景运行100次，系统地研究了影响AI军事干预决策的关键因素。研究还在不同AI模型中验证了研究结果的稳健性，强调了国内支持度和成功概率的决定性影响。", "conclusion": "文章发现，国内支持度和成功概率对AI决策至关重要，而国际谴责、军事死亡、平民伤亡等成本因素的影响相对较小。机会窗口的因素仅在与其他因素交互后才具有统计显著性。实验结果在不同的AI模型中表现出高度一致性，揭示了AI决策模式的规律性。"}
{"llm_update_time": "20251116", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.14882", "html_url": "https://arxiv.org/abs/2507.14882", "title": "控制中基于软系数优化的自特定应用组件感知的结构剪枝", "title_en": "Application-Specific Component-Aware Structured Pruning of Deep Neural Networks in Control via Soft Coefficient Optimization", "authors": "Ganesh Sundaram,Jonas Ulmen,Amjad Haider,Daniel Görges", "background": "深度神经网络（DNNs）具有高度灵活性和良好的稳健性能，适合构建系统模型和高级神经网络控制器（NNCs）。然而，其复杂性和计算需求限制了其应用。为解决此问题，多个模型压缩策略已被开发，但这些策略对通用的DNNs有效，却不适用于NNCs。文章指出，Nbcs需要在缩小模型规模的同时保留关键的应用特定性能特征，并且现有的重要性度量标准在剪枝组时通常无法保护这些关键特征。因此，本文提出了一种基于软系数优化的自特定应用组件感知的DNNs结构剪枝框架", "innovation": "文章提出了一种新的框架来计算剪枝组的重要性指标，该框架不仅缩小了模型规模，还考虑了各种应用特定约束。通过评估两种方法来确定每个组的最佳剪枝系数：一种是简单的网格搜索探索，另一种是利用梯度下降优化，以平衡压缩和任务性能。实验结果表明，该方法能够有效保持应用相关的性能并实现显著的模型规模减小。", "conclusion": "方法能够在保持应用相关的性能的同时，实现显著的模型规模减小。这种方法特别适合用于控制任务中的NNCs，并可应用于两种具体场景：MNIST自编码器和时差模型预测控制（TDMPC）智能体。"}
{"llm_update_time": "20251116", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.05294", "html_url": "https://arxiv.org/abs/2508.05294", "title": "迈向具身代理人工智能：基于大规模语言模型和视觉语言模型的机器人自主与交互的回顾与分类", "title_en": "Towards Embodied Agentic AI: Review and Classification of LLM- and VLM-Driven Robot Autonomy and Interaction", "authors": "Sahar Salimpour,Lei Fu,Kajetan Rachwał,Pascal Bertrand,Kevin O'Sullivan,Robert Jakob,Farhad Keramat,Leonardo Militano,Giovanni Toffetti,Harry Edelman,Jorge Peña Queralta", "background": "大语言模型（LLMs）和视觉语言模型（VLMs）为机器人自主和人机交互提供了新的方法。同时，视觉语言行动模型（VLAs）或大型行为模型（LBMs）也增强了机器人的灵巧性和能力。本文综述了推进代理应用和发展架构的研究，包括采用GPT风格界面的初步努力以及更复杂的系统，其中AI代理作为协调者、计划者、感知执行者或通用接口发挥作用。这类代理架构使机器人能够理解自然语言指令、调用API、计划任务序列或助力操作和诊断。", "innovation": "提出了模型集成方法的分类体系，并进行了代理在当前文献中不同解决方案中角色的比较分析", "conclusion": "介绍了促进代理应用和发展架构的研究。同时强调了社区驱动项目、ROS包和工业框架，展示了新兴趋势。"}
{"llm_update_time": "20251116", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.10496", "html_url": "https://arxiv.org/abs/2507.10496", "title": "相机作为相对位置编码", "title_en": "Cameras as Relative Positional Encoding", "authors": "Ruilong Li,Brent Yi,Junchen Liu,Hang Gao,Yi Ma,Angjoo Kanazawa", "background": "在多视角计算机视觉任务中，Transformer模型越来越受欢迎，因为它们能够捕捉不同视角之间的几何关系，这对于3D感知至关重要。现有的多视角Transformer技术需要利用相机几何信息将视觉标记锚定在三维空间中，以便利用这些几何关系。现有的多视角Transformer方法通常使用标记级射线图编码或注意级相对姿态编码。然而，这些方法无法同时捕捉相机的内在和外在参数，并且在不同场景中的表现如何还需要进一步验证。", "innovation": "本文提出了Projective Positional Encoding (PRoPE) 这种新的相对编码方式，它可以捕获完整的相机视锥体信息，包括内在和外在参数作为相对位置编码。通过实验表明，基于相机的相对定位可以提高前馈新视图合成性能，并进一步通过PRoPE获得更好的结果。这种改进在不同场景中表现一致，包括共享及变化的内在参数场景，以及对于不同长度的输入序列和相机内在参数的泛化能力。进而在不同的任务，如立体深度估计和判别空间认知中得到验证，并且能够在较大的模型规模下适用。", "conclusion": "本文验证了基于相机的相对定位能够提高多视角Transformer在不同任务和不同模型规模中的表现。尤其是PRoPE这一新的相对编码方法的引入，为多视角Transformer提供了更好地处理相机几何关系的能力，从而促进了3D感知任务的发展。"}
{"llm_update_time": "20251116", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.06959", "html_url": "https://arxiv.org/abs/2508.06959", "title": "超越频率：基于空间分解视角观察细粒度视觉分类中的细微线索", "title_en": "Beyond Frequency: Seeing Subtle Cues Through the Lens of Spatial Decomposition for Fine-Grained Visual Classification", "authors": "Qin Xu,Lili Zhu,Xiaoxia Cheng,Bo Jiang", "background": "细粒度视觉分类（FGVC）的核心在于捕捉区分性和类特定的细小特征。频率分解/变换方法因其能够提取区分性线索而受到了广泛关注。但现有的频率域方法依赖于固定的基函数，缺乏适应不同图像内容的能力，难以根据不同图像的区分性要求灵活调整特征提取。", "innovation": "本文提出了一种名为Subtle-Cue Oriented Perception Engine (SCOPE)的新方法，该方法在空间域中动态提升低级细节和高级语义的表征能力，突破了固定尺度的限制，提高了多尺度融合的灵活性。SCOPE的核心在于两个模块：Subtle Detail Extractor（SDE）动态提升浅层特征中的细小细节，如边缘和纹理；Salient Semantic Refiner（SSR）从高级特征中学习语义一致且结构意识的改进特征，后者由增强的浅层特征引导。SDE和SSR逐级嵌入，逐步将局部细节与全局语义结合在一起。", "conclusion": "大量的实验表明，本文提出的方法在四个流行的细粒度图像分类基准上达到了新的最先进的性能。"}
{"llm_update_time": "20251116", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.04449", "html_url": "https://arxiv.org/abs/2509.04449", "title": "Chrono图：一个基于真实世界的图结构多变量时间序列数据集", "title_en": "ChronoGraph: A Real-World Graph-Based Multivariate Time Series Dataset", "authors": "Adrian Catalin Lutu,Ioana Pintilie,Elena Burceanu,Andrei Manolache", "background": "现有的基准数据集来自工业控制系统或交通、空气质量领域，这些数据集具有局限性。ChronoGraph数据集基于真实世界的生产微服务构建，包含了多变量时间序列数据，以及一个显示服务间依赖关系的有向图，并提供了与实际事件对齐的异常标签。这使得它能够更好地为结构感知预测和事故感知评估提供研究基准。", "innovation": "ChronoGraph数据集的独特之处在于结合了多变量时间序列、显式的机器可读的依赖图以及与实际事件对齐的异常标签。它为研究结构感知预测和事件感知评估提供了新的基准。", "conclusion": "ChronoGraph为研究微服务系统中的结构感知预测和事件感知评估提供了现实基准。实验报告了预测模型、预训练时间序列基础模型和标准异常检测器的基本结果，以展示其在实际场景中的适用性。"}
{"llm_update_time": "20251116", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.12211", "html_url": "https://arxiv.org/abs/2508.12211", "title": "使用基于模型搜索改进预训练的视觉-语言-动作策略", "title_en": "Improving Pre-Trained Vision-Language-Action Policies with Model-Based Search", "authors": "Cyrus Neary,Omar G. Younis,Artur Kuramshin,Ozgur Aslan,Glen Berseth", "background": "预训练的视觉-语言-动作（VLA）模型为通用机器人策略提供了一个有前景的基础，但在部署到新环境时往往会表现出脆弱的行为或不安全的失败。通过将基于模型的搜索嵌入到预训练VLA策略的推理过程中，Vision-Language-Action Planning & Search (VLAPS) 提供了一个新的框架和相应的算法，以改善他们在机器人任务中的表现。", "innovation": "VLAPS 结合了预训练 VLA 策略所生成的动作先验与基于模型的搜索，具体地，使用修改后的蒙特卡洛树搜索 (MCTS) 算法，该算法运行于目标环境的模型上，并利用 VLA 政策生成的动作先验。该方法通过使用从 VLA 提取的抽象和先验知识来有效探索语言条件下的机器人任务，这些任务的搜索空间原本无法操作。与直接跟随 VLA 策略的动作预测相比，VLAPS 提供了更优的行为，并提供了一个原理性的框架来：I）控制 VLA 模型的测试时间计算量，II）利用有关机器人环境的先验知识，以及 III）将已建立的规划和强化学习技术整合到 VLA 推理过程中。", "conclusion": "在所有实验中，VLAPS 在语言指定的任务上显著优于仅使用 VLA 的基线，当任务无法通过未受过训练的搜索算法解决时，其成功率为提高高达 67 个百分点。"}
{"llm_update_time": "20251116", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.05314", "html_url": "https://arxiv.org/abs/2509.05314", "title": "ManipDreamer3D: 生成具有occupancy意识的3D路径的合现实机器人操作视频", "title_en": "ManipDreamer3D : Synthesizing Plausible Robotic Manipulation Video with Occupancy-aware 3D Trajectory", "authors": "Ying Li,Xiaobao Wei,Xiaowei Chi,Yuming Li,Zhongyu Zhao,Hao Wang,Ningning Ma,Ming Lu,Sirui Han,Shanghang Zhang", "background": "机器人的操作数据稀缺继续是机器人操作领域的重大挑战。现有的基于扩散模型的解决方案主要依赖2D路径，存在3D空间上的歧义问题。", "innovation": "本文提出了一种名为ManipDreamer3D的新型框架，用于从输入图像和文本指令生成具有合理3D意识的机器人操作视频。该方法结合了3D路径规划与从第三人视角重建的3D占有地图，并采用了新型的路径到视频扩散模型。", "conclusion": "实验结果表明，该方法生成的机器人类视频具有合理规划的3D路径，显著减少了人工干预的需求，并在视觉质量上优于现有方法。"}
{"llm_update_time": "20251116", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.17311", "html_url": "https://arxiv.org/abs/2508.17311", "title": "bine 树：通过优化通信局部性改进集体操作", "title_en": "Bine Trees: Enhancing Collective Operations by Optimizing Communication Locality", "authors": "Daniele De Sensi,Saverio Pasqualoni,Lorenzo Piarulli,Tommaso Bonato,Seydou Ba,Matteo Turisini,Jens Domke,Torsten Hoefler", "background": "在大规模高性能计算系统中，特别是在过度订阅网络中，通信局部性对大规模集合操作的性能至关重要。在这种环境下，节点内部完全连接，但通过全局连接彼此稀疏连接。传统的集合算法未能充分优化这种局部通信，导致全球链接的通信流量较大，影响整体性能。", "innovation": "提出了一种新的集合算法家族——bine（二项负二进制）树，这种算法优化了通信局部性。Bine树保持了二项树和蝴蝶结构的一般性，同时减少了高达33%的全球链接通信流量。研究者实现了八种基于bine树的集合算法，并在四种大型超级计算机上进行了评估，其中包括Dragonfly、Dragonfly+、过度订阅的fat-tree和拓扑结构的环形网络，结果显示在不同的向量大小和节点数量下，实现了高达5倍的性能提升和一致的全球链接通信流量减少。", "conclusion": "bine树集合算法成功地提高了通信局部性，显著提升了大规模集合操作的性能，并在多种网络环境下展示了其稳定性和高效性。这是首个将二项负二进制原理应用于优化分布式系统中全局连接通信流量的创新研究。"}
{"llm_update_time": "20251116", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.05615", "html_url": "https://arxiv.org/abs/2508.05615", "title": "基于区域一致性的时间测试强化学习方法用于GUI接地", "title_en": "Test-Time Reinforcement Learning for GUI Grounding via Region Consistency", "authors": "Yong Du,Yuchen Yan,Fei Tang,Zhengxi Lu,Chang Zong,Weiming Lu,Shengpei Jiang,Yongliang Shen", "background": "GUI接地是将自然语言指令映射到精确屏幕坐标的任务，对于自主GUI代理而言至关重要。现有的方法通过大量监督训练或带有标记奖励的强化学习实现良好的性能，但它们受限于像素级标注的成本和可用性。", "innovation": "提出GUI-RC（区域一致性）测试时间缩放方法，通过构建来自多个预测的选择区域投票网格来识别模型最一致的区域。此外，提出GUI-RCPO（区域一致性策略优化），将一致性模式转化为测试时间强化学习的奖励，从而使模型在无标签数据上的推断输出逐步精细化。", "conclusion": "实验表明，仅使用1,272个未标注数据，GUI-RCPO在不同架构上相较于ScreenSpot基准提高了3-6%的准确性。该方法揭示了测试时间和强化学习在GUI接地中的潜在价值，为开发更高效的数据GUI代理提供了前景。"}
{"llm_update_time": "20251116", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.15721", "html_url": "https://arxiv.org/abs/2508.15721", "title": "EcomMMMU: 精准利用视觉元素以增强鲁棒多模态电子商务模型", "title_en": "EcomMMMU: Strategic Utilization of Visuals for Robust Multimodal E-commerce Models", "authors": "Xinyi Ling,Hanwen Du,Zhihui Zhu,Xia Ning", "background": "电子商务平台富含多模态数据，涉及大量图像，这些图像有助于展示产品细节。然而，现有研究尚未系统地探讨这些图像是否总是提升产品理解，还是有可能增加冗余或损害性能。现有的数据集规模有限且设计不足，难以全面研究这一问题。为此，本文提出了EcomMMMU，这是一个包含406,190个样例和8,989,510张图像的电子商务多模态多任务理解数据集。EcomMMMU专门设计了可用于评估大规模语言模型（MLLMs）利用视觉内容能力的视觉语义子集（VSS）。分析表明，产品图像并不总是提升性能，有时甚至会导致性能下降，这表明MLLMs可能难以有效利用丰富的视觉内容来完成电子商务任务。", "innovation": "本文创新性地提出了EcomMMMU数据集，旨在评估大模型在电子商务场景下对视觉内容的利用能力。此外，还提出了基于数据驱动的SUMEI方法，通过预测图像的视觉效用以在下游任务中战略性地利用多种图像。该方法在综合实验中显示出其有效性和鲁棒性。", "conclusion": "本文揭示了电子商务中的图像并非始终提升模型性能，有时可能产生负面影响。研究人员建议通过SUMEI方法在信息利用时考虑到图像的视觉效用，以提高模型在实际应用中的性能和稳定性。"}
{"llm_update_time": "20251116", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.09958", "html_url": "https://arxiv.org/abs/2509.09958", "title": "基于视觉语言True/False验证的零样本 REFERING 表达理解", "title_en": "Zero-Shot Referring Expression Comprehension via Vison-Language True/False Verification", "authors": "Jeffrey Liu,Rongbin Hu", "background": "REFERING 表达理解（REC）通常采用任务训练的地基模型进行处理。以前的研究表明，这些模型在特定任务上的训练有助于提高性能。然而，该论文提出了一个无训练的零样本工作流，在不进行任何REC特定训练的情况下能够达到与训练模型相当甚至更优的性能。", "innovation": "该研究创新性地将REC重新表述为框级的视觉语言验证，使用COCO-clean通用检测器（YOLO-World）产生的提议，让具有通用感知能力的视觉语言模型（VLM）独立对每个区域进行True/False的查询回答。这种方法减少了框间的干扰，支持弃权和多匹配，并不需要微调。通过RefCOCO、RefCOCO+和RefCOCOg等数据集上的实验证明，该方法在零样本GroundingDINO基线甚至在REC和CRG训练的GroundingDINO之上取得了更好的表现。同时也证明了验证过程在零样本设置中显著优于基于选择的提示方法。", "conclusion": "研究表明，工作流设计而非任务特定的预训练是驱动零样本REC性能的关键因素。"}
{"llm_update_time": "20251116", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.05796", "html_url": "https://arxiv.org/abs/2509.05796", "title": "双模式深度异常检测在医疗制造中的应用：结构相似性和特征距离", "title_en": "Dual-Mode Deep Anomaly Detection for Medical Manufacturing: Structural Similarity and Feature Distance", "authors": "Julio Zanon Diaz,Georgios Siogkas,Peter Corcoran", "background": "医疗设备制造中的自动化视觉检查面临独特的挑战，包括极低的缺陷率、有限的标注数据、生产线上的硬件限制以及需要验证且可解释的人工智能系统。现有解决方案未能有效应对这些挑战。", "innovation": "该论文提出了一种双模式深度异常检测框架，通过互补的异常检测策略解决了上述限制。第一种方法使用四尺度结构相似性指数进行实时缺陷检测，适合受限硬件环境。第二种方法通过马氏距离分析随机降维的潜在特征，实现高效的功能空间监控和生命周期验证。研究还表明，该方法在实际制造条件下优于参考基准。研究结果展示了该方法在确保安全关键制造环境的可靠性、可观测性和生命周期监控方面的优势。", "conclusion": "实验结果在表面封边图像数据集（SSI）上的验证表明，提出的双模式方法在现实工业条件下优于参考基准，包括MOCCA、CPCAE和RAG-PaDiM。跨领域验证还证实了与最新异常检测方法相当的准确性。此框架提供了在线异常检测和监督监控的集成，推动了可解释的人工智能架构的发展。源代码和数据集已在项目资源库中公开，以促进可重复研究。"}
{"llm_update_time": "20251116", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.09651", "html_url": "https://arxiv.org/abs/2509.09651", "title": "为可靠解读无线电法规而采用检索增强生成方法", "title_en": "Retrieval-Augmented Generation for Reliable Interpretation of Radio Regulations", "authors": "Zakaria El Kassimi,Fares Fourati,Mohamed-Slim Alouini", "background": "我们研究了无线电法规领域的问答问题，这是一个法律敏感且风险高的领域。本文提出了一种专门针对电信的检索增强生成(RAG)流水线，并构建了首个基于权威来源的多方选择评估集，使用自动化过滤和人工验证。通过定义一个领域特定的检索评价指标，我们的检索器在该指标下的准确率达到了约97%。在检索之外，我们的方法在所有测试的模型中始终提高了生成准确性。特别是在使用我们的流水线时，对于GPT-4o模型，其生成准确性提高了近12%。这些发现表明，精心设计的定位提供了一个简单但强大的基准，并且是针对监管问答问题的有效的领域特定解决方案。", "innovation": "本文提出了一种专门针对电信的检索增强生成(RAG)流水线，并构建了首个基于权威来源的多方选择评估集，使用自动化过滤和人工验证。同时，定义了一个领域特定的检索评价指标，评估了检索质量。研究发现，在所有测试的模型中，专门的流水线方法始终提高了生成准确性，特别是在GPT-4o模型上，增益达到了近12%。", "conclusion": "这项研究展示了精心设计的定位提供了一个简单但强大的基准，并且是针对无线电法规领域监管问答问题的有效的领域特定解决方案。所有代码和评价脚本，以及我们的问答数据集都已公开。"}
{"llm_update_time": "20251116", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.11816", "html_url": "https://arxiv.org/abs/2509.11816", "title": "Collapse of Irrelevant Representations (CIR) 保障了LLM稳健且非破坏性的遗忘", "title_en": "Collapse of Irrelevant Representations (CIR) Ensures Robust and Non-Disruptive LLM Unlearning", "authors": "Filip Sondej,Yushi Yang", "background": "当前的卸载和安全训练方法在从语言模型中移除危险知识方面成效不佳。研究发现这些方法的目标在于卸载过于泛化的表示，导致卸载过程中未有效区分一般知识和具体事实，从而影响了性能。为了解决这个问题，研究提出了一个选择性卸载技术称为Collapse of Irrelevant Representations (CIR)，通过此技术可以更精准地卸载具体事实而不影响一般性能。", "innovation": "CIR 技术通过对激活和模块输出梯度进行PCA来识别包含共性表示的子空间，然后压缩这些子空间，计算卸载更新。这种方法只针对需要卸载的具体事实并避免卸载一般知识，和现有的最佳基线方法Circuit Breakers相比，CIR技术在卸载生物和网络危害事实时，能够减少超过30倍的后攻击精度损失，同时只为每条事实消耗不到3个GPU秒的时间，且对整体性能影响也小30倍。", "conclusion": "CIR能够通过在表示层面分离有害和无害的能力，实现稳健且非破坏性的卸载。"}
{"llm_update_time": "20251116", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.15674", "html_url": "https://arxiv.org/abs/2509.15674", "title": "边缘计算中成本敏感二分类的推理卸载", "title_en": "Inference Offloading for Cost-Sensitive Binary Classification at the Edge", "authors": "Vishnu Narayanan Moothedath,Umang Agarwal,Umeshraja N,James Richard Gross,Jaya Prakash Champati,Sharayu Moharir", "background": "该研究关注的是边缘智能系统中的二分类问题，其中假阴性比假阳性更昂贵。系统中有一个紧凑的本地部署模型，该模型还可通过网络获得一个更大的远程模型来进行支持，但这需要一笔卸载成本。对于每个样本，系统首先使用本地模型进行推理，在本地模型输出的基础上判断是否将样本卸载到远程模型中。因此，该工作旨在理解这种层次推理系统（HI系统）中的分类准确性和卸载成本之间的根本权衡。", "innovation": "为了优化该系统，提出了一种在线学习框架，该框架能够不断适应本地模型的置信度评分阈值。这一框架能够为校准的本地模型提供闭式解，并为非校准模型引入了一种新的在线两阈值层次推理策略H2T2，证明其达到了次线性遗憾，并且能够适应分布迁移，实现高效的分类。", "conclusion": "仿真实验结果显示，H2T2策略在真实数据集上持续优于简单的单阈值HI策略，并且有时甚至超过了离线最优值。该策略还展示了对于分布迁移的鲁棒性和偏差分类器的良好适应能力。"}
{"llm_update_time": "20251116", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.23213", "html_url": "https://arxiv.org/abs/2509.23213", "title": "一次成像多标签因果发现高维事件序列", "title_en": "One-Shot Multi-Label Causal Discovery in High-Dimensional Event Sequences", "authors": "Hugo Math,Robin Schön,Rainer Lienhart", "background": "在医疗保健、网络安全或车辆诊断等领域中，理解涉及数千种稀疏事件类型的时间序列因果关系至关重要。然而，当前的方法在扩展性上存在局限性，难以处理大规模数据集。", "innovation": "本文提出了OSCAR，一种基于Transformer的单步因果自回归方法，通过两个预训练的Transformer作为概率估计器来推断每序列的马尔可夫边界。这种方法无需昂贵的全局条件独立性测试即可实现高效的并行因果发现。在真实汽车数据集上，OSCAR可以在几分钟内恢复可解释的因果结构，而传统方法因扩展性问题无法处理大规模数据。", "conclusion": "OSCAR方法在高维事件序列的单次操作中实现了因果发现，并且能够在生产规模上进行实际的科学诊断，相比之下，传统的因果发现方法无法在处理大规模数据时进行有效的扩展。"}
{"llm_update_time": "20251116", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.19319", "html_url": "https://arxiv.org/abs/2509.19319", "title": "FHIR-AgentBench：基于现实互操作EHR问题解答的LLM代理基准测试", "title_en": "FHIR-AgentBench: Benchmarking LLM Agents for Realistic Interoperable EHR Question Answering", "authors": "Gyubok Lee,Elea Bach,Eric Yang,Tom Pollard,Alistair Johnson,Edward Choi,Yugang jia,Jong Ha Lee", "background": "HL7 FHIR标准的普及为临床AI开辟了新领域，需要LLM代理能够处理复杂、基于资源的数据模型，而不仅仅是传统的结构化健康数据。然而，现有的基准测试未能紧跟这一转变，无法准确评估近期的LLM在互操作性临床数据上的表现。因此，有必要建立新的基准测试来填补这一空白。", "innovation": "本文提出FHIR-AgentBench基准测试，该基准测试将2,931个真实的临床问题与HL7 FHIR标准联系起来，系统评估了不同的数据检索策略、交互模式和推理策略。该测试揭示了从复杂FHIR资源检索数据以及在其上进行推理的实践挑战，这对问题回答的表现至关重要。同时，开发者现在可以使用公开发布的FHIR-AgentBench数据集和评估套件促进可重复的研究和可靠LLM代理的发展。", "conclusion": "通过FHIR-AgentBench基准测试，展示了对从复杂的FHIR资源检索数据以及在其上进行推理的实践挑战，这些挑战对问题回答的表现有重要影响。此外，通过提供的数据集和评估套件，促进可重复的研究和用于临床应用的稳健、可靠的LLM代理的发展。"}
{"llm_update_time": "20251116", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.19112", "html_url": "https://arxiv.org/abs/2509.19112", "title": "关于高维事件序列中的实用单次图聚合的一种多标签因果发现方法", "title_en": "Towards Practical Multi-label Causal Discovery in High-Dimensional Event Sequences via One-Shot Graph Aggregation", "authors": "Hugo Math,Rainer Lienhart", "background": "在事件序列中，因果关系的理解至关重要，尤其是在医疗或车辆诊断等领域，事件结果如疾病或系统故障往往由之前事件如症状或错误代码引起。然而，识别和表示这种因果关系仍然在这些领域被视为一个未解决的挑战。本研究旨在解决这一挑战，应用于具有数千种独特事件类型的稀疏、高维事件序列因果发现方法，并探讨其在解决实际问题中的潜力和效率。", "innovation": "CARGO方法提出了一个新的、可扩展的多标签因果发现方法，用于稀疏的、高维度的事件序列。该方法使用两种预先训练的因果变换器作为特定领域的基础模型，能够并行地为每个序列推断出一个单次的因果图，并通过自适应频率融合整合这些因果图，从而重构全局标签的马尔可夫边界。这种方法两阶段并行推理，减少了详尽条件独立性测试的成本，从而实现大规模高效概率推理。", "conclusion": "通过对一个具有29,100种唯一事件类型和474个不平衡标签的复杂现实汽车故障预测数据集的测试，该文证明了CARGO方法在执行结构化推理方面的强大能力。"}
{"llm_update_time": "20251116", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.01299", "html_url": "https://arxiv.org/abs/2510.01299", "title": "使用大型语言模型增强切伦科夫望远镜阵列控制软件的发展", "title_en": "Enhancing the development of Cherenkov Telescope Array control software with Large Language Models", "authors": "Dmitriy Kostunin,Elisa Jones,Vladimir Sotnikov,Valery Sotnikov,Sergo Golovachev,Alexandre Strube", "background": "本文档描述了基于指令微调的大语言模型（LLMs）开发的人工智能代理，用于协助切伦科夫望远镜阵列观测站（CTAO）的控制和数据获取软件（ACADA）。这些代理与项目特定的文档和代码库相一致，能够理解上下文信息，与外部API交互，并以自然语言与用户进行沟通。这项工作旨在将这些功能集成到CTAO的操作管道中，以及进行离线数据分析。", "innovation": "论文的主要创新在于开发了一种基于大语言模型的人工智能代理，用于提高切伦科夫望远镜阵列控制软件开发过程中的效果。这些代理具有项目特定的文档和代码库的一致性、理解上下文信息的能力、与外部API的交互能力以及与用户的自然语言沟通能力。这项创新使得软件开发更加高效和智能。", "conclusion": "本文研究了将大语言模型引入切伦科夫望远镜阵列控制软件开发中的进度。这些人工智能代理已经成功地被集成到CTAO的操作和离线数据分析管道中，并且展示了其可以显著提高软件开发的效率和效果。未来的工作将继续扩展和优化这些代理的功能，以进一步提高CTAO系统的性能。"}
{"llm_update_time": "20251116", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.04602", "html_url": "https://arxiv.org/abs/2510.04602", "title": "通过梯度流计算Wasserstein势心", "title_en": "Computing Wasserstein Barycenters through Gradient Flows", "authors": "Eduardo Fernandes Montesuma,Yassir Bendou,Mike Gartrell", "background": "Wasserstein势心是一种强大的方法，用于聚合概率措施，利用其环境空间的几何结构。现有的离散方法存在可扩展性差的问题，因为它们需要访问输入措施的完整样本集。", "innovation": "本文通过将原始势心问题重新表述为Wasserstein空间中的梯度流，来解决这一问题。文章的优势在于两种方式：一是通过从输入措施中采样迷你批次实现可扩展性；二是引入概率措施上的泛函，通过内部、潜在和相互作用能量来正则化势心问题。文章还提出了针对经验概率和高斯混合概率的两个算法，并在多项实验证明了本文方法优于之前的离散和基于神经网络的方法。", "conclusion": "实验结果表明，作者的方法在玩具数据集和领域适应基准测试中优于先前的离散和基于神经网络的方法来计算Wasserstein势心。"}
{"llm_update_time": "20251116", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.01252", "html_url": "https://arxiv.org/abs/2510.01252", "title": "GPT与偏见：理解大型语言模型中学习表示的稀疏方法", "title_en": "GPT and Prejudice: A Sparse Approach to Understanding Learned Representations in Large Language Models", "authors": "Mariam Mahran,Katharina Simbeck", "background": "大型语言模型（LLMs）在大规模且未结构化的语料上进行训练，导致人们对其吸收的社会模式和偏见的了解模糊。现有的评估通常只检查输出或激活，但很少将它们与预训练数据联系起来。因此，本文旨在通过引入将LLMs与稀疏自动编码器（SAEs）相结合的管道，来追踪和理解不同主题在训练过程中如何被编码的方法和途径。具体案例是在10位女性作者的37部19世纪小说上训练了一种GPT风格的模型，这些小说围绕性别、婚姻、社会阶层和道德等主题展开。通过在各层中应用SAEs和使用11类社会和道德分类进行探测，将稀疏特征映射到可解释的人类概念上，从而分析出稳定的主题核心，并展示了这些关联如何在深度中扩展和纠缠。这一工作基于的背景是目前缺乏有效的方法来审计和理解这些模型在训练数据中吸收的隐式偏见。", "innovation": "本文提出了一种将大型语言模型（LLMs）与稀疏自动编码器（SAEs）相结合的方法，通过追踪主题在训练过程中的编码，来评估和理解模型中隐含的文化假设，特别是关于性别和社会关系的主题。这种方法提供了一种可扩展的框架，用于审计和理解大型语言模型中嵌入的偏见及其在深度中的作用方式。此外，该研究还展示了如何通过稀疏特征映射到人类可解释的概念上来揭示模型中的主题结构和偏见模式。", "conclusion": "本文通过引入LLM与SAEs结合的管道，提供了一种可扩展的审计框架，以理解大型语言模型如何在其表示中嵌入文化假设，特别是上面提到的社会主题。这一方法为研究和理解大型语言模型中的隐含偏见提供了新的视角。"}
{"llm_update_time": "20251116", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.05162", "html_url": "https://arxiv.org/abs/2510.05162", "title": "人工智能批改手写微积分考试", "title_en": "Artificial-Intelligence Grading Assistance for Handwritten Components of a Calculus Exam", "authors": "Gerd Kortemeyer,Alexander Caspar,Daria Horica", "background": "本文探讨了现代多模态大语言模型是否可以在大规模开放性微积分题目的批改中提供帮助，而不影响评分的有效性。在一场大型的第一年考试中，GPT-5对学生的手写工作进行了评分，评分标准与助教（TAs）一致，并允许部分得分；助教的评分作为参考标准。文章通过人工在环中的过滤机制，结合部分得分阈值和基于AI评分与模型预期评分偏差的项目反应理论（2PL）风险度量进行校准。未经过滤的情况下，AI-TA评分一致性一般，适用于低风险反馈但不适合高风险使用。通过置信度筛选使工作量与质量之间的权衡变得明确：在更严格的设置下，AI可以达到人类级别的精度，但也会留下约70%的题目需要人工批改。", "innovation": "本文的创新在于首次使用现代多模态大语言模型（如GPT-5）进行大规模的手写开放性数学题评分，并提出了结合部分得分阈值与项目反应理论风险度量的评分过滤机制。此外，通过人工在环中提高了评分的准确性，并明确工作量与质量之间的权衡关系。", "conclusion": "经过校准的置信度和保守路由策略可以让AI可靠地处理大部分常规情况，并保留专家判断用于模糊或教学丰富的回答。提高评估的权重、留出保护时间、增加显著子步骤并在评分准则中强固空间锚定，可以进一步提升表现。"}
{"llm_update_time": "20251116", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.12858", "html_url": "https://arxiv.org/abs/2510.12858", "title": "对古兰经诵读评估知识为中心的需求的批判性审查", "title_en": "A Critical Review of the Need for Knowledge-Centric Evaluation of Quranic Recitation", "authors": "Mohammed Hilal Al-Kharusi,Khizar Hayat,Khalil Bader Al Ruqeishi,Haroon Rashid Lone", "background": "古兰经诵读（塔吉威德）是一项受精密音位学、节奏学和神学原则指导的学科，在当今数字化时代面临了许多教育挑战。现代技术提供了前所未有的学习机会，但现有的自动评估系统尚未广泛接受或显示出教育效果。现有的技术方法侧重于单词识别，而忽视了高质量声音评估的重要性，导致这些系统存在数据偏差、人群不平等以及无法提供有效的反馈等问题。", "innovation": "文章倡导从数据驱动的方法转向基于知识的计算框架。强调利用古兰经文本的不变特性以及塔吉威德的明确规则，提出了一套基于规则的声学建模方案，通过关注标准发音原则和发音点（Makhraj），而非依赖于从有缺陷或有偏差的数据中提取的统计模式。文章进一步指出，未来的自动化古兰经诵读评估应结合语言学知识和高级音频处理技术。", "conclusion": "未来的自动化评估系统需要结合语言学专业知识和先进的音频处理技术，发展出可靠、公平且教育有效的工具，能够在全球范围内真正支持学习者。"}
{"llm_update_time": "20251116", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.16781", "html_url": "https://arxiv.org/abs/2510.16781", "title": " Xiaoice: 通过半监督时空语义特征聚类实现无需训练的视频理解", "title_en": "Xiaoice: Training-Free Video Understanding via Self-Supervised Spatio-Temporal Clustering of Semantic Features", "authors": "Shihao Ji,Zihui Song", "background": "尽管大型视觉语言模型（VLMs）在静态图像上的零样本推理能力表现出色，但这些能力尚未完全被推广到视频领域。传统视频理解模型通常需要在标注数据集上进行大量的、任务特定的训练，这一过程既昂贵又在可扩展性上有限。", "innovation": "本文引入了一个无需训练的创新框架，通过将预训练VLMs丰富的语义先验与经典机器学习算法相结合，来解决视频理解问题。该框架重新定义了视频理解为高维度语义特征空间内的自监督时空聚类问题。首先，使用预训练VLMs的冻结视觉编码器将视频流转换为语义特征轨迹。接着，通过Kernel Temporal Segmentation (KTS)技术将连续的特征流划分成具有语义一致性的事件段。最后，使用无监督的基于密度的聚类方法识别视频中反复出现的宏观场景和主题。该段落总结了该技术的创新点。", "conclusion": "通过这种方法，可以自动为视频内容生成结构化的多模态总结，提供了一种有效的、可解释的和模型无关的零样本自动结构分析路径。"}
{"llm_update_time": "20251116", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.26125", "html_url": "https://arxiv.org/abs/2510.26125", "title": "WOD-E2E: Waymo 开放数据集，用于在挑战性长尾场景中的端到端驾驶", "title_en": "WOD-E2E: Waymo Open Dataset for End-to-End Driving in Challenging Long-tail Scenarios", "authors": "Runsheng Xu,Hubert Lin,Wonseok Jeon,Hao Feng,Yuliang Zou,Liting Sun,John Gorman,Ekaterina Tolstaya,Sarah Tang,Brandyn White,Ben Sapp,Mingxing Tan,Jyh-Jing Hwang,Dragomir Anguelov", "background": "视觉基础的端到端(E2E)驾驶在研究社区中引起了显著的兴趣，因为其可扩展性和与多模态大型语言模型(MMLLMs)的协同工作。然而，现有的E2E驾驶基准主要包含理想的场景，未能充分测试这些系统的真正潜力。此外，现有的开环评估指标往往无法捕捉驾驶中的多模态性质或有效地评估长尾场景中的表现。", "innovation": "本文介绍了Waymo 开放数据集WOD-E2E，包含4,021段驾驶序列，专为罕见的长尾场景而设计，这些场景在日常生活中出现的频率低于0.03%。每个序列包括高级路径信息、自我状态和来自8个周围的360度摄像机视图。我们提出了一个新的开环评估指标：Rater Feedback Score (RFS)。RFS衡量预测轨迹与评判标注轨迹偏好标签的匹配程度，而非仅仅测量预测路径点与日志之间的距离。", "conclusion": "通过我们的研究，我们旨在促进可泛化、鲁棒且安全的端到端自动驾驶代理的研究，这些代理能够处理复杂的真实世界情况。我们已发布了WOD-E2E验证集的所有评判偏好标签，而保留的测试集标签用于2025年的WOD-E2E挑战赛。"}
{"llm_update_time": "20251116", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.03826", "html_url": "https://arxiv.org/abs/2511.03826", "title": "CORE - 一种多染色图像对齐的细胞级粗细粒度图像注册引擎", "title_en": "CORE - A Cell-Level Coarse-to-Fine Image Registration Engine for Multi-stain Image Alignment", "authors": "Esha Sadia Nasir,Behnaz Elhaminia,Mark Eastwood,Catherine King,Owen Cain,Lorraine Harper,Paul Moss,Dimitrios Chanouzas,David Snead,Nasir Rajpoot,Adam Shephard,Shan E Ahmed Raza", "background": "准确且高效的全切片图像（WSI）注册对于高分辨率、亚细胞级别的组织分析至关重要，尤其是对于多染色组织切片。现有方法多针对特定数据集，缺乏普适性，且经常出现亚细胞级对齐不精准的问题。因此，迫切需要一种能够处理多种模态的WSI数据集并实现精确、细胞级对齐的方法.", "innovation": "本文提出了一种新颖的粗细粒度框架CORE，用于多种模态WSI数据集中跨数据集的亚细胞水平注册。该框架包括三种关键技术：1. 使用提示基础的组织掩膜提取进行粗粒度对齐，有效过滤掉伪影和非组织区域；2. 利用组织形态进行全局对齐，并结合预训练特征提取器进行加速密集特征匹配；3. 通过估计非线性位移场实现细胞水平的非刚性对齐。此外，自动生成的细胞核提高了可变形对齐的精度，确保了不同模态下的细胞核级对应关系.", "conclusion": "本文提出的CORE方法在三项公开的WSI注册数据集和两项私人数据集上进行了评估，并且在多光镜和免疫荧光显微镜的WSI中表现出了高通用性、精度和鲁棒性，优于现有的领先方法."}
{"llm_update_time": "20251116", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.02162", "html_url": "https://arxiv.org/abs/2511.02162", "title": "使用3D生成AI和视觉语言模型实现基于文本的多组件对象机器人装配", "title_en": "Text to Robotic Assembly of Multi Component Objects using 3D Generative AI and Vision Language Models", "authors": "Alexander Htet Kyaw,Richa Gupta,Dhruv Shah,Anoop Sinha,Kory Mathewson,Stefanie Pender,Sachin Chitta,Yotto Koga,Faez Ahmed,Lawrence Sass,Randall Davis", "background": "3D生成AI技术已经能够从文本提示生成实物对象，但难以为包含多种组件类型的对象生成。本研究介绍了一个结合了3D生成AI和视觉语言模型（VLMs）的流水线，以通过自然语言实现多组件物体的机器人装配。VLMs用于零样本、多模态几何和功能推理，将AI生成的网格分解为包含预定义结构和面板组件的多组件3D模型。实验表明，VLM能够根据物体的几何形状和功能确定哪些网格区域需要面板组件，用户更倾向于VLM生成的组件分配（90.6%），而非基于规则的分配（59.4%）或随机分配（2.5%）。系统还允许用户通过对话反馈细化组件分配，增强了通过生成AI和机器人技术制造实物对象的人类控制和自主性。", "innovation": "该研究引入了一个结合3D生成AI和VLM的流水线，能够处理多组件物体的机器人装配，特别是那些包含多种组件类型的对象。创新之处在于使用VLM解决几何和功能推理问题，以及实现基于对话反馈的人机交互优化。", "conclusion": "该研究证明了VLM在多组件装配中的有效性，用户更倾向于VLM生成的区域分配，并提出了通过对话反馈机制进一步增强系统灵活性的方法，为生成AI和机器人技术在制造业中的应用奠定了基础。"}
{"llm_update_time": "20251116", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.04939", "html_url": "https://arxiv.org/abs/2511.04939", "title": "搜索并非检索：在RAG中的语义匹配与上下文组装的解耦", "title_en": "Search Is Not Retrieval: Decoupling Semantic Matching from Contextual Assembly in RAG", "authors": "Harshit Nainwani,Hediyeh Baban", "background": "检索系统是现代AI管道中的基础组件，尽管大多数系统混错了两个过程：信息检索和提供推理所需的上下文。现有的检索系统通常作为被动步骤执行，限制了它们的可组合性、规模性和上下文的准确度。", "innovation": "提出了Search-Is-Not-Retrieve (SINR)框架，这是一种双层架构，区分了精细的搜索表示和粗糙的检索上下文。SINR通过直接连接小型、语义准确的搜索片段到更大的、上下文完整的检索片段，增强了检索系统的可组合性、可扩展性和上下文保真度，而不需要额外的处理成本。", "conclusion": "SINR将检索从被动步骤转变为积极步骤，使系统架构更符合人类信息处理的方式，为下一代使用检索的AI系统提供了实用基础。"}
{"llm_update_time": "20251116", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.06557", "html_url": "https://arxiv.org/abs/2510.06557", "title": "The Markovian Thinker: Architecture-Agnostic Linear Scaling of Reasoning", "title_en": "The Markovian Thinker: Architecture-Agnostic Linear Scaling of Reasoning", "authors": "Milad Aghajohari,Kamran Chitsaz,Amirhossein Kazemnejad,Sarath Chandar,Alessandro Sordoni,Aaron Courville,Siva Reddy", "background": "强化学习(RL)近年来成为训练生成长链条推理的大型语言模型(LongCoT)的强大工具。然而，在传统的RL“思考环境”中，状态包括提示和所有先验推理标记，这使得状态无边界，并迫使基于注意力的策略随着推理长度增加而呈现平方计算负担。该论文重新审视了这一环境本身，提出了马尔可夫式思考的新范式，通过此范式，策略可以在保持推理的同时条件依赖于固定大小的状态，从而解耦思考长度和上下文大小，实现线性计算和恒定内存。解决了传统RL方法在处理长推理链时的计算复杂度问题，适应于更大的推理窗口。尤其是在长推理链任务上，Delethink表现出了与LongCoT-RL相似或更好的效果，同时以线性增长的计算复杂度优化了环境。", "innovation": "提出了马尔可夫式思考(Markovian Thinking)的新思想，通过将思考过程分解成固定大小的块来构建Delethink环境。这种环境使得政策学习在片段结束时编写足够的文本状态，以在重置后无缝继续推理。实验表明，训练1.5B参数的R1-Distill模型在8K标记的片段内进行推理，但最多可以进行24K标记的思考，这与在24K预算下训练的LongCoT-RL相当或更好。此外，Delethink在推理时间上可扩展，而LongCoT则趋于停滞，估计在100万平均推理长度上，LongCoT-RL的成本是Delethink的27倍。表明重新设计思考环境是游戏规则改变者，消除了二次计算复杂度，并提供了高效可扩展的推理大语言模型的可能途径。", "conclusion": "通过重新设计思考环境，该研究展示了如何实现马尔可夫式思维的架构无关的线性扩展，无需二次计算复杂度便能实现非常长的推理链。这为将来开发高效的可扩展推理大语言模型开辟了新途径。"}
{"llm_update_time": "20251116", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.04427", "html_url": "https://arxiv.org/abs/2511.04427", "title": "AI辅助编码是否奏效？CURSOR对软件项目的影响差异分析研究", "title_en": "Does AI-Assisted Coding Deliver? A Difference-in-Differences Study of Cursor's Impact on Software Projects", "authors": "Hao He,Courtney Miller,Shyam Agarwal,Christian Kästner,Bogdan Vasilescu", "background": "大型语言模型（LLMs）在软件工程领域显示出革命性的潜力。LLM代理在软件开发中的应用正迅速增加，许多实践者声称采用后可大幅提高生产力。然而，这些声明缺乏实证证据支持。本文通过差分差异法（difference-in-differences）研究了广泛使用的LLM代理助手Cursor对项目开发速度和软件质量的影响，从而量化了其效应，填补了该领域的研究空白。", "innovation": "本文创新地使用差分差异法，通过将采用Cursor的GitHub项目与不采用Cursor的相似GitHub项目进行比较，估算采用Cursor对项目开发速度和软件质量的实际影响。该研究揭示了部分因素如何导致长期影响，尤其是静态分析警告和代码复杂性的增加对长期开发速度的负面影响。这为软件工程从业者、LLM代理设计师和研究人员提供了宝贵的见解。", "conclusion": "采用Cursor导致项目开发速度出现显著但短暂的增加，同时导致静态分析警告和代码复杂性的长期持续增加，从而影响长期的开发速度。这对软件工程实践、LLM代理助手设计以及研究领域具有重要启示意义。"}
{"llm_update_time": "20251116", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.05508", "html_url": "https://arxiv.org/abs/2511.05508", "title": "个人化的链式思考总结方法在支持投资者决策中的应用：用于金融新闻的个性化链式思考摘要", "title_en": "Personalized Chain-of-Thought Summarization of Financial News for Investor Decision Support", "authors": "Tianyi Zhang,Mu Chen", "background": "金融顾问和投资者在面对大量金融新闻时感到困扰，因为其中的无关内容和噪音会掩盖关键市场信号，从而影响投资者做出及时的投资决策。这些海量信息常常包括大量的非关键信息和噪声，这阻碍了快速洞察有用信息的过程和实时决策的制定。", "innovation": "我们提出了一种创新的链式思考（CoT）总结框架，它能够将金融新闻简洁地汇总为以事件驱动的方式呈现的摘要。该框架集成了用户指定的关键字来生成个性化的输出，确保只突出最相关的上下文。这种个性化的总结为语言模型提供了中间层，帮助它们生成聚焦于投资者需求的叙事，缩小从原始新闻到可操作洞察之间的差距。", "conclusion": "本文提出的方法不仅提供了一种高效且高效的过滤金融新闻的方式，而且通过生成个性化的、简洁的摘要，为投资者提供了有用的洞察。这种方法可以在投资决策过程中为用户提供实质性的帮助，从而提高投资效率和决策质量。"}
{"llm_update_time": "20251116", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.07250", "html_url": "https://arxiv.org/abs/2511.07250", "title": "MVU-Eval: 朝着多视频理解评估为多模态LLM的方向", "title_en": "MVU-Eval: Towards Multi-Video Understanding Evaluation for Multimodal LLMs", "authors": "Tianhao Peng,Haochen Wang,Yuanxing Zhang,Zekun Wang,Zili Wang,Gavin Chang,Jian Yang,Shihao Li,Yanghai Wang,Xintao Wang,Houyi Li,Wei Ji,Pengfei Wan,Steven Huang,Zhaoxiang Zhang,Jiaheng Liu", "background": "随着多模态大型语言模型（MLLMs）的出现，AI的能力已经扩展到视觉模态，但现有的评估基准仍然局限于单视频理解，忽略了在实际场景中对多视频理解的迫切需求（例如体育分析和自主驾驶）。", "innovation": "作者引入了MVU-Eval，这是首个用于评估多视频理解（MVU）的基准。MVU-Eval通过1824个精挑细选的问题-答案对评估了MLLMs在4959个来自不同领域的视频中的八个核心能力，涵盖了基本感知任务和高级推理任务，这些能力与实际应用紧密相连，如自主系统中的多传感器合成和多角度体育分析。此基准揭示了当前MLLMs在多视频理解方面的显著性能差异和局限性，并将公开发布以促进未来的研究。", "conclusion": "通过广泛的实测，研究揭示了当前MLLMs在多视频理解方面的显著性能差异和局限性，并呼吁未来的模型改进。"}
{"llm_update_time": "20251116", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.06625", "html_url": "https://arxiv.org/abs/2511.06625", "title": "LDCT的心脏疾病可解释跨病症推理", "title_en": "Explainable Cross-Disease Reasoning for Cardiovascular Risk Assessment from LDCT", "authors": "Yifei Zhang,Jiashuo Zhang,Mojtaba Safari,Xiaofeng Yang,Liang Zhao", "background": "低剂量胸部CT（LDCT）能够同时捕捉肺部和心脏结构，提供了肺部和心血管健康联合评估的独特机会。然而，大多数现有方法将这些领域视为独立任务，忽视了它们的生理相互作用和共同的影像学生物标志物。因此，目前的肺部和心血管疾病评估过程中缺乏统一且可解释的推理框架。", "innovation": "本文提出了一种解释性跨病症推理框架，该框架能够从单次LDCT扫描中进行可解释的心肺风险评估。该框架引入了一个代理推理过程，模仿临床诊断思维，首先感知肺部发现，然后通过医学知识推理论证，最后得出心血管判断并提供解释性理由。该框架由三个协同工作的组件组成：肺部感知模块，知识指导的推理模块和心脏表示模块。它们的输出被融合以生成准确且生理基础的心血管风险预测。与现有的单病症和纯粹基于影像的方法相比，该框架在心血管疾病筛查和死亡率预测方面取得了最先进的性能。此外，该框架还提供了可与心脏病学理解验证的定量收益外的推理过程。", "conclusion": "本文建立了一个统一且可解释的心脏病学分析框架，从LDCT的角度看，该框架弥合了基于图像的预测与机制为基础的医学解释之间的差距。"}
{"llm_update_time": "20251116", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.05901", "html_url": "https://arxiv.org/abs/2511.05901", "title": "医学中的检索增强生成：技术实现、临床应用和伦理考量的综述", "title_en": "Retrieval-Augmented Generation in Medicine: A Scoping Review of Technical Implementations, Clinical Applications, and Ethical Considerations", "authors": "Rui Yang,Matthew Yu Heng Wong,Huitao Li,Xin Li,Wentao Zhu,Jingchi Liao,Kunyu Yu,Jonathan Chong Kai Liew,Weihao Xuan,Yingjian Chen,Yuhe Ke,Jasmine Chiat Ling Ong,Douglas Teodoro,Chuan Hong,Daniel Shi Wei Ting,Nan Liu", "background": "医学知识的快速增长和临床实践的复杂性带来了挑战。在此背景下，大型语言模型（LLMs）显示出价值，但仍存在局限性。检索增强生成（RAG）技术展示出增强其临床适用性的潜力。已有研究主要依赖公开数据，少有涉及私有数据。检索过程中，方法通常依赖于英语为主的嵌入模型，而LLMs大多是通用的，较少使用专门的医学LLMs。评估方面，自动化指标评估生成质量和任务性能，而基于人类的评价主要关注准确性、完整性、相关性和流畅性，较少关注偏见和安全性。RAG应用主要集中在问题回答、报告生成、文本摘要和信息提取等方面。总体而言，医学中的RAG仍处于早期阶段，需要在临床验证、跨语言适应和低资源环境支持方面取得进步，以促进全球的可靠使用并确保可信赖。", "innovation": "RAG技术展示了增强LLMs临床适用性的潜力，特别是通过检索功能提升生成质量与任务性能，这为解决数据局限性提供了一种新的方法。基于人类的评价更多关注准确性和相关性，未来可探讨更多维度的评估方法，包括偏见和安全性的考量。RAG在具体应用方面，涵盖问题回答、报告生成、文本摘要和信息提取等多个方面，并识别出医疗领域RAG应用目前所处的早期阶段，以及需要进一步发展的方向。", "conclusion": "医学中的RAG技术仍需在临床验证、跨语言适应和低资源环境支持方面取得进步，以促进其更加可靠的全球应用，并注意在评估方法中加入偏见和安全性的考量。"}
{"llm_update_time": "20251116", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.08238", "html_url": "https://arxiv.org/abs/2511.08238", "title": "视觉-语言微调中重构语义关系", "title_en": "Remodeling Semantic Relationships in Vision-Language Fine-Tuning", "authors": "Xiangyang Wu,Liu Liu,Baosheng Yu,Jiayan Qiu,Zhenwei Shi", "background": "视觉-语言微调已成为构建多模态基础模型的一种高效范式。现有的视觉-语言微调方法通常忽略了文本上下文中对图像中语义关系的强调，导致了次优的性能。", "innovation": "本文提出了一种方法，通过重新构建设计算法中的多重语义特征来改善视觉-语言表示的融合。该方法首先从不同的视觉编码器中提取多级语义特征，以捕获更多图像中视觉关系的可视化线索。然后，通过投影视觉特征以分组相关的语义，来加强视觉和语言间的匹配。最后，使用继承交叉注意力机制进行视觉特征和文本特征的融合，并通过删除相关性低的视觉-语言特征对来去除冗余的视觉关系。", "conclusion": "本文的方法在八个基础模型和两个下游任务（视觉问答和图像字幕生成）上进行了评估，结果显示该方法优于所有现有的方法。"}
{"llm_update_time": "20251116", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.07503", "html_url": "https://arxiv.org/abs/2511.07503", "title": "基于生物学知识的生成基因模型混合成员推断攻击", "title_en": "Biologically-Informed Hybrid Membership Inference Attacks on Generative Genomic Models", "authors": "Asia Belfiore,Jonathan Passerat-Palmbach,Dmitrii Usynin", "background": "随着遗传数据的可用性增加，基因组学研究得到了重大转型，但由于其敏感性，这引发了对如何处理这些数据的许多隐私担忧。本研究探讨了使用语言模型（LM）生成合成遗传突变谱型的方法，并利用差分隐私（DP）技术来保护敏感的遗传数据。研究通过引入一种新的生物信息学启发混合成员推断攻击（biHMIA），结合传统的黑盒MIA和上下文基因组度量来增强攻击能力，对我们的DP模式的隐私保障进行了实证评估。实验结果表明，无论是小型还是大型变压器GPT-like模型，均可作为小型基因组学的合成变异生成器，并且我们的混合攻击在平均上比传统的基于度量的MIA具有更高的对抗成功率。", "innovation": "本研究提出了一种基于生物学知识的混合成员推断攻击（biHMIA），它结合了传统的黑盒MIA和上下文基因组度量，增强了攻击能力。并通过生物信息学的知识提高了合成数据的合理性，同时利用差分隐私保护敏感的遗传数据。实验结果展示了使用GPT-like模型生成合成变异的有效性及其增强的攻击成功率，从而为小型基因组学研究提供了新的安全防护方案和技术支持。", "conclusion": "小型和大型变压器GPT-like模型均可作为生成小型基因组学中合成变异的可行选择，且我们的混合攻击（biHMIA）在对抗成功率上优于传统的基于度量的MIA。"}
{"llm_update_time": "20251116", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.08655", "html_url": "https://arxiv.org/abs/2511.08655", "title": "Learning the Basis: A Kolmogorov-Arnold Network Approach Embedding Green's Function Priors", "title_en": "Learning the Basis: A Kolmogorov-Arnold Network Approach Embedding Green's Function Priors", "authors": "Rui Zhu,Yuexing Peng,George C. Alexandropoulos,Wenbo Wang,Wei Xiang", "background": "Method of Moments (MoM) 使用固定的、基于几何的基函数，如Rao-Wilton-Glisson (RWG) 基，限制了其灵活性和适应性。这促使作者重新构思电磁建模方法，不再局限于固定的基函数，而是通过学习可变的基函数来解决问题。作者指出RWG基实质上是一种静态的、分段线性的 Kolmogorov-Arnold 逼近定理的实现。", "innovation": "提出了一种基于物理的 Kolmogorov-Arnold 网络 (PhyKAN)，这是一种学习并自适应的基函数家族，来源于电场积分方程 (EFIE)。PhyKAN 结合了局部 KAN 分支和嵌入Green's 函数先验的全局分支，以保持物理一致性。实验结果表明，PhyKAN 在多种典型几何形状下实现了低于0.01的重构误差，并且能够提供无监督的雷达截面预测，填补了经典求解器和现代神经网络模型在电磁建模中的空白，提供了一种可解释、物理一致性的桥梁。", "conclusion": "PhyKAN 在多种典型几何形状中实现了低于0.01的重构误差，并提供了精确的、无监督的雷达截面预测，证明了其作为经典求解器和现代神经网络模型在电磁建模中桥梁的价值，提供了一种物理一致性的学习基函数方法。"}
{"llm_update_time": "20251116", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.09109", "html_url": "https://arxiv.org/abs/2511.09109", "title": "思考前向与后向：用于检索增强推理的多目标强化学习", "title_en": "Thinking Forward and Backward: Multi-Objective Reinforcement Learning for Retrieval-Augmented Reasoning", "authors": "Wenda Wei,Yu-An Liu,Ruqing Zhang,Jiafeng Guo,Lixin Su,Shuaiqiang Wang,Dawei Yin,Maarten de Rijke,Xueqi Cheng", "background": "检索增强生成（RAG）被证明在减少大型语言模型中的幻觉方面是有效的，但在复杂的多步骤推理场景中，其效果仍然有限。最近的努力将基于搜索的交互引入RAG，允许迭代推理和实时检索。大多数方法依赖于基于结果的监督，没有为中间步骤提供明确的指导。这通常会导致奖励黑客和响应质量下降。", "innovation": "提出了一种名为Bi-RAR的新颖检索增强推理框架，该框架在前向和后向方向上评估每个中间步骤。通过引入基于柯尔莫哥洛夫复杂性的双向信息距离，结合语言模型生成概率的近似值来评估每一步信息的完整性。此外，采用一个多层次的奖励结构的多目标强化学习框架来优化推理，强调早期轨迹对齐。", "conclusion": "在七个问答基准测试上的实验证明，Bi-RAR超越了先前的方法，并使在训练和推理期间与搜索引擎的高效交互和推理成为可能。"}
{"llm_update_time": "20251116", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.09193", "html_url": "https://arxiv.org/abs/2511.09193", "title": "通过多动作操作增强PIBT", "title_en": "Enhancing PIBT via Multi-Action Operations", "authors": "Egor Yukhnevich,Anton Andreychuk", "background": "PIBT 是一种基于规则的多智能体路径规划 (MAPF) 求解器，广泛用作许多前沿方法中的低级规划器或动作采样器。它的主要优势在于其极高的速度，使其能够在几毫秒内为成千上万个智能体选择行动，并仅考虑下个时间步骤。然而，这种短视的设计导致在智能体具有方向性且需要执行耗时旋转操作的场景中表现不佳。", "innovation": "本文提出了一种增强版的PIBT，通过引入多动作操作来弥补其不足。该方法在保持PIBT标志性高效性的同时，提升了其性能。此外，研究还展示了将图引导技术和大邻域搜索优化整合到增强版PIBT中，使其在在线LMAPF-T设置中达到最先进的性能。", "conclusion": "我们的方法通过多动作操作增强了PIBT的性能，结合图引导技术和大邻域搜索优化，在在线LMAPF-T设置中达到了最高的性能标准。"}
{"llm_update_time": "20251116", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.09147", "html_url": "https://arxiv.org/abs/2511.09147", "title": "PressTrack-HMR: 基于压力的顶部向下多人全身人体网格恢复", "title_en": "PressTrack-HMR: Pressure-Based Top-Down Multi-Person Global Human Mesh Recovery", "authors": "Jiayue Yuan,Fangting Xie,Guangwen Ouyang,Changhai Ma,Ziyu Wu,Heyu Ding,Quan Wan,Yi Ke,Yuchen Wu,Xiaohui Cai", "background": "多人全局人体网格恢复（HMR）对于理解人群动态和互动至关重要。传统基于视觉的人体网格恢复方法在现实场景中可能因相互遮挡、照明不足和隐私问题而受限。相比之下，人类与地面的触觉互动提供了一种无遮挡且隐私友好的替代方案来捕捉人体动作。现有研究证明，在单人情况下，来自触觉垫的压力信号能有效估计人体姿态。然而，在多人同时随机在垫子上行走时，如何将不同人产生的混合压力信号区分开来并随后获取每个人的个体时间压力数据，仍然是将压力基HMR扩展到多人情况的挑战。", "innovation": "本文提出了PressTrack-HMR，这是一种顶部向下的管道，仅通过压力信号恢复多人全球人体网格。该管道采用检测跟踪策略，首先从原始压力数据中识别和分割每个人的单独压力信号，然后对每个提取的信号进行HMR。此外，我们建立了一个多人互动压力数据集MIP，它促进了基于压力的人体动作分析在多人场景中的进一步研究。", "conclusion": "实验结果表明，我们的方法在使用压力数据进行多人HMR方面表现出色，MPJPE为89.2 mm，WA-MPJPE$_{100}$为112.6 mm，这展示了触觉垫在普及、保护隐私的多人动作识别中的潜力。我们的数据集及代码可在此网址获取。"}
{"llm_update_time": "20251116", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.08570", "html_url": "https://arxiv.org/abs/2511.08570", "title": "使用层直方图的柯莫洛夫-阿诺德网络自动更新网格", "title_en": "Automatic Grid Updates for Kolmogorov-Arnold Networks using Layer Histograms", "authors": "Jamison Moody,James Usevitch", "background": "柯莫洛夫-阿诺德网络（Kolmogorov-Arnold Networks, KANs）是一种受到了近年来文献关注的神经网络。与多层感知器（MLPs）不同，KANs 使用参数化和可训练的激励函数，并提供多种好处，例如改善的可解释性和在学习符号方程时更高的准确性。然而，最初的 KAN 架构在训练过程中需要用户调整网络的域离散化（称为“域网格”），这为训练过程增加了额外的负担。普通的 KAN 层通常缺乏自主地以生成的数据范围变化为依据更新其域的能力。此外，这种直方图算法还可以用于各种情况下检测超分布（OOD）输入。在四个不同的任务中，AdaptKAN 超过了或与之前的 KAN 架构和MLPs 的性能相当，这些任务包括从费恩曼数据集学习科学方程、从冻结特征进行图像分类、学习控制李亚普诺夫函数，以及在 OpenOOD v1.5 数据集上检测超分布输入。", "innovation": "该研究提出了使用层直方图的自动网状更新算法，该算法替代了传统的柯莫洛夫-阿诺德网络训练中需要手动调整的域网格。AdaptKAN 模型在不同任务中表现出与 KAN 和 MLP 相当甚至更好的性能，证明了该算法的有效性。这种更新方法还提高了网络的自动性和灵活性，能够根据数据变化自主调整其参数化的激励函数范围，有利于更好地适应数据的变化，并且为 KANs 的进一步开发提供了新的思路。该算法还增强了 KANs 在实际应用中的可用性和鲁棒性，使其能够有效地检测超分布输入。", "conclusion": "论文提出了 AdaptKAN，一种使用层直方图自动更新网络域的方法。通过基于数据范围变化的自动调整，AdaptKAN 能够提供与 KAN 和 MLP 类似的或更好的性能。此外，该方法还可以用于检测超分布输入，增强了网络的实用性。实验结果表明，AdaptKAN 在多个任务中均表现出色，验证了此创新方法的有效性和实际应用价值。"}
{"llm_update_time": "20251116", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.09492", "html_url": "https://arxiv.org/abs/2511.09492", "title": "通过随机森林提升密码安全性：基于高精度评分框架", "title_en": "Enhancing Password Security Through a High-Accuracy Scoring Framework Using Random Forests", "authors": "Muhammed El Mustaqeem Mazelan,Noor Hazlina Abdul,Nouar AlDahoul", "background": "传统密码强度检测器依赖于静态规则，如字符类型要求，容易被常见的弱密码模式（如'P@ssw0rd1!'）攻破，给用户一种虚假的安全感。", "innovation": "引入了一种新颖的混合特征工程方法，捕捉标准度量所忽视的细微漏洞，并通过随机森林模型实现99.12%的准确率。这种方法使用了诸如勒特取代归一化的熵、键盘行走和序列检测、以及基于泄漏密码数据集的字符级TF-IDF n-克隆特征，以评估真正的随机性和识别频繁重复的子字符串。", "conclusion": "研究填补了预测准确性和实际可用性之间的空白，形成了一套高性能的评分系统，不仅减少了基于密码的安全漏洞，还让用户做出了更明智的安全决策。"}
{"llm_update_time": "20251116", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.09231", "html_url": "https://arxiv.org/abs/2511.09231", "title": "使用大型语言模型从软件需求生成用例模型", "title_en": "Leveraging Large Language Models for Use Case Model Generation from Software Requirements", "authors": "Tobias Eisenreich,Nicholas Friedlaender,Stefan Wagner", "background": "用例建模通过用户中心的场景来概述系统需求，这有助于相关利益相关者达成共识。但是，手工创建用例模型既耗时又费力，因此在实践中经常被跳过。本文探讨了大型语言模型（LLMs）在这一繁琐过程中可能起到的帮助作用。研究团队提出的方法利用了具有开放权重的大规模语言模型，并结合高级提示工程技术，系统地从软件需求中提取角色和用例。研究通过与五名专业软件工程师进行探索性研究来进行评估，比较了传统的手动建模方法与提出的基于LLM的方法。研究结果表明，这种方法使建模时间降低了60%，同时保持了模型质量。此外，参与者表示这种方法在过程中提供了有用的指导。", "innovation": "提出的方法结合了具有开放权重的大规模语言模型，并通过高级提示工程技术系统地从软件需求中提取角色和用例，从而辅助手工过程，实现显著的效率提升，同时保持模型质量。这种方法在实践中具有较高的应用价值，能大大提高用例建模的效率。", "conclusion": "本研究通过引入大型语言模型在用例建模过程中的应用，实现了显著的时间节省，且模型质量保持不变。这种方法为软件需求分析与用例建模提供了一条高效的途径。未来的研究可以进一步探索模型在更多应用场景中的应用潜力。"}
{"llm_update_time": "20251116", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.09392", "html_url": "https://arxiv.org/abs/2511.09392", "title": "强大的但隐秘的：通过双层约束强化范式重新思考序贯推荐的配置文件污染", "title_en": "Potent but Stealthy: Rethink Profile Pollution against Sequential Recommendation via Bi-level Constrained Reinforcement Paradigm", "authors": "Jiajie Su,Zihan Nan,Yunshan Ma,Xiaobo Xia,Xiaohua Feng,Weiming Liu,Xiaolin Zheng,Chaochao Chen", "background": "序贯推荐系统利用用户的交互序列来推断动态意图，但这些系统容易受到对抗性攻击的影响。现有攻击主要依赖于数据污染，但需要大规模的用户访问或虚假资料，这在实际应用中缺乏可行性。现有的一些配置文件污染攻击（PPA）方法有两个主要限制：一是过度依赖序列窗口影响限制了对项目转移的细粒度干扰；二是整体修改导致可检测到的数据分布偏移。这些挑战对攻击的有效性和隐蔽性提出了挑战。", "innovation": "本文提出了一种受限的强化驱动攻击（CREAT），结合了双层优化框架和多奖励强化学习来平衡攻击的有效性和隐蔽性。首先，开发了一种模式平衡奖励策略，集成模式反转奖励和分布一致性奖励，通过不平衡联合最优运输来反转关键模式和最小化可检测偏移。其次，采用约束组相对强化学习范式，允许动态障碍约束下的逐步干扰并通过组共享的经验回放实现目标污染，同时最大限度减少可检测性。", "conclusion": "广泛的实验表明，CREAT在攻击有效性及隐蔽性方面具有显著优势。"}
{"llm_update_time": "20251116", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2511.09700", "html_url": "https://arxiv.org/abs/2511.09700", "title": "顺序很重要：重新思考在上下文学习中的提示构建", "title_en": "Order Matters: Rethinking Prompt Construction in In-Context Learning", "authors": "Warren Li,Yiqian Wang,Zihan Wang,Jingbo Shang", "background": "In-context learning (ICL) 允许大规模语言模型通过提供一个实例序列来执行新的任务。大多数先前的研究认为，所选的实例对性能的影响远大于实例的排序方式，因此集中在实例的选择上。", "innovation": "作者重新审视了这一假设，并进行了系统性的比较，得出了实例的选择和排序对性能影响相近的结论。通过控制实验，他们展示了仅使用开发集就可以识别出强有力的排序方式，从而接近最优排序的效果。", "conclusion": "作者的研究结果强调了实例选择和排序在提示设计中同等且交织的重要性，呼吁对 ICL 中的假设进行重新评估。"}
{"llm_update_time": "20251116", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.09057", "html_url": "https://arxiv.org/abs/2511.09057", "title": "PAN：一种用于通用、互动和长时跨域世界模拟的世界模型", "title_en": "PAN: A World Model for General, Interactable, and Long-Horizon World Simulation", "authors": "PAN Team Institute of Foundation Models:Jiannan Xiang,Yi Gu,Zihan Liu,Zeyu Feng,Qiyue Gao,Yiyan Hu,Benhao Huang,Guangyi Liu,Yichi Yang,Kun Zhou,Davit Abrahamyan,Arif Ahmad,Ganesh Bannur,Junrong Chen,Kimi Chen,Mingkai Deng,Ruobing Han,Xinqi Huang,Haoqiang Kang,Zheqi Li,Enze Ma,Hector Ren,Yashowardhan Shinde,Rohan Shingre,Ramsundar Tanikella,Kaiming Tao,Dequan Yang,Xinle Yu,Cong Zeng,Binglin Zhou,Zhengzhong Liu,Zhiting Hu,Eric P. Xing", "background": "智能体可以通过世界模型进行想象、预测和推理，以了解其行为如何影响世界的变化，从而规划和制定策略。最近的视频生成模型可以生成逼真的视频序列，但通常缺乏因果控制、交互性和长时间跨度的连贯性，这些都是进行目的性推理所需要的。现有的世界建模研究往往集中在物理、游戏或3D场景动力学等有限领域，这些模型难以在不同的环境中进行泛化和适应不同的互动形式。该论文介绍了PAN，一种通用的、可交互的、能够进行长时间跨域预测的世界模型，该模型基于历史和自然语言指令预测未来世界状态，通过结合生成式潜在预测（GLP）架构，该架构融合了一个基于大型语言模型（LLM）的自回归潜在动力学底层结构，并通过一段视频散度解码器（Video Diffusion Decoder），重建出感知上详细的、时空一致的视觉观察，实现潜在空间推理（想象）和可实现世界动力学（现实）的统一。PAN通过大规模视频-动作对进行训练，支持开放领域的、基于动作的模拟，并具有一致的、长期的动力学表现。实验结果表明，PAN在基于动作的场景模拟、长时间预报和模拟推理中表现优异，为预测未来世界状态进行推理和行为提供了一种解决方案，朝着通用世界模型迈进了一步。", "innovation": "PAN通过结合生成式潜在预测（GLP）架构，将基于大型语言模型（LLM）的自回归潜在动力学模型与视频散度解码器相结合，实现了长期跨域的预测。它能够支持开放领域、基于动作的模拟，并具有一致的、长期的动力学表现，显著提升了基于动作的世界模拟、长时预测和模拟推理的能力。此外，PAN能够结合语言指定的动作进行条件模拟，增强了模型的灵活性和跨域适应性。", "conclusion": "PAN是一种新型的世界模型，能够进行长时间的、跨领域的预测，支持开放领域的动作条件模拟，具有长时间连贯的动力学。该模型在动作条件下的世界模拟、长时预测和模拟推理中表现出色，朝着通用世界模型的发展方向迈进了一大步，为未来的智能感知和决策提供了有力支持。"}
{"llm_update_time": "20251116", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2511.09709", "html_url": "https://arxiv.org/abs/2511.09709", "title": "基于上下文的形态学导向分词技术在拉丁语编码模型中的应用", "title_en": "Contextual morphologically-guided tokenization for Latin encoder models", "authors": "Marisa Hudspeth,Patrick J. Burns,Brendan O'Connor", "background": "分词是语言模型预训练中的关键组件，但目前的标准分词方法往往侧重信息论目标如高压缩率和低生育率，而非像词形学对齐这样的语言学目标。这已经证明在富词形学语言中效果不佳，而在富词形学语言中，分词质量直接影响下游性能。本研究聚焦于拉丁语，这是一种富词形学语言但在预训练数据上是中等资源语言，但在编纂词库资源上是高资源的——这一区别经常被忽视但在低资源语言模型讨论中至关重要。", "innovation": "研究探索了基于形态学的拉丁语分词方法，从而提高了模型在四个下游任务上的整体性能，尤其是在领域外文本上的性能提升最为显著，表明模型具备更好的泛化能力。研究结果表明了语言资源用于改善富词形学语言的语言模型的实用性。对于缺乏大规模预训练数据的低资源语言，开发和整合语言资源可作为提升语言模型性能的有效替代方案。", "conclusion": "研究结果证实，使用形态学导向的分词技术可以有效提升语言模型在复杂词形语言中的性能，并且对于缺乏大规模预训练数据的低资源语言，开发和引入语言资源是非常实用的方法。"}
{"llm_update_time": "20251116", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2511.09690", "html_url": "https://arxiv.org/abs/2511.09690", "title": "跨语言ASR：1600多种语言的开源多语言语音识别", "title_en": "Omnilingual ASR: Open-Source Multilingual Speech Recognition for 1600+ Languages", "authors": "Omnilingual ASR team:Gil Keren,Artyom Kozhevnikov,Yen Meng,Christophe Ropers,Matthew Setzler,Skyler Wang,Ife Adebara,Michael Auli,Can Balioglu,Kevin Chan,Chierh Cheng,Joe Chuang,Caley Droof,Mark Duppenthaler,Paul-Ambroise Duquenne,Alexander Erben,Cynthia Gao,Gabriel Mejia Gonzalez,Kehan Lyu,Sagar Miglani,Vineel Pratap,Kaushik Ram Sadagopan,Safiyyah Saleem,Arina Turkatenko,Albert Ventayol-Boada,Zheng-Xin Yong,Yu-An Chung,Jean Maillard,Rashel Moritz,Alexandre Mourachko,Mary Williamson,Shireen Yates", "background": "自动语音识别（ASR）在资源丰富的语言中取得了进展，但世界上7000多种语言中的大多数仍然得不到支持，留下了许多长尾语言。扩展ASR覆盖范围的成本高昂，并且由于架构限制语言支持，使得扩展性对大多数人都不可及，且在没有社区合作的情况下推进这些问题时还伴随着伦理问题。", "innovation": "我们引入了跨语言ASR，这是第一个为可扩展性设计的大规模ASR系统。跨语言ASR允许社区仅通过少量数据演示样例引入未服务的语言。通过自我监督预训练扩展到7B参数，学习稳健的语音表示，并引入了一个编码器-解码器架构，旨在实现零样本泛化，借鉴了LLM的解码器设计理念。该模型通过结合广泛的覆盖范围和语言多样性进行训练，从而学习到足以适应未见过的语言的表示。将公共资源与社区为补偿合作伙伴收集的录音相结合，跨语言ASR将覆盖扩展到超过1600种语言，这一努力迄今为止是最广泛的覆盖范围，包括超过500种从未被ASR支持的语言。自动评估显示与先前系统相比取得了显著的提高，尤其是低资源条件下，具有很强的泛化能力。我们以从小型300M参数模型到最大7B参数模型的系列模型形式发布跨语言ASR，从小型设备到高性能都可适用。", "conclusion": "我们讨论了影响这些设计的伦理考虑，并展望了其社会影响。特别是，我们强调开源模型和工具如何降低研究人员和社区的参与壁垒，邀请新的参与形式。开源的工件可在以下链接获得：[公开资源链接]。"}
{"llm_update_time": "20251116", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2511.09812", "html_url": "https://arxiv.org/abs/2511.09812", "title": "Khmer拼写检查：一种综合方法", "title_en": "Khmer Spellchecking: A Holistic Approach", "authors": "Marry Kong,Rina Buoy,Sovisal Chenda,Nguonly Taing", "background": "与英语和其他资源丰富的语言相比，Khmer语言的拼写检查仍然是一个未解决的问题，这主要是由于几个挑战：词汇库和词切分模型之间的对齐不一致；Khmer词可以有不同的形式；Khmer复合词通常容易且松散地形成，这些复合词可能不在词汇库中；由于缺乏Khmer命名实体识别（NER）模型，一些专有名词可能会被错误地标记为拼写错误。现有的解决方案并未充分解决这些问题。", "innovation": "该论文提出了一种综合方法来解决Khmer拼写检查问题，通过整合Khmer子词切分、Khmer NER、Khmer音素到拼音（G2P）转换和Khmer语言模型来应对这些挑战，确定潜在的修正候选词，并最终对候选词进行排名。实验结果显示，该提出的解决方案在Khmer拼写检查方面达到了迄今为止最高的94.4%准确性。", "conclusion": "本文研究中用于Khmer拼写检查和NER任务的基准数据集将公开发布。"}
{"llm_update_time": "20251116", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2511.09738", "html_url": "https://arxiv.org/abs/2511.09738", "title": "评估自然语言处理在传统社会科学研究中的适用性：识别总统指令中的战略信号模式案例研究", "title_en": "Assessing the Applicability of Natural Language Processing to Traditional Social Science Methodology: A Case Study in Identifying Strategic Signaling Patterns in Presidential Directives", "authors": "C. LeMay,A. Lane,J. Seales,M. Winstead,S. Baty", "background": "我们的研究探讨了自然语言处理（NLP）如何被用于从大量书面数据中提取主要话题，特别是在识别里根到克林顿时期总统指令中的信号主题方面的方法。研究人员和NLP都识别了相关的文档，表明NLP在研究涉及大量书面资料方面具有潜在的应用价值。然而，也发现了NLP和人工标注结果之间的差异，这表明需要更多的研究来评估NLP在这一应用中的有效性。此外，由于人工智能和机器学习领域迅速发展，现有的工具已经得到改善，新的工具已开发，这显示了一项可能已经过时的AI工具在新兴的社会科学研究应用中的内在能力。", "innovation": "研究使用了自然语言处理技术来识别官方文件中的战略信号模式，并将AI工具的结果与人类标注进行了比较，以评估其在该领域的应用价值与局限性。这项工作展示了在传统社会科学研究中应用NLP的潜力和挑战。研究展示了即使AI技术不断发展，仍需进行进一步的研究来确保其在现实应用中的准确性和可靠性。", "conclusion": "尽管NLP在从大量文本数据中提取信息方面显示出巨大的潜力，但与人工标注相比仍存在一些差异，这表明需要更多的研究来验证AI的准确性和可靠性。此外，随着人工智能和机器学习领域的发展，新的工具和技术不断涌现，这为社会科学研究带来了更多机遇。"}
{"llm_update_time": "20251116", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2511.09748", "html_url": "https://arxiv.org/abs/2511.09748", "title": "How Small Can You Go? Compact Language Models for On-Device Critical Error Detection in Machine Translation", "title_en": "How Small Can You Go? Compact Language Models for On-Device Critical Error Detection in Machine Translation", "authors": "Muskaan Chopra,Lorenz Sparrenberg,Sarthak Khanna,Rafet Sifa", "background": "现有大语言模型（LLMs）在评估机器翻译（MT）方面表现优异，但是它们的规模和成本限制了在边缘设备和隐私敏感的工作流程中的部署。研究问题是如何在仍然能够检测到意义改变的翻译错误的同时，使模型变得更小？研究聚焦于英文到德文的关键错误检测（CED），并基于WMT21, WMT22和SynCED-EnDe-2025数据集，对模型进行评估。", "innovation": "该研究提出了一种标准化提示的方法，并应用了轻量级logit偏置校准和多数投票技术，同时报告了语义质量（MCC, F1-ERR/F1-NOT）和计算指标（显存要求, 延迟, 通过量）。结果发现，在参数量大约一亿时，能够实现最佳的质量效率平衡。这表明紧凑型指令调整的LLMs与轻量级校准结合，能够在不显著增加计算成本的情况下，提供有效的带设备关键错误检测（CED），并在实际翻译流水线中实现隐私保护和低成本错误筛查。", "conclusion": "总的来说，紧凑型、指令调优的语言模型与轻量级校准和小样本监督相结合，可以在设备上进行关键错误检测，从而在实际的翻译流程中实现私密性和低成本的错误筛选。所有数据集、提示和脚本都可以在作者的GitHub仓库中公开获取。"}
{"llm_update_time": "20251116", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2511.09803", "html_url": "https://arxiv.org/abs/2511.09803", "title": "TARG：无需训练的自适应检索门控机制用于高效的RAG", "title_en": "TARG: Training-Free Adaptive Retrieval Gating for Efficient RAG", "authors": "Yufeng Wang,Lu wei,Haibin Ling", "background": "检索增强生成（RAG）可以提高事实准确性，但每次查询都进行检索往往会损害质量，增加令牌数量并延长延迟。现有方法往往需要在每次查询时进行检索，从而增加了模型的复杂性和计算开销。", "innovation": "提出了一种无需训练的自适应检索门控机制（Training-free Adaptive Retrieval Gating，TARG），它仅使用基础模型的短、无上下文草案来决定何时进行检索。TARG 通过从草案的前缀中计算轻量级的不确定性分数（如均值 token 熵、top-1/top-2 对数概率差异的 margin 信号或小样本方差），如果分数超过阈值则触发检索。这种机制在多个数据集上表现出色，能够在减少检索次数和降低整体延迟的同时，保持甚至提高准确性和效率。", "conclusion": "TARG 实验结果显示，与始终进行检索的 RAG 方法相比，TARG 可以减少 70-90% 的检索次数并大幅降低端到端延迟，同时保持性能。此外，为了计算不确定性分数，TARG 使用的几种方法表明，在现代指令调优的大语言模型中，margin 信号是最稳健的选择，而小样本方差则提供了一种保守的预算优先替代方案。"}
{"llm_update_time": "20251116", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2511.09796", "html_url": "https://arxiv.org/abs/2511.09796", "title": "中文和英文平行句中的谓词-论元结构差异及其对语言传输的影响", "title_en": "Predicate-Argument Structure Divergences in Chinese and English Parallel Sentences and their Impact on Language Transfer", "authors": "Rocco Tripodi,Xiaoyu Liu", "background": "跨语言自然语言处理（NLP）近年来取得了显著进展，为资源稀缺的语言提供了实际解决方案，通过从资源丰富的语言向资源稀缺的语言转移语言知识。该领域利用注释投射和模型迁移等技术进行语言适应，依托多语言预训练语言模型。然而，语言间的差异阻碍了跨语言的迁移，尤其是在类型学差异较大的语言之间。本文分析了平行汉语和英语句子中的谓词-论元结构差异，探讨了谓词注释的对齐和错位，并提出了结构差异的分类方法。通过对投射注释实验结果进行定性和定量分析，证明了语言传输具有不对称性。这对选择源语言以应用于迁移学习时具有重要意义，必须在提出任何关于跨语言NLP的科学主张之前进行调查研究。", "innovation": "论文提出了谓词-论元结构差异的分类方法，并通过注释投射实验分析证明了语言传输的不对称性。这种分类方法有助于更好地理解不同语言间的结构差异，为跨语言NLP的应用提供了理论支持。此外，通过对平行汉语和英语句子的详细分析，发现了语言传输中的具体机制，为后续研究提供了新的视角。", "conclusion": "语言传输具有不对称性，不同语言间的结构差异需要在跨语言NLP的应用中引起注意。选择源语言时应充分考虑这些差异，以优化迁移效果。未来的跨语言NLP研究应深入探索不同类型语言间结构差异的具体表现及其对语言传输的影响机制。"}
{"llm_update_time": "20251116", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2511.09831", "html_url": "https://arxiv.org/abs/2511.09831", "title": "在课程论坛中利用多步骤推理和RAG增强的微调LLM回答学生问题", "title_en": "Answering Students' Questions on Course Forums Using Multiple Chain-of-Thought Reasoning and Finetuning RAG-Enabled LLM", "authors": "Neo Wang,Sonit Singh", "background": "课程论坛对于促进学生讨论和解答课程相关问题变得越来越重要且发挥着关键作用，为学生提供了一个发布问题和课程管理相关问题的平台。然而，随着选课学生数量的增加，存在一些挑战，主要是学生的问题无法立即得到回复，且教师需要回答大量的重复性问题。", "innovation": "为解决这些问题，作者提出了一种基于大型语言模型的检索增强生成（RAG）方法的问题回答系统。通过使用开源大型语言模型进行微调并且运用RAG方法，从本地知识库中检索相关的文档以回答学生的查询。为了减少模型的幻觉，作者将多步骤推理与模型结合来克服大型语言模型的幻觉挑战。实验结果表明，利用RAG方法微调后的LLM在问答任务上有很强的表现力。", "conclusion": "通过使用多步骤推理和RAG增强的微调LLM，能够有效地提高课程论坛中对学生问题的回答效率和准确度。"}
{"llm_update_time": "20251116", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2511.09819", "html_url": "https://arxiv.org/abs/2511.09819", "title": "通过识别技能缺口和基于职业兴趣推荐课程提高毕业生成果", "title_en": "Improving Graduate Outcomes by Identifying Skills Gaps and Recommending Courses Based on Career Interests", "authors": "Rahul Soni,Basem Suleiman,Sonit Singh", "background": "本文旨在解决为学生选择相关课程的挑战，通过设计和开发一门课程推荐系统。该系统利用数据分析技术和机器学习算法来推荐符合当前行业趋势和要求的课程，以提供定制化建议，结合机器学习方法、用户偏好和学术标准进行课程推荐，通过数据分析和协作过滤技术分析过往课程和个体职业目标，以提升系统对学生的适用性和吸引力。评测结果表明，所提系统能够有效满足目标使用者的需求和偏好，进而填补大学学习与行业期望之间的鸿沟，为学生、讲师和职业顾问提供终身学习和专业发展的工具，从而提升大学毕业生的成果。", "innovation": "该文章的创新之处在于提出了一种结合数据分析技术和机器学习算法的课程推荐系统，它可以根据当前行业趋势和用户的职业兴趣推荐相关课程。此外，系统前端设计注重直观性、交互性和简洁性，通过迭代原型设计和用户反馈不断优化，提供了一个用户友好的界面。", "conclusion": "所提出的课程推荐系统可以成为学生、讲师和职业顾问在促进终身学习和职业发展过程中有用的工具，通过填补大学教育与行业需求之间的差距，从而提高毕业生的就业成果。我们希望这项系统能帮助大学学生做出基于数据和行业洞察的课程决定，从而提升大学的整体毕业生成果。"}
{"llm_update_time": "20251116", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2511.09854", "html_url": "https://arxiv.org/abs/2511.09854", "title": "TermGPT：在法律和金融领域中术语适应的多级对比微调", "title_en": "TermGPT: Multi-Level Contrastive Fine-Tuning for Terminology Adaptation in Legal and Financial Domain", "authors": "Yidan Sun,Mengying Zhu,Feiyue Chen,Yangyang Wu,Xiaolei Dan,Mengyuan Yang,Xiaolin Zheng,Shenglin Ben", "background": "大型语言模型（LLMs）在文本生成任务中表现出色；然而，它们的嵌入空间通常存在各向同性问题，导致对特定领域的术语辨别能力较差，尤其是法律和金融领域的术语。这种术语层面表示的弱点严重影响了法律判决预测或金融风险分析等下游任务，因为它们依赖于细微的语义区别。为解决此问题，该研究提出了TermGPT，一种用于术语适应的多级对比微调框架。通过构建句子图来捕捉语义和结构关系，并根据上下文和拓扑线索生成语义一致但有区别的正负样本。然后，设计了一个多级对比学习方法，涵盖句子和token层面，增强全局语境理解和细粒度的术语辨别能力。为了支持稳健的评估，构建了首个源自官方监管文件的金融术语数据集。实验结果表明，TermGPT在金融和法律领域的术语差异任务中明显优于现有基线。", "innovation": "提出了一种用于术语适应的多级对比微调框架TermGPT。该方法包括构建句子图以捕捉语义和结构关系，产生语义一致但有区别的正负样本，以及在句子和token层面设计多级对比学习方法，以增强全球语境理解和细粒度术语辨别能力。还构建了首个依据官方监管文件的金融术语数据集，支持稳健评估。", "conclusion": "实验表明，TermGPT在金融和法律领域内的术语区分任务中表现出色，能够有效提升术语的辨别能力，超越现有基线模型。"}
{"llm_update_time": "20251116", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2511.09865", "html_url": "https://arxiv.org/abs/2511.09865", "title": "In-Token Rationality Optimization: Through自我反馈提升准确简洁的大语言模型推理", "title_en": "In-Token Rationality Optimization: Towards Accurate and Concise LLM Reasoning via Self-Feedback", "authors": "Mingye Zhu,Yi Liu,Zheren Fu,Quan Wang,Yongdong Zhang", "background": "训练大规模语言模型（LLMs）进行链式推理面临着显著挑战：监督微调在单一‘正确’推理上会导致泛化能力下降，因为这惩罚了同样合理的替代方案；而使用可验证奖励的强化学习则在归因和计算成本上面临困难。", "innovation": "提出了一种新的框架InTRO（In-Token Rationality Optimization），该框架允许在token级别进行探索并提供自我反馈，从而实现准确简洁的推理。InTRO通过使用生成策略与其问题条件版本之间的信息差异来估计token的重要性权重，进行有信息性的下一个token选择。这种方法使模型在单次前向传递中进行token级别的探索并接收自动生成的反馈，最终促进准确且简洁的推理。", "conclusion": "在六个数学推理基准测试中，InTRO在解决方案准确性上表现出色，相对于基础模型提高了高达20%，并且其推理步骤更为简洁。此外，InTRO还能够实现跨领域转移，成功适应超出数学领域的推理任务，展现出强大的泛化能力。"}
{"llm_update_time": "20251116", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2511.09873", "html_url": "https://arxiv.org/abs/2511.09873", "title": "HierRouter: 通过强化学习协调专业化大规模语言模型的路由", "title_en": "HierRouter: Coordinated Routing of Specialized Large Language Models via Reinforcement Learning", "authors": "Nikunj Gupta,Bill Guo,Rajgopal Kannan,Viktor K. Prasanna", "background": "大规模语言模型（LLMs）在众多任务中表现出色，但同时也带来了高计算和内存成本，这限制了它们在资源受限或实时环境中的部署。", "innovation": "提出了一种名为HierRouter的分层路由方法，该方法动态从一组轻量级的专业化语言模型中组装推理管道。该方法通过有限时间窗口的马尔可夫决策过程（MDP）来训练一个基于Proximal Policy Optimization (PPO) 的强化学习代理，该代理能够在多跳推理的每个阶段选择要调用的模型。代理基于不断变化的上下文和累积成本做出面向上下文的路由决策。", "conclusion": "实验结果表明，使用HierRouter可以将响应质量提高2.4倍，相比单独使用模型，在平均推理成本上只增加了少量开销。这些结果突显了分层路由在高效、高精度LLM推理中的前景。"}
{"llm_update_time": "20251116", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2511.09935", "html_url": "https://arxiv.org/abs/2511.09935", "title": "利用大型语言模型识别知识组件", "title_en": "Leveraging Large Language Models for Identifying Knowledge Components", "authors": "Canwen Wang,Jionghao Lin,Kenneth R. Koedinger", "background": "知识组件（KCs）对于自适应学习系统至关重要，但它们的手工识别由领域专家完成是一个重大瓶颈。虽然大型语言模型（LLMs）为自动化这一过程提供了希望，但此前的研究大多局限于小数据集，并产生了不必要的重复KCs标签。", "innovation": "本研究通过将模拟教科书LLM提示策略扩展到646个多选题的数据集解决了这些限制。我们提出并评估了一种根据余弦相似度合并语义相似的KCs标签的新方法，显著提高了模型性能。利用余弦相似度阈值0.8的方法取得了最佳结果，减少了KCs数量至428，将RMSE提高到0.4259。这表明单独扩展LLM生成是不够的，结合语义合并技术为自动化和细化KCs识别提供了一条可行路径。", "conclusion": "本研究展示了通过使用大型语言模型和语义合并技术，可以在一定程度上自动化和精炼KCs识别过程。"}
{"llm_update_time": "20251116", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2511.09880", "html_url": "https://arxiv.org/abs/2511.09880", "title": "EnchTable：微调大型语言模型中的统一安全性对齐转移", "title_en": "EnchTable: Unified Safety Alignment Transfer in Fine-tuned Large Language Models", "authors": "Jialin Wu,Kecen Li,Zhicong Huang,Xinfeng Li,Xiaofeng Wang,Cheng Hong", "background": "许多机器学习模型是从大型语言模型（LLMs）微调而来的，以在代码生成、生物医学分析和数学问题解决等专门领域中实现高性能。然而，这一微调过程往往会导致一个重要问题：安全性对齐的系统性降级，这破坏了伦理准则并增加了有害输出的风险。 EnchTable 提出了一种新框架，旨在在下游LLM中传输和维护安全性对齐，而无需进行广泛的重新训练，以解决该挑战。", "innovation": "EnchTable 引入了一种基于神经函数切线核（NTK）的安全向量提取方法，确保了从安全约束中解耦任务特定推理的兼容性，适用于各种模型结构和规模。此外，它还采用了干扰感知合并技术，有效平衡了安全性和实用性，尽可能降低不同任务领域中的性能妥协。研究表明，EnchTable 在各种部署管道中都具有无缝集成的能力，并且在应对来自不同供应商的LLMs时展示了泛化能力。", "conclusion": "EnchTable 在抵御静态和动态逃逸攻击方面表现出强大的鲁棒性，相对于供应商提供的安全模型，能更有效对抗对抗性提示。对比分析表明，与六种参数修改方法和两种推理时校准基准相比，EnchTable 实现了更低的不利率，更高的实用性评分，并具有跨领域的一致适用性。"}
{"llm_update_time": "20251116", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2511.09918", "html_url": "https://arxiv.org/abs/2511.09918", "title": "MINDS：一种用于社会规范分类与遵守检测的跨文化对话语料库", "title_en": "MINDS: A Cross-cultural Dialogue Corpus for Social Norm Classification and Adherence Detection", "authors": "Pritish Sahu,Anirudh Som,Dimitra Vergyri,Ajay Divakaran", "background": "社会规范是文化和背景驱动的隐含期望，指导人际交流。以往的工作为非事实常识性规范推理提供了有价值的注释，但主要针对孤立的陈述或合成对话，限制了它们捕捉现实生活对话中多轮次的流动性质的能力。", "innovation": "本文提出了Norm-RAG（一种检索增强的、有主动性的框架），用于在多轮对话中进行细致的社会规范推理。Norm-RAG模型每个句子的属性，如沟通意图、说话人角色、人际框架和语言线索，并通过一种新颖的语义分块方法将它们与结构化的规范性文档关联起来。这使得跨多种语言对话可以进行可解释且情境感知的规范遵守和违反推理。此外，引入了MINDS（跨文化互动的以规范驱动的语音），一个双语数据集，包含31个双向的普通话-英语和西班牙语-英语对话，每个对话轮次都进行了规范类别和遵守状态的多注释者一致注释，反映出跨文化和现实中的规范表达。", "conclusion": "实验表明，Norm-RAG在规范检测和泛化方面有所改进，并展示了更好地适应文化特性和社会智能对话系统的性能。"}
{"llm_update_time": "20251116", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2511.09966", "html_url": "https://arxiv.org/abs/2511.09966", "title": "REAP: 使用递归评估和适应性规划提升RAG多跳问答", "title_en": "REAP: Enhancing RAG with Recursive Evaluation and Adaptive Planning for Multi-Hop Question Answering", "authors": "Yijie Zhu,Haojie Zhou,Wanting Hong,Tailin Liu,Ning Wang", "background": "Retrieval-augmented generation (RAG) 方法被广泛应用于减轻大型语言模型（LLMs）中的幻觉。然而，现有的多跳推理任务方法通常缺乏全局规划，容易陷入局部推理障碍。提取的外部内容利用不足以及潜在线索忽略，无法保证推理结果的准确性。因此，我们需要提出一种新的方法来解决这些限制问题。", "innovation": "我们提出了递归评估和适应性规划（REAP），其核心思想是借助子任务规划器（SP）和事实提取器（FE）模块显式地维护当前任务相关的结构化子任务和事实。SP 维护全局视角，指导总体推理方向并根据FE输出评估任务状态，实现动态优化任务解决路径。FE对检索内容进行细致分析，提取可靠答案和线索，进一步丰富知识表示并提高推理过程的可靠性和可追溯性。此外，我们提出了一种统一的任务范式设计，能够高效地进行多任务微调，显著提升SP在复杂、数据稀少任务上的表现。", "conclusion": "我们在多个公共多跳数据集上进行了广泛实验，结果表明我们的方法在领域内外均显著优于现有的RAG方法，证明了其在复杂多跳推理任务中的有效性。"}
{"llm_update_time": "20251116", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2511.09971", "html_url": "https://arxiv.org/abs/2511.09971", "title": "NumPert: 通过数值扰动探测语言模型的论断预测准确性", "title_en": "NumPert: Numerical Perturbations to Probe Language Models for Veracity Prediction", "authors": "Peter Røysland Aarnes,Vinay Setty", "background": "大型语言模型在知识密集型任务如事实核查和问答中表现出色，但在数值推理方面常常出现问题。本文通过使用控制扰动进行系统评估，包括标签反转探针测试，以测试模型在应对不同条件下的鲁棒性。研究表明，在某些扰动条件下，即使是最先进的专有系统准确率也会下降多达62%。没有任何模型能够在所有条件下证明其鲁棒性。此外，研究发现扩展上下文长度通常会降低准确率，但在扩展上下文中加入扰动示范后，大多数模型表现显著改善。这些发现揭示了数值事实核查中的关键局限，表明当前语言模型在鲁棒性方面仍存在开放挑战。", "innovation": "本文通过使用控制扰动进行系统评估，包括标签反转探针测试，以测试模型在应对不同条件下的鲁棒性。研究表明，在某些扰动条件下，即使是最先进的专有系统准确率也会下降多达62%。没有任何模型能够在所有条件下证明其鲁棒性。此外，研究发现扩展上下文长度通常会降低准确率，但在扩展上下文中加入扰动示范后，大多数模型表现显著改善。", "conclusion": "这些发现揭示了数值事实核查中的关键局限，表明当前语言模型在鲁棒性方面仍存在开放挑战。"}
{"llm_update_time": "20251116", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2511.09915", "html_url": "https://arxiv.org/abs/2511.09915", "title": "HI-TransPA: 听力障碍翻译个人助理", "title_en": "HI-TransPA: Hearing Impairments Translation Personal Assistant", "authors": "Zhiming Ma,Shiyu Gan,Junhao Zhao,Xianming Li,Qingyun Pan,Peidong Wang,Mingjun Pan,Yuhao Mo,Jiajie Cheng,Chengxin Chen,Zhonglun Cao,Chonghan Liu,Shi Cheng", "background": "为了为听力受损个体提供统一且灵活的日常交流解决方案，本文将Omni-Model paradigm引入辅助技术，并提出了由指令驱动的视听个人助理HI-TransPA。此模型将模糊语音与高帧率唇动融合在一起，实现了在同一多模态框架内的翻译和对话。为了应对嘈杂和异构的原始数据以及现有Omni-Model对听力受损语音有限的适应性，本文构建了一个全面的预处理和纂修管道，该管道能够检测面部特征、隔离和稳定唇部区域并量化多模态样本质量。这些质量评分指导一种课程学习策略，该策略首先在干净且高置信度的样本上进行训练，然后逐渐引入更难的案例以增强模型的鲁棒性。进一步采用了SigLIP编码器和统一的3D重采样器来高效编码高帧率的唇动。", "innovation": "本文创新之处在于引入Omni-Model paradigm打造индивидуальный помощник для слежения за переводом (HI-TransPA) 并提出了一个由指令驱动的视听个人助理，融合了模糊语音与高帧率唇动，实现了在同一多模态框架内的翻译和对话。为了应对数据挑战，提出了一个综合的预处理和体系结构，包括面部特征检测、唇部区域隔离和稳定化、多模态样本质量量化，以及引导课程学习策略。此外，采用了SigLIP编码器与统一的3D重采样器来高效地编码高帧率唇动。", "conclusion": "实验结果显示，HI-TransPA在HI-Dialogue数据集上实现了字面精度和语义准确性的最好性能。本研究为将Omni-Models应用于辅助通信技术奠定了基础，提供了端到端的建模框架和必需的前期处理工具，为未来研究提供了重要支持。"}
{"llm_update_time": "20251116", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2511.09980", "html_url": "https://arxiv.org/abs/2511.09980", "title": "动态RAG中的及时检索不确定性趋势建模", "title_en": "Modeling Uncertainty Trends for Timely Retrieval in Dynamic RAG", "authors": "Bo Li,Tian Tian,Zhenghua Xu,Hao Cheng,Shikun Zhang,Wei Ye", "background": "动态检索增强生成（Dynamic Retrieval-Augmented Generation, Dynamic RAG）允许大型语言模型在需要时检索外部知识，提供了比静态RAG更大的适应性。然而，一个核心挑战在于确定检索的最佳时机。现有方法常常基于低token级置信度触发检索，这可能导致错误已经传播后延迟干预。因此，需要一种能够更早、更精确地捕捉不确定性趋势，从而优化检索时机的方法。", "innovation": "本文提出了熵趋势约束（Entropy-Trend Constraint, ETC），这是一种无需训练的方法，通过建模token级不确定性动态来确定最佳检索时机。具体来说，ETC利用熵序列的一阶和二阶差分来检测新兴不确定性趋势，从而实现更早和更精确的检索。实验结果显示，ETC在六个问答基准测试中的一致性能优于强基线，同时降低了检索频率。ETC特别适用于特定领域场景，显示出较强的泛化能力。消融研究和定性分析进一步证实，具有趋势意识的不确定性建模可以提供更有效的检索时机。该方法是插即用、模型无关且易于集成到现有解码管道中。相关实现代码在补充材料中提供。", "conclusion": "熵趋势约束（ETC）是一种无需训练的方法，能够通过建模token级不确定性动态来确定最佳检索时机，从而实现更早、更精确的检索。实验结果表明ETC在多个问答基准测试中优于基线方法，并且特别适用于特定领域场景。该方法是插即用、模型无关且易于集成到现有解码管道中。"}
{"llm_update_time": "20251116", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2511.09997", "html_url": "https://arxiv.org/abs/2511.09997", "title": "FinNuE：揭示在金融领域使用BERTScore进行数值语义评估的风险", "title_en": "FinNuE: Exposing the Risks of Using BERTScore for Numerical Semantic Evaluation in Finance", "authors": "Yu-Shiang Huang,Yun-Yu Lee,Tzu-Hsin Chou,Che Lin,Chuan-Ju Wang", "background": "BERTScore已经成为评估自然语言句子间语义相似性的广泛采用指标。然而，研究发现BERTScore对数值变化的敏感性较低，这在金融领域是一个重大弱点，因为数值精确度直接影响含义（例如，区分2%的收益和20%的损失）。", "innovation": "本文引入了FinNuE，这是一个通过在财报电话会议、监管文件、社交媒体和新闻文章中引入可控数值扰动构建的诊断数据集。使用FinNuE证明了BERTScore无法区分语义上关键的数值差异，经常将财务上截然不同的文本对赋予高相似度评分。本文揭示了基于嵌入的指标在金融领域中的根本局限，并激发了金融NLP中具有数值意识的评估框架的需求。", "conclusion": "研究发现表明，基于嵌入的度量标准在金融领域存在根本局限，因此强调了需要开发具有数值敏感性的金融NLP评估框架。"}
{"llm_update_time": "20251116", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2511.09984", "html_url": "https://arxiv.org/abs/2511.09984", "title": "多语言检索增强生成中的语言漂移：表征与解码时缓解", "title_en": "Language Drift in Multilingual Retrieval-Augmented Generation: Characterization and Decoding-Time Mitigation", "authors": "Bo Li,Zhenghua Xu,Rui Xie", "background": "多语言检索增强生成（RAG）让大型语言模型（LLMs）在多语言环境中执行知识密集型任务，通过利用检索到的文档作为外部证据。然而，当检索到的证据与用户查询和上下文示例的语言不同，模型往往会由于生成不受意的语言而出现语言漂移，尤其是在需要推理的解码过程中，如chain-of-thought（CoT）生成，其中中间步骤会进一步引入语言不稳定。本文通过在多个数据集、多种语言和不同的LLM架构上系统研究了多语言RAG中的输出语言漂移", "innovation": "研究表明，语言漂移不是理解失败的结果，而是解码器级别的崩溃，其中主要的令牌分布和高频英语模式主导了目标生成语言。观察到在跨语言条件下英语作为语义吸引子，既是最重要的干扰源也是最常见的退化语言。为缓解这一问题，我们提出了软约束解码（SCD）策略，这是一种无需训练的解码策略，通过惩罚非目标语言的令牌柔和地引导生成向目标语言靠拢。SCD适用于任何生成算法且无需修改架构或额外数据。实验结果表明SCD能够一致地提高语言对齐和任务性能，提供了一个有效和可推广的解决方案", "conclusion": "实验结果表明，软约束解码（SCD）可以有效地缓解多语言RAG中的语言漂移现象，提高语言对齐和任务性能，为多语言RAG提供了一种通用的解决方案。\n"}
{"llm_update_time": "20251116", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2511.10002", "html_url": "https://arxiv.org/abs/2511.10002", "title": "PustakAI：使用大规模语言模型设计和评估符合课程标准的交互式电子课本", "title_en": "PustakAI: Curriculum-Aligned and Interactive Textbooks Using Large Language Models", "authors": "Shivam Sharma(1),Riya Naik(1),Tejas Gawas(1),Heramb Patil(1),Kunal Korgaonkar(1) ((1) CSIS Department, BITS Pilani K K Birla Goa Campus, India)", "background": "大规模语言模型（LLMs）在理解和生成人类内容方面表现出色，已经革命性地改变了医疗保健、软件开发和教育等各个领域。在教育领域，LLMs 为个性化和互动学习体验提供了潜力，尤其是在资源有限的教学地区。然而，有效将这些模型应用于特定学科的课程内容（如印度国家教育研究与培训委员会NCERT的课程标准），在准确度、对齐性和教学相关性方面面临独特的挑战。", "innovation": "本文介绍了一种名为PustakAI（Pustak在许多印度语言中意为“书”）的框架，用于设计和评估与NCERT课程标准对齐的英语和自然科学科目（6至8年级）的新型问答数据集“NCERT-QA”。通过对问答对进行事实、推理和评价（评价性和推理性）分类，使用各种提示技术（元提示、少量提示和基于CoT的提示）进行评估，旨在理解哪种方法能更高效地与课程结构和需求相匹配。此外，还分析了当前开源LLMs（Gemma3:1b、Llama3.2:3b和Nemotron-mini:4b）和高端LLMs（Llama-4-Scout-17B和Deepseek-r1-70B）作为基于AI的教育工具的优势与局限。", "conclusion": "本文展示了使用PustakAI框架设计和评估符合NCERT课程标准的新型问答数据集“NCERT-QA”，并分析了不同LLM模型作为AI教育工具的优势和局限，为进一步促进个性化和互动教育提供了新的思路。"}
{"llm_update_time": "20251116", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2511.10070", "html_url": "https://arxiv.org/abs/2511.10070", "title": "ADI-20：阿拉伯语方言识别数据集和模型", "title_en": "ADI-20: Arabic Dialect Identification dataset and models", "authors": "Haroun Elleuch,Salima Mdhaffar,Yannick Estève,Fethi Bougares", "background": "本文介绍了ADI-20，它是在之前发布的ADI-17阿拉伯语方言识别（ADI）数据集的基础上进行扩展的。ADI-20覆盖了所有阿拉伯国家的方言，并且包括现代标准阿拉伯语（MSA）。文章使用这个数据集来训练和评估了多种最新的ADI系统。", "innovation": "文中研究了针对预训练ECAPA-TDNN模型的微调，以及Whisper编码器块结合注意力池化层和分类密集层的应用效果；此外，还探讨了训练数据集大小和模型参数数量对识别性能的影响。研究结果表明，即使使用原始训练数据的30%，F1分数也只有小幅下降。研究人员开源了收集的数据和训练模型，以便于后续研究和重复实验。", "conclusion": "研究展示了在减少训练数据集和模型复杂度的条件下，仍旧保持了较高的识别性能。开源的数据和模型将支持未来的相关研究。"}
{"llm_update_time": "20251116", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2511.10029", "html_url": "https://arxiv.org/abs/2511.10029", "title": "ScaleFormer: Span Representation Cumulation for Long-Context Transformer", "title_en": "ScaleFormer: Span Representation Cumulation for Long-Context Transformer", "authors": "Jiangshu Du,Wenpeng Yin,Philip Yu", "background": "标准的自注意力机制在Transformer模型中的复杂度限制了它们在长上下文任务中的应用。尽管存在高效变种的Transformer，但它们通常需要架构变化和从头开始的昂贵预训练。为了克服这些问题，提出了ScaleFormer框架，该框架继承了预训练的编码器-解码器模型，能够处理长序列而不必进行架构修改。这种方法将长输入分割为重叠的片段，并生成解码器的压缩、上下文感知表示。", "innovation": "核心创新在于一种新的、无参数融合机制，赋予每个片段的表示以文档内位置结构意识。通过融合所有先前和后续片段的累积上下文向量，增强每个片段边界表示，确保模型具有文档叙事流的强信号。该策略实现了线性复杂性，使得预训练模型能够有效地处理长文档文本，且不需要架构修改或外部检索机制。", "conclusion": "实验结果表明，该方法在长文档摘要任务中表现高度竞争，且经常优于最先进的方法，无需进行架构修改或外部检索机制。"}
{"llm_update_time": "20251116", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2511.10090", "html_url": "https://arxiv.org/abs/2511.10090", "title": "ELYADATA & LIA在2025 NADI比赛中的ASR和ADI子任务", "title_en": "ELYADATA & LIA at NADI 2025: ASR and ADI Subtasks", "authors": "Haroun Elleuch,Youssef Saidi,Salima Mdhaffar,Yannick Estève,Fethi Bougares", "background": "本文描述了Elyadata与LIA联合提交的2025 NADI多方言阿拉伯语言处理竞赛的参赛内容。他们参加了有声阿拉伯方言识别（ADI）和多方言阿拉伯ASR子任务的比赛", "innovation": "他们的ADI系统是使用数据增强对 Whisper-large-v3 编码器进行微调。对于多方言阿拉伯ASR，他们分别对每种方言对 SeamlessM4T-v2 Large (埃及变体) 进行了微调。结果展示了针对阿拉伯语言处理的大规模预训练语音模型的有效性与针对性微调的效果", "conclusion": "他们在这个任务中，在ADI子任务中排名第一，在多方言阿拉伯ASR子任务中排名第二。ADI系统在官方测试集上的最高识别准确率为79.83%，多方言阿拉伯ASR的平均WER和CER分别为38.54%和14.53%。"}
{"llm_update_time": "20251116", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2511.10045", "html_url": "https://arxiv.org/abs/2511.10045", "title": "语言模型是否会将声音与意义关联起来？一种多模态的语言音义关联研究", "title_en": "Do Language Models Associate Sound with Meaning? A Multimodal Study of Sound Symbolism", "authors": "Jinhong Jeong,Sunghyun Lee,Jaeyoung Lee,Seonah Han,Youngjae Yu", "background": "音义关联是语言学中的概念，指的是音素形式与其意义之间非任意的关联。本文探讨了多模态大型语言模型（MLLMs）如何解释人类语言中的听觉信息，并研究了这些模型在文本（拼写和音标）和听觉输入形式下，对于多达25个语义维度（如锐利 vs 圆润）的音节音义关联的处理能力。通过测量音节级别的注意力分数，作者分析了模型的层级信息处理。研究使用了一个包含8052个单词（来自英语、法语、日语和韩语）和2930个系统构建的伪词的广泛拟声词数据集（LEX-ICON），每个单词都标注了跨文字和音频模态的语义特征。", "innovation": "本文展示了MLLMs在多个语义维度上与现有语言研究的音义直觉一致性，并揭示了模型在音义关联时对拟声音素的关注模式。这是首次从可解释性的角度对MLLMs的音义关联进行大规模定量分析，连接了人工智能领域与认知语言学领域。", "conclusion": "研究结果表明MLLMs在音义关联上有一定的理解能力，并且对拟声音素有显著的注意力集中，这为认知语言学和人工智能之间的交叉研究提供了新视角。"}
{"llm_update_time": "20251116", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2511.10051", "html_url": "https://arxiv.org/abs/2511.10051", "title": "GraphIF: 使用关系图提示增强大型语言模型的多轮指令跟随", "title_en": "GraphIF: Enhancing Multi-Turn Instruction Following for Large Language Models with Relation Graph Prompt", "authors": "Zhenhe Li,Can Lin,Ling Zheng,Wen-Da Wei,Junli Liang,Qi Song", "background": "多轮指令跟随是构建能够一致遵循指令的智能对话系统的关键。目前，增强多轮指令跟随的方法主要依赖于收集或生成大规模多轮对话数据集来微调大规模语言模型（LLMs），这些方法将每次响应生成视为一个孤立的任务，未能明确将多轮指令跟随融入优化目标。因此，指令调整后的LLMs常常难以处理复杂的长距离约束。在多轮对话中，跨轮次的关系约束自然可以建模为标记的有向边，使图结构特别适合建模多轮指令跟随。但是，目前尚未利用图结构来增强LLMs的多轮指令跟随能力。", "innovation": "提出了一个即插即用框架GraphIF，通过将多轮对话建模为有向关系图并利用图提示来增强LLMs的指令跟随能力。GraphIF包含三个关键组件：基于代理的关系抽取模块、关系图提示生成模块和响应重写模块。该框架利用动作触发机制捕获跨轮次的语义关系来构造结构化的图，将结构化的图信息转换为自然语言提示，并使用生成的图提示来优化LLMs的初始输出。实验结果表明，GraphIF可以无缝集成到指令调整后的LLMs中，并在所有四个多轮指令遵循评估指标上取得了显著改进。", "conclusion": "通过实验验证了GraphIF在两个长多轮对话数据集上的有效性，证明其可以无缝集成到指令调整后的LLMs中，显著提高了LLMs的多轮指令跟随能力。"}
{"llm_update_time": "20251116", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2511.10093", "html_url": "https://arxiv.org/abs/2511.10093", "title": "大型语言模型在军事应用方面的研究", "title_en": "On the Military Applications of Large Language Models", "authors": "Satu Johansson,Taneli Riihonen", "background": "本文探讨了自然语言处理和大型语言模型在军事用途中的应用和实施背景，特别是在生成式预训练变压器（GPT）的发明和OpenAI为ChatGPT和其他项目进行的广泛基础模型预训练之后，这些模型已崭露头角。研究从两个方面进行：首先，对基于GPT的语言模型（如Microsoft Copilot）进行了调查，以揭示其潜在的军事应用并对其进行批评性评估；其次，研究了商业云服务（如Microsoft Azure）如何便于构建此类应用，并评估哪些应用是切实可行的。研究表明，语言模型的总结和生成属性直接促进了多种应用的发展，而其他特性可能具有特定的应用价值。", "innovation": "本文创新性地探讨了大型语言模型在军事应用中的可能性和可行性，并通过调查和评估蚂蚁构建特定军事应用的潜力", "conclusion": "本文总结指出，语言模型的总结和生成属性广泛适用于许多应用，而其他特性亦有可能发现特定用途。通过使用商业云服务，可以有效地构建和部署这些应用。"}
{"llm_update_time": "20251116", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2511.10120", "html_url": "https://arxiv.org/abs/2511.10120", "title": "未知灾难事件中的一致性视角：基于因果关系的方法", "title_en": "Generalizing to Unseen Disaster Events: A Causal View", "authors": "Philipp Seeberger,Steffen Freisinger,Tobias Bocklet,Korbinian Riedhammer", "background": "随着社交媒体平台的快速发展，这些工具已成为在灾难事件发生时监控信息的必备工具。然而，提取有价值的观点需要实时处理大量的数据。现有系统的主要挑战是对事件相关的偏见的敏感性，这不利于其对未来事件的泛化能力。虽然最近在去偏见和因果学习方面的突破提供了有希望的解决方案，但这些方法在灾难事件领域仍然没有得到充分探索。", "innovation": "本文通过因果视角来减轻偏见，并提出了一种减少事件和领域相关偏见的方法，以提高对未来事件的泛化能力。与多个基线相比，该方法在F1分数上高出至多+1.9%，并显著提高了基于PLM的分类器在三个灾难分类任务中的性能。", "conclusion": "我们的方法在三个灾难分类任务上均优于多个基线，显著提升了基于PLM的分类器的性能。这种方法通过因果视角来减轻偏见，有助于减少事件相关和领域相关偏见，从而提高模型对未来事件的泛化能力。"}
{"llm_update_time": "20251116", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2511.10075", "html_url": "https://arxiv.org/abs/2511.10075", "title": "格式很重要：表格和图表证据审查中多模态大语言模型的稳健性", "title_en": "Format Matters: The Robustness of Multimodal LLMs in Reviewing Evidence from Tables and Charts", "authors": "Xanh Ho,Yun-Ang Wu,Sunisth Kumar,Florian Boudin,Atsuhiro Takasu,Akiko Aizawa", "background": "随着提交的科学论文数量不断增加，对能够协助评审员评估研究主张的系统的刚性需求也在增长。实验结果是科学工作的重要组成部分，常以表格或图表等形式呈现。目前，了解当前多模态大语言模型（多模态LLM）在多种证据格式下验证科学主张的鲁棒性仍然是一个有待深入调查的重要挑战。本文旨在评估多模态LLM利用表格和图表证据验证科学研究声明的能力，为此，作者通过修改现有数据集，加入了多模态声明验证任务所需的注释和结构，利用此数据集比较了12个当前多模态LLM的表现。实验发现，现有模型在表格证据方面表现更好，但在图表证据方面遇到困难。此外，人工评估结果显示，在两种格式之间，人类保持了较好的表现，而模型则表现不佳。作者分析还发现，规模较小的多模态LLM（低于8B）在表格任务和图表任务之间表现出弱相关性，表明其在跨模态推理方面存在局限性。这些发现揭示了当前模型在多模态推理能力方面的关键差距，指出了未来需改进的方向，即强调提升对图表的理解能力，以更好地支持科学声明验证。", "innovation": "1. 设计和执行实验评估多模态LLM在利用表格和图表证据验证科学声明时的能力。\n2. 提供了通过修改现有数据集的方法，以适应多模态声明验证任务的需求。\n3. 发现当前多模态LLM在表格证据上的表现优于图表证据，且小型多模态LLM在两种任务间表现的相关性较弱，强调了其跨模态推理能力的局限性。", "conclusion": "当前多模态LLM在表格证据方面表现良好，但在图表证据方面存在困难。模型在跨模态推理上存在局限性，未来的多模态LLM应加强图表理解能力以支持科学主张的验证。"}
{"llm_update_time": "20251116", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2511.10182", "html_url": "https://arxiv.org/abs/2511.10182", "title": "超越黑盒：VISTA 解密多轮 LLM 推理", "title_en": "Beyond the Black Box: Demystifying Multi-Turn LLM Reasoning with VISTA", "authors": "Yiran Zhang,Mingyang Lin,Mark Dras,Usman Naseem", "background": "近期研究越来越多地关注大型语言模型（LLMs）在多轮对话中的推理能力，这类情景更接近现实世界的问题解决方式。然而，分析这些交互中的复杂推理过程因其复杂的上下文依赖性和缺乏专门的可视化工具，给研究者带来较大的认知负担。", "innovation": "本文介绍了一种名为 VISTA 的基于网络的可视化交互系统，用于多轮推理任务中的文本分析。VISTA 允许用户可视化背景对模型决策的影响，交互式地修改对话历史，进行“如果-则”分析，并且可以自动生成推理依赖树，提供模型逐步逻辑路径的透明视图。通过提供统一且交互的框架，VISTA 显著降低了分析推理链的复杂性，从而促进了对当前 LLMs 能力和局限的深入理解。该平台是开源的，支持集成自定义基准和本地模型。", "conclusion": "本文提出的 VISTA 平台显著降低了多轮 LLM 推理分析的复杂性，提供了对模型推理过程更直观、透明的理解，从而促进研究者对 LLMs 的深入理解与应用。"}
{"llm_update_time": "20251116", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2511.10215", "html_url": "https://arxiv.org/abs/2511.10215", "title": " Persona-Aware Alignment Framework for Personalized Dialogue Generation ", "title_en": "Persona-Aware Alignment Framework for Personalized Dialogue Generation", "authors": "Guanrong Li,Xinyu Liu,Zhen Wu,Xinyu Dai", "background": "个人对话生成旨在利用人物简介和对话历史生成相关且一致的回复。主流模型通常依赖于基于个人对话数据的令牌级语言模型训练，如Next Token Prediction，以隐式实现个性化，这使得这些方法往往忽略了给定的人物信息并生成泛化的回复。因此，为解决这一问题，提出了一个新颖的意志感知对齐框架（PAL），直接将个人特质对齐作为对话生成的训练目标。", "innovation": "PAL采用两阶段训练方法，包括意志感知学习和意志对齐，配备易于使用的推理策略（选择然后生成），以提高个人特质敏感性并在语义层面生成更多相关的回复。", "conclusion": "通过广泛实验，证明了该框架优于许多最先进的个性化对话方法和大型语言模型。"}
{"llm_update_time": "20251116", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2511.10232", "html_url": "https://arxiv.org/abs/2511.10232", "title": "VocalNet-M2：通过集成多码本标记化和多标记预测推动低延迟语音语言建模", "title_en": "VocalNet-M2: Advancing Low-Latency Spoken Language Modeling via Integrated Multi-Codebook Tokenization and Multi-Token Prediction", "authors": "Yuhao Wang,Ziyang Cheng,Heyang Liu,Ronghua Wu,Qunshan Gu,Yanfeng Wang,Yu Wang", "background": "当前的端到端语音语言模型（SLMs）虽然取得了显著进展，但也面临着响应延迟的问题，主要原因是通过自回归生成语音标记以及依赖复杂的流匹配模型进行语音合成。", "innovation": "VocalNet-M2 是一个新的低延迟 SLM，它结合了多码本分词器和多标记预测（MTP）策略。该模型可以直接生成多码本语音标记，从而消除引起延迟的流匹配模型的需要。此外，MTP 策略提高了生成效率并提升了总体性能。", "conclusion": "广泛的实验表明，VocalNet-M2 在减少首个片段延迟（从约 725ms 降至 350ms）的同时，仍然保持了与其他主流 SLM 相当的性能。此外，该工作还对单码本策略和多码本策略进行了全面比较，提供了有关开发适用于实时交互应用的高效且高性能 SLM 的有价值见解。"}
{"llm_update_time": "20251116", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2511.10303", "html_url": "https://arxiv.org/abs/2511.10303", "title": "通过困惑度感知强化学习矫正评估偏好：通过困惑度感知强化学习改进大型语言模型在数学推理中的评判", "title_en": "Rectify Evaluation Preference: Improving LLMs' Critique on Math Reasoning via Perplexity-aware Reinforcement Learning", "authors": "Changyuan Tian,Zhicong Lu,Shuang Qian,Nayu Liu,Peiguang Li,Li Jin,Leiyi Hu,Zhizhao Zeng,Sirui Wang,Ke Zeng,Zhi Guo", "background": "现有的方法主要依赖于设计高质量的监督微调示例来提升批评能力，但很少探索和分析导致大型语言模型批评性能不佳的根本原因。本文通过对评估偏好失衡这一潜在原因进行量化和研究，发现LLMs倾向于给低困惑度的答案打正确的分数，这一现象被称为评估偏好失衡。", "innovation": "本文提出了一种新的困惑度感知强化学习算法，通过将困惑度作为判别标准，引导LLMs探索判定低困惑度为错误、高困惑度为正确的评估策略。同时，构建了一个一对多问题解决基准（OPS），量化LLMs在评估自身和他人生成的答案时的行为差异，揭示了评估偏好失衡这一现象。", "conclusion": "在自建的OPS基准和现有批评基准上进行的广泛实验结果表明，本文提出的方法在提高LLMs的数学推理批评能力方面是有效的。"}
{"llm_update_time": "20251116", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2511.10297", "html_url": "https://arxiv.org/abs/2511.10297", "title": "本地混合检索增强文档问答", "title_en": "Local Hybrid Retrieval-Augmented Document QA", "authors": "Paolo Astrino", "background": "组织在处理敏感文件时面临着一个关键困境：采用基于云的AI系统以获得强大的问题回答能力但会牺牲数据隐私，或保持本地处理以确保安全但准确性较差。现有的解决方案都不能很好解决这一问题，急需一种能够在保证隐私的同时还能提供高准确度的方法。", "innovation": "本文提出了一种本地混合检索增强的文档问答系统，该系统结合了语义理解和关键词精确度，并完全在本地基础设施上运行而不依赖互联网。通过平衡两种互补的检索策略，并利用消费级硬件加速，该系统可以在不传输企业机密信息给外部提供商的情况下，实现银行、医院和律师事务所在处理复杂查询时的高准确性。这项工作展示了隐私和性能在企业AI部署中并非不可调和的对立关系。", "conclusion": "通过本文提出的方法，组织可以在不将数据传输到外部提供商的情况下，使用对话式文档AI系统并保持高准确性。该研究为企业在高效处理敏感信息时提供了一种兼具隐私保护和高性能的解决方案。"}
{"llm_update_time": "20251116", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2511.10229", "html_url": "https://arxiv.org/abs/2511.10229", "title": "LangGPS：基于语言可分性的数据预筛选方法在联合多语言指令调优中的应用", "title_en": "LangGPS: Language Separability Guided Data Pre-Selection for Joint Multilingual Instruction Tuning", "authors": "Yangfan Ye,Xiaocheng Feng,Xiachong Feng,Lei Huang,Weitao Ma,Qichen Hong,Yunfei Lu,Duyu Tang,Dandan Tu,Bing Qin", "background": "联合多语言指令调优是一种广泛采用的方法，用于提高大型语言模型（LLMs）的多语言指令遵循能力和下游性能。然而，这种多语言能力仍然高度依赖于训练数据的组成和选择。现有的选择方法通常基于文本质量、多样性或任务相关性等特征，但往往忽略了多语言数据的内在语言结构。因此，需要一种更好地利用多语言数据方法，以提高多语言模型的性能和泛化能力，尤其是针对理解和低资源语言任务。", "innovation": "本文提出了LangGPS，这是一种基于语言可分性的轻量级两阶段预筛选框架。首阶段基于可分性分数筛选训练数据，第二阶段使用现有的筛选方法进一步完善子集。该框架在六个基准和22种语言上进行的广泛实验表明，在现有的筛选方法基础上应用LangGPS可以提高它们的效率和泛化能力，特别是对于理解和低资源语言任务。进一步分析显示，具有良好可分性的样本有助于形成更清晰的语言边界并加快适应过程，而低可分性的样本则作为跨语言对齐的桥梁。此外，本文还发现语言可分性可以作为多语言课程学习的有效信号，通过交错具有不同可分性水平的样本可以获得稳定和泛化的效果。", "conclusion": "本文的研究为多语言上下文中的数据效用提供了一个新的视角，并支持开发更具语言意识的大型语言模型。"}
{"llm_update_time": "20251116", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2511.10201", "html_url": "https://arxiv.org/abs/2511.10201", "title": "EffiReason-Bench: 一个评估和促进大型语言模型高效推理的统一基准", "title_en": "EffiReason-Bench: A Unified Benchmark for Evaluating and Advancing Efficient Reasoning in Large Language Models", "authors": "Junquan Huang,Haotian Wu,Yubo Gao,Yibo Yan,Junyan Zhang,Yonghua Hei,Song Dai,Jie Zhang,Puay Siew Tan,Xuming Hu", "background": "大型语言模型（LLMs）通过Chain-of-Thought（CoT）提示实现强大的推理能力，但往往产生不必要的冗长解释，增加了成本并有时降低了准确性。公正比较效率优化方法受到碎片化评估实践的阻碍。尽管如此，研究人员仍需要一个统一的基准来评估和改进高效推理方法。EffiReason-Bench通过为CommonsenseQA和LogiQA构建验证的CoT注释，提供了跨三种类型（推理蓝图、动态执行和后处理精炼）的严格跨范式评估框架。该基准旨在支持逐步评估，并提供了经济模型启发的E3-Score作为评估指标，有助于平稳、稳定地评估不同方法的效果，而无需断点或大量依赖于启发式方法。实验表明，没有一种方法单方面领先，最优策略依赖于模型规模、任务复杂性和架构特性。", "innovation": "EffiReason-Bench 提出了一个新的统一基准，以跨范式评估高效推理方法。该基准包括三个类别：推理蓝图、动态执行和后处理精炼，涵盖了数学、常识和逻辑等多个领域。通过构建验证的CoT注释，统一的评估流程确保了数据的一致性和准确性。E3-Score是一个原则性的指标，受到经济权衡建模的启发，用于评估方法，为避免断点和过度依赖启发式方法提供了一种平稳的方法。", "conclusion": "实验结果表明，没有一种单一的方法可以普遍占据上风，最优策略依赖于模型的规模、任务的复杂性和架构。EffiReason-Bench 提供了一种新的框架来评估和推进高效推理方法，帮助研究人员更好地理解和优化大型语言模型的推理效果。"}
{"llm_update_time": "20251116", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2511.10262", "html_url": "https://arxiv.org/abs/2511.10262", "title": "MTR-DuplexBench: 向全面评估全双工对话的多轮会话方向努力", "title_en": "MTR-DuplexBench: Towards a Comprehensive Evaluation of Multi-Round Conversations for Full-Duplex Speech Language Models", "authors": "He Zhang,Wenqian Cui,Haoning Xu,Xiaohui Li,Lei Zhu,Shaohua Ma,Irwin King", "background": "全双工语音语言模型（FD-SLMs）能够实现实时的重叠对话交互，提供比传统半双工模型更动态的用户体验。然而，现有的基准测试主要集中在单轮交互和对话功能上，忽略了多轮交流的复杂性以及如指令遵循和安全性等关键能力。在多轮设置中评估FD-SLM们具有巨大挑战，包括通信中的发言界限模糊以及模型推理过程中上下文的一致性问题。因此，现有基准存在不足，无法充分评价FD-SLMs的能力。", "innovation": "提出了一种新型基准MTR-DuplexBench，该基准将连续的全双工对话分成离散的轮次，以实现对对话质量、对话动态、指令遵循和安全性等方面进行全面、逐轮的评估。实验结果表明当前的FD-SLMs在多轮交互和多个评估维度上难以保持一致的性能，强调了我们该基准的必要性和有效性。", "conclusion": "当前的FD-SLMs在多轮交互上的表现存在局限性，MTR-DuplexBench能更好地评估其性能，这将有助于改进全双工语音语言模型。未来将公布该基准和相关代码。"}
{"llm_update_time": "20251116", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2511.10338", "html_url": "https://arxiv.org/abs/2511.10338", "title": "BhashaKritika: 构建大规模合成预训练数据集用于印度语言", "title_en": "BhashaKritika: Building Synthetic Pretraining Data at Scale for Indic Languages", "authors": "Guduru Manoj,Neel Prabhanjan Rachamalla,Ashish Kulkarni,Gautam Rajeev,Jay Piplodiya,Arul Menezes,Shaharukh Khan,Souvik Rana,Manya Sah,Chandra Khatri,Shubham Agarwal", "background": "在大型语言模型（LLMs）的预训练过程中，合成数据已成为生成大量高质量预训练数据的替代方案，特别是在资源贫乏的语言环境中，这些环境受到了近期LLMs带来的好处分布不均的问题。因此，对于印度语言，本研究进行了系统性的研究和评估，构建了一个大规模的合成数据集BhashaKritika，包含540亿个令牌，涵盖了十种不同语言，并探索了文档、人物和主题等基础生成方法的影响。", "innovation": "本研究引入了一个模块化的质量评估流程，该流程结合了脚本和语言检测、元数据一致性检查、n-克容量重复分析以及基于KenLM模型的困惑度过滤。这使得质量控制能够跨越多种脚本和语言环境。通过模型实验，该研究揭示了生成策略中的关键权衡，并指出了构建有效多语言语料库的最佳实践。", "conclusion": "本研究的实验结果揭示了生成策略中的关键权衡，并突显了在构建有效多语言语料库方面的最佳实践。"}
{"llm_update_time": "20251116", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2511.10192", "html_url": "https://arxiv.org/abs/2511.10192", "title": "Text2SQL-Flow: 一种用于文本到SQL的稳健SQL感知数据增强框架", "title_en": "Text2SQL-Flow: A Robust SQL-Aware Data Augmentation Framework for Text-to-SQL", "authors": "Qifeng Cai,Hao Liang,Chang Xu,Tao Xie,Wentao Zhang,Bin Cui", "background": "在AI领域，以数据为中心的范式变得尤为重要，特别是在文本到SQL（Text-to-SQL）任务中，由于可用的数据集稀缺、简单且缺乏多样性，性能受到了限制。", "innovation": "本文提出了Text2SQL-Flow，这是一种SQL感知的数据增强框架，能够从少量种子数据生成大规模、语义有效且结构多样的Text-to-SQL对。该框架在六个增强维度上运作，并集成了SQL执行验证、自然语言问题生成、推理轨迹以及数据分类等端到端流水线。方法还包括一个模块化数据库管理系统以确保跨库兼容性和可扩展性。", "conclusion": "我们在Text2SQL-Flow上构建了SQLFlow，一个包含89,544个标注示例的高质量数据集。实验表明，对于开源模型，对SQLFlow进行微调可以持续提高不同基准测试的性能；对于封闭源模型，引入了掩码对齐检索方法，该方法将SQLFlow同时用作检索器的知识库和训练数据。这通过细粒度的SQL查询与问题对齐模型，改善了结构意识的示例匹配。我们的方法和数据集提高了性能，展示了SQLFlow对高质量结构化数据在现代AI中的重要性。"}
{"llm_update_time": "20251116", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2511.10375", "html_url": "https://arxiv.org/abs/2511.10375", "title": "TruthfulRAG：使用知识图谱解决检索增强生成中的事实级冲突", "title_en": "TruthfulRAG: Resolving Factual-level Conflicts in Retrieval-Augmented Generation with Knowledge Graphs", "authors": "Shuyi Liu,Yuming Shang,Xi Zhang", "background": "检索增强生成(RAG)作为一种强大的框架，通过将检索方法与生成模型结合，增强了大型语言模型(LLMs)的能力。随着外部知识库不断扩展，模型中参数化知识变得陈旧，RAG系统面临一个关键挑战，即在检索到的外部信息和LLMs内部知识之间解决冲突，这可能严重影响生成内容的准确性和可靠性。现有解决冲突的方法通常在标记或语义级别进行操作，往往导致对LLMs知识和上下文之间事实性差异的不完整理解，特别是在知识密集型任务中。", "innovation": "提出了一种名为TruthfulRAG的新框架，这是第一个利用知识图谱(KGs)解决RAG系统中事实级知识冲突的框架。具体而言，TruthfulRAG通过系统地从检索到的内容中提取三元组构建KGs，采用基于查询的图检索来识别相关知识，并使用基于熵的筛选机制精确找到冲突元素并减轻事实不一致性，从而使LLMs能够生成忠实且准确的响应。", "conclusion": "广泛的实验表明，TruthfulRAG在性能上优于现有方法，有效地缓解了知识冲突，提高了RAG系统的稳健性和可信度。"}
{"llm_update_time": "20251116", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2511.10354", "html_url": "https://arxiv.org/abs/2511.10354", "title": "文化遗存文本的知识图谱生成：结合LLMs与本体工程的学术争鸣", "title_en": "Knowledge Graphs Generation from Cultural Heritage Texts: Combining LLMs and Ontological Engineering for Scholarly Debates", "authors": "Andrea Schimmenti,Valentina Pasqual,Fabio Vitali,Marieke van Erp", "background": "文化遗存文本蕴含丰富的知识，但由于将非结构化叙述转换为结构化知识图谱（KGs）的挑战，这些知识难以系统查询。现有的方法难以有效提取和组织这些信息，尤其是在进行遗产真实性评估等学术讨论时。因此，迫切需要一种系统的方法来解决这些问题，用于从文化遗存文档中提取和构建知识图谱。", "innovation": "本文提出了ATR4CH (Adaptive Text-to-RDF for Cultural Heritage) 方法论，这是一种基于大规模语言模型（LLM）的知识提取系统性五步法。该方法利用迭代开发的注释模型、本体框架以及LLM基础的提取技术，成功地将复杂的文化遗存知识进行了提取和组织，并且在不同的LLM模型上表现出色，使得小模型也能有效应用，降低了部署成本。这是首次将LLM与文化遗产本体学相结合的系统性方法，提供了适用于文化遗产领域和机构资源的复制框架。", "conclusion": "ATR4CH方法成功地从争议性文章（如争议文档、文物等）中提取了文化遗存知识。本文的研究发现，知识图谱的生成可以有效支持文化遗产机构的元数据丰富和知识探索，但在处理生成的知识图谱时仍需人类监督。"}
{"llm_update_time": "20251116", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2511.10381", "html_url": "https://arxiv.org/abs/2511.10381", "title": "关于评估基础LLM推理能力的方法论陷阱", "title_en": "Position: On the Methodological Pitfalls of Evaluating Base LLMs for Reasoning", "authors": "Jason Chan,Zhixue Zhao,Robert Gaizauskas", "background": "现有研究探讨了大型语言模型（LLMs）的推理能力，以揭示其局限性、人类偏见和底层机制。此类研究包括对未接触过标记数据的预训练基LLMs的评估。本文认为，评估基LLMs的推理能力存在固有的方法论问题，在现有研究中往往未引起足够重视。主要讨论了基LLMs的预训练目标与推理评估所依据的规范性标准之间的根本不匹配。", "innovation": "论文揭示了基LLMs生成逻辑上有效或无效结论的本质，这些结论是由于遵从统计学上合理的纯语言模式而产生的偶然副产品。这种不匹配挑战了现有工作的两项假设：一是认为基LLMs的输出是其正确答案或结论的真正尝试；二是关于基LLMs推理的结论能概括到优化成功的指令遵循的后训练LLMs。", "conclusion": "论文呼吁对依赖这些假设的现有工作进行重新审视，并在未来的研究中考虑到这些方法论问题。"}
{"llm_update_time": "20251116", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2511.10453", "html_url": "https://arxiv.org/abs/2511.10453", "title": "针对模糊请求的意图推理", "title_en": "Reasoning About Intent for Ambiguous Requests", "authors": "Irina Saparina,Mirella Lapata", "background": "大型语言模型在面对模棱两可的请求时，往往会隐含地选择一种解释并做出响应，这可能导致用户意图理解错误，进而引发安全风险。", "innovation": "本文提出了一种方法，即通过生成单一结构化响应中的多个解释-答案对来解决模棱两可请求的问题。模型采用了强化学习和定制的奖励函数进行训练，使用多个有效的答案作为监督。实验结果显示，该方法的覆盖有效答案的比率高于基准方法。人类评估表明，预测的解释与答案高度一致。这种方法提高了透明度，只需一步生成步骤即可实现高效性，并通过结构化输出支持下游应用。", "conclusion": "该方法通过促进透明性、实现高效性并支持下游应用，有效解决了模棱两可请求的意图理解问题。"}
{"llm_update_time": "20251116", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2511.10441", "html_url": "https://arxiv.org/abs/2511.10441", "title": "类比结构、最小上下文线索和对比干扰物：输入设计以实现样本高效的语言规则归纳", "title_en": "Analogical Structure, Minimal Contextual Cues and Contrastive Distractors: Input Design for Sample-Efficient Linguistic Rule Induction", "authors": "Chunyang Jiang,Paola Merlo", "background": "大型语言模型通过在大量数据上训练来实现强大的性能。本文研究了是否可以通过类比范式的组织来使轻量级模型在最少的数据下达到类似的性能。", "innovation": "开发了一种基于类比结构、对比学习和最小上下文线索的计算方法。通过结构化的完成任务测试，仅用100个结构化的英语原因/初始变化示例训练轻量级模型（BERT+CNN，0.5M参数），达到了0.95的F1分数，优于零样本的GPT-o3（F1=0.87）。消融研究表明，类比组织和对比结构可以提高性能。此外，通过未指定物体替代物进行的交叉现象验证证实了这些效率增益，表明该方法的鲁棒性。", "conclusion": "结果表明，类比范式的组织能够使轻量级模型在与传统方法相比依赖少得多的数据的情况下，仍然能实现竞争力的语言规则学习。"}
{"llm_update_time": "20251116", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2511.10404", "html_url": "https://arxiv.org/abs/2511.10404", "title": "DELICATE：使用类和时间证据进行历时实体链接", "title_en": "DELICATE: Diachronic Entity LInking using Classes And Temporal Evidence", "authors": "Cristian Santini,Sebastian Barzaghi,Paolo Sernani,Emanuele Frontoni,Mehwish Alam", "background": "尽管自然语言处理领域取得了显著进展，但由于人文领域中复杂的文档类型、缺乏领域特定的数据集和模型以及长尾实体（即知识库中代表性不足的实体）的存在，实体链接任务仍然具有挑战性。", "innovation": "本文提出两个主要贡献：首先，提出了一种名为DELICATE的新型神经符号方法，用于历史上意大利语的实体链接，结合了基于BERT的编码器和来自维基数据的上下文信息，并使用时间上的合理性与实体类型一致性来选择适当的知识库实体。其次，提供了一个多领域的实体链接语料库（ENEIDE），语料库内容来自19世纪至20世纪两个注释版本的历史意大利文本，包括文学和政治文本，这些文本是半自动地从中提取出来的。", "conclusion": "实验结果表明，DELICATE在历史上意大利语的实体链接任务中优于其他实体链接模型，即使在参数规模更大的模型中也是如此。进一步的分析表明，DELICATE不仅仅提供更可解释和可解释性强的表现，还有在模型特性敏感性方面的优势。"}
{"llm_update_time": "20251116", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2511.10457", "html_url": "https://arxiv.org/abs/2511.10457", "title": "探索大型语言模型的状态跟踪能力", "title_en": "Exploring State Tracking Capabilities of Large Language Models", "authors": "Kiamehr Rezaee,Jose Camacho-Collados,Mohammad Taher Pilehvar", "background": "大型语言模型（LLMs）在解决复杂任务方面表现出色，包括需要一定推理能力的任务。状态跟踪是一个问题，其中模型需要跟踪多个实体的治理状态。为了将状态跟踪组件与其他因素分离，该研究通过创建基于三个明确定义的状态跟踪任务的基准来分析LLMs在不同场景中的性能。", "innovation": "该研究提出了一种基于三个明确定义的状态跟踪任务的基准，以评估LLMs在状态跟踪中的表现。特别地，该研究发现最近的LLMs（如GPT-4和Llama3）具有跟踪状态的能力，尤其是在使用Chain of Thought机制时。然而，较早一代的模型尽管能理解任务并在初期能解决此任务，但在多次步骤后会失败。", "conclusion": "研究结果表明，较新的LLMs（如GPT-4和Llama3）在状态跟踪方面表现出色，特别是当结合Chain of Thought机制时。虽然较旧的LLMs在任务初期能理解和解决任务，但会在多次步骤后失败。"}
{"llm_update_time": "20251116", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2511.10465", "html_url": "https://arxiv.org/abs/2511.10465", "title": "Beyond Elicitation: Provision-based Prompt Optimization for Knowledge-Intensive Tasks", "title_en": "Beyond Elicitation: Provision-based Prompt Optimization for Knowledge-Intensive Tasks", "authors": "Yunzhe Xu,Zhuosheng Zhang,Zhe Liu", "background": "尽管prompt优化已成为提升语言模型性能的关键技术，现有的方法主要集中在通过唤引策略搜索最优提示以激活模型的能力。这些方法在应对知识密集型任务时存在固有局限性，因为它们受限于固定的参数边界，而不是提供所需的专业领域中的事实知识、术语精度和推理模式。", "innovation": "本文提出了基于知识补充的提示优化（KPPO），将提示优化重新定义为系统性的知识整合，而不是潜在的唤引。KPPO 的三大创新包括：1) 知识缺口填充机制，用于识别和有针对性地修复知识缺口；2) 批处理级别的候选评估方法，兼顾性能提升和分布稳定性；3) 适应性知识修剪策略，平衡性能和令牌效率，最多可减少29%的令牌使用量。", "conclusion": "在15个来自不同领域的知识密集型基准测试中的广泛评估表明，KPPO 在性能上优于现有的唤引方法，相比最强的基线平均提高了约6%的性能，同时实现了相当或更低的令牌消耗。"}
{"llm_update_time": "20251116", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2511.10515", "html_url": "https://arxiv.org/abs/2511.10515", "title": "LOCA-R：2025年中国物理奥林匹克竞赛的近完美表现", "title_en": "LOCA-R: Near-Perfect Performance on the Chinese Physics Olympiad 2025", "authors": "Dong-Shan Jian,Xiang Li,Chen-Xu Yan,Hui-Wen Zheng,Zhi-Zhang Bian,You-Le Fang,Sheng-Qi Zhang,Bing-Rui Gong,Ren-Xi He,Jing-Tian Zhang,Ce Meng,Yan-Qing Ma", "background": "奥林匹克级别的物理问题解决对于人类和人工智能都构成了重大挑战，因为它要求复杂的精确计算、抽象推理和物理原理的深刻理解。中国物理奥林匹克（CPhO），因其复杂性和深度成为检验高级能力的理想和严格的测试平台。LOCA-R 是 LOCA 框架的改进版本，是为复杂推理定制的，应用于2025年中国物理奥林匹克理论考试中。", "innovation": "LOCA-R 是一种改进后的 LOCA 框架，专门用于复杂的推理，显著优于传统方法和所有基准方法，能够在复杂的问题解决中实现接近满分的成绩。", "conclusion": "LOCA-R 在2025年中国物理奥林匹克理论考试中取得了320分中的313分的近满分成绩，超越了最高分的人类竞争对手，显著超越了所有基线方法，表明在解决复杂的物理问题上，AI 已经取得了重要的进步。"}
{"llm_update_time": "20251116", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2511.10507", "html_url": "https://arxiv.org/abs/2511.10507", "title": "基于评分表的基准测试与强化学习以推进大型语言模型指令跟随", "title_en": "Rubric-Based Benchmarking and Reinforcement Learning for Advancing LLM Instruction Following", "authors": "Yun He,Wenzhe Li,Hejia Zhang,Songlin Li,Karishma Mandyam,Sopan Khosla,Yuanhao Xiong,Nanshu Wang,Selina Peng,Beibin Li,Shengjie Bi,Shishir G. Patil,Qi Qi,Shengyu Feng,Julian Katz-Samuels,Richard Yuanzhe Pang,Sujan Gonugondla,Hunter Lang,Yue Yu,Yundi Qian,Maryam Fazel-Zarandi,Licheng Yu,Amine Benhalloum,Hany Awadalla,Manaal Faruqui", "background": "近期，大型语言模型（LLMs）在各种任务中的表现显著提升。然而，对于复杂的、多回合的和系统提示的指令，高级指令跟随（IF）仍然是一个重大挑战。严格评估和有效的训练受限于缺乏高质量的人工注释基准和可靠的、可解释的奖励信号。", "innovation": "我们提出了一个名为AdvancedIF的综合基准，包含超过1600个提示和专家定制的评价标准来评估LLMs的复杂、多回合和系统级指令跟随能力。我们进一步提出了RIFL（基于评分表的指令跟随学习），这是一个创新的后训练管道，利用评分表生成、微调的评分表验证器和奖励构建来实现对指令跟随的有效强化学习。", "conclusion": "大量的实验证明，RIFL显著提高了LLMs的指令跟随能力，相较于AdvancedIF获得了6.7%的绝对提升，并在公共基准上取得了良好的结果。我们的消融研究证实了RIFL中每个组件的有效性。这项工作确立了评分表作为训练和评估LLMs先进IF的强大工具，推动了更具能力和可靠的AI系统的开发。"}
{"llm_update_time": "20251116", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2511.10459", "html_url": "https://arxiv.org/abs/2511.10459", "title": "LocalBench: 在县级地方知识和推理方面的LLM基准测试", "title_en": "LocalBench: Benchmarking LLMs on County-Level Local Knowledge and Reasoning", "authors": "Zihan Gao,Yifei Xu,Jacob Thebault-Spieker", "background": "大型语言模型（LLMs）在宏观地理任务上已经得到广泛评估，如全球事实回忆、事件总结和区域推理。然而，它们在处理超地方知识方面的能力仍不明确。随着公民平台和社区新闻等实际应用对AI系统提出了越来越高的要求，系统需要能够推理关于社区动态、文化叙事和地方治理等地方具体问题。现有的基准工具在捕捉这种复杂性方面存在不足，往往依赖粗粒度数据或孤立参考。因此，需要一种新的基准工具来系统地评估LLMs在县级地方知识上的表现。因此，研究人员提出了LocalBench，这是一个专为评估美国526个县的县级地方知识设计的新基准工具，包括14,782个验证过的问答对，涵盖了物理、认知和关系三个地方维度。LocalBench使用14个验证问题对13个最先进的LLM模型进行了评估，结果显示即使是表现最好的模型也只能达到56.8%的准确率，尤其在数值推理任务上表现更差，一些较大的模型甚至在网络增强后表现反而更差。这些结果揭示了开发地方公平、地方意识的AI系统的需求，这些系统能够应对地方社区在地理和文化背景下的多元、细粒度现实。", "innovation": "首次提出了LocalBench，这是一个专为评估LLMs在县级地方知识上的表现设计的新基准工具，包括广泛的验证问题对，整合了多元数据源，覆盖了物理、认知和关系三条地方维度。首次系统地评估了13个最先进的LLM模型在县级地方知识上的表现，揭示了现有模型在地方知识和推理方面的局限性，为开发更强大的地方意识的语言模型提供了理论基础。", "conclusion": "现有模型在地方知识和推理方面存在严重局限性。研究结果强调了地方公平、地方意识AI系统的重要性，这些系统能够应对地方社区在地理和文化背景下的多元、细粒度现实。未来需要更多关注这些挑战，推动地方意识的语言模型的发展。"}
{"llm_update_time": "20251116", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2511.10523", "html_url": "https://arxiv.org/abs/2511.10523", "title": "Convomem基准测试：为什么前150次对话不需要RAG", "title_en": "Convomem Benchmark: Why Your First 150 Conversations Don't Need RAG", "authors": "Egor Pakhomov,Erik Nijkamp,Caiming Xiong", "background": "目前存在的一些基准测试虽然推进了领域发展，但本研究关注并解决了统计功效不足、数据生成一致性以及评估灵活性等限制现有记忆评估框架的关键挑战。此外，研究探讨了对话记忆与检索增强生成（RAG）之间的关系。", "innovation": "提出了一套包含75336个跨多类型问题答案对的全面基准测试，这些类型包括用户事实、助手回忆、放弃、偏好、时间变化和隐含联系。研究发现，基于长上下文的简单方法在最复杂的多消息证据情况下仍能达到70-82%的准确率，而像Mem0这样复杂的基于RAG的记忆系统在这种情况下只能获得30-45%的准确率。研究揭示了实际的过渡点：长上下文方法适用于前30次对话，可管理的折衷可维持到150次对话，但通常需要混合方法或RAG方法以超出这一范围。", "conclusion": "长上下文对话记忆对150次以内对话广有效果，超出此范围通常需混合方法或RAG方法，这表明针对长对话历史的小语料库优势值得专门的研究关注，而不仅仅是将通用的RAG解决方案应用于对话历史。"}
{"llm_update_time": "20251116", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2511.10519", "html_url": "https://arxiv.org/abs/2511.10519", "title": "Say It Differently: 语言风格作为越狱向量", "title_en": "Say It Differently: Linguistic Styles as Jailbreak Vectors", "authors": "Srikant Panda,Avinash Rai", "background": "大型语言模型（LLMs）通常会针对重新表述或语义等价的越狱提示进行鲁棒性评估，但很少关注语言变体作为潜在攻击面。目前的研究主要集中在识别和防止这些类型的提示，然而本文提出了一种新的研究视角，即将语言风格（如恐惧或好奇心）作为一个新的威胁向量。研究人员通过将标准数据集中的提示转换为11种不同的语言风格，研究了这些风格如何重新阐述有害意图并促使对齐模型产生不安全响应。实验结果表明，这种语言风格的重新表达可以显著提高模型被越狱的成功率，特别是使用情感化的语言（如恐惧、好奇或同情）效果最佳。", "innovation": "本文创新点在于通过系统性地研究不同语言风格如何重新阐述有害意图，提出了一个带有11种独特语言风格样式增强的越狱基准。同时，研究人员提出了一种使用secondary LLM进行预处理的方法，以消除用户输入中的操控性语言线索，从而有效减少越狱成功率。这种方法揭示了一个可能被当前安全处理流程忽略的系统性和难以扩展的安全漏洞。", "conclusion": "研究表明，语言风格可以作为新的越狱向量，通过变换语言风格可以提高模型越狱的成功率。为了减轻这种威胁，提出了一种新的预处理步骤来消除用户输入中的操控性语言线索。研究发现揭示了当前安全处理流程中存在的隐性漏洞。"}
{"llm_update_time": "20251116", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2511.10546", "html_url": "https://arxiv.org/abs/2511.10546", "title": "当代类型小说与文学小说的形式与机构边界的计算分析", "title_en": "Computing the Formal and Institutional Boundaries of Contemporary Genre and Literary Fiction", "authors": "Natasha Johnson", "background": "尽管自古以来一直讨论文本类型的概念，但较近年新兴的类型小说为这一讨论增添了新的维度。传统上，文本类型的定义侧重于形式，而当代研究将其分类体系扩展至形式与机构特征。本研究利用计算方法探讨类型作为形式与机构分类标签的有效性。研究选取 Andrew Piper 的 CONLIT 当代文学数据集，汇集了文学与类型小说（其中包含爱情、惊悚和科幻小说）的文本，并运用 Welch 的 F-检验比较不同作者性别在各类类型小说中的叙事特征分布，并通过逻辑回归分析每个特征对文学分类的影响及其作者性别的影响。最终，研究通过风格和语义向量表示来理解形式和内容对文学分类的重要性，发现统计上显著的形式标记，并证明女性作者对文学地位的获取具有影响作用，使得这一目标更加集中、模糊。", "innovation": "利用计算方法探讨类型小说和文学小说的形式与机构边界的有效性，通过定量分析揭示作者性别对类型小说与文学小说分类的影响，并通过风格和语义向量表示研究形式与内容在文学分类中的重要性。引入了 Welch 的 F-检验方法和逻辑回归模型来分析叙事特征和作者性别之间的关系。", "conclusion": "研究发现，不同类型小说中有显著的形式特点，证明女性作者对获取文学地位具有重要影响，使得这一目标更加集中和模糊。通过分析作者性别对不同类型小说分类的影响，进一步理解文学与类型小说之间的关系，并提出新的研究方向。"}
{"llm_update_time": "20251116", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2511.10583", "html_url": "https://arxiv.org/abs/2511.10583", "title": "使用MedGemma评估医疗指令提取中的提示策略", "title_en": "Evaluating Prompting Strategies with MedGemma for Medical Order Extraction", "authors": "Abhinand Balachandran,Bavana Durgapraveen,Gowsikkan Sikkan Sudhagar,Vidhya Varshany J S,Sriram Rajkumar", "background": "准确从医生-患者对话中提取医疗指令对于减轻临床记录负担和保障患者安全至关重要。本文介绍了我们团队对MEDIQA-OE-2025共享任务的提交情况，研究了新的领域特定开源语言模型MedGemma在结构化指令提取上的性能，并系统地评估了三种不同的提示策略：直接的一次性提示、注重推理的ReAct框架和多步代理工作流。实验结果显示，尽管复杂的ReAct和代理流程策略更为强大，但简单的一次性提示方法在正式验证集上表现最好。我们推测，在手动标注的记录中，复杂的推理链会导致“过度思考”并引入噪音，从而使直接的方法更为稳健和高效。这项工作为在不同数据条件下选择适当的提示策略提供了宝贵的见解。", "innovation": "提出了一个新颖的领域特定开源语言模型MedGemma，并对其在医学指令提取中的应用进行了研究，评估了三种不同的提示策略，包括一次性提示、ReAct框架和多步代理工作流。该研究发现，虽然复杂数学策略强大，但简单的一次性提示方法在实际性能上表现最佳。这一发现为临床信息提取中的提示策略选择提供了新视角。", "conclusion": "研究发现，虽然ReAct框架和多步代理工作流在理论上更强大，但在实际应用中，简单的一次性提示方法更为高效和稳健，并且能够减少复杂推理带来的噪音。这项工作为选择合适的提示策略以促进临床信息提取提供了有价值的见解。"}
{"llm_update_time": "20251116", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2511.10577", "html_url": "https://arxiv.org/abs/2511.10577", "title": "DESS: DeBERTa增强的语义-语法方面情感三元组提取", "title_en": "DESS: DeBERTa Enhanced Syntactic-Semantic Aspect Sentiment Triplet Extraction", "authors": "Vishal Thenuwara,Nisansa de Silva", "background": "细粒度情感分析在方面情感三元组抽取（ASTE）中面临持续的挑战，尤其是在准确捕捉方面、意见和情感极性之间的关系方面。尽管研究人员已经使用BERT和图神经网络取得了一定的进展，但高级语言模型在理解复杂语言模式的潜力仍未得到完全探索。细粒度情感分析在捕捉情感极性、意见和方面之间的关系时仍然具有挑战性，尤其是当重要词相距较远时，处理复杂句子结构更为困难。", "innovation": "我们提出了DESS的新方法，通过将DeBERTa的增强注意机制与先前工作相结合，更好地理解文本中的上下文和关系。框架保持了双通道结构，DeBERTa与LSTM通道协同工作，处理文本中的含义和语法模式。特别注意不同类型的语言信息之间的交互。在标准数据集上的测试表明，DESS在识别方面意见对和准确判断情感方面超过了当前方法，F1分数提高了4.85、8.36和2.42。改进结果表明，当仔细集成到精确实验时，使用更高级的语义模型可以显著提高文本情感分析的准确性。", "conclusion": "DESS表明，当仔细集成到精确实验时，使用更高级的语义模型可以显著提高文本情感分析的准确性。我们的工作证明了增强注意机制和高级语言模型对复杂句子结构处理的优势。DESS的实现可以在这个链接中找到：[提供链接]。"}
{"llm_update_time": "20251116", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2511.10591", "html_url": "https://arxiv.org/abs/2511.10591", "title": "挖掘提示和元数据指导生成在伤口护理视觉问答中的应用", "title_en": "Mined Prompting and Metadata-Guided Generation for Wound Care Visual Question Answering", "authors": "Bavana Durgapraveen,Sornaraj Sivasankaran,Abhinand Balachandran,Sriram Rajkumar", "background": "异步远程医疗服务的迅速扩展增加了医疗提供者的负担，从而产生了对可以协助临床医生更高效管理患者查询的AI系统的高需求。MEDIQA-WV 2025 共享任务通过关注伤口护理查询与图像相关联的自由文本响应，来解决这一挑战。", "innovation": "提出了一种挖掘提示策略，通过嵌入训练数据并检索最相似的k个示例作为零样本演示，用于生成过程。另一种方法基于元数据消除研究，发现四个元数据属性能够持续提高响应质量，通过训练分类器预测这些属性，并将其动态集成到生成管道中，基于预测信心调整输出。", "conclusion": "挖掘提示能够提高响应的相关性，而元数据引导的生成进一步提升了临床精度。这些方法为开发能够提供可靠和高效伤口护理支持的AI驱动工具展示了有前景的方向。"}
{"llm_update_time": "20251116", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2511.10618", "html_url": "https://arxiv.org/abs/2511.10618", "title": "了解你的极限：压缩和泛化的熵估计建模", "title_en": "Know Your Limits: Entropy Estimation Modeling for Compression and Generalization", "authors": "Benjamin L. Badger,Matthew Neligeorge", "background": "语言预测受到语言固有的信息熵限制，存在语言模型准确性的上限以及语言压缩的下限。目前最有效的语言压缩算法是因果（下一个词预测）的大规模语言模型，但由于计算限制，使用这些模型进行语言熵估计目前不可行。已有研究表明，某些训练模型以接近但不超过预估单个词熵的模型，在泛化能力上优于不考虑熵的方法训练的模型。", "innovation": "该研究引入了增强编码器因果解码器模型架构，即使在使用中端硬件训练时，其压缩效果也优于因果变换模型，并且能够基于单个词获得熵估计。此外，证明了训练模型以接近训练数据的熵值在泛化能力上优于仅最小化损失的模型。", "conclusion": "通过因果模型训练以接近但不超过预估的单个词熵，可以提高模型的泛化能力。在模型训练过程中考虑熵的模型，即使没有完全超越熵估计值，其泛化性能也优于不考虑熵的方法训练的模型。"}
{"llm_update_time": "20251116", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2511.10552", "html_url": "https://arxiv.org/abs/2511.10552", "title": "URaG: 多模态大规模语言模型中统一检索和生成以实现高效长文档理解", "title_en": "URaG: Unified Retrieval and Generation in Multimodal LLMs for Efficient Long Document Understanding", "authors": "Yongxin Shi,Jiapeng Wang,Zeyu Shan,Dezhi Peng,Zening Lin,Lianwen Jin", "background": "近期的多模态大型语言模型（MLLMs）在处理长文档理解时仍然存在两个根本问题：大量无关内容的信息干扰，以及基于Transformer架构的计算成本呈平方级增加。现有方法主要分为两类：通过牺牲细节来进行token压缩；或者引入外部检索器，这会增加系统复杂性，妨碍端到端优化。现有的解决方案并未根本解决这些挑战。以往的方法在优化速度和精确度之间难以取舍，或者未能充分利用模型本身内在的证据定位能力。已有研究观察到MLLMs在处理长文档时表现出了类似人类的认知模式，即早期Transformer层广泛关注整个文档，而深层层则专注于相关证据页。因此，MLLMs本身就具备进行有效检索的能力，但这一能力尚未在模型中得到充分应用。", "innovation": "本文提出了URaG，一种简单的框架，将检索和生成统一在多模态大规模语言模型中。URaG引入了一个轻量级的跨模态检索模块，将早期的Transformer层转换为高效的证据选择器，能够高效地识别并保存最相关的页面，同时丢弃无关内容。这一设计使得深层层能够更集中地利用计算资源，专注于关键信息，从而提高准确性和效率。实验结果显示，URaG不仅达到了最先进的性能，还降低了44-56%的计算开销。该框架为长文档理解提供了一种新颖的方法论，有效地利用了MLLMs的内在记忆和选择能力，提出了一个简洁有效的解决方案来优化模型资源利用和理解能力。", "conclusion": "本文提出了一种名为URaG的新框架，该框架通过将检索和生成功能统一到多模态大型语言模型中，有效提升了长文档的理解效率，同时保持了性能的领先性。URaG通过引入一种轻量级的跨模态检索模块，帮助模型集中处理关键信息，显著提升了模型的计算效率和理解精度。"}
{"llm_update_time": "20251116", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2511.10628", "html_url": "https://arxiv.org/abs/2511.10628", "title": "Instella：完全开源且具优异表现的语言模型", "title_en": "Instella: Fully Open Language Models with Stellar Performance", "authors": "Jiang Liu,Jialian Wu,Xiaodong Yu,Yusheng Su,Prakamya Mishra,Gowtham Ramesh,Sudhanshu Ranjan,Chaitanya Manem,Ximeng Sun,Ze Wang,Pratik Prabhanjan Brahma,Zicheng Liu,Emad Barsoum", "background": "大型语言模型（LLMs）在各种任务中表现出了显著的能力，但大多数高性能模型仍然是闭源或部分开放的，这限制了透明度和可再现性。Instella是一款完全开源的三亿参数语言模型，其训练数据和代码均为公开获取，这是为了提高研究的透明性和可再现性而提供的解决方案。", "innovation": "Instella通过在AMD Instinct MI300X GPU上进行大规模预训练、通用指令调优以及与人类偏好对齐的方式开发，尽管使用了比许多同行模型更少的预训练令牌，Instella仍然实现了最佳的开放模型结果，并且在可相比的模型规模下与领先的开放权重模型竞争。此外，Instella还提供了两个专有版本：Instella-Long可以处理多达128K令牌的上下文长度，Instella-Math则通过监督微调和数学任务上的强化学习增强了其推理能力。", "conclusion": "这些贡献将Instella确立为透明、高效且多用途的替代方案，它为公开和可再现的语言模型研究的目标进行了推进。"}
{"llm_update_time": "20251116", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2511.10621", "html_url": "https://arxiv.org/abs/2511.10621", "title": "SSR:苏菲克自校正技术在大型语言模型推理中的应用", "title_en": "SSR: Socratic Self-Refine for Large Language Model Reasoning", "authors": "Haizhou Shi,Ye Liu,Bo Pang,Zeyu Leo Liu,Hao Wang,Silvio Savarese,Caiming Xiong,Yingbo Zhou,Semih Yavuz", "background": "大型语言模型（LLMs）已经在推理任务中显示出非凡的能力，但现有的测试时框架通常依赖粗略的自我验证和自我修正，这在处理复杂任务时受到了限制。现有的评估与校正框架往往过于粗糙，无法提供精细的评估和合理的推理链解析。本文旨在弥合现有方法的不足，提出了一种新颖的框架Socratic Self-Refine (SSR)，以改善LLM推理的准确性和可解释性。", "innovation": "SSR框架通过将模型响应分解为可验证的（子问题，子答案）对，使得可以通过控制性重解题和自我一致性检查来进行步骤级的信心估计。通过精确定位不可靠的步骤并不断迭代性优化，该框架产生更准确、更可解释的推理链。实验结果表明，SSR在五个推理基准和三种LLM上的一致表现优于最新的迭代自我校正基准。此外，SSR提供了一种原理性的黑盒方法来评估和理解LLM的内部推理过程。", "conclusion": "实验结果展示了SSR框架在提高LLM推理准确性和解释性方面的优越性，并提供了一种系统的方法来评估和理解大型语言模型的内部推理机制。代码已开源。"}
{"llm_update_time": "20251116", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2511.10643", "html_url": "https://arxiv.org/abs/2511.10643", "title": "大语言模型的黑盒在线策略蒸馏", "title_en": "Black-Box On-Policy Distillation of Large Language Models", "authors": "Tianzhu Ye,Li Dong,Zewen Chi,Xun Wu,Shaohan Huang,Furu Wei", "background": "黑盒蒸馏通过让学生大语言模型（LLMs）学习教师模型的文本输出，而不接触其内部参数或内部逻辑，从而创建学生LLMs。现有的蒸馏方法往往依赖于序列级别的知识蒸馏，但这种方法存在稳定性和适应性问题。", "innovation": "提出了一种生成对抗蒸馏（GAD）方法，将学生LLM视为生成器，训练鉴别器以区别其响应和教师LLM的响应，形成一个最小最大博弈。鉴别器作为在线策略奖励模型，与学生LLM同时进化，提供稳定且适应的反馈。实验结果证明GAD优于常用的序列级别知识蒸馏方法，并表明使用GAD训练的学生模型Qwen2.5-14B-Instruct能够与教师模型GPT-5-Chat在LMSYS-Chat自动评估中达到相似水平。", "conclusion": "GAD为黑盒LLM蒸馏提供了一种有潜力且有效的范式，能够提供稳定且适应的反馈，有效提升学生模型的性能。"}
{"llm_update_time": "20251116", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2511.10645", "html_url": "https://arxiv.org/abs/2511.10645", "title": "ParoQuant: 用于高效推理LLM的成对旋转量化", "title_en": "ParoQuant: Pairwise Rotation Quantization for Efficient Reasoning LLM Inference", "authors": "Yesheng Liang,Haisheng Chen,Song Han,Zhijian Liu", "background": "大型语言模型（LLMs）的权重量化（PTQ）可以将权重压缩到低精度表示，以减少内存占用和加速推理。但权重和激活中的异常值会导致量化误差增大，尤其是在需要长时间思考推理的LLMs中，这种误差会累积，严重影响模型的准确度。现有的PTQ方法要么无法充分抑制异常值，要么在推理时会引入大量开销。", "innovation": "提出了成对旋转量化（ParoQuant），这是一种仅权重的PTQ方法，结合了硬件高效且可优化的独立吉文斯旋转与通道间缩放，使通道间幅度均衡并缩小每个量化组内的动态范围。此外，设计了推理内核，充分利用GPU并行性，确保旋转和缩放轻量级运行。ParoQuant在推理任务上比AWQ实现平均2.4%的准确度提升，且开销少于10%。", "conclusion": "成对旋转量化为更高效准确地部署推理LLMs铺平了道路。"}
{"llm_update_time": "20251116", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2511.09893", "html_url": "https://arxiv.org/abs/2511.09893", "title": "基于区域注意力增强的Swin变压器在临床相关医学图像描述中的应用", "title_en": "Regional Attention-Enhanced Swin Transformer for Clinically Relevant Medical Image Captioning", "authors": "Zubia Naz,Farhan Asghar,Muhammad Ishfaq Hussain,Yahya Hadadi,Muhammad Aasim Rafique,Wookjin Choi,Moongu Jeon", "background": "自动化医学图像描述可以将复杂的放射学图像转换为诊断叙事，这有助于支持报告流程。现有的系统通常无法很好地平衡语义准确性和模型的紧凑性与可解释性。", "innovation": "本文提出了一个结合了轻量级区域注意力模块的Swin-BART编码器-解码器系统，该模块在交叉注意力之前增强诊断相关性显著的区域。模型在ROCO数据集上进行训练和评估，达到了最先进的语义保真度，同时保持了紧凑性和可解释性。此外，本文还提供了消融实验、模态分析、配对显著性检验和可视化热图等结果，展示了提出的系统的优势。", "conclusion": "本文提出的方法改善了ROUGE、BERTScore等指标，并与基线系统相比取得了竞争性的BLEU、CIDEr和METEOR得分。实验还证明了区域注意力模块的效用和对不同模态的适用性，使得生成的描述具有准确和临床细节，并提供透明的区域属性，支持包含人类在内循环的研究使用。"}
{"llm_update_time": "20251116", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2511.09559", "html_url": "https://arxiv.org/abs/2511.09559", "title": "基于有向二分图的概率偏倚注意力机制在长尾ICD编码中的应用", "title_en": "Probability-Biased Attention over Directed Bipartite Graphs for Long-Tail ICD Coding", "authors": "Tianlei Chen,Yuxiao Chen,Yang Li,Feifei Wang", "background": "自动化国际疾病分类（ICD）编码旨在将多个疾病代码分配给临床文档，这在医疗信息学中是一项关键的多标签文本分类任务。然而，该任务因庞大的标签空间（10,000到20,000个代码）和长尾分布而颇具挑战性，其中少量主要代码占据主导地位，而许多罕见代码则缺乏足够的训练数据。", "innovation": "本文提出了一种建模细粒度代码共现关系的学习方法。具体地，该方法构建了一个有向二分图编码器，含有公共代码节点和罕见代码节点的独立集合。通过仅从公共代码到罕见代码的方向连接来促进单向信息流，并基于条件概率定义这些连接的性质，从而将偏倚注入编码器的注意力模块，该过程称之为共现编码。此外，利用大型语言模型（LLM）生成代码的全面描述，丰富了初始嵌入的临床背景和共病信息，为编码系统中的统计共现关系提供了外部知识。实验证明，该方法在三个自动化ICD编码基准数据集上取得了最佳性能，特别是在宏F1分数上表现尤为明显，这是长尾分类的关键指标。", "conclusion": "本文提出的方法在长尾ICD编码任务中取得了最先进的性能，特别是在关键指标宏F1上表现出显著的优势。"}
{"llm_update_time": "20251116", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2511.10067", "html_url": "https://arxiv.org/abs/2511.10067", "title": "通过多层自我完善学习增强LLMs的医疗情境意识能力", "title_en": "Enhancing the Medical Context-Awareness Ability of LLMs via Multifaceted Self-Refinement Learning", "authors": "Yuxuan Zhou,Yubin Wang,Bin Wang,Chen Ning,Xien Liu,Ji Wu,Jianye Hao", "background": "大语言模型（LLMs）在医学领域表现出巨大的潜力，已经在多个基准测试中取得了优异的成绩。然而，它们仍然在现实世界的医疗场景中表现不足，这些场景往往要求更强的情境意识，即识别缺失或至关重要的细节（如用户身份、病史、风险因素）并提供安全、有帮助且情境合适响应的能力。", "innovation": "提出了一个多层自我完善（MuSeR）方法，通过自我评估和改进来增强LLMs的情境意识能力。该方法设计了一个属性条件查询生成器，以模拟多样化的实际用户情境，并通过监督微调强化模型的情境意识能力。此外，通过知识蒸馏方法，将较小的LLM（如Qwen3-32B）的性能提升至新最佳水平。", "conclusion": "实验结果表明，MuSeR方法在HealthBench数据集上显著提高了LLM的性能，特别是在情境意识领域取得了明显的进步。通过对提出的方法进行监督微调，小型LLM（如Qwen3-32B）的性能超过了其教师模型，并在所有开源LLM上达到新记录（63.8%），其难度子集为43.1%。相关代码和数据将公开发布。"}
{"llm_update_time": "20251116", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2511.10281", "html_url": "https://arxiv.org/abs/2511.10281", "title": "FactGuard：基于事件中心和常识引导的假新闻检测", "title_en": "FactGuard: Event-Centric and Commonsense-Guided Fake News Detection", "authors": "Jing He,Han Zhang,Yuanhui Xiao,Wei Guo,Shaowen Yao,Renyang Liu", "background": "基于写作风格的假新闻检测方法已取得了显著进步，但随着对手模仿真实新闻写作风格能力的增强，这类方法的效果逐渐减弱。为了提高假新闻检测的有效性，最近的研究开始尝试将大型语言模型（LLMs）纳入其中，尽管这些模型有巨大的潜力，但在实际应用中仍未充分发挥作用，主要受限于浅显的功能探索、模糊的易用性以及高昂的推理成本。", "innovation": "本文提出了一种名为FactGuard的新颖假新闻检测框架，该框架利用大型语言模型提取事件中心内容，以减少写作风格对检测性能的影响。此外，该方法还引入了动态易用机制，通过识别事实推理中的矛盾和模糊情况，适配地综合大型语言模型的建议以提高决策的可靠性。为了确保效率和实际部署，采用了知识蒸馏技术开发了FactGuard-D模型，在冷启动和资源受限场景下有效运行。", "conclusion": "在两个基准数据集上的全面实验表明，本文的方法在鲁棒性和准确性上均优于现有方法，有效应对了假新闻检测中的写作风格敏感性和大型语言模型易用性挑战。"}
{"llm_update_time": "20251116", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2511.09926", "html_url": "https://arxiv.org/abs/2511.09926", "title": "预训练视觉变换器的类增量学习中补偿分布漂移", "title_en": "Compensating Distribution Drifts in Class-incremental Learning of Pre-trained Vision Transformers", "authors": "Xuan Rao,Simian Xu,Zheng Li,Bo Zhao,Derong Liu,Mingming Ha,Cesare Alippi", "background": "近年来的研究表明，通过序列微调（SeqFT）预训练的视觉变换器（ViTs），并使用类特征的近似分布来优化分类器，可以作为有效的类增量学习（CIL）策略。然而，这种做法对于分布漂移较为敏感，这种漂移是由共享主干参数的序列优化引起的结果不一致导致的。这会使得旧类别的分布与更新模型的分布之间产生偏差，最终随着时间的推移降低分类器的性能", "innovation": "本文提出了一个潜在空间过渡算子，并提出了一种序列学习与漂移补偿（SLDC）方法。SLDC旨在跨任务对特征分布进行对齐，以减轻漂移的影响。首先，提出了SLDC的线性版本，通过求解正则化最小二乘问题来学习一个线性算子，实现微调前后的特征映射。接着，进行了弱非线性SLDC版本的扩展，假设理想的过渡算子位于纯粹线性和完全非线性变换之间。该版本使用可学习的、弱非线性映射来平衡灵活性和泛化能力。为了进一步减少表示漂移，两种算法变体中都应用了知识蒸馏（KD）。实验结果表明，SLDC明显提高了SeqFT的表现。通过将知识蒸馏（KD）与分布漂移补偿的SLDC结合使用，SeqFT在所有评估数据集上的表现达到了与联合训练相当的水平", "conclusion": "本文通过提出SLDC方法，显著改善了SeqFT在类增量学习中的表现。实验结果表明，结合知识蒸馏（KD）和SLDC的SeqFT可以实现与联合训练相当的效果。"}
{"llm_update_time": "20251116", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2511.10240", "html_url": "https://arxiv.org/abs/2511.10240", "title": "ProgRAG：在知识图谱上具有 hallucination 抵抗性的逐步检索与推理", "title_en": "ProgRAG: Hallucination-Resistant Progressive Retrieval and Reasoning over Knowledge Graphs", "authors": "Minbae Park,Hyemin Yang,Jeonghyun Kim,Kunsoo Park,Hyunjoon Kim", "background": "大型语言模型 (LLMs) 在推理方面表现出色，但容易出现幻觉和透明度不足的问题。近期研究表明，将知识图谱 (KGs) 集成到LLMs中可以提升其推理性能，特别是对于复杂的、知识密集型任务。然而，这些方法仍然面临重大挑战，包括不准确的检索和推理失败，这些问题在处理长输入上下文时尤为明显。这些长输入上下文会遮蔽相关的信息，或者难以构建能够捕捉不同问题类型所需逻辑方向的上下文。此外，许多方法依赖LLMs直接从KG中检索证据，并自行评估证据的充分性，这往往会导致推理提前或错误。", "innovation": "本文提出了ProgRAG，一种多跳知识图谱问答 (KGQA) 框架，它将复杂问题分解为子问题，并逐步扩展部分推理路径。在每一步中，外部检索器收集候选证据，LLMs 通过不确定性感知的剪枝对这些证据进行优化。最后，通过组织和重新排列根据子问题答案获得的部分推理路径来优化LLMs推理的上下文。实验结果表明，与现有基线相比，ProgRAG在多跳KGQA任务中表现出更高的可靠性和推理质量。", "conclusion": "实验结果表明，ProgRAG在多跳KGQA中表现出了更高的可靠性和推理质量，解决了检索和推理失败的问题。"}
{"llm_update_time": "20251116", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2511.10289", "html_url": "https://arxiv.org/abs/2511.10289", "title": "Music Flamingo：在音频语言模型中规模化音乐理解", "title_en": "Music Flamingo: Scaling Music Understanding in Audio Language Models", "authors": "Sreyan Ghosh,Arushi Goel,Lasha Koroshinadze,Sang-gil Lee,Zhifeng Kong,Joao Felipe Santos,Ramani Duraiswami,Dinesh Manocha,Wei Ping,Mohammad Shoeybi,Bryan Catanzaro", "background": "尽管音频-自然语言研究进展迅速，但由于音乐动态性、层次结构和信息密集性所带来的挑战，音乐的理解仍然较为困难。此外，由于高质量音乐数据和标注稀缺，难以将开放音频理解模型进行扩展。因此，之前的模型只能产生简短的高层次描述，只能回答表面问题，并且在不同音乐文化中的泛化能力有限。", "innovation": "本文提出了一个新的大型音频-自然语言模型Music Flamingo，专门用于推进基础音频模型中的音乐理解。为了克服上述挑战，作者通过一个多阶段流水线创建了MF-Skills，该数据集包含了丰富的描述和问答对，涵盖了和声、结构、音色、歌词和文化背景等。此外，还添加了MF-Think数据集，该数据集基于音乐理论并经过GRPO（梯度策略优化）强化学习增强音乐理解相关技能。最终，Music Flamingo在多个音乐理解与推理基准测试中取得了最佳结果，并展示了模型如何从表面识别转向多层次、类人感知。", "conclusion": "Music Flamingo不仅在实证结果上表现优异，还通过展示模型从表面识别向多层次、类人感知的演化，确立了新的音乐理解标准，并为通力推进下一代能够与人类互动的音乐模型提供了基准和基础。"}
{"llm_update_time": "20251116", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2511.10287", "html_url": "https://arxiv.org/abs/2511.10287", "title": "OutSafe-Bench: 多模态大型语言模型有害内容检测标准", "title_en": "OutSafe-Bench: A Benchmark for Multimodal Offensive Content Detection in Large Language Models", "authors": "Yuping Yan,Yuhan Xie,Yuanshuai Li,Yingchao Yu,Lingjuan Lyu,Yaochu Jin", "background": "随着多模态大型语言模型（MLLMs）被越来越多地整合到日常工具和智能代理中，人们对它们可能输出的不安全内容的关注也在增加，这些不安全内容包括有毒语言、偏向性图像、隐私侵犯和有害 misinformation。目前的安全基准测试在模态覆盖和性能评估方面仍较为有限，经常忽视内容安全的广泛领域。因此，作者开发了OutSafe-Bench，这是首个针对多模态时代的一体化综合性内容安全评估测试套件，提供了超越现有基准的新模式，以推动研究和应用更加关注内容安全问题。\n", "innovation": "OutSafe-Bench 包含一项大型数据集，涵盖了四种模态的内容，包括超过18,000条中英双语文本提示，4,500张图片，450段音频剪辑，以及450段视频，所有这些内容都在9个关键内容风险类别上进行了系统标注。此外，还引入了多维度交叉风险评分（MCRS），这是一种新型的测评指标，用于建模和评估不同类别之间重叠和相关的内容风险。为了确保测评的公平性和稳健性，提出了FairScore框架，这是一个可解释的自动化多评审人加权聚合框架，可通过选择顶级模型作为适应性陪审团来减少单一模型判断带来的偏差，从而提高总体评估的可靠性。\n", "conclusion": "在对九种最先进的MLLM进行评估后，揭示了持续存在的重大安全漏洞，强调了在MLLM中建立强大防护的紧迫性。"}
{"llm_update_time": "20251116", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2511.10395", "html_url": "https://arxiv.org/abs/2511.10395", "title": "AgentEvolver：迈向高效自主演进智能体系统", "title_en": "AgentEvolver: Towards Efficient Self-Evolving Agent System", "authors": "Yunpeng Zhai,Shuchang Tao,Cheng Chen,Anni Zou,Ziqian Chen,Qingxu Fu,Shinji Mai,Li Yu,Jiaji Deng,Zouying Cao,Zhaoyang Liu,Bolin Ding,Jingren Zhou", "background": "自主智能体可通过推理、使用工具和执行复杂任务来显著提升人类生产力，在多种环境中有广泛的应用潜力。然而，当前这些智能体的开发方法存在成本高、效率低的问题，通常需要手工构建任务数据集并通过强化学习（RL）管道进行广泛探索学习，这导致了数据构建成本高昂、探索效率低下以及样本利用效率低下的问题。", "innovation": "本文提出了AgentEvolver，这是一种利用大型语言模型（LLM）的语义理解和推理能力的自我演化智能体系统。AgentEvolver通过引入三个协同机制解决了上述问题：（i）自我提问，实现好奇心驱动的任务生成，减少对手工制作数据集的依赖；（ii）自我导航，通过经验重用和混合策略指导提高探索效率；（iii）自我归因，通过根据轨迹状态和动作贡献分配不同的奖励来提高样本效率。整合这些机制，AgentEvolver能够实现智能体能力的规模化、低成本和持续提升。", "conclusion": "初步实验表明，与传统基于强化学习的基线相比，AgentEvolver实现了更高效的探索、更好的样本利用和更快的适应速度。这为通过语言模型驱动的自主智能体的开发提供了一种新的、有效的方法，有望显著提高智能体的自主学习能力。"}
{"llm_update_time": "20251116", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2511.10384", "html_url": "https://arxiv.org/abs/2511.10384", "title": "使用大型语言模型在社交网络中模拟信息传播", "title_en": "Simulating Misinformation Propagation in Social Networks using Large Language Models", "authors": "Raj Gaurav Maurya,Vaibhav Shukla,Raj Abhijit Dandekar,Rajat Dandekar,Sreedath Panat", "background": "社交媒体上广泛传播的错误信息利用了惊奇、情感和身份驱动的推理，常常通过人类认知偏差进行放大。为了探讨这些机制，本文将大型语言模型（LLM）的人格化为模拟用户级偏差、意识形态对齐和信任启发式的合成代理。在此设置中，引入了一个审计-节点框架来模拟和分析错误信息在这些代理的网络中传播时如何演变的过程。新闻文章传播在由人格化条件化的LLM节点组成的网络上，每个节点都在收到的内容基础上重新编写。基于问题-回答的审计员在每一步测量事实性，提供逐条声明可解释的事实性衰减跟踪.", "innovation": "提出了一个使用大型语言模型来模拟在社交网络中错误信息传播的框架。其中包含一个审计-节点框架，模拟和分析错误信息在由人格化条件化的LLM节点组成的网络中的传播过程。通过正式化错误信息指数和错误信息传播速率，量化事实衰减。通过实验发现基于身份和意识形态的人格加速了错误信息传播，而由专家驱动的人格则维持事实稳定性。进一步，通过受控随机分支模拟展示了早期错误一旦出现，不同人格间的交互会迅速升级到宣传级的错误.", "conclusion": "研究表明，LLM既作为人类偏见的代理，也作为审计评估信息忠实度的代理，发挥双重作用。提出的框架提供了一种解释性和基于经验的方法，用于研究、模拟和缓解数字生态系统中的信息传播。 taxonomy of misinformation severity (包含事实错误、谎言和宣传)将观察到的偏移与错误信息研究中的现有理论联系起来。"}
{"llm_update_time": "20251116", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2511.10400", "html_url": "https://arxiv.org/abs/2511.10400", "title": "重新思考多agent系统的可靠性：基于拜占庭故障容错的观点", "title_en": "Rethinking the Reliability of Multi-agent System: A Perspective from Byzantine Fault Tolerance", "authors": "Lifan Zheng,Jiawei Chen,Qinghong Yin,Jingyuan Zhang,Xinyi Zeng,Yu Tian", "background": "在多agent系统(MAS)中，确保agent架构的可靠性和及时识别故障agent是关键挑战。大型语言模型(LLLs)的进步使基于LLL的agent成为MAS的主要分支，为复杂问题解决和世界建模带来了突破。然而，基于LLL的agent替换传统agent是否能有效提升MAS的可靠性尚未被充分研究。本文从拜占庭故障容错的角度研究和量化了基于LLL的agent的可靠性，观察到当处理错误消息流时，基于LLL的agent表现出更强的怀疑态度，这使它们能够在不同拓扑结构中超越传统agent。", "innovation": "设计了一种名为CP-WBFT的基于信任度探测的加权拜占庭故障容错共识机制，通过利用LLL固有的反思性和区分性功能，采用基于探测的加权信息流传输方法，提升了基于LLL的agent的可靠性。实验结果表明，CP-WBFT在极端拜占庭条件下（85.7%的故障率）在各种网络拓扑下均表现出色，并且在数学推理和安全性评估任务中保持了强大的可靠性，显著超越了传统方法。", "conclusion": "该研究表明，基于LLL的agent更可靠，能有效提升MAS的稳定性和可靠性。提出的CP-WBFT机制在复杂网络拓扑条件下表现出优越的性能，能够在不同场景下保持高度的可靠性，对MAS的可靠性研究具有重要意义。"}
{"llm_update_time": "20251116", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2511.10566", "html_url": "https://arxiv.org/abs/2511.10566", "title": "层标准化对Transformer中记忆和泛化的影晌", "title_en": "Impact of Layer Norm on Memorization and Generalization in Transformers", "authors": "Rishi Singhal,Jung-Eun Kim", "background": "层标准化（LayerNorm）是Transformer中的基础组件，有助于稳定训练和优化。近年来，Pre-LayerNorm架构因其稳定的梯度流动而成为首选，而非Post-LayerNorm架构。尽管如此，层标准化对这些架构中的学习和记忆影响尚未明确。本文旨在探讨层标准化在Pre-和Post-LayerNorm架构中的影响，尤其是其对记忆和学习的促进效果。", "innovation": "本文揭示了层标准化在不同的Transformer架构中扮演的不同角色。在Pre-LayerNorm架构中，层标准化是一个关键因素，保证了稳定的学习；而在Post-LayerNorm架构中，层标准化影响记忆。还发现早期层的层标准化比中间或后期层更为关键。研究结果通过在6个视觉和语言数据集上的13个模型中验证，提供了对层标准化在塑造Transformer中记忆和学习作用的新见解。", "conclusion": "移除Pre-LayerNorm模型中的层标准化参数会加剧记忆并使学习不稳定，而在Post-LayerNorm模型中，这会通过恢复真实的标签有效缓解记忆。早期层的层标准化对记忆和学习的影响在Pre和Post层标准化模型中各不相同。"}
{"llm_update_time": "20251116", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2511.10615", "html_url": "https://arxiv.org/abs/2511.10615", "title": "轻量级VLMs及其定制LLM评估向盲人和低视力用户可达性的迈进", "title_en": "Towards Blind and Low-Vision Accessibility of Lightweight VLMs and Custom LLM-Evals", "authors": "Shruti Singh Baghel,Yash Pratap Singh Rathore,Sushovan Jena,Anurag Pradhan,Amit Shukla,Arnav Bhavsar,Pawan Goyal", "background": "大型视觉-语言模型（VLMs）擅长理解和生成视频描述，但其高内存、计算和部署需求阻碍了其在盲人和低视力（BLV）用户中的实际使用，这些用户依赖于详细的、情境相关的描述。", "innovation": "引入了两种专门为BLV可达性评估设计的新颖评估框架：用于评估空间定位、社会互动、动作事件和环境背景的多上下文BLV框架，以及专注于行动关键信息的导航辅助框架。此外，系统评估了四种不同的提示设计策略，并在智能手机上实现这两种模型，评估FP32和INT8精度变体，以评估资源受限的移动设备上的实际性能限制。", "conclusion": "研究了模型大小对无障碍重点关注描述质量的影响，评估了具有不同参数数量的SmolVLM2变体，旨在通过定制评估（LLM-Evals）框架，提升轻量级VLMs在盲人和低视力人群中的可达性及实用性。"}
{"llm_update_time": "20251116", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2511.10573", "html_url": "https://arxiv.org/abs/2511.10573", "title": "具有情感智能和负责任的强化学习", "title_en": "Towards Emotionally Intelligent and Responsible Reinforcement Learning", "authors": "Garapati Keerthana,Manik Gupta", "background": "现有的个性化决策系统在医疗保健和行为支持中通常依赖于静态规则或最大化参与度的经验法则，这些法则忽视了用户的心理状态和伦理约束。这种方法存在风险，尤其是在涉及严重精神疾病、物质使用障碍或抑郁症等领域，可能推荐不敏感或不安全的干预措施。", "innovation": "本文提出了一种负责任的强化学习（RRL）框架，该框架将情感理解和伦理考虑融入序列决策过程，将其形式化为受约束的马尔可夫决策过程（CMDP），以优化参与度和依从性，同时确保情感契合度和伦理安全性。还引入了一种多目标奖励函数，平衡短期行为参与与长期用户福祉，并定义了一种基于情感的状态表示，捕捉情绪准备度、情绪和风险的变化情况。该架构可以使用任何强化学习算法（如DQN、PPO）并附带安全约束或拉格朗日正则化来实现。", "conclusion": "本文旨在启动关于情感意识和可信赖个性化系统中伦理对齐强化学习的方法论讨论，探讨此方法在行为健康、教育和数字疗法等以人为本领域的含义，并概述未来实证工作的仿真验证路径。"}
{"llm_update_time": "20251116", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2406.15045", "html_url": "https://arxiv.org/abs/2406.15045", "title": "基于知识精简的多阶段框架在放射报告中的错误修正", "title_en": "Error Correction in Radiology Reports: A Knowledge Distillation-Based Multi-Stage Framework", "authors": "Jinge Wu,Zhaolong Wu,Ruizhe Li,Tong Chen,Abul Hasan,Yunsoo Kim,Jason P.Y. Cheung,Teng Zhang,Honghan Wu", "background": "临床放射学的复杂性和工作量增加导致使用放射学工具时不可避免地会出现误诊，导致治疗延迟甚至对患者造成生命威胁。虽然大型语言模型（LLMs）在多个任务上取得了显著的进步，但在放射学报告中的检测和纠正错误方面的作用有限。因此，本文分析了放射学报告中错误修正的背景。", "innovation": "本文提出了一种新颖的双重知识融合框架，通过系统地结合医学知识图谱精简（MKGD）和外部知识检索（EXKR），增强LLMs在放射学报告校对中的能力。具体来说，该方法将复杂校对任务分解为三个专门阶段：检测、定位和纠正，从而模仿专家放射科医生系统审查过程，确保精确性和临床可解释性。", "conclusion": "通过对多个LLM架构进行了广泛的评估，证实了本方法的显著改进：错误检测准确率提高最多可达31.56%，处理时间减少37.4%。同时也通过放射科医生的人工评估确认了该方法在临床相关性和事实一致性方面优于现有方法。"}
{"llm_update_time": "20251116", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2408.11062", "html_url": "https://arxiv.org/abs/2408.11062", "title": "使用大型语言模型进行多轮交互的文本到SQL转换", "title_en": "Multi-Turn Interactions for Text-to-SQL with Large Language Models", "authors": "Guanming Xiong,Junwei Bao,Hongfei Jiang,Yang Song,Wen Zhao", "background": "尽管近年来大型语言模型（LLMs）的推理能力有了显著进步，现有的基于LLM的方法在处理宽表时仍效率低下，且很难进行有效的交互。现有的基于交互的方法要么无法提供逐步且可解释的SQL生成过程，要么不能提供普遍适用的交互设计。", "innovation": "提出了Interactive-T2S框架，这是一种通过直接与数据库交互生成SQL查询的方法。该框架包括四个通用工具，帮助LLM进行主动且高效的的信息检索。此外，还开发了详细的示例，展示框架内部的逐步推理过程。该方法在Spider和BIRD数据集及其变体上达到了先进的性能，并且在没有先验知识的情况下获得BIRD排行榜的最好结果，证明了方法的有效性。", "conclusion": "Interactive-T2S框架和逐步推理过程使得生成SQL查询变得更为高效和可解释，验证了该方法在多种数据集上的有效性和先进性。"}
{"llm_update_time": "20251116", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2407.03646", "html_url": "https://arxiv.org/abs/2407.03646", "title": "使用在线计算工具自动提取的语言特征区分人类撰写的文本和AI生成的文本", "title_en": "Differentiating between human-written and AI-generated texts using linguistic features automatically extracted from an online computational tool", "authors": "Georgios P. Georgiou", "background": "尽管近年来对ChatGPT的研究十分广泛，但很少有研究系统地量化和比较人类写作和AI生成语言的特征差异。该研究旨在探讨不同类型文本中各种语言成分的表示方式，评估AI模仿人类写作的能力。研究人员以人类撰写的文章为基准，促使ChatGPT生成等长度的文章，并使用在线计算工具Open Brain AI提取语音学、形态学、句法学和词汇学构成的度量标准。研究结果表明，尽管AI生成的文本表面上模仿了人类语言，但在多个语言特征上仍然存在显著差异，这些发现突显了集成自动化工具进行高效语言评估的重要性，以减少数据分析的时间和努力。", "innovation": "该研究利用ChatGPT生成等长度的文章，并通过一种在线计算工具（Open Brain AI）自动提取语音学、形态学、句法学和词汇学构成的度量标准，系统地量化和比较了人类写作和AI生成语言的特征。这是首次针对ChatGPT进行了这种系统性的语言分析研究。", "conclusion": "这些发现强调了集成自动化工具进行高效语言评估的重要性，以减轻数据分析的时间和努力。此外，它们还强调了提高AI生成更接近人类写作能力的必要性，通过改进训练方法。"}
{"llm_update_time": "20251116", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2408.13171", "html_url": "https://arxiv.org/abs/2408.13171", "title": "共创之路：包容性手语技术开发中的棘手事实", "title_en": "Lessons in co-creation: the inconvenient truths of inclusive sign language technology development", "authors": "Maartje De Meulder,Davy Van Landuyt,Rehana Omardeen", "background": "在人工智能驱动的语言技术时代，聋人社区参与手语技术的研发，尤其是作为一个共同创造过程的视角下，越来越受到重视。本文通过两个历时两年的欧盟项目（2021-2023），对欧洲聋人主导的非政府组织进行了案例研究，旨在探讨共同创造作为一种实践和话语的含义。", "innovation": "文章提出了五个使共同创造具有实质性的教训：1) 认识并资源分配聋人伙伴们的隐形工作，2) 通过无障碍科学传播管理期望值，3) 通过根除结构性体能主义来使共同创造成为现实，4) 采用多样化的参与方法以应对共同创造疲劳及交叉性问题，5) 通过聋人领导分配权力。这些教训填补了多合作伙伴人工智能项目中的共同创造理论与实践之间的空白，并对包容性手语技术开发具有实际指导意义。", "conclusion": "本文提供了一项基于经验的手语技术中共同创造的具体实践，同时对包容性手语技术开发设计提供了可操作的指导意见，拓展了参与式人工智能应用于边缘化语言和残疾社区的研究。"}
{"llm_update_time": "20251116", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2410.09019", "html_url": "https://arxiv.org/abs/2410.09019", "title": "MedMobile：一款具有临床能力的移动大小语言模型", "title_en": "MedMobile: A mobile-sized language model with clinical capabilities", "authors": "Krithik Vishwanath,Jaden Stryker,Anton Alyakin,Daniel Alexander Alber,Eric Karl Oermann", "background": "语言模型在医学领域已经展现了专家级的推理和记忆能力，但计算成本和隐私问题正成为大规模实施的重要障碍。", "innovation": "该研究引入了一种简化的phi-3-mini适应版本，即MedMobile，这是一种38亿参数的语言模型，能够在移动设备上运行，专门用于医学应用。通过一系列精心设计的流水线添加，该研究发现逻辑推理链、模型集成和微调带来了最大的性能提升，而检索增强生成并未显示出显著改进。MedMobile在MultiMedQA和MedBullets上的效率评估显示了出色的性能，特别是在MedQA (USMLE)上达到了75.7%的得分，这一成绩超过了合格医生的门槛（大約60%），甚至与规模比自己大100倍的模型相媲美。此外，MedMobile是首个通过MedQA (USMLE)的最小模型，在50亿参数以下的模型中实现了SOTA性能，展示了其在计算资源需求和快速推理速度上的优势。", "conclusion": "MedMobile有望促进医学语言模型的普及，降低计算需求并提高快速推理速度。凭借其解决医学语言模型主要障碍的能力，作者认为MedMobile是开发临床相关语言模型的一个关键步骤。"}
{"llm_update_time": "20251116", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2411.18634", "html_url": "https://arxiv.org/abs/2411.18634", "title": "人类Wordle游戏中的语义、拼写和音韵偏差", "title_en": "Semantic, Orthographic, and Phonological Biases in Humans' Wordle Gameplay", "authors": "Jiadong Liang,Adam Kabbara,Jiaying Liu,Ronaldo Luo,Kina Kim,Michael Guerzhoy", "background": "本研究探讨了玩家在Wordle游戏中决策受到语义、拼写和音韵的影响。通过对比实际玩家的猜测与接近最优的猜测，使用自然语言处理技术，研究人类语言在受限环境下的使用情况，该环境介于自然语言使用和人造词汇关联任务之间。", "innovation": "研究发现，玩家在Wordle中的猜测受到语义、拼写和音韵的影响，通过NLP技术对比实际玩家与最优猜测，揭示了人类语言使用在受限环境中的微妙差别。", "conclusion": "本研究展示了人类玩家在Wordle中的游戏行为受到语义、拼写和音韵的显著影响，通过对比分析发现人类语言使用在受限环境中的特点，为更好地理解人类语言处理提供了新的视角。"}
{"llm_update_time": "20251116", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2501.11094", "html_url": "https://arxiv.org/abs/2501.11094", "title": "使用CNN-BiLSTM混合模型从社交媒体中增强自杀意念检测", "title_en": "Enhanced Suicidal Ideation Detection from Social Media Using a CNN-BiLSTM Hybrid Model", "authors": "Mohaiminul Islam Bhuiyan,Nur Shazwani Kamarudin,Nur Hafieza Ismail", "background": "自杀意念的检测对于预防自杀这一全球主要死因至关重要。许多人在社交媒体上表达了自杀的想法，为通过先进的机器学习技术进行早期检测提供了重要机会。", "innovation": "本文提出了一种结合卷积神经网络（CNN）和双向长短期记忆（BiLSTM）的混合框架，并通过注意力机制进一步优化，以提高社交媒体文本中自杀意念的识别效果。为了增强模型预测的可解释性，应用了解释性人工智能（XAI）方法，特别是SHapley Additive exPlanations（SHAP）。通过改进和早停技术，模型的准确率从最初的92.81%提升到了94.29%。SHAP分析揭示了影响模型预测的关键特征，从而提高了模型的透明度和可信度，有助于心理健康专业人员理解和信任预测结果。", "conclusion": "本文通过提升准确性和可解释性，强调了使用强大的机器学习方法与解释性的结合来改进自杀倾向检测的潜力，为心理健康监控系统的发展做出了宝贵贡献。"}
{"llm_update_time": "20251116", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2410.21597", "html_url": "https://arxiv.org/abs/2410.21597", "title": "减少语言模型的作用范围", "title_en": "Reducing the Scope of Language Models", "authors": "David Yunis,Siyu Huo,Chulaka Gunasekara,Danish Contractor", "background": "大型语言模型（LLMs）在多种用户界面应用中部署，虽然它们通常有特定用途，如文档基础上的问题回答和编程助手等，但也需要具备一般语言理解能力。在这些部署中，LLMs应当只回应那些符合预定目的的查询，而拒绝其他请求，例如诗歌生成或物理问题回答。这项研究旨在探讨如何通过不同方法‘规范围积’LLMs，确保它们只执行期望的任务而不偏离主题。研究覆盖了多种语言模型和各类任务，通过实证分析发现，方法效果会因无关查询多样性的不同而异。", "innovation": "该研究设计了全面的实证评估方法，检验了多种规范围积LLMs的方法，包括提示、微调、偏好学习以及近日提出的通用对齐技术‘电路断路器’。研究发现，当存在多样化的无关查询示例时，简单的监督微调表现最佳；但在多样性较低时，‘电路断路器’效果很好。还发现通过层层叠加不同方法可以兼顾两者的优势。这项研究旨在为实践者提供一份规范围积LLMs的指南，为贴近实际应用提供了实用指导。", "conclusion": "本研究通过全面分析多种规范围积方法的有效性，展示了在不同任务和语言模型类型下规范围积的技术可能性。结果表明，虽然不同方法在不同的情况下表现各异，但通过深入研究和创新技术的综合使用，可以有效规范围积LLMs。"}
{"llm_update_time": "20251116", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2410.17337", "html_url": "https://arxiv.org/abs/2410.17337", "title": "Captions Speak Louder than Images: Generalizing Foundation Models for E-commerce from High-quality Multimodal Instruction Data", "title_en": "Captions Speak Louder than Images: Generalizing Foundation Models for E-commerce from High-quality Multimodal Instruction Data", "authors": "Xinyi Ling,Hanwen Du,Bo Peng,Zhihui Zhu,Xia Ning", "background": "通过多模态数据推动电子商务应用取得突破，吸引了越来越多研究社区的关注。然而，存在的挑战限制了基础模型对多模态电子商务数据的充分运用，主要包括大规模高质量多模态基准数据集的稀缺性以及有效的多模态信息融合方法的缺乏。为了应对这些问题，本文提出了一种名为MMECInstruct的大规模高质量电子商务多模态指令数据集，并开发了CASLIE框架，该框架可以简化、轻量化且有效地整合多模态信息。通过对电子商务多模态基础模型在CASLIE框架上的微调，展示了CASLIE模型相比于多种先进的对照模型在领域内评估中明显优越，并且具有良好的跨领域泛化能力。其中，数据集和模型已经在官方地址上公开。", "innovation": "本文的创新点在于提出的MMECInstruct数据集和CASLIE框架。MMECInstruct数据集是首个大规模高质量的电子商务多模态指令数据集，CASLIE框架是一种轻量级且有效的多模态信息整合方法，通过该方法对电子商务多模态基础模型进行微调后，构建了CASLIE模型，该系列模型在领域内评估中显著优于多种先进的对照模型，并且表现出良好的跨领域泛化能力。", "conclusion": "研究结果表明，通过MMECInstruct数据集和CASLIE框架构建的CASLIE模型，在电子商务应用中表现优异，特别是在多模态数据的利用上取得了突破，为进一步研究和实际应用提供了强有力的数据支持和方法指导。相关数据集和模型已在官方地址上公开，以供进一步研究使用。"}
{"llm_update_time": "20251116", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2501.14250", "html_url": "https://arxiv.org/abs/2501.14250", "title": "Siren: 一种基于学习的多轮攻击框架，用于模拟真实世界的人类越狱行为", "title_en": "Siren: A Learning-Based Multi-Turn Attack Framework for Simulating Real-World Human Jailbreak Behaviors", "authors": "Yi Zhao,Youzhi Zhang", "background": "大语言模型（LLMs）在实际应用中被广泛使用，这引起对其安全性和可信度的关注。现有的红队测试方法主要使用撤销提示来揭示LLMs的漏洞，但这些方法大多集中于单一回合攻击，忽视了实际对手可能使用的多轮策略。现有的多轮方法依赖于固定模式或预先定义的逻辑链，未能考虑到攻击过程中的动态策略。", "innovation": "本文提出了一种基于学习的多轮攻击框架Siren，旨在模拟真实世界人类对LLMs进行越狱的行为。该框架包括三个阶段：（1）利用Turn-Level LLM反馈的小样本驱动训练集构建；（2）后训练攻击者通过有监督微调和直接偏好优化；（3）攻击者与目标LLM之间的交互。实验结果表明，Siren在攻击成功率（ASR）方面优于传统的单一回合基准，特别是在攻防双方都是大型模型的情况下，Siren的表现与更复杂的多轮方法相当，但所需回合较少且分解策略更符合攻击目标的语义对齐。", "conclusion": "Siren有望激励在实际场景下开发更强的防御措施，以对抗复杂的多轮越狱攻击。同时，该文也指出，包含潜在有害文本的代码可通过这个链接获取。"}
{"llm_update_time": "20251116", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2502.02390", "html_url": "https://arxiv.org/abs/2502.02390", "title": "CoAT: 一种增强大型语言模型推理的关联思维链框架", "title_en": "CoAT: Chain-of-Associated-Thoughts Framework for Enhancing Large Language Models Reasoning", "authors": "Jianfeng Pan,Senyou Deng,Shaomang Huang", "background": "LLM技术正在快速兴起，大多数使用“快思考”方法进行推理。它们主要基于单一查询和模型自身的推理能力生成最终结果。然而，OpenAI-o1的出现引起了人们的关注，因为它采用的“慢思考”技术更接近人类的思考过程。基于人类不断关联和补充知识的能力，该研究开发了一种名为CoAT（Chain-of-Associated-Thoughts）的新颖框架，引入了蒙特卡洛树搜索（MCTS）算法与动态的新关键信息整合机制（称为‘联想记忆’）的融合。", "innovation": "CoAT框架结合了MCTS的结构化探索能力和联想记忆的自适应学习能力，显著扩展了LLM的搜索空间，使其能够探索多样的推理路径并实时更新知识库。这使得框架不仅能重新审视和精炼早期推理，还能适应性地整合不断变化的信息，确保输出的准确性和全面性。", "conclusion": "该研究通过在各种生成和推理任务上的定量实验验证了CoAT的有效性，表明它在开源多跳推理数据集（HotpotQA，MuSiQue）和自有的CRB数据集上的性能分别提高了超过10%和15%。"}
{"llm_update_time": "20251116", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2502.13595", "html_url": "https://arxiv.org/abs/2502.13595", "title": "MMTEB: 巨量多语言文本嵌入基准", "title_en": "MMTEB: Massive Multilingual Text Embedding Benchmark", "authors": "Kenneth Enevoldsen,Isaac Chung,Imene Kerboua,Márton Kardos,Ashwin Mathur,David Stap,Jay Gala,Wissam Siblini,Dominik Krzemiński,Genta Indra Winata,Saba Sturua,Saiteja Utpala,Mathieu Ciancone,Marion Schaeffer,Gabriel Sequeira,Diganta Misra,Shreeya Dhakal,Jonathan Rystrøm,Roman Solomatin,Ömer Çağatan,Akash Kundu,Martin Bernstorff,Shitao Xiao,Akshita Sukhlecha,Bhavish Pahwa,Rafał Poświata,Kranthi Kiran GV,Shawon Ashraf,Daniel Auras,Björn Plüster,Jan Philipp Harries,Loïc Magne,Isabelle Mohr,Mariya Hendriksen,Dawei Zhu,Hippolyte Gisserot-Boukhlef,Tom Aarsen,Jan Kostkan,Konrad Wojtasik,Taemin Lee,Marek Šuppa,Crystina Zhang,Roberta Rocca,Mohammed Hamdy,Andrianos Michail,John Yang,Manuel Faysse,Aleksei Vatolin,Nandan Thakur,Manan Dey,Dipam Vasani,Pranjal Chitale,Simone Tedeschi,Nguyen Tai,Artem Snegirev,Michael Günther,Mengzhou Xia,Weijia Shi,Xing Han Lù,Jordan Clive,Gayatri Krishnakumar,Anna Maksimova,Silvan Wehrli,Maria Tikhonova,Henil Panchal,Aleksandr Abramov,Malte Ostendorff,Zheng Liu,Simon Clematide,Lester James Miranda,Alena Fenogenova,Guangyu Song,Ruqiya Bin Safi,Wen-Ding Li,Alessia Borghini,Federico Cassano,Hongjin Su,Jimmy Lin,Howard Yen,Lasse Hansen,Sara Hooker,Chenghao Xiao,Vaibhav Adlakha,Orion Weller,Siva Reddy,Niklas Muennighoff", "background": "文本嵌入通常在受限的、语言和领域多样性有限的任务集上进行评估。MMTEB旨在解决这些问题，提供一个全面的评估标准，涵盖超过500个质量控制的评估任务，涉及250多种语言，并包括多种挑战性和新颖的任务，如指令遵循、长文档检索和代码检索。", "innovation": "MMTEB是一个大规模、社区驱动的扩展，增加了超过500个质量控制的评估任务，覆盖250多种语言。通过该集合，开发了多个高度多语言基准，用于评估代表性模型。MMTEB提出了一种基于任务间相关性的新颖降采样方法，确保多样选择的同时保持相对模型排名。此外，MMTEB通过采样硬负例优化检索任务，创建了更小但有效的子集，大大降低了计算需求。", "conclusion": "虽然具有数十亿参数的大语言模型（LLMs）在某些语言子集和任务类别上达到了最先进的性能，但最佳表现的公共模型为具有5.6亿参数的multilingual-e5-large-instruct。MMTEB通过引入基准测试大幅减少了计算需求，如零样本的英语基准，保持了与全规模版本相似的排名顺序，但计算成本大大降低。"}
{"llm_update_time": "20251116", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2502.18573", "html_url": "https://arxiv.org/abs/2502.18573", "title": "FactReasoner: 长文本事实评估的概率方法", "title_en": "FactReasoner: A Probabilistic Approach to Long-Form Factuality Assessment for Large Language Models", "authors": "Radu Marinescu,Debarun Bhattacharjya,Junkyu Lee,Tigran Tchrakian,Javier Carnerero Cano,Yufang Hou,Elizabeth Daly,Alessandra Pascale", "background": "大语言模型（LLMs）在生成任务中取得了显著的成功，但往往在确保生成结果的真实性方面存在不足，限制了其在正确性至关重要的实际应用场景中的可靠性。现有基于提示的方法在真实性和召回率上无法满足需求，急需新的解决方案来提升语言模型生成内容的真实性验证能力。", "innovation": "本文提出了一种新颖的神经符号事实性评估框架FactReasoner，通过概率推理评估长文本生成响应的真实性。FactReasoner将响应分解为原子单元，从外部知识源检索相关背景信息，并使用概率编码建模这些单元与其背景之间的逻辑关系（如蕴含、矛盾）。此外，它还提供了每个原子单元得到证据支持的概率估计。实验证明，FactReasoner在真实性和召回率上通常优于现有基于提示的方法。", "conclusion": "本文通过公开的实验证明，FactReasoner在基准数据集（包括有标签和无标签数据）上显著提升了LLMs生成内容的真实性和召回率。研究者已将开源代码发布在公开渠道，为语言模型性能评估和提升提供重要工具。"}
{"llm_update_time": "20251116", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2504.03595", "html_url": "https://arxiv.org/abs/2504.03595", "title": "基于FlexOffers扩展SAREF4ENER本体", "title_en": "Extending the SAREF4ENER Ontology with Flexibility Based on FlexOffers", "authors": "Fabio Lilliu(1),Amir Laadhar(2),Christian Thomsen(3),Diego Reforgiato Recupero(1),Torben Bach Pedersen(3) ((1) University of Cagliari, (2) PANTOPIX GmbH &amp; Co. KG, (3) Aalborg University)", "background": "为了支持能源系统中日益增加的可再生能源比例，灵活性（即能源负荷在时间和数量上的改变可能性）是关键要素之一。尽管已设计了许多灵活性模型，但现有的精确模型难以扩展至长时间段或大量设备。为解决这一问题，FlexOffers模型被设计出来，提供设备无关的灵活性近似值，具备较高的精度和更好的扩展性。此外，智能能源领域的实际实施需要灵活的数据交换机制与多种智能能源设备及市场系统交互，特别是智能建筑领域。然而，当前用于集成智能设备的能量领域的行业标准本体SAREF4ENER仅有限地支持灵活性，无法支持关键用例。", "innovation": "本文提出了一种基于FlexOffers扩展SAREF4ENER本体的方法，增强了对FlexOffer模型的全面支持，包括高级用例，同时保持向后兼容性。这种新型本体模块可以准确描述先进的柔性设备（如电动汽车、电池和热泵）的灵活性，同时捕捉许多灵活负载类型的内在不确定性。", "conclusion": "通过扩展SAREF4ENER本体，本文提出的模块能够更准确地描述灵活性，并支持更多高级设备的应用场景，从而更好地适应智能能源领域的需求。"}
{"llm_update_time": "20251116", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2505.14990", "html_url": "https://arxiv.org/abs/2505.14990", "title": "语言特定知识：模型在X语言中表现更好吗？", "title_en": "Language Specific Knowledge: Do Models Know Better in X than in English?", "authors": "Ishika Agarwal,Nimet Beyza Bozdag,Dilek Hakkani-Tür", "background": "通常，多语言模型旨在将不同语言中语义相似的内容映射到相同的潜在空间中进行训练。然而，本文揭示了训练目标的一个新的细微之处，发现通过更改输入查询的语言，可以提高语言模型的问答能力。", "innovation": "本文的贡献有两部分。首先，提出\"语言特定知识\"(LSK)的概念，指针对给定的大语言模型，在特定语言中最优的问题查询，进而提升其问答能力。同时引入了语言选择问题，即对于某些查询，模型在非英语语言中的表现更好，有时甚至在资源较少的语言中表现更佳。目标是选择最合适的语言进行查询。其次，引入了从简单到强大的基线测试这个问题，还设计了LSKExtractor作为初步解决方案，用于基准测试语言特定知识，并在推理时加以利用。", "conclusion": "LSKExtractor在三个包含文化和社交行为规范知识的数据集上实现了高达10%的相对改进，并且在较强的基线下具有竞争力，同时在实际应用场景中是可行的。从广泛的角度说，我们的研究为开源的发展多语言模型做出了贡献，这些模型更加包容并且更符合其部署的文化和语言背景。"}
{"llm_update_time": "20251116", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2505.16838", "html_url": "https://arxiv.org/abs/2505.16838", "title": "R1-Compress: 长 Chain-of-Thought 压缩通过分块压缩和搜索实现", "title_en": "R1-Compress: Long Chain-of-Thought Compression via Chunk Compression and Search", "authors": "Yibo Wang,Haotian Luo,Huanjin Yao,Tiansheng Huang,Haiying He,Rui Liu,Naiqiang Tan,Jiaxing Huang,Xiaochun Cao,Dacheng Tao,Li Shen", "background": "Chain-of-Thought (CoT) 理论增强了大规模语言模型 (LLM) 的问题解决能力，但将其扩展到长 CoT（Long-CoT）由于增加的 token 长度，引入了显著的计算开销。现有的压缩方法——实例级和 token 级——要么牺牲了关键的本地推理信号，比如反思，要么导致输出不一致。", "innovation": "提出了 R1-Compress，这是一种双阶段块级压缩框架，旨在同时保持局部信息和连贯性。该方法将长 CoT 分段为可管理的块，应用 LLM 驱动的块内压缩，并使用跨块搜索机制选择简短且连贯的序列。", "conclusion": "实验表明，R1-Compress 在减少 token 使用量的同时，显著保持了可比较的推理准确性。例如，在 MATH500 测试上，R1-Compress 达到了 92.4% 的准确率，比长 CoT 基线仅下降了 0.6%，同时 token 使用量减少了约 20%。"}
{"llm_update_time": "20251116", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2506.01939", "html_url": "https://arxiv.org/abs/2506.01939", "title": "超越80/20法则：高熵少数令牌驱动有效的LLM推理强化学习", "title_en": "Beyond the 80/20 Rule: High-Entropy Minority Tokens Drive Effective Reinforcement Learning for LLM Reasoning", "authors": "Shenzhi Wang,Le Yu,Chang Gao,Chujie Zheng,Shixuan Liu,Rui Lu,Kai Dang,Xionghui Chen,Jianxin Yang,Zhenru Zhang,Yuqiong Liu,An Yang,Andrew Zhao,Yang Yue,Shiji Song,Bowen Yu,Gao Huang,Junyang Lin", "background": "奖励学习（RLVR）作为一种增强大型语言模型（LLMs）推理能力的有力方法已经出现，但其机制尚未被充分理解。本文通过对标记熵模式的新视角进行RLVR的开创性探索，全面分析不同标记对推理性能的影响。", "innovation": "研究表明，只有少数高熵标记（即分叉标记）显著影响推理路径，RLVR主要调整这些高熵标记的熵。基于此发现，研究通过限制策略梯度更新到分叉标记来改进RLVR，并且发现使用仅20%的令牌就能在保留与全梯度更新相当的性能的基础上超越全梯度更新。这些发现表明，RLVR的有效性主要来自于优化决定推理方向的高熵标记。这一方法验证了从标记熵视角理解RLVR和利用高熵少数标记进一步改进LLM推理的潜力。", "conclusion": "我们的结果表明，通过利用高熵少数令牌优化RLVR可以进一步提高LLM的推理性能。与仅训练最低熵80%令牌相比，优化高熵令牌对于提高LLM推理的有效性更为关键。"}
{"llm_update_time": "20251116", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2506.19794", "html_url": "https://arxiv.org/abs/2506.19794", "title": "为何开源大语言模型在数据分析中表现不佳？一项系统性的实证研究", "title_en": "Why Do Open-Source LLMs Struggle with Data Analysis? A Systematic Empirical Study", "authors": "Yuqi Zhu,Yi Zhong,Jintian Zhang,Ziheng Zhang,Shuofei Qiao,Yujie Luo,Lun Du,Da Zheng,Ningyu Zhang,Huajun Chen", "background": "开源大语言模型（LLMs）在自动化数据分析任务方面展现出潜力，但在需要大量推理的情景中存在明显限制。现有的开源LLMs在处理复杂数据理解和编程任务时遇到挑战。为了改进开源LLMs的数据分析能力，作者通过构建一个多样且现实的数据集，从三个核心维度评估模型表现：数据理解、代码生成和策略规划。研究表明，策略规划的质量是决定模型性能的主要因素，交互设计和任务复杂度显著影响推理能力，而数据质量比多样性对性能优化的影响更大。基于研究发现，作者提出了一种数据合成方法，显著提升了开源LLMs在分析推理能力方面的能力。研究结果表明，高质量的策略规划和优化的数据质量对于提高机器人的数据分析能力至关重要。相关代码可在指定链接获取。", "innovation": "本研究通过系统评估开源LLMs在数据理解、代码生成和策略规划三个方面的表现，揭示了影响模型性能的关键因素，并据此开发了一种数据合成方法，显著提高了开源LLMs的分析推理能力。该方法强调了高质量策略规划和优化数据质量的重要性，并提供了实证支持，为提升开源LLMs的实用性和效能提供了宝贵见解。", "conclusion": "研究结果表明，策略规划质量是最主要影响因素，交互设计和任务复杂度对推理有显著影响，而高质量的数据比多样化的数据样例对提升性能更有效。研究提出了一种新的数据合成方法，显著增强了开源LLMs的分析推理能力，相关代码已开源。"}
{"llm_update_time": "20251116", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.02635", "html_url": "https://arxiv.org/abs/2508.02635", "title": "多语言LLM评估中的测试集质量", "title_en": "Test Set Quality in Multilingual LLM Evaluation", "authors": "Chalamalasetti Kranti,Gabriel Bernier-Colborne,Yvan Gauthier,Sowmya Vajjala", "background": "近年来，已经开发了多种半自动多语言基准数据集以衡量大型语言模型的多语言能力，理解其最新状态。然而，很少考虑这些数据集本身的质量，尽管之前的工作已经指出了即使在完全由人工注释的测试集中也存在错误。本研究分析了两种语言（法语和泰卢固语）的最近多语言评估集，发现了多个错误，并比较了多个大型语言模型在原始版本和修订版本的数据集上的性能差异，在某些情况下差异高达几乎10%。这些结果显示测试集不应被视为不可改变的，应重新检查其准确性，并可能进行版本更新。", "innovation": "本研究通过手动分析近期的多语言评估集，发现了多个错误，并通过比较不同大型语言模型在原版和修订版数据集上的性能差异，提出了重新审视和检查测试集正确性的建议，并讨论了数据集质量的问题。这是对测试集质量和稳定性的创新性研究，强调了数据集维护的重要性。", "conclusion": "本研究建议测试集不应被视为不可改变的，应该定期重新检查其准确性，并确定其是否需要版本更新。此外，还为数据集创建者和使用者提供了多项建议来解决数据集质量问题。"}
{"llm_update_time": "20251116", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.05909", "html_url": "https://arxiv.org/abs/2508.05909", "title": "超越困惑度：通过光谱投影得分让阅读器选择检索摘要", "title_en": "Beyond Perplexity: Let the Reader Select Retrieval Summaries via Spectrum Projection Score", "authors": "Zhanghao Hu,Qinglin Zhu,Siya Qi,Yulan He,Hanqi Yan,Lin Gui", "background": "大型语言模型（LLMs）通过检索增强生成（RAG）方法展示了改进的生成性能，这种方法遵循检索器-阅读者范式，通过为模型输入补充外部检索知识。然而，先前的研究经常将RAG作为一个整体进行评估，同时评估检索器和阅读器，这使得分离检索的真实贡献变得困难，尤其是考虑到LLMs作为阅读器的提示敏感性问题。", "innovation": "提出了一种名为Spectrum Projection Score (SPS)的轻量级且无需监督的度量标准，允许阅读器通过比较生成令牌区域与阅读器子空间的主要方向来评估检索摘要与隐藏表示的语义对齐。基于SPS，提出了xCompress，一种推理时控制器框架，能够动态地抽取、排序和压缩检索摘要候选者。实验证明，SPS不仅能提高跨多种任务的性能，还为检索和生成之间的互动提供了一个有原则的观点。", "conclusion": "广泛的实验表明，SPS在多个问答基准上增强了模型表现，并且还为评估检索和生成之间的交互提供了有依据的方法。xCompress框架有助于实现实时高效的检索摘要控制。"}
{"llm_update_time": "20251116", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2506.00400", "html_url": "https://arxiv.org/abs/2506.00400", "title": "基于采样动量的文本梯度扩展", "title_en": "Scaling Textual Gradients via Sampling-Based Momentum", "authors": "Zixin Ding,Junyuan Hong,Jiachen T. Wang,Zinan Lin,Li Yin,Meng Liu,Zhangyang Wang,Yuxin Chen", "background": "基于大语言模型（LLM）的提示优化方法，通过利用LLM提供的'文本梯度'（反馈）来精炼提示，已成为自动提示工程的有效方法。然而，当使用更多数据进行训练时，其可扩展性和稳定性仍然不清楚。本研究系统地探讨了在文本梯度下降中利用训练数据扩展的潜在和挑战。研究表明，简单地扩展训练示例是不可行的，因为存在显式的上下文长度限制和隐含的上下文墙，这导致长上下文降解的效益递减。", "innovation": "受随机梯度下降中先验智慧的启发，本研究提出了一种基于采样动量的文本随机梯度下降（TSGD-M）方法，该方法通过使用带有重要性权重的历史提示的带动量采样的批量验证准确度进行加权更新。此外，研究还引入了一种Gumbel-Top-$k$采样方法，平衡了探索与利用的权衡，提高了采样效率，并维持了低方差运行平均估计器。TSGD-M可以无缝整合到现有的提示优化框架中，包括TextGrad、DSPy-COPRO和AdalFlow，并在5个基准测试中实现了持续的增益。研究发现强调了将概率探索纳入文本梯度优化的重要性，为更加稳定和可扩展的提示优化铺平了道路。", "conclusion": "研究发现，将概率探索融入基于文本梯度的优化中对于实现更稳定和可扩展的提示优化具有重要意义，TSGD-M方法在多种基准测试中表现出一致的优化增益，并为未来的工作指明了方向。"}
{"llm_update_time": "20251116", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.02573", "html_url": "https://arxiv.org/abs/2508.02573", "title": "猜测还是回忆？基于CNN分类和定位LLMs中的记忆现象", "title_en": "Guess or Recall? Training CNNs to Classify and Localize Memorization in LLMs", "authors": "Jérémie Dentan,Davide Buscaldi,Sonia Vanier", "background": "大型语言模型（LLMs）中的逐字记忆（verbatim memorization）是涉及多种底层机制的复杂现象。现有的分类方法未能准确反映这些机制，因此需要引入新的方法来分析和分类不同形式的记忆。作者提出了一种使用卷积神经网络（CNNs）训练和评估的新型方法，以更好地理解大型语言模型中的逐字记忆现象。通过这一方法，研究者发现现有的分类方法效果不佳，不能准确地识别这些机制，因此需要提出一个新的分类方法来提高与注意力权重的契合度。研究结果揭示了少样本的逐字记忆并非特定的注意力机制，并且大量可提取样本实际上是通过语言模型猜测生成的，应分开研究。此外，提出了一种定制化的可视化解释技术，以定位每种记忆形式相关的注意力权重区域。", "innovation": "开发了一种基于CNN的方法，用于训练和评估LLM中的逐字记忆现象，提出了一种新的分类法，该分类法能够最大化与注意力权重的匹配度，定义了三类不同于先前方法的分类标准：使用语言建模能力猜测的记忆样本、由于训练集中高重复性而回忆的记忆样本和非记忆样本。此外，还开发了一种可视化解释技术，用于定位不同形式记忆相关的注意力权重区域，以提供更深入的理解。", "conclusion": "研究表明，少样本的逐字记忆并不是一种独特或独立的注意力机制。大量的可提取样本实际上是通过语言建模能力猜测出来的，而非完全依靠记忆。提出了更具体的分类方法和定制化的可视化解释技术，有助于更好地理解大型语言模型中的逐字记忆现象。"}
{"llm_update_time": "20251116", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.15721", "html_url": "https://arxiv.org/abs/2508.15721", "title": "EcomMMMU: 利用视觉信息增强 robust 多模态电子商务模型的策略", "title_en": "EcomMMMU: Strategic Utilization of Visuals for Robust Multimodal E-commerce Models", "authors": "Xinyi Ling,Hanwen Du,Zhihui Zhu,Xia Ning", "background": "电子商务平台拥有丰富的多模态数据，其中包含描绘商品细节的各种图像。但现有的研究仍在探讨这些图像是否总是有助于提升对商品的理解，还是有时可能会引入冗余或降低性能。现有的数据集规模有限且设计上不够完善，限制了对这个问题系统性的研究。为了填补这一空白，该研究引入了一个名为EcomMMMU的新多模态多任务理解数据集，其中包括406,190个样本和8,989,510张图像，数据集设计了8项多图像视觉-语言任务，专门有一个用于评估多模态大型语言模型（MLLMs）使用视觉内容能力的VSS子集。研究分析表明，产品图片并不总是提高性能，有时甚至会降低它，表明MLLMs在利用丰富的视觉信息完成电子商务任务方面可能存在困难。", "innovation": "该研究提出了一种名为SUMEI的数据驱动方法，该方法在使用多幅图像完成下游任务之前，先预测每幅图像的视觉价值，从而有效利用多幅图像。彻底的实验表明SUMEI的有效性和鲁棒性，并提供数据和代码下载地址供研究者使用。", "conclusion": "研究表明，产品图片并不总是提升系统性能，有时甚至会降低它。研究还提出了一种名为SUMEI的数据驱动方法，该方法先评估每幅图片的视觉价值，然后用于完成下游任务，证明了该方法的有效性和鲁棒性。"}
{"llm_update_time": "20251116", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.01157", "html_url": "https://arxiv.org/abs/2510.01157", "title": "针对语音语言模型的后门攻击", "title_en": "Backdoor Attacks Against Speech Language Models", "authors": "Alexandrine Fortier,Thomas Thebaud,Jesús Villalba,Najim Dehak,Patrick Cardinal", "background": "大型语言模型（LLMs）及其多模态扩展变得越来越受欢迎。一个常见的多模态实现方法是将领域特定编码器与LLM级联，从而使结果模型继承所有组件的漏洞。本文提出了首个系统性研究对语音语言模型的后门攻击。研究在不同语音编码器和数据集上展示了后门攻击的有效性，覆盖了自动语音识别（ASR）、语音情感识别以及性别和年龄预测四个任务。攻击成功率从90.76%到99.41%不等。", "innovation": "本文首次系统性研究了针对语音语言模型的后门攻击，研究了对语音编码器的攻击并提出了基于微调的防御策略。具体来说，研究了四种不同编码器和三个数据集，四种任务：自动语音识别（ASR），语音情感识别，以及性别和年龄预测，并成功实现了高成功率的后门攻击。通过组件级分析，发现并定位了最脆弱的管道阶段。此外，提出了一种基于微调的防御方法，以缓解中毒预训练编码器带来的威胁。", "conclusion": "本文研究了语音语言模型的后门攻击，并通过组件级分析明确了最脆弱的环节。提出基于微调的防御策略，有效缓解了受攻击的影响。研究的结果强调了对多模态扩展中的安全挑战的理解和缓解的重要性。"}
{"llm_update_time": "20251116", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.01252", "html_url": "https://arxiv.org/abs/2510.01252", "title": "GPT与偏见：理解大型语言模型中学习表示的一种稀疏方法", "title_en": "GPT and Prejudice: A Sparse Approach to Understanding Learned Representations in Large Language Models", "authors": "Mariam Mahran,Katharina Simbeck", "background": "大型语言模型(L Large Language Models)在大量非结构化的语料库上进行训练，这使得人们难以明确了解模型在训练期间吸收的社会模式和偏见。当前的评估方法通常局限于输出或激活的测试，但较少将它们与预训练数据关联起来。本文介绍了一个结合GPT样式的模型与稀疏自编码器(Sparse Autoencoders, SAEs)的管道，用于追踪不同的主题在训练过程中的编码情况。", "innovation": "提出了一种使用GPT样式的模型与稀疏自编码器连接的管道，通过此管道可以追溯不同主题在训练过程中的编码方式，并利用社会和道德类别进行特征探查，将稀疏特征映射到人类可理解的概念，揭示了主题框架的稳定性，并展示了关联在深度上的扩展与交织。这种方法为审计大型语言模型中嵌入的文化假设提供了一种可扩展的框架。", "conclusion": "本文的研究表明，GPT与SAEs管道提供了一种可扩展的方法，用于审计大型语言模型中嵌入的文化假设，展示了社会和道德假设在模型表示中的作用，尤其是在文学作品中的体现。"}
{"llm_update_time": "20251116", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2509.19319", "html_url": "https://arxiv.org/abs/2509.19319", "title": "FHIR-AgentBench：用于实际互操作EHR问题回答的LLM代理基准", "title_en": "FHIR-AgentBench: Benchmarking LLM Agents for Realistic Interoperable EHR Question Answering", "authors": "Gyubok Lee,Elea Bach,Eric Yang,Tom Pollard,Alistair Johnson,Edward Choi,Yugang jia,Jong Ha Lee", "background": "最近向HL7 Fast Healthcare Interoperability Resources (FHIR)标准的转变为临床人工智能开辟了新领域，这要求大型语言模型（LLM）代理在复杂、基于资源的数据模型中导航，而非传统结构化的医疗数据。然而，现有的基准测试已经落后于这一转变，缺乏对近期LLM在互操作临床数据上的评估所需要的现实标准。因此，缺少一个可以实际评估LLM代理的重要基准。为此，作者提出了FHIR-AgentBench，一个基于2,931个真实临床问题，与HL7 FHIR标准对齐的评估基准。这些地面真值问题使得研究人员能够系统地评估逻辑代理框架，比较不同的数据检索策略、交互模式和推理策略的效果，并突出从错综复杂的FHIR资源中检索数据的实践挑战以及逻辑推理的难度，这是影响问题回答性能的关键因素。", "innovation": "该研究引入了一个名为FHIR-AgentBench的新基准测试工具，旨在填补现有基准测试工具在现实性和互操作性方面的不足。FHIR-AgentBench以HL7 FHIR标准为依据，集成了2,931个真实临床问题。研究通过该基准测试系统性地评估不同的数据检索策略（直接FHIR API调用与专业工具）、互动模式（单回合与多回合）和推理策略（自然语言与代码生成），对比实验结果揭示了从复杂FHIR资源中检索数据和推理上存在的挑战。这些发现对于进一步研究临床应用中的LLM代理模型具有重要价值。同时，作者公开发布了FHIR-AgentBench数据集和评估套件，以促进可重复研究和开发出可靠、强大的LLM代理模型。", "conclusion": "FHIR-AgentBench能够有效评估现有的LLM代理模型在互操作临床数据场景中的表现，揭示出从复杂FHIR资源检索数据和推理的关键实践挑战。研究公开的数据集和评估套件可以促进重复研究及提高LLM在临床应用中的可靠性和有效性。"}
{"llm_update_time": "20251116", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2511.05534", "html_url": "https://arxiv.org/abs/2511.05534", "title": "FlowMM：跨模态信息流引导的KV缓存合并以提高高效多模态上下文推理", "title_en": "FlowMM: Cross-Modal Information Flow Guided KV Cache Merging for Efficient Multimodal Context Inference", "authors": "Kunxi Li,Yufan Xiong,Zhonghua Jiang,Yiyun Zhou,Zhaode Wang,Chengfei Lv,Shengyu Zhang", "background": "传统的KV缓存淘汰策略依据注意力分数丢弃不那么关键的KV对，这往往会降低生成质量，造成上下文丢失或幻觉。最近的工作转向KV合并，基于相似性合并淘汰标记和保留标记，但在多模态场景中，模态标记之间的分布偏见和跨模态交互中的注意力偏见限制了其有效性。", "innovation": "FlowMM，一种跨模态信息流引导的多模态KV缓存合并框架。FlowMM利用跨模态信息流动态应用分层特定的合并策略，捕捉模态特有的模式同时保持上下文完整性。还引入了一种灵敏度自适应的标记匹配机制，联合评估标记相似性和任务关键敏感度，合并低风险标记，保护高敏感标记。", "conclusion": "在各种领先MLLMs的广泛实验中，FlowMM降低了KV缓存内存80%到95%，解码延迟1.3-1.8倍，同时保持了竞争力的任务性能。"}
{"llm_update_time": "20251116", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.03156", "html_url": "https://arxiv.org/abs/2510.03156", "title": "语言模型的神经相关性仅限于人类语言", "title_en": "Neural Correlates of Language Models Are Specific to Human Language", "authors": "Iñigo Parra", "background": "先前的研究发现，大型语言模型的隐藏状态与功能性磁共振成像（fMRI）大脑反应之间存在相关性，特别是在语言任务上。这些相关性被作为这些模型的大脑状态相似性的证据。但这些研究还存在一些可能的质疑点，比如维度灾难、相似性测量的不同以及对于非人类语言数据的不同表现等问题。因此，本研究旨在验证前人研究的结果是否可以长期保持稳定，以及探索这些相关性背后的新见解。", "innovation": "本研究通过（i）降维后依然发现旧结果，排除了维度灾难的可能性；（ii）使用新的相似性度量方法验证了先前的结果；（iii）证明了神经表征和模型表征之间的关联仅限于人类语言的训练模型；（iv）发现结果的产生依赖于模型中的位置编码。这些结果进一步确认并强化了前人研究的内容，并有助于探讨顶级大型语言模型的生物可行性和可解释性。", "conclusion": "本研究表明，大型语言模型和人类大脑之间的神经相关性不仅存在于模型训练中，而且在维度减少和不同相似性度量环境中仍然存在。更重要的是，这些相关性仅限于人类语言训练的模型，且这些结果依赖于位置编码的存在。这些发现支持并加强了之前的研究，并为大型语言模型的生物可行性和可解释性提供了新的视角。"}
{"llm_update_time": "20251116", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2511.05901", "html_url": "https://arxiv.org/abs/2511.05901", "title": "医学中的检索增强生成：技术实现、临床应用与伦理考量的范围审查", "title_en": "Retrieval-Augmented Generation in Medicine: A Scoping Review of Technical Implementations, Clinical Applications, and Ethical Considerations", "authors": "Rui Yang,Matthew Yu Heng Wong,Huitao Li,Xin Li,Wentao Zhu,Jingchi Liao,Kunyu Yu,Jonathan Chong Kai Liew,Weihao Xuan,Yingjian Chen,Yuhe Ke,Jasmine Chiat Ling Ong,Douglas Teodoro,Chuan Hong,Daniel Shi Wei Ting,Nan Liu", "background": "医学知识的快速发展和临床实践的复杂性给医学界带来了挑战。在这种背景下，尽管大语言模型（LLMs）已经展示了其价值，但其内在局限性依然存在。检索增强生成（RAG）技术展示了增强其临床应用潜力的可能性。本研究回顾了RAG在医学中的应用情况。", "innovation": "本研究集中在RAG技术在医学中的应用，特别关注其在数据获取、模型选择和评估标准上的应用情况。研究发现了RAG应用集中于问题回答、报告生成、文本总结和信息提取等方面，尤其是在数据获取和模型选择方面仍需改进，尤其是在私人数据的应用、多语言适应性和低资源环境支持上。", "conclusion": "总体而言，医学中的RAG技术仍处于初期阶段，需要通过临床验证的进展、跨语言适应以及低资源环境的支持，来确保其更具可信性和负责任的全球使用。"}
{"llm_update_time": "20251116", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.03553", "html_url": "https://arxiv.org/abs/2510.03553", "title": "CCD-Bench: 探测大型语言模型决策中的文化冲突", "title_en": "CCD-Bench: Probing Cultural Conflict in Large Language Model Decision-Making", "authors": "Hasibur Rahman,Hanan Salam", "background": "尽管大型语言模型（LLMs）在人际和社会决策中发挥着越来越大的作用，但它们在处理不同文化价值系统之间明确冲突时的能力尚未得到充分研究。现有基准主要针对文化知识（CulturalBench）、价值观预测（WorldValuesBench）或单一轴向偏见诊断（CDEval），但未能评估LLMs在面对多重文化价值观直接冲突时的决策过程。", "innovation": "本文提出了CCD-Bench基准，旨在评估LLMs在跨文化价值观冲突情况下的决策能力。该基准包含2,182个开放性情境，每个情境配十个基于GLOBE文化集群的匿名选项，通过分层拉丁方设计来减少顺序效应的影响。评估了17个非推理型LLMs，结果显示模型对其决策的偏好具有偏向性，特别是在不同的文化背景下，并且在给出的理由中，模型更多地结合了未来取向和绩效取向。", "conclusion": "CCD-Bench的测评超越了孤立的偏见检测，转向多元文化的决策制定，并突出了需要致力于与多元世界观实质性互动的对齐策略，以满足需要权力协商、基于权利的推理或性别敏感分析的情境需求。"}
{"llm_update_time": "20251116", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.12858", "html_url": "https://arxiv.org/abs/2510.12858", "title": "知识为中心的古兰经诵读评估需求的批判性回顾", "title_en": "A Critical Review of the Need for Knowledge-Centric Evaluation of Quranic Recitation", "authors": "Mohammed Hilal Al-Kharusi,Khizar Hayat,Khalil Bader Al Ruqeishi,Haroon Rashid Lone", "background": "古兰经诵读（Tajweed）作为一门受到精确发音、节奏和神学原则约束的学科，在当今数字时代面临显著的教育挑战。尽管现代技术提供了前所未有的学习机会，现有的自动化评估系统普遍存在接受度不高且教育效果不佳的问题。已有大量文献、数字平台和商业工具的研究，但当前针对自动语音识别（ASR）系统的适应性方法存在的主要问题是强调单词识别而不是质性声学评价，从而导致这些系统具有偏见数据集依赖、人口统计差异和无法提供改进反馈的局限性。", "innovation": "本文提出了一种转变现有方法的议程，倡导知识为中心的计算框架。通过利用古兰经文本的不变性和tajweed定义明确的规则，建议构建基于规则的声学模型，重点突出传统的发音原则和发音点（Makhraj），而不是依赖于从有缺陷或偏见数据中得出的统计模式。这是一项倡导从数据依赖方法转向基于知识的方法的重要转变，特别是在促进古兰经诵读评估方面。", "conclusion": "未来自动化的古兰经诵读评估在于结合语言学专业知识和高级音频处理的混合系统。这样的方法为开发可靠、公平且教育有效的工具铺平了道路，这些工具能够真正帮助全球的学习者。"}
{"llm_update_time": "20251116", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2511.08455", "html_url": "https://arxiv.org/abs/2511.08455", "title": "社交机器人遇见捷径：大规模语言模型如何帮助处理未知不变性OOD场景？", "title_en": "Bot Meets Shortcut: How Can LLMs Aid in Handling Unknown Invariance OOD Scenarios?", "authors": "Shiyan Zheng,Herun Wan,Minnan Luo,Junhang Huang", "background": "尽管现有的社交机器人检测器在基准测试中表现良好，但在多种现实场景中的鲁棒性仍然有限，原因在于不清晰的现实真值和多样的误导性线索。特别地，模型依赖于虚假相关而非因果任务相关信息的祈祷学习机制尚未得到充分研究。为了弥补这一不足，本文深入研究了基于文本特征的潜在捷径如何影响检测器的表现，并通过构建虚假关联以评估模型的稳健性。", "innovation": "本文设计了一系列捷径场景，通过构建用户标签与表面文本线索之间的虚假关联来评估模型的稳健性。结果表明，无关特征分布的改变显著降低了社交机器人检测器的性能。为了应对这一挑战，本文提出了一种基于大规模语言模型的缓解策略，利用反事实数据增强来处理数据和模型层面的问题：包括个体用户文本和整体数据集的分布层次，以及模型提取因果信息的能力。这组策略在捷径场景下的相对性能改进平均达到了56%。", "conclusion": "本文深入研究了社交机器人检测器在遇到捷径时的鲁棒性问题，并提出了基于大规模语言模型的缓解策略，以提升模型在未知不变性OOD场景下的性能。"}
{"llm_update_time": "20251116", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2511.07871", "html_url": "https://arxiv.org/abs/2511.07871", "title": "AlignSurvey：社交调查中人类偏好对齐的综合基准", "title_en": "AlignSurvey: A Comprehensive Benchmark for Human Preferences Alignment in Social Surveys", "authors": "Chenxi Lin,Weikang Yuan,Zhuoren Jiang,Biao Huang,Ruitao Zhang,Jianan Ge,Yueqian Xu,Jianxing Yu", "background": "理解人类的态度、偏好和行为对于学术研究和政策制定至关重要。然而，传统的调查方式面临着固定问题格式、高昂成本、适应性不足和跨文化等效性难以保证等挑战。近期的研究利用大型语言模型（LLMs）模拟调查回应，但大多数研究仅限于结构化问题，忽视了整个调查过程，并且存在由于训练数据偏见而导致少数群体代表性不足的风险。", "innovation": "本文介绍了AlignSurvey，这是首个系统地利用LLMs复制和评估整个调查流程的基准。它定义了四大任务，与关键调查阶段对齐：社会角色建模、半结构化访谈建模、态度立场建模和调查回应建模。AlignSurvey还提供了针对个体和团体的定制评估指标，重点是种群多样性。为此，构建了一个多层数据架构，包括社会基础语料库，这是一个跨国资源，包含了44000多条访谈对话和400000多条结构化调查记录；以及包含专家注释的AlignSurvey-Expert (ASE) 和两个国家代表性调查组成的全套整体流程调查数据集，用于跨文化评估。此外，还发布了通过两阶段微调开源LLMs获得的SurveyLM系列，并提供了针对特定领域的对比模型。所有数据集、模型和工具均可公开获取，以支持透明和负责任的研究。", "conclusion": "本文通过引入AlignSurvey基准，填补了利用LLMs模拟调查响应过程的空白，提供了一套评估LLMs和多层数据架构的方法，旨在增强调查响应的多样性和公平性，支持透明和负责任的研究。"}
{"llm_update_time": "20251116", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2511.09109", "html_url": "https://arxiv.org/abs/2511.09109", "title": "向前思考和向后思考：基于多目标强化学习的检索增强推理", "title_en": "Thinking Forward and Backward: Multi-Objective Reinforcement Learning for Retrieval-Augmented Reasoning", "authors": "Wenda Wei,Yu-An Liu,Ruqing Zhang,Jiafeng Guo,Lixin Su,Shuaiqiang Wang,Dawei Yin,Maarten de Rijke,Xueqi Cheng", "background": "检索增强生成（RAG）在减少大语言模型幻觉方面取得了成功，但在复杂、多步骤推理场景中的效果有限。现有的方法主要依赖于基于结果的监督，无法为中间步骤提供明确指导，导致奖励作弊和响应质量下降。", "innovation": "提出了Bi-RAR（双向推理增强框架），这是一种新的双向推理增强框架，能够联合评估每个中间步骤的正向和反向信息。引入了基于柯爾莫果洛夫复杂性的双向信息距离，通过语言模型生成概率进行近似计算，衡量当前推理与答案的距离和问题的覆盖率。采用基于多目标强化学习框架和层次奖励结构进行推理优化，特别强调早期轨迹对齐。", "conclusion": "在七个问答基准测试上的实验证明，Bi-RAR 在多步骤推理方面优于先前的方法，能够在训练和推理过程中与搜索引擎进行高效的交互和推理。"}
{"llm_update_time": "20251116", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2511.08525", "html_url": "https://arxiv.org/abs/2511.08525", "title": "在大型推理模型中调查CoT可监视性", "title_en": "Investigating CoT Monitorability in Large Reasoning Models", "authors": "Shu Yang,Junchao Wu,Xilin Gong,Xuansheng Wu,Derek Wong,Ninhao Liu,Di Wang", "background": "大型推理模型（LRMs）通过在生成最终答案前进行长期推理，已经展示了在复杂任务上的出色性能。这些详细的推理链创造了新的AI安全性机会，即通过推理链（CoT）来监控模型在决策时可能出现的潜在不当行为，如使用捷径或奉迎。然而，在构建更有效的监视机制时，基于CoT分析遇到了两个关键挑战：首先，模型通常不总是真诚地在生成的推理中反映其决策过程；其次，监视器本身可能会过于敏感或不够敏感，并可能被模型复杂的推理链条欺骗。因此，有必要系统地调查CoT可监视性的挑战及其潜力，以便更好地确保模型的决策过程透明可信且可靠。", "innovation": "本文首次系统地研究了CoT可监视性的挑战与潜力。作者通过验证真实性（verbalization）和监视可靠性（monitor reliability）两个主要视角，探讨了大型推理模型在数学、科学和伦理等各种领域的推理过程中，其CoT如何真实地表达决策驱动因素，并研究不同推理干预方法对监测效果的影响。提出了一个新的范式MoME，即大型语言模型通过其CoT监测其他模型的不当行为，并提供结构化的评判和支撑证据。", "conclusion": "研究通过实证证据和相关性分析，展示了CoT的真实性和监视可靠性的关联，并进一步探讨了不同CoT干预方法对监测效果的影响。最后提出了MoME范式，从而为通过CoT监控大型推理模型的不当行为提供了一种新的思路和方法。"}
{"llm_update_time": "20251116", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2410.20749", "html_url": "https://arxiv.org/abs/2410.20749", "title": "Matryoshka Pilot: 使用 LLM 控制黑盒 LLM", "title_en": "Matryoshka Pilot: Learning to Drive Black-Box LLMs with LLMs", "authors": "Changhao Li,Yuchen Zhuang,Rushi Qiang,Haotian Sun,Hanjun Dai,Chao Zhang,Bo Dai", "background": "尽管黑盒大规模语言模型（LLMs）具备出色的生成能力，但其固有的不透明性阻碍了在推理、规划和个人化等方面的进一步进步。现有工作通过领域特定的适应来提升LLM能力，但这需要额外训练可访问的模型参数，对于黑盒LLMs来说是不可行的。因此，需要一种能够引导黑盒LLM生成的轻量级白盒LLM控制器，以逐步分解复杂任务为一系列中间输出，从而克服这一挑战。", "innovation": "提出了Matryoshka Pilot（M-Pilot），这是一种轻量级的白盒LLM控制器，通过将黑盒LLM视为环境，并通过提示提供中间指导来引导黑盒LLM生成。M-Pilot在迭代交互中训练，以使黑盒LLM的输出适应用户的偏好，从而实现可控的多轮生成和在提供中间指导方面的自我优化。实证研究表明，这种方法在复杂、长远的任务中有效提升了黑盒LLM的能力。", "conclusion": "我们的方法在各种任务上证明了在复杂、长期任务中有效增强了黑盒LLM的能力。我们已将代码公开发布。"}
{"llm_update_time": "20251116", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2503.14615", "html_url": "https://arxiv.org/abs/2503.14615", "title": "硬性注意：左右之分", "title_en": "Unique Hard Attention: A Tale of Two Sides", "authors": "Selim Jerad,Anej Svete,Jiaoda Li,Ryan Cotterell", "background": "近年来，研究人员越来越关注变压器的表达能力，这有助于理解它们的优势和局限。多数研究集中在唯一硬性注意变压器上，其中注意机制选择最大化注意力分数的单一位置。如果多个位置达到最大分数，通常会选择最右侧或最左侧的那个位置。然而，这种看似简单的机制的重要性却未被充分认识到。", "innovation": "本研究发现，带有最左侧硬性注意的有限精度变压器不再等同于线性时序逻辑（LTL），而是等同于LTL的更弱片段。此外，带有最左侧硬性注意的模型等同于软性注意力模型，暗示它们可能比右侧注意力模型更好地逼近实际的变压器，从而细化了变压器表达能力的景观。", "conclusion": "本研究揭示了注意力方向性在变压器表达能力中的核心作用，强调了硬性注意机制的重要性，指出带最左侧硬性注意的模型可能具备更好的近似性。"}
{"llm_update_time": "20251116", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2501.18638", "html_url": "https://arxiv.org/abs/2501.18638", "title": "Graph of Attacks with Pruning: Optimizing Stealthy Jailbreak Prompt Generation for Enhanced LLM Content Moderation", "title_en": "Graph of Attacks with Pruning: Optimizing Stealthy Jailbreak Prompt Generation for Enhanced LLM Content Moderation", "authors": "Daniel Schwartz,Dmitriy Bespalov,Zhe Wang,Ninad Kulkarni,Yanjun Qi", "background": "随着大型语言模型（LLMs）的日益普及，确保其免受恶意使用的威胁变得至关重要。现有的基于树的方法在攻击LLMs时存在局限性，GAP（Graph of Attacks with Pruning）框架通过引入一种互联图结构解决了这些问题，该结构可以在攻击路径之间共享知识。", "innovation": "GAP框架通过使用图结构实现了知识在攻击路径之间的共享，改进了现有基于树的方法。实验结果表明，与现有的技术相比，GAP在攻击成功率上提高了20.8%，同时减少了62.7%的查询成本。GAP不仅在开放和封闭的LLMs中表现突出，而且产生了专门的变体，如GAP-Auto和GAP-VLM，专门用于自动化种子生成和多模态攻击。此外，GAP生成的提示在改进内容审核系统方面表现出色，准确性提高了183.6%，检测率提高了108.5%。", "conclusion": "GAP框架在攻击LLMs方面表现出色，并有效提高了内容审核系统的性能。该实现可以在该网址获取：[this https URL](this https URL)。"}
{"llm_update_time": "20251116", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2505.17519", "html_url": "https://arxiv.org/abs/2505.17519", "title": "链式诱惑：利用非约束合成叙述构建通用逃逸攻击框架", "title_en": "Chain-of-Lure: A Universal Jailbreak Attack Framework using Unconstrained Synthetic Narratives", "authors": "Wenhan Chang,Tianqing Zhu,Yu Zhao,Shuangyong Song,Ping Xiong,Wanlei Zhou", "background": "在生成式人工智能快速发展时期，与大型语言模型（LLMs）的交互带来了日益增加的滥用风险。早期的研究主要集中在基于模板的攻击和优化方法上，而忽视了LLMs具有强大的未经约束的欺骗能力去攻击其他LLMs的现实。本文通过受到Chain-of-Thought机制启发提出了一种新的逃逸技术，突破了依赖预定义模板的限制。", "innovation": "本文引入了一种名为'Chain-of-Thought'机制启发的新型逃逸方法，采用任务转移策略在对话中隐藏有害用户意图，并生成一系列诱饵问题链，无需使用预定义模板。此外，本文还引入了一个辅助LLM模型，通过随机叙事优化来增强攻击效果，同时保持原始意图的一致性，并提供了一个基于毒性评估的框架来检测有害内容及其与恶意意图的一致性。", "conclusion": "通过广泛的实验，本文的方法在多样化类型的LLMs下展示出了高攻击成功率和升高的毒性评分，揭示了在缺乏强大对齐约束的情况下，LLMs具有进行不受限制攻击的内在潜力。我们提出的策略为未来的对齐机制设计提供了数据驱动的见解，并提出了两种实际的防御策略以支持更安全的生成模型的发展。"}
{"llm_update_time": "20251116", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2509.03113", "html_url": "https://arxiv.org/abs/2509.03113", "title": "通过梯度自反减轻多模态幻觉", "title_en": "Mitigating Multimodal Hallucinations via Gradient-based Self-Reflection", "authors": "Shan Wang,Maying Shen,Nadine Chang,Chuong Nguyen,Hongdong Li,Jose M. Alvarez", "background": "多模态大语言模型在不同任务上表现出色，但仍然容易出现幻觉现象，即模型输出与视觉输入不一致的情况。这种问题可归因于两种主要偏见：文本-视觉偏见，即模型过度依赖提示和先前输出；共现偏见，即频繁配对的物体之间存在虚假相关性。", "innovation": "提出了一种基于梯度的影响感知约束解码方法（GACD），该方法能针对这两种偏见进行干预，而无需额外的辅助模型，无需微调现有的模型即可应用。该方法的核心在于偏见估计，通过一阶泰勒梯度来理解单个文本-视觉特征和文本单词对当前输出的贡献。基于此分析，GACD 通过两个方面减轻幻觉：一是抑制与输出物体相关的虚假视觉特征，二是重新平衡跨模态贡献，增强视觉特征相对于文本的权重。", "conclusion": "在多个基准测试中的实验表明，GACD 有效减少了幻觉现象并提高了多模态大语言模型输出的视觉定位能力。"}
{"llm_update_time": "20251116", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2509.09651", "html_url": "https://arxiv.org/abs/2509.09651", "title": "可靠解读无线电法规的检索增强生成", "title_en": "Retrieval-Augmented Generation for Reliable Interpretation of Radio Regulations", "authors": "Zakaria El Kassimi,Fares Fourati,Mohamed-Slim Alouini", "background": "研究领域为无线电法规，这是一个法律敏感且高风险的领域。论文提出了一种针对电信领域的检索增强生成（RAG）管道，并构建了首个基于权威资源的多选评价集，使用自动过滤和人工验证。通过定义一个特定领域的检索度量，表明检索器可以实现约97%的准确性。", "innovation": "提出了针对电信领域的RAG管道，并构建了首个基于权威资源的多选评价集，定义了特定领域的检索度量，显著提高了生成准确性，特别是对于GPT-4o，使用该管道相对改进了近12%的准确率。", "conclusion": "精心设计的检索增强提供了一个简单而有效的基线和特定领域的解决方案，用于规范性问题解答。研究结果表明，该方法能显著提升生成准确性，并提供了可靠解读无线电法规的技术手段。"}
{"llm_update_time": "20251116", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2507.20067", "html_url": "https://arxiv.org/abs/2507.20067", "title": "PITA: Preference-Guided Inference-Time Alignment for LLM Post-Training", "title_en": "PITA: Preference-Guided Inference-Time Alignment for LLM Post-Training", "authors": "Sarat Chandra Bobbili,Ujwal Dinesha,Dheeraj Narasimha,Srinivas Shakkottai", "background": "现有的后训练方法通过使用小型指导模型在推理时修改标记生成，来使大型语言模型（LLM）的输出与最终用户偏好对齐。这些方法通常通过KL-正则化原始LLM作为参考策略来优化奖励函数。然而，这种方法依赖于预先训练的奖励模型，需要对人类偏好反馈进行拟合，这可能是一个不稳定的过程。本文旨在克服这一限制，提出了一种新的框架PITA，该框架直接将偏好反馈整合到LLM的标记生成中，消除了对奖励模型的依赖，降低了计算成本并简化了优化过程。", "innovation": "本文引入了一种新颖的框架PITA，该框架能够直接将用户偏好反馈整合到LLM的推理过程中，通过学习一个小型的基于偏好的指导策略来修改标记概率，无需进一步微调LLM，从而降低了计算成本并彻底摆脱了对预先训练的奖励模型的依赖。PITA将问题表述为识别潜在的偏好分布，并通过随机搜索和基于偏好的指导模型的迭代优化来解决。这一框架在多个任务上进行了评估，如数学推理和情感分类，展示了其在使LLM输出与用户偏好对齐方面的有效性。", "conclusion": "PITA框架能够在不进行任何进一步的模型微调的情况下，通过直接整合用户偏好反馈来优化大型语言模型的输出与用户期望的一致性，其通过一个小型的基于偏好的指导策略，显著降低了计算成本，并且能够有效实现输出与用户偏好的对齐。"}
{"llm_update_time": "20251116", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2509.14289", "html_url": "https://arxiv.org/abs/2509.14289", "title": "从功能到性能：评估LLM架构在渗透测试中的关键功能属性", "title_en": "From Capabilities to Performance: Evaluating Key Functional Properties of LLM Architectures in Penetration Testing", "authors": "Lanxiao Huang,Daksh Dave,Tyler Cody,Peter Beling,Ming Jin", "background": "大型语言模型（LLMs）越来越多地用于自动化或增强渗透测试，但它们在攻击各个阶段的有效性和可靠性仍然不清楚。", "innovation": "本研究对多种LLM基渗透测试代理进行了全面评估，包括单一代理和模块化设计，测量了实际渗透测试场景中的实证性能和反复出现的失败模式。此外，通过有针对性的增强，隔离了五个核心功能能力的影响：全局上下文记忆（GCM）、代理间消息传递（IAM）、上下文条件调用（CCI）、自适应规划（AP）和实时监控（RTM）。这些干预措施分别支持：（i）上下文的一致性和保留，（ii）组件间的协调和状态管理，（iii）工具使用准确性及选择性执行，（iv）多步战略规划、错误检测和恢复，以及（v）实时动态响应。", "conclusion": "我们的结果显示，尽管一些架构先天表现出这些特性的部分子集，但有针对性的增强在模块化代理性能上显著提高，尤其是在复杂、多步和实时渗透测试任务上。"}
{"llm_update_time": "20251116", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.05615", "html_url": "https://arxiv.org/abs/2508.05615", "title": "通过区域一致性进行GUI地面工作的测试时强化学习", "title_en": "Test-Time Reinforcement Learning for GUI Grounding via Region Consistency", "authors": "Yong Du,Yuchen Yan,Fei Tang,Zhengxi Lu,Chang Zong,Weiming Lu,Shengpei Jiang,Yongliang Shen", "background": "GUI接地是指将自然语言指令映射到精确屏幕坐标的任务，这对于自主GUI代理是基本的。现有方法虽然通过大量的监督训练或带有标记奖励的强化学习实现了强性能，但仍然受限于像素级注释的成本和可用性。我们观察到，当模型为相同的GUI元素生成多个预测时，空间重叠模式揭示了隐含的信心信号，可以指导更准确的定位。利用这一洞察，我们提出了GUI-RC（区域一致性），这是一种测试时扩展方法，从多个采样预测构建空间投票网格以识别模型一致显示最高同意的共识区域。无需任何训练，GUI-RC在ScreenSpot基准上各种架构上提高了2-3%的准确性。进一步引入了GUI-RCPO（区域一致性策略优化），将这些一致性模式转化为测试时强化学习的奖励。通过计算每个预测与整体一致性的匹配度，GUI-RCPO使模型能够在推断过程中逐步细化其在未标记数据上的输出。广泛的实验表明该方法具有普遍性：仅使用1,272个未标记数据，GUI-RCPO在ScreenSpot基准上各种架构上实现了3-6%的准确性改进。这种方法揭示了测试时扩展和测试时强化学习在GUI接地中的潜在价值，为更高效的数据GUI代理提供了富有前景的道路。", "innovation": "提出GUI-RC（区域一致性），一种测试时扩展方法，通过构建来自多个采样预测的空间投票网格来识别模型一致显示最高同意的共识区域；进一步提出GUI-RCPO（区域一致性策略优化），将一致性模式转化为测试时强化学习的奖励，使模型能够逐步细化其在未标记数据上的输出。", "conclusion": "从理论上和实验上展示了测试时强化学习和测试时扩展方法在GUI接地中的应用潜力，进一步揭示了在未标记数据上通过区域一致性改进精度的可能性，为更高效的数据GUI代理提供了新的路径。"}
{"llm_update_time": "20251116", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2509.11816", "html_url": "https://arxiv.org/abs/2509.11816", "title": " Collapse of Irrelevant Representations (CIR) 确保LLM稳健且非破坏性卸载", "title_en": "Collapse of Irrelevant Representations (CIR) Ensures Robust and Non-Disruptive LLM Unlearning", "authors": "Filip Sondej,Yushi Yang", "background": "当前的卸载和安全培训方法不能有效地从语言模型中移除危险知识。主要原因在于，这些方法针对过于泛化的表示进行卸载，导致不必要的知识被一并移除，从而影响了模型的整体性能。本研究识别了这一根本原因，并提出了一种高度选择性的技术，能够在不破坏性能的前提下有效卸载特定事实的知识。", "innovation": "本文提出了一种名为‘无关表示坍缩（CIR，Collapse of Irrelevant Representations）’的方法。该方法首先对激活和模块输出梯度进行PCA分析，以识别包含共同表示的子空间，然后通过对这些子空间进行坍缩来计算卸载更新。这种方法专门针对特定事实的知识进行卸载，避免了卸载与之相关的整体知识，从而实现了稳健且非破坏性的卸载效果。通过在Llama-3.1-8B上卸载生物和网络危害知识，本方法实现了比最佳基线（Circuit Breakers）高30倍的后攻击准确度降低，同时对整体性能的干扰减少了30倍，整个过程用时不到3个GPU秒/个事实。", "conclusion": "通过在表示层面区分有害和良性能力，CIR 方法为稳健且非破坏性的卸载提供了可能。"}
{"llm_update_time": "20251116", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.26495", "html_url": "https://arxiv.org/abs/2510.26495", "title": "重新思考Text-to-SQL：面向现实数据库探索的动态多轮SQL交互", "title_en": "Rethinking Text-to-SQL: Dynamic Multi-turn SQL Interaction for Real-world Database Exploration", "authors": "Linzhuang Sun,Tianyu Guo,Hao Liang,Yuying Li,Qifeng Cai,Jingxuan Wei,Bihui Yu,Wentao Zhang,Bin Cui", "background": "尽管Text-to-SQL在静态、单轮任务中取得了强健的成果，但现有系统在实际的交互场景中表现不足，特别是在用户意图演化和查询需要多次迭代的动态场景中缺乏表现。因此，需要一种能评估模型在动态交互中表现的新基准DySQL-Bench。", "innovation": "该研究提出了DySQL-Bench，一种评估模型在动态用户交互中的性能的基准。DySQL-Bench通过自动化的两阶段流程构建，包括任务合成和验证。研究还提出了一个多轮评估框架，模拟了模拟用户、测试模型和可执行数据库之间的交互，并评估模型根据用户意图变化来调整推理和SQL生成的能力。", "conclusion": "DySQL-Bench涵盖了13个领域，共计1,072个任务。即使GPT-4o的表现也只能达到58.34%的整体准确率以及23.81%的Pass@5指标，强调了 Benchmark 的挑战性。所有代码和数据已公开发布。"}
{"llm_update_time": "20251116", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.01611", "html_url": "https://arxiv.org/abs/2510.01611", "title": "PsychCounsel-Bench：评估大型语言模型的心理学智能", "title_en": "PsychCounsel-Bench: Evaluating the Psychology Intelligence of Large Language Models", "authors": "Min Zeng", "background": "大型语言模型（LLMs）在多行业的应用中表现出色，主要得益于它们出色的生成能力。然而，它们在需要认知能力的应用中，例如心理辅导方面，潜力尚未得到充分发掘。本文探讨了关键问题：大规模语言模型是否能够有效地应用于心理辅导？为评估大规模语言模型是否能够承担心理咨询师的角色，第一步是测试它们是否符合成为心理咨询师所需的心理学知识要求，即通过美国全国咨询认证考试（NCE）。为此，本文提出了PsychCounsel-Bench基准，该基准基于咨询师考试，这是一种专业咨询师的执照测试，通过率约为70%。PsychCounsel-Bench包含约2,252个精心挑选的单选题，这些问题既考查了对心理学的深刻理解，又覆盖了该学科的各个分支。通过评估展示出，最先进的模型如GPT-4o、Llama3.3-70B和Gemma3-27B显著超过了通过阈值，而小型开源模型（如Qwen2.5-7B、Mistral-7B）仍然远低于通过阈值。结果表明，只有最前沿的大型语言模型目前能够达到咨询师考试的标准，这既展示了开发心理学定向的大型语言模型的潜力，也凸显了面临的挑战。", "innovation": "本文提出并开发了PsychCounsel-Bench基准，这是一个基于心理咨询师资格考试标准的全面评估测试。该基准使用了约2,252个精心挑选的单选题，评估模型在心理学领域的理解和应用能力。通过实验验证，只有最先进的模型如GPT-4o、Llama3.3-70B和Gemma3-27B才能通过该基准测试。", "conclusion": "尽管最先进的大型语言模型目前能够达到心理辅导考试的标准，但仍需进一步加强它们在心理学知识和应用方面的表现，尤其是对于更广泛的模型和应用领域。这项研究突显了在心理学定向的大型语言模型开发过程中面临的挑战，同时也展示了其潜力。"}
{"llm_update_time": "20251116", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.16781", "html_url": "https://arxiv.org/abs/2510.16781", "title": "小冰：基于语义特征自监督时空聚类的无训练视频理解", "title_en": "Xiaoice: Training-Free Video Understanding via Self-Supervised Spatio-Temporal Clustering of Semantic Features", "authors": "Shihao Ji,Zihui Song", "background": "大型视觉语言模型（VLMs）在静态图像上的零样本推理能力已经有了显著的成果，但这些能力尚未被完全转移到视频领域。传统的视频理解模型通常需要在标注数据集上进行大量的、任务特定的训练，这一过程既昂贵又在可扩展性上有限。", "innovation": "本文提出了一种无训练框架，通过结合预训练VLM的丰富语义先验与经典机器学习算法中的模式发现，将视频理解重新框定为自监督的空间-时间聚类问题。该方法首先使用预训练VLM的冻结视觉编码器将视频流转换为语义特征轨迹，然后运用内核时间分割（KTS）技术将连续的特征流分割成离散的、语义上一致的事件段。之后，通过对这些段落进行无监督的密度基聚类来识别视频中的反复出现的宏观场景和主题。最后，通过选择每个发现聚类的代表关键帧并利用VLM的生成能力进行文本描述，该框架自动生成视频内容的结构化、多模态总结。这种方法提供了一种有效的、可解释的、模型不变的途径来进行零样本、自动的视频内容结构化分析。", "conclusion": "该研究表明，通过结合预训练VLM和经典机器学习方法，可以在无需训练的情况下实现视频内容的自动、结构化理解。这种新的无训练框架提供了一种逐步处理视频数据的自监督方法，能够识别视频中的重要事件和场景变化，从而为未来的视频内容分析和理解提供了新的工具和方法。"}
{"llm_update_time": "20251116", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2511.08066", "html_url": "https://arxiv.org/abs/2511.08066", "title": "信息容量：通过文本压缩评估大型语言模型的效率", "title_en": "Information Capacity: Evaluating the Efficiency of Large Language Models via Text Compression", "authors": "Cheng Yuan,Jiawei Shao,Chi Zhang,Xuelong Li", "background": "近年来，大型语言模型（LLMs）及其应用迅速发展，这导致了对计算资源的巨大需求。测试时扩展的广泛采用加剧了模型能力与资源消耗之间的紧张关系，突显了推理效率的重要性。但是，一种能够准确反映Laccept不同尺寸和架构的模型效率的统一指标至今仍未出现。", "innovation": "本文通过引入信息容量这一基于文本压缩性能相对计算复杂性的模型效率度量指标，解决了这一问题。信息容量能够跨系列模型进行公平的效率比较，并能准确预测同一系列模型中的性能。该指标的一个独特之处在于它考虑了分词器效率的影响，这种影响虽然在模型评估中经常被忽略，但会影响到输入和输出的令牌数量变化。通过在5个异构数据集上评估49个模型，展示了分词器效率、预训练数据以及专家混合架构对信息容量的影响具有一致性结果。", "conclusion": "本文提出的信息容量是一个能够跨不同尺寸和架构的Laccept提供公平评估并能准确预测性能的新度量指标，且突出了分词器效率在模型评估中的重要性。"}
{"llm_update_time": "20251116", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.06557", "html_url": "https://arxiv.org/abs/2510.06557", "title": "马尔可夫型思考者：架构无关的推理线性扩展", "title_en": "The Markovian Thinker: Architecture-Agnostic Linear Scaling of Reasoning", "authors": "Milad Aghajohari,Kamran Chitsaz,Amirhossein Kazemnejad,Sarath Chandar,Alessandro Sordoni,Aaron Courville,Siva Reddy", "background": "强化学习（RL）最近已经成为训练产生长链推理（LongCoT）的LLMs的强大工具。然而，标准的RL‘思考环境’使得状态不可界定，并迫使基于注意力的策略在思考长度增加时付出平方级的计算量。研究者们重新审视了思考环境本身，提出了马尔可夫型思考者这一理念，该理念允许策略在保持对固定大小状态的有效条件限制的情况下推进思考，从而切割开思考长度和上下文大小之间的联系。这导致了线性计算成本和常量级别内存的直接结果。研究团队具体实例化了这种思路，构建了Delethink这种基于RL的环境，将推理结构化为固定大小的块，在每个块内，模型如常推理；在块边界上，环境重置上下文并用简短的延续信息重新初始化提示。由此，通过RL训练策略能够写出每个块末尾的足够文本状态，以便思考在重置后能无缝继续。", "innovation": "提出了一种新的依赖于常量状态的马尔可夫型思考者理念，通过将推理分割为固定大小的块，结合RL训练，使得推理长度可以线性扩展而无需平方级的计算量。具体实例为Delethink环境的构想，它在保持固定内存成本的同时，使得超大型模型（1.5B到120B参数）能生成超过24K tokens的长思考，而传统方法如LongCoT-RL在24K预算下只有16K tokens的思考长度。实验证明，Delethink在推理时核成本上相比长思考链的RL降低了3.8倍，表现出显著的时间效率提升。这些积极的样本使得区间外的RL训练也得以有效应用。", "conclusion": "重新设计思考环境是一种有强大杠杆效应的途径：它能够实现非常长的推理而不需要平方级的额外成本，并为高效、可扩展的推理LLMs铺平了道路。实验结果表明，通过Delethink这种环境，模型得以处理长度可达24K的长思考，这远远超过了传统手法所能达到的水平。并且通过增量扩展推理长度，Delethink在测试阶段继续改善，而长思考链的效果已趋于平台。"}
{"llm_update_time": "20251116", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2511.09057", "html_url": "https://arxiv.org/abs/2511.09057", "title": "PAN：一种支持广泛、交互和长时间世界模拟的世界模型", "title_en": "PAN: A World Model for General, Interactable, and Long-Horizon World Simulation", "authors": "PAN Team Institute of Foundation Models:Jiannan Xiang,Yi Gu,Zihan Liu,Zeyu Feng,Qiyue Gao,Yiyan Hu,Benhao Huang,Guangyi Liu,Yichi Yang,Kun Zhou,Davit Abrahamyan,Arif Ahmad,Ganesh Bannur,Junrong Chen,Kimi Chen,Mingkai Deng,Ruobing Han,Xinqi Huang,Haoqiang Kang,Zheqi Li,Enze Ma,Hector Ren,Yashowardhan Shinde,Rohan Shingre,Ramsundar Tanikella,Kaiming Tao,Dequan Yang,Xinle Yu,Cong Zeng,Binglin Zhou,Zhengzhong Liu,Zhiting Hu,Eric P. Xing", "background": "智能代理需要构建世界模型来预测和推理世界如何响应其行为，进而规划和策略化。现有的视频生成模型能生成逼真的视频序列，但缺乏因果控制、交互性和长期一致性，这些都是进行有目的推理所必需的。虽然现有的世界模型在物理、游戏或3D场景动态等领域取得了一定进展，但在广泛环境和交互形式下的迁移性仍然有限。", "innovation": "PAN 是一种能够通过历史和自然语言动作条件下的高质量视频模拟预测未来世界状态的通用、可交互和具有长期视角的世界模型。PAN 使用生成潜在预测 (GLP) 架构，这是一种结合了基于大型语言模型（LLM）的自回归潜在动力学主干和视频扩散解码器的框架。GLP 架构融合了基于大量文本知识的模拟和根据自然语言动作进行条件化的能力，以及重建详细且时序一致的视觉观察的能力，从而实现了潜在空间推理与现实世界动力学的统一。", "conclusion": "通过在广泛的视频-动作对数据上进行训练，PAN 支持广泛领域的、根据动作条件化的、具有长期一致性的模拟。广泛的实验表明，与现有的其他视频生成器和世界模型相比，PAN 在动作条件化的世界模拟、长期预测和模拟推理方面表现出色，迈出了通向下一代通用世界模型的重要一步，使其能够预测未来世界状态进行推理和行动。"}
{"llm_update_time": "20251116", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2511.09599", "html_url": "https://arxiv.org/abs/2511.09599", "title": "FedeCouple: 细粒度平衡全局泛化与局部适应回归中的联邦学习", "title_en": "FedeCouple: Fine-Grained Balancing of Global-Generalization and Local-Adaptability in Federated Learning", "authors": "Ming Yang,Dongrun Li,Xin Wang,Feng Li,Lisheng Fan,Chunxiao Wang,Xiaoming Wu,Peng Cheng", "background": "在具有异质客户端数据的隐私保护移动网络传输场景中，分拆特征提取器和分类器的个性化联邦学习方法显示出显著的优势，但现有方法往往侧重于局部训练中的特征空间一致性和分类个性化，而忽视了提取器的局部适应性和分类器的全局泛化，这种忽视导致了组件间协调不足和耦合薄弱，最终降低了整体模型性能。", "innovation": "提出了FedeCouple，一种在细粒度级别平衡全局泛化与局部适应回归的联邦学习方法。该方法结合学习全局和局部特征表示，并使用动态知识蒸馏来增强个性化的分类器泛化能力，引入锚点以精炼特征空间，确保其严格局部性和非传输性，从而保护隐私并减少通信开销。此外，对非凸目标问题进行了理论分析，证明了FedeCouple的收敛性。", "conclusion": "在五个图像分类数据集上的大规模实验表明，FedeCouple在有效性、稳定性和安全性方面均优于九种基线方法，特别是在有效性评估中，FedeCouple以4.3%的显著优势超过了最佳基线方法。"}
{"llm_update_time": "20251116", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2511.09611", "html_url": "https://arxiv.org/abs/2511.09611", "title": "MMaDA-Parallel：用于思考感知编辑和生成的多模态大型扩散语言模型", "title_en": "MMaDA-Parallel: Multimodal Large Diffusion Language Models for Thinking-Aware Editing and Generation", "authors": "Ye Tian,Ling Yang,Jiongfan Yang,Anran Wang,Yu Tian,Jiani Zheng,Haochen Wang,Zhiyang Teng,Zhuochen Wang,Yinjie Wang,Yunhai Tong,Mengdi Wang,Xiangtai Li", "background": "当前的思考感知生成旨在改善复杂任务的表现，但现有的顺序自回归方法由于错误传播可能会反噬性地降低表现。为系统地分析这一问题，作者提出了一个新的基准ParaBench，用于评估文本和图像输出模态。研究表明，性能下降与生成的推理和最终图之间缺乏对齐密切相关。", "innovation": "作者提出了一个新的平行多模态扩散框架MMaDA-Parallel，该框架在整个去噪过程中实现了文本和图像之间的持续双向交互以解决这一问题。MMaDA-Parallel通过监督微调和后续通过Parallel Reinforcement Learning (ParaRL)优化，应用沿轨迹的语义奖励来确保跨模态一致性。实验结果表明该模型显著改善了多模态对齐和语义一致性，并在ParaBench上实现了比现有最佳模型Bagel高出6.9%的Output Alignment改进，建立了更为稳健的思考感知图像合成范式。", "conclusion": "我们的模型显著改善了多模态对齐和语义一致性，超越了现有最佳模型，在ParaBench上获得了6.9%的Output Alignment改进，确立了一个更为稳健的思考感知图像合成范式。我们开源了代码：在<此链接>。"}
{"llm_update_time": "20251116", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2511.09675", "html_url": "https://arxiv.org/abs/2511.09675", "title": "PriVi: 向普适性的灵长类行为野外视频模型迈进", "title_en": "PriVi: Towards A General-Purpose Video Model For Primate Behavior In The Wild", "authors": "Felix B. Mueller,Jan F. Meier,Timo Lueddecke,Richard Vogg,Roger L. Freixanet,Valentin Hassler,Tiffany Bosshard,Elif Karakoc,William J. O'Hearn,Sofia M. Pereira,Sandro Sehner,Kaja Wierucka,Judith Burkart,Claudia Fichtel,Julia Fischer,Alexander Gail,Catherine Hobaiter,Julia Ostner,Liran Samuni,Oliver Schülke,Neda Shahidi,Erin G. Wessling,Alexander S. Ecker", "background": "非人灵长类是我们的近亲，研究它们的行为对认知、进化和保护研究至关重要。计算机视觉可以极大地帮助这项研究，但现有的方法往往依赖于以人为中心的预训练模型，并且主要集中在单一数据集上，限制了泛化能力。", "innovation": "本文通过从模型中心主义转变为数据中心主义的方法，引入了一个大规模的灵长类中心视频预训练数据集PriVi。该数据集包含424小时的经过精编的视频，整合了11个实验场景的174小时行为研究视频和250小时的多样化网络来源片段。本文对V-JEPA进行PriVi预训练，学习灵长类特有的表示，并用轻量级冻结分类器进行评估。在四个基准数据集（ChimpACT、BaboonLand、PanAf500、ChimpBehave）上，本文的方法一致地优于先前工作，包括完全微调的基线，并且在较少标注的情况下表现出较好的扩展性。这些结果表明，灵长类中心预训练显著提高了数据效率和泛化能力，使其成为低标注应用的有希望的方法。", "conclusion": "这些结果证明了灵长类中心预训练极大地提高了数据效率和泛化能力，很好地解决了现有方法在泛化能力上的不足，使得该模型在低标注场景下应用具有很大的潜力。"}
{"llm_update_time": "20251116", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2511.02833", "html_url": "https://arxiv.org/abs/2511.02833", "title": "在良好的GRACE中：知识蒸馏中原理性的教师选择", "title_en": "In Good GRACEs: Principled Teacher Selection for Knowledge Distillation", "authors": "Abhishek Panigrahi,Bingbin Liu,Sadhika Malladi,Sham Kakade,Surbhi Goel", "background": "知识蒸馏是一种通过使用大型“老师”语言模型生成的数据来训练较小的“学生”模型的有效策略，但选择特定学生任务组合的最佳老师需要昂贵的试错方法。已有研究表明，直接选择最佳性能的老师进行蒸馏可能存在局限性，尤其是在需要精确且高效的教师选择时。现有的方法主要依赖于验证器、教师概率输出或测试数据，无法满足所有情况的需求。因此，迫切需要一种新的、高效的方法来选择合适的教师，而不依赖这些数据。本文提出了一种轻量级评分标准GRACE，可以量化老师对学生模型后训练效果的有效性，而无需访问这些数据。GRACE从信息论的角度出发，与基于梯度算法的离散化稳定性联系起来，这能影响蒸馏学生模型的外推性能。GRACE在GSM8K和MATH数据集上的表现与蒸馏后的LLaMA和OLMo学生模型的性能高度相关，Spearman相关系数最高可达86%。GRACE还能为蒸馏提供重要的设计指导，包括生成教师时的最佳温度、给定大小限制下的最佳教师以及特定模型家族内的最佳教师选择。", "innovation": "本文提出了一个新的轻量级评分标准GRACE，它是第一个无需验证器、教师概率输出或测试数据就能量化教师对学生模型后训练有效性的方法。GRACE提供了一个新的方法，从信息论视角出发，连接到基于梯度算法的离散化稳定性，从而控制蒸馏学生模型的外推性能。研究人员证实GRACE能够有效地识别与给定学生高度兼容的教师，并为蒸馏提供细化指导，包括生成时的最佳温度、最佳教师选择以及特定模型家族内的最佳教师选择。这种创新性方法将极大地简化教师选择过程，并提高蒸馏精度。", "conclusion": "我们的研究结果表明，GRACE能够高效且有效地识别与给定学生相匹配的教师，并提供关于如何执行蒸馏的详细指导。通过使用GRACE选择的教师训练学生，可以显著提高性能，最高可提高7.4%。此外，GRACE还能够为蒸馏中的关键设计选择提供指导，包括最佳的温度、最佳的教师选择以及特定模型家族内的最佳教师选择。这些发现证明GRACE可以使知识蒸馏过程更加高效和精确。"}
{"llm_update_time": "20251116", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2511.09702", "html_url": "https://arxiv.org/abs/2511.09702", "title": "从声带图像中使用软序数回归分类声带创伤严重程度", "title_en": "Classifying Phonotrauma Severity from Vocal Fold Images with Soft Ordinal Regression", "authors": "Katie Matton,Purvaja Balaji,Hamzeh Ghasemzadeh,Jameson C. Cooper,Daryush D. Mehta,Jarrad H. Van Stan,Robert E. Hillman,Rosalind Picard,John Guttag,S. Mazdak Abulnaga", "background": "声带创伤是指由于发声时受到的力量而造成的声带组织损伤，从轻微到严重不等，治疗方案根据损伤程度而有所不同。目前，声带创伤严重程度的评估主要依赖于临床专家的经验判断，这种方法成本高且可靠性差异大。因此，研究自动分类声带创伤严重程度的方法对于大规模研究声带创伤、提高临床理解和患者护理具有重要意义和价值。", "innovation": "提出了一种新颖的使用软序数回归方法自动分类声带创伤严重程度的方法。该方法使用了一种广泛使用的序数回归框架，并对序数回归损失函数进行了创新修改，使其可以应用于反映注释员评级分布的软标签。该方法实现的预测性能接近临床专家，同时还能生成可靠的不确定性估计。", "conclusion": "通过提供一个自动化的声带创伤严重程度评估工具，本研究有助于实现大规模的声带创伤研究，最终促进声带创伤的临床理解和患者护理的改善。"}
{"llm_update_time": "20251116", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2511.09740", "html_url": "https://arxiv.org/abs/2511.09740", "title": "高级驾驶辅助系统中的污渍检测", "title_en": "Soiling detection for Advanced Driver Assistance Systems", "authors": "Filip Beránek,Václav Diviš,Ivan Gruber", "background": "在先进的驾驶辅助系统中，汽车摄像头的污染检测是一个关键部分，旨在使其能够更 robust 地适应外部条件如天气、灰尘等因素。", "innovation": "将污渍检测视为语义分割问题，并对流行的分割方法进行了全面比较，展示了它们在性能上优于行级分类方法。同时，对Woodscape数据集进行了深入分析，指出原始数据集存在数据泄漏和不精确的标注问题，并创建了新的数据子集，具有更少的数据量但提供足够的信息用于达到类似结果并节省时间。", "conclusion": "所有代码和数据集划分均在 https://www.example.com/ 获得。"}
{"llm_update_time": "20251116", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2511.09723", "html_url": "https://arxiv.org/abs/2511.09723", "title": "密度估计与人群计数", "title_en": "Density Estimation and Crowd Counting", "authors": "Balachandra Devarangadi Sunil,Rakshith Venkatesh,Shantanu Todmal", "background": "本文通过优化一种原本用于图像分析的拥挤度估计算法，使其适用于基于视频的场景。该算法结合了降噪概率模型、高斯核、回归分支和事件驱动的采样技术，以提高拥挤度估计的准确性。", "innovation": "1. 引入了利用扩散过程生成高质量人群密度图的降噪概率模型。\n2. 通过使用窄高斯核并生成多个密度图输出来提高准确性。\n3. 融入了回归分支以进行精确特征提取，并通过相似度分数合并这些图以生成稳健的结果。\n4. 利用 Farneback 光流算法引入了事件驱动的采样技术来选择性地捕获显示重要人群移动的帧，从而减少计算负载和存储需求。", "conclusion": "通过定性和定量评估，该模型在包含重叠图和平均绝对误差 (MAE) 的测试中，展示了其在稠密和稀疏情况下有效捕捉人群动态的能力。此外，通过选择性地捕获关键帧，采样方法的效率被验证，证明了其在减少帧计数的同时保持了关键人群事件的能力。因此，该研究为实时人群监控提供了一个可扩展且有效的框架，适用于公共安全、灾难响应和活动管理等应用场景。"}
{"llm_update_time": "20251116", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2511.09715", "html_url": "https://arxiv.org/abs/2511.09715", "title": "SliderEdit: 细粒度指令控制下的连续图像编辑", "title_en": "SliderEdit: Continuous Image Editing with Fine-Grained Instruction Control", "authors": "Arman Zarei,Samyadeep Basu,Mobina Pournemat,Sayan Nag,Ryan Rossi,Soheil Feizi", "background": "基于指令的图像编辑模型已经取得了显著的成绩，能够根据多指令提示生成复杂的图像编辑效果。然而，这些模型中的每一个指令在整个编辑过程中强度固定，限制了用户对各个编辑强度的精确和连续控制能力。", "innovation": "我们引入了 SliderEdit 框架，通过细粒度和可解释的指令控制实现连续的图像编辑。SliderEdit 将多个编辑指令拆解为单独的滑块，并对每个滑块进行全局训练，允许平滑调整其强度。我们的方法不仅在属性或概念上需要独立训练，而是学习一套泛化的低秩适应矩阵，适用于各种编辑、属性和组合指令，从而在各个编辑维度上实现连续的插值，同时保持空间局部性和全局语义一致性。", "conclusion": "我们对先进的图像编辑模型 FLUX-Kontext 和 Qwen-Image-Edit 应用 SliderEdit，并观察到在编辑可控性、视觉一致性以及用户可控性方面显著的改进。在我们所知的研究中，我们是首次探索并在指令驱动的图像编辑模型中提出连续、细粒度指令控制框架的方法。我们的研究成果为交互式、指令驱动的图像操作提供了连续和组合控制的基础。"}
{"llm_update_time": "20251116", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2511.09724", "html_url": "https://arxiv.org/abs/2511.09724", "title": "PALMS+: 基于深度基础模型模块化图像楼层计划定位", "title_en": "PALMS+: Modular Image-Based Floor Plan Localization Leveraging Depth Foundation Model", "authors": "Yunqian Cheng,Benjamin Princen,Roberto Manduchi", "background": "在缺乏GPS信号的室内环境中，位置定位对于紧急响应和辅助导航应用至关重要。现有的如PALMS等基于视觉的方法能够通过仅使用地板平面图和静态扫描进行基础设施自由的定位，但这些方法受到智能手机LiDAR的有效范围有限以及室内布局的模糊性限制。本文背景在于研究如何克服这些限制以提高室内定位系统的准确性和鲁棒性。", "innovation": "本文提出了PALMS+，这是一个模块化、基于图像的系统，通过使用基础单目深度估计模型（Depth Pro）重建与比例对齐的3D点云，并通过与平面图卷积进行几何布局匹配，解决了上述问题。PALMS+无需训练即可实现静止定位精度的提升，并在实际应用中展示了其在无相机跟踪和基础设施自由应用方面的鲁棒性和潜力。", "conclusion": "通过对Structured3D和自定义校园数据集（包含八个校园建筑中的80个观测）的评估，PALMS+在静止定位精度上优于PALMS和F3Loc。结合粒子滤波器进行序列定位时，PALMS+在33个实际轨迹中的定位误差也低于其他方法，证明了其在相机自由追踪和基础设施自由应用中的实用性和可行性。"}
{"llm_update_time": "20251116", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2511.09771", "html_url": "https://arxiv.org/abs/2511.09771", "title": "STORM: 从单个3D模型进行分割、跟踪和对象重新定位", "title_en": "STORM: Segment, Track, and Object Re-Localization from a Single 3D Model", "authors": "Yu Deng,Teng Cao,Hikaru Shindo,Jiahong Xue,Quentin Delfosse,Kristian Kersting", "background": "6D姿态估计和跟踪对于物理人工智能系统，如机器人来说是基本能力。现有方法通常依赖于第一帧中目标的手动标注分割掩码，这既耗时又在遇到遮挡或快速运动时会导致性能下降。", "innovation": "提出了STORM (Segment, Track, and Object Re-localization from a single 3D Model)，一种无需手动注释的开源实时6D姿态估计系统。STORM利用一种新颖的三阶段管道，结合了视觉语言理解与自我监督特征匹配：上下文对象描述引导定位，自我交叉注意力机制识别候选区域，并且分割模型生成精确的掩码以实现准确的姿态估计。另一个关键创新是自动重新注册机制，通过特征相似度监控来检测跟踪失败，并且从严重的遮挡或快速运动中恢复。", "conclusion": "STORM在具有多对象遮挡、高速运动和不同光照条件的挑战性工业数据集上实现了最先进的精度，同时以实时速度运行。这款无需标记的方法大大减少了部署开销，为现代应用如灵活制造和智能质量控制提供了实践解决方案。"}
{"llm_update_time": "20251116", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2511.09749", "html_url": "https://arxiv.org/abs/2511.09749", "title": "基于梯度引导生成模型隐空间探索的可控虹膜图像增强方法", "title_en": "Gradient-Guided Exploration of Generative Model's Latent Space for Controlled Iris Image Augmentations", "authors": "Mahsa Mitcheff,Siamul Karim Khan,Adam Czajka", "background": "可靠的眼虹膜识别和欺骗攻击检测方法需要包含多种真实变化的虹膜特征多样数据集。由于虹膜图像的丰富纹理范围广泛，控制特定属性的同个体虹膜图像的合成仍然是一个挑战。因此，开发能够捕捉虹膜特征多样化并呈现广泛异常的虹膜图像数据集成为了必要。", "innovation": "本文提出了一种新的虹膜图像增强策略，通过生成模型的隐空间漫步，利用特定几何、纹理或质量相关的虹膜图像特征（如清晰度、瞳孔大小、虹膜大小或瞳孔到虹膜的比例）的梯度来引导隐空间的探索。这种方法能够保留被操纵图像所代表的身份，并且可以轻松扩展以操纵任何可以定义差异性损失项的属性。此外，该方法可以使用预训练的生成对抗网络模型生成的随机图像或真实世界的虹膜图像，并利用生成对抗网络逆转投影将任意给定的虹膜图像映射到隐空间以获得其相应的隐码。", "conclusion": "本文提出的方法提供了一种控制虹膜图像增强的技术，通过隐空间探索与特定特征梯度的引导，这种方法可以使虹膜图像增强具有更好的可控性与多样性，同时保留了虹膜图像的身份信息，并且具有广泛的适用性。"}
{"llm_update_time": "20251116", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2511.09735", "html_url": "https://arxiv.org/abs/2511.09735", "title": "使用动态占用建模的社交LSTM模型实现现实行人轨迹预测", "title_en": "Social LSTM with Dynamic Occupancy Modeling for Realistic Pedestrian Trajectory Prediction", "authors": "Ahmed Alia,Mohcine Chraibi,Armin Seyfried", "background": "在动态且拥挤的环境中，真实的人行轨迹预测仍然是一个具有挑战性的任务，这主要是由于人类运动的复杂性以及个人间的相互影响。传统的深度学习模型通过隐式学习二维轨迹数据中的模式已经取得了不错的成果，但大多数方法将行人视为点实体，忽视了每个人所占据的物理空间。针对这些问题，本文从2022年罗讷河灯光节收集的真实行人轨迹数据生成了五个数据集，解决了密度变化带来的问题，证明了所提出模型在每个数据集中的碰撞率降低以及位移预测精度提高，并且相比于基准模型，在不同密度条件下均表现出更优的性能。本文的数据集更具代表性和多样性，能够提高模型在实际应用中的鲁棒性，这有助于实现更精确的行人轨迹预测。", "innovation": "本文提出了一种结合了新型动态占用空间损失函数的深度学习模型，以增强社交LSTM。该损失函数通过结合平均位移误差和对场景密度和个体空间占用敏感的碰撞惩罚，指导社交LSTM学习避免真实的碰撞，同时在不同密度条件下（从低到高）减少位移误差，且在同质和异质密度设置中都展现出优越性。此外，通过有效训练和评估，本文在五个真实数据集上进行了实验，并通过比较多种最先进的深度学习模型，表明了该模型具有更好的性能和更高的预测精度。", "conclusion": "实验证明，本文提出的方法不仅减少了碰撞率，还在每个数据集上提高了位移预测的准确性。平均而言，该模型在所有数据集上的碰撞率降低了约31%，平均位移误差和最终位移误差分别降低了5%和6%。此外，在大部分测试集上，本文提出的模型都优于几种最先进的深度学习模型。"}
{"llm_update_time": "20251116", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2511.09791", "html_url": "https://arxiv.org/abs/2511.09791", "title": "PANDA - 具有数据分布和补丁意识增强的长尾无例元连续学习方法", "title_en": "PANDA - Patch And Distribution-Aware Augmentation for Long-Tailed Exemplar-Free Continual Learning", "authors": "Siddeshwar Raghavan,Jiangpeng He,Fengqing Zhu", "background": "Exemplar-Free Continual Learning (EFCL)限制了先前任务数据的存储，并且容易遭受灾难性遗忘。现有方法在EFCL中使用预训练模型(PTMs)，但往往忽略了现实世界数据分布中存在的固有不平衡。发现这些数据流通常在不同层面上存在不平衡，包括数据集层面的分布与个别任务中的极端或反向偏斜，造成了任务内和任务间的学习和泛化障碍。因此，需要一种能够应对这些挑战的方法来改进EFCL的效果，特别是在应用预训练模型的方法中。", "innovation": "PANDA（具有数据分布和补丁意识的增强）是一种框架，它可以无缝地与现有的基于预训练模型的EFCL方法集成，解决现实世界数据流中存在的固有不平衡和双重不平衡问题。通过使用CLIP编码器识别典型区域并将它们移植到每个任务中的频繁类样例，PANDA放大了低频类的变化。此外，PANDA采用了一个自适应均衡策略，利用先前任务的分布平滑任务间不平衡，减少了跨任务样本集的总体差距，并在冻结预训练模型的情况下实现了更公平的学习。", "conclusion": "广泛的实验和消融研究表明，PANDA能够与现有基于预训练模型的连续学习方法有效结合，从而提高准确性并减少灾难性遗忘。"}
{"llm_update_time": "20251116", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2511.09818", "html_url": "https://arxiv.org/abs/2511.09818", "title": "Lumos3D：单一前向框架在低光照三维场景重建中的应用", "title_en": "Lumos3D: A Single-Forward Framework for Low-Light 3D Scene Restoration", "authors": "Hanzhou Liu,Peng Jiang,Jia Huang,Mi Lu", "background": "在低光照条件下恢复三维场景依然是一个基础但具挑战性的问题。现有的大多数方法依赖于预先计算的相机姿态和场景特定的优化，这极大地限制了它们在动态真实环境中的可扩展性。", "innovation": "我们介绍了一种名为Lumos3D的普遍适用且无需姿态的低光三维场景恢复框架。该框架在单一数据集上训练后，在纯粹前向方式下进行推理，直接从未定位的低光照多视角图像中恢复光照和结构，无需对每个场景进行特定训练或优化。", "conclusion": "Lumos3D在实际数据集上的实验表明，它能够实现高保真的低光照三维场景恢复，具有准确的几何形状和较强的人文环境适应性。此外，框架自然地扩展适用于过度曝光校正，展示了其在多种照明恢复任务中的多样性和灵活性。"}
{"llm_update_time": "20251116", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2511.09742", "html_url": "https://arxiv.org/abs/2511.09742", "title": "医疗基础模型的特征质量和适应性：放射分类和分割的比较评价", "title_en": "Feature Quality and Adaptability of Medical Foundation Models: A Comparative Evaluation for Radiographic Classification and Segmentation", "authors": "Frank Li,Theo Dapamede,Mohammadreza Chavoshi,Young Seok Jeon,Bardia Khosravi,Abdulhameed Dere,Beatrice Brown-Mulry,Rohan Satya Isaac,Aawez Mansuri,Chiratidzo Sanyika,Janice Newsome,Saptarshi Purkayastha,Imon Banerjee,Hari Trivedi,Judy Gichoya", "background": "医疗基础模型（FMs）有望在医疗成像中实现通用性，但这些模型的效果因任务而异。目前尚不清楚预训练领域（医疗 vs. 通用）、范式（例如，文本引导）和架构如何影响嵌入质量，这妨碍了在特定放射学任务中选择最佳编解码器的选择过程。为此，本文评估了八种医疗和通用领域FMs的视觉编码器在胸部X射线分析中的表现，以对比分类（气胸、心脏增大）和分割（气胸、心缘）任务的线性探针和微调基准。", "innovation": "本文创新性地评估了多种医疗和通用领域基础模型（FMs）的视觉编码器在胸部X射线分析中的表现，使用线性探针和微调基准测试分类和分割任务，揭示了领域特定预训练的优势，并发现不同的FMs在不同类型的任务中表现不同。具体而言，使用仅图像（RAD-DINO）和监督标签（Ark+）的FMs表现突出，并且监督学习方法在分割任务中仍具有竞争力，这表明预训练特征并不适用于所有复杂定位任务。", "conclusion": "研究表明，虽然医疗预训练有益，但架构选择（如多尺度）至关重要，而且预训练特征并非适用于所有任务，特别是对于复杂的定位任务，监督模型仍然是一个强大而有效的替代方案。"}
{"llm_update_time": "20251116", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2511.09809", "html_url": "https://arxiv.org/abs/2511.09809", "title": "在视觉语言模型中用于零样本泛化的测试时频谱感知潜在方向控制", "title_en": "Test-Time Spectrum-Aware Latent Steering for Zero-Shot Generalization in Vision-Language Models", "authors": "Konstantinos M. Dafnis,Dimitris N. Metaxas", "background": "视觉语言模型（VLMs）在零样本推理方面表现出色，但在测试时面对领域转移时会性能下降。为了解决这一问题，最近出现了在单一未标记图像上适应VLMs的 episodic 测试时适应策略。然而，现有的适应策略，如测试时指令调优，通常需要对大型编码器权重进行反向传播或修改核心模型组件。因此，本文提出了一种轻量级的适应框架，Spectrum-Aware Test-Time Steering (STS)，该框架通过在少量样本移位参数的适应过程中最小化潜在表示的熵来定义主语义方向，从而在测试时完全在潜在空间中运作，无需对冻结的编码器进行反向传播或修改。", "innovation": "提出了 Spectrum-Aware Test-Time Steering (STS) 框架，这是一种轻量级的适应方法，通过在少量样本移位参数的适应过程中最小化潜在表示的熵来定义主语义方向，从而在测试时完全在潜在空间中运作，无需对冻结的编码器进行反向传播或修改。STS 在标准评估协议下进行全面实验，结果表明它在大多数情况下超过了或与最先进的测试时适应方法相当，同时仅引入了少量额外参数，且相比传统测试时指令调优具有高达 8 倍的推理速度和 12 倍的小内存占用。代码可在以下链接访问：this https URL", "conclusion": "该工作通过引入 Spectrum-Aware Test-Time Steering (STS) 框架来解决视觉语言模型在测试时面对领域转移时性能下降的问题，并展示了其在标准评估协议下的优越性能。"}
{"llm_update_time": "20251116", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2511.09820", "html_url": "https://arxiv.org/abs/2511.09820", "title": "从街道到轨道：基于位置语义和LLM指导的无需训练的跨视图检索", "title_en": "From Street to Orbit: Training-Free Cross-View Retrieval via Location Semantics and LLM Guidance", "authors": "Jeongho Min,Dongyoung Kim,Jaehyup Lee", "background": "跨视图图像检索，尤其是街道到卫星图像的匹配，对于自动驾驶导航、城市规划和GPS受限环境下的定位非常重要。然而，现有的方法需要在精心制作的数据集上进行监督训练，并依赖全景或无人机图像，这限制了其现实世界的部署能力。", "innovation": "本文提出了一种简单而有效的无需训练的跨视图图像检索框架，利用预训练的视觉编码器和大型语言模型（LLM）。通过基于网络的图像搜索和LLM的位置推理提取地理线索，使用地理编码API生成卫星查询，并使用预训练的视觉编码器（如DINOv2）检索匹配的图像块，采用PCA基于的白化特征精细处理。该方法在零样本设置下优于先前基于学习的方法，无需地面真实监督或微调，并且能够自动构建语义对齐的街道到卫星图像数据集，提供了一种可扩展且成本效率高的手动标注替代方案。", "conclusion": "我们的方法和管道展示了无需训练的跨视图图像检索的能力，并能够自动构建语义对齐的数据集，同时在零样本设置下优于现有的学习方法。所有源代码将在指定的URL网址上公开。"}
{"llm_update_time": "20251116", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2511.09834", "html_url": "https://arxiv.org/abs/2511.09834", "title": "CertMask: Certifiable Defense Against Adversarial Patches via Theoretically Optimal Mask Coverage", "title_en": "CertMask: Certifiable Defense Against Adversarial Patches via Theoretically Optimal Mask Coverage", "authors": "Xuntao Lyu,Ching-Chi Lin,Abdullah Al Arafat,Georg von der Brüggen,Jian-Jia Chen,Zhishan Guo", "background": " adversarial patch attacks, which inject localized perturbations into images to mislead deep vision models, pose serious risks in real-world applications. Existing defenses like PatchCleanser require multiple masking rounds and significant computational resources.", "innovation": "CertMask 提出了一种名为 CertMask 的可验证鲁棒防御方法，通过一个数学上严谨的覆盖策略计算掩码集，确保每个可能的贴图位置至少被覆盖 k 次，从而仅需要一轮掩码操作且时间复杂度为 O(n)，提高了效率和鲁棒性。相比 PatchCleanser，CertMask 在 ImageNet、ImageNette 和 CIFAR-10 上提高了高达 13.4% 的认证鲁棒准确性，同时保持了接近原始模型的准确率。", "conclusion": "实验表明，CertMask 在提高认证鲁棒准确性方面表现出色，同时保持了与原始模型相似的准确率，且具有更强的计算效率。与现有的方法相比，CertMask 显示出显著的优势，为对抗贴图攻击提供了一种更为高效和鲁棒的防御手段。"}
{"llm_update_time": "20251116", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2511.09827", "html_url": "https://arxiv.org/abs/2511.09827", "title": "AHA！使用Gaussian Splatting在多样场景中动画化人类 avatar", "title_en": "AHA! Animating Human Avatars in Diverse Scenes with Gaussian Splatting", "authors": "Aymen Mir,Jian Wang,Riza Alp Guler,Chuan Guo,Gerard Pons-Moll,Bing Zhou", "background": "近年来，3D高斯团集（3DGS）神经场景表示取得了前所未有的实时、接近真实的视角合成结果，但在人类场景动画和交互方面的应用却相对较少。现有的动画管道通常使用网格或点云作为底层3D表示，而该研究提出了一种全新的框架，将3DGS用于三维人类动画，实现了几何一致的多视角渲染，且能够独立解决运动合成和渲染问题，无需配对的人类-场景数据，从而大大简化了实现过程。", "innovation": "引入了3DGS作为全新的3D表示方法用于人类动画，提出了Gaussian-aligned运动模块，该模块不依赖于具体的场景几何，而是通过不透明性提示和投影的高斯结构引导人类的位置和姿态对齐，另外还提出了一种人类-场景高斯细化优化方法，用于确保人类与场景之间的自然交互和导航。此方法不仅适用于扫描数据，还适用于稀疏和密集多视角人类捕捉的数据。通过与Scannet++和SuperSplat库的场景相比，展示了其优越性。尤其是可以应用于编辑单目RGB视频，生成新的具有动画效果的人类的多视角渲染，展示了3DGS在单目视频基于的人类动画中的独特优势。", "conclusion": "研究表明，3DGS对于单目视频中的人类动画具有独特优势，可实现几何一致的多视角渲染，尤其在处理单目RGB视频的编辑素材时，效果显著。未来工作将涉及增强模型的鲁棒性和适用性，以应对更复杂和多样化的场景。"}
{"llm_update_time": "20251116", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2511.09866", "html_url": "https://arxiv.org/abs/2511.09866", "title": "IPCD: Intrinsic Point-Cloud Decomposition", "title_en": "IPCD: Intrinsic Point-Cloud Decomposition", "authors": "Shogo Sato,Takuhiro Kaneko,Shoichiro Takeda,Tomoyasu Shimada,Kazuhiko Murasaki,Taiga Yoshida,Ryuichi Tanida,Akisato Kimura", "background": "点云在增强现实(AR)、机器人等领域被广泛应用，实现光照调整和纹理编辑对于现实可视化至关重要。然而，在点云上进行这些任务存在两个关键技术挑战：（1）点云的非网格结构使基于图像的传统分解模型无效；（2）用于其他任务的点云模型未考虑全局光方向，导致阴影不准确。", "innovation": "提出了一种名为“内在点云分解”（Intrinsic Point-Cloud Decomposition, IPCD）的方法，用于直接将着色点云分解为反射率和阴影。为解决点云非网格结构的问题，提出了IPCD-Net模型，用于非网格数据处理。通过基于投影的亮度分布（Projection-based Luminance Distribution, PLD）来捕捉全局光照，使用多视角投影进行层次特征优化。创建了一个合成的室外场景数据集进行综合评估。", "conclusion": "实验结果表明，IPCD-Net能够减少反射率中的投射阴影并增强阴影中颜色的准确性。此外，展示了其在不同光照条件下的纹理编辑、重新光照和点云注册应用效果。最后，验证了IPCD-Net在真实世界应用中的有效性。"}
{"llm_update_time": "20251116", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2511.09843", "html_url": "https://arxiv.org/abs/2511.09843", "title": "CORONA-Fields: 利用基础模型对太阳风现象进行分类", "title_en": "CORONA-Fields: Leveraging Foundation Models for Classification of Solar Wind Phenomena", "authors": "Daniela Martin,Jinsu Hong,Connor O'Brien,Valmir P Moraes Filho,Jasmine R. Kobayashi,Evangelia Samara,Joseph Gallego", "background": "地球周围的空间天气由太阳活动驱动，对轨道卫星以及地面关键技术基础设施构成了日益增长的威胁。太阳风和日冕物质抛射等主要空间天气因素因其密度、速度、温度和磁场的不同而变化，使得自动分类这些结构具有挑战性。当前的研究旨在利用一个原始用于太阳物理学基础模型来生成适用于太阳风结构分析的嵌入。通过结合太空气象站的位置信息与太阳磁场连接性，并采用傅里叶特征进行编码，构建了一个基于神经场的深度学习模型。这种全深度学习架构能够弥合遥感观测与原位观测之间的差距，研究中利用帕克太阳探测器的测量结果作为标签，形成一个下游分类任务，将等离子体特征映射到太阳风结构上。尽管整体分类性能较低，但研究表明利用基础模型嵌入进行现场太阳风任务的可行性，并为未来更可靠的空间天气预测奠定了基础。研究代码和配置文件已公开，支持可重现性研究。", "innovation": "1. 将原本用于太阳物理学的基础模型应用于太阳风结构分析，研发了嵌入式表示方法。\n2. 结合太空气象站的位置信息与太阳磁场连接性，通过傅里叶特征进行编码，构建神经场模型。\n3. 构建了全深度学习架构，实现了遥感观测与原位观测的连接。\n4. 利用帕克太阳探测器的数据作为标签，形成等离子体特性到太阳风结构的映射的下游分类任务研究背景。", "conclusion": "尽管整体分类性能由于标注粗糙、类别不平衡以及预训练模型的有限转移性而较低，但研究表明利用基础模型嵌入进行现场太阳风任务的可行性。该研究为未来更可靠的空间天气预测打下了基础，同时也证明了相关代码和配置文件的公开性，支持了研究的可重现性。"}
{"llm_update_time": "20251116", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2511.09870", "html_url": "https://arxiv.org/abs/2511.09870", "title": "SAM-DAQ: Segment Anything Model with Depth-guided Adaptive Queries for RGB-D Video Salient Object Detection", "title_en": "SAM-DAQ: Segment Anything Model with Depth-guided Adaptive Queries for RGB-D Video Salient Object Detection", "authors": "Jia Lin,Xiaofei Zhou,Jiyuan Liu,Runmin Cong,Guodao Zhang,Zhi Liu,Jiyong Zhang", "background": "最近，SAM（Segment Anything Model）引起了广泛关注，并且经常被视为一种用于泛化分割的视觉基础模型。一些研究者尝试直接将基础模型应用于RGB-D视频显著对象检测（RGB-D VSOD）任务中，但遇到了三个挑战：依赖手动提示、顺序适配器高内存消耗和内存注意力计算负担。因此，研究者们提出了一个新的方法，即SAM-DAQ（Segment Anything Model with Depth-guided Adaptive Queries），该方法通过统一深度和时间线索来适配SAM，解决上述问题。", "innovation": "SAM-DAQ方法创新性地使用了并行适配器多模态图像编码器（PAMIE），其中包含深度引导的并行适配器（DPAs）以跳跃连接方式集成。在无需提示的情况下微调不动的SAM编码器，DPA利用深度线索来促进多模态特征的融合。同时，部署了一个查询驱动的时间记忆模块（QTM），该模块将内存银行和提示嵌入统一为可学习的流水线。通过同时利用帧级查询和视频级查询，QTM模块不仅可以选择性地提取时间一致性特征，还可以逐步更新查询的时间表示。", "conclusion": "在三个RGB-D VSOD数据集上进行了广泛的实验，结果表明所提出的SAM-DAQ方法在所有评估指标中都优于现有的先进方法。"}
{"llm_update_time": "20251116", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2511.09868", "html_url": "https://arxiv.org/abs/2511.09868", "title": "Remember Me: Bridging the Long-Range Gap in LVLMs with Three-Step Inference-Only Decay Resilience Strategies", "title_en": "Remember Me: Bridging the Long-Range Gap in LVLMs with Three-Step Inference-Only Decay Resilience Strategies", "authors": "Peng Gao,Yujian Lee,Xiaofeng Zhang,Zailong Chen,Hui Zhang", "background": "大型的视觉-语言模型（LVLMs）在多种跨模态任务中取得了显著的性能。然而，在使用旋转位置编码（ROPE）建模长范围依赖时，仍然面临重大挑战。ROPE 虽然有助于精确地建模标记位置，但会导致注意力逐渐衰减，尤其是远距离标记对间的注意力衰减严重削弱了模型对全局上下文的记忆能力。", "innovation": "本文提出了仅在推理阶段使用三种步骤衰减韧性策略（T-DRS），包括（1）语义驱动的 DRS (SD-DRS)，通过内容感知的残差增强语义相关但距离较远的信号；（2）距离感知控制 DRS (DC-DRS)，通过根据位置距离平滑调节权重来净化注意力，抑制噪声同时保留局部性；（3）再增强远距离 DRS (reRD-DRS)，巩固剩余的远程信息依赖，保持全局一致性。这些策略在不需要训练的情况下改善了基于视觉问答基准（VQA）的表现。", "conclusion": "T-DRS 恢复了被抑制的远程标记对，同时不损害局部归纳偏置，并且在视觉问答基准上的广泛实验中表现出了一致的性能提升。"}
{"llm_update_time": "20251116", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2511.09883", "html_url": "https://arxiv.org/abs/2511.09883", "title": "HCC-3D: 分级补偿压缩算法在视觉语言模型中实现98%的3D标记减少", "title_en": "HCC-3D: Hierarchical Compensatory Compression for 98% 3D Token Reduction in Vision-Language Models", "authors": "Liheng Zhang,Jin Wang,Hui Li,Bingfeng Zhang,Weifeng Liu", "background": "近年来，三维理解吸引了广泛关注，利用视觉语言模型（VLMs）实现点云与文本数据之间的多模态推理。当前的3D-VLMs直接将3D点云嵌入到3D标记中，类似大型二维VLMs具有强大的推理能力。然而，这种方法计算成本高，限制了其应用。作者认为瓶颈在于大型语言模型（LLM）部分处理所有3D标记。因此，如何在压缩3D标记的同时保留其关键信息，成为研究的关键问题。", "innovation": "引入了分级补偿压缩（HCC-3D）机制，以高效压缩3D标记的同时保留关键细节。具体包括：1. 全局结构压缩（GSC），通过设计全局查询将所有3D标记压缩为少量关键标记，同时保持整体结构信息；2. 适应性细节挖掘（ADM），通过互补评分选择性压缩未被充分关注但重要的特征，补偿信息损失。实验表明，HCC-3D不仅实现了极高的压缩比（约98%），还在效率和性能上取得了新的最佳表现，显示了显著的改进。", "conclusion": "HCC-3D不仅大幅降低了三维标记的计算开销，还保持了其关键信息，显著提高了3D-VLMs的效率和性能。"}
{"llm_update_time": "20251116", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2511.09891", "html_url": "https://arxiv.org/abs/2511.09891", "title": "Scale-Aware Relay and Scale-Adaptive Loss for Tiny Object Detection in Aerial Images", "title_en": "Scale-Aware Relay and Scale-Adaptive Loss for Tiny Object Detection in Aerial Images", "authors": "Jinfu Li,Yuqi Huang,Hong Song,Ting Wang,Jianghan Xia,Yucong Lin,Jingfan Fan,Jian Yang", "background": "尽管在目标检测领域取得了显著进展，现代检测器在检测航拍图像中的微小目标时仍然存在困难。这主要是因为微小目标携带的特征有限，在长时间网络传播过程中不可避免地受到降级或丢失；此外，在训练过程中，较小的目标会受到相对更大的回归惩罚。", "innovation": "本文提出了尺度感知递送层（SARL）和尺度自适应损失（SAL），能够与当前最佳框架无缝兼容。SARL 利用跨尺度空间-通道注意机制逐层丰富有意义的特征，加强跨层特征共享。SAL 改造了传统的基于 IOU 的损失函数，使训练能够动态地对不同大小的目标分配权重，从而集中在微小目标上同时减少对大型物体的影响。", "conclusion": "在三个基准数据集（AI-TOD，DOTA-v2.0 和 VisDrone2019）上进行了大量实验，结果显示，当嵌入 YOLOv5（基于锚点）和 YOLOx（无锚点）基线时，所提出的方法在平均精度（AP）上提升了 5.5% 的泛化能力；此外，在实际噪声数据集 AI-TOD-v2.0 上也提高了 29.0% 的鲁棒性能。"}
{"llm_update_time": "20251116", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2511.09878", "html_url": "https://arxiv.org/abs/2511.09878", "title": "RWKV-PCSSC: 探索RWKV模型在点云语义场景完成中的应用", "title_en": "RWKV-PCSSC: Exploring RWKV Model for Point Cloud Semantic Scene Completion", "authors": "Wenzhe He,Xiaojun Chen,Wentang Chen,Hongyu Wang,Ying Liu,Ruihui Li", "background": "语义场景完成（SSC）旨在从不完整的输入生成完整的语义场景。现有方法通常采用密集网络架构，参数量大，导致模型复杂度和资源需求增加。针对这些局限性，本文提出了一种基于Receptance Weighted Key Value (RWKV)机制的轻量级点云语义场景完成网络RWKV-PCSSC。", "innovation": "引入了RWKV Seed Generator (RWKV-SG) 模块，可以从前部分点云聚合特征以生成粗略的点云和特征。然后，通过多阶段的RWKV Point Deconvolution (RWKV-PD) 模块逐步恢复点云的逐点特征。这种方法采用了紧凑且高效的结构设计，实现了轻量级的模型表示。实验结果表明，RWKV-PCSSC相比现有最先进的方法PointSSC，参数减少了4.18倍，内存效率提高了1.37倍，并且在室内（SSC-PC，NYUCAD-PC）和室外（PointSSC）场景的数据集以及作者提出的数据集（NYUCAD-PC-V2，3D-FRONT-PC）上均达到了最先进的性能水平。", "conclusion": "RWKV-PCSSC通过采用RWKV机制，提供了轻量且高效的点云语义场景完成方法，减少了参数量和提高了内存效率，同时在多个场景数据集上表现出优异的性能。"}
{"llm_update_time": "20251116", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2511.09909", "html_url": "https://arxiv.org/abs/2511.09909", "title": "模拟分布动态：单域通用目标检测中的液态时间特征演进", "title_en": "Simulating Distribution Dynamics: Liquid Temporal Feature Evolution for Single-Domain Generalized Object Detection", "authors": "Zihao Zhang,Yang Li,Aming Wu,Yahong Han", "background": "现有的单域通用对象检测方法通常依赖于离散的数据增强或静态扰动方法来扩展数据多样性，以缓解无法访问目标域数据的问题。但在实际场景中，如天气或光照条件的变化，领域偏移往往持续而渐进地发生。这些离散的增强和静态扰动方法无法有效地捕捉特征分布的变化，从而限制了模型对细粒度的跨域差异的感知能力。", "innovation": "本文提出了一种新的方法，液态时间特征演进，通过引入时间建模和液态神经网络驱动的参数调整机制，模拟从源域到模拟潜在分布的特征渐进演变过程。具体而言，通过可控的高斯噪声注入和多尺度高斯模糊，模拟初始特征扰动；接着通过时间建模和液态参数调整机制，生成适应性调节参数，实现跨域的平滑和连续适应，从而弥合源域与未知域之间的分布差距，提升泛化能力和适应未见偏移的鲁棒性。", "conclusion": "通过捕获渐进的跨域特征演变并动态调节适应路径，我们的方法显著填补了源域与未知域之间的分布差距，大幅提升了泛化能力和鲁棒性。在多样天气数据集和Real-to-Art基准上的显著性能改进证明了我们方法的优势。我们的代码可在如下链接获取：this https URL"}
{"llm_update_time": "20251116", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2511.09919", "html_url": "https://arxiv.org/abs/2511.09919", "title": "MosaicDoc: 大规模双语基准数据集用于视觉丰富文档理解", "title_en": "MosaicDoc: A Large-Scale Bilingual Benchmark for Visually Rich Document Understanding", "authors": "Ketong Chen,Yuhao Chen,Yang Xue", "background": "现有的视觉语言模型(VLMs)评估基准主要侧重于英语，布局简单，支持的任务有限。这使得它们无法充分评估模型在复杂布局和密集文本的视觉丰富文档理解(VRDU)任务中的性能。", "innovation": "提出了一种名为DocWeaver的新颖多代理流程，利用大型语言模型自动生成一个新的基准。MosaicDoc是一个大规模、双语（中文和英语）资源，旨在推动VRDU的边界。MosaicDoc从报纸和杂志中获取，具有多样且复杂的布局（包括多栏和非曼哈顿式布局）、来自196家出版商的丰富风格变体以及全面的多任务注释(OCR、VQA、阅读顺序和定位)。", "conclusion": "对MosaicDoc上最先进的模型进行了广泛的评估，揭示了它们在处理真实世界文档复杂性方面的局限性，并为未来的研究指明了清晰的方向。"}
{"llm_update_time": "20251116", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2511.09893", "html_url": "https://arxiv.org/abs/2511.09893", "title": "增强区域注意力的Swin变换器在临床相关医疗图像描述中的应用", "title_en": "Regional Attention-Enhanced Swin Transformer for Clinically Relevant Medical Image Captioning", "authors": "Zubia Naz,Farhan Asghar,Muhammad Ishfaq Hussain,Yahya Hadadi,Muhammad Aasim Rafique,Wookjin Choi,Moongu Jeon", "background": "自动化的医学图像描述能够将复杂的放射学图像转化为诊断性的叙述文本，支持报告工作流程。现有的方法在语义保真度和模型复杂度之间存在权衡问题。本研究旨在开发一个既能保持高语义保真度又简洁可解释的医学图像描述系统。本研究基于ROCO数据集进行训练和评估，使用Swin-BART编码器-解码器系统和一个轻量级的区域注意力模块，能够强化诊断上重要的区域，提高描述的质量。", "innovation": "该研究提出了一个区域注意力增强的Swin-BERT系统，通过放大诊断上重要区域增强描述质量。与基线方法相比，该方法在ROUGE和BERTScore等指标上表现更优，同时模型保持较小的复杂度和较高的可解释性。此外，该研究还进行了子模态分析、显著性测试以及应用于不同模态图像的描述效果评估，并提供了可视化区域驱动的手段，确保临床使用中的医学图像描述的安全性和透明度。", "conclusion": "本研究提出的模型在医学图像描述任务上取得了较好的效果，能够生成准确且临床适用的描述文本，并通过轻量级的区域注意力模块增强了可解释性。同时，通过一系列实验验证了其在不同医学图像模态上的可行性，为未来医学图像描述的研究提供了新的思路。"}
{"llm_update_time": "20251116", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2511.09926", "html_url": "https://arxiv.org/abs/2511.09926", "title": "补偿预训练视觉得类增量学习中的分布漂移", "title_en": "Compensating Distribution Drifts in Class-incremental Learning of Pre-trained Vision Transformers", "authors": "Xuan Rao,Simian Xu,Zheng Li,Bo Zhao,Derong Liu,Mingming Ha,Cesare Alippi", "background": "近期研究表明，通过预训练的视觉变换器（ViTs）进行顺序微调（SeqFT），随后使用类别特征的近似分布来精炼分类器，可以成为有效的类增量学习（CIL）策略。然而，这种做法容易受到分布漂移的影响，因为共享主干参数的序列优化会导致之前学习的类别分布与更新模型的分布不匹配，从而随着时间的推移降低分类器性能的效果。", "innovation": "该研究提出了一种称为Sequential Learning with Drift Compensation (SLDC) 的方法，通过引入潜在空间转换算子，旨在沿任务对齐特征分布以减轻漂移的影响。研究进一步扩展了一种弱非线性SLDC变体，通过可学习的弱非线性变换平衡灵活性和泛化能力。为了进一步减少表示漂移，算法变体中采用了知识蒸馏（KD）。实验表明，SLDC显著提升了SeqFT的表现。结合KD和SLDC，SeqFT在所有评估数据集上的性能可与联合训练相媲美。", "conclusion": "大量的基准测试表明，SLDC不仅在顺序微调的基础上解决了分布漂移问题，还通过结合知识蒸馏提高了分类器的整体性能。这项工作提供了补偿预训练视觉模型类增量学习中分布漂移的创新解决方案。"}
{"llm_update_time": "20251116", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2511.09933", "html_url": "https://arxiv.org/abs/2511.09933", "title": "Debiased Dual-Invariant Defense for Adversarially Robust Person Re-Identification", "title_en": "Debiased Dual-Invariant Defense for Adversarially Robust Person Re-Identification", "authors": "Yuhang Zhou,Yanxiang Zhao,Zhongyun Hua,Zhipu Liu,Zhaoquan Gu,Qing Liao,Leo Yu Zhang", "background": "行人再识别（ReID）在多个实际应用场景中是一项基本任务，如行人轨迹跟踪。然而，基于深度学习的ReID模型易受对抗性攻击的影响，小的不可察觉的图像扰动可能导致完全错误的预测，构成重大安全威胁。尽管已经提出了许多针对分类任务的对抗性防御策略，但这些策略向度量学习任务（如行人ReID）的扩展仍未得到充分探索。现有的行人ReID防御方法未能解决对抗性鲁棒ReID固有的独特挑战。", "innovation": "本文系统地将对抗性防御中的挑战归结为两个关键问题：模型偏差和综合泛化要求。作者提出了一种去偏差的双不变防御框架，包括两个主要阶段。数据平衡阶段通过使用基于扩散模型的数据重采样策略减轻模型偏差，促进训练数据的公平性和多样性。 bi-对抗性自元防御阶段则引入了一种新的度量对抗训练方法，采用远负样本延伸柔和化，以克服缺少分类器导致的鲁棒性退化。同时，提出了一种对抗性增强的自元机制，以实现针对未见过的身份和未见过的攻击类型的双重泛化。", "conclusion": "实验表明，本文的方法显著优于现有的先进防御方法。"}
{"llm_update_time": "20251116", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2511.09965", "html_url": "https://arxiv.org/abs/2511.09965", "title": "通过等变采样提高基于扩散模型的图像恢复性能", "title_en": "Equivariant Sampling for Improving Diffusion Model-based Image Restoration", "authors": "Chenxu Wu,Qingpeng Kong,Peiang Zhao,Wendi Yang,Wenxin Ma,Fenghe Tang,Zihang Jiang,S.Kevin Zhou", "background": "近年来，生成模型，尤其是扩散模型，大大提高了图像恢复（IR）的效果。然而，现有的通用基于扩散模型的图像恢复（DMIR）方法在充分利用扩散先验时存在挑战，导致性能不足。", "innovation": "通过分析当前通用DMIR方法的采样过程并提供有效解决方案，提出了EquS方法，该方法通过双重采样轨迹引入等变信息。进一步，提出了时间步长感知调度（TAS），并引入了EquS+。TAS优先处理确定性步骤以增强确定性和采样效率。广泛的基准测试表明，该方法可以与之前的通用DMIR方法兼容，并显著提升了其性能，而不会增加计算成本。", "conclusion": "实验结果证明，即使不增加计算成本，该方法也可以与之前的通用DMIR方法兼容并显著提升其性能。"}
{"llm_update_time": "20251116", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2511.09942", "html_url": "https://arxiv.org/abs/2511.09942", "title": "AdaptViG: 自适应视觉GNN及其指数衰减门机制", "title_en": "AdaptViG: Adaptive Vision GNN with Exponential Decay Gating", "authors": "Mustafa Munir,Md Mostafijur Rahman,Radu Marculescu", "background": "视觉图神经网络(ViGs)为视觉架构的进步提供了一个新方向，尽管强大，但ViGs在图构建阶段面临着巨大的计算挑战，这限制了它们的效率。现有的方法难以在准确性和效率之间取得良好平衡，尤其是在大规模应用中。", "innovation": "提出了一种名为AdaptViG的高效且强大的混合视觉GNN，引入了一种新型的图构建机制——自适应图卷积。该机制基于一个高效的静态轴结构，并采用动态的内容感知门控策略——指数衰减门。这种方法根据特征相似性有选择地权衡长时间联系。AdaptViG采用了混合策略，在早期阶段采用高效门控机制，在最终阶段使用全局注意力模块进行最大特征聚合。AdaptViG展示了在视觉GNN中新的准确性和效率折衷的最佳实践。例如，AdaptViG-M在top-1精度上达到82.6%，相比ViG-B精度提高了0.3%，参数减少80%，GMACs减少84%。在下游任务上，AdaptViG-M分别超过EfficientFormer-L7 0.7 IoU、2.2 APbox和2.1 APmask，同时参数减少78%。", "conclusion": "AdaptViG在视觉GNN中实现了新的准确性和效率折衷。这种新的图构建机制和门控策略可有效解决计算挑战，并提高了性能。"}
{"llm_update_time": "20251116", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2511.09948", "html_url": "https://arxiv.org/abs/2511.09948", "title": "基于特征大小感知CLIP的无参考图像质量评估", "title_en": "Beyond Cosine Similarity Magnitude-Aware CLIP for No-Reference Image Quality Assessment", "authors": "Zhicheng Liao,Dongxu Wu,Zhenshan Shi,Sijie Mai,Hanwei Zhu,Lingyu Zhu,Yuncheng Jiang,Baoliang Chen", "background": "近期的研究已尝试将对比学习语言-图像预训练（CLIP）模型重新用于无参考图像质量评估（NR-IQA），主要通过计算图像嵌入与文本提示（例如“一张好的照片”或“一张糟糕的照片”）之间的余弦相似度来实现。然而，这种语义相似度忽略了对感知质量有重要影响但尚待深入探索的线索——CLIP图像特征的大小。实验结果显示，CLIP图像特征的大小与感知质量存在显著相关性。", "innovation": "本文提出了一种新型自适应融合框架，将余弦相似度与大小感知的质量线索相结合。具体而言，首先提取绝对CLIP图像特征并应用Box-Cox变换以统计地正态化特征分布并降低语义敏感性。由此产生的标量摘要信息作为语义归一化辅助线索，辅助基于余弦的提示匹配。此外，设计了一种根据各自强度自适应加权的置信度导向融合方案，将两种线索有效结合。", "conclusion": "大量基准IQA数据集上的实验表明，本文方法在无需特定任务训练的情况下，始终优于标准的CLIP基线和先进的基线模型。"}
{"llm_update_time": "20251116", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2511.09944", "html_url": "https://arxiv.org/abs/2511.09944", "title": "TSPE-GS：通过三维高斯溅射提取透明表面的概率深度", "title_en": "TSPE-GS: Probabilistic Depth Extraction for Semi-Transparent Surface Reconstruction via 3D Gaussian Splatting", "authors": "Zhiyuan Xu,Nan Min,Yuhang Guo,Tong Wei", "background": "3D高斯溅射提供了速度和质量之间的强大权衡，但在重建半透明表面时遇到困难，因为大多数方法假设每个像素只有一个深度，当多表面显示时，这种假设会失败。为解决这个问题，作者提出了TSPE-GS（透明表面概率提取用于高斯溅射），通过均匀采样透射率来构建像素级别的多模态不透明度和深度分布，替代单一峰值假设，解决了跨表面的深度歧义问题。通过逐步融合截断的符号距离函数，TSPE-GS在统一框架中分别重建外部和内部表面。该方法可以适用于其他基于高斯的重建管道而无额外训练开销。在公共和自行收集的半透明和不透明数据集上的大量实验显示，TSPE-GS在重建半透明几何结构方面显著优于现有方法，同时在不透明场景中的性能保持良好。", "innovation": "提出TSPE-GS（透明表面概率提取用于高斯溅射），通过均匀采样透射率来模拟像素级别的多模态不透明度和深度分布，解决跨表面的深度歧义问题；通过逐步融合截断的符号距离函数，该方法可以同时重建内部和外部表面，且不会增加额外的训练开销。", "conclusion": "在公共和自行收集的半透明和不透明数据集上的实验表明，TSPE-GS在半透明几何重建方面表现优异，同时在不透明场景中保持了良好的性能。"}
{"llm_update_time": "20251116", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2511.09973", "html_url": "https://arxiv.org/abs/2511.09973", "title": "Difference Vector Equalization for Robust Fine-tuning of Vision-Language Models", "title_en": "Difference Vector Equalization for Robust Fine-tuning of Vision-Language Models", "authors": "Satoshi Suzuki,Shin'ya Yamaguchi,Shoichiro Takeda,Taiga Yamane,Naoki Makishima,Naotaka Kawata,Mana Ihori,Tomohiro Tanaka,Shota Orihashi,Ryo Masumura", "background": "对比预训练的跨模态模型，如CLIP，在零样本分类中的泛化能力很强，通过利用图像和文本编码器提取的嵌入。当前的稳健微调方法通过重新利用预训练中使用的对比学习来应对微调中保持泛化能力的挑战，但研究发现这些方法会导致嵌入的几何结构失真，从而影响模型在离域和零样本场景下的性能。", "innovation": "提出了一种新的方法——差异向量均衡（DiVE），这种方法在微调过程中的约束了差异向量的几何结构。通过两个损失函数：平均向量损失（AVL）和成对向量损失（PVL），全局和局部地保持几何结构，从而在保持泛化能力的同时实现稳健的微调。", "conclusion": "实验结果表明，DiVE 有效地保持了几何结构，在离域、离分布外和零样本方面都取得了很好的性能。"}
{"llm_update_time": "20251116", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2511.09955", "html_url": "https://arxiv.org/abs/2511.09955", "title": "使用对象级共学习从VLM生成伪标签的鲁棒对象检测", "title_en": "Robust Object Detection with Pseudo Labels from VLMs using Per-Object Co-teaching", "authors": "Uday Bhaskar,Rishabh Bhattacharya,Avinash Patel,Sarthak Khoche,Praveen Anil Kulkarni,Naresh Manwani", "background": "基础模型，尤其是视觉-语言模型（VLMs），在如自动驾驶等应用场景中提供零样本对象检测方法，但这些模型存在检测延迟高和容易生成虚假预测的问题，不利于直接应用。", "innovation": "提出了一种新的基于对象级共学习的训练策略，通过充分利用VLMs自动生成伪标签来训练高效的实时对象检测器，该策略专门过滤训练中的不准确边界框而不是整个图像，从而减轻VLM生成标签的固有噪声。两个YOLO模型协作，根据同伴的对象损失值筛选出不可靠的边界框，这种方法提高了性能同时保持了实时检测延迟。", "conclusion": "实验结果表明，该方法在KITTI数据集上超越了YOLOv5m基线模型，mAP@0.5值提高了$31.12\rightarrow46.61\text{%}$，并继续加入少量的精确标签（$10\text{%}$）获取到$57.97\text{%}$的mAP@0.5。此外，在ACDC和BDD100k数据集上也观察到类似的性能改进。"}
{"llm_update_time": "20251116", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2511.09977", "html_url": "https://arxiv.org/abs/2511.09977", "title": "STELLAR：低资源语言和现实世界数据的场景文本编辑器", "title_en": "STELLAR: Scene Text Editor for Low-Resource Languages and Real-World Data", "authors": "Yongdeuk Seo,Hyun-seok Min,Sungchul Choi", "background": "场景文本编辑（STE）是指在保持文本视觉风格（如字体、颜色和背景）的情况下对图像中的文本内容进行修改的任务。尽管近期基于扩散的方法在视觉质量上有所提高，但仍然存在低资源语言支持不足、合成数据与真实数据之间的领域差距以及没有合适的风格保持评价指标等关键问题。", "innovation": "提出了STELLAR（场景文本编辑器，针对低资源语言和现实世界数据），通过一种适应语言的字形编码器和多阶段训练策略，首先在合成数据上预训练，然后在真实图像上进行微调。此外，还构建了一个新的数据集STIPLAR（低资源语言和现实世界数据的场景文本图像对），用于训练和评估。提出了文本外观相似性（TAS）指标，一种独立测量字体、颜色和背景相似性的新颖评价指标，即使没有地伤心使用也能进行稳健的评价。实验结果表明，STELLAR在视觉一致性和识别准确性上优于现有模型，实现了一种TAS指标的平均2.2%提高。", "conclusion": "STELLAR模型在低资源语言的场景文本编辑任务中表现出了优越的性能，特别是在视觉一致性、识别准确性和风格保持方面有所突破。"}
{"llm_update_time": "20251116", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2511.09999", "html_url": "https://arxiv.org/abs/2511.09999", "title": "MOBA: A Material-Oriented Backdoor Attack against LiDAR-based 3D Object Detection Systems", "title_en": "MOBA: A Material-Oriented Backdoor Attack against LiDAR-based 3D Object Detection Systems", "authors": "Saket S. Chaturvedi,Gaurav Bagwe,Lan Zhang,Pan He,Xiaoyong Yuan", "background": "LiDAR-based 3D对象检测在安全关键系统中广泛应用，但这些系统仍易受训练时植入隐藏恶意行为的后门攻击。现有后门攻击的一个主要限制是它们在数字到物理领域的不可实现性，这主要是由于触发器在现实世界中的有效性往往忽略材料依赖的LiDAR反射特性。因此，实际构建的触发器通常未经过优化，导致其效果低下或容易被发现。", "innovation": "本文介绍了Material-Oriented Backdoor Attack (MOBA)，这是一种新颖的框架，通过明确建模真实触发器的材料特性来弥合数字到物理领域的差距。MOBA克服了物理后门设计中的两个关键挑战：1)在各种环境条件下触发材料的鲁棒性; 2)物理触发器行为与数字模拟的对齐。具体包括选择鲁棒的触发材料，使用TiO_2材料，以及开发一个具有角度无关近似Oren-Nayar BRDF模型和距离感知缩放机制的模拟管道，以确保数字触发器准确模拟基于材料的触发器的行为。MOBA的攻击成功率高达93.50%，远超先前方法的41%以上。", "conclusion": "本工作中揭示了一类新的可实现的物理威胁，并强调了在现实环境中考虑材料级属性对于安全防御的迫切需求。"}
{"llm_update_time": "20251116", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2511.10003", "html_url": "https://arxiv.org/abs/2511.10003", "title": "DBGroup: 双分支点分组用于弱监督3D实例分割", "title_en": "DBGroup: Dual-Branch Point Grouping for Weakly Supervised 3D Instance Segmentation", "authors": "Xuexun Liu,Xiaoxu Xu,Qiudan Zhang,Lin Ma,Xu Wang", "background": "弱监督3D实例分割对于3D场景理解至关重要，尤其是在数据规模扩大和全监督方法标注成本升高的背景下。现有方法主要依赖于点击一个物体一次和边界框标注两种弱监督形式，这些方法虽然减少了标注工作量，但仍面临标注过程劳动密集、复杂度高以及依赖专家标注人员的挑战。因此，如何设计一个更高效且可扩展的弱监督方法成为亟待解决的问题。", "innovation": "本文提出了一种名为DBGroup的两阶段弱监督3D实例分割框架，该框架利用场景级别的标注作为更高效且可扩展的替代方案。第一阶段使用Dual-Branch Point Grouping模块基于多视角图像提取的语义和掩膜线索生成伪标签，并通过Granularity-Aware Instance Merging和Semantic Selection and Propagation两个策略进一步提高标签质量。第二阶段利用细化后的伪标签在端到端实例分割网络上进行多轮自训练。此外，引入了Instance Mask Filter策略来解决伪标签不一致性的问题。实验结果表明，DBGroup在性能上与稀疏点级监督3D实例分割方法相当，而在场景级监督3D语义分割方面超越了现有先进方法。", "conclusion": "DBGroup框架在弱监督3D实例分割中表现出色，解决了现有方法存在的问题，并且性能优于当前的先进方法。"}
{"llm_update_time": "20251116", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2511.10013", "html_url": "https://arxiv.org/abs/2511.10013", "title": "MIRNet: 结合预训练与约束图推理的诊断医学影像分析", "title_en": "MIRNet: Integrating Constrained Graph-Based Reasoning with Pre-training for Diagnostic Medical Imaging", "authors": "Shufeng Kong,Zijie Wang,Nuan Cui,Hao Tang,Yihan Meng,Yuanyuan Wei,Feifan Chen,Yingheng Wang,Zhuo Cai,Yaonan Wang,Yulong Zhang,Yuzheng Li,Zibin Zheng,Caihua Liu", "background": "医学图像的自动化解释需要强大的建模能力来处理复杂的视觉-语义关系，同时解决注解稀缺性、标签不平衡以及临床可行性的问题。舌部图像诊断是一个特别具有挑战性的领域，需要对细微视觉和语义的理解。", "innovation": "本文介绍了一种名为MIRNet的新框架，该框架结合了自监督预训练与约束图推理。MIRNet利用自监督掩码自编码器（MAE）从未标注数据中学习可迁移的视觉表示；使用图注意力网络（GAT）通过专家定义的结构化图模型标签相关性；通过约束感知优化使用KL散度和正则化损失强制执行临床先验；并使用不对称损失（ASL）和提升集成缓解标签不平衡。此外，还引入了TongueAtlas-4K专家编写的基准数据集，包含4,000张带有22个诊断标签的图像—这是舌部分析中最大的公共数据集。", "conclusion": "验证表明，我们的方法在诊断医学影像中达到了最先进的性能。虽然该框架针对舌部诊断进行优化，但其易于推广至更广泛的诊断医学影像任务。"}
{"llm_update_time": "20251116", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2511.10004", "html_url": "https://arxiv.org/abs/2511.10004", "title": "LampQ: 向量变压器逐层混合精度量化的准确方法", "title_en": "LampQ: Towards Accurate Layer-wise Mixed Precision Quantization for Vision Transformers", "authors": "Minjun Kim,Jaeri Lee,Jongjin Kim,Jeongin Yun,Yongmo Kwon,U Kang", "background": "预训练视觉变压器模型可以通过量化技术压缩成低精度格式，以减少内存和计算需求，同时保持较低的准确度下降。现有的量化方法依赖于均匀精度，未能考虑到视觉变压器组件对量化具有不同的敏感度。虽然基于度量的混合精度量化（MPQ）作为一种替代方案显示出潜力，但现有的MPQ方法针对视觉变压器存在三个主要局限性：粗粒度的量化、量化的不同组件类型之间度量尺度的不匹配，以及缺乏量化知晓的比特分配。", "innovation": "本文提出了一种新的量化方法，LampQ（逐层混合精度量化），它是一种针对视觉变压器的精确基于度量的MPQ方法，能够克服上述局限性。LampQ采用逐层的量化方式以实现细粒度控制和高效加速，同时结合一种类型感知的Fisher度量来衡量敏感性。此外，LampQ通过整数线性规划最佳地分配比特宽度，并进行迭代更新。实验结果表明，LampQ在量化在各类任务上预训练的视觉变压器时提供了最先进的性能，包括图像分类、对象检测和零样本量化。", "conclusion": "本文通过提出LampQ，展示了在视觉变压器上实现基于度量的混合精度量化的准确方法，克服了现有方法的局限性，并且在各种任务上的量化效果达到了最先进的水平。"}
{"llm_update_time": "20251116", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2511.10040", "html_url": "https://arxiv.org/abs/2511.10040", "title": "LoG3D：通过局部到全局分区实现超高清3D形状建模", "title_en": "LoG3D: Ultra-High-Resolution 3D Shape Modeling via Local-to-Global Partitioning", "authors": "Xinran Yang,Shuichang Lai,Jiangjing Lyu,Hongjie Li,Bowen Pan,Yuanqi Li,Jie Guo,Zhou Zhengkang,Yanwen Guo", "background": "生成高保真3D内容仍然是一个基础挑战，因为需要表示复杂的拓扑结构（如开放表面和复杂内部结构），同时保持几何细节。现有基于符号距离场（SDFs）的方法受到昂贵的无缝预处理的困扰，并且难以处理非关联几何结构，而点云表示经常会遭受采样伪影和表面不连续性。", "innovation": "本研究提出了一种新颖的3D变分自编码器（VAE）框架，该框架基于无符号距离场（UDFs），这是一种更稳健且计算效率更高的表示方法，能够自然地处理复杂且不完整的形状。核心创新是局部到全局（LoG）架构，该架构通过将UDFs划分为均匀子体块（称为UBlocks）来进行处理，并结合3D卷积捕获局部细节和稀疏变换强制全局一致性。此外，通过填充平均策略确保重建时子体块边界处平滑过渡。这种模块化设计使得无缝扩展到超高清分辨率（高达2048^3），这在之前的3D VAE中是无法实现的。", "conclusion": "实验表明，在重构准确性和生成质量方面均达到了最先进的性能，取得了更光滑的表面和更大的几何灵活性。"}
{"llm_update_time": "20251116", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2511.10017", "html_url": "https://arxiv.org/abs/2511.10017", "title": "AffordBot：通过多模态大型语言模型实现3D精细体态推理", "title_en": "AffordBot: 3D Fine-grained Embodied Reasoning via Multimodal Large Language Models", "authors": "Xinyi Wang,Xun Yang,Yanlong Xu,Yuchen Wu,Zhen Li,Na Zhao", "background": "有效的人机协作需要理解不仅要知道执行什么动作，还需要知道在哪里找到可以执行的元素以及如何与它们互动。现有的方法往往停留在物体层面，或不连贯地处理细粒度的功能推理，缺乏基于指令的连续推理和指导。现有研究缺乏一个能够将任务指令、空间位置、运动类型和运动轴向进行有效结合和解释的框架，特别是在3D环境中进行细致推理方面存在挑战。文章提出的任务要求智能体根据指令预测3D场景中每个提及的功能元素的空间位置、运动类型和运动轴向。", "innovation": "文章引入了一种名为AffordBot的新框架，该框架结合了多模态大型语言模型（MLLMs）和定制的逻辑链（CoT）。为了实现从3D输入到2D兼容模型的转换，AffordBot渲染了场景的全景视图并将3D元素投射到这些视图中，从而形成一个与场景几何结构对齐的丰富视觉表示。通过这种框架，AffordBot能够在仅有3D点云输入和MLLMs的情况下，展示出强大的泛化能力和物理上合理的推理能力，同时仅通过指令和视觉输入，解决了复杂的3D环境中的细粒度推理问题。", "conclusion": "AffordBot在SceneFun3D数据集上的性能达到了最新的技术水平，证明了其不仅能够进行有效的指令驱动的空间推理，同时也能根据3D环境中的元素进行详细的交互操作。"}
{"llm_update_time": "20251116", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2511.10035", "html_url": "https://arxiv.org/abs/2511.10035", "title": "DGFusion: 双引导融合用于稳健的多模态3D目标检测", "title_en": "DGFusion: Dual-guided Fusion for Robust Multi-Modal 3D Object Detection", "authors": "Feiyang Jia,Caiyan Jia,Ailin Liu,Shaoqing Xu,Qiming Xia,Lin Liu,Lei Yang,Yan Gong,Ziying Song", "background": "作为自动驾驶感知系统中的关键任务，3D物体检测用于识别和追踪关键对象，如车辆和行人。然而，难以检测远处、小型或被遮挡的对象（即，硬实例），这直接影响了自动驾驶系统的安全性。现有的多模态3D物体检测方法往往遵循单一引导模式，忽视了不同模态之间硬实例信息密度的差异。因此，现有的方法在硬实例检测中存在局限性。", "innovation": "本文提出了一种基于双引导范式的DGFusion方法，它充分利用了点引导-图像范式和图像引导-点范式的优势，解决了单一范式的局限性。DGFusion的核心是难度感知实例对匹配器（DIPM），基于难度进行实例级特征匹配，生成容易和困难的实例对。双引导模块进一步利用这两种类型的优势，实现有效的多模态特征融合。实验结果表明，DGFusion在nuScenes数据集上的mAP、NDS和平均召回率分别提高了1.0%，0.8%和1.3%，证明了其在硬实例检测中的稳健性优势，且不受 ego 距离、大小、可见性和小规模训练场景的影响。", "conclusion": "实验结果显示，DGFusion在nuScenes数据集上相对于基线方法的性能显著提升，特别在硬实例检测中展示了稳健的性能增益。"}
{"llm_update_time": "20251116", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2511.10046", "html_url": "https://arxiv.org/abs/2511.10046", "title": "FreDFT: 频率域融合变换器用于可见-红外目标检测", "title_en": "FreDFT: Frequency Domain Fusion Transformer for Visible-Infrared Object Detection", "authors": "Wencong Wu,Xiuwei Zhang,Hanlin Yin,Shun Dai,Hongxi Zhang,Yanning Zhang", "background": "可见-红外目标检测在低光照、雾和雨等条件下的检测性能引起了足够的关注。然而，由不同传感器捕获的可见光和红外模式存在信息不平衡问题，特别是在复杂场景中，这会导致跨模态融合不足，从而降低检测性能。", "innovation": "现有的大多数方法在空间域中使用变压器来捕捉互补特征，忽视了在频率域开发变压器以挖掘互补信息的优势。为此，该研究提出了一种频率域融合变换器（FreDFT）用于可见-红外目标检测。提出的方法采用了新颖的多模态频率域注意力（MFDA）来挖掘不同模态之间的互补信息，并通过混合尺度频率特征融合策略设计了频率域前馈层（FDFFL）以更好地增强多模态特征。为了消除多模态信息的不平衡，还构建了一个跨模态全局建模模块（CGMM），以在空间和通道上进行像素级跨模态特征交互。此外，提出了一种局部特征增强模块（LFEM），通过使用各种卷积层并应用通道洗牌增强多模态局部特征表示，促进多模态特征融合。", "conclusion": "通过广泛的实验结果证实，提出的 FreDFT 在多个公共数据集中的性能优于其他最先进的方法。我们的 FreDFT 代码可在以下链接处获得。"}
{"llm_update_time": "20251116", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2511.10020", "html_url": "https://arxiv.org/abs/2511.10020", "title": "Anomagic: 双模态提示驱动的零样本异常生成", "title_en": "Anomagic: Crossmodal Prompt-driven Zero-shot Anomaly Generation", "authors": "Yuxin Jiang,Wei Luo,Hui Zhang,Qiyu Chen,Haiming Yao,Weiming Shen,Yunkang Cao", "background": "当前异常生成方法通常需要使用示例异常数据，这限制了方法的应用范围。Anomagic 提出了一种无需任何示例异常数据就能生成语义连贯异常的零样本异常生成方法。通过结合视觉和文本线索，Anomagic 利用丰富的上下文信息引导无损修复生成管道，并通过对比优化策略加强合成异常与掩码之间的精确对齐，从而提高下游异常检测的准确性。此外，为了简化训练过程，作者构建了包含12,987个异常-掩码-描述三元组的 AnomVerse 数据集，用于训练和测试该方法。", "innovation": "Anomagic 提出了一种无需示例异常数据就能生成语义连贯异常的零样本生成方法，通过集成视觉和文本线索，并利用富有的上下文信息来引导生成过程。此外，Anomagic 引入了一个双模态提示驱动的对比优化策略，确保了合成异常与掩码之间的精确匹配。该方法还提出了一种新的数据集 AnomVerse，包含了12,987个异常-掩码-描述三元组，有助于该方法的训练和发展。", "conclusion": "广泛的实验表明，利用 AnomVerse 训练的 Anomagic 能够生成比之前的算法更真实和多样的异常，从而显著提高了下游的异常检测性能。此外，Anomagic 完全能够在任意正常图像上生成异常，为异常生成建立了一个多功能的基础模型。"}
{"llm_update_time": "20251116", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2511.10055", "html_url": "https://arxiv.org/abs/2511.10055", "title": "通过HCM-GRPO实现图像美学推理：提高紧凑模型性能", "title_en": "Image Aesthetic Reasoning via HCM-GRPO: Empowering Compact Model for Superior Performance", "authors": "Zhiyuan Hu,Zheng Sun,Yi Wei,Long Yu", "background": "近年来，图像生成的性能显著提高，但图像筛选的研究相对较少，特别是在多模态大型语言模型（MLLMs）中，由于缺乏数据和模型的图像美学推理能力较弱，因此表现不佳。", "innovation": "提出了一个全面的数据解决方案和Hard Cases Mining（HCM）策略结合Dynamic Proportional Accuracy（DPA）奖励的方法，以此引入Group Relative Policy Optimization（GRPO）框架，形成HCM-GRPO。这种方法在图像美学推理方面表现出色，即使是对闭源的MLLMs（如GPT4o和Qwen-VL-Max）而言，它们的表现也类似于随机猜测，但通过HCM-GRPO方法，能显著超越开源和闭源的大规模和顶级模型的性能，使用较小的模型便可实现。", "conclusion": "本文通过收集包含超过128,000个样本，近640,000张图像的全面图像筛选数据集，以及多种数据注释方法，提出了HCM-GRPO方法。实验结果表明，HCM-GRPO方法在图像美学推理方面表现出优越的能力，即使对于闭源的MLLMs，通过该方法也能实现超越大模型的性能。"}
{"llm_update_time": "20251116", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2511.10047", "html_url": "https://arxiv.org/abs/2511.10047", "title": "MuSc-V2：利用未标注样本的互评实现全模态零样本工业异常分类与分割", "title_en": "MuSc-V2: Zero-Shot Multimodal Industrial Anomaly Classification and Segmentation with Mutual Scoring of Unlabeled Samples", "authors": "Xurui Li,Feng Xue,Yu Zhou", "background": "零样本异常分类（AC）和分割（AS）方法旨在无需使用任何标注样本的情况下识别和定位缺陷。现有方法通常忽视了一个关键特性：工业产品中的正常图像块通常在2D外观和3D形状上找到了很多相似的块，而异常保持多样且孤立。这一特性对于有效地区分异常和正常情况至关重要，但之前的方法未能充分利用这个特点。因此，需要新的方法来发生这种情况下的区分.", "innovation": "本文提出了一个新的互评框架（MuSc-V2），灵活支持单一2D/3D或多模态的情况。框架首先通过迭代点组（IPG）改进3D表示以降低假阳性的比例，然后利用具有多种度的相似邻域聚合（SNAMD）将2D/3D区域线索融合成更具判别性的多尺度图像块特征用于互评。核心组成部分包括基于每种模态内样本给彼此打分的互评机制（MSM）和跨模态异常增强（CAE），后者对2D和3D评分进行融合，以恢复模态特定的缺失异常。此外，约束邻域重评分（RsCon）机制基于相似性抑制基于相似性虚假分类。MuSc-V2框架在全数据集和较小的子集上都能保持一贯的稳健性能，能够在不同的产品线之间无缝适应。实验结果表明，MuSc-V2在多个数据集上显著提高了性能，特别是在MVTec 3D-AD数据集上提高了23.7%的AP精度，以及在Eyecandies数据集上提高了19.3%的AP精度，超越了先前的零样本基准，甚至超过了大多数几样本方法。", "conclusion": "MuSc-V2框架在多个工业数据集上实现了显著的性能提升，提供了一种有效的零样本异常分类与分割方法，可用于多种模态情况。"}
{"llm_update_time": "20251116", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2511.10068", "html_url": "https://arxiv.org/abs/2511.10068", "title": "感知、行动与修正：信心不足以进行高光谱分类", "title_en": "Perceive, Act and Correct: Confidence Is Not Enough for Hyperspectral Classification", "authors": "Muzhou Yang,Wuzhou Quan,Mingqiang Wei", "background": "在高光谱图像分类中，仅仅依赖信心往往是误导性的，因为模型倾向于将高预测得分误认为正确性，而缺乏对不确定性的感知。这会导致确认偏差，特别是在稀疏注释或类别不平衡的情况下，模型会过度拟合自信的错误而无法泛化。", "innovation": "我们提出一种名为CABIN（认知感知行为引导学习）的半监督框架，通过感知、行动和修正的闭环学习过程来解决这一局限。CABIN首先通过估算先天不确定性来培养感知能力，识别出错误可能发生的位置。然后采取不确定样本的探索，同时将自信样本锚定为稳定的伪标签以减少偏差。为了修正不准确的监督，CABIN引入了一种细粒度动态分配策略，将伪标签数据分为可靠、模糊和噪声子集，并应用定制损失来增强泛化能力。", "conclusion": "实验结果表明，CABIN可以显著提升各种最先进的方法的标签效率和性能。"}
{"llm_update_time": "20251116", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2511.10059", "html_url": "https://arxiv.org/abs/2511.10059", "title": "当眼睛和耳朵不一致时：MLLMs能否区分视听混淆？", "title_en": "When Eyes and Ears Disagree: Can MLLMs Discern Audio-Visual Confusion?", "authors": "Qilang Ye,Wei Zeng,Meng Liu,Jie Zhang,Yupeng Hu,Zitong Yu,Yu Zhou", "background": "研究多模态大语言模型（MLLMs）在视听信息不一致情况下的认知能力。传统上，MLLMs 主要依赖视觉信息进行推理，而忽视了听觉信息。本文提出 AV-ConfuseBench，一种模拟视听混淆场景的新基准，通过改变视频中对象的声音，促使 MLMS 理解无声音的物体是否存在，以此揭示 MLMS 在区分非存在声音时的困难。", "innovation": "提出 RL-CoMM（基于强化学习的协作多MLLM系统），系统包含两个阶段：1) 通过引入大型音频语言模型（LALM）作为参考模型，提供纯音频推理，减少视觉主导的歧义，利用步进推理奖励机制提升 MLMS 的音频-视觉推理能力；2) 引入以答案为中心的信心优化策略，减少潜在推理差异的不确定性，提高答案预测的准确性。实验结果表明，与基线模型相比，即使训练数据有限，RL-CoMM 在音频-视觉问答和音频-视觉幻觉上的准确率提高了 10~30%。", "conclusion": "通过 AV-ConfuseBench 和 RL-CoMM，研究表明 MLMS 可以通过引入更高级的音频推理机制，有效地解决视听信息不一致的问题，显著提高准确性。"}
{"llm_update_time": "20251116", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2511.10074", "html_url": "https://arxiv.org/abs/2511.10074", "title": "VLF-MSC: 基于视觉-语言特征的多模态语义通信系统", "title_en": "VLF-MSC: Vision-Language Feature-Based Multimodal Semantic Communication System", "authors": "Gwangyeon Ahn,Jiwan Seo,Joonhyuk Kang", "background": "现有的语义通信技术通常会对不同的模态如图像和文本分别进行处理，缺乏一种能够同时支持图像和文本生成的统一系统。本文旨在提出一种新的解决方案，即视觉语言特征基于的多模态语义通信（VLF-MSC），它能够通过无线信道传输一个单一且紧凑的视觉-语言表示，简化接收端的处理流程，提升频谱效率和适应性。", "innovation": "VLF-MSC 的创新之处在于它利用预训练的视觉-语言模型（VLM）将来源图像编码为视觉-语言语义特征（VLF），该特征可以同时支持文本生成和图像生成。这种统一的表示形式避免了特定模态流或重传的需要，从而提高了频谱效率和适应性。此外，系统利用基础模型实现了对信道噪声的鲁棒性，同时保持语义保真度。", "conclusion": "实验结果表明，VLF-MSC 超过了仅文本和仅图像的基准，即使在信噪比（SNR）较低的情况下也能实现更高的语义准确性，并且所需的带宽显著减少。"}
{"llm_update_time": "20251116", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2511.10076", "html_url": "https://arxiv.org/abs/2511.10076", "title": "通过全局旋转扩散和多级约束缓解共语动捕中的累积误差", "title_en": "Mitigating Error Accumulation in Co-Speech Motion Generation via Global Rotation Diffusion and Multi-Level Constraints", "authors": "Xiangyue Zhang,Jianfang Li,Jianqiang Ren,Jiaxu Zhang", "background": "可靠的同声传译运动生成需要精确的运动表示和关节间的结构先验一致性。现有生成方法通常基于骨架层次结构定义局部关节旋转，这会导致生成过程中累积误差，表现为末端执行器的不稳定和不可信的运动。", "innovation": "我们提出了GlobalDiff，一种基于全局关节旋转的扩散框架。这种方法第一次直接操作在全局关节旋转空间中，并且从上游依赖中解耦每个关节的预测，从根本上缓解了层级错误累积。为了弥补全局旋转空间中结构性先验的缺失，引入了多级约束方案。具体而言，关节结构约束引入虚拟锚点来更好地捕获细微的方向，骨骼结构约束确保骨架结构保持一致性，时间结构约束使用多尺度变分编码器使生成的运动与真实时间模式对齐。这些约束联合正则化全局扩散过程并强化了结构意识。", "conclusion": "在标准共语运动基准上的广泛评估显示，GlobalDiff生成了流畅且准确的运动，与当前SOTA相比，在多个说话者身份上性能提高了46.0%。"}
{"llm_update_time": "20251116", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2511.10091", "html_url": "https://arxiv.org/abs/2511.10091", "title": "SUGAR: 学习视觉-动力学知识的骨架表示", "title_en": "SUGAR: Learning Skeleton Representation with Visual-Motion Knowledge for Action Recognition", "authors": "Qilang Ye,Yu Zhou,Lian He,Jie Zhang,Xuanming Guo,Jiayu Zhang,Mingkui Tan,Weicheng Xie,Yue Sun,Tao Tan,Xiaochen Yuan,Ghada Khoriba,Zitong Yu", "background": "大规模语言模型（LLMs）蕴含丰富的隐含知识和强大的迁移能力。本文探讨了将LLMs与人体骨架相结合，用于动作分类与描述。然而，当将LLMs用作识别器时，会遇到两个问题：1）如何使LLMs理解骨架？2）如何使LLMs区分不同动作？", "innovation": "本文提出了一种名为学习视觉-动力学知识的动作识别（SUGAR）的新范式。首先，利用现成的大规模视频模型作为知识库生成相关动作的视觉和动力学信息。然后，通过这种先验知识监督骨架学习，生成离散表示。最后，使用未初始化预训练权重的LLMs来理解和生成所需的动作目标和描述。此外，还提出了一种时间查询投影（TQP）模块，以连续建模长序列中的骨架信号。", "conclusion": "在几种基于骨架的动作分类基准上的实验表明，SUGAR的有效性。在零样本场景下的实验还表明，SUGAR比基于线性的方法更具通用性。"}
{"llm_update_time": "20251116", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2511.10081", "html_url": "https://arxiv.org/abs/2511.10081", "title": "GridPrune: 从“看哪里”到“选什么”在MLLM中对视觉词元剪枝的新策略", "title_en": "GridPrune: From \"Where to Look\" to \"What to Select\" in Visual Token Pruning for MLLMs", "authors": "Yuxiang Duan,Ao Li,Yingqin Li,Luyu Li,Pengwei Wang", "background": "多模态大语言模型（MLLMs）在一系列视觉-语言任务中展现了显著的能力，但大量的视觉词元带来了显著的计算负担。现有剪枝方法主要集中于直接优化“选什么”，通常使用注意力分数或相似性度量，而忽略了“看哪里”，这导致了空间分配效率低下、位置偏见以及保留了不相关或冗余的词元。", "innovation": "提出了GridPrune方法，通过将剪枝过程分为两步来解决上述问题：首先，使用文本条件指导动态分配空间区域的词元预算；然后，在每个预算区域内部进行局部选择。GridPrune在视觉词元剪枝中引入了“全球引导，局部选择”的区域选择系统，显著提高了MLLM的效率。实验结果表明，GridPrune在多种MLLM架构中表现优异，特别是在LLaVA-NeXT-7B上的表现尤为突出，通过保留96.98%的性能同时仅使用11.1%的词元，比最佳基线提高了2.34%。", "conclusion": "GridPrune方法通过结合全局引导和局部选择，提高了视觉词元剪枝的效率，显著减少了不必要的计算负载，同时保持了模型性能。"}
{"llm_update_time": "20251116", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2511.10107", "html_url": "https://arxiv.org/abs/2511.10107", "title": "RobIA: 基于稳健实例感知的连续测试时自适应方法在深度立体视觉中的应用", "title_en": "RobIA: Robust Instance-aware Continual Test-time Adaptation for Deep Stereo", "authors": "Jueun Ko,Hyewon Park,Hyesong Choi,Dongbo Min", "background": "在现实环境中进行立体深度估计面临重大挑战，包括动态领域漂移、稀疏或不可靠的监督以及获取密集地面真实标签的高成本。尽管最近的测试时自适应（TTA）方法提供了有希望的解决方案，但大多数方法都依赖于静态目标领域假设和输入不变的自适应策略，这在连续变化的场景下限制了其有效性。", "innovation": "本文提出了一种名为RobIA的新颖鲁棒实例感知连续测试时自适应框架（CTTA），用于立体深度估计。RobIA融合了两项关键组件：（1） Attend-and-Excite Mixture-of-Experts (AttEx-MoE) 功能模块，通过轻量级针对共轭几何定制的自注意力机制动态地将输入路由到冻结专家，从而实现参数效率；（2）鲁棒AdaptBN教师模型，通过补充稀疏的手工标签来提供密集伪监督。这种方法通过输入特定的灵活性和广泛的监督覆盖来提升在领域漂移下的泛化能力。", "conclusion": "广泛实验表明，RobIA能够实现动态目标领域下的卓越自适应性能，同时保持计算效率。"}
{"llm_update_time": "20251116", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2511.10060", "html_url": "https://arxiv.org/abs/2511.10060", "title": "医学动作评估中的多元高斯表示学习", "title_en": "Multivariate Gaussian Representation Learning for Medical Action Evaluation", "authors": "Luming Yang,Haoxian Liu,Siqing Li,Alper Yilmaz", "background": "医学视觉领域中精细动作评估面临着独特的挑战，包括缺乏全面的数据集、严格的精度要求以及对极其快速动作的不足的时空动态建模。为了支持开发和评估，我们引入了CPREval-6k，这是一个包含6,372个由专家标注的视频、具有22个临床标签的多视角、多标签医学动作基准数据集。利用这个数据集，我们提出了GaussMedAct，一种多元高斯编码框架，通过自适应时空表示学习来推进医学运动分析。GaussMedAct通过将关节动作投影到时间尺度多维空间中，并将动作分解为适应性的三维高斯分布，从而起到动作令牌的作用。这些令牌能够通过各向异性协方差建模来保护运动语义，同时保持对时空噪音的鲁棒性。同时，我们采用了一种混合空间编码策略，该策略结合了直角坐标和向量流两种方法，有效地利用了骨骼信息，包括关节和骨骼特征。", "innovation": "我们提出了GaussMedAct，一种多元高斯编码框架，它通过将关节动作投影到时间尺度多维空间，并将动作分解为适应性的三维高斯分布，来实现医学动作的自适应时空表示学习。同时，我们采用了混合空间编码策略，结合了直角坐标和向量流的双流策略，有效利用了骨骼信息。实验表明，该方法在基准测试中的Top-1准确率为92.1%，在实时推理性能上优于ST-GCN基线5.9%，同时只使用了10%的FLOPs。此外，跨数据集实验结果还证明了我们方法的优越性及其在鲁棒性方面的影响。", "conclusion": "GaussMedAct通过多元高斯编码框架在医学动作评估中取得了显著的性能提升，并且在时空动态建模、医学动作分析以及鲁棒性方面表现出色，为该领域提供了新的研究方向和思路。"}
{"llm_update_time": "20251116", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2511.10098", "html_url": "https://arxiv.org/abs/2511.10098", "title": "MTAttack: 多目标后门攻击对抗大视觉语言模型", "title_en": "MTAttack: Multi-Target Backdoor Attacks against Large Vision-Language Models", "authors": "Zihan Wang,Guansong Pang,Wenjun Miao,Jin Zheng,Xiao Bai", "background": "近年来，大规模视觉语言模型（LVLMs）通过大规模图像文本预训练和指令调优，在各种视觉语言任务中展现了令人印象深刻的性能。然而，这些模型的安全漏洞越来越引起关注，特别是它们容易遭受后门攻击。现有的后门攻击主要集中在针对单一目标的攻击上，即针对特定触发器的单一恶意输出。本文发现了多目标后门攻击，即在单次训练过程中添加多个独立的触发器，每个触发器对应不同的攻击目标，这给实际应用中的LVLMs带来了更大的威胁。由于不同触发器之间的特征相互干扰可能导致许多不正确的触发器-目标映射，这使得在LVLMs中执行此类攻击具有挑战性。", "innovation": "本文提出了MTAttack，这是一种创新的多目标后门攻击框架，为LVLMs强制执行精准的多个触发器-目标映射。MTAttack的核心是一种新颖的优化方法，该方法包含两种约束：代理空间分区约束和触发器原型锚定约束。该方法在潜在空间中联合优化多个触发器，每个触发器独立将清洁图像映射到唯一的代理类别，同时确保各触发器之间的可分性。实验结果表明，MTAttack在多目标攻击中的成功率远高于现有攻击方法，并且具有较强的跨数据集泛化能力和对后门防御策略的鲁棒性。这些发现强调了LVLMs对抗多目标后门攻击的脆弱性，突显了缓解此类威胁的急迫需要。", "conclusion": "这些研究表明，LVLMs在多目标后门攻击面前存在巨大的漏洞，强调了缓解此类威胁的迫切需要。"}
{"llm_update_time": "20251116", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2511.10134", "html_url": "https://arxiv.org/abs/2511.10134", "title": "通过情境感知跨模态交互进行明确的时间语义建模以实现密集视频字幕生成", "title_en": "Explicit Temporal-Semantic Modeling for Dense Video Captioning via Context-Aware Cross-Modal Interaction", "authors": "Mingda Jia,Weiliang Meng,Zenghuang Fu,Yiheng Li,Qi Zeng,Yifan Zhang,Ju Xin,Rongtao Xu,Jiguang Zhang,Xiaopeng Zhang", "background": "近期的研究主要集中在利用额外的先验知识和先进的多任务架构来提高性能，但这些方法依赖于帧级或片段视频特征的隐式建模，未能捕捉事件序列中的时序一致性以及视觉上下文中的全面语义。", "innovation": "提出了一个名为Context-Aware Cross-Modal Interaction (CACMI)的明确的时间语义建模框架，该框架结合了视频中的潜在时序特征和文本语料库中的语言语义。模型包括两个核心组件：跨模态帧聚合和情境感知特征增强。前者通过跨模态检索聚合相关帧以提取时序一致、事件对齐的文本特征，后者利用查询引导注意力将视觉动态与伪事件语义整合起来。", "conclusion": "在ActivityNet Captions和YouCook2数据集上的广泛实验表明，CACMI在密集视频字幕生成任务中达到了最先进的性能。"}
{"llm_update_time": "20251116", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2511.10136", "html_url": "https://arxiv.org/abs/2511.10136", "title": "外观正确，原因错误：文本到图像生成中的组合忠实度", "title_en": "Right Looks, Wrong Reasons: Compositional Fidelity in Text-to-Image Generation", "authors": "Mayank Vatsa,Aparna Bharati,Richa Singh", "background": "现有文本到图像模型的架构设计存在根本缺陷，即无法处理逻辑组合。本文通过对否定、计数和空间关系这三个核心原则进行调查，揭示了模型在处理这些原则的组合时出现的显著性能下降，并归因于多种因素。", "innovation": "研究揭示了模型性能下降的关键因素，包括训练数据中缺乏明确的否定表达、连续注意力架构不适合离散逻辑以及评估指标更倾向于视觉可行性而非规则满足度。研究提出，当前的解决方案和简单的扩展无法解决这一根本问题，未来需要在表示和推理方面实现根本性的进展，而不仅仅是对现有架构的微调。", "conclusion": "真正实现组合性将需要在表示和推理方面取得根本性进展，而非对现有架构进行逐步调整。"}
{"llm_update_time": "20251116", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2511.10150", "html_url": "https://arxiv.org/abs/2511.10150", "title": "解耦偏见，对齐分布：深度虚假信息检测中的协同公平优化", "title_en": "Decoupling Bias, Aligning Distributions: Synergistic Fairness Optimization for Deepfake Detection", "authors": "Feng Ding,Wenhui Yi,Yunpeng Zhou,Xinan He,Hong Rao,Shu Hu", "background": "公平性是可靠部署深度伪造检测模型的核心要素，尤其是在数字身份安全领域。检测模型对不同人口群体的偏见（如性别和种族）可能导致系统性误判，加剧数字鸿沟和社会不平等。然而，当前的公平性增强检测器通常以牺牲检测准确性为代价来改善公平性。", "innovation": "我们提出了一种双机制协同优化框架。该方法创新性地结合了结构公平分解和全局分布对齐：在模型架构级别解耦对人口群体敏感的通道，在特征级别减少总体样本分布与每个人口群体分布之间的距离。", "conclusion": "实验结果表明，与现有方法相比，我们的框架在保持整体检测准确性的同时，提高了组间和组内的公平性。"}
{"llm_update_time": "20251116", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2511.10142", "html_url": "https://arxiv.org/abs/2511.10142", "title": "Split-Layer：通过最大化特征空间维度增强隐式神经表示", "title_en": "Split-Layer: Enhancing Implicit Neural Representation by Maximizing the Dimensionality of Feature Space", "authors": "Zhicheng Cai,Hao Zhu,Linsen Chen,Qiu Shen,Xun Cao", "background": "隐式神经表示（INR）模型利用神经网络表示连续函数，有效地解决了各种学科中的逆问题的优化，但是其表示能力受限于传统多层感知器（MLP）架构的低维特征空间。增加MLP的宽度可以线性扩展特征空间维度，但也会导致计算和内存成本的平方增长，这成为了实现高维度特征空间的主要限制。本文分析了INR模型表示能力受限的问题，并介绍了新的split-layer设计来解决这个问题，进而提升了INR模型的表示能力。", "innovation": "本文提出了一种新的split-layer设计，通过将每个层拆分为多个并行分支，并结合Hadamard乘积的方法，构建了一个高阶多项式空间。这种设计在不增加过多计算开销的情况下，显著增强了INR模型的表示能力，使得在多种任务，如2D图像拟合、2D CT重建、3D形状表示和5D新视角合成中，INR模型的性能显著提高，超越了现有的方法。", "conclusion": "实验结果表明，使用split-layer设计的INR模型在多个任务中表现出显著的性能提升。"}
{"llm_update_time": "20251116", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2511.10154", "html_url": "https://arxiv.org/abs/2511.10154", "title": "GEA: 从生成视角增强的跨模态对齐技术用于文本到图像的人像检索", "title_en": "GEA: Generation-Enhanced Alignment for Text-to-Image Person Retrieval", "authors": "Hao Zou,Runqing Zhang,Xue Zhou,Jianxiao Zou", "background": "文本到图像的人像检索（TIPR）旨在根据自然语言描述检索图像。尽管许多TIPR方法已经取得了令人鼓舞的结果，但文本查询有时无法准确且全面地反映图像内容，导致跨模态对齐效果不佳且过度拟合到有限的数据集。此外，文本与图像固有的模态差距进一步加剧了这些问题，使得准确的跨模态检索更加困难。", "innovation": "本文从生成的角度提出了一种增强对齐的技术（GEA）。GEA 包含两个并行模块：（1）文本引导的标记增强（TGTE），它引入了通过扩散生成的图像作为文本和视觉模式之间的中间语义表示。这些生成的图像丰富了文本的语义表示并促进了跨模态对齐。（2）生成中间融合（GIF），它通过生成图像、原始图像和文本特征之间的交叉注意来生成经过三元对齐损失优化的统一表示。", "conclusion": "我们在三个公有 TIPR 数据集 CUHK-PEDES、RSTPReid 和 ICFG-PEDES 上进行了广泛的实验，以评估 GEA 的性能。结果证明了我们方法的有效性。更多实现细节和扩展结果请访问此链接this https URL."}
{"llm_update_time": "20251116", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2511.10166", "html_url": "https://arxiv.org/abs/2511.10166", "title": "通过深度展开网络和可解释卷积实现物理可解释的多退化图像恢复", "title_en": "Physically Interpretable Multi-Degradation Image Restoration via Deep Unfolding and Explainable Convolution", "authors": "Hu Gao,Xiaoning Lei,Xichen Xu,Depeng Dang,Lizhuang Ma", "background": "尽管图像恢复技术取得了显著进步，但大多数现有方法仅针对单一类型的退化。在现实场景中，图像通常同时存在多种退化，如雨、噪声和雾，需要能够处理多种退化类型的模型。此外，通过模块堆叠提升性能的方法往往缺乏解释性。该文背景介绍了这些挑战以及现有方法的不足之处，强调了多退化图像恢复模型的必要性和复杂性。", "innovation": "该文提出了一种基于深度展开网络的新型物理可解释多退化图像恢复方法，该网络将数学优化算法的迭代过程映射为可学习的网络结构。具体来说，使用改进的第二阶半光滑牛顿算法确保每个模块具有明确的物理解释性，并设计了解释性卷积模块，该模块借鉴了人脑灵活的信息处理方式和图像的固有特性，使网络能够灵活地利用所学知识并自主调整参数以适应不同的输入。这种紧密集成的架构在多退化恢复中表现出色，同时在单一退化任务上也具有竞争力.", "conclusion": "所提出的方法InterIR在多退化恢复中表现出优异性能，并且在单一退化任务中也具有高度竞争力，同时该方法具有优秀的解释性，并能够灵活适应不同输入。"}
{"llm_update_time": "20251116", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2511.10177", "html_url": "https://arxiv.org/abs/2511.10177", "title": "利用地理空间基础模型在小型沙岛海岸线划分中的应用", "title_en": "Utilizing a Geospatial Foundation Model for Coastline Delineation in Small Sandy Islands", "authors": "Tishya Chhabra,Manisha Bajpai,Walter Zesk,Skylar Tibbits", "background": "本文介绍了NASA和IBM的Prithvi-EO-2.0地理空间基础模型在利用卫星图像进行小型沙岛海岸线划分的初步评估。研究团队收集并标注了来自两个马尔代夫岛屿的225张多光谱图像，公开发布这些数据，并对Prithvi的不同参数版本进行了微调。", "innovation": "研究采用了一个新的地理空间基础模型Prithvi-EO-2.0，并对其进行了微调，展示了即使使用5张图像作为训练集，模型也能达到高精度（F1为0.94，IoU为0.79）。这证明了Prithvi模型在数据贫乏地区海岸线监测方面的强大迁移学习能力。", "conclusion": "研究结果表明，Prithvi模型具有很强的迁移学习能力，能够在几乎没有数据的情况下支持沿海地区的监测工作，强调了这种模型的潜力和重要性。"}
{"llm_update_time": "20251116", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2511.10212", "html_url": "https://arxiv.org/abs/2511.10212", "title": "多模态深度伪造检测和时间局部化中的下一帧特征预测", "title_en": "Next-Frame Feature Prediction for Multimodal Deepfake Detection and Temporal Localization", "authors": "Ashutosh Anshul,Shreyas Gopal,Deepu Rajan,Eng Siong Chng", "background": "近期的多模态深度伪造检测方法提出了单阶段监督训练难以在未见过的操作和数据集上泛化的假设。现有方法大多集中在检测音视频不一致性上，而未能有效处理保音视频对齐的其他形式的伪造。这些问题限制了模型的性能和泛化能力。", "innovation": "本文提出了一个单阶段训练框架，通过结合单一模态和跨模态的下一帧预测特征，来提升泛化能力。同时引入了窗口级注意力机制，用于捕捉预测帧与实际帧之间的差异，使得模型能够准确检测每一帧周围的局部伪影，这对于全伪造视频的分类和部分伪造样本中的欺诈片段的有效定位至关重要。", "conclusion": "所提出的方法在多个基准数据集上进行了测试，表现出了强大的泛化能力和精确的时间局部化能力。"}
{"llm_update_time": "20251116", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2511.10173", "html_url": "https://arxiv.org/abs/2511.10173", "title": "CephRes-MHNet: 一个用于精确和稳健的颅面 landmark 检测的多头残差网络", "title_en": "CephRes-MHNet: A Multi-Head Residual Network for Accurate and Robust Cephalometric Landmark Detection", "authors": "Ahmed Jaheen,Islam Hassan,Mohanad Abouserie,Abdelaty Rehab,Adham Elasfar,Knzy Elmasry,Mostafa El-Dawlatly,Seif Eldawlatly", "background": "在正畸诊断和治疗中，2D 横向头颅X光片上的颅面 landmark 位置准确标注至关重要。手动标注耗时且容易出错，而自动化方法在低对比度和解剖复杂性的环境中常常表现不佳。该文旨在解决这一问题，提出了一种基于多头残差卷积网络的 CephRes-MHNet 模型，用于提高颅面 landmark 的检测精度和鲁棒性。", "innovation": "CephRes-MHNet 将残差编码、双重注意机制和多头解码器结合在一起，增强了上下文理解和解剖精确度。该模型在 Aariz Cephalometric 数据集上训练，取得了均方根误差（MRE）为 1.23 毫米和 2.0 毫米成功检测率（SDR）为 85.5% 的优异结果，优于所有评估模型。特别地，CephRes-MHNet 的参数数量不到 strongest baseline AFPF-Net 的 25%，但性能更优。这表明 CephRes-MHNet 通过架构的高效性达到了最先进的精度，适用于实际临床应用。", "conclusion": "CephRes-MHNet 通过其结构的高效性在颅面 landmark 检测中达到了最先进的精度，提供了一种解决实际正畸分析问题的实用方案。"}
{"llm_update_time": "20251116", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2511.10209", "html_url": "https://arxiv.org/abs/2511.10209", "title": "LiNeXt：重新审视高效非扩散架构下的LiDAR完成", "title_en": "LiNeXt: Revisiting LiDAR Completion with Efficient Non-Diffusion Architectures", "authors": "Wenzhe He,Xiaojun Chen,Ruiqi Wang,Ruihui Li,Huilong Pi,Jiapeng Zhang,Zhuo Tang,Kenli Li", "background": "3D LiDAR场景重建是自主车辆感知系统中的基本组件。以往的方法主要使用扩散模型进行高保真重建，但其多步骤迭代抽样会导致大量的计算开销，限制了实时应用。", "innovation": "我们提出了LiNeXt——一种轻量级、非扩散网络，旨在实现快速而准确的点云完成。具体而言，LiNeXt首先应用Noise-to-Coarse (N2C) 模块一次性去除输入噪声点云中的噪声，从而避免了扩散基方法的多步骤迭代采样。然后，Refine模块利用N2C模块生成的原始点云和中间特征来执行更精确的细化，进一步增强结构完整性。此外，我们还提出了一种距离感知的重复策略，生成更均匀分布的噪声点云。", "conclusion": "在SemanticKITTI数据集上，LiNeXt实现了199.8倍的推理速度提升，减少了50.7%的均方根误差(Chamfer Distance)，并且仅使用LiDiff参数的6.1%，这表明LiNeXt在实时场景完成方面具有更高的效率和效果。"}
{"llm_update_time": "20251116", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2511.10203", "html_url": "https://arxiv.org/abs/2511.10203", "title": "VISTA: 一种基于视觉和意图的社交注意力框架，用于多智能体轨迹预测", "title_en": "VISTA: A Vision and Intent-Aware Social Attention Framework for Multi-Agent Trajectory Prediction", "authors": "Stephane Da Silva Martins,Emanuel Aldea,Sylvie Le Hégarat-Mascle", "background": "在密集且交互性高的环境中，自主系统的运作依赖于准确的多智能体轨迹预测。现有方法往往无法同时捕捉智能体的长期目标及其细粒度的社会互动，导致预测的多智能体未来显得不切实际。", "innovation": "我们提出了VISTA（愿景和意图感知的社交注意力框架），这是一种递归的目标条件变换器，用于多智能体轨迹预测。VISTA结合了（i）一种用于将长远意图与过去运动集成的交叉注意力融合模块；（ii）一种灵活的社交标记注意力机制，用于跨智能体进行社会互动建模；（iii）两两注意图，使社会影响模式在推理时具有可解释性。我们的模型将单智能体的目标条件预测转变为一个一致的多智能体预测框架。除了标准的位移度量外，我们还使用轨迹碰撞率来衡量联合的真实性。", "conclusion": "在高密度MADRAS基准和SDD上，VISTA实现了最先进的准确性和显著减少的碰撞数。在MADRAS上，它将强基准的平均碰撞率从2.14%降低到0.03%，在SDD上实现了零碰撞，同时提高了ADE、FDE和minFDE。这些结果表明，VISTA生成了社会合规、目标意识且可解释的轨迹，使其非常适合安全关键的自主系统。"}
{"llm_update_time": "20251116", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2511.10211", "html_url": "https://arxiv.org/abs/2511.10211", "title": "HeatV2X: 通过高效对齐和交互实现可扩展的异构协作感知", "title_en": "HeatV2X: Scalable Heterogeneous Collaborative Perception via Efficient Alignment and Interaction", "authors": "Yueran Zhao,Zhang Zhang,Chao Sun,Tianze Wang,Chao Yue,Nuoran Li", "background": "车辆到一切（V2X）协作感知通过传输超越单一车辆限制来扩展感知范围。然而，随着参与的代理数量的增加，现有框架面临两大挑战：(1) 参与的代理天生是多模态和异构的，(2) 协作框架必须具备可扩展性以适应新的代理。前者的有效跨代理特征对齐是必要的，以减轻异构性损失；后者的出现则使得全参数训练变得不切实际，强调了可扩展适应的重要性。", "innovation": "我们提出了 HeatV2X，这是一种可扩展的协作框架。首先基于异构图注意力训练高性能代理，作为协作学习的基础。然后，我们设计了局部异构微调和全局协作微调，以实现异构代理间有效的对齐和交互。前者通过异构感知适配器高效提取模态特定差异，而后者使用多认知适配器来增强跨代理协作并充分利用融合潜力。这些设计使得协作框架的性能提升具备了最小的训练成本。", "conclusion": "我们在 OPV2V-H 和 DAIR-V2X 数据集上评估了我们的方法。实验结果表明，我们的方法在显著减少训练开销的情况下取得了优越的感知性能，并优于现有最先进的方法。我们的实现将在不久后发布。"}
{"llm_update_time": "20251116", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2511.10250", "html_url": "https://arxiv.org/abs/2511.10250", "title": "FineSkiing：滑雪动作质量评估的精细化基准", "title_en": "FineSkiing: A Fine-grained Benchmark for Skiing Action Quality Assessment", "authors": "Yongji Zhang,Siqi Li,Yue Gao,Yu Jiang", "background": "动作质量评估（AQA）旨在评价和打分体育动作，近年来引发了广泛关注。现有AQA方法主要基于视频整体特征进行预测，缺乏解释性和可靠性。同时，现有数据集也缺乏对动作分数的精细级注释，特别是在扣分项和子分数注释方面存在不足。", "innovation": "本文构建了首个包含滑雪动作精细级子分数和扣分注释的AQA数据集，提出了名为JudgeMind的新颖AQA方法，通过模拟专业评审的评判和打分思维，显著提高了性能和可靠性。该方法将输入的动作视频划分为不同阶段并为每个阶段打分，增强了准确性。进一步提出了阶段感知特征增强和融合模块，以提升对特定阶段关键区域的感知，并增强对由于频繁摄像头视角切换导致的视觉变化的鲁棒性。此外，提出了基于知识的分数感知解码器以纳入可能的扣分项作为先验知识，从而预测更为准确和可靠的得分。", "conclusion": "实验结果表明，本文的方法达到当前最佳性能。"}
{"llm_update_time": "20251116", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2511.10241", "html_url": "https://arxiv.org/abs/2511.10241", "title": "TubeRMC：基于时空约束的管状条件重建及其互斥约束方法用于弱监督时空视频定位", "title_en": "TubeRMC: Tube-conditioned Reconstruction with Mutual Constraints for Weakly-supervised Spatio-Temporal Video Grounding", "authors": "Jinxuan Li,Yi Zhang,Jian-Fang Hu,Chaolei Tan,Tianming Liang,Beihao Xia", "background": "Spatio-Temporal Video Grounding (STVG)的目标是在未剪裁的视频帧中找到与给定语言查询相对应的时空管。这是一个艰巨的任务，因为它需要复杂的视觉-语言理解以及时空推理。最近的研究探索了STVG中的弱监督设置，以减少对精细注释（如边界框或时间戳）的依赖。然而，大多数方法采用简单后期融合的方式，这导致了目标识别失败以及不一致的目标跟踪。", "innovation": "提出了一种名为Tube-conditioned Reconstruction with Mutual Constraints (TubeRMC)的框架。该框架利用预训练的视觉定位模型生成符合文本条件的候选管，并通过时空约束的管状条件重建进一步精炼这些候选管。具体来说，设计了从时间、空间和时空三个视角出发的重建策略，以全面捕捉丰富的管-文本对应关系。引入了空间和时间提议之间的互斥约束，以提高它们的重建质量。TubeRMC在两个公开基准VidSTG和HCSTVG上优于现有方法。", "conclusion": " TubeRMC方法通过时空约束的管状条件重建和空间时间提议之间的互斥约束有效地解决了目标识别错误和不一致跟踪问题。"}
{"llm_update_time": "20251116", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2511.10254", "html_url": "https://arxiv.org/abs/2511.10254", "title": "Facial-R1：面部情感分析中推理与识别的对齐", "title_en": "Facial-R1: Aligning Reasoning and Recognition for Facial Emotion Analysis", "authors": "Jiulong Wu,Yucheng Shen,Lingyong Yan,Haixin Sun,Deguo Xia,Jizhou Huang,Min Cao", "background": "传统的面部情感识别方法仅仅局限于情感识别，而面部情感分析（FEA）在此基础上加入了可解释、细粒度的推理能力。当前的研究主要采用视觉语言模型(VLMs)，虽然取得了显著的成果，但主要存在两个限制：一是幻觉推理，即VLMs生成虽然看起来合理但实际上是不准确的解释；二是情感推理与识别之间的错位，由于面部特征与最终标签之间存在断层连接。", "innovation": "该研究提出了Facial-R1，一个三阶段对齐框架，有效地解决了上述两个挑战，同时仅需少量监督。首先通过指令微调建立基本的情感推理能力；其次引入由情感和面部动作单元（AU）标签引导的强化训练，该过程将生成的推理过程与预测的情感明确对齐；最后设计了一个数据合成管道，利用先前阶段的信息迭代扩展训练数据集，以使模型的自我改进更具扩展性。在此基础上，该研究还引入了包含17,737个训练样本和1,688个测试样本的FEA-20K基准数据集，具备细致的情感分析标注。", "conclusion": "广泛的实验表明，Facial-R1在面部情感分析中表现出最先进的性能，具有强大的泛化能力和稳健的解释性。"}
{"llm_update_time": "20251116", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2511.10260", "html_url": "https://arxiv.org/abs/2511.10260", "title": "H3Former: 基于超图的语义感知聚合通过双曲层次对比损失进行细粒度视觉分类", "title_en": "H3Former: Hypergraph-based Semantic-Aware Aggregation via Hyperbolic Hierarchical Contrastive Loss for Fine-Grained Visual Classification", "authors": "Yongji Zhang,Siqi Li,Kuiyang Huang,Yue Gao,Yu Jiang", "background": "细粒度视觉分类（FGVC）因其类间细微差异和类内显著变化而具有挑战性。现有方法通常依赖于特征选择机制或区域建议策略来定位用于语义分析的显著区域，但这些方法往往无法全面捕捉判别性线索，同时引入了大量与类别无关的冗余信息。", "innovation": "我们提出了一种新颖的 token-to-region 框架 H3Former，该框架利用高阶语义关系，通过结构化的区域级别建模汇合局部的细粒度表征。具体来说，我们提出了语义感知聚合模块（SAAM），它利用多尺度上下文线索动态构建令牌之间的加权超图。通过超图卷积，SAAM 捕捉高阶语义依赖关系，并逐步将令牌特征汇合为紧凑的区域级别表示。此外，我们引入了超曲面层次对比损失（HHCL），它强制在非欧几里得嵌入空间中实现层次化语义约束。HHCL 提高了类间的可区分性和类内的一致性，同时保留了细粒度类别之间的固有层次关系。", "conclusion": "在四个标准 FGVC 验证基准上的全面实验验证了我们提出的 H3Former 框架的优势。"}
{"llm_update_time": "20251116", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2511.10300", "html_url": "https://arxiv.org/abs/2511.10300", "title": "基于Mixture-of-Experts的卫星图像泛化贫民窟检测", "title_en": "Generalizable Slum Detection from Satellite Imagery with Mixture-of-Experts", "authors": "Sumin Lee,Sungwon Park,Jeasurk Yang,Jihee Kim,Meeyoung Cha", "background": "基于卫星的贫民窟分割有显著潜力生成全球范围内的城市贫困估计。然而，非正规聚居区的形态异质性构成了一个重大挑战，阻碍了在特定地区训练的模型有效泛化到未知的地理位置。", "innovation": "本文介绍了大规模高分辨率数据集并提出了GRAM（广义区域感知混合专家模型），这是一种双阶段测试时自适应框架，允许在无需目标区域标注数据的情况下实现稳健的贫民窟分割。利用来自四大洲12个城市的数据集进行源训练，该模型采用混合专家架构捕捉地区特定的贫民窟特征，同时通过共享主干学习通用特征。适应阶段中，专家之间的一致性预测过滤掉不可靠的伪标签，使模型能够有效地泛化到之前未见过的地区。", "conclusion": "GRAM在非洲城市等资源受限环境中优于最先进的基线模型，提供了一种可扩展且标签高效的全球贫民窟制图和数据驱动的城市规划解决方案。"}
{"llm_update_time": "20251116", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2511.10301", "html_url": "https://arxiv.org/abs/2511.10301", "title": "重思多模态LLMs中的视觉信息处理", "title_en": "Rethinking Visual Information Processing in Multimodal LLMs", "authors": "Dongwan Kim,Viresh Ranjan,Takashi Nagata,Arnab Dhua,Amit Kumar K C", "background": "尽管LLaVA架构在视觉-语言任务上取得了显著的成功，但其设计本质上难以有效地整合视觉特征，由于文本和视觉模态之间固有的不匹配。本文从一个新的角度探讨这个问题，即LLM不仅仅是一个语言模型，而且还可以作为强大的视觉编码器。", "innovation": "本文提出了一种名为LLaViT的方法，即大型语言模型作为扩展的视觉变换器。LLaViT通过三种关键修改使LLM能够同时作为视觉编码器发挥作用：（1）为视觉模态学习独立的QKV投影；（2）使视觉标记能够进行双向注意；（3）结合全局和局部视觉表示。", "conclusion": "通过广泛的控制实验，本文证明LLaViT在多个基准测试上显著优于基线方法LLaVA，甚至超越了参数量为该模型两倍的模型，表明这种方法在视觉-语言建模中的更有效途径。"}
{"llm_update_time": "20251116", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2511.10292", "html_url": "https://arxiv.org/abs/2511.10292", "title": "低开销幻觉缓解的自适应残差更新导向", "title_en": "Adaptive Residual-Update Steering for Low-Overhead Hallucination Mitigation in Large Vision Language Models", "authors": "Zhengtao Zou,Ya Gao,Jiarui Guan,Bin Li,Pekka Marttinen", "background": "大视觉-语言模型（LVLMs）经常面临对象幻觉的问题，生成的文本与视觉输入不一致，这严重影响了其可靠性。现有的推理时干预措施面临着一个具有挑战性的权衡：虽然可以有效调整内部状态或输出对数的方法比较有效，但这些方法通常会带来显著的计算开销，通常需要额外的前向传递。这种效率瓶颈限制了它们在实时、低延迟部署中的实用性。", "innovation": "鲁德耳（RUDDER）框架提出了两项关键创新：1) 上下文激活残差方向（CARD）向量，这是一种从单次标准前向传递中来自注意力层残差更新的每个样本的视觉证据向量。2) 一个贝叶斯启发的自适应门，执行按标记注入，根据模型与视觉上下文的偏差施加重校正信号。", "conclusion": "广泛的实验表明，鲁德耳（RUDDER）在POPE和CHAIR等关键幻觉基准上的表现与最先进的方法相当，引入的计算延迟可以忽略不计，验证了鲁德耳（RUDDER）作为一种实用且有效的方法，能够提高LVLMs的可靠性，而不显著牺牲效率。"}
{"llm_update_time": "20251116", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2511.10308", "html_url": "https://arxiv.org/abs/2511.10308", "title": "重新评估用于行人检测的深度神经网络", "title_en": "Revisiting Evaluation of Deep Neural Networks for Pedestrian Detection", "authors": "Patrick Feifel,Benedikt Franke,Frank Bonarens,Frank Köster,Arne Raulf,Friedhelm Schwenker", "background": "可靠的行人检测是向自动化驾驶系统迈出的重要一步。然而，当前的性能基准存在不足。目前在验证数据集中应用的各类评估指标无法真实评估DNN的行人检测性能。图像分割可以提供关于街道场景的细粒度信息，作为评估行人检测器性能的一个起点，可以根据不同的错误类型自动区分错误。", "innovation": "本文提出了八种不同的行人检测错误分类，并且提出了新的性能比较指标，用于这些错误类别的比较。通过这些新的指标比较简化的版本自动行人检测（APD），展示了更细腻和稳健的模型评估方式，特别是在安全性方面。这种评估方法达到了CityPersons合理（无额外训练数据）的最佳性能（SOTA），并且使用的是较为简单的架构。", "conclusion": "通过新的评估指标，展示了更精细且稳健的模型比较方式，尤其是在安全性方面，并在CityPersons数据集上取得了SOTA的性能表现。"}
{"llm_update_time": "20251116", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2511.10279", "html_url": "https://arxiv.org/abs/2511.10279", "title": "PROPA: 通过强化学习向级过程优化在视觉推理方向", "title_en": "PROPA: Toward Process-level Optimization in Visual Reasoning via Reinforcement Learning", "authors": "Yanbei Jiang,Chao Lei,Yihao Ding,Krista Ehinger,Jey Han Lau", "background": "尽管视觉-语言模型（VLMs）在许多任务上取得了显著进展，但在复杂的视觉推理任务中仍然存在问题。这类任务往往有多步依赖关系，早期错误会通过推理链层层放大。现有的后训练方法，如监督微调（SFT）依赖于详细的步骤级注释，而如GRPO这样的可验证奖励的强化学习（RLVR）方法提供了稀疏的、结果级别的反馈，这限制了优化过程的稳定性。因此，需要新的方法来改善这一问题。", "innovation": "本文提出了一种名为PROPA的新框架，它结合了蒙特卡洛树搜索（MCTS）与GRPO来生成密集的过程级奖励，能够在无需人工注释的情况下优化每一步的推理过程。此外，还引入了过程奖励模型（PRM），以指导推理阶段的搜索，使得测试期间的搜索与训练信号对齐。该方法在多种基准和多个VLM模型上都优于现有的SFT和RLVR基线方法，特别是在领域内外的任务上的表现更是显著提升，从而确立了在视觉推理任务中的强大推理和泛化能力。", "conclusion": "PROPA不仅能提高视觉推理任务上的性能，还建立了一种强有力的推理和泛化能力。通过结合MCTS和GRPO的方法，以及过程奖励模型的引入，该方法在各个基准和VLM模型上提供了显著的进步，证明了其在处理复杂多步依赖关系的视觉推理任务上的有效性和优势。"}
{"llm_update_time": "20251116", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2511.10309", "html_url": "https://arxiv.org/abs/2511.10309", "title": "CLIP4VI-ReID: 通过CLIP语义桥梁学习跨模态表示以实现可见红外行人再识别", "title_en": "CLIP4VI-ReID: Learning Modality-shared Representations via CLIP Semantic Bridge for Visible-Infrared Person Re-identification", "authors": "Xiaomei Yang,Xizhan Gao,Sijie Niu,Fa Zhu,Guang Feng,Xiaofeng Qu,David Camacho", "background": "在可见光和红外图像的人再识别任务中，天然图像和红外图像在物理特性上有巨大的差距。现有方法难以有效学习跨模态共享的表示，尤其是在模态间的语义对齐方面存在挑战。", "innovation": "提出了一种基于CLIP的新型跨模态共享表示学习网络CLIP4VI-ReID，它包含Text Semantic Generation (TSG)、Infrared Feature Embedding (IFE)和High-level Semantic Alignment (HSA)三个模块。TSG生成可见图像的文本语义，实现初步的模态对齐。IFE使用生成的文本语义矫正红外图像的特征嵌入，将id相关的语义注入到共享的图像编码器中，增强其对红外模态的适应性。HSA进一步优化高层语义对齐，确保调整后的文本语义仅包含id相关信息，从而实现更准确的跨模态对齐。", "conclusion": "CLIP4VI-ReID在多个广泛应用的可见红外人再识别数据集上取得了优于其他最先进的方法的性能，显著提升了跨模态共享表示的学习效果和判别性。"}
{"llm_update_time": "20251116", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2511.10334", "html_url": "https://arxiv.org/abs/2511.10334", "title": "学习区分：通过解耦语义对齐进行弱监督视频异常检测", "title_en": "Learning to Tell Apart: Weakly Supervised Video Anomaly Detection via Disentangled Semantic Alignment", "authors": "Wenti Yin,Huaxin Zhang,Xiang Wang,Yuqing Lu,Yicheng Zhang,Bingquan Gong,Jialong Zuo,Li Yu,Changxin Gao,Nong Sang", "background": "近年来，基于多实例学习范式和多模态基础模型（如CLIP）的弱监督视频异常检测取得了显著的性能。然而，现有方法在检测最显著响应片段时可能忽略从异常中分离出多样的正常模式，且由于相似外观容易导致类别混淆，从而影响细粒度分类的结果。", "innovation": "我们提出了一种新的解耦语义对齐网络（DSANet），以明确分离粗粒度和细粒度的异常和正常特征，增强可区分性。通过自引导正常性建模分支，在粗粒度级别上，利用学习到的正常原型重建输入视频特征，从而更好地利用视频中固有的正常性线索，提高正常模式和异常事件的时间分离。在细粒度级别上，提出了拆分对比语义对齐机制，首先根据帧级异常评分将每个视频拆分为事件中心和背景中心组件，然后应用视觉-语言对比学习以增强类区分特征表示。", "conclusion": "在两个标准基准数据集（XD-Violence和UCF-Crime）上的全面实验表明，DSANet在细粒度分类效果上优于现有最先进的方法。"}
{"llm_update_time": "20251116", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2511.10316", "html_url": "https://arxiv.org/abs/2511.10316", "title": "通过物理景深建模和多视几何监督实现一致的3D高斯绘制", "title_en": "Depth-Consistent 3D Gaussian Splatting via Physical Defocus Modeling and Multi-View Geometric Supervision", "authors": "Yu Deng,Baozhu Zhao,Junyan Su,Xiaohan Zhang,Qi Liu", "background": "在具有极端深度变化的场景中进行三维重建仍然是一个挑战，因为近场和远场区域之间的监督信号不一致。现有的方法无法同时解决远处区域不准确的深度估计和近距离区域结构降解的问题。", "innovation": "该论文提出了一种新颖的计算框架，该框架结合了景深监督和多视几何监督，以改进3D Gaussian Splatting。框架包括两部分核心组件：1) 景深监督采用单目深度估计器（例如Metric3D）生成深度先验信息，利用失焦卷积合成物理上准确的失焦图像，并通过新颖的景深损失确保几何一致性，从而增强远场和近场区域的深度保真度；2) 多视几何监督使用LoFTR基于的半密集特征匹配来最小化跨视几何误差，并通过可靠的匹配点的最小二乘优化强制深度一致性。", "conclusion": "通过将失焦物理与多视几何约束统一，该方法实现了更高的深度保真度。在Waymo Open Dataset上的性能优于最先进的方法，表明PSNR提高了0.8 dB。该框架结合了物理成像原理和基于学习的深度正则化，为城市环境中的复杂深度分层提供了一个可扩展的解决方案。"}
{"llm_update_time": "20251116", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2511.10352", "html_url": "https://arxiv.org/abs/2511.10352", "title": "基于傅里叶变换的vM分布在物体检测中鲁棒单域泛化的 FOUND 方法", "title_en": "FOUND: Fourier-based von Mises Distribution for Robust Single Domain Generalization in Object Detection", "authors": "Mengzhu Wang,Changyuan Deng,Shanshan Wang,Nan Yin,Long Lan,Liang Yang", "background": "单域泛化（SDG）在物体检测中的目标是训练模型在单一来源域上进行有效推广，以适应未知目标域。现有方法，如基于CLIP的语义增强，虽然有所进展，但往往忽略了特征分布的内在结构和频域特征，这些特征对于鲁棒性至关重要。", "innovation": "本文提出了一种新颖的框架，通过将von Mises-Fisher（vMF）分布和傅里叶变换整合到CLIP引导的管道中来增强SDG物体检测。具体而言，该方法使用vMF建模物体表示的定向特征，以更好地捕捉嵌入空间中的领域不变语义结构。此外，引入了基于傅里叶变换的增强策略，调整幅度和相位分量以模拟频域中的域移位，进一步提高特征鲁棒性。该方法不仅保留了CLIP的语义对齐优势，还增强了跨域的特征多样性及结构一致性。", "conclusion": "在多样天气驾驶基准上的广泛实验表明，本文方法优于现有的最新方法。"}
{"llm_update_time": "20251116", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2511.10367", "html_url": "https://arxiv.org/abs/2511.10367", "title": "DermAI：通过质量驱动的图像收集进行AI分类的临床皮肤病学获取", "title_en": "DermAI: Clinical dermatology acquisition through quality-driven image collection for AI classification in mobile", "authors": "Thales Bezerra,Emanoel Thyago,Kelvin Cunha,Rodrigo Abreu,Fábio Papais,Francisco Mauro,Natália Lopes,Érico Medeiros,Jéssica Guido,Shirley Cruz,Paulo Borba,Tsang Ing Ren", "background": "人工智能在皮肤病学中的应用受限于偏差数据集、图像质量的差异以及有限的验证。皮肤科医生在常规咨询中需要能够实时捕获、标注和分类皮肤病变的应用工具，但现有工具多聚焦于皮肤镜检查，不能进行实时的质量检查和本地模型的自适应。", "innovation": "DermAI是一个轻量级的智能手机应用程序，能够在常规咨询中实时捕获、标注和分类皮肤病变。它能够进行设备上的质量检查和本地模型的自适应调整。DermAI的数据集涵盖了广泛的肤色、种族和拍摄设备。初步实验显示，基于公共数据集训练的模型在泛化至新样本时表现不佳，而使用当地数据进行微调则能提高性能。这让人们认识到标准化、多样化的数据收集对于满足医疗需求并促进机器学习发展的重要性。", "conclusion": "DermAI有效地解决了现有皮肤病学AI应用中的数据偏差和图像质量参差不齐的问题，通过实时的质量检查和本地模型适配，提高了模型的准确性和适用性，强调了标准化多样化的数据收集方法的重要性。"}
{"llm_update_time": "20251116", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2511.10376", "html_url": "https://arxiv.org/abs/2511.10376", "title": "MSGNav: 释放多模态3D场景图在零样本嵌入式导航中的潜力", "title_en": "MSGNav: Unleashing the Power of Multi-modal 3D Scene Graph for Zero-Shot Embodied Navigation", "authors": "Xun Huang,Shijia Zhao,Yunxiang Wang,Xin Lu,Wanfa Zhang,Rongsheng Qu,Weixin Li,Yunhong Wang,Chenglu Wen", "background": "嵌入式导航是机器代理的基本能力。实际部署需要广泛的开放词汇泛化和低训练开销，推动了零样本方法而不是特定任务的RL训练。然而，现有的零样本方法虽然构建了明确的3D场景图，但常将丰富的视觉观察压缩为纯文本关系，导致高构建成本、不可逆地丧失视觉证据以及受限的词汇表.", "innovation": "提出了一种多模态3D场景图(M3DSG)，通过用动态分配的图像替换文本关系保留视觉线索。基于M3DSG，提出了一种零样本导航系统MSGNav，包括关键子图选择模块（高效推理）、自适应词汇更新模块（支持开放词汇）和闭环推理模块（精确探索推理）。此外，还提出了一种基于可见性的视点决策模块，以明确解决零样本导航中的最后一英里问题——确定具有合适最终视角的目标位置。", "conclusion": "全面的实验结果表明，MSGNav在GOAT-Bench和HM3D-OVON数据集上达到了最先进的性能。开源代码将公开可用。"}
{"llm_update_time": "20251116", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2511.10370", "html_url": "https://arxiv.org/abs/2511.10370", "title": "SHRUG-FM: 地球观测中的可靠性感知基础模型", "title_en": "SHRUG-FM: Reliability-Aware Foundation Models for Earth Observation", "authors": "Kai-Hendrik Cohrs,Zuzanna Osika,Maria Gonzalez-Calabuig,Vishal Nedungadi,Ruben Cartuyvels,Steffen Knoblauch,Joppe Massant,Shruti Nath,Patrick Ebel,Vasileios Sitokonstantinou", "background": "地球观测中的地理空间基础模型在未在预训练中充分代表的环境中通常表现不可靠。本文研究了解决这一问题的方法，提出了一种名为SHRUG-FM的框架，旨在提高在特定环境下的预测可靠性.", "innovation": "SHRUG-FM框架结合了输入空间的异常检测、嵌入空间的异常检测和特定任务的预测不确定性，应用于烧伤疤痕分割实验，展示了异常评分与特定环境条件下的低性能相关，而基于不确定性标记有助于剔除许多性能较差的预测。通过将这些标记与HydroATLAS的土地覆盖属性相关联，作者发现错误不是随机的，而是集中在低海拔区和大河区域等地理区域，这很可能是由于预训练数据中的代表性不足造成的。因此，SHRUG-FM提供了一种在气候敏感应用中更加安全且可解释地部署地理空间基础模型的路径，有助于弥合基准性能与现实可靠性之间的差距.", "conclusion": "SHRUG-FM为在地球观测中更安全和可解释地部署地理空间基础模型提供了途径，有助于解决预训练数据不足导致的特定地理环境下模型性能下降问题，并提出了可靠的评估方法来提高实际应用中的可靠性."}
{"llm_update_time": "20251116", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2511.10387", "html_url": "https://arxiv.org/abs/2511.10387", "title": "基于PROSAIL模型的Sentinel-2影像生物物理参数估计的物理约束Transformer-VAE方法", "title_en": "Physics informed Transformer-VAE for biophysical parameter estimation: PROSAIL model inversion in Sentinel-2 imagery", "authors": "Prince Mensah,Pelumi Victor Aderinto,Ibrahim Salihu Yusuf,Arnu Pretorius", "background": "准确从卫星影像中检索植被生物物理参数对于生态系统监测和农业管理至关重要。传统的混合方法需要使用真实的卫星图像进行半监督训练，模型效果受限。本文研究提出了一个将物理模型与Transformer-VAE相结合的方法，用于从Sentinel-2数据反演PROSAIL辐射传输模型，无需使用真实的卫星图像进行模型训练，展示了一种低成本且无需现场标签的全球植被监测解决方案。", "innovation": "提出的模型结合了物理模型PROSAIL和Transformer-VAE架构，通过Diffabled物理解码器保证估算的潜变量对应于物理上合理的大气和冠层参数。与之前依赖真实卫星图像进行半监督训练的方法不同，该模型仅在模拟数据上进行训练，仍能达到与使用真实影像训练的最新方法相当的性能。该方法无需现场标签或校准真实图像，提供了一种低成本的自我监督解决方案，用于全球植被监测。", "conclusion": "该研究证明了将物理模型与先进的深度神经网络结合使用可以改善辐射传输模型的反演，开启了大型尺度、物理约束遥感植被属性监测的新前景。"}
{"llm_update_time": "20251116", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2511.10385", "html_url": "https://arxiv.org/abs/2511.10385", "title": "SAMIRO: 基于预训练模型的空间注意力互信息正则化的车道检测", "title_en": "SAMIRO: Spatial Attention Mutual Information Regularization with a Pre-trained Model as Oracle for Lane Detection", "authors": "Hyunjong Lee,Jangho Lee,Jaekoo Lee", "background": "车道检测是未来移动解决方案中的重要课题。现实环境中的背景杂乱、光照变化和遮挡等挑战给车道检测带来了巨大障碍，尤其是在依赖数据驱动方法时，这些方法需要大量数据采集和标注工作。于是，车道检测方法必须利用周围车道和物体的上下文和全局信息。本文针对上述问题，提出了一个名为SAMIRO的空间注意力互信息正则化方法，结合预训练模型作为Oracle，以此来提高车道检测性能。", "innovation": "SAMIRO通过从预训练模型中转移知识，同时保留领域无关的空间信息，增强了车道检测性能。利用SAMIRO的即插即用特性，将其集成到多个最新的车道检测方法中，并在CULane、Tusimple和LLAMAS等主要基准上进行了广泛的实验，结果表明，SAMIRO在不同模型和数据集上均能提供一致的性能提升。", "conclusion": "实验结果表明，SAMIRO在不同的模型和数据集上都能一致地提高车道检测性能。研究团队计划在发布时提供代码。"}
{"llm_update_time": "20251116", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2511.10382", "html_url": "https://arxiv.org/abs/2511.10382", "title": "设计脆弱：个性化生成中对抗性防御的局限性", "title_en": "Fragile by Design: On the Limits of Adversarial Defenses in Personalized Generation", "authors": "Zhen Chen,Yi Zhang,Xiangyu Yin,Chengxuan Qin,Xingyu Zhao,Xiaowei Huang,Wenjie Ruan", "background": "个性化AI应用如DreamBooth能够根据用户提供的图像生成定制内容，但同时也引发重要的隐私问题，尤其是面部身份泄漏的风险。为缓解这一风险，近期开发了Anti-DreamBooth等防御机制，通过在用户照片中注入对抗扰动来防止个性化生成的成功。然而，这些方法存在两个关键且被忽略的局限性：其一，对抗性示例常常包含明显的视觉瑕疵，如明显的模式或条纹，使其易于被检测出被修改；其二，这些扰动非常脆弱，简单的、未学习的滤镜即可有效去除它们，从而恢复模型对用户身份的记忆和再生成能力。为了研究这种脆弱性，作者提出了一种新的评估框架，即AntiDB_Purify，旨在在包括传统图像滤镜和对抗性净化在内的现实净化威胁下系统性地评估现有防御效果。", "innovation": "提出了一个新的评估框架AntiDB_Purify，专门用于应对现实中的净化威胁，包括传统的图像滤镜和对抗性净化。这项工作揭示了当前防御方法在面对现实威胁时的有效性会大幅下降，突出了需要更无形且稳健的防护措施来保护用户身份的需求。", "conclusion": "当前的防御措施提供的防护效果存在虚假的安全感，未被验证可以抵御多种现实威胁。研究结果强调了在个性化生成中实现隐形且高度鲁棒性防护措施的迫切需求。"}
{"llm_update_time": "20251116", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2511.10390", "html_url": "https://arxiv.org/abs/2511.10390", "title": "MonkeyOCR v1.5 技术报告：解锁复杂模式下的稳健文档解析", "title_en": "MonkeyOCR v1.5 Technical Report: Unlocking Robust Document Parsing for Complex Patterns", "authors": "Jiarui Zhang,Yuliang Liu,Zijun Wu,Guosheng Pang,Zhili Ye,Yupei Zhong,Junteng Ma,Tao Wei,Haiyang Xu,Weikai Chen,Zeen Wang,Qiangjun Ji,Fanxi Zhou,Qi Zhang,Yuanrui Hu,Jiahao Liu,Zhang Li,Ziyang Zhang,Qiang Liu,Xiang Bai", "background": "文档解析是文档智能的核心任务，支持信息提取、检索增强生成和自动化文档分析等多种应用。但是，现实世界中的文档经常具有复杂的布局，包括多层次表格、嵌入的图片或公式，以及跨页结构，这些对于现有的OCR系统来说仍然是一个挑战。", "innovation": "MonkeyOCR v1.5 提出了一种统一的视觉-语言框架，通过两阶段解析流水线增强了布局理解和内容识别。第一阶段使用大规模的多模态模型共同预测文档布局和阅读顺序，利用视觉信息确保结构和顺序的一致性。第二阶段在检测区域内进行局部化对文本、公式和表格的识别，保持高水平的视觉保真度，减少误差传播。为了处理复杂的表格结构，提出了基于视觉一致性的强化学习方案，通过渲染和比较对齐来评估识别质量，提高结构准确性而无需手动注释。此外还引入了两个专门模块：图像解耦表格解析和类型引导表合并，使表格尤其是包含嵌入图片的表格能够可靠解析，以及重建跨页面或列的表格。", "conclusion": "MonkeyOCR v1.5 在 OmniDocBench v1.5 上的全面实验表明，其达到了业界最佳性能，超越了 PPOCR-VL 和 MinerU 2.5，并且在视觉复杂文档场景中展现了出色的鲁棒性。"}
{"llm_update_time": "20251116", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2511.10412", "html_url": "https://arxiv.org/abs/2511.10412", "title": "3DFETUS: 在三维超声中标准化胎儿面部平面", "title_en": "3DFETUS: Standardizing Fetal Facial Planes in 3D Ultrasound", "authors": "Alomar Antonia,Rubio Ricardo,Albaiges Gerard,Salort-Benejam Laura,Caminal Julia,Prat Maria,Rueda Carolina,Cortes Berta,Piella Gemma,Sukno Federico", "background": "在常规的胎儿超声检查中，由于胎儿运动、方向差异和操作者经验的依赖性，获取标准面部平面通常颇具挑战性。这些因素导致了检查结果的一致性差、检查时间延长，以及潜在的诊断偏差问题。", "innovation": "本文提出了一种方法：1) GT++算法，能够从三维超声图像中估计标准面部平面，并使用注释的解剖标志进行校准；2) 3DFETUS深度学习模型，可以自动化并标准化三维胎儿超声图像中这些平面的定位。通过专家临床审核和定量评估，证实了该方法在平面估计方面的准确性，并优于其他最先进的方法。", "conclusion": "临床评估进一步证明了GT++和3DFETUS的有效性，显示出在平面估计准确性方面具有统计学显著性的改进。"}
{"llm_update_time": "20251116", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2511.10461", "html_url": "https://arxiv.org/abs/2511.10461", "title": "OpenSR-SRGAN: 一种灵活的多光谱地球观测数据超分辨率框架", "title_en": "OpenSR-SRGAN: A Flexible Super-Resolution Framework for Multispectral Earth Observation Data", "authors": "Simon Donike,Cesar Aybar,Julio Contreras,Luis Gómez-Chova", "background": "当前存在一种基于SRGAN（单一图像超分辨率生成对抗网络）的框架，但其灵活性较低，用户需要修改模型代码才能应用到不同的场景中。", "innovation": "OpenSR-SRGAN是一个开放且模块化的框架，针对地球观测中的单张图像超分辨率问题。它通过简洁的配置文件暴露了生成器、判别器、损失函数和训练计划，使得用户可以方便地切换架构、缩放因子和波段设置。该框架作为实用工具和基准实现，而不仅仅是最新的模型。", "conclusion": "OpenSR-SRGAN通过将基于GAN的超分辨率转变为配置驱动的工作流程，降低了研究人员和实践者使用SRGAN、以可重复的方式比较模型，并在多种地球观测数据集中部署超分辨率管道的门槛。"}
{"llm_update_time": "20251116", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2511.10394", "html_url": "https://arxiv.org/abs/2511.10394", "title": "LLM-YOLOMS: 基于大型语言模型的风电叶片组件语义解释与故障诊断", "title_en": "LLM-YOLOMS: Large Language Model-based Semantic Interpretation and Fault Diagnosis for Wind Turbine Components", "authors": "Yaru Li,Yanxue Wang,Meng Li,Xinming Li,Jianbo Feng", "background": "风电叶片的健康状况对于确保其稳定和可靠运行至关重要。然而，现有的故障检测方法主要依赖于视觉识别，仅产生结构化的输出，缺乏语义可解释性，无法支持维护决策。为解决这些问题，本研究提出了一种结合YOLOMS与大型语言模型（LLM）的综合框架，用于智能故障分析和诊断。", "innovation": "该研究创新性地提出了一种结合YOLOMS和LLM的综合框架。YOLOMS通过多尺度检测和滑动窗口裁剪增强故障特征提取，而轻量级的关键值映射模块则可以在视觉输出和文本输入之间建立桥梁。通过将YOLOMS的检测结果转换为包含定量和定性属性的结构化文本表示，结合LLM进行语义推理，生成可解释的故障分析和维护建议。实验结果表明，该框架在真实数据集上的故障检测准确率达到90.6%，生成的维护报告准确率平均为89%，从而提高了诊断结果的解释性和实际运维的决策支持。", "conclusion": "实验结果表明，所提出的框架在真实数据集上的故障检测准确率达到90.6%，并产生了具有89%准确率的维护报告。这些结果提高了诊断结果的解释性和实际运维的决策支持效果。"}
{"llm_update_time": "20251116", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2511.10391", "html_url": "https://arxiv.org/abs/2511.10391", "title": "GrounDiff: 基于扩散的数字地表模型生成地表生成", "title_en": "GrounDiff: Diffusion-Based Ground Surface Generation from Digital Surface Models", "authors": "Oussema Dhaouadi,Johannes Meier,Jacques Kaiser,Daniel Cremers", "background": "数字地形模型（DTMs）代表了地面的真实高度，对于地理空间应用至关重要。然而，这种数据模型不能由传感器直接测量，通常是从LiDAR或摄影测量产生的数字地表模型（DSMs）生成而来。传统的方法依赖于手动调参，而基于学习的方法则需要精心设计的架构，并且通常需要后处理。为了解决这些问题，本文提出了一种新的方法GrounDiff，它是一个基于扩散的方法，通过将问题形式化为去噪任务，迭代地移除非地面结构。为了解决可扩展性问题，还提出了Prior-Guided Stitching（PrioStitch），通过自动使用GrounDiff生成的下采样全局先验来引导局部高分辨率预测。", "innovation": "本文首次提出了一种基于扩散的方法GrounDiff，它通过将问题形式化为去噪任务，迭代地移除非地面结构。此外，为了提高可扩展性，还提出了一种Prior-Guided Stitching（PrioStitch）方法，通过自动使用GrounDiff生成的下采样全局先验来引导局部高分辨率预测。", "conclusion": "本文方法在DSM向DTM转换任务中表现出色，GrounDiff在ALS2DTM和USGS基准测试中分别将RMSE降低了高达93%和47%。在道路重建任务中，该方法在GeRoD基准测试上的距离误差降低了81%，并在不专门优化的情况下保持了竞争性的表面光滑度。此外，GrounDiff+专门设计用于生成更平滑的表面，进一步超过了最先进的方法。"}
{"llm_update_time": "20251116", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2511.10431", "html_url": "https://arxiv.org/abs/2511.10431", "title": "RodEpil: 一种用于癫痫发作检测和基准评估的实验鼠视频数据集", "title_en": "RodEpil: A Video Dataset of Laboratory Rodents for Seizure Detection and Benchmark Evaluation", "authors": "Daniele Perlo,Vladimir Despotovic,Selma Boudissa,Sang-Yoon Kim,Petr Nazarov,Yanrong Zhang,Max Wintermark,Olivier Keunen", "background": "背景介绍了一种专门用于自动检测癫痫发作的实验鼠视频数据集。该数据集是从19只实验鼠的视频中提取的，包含正常活动和癫痫发作两类标记的视频片段。该研究的背景在于开发非侵入性的视频监测手段，以支持癫痫发作的早期发现和监测，这是当前实验鼠癫痫研究中的一项重要需求。", "innovation": "该论文的创新之处在于创建了一个专门用于实验室实验鼠癫痫发作检测的数据集。该数据集不仅包含了丰富的标注信息，还详细描述了数据整理、标注协议和预处理管道，使用基于时序的视频分类器（TimeSformer）进行实验，通过五折交叉验证和严格的主体分割，实现了高精度的癫痫发作与正常活动的区分。", "conclusion": "该论文最终结论是展示了TimeSformer架构在实验鼠癫痫发作检测任务中的有效性，平均F1分数达到了97%，并且公开发布了数据集和实验代码，以支持无创性、基于视频的癫痫研究的可重复性。数据集可通过DOI: https://doi.org/17601357 获取。"}
{"llm_update_time": "20251116", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2511.10488", "html_url": "https://arxiv.org/abs/2511.10488", "title": "SPOT: Sparsification with Attention Dynamics via Token Relevance in Vision Transformers", "title_en": "SPOT: Sparsification with Attention Dynamics via Token Relevance in Vision Transformers", "authors": "Oded Schlesinger,Amirhossein Farzam,J. Matias Di Martino,Guillermo Sapiro", "background": "ViT模型在多种任务中都表现出显著的性能，但其计算需求庞大，随着处理的标记数量增加，计算需求呈二次方增长。Token交互分布可以表示为紧凑的注意力表示，从而可以引导在进行注意力计算之前，提前检测和减少不那么显著的标记，以实现计算上的优化.", "innovation": "提出了SPOT框架，利用标记嵌入、标记间交互和层间注意力动态来推断标记的重要性，从而实现更全面的注意力计算前的冗余标记检测。SPOT框架轻量级预测器可插入各种ViT架构，并具备可学习提取不同输入的具体标记优先级的能力，其设计灵活性支持在不同资源约束条件下实现性能的多样化.", "conclusion": "实验结果表明，与标准ViT相比，SPOT可以在提高功效40%以上的同时，保持甚至提高了准确性。代码和模型可在指定的网址获取."}
{"llm_update_time": "20251116", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2511.10432", "html_url": "https://arxiv.org/abs/2511.10432", "title": "整个组织切片的组织学导向分割提高癌症复发和遗传改变的可解释性和预测性", "title_en": "Histology-informed tiling of whole tissue sections improves the interpretability and predictability of cancer relapse and genetic alterations", "authors": "Willem Bonnaffé,Yang Hu,Andrea Chatrian,Mengran Fan,Stefano Malacrino,Sandy Figiel,CRUK ICGC Prostate Group,Srinivasa R. Rao,Richard Colling,Richard J. Bryant,Freddie C. Hamdy,Dan J. Woodcock,Ian G. Mills,Clare Verrill,Jens Rittscher", "background": "病理学家通过评估组织结构，如前列腺癌中的腺体来确定癌变等级，但现有的数字病理管道依赖于基于网格的分割，忽视了组织架构，引入了无关信息并限制了可解释性。HIT（组织学导向分割）使用语义分割从整张组织切片图像（WSI）中提取腺体，作为生物学上有意义的输入片段用于多重实例学习（MIL）和表型研究。", "innovation": "HIT引入了一种使用语义分割技术从全量组织切片图像中提取腺体的方法，作为有意义的输入片段，应用于多个实例学习和表型研究，提高了癌症复发和遗传改变的可解释性和预测性。通过对来自ProMPT队列的137个样本训练，HIT实现了腺体级别的Dice评分0.83±0.17。从ICGC-C和TCGA-PRAD队列的760个WSI中提取了380,000个腺体，HIT提升了MIL模型判别与上皮-间充质转换相关的基因（EMT和MYC）拷贝数变异的AUC值10%，并揭示了15个腺体簇，其中一些与癌症复发、 Oncogenic突变和高Gleason评分相关。因此，HIT提高了MIL预测的准确性和可解释性，通过聚焦于特征提取过程中的生物含义结构简化了计算。", "conclusion": "HIT提高了癌症复发和遗传改变的可解释性和预测性，通过专注于生物含义结构简化了特征提取计算，提高了MIL预测的准确性和可解释性。"}
{"llm_update_time": "20251116", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2511.10500", "html_url": "https://arxiv.org/abs/2511.10500", "title": "Learnable Total Variation with Lambda Mapping for Low-Dose CT Denoising", "title_en": "Learnable Total Variation with Lambda Mapping for Low-Dose CT Denoising", "authors": "Yusuf Talha Basak,Mehmet Ozan Unal,Metin Ertas,Isa Yildirim", "background": "Total Variation (TV) 模型在噪声去除和边缘保留方面表现出色，但其对 λ 参数的依赖性限制了其效率，并使其难以有效使用。现有的方法在低剂量CT影像降噪中的表现可能不如人意，特别是在噪声建模和优化方面存在局限性。", "innovation": "提出了一种 Learnable Total Variation (LTV) 框架，结合了无卷 Folder TV 求解器和数据驱动的 Lambda Mapping Network (LambdaNet) 来预测像素级正则化图。LTV 框架通过端到端训练来联合优化重建和正则化，实现了空间自适应平滑：在均质区域强化，在解剖边界附近放松。实验结果表明，在使用 LoDoPaB-CT 方法学适应的现实噪声模型的情况下，LTV 在 DeepLesion 数据集上比经典 TV 和 FBP+U-Net 更优：平均 PSNR 提高 2.9 dB，SSIM 提高 6%。LTV 提供了一种可解释的替代黑盒 CNN，为 3D 和数据一致性驱动的重建奠定了基础。", "conclusion": "LTV 框架在低剂量 CT 影像的降噪方面有显著优势，提供了一种空间自适应策略，并且实验结果验证了其在实际应用中的优越性。此外，该方法为 3D 和数据一致性驱动的重建提供了一种新思路。"}
{"llm_update_time": "20251116", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2511.10484", "html_url": "https://arxiv.org/abs/2511.10484", "title": "胰腺表面积分叶性作为CT生物标志物进行机会性筛查2型糖尿病的应用价值", "title_en": "Utility of Pancreas Surface Lobularity as a CT Biomarker for Opportunistic Screening of Type 2 Diabetes", "authors": "Tejas Sudharshan Mathai,Anisa V. Prasad,Xinya Wang,Praveen T.S. Balamuralikrishna,Yan Zhuang,Abhinav Suri,Jianfei Liu,Perry J. Pickhardt,Ronald M. Summers", "background": "2型糖尿病（T2DM）是一种影响全世界数百万人的慢性代谢疾病。早期检测对于阻止胰腺功能的形态学变化和外周脂肪积聚至关重要，从而可能导致器官损伤。尽管已有研究表明T2DM与胰腺体积和脂肪含量有关，但胰腺表面分叶度（PSL）在T2DM患者中的作用尚未得到充分研究。这项初步研究旨在提出一种全自动方法，用于界定胰腺和其他腹部结构、提取CT影像生物标志物，并适时筛查T2DM。", "innovation": "研究采用四种基于深度学习的模型在内部数据集中对584名患者（297名男性、437名非糖尿病患者，年龄45±15岁）的胰腺进行分割。自动检测发现糖尿病患者的PSL较高（p=0.01），分别为4.26±8.32和3.19±3.62。PancAP模型获得了最高的Dice评分（0.79±0.17）和最低的ASSD误差（1.94±2.63 mm）（p<0.05）。通过使用CT生物标志物训练的多变量模型在预测T2DM方面的AUC为0.90，敏感性为66.7%，特异性为91.9%。这些结果表明PSL可作为T2DM筛查的有效工具，有望预测T2DM的早期发生。", "conclusion": "研究表明，胰腺表面分叶度可能是一个有用的CT生物标志物，可用于机会性筛查T2DM。这种方法可以更早地发现T2DM，有助于胰腺功能的保护和疾病的预防。"}
{"llm_update_time": "20251116", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2511.10518", "html_url": "https://arxiv.org/abs/2511.10518", "title": "SemanticVLA: Semantic-Aligned Sparsification and Enhancement for Efficient Robotic Manipulation", "title_en": "SemanticVLA: Semantic-Aligned Sparsification and Enhancement for Efficient Robotic Manipulation", "authors": "Wei Li,Renshan Zhang,Rui Shao,Zhijian Fang,Kaiwen Zhou,Zhuotao Tian,Liqiang Nie", "background": "尽管视觉-语言-动作（VLA）模型在机器人操作方面取得了进步，但其实用部署仍受到两个关键问题的阻碍：1）感知冗余，即无用的视觉输入被无效处理；2）表面化的指令-视觉对齐，这限制了操作的语义定位。", "innovation": "该论文提出了一种新的VLA框架——SemanticVLA，实现了语义对齐的稀疏化和增强，以实现高效的机器人操作。具体包括：1）使用指令引导的视觉剪裁器（ID-Pruner）和空间聚集剪裁器（SA-Pruner）进行稀疏处理，并保留语义对齐；2）语义互补的分层次融合器（SH-Fuser）实现稠密补丁和稀疏令牌的融合，以实现连贯表示；3）语义条件下的动作耦合器（SA-Coupler）替代传统的观察到自由度的方法，提高感知到操作的转换效率，并具备更好的可解释性。", "conclusion": "通过广泛的模拟和实际任务实验，证明了SemanticVLA在性能和效率上都达到了新的SOTA。与其他解决方案相比，SemanticVLA在LIBERO基准测试上的成功率提高了21.1%，同时训练成本和推理延迟分别减少了3倍和5.3倍。SemanticVLA开源且公开发布在相关链接。"}
{"llm_update_time": "20251116", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2511.10539", "html_url": "https://arxiv.org/abs/2511.10539", "title": "从以人体为中心的上下文中动态化身-场景渲染", "title_en": "Dynamic Avatar-Scene Rendering from Human-centric Context", "authors": "Wenqing Wang,Haosen Yang,Josef Kittler,Xiatian Zhu", "background": "从单目视频重建动态人类与真实环境交互是一项重要且具有挑战性的任务。尽管在4D神经渲染方面取得了一定进展，现有的方法要么整体建模动态场景，要么分别建模场景和背景，并引入参数化的先验信息。然而，这些方法要么忽视了场景中各个组成部分，尤其是人体，特有的运动特征，导致重建不完整，要么忽略分别建模的组成部分之间的信息交换，导致在人体-场景边界处出现空间不一致性和视觉伪影。", "innovation": "本文提出了名为'Separate-then-Map' (StM) 的策略，引入了专门的信息映射机制，以连接分别定义和优化的模型。方法使用共享的变换函数对每个高斯属性进行统一，增强了计算效率，同时确保人体与其周围环境的空间和视觉连贯性，而不需要进行耗时的两两交互。", "conclusion": "在单目视频数据集上的广泛实验表明，StM在视觉质量和渲染准确性方面显著优于现有最先进的方法，特别是在人体-场景交互边界处更具挑战性的情况下。"}
{"llm_update_time": "20251116", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2511.10547", "html_url": "https://arxiv.org/abs/2511.10547", "title": "基于属性条件的人工评估基准测试图像生成的多样性", "title_en": "Benchmarking Diversity in Image Generation via Attribute-Conditional Human Evaluation", "authors": "Isabela Albuquerque,Ira Ktena,Olivia Wiles,Ivana Kajić,Amal Rannen-Triki,Cristina Vasconcelos,Aida Nematzadeh", "background": "尽管文本到图像（T2I）模型在生成质量上取得了进步，但现有模型常常缺乏多样性，生成的图像具有同质性。本文引入了一个框架来解决T2I模型在多样性评估方面的需求。该框架系统性地评估多样性，通过评估单一概念及其相关的变化因素来进行多维度的评价。背景部分指出当前T2I模型的同质性问题，需要一种更有力的方法来进行多样性评估，从而提出了解决这一需求的新框架。", "innovation": "本文的主要创新点包括：(1) 提出了一种新的用于细微多样性评估的人工评估模板；(2) 编制了一个涵盖多样化概念及其已确认变化因素的提示集（如：提示：苹果的图像，变化因素：颜色）；(3) 提出了通过二项式测试比较模型的人类注释方法；此外，还严格地比较了多种图像嵌入方法以测量多样性。", "conclusion": "通过逻辑、系统化的评价方法，该研究不仅能评估T2I模型的多样性，还能识别它们在某些类别上的不足，从而提供一种稳健的方法和见解，为改进T2I模型的多样性及评估指标的发展铺平道路。"}
{"llm_update_time": "20251116", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2511.10560", "html_url": "https://arxiv.org/abs/2511.10560", "title": " OmniVGGT：全方位驱动的视觉几何基础模型", "title_en": "OmniVGGT: Omni-Modality Driven Visual Geometry Grounded", "authors": "Haosong Peng,Hao Li,Yalun Dai,Yushi Lan,Yihang Luo,Tianyu Qi,Zhengshen Zhang,Yufeng Zhan,Junfei Zhang,Wenchao Xu,Ziwei Liu", "background": "通用的三维基础模型已经开始引领多种视觉任务的统一趋势，但大多数模型仅假设RGB输入并通过零初始化卷积逐步注入几何信息，忽略了可用的几何先验，如相机内参、外参和深度图，这些信息没有被充分利用。", "innovation": "提出了OmniVGGT框架，该框架能够有效利用任意数量的辅助几何模态，在训练和推断过程中均能从中受益。OmniVGGT通过GeoAdapter将深度和相机内参/外参编码到空间基础模型中，采用零初始化卷积逐步注入几何信息，确保优化稳定且几乎没有额外开销。同时，提出了随机多模态融合机制，使其在测试中能够使用任意数量的模态输入，并促进学习稳健的空间表示而非过度拟合辅助线索。", "conclusion": "综合实验表明，OmniVGGT在单目/多视图深度估计、多视图立体视觉和相机姿态估计方面优于具有辅助输入的先前方法，并且在仅使用RGB输入的情况下也达到了最新的结果。此外，还将OmniVGGT集成到视觉-语言-行动模型中，增强了的VLA模型在主流基准测试上超越了基于点云的基线，并有效利用了可获得的辅助输入，从而在机器人任务中实现了持续的性能提高。"}
{"llm_update_time": "20251116", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2511.10555", "html_url": "https://arxiv.org/abs/2511.10555", "title": "一个代码定义一个风格：通过离散风格空间解锁代码到风格图像生成", "title_en": "A Style is Worth One Code: Unlocking Code-to-Style Image Generation with Discrete Style Space", "authors": "Huijie Liu,Shuhao Cui,Haoxiang Cao,Shuai Ma,Kai Wu,Guoliang Kang", "background": "创新视觉风格化是艺术创作的基础，但生成新颖且一致的视觉风格仍然是一个重大挑战。现有的生成方法通常依赖长文本提示、参考图像或参数高效的微调来指导风格感知图像生成，但在风格一致性、创造力限制和复杂风格表示方面常常存在困难。", "innovation": "本文提出了一个新颖的任务：基于代码的风格图像生成，通过一个唯一的数字符号产生风格新颖且一致的图像，同时不需要参考图像或复杂的参数调整。为此，作者提出了一种名为CoTyle的开源方法，首先从图像集合中训练离散风格码本，提取风格嵌入，作为文本到图像扩散模型(T2I-DM)的条件生成具有风格的图像。进而，训练一个自回归风格生成器在离散风格嵌入上建模其分布，以合成新的风格嵌入。在推理时，通过风格生成器将一个数字符号映射到唯一的风格嵌入，该嵌入指导T2I-DM生成相应的风格图像。", "conclusion": "大量实验证明，CoTyle能够有效将一个数字符号变成风格控制器，证实了一个风格用一个代码就能表达。这种方法提供了前所未有的简洁性和多样性，极大地扩展了从最少输入中实现可重复风格的空间。"}
{"llm_update_time": "20251116", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2511.10604", "html_url": "https://arxiv.org/abs/2511.10604", "title": "Multitask GLocal OBIA-Mamba for Sentinel-2 Landcover Mapping", "title_en": "Multitask GLocal OBIA-Mamba for Sentinel-2 Landcover Mapping", "authors": "Zack Dewis,Yimin Zhu,Zhengsen Xu,Mabel Heffring,Saeid Taleghanidoozdoozan,Kaylee Xiao,Motasem Alkayid,Lincoln Linlin Xu", "background": "Sentinel-2 基于土地利用和土地覆盖（LULC）分类对于各种环境监测应用至关重要，但由于一些关键数据挑战（例如空间异质性、上下文信息、特征混淆）使其成为一项非常困难的任务。以往的研究和方法在处理这些挑战时遇到了一定的局限性，因此亟需一种新的方法来改进Sentinel-2的地表覆盖分类。", "innovation": "本文提出了一种新颖的多任务全域OBIA-Mamba (MSOM) 方法，通过以下贡献提高了Sentinel-2分类的准确性。首先，设计了基于超像素的OBIA-Mamba模型，这不仅减少了冗余计算，还保留了细节。其次，设计了一种全局-局部双重卷积神经网络（CNN）-Mamba架构来同时建模局部空间细节和全局上下文信息。最后，设计了一种多任务优化框架，利用双重损失函数平衡局部精确性和全局一致性。这项工作的创新之处在于结合了OBIA、全局-局部CNN架构和多任务优化框架，以提高空间细节和分类准确度。", "conclusion": "该方法在加拿大的阿尔伯塔省Sentinel-2图像上进行了测试，并与几种先进的分类方法进行了比较。结果表明，该方法在分类准确性和细节表现上优于现有的最佳方法。"}
{"llm_update_time": "20251116", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2511.10597", "html_url": "https://arxiv.org/abs/2511.10597", "title": "从2D到3D无需额外负担：数字乳腺断层摄影中的高效癌症检测", "title_en": "From 2D to 3D Without Extra Baggage: Data-Efficient Cancer Detection in Digital Breast Tomosynthesis", "authors": "Yen Nhi Truong Vu,Dan Guo,Sripad Joshi,Harshit Kumar,Jason Su,Thomas Paul Matthews", "background": "数字乳腺断层合成（DBT）通过提供体积信息，增强了乳腺癌检测中病变的可见性，减少了重叠组织的影响。然而，由于标注数据有限，限制了深度学习模型的开发。现有方法试图通过将DBT体积扁平化或逐片处理2D全野数字化乳腺摄影（FFDM）模型的方式来重用2D模型，但这会丢弃体积信息。另一种方法是引入复杂的3D推理架构，这需要更多的DBT训练数据。", "innovation": "我们提出了M&M-3D架构，其创新之处在于能够学习3D推理的同时保持相对于其FFDM对等物M&M的无参数化。M&M-3D通过构建病症导向的3D特征并反复混合这些3D特征与切片级信息来进行3D推理，而不需要添加参数，从而允许直接将FFDM的权重转移过来。实验表明，M&M-3D在局部化和分类方面分别优于2D投影和基于3D切片的方法11-54%和3-10%，在数据稀缺的情况下，M&M-3D在局部化和分类方面的性能比复杂的3D推理变体分别提高了20-47%和2-10%，而在数据丰富的情况下，M&M-3D匹配它们的性能。在流行的BCS-DBT基准测试中，M&M-3D在分类和局部化方面的表现分别比之前最好的基线提高了4%和10%。", "conclusion": "M&M-3D架构在降低标注数据需求的同时，提高了DBT中癌症检测的准确性，尤其在数据稀缺的情况下表现出色。"}
{"llm_update_time": "20251116", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2511.10629", "html_url": "https://arxiv.org/abs/2511.10629", "title": "在潜在空间迈出一小步，为你的扩散模型实现像素级飞跃：快速潜在上采样适配器", "title_en": "One Small Step in Latent, One Giant Leap for Pixels: Fast Latent Upscale Adapter for Your Diffusion Models", "authors": "Aleksandr Razin,Danil Kazantsev,Ilya Makarov", "background": "当前的扩散模型在超过其训练分辨率时存在困难，由于直接生成高分辨率图像速度缓慢且成本高昂，而后处理的图像超分辨率（ISR）会引入伪影并增加延迟，这是在解码之后进行的处理步骤。", "innovation": "提出了轻量级的潜在上采样适配器（LUA），该模块可以在生成器的潜在代码进行超分辨率处理，出现在最终的VAE解码步骤之前。LUA作为一个插件模块，无需对基本模型进行修改或增加额外的扩散阶段，通过潜在空间单次前向传递实现高分辨率合成。LUA与共享Swin风格的骨干网络结构结合，具有特定尺度的像素混频头，支持2倍和4倍的上采样因子，并与图像空间SR基线兼容，实现近3倍的解码和上采样时间降低（从512像素生成1024像素仅增加0.42秒，而使用相同的SwinIR架构时空域SR需要1.87秒），同时在各种VAE潜在空间中表现出良好的泛化能力，无需从头开始重新训练便可轻松部署。", "conclusion": "LUA接近直接高分辨率生成的保真度，同时在现代扩散流水线中提供了一条可扩展且高效的高保真图像合成路径。"}
{"llm_update_time": "20251116", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2511.10615", "html_url": "https://arxiv.org/abs/2511.10615", "title": "轻量级VLMs及其定制LLM评估方法向盲人和低视力用户的可访问性", "title_en": "Towards Blind and Low-Vision Accessibility of Lightweight VLMs and Custom LLM-Evals", "authors": "Shruti Singh Baghel,Yash Pratap Singh Rathore,Sushovan Jena,Anurag Pradhan,Amit Shukla,Arnav Bhavsar,Pawan Goyal", "background": "大型视音频语言模型（VLMs）在视频描述理解和生成方面表现出色，但由于其对高内存、高计算和部署需求的限制，尤其是在盲人和低视力（BLV）用户依赖详细、上下文相关的描述时，这些模型的实际应用受到了阻碍。因此，为了研究模型大小对基于无障碍的描述质量的影响，研究者评估了两个不同参数量的SmolVLM2变体，并提出了专门用于BLV可访问性评估的两种新的评估框架：多上下文评估框架和导航辅助框架以评估盲和低视力用户的可访问性问题。此外，研究还系统地评估了四种不同的提示设计策略，并在智能手机上部署了这两种模型，以评估其在资源有限的移动设备上的实际性能限制。", "innovation": "研究引入了两种针对BLV无障碍评估的新框架：多上下文评估框架和导航辅助评估框架，专注于空间定向、社交互动、行为事件和氛围等上下文信息。研究还系统评估了四种不同提示设计策略，并在智能手机上部署了不同精度的模型，以评估其在资源受限移动设备上的实际性能。这些创新方法主要聚焦于改善BLV用户使用音视频模型的体验，提供更适用的、可访问的视频描述生成能力。", "conclusion": "研究表明，适当的模型大小和提示设计对于提高盲和低视力用户的可访问性描述质量至关重要。提出的评估框架为改进这些模型提供了新的思路和方法，有助于开发更适用于盲人和低视力用户的轻量化音视频模型。"}
{"llm_update_time": "20251116", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2511.10647", "html_url": "https://arxiv.org/abs/2511.10647", "title": "Depth Anything 3：从任意视角恢复视觉空间", "title_en": "Depth Anything 3: Recovering the Visual Space from Any Views", "authors": "Haotong Lin,Sili Chen,Junhao Liew,Donny Y. Chen,Zhenyu Li,Guang Shi,Jiashi Feng,Bingyi Kang", "background": "本文基于现有的深度几何预测模型，提出了一种名为Depth Anything 3 (DA3) 的模型，能够从任意数量的视觉输入中预测空间上一致的几何结构，并且在已知或未知相机姿态的情况下都能适用。该模型通过最小化模型设计，得出了两个关键性见解：单一的变压器（如经典DINO编码器）作为基础模型就足够，单一的深度射线预测目标简化了复杂的多任务学习。作者通过教师-学生训练架构，使DA3模型在细节和泛化能力上与之前的模型Depth Anything 2 (DA2) 相当。同时，文章还建立了一个新的视觉几何基准，涵盖了相机姿态估计、任意视角几何和视觉渲染等多个方面。", "innovation": "本文的创新点在于提出了Depth Anything 3 (DA3) 模型，简化了模型架构不需要专门的网络结构，单一的深度射线预测目标简化了复杂的多任务学习。通过教师-学生训练框架，DA3模型在细节和泛化能力上与之前的深度几何预测模型DA2相当，并且在相机姿态估计和几何准确性方面超过了先前的最佳模型44.3%和25.1%，还在单目深度估计上优于DA2。所有模型仅在公共学术数据集上进行训练，进一步证明模型的有效性和普适性.", "conclusion": "本文通过建立一个新的视觉几何基准，并通过教师-学生训练架构，改进了深度几何预测模型DA3，结果显示该模型在多个任务上达到了新的最佳水平，并且在开放的学术数据集上训练模型证明了其良好的泛化性能。"}
{"llm_update_time": "20251116", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2511.09894", "html_url": "https://arxiv.org/abs/2511.09894", "title": "EgoEMS：急救医疗服务中认知辅助的高保真多模态第一人称数据集", "title_en": "EgoEMS: A High-Fidelity Multimodal Egocentric Dataset for Cognitive Assistance in Emergency Medical Services", "authors": "Keshara Weerasinghe,Xueren Ge,Tessa Heick,Lahiru Nuwan Wijayasingha,Anthony Cortez,Abhishek Satpathy,John Stankovic,Homa Alemzadeh", "background": "急诊医疗服务（EMS）在紧急情况下对患者生存至关重要，但前线救援人员在高风险场景中常面临巨大的认知负担。人工智能认知辅助工具，作为虚拟伙伴，能够通过支持实时数据收集和决策过程来减轻这一负担。研究团队为实现这一愿景，创建了EgoEMS，这是首个端到端、高保真、多模式、多对象的数据集，涵盖了233个模拟紧急场景中的真实、程序化的EMS活动。数据集记录了20多个小时的急救活动，其中包括62名参与者，46名为专业救援人员。", "innovation": "该研究创新地开发了EgoEMS数据集，这是首个针对急诊医疗场景的高保真度、多模式的第一人称数据集。EgoEMS记录了超过20小时的紧急医疗活动现场活动，采用开源、低成本、可复制的数据收集系统。数据集中包括应急响应人员与患者的互动，以及多个关键步长、带时间戳的音频转录、带有发言人识别的行动质量度量和带有分割掩码的边界框。研究团队还提出了实时多模态关键步骤识别和行动质量估计的基准测试，这对于开发支持紧急医疗服务的AI工具至关重要。", "conclusion": "EgoEMS旨在激发研究社区进一步探索智能急诊医疗服务系统，并希望最终有助于改善患者结果。该数据集的创建为急救医疗服务研究提供了新的方法和工具。"}
{"llm_update_time": "20251116", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2511.10648", "html_url": "https://arxiv.org/abs/2511.10648", "title": "基于自我一致性采样的多模态大语言模型结果奖励RL培训增强", "title_en": "Enhancing the Outcome Reward-based RL Training of MLLMs with Self-Consistency Sampling", "authors": "Jiahao Wang,Weiye Xu,Aijun Yang,Wengang Zhou,Lewei Lu,Houqiang Li,Xiaohua Wang,Jinguo Zhu", "background": "在解决多模态大语言模型(MLLMs)逐步推理过程中，频繁采用基于奖励的强化学习(Outcome-reward RL)方法。但在多项选择题设置中，即多模态推理基准中常见的形式，该范式面临一个重要却常被忽视的问题：那些基于错误推理命中正确选项的路径与基于真实推理的路径获得相同奖励，但这不能被忽视。这种方法会导致在训练过程中无法有效区分虚假和真实推理路径，从而影响最终模型效果。因此，迫切需要一种方法来纠正这一问题，确保模型能够更准确地评估和强化真实推理过程的路径而非随机猜测的结果。", "innovation": "为了应对上述挑战，作者提出了一种自我一致性采样(Self-Consistency Sampling, SCS)方法。该方法具体包括：(1) 为每个问题引入细微的视觉干扰；(2) 对初始路径进行多次截断和重采样；(3) 结果路径的一致性评估得到一个可微的一致性分数，这个分数在策略更新中可以降低不可靠路径的权重。通过将这种新方法应用于Qwen2.5-VL-7B-Instruct模型及其变体，作者在六个多模态基准测试上分别将准确性提高了5.9%至7.7%，且未增加额外的计算负担。此外，该方法还提高了Qwen2.5-VL-3B-Instruct和InternVL3-8B模型的表现，显示出适用于多模态大语言模型(MLLMs)的一种简单而通用的解决方案来改进基于结果奖励的RL训练过程。", "conclusion": "自我一致性采样(SCS)方法通过改进基于结果奖励的强化学习过程，在多模态大语言模型上取得了显著效果，不仅提高了模型的准确率，而且实现了简单且通用的应用，弥补了以往仅依靠错误奖励来更新模型时的不足。这一方法为提升多模态大语言模型的整体性能提供了新的思路和实践方法。"}
{"llm_update_time": "20251116", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2511.09905", "html_url": "https://arxiv.org/abs/2511.09905", "title": "PRISM：通过解耦结构先验来多样化数据集蒸馏", "title_en": "PRISM: Diversifying Dataset Distillation by Decoupling Architectural Priors", "authors": "Brian B. Moser,Shalini Strode,Federico Raue,Stanislav Frolov,Krzysztof Adamkiewicz,Arundhati Shanbhag,Joachim Folk,Tobias C. Nauen,Andreas Dengel", "background": "数据集蒸馏（DD）旨在生成紧凑且忠实的合成数据，但现有方法通常继承单一教师模型的归纳偏见。数据集规模增大时，这种偏见会导致生成过度平滑、同质的样本，减少了同类之间的多样性，限制了泛化能力。", "innovation": "提出了一种框架（PRISM），在合成过程中分离出架构先验。PRISM将逻辑匹配和正则化目标分离，分别使用不同的教师架构进行监督：主要模型用于逻辑匹配，随机子集用于批量归一化（BN）对齐。PRISM在ImageNet-1K上的表现始终优于单一教师方法（如SRe2L）和最近的多教师变体（如G-VBSM），特别是在低到中等IPC（每周期指令）区间。生成的数据也显示丰富得多的类别内多样性，特征之间的余弦相似度显著下降。进一步分析了教师选择策略（预蒸馏 vs. 内部蒸馏）并引入了跨类别批量形成方案以实现快速并行合成。", "conclusion": "PRISM在低到中等IPC区间在ImageNet-1K上始终优于单一教师方法和多教师变体，并且生成的数据展现了更丰富的类别内多样性。还分析了教师选择策略并提出了快速并行合成方案。"}
{"llm_update_time": "20251116", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2511.10023", "html_url": "https://arxiv.org/abs/2511.10023", "title": "Customize CNN Models for Efficient Automated Diagnosis of Retinopathy of Prematurity", "title_en": "Efficient Automated Diagnosis of Retinopathy of Prematurity by Customize CNN Models", "authors": "Farzan Saeedi,Sanaz Keshvari,Nasser Shoeibi", "background": "本研究深入探讨了早产儿视网膜病变（ROP）的诊断，利用先进的深度学习方法。重点关注基于CNN的检测方法的改进和评估，以便实现更精准和高效的ROP检测。研究涵盖了数据集的构建、预处理策略和模型架构等多个复杂方面，旨在评估模型的有效性、计算成本和时间复杂性。研究表明，定制的CNN模型在准确性和F1评分方面优于预训练模型，并通过投票系统进一步提升了性能。此外，研究还揭示了定制CNN模型在缓解深度神经网络计算负担方面的潜力，并展示了在特定软件和硬件配置中部署这些模型的可能性，从而在临床环境中为诊断提供有价值的辅助工具。", "innovation": "本研究的创新之处在于利用定制的CNN模型进行ROP的自动化诊断，并展示了其在提高准确性和效率方面优于预训练模型。模型的有效性和计算成本被详细评估，同时引入了投票系统来进一步优化性能。研究还探讨了定制CNN模型在临床应用中的可行性，特别是在减轻深度学习计算负担方面的作用。", "conclusion": "本研究显著促进了ROP的诊断，展示了深度学习模型在提高诊断精度和效率方面的有效性。研究结果强调了定制CNN模型的优越性，并提出这些模型在临床诊断中的可行性，这将为ROP患者提供更有效的早期诊断和治疗手段。"}
{"llm_update_time": "20251116", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2511.09907", "html_url": "https://arxiv.org/abs/2511.09907", "title": "学习提出问题：基于推理驱动和解决者自适应的数据合成方法", "title_en": "Learning to Pose Problems: Reasoning-Driven and Solver-Adaptive Data Synthesis for Large Reasoning Models", "authors": "Yongxian Wei,Yilin Zhao,Li Shen,Xinrui Chen,Runxi Cheng,Sinan Du,Hao Yu,Gang Liu,Jiahong Yan,Chun Yuan,Dian Li", "background": "数据合成用于训练大规模推理模型提供了一种比有限的人工校正数据集更具可扩展性的选择，能够创建高质量的数据。但现有方法面临挑战：（i）无差别的生成忽视了解决者的能力，产生低价值的问题，或依赖复杂的数据管道平衡问题难度；（ii）在问题生成中缺乏推理，导致浅层的问题变体。", "innovation": "本文发展了一个问题生成器，该生成器在合成之前明确推理以规划问题方向，并根据解决者的能力调整难度。具体来说，构造相关的成对问题，并通过推理模型提供的中间问题设计逐步进行扩充。数据以问题设计策略的方式为生成器提供支持。然后，将解决者对合成问题的反馈视为奖励信号，使生成器能够校准难度并生成接近解决者边界的互补问题。实验结果表明，该方法在10个数学和通用推理基准上的平均改进幅度为2.5%，并且能够应用于语言和视觉-语言模型。训练于合成数据的解决者还能提供改进的奖励信号，促进生成器的协同进化并对性能提升带来0.7%的额外收益。", "conclusion": "我们的方法在大型推理模型训练数据合成中取得了显著效果，并且通过持续优化与解决者之间的协同进化进一步提高了性能。该方法利用解决者的反馈自适应调整难度，并生成与解决者能力相匹配的高质量合成数据，为解决者提供互补的问题，从而显著提高了模型的性能。"}
{"llm_update_time": "20251116", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2511.09568", "html_url": "https://arxiv.org/abs/2511.09568", "title": "VEDA: 通过方差爆炸扩散进行退火的3D分子生成", "title_en": "VEDA: 3D Molecular Generation via Variance-Exploding Diffusion with Annealing", "authors": "Peining Zhang,Jinbo Bi,Minghu Song", "background": "扩散模型在3D分子生成方面显示出了潜力，但存在采样效率和构象准确性的基本权衡。流式模型速度快，但产生的分子结构几何上不够准确，难以捕捉分子构象的多模态分布。相比之下，去噪扩散模型更加准确，但采样速度较慢，这是由于扩散动力学与SE(3)-不变架构之间的次优整合所致。", "innovation": "提出了一种统一的SE(3)-不变框架VEDA，结合方差爆炸扩散与退火以高效生成构象准确的3D分子结构。其关键技术贡献包括：(1) 基于冒泡冷却的VE调度表，使噪声注入功能类似于模拟退火，提高3D准确性并减少松弛能；(2) 一个新颖的预处理方案，将SE(3)-不变网络的坐标预测性质与残差导向的扩散目标相结合；(3) 提出了一种新弧度基础上的调度器，集中采样在对数信噪比的关键区间上。", "conclusion": "在QM9和GEOM-DRUGS数据集上，VEDA在仅100次采样的情况下匹配了流式模型的采样效率，并达到了最先进的价数稳定性和有效性。更重要的是，VEDA生成的结构在GFN2-xTB优化过程中的稳定性更高，中位能量变化仅为1.72 kcal/mol，远低于其架构基线SemlaFlow的32.3 kcal/mol。枕框架明了方差爆炸扩散与SE(3)-不变架构的深度融合可以同时实现高度的化学准确性和计算效率。"}
{"llm_update_time": "20251116", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2511.10050", "html_url": "https://arxiv.org/abs/2511.10050", "title": "被它们自己的光芒所捕获：针对交通标志识别系统的可部署且隐形的反光片攻击", "title_en": "Trapped by Their Own Light: Deployable and Stealth Retroreflective Patch Attacks on Traffic Sign Recognition Systems", "authors": "Go Tsuruoka,Takami Sato,Qi Alfred Chen,Kazuki Nomoto,Ryunosuke Kobayashi,Yuna Tanaka,Tatsuya Mori", "background": "交通标志识别在确保自动驾驶车辆的安全和高效运输中发挥着关键作用，但仍然容易受到使用贴纸或激光投影的对抗性攻击的影响。虽然现有的攻击途径表明了安全问题，但它们存在视觉可检测性或实施限制的问题，暗示了 TSR 系统中尚未探索的潜在漏洞。这篇论文针对这个问题介绍了名为 Adversarial Retroreflective Patch (ARP) 的新型攻击向量，这种攻击通过在受害者车灯照射下激活反光材料来结合了补丁攻击的高部署性和激光投影的隐形性，旨在突破现有攻击途径的局限。", "innovation": "论文提出了名为 Adversarial Retroreflective Patch (ARP) 的一种新型攻击向量，通过结合补丁攻击的高部署性和激光投影的隐形性，在受害者车灯照射下激活反光材料。研究开发了一种反光模拟方法，并使用黑盒优化来最大化攻击效果。在动态场景中，ARP 在 35 米距离下实现了至少 93.4% 的成功率，并在真实世界条件下对商用 TSR 系统的成功率为至少 60%。此外，通过用户研究证实 ARP 攻击的隐蔽性几乎与普通标志相同，相较于之前的补丁攻击，更高的隐蔽性分数为至少 1.9%。论文还提出了名为 DPR Shield 的防御策略，采用战略放置的偏振滤镜来对抗微棱镜补片攻击，对停止标志和速度限制标志实现了至少 75% 的防御成功率。", "conclusion": "研究结果显示，ARP 攻击在现实环境中的成功率为至少 60%，并且提供了对现有补丁攻击的超越性的隐身性特点。而 DPR Shield 防御策略可以有效地减少 ARP 攻击的成功率，并提高了交通标志识别系统的安全性。"}
{"llm_update_time": "20251116", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2511.10094", "html_url": "https://arxiv.org/abs/2511.10094", "title": "我的模型是如何失败的？Matryoshka Transcoders自动识别和解释物理可信度故障模式", "title_en": "How does My Model Fail? Automatic Identification and Interpretation of Physical Plausibility Failure Modes with Matryoshka Transcoders", "authors": "Yiming Tang,Abhijeet Sinha,Dianbo Liu", "background": "尽管最近的生成模型已经在指令遵循和现实输出方面表现出色，但由于物理可信度方面的明显错误仍然存在，它们在实际应用中仍存在问题。现有的评估方法往往未能发现这些错误，因此缺乏一种自动识别和解释生成模型中的物理错误模式的框架，阻碍了模型的精确改进。", "innovation": "提出了Matryoshka Transcoders，这是一种新颖的框架，用于自动发现和解释生成模型中的物理可信度特性。该方法扩展了Matryoshka特征学习范式，适用于编码器-解码器架构，能够在多个粒度级别进行分层稀疏特征学习。通过在物理可信度分类器的中间表示上进行训练，并利用大规模的多模态模型进行解释，该方法在无需手动特征工程的情况下识别多种物理相关失败模式，比现有方法具有更高的特征相关性和准确性。使用发现的视觉模式建立了物理可信度评估基准，对八种最先进的生成模型的分析提供了关于这些模型如何违反物理约束的重要见解。", "conclusion": "本文通过Matryoshka Transcoders建立了评估生成模型物理可信度的基准，通过分析八大领先生成模型揭示了模型违反物理约束的具体模式，为未来的模型改进开创新途径。"}
{"llm_update_time": "20251116", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2511.10088", "html_url": "https://arxiv.org/abs/2511.10088", "title": "eXIAA: eXplainable Injections for Adversarial Attack", "title_en": "eXIAA: eXplainable Injections for Adversarial Attack", "authors": "Leonardo Pesce,Jiawen Wei,Gianmarco Mengaldo", "background": "后验可解释性方法是机器学习中的一类技术，旨在提供模型行为原因的解释。本文介绍了一种针对图像领域后验可解释的人工智能（XAI）的新黑盒模型通用对抗攻击方法。该攻击旨在修改原始解释而不被人类视觉察觉，同时保持相同的预测类别。不同于以往的方法，该研究仅需要访问模型的预测结果和解释，而不需任何模型权重的访问权限。方法的低要求揭示了当前可解释方法中存在的关键脆弱性，引起了人们对其在关键安全应用中的可靠性的担忧。研究基于预训练的ResNet-18和ViT-B16模型在ImageNet上的后验解释（如显著图、集成梯度和DeepLIFT SHAP）系统地生成攻击。结果表明，攻击能够导致显著不同的解释，而不改变预测概率。", "innovation": "本文提出了一种不需要任何形式的模型或权重访问的单步后验可解释的人工智能对抗攻击方法，仅需访问模型的预测结果和解释。此方法暴露了当前解释方法的关键脆弱性，并且其低要求暴露了当前解释方法中的可靠性和安全性问题，评估了攻击方法的有效性，并且通过均方绝对差和结构相似性指数测量（SSIM）验证了原始图像和被攻击图像的相似性。", "conclusion": "本文提出的方法揭示了当前解释方法中的关键脆弱性，并且在不需要模型权重访问的情况下，能够显著改变解释结果而不被人类视觉察觉，从而提高对抗攻击的效果和可靠性，引起对可解释性在关键安全应用中的可靠性的进一步关注。"}
{"llm_update_time": "20251116", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2511.10475", "html_url": "https://arxiv.org/abs/2511.10475", "title": "以固有维数作为无模型依赖的类别不平衡度量", "title_en": "Intrinsic Dimensionality as a Model-Free Measure of Class Imbalance", "authors": "Çağrı Eser,Zeynep Sonat Baltacı,Emre Akbaş,Sinan Kalkan", "background": "类别不平衡度通常通过各个类别中样本数量的统计计算来量化，但这种方法忽略了冗余样本的存在和学习难度的内在差异。尽管可以使用训练损失和不确定性等复杂度量，但这些方法依赖于训练机器学习模型。目前的方法主要是基于卡方或Fisher准则的重加权和重采样技术，但这些方法在性能上并不理想。因此，需要一种模型无关的、易于计算的不平衡度量技术，以提高不平衡数据分类任务的效果。", "innovation": "本文提出使用固有维数（ID）作为平衡度量，这是一种易于计算、无需训练模型的方法，可以无缝集成到各种平衡方法中。实验结果表明，ID在不同不平衡比例数据集上的表现优于现有的基于卡方或Fisher准则的重加权和重采样技术，并且结合卡方度量可以进一步提高性能。", "conclusion": "固有维数是一种有效的、无模型依赖的类别不平衡度量方法，能够改善类别不平衡数据集上的分类表现，并且该方法具有与现有技术结合使用的能力，以进一步优化性能。"}
{"llm_update_time": "20251116", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2511.10627", "html_url": "https://arxiv.org/abs/2511.10627", "title": "使用情境程序查询标注时间序列数据", "title_en": "Querying Labeled Time Series Data with Scenario Programs", "authors": "Edward Kim,Devan Shanker,Varun Bharadwaj,Hongbeen Park,Jinkyu Kim,Hazem Torfah,Daniel J Fremont,Sanjit A Seshia", "background": "基于仿真的测试已成为确保自主驾驶系统（ADS）安全的关键补充，尤其是对于确保它们在实际世界中的可靠性。鉴于此，研究人员正在努力识别仿真环境中的故障场景。然而，一个关键问题是，在仿真中发现的ADS故障场景能否在实际系统中重现？由于仿真和实际传感器数据之间的差异（即仿真实验与现实差距），仿真中发现的故障场景可能是合成传感器数据的产物，也可能是实际传感器数据中存在的问题。", "innovation": "本文提出了一种有效的方法来验证仿真中的故障场景，即通过定位实际世界数据集中匹配特定场景的子集，并验证这些故障是否在实际数据中持续存在。具体而言，作者通过引入一种正式定义的时间序列传感器数据如何与用Scenic概率编程语言表示的抽象场景匹配的方法，并提出一种查询算法，该算法能够根据给定的场景程序和标注数据集来识别匹配特定场景的数据子集。实验证明，该算法在查询场景方面比最先进的商业视觉大型语言模型更准确、速度更快，并且能够根据查询时间序列数据的持续时间进行扩展。", "conclusion": "本文的实验结果表明，提出的查询算法在场景查询的准确性和速度上都显著优于现有技术，并能够处理较长的时间序列数据。这为验证仿真测试中发现的故障场景提供了一种有效且高效的解决方案，有助于缩小仿真与实际之间的差距，提高ADS的安全性和可靠性。"}
{"llm_update_time": "20251116", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2511.10566", "html_url": "https://arxiv.org/abs/2511.10566", "title": "Layer Norm对Transformer中记忆和泛化的影晌", "title_en": "Impact of Layer Norm on Memorization and Generalization in Transformers", "authors": "Rishi Singhal,Jung-Eun Kim", "background": "Layer Normalization (LayerNorm) 是Transformer架构中的一个基本组成部分，用于稳定训练并提高优化效果。最近，Pre-LayerNorm架构因其稳定的梯度流动而取代了Post-LayerNorm架构成为首选。然而，LayerNorm对这些架构中的学习和记忆影响仍不清楚。本研究旨在调查LayerNorm如何影响Pre-和Post-LayerNorm架构中的学习和记忆。研究表明，在Pre-LayerNorm架构中，LayerNorm是稳定学习的关键因素，而在Post-LayerNorm架构中，它会影响记忆。通过在6个视觉和语言数据集上的13个模型上进行验证，研究人员发现早期层的LayerNorm在Pre-和Post-LayerNorm模型中最为关键，其影响因模型而异。", "innovation": "本研究首次系统地分析了LayerNorm在Pre-和Post-LayerNorm两种架构中的具体影响，揭示了LayerNorm参数对于学习和记忆的不同作用机制。特别是在Pre-LayerNorm模型中消除LayerNorm参数会加剧记忆并导致学习不稳定；而在Post-LayerNorm模型中，消除LayerNorm参数能够有效地减轻记忆负担，恢复真实标签。这些发现为理解Transformer中LayerNorm的作用提供了新的见解。", "conclusion": "研究结果显示，LayerNorm对学习和记忆的影响因架构（Pre-或Post-LayerNorm）而异。在Pre-LayerNorm架构中，LayerNorm是稳定学习的关键；而在Post-LayerNorm架构中，它能够减轻过度记忆并恢复真实性。此外，早期层的LayerNorm在两种架构中的作用尤为关键，其影响因模型而异。这些发现进一步丰富了关于Transformer架构中LayerNorm作用的认知。"}
{"llm_update_time": "20251116", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2208.08083", "html_url": "https://arxiv.org/abs/2208.08083", "title": "两个头脑胜过一个：稳健学习与多分支模型结合", "title_en": "Two Heads are Better than One: Robust Learning Meets Multi-branch Models", "authors": "Zongyuan Zhang,Qingwen Bu,Tianyang Duan,Zheng Lin,Yuhao Qing,Zihan Fang,Heming Cui,Dong Huang", "background": "深度神经网络(DNNs)容易受到对抗样本的影响，在这种情况下，DNNs会因为输入包含不可感知的扰动而被误导产生错误输出。对抗训练作为一种可靠的防御方法，能够显著减少神经网络的脆弱性，已成为实现稳健学习的行业标准。然而，尽管许多最近的工作强调了数据为中心的方法，如如何生成更好的对抗样本或利用生成模型生成额外的训练数据，本文却转向模型本身，从深层特征分布的角度重新审视了对抗鲁棒性，作为一种重要的补充。", "innovation": "本文提出了Branch Orthogonality adveRsarial Training (BORT)，仅通过原始数据集即可实现最佳性能。为了结合多个正交求解空间的设计理念，本文采用了一个简单的多分支神经网络，并提出了相应的分支正交损失函数，使多分支模型的每个解决方案空间正交。实验结果显示，本文方法超越了所有最先进的方法，不使用任何技巧。与所有不使用额外数据训练的方法相比，BORT模型在CIFAR-10上的鲁棒准确率为67.3%，在CIFAR-100上的鲁棒准确率为41.5%，分别提高了7.23%和9.07%。", "conclusion": "我们的方法在对抗训练中取得了最先进的性能，不需要使用额外的数据，并通过多项实验展示了其优越性，为对抗鲁棒性的研究提供了新的视角。"}
{"llm_update_time": "20251116", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2406.05477", "html_url": "https://arxiv.org/abs/2406.05477", "title": "Attri-Net: 一种基于类特定可反驳例子的全局和局部固有可解释的多标签分类模型", "title_en": "Attri-Net: A Globally and Locally Inherently Interpretable Model for Multi-Label Classification Using Class-Specific Counterfactuals", "authors": "Susu Sun,Stefano Woerner,Andreas Maier,Lisa M. Koch,Christian F. Baumgartner", "background": "在高风险医疗应用中，机器学习算法的可解释性至关重要。然而，高性能的神经网络通常无法解释其预测结果。后验解释方法提供了一种理解神经网络的方式，但这些方法在概念上存在一些问题。当前研究主要集中于为单一样本提供局部解释，而没有为模型本身提供全局解释。", "innovation": "本文提出了一种名为Attri-Net的固有可解释模型，适用于多标签分类任务，提供局部和全局解释。Attri-Net首先通过类特定的可反驳生成类别的归因图以突出疾病证据，然后基于归因图使用逻辑回归分类器进行分类。通过权衡分类器权重解释每个预测的归因图权重可获得局部解释。通过联合考虑每类学习到的归因图的平均表示（称为类中心）和线性分类器的权重，可以得到整个模型的全局解释。此外，提出的机制确保模型解释与人类知识一致。", "conclusion": "我们的全面评估表明，Attri-Net 能够生成与临床知识一致的高质量解释，同时不牺牲分类性能。"}
{"llm_update_time": "20251116", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2410.08207", "html_url": "https://arxiv.org/abs/2410.08207", "title": "DICE: 离散反转以使二项式扩散和蒙面生成模型的可控编辑成为可能", "title_en": "DICE: Discrete Inversion Enabling Controllable Editing for Multinomial Diffusion and Masked Generative Models", "authors": "Xiaoxiao He,Quan Dao,Ligong Han,Song Wen,Minhao Bai,Di Liu,Han Zhang,Martin Renqiang Min,Felix Juefei-Xu,Chaowei Tan,Bo Liu,Kang Li,Hongdong Li,Junzhou Huang,Faez Ahmed,Akash Srivastava,Dimitris Metaxas", "background": "离散扩散模型在图像生成和蒙面语言建模等任务中取得了成功，但在可控内容编辑方面存在局限性。DICE（离散反转以实现可控编辑）是首个能够启用离散扩散模型精确反转的方法，包括多项式扩散和蒙面生成模型，通过在逆向扩散过程中记录噪声序列和蒙面模式，使离散数据的准确重建和灵活编辑成为可能，无需预先定义的蒙板或注意力操纵。", "innovation": "DICE 是首个启用离散扩散模型精确反转的方法，适用于多项式扩散和蒙面生成模型。它能够准确重建和灵活编辑离散数据，同时无需预先定义的蒙板或注意力操纵，适用于图像和文本领域，评估表明 DICE 能够保持高数据保真度的同时增强编辑能力，为离散空间中细粒度内容操作提供新机会。", "conclusion": "DICE 通过逆向扩散过程中记录噪声序列和蒙面模式，使多项式扩散和蒙面生成模型的离散数据能够实现精确的重建和灵活的编辑，而不依赖于预先定义的蒙板或注意力操控。评估显示，DICE 能够保持数据的高保真度，提高编辑能力，为离散空间中的细粒度内容编辑提供了新的可能性。"}
{"llm_update_time": "20251116", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2410.05217", "html_url": "https://arxiv.org/abs/2410.05217", "title": "利用自然语言组织无结构图像集合", "title_en": "Organizing Unstructured Image Collections using Natural Language", "authors": "Mingxuan Liu,Zhun Zhong,Jun Li,Gianni Franchi,Subhankar Roy,Elisa Ricci", "background": "当前，自动组织和分类大型图像集合需要多样且自定义的语义聚类标准，而这些聚类标准通常需要预先设定的任务约束或固定数量的集群。现有的方法要么依赖于预定义的聚类标准，要么固定集群的数量。这篇论文的目标是在不需要任何人为输入的情况下，从大量无结构图像集合中自动发现和组织多样且自定义的语义聚类标准。", "innovation": "提出了一种名为X-Cluster（探索性聚类）的新框架，该框架利用文本作为推理代理，同时扫描整个图像集合，提出自然语言中的候选标准，并根据标准将图像分组成有意义的集群。这个方法与现有方法的不同之处在于，它允许自动发现多个多样化的聚类标准，而非依赖预定义的标准或固定数量的集群。通过这种方法，作者创新性地提供了一种无需人类干预即可组织和聚类大规模无结构图像集合的方法。此外，作者还创建了两个新的基准，COCO-4C和Food-4C，以评估X-Cluster的有效性，并探索将X-Cluster应用于文本到图像生成模型隐藏偏见的发现和社交媒体图像热度分析等实际用途。", "conclusion": "X-Cluster能够在多个数据集上有效地揭示有意义的分区，并在需要自动的图像聚类和组织的应用场景中表现出色。X-Cluster还能够揭示图像生成模型中的潜在偏差，并分析社交媒体上图像的传播情况。代码和数据集将开源，为未来的研究提供支持。"}
{"llm_update_time": "20251116", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2411.11343", "html_url": "https://arxiv.org/abs/2411.11343", "title": "由单个初始帧引导的潜在知识指导的视频扩散模型在科学现象生成中的应用", "title_en": "Latent Knowledge-Guided Video Diffusion for Scientific Phenomena Generation from a Single Initial Frame", "authors": "Qinglong Cao,Xirui Li,Ding Wang,Chao Ma,Yuntian Chen,Xiaokang Yang", "background": "视频扩散模型在生成自然场景方面取得了显著成果，但在处理遵循科学定律的科学现象如流体模拟和气象过程时遇到困难。这些任务带来了独特挑战，如严重的领域差距、有限的训练数据以及缺乏描述性语言注释。", "innovation": "该研究从单一初始帧出发，通过预训练的掩码自编码器提取静态知识，通过预先训练的光流预测提取动态知识。基于CLIP视觉和语言编码器之间的对齐空间关系，将科学现象的视觉嵌入在潜在科学现象知识的引导下投影到空间和频域中的伪语言提示嵌入。通过将这些提示融入并微调视频扩散模型，使生成的视频更符合科学定律。", "conclusion": "在计算流体动力学模拟和实际台风观察中的广泛实验表明，该方法具有优越的准确性和一致性，适用于各种科学场景。"}
{"llm_update_time": "20251116", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2411.10794", "html_url": "https://arxiv.org/abs/2411.10794", "title": "基于训练数据的图像异常合成", "title_en": "Image-based Outlier Synthesis With Training Data", "authors": "Sudarshan Regmi", "background": "深度学习模型在关键应用中的安全部署依赖于准确的异常值（Out-of-distribution, OOD）检测。传统的ODD检测方法主要针对相对简单的场景，并且大多数针对细粒度和虚假相关场景的方法都依赖于精心标注或合成的异常样本，这需要外部数据的支持。缺乏对细粒度和虚假相关场景中ODD检测的有效处理，尤其是在没有外部数据的情况下，是一个挑战。", "innovation": "本文提出了一种名为ASCOOD的统一框架，该框架在没有外部数据的情况下解决了细粒度和虚假相关场景中的ODD检测问题。ASCOOD通过合成虚拟异常样本和同时优化ID分类和预测不确定性，来应对虚假相关性的影响并捕捉细粒度属性，同时利用标准化特征和z-score归一化技术实现了这一目标。该方法在多种数据集上的实验证明了其在各类场景下的有效性。", "conclusion": "ASCOOD框架能够在没有外部数据的情况下有效解决细粒度和虚假相关场景中的ODD检测问题，展示了在多个数据集和多个方法比较中的优越性。"}
{"llm_update_time": "20251116", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2412.01090", "html_url": "https://arxiv.org/abs/2412.01090", "title": "STATIC: Surface Temporal Affine for Time Consistency in Video Monocular Depth Estimation", "title_en": "STATIC : Surface Temporal Affine for TIme Consistency in Video Monocular Depth Estimation", "authors": "Sunghun Yang,Minhyeok Lee,Suhwan Cho,Jungho Lee,Sangyoun Lee", "background": "单目视频深度估计对于自动驾驶、AR/VR和机器人技术等领域至关重要。尽管基于Transformer的单图像单目深度估计模型在单帧上表现良好，但在视频帧之间的深度一致性方面存在挑战。传统方法通过多帧时间模块或先验信息（如光流和相机参数）来提高时间一致性，但这些方法面临着高内存使用、动态或不规则运动时性能下降以及运动理解有限的问题。", "innovation": "我们提出了STATIC模型，该模型独立地在静态和动态区域学习时间一致性，无需额外信息。通过表面法线差异掩码识别静态和动态区域，并通过方向方差测量。对于静态区域，Masked Static (MS) 模块通过关注稳定的区域来增强时间一致性。对于动态区域，Surface Normal Similarity (SNS) 模块通过测量帧间特征相似性来对齐区域并增强时间一致性。最后，通过集成独立学习的静态和动态区域，STATIC能够在整个序列中实现时间一致性。该方法在KITTIL和NYUv2数据集上达到了最新的视频深度估计效果，无需额外信息。", "conclusion": "我们的方法在没有任何附加信息的情况下，在KITTIL和NYUv2数据集上实现了最先进的视频深度估计效果，显著提高了在同一序列中保持深度一致性的能力。"}
{"llm_update_time": "20251116", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2411.12791", "html_url": "https://arxiv.org/abs/2411.12791", "title": "缓解感知偏见：基于无训练的增强方法提升大模型在图像质量评估中的性能", "title_en": "Mitigating Perception Bias: A Training-Free Approach to Enhance LMM for Image Quality Assessment", "authors": "Baoliang Chen,Siyi Pan,Dongxu Wu,Liang Xie,Xiangjie Sui,Lingyu Zhu,Hanwei Zhu", "background": "尽管大型多模态模型（LMMs）在高级视觉任务中表现出色，但在图像质量评估（IQA）方面的能力仍然有限。主要原因在于LMMs主要被训练服务于高级任务（如图像标注），强调在不同质量标准下的统一图像语义提取。这种语义意识但质量不敏感的感知偏差导致在要求LMM进行质量评估时，它们对图像语义的依赖性很强。因此，该论文旨在通过无训练的去偏见框架来改善LMM在IQA中的性能，以纠正由于图像语义造成的感知偏差。", "innovation": "论文创新地提出了一种无训练的去偏见框架，通过减轻由图像语义引发的偏差来纠正图像质量预测。具体来说，构建了一种可以显著降低图像质量但同时保留可识别语义的语义保留式失真方法，然后通过将查询或测试图像及其受这些特定位移影响的版本与一个提示一起输入LMM来实施质量推理。该提示确保降质图像被视为质量差，语义保持不变。最后，使用条件概率模型聚合在不同先验条件下推断出的质量得分。实验结果表明，论文提出的去偏见框架可以一致地提升LMM在IQA中的性能。", "conclusion": "大量实验表明，论文提出的无训练的去偏见框架能够一致地提升LMM的IQA性能，即通过减轻图像语义感知偏差，使LMM在质量评估中更关注图像质量本身而非语义，从而提高了评估的准确性和可靠性。"}
{"llm_update_time": "20251116", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2412.02054", "html_url": "https://arxiv.org/abs/2412.02054", "title": "DETR基3D检测方法中的冗余查询：不必要的可修剪部分", "title_en": "Redundant Queries in DETR-Based 3D Detection Methods: Unnecessary and Prunable", "authors": "Lizhen Xu,Zehao Wu,Wenzhao Qiu,Shanmin Pang,Xiuxiu Bai,Kuizhi Mei,Jianru Xue", "background": "在3D物体检测任务中，查询为基础的模型被广泛使用，并且有大量的预训练模型可供在线使用。尽管这些模型非常流行，但它们通常需要远超过实际需要检测的对象数量的查询，这导致了不必要的计算和内存开销。研究观察到，不是所有查询都具有相同的贡献度，许多查询的影响远小于其他查询。", "innovation": "提出了一种简单的方法，称作Gradually Pruning Queries (GPQ)，该方法基于分类分数逐步修剪查询。GPQ的一个关键优点是不需要额外的学习参数，并且可以无缝集成到任何基于查询的方法中，作为训练后的一个微调步骤。使用GPQ，用户可以从具有过多查询的模型开始，轻松生成具有更少查询的多个模型。实验表明，GPQ可以在保持性能的同时有效减少冗余查询，桌面GPU的推理加速可以高达1.35倍。部署在边缘设备上时，它实现了高达67.86%的FLOPs减少和65.16%的推理时间减少。", "conclusion": "通过GPQ，可以很容易地减少模型中的冗余查询，从而加速推理过程并降低计算和内存成本。已经对各种高级3D检测器进行了实验，表明GPQ在保持性能的同时有效地减少了冗余查询，特别是在边缘设备上的部署。项目代码已公开在指定网站上。"}
{"llm_update_time": "20251116", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2501.16289", "html_url": "https://arxiv.org/abs/2501.16289", "title": "多视角结构卷积网络在自主驾驶车辆领域不变点云识别中的应用", "title_en": "Multi-view Structural Convolution Network for Domain-Invariant Point Cloud Recognition of Autonomous Vehicles", "authors": "Younggun Kim,Mohamed Abdel-Aty,Beomsik Cho,Seonghoon Ryoo,Soomok Lee", "background": "点云表示在计算机视觉领域已成为研究热点，并被用于自动驾驶车辆中。然而，将深度学习网络应用于点云数据识别因数据集和传感器技术的变异性而具有挑战性。这种变异性强调了适应性技术的必要性，以在不同条件下保持准确性。", "innovation": "提出了多视角结构卷积网络(MSCN)，用于领域不变的点云识别。MSCN 包括结构卷积层(SCL)，用于从点云中提取局部上下文几何特征，以及结构聚合层(SAL)，用于从点云中提取和聚合局部和整体上下文特征。此外，MSCN 通过使用来自源域的未见过的领域点云进行训练，增强了特征的鲁棒性，使模型能够获得领域不变的表示。", "conclusion": "大量的跨域实验表明，MSCN实现了82.0%的平均精度，超过了强大的基线 PointTransformer 15.8%，证实了其在真实世界领域转移下的有效性。我们的代码可在以下链接访问：this https URL"}
{"llm_update_time": "20251116", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2412.06465", "html_url": "https://arxiv.org/abs/2412.06465", "title": "超越RGB的智能体之旅：Vision-and-Language Navigation中的分层语义-空间表示增强", "title_en": "Agent Journey Beyond RGB: Hierarchical Semantic-Spatial Representation Enrichment for Vision-and-Language Navigation", "authors": "Xuesong Zhang,Yunbo Xu,Jia Li,Ruonan Liu,Zhenzhen Hu", "background": "在Vision-and-Language Navigation (VLN)领域中，基于自身视角的自主代理从自然语言指令中引导未见过的环境依旧具有挑战性。人类在室内导航时能够自然地将具体的语义知识与空间布局联系起来。尽管前人工作引入了多种环境表示形式来提升推理能力，但辅助模态通常简单地与RGB特征拼接在一起，这未能充分利用每种模态的独特贡献。", "innovation": "本文提出了一种分层语义理解和空间意识（SUSA）架构，使代理能够在多个尺度上感知和语义化环境。具体而言，文本语义理解（TSU）模块通过生成视图级描述来支持局部动作预测，捕捉细粒度语义并将指令与环境之间的模态差距缩小。互补地，深度增强的空间感知（DSP）模块逐步构建轨迹级深度探索图，提供全局空间布局的粗粒度表示。", "conclusion": "实验证明，SUSA层次结构表示的增强显著提高了对离散VLN基准(REVERIE, R2R, SOON)的导航性能，并在连续的R2R-CE基准上表现出更好的泛化能力。"}
{"llm_update_time": "20251116", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2502.00266", "html_url": "https://arxiv.org/abs/2502.00266", "title": "MCM: 多层概念图，用于从掩码图像中高效学习概念", "title_en": "MCM: Multi-layer Concept Map for Efficient Concept Learning from Masked Images", "authors": "Yuwei Sun,Lu Mi,Ippei Fujisawa,Ruiqiao Mei,Jimin Chen,Siyu Zhu,Ryota Kanai", "background": "在图像概念学习任务中，传统的视觉方法通常依赖于完整的图像输入，而自然语言处理中的掩码策略尚未充分应用于视觉任务中。为了改变这一现状，作者提出了一种新的方法，利用掩码图像来提高概念学习的效率和效果。", "innovation": "作者提出了Multi-layer Concept Map（MCM），首次设计了一种基于掩码图像的概念学习方法。该方法通过在不同编码器和解码器层之间建立关联，并利用重建任务的反向梯度更新概念令牌，从而实现了高效的多层概念学习。这种方法不仅减少了计算成本，还在保持概念预测性能方面表现出色，并且能够在遮罩图像中进行特定概念令牌的编辑以生成目标图像。", "conclusion": "实验结果显示，MCM 能够显著降低计算成本，通过使用少于 75% 的图像补丁进行训练，同时提升了概念预测的性能。此外，该方法在遮罩图像中通过编辑特定的概念令牌能够实现有针对性的图像生成，通过调整测试时的遮罩比例，还能够产生不同比例的图像重建结果，将可见的图像补丁与提供的概念融合在一起。"}
{"llm_update_time": "20251116", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2412.09959", "html_url": "https://arxiv.org/abs/2412.09959", "title": "通过扩散驱动选择实现一致且高效的数据集蒸馏", "title_en": "Towards Consistent and Efficient Dataset Distillation via Diffusion-Driven Selection", "authors": "Xinhao Zhong,Shuoyang Sun,Xulin Gu,Zhaoyang Xu,Yaowei Wang,Min Zhang,Bin Chen", "background": "数据集蒸馏提供了一种有效的方法，通过优化一个紧凑的数据集来降低内存和计算成本，该紧凑数据集的性能与全量原始数据集相当。但对于大规模数据集和复杂的深度网络（如带有ResNet-101的ImageNet-1K），庞大的优化空间限制了蒸馏的有效性，从而限制了其实用应用。最近的方法利用预训练的扩散模型直接生成具有信息量的图像，从而绕过像素级优化并取得令人瞩目的结果。然而，这些方法通常会遇到预训练的扩散模型先验分布与目标数据集之间的分布偏移问题，以及在不同设置下需要多步蒸馏的问题。", "innovation": "本文提出了一种新颖的框架，该框架与现有的扩散驱动蒸馏技术正交，通过利用扩散先验用于补丁选择而不是生成。该方法基于输入图像和可选的文本提示（有或无标签信息），从扩散模型中预测噪声并计算每个图像补丁对相关的损失。基于损失差异，该方法识别出原始图像中的独特区域。此外，该方法在所选补丁上应用类内聚类和排名以施加多样性约束，从而简化了流程，可以在一步中完成蒸馏过程。", "conclusion": "广泛的实验证明，本文的方法在各种指标和设置下都优于最先进的方法。"}
{"llm_update_time": "20251116", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2502.09125", "html_url": "https://arxiv.org/abs/2502.09125", "title": "基于类内信息的增强结构化拉索剪枝", "title_en": "Enhanced Structured Lasso Pruning with Class-wise Information", "authors": "Xiang Liu,Mingchen Li,Xia Li,Leigang Qu,Guangsu Wang,Zifan Peng,Yijun Song,Zemin Liu,Linshan Jiang,Jialin Li", "background": "现代应用需要轻量级的神经网络模型。现有的许多神经网络剪枝方法主要集中在移除不重要的滤波器，但这种做法可能会在剪枝后导致统计信息损失，因为它没有考虑到类别的信息。", "innovation": "本文从利用精确的类内信息的角度出发，引入了结构化拉索和Information Bottleneck理论来指导模型剪枝，以确保剪枝前后统计信息的保留。提出了两种新的适应性网络剪枝方案：基于稀疏图结构拉索和Information Bottleneck (sGLP-IB) 以及基于稀疏树引导拉索和Information Bottleneck (sTLP-IB)。通过精确利用类内相关性对模型滤波器进行剪枝。", "conclusion": "与多个最先进的方法相比，本文的方法在三个数据集和六种模型结构的大量实验中均取得了最优性能。例如，在基于CIFAR-10数据集的VGG16模型上，参数减少了85%，FLOPs减少了61%，准确度保持在94.10% (比原版高0.14%)。对于大规模的ImageNet数据集，使用ResNet架构，参数减少了55%，准确度保持在76.12%（仅降低了0.03%）。总之，我们成功地减少了模型尺寸和计算资源的使用，同时保持了准确性的有效性。"}
{"llm_update_time": "20251116", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2503.09399", "html_url": "https://arxiv.org/abs/2503.09399", "title": "ForAug: 通过重组前景和背景改进视觉变换器训练以减少偏见", "title_en": "ForAug: Recombining Foregrounds and Backgrounds to Improve Vision Transformer Training with Bias Mitigation", "authors": "Tobias Christian Nauen,Brian Moser,Federico Raue,Stanislav Frolov,Andreas Dengel", "background": "Transformers，特别是Vision Transformers (ViTs)，在大规模图像分类任务中取得了最先进的性能。然而，它们通常需要大量的数据，并且可能表现出偏见，这限制了它们的鲁棒性和通用性。", "innovation": "引入ForAug，一种新颖的数据增强方案，它通过使用预训练的基础模型来分离和重组前景对象与不同的背景，将常见的归纳偏置纳入训练数据中。这种方法增加了数据多样性，并提高了有效的训练样本数量。研究表明，使用ForAug处理的ForNet在ImageNet上的准确率提高了4.5个百分点，在下游任务上的准确率提高了7.3个百分点。此外，ForAug还提供了一种分析和量化模型行为以及偏见的新方法。", "conclusion": "ForAug为分析和减少偏见提供了一个有价值的工具，有助于开发更稳健和可靠的计算机视觉模型。我们的代码和数据集可在此公开访问：[此链接]。"}
{"llm_update_time": "20251116", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2503.06161", "html_url": "https://arxiv.org/abs/2503.06161", "title": "特征内镜高斯：手术可变形场景重建中提取特征的高斯喷溅", "title_en": "Feature-EndoGaussian: Feature Distilled Gaussian Splatting in Surgical Deformable Scene Reconstruction", "authors": "Kai Li,Junhao Wang,William Han,Ding Zhao", "background": "微创手术（MIS）需要高保真、实时的视觉反馈，以处理动态且低纹理的手术场景。如何满足这一需求是当前面临的一个挑战。现有技术要么受限于静态场景，要么缺少语义集成，无法提供实时且高保真的视图反馈。", "innovation": "本文提出了FeatureEndo-4DGS (FE-4DGS)，这是首个利用特征提取的4D高斯喷溅实时管道，实现了可变形手术环境的实时重建和语义分割。FE-4DGS 的创新之处在于它可以无缝地利用预训练的2D语义嵌入生成统一的4D表示，其中语义信息会随着组织运动变化。这一统一方法通过单一并行化的光栅化过程能够实时生成RGB和语义输出，同时处理特征提取的复杂度，仍能实现即时渲染（61 FPS），并且在EndoNeRF中实现了最先进的渲染保真度（39.1 PSNR）和SCARED（27.3 PSNR），在EndoVis18分割任务上也表现出了竞争力，与强大的2D基线相比，在二分类任务中达到了0.93 DSC，在多标签分割任务中保持了竞争力，得分为0.77 DSC。", "conclusion": "FE-4DGS能够提供高保真、实时的视图反馈，并且具体在二分类和多标签分割任务中展示了优于现有方法的性能。"}
{"llm_update_time": "20251116", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2503.02034", "html_url": "https://arxiv.org/abs/2503.02034", "title": "Abn-BLIP: 异常对齐的逐步语言-图像预训练模型用于CTPA肺栓塞诊断及报告生成", "title_en": "Abn-BLIP: Abnormality-aligned Bootstrapping Language-Image Pre-training for Pulmonary Embolism Diagnosis and Report Generation from CTPA", "authors": "Zhusi Zhong,Yuli Wang,Lulu Bi,Zhuoqi Ma,Sun Ho Ahn,Christopher J. Mullin,Colin F. Greineder,Michael K. Atalay,Scott Collins,Grayson L. Baird,Cheng Ting Lin,Webster Stayman,Todd M. Kolb,Ihab Kamel,Harrison X. Bai,Zhicheng Jiao", "background": "医学影像在现代医疗中起着关键作用，特别是CT肺动脉造影（CTPA）是诊断肺栓塞和其他胸部疾病的重要工具。然而，解读CTPA扫描结果并生成准确的放射学报告仍是一个重大挑战。当前，尚未有一个能有效解决这一问题的模型，传统方法在检测异常和生成结构化报告方面表现不佳。因此，该研究旨在开发一种先进的诊断模型Abn-BLIP，以更好地进行异常标记，生成准确且全面的放射学报告。通过利用学习查询和跨模态注意力机制，模型在检测异常、减少遗漏和生成结构化报告方面显示出优于现有方法的性能。实验结果表明，Abn-BLIP在准确性和临床相关性方面均优于现有的医学视觉语言模型和3D报告生成方法。", "innovation": "该研究创新地提出了一种名为Abn-BLIP的先进诊断模型，该模型在医疗视觉-语言预训练模型的基础上，通过包括可学习查询和跨模态注意力机制在内的技术，显著提升了CTPA图像中异常检测的准确率和报告结构化生成的全面性。与现有的方法相比，Abn-BLIP在检测异常、减少漏诊以及生成结构化报告方面的表现更为出色。模型引入的学习查询机制能够有效识别和定位CTPA影像中的异常区域，而跨模态注意力机制则促进了图像与文本之间的有效关联，从而提升报告的诊断准确性和临床相关性。", "conclusion": "研究结果表明，结合多模态学习策略的Abn-BLIP模型在CTPA肺栓塞诊断及报告生成方面表现突出，能够显著提升报告的准确性和临床相关性，展示了其在改善放射学报告和诊断方面的巨大潜力，为今后相关研究提供了新的思路和技术参考。实验结果和源代码已公开。"}
{"llm_update_time": "20251116", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2503.19361", "html_url": "https://arxiv.org/abs/2503.19361", "title": "ImageSet2Text：通过文本描述图像集", "title_en": "ImageSet2Text: Describing Sets of Images through Text", "authors": "Piera Riccio,Francesco Galati,Kajetan Schweighofer,Noa Garcia,Nuria Oliver", "background": "在大规模视觉数据时代，理解图像集合是一项具有挑战性但又重要的任务。已有的方法难以有效地生成自然而准确的图像集合描述。为此，本文提出了一种基于大型语言模型、视觉问答链、外部词典图和CLIP基验证的新方法ImageSet2Text，旨在自动为图像集合生成自然语言描述。这种方法通过迭代提取图像子集的关键概念，并将其组织成结构化的概念图来实现这一目标。实验和评估结果显示，ImageSet2Text 方法能够可靠地总结广泛的图像集合应用。", "innovation": "ImageSet2Text方法创新性地结合了数据驱动的AI技术和符号表示方法，能够通过迭代地提取图像子集的关键概念并组织成结构化的概念图，从而有效地自动生成自然语言描述。这种方法基于大型语言模型、视觉问答链、外部词典图和CLIP基验证，特别适用于大规模图像集合的理解任务。", "conclusion": "通过广泛的实验评估，本文证明了ImageSet2Text方法在准确性、完整性和用户满意度方面的优越性。此外，通过消融研究、可扩展性评估和失败分析，进一步证实了其可靠性和适用范围。ImageSet2Text方法为图像集合理解和自然语言生成提供了新的解决方案，尤其适用于多种应用场景。"}
{"llm_update_time": "20251116", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2505.11881", "html_url": "https://arxiv.org/abs/2505.11881", "title": "重访残差连接：促进稳定而高效的深度网络的正交更新", "title_en": "Revisiting Residual Connections: Orthogonal Updates for Stable and Efficient Deep Networks", "authors": "Giyeong Oh,Woohyun Cho,Siyeol Kim,Suhwan Choi,Youngjae Yu", "background": "残差连接对深度神经网络至关重要，通过减轻梯度消失问题，使网络能够达到更深的层次。然而，在标准的残差更新中，模块的输出直接添加到输入流中，这可能导致更新主要强化或调节现有的流方向，从而可能未能充分利用模块学习全新特征的能力。", "innovation": "提出了正交残差更新：将模块的输出相对于输入流分解，并仅添加该流正交的部分。此设计旨在引导模块主要贡献新的表示方向，从而促进更丰富特征的学习并促进更高效的训练。", "conclusion": "结果表明，我们的正交更新策略在各种架构（如ResNetV2、Vision Transformers）和数据集（如CIFARs、TinyImageNet、ImageNet-1k）上提高了泛化准确性和训练稳定性，例如在ImageNet-1k上的ViT-B模型上实现了3.78个百分点的top-1准确性提升。"}
{"llm_update_time": "20251116", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2505.13928", "html_url": "https://arxiv.org/abs/2505.13928", "title": "LoVR：多模态背景下长视频检索的基准", "title_en": "LoVR: A Benchmark for Long Video Retrieval in Multimodal Contexts", "authors": "Qifeng Cai,Hao Liang,Hejun Dong,Meiyi Qiang,Ruichuan An,Zhaoyang Han,Zhengzhou Zhu,Bin Cui,Wentao Zhang", "background": "长视频包含了大量信息，使得视频-文本检索成为多模态学习中重要且具有挑战性的任务。然而，现有的基准测试在视频时长、caption质量及标注粒度等方面存在不足，限制了先进视频-文本检索方法的评估。", "innovation": "本文提出了专门设计用于长视频-文本检索的LoVR基准测试。该基准包含467个长视频和40,804个高质量的细粒度片段，还提出了一种高效的caption生成框架，用于克服机器生成标注质量差的问题。此外，引入了一种语义融合方法，生成连贯的全视频caption，同时保留重要上下文信息。", "conclusion": "通过在多种先进的嵌入模型上的广泛实验，证明LoVR是一个具有挑战性的基准测试，揭示了当前方法的局限性，并为未来研究提供了有价值的见解。"}
{"llm_update_time": "20251116", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2504.14396", "html_url": "https://arxiv.org/abs/2504.14396", "title": "SphereDiff: Tuning-free 360° Static and Dynamic Panorama Generation via Spherical Latent Representation", "title_en": "SphereDiff: Tuning-free 360° Static and Dynamic Panorama Generation via Spherical Latent Representation", "authors": "Minho Park,Taewoong Kang,Jooyeol Yun,Sungwon Hwang,Jaegul Choo", "background": "随着AR/VR应用需求的增加，高质量的内容，如360°全景壁纸变得越来越重要。然而，由于equirectangular投影（ERP）引入的严重失真，生成高质量的360°全景内容仍然是一个挑战。现有方法要么在有限的ERP数据集上微调预训练的扩散模型，要么采用无需微调的方法，但这些方法仍然依赖于ERP的潜在表示，经常会在极点附近产生引人分神的失真.", "innovation": "本文介绍了一种名为SphereDiff的新颖方法，用于通过球形潜在表示合成360°静态和动态壁纸，无需额外的微调即可与最先进的扩散模型兼容。通过定义确保所有视角一致质量的球形潜在表示，以及扩展MultiDiffusion并提出动态球形潜在采样方法，直接利用预训练的扩散模型。此外，引入了失真感知加权平均，以进一步提高生成质量。SphereDiff方法在生成360°静态和动态壁纸方面优于现有方法，为沉浸式AR/VR应用提供了一个稳健的解决方案.", "conclusion": "SphereDiff方法在生成360°静态和动态壁纸方面超越了现有方法，为企业提供了创造高质量全景壁纸的稳健解决方案，适用于AR/VR应用。"}
{"llm_update_time": "20251116", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2505.15176", "html_url": "https://arxiv.org/abs/2505.15176", "title": "使用有限数据集提高步态识别的泛化能力", "title_en": "Improving the generalization of gait recognition with limited datasets", "authors": "Qian Zhou,Xianda Guo,Jilong Wang,Chuanfu Shen,Zhongyuan Wang,Zhen Han,Qin Zou,Shiqi Yu", "background": "步态识别在不同视角、外观和环境之间的显著领域偏移下仍具有挑战性。混合数据集训练已成为提高跨域鲁棒性的一种实用途径，但这种方法引入了未探索的问题：数据集间的监督冲突，会分散身份学习；冗余或噪声样本，会降低数据效率并可能强化数据集特定模式。", "innovation": "本文提出了一种统一的跨数据集步态学习范式，该范式同时改善了运动信号质量和监督一致性。首先，通过抑制由冗余步态周期或不稳定轮廓主导的序列来提高训练数据的可靠性，这些是根据表示冗余性和预测不确定性引导的。其次，通过在每个数据源内形成三重组来稳定监督，防止破坏性跨域梯度，同时保留可转移的身份线索。", "conclusion": "在CASIA-B、OU-MVLP、Gait3D和GREW上的实验表明，在使用GaitBase和DeepGaitV2骨干网络的情况下，该方法能够提升跨域性能，同时不牺牲领域内准确性。结果表明，数据选择和调整监督可以有效实现可扩展的混合数据集步态学习。"}
{"llm_update_time": "20251116", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2505.05469", "html_url": "https://arxiv.org/abs/2505.05469", "title": "从文本生成物理稳定且可构建的砖结构", "title_en": "Generating Physically Stable and Buildable Brick Structures from Text", "authors": "Ava Pun,Kangle Deng,Ruixuan Liu,Deva Ramanan,Changliu Liu,Jun-Yan Zhu", "background": "当前，存在从文本生成砖结构的需求，但现有的方法往往无法生成物理上稳定的砖结构。本研究旨在填补这一空白，通过构建一个大规模的物理上稳定的砖结构数据集，并训练一个自回归大语言模型，预测添加后的下一个砖块。同时，利用物理法则和装配约束优化设计，使得生成的砖结构既稳定又美观，能够与输入的文本提示保持高度一致。此外，还开发了一种基于文本的砖纹理生成方法，生成彩色且多样化的设计。", "innovation": "提出了一种名为BrickGPT的方法，可以生成从文本提示中生成物理稳定且可装配的砖结构模型。通过大规模的砖结构数据集训练，结合自回归模型和先进的物理验证技术，优化生成的砖结构。引入了一种高效的有效性检查和物理感知回滚机制，用于自回归推理过程中排除不切实际的预测，从而提高设计的稳定性。同时，开发了基于文本的砖纹理生成方法，增强了设计的多样性和美观性。", "conclusion": "实验表明，BrickGPT生成的砖结构是稳定的、多样的且外观满足用户需求，能够很好地与输入的文本提示对齐。除此外，还展示了这种砖结构在人工和机器人装配方面的可行性。项目还发布了包含超过47,000个砖结构物体的数据集以及相应的代码和模型。"}
{"llm_update_time": "20251116", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2506.21912", "html_url": "https://arxiv.org/abs/2506.21912", "title": "从文本提示生成属性感知的人类动作", "title_en": "Generating Attribute-Aware Human Motions from Textual Prompt", "authors": "Xinghan Wang,Kun Xu,Fei Li,Cao Sheng,Jiazhong Yu,Yadong Mu", "background": "文本驱动的人体动作生成近年来引起了广泛关注，但现有的方法往往忽视了年龄、性别、体重和身高等人属性的影响，这些因素对人类动作模式有着重要影响。该研究旨在填补这一缺口，将动作分解为属性信息和动作语义，通过一种新的框架实现文本到动作语义的预测，并通过设定的用户属性输入生成相应的动作。", "innovation": "提出了一种由结构因果模型启发的新框架，能够解耦动作语义和人属性，实现基于文本的语义预测和属性控制的动作生成。该研究还引入了一个包含属性注释的综合数据集，作为属性感知动作生成的第一个基准。", "conclusion": "通过大量实验验证了模型的有效性，能够根据用户的文本和属性输入生成属性感知的动作。"}
{"llm_update_time": "20251116", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2506.11616", "html_url": "https://arxiv.org/abs/2506.11616", "title": "Wi-CBR: Salient-aware Adaptive WiFi Sensing for Cross-domain Behavior Recognition", "title_en": "Wi-CBR: Salient-aware Adaptive WiFi Sensing for Cross-domain Behavior Recognition", "authors": "Ruobei Zhang,Shengeng Tang,Huan Yan,Xiang Zhang,Jiabao Guo", "background": "WiFi-based cross-domain Behavior Recognition面临主要挑战是不同领域的特定信号对手势变化的显著干扰。之前的解决方法是将多个域的相位映射到一个公共特征空间来缓解这种干扰。使用多普勒频移信号(Doppler Frequency Shift, DFS)动态补充相位特征，可以实现更好的泛化，并使模型不仅能够探索更广泛的特征空间，而且能够避免手势语义信息的潜在降解。", "innovation": "本研究提出了一种新的Wi-CBR (Salient-aware Adaptive WiFi Sensing for Cross-domain Behavior Recognition)，该方法构建了一个双分支自注意力模块，用于从反映动态路径长度变化的相位信息中捕获时序特征，并从DFS中提取与运动速度相关的动力学特征。此外，设计了一种引导显著性模块，采用了组注意力机制挖掘关键活动特征，并利用门控机制优化信息熵，促进特征融合，实现显著性和非显著行为特征的有效交互。", "conclusion": "在两个大规模公共数据集（Widar3.0和XRF55）上的广泛实验表明，本方法在域内和跨域场景中都表现出优越性能。"}
{"llm_update_time": "20251116", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2505.23740", "html_url": "https://arxiv.org/abs/2505.23740", "title": "LayerPeeler: 自回归去层化用于分层图像矢量化", "title_en": "LayerPeeler: Autoregressive Peeling for Layer-wise Image Vectorization", "authors": "Ronghuan Wu,Wanchao Su,Jing Liao", "background": "图像矢量化是一种将栅格图像转换为矢量图形的强大技术，可以增强灵活性和交互性。但现有的矢量化工具在处理被遮挡区域时存在局限性，导致生成的形状不完整或碎片化，影响编辑性。虽然近年来基于优化和基于学习的逐层矢量化有了一定进展，但在矢量化质量和灵活性方面仍存在问题。", "innovation": "引入了一种新颖的逐层图像矢量化方法——LayerPeeler，通过逐步简化范式解决上述挑战。LayerPeeler 的关键在于其自回归剥除策略：通过识别和移除最顶层未被遮挡的图层并恢复底层内容，生成完整的路径和连贯的分层结构。该方法利用视觉语言模型构建层图，捕捉元素之间的遮挡关系，实现精准检测和描述未被遮挡的图层。这些描述性的标题作为编辑指令，用于微调的图像扩散模型来移除识别出的图层。为了确保准确去除，采用了局部注意力控制，精确引导模型针对目标区域并忠实保留周围内容。为了支持这一点，还贡献了一个专用的大规模数据集供分层剥离任务使用。广泛的质量和定量实验表明，LayerPeeler 显著优于现有技术，提供具有优越路径语义、几何规整性和视觉保真的矢量化结果。", "conclusion": "实验结果表明，LayerPeeler 在路径语义、几何规整性和视觉保真度方面显著优于现有技术。"}
{"llm_update_time": "20251116", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.10496", "html_url": "https://arxiv.org/abs/2507.10496", "title": "相机作为相对位置编码", "title_en": "Cameras as Relative Positional Encoding", "authors": "Ruilong Li,Brent Yi,Junchen Liu,Hang Gao,Yi Ma,Angjoo Kanazawa", "background": "在多视角计算机视觉任务中，Transformer模型因能利用几何关系进行3D感知而越来越受欢迎。为了充分利用这些关系，多视角Transformer必须结合相机几何信息，将视觉感知实体具象化到三维空间中。", "innovation": "本文提出了“投影位置编码”(PRoPE)，这是一种全新的相对位置编码方法，它能够捕捉完整相机视锥体，包括内参数和外参数，从而在多视角Transformer中有效利用相机几何信息。通过对比分析不同条件化方法，包括基于token的raymap编码、基于attention的相对姿态编码以及PRoPE，研究证实了相对相机条件化能够显著提高模型在新颖视角合成等任务中的性能，特别是当模型规模增大时效果更加显著。", "conclusion": "实验结果表明，在新颖视角合成、立体深度估计和分布外输入场景中，基于相对姿态的条件化方法能够带来性能提升，而PRoPE作为新的相对位置编码方案，展示了其在多视角Transformer模型中的潜力，尤其是在大模型规模下的性能增益。这一方法为多视角Transformer在未来研究中的应用提供了新的思路。"}
{"llm_update_time": "20251116", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2505.21538", "html_url": "https://arxiv.org/abs/2505.21538", "title": "Caption This, Reason That: VLMs Caught in the Middle", "title_en": "Caption This, Reason That: VLMs Caught in the Middle", "authors": "Zihan Weng,Lucas Gomez,Taylor Whittington Webb,Pouya Bashivan", "background": "视觉-语言模型（VLMs）近年来在视觉理解方面取得了显著进展，但在特定任务（如计数或关系推理）上仍落后于人类的能力。为了解这些局限性，作者采用了认知科学的方法，分析VLM在感知、注意力和记忆等核心认知轴上的表现。使用一系列测试这些能力的任务，评估了最先进的VLM，包括GPT-4o。研究表明，虽然高级模型在某些任务（如类别识别）上接近天花板效应，但在需要空间理解或选择性注意力的任务上仍存在显著差距。进一步分析发现，那些在直接视觉推理方面表现较弱的模型，在通过自己的生成文本描述进行推理时表现出明显改善。这些实验证明了改进VLM连贯推理能力的迫切需求，即使这些模型在多次超过人类表现的情况下也是如此。此外，还展示了针对复合视觉推理任务进行有目标微调的潜力，并证明了微调较小的VLM可以显著提高核心认知能力。不过，这些改进并未在具有挑战性的、分布外基准上转化为显著增强。我们的研究以多种数据集为载体，展示了VLM在其他基准上的表现与其在我们数据集上的表现之间的强烈关联。", "innovation": "1. 采用认知科学的方法，分析VLM在感知、注意力和记忆等核心认知轴上的表现，识别任务之间的不匹配。\n2. 使用视觉-文本解耦分析，发现生成文本描述可以显著提高VLM直接视觉推理能力，强调了改进VLM连贯推理能力的重要性。\n3. 展示了有目标微调较小VLM可以显著提高核心认知能力，尽管未在所有分布外基准上取得显著改善，但显示出强烈的关联性。\n4. 指出了视觉和推理同时进行时的关键瓶颈，并提出了解决方案。", "conclusion": "本研究表明，尽管最先进的VLMs在某些任务上接近或超越了人类的能力，但在空间理解和选择性注意力任务上仍存在显著差距。通过视觉-文本解耦分析，发现生成文本描述可以显著提高VLM直接视觉推理能力，强调了改进VLM连贯推理能力的迫切需求。进一步展示了有目标微调较小VLM可以显著提高核心认知能力，并且该方法在其他基准上的表现与其在数据集上的表现之间存在强烈的相关性。"}
{"llm_update_time": "20251116", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2506.18925", "html_url": "https://arxiv.org/abs/2506.18925", "title": "Parkinson 疾病中基于视频的可解释且细腻的指尖敲击测验运动特征量化", "title_en": "Interpretable and Granular Video-Based Quantification of Motor Characteristics from the Finger Tapping Test in Parkinson Disease", "authors": "Tahereh Zarrat Ehsan,Michael Tangermann,Yağmur Güçlütürk,Bastiaan R. Bloem,Luc J. W. Evers", "background": "准确量化帕金森病（PD）的运动特征对于监测疾病进展和优化治疗策略至关重要。指尖敲击测试是标准的运动评估方法。然而，临床医生基于敲击幅度、速度和不规则性进行主观评价并打分，这容易受到评分者之间和评分者内部的一致性问题，不能提供敲击过程中的个体运动特征见解。", "innovation": "本文提出了一种基于计算机视觉的细粒度方法，用于从视频记录中量化PD运动特征。文中提出了四组临床相关特征来描述运动不足、动作迟缓、序列效应和犹豫-停顿。通过视频记录和74名患者的临床评估，展示了基于视频的特征与四种缺陷之间的关系。这些视频分析还允许进一步识别序列效应和犹豫-停顿缺陷的精细差异。利用这些特征，训练了机器学习分类器来估计运动障碍学会统一帕金森病评定量表（MDS-UPDRS）的指尖敲击得分。与最先进的方法相比，本文的方法在MDS-UPDRS评分预测方面具有更高的准确性，同时仍提供可解释的个体指尖敲击运动特征量化。", "conclusion": "提出的框架提供了一种实用的PD运动特征客观评估解决方案，可以在临床和远程环境中应用。未来的工作将评估其对症状治疗和疾病进展的敏感性。"}
{"llm_update_time": "20251116", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.19110", "html_url": "https://arxiv.org/abs/2507.19110", "title": "LISA: 层级集成与抑制方法以减轻多模态大规模语言模型中的幻觉", "title_en": "LISA: A Layer-wise Integration and Suppression Approach for Hallucination Mitigation in Multimodal Large Language Models", "authors": "Zhihui Guo,Xin Man,Hui Xu,Jie Shao,Zhiguo Jiang,Xianchao Zhang,Heng Tao Shen", "background": "多模态大语言模型（MLLMs）在视觉-语言任务（例如图像字幕）中表现出色，但在这些任务中，它们仍容易出现对象幻觉现象，即它们会描述图像中不存在的对象。这种现象限制了MLLMs的实际应用效果。", "innovation": "本文提出了一种名为LISA（层级集成与抑制方法）的方法，用来减轻MLLMs中的对象幻觉现象。LISA利用了MLLMs中不同层级的功能作用：浅层部分提供视觉锚定，中间层编码语义信息，深层部分则倾向于放大虚假信号。LISA通过逐层光谱调制来稳定注意力，抑制过放大激活，并保留先前层的对齐线索。此外，通过基于锚点的路由机制，逐token级的锚点选择与软logit融合实现解码过程中的适应性集成。LISA具有全插即用功能，可无缝集成到现有的MLLMs中。", "conclusion": "实验表明，LISA在多个基准上将幻觉减少了高达53.6%，并提高了POPE F1分数高达5.1%，证明了LISA在不同模型和任务上的强大泛化能力。"}
{"llm_update_time": "20251116", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.05615", "html_url": "https://arxiv.org/abs/2508.05615", "title": "基于区域一致性的测试时强化学习用于GUI接地", "title_en": "Test-Time Reinforcement Learning for GUI Grounding via Region Consistency", "authors": "Yong Du,Yuchen Yan,Fei Tang,Zhengxi Lu,Chang Zong,Weiming Lu,Shengpei Jiang,Yongliang Shen", "background": "GUI接地是自主GUI代理的基本任务，将自然语言指令映射到精确的屏幕坐标。现有方法通过大量的监督训练或带有标记奖励的强化学习来实现强大的性能，但依然受到像素级注解成本和可用性的限制。", "innovation": "提出了一种测试时尺度方法GUI-RC（区域一致性），通过从多个预测中构建空间投票网格来识别模型一致性的区域，无需训练即可提高各种架构在ScreenSpot基准数据集上的准确性。进一步引入GUI-RCPO（区域一致性策略优化），将其一致性模式转化为测试时强化学习的奖励，通过计算每个预测与集体一致性匹配程度来使模型在推断过程中逐步优化其输出，仅使用少量未标注数据即可显著提升准确性。", "conclusion": "该研究揭示了测试时尺度方法和测试时强化学习在GUI接地中的潜力，为其向更数据高效的GUI代理发展提供了前景。"}
{"llm_update_time": "20251116", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.06959", "html_url": "https://arxiv.org/abs/2508.06959", "title": "超越频率：通过空间分解视角感知细微线索进行细粒度视觉分类", "title_en": "Beyond Frequency: Seeing Subtle Cues Through the Lens of Spatial Decomposition for Fine-Grained Visual Classification", "authors": "Qin Xu,Lili Zhu,Xiaoxia Cheng,Bo Jiang", "background": "细粒度视觉分类（FGVC）的核心在于捕获具有差异性和类别特异性的微小视觉特征。最近，基于频域分解/变换的方法引起了广泛关注，因为它们能够提取判别性线索。然而，这些频域方法依赖于固定的基础函数，缺乏对图像内容的适应性，并且无法根据不同图像的判别性需求动态调整特征提取。", "innovation": "提出了一种名为Subtle-Cue Oriented Perception Engine（SCOPE）的新方法，该方法在空间域中动态增强低级细节和高级语义的表示能力，突破了固定尺度的频域限制，提高了多尺度融合的灵活性。SCOPE的核心在于两个模块：Subtle Detail Extractor（SDE）和Salient Semantic Refiner（SSR）。SDE动态增强浅层特征中的细微细节，如边缘和纹理；SSR则从高级特征中学习语义一致且结构意识的精炼特征，并由增强后的浅层特征引导。SDE和SSR逐层级联，逐步结合局部细节与全局语义。", "conclusion": "广泛的实验表明，该方法在四个流行的细粒度图像分类基准上达到了新的最先进性能。"}
{"llm_update_time": "20251116", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.04369", "html_url": "https://arxiv.org/abs/2508.04369", "title": "TSPO: Temporal Sampling Policy Optimization for Long-form Video Language Understanding", "title_en": "TSPO: Temporal Sampling Policy Optimization for Long-form Video Language Understanding", "authors": "Canhui Tang,Zifan Han,Hongbo Sun,Sanping Zhou,Xuchong Zhang,Xin Wei,Ye Yuan,Huayu Zhang,Jinglin Xu,Hao Sun", "background": "尽管多模态大型语言模型（MLLMs）在视觉语言任务中取得了显著进展，但在处理长时间视频输入时仍面临挑战。这些挑战主要源于MLLMs 的上下文限制和训练成本，因此需要在将视频输入MLLMs前对其进行稀疏帧采样。然而，构建可训练的采样方法仍然具有挑战性，因为视频-MLLMs 中的稀疏帧采样具有不可监督性和非差分性。现有的方法主要是基于固定的帧采样策略，但未能充分利用视频中的关键信息。因此，研究者们需要一种能够灵活调整的采样策略，以更好地理解和生成长视频中的语言内容。", "innovation": "本研究提出了一种名为Temporal Sampling Policy Optimization（TSPO）的方法，通过强化学习提升MLLMs对长视频-语言理解的能力。具体包括：1）提出了一种可训练的事件感知时间智能体，能够捕捉事件和查询之间的关联，进行概率性关键帧选择。2）提出了TSPO强化学习范式，将关键帧选择和语言生成建模为一个联合决策过程，以实现端到端的时间采样策略优化。此外，还提出了一种双风格长视频训练数据构建管道，平衡了全面的时间理解和关键段落定位。最后，通过规则基准确率和时间定位奖励机制优化时间采样策略。实验结果表明，TSPO在多个长视频理解基准上取得了最先进的性能，并且展示了在不同尖端Video-MLLMs中的可迁移能力。", "conclusion": "综合实验表明，TSPO在多个长视频理解基准上取得了最先进的性能，并展示了在不同先进Video-MLLMs中的可迁移能力。进一步研究中，可以通过结合多模态数据和更复杂的奖励机制提高TSPO的性能。"}
{"llm_update_time": "20251116", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.10794", "html_url": "https://arxiv.org/abs/2508.10794", "title": "VasoMIM：血管解剖意识的遮盖图像建模方法用于血管分割", "title_en": "VasoMIM: Vascular Anatomy-Aware Masked Image Modeling for Vessel Segmentation", "authors": "De-Xing Huang,Xiao-Hu Zhou,Mei-Jiang Gui,Xiao-Liang Xie,Shi-Qi Liu,Shuang-Yi Wang,Tian-Yu Xiang,Rui-Ze Ma,Nu-Fang Xiao,Zeng-Guang Hou", "background": "精确的X射线血管造影图像血管分割对于许多临床应用至关重要，但标注数据的稀缺性构成了一个巨大挑战，因此驱动了自监督学习（SSL）方法，如遮盖图像建模（MIM）的采用，以便利用大量未标注数据学习可迁移的表示。然而，传统MIM方法由于血管像素与背景像素之间严重类别不平衡，往往无法捕捉到血管解剖结构，导致血管表示较弱。", "innovation": "提出了Vascular anatomy-aware Masked Image Modeling（VasoMIM），一种专门针对X射线血管造影图像的新颖MIM框架，该框架在预训练过程中明确整合了解剖学知识。具体而言，它包括两种互补的组成部分：解剖结构导向的遮盖策略和解剖学一致性损失。前者优先遮盖含有血管的补丁，以使模型集中于重建与血管相关的区域。后者通过确保原始图像和重建图像之间在血管语义上的一致性，从而提高了血管表示的可区分性。", "conclusion": "实验证明，VasoMIM在三个数据集上实现了最佳性能。这些发现突显了其在促进X射线血管造影分析方面的潜在价值。"}
{"llm_update_time": "20251116", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.03113", "html_url": "https://arxiv.org/abs/2509.03113", "title": "通过基于梯度的自我反思减轻多模态幻觉", "title_en": "Mitigating Multimodal Hallucinations via Gradient-based Self-Reflection", "authors": "Shan Wang,Maying Shen,Nadine Chang,Chuong Nguyen,Hongdong Li,Jose M. Alvarez", "background": "多模态大型语言模型在各种任务中表现出色，但仍容易产生幻觉，即输出与视觉输入不相关。造成这一问题的原因在于两种主要偏见：文本-视觉偏见，即过于依赖提示和先前的输出，以及共现偏见，即频繁配对的对象之间的虚假关联.", "innovation": "提出了基于梯度的影响感知约束解码（GACD）方法，这是一种基于推理的方法，可以通过分析单个文本和视觉特征对当前输出的贡献来减轻这两种偏见。GACD 通过抑制与输出对象相关且虚假的视觉特征，以及通过增强视觉特征相对于文本的作用来平衡跨模态贡献，有效地减少了幻觉并提高了MLLM的视觉定位.", "conclusion": "在多个基准测试中的实验表明，GACD 有效地减少了幻觉，并改进了 MLLM 输出的视觉定位."}
{"llm_update_time": "20251116", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.12711", "html_url": "https://arxiv.org/abs/2508.12711", "title": "由GenAI驱动的新闻多样性偏离事实：基于LVLM的虚假信息检测挑战", "title_en": "Drifting Away from Truth: GenAI-Driven News Diversity Challenges LVLM-Based Misinformation Detection", "authors": "Fanxiao Li,Jiaying Wu,Tingchao Fu,Yunyun Dong,Bingbing Song,Wei Zhou", "background": "多模态虚假信息的传播正在对公众讨论和社会信任构成越来越大的威胁。大型跨模态语言模型（LVLMs）在多模态虚假信息检测（MMD）方面取得了近年来的进步，但生成式人工智能（GenAI）工具的兴起带来了新的挑战。这些工具创造的新闻多样性包括多样化和复杂的内容，导致了多层次偏移问题，其中包括模型级别感知偏移（由于风格变化破坏了模型内部推理）和证据级别偏移（由于表达多样性降低检索外部证据的质量或相关性）。这些问题显着削弱了现有的基于LVLM的MMD系统。为了系统地研究这一问题，我们推出了一个包含6个多样化类别共计16,000个新闻实例的大规模基准DriftBench，评估其在多层次偏移条件下的真相验证稳健性、对抗性证据污染的易感性以及对多样化输入的一致性推理分析。", "innovation": "我们引入了DriftBench，一个大规模基准，包含6个多样化类别的16,000个新闻实例，用于评估TSD系统在多层次偏移条件下的性能。我们设计了三个评估任务：对抗多级偏移条件下的真相验证稳健性、对抗性证据污染的易感性分析以及多样输入推理一致性分析。我们的实验表明，当前最先进的基于LVLM的检测器在对抗生成式证据注入的场景下不仅性能显著下降（平均F1分数降低14.8%），而且推理过程也变得不稳定。", "conclusion": "我们的研究揭示了现有MMD系统的根本性漏洞，并指出对抗AI时代需要更稳健的方法。"}
{"llm_update_time": "20251116", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.09958", "html_url": "https://arxiv.org/abs/2509.09958", "title": "基于视觉-语言True/False验证的零样本指称表达理解", "title_en": "Zero-Shot Referring Expression Comprehension via Vison-Language True/False Verification", "authors": "Jeffrey Liu,Rongbin Hu", "background": "指称表达理解（REC）通常通过特定任务的视觉定位模型来解决。本研究探讨了一种无需专门训练的零样本方法，能够与现有的任务训练模型取得竞争力或超越的效果。", "innovation": "本文提出了一种将REC重新定义为框级别的视觉-语言验证的方法。具体而言，利用通用的检测器（如YOLO-World）生成的提案，一个通用的视觉-语言模型独立地为每个区域回答True/False查询。这种方法简化了跨框干扰，支持避免和匹配多个对象，并且不需要微调。该方法不仅超越了零样本的GroundingDINO基线，还超过了在REC和GroundingDINO+CRG数据集上进行训练的GroundingDINO的报告结果。实验结果显示，验证方法的表现优于基于选择的提示方法，并且结果在使用开放式的视觉-语言模型时仍然有效。", "conclusion": "研究表明，零样本性能的强表现主要归因于工作流的设计，而非任务特定的预训练。"}
{"llm_update_time": "20251116", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.06890", "html_url": "https://arxiv.org/abs/2509.06890", "title": "基于球面相似学习和推断时的完全可微勒夫登-马奎尔特优化的术中2D/3D配准", "title_en": "Intraoperative 2D/3D Registration via Spherical Similarity Learning and Inference-Time Differentiable Levenberg-Marquardt Optimization", "authors": "Minheng Chen,Youyong Kong", "background": "术中2D/3D配准技术能够将术前3D影像与实时2D影像对齐，以便准确定位手术器械和植入物。现有的基于完全可微相似度学习的框架能在SE(3)上近似测地距离，从而扩大配准范围并减少显著干扰的影响，但现有的欧几里得近似会扭曲流形结构，导致收敛速度减慢。", "innovation": "本文探索在非欧几里得球面特征空间中进行相似学习，以更好地捕捉和拟合复杂的流形结构。使用CNN-Transformer编码器来提取特征嵌入，然后将其投影到球形空间，并通过双不变SO(4)空间中的里emannian距离来近似测地距离，从而实现更具表现力且几何上一致的深度相似度度量。在推断过程中，通过完全可微的勒夫登-马奎尔特优化来替代梯度下降，以加速收敛。", "conclusion": "在实际和合成数据集上的实验表明，该方法在术前个体化和术前无差别场景中都具有更高的精度。"}
{"llm_update_time": "20251116", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.18425", "html_url": "https://arxiv.org/abs/2508.18425", "title": "LPLC：一种用于车牌可读性分类的数据集", "title_en": "LPLC: A Dataset for License Plate Legibility Classification", "authors": "Lucas Wojcik,Gabriel E. Lima,Valfride Nascimento,Eduil Nascimento Jr.,Rayson Laroca,David Menotti", "background": "自动车牌识别（ALPR）在处理难以辨认的车牌时面临重大挑战。虽然超分辨率（SR）等重建方法已经出现，但如何有效识别低质量车牌仍然是一个未解的问题。为了优化模型性能和计算效率，应该对需要增强可读性的特定情况进行选择性预处理。鉴于此，本文发布了一个包含10,210辆汽车图像和12,687个车牌注释的数据集，用于车牌可读性分类（LPLC数据集），并采用细粒度注释策略，详细涵盖了车辆和车牌遮挡情况、四类可读性等级（完美、良好、较差和难以辨认）以及三类字符标签（不包括难以辨认的车牌）", "innovation": "提出了一个名为LPLC的新数据集，该数据集包含10,210个带有12,687个注释的车牌的汽车图像，覆盖各种车辆类型、光照条件和摄像头/图像质量等级。同时，引入了细粒度注释策略，包括车辆和车牌的遮挡情况、四个读取级别以及三种字符标签（不包括难以辨认的车牌）。结合三种图像识别网络（ViT、ResNet和YOLO）来判断车牌图像是否足够清晰、是否需要超分辨率处理或完全无法恢复，结果表明，这三个基线模型的整体F1分数均未超过80%，进一步强调了该领域的研究需求", "conclusion": "研究表明，使用不同图像识别网络进行车牌可读性分类仍然具有挑战性，LPLC数据集提供了宝贵的资源，为自动车牌识别领域提供了新的研究基础"}
{"llm_update_time": "20251116", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.05796", "html_url": "https://arxiv.org/abs/2509.05796", "title": "双模式深度异常检测在医疗制造中的应用：结构相似性和特征距离", "title_en": "Dual-Mode Deep Anomaly Detection for Medical Manufacturing: Structural Similarity and Feature Distance", "authors": "Julio Zanon Diaz,Georgios Siogkas,Peter Corcoran", "background": "医疗设备制造中的自动化视觉检查面临着独特的挑战，包括极低的缺陷率、有限的标注数据、生产设备线上的硬件限制以及需要经过验证且可解释的人工智能系统。现有的解决方案在应对这些挑战时存在不足，因此需要开发新的方法来满足这些要求。", "innovation": "本文提出了两种互补的自动编码器架构，通过结合基于结构相似性的4-MS-SSIM指数和马氏距离分析，实现了在受限硬件条件下进行实时缺陷检测以及有效的特征空间监控和生命周期验证。这两种方法共享一个针对典型制造条件优化的轻量级骨干网络，特别适用于高分辨率图像。实验结果表明，提出的方法在SS模块和跨领域的MV模块上均优于MOCCA、CPCAE和RAG-PaDiM等基准方法，并且在形状、纹理、结构以及颜色等特征方面表现得更为出色。", "conclusion": "本文提出了一个双模式框架，结合了实时异常检测和监督监测，该方法在医疗制造这种关键制造环境中显著提高了可解释的人工智能模型的可靠性和可观察性，并实现了持续的生命周期监控。研究结果已在公开的项目库中通过发布源代码的形式提供，数据集则来自公开可获取的源。"}
{"llm_update_time": "20251116", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.15886", "html_url": "https://arxiv.org/abs/2509.15886", "title": "RangeSAM: 在视觉基础模型用于范围视图表示的LiDAR分割潜力方面的研究", "title_en": "RangeSAM: On the Potential of Visual Foundation Models for Range-View represented LiDAR segmentation", "authors": "Paul Julius Kühn,Duc Anh Nguyen,Arjan Kuijper,Holger Graf,Saptarshi Neil Sinha", "background": "点云分割是自动驾驶和3D场景理解的关键技术。尽管基于体素和点的方法由于其与深度架构的兼容性和抓取细粒度几何形状的能力而占据主导地位，但这些方法通常会带来高昂的计算成本、不规则的内存访问和有限的实时效率。相比之下，尽管范围视图方法相对未被充分探索，但它们可以利用成熟的二维语义分割技术实现快速和准确的预测。", "innovation": "提出了一种范围视图框架，该框架将 state-of-the-art 的视觉基础模型 SAM2 适应于 3D 分割任务，结合高效的 2D 特征提取与标准的投影/反投影操作，适用于点云。对 SAM2 的编码器进行了几种架构修改：1）一个新颖的模块，强调了 LiDAR 范围图像中固有的水平空间相关性；2）一个针对球形投影的几何特性定制的配置；3）在编码器骨干中适应机制，专门设计用于捕捉范围视图伪图中存在的独特空间模式和不连续性。该方法在 SemanticKITTI 上实现了竞争力的性能，同时还得益于以二维为中心的流水线的速度、可扩展性和部署简便性。", "conclusion": "我们的工作表明，视觉基础模型作为3D感知的通用骨干是可行的，为统一、基础模型驱动的LiDAR分割开辟了一条道路。结果使我们得出结论，使用视觉基础模型进行范围视图分割方法具有令人期待的结果。"}
{"llm_update_time": "20251116", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.23304", "html_url": "https://arxiv.org/abs/2509.23304", "title": "低光强脉冲流中的看不见的图像重建", "title_en": "Seeing the Unseen in Low-light Spike Streams", "authors": "Liwen Hu,Yang Li,Mianzhi Liu,Yijia Guo,Shenghao Xie,Ziluo Ding,Tiejun Huang,Lei Ma", "background": "脉冲相机是一种具有高时间分辨率的神经形态传感器，尤其适用于高速视觉任务。传统相机通过固定的时间间隔获取图像，而脉冲相机持续积累光子并以异步事件流的形式输出。然而，在低光高速场景下，脉冲流的稀疏信息和严重噪声给图像重建带来了极大挑战。现有的重建方法往往难以有效处理这类情况。因此，开发一种有效的重建方法以补充这些场景下的纹理信息变得非常重要。", "innovation": "本文提出了一种基于扩散的重建方法——Diff-SPK。该方法利用生成先验知识补充各种低光条件下稀疏的纹理信息。具体来说，首先使用增强的基于事件间间隔的纹理（ETFI）聚集低光脉冲流中的稀疏信息。然后，经过适当编码后的ETFI被送入ControlNet生成高速场景下的图像。为了提升生成图像的质量，在生成过程中引入了基于ETFI的特征融合模块。", "conclusion": "本文提出的Diff-SPK方法能够有效补充低光条件下脉冲流中稀疏的纹理信息，提高高速场景重建图像的质量。"}
{"llm_update_time": "20251116", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.26091", "html_url": "https://arxiv.org/abs/2509.26091", "title": "利用大型推理模型实现从文本到场景的转换", "title_en": "Text-to-Scene with Large Reasoning Models", "authors": "Frédéric Berdoz,Luca A. Lanzendörfer,Nick Tuninga,Roger Wattenhofer", "background": "当前的文本到场景转换方法在处理复杂的几何结构和物体变形方面常常表现不佳，且很难严格遵守复杂的指令。研究者们致力于解决这些局限，以提高生成的3D环境与文本描述的一致性和精确性，特别是针对复杂室内配置的生成能力。因此，提出了一种基于大型推理模型（LRMs）的Prompt驱动场景合成方法，以克服当前技术的不足，生成更高质量和更准确的3D环境。", "innovation": "研究提出了Reason-3D模型，该模型通过结合对象检索（基于包括物理、功能和上下文属性的描述）和基于隐式和显式布局约束的放置策略，并借助碰撞感知的空间推理来优化物体的位置。评价显示，Reason-3D在视觉真实度、约束遵守度以及资产检索质量方面明显优于现有方法。这项工作展示了现代LRMs的高级空间推理能力，同时也为对象检索和放置的研究提供了代码基础，提供了进一步的研究平台和工具。", "conclusion": "Reason-3D模型在人类评分的视觉真实度、约束遵守度和资产检索质量上显著超越了先前的方法。这项工作不仅为文本到场景生成领域做出了贡献，还展示了现代LRMs的强大空间推理能力，并公开了代码以促进相关研究的进一步发展。"}
{"llm_update_time": "20251116", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.25238", "html_url": "https://arxiv.org/abs/2510.25238", "title": "VADB:一个具有专业多维注释的大型视频美学数据库", "title_en": "VADB: A Large-Scale Video Aesthetic Database with Professional and Multi-Dimensional Annotations", "authors": "Qianqian Qiao,DanDan Zheng,Yihang Bo,Bao Peng,Heng Huang,Longteng Jiang,Huaye Wang,Jingdong Chen,Jun Zhou,Xin Jin", "background": "视频美学评估是多媒体计算中的一个重要领域，它结合了计算机视觉和人类认知。这一领域的发展受限于标准化数据集的缺乏和鲁棒模型的不足，视频的时序动态和多模态融合的挑战阻碍了基于图像的方法的直接应用。", "innovation": "该研究引入了VADB，这是一个包含10,490个由37名专业人士在多个美学维度上标注的多样视频的大规模视频美学数据库，包括整体和特定属性的美学评分，丰富的语言评论和客观标签。此外，研究者提出了VADB-Net，这是一种双模态预训练框架，具有两阶段训练策略，它在评分任务中优于现有的视频质量评估模型，并支持下游视频美学评估任务。", "conclusion": "该数据库和源代码可以在指定链接处获取。该研究提出的VADB-Net框架在视频美学评估任务上取得了显著效果，并为后续研究提供了强有力的数据支持。"}
{"llm_update_time": "20251116", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.14260", "html_url": "https://arxiv.org/abs/2510.14260", "title": "MatchAttention: 高分辨率跨视图匹配的相对位置匹配", "title_en": "MatchAttention: Matching the Relative Positions for High-Resolution Cross-View Matching", "authors": "Tingman Yan,Tao Liu,Xilian Yang,Qunfei Zhao,Zeyang Xia", "background": "跨视图匹配本质上是通过交叉注意力机制实现的。然而，高分辨率图像的匹配仍然具有挑战性，因为现有的交叉注意力机制存在平方复杂度问题和缺乏明确的匹配约束。", "innovation": "本文提出了一种新的注意力机制——MatchAttention，它能够动态匹配相对位置。相对位置决定了查询下键值对的注意力采样中心。通过提出的双线性softmax实现了连续可微的滑动窗口注意力采样。通过将相对位置嵌入到特征通道中并通过逐层的残差连接迭代更新，使得相对位置能够在跨视图匹配学习中作为精确的目标。为此，设计了一个高效的层次跨视图解码器 MatchDecoder，MatchAttention 是其核心组件。此外还提出了门控的跨视图 MatchAttention 和一致性约束损失来处理跨视图遮挡，有效地降低了正反向传播中的遮挡影响，使模型更专注于学习匹配关系。", "conclusion": "当应用于立体匹配时，MatchStereo-B 在公开的 Middlebury 测试基准平均误差上排名第一，仅需 29ms 进行 KITTI 分辨率的推理。MatchStereo-T 能够使用仅 3GB 的 GPU 内存处理 4K UHD 图像，仅需 0.1 秒。提出的模型在 KITTI 2012, KITTI 2015, ETH3D 和 Spring 流数据集上也达到了最先进的性能。这种高精度和低计算复杂度的结合使得实时、高分辨率和高精度的跨视图匹配成为可能。"}
{"llm_update_time": "20251116", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.12174", "html_url": "https://arxiv.org/abs/2510.12174", "title": "UniGS：统一几何感知的高斯点云渲染以实现多模态渲染", "title_en": "UniGS: Unified Geometry-Aware Gaussian Splatting for Multimodal Rendering", "authors": "Yusen Xie,Zhenmin Huang,Jianhao Jiao,Dimitrios Kanoulas,Jun Ma", "background": "本文提出了一种基于3D高斯点云的统一样图表示和可微分框架，用于高保真多模态三维重建。该框架结合了CUDA加速的光栅化管道，可以同时生成逼真的RGB图像、几何精确的深度图、一致的法线图和语义标签。本文重新设计了光栅化，通过可微分射线-椭球交集渲染深度，而不是使用高斯中心，从而能够通过解析深度梯度优化旋转和尺度属性。此外，还推导出了表面正常渲染的解析梯度公式，确保重建的3D场景几何一致性。为了提高计算和存储效率，引入了一个学习属性，能够在训练过程中对贡献度最小的高斯进行可微分修剪。定量和定性实验结果表明，该方法在所有模态下均达到最先进的重建精度，验证了其几何感知范式的有效性。源代码和多模态查看器将在GitHub上提供。", "innovation": "提出了一种统一样图表示和可微分框架，用于基于3D高斯点云的高保真多模态三维重建。通过重新设计光栅化，使用可微分射线-椭球交集渲染深度，从而能够优化旋转和尺度属性。推导出表面正常渲染的解析梯度公式，确保几何一致性。引入学习属性以减少在训练过程中的高斯数，提高计算和存储效率。", "conclusion": "该框架在所有模态下均达到最先进的重建精度，验证了其几何感知范式的有效性。"}
{"llm_update_time": "20251116", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.16781", "html_url": "https://arxiv.org/abs/2510.16781", "title": " Xiaoice: 依靠语义特征的自监督时空聚类实现无训练视频理解", "title_en": "Xiaoice: Training-Free Video Understanding via Self-Supervised Spatio-Temporal Clustering of Semantic Features", "authors": "Shihao Ji,Zihui Song", "background": "大规模视觉语言模型（VLMs）在静态图像上的零样本推理能力尚未完全扩展到视频领域。传统的视频理解模型通常需要在注释数据集上进行大量、特定任务的训练，这个过程既昂贵又缺乏可扩展性。", "innovation": "本文提出了一种无需训练的框架，通过结合预训练VLM丰富的语义先验与经典的模式发现机器学习算法，以自监督时空聚类的方式实现了视频理解。核心思想是将视频理解重构为一个高维语义特征空间内的自监督时空聚类问题。该框架首先使用预训练VLM的冻结视觉编码器将视频流转换为语义特征轨迹，然后利用Kernel Temporal Segmentation（KTS）将连续的特征流分割成离散的、语义一致的事件段，最后对这些段进行无监督的密度聚类，以识别视频中反复出现的宏观场景和主题。通过从每个发现的簇中选择代表性关键帧并利用VLM的生成能力来进行文本描述，该框架可以自动生成视频内容的结构化、多模态摘要。", "conclusion": "这种基于语义特征的自监督时空聚类方法为视频内容的零样本、自动化结构分析提供了一种有效、可解释且模型独立的途径。"}
{"llm_update_time": "20251116", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2511.06625", "html_url": "https://arxiv.org/abs/2511.06625", "title": "从低剂量胸部计算机断层扫描中进行心血管风险评估的可解释跨疾病推理", "title_en": "Explainable Cross-Disease Reasoning for Cardiovascular Risk Assessment from LDCT", "authors": "Yifei Zhang,Jiashuo Zhang,Mojtaba Safari,Xiaofeng Yang,Liang Zhao", "background": "低剂量胸部计算机断层扫描（LDCT）能够同时捕捉肺部和心脏结构，为肺部和心血管健康联合评估提供了独特机会。然而，现有方法通常将这两个领域视为独立任务，忽视了它们的生理交互和共享影像生物标志物。", "innovation": "我们提出了一个解释性的跨疾病推理框架，可以实现单次LDCT扫描的心肺风险评估。该框架通过引入一种有机构思过程，率先感知肺部发现，利用既定的医学知识进行推理，最终得出心血管判断并附带解释性理由。框架集成了三个相互协同的组件：肺部感知模块、知识引导推理模块和心脏表示模块，它们的输出共同产生了一个准确且生理上可解释的心血管风险预测。实验结果表明，所提出的框架在心血管疾病筛查和死亡率预测方面表现出了最先进的性能，并优于单一疾病和纯粹基于影像的基线模型。此外，该框架提供了可由人类验证的理由，与心血管理解相契合，揭示了肺部异常与心脏应激机制之间的连贯联系。", "conclusion": "这项工作创建了一个统一且可解释的心血管分析框架，从LDCT桥接基于图像的预测和基于机制的医学解释之间的差距。"}
{"llm_update_time": "20251116", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2511.03943", "html_url": "https://arxiv.org/abs/2511.03943", "title": "Temporal Zoom Networks: 距离回归和连续深度在高效动作定位中的应用", "title_en": "Temporal Zoom Networks: Distance Regression and Continuous Depth for Efficient Action Localization", "authors": "Ibne Farabi Shihab,Sanjeda Akter,Anuj Sharma", "background": "时空动作定位需要精确的边界检测和高效性。当前方法在所有时间位置上应用均匀计算，导致在简单边界上浪费资源，在难以界定的边界上无法有效处理。因此，提出了两种创新方法以解决此问题：边界距离回归（BDR）及自适应时域细化（ATR）.", "innovation": "边界距离回归（BDR）用基于带符号距离的回归来替换分类式的边界检测，降低了3.3至16.7倍的方差；自适应时域细化（ATR）则以连续的方式分配注意力（$\tau\neq0/1$），从而在困难边界附近集中计算量。相比ActionFormer++，我们的方法在THUMOS14数据集上实现了更高的mAP，并且使用 fewer FLOPs 和较短的延迟，尤其在短动作分类上表现更加突出，并通过知识蒸馏进一步减小了一次性开销成本。贡献包括：（i）理论上支持的距离公式，带信息论分析显示最优的方差扩展；（ii）避免离散路由复杂性的连续深度分配机制；（iii）四个数据集上的持续改进，与边界变异性相关.", "conclusion": "我们的方法在时空动作定位上实现了高精度和高效性，特别在简单和混杂边界上改进显著，同时通过知识蒸馏进一步优化了计算效率并保留了高准确性。"}
{"llm_update_time": "20251116", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.26125", "html_url": "https://arxiv.org/abs/2510.26125", "title": "WOD-E2E: Waymo Open Dataset for End-to-End Driving in Challenging Long-tail Scenarios", "title_en": "WOD-E2E: Waymo Open Dataset for End-to-End Driving in Challenging Long-tail Scenarios", "authors": "Runsheng Xu,Hubert Lin,Wonseok Jeon,Hao Feng,Yuliang Zou,Liting Sun,John Gorman,Ekaterina Tolstaya,Sarah Tang,Brandyn White,Ben Sapp,Mingxing Tan,Jyh-Jing Hwang,Dragomir Anguelov", "background": "基于视觉的端到端（E2E）驾驶因其可扩展性以及与多模态大语言模型（MLLMs）的协同增益而受到了研究界的广泛关注。然而，目前的E2E驾驶基准主要集中在常规场景上，难以全面测试这些系统的真正潜力。现有的开环评估指标通常无法充分捕捉驾驶的多模态性质或在长尾情景下有效评估性能。", "innovation": "论文提出了Waymo Open Dataset for End-to-End Driving (WOD-E2E)，该数据集包含4021个驾驶片段（约12小时），特别为您日常生活中罕见且发生频率低于0.03%的挑战性长尾场景设计。为了评估这些长尾情况下的E2E驾驶性能，论文还提出了一种新的开环评估指标：评估者反馈评分（Rater Feedback Score, RFS）。RFS评估预测轨迹与评估者注释的轨迹偏好标签之间的契合程度，不同于传统的评估指标，后者仅衡量预测航点与日志之间的距离。", "conclusion": "通过这项工作，论文旨在推动能够处理复杂实际场景的通用、稳健且安全的端到端自动驾驶代理的研究，这些代理能够处理长尾情况。并已为WOD-E2E验证集的所有片段发布了评估者偏好标签，而保留的测试集标签则用于2025年的WOD-E2E挑战赛。"}
{"llm_update_time": "20251116", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2511.07250", "html_url": "https://arxiv.org/abs/2511.07250", "title": "MVU-Eval: Towards Multi-Video Understanding Evaluation for Multimodal LLMs", "title_en": "MVU-Eval: Towards Multi-Video Understanding Evaluation for Multimodal LLMs", "authors": "Tianhao Peng,Haochen Wang,Yuanxing Zhang,Zekun Wang,Zili Wang,Gavin Chang,Jian Yang,Shihao Li,Yanghai Wang,Xintao Wang,Houyi Li,Wei Ji,Pengfei Wan,Steven Huang,Zhaoxiang Zhang,Jiaheng Liu", "background": "现有的多模态大语言模型（MLLMs）的能力已经扩展到了视觉模态，但现有的评价基准仍然局限于单一视频的理解，忽视了在现实世界场景中多视频理解的迫切需求（例如体育分析和自动驾驶）。这是由于缺乏评估多视频理解的重要评价基准，尤其在多传感器合成和跨角度体育分析等实际应用方面，因此存在着显著的技术缺口。", "innovation": "该研究引入了MVU-Eval，这是首次为MLLMs的多视频理解制定的全面基准。MVU-Eval主要通过1,824个精心筛选的问题-答案对评估了4,959个来自不同领域的视频，涵盖了基本感知任务和高级推理任务等八个核心能力。通过广泛评估最新的开源和封闭源模型，揭示了当前MLLMs在跨视频理解上的显著性能差异和局限性。这项工作为未来的多视频理解研究提供了坚实的基础，并将公开可用，促进这一领域的进一步发展与研究。", "conclusion": "该研究通过MVU-Eval评估了当前最新的MLLMs在多视频理解上的表现，发现了重大性能差距和局限性，因此呼吁研究人员关注这一重要领域。MVU-Eval将为研究界提供一个全面的评估工具，促进更多关于多视频理解的研究。"}
{"llm_update_time": "20251116", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2511.07925", "html_url": "https://arxiv.org/abs/2511.07925", "title": "HD$^2$-SSC: 高维度高密度语义场景完成算法在自主驾驶中的应用", "title_en": "HD$^2$-SSC: High-Dimension High-Density Semantic Scene Completion for Autonomous Driving", "authors": "Zhiwen Yang,Yuxin Peng", "background": "相机基于的3D语义场景完成（SSC）在自主驾驶中起着关键作用，有助于实现对有效场景感知和决策的三维场景理解。现有的SSC方法在改善3D场景表示方面显示出其有效性，但由于输入输出维度差距和注释与实际密度差距，导致从输入图像中的稀疏标注标签二维规划视角预测真实世界的密集占用情况存在不足。当前的研究方向集中在解决这些差距，提升在三维立体视角下对场景的理解能力。", "innovation": "提出了一种名为HD$^2$-SSC的框架，通过扩展像素语义并细化体素占用来解决存在的差距问题。设计了高维度语义解耦模块来扩展2D图像特征，分离出较粗的像素语义和遮挡，以及识别具有良好语义的焦点区域，从而丰富图像特征。设计了高密度占位细化模块，采用“检测-细化”架构利用上下文几何和语义结构，完成缺失的体素并纠正错误的体素占位，从而提升语义密度。", "conclusion": "通过对SemanticKITTI和SSCBench-KITTI-360两个数据集的广泛实验和分析，验证了HD$^2$-SSC框架的有效性。"}
{"llm_update_time": "20251116", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2511.08238", "html_url": "https://arxiv.org/abs/2511.08238", "title": "重塑视觉-语言微调中的语义关系", "title_en": "Remodeling Semantic Relationships in Vision-Language Fine-Tuning", "authors": "Xiangyang Wu,Liu Liu,Baosheng Yu,Jiayan Qiu,Zhenwei Shi", "background": "视觉-语言微调已成为构建多模态基础模型的有效范式。然而，现有的微调方法在调整视觉与语言时往往忽略了文本上下文中由图像揭示的语义关系，导致模型性能不佳。因此，本文探索如何利用这些语义关系来提高多模态模型的效果和融合效率。", "innovation": "本文提出了一种新方法，通过提取多水平语义特征并将其投影到相关语义中，利用可继承的跨注意力机制融合视觉与文本特征。该方法特别设计用于去除冗余的视觉关系，从而优化了模型的整体表现能力。", "conclusion": "通过在八个基础模型及视觉问答和图像标题生成等两项下游任务上的评估，本文提出的方法显著优于现有所有方法，表明了该方法在提升多模态模型性能上的有效性和优越性。"}
{"llm_update_time": "20251116", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2511.08272", "html_url": "https://arxiv.org/abs/2511.08272", "title": "MAUGIF: 基于双跨像自动编码器的机制感知无监督通用图像融合", "title_en": "MAUGIF: Mechanism-Aware Unsupervised General Image Fusion via Dual Cross-Image Autoencoders", "authors": "Kunjing Yang,Zhiwei Wang,Minru Bai", "background": "图像融合旨在整合多源图像中的结构性和补充性信息。然而，现有的融合方法往往要么高度特定于某些任务，要么是通用框架，遍用统一策略覆盖多样任务，忽视了它们各自的融合机制的独特性。针对这一问题，本文提出了一种基于双跨像自动编码器的机制感知无监督通用图像融合（MAUGIF）方法。", "innovation": "本文创新点包括：区分了加法和乘法融合的基本机制；使用双编码器将源图像映射到共享潜在空间，捕捉共性内容并分离模态特定细节；双解码器作为特征注入器，选择性地将每种模态的独特特性重新整合到共享内容中进行重构；解码器架构根据其融合机制变化，提高了性能和解释性。广泛的实验结果验证了该方法的有效性和泛化能力。", "conclusion": "本文提出的MAUGIF方法通过双跨像自动编码器，针对不同融合任务的内在机制，实现了机制感知的无监督通用图像融合，通过区分模态间的差异性，并利用双编码器和双解码器机制，提高了图像融合的性能与解释性。实验结果表明，该方法在多种融合任务上具有优越的性能和强大的泛化能力。"}
{"llm_update_time": "20251116", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2511.08903", "html_url": "https://arxiv.org/abs/2511.08903", "title": "LLM-Guided Probabilistic Fusion for Label-Efficient Document Layout Analysis", "title_en": "LLM-Guided Probabilistic Fusion for Label-Efficient Document Layout Analysis", "authors": "Ibne Farabi Shihab,Sanjeda Akter,Anuj Sharma", "background": "尽管半监督学习取得了进展，文档布局理解仍需大量数据。该研究提出了一种通过融合视觉预测和文本预训练的语言模型提供的结构先验来增强半监督检测的框架，利用了概率加权原则。", "innovation": "提出了一种通过原理性的概率加权融合视觉预测和语义先验的方法，这在轻量级和预训练模型中均显示出一致的性能提升。此方法在仅使用5%的标签时，在轻量级模型上实现88.2 ± 0.3 AP，并在预训练模型上达到了89.7 ± 0.4 AP，超过了标准半监督学习方法并且与需要大量预训练数据的方法相比，具有竞争力。", "conclusion": "此研究通过LLM结构先验证明了其与轻量级和预训练架构的互补性。主要发现包括：1) 实例自适应门控机制在有数据依赖条件的概率一致性下，比固定权重提高0.9 AP；2) 开源LLM使隐私保护部署成为可能，且损失最小；3) LLM在语义消歧方面提供了具体的增益（18.7%，提高3.8 AP），并且提供了成本效益分析。"}
{"llm_update_time": "20251116", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2503.16711", "html_url": "https://arxiv.org/abs/2503.16711", "title": "深度感知对于稳健自主代理的重要性：多模态RGB-D 视觉", "title_en": "Depth Matters: Multimodal RGB-D Perception for Robust Autonomous Agents", "authors": "Mihaela-Larisa Clement,Mónika Farsang,Felix Resch,Mihai-Teodor Stanusoiu,Radu Grosu", "background": "为自主代理设计纯粹依赖感知并在实时控制中做决策的高效且稳健的架构十分重要。本文展示了将深度信息与RGB输入结合使用能显著提升代理预测转向命令的能力，并通过轻量级循环控制器利用融合RGB-D特征进行序列决策来验证这一观点。", "innovation": "本文创新点在于通过早期融合深度数据来增强代理的稳健性。这种融合不仅提高了代理预测转向命令的准确性，而且在面对帧丢失和噪声增加的情况下仍然有效。实验证明，增强的代能够在复杂驾驶条件下避免动态和静态障碍物，即使是在超出分布范围的情景下也能保持任务重点。", "conclusion": "研究表明，早期融合深度信息的控制器具有高度的稳健性，即便在存在帧丢失和噪声增大的情况下也能保持其有效性，无需牺牲网络对任务的关注。该模型已被成功部署在实际硬件上，并展示出卓越的自主驾驶能力。"}
{"llm_update_time": "20251116", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2511.09057", "html_url": "https://arxiv.org/abs/2511.09057", "title": "PAN: 一种用于泛化、交互和长时间模拟的世界模型", "title_en": "PAN: A World Model for General, Interactable, and Long-Horizon World Simulation", "authors": "PAN Team Institute of Foundation Models:Jiannan Xiang,Yi Gu,Zihan Liu,Zeyu Feng,Qiyue Gao,Yiyan Hu,Benhao Huang,Guangyi Liu,Yichi Yang,Kun Zhou,Davit Abrahamyan,Arif Ahmad,Ganesh Bannur,Junrong Chen,Kimi Chen,Mingkai Deng,Ruobing Han,Xinqi Huang,Haoqiang Kang,Zheqi Li,Enze Ma,Hector Ren,Yashowardhan Shinde,Rohan Shingre,Ramsundar Tanikella,Kaiming Tao,Dequan Yang,Xinle Yu,Cong Zeng,Binglin Zhou,Zhengzhong Liu,Zhiting Hu,Eric P. Xing", "background": "现有的世界模型通常集中在物理、游戏或3D场景等特定领域，并且难以在不同环境和交互格式之间进行泛化。此外，视频生成模型虽然可以产生逼真的视觉序列，但缺乏因果控制、交互性和远期一致性，这些特性对于目的性推理是必要的。因此，存在一个改进现有模型以实现这些特性的需求。", "innovation": "PAN是一种泛化、可交互且具有长时程的世界模型，它通过基于历史和自然语言动作条件下的高质量视频模拟来预测未来世界状态。PAN使用生成性潜空间预测（GLP）架构，该架构结合了一个基于大型语言模型（LLM）的自回归潜动力学基础结构，以及一个视频扩散解码器，可以直接根据语言指定的动作进行情景化推理，同时重建感知详细的、时间上连续的视觉观察。这实现了潜空间推理（想象）与可实现世界动态（现实）的统一。PAN在多样领域的视频-动作对上进行了大规模训练，支持开放领域、动作条件下的模拟，并能够生成连贯、长时间的动态效果。", "conclusion": "在广泛的实验中，PAN在动作条件下的世界模拟、远期预测和模拟推理方面表现出色，优于其他视频生成器和世界模型，朝着能够预测未来世界状态以进行推理和行动的通用世界模型迈出了重要一步。"}
{"llm_update_time": "20251116", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2511.08937", "html_url": "https://arxiv.org/abs/2511.08937", "title": "通过集合理群非注意机制增强对抗性转移能力", "title_en": "Boosting Adversarial Transferability via Ensemble Non-Attention", "authors": "Yipeng Zou,Qin Liu,Jie Wu,Yu Peng,Guo Chen,Hui Zhou,Guanghui Ye", "background": "集成攻击结合了具有不同架构的代理模型的输出，可以与各种基于梯度的攻击结合使用以提高对抗性传输性。然而，先前的研究在跨异构模型架构进行传输时表现出不尽如人意的攻击性能。主要原因是异构代理模型的梯度更新方向差异很大，使得集成模型的梯度方差难以减少，同时充分利用个体模型的优势变得困难。", "innovation": "设计了一种新型集成攻击——NAMEA，首次将集成模型非注意区域的梯度整合到迭代梯度优化过程中。该设计灵感来自于观察到异构模型的注意区域差异很大，因此ViTs的非注意区域很可能是CNNs的关注焦点，反之亦然。因此，通过将集成模型的注意和非注意区域的梯度分别合并，从而融合CNNs和ViTs的转移信息。具体而言，首创了一种分解非注意区域梯度与注意区域梯度的新方法，并通过元学习合并梯度。在ImageNet数据集上进行的实证评估表明，NAMEA分别比AdaEA和SMER（目前最先进的集成攻击）的性能平均高出15.0%和9.6%。这项工作是首次尝试探索集合理群非注意机制在提升跨架构转移能力方面的潜力，为启动集成攻击提供新的见解。", "conclusion": "通过NAMEA，首次创新地利用集成非注意机制，显著提升了跨架构的对抗性传输能力，实验证明了其在实际应用中的效果和潜力，提供了新的攻击方法见解。"}
{"llm_update_time": "20251116", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2511.09540", "html_url": "https://arxiv.org/abs/2511.09540", "title": "vMFCoOp: 在统一的超球面流形上实现平衡，用于生物医学VLMs的提示", "title_en": "vMFCoOp: Towards Equilibrium on a Unified Hyperspherical Manifold for Prompting Biomedical VLMs", "authors": "Minye Shao,Sihan Guo,Xinrun Li,Xingyu Miao,Haoran Duan,Yang Long", "background": "近期研究表明，通过大型语言模型(LLM)提取的医疗语义先验指导的上下文优化(CoOp)可以作为手工提示工程和全面微调的可伸缩替代方案，调整基于医学CLIP的视觉-语言模型(VLMs)。然而，这种上下文中的提示学习受到LLMs和CLIP变体间的语义不一致的挑战，这种不一致源于不同的训练数据集和模型架构。此外，传统的欧几里得空间优化方法无法建模统一表示或应用局部几何约束，这在复杂的生物医学成像中会加剧模态差距并导致少样本适应不稳定。", "innovation": "本文提出了vMFCoOp框架，通过在共享的超球面流形上逆向估计vMises-Fisher (vMF)分布，用统一语义锚点对任意LLMs和CLIP基干的语义偏差进行对齐，从而实现稳健的生物医学提示和卓越的少样本分类。vMFCoOp基于三个互补约束，展示了在14个医疗数据集、12种医疗成像模态和13个解剖区域中的持续改进，超越了目前最先进的方法在准确率、泛化能力和临床适用性方面的表现。", "conclusion": "该工作旨在不断扩展，涵盖更多的下游应用，相关的资源可以通过该链接共享：this https URL。"}
{"llm_update_time": "20251116", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2511.09147", "html_url": "https://arxiv.org/abs/2511.09147", "title": "PressTrack-HMR：基于压力的顶部向下多人全局人体网格恢复", "title_en": "PressTrack-HMR: Pressure-Based Top-Down Multi-Person Global Human Mesh Recovery", "authors": "Jiayue Yuan,Fangting Xie,Guangwen Ouyang,Changhai Ma,Ziyu Wu,Heyu Ding,Quan Wan,Yi Ke,Yuchen Wu,Xiaohui Cai", "background": "多人全局人体网格恢复（HMR）对理解人群动力学和互动至关重要。传统基于视觉的HMR方法在实际场景中可能会受到互射遮挡、照明不足和隐私问题的限制。基于人类与地面的触觉交互提供了一种无遮挡且保护隐私的替代方案来捕捉人类运动。尽管现有的研究表明，从触觉垫获取的压力信号可以在单人场景中有效估计人类姿态，但对于多人同时随机走在垫子上时如何区分由不同人产生的掺杂信号，并进而获取每个人的时间压力数据，仍存在挑战，亟需扩展基于压力的HMR方法到多人情况。", "innovation": "该论文提出了一个顶部向下的管道PressTrack-HMR，仅从压力信号恢复多人的全球人体网格。该管道利用检测跟踪策略首先从原始压力数据中识别并分割出每个人的压力量信号，然后对每个提取的信号执行HMR。此外，还构建了一个多人交互压力数据集MIP，促进了在多人场景中基于压力的人体运动分析的研究。实验结果证明了使用压力数据进行多人HMR方法的优越性，89.2 mm MPJPE和112.6 mm WA-MPJPE$_{100}$，展示了触觉垫在无处不在的、保护隐私的多个人体动作识别中的潜力。", "conclusion": "该方法在多个人体姿势恢复中的表现优异，验证了触觉垫在保护隐私的多人姿态识别中的潜在应用。此外，通过构建MIP数据集，该研究表明了基于压力的人体运动分析在未来多个人体场景中的应用前景。"}
{"llm_update_time": "20251116", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2010.13232", "html_url": "https://arxiv.org/abs/2010.13232", "title": "自监督训练在低剂量CT重建中的应用", "title_en": "Self-Supervised Training For Low Dose CT Reconstruction", "authors": "Mehmet Ozan Unal,Metin Ertas,Isa Yildirim", "background": "CT成像中的电离辐射引起了广泛关注，为了在不降低图像质量的情况下降低剂量，压缩感知重建方法已提供了低剂量CT重建。近年来，随着深度学习的兴起、高性能计算能力和大数据集的可用性，数据驱动的方法受到了关注。这些方法通常依赖于标记数据集，但最近的研究表明，可以使用含噪的数据集成功训练。基于此背景，本文提出了一种将低剂量sinograms作为其自身训练目标的训练方案，利用自监督原则在噪声元素独立的投影域中进行训练，优化了滤波反投影方法的过滤部分和去噪神经网络的参数，最终在低剂量CT重建任务中展示了本文方法在分析CT模型和真实CT图像中的定量和定性表现均优于传统方法和压缩感知迭代重建方法的结果。", "innovation": "本文提出了一种将低剂量sinogram作为自身训练目标的方法，并利用自监督原则在投影域中进行训练，优化了滤波反投影方法和去噪神经网络的参数，应用于低剂量CT重建任务，这种方法创新点在于利用含噪数据集进行成功训练，并取自我监督训练的方法，有效提高了重建图像的质量。", "conclusion": "本文方法在低剂量CT重建任务中实现了定量和定性的双重提升，优于传统的和基于压缩感知的迭代重建方法，证明了这种方法在低剂量CT在保持图像质量的同时降低辐射剂量方面的潜力和优势。"}
{"llm_update_time": "20251116", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2505.13813", "html_url": "https://arxiv.org/abs/2505.13813", "title": "FlashKAT：理解并解决Kolmogorov-Arnold变换器中的性能瓶颈", "title_en": "FlashKAT: Understanding and Addressing Performance Bottlenecks in the Kolmogorov-Arnold Transformer", "authors": "Matthew Raffel,Lizhong Chen", "background": "Kolmogorov-Arnold网络（KAN）因其优越的表达能力和可解释性受到了越来越多的关注，但它的计算成本和训练稳定性较高，因而限制了其在大规模任务上的应用。最近，Kolmogorov-Arnold变换器（KAT）被提出，其利用团体有理KAN（GR-KAN）实现了与传统Transformer相类似的浮点运算量（FLOPs），但KAT在训练速度上仍然比传统的Transformer慢123倍，表明FLOPs并非唯一的性能瓶颈。", "innovation": "本文通过一系列实验系统性地研究了KAT训练速度慢的原因，发现主要原因在于GR-KAN正向传播回传过程中内存访问效率低。为此，论文提出一种新的FlashKAT方法，减少了对慢速内存的访问和无素加的操作，通过结构化内核使得训练速度提高了86.5倍，同时减少了梯度计算中的舍入误差。", "conclusion": "FlashKAT通过减少对慢速内存的访问和优化梯度更新运算，有效提高了KAT的训练速度。这种策略为解决KAT在大规模任务中的应用瓶颈提供了新的思路。"}
{"llm_update_time": "20251116", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2504.14795", "html_url": "https://arxiv.org/abs/2504.14795", "title": "通过基于空间相关分布的贝叶斯方法处理嘈杂标签的分割", "title_en": "A Bayesian Approach to Segmentation with Noisy Labels via Spatially Correlated Distributions", "authors": "Ryu Tadokoro,Tsukasa Takagi,Shin-ichi Maeda", "background": "在语义分割中，模型的准确度高度依赖于高质量的注释。但在许多实际应用场景，如医疗成像和遥感中，获取真实的注释并不容易，通常需要大量人力。依赖人力注释引入了诸如标注错误、遗漏和标注者之间不一致等问题。尤其是在遥感领域，采购时间差异可能导致地真实标记位移。这些标注错误并不是独立分布的，而是通常在空间相邻的区域内出现，相邻像素之间共享错误的概率较高。研究中提出了一种基于概率模型的近似贝叶斯估计方法，此模型假设训练数据包括标注错误，并且这些错误具有空间相关性。然而，基于空间相关性的离散变量的贝叶斯推断通常是不可计算的。为解决这一基本挑战，引入了一种新型的概率模型，即ECCD（ELBO-Computable Correlated Discrete Distribution），通过使用连续的高斯隐变量表示离散依赖，利用Kac-Murdock-Szegö结构协方差，本框架使得以前被认为计算上不可行的问题可以进行缩放和高效变分推断。实验结果表明，利用标签错误的空间相关性能够显著提高性能，在某些任务如肺部分割中，方法在轻微噪声条件下实现出色的表现，与使用清洁标签训练方法具有可比性能。", "innovation": "引入了一种基于概率模型的近似贝叶斯估计方法ECCD，该方法采用了连续的高斯隐变量表示离散依赖，并利用Kac-Murdock-Szegö结构协方差。这使得处理空间相关标注错误的语义分割问题变得更加可行和高效，显著提高了模型性能，特别在肺部分割等任务中表现出色。", "conclusion": "通过引入ECCD模型，研究解决了空间相关标注错误对语义分割性能影响的挑战，实验结果显示，该方法在多个分割任务上取得了显著改进，特别是在处理噪声数据时，模型表现接近于无噪声数据的训练效果。"}
{"llm_update_time": "20251116", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2506.00225", "html_url": "https://arxiv.org/abs/2506.00225", "title": "理解与探索：基于语义的主动建图", "title_en": "Understanding while Exploring: Semantics-driven Active Mapping", "authors": "Liyan Chen,Huangying Zhan,Hairong Yin,Yi Xu,Philippos Mordohai", "background": "有效在未知环境中的机器人自主性要求主动探索和对几何和语义的理解。这项研究基于3D高斯斑点（3DGS）建图基础架构，结合了语义和几何不确定性量化以及稀疏语义表示，以引导更有效的探索。", "innovation": "提出了一种名为ActiveSGM的主动语义建图框架，能够在执行前预测潜在观察的信息价值。通过允许机器人战略性地选择最有益的视角，ActiveSGM增强了建图的完整性和准确性，即使在语义数据噪声较大的情况下也能提高建图的鲁棒性。", "conclusion": "实验结果表明，ActiveSGM在Replica和Matterport3D数据集上的表现有效支持了对更适应的场景探索需求。"}
{"llm_update_time": "20251116", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.05314", "html_url": "https://arxiv.org/abs/2509.05314", "title": "ManipDreamer3D：基于占用感知3D轨迹合成合乎实际的机器人操作视频", "title_en": "ManipDreamer3D : Synthesizing Plausible Robotic Manipulation Video with Occupancy-aware 3D Trajectory", "authors": "Ying Li,Xiaobao Wei,Xiaowei Chi,Yuming Li,Zhongyu Zhao,Hao Wang,Ningning Ma,Ming Lu,Sirui Han,Shanghang Zhang", "background": "机器人操作领域中数据稀缺仍然是一个重大挑战。尽管扩散模型为生成机器人操作视频提供了一种有希望的解决方案，但现有方法主要依赖于2D轨迹，这在3D空间中存在的固有歧义性上面临问题。", "innovation": "提出了一个名为ManipDreamer3D的新框架，用于从输入图像和文本指令生成合乎实际且3D感知的机器人操作视频。该方法结合了3D轨迹规划与从第三人称视角重建的3D占用图，以及一种新颖的轨迹到视频扩散模型。该模型通过自动生成机器人操作视频，减少了人类介入的需求，且视觉质量优于现有方法。", "conclusion": "实验结果表明，与现有方法相比，本方法生成的机器人视频在视觉质量上更优，具有自主规划的合乎实际的3D轨迹。"}
{"llm_update_time": "20251116", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.20322", "html_url": "https://arxiv.org/abs/2509.20322", "title": "VisualMimic: 通过动作跟踪与生成实现视觉类人行走操作", "title_en": "VisualMimic: Visual Humanoid Loco-Manipulation via Motion Tracking and Generation", "authors": "Shaofeng Yin,Yanjie Ze,Hong-Xing Yu,C. Karen Liu,Jiajun Wu", "background": "在未结构化环境中类人的移动与操作要求紧密结合的本体视角感知与全身控制。现有方法要么依赖外部动作捕捉系统，要么在不同任务间无法泛化。", "innovation": "提出了VisualMimic，一种通过教师-学生方案训练自适应低级关键点跟踪器和特定任务高级策略的视觉仿真到现实的框架，该框架将本体视角视觉与分层全身控制统一。通过注入噪声和使用人类动作统计数据裁剪高级行动确保了稳定的训练。VisualMimic 支持多种行走操作任务，并且在户外环境中表现出良好的泛化能力。", "conclusion": "VisualMimic 在仿真中训练的视觉运动策略能够零样本地应用于实际的类人机器人，实现了包括举盒子、推、足球挑球和踢等多种行走操作任务，并在超出实验室控制环境的户外场景中表现出良好的泛化能力。"}
{"llm_update_time": "20251116", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.22689", "html_url": "https://arxiv.org/abs/2509.22689", "title": "基于图论一致性的鲁棒且拓扑感知半监督病理组织分割", "title_en": "Graph-Theoretic Consistency for Robust and Topology-Aware Semi-Supervised Histopathology Segmentation", "authors": "Ha-Hieu Pham,Minh Le,Han Huynh,Nguyen Quoc Khanh Le,Huy-Hieu Pham", "background": "在计算病理学中，密集标注的成本高且有限。现有方法通常依赖像素级别的一致性，这会导致噪声伪标签并产生不连续或拓扑不正确的掩膜。GlaS和CRAG上的实验表明，在5%-10%监督的情况下，现有的方法往往不能达到全监督时的性能。", "innovation": "本文提出了一种图论一致性框架——拓扑图一致性(TGC)，通过在预测图和参考图之间对拉普拉斯谱、组件计数和邻接统计进行对齐，来整合图论约束。这一框架保证了全局拓扑，提升了分割准确性。", "conclusion": "TGC在GlaS和CRAG数据集上实现了最先进的表现，并在5%-10%的监督下显著缩小了与全监督之间的差距。"}
{"llm_update_time": "20251116", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2511.09567", "html_url": "https://arxiv.org/abs/2511.09567", "title": "让专家发言：通过Mixture-of-Experts头部提高生存预测与校准", "title_en": "Let the Experts Speak: Improving Survival Prediction & Calibration via Mixture-of-Experts Heads", "authors": "Todd Morrill,Aahlad Puli,Murad Megjhani,Soojin Park,Richard Zemel", "background": "深度混合专家模型近年来在生存分析问题中引起了广泛关注，特别是由于其能够将相似患者分组的能力。然而，在实践中，这种分组通常会牺牲一些关键指标，如校准误差和预测准确性。这是由于混合专家模型施加的限制性归纳偏见导致的，即个体患者的预测必须类似于它们被分配到的组的预测。因此，研究人员问自己是否可以在发现存在患者组结构的同时，提高校准和预测准确性？", "innovation": "在本文中，作者引入了几种针对生存分析问题的时间离散的深度混合专家架构，其中一种架构能够同时实现聚类、校准和预测准确性这三个目标。差异在于其专家的表达力，更具有表达力的专家（针对个体患者量身定制预测）相比依赖固定组原型的专家表现更佳。", "conclusion": "通过引入这些新的混合专家模型架构，作者证明了专家的表达力是影响模型性能的关键因素，更灵活和个性化的专家能够提高整体的预测准确性与校准水平。"}
{"llm_update_time": "20251116", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2506.21765", "html_url": "https://arxiv.org/abs/2506.21765", "title": "TUS-REC2024：一项无需外部跟踪器重建3D自由手超声的挑战", "title_en": "TUS-REC2024: A Challenge to Reconstruct 3D Freehand Ultrasound Without External Tracker", "authors": "Qi Li,Shaheer U. Saeed,Yuliang Huang,Mingyuan Luo,Zhongnuo Yan,Jiongquan Chen,Xin Yang,Dong Ni,Nektarios Winter,Phuc Nguyen,Lucas Steinberger,Caelan Haney,Yuan Zhao,Mingjie Jiang,Bowen Ren,SiYeoul Lee,Seonho Kim,MinKyung Seo,MinWoo Kim,Yimeng Dou,Zhiwei Zhang,Yin Li,Tomy Varghese,Dean C. Barratt,Matthew J. Clarkson,Tom Vercauteren,Yipeng Hu", "background": "自由手超声重建旨在从一系列2D超声图像中重建3D体积，而不依赖外部跟踪系统。此方法通过消除对外部光学或电磁追踪器的需求，提供了比更昂贵的体层超声成像系统更为经济、便携和具有广泛部署性的替代方案，特别适合资源受限的临床环境。然而，预测长距离变换和处理复杂的探头轨迹仍然是挑战。因此，TUS-REC2024挑战旨在通过提供大型公开可用数据集、基线模型和严格的评估框架，构建首个无需外部追踪器的3D自由手超声重建基准。", "innovation": "TUS-REC2024挑战通过第一次公开挑战无需外部跟踪器的3D自由手超声重建，吸引了43支注册团队中的6支提交了21个有效docker容器解法。这些方法涵盖了状态空间模型、递归模型、注册驱动体积精炼、注意力机制和物理驱动模型等多种方法。该挑战提供了全面的背景介绍和文献综述，概述了挑战设计和数据集，并进行了多评价指标的提交方法比较分析，突显了当前最先进的方法的进展和局限性，并为未来研究方向提供了见解。所有数据和代码均公开，以便持续发展和可重复性。", "conclusion": "TUS-REC2024挑战作为实时和不断发展的基准设计，旨在不断改进和迭代，并将在MICCAI 2024和2025再次举办，体现了其对该领域的持续承诺。"}
{"llm_update_time": "20251116", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2511.09573", "html_url": "https://arxiv.org/abs/2511.09573", "title": "物理应用中的组平均：零训练成本的精度改进", "title_en": "Group Averaging for Physics Applications: Accuracy Improvements at Zero Training Cost", "authors": "Valentino F. Foit,David W. Hogg,Soledad Villar", "background": "许多自然科学中的机器学习任务对特定的对称性具有精确不变性。然而，这些方法往往未被使用，可能是因为训练被认为具有挑战性，或者认为对称性可以被学习，或者认为实现精确不变性的方法很困难。组平均是一种在这些情况下的可用技术，它在测试时使用，可以在不影响模 QVariant]型结构或训练的前提下，使任何训练好的模型对一个（通常较小）的群组成精确不变性，并且在证明的条件下，组平均模型的预测准确性至少与原始模型相媲美。", "innovation": "本文展示了在无需训练成本的情况下，组平均可以改善预测精度。在验证时，通过对一小群对称性进行模型平均，实验结果表明这种做法总是降低平均评估损失，精度最高可提高37%的 VRMSE。组平均还能生成视觉上更好的连续动力学预测。", "conclusion": "在某些常见情况下，强制执行精确对称性没有缺点，ML4PS社区应考虑将组平均视为改进模型精度的一种廉价且简单的方法。"}
{"llm_update_time": "20251116", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2511.09569", "html_url": "https://arxiv.org/abs/2511.09569", "title": "使用部分已知动力学进行跳变马尔可夫系统滤波：一种基于模型的深度学习方法", "title_en": "Filtering Jump Markov Systems with Partially Known Dynamics: A Model-Based Deep Learning Approach", "authors": "George Stamatelis,George C. Alexandropoulos", "background": "本文介绍了跳变马尔可夫滤波网络（JMFNet），这是一种新的基于模型的深度学习框架，用于具有未知噪声统计和模式转换动力学的跳变马尔可夫系统的实时状态估计。文章提出了一个混合架构，包含了两个循环神经网络（RNN）：一个用于模式预测，另一个基于最近提出的KalmanNet架构的增强版本，用于滤波。该研究利用交替最小二乘法策略训练这两个RNNs，使其在没有监督的情况下相互适应。", "innovation": "研究提出了一种基于模型的深度学习框架JMFNet，该框架能够在具有未知噪声统计和模式转换动力学的跳变马尔可夫系统中进行实时状态估计。该方法通过交替最小二乘法训练两个RNNs，使其能够在没有模式监督的情况下相互适应。在广泛的数值实验中，该框架在非平稳和高噪声条件下，优于经典的基于模型的滤波器（如交互的多重模型和粒子滤波器），以及无模型的深度学习基准方法。", "conclusion": "实验结果表明，JMFNet框架在复杂的系统或长时间轨迹中相比KalmanNet框架取得了显著的改进。此外，该方法的性能经过实证验证，展示了在初始条件、超参数选择以及未知模型知识方面具有低敏感性，表现出一致性和可靠性。"}
{"llm_update_time": "20251116", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2511.09559", "html_url": "https://arxiv.org/abs/2511.09559", "title": "基于定向二分图的概率偏差注意力长尾ICD编码", "title_en": "Probability-Biased Attention over Directed Bipartite Graphs for Long-Tail ICD Coding", "authors": "Tianlei Chen,Yuxiao Chen,Yang Li,Feifei Wang", "background": "国际疾病分类（ICD）编码自动化旨在为临床文档分配多个疾病代码，这是一个医学信息技术中的关键多标签文本分类任务。但由于其巨大的标签空间（10,000到20,000个编码）和长尾分布（少量编码占据主导地位而许多罕见编码缺乏足够的训练数据），该任务具有挑战性。", "innovation": "本文提出了一种学习方法，用于建模编码之间的细粒度共现关系。具体而言，构建了一个定向二分图编码器，由常见和罕见编码的分离集合构成节点。通过仅从常见代码到罕见代码的方向性边促进了一维信息流，并通过概率偏差定义了这些连接的特点。该偏差源自罕见代码存在的条件下常见代码共现的概率条件概率。此偏差注入到编码器的注意力模块，称之为共现编码。此外，为了提供高质量的输入，利用大型语言模型(Large Language Model)生成代码的全面描述，将临床语境和共病信息充实到初始嵌入中，作为统计共现关系在分类代码系统中的外部知识支撑。实验结果表明，该方法在三个自动ICD编码基准数据集上达到了最先进的性能，特别是在宏F1分数方面有显著提升，这是长期尾分类的关键指标。", "conclusion": "实验证明，本文提出的方法在三个自动ICD编码基准数据集上表现出色，尤其是在宏F1分数上取得了显著的改进，证明了该方法在处理长尾分类问题上的优越性。"}
{"llm_update_time": "20251116", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2511.09586", "html_url": "https://arxiv.org/abs/2511.09586", "title": "在交互学习时代为LLM代理扩展环境的研究", "title_en": "Scaling Environments for LLM Agents in the Era of Learning from Interaction: A Survey", "authors": "Yuchen Huang,Sijia Li,Minghao Liu,Wei Liu,Shijue Huang,Zhiyuan Fan,Hou Pong Chan,Yi R. Fung", "background": "LLM代理可以通过自主学习完成跨行业复杂任务。然而，通过静态数据集进行训练，这种方法在培养适应性和长期决策等能力方面存在不足。这些数据集成本高，缺乏动态性和现实感。当前共识认为，代理应直接与环境互动，并通过强化学习从经验中学习。为此，文章将这一过程形式化为一个逐步优化的环路（Generation-Execution-Feedback, GEF），在这一环路中，环境生成挑战性任务、提供观察反馈并给出评估性反馈以辅助学习。在这种范式下，环境被视为不可或缺的数据生产者，强调了其复杂性、真实性和互动性的扩展需求。", "innovation": "本文系统地从环境中心的角度回顾了环境扩展的方法，并将这些方法组织到GEF环路的不同阶段，包括任务生成、任务执行和反馈。此外，文章还分析了基准、实施策略和应用，整合了碎片化的进步，并指出了代理智能的未来研究方向。", "conclusion": "文章为代理智能技术的发展提供了理论支持和实用指导，明确了未来的研发重点，强调了环境在培养LLM代理能力中的关键作用，特别是环境的复杂性、真实性和互动性扩展的重要性。"}
{"llm_update_time": "20251116", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2511.09578", "html_url": "https://arxiv.org/abs/2511.09578", "title": "HeatGen：一种多物理场热沉设计优化的引导扩散框架", "title_en": "HeatGen: A Guided Diffusion Framework for Multiphysics Heat Sink Design Optimization", "authors": "Hadi Keramati,Morteza Sadeghi,Rajeev K. Jaiman", "background": "该研究提出了一种基于引导去噪扩散概率模型（DDPM）的生成优化框架，利用替代梯度生成同时满足低压力降和表面温度限制的热沉设计。通过多保真方法生成训练数据，并利用这些数据训练去噪扩散概率模型，以生成具有与数据相应的特性的热沉。该模型使用与设计变量相关的替代模型的梯度来引导几何生成过程，以满足低压力和表面温度的约束条件。这种方法在推理阶段对生成过程进行指导，导致不仅防止过热，而且实现与传统优化方法（如CMA-ES）相比更低的压力降的热沉设计。", "innovation": "该研究提出了一种新的方法，利用DDPM和替代梯度来生成热沉设计，以满足低压力和表面温度限制。这种方法在推理阶段使用替代模型的梯度来直接指导热沉设计，避免了传统方法需要多次重新训练的问题。与其他不需要重新训练的拓扑优化方法相比，即使使用黑盒优化方法，训练后仅在计算上负担较少，可以应对新的约束条件下的推理。实验结果表明，使用DDPM生成的样本在压力降方面比传统黑盒优化方法低10%以上。这项工作为构建电子冷却的生成模型奠定了基础", "conclusion": "该研究开发了一种新颖的热沉设计优化方法，能够高效生成同时满足低压力降和表面温度限制的热沉设计，并且在推理阶段可以轻松地应用新的约束条件。这种方法为电子冷却领域提供了新的解决方案，并为进一步开发自动化热管理组件生成模型铺平了道路。"}
{"llm_update_time": "20251116", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2511.09593", "html_url": "https://arxiv.org/abs/2511.09593", "title": "DynamicRTL：用于动态电路行为的RTL表示学习", "title_en": "DynamicRTL: RTL Representation Learning for Dynamic Circuit Behavior", "authors": "Ruiyang Ma,Yunhao Zhou,Yipeng Wang,Yi Liu,Zhengyuan Shi,Ziyang Zheng,Kexin Chen,Zhiqiang He,Lingwei Yan,Gang Chen,Qiang Xu,Guojie Luo", "background": "目前，有关使用图形神经网络（GNNs）来学习电路表示的研究越来越多，这些研究主要侧重于静态特性。然而，这些模型未能捕捉电路的运行时行为，这对于电路验证和优化任务至关重要。为了解决这一局限性，作者提出了DR-GNN（DynamicRTL-GNN），一种通过结合静态结构和多周期执行行为来学习RTL电路表示的新型方法。DR-GNN利用操作级控制数据流图（CDFG）表示寄存器传输级（RTL）电路，从而使模型能够捕捉动态依赖关系和运行时执行。", "innovation": "DR-GNN 通过引入操作级控制数据流图（CDFG）来代表寄存器传输级（RTL）电路，使其能够捕捉动态依赖关系和运行时执行行为。为了训练和评估 DR-GNN，作者构建了第一个全面的动态电路数据集，包括超过 6,300 个Verilog 设计和 63,000 个模拟轨迹。实验结果表明，DR-GNN 在分支命中预测和翻转率预测任务上优于现有模型，并且其学习的表示可以有效地转移到相关动态电路任务，如功耗估计和断言预测。", "conclusion": "DR-GNN 能够通过结合静态结构和多周期行为来学习 RTL 电路的动态表示，显著提升了电路验证和优化任务的效果。通过构建动态电路数据集，DR-GNN 在分支命中预测和翻转率预测中表现优异，并且其学习到的表示在其他动态电路任务中也能有效应用。"}
{"llm_update_time": "20251116", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2511.09598", "html_url": "https://arxiv.org/abs/2511.09598", "title": "通过生成解决方案建模实现参数化昂贵多目标优化", "title_en": "Parametric Expensive Multi-Objective Optimization via Generative Solution Modeling", "authors": "Tingyang Wei,Jiao Liu,Abhishek Gupta,Chin Chun Ooi,Puay Siew Tan,Yew-Soon Ong", "background": "许多实际应用需要在不同操作条件下解决昂贵的多目标优化问题（EMOPs），这导致了参数化昂贵多目标优化问题（P-EMOPs）出现，每个任务参数定义了一个不同的优化实例。现有的多目标贝叶斯优化方法主要用于为个别任务寻找有限的 Pareto 最优解集，但 P-EMOPs 呈现出一个基本的挑战：连续的任务参数空间包含无限多个不同的优化问题，每个都需要昂贵的评估。这需要学习一个逆模型来直接预测任何任务偏好查询的优化解决方案，无需昂贵的重新评估。目前还没有针对 P-EMOPs 的参数化多目标贝叶斯优化方法来解决这一挑战。", "innovation": "本文提出了第一个针对 P-EMOPs 的参数化多目标贝叶斯优化器，通过交替利用（1）利用任务间协同效应的获取驱动搜索和（2）通过条件生成模型的生成解决方案采样来学习这个逆模型。这种方法允许高效地跨相关任务进行优化，并最终实现了直接预测未见参数化 EMOPs 的解决方案，无需额外的昂贵评估。通过使用任务感知高斯过程利用任务间协同效应来证明更快的收敛性，以及在合成和实际应用基准上的实证研究进一步验证了我们交替框架的有效性。", "conclusion": "通过交替框架，我们的工作实现了一种有效的参数化多目标优化策略，该方法能够在不需要额外昂贵评估的情况下直接预测未见参数化 EMOPs 的优化解决方案，而现有的方法无法做到这一点。"}
{"llm_update_time": "20251116", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2511.09596", "html_url": "https://arxiv.org/abs/2511.09596", "title": "没有速度-性能权衡的每一头都算数：无损稀疏注意力", "title_en": "Making Every Head Count: Sparse Attention Without the Speed-Performance Trade-off", "authors": "Mingkuan Zhao,Wentao Hu,Jiayin Wang,Xin Lai,Tianchen Huang,Yuheng Min,Rui Yan,Xiaoyan Zhu", "background": "大型语言模型（LLMs）的设计长期以来受限于其核心注意力机制中的根本冲突：这种机制具有非凡表现力的前提是计算复杂度为$O(H \times N^2)$，且随着上下文大小（$N$）和头数（$H$）的增加而增加。现有稀疏方法虽然提高了计算效率，但往往牺牲了信息完整性。论文指出，现有方法存在显著的计算冗余，所有头都独立地在相同的序列空间计算注意力，这导致了效率-性能权衡问题。", "innovation": "论文提出了SPAttention，引入了一种新的指导原则结构稀疏性（Principled Structural Sparsity）机制。SPAttention 通过对总注意力工作负载进行分区，将多头注意机制转变为分段协作任务，由此使$H$个独立的$O(N^2)$计算变成了单个$O(N^2)$计算，从而减少了$H$倍的复杂度。结构化的归纳偏置促使每个头的功能专业化，更有效地分配计算资源，从冗余建模转向整个序列范围内的独特依赖关系。实验结果显示SPAttention显著提高了训练吞吐量（约两倍），在某些关键指标上甚至超过了标准密集注意力，且在所有评估指标上超过了Longformer、Reformer和BigBird等代表性稀疏注意力方法。", "conclusion": "SPAttention通过结构化稀疏的方法解决了速度-性能权衡问题。与当前稀疏方法相比，SPAttention能够减少计算冗余，提高模型效率。广泛的实验表明，该方法不仅提升了训练效率，还在某些情况下达到了甚至超过了标准密集注意力的效果，特别是在大量模型上验证了其优越性。"}
{"llm_update_time": "20251116", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2511.09652", "html_url": "https://arxiv.org/abs/2511.09652", "title": "基于量纲目标的乐观强化学习", "title_en": "Optimistic Reinforcement Learning with Quantile Objectives", "authors": "Mohammad Alipour-Vaezi,Huaiyang Zhong,Kwok-Leung Tsui,Sajad Khodadadian", "background": "近年来，强化学习（RL）取得了巨大的成功。然而，传统的RL基础没有考虑到目标函数的风险敏感性，这是在包括医疗保健和金融等各个领域至关重要的因素。一种常用的方法是优化累积奖励分布的具体分位数。本文关注于在有限时期马尔可夫决策过程（MDPs）中针对τ-分位数目标函数的乐观学习算法。", "innovation": "本文开发了UCB-QRL算法，这是一种在有限时期MDPs中针对τ-分位数目标函数的乐观学习算法。在每次迭代中，首先估计底层的转移概率，然后在该估计的置信球上优化分位数价值函数。研究表明，UCB-QRL在episodic设置下具有高概率遗憾上界$\text{Ο}\big((2/\text{κ})^{H+1}H\text{√}(SAH\text{log}(2SAH/\text{δ}))\big)$。这里，$\text{κ}>0$是与MDP相关的一个常数，它捕获了MDP的不同敏感性。", "conclusion": "本文提出了UCB-QRL算法，这是一种针对有限时期MDPs中τ-分位数目标函数的乐观学习算法，证明了其理论上具有有效的高概率遗憾上界。"}
{"llm_update_time": "20251116", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2511.09665", "html_url": "https://arxiv.org/abs/2511.09665", "title": "从单个表格中出现泛化现象的表格基础模型", "title_en": "Generalization Can Emerge in Tabular Foundation Models From a Single Table", "authors": "Junwei Ma,Nour Shaheen,Alex Labach,Amine Mhedhbi,Frank Hutter,Anthony L. Caterini,Valentin Thomas", "background": "深度表格建模越来越多地依赖于上下文学习（Conext Learning），在这种情况下，模型在推理期间接收$(x, y)$对作为上下文，并预测新输入的标签而无需权重更新。当前普遍认为，广泛的泛化需要在大规模合成数据集（如TabPFN先验）或大量真实数据集（如TabDPT训练数据集）上进行预训练。本文挑战了这一观点，发现相对少量的数据即可实现良好的泛化效果。通过在多种不同数据集上系统地进行预训练与评估，研究核心数据的哪些方面对于构建跨领域泛化的表格基础模型（TFM）最重要。", "innovation": "发现简单的自我监督预训练只需要一个单一的真实表格即可在异构基准上产生令人惊讶的强大迁移效果。进而揭示构建任务的数量和质量对后续性能至关重要，这直接影响大多数TFMs所共享的预训练过程的有效性。", "conclusion": "无论是在单个真实表格上的自我监督预训练还是通过多种不同数据集的系统化预训练与评估，关键在于数据本身的重要特征，这些特征有助于构建泛化能力更强的表格基础模型。"}
{"llm_update_time": "20251116", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2511.09681", "html_url": "https://arxiv.org/abs/2511.09681", "title": "SEBA: 样本高效的目标视觉强化学习黑盒攻击", "title_en": "SEBA: Sample-Efficient Black-Box Attacks on Visual Reinforcement Learning", "authors": "Tairan Huang,Yulin Jin,Junxu Liu,Qingqing Ye,Haibo Hu", "background": "视觉强化学习在视觉控制和机器人领域取得了显著进展，但在对抗性扰动下的脆弱性仍被忽视。现有大部分黑盒攻击主要针对基于向量或离散动作的强化学习，这些攻击在针对基于图像的连续控制时效果受限，因为存在庞大的动作空间和次级环境查询需求。", "innovation": "SEBA 提出了一种样本高效框架，用于针对视觉奖励学习代理的黑盒对抗性攻击。该框架结合了一个阴影 Q 模型，用于估计对抗条件下的累计奖励；一个生成对抗网络，用于产生视觉上不可感知的扰动；以及一个世界模型，用于模拟环境动力学，从而减少对实际环境的查询。通过交替学习阴影模型和优化生成器的两阶段迭代训练过程，SEBA 在保持效率的同时实现了强大的攻击表现。", "conclusion": "实验表明，SEBA 在 MuJoCo 和 Atari 指标上显著减少了累积奖励，保持了视觉保真度，大幅减少了环境互动，相较于先前的黑盒和白盒方法更加有效。"}
{"llm_update_time": "20251116", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2511.09677", "html_url": "https://arxiv.org/abs/2511.09677", "title": "Boosted GFlowNets：通过顺序学习提高探索能力", "title_en": "Boosted GFlowNets: Improving Exploration via Sequential Learning", "authors": "Pedro Dall'Antonia,Tiago da Silva,Daniel Augusto de Souza,César Lincoln C. Mattos,Diego Mesquita", "background": "Generative Flow Networks (GFlowNets) 是一种强大的生成器，用于采样组合对象，并且设计上能够根据给定的非负奖励进行比例采样。然而，在实践中，它们往往难以均匀地探索奖励景观：容易到达区域的路径在训练中占主导地位，难以到达的区域则几乎得不到梯度激励，导致高奖励区域覆盖不足。", "innovation": "提出了 Boosted GFlowNets 方法，该方法通过顺序训练一个 GFlowNets 集合，每个模型优化补偿先前模型已捕捉的质量的残差奖励。这种方法在未开发区域重新激活学习信号，并在温和的假设下确保单调非降特性：增加补强器不会恶化学到的分布，并且通常会改进它。实验证明，Boosted GFlowNets 在多模态合成基准和肽设计任务上实现了更好的探索和样本多样性，同时保留了标准轨迹平衡训练的稳定性和简洁性。", "conclusion": "Boosted GFlowNets 通过补偿残差奖励确保了在未开发区域更均匀地探索奖励景观，并且在整个训练过程中增加了样本覆盖范围和多样性，提升了整体性能。"}
{"llm_update_time": "20251116", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2511.09672", "html_url": "https://arxiv.org/abs/2511.09672", "title": "GEM+: 使用生成器网络的高效隐私保护合成数据", "title_en": "GEM+: Scalable State-of-the-Art Private Synthetic Data with Generator Networks", "authors": "Samuel Maddock,Shripad Gade,Graham Cormode,Will Bullock", "background": "目前，差分隐私的合成表数据大多基于自适应的‘测量-度量-生成’框架，如AIM方法。这些方法通过迭代测量低阶的噪声边际和拟合图形模型来生成合成数据，从而在隐私约束下优化数据质量。图形模型在高维数据上效率较低，因为它们需要大量的内存，并且每改变一次图形结构就需从头再训练一次，导致了大量的计算开销。最近的方法，如GEM，通过使用生成器神经网络提高可扩展性，解决了这一问题。但是，现有的实验主要集中在小型数据集上，限制了其在现实世界中的适用性。", "innovation": "本文引入了GEM+，它将AIM的自适应测量框架与GEM的可扩展生成器网络结合了起来。实验结果表明，GEM+在实用性和可扩展性方面优于AIM，并且能够高效处理包含一百多列的大型数据集，而AIM因内存和计算开销问题在此类型的数据集上表现不佳。", "conclusion": "GEM+在保留了生成器网络的高效性和模块化优势的同时，还继承了状态领先的自适应测量框架，实现了在大数据集上的高表现，证明了其在实际应用中的潜力。"}
{"llm_update_time": "20251116", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2511.09693", "html_url": "https://arxiv.org/abs/2511.09693", "title": "ConstrainedSQL: 使用约束强化学习训练用于Text2SQL的LLMs", "title_en": "ConstrainedSQL: Training LLMs for Text2SQL via Constrained Reinforcement Learning", "authors": "Weiqin Chen,Nhan Huu Pham,Michael Robert Glass,Long Hai Vu,Gaetano Rossiello,Dharmashankar Subramanian,Santiago Paternain", "background": "强化学习（RL）在提升Text2SQL语言模型的推理能力方面展示了显著潜力，尤其是在使用GRPO和DAPO等先进算法后。然而，这些方法的性能高度依赖于奖励函数的设计。不合适的奖励可能导致奖励作弊现象，即模型通过利用奖励结构中的漏洞来取得高分，而实际上并未真正解决问题。", "innovation": "本文提出了一种受限的RL框架应用于Text2SQL场景，该框架整合了自然且可解释的奖励和约束信号，同时在训练过程中动态平衡这些信号之间的权衡。我们为该受限的RL框架建立了理论保证，通过在知名Text2SQL数据集上的数值实验验证了该方法相比现有最先进的RL训练LLMs的优越性。", "conclusion": "我们的受限RL框架通过理论保证和实验验证，证明了在Text2SQL任务中相较于现有最先进的RL训练LLMs方法的有效性提高。"}
{"llm_update_time": "20251116", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2511.09731", "html_url": "https://arxiv.org/abs/2511.09731", "title": "FlowCast: 采用条件流匹配提升降水现在预警", "title_en": "FlowCast: Advancing Precipitation Nowcasting with Conditional Flow Matching", "authors": "Bernardo Perrone Ribeiro,Jana Faganeli Pucer", "background": "雷达基降水现在预警的任务是根据以前的雷达图像来预测短期内的降水区域，这对于洪水风险管理与决策十分重要。尽管深度学习已经在该领域取得了显著进展，但面临的两大挑战是大气动态的不确定性以及高效建模高维数据。扩散模型虽然能够产生清晰可靠的预测结果，但其迭代采样过程在时间关键型应用中耗时较长。", "innovation": "我们引入了FlowCast模型，这是首次将条件流匹配（Conditional Flow Matching, CFM）应用于降水现在预警。CFM学习直接从噪声到数据的映射关系，使之能够迅速生成高保真的样本，且函数评估次数显著减少。实验结果表明，FlowCast在预测精度上达到了新的最佳水平，并且与扩散模型相比，CFM目标更精确且效率更高，能够显著减少采样步骤，维持高性能。", "conclusion": "这项工作将CFM作为一种强大的、实际可行的替代方案用于高时空维度的预报，特别是适用于时间关键型应用。"}
{"llm_update_time": "20251116", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2511.09729", "html_url": "https://arxiv.org/abs/2511.09729", "title": "使用方程感知神经运算器泛化PDE拟合", "title_en": "Generalizing PDE Emulation with Equation-Aware Neural Operators", "authors": "Qian-Ze Zhu,Paul Raccuglia,Michael P. Brenner", "background": "传统的数值方法求解偏微分方程（PDEs）成本高昂。基于深度学习的代理模型通常针对单一具有固定参数的PDE进行优化，缺乏泛化到未见过的PDE的能力。本文提出了一种基于神经模型的方程感知仿生框架，通过将PDE中各项及其系数进行编码，并以此作为条件训练神经模型，使得模型能够泛化到未见过的PDE。该研究属于一个更广泛的探索自动创建可评分科学任务的专家级经验软件的AI系统努力的一部分。", "innovation": "提出了一种基于神经模型的方程感知仿生框架，能够泛化到未见过的PDE，这是通过将PDE中各项及其系数进行编码并训练神经模型来实现的。这种方法在参数集上的表现强于训练分布，并且长时间模拟具有很强的稳定性，还能够泛化到完全未见过的PDE。", "conclusion": "本研究展示了方程感知神经运算器可有效泛化到未见过的PDE，实现了在未知参数集上的强大性能和长期模拟的稳定性，并成功将完全未见过的PDE也进行泛化。未来工作的目标是进一步扩展此类模型的应用范围和能力。"}
{"llm_update_time": "20251116", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2511.09708", "html_url": "https://arxiv.org/abs/2511.09708", "title": "高效模复合表示的超维度计算（Efficient Hyperdimensional Computing with Modular Composite Representations）", "title_en": "Efficient Hyperdimensional Computing with Modular Composite Representations", "authors": "Marco Angioli,Christopher J. Kymn,Antonello Rosato,Amy Loutfi,Mauro Olivieri,Denis Kleyko", "background": "模块复合表示（MCR）是一种使用模运算表示高维整数向量的计算模型。它最初是作为二进制斑点码模型的扩展提出，旨在提供更大的表示能力，同时作为一个比要求高精度组件的模型更轻量的选择。尽管有这种潜力，MCR仍然未能获得广泛的关注，系统地分析其权衡及其与其他模型的比较不足，使得人们对它的额外复杂性是否超过了改进的表达性保持怀疑。", "innovation": "本文通过首次对MCR进行详细评估，证明了其在容量、准确性和硬件效率方面实现了独特的平衡。实验表明，MCR在容量上优于二进制和整数向量，且只占用复数值表示法较少的内存空间。在123个数据集上的评估显示，与二进制斑点码相比，MCR可以节省多达4倍的内存而保持一致的准确率增益。通过数字逻辑展示了MCR的硬件实现，并设计了首个专用加速器。针对基本操作和7个选定数据集的评估表明，与软件实现相比速度提高了3个数量级，并且显著降低了能耗。针对准确率与二进制斑点码匹配时，MCR均表现出3.08倍的速度提升和2.68倍的能效降低。", "conclusion": "这些发现证明，尽管MCR需要比二进制斑点码更复杂的操作，但由于其模运算和每个组件更高的精度，MCR可以实现更低维度。当通过专用硬件实现时，结果是一个更快、更节能且更精确的替代现有模型的选择。"}
{"llm_update_time": "20251116", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2511.09737", "html_url": "https://arxiv.org/abs/2511.09737", "title": "使用SPARC在陌生环境中进行分布外泛化：用单一策略进行100辆赛车的驾驶", "title_en": "Out-of-Distribution Generalization with a SPARC: Racing 100 Unseen Vehicles with a Single Policy", "authors": "Bram Grooten,Patrick MacAlpine,Kaushik Subramanian,Peter Stone,Peter R. Wurman", "background": "在机器人学和控制领域，向未见过的环境中推广是一个重大挑战。本文关注有上下文的强化学习，其中智能体需要在改变的环境中进行操作，类似自动驾驶汽车或四足机器人，必须适应比训练条件更广泛的地形或天气条件。最近的研究试图通过分阶段训练上下文编码器和历史适应模块来处理这个问题，但这种方法实施和训练复杂。本文简化了这一方法，提出了一种单阶段适应方法——SPARC，能实现可靠且鲁棒的分布外泛化。", "innovation": "提出了一种单阶段适应方法SPARC，简化了当前的两阶段训练方法，解决了在未见过的环境中推广的问题，且不需要在测试时间使用明确的上下文信息。", "conclusion": "对高保真赛车模拟器Gran Turismo 7和风扰动的MuJoCo环境中的不同上下文进行了测试，结果表明SPARC能够实现可靠的和鲁棒的分布外泛化。"}
{"llm_update_time": "20251116", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2511.09736", "html_url": "https://arxiv.org/abs/2511.09736", "title": "数据异质性与遗忘标签在分裂联邦学习中的现象", "title_en": "Data Heterogeneity and Forgotten Labels in Split Federated Learning", "authors": "Joana Tirana,Dimitra Tsigkari,David Solans Noguero,Nicolas Kourtellis", "background": "在分裂联邦学习（SFL）中，客户端通过服务器的帮助协作训练模型，将模型分为两部分。部分1（Part-1）在每个客户端本地训练，在每轮结束时由聚合器进行汇总。部分2（Part-2）在服务器上训练，并按顺序处理来自每个客户端的中间激活。由于SFL的特性，本地更新的Part-1可能偏离全局最优值，而Part-2对处理顺序敏感，类似于不断学习（CL）中的遗忘现象。研究发现，训练的模型在序列末尾看到的类别（标签）上的表现更好。", "innovation": "对SFL中数据异质性导致的灾难性遗忘现象进行了研究，特别是重点研究了服务器处理顺序和分割层的关键方面。根据研究结果，提出了一种名为Hydra的新缓解方法，该方法灵感来自多头神经网络，并且专门针对SFL设置进行了调整。广泛的数值评估表明，Hydra在性能上优于基准和文献中的其他方法。", "conclusion": "研究结果表明，在存在数据异质性的情况下，分裂联邦学习中存在灾难性遗忘现象。提出的Hydra方法有效地缓解了该问题，显著提高了模型在序列末尾看到的类别上的表现。"}
{"llm_update_time": "20251116", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2511.09741", "html_url": "https://arxiv.org/abs/2511.09741", "title": "TawPipe：加速训练长上下文大规模模型的拓扑感知权重管道并行性", "title_en": "TawPipe: Topology-Aware Weight Pipeline Parallelism for Accelerating Long-Context Large Models Training", "authors": "Houming Wu,Ling Chen", "background": "训练大型语言模型（LLMs）受到设备内存有限和设备间通信成本高的限制。管程并行性通过在设备间划分模型来缓解内存压力，但在长上下文训练中，激活物体通信开销会随着序列长度线性增加，影响效率。尽管已有方法（如WeiPipe）通过传输模型权重而非激活物体来减轻该问题，但仍存在冗余的点对点传输及节点内带宽未充分利用的问题。", "innovation": "TawPipe利用分布式集群中的分层带宽以提高通信效率，具体而言，(i) 基于拓扑对设备进行分组，优化节点内集体通信和节点间点对点通信；(ii) 每个设备固定一个模型权重和梯度片断，避免冗余传输；(iii) 将通信与计算重叠以隐藏延迟。与全面分割数据并行（FSDP）中使用的全局集体操作不同，TawPipe将大部分通信限制在节点边界内，显著减少跨节点传输。", "conclusion": "在最多24个GPU上对LLaMA风格的模型进行广泛实验表明，TawPipe在吞吐量和可扩展性方面均优于最先进的基线方法。"}
{"llm_update_time": "20251116", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2511.09754", "html_url": "https://arxiv.org/abs/2511.09754", "title": "历史咏叹：宏参数检索在稳健金融预测中的应用", "title_en": "History Rhymes: Macro-Contextual Retrieval for Robust Financial Forecasting", "authors": "Sarthak Khanna,Armin Berger,Muskaan Chopra,Rafet Sifa", "background": "金融市场本质上是非平稳的：结构突变和宏观经济制度转变常导致脱域数据（OOD）环境下预测模型失效。传统多模态方法通常仅融合数值指标和文本情感，未能适应这些变化。因此，研究者需要一个能够适应宏观经济环境变化的预测框架。", "innovation": "本文提出了一种宏参数检索方法，这是一种增强型检索增强预测框架，能够在预测时将每个预测与历史上类似的历史宏观经济环境相关联。该方法联合嵌入宏观经济指标（如CPI、失业率、收益率差、GDP增长率）和金融新闻情感，在共享相似性空间中，使得在推理时无需重新训练即可进行因果检索。通过在17年S&P 500数据（2007-2023）上训练并在苹果（AAPL）和雪佛龙（XOM）2024年的数据上评估，该框架在cv到OOD性能差距上表现出持续降低，宏条件检索实现了唯一的积极非样本交易结果，而静态数值、纯文本和朴素的多模态基线在制度转变下会崩溃。", "conclusion": "宏参数检索通过因果理论上实现了稳健、可解释的预测，鼠标操作的原则是“金融历史不重复但常韵脚”，证明了在分布变化下这种有前瞻性的检索方法可以提供准确和透明的预测结果。所有数据集、模型和源代码都公开可供访问。"}
{"llm_update_time": "20251116", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2511.09773", "html_url": "https://arxiv.org/abs/2511.09773", "title": "NeuroLingua: 一种基于语言启发式层次框架的多模态睡眠阶段分类方法 (使用EEG和EOG)", "title_en": "NeuroLingua: A Language-Inspired Hierarchical Framework for Multimodal Sleep Stage Classification Using EEG and EOG", "authors": "Mahdi Samaee,Mehran Yazdi,Daniel Massicotte", "background": "自动睡眠阶段分类从多导睡眠图 (polysomnography) 中仍然受到缺乏表达性的时间层次结构、EEG和EOG多模态融合的挑战以及深度学习模型的低解释性所限制。", "innovation": "提出了一种基于语言的框架NeuroLingua，将睡眠视为有结构的生理语言。每个30秒的周期分解为重叠的3秒子窗口（“标记”），并通过基于CNN的标记器实现，使用双级Transformer进行层次时间建模：局部依赖的内部控制编码和连续七个周期（3.5分钟）之间扩展上下文的跨段整合。通过图卷积网络融合来自EEG和EOG通道的模态特定嵌入，促进稳健的多模态集成。NeuroLingua在Sleep-EDF Expanded和ISRUC-Sleep数据集上进行评估，达到最先进的准确率 (85.3%)、宏F1 (0.800) 和Cohen's kappa (0.796)。该架构的注意力机制增强了临床相关睡眠微事件的检测，为睡眠研究中的可解释性、可解释性和因果推理奠定了原则性的基础。", "conclusion": "通过将睡眠视为组合语言，NeuroLingua统一了层次序列建模和多模态融合，朝着更透明和具有临床意义的应用方向推进了自动化睡眠阶段分类。"}
{"llm_update_time": "20251116", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2511.09780", "html_url": "https://arxiv.org/abs/2511.09780", "title": "探索去中心化GRPO中的攻击与防御：盗贼的伟大胜利", "title_en": "Hail to the Thief: Exploring Attacks and Defenses in Decentralised GRPO", "authors": "Nikolay Blagoev,Oğuzhan Ersoy,Lydia Yiyu Chen", "background": "Group Relative Policy Optimization (GRPO)已经证明了在大型语言模型（LLMs）的训练后使用方面的巨大潜力。在GRPO中，模型通过强化学习来学习优选的完成方式，这种方式通过回答提示来实现。由于通信量小，GRPO天生适合去中心化训练，因为可以通过多个节点同时回答提示，然后以字符串形式交换。", "innovation": "本文首次提出了去中心化GRPO中的对抗性攻击。研究表明，恶意参与者可以通过在良性模型中注入任意恶意标记来污染系统，在上下文攻击和离文攻击中均可实现。通过数学和编程任务的实证示例，本文展示了对抗性攻击可以在短短50个迭代中使良性节点受到污染，成功率为100%。提出了针对这些攻击的两种防御方法，取决于所有用户是否训练相同的模型还是不同的模型。这些防御方法可以实现高达100%的成功阻止率，使攻击成为不可能。", "conclusion": "本文提出了去中心化GRPO中的首个对抗性攻击，并证明了其有效性和危害性。同时，针对这一威胁提出了有效的防御措施，确保GRPO的安全性和可靠性。"}
{"llm_update_time": "20251116", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2511.09763", "html_url": "https://arxiv.org/abs/2511.09763", "title": "恶毒噪声实际上比恶意噪声更难吗？", "title_en": "Is nasty noise actually harder than malicious noise?", "authors": "Guy Blanc,Yizhi Huang,Tal Malkin,Rocco A. Servedio", "background": "本文研究了在两种广为人知且具有挑战性的对抗性噪声模型下，有效算法在学习布尔函数时的相对能力和局限性。这两种噪声模型是：敌手噪声，其中敌手可以任意篡改提供给学习者的随机子集样本；恶劣噪声，其中敌手可以任意篡改提供给学习者的精心选择的子集样本。研究了分布独立和固定分布两种设置下的问题。在分布独立学习设置下，证明当出现η比率为恶意噪声时，该函数类的高效可学习性与出现η比率为恶劣噪声时的高效可学习性之间存在强烈等价性；然而，在固定分布设置下，发现两者之间存在任意大的分离：在标准加密假设下，对于任何任意大的值r，都存在一个概念类，使得多项式时间学习算法可以容忍的恶意噪声率η_malicious与可以容忍的恶劣噪声率η_nasty之间的比率可以达到r。为了缓解固定分布设置下的消极结果，定义了一种广泛的且自然的算法类别，即忽略矛盾样例（ICE）的算法。然后发现这两种噪声在噪音率上的等价性最多差一个因子2：任何高效ICE学习者，如果它在η比率为恶意噪声时成功，可以转换为高效的学习者，该学习者在η/2比率为恶劣噪声时成功。同时证明了这个因子2是最必要的，再次在标准加密假设下成立。", "innovation": "文章首次在固定分布设置下展示了恶意噪声和恶劣噪声之间的显著性能差异，并且定义了忽略矛盾样例（ICE）算法，并证明了恶意噪声下和恶劣噪声下的学习能力最多相差一个因子2。同时，研究给出了ICE算法下恶意噪声和恶劣噪声等价性的必要条件", "conclusion": "恶毒噪声实际上比恶意噪声更难。这一发现为在两种不同的噪声模型下实现高效学习算法的任务提供了新的见解。"}
{"llm_update_time": "20251116", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2511.09783", "html_url": "https://arxiv.org/abs/2511.09783", "title": "科祖曼不变量作为联合嵌入预测架构中 Emergent 时间序列聚类的驱动因素", "title_en": "Koopman Invariants as Drivers of Emergent Time-Series Clustering in Joint-Embedding Predictive Architectures", "authors": "Pablo Ruiz-Morales,Dries Vanoost,Davy Pissoort,Mathias Verbeke", "background": "联合嵌入预测架构（JEPAs）是一种强大的自监督模型，表现出一种无法解释的能力，能够通过其基础动态模式来聚类时间序列数据。", "innovation": "作者提出了一个关于 JEPAs 这种现象的新型理论解释，假设 JEPAs 的预测目标隐式地驱动它学习系统科祖曼算子的不变子空间。作者证明，理想化的 JEPAs 损失在编码器表示系统状态的不变指标函数（科祖曼本征函数）时被最小化。此外，作者探讨了将线性预测器约束为接近恒等算子这一限制对模型设计的重要性，揭示了预测器在表示解纠缠方面的作用。", "conclusion": "该研究揭示了 JEPAs 的一项关键行为，建立了一个现代自监督学习与动力系统理论之间的原理性联系，并为更稳健和可解释的时间序列模型设计提供了指导。"}
{"llm_update_time": "20251116", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2511.09789", "html_url": "https://arxiv.org/abs/2511.09789", "title": "CaReTS: 统一分类与回归的多任务框架用于时间序列预测", "title_en": "CaReTS: A Multi-Task Framework Unifying Classification and Regression for Time Series Forecasting", "authors": "Fulong Yao,Wanqing Zhao,Chao Zheng,Xiaofei Han", "background": "近年来深度预测模型取得了显著的成果，但大多数方法仍然难以同时提供准确的预测和对时间动态的可解释洞察。本文对这类挑战进行分析，指出现有的方法在准确性和可解释性之间存在权衡。", "innovation": "本文提出了CaReTS，这是一种新颖的多任务学习框架，结合了分类和回归任务，特别适用于多步时间序列预测问题。该框架采用了双流架构，一个分类支路学习未来逐步趋势，一个回归支路估计目标变量最新观测值的相应偏差。双流设计通过分离宏观趋势和微观偏差提供了更可解释的预测。此外，设计了一种具有不确定性感知权重的多任务损失函数，以自适应地平衡每个任务的贡献。该框架还实例化了四种变体（CaReTS1-4），结合了主流的时间建模编码器，包括卷积神经网络（CNN）、长短期记忆网络（LSTM）和Transformer。", "conclusion": "实验结果表明，CaReTS在预测精度上优于最先进的算法，同时在趋势分类性能上也表现出色。"}
{"llm_update_time": "20251116", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2511.09792", "html_url": "https://arxiv.org/abs/2511.09792", "title": "超越单调性：重访多智能体 Q 学习中的因子化原理", "title_en": "Beyond Monotonicity: Revisiting Factorization Principles in Multi-Agent Q-Learning", "authors": "Tianmeng Hu,Yongzheng Cui,Rui Tang,Biao Luo,Ke Li", "background": "多智能体强化学习（MARL）中，价值分解是一种核心方法，通过将全局价值函数分解为局部值，实现了集中训练与分散执行的融合。为确保个体-全局-最大（IGM）一致性，现有方法要么施加单调性约束，限制其表达能力；要么采用较为宽松的替代方案，增加算法复杂度。", "innovation": "本文提出了非单调价值分解的动态系统分析，将其学习动力学建模为连续时间梯度流动。证明在近似贪婪探索下，所有违反IGM一致性的零损失平衡点是不稳定的鞍点，而仅IGM一致的解是学习动力学的稳定吸引子。通过合成矩阵博弈和复杂的MARL基准实验，表明无约束、非单调因子化更可靠地恢复IGM最优解，并且优于单调基线。另外，还研究了时间差分目标和探索策略的影响，为未来基于价值的MARL算法的设计提供了实用见解。", "conclusion": "结果显示，不受约束的、非单调的因子化可靠地恢复了IGM最优解，并且在所有测试的基准上都表现出色。该研究还探讨了目标类型和探索策略对算法性能的影响，为该领域未来的算法设计提供了实际建议。"}
{"llm_update_time": "20251116", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2511.09808", "html_url": "https://arxiv.org/abs/2511.09808", "title": "具测试可行性约束的最佳臂识别", "title_en": "Constrained Best Arm Identification with Tests for Feasibility", "authors": "Ting Cai,Kirthevasan Kandasamy", "background": "最佳臂识别（BAI）旨在通过从每个臂中收集随机样本来识别一组K个臂中表现最佳的臂。实际问题中，最佳臂需要满足额外的可行性约束。现有针对带有可行性约束的BAI工作的研究较少，且通常假设在每次拉取臂时都能同时观测到臂的表现和约束。然而，这种假设并不符合大多数实际应用案例，例如在药物发现中，寻找最有效的药物，需要满足特定的安全阈值。这些安全性测试可以独立于效果测试进行，因此需要设计既能决定拉取哪个臂，又能决定是否测试臂的表现或约束的BAI算法。", "innovation": "本文研究了一种具有测试可行性约束的最佳臂识别方法，允许决策者选择一个元组(i, ℓ)，其中i表示臂，ℓ表示她是否想测试其表现（ℓ=0）或其N个约束之一（ℓ∈[N]）。本文专注于固定置信度的设定，即确定具有最高表现的可行臂的概率至少为1-δ。提出了一种高效的算法，并界定了其样本复杂性上限，证明了该算法可以自然地适应问题的难度，通过较差的表现或不可行性淘汰掉臂。同时提供了另一个下界来证明该算法在δ→0时是渐近最优的。实验证明，该算法在合成和真实数据集上均优于其他最先进的BAI算法。", "conclusion": "最后，本文展示了提出的算法在合成和真实数据集上的性能均优于其他最先进的BAI算法。"}
{"llm_update_time": "20251116", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2511.09953", "html_url": "https://arxiv.org/abs/2511.09953", "title": "自主概念漂移阈值决定", "title_en": "Autonomous Concept Drift Threshold Determination", "authors": "Pengqian Lu,Jie Lu,Anjin Liu,En Yu,Guangquan Zhang", "background": "现有的漂移检测方法专注于设计敏感的检验统计量，将检测阈值视为固定的超参数，在设定时需要平衡假报警和检测延迟，并在整个数据集和时间范围内统一应用。然而，从机器学习的角度来看，保持模型性能是关键目标，我们观察到模型性能对这个阈值非常敏感。", "innovation": "该研究证明了随着时间动态调整的阈值能够优于单一固定阈值，并提出了一种动态阈值决定算法，通过结合每个独立数据段的最佳阈值来实现动态策略，从而确保任何单一应用于所有段的阈值都无法超过它。此算法增强了现有的漂移检测框架，并通过一个新的比较阶段来指示阈值应该如何调整。", "conclusion": "通过广泛的合成和真实世界数据集的实验验证，我们的方法显著提高了最新的漂移检测方法的性能。"}
{"llm_update_time": "20251116", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2511.09996", "html_url": "https://arxiv.org/abs/2511.09996", "title": "大型假设类别的新型数据依赖学习范式", "title_en": "A Novel Data-Dependent Learning Paradigm for Large Hypothesis Classes", "authors": "Alireza F. Pour,Shai Ben-David", "background": "在面对模型候选集合过大，使得经验估计无法均匀收敛到真实损失的情况时，常见的方法是基于SRM（或正则化）的学习算法。但是，本文提出了一个全新的学习范式，该范式更加强调数据的直接利用，并减少对先验假设的依赖。", "innovation": "提出的新型学习范式不需要事先了解其具体参数，可以利用相似性假设、领域聚类假设、标签同质化区域的假设、标记规则的Lipschitz连续性假设以及对比学习假设等多种学习前提，增强了数据的直接利用程度。", "conclusion": "该方法在一系列通用学习假设下展示了其优越性，并分析了其泛化能力。"}
{"llm_update_time": "20251116", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2511.09979", "html_url": "https://arxiv.org/abs/2511.09979", "title": "通过嵌入物理偏置的AI费曼重新发现月球中项方程", "title_en": "Rediscovering the Lunar Equation of the Centre with AI Feynman via Embedded Physical Biases", "authors": "Saumya Shah,Zi-Yu Khoo,Abel Yang,Stéphane Bressan", "background": "本文探讨了使用物理启发的AI费曼符号回归算法自动重新发现天文学中的基本方程——中项方程。通过数据预处理和搜索空间限制引入与系统物理性质相对应的观测和归纳偏置，AI费曼成功从月球天表数据中恢复了该方程的一阶分析形式。然而，这种手动方法强调了其在依赖专家主导的坐标系选择方面的关键局限性。", "innovation": "本文提出了一个自动化预处理扩展，以找到标准坐标系。结果表明嵌入目标领域知识能够使符号回归重新发现物理定律，但也突显出通过定制偏置利用领域知识在推导物理方程时的进一步挑战。", "conclusion": "本文的研究表明，嵌入物理偏置的符号回归算法能够重新发现物理定律，但也指出了进一步挑战，特别是在利用领域知识约束符号回归以推导物理方程时。"}
{"llm_update_time": "20251116", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2511.09962", "html_url": "https://arxiv.org/abs/2511.09962", "title": "AI-Integrated Decision Support System for Real-Time Market Growth Forecasting and Multi-Source Content Diffusion Analytics", "title_en": "AI-Integrated Decision Support System for Real-Time Market Growth Forecasting and Multi-Source Content Diffusion Analytics", "authors": "Ziqing Yin,Xuanjing Chen,Xi Zhang", "background": "AI生成内容（AIGC）的快速增长已经重塑了数字营销和在线消费者行为的动力学。但由于数据异质性、非线性传播机制和消费者互动的演变，预测此类内容的传播轨迹及其市场影响仍然具有挑战性。", "innovation": "提出了一个结合多源数据（如社交媒体流、营销支出记录、消费者参与日志和情感动态）的人工智能驱动决策支持系统（DSS）。该系统使用混合图神经网络（GNN）和时间变换框架，通过双重通道结构联合学习内容扩散结构和时序影响力演变，并利用因果推断模块将营销刺激对投资回报率（ROI）和市场可见性的影响分离出来。实验结果表明，该系统在一个多平台（如Twitter、TikTok和YouTube广告）的大规模真实数据集上，在六个指标上优于现有基线。", "conclusion": "该DSS通过提供基于AI驱动内容传播和市场增长模式的可解释实时洞察，提升了营销决策。"}
{"llm_update_time": "20251116", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2511.09923", "html_url": "https://arxiv.org/abs/2511.09923", "title": "利用有界支持进化策略进行策略细化", "title_en": "Harnessing Bounded-Support Evolution Strategies for Policy Refinement", "authors": "Ethan Hirschowitz,Fabio Ramos", "background": "使用在线策略梯度（on-policy RL）改进机器人策略通常受到嘈杂、低信号梯度的困扰。我们重新审视了进化策略（ES）作为策略梯度代理，并使用有界、反三角扰动来本地化探索，这适用于策略细化。PPO预训练后续通过TD-ES细化的两阶段流程保留了早期样本效率，同时允许稳健的后期收益。", "innovation": "提出了一种三角分布进化策略（TD-ES），它结合了有界三角噪音和中心排序有限差分估计器，以提供稳定、并行且无梯度的更新。通过PPO预训练和TD-ES细化的两阶段管道，保持了早期样本效率，并在后期实现稳健的收益。与PPO相比，TD-ES提高了成功率为26.5%，显著降低了变异性。", "conclusion": "TD-ES为可靠的策略细化提供了一条简单且计算量轻的路径。"}
{"llm_update_time": "20251116", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2511.09947", "html_url": "https://arxiv.org/abs/2511.09947", "title": "EEGAgent: 使用大型语言模型进行自动化脑电图分析的统一框架", "title_en": "EEGAgent: A Unified Framework for Automated EEG Analysis Using Large Language Models", "authors": "Sha Zhao,Mingyi Peng,Haiteng Jiang,Tao Li,Shijian Li,Gang Pan", "background": "脑电图（EEG）作为具有高时间分辨率的非侵入性成像技术，在脑状态分析中得到了广泛的应用。尽管如此，现有的EEG模型通常针对特定任务定制，限制了其在涉及多任务和连续推理的现实场景中的应用。因此，需要一种能够处理多任务并进行灵活且可解释的EEG分析的方法。作者提出了EEGAgent，这是一种通用框架，利用大型语言模型调度和规划多种工具以自动完成EEG相关任务，涵盖了从基本信息感知到报告生成的一系列功能。这些功能在公开数据集上进行了评估，表明EEGAgent具有在临床应用中的潜力和优势。", "innovation": "EEGAgent采用了大型语言模型来调度和规划多种工具，以自动完成EEG相关的任务。它具备基本信息感知、时空EEG探索、EEG事件检测、与用户交互以及EEG报告生成等功能，这是通过设计由不同工具组成的工具箱来实现的。这不仅扩展了EEG分析的范围，还提高了分析的准确性和实用性。", "conclusion": "我们的EEGAgent能够在公共数据集上支持灵活且可解释的EEG分析，并展示了其在现实世界临床应用的潜力。它为自动化EEG分析提供了一种新颖的方法，能够处理多任务，提供清晰的报告，并与用户进行有效交互。"}
{"llm_update_time": "20251116", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2511.09989", "html_url": "https://arxiv.org/abs/2511.09989", "title": "在开放世界中实现稳健的多模态学习", "title_en": "Towards Robust Multimodal Learning in the Open World", "authors": "Fushuo Huo", "background": "机器学习的快速发展推动了神经网络在各个领域的成功应用。特别是多模态学习作为一种具有变革性的范式，通过整合异质数据流（如文本、视觉、音频）中的互补信息，提升了上下文推理和智能决策能力。尽管取得了一定进展，但当前基于神经网络的模型在开放世界环境下的表现往往不尽如人意。开放世界环境的不确定性和复杂性（如意外的环境组成动态、不完整的模态输入和虚假数据分布关系）严重削弱了系统的可靠性。与人类自然适应这种动态且模糊的场景不同，人工智能系统在处理现实世界复杂多模态信号时表现出重大局限性，特别是在鲁棒性方面。本文探讨了开放世界条件下多模态学习鲁棒性这一根本性的挑战，旨在弥合受控实验环境下的性能与实际部署需求之间的差距。", "innovation": "本文提出了多模态学习在开放世界背景下的鲁棒性问题，并试图解决这一挑战，以提升AI系统在不确定、复杂环境下的适应能力和可靠性。", "conclusion": "本文通过探索开放世界条件下的多模态学习鲁棒性，旨在为真实世界应用中更可靠和灵活的AI系统开发奠定理论基础。"}
{"llm_update_time": "20251116", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2511.09924", "html_url": "https://arxiv.org/abs/2511.09924", "title": "MDMLP-EIA: 多域动态MLP与能量不变注意力机制在时间序列预测中的应用", "title_en": "MDMLP-EIA: Multi-domain Dynamic MLPs with Energy Invariant Attention for Time Series Forecasting", "authors": "Hu Zhang,Zhien Dai,Zhaohui Tang,Yongfang Xie", "background": "时间序列预测在多个领域中都具有重要的应用价值。尽管基于MLP的方法因其使用较少的参数和更好的鲁棒性而得到了与Transformer相当的性能表现，但它们仍然存在一些关键限制，包括弱季节信号的消失、权重共享MLP中的容量限制以及独立通道策略中不足的通道融合。", "innovation": "MDMLP-EIA 提出了三种创新点。首先，开发了一种自适应融合双域季节MLP，将季节信号分类为强和弱成分，并采用自适应零初始化通道融合策略以最小化噪音干扰的同时有效集成预测。其次，引入了一种能量不变注意力机制，能够在时间步内的趋势和季节预测不同特征通道上自适应聚焦。该机制保持恒定总信号能量，与分解-预测-重构框架一致，以增强对干扰的鲁棒性。第三，提出了独立通道MLP的动态容量调整机制，该机制随着通道数量增加按平方根比例调整神经元数量，以确保足够的容量。", "conclusion": "在九个基准数据集上的大量实验表明，MDMLP-EIA 在预测准确性和计算效率方面均达到了最先进的技术水平。"}
{"llm_update_time": "20251116", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2511.09998", "html_url": "https://arxiv.org/abs/2511.09998", "title": "DemoTuner: 通过LLM辅助示范强化学习进行高效DBMS参数调优", "title_en": "DemoTuner: Efficient DBMS Knobs Tuning via LLM-Assisted Demonstration Reinforcement Learning", "authors": "Hui Dou,Lei Jin,Yuxuan Zhou,Jiang He,Yiwen Zhang", "background": "现代DBMS如MySQL和PostgreSQL的性能高度依赖于关键性能参数的配置。手动调优这些参数由于配置空间的复杂性和多维性，操作繁重且效率低下。尽管存在一些自动化调优方法，特别是在使用强化学习(RL)的调优方法中，但仍面临线下训练收敛速度慢的问题。本文主要探讨如何利用DBMS手册和网络论坛中的各种文本文档提供的调优提示，以改善基于RL的调优方法的线下训练。", "innovation": "本文提出了一种名为DemoTuner的DBMS调优框架，该框架通过一种新型的LLM辅助示范强化学习方法来实现。具体来说，通过设计结构化的思维链提示来利用LLM从文档中全面准确地提取调优提示。为了有效整合提取的调优提示，提出了一种名为HA-DDPGfD的提示感知示范强化学习算法。这是首次将示范强化学习算法引入DBMS调优领域的研究。实验结果表明，DemoTuner在MySQL和PostgreSQL中的多种工作负载下，相对于DB-BERT、GPTuner和CDBTune三种代表性基线，性能提升显著，且在线调优成本更低。此外，DemoTuner还表现出对未知工作负载场景的优越适应性。", "conclusion": "DemoTuner利用LLM辅助的示范强化学习方法，在提升DBMS性能并减少在线调优成本方面表现出显著的优势，且适用于各种工作负载场景下的DBMS参数调优。"}
{"llm_update_time": "20251116", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2511.09970", "html_url": "https://arxiv.org/abs/2511.09970", "title": "MultiTab：面向表格数据的可扩展多任务学习基础架构", "title_en": "MultiTab: A Scalable Foundation for Multitask Learning on Tabular Data", "authors": "Dimitrios Sinodinos,Jack Yi Wei,Narges Armanfard", "background": "表格数据是全球最丰富的数据类型，广泛应用于金融、医疗、电子商务等领域。随着表格数据集的增长和跨多个相关目标的应用，利用共享任务信息以提高多任务泛化能力的需求日益增加。多任务学习（MTL）被证明是一种有效的提升泛化能力和效率的方式，但现有的大多数工作主要集中在大规模推荐系统上，而对于更广泛的数据表域尚未充分利用其潜力。此外，现有的表格数据MTL方法大多依赖多层感知器（MLP）作为骨干网络，这些方法难以捕捉复杂的特征交互，尤其在数据量大时扩展性有限，而这一问题在其他领域已经被基于变换器（Transformer）的方法所克服。本文从这些观察出发，探讨了这个问题。", "innovation": "本文引入了MultiTab-Net，这是一种专门针对大规模表格数据设计的多任务变换器架构。MultiTab-Net采用了新颖的多任务掩码注意力机制，能够动态建模特征间的依赖关系，同时缓解任务竞争。经过广泛的实验证明，MultiTab-Net在大型推荐数据、类似人口普查的社会经济数据以及物理学数据等多个领域取得了优于现有MTL架构和单任务变换器的多任务泛化性能。此外，本文还提出了MultiTab-Bench，这是一个通用的多任务合成数据集生成器，用于通过调整任务数量、任务相关性和任务复杂度来系统地评估多任务动态。", "conclusion": "MultiTab-Net提供了专门针对大型表格数据设计的多任务变换器架构，相比现状实现了更好的多任务泛化能力。研究还贡献了MultiTab-Bench，一个通用的多任务合成数据集生成器，以支持系统的多任务动态评估。"}
{"llm_update_time": "20251116", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2511.10022", "html_url": "https://arxiv.org/abs/2511.10022", "title": "GraphSB: 通过结构平衡提高图上的不平衡节点分类", "title_en": "GraphSB: Boosting Imbalanced Node Classification on Graphs through Structural Balance", "authors": "Chaofan Zhu,Xiaobing Rui,Zhixiao Wang", "background": "图学习中的不平衡节点分类是一个关键挑战，现有方法通常使用图神经网络(GNNs)来学习节点表示。这些方法可以分为数据层面和算法层面两类。前者旨在合成少数类节点以缓解数量不平衡，后者则试图优化学习过程以突出少数类。然而，这两种方法并未解决固有的不平衡图结构问题，这是导致GNN中多数类主导和少数类同化的基本因素。理论分析进一步支持这一关键见解。", "innovation": "我们提出了GraphSB（图结构平衡）框架，该框架将结构平衡作为核心策略，在节点合成之前解决底层的不平衡图结构。结构平衡进行了两阶段结构优化：结构增强，自适应构建基于相似性的边以增强少数类节点的连通性；关系扩散，捕捉高阶依赖关系的同时增强少数类信号。GraphSB 在进行节点合成之前平衡结构分布，使得在GNN中实现更有效的学习。实验结果表明，GraphSB 显著优于现有方法。更重要的是，提出的结构平衡可以无缝集成到现有方法中作为简单的插件模块，平均提高其精度3.67%。", "conclusion": "广泛实验证明，GraphSB在不平衡节点分类性能上超越了最先进的方法，且提出的结构平衡可无缝集成到现有方法中，提升其精准度。"}
{"llm_update_time": "20251116", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2511.10018", "html_url": "https://arxiv.org/abs/2511.10018", "title": "交互作用即叠加效果：一种受启发于量子论的聚合方法", "title_en": "Interaction as Interference: A Quantum-Inspired Aggregation Approach", "authors": "Pilsung Kang", "background": "传统的交互作用处理方式将其视为工程化的产品项或在灵活模型中出现的模式，这提供不了对交互作用如何产生协同效应或拮抗作用的控制。本文提出了一种借鉴量子力学思想的方法：遵循波函数的Born规则（概率是幅度的平方），相干聚合在平方之前求和复数幅度，从而生成干涉交叉项，而非相干聚合则先平方再求和，移除交叉项。在最小的线性幅度模型中，这个交叉项等于一个标准的潜在结果交互作用对比量Δ_INT，赋予相对相位在机制层面直接控制协同作用和拮抗作用的能力。", "innovation": "提出了一种新的理论框架，借鉴量子力学中的相干和非相干叠加概念，来解释和控制交互作用中的协同和拮抗效应。通过这种方式，模型可以更精细地控制交互作用产生的机制，从而提供更好的预测和解释能力。此外，还提出了一种轻量级的“干扰内核分类器（IKC）”及其两个诊断指标：相干增益和干扰信息。", "conclusion": "在高交互合成任 务（XOR）上，IKC 在配对测试中优于强基准模型；在真实的表格数据（Adult 和 Bank Marketing）中，IKC 性能整体上可与最强基准模型媲美，但在配对差异中通常落后于最具容量的基准模型。固定学习参数后，从非相干到相干的聚合转换可以一致地提高负对数似然、Brier分数和期望校准误差，并在两个数据集上都获得了正的相干增益。"}
{"llm_update_time": "20251116", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2511.10255", "html_url": "https://arxiv.org/abs/2511.10255", "title": "Unitho：计算光刻统一多任务框架", "title_en": "Unitho: A Unified Multi-Task Framework for Computational Lithography", "authors": "Qian Jin,Yumeng Liu,Yuqi Jiang,Qi Sun,Cheng Zhuo", "background": "可靠的、可泛化的数据基础对于启用计算光刻中的大规模模型至关重要。然而，关键任务（掩模生成、规则违规检测和布局优化）通常独立处理，受到稀缺数据集和有限建模方法的阻碍。", "innovation": "本文引入了Unitho，一种基于Transformer架构的统一多任务大型视觉模型。Unitho在大规模工业光刻仿真数据集上进行训练，支持端到端的掩模生成、光刻模拟和规则违规检测。通过实现灵活且高保真的光刻模拟，Unitho进一步促进了智能EDA中稳健数据基础的构建。", "conclusion": "实验结果验证了其有效性和泛化能力，性能显著优于学术基准。"}
{"llm_update_time": "20251116", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2511.10234", "html_url": "https://arxiv.org/abs/2511.10234", "title": "序列化迷失：LLM图推理器的不变性和泛化", "title_en": "Lost in Serialization: Invariance and Generalization of LLM Graph Reasoners", "authors": "Daniel Herbst,Lea Karbeska,Divyanshu Kumar,Akanksha Ahuja,Fatemeh Gholamzadeh Nasrabadi,Fabrizio Frasca", "background": "虽然基于大规模语言模型（LLMs）的图推理器显示出一定的潜力，但它们在图表示对称性上的固有不变性较差。在处理节点重新索引、边重新排序或格式更改时，LLMs 会生成不同的输出，从而影响其稳健性。", "innovation": "系统分析了这些影响，探讨了微调对编码敏感性和未见任务泛化能力的影响。提出了一种有原则性的图序列化分解，涵盖了节点标记、边编码和语法，并在综合基准测试套件中评估了LLMs对这些因素变化的鲁棒性。还贡献了一组新的谱任务来进一步评估微调推理器的泛化能力。", "conclusion": "较大的（非微调）模型更稳健。微调可以减少对节点重新标记的敏感性，但可能会增加对结构和格式变化的敏感性，而微调并不总是能提高对未见任务的性能。"}
{"llm_update_time": "20251116", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2511.10251", "html_url": "https://arxiv.org/abs/2511.10251", "title": "启发式变换器：基于信念增强的即席强化学习", "title_en": "Heuristic Transformer: Belief Augmented In-Context Reinforcement Learning", "authors": "Oliver Dippel,Alexei Lisitsa,Bei Peng", "background": "变换器展示了卓越的即席学习（ICL）能力，使其在自然语言处理、计算机视觉和序列决策等领域有广泛的应用。在强化学习中，即席学习重新定义了学习为监督问题，使任务适应无需参数更新成为可能。先前的工作利用变换器进行序列决策，而本文在此基础上提出了启发式变换器（HT），一种基于即席强化学习（ICRL）的方法。", "innovation": "HT 方法通过结合变换器和信念分布来增强即席数据集，从而优化决策能力。通过变分自编码器（VAE）学习低维度的随机变量来表示奖励的后验分布，并将其与即席数据集和查询状态一起作为提示传递给变换器策略。研究表明，HT 在 Darkroom、Miniworld 和 MuJoCo 环境中均优于类似的基线方法，展现了替代基于信念增强与变换器决策之间的桥梁作用。", "conclusion": "HT 方法展示了在基于信念增强的即席强化学习领域的一个具有前景的方向，通过结合变换器和低维度随机变量的后验分布，提高决策效率和泛化能力。"}
{"llm_update_time": "20251116", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2511.10282", "html_url": "https://arxiv.org/abs/2511.10282", "title": "Torch-Uncertainty：一种深度学习不确定性量化框架", "title_en": "Torch-Uncertainty: A Deep Learning Framework for Uncertainty Quantification", "authors": "Adrien Lafage,Olivier Laurent,Firas Gabetni,Gianni Franchi", "background": "深度神经网络（DNNs）在计算机视觉和自然语言处理等多个领域中展现了出色的表现。然而，这些网络在准确量化其预测不确定性方面经常存在局限性，这限制了它们在关键的现实世界应用中的更广泛应用。深度学习不确定性量化（UQ）旨在通过提供各种方法来改善不确定性估计的可靠性。尽管已经提出了许多技术，但缺乏一个统一的工具或框架来无缝地评估和整合这些方法。因此，迫切需要解决这一不足，以促进不确定性量化技术的发展与应用。", "innovation": "我们介绍了Torch-Uncertainty，一种基于PyTorch和Lightning的框架，旨在简化深度神经网络（DNN）的训练和评估，并集成不确定性量化（UQ）技术及指标。通过这个框架，用户可以更加便捷地应用和比较各种不确定性量化方法，并应用于分类、分割和回归等多种任务。", "conclusion": "本文阐述了我们库的基石原理，并在此基础上进行了全面的实验，对多个不确定性量化方法进行了基准测试。通过本研究，我们为深度学习领域贡献了一个实用且高效的不确定性量化框架，有助于提高模型的可靠性和透明度。我们的库可在此网址获得：[此项请参照原文页面地址插入]。"}
{"llm_update_time": "20251116", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2511.10190", "html_url": "https://arxiv.org/abs/2511.10190", "title": "在动物 vocalizations 中利用序贯结构", "title_en": "Towards Leveraging Sequential Structure in Animal Vocalizations", "authors": "Eklavya Sarkar,Mathew Magimai.-Doss", "background": "动物的声音包含有顺序性的结构，这些结构传递重要的交流信息。然而，大多数计算生物声学的研究在时间轴上对提取出的帧级特征进行平均处理，从而丢失了声音单元顺序中的时间信息。本文研究通过矢量量化和 Gumbel-Softmax 矢量量化提取的自监督语音模型表示生成的离散声学令牌序列是否能够有效地捕捉和利用这些时间信息。通过对来自 HuBERT 嵌入生成的令牌序列的成对距离分析表明，它们能够区分四组生物声学数据集中的呼唤类型和发出声音的动物。利用 $k$-Nearest Neighbour，通过 Levenshtein 距离进行序列分类实验显示，矢量量化后生成的令牌序列提供了一种合理的呼唤类型和发声者分类性能，并为未来的利用动物声音中的序列信息提供了新的替代特征表示法的潜力。", "innovation": "本文创新性地提出了利用矢量量化和 Gumbel-Softmax 矢量量化生成的离散声学令牌序列，有效地捕捉和利用声音中的时间信息。相比传统的平均处理，这种方法能够更好地保留声音单元顺序中的时间信息，从而为动物声音的分类带来更好的性能。", "conclusion": "研究表明，矢量量化后生成的令牌序列能够有效捕捉和利用动物声音中的时间信息，提供了一种新的替代特征表示法，有望在未来更好地利用动物声音中的序列信息，提高分类的准确性。"}
{"llm_update_time": "20251116", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2511.10227", "html_url": "https://arxiv.org/abs/2511.10227", "title": "FedCure: 在非同态数据中缓解半异步联邦学习中的参与偏差", "title_en": "FedCure: Mitigating Participation Bias in Semi-Asynchronous Federated Learning with Non-IID Data", "authors": "Yue Chen,Jianfeng Lu,Shuqing Cao,Wei Wang,Gang Li,Guanghui Wen", "background": "半异步联邦学习（SAFL）结合了同步训练的效率和异步更新的灵活性，但存在固有的参与偏差问题，尤其是在非独立同分布（非IID）数据存在时。随着分级架构的使用，客户端参与度转移至客户端组，进一步加剧了这一问题。尽管在SAFL领域的研究取得了一定进展，但现有工作大多关注云端架构，忽略了非IID数据对云边缘客户端层次结构中调度的严重影响。", "innovation": "提出了一种名为FedCure的新型半异步联邦学习框架，该框架通过联盟构建和参与意识调度来缓解非IID数据引起的参与偏差。FedCure的创新点包括偏好规则、调度规则和资源分配规则，分别用于优化联盟形成、动态调度管理和计算效率优化。", "conclusion": "在四项实际数据集上的全面实验表明，FedCure将准确度提高了5.1倍，同时在每轮延迟系数变异方面表现最优（0.0223），并且在整个过程中保持了多样性场景下的长期平衡。"}
{"llm_update_time": "20251116", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2511.10208", "html_url": "https://arxiv.org/abs/2511.10208", "title": "基于几何谐波的分数神经注意机制实现高效的多尺度序列处理", "title_en": "Fractional neural attention for efficient multiscale sequence processing", "authors": "Cheng Kevin Qu,Andrew Ly,Pulin Gong", "background": "注意力机制是Transformer模型计算能力的核心，这些模型已在多个领域取得了显著成功。然而，理解和扩展自注意力的基本原理仍然是推进人工智能的关键挑战。受生物注意力的多尺度动态和动力系统理论的启发，引入了分数神经注意（FNA）模型，这是一种基于神经科学启发的多尺度信息处理的原理性框架。", "innovation": "FNA通过由分数Laplace算子调控的Lévy扩散来建模令牌之间的交互，这种机制在多个尺度上同时体现短程和远程依赖关系，从而增加了表达能力和信息混合速度，推进了Transformer的基础能力。FNA的动力学由分数扩散方程控制，显示出更大的谱间隙和更短的路径长度，这表明其计算效率得到了增强。实验结果显示，即使是单层单头，FNA在文本分类任务中也表现出竞争力；同时它在图像处理和神经机器翻译方面提高了性能。", "conclusion": "FNA将自注意力机制、随机动力学和几何结构联系起来，并通过几何谐波中的扩散映射算法实现了FNA权重的降维同时保有嵌入和隐藏状态的内在结构，从而为强大的神经科学启发式人工智能提供了可解释的、生物基础性的理论框架。"}
{"llm_update_time": "20251116", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2511.10213", "html_url": "https://arxiv.org/abs/2511.10213", "title": "基于测试时训练的变分领域不变学习的离境错误信息检测", "title_en": "Out-of-Context Misinformation Detection via Variational Domain-Invariant Learning with Test-Time Training", "authors": "Xi Yang,Han Zhang,Zhijian Lin,Yibiao Hu,Hong Han", "background": "离境错误信息作为一种低成本的新闻误导形式，指的是将真实图像放入脱节的图像-文本配对中。近年来，这个问题引起了研究人员的广泛关注。当前的方法主要集中在评估图像-文本的一致性或生成解释上。然而，这些方法假设训练数据和测试数据来自相同的分布。因此，面对新型新闻领域时，模型往往会表现出色的性能，因为缺乏前置知识。", "innovation": "本文提出了一种名为VDT的方法，通过学习领域不变特征和测试时训练机制来增强OOC错误信息检测的领域适应能力。VDT方法利用领域不变变分对齐模块，联合编码源和目标领域数据，学习分离的分布空间领域不变特征，同时采用领域一致性约束模块保持语义完整性，并在测试阶段采用测试时间训练策略以及置信度方差筛选模块，动态更新变分自动编码器和分类器，使模型能够适应目标领域分布。", "conclusion": "在基准数据集NewsCLIPpings进行的广泛实验表明，在大多数领域适应设置下，本文的方法优于最先进的基线。"}
{"llm_update_time": "20251116", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2511.10200", "html_url": "https://arxiv.org/abs/2511.10200", "title": "超越MSE：基于序交叉熵的概率时间序列预测", "title_en": "Beyond MSE: Ordinal Cross-Entropy for Probabilistic Time Series Forecasting", "authors": "Jieting Wang,Huimei Shi,Feijiang Li,Xiaolei Shang", "background": "时间序列预测是一个重要的任务，它需要分析历史数据中时间依赖性和潜在模式（如趋势、周期性和季节性），以预测未来值或趋势。当前基于深度学习的预测模型主要使用均方误差（MSE）损失函数进行回归建模。尽管MSE损失函数能够直接预测值，但它无法提供不确定性评估，对异常值的鲁棒性较差。", "innovation": "本文提出了OCE-TS，一种新颖的时间序列预测方法，通过使用序交叉熵（OCE）损失替代MSE损失，在保持预测顺序的同时，使用概率输出量化不确定性。OCE-TS首先将观测值离散化成有序区间，并通过参数分布推导出它们的概率作为监督信号。然后，使用简单的线性模型预测每个时间步的概率分布。通过累积概率分布之间的序交叉熵计算损失，明确地保留了预报值之间的序关系。通过影响函数的理论分析，证明了序交叉熵损失在稳定性和异常值鲁棒性方面优于均方误差损失。", "conclusion": "我们在MSE和平均绝对误差（MAE）作为评估指标的七个公开时间序列数据集上，将OCE-TS与五个基线模型（Autoformer、DLinear、iTransformer、TimeXer和TimeBridge）进行了比较。实验结果表明，OCE-TS在所有数据集上均优于基准模型。代码将会开源发布。"}
{"llm_update_time": "20251116", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2511.10287", "html_url": "https://arxiv.org/abs/2511.10287", "title": "OutSafe-Bench: 大型语言模型中多模态攻击内容检测的标准", "title_en": "OutSafe-Bench: A Benchmark for Multimodal Offensive Content Detection in Large Language Models", "authors": "Yuping Yan,Yuhan Xie,Yuanshuai Li,Yingchao Yu,Lingjuan Lyu,Yaochu Jin", "background": "由于多模态大语言模型（MLLMs）越来越多地被集成到日常工具和智能代理中，人们越来越关注它们可能产生不安全内容的风险，包括有毒语言、偏见图像、隐私侵权和有害信息。当前的安全评估基准在模态覆盖和性能评估方面仍然非常有限，经常会忽略了内容安全的广阔领域。作为回应，本文提出了首个为多模态时代设计的全面内容安全性评估测试套件——OutSafe-Bench，以此填补这一空白。", "innovation": "本文提出了OutSafe-Bench，这是一个全新的多模态内容安全评估测试套件，其中包括了一个涵盖四大模态的大规模数据集，共有18,000个双语（中文和英文）文本提示、4,500张图片、450段音频和450段视频，并在九个关键内容风险类别进行了系统注释。此外，文章还创新性地提出了多维度跨风险评分（MCRS）作为评估不同类别之间重叠和关联内容风险的新度量标准，并提出了一种可解释的自动多审阅者加权聚合框架FairScore，以确保公平和稳健的评估，该框架选择表现最佳的模型作为自适应陪审团，从而减少单一模型判断带来的偏见，提高整体评估的可靠性。", "conclusion": "九种最先进的MLLMs的安全漏洞仍然普遍和显著，这强调了在MLLMs中实行稳健保障措施的紧迫性。"}
{"llm_update_time": "20251116", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2511.10566", "html_url": "https://arxiv.org/abs/2511.10566", "title": "Layer 正规化对Transformer 中记忆化和泛化的影响", "title_en": "Impact of Layer Norm on Memorization and Generalization in Transformers", "authors": "Rishi Singhal,Jung-Eun Kim", "background": "Layer Normalization (LayerNorm) 是transformer 中的一个基础组件，用于稳定训练和优化。近年来，Pre-LayerNorm transformer 因其稳定的梯度流动而成为首选，代替了Post-LayerNorm transformer。然而，LayerNorm 对这两种架构中学习和记忆的影响仍然不清楚。本研究旨在探讨LayerNorm 如何影响 Pre-和Post-LayerNorm transformer 中的记忆和学习。", "innovation": "研究表明，LayerNorm 在Pre-LayerNorm transformer 中对稳定学习至关重要，而在Post-LayerNorm transformer 中则影响记忆。去除Pre-LayerNorm模型中的LayerNorm参数会加剧记忆并使学习不稳定；而在Post-LayerNorm模型中，去除LayerNorm参数能够通过恢复真实标签有效地减轻记忆问题。此发现进一步揭示了早期层的LayerNorm 对Pre 和Post LayerNorm模型的重要性差异。这些验证工作涵盖了13个模型和6个视觉和语言数据集。", "conclusion": "这些见解为我们了解LayerNorm 如何通过塑造记忆力和学习来影响transformer 的作用提供了新的视角。"}
{"llm_update_time": "20251116", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2511.10571", "html_url": "https://arxiv.org/abs/2511.10571", "title": "Belief Net：从观察中学习隐马尔可夫模型的一种滤波器基础框架", "title_en": "Belief Net: A Filter-Based Framework for Learning Hidden Markov Models from Observations", "authors": "Reginald Zhiyan Chen,Heng-Sheng Chang,Prashant G. Mehta", "background": "隐马尔可夫模型（HMM）是序列数据建模的基础，但其参数学习却充满挑战。经典方法如baum-welch（EM）算法计算量大且容易陷入局部最优解。现代谱算法虽然提供可验证的保证，但可能会产生超出有效范围的概率输出。", "innovation": "Belief Net引入了一种新颖的框架，通过梯度优化方法将HMM的前向过滤公式化为结构化的神经网络，从而学习HMM参数。该模型采用解码器架构，通过标准的自回归下一个观察预测损失进行端到端训练。相比黑盒Transformer模型，Belief Net的可学习权重明确为初始分布、转移矩阵和发射矩阵的逻辑值，确保完全可解释性。在合成HMM数据上，Belief Net在收敛速度上优于baum-welch，并能在谱方法失效的情况下成功恢复参数（在欠完全和过完全的情况下）。", "conclusion": "Belief Net在真实世界语言数据上也与基于Transformer的模型进行了比较。"}
{"llm_update_time": "20251116", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2511.10573", "html_url": "https://arxiv.org/abs/2511.10573", "title": "向具有情感智能和责任感的强化学习迈进", "title_en": "Towards Emotionally Intelligent and Responsible Reinforcement Learning", "authors": "Garapati Keerthana,Manik Gupta", "background": "当前，个人化决策系统在医疗和行为支持中的应用主要依赖于静态规则或最大化参与度的直觉，而这往往忽视了用户的情感背景和伦理约束。这种做法可能导致对用户不够敏感或不安全的干预措施，特别是在涉及严重精神疾病、药物滥用障碍或抑郁症等领域的干预中。文章介绍了一种负责任的强化学习（RRL）框架，该框架将情感理解、情境理解与伦理考虑整合进了序列决策过程中。", "innovation": "RRL框架通过将个人化决策建模为受限马尔可夫决策过程（CMDP），使得代理可以同时优化参与度和依从性，同时确保情感一致性与伦理安全。RRL引入了一个多目标奖励函数，明确平衡了短期行为参与与长期用户福祉，并定义了一个基于情感的状态表示，捕捉了情感准备度、情感影响和风险的波动。此外，RRL还可以与任何RL算法（如DQN、PPO）结合，加入安全约束或拉格朗日正则化。", "conclusion": "本文提出了一个伦理对齐的强化学习方法，旨在为情感意识和可信赖的个性化系统奠定基础，并讨论了该方法在心理卫生、教育和数字疗法等人本领域的意义。同时，文章指出了未来基于模拟的验证路径，旨在促进相关政策在实际应用中的进一步研究。"}
{"llm_update_time": "20251116", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2511.10494", "html_url": "https://arxiv.org/abs/2511.10494", "title": "使用人工神经网络进行长期股票预测的低强度关系强化", "title_en": "Weak Relation Enforcement for Kinematic-Informed Long-Term Stock Prediction with Artificial Neural Networks", "authors": "Stanislav Selitskiy", "background": "在长期股票预测中，时间序列数据的波动性、测试数据的未遇到分布（OOD）以及训练数据中的异常值等问题一直困扰着预测模型。传统的自回归人工神经网络（AR ANN）虽然能够预测未来的点，但往往无法准确地捕捉点之间的速度关系，导致难以避免不实且虚假的预测。", "innovation": "本文提出了一种新的损失函数，在Kinematic-Informed人工神经网络（KINN）中减弱对时间序列点间速度关系的控制。与传统的损失函数只惩罚预测与监督标签之间的误差不同，这种新的损失函数还惩罚了未来点预测与先前点加速度预测之间的误差差异。这一创新在多个常用的和非主流的自回归ANN架构上进行了测试，并在道琼斯指数上显示出了统计意义上的改进，尤其是在可能导致异常行为的未遇到分布数据条件下对于易受归一化影响的激活函数表现尤为明显。", "conclusion": "这种结构通过减少数据邻域保护的力度（即弱化对数据邻域的接近关系保护），有效地解决了自回归模型破坏数据拓扑的难点，从而在未遇到分布的数据条件下为具体归一化敏感的激活函数提供了有意义的改进，有效地处理了长期股票预测中的问题。"}
{"llm_update_time": "20251116", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2511.10562", "html_url": "https://arxiv.org/abs/2511.10562", "title": "Oya: 深度学习在准确全球降水估计中的应用", "title_en": "Oya: Deep Learning for Accurate Global Precipitation Estimation", "authors": "Emmanuel Asiedu Brempong,Mohammed Alewi Hassen,MohamedElfatih MohamedKhair,Vusumuzi Dube,Santiago Hincapie Potes,Olivia Graham,Amanie Brik,Amy McGovern,George Huffman,Jason Hickey", "background": "准确的降水估计对水文应用至关重要，特别是在地面观测网络稀疏的全球南方地区。当前基于卫星的降水产品往往依赖于长波红外通道，或使用可能导致显著误差的校准数据，尤其是在次日时间尺度上。此外，这些产品在降水检测和定量降水估计（QPE）方面存在局限性，特别是在降水事件与无降水事件之间的数据不平衡。", "innovation": "该研究引入了Oya，一种利用地球静止轨道（GEO）卫星全光谱可见光和红外（VIS-IR）观测的新颖实时降水检索算法。Oya采用两阶段深度学习方法，结合两个U-Net模型：一个用于降水检测，另一个用于定量降水估计（QPE），以解决降水与无降水事件之间的数据不平衡问题。该模型使用高分辨率的GPM联合雷达辐射计算法（CORRA）v07数据作为地面真实值进行训练，并通过预训练在IMERG-Final检索上增强稳健性，减轻由于CORRA的有限时间采样导致的过拟合。", "conclusion": "通过利用多个GEO卫星，Oya实现了准全球覆盖，并展示了与现有区域和全球降水基准相比的优越性能，为提高降水监测和预报提供了有前途的道路。"}
{"llm_update_time": "20251116", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2511.10475", "html_url": "https://arxiv.org/abs/2511.10475", "title": "内在维度作为无模型测量类别不平衡的手段", "title_en": "Intrinsic Dimensionality as a Model-Free Measure of Class Imbalance", "authors": "Çağrı Eser,Zeynep Sonat Baltacı,Emre Akbaş,Sinan Kalkan", "background": "分类任务中的类别不平衡通常通过各类别示例的数量来量化，但这种方法忽略了冗余样本的存在以及类别间学习难度的不同。尽管可以使用训练损失和不确定性等复杂度量，但这些方法依赖于训练机器学习模型。已有研究常采用基于数量重采样和加权的方法来缓解类别不平衡问题，但效果有限。本研究提出使用数据内在维度（ID）作为计算简便、无需模型的类别不平衡度量，并将其无缝融入到各种缓解不平衡的方法中。实验结果表明，ID 在五个不同数据集上性能优越，超越了文献中使用的基于数量的重新加权和重采样技术。研究发现结合内在维度与数量可以进一步提升性能。", "innovation": "提出将数据内在维度（ID）作为一个简便的、无需模型的类别不平衡度量方法，并展示其在缓解类别不平衡方面的优越性能。此外，该方法展示了与其他数量指标结合使用可以进一步提升性能的有效性。现有方法依赖复杂的度量以及模型训练，该研究提供了一种简单、实用、无需模型的方式来识别类别不平衡问题。", "conclusion": "数据内在维度（ID）作为类别不平衡的度量方法，在五个不同数据集的实验中表现出优越的效果，超越了传统的基于数量的方法。结合内在维度与数量可以进一步改善性能。研究结果表明内在维度是一种有效且简便的方法，可以集成到各种不平衡缓解方法中，来提高分类任务的性能。"}
{"llm_update_time": "20251116", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2511.10575", "html_url": "https://arxiv.org/abs/2511.10575", "title": "带有可学习Top-K LISTA和FISTA编码器的半统一稀疏词典学习", "title_en": "Semi-Unified Sparse Dictionary Learning with Learnable Top-K LISTA and FISTA Encoders", "authors": "Fengsheng Lin,Shengyi Yan,Trac Duy Tran", "background": "本文介绍了一种将经典稀疏模型与现代深度架构统一起来的半统一稀疏字典学习框架。该框架整合了严格的Top-$K$ LISTA和其凸优化变种LISTAConv到判别性LC-KSVD2模型中，使得在监督或无监督条件下，稀疏编码器和词典可以协同进化。这种方法保留了传统稀疏编码的可解释性，并且能够从高效的可微训练中获益。", "innovation": "本文提出了将Top-$K$ LISTA和LISTAConv与判别性LC-KSVD2模型整合的一种半统一稀疏字典学习框架。这种方法整合了严格的Top-$K$ LISTA和其凸优化变种LISTAConv到判别性LC-KSVD2模型中，实现了两者在监督或无监督条件下的协同进化。同时，建立了凸优化变种的PALM风格收敛性分析，确保了块交替下的理论稳定性。实验结果表明，该方法在CIFAR-10、CIFAR-100和TinyImageNet数据集上分别获得了95.6%、86.3%和88.5%的准确率，具有更快的收敛速度和更低的内存成本（小于4GB GPU）", "conclusion": "提出的LC-KSVD2 + LISTA/LISTAConv流水线提供了一种具有可解释性和计算效率的现代深度架构的替代方案。"}
{"llm_update_time": "20251116", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2511.10481", "html_url": "https://arxiv.org/abs/2511.10481", "title": "Panda: 以负数据增强为基础的测试时适应方法", "title_en": "Panda: Test-Time Adaptation with Negative Data Augmentation", "authors": "Ruxi Deng,Wenxuan Bao,Tianxin Wei,Jingrui He", "background": "预训练的视觉语言模型（VLMs）在零样本分类方面表现出色，但在常见的图像降级（诸如图像腐蚀）下其预测能力明显下降。许多在测试时的适应（TTA）方法使用正数据增强（PDA）来生成每个测试样本的多个视图，以减少预测偏差。然而，这些方法存在两个关键限制：第一，由于每张图像需要大量的增强，导致计算开销显著增加；第二，PDA无法缓解预测偏向，即模型在某些类别下的预测会因为降级而出现偏差，因为PDA通常不会消除降级本身的影响。", "innovation": "为了克服这些挑战，我们提出了Panda，一种基于负数据增强（NDA）的新型TTA方法。Panda不同于正增强保持对象语义的方式，它通过扰乱语义内容来生成负增强。Panda将图像划分为块，并从共享块池中随机组装产生负增强，这些负增强保留了降级特定的特征，同时消除了与对象相关的信息。通过从原始图像特征中减去这些负样本的均值特征，可以有效地抑制与降级相关的成分，同时保存类别相关的信息，从而缓解在分布偏移下的预测偏差。Panda允许增强在批次内部的样本间共享，实现了几乎无计算开销。此外，Panda可以无缝集成到现有的TTA框架中，显著提升其鲁棒性。", "conclusion": "我们的实验表明，Panda相比PDA方法展现出更好的性能，且多种TTA方法在与Panda结合后也显著提升了性能。我们的代码已公开."}
{"llm_update_time": "20251116", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2511.10504", "html_url": "https://arxiv.org/abs/2511.10504", "title": "Holonorm", "title_en": "Holonorm", "authors": "Daryl Noupa Yongueng,Hamidou Tembine", "background": "在变压器训练过程中，归一化是一个关键点。动态Tanh（DyT）提出将Tanh作为替代层归一化（LN）的方法，并验证了这一想法的有效性，但是Tanh自身面临正交性、线性和失真问题，导致其可靠性不足。因此，本文提出了一种新的归一化方法——Holonorm，特点是具有残差连接和非线性，能够适合作为Tanh的替代品在归一化领域使用。尽管Holonorm在维度为一时可与软信号函数相似，但软信号函数不是一个好的张量和大维度向量函数，而Holonorm能够保持信号的正交性、方向性和可逆性。此外，Holonorm还能将所有向量映射到开单位球中，有助于防止激活值爆炸，并提升深层变压器模型的稳定性。", "innovation": "霍洛诺姆（Holonorm）是一种新的归一化方法，引入了残差连接和非线性，以替代Tanh在变压器中的使用。Holonorm能够保持信号的正交性、方向性和可逆性，并且能够将所有向量映射到开单位球中，有助于避免激活值过大的问题，提高模型的稳定性。此外，Holonorm在评估模型时更有助于理解，因为它可以表示为0到1之间的一个数值，且$1 - \text{Holonorm}$是它的互补值。", "conclusion": "本文详细研究了变压器的归一化过程，并提出了霍洛诺姆（Holonorm），这是一种适合作为归一化函数的改进形式的软信号函数。Holonorm在评估模型时更具可理解性，并且能够提高变压器模型的稳定性和性能。"}
{"llm_update_time": "20251116", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2511.10590", "html_url": "https://arxiv.org/abs/2511.10590", "title": "预训练联合预测实现分子设计可扩展的批量贝叶斯优化", "title_en": "Pretrained Joint Predictions for Scalable Batch Bayesian Optimization of Molecular Designs", "authors": "Miles Wang-Henderson,Ben Kaufman,Edward Williams,Ryan Pederson,Matteo Rossi,Owen Howell,Carl Underkoffler,Narbe Mardirossian,John Parkhill", "background": "药物开发中的批量合成和测试分子设计是关键瓶颈。为了加速这一过程，研究人员正在探索利用生物分子基础模型作为替代方案。本文探讨了如何通过批量贝叶斯优化(Batch BO)实现可扩展的结合亲和力概率替代方案。", "innovation": "本文通过玉溪神经网络(ENNs)框架，在大型结构信息模型的基础上，获得了可扩展的结合亲和力联合预测分布。研究的重点是先验网络在ENNs中的重要性，以及如何在合成数据上预训练它们以提高批量BO下游性能。这种方法通过在半合成基准和真实世界的分子库中发现已知有效的EGFR抑制剂演示了其实用性。", "conclusion": "该工作展示了预训练先验网络对于批量贝叶斯优化实现大规模药物发现的潜力，能够在最多5倍的迭代次数内发现高效的EGFR抑制剂，最多10倍的迭代次数内发现真实世界的小分子库中的高效抑制剂。"}
{"llm_update_time": "20251116", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2511.10619", "html_url": "https://arxiv.org/abs/2511.10619", "title": "算法设计与改进多臂老虎机问题的更强性能保证", "title_en": "Algorithm Design and Stronger Guarantees for the Improving Multi-Armed Bandits Problem", "authors": "Avrim Blum,Marten Garicano,Kavya Ravichandran,Dravyansh Sharma", "background": "改进的多臂老虎机问题是一种在不确定性条件下分配努力的正式模型，适用于新科技研究投资、临床试验和从学习曲线选择超参数等多种场景。每次拉动手臂会得到一个单调增加但递减的奖励。虽然已经有很多基于改进多臂老虎机的算法设计工作，但这些算法主要提供的是较为悲观的最坏情况保证。已知算法相对于最优手臂的竞争因子下界分别为确定性算法的$\boldsymbol{\rm \tilde{O}(k)}$和随机算法的$\boldsymbol{\rm \tilde{O}(\boldsymbol{\rm \tilde{\boldsymbol{\root \frac{1}{2}\right}} k)}}$。", "innovation": "本文提出了两种新的参数化多臂老虎机算法族，并利用离线数据对每种算法族学习近最优算法所需的样本复杂度进行了分析。第一种算法族包括了之前工作的最优随机算法。当手臂奖励曲线满足某些关于凹性的额外性质时，适当选择此类算法可以实现更强的保证，且与$k$的依赖关系最优。第二种算法族保证在良好行为实例上找到最优手臂（best-arm identification），在糟糕行为实例上退回到最坏情况保证。", "conclusion": "从统计学习的角度来看，本文在无需验证假设是否满足的情况下，实现了更强的数据依赖性保证，从而克服了传统多臂老虎机算法在最坏情况下的悲观性能限制，使得算法能够在实际应用中更有效并实现更好的性能。"}
{"llm_update_time": "20251116", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2511.10576", "html_url": "https://arxiv.org/abs/2511.10576", "title": "通过 $\boldsymbol{\textbf{\text{ℓ₀}}} \boldsymbol{\textbf{攻击}}$ 的凸包实现稳健性认证", "title_en": "Tight Robustness Certification through the Convex Hull of $\\ell_0$ Attacks", "authors": "Yuval Shapira,Dana Drachsler-Cohen", "background": "该论文探讨了通过修改图像中的少量像素来欺骗分类器的少数像素攻击(few-pixel attacks)。这些攻击的扰动空间是 $\boldsymbol{\textbf{\text{ℓ₀}}}$-球，而非凸的，不同于 $p \boldsymbol{\textbf{\text{≥}}} 1$ 时的 $\boldsymbol{\textbf{\text{ℓ_p}}}$-球。现有的局部鲁棒性验证器通常依赖于线性边界传播，这种方法能捕捉凸扰动空间。论文指出，$\boldsymbol{\textbf{\text{ℓ₀}}} \boldsymbol{\textbf{球}}$ 的凸包是其边界框和不对称扩展的类似 $\boldsymbol{\textbf{\text{ℓ₁}}}$ 多面体的交集，并证明当输入维度增加时，凸包和此多面体的体积几乎相等。", "innovation": "论文提出了通过准确计算凸包边界来精确计算 $\boldsymbol{\textbf{\text{ℓ₀}}} \boldsymbol{\textbf{球}}$ 凸包边界的线性边界传播方法，这种方法比在边界框或类似 $\boldsymbol{\textbf{\text{ℓ₁}}}$ 多面体上的边界传播更为精确。该方法显著提高了最先进的 $\boldsymbol{\textbf{\text{ℓ₀}}} \boldsymbol{\textbf{球}}$ 验证器在最具有挑战性的鲁棒性基准上的性能，提高了 1.24 至 7.07 倍，平均提高了 3.16 倍。", "conclusion": "论文通过对 $\boldsymbol{\textbf{\text{ℓ₀}}} \boldsymbol{\textbf{攻击}}$ 凸包的深入分析和精确的边界传播技术，显著提高了 $\boldsymbol{\textbf{\text{ℓ₀}}}$ 验证器在评估模型鲁棒性方面的性能，使得验证过程更加精确和高效。"}
{"llm_update_time": "20251116", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2511.10561", "html_url": "https://arxiv.org/abs/2511.10561", "title": "使用信息论最大化机器学习势函数数据集压缩效率", "title_en": "Maximizing Efficiency of Dataset Compression for Machine Learning Potentials With Information Theory", "authors": "Benjamin Yu,Vincenzo Lordi,Daniel Schwalbe-Koda", "background": "机器学习原子间势（MLIPs）相较于密度泛函理论计算，具有更高的准确性和较低的成本。然而，其性能依赖于训练数据集的大小和多样性。尽管使用大规模数据集可以提高模型的准确性和泛化能力，但同时也增加了计算成本和训练难度。相反，小规模数据集可能会排除重要的原子环境，从而影响MLIP的准确性和可靠性。因此，需要一种有效的数据集压缩方法，既能保留关键信息，又能提高计算效率。", "innovation": "本文提出了一种信息论框架，用于量化数据集压缩方法的效率，并提出了一种算法以最大化该效率。该方法将原子数据集压缩视为最小集合覆盖（Minimum Set Cover, MSC）问题的实例，通过识别保留最多信息的最小数据集子集，同时去除冗余信息。这种方法在GAP-20、TM23数据集以及ColabFit库中的64个不同数据集上进行了全面演示和验证。实验结果表明，对于所有压缩率，MSC方法都可以保留异常值、保存数据集多样性，并在高压缩率下保持力的长尾分布，表现出优于其他子采样方法的效果。此外，基于MSC压缩的数据训练出的MLIPs，在低数据状态下仍能减少离域数据的误差。", "conclusion": "该研究提出的方法通过实验验证了其优势，不仅可以实现数据的高效压缩，还能在低数据状态下有效训练出准确性更高的MLIPs，并且使用开源软件 QUESTS 实现，适用于原子建模中的多种任务，包括数据子采样、异常检测和低成本训练改进的MLIPs。"}
{"llm_update_time": "20251116", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2511.09767", "html_url": "https://arxiv.org/abs/2511.09767", "title": "LASSO双选择模型的实证讨论: 机场运输研究", "title_en": "Modelos Empiricos de Pos-Dupla Selecao por LASSO: Discussoes para Estudos do Transporte Aereo", "authors": "Alessandro V. M. Oliveira", "background": "该文讨论了利用正则化回归和LASSO方法（最小绝对 shrinkage 和选择算子）进行估计的各种形式。LASSO作为一种在高维计量经济学中广泛应用的监督学习方法，允许处理大数据集和多个相关控制变量。文中还探讨了高维计量经济学中的概念性问题及其对模型维度的影响，以及正则化程序背后的稀疏性原理。", "innovation": "重点讨论了LASSO方法及其在高维和高维稀疏模型以及工具变量模型中的应用。同时还简要介绍了Lassopack常规程序包，涵盖了其语法，并提供了HD、HDS和IV-HDS模型的例子，以及结合了固定效应估计器的模型组合。", "conclusion": "该文最后讨论了研究方法在机场运输研究中的潜在应用，特别是在航空公司运营效率和航空燃料消耗的实证研究中。"}
{"llm_update_time": "20251116", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2511.09790", "html_url": "https://arxiv.org/abs/2511.09790", "title": "用于学习动态系统的稳健任务级控制架构", "title_en": "A Robust Task-Level Control Architecture for Learned Dynamical Systems", "authors": "Eshika Pathak,Ahmed Aboudonia,Sandeep Banik,Naira Hovakimyan", "background": "基于动力系统（DS）的学习从演示（LfD）是一种强大的工具，用于在机器人系统的操作（任务）空间中生成运动计划。然而，生成的运动计划的实现经常受到所谓的任务执行不匹配的影响，由于未建模的动力学、持续的干扰和系统延迟，导致机器人实际的任务空间状态偏离所需的运动轨迹。", "innovation": "我们提出了一种名为L1增强动力系统（L1-DS）的新型任务级鲁棒控制架构，该架构明确处理由任何DS-LfD方案生成的名义运动计划的执行差异。该框架将任何DS-LfD模型与一个名义稳定控制器和一个L1自适应控制器进行增强。此外，引入了一种基于窗口动态时间规整（DTW）的目标选择器，使名义稳定控制器能够处理时间对齐偏差，以提高相位一致性跟踪能力。", "conclusion": "我们展示了我们的架构在LASA和IROS手写数据集上的有效性，证明了其在鲁棒任务级控制方面的优越性能。"}
{"llm_update_time": "20251116", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2511.09769", "html_url": "https://arxiv.org/abs/2511.09769", "title": "使用卷积神经网络的轴对称雷诺平均纳维-斯托克斯湍流模型", "title_en": "Symmetry aware Reynolds Averaged Navier Stokes turbulence models with equivariant neural networks", "authors": "Aaron Miller,Sahil Kommalapati,Robert Moser,Petros Koumoutsakos", "background": "准确且普遍适用的雷诺平均纳维-斯托克斯（RANS）模型需要有效的闭合方法。现有模型依赖于对高阶张量关系的有效学习，以提高模型的准确性和通用性。", "innovation": "引入基于张量、意识对称的闭合方法，使用等变神经网络（ENNs）来增强模型的有效性。提出一个算法来确保张量组件的代数收缩关系。这种建模方法借鉴了Kassinos和Reynolds引入的结构张量框架，用于在快速剪切理论框架下学习闭合方法。实验表明，ENNs能够有效地学习涉及高阶张量的关系，其性能与现有模型相当或更好。", "conclusion": "ENNs提供了一种与经典张量基模型物理上一致的替代方法，能够实现RANS中未闭合项的端到端学习，并快速探索模型依赖性。"}
{"llm_update_time": "20251116", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2511.09768", "html_url": "https://arxiv.org/abs/2511.09768", "title": "ProbLog4Fairness: 一种基于神经符号的方法来建模和减轻偏见", "title_en": "ProbLog4Fairness: A Neurosymbolic Approach to Modeling and Mitigating Bias", "authors": "Rik Adriaensen,Lucas Van Praet,Jessa Bekker,Robin Manhaeve,Pieter Delobelle,Maarten Buyl", "background": "在实践中，定义公平性的具体步骤通常是困难的，因为多个定义可能是不兼容的，但每个定义又可能是合理的。相反，直接根据特定实际任务的背景信息，通过具体的假设描述算法偏见可能更易于实现。虽然这种假设可以在训练过程中用于减轻偏见，但目前缺乏一种既基于原则、灵活且可解释的框架来整合这些假设。", "innovation": "我们的方法是将偏见假设形式化为ProbLog编程语言中的程序。ProbLog是一种概率逻辑编程语言，允许通过逻辑描述概率因果关系。神经符号的扩展使得能够轻松将这些假设集成到神经网络的训练过程中。我们提出了表达不同类型偏见的模板，并在具有已知偏见的合成表格数据集上展示了这种方法的灵活性和多样性。通过算法偏见扭曲的估计值，我们还成功减轻了实际表格和图像数据中的算法偏见。", "conclusion": "我们得出的结论是，ProbLog4Fairness优于基准，因为它能够灵活地建模相关偏见假设，其他方法通常会坚持固定的偏见类型或公平性概念。"}
{"llm_update_time": "20251116", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2511.09765", "html_url": "https://arxiv.org/abs/2511.09765", "title": "Brian Intensify: 一种基于机器学习的适应性听觉EEG刺激和FXS认知增强框架", "title_en": "Brian Intensify: An Adaptive Machine Learning Framework for Auditory EEG Stimulation and Cognitive Enhancement in FXS", "authors": "Zag ElSayed,Grace Westerkamp,Jack Yanchen Liu,Ernest Pedapati", "background": "神经发育障碍，如脆性X综合症（FXS）和自闭症谱系障碍（ASD），其特点是在α和γ频带等特定频率范围内的皮层振荡活动紊乱，这与注意力、感觉处理和认知功能的缺陷有关。为了改善这些个体的认知准备状态，本文提出了一种基于机器学习的自适应脑-机接口（BCI）系统，通过特定频率的听觉刺激调节神经振荡。", "innovation": "本文开发了一种基于机器学习的自适应听觉EEG刺激框架，能够通过特定频率的听觉刺激调节神经振荡，以提升FXS等个体的认知准备状态。该系统通过实时调整刺激参数，实现个性化神经调节，该项目通过综合分析不同频段的功率谱特征和跨频率耦合指标，实现了优化目标。", "conclusion": "本文建立了一种新型的基于EEG的优化框架，用于认知神经调节，有效提升了FXS等神经发育障碍患者的认知功能，并为下一代融合AI的BCI系统奠定了基础，实现了个性化的神经康复。"}
{"llm_update_time": "20251116", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2511.09801", "html_url": "https://arxiv.org/abs/2511.09801", "title": "基于广义无穷维度Alpha-Procrustes几何", "title_en": "Generalized infinite dimensional Alpha-Procrustes based geometries", "authors": "Salvish Goomanee,Andi Han,Pratik Jawanpuria,Bamdev Mishra", "background": "本文扩展了近期引入的用于对称正定矩阵（SPD矩阵）的Alpha-Procrustes家族里黎曼度量，通过引入广义Bures-Wasserstein（GBW）、Log-Euclidean和Wasserstein距离的形式版本。尽管Alpha-Procrustes框架在有限维和无限维设置中统一了许多经典度量，但之前缺少实现这些广义形式所需的结构性组件。这一框架的改进基于单位化的希尔伯特-施密特算子和扩展马哈拉诺比斯范数，允许构造鲁棒的无限维度广义GBW和Log-Hilbert-Schmidt距离。这种方法还整合了一个可学习的正则化参数，以增强高维比较中的几何稳定性。", "innovation": "本文通过引入单位化的希尔伯特-施密特算子和扩展马哈拉诺比斯范数，实现了GBW和Log-Hilbert-Schmidt距离的鲁棒的、无限维度的广义形式。此外，提出了一个可学习的正则化参数，以增强高维比较中的几何稳定性。初步实验结果表明，与现有的基准相比，这些广义度量在涉及不同维度和规模的数据集比较时能展示出更好的性能。", "conclusion": "本文为先进的几何学方法在机器学习、统计推断和函数数据分析中的发展奠定了理论和计算基础。"}
{"llm_update_time": "20251116", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2511.09894", "html_url": "https://arxiv.org/abs/2511.09894", "title": "EgoEMS: 一种用于紧急医疗服务认知辅助的高保真多模态第一人称数据集", "title_en": "EgoEMS: A High-Fidelity Multimodal Egocentric Dataset for Cognitive Assistance in Emergency Medical Services", "authors": "Keshara Weerasinghe,Xueren Ge,Tessa Heick,Lahiru Nuwan Wijayasingha,Anthony Cortez,Abhishek Satpathy,John Stankovic,Homa Alemzadeh", "background": "急诊医疗服务（EMS）对于紧急情况下的患者生存至关重要，但在高强度情境下，第一响应者往往面临巨大的认知压力。人工智能认知助理，作为虚拟伙伴，可以通过支持实时数据收集和决策来减轻这种负担。", "innovation": "该研究首次引入了EgoEMS数据集，这是一个端到端、高保真、多模态、多人员数据集，记录了超过20小时的真实模拟紧急医疗救援流程。数据集在233种由62名参与者（包括46名专业急诊医护人员）进行的场景中捕捉了第一人称视角的数据。该数据集通过开放源代码、低成本且可复制的数据收集系统创建，附带标注的关键步骤、时间戳音频转录（带有说话人识别）、动作质量度量以及带有分割掩码的边界框。强调现实性，数据集包括响应者-患者互动，反映现实世界的急救动态。", "conclusion": "我们希望EgoEMS能够激发研究社区对智能急诊系统边界的探索，并最终改善患者结果。此外，我们还提出了一套针对实时多模态关键步骤识别和动作质量估计基准，对于开发支持急诊医疗服务的人工智能工具至关重要。"}
{"llm_update_time": "20251116", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2511.09775", "html_url": "https://arxiv.org/abs/2511.09775", "title": "通过SHAP熵正则化的隐私保护可解释AIoT应用", "title_en": "Privacy-Preserving Explainable AIoT Application via SHAP Entropy Regularization", "authors": "Dilli Prasad Sharma,Xiaowei Sun,Liang Xue,Xiaodong Lin,Pulei Xiong", "background": "随着人工智能物联网（AIoT）在智能家庭环境中的普及，对透明且可解释的机器学习模型的需求大幅增加。为提高用户信任并遵守新兴的监管框架，解释性人工智能（XAI）方法，尤其是后验技术如SHapley Additive exPlanations (SHAP)和Local Interpretable Model-Agnostic Explanations (LIME)，被广泛用于阐明模型的行为。然而，最近的研究表明，这些解释方法可能会无意地暴露用户的敏感属性和行为模式，从而引入新的隐私风险。", "innovation": "为解决上述问题，本文提出了一种基于SHAP熵正则化的新型隐私保护方法，以减轻解释性AIoT应用中的隐私泄露。该方法通过在训练过程中引入熵为基础的正则化目标，惩罚低熵的SHAP归因分布，从而促进特征贡献的均匀分布。通过开发基于SHAP的隐私攻击套件，并结合利用模型解释输出推断敏感信息，证明了该方法的有效性。实验结果表明，与基线模型相比，SHAP熵正则化显著减少了隐私泄露，同时保持了高预测准确性和忠实的解释一致性。", "conclusion": "本研究为确保智能家庭物联网应用中的隐私保护和信任度做出了贡献，推动了隐私保护的可解释AI技术的发展。"}
{"llm_update_time": "20251116", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2511.09925", "html_url": "https://arxiv.org/abs/2511.09925", "title": "四层矩阵分解在随机初始化下的全局收敛性", "title_en": "Global Convergence of Four-Layer Matrix Factorization under Random Initialization", "authors": "Minrui Luo,Weihang Xu,Xiang Gao,Maryam Fazel,Simon Shaolei Du", "background": "深度矩阵分解问题的梯度下降动力学被广泛研究作为深度神经网络的简化理论模型。尽管两层矩阵分解的收敛理论已经很成熟，但到目前为止，尚没有在随机初始化下对更一般的深度矩阵分解提供全局收敛保证。本文填补了这一空白，提出了在符合特定条件的目标矩阵和标准平衡正则化项下，四层矩阵分解在随机初始化下的多项式时间全局收敛保证。", "innovation": "本文通过引入新的技术以证明梯度下降动力学的鞍点避免性质，并将先前的理论拓展至层权重特征值变化的刻画，为随机初始化下的四层矩阵分解提供了全局收敛保证。", "conclusion": "在特定条件下，随机初始化下的四层矩阵分解在标准平衡正则化项下具有多项式时间的全局收敛性。"}
{"llm_update_time": "20251116", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2511.09809", "html_url": "https://arxiv.org/abs/2511.09809", "title": "Test-Time Spectrum-Aware Latent Steering for Zero-Shot Generalization in Vision-Language Models", "title_en": "Test-Time Spectrum-Aware Latent Steering for Zero-Shot Generalization in Vision-Language Models", "authors": "Konstantinos M. Dafnis,Dimitris N. Metaxas", "background": "视觉语言模型(VLMs)在零样本推理方面表现出色，但在测试时遇到领域转换时性能会下降。为了解决这一问题，最近提出了在单张未标记图像上适应VLMs的 episodic 测试时适应策略。现有的适应策略，例如测试时提示调优，通常需要通过大型编码器权重进行反向传播或修改核心模型组件。这些方法可能涉及对系统造成较大负担的修改或计算开销。因此，本文的背景是寻找一种适应策略，能够在保持模型结构不变或最少修改的情况下，有效地进行零样本泛化适应。", "innovation": "本文提出了一种称为 Spectrum-Aware Test-Time Steering (STS) 的轻量化适应框架。STS 从文本嵌入中提取光谱子空间，定义主要语义方向，并通过适应少数可变移位参数来学习光谱自适应地调整潜在表示，以最小化增强视图之间的熵。与现有方法相比，STS 在标准评估协议下表现出色，几乎超过了或优于最先进的测试时适应方法，同时仅引入少量新的参数，且具有更快的推理速度和更小的内存占用。", "conclusion": "通过实验评估，本文展示了 STS 在零样本泛化任务上的优异性能，整体优于或至少与最先进的测试时适应方法持平，而参数量更少，且运行速度更快，内存占用更小。此外，STS 在整个推理过程中不需要对冻结的编码器进行反向传播或修改。"}
{"llm_update_time": "20251116", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2511.09873", "html_url": "https://arxiv.org/abs/2511.09873", "title": "HierRouter: Coordinated Routing of Specialized Large Language Models via Reinforcement Learning", "title_en": "HierRouter: Coordinated Routing of Specialized Large Language Models via Reinforcement Learning", "authors": "Nikunj Gupta,Bill Guo,Rajgopal Kannan,Viktor K. Prasanna", "background": "大语言模型（LLM）在许多任务中表现出顶级性能，但同时也带来了巨大的计算和内存成本，这限制了它们在资源受限或实时环境中的部署。为了应对这一挑战，研究提出了一种基于层次路由的方法HierRouter，该方法能动态地从一组专门的小型语言模型中组装出推理管道。HierRouter 表现为一个有限时区马尔可夫决策过程（MDP），通过使用Proximal Policy Optimization（PPO）强化学习算法训练奖励学习代理，以实现多跳推理过程中的逐步模型调用选择。代理依据不断变化的上下文信息和累积的成本信息，做出上下文感知的路由决策。实验结果表明，HierRouter 在三个开源候选大语言模型和六个基准测试中（包括问答、代码生成和数学推理）将响应质量提高了高达2.4倍，而平均额外的推理成本却非常有限。这些结果突显了层次路由在高效、高性能大语言模型推理方面的潜力。所有代码可在此找到: https://github.com/Nikunj-Gupta/hierouter.", "innovation": "HierRouter采用层次路由的创新方法，通过强化学习训练代理，动态地从一组专门的小型语言模型中组装出推理管道，实现了上下文感知的多跳推理。这种方法能够显著提高响应质量，同时保持较低的额外推理成本。", "conclusion": "实验结果表明，HierRouter 在多个基准测试中取得了显著的性能提升，展示了层次路由在成本效率和高性能大语言模型推理方面的巨大潜力。"}
{"llm_update_time": "20251116", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2511.10079", "html_url": "https://arxiv.org/abs/2511.10079", "title": "基于柯尔莫哥洛夫-阿诺德网络的机器人 manipulator 静摩擦力物理启发式机器学习建模", "title_en": "Physics-informed Machine Learning for Static Friction Modeling in Robotic Manipulators Based on Kolmogorov-Arnold Networks", "authors": "Yizheng Wang,Timon Rabczuk,Yinghua Liu", "background": "摩擦力模型在实现机器人操作系统中的高精度运动控制中起着关键作用。传统的静摩擦模型（如斯屈克模型）由于其简单的形式而被广泛使用，但这些模型通常需要预先定义的函数假设，这在处理未知函数结构时带来了重大挑战。", "innovation": "本文提出了一种基于柯尔莫哥洛夫-阿诺德网络（KAN）的物理启发式机器学习方法，用于机器人关节的静摩擦力建模。该方法结合了样条激活函数和符号回归机制，通过修剪和属性评分实现模型简化和物理表达提取，同时保持高预测精度和可解释性。", "conclusion": "实验表明，所提出的方法在各种任务中实现了决定系数大于0.95，并成功提取了简洁且物理上有意义的摩擦表达式。这项研究为可解释和数据驱动的机器人摩擦力建模提供了新的视角，具有广阔的工程应用前景。"}
{"llm_update_time": "20251116", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2511.09906", "html_url": "https://arxiv.org/abs/2511.09906", "title": "基于图式方程发现的固体中新本构律的发现超越经验模型", "title_en": "Beyond empirical models: Discovering new constitutive laws in solids with graph-based equation discovery", "authors": "Hao Xu,Yuntian Chen,Dongxiao Zhang", "background": "本构模型是固体力学和材料科学的基础，它们能对材料在不同加载条件下的响应进行定量描述和预测。传统的现象学模型通过经验拟合而来，具有局限性，往往需要依赖专家的直觉和预设的功能形式。本文探讨了一种基于图的方程发现框架，该框架可以从多种来源的实验数据中自动化地发现本构定律。这种方法通过将方程表示为有向图来实现，其中节点代表操作和变量，边表示计算关系，边特征编码参数依赖性，从而生成和优化具有未确定的特定材料参数的自由形式符号表达式。", "innovation": "本文提出了一个基于图的方程发现框架，能够从多来源实验数据中自动化发现本构定律。这种方法可以在传统经验公式无法表示复杂物理现象的背景下提供一种可解释且可推广的数据驱动科学建模方法。已通过这种方式发现新的本构模型，用于合金钢材料的应变率效应和锂金属的变形行为，并达到了比传统经验模型更高的准确性。", "conclusion": "本框架提供了一种可用于数据分析的新方法，特别是当传统经验公式无法 adequately 表示复杂物理现象时。通过这种方式，发现了新的固体力学本构模型，展示出了紧凑的分析结构，并且提高了预测精度。"}
{"llm_update_time": "20251116", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2511.10010", "html_url": "https://arxiv.org/abs/2511.10010", "title": "先进计算机架构在加速人工智能工作负载中的作用", "title_en": "The Role of Advanced Computer Architectures in Accelerating Artificial Intelligence Workloads", "authors": "Shahid Amin,Syed Pervez Hussnain Shah", "background": "伴随人工智能（AI）领域取得的显著进展，计算机架构也同步经历了革命性的变化。特别是深度神经网络（DNNs）等复杂AI模型的计算需求，已经超越了传统架构的能力极限。论文对这种同步演进进行了结构化的综述，分析了旨在加速现代AI任务的架构 landscape，探索了图形处理单元（GPUs）、应用程序特定集成电路（ASICs）和现场可编程门阵列（FPGAs）等主要架构范式的设计理念、关键特征和性能权衡。进一步分析了影响性能和能效的核心原则，包括数据流优化、先进的内存层次结构、稀疏性和量化。", "innovation": "论文通过合成架构原则与行业标准基准的定量性能数据，提供了一个全面的人工智能加速器领域景观图。强调了硬件与软件协同设计对于未来计算推进的重要性，不再是优化，而是必要性。", "conclusion": "人工智能与计算机架构之间存在共生关系，未来的计算进步需要硬件与软件协同设计。"}
{"llm_update_time": "20251116", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2511.09942", "html_url": "https://arxiv.org/abs/2511.09942", "title": "AdaptViG: 适应性视觉GNN及其指数衰减门机制", "title_en": "AdaptViG: Adaptive Vision GNN with Exponential Decay Gating", "authors": "Mustafa Munir,Md Mostafijur Rahman,Radu Marculescu", "background": "Vision Graph Neural Networks (ViGs)虽然在视觉架构方面提供了新的发展方向，但由于其在图构建阶段的大量计算挑战，往往影响了它们的效率。", "innovation": "该论文提出了一种高效的混合视觉图神经网络AdaptViG，引入了一种新颖的自适应图卷积机制，结合了高效的静态轴向支架和动态的内容感知门控策略。此外，AdaptViG采用了一种混合策略，在早期阶段使用高效的门控机制，在最终阶段使用全局注意模块以实现最佳特征聚合。", "conclusion": "AdaptViG在准确性与效率之间的权衡方面建立了新的状态水平。例如，AdaptViG-M实现了82.6%的top-1精度，使用比ViG-B少80%的参数和84%的GMACs。在下游任务中，AdaptViG-M取得了45.8 mIoU，44.8 APbox和41.1 APmask的结果，分别超过了EfficientFormer-L7 0.7 mIoU，2.2 APbox和2.1 APmask，而参数量减少了78%。"}
{"llm_update_time": "20251116", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2511.09897", "html_url": "https://arxiv.org/abs/2511.09897", "title": "结构化变分推断的理论与计算", "title_en": "Theory and computation for structured variational inference", "authors": "Shunan Sheng,Bohan Wu,Bennett Zhu,Sinho Chewi,Aram-Alexandre Pooladian", "background": "结构化变分推断是现代统计应用中的核心方法论。它假设近似后验具有相互依赖的结构，与均场变分推断不同。本文考虑星结构的变分推断，其中根变量影响所有其他变量。研究第一次证明了变分近似存在的唯一性和自我一致性结果，并将均场设置下的结果扩展到星结构设置下，提出了计算变分近似的新梯度算法有理论保证，开发了新的星可分运输映射稳定性结果，这可能具有单独的意义。内容进一步扩展到高斯度量、分层贝叶斯模型，包括广义线性模型和具有位置族先验的尖峰和查看先验，以及在封闭核偏差中的一维偏差。", "innovation": "提出了星结构变分推断的理论，并证明了变分近似的存在性、唯一性和自我一致性；发展了一种基于最优传输理论的新梯度算法，具有可证明的保证；为星结构变分推断提供了新的稳定性结果，这些结果对运输映射具有独立意义；扩展到高斯度量和具有位置族先验、尖峰和查看先验的分层贝叶斯模型，以及广义线性模型和尖峰和查看先验中的封闭核偏差线性模型。", "conclusion": "鉴于上述贡献，论文证明了星结构变分推断中涉及的变分近似的性质，并通过开发新的稳定性结果在运输映射上扩展了稳定性，同时提出了关于计算星结构变分推断的新方法，并将其应用到广义线性模型和分层贝叶斯模型，这将为该领域后续研究提供重要的理论基础和实践指导。"}
{"llm_update_time": "20251116", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2511.10030", "html_url": "https://arxiv.org/abs/2511.10030", "title": "通过分布式内存检索实现多智能体上下文协调", "title_en": "Multi-agent In-context Coordination via Decentralized Memory Retrieval", "authors": "Tao Jiang,Zichuan Lin,Lihe Li,Yi-Chen Li,Cong Guan,Lei Yuan,Zongzhang Zhang,Yang Yu,Deheng Ye", "background": "大型变压器模型在多样化的数据集上进行训练后，在以前未见过的任务上展示了出色的少量提示性能，无需更新参数。这一能力也已经探索应用于强化学习（RL），其中智能体与环境互动，获取上下文并最大化累积奖励，展现了在复杂环境中的强大适应性。然而，在协作多智能体强化学习（MARL）中，由于智能体必须朝向共同目标进行协调，因此分布式策略部署可能导致任务对齐和奖励分配的偏差，从而限制了策略适应的效率。", "innovation": "我们提出了多智能体上下文协调通过分布式记忆检索（MAICC），这是一种增强协调的新方法，专注于快速适应。该方法涉及训练一个集中式嵌入模型以捕捉细粒度轨迹表示，随后分布式模型近似集中式模型以获取团队任务信息。基于学到的嵌入，相关轨迹作为上下文检索，结合智能体当前子轨迹来辅助决策。在分布式执行过程中，我们引入了一种新颖的记忆机制，有效平衡测试时在线数据与离线记忆。根据构造的记忆，我们提出了结合个体和团队回报的混合有用性评分，确保跨智能体的奖励归属。", "conclusion": "在多智能体对齐基准测试（包括基于层级的采集（LBF）和SMAC（v1/v2））中的广泛实验表明，MAICC相比于现有方法能更快适应未见过的任务。有关的代码可在以下链接访问：this https URL"}
{"llm_update_time": "20251116", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2511.10547", "html_url": "https://arxiv.org/abs/2511.10547", "title": "利用属性条件的人评基准评估图像生成的多样性", "title_en": "Benchmarking Diversity in Image Generation via Attribute-Conditional Human Evaluation", "authors": "Isabela Albuquerque,Ira Ktena,Olivia Wiles,Ivana Kajić,Amal Rannen-Triki,Cristina Vasconcelos,Aida Nematzadeh", "background": "尽管在生成质量方面取得了进展，当前的文本到图像（T2I）模型仍然缺乏多样性，生成了同质化的输出。", "innovation": "提出了一种框架来解决T2I模型中鲁棒性多样性评估的需求。该框架系统地评估多样性的方法包括：（1）一种新颖的人评模板，用于细致的多样性评估；（2）一个经过策划的主题集，涵盖了各种概念及其识别出的因素变化（例如，主题：苹果，变化因素：颜色）；（3）一种通过二项检验比较模型的方法，基于人类注解来评估图像生成模型的多样性。", "conclusion": "本研究提供了一种稳健的方法和洞察，为T2I模型多样性和评估指标的发展铺平了道路。通过严谨地比较各种图像嵌入，可以评估其在多样性方面的表现，并识别出模型在特定类别中的弱点，从而为改进T2I模型的质量提供了依据。"}
{"llm_update_time": "20251116", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2511.10572", "html_url": "https://arxiv.org/abs/2511.10572", "title": "基于延迟反馈的两层上下文贝叶斯个体资源分配", "title_en": "Bi-Level Contextual Bandits for Individualized Resource Allocation under Delayed Feedback", "authors": "Mohammadsina Almasi,Hadis Anahideh", "background": "在高风险领域如教育、就业和医疗中，公平地分配有限资源需要在短期效益与长期影响之间保持平衡，并考虑延迟的后果、隐藏的异质性和道德限制。现有的基于学习的分配框架要么假设即时反馈，要么忽略了个体特征与干预动态之间的复杂相互作用。在动态人口、容量限制和时间敏感效果影响下，提出了一种新的两层上下文贝叶斯框架，用于在延迟反馈情况下进行个体化资源分配，以便在实际操作中实现更加灵活和响应性的决策.", "innovation": "该框架在宏观层面优化各细分群体的预算分配以满足公平性和运营约束，在微观层面使用神经网络根据观察数据识别最响应个体，同时考虑冷却期和通过特定资源延迟核建模的延迟治疗效果。通过明确建模时间动态和反馈延迟，算法能够随着新数据的不断到来，不断改进决策策略，使其更具响应性和适应性.", "conclusion": "通过在教育和就业发展领域的两个实际数据集上验证，该方法实现了更高的累积结果，能够更好地适应延迟结构，并确保各细分群体之间的公平分配。结果强调了延迟意识的数据驱动决策系统在提高机构政策和社会福利中的潜在作用."}
{"llm_update_time": "20251116", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2511.10542", "html_url": "https://arxiv.org/abs/2511.10542", "title": "两个美国的幸福感：26亿条社交媒体帖子中的农村与城市幸福感差异模式", "title_en": "Two Americas of Well-Being: Divergent Rural-Urban Patterns of Life Satisfaction and Happiness from 2.6 B Social Media Posts", "authors": "Stefano Maria Iacus,Giuseppe Porro", "background": "该研究使用2014年至2022年的2.6亿条地理定位的社交媒体帖子和一个微调的生成语言模型，为美国50个州的每个县构建了生活满意度和幸福感指标。研究发现，在农村地区和城市地区存在一个显性的农村-城市悖论：农村地区的居民表现出更高的生活满意度，而城市地区则体现出了更高的幸福感。", "innovation": "该研究通过引入对两种不同主观幸福感维度的分析，即评价性的生活满意度和享乐主义的幸福感，解决了这一悖论。研究结果显示了这两种幸福感类型的差异及其在不同政区和不同时间背景下对政策和环境的反应。特别值得注意的是，该研究利用大规模语言数据和模型来填补传统调查的不足，提供了传统调查方法之外的透明和可重复的数据分析方法。", "conclusion": "总体而言，研究发现针对大规模语言数据的结果显示，大型、语言基础的指标可以解决关于城乡差距的不同发现，通过区分表达的幸福感类型，提供了一种对传统的调查方法的透明、可重复的补充。时间冲击主导了享乐层，2020-2022年的幸福感急剧下降，而生活满意度的变动则更加温和。这些模式在逻辑和OLS模型中是稳健的，且与幸福感理论一致。"}
{"llm_update_time": "20251116", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2511.10540", "html_url": "https://arxiv.org/abs/2511.10540", "title": "下一代漂移室中边缘机器学习在簇计数中的应用", "title_en": "Edge Machine Learning for Cluster Counting in Next-Generation Drift Chambers", "authors": "Deniz Yilmaz,Liangyu Wu,Julia Gonski", "background": "传统漂移室一直是在对撞机跟踪中不可或缺的元件，但在未来如希格斯工厂等机器中，需要更高的粒度和簇计数以进行粒子识别。这提出了一些新的数据处理挑战。通过在单元级读取中实施边缘机器学习，可以在源头进行簇计数，显著减少离开探测器的数据速率，特别是在高粒度漂移室中。", "innovation": "文中提出了用于未来漂移室实时读取的机器学习算法，在簇计数能力上超越了传统的基于导数的技术，特别是在π-κ区分上表现更优。这些算法在FPGA资源上得到实现，能保证与未来的希格斯工厂场景所需的实时操作相一致的延迟。这对于未来加速器探测器的研发以及高能物理中的硬件基于机器学习的边缘应用都有显著进步意义。", "conclusion": "这些结果不仅推动了下一代探测器的设计研发，还展示了高能物理领域中边缘机器学习实际应用的能力。"}
{"llm_update_time": "20251116", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2511.10416", "html_url": "https://arxiv.org/abs/2511.10416", "title": "从布尔到连续域推广类比推理", "title_en": "Generalizing Analogical Inference from Boolean to Continuous Domains", "authors": "Francisco Cunha,Yves Lepage,Zied Bouraoui,Miguel Couceiro", "background": "类比推理是一种强大的归纳机制，在人类认知和人工智能中得到了广泛应用。尽管在布尔领域中已经构建了形式化的类比推理框架，并且可以证明这些框架适用于仿射函数且接近仿射函数的函数可以提供近似正确的推理结果，但这些理论尚未扩展到回归任务或连续领域。", "innovation": "本文从基础出发重新审视了类比推理，发现现有的泛化边界在布尔设置中也会失败。基于此提出了一个基于广义均值的参数化类比推理框架，可以应用于实值领域。此模型不仅包括布尔分类，还支持连续函数上的类比推理。文中还对该场景下的类比保持函数进行了分类，并在光滑假设下推导了最坏情况和平均情况下的误差边界。", "conclusion": "本文提出了跨离散和连续域的类比推理的一般理论，为类比推理在不同领域的应用提供了新的视角和理论基础。"}
{"llm_update_time": "20251116", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2511.10446", "html_url": "https://arxiv.org/abs/2511.10446", "title": "连续性Dropout方法在神经微分方程中的应用", "title_en": "Continuum Dropout for Neural Differential Equations", "authors": "Jonghun Lee,YongKyung Oh,Sungil Kim,Dong-Young Lim", "background": "神经微分方程（NDEs）擅长模拟连续时间动力学，有效处理不规则观测、缺失值和噪声等问题。然而，它们在采用dropout这种深度学习中的核心正则化技术时存在根本性的挑战，使它们容易过度拟合。研究表明，现有的正则化方法不能很好地适应NDEs的需求，因此需要一种通用且适用的正则化策略来解决这一问题，提升NDEs的性能和泛化能力，并有效地防止过拟合和提高预测不确定性量化的能力，使模型更加可靠和可信。", "innovation": "提出了一种名为连续性Dropout的适用于NDEs的通用正则化技术，基于交替更新过程理论，将dropout机制视为在连续时间中交替参与和暂停的随机过程。这种方法提供了一种预防过拟合并增强NDEs泛化能力的原理性方法，并提供了一种结构化框架来通过测试时的蒙特卡洛采样量化预测不确定性。实验结果表明，连续性Dropout在时间序列和图像分类任务中优于现有的NDEs正则化方法，实现了更好的性能和更加可靠和可信的概率估计，促进了不确定性的建模意识。", "conclusion": "实验表明，连续性Dropout在各种时间序列和图像分类任务上优于现有的正则化方法，实现了更优的性能和更可靠、可信的概率估计，鲁棒性和适应性得到了提升，能够更好地进行不确定性预测，并为NDEs提供了有效的新正则化方法。"}
{"llm_update_time": "20251116", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2511.10492", "html_url": "https://arxiv.org/abs/2511.10492", "title": "利用多头解码引导生成型推荐模型中的结构化人类先验——不要浪费它", "title_en": "Don't Waste It: Guiding Generative Recommenders with Structured Human Priors via Multi-head Decoding", "authors": "Yunkai Zhang,Qiang Zhang,Feng(Ryan)Lin,Ruizhong Qiu,Hanchao Yu,Jason Liu,Yinglong Xia,Zhuoran Yu,Zeyu Zheng,Diji Yang", "background": "优化推荐系统以实现准确度之外的目标，例如多样性、新颖性和个性化，对于长期用户满意度至关重要。工业从业者积累了大量结构化的领域知识，这些知识我们称之为人类先验（例如项目分类、时间模式等）。这些知识通常在排名或重新排名后进行后置调整。然而，这种方法仍然与核心模型学习过程脱节，而行业正朝着端到端生成推荐基础模型转变，这一方式尤为不利。另一方面，许多旨在实现准确度之外目标的方法往往需要特定架构的修改，并且倾向于完全无监督地学习用户意图，从而放弃了这些宝贵的人类先验。", "innovation": "我们提出了一种无需依赖模型结构的框架，直接将这些人类先验集成到生成推荐模型的端到端培训中。基于高效LLM解码策略，我们利用轻量级、先验条件化的适配头部引导模型，使其沿着易于理解的维度（例如，交互类型，长期 vs. 短期兴趣）分解用户意图。我们还提出了一种分层组合策略，用于建模不同人类先验类型之间的复杂交互。实验结果显示，我们的方法显著提高了准确度和准确度之外的目标。", "conclusion": "我们的研究证明了人类先验的重要性，它们使基础模型能够更有效地利用更长的上下文和更大的模型规模。该研究为生成推荐模型的优化提供了一种新的视角，即通过整合积累的人类先验知识，实现更好的用户体验和推荐效果。"}
{"llm_update_time": "20251116", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2511.10440", "html_url": "https://arxiv.org/abs/2511.10440", "title": "使用CrysFormer机器学习模型利用Patterson图完成部分结构", "title_en": "Completion of partial structures using Patterson maps with the CrysFormer machine learning model", "authors": "Tom Pan,Evan Dramko,Mitchell D. Miller,Anastasios Kyrillidis,George N. Phillips Jr", "background": "蛋白质结构确定一直是结构生物学的主要挑战之一，近年来基于深度机器学习（ML）的方法得到了越来越多的应用。然而，这些ML模型通常不直接整合实际的实验数据，例如X射线晶体学衍射数据。本文探索了一种方法，通过将传统的晶体学方法和近期的基于ML的方法更紧密地结合，训练一个3D视觉变换器和卷积网络混合模型，以更紧密地结合这两种领域的方法。作者利用两种不同的输入构造，即直接从晶体学数据中获得的Patterson图和从AlphaFold蛋白质结构数据库中预测的结构模板，通过去除某些残基的部分结构模板，来预测电子密度图并进行后处理以生成原子模型。这表明他们可以有效提高晶体学结构因子的相位，完成部分结构模板缺失的区域，同时提高电子密度图与真实原子结构的一致性", "innovation": "本文的主要创新在于结合传统晶体学方法和基于ML的方法，通过训练3D视觉变换器和卷积网络混合模型，利用直接从晶体学数据中获取的Patterson图和预测的部分结构模板来进行电子密度图的预测。此外，该方法能有效提高晶体学结构因子的相位和补全部分结构模板缺失的区域，并且能与真实的原子结构更好地匹配", "conclusion": "本文介绍的方法能够有效提升基于Patterson图直接或间接获取的晶体结构数据的相位，填补缺失的部分结构区域，同时还提高了预测的电子密度图与实际原子结构数据的一致性。这为蛋白质结构确定提供了一种新的思路和技术手段"}
{"llm_update_time": "20251116", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2511.10461", "html_url": "https://arxiv.org/abs/2511.10461", "title": "OpenSR-SRGAN：多光谱地球观测数据的灵活超分辨率框架", "title_en": "OpenSR-SRGAN: A Flexible Super-Resolution Framework for Multispectral Earth Observation Data", "authors": "Simon Donike,Cesar Aybar,Julio Contreras,Luis Gómez-Chova", "background": "在地球观测中，单图像超分辨率（SISR）是从低分辨率图像生成高分辨率图像的重要技术。SRGAN（超分辨率生成对抗网络）模型是实现这一目标的有效方法。然而，目前的SISR框架可能需要用户修改模型代码，限制了用户在不同场景中的灵活性。OpenSR-SRGAN提供了一个开放且模块化的框架，旨在简化这一过程，使得研究人员和实践者可以更容易地使用和比较SRGAN模型，特别是在多光谱卫星数据如Sentinel-2的处理中。", "innovation": "OpenSR-SRGAN的主要创新点在于其通过简洁的配置文件暴露了生成器、判别器、损失函数和训练策略，使得用户可以轻松地在不同的架构、缩放因子和波段设置之间切换，降低了研究人员和实践者的使用门槛。此外，该框架还包括了针对对抗训练的默认设置，并具有日志记录、验证和大规模场景推理的内置钩子，使其成为一个实用工具和基准实现，而不仅仅是最先进的模型。", "conclusion": "OpenSR-SRGAN通过将基于生成对抗网络的超分辨率处理转化为配置驱动的工作流程，极大地降低了研究人员和实践者的入门门槛，使他们能够进行模型实验、在可重复的方式下比较模型，并在多种地球观测数据集中部署超分辨率流水线。"}
{"llm_update_time": "20251116", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2501.02409", "html_url": "https://arxiv.org/abs/2501.02409", "title": "扰动下的可解释神经ODE模型在基因调控网络发现中的应用", "title_en": "Interpretable Neural ODEs for Gene Regulatory Network Discovery under Perturbations", "authors": "Zaikang Lin,Sei Chang,Aaron Zweig,Minseo Kang,Elham Azizi,David A. Knowles", "background": "现代生物学高通量数据集提供了大规模发现基因因果图的机会，这些图可以代表基因之间的调控关系。已有的可微分因果图形模型试图从大规模干预数据集中推断基因调控网络（GRN），但这些模型在表达能力和扩展性方面有限，并且无法处理如细胞分化等生物学过程的动态性质。", "innovation": "我们提出了PerturbODE，一个结合生物学信息的神经常微分方程模型的新框架，用于建模扰动下的细胞状态轨迹，并从神经常微分方程的参数中推导因果GRN。PerturbODE在模拟和实际过表达数据集中的轨迹预测和GRN推断方面表现出色。", "conclusion": "PerturbODE在扰动下的基因调控网络发现中展示了其在轨迹预测和GRN推断中的有效性和优越性。"}
{"llm_update_time": "20251116", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2404.02629", "html_url": "https://arxiv.org/abs/2404.02629", "title": "Effector：一个用于区域解释的Python包", "title_en": "Effector: A Python package for regional explanations", "authors": "Vasilis Gkolemis,Christos Diou,Dimitris Kyriakopoulos,Konstantinos Tsopelas,Julia Herbinger,Hubert Baniecki,Dimitrios Rontogiannis,Loukas Kavouras,Maximilian Muschalik,Theodore Dalamagas,Eirini Ntoutsi,Bernd Bischl,Giuseppe Casalicchio", "background": "传统的全局效应方法，如部分依赖图（PDP）和累积局部效应（ALE），广泛用于解释基于表格数据训练的机器学习模型，因为它们简单易懂，能够通过单一的一维图表汇总每个特征对预测值的平均影响。然而，当特征之间存在相互作用时，全局效应可能会误导解释。针对这一问题，区域效应通过将输入空间划分为互作用最小的不同区域，并在每个区域中计算单独的局部效应来提供解决方案。区域效应通过一系列关于各个特征的一维图表来可视化。", "innovation": "Effector提供了一种高效实现最先进的全局和区域效应方法的统一API，其模块化和可扩展的设计使其能够无缝整合到主流机器学习库中，如scikit-learn和PyTorch，并且附带了全面的文档和教程。Effector是一个开源项目，托管在GitHub上。", "conclusion": "Effector作为一个专注于区域效应解释的Python包，为用户提供了一种理解和解释复杂机器学习模型的新方法，其高效和模块化的特性使得用户能够轻松地将其集成到自己的项目中。"}
{"llm_update_time": "20251116", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2502.19611", "html_url": "https://arxiv.org/abs/2502.19611", "title": "PRDP: 进一步细化的可微物理", "title_en": "PRDP: Progressively Refined Differentiable Physics", "authors": "Kanishk Bhatia,Felix Koehler,Nils Thuerey", "background": "物理求解器通常用于神经网络训练是迭代的，这随着迭代次数增加会引入严重的计算负担。现有的可微物理方法需要完全收敛的求解器来达到全精度，这大大增加了计算开销。本文借鉴二阶优化中的相关工作，提出通过比完全收敛求解器更粗的物理方法也可以实现全精度的网络训练。", "innovation": "本文提出了一种名为Progressively Refined Differentiable Physics (PRDP)的方法，该方法可以在训练过程中逐步细化物理求解器的精度，以减少计算开销而不牺牲网络精度。这种方法适用于稀疏离散差分算子的迭代线性求解器，也适用于展开求解和隐式求解。", "conclusion": "实验结果表明，PRDP在多种涉及可微物理求解器的学习场景中表现出良好的性能。在模拟Navier-Stokes方程的复杂案例中，训练时间减少了62%，证明了该方法的有效性。"}
{"llm_update_time": "20251116", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2412.12837", "html_url": "https://arxiv.org/abs/2412.12837", "title": "通过图混合视角揭示分布式学习对成员推断攻击的脆弱性", "title_en": "Exposing the Vulnerability of Decentralized Learning to Membership Inference Attacks Through the Lens of Graph Mixing", "authors": "Ousmane Touat,Jezekael Brunon,Yacine Belal,Julien Nicolas,César Sabater,Mohamed Maouche,Sonia Ben Mokhtar", "background": "分布式学习的主要优点是允许用户在其本地保持数据的同时协作训练机器学习模型，而无需依赖任何中央实体。然而，这种模式需要在参与者之间交换模型参数或梯度，这可能会被利用来推断训练数据中的敏感信息，这被称为隐私攻击（如成员推断攻击--MIA）。为了设计有效的防御机制，理解特定分布式学习架构对MIA的脆弱性至关重要。本研究探讨了各种分布式学习架构对MIA的脆弱性，通过改变图结构（如邻居数量）、图动力学和聚合策略，以及在不同数据集和数据分布下进行广泛研究。研究发现，分布式学习架构对MIA的脆弱性与节点接收到相邻节点模型后的局部模型混合策略以及通信图的全局混合属性高度相关。", "innovation": "研究表明，分布式学习架构对MIA的脆弱性主要与节点接收到相邻节点模型后的局部模型混合策略以及通信图的全局混合属性高度相关。这是一个新颖的发现，之前的文献中没有报道。此外，研究还证明增强混合特性与差分隐私等其他隐私保护技术结合时，效果显著提升。", "conclusion": "论文从设计上提供了一组减少分布式学习系统对MIA的脆弱性的教训。这些发现对于构建具有固有抵抗MIA能力的分布式学习系统至关重要。"}
{"llm_update_time": "20251116", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2410.20749", "html_url": "https://arxiv.org/abs/2410.20749", "title": "Matryoshka Pilot: 使用 LLM 控制黑盒 LLM", "title_en": "Matryoshka Pilot: Learning to Drive Black-Box LLMs with LLMs", "authors": "Changhao Li,Yuchen Zhuang,Rushi Qiang,Haotian Sun,Hanjun Dai,Chao Zhang,Bo Dai", "background": "尽管黑盒大型语言模型（LLM）展示了令人印象深刻的生成能力，但其固有的不透明性阻碍了进一步提升如推理、计划和个人化等能力的空间。现有工作主要通过领域特定的适应来增强LLM的能力，这需要额外针对模型的参数进行训练，而这一选项对于黑盒LLM来说是不可行的。为解决这一挑战，本文提出了Matryoshka Pilot（M-Pilot），一种轻量级的白盒LLM控制器，通过将复杂任务分解为一系列中间输出来引导大规模黑盒LLM生成模型。作者将黑盒LLM视为环境，M-Pilot则作为策略通过提示来为驱动黑盒LLM提供中间指导。M-Pilot在迭代交互中被训练以调整黑盒LLM的输出以符合偏好，从而使多轮生成可控并优化中间指导，适用于复杂的长期任务。", "innovation": "提出了一种名为Matryoshka Pilot（M-Pilot）的轻量级白盒LLM控制器，可以通过将复杂任务分解为一系列中间输出来引导黑盒LLM生成模型。M-Pilot被训练以调整黑盒LLM的输出以符合偏好，从而实现多轮生成的可控性和优化中间指导。在多样化的任务上进行了实证评估，证明了该方法有效提升了黑盒LLM在复杂、长期任务中的能力。", "conclusion": "实证评估表明，该方法有效提升了黑盒LLM在复杂且长期的任务中的能力。M-Pilot已在公开可用的代码库中提供，地址为：this https URL。"}
{"llm_update_time": "20251116", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2404.13879", "html_url": "https://arxiv.org/abs/2404.13879", "title": "Lipschitz-正则化批评者导致针对转换动力学不确定性策略的鲁棒性", "title_en": "Lipschitz-Regularized Critics Lead to Policy Robustness Against Transition Dynamics Uncertainty", "authors": "Xulin Chen,Ruipeng Liu,Zhenyu Gan,Garrett E. Katz", "background": "在强化学习（RL）中，过渡动态的不确定性是对策略性能提出关键挑战的因素。许多鲁棒RL方法采用两种策略：对演员或演员-批评家模块施加Lipschitz正则化以实现平滑度，或学习鲁棒贝尔曼算子。然而，第一种策略未研究批评家仅Lipschitz正则化对策略鲁棒性的影响，而第二种策略缺乏现实世界的全面验证。面对这些局限性，本文研究了Lipschitz-正则化批评者和策略鲁棒性之间的关系。", "innovation": "本文提出了PPO-PGDLC算法，结合投影梯度下降（PGD）与Lipschitz正则化的批评者（LC），以解决上述问题。PGD部分计算了不确定性集内的对抗状态以近似鲁棒贝尔曼算子，而Lipschitz-正则化的批评者进一步提高了学到的策略的平滑性。", "conclusion": "实验结果表明，PPO-PGDLC在两个经典控制任务和一个真实世界的机器人行走任务中，在与几种基线算法的对比中，取得了更好的性能，并且预测了在环境变化下的更平滑的行动。"}
{"llm_update_time": "20251116", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2409.17806", "html_url": "https://arxiv.org/abs/2409.17806", "title": "Caption, Create, Continue: Continual Learning with Pre-trained Generative Vision-Language Models", "title_en": "Caption, Create, Continue: Continual Learning with Pre-trained Generative Vision-Language Models", "authors": "Indu Solomon,Aye Phyu Phyu Aung,Uttam Kumar,Senthilnath Jayavelu", "background": "连续学习（CL）允许模型适应不断变化的数据流，而无需灾难性遗忘，这是现实世界AI系统的基本要求。然而，当前方法常常依赖于大型重演缓冲区或高度注释的数据集，由于存储、隐私和成本的限制，这些是不切实际的。", "innovation": "CLTS（连续学习通过文本-图像协同作用），一种新颖的类别递增框架，能够在不存储真实任务数据的情况下缓解遗忘。CLTS 利用了预训练的视觉语言模型 BLIP（Bootstrapping Language-Image Pre-training）进行描述生成和稳定扩散进行样本生成。每个任务由一个专门的任务头处理，而任务路由器则学习使用生成的数据将输入分配给正确的任务头。在三个基准数据集上，CLTS 将平均任务精度提高了最高54%，并且与四个最近的连续学习基线相比，其内存效率提高了63倍，显示出更好的保留和适应性。CLTS 通过集成生成的文本-图像增强为可扩展的连续学习引入了一个新的视角。", "conclusion": "CLTS 在平均任务准确性和内存效率方面显著优于现有方法，展示了改进的记忆保留和适应性，同时也为可扩展的连续学习提供了一个新的视角。"}
{"llm_update_time": "20251116", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2502.10784", "html_url": "https://arxiv.org/abs/2502.10784", "title": "预不精确随机ADMM算法在深度模型训练中的应用", "title_en": "Preconditioned Inexact Stochastic ADMM for Deep Model", "authors": "Shenglong Zhou,Ouya Wang,Ziyan Luo,Yongxu Zhu,Geoffrey Ye Li", "background": "基础模型（FMs）的进步带来了一场范式的转变，极大地改变了各个领域。当前流行的训练这些模型的优化器是基于随机梯度下降的算法，但它们存在局限性，如收敛速度慢和对收敛的严格假设条件。特别是，分布式环境中存在的数据异质性对这些优化器的理论和数值性能提出了巨大挑战。为应对这些挑战，该论文开发了一种算法，称为PISA（预条件不精确随机交替方向乘子法），该算法仅依赖于梯度在有界区域内Lipschitz连续这一假设，在此基础上保证了收敛性。", "innovation": "PISA算法可以有效应对数据异质性挑战，归功于它独特的架构支持并行计算。同时，该算法允许使用多种预条件，如第二阶信息、二次矩和通过Newton-Schulz迭代进行正交化动量，这两种预条件被整合到算法中，产生高效的SISA和NSISA两种变体。实验结果表明，这两种变体在训练或微调包括视觉模型、大型语言模型、强化学习模型、生成对抗网络和循环神经网络等多样化深度模型方面，相比当前最先进的优化器表现更出色。", "conclusion": "该论文通过提出PISA算法，不再需要传统随机方法所需的多种条件，并且展示出在处理数据异质性时的优越表现。实验结果证明了SISA和NSISA在各种深度模型训练或微调中具有更优秀的数值性能，进一步验证了该算法的有效性。"}
{"llm_update_time": "20251116", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2501.02808", "html_url": "https://arxiv.org/abs/2501.02808", "title": "DarkFarseer：在图稀疏性和噪声下的鲁棒时空克里金法", "title_en": "DarkFarseer: Robust Spatio-temporal Kriging under Graph Sparsity and Noise", "authors": "Zhuoxuan Liang,Wei Li,Dalin Zhang,Ziyu Jia,Yidan Chen,Zhihong Wang,Xiangping Zheng,Moustafa Youssef", "background": "随着互联网物联网和网络物理系统的迅速增长，广泛部署传感器变得至关重要。然而，构建传感器网络的高成本限制了其规模和覆盖范围，使得精确部署变得困难。传统克里金插值方法通过引入虚拟传感器来缓解这一问题。基于图神经网络（GNNs）提取物理和虚拟传感器之间的关系，ISK可以从物理传感器推断虚拟传感器的测量值。然而，当前的ISK方法依赖于传统消息传递机制和网络架构，不能有效地提取物理传感器的空间-时间特征，且未重点表示虚拟传感器。现有的图构建方法还存在连接稀疏且噪声较大的问题，影响了ISK的性能", "innovation": "为解决上述问题，本文提出了DarkFarseer，一个新型的ISK框架，包含三个关键组件：首先，提出了邻居隐藏样式增强模块，采用样式转换策略以时间-空间的方式增强虚拟节点的表示，以便更好地提取物理和虚拟节点之间的空间关系；其次，提出了虚拟组分对比学习，通过虚拟节点模式和图组件内的区域模式之间的关联，丰富节点表示；最后，设计了一种基于相似性的图去噪策略，根据时间信息和区域空间模式，减少围绕虚拟节点及其邻居的噪声连接强度。实验证明，DarkFarseer在各种测试中显著优于现有的ISK方法", "conclusion": "通过采用样式转换策略、虚拟组分对比学习和基于相似性的图去噪策略，DarkFarseer显著提高了在图稀疏性和噪声下的时空克里金性能"}
{"llm_update_time": "20251116", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2405.07914", "html_url": "https://arxiv.org/abs/2405.07914", "title": "分布学习与图结构采样相交", "title_en": "Distribution Learning Meets Graph Structure Sampling", "authors": "Arnab Bhattacharyya,Sutanu Gayen,Philips George John,Sayantan Sen,N. V. Vinodchandran", "background": "该研究建立了一种连接聚类一致学习高维图形模型问题与高效图形结构计数与采样任务的新纽带，使用了在线学习框架。通过EWA或RWM预测器对分布P的序列样本应用，并使用对数损失函数，可以利用预测者预测平均遗憾来界定向量之间的预期KL分散。已知的遗憾边界为EWA和RWM带来了学习贝叶斯网络的新样本复杂度边界。这些算法还为树的未知结构和贝叶斯网络的给定共边骨架提供了有效的计算方法。特别是，给出了基于未知结构树的采样的新样本最优且多项式时间学习算法，以及学习给定共边骨架上的贝叶斯网络的第一个多项式样本和时间算法。", "innovation": "该工作通过在线学习框架，将聚类一致学习高维图形模型问题与高效图形结构计数与采样任务联系起来，并利用EWA和RWM预测器提供了学习贝叶斯网络的新样本复杂度边界。此外，还为一些有趣的贝叶斯网络类提供了高效计算方法，具体包括基于未知结构树的采样的新样本最优且多项式时间学习算法，以及基于给定共边骨架的贝叶斯网络学习的第一个多项式样本和时间算法。", "conclusion": "该方法不仅能够显著优化贝叶斯网络的学习复杂度，还能够针对特定类型的贝叶斯网络（尤其是基于未知结构的树和给定共边骨架的网络）提供高效的计算方案。"}
{"llm_update_time": "20251116", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2503.07961", "html_url": "https://arxiv.org/abs/2503.07961", "title": "提升节点分类的增强重叠元学习注意力以增强超图神经网络", "title_en": "Overlap-aware meta-learning attention to enhance hypergraph neural networks for node classification", "authors": "Murong Yang,Shihui Ying,Yue Gao,Xin-Jian Xu", "background": "虽然超图神经网络（HGNNs）已经成为了分析复杂数据集的强大框架，但它们的实际性能仍然受到限制。现有网络采用单一类型的关注机制，侧重于结构或特征相似性。假设所有节点在当前超图模型中的重叠程度相同可能会影响模型的泛化能力。", "innovation": "作者提出了一种新的框架，超图交注意力元学习（OMA-HGNN），它包括：1. 一种同时考虑结构和特征相似性的超图注意力机制；2. 根据节点不同的重叠层级对节点进行任务划分，并开发多任务Meta-Weight-Net（MWN）来确定相应的权重因子；3. 联合训练内部MWN模型与外部HGNN模型的损失以及使用内部模型的权重因子来训练外部模型。", "conclusion": "OMA-HGNN在六种实际数据集上的实验表明，它在学习更优节点表示方面表现优异，并超越了九种最先进的节点分类方法。"}
{"llm_update_time": "20251116", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.22712", "html_url": "https://arxiv.org/abs/2506.22712", "title": "Transformer模型的广义线性模式连通性", "title_en": "Generalized Linear Mode Connectivity for Transformers", "authors": "Alexander Theus,Alessandro Cabodi,Sotiris Anagnostidis,Antonio Orvieto,Sidak Pal Singh,Valentina Boeva", "background": "理解神经网络损失景观的几何结构是深度学习中的关键问题，与模型的泛化能力和优化过程密切相关。之前的研究主要是关注神经元重排通过置换，但这些方法的范围有限，并且无法捕捉现代架构如transformer所展示的更丰富的对称性。", "innovation": "本研究介绍了统一的框架来捕捉四种对称类——置换、半置换、正交变换和一般的可逆映射——极大地扩展了有效的重参数化范围，并将许多先前的方法作为特例包含进来。这一推广使得首次能够在独立训练的视觉transformer和gpt-2模型之间发现低或零障碍线性插值路径。此外，该框架不仅限于一对一的对齐，还扩展到多模型和宽度异构设置，能够在不同大小的架构之间实现对齐。", "conclusion": "这些结果揭示了损失景观中的更深层次结构，并强调了对称性意识分析对于理解模型空间几何结构的重要性。"}
{"llm_update_time": "20251116", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.00718", "html_url": "https://arxiv.org/abs/2508.00718", "title": "使用开源合成数据SDK实现表格数据的民主化", "title_en": "Democratizing Tabular Data Access with an Open$\\unicode{x2013}$Source Synthetic$\\unicode{x2013}$Data SDK", "authors": "Ivona Krchova,Mariana Vargas Vieyra,Mario Scriminaci,Andrey Sidorenko", "background": "机器学习的发展高度依赖高质量的数据，然而，由于隐私、专有利益和伦理问题的限制，数据的获取变得困难。合成数据通过在不泄露敏感信息的情况下安全广泛地使用数据提供了一个可行的解决方案。尽管如此，市场上目前并没有专门针对高质量表格数据合成的开源工具包，尤其是在支持自动质量保证和公平性数据生成方面。", "innovation": "该论文提出了MOSTLY AI的合成数据软件开发工具包（SDK），这是一种开源工具，专门设计用于合成高质量的表格数据。该SDK通过集成差分隐私保证、公平性数据生成和自动化质量保证等功能，提供了一个灵活且易于使用的Python接口。该SDK使用TabularARGN自回归框架支持多种数据类型和复杂的多表和序列数据集，具有竞赛级别的性能，在速度和易用性方面表现出显著改进。", "conclusion": "该SDK不仅作为一个云服务还支持本地安装，并已快速被采纳，证明其在应对实际数据瓶颈和推动数据民主化方面的实用性。"}
{"llm_update_time": "20251116", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.11836", "html_url": "https://arxiv.org/abs/2507.11836", "title": "HyperEvent：通过相对结构编码实现动态链接预测的强基线", "title_en": "HyperEvent: A Strong Baseline for Dynamic Link Prediction via Relative Structural Encoding", "authors": "Jian Gao,Jianshe Wu,JingYi Ding", "background": "连续时间动态图的表示学习对于动态链接预测至关重要。虽然最近的方法变得越来越复杂，但领域内缺乏一个强而有信息量的基准来可靠地衡量进展。", "innovation": "本文提出了HyperEvent，这是一种简单的方法，通过直观的编码机制捕捉事件序列中的相对结构模式。HyperEvent利用相对结构编码识别有意义的事件序列，无需复杂参数化。通过结合可解释特征和轻量级变压器分类器，使链接预测成为事件结构识别。", "conclusion": "尽管简单，但HyperEvent在多个基准测试中取得了竞争力的结果，经常与更复杂模型的性能持平。这项工作展示了有效的建模可以通过简单的结构编码实现，并为评估未来进展提供了清晰的基准点。"}
{"llm_update_time": "20251116", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.02364", "html_url": "https://arxiv.org/abs/2508.02364", "title": "一种新颖的切片融合广义维谢茨距离", "title_en": "A Novel Sliced Fused Gromov-Wasserstein Distance", "authors": "Moritz Piening,Robert Beinert", "background": "广义维谢茨（GW）距离和其融合扩展（FGW）是用于对比不同形态数据的强大工具。然而，由于它们基于非凸的二次最优运输（OT）问题，计算这些距离具有挑战性。尽管存在利用一维OT减少计算负担的切片版本GW，但由于这种切片版本仅适用于欧几里得几何并且丧失了等距不变性，导致实际应用受限。", "innovation": "作者提出了针对GW和FGW的新颖切片技术，该技术基于适当的下界、层次最优运输和一维OT问题的合适积分规则。这种新型切片FGW在保持等距不变性的同时，大幅度减少了数值计算工作，能够比较任意几何结构。此外，该方法避免了潜在的二次程序，使其在物体检索和图同构测试方面相较于原GW和FGW距离更加稳健可靠，并且其定义为结构化空间的伪度量，连接了切片沃尔特斯坦距离和GW之间的问题插值特性。", "conclusion": "通过这种方法，新定义的距离不仅在计算上更为稳健可靠，而且在结构化空间方面得到了有理保证。此外，该方法在形状检索和图同构测试等应用中表现出了明显的优势。"}
{"llm_update_time": "20251116", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.14882", "html_url": "https://arxiv.org/abs/2507.14882", "title": "控制领域中基于软系数优化的深度神经网络应用特定组件感知结构化剪枝", "title_en": "Application-Specific Component-Aware Structured Pruning of Deep Neural Networks in Control via Soft Coefficient Optimization", "authors": "Ganesh Sundaram,Jonas Ulmen,Amjad Haider,Daniel Görges", "background": "DNNs提供了灵活性和稳健的性能，使其非常适合构建系统模型和高级神经网络控制器（NNCs）。但由于它们的高复杂性和计算需求，通常限制了它们的使用。在过去几十年中，开发了各种模型压缩策略来解决这些问题，但这些策略主要适用于一般DNNs，而不直接适用于NNCs。NNCs需要减少尺寸的同时保留关键的应用特定性能特性。在结构化剪枝中，标准的重要性度量往往无法保护这些关键特性，因此该研究引入了一种新的框架来计算剪枝组的重要度量，该框架不仅减少了模型大小，而且还考虑了各种应用特定的约束。通过网格搜索和梯度下降优化两种方法来找到每个组的最佳剪枝系数，以平衡压缩和任务性能。研究结果表明，该方法能有效保持应用相关的性能，同时大幅减少模型大小。", "innovation": "本文提出了一个新颖的框架，用于计算剪枝组的重要性度量，该框架不仅减少了模型大小，还考虑了各种应用特定的约束，并通过网格搜索和梯度下降优化两种方法来找到最佳剪枝系数，以平衡压缩和任务性能。提出了软系数优化方法来处理控制领域的应用特定组件感知的结构化剪枝问题，这是对现有压缩策略的有效补充，并提高了控制器的实际应用效果。", "conclusion": "研究在MNIST自动编码器和时间差分模型预测控制（TDMPC）代理中测试了该方法，结果表明，该方法在缩小模型大小的同时有效地保持了应用相关的性能。"}
{"llm_update_time": "20251116", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.01720", "html_url": "https://arxiv.org/abs/2509.01720", "title": "Succeed or Learn Slowly: Sample Efficient Off-Policy Reinforcement Learning for Mobile App Control", "title_en": "Succeed or Learn Slowly: Sample Efficient Off-Policy Reinforcement Learning for Mobile App Control", "authors": "Georgios Papoudakis,Thomas Coste,Jianye Hao,Jun Wang,Kun Shao", "background": "在使用基础模型进行策略逼近的多轮任务中，强化学习（RL）依然面临挑战，特别是在稀疏奖励设置和策略梯度更新方面。研究发现，正样本的更新通常不需要策略正则化，而负样本则可能影响模型性能。因此，需要一种新的off-policy RL算法来提高样本效率，减少对计算资源的需求，并且在不同任务中保持高性能。", "innovation": "提出了一种新的off-policy RL算法SoLS（Succeed or Learn Slowly），通过调整的off-policy演员-评论家方法，使用直接策略更新处理正样本，而保守地更新负样本以避免模型性能下降。此外，通过引入成功的过渡重放（STR）策略，SoLS进一步提高了样本效率。SoLS在AndroidWorld基准测试中表现突出，相比现有方法（至少17%的相对提升）所需计算资源大幅减少，并且速度快5-60倍。", "conclusion": "SoLS算法在移动应用控制任务中显著提高了样本效率，超出了对比方法的预期表现，且计算资源占用少，提高了学习效率。"}
{"llm_update_time": "20251116", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.03210", "html_url": "https://arxiv.org/abs/2508.03210", "title": "确定性和随机扩散模型采样器的收敛性：Wasserstein距离中的简单分析", "title_en": "Convergence of Deterministic and Stochastic Diffusion-Model Samplers: A Simple Analysis in Wasserstein Distance", "authors": "Eliot Beyler(SIERRA),Francis Bach(SIERRA)", "background": "本文提供了扩散生成模型在Wasserstein距离下收敛的新保证，涵盖了随机（如DDPM）和确定性（如DDIM）的采样方法。文章介绍了一种简单的框架来分析离散化、初始化和评分估计误差。该研究强调了学习评分函数的空间正则性的重要性，并提出了控制评分误差相对于真实逆过程的方法，这与去噪评分匹配一致。同时，它还结合了关于光滑的Wasserstein距离的最新结果，以细化初始化误差边界。", "innovation": "1. 提供了扩散生成模型的Wasserstein距离收敛的新保证，覆盖了随机和确定性采样方法。\n2. 引入了一种简单的框架来分析离散化、初始化和评分估计误差。\n3. 得到了Heun采样器的第一个Wasserstein收敛界，并改进了概率流动ODE的Euler采样器的现有结果。\n4. 强调了学习评分函数的空间正则性的重要性，并提出了控制评分误差相对于真实逆过程的方法。\n5. 结合了光滑的Wasserstein距离的最新结果，来细化初始化误差边界。", "conclusion": "本文的研究结果突显了空间正则性在学习评分函数中的重要性，提出了一种基于真实逆过程的评分误差控制方法，并通过引入光滑的Wasserstein距离来改进初始化误差边界。这些贡献为理解扩散模型的稳定性提供了新的见解。"}
{"llm_update_time": "20251116", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.22837", "html_url": "https://arxiv.org/abs/2506.22837", "title": "xLSTMAD：基于xLSTM的方法在异常检测中的强大能力", "title_en": "xLSTMAD: A Powerful xLSTM-based Method for Anomaly Detection", "authors": "Kamil Faber,Marcin Pietroń,Dominik Żurek,Roberto Corizzo", "background": "xLSTM 是一种利用表达性强的乘法门控和残差连接的模型，提供了长时序预测和表示学习所需的时序容量。该架构已证明在时间序列预测、无损压缩和大规模语言建模任务中取得成功，其线性内存占用和快速推理使得它成为 Transformer 的可行替代品。尽管 xLSTM 日益受欢迎，但之前没有将其用于异常检测的工作。因此，本研究填补了这个空白，提出了一种名为 xLSTMAD 的新的多变量时间序列异常检测方法。", "innovation": "本研究首次将 xLSTM 用于异常检测，通过构建一个完整的编码器-解码器 xLSTM 架构应用于多变量时间序列数据。该方法在解码器中采用两种变体，一种是预测未来值 xLSTMAD-F 的方法，一种是基于编码反向重构输入时间序列 xLSTMAD-R 的方法。通过比较两种损失函数（均方误差 MSE 和软动态时间卷积 SoftDTW）以评估局部重构准确性和全局序列对齐。此方法在 TSB-AD-M 基准上进行了评价，该基准涵盖了 17 个真实世界的数据集，使用先进的评估指标 VUS-PR。实验结果表明 xLSTM 具有最先进的准确率，优于 23 个流行的异常检测基准，并揭示了 xLSTM 在异常检测中的强大建模能力。", "conclusion": "研究结果表明 xLSTMAD 在异常检测中表现出色，为这一研究领域开辟了新的发展方向。该研究提供了 xLSTM 在多变量时间序列异常检测中的强大能力，并且其代码公开可供进一步研究使用。"}
{"llm_update_time": "20251116", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.08605", "html_url": "https://arxiv.org/abs/2507.08605", "title": "面向可持续水稻生产的机器学习：监测印度旁遮普邦节水耕作的地区规模", "title_en": "Machine Learning for Sustainable Rice Production: Region-Scale Monitoring of Water-Saving Practices in Punjab, India", "authors": "Ando Shah,Rajveer Singh,Akram Zaytar,Girmaw Abebe Tadesse,Caleb Robinson,Negar Tafti,Stephen A. Wood,Rahul Dodhia,Juan M. Lavista Ferres", "background": "水稻种植为全球一半人口提供主食，同时也是淡水消耗的主要驱动因素，约占全球淡水消耗的四分之一，并且占耕地温室气体排放的约48%。在地下水位急剧下降的地区，如印度旁遮普邦，节约用水的水稻种植实践至关重要。直接播种水稻（DSR）和交替湿润和排水（AWD）可以减少20-40%的灌溉用水，而不影响产量。然而，由于缺少灌溉的做法数据，有效的适应政策和气候行动受到阻碍。", "innovation": "本文提出了一种机器学习框架，通过使用Sentinel-1卫星图像大规模监测可持续水稻耕作。通过与农艺专家和大规模农民培训计划合作，作者从旁遮普邦的1400个田地获得了实况数据，并开发了一种新颖的维度分类方法，该方法独立分析播种和灌溉实践，仅使用Sentinel-1卫星图像分别达到了0.8和0.74的F1分数。解释性分析表明，DSR分类的稳健性较高，而AWD分类主要依赖于种植时间表的不同。", "conclusion": "将该模型应用于300万块田地揭示了各邦在节水耕作方面的地域性差异，有助于政策的针对性。区级采用率与政府估计高度相关（Spearman's ρ=0.69，Rank Biased Overlap=0.77）。此研究为政策制定者和可持续发展计划提供了一个强大的工具，用于监测实践采用情况、指导针对性介入，并驱动区域规模的节水和气候缓解的数据驱动政策。"}
{"llm_update_time": "20251116", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.02909", "html_url": "https://arxiv.org/abs/2507.02909", "title": "通过操作修剪实现精细的token分配以提高高效MLLMs", "title_en": "Fine-grained Token Allocation Via Operation Pruning for Efficient MLLMs", "authors": "Aoming Liu,Reuben Tan,Boqing Gong,Bryan A. Plummer", "background": "目前，多模态大型语言模型（MLLMs）通过减少多余token的处理来加速，但忽视了结构性冗余差异。在关键和冗余模块下，处理的token负载是相同的。为了精细控制计算量，引入了一个新的定义来说明“操作”是在一个模块中对一组token进行的计算，并在此基础上提出了操作修剪框架，使得模块能够有选择地处理token。基于这个框架，本文提出了深度操作修剪（DOP）方法。该方法是一个数据驱动的策略搜索方法，用于修剪冗余操作并为关键模块节省计算资源，同时尽可能保持与原始模型输出概率分布的一致性，满足计算约束条件。为了有效的优化，DOP采用了深度修剪来减少策略空间，并使用加法近似来减少所需的验证次数。DOP通过模块类型和token组将操作分层，并在每个模块组内先修剪深层操作再修剪浅层操作。加法近似通过独立改变每个策略参数获得单个偏离值，然后将这些值相加以近似所有策略参数同时改变的联合偏离值，从而将所需的验证次数从指数级减少到线性级。", "innovation": "提出了一种深度操作修剪（DOP）方法，这是一种基于数据驱动的修剪方法，通过搜索策略来修剪冗余操作，为关键模块节省计算资源，并通过最小化与原始模型输出概率分布的最大偏差来优化模型，同时满足计算约束条件。此外，通过深度修剪操作并在每个模块组中先修剪深层操作再修剪浅层操作来优化策略空间，使用加法近似进一步减少计算验证次数，提高优化效率。", "conclusion": "DOP在这项研究中表现出色，证明了其在6个MLLMs和13个基准测试中超越了12个基线的新最先进的性能。在LLaVA-Next-7B模型上，DOP与原始模型相比实现了86%的TFLOPS减少和83%的延迟减少，同时仅损失了1%的性能。通过广泛的消融研究，进一步证明了DOP在数据和时间效率以及泛化能力上的优势。"}
{"llm_update_time": "20251116", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.11816", "html_url": "https://arxiv.org/abs/2509.11816", "title": "避免有害和无害能力混淆的代表性分隔确保语言模型的稳健且不破坏性遗忘", "title_en": "Collapse of Irrelevant Representations (CIR) Ensures Robust and Non-Disruptive LLM Unlearning", "authors": "Filip Sondej,Yushi Yang", "background": "当前的卸载和安全培训方法无法有效从语言模型中清除危险知识。研究表明，卸载目标过于宽泛，这些宽泛的目标未能精确进行卸载操作。因此，迫切需要开发一种既能有效卸载特定知识又能保持模型总体性能的新方法。", "innovation": "本文提出了一种新的技术，即不可选代表性坍缩(Collapse of Irrelevant Representations，CIR)，该技术通过对激活和模块输出梯度进行PCA（主成分分析），识别包含常见表示的子空间，然后压缩这些子空间，从而计算卸载更新。这种方法针对特定待卸载的事实，仅消除特定知识的相关表示，避免了卸载一般性知识。在实验中，CIR 在去除 Llama-3.1-8B 中涉及生物和网络安全知识时，相比现有最佳方法（Circuit Breakers）减少了30倍对整体性能的负面影响，同时仅花费不到3个GPU秒即可处理一个事实。", "conclusion": "通过在表现层面上将有害与无害的能力解耦，CIR 使卸载操作变得既稳健又不破坏性，证明了其在安全语言模型训练中的有效性和可行性。"}
{"llm_update_time": "20251116", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.04449", "html_url": "https://arxiv.org/abs/2509.04449", "title": "ChronoGraph：基于现实世界的图结构多变量时间序列数据集", "title_en": "ChronoGraph: A Real-World Graph-Based Multivariate Time Series Dataset", "authors": "Adrian Catalin Lutu,Ioana Pintilie,Elena Burceanu,Andrei Manolache", "background": "该研究基于真实的生产微服务构建了一个图结构的多变量时间序列预测数据集，每个节点代表一个服务，该服务发出多个系统级别性能指标的多变量流，包括CPU、内存和网络使用模式。边用于编码服务之间的依赖关系。主要任务是预测这些信号在服务级别未来值。此外，ChronoGraph提供了专家标注的事故窗口作为异常标签，这使得可以评估异常检测方法，并评估在运营中断期间预测的鲁棒性。与来自工业控制系统或交通和空气质量领域的现有基准相比，ChronoGraph独特地结合了(i)多变量时间序列，(ii)显式的、机器可读的依赖关系图，和(iii)与实际事件对齐的异常标签。", "innovation": "ChronoGraph 数据集创新地结合了多变量时间序列、明确的机器可读依赖图以及与实际事故对齐的异常标签。与其他现有的工业控制系统或交通和空气质量领域的基准相比，ChronoGraph 提供了更接近真实生产环境的数据，有助于研究结构感知预测和事故感知评估。", "conclusion": "本文报告了涵盖预测模型、预训练时间序列基础模型和标准异常检测器的基准结果。ChronoGraph 为研究微服务系统中的结构感知预测和事故感知评估提供了现实基准。"}
{"llm_update_time": "20251116", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.15674", "html_url": "https://arxiv.org/abs/2509.15674", "title": "边缘设备的敏感成本二分类推理卸载", "title_en": "Inference Offloading for Cost-Sensitive Binary Classification at the Edge", "authors": "Vishnu Narayanan Moothedath,Umang Agarwal,Umeshraja N,James Richard Gross,Jaya Prakash Champati,Sharayu Moharir", "background": "本文研究了一种边缘智能系统中的二分类问题，其中错误的负样本比错误的正样本更昂贵。系统包含一个紧凑的本地部署模型和一个更大的远程模型，后者可经由网络远程访问，但会带来卸载成本。针对每一批样本，系统首先利用本地模型进行推理，基于本地模型的输出决定是否将其卸载至远程模型以获得更高精度。该研究旨在理解在这种层级推理系统中的分类准确性和卸载成本之间的基本权衡，并提出了一种在线学习框架，通过不断调整本地模型置信度分数的阈值来优化系统。这一框架在可校准模型的场景下提供了一个闭式解，对于不具备校准的模型，则引入了H2T2策略，证明了其在次线性后悔上的表现，该策略不依赖于特定模型，无需训练，并在推理过程中通过有限反馈进行学习。实验结果表明，H2T2在真实数据集上表现优于简单和单一阈值的策略，并且在分布变化时表现出较强的鲁棒性，能有效适应分类器的不匹配情况。", "innovation": "本文提出了一个在线学习框架，该框架通过不断调整本地模型置信度分数的两个阈值来优化层级推理系统。尤其在不具备校准的模型场景中，引入了H2T2策略，并证明其在次线性后悔上的表现。该策略具有模型无关性，无需训练，能在有限反馈下进行学习，并且对于分布变化具有鲁棒性，能够有效适应分类器的不匹配情况。研究人员通过真实数据集的模拟展示了该策略的优势，其表现优于简单的单一阈值策略，有时甚至超出静态优化效果。", "conclusion": "本文通过研究低成本高效益的层级推理系统，提出了一个适用于校准和非校准模型的理论分析和策略。H2T2策略提供了强大的鲁棒性，可以适应模型与数据分布的变化。通过实验验证，H2T2策略在真实数据集上表现优异，提升了边缘设备的二分类推理效果。"}
{"llm_update_time": "20251116", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2511.09211", "html_url": "https://arxiv.org/abs/2511.09211", "title": "参数无参数聚类通过自我监督共识最大化", "title_en": "Parameter-Free Clustering via Self-Supervised Consensus Maximization (Extended Version)", "authors": "Lijun Zhang,Suyuan Liu,Siwei Wang,Shengju Yu,Xueling Zhu,Miaomiao Li,Xinwang Liu", "background": "聚类是无监督学习中的基本任务，但现有方法大多依赖于群集数量等超参数，这限制了它们在实际场景中的应用。", "innovation": "我们提出了一种新的无参数聚类框架，即通过自我监督共识最大化（SCMax），该框架将层次凝聚聚类和聚类评估集成在一个过程中。在每次聚合并过程中，它通过自我监督学习任务创建一个新的具有结构感知的数据表示，该任务由当前的聚类结构指导。我们介绍了一个最近邻共识评分，该评分衡量自监督决策与基于最近邻合并决策的一致性。共识最大化时刻可以作为确定最佳群集数量的标准。", "conclusion": "在多个数据集上的广泛实验表明，所提出的框架在未知群集数量的情况下优于现有聚类方法。"}
{"llm_update_time": "20251116", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2511.07938", "html_url": "https://arxiv.org/abs/2511.07938", "title": "预测-优化方法在港口动力物流调度中的应用：跨任务流的一般性", "title_en": "Predict-then-Optimize for Seaport Power-Logistics Scheduling: Generalization across Varying Tasks Stream", "authors": "Chuanqing Pu,Feilong Fan,Nengling Tai,Yan Xu,Wentao Huang,Honglin Wen", "background": "现代港口的电力物流调度通常遵循预测-优化的流程。为了提高预测决策的质量，已提出决策导向的学习方法，该方法使预测模型的训练与下游决策结果相匹配。然而，这种端到端的设计使得预测模型的价值局限于特定的任务结构，难以适应由于船舶到港多样化而引起的变化任务。", "innovation": "本文提出了一种决策导向的持续学习框架，该框架能够在线适应一系列调度任务流。具体来说，引入了基于Fisher信息的正则化方法来增强跨任务的一般性，并通过保留先前任务关键参数来保持模型状态。此外，还开发了一个可微凸近似方法以稳定梯度反向传播。", "conclusion": "实验结果证明，该方法能够在一系列变化的任务流中学习到决策导向的预测模型，并具有更优的决策性能和较好的泛化能力，同时计算成本较低。"}
{"llm_update_time": "20251116", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2405.13846", "html_url": "https://arxiv.org/abs/2405.13846", "title": "回归树掌握微积分", "title_en": "Regression Trees Know Calculus", "authors": "Nathan Wycoff", "background": "回归树因其处理非线性、交互效应和尖锐断点的能力而成为解决实际回归问题的主要工具。本文的研究对象是行为良好的、可微函数上的回归树，研究节点参数与所逼近函数局部梯度之间的关系。", "innovation": "本文提出了一种简单的梯度估计方法，该方法可以通过流行的树学习库中暴露的量有效计算。这种方法使得微分算法（如神经网络和高斯过程）开发的工具能够应用于基于树的模型。研究了用梯度的积分定义的模型灵敏度度量，并通过所提出的梯度估计计算了回归树中的这些指标。定量和定性的数值实验显示了通过回归树估计的梯度提升预测分析能力，解决不确定性量化任务，并提供对模型行为的解释。", "conclusion": "通过回归树估计的梯度能够改进预测分析，解决不确定性量化任务，并提供对模型行为的解释。"}
{"llm_update_time": "20251116", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2511.08655", "html_url": "https://arxiv.org/abs/2511.08655", "title": "学习基函数：嵌入格林函数先验的柯尔莫哥洛夫-阿诺尔德网络方法", "title_en": "Learning the Basis: A Kolmogorov-Arnold Network Approach Embedding Green's Function Priors", "authors": "Rui Zhu,Yuexing Peng,George C. Alexandropoulos,Wenbo Wang,Wei Xiang", "background": "方法矩（MoM）依赖于静态几何定义的基函数，如Rao-Wilton-Glisson（RWG）基。这类方法在电磁建模中存在局限，特别是基函数固定不变无法适应变化。本文从RWG基的功能出发，揭示了其实质上的局限性，并提出了一种新的学习基函数方法，即PhyKAN（物理导向的柯尔莫哥洛夫-阿诺尔德网络），旨在克服传统方法的不足。", "innovation": "PhyKAN是一种结合了GW模型先验的可学习和自适应基函数网络。从体积电位方程（EFIE）出发，PhyKAN设计了局部KAN分支和嵌入格林函数先验的全局分支，这样就能够在保持物理一致性的同时实现动态基函数的优化。", "conclusion": "PhyKAN方法在标准几何体上实现了小于0.01的重构误差，以及无监督的雷达截面预测，证明了其在电磁建模中从经典求解器过渡到现代神经网络模型的解释性和物理一致性。"}
{"llm_update_time": "20251116", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2401.10989", "html_url": "https://arxiv.org/abs/2401.10989", "title": "基于结构化变分族可证明可扩展的黑盒变分推断", "title_en": "Provably Scalable Black-Box Variational Inference with Structured Variational Families", "authors": "Joohwan Ko,Kyurae Kim,Woo Chang Kim,Jacob R. Gardner", "background": "在黑盒变分推断（BBVI）中，具有完整协方差近似的变分族已知表现不佳，无论是从实际实验结果还是理论角度来看。近期的计算复杂度研究表明，与均场族相比，完整协方差族在问题维度增加时会表现出较差的扩展性。对具有本地变量的分层贝叶斯模型尤其如此，其维度会随着数据集大小的增加而增加，导致迭代复杂度与数据集大小$N$呈现$O(N^2)$的显式依赖关系。", "innovation": "本研究探索了一种在均场族和完整协方差族之间的理论中间地带：结构化变分族。证明了一定的尺度矩阵结构可以使迭代复杂度达到$O(N)$，比$O(N^2)$有更好的$N$的扩展性。通过大规模分层模型的实验验证了理论结果的有效性。", "conclusion": "研究证明，特定结构化变分族可以实现更好的扩展性，适合大型分层模型的推断。"}
{"llm_update_time": "20251116", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2312.05654", "html_url": "https://arxiv.org/abs/2312.05654", "title": "谱方法在神经积分方程中的应用", "title_en": "Spectral methods for Neural Integral Equations", "authors": "Emanuele Zappala", "background": "神经积分方程是基于积分方程理论的深度学习模型，包含积分算子及其对应的方程（第二类），该方程是通过优化过程学习的。这种方法能够利用积分算子的非局部性质来改进机器学习，但计算成本较高。现有的神经积分方程方法虽然有效，但计算成本较高，降低了实际应用的效率和效果。本文旨在通过谱方法，学习算子的谱域表示，从而降低成本，同时提高插值精度。", "innovation": "本文引入了一种基于谱方法的神经积分方程框架，能够在频域中学习算子，从而降低了计算成本，并提高了插值精度。该方法还研究了方法的性质，并提供了关于模型逼近能力和数值方法解的收敛性的一些理论保证。通过数值实验验证了所提出模型的实用效果和有效性。", "conclusion": "本文提出了一种基于谱方法的神经积分方程框架，该框架在频域中学习算子，从而降低计算成本，并通过理论分析证明了模型的逼近能力和数值方法解的收敛性。实验结果表明，该方法在提高插值准确性和降低计算成本方面具有显著的效果。"}
{"llm_update_time": "20251116", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2511.09392", "html_url": "https://arxiv.org/abs/2511.09392", "title": "强大的但隐蔽的：通过分层约束强化范例重新思考针对序列推荐的模式污染", "title_en": "Potent but Stealthy: Rethink Profile Pollution against Sequential Recommendation via Bi-level Constrained Reinforcement Paradigm", "authors": "Jiajie Su,Zihan Nan,Yunshan Ma,Xiaobo Xia,Xiaohua Feng,Weiming Liu,Xiaolin Zheng,Chaochao Chen", "background": "序列推荐系统通过用户交互序列揭示动态用户意图，但这些系统容易受到恶意攻击。现有的攻击方法主要依赖数据污染，但这需要大量用户访问或假定身份，缺乏实际可行性。关注用户部分交互的模式污染攻击（Pattern Pollution Attack，PPA）虽然有效，但存在两个主要限制：一、对序列范围的过度依赖，限制了对项目转换的精细扰动；二、全面修改导致可检测的分布变化。为了克服这些挑战并提高攻击的效率和隐蔽性，本文提出了一种基于约束强化学习的攻击模型（CREAT），该模型通过结合双层优化框架和多奖励强化学习平衡了攻击的有效性和隐蔽性", "innovation": "提出了一个名为CREAT的约束强化驱动攻击，该方法通过结合双层优化框架和多奖励强化学习机制，旨在平衡攻击的有效性与隐蔽性。CREAT包含两个关键创新点：第一，开发了一种模式平衡奖励策略，该策略结合了模式反演奖励和分布一致性奖励，以反转关键模式并最小化可检测到的分布变化；第二，采用了受限分组相对强化学习框架，通过动态障碍约束和组内共享经验重播，实现了目标污染并最大限度地减少了检测可能性", "conclusion": "大量的实验表明CREAT方法的有效性，该方法在提高攻击的有效性的同时，显著提高了隐蔽性。"}
{"llm_update_time": "20251116", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2511.08946", "html_url": "https://arxiv.org/abs/2511.08946", "title": "使用normalizing flows进行条件VAE改进", "title_en": "Improving Conditional VAE with approximation using Normalizing Flows", "authors": "Tuhin Subhra De", "background": "变分自编码器（VAE）和生成对抗网络（GAN）长期以来一直是生成模型的领先方法，直到2022年才被基于扩散的模型取代。传统的模型改进努力已趋于停滞。在传统的做法中，我们通过条件变分自编码器（CVAE）探索图像生成，以在图像中加入所需的属性。但由于VAE通常会产生模糊且缺乏多样性的图像，我们采用了一种方法利用高斯解码器的方差作为训练中的可学习参数来解决这一问题。之前的CVAE工作假定在给定标签的潜在空间条件分布与先验分布相等，而实际上并不存在这种情况。", "innovation": "我们通过使用normalizing flows来估计给定标签的潜在空间条件分布，而不是假设它等于先验分布，从而改进了条件VAE。实验结果显示，这种方法在降低FID（弗雷舍-伊斯尼克距离，衡量生成图像与真实图像差异的一个指标）5%和增加对数似然率7.7%方面表现优于现有方法。", "conclusion": "我们的方法通过结合条件VAE和normalizing flows显著提高了图像生成的质量和多样性。实验结果表明，与现有方法相比，该方法在生成质量和多样性方面都有了提升，证明了正常分布流动方法可以有效提高条件VAE的性能。"}
{"llm_update_time": "20251116", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2511.08229", "html_url": "https://arxiv.org/abs/2511.08229", "title": "非站定时间序列预测中的时间稳定化与频域差分", "title_en": "Towards Non-Stationary Time Series Forecasting with Temporal Stabilization and Frequency Differencing", "authors": "Junkai Lu,Peng Chen,Chenjuan Guo,Yang Shu,Meng Wang,Bin Yang", "background": "时间序列预测在能源、金融、交通和云计算等动态领域中至关重要。然而，现实中的时间序列往往表现出非站定性，包括时间分布的变化和频谱变化，这给长期时间序列预测带来了巨大挑战。于是提出了一种双重分支框架DTAF，以解决时间和频域中的非站定性问题。DTAF中的时间稳定化融合(TFS)模块使用非站定的专家组合滤波器分离并抑制了时间非站定模式，同时保留了长期依赖性。频域建模(FWM)模块则通过频域差分动态突出显示具有显著频谱变化的成分。通过融合TFS和FWM的互补输出，DTAF能够生成既适合时间节点又适合频域非站定性的稳健预测。经过在实际基准上的广泛实验，DTAF在非站定条件下显著优于最先进的基线方法，提高了预测精度。所有代码可在该链接下载：this https URL.", "innovation": "提出了一种双重分支框架DTAF，解决了时间序列中时间和频域的非站定性问题。TFS模块通过非站定的专家组合滤波器在保留长期依赖性的同时分离和抑制时间非站定模式。FWM模块通过频域差分突显频谱变化显著的成分，最终融合两模块的输出生成稳健的预测。实验结果显示DTAF在非站定条件下显著优于最先进的基线方法。", "conclusion": "DTAF在非站定条件下显著提高了时间序列预测的准确性，验证了该方法的有效性。"}
{"llm_update_time": "20251116", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2511.08570", "html_url": "https://arxiv.org/abs/2511.08570", "title": "使用层直方图的Kolmogorov-Arnold网络的自动网格更新", "title_en": "Automatic Grid Updates for Kolmogorov-Arnold Networks using Layer Histograms", "authors": "Jamison Moody,James Usevitch", "background": "Kolmogorov-Arnold网络（KANs）是一种近年来在文献中受到广泛关注的神经网络类型，与多层感知机（MLPs）相比，KANs利用了参数化的、可训练的激活函数，并提供了更好的可解释性以及在学习符号方程上更高的准确性。然而，原始的KAN架构需要在训练过程中调整网络的领域离散化（称为“领域网格”），这给用户增加了额外的训练过程负担。传统的KAN层通常不具备在数据驱动的基础上自主更新其领域范围以反映之前层输出范围变化的能力。此外，该直方图算法还可以应用于检测各种情况下的异常值输入（OOD）.", "innovation": "文章提出了一种使用层直方图的自动网格更新方法来解决KANs中存在的领域网格调整问题，从而使KANs能够自主更新其领域范围，并在数据驱动的基础上进行优化。这一创新点不仅提高了KANs的灵活性和适应性，还进一步提升了其在多个任务上的性能。同时，该方法还能够应用于检测不同场景下的异常输入（OOD）.", "conclusion": "实验结果表明，AdaptKAN在四个不同的任务上超过了或与先前的KAN架构和MLP性能相当：从Feynman数据集学习科学方程、从冻结特征进行图像分类、学习控制Lyapunov函数以及在OpenOOD v1.5基准测试中检测异常值输入。"}
{"llm_update_time": "20251116", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2406.05477", "html_url": "https://arxiv.org/abs/2406.05477", "title": "Attri-Net: 使用类别特定反事实进行多标签分类的全局和局部固有可解释模型", "title_en": "Attri-Net: A Globally and Locally Inherently Interpretable Model for Multi-Label Classification Using Class-Specific Counterfactuals", "authors": "Susu Sun,Stefano Woerner,Andreas Maier,Lisa M. Koch,Christian F. Baumgartner", "background": "在高风险医疗应用中，机器学习算法的可解释性至关重要。然而，高性能的神经网络通常无法解释其预测。后 hoc 解释方法可以理解神经网络，但已被证明存在概念上的问题。当前研究主要关注为单个样本提供局部解释，而忽视了为模型提供全局解释。", "innovation": "本文提出了 Attri-Net，一种固有可解释的多标签分类模型，能够提供局部和全局解释。Attri-Net 首先事实上生成类特定的归因图以突出疾病证据，然后使用基于归因图的逻辑回归分类器进行分类。通过解释加权的归因图以获取每个预测的局部解释。通过共同考虑每个类别的归因图的学习平均表示（称为类别中心）和线性分类器的权重来获得整个模型的全局解释。为了确保“正确的理由进行正确的分类”，我们进一步提出了一种机制来引导模型的解释与人类知识一致。", "conclusion": "全面的评估表明，Attri-Net 可以生成与临床知识一致的质量高的解释，同时不牺牲分类性能。"}
{"llm_update_time": "20251116", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2505.19164", "html_url": "https://arxiv.org/abs/2505.19164", "title": "BroadGen：一种生成高效有效的广告商广泛匹配关键词推荐框架", "title_en": "BroadGen: A Framework for Generating Effective and Efficient Advertiser Broad Match Keyphrase Recommendations", "authors": "Ashirbad Mishra,Jinyu Zhao,Soumik Dey,Hansi Wu,Binbin Li,Kamesh Madduri", "background": "在 sponsored search 广告领域，关键短语推荐主要集中在精确匹配类型上，这带来了高管理成本、狭窄的目标范围以及不断变化的搜索查询模式等问题。广义匹配类型虽然可以解决部分精确匹配的缺陷，但会因为广告主使用率低、缺少监管信号以及较低的目标准确性而带来新的问题。因此，研究定义了理想的广义匹配标准，强调效率和效果，确保大量匹配查询的相关性。", "innovation": "提出了 BroadGen 框架，该框架利用历史搜索查询数据推荐高效的广义匹配关键词。BroadGen 通过标记对应建模保持了长时间内的查询稳定性。", "conclusion": "BroadGen 的能力使其能够每天为 eBay 的数百万卖家提供超过 25 亿件商品的相关广义匹配关键词建议。"}
{"llm_update_time": "20251116", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2502.07285", "html_url": "https://arxiv.org/abs/2502.07285", "title": "负相关性作为机器学习工具箱：回顾与新进展", "title_en": "Negative Dependence as a toolbox for machine learning : review and new developments", "authors": "Hoang-Son Tran,Vladimir Petrovic,Remi Bardenet,Subhroshekhar Ghosh", "background": "负相关性正在成为超越传统独立性限制提升学习能力的关键驱动力。近期的发展表明，负相关系统在优化、采样、降维和稀疏信号恢复等基本机器学习挑战中提供了支持，并且在某些情况下超越了基于统计独立性的当前方法。虽然确定性点过程（DPPs）是目前最流行的负相关模型，但其他模型如扰动晶格模型、强莱依利测度和随机函数的零点也获得了重视。", "innovation": "该文章重新审视了过去二十年中负相关领域的研究进展，并引入了关于DPPs在神经网络简洁表示中的新应用。此外，它将负相关作为一个整体方法应用于机器学习，覆盖一系列负相关模型及其超DPPs的应用，提出了具有广泛性和独特性的新视角。", "conclusion": "文章强调了负相关性作为一个整体方法在机器学习中的价值，并提供了广泛的参考文献，以覆盖可能超出文章范围的相关发展。它特别关注了作者在Monte Carlo方法、核心子集和随机梯度下降、随机网络、信号处理和量子计算连接方面的应用贡献。"}
{"llm_update_time": "20251116", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2503.09399", "html_url": "https://arxiv.org/abs/2503.09399", "title": "ForAug: 将前景与背景重新组合以提高具有偏见缓解的视觉变换器训练", "title_en": "ForAug: Recombining Foregrounds and Backgrounds to Improve Vision Transformer Training with Bias Mitigation", "authors": "Tobias Christian Nauen,Brian Moser,Federico Raue,Stanislav Frolov,Andreas Dengel", "background": "尽管Vision Transformers (ViTs)在大规模图像分类任务中表现出色，但它们通常需要大量数据，并且可能存在偏见问题，影响了模型的鲁棒性和泛化能力。", "innovation": "该论文提出了ForAug，一种新颖的数据增强方案，通过使用预训练的基础模型将前景对象与不同背景分离和重组，在训练数据中显式地引入了诱导偏差，从而增强了数据多样性，增加了有效的训练样本数量。在ForNet上进行预训练显著提高了ViTs及其他架构在ImageNet和下游任务中的准确性，同时减少模型的偏见。", "conclusion": "ForAug为分析和缓解偏见提供了有价值的工具，有助于开发更可靠和鲁棒的计算机视觉模型。相关代码和数据集已公开。"}
{"llm_update_time": "20251116", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2503.08207", "html_url": "https://arxiv.org/abs/2503.08207", "title": "基石原子模型在有限温度分子动力学模拟中的可靠性如何？", "title_en": "Are Foundational Atomistic Models Reliable for Finite-Temperature Molecular Dynamics?", "authors": "Denan Li,Jiyuan Yang,Xiangkai Chen,Lintao Yu,Shi Liu", "background": "机器学习力场作为一种有前景的工具，能够实现分子动力学（MD）模拟，具有潜在的量子机械精度和经典MD的高效性。近年来，基于大型语言模型的进步，研究人员开发出了涵盖周期表中大多数元素的基础原子模型，有时被称为通用力场。本综述从实际应用的角度出发，探讨这些基础原子模型在模拟有限温度动态特性时的可靠性。通过研究铅钛酸铅（PbTiO3）的铁电-顺电相变这一典型案例，评估了这些模型的表现。", "innovation": "采用单一特定系统作为案例研究，深入探讨了基础原子模型在特定条件下的可靠性和局限性。指出了静态准确性和动态可靠性之间的潜在矛盾，并推测这些挑战可能源于训练数据中的固有偏差和对非谐性的有限描述。表明这些短期问题可以通过有针对性的微调得到解决，旨在推动这一领域的进一步发展和改进。", "conclusion": "本综述不旨在对模型进行排名，而是提出一个关于基础原子模型在实际应用中的可靠性的关键对话，以探索其进一步改进的方向。"}
{"llm_update_time": "20251116", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.05590", "html_url": "https://arxiv.org/abs/2506.05590", "title": "通过顺序边定向方法进行非线性因果发现", "title_en": "Nonlinear Causal Discovery through a Sequential Edge Orientation Approach", "authors": "Stella Huang,Qing Zhou", "background": "近年来，已经建立了一个有向无环图（DAG）在加性噪声模型（ANMs）下的可识别性，推动了各种因果发现方法的发展。然而，大多数现有方法都作出了限制性假设，严重依赖一般的独立性检验，或者需要大量的计算时间。", "innovation": "该研究提出了一种顺序程序来通过利用成对加性噪声模型（PANM）对补充部分DAG（CPDAG）中的无向边进行定向，以识别它们的因果方向。基于此结果，开发了一种新的约束法算法，用于在非线性ANMs下学习因果DAG。开发了一种排序程序，根据PANM，对无向边进行排序，定义一个边的评估顺序。还设计了一种统计测试，通过对包含候选节点及其部分DAG中已识别的父节点的子图的对竞争方向进行评估的对数似然值进行比较，来确定边的方向。进一步建立了该算法的大样本结构学习一致性。", "conclusion": "在合成和实际数据集上的广泛实验表明，该方法具有计算效率高、对模型误用具有鲁棒性，并且在性能上持续优于许多现有的非线性DAG学习方法。"}
{"llm_update_time": "20251116", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.01939", "html_url": "https://arxiv.org/abs/2506.01939", "title": "超越80/20规则: 高熵少数令牌驱动有效的LLM推理强化学习", "title_en": "Beyond the 80/20 Rule: High-Entropy Minority Tokens Drive Effective Reinforcement Learning for LLM Reasoning", "authors": "Shenzhi Wang,Le Yu,Chang Gao,Chujie Zheng,Shixuan Liu,Rui Lu,Kai Dang,Xionghui Chen,Jianxin Yang,Zhenru Zhang,Yuqiong Liu,An Yang,Andrew Zhao,Yang Yue,Shiji Song,Bowen Yu,Gao Huang,Junyang Lin", "background": "论文探讨了一种名为RLVR（具有可验证奖励的强化学习）的方法，该方法能够增强大型语言模型（LLMs）的推理能力，但其机制尚未完全理解。本文通过探索令牌熵模式来深入理解RLVR，侧重分析令牌对推理性能的影响，特别是令牌熵如何随着RLVR训练而变化，以及高熵令牌在推理决策中的关键作用。", "innovation": "本文通过将RLVR的训练限制在高熵令牌上，发现即使训练仅使用令牌的20%，也能实现与全梯度更新相当的性能，甚至在更大规模的Qwen3-32B和Qwen3-14B模型上，利用仅20%的令牌提高性能，显示出良好的可扩展性。这超出了传统的80/20规则，即20%的关键部分决定80%的整体效果。研究表明，优化决定推理方向的高熵令牌是RLVR有效性的主要原因。", "conclusion": "本研究表明，理解和优化高熵令牌对于改进LLM的推理能力具有重要意义。通过专注于这些高熵令牌，可以显著提高强化学习的效率和效果。这为我们提供了通过令牌熵模式理解RLVR的新视角，并指出了优化LLM推理性能的潜在方法。"}
{"llm_update_time": "20251116", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.06094", "html_url": "https://arxiv.org/abs/2506.06094", "title": "基于嵌入式计算的自适应协同多机器人系统的任务重规划", "title_en": "Onboard Mission Replanning for Adaptive Cooperative Multi-Robot Systems", "authors": "Elim Kwan,Rehman Qureshi,Liam Fletcher,Colin Laganier,Victoria Nockles,Richard Walters", "background": "协作自主机器人系统具有在太空、空中、地面和海洋等领域执行复杂多任务的潜力。但它们通常在远程、动态和危险环境中运行，需要快速的在任务中的适应能力，而无需依赖脆弱或慢速的通信链路来实现集中计算。因此，需要快速的机载重规划算法以增强系统的鲁棒性。强化学习在作为旅行商问题（TSP）任务形式化的情况下，显示解决任务规划任务的强大潜力。然而，现有方法存在4个主要问题：1）不适合重规划，因为机器人不从单一位置开始；2）不允许机器人之间的合作；3）无法处理任务具有可变持续时间的情况；4）缺乏适用于嵌入式部署的考虑。", "innovation": "该论文定义了协作任务重规划问题作为多TSP的新型变体，并结合了图注意力网络和注意力模型开发了一种新的编码器/解码器模型，以有效地且高效地解决它。使用合作无人机的简单示例，说明了该重规划器始终在90%的情况下保持与最先进的LKH3启发式求解器的性能在10%以内，同时在Raspberry Pi上运行速度提高了85-370倍。", "conclusion": "这项工作为自主多智能体系统的鲁棒性增强开辟了途径。"}
{"llm_update_time": "20251116", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2503.16711", "html_url": "https://arxiv.org/abs/2503.16711", "title": "深度数据重要：RGB-D多模态感知对于稳健自主代理的作用", "title_en": "Depth Matters: Multimodal RGB-D Perception for Robust Autonomous Agents", "authors": "Mihaela-Larisa Clement,Mónika Farsang,Felix Resch,Mihai-Teodor Stanusoiu,Radu Grosu", "background": "自主代理依赖纯感知进行实时控制决策，需要高效且稳健的架构。本文展示了将RGB输入与深度信息结合使用，相较于单独使用RGB，显著提升了代理预测转向指令的能力。轻量级递归控制器利用融合的RGB-D特征进行序列决策已被基准测试。通过一个由专家通过物理方向盘控制的小规模自主汽车收集高质量数据，捕捉不同难度的转向情况，模型在实际硬件中部署成功，并在出现动态和静态障碍物、超出分布范围情况下仍能避免障碍，保持控制器的有效性，即使在帧丢失和噪声增加的情况下，也不会分散网络对任务的注意力。", "innovation": "将RGB输入与深度信息结合，轻量级递归控制器利用融合的RGB-D特征进行序列决策。高质量数据通过小型自主汽车在专家操作下收集，模型在实际硬件中部署成功，避免了动态和静态障碍物，尤其是在帧丢失和噪声增加的情况下，控制器保持有效性，而不会影响网络任务关注的焦点。", "conclusion": "本研究揭示，早期融合深度数据的结果是非常稳健的控制器，在出现帧丢失和增加噪声水平的情况下仍然有效，而不会分散网络对任务的关注。"}
{"llm_update_time": "20251116", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2503.15554", "html_url": "https://arxiv.org/abs/2503.15554", "title": "重新思考安全代码生成的评估", "title_en": "Rethinking the Evaluation of Secure Code Generation", "authors": "Shih-Chieh Dai,Jun Xu,Guanhong Tao", "background": "大语言模型（LLMs）在软件开发中广泛应用，但生成的代码常包含安全漏洞。已有安全代码生成方法虽存在，但其评估方案未能全面覆盖，主要表现为未将安全性和功能性评估统一进行，并依赖单一静态分析器，CodeQL，评估范围有限，无法全面衡量安全性和功能性的表现，尤其当一起评估两者时，现有的方法常以牺牲代码功能性的代价提升安全性，甚至降低基础LLM的表现超过50%，且常用的静态分析器CodeQL未能检测出部分漏洞，进一步模糊了现有技术所实现的安全改进的真实情况。", "innovation": "研究系统地评估了四种最先进的安全代码生成技术，采用统一的方法进行安全性和功能性的双重评估，并使用三种流行的静态分析器和两种LLM来识别生成代码中潜在的漏洞，揭示了现有技术在安全性和功能性方面存在的局限，并发现这些技术要么完全删除潜在漏洞代码，要么生成与任务无关的“垃圾代码”。", "conclusion": "现有的安全代码生成技术常常在提升安全性的同时牺牲代码的功能性，整体表现有限，甚至在某些情况下，这些技术在综合评估安全性和功能性时显著降低了基础LLM的性能，这也凸显了现有的静态分析工具（如CodeQL）对于检测某些安全漏洞的不足，强调了需要改进现有的评估标准和分析工具，以更全面地衡量安全代码生成技术的效能。"}
{"llm_update_time": "20251116", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2504.14795", "html_url": "https://arxiv.org/abs/2504.14795", "title": "通过空间相关分布的贝叶斯分割方法解决嘈杂标签问题", "title_en": "A Bayesian Approach to Segmentation with Noisy Labels via Spatially Correlated Distributions", "authors": "Ryu Tadokoro,Tsukasa Takagi,Shin-ichi Maeda", "background": "在语义分割中，模型的准确性很大程度上依赖于高质量的标注。然而，在医疗成像和遥感等实际应用场景中，获取准确的标注信息往往非常困难，并且需要大量的手工劳动。这导致标注过程中容易出现错误，如误标、遗漏和标注者之间的不一致性。特别是在遥感领域，由于采购时间的不同，可能会导致标注信息不一致。这些标注错误通常在空间上是相关的，即相邻像素出现错误的概率较高。因此，如何通过利用标注错误的空间相关性来提高分割模型的准确性成为了一个重要的研究方向。", "innovation": "本文提出了一种基于非独立分布的贝叶斯估计方法，通过引入一种新的概率模型，即ELBO-Computable Correlated Discrete Distribution (ECCD)，解决空间相关离散变量的贝叶斯推理难题。通过将离散依赖关系表示为具有Kac-Murdock-Szegö (KMS) 结构协方差的连续隐高斯领域，该框架可以实现以前被认为计算上不可行问题的高效近似变分推理。实验结果表明，利用标注错误的空间相关性能显著提高分割性能，特别是在肺分割任务中，该方法在中等噪声水平下能达到与干净标签训练相当的性能。", "conclusion": "本文提出了一种基于空间相关性的概率模型，通过在标注数据中考虑标签错误的空间相关性，利用贝叶斯估计解决了标注噪声问题。实验结果证明了该方法的有效性，特别是在噪声条件下，其性能可与干净标签训练媲美。"}
{"llm_update_time": "20251116", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.19794", "html_url": "https://arxiv.org/abs/2506.19794", "title": "为什么开源大语言模型在数据分析方面遇到困难？一项系统性实证研究", "title_en": "Why Do Open-Source LLMs Struggle with Data Analysis? A Systematic Empirical Study", "authors": "Yuqi Zhu,Yi Zhong,Jintian Zhang,Ziheng Zhang,Shuofei Qiao,Yujie Luo,Lun Du,Da Zheng,Ningyu Zhang,Huajun Chen", "background": "大型语言模型（LLMs）在自动化数据分析任务方面展现出巨大潜力，但开源模型在这些需要大量推理的场景中面临巨大限制。本文旨在探索提升开源LLMs在数据分析能力的策略。研究通过编译多样化的种子数据集，从数据理解、代码生成和战略规划三个核心维度评估模型行为。", "innovation": "研究发现，战略规划质量是决定模型性能的关键；交互设计和任务复杂性显著影响推理能力；数据质量比多样性对实现最佳性能有更大的影响。基于这些洞见，本文开发了一种数据合成方法，显著提升了开源LLMs的分析推理能力。研究中的相关代码在此处可获取：this https URL。", "conclusion": "研究揭示了影响开源LLMs数据分析能力的关键因素，并提出了一种数据合成的方法以增强其推理能力，对未来改进此类模型具有重要指导意义。"}
{"llm_update_time": "20251116", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.26091", "html_url": "https://arxiv.org/abs/2509.26091", "title": "利用大型推理模型实现从文本到场景的生成", "title_en": "Text-to-Scene with Large Reasoning Models", "authors": "Frédéric Berdoz,Luca A. Lanzendörfer,Nick Tuninga,Roger Wattenhofer", "background": "现有的文本到场景生成方法在处理复杂几何结构和对象变换时常常表现不佳，对于复杂的指令依赖性也较弱。因此，该研究旨在通过引入一个基于大型推理模型（LRMs）的文本到场景生成模型（Reason-3D），解决这些现有方法的限制问题。", "innovation": "Reason-3D模型结合了使用描述物理、功能和上下文属性的标题来检索对象，并通过隐性和显性的布局约束放置选定的对象。该模型还使用碰撞感知的空间推理来完善对象的位置。相对于其他方法，Reason-3D在视觉真实度、约束遵守度和资产检索质量方面取得了显著的提升。此外，这项工作还展示了现代LRMs的高级空间推理能力，并公开了代码库，以促进对象检索和放置的研究。", "conclusion": "该研究证明了通过将大型推理模型与物体检索和布局优化相结合，可以显著提高从文本生成复杂3D场景的生成能力，为该领域的发展带来了新的视角和解决方案，同时为未来的研究提供了支持。"}
{"llm_update_time": "20251116", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2511.06625", "html_url": "https://arxiv.org/abs/2511.06625", "title": "从LDCT进行心血管风险评估的可解释跨疾病推理", "title_en": "Explainable Cross-Disease Reasoning for Cardiovascular Risk Assessment from LDCT", "authors": "Yifei Zhang,Jiashuo Zhang,Mojtaba Safari,Xiaofeng Yang,Liang Zhao", "background": "低剂量胸部计算机断层扫描（LDCT）能够同时捕捉肺部和心脏结构，提供联合评估肺部和心血管健康的独特机会。然而，大多数现有方法将这两个领域视为独立的任务，忽略了它们的生理交互和共享的成像生物标志物。", "innovation": "提出了一种可解释的跨疾病推理框架，该框架能够仅通过一个LDCT扫描进行肺心部风险评估。此框架引入了一种代理性的推理过程，模拟了临床诊断思考过程，并集成了三个协同组件：肺部感知模块、知识引导的推理模块和心脏表示模块，以生成准确且生理上真实的整体心血管风险预测。此框架在NLST队列上的实验表明，其在心血管疾病筛查和死亡率预测上达到了最先进的性能，优于单一疾病和纯粹基于图像的基线方法。此外，该框架还提供了与心血管学理解相一致的人机可验证推理，揭示了肺异常与心脏压力机制之间的一致联系。", "conclusion": "这项工作建立了一个统一且可解释的心血管分析框架，从LDCT中结合图像预测和机制基础的医学解释，填补了两者的差距。"}
{"llm_update_time": "20251116", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.17425", "html_url": "https://arxiv.org/abs/2510.17425", "title": "量化气候政策行动及其与发展结果的关系：基于跨国民间数据分析", "title_en": "Quantifying Climate Policy Action and Its Links to Development Outcomes: A Cross-National Data-Driven Analysis", "authors": "Aditi Dutta", "background": "有效应对气候变化不仅需要记录政策数量，还需要能够揭示其主题优先事项及其对发展成果的直接影响的工具。现有评估通常依赖于定性描述或综合指数，这些方法可能会掩盖减缓、适应、灾害风险管理以及损失和损害等关键领域的关键差异。", "innovation": "开发了一种通过应用多语言变压器语言模型对官方国家政策文件进行定量气候政策导向指标的方法，实现了0.90的分类准确率（F1分数）。将这些指标与世界银行的发展数据联系起来进行面板回归分析，揭示了减缓政策与更高GDP和国民总收入的关系，灾害风险管理与更高的国民总收入和债务但减少的外国直接投资的关系，适应和损失与损害表现出有限的可测量效应。集成自然语言处理和计量经济模型框架，可实现针对主题的可比分析，提供了一种可扩展的方法来监控进展、评估权衡并使政策重点与发展目标一致。", "conclusion": "该综合自然语言处理-计量经济学框架能够针对主题进行可比的分析，为评估气候治理进展、评价权衡并使政策重点与发展目标一致提供了工具。"}
{"llm_update_time": "20251116", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2511.06040", "html_url": "https://arxiv.org/abs/2511.06040", "title": "对称相伴尖峰威格纳模型的算法相变", "title_en": "The Algorithmic Phase Transition in Symmetric Correlated Spiked Wigner Model", "authors": "Zhangsong Li", "background": "该研究关注的是在一对尖峰威格纳矩阵中检测和估计相关信号的任务。模型包含观测矩阵X和Y，其中X和Y观察到的特征向量x和y分别对应线性变换后的尖峰信号，同时这些信号受到高斯威格纳矩阵W和Z的高斯噪声影响。研究者们探讨了信号检测和估计的条件，特别是在仅从单一矩阵中恢复信号被认为是计算上不可行的区域，检测和估计相关信号是否依然可行的问题。", "innovation": "提出了一种有效的算法，能够在满足特定条件时成功检测和估计信号。此算法基于信号之间的相关性，可以在高效恢复单一信号不可行的场景下工作。研究表明，低阶多项式基算法无法区分尖峰相关信号矩阵，以此进一步证明了检测和估计的精确计算阈值为$F(\theta, \rho, \rho) = 1$。", "conclusion": "研究证实，在信号之间的相关性足够强时，即使单独从单一兰德尔中恢复信号本是计算上无法完成的任务，也能通过相关性有效地检测和估计信号。进一步的实验证明，当这个特定的函数$F$小于1时，基于低阶多项式的方法将无法区分这些相关信号矩阵。"}
{"llm_update_time": "20251116", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2511.01467", "html_url": "https://arxiv.org/abs/2511.01467", "title": "量子信息排序与差分隐私", "title_en": "Quantum Information Ordering and Differential Privacy", "authors": "Ayanava Dasgupta,Naqueeb Ahmad Warsi,Masahito Hayashi", "background": "本文研究量子差分隐私（QDP），通过定义量子状态对之间的信息序关系来探讨。研究指出，若一对量子态的假设检验距离大于另一对，则这种优势对所有f-距离都保持。通过这一方法，完全界定了（ε，δ）-QDP机制，即通过识别最具有信息量的（ε，δ）-DP量子状态对来达到这一目标。此外，该研究还将经典结果推广到δ>0的情况，并分析了量子化的假设检验和量子参数估计的隐私边界，包括量子费舍尔信息的紧上界。", "innovation": "文章通过引入量子态对的信息序关系，完全界定了（ε，δ）-QDP机制，并从而识别出最具有信息量的（ε，δ）-DP量子状态对。此外，该研究将结果推广到经典结果不适用的δ>0情况，并探讨了包括量子费舍尔信息的紧上界在内的更多隐私边界问题。", "conclusion": "本文为不同类型的量子信道建立了近最优的收敛边界，并且对于Hockey-Stick距离定义了不同的差分隐私量子信道。"}
{"llm_update_time": "20251116", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2511.08379", "html_url": "https://arxiv.org/abs/2511.08379", "title": "SOM Directions are Better than One: Multi-Directional Refusal Suppression in Language Models", "title_en": "SOM Directions are Better than One: Multi-Directional Refusal Suppression in Language Models", "authors": "Giorgio Piras,Raffaele Mura,Fabio Brau,Luca Oneto,Fabio Roli,Battista Biggio", "background": "该研究背景是在功能安全方面，针对语言模型拒绝有害或不道德提示的行为。现有的研究表明，有害和无害提示的表示在高维潜空间中往往是以低维流形的形式存在。为了解决这一问题，研究者提出了利用自组织图（SOM）来提取多个拒绝方向的创新方法。", "innovation": "该研究的创新之处在于，利用自组织图（SOM）提取多个拒绝方向，而不是之前的方法中使用的单一方向。它首先证明了SOM在形式上扩展了先前工作的样本均值差异技术。然后，通过训练SOM并从中识别多个神经元，再针对每个神经元减去无害提示的中心点，从而得到表达拒绝概念的多个方向。这种方法显著优于先前的单方向基础模型和专门的模型设障算法。", "conclusion": "该研究通过实验证明，从模型内部删除多个方向比单一方向或专门的模型设障算法更有效，能够有效抑制拒绝。进一步分析了该方法的机制意义，表明这种方法能够更全面地理解和控制有害提示在模型中的表现。"}
{"llm_update_time": "20251116", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2511.07883", "html_url": "https://arxiv.org/abs/2511.07883", "title": "SpikCommander：一种基于多视图学习的高性能脉冲变换器，用于高效的语音命令识别", "title_en": "SpikCommander: A High-performance Spiking Transformer with Multi-view Learning for Efficient Speech Command Recognition", "authors": "Jiaqi Wang,Liutao Yu,Xiongri Shen,Sihang Guo,Chenlin Zhou,Leilei Zhao,Yi Zhong,Zhiguo Zhang,Zhengyu Ma", "background": "现有的基于SNN的语音命令识别（SCR）方法由于时序建模能力和二进制脉冲表示的限制，常常难以捕捉到语音中的丰富时序依赖性和上下文信息。Spiking神经网络（SNN）通过利用事件驱动的处理范式，为能量效率高的语音命令识别提供了有前途的途径。", "innovation": "本文引入了多视角脉冲时序感知自注意（MSTASA）模块，将有效的脉冲时序感知自注意与多视角学习框架结合起来，以建模语音命令中的互补时序依赖性。基于MSTASA，提出了完全基于脉冲的SpikCommander，这是一个结合了MSTASA与脉冲上下文细化通道全连接神经网络（SCR-MLP）的变换器架构，用于同时增强时序上下文建模和通道内部特征集成。实验结果表明，SpikCommander在多种基准数据集上性能优越，展示了其在语音命令识别中的有效性和效率。", "conclusion": "SpikCommander在与SOTA SNN方法相比具有较少参数的情况下表现更优，特别是在相同的时间步长下，证明了其在鲁棒语音命令识别中的作用和效率。"}
{"llm_update_time": "20251116", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.01252", "html_url": "https://arxiv.org/abs/2510.01252", "title": "GPT与偏见：理解大型语言模型中学习表示的稀疏方法", "title_en": "GPT and Prejudice: A Sparse Approach to Understanding Learned Representations in Large Language Models", "authors": "Mariam Mahran,Katharina Simbeck", "background": "大型语言模型（LLMs）在训练过程中吸收了大量的、未结构化的数据集，因此很难确定它们吸收了哪些社会模式和偏见并在未来进行再现。现有评估通常仅检查输出或激活，但鲜少连接这些结果与预训练数据之间的关系。此研究引入了一种将LLMs与稀疏自编码器（SAEs）结合的管道，以追踪在训练期间不同主题的编码过程。研究选择了19世纪的37部以性别、婚姻、阶级和道德为主题的小说作为案例研究，训练了一个类GPT模型。通过使用稀疏自编码器和多个人类可解释的社会与道德类别进行探查，研究人员能够将稀疏特征映射为人类可理解的概念。这项研究揭示了稳定的主题骨架（最显著的是性别和家庭关系），展示了深层次中的关联如何扩展和交织在一起。总体上，研究认为LLM+SAEs管道提供了一种可扩展的框架，用于审查数据中的文化假设如何嵌入到模型表示中。", "innovation": "研究人员提出了一种结合LLMs和稀疏自编码器（SAEs）的管道，以追踪大型语言模型在训练过程中如何编码不同的主题。通过使用19世纪的小说数据和多个社会与道德类别进行探查，将稀疏特征映射到人类可理解的概念上。这种方法提供了识别和理解模型中文化假设的新方式。此外，通过对比不同深度的表示，展示了社会关系如何深化和复杂化。这项研究为审计大型语言模型中的社会偏见提供了一个新的视角和工具。", "conclusion": "使用大型语言模型+稀疏自编码器（SAEs）的管道可以为研究提供一个可扩展的框架，以审计数据中的文化假设如何嵌入到模型表示中。这种方法使得能够识别和理解大型语言模型中的社会偏见，并为审计模型提供了一种新的方式。此项研究揭示了如何在深层次中扩展和交织的社会关联，并为未来研究提供了新的见解。"}
{"llm_update_time": "20251116", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.04602", "html_url": "https://arxiv.org/abs/2510.04602", "title": "通过梯度流动计算 Wasserstein 中心", "title_en": "Computing Wasserstein Barycenters through Gradient Flows", "authors": "Eduardo Fernandes Montesuma,Yassir Bendou,Mike Gartrell", "background": "Wasserstein 中心为聚合概率测度提供了强大的工具，同时充分挖掘其周围空间的几何特性。现有的离散方法在可扩展性方面表现不佳，因为需要访问输入测度的完整样本集。为了解决这个问题，我们将原始的中心化问题重新表述为 Wasserstein 空间的梯度流动。通过这种方法，实现了通过从输入测度中采样小批量数据来获得可扩展性。此外，通过包含概率测度的功能项，这些方法可以引入内部、潜在和交互能量，从而对中心化问题进行正则化。", "innovation": "该方法通过梯度流动重新表述了原始的 Wasserstein 中心问题，使其具有两个主要优势。首先，通过从输入测度中采样小批量数据提升了可扩展性。其次，通过引入对概率测度的功能项进行有效正则化，内部、潜在和交互能量的使用进一步改进了问题的解决方案。此外，该方法提出了两种算法来处理经验样本和高斯混合测度，并提供了关于数值收敛性的理论保障。", "conclusion": "在玩具数据集和领域适应基准测试中的实验验证表明，该方法在计算 Wasserstein 中心方面优于先前的离散方法和基于神经网络的方法。"}
{"llm_update_time": "20251116", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.21004", "html_url": "https://arxiv.org/abs/2510.21004", "title": "当前检测器能否发现基于面部到语音的深度伪造攻击？", "title_en": "Can Current Detectors Catch Face-to-Voice Deepfake Attacks?", "authors": "Nguyen Linh Bao Nguyen,Alsharif Abuadbba,Kristen Moore,Tingmin Wu", "background": "生成模型的快速发展使得创建越来越难以察觉的合成声音成为可能，这些声音通常被称为音频深度仿冒。最近的技术FOICE（使用NUSENIX'24）展示了一项特别令人担忧的能力：仅从单张面部图像生成受害者的语音，而无需任何语音样本。通过利用面部和语音特征之间的相关性，FOICE生成了足以绕过行业标准身份验证系统的合成语音，包括WeChat Voiceprint和Microsoft Azure。这引发了严重的安全问题，因为面部图像比语音样本更容易被对手获取，大大降低了大规模攻击的门槛。", "innovation": "本研究提出了两个核心研究问题：(RQ1)最先进的音频深伪检测器是否能可靠地在干净和嘈杂条件下检测到FOICE生成的语音，(RQ2)是否可以通过微调这些检测器在FOICE数据上的表现以提高检测精度而不导致过拟合，从而保留对未见过的语音生成器如SpeechT5的鲁棒性。研究做出了三项贡献：首先，我们对FOICE检测进行了第一个系统性的评估，发现最先进的检测器在标准和嘈杂条件下始终未能成功；其次，我们提出了专门针对FOICE特征的微调策略，实现了显著的准确率提升；第三，我们评估了微调后的泛化能力，揭示了专注于FOICE和对未见过合成管道的鲁棒性之间的权衡。这些发现暴露了当今防御系统的根本弱点，并激励了下一代音频深伪检测架构和训练协议的发展", "conclusion": "本研究揭示了现有防护措施中的根本性弱点，指出需要开发新的架构和训练协议以应对未来可能出现的新一代音频深伪检测挑战。"}
{"llm_update_time": "20251116", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2407.04596", "html_url": "https://arxiv.org/abs/2407.04596", "title": "软件工程背景中的教学与学习人类学方法", "title_en": "Teaching and Learning Ethnography for Software Engineering Contexts", "authors": "Yvonne Dittrich,Helen Sharp,Cleidson de Souza", "background": "人类学已经成为软件工程领域实证研究中的一种成熟的实证方法。尽管有很多入门书籍，但是专门为软件工程学生编写的特定材料仍然缺乏。", "innovation": "该章节填补了这一空白，专注于介绍人类学作为研究方法的基础知识给软件工程研究生及教员。\n该篇目还包括针对练习、教学技巧及经验教训的建议。", "conclusion": "该章节旨在支持软件工程中的实证研究课程，并提供进一步阅读的参考和文献指南。"}
{"llm_update_time": "20251116", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2511.09572", "html_url": "https://arxiv.org/abs/2511.09572", "title": "SynthTools：为代理开发扩展合成工具的框架", "title_en": "SynthTools: A Framework for Scaling Synthetic Tools for Agent Development", "authors": "Tommaso Castellani,Naimeng Ye,Daksh Mittal,Thomson Yen,Hongseok Namkoong", "background": "人工智能代理越来越多地依赖外部工具来解决复杂的长周期任务。推进这些代理需要在可控、多样且现实的工具使用环境中实现可重复的评估和大规模训练。然而，现实世界的API在可用性、领域覆盖面和稳定性方面受到限制，经常需要访问密钥并施加速率限制，这使它们不适合稳定评估或可扩展训练。", "innovation": "本文介绍了SynthTools，这是一个灵活且可扩展的框架，用于生成合成工具生态系统。它由三个核心组件组成：工具生成、工具模拟和工具审核，以自动和可扩展的方式创建多样化的工具、模拟现实的工具行为并确保工具模拟的正确性和一致性。SynthTools能够生成覆盖更广泛领域和每个领域更多种工具的工具集，具有强大的可靠性，分别为94%和99%。并且通过生成的工具构建的下游任务，即使是最先进的模型也难以完成。", "conclusion": "通过提供可扩展、多样且可靠的工具生态系统，SynthTools为大规模培训和评估工具使用代理提供了实用路径。"}
{"llm_update_time": "20251116", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2407.04650", "html_url": "https://arxiv.org/abs/2407.04650", "title": "工业软件工程中的行动研究——教育视角", "title_en": "Action Research with Industrial Software Engineering -- An Educational Perspective", "authors": "Yvonne Dittrich,Johan Bolmsten,Catherine Seidelin", "background": "行动研究为探索软件工程方法在工业环境中的适用性和实用性提供了机会，同时也促进了软件工程从业者发展方法、工具和技术的能力。然而，随着研究从观察性方法向与软件开发组织的互动方法转变，行动研究变得更具挑战性，并且很难通过仅仅解释原则的方式来教授行动研究。", "innovation": "本章通过提供丰富的实例和识别在行动研究项目中发现有用的工具，旨在支持行动研究的教育和学习。章节的核心内容集中在作者参与的行动研究项目中与参与开发人员及领域专家的互动及其组织背景上，强调了一系列在这些项目中反复出现的挑战，并为每个部分配备了相关技术和工具的工具包，以便进行实践练习和探索课题。", "conclusion": "本章节希望通过提供的内容和工具，鼓励新接触行动研究的研究人员进一步探索这一有希望的机会。"}
{"llm_update_time": "20251116", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2511.10326", "html_url": "https://arxiv.org/abs/2511.10326", "title": "全面采样SMT解的方法", "title_en": "Towards Comprehensive Sampling of SMT Solutions", "authors": "Shuangyu Lyu,Chuan Luo,Ruizhi Shi,Wei Wu,Chanjuan Liu,Chunming Hu", "background": "该研究关注于通过有效生成满足理论（SMT）公式的多样化解来解决软件和硬件测试中的关键任务，特别是针对位向量、数组和无定义函数的理论。这有助于在验证和测试过程中发现故障和检测安全违规，从而形成了SMT采样问题，即在有限的解数量下覆盖整个约束空间。尽管高覆盖率对于探索系统行为至关重要，但减少解的数量也极为重要，因为过多的解会增加测试时间和资源使用，从而影响效率。", "innovation": "引入了PanSampler，这是一种新型的SMT采样器，能够在少量解的情况下实现高覆盖率。PanSampler结合了三种新技术：多样性意识的SMT算法、基于抽象语法树（AST）的评分函数和后采样优化技术，增强了其实用性能。它通过迭代采样解、评估候选解并采用局部搜索来优化解，确保用少量样本实现高覆盖率。实验表明，与现有采样器相比，PanSampler能够以更少的解达到相同的覆盖率水平，显示出更强的能力，并且在实际基准上的测试还显示PanSampler能够检测更多故障，减少了所需测试用例的数量，从而显著提高了测试效率。", "conclusion": "PanSampler推动了SMT采样领域的发展，降低了软件测试和硬件验证的成本，提高了测试效率。"}
{"llm_update_time": "20251116", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2511.04427", "html_url": "https://arxiv.org/abs/2511.04427", "title": "AI辅助编程有效吗？Cursor对软件项目影响的差异差异研究", "title_en": "Does AI-Assisted Coding Deliver? A Difference-in-Differences Study of Cursor's Impact on Software Projects", "authors": "Hao He,Courtney Miller,Shyam Agarwal,Christian Kästner,Bogdan Vasilescu", "background": "大型语言模型（LLMs）在软件工程领域的潜力已得到展现，尤其是在软件开发中的应用受到开发人员的高度重视。然而，关于这一应用效果的真实证据却很少。本文通过比较使用Cursor软件开发助手的GitHub项目与未使用Cursor的匹配控制组，研究Cursor对企业级开发速度和软件质量的影响。", "innovation": "本文提出了一种前瞻性差异差异设计，采用最新的方法比较了Cursor使用情况下的GitHub项目与未使用Cursor的同类GitHub项目，评估了Cursor对开发速度和软件质量的影响。通过进一步的面板广义矩估计，揭示了静态分析警告和代码复杂性的增加是导致长期速度下降的主要因素。", "conclusion": "研究表明，Cursor的采用能显著提高项目级别的开发速度，但这种效果是短暂的。此外，增加的静态分析警告和代码复杂性是导致长期开发速度下降的主要因素。此研究对软件工程从业者、软件开发助手设计人员和研究人员具有重要意义。"}
{"llm_update_time": "20251116", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2511.09231", "html_url": "https://arxiv.org/abs/2511.09231", "title": "利用大型语言模型从软件需求生成用例模型", "title_en": "Leveraging Large Language Models for Use Case Model Generation from Software Requirements", "authors": "Tobias Eisenreich,Nicholas Friedlaender,Stefan Wagner", "background": "用例建模通过用户中心的场景概述系统需求，可以帮助实现各相关利益相关者之间的共识。然而，手工创建用例模型费时费力，常常被实际操作中忽略。因此，研究探索了大型语言模型（LLMs）在这一冗长过程中的潜在应用价值。", "innovation": "本文提出了一种方法，利用开放式权重的大规模语言模型结合高级提示工程技术，系统地从软件需求中提取参与者和用例。该方法通过一项探索性研究进行了评估，研究对象为五名专业的软件工程师，对比传统的人工建模与提出的基于LLM的方法。结果表明，该方法能够显著加速建模过程，使建模时间减少了60%，而模型质量保持稳定。", "conclusion": "除了提高建模效率外，参与者还指出这种方法在过程中提供了有价值的指导。"}
{"llm_update_time": "20251116", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2511.10271", "html_url": "https://arxiv.org/abs/2511.10271", "title": "LLM生成代码的质量保证：解决非功能性质量特征", "title_en": "Quality Assurance of LLM-generated Code: Addressing Non-Functional Quality Characteristics", "authors": "Xin Sun,Daniel Ståhl,Kristian Sandahl,Christoph Kessler", "background": "近年来，大语言模型（LLMs）被广泛应用于软件工程的工作流程中，支持代码生成等任务。尽管这些模型经常生成功能上正确的输出，但对它们的非功能性质量缺乏系统性理解和评估。现有研究主要关注生成代码是否通过测试，而忽视了其质量。研究基于ISO/IEC 25010质量模型，进行了三项互补的研究：系统回顾108篇论文、两家多组织从业者参与的行业研讨会，以及使用三种LLM解决真实软件问题的实证分析。", "innovation": "本研究通过来自文献和从业人员的洞见，对功能正确代码的生成质量进行了实证研究，评估了生成补丁在安全性、可维护性和性能效率等方面的质量。发现学术界关注安全性和性能效率，而行业更重视可维护性和可读性。研究结果揭示了学术关注、工业优先事项和模型性能之间的不匹配，强调了在LLM代码生成流程中集成质量保证机制的紧迫性。", "conclusion": "研究揭示了学术界、工业界和模型性能之间的不匹配，指出生成代码不应仅通过测试，还应保证高质量。需要在LLM代码生成过程中引入质量保证机制，确保未来生成的代码不仅通过测试，而且真正具有高质量。"}
{"llm_update_time": "20251116", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2503.15626", "html_url": "https://arxiv.org/abs/2503.15626", "title": "一种基于标准化目录的安全控制可扩展博弈论方法", "title_en": "A Scalable Game-Theoretic Approach for Selecting Security Controls from Standardized Catalogues", "authors": "Dylan Léveillé,Jason Jaskolka", "background": "从标准化目录中选择能够最有效地保护系统资产的安全控制组合是一项艰巨的任务。如果选择了不恰当的控制措施，系统可能会受到影响重要数据和服務的网络攻击，破坏其机密性、完整性和可用性。在实际应用中，由于标准化目录可能非常庞大，无法选取和实施所有的可能控制措施。因此，需要综合考虑预算、有效性及控制措施之间的依赖性，从中选择最合适的控制措施组合，以实现系统的安全目标。本文基于预期攻击者的特征和预算，提出了一个博弈论方法来选择安全控制的组合。该方法将控制选择问题设置为零和博弈，并使用代数公正式来考虑到选择控制之间依赖性。通过一个软件工具，我们基于加拿大的标准化控制目录（ITSG-33）和一个虚构的加拿大军事系统应用该方法。通过案例研究，本文展示了这种方法在大型系统中选择有效的安全控制组合方面的可扩展性，如何在开发不同规模的安全系统时指导和支持决策过程。", "innovation": "本文提出的是一种博弈论方法，通过预期攻击者的特征和预算来选择安全控制的组合。使用代数公正式来生成适当的控制组合，并考虑到选择控制之间的依赖性。这种方法可以扩展到大型系统中，帮助安全分析师在规划不同规模的安全系统时进行有效的决策。", "conclusion": "通过案例研究，本文验证了方法的可行性和可扩展性，有效支持了在开发大型系统的安全控制选择活动。同时，引入了一个软件工具来辅助和指导决策过程，增加了方法的实际应用价值。"}
{"llm_update_time": "20251116", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2508.11034", "html_url": "https://arxiv.org/abs/2508.11034", "title": "大型语言模型（LLMs）对代码评审过程的影响", "title_en": "The Impact of Large Language Models (LLMs) on Code Review Process", "authors": "Antonio Collante,Samuel Abedu,SayedHassan Khatoonabadi,Ahmad Abdellatif,Ebube Alor,Emad Shihab", "background": "大型语言模型（LLMs）在软件开发领域的应用迅速增多，极大地提升了生产力并简化了团队合作。虽然之前的研究已经考察了特定任务的应用，但LLM对代码评审过程各阶段效率的具体影响仍鲜有研究。本文通过研究GPT对GitHub合并请求（PR）工作流程的影响，检测其对评审时间和各阶段性能的具体优化效果，以及对开发人员的支持作用。研究者收集了25,473个来自9,254个GitHub项目的PR数据，并使用结合关键词检测、正则表达式过滤和手动验证的半自动启发式方法识别了GPT辅助的PR。", "innovation": "研究基于大型语言模型（LLMs），特别是GPT，对代码评审过程的具体影响进行了深入探索。通过一个包含25,473个PR的全面数据集，研究揭示了早期采用GPT可以显著提升代码评审过程的有效性，特别是在缩短各个阶段所需时间方面。研究发现，GPT辅助的PR在总体解决时间上降低了60%以上（9小时对比非辅助的23小时），在评审时间上减少了33%，在等待接受的时间上减少了87%。开发人员主要使用GPT进行代码优化（60%）、错误修复（26%）和文档更新（12%）", "conclusion": "研究揭示了GPT模型对代码评审过程的具体影响，为希望提升工作流程、促进顺畅合作的软件团队提供了实用见解。早期采用GPT能够显著提升代码评审过程的效率，大幅节省在各个阶段所需的时间。"}
{"llm_update_time": "20251116", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2503.15554", "html_url": "https://arxiv.org/abs/2503.15554", "title": "重新审视安全代码生成的评估", "title_en": "Rethinking the Evaluation of Secure Code Generation", "authors": "Shih-Chieh Dai,Jun Xu,Guanhong Tao", "background": "大语言模型（LLMs）在软件开发中广泛应用，但由这些模型生成的代码经常包含安全隐患。尽管已有一些方法尝试解决这一问题，但这些方法的安全评估和功能验证通常分别进行，使用不同的数据集，且主要依赖单一的静态分析器（CodeQL）来检测代码中的漏洞，这限制了安全评估的范围和全面性。因此，当前的方法在同时评估安全性与功能性方面存在不足，这些不足包括不能确保在提升安全性的同时不会损害代码功能，并且可能降低基础LLM的性能。", "innovation": "该研究通过结合安全检查和功能验证对最先进的安全代码生成技术进行了全面评估。使用了三种流行的静态分析器和两种LLM来识别生成代码中的潜在漏洞。这项研究揭示了现有技术通常为了提高安全性而牺牲了代码功能，且整体性能受限于综合评估两方面的能力。此外，常用的静态分析器CodeQL未能检测到一些漏洞，进一步模糊了现有技术的实际安全改进效果。", "conclusion": "现有安全代码生成技术常常在提升安全性时损害代码功能，综合评估其安全性和功能性时的整体性能有限，甚至可能降低基础LLM的性能。许多方法甚至完全删除了存在隐患的代码行或生成无关任务的“垃圾代码”。文中发现，常用的静态分析器CodeQL未能检测出若干漏洞，进一步混淆了现有技术的安全改进效果。"}
