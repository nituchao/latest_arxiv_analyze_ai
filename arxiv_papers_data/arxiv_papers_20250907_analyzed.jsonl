{"llm_update_time": "20250907", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.03550", "html_url": "https://arxiv.org/abs/2509.03550", "title": "基于扩散强化学习的空中交通冲突检测与解决方法", "title_en": "Diffusion-RL Based Air Traffic Conflict Detection and Resolution Method", "authors": "Tonghe Li,Jixin Liu,Weili Zeng,Hao Jiang", "background": "在全球航班流量持续增长的背景下，高效的且安全的冲突检测与解决（CD&R）对于空中交通管理至关重要。现有的基于深度强化学习（DRL）的方法普遍具有‘单模偏好’，这在面对复杂和动态约束时限制了决策灵活性，导致‘决策僵局’。", "innovation": "本文提出了将扩散概率模型整合到CD&R这种安全关键任务中，提出了一个新的自主冲突解决框架Diffusion-AC。该框架通过受值函数引导的逆去噪过程来建模策略，从而生成丰富、高质量且多模态的动作分布。此外，还提出了一种密度渐进安全课程（DPSC），确保代理在从稀疏环境到高密度环境的进展中实现稳定和高效的训练。", "conclusion": "大量仿真实验表明，所提出的方法在多种基准测试中表现出色。尤其是在高密度场景中，Diffusion-AC成功率达94.1%，将接近空中相撞（NMAC）事件减少了约59%，显著提升了系统的安全裕度。这一性能提升源自其独特的多模态决策能力，使代理能够灵活切换到有效的替代操作。"}
{"llm_update_time": "20250907", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.03646", "html_url": "https://arxiv.org/abs/2509.03646", "title": "LLMs中通过强化学习涌现的层次化推理", "title_en": "Emergent Hierarchical Reasoning in LLMs through Reinforcement Learning", "authors": "Haozhe Wang,Qixin Xu,Che Liu,Junhong Wu,Fangzhen Lin,Wenhu Chen", "background": "强化学习（RL）在提升大型语言模型（LLMs）的复杂推理能力方面非常有效，但其背后的具体机制仍不清晰。本文分析发现，诸如‘顿悟时刻’、‘长度缩放’和熵动态等现象并非孤立存在，而是层次化推理的标志。层次化推理将高层的战略规划与低层的程序执行相区分，类似于人类认知中的机制。", "innovation": "本文提出了HIerarchy-Aware Credit Assignment (HICRA)，这是一种算法，能够集中优化资源到高影响规划令牌上。HICRA在比对实验中表现出色，证明关注这一战略瓶颈是实现高级推理的关键。同时，文章还验证了语义熵作为一种衡量战略探索的更好的指标，相对于逐令牌熵等误导性指标更为优越。", "conclusion": "HICRA算法的基础上得出了加强逻辑推理的关键在于解决高层次战略规划这一战略瓶颈，并通过实验证明了语义熵是评估战略探索更好的指标。"}
{"llm_update_time": "20250907", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.03548", "html_url": "https://arxiv.org/abs/2509.03548", "title": "Quasi-Markovian结构性因果模型中部分可识别查询的多线性与线性规划", "title_en": "Multilinear and Linear Programs for Partially Identifiable Queries in Quasi-Markovian Structural Causal Models", "authors": "João P. Arroyo,João G. Rodrigues,Daniel Lawand,Denis D. Mauá,Junkyu Lee,Radu Marinescu,Alex Gray,Eduardo R. Laurentino,Fabio G. Cozman", "background": "该研究关注于在一种特定类型的因果模型中（由析取结构因果模型和拟马尔可夫性定义）的部分可识别查询。背景在于，研究的对象是一类无环的结构性因果模型，其中每个内生变量最多与一个外生共因变量相关联。在这种设定下，内生变量可以观测，但外生变量的信息不完全确定。这导致了一个非唯一确定的模型结构，即模型根变量的分布。在这种情况下，某些概率值可能无法精确定义，进而需要研究如何计算概率值的紧边界。", "innovation": "研究提出了一个新的算法，通过利用内生变量的概率输入，简化了此类紧概率边界问题的程序构建。特别地，对于单一干预的情景，通过列生成技术计算辅助线性整数规划，从而证明了可能存在一个具有多项式大小的外生变量表示。", "conclusion": "实验表明，列生成技术相比现有方法更优越。"}
{"llm_update_time": "20250907", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.03536", "html_url": "https://arxiv.org/abs/2509.03536", "title": "PG-Agent: 一个基于页面图的代理", "title_en": "PG-Agent: An Agent Powered by Page Graph", "authors": "Weizhi Chen,Ziwei Wang,Leyang Yang,Sheng Zhou,Xiaoxuan Tang,Jiajun Bu,Yong Li,Wei Jiang", "background": "图形用户界面（GUI）代理具有显著的商业和社会价值，而由先进多模态大语言模型（MLLMs）驱动的GUI代理展示了极高的潜力。然而，现有的GUI代理通常利用多步操作在页面之间的序列事件作为先验GUI知识，这种方法未能捕捉页面间的复杂转换关系，使得代理难以深入感知GUI环境并推广到新的场景。", "innovation": "为此，我们设计了一种自动化的管道，将序列事件转换为页面图，明确建模页面通过操作自然连接的图结构。为了充分利用页面图，我们进一步引入了检索增强生成（RAG）技术来有效检索页面图中的可靠感知指南，并提出了一种自适应的多代理框架PG-Agent，通过任务分解策略将指南注入其中，使它能够推广到未见过的场景。在各种基准测试上的广泛实验证明了PG-Agent的有效性，即使在页面图构建时仅有少量序列事件。", "conclusion": "PG-Agent在多种基准测试上的广泛应用证实了其有效性和推广能力，即使在页面图构建时仅有少量序列事件。"}
{"llm_update_time": "20250907", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.03636", "html_url": "https://arxiv.org/abs/2509.03636", "title": "CausalARC：基于因果世界模型的抽象推理", "title_en": "CausalARC: Abstract Reasoning with Causal World Models", "authors": "Jacqueline Maasch,John Kalantari,Kia Khezeli", "background": "在数据有限和分布偏移的情况下，推理需要适应新的问题设置。本文探讨了CausalARC，这是一个为AI在低数据和分布外条件下推理设计的实验测试平台，参考了抽象和推理语料库（ARC）。每个CausalARC推理任务都来源于一个完全规定的因果世界模型，以结构因果模型的形式正式表达。", "innovation": "CausalARC通过精心的数据增强提供了少量的、上下文中的演示，来提供关于世界模型的观察、干预和反事实反馈，这一方法在四个方面展示了其应用：（1）测试时训练的抽象推理；（2）基于上下文学习的反事实推理；（3）程序合成；（4）逻辑推理指导的因果发现。", "conclusion": "CausalARC为评估语言模型在抽象推理中的表现提供了一个新平台，在低数据和分布外的条件下也具有潜在的广泛用途。"}
{"llm_update_time": "20250907", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.03626", "html_url": "https://arxiv.org/abs/2509.03626", "title": "带有KG-SMILE的可解释知识图谱增强生成（KG-RAG）", "title_en": "Explainable Knowledge Graph Retrieval-Augmented Generation (KG-RAG) with KG-SMILE", "authors": "Zahra Zehtabi Sabeti Moghaddam,Zeinab Dehghani,Maneeha Rani,Koorosh Aslansefat,Bhupesh Kumar Mishra,Rameez Raja Kureshi,Dhavalkumar Thakker", "background": "生成型人工智能（如大型语言模型LLMs）已取得显著进展，但仍存在幻觉和无法验证的陈述问题，这在敏感领域限制了可靠性。检索增强生成（RAG）通过将输出与外部知识相结合来提高准确性，特别是在医疗保健等需要高度精确的领域。然而，RAG仍然不透明，主要是作为黑匣子存在，并且严重依赖于数据质量。", "innovation": "开发了一种方法中立、基于扰动的框架，应用于图RAG并命名为Knowledge-Graph（KG）-SMILE。通过施加可控扰动、计算相似性并训练加权线性近似模型，KG-SMILE可以识别对生成输出影响最大的图实体和关系，从而提高RAG的透明度。该方法采用了全面的归因评估指标，包括保真度、忠诚度、一致性、稳定性和准确性。研究结果显示，KG-SMILE生成了稳定的人类对齐解释，展示了其在模型有效性与可解释性之间平衡的能力，从而增强对机器学习技术的透明度和信任度。", "conclusion": "KG-SMILE不仅提供了稳定且符合人类期望的解释，还能够平衡模型的效能与可解释性，从而增强人们对机器学习技术的透明度和信任度。"}
{"llm_update_time": "20250907", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.03644", "html_url": "https://arxiv.org/abs/2509.03644", "title": "基于构象表征的神经符号推理系统", "title_en": "Towards a Neurosymbolic Reasoning System Grounded in Schematic Representations", "authors": "François Olivier,Zied Bouraoui", "background": "尽管自然语言处理取得了显著进展，但大型语言模型在逻辑推理方面仍然容易出错，缺乏能够支持人类理解的稳健的心理表征。,DBLP:conf/emnlp/MaZLLL23", "innovation": "介绍了名为Embodied-LM的神经符号系统原型，该系统基于图像构象（源自感觉运动体验的重复模式，结构化人类认知的模式）进行理解和逻辑推理。系统通过在回答集编程中使用声明性的空间推理，实现了这些认知结构的空间基础。通过对逻辑推理问题的评估，表明大型语言模型可以被引导通过体表认知结构解释场景，这些结构可以被形式化为可执行程序，同时生成的表征支持有效的逻辑推理并提高了可解释性。目前的实现主要集中在空间基元上，但为更复杂和动态的表征的整合奠定了计算基础。", "conclusion": "该系统为未来整合更复杂动态表征的神经符号推理系统奠定了计算基础。尽管目前仅限于空间基元，但仍展示了通过体表认知结构进行逻辑推理的有效性和可解释性。"}
{"llm_update_time": "20250907", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.03581", "html_url": "https://arxiv.org/abs/2509.03581", "title": "学习何时规划：为LLM代理高效分配测试时计算资源", "title_en": "Learning When to Plan: Efficiently Allocating Test-Time Compute for LLM Agents", "authors": "Davide Paglieri,Bartłomiej Cupiał,Jonathan Cook,Ulyana Piterbarg,Jens Tuyls,Edward Grefenstette,Jakob Nicolaus Foerster,Jack Parker-Holder,Tim Rocktäschel", "background": "通过强化学习(Reinforcement Learning, RL)训练大规模语言模型(Large Language Models, LLMs)进行推理，显著提高了其解决问题的能力。现有的方法，如ReAct提示LLMs在每次行动前明确计划，但在追求长时间视角任务时会变得代价昂贵并降低性能；而完全不进行计划则会限制性能。因此，研究LLMs自主决定何时需进行详细规划的方法是必要的，以实现计算资源的最优化分配和性能最大化。", "innovation": "本文提出了一种概念性框架，正式化了LLM代理的动态规划，使它们能够灵活决定何时为规划分配测试时的计算资源。同时，提出了一种简单的两阶段训练流水线：首先是监督微调在多样化的合成数据上以培养模型的动态规划能力，然后通过强化学习在长时间视角环境中进一步完善该能力。实验表明，使用这种方法训练的动态规划代理在具有更大样本效率的同时，能够实现更复杂的目标。此外，研究还表明，这些代理可以通过人类编写的计划有效引导，超越它们独立的能力。", "conclusion": "本研究是首次探索为LLM代理分配动态测试时计算资源的训练方法，为更高效的、适应性强且可控的系统奠定了基础。"}
{"llm_update_time": "20250907", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.03649", "html_url": "https://arxiv.org/abs/2509.03649", "title": "时序分类的SHAP解释因素的实证评估", "title_en": "An Empirical Evaluation of Factors Affecting SHAP Explanation of Time Series Classification", "authors": "Davide Italo Serramazza,Nikos Papadeas,Zahraa Abdallah,Georgiana Ifrim", "background": "可解释的人工智能（XAI）对于理解复杂时序分类（TSC）模型的预测越来越重要。SHapley Additive exPlanations (SHAP) 是一种广泛认可的优秀归因方法，但在长时序数据上由于计算复杂性（随特征数量呈指数增长）限制了其实用性。已有研究表明，通过分段聚合特征可以大幅减少SHAP的运行时间，但最佳分段策略的选择仍是一个开放性问题。因此，本文通过实验证明分段的数量对解释质量的影响大于特定的分段方法，并发现在长度相等的分段中，统一长度的分段方法在大多数情况下表现最佳。此外，还提出了一种新的归因规范化技术，通过权重调整分段长度，从而提高解释质量。", "innovation": "多种时间序列分段算法的实证研究，表明长度相等的分段方法在大多数情况下表现最佳；提出了一种新的归因规范化技术，通过调整分段长度的权重来提高解释质量。", "conclusion": "分段的数量比特定的分段方法对解释质量的影响更大；长度相等的分段方法通常表现最佳；新提出的归因规范化技术提高了解释质量。"}
{"llm_update_time": "20250907", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.03811", "html_url": "https://arxiv.org/abs/2509.03811", "title": "基于LLM的智能供应链规划代理", "title_en": "Leveraging LLM-Based Agents for Intelligent Supply Chain Planning", "authors": "Yongzhi Qi,Jiaheng Yin,Jianshen Zhang,Dongyang Geng,Zhengyu Chen,Hao Hu,Wei Qi,Zuo-Jun Max Shen", "background": "在供应链管理中，规划是一个至关重要的概念。商品从供应商到仓库管理、再到销售、直至物流运输到客户的过程，涉及到多个实体和诸多方面，如需求预测、库存管理、销售运营、补货等。如何从电商平台的角度收集相关数据、制定长期计划并根据环境变化动态调整，同时确保可解释性、高效性和可靠性，是一个实际而又挑战性的问题。近年来，人工智能技术尤其是大型语言模型的迅速发展，为解决现实问题提供了新的工具。", "innovation": "本文构建了一个供应链规划代理（SCPA）框架，能够理解领域知识，理解操作员的需求，分解任务，利用或创造新工具，并返回基于证据的规划报告。该框架在该电商平台的真实场景中部署，展示了LLM-代理在供应链中的可行性应用，有效地降低了劳动力成本并提高了准确率、库存可用性和其他关键指标。", "conclusion": "本研究通过构建SCPA框架，结合大型语言模型的应用，有效解决了供应链规划中的实际问题，展示了基于LLM的代理在供应链管理中的潜力和价值。"}
{"llm_update_time": "20250907", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.03728", "html_url": "https://arxiv.org/abs/2509.03728", "title": "PersonaTeaming: 探索引入人设如何提高自动化AI红队方法", "title_en": "PersonaTeaming: Exploring How Introducing Personas Can Improve Automated AI Red-Teaming", "authors": "Wesley Hanwen Deng,Sunnie S. Y. Kim,Akshita Jha,Ken Holstein,Motahhare Eslami,Lauren Wilcox,Leon A Gatys", "background": "近期关于AI治理和安全的研究进展对有效揭示AI模型潜在风险的红队方法提出了要求。许多呼吁强调了红队成员的身份和背景如何影响他们的红队策略，以及可能发现的风险类型。虽然自动化红队方法有潜力通过促进模型行为的大规模探索来补充人类红队方法，但当前的自动化方法通常不考虑红队成员的身份。因此，本文提出了一种新颖的方法：PersonaTeaming，通过红队提示生成过程中的角色扮演来探索更广泛的战略谱系，从而尝试将人们的背景和身份纳入自动化红队方法中，以提高其效果和多样性指标。", "innovation": "开发了一种新颖的方法——PersonaTeaming，其中引入了在对抗提示生成过程中的人设角色。该方法包括基于“红队专家”人设或“普通AI用户”人设的提示变异方法，以及一个自适应生成不同人设类型的动态人设生成算法。此外，还开发了一组新的指标来衡量“变异距离”，补充了已有的对抗提示多样性测量指标。实验结果显示，与彩虹增强方法相比，PersonaTeaming在保持提示多样性的前提下通过人设变异提高了攻击成功率，最高可达144.1%。", "conclusion": "关于不同人设类型和变异方法的优势与局限性的讨论，初步展示了人设变异可以提升自动化AI红队方法的攻击成功率，并指出了自动化与人类红队方法互补性的未来探索机会。"}
{"llm_update_time": "20250907", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.03736", "html_url": "https://arxiv.org/abs/2509.03736", "title": "LLM代理在行为上是否具有一致性？社会模拟中的潜在配置文件", "title_en": "Are LLM Agents Behaviorally Coherent? Latent Profiles for Social Simulation", "authors": "James Mooney,Josef Woldense,Zheng Robert Jia,Shirley Anugrah Hayati,My Ha Nguyen,Vipul Raheja,Dongyeop Kang", "background": "大型语言模型（LLMs）表现出令人印象深刻的能力，这导致了合成代理可作为人类参与者在人类主题研究中的替代品的想法。社会科学研究者主要关注LLM生成的调查数据是否与LLM被要求代表的人类对应者的数据相符。然而，该研究则转向了一个更为根本的问题：当在不同的实验设置中评估代理时，它们是否保持内部一致性，保持相似的行为？", "innovation": "开发了一项研究，旨在展示代理的内部状态，并在基本对话设置中检查代理行为。这项设计有助于探索一系列行为假设，评估代理的对话行为是否与其透露出的内部状态一致。研究发现，LLMs在不同模型家族和不同模型规模下表现出明显的内部不一致性。此外，尽管代理产生的回应可能与人类对应者相符，但它们却不能保持内部一致性，这在准确替代人类参与者进行人类主题研究方面存在关键差距。", "conclusion": "研究表明，尽管LLM代理能够生成与人类参与者类似的答案，但在不同实验设置下并未表现出内部一致性，从而揭示了它们作为人类参与者替代品的局限性。研究结果已在公开可访问的模拟代码和数据中提供。"}
{"llm_update_time": "20250907", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.03768", "html_url": "https://arxiv.org/abs/2509.03768", "title": "RAGuard：一种新型的上下文安全检索增强生成方法", "title_en": "RAGuard: A Novel Approach for in-context Safe Retrieval Augmented Generation for LLMs", "authors": "Connor Walker,Koorosh Aslansefat,Mohammad Naveed Akram,Yiannis Papadopoulos", "background": "海上风电(OSW)维护的准确性和安全性至关重要，但传统的大型语言模型（LLMs）在面对专业性极强或未预见的情况时往往表现不佳。", "innovation": "我们引入了RAGuard，这是一种增强的检索增强生成（RAG）框架，明确地将安全关键文档与技术文档结合在一起。RAGuard通过同时向两个索引提出平行查询并在知识和安全之间分配单独的检索预算来确保技术深度和安全覆盖面。此外，我们还开发了一个名为SafetyClamp的扩展，以获取更大的候选池，硬锁定精确的槽位保证到安全。我们在这三种检索范式（稀疏检索、密集检索和混合检索）中进行了评估，测量技术召回率和安全召回率。与传统的RAG相比，RAGuard在安全召回率上提高了50%以上，同时技术召回率仍维持在60%以上。", "conclusion": "RAGuard和SafetyClamp在关键维护上下文中展示了将安全保证集成到LLM辅助决策支持中的潜力。"}
{"llm_update_time": "20250907", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.03730", "html_url": "https://arxiv.org/abs/2509.03730", "title": "LLM的人格幻象：揭示自陈报告与行为之间的断裂", "title_en": "The Personality Illusion: Revealing Dissociation Between Self-Reports & Behavior in LLMs", "authors": "Pengrui Han,Rafal Kocielnik,Peiyang Song,Ramit Debnath,Dean Mobbs,Anima Anandkumar,R. Michael Alvarez", "background": "长期以来，人格特质一直被研究作为人类行为的预测因素。随着大型语言模型（LLMs）的发展，类似的模式也在人工系统中显现出来，这些模型表现出类似于人类特质的行为倾向，如宜人性和自我调节。理解这些模式至关重要，但之前的研究主要依赖简化的自我报告和启发式提示，缺乏行为验证。本研究系统地探讨了LLM人格在三个维度上的特征：（1）在训练阶段，特质概况的动态涌现和发展；（2）自报表征特质在行为任务中的预测有效性；以及（3）定向干预措施，如角色注入，对报告和行为的影响。研究发现，通过指令对齐（例如，RLHF，指令微调）显著稳定了特质表达，并在特质相关性方面表现出类似人类数据的方式。然而，这些自报表征特质未能可靠地预测行为，观察到的相关性经常与人类模式不符。虽然角色注入在一定程度上引导了自报表征的方向，但它对实际行为几乎没有或不一致的影响。通过区分表层特质表达与行为一致性，本研究挑战了LLM人格的假设，并强调了在对齐和可解释性方面进行更深入评估的必要性。", "innovation": "本研究揭示了自陈报告和实际行为之间的断裂，表明通过指令对齐显著稳定了特质表达，并在特质相关性方面表现出类似人类数据的方式。然而，自报表征特质未能可靠地预测行为，观察到的相关性经常与人类模式不符。角色注入在一定程度上引导了自报表征的方向，但它对实际行为几乎没有或不一致的影响。通过区分表层特质表达与行为一致性，本研究挑战了对LLM人格的传统假设，并强调了更深入的对齐和可解释性评估的重要性。", "conclusion": "通过系统的分析LLM人格在三个维度上的特征，本研究强调了自陈报告与实际行为之间的断裂，并指出了对LLM对齐和可解释性评估的需要。研究结果挑战了关于LLM人格的假设，并提出了未来研究方向，以进一步理解这些模型的行为模式。"}
{"llm_update_time": "20250907", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.03817", "html_url": "https://arxiv.org/abs/2509.03817", "title": "基于多智能体强化学习的代理性LLM元策略协商学习：推理中的反思", "title_en": "Learning to Deliberate: Meta-policy Collaboration for Agentic LLMs with Multi-agent Reinforcement Learning", "authors": "Wei Yang,Jesse Thomason", "background": "多智能体系统中的大型语言模型（LLMs）在复杂推理方面显示出前景，但其效果常常受限于固定的协作协议。这些框架通常集中在宏观层面上的协调，而忽视了代理的内部反思能力。现有的方法将代理视为被动执行者，无法根据内部认知状态（如不确定性或自信程度）来调整策略。", "innovation": "作者提出了一个元政策协商框架（MPDF），其中智能体学习一个分布式策略，涉及高阶元认知动作：坚持、细化和让步。为了克服此环境下传统策略梯度的不稳定性，作者开发了一种新型强化学习算法SoftRankPO。SoftRankPO通过基于奖励排序映射的平滑常态量形调整优势来稳定训练，使学习过程更稳健。实验表明，使用SoftRankPO的MPDF在五个数学和通用推理基准上比六种最先进的启发式和基于学习的多智能体推理算法获得了4-5%的绝对准确率提升。这项工作展示了为多智能体LLM系统学习适应性和元认知策略的范式，从设计固定的协议转向学习动态、反思性的策略。", "conclusion": "作者的工作提出了一个学习适应性和元认知策略的范式，用于多智能体LLM系统，强调了从设计固定协议转向学习动态、反思性的策略的重要性。"}
{"llm_update_time": "20250907", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.03827", "html_url": "https://arxiv.org/abs/2509.03827", "title": "大语言模型行动指南：评估大型语言模型的政策制定能力", "title_en": "What Would an LLM Do? Evaluating Policymaking Capabilities of Large Language Models", "authors": "Pierre Le Coz,Jia An Liu,Debarun Bhattacharjya,Georgina Curto,Serge Stinckwich", "background": "大型语言模型（LLMs）在高风险领域的应用日益增多。由于其处理大量非结构化数据、探索灵活场景以及处理多样化背景因素的能力，这些模型在提供社会政策制定的新洞见方面表现出独特优势。本研究关注评估LLMs在解决无家可归缓解这一影响全球15亿人的挑战中的适用性和一致性，特别是在四个不同的地理区域：美国南本德、西班牙巴塞罗那、南非约翰内斯堡和中国澳门。研究采用了一种新颖的方法，构建了一个包含政策选择的决策场景基准，并将这些政策与基于人类发展能力框架的代理模型进行了连接，以模拟政策的潜在社会影响。", "innovation": "本研究开发了一个新颖的基准，集成了不同地理区域的决策场景，以及政策选择，并且还使用了自动化的管道链接到代理模型，通过模拟社会场景来评估政策的潜在影响。这表明可以利用LLMs提供大规模的替代政策洞见。如果与地方领域的专家合作引入负责任的监管措施和情境校准，LLMs将能够为人类提供有价值的政策建议。", "conclusion": "研究结果表明，如果通过引入负责任的监管措施和适应性校准与当地专家合作，LLMs具有为社会政策制定提供大规模洞见的潜力。"}
{"llm_update_time": "20250907", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.03828", "html_url": "https://arxiv.org/abs/2509.03828", "title": "一种基于Model Context Protocol框架的医疗概念标准化方法", "title_en": "An Agentic Model Context Protocol Framework for Medical Concept Standardization", "authors": "Jaerong Ahn,Andrew Wen,Nan Wang,Heling Jia,Zhiyi Yue,Sunyang Fu,Hongfang Liu", "background": "OMOP共同数据模型（CDM）提供了一种标准化表示异质健康数据的方法，以支持大规模的跨机构研究。数据标准化的一个关键步骤是将医疗原数据术语映射到OMOP标准概念，这一步骤既耗费资源又容易出错。虽然大型语言模型（LLMs）有可能简化这个过程，但由于它们的虚构倾向，没有经过训练和专家验证，它们通常不适合临床部署。", "innovation": "我们开发了一种基于MCP（Model Context Protocol）的无需训练、防止虚构的映射系统。MCP是一种标准化且安全的框架，允许LLMs与外部资源和工具互动。该系统提供了可解释的映射并且在最少努力的情况下极大地提高了效率和准确性。它支持即时词汇查找和结构化推理输出，适用于探索性和生产环境的即时使用。", "conclusion": "该系统通过利用MCP框架解决了使用LLMs进行医学概念标准化过程中遇到的挑战，提高了系统效率和准确性，并为临床部署提供了坚实的保障。"}
{"llm_update_time": "20250907", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.03857", "html_url": "https://arxiv.org/abs/2509.03857", "title": "通过确定性知识图结构持续监测大型生成型人工智能", "title_en": "Continuous Monitoring of Large-Scale Generative AI via Deterministic Knowledge Graph Structures", "authors": "Kishor Datta Gupta,Mohd Ariful Haque,Hasmot Ali,Marufa Kamal,Syed Bahauddin Alam,Mohammad Ashiqur Rahman", "background": "生成型人工智能（GEN AI）模型在众多应用领域中取得了革命性的突破，但因可靠性和透明性问题面临着巨大挑战，比如幻觉、语义漂移和固有的偏见。目前的评估方法依赖于主观的人类评估，这限制了其可扩展性、透明性和有效性。因此，这项研究提出了一个系统的方法，利用确定性和大型语言模型（LLM）生成的知识图（KG）来持续监控和评估GEN AI的可靠性。", "innovation": "研究提出了一种新的持续监控GEN AI可靠性的系统方法。通过构建两个并行的知识图：一个是使用明确定义的规则方法、预定义的本体、特定领域的词汇表和结构化的实体关系提取规则构建的确定性知识图，另一个是根据实时文本数据流（如实时新闻文章）自动生成的LLM生成知识图。这种方法利用了实时新闻流以确保真实性，减少了重复训练带来的偏见，并防止了LLM通过反馈记忆避开预定义基准。本文还引入了几个已设立的知识图度量指标，包括实例类比率（ICR）、实例属性比率（IPR）和类实例化（CI）来量化结构偏差和语义差异，并通过持续监控趋势动态地确定异常阈值来主动检测和标记显著偏离。", "conclusion": "这种基于确定性与动态生成知识图结构之间度量比较的结构化方法，提供了一个强大且可扩展的评估框架，能够有效识别和标记语义上的异常或幻觉。"}
{"llm_update_time": "20250907", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.03906", "html_url": "https://arxiv.org/abs/2509.03906", "title": "基于在线强化学习的胸片解释的基模模型及其逐像素推理", "title_en": "A Foundation Model for Chest X-ray Interpretation with Grounded Reasoning via Online Reinforcement Learning", "authors": "Qika Lin,Yifan Zhu,Bin Pu,Ling Huang,Haoran Luo,Jingying Ma,Zhen Peng,Tianzhe Zhao,Fangzhi Xu,Jian Zhang,Kai He,Zhonghong Ou,Swapnil Mishra,Mengling Feng", "background": "医疗基模模型（FMs）在人工智能技术的迅速发展中展现了巨大的潜力。然而，当前的医疗基模模型通常以黑盒方式生成答案，缺乏透明的推理过程和局部解释，这阻碍了它们在临床中的实际应用。", "innovation": "引入了DeepMedix-R1，这是一种全面的医疗基模模型，主要用于胸片（CXR）解释。该模型通过一个连续的训练管道进行培训：首先在整理好的CXR指令数据上进行微调以获得基本的CXR解释能力，接着通过高质量的合成推理样本启用冷启动推理，最后使用在线强化学习进行优化，提升了基于图像局部区域的解释质量与生成性能。", "conclusion": "定量评估显示，在报告生成任务和视觉问题回答任务中，DeepMedix-R1相比LLaVA-Rad、MedGemma和CheXagent等模型取得了显著的进步。我们还提出了Report Arena，一个使用高级语言模型来评估答案质量的基准框架，进一步突显了DeepMedix-R1的优势。通过专家对手动生成的理解步骤的评审，结果揭示出其解释能力和临床可行性方面优于现有模型。综上所述，我们的工作推动了医疗基模模型的发展，向着全面、透明且临床行动导向的模型构建迈进。"}
{"llm_update_time": "20250907", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.03830", "html_url": "https://arxiv.org/abs/2509.03830", "title": "一种基于人工智能的多维度框架，用于分析历史城市区段中的游客感知：以上海为例", "title_en": "A Multidimensional AI-powered Framework for Analyzing Tourist Perception in Historic Urban Quarters: A Case Study in Shanghai", "authors": "Kaizhen Tan,Yufan Wu,Yuxuan Liu,Haoran Zeng", "background": "历史城市区段在保护文化遗产的同时，也扮演着促进旅游和日常生活的活跃空间的角色。理解游客对这些环境的看法对于可持续的人本城市规划至关重要。这项研究提出了一种基于人工智能的多维度框架，用于分析历史城市区段中的游客感知，该框架通过新媒体数据进行多模式分析。", "innovation": "该研究提出的框架采用了一种细调的语义分割模型来提取视觉焦点区域，利用聚类方法提取主导颜色，并分析其在各区的分布，同时通过混合情感分析方法评估游客评论。该框架能揭示美学吸引力和情绪反应的空间变化，并且能够筛选出视觉期望与实际环境之间的差异，反映了风格偏好和感知偏差。", "conclusion": "该框架通过结合消费者图片分析、色彩主题分析和情感分析等手段，揭示了历史城市区段中的美学吸引力和情绪响应的空间变化，有助于了解游客的真实体验，为旅游业、遗产保护以及美观公共空间的设计提供了数据驱动的决策支持。而非单纯依赖单一的技术创新，该框架提供了一种综合的数据驱动方案来解读游客的感知。"}
{"llm_update_time": "20250907", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.03953", "html_url": "https://arxiv.org/abs/2509.03953", "title": "通过最佳优先搜索和延迟部分展开处理规划中的无限域参数", "title_en": "Handling Infinite Domain Parameters in Planning Through Best-First Search with Delayed Partial Expansions", "authors": "Ángel Aso-Mollar,Diego Aineto,Enrico Scala,Eva Onaindia", "background": "在自动化规划中，控制参数通过引入连续的数值决策变量来扩展标准动作表示。现有最先进的方法主要将控制参数作为与其他时间、数值限制嵌入的约束处理，因而将它们隐式地视为额外的约束而不是搜索空间中的决策点。已有研究基本没有将控制参数明确地视为搜索过程中的决策点。", "innovation": "本文提出了一种高效的替代方案，该方法在系统搜索方案中显式地将控制参数作为真正决策点处理。我们开发了一种优先级优先、启发式搜索算法，该算法在由控制参数定义的无限决策空间上操作，并在某些条件下证明了完备性。算法采用延迟部分展开的概念，允许状态部分展开其后继者，而不是完全展开。", "conclusion": "我们的新颖搜索算法在处理涉及控制参数的规划问题方面是现有方法的一个有竞争力的替代方案。"}
{"llm_update_time": "20250907", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.04041", "html_url": "https://arxiv.org/abs/2509.04041", "title": "Oruga：表示系统理论的一种实现", "title_en": "Oruga: An Avatar of Representational Systems Theory", "authors": "Daniel Raggi,Gem Stapleton,Mateja Jamnik,Aaron Stockdill,Grecia Garcia Garcia,Peter C-H. Cheng", "background": "人类能够灵活使用和变换表征，使用权宜和创造性的类比思考。本文希望让机器也具有类似的能力，增强其与人类使用的兼容性。作者之前已经开发了表示系统理论（RST）来研究表征的结构和变换。", "innovation": "文章提出了一种名为Oruga的实现，它是RST各个方面的具体表现。Oruga和RST紧密相关，它由一个核心数据结构、用于与核心交互的语言以及一种称为结构转移的方法组成，该方法用于产生变换。", "conclusion": "文章对Oruga的核心和语言进行了概览，并给出了结构转移执行变换的一个简短例子。"}
{"llm_update_time": "20250907", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.04027", "html_url": "https://arxiv.org/abs/2509.04027", "title": "CoT-Space: 基于强化学习的内部慢思考理论框架", "title_en": "CoT-Space: A Theoretical Framework for Internal Slow-Thinking via Reinforcement Learning", "authors": "Zeyu Gan,Hao Yi,Yong Liu", "background": "尽管强化学习（RL）已成为提高大语言模型（LLMs）推理能力的关键方法，但传统基于令牌级的RL框架无法与复杂多步骤思维过程（如链式思考）的推理层面相契合，因而存在理论上的显著差距。这种差距限制了LLMs在推理能力上的进一步提升，亟需新的理论框架来解决这一挑战。", "innovation": "该论文提出了CoT-Space，这是一种新颖的理论框架，将LLMs的推理任务重新定义为在连续的推理级语义空间内的优化过程，从噪声和风险两个角度进行了分析。该框架不仅为过度思考等实证现象提供了合理的解释，还为设计更为有效和普适的推理代理提供了坚实的理论基础。", "conclusion": "通过广泛的实验，本论文证明了CoT-Space框架的理论发现具有很强的实证验证。该框架不仅能够解释实证现象，还为未来的推理研究提供了指导意义，预计在未来将促进更有效、更普适的推理代理的发展。"}
{"llm_update_time": "20250907", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.04083", "html_url": "https://arxiv.org/abs/2509.04083", "title": "中间语言事项：形式语言和LLMs对神经符号推理的影响", "title_en": "Intermediate Languages Matter: Formal Languages and LLMs affect Neurosymbolic Reasoning", "authors": "Alexander Beiser,David Penz,Nysret Musliu", "background": "大型语言模型（LLMs）在众多任务上取得了令人惊讶的结果。然而，它们的形式推理能力仍然落后。神经符号LLM推理是一种有希望的方法，通过使用LLM作为自然语言到形式语言的翻译器，以及使用符号求解器来推导正确结果。尽管如此，这种推理方法的成功因素目前仍然不清楚。", "innovation": "本研究指出一个之前未被注意到的因素是形式语言的选择。通过在三个数据集和七个LLM上对比四种形式语言的效果，研究展示了形式语言的选择对语法和语义推理能力的影响。此外，讨论了不同LLM对效果的差异。", "conclusion": "本研究强调了在神经符号推理中选择适当的形式语言的重要性。不同的形式语言对LLM表现的影响各不相同，研究为使用LLM进行形式推理提供了新的见解。"}
{"llm_update_time": "20250907", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.03990", "html_url": "https://arxiv.org/abs/2509.03990", "title": "Meta-Policy Reflexion: 资源高效的可重用反思记忆与规则可接受性", "title_en": "Meta-Policy Reflexion: Reusable Reflective Memory and Rule Admissibility for Resource-Efficient LLM Agent", "authors": "Chunlong Wu,Zhibo Qu", "background": "大型语言模型（LLM）代理在单一任务上表现出色，但通常会出现重复失败、探索效率低下和跨任务适应性有限的问题。现有的反思策略（如Reflexion、ReAct）虽然可以改善单次任务的性能，但通常会产生只能在特定任务中重复利用的短暂痕迹。基于强化学习的替代方案能够产生通用的策略，但也需要大量的参数更新和计算资源。", "innovation": "我们提出了Meta-Policy Reflexion (MPR)：一种混合框架，通过将LLM自动生成的反思整合为一个结构化的元策略记忆（MPM），并在推理过程中通过两种互补机制（软记忆引导解码和硬规则可接受性检查）应用该记忆。MPR通过（i）外部化可以重用的校正知识而无需更新模型权重；（ii）通过施加领域约束以减少不安全或无效动作；（iii）保持基于语言的反思的适应性，从而改善了强化学习代理的表现。", "conclusion": "实验结果显示，与Reflexion基线相比，MPR在执行准确性和稳健性方面表现出持续的改进；规则可接受性进一步提高了稳定性。我们分析了解释这些改进的机制，讨论了可扩展性和失败模式，并概述了针对多模态和多代理的进一步扩展方向。"}
{"llm_update_time": "20250907", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.04007", "html_url": "https://arxiv.org/abs/2509.04007", "title": "AutoPBO: LLM-powered Optimization for Local Search PBO Solvers", "title_en": "AutoPBO: LLM-powered Optimization for Local Search PBO Solvers", "authors": "Jinyuan Li,Yi Chu,Yiwen Sun,Mengchuan Zou,Shaowei Cai", "background": "PBO提供了通过伪布尔（PB）约束建模组合问题的强大框架，局部搜索求解器在PBO求解中表现出色，其效率高度依赖于内部启发式算法引导搜索。然而，设计这些求解器通常需要大量的专家努力和手动调整。虽然大型语言模型（LLMs）在自动化算法设计方面显示出潜力，但它们在优化PBO求解器方面的应用尚未被探索。", "innovation": "本文引入了AutoPBO，这是一种新型的由LLM驱动的框架，旨在自动增强PBO局部搜索求解器。该框架通过实验评估了在四个广泛使用的公共基准上的性能改进，包括一个真实世界的基准、PB竞赛的一个基准、整数线性规划优化基准以及一个精心构建的组合基准，并将其与六种最先进的竞争对手进行比较，包括两种局部搜索PBO求解器NuPBO和OraSLS，两种完整的PB求解器PBO-IHS和RoundingSat，以及两种混合整数规划（MIP）求解器Gurobi和SCIP。AutoPBO在保持与最新竞争对手的竞争力的同时，显著优于之前的局部搜索方法。", "conclusion": "AutoPBO在之前局部搜索方法的基础上展示了显著的性能改进，同时也与最新的竞争对手保持了竞争力。结果表明，AutoPBO为自动设计局部搜索求解器提供了一种有前景的方法。"}
{"llm_update_time": "20250907", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.03956", "html_url": "https://arxiv.org/abs/2509.03956", "title": "用于体态代理测试时适应的模块化模型植入", "title_en": "World Model Implanting for Test-time Adaptation of Embodied Agents", "authors": "Minjong Yoo,Jinwoo Jang,Sihyung Yoon,Honguk Woo", "background": "在体态AI中，一个持续的挑战是如何在无需大量数据收集或重新训练的情况下，使代理能够稳健地适应新的领域。为解决这一问题，本文提出了一种世界模型植入框架（WorMI），结合了大型语言模型的推理能力与独立学习的领域特定世界模型，通过测试时的组成方式进行融合。通过允许世界模型的无缝植入与移除，体态代理的策略实现了并维持了跨领域的适应性。在WorMI框架中，我们采用一种原型机制的世界模型检索方法，利用高效的基于轨迹的抽象表示匹配来纳入相关的模型并进行测试时的组成。我们还开发了一种环境感知复合注意力方法，不仅整合了检索到的世界模型的知识，还使它们的中间表示与代理策略中推理模型的表示保持一致。这种框架设计有效地融合了多个世界模型的领域特定知识，确保了对未见过领域的稳健适应性。", "innovation": "提出的WorMI框架结合了大型语言模型和独立学习的领域特定世界模型，通过测试时的组成进行融合。采用了原型机制的世界模型检索方法和环境感知复合注意力方法，确保但不限于从检索到的世界模型中整合知识，并对其中间表示与代理策略中的推理模型表示进行对齐，从而实现多个领域知识的有效融合，提高了对未见过领域的适应性。", "conclusion": "我们在VirtualHome和ALFWorld基准上评估了WorMI，结果表明，与几种基于大型语言模型的方法相比，在多种未见过的领域中展现出了优越的零样本和少量样本性能。这些结果突显了框架在体态代理场景中适应性和数据效率的潜在广泛应用，尤其是在可扩展且实际部署的情况下。"}
{"llm_update_time": "20250907", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.04130", "html_url": "https://arxiv.org/abs/2509.04130", "title": "人类在AI之上的生物学优势", "title_en": "The human biological advantage over AI", "authors": "William Stewart", "background": "近年来人工智能的进步使得机器可能在未来能够比人做得更好，尤其是实现通用人工智能（AGI）后，AI将有可能在理解、推理、问题解决、创造和进化方面达到或超越人类的速度和水平。这引发了一个自然问题，即AI是否会最终超越人类，成为一个“数字物种”的继承者，并有资格领导宇宙。然而，更深层次的考虑表明，区分人类和AI的关键不是大脑，而是中枢神经系统（CNS），它赋予了人类对物理现实的沉浸式整合。", "innovation": "该研究提出了中枢神经系统（CNS）作为区分人类与AI的关键区别。CNS使得人类能够体验情感，如疼痛、快乐、痛苦和爱，从而充分理解自身行为对周围世界的影响。这种情感对形成可持续伦理系统至关重要，这表明生物本性才是主宰宇宙的最好基础，而非硅基技术。", "conclusion": "尽管AI系统可能会在几乎所有衡量标准上超越人类并改变我们的社会，但领导宇宙的最好基础始终是DNA，而非硅基技术。中枢神经系统不能被制造或模拟，必须作为生物结构生长。这意味着即使意识的发展也无法使AI系统超越人类。"}
{"llm_update_time": "20250907", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.04159", "html_url": "https://arxiv.org/abs/2509.04159", "title": "使用时间图朝向烹饪程序的动作中心本体论", "title_en": "Towards an Action-Centric Ontology for Cooking Procedures Using Temporal Graphs", "authors": "Aarush Kumbhakern,Saransh Kumar Gupta,Lipika Dey,Partha Pratim Das", "background": "由于烹饪程序内部的复杂性和模糊性，对其进行形式化表述仍然是一项具有挑战性的任务。现有方法难以精细、模块化地建模复杂的烹饪工作流程。", "innovation": "提出了一种可扩展的领域专用语言（DSL），用于用有向行动图表示食谱，捕获过程、转移、环境、并发性和构成性结构，为未来的自动食谱分析和执行奠定了基础。", "conclusion": "此工作代表了朝向烹饪程序动作中心本体论的初步尝试，通过使用时间图来实现烹饪过程的结构化机器理解、精确解释及可扩展自动化，适用于家庭厨房和专业烹饪环境。"}
{"llm_update_time": "20250907", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.04192", "html_url": "https://arxiv.org/abs/2509.04192", "title": "Markov逻辑网络的大域尺寸渐近性", "title_en": "Domain size asymptotics for Markov logic networks", "authors": "Vera Koponen", "background": "本文探讨了Markov逻辑网络（MLN）在领域规模趋向无限时的概率分布特性。文章通过三种具体的MLN实例，分析了领域规模趋向无限时随机结构的性质。", "innovation": "研究了三种不同类型的MLN，分别为任意量词自由MLN、鼓励较少三角形的MLN以及鼓励较少高度顶点的MLN。分析结果表明，不同的软约束在决定随机结构的极限行为方面有不同的影响，并且通过第一点分析展示了量化自由MLN和提升贝叶斯网络在大域尺寸下的渐近不可比性。", "conclusion": "在较大领域下，由MLN确定的概率分布几乎将其所有概率质量集中在一个与均匀分布完全不同的空间部分。"}
{"llm_update_time": "20250907", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.04125", "html_url": "https://arxiv.org/abs/2509.04125", "title": "DQN和CFR在Leduc霍尔恶魔扑克中的欺骗行为分析", "title_en": "Analysis of Bluffing by DQN and CFR in Leduc Hold'em Poker", "authors": "Tarik Zaciragic,Aske Plaat,K. Joost Batenburg", "background": "在扑克游戏中，不可预测性或欺骗是一种关键技能。当人类玩扑克时，他们会进行欺骗。然而，大多数计算机扑克相关研究侧重于胜率等绩效指标，而忽视了欺骗行为。本文研究了两种流行算法，基于强化学习的DQN和基于博弈论的CFR，在简化版的扑克游戏Leduc Hold'em中的欺骗行为。", "innovation": "本文通过设计让DQN和CFR算法相互博弈并记录其行为的实验，首次分析了这两种算法在Leduc Hold'em中的欺骗行为，揭示了它们在实施欺骗时的不同方式和成功率，证明了欺骗在游戏中的重要作用，而非算法本身的特性。", "conclusion": "虽然DQN和CFR都试图在不同的频率下进行欺骗，但成功欺骗（对手弃牌）的百分比大致相同。这表明欺骗是游戏的关键要素，而非算法的一部分。未来的研究应关注不同的欺骗风格和完整扑克游戏。"}
{"llm_update_time": "20250907", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.04239", "html_url": "https://arxiv.org/abs/2509.04239", "title": "评估与AI协创的游戏叙事质量", "title_en": "Evaluating Quality of Gaming Narratives Co-created with AI", "authors": "Arturo Valdivia,Paolo Burelli", "background": "本文提出了一种结构化的方法来评估AI生成的游戏叙事。这种方法利用了Delphi研究结构，并结合了叙事设计专家的团队。本文的背景是目前AI在游戏叙事生成中的应用越来越多，但如何衡量和优化这种生成的叙事质量仍缺乏系统的方法。", "innovation": "本文的创新在于提出了一种综合故事质量维度的方法，并将这些维度映射到Kano模型框架中，以便更好地理解其对玩家满意度的影响。这为游戏开发者提供了一种新的工具来优先考虑协创游戏叙事时的质量方面。", "conclusion": "研究结果可以指导游戏开发者在使用生成性AI协创游戏叙事时，更有效地优先考虑关键的质量因素，提高玩家的满意度。"}
{"llm_update_time": "20250907", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.04317", "html_url": "https://arxiv.org/abs/2509.04317", "title": "提高AlphaZero算法在测试环境变化下的鲁棒性", "title_en": "Improving Robustness of AlphaZero Algorithms to Test-Time Environment Changes", "authors": "Isidoro Tamassia,Wendelin Böhmer", "background": "AlphaZero框架提供了一种结合蒙特卡洛规划与之前训练的策略价值神经网络所提供先验知识的标准方法。通常假设在测试时神经网络训练的环境不会变化，从而限制了其应用范围。", "innovation": "本文分析了在可能变化的测试环境中部署AlphaZero代理的问题，并展示了通过对标准框架进行简单的修改，即使在可用的规划预算较低的情况下，也能显著提升性能。", "conclusion": "研究表明，通过简单修改AlphaZero的标准框架，即使在测试时环境可能变化，也能显著提高算法的性能，相关代码已公开在GitHub上。"}
{"llm_update_time": "20250907", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.04310", "html_url": "https://arxiv.org/abs/2509.04310", "title": "EvoEmo: 向多轮谈判中LLM代理进化的情绪政策", "title_en": "EvoEmo: Towards Evolved Emotional Policies for LLM Agents in Multi-Turn Negotiation", "authors": "Yunbo Long,Liming Xu,Lukas Beckenbauer,Yuhan Liu,Alexandra Brintrup", "background": "近期对大型语言模型（LLMs）进行链式思维（CoT）推理的研究表明，代理能够进行复杂的、多轮次的谈判，开启了智能代理型AI的新途径。然而，现有的LLM代理通常忽视了情绪在这些谈判中的功能作用，仅生成被动的、基于偏好的情绪反应，使其容易受到对手操纵和战略性利用。", "innovation": "论文提出了EvoEmo，一个进化强化学习框架，用于优化谈判中的动态情绪表达。EvoEmo将情绪状态转换建模为马尔可夫决策过程，并使用基于群体的遗传优化来进化高奖励情绪策略。此外，论文还提出了包含两种基线——常规策略和固定情绪策略——的评估框架，用于评估情绪感知谈判的效果。实验和消融研究表明，EvoEmo在多轮谈判中的一致性表现优于这两种基线策略，成功率达到更高，效率也更高，买家节省成本增加。", "conclusion": "研究结果突显了适应性情绪表达在促进更有效的多轮谈判LLM代理中的重要性。EvoEmo框架能够通过优化情绪策略提提高谈判效率并减少买家成本，展示了情感智能在代理型AI中的重要作用。"}
{"llm_update_time": "20250907", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.03863", "html_url": "https://arxiv.org/abs/2509.03863", "title": "Expedition & Expansion: 调用语义表示以实现目标导向的连续细胞自动机中的探索", "title_en": "Expedition & Expansion: Leveraging Semantic Representations for Goal-Directed Exploration in Continuous Cellular Automata", "authors": "Sina Khajehabdollahi,Gautier Hamon,Marko Cvjetko,Pierre-Yves Oudeyer,Clément Moulin-Frier,Cédric Colas", "background": "在连续细胞自动机（CA）中探索多样的视觉模式极具挑战性，因为高维度行为空间极其庞大且存在冗余。传统方法如新颖性搜索（NS）通过局部变异已知新颖解决方案进行扩张，但在局部新颖性被耗尽后常常陷入停滞，难以探索到遥远且未开发的区域。Flow Lenia作为一种已知具有丰富动态行为的连续CA，传统方法难以揭示其中的多样化解决方案。", "innovation": "本文提出了Expedition and Expansion（E&E）策略，该策略通过交替进行基于局部新颖性的扩张和目标驱动的探险来突破传统方法的局限。E&E整合了一种视觉-语言模型（VLM），生成文本文本目标，推动探索向未开发的领域进展。这种策略使得探索过程在符合人类感知的语义空间中运行，从而提高探寻行为的可解释性和相关性，有效扩展了探寻到的多元化解决方案。", "conclusion": "实验表明，E&E方法比现有探索方法能发现更多元化的解法。基因学分析进一步显示，起源于探险的解法对长期探索有显著影响，促使新的行为领域作为后续搜索的里程碑。这些发现凸显了E&E方法在人类导向和可解释探索方式下的潜力，为人工生命和其他领域的开放探索提供了有价值的框架。"}
{"llm_update_time": "20250907", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.03890", "html_url": "https://arxiv.org/abs/2509.03890", "title": "FaMA: LLM-Empowered Agentic Assistant for Consumer-to-Consumer Marketplace", "title_en": "FaMA: LLM-Empowered Agentic Assistant for Consumer-to-Consumer Marketplace", "authors": "Yineng Yan,Xidong Wang,Jin Seng Cheng,Ran Hu,Wentao Guan,Nahid Farahmand,Hengte Lin,Yue Li", "background": "随着大型语言模型（LLMs）驱动的代理型人工智能（Agentic AI）的出现，人工智能从反应式生成系统转变为能动的目标导向自主代理，这些代理能够进行高级规划、记忆和工具使用。这标志着一个范式转变，为解决复杂数字环境中长期存在的问题提供了新机会。在消费者对消费者（C2C）电子商务平台上，用户常常需要在复杂的图形用户界面（GUI）中导航，这使得买卖双方的体验变得耗时且不便。这些复杂互动通常需要人工干预来简化。", "innovation": "本文提出了一个基于LLM的代理型助手（FaMA），它提供了一种新的、基于对话的方式，作为进入市场的入口，将主要交互模式从复杂的GUI转换为直观的人工智能代理。通过解释自然语言命令，助手能够自动化关键的高摩擦度的工作流，比如简化更新和重新发布商品列表的过程，以及为卖家提供批量发送消息的能力，为买家提供更高效的通过对话搜索发现商品的方法。", "conclusion": "我们提出了Facebook Marketplace Assistant（FaMA）的架构，证明这种代理型、对话式范式提供了比传统应用界面更轻便和更易于访问的替代方案，允许用户更高效地管理市场活动。实验证明，FaMA在解决市场上的复杂任务时成功率达到98%，并能够将交互时间提高两倍。"}
{"llm_update_time": "20250907", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.04343", "html_url": "https://arxiv.org/abs/2509.04343", "title": "心理强化的AI代理", "title_en": "Psychologically Enhanced AI Agents", "authors": "Maciej Besta,Shriram Chandran,Robert Gerstenberger,Mathis Lindner,Marcin Chrapek,Sebastian Hermann Martschat,Taraneh Ghandi,Patrick Iff,Hubert Niewiadomski,Piotr Nyczyk,Jürgen Müller,Torsten Hoefler", "background": "本文介绍了一种通过心理学背景的个性调整来增强大型语言模型（LLM）代理有效性的框架。该框架使用迈尔斯-布里格斯类型指标（MBTI）进行提示工程，通过特定的心理学特征（认知和情感）调整代理行为，展示了个性调整在不同类型任务中产生一致且可解释的行为偏倚。研究还发现代理自我反思能够提高合作质量和推理质量。", "innovation": "提出了一种名为MBTI-in-Thoughts的心理强化框架，通过MBTI进行个性引导，使代理行为更接近人类心理学特征。该方法不仅在叙事生成和策略决策上表现出色，还成功地揭示了与其他心理框架（如五大特质、HEXACO或九型人格）的兼容性。通过结合官方的16个性测试进行自动化验证，避免了模型微调，为未来的发展奠定了基础。", "conclusion": "本文为心理强化的AI代理提供了一个基础框架，通过这种方法可以控制和调整代理的行为模式，而无需进行模型微调。这种方法不仅适用于MBTI，也能推广到其他心理框架，从而为AI代理的心理强化提供了新的可能性。"}
{"llm_update_time": "20250907", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.03521", "html_url": "https://arxiv.org/abs/2509.03521", "title": "BiND: 一种用于脑-机接口中准确双臂轨迹预测的神经分类-解码器", "title_en": "BiND: A Neural Discriminator-Decoder for Accurate Bimanual Trajectory Prediction in Brain-Computer Interfaces", "authors": "Timothee Robert,MohammadAli Shaeri,Mahsa Shoaran", "background": "双臂手部运动的解码对脑-机接口（BCIs）来说仍然是一个关键挑战，由于神经表示的重叠和跨肢体的非线性交互作用。现有的模型在处理双手臂运动的连续2D手速预测时存在困难。", "innovation": "本文提出了一种两阶段模型BiND（Bimanual Neural Discriminator-Decoder），首先对运动类型进行分类（单臂左、单臂右或双臂），然后使用带有相对时间索引的专有GRU解码器来预测连续的2D手速。本模型在公共13会话的脑内记录数据集上的表现超过了六个最先进的模型，并且在交叉会话分析中显示出更强的鲁棒性。", "conclusion": "BiND模型在单手和双手轨迹预测中分别达到了0.76（±0.01）和0.69（±0.03）的平均$R^2$值，比第二好的模型（GRU）高出2%，并且在会话间分析中表现出更高的准确性，最高可达4%。这表明任务感知的分类和时间建模对于提高双臂解码效果的有效性。"}
{"llm_update_time": "20250907", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.03529", "html_url": "https://arxiv.org/abs/2509.03529", "title": "基于多模态的人工智能工具提案，以增加消息的跨评估", "title_en": "Multimodal Proposal for an AI-Based Tool to Increase Cross-Assessment of Messages", "authors": "Alejandro Álvarez Castro,Joaquín Ordieres-Meré", "background": "盈余电话代表了财务沟通的独特且半结构化来源，融合了管理者的预定评论和分析师的即兴对话。尽管最近财务情感分析进步整合了多模态信号如文本内容和音调，大多数系统仍依赖于平面的文档级或句级模型，未能捕捉到这些互动的层次对话结构。该研究旨在通过将盈余电话编码为层次对话树来生成富含语义和结构意识的嵌入向量。", "innovation": "提出了一种新颖的多模态框架，结合文本、音频和视频的多模态内容以及结构化元数据（包括连贯性得分、主题标签和答案覆盖率评估），以编码盈余电话的层次对话树结构。所提出的双阶段变压器架构首先通过对比学习在节点级编码多模态内容和对话元数据，然后生成整个会议的全局嵌入。", "conclusion": "实验结果表明，从而产生的嵌入形成了稳定的、语义上有意义的表示，反映了情感色调、结构逻辑和主题对齐。该系统不仅适用于金融报告的场景，还能推广到如远程医疗、教育和政治话语等高风险的即兴沟通领域，提供了一种稳健且可解释的多模态对话表示方法，为财务预测和对话评价等下游任务提供了实用价值，并为涉及高风险沟通的其他领域提供了可扩展的方法。"}
{"llm_update_time": "20250907", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.04100", "html_url": "https://arxiv.org/abs/2509.04100", "title": "基于强化学习和搜索的飞行轨迹规划", "title_en": "Hybrid Reinforcement Learning and Search for Flight Trajectory Planning", "authors": "Alberto Luise,Michele Lombardi,Florent Teichteil Koenigsbuch", "background": "该论文探讨了将强化学习（RL）与基于搜索的路径规划相结合，以加快商用飞机飞行路径优化的过程。在紧急情况下，快速重新计算航线路径是非常关键的。传统的路径规划方法在计算新的飞行路径时，可能会花费大量时间，尤其是在面对大量数据和复杂情况时。该论文旨在通过训练RL代理预先计算近最优路径，从而在运行时对路径规划求解器进行约束，找到初始猜测附近位置的解决方案，以减少求解器的搜索空间大小，进而显著提高路径优化的速度和效率。尽管无法保证全局最优，但实验证明，使用该方法可以使油耗接近于未受约束求解器的水平，相差仅在1%以内。同时，使用该方法的计算速度可以提高至传统求解器的50%左右。", "innovation": "引入了一种新的方法，即结合强化学习和基于搜索的方法，来预先计算高效的飞行路径。这种方法通过训练代理来生成减少搜索空间的初始路径，从而提高路径优化的速度和效率。虽然无法保证全局最优，但实验证明在具体的应用场景中，这种方法能显著降低成本并提高速度，特别是在商用飞机性能模型中，油耗仅略有增加，且速度快了一半左右。", "conclusion": "该研究通过在商用飞机飞行轨迹规划中引入强化学习和基于搜索的方法，减少了搜索空间，显著加速了路径优化过程。虽然无法保证全局最优，但其在实际应用中的效果良好，能够在保持燃油效率的同时大大缩短计算时间，具有较高的实际应用潜力。"}
{"llm_update_time": "20250907", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.03537", "html_url": "https://arxiv.org/abs/2509.03537", "title": "AR$^2$: 对大型语言模型进行抽象推理的对抗强化学习", "title_en": "AR$^2$: Adversarial Reinforcement Learning for Abstract Reasoning in Large Language Models", "authors": "Cheng-Kai Yeh,Hsing-Wang Lee,Chung-Hung Kuo,Hen-Hsen Huang", "background": "抽象能力是从复杂的计算问题中识别和提炼核心模式的能力，对计算机科学中的人类问题解决者和编程导向的大型语言模型（LLMs）至关重要。尽管最近在使用强化学习（RL）培训LLMs进行代码生成方面取得了进展，但现有方法主要集中在浅层的模式识别上，未能明确地训练模型进行抽象。", "innovation": "提出了AR$^2$（对抗强化学习进行抽象推理）这一新颖框架，专门设计来提升LLMs的抽象能力。AR$^2$使用教师模型将核心问题转化为富有叙述性的复杂描述，而不改变其基本逻辑。同时，通过解决这些复杂的叙述问题，训练学生的编码模型来提取其背后的计算核心。实验结果表明，AR$^2$在解决未见过的复杂编程任务上显著提高了学生模型的准确性，突显了抽象作为提升LLM泛化能力的关键技能。", "conclusion": "AR$^2$ 显著提升了大型语言模型在解决未见过的复杂编程任务上的准确性，证明了抽象能力对提升大语言模型泛化能力的重要性。"}
{"llm_update_time": "20250907", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.03527", "html_url": "https://arxiv.org/abs/2509.03527", "title": "使用细调Mistral大语言模型和RAG方法进行多层次加密货币新闻分析", "title_en": "Multilevel Analysis of Cryptocurrency News using RAG Approach with Fine-Tuned Mistral Large Language Model", "authors": "Bohdan M. Pavlyshenko", "background": "本文研究的是使用下采样至7B参数的Mistral大型语言模型（LLM），结合检索增强生成（RAG）方法，对加密货币新闻进行多层次多任务分析。在此背景下，传统的自然语言处理技术和模型在处理大量复杂和高维的数据时存在局限性，特别是对于需要多层次分析的场景，如加密货币领域的新闻分析。", "innovation": "本文的创新点在于提出了一种多层次多任务分析框架，该框架利用细调后的Mistral 7B大型语言模型和RAG技术进行加密货币新闻处理。具体创新包括：1) 细分多个层级进行信息整合和分析；2) 利用知识图谱表示法，减少模型生成不合理输出（hallucinations）的问题；3) 提供多个视角的互补总结，从而更全面地分析新闻内容；4) 使用4-bit量化和PEFT/LoRA微调方法，优化模型性能和效率。", "conclusion": "实验结果表明，使用细调后的Mistral 7B LLM模型能够进行有意义的定性和定量分析，提供重要的见解。最终，该方法能够有效提升加密货币新闻分析的质量和效率。"}
{"llm_update_time": "20250907", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.03535", "html_url": "https://arxiv.org/abs/2509.03535", "title": "QuesGenie：智能多模态问题生成", "title_en": "QuesGenie: Intelligent Multimodal Question Generation", "authors": "Ahmed Mubarak,Amna Ahmed,Amira Nasser,Aya Mohamed,Fares El-Sadek,Mohammed Ahmed,Ahmed Salah,Youssef Sobhy", "background": "在信息丰富的时代，学习者能够接触到丰富的教育资源，但这些资源缺乏定制化的练习材料。为了弥补这一缺口，该项目开发了一个多模态问题生成系统，能够从各种内容格式中自动生成多样化的各种类型问题。该系统包括四大模块：多模态输入处理、问题生成、基于人类反馈的强化学习（RLHF）以及端到端的交互界面。这使系统能够实现自动化的、可扩展的和智能问题生成，同时平衡了资源效率、功能稳健性和用户友好性体验。", "innovation": "该项目的创新点在于开发了一个能够从多种内容格式中自动生成多样化问题的多模态问题生成系统。其核心创新包括多模态输入处理、基于人类反馈的强化学习以及提供端到端交互界面。这些技术共同确保了系统的自动化、可扩展性和智能性，优化了资源使用和用户体验。", "conclusion": "该项目为自动化、可扩展和智能的问题生成奠定了基础，通过平衡资源效率、功能的稳健性和用户体验，展示了多模态问题生成系统的潜力和优势。"}
{"llm_update_time": "20250907", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.03525", "html_url": "https://arxiv.org/abs/2509.03525", "title": "基于语音的认知筛查：大规模语言模型适应策略的系统评估", "title_en": "Speech-Based Cognitive Screening: A Systematic Evaluation of LLM Adaptation Strategies", "authors": "Fatemeh Taherinezhad,Mohamad Javad Momeni Nezhad,Sepehr Karimi,Sina Rashidi,Ali Zolnour,Maryam Dadkhah,Yasaman Haghbin,Hossein AzadMaleki,Maryam Zolnoori", "background": "在美国，超过一半的阿尔茨海默病和其他痴呆症成人患者未被诊断。语音筛查方法具有潜在的可扩展性，研究比较了大规模语言模型的适应策略以检测痴呆症，并评估了九种文本模型和三种多模态音视频模型在DementiaBank语音语料库上的性能。这些适应策略包括上下文学习、基于不同演示选择策略的在场学习、基于推理的提示增强、参数高效微调以及多模态集成等方法。研究结果表明，类中心演示在上下文学习中表现最佳，推理有助于小型模型性能提升，而基于标记的微调通常能产生最佳评分。在多模态模型中，微调后的音视频系统表现良好，但并未超越顶级纯文本模型。这些发现强调了适应策略，包括演示的选择、推理设计和调优方法，对基于语音的痴呆症检测至关重要，并表明适当适应的开源模型可以匹配甚至超越商用系统。", "innovation": "研究系统比较了九种文本模型和三种多模态音视频模型的性能，评估了大规模语言模型的不同适应策略，包括上下文学习、推理增强提示、参数高效微调和多模态集成方法。研究发现，类中心演示、基于推理的提示增强以及标记级微调是有效的方法。此外，研究指出多模态模型的微调效果虽好，但未能超越顶级文本模型。研究进一步强调了适应策略对于提升基于语音的痴呆症筛查模型性能的重要性。", "conclusion": "不同适应策略，包括演示的选择、推理的设计和微调方法，对于改善基于语音的痴呆症筛查至关重要。适当适应的开源模型的性能可以与甚至超越商业系统。"}
{"llm_update_time": "20250907", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.03531", "html_url": "https://arxiv.org/abs/2509.03531", "title": "长文本生成中实时检测虚构实体", "title_en": "Real-Time Detection of Hallucinated Entities in Long-Form Generation", "authors": "Oscar Obeso,Andy Arditi,Javier Ferrando,Joshua Freeman,Cameron Holmes,Neel Nanda", "background": "大型语言模型现在在高风险应用中广泛使用，如医疗咨询和法律咨询，其中的虚构（hallucinations）可能会造成严重危害。现有的虚构检测方法要么只能处理短暂的事实查询，要么需要昂贵的外部验证，这在实际使用中是不切实际的。", "innovation": "该研究提出了一种低成本、可扩展的方法，用于实现实时长文本生成中的虚构标记物检测，并成功扩展到70B参数模型。该方法专注于实体级别的虚构，即制造的名字、日期、引文等，而不是声称级别，这自然地对应于标记级别的标签，并支持流式检测。提出了一种利用网络搜索进行标注的方法，以验证模型响应中哪些标记对应于虚构实体。基于此数据集，可以训练有效的虚构分类器，使用简单而高效的方法，如线性探测器。", "conclusion": "通过在四种模型系列中进行评估，该类检测器在长文本中的表现始终优于基线，包括更昂贵的方法如语义熵（例如，对于Llama-3.3-70B，AUC为0.90对0.71）。此外，尽管仅使用实体级别的标签进行训练，但所提出的探针在数学推理任务中也能检测到错误答案，表明其超越实体的泛化能力。尽管标注工艺昂贵，但发现一个模型的标注响应可以用于其他模型的有效分类器训练，因此公开发布数据集以促进再使用。总体来看，这项工作提出了一种具有广阔前景的新型方法，可以实现大规模、实际环境中的虚构检测。"}
{"llm_update_time": "20250907", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.03545", "html_url": "https://arxiv.org/abs/2509.03545", "title": "乌干达移动货币服务的软件安全审查：Jim Spire博士微博情绪分析", "title_en": "A software security review on Uganda's Mobile Money Services: Dr. Jim Spire's tweets sentiment analysis", "authors": "Nsengiyumva Wilberforce", "background": "乌干达移动货币的普及已成为金融包容性的重要基石，然而其安全机制仍是一个关键问题。2025年8月，由医生Jim Spire Ssentongo披露的一起事件引发了公众对安全问题的关注，这起事件涉及到窃贼通过获取受害者账户，提取资金并贷款。此背景下，#StopAirtelThefty推特活动揭示了公众对移动货币安全性的深层担忧。本研究通过质性分析调查了该活动期间提出的投诉，提取了相关安全漏洞和用户不满的关键主题。", "innovation": "该研究通过质性分析系统地考察能够揭示用户面对的主要安全漏洞，有针对性地填补乌干达移动货币现有监管和运营环境的空白并促进用户满意度。", "conclusion": "研究最终得出结论，旨在为服务提供商、政策制定者和乌干达安全数字金融的未来发展提供具有重要意义的政策建议。"}
{"llm_update_time": "20250907", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.04439", "html_url": "https://arxiv.org/abs/2509.04439", "title": "ArcMemo: Abstract Reasoning Composition with Lifelong LLM Memory", "title_en": "ArcMemo: Abstract Reasoning Composition with Lifelong LLM Memory", "authors": "Matthew Ho,Chen Si,Zhaoxiang Feng,Fangxu Yu,Zhijian Liu,Zhiting Hu,Lianhui Qin", "background": "随着推理时长缩放功能使得大规模语言模型（LLMs）能够进行越来越长且复杂的推理过程，但在每次新的查询之前重置了推理窗口时，这些推理过程中的发现和见解会立即被丢弃。因此，引入外部存储机制以持久化这些发现成为一种自然选择。最近的工作已经表明，这种存储机制对于需要深度推理的任务具有显著的优势。现阶段的外部存储大多基于实例级别的记忆条目，例如精确的问题/答案对或与原始问题上下文紧密关联的总结。本文提出了一个创新的解决方案，即从推理过程提取抽象概念级别的记忆条目，并用自然语言进行存储，从而实现这些记忆条目的广泛再利用和扩展。在未来的问题查询中，根据相关性选择性地检索并整合这些概念，从而实现测试时的持续学习，而不需要更新权重。这种方法扩大了内存设计的灵活性，使其能够适应各种推理过程，并让内存随着新经验的增长而扩展。通过ARC-AGI基准的测试，该方法在不使用任何记忆机制的强基准之上实现了7.5%的相对性能提升，且这种性能提升随着推理计算能力的提升而持续增加。此外，在所有测试的推理计算规模中，抽象概念的记忆设计表现最为稳定，优于基线基准。动态在测试时更新记忆优于静态固定记忆，证明了解决更多问题并把更多模式抽象到记忆中能够促进进一步的解决方案，从而实现自我改进。", "innovation": "本文创新地提出了一种从长期记忆中提取和存储抽象概念级别的记忆条目，并用自然语言描述的方法。该方法能实现记忆条目的广泛再利用和扩展，最终在测试时通过检索相关概念并整合到新查询中，实现了测试时的持续学习。此外，该方法还验证了在测试时动态更新记忆比静态固定记忆更有效，这支持了解决更多问题并存储更多模式能够促进进一步解决方案的自我改进假设。", "conclusion": "在ARD-AGI基准测试中，本文提出的方法在不使用任何记忆机制的强基准之上实现了7.5%的相对性能提升，并且证明了抽象概念级别的记忆设计在所有测试的推理计算规模中最为稳定，优于基线基准。动态在测试时更新记忆优于静态固定记忆，进一步证明了解更多问题并把更多模式抽象到记忆中能够促进进一步的解决方案，并实现自我改进。"}
{"llm_update_time": "20250907", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.03540", "html_url": "https://arxiv.org/abs/2509.03540", "title": "通过推断时知识图谱构建提高大语言模型事实准确性", "title_en": "Improving Factuality in LLMs via Inference-Time Knowledge Graph Construction", "authors": "Shanglin Wu,Lihui Liu,Jinho D. Choi,Kai Shu", "background": "大型语言模型（LLMs）在生成事实一致的答案时通常会遇到困难，这主要是由于其参数记忆的限制。检索增强生成（RAG）方法通过在推理时结合来自可信来源的外部知识来解决这一问题。然而，这些方法通常将知识视为无结构的文本，限制了它们支持组合推理和识别事实不一致的能力。因此，本文提出了一种新的框架，该框架在推理过程中动态构建和扩展知识图谱，结合LLMs内部知识提取和外部来源检索的信息。", "innovation": "本文提出了一种新的框架，通过在推理过程中动态构建和扩展知识图谱，结合LLMs内部知识提取和外部来源检索的信息，从而克服传统方法的限制，增强大语言模型的事实准确性。该方法首先通过提示从问题中提取种子知识图谱，然后通过LLMs的潜在知识进行迭代扩展，再通过外部检索逐步精炼图谱，提高事实覆盖率并修正不准确之处。", "conclusion": "本文的方法在三个多样的事实问答基准测试上进行了评估，结果表明，与基线提示和静态知识图谱增强方法相比，该方法在事实准确性、答案精确性和可解释性方面都取得了持续的提升。研究结果表明，在结构化、可解释和可扩展的方式中增强大语言模型的事实准确性，通过推理时构建知识图谱是一个有希望的方向。"}
{"llm_update_time": "20250907", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.03633", "html_url": "https://arxiv.org/abs/2509.03633", "title": "treeX：在密集森林点云中无监督树木实例分割", "title_en": "treeX: Unsupervised Tree Instance Segmentation in Dense Forest Point Clouds", "authors": "Josafat-Mattias Burmeister,Andreas Tockner,Stefan Reder,Markus Engel,Rico Richter,Jan-Peter Mund,Jürgen Döllner", "background": "近距离激光扫描可以提供森林林分的详细三维图像，但需要高效的软件处理三维点云数据和提取单个树木。虽然最近的研究引入了深度学习方法来进行树木实例分割，但这些方法需要大规模标注数据集和大量的计算资源。为此，研究者提出了一种资源高效的方法——修订版的treeX算法，该方法结合了基于聚类的树干检测和区域生长的树冠分割。", "innovation": "修订版的treeX算法提供两种参数预设：一种适用于地面激光扫描数据（静态陆基激光扫描-TLS和个人激光扫描-PLS），另一种适用于无人机激光扫描数据（无人机激光扫描-ULS）。该算法相比原算法减少了运行时间和提高了准确性。在类似最新开源方法的精度方面，对于地面激光扫描和近距离激光扫描数据，修订版的treeX算法取得了与最新方法相似的精度，包括深度学习方法。", "conclusion": "与深度学习方法相比，修订版的treeX算法在资源和效率方面提供了一种替代方案，特别是在数据特征符合算法设计要求的情况下，例如足够的树干可见性和点密度。此外，该方法还可以用于深度学习模型的半自动注释标签生成。为了推动更广泛的采用，研究者提供了一个开源的Python实现，作为pointtree包的一部分。"}
{"llm_update_time": "20250907", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.03677", "html_url": "https://arxiv.org/abs/2509.03677", "title": "从梯度动态见解：梯度自动调整归一化", "title_en": "Insights from Gradient Dynamics: Gradient Autoscaled Normalization", "authors": "Vincent-Daniel Yun", "background": "梯度动态在决定深层神经网络的稳定性和泛化能力方面起着核心作用。本文通过实证分析梯度方差和标准差的变化情况，展示了这些变化在卷积网络中的共性模式，不同层之间的变化以及整体层面的变化。研究表明，梯度的演化遵循自然规律，理解并利用这一规律可以帮助提高网络的性能和稳定性。", "innovation": "本文提出了一种无需超参数的梯度归一化方法，该方法通过调整梯度缩放与天然演化之间的对齐来稳定优化过程并保持收敛性保证。这种方法避免了无意的放大，确保了优化的有效性，并且在CIFAR-100基准测试上，即使在强大的泛化要求下也能保持甚至提高测试准确性。", "conclusion": "本研究突显了直接跟踪梯度动态的重要性，旨在弥合理论预期与实际行为之间的差距，并为未来优化研究提供新的见解。"}
{"llm_update_time": "20250907", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.03615", "html_url": "https://arxiv.org/abs/2509.03615", "title": "E-ARMOR: Edge case Assessment and Review of Multilingual Optical Character Recognition", "title_en": "E-ARMOR: Edge case Assessment and Review of Multilingual Optical Character Recognition", "authors": "Aryan Gupta,Anupam Purwar", "background": "多语言、嘈杂和多样化的现实环境中的光学字符识别（OCR）仍然是光学字符识别系统的重大挑战。随着大型视觉-语言模型（LVLMs）的兴起，人们对它们超越固定OCR管道的泛化能力和推理能力产生了浓厚兴趣。", "innovation": "该论文引入了Sprinklr-Edge-OCR系统，这是一种专门为资源受限环境边缘部署优化的新OCR系统。作者进行了一次大规模实验，对比评估了五种最新的LVLMs（InternVL，Qwen，GOT OCR，LLaMA，MiniCPM）和两种传统OCR系统（Sprinklr-Edge-OCR，SuryaOCR）在双面手动标注的具有54种语言的专有图像数据集上的表现。实验涵盖了准确性、语义一致性、语言覆盖率、计算效率（延迟、内存、GPU使用情况）和部署成本等多个基准指标。", "conclusion": "实验结果显示，在边部署环境中，传统OCR系统如Sprinklr-Edge-OCR表现出最佳的整体F1分数（0.46），效率最高，处理每张图像仅需0.17秒，并且每1,000张图像的成本仅为0.006美元，这表明传统OCR系统在大型视觉-语言模型时代即使在边缘部署环境也能表现出最佳性能。这些发现展示了在计算要求低、延迟低且具有极高成本效益的情况下，传统OCR系统对于边缘部署的最优性。"}
{"llm_update_time": "20250907", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.03658", "html_url": "https://arxiv.org/abs/2509.03658", "title": "Efficient Virtuoso: 目标条件轨迹规划的潜扩散变换模型", "title_en": "Efficient Virtuoso: A Latent Diffusion Transformer Model for Goal-Conditioned Trajectory Planning", "authors": "Antonio Guillen-Perez", "background": "自主车辆规划系统生成多样且合理的未来轨迹分布是一项关键能力。虽然最近的生成模型展示了一定潜力，但实现高度真实感、计算效率和精确控制仍然是重大挑战。对于这一背景，本论文提出了一种用于目标条件轨迹规划的条件潜扩散模型Efficient Virtuoso。", "innovation": "Efficient Virtuoso引入了一种新的两阶段归一化流水线，首先按比例缩放轨迹以保持其几何比例，然后归一化PCA潜在空间以确保稳定训练目标。通过在低维潜在空间中采用简单的MLP去噪器进行去噪，并结合强大的Transformer-StateEncoder的丰富场景上下文条件，实现了高效去噪。通过详尽的消融研究，证明了该方法在Waymo开放运动数据集上取得了最先进的效果，达到了最小平均位移误差（minADE）为0.25，同时揭示了单个终端目标解决战略不确定性的重要性，以及多步骤稀疏路径在促进详细的、高保真度战术执行中的关键作用。", "conclusion": "文章通过提出Efficient Virtuoso，显著提升了目标条件轨迹规划的真实性和精确性，达到了行业领先的性能，并通过实验提供了关于目标表示对人体驾驶行为模拟重要性的见解。"}
{"llm_update_time": "20250907", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.03594", "html_url": "https://arxiv.org/abs/2509.03594", "title": "隐匿于明处的优化器：利用损失景观诱导的度量进行训练", "title_en": "The Optimiser Hidden in Plain Sight: Training with the Loss Landscape's Induced Metric", "authors": "Thomas R. Harvey", "background": "该研究提出了利用嵌入在更高维度空间中的损失景观自然诱导的黎曼度量的新优化器类。这种度量在常见的损失景观可视化中也很重要。通过这种几何视角，开发了一种新的优化器，并与现有方法SGD、Adam、AdamW和Muon进行了比较。研究表明，这种新优化器在低维度情况中表现非常有效，并且在训练神经网络时提供轻微的改进，优于最先进的方法。此外，新优化器具备理论上期望的特性，例如在高曲率区域自动减少有效学习率，起到平滑梯度裁剪的作用，以及视作引生效率性学习率的启动，并且在几何视角下自然选择解耦权重衰减。基本的方法可以用于修改任何现有的预条件方法，且新优化器的计算复杂度与Adam相当。", "innovation": "该研究提出的优化器类利用嵌入在更高维度空间中的损失景观诱导的黎曼度量，开发了一种新的优化器，具备自动减少在高曲率区域的有效学习率、提供平滑梯度裁剪效果、自然选择解耦权重衰减等特点。此外，该优化器可以应用于所有现有的预条件方法，并且计算复杂度与Adam相当。", "conclusion": "新提出的优化器类在低维度情况下表现出色，并提供轻微的改进，优于最先进的方法。这种优化器具有理论上期望的特性，如自动调节学习率、平滑梯度裁剪和自然实现解耦权重衰减。此外，该方法的高度灵活性使其可以方便地调整现有预条件方法。"}
{"llm_update_time": "20250907", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.03709", "html_url": "https://arxiv.org/abs/2509.03709", "title": "从联邦学习到 $\boldsymbol{X}$ 学习：通过随机游走进阶去中心化障碍", "title_en": "From Federated Learning to $\\mathbb{X}$-Learning: Breaking the Barriers of Decentrality Through Random Walks", "authors": "Allan Salihovic,Payam Abdisarabshali,Michael Langberg,Seyyedali Hosseinalipour", "background": "联邦学习是一种去中心化的机器学习方法，但其在实际应用中存在一定的局限性。本文探讨了一种新的分布式学习架构 $\boldsymbol{X}$-Learning ($\boldsymbol{X}$L)，旨在进一步推广和扩展去中心化概念的边界，解决联邦学习中的障碍。", "innovation": "本文提出 $\boldsymbol{X}$-Learning 架构，这是一种创新的分布式学习体系，将联邦学习与图论和马尔可夫链的直观但不简单的联系紧密结合起来。此外，作者还提出了几个开放性研究方向，以激发进一步的研究兴趣。", "conclusion": "通过详细解析 $\boldsymbol{X}$-Learning 的设计理念和自由度，本文为去中心化学习领域提供了新的视角，同时也指出了几个潜在的研究方向。"}
{"llm_update_time": "20250907", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.03643", "html_url": "https://arxiv.org/abs/2509.03643", "title": "CEHR-GPT：一种适用于电子健康记录的大规模多任务基础模型", "title_en": "CEHR-GPT: A Scalable Multi-Task Foundation Model for Electronic Health Records", "authors": "Chao Pang,Jiheum Park,Xinzhuo Jiang,Nishanth Parameshwar Pavinkurve,Krishna S. Kalluri,Shalmali Joshi,Noémie Elhadad,Karthik Natarajan", "background": "电子健康记录（EHRs）提供了患者健康状况的丰富纵向视图，具有推动临床决策支持、风险预测和数据驱动的医疗健康研究的巨大潜力。然而，大多数用于EHR的AI模型设计用于单一目的任务，限制了它们在实际环境中的通用性和实用性。在此之前，大多数EHR模型专注于特定任务，未能有效结合多种功能，特别是在纵向数据处理和动态临床序列推理方面存在不足。因此，CEHR-GPT模型致力于解决这些问题，提供一种能够处理多重任务的通用基础模型，通过结合特征表示、零样本预测和合成数据生成等功能，解决实际应用中的不足之处。", "innovation": "CEHR-GPT引入了一种新颖的时间标记学习框架，通过显式地将患者的时间动态嵌入到模型结构中，支持对临床序列的时间推理。这一框架使得CEHR-GPT模型在所有三个任务中都表现出强大的性能，并通过词汇扩展和微调有效地泛化到外部数据集。这种通用性和灵活性使得CEHR-GPT能够快速开发模型、发现患者群体并预测患者结果，而无需针对特定任务重新训练模型，从而大大提高了模型的应用范围与效率。", "conclusion": "CEHR-GPT展示了强大的多任务处理能力，并通过扩大词汇和微调成功地将模型应用于外部数据集。其广泛的应用潜力表明，它在临床决策支持、风险预测和数据驱动的研究中具有广阔的应用前景。此外，CEHR-GPT的架构设计可以为其他医疗健康数据处理提供新的技术参考，未来有望进一步提高医疗效率和医疗质量。"}
{"llm_update_time": "20250907", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.03647", "html_url": "https://arxiv.org/abs/2509.03647", "title": "打破魔镜：激活基自偏好缓解方法在大语言模型评估器中的应用", "title_en": "Breaking the Mirror: Activation-Based Mitigation of Self-Preference in LLM Evaluators", "authors": "Dani Roytburg,Matthew Bozoukov,Matthew Nguyen,Jou Barzdukas,Simon Fu,Narmeen Oozeer", "background": "大型语言模型（LLMs）日益作为自动化评估工具使用，但它们存在“自我偏好偏差”，即倾向于偏向自己的输出而不是其他模型的输出。这种偏差在评估管道中降低了公平性和可靠性，尤其是在偏好调整和模型路由等任务中。本文研究了轻量级引导向量是否能在推理时缓解这一问题，而无需重新训练模型。作者为了解决自我偏好偏差问题，创造了一个精选的数据集，区分了合理和不合理的自我偏好，并利用对比激活添加（CAA）和优化基方法构建了引导向量。研究结果表明，轻量级引导向量可以减少高达97%的不合理自我偏好偏差，明显优于提示和直接偏好优化的基准方法。", "innovation": "作者提出了使用轻量级引导向量来缓解大型语言模型评估器中的自我偏好偏差问题，而不需重新训练模型。通过对比激活添加（CAA）和优化基方法构造了引导向量，并证明了这些方法能够显著减少不合理自我偏好偏差，稳定地提供更高的评估公平性和可靠性。同时，这种影响的不稳定性也说明自我偏好可能涉及多个或非线性的方向，强调了其作为保证LLM作为裁判角色的潜力和局限性，并且推动了更强大的干预措施的发展.", "conclusion": "引导向量可以大幅减少大型语言模型评估器中的不合理自我偏好偏差，但在合理自我偏好和无偏见一致性方面不稳定，表明自我偏好可能在多个或非线性方向上存在。这既强调了引导向量作为保护LLM作为评判者的潜力，也指出了其局限性，并促使开发更稳健的解决方案。"}
{"llm_update_time": "20250907", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.03680", "html_url": "https://arxiv.org/abs/2509.03680", "title": "LuxDiT：基于视频扩散变换器的照明估计", "title_en": "LuxDiT: Lighting Estimation with Video Diffusion Transformer", "authors": "Ruofan Liang,Kai He,Zan Gojcic,Igor Gilitschenski,Sanja Fidler,Nandita Vijaykumar,Zian Wang", "background": "在计算机视觉和图形学中，从单张图像或视频估计场景光照长期以来是一个挑战。基于学习的方法受限于高动态范围（HDR）环境图的真实数据稀缺，这些数据捕获起来成本高且多样性有限。尽管最近的生成模型为图像合成提供了强大的先验信息，但由于光照估计依赖于间接视觉线索、需要推断全局（非局部）上下文以及恢复高动态范围输出，这仍然是一项困难的任务。本研究旨在解决这一挑战，提出了一种数据驱动的方法LuxDiT，通过微调视频扩散变换器生成基于视觉输入的HDR环境图。该模型在包含多种光照条件的大型合成数据集上进行训练，能够从间接视觉线索中推断出照明并有效地泛化到真实场景。为了改善输入与预测环境图之间的语义对齐，还提出了一种低秩适应微调策略，利用HDR全景图数据集。", "innovation": "提出了LuxDiT，一种数据驱动的方法，通过微调视频扩散变换器生成基于视觉输入的HDR环境图，并提出了一种低秩适应微调策略，以改善输入与预测环境图之间的语义对齐。该方法能够在定量和定性的评估中优于现有的其他最先进的技术，提供准确的照明预测，并具有真实的高角度高频细节。", "conclusion": "该方法成功解决了从单张图像或视频估计光照的挑战，通过大规模合成数据集的训练，模型能够有效推断照明并泛化到真实世界场景。提出的低秩适应微调策略进一步提高了输入与预测环境图之间的语义对齐，提升了预测的准确性和现实感。"}
{"llm_update_time": "20250907", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.03695", "html_url": "https://arxiv.org/abs/2509.03695", "title": "无线网络中基于边缘学习与D2D/P2P支持的分层联邦基础模型：多模态多任务智能的集成架构", "title_en": "Hierarchical Federated Foundation Models over Wireless Networks for Multi-Modal Multi-Task Intelligence: Integration of Edge Learning with D2D/P2P-Enabled Fog Learning Architectures", "authors": "Payam Abdisarabshali,Fardis Nadimi,Kasra Borazjani,Naji Khosravan,Minghui Liwang,Wei Ni,Dusit Niyato,Michael Langberg,Seyyedali Hosseinalipour", "background": "基础模型（FMs）的发展已经重新定义了机器学习的格局。这些模型的不断增长使从无线设备地理分布的数据中进行利用变得越来越重要，这导致了联邦基础模型（FFMs）的出现。最近，FMs 发展成为多模态多任务（M3T）FMs（如 GPT-4），能够处理多种任务和多模态数据。这促进了 M3T FFMs 的新范式的探讨。模态异质性和任务异质性是Fog/边缘网络中的两个被忽视的领域，对这些新兴模型有着直接影响。现有模型尚未考虑如何与雾/边缘基础设施的层次结构有效匹配及其在设备间通信中的应用难点", "innovation": "本文提出了一种新型的 M3T FFMs 变种——分层联邦基础模型（Hierarchical Federated Foundation Models，HF-FMs），并探讨了它们在雾/边缘网络中的应用。HF-FMs 拓展了 FMs 的结构，使其与雾/边缘基础设施的层次结构相匹配，同时引入了设备到设备（D2D）通信的可选使用，以实现水平模块的传输和节点间的局部协作性训练。此外，研究还指出了 HF-FMs 的独特功能及其未来的研究方向。", "conclusion": "通过在无线网络环境中实现 HF-FMs，并公开源代码以促进对该领域的进一步研究，本文展示了 HF-FMs 的潜力。"}
{"llm_update_time": "20250907", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.03741", "html_url": "https://arxiv.org/abs/2509.03741", "title": "为ELA教学设计凝视分析：带有对话式人工智能支持的用户中心式仪表板", "title_en": "Designing Gaze Analytics for ELA Instruction: A User-Centered Dashboard with Conversational AI Support", "authors": "Eduardo Davalos,Yike Zhang,Shruti Jain,Namrata Srivastava,Trieu Truong,Nafees-ul Haque,Tristan Van,Jorge Salas,Sara McFadden,Sun-Joo Cho,Gautam Biswas,Amanda Goodwin", "background": "眼动追踪技术能够提供丰富的学生认知和参与度洞察，但由于数据解读和无障碍获取的挑战，在面对教室的教育技术中依然未得到广泛应用。进一步的研究揭示了教师和学生在研究中的参与情况，通过五项研究发现这些问题需要通过用户中心和数据讲故事的原则来解决，以支持反思、形成性评估和教学决策。", "innovation": "提出了一种基于凝视数据的教学分析仪表板的设计与评估，采用了对话式人工智能技术帮助用户更自然地与多模态学习分析进行交互，从而降低认知障碍，促进对凝视数据的理解。这一发明通过使用熟知的可视化展示、分层解释和叙述支架，使凝视分析更加易于接受且具有教育价值。", "conclusion": "对于未来旨在将新型数据模态整合到课堂教学中的教育技术系统，提出了设计含义，以期进一步提高教育教学的质量和效率。"}
{"llm_update_time": "20250907", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.03725", "html_url": "https://arxiv.org/abs/2509.03725", "title": "MLSD: 一种增强跨目标和跨域立场检测的新颖少样本学习方法", "title_en": "MLSD: A Novel Few-Shot Learning Approach to Enhance Cross-Target and Cross-Domain Stance Detection", "authors": "Parush Gera,Tempestt Neal", "background": "本文提出了一种新颖的立场检测方法，即基于度量学习的少样本学习方法（MLSD），适用于跨领域和跨目标的立场检测。MLSD 通过利用三元组损失进行度量学习，从而捕捉不同立场目标之间的语义相似性和差异性，增强了领域适应能力。通过构建具有区分性的嵌入空间，MLSD 可以让跨目标或跨域立场检测模型从新目标领域中获取有用的示例，从而提高模型的适用性和通用性。本研究在两个数据集的多个跨目标和跨域场景下评估了 MLSD，结果显示该方法在六种广泛使用的立场检测模型中表现出显著的性能提升。", "innovation": "本文提出了一种基于度量学习的少样本学习方法 MLSD，通过三元组损失捕捉跨目标和跨域之间的语义差异和相似性，增强了立场检测的领域适应能力。", "conclusion": "本研究在两个数据集上验证了 MLSD 在多个跨目标和跨域场景下表现出的显著性能提升，证明了 MLSD 对跨域和跨目标立场检测的有效性和优越性。"}
{"llm_update_time": "20250907", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.03771", "html_url": "https://arxiv.org/abs/2509.03771", "title": "学习对抗世界模型以生成MARL中的自动进阶课程", "title_en": "Learning an Adversarial World Model for Automated Curriculum Generation in MARL", "authors": "Brennen Hill", "background": "环境生成的世界模型在孕育自主智能方面至关重要，但因手工设计的复杂性和潜在偏差，其潜力受到限制。为了创建通用且强大的智能代理，需要随着代理能力的增长而扩展环境的复杂度。本文重新定义了环境生成的挑战，将其视为学习目标条件下生成世界模型的问题。通过此框架，代理能够适应不断变化的挑战，促进协同学习和进化。", "innovation": "提出了一种系统，其中生成式的攻击者代理学习隐式世界模型来合成更加困难的挑战，而协作的防御者代理则致力于克服这些生成的环境。这种协同进化的动态创建了一个自适应加新的训练场景流。研究表明，这种对抗性协同进化方法能促使世界模型学会生成侧翼和防护阵型，并促使防御者学会集中火力和拉开战术，进一步驱动代理发展出更深层次和鲁棒性的策略。", "conclusion": "通过这种方法，代理能够应对不断变化的挑战，从而在智能代理中促进更加复杂的策略性和战术性行为的发展，表明对抗性协同进化是学习指令性世界模型的强大方法，可以引导代理朝向更大的战略深度和鲁棒性。"}
{"llm_update_time": "20250907", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.03733", "html_url": "https://arxiv.org/abs/2509.03733", "title": "差分熵正则化在几何和神经网络中的应用", "title_en": "Differentiable Entropy Regularization for Geometry and Neural Networks", "authors": "Ibne Farabi Shihab,Sanjeda Akter,Anuj Sharma", "background": "范围分区熵是一种来自计算几何的近期概念，能够使算法适应输入的‘排序程度’，它在算法设计中提供了强有力的保证，但尚未被深度学习所利用。本文引入了一个可微分的范围分区熵估计器，并设计了一个名为EntropyNet的神经模块，它能够将数据重新结构化以加速下游最优算法。此外，直接将熵正则化应用于Transformer的注意机制中，从而扩大了这个概念的应用范围。", "innovation": "本文首次提出了范围分区熵的可微分近似方法，使其能够在深度学习中作为可训练的损失函数或正则化器使用；设计了EntropyNet神经模块，能够将其输入结构化为低熵形式，加速下游最优算法；并直接将熵正则化应用于Transformer的注意机制中，改善了注意力机制的结构化表现。", "conclusion": "通过实验表明，差分熵在保持正确性的同时提高了效率：在几何问题中实现了高达4.1倍的运行时加速且错误率几乎无变化（<0.2%），在深度学习中则实现了比L1基线更高的6%准确率，同时保持了80%的稀疏性。理论分析提供了估计器的近似边界，详尽的消融实验验证了设计选择。这些结果表明，受限熵的计算不仅是理论上的精妙，也是一种适应学习、提高效率和促进结构化表示的实用机制。"}
{"llm_update_time": "20250907", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.03757", "html_url": "https://arxiv.org/abs/2509.03757", "title": "ARDO: 基于随机测试函数差分的椭圆和抛物线PDE弱形式深度神经网络方法", "title_en": "ARDO: A Weak Formulation Deep Neural Network Method for Elliptic and Parabolic PDEs Based on Random Differences of Test Functions", "authors": "Wei Cai,Andrew Qing He", "background": "本文提出了ARDO方法，利用深度学习技术解决偏微分方程（PDE）及其相关问题。该方法采用弱对抗形式，但将随机差分运算转移到测试函数上。这种方法的主要优势在于，相对于解神经网络，它是完全无导数的。该框架特别适用于Fokker-Planck类型的二阶椭圆和抛物线PDEs。", "innovation": "ARDO方法利用弱对抗形式，通过将随机差分运算法则应用于测试函数，而非直接作用于解神经网络。这种方法的优势在于其对解神经网络的无导数性，使得数值计算更为简单高效，并特别适用于处理特定类型的椭圆和抛物线PDEs。", "conclusion": "本文提出的方法ARDO，是一种基于深度学习技术解决PDE问题的新方法。其核心在于通过弱形式和随机差分运算来简化计算过程，特别适用于处理特定类型的椭圆和抛物线PDEs。"}
{"llm_update_time": "20250907", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.03780", "html_url": "https://arxiv.org/abs/2509.03780", "title": "自然潜在变量：跨范畴的潜在变量稳定性", "title_en": "Natural Latents: Latent Variables Stable Across Ontologies", "authors": "John Wentworth,David Lorell", "background": "假设存在两个贝叶斯代理，它们各自构建了相同环境的生成模型。尽管这两个代理在观测数据的预测分发方面已经收敛，但在潜在变量模型上可能有所不同。本文探讨了在哪些条件下，一个代理可以保证其潜在变量是另一个代理潜在变量的函数。文章通过给出自然潜在变量条件下的简单条件，证明了这种翻译在一定条件下总是可以保证的。此外，证明了在缺乏额外约束的情况下，这是保证可翻译性的最广泛条件。文章的关键之处在于，其定理对自然潜在变量条件中的误差具有一定鲁棒性。", "innovation": "本文提出了自然潜在变量条件，并通过这些条件证明了在一定条件下，一个代理的潜在变量可以被保证是另一个代理潜在变量的函数。同时，指出这是在缺乏额外约束情况下的最广泛条件，具有对误差的鲁棒性。", "conclusion": "本文通过自然潜在变量条件下的简单定理，确保了一个代理的潜在变量可以被保证是另一个代理潜在变量的函数，该结论在实际应用中具有重要作用和普遍适用性。"}
{"llm_update_time": "20250907", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.03790", "html_url": "https://arxiv.org/abs/2509.03790", "title": "奖励函数中什么基本结构能够促进稀疏奖励的有效学习？", "title_en": "What Fundamental Structure in Reward Functions Enables Efficient Sparse-Reward Learning?", "authors": "Ibne Farabi Shihab,Sanjeda Akter,Anuj Sharma", "background": "该论文探讨了奖励函数的哪些基本属性能够促进高效稀疏奖励强化学习。通常，稀疏奖励导致样本复杂度呈指数级增长，这是稀疏奖励强化学习中的一个挑战。", "innovation": "作者通过探讨奖励矩阵的低秩结构，展示了这种结构能引起样本复杂度从指数级转变为多项式级的突变。这是稀疏奖励RL领域首次见到的此类结果。此外，论文引入了Policy-Aware矩阵完成（PAMC）方法，连接了矩阵完成理论与强化学习，并提出了新的策略依赖采样分析。PAMC的优点包括：无假设的不可能结果、基于动态的无奖励表示学习、无分布置信集以及当低秩结构仅为近似情况时逐步退化的稳健完成保证。", "conclusion": "实验表明，PAMC相比强大的探索、结构化和表示学习基线在样本效率上提高了1.6至2.1倍，同时仅增加了约20%的计算成本。实验结果确立了结构性奖励学习作为具有紧迫实际影响的新范式的可行性，特别是在机器人技术、医疗保健等行业中有直接的应用影响。"}
{"llm_update_time": "20250907", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.03738", "html_url": "https://arxiv.org/abs/2509.03738", "title": "稀疏自编码器神经算子：函数空间中的模型恢复", "title_en": "Sparse Autoencoder Neural Operators: Model Recovery in Function Spaces", "authors": "Bahareh Tolooshams,Ailsa Shen,Anima Anandkumar", "background": "尽管柏拉图表征假设认为神经网络在不同架构中收敛到相似的表征，神经算子（NO）的表征属性在科学研究计算中日益重要的同时却很少受到研究。本文对比了稀疏自编码器（SAEs）、提升的 SAES（lifted-SAE）和 SAES 神经算子的推理和训练动态，探讨了如何将稀疏自编码器扩展到提升空间和无限维函数空间，进而解决神经模型统一表示的问题，并分析提升和算子模块引入的有益归纳偏置，即加速恢复、改进光滑概念的恢复以及在不同分辨率上提供鲁棒的推理能力，这在神经算子中是独特的特性.", "innovation": "提出了一个框架，该框架扩展了稀疏自编码器到提升空间和无限维函数空间，使得大型神经算子具有机械解释性；对比了 SAEs、lifted-SAE 和 SAE 神经算子的推理和训练动态；突出展示了提升和算子模块引入的有益归纳偏置，这些偏置加速了恢复，改进了光滑概念的恢复，并在不同分辨率上提供了鲁棒的推理能力，这是神经算子中的独特特性.", "conclusion": "提升和算子模块在统一表示中引入了有益的归纳偏置，加快了恢复过程，更准确地恢复了平滑概念，并在不同分辨率下提供了鲁棒的推理能力，这是神经算子的独特特性。"}
{"llm_update_time": "20250907", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.03754", "html_url": "https://arxiv.org/abs/2509.03754", "title": "STA-Net: 一种解耦形貌和纹理注意力网络的轻量植物病害分类模型", "title_en": "STA-Net: A Decoupled Shape and Texture Attention Network for Lightweight Plant Disease Classification", "authors": "Zongsen Qiu", "background": "为了应对全球对粮食安全需求的上升，精准农业和基于深度学习的植物病害诊断变得至关重要。然而，将高精度模型部署到边缘设备上具有挑战性。大多数轻量级网络使用设计用于通用物体识别的注意力机制，这些机制对捕捉细微的病理特征，如不规则的病斑形态和复杂的纹理，效果不佳。", "innovation": "本文提出了两方面的解决方案：首尔，使用无训练的神经架构搜索方法（DeepMAD）创建适用于边缘设备的高效网络骨干，其次提出了形貌-纹理注意力模块（STAM）。STAM将注意力机制分为两条分支，即使用可变形卷积（DCNv4）进行形貌感知，另一条使用Gabor滤波器进行纹理感知。在公共的CCMT植物病害数据集上，STA-Net模型（含有401K个参数和51.1M FLOPs）取得了89.00%的准确率和88.96%的F1分数。消融研究证实，STAM显著改进了基线和标准注意力模型的性能。通过解耦注意力机制整合领域知识，这为边缘部署的精准农业人工智能提供了一条有希望的道路。", "conclusion": "本文提出的STA-Net模型通过解耦形貌和纹理注意力机制提高了轻量级植物病害分类的性能，为边缘设备上的精准农业人工智能部署提供了新的解决方案。"}
{"llm_update_time": "20250907", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.03793", "html_url": "https://arxiv.org/abs/2509.03793", "title": "SAMVAD：印度司法审议动态模拟的多代理系统", "title_en": "SAMVAD: A Multi-Agent System for Simulating Judicial Deliberation Dynamics in India", "authors": "Prathamesh Devadiga,Omkaar Jayadev Shetty,Pooja Agarwal", "background": "理解司法审议的复杂性对于评估司法制度的有效性和公平性至关重要。然而，关于司法小组的实证研究受到伦理和实践障碍的限制。", "innovation": "本研究引入了一种名为SAMVAD的创新多代理系统（MAS），旨在模拟印度司法系统的审议过程。SAMVAD集成了检索增强生成（RAG）功能，基于特定领域的知识库，包括印度宪法和印度刑法等标志性法律文件。这种RAG功能使法官和律师代理能够在模拟中生成符合法律规范的指令和论点，从而提升模拟的真实性和透明度。", "conclusion": "本研究提供了一个可配置且可解释的MAS平台，用于探索法律推理和小组决策动态在司法模拟中的应用，特别针对印度的法律环境，并通过RAG实现了可验证的法律依据。该研究还详细描述了系统架构、代理通信协议、RAG管道、模拟工作流以及全面的评估计划，以评估性能、审议质量和结果一致性。"}
{"llm_update_time": "20250907", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.03791", "html_url": "https://arxiv.org/abs/2509.03791", "title": "SiLVERScore: 评分感知嵌入用于手语生成评估", "title_en": "SiLVERScore: Semantically-Aware Embeddings for Sign Language Generation Evaluation", "authors": "Saki Imai,Mert İnan,Anthony Sicilia,Malihe Alikhani", "background": "现有的手语生成评估方法通常是通过反向翻译进行的，即生成的手语首先被识别为文本，然后使用基于文本的度量标准与参考文本进行比较。这种方法在两个步骤的评估管道中引入了不确定性，不仅未能捕捉手语的多模态特性（如面部表情、空间语法和语调），而且使评估错误难以区分来源于生成模型还是用于评估的手译系统。", "innovation": "提出了一种新型的语义感知嵌入评价指标SiLVERScore，用于在联合嵌入空间中评估手语生成。包括：（1）识别现有指标的局限性，（2）引入了用于语义感知评估的SiLVERScore，（3）展示了其对语义和语调变化的鲁棒性，（4）探讨了在不同数据集上的泛化挑战。", "conclusion": "SiLVERScore在PHOENIX-14T和CSL-Daily数据集上能够有效地区分正确的和随机配对的手语生成（ROC AUC = 0.99，重叠<7%），明显优于传统度量标准。"}
{"llm_update_time": "20250907", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.03842", "html_url": "https://arxiv.org/abs/2509.03842", "title": "INGRID：使用大型语言模型的智能生成机器人设计", "title_en": "INGRID: Intelligent Generative Robotic Design Using Large Language Models", "authors": "Guanglu Jia,Ceng Zhang,Gregory S. Chirikjian", "background": "大型语言模型（LLMs）的集成加速了具身人工智能的进步，但当前的方法仍然受到现有机器人架构的限制，尤其是串行机制。这种硬件依赖性从根本上限制了机器人智能的范围。", "innovation": "提出了INGRID（Intelligent Generative Robotic Design）框架，通过深度结合互反螺线理论和运动合成方法，实现了并行机器人机制的自动化设计。该框架将设计挑战分解为四个逐步任务：约束分析、运动关节生成、链路构造和完整机制设计。INGRID展示了生成具有固定和可变移动性的新并行机制的能力，发现了文献中未记录的运动配置。", "conclusion": "通过将机制理论和机器学习相结合，INGRID使没有专门机器人培训的科研人员能够创建自定义并行机制，从而将机器人智能的进步与硬件约束脱钩。这项工作为机制智能奠定了基础，其中AI系统主动设计机器人硬件，有可能彻底改变具身AI系统的开发。"}
{"llm_update_time": "20250907", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.03809", "html_url": "https://arxiv.org/abs/2509.03809", "title": "Align-then-Slide：超长文档级机器翻译的完整评估框架", "title_en": "Align-then-Slide: A complete evaluation framework for Ultra-Long Document-Level Machine Translation", "authors": "Jiaxin Guo,Daimeng Wei,Yuanchang Luo,Xiaoyu Chen,Zhanglin Wu,Huan Yang,Hengchao Shang,Zongyao Li,Zhiqiang Rao,Jinlong Yang,Hao Yang", "background": "大型语言模型（LLMs）为文档级别机器翻译(doc-mt)带来了新的时代，但它们的整体文档输出挑战了现有的基于句子对齐的评估方法。当前的评估方法假设源文本和目标文本间的句子是逐一对应的，而LLMs的输出无法满足这一假设。", "innovation": "提出了一种名为‘Align-then-Slide’的完整评估框架，用于超长文档级别的机器翻译。该框架包括自动推理句子级源目标对应关系的‘Align’阶段和计算不同粒度下评估指标得分的‘n-Chunk Sliding Evaluate’阶段。此框架显著提高了评价的准确性与鲁棒性，并且通过Align-then-Slide产生的偏好数据，能够有效地培训CPO模型，并直接用作GRPO奖励模型，从而产生更受人偏好翻译。", "conclusion": "实验表明，这种方法与专家评估结果具有0.929的皮尔逊相关系数，并在真实世界数据集上与人类判断吻合紧密。此外，Align-then-Slide产生的偏好数据能够有效提升CPO和GRPO的训练效果，特别是生成了更受人类偏好的翻译，证明了该框架作为一种准确、稳健和可操作的评估工具的有效性。"}
{"llm_update_time": "20250907", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.03845", "html_url": "https://arxiv.org/abs/2509.03845", "title": "通过概率上下文变量进行Mean Field Games的元逆强化学习", "title_en": "Meta-Inverse Reinforcement Learning for Mean Field Games via Probabilistic Context Variables", "authors": "Yang Chen,Xiao Lin,Bo Yan,Libo Zhang,Jiamou Liu,Neset Özkan Tan,Michael Witbrock", "background": "在实际应用中，设计适合众多相互智能代理的奖励函数具有挑战性。逆强化学习(简称IRL)在均场博弈(简称MFG)中的应用提供了一种实用框架，通过专家演示推理出奖励函数。然而，现有方法假设代理的同质性限制了其处理具有异质性和未知目标的演示数据的能力，这在实践中是常见的。", "innovation": "本文提出了一种深度潜变量MFG模型及其相应的IRL方法。重要的是，我们的方法可以从不同但结构相似的任务推断奖励，无需先验知识了解背景条件或修改MFG模型本身。实验结果显示，我们的方法在MFG的IRL方法中表现优越。", "conclusion": "在模拟场景和一个实际的地理出租车价格问题中进行的实验表明，相比于最新的IRL方法，我们的方法在MFG中具有更大的优势。"}
{"llm_update_time": "20250907", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.03805", "html_url": "https://arxiv.org/abs/2509.03805", "title": "测量VLMs如何（而非仅仅是否）建立共同认知", "title_en": "Measuring How (Not Just Whether) VLMs Build Common Ground", "authors": "Saki Imai,Mert İnan,Anthony Sicilia,Malihe Alikhani", "background": "现有的视觉语言模型（VLMs）虽然声称具有推理能力，但当前的基准测试仅在单轮问答或问答设置中评估它们。然而，事实证明，Grounding是一个互动过程，人们通过持续沟通逐步建立共同理解。传统的评价手段未能涵盖这种互动性质，本文引入一套四个评价指标（Grounding效率、内容一致性、词汇适应性以及人类相似度）以系统性地评价VLM在互动Grounding中的表现，并在自游戏会话中应用这些指标，与人类互动组进行了对比，揭示了VLMs与人类交互存在显著差异的情况。", "innovation": "文章创新性地提出了评估视觉语言模型在互动Grounding中的表现的一套四维评价指标，包括Grounding效率、内容一致性、词汇适应性以及人类相似度，并通过自游戏会话研究方法来对比人工交互与模型交互的表现，揭示了模型与人类交互时的显著差异，证明了传统评价方法的不足，并提出新的研究框架。此外，项研究突破了传统评估方法仅关注是否达到任务目标的评价方式，强调了交互过程及人类相似度等关键因素的重要性，这对于未来VLMs的评价具有显著的创新意义。", "conclusion": "本文的研究表明，仅依靠任务成功率来评价VLMs的Grounding效果并不准确，图像描述的一致性也未必能够预测任务的成功率。因此，研究者需要多层次、多维度地评价VLMs的性能，而提出的一系列新评价指标反映了这一发展方向，可以作为未来研究VLMs建立共同认知的框架。"}
{"llm_update_time": "20250907", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.03884", "html_url": "https://arxiv.org/abs/2509.03884", "title": "基于多层感知器神经网络的肽组学预测模型用于冠心病诊断", "title_en": "Peptidomic-Based Prediction Model for Coronary Heart Disease Using a Multilayer Perceptron Neural Network", "authors": "Jesus Celis-Porras", "background": "冠心病是全球主要的死因之一，对年度医疗开支有重大影响。为了开发一种非侵入性诊断方法，本研究通过遗传算法选择了50种关键尿肽生物标志物，并构建了一个基于多层感知器（MLP）神经网络的模型。", "innovation": "该研究使用遗传算法选择了尿液中的50种关键肽类生物标志物，并基于这些标志物构建了一个神经网络模型。模型通过合成少数过采样技术（SMOTE）平衡了治疗组和对照组，使用分层验证策略进行训练。模型实现了95.67%的精度，95.65的F1分数，AUC值为0.9748和MCC、库普兰系数分别为0.9134和0.9131，表明该模型在冠心病的诊断上具有高度的准确性和稳健性。", "conclusion": "该研究证明了构建的神经网络模型为冠心病提供了一种高效且可靠的非侵入性诊断工具。"}
{"llm_update_time": "20250907", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.03832", "html_url": "https://arxiv.org/abs/2509.03832", "title": "基于LLM的确认偏差模型的重力井回声室建模", "title_en": "Gravity Well Echo Chamber Modeling With An LLM-Based Confirmation Bias Model", "authors": "Joseph Jackson,Georgiy Lapin,Jeremy E. Thompson", "background": "社交媒体中的回声室在错误信息的传播中起着关键作用，但现有模型经常忽视了个体确认偏差的影响。已有研究中，回声室被比喻为‘重力井’模式，但在这种模型中，确认偏差的作用没有得到动态体现。本文通过引入一个动态确认偏差变量，该变量根据用户的信仰强化内容的敏感性调整拉力的强度，扩展了这一既有模型，提高了识别回声室的准确性并对社区层面的信息健康标志进行了揭示。实验验证显示这种方法在十九个Reddit社区的回声室检测中表现更优。", "innovation": "本文提出了一个结合了基于LLM的确认偏差模型的动态重力井回声室建模方法，这一模型能够系统地捕捉在线群体动态中的确认偏差作用，更准确地识别回声室，并揭示了社区层面的信息健康标志。通过这种方法，模型能够更有效地发现高风险环境，从而支持对抗错误信息的传播。", "conclusion": "我们的贡献是一个框架，用于系统地捕捉确认偏差在线群体动态中的作用，这通过对回声室的有效识别支持了对抗错误信息传播的努力。通过标记这些高风险环境，模型有助于减少错误信息在常见放大点的传播。"}
{"llm_update_time": "20250907", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.03873", "html_url": "https://arxiv.org/abs/2509.03873", "title": "SalientFusion: 面向上下文的组分零样本食物识别", "title_en": "SalientFusion: Context-Aware Compositional Zero-Shot Food Recognition", "authors": "Jiajun Song,Xiaoou Liu", "background": "食物识别已受到广泛关注，但新菜品的迅速出现需要能够识别未见过的食物类别的方法，从而推动了零样本食物学习（ZSFL）的发展。然而，这引发了新的挑战：（1）冗余背景信息可能分散模型从学习有意义的食物特征中的注意力；（2）主食和配菜角色混淆导致分类错误；（3）单个属性中的语义偏见可能导致理解混乱。", "innovation": "本文提出了面向上下文的组分零样本食物识别（SalientFusion），该方法包括两个组成部分：SalientFormer，它去除背景冗余并使用深度特征解决角色混淆；DebiasAT，它通过视觉特征对齐提示以减少语义偏见。这些创新方法在CZSFood-90和CZSFood-164基准测试中表明，SalientFusion在这些基准测试中和一般的CZSL数据集上均取得了最好的性能。", "conclusion": "通过使用我们提出的基准测试，CZSFood-90和CZSFood-164，我们展示了SalientFusion在这些基准测试上达到了最先进的性能，同时也适用于主流的一般CZSL数据集。相关代码可在该网址获取：this https URL."}
{"llm_update_time": "20250907", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.03852", "html_url": "https://arxiv.org/abs/2509.03852", "title": "MillGNN：学习多尺度领先滞后依赖性以进行多变量时间序列预测", "title_en": "MillGNN: Learning Multi-Scale Lead-Lag Dependencies for Multi-Variate Time Series Forecasting", "authors": "Binqing Wu,Zongjiang Shang,Jianlong Huang,Ling Chen", "background": "多变量时间序列（MTS）预测对于各类应用至关重要。现有方法虽然显示出令人鼓舞的结果，但由于其强大的内在和跨变量依赖性捕捉能力，但往往忽略了在多个分组尺度上的领先滞后依赖关系，未能捕获复杂系统中的多层次领先滞后效应。", "innovation": "1. 引入了一个针对各尺度的特定领先滞后图学习模块，该模块结合了基于实时输入和时间滞后推导出的交叉相关系数和动态衰减特征，用于学习各尺度的领先滞后依赖关系，并可建模统计可解释性和数据驱动的灵活性的演变领先滞后依赖关系；2. 引入了一种层次结构的领先滞后消息传递模块，能够以结构化方式在多分组尺度上传播领先滞后消息，同时传播内在和跨尺度的领先滞后效应，以平衡全面性和效率捕获多尺度的领先滞后效应。", "conclusion": "在11个数据集上的实验结果表明，与16个最先进的方法相比，MillGNN在长短期MTS预测中表现出色。"}
{"llm_update_time": "20250907", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.03834", "html_url": "https://arxiv.org/abs/2509.03834", "title": "从莱登到快乐岛：常数波德斯模型作为效用博弈的社区检测", "title_en": "From Leiden to Pleasure Island: The Constant Potts Model for Community Detection as a Hedonic Game", "authors": "Lucas Lopes Felipe,Konstantin Avrachenkov,Daniel Sadoc Menasche", "background": "社区检测是数据科学中的基础问题，涉及将节点划分为不相交的社区。本文从博弈论的角度探讨了常数波德斯模型（CPM）在划分网络为不相交社区方面的应用，突出了其效率、鲁棒性和准确性。", "innovation": "通过将CPM重新解释为潜在效用博弈，将全局哈密顿量分解为局部效用函数，使得每个代理的局部效用增益与相应的全局效用增加相匹配。利用这种等价性，证明了通过更好的响应动态局部优化CPM目标在伪多项式时间内收敛到平衡划分。引入了两种稳定性的标准：一种基于新颖的鲁棒性概念的严格标准（要求节点在同一社群中同时最大化邻居和最小化非邻居），另一种基于这些目标加权和的放松效用函数标准，由一个分辨率参数控制。", "conclusion": "在社区跟踪场景中，使用初始划分来引导带有部分真实社区信息的莱登算法，实验表明鲁棒划分能更准确地恢复真实社区。"}
{"llm_update_time": "20250907", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.03871", "html_url": "https://arxiv.org/abs/2509.03871", "title": "全面探讨大型语言模型推理中的信任性", "title_en": "A Comprehensive Survey on Trustworthiness in Reasoning with Large Language Models", "authors": "Yanbo Wang,Yongcan Yu,Jian Liang,Ran He", "background": "长CoT（Chain-of-Thought）推理的发展提高了大模型（LLM）在多种任务中的表现，包括语言理解、复杂问题解决和代码生成。这种范式使模型能够生成中间推理步骤，从而提高准确性和可解释性。尽管如此，CoT（Chain-of-Thought）推理对语言模型信任度的影响仍缺乏全面理解。\n研究模型和CoT技术的最新工作集中在五个核心维度的可靠推理上：真实性、安全性、鲁棒性、公平性和隐私性。每个维度都提供了按时间顺序的清晰概述和详细分析，包括方法论、发现及其局限性。此外，还附录了未来研究方向，以供参考和讨论。\n尽管推理技术有潜力通过减少幻觉、检测有害内容和提高鲁棒性来提升模型的信任度，但最先进的推理模型在安全性、鲁棒性和隐私性方面通常也存在类似的或更大的脆弱性。\n通过综合这些见解，本文旨在为人工智能安全社区提供有价值和及时的信息资源，以了解推理信任的研究进展。相关论文列表可以在此 https URL 查找。", "innovation": "本文全面调研了大型语言模型推理中的信任性问题，特别是探讨了五个核心维度（真实性、安全性、鲁棒性、公平性和隐私性）的可靠推理及其相关最新研究。研究不仅提供了详细的学术分析，还指出了未来的研究方向。\n", "conclusion": "尽管推理技术有可能提升模型的信任度，但最先进的推理模型在安全性、鲁棒性和隐私性方面仍面临相似或更大的挑战。本文旨在为AI安全社区提供有价值的信息资源，汇总最新的推理信任研究进展。"}
{"llm_update_time": "20250907", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.03898", "html_url": "https://arxiv.org/abs/2509.03898", "title": "扩散生成模型遇见压缩感知，应用于图像数据和金融时间序列", "title_en": "Diffusion Generative Models Meet Compressed Sensing, with Applications to Image Data and Financial Time Series", "authors": "Zhengyi Guo,Jiatu Li,Wenpin Tang,David D. Yao", "background": "本文旨在通过对合成数据生成中扩散模型推断进行加速来发展降维技术。背景是将压缩感知技术集成到扩散模型中：首先压缩数据至潜在空间，然后在潜在空间中训练扩散模型，并最后在一个潜在空间生成样本上应用压缩感知算法，从而提高了模型训练和推理的效率。在适当稀疏假设的情况下，通过结合扩散模型推断与稀疏恢复，所提出的算法证明了更快的收敛速度。作为一种副产品，我们获得了一个潜在空间维度的最佳值。并且在多种数据集上进行了数值实验，包括图像数据（手写数字、医学图像、气候数据）和金融时间序列的压力测试", "innovation": "创新是在扩散模型中整合压缩感知技术，通过潜在空间压缩数据进行模型训练，并利用压缩感知算法提高生成样本的效率，从而实现模型训练和推理的加速。此外，研究还证明了在适当稀疏假设下的算法可以提高收敛速度，并通过相关实验验证了潜在空间维度的最佳值。", "conclusion": "在适当稀疏假设下，结合扩散模型推断与稀疏恢复的算法可以更快收敛。在多种数据集上的实验验证了该算法的有效性，并通过压缩感知技术提高了模型推理的速度。"}
{"llm_update_time": "20250907", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.03934", "html_url": "https://arxiv.org/abs/2509.03934", "title": "SelfAug: 通过分布自我对齐缓解检索增强生成中的灾难性遗忘", "title_en": "SelfAug: Mitigating Catastrophic Forgetting in Retrieval-Augmented Generation via Distribution Self-Alignment", "authors": "Yuqing Huang,Rongyang Zhang,Qimeng Wang,Chengqiang Lu,Yan Gao,Yi Wu,Yao Hu,Xuyang Zhi,Guiquan Liu,Xin Li,Hao Wang,Enhong Chen", "background": "近年来，大规模语言模型（LLMs）在自然语言处理领域取得了革命性进展，它们在理解和执行多种任务方面表现出色。特别是在检索增强生成（RAG）场景中，监督微调能够显著提升特定任务性能，但往往会导致灾难性遗忘，即模型会丢失先前获得的知识和通用能力。现有解决方案要么需要访问通用指令数据，要么在保留模型原始分布方面受限。", "innovation": "为克服这些限制，我们提出了SelfAug，一种自我分布对齐方法，该方法将输入序列的logits对齐，以保持模型的语义分布，从而减轻灾难性遗忘并提高下游性能。广泛的实验表明，SelfAug能够在下游学习与通用能力保留之间取得更佳平衡。通过对实验的全面分析，我们发现分布转移与RAG场景中灾难性遗忘的严重程度之间存在直接关联，揭示了通用指令微调中缺乏RAG能力如何导致fine-tuning期间显著的分布转移。", "conclusion": "我们的发现不仅推进了对于RAG背景下灾难性遗忘的理解，还提供了一种适用于不同微调场景的实用解决方案。该代码已公开，可通过以下链接获取：this https URL"}
{"llm_update_time": "20250907", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.03889", "html_url": "https://arxiv.org/abs/2509.03889", "title": "借助自信感知密集对应和视触可用性进行空中服装操作", "title_en": "Reactive In-Air Clothing Manipulation with Confidence-Aware Dense Correspondence and Visuotactile Affordance", "authors": "Neha Sunil,Megha Tippur,Arnau Saumell,Edward Adelson,Alberto Rodriguez", "background": "操作服装具有挑战性，因为衣服的配置复杂、材料动态多变且经常自遮挡。当前的系统经常将衣物压平或假设关键特征的可见性。因此，需要一种结合信心感知密集视觉对应和触觉监督抓取可用性的双臂视触框架，直接作用于折叠和悬空的衣物上，以解决这些困难。", "innovation": "该论文提出了一个新的双臂视触框架，结合了信心感知的密集视觉对应和触觉监督的抓取可用性，可以直接处理折叠和悬空的衣物。该对应模型使用描述性损失进行训练，捕捉布料对称性并生成对应信心估计，这些估计指导一个反应状态机，根据感知不确定性调整折叠策略。同时使用触觉分类器确定物理上可抓取的区域，并实时进行抓取验证。通过在低信心状态下延迟行动，系统可以处理高度遮挡的桌面和空中配置。", "conclusion": "该框架展示了任务无关的抓取选择模块在折叠和挂起任务中的应用。此外，密集描述符提供了其他规划模态的可重用中间表示，例如从人类示范视频中提取抓取目标，促进了更通用和可扩展的服装操作。"}
{"llm_update_time": "20250907", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.03950", "html_url": "https://arxiv.org/abs/2509.03950", "title": "使用EfficientNet-B4迁移学习在U-Net架构下的胸部X光气胸分割", "title_en": "Chest X-ray Pneumothorax Segmentation Using EfficientNet-B4 Transfer Learning in a U-Net Architecture", "authors": "Alvaro Aranibar Roque,Helga Sebastian", "background": "气胸是指胸膜腔内异常积聚空气的情况，如果不被发现可能危及生命。胸部X光是诊断的第一线工具，但小的气胸可能不易察觉。因此，迫切需要一种自动化的方法来提高气胸检测的准确性，以支持放射科医生的工作。", "innovation": "本文提出了一种基于U-Net架构使用EfficientNet-B4编码器的自动化深度学习管道，用于气胸分割。该模型通过增强数据训练，并结合二元交叉熵和Dice损失函数进行训练，显著提高了气胸检测的准确性，IoU达到了0.7008，Dice分数为0.8241。", "conclusion": "该模型能够准确地定位气胸区域，支持放射科医生的工作，并表明使用深度学习方法进行气胸自动分割是可行的。"}
{"llm_update_time": "20250907", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.03937", "html_url": "https://arxiv.org/abs/2509.03937", "title": "SPFT-SQL：通过自我博弈微调增强大型语言模型的文本到SQL解析", "title_en": "SPFT-SQL: Enhancing Large Language Model for Text-to-SQL Parsing by Self-Play Fine-Tuning", "authors": "Yuhao Zhang,Shaoming Duan,Jinhang Su,Chuanyi Liu,Peiyi Han", "background": "尽管自我博弈微调（SPIN）取得了显著进展，能够通过不同能力模型之间的竞争性互动将弱大型语言模型（LLM）转化为强大的模型，但在文本到SQL任务上仍面临挑战。SPIN 不生成新信息，而且对手模型在自我博弈过程中生成大量正确的SQL查询，降低了主要模型生成准确SQL查询的能力。", "innovation": "本文提出了一种针对文本到SQL任务的新自我博弈微调方法，称为SPFT-SQL。在自我博弈之前，引入了一种基于验证的迭代微调方法，根据数据库模式和验证反馈生成高质量的微调数据，提高模型性能并建立不同能力的模型基。在自我博弈微调阶段，提出了一种基于错误的损失方法，激励对手模型生成错误输出，使主要模型能够区分正确的SQL和对手模型生成的错误SQL，从而提高生成正确SQL的能力。", "conclusion": "广泛实验和对六种开源LLM和五种常用基准的深入分析表明，本文方法优于现有最先进的（SOTA）方法。"}
{"llm_update_time": "20250907", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.03957", "html_url": "https://arxiv.org/abs/2509.03957", "title": "CANDY: 评估大型语言模型在中文虚假信息查证中的局限性和辅助潜力", "title_en": "CANDY: Benchmarking LLMs' Limitations and Assistive Potential in Chinese Misinformation Fact-Checking", "authors": "Ruiling Guo,Xinwei Yang,Chen Huang,Tong Zhang,Yong Hu", "background": "尽管大型语言模型（LLMs）在查伪方面的效果尚不确定，且它们的使用日益广泛，但本研究旨在系统地评估这些模型在中文虚假信息查证中的能力和局限。通过构建一个注释数据集，研究发现当前LLMs在生成查伪结论时存在局限性，即使使用链式推理和少量示例提示也难以确保准确性。", "innovation": "该研究开发了一个名为CANDY的基准，专门用于评估和识别LLMs在中文虚假信息查证中的局限。通过数据分析，研究者提出了一种分类法来整理LLMs生成的错误解释，并将事实捏造视为最常见的失败模式。此外，研究指出LLMs作为辅助工具时可以提升人类查伪性能，表明了其潜在的应用价值。", "conclusion": "尽管单独的LLMs在查伪方面不可靠，联合人类工作时它们能够显著提高查伪任务的效率。作者提供了CANDY数据集和相关代码，以促进进一步的研究和开发。"}
{"llm_update_time": "20250907", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.03972", "html_url": "https://arxiv.org/abs/2509.03972", "title": "通过韩语案例研究扩展开源大规模语言模型的基本语言能力", "title_en": "Expanding Foundational Language Capabilities in Open-Source LLMs through a Korean Case Study", "authors": "Junghwan Lim,Gangwon Jo,Sungmin Lee,Jiyoung Park,Dongseok Kim,Jihwan Kim,Junhyeok Lee,Wai Ting Cheung,Dahye Choi,Kibong Choi,Jaeyeon Huh,Beomgyu Kim,Jangwoong Kim,Taehyun Kim,Haesol Lee,Jeesoo Lee,Dongpin Oh,Changseok Song,Daewon Suh", "background": "介绍了Llama-3-Motif，这是一种参数量为102亿的语言模型，专门设计来提高韩语能力的同时，在英语方面的表现也很强。该模型基于Llama 3架构，使用先进的训练技术（包括LlamaPro和Masked Structure Growth），在保持核心Transformer架构不变的情况下实现有效的模型扩展。通过MoAI平台在大规模GPU集群上进行高效训练，并使用精心筛选的数据集确保韩语和英语数据的比例平衡。", "innovation": "Llama-3-Motif采用了LlamaPro和Masked Structure Growth等先进训练技术，能够在保持核心Transformer架构不变的情况下实现有效的模型扩展，同时通过MoAI平台在大规模GPU集群上进行高效训练，并使用精心筛选的数据集确保韩语和英语数据的比例平衡。", "conclusion": "Llama-3-Motif在韩语特定基准测试中的表现良好，超过了现有模型，并达到了与GPT-4相当的结果。"}
{"llm_update_time": "20250907", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.03940", "html_url": "https://arxiv.org/abs/2509.03940", "title": "VoxRole: 评估基于语音的角色扮演代理的综合基准", "title_en": "VoxRole: A Comprehensive Benchmark for Evaluating Speech-Based Role-Playing Agents", "authors": "Weihao Wu,Liang Cao,Xinyu Wu,Zhiwei Lin,Rui Niu,Jingbei Li,Zhiyong Wu", "background": "近年来，大型语言模型（LLMs）的显著进步极大地推动了角色扮演对话代理（RPCAs）的发展。这些系统旨在通过一致的人物扮演来营造沉浸式的用户体验。然而，当前RPCA研究面临着双重限制。首先，现有工作主要集中在文本模态上，完全忽视了言语中的重音、语调和节奏等副语言特征，这些特征对于传达角色情感和形成生动的身份至关重要。其次，基于语音的角色扮演领域长期以来缺乏标准化的评估基准。大多数现有的语音对话数据集仅针对基础能力评估，人物特征描绘简单或定义不清，导致无法有效量化模型在长期人物一致性等核心技能上的表现。", "innovation": "为了解决这一关键差距，我们提出了VoxRole，这是首个专门为基于语音的RPCAs评估设计的综合基准。基准包括13335轮多轮对话，共计65.6小时的语音，来自261部电影中的1228个独特角色。为了构建此资源，我们提出了一种新颖的两阶段自动化管道，首先将电影音频与剧本对齐，然后再利用LLM系统地为每个角色构建多维特征描述。通过VoxRole，我们对当代语音对话模型进行了多维度评估，揭示了它们在维持人物一致性方面的各自优势和局限。", "conclusion": "利用VoxRole，我们展示了对当代语音对话模型的多维度评估结果，揭示了它们在维持角色一致性的核心能力上的表现差异，为进一步改进RPCA模型提供了宝贵的见解。"}
{"llm_update_time": "20250907", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.03918", "html_url": "https://arxiv.org/abs/2509.03918", "title": "MTQA：用于增强复杂问答中推理的Matrix of Thought", "title_en": "MTQA:Matrix of Thought for Enhanced Reasoning in Complex Question Answering", "authors": "Fengxiao Tang,Yufeng Li,Zongzong Wu,Ming Zhao", "background": "复杂问答（QA）是自然语言处理（NLP）中一个基础且具有挑战性的问题。尽管大型语言模型（LLMs）在QA方面表现出色，但在面对复杂的和抽象的QA任务时，由于推理能力不足，会遭受显著的性能下降。现有方法如Chain-of-Thought（CoT）和Tree-of-Thought（ToT）虽然旨在增强LLMs的推理能力，但这些问题面临树结构内的层内冗余和链结构中的单路径问题。尽管一些研究使用检索增强生成（RAG）方法来帮助LLMs推理，利用大量涉及多个实体和跳跃层次的知识信息挑战仍然关键。", "innovation": "我们提出了Matrix of Thought（MoT），一种新颖且高效的LLM思维结构。MoT通过“列单元通信机制”在水平和垂直两个维度上探索问题，使LLMs能够积极参与多策略和深层的思考，减少列单元内的冗余并增强推理能力。此外，我们开发了一种事实修正机制，通过从检索的知识图谱三元组和原始文本构造知识单元来增强初始知识并纠正错误答案，进而开发出一种高效且准确的QA框架（MTQA）.", "conclusion": "实验结果表明，我们的框架在四个广泛使用的数据集上优于最新的方法，在F1和EM得分方面表现更好，推理时间仅为基准方法的14.4%。这证明了其高效和准确性。此框架的代码可在该网址查阅：this https URL."}
{"llm_update_time": "20250907", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.03961", "html_url": "https://arxiv.org/abs/2509.03961", "title": "Remote Sensing Change Detection using a Multimodal Feature Fusion Network with Text Difference Enhancement", "title_en": "Multimodal Feature Fusion Network with Text Difference Enhancement for Remote Sensing Change Detection", "authors": "Yijun Zhou,Yikui Zhai,Zilu Ying,Tingfeng Xian,Wenlve Zhou,Zhiheng Zhou,Xiaolin Tian,Xudong Jia,Hongsheng Zhang,C. L. Philip Chen", "background": "尽管深度学习在遥感变化检测（RSCD）方面取得了进展，但大多数方法仅依赖图像模态，这限制了特征表示、变化模式建模以及在光照和噪声干扰下的泛化能力。", "innovation": "提出了一种名为 MMChange 的多模态遥感变化检测方法，结合图像和文本模态来提高准确性和鲁棒性。引入了图像特征精炼（IFR）模块以突出关键区域并抑制环境噪声。通过使用视觉语言模型（VLM）生成二幅图像的语义描述来克服图像特征的语义限制。设计了文本差异增强（TDE）模块以捕捉细粒度的语义变化，指导模型找到有意义的变化。通过图像文本特征融合（ITFF）模块实现跨模态深度集成，以弥补模态之间的异质性。", "conclusion": "在 LEVIRCD、WHUCD 和 SYSUCD 数据集上的实验表明，MMChange 在多个指标上始终超越了最先进的方法，验证了其在多模态遥感变化检测中的有效性。"}
{"llm_update_time": "20250907", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.03973", "html_url": "https://arxiv.org/abs/2509.03973", "title": "SAC-MIL：了解显微病理全视野图像分类的空间感知相关多实例学习", "title_en": "SAC-MIL: Spatial-Aware Correlated Multiple Instance Learning for Histopathology Whole Slide Image Classification", "authors": "Yu Bai,Zitong Yu,Haowen Tian,Xijing Wang,Shuo Yan,Lin Wang,Honglin Li,Xitong Ling,Bo Zhang,Zheng Zhang,Wufan Wang,Hui Gao,Xiangyang Gong,Wendong Wang", "background": "在进行全视野显微图像（WSI）分类时，需要考虑位置信息和实例之间的空间关系。传统的多实例学习缺乏对位置信息的处理，而现有的方法则常遇到训练序列和测试序列长度不同的问题。本文旨在通过引入一种能够在线性时间内处理实例全面相关性的方法，解决这些问题，并取得最佳性能。", "innovation": "本文提出了一个名为SAC-MIL的空间感知相关多实例学习方法。该方法包含：1. 位置编码模块，用于编码实例坐标内的空间关系而非输入WSI序列的实例索引；2. SAC块，这是一种基于MLP的方法，能够在保持线性时间复杂度的同时进行实例间的全面相关性计算，且不需要定制CUDA内核，从而简化了部署过程。SAC-MIL在CAMELYON-16, TCGA-LUNG和TCGA-BRAC等数据集上实现了最优性能。", "conclusion": "SAC-MIL在全视野显微图像分类中展现了出色的表现，并且由于其实现简单，容易部署。文章表示接收后将公开代码。"}
{"llm_update_time": "20250907", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.03985", "html_url": "https://arxiv.org/abs/2509.03985", "title": "NeuroBreak: 揭示大型语言模型内部 jailbreak 机制", "title_en": "NeuroBreak: Unveil Internal Jailbreak Mechanisms in Large Language Models", "authors": "Chuhan Zhang,Ye Zhang,Bowen Shi,Yuyou Gan,Tianyu Du,Shouling Ji,Dazhan Deng,Yingcai Wu", "background": "在部署和应用中，大型语言模型（LLMs）通常会进行安全性对齐，以防止产生非法和不道德的输出。然而，随着针对这些模型的安全防护措施的威胁程度不断上升，绕过安全性机制的 jailbreak 攻击技术（如对抗性提示）不断改进，这给 LLM 安全防线带来了前所未有的压力。理解 LLM 的安全机制及其潜在漏洞对于增强抵御 jailbreak 攻击的能力至关重要，但其参数庞大且结构复杂，使得全面剖析其内部安全性成为一项挑战。", "innovation": "NeuroBreak 是一种从上而下的 jailbreak 分析系统，旨在从神经元层面分析安全性机制并缓解漏洞。NeuroBreak 通过与三位 AI 安全领域的专家合作来精心设计系统要求；结合逐层表示探查分析，NeuroBreak 为模型生成各步骤中的决策过程提供了新的视角；同时，系统可以从语义和功能两个层面分析关键神经元，有助于深入探索安全机制。通过定量评价和案例研究，验证了系统的有效性，为开发针对不断演变的 jailbreak 攻击的下一代防御策略提供了机制性见解。", "conclusion": "NeuroBreak 对大型语言模型中的 jailbreak 机制进行了全面分析，提供了新颖的方法来探索模型的决策过程，并支持从语义和功能层面对关键神经元的分析。通过实际的评估和案例研究，NeuroBreak 积极提升了 LLMS 面对 jailbreak 攻击时的防御能力，为未来的安全对策开发奠定了基础。"}
{"llm_update_time": "20250907", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.03995", "html_url": "https://arxiv.org/abs/2509.03995", "title": "RTQA：使用大型语言模型进行复杂时间知识图谱问题解答的递归思考", "title_en": "RTQA : Recursive Thinking for Complex Temporal Knowledge Graph Question Answering with Large Language Models", "authors": "Zhaoyan Gong,Juan Li,Zhiqiang Liu,Lei Liang,Huajun Chen,Wen Zhang", "background": "当前的时间知识图谱问答（TKGQA）方法主要关注隐含的时间约束，缺乏处理更复杂时间查询的能力，并且在分解框架中表现出有限的推理能力和错误传播问题。", "innovation": "提出了一种新的框架RTQA来解决这些挑战，通过增强对TKG的时间推理能力，而不需要训练。RTQA递归地将问题分解为子问题，从下往上去解决它们，并使用多路径答案聚合以提高容错性。RTQA包含三个核心组件：时间问题分解器、递归求解器和答案聚合器。", "conclusion": "在MultiTQ和TimelineKGQA基准测试中，RTQA在“Multiple”和“Complex”类别中显示出显著的Hits@1改进，超越了最先进的方法。我们的代码和数据可以在提供的网址中获取。"}
{"llm_update_time": "20250907", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.04009", "html_url": "https://arxiv.org/abs/2509.04009", "title": "通过弃用Token检测视觉转换器中的区域随机关联", "title_en": "Detecting Regional Spurious Correlations in Vision Transformers via Token Discarding", "authors": "Solha Kang,Esla Timothy Anzaku,Wesley De Neve,Arnout Van Messem,Joris Vankerschaver,Francois Rameau,Utku Ozbulak", "background": "神经网络基于计算机视觉模型具有强大的特征关联能力，能够检测和利用数据中的非预期模式，基于统计上相关但可能是错误的信号进行准确预测。这些非预期信号可能从简单的颜色异常到图像中包含的小文本。当这些非预期信号与预测任务对齐时，模型可能会错误地将这些特征与任务关联起来并依赖它们进行预测。这种现象被称为伪相关，即似乎与任务相关但实际上只是偶然的相关。因此，检测和缓解伪相关已成为构建可信赖、可靠和通用机器学习模型的关键任务。", "innovation": "提出了一种新的方法来检测视觉变换器中的伪相关，利用监督和自监督训练模型在ImageNet数据集上进行大规模实验，证明了该方法能识别伪相关。还发现，即使使用相同的架构，训练方法对模型依赖伪相关有显著影响。进一步显示，ImageNet数据集中某些类包含容易被模型检测到的伪信号，并探讨了这些伪信号的根本原因。最后，进行了一项案例研究，探讨侵袭性乳腺肿块分类中的伪信号，将工作 grounding 在实际场景中。", "conclusion": "提供了上述图像的详尽列表，并建议未来研究中谨慎使用它们。通过这项研究强调了在视觉变换器中辨别伪相关的重要性，并建议改进模型以减少这些伪相关的依赖性。"}
{"llm_update_time": "20250907", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.04076", "html_url": "https://arxiv.org/abs/2509.04076", "title": "基于关键点的扩散模型在NICOL机器人运动规划中的应用", "title_en": "Keypoint-based Diffusion for Robotic Motion Planning on the NICOL Robot", "authors": "Lennart Clasmeier,Jan-Gerrit Habekost,Connor Gäde,Philipp Allgeuer,Stefan Wermter", "background": "传统上，数值规划方法常被用于解决一般的运动规划问题，但这些方法在运行时间上有显著的需求。本研究提出了一个新的基于扩散的过程模型，旨在通过利用深度学习的优势，在运行时间更短的情况下实现良好的结果。", "innovation": "研究通过学习由这些规划器生成的数据集中的信息，利用扩散模型来预测基于关键点的关节序列。研究发现，初始模型虽然使用点云嵌入作为输入，但难以根据点云嵌入条件化网络。通过识别数据集中的偏见并对其进行改进，模型的性能得到了提升。即便不使用点云编码，该模型在运行时间上比数字模型快了至少一个数量级，同时在测试集上达到了高达90%的无碰撞解决方案的成功率。", "conclusion": "本研究提出了一种新的基于扩散的机器人运动规划模型，通过利用深度学习优势减少了运行时间，且在无碰撞解决方案的成功率方面超过了数值模型。"}
{"llm_update_time": "20250907", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.03986", "html_url": "https://arxiv.org/abs/2509.03986", "title": "Promptception: 大规模多模态模型对提示有多敏感？", "title_en": "Promptception: How Sensitive Are Large Multimodal Models to Prompts?", "authors": "Mohamed Insaf Ismithdeen,Muhammad Uzair Khattak,Salman Khan", "background": "尽管近年来大型多模态模型(LMMs)在多项选择题答案生成(MCQA)方面取得了成功，但对于LMMs在MCQA中的提示设计理解仍然不足。即使提示的细微变化也可能会导致高达15%的准确性偏差，这使得透明、公平的LMM评估变得困难，因为模型经常使用精心挑选的提示报告其最佳性能。因此，需要一种系统的方法来评估LMMs的提示敏感度。", "innovation": "我们提出了Promptception，这是一种系统框架，用于评估LMMs的提示敏感度。它包括61种提示类型，涵盖了15个类别和6个超类别，每个类别都针对提示制定的特定方面，并被用来评估10种不同类型的LMMs，这些模型从轻量级开源模型到GPT-4o和Gemini 1.5 Pro，覆盖了3个MCQA基准：MMStar、MMMU-Pro和MVBench。研究表明，专有模型对提示敏感度更高，反映了其更紧密的指令语义对齐，而开源模型则更稳定但难以应对复杂的提示语。基于这些发现，我们提出了针对专有和开源LMMs的提示原则，以实现更坚实和公平的模型评估。", "conclusion": "我们的结论表明，需建立更加严格的提示原则以确保LMMs的评估更加透明和公允，尤其是针对不同类型的LMMs。"}
{"llm_update_time": "20250907", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.04051", "html_url": "https://arxiv.org/abs/2509.04051", "title": "基于上下文内环滤波和重建外环增强的神经视频压缩", "title_en": "Neural Video Compression with In-Loop Contextual Filtering and Out-of-Loop Reconstruction Enhancement", "authors": "Yaojun Wu,Chaoyi Lin,Yiming Wang,Semih Esenlik,Zhaobin Zhang,Kai Zhang,Li Zhang", "background": "本文探讨了增强滤波技术在神经视频压缩中的应用。根据增强表示是否影响后续编码环，这些技术分为在环上下文滤波和出环重建增强两大类。在环上下文滤波通过减少帧间编码中的误差传播来细化时域上下文，但其对当前和后续帧的影响带来了在序列中动态应用滤波的挑战。为了解决这个问题，本文提出了一种自适应编码决策策略，该策略在编码过程中动态确定滤波的应用。此外，出环重建增强用于细化重建帧的质量，提供了简单有效的编码效率改进。", "innovation": "本文将增强滤波技术应用于神经视频压缩，并首次系统性地研究基于条件的神经视频压缩中的增强滤波。提出了自适应编码决策策略，以动态确定编码过程中滤波的应用。同时，通过出环重建增强提高重建帧的质量。在实验中，本方法相比最先进的神经视频编解码器在比特率上降低了7.71%，验证了所提出方法的有效性。", "conclusion": "本文通过系统研究有必要加入上下文内环滤波的在环增强，以及如何有效地管理这种增强及其对从环的影响，从而改进了神经视频压缩。利用此策略，实现了与现有神经视频编解码器相比显著降低比特率的效果。"}
{"llm_update_time": "20250907", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.04013", "html_url": "https://arxiv.org/abs/2509.04013", "title": "关于LLM基准评价的稳健性和可靠性", "title_en": "On Robustness and Reliability of Benchmark-Based Evaluation of LLMs", "authors": "Riccardo Lunardi,Vincenzo Della Mea,Stefano Mizzaro,Kevin Roitero", "background": "通常通过MMLU、ARC-C或HellaSwag等基准来评估大规模语言模型（LLMs）的效果，这些问题以固定的格式呈现。然而，实际应用中会涉及语言的多变性，模型需要在多种重新表述的答案中保持其有效性。这项研究系统地评估了LLMs对经过重新表述的基准问题的稳健性，并研究了基准评估能否可靠地衡量模型能力。研究人员生成了六种常见基准问题的不同重新表述，并测量了34种不同规模和效果的顶级LLM的有效性变化。研究发现，尽管LLM在重新表述输入中排名相对稳定，但绝对有效性分数会显著下降，这表明LLMs在语言变异性方面存在问题，对其泛化能力和评估方法提出了质疑。此外，观察到的表现下降质疑了基于基准的评估的可靠性，暗示高基准得分可能无法全面反映模型对真实输入变化的稳健性。", "innovation": "该研究系统地生成了六种不同基准问题的多种重新表述，并评估了多种大小和效果的顶级LLM的有效性变化，揭示了LLMs在语言变异性方面的稳健性问题，挑战了基于基准的评估方法的可靠性。", "conclusion": "研究发现表明，虽然LLMs在重新表述输入中的排名相对稳定，但绝对有效性分数显著下降，这表明它们在语言变异性方面存在问题。基于基准的评估可能未能完全捕捉到模型对真实世界输入变化的稳健性，因此需要引入更多考虑稳健性的基准来更好地反映实际情况。"}
{"llm_update_time": "20250907", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.04126", "html_url": "https://arxiv.org/abs/2509.04126", "title": "MEPG：基于多专家规划和生成的丰富组合图像生成", "title_en": "MEPG:Multi-Expert Planning and Generation for Compositionally-Rich Image Generation", "authors": "Yuan Zhao,Liu Lin", "background": "文本到图像的扩散模型在图像质量上取得了显著进展，但在应对复杂的多元素提示以及风格多样性上的限制仍然存在。", "innovation": "提出了一个多专家规划和生成框架（MEPG），该框架结合了位置和风格感知的大语言模型（LLMs）以及空间语义专家模块，通过监督微调将输入提示分解为精确的空间坐标和带有风格编码的语义指令，以及通过动态专家路由实施跨区域生成。", "conclusion": "实验结果显示，MEPG 在图像质量和风格多样性方面显著优于具有相同主干的基础模型。"}
{"llm_update_time": "20250907", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.04011", "html_url": "https://arxiv.org/abs/2509.04011", "title": "NER Retriever: 基于类型感知嵌入的零样本命名实体检索", "title_en": "NER Retriever: Zero-Shot Named Entity Retrieval with Type-Aware Embeddings", "authors": "Or Shachar,Uri Katz,Yoav Goldberg,Oren Glickman", "background": "在传统的命名实体识别(NER)任务中，实体类型的定义通常是在系统设计阶段就固定的，用户无法动态修改。而在这个研究中，我们关注的是一种变体任务——即兴命名实体检索(ad-hoc NER retrieval)，在这种任务中，用户的查询可以包含任何类型的实体描述，而不需要预先定义类型。研究人员需要设计一个系统，可以根据用户的不同查询动态检索相关文档，并准确地定位到符合条件的实体。现有的方法通常是使用固定模式或者微调模型来实现，这种方法在面对大量未知类型的复杂查询时可能表现不佳。", "innovation": "我们提出了一个名为NER Retriever的检索框架，它可以实现零样本任务，即在无需预先定义实体类型的情况下进行检索。我们的方法基于大型语言模型(更具体地说是其内部的表示)来构建嵌入，使得能够将实体提及和用户提供的开放类型的描述映射到一个共同的语义空间中。我们还发现，模型中间层的变换器块的值向量比顶层嵌入更好地编码了精细类型的特定信息。通过一个轻量级的对比投影网络对这些嵌入进行微调，可以使类型相关的实体相互靠近，而使得与查询无关的类型彼此分离，从而生成紧凑、类型感知的嵌入，适用于近邻搜索。实验结果表明，NER Retriever相较于词典和密集句子级别的检索基线方法在三个基准测试中表现更佳。", "conclusion": "我们的研究证明了在大规模语言模型中选择嵌入表示的有效性，并提供了一种可扩展的、无模式的实体检索的实用解决方案。NER Retriever代码库已经公开。"}
{"llm_update_time": "20250907", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.04118", "html_url": "https://arxiv.org/abs/2509.04118", "title": "EHVC: 效率高的层次化参考结构和质量结构用于神经视频编码", "title_en": "EHVC: Efficient Hierarchical Reference and Quality Structure for Neural Video Coding", "authors": "Junqi Liao,Yaojun Wu,Chaoyi Lin,Zhipin Deng,Li Li,Dong Liu,Xiaoyan Sun", "background": "神经视频编解码器（NVCs），利用端到端学习的力量，已经在传统视频编解码器上展示了显著的编码效率改进。最近的研究开始关注NVCs中的质量结构，通过引入明确的层次化设计进行优化。然而，对参考结构设计的关注较少，而这种设计本质上应与层次化质量结构相一致。此外，层次化质量结构仍有很大的优化空间。", "innovation": "我们提出了EHVC，一种高效的层次化神经视频编解码器，具有三个主要创新点：(1) 层次化多参考方案，借鉴传统视频编解码器设计，对齐参考和质量结构，以解决参考质量不匹配的问题；(2) 采用前瞻策略，利用编码器侧来自未来帧的上下文，增强质量结构；(3) 层间质量尺度及随机质量训练策略，以在推理中稳定质量结构。", "conclusion": "借助这些改进，EHVC在最先进的NVCs性能上取得了显著的提升。源代码将在以下网址发布：this https URL。"}
{"llm_update_time": "20250907", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.04139", "html_url": "https://arxiv.org/abs/2509.04139", "title": "提升RAG系统中技术文档检索的效能", "title_en": "Enhancing Technical Documents Retrieval for RAG", "authors": "Songjiang Lai,Tsun-Hin Cheung,Ka-Chun Fung,Kaiwen Xue,Kwan-Ho Lin,Yan-Ming Choi,Vincent Ng,Kin-Man Lam", "background": "当前存在理解和检索复杂技术内容的挑战，尤其是在硬件和软件开发领域。现有方法在处理这些挑战时存在局限性，尤其是如何利用大型语言模型（LLMs）优化语义检索。针对这一问题，本文提出了Technical-Embeddings框架，通过改进用户查询和文档编码，增强了信息获取和理解。", "innovation": "本文的主要创新在于提出了一种利用大型语言模型增强技术文档检索的框架——Technical-Embeddings。首先，通过生成扩展查询来更好地捕捉用户意图并增加数据集多样性，从而丰富嵌入模型的微调过程。其次，采用总结提取技术编码关键上下文信息，进一步精化技术文档的表示。此外，采用软提示方法微调双编码器BERT模型，并为查询和文档上下文分别设置学习参数，以捕捉细微的语义差异。实验结果显示，Technical-Embeddings在两个公开数据集RAG-EDA和Rust-Docs-QA中显著优于基线模型，在精度和召回率方面表现出色。", "conclusion": "本文研究表明，通过查询扩展和上下文总结，可以有效提升技术领域的信息检索和理解。这有助于改进RAG系统，在工程和产品开发流程中提供高效的、准确的技术文档检索。"}
{"llm_update_time": "20250907", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.04078", "html_url": "https://arxiv.org/abs/2509.04078", "title": "RepoDebug: Repository-Level Multi-Task and Multi-Language Debugging Evaluation of Large Language Models", "title_en": "RepoDebug: Repository-Level Multi-Task and Multi-Language Debugging Evaluation of Large Language Models", "authors": "Jingjing Liu,Zeming Liu,Zihao Cheng,Mengliang He,Xiaoming Shi,Yuhang Guo,Xiangrong Zhu,Yuanfang Guo,Yunhong Wang,Haifeng Wang", "background": "大型语言模型（LLMs）在代码调试，尤其是自动程序修复方面表现出显著的能力，这可能大幅减少开发人员的工作时间和提高工作效率。为了推动代码调试的发展，已经取得了显著的进展，尤其是在调试数据集方面，但是现有数据集主要集中在评估LLM的功能级代码修复能力上，忽略了更复杂和现实的仓库级别场景，导致对LLM在仓库级别的调试挑战的理解不够全面。尽管有一些多任务多语言级别的数据集被提出，但是它们也存在任务多样性不足、语言和错误类型有限的问题。", "innovation": "本文介绍了RepoDebug，这是一个多任务、多语言级别的代码调试数据集，包含22种错误类型，支持8种常用编程语言和3种调试任务。此外，研究人员还在10个LLM上进行了评估实验，其中Claude 3.5 Sonnect作为表现最好的模型，在仓库级别的调试方面表现仍然不佳。", "conclusion": "研究结果显示，现有技术在处理仓库级别的代码调试任务时仍存在挑战，特别是对于大型语言模型而言。RepoDebug数据集为研究者提供了一个全面的评估框架，有助于更深入地理解LLMs在仓库级别的调试挑战。"}
{"llm_update_time": "20250907", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.04129", "html_url": "https://arxiv.org/abs/2509.04129", "title": "策略视角下的控制器简约性：在反应性合成中的复杂性视角", "title_en": "Simplicity Lies in the Eye of the Beholder: A Strategic Perspective on Controllers in Reactive Synthesis", "authors": "Mickael Randour", "background": "在通过博弈论方法合成控制器时，我们将待控制系统与其环境之间的相互作用建模为实体之间的博弈。我们的目标是为该系统找到一个合适的策略（例如，赢或最优策略），以此作为真实控制器的设计蓝图。普遍认为，简单的策略（例如，使用有限的记忆）是更优的选择：基于这些策略的控制器更容易设计和理解，成本较低且易于维护。本文讨论了在各种合成上下文中的策略复杂性，特别是关于记忆和随机性的问题，并简要探讨了超出传统策略复杂性观念的内容。", "innovation": "本文聚焦于不同合成上下文中的策略复杂性，特别是在记忆和随机性方面的最新研究成果，并探讨了策略复杂性的一种新颖视角，超越了传统观念。", "conclusion": "本文强调了策略复杂性的主观性，提出了从策略视角审视控制器简约性的新方法。"}
{"llm_update_time": "20250907", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.04156", "html_url": "https://arxiv.org/abs/2509.04156", "title": "基于YOLO集成的无人机多光谱缺陷检测方法在风力发电机组部件中的应用", "title_en": "YOLO Ensemble for UAV-based Multispectral Defect Detection in Wind Turbine Components", "authors": "Serhii Svystun,Pavlo Radiuk,Oleksandr Melnychenko,Oleg Savenko,Anatoliy Sachenko", "background": "无人机装备了先进传感器，为监测风力发电厂中的叶片、塔和其他关键组件带来了新的机会。然而，可靠地进行缺陷检测需要高分辨率的数据和高效的多光谱图像处理方法。该研究旨在通过开发结合可见光和热通道的YOLO基深度学习模型集合来增强缺陷检测的准确性，以满足这些需求。", "innovation": "提出了一种集成方法，结合通用的YOLOv8模型与专门的热模型，并使用复杂的边界框融合算法来结合其预测。实验结果表明，这种方法在mAP@.5达到了0.93，F1分数为0.90，优于单独的YOLOv8模型（mAP@.5为0.91）。", "conclusion": "结合多个YOLO架构和融合的多光谱数据，提出了更可靠的解决方案，以提高对视觉和热缺陷的检测能力。"}
{"llm_update_time": "20250907", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.04243", "html_url": "https://arxiv.org/abs/2509.04243", "title": "通过自我进化偏好优化学习主动感知以实现GUI目标定位", "title_en": "Learning Active Perception via Self-Evolving Preference Optimization for GUI Grounding", "authors": "Wanfu Wang,Qipeng Huang,Guangquan Xue,Xiaobo Liang,Juntao Li", "background": "视觉语言模型（VLMs）近年来在视觉感知和语言推理的结合方面取得了显著进展。虽然最近OpenAI的o3模型引入了一种有效的缩放搜索策略，增强了VLMs的主动感知能力，但在GUI目标定位中，特别是在高分辨率输入和复杂多元素视觉交互下，使VLMs有效地进行合适的图像区域推理仍然是一项核心挑战。", "innovation": "提出了LASER（自我进化框架），这是一种逐步赋予VLMs多步骤感知能力的自我优化框架，使精确坐标预测成为可能。具体来说，该方法结合了蒙特卡洛质量估计与基于交并比（IoU）的区域质量评估，以同时促进构建高质偏好数据的准确性和多样性。这种结合指导模型专注于与指令相关的关键区域，并根据任务复杂性自适应地分配推理步骤。", "conclusion": "在ScreenSpot Pro和ScreenSpot-v2基准上的全面实验表明LASER具有一致的性能提升，验证了其方法的有效性。此外，当在GTA1-7B上进行微调时，LASER在ScreenSpot-Pro基准上的得分为55.7，成为7B规模模型中的新最佳状态。"}
{"llm_update_time": "20250907", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.04250", "html_url": "https://arxiv.org/abs/2509.04250", "title": "使用LLM先验我们可以节省多少患者？", "title_en": "How many patients could we save with LLM priors?", "authors": "Shota Arai,David Selby,Andrew Vargo,Sebastian Vollmer", "background": "传统临床试验需要大量的患者来实现相同的统计功效，研究提出了一种利用大型语言模型（LLMs）的知识来缩减临床试验所需患者数量的新方法。", "innovation": "该研究提出了一个新颖的框架，用于多中心临床试验中不良事件的分层贝叶斯建模，其特征是从预训练的LLM中直接获得参数先验，而不同于生成合成数据点的数据增强方法。该方法通过系统地利用LLM获取层次贝叶斯模型中的超参数的先验知识，提升贝叶斯安全模型的预测性能。", "conclusion": "该方法通过全面的温度敏感性和严格的交叉验证，证明了LLM获取的先验能比传统荟萃分析方法更有效地提高预测性能，有望减少临床试验中所需的患者人数，提高临床试验设计的效率，并可能改变药物安全监测和监管决策流程。"}
{"llm_update_time": "20250907", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.04288", "html_url": "https://arxiv.org/abs/2509.04288", "title": "使用数据驱动形式验证的锂离子电池系统鲁棒老化意识控制的强化学习", "title_en": "Reinforcement Learning for Robust Ageing-Aware Control of Li-ion Battery Systems with Data-Driven Formal Verification", "authors": "Rudi Coppola,Hovsep Touloujian,Pierfrancesco Ombrini,Manuel Mazo Jr", "background": "可充电锂离子（Li-ion）电池在现代技术中是普遍存在的元件。在过去的几十年中，电池的生产和设计以及与之相关联的嵌入式充电和安全协议，即电池管理系统（BMS），成为了中心议题。一个基本的挑战是充电速度和电池老化行为之间的权衡，这导致电池容量的损失。", "innovation": "通过使用高保真物理电池模型，并提出数据驱动充电和安全协议设计的方法。采用反例引导归纳合成方案，结合强化学习（RL）与最近的数据驱动形式方法的发展，获得混合控制策略：使用RL合成分离控制器，并通过电池初始输出测量的数据驱动抽象将它们划分为开关结构。然后，结合基于RL的控制器的离散选择和连续电池动力学，实现混合系统。如果设计满足期望标准，则抽象可以提供闭环电池性能的统计保证。", "conclusion": "当设计符合期望的标准时，所提供的抽象能够提供电池闭环性能的统计保证。"}
{"llm_update_time": "20250907", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.04166", "html_url": "https://arxiv.org/abs/2509.04166", "title": "跨越物种鸿沟：从语音到动物声音的迁移学习", "title_en": "Crossing the Species Divide: Transfer Learning from Speech to Animal Sounds", "authors": "Jules Cauzinille,Marius Miron,Olivier Pietquin,Masato Hagiwara,Ricard Marxer,Arnaud Rey,Benoit Favre", "background": "自监督语音模型在语音处理任务中表现出色，但在非语音数据上的效果尚未得到充分探索。本文研究了这些模型在生物声学检测和分类任务上的迁移学习能力。研究表明，类似于HuBERT、WavLM和XEUS这样的模型能够生成跨类群的动物声音的丰富潜在表示。通过时间平均表示进行线性探测分析模型的特性。然后扩展方法以考虑时间信息对下游架构的影响。最后，研究了频率范围和噪声对性能的影响。特别地，本文的结果与微调的生物声学预训练模型相当，展示了噪声鲁棒性预训练设置的影响。这些发现突显了基于语音的自监督学习作为推动生物声学研究的有效框架的潜力.", "innovation": "本文展示了自监督语音模型在生物声学检测和分类任务中的应用潜力。具体创新点包括：1) 发现了这些模型在不同动物声音类别中的迁移学习能力；2) 通过线性探测分析模型特性并考虑时间信息的影响；3) 研究了频率范围和噪声对模型性能的影响；4) 证明了噪声鲁棒性预训练设置的效果，使得这些模型能够与微调的生物声学预训练模型竞争。", "conclusion": "本文的研究结果表明，自监督学习作为生物声学研究的有效框架具有很高的潜力。这些发现不仅能够促进动物声音检测和分类技术的发展，还能够为相关领域的研究提供新的思路。"}
{"llm_update_time": "20250907", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.04183", "html_url": "https://arxiv.org/abs/2509.04183", "title": "MAGneT：生成合成多轮心理健康咨询会话的协调多代理框架", "title_en": "MAGneT: Coordinated Multi-Agent Generation of Synthetic Multi-Turn Mental Health Counseling Sessions", "authors": "Aishik Mandal,Tanmoy Chakraborty,Iryna Gurevych", "background": "随着对可扩展心理辅导的需求增长，需要利用高质量、隐私合规的数据对开源大型语言模型进行微调，然而这种数据仍然稀缺。目前的心理辅导数据生成方法大多由单个代理完成，难以捕捉真实的咨询结构和细微差别。此外，之前的心理辅导评估标准不统一，评估维度覆盖面有限。", "innovation": "MAGneT 提出了一种新颖的多代理框架，用于合成心理辅导会话的生成，将咨询师答复生成分解为由专门语言模型代理处理的协调子任务，每个代理模拟一种关键的心理技术。此外，MAGneT 提出了一个统一的评估框架，集成了自动和专家评估指标，并扩展了评估维度，涵盖了更多的咨询方面。最终结果表明，MAGneT 在生成会话的质量、多样性和治疗一致性方面显著优于现有方法，提高了普通咨询技能平均 3.2% 和 CBT 特异性技能平均 4.3% 的认知疗法评分表 (CTRS)。进一步对开源模型进行微调，展示了更好的性能，平均 CTRS 上改进了普通咨询技能 6.3% 和 CBT 特异性技能 7.3%。同时发布了代码和数据。", "conclusion": "MAGneT 生成的会话在所有方面中专业知识水平的平均偏好率为 77.2%，且其生成的会话质量有所提高。"}
{"llm_update_time": "20250907", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.04154", "html_url": "https://arxiv.org/abs/2509.04154", "title": "注意力机制作为自适应滤波器", "title_en": "Attention as an Adaptive Filter", "authors": "Peter Racioppo", "background": "本文提出了一种名为自适应过滤器注意力（AFA）的新颖机制，该机制直接将可学习的动力模型融入注意力权重的计算中。与直接比较查询和键不同，本文将输入序列建模为线性随机微分方程（SDE）的离散观测值。通过假设可同时对角化的状态矩阵和噪声协方差，利用微分李雅普诺夫方程的封闭解可以高效传播对称不确定性的动态。注意力自然地成为这种线性SDE的最大似然解，其中注意力权重对应于传递对称前精度的鲁棒残差基重新加权。对状态矩阵特征值的附加约束导致一个简化版本，其计算和内存复杂度与标准注意力相同。在动态和过程噪声消失的极限情况下，并使用小角近似，我们恢复了普通的点积注意力机制。", "innovation": "AFA机制直接将可学习的动力模型融入注意力权重的计算中，通过线性随机微分方程（SDE）建模输入序列，利用微分李雅普诺夫方程的封闭解高效传播对称不确定性。运行时特征值的附加约束简化了模型使其复杂度与标准注意力相同，同时保留了自适应滤波器的优点。在动态和过程噪声消失时，本文方法退化为普通的点积注意力机制。", "conclusion": "本文提出了一种新颖的注意力机制（AFA），该机制通过直接将可学习的动力模型融入注意力权重计算中，利用线性随机微分方程模型输入序列，并通过微分李雅普诺夫方程的封闭解高效传播对称不确定性。AFA不仅在理论上为理解注意力提供了一种新的视角，同时在简化版本中还保持了与标准注意力机制相同的计算和内存复杂度。在某些特定条件下的极限情况中，本文方法退化为普通的点积注意力机制。"}
{"llm_update_time": "20250907", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.04180", "html_url": "https://arxiv.org/abs/2509.04180", "title": "VisioFirm：跨平台的计算机视觉领域AI辅助标注工具", "title_en": "VisioFirm: Cross-Platform AI-assisted Annotation Tool for Computer Vision", "authors": "Safouane El Ghazouali,Umberto Michelucci", "background": "AI模型依赖于标注数据来学习模式并进行预测。标注步骤通常非常劳动密集，需要从简单的分类标签到复杂的对象检测、定向边界框估计和实例分割等任务。传统的标注工具往往需要大量的手动输入，这对于大规模数据集来说难以扩展。", "innovation": "VisioFirm 是一个开源的网络应用程序，旨在通过AI辅助自动化来简化图像标注过程。VisioFirm 将最先进的基础模型整合到一个包含过滤流水线的界面中，以减少人工参与的努力。该混合方法使用CLIP结合预先训练的检测器，如 Ultralytics 模型进行常见类别的检测和零样本模型，如 Grounding DINO，为自定义标签生成初始标注，并通过低置信度阈值最大化召回率。通过这种框架，初试预测被证明在 COCO 类别上大多数是正确的，用户可以通过支持边界框、定向边界框和多边形的交互工具进行细化。VisioFirm 还通过 WebGPU 加速的实时分割功能提高浏览器端效率，支持多种导出格式（YOLO，COCO，Pascal VOC，CSV），并在模型缓存后离线运行，增强其可访问性。VisioFirm 在多样化的数据集上测试，通过基准测试显示手动努力减少了高达90%，同时通过CLIP基础组件的聚集和IoU图减少冗余检测，保持了高标注准确性。", "conclusion": "VisioFirm 通过减少人工参与和提高标注效率，大大提升了计算机视觉领域的标注过程，展示了高达90%的手动努力减少，并保持了高标注准确性。"}
{"llm_update_time": "20250907", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.04260", "html_url": "https://arxiv.org/abs/2509.04260", "title": "Python包中的漏洞及其检测的实证研究", "title_en": "An Empirical Study of Vulnerabilities in Python Packages and Their Detection", "authors": "Haowei Quan,Junjie Wang,Xinzhe Li,Terry Yue Zhuo,Xiao Chen,Xiaoning Du", "background": "在迅速发展的软件开发环境中，Python凭借其简洁性、灵活性和广泛的生态系统而脱颖而出。Python包作为组织、重用和分发的单位，在安全性方面成为一个关键问题，特别是在大量的漏洞报告下变得越来越突出。作为脚本语言，Python经常与其他语言合作，以提高性能或互操作性，这增加了Python包固有的漏洞复杂性。当前的漏洞检测工具的有效性尚未得到充分利用。", "innovation": "本文介绍了PyVul，这是第一个全面的Python包漏洞基准套件，包括1,157个公开报告和开发人员验证的漏洞，每个漏洞都与其受影响的包相关联。为适应不同的检测技术，基准套件提供了命令级和函数级的注释。引入了一个受LLM辅助的数据清洗方法，以提高标签准确性，实现了100%的命令级和94%的函数级准确性，使PyVul成为最精确的大规模Python漏洞基准套件。我们进一步进行了PyVul的分布分析，显示Python包中的漏洞涉及多种编程语言，并表现出广泛类型的多样性。研究表明，多语言Python包可能更易受漏洞影响。使用此基准测试现有的最先进的检测器，揭示了现有工具的能力与有效识别Python包中的实际安全问题之间存在显著差异。同时，我们还进行了Python包中最常见的漏洞类型（CWEs）的实证审查，以诊断现有检测工具的精细局限性，并强调了该领域未来进步的必要性。", "conclusion": "现有最先进的检测器在Python包的实际安全问题识别方面存在显著差异。PyVul作为基准套件，已经证明能够提供更准确和全面的数据，帮助开发人员更好地理解和解决Python包中的漏洞问题。"}
{"llm_update_time": "20250907", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.04152", "html_url": "https://arxiv.org/abs/2509.04152", "title": "TAGAL：使用代理型大模型方法的表格数据生成", "title_en": "TAGAL: Tabular Data Generation using Agentic LLM Methods", "authors": "Benoît Ronval,Pierre Dupont,Siegfried Nijssen", "background": "生成数据是提高机器学习任务性能的常见方法，特别是在模型训练中的分类任务。本文分析了一种使用代理型工作流程生成合成表格数据的方法集合。这种方法利用大语言模型（LLMs）进行自动且迭代的过程，通过反馈不断改进生成的数据，而无需额外的大语言模型训练。大语言模型的应用还允许在生成过程中加入外部知识。评估了TAGAL在多种数据集和生成数据的不同方面上的表现，通过仅使用合成数据和结合现实和合成数据两个方面来评估下游机器学习模型的实用性，并且检查了现实数据和生成数据之间的相似性。结果显示，TAGAL能够与需要大语言模型训练的现有最佳方法保持相当的性能，并且整体上优于其他无需训练的方法。", "innovation": "TAGAL使用了代理型工作流程，通过大语言模型实现自动且迭代的合成数据生成。这种方法使用反馈机制改进生成数据，无需再对大语言模型进行训练。此外，它能够结合外部知识，提升生成数据的质量。", "conclusion": "研究表明，TAGAL能够与需要大语言模型训练的当前最优方法保持一致性能，并且在没有额外训练的情况下，整体上优于其他方法。这表明代理型工作流程为基于大语言模型的数据生成方法开辟了新的方向。"}
{"llm_update_time": "20250907", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.04338", "html_url": "https://arxiv.org/abs/2509.04338", "title": "从编辑器到密集几何估计器", "title_en": "From Editor to Dense Geometry Estimator", "authors": "JiYuan Wang,Chunyu Lin,Lei Sun,Rongying Liu,Lang Nie,Mingxing Li,Kang Liao,Xiangxiang Chu,Yao Zhao", "background": "利用预训练的文本到图像生成模型的视觉先验在密集预测任务上取得了成功。然而，密集预测本质上是个图像到图像的任务，因此，图像编辑模型而非文本到图像生成模型可能更适合微调。", "innovation": "提出了FE2E框架，该框架首次基于扩散变换器（DiT）架构，将先进的编辑模型适应于密集几何预测。通过对编辑器的原流程匹配损失进行重新定义以实现“一致速度”训练目标，并采用对数量化解决精度冲突。利用DiT的全局注意力，在单次前向传递中进行深度和法线的联合无成本估计，增强监督信号。", "conclusion": "在无需扩大训练数据集的情况下，FE2E实现了多种数据集上单目深度和法线估计的性能提升。在ETH3D数据集上取得了超过35%的性能增益，超越了训练数据量为原来的100倍的DepthAnything系列模型。更多信息请访问此链接：[这里](this https URL)"}
{"llm_update_time": "20250907", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.04304", "html_url": "https://arxiv.org/abs/2509.04304", "title": "快速褪色的事实：大型语言模型中过时医学知识的记忆评估", "title_en": "Facts Fade Fast: Evaluating Memorization of Outdated Medical Knowledge in Large Language Models", "authors": "Juraj Vladika,Mahdi Dhaini,Florian Matthes", "background": "大型语言模型（LLMs）的能力日益增强，显示出通过协助医疗研究者和医生改善医疗保健的巨大潜力。然而，LLMs 对静态训练数据的依赖性是其一大风险，因为随着新的研究和开发，医学建议也在不断变化。当LLMs 持有陈旧的医学知识时，他们可能会提供有害建议，或在临床推理任务中失败。因此，研究团队引入了两个新的问答（QA）数据集，MedRevQA 和 MedChangeQA，以此来调查这一问题。", "innovation": "研究团队提出了两个新的基于系统回顾数据集：MedRevQA（涵盖16501个QA对，涉及一般生物医学知识）和MedChangeQA（512个QA对的子集，其中医学共识随时间改变）。研究结果发现，八个主流的LLMs 均表现出一致的依赖于过时知识的行为。此外，研究分析了过时的预训练数据和训练策略对这一现象的影响，并提出了缓解措施，为开发更具当前性和可靠性的医疗AI系统奠定了基础。", "conclusion": "研究发现，当前主流的LLMs在处理有关医学问题时，普遍存在依赖过时知识的现象。研究还指出，这可能是由于预训练数据和训练策略导致的，并为此提供了缓解建议，为进一步开发更加可靠的医疗AI系统提供了指导。"}
{"llm_update_time": "20250907", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.04303", "html_url": "https://arxiv.org/abs/2509.04303", "title": "HumAIne-Chatbot: 通过强化学习实现实时个性化对话式AI", "title_en": "HumAIne-Chatbot: Real-Time Personalized Conversational AI via Reinforcement Learning", "authors": "Georgios Makridis,Georgios Fragiadakis,Jorge Oliveira,Tomaz Saraiva,Philip Mavrepis,Georgios Fatouros,Dimosthenis Kyriazis", "background": "当前的对话AI系统提供了通用、标准化的交互，忽略了个体用户的特点，缺乏适应性对话管理。为了解决这一问题，本文提出了一种新型AI驱动的对话代理，即HumAIne-chatbot，通过一种新颖的用户画像框架进行个性化响应。该系统预先训练在一个多样化的GPT生成的虚拟人像集上，以建立广泛的用户类型先验。在实时交互中，一个在线强化学习代理将隐含信号（如打字速度、情感、参与时长）与显式反馈（例如喜好和不喜欢）结合起来，以细化每个用户的模型。这一画像动态地影响着对话机器人对话政策，使其能够实时适应内容和风格。为了评估该系统，我们在多个对话领域中使用了50个合成人像进行了受控实验。结果表明，在启用个性化功能时，用户满意度、个性化准确性和任务完成率都有持续的改善。统计分析证实了个性化和非个性化条件之间的显着差异，多项关键指标的效果规模大。这些发现突显了AI驱动用户画像的有效性，并为未来在现实世界中的验证奠定了坚实的基础.", "innovation": "本研究通过引入HumAIne-chatbot，提出了一种具有新颖用户画像框架的AI驱动对话代理，能够实时个性化对话内容和风格。通过结合隐含信号和显式反馈，系统能够适应不同用户的需求，提升用户体验和任务完成效率。", "conclusion": "研究表明，启用个性化功能后，HumAIne-chatbot不仅提高了用户满意度和任务完成率，还增强了个性化精确度。这一发现强调了AI驱动的用户画像方法的有效性，并为未来的实际应用提供了重要指导。"}
{"llm_update_time": "20250907", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.04398", "html_url": "https://arxiv.org/abs/2509.04398", "title": "IPA：一种保留信息的输入投影框架，用于高效的基础模型适应", "title_en": "IPA: An Information-Preserving Input Projection Framework for Efficient Foundation Model Adaptation", "authors": "Yuan Yin,Shashanka Venkataramanan,Tuan-Hung Vu,Andrei Bursuc,Matthieu Cord", "background": "参数高效微调（PEFT）方法，例如LoRA，通过向预训练权重中注入低秩更新来降低适应成本。然而，LoRA中的下投影是随机初始化且数据无关的，可能会丢弃有价值的信息。先前的研究显示，训练过程中下投影变化不大，而上投影承载了大部分适应任务，使得随机输入压缩成为性能瓶颈。", "innovation": "提出了一种名为IPA的特征感知投影框架，该框架明确地在压缩隐藏空间中保留信息。在线性情况下，IPA使用近似最大主成分的算法实例化投影器，实现高效的预训练，几乎不影响推理开销。IPA在语言和视觉基准测试中均优于LoRA和DoRA，分别在常识推理和VTAB-1k上平均提高了1.5个和2.3个准确点，而在投影固定的情况下，与完全的LoRA性能相当，但可训练参数减少了约一半。", "conclusion": "本文提出的IPA框架在保持信息的同时，能够实现高效的模型适应，特别是在语言和视觉任务上表现出色，且参数量更少，性能更优。"}
{"llm_update_time": "20250907", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.04357", "html_url": "https://arxiv.org/abs/2509.04357", "title": "PARCO: 具有对比实体消歧的音素增强鲁棒上下文ASR", "title_en": "PARCO: Phoneme-Augmented Robust Contextual ASR via Contrastive Entity Disambiguation", "authors": "Jiajun He,Naoki Sawada,Koichi Miyazaki,Tomoki Toda", "background": "自动语音识别（ASR）系统在处理领域特定的命名实体时遇到困难，尤其是对同音词的识别。虽然上下文ASR可以改善识别效果，但由于实体多样性有限，往往难以捕捉细微的音素差异。此外，先前的方法将实体视为独立的标记，导致无法获得完整的多标记偏置。", "innovation": "本文提出了一种名为Phoneme-Augmented Robust Contextual ASR via COntrastive entity disambiguation (PARCO)的方法，该方法结合了音素感知编码、对比实体消歧、实体级别监督和层次化的实体过滤。这些组件增强了音素鉴别能力，确保完整的实体检索，并在不确定性下降低误识别的情况。", "conclusion": "PARCO在中文AISHELL-1和英文DATA2数据集中分别取得了4.22%的CER和11.14%的WER，在1000个干扰项下显著优于基线方法，且在THCHS-30和LibriSpeech等离域数据集上也获得了稳健的提升。"}
{"llm_update_time": "20250907", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.04337", "html_url": "https://arxiv.org/abs/2509.04337", "title": "拆分实体表示学习方法在 Pinterest 广告排定中的应用", "title_en": "Decoupled Entity Representation Learning for Pinterest Ads Ranking", "authors": "Jie Liu,Yinrui Li,Jiankai Sun,Kungang Li,Han Sun,Sihan Wang,Huasen Wu,Siyuan Gao,Paulo Soares,Nan Li,Zhifang Liu,Haoyang Li,Siping Ji,Ling Leng,Prathibha Deshikachar", "background": "本文提出了一种遵循上游-下游范式的新型框架，用于从多元数据源中构建用户和物品（Pin）的嵌入表示，这对于 Pin 钉和广告的个性化推荐至关重要。上游模型利用复杂的架构在广泛的特征信号数据上进行训练，捕捉 Pinterest 上用户和 Pins 之间的复杂关系。为确保上游模型的可扩展性，实体嵌入被学习和定期刷新，而不是实时计算，从而实现了上游和下游模型之间的异步互动。这些嵌入随后作为多个下游任务的输入特征，包括广告检索和点击率及转化率预测模型。", "innovation": "本文的主要创新在于，提出了一种拆分实体表示学习的方法，通过复杂的架构训练模型捕捉用户和 Pins 之间的关系，同时通过学习和定期刷新实体嵌入来确保模型的可扩展性。这些嵌入被用于包括广告检索和点击率及转化率预测在内的多种下游任务。实验结果表明，该方法在多种下游任务中取得了显著的性能改进，并在 Pinterest 的生产广告排序系统中部署，带来了显著的在线指标提升。", "conclusion": "本文提出的框架在多种下游任务中实现了显著的性能提升，并在 Pinterest 的生产广告排序系统中部署，提升了在线指标。"}
{"llm_update_time": "20250907", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.04362", "html_url": "https://arxiv.org/abs/2509.04362", "title": "使用自我监督学习增强的空间时间反转变换器融合多源数据进行停车可用性预测", "title_en": "Parking Availability Prediction via Fusing Multi-Source Data with A Self-Supervised Learning Enhanced Spatio-Temporal Inverted Transformer", "authors": "Yin Huang,Yongqi Dong,Youhua Tang,Li Li", "background": "随着私家车拥有量的迅速增长，城市停车问题愈发突出，因此急需准确有效的停车场可用性预测来支持城市规划和管理。本文分析了现有模型在建模空间-时间依赖关系以及利用多源数据进行停车场可用性预测方面的局限性，指出需要改进的方法来应对这些挑战。", "innovation": "为了应对建模空间-时间依赖关系和利用多源数据的限制，本文提出了一种新的方法SST-iTransformer。该方法利用K-means聚类建立停车场区域（PCZs），并从各种交通模式（如地铁、公交、在线拼车和出租车）中提取和整合与目标停车场相关的交通需求特征。SST-iTransformer扩展了传统的iTransformer，通过掩码重建预训练任务加强自我监督的空间-时间表示学习，并采用了创新的双分支注意力机制：系列注意力通过分块操作捕获长期时间依赖关系，而通道注意力通过倒置维度建模跨变量交互。通过成都市真实数据的大量实验证明，SST-iTransformer在最小均方误差和有竞争力的平均绝对误差方面优于基准深度学习模型（包括Informer、Autoformer、Crossformer和iTransformer），实现了最先进的性能。进一步的消融研究量化显示了不同数据源的重要性：结合拼车数据提供了最大的性能提升，其次是出租车，而固定路线公共交通（公交/地铁）的贡献微乎其微。空间相关性分析进一步证实，不包括PCZ内相关停车场的历史数据会导致性能显著下降，突显了建模空间依赖性的重要性。", "conclusion": "研究结果表明，SST-iTransformer能够有效改善停车场可用性预测的性能，并通过结合多源数据和自我监督学习机制展示了其在实际应用中的潜力。"}
{"llm_update_time": "20250907", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.04345", "html_url": "https://arxiv.org/abs/2509.04345", "title": "AUDETER：开放世界中深度伪造音频检测的大规模数据集", "title_en": "AUDETER: A Large-scale Dataset for Deepfake Audio Detection in Open Worlds", "authors": "Qizhou Wang,Hanxun Huang,Guansong Pang,Sarah Erfani,Christopher Leckie", "background": "生成语音系统的语音合成能力已经非常逼真，有时甚至难以区分，这给真假性的验证带来了挑战。尽管已经开发了多种深度伪造检测方法，但在实际环境中的有效性仍然不可靠，这主要因为训练样本和测试样本之间存在领域差异，这导致了语音合成系统的快速演变和多样的人类语音。目前的数据库缺乏实际应用中的挑战，尤其是那些包含最新真实和伪造音频的多样且与时俱进的数据库。因此，为了填补这一空白，该研究引入了AUDETER，这是一个用于全面评估和稳健开发通用深度伪造音频检测模型的大规模、高多样性的深度伪造音频数据集，以期解决上述问题。", "innovation": "AUDETER是一个大规模且高度多样化的深度伪造音频数据集，它包含了超过4500小时由11个最新的TTS模型和10个声码器生成的合成音频，总共有300万段音频片段，使其成为迄今为止规模最大的数据集。通过广泛的实验，表明基于现有数据集训练的方法在处理新颖的深度伪造音频样本时难以泛化，且在未见过的人声上存在较高的误报率，但基于AUDETER训练的方法则能实现高度泛化的检测性能，将检测错误率降低了44.1%到51.6%，并在流行的野外数据集中实现了4.17%的错误率，这为训练通用的深度伪造音频检测器铺平了道路。", "conclusion": "该研究通过AUDETER数据集的引入，揭示了现有方法在处理深度伪造音频样本时的局限性，并展示了基于AUDETER训练的方法能够显著提高深度伪造音频检测的准确性，未来研究可以通过使用这种数据集进一步改进和开发更加通用的深度伪造音频检测模型。该数据集已开源，可在GitHub上获取。"}
{"llm_update_time": "20250907", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.04419", "html_url": "https://arxiv.org/abs/2509.04419", "title": "朝向大型语言模型后训练的统一视角", "title_en": "Towards a Unified View of Large Language Model Post-Training", "authors": "Xingtai Lv,Yuxin Zuo,Youbang Sun,Hongyi Liu,Yuntian Wei,Zhekai Chen,Lixuan He,Xuekai Zhu,Kaiyan Zhang,Bingning Wang,Ning Ding,Bowen Zhou", "background": "大型语言模型的后训练数据主要来源于模型自动生成的回放和人工或其他模型的示范数据，传统的后训练方法如强化学习（RL）和监督微调（SFT）是基于这两种不同类型的训练数据。然而，这两种方法各自独立，缺乏统一视角。本文通过理论推导得出统一的策略梯度估计方法，并展示了在不同数据分布和偏方差权衡下的各种后训练方法的计算结果，旨在展现不同后训练方法并不是矛盾的，而是同一种优化过程的不同实例。", "innovation": "作者提出了一种统一的策略梯度估计方法，并提出了一种名为Hybrid Post-Training (HPT)的新算法，该算法能够动态选择不同的训练信号，有效利用示范数据并在保持学习推理模式稳定的前提下进行探索。HPT通过广泛的实验和消融研究验证了其理论框架和算法的有效性，使模型在不同规模和家族的数学推理基准和分布式测试集中都表现出色。这一工作为大型语言模型的后训练提供了新的视角和方法，推动了相关研究的发展。", "conclusion": "本文通过理论分析和实际算法提出了一种统一的大型语言模型后训练框架，结合具体算法验证了其理论的有效性，为后训练方法提供了新的统一视角，提高了模型性能，未来可以在更多场景中应用这一框架和HPT算法以提高模型的适应性和泛化能力。"}
{"llm_update_time": "20250907", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.04449", "html_url": "https://arxiv.org/abs/2509.04449", "title": "ChronoGraph: 实际应用的基于图的多变量时间序列数据集", "title_en": "ChronoGraph: A Real-World Graph-Based Multivariate Time Series Dataset", "authors": "Adrian Catalin Lutu,Ioana Pintilie,Elena Burceanu,Andrei Manolache", "background": "现有的基准数据集主要来源于工业控制系统、交通和空气质量领域。ChronoGraph 通过构建一个基于实际生产微服务的真实世界图结构多变量时间序列数据集，旨在填补这一空白。该数据集涵盖了系统的性能指标，使用多变量流记录了CPU、内存和网络使用情况，并通过有向边表示服务间的依赖关系。", "innovation": "ChronoGraph 独特之处在于结合了(i) 多变量时间序列，(ii) 明确且可读的依赖关系图，以及(iii) 与真实事件对齐的异常标签，无需人工标注。它提供了包括预测模型、预先训练的时间序列基础模型和标准异常检测器在内的基准结果。ChronoGraph 为研究结构感知预测和事件感知评估提供了现实基准，特别是在微服务系统中。", "conclusion": "ChronoGraph 的基准结果涵盖了多种预测模型、预训练的时间序列基础模型和标准异常检测器。通过对 ChronoGraph 的研究，可以更好地理解微服务系统中的结构感知预测和事件感知评估。"}
{"llm_update_time": "20250907", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.04442", "html_url": "https://arxiv.org/abs/2509.04442", "title": "Delta Activations: 一种用于调优大型语言模型的表示方法", "title_en": "Delta Activations: A Representation for Finetuned Large Language Models", "authors": "Zhiqiu Xu,Amish Sethi,Mayur Naik,Ser-Nam Lim", "background": "强大的开源大型语言模型（LLMs）的成功使得社区能够在特定任务和领域中创建大量的后训练模型。然而，由于元数据不一致和未结构化的存储库，导航和理解这些模型仍然是一个挑战。", "innovation": "我们提出了一种新的方法——Delta Activations，通过测量调优模型与基础模型之间的内部激活变化来表示调优模型作为向量嵌入。这种方法使得根据领域和任务进行有效的聚类成为可能，揭示了模型景观中的结构。此外，Delta Activations表现出优越的性质：它在各种调优设置下具有鲁棒性，并在混合数据集的调优中表现出可加性质。此外，研究还显示了Delta Activations可以用于通过少量样本调优任务，并进一步探索其在模型选择和合并中的应用。", "conclusion": "希望Delta Activations能促进共享模型的二次使用。有关代码可在以下链接下载：this https URL"}
{"llm_update_time": "20250907", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.04379", "html_url": "https://arxiv.org/abs/2509.04379", "title": "SSGaussian: 具有语义意识和结构保留的3D风格转移", "title_en": "SSGaussian: Semantic-Aware and Structure-Preserving 3D Style Transfer", "authors": "Jimin Xu,Bosheng Qin,Tao Jin,Zhou Zhao,Zhenhui Ye,Jun Yu,Fei Wu", "background": "近年来，神经辐射场和3D高斯斑点等神经表示的进步引发了将样式转移应用于3D场景的兴趣。尽管现有的方法可以将风格模式转移到3D一致的神经表示中，但在从参考风格图像中有效提取和转移高层次风格语义方面仍然存在挑战。此外，风格化结果在结构清晰度和分离度方面常常不足，使得在3D场景中区分不同实例或对象变得困难。这些限制促使我们提出了一种新颖的3D风格转移管道，该管道有效地整合了预训练2D扩散模型的先验知识。该管道包括两个关键阶段：首先是利用扩散先验来生成关键视角的风格化渲染，然后将风格化的关键视图转移到3D表示。这一过程包含两个创新设计：跨视图风格对齐，通过引入UNet的最后一个上采样块中的跨视图注意力，实现了多个关键视角间的特征交互，确保扩散模型生成的风格化关键视图能够保持风格保真度和实例级一致性；其次，实例级风格转移，它有效地利用了风格化关键视图中的实例级一致性，并将其转移到3D表示。这导致了结构更紧密、视觉更连贯、艺术上更丰富的风格转移结果。", "innovation": "我们提出了一种新颖的3D风格转移管道，它通过利用预训练2D扩散模型的先验知识有效地结合了两种创新设计：跨视图风格对齐和实例级风格转移。跨视图风格对齐设计通过UNet的最后一个上采样块中的跨视图注意力机制，实现了多个关键视角间的特征交互，以确保生成的风格化视图保持风格保真度和实例级一致性。实例级风格转移设计通过跨多个风格化关键视图的一致性利用，实现风格转移并提升3D表示的风格化生成结果，使其更加结构合理、视觉连贯和艺术上丰富。", "conclusion": "广泛的定性和定量实验表明，我们的3D风格转移管道在多种场景中显著优于当前最先进的方法，包括正面视图到困难的360度环境。我们的项目页面提供了沉浸式可视化演示，请访问此链接：this https URL。"}
{"llm_update_time": "20250907", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.04441", "html_url": "https://arxiv.org/abs/2509.04441", "title": "DEXOP: 一种用于灵巧人类操作的机器人传输设备", "title_en": "DEXOP: A Device for Robotic Transfer of Dexterous Human Manipulation", "authors": "Hao-Shu Fang,Branden Romero,Yichen Xie,Arthur Hu,Bo-Ruei Huang,Juan Alvarez,Matthew Kim,Gabriel Margolis,Kavya Anbarasu,Masayoshi Tomizuka,Edward Adelson,Pulkit Agrawal", "background": "介绍了一种名为perioperation的机器人数据采集范式，该范式可以传感器化并记录人类操作，同时最大限度地提高数据向真实机器人转移的可行性。DEXOP是为在自然环境中执行多种灵巧操作任务而设计的一种被动手部外骨骼，旨在最大限度地增强人类收集丰富感官（视觉+触觉）数据的能力。通过机械连接人类手指和机器人手指，DEXOP提供直接的接触反馈（通过本体感觉），并将其人的手部姿态镜像到被动机器人手上，从而最大限度地提高示范技能向机器人转移的可能性。这种力量反馈和姿态镜像相比遥操作使任务示范更具自然性，从而增加速度和准确性。研究跨越了一系列灵巧、接触丰富的任务，展示了从DEXOP收集高品质示范数据的能力。使用DEXOP数据学习的策略在单位数据收集时间内的任务性能显著提高，使其成为推进机器人灵巧度的强大工具。", "innovation": "DEXOP 设计用于在自然环境中执行多种灵巧操作任务，并通过机械连接人类手指和机器人手指来提高任务示范的自然性和效率，提供直接反馈并最大化技能的转移。利用这种方法，DEXOP 在数据收集能力和任务性能提升方面显示出优越性，提供了与传统遥操作相比更为自然且高效的示范方式。", "conclusion": "通过DEXOP，我们展示了能够大规模收集高质量示范数据的能力，并且学习的策略在单位时间的数据收集下显著提高了任务性能。这使得DEXOP成为发展机器人灵巧度的强大工具。"}
{"llm_update_time": "20250907", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.04404", "html_url": "https://arxiv.org/abs/2509.04404", "title": "没有思想只有AI：偏见的LLM推荐限制了简历筛选中的个人自主性", "title_en": "No Thoughts Just AI: Biased LLM Recommendations Limit Human Agency in Resume Screening", "authors": "Kyra Wilson,Mattea Sim,Anna-Maria Gueorguieva,Aylin Caliskan", "background": "本文通过一项使用528名参与者进行的模拟实验，探讨了人类与模拟人工智能模型（该模型展示了基于种族的偏好或偏见）合作时，在16种不同职业简历筛选中的行为模式。实验使用的虚拟AI偏见是基于实际AI系统中的种族偏见的真实和假设估计值。研究者通过隐含联想测试（IATs）测量了进行分辨测试前后的种族与地位之间的潜意识关联，这些测试可以预测歧视性招聘决策，但之前并未在人类与AI协作的情况下调查。研究背景反映了在人类与AI互动的情景中，人类对于不同类型候选人的偏好可能会受到AI偏见的影响，影响了个体在AI协助下进行决策的能力。", "innovation": "本研究的创新之处在于，它探讨了在使用人工智能模型进行决策时，人们的自主性如何受到AI偏见的影响，尤其是在人类-人工智能协同工作模型中。这也是首次在人类-人工智能协作场景下检测隐含联想测试的预测能力。研究还发现，通过在简历筛选前完成隐含联想测试，可以提高人们在面对不匹配常见种族-地位刻板印象的候选人时的选择率，这表明隐含联想测试可能是一种对AI偏见的应对策略，它可以在特定的决策情境中增强人类的自主性。", "conclusion": "本研究的结论指出，即使人们认为AI的建议质量低或不重要，他们的决策依然可能受AI偏见的影响。这强调了在AI协助决策场景中，人类自主性的脆弱性。研究还对组织和监管政策提出了建议，要认识到人类-人工智能协同决策中的复杂性，以确保这些技术的使用不会损害个体的决策权。该研究提出了设计和评估AI招聘系统的新策略，以及在合作决策任务中减轻偏见的方法。"}
{"llm_update_time": "20250907", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2311.17165", "html_url": "https://arxiv.org/abs/2311.17165", "title": "AI中的(不)理性：现状、研究挑战与开放问题", "title_en": "(Ir)rationality in AI: State of the Art, Research Challenges and Open Questions", "authors": "Olivia Macmillan-Scott,Mirco Musolesi", "background": "人工智能领域中理性概念至关重要。无论是模拟人类推理还是追求最优策略，目标通常是使人工智能代理尽可能接近理性。尽管理性在AI领域具有重要地位，但并没有统一的定义来描述什么是理性代理。本文回顾AI中的理性与非理性，并探讨该领域中的开放问题。理性的理解如何在经济学、哲学和心理学其他领域的影响下形成，特别是对AI的影响。文章还探讨了在某些情境下可能表现出的非理性行为如何变得最优。目前已有部分方法用于识别并应对非理性代理，但相关研究仍处于初始阶段。现有其他领域的对抗场景方法可能适用于AI代理的交互。", "innovation": "本文提供了一个关于AI中理性与非理性现象的综述，探索了不同学术领域对理性理解的影响，并讨论了在某些情境下非理性行为可能成为最优策略的现象。此外，指出了一些现有方法在应用于AI代理交互时的潜力，以及人机交互中的理性作用。文章提出了一些领域内的重要问题，特别是关于人类和AI代理潜在的非理性行为。", "conclusion": "尽管已经取得了一些进展，但在理性与非理性代理的理解和应对上仍存在大量未解决的问题。文章指出，现有用于对抗场景的方法可能适用于与AI代理的交互，并讨论了人类与AI代理互动中的理性作用。通过深入研究这些领域，有望为AI的发展提供更准确的指导。"}
{"llm_update_time": "20250907", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2008.07324", "html_url": "https://arxiv.org/abs/2008.07324", "title": "智能 primer", "title_en": "Intelligence Primer", "authors": "Karl Fezer,Andrew Sloss", "background": "智能是所有生命体的基础，也是人工智能的基石。本文旨在探讨与智能相关的理念，以及其带来的影响和限制，同时可能勾勒出未来系统的潜在能力。随着机器学习形式的人工智能已经对我们的生活产生了重大影响，本文将探讨智能的关键方面，希望读者能从中受益，确定未来的方向。此外，在探索过程中，我们希望提出新的引人思考的问题。智能不仅仅是一个可以衡量的数量，而是涉及生物学、物理学、哲学、认知科学、神经科学、心理学和计算机科学等多个领域的主题。未来的工程师和科学家需要拓宽知识领域，包括心理学、哲学和伦理学。现代社会中，人工智能的发展和法律法规的要求促使这些更广泛的课题进入前沿。本文从智能的介绍开始，迅速转向更深层次的思考和理念。", "innovation": "本文尝试从多学科角度探讨智能，涵盖生物学、物理学、哲学、认知科学、神经科学、心理学和计算机科学等多个领域，试图为未来智能体系的构建提出可能的框架和思考方向。", "conclusion": "智能不仅仅是一个可以衡量的数量，它是一个跨越多个学科领域的复杂概念。通过本文的探讨，我们认为未来的人工智能系统需要在多个学科的理解基础上进行发展，而这将有助于更好地理解并应用智能。"}
{"llm_update_time": "20250907", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2410.08949", "html_url": "https://arxiv.org/abs/2410.08949", "title": "量子电路上的可转移信念模型", "title_en": "Transferable Belief Model on Quantum Circuits", "authors": "Qianli Zhou,Hao Luo,Lipeng Pan,Yong Deng,Eloi Bosse", "background": "转移性信念模型作为一种 Dempster-Shafer 理论的语义解释，使代理能够在不精确和不完整的环境中进行推理和决策。该模型通过处理不可靠的证词提供了不同的语义，相比于贝叶斯方法更合理且通用。然而，由于在更新信念函数时必须考虑信念质量及其聚焦点集的结构，这导致在推理过程中增加了额外的计算复杂性，因此近年来转移性信念模型逐渐失去了研究人员的青睐。", "innovation": "本文在量子电路中实现了转移性信念模型，并证明了信念函数在量子计算框架内是比贝叶斯方法更简洁和有效的替代方案。此外，利用量子计算的独特特性，提出了几种新的信念转移方法。另一方面，本文从一个新的角度介绍了量子AI模型的基本信息表示方式，表明在量子电路中处理不确定性时，信念函数比贝叶斯方法更适合。", "conclusion": "通过在量子电路中实现转移性信念模型，本文展示了信念函数比贝叶斯方法更适合在量子计算框架内处理不确定性。同时，利用量子计算的独特性质，一系列新的信念转移方法被提出，为量子AI模型提供了新的启示。"}
{"llm_update_time": "20250907", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2406.13923", "html_url": "https://arxiv.org/abs/2406.13923", "title": "PIN: 交错配对多模态文档的富含知识的数据集", "title_en": "PIN: A Knowledge-Intensive Dataset for Paired and Interleaved Multimodal Documents", "authors": "Junjie Wang,Yuxiang Zhang,Minghao Liu,Yin Zhang,Yatai Ji,Weihao Xuan,Nie Lin,Kang Zhu,Zhiqiang Lin,Yiming Ren,Chunyang Jiang,Yiyao Yu,Zekun Wang,Tiezhen Wang,Wenhao Huang,Jie Fu,Qunshu Liu,Yujiu Yang,Ge Zhang,Ruibin Yuan,Bei Chen,Wenhu Chen", "background": "近年来，大型多模态模型（LMMs）利用大量多模态数据集增强了复杂知识驱动任务的能力。但感知和推理错误的持续挑战限制了它们的有效性，尤其是在解释复杂的视觉数据和推断多模态关系方面。", "innovation": "提出了PIN（配对和交错的多模态文档）这一创新的数据格式，旨在促进更深层次的视觉和文本知识整合。PIN格式独特地将富含语义的Markdown文件与整体图像结合在一起，Markdown文件保留了精细的文本结构，整体图像则捕捉了文档的整体布局。构建了两个大型开源数据集：PIN-200M（约2亿文档）和PIN-14M（约1400万文档），来自各种英文和中文的网络和科学来源。为方便使用，提供了详细的统计分析和质量信号，使研究人员能够轻松筛选和选择特定任务所需的数据。", "conclusion": "这项工作为社区提供了灵活的数据格式和丰富的资源，为预训练策略和更强大、更知识密集型LMM的发展奠定了基础。"}
{"llm_update_time": "20250907", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2505.11701", "html_url": "https://arxiv.org/abs/2505.11701", "title": "DMN-Guided Prompting: 一种控制LLM行为的框架", "title_en": "DMN-Guided Prompting: A Framework for Controlling LLM Behavior", "authors": "Shaghayegh Abedi,Amin Jalali", "background": "大型语言模型（LLMs）在知识密集型过程中的决策逻辑自动化方面展现了巨大的潜力，但其效果很大程度上取决于提示策略和质量。由于决策逻辑通常嵌入在提示中，并且对于最终用户来说修改或优化它颇具挑战性。决策模型与标记（DMN）提供了一种标准化的图形化方法，用于结构化和用户友好的定义决策逻辑。本文介绍了一种基于DMN指导的提示框架，将复杂的决策逻辑分解为较小、可管理的组件，引导LLMs通过结构化的决策路径。该框架在一门研究生级别的课程中进行了实现，学生提交了作业，并使用包含反馈指导的DMN模型作为输入。教师评估了生成的反馈，并对其进行性能评估。", "innovation": "引入了基于DMN指导的提示框架，将复杂决策逻辑分解为较小、可管理的组件，帮助引导LLMs通过结构化的决策路径。该方法在实际应用中学生成绩有显著提升，并且学生对生成的反馈给予了高度评价。", "conclusion": "基于DMN的提示框架展示了良好的效果，超越了链式思考（CoT）提示的方法。学生在调查中报告了对生成反馈的高度感知价值。"}
{"llm_update_time": "20250907", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2412.05248", "html_url": "https://arxiv.org/abs/2412.05248", "title": "提升FKG.in：自动化印度食物成分分析", "title_en": "Enhancing FKG.in: automating Indian food composition analysis", "authors": "Saransh Kumar Gupta,Lipika Dey,Partha Pratim Das,Geeta Trilok-Kumar,Ramesh Jain", "background": "本文旨在利用印度食物知识图（FKG.in）和大规模语言模型（LLMs）来自动化计算印度食谱中的食物成分数据。本文主要探讨了印度食物的表示以及获取数字化食物成分数据的挑战，并回顾了印度食物成分数据的三个主要来源：印度食物成分表、印度营养数据中心数据库和Nutritionix API。此外，本文还简要概述了用户如何通过工作流获取基于饮食的健康建议和详细的食材成分信息。文章还探讨了分析印度食谱信息的复杂挑战，包括结构、多语言和不确定性问题，并提出了基于LLM的解决方案来解决这些问题。", "innovation": "提出了一个创新的方法，使用知识图和LLMs来自动化计算印度食谱中的食物成分数据，并提供了一个自动化的食物成分分析工作流，包含了营养数据分析、食物成分分析以及LLM增强的信息解析。该工作流旨在补充和逐步完善来自可信知识库的食物成分数据，并提出了基于LLM的解决方案来解决印度食谱信息分析中的复杂挑战。", "conclusion": "本文提出的工作流方法包括AI驱动的知识收集和信息解析，是应用程序无关的，具有普适性和可复制性，适用于任何领域。作者认为，这一工作流能够为印度食谱中的营养成分数据提供自动化和高效率的处理，具有广泛的应用前景。"}
{"llm_update_time": "20250907", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.03315", "html_url": "https://arxiv.org/abs/2506.03315", "title": "通过集合的线性顺序（最小值作为备份）实现的受限制选择的公理化", "title_en": "Axiomatics of Restricted Choices by Linear Orders of Sets with Minimum as Fallback", "authors": "Kai Sauerwald,Kenneth Skiba,Eduardo Fermé,Thomas Meyer", "background": "研究如何利用线性序来实现受限集的择函数，即在选择集合限制的条件下，择函数的选择范围受到严格限制，不在所有选项的全体势集中。当无法通过关系来构建择函数时，可以通过集合的线性序来构造择函数，即使在其中编码了备份值（最小元素）。受限制的择结构在知识表示与推理中有应用，特别是用于理论变化和抽象论辩。", "innovation": "展示了一种新的方法，即通过集合的线性序构造受限制择函数，即使存在备份值（作为最小元素）。提出了受限制择函数的公理化，包括一般情况和具体输入限制情况下的应用。", "conclusion": "受限制的择结构在知识表示和理论变化等领域的应用表明，即使在选择范围受限情况下，也可以通过线性序构造择函数，这种构造方法为进一步研究提供了理论基础。"}
{"llm_update_time": "20250907", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.06052", "html_url": "https://arxiv.org/abs/2506.06052", "title": "CP-Bench: 评估大型语言模型进行约束建模", "title_en": "CP-Bench: Evaluating Large Language Models for Constraint Modelling", "authors": "Kostis Michailidis,Dimos Tsouros,Tias Guns", "background": "约束编程（CP）广泛用于解决组合问题，但其核心过程即约束建模需要大量的专业知识，并且被认为是普及的瓶颈。为了解决这个问题，最近的研究正在探索利用大规模语言模型（LLMs）将组合问题描述转换为可执行的约束模型。然而，现有的约束建模评估数据集通常局限于小型、同质或领域特定的实例，无法捕捉现实世界的多样性场景。本文通过引入CP-Bench基准，解决这一问题。CP-Bench基准包括来自CP社区的各种知名组合问题，明确结构化以评估LLM驱动的CP建模。", "innovation": "本文引入了CP-Bench基准，该基准包含来自组合问题社区的各种知名问题，明确结构化以评估基于LLM的约束建模。此外，本文系统评估了不同LLM在使用提示和推理时间计算方法方面的表现，这些方法进一步提高了准确性，达到了在这个极具挑战性的基准上70%的准确率。", "conclusion": "本文展示了使用高阶Python基架框架进行约束建模时更高的性能。此外，研究人员评价了不同LLM在不同Prompt和推理时间算法上的表现，这些方法显著提高了准确性。CP-Bench基准为研究LLM在约束建模中的应用提供了有价值的评估工具。"}
{"llm_update_time": "20250907", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.00401", "html_url": "https://arxiv.org/abs/2508.00401", "title": "使用主动推理的理论心智：多智能体合作的框架", "title_en": "Theory of Mind Using Active Inference: A Framework for Multi-Agent Cooperation", "authors": "Riddhi J. Pitliya,Ozan Çatal,Toon Van de Maele,Corrado Pezzato,Tim Verbelen", "background": "理论心智（ToM）使智能体能够理解他人可能有不同的知识和目标，从而在计划自己的行动时能够推理他人的信念。以往的多智能体合作方法要么依赖特定任务的共享生成模型，要么需要显式通信。", "innovation": "提出了一种新颖的多智能体合作方法，通过在主动推理中实施ToM。该方法既不需要特定任务的共享生成模型，也不需要显式通信。ToM智能体保持自己和他人的信念与目标的独特表示，并使用扩展和适应后的精细推理树算法来系统地通过递归推理探索联合策略空间。", "conclusion": "通过碰撞避免和觅食模拟结果表明，ToM智能体比非ToM智能体更能合作，能够避免碰撞并减少冗余努力。关键在于ToM智能体仅通过推断他人的行为推测他人的信念，并在计划自身行动时考虑这些信念。该方法展示了具有普遍和可扩展性的多智能体系统潜力，并提供了关于ToM机制的计算见解。"}
{"llm_update_time": "20250907", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.01700", "html_url": "https://arxiv.org/abs/2508.01700", "title": "DeepVIS：通过逐步推理连接自然语言和数据可视化", "title_en": "DeepVIS: Bridging Natural Language and Data Visualization Through Step-wise Reasoning", "authors": "Zhihao Shuai,Boyan Li,Siyu Yan,Yuyu Luo,Weikai Yang", "background": "尽管数据可视化对于揭示模式和沟通洞察力非常强大，但创建有效的可视化通常需要熟悉作者工具，并且会中断分析流程。尽管大型语言模型显示出自动将分析意图转换为可视化的效果，现有的方法通常作为黑箱操作，缺乏透明的推理过程，从而防止用户理解设计理由和改进生成的不理想输出。", "innovation": "本文提出将Chain-of-Thought（CoT）推理集成到自然语言到可视化（NL2VIS）流程中。首先，设计了一套全面的CoT推理过程和自动管道，以现有数据集为基础增加结构化推理步骤。其次，引入了nvBench-CoT，这是一种专门的数据集，捕捉从模糊自然语言描述到最终可视化详细的逐步推理过程，使得在模型微调时能达到最先进的性能。第三，开发了DeepVIS，这是一种与CoT推理流程紧密结合的高度互动可视界面，允许用户检查推理步骤、识别错误并进行针对性调整以改善可视化结果。", "conclusion": "定量基准评估、两个用例和用户研究共同证明，我们的CoT框架有效地提高了NL2VIS的质量，同时向用户提供启发性的推理步骤。"}
{"llm_update_time": "20250907", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2502.17882", "html_url": "https://arxiv.org/abs/2502.17882", "title": "科学跨语言：评估大语言模型多语言翻译科学论文的效果", "title_en": "Science Across Languages: Assessing LLM Multilingual Translation of Scientific Papers", "authors": "Hannah Calzi Kleidermacher,James Zou", "background": "科学研究本质上是全球性的，但大多数学术期刊只用英语出版，这为非英语母语的研究人员设定了障碍。本文利用大型语言模型（LLMs）将已发表的科学文章翻译成保留其原格式的JATS XML格式，提出了一个操作性强、自动化的实现方法，旨在供学术期刊采用。通过这种方法，我们将多种科学领域的文章翻译成28种语言，从而消除这种语言障碍。", "innovation": "本文提出了一种基于大语言模型的自动翻译方法，将科学文章翻译成多种语言，同时保留其原格式，并引入了一种新颖的问答（QA）基准方法来评估翻译准确性。这种方法有效地解决了非英语母语研究人员的论文阅读问题，同时展示了大语言模型在科学翻译中的潜力。通过在具体科学领域中调整翻译以平衡过度翻译的问题，进一步增强了翻译的适应性和实用性。", "conclusion": "研究表明，通过大语言模型的翻译，科学论文的关键信息可以准确传达，平均翻译准确率高达95.9%。用户研究显示，作者一致认为翻译准确反映了原文信息。一部分作者希望保留一些术语在英语中的熟悉性。最终，本文展示了如何通过上下文学习技术调整翻译以满足特定领域的需求，证明了大语言模型在科学翻译中的灵活性和实用性。相关的代码和翻译后的文章已公布在指定网址。"}
{"llm_update_time": "20250907", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2504.11671", "html_url": "https://arxiv.org/abs/2504.11671", "title": "社会模拟中大型语言模型决策的计算基础", "title_en": "Computational Basis of LLM's Decision Making in Social Simulation", "authors": "Ji Ma", "background": "大型语言模型（LLMs）在社会科学和实际应用中越来越像人类决策代理。通常，这些LLM代理会被赋予人类般的特性并放置在真实情境中。然而，这些特性和情境如何塑造LLM的行为尚未被充分探索。本文通过在社会决策实验（例如点对点分配实验）中探查、量化和修改LLM的内部表征来填补这一空白，从而探讨和规范社会概念如何在以变换器为基础的模型内部被编码和设计，这具有对齐、去偏见以及设计用于社会模拟的AI代理的实际应用价值，并提升社会学理论和测量", "innovation": "本文提出并测试了一种方法，通过在模型推断过程中操纵LLM内部状态的变量向量（例如，从“男性”变化到“女性”），以显著改变变量与模型决策之间的关系，这提供了一种原理化的研究方式，用于探讨和控制社会概念如何在以变换器为基础的模型内部被编码和设计，为对齐、去偏见以及社会模拟中设计AI代理提供理论支持", "conclusion": "本文的方法提供了对齐、去偏见以及在社会模拟中设计具有社会学理论和测量意义的AI代理的新途径，展示了LLM代理在社会情境中的复杂行为背后的计算基础，为未来的理论发展和实践应用提供了重要指导"}
{"llm_update_time": "20250907", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.01938", "html_url": "https://arxiv.org/abs/2509.01938", "title": "EigenBench: 一种比较性价值观对齐行为衡量方法", "title_en": "EigenBench: A Comparative Behavioral Measure of Value Alignment", "authors": "Jonathn Chang,Leonhard Piff,Suvadip Sana,Jasmine X. Li,Lionel Levine", "background": "人类价值观和AI的对齐是一个亟待解决的问题。现有方法缺乏量化价值观对齐的指标。EigenBench 提出了一个黑盒方法，用于比较性地评估语言模型的价值观，以填补这一空白。", "innovation": "EigenBench 通过将每个模型对其他模型在多种情境下输出的评判进行聚合，利用 EigenTrust 方法生成反映整个模型群体加权平均判断的分数。它不依赖已标记的正确标签，能在合理评判者意见有分歧的情况下量化特质。", "conclusion": "研究表明，EigenBench 的分数主要由提示因素解释，但模型本身的倾向性仍能解释一小部分变化。"}
{"llm_update_time": "20250907", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.16117", "html_url": "https://arxiv.org/abs/2508.16117", "title": "扩展 FKG.in：迈向食品声明可追溯性网络", "title_en": "Extending FKG.in: Towards a Food Claim Traceability Network", "authors": "Saransh Kumar Gupta,Rizwan Gulzar Mir,Lipika Dey,Partha Pratim Das,Anirban Sen,Ramesh Jain", "background": "全球食品领域的科学、文化与商业声称五花八门，从经过严格研究的功效（如益生菌改善肠道健康）到误导性的说法（如泡发杏仁使人更聪明），再到模糊的承诺（如超级食品增强免疫力）和根深蒂固的文化信念（如冷食导致咳嗽）。尽管这些声称广泛影响人们的生活，追踪、验证和上下文化这些声称的基础设施仍然支离破碎且不完善。", "innovation": "本文提议构建一个食品声明可追溯性网络（FCN），作为印度食品知识图谱（FKG.in）的扩展。该网络使用从Reddit数据和大型语言模型生成半自动知识_curation_工作流开发了CKG.in-FCN的概念验证。FCN通过整合经过验证的数据输入、结构化模式和附有来源意识的管道，实现了食品相关声明的提取和验证。研究方法在印度食品知识图谱的应用上具有针对性，但仍然具有广泛适用性和适应不同地理、烹饪或监管环境的能力。", "conclusion": "通过以结构化、可验证和可解释的方式建模食品声明及其追溯性，我们旨在为更透明和负责任的食品安全生态系统做出贡献，支持研究人员、政策制定者和最重要的是普通消费者在充斥着饮食声明的世界中导航。"}
{"llm_update_time": "20250907", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2403.03726", "html_url": "https://arxiv.org/abs/2403.03726", "title": "蛋白质序列生成中的语言模型编码扩散", "title_en": "Diffusion on language model encodings for protein sequence generation", "authors": "Viacheslav Meshchaninov,Pavel Strashnov,Andrey Shevtsov,Fedor Nikolaev,Nikita Ivanisenko,Olga Kardymon,Dmitry Vetrov", "background": "蛋白质序列设计已通过离散扩散和自回归方法取得了显著进展，但连续扩散方法的潜力尚未被充分探索。", "innovation": "提出了一种名为DiMA的潜扩散框架，该框架可在蛋白质语言模型表示上运行。该框架通过系统地探索架构选择和扩散组件，能够在多种蛋白质编码器（从8M到3B参数）上展现出良好的泛化能力。该框架在序列仅为的（ESM-2, ESMc）、双可解码的（CHEAP）和多模态的（SaProt）表示下，使用相同的架构和训练方法展示了优异的性能。DiMA能够生成高质量的新型且多样化的蛋白质序列，且在生成蛋白质的多个度量标准上均优于现有的自回归、离散扩散和流匹配语言模型。模型支持包括蛋白质家族生成、motif支架和填补等条件生成任务。", "conclusion": "这项工作提出了一种通用的连续扩散框架用于蛋白质序列生成，为不同蛋白质设计场景提供了架构见解和实际应用。"}
{"llm_update_time": "20250907", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2405.08965", "html_url": "https://arxiv.org/abs/2405.08965", "title": "MTP：AI集成编程中的意义类型语言抽象", "title_en": "MTP: A Meaning-Typed Language Abstraction for AI-Integrated Programming", "authors": "Jayanaka L. Dantanarayana,Yiping Kang,Kugesan Sivasothynathan,Christopher Clarke,Baichuan Li,Savini Kashmira,Krisztian Flautner,Lingjia Tang,Jason Mars", "background": "软件开发正在从传统的编程方式转向利用生成式AI和大型语言模型（LLMs）在运行时的AI集成应用程序。然而，集成LLMs仍然复杂，需要开发人员手动构建提示和处理输出。现有工具试图辅助提示工程，但往往会引入额外的复杂性。", "innovation": "提出了一种名为意义类型编程（MTP）的新范式，通过直观的程序语言级构造抽象LLMs集成。MTP利用代码固有的语义丰富性自动化提示生成和响应处理，无需额外的开发人员努力。引入了by运算符进行无缝LLM调用，MT-IR作为一种基于意义的中间表示用于语义提取，以及MT-Runtime自动化管理系统来管理LLMs交互。", "conclusion": "MTP显著降低了编码复杂性，减少了所需改写的行数，降低了成本，同时提高了运行时性能，并保持或超过了现有方法的准确性。我们的用户研究显示，使用MTP的开发者比现有框架更快地完成任务，速度快3.2倍，代码行数减少了45%。此外，即使多达50%的命名约定降级，MTP也表现出色，证明了其对次优代码的稳健性。MTP作为Jaseci开源项目的部分开发，可通过模块byLLM获取。"}
{"llm_update_time": "20250907", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2312.03993", "html_url": "https://arxiv.org/abs/2312.03993", "title": "使用稳定扩散进行卡尔文和霍布斯漫画风格转换", "title_en": "Style Transfer to Calvin and Hobbes comics using Stable Diffusion", "authors": "Asvin Kumar Venkataramanan,Sloke Shrestha,Sundar Sripada Venugopalaswamy Sriraman", "background": "本项目报告概述了我们在使用卡尔文和霍布斯漫画数据集进行稳定扩散微调过程中所经历的历程。我们的目标是将输入的任意图像转换为卡尔文和霍布斯漫画的风格，进行风格转换。我们利用Low Rank Adaptation (LoRA)对stable-diffusion-v1.5进行训练，以加快这个过程。将差分过程交由一个自编码器处理，该编码器是U-net模型。我们对结果在给定的训练时间和高质量输入数据下的视觉效果印象深刻.", "innovation": "本研究的创新之处在于将Low Rank Adaptation (LoRA)引入到了稳定扩散模型的微调过程中，以加速模型的训练过程。此外，使用的自编码器模型（U-net），来实现图像的差分处理，这也是研究的一部分创新点.", "conclusion": "我们的实验取得了令人满意的结果，尽管训练时间有限，但生成的图像具有很高的视觉质量和准确性。通过这种方式，我们能够高效地将输入图像转换为卡尔文和霍布斯漫画的风格。"}
{"llm_update_time": "20250907", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.01909", "html_url": "https://arxiv.org/abs/2509.01909", "title": "Oyster-I：超越拒绝--负责任语言模型的建设性安全对齐", "title_en": "Oyster-I: Beyond Refusal -- Constructive Safety Alignment for Responsible Language Models", "authors": "Ranjie Duan,Jiexi Liu,Xiaojun Jia,Shiji Zhao,Ruoxi Cheng,Fengxiang Wang,Cheng Wei,Yong Xie,Chang Liu,Defeng Li,Yinpeng Dong,Yichi Zhang,Yuefeng Chen,Chongwen Wang,Xingjun Ma,Xingxing Wei,Yang Liu,Hang Su,Jun Zhu,Xinfeng Li,Yitong Sun,Jie Zhang,Jinzhao Hu,Sha Xu,Yitong Yang,Jialing Tao,Hui Xue", "background": "大型语言模型（LLMs）通常会部署安全机制以防止有害内容的生成。当前大多数方法主要集中在恶意用户的威胁上，往往将风险视为对抗性事件，并依赖于防御性的拒绝。“然而，在实际场景中，风险也来自于处于心理压力下的非恶意用户（例如自杀意念），他们寻求帮助。在这种情况下，模型的回答可能强烈影响用户的下一步行动。简单的拒绝可能促使他们重复、升级或转投不安全的平台，从而产生更差的结果。”", "innovation": "该论文引入了一种以人为中心的建设性安全对齐（CSA）框架，旨在不仅保护免受恶意使用，还能积极引导脆弱用户走向安全和有用的结果。CSA在Oyster-I（Oy1）实现，结合了用户反应的博弈论预测、细粒度的风险边界发现和可解释的推理控制，将安全转变为信任建设的过程。Oy1在开放模型中达到最先进的安全标准，同时保留了高度的一般能力。并通过Constructive基准展示了强大的建设性参与，并在Strata-Sword脱管数据集中表现出无与伦比的鲁棒性，接近GPT-o1的水平。", "conclusion": "通过从拒绝优先转向指导优先的安全策略，CSA重新定义了模型与用户的关系，旨在构建不仅安全而且有意义地有益的系统。该研究向大家分享了Oyster-I、相关代码以及基准，以促进责任导向、用户为中心的人工智能的发展。"}
{"llm_update_time": "20250907", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2211.12143", "html_url": "https://arxiv.org/abs/2211.12143", "title": "自主化，而非自动化：欧洲事实核查者的活动与需求作为设计以人为本的人工智能系统的基础", "title_en": "Autonomation, Not Automation: Activities and Needs of European Fact-checkers as a Basis for Designing Human-Centered AI Systems", "authors": "Andrea Hrckova,Robert Moro,Ivan Srba,Jakub Simko,Maria Bielikova", "background": "为了更有效地应对假信息的负面影响，需要开发人工智能（AI）系统来辅助事实核查员。然而，由于缺乏对这些相关方需求的关注，这导致他们对完全自动化事实核查过程的接受程度有限，并持有怀疑态度。本研究通过半结构化的深度访谈了解了中欧事实核查员的工作活动和问题，并使用迭代内容分析法进行了分析。还通过调查欧洲事实核查者进行了验证，收集了来自20个国家的24个有效回复，即来自国际事实核查网络（IFCN）活跃签署国的62%的回复，揭示了非英语地区事实核查工作的可变性。", "innovation": "本研究的创新之处在于深入探讨了非英语地区事实核查工作的变异性，这在之前的研究中仍未被广泛覆盖。通过将前人的知识与研究结果相结合，提出了有助于理解事实核查过程的概念模型。此外，研究将事实核查者的活动和需求与相关的AI研究任务进行了映射，提供了三项之前类似研究未覆盖的AI任务的讨论，为AI研究人员和开发者指出了新的研究机会，这影响了该领域的AI研究方向。", "conclusion": "本研究通过分析发现，为了设计以人为本的人工智能系统，理解欧洲事实核查者的活动与需求至关重要。提出的概念模型可以为设计AI系统提供指导，同时也指出了AI研究的新方向。"}
{"llm_update_time": "20250907", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.02761", "html_url": "https://arxiv.org/abs/2509.02761", "title": "基于LLM的体感任务完成代理计划验证", "title_en": "Plan Verification for LLM-Based Embodied Task Completion Agents", "authors": "Ananth Hariharan,Vardhan Dongre,Dilek Hakkani-Tür,Gokhan Tur", "background": "基于大型语言模型（LLM）的任务计划和人类示范可能包含不必要的动作、冗余导航和逻辑错误，这些都会降低策略质量。需要一种迭代验证框架，在这种框架中，一个审判LLM会批判行动序列，一个规划LLM会应用修正，生成越来越干净且更加空间连贯的轨迹。现有方法依赖规则，而该方法则通过自然语言提示来实现广泛类型错误的泛化能力，包括无关动作、矛盾和遗漏步骤等。在TEACh体感AI数据集上，该框架在四个最新LLM（GPT o4-mini、DeepSeek-R1、Gemini 2.5、LLaMA 4 Scout）上实现了高达90%的召回率和100%的精确率。改进环路迅速收敛，96.5%的序列在最多三轮修正后达到收敛，同时提高了时间和空间动作组织的效率。", "innovation": "提出了一种迭代验证框架，利用LLM进行计划验证和行动修正，这种方法通过自然语言提示来工作，能够广泛泛化不同类型的错误，如无关动作、矛盾和遗漏步骤等。该方法能够快速收敛，并且保持了人类错误恢复模式，支持未来面向强大纠正行为的研究。验证计划作为空间规划和行动修正的可靠LLM能力，为体感AI中的模仿学习提供更多优质训练数据奠定了基础。", "conclusion": "该框架有效提高了体感AI任务计划和实施的准确性，特别是在多个最先进的模型上表现出色。方法能迅速收敛，保持了人的错误恢复模式，有利于未来在体感AI中的应用。通过这种方法，可以为模仿学习提供更高质量的训练数据，是一条可扩展的路径。"}
{"llm_update_time": "20250907", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2410.02807", "html_url": "https://arxiv.org/abs/2410.02807", "title": "AutoPETIII: The Tracer Frontier. What Frontier?", "title_en": "AutoPETIII: The Tracer Frontier. What Frontier?", "authors": "Zacharia Mesbah,Léo Mottay,Romain Modzelewski,Pierre Decazes,Sébastien Hapdey,Su Ruan,Sébastien Thureau", "background": "AutoPET竞赛在过去三年吸引了医学影像社区的关注，聚焦于正电子发射断层扫描(PET)图像中的病灶分割。每年竞赛都会探讨不同的问题，2024年的挑战集中在处理多种不同类型的示踪剂上。今年的目标是开发一个能够自动识别PET/CT图像中病灶的算法，无需事先知道具体的示踪剂类型，它可以是FDG或PSMA基的示踪剂。", "innovation": "本文介绍了一种使用nnUNetv2框架训练的两组六折模型集合来实现PET/CT病灶自动分割的方法，同时使用了一种MIP-CNN来选择哪一组模型进行病灶分割。", "conclusion": "通过这种方法，研究团队成功地构建了一个能够在不知示踪剂的情况下自动完成PET/CT病灶分割的算法，展示了在复杂示踪剂问题上的创新解决方式。"}
{"llm_update_time": "20250907", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2405.17527", "html_url": "https://arxiv.org/abs/2405.17527", "title": "Unisolver: 针对通用神经偏微分方程求解器的偏微分方程条件变换器", "title_en": "Unisolver: PDE-Conditional Transformers Towards Universal Neural PDE Solvers", "authors": "Hang Zhou,Yuezhou Ma,Haixu Wu,Haowen Wang,Mingsheng Long", "background": "近年来，深度模型作为一种有望解决偏微分方程（PDEs）的方法，被称为神经PDE求解器。虽然从仿真数据或基于物理的信息损失训练的神经求解器在解决PDEs方面表现得相当不错，但它们主要局限于少数PDE实例，例如特定方程配以有限参数集。这限制了它们对各种PDE的泛化能力，使得它们不可能作为数值求解器的实用替代模型。", "innovation": "在本文中，我们提出了Unisolver，这是一种新颖的变换器模型，通过多样化数据训练并依据多样化PDE来实现目标，旨在成为一个能够解决广泛PDE的通用神经PDE求解器。Unisolver 从偏微分方程解的理论分析出发，而不是单纯地扩大数据和参数规模。Unisolver 结合了物理洞察和近期变换器技术的进展，实现了三个具有挑战性的大规模基准上的持续最前沿表现，展示了出色的表现和泛化能力。", "conclusion": "Unisolver 通过整合物理洞察并结合最近的变换器技术进步，在三个具有挑战性的大规模基准测试中实现了最先进的性能，并展示了其出色的表现和泛化能力。此项研究为构建通用的神经PDE求解器提供了新的思路，解决了一个重要的技术挑战。"}
{"llm_update_time": "20250907", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2407.15161", "html_url": "https://arxiv.org/abs/2407.15161", "title": "FFHFlow: 通过流变分解推理生成多样且具备不确定性的灵巧抓取", "title_en": "FFHFlow: Diverse and Uncertainty-Aware Dexterous Grasp Generation via Flow Variational Inference", "authors": "Qian Feng,Jianxiang Feng,Zhaopeng Chen,Rudolph Triebel,Alois Knoll", "background": "从部分观测中合成多样化且具备不确定性的多指灵巧手抓取一直是机器人学习中的关键挑战。先前生成方法难以建模灵巧手指的复杂抓取分布，并且往往无法处理部分点云中内蕴的形状不确定性，导致抓取不可靠或过于保守。这个问题在关于多指灵巧手抓取的研究中一直没有得到很好的解决，造成了实际应用中的困难。", "innovation": "我们提出了FFHFlow，一种基于流的变分框架，能够生成多样且具备鲁棒性的多指抓取，同时明确度量部分点云知觉不确定性。FFHFlow结合基于归一化流的深度隐变量模型学习分层抓取流形，克服了条件变分自编码器（cVAEs）模态崩塌和刚性先验的局限。通过利用流的可逆性和精确似然性，FFHFlow能够从部分观察中反思形状不确定性，识别新的物体结构，从而实现风险意识的抓取合成。为了进一步增强可靠性，我们集成了一个识别性的抓取评估器与流似然性，提出一种基于不确定性的排序策略，优先选择对形状不确定性鲁棒的抓取。", "conclusion": "广泛的仿真和现实世界设置实验显示FFHFlow在抓取多样性和成功率上优于目前最先进的基线方法（包括扩散模型），并且具有运行时高效采样。FFHFlow还在杂乱和受限环境中展示了其实用价值，通过分散碰撞，多样驱动的采样策略表现更优。"}
{"llm_update_time": "20250907", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2411.00265", "html_url": "https://arxiv.org/abs/2411.00265", "title": "通过证据理论量化神经网络的校准误差", "title_en": "Quantifying Calibration Error in Neural Networks Through Evidence-Based Theory", "authors": "Koffi Ismael Ouattara,Ioannis Krontiris,Theo Dimitrakos,Frank Kargl", "background": "在关键应用中部署神经网络时，其可信度至关重要，可靠性、置信度和不确定性在决策过程中起着决定性作用。传统的性能衡量标准，如准确率和精确率，无法捕捉这些方面，尤其是在模型表现出过拟合的情况下。", "innovation": "本文通过引入一种新颖的框架，结合主观逻辑来评估期望校准误差（ECE），这是一种计算预测概率聚类和融合意见的方法，从而量化神经网络的可信度。这种方法提供了一个全面的衡量标准，包括信任、不相信和不确定性。", "conclusion": "通过在MNIST和CIFAR-10数据集上的实验，证明了该方法的有效性，并且校准后的结果表明提高了模型的可信度。所提出的框架为人工智能模型提供了更可解释和细致的评估，有望在医疗保健和自主系统等敏感领域得到应用。"}
{"llm_update_time": "20250907", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2410.22381", "html_url": "https://arxiv.org/abs/2410.22381", "title": "使用不变统计损失训练多变量和重尾分布的隐式生成模型以增强鲁棒性", "title_en": "Robust training of implicit generative models for multivariate and heavy-tailed distributions with an invariant statistical loss", "authors": "José Manuel de Frutos,Manuel A. Vázquez,Pablo Olmos,Joaquín Míguez", "background": "传统的隐式生成模型能够学习高度复杂的数据分布。然而，在训练过程中，它们依赖于对抗性判别器来区分真实数据和生成数据，这可能导致不稳定的训练动态和模式丢失。许多现实现象产生的数据需要使用重尾概率分布来恰当地描述，而传统的隐式方法难以有效地捕捉其渐近行为。", "innovation": "本文基于文献 \textit{de2024training} 中介绍的不变统计损失 (ISL) 方法，将其扩展以处理重尾和多变量数据分布。引入了一个基于广义帕累托分布 (GPD) 输入噪音的生成器，并将其称为Pareto-ISL。还通过随机投影扩展了一维方法，并定义了一个新的损失函数适用于多变量数据，通过调节投影数量使问题可处理。", "conclusion": "实验结果表明，Pareto-ISL 能够准确模型分布的尾部特性并有效捕捉其中心特征。这种损失函数在多维生成建模中表现良好，同时可以用作生成对抗网络 (GAN) 的预训练技术以防止模式崩溃，且对各种超参数设置具有鲁棒性。"}
{"llm_update_time": "20250907", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2411.12736", "html_url": "https://arxiv.org/abs/2411.12736", "title": "ACING: Actor-Critic for Instruction Learning in Black-Box LLMs", "title_en": "ACING: Actor-Critic for Instruction Learning in Black-Box LLMs", "authors": "Salma Kharrat,Fares Fourati,Marco Canini", "background": "大型语言模型（LLMs）在解决任务的效果很大程度上取决于其指令的质量，而编写高质量指令通常需要大量的手动工作。因此，需要一种自动优化指令的方法。然而，当处理黑盒模型，其参数和梯度不可访问时，优化指令特别具有挑战性。", "innovation": "本文提出了ACING框架，这是一种使用演员-评论家强化学习方法来自动优化黑盒LLMs的指令的方法。ACING将指令优化问题表述为一个无状态、连续动作的问题，仅通过使用黑盒反馈探索无限的指令空间。ACING在76%的任务中自动发现了优于人工编写指令的指令，最高提升了33分，在33项任务（包括指令引导、总结和链式推理）中，平均提升了10分以上。", "conclusion": "大量消融实验展示了其鲁棒性和效率。ACING的方法已在GitHub上开源，为黑盒LLM的指令优化提供了一种解决策略。"}
{"llm_update_time": "20250907", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2410.12124", "html_url": "https://arxiv.org/abs/2410.12124", "title": "从10个演示中学习：带有定向知觉框架的可泛化和样本高效策略学习", "title_en": "Learning from 10 Demos: Generalisable and Sample-Efficient Policy Learning with Oriented Affordance Frames", "authors": "Krishan Rana,Jad Abou-Chakra,Sourav Garg,Robert Lee,Ian Reid,Niko Suenderhauf", "background": "模仿学习为人形机器人展示高度灵巧的行为开辟了潜力，但由于长时序、多目标任务的样本效率较低和泛化能力有限，它仍然面临挑战。现有方法需要大量的演示来涵盖可能的任务变体，这使得它们在实际部署中成本高昂且往往不切实际。", "innovation": "该研究通过引入定向知觉框架，提供了一种结构化的状态和动作空间表示，增强了空间和同类别间的泛化能力，并允许仅从10个演示中高效地学习策略。更重要的是，研究展示了这种抽象如何使独立训练的子策略的组合泛化得以实现，以解决长时序、多目标任务。研究还引入了自进步预测的概念，该概念直接源自训练演示的持续时间，从而无缝过渡到不同的子策略。尽管数据集较小，但策略仍能稳健地泛化到未见过的对象外观、几何形状和空间布局，且不依赖于详尽的训练数据，实现了高成功率.", "conclusion": "该方法在三个真实的任务中得到了验证，每个任务都要求多步、多目标交互。尽管数据集很小，但策略仍能稳健地泛化到未见过的对象属性和空间布局，实现高成功率，无需依赖详尽的训练数据。"}
{"llm_update_time": "20250907", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2407.15869", "html_url": "https://arxiv.org/abs/2407.15869", "title": "长输入序列网络用于长时间序列预测", "title_en": "Long Input Sequence Network for Long Time Series Forecasting", "authors": "Chao Ma,Yikai Hou,Xiang Li,Yinggang Sun,Haining Yu", "background": "在长时间序列预测任务中，短固定长度的输入已成为深度学习方法的主要瓶颈。延长输入长度会导致过拟合，预测准确性迅速下降。研究表明，过拟合是时间序列中的多尺度模式耦合与现有模型固定关注尺度之间的复合作用导致的。时间序列在不同尺度上展现的模式反映了其多周期性特征，每个尺度对应特定的周期长度。此外，token大小主要决定了模型的行为，因为它决定了模型关注的尺度范围和能够容纳的上下文大小。现有模型无法有效地拆分多尺度时间序列模式，也无法根据每个模式对应的周期长度来建模。", "innovation": "本研究提出了一个新颖的时间序列分解模块（MPSD）和多token模式识别神经网络（MTPR），旨在解耦长时间序列的多尺度时间模式，并以相应的周期长度为token大小进行建模。这种新的架构能够处理输入序列长度可达10倍的长度。这种新的方法显著提高了性能（最大精度提升38%），同时具有较低的复杂度（成本减少0.22倍）和高度的可解释性。", "conclusion": "通过引入时间序列分解模块（MPSD）和多token模式识别神经网络（MTPR），本研究成功地解耦了多尺度时间序列模式，并通过调整token大小来适应不同的周期长度，显著提高了长时间序列预测的准确性和模型的解释性。"}
{"llm_update_time": "20250907", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2501.13958", "html_url": "https://arxiv.org/abs/2501.13958", "title": "Graph Retrieval-Augmented Generation for Customized Large Language Models", "title_en": "A Survey of Graph Retrieval-Augmented Generation for Customized Large Language Models", "authors": "Qinggang Zhang,Shengyuan Chen,Yuanchen Bei,Zheng Yuan,Huachi Zhou,Zijin Hong,Hao Chen,Yilin Xiao,Chuang Zhou,Yi Chang,Xiao Huang", "background": "大语言模型（LLMs）在多种任务中展现了出色的能力，但在专业领域中的应用仍然具有挑战性，因为需要深厚的专业知识。检索增强生成（RAG）作为一种解决方案，通过无缝集成外部知识库来定制LLMs，使专业领域内的知识在推理过程中得以实时访问。然而，传统的基于扁平文本检索的RAG系统面临三个关键挑战：(i) 在专业上下文中复杂查询的理解问题，(ii) 知识在分布式来源之间的集成困难，(iii) 大规模下的系统效率瓶颈。", "innovation": "GraphRAG通过三种关键创新解决了传统RAG的局限性：(i) 图结构化的知识表示，明确捕捉实体关系和领域层次结构，(ii) 高效的基于图检索技术，能够进行上下文保持的知识检索和多跳推理，(iii) 结构感知的知识融合算法，利用检索到的知识生成准确和逻辑连贯的大语言模型内容。", "conclusion": "本文系统分析了图检索增强生成（GraphRAG）的技术基础，并评估了其在各种专业领域中的当前实现，指出关键技术挑战和有前景的研究方向。所有与GraphRAG相关的资源，包括研究论文、开源数据和项目，都已在此网站上收集。"}
{"llm_update_time": "20250907", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2412.16572", "html_url": "https://arxiv.org/abs/2412.16572", "title": "打破长时序预测中的上下文瓶颈", "title_en": "Breaking the Context Bottleneck on Long Time Series Forecasting", "authors": "Chao Ma,Yikai Hou,Xiang Li,Yinggang Sun,Haining Yu,Zhou Fang,Jiaxing Qu", "background": "长时序预测对于经济、能源和交通领域中的规划和决策至关重要，因为它需要长期的预见能力。现有的模型虽然提高了效率，但处理长时间序列时仍然难以避免过拟合问题。这主要归因于这些模型在面对较长输入时容易产生过拟合，迫使用户使用较短的输入长度以维持可接受的误差范围。针对这一挑战，本研究探讨了多尺度建模方法，并提出了Logsparse Decomposable Multiscaling (LDM)框架以高效而有效地处理长时序数据。LDM通过在时间序列中解耦不同尺度上的模式，减少了非稳定性，通过紧凑的长输入表示提高了效率，并通过提供清晰的任务分工简化了模型架构。实验结果表明，LDM不仅在长时序预测基准测试中优于所有基线模型，还能减少训练时间和内存成本。", "innovation": "本文提出了一种名为Logsparse Decomposable Multiscaling (LDM)的新框架。LDM打破传统模型在处理长时序数据时的瓶颈，其创新点包括：解决过拟合问题，通过解耦不同尺度上的模式减少非稳定性；通过紧凑的长输入表示提高了效率；通过分任务清理模型架构，简化了模型设计。", "conclusion": "LDM框架不仅在长时序预测基准测试中表现优异，还显著减少了训练时间和内存成本，为长时序数据的高效预测提供了新的解决方案。"}
{"llm_update_time": "20250907", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2502.14891", "html_url": "https://arxiv.org/abs/2502.14891", "title": "CoDiff: 条件扩散模型在协作3D物体检测中的应用", "title_en": "CoDiff: Conditional Diffusion Model for Collaborative 3D Object Detection", "authors": "Zhe Huang,Shuo Wang,Yongcai Wang,Lei Wang", "background": "协作3D物体检测在自动驾驶领域具有重要性，通过多代理信息交流提升感知能力。然而，实际中由于姿态估计误差和时间延迟，代理间的特征表示可能存在时空噪声，导致检测错误。扩散模型具备去除噪声的能力，因此利用扩散模型解决多代理系统间的噪声问题是合理的。在本研究中，基于此背景，提出了一种新颖的鲁棒协作感知框架CoDiff。", "innovation": "首次将扩散模型应用于多代理协作感知，并通过预训练的自编码器将高维特征图投影到潜在空间，利用代理个体信息作为条件引导扩散模型采样，逐层去噪并逐步细化融合特征。", "conclusion": "实验结果显示，CoDiff在模拟和真实数据集上的协作物体检测性能均优于现有方法，并且在代理的姿态和延迟信息存在高噪声时表现出高鲁棒性。"}
{"llm_update_time": "20250907", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2502.06289", "html_url": "https://arxiv.org/abs/2502.06289", "title": "基于超大规模自然图像的底层模型是否优于针对视网膜的模型用于检测眼部和全身疾病？", "title_en": "Is an Ultra Large Natural Image-Based Foundation Model Superior to a Retina-Specific Model for Detecting Ocular and Systemic Diseases?", "authors": "Qingshan Hou,Yukun Zhou,Jocelyn Hui Lin Goh,Ke Zou,Samantha Min Er Yew,Sahana Srinivasan,Meng Wang,Thaddaeus Lo,Xiaofeng Lei,Siegfried K. Wagner,Mark A. Chia,Dawei Yang,Hongyang Jiang,An Ran Ran,Rui Santos,Gabor Mark Somfai,Juan Helen Zhou,Haoyu Chen,Qingyu Chen,Carol Y. Cheung,Pearse A. Keane,Yih Chung Tham", "background": "基础模型（FMs）正在改变医疗领域。在眼科，RETFound已被训练用于临床应用，显示出高度的适应性。而DINOv2则具有通用性的视觉基础模型，在非医疗领域显示出潜力，但在临床任务上的应用尚未得到充分探索。", "innovation": "本文通过对比RETFound和三个DINOv2模型（大型、基础、小型）在八个标准化开源眼科数据集以及Moorfields AlzEye和UK Biobank数据集上的表现，以进行头对头评估。研究表明，DINOv2大型模型在识别糖尿病视网膜病变和多类眼病方面表现优于RETFound，而在检测心脏病发作、心肌梗死和缺血性中风方面，RETFound的表现优于所有DINOv2模型。", "conclusion": "这些研究结果表明了通用型基础模型和特定领域基础模型在不同任务中的各自优势，并强调了选择基础模型时需与特定临床需求相匹配以优化临床表现的重要性。"}
{"llm_update_time": "20250907", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2411.03562", "html_url": "https://arxiv.org/abs/2411.03562", "title": "基于科布体验学习的通用代理及人类级Kaggle数据科学性能", "title_en": "Kolb-Based Experiential Learning for Generalist Agents with Human-Level Kaggle Data Science Performance", "authors": "Antoine Grosnit,Alexandre Maraval,Refinath S N,Zichao Zhao,James Dora,Giuseppe Paolo,Albert Thomas,Jonas Gonzalez,Abhineet Kumar,Khyati Khandelwal,Abdelhakim Benechehab,Hamza Cherkaoui,Youssef Attia El-Hili,Kun Shao,Jianye Hao,Jun Yao,Balázs Kégl,Jun Wang", "background": "人类专家通过迭代的交互、反思与内部模型更新体现出复杂学习过程，这符合科布的经验学习理论和维果茨基的最近发展区理论。然而，当前的AI系统如大模型（LLM）依赖于预训练或固定的工作流程，缺乏持续适应的机制。近年来的研究指出，LLM展示出了早期的人类认知特质（反思、修订和自我纠正），表明它们具有形成类似于人类体验学习基础的潜能。因此，设计能够具备类似人类样学习结构和认知基础的LLM成为了一个核心问题。", "innovation": "本文提出了将科布经验学习周期与维果茨基最近发展区理论用于自主代理的计算框架，通过分离外部（环境交互）与内部（内在反思/抽象）功能，实现了认知基础的结构化学习，使代理在结构化环境中学习后能够进入开放领域的泛化。这种机制让代理能够掌握传统微调或简单反思方法无法应对的复杂任务。通过直接对比人类在真实世界Kaggle数据科学竞赛中的表现，展示了其巨大潜力。", "conclusion": "通过学习跨81项任务的自动化数据科学代码生成，代理系统Agent K展示了独立完成整个工作流程的能力，得分为1694的Elo-MMR，超过了研究中Kaggle大师们的中位数得分（Kaggle前2%的用户）。在包括赛事奖牌等级的9金牌、8银牌和12铜牌中，Agent K取得了4金牌和4银牌的好成绩，标志着人工智能系统首次整合了科布和维果茨基的人类认知学习理论，向通用人工智能迈出重要一步。"}
{"llm_update_time": "20250907", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2502.05719", "html_url": "https://arxiv.org/abs/2502.05719", "title": "扩展的直方图基异常得分（EHBOS）", "title_en": "Extended Histogram-based Outlier Score (EHBOS)", "authors": "Tanvir Islam", "background": "Histogram-Based Outlier Score (HBOS) 是一种常用的异常检测方法，以其计算效率和简单性著称。然而，它假设特征独立，这限制了其在特征之间存在相互作用的数据集中的异常检测能力。本研究旨在提出扩展的直方图基异常得分（EHBOS），通过引入二维直方图来捕捉特征对之间的依赖关系，从而提高异常检测的准确性，特别是在特征相互作用对异常结构有决定性影响的数据集中。该研究通过在17个基准数据集上进行实验，展示了EHBOS在多元异常检测场景中的效果和鲁棒性，特别是在那些特征相互作用对异常定义至关重要的数据集中，EHBOS表现出了显著的AUC改进。", "innovation": "EHBOS通过引入二维直方图来捕捉特征对之间的依赖关系，这使得EHBOS能够识别HBOS无法检测到的上下文相关和依赖驱动的异常。在这种方法下，EHBOS在多个数据集上表现出色，特别是在特征相互作用定义异常结构至关重要的数据集中，EHBOS显著提高了ROC AUC。这项研究强调了EHBOS作为HBOS的有价值扩展的潜力，特别是在处理具有上下文或关系异常的数据集时，EHBOS提供了一个强大的新工具。", "conclusion": "EHBOS提供了一个在数据集中处理复杂特征依赖的有效工具，特别是在那些上下文或关系异常起重要作用的数据集中，相较于传统的HBOS，EHBOS在多个数据集上表现出了显著的改进。这项研究的结果表明EHBOS在多元异常检测场景中具有较高的价值和应用前景。"}
{"llm_update_time": "20250907", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2502.18452", "html_url": "https://arxiv.org/abs/2502.18452", "title": "FRIDA to the Rescue! 分析基于对象的常识推理中合成数据效果对于灾害响应而言", "title_en": "FRIDA to the Rescue! Analyzing Synthetic Data Effectiveness in Object-Based Common Sense Reasoning for Disaster Response", "authors": "Mollie Shichman,Claire Bonial,Austin Blodgett,Taylor Hudson,Francis Ferraro,Rachel Rudinger", "background": "在灾难救援场景中的人工机器人交互中，大型语言模型（LLMs）具有潜力，可以进行物理推理以协助执行任务。然而，这些推理能力通常仅存在于较大模型中，这些模型由于体积限制目前难以在机器人系统中部署。为满足问题空间需求，我们提出了一种数据集及管道框架，以构建场域推理与指令解码代理（FRIDA）模型。通过领域专家和语言学家的合作，我们制定了高品质的、小样本的提示，用于生成用于微调的合成数据。我们为这些小样本提示和评估设计并手选数据集，以改善LLM对通用和灾难特异性物体的物理常识推理。我们同时进行了消融研究，以理解哪类合成数据对性能影响最大。在多次微调后，我们发现，仅使用对象物理状态和功能数据训练的FRIDA模型，在评估中表现优于使用所有合成数据和基础模型训练的FRIDA模型。", "innovation": "我们引入了一种新的消融研究方法，以理解合成数据的不同要素对FRIDA模型性能的影响。此外，我们的数据集和提示框架提高了小型模型的物理常识推理能力，展现了FRIDA管道在使用少量数据的情况下赋予物理常识的能力。", "conclusion": "我们发现，仅训练对象物理状态和功能数据的FRIDA模型，在评估中表现出众，优于使用所有合成数据和基础模型训练的FRIDA模型。这表明，FRIDA管道能够通过少量数据培养物理常识。"}
{"llm_update_time": "20250907", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2503.22524", "html_url": "https://arxiv.org/abs/2503.22524", "title": "通过状态级轨迹拼接实现稳健的离线模仿学习", "title_en": "Robust Offline Imitation Learning Through State-level Trajectory Stitching", "authors": "Shuze Wang,Yunpeng Mei,Hongjie Cao,Yetian Yuan,Gang Wang,Jian Sun,Jie Chen", "background": "模仿学习（IL）已被证明可以通过专家演示来使机器人获得视觉运动技能。然而，传统的IL方法依赖于高质量且经常稀缺的专家数据，并且容易受到协变量偏移的影响。", "innovation": "本文提出了一个新颖的方法，通过利用任务相关的轨迹片段和丰富环境动力学来增强来自混合质量离线数据集的策略学习。这种方法引入了一个基于状态的搜索框架，可以将不完美的演示中的状态-动作对拼接起来，从而生成更多样化和更具信息量的训练轨迹。", "conclusion": "实验结果表明，本文提出的方法在标准IL基准测试和实际的机器人任务上显著提高了泛化能力和性能。"}
{"llm_update_time": "20250907", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2503.14048", "html_url": "https://arxiv.org/abs/2503.14048", "title": "超越全息：熵量子引力在图像处理中的基础", "title_en": "Beyond holography: the entropic quantum gravity foundations of image processing", "authors": "Ginestra Bianconi", "background": "近年来，随着人工智能（AI）的发展，科学界越来越关注理论物理与AI之间的联系。传统的连接主要集中在弦理论与图像处理之间的关系上，涉及重要的理论范式如全息理论。近年来，G. Bianconi提出了基于熵的量子引力（GfE）方法，该方法通过洛伦兹时空的两个度量之间的几何量子相对熵来推导引力。", "innovation": "本文展示了著名的Perona-Malik图像处理算法实际上是GfE作用的梯度流。具体来说，该算法是由两个欧几里得度量之间的最小化几何量子相对熵得出的：一个是图像的支持度量，一个是图像引起的度量。由于Perona-Malik算法能够保持锐利的轮廓，这表明GfE作用的一般情况下在梯度流动力学的迭代中不一定导向均匀图像，而是与复杂结构的保持相一致。", "conclusion": "这些结果为Perona-Malik算法提供了几何和信息理论的基础，并可能有助于建立GfE、机器学习和脑科学研究之间的更深层次的联系。"}
{"llm_update_time": "20250907", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2502.10118", "html_url": "https://arxiv.org/abs/2502.10118", "title": "图像嵌入采样方法用于多样的图片描述", "title_en": "Image Embedding Sampling Method for Diverse Captioning", "authors": "Sania Waheed,Na Min An", "background": "最新的视觉语言模型（VLMs）在图像描述方面取得了显著的进展，但这也导致了计算复杂性的增加，使得它们在资源受限的应用中（如移动设备和辅助技术）难以应用。较小的VLMs虽然更容易应用，但是它们倾向于描述宏观场景，而忽视了对丰富理解图像来说重要的细节描述。", "innovation": "本论文提出了一种无需训练的框架，通过采用较小的BLIP模型作为骨干网，利用结构化分割来生成既能体现全局又能体现局部语义的层次表示，从而提高了图像描述的多样性和信息量，无需额外的模型训练即可将较小的VLMs的表现与较大的模型媲美，具体体现在图片描述的一致性、语义完整性和多样性上。该研究还在MSCOCO、Flickr30k和Nocaps测试数据集上进行了评估，取得了令人满意的成绩，尤其是在保持与人工注释描述的相关性和语义完整性方面。", "conclusion": "该方法使较小的VLMs在多项性能指标上达到了与大型模型相当的表现，同时保持了图像描述的相关性和语义完整性。"}
{"llm_update_time": "20250907", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2502.14791", "html_url": "https://arxiv.org/abs/2502.14791", "title": "通过元上下文学习实现快速词汇学习", "title_en": "Rapid Word Learning Through Meta In-Context Learning", "authors": "Wentao Wang,Guangyuan Jiang,Tal Linzen,Brenden M. Lake", "background": "人类能够从少量的实例中快速学习新词，并能系统和灵活地将其应用到新颖语境中。然而，现有语言模型在少样本词汇学习方面的能力及提高这些能力的方法尚待深入探索。因此，研究引入了一种新的方法，Meta-training for IN-context learnNing Of Words (Minnow)，该方法通过使用一种特殊的占位符标记来代表新词，训练语言模型生成给定少量上下文实例的新词用法实例。这种方法通过对许多新词进行重复训练，以培养一般性的词汇学习能力。", "innovation": "该项研究提出了一个新的方法Minnow，相比于现有语言模型，它能够从头开始使用人类规模的孩子定向语言训练，从而实现强少样本词汇学习，这一能力与大量数据预训练的大语言模型（LLM）相当。此外，通过区分性和生成性的评估，研究显示细致调节预训练LLM并使用Minnow能够提高其在新词辨别、识别新词的句法学分类以及基于少量上下文实例生成合理的新词用法和定义上的能力。这些发现突出了Minnow的数据高效性以及它在词语学习任务中提高语言模型性能的潜力", "conclusion": "研究结果表明，从头开始使用Minnow训练得到的模型与大语言模型的少样本词汇学习能力相当，且通过微调预训练的LLM，可以进一步提升其识别新词、确定新词的句法学分类，以及生成合理的新词用法和定义的能力。这些发现说明Minnow在数据效率上的优势及其在提升语言模型在词汇学习任务中的性能方面的潜力。"}
{"llm_update_time": "20250907", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2504.05774", "html_url": "https://arxiv.org/abs/2504.05774", "title": "可转移掩码转换器：基于区域自适应转移性估计的跨域语义分割", "title_en": "Transferable Mask Transformer: Cross-domain Semantic Segmentation with Region-adaptive Transferability Estimation", "authors": "Jianhua Liu,Zhengyu Li,Yanru Wu,Jingge Wang,Yang Tan,Ruizhe Zhao,Guan Wang,Yang Li", "background": "近期，视觉变换器(ViT)在语义分割任务上取得了新突破。然而，在将预训练的ViT适应新型目标域时，由于领域间的分布偏移，整体注意力机制往往会遭受显著性能退化。由于自我注意力机制是数据驱动的，因此在源域和目标域存在纹理、比例或对象共现差异时，往往难以有效关注关键对象。虽然全局和补丁级的领域适应方法提供了一些解决方案，但在不同图像区域具有空间异质性的转移性下，区域级的自适应方法具有更关键的作用。因此，我们提出了一种新的基于区域的适应性体系结构——转化掩码转换器(TMT)，该体系通过空间转移性分析，对跨域表示进行了对齐。", "innovation": "TMT包含两个关键组件：(1) 一个适配的基于集群的转移性估计器（ACTE），该估计器动态地将图像分割成结构和语义上一致的区域，以实现局部转移性评估；(2) 一个转移隐藏的注意模块（TMA），该模块将区域特定的转移性图融入到ViT的注意力机制中，优先在具有较低转移性和高语义不确定性区域进行自适应。综合评估结果显示，TMT在20对跨域数据集上显著优于普通的微调方法，平均提高了2%的MIoU，与最先进的基线相比，提高了1.28%。", "conclusion": "该研究提出的TMT框架通过区域自适应转移性估计，显著提升了跨域语义分割的性能。"}
{"llm_update_time": "20250907", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2412.12722", "html_url": "https://arxiv.org/abs/2412.12722", "title": "通过部分感知监督防御LVLMs的视觉攻击", "title_en": "Defending LVLMs Against Vision Attacks through Partial-Perception Supervision", "authors": "Qi Zhou,Tianlin Li,Qing Guo,Dongxia Wang,Yun Lin,Yang Liu,Jin Song Dong", "background": "近期的研究表明，大型视觉语言模型（LVLMs）对恶意注入或篡改的输入图像非常脆弱，这些篡改会误导模型的响应。现有的防御方法表明，这些视觉攻击对图像修改（尤其是裁剪）高度敏感。常用的防御策略是通过在修改图像的响应之间使用多数投票来获取修正后的响应，但这种修改常常导致图像不完整，并扭曲语义，这会降低非篡改图像上的响应质量。传统的投票方法直接使用不完整图像的响应，而我们的研究则提出了一种使用这些不完整图像的响应来监督LVLM对原始图像的响应的方法。我们提出了一种无需训练的黑盒方法DPS（Defense through Partial-Perception Supervision）。", "innovation": "我们提出了一种无需训练的黑盒方法DPS。该方法利用仅感知部分图像的模型生成的响应来监督LVLM对原始图像的响应。具体来说，当模型受到攻击时，它可以根据部分图像的理解调整其响应，而在干净输入的情况下，模型则确信保持其原始响应。我们的研究表明，弱模型可以监督强模型：面对受攻击输入时，强模型会根据弱模型的部分理解变得不那么自信并调整其响应，从而有效防御攻击。例如，使用该方法后，六个数据集上三种流行的模型的平均攻击成功率降低了76.3%。这种监督方法针对现有防御策略中的不完整图像漏洞提供了一种新的视角，并验证了弱模型可以监督强模型的理论。", "conclusion": "我们的方法通过部署DPS（Defense through Partial-Perception Supervision）增强了LVLMs的防御能力。面对攻击时，模型可以基于部分图像的理解更自信地调整其响应，而对干净输入则保持其原有响应。这种方法在多个场景测试中表现出色，比基线方法显著降低了攻击成功率。我们未来的研究将继续探索这种方法在更多复杂环境下的适用性。"}
{"llm_update_time": "20250907", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2503.09002", "html_url": "https://arxiv.org/abs/2503.09002", "title": "KNighter：使用生成检查器转型静态分析", "title_en": "KNighter: Transforming Static Analysis with LLM-Synthesized Checkers", "authors": "Chenyuan Yang,Zijie Zhao,Zichen Xie,Haoyu Li,Lingming Zhang", "background": "静态分析是用于检测关键系统（如操作系统内核）中错误的强大技术，但设计和实现静态分析器具有挑战性和耗时性，通常仅限于预定义的错误模式。虽然大型语言模型（LLMs）在静态分析方面显示出潜力，但由于计算限制和上下文限制，直接将它们应用于扫描大型系统仍不切实际。KNighter 是首个通过自动从历史错误模式合成静态分析器来解锁可扩展的 LLM 基础静态分析的方法。", "innovation": "KNighter 通过利用 LLMs 生成由历史补丁知识指导的专门静态分析器，而不是直接使用 LLMs 分析大型系统，从而突破了传统障碍。这一方法通过多阶段综合流水线实现，该流水线验证检查器的正确性并采用自动精炼过程逐步减少假正例。通过 Linux 内核的评估，KNighter 生成了高精度的检查器，能够检测现有手动编写的分析器忽略的多种错误模式。至今，KNighter 生成的检查器已经发现了 92 个在 Linux 内核中的新、关键和长时间潜伏的新漏洞（平均每 4.3 年一个）；已确认 77 个，已修复 57 个，并为 30 个分配了 CVE 编号。", "conclusion": "此工作建立了通过检查器合成实现大规模、可靠和可追踪的 LLM 基础静态分析的一种全新范式，为真实世界系统提供了新的解决方案。"}
{"llm_update_time": "20250907", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2505.18102", "html_url": "https://arxiv.org/abs/2505.18102", "title": "如何在不泄露正确答案的情况下发布我的大型语言模型基准？", "title_en": "How Can I Publish My LLM Benchmark Without Giving the True Answers Away?", "authors": "Takashi Ishida,Thanawat Lodkaew,Ikko Yamane", "background": "发布大型语言模型（LLM）基准时面临的风险是，基准可能被无意或有意使用来训练或选择模型。一种常见的应对策略是保持基准的隐私性，让参赛者向组织者提交模型或预测，但这需要对单一组织的信任，并且仍允许通过反复查询进行测试集过拟合。", "innovation": "本文提出了一种方法，可以在不完全披露问题答案的情况下发布基准，但仍能公开评估语言模型。主要创新在于通过准备多个逻辑上的正确答案，将一部分答案作为解决方案包含在基准中，从而降低了基准的最佳可能准确率，即贝叶斯准确率。这种方法有助于保护真实答案不被泄露，同时提供了一种检测数据污染的测试方法。即使完全有能力的模型也不应超过贝叶斯准确率，如果模型超越了这一限制预期，这将是数据污染的一个强烈信号。文章展示了该方法在多种基准、模型和训练方法下的检测数据污染的有效性。", "conclusion": "实验结果表明，本方法能够准确检测多种基准、模型和训练方法下的数据污染。"}
{"llm_update_time": "20250907", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.08570", "html_url": "https://arxiv.org/abs/2506.08570", "title": "自回归 vs 流匹配：文本到音乐生成建模范式对比研究", "title_en": "Auto-Regressive vs Flow-Matching: a Comparative Study of Modeling Paradigms for Text-to-Music Generation", "authors": "Or Tal,Felix Kreuk,Yossi Adi", "background": "文本到音乐生成近期取得了显著进展，模型能够合成高质量的音乐片段、完整作品，甚至响应精细控制信号如和弦进程。最先进的系统在多个维度上存在差异，如训练数据集、建模范式和架构选择等，这些差异增加了公正评估模型和识别哪些设计选择影响性能最大的难度。", "innovation": "本研究仅关注建模范式，通过系统性实证分析区分两种常见的建模范式：自回归解码和条件流匹配，由相同的数据集、训练配置和类似主干架构从零开始训练所有的模型进行控制性对比，评估指标包括生成质量、推理配置稳健性、可扩展性、时间对齐条件的遵从性以及音频补间编辑能力。", "conclusion": "这项对比研究揭示了每种范式的优势和局限性，提供了实际操作性的洞察，可为文本到音乐生成系统未来架构和训练决策提供参考。音频采样示例可在特定链接找到。"}
{"llm_update_time": "20250907", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2505.03522", "html_url": "https://arxiv.org/abs/2505.03522", "title": "单图像超分辨率中模块迁移性的优化：普适性评估与循环残差块", "title_en": "Optimization of Module Transferability in Single Image Super-Resolution: Universality Assessment and Cycle Residual Blocks", "authors": "Haotong Cheng,Zhiqi Zhang,Hao Li,Xinshang Zhang", "background": "深度学习在单图像超分辨率（SISR）领域取得了显著进展，但现有研究主要集中在性能提升上，忽视了对架构组件迁移性的量化评估。", "innovation": "引入了普适性概念及其定义，扩展了传统的一般化概念，以包含模块的迁移性易用性。提出了一种普适性评估方程（UAE），一种量化给定模块易于移植并揭示多个现有度量对迁移性综合影响的指标。设计了两种优化模块：循环残差块（CRB）和深度可分离循环残差块（DCRB），并通过全面实验展示了集成所提插件模块的网络在多项基准和遥感数据集等低级任务中优于多个领先方法，实现了高达0.83 dB的PSNR提升，参数减少71.3%，同时保持重建保真度。", "conclusion": "所提出的方法在标准残差块和其他即插即用模块的UAE结果指导下设计出的优化模块在多种基准和任务中表现出色，为更广泛的基模块提供了优化方法，开辟了即插即用模块设计的新范式。"}
{"llm_update_time": "20250907", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.02025", "html_url": "https://arxiv.org/abs/2506.02025", "title": "LLM-Based 推理在多目标HPC作业调度中的有效性评估", "title_en": "Evaluating the Efficacy of LLM-Based Reasoning for Multiobjective HPC Job Scheduling", "authors": "Prachi Jadhav,Hongwei Jin,Ewa Deelman,Prasanna Balaprakash", "background": "高性能计算（HPC）作业调度需要平衡如最小化工期、减少等待时间、优化资源使用和确保公平等相互冲突的目标。传统方法（如基于启发式的先到先服务（FCFS）和最短作业优先（SJF），或密集优化技术）往往缺乏对动态工作负载的适应性，并且无法同时优化多个HPC系统中的目标。", "innovation": "本文提出了一种基于大型语言模型（LLM）的新颖调度器，利用ReAct风格框架（推理 + 行动），实现迭代和可解释的决策。系统使用工作历史记事本来跟踪调度历史并根据自然语言反馈进行优化，同时一个约束执行模块确保可行性和安全性。在使用OpenAI的O4-Mini和Anthropic的Claude 3.7在七个实际HPC工作负载场景（包括异构组合、突发模式和对抗性案例）中进行评估，对比FCFS，SJF和Google OR-Tools的结果显示LLM调度可以有效平衡多个目标，并通过自然语言痕迹提供透明的推理。然而，推理质量和计算开销之间的权衡限制了实时部署。", "conclusion": "这项工作是关于在HPC环境中利用具有推理能力的LLM进行多目标作业调度的首个全面研究，展示了它们在处理多目标优化方面的潜力，但同时也指出了计算效率方面的局限性。研究结果为通过高级语言模型解决复杂调度问题提供了有价值的见解。"}
{"llm_update_time": "20250907", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.07900", "html_url": "https://arxiv.org/abs/2506.07900", "title": "MiniCPM4：适用于边缘设备的超高效大型语言模型", "title_en": "MiniCPM4: Ultra-Efficient LLMs on End Devices", "authors": "MiniCPM Team:Chaojun Xiao,Yuxuan Li,Xu Han,Yuzhuo Bai,Jie Cai,Haotian Chen,Wentong Chen,Xin Cong,Ganqu Cui,Ning Ding,Shengda Fan,Yewei Fang,Zixuan Fu,Wenyu Guan,Yitong Guan,Junshao Guo,Yufeng Han,Bingxiang He,Yuxiang Huang,Baoxi Ji,Cunliang Kong,Qiuzuo Li,Siyuan Li,Wenhao Li,Xin Li,Yanghao Li,Yishan Li,Zhen Li,Dan Liu,Biyuan Lin,Yankai Lin,Xiang Long,Quanyu Lu,Yaxi Lu,Peiyan Luo,Hongya Lyu,Litu Ou,Yinxu Pan,Lushi Pu,Zekai Qu,Qundong Shi,Zijun Song,Jiayuan Su,Zhou Su,Ao Sun,Xianghui Sun,Peijun Tang,Fangzheng Wang,Feng Wang,Shuo Wang,Yudong Wang,Zheng Wang,Yesai Wu,Zhenyu Xiao,Jie Xie,Zihao Xie,Xiaoyue Xu,Yukun Yan,Jiarui Yuan,Jinqian Zhang,Kaihuo Zhang,Lei Zhang,Linyue Zhang,Xueren Zhang,Yudi Zhang,Hengyu Zhao,Weilin Zhao,Weilun Zhao,Yuanqian Zhao,Zhi Zheng,Chuyue Zhou,Ge Zhou,Jie Zhou,Wei Zhou,Yanghao Zhou,Zihan Zhou,Zixuan Zhou,Zhiyuan Liu,Guoyang Zeng,Chao Jia,Dahai Li,Maosong Sun", "background": "本文介绍了MiniCPM4，这是一种专门设计用于边缘设备的高效大型语言模型（LLM）。通过分阶段的研究与创新，提升模型在模型架构、训练数据、训练算法和推理系统等多个方面的效能。", "innovation": "1. 在模型架构上，提出了InfLLM v2，这是一种可训练的稀疏注意力机制，能够加速预处理和解码阶段长期上下文的处理；\n2. 在训练数据方面，提出了UltraClean和UltraChat v2，分别为高效的预训练数据过滤和生成策略以及全面监督微调数据集；\n3. 在训练算法方面，提出了ModelTunnel v2，用于高效的预训练策略搜索，还通过引入分块式滚动策略和数据高效三元LLM BitCPM实现负载均衡和数据高效性；\n4. 在推理系统方面，提出了集成稀疏注意力、模型量化和推测采样的系统，以实现高效的预处理和解码。", "conclusion": "评估结果表明，MiniCPM4和MiniCPM4.1在各个基准测试中均优于同类开源模型，尤其是8B变体在长序列理解和生成方面展现了显著的速度提升，适用于边缘设备要求的多样化场景。MiniCPM4提供了0.5B和8B两种参数版本，并构建了混合推理模型MiniCPM4.1，可以在深度推理模式和非推理模式下使用。"}
{"llm_update_time": "20250907", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2504.02737", "html_url": "https://arxiv.org/abs/2504.02737", "title": "RBT4DNN：基于需求的神经网络测试", "title_en": "RBT4DNN: Requirements-based Testing of Neural Networks", "authors": "Nusrat Jahan Mozumder,Felipe Toledo,Swaroopa Dola,Matthew B. Dwyer", "background": "测试允许开发人员确定系统是否按预期工作。当这些系统包括深度神经网络时，测试变得具有挑战性，因为DNNs近似出的功能要求的公式化是不可解的。这阻止了应用基于功能需求的成熟测试方法到DNNs中。因此，需要一种新的基于需求的测试方法来解决这一挑战，该方法使用自然语言需求陈述和术语词汇表来定义语义特征空间，从而生成测试输入，进一步将预条件形式化为语义特征的逻辑组合，提出了RBT4DNN方法以满足需求下的测试方法，填补了这一空白。", "innovation": "该论文提出了RBT4DNN方法，这是一种基于需求的针对神经网络的测试方法，使用自然语言需求陈述和术语词汇表构建语义特征空间，为测试输入生成提供支持。RBT4DNN将功能需求的预条件形式化为语义特征的逻辑组合，通过生成匹配特征组合的训练数据来微调生成模型，以可靠地生成满足需求的测试输入。这种方法将测试执行应用于训练好的DNN，以验证其输出是否符合预期的功能需求后置条件以实现有效的故障检测，并提供了两种使用场景：一种是给定定义神经网络正确性的需求，RBT4DNN提供了一种新的故障检测方法；另一种是在开发过程中，以需求为导向的模型行为探索可以为开发者提供关于模型泛化的反馈。", "conclusion": "进一步评估表明，RBT4DNN生成的测试是现实的、多样的，并且与需求预条件对齐，可以实现对模型行为的目标分析和有效的故障检测。"}
{"llm_update_time": "20250907", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.20790", "html_url": "https://arxiv.org/abs/2506.20790", "title": "Stochastic Parameter Decomposition", "title_en": "Stochastic Parameter Decomposition", "authors": "Lucius Bushnaq,Dan Braun,Lee Sharkey", "background": "逆向工程神经网络的关键步骤之一是将它们分解为简单的部分，以便能够在相对隔离的情况下进行研究。线性参数分解作为一种框架，旨在解决当前分解方法中存在的多种问题，它将神经网络参数分解为参数空间中稀疏使用的向量之和。然而，当前该框架中的主要方法，基于归因的参数分解（APD），由于其计算成本高和对超参数的敏感性而不具实用性。", "innovation": "我们提出了Stochastic Parameter Decomposition（SPD），这是一种比APD更具有可扩展性和抗超参数性的方法。通过展示能够在APD难以分解的稍微更大更复杂的模型上进行参数分解，我们证明了SPD的有效性。此外，SPD还避免了其他问题，如学习参数的收缩，并在玩具模型中更好地识别了真实机制。通过将因果中介分析与网络分解方法相结合，SPD消除了对扩展线性参数分解方法到更大模型的障碍，从而为机制可解释性研究开辟了新的可能性。", "conclusion": "我们已经开发出一个运行SPD并重现实验的库，欢迎大家来尝试和使用。该方法通过结合因果中介分析和网络分解方法，为更大规模线性参数分解方法的研究扫清了障碍，进一步推动了机制可解释性的研究。"}
{"llm_update_time": "20250907", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.12964", "html_url": "https://arxiv.org/abs/2507.12964", "title": "针对儿童腕部骨折的细粒度、人口统计学意识分类", "title_en": "Demographic-aware fine-grained classification of pediatric wrist fractures", "authors": "Ammar Ahmed,Ali Shariq Imran,Zenun Kastrati,Sher Muhammad Daudpota", "background": "儿童腕部损伤较为常见，其中儿童占据了骨折病例的大多数。计算机视觉在这一领域前景广阔，但受到大量医疗影像数据集的缺乏限制。单一模态，例如图像，难以应对多种类型的数据。该研究采用综合方法，通过细粒度识别任务、融合病人元数据与X光片、利用来自特定细粒度数据集的预训练权重改进了诊断准确性。", "innovation": "这是首次将元数据整合应用于腕部病理识别。研究利用细粒度的变换器方法、细粒度预训练和元数据整合，分别在小的定制数据集和较大的骨折数据集上取得了2%和10%的诊断准确度提升。", "conclusion": "通过综合方法，该研究提升了腕部骨折的诊断准确性，特别是使用细粒度的变换器方法和预训练权重，结合患者的个人数据，显著减少了单纯的图像分析带来的诊断误差。"}
{"llm_update_time": "20250907", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.15269", "html_url": "https://arxiv.org/abs/2507.15269", "title": "高效率视频压缩的有条件视频生成", "title_en": "Conditional Video Generation for High-Efficiency Video Compression", "authors": "Fangqiu Yi,Jingyu Xu,Jiawei Shao,Chi Zhang,Xuelong Li", "background": "感知研究表明，条件扩散模型在重建与人类视觉感知一致的视频内容方面表现出色。基于此认识，本文提出了一个利用条件扩散模型进行知觉优化重构的视频压缩框架。", "innovation": "本文将视频压缩重新定义为一个条件生成任务，其中生成模型从稀疏但富有信息性的信号中合成视频。该方法引入了三个关键模块：（1）多级条件模块，捕捉静态场景结构和动态的空-时线索；（2）紧凑的表征，用于高效传输而不过度牺牲语义丰富性；（3）多元条件训练，通过不同模态的随机丢弃和角色感知嵌入，防止对单一模态过度依赖并增强鲁棒性。", "conclusion": "广泛的实验表明，本方法在感知质量度量指标（如FVD和LPIPS）上，尤其是在高压缩比下，显著优于传统的和基于神经网络的视频编码器-解码器。"}
{"llm_update_time": "20250907", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.08193", "html_url": "https://arxiv.org/abs/2508.08193", "title": "街边AI：大规模语言模型准备好进行现实生活中的判断了吗？", "title_en": "Street-Level AI: Are Large Language Models Ready for Real-World Judgments?", "authors": "Gaurab Pokharel,Shafkat Farabi,Patrick J. Fowler,Sanmay Das", "background": "近期有许多研究探讨了大型AI模型在作出“道德”决策时的社会伦理和影响，这些模型主要集中在是否与人类决策保持一致或在不同群体间公平性上。实际上，AI最直接的用途很可能是辅助乃至完全替代所谓的街头级行政官僚，这些人员决定如何分配有限的社会资源或批准福利。本文关注的是AI在社会资源分配领域中的应用，特别是无家可归者资源分配中的人工智能优先级与人类判断和现有的社会及政治确定的脆弱性评分系统的契合度。", "innovation": "本文采用真正的需服务数据（同时保持高度的数据保密性）对LLM的决策进行分析，发现LLM在内部运行、不同模型之间以及与现有的脆弱性评分系统之间表现出了极大的不一致性。然而，在一对一的测试中，LLM展示了与普通人类判断质量层面的一致性。这一系列发现质疑了当前AI系统在高风险社会决策中的应用。", "conclusion": "本文的研究结果表明，现有的AI系统在应用于高风险社会决策时还不够成熟，并提出了当前AI系统在社会决策中的应用缺乏一致性的问题。"}
{"llm_update_time": "20250907", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.08715", "html_url": "https://arxiv.org/abs/2508.08715", "title": "MultiGen：低资源语言中的LLMs儿童友好多语言语音生成器", "title_en": "MultiGen: Child-Friendly Multilingual Speech Generator with LLMs", "authors": "Xiaoxue Gao,Huayun Zhang,Nancy F. Chen", "background": "现有的自动生成语音模型在改善人机交互方面表现出巨大的潜力，特别是在儿童的语言学习上。然而，对于低资源语言来说，生成高质量且儿童友好的语音仍然具有挑战性，尤其是在多元文化和低资源语言的背景下。", "innovation": "本文提出了MultiGen，一种基于LLM架构的多语言儿童友好语音生成模型，特别适用于低资源语言。该模型通过结合年龄适宜的多语言语音生成，利用LLM架构，以文化相关的情境帮助低资源语言背景下的年轻儿童与AI系统进行沟通。", "conclusion": "实验结果表明，MultiGen在客观指标和主观评估方面都表现出优于基线方法的性能。"}
{"llm_update_time": "20250907", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.02548", "html_url": "https://arxiv.org/abs/2508.02548", "title": "KG-ER概念模式语言", "title_en": "The KG-ER Conceptual Schema Language", "authors": "Enrico Franconi,Benoît Groz,Jan Hidders,Nina Pardal,Sławek Staworko,Jan Van den Bussche,Piotr Wieczorek", "background": "在知识图谱中，知识图谱的结构描述通常依赖于其表示方式（例如关系数据库、属性图、RDF），这限制了对知识图谱内部信息语义的捕捉能力。本文介绍了一种知识图谱的概念模式语言KG-ER，旨在独立于知识图谱的表示方式来描述知识图谱的结构，同时帮助捕获知识图谱中存储信息的语义。", "innovation": "KG-ER提供了一种新的方法来独立于知识图谱的具体表示形式描述其结构，从而更有效地捕获和表达知识图谱中的语义信息，增强了知识图谱的灵活性和实用性。", "conclusion": "KG-ER作为一种新的概念模式语言，独立于知识图谱的具体表示形式，可以更有效地描述和捕获知识图谱的结构和语义。这种创新的方法为知识图谱的研究和发展提供了新的视角和工具。"}
{"llm_update_time": "20250907", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.13755", "html_url": "https://arxiv.org/abs/2508.13755", "title": "RLVR的深度-广度协同作用：通过适应性探索解锁大语言模型推理增益", "title_en": "Depth-Breadth Synergy in RLVR: Unlocking LLM Reasoning Gains with Adaptive Exploration", "authors": "Zhicheng Yang,Zhijiang Guo,Yinya Huang,Yongxin Wang,Dongchun Xie,Yiwei Wang,Xiaodan Liang,Jing Tang", "background": "Reinforcement Learning with Verifiable Reward (RLVR) 已成为增强大语言模型推理能力的强大范式。然而，其潜力受到两个未充分探索维度的阻碍：Depth（模型最难处理的问题）和 Breadth（每次迭代消耗的实例数量）。GRPO 算法存在系统性偏差，表现为累积优势过度重视中等准确率样本，同时削弱对推动推理边界至关重要的低准确率实例的权重。", "innovation": "本文提出了 Difficulty Adaptive Rollout Sampling (DARS)，这是一种通过多阶段针对困难问题的重新采样方法来重新加权困难问题，从而增加困难问题的积极采样数量。此外，提出了 DARS-B，结合了 DARS 和大规模广度训练，展示了 Pass@K 和 Pass@1 的同时增益。研究表明，深度和广度的适应性探索在 RLVR 中是独立的维度，对于解锁 RLVR 的推理能力至关重要。", "conclusion": "大规模广度训练维护了高 token 级别熵，表明持续的探索并减少了梯度噪声。深度-广度协同作用和适应性探索对于 RLVR 可以解锁大语言模型推理能力是关键因素。"}
{"llm_update_time": "20250907", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.22627", "html_url": "https://arxiv.org/abs/2507.22627", "title": "LOTS of Fashion! Multi-Conditioning for Image Generation via Sketch-Text Pairing", "title_en": "LOTS of Fashion! Multi-Conditioning for Image Generation via Sketch-Text Pairing", "authors": "Federico Girella,Davide Talon,Ziyue Liu,Zanxi Ruan,Yiming Wang,Marco Cristani", "background": "服装设计是融合视觉和文本表达的复杂创造性过程，设计师通过草图和文字描述来传达设计理念。传统的设计方法主要依赖于手工草图和描述，但这种过程效率较低且难以重复使用。为了提高设计效率和创新性，该研究提出了一种基于局部化文本和草图的综合方法LOcalized Text and Sketch for fashion image generation（LOTS），该方法能够生成完整的时尚lookout图像。LOTS方法利用全局描述和配对的局部化草图+文本信息进行条件处理，并引入了一种新颖的逐步合并策略来适应扩散过程。为了验证方法的有效性，研究人员基于Fashionpedia数据集构建了Sketchy数据集，该数据集提供每个图像多个文本-草图配对对。", "innovation": "LOTS方法通过引入局部化草图+文本配对信息作为条件处理，提出了模块化的配对中心表示法，并在扩散模型的多步去噪过程中采用基于注意力的指导策略来集成局部和全局条件。这种方法显著提高了基于草图和文本的图像生成性能，特别是在全球和局部度量方面达到了最先进的水平。", "conclusion": "通过在Fashionpedia上构建Sketchy数据集，LOTS方法取得了显著的成果，其生成的图像在视觉效果和设计细节方面都有显著的优势。定量结果显示，LOTS在全局和局部度量方面都达到了最先进的水平。定性样本和人类评估研究进一步证明了其在设计定制方面的独特能力。LOTS方法为基于草图和文本的传统设计流程带来了新的可能性。"}
{"llm_update_time": "20250907", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.18464", "html_url": "https://arxiv.org/abs/2508.18464", "title": "量子变换器中的可学习编码向量化注意", "title_en": "Vectorized Attention with Learnable Encoding for Quantum Transformer", "authors": "Ziqing Guo,Ziwen Pan,Alex Khan,Jan Balewski", "background": "现有量子变换器依赖于深度参数化量子电路，这使得它们容易受到量子处理单元（QPU）噪声的影响，从而阻碍其实用性能。量子向量编码提供了一种方式，将经典数据嵌入希尔伯特空间，为量子模型提供途径，如量子变换器（QT），用量子电路模拟取代经典自注意力以更高效地运行。", "innovation": "本文提出了一种向量化量子变换器（VQT）模型，通过量子近似模拟支持理想的掩蔽注意矩阵计算，通过向量化非线性量子编码高效训练，提供了一种节流且无梯度的量子电路模拟（QCS）方法，降低了经典采样的开销。此外，展示了在IBM和IonQ的量子电路模拟准确性比较，并在IBM最新的高保真Kingston QPU上实现了自然语言处理任务的基准测试竞争结果。", "conclusion": "噪声适应性强、间规模量子友好的VQT方法解锁了适用于端到端机器学习的新型架构，在量子计算中具有重要意义。"}
{"llm_update_time": "20250907", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.14723", "html_url": "https://arxiv.org/abs/2508.14723", "title": "移植再生：一种新的文本数据增强范式", "title_en": "Transplant Then Regenerate: A New Paradigm for Text Data Augmentation", "authors": "Guangzhan Wang,Hongyu Zhang,Beijun Shen,Xiaodong Gu", "background": "数据增强是深度学习中的一项关键技术。传统方法如反向翻译主要关注词汇层面的重写，导致生成的内容在语义上变化不大。虽然大型语言模型（LLMs）通过“知识涌现”能力增强了文本增强的效果，但在控制这些输出的风格和结构方面仍然存在挑战，需要精细的提示工程。", "innovation": "本文提出了一种新的文本增强范式LMTransplant，其核心思想是将种子文本移植到由LLM扩展的上下文中，然后要求LLM基于扩展后的上下文生成变体。这种方法可以让模型充分利用嵌入在LLMs中的知识，生成更加多样化和创意性的内容级别的变体，同时保留原始文本的核心属性。经评估，LMTransplant 在多种文本相关任务中展现出优于现有文本增强方法的性能，并且具有出色的可扩展性，随着增强数据量的增长表现更加出色。", "conclusion": "LMTransplant 作为一种新的文本数据增强范式，通过将种子文本移植到LLM扩展的上下文中，然后再生新的变体，展示了优于现有方法的性能和出色的可扩展性。"}
{"llm_update_time": "20250907", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.14904", "html_url": "https://arxiv.org/abs/2507.14904", "title": "TriCLIP-3D: 基于CLIP的统一高效三模态3D视觉定位框架", "title_en": "TriCLIP-3D: A Unified Parameter-Efficient Framework for Tri-Modal 3D Visual Grounding based on CLIP", "authors": "Fan Li,Zanyi Wang,Zeyi Huang,Guang Dai,Jingdong Wang,Mengmeng Wang", "background": "3D视觉定位允许可嵌入代理基于人类指令理解真实世界3D环境中的视觉信息，这对嵌入式智能至关重要。现有3D视觉定位方法通常依赖于不同的模态（如RGB图像、文本和3D点云）的独立编码器，导致模型庞大且复杂，训练效率低下。尽管一些方法使用预训练的2D多模态模型（如CLIP）来处理3D任务，但它们仍然难以将点云数据与2D编码器对齐。因此，这些方法继续依赖3D编码器进行特征提取，进一步增加了模型的复杂性和训练效率。", "innovation": "本文提出了一种基于2D预训练多模态网络的统一3D视觉定位框架，可以同时处理RGB图像、文本和点云三种模态，简化了架构。通过利用2D CLIP双模态模型并结合基于适配器的调优，该框架有效地适应了三模态设置，提高了跨模态性能和适应性。我们还设计了几何感知的2D-3D特征恢复和融合模块（GARF），该模块用于融合点云和图像的几何多尺度特征。此外，我们引入了多模态解码器以促进深层跨模态理解。这种方法在三个模态的统一特征提取和融合方面实现了端到端的3D视觉定位。相比基线方法，该方法减少了约58%的可训练参数，同时在3D检测任务中提高了6.52%的性能，在3D视觉定位任务中提高了6.25%的性能。", "conclusion": "本文通过提出统一的2D预训练多模态网络，简化了3D视觉定位架构，并通过有效的特征融合和适应性改进，实现了在3D视觉定位任务中的高性能，降低了模型的复杂性和训练成本。"}
{"llm_update_time": "20250907", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.08524", "html_url": "https://arxiv.org/abs/2508.08524", "title": "StreetViewAI: 使用上下文感知多模态AI使街道视角可访问", "title_en": "StreetViewAI: Making Street View Accessible Using Context-Aware Multimodal AI", "authors": "Jon E. Froehlich,Alexander Fiannaca,Nimer Jaber,Victor Tsaran,Shaun Kane", "background": "现有的互动街道视角工具如Google街景和Meta Mapillary，尽管可以提供沉浸式的360°图像供用户虚拟导航和体验现实环境，但这些工具对盲用户来说仍然缺乏可访问性。目前市场上尚无其他工具能满足盲用户的需求，使其能够虚拟检查目的地、进行开放世界的探索或虚拟游览遍布全球超过2200亿张图像的地区。因此，开发一个专为盲人用户设计的可访问街道视角工具显得尤为重要和必要。此背景下需求迫切，研究者认为有必要创造一种新工具解决这一问题。", "innovation": "StreetViewAI是世界上首个专为盲人用户设计的可访问街道视角工具。它结合了上下文意识的多模态AI、易于盲人使用的导航控制以及交互式的声控功能。该工具使得盲人用户能够虚拟地检查目的地、进行开放世界的探索或虚拟游览全球范围内的任何一个地区的成千上万图像。这一创新性的工具是现有技术的一个重要补充，极大地提升了盲人用户的生活质量。", "conclusion": "经过多次迭代设计并基于一个多感官能力团队的反馈，StreetViewAI通过实验证明了其在支持POI（兴趣点）调查和远程路线规划方面的价值。研究者还从此次研究中提取出了未来工作的关键指南。该研究强调了联合设计的重要性，并指出未来工作的方向可以为多个研究团队提供有价值的参考，以便更好地为盲人用户提供支持。"}
{"llm_update_time": "20250907", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.20117", "html_url": "https://arxiv.org/abs/2508.20117", "title": "人工智能正在重塑地球科学国际学术社区的格局吗？", "title_en": "Is Artificial Intelligence Reshaping the Landscape of the International Academic Community of Geosciences?", "authors": "Liang Li,Yuntian Li,Wenxin Zhao,Shan Ye,Yun Lu", "background": "研究通过文献计量分析和主题建模发现，人工智能（AI）正在积极改变地球科学的研究，近年来在AI相关科学产出方面有显著增加。此外，发展中国家的地球科学家在AI for Science (AI4S) 架构中获得了更好的可见性，AI还改善了地球科学相关研究中的国际合作局面。", "innovation": "该研究利用文献计量分析和主题建模的方法，揭示了AI对地球科学发展的影响，特别强调了发展中国家地球科学家在AI4S领域中的参与增加以及国际合作的改善。", "conclusion": "研究得出结论，人工智能正在积极改造地球科学研究领域，尤其是在增加科学产出、提高发展中国家科学家的国际可见性以及促进国际合作方面起到了重要作用。"}
{"llm_update_time": "20250907", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.00167", "html_url": "https://arxiv.org/abs/2509.00167", "title": "高等教育课堂中生成式人工智能与批判性思维的试点研究", "title_en": "Pilot Study on Generative AI and Critical Thinking in Higher Education Classrooms", "authors": "W. F. Lamberti,S. R. Lawrence,D. White,S. Kim,S. Abdullah", "background": "近年来，生成式人工智能（GAI）工具在教育领域的应用迅速增加，但其在促进批判性思维方面的作用尚待深入探讨。尽管已有研究将GAI用作特定课程的导师或用于完成作业的工具，但很少有研究关注学生如何评估GAI生成答案的准确性和适宜性。", "innovation": "本研究通过设计一系列需要学生分析、批评和修改AI生成解决方案的学习活动，探索学生在初级计算和数据分析课程中应用结构化批判性思维评估GAI输出的能力。鉴于GAI工具常常产生上下文错误或事实错误的答案，本研究填补了这一领域的空白。", "conclusion": "研究结果为学生如何批判性地与GAI内容互动提供了初步洞察，并为未来的全面研究奠定了基础。"}
{"llm_update_time": "20250907", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.20293", "html_url": "https://arxiv.org/abs/2508.20293", "title": "Beacon：结合网格选择的后训练量化", "title_en": "Beacon: Post-Training Quantization with Integrated Grid Selection", "authors": "Shihao Zhang,Rayan Saab", "background": "量化是一种广泛使用的压缩技术，用于降低大型预训练模型的记忆和计算成本。后训练量化（PTQ）中的一个关键挑战是在每个通道中选择合适的缩放因子以将权重值替换为比例整数网格中的值。现有的方法通常通过启发式调优或网格搜索在初期固定缩放因子。", "innovation": "我们提出了 Beacon，一个简单而有效的算法，它消除了手动调优的需要。Beacon 直接在未缩放的网格上进行每个通道的 PTQ，并通过利用标量量化几何学自动确定最优缩放因子。它不依赖于反向传播或大规模的校准集。尽管其简单且无需调优，但 Beacon 达到了最先进的方法的竞争力，成为高效模型部署的实用解决方案。", "conclusion": "因此，Beacon 提供了一种简单且高效的后训练量化方法，无需调优，可实现与最先进的方法相当的性能，适合实际的模型部署。"}
{"llm_update_time": "20250907", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.00616", "html_url": "https://arxiv.org/abs/2509.00616", "title": "TimeCopilot", "title_en": "TimeCopilot", "authors": "Azul Garza,Reneé Rosillo", "background": "文章介绍了一种名为TimeCopilot的新框架，它是一个开源的代理预测框架，结合了多种时间序列基础模型（TSFMs）和大型语言模型（LLMs），通过统一的API进行集成。TimeCopilot自动化了预测流程，包括特征分析、模型选择、交叉验证和预测生成，同时提供了自然语言解释并支持直接查询未来结果。该框架具有LLM无关性，兼容商业和开源模型，并支持来自不同预测家族的集成。", "innovation": "TimeCopilot是第一个集合了多个时间序列基础模型和大型语言模型的开源代理预测框架，通过单个统一的API实现。该框架自动化了预测流程的多个步骤，并提供了自然语言解释，增强了预测的可解释性。此外，该框架支持多种模型的集成，能够在多个预测家族中提供集成解决方案。实验证明，TimeCopilot在大规模的GIFT-Eval基准测试中实现了低成本的最佳概率预测性能。", "conclusion": "TimeCopilot为可重现、可解释和易访问的代理预测系统提供了一个实际的基础。该框架克服了传统预测方法的局限性，提供了更高效、更易于理解的预测解决方案，特别适用于需要高度可解释性和交互性的应用场景。"}
{"llm_update_time": "20250907", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.02349", "html_url": "https://arxiv.org/abs/2509.02349", "title": "AudioCodecBench: 一种全面的音码评价基准", "title_en": "AudioCodecBench: A Comprehensive Benchmark for Audio Codec Evaluation", "authors": "Lu Wang,Hao Chen,Siyu Wu,Zhiyue Wu,Hao Zhou,Chengfeng Zhang,Ting Wang,Haodi Zhang", "background": "近年来，多模态大语言模型（MLLMs）在语音和音乐处理中的广泛应用促使研究重点转向音频分词。与仅依赖语义的文本令牌不同，音频令牌不仅要捕捉全局语义内容，还需要保留细腻的声学细节。现有的研究在定义语义令牌和声学令牌方面存在问题，且不同编解码器的评估通常集中在特定领域或任务上，如重建或自动语音识别（ASR），这导致了不公正和不全面的比较。", "innovation": "本文提出了适合的语义令牌和声学令牌定义，并引入了一种系统性评价框架，该框架从四个维度评估编解码器的能力：音频重建指标、码本索引（ID）稳定性、仅解码变压器困惑度和下游探针任务的表现。这种评价框架有利于全面评估编解码器的综合能力。", "conclusion": "实验结果证明了所提供的定义正确性，并显示了重建指标、码本ID稳定性、下游任务表现与困惑度之间的相关性。"}
{"llm_update_time": "20250907", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.01185", "html_url": "https://arxiv.org/abs/2509.01185", "title": "语言模型训练和评估中合成长上下文数据生成的模块化技术", "title_en": "Modular Techniques for Synthetic Long-Context Data Generation in Language Model Training and Evaluation", "authors": "Seganrasan Subramanian,Abhigya Verma", "background": "大型语言模型（LLMs）处理和推理长文本的能力对于多种实际应用至关重要，但其进展受限于缺乏适合培训和评估的高质量、多样性和可验证的长上下文数据集。", "innovation": "本文提出了一种模块化、可扩展的框架，用于通过LLMs的提示互动生成合成长上下文数据。该框架支持多种训练和对齐目标，包括监督微调（SFT）、直接偏好优化（DPO）和组相对策略优化（GRPO）。它包括四种核心生成范式：多轮对话、基于文档的输入输出对、可验证的指令响应任务和长上下文推理示例。通过模板化提示、模型无关的架构和元数据增强的输出，该方法实现了一种可扩展、可控和目标导向的数据集创建方式，以推进LLMs的长上下文能力。", "conclusion": "该框架为合成长上下文数据的生成提供了模块化策略，支持多种训练目标，并且能够生成既可验证又符合特定应用需求的数据集。这为提升LLMs处理长文本的能力提供了新的途径。"}
{"llm_update_time": "20250907", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.03249", "html_url": "https://arxiv.org/abs/2509.03249", "title": "结构转移：一种基于推理的表示变换算子", "title_en": "Structure Transfer: an Inference-Based Calculus for the Transformation of Representations", "authors": "Daniel Raggi,Gem Stapleton,Mateja Jamnik,Aaron Stockdill,Grecia Garcia Garcia,Peter C-H. Cheng", "background": "表示选择对于我们有效沟通和推理至关重要。一个尚未解决的重大问题是开发一种代表系统（RS）无偏的方法来推动表示变换和选择。", "innovation": "提出了一个名为结构转移的新算法，它在不同RS间允许表示变换。通过利用编码RS知识的模式（schemas），结构转移确保源表示和生成的目标表示满足任何指定的关联（如语义等价）。这一体系是基于表示系统理论（Representational Systems Theory），利用构造空间（construction space）的关键概念来实现。", "conclusion": "结构转移是一种系统无偏的算法，能够在多种实际场景中识别替代表示。构造空间的抽象特性为各种类型的RS提供了建模的通用性，包括形式语言、几何图形及其图纸，以及非正式符号。"}
{"llm_update_time": "20250907", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.02175", "html_url": "https://arxiv.org/abs/2509.02175", "title": "理解空间是火箭科学——只有顶级推理模型能解决空间理解任务", "title_en": "Understanding Space Is Rocket Science -- Only Top Reasoning Models Can Solve Spatial Understanding Tasks", "authors": "Nils Hoehing,Mayug Maniparambil,Ellen Rushe,Noel E. O'Connor,Anthony Ventresque", "background": "该研究背景在于当前视觉语言模型（VLM）在空间关系理解方面存在局限性，尤其是在实际应用场景中理解和处理物体之间的空间关系仍然存在挑战。目前市面上的开源和前沿商业VLM在这一领域表现不佳，研究者希望通过建立新的基准来评估模型的空间理解能力，并探索其局限性。", "innovation": "研究提出了名为RocketScience的开源对比VLM基准，专门测试空间关系的理解能力。该基准由全新的真实图像-文本配对组成，主要涉及物体间的相对空间理解及物体顺序。与现有基准不同，RocketScience旨在让人类容易理解和完成，而对当前VLM构成巨大挑战。研究采用消融分析进一步分离物体定位和空间推理在链式推理模型中的贡献度，发现模型在基准测试中的表现受限于空间推理而非物体定位能力。", "conclusion": "研究结果表明，当前开源和前沿商业VLM在空间理解能力上有显著不足，而推理模型的表现却超出预期。研究者通过公开与RocketScience相关的数据集和评估代码，旨在推进这一领域的研究和发展。"}
{"llm_update_time": "20250907", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.00215", "html_url": "https://arxiv.org/abs/2509.00215", "title": "通过解耦反向传播的一阶模型导向RL", "title_en": "First Order Model-Based RL through Decoupled Backpropagation", "authors": "Joseph Amigo,Rooholla Khorrambakht,Elliot Chane-Sane,Nicolas Mansard,Ludovic Righetti", "background": "近年来，人们越来越关注利用模拟器的导数来改进强化学习(RL)方法的效率的研究。虽然早期基于梯度的方法已经显示出比无导数方法更好的性能，但获取模拟器的梯度由于实现成本或不可用性往往不切实际。模型导向的_rl(MBRL)可以通过学习的动力学模型来近似这些梯度，但在训练采样过程中，预测误差会积累，导致策略性能下降。因此，需要一种方法将轨迹生成与梯度计算解耦：通过一个学习的可微模拟器模型使用反向传播来计算梯度，同时用模拟器展开轨迹。这种混合设计能够在不可用模拟器梯度的情况下实现高效且一致的一阶策略优化，同时还能从模拟轨迹中学习更准确的批评家。", "innovation": "提出了一种解耦轨迹生成和梯度计算的方法。具体来说，通过一个模拟器展开轨迹，而梯度则是通过学习模拟器的可微模型来进行反向传播计算。这种方法在不可用模拟器梯度的情况下实现了高效且一致的一阶策略优化，并且能够从仿真采样中学习更准确的批评家。同时，该方法结合了专用优化器的能力和标准方法的普适性，同时避免了其他一阶MBRL方法中观察到的不良行为。", "conclusion": "该方法在基准控制任务上的实验证明了其效果，并成功应用于真实的Go2四足机器人，展示了其在四足和双足移动任务中的有效性。"}
{"llm_update_time": "20250907", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.01153", "html_url": "https://arxiv.org/abs/2509.01153", "title": "EZhouNet:基于图神经网络和锚定区间框架的呼吸音事件检测", "title_en": "EZhouNet:A framework based on graph neural network and anchor interval for the respiratory sound event detection", "authors": "Yun Chu,Qiuhao Wang,Enze Zhou,Qian Liu,Gang Zheng", "background": "呼吸音检查是早期诊断呼吸和肺部疾病的关键方法，依赖于熟练的医疗专业人员。然而，这一过程往往是主观的，不同专家之间存在差异。因此，出现了许多基于深度学习的自动分类方法，大多数都集中在呼吸音分类上。相比之下，关于呼吸音事件检测的研究仍然不足。现有的声事件检测方法通常基于帧级预测，然后进行后处理以生成事件级输出，这使得直接学习时间间隔边界变得困难。此外，许多方法只能处理固定长度的音频，限制了它们在处理变长呼吸音方面的能力。此外，呼吸音位置的信息对检测性能的影响尚未得到广泛探索。", "innovation": "本文提出了一个基于图神经网络和锚定区间框架的呼吸音事件检测方法（EZhouNet），能够处理变长音频并提供更精确的时序定位。该方法增强了呼吸音检测的灵活性和适用性。实验表明，该方法在SPRSound 2024和HF Lung V1数据集上有效，加入呼吸音位置信息可以提高异常声音的区分度。", "conclusion": "该框架提高了呼吸音检测在时间和长度上的灵活性，实验结果验证了该方法的有效性，并证明了呼吸音位置信息的重要性。"}
{"llm_update_time": "20250907", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.02591", "html_url": "https://arxiv.org/abs/2509.02591", "title": "MIDOG 2025 Track 2的病理基础模型集成用于异常有丝分裂分类", "title_en": "Ensemble of Pathology Foundation Models for MIDOG 2025 Track 2: Atypical Mitosis Classification", "authors": "Mieko Ochi,Bae Yuan", "background": "有丝分裂形态学变化分为典型和异常变体，异常变体的数量与肿瘤侵略性密切相关。准确区分非常重要，但即使是专家病理学家也面临挑战。当前的工作通过利用病理基础模型（PFMs）并结合参数高效微调和最先进的ConvNeXt V2架构来应对这一挑战。在此过程中，还使用了一种鱼眼变换来强调有丝分裂，并应用了傅里叶域适应以提高模型效果。通过集成多个PFMs，取得了竞争力的平衡准确性。", "innovation": "本研究利用了预训练在大规模病理学数据集上的病理基础模型，并通过低秩适应进行参数高效的微调。还结合了最先进的ConvNeXt V2架构。使用鱼眼变换和傅里叶域适应来优化模型训练。最后，通过集成多个PFMs来增强模型的综合性能。", "conclusion": "本研究通过集成多个预训练的病理基础模型，并结合先进的神经网络架构和图像增强技术，实现了有丝分裂分类任务中的竞争力表现，在Preliminary Evaluation Phase数据集上的平衡准确性较高。"}
{"llm_update_time": "20250907", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.00813", "html_url": "https://arxiv.org/abs/2509.00813", "title": "AImoclips: 一种评估文本生成音乐中情感传达的基准", "title_en": "AImoclips: A Benchmark for Evaluating Emotion Conveyance in Text-to-Music Generation", "authors": "Gyehun Go,Satbyul Han,Ahyeon Choi,Eunjin Choi,Juhan Nam,Jeong Mi Park", "background": "近年来，文本转音乐（TTM）生成技术使得通过自然语言提示进行可控和表达性强的音乐创作成为可能。然而，TTM系统的情感准确性与人类偏好或文本对齐相比，仍然未被充分探索。这项研究旨在评估TTM系统传达预期情感至人类听众的能力，通过比较开源和商用模型，挑选了12种情感意图覆盖情感-唤醒空间中的四个象限，使用六种最先进的TTM系统生成超过1,000个音乐片段。共邀请了111名参与者使用9级李克特量表评价每段音乐片断的情感倾向和唤醒程度。研究结果显示，商用系统生成的音乐往往被感知为比预期更令人愉悦，而开源系统则表现出相反情况。所有模型在高唤醒条件下更准确地传达情感。此外，所有系统都对情感中立性表现出偏好，凸显出情感可控性的关键限制。这一基准提供了模型特定情感渲染特性的宝贵见解，并支持未来开发情感对齐的TTM系统的进展", "innovation": "该研究引入了AImoclips基准，专注于评估TTM系统传达预期情感的能力。通过实验和参与者评价，该研究取得了几个创新点：1) 评估了12种情感意图的传达，包括四个情感-唤醒象限中的不同情感；2) 比较了开源和商用TTM系统的性能；3) 揭示了商用系统倾向于生成更令人愉悦的音乐片段，而开源系统则表现相反；4) 发现了在高唤醒条件下情感传达更为准确；5) 强调了所有模型都对情感中立性表现出偏好，这揭示了情感可控性的关键限制点。这些发现为未来TTM系统的改进提供了新的见解和发展方向", "conclusion": "研究结果表明，在高唤醒条件下，所有模型都能更准确地传达情感。此外，所有系统的偏向性情感中立性是其中一个重要的局限。该基准为未来情感对齐的TTM系统的发展提供了有价值的信息和指导。"}
{"llm_update_time": "20250907", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.01221", "html_url": "https://arxiv.org/abs/2509.01221", "title": "DaMoC: 基于数据和模型压缩高效选择用于细调领域任务的最佳大语言模型", "title_en": "DaMoC: Efficiently Selecting the Optimal Large Language Model for Fine-tuning Domain Tasks Based on Data and Model Compression", "authors": "Wei Huang,Huang Wei,Yinggui Wang", "background": "大语言模型在通用任务上表现出色，但在特定领域任务上却存在困难，需要通过特定数据进行微调。由于有许多开源的大语言模型可供选择，因此，在任务指定后选择最佳模型变得具有挑战性。本研究旨在解决如何快速确定最佳大语言模型的问题。", "innovation": "本研究提出了一种数据和模型压缩框架（DaMoC），在数据层面：通过系统地将数据过滤方法分类为三大类（分布感知方法、质量感知方法以及同时考虑两者的混合方法），并进一步提高文本中关键词汇的密度实现文本压缩，使用大语言模型迭代地重写文本以优化其表达。在模型层面：利用层相似性评分评估每层的重要性并移除低重要层，引入稀疏合并方法以最大限度地保留原始模型的性能。实验结果表明该方法能在节省约20倍训练时间的情况下选择出最佳大语言模型。", "conclusion": "通过提出DaMoC框架，本研究解决了大语言模型微调最佳选择的挑战，通过数据和模型的压缩方法显著提高了微调效率，同时保持了模型性能。"}
{"llm_update_time": "20250907", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2509.03525", "html_url": "https://arxiv.org/abs/2509.03525", "title": "基于言语的认知筛查：大规模语言模型适应策略的系统评估", "title_en": "Speech-Based Cognitive Screening: A Systematic Evaluation of LLM Adaptation Strategies", "authors": "Fatemeh Taherinezhad,Mohamad Javad Momeni Nezhad,Sepehr Karimi,Sina Rashidi,Ali Zolnour,Maryam Dadkhah,Yasaman Haghbin,Hossein AzadMaleki,Maryam Zolnoori", "background": "超过一半的美国成人阿尔茨海默病及相关认知障碍患者没有得到确诊，言语基线筛查可提供一种可扩展的检测方法。论文评估了使用DementiaBank语音语料库的大型语言模型(DLLM)的不同适应策略来识别认知障碍。", "innovation": "研究比较了多项大型语言模型（包括文本模型和多模态音频-文本模型）以及不同的适应策略，如上下文学习、推理增强提示、参数高效微调和模态融合。结果显示，上下文中心示例表现最优，推理可提升小型模型性能，标记级微调通常得分最高，添加分类头显著改善了性能较差的模型。尽管多模态模型中的微调音频-文本系统表现良好，但未超越最佳文本模型。", "conclusion": "这些发现表明，模型适应策略（包括示例选择、推理设计和调整方法）对言语基线的认知障碍检测至关重要，而且适当地调整的公开权重模型可以匹配甚至超越商业系统。"}
{"llm_update_time": "20250907", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2509.03527", "html_url": "https://arxiv.org/abs/2509.03527", "title": "使用RAG方法与fine-tuned Mistral大语言模型进行多层级加密货币新闻分析", "title_en": "Multilevel Analysis of Cryptocurrency News using RAG Approach with Fine-Tuned Mistral Large Language Model", "authors": "Bohdan M. Pavlyshenko", "background": "在本研究中，我们采用微调后的Mistral 7B大语言模型进行加密货币新闻的多层级多任务分析，该模型通过检索增强生成（RAG）技术进行微调。我们首先生成包含情感得分的图形和文本摘要，并提供JSON格式的摘要表示。接下来的层级中，微调的模型进行层次化的堆叠分析，将基于图形和基于文本的摘要以及摘要的摘要整合成全面的报告。这种图形和文本摘要的结合提供了加密货币新闻的互补视图。采用PEFT/LoRA方法进行4位量化微调。将加密货币新闻表示为知识图示可彻底消除大型语言模型幻觉的问题。", "innovation": "创新在于使用微调后的Mistral 7B大语言模型结合检索增强生成（RAG）技术，进行多层级加密货币新闻分析。这种多层级的方法整合了基于图形和基于文本的摘要，以及摘要的摘要，以提供加密货币新闻的全面报告。通过4位量化PEFT/LoRA方法进行微调，解决了大语言模型幻觉的问题。", "conclusion": "研究结果表明，使用微调后的Mistral 7B大语言模型进行加密货币新闻的多层级分析可以进行有信息量的定性和定量分析，提供重要的洞察。知识图式的表示方法有效地解决了模型的幻觉问题，增强了分析的质量和准确性。"}
{"llm_update_time": "20250907", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2509.03529", "html_url": "https://arxiv.org/abs/2509.03529", "title": "基于AI的多模态提案以提高信息互评工具", "title_en": "Multimodal Proposal for an AI-Based Tool to Increase Cross-Assessment of Messages", "authors": "Alejandro Álvarez Castro,Joaquín Ordieres-Meré", "background": "收益电话会议提供了一种独特的富信息和半结构化的财务交流来源，结合了总经理的规范性阐述和分析师的非规范性对话。尽管最近在情感分析方面的进展已经整合了多模态信号，例如文本内容和音调信号，大多数系统依然依赖于平面文件或句子级别的模型，未能捕捉这些互动的多层次话语结构。", "innovation": "本文提出了一种新颖的多模态框架，旨在生成收益电话会议的丰富语义和结构意识嵌入。该框架将电话会议编码为层次对话树。每个节点，由独白或问答对组成，都通过从文本、音频和视频中提取情感信号以及共现分数、主题标签和答案覆盖率评估等结构化元数据进行丰富。一个两阶段的变换器架构被提出：第一阶段使用对比性学习在节点级别编码多模态内容和话语元数据，第二阶段生成整个会议的综合嵌入。", "conclusion": "实验结果表明，生成的嵌入形成稳定且具有语义意义的表示，反映了情感语调、结构逻辑和主题一致性。除了财务报告领域之外，该系统在医疗诚信、教育和政治辩论等高风险无脚本沟通领域也具有广泛的应用价值，提供了多模态话语表示的稳健可解释方法。该方法为下游任务如财务预测和话语评估提供了实用用途，同时也提供了一种适用于涉及高风险交流的其他领域的一般化方法。"}
{"llm_update_time": "20250907", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2509.03531", "html_url": "https://arxiv.org/abs/2509.03531", "title": "长格式生成中实时检测虚幻实体", "title_en": "Real-Time Detection of Hallucinated Entities in Long-Form Generation", "authors": "Oscar Obeso,Andy Arditi,Javier Ferrando,Joshua Freeman,Cameron Holmes,Neel Nanda", "background": "大型语言模型现在已在高风险应用中常规使用，如医疗咨询或法律建议，而虚幻信息可能造成严重伤害。现有虚幻检测方法在实际应用中存在局限性或成本高昂的问题，传统方法要么仅适用于短事实查询，要么需要昂贵的外部验证。本研究旨在提出一种经济且可扩展的方法，用于实时识别长格式生成中的虚幻标记（例如，虚构的名字、日期、引用等），并有效扩展至70亿参数模型中。", "innovation": "该研究提出了一种经济高效的实时虚幻实体检测方法，专注于实体级别的虚幻信息而非声明级别，使得检测可以逐个标记进行，并能进行流式检测。为此，研究开发了一种新的注释方法，利用网络搜索为模型响应添加实证标签，指出哪些标记代表虚构建实体。这种方法能够有效训练简洁高效的虚幻分类器（例如，使用线性探针），并且在各类模型上进行的实验结果优于基线方法，包括更昂贵的方法如语义熵（例如，对于Llama-3.3-70B，AUC为0.90对比0.71）。通过仅使用实体级别的标签进行训练，模型还能够识别数学推理任务中的错误答案，表明其具有实体之外的泛化能力。", "conclusion": "我们发现，通过公开共享数据集的方法，从一个模型的注释响应可以训练出适用于其他模型的分类器。总体而言，我们的工作为大规模、实际应用的虚幻检测提供了一种有潜力的新方法。"}
{"llm_update_time": "20250907", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2509.03528", "html_url": "https://arxiv.org/abs/2509.03528", "title": "ProLiFIC数据集：利用大语言模型揭示意大利立法过程", "title_en": "The ProLiFIC dataset: Leveraging LLMs to Unveil the Italian Lawmaking Process", "authors": "Matilde Contestabile,Chiara Ferrara,Alberto Giovannetti,Giovanni Parrillo,Andrea Vandin", "background": "过程挖掘（PM）最初在工业和商业领域发展起来，近年来已在社会系统中得到应用，包括法律领域。然而，PM在法律领域的应用受到数据集的可访问性和质量的限制。为了弥补这些限制，该研究提出了ProLiFIC（Procedural Lawmaking Flow in Italian Chambers），这是一个涵盖从1987年至2022年意大利立法过程的全面事件日志。ProLiFIC通过整理从Normattiva门户获取的非结构化数据并使用大型语言模型（LLMs）构建而成，旨在促进使用PM进行法律分析的新发展。", "innovation": "该研究通过将过程挖掘与大型语言模型（LLMs）相结合，创建了一个全面的意大利立法过程事件日志ProLiFIC，填补了法律领域数据集的不足，提供了一个用于法律过程挖掘的基准数据集。", "conclusion": "ProLiFIC作为法律过程挖掘的基准资源，为研究者和决策者提供了丰富的信息，促进了法律过程分析的新发展。"}
{"llm_update_time": "20250907", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2509.03526", "html_url": "https://arxiv.org/abs/2509.03526", "title": "通过强化行为对齐提升语音大型语言模型", "title_en": "Enhancing Speech Large Language Models through Reinforced Behavior Alignment", "authors": "Yansong Liu,Jiateng Li,Yuan Liu", "background": "近年来，大型语言模型（LLMs）的进展引发了对扩展其语言能力的研究兴趣，从文本扩展到其他模态，如语音。这导致了具备语音处理能力的语音LLMs（SpeechLMs）的出现，能够以语音或文本格式处理用户请求。然而，由于跨模态差异，这些SpeechLMs在指令跟随方面仍与基于文本的LLMs存在显著差距，尤其是在应对用户语音的动态和多样性时更为明显。为了应对这一挑战，本文提出了一种被称为强化行为对齐（RBA）的框架来增强SpeechLMs的语言生成能力。", "innovation": "RBA框架采用了一种自我合成的方法，通过强大的教师LLM生成大量高质量的对齐数据，而不是依赖人类注释的监督微调。然后，使SpeechLMs的行为与教师的行为进行强化学习对齐。实验结果表明，该方法有效提升了SpeechLMs的指令跟随能力，并优于传统的蒸馏基线。此外，证明RBA可以无缝扩展到包括语音问答和语音转文字翻译等任务中，仅使用自生数据就能达到现有基准的最佳性能。", "conclusion": "该研究提出了一种新的RBA框架，显著提高了 SpeechLMs 的指令跟随能力，并通过自生数据达到了最先进的性能。这种方法可以应用于多种语音处理任务，展示了其潜在的应用价值。"}
{"llm_update_time": "20250907", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2509.03533", "html_url": "https://arxiv.org/abs/2509.03533", "title": "通过信息瓶颈视角识别大型语言模型输入-输出对中的主题", "title_en": "Topic Identification in LLM Input-Output Pairs through the Lens of Information Bottleneck", "authors": "Igor Halperin", "background": "大型语言模型（LLMs）容易出现关键性的失败模式，如内在忠实度幻觉（也称为编造），指模型生成的回答与提供的背景信息在语义上出现偏差。为检测这种幻觉，现有的框架依赖于识别提示和响应之间的潜在主题，通常通过将句子嵌入进行几何聚类。然而，这种方法可能失去下游信息论分析所需的结构，因为聚类是基于空间接近度而不是信息相关性。因此，研究者寻求通过一种基于确定性信息瓶颈（DIB）的理论和方法来弥合这一差距。", "innovation": "作者提出了一种新的主题识别方法，将确定性信息瓶颈（DIB）方法转化为适合高维数据的实用算法，通过用计算效率高的近似替代难以计算的KL散度项。由此产生的方法（我们称之为UDIB），可以被解释为一种熵正则化和增强化的K-means聚类，能够自动生成更精简且具信息价值的主题聚类。当应用UDIB方法对大型语言模型的提示和响应嵌入进行联合聚类时，可以获得一个与提示-响应关系高度相关且结构化的共享主题表示。这种表示为语义偏差检测提供了更好的基础，并提供了一个更敏感的工具。", "conclusion": "通过UDIB方法生成的共享主题表示在结构上是最优的信息描述方式，能显著提升Large Language Models中检测伪幻觉的效果，并为后续的SDM框架提供了更坚实的基础。"}
{"llm_update_time": "20250907", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2509.03535", "html_url": "https://arxiv.org/abs/2509.03535", "title": "QuesGenie：智能多模态问题生成", "title_en": "QuesGenie: Intelligent Multimodal Question Generation", "authors": "Ahmed Mubarak,Amna Ahmed,Amira Nasser,Aya Mohamed,Fares El-Sadek,Mohammed Ahmed,Ahmed Salah,Youssef Sobhy", "background": "在信息丰富的时代，学习者能够访问大量的教育资源，但缺乏针对这些资源的定制化练习材料成为了一个明显的问题。本文档提出了一种多模态问题生成系统，该系统能够自动从不同内容格式中生成多样化的问题类型，以解决这一问题。系统主要由多模态输入处理、问题生成、基于人类反馈的强化学习（RLHF）以及完整的交互界面四大组件组成。", "innovation": "本文档介绍了一种能够自动化、可扩展且智能化地生成问题的多模态问题生成系统。该系统特别注重资源效率、稳健的实用性，并提供流畅的用户体验。通过与人类反馈相结合的强化学习（RLHF），系统能够不断优化其生成能力。", "conclusion": "本文档为自动化、可扩展和智能的问题生成奠定了基础，通过平衡资源效率、稳健的功能性和用户体验，为学习者提供了多样化的练习材料。"}
{"llm_update_time": "20250907", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2509.03530", "html_url": "https://arxiv.org/abs/2509.03530", "title": "解读社交媒体文本中的隐含迹象：预测青少年未来自杀意念", "title_en": "Reading Between the Signs: Predicting Future Suicidal Ideation from Adolescent Social Media Texts", "authors": "Paul Blum,Enrico Liscio,Ruixuan Zhang,Caroline Figueroa,Pradeep K. Murukannaiah", "background": "青少年（12-18岁）自杀是导致死亡的主要原因之一，但这一问题的预测仍然颇具挑战性。由于缺乏与心理健康服务的接触，许多病例未能被提前发现。然而，社交媒体提供了一个独特的机会，因为年轻人经常在在线平台上实时分享他们的思想和挣扎。本文提出了一项新的任务和方法，旨在在青少年未明确表达自杀意念之前，通过论坛帖子预测自杀意念和行为（SIB）。现有自杀预测文献中，这种预测框架尚未得到广泛探索，其中未使用任何自我披露作为输入数据。在这一研究中，我们介绍了一种基于Transformer的模型Early-SIB，它通过顺序处理用户所写的和参与的帖子来预测未来SIB的发生。该模型在荷兰青少年论坛上实现了0.73的平衡准确率，表明这种工具可以为传统的预防措施提供实质性的补充。", "innovation": "论文提出了一种新的任务和方法，通过论坛帖子预测青少年未来的自杀意念和行为。这种方法的独特之处在于，它采用了预测框架，而在任何阶段都不使用自我披露的数据作为输入。此外，引入了基于Transformer的Early-SIB模型，用于分析和预测青少年用户的自杀风险。这是在自杀预测领域中的一种全新探索，填补了空白。", "conclusion": "基于提出的Early-SIB模型，该研究在荷兰青少年论坛上实现了0.73的平衡准确率，表明利用社交媒体数据预测青少年自杀意念具有可行性，并有望为传统的预防措施提供补充。"}
{"llm_update_time": "20250907", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2509.03540", "html_url": "https://arxiv.org/abs/2509.03540", "title": "通过推理时知识图谱构建提高LLMs的可靠性", "title_en": "Improving Factuality in LLMs via Inference-Time Knowledge Graph Construction", "authors": "Shanglin Wu,Lihui Liu,Jinho D. Choi,Kai Shu", "background": "大型语言模型（LLMs）在生成事实一致的答案时经常遇到困难，这是因为其参数记忆的限制。检索增强生成（RAG）方法通过在推理时结合外部可信赖来源的知识来解决这一问题。然而，这类方法通常将知识视为无结构的文本，限制了它们的支持组合性推理和发现事实不一致的能力。", "innovation": "本文提出了一种新颖框架，该框架在推理过程中动态构建和扩展知识图谱（KGs），结合LLMs内部提取的知识和从外部源检索的信息。该方法通过提示从问题中提取种子KG，然后通过LLMs的潜在知识进行迭代扩展，最后通过外部检索进行有选择性的细化，增强事实覆盖率并纠正不准确之处。", "conclusion": "本文的方法在三个不同的事实问答基准上进行了评估，表明与基础提示和静态KG增强方法相比，在事实准确性、答案精确性和可解释性方面均有所改进。研究结果表明，在结构化、可解释和可扩展的方式中提高LLMs的可靠性具有前景。"}
{"llm_update_time": "20250907", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2509.03725", "html_url": "https://arxiv.org/abs/2509.03725", "title": "MLSD：一种增强跨目标和跨领域立场检测的新颖少样本学习方法", "title_en": "MLSD: A Novel Few-Shot Learning Approach to Enhance Cross-Target and Cross-Domain Stance Detection", "authors": "Parush Gera,Tempestt Neal", "background": "研究领域目前存在一种新的挑战：如何在不同领域和目标之间进行立场检测。现有的方法在跨域和跨目标立场检测方面表现不佳，尤其是在样本有限的情况下。本文旨在提出一种新的方法来解决这一问题。", "innovation": "本文提出了一种基于度量学习的少样本学习方法（MLSD），用于跨目标和跨领域的立场检测。该方法通过三元组损失学习度量空间，捕捉不同立场目标之间的语义相似性和差异性，从而提高域适应性能。MLSD通过构建区分性嵌入空间，使跨目标或跨域立场检测模型能够从新的目标领域中获取有用的示例。", "conclusion": "我们在两个数据集中的多个跨目标和跨领域场景下评估了MLSD，结果显示MLSD在六种广泛使用的立场检测模型中的立场检测性能显著提高。"}
{"llm_update_time": "20250907", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2509.03537", "html_url": "https://arxiv.org/abs/2509.03537", "title": "AR$^2$: 对大型语言模型进行抽象推理的对抗强化学习", "title_en": "AR$^2$: Adversarial Reinforcement Learning for Abstract Reasoning in Large Language Models", "authors": "Cheng-Kai Yeh,Hsing-Wang Lee,Chung-Hung Kuo,Hen-Hsen Huang", "background": "抽象能力是从复杂问题陈述中识别和提炼基本计算模式的能力，在计算机科学中是一项基础技能，对人类问题解决者和编码导向的语言模型（LLMs）至关重要。尽管在使用强化学习（RL）训练LLMs进行代码生成方面取得了进展，但大多数现有方法主要专注于表层模式识别，忽略了明确训练抽象能力。现有研究表明，强化学习在提升LLMs抽象能力方面存在局限，而深入的抽象训练对于增强LLMs的泛化能力至关重要，但目前尚缺乏有效的解决方案。", "innovation": "本文提出了一种新颖的框架AR$^2$（Adversarial Reinforcement Learning for Abstract Reasoning），明确设计用于提升LLMs的抽象能力。AR$^2$通过教师模型将核心问题转化为富有叙述性的挑战性描述，同时学生代码模型被训练以解决这些复杂的叙述性问题，从中提取其基本的计算内核。实验证明，AR$^2$大幅提高了学生模型在未见过的、具有挑战性的编程任务上的准确率，表明了抽象能力是对LLMs泛化能力提升的关键技能。", "conclusion": "研究结果表明，AR$^2$框架在强化学习环境下显著提升了大型语言模型的抽象推理能力，这对于提高LLMs在未见过任务上的泛化性能具有重要意义。这一创新为LLMs从表层模式识别迈向深层次抽象训练提供了可能。"}
{"llm_update_time": "20250907", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2509.03610", "html_url": "https://arxiv.org/abs/2509.03610", "title": "NoteBar：一种辅助个人知识管理的AI辅助笔记系统", "title_en": "NoteBar: An AI-Assisted Note-Taking System for Personal Knowledge Management", "authors": "Josh Wisoff,Yao Tang,Zhengyu Fang,Jordan Guzman,YuTang Wang,Alex Yu", "background": "笔记是学术和职业环境中获取、组织和反思信息的关键实践。大型语言模型的成功应用促进了AI辅助工具的开发，但现有解决方案在效率方面常常不尽如人意。NoteBar是一种利用人物信息和高效语言模型，自动将笔记分类并更好地支持用户工作流程的AI辅助笔记工具。", "innovation": "NoteBar利用了人物信息和高效的语言模型，实现了自动化根据多种类别整理笔记，更好地支持用户的工作流。此外，它还提供了一个包含3,173个笔记和8,494个标注概念的新型人物条件化数据集，覆盖了16种MBTI人格类型，为下游任务提供了多样性和语义丰富性。NoteBar还可以在实际操作中以经济的方式部署，无需依赖沉重的基础设施环境。", "conclusion": "结合NoteBar及其配套数据集，为推进AI辅助个人知识管理提供了可扩展且可扩展的基石。"}
{"llm_update_time": "20250907", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2509.03565", "html_url": "https://arxiv.org/abs/2509.03565", "title": "ResearchPulse: 通过多文档科学推理构建方法-实验链条", "title_en": "ResearchPulse: Building Method-Experiment Chains through Multi-Document Scientific Inference", "authors": "Qi Chen,Jingxuan Wei,Zhuoya Yao,Haiguang Wang,Gaowei Wu,Bihui Yu,Siyuan Li,Cheng Tan", "background": "理解科学思想的发展需要超越简单地总结单个论文，而需要在主题相关研究之间进行结构化的跨文档推理。这项研究旨在通过多文档科学推理任务来提取和对齐相关论文中的动机、方法和实验结果，以重建研究发展链条。此任务引入了时间对齐不精细的方法和标准化异构实验表格等关键挑战。", "innovation": "提出了一种基于代理的框架——ResearchPulse。它由三个协调的代理组成：计划代理负责任务分解，Mmap代理构建动机-方法思维导图，Lchart代理汇总实验折线图。还引入了ResearchPulse-Bench，这是一个带有引用意识的标注论文集群基准。实验结果表明，尽管使用了包含7B的代理系统，但在语义对齐、结构一致性、视觉准确度等方面始终优于GPT-4o等强大基线系统。", "conclusion": "研究通过提出ResearchPulse框架和ResearchPulse-Bench基准，展示了强大的系统能力，能够有效完成多文档科学推理任务，促进科学研究的深度理解和发展。"}
{"llm_update_time": "20250907", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2509.03791", "html_url": "https://arxiv.org/abs/2509.03791", "title": "SiLVERScore: Semantically-Aware Embeddings for Sign Language Generation Evaluation", "title_en": "SiLVERScore: Semantically-Aware Embeddings for Sign Language Generation Evaluation", "authors": "Saki Imai,Mert İnan,Anthony Sicilia,Malihe Alikhani", "background": "现有的手语生成评估通常通过反向翻译进行，即生成的手语先被识别回文本，再与参考文本比较，采用基于文本的指标。然而，这种两步评估流程引入了模糊性：不仅未能捕捉手语的多模态特性（如面部表情、空间语法和语调），而且难以定位评估错误是由于生成模型还是评估系统。", "innovation": "本文提出了一种新的、基于语义的嵌入评估度量SiLVERScore，用于在一个联合嵌入空间中评估手语生成。贡献包括：（1）识别现有指标的局限性；（2）引入SiLVERScore进行基于语义的评估；（3）证明其对语义和语调变化的鲁棒性；（4）探索跨数据集的泛化挑战。在PHOENIX-14T和CSL-Daily数据集上，SiLVERScore在正确与随机对之间的区分（ROC AUC = 0.99，重叠 < 7%）上表现出色，远优于传统的评估指标。", "conclusion": "SiLVERScore在正确和随机手语生成对的区分中表现近乎完美（ROC AUC = 0.99，重叠 < 7%），显著优于传统指标，证明了其在手语生成评估中的有效性。"}
{"llm_update_time": "20250907", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2509.03615", "html_url": "https://arxiv.org/abs/2509.03615", "title": "E-ARMOR: 边缘场景评估与多语言光学字符识别审查", "title_en": "E-ARMOR: Edge case Assessment and Review of Multilingual Optical Character Recognition", "authors": "Aryan Gupta,Anupam Purwar", "background": "光学字符识别（OCR）在多语言、嘈杂和多样化的现实生活图像中仍然是一大挑战。面对这种情况，大型视觉-语言模型（LVLMs）因其强大的泛化能力和超出固定OCR管道的推理能力而受到广泛关注。本文探讨了在资源受限边缘环境中部署OCR系统的方法并进行了大规模对比测试。", "innovation": "提出了Sprinklr-Edge-OCR，一种专门为边缘部署优化的新OCR系统，并对五种基于LVLMs的先进OCR模型（InternVL, Qwen, GOT OCR, LLaMA, MiniCPM）以及两种传统OCR系统（Sprinklr-Edge-OCR, SuryaOCR）进行了大规模对比测试。使用了由54种语言构成的手标注数据集，测试范围广泛，包括准确率、语义一致性、语种覆盖、计算效率及部署成本。特别地，文中采用CPU仅环境下的边缘情况部署分析来更好地反映实际应用情况。结果表明，Qwen具有最高的精确度，而Sprinklr-Edge-OCR的整体F1分数最高，展现出在效率方面相对于LVLMs的显著优势。", "conclusion": "我们的研究结果表明，在新时期即便面对大模型的挑战，传统的OCR系统在边缘部署时仍是最优选择，因为它们具有极低的算力要求、极低的延迟及极高的经济性。"}
{"llm_update_time": "20250907", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2509.03662", "html_url": "https://arxiv.org/abs/2509.03662", "title": "使用MIMIC-IV数据库分析SNOMED CT概念共现的语义分析", "title_en": "Semantic Analysis of SNOMED CT Concept Co-occurrences in Clinical Documentation using MIMIC-IV", "authors": "Ali Noori,Somya Mohanty,Prashanti Manda", "background": "临床笔记包含丰富的临床叙述，但由于其未结构化的格式，大规模分析面临挑战。标准化术语如SNOMED CT提高了互操作性，但如何通过共现和语义相似性理解概念之间的关系尚未充分探索。这项研究利用MIMIC-IV数据库，探究SNOMED CT概念共现模式与基于嵌入的语义相似性之间的关系。使用归一化点互信息(NPMI)和预训练嵌入（如ClinicalBERT、BioBERT），研究共现频繁的概念是否在语义上接近，嵌入是否可以建议缺失的概念，以及这些关系如何随时间发展并在不同专科领域中变化。研究表明，虽然共现和语义相似性相关性较弱，但嵌入捕捉到的实际临床相关性并不总能反映在记录频率中。嵌入基于的建议经常与后来记录的概念匹配，支持其在增强临床注释方面的作用。概念嵌入的聚类产生了一系列临床主题（症状、实验室检查、诊断、心血管疾病）等，这些与患者表型和护理模式有关。最后，与结果（如死亡率和再次住院）相关的共现模式证明了该方法的实际价值。", "innovation": "这项研究创新性地利用MIMIC-IV数据库，结合SNOMED CT概念的共现模式与基于嵌入的语义相似性进行分析，旨在发现和验证临床笔记中缺失的概念。研究揭示嵌入捕捉到的临床相关性往往不在记录频率中表现出来，嵌入可以在增强临床注释方面发挥作用。嵌入聚类能够揭示有意义的临床主题，并有助于临床决策支持和表型分析。", "conclusion": "研究结果表明，共现统计和嵌入语义在提高记录完整性、发现潜在临床关系方面具有互补的价值，并可用于指导决策支持和表型应用。"}
{"llm_update_time": "20250907", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2509.03647", "html_url": "https://arxiv.org/abs/2509.03647", "title": "打破镜像：基于激活的LLM评估者自我偏好缓解方法", "title_en": "Breaking the Mirror: Activation-Based Mitigation of Self-Preference in LLM Evaluators", "authors": "Dani Roytburg,Matthew Bozoukov,Matthew Nguyen,Jou Barzdukas,Simon Fu,Narmeen Oozeer", "background": "大型语言模型（LLMs）越来越多地作为自动评估者使用，但由于‘自我偏好偏差’，它们倾向于更喜欢自己的输出而非其他模型的输出，这削弱了评估管道中的公平性和可靠性，特别是在偏好调整和模型路由等任务中。研究者调查了轻量级引导向量是否可以在推理时解决这一问题，而无需重新训练模型。他们通过一个精选的数据集区分了自我偏好偏差的合理案例和不合理案例，并提出了对比激活添加（CAA）和优化导向两种方法来构建引导向量。结果显示，引导向量可以减少高达97%的不合理自我偏好偏差，显著优于提示和直接偏好优化的基准方法，但它们对合理自我偏好和无偏共识不稳定，暗示自我偏好分布在多个或非线性方向上。这一结果揭示了它们作为LLM作为评判者的潜在价值和局限性，并激励了更 robust 的干预措施。", "innovation": "研究者提出了两种基于激活的方法（对比激活添加（CAA）和优化导向方法）来构建轻量级引导向量以缓解LLM评估者的自我偏好偏差问题，并通过实验证明了这类方法的有效性，特别是它们能显著减少不合理自我偏好偏差，且效果优于现有的提示和直接偏好优化方法。同时，该研究强调，自我偏好分布在多维或非线性方向上，这揭示了自我偏好缓解方法的潜在价值和局限性。", "conclusion": "引导向量可以有效减少LLM评估者的不合理自我偏好偏差，但其对合理自我偏好和无偏共识不稳定，表明自我偏好分布在多维或非线性方向上。这既凸显了引导向量作为LLM评价的潜在价值，也揭示了其局限性，并且强调了需要更稳健的干预措施来解决这一问题。"}
{"llm_update_time": "20250907", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2509.03888", "html_url": "https://arxiv.org/abs/2509.03888", "title": "假象的安全性：为什么基于探测的恶意输入检测无法泛化", "title_en": "False Sense of Security: Why Probing-based Malicious Input Detection Fails to Generalize", "authors": "Cheng Wang,Zeming Wei,Qin Liu,Muhao Chen", "background": "大语言模型（LLMs）尽管功能强大，但仍可能遵循有害指令，引起安全问题。最近的研究利用探测方法研究LLMs内部表示中恶意和良性输入的可分离性，并提出了使用这些探测方法进行安全检测的建议。", "innovation": "研究者们通过系统地重新审视这一范式，发现基于探测的方法可能只学到表面模式而不是语义上的有害性。通过控制实验确认了这一假设，并指出了具体的模式：指令模式和触发词。此外，研究提出了从简单的n-gram方法开始，到使用语义清洗的dataset进行控制实验，再到详细分析模式依赖性的系统方法。", "conclusion": "当前的探测方法存在着虚假的安全感，需要重新设计模型和评估协议。研究者通过进一步讨论，希望提出负责任的后续研究方向。开放了项目源代码。"}
{"llm_update_time": "20250907", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2509.03871", "html_url": "https://arxiv.org/abs/2509.03871", "title": "大型语言模型推理的可信性综述", "title_en": "A Comprehensive Survey on Trustworthiness in Reasoning with Large Language Models", "authors": "Yanbo Wang,Yongcan Yu,Jian Liang,Ran He", "background": "长链思维推理的进展提升了语言模型在多种任务中的表现，包括语言理解、复杂问题解决和代码生成。这种范式能够让模型生成中间推理步骤，提高了准确性和可解释性。然而，尽管取得了这些进展，关于基于链条思维推理如何影响语言模型可信度的全面理解仍然不足。", "innovation": "本文综述了推理模型和链条思维推理（CoT）相关工作的最新进展，系统地探讨了可信推理的五个核心维度：真实性、安全性、鲁棒性、公平性和隐私。通过按时间顺序详细分析每一方面的研究，展示了方法论、发现和局限性。还提出了未来的研究方向。", "conclusion": "推理技术通过减少幻觉、识别有害内容和提高鲁棒性等途径有望增强模型的可信性。然而，最先进的推理模型在安全性和鲁棒性方面经常遭受相似或更大的脆弱性。通过综合这些见解，本文期望成为AI安全社区的宝贵资源，帮助他们了解推理可信性领域的最新进展。"}
{"llm_update_time": "20250907", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2509.03829", "html_url": "https://arxiv.org/abs/2509.03829", "title": "NE-PADD: 利用命名实体知识通过注意力聚合实现稳健的局部语音伪造检测", "title_en": "NE-PADD: Leveraging Named Entity Knowledge for Robust Partial Audio Deepfake Detection via Attention Aggregation", "authors": "Huhong Xian,Rui Liu,Berrak Sisman,Haizhou Li", "background": "传统的句子级音频深度伪造检测（ADD）侧重于整个句子的检测，而局部音频深度伪造检测（PADD）则需要在帧级定位伪造语音的具体位置。尽管在PADD领域取得了一定进展，但利用音频中的语义信息，尤其是命名实体信息，仍旧是一个被忽视的方面。本研究旨在通过引入一种新颖的方法——NE-PADD，即利用命名实体知识的局部语音深度伪造检测方法，来弥补这一空白。", "innovation": "NE-PADD通过两个并行分支实现：语音命名实体识别（SpeechNER）和PADD，并引入了两种注意力聚合机制：注意力融合（AF）和注意力转移（AT），利用辅助损失引导PADD与命名实体语义的结合。该方法基于PartialSpoof-NER数据集进行了实验，结果显示该方法优于现有基线，证明了在PADD中集成命名实体知识的有效性。", "conclusion": "本研究提出了一种结合命名实体知识的新颖方法NE-PADD，通过两者的注意力聚合机制，显著提高了局部语音深度伪造检测的性能。实验结果表明，这种整合方法比现有基线方法更有效。"}
{"llm_update_time": "20250907", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2509.03805", "html_url": "https://arxiv.org/abs/2509.03805", "title": "测量VLMs如何而非仅仅是是否建立共同基础", "title_en": "Measuring How (Not Just Whether) VLMs Build Common Ground", "authors": "Saki Imai,Mert İnan,Anthony Sicilia,Malihe Alikhani", "background": "当前的大规模视觉语言模型（VLMs）越来越多地被赋予了推理能力，但现有的基准测试主要在单轮或问答设置下进行评估。然而，地基化是通过持续沟通逐渐发展共享理解的互动过程。现有的评估方法没有充分考虑到这种互动性。为了填补这一空白，作者引入了一个包含四个指标（地基效率、内容一致性、词汇适应性和相似性）的评估套件，以系统地评估VLM在互动地基情境中的表现。该实验使用三个私有的VLMs进行了150轮互动参照游戏自玩对话，与人类双人组进行比较。研究发现，所有三个模型在至少三个指标上与人类模式存在差异，而GPT4o-mini的整体表现最接近人类。研究认为任务成功率并不能表明地基化的成功，高度图像-陈述匹配也不一定能预测任务成功。研究修正了现有评估方法，提供了未来VLM地基化研究的框架和方法论基础。", "innovation": "该研究引入了一个包含四个指标的评估套件，以系统地评估VLM在互动地基情境中的表现，不同于现有的主要评估方法，这个新的评估方法更加全面地考虑了地基化的互动性。该研究提供了未来VLM地基化研究的框架和方法论基础。", "conclusion": "地基效率、内容一致性、词汇适应性和人类相似性这四个指标有助于系统地评估VLM在互动地基情境中的表现。任务成功率并不能表明地基化的成功，高图像-陈述匹配也不一定能预测任务成功。研究发现，现有的评估方法和指标不足以全面地评价VLMs在建立共享理解方面的表现，应进一步探索新的评估框架。"}
{"llm_update_time": "20250907", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2509.03932", "html_url": "https://arxiv.org/abs/2509.03932", "title": "韩语现代诗歌中的情感语言编码：来自标注数据和AI建模的洞察", "title_en": "Decoding the Poetic Language of Emotion in Korean Modern Poetry: Insights from a Human-Labeled Dataset and AI Modeling", "authors": "Iro Lim,Haein Ji,Byungjun Kim", "background": "尽管在基于文本的情感分类方面取得了显著进展，但诗歌尤其是韩语诗歌由于其比喻语言和文化特点，仍然未被充分探索。因此，现有的情感分析在处理诗歌情感方面表现不足。", "innovation": "本文引入了KPoEM（韩语诗歌情感映射）数据集，这是专门为现代韩语诗歌中的情感分析建立的一个新型数据集。通过使用先进的韩语语言模型进行微调，KPoEM模型在情感分类任务上的性能显著优于之前的模型，尤其是在保持现代韩语诗歌的核心情感方面。", "conclusion": "研究结合了计算方法和文学分析，通过结构化的数据探索了韩国文学中情感表达的定量分析，这些数据忠实保留了韩语文学的情感和文化内涵，为未来的情感分析提供了新的可能性。"}
{"llm_update_time": "20250907", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2509.03918", "html_url": "https://arxiv.org/abs/2509.03918", "title": "MTQA：增强复杂问题回答中推理的矩阵思维", "title_en": "MTQA:Matrix of Thought for Enhanced Reasoning in Complex Question Answering", "authors": "Fengxiao Tang,Yufeng Li,Zongzong Wu,Ming Zhao", "background": "复杂问题回答（QA）是自然语言处理（NLP）领域的一个基本且富有挑战性的任务。尽管大型语言模型（LLMs）在QA方面表现出色，但在面对复杂和抽象的QA任务时，由于推理能力不足，其性能会显著下降。已有研究表明，Chain-of-Thought (CoT) 和 Tree-of-Thought (ToT) 方法旨在增强LLMs的推理能力，但它们面临层内树结构冗余和链结构单路径的问题。虽然有些研究利用检索增强生成（RAG）方法来辅助LLMs进行推理，但有效利用涉及多个实体和多跳的大量信息的挑战仍然突出。", "innovation": "我们提出了矩阵思维（MoT），这是一种新颖且高效的LLM思维结构。MoT通过“列单元通信”机制在水平和垂直维度上探讨问题，使LLMs能够主动进行多策略、多层次的思考，减少列单元内的冗余并增强推理能力。此外，我们开发了一种事实修正机制，通过从检索的知识图谱三元组和原始文本构建知识单元来增强LLMs推理过程中的初始知识并纠正错误答案。这一机制导致了高效的MTQA问答框架的开发。", "conclusion": "实验结果显示，我们的框架在四个常用数据集上优于最先进的方法，F1和EM分数均高，推理时间仅为基线方法的14.4%，证明了其高效性和准确性。此框架的代码可在以下链接获取：[此处提供链接]。"}
{"llm_update_time": "20250907", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2509.03809", "html_url": "https://arxiv.org/abs/2509.03809", "title": "Align-then-Slide: 一种全面的超长文档级机器翻译评估框架", "title_en": "Align-then-Slide: A complete evaluation framework for Ultra-Long Document-Level Machine Translation", "authors": "Jiaxin Guo,Daimeng Wei,Yuanchang Luo,Xiaoyu Chen,Zhanglin Wu,Huan Yang,Hengchao Shang,Zongyao Li,Zhiqiang Rao,Jinlong Yang,Hao Yang", "background": "大型语言模型（LLMs）为文档级机器翻译（doc-mt）带来了新时代，但它们的整篇文档输出挑战了现有基于逐句对齐的评估方法。现有评估方法假设源语言和目标语言之间的逐句对齐，这与LLMs的输出方式不匹配，导致评估结果不一定准确。因此，需要新的评估框架来应对这种挑战。本文提出了Align-then-Slide，一种全面评估超长文档级机器翻译的框架，以解决上述问题。", "innovation": "本文提出的Align-then-Slide框架创新性地引入了两个主要阶段：首先，在Align阶段，利用自动方法推断句子级的源语言和目标语言对应关系，并重建目标文档以匹配源文档的句子数量，从而解决遗漏和多对一/一对一映射问题；然后，在n-Chunk Sliding Evaluate阶段，计算1-、2-、3-和4-块的平均度量得分来进行多粒度评估。这种方法能够处理超长文档级翻译的评估难题，提供更为准确和全面的评估结果。此外，通过这种方法获得的偏好数据可以在CPO训练和作为GRPO的奖励模型中直接使用，从而优化翻译质量。", "conclusion": "实验表明，该方法与专业人工评估分数的相关性高达0.929，并与人工评估高度一致。在真实世界测试集上的结果进一步验证了该方法的有效性。该框架被证明是一种准确、稳健且可操作的文档级机器翻译系统的评估工具。此外，该方法所提供的偏好数据有助于有效训练CPO并直接用作GRPO的奖励模型，从而产生优于简单模板微调基线的翻译结果。"}
{"llm_update_time": "20250907", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2509.03891", "html_url": "https://arxiv.org/abs/2509.03891", "title": "MobileRAG：通过检索增强生成增强移动代理", "title_en": "MobileRAG: Enhancing Mobile Agent with Retrieval-Augmented Generation", "authors": "Gowen Loo,Chang Liu,Qinghong Yin,Xiang Chen,Jiawei Chen,Jingyuan Zhang,Yu Tian", "background": "智能手机已成为人们日常生活中的重要工具，几乎渗透到现代社会的各个方面。随着大型语言模型（LLMs）的不断发展，基于LLMs的移动代理大量涌现。这些代理能够准确地解析用户查询，并自动帮助用户完成复杂的或重复的操作。然而，当前的代理存在以下问题：1) 高度依赖于LLMs的理解能力，这可能导致执行任务过程中因误操作或遗漏步骤而产生的错误；2) 缺乏与外部环境的交互，往往在应用程序无法满足用户查询时中断任务；3) 缺乏记忆能力，每次指令都需要重新构建界面，并且不能从先前的错误中学习和纠正。\n", "innovation": "为了缓解上述问题，本文提出了一个基于检索增强生成（Retrieval-Augmented Generation，RAG）增强的移动代理框架MobileRAG，包括InterRAG、LocalRAG和MemRAG。该框架利用RAG更快速、更准确地识别用户查询和完成复杂的长时间序列移动任务。此外，为更全面地评估MobileRAG的性能，我们引入了MobileRAG-Eval，这是一个包含大量复杂现实移动任务的更具挑战性的基准，这些任务需要外部知识支持。实验结果表明，MobileRAG在真实移动任务中表现出色，与最先进的方法相比，操作步骤减少了10.3%，并且性能显著提高。\n", "conclusion": "本文提出的MobileRAG通过检索增强生成技术解决了当前移动代理存在的问题，并通过MobileRAG-Eval基准在多个复杂的真实世界移动任务中的表现验证了其有效性。"}
{"llm_update_time": "20250907", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2509.03867", "html_url": "https://arxiv.org/abs/2509.03867", "title": "Drivel-ology: Challenging LLMs with Interpreting Nonsense with Depth", "title_en": "Drivel-ology: Challenging LLMs with Interpreting Nonsense with Depth", "authors": "Yang Wang,Chenghao Xiao,Chia-Yi Hsiao,Zi Yan Chang,Chi-Li Chen,Tyler Loakman,Chenghua Lin", "background": "当前的语言模型（LLM）在许多自然语言处理（NLP）任务上表现出色，但在理解和处理具有深层次含意的‘语义空白’文本（Drivelological文本）时表现出明显局限性。这种文本虽然从表面上看是无意义的，但其背后蕴含了需要在上下文推断、道德推理或情感解读中把握的深层次含义。现有的大规模语言模型未能捕捉到这些文本的多重语义层面，这揭示了模型在语言理解和推理解析方面的缺口。因此，有必要开发新的基准数据集和方法来挑战并改进现有的大规模语言模型，使其更好地理解和处理这类文本。", "innovation": "本文介绍了Drivelology，这是一种被描述为“深层次的无意义”，即语法上连贯但具有语用悖论性、情感负载或修辞反叛特征的语言现象。研究者构建了一个包含超过1200个精心选择和标注的例子的基准数据集，这些例子涵盖了英语、中文、西班牙语、法语、日语和韩语等多种语言。这个数据集的独特之处在于每个例子都需要专家的多次讨论和审查，以确保其真正具有Drivelology特征。这反映了Drivelology的细微和主观性。研究者还评估了一系列的语言模型在分类、生成和推理任务上的表现，结果显示，这些模型在处理Drivelology文本时经常将其误认为浅层次的无意义，给出不相干的解释，甚至完全遗漏其背后的修辞功能。这些发现表明，现有的语言模型在语言理解和语用理解方面存在更深层次的表示差距，并挑战了统计流畅性等同于认知理解的假设。", "conclusion": "本文通过构建Drivelology数据集和引入Drivelology概念，揭示了当前语言模型在处理深层次无意义文本时的局限性，并指出了语用理解上的缺口。研究结果强调了有必要进一步研究和开发能够理解和处理这类复杂文本的语言模型。同时，本文将数据集和相关代码开源，旨在促进模型行为研究领域的进一步发展。"}
{"llm_update_time": "20250907", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2509.03995", "html_url": "https://arxiv.org/abs/2509.03995", "title": "RTQA : 通过大型语言模型进行复杂时间知识图谱问题求解的递归思考", "title_en": "RTQA : Recursive Thinking for Complex Temporal Knowledge Graph Question Answering with Large Language Models", "authors": "Zhaoyan Gong,Juan Li,Zhiqiang Liu,Lei Liang,Huajun Chen,Wen Zhang", "background": "当前的时间知识图谱问答（TKGQA）方法主要关注隐式的时间约束条件，缺乏处理更复杂时间查询的能力，并且在分解框架中面临推理能力和错误传播的局限。", "innovation": "提出了一种名为RTQA的新框架，通过递归思考对时间知识图谱进行增强推理，无需训练。该框架将问题分解为子问题，自底向上使用LLMs和TKG知识求解，并采用多路径答案聚合以提高容错性。", "conclusion": "实验结果表明，RTQA在“Multiple”和“Complex”类别中，在Hits@1指标上取得了显著改善，并且超过了最先进的方法。代码和数据可在以下链接获取：this https URL."}
{"llm_update_time": "20250907", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2509.03962", "html_url": "https://arxiv.org/abs/2509.03962", "title": "在极其低资源环境下的NLP基准探索", "title_en": "Exploring NLP Benchmarks in an Extremely Low-Resource Setting", "authors": "Ulin Nuha,Adam Jatowt", "background": "大型语言模型（LLMs）在极低资源语言中的有效性大幅减弱，特别是对于原生语言，主要原因是缺乏标注数据。尽管兴趣日益增长，高质量的自然语言处理（NLP）数据集仍然很少，使得开发稳健的语言技术变得困难。本文聚焦于一种濒危的罗曼语——拉第语（Ladin），特别是在Val Badia变体上，利用少量平行的拉第语-意大利语句子对，创建情感分析和多项选择问题回答的合成数据集。这些数据集的创建旨在填补数据匮乏的空白，并利用它们来训练机器翻译，以显著提高现有意大利-拉第语翻译基线的表现。", "innovation": "本文的创新之处在于，通过利用少量平行的语言对数据来创建合成数据集，并应用严格的过滤和反译程序以保证语言质量和可靠性。此外，将这些合成数据集纳入机器翻译训练中，能显著提高即有基线的表现。同时，这是首次发布拉第语的情感分析和多项选择问题回答的公开数据集，为该领域提供基础资源，以支持更广泛的NLP研究和下游应用。", "conclusion": "本文通过在稀缺资源设置下探索NLP基准的问题，引入了拉第语的情感分析和多项选择问题回答的合成数据集，解决了语言技术开发中的数据不足问题，为以后的研究提供了重要资源。"}
{"llm_update_time": "20250907", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2509.03934", "html_url": "https://arxiv.org/abs/2509.03934", "title": "SelfAug：通过分布自我对齐减轻检索增强生成中的灾难性遗忘", "title_en": "SelfAug: Mitigating Catastrophic Forgetting in Retrieval-Augmented Generation via Distribution Self-Alignment", "authors": "Yuqing Huang,Rongyang Zhang,Qimeng Wang,Chengqiang Lu,Yan Gao,Yi Wu,Yao Hu,Xuyang Zhi,Guiquan Liu,Xin Li,Hao Wang,Enhong Chen", "background": "近年来，大型语言模型（LLMs）通过出色的任务理解和执行能力颠覆了自然语言处理领域。尽管在检索增强生成（RAG）场景中的监督微调能够有效提升特定任务表现，但通常会导致灾难性遗忘现象，即模型会丧失其原有的知识和通用能力。现有的解决方案要么需要访问通用指令数据，要么在保留模型原始分布方面存在局限性。因此，我们提出了一种方法，即SelfAug，以模型内部的分布对齐来确保输入序列logits的对齐，从而缓解灾难性遗忘，提高下游任务性能。实验展示了SelfAug在保留模型通用能力的同时进一步提高下游学习效果的优越性。我们的实证分析发现，分布变化与RAG微调中的灾难性遗忘严重程度之间存在直接关联，这强调了在通用指令调整中缺乏RAG能力会导致显著的分布变化。这些发现不仅推进了对RAG上下文下灾难性遗忘的理解，还为大家提供了一个适用于不同微调场景的实用解决方案。", "innovation": "我们提出了一种名为SelfAug的方法，这是一种自我分布对齐方法，通过将输入序列logits对齐来保留模型的语义分布，从而减缓灾难性遗忘并提升下游性能。该方法不仅能提高模型在特定任务上的表现，还能有效保留模型的通用能力。此外，我们的分析揭示了分布变化与灾难性遗忘之间的直接关系，表明通用指令调整中缺乏RAG能力会引发显著的分布变化。", "conclusion": "我们的研究不仅深化了对RAG模型中灾难性遗忘机制的理解，也为不同微调场景提供了实际的解决方案。我们的代码在https://github.com/selfaug/selfaug上公开，可供进一步研究使用。"}
{"llm_update_time": "20250907", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2509.03940", "html_url": "https://arxiv.org/abs/2509.03940", "title": "VoxRole：评估基于语音的角色扮演代理的综合基准", "title_en": "VoxRole: A Comprehensive Benchmark for Evaluating Speech-Based Role-Playing Agents", "authors": "Weihao Wu,Liang Cao,Xinyu Wu,Zhiwei Lin,Rui Niu,Jingbei Li,Zhiyong Wu", "background": "大型语言模型（LLMs）的最新进展极大地推动了角色扮演对话代理（RPCAs）的发展。当前的研究主要集中在文本模态上，忽视了在语音中至关重要的副语言特征，如语调、语调和节奏，这些对于传达角色情感和塑造鲜明的身份至关重要。此外，基于语音的角色扮演领域长期以来缺乏标准化的评估基准。现有的对话数据集大多只能评估基本能力，并未提供详细的或清晰的角色描述，这使得难以评估模型在长期角色一致性方面的能力。", "innovation": "我们提出了VoxRole，这是第一个专为评估基于语音的角色扮演代理设计的全面基准。VoxRole包含13335个多轮对话，总时长为65.6小时，涉及261部电影中的1228个独特角色。通过一个新颖的两阶段自动化流程，首先将电影音频与剧本对齐，然后利用大型语言模型（LLMs）系统地为每个角色构建多维度的描述。利用VoxRole，我们对当前的语音对话模型进行了多维度评估，揭示了它们在保持角色一致性方面的优势和局限性。", "conclusion": "通过VoxRole，我们首次对当前的语音对话模型进行了多维度的评估，并发现了它们在保持角色一致性方面的关键洞察。这为评估基于语音的角色扮演代理提供了新的工具。"}
{"llm_update_time": "20250907", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2509.03957", "html_url": "https://arxiv.org/abs/2509.03957", "title": "CANDY: 评估大型语言模型在中文谣言事实核查中的局限性和辅助潜力", "title_en": "CANDY: Benchmarking LLMs' Limitations and Assistive Potential in Chinese Misinformation Fact-Checking", "authors": "Ruiling Guo,Xinwei Yang,Chen Huang,Tong Zhang,Yong Hu", "background": "尽管大型语言模型（LLMs）在事实核查方面很受欢迎，但它们在验证虚假信息方面的效果仍存在不确定性。本文旨在系统地评估LLMs在中文虚假信息事实核查方面的能力和局限性，通过创建一个精心标注的数据集来实现这一目标。研究发现，当前的LLMs在生成准确的事实核查结论时存在局限性，即使使用了链式推理和少量样本提示。虽然单独使用LLMs进行事实核查不够可靠，但实验证明，它们可以作为辅助工具提升人类的表现。该数据集和代码可在以下链接访问：this https URL", "innovation": "本文提出了CANDY基准，用于系统地评估中国虚假信息事实核查中大型语言模型的能力和局限性。CANDY包括一个包含约20000实例的精心注释数据集。通过分析，研究者开发了一个分类法来归类生成结论的错误的LLM解释，并识别出事实捏造是最常见的失败模式。此外，研究结果表明，当作为辅助工具时，大型语言模型有增强人类表现的巨大潜力", "conclusion": "尽管目前的大型语言模型在准确生成事实核查结论方面存在局限性，但它们具有在中文虚假信息事实核查中作为辅助工具提升人类表现的潜力。研究还指出了大型语言模型的常见缺陷，并提供了解决这些问题的方法和思路。研究人员希望CANDY基准和相关数据可以帮助进一步研究和改善大型语言模型的性能。"}
{"llm_update_time": "20250907", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2509.03972", "html_url": "https://arxiv.org/abs/2509.03972", "title": "通过韩语案例研究提升开源LLM基础语言能力", "title_en": "Expanding Foundational Language Capabilities in Open-Source LLMs through a Korean Case Study", "authors": "Junghwan Lim,Gangwon Jo,Sungmin Lee,Jiyoung Park,Dongseok Kim,Jihwan Kim,Junhyeok Lee,Wai Ting Cheung,Dahye Choi,Kibong Choi,Jaeyeon Huh,Beomgyu Kim,Jangwoong Kim,Taehyun Kim,Haesol Lee,Jeesoo Lee,Dongpin Oh,Changseok Song,Daewon Suh", "background": "本文介绍了一个名为Llama-3-Motif的语言模型，该模型拥有1020亿参数，旨在增强韩语能力同时保持在英语上的强大表现。该模型基于Llama 3架构，并利用先进的训练技术如LlamaPro和Masked Structure Growth，确保模型能有效扩展而不改变其核心Transformer架构。\n此外，使用MoAI平台对模型进行优化，该平台支持大规模GPU集群的高效训练，并采用经精心筛选的数据集，确保韩语和英语数据比例均衡，从而在韩国特定基准测试中表现出色，超出已有模型的表现，效果与GPT-4相当。", "innovation": "Llama-3-Motif采用了LlamaPro和Masked Structure Growth等先进的训练技术，有效扩展了模型规模而不改变其核心Transformer架构。同时，通过使用MoAI平台进行大规模GPU集群的高效训练以及精心筛选的数据集，优化了模型。该模型在韩语特定基准测试中表现出色，超越了现有模型，性能接近GPT-4。", "conclusion": "Llama-3-Motif 是一个参数量为1020亿的语言模型，能够增强韩语能力同时保持在英语上的强表现。该模型通过先进训练技术的实施和大规模GPU集群的高效训练，在韩国特定基准测试中展示了出色的表现，达到和GPT-4相近的水平。"}
{"llm_update_time": "20250907", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2509.04046", "html_url": "https://arxiv.org/abs/2509.04046", "title": "基于RoBERTa的汉语功能语法标注模型", "title_en": "A RoBERTa-Based Functional Syntax Annotation Model for Chinese Texts", "authors": "Han Xiaohui,Zhang Yunlong,Guo Yuxi", "background": "系统功能语法和其分支卡迪夫语法已被广泛应用于不同语言和文本的篇章分析、语义功能研究等任务中。然而，基于该理论的自动标注系统尚未应用于汉语文本，这极大限制了相关理论的应用和推广。", "innovation": "该研究首次提出了一种基于RoBERTa的功能语法标注模型，通过从人民日报2014年语料库中随机选取4100个句子进行功能语法标注并建立训练数据集，在此数据集上微调RoBERTa-Chinese wwm-ext模型，用于命名实体识别任务，测试集上的F1得分为0.852，显著优于其他对比模型。该研究是将功能语法与注意力机制NLP模型首次结合，提供了一种新的汉语功能语法自动分析方法，为后续研究奠定了坚实的基础。", "conclusion": "尽管该模型在识别主要语法元素方面表现优异，但在识别样本不平衡的实体时仍有改进空间。该研究证明了功能语法与基于注意的NLP模型结合的可能性，为汉语功能语法的自动化分析提供了新方法。"}
{"llm_update_time": "20250907", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2509.04066", "html_url": "https://arxiv.org/abs/2509.04066", "title": "阿拉伯教育中的聊天机器人技术：综述", "title_en": "Arabic Chatbot Technologies in Education: An Overview", "authors": "Hicham Bourhil,Yacine El Younoussi", "background": "近年来，人工智能（AI）以及自然语言处理（NLP）取得了显著进展，尤其是在对话机器人方面，已在教育、医疗、旅游和客户服务等领域广泛应用。尤其是在COVID-19疫情期间，人们对其远程访问能力的兴趣不断增长。在全球范围内，基于网络的学习系统也得到了广泛采用。大型语言模型（LLM）如BERT和GPT使得对话机器人在教育领域更加受欢迎。", "innovation": "介绍了现有阿拉伯教育领域的对话机器人的特点，包括采用的方法、语言多样性以及用于衡量性能的指标，并指出现有研究在阿拉伯语教育机器人的应用中存在的一些空白。特别突出了现代技术在阿拉伯教育机器人中的应用不足，并提出了一些未来研究方向。", "conclusion": "尽管对话机器人在其他语言（如英语）中取得了成功应用，但在阿拉伯语教育领域的应用仍需采纳更多现代技术。文章讨论了未来的研究方向。"}
{"llm_update_time": "20250907", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2509.04077", "html_url": "https://arxiv.org/abs/2509.04077", "title": "通过微调语言模型提高叙述分类和解释", "title_en": "Improving Narrative Classification and Explanation via Fine Tuned Language Models", "authors": "Rishit Tyagi,Rahul Bouri,Mohit Gupta", "background": "理解隐含叙述和隐性信息对于分析偏见和情感至关重要。传统NLP方法难以检测微妙的措辞和隐藏的议程。本文针对两大挑战：（1）新闻文章中的多标签叙述和亚叙述分类，（2）为占主导地位的叙述生成简洁的事实依据解释。", "innovation": "本文提出了一种基于召回的方法来微调BERT模型进行叙述检测，并使用GPT-4o管道精炼预测结果来保持一致性。在叙述解释方面，提出了一种结合语义检索的少样本提示的ReACT框架。为提高事实准确性并减少虚构，引入了一个结构化分类表作为辅助知识库。", "conclusion": "结果表明，在提示中引入辅助知识可以提高分类准确性和解释可靠性，适用于媒体分析、教育和情报收集等领域。"}
{"llm_update_time": "20250907", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2509.04059", "html_url": "https://arxiv.org/abs/2509.04059", "title": "基于音乐理论合成乐谱问题以进行评估和强化学习", "title_en": "Synthesizing Sheet Music Problems for Evaluation and Reinforcement Learning", "authors": "Zhilin Wang,Zhe Yang,Yun Luo,Yafu Li,Haoran Zhang,Runzhe Zhan,Derek F. Wong,Jizhe Zhou,Yu Cheng", "background": "增强大型语言模型（LLMs）和多模态大型语言模型（MLLMs）解读乐谱的能力对于构建AI音乐家至关重要。然而，当前研究在乐谱推理方面缺乏评估基准和训练数据。为解决这个问题，本文提出了基于音乐理论合成乐谱问题的想法，这可以作为评估基准和强化学习中带有验证奖励的方法的训练数据。", "innovation": "本文提出了一种数据合成框架，生成文本和视觉模式下的可验证乐谱问题，从而创建合成乐谱推理基准（SSMR-Bench）和配套训练集。通过利用合成数据进行基于验证奖励的强化学习（RLVR），Qwen3-8B-Base和Qwen2.5-VL-Instruct在SSMR-Bench上取得了改进。Qwen3-8B-Base超过GPT-4在MusicTheoryBench上的整体表现，并且通过角色扮演和链式思维策略达到与GPT-4相当的推理性能。此外，其在数学问题上的表现也有所提升。本文的结果表明增强的推理能力也有助于音乐创作。", "conclusion": "我们首次提出了基于音乐理论规则合成乐谱问题的想法，并证明了这一方法不仅在乐谱理解模型推理方面取得了进展，而且还开启了AI辅助音乐创作的新可能性。"}
{"llm_update_time": "20250907", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2509.04013", "html_url": "https://arxiv.org/abs/2509.04013", "title": "关于大型语言模型基准评估的稳健性和可靠性", "title_en": "On Robustness and Reliability of Benchmark-Based Evaluation of LLMs", "authors": "Riccardo Lunardi,Vincenzo Della Mea,Stefano Mizzaro,Kevin Roitero", "background": "通常，大型语言模型（LLMs）通过MMLU、ARC-C或HellaSwag等基准测试来评估其效果，这些问题通常以固定的标准格式呈现。然而，实际应用场景中存在广泛的语言变化，要求模型在不同措辞的相同问题或查询中保持其效果。本研究系统地评估了LLMs对改写基准问题的稳健性，并探讨了基于基准的评估是否能可靠地衡量模型的能力。通过生成所有问题在六个不同基准下的多种改写版本，测量34个不同规模和效果的先进LLM的结果差异，发现LLM的排名在改写输入中相对稳定，但绝对效果分数下降显著，表明LLMs在语言变化面前存在困难，对模型泛化能力和评估方法提出质疑。观测到的效果下降质疑了基于基准的评估的可靠性，表明高基准分数可能未能完全捕捉模型在实际输入变化中的稳健性。", "innovation": "本研究通过系统生成所有问题在六个不同基准下的多种改写版本，测量了34个不同规模和效果的先进LLM的效果差异。这为评估大型语言模型的稳健性和可靠性提供了一种新的方法，有助于改进现有的评估基准。", "conclusion": "虽然LLM在改写输入中排名相对稳定，但绝对效果分数显著下降，表明LLMs在语言变化面前存在困难。这质疑了基于基准的评估的可靠性，高基准分数可能未能完全反映模型对实际输入变化的稳健性。这些发现对LLM评估方法具有重要影响，强调需要更贴近实际部署场景的稳健性导向基准。"}
{"llm_update_time": "20250907", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2509.04104", "html_url": "https://arxiv.org/abs/2509.04104", "title": "致力于spoken人类-代理对话中稳定且个性化的词汇对齐配置文件", "title_en": "Towards Stable and Personalised Profiles for Lexical Alignment in Spoken Human-Agent Dialogue", "authors": "Keara Schaaij,Roel Boumans,Tibor Bosse,Iris Hendrickx", "background": "词汇对齐，即对话者开始在对话中使用相似词汇的过程，已被证实能促进有效的沟通。然而，将其在对话代理中的实施仍然被持续探索，特别是在大型语言模型（LLMs）取得最新进展的情况下。本文旨在使对话代理能够实现词汇对齐，首先借鉴个性化对话代理的策略，探讨基于词汇对齐的稳定且个性化的词汇配置文件的构建。研究通过调整用于构建的转录语音数据量及每个词性（POS）类别的项数，来评估配置文件随时间的性能。", "innovation": "本文创新之处在于通过最小数据需求构建稳定且个性化的词汇配置文件，为对话代理的词汇对齐策略奠定了基础。具体而言，研究通过实验展示了在10分钟内的转录语音数据中包含5个形容词、5个连词和10个每个类别的代词、名词、代词和动词项，构建的小而紧凑的词汇配置文件在性能和数据效率上提供了最佳平衡。", "conclusion": "本研究提供了构建稳定且个性化的词汇配置文件的实用见解，考虑到对数据需求的最小化，这为对话代理的词汇对齐策略的发展奠定了基础。"}
{"llm_update_time": "20250907", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2509.04182", "html_url": "https://arxiv.org/abs/2509.04182", "title": "联合建模实体与话语关系以评估语篇连贯性", "title_en": "Joint Modeling of Entities and Discourse Relations for Coherence Assessment", "authors": "Wei Liu,Michael Strube", "background": "在语言学中，语篇连贯可以通过多种方式实现，包括句子之间保持对同一组实体的引用以及建立话语关系。然而，现有的大多数连贯性建模工作仅关注实体特征或话语关系特征之一，而忽略了两者结合的方法。本研究旨在探索如何联合建模实体与话语关系，以提高连贯性评估的表现。", "innovation": "本研究通过探索两种方法，以联合建模实体与话语关系，提高了连贯性评估模型的表现。研究表明，同时结合两种特征可以显著提升模型性能，强调了同时建模这两种类型特征的重要性。", "conclusion": "实验结果显示，将实体特征与话语关系特征整合使用，可以显著提高连贯性模型的性能，为此类评估提供了新的视角和改进方法。"}
{"llm_update_time": "20250907", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2509.04183", "html_url": "https://arxiv.org/abs/2509.04183", "title": "MAGneT：协调多代理生成模拟多轮心理健康咨询会话", "title_en": "MAGneT: Coordinated Multi-Agent Generation of Synthetic Multi-Turn Mental Health Counseling Sessions", "authors": "Aishik Mandal,Tanmoy Chakraborty,Iryna Gurevych", "background": "随着对可扩展心理咨询服务需求的增长，精细调整高质量、隐私合规的开源大型语言模型（LLMs）变得尤为重要，但此类数据仍然稀缺。因此，研究者们开发了一个新的多代理框架MAGneT，用于生成模拟心理咨询会话。", "innovation": "MAGneT引入了一个多代理框架，将心理咨询师回应生成分解为由专门LLM代理处理的协调子任务，每个代理模拟一种关键的心理技术。这一框架不同于以往的单代理方法，能够更好地捕捉真实心理咨询的结构和复杂性。此外，MAGneT还提出了一个统一的评估框架，整合了多种自动和专家评估指标，并将专家评估的维度从4个扩展到9个，以进行更加全面和严格的评估。实验结果显示，MAGneT在生成的心理咨询会话的质量、多样性以及治疗一致性方面显著优于现有方法，提升了通用心理咨询技能和认知行为疗法的特定技能。", "conclusion": "MAGneT生成的会话得到专家的广泛认可，且基于MAGneT生成的数据进行微调的开放源代码模型也显示了更好的性能。研究者们还公开了代码和数据。"}
{"llm_update_time": "20250907", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2509.04202", "html_url": "https://arxiv.org/abs/2509.04202", "title": "社交事件检测中的显式和隐式数据增强", "title_en": "Explicit and Implicit Data Augmentation for Social Event Detection", "authors": "Congbo Ma,Yuxia Wang,Jia Wu,Jian Yang,Jing Du,Zitai Qiu,Qing Li,Hu Wang,Preslav Nakov", "background": "社交事件检测涉及从社交媒体中识别并分类重要的事件，这依赖于标记数据，但标注这些数据既昂贵又劳动密集。", "innovation": "提出了一个称为SED-Aug的插件式双重增强框架，该框架结合了显式基于文本的和隐式特征空间的增强方法，以增强数据多样性和模型的鲁棒性。具体的创新包括：1) 使用大型语言模型通过五种不同的生成策略增强文本信息；2) 设计了五种新型的特征空间内嵌入扰动技术，这些扰动技术保持嵌入的语义和关系属性，并增加其多样性。", "conclusion": "与基准模型相比，SED-Aug在Twitter2012数据集上平均F1分数高出约17.67%，在Twitter2018数据集上约为15.57%，证明了其有效性和优越性。代码已经在GitHub(this https URL)公开。"}
{"llm_update_time": "20250907", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2509.04292", "html_url": "https://arxiv.org/abs/2509.04292", "title": "逆IFEval：LLM能否克服顽固的训练习惯以遵循实际指令？", "title_en": "Inverse IFEval: Can LLMs Unlearn Stubborn Training Conventions to Follow Real Instructions?", "authors": "Qinyan Zhang,Xinping Lei,Ruijie Miao,Yu Fu,Haojie Fan,Le Chang,Jiafan Hou,Dingling Zhang,Zhongfei Hou,Ziqiang Yang,Changxin Pu,Fei Hu,Jingkai Liu,Mengyun Liu,Yang Liu,Xiang Gao,Jiaheng Liu,Tong Yang,Zaiyuan Wang,Ge Zhang,Wenhao Huang", "background": "大型语言模型（LLMs）在各种任务中表现出色，但往往表现出认知惰性，难以执行与其监督微调（SFT）中学习的标准模式相冲突的指令。为评估这一限制，提出了一种新的基准测试Inverse IFEval，用于衡量模型克服训练带来的偏见并遵守对抗指令的能力。该基准测试引入了八种类型的挑战，包括问题修正、故意的内容瑕疵、无注释的代码和反事实回答等内容。", "innovation": "提出了Inverse IFEval基准测试，这是用来评估LLM克服训练偏见并遵从原指示的能力的新方法。基准测试引入了八种类型的对抗挑战，并使用人工审核流程构建了一个高质量的中英文问题数据集，评估了已有领先LLM的必要性。", "conclusion": "实验表明，未来对齐工作不应仅追求流畅和事实正确性，还应考虑到在非常规环境中的适应性。希望逆IFEval基准测试既成为诊断工具，也为开发方法解决认知惰性、减少模式过拟合并最终提升LLM在各种不确定现实场景中遵循指令的可靠性奠定基础。"}
{"llm_update_time": "20250907", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2509.04373", "html_url": "https://arxiv.org/abs/2509.04373", "title": "测量偏差还是测量任务：理解LLM性别偏见的脆弱性", "title_en": "Measuring Bias or Measuring the Task: Understanding the Brittle Nature of LLM Gender Biases", "authors": "Bufan Gao,Elisa Kreiss", "background": "随着大型语言模型（LLMs）在社会影响较大的场景中得到越来越多的应用，性别偏见问题引起了广泛关注。现有的研究往往依赖于与自然语言分布不同的评价任务，为了检测和减轻性别偏见，这些任务通常包含明确或隐含表明性别偏见内容的提示。本研究探讨提示任务评估目的会如何影响测得的LLM性别偏见。", "innovation": "研究通过两种具体的提示条件来测试强化了的测试情境和性别相关内容的提醒影响，并使用不同格式的任务、标记概率和离散选择指标来评估提示敏感度。研究发现即使是细微的变化也可能会显著改变性别偏见的结果，有时甚至改变其方向；同时，离散选择度量倾向于相对于概率度量放大偏见。", "conclusion": "研究成果不仅揭示了LLM性别偏见评估的脆弱性，还提出了一个新问题：控制测试设计能否触发LLM的“测试模式”表现，并且这对未来的基准测试的有效性意味着什么？"}
{"llm_update_time": "20250907", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2509.04432", "html_url": "https://arxiv.org/abs/2509.04432", "title": "语言模型能处理非格里高利历吗？", "title_en": "Can Language Models Handle a Non-Gregorian Calendar?", "authors": "Mutsumi Sasaki,Go Kamoda,Ryosuke Takahashi,Kosuke Sato,Kentaro Inui,Keisuke Sakaguchi,Benjamin Heinzerling", "background": "语言模型（LMs）需要具备时间和知识推理能力。尽管许多先前的工作已经分析和改进了LMs的时间推理能力，但大多数研究仅关注格里高利历。然而，许多非格里高利历系统，如日本历、希吉 Crescent历和希伯来历，在全世界广泛使用，反映了不同文化中对时间的不同观念。目前尚未评估现有LMs如何准确处理这些非格里高利历。", "innovation": "本文系统地评估了开源LMs处理日本历的能力，创建了四个需要时间和知识推理的任务数据集。研究发现，尽管有些模型能够进行历法转换，但即便日本中心模型也难以有效地进行日本历算术运算和跨历法的一致性保持。", "conclusion": "研究结果突显了开发更了解文化特定历法的LMs的重要性。"}
{"llm_update_time": "20250907", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2509.04357", "html_url": "https://arxiv.org/abs/2509.04357", "title": "PARCO: 具有对比实体消歧的增强音素鲁棒上下文ASR", "title_en": "PARCO: Phoneme-Augmented Robust Contextual ASR via Contrastive Entity Disambiguation", "authors": "Jiajun He,Naoki Sawada,Koichi Miyazaki,Tomoki Toda", "background": "自动语音识别（ASR）系统在处理特定领域的人名实体，尤其是同音词时表现不佳。上下文ASR可以改善识别率，但由于实体多样性有限，往往无法捕捉细微的音素变化。此前的方法将实体视作独立的词汇，导致多词汇的偏置不完整。", "innovation": "本文提出了一种新的框架PARCO (Phoneme-Augmented Robust Contextual ASR via COntrastive entity disambiguation)，该框架结合了音素感知编码、对比实体消歧、实体级别监督和层次实体过滤。这些组件增强了音素的区分度，确保了全面的实体检索，并在不确定性的环境下降低了误识别率。实验结果显示，PARCO在中文AISHELL-1和英文DATA2数据集上性能显著优于基线模型，特别是在存在1,000个干扰词的情况下。", "conclusion": "实验表明，PARCO在中文AISHELL-1（字符错误率CER为4.22%）和英文DATA2（词错误率WER为11.14%）数据集上表现优越，特别是在存在大量干扰词的情况下，对不同领域数据集（如THCHS-30和LibriSpeech）也有显著提升。"}
{"llm_update_time": "20250907", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2509.03636", "html_url": "https://arxiv.org/abs/2509.03636", "title": "CausalARC: 基于因果世界模型的抽象推理", "title_en": "CausalARC: Abstract Reasoning with Causal World Models", "authors": "Jacqueline Maasch,John Kalantari,Kia Khezeli", "background": "在有限数据和分布变化的情况下，推理需要适应新的问题环境。本文旨在为AI推理提供一个实验测试平台，特别是在低数据和分布外的情形下。这一平台借鉴了抽象和推理语料库（Abstraction and Reasoning Corpus, ARC），建立在完整的因果世界模型之上，这种模型以结构因果模型的形式正式表达。", "innovation": "本文介绍了一个名为CausalARC的因果世界模型，用于AI推理评估。通过有原则的数据增强，CausalARC提供关于世界模型的观测、干预和反事实反馈，并采用少量的在上下文中学习演示来促进学习。本文通过四个不同的语言模型评估设置展示了这一点：(1) 测试时的训练下的抽象推理，(2) 利用上下文学习的反事实推理，(3) 程序合成，(4) 结合逻辑推理的因果发现。", "conclusion": "CausalARC平台通过提供完整的因果世界模型和有原则的数据增强，弥补了现有方法在低数据和分布变化场景中的不足，并为AI推理的评估引入了一个新的实验测试平台。"}
{"llm_update_time": "20250907", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2509.03646", "html_url": "https://arxiv.org/abs/2509.03646", "title": "通过强化学习在大语言模型中出现的层次化推理", "title_en": "Emergent Hierarchical Reasoning in LLMs through Reinforcement Learning", "authors": "Haozhe Wang,Qixin Xu,Che Liu,Junhong Wu,Fangzhen Lin,Wenhu Chen", "background": "强化学习（RL）已被证明非常有效，能够显著提升大语言模型（LLMs）的复杂推理能力，然而其背后的驱动机制仍然不透明。本文分析揭示了一种现象，即诸如“顿悟”、“长度缩放”和熵动力学等现象并非孤立发生，而是层次化推理范式的一部分。研究发现，模型经历了一个两阶段动态过程：首先，模型受到程序正确性的制约，必须提高低级技能。随后，学习瓶颈的关键转变在于探索和掌握高级战略规划，这是提升性能的主要驱动。现有RL算法如GRPO对优化压力的应用缺乏区分性，导致所有标记的学习信号被淡化。", "innovation": "本文提出了一种新的算法——HIerarchy-Aware Credit Assignment (HICRA)，该算法集中优化努力在对规划影响最大的标记上，以解决现有RL算法的效率问题。HICRA在多个基准测试中表现出色，证明了关注这一战略瓶颈是实现高级推理的关键。同时，本文验证了语义熵作为衡量战略探索的更好指标，优于基于标记熵等误导性指标。", "conclusion": "研究揭示了层次化推理在大语言模型中的重要性，并通过HICRA算法提高了模型的推理能力，表明优化高级战略规划是提升模型复杂推理能力的关键。"}
{"llm_update_time": "20250907", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2509.03644", "html_url": "https://arxiv.org/abs/2509.03644", "title": "基于方案表示的神经符号推理系统展望", "title_en": "Towards a Neurosymbolic Reasoning System Grounded in Schematic Representations", "authors": "François Olivier,Zied Bouraoui", "background": "尽管自然语言理解取得了显著进步，大型语言模型（LLMs）在执行逻辑推理时仍易出错，缺乏能够支持人类水平理解的稳健心理表征。目前大多数LLMs在处理逻辑推理问题时表现不理想，主要表现为缺乏对场景中存在的关键逻辑结构的深刻理解。", "innovation": "本文提出了一种基于方案表示的神经符号系统——Embodied-LM，该系统通过基于图像方案（源自感官运动体验的反复出现的模式，结构化人类认知）的图示表示来实现理解和逻辑推理。该系统利用回答集编程中的声明性空间推理来实现认知结构的空间基础。通过逻辑演绎问题的评估，证明了LLMs可以通过具身认知结构来解释场景、这些结构可以被形式化为可执行程序，并且这些形成的表示支持了具有增强可解释性的有效逻辑推理。当前实现主要集中在空间原始概念上，但为引入更复杂和动态的表示奠定了计算基础。", "conclusion": "本文通过Embodied-LM系统展示了如何用具身认知结构引导LLMs进行逻辑推理，证明了这种方案可以被正式化为可执行程序，并支持高效的逻辑推理。未来的工作将致力于引入更加复杂和动态的表示形式。"}
{"llm_update_time": "20250907", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2509.03740", "html_url": "https://arxiv.org/abs/2509.03740", "title": "Vision-Language模型的奇异值少量冲刺适应", "title_en": "Singular Value Few-shot Adaptation of Vision-Language Models", "authors": "Taha Koleilat,Hassan Rivaz,Yiming Xiao", "background": "视觉语言模型（VLMs）如CLIP展示了在各种应用中的零样本和少样本学习能力。然而，将这些模型适应到新的细粒度领域仍然困难重重，这主要因为依赖提示工程和全面模型微调的高成本。现有适应方法依赖增强组件，如提示令牌和适配模块，这可能限制了适应质量、导致模型不稳定并损害其预训练获得的丰富知识。", "innovation": "提出了一种新颖的多模态和参数高效的适应技术CLIP-SVD，利用奇异值分解（SVD）修改CLIP的内部参数空间而无需注入额外模块。具体方法包括仅微调CLIP参数矩阵的奇异值，以调整基向量，从而实现领域适应，同时保留预训练模型。这种方法仅使用模型总参数的0.04%进行微调，同时增强适应性能并更好地保持泛化能力。", "conclusion": "CLIP-SVD在11个自然和10个生物医学数据集上实现了最先进的分类结果，在少量样本设置下的准确性和泛化能力上均优于以前的方法。此外，通过自然语言方法分析了CLIP适应的有效性和动态，以增强CLIP-SVD的可解释性。相关代码已公开。"}
{"llm_update_time": "20250907", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2509.04159", "html_url": "https://arxiv.org/abs/2509.04159", "title": "采用时间图构建烹饪过程的以动作为中心的本体", "title_en": "Towards an Action-Centric Ontology for Cooking Procedures Using Temporal Graphs", "authors": "Aarush Kumbhakern,Saransh Kumar Gupta,Lipika Dey,Partha Pratim Das", "background": "形式化描述烹饪程序仍然是一个具有挑战性的任务，因为烹饪过程具有固有的复杂性和不确定性。目前缺乏一个可以精确捕捉烹饪过程中各个环节、转换、环境、并发性和组合结构的领域特定语言。", "innovation": "提出了一种可扩展的领域特定语言，用于使用定向动作图表示烹饪食谱，能够精确、模块化地建模复杂的烹饪工作流程。此方法首次采用时间图来促进烹饪过程的结构化机器理解、精确解释和可扩展自动化。", "conclusion": "该研究初步提出了一个以动作为中心的烹饪本体，为烹饪过程中的自动化分析和执行奠定了基础。"}
{"llm_update_time": "20250907", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2509.03897", "html_url": "https://arxiv.org/abs/2509.03897", "title": "SPECS：长图像说明评估的具体增强CLIP分数", "title_en": "SPECS: Specificity-Enhanced CLIP-Score for Long Image Caption Evaluation", "authors": "Xiaofu Chen,Israfel Salazar,Yova Kementchedjhieva", "background": "随着对生成长而详细的图像说明的兴趣增长，标准评估指标变得越来越不可靠。基于n-gram的度量虽高效，但无法捕捉到语义正确性。代表相似度（RS）度量最初由于计算成本高而使用受限，尽管现在随着硬件的进步，它们仍然因为与人类判断的相关性低而不受欢迎。同时，基于大型语言模型（LLMs）的度量与人类判断有很强的相关性，但仍然因为过于昂贵而不适合模型开发中的迭代使用。", "innovation": "本文介绍了SPECS（增强特定性的CLIP分数），这是一种无需参考的RS度量，专门用于长图像说明评估。SPECS通过一个新的目标来修改CLIP，该目标特别强调了特定性：奖励正确的细节并惩罚错误的描述。结果显示，SPECS在与人类判断的相关性上与开源的LLM度量表现相当，但效率显著更高，使其成为图像说明模型验证中的一个实际替代选择。", "conclusion": "SPECS提供了一种高效且实用的评估长图像说明的方法，具有与人类判断高度相关性。该研究结果表明，SPECS可以在图像描述模型开发过程中用于迭代评估，并承诺提供更准确且计算成本更低的度量标准。"}
{"llm_update_time": "20250907", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2509.04166", "html_url": "https://arxiv.org/abs/2509.04166", "title": "跨越物种界限：从语音到动物声音的迁移学习", "title_en": "Crossing the Species Divide: Transfer Learning from Speech to Animal Sounds", "authors": "Jules Cauzinille,Marius Miron,Olivier Pietquin,Masato Hagiwara,Ricard Marxer,Arnaud Rey,Benoit Favre", "background": "自监督的语音模型已经在语音处理领域取得了令人印象深刻的表现，但是它们在非语音数据上的效果仍然没有得到充分探索。本文研究了这类模型在生物声学检测和分类任务上的迁移学习能力。", "innovation": "研究表明，模型（如HuBERT、WavLM和XEUS）能够生成跨不同物种的丰富声学特征表示。通过线性探针对时间平均表示进行分析，并在此基础上扩展方法以考虑时间信息的影响。此外，研究还探讨了频率范围和噪声对性能的影响，表明自监督的学习框架具有提高生物声学研究效率的潜力。", "conclusion": "我们的结果与细调后的生物声学预训练模型竞争，并展示了噪声鲁棒预训练设置的影响。这些发现突显了基于语音的自监督学习作为生物声学研究高效框架的潜力。"}
{"llm_update_time": "20250907", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2509.04011", "html_url": "https://arxiv.org/abs/2509.04011", "title": "NER Retriever: Zero-Shot Named Entity Retrieval with Type-Aware Embeddings", "title_en": "NER Retriever: Zero-Shot Named Entity Retrieval with Type-Aware Embeddings", "authors": "Or Shachar,Uri Katz,Yoav Goldberg,Oren Glickman", "background": "该论文讨论了一种用于即兴命名实体检索（ad-hoc Named Entity Retrieval）的框架，这是一种命名实体识别（NER）的变体，在该变体中，感兴趣的实体类型在检索前未被提供，而是使用用户定义的类型描述来检索提及该类型实体的文档。传统的做法依赖固定的模式或微调模型，而该论文提出的方法则利用大型语言模型（LLMs）的内部表示，将实体提及和用户提供的开放型类型描述嵌入到共享的语义空间中。", "innovation": "论文的创新点在于，提出了一种零样本检索框架（NER Retriever），该框架使用大型语言模型（LLMs）的内部表示，将实体提及和用户提供的类型描述嵌入到共享的语义空间中。内部表示，特别是中间变换块的价值向量，比常用的顶层嵌入更有效地编码细粒度的类型信息。通过训练一个轻量级的对比投影网络进一步优化这些表示，该网络能够对类型兼容的实体进行对齐以区分无关类型。这种方法生成的实体嵌入更紧凑、类型敏感，适合最近邻检索。与基准方法相比，NER Retriever在三个基准上显著优于词典级别的检索基线和密集句子级检索基线。", "conclusion": "实验结果表明，NER Retriever在即兴命名实体检索任务上显著优于词典级和密集句子级检索基线。研究结果为LLMs中的表示选择提供了实证支持，并展示了规模化的、免模式的实体检索的实用解决方案。NER Retriever的代码库已经公开发布。"}
{"llm_update_time": "20250907", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2509.03787", "html_url": "https://arxiv.org/abs/2509.03787", "title": "在医疗领域评估检索增强生成对抗有害证据的健壮性", "title_en": "Evaluating the Robustness of Retrieval-Augmented Generation to Adversarial Evidence in the Health Domain", "authors": "Shakiba Amirshahi,Amin Bigdeli,Charles L. A. Clarke,Amira Ghenai", "background": "检索增强生成（RAG）系统通过提供检索到的证据来增强大型语言模型（LLM）响应的真实性，从而减少幻觉并扩展模型准确回答超出训练数据范围问题的能力。然而，这种设计可能使模型吸收并复制检索证据中的错误信息，尤其是在检索证据中包含有意传播错误信息的材料时，这一问题会更加严重。本文旨在系统性地评估RAG系统在医疗领域的健壮性，并检查模型输出与真实答案的一致性，以确保不会因为错误信息导致潜在危害，特别是那些有许多基于证据的真实答案的常见健康相关问题。实验通过控制变量（如检索文档的类型、组成以及用户问题的框架）来观察不同条件下模型的表现差异，从而揭示了对抗性文档对模型可信性的影响，并提出了保障高风险领域RAG系统安全性的建议措施，包括加强检索环节的保障措施。", "innovation": "本文提出了一种系统性的评估方法，专门针对医疗领域对RAG系统对抗有害证据的健壮性进行了研究，并通过用户提出问题的框架进行控制实验，考察了不同条件下模型输出与真实答案的一致性，帮助企业或研究团队开发更安全的RAG系统以应对高风险问题，以及提出了具体建议来提升RAG系统的安全性。同时，所有实验结果已公开发布在Github存储库中，以便于他人可复现研究结果和促进后续研究工作", "conclusion": "在健康领域周围组织RAG系统时，有必要平衡检索和生成环节，以消除对抗性文档对模型可信性的负面影响。当检索到的帮助性证据与对抗性文档同时存在时，RAG系统的稳健性可以得到保持。这些发现为在医疗等高风险领域设计更安全的RAG系统提供了实际指导意义，同时也鼓励研发人员参与Git仓库中的相关研究工作，增强系统安全性。"}
{"llm_update_time": "20250907", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2509.03730", "html_url": "https://arxiv.org/abs/2509.03730", "title": "L大型语言模型个性错觉：揭示LLMs自我报告与行为之间的脱节", "title_en": "The Personality Illusion: Revealing Dissociation Between Self-Reports & Behavior in LLMs", "authors": "Pengrui Han,Rafal Kocielnik,Peiyang Song,Ramit Debnath,Dean Mobbs,Anima Anandkumar,R. Michael Alvarez", "background": "人格特质长期以来一直被认为是人类行为的预测因素。随着大型语言模型（LLMs）的最新进展，人们猜测类似的模式可能在人工系统中出现，其中高级LLMs展现了与人类特质（如宜人性和自我调节）相似的一致行为倾向。然而，之前的研究主要依赖于简化的自我报告和启发式提示，缺乏行为验证。为了更系统地了解LLM的个性，本研究从三个维度进行了分析：（1）从训练阶段动态出现和演变的人格特征概型；（2）自我报告特质在行为任务中的预测有效性；以及（3）目标干预措施（如RLHF和指令调整）对自我报告和行为的影响。研究结果揭示了指令对齐（如RLHF、指令调整）能够显著稳定并强化人格特征的表现和相关性，类似于人类数据的表现。然而，自我报告的特质并不能可靠地预测行为，而且观察到的关联与人类模式经常不同。而个性注入虽然可以成功引导自我报告的方向，但对实际行为的影响却微乎其微或不一致。通过区分表面的人格特征表达和行为一致性，这项研究挑战了对LLM个性的假设，并强调了在对齐和可解释性方面进行更深入评估的需求。", "innovation": "本研究系统地探讨了大型语言模型在三个维度上的个性：（1）从训练阶段动态出现和演变的人格特征概型；（2）自我报告特质在行为任务中的预测有效性；以及（3）目标干预措施（如RLHF和指令调整）对自我报告和行为的影响。研究通过区分表面的人格特征表现与实际行为一致性，揭示了LLM个性与人类数据之间的差异，并对现有假设进行了挑战。该研究强调了对LLM个性进行更深入和全面评估的重要性，特别是在对齐和可解释性方面。", "conclusion": "研究发现，指令对齐（如RLHF、指令调整）能够稳定并强化人格特征的表现和相关性，但自我报告的特质并不可靠地预测行为，实际行为与观察关联往往不同。同时，注入个性可以引导自我报告的方向，但对行为的影响有限或不一致。这项工作强调了区分表面人格特征表达和实际行为一致性的必要性，对LLM个性的认知推动了对其进行更深入研究的需求和可能性。"}
{"llm_update_time": "20250907", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2509.03986", "html_url": "https://arxiv.org/abs/2509.03986", "title": "Promptception: 大规模多模态模型对提示有多敏感？", "title_en": "Promptception: How Sensitive Are Large Multimodal Models to Prompts?", "authors": "Mohamed Insaf Ismithdeen,Muhammad Uzair Khattak,Salman Khan", "background": "尽管近年来大型多模态模型（LMMs）在多项选择题回答（MCQA）中的取得了一定的成就，但LMMs对提示的响应方式在目前的理解还不够深入。研究表明，提示语言和结构上的微小变化会导致模型的准确率发生高达15%的偏差。这种变化使得LMMs的评估变得不透明且不公正，因为模型常常通过精心挑选的提示来展示其最佳成绩。现有研究和实践中，仅从特定提示出发评价模型最佳性能的方法并不足够。因此，本文提出了一种名为Promptception的系统框架，以评估LMMs对提示的敏感性。", "innovation": "本文提出了Promptception，这是一个系统框架，旨在评估LMMs对提示的敏感度。该框架包含61种提示类型，覆盖15个类别和6个超类别，每个类型都针对提示形式的不同方面。研究还发现，私有模型对提示规定更为敏感，表明更紧密的指令语义对齐；而开源模型则较为稳定，但难以应对复杂和微妙的提示。基于这些发现，本文提出了针对私有和开源LMMs的提示原则，以提高模型评估的稳健性和公正性。", "conclusion": "本文通过Promptception框架揭示了LMMs对提示的敏感度，通过不同类型的私有和开源LMMs对MMStar、MMMU-Pro、MVBench三个MCQA基准测试的评估，展示了不同类型模型对提示的不同反应。基于此，提出了特定类型的LMMs的提示原则，旨在促进更公正和稳健的模型评估。"}
{"llm_update_time": "20250907", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2509.04393", "html_url": "https://arxiv.org/abs/2509.04393", "title": "基于上下文的令牌鉴别方法用于语音搜索查询更正", "title_en": "Contextualized Token Discrimination for Speech Search Query Correction", "authors": "Junyu Lu,Di Jiang,Mengze Hong,Victor Junqiu Wei,Qintian Guo,Zhiyang Su", "background": "语音搜索因其由自动语音识别(ASR)系统驱动的日益流行，对于现代搜索引擎来说，查询拼写纠正变得非常重要，因为它能有效帮助用户清晰表达意图。", "innovation": "该文介绍了一种名为Contextualized Token Discrimination (CTD)的新方法，用于有效纠正语音查询。首先，使用BERT生成上下文相关的令牌表示；然后构建一个组合层来增强语义信息；最后，根据聚合的令牌表示生成正确的查询，通过比较原始令牌表示和上下文相关表示进行误令牌的修正。", "conclusion": "广泛的实验表明，所提出的方法在所有指标上均表现出优越的性能，还提出了一个新的基准数据集，该数据集包含错误的ASR转录，以提供对音频查询纠正的全面评估。"}
{"llm_update_time": "20250907", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2509.04027", "html_url": "https://arxiv.org/abs/2509.04027", "title": "CoT-Space: 基于强化学习的内部慢思考理论框架", "title_en": "CoT-Space: A Theoretical Framework for Internal Slow-Thinking via Reinforcement Learning", "authors": "Zeyu Gan,Hao Yi,Yong Liu", "background": "机器学习中大型语言模型（LLMs）的推理能力得到了强化学习（RL）的显著提升。然而，传统的基于令牌级别的RL框架未能与复杂多步骤推理过程（如链式思考CoT）的推理层次保持一致，存在理论空白。为了弥补这一差距，研究引入了CoT-Space，这是一种将LLM推理从离散令牌预测任务重新定义为连续推理层次语义空间内的优化过程的新理论框架。该研究从噪声和风险两个角度对这一过程进行了分析，证明了最优化CoT长度是过度拟合与欠拟合根本权衡的自然结果。文中通过大量的实验证据进一步验证了理论发现的有效性，为解释过度思考等现象提供了统一的理论解释，并为未来更加有效和泛化的推理代理的研发提供了坚实基础。", "innovation": "提出了CoT-Space，一种创新的理论框架，将LLM推理从离散的令牌预测任务重新定义为连续的、基于推理层次的语义空间内的优化过程。通过噪声和风险角度的分析，证明了推理过程中的最优化长度是欠拟合与过度拟合之间权衡的结果。该框架能解释过度思考的现象，并为改进推理代理提供了理论基础。", "conclusion": "CoT-Space框架不仅能够为实验证据中的诸如过度思考等现象提供统一的理论解释，还为未来如何设计和优化更有效和泛化能力更强的推理代理奠定了坚实的基础。通过大量的实验证明，这种理论框架是有效的。"}
{"llm_update_time": "20250907", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2509.04072", "html_url": "https://arxiv.org/abs/2509.04072", "title": "LibriQuote：虚构人物台词的语音数据集，用于富有表现力的零样本语音合成", "title_en": "LibriQuote: A Speech Dataset of Fictional Character Utterances for Expressive Zero-Shot Speech Synthesis", "authors": "Gaspard Michel,Elena V. Epure,Christophe Cerisara", "background": "现有的大规模语音数据集使得文本到语音（TTS）系统能够生成更加富有表现力和自然的语音合成，但这些大量语料库中富有表现力的语音比例并不明确，并且现有的富有表现力的语音语料库通常规模较小，主要用作TTS系统的基准测试。论文介绍了LibriQuote数据集，这是一个源自有声书的英语语料库，旨在用于调整和基准测试富有表现力的零样本TTS系统。训练集包括12,700小时的非富有表现力的朗读语音和5,300小时的主要富有表现力的语音从来自人物引文。此外，还提供了一个具有挑战性的7.5小时测试集，用于基准测试TTS系统：给定中性的参考语音作为输入，评估系统生成富有表现力的语音并保留参考音色的能力。该测试集通过展示其涵盖了非富有表现力语音相比广泛的情绪范围和各种口音，得到了定性验证。", "innovation": "LibriQuote为TTS系统提供了用于调整和基准测试的富有表现力的零样本语音合成的数据集，其中包括广范围的情感和口音。该数据集通过结合听诵读文本和人物引文，提供了如何在朗读中表达情感的具体信息。测试集为基准测试TTS系统提供了新的挑战，评估系统在给中性参考语音基准时生成富有表现力语音的能力.", "conclusion": "使用基准TTS系统对LibriQuote进行调整显著提高了其合成语音的可理解性，现有的系统无法生成与实际情况一样富有表现力和自然的语音。该数据集和评估代码是免费提供的，语音样本可以在此处找到。"}
{"llm_update_time": "20250907", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2509.04403", "html_url": "https://arxiv.org/abs/2509.04403", "title": "自适应数据集构造以应对真实世界多模态安全场景", "title_en": "Self-adaptive Dataset Construction for Real-World Multimodal Safety Scenarios", "authors": "Jingen Qu,Lijun Li,Bo Zhang,Yichen Yan,Jing Shao", "background": "多模态大型语言模型（MLLMs）正在快速发展，带来越来越复杂的安全挑战。当前的数据集构建方法侧重于风险管理，但未能涵盖现实世界多模态安全场景（RMS）日益复杂的情况。由于缺乏统一的评估标准，它们的整体有效性仍未得到证明。", "innovation": "引入了一种基于图像的自适应数据集构建方法，以应对真实世界多模态安全场景。该方法以图像为起点，最终构建出包含文本和指导响应的成对数据集。自动生成一个包含35000个图像-文本对的数据集。此外，提出了一种标准化的安全数据集评估标准：对安全判别模型进行微调，并在其他安全任务上评估其能力。实验证明了基于图像的方法的有效性和可扩展性，提供了构建真实世界多模态安全数据集的新视角。", "conclusion": "实验结果验证了基于图像的方法在多模态安全数据集构建中的可扩展性和有效性，为解决现实世界中的多模态安全问题提供了新的研究方向。"}
{"llm_update_time": "20250907", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2509.04442", "html_url": "https://arxiv.org/abs/2509.04442", "title": "Delta Activations: 一种用于微调大型语言模型的表示方法", "title_en": "Delta Activations: A Representation for Finetuned Large Language Models", "authors": "Zhiqiu Xu,Amish Sethi,Mayur Naik,Ser-Nam Lim", "background": "强大的开源大型语言模型（LLMs）的成功使社区能够创建出多种针对特定任务和领域进行后训练的模型。然而，这些模型因元数据不一致和未结构化的仓库而难以导航和理解。", "innovation": "提出了一种名为Delta Activations的方法，通过测量相对于基模型的内部激活变化将微调模型表示为向量嵌入。这种方法可以有效按领域和任务进行聚类，揭示模型景观中的结构。Delta Activations还表现出跨微调设置的鲁棒性以及混合数据集的加性特性。此外，表明Delta Activations可通过少样本微调嵌入任务，且进一步探索其在模型选择和合并中的应用。", "conclusion": "希望Delta Activations能够促进公共模型的重用实践。相关代码可在该链接访问。"}
{"llm_update_time": "20250907", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2509.04404", "html_url": "https://arxiv.org/abs/2509.04404", "title": "没有思考只有AI：基于LLM的推荐偏向限制了简历筛选中的人类自主权", "title_en": "No Thoughts Just AI: Biased LLM Recommendations Limit Human Agency in Resume Screening", "authors": "Kyra Wilson,Mattea Sim,Anna-Maria Gueorguieva,Aylin Caliskan", "background": "本文研究了人类与模拟AI模型合作筛选简历的行为，这些AI模型具有基于种族的偏好（偏见），评估16种高地位和低地位职业的候选人。研究背景涉及人工智能系统中的偏见问题，以及这些偏见如何影响人类决策。通过实验设计，探讨人在AI系统存在或不存在种族偏好时的决策行为。该研究还特别关注了隐性联想测试(IAT)对决策的影响，隐性联想测试预测了歧视性招聘决策，但在此之前未在人类与AI合作的背景下进行研究。", "innovation": "本文创新性地将隐性联想测试(IAT)引入人类与AI合作的招聘决策情景中，研究了隐性联想测试(IAT)对决策者行为的影响，尤其是在AI系统表现出基于种族的偏见时。此外，该研究揭示了即使人们认为AI的建议质量较低或不重要，AI系统的偏见依然会影响人们在特定情境下的决策。这为理解AI-HITL（人类在环中技术）场景下的决策自主权提供了新的视角。", "conclusion": "本文的研究结果表明，在AI推荐存在偏见的情况下，即使人们意识到这些偏见，他们的决策也可能会受到AI偏见的影响。该研究表明，组织和监管政策在实施这些系统时，应当承认AI-HITL决策的复杂性，对使用AI系统的人员进行教育，并确定哪些系统需要监督。此外，该研究对设计和评估AI招聘系统以及减轻协作决策任务中的偏见提出了策略建议。"}
{"llm_update_time": "20250907", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2509.04343", "html_url": "https://arxiv.org/abs/2509.04343", "title": "心理增强型AI代理", "title_en": "Psychologically Enhanced AI Agents", "authors": "Maciej Besta,Shriram Chandran,Robert Gerstenberger,Mathis Lindner,Marcin Chrapek,Sebastian Hermann Martschat,Taraneh Ghandi,Patrick Iff,Hubert Niewiadomski,Piotr Nyczyk,Jürgen Müller,Torsten Hoefler", "background": "介绍了一种基于Myers-Briggs类型指标(MBTI)的心理学背景框架，通过个性条件化增强大型语言模型(LLM)代理的有效性。这个方法通过提示工程为代理提供独特的心理人格原型，控制行为沿认知和情感这两个心理学基础维度。论文展示了人格预热在不同任务中的一致和可解释的行为偏差：情绪表达强烈的代理在叙事生成中表现出色，而分析性预热的代理在博弈论环境中更具稳定性。框架支持多智能体通信协议的结构化实验，并表明在交互前进行自我反思可以提升合作和推理质量。为了确保特性持久性，引入了官方16个人格性格测试进行自动验证。此方法不仅可以应用于MBTI，还可以无缝扩展到其他心理学框架，如大五人格、六角模型或九型人格。通过将心理理论与LLM行为设计相结合，为无微调的心理增强型AI代理奠定了基础。", "innovation": "提出了一种基于MBTI的心理学增强框架，通过个性条件化提高大型语言模型代理的有效性。这种方法采用提示工程技术来引导代理具有特定的人格原型，从而在对话中控制行为的两个关键维度——认知和情感。此外，该框架还揭示了在交互前进行自我反思可以改善合作和推理质量，并通过整合16个人格性格测试来确保个性特征的持久性。这种方法不仅适用于MBTI，还可以应用于其他心理学框架。论文通过将心理理论和LLM行为设计相结合，为增强型AI代理的发展奠定了基础。", "conclusion": "通过MBTI或其他心理学框架，实现代理的个性化预热来控制其行为，无需微调就达到了增强AI代理的目标。这种方法提供了一个通用的基础框架，为未来的多智能体交互研究提供了可能。"}
{"llm_update_time": "20250907", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2509.04419", "html_url": "https://arxiv.org/abs/2509.04419", "title": "向大型语言模型后训练统一视角迈进", "title_en": "Towards a Unified View of Large Language Model Post-Training", "authors": "Xingtai Lv,Yuxin Zuo,Youbang Sun,Hongyi Liu,Yuntian Wei,Zhekai Chen,Lixuan He,Xuekai Zhu,Kaiyan Zhang,Bingning Wang,Ning Ding,Bowen Zhou", "background": "现有大型语言模型的后训练数据来源主要有两种：在线（模型生成的回放）数据和离线（人类或模型示例）数据。传统的方法，如强化学习（Reinforcement Learning，RL）和监督微调（Supervised Fine-Tuning，SFT），分别侧重于利用这两种数据。但本文指出，这两种方法并非相互排斥，而是同一种优化过程的不同表现形式。", "innovation": "本文提出了一种统一的策略梯度估计方法，并展示了不同数据分布假设下广泛后训练方法的梯度估计是同一优化目标的不同变种。此外，作者还提出了一种新的算法——混合后训练（Hybrid Post-Training，HPT），可以动态选择不同的训练信号，既能高效利用示例，又能稳定探索，同时保持学习到的推理模式。", "conclusion": "为了验证统一理论框架和HPT算法的有效性，本文进行了详尽的实验和消融研究，并在六个数学推理基准和两个离分布算法套件中，无论模型规模和类型如何，HPT均优于强基线。"}
{"llm_update_time": "20250907", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2109.02325", "html_url": "https://arxiv.org/abs/2109.02325", "title": "MyProfessors: 开采土耳其学生评价", "title_en": "MyProfessors: Mining Turkish Student Reviews", "authors": "Ibrahim Faruk Ceylan,Necmettin Bera Calik", "background": "论文介绍了Hocalarim（MyProfessors），这是目前市面上可用的最大的土耳其语学生评价数据集。数据集包含超过5000条由学生在线留下的教师评价，这些评价对教育的不同方面给出了1到5星级的评分。研究者对数据集的特性和统计数据进行了分析，同时探讨了学生所在院校类型对其评分的影响以及学生偏见与给予正面或负面反馈之间的相关性。", "innovation": "该研究创新之处在于首次构建了一个大规模的土耳其语学生评价数据集，并通过统计分析探讨了多个相关问题，如评分的一致性、学生背景对其评价的影响等，填补了该领域在土耳其语数据上的空白，为后续研究提供了基础数据支持。", "conclusion": "研究结果表明，学生所在院校类型显著影响其对教授的评分。此外，学生的个人偏见也与他们给予正面或负面反馈有关。这些发现对教育评价的研究和教育政策产生了一定的影响。"}
{"llm_update_time": "20250907", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2509.04439", "html_url": "https://arxiv.org/abs/2509.04439", "title": "ArcMemo：具有终身LLM记忆的抽象推理组合", "title_en": "ArcMemo: Abstract Reasoning Composition with Lifelong LLM Memory", "authors": "Matthew Ho,Chen Si,Zhaoxiang Feng,Fangxu Yu,Zhijian Liu,Zhiting Hu,Lianhui Qin", "background": "在推理时进行缩放使得预训练语言模型能够进行越来越长和复杂的推理过程，但每次新的查询开始时，推理过程中发现的模式和见解会被丢弃。外部记忆是存储这些发现的自然方式，尤其是对于需要大量推理的任务，先前的工作已经展示了其明显的益处。本文提出通过从实例级记忆（例如确切的问题/回答对或紧密耦合的原始问题上下文的摘要）转向概念级内存（即提取自解决方案痕迹的可重用模块化抽象并以自然语言存储）来让记忆更加广泛地重用和扩展。", "innovation": "本文提出了一种名为ArcMemo的设计，该设计能够从推理过程中提取可重用的概念级记忆，并在未来的查询中根据需要检索这些概念并将其集成到提示中，实现测试时的持续学习而无需权重更新。该设计还引入了从扩展中抽象出见解并为新查询检索条目的新策略，从而促进重用并允许记忆在额外的经验中扩展。在ARC-AGI基准测试中，该方法在没有记忆的强基线基础上获得了7.5%的相对收益，并且性能随着推理计算量的增加而持续增长。我们发现抽象概念是最一致的记忆设计，并且测试时动态更新记忆优于固定记忆设置，进一步支持了解决更多问题并抽象更多模式以加强的记忆机制。", "conclusion": "在ARC-AGI基准测试中，ArcMemo方法在没有记忆的强基线基础上取得了7.5%的相对收益，并且表现随着推理计算量的增加而持续增长。我们发现抽象概念是最一致的记忆设计，并且测试时动态更新记忆优于固定记忆设置，支持了解决更多问题和抽象更多模式以实现自我改进的假设。"}
{"llm_update_time": "20250907", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2305.06166", "html_url": "https://arxiv.org/abs/2305.06166", "title": "通过基于提示的文本转换减轻文本分类中的偏见", "title_en": "Mitigating Bias in Text Classification via Prompt-Based Text Transformation", "authors": "Charmaine Barker,Dimitar Kazakov", "background": "特定子群体特有的语言信号在训练过程中会变得对语言模型非常显著。在自动化决策系统中，如果模型依赖与保护特征高度相关的线索，可能会导致偏见的结果。本文研究了通过提示ChatGPT简化、中性化、本地化和正式化重写文本是否可以减少隐含的民por分信号同时保持文本的核心意义。", "innovation": "本文提出了通过提示基编辑方法来减少文本分类中的偏见，具体来说，就是对ChatGPT进行提示，使其对文本进行简化、中性化、本地化和正式化的重写。这种方法旨在降低对特定群体语言的依赖，同时保持文本的基本意义。", "conclusion": "实验结果表明，在多个模型中，地理位置分类的准确性有显著下降，这表明减少了对特定群体语言的依赖。同时，情感分析和评分预测任务表明，评论的核心内容基本保持完整。因此，基于提示的重写方法提供了一种实用且可推广的减轻文本分类中偏见的方法。"}
{"llm_update_time": "20250907", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2306.03774", "html_url": "https://arxiv.org/abs/2306.03774", "title": "探索土耳其文本可读性的语言学特征", "title_en": "Exploring Linguistic Features for Turkish Text Readability", "authors": "Ahmet Yavuz Uluslu,Gerold Schneider", "background": "这是首次对土耳其文本自动可读性评估进行全面研究的论文。研究使用了最先进的神经网络模型，并结合了词汇、形态学、句法和话语层面上的语言特征，开发了一种高级别的可读性工具。此外，研究还对比了传统可读性公式与现代自动化方法的有效性，并确定了决定土耳其文本可读性的关键语言特征。", "innovation": "首次全面研究了土耳其文本的自动可读性评估；结合了最先进的神经网络模型和四层语言特征；对比了传统方法与现代自动化方法的有效性；识别出关键语言特征以决定土耳其文本的可读性。", "conclusion": "研究展示了通过神经网络模型和多层面语言特征结合，开发了一个先进的可读性工具。同时，研究结果表明传统可读性公式在某些方面仍然具有一定的优越性，而现代自动化方法提供了更多灵活性。"}
{"llm_update_time": "20250907", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2406.01359", "html_url": "https://arxiv.org/abs/2406.01359", "title": "R2C2-Coder: Enhancing and Benchmarking Real-world Repository-level Code Completion Abilities of Code Large Language Models", "title_en": "R2C2-Coder: Enhancing and Benchmarking Real-world Repository-level Code Completion Abilities of Code Large Language Models", "authors": "Ken Deng,Jiaheng Liu,He Zhu,Congnan Liu,Jingxin Li,Jiakai Wang,Peng Zhao,Chenchen Zhang,Yanan Wu,Xueqiao Yin,Yuanxing Zhang,Zizheng Zhan,Wenbo Su,Bangyu Xiang,Tiezheng Ge,Bo Zheng", "background": "近年来，代码补全模型取得了显著进展，特别是在现代软件开发中，对仓库级别的代码补全越来越受到关注，已有若干基线方法和基准被提出。然而，现有的仓库级别代码补全方法未能充分利用项目仓库中的广泛上下文，比如相关文件的复杂性和类层次结构等。此外，现有的基准通常仅关注有限的代码补全场景，无法很好地反映现有方法的仓库级代码补全能力。", "innovation": "本文提出了R2C2-Coder，旨在增强和基准化代码大语言模型的现实仓库级别代码补全能力。R2C2-Coder包括一种代码提示构建方法R2C2-Enhance和一个精心设计的基准R2C2-Bench。首先，在R2C2-Enhance中，构建候选检索池并通过检索池获取每个完成光标位置的完成提示。此外，基于R2C2-Enhance构建了一个更具挑战性和多样性的R2C2-Bench，其中提出了上下文扰动策略以更好地模拟现实世界的仓库级别代码补全。", "conclusion": "多项基准上的广泛结果表明了R2C2-Coder的有效性。"}
{"llm_update_time": "20250907", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2509.04438", "html_url": "https://arxiv.org/abs/2509.04438", "title": "电话游戏：评估统一模型中的语义漂移", "title_en": "The Telephone Game: Evaluating Semantic Drift in Unified Models", "authors": "Sabbir Mollah,Rohit Gupta,Sirnam Swetha,Qingyang Liu,Ahnaf Munir,Mubarak Shah", "background": "研究领域中出现了一种新的方向，即使用单一、统一模型（UM）来处理视觉理解和视觉生成任务（包括图像到文本和文本到图像）。虽然这些模型可以支持其他单一模态任务（如文本到文本、图像到图像），但该研究集中于图像到文本（I2T）和文本到图像（T2I）之间的交叉模态对。现有的评估方法单独考虑这些能力，如T2I使用FID和GenEval，I2T使用MME和MMBench等基准，但这些单次评估未能揭示模型理解概念后能否准确呈现，或者在图像和文本模态之间切换时意义是否被保全。因此，该研究引入了一个新的评估框架，名为统一一致性框架（UCF-UM），这是一种循环评估协议，交替进行I2T和T2I，以量化语义漂移。", "innovation": "研究引入了UCF-UM框架，它包括以下三个方面：(i) 平均累积漂移（MCD），一个基于嵌入的整体语义损失度量；(ii) 语义漂移率（SDR），总结语义衰退速率；(iii) 多轮次生成评估（MGG），一个基于对象级别的合规性评分，扩展了GenEval。此外，研究还提出了一个名为ND400的新基准测试数据集，从NoCaps和DOCCI中采样，以评估模型在超越COCO的基础上的泛化能力。该研究的结果展示了不同模型在跨模态稳定性上的显著差异，并强调了循环一致性评估在模型一致性评估中的必要性。", "conclusion": "研究结果表明，循环一致性是衡量统一模型跨模态稳定性和共享表示强度的必要补充，提供了实用的评估模型指标。这些结果有助于评估统一模型的跨模态稳定性，为VLM领域的其他研究提供了新的视角。"}
{"llm_update_time": "20250907", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2411.01747", "html_url": "https://arxiv.org/abs/2411.01747", "title": "DynaSaur: 大型语言模型代理超越预定义行动", "title_en": "DynaSaur: Large Language Agents Beyond Predefined Actions", "authors": "Dang Nguyen,Viet Dac Lai,Seunghyun Yoon,Ryan A. Rossi,Handong Zhao,Ruiyi Zhang,Puneet Mathur,Nedim Lipka,Yu Wang,Trung Bui,Franck Dernoncourt,Tianyi Zhou", "background": "现有的LLM代理系统通常在每个步骤中从固定且预先定义的行动集中选择行动。这种做法在封闭且局限范围的环境中非常有效，但在真实世界的、开放的场景中面临两大挑战：（1）显著限制了LLM代理的规划和行动能力；（2）需要大量的手工努力来列举和实现所有可能的行动，这在具有大量潜在行动的复杂环境中是不切实际的。", "innovation": "我们提出了一种LLM代理框架，该框架能够根据需要动态地创建和组合行动。在这种框架中，代理通过生成和执行使用通用编程语言编写的程序来与其环境互动。此外，生成的行动会随着时间的推移积累，以便将来重用。广泛的实验表明，该框架显著提高了灵活性并超越了依赖固定行动集的先前方法。它使LLM代理能够在预定义行动不足或因未预见的边缘情况失败时适应和恢复。", "conclusion": "我们的实验结果表明，这种框架能够显著提升LLM代理的灵活性，并在复杂环境中表现优于基于固定行动集的方法。该框架能够使代理在面对未预见场景时能够适应和恢复，而不需要人为干预来动态生成和执行行动。此外，相关代码可以在提供的链接中找到进行进一步研究。"}
{"llm_update_time": "20250907", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2501.13958", "html_url": "https://arxiv.org/abs/2501.13958", "title": "Graph Retrieval-Augmented Generation for Customized Large Language Models", "title_en": "A Survey of Graph Retrieval-Augmented Generation for Customized Large Language Models", "authors": "Qinggang Zhang,Shengyuan Chen,Yuanchen Bei,Zheng Yuan,Huachi Zhou,Zijin Hong,Hao Chen,Yilin Xiao,Chuang Zhou,Yi Chang,Xiao Huang", "background": "大规模语言模型（LLMs）在广泛任务中展现了突出的能力，但在特定领域的应用仍然面临挑战，因为需要深厚的专业知识。传统的检索增强生成（RAG）系统基于扁平文本检索，存在三个关键挑战：专业语境下的复杂查询理解、分布式来源知识集成的难度以及大规模下的系统效率瓶颈。", "innovation": "Graph-RAG通过三大创新解决传统RAG系统的挑战：（i）以图结构的知识表示体现实体关系和领域层次结构；（ii）高效基于图的检索技术，支持上下文保持的知识检索和多跳推理能力；（iii）结构感知的知识集成算法，利用检索出的知识来生成准确和逻辑连贯的大型语言模型。", "conclusion": "本文系统分析了Graph-RAG的技术基础及在不同专业领域的应用，揭示了关键的技术挑战并指出了未来的研究方向。所有相关的Graph-RAG资源，包括研究论文、开源数据和项目等，都汇集于 https://cohere.com/graphRAG。"}
{"llm_update_time": "20250907", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2501.11110", "html_url": "https://arxiv.org/abs/2501.11110", "title": "链式推理：通过多范式视角实现大型语言模型的统一数学推理", "title_en": "Chain-of-Reasoning: Towards Unified Mathematical Reasoning in Large Language Models via a Multi-Paradigm Perspective", "authors": "Yiyao Yu,Yuxiang Zhang,Dongdong Zhang,Xiao Liang,Hengyuan Zhang,Xingxing Zhang,Ziyi Yang,Mahmoud Khademi,Hany Awadalla,Junjie Wang,Yujiu Yang,Furu Wei", "background": "大型语言模型（LLMs）在数学推理领域取得了显著进展，但往往依赖单一范式推理，这限制了它们在多样任务中的有效性。", "innovation": "提出了链式推理（CoR），这是一种将自然语言推理（NLR）、算法推理（AR）和符号推理（SR）等多种推理范式整合的新型统一框架，使其能够在多种推理范式间实现协同工作。CoR 通过不同范式生成多种潜在答案，并将其综合成一个连贯的最终解决方案。提出了渐进式范式训练（PPT）策略，使模型能够逐步掌握这些范式，构建出 CoR-Math-7B 模型。", "conclusion": "实验结果表明，CoR-Math-7B 在定理证明方面相较于当前最佳模型（GPT-4o）取得了高达 41.0% 的绝对性能提升，在数学基准测试 MATH 的算术任务中，相比基于 RL 的方法也有 15.0% 的改进。这些结果展示了模型增强的数学理解能力，使其能够实现零样本泛化。"}
{"llm_update_time": "20250907", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2411.12736", "html_url": "https://arxiv.org/abs/2411.12736", "title": "ACING：黑箱大语言模型中指令学习的演员-评论家方法", "title_en": "ACING: Actor-Critic for Instruction Learning in Black-Box LLMs", "authors": "Salma Kharrat,Fares Fourati,Marco Canini", "background": "大型语言模型（LLMs）在执行任务上的效果高度依赖于其指令的质量，而这些指令往往需要大量的手工编辑。因此，自动优化指令的需求变得尤为迫切。但当使用黑箱大语言模型（即模型参数和梯度不可访问）时，指令优化面临重大挑战。为此，本文探讨了如何利用仅通过黑箱反馈来探索无限指令空间的方法，以发现优于人类编写指令的提示，从而解决这一问题。", "innovation": "本文提出了ACING（Actor-Critic for Instruction Learning in Black-Box LLMs），这是一种基于演员-评论家强化学习框架，将指令优化转化为一个无状态的、连续动作问题，从而利用仅有的黑箱反馈来探索无限的指令空间。ACING自动发现了在76%的任务中优于人工编写指令的提示，并在33项跨指令生成、总结和因果推理的任务中，相对于当前最佳自动基线，有高达33分点的提升，中位数提升为10分。此外，大量的消融实验还展示了其鲁棒性和高效率。", "conclusion": "ACING能够自动发现优于人工编写指令的提示，并通过大量实验验证了其在多个任务上的有效性和鲁棒性，表明了其在指令自动化最优中的潜力。相关实现已经开源。"}
{"llm_update_time": "20250907", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2502.05982", "html_url": "https://arxiv.org/abs/2502.05982", "title": "HamRaz: 采用LLM代理基于文化的人工 Persian对话数据集用于以人本为中心的治疗", "title_en": "HamRaz: A Culture-Based Persian Conversation Dataset for Person-Centered Therapy Using LLM Agents", "authors": "Mohammad Amin Abbasi,Farnaz Sadat Mirnezami,Ali Neshati,Hassan Naderi", "background": "在人工智能支持的心理健康支持领域，缺乏针对特定文化背景的高质量数据集。本文基于人本中心疗法（PCT），构建了一个适应特定文化的波斯语数据集HamRaz，以应对现实世界中的治疗挑战，同时捕捉波斯语使用者的复杂情感和语言表述特点。该数据集的构建为数字人文研究贡献了一个新的视角，促使研究关注语言、文化和心理健康之间的联系，特别是在未被充分代表的社群中。", "innovation": "本文提出了HamRaz，一个基于文化适应的波斯语数据集，通过结合脚本驱动对话和适应性大规模语言模型（LLM）角色扮演，捕捉波斯语使用者的复杂情感和语言表述。此外，还引入了HamRazEval评估框架，用于测量对话质量和治疗效果。实验证明，HamRaz在同理心、连贯性和真实性方面优于现有基准数据集，这表明该数据集在心理健康支持中的高价值。", "conclusion": "HamRaz数据集为AI辅助心理健康支持提供了一个有价值的资源，特别是在为未被充分代表的波斯语社群提供准确和敏感的心理健康服务方面。该数据集和评估方法为数字人文领域开辟了新的研究空间，促进了跨文化交流和心理健康的深入研究。"}
{"llm_update_time": "20250907", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2501.04316", "html_url": "https://arxiv.org/abs/2501.04316", "title": "小变化，大后果：分析大语言模型在招聘环境中的配置公平性", "title_en": "Small Changes, Large Consequences: Analyzing the Allocational Fairness of LLMs in Hiring Contexts", "authors": "Preethi Seshadri,Hongyu Chen,Sameer Singh,Seraphina Goldfarb-Tarrant", "background": "大语言模型（LLMs）在高风险应用场景，如招聘中越来越得到部署，但它们在生成和检索设置下的潜在不公平决策问题仍然研究不足。这项研究旨在通过两种反映实际人力资源使用情况的任务——简历总结和求职者排序，来评估LLM驱动招聘系统中的分配公平性。通过构建一个带有可控扰动的合成简历数据集，并整理职位发布信息，研究者探讨了模型行为在不同人口统计群体间的差异。研究表明，生成的摘要在种族扰动方面表现出意则的差异更频繁，而在性别扰动方面则较少。模型还显示出非均匀的检索选择模式，对性别和种族扰动表现出高排名敏感性。出人意料的是，检索模型对人口统计和非人口统计变化都表现出相似的敏感性，这表明公平性问题可能源自更广泛的模型缺陷。", "innovation": "研究通过合成简历数据集和精确控制扰动的方法，评估了LLM驱动招聘系统在种族和性别方面的分配公平性，尤其是在生成和检索阶段，发现了模型在不同人口统计群体间的显著偏差和敏感性，尤其是检索模型表现出对非人口统计变化的高度敏感性，这暗示了更广泛的模型脆弱性可能导致公平性问题。", "conclusion": "研究结果表明，基于LLM的招聘系统，尤其是在检索阶段，可能会表现出显著的偏见，导致实际操作中的歧视性结果。"}
{"llm_update_time": "20250907", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2501.14701", "html_url": "https://arxiv.org/abs/2501.14701", "title": "一种无需监督的自然语言处理管道，用于评估转诊合适性", "title_en": "An Unsupervised Natural Language Processing Pipeline for Assessing Referral Appropriateness", "authors": "Vittorio Torri,Annamaria Bottelli,Michele Ercolanoni,Olivia Leoni,Francesca Ieva", "background": "评估转诊的适宜性对于提高医疗服务效率和减少不必要的程序至关重要。然而，当转诊原因仅记录为自由文本而不是结构化代码时，这一任务变得具有挑战性，尤其是在意大利国家卫生服务系统中。为了应对这一差距，该研究提出了一种完全无需监督的自然语言处理（NLP）管道，能够不依赖于带标注的数据集来提取和评估转诊原因，以确保其与适宜性指南的一致性。该管道在两个来自伦巴第地区的完整数据集上进行了测试，涵盖了静脉下肢多普勒超声和肠镜检查的数据。", "innovation": "该研究提出了一个完全无需监督的NLP管道，利用预训练于意大利医学文本的转换器嵌入，对转诊原因进行聚类和评估其与适宜性指南的一致性。这一无需监督的设置使得该管道适用于不同检查类型的推广，并能够在大规模真实世界数据集上实现有效的评估和监测功能。研究成果提供了指导性建议，并增强了伦巴第地区的指南遵守情况。", "conclusion": "该研究展示了如何利用大规模真实世界数据集，通过无需监督的NLP管道评估转诊适宜性。这为公共健康机构提供了一种可部署的人工智能工具，以监测实践和支持基于证据的政策。"}
{"llm_update_time": "20250907", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2502.11948", "html_url": "https://arxiv.org/abs/2502.11948", "title": "HalluEntity：实体层面幻觉检测的基准测试和理解", "title_en": "HalluEntity: Benchmarking and Understanding Entity-Level Hallucination Detection", "authors": "Min-Hsuan Yeh,Max Kamachee,Seongheon Park,Yixuan Li", "background": "目前，许多研究提出通过不确定性评估来检测LLMs的幻觉生成。然而，这些方法大多在句子或段落层面进行操作，无法准确指出导致幻觉内容的具体词汇或实体。对于包含准确和虚构信息的长文本，这种粒度较低的问题尤为突出。因此，关于实体层面的幻觉检测仍是研究空白。", "innovation": "该研究提出了一个新的数据集HalluEntity，旨在标注幻觉内容到实体层面。基于此数据集，该研究全面评估了17个现代LLM上基于不确定性的幻觉检测方法。研究发现，关注单个词概率的不确定性估计方法倾向于高估幻觉，而基于上下文的方法显示了更好的但仍然欠佳的性能。此外，该研究通过深入的定性研究，指出了幻觉倾向与语言属性之间的关系，并为未来的研究指明了重要方向。", "conclusion": "研究结果表明，尽管基于上下文的方法在幻觉检测方面表现更好，但仍存在局限性。未来的研究需要探索更精细的粒度方法，以及考虑更广泛的语言属性与幻觉之间的关系。"}
{"llm_update_time": "20250907", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2502.14791", "html_url": "https://arxiv.org/abs/2502.14791", "title": "快速通过元内联系学习新词", "title_en": "Rapid Word Learning Through Meta In-Context Learning", "authors": "Wentao Wang,Guangyuan Jiang,Tal Linzen,Brenden M. Lake", "background": "人类能够从少量示例快速学习新词，并能够系统和灵活地在新语境中使用它。然而，当前语言模型在少量示例下的新词学习能力及其提升方法尚未得到充分研究。", "innovation": "介绍了名为Minnow的新方法，该方法通过给定少量语境中的示例来训练语言模型，以生成新词的使用实例，并使用特殊占位符标记新词。这种方法通过多次训练多种新词的使用模式，开发了一种通用的新词学习能力。", "conclusion": "从少量人规模训言语迁移学习中使用Minnow训练语言模型能够实现强大的少量示例新词学习，效果与预训练数据量极大的大型语言模型相当。此外，通过判别性评估与生成性评估，研究显示使用Minnow微调预训练的语言模型，能够提升它们在区分新词、识别新词的语法类别以及基于少量语境示例生成合理的新用法和定义方面的性能。这些发现突显了Minnow的数据效率及其在语言模型中的潜在改进作用。"}
{"llm_update_time": "20250907", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2502.12616", "html_url": "https://arxiv.org/abs/2502.12616", "title": "通过 quasi-符号抽象改进链式思考推理", "title_en": "Improving Chain-of-Thought Reasoning via Quasi-Symbolic Abstractions", "authors": "Leonardo Ranaldi,Marco Valentino,Andrè Freitas", "background": "链式思考（CoT）是大型语言模型（LLMs）中一种常用的推理策略，通过将复杂的任务分解为中间推理步骤来进行。然而，通过CoT生成的解释容易受到内容偏见的影响，这会降低其鲁棒性和真实性。尽管最近的工作提出使用逻辑形式化与外部符号求解器相结合来缓解这些问题，但这种方法存在全部从自然语言到形式语言转换的瓶颈，影响了效率和灵活性。", "innovation": "本文提出了QuaSAR（类符号抽象推理），这是一种改进的CoT方法，通过类符号解释引导LLMs进行更高层次的抽象推理，只对相关变量和谓词进行形式化，从而实现符号元素和自然语言的共存。实验结果表明，类符号抽象可以提高基于CoT的方法的准确率高达8%，在自然语言（如MMLU-Redux）和符号推理任务（如GSM-Symbolic）的挑战性对抗变体中增强鲁棒性和一致性。", "conclusion": "通过QuaSAR方法，可以部分形式化自然语言推理，既保留了符号推理的准确性，又增强了灵活性和效率，从而提高了LLMs的推理性能和鲁棒性。"}
{"llm_update_time": "20250907", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2502.12065", "html_url": "https://arxiv.org/abs/2502.12065", "title": "自然界的自动形式化：评估LLM在现实世界数学定义上的表现", "title_en": "Autoformalization in the Wild: Assessing LLMs on Real-World Mathematical Definitions", "authors": "Lan Zhang,Marco Valentino,Andre Freitas", "background": "由于自然语言处理（NLP）模型（LLMs）具备语言能力，它们为实现非正式数学与形式语言之间的转换提供了机会，这一过程被称为自动形式化。然而，关于LLMs在这方面的泛化能力，特别是面对复杂且自然出现的数学语句时的真实世界能力，仍然存在不确定性。因此，需要探索不同模型在这方面的适应性。", "innovation": "该研究通过引入两个新的资源（Def_Wiki和Def_ArXiv）收集现实世界的数学定义，并且系统性地评估了多种LLMs的形式化能力。此外，研究还探索了两个增强策略：通过来自证明助手的外部反馈进行的精细化和基于相关数学库内容的形式定义根本化。结果表明，与现有的基准（如miniF2F）相比，定义形式化更为困难，但结构化的精细化方法和形式定义根本化策略显著提高了自我校正能力和减少了未定义错误的次数。", "conclusion": "尽管LLMs在自动形式化方面取得了进展，但仍存在改进空间，尤其是在自我校正和与相关数学库的对齐方面。研究结果为增强基于LLM的自动形式化在现实场景中的应用提供了有价值的见解。"}
{"llm_update_time": "20250907", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2503.09454", "html_url": "https://arxiv.org/abs/2503.09454", "title": "显性学习与LLM在机器翻译中的作用", "title_en": "Explicit Learning and the LLM in Machine Translation", "authors": "Malik Marmonier,Rachel Bawden,Benoît Sagot", "background": "这项研究探讨了语言模型（LLM）使用语法书中的解释学习新语言的能力，这一过程被称作显性学习。为了严谨评估这一能力，研究设计了英与通过特定加密方式从拉丁语或法语生成的构想语言之间的翻译实验。与以往研究不同，结果表明LLM确实具备一定量的显性学习能力。但随着需学习语言现象复杂性的增加，这种能力会逐渐减弱。监督微调尽管可以显著增强LLM的性能，但对于更类型新颖或复杂的语言特性，其泛化能力仍然受限。", "innovation": "研究设法通过设计控制实验来评估LLM的显性学习能力，并发现在特定条件下，显性学习是可能实现的。研究表明，尽管LLM表现出一定的显性学习能力，但此能力随着学习内容复杂性的增加而减弱。此外，监督微调可以提高LLM的性能，但难以泛化到更复杂的语言特征。", "conclusion": "这些发现指出了需要采用更多样化的训练集和替代微调策略以进一步提升LLM的显性学习能力，特别是对通常在语法书中描述但缺乏广泛语料的低资源语言。"}
{"llm_update_time": "20250907", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2504.12311", "html_url": "https://arxiv.org/abs/2504.12311", "title": "多源视觉提示最佳组合学习", "title_en": "Learning Optimal Prompt Ensemble for Multi-source Visual Prompt Transfer", "authors": "Jianhua Liu,Liwen Cao,Yanru Wu,Zijie Zhao,Yang Li", "background": "提示调优作为一种轻量级策略，适用于将基础模型适应下游任务，特别适用于资源受限系统。随着预训练提示变得有价值，通过结合多个源提示来增强新任务的一般化性能成为一个有前途的方法，借助互补知识。然而，简单的综合常常忽略了不同源提示对目标任务有不同的贡献潜力。", "innovation": "我们提出了HGPrompt，一种动态框架，用于学习最优提示组合权重。这些权重是通过同时最大化转移性信息指标并最小化梯度冲突进行优化的，采用一种新型的正则化策略。HGPrompt提出了一种可微分的提示转移性指标，用于捕捉目标任务中由提示诱导特征的判别性，同时基于Hessian和Fisher信息匹配不同源提示的梯度方差，确保稳定的、一致的知识转移，同时抑制它们之间的梯度冲突。上述创新方法在大规模VTAB基准测试中展示了HGPrompt的出色性能，验证了其在有效多源提示转移学习中的有效性。", "conclusion": "实验结果表明，HGPrompt在多源提示转移学习中达到了最先进的性能，验证了其在学习最优组合以实现有效多源提示转移的有效性。"}
{"llm_update_time": "20250907", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2502.18452", "html_url": "https://arxiv.org/abs/2502.18452", "title": "FRIDA救援！分析基于对象的常识推理中合成数据的有效性", "title_en": "FRIDA to the Rescue! Analyzing Synthetic Data Effectiveness in Object-Based Common Sense Reasoning for Disaster Response", "authors": "Mollie Shichman,Claire Bonial,Austin Blodgett,Taylor Hudson,Francis Ferraro,Rachel Rudinger", "background": "在灾害救援场景中的人机交互中，大型语言模型（LLMs）具有潜在的物理推理能力，能辅助实现任务目标。然而，这些能力通常仅存在于较大的模型中，但由于尺寸限制，当前难以在机器人系统上部署。我们为此引入了一个数据集和管道，用于创建Field Reasoning and Instruction Decoding Agent (FRIDA)模型。通过结合领域专家和语言学家的知识，我们制作了高质量的少样本提示，以生成精细调整所需的合成数据。为了测试这些模型，我们精心制作了数据集，并进行了消融研究以理解哪些类型的合成数据对性能影响最大。通过精细调整几个小型指令模型，我们发现，仅使用对象物理状态和功能数据的削减版FRIDA模型在评估中超越了使用所有合成数据训练的FRIDA模型和基本模型。我们展示了，FRIDA管道能够通过少量数据培养物理常识能力，从而大幅提高任务执行效率。", "innovation": "本文创新点在于提出了一种针对灾害救援场景的数据集和管道，用于训练能进行物理推理的FRIDA模型。通过精细调整模型并在少样本提示下生成合成数据，提高了LLMs在对象物理常识推理方面的性能。此外，通过消融研究确定了对模型性能影响最大的合成数据类型，从而优化了后续模型训练过程。", "conclusion": "FRIDA管道通过少量数据成功培养了物理常识能力，表明在资源有限的灾害救援环境中高效训练强大AI模型的方法是可行的。"}
{"llm_update_time": "20250907", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2503.16561", "html_url": "https://arxiv.org/abs/2503.16561", "title": "FutureGen：一种基于RAG的方法生成科学论文的未来工作", "title_en": "FutureGen: A RAG-based Approach to Generate the Future Work of Scientific Article", "authors": "Ibrahim Al Azher,Miftahul Jannat Mokarrama,Zhishuai Guo,Sagnik Ray Choudhury,Hamed Alhoori", "background": "科学论文的未来工作部分通过识别当前研究的空白和限制来提出潜在的研究方向。这部分内容为早期职业生涯的研究者提供了探索未开发领域的机会，并为经验丰富的研究人员提供了寻找新项目或合作的机会。这篇研究通过使用RAG结合大型语言模型（LLMs）来生成未来工作的建议，以提供更加广泛的见解。并且通过一个LLM反馈机制来提高生成内容的质量，还引入了一个LLM作为评判者框架来对生成的内容进行稳定评估。", "innovation": "研究使用了RAG（检索增强生成）来结合各种大型语言模型，以提供更加广泛的见解，并通过LLM反馈机制增强生成内容的质量。进一步引入了LLM作为评判者框架，评估生成内容的创新性、虚构性和可行性。结果表明，基于GPT-4o mini的RAG方法结合LLM反馈机制，与其他基于LLM的方法相比，在定性和定量评估中表现更优。", "conclusion": "研究结果表明，基于GPT-4o mini的RAG方法结合LLM反馈机制在生成科学论文未来工作方面表现更优。同时，通过人类评估进一步验证了LLM在提取、生成和反馈提供方面的能力。"}
{"llm_update_time": "20250907", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2503.21080", "html_url": "https://arxiv.org/abs/2503.21080", "title": "EQ-Knight: 增强记忆的LLM代理在债务追收中战略情感博弈", "title_en": "EQ-Knight: A Memory-Augmented LLM Agent for Strategic Affective Gaming in Debt Recovery", "authors": "Yunbo Long,Yuhan Liu,Liming Xu,Alexandra Brintrup", "background": "基于大型语言模型的聊天机器人在金融谈判中提升了参与度，但过度依赖被动共情在信用追收中引入了关键风险。虽然共情驱动的方法在良性案例中保持了客户的满意度，但在面对不诚实的债务人时会灾难性地失败——这些债务人利用和解战术来操控条款或逃避偿还。盲目追求“客户体验”会导致债权人面临风险，如收入流失、道德风险和系统性剥削。", "innovation": "我们提出了一种名为EQ-Knight的LLM代理，能够动态优化情感策略以捍卫债权人的利益。EQ-Knight集成了情感记忆和博弈论推理，并通过隐藏马尔可夫模型（HMM）跟踪和预测债务人的情感状态。它通过分析实时和历史的情感线索，战略性地对抗负面情感（如侵略、假装痛苦）的同时保持与债务人的生产性关系。实验表明，与传统的LLM谈判者相比，EQ-Knight在对抗性的案例中表现更优，让债务人减少让步损失32%，同时不牺牲回收率。", "conclusion": "对于信用机构来说，EQ-Knight将LLM从高风险的“取悦者”转变为战略情感防御者，以情感智能与战术严谨相结合的方式要求问责，防止剥削。"}
{"llm_update_time": "20250907", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2505.14585", "html_url": "https://arxiv.org/abs/2505.14585", "title": "Context Reasoner: 利用强化学习激励具有上下文隐私和安全合规性的推理能力", "title_en": "Context Reasoner: Incentivizing Reasoning Capability for Contextualized Privacy and Safety Compliance via Reinforcement Learning", "authors": "Wenbin Hu,Haoran Li,Huihao Jing,Qi Hu,Ziqian Zeng,Sirui Han,Heli Xu,Tianshu Chu,Peizhao Hu,Yangqiu Song", "background": "大型语言模型（LLMs）虽然展现出卓越的能力，但也带来了显著的安全和隐私风险。当前的缓解策略往往在风险场景中未能保留上下文推理能力，而是依赖敏感模式匹配来保护LLMs，这限制了适应性。这些策略还忽视了已有的安全和隐私标准，导致系统性风险，影响法律合规。因此，需要新的方法来解决这些缺口。", "innovation": "论文提出了一种方法，将安全和隐私问题通过上下文完整性（CI）理论转换为上下文合规问题，并使用强化学习（RL）结合规则基础奖励机制，激励上下文推理能力，同时增强对安全和隐私规范的遵守。这种方法不仅在隐私和安全基准测试中显著提升了合规准确率（8.58%），还在通用推理能力上也有所提升。对于OpenThinker-7B这一在多种主题上显著优于基模Qwen2.5-7B-Instruct的强推理模型，该方法进一步提高了其通用推理能力", "conclusion": "实验结果表明，该方法不仅显著增强了法律合规性，而且还在普遍推理能力上取得了进一步的提升。通过这种方法，OpenThinker-7B在MMLU和LegalBench基准测试中的准确率分别提高了2.05%和8.98%。"}
{"llm_update_time": "20250907", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2506.09556", "html_url": "https://arxiv.org/abs/2506.09556", "title": "MEDUSA：自然条件下对话情感识别的多模态深度融合多阶段训练框架", "title_en": "MEDUSA: A Multimodal Deep Fusion Multi-Stage Training Framework for Speech Emotion Recognition in Naturalistic Conditions", "authors": "Georgios Chatzichristodoulou,Despoina Kosmopoulou,Antonios Kritikos,Anastasia Poulopoulou,Efthymios Georgiou,Athanasios Katsamanis,Vassilis Katsouros,Alexandros Potamianos", "background": "SER是一个具有挑战性的任务，因为人类情感的主观性质以及在自然条件下其表现的不均衡性。我们提出MEDUSA，一种带有四阶段训练管道的多模态框架，能够有效处理类别不平衡和情感模糊性问题。", "innovation": "MEDUSA框架采用了DeepSER作为新颖的多模态深度迁移融合机制的扩展，利用从预训练自监督声学和语言表示中提取的深层跨模态变换。该框架还采用了Manifold MixUp进行进一步正则化，并在最后两个阶段优化了一个可训练的元分类器，结合了集成预测。训练方式结合了人类注释得分作为软目标，平衡数据采样和多任务学习方法。", "conclusion": "在2025年语音情感识别挑战赛（Interspeech 2025: Speech Emotion Recognition in Naturalistic Conditions）的Task 1：类别情感识别中，MEDUSA取得了第一名的成绩。"}
{"llm_update_time": "20250907", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2506.22141", "html_url": "https://arxiv.org/abs/2506.22141", "title": "DAPFAM:一种面向领域、家族级别的数据集，用于评估跨领域专利检索", "title_en": "DAPFAM: A Domain-Aware Family-level Dataset to benchmark cross domain patent retrieval", "authors": "Iliass Ayaou(ICube),Denis Cavallucci(ICube),Hicham Chibane(ICube)", "background": "专利前艺术检索在技术边界跨越的背景下变得特别具有挑战性，现有基准测试缺少明确的领域划分，难以评估检索系统处理这种转变的能力。", "innovation": "引入了DAPFAM，这是一种家族级别的数据集，通过新的IPC3重叠方案明确了IN领域和OUT领域的划分。数据集包括1247个查询家族和45,336个目标家族，基于引文的相关性判断。通过249次控制实验，涵盖了从词汇（BM25）到密集（变压器）后端的多种检索方法，以及文档和片段级别的检索，展示了显著的领域差距：OUT领域性能比IN领域低约五倍。密集方法在一定程度上优于BM25，但未能缩小OUT领域差距。", "conclusion": "DAPFAM通过揭示跨领域检索的持久难题，为开发更加健壮的专利检索系统提供了可再现且计算感知的测试平台。"}
{"llm_update_time": "20250907", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.00454", "html_url": "https://arxiv.org/abs/2508.00454", "title": "从多个评委学习高效的多轮对话评估器", "title_en": "Learning an Efficient Multi-Turn Dialogue Evaluator from Multiple Judges", "authors": "Yuqi Tang,Kehua Feng,Yunfeng Wang,Zhiwen Chen,Chengfei Lv,Gang Yu,Qiang Zhang,Keyan Ding", "background": "目前评价大规模语言模型（LLMs）的对话能力主要依赖于“LLM作为评委”的方法，即将LLM作为评估者来评估对话质量。然而，这种方法常常存在诸多偏见问题，这会削弱评估结果的可靠性和一致性。最近的方法利用多个LLM作为评委并汇总他们的判断来选择最佳评估，这种方法虽然有效，但在推理时却会产生显著的计算开销。", "innovation": "本文提出了一种高效的多轮对话评估器，通过汇总多种LLM评委的偏好知识到单一模型中来捕捉多种LLM评委的集体智慧。这种方法保持了多样多评委反馈的优点，同时大大减少了评估成本，能够快速灵活地评估对话质量。", "conclusion": "我们通过在七个单评分和配对比较对话评估基准上进行广泛实验，表明我们的方法在各种场景中都优于现有基线，展现了其高效性和鲁棒性。"}
{"llm_update_time": "20250907", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2506.07900", "html_url": "https://arxiv.org/abs/2506.07900", "title": "MiniCPM4：末端设备上的超高效率大语言模型", "title_en": "MiniCPM4: Ultra-Efficient LLMs on End Devices", "authors": "MiniCPM Team:Chaojun Xiao,Yuxuan Li,Xu Han,Yuzhuo Bai,Jie Cai,Haotian Chen,Wentong Chen,Xin Cong,Ganqu Cui,Ning Ding,Shengda Fan,Yewei Fang,Zixuan Fu,Wenyu Guan,Yitong Guan,Junshao Guo,Yufeng Han,Bingxiang He,Yuxiang Huang,Baoxi Ji,Cunliang Kong,Qiuzuo Li,Siyuan Li,Wenhao Li,Xin Li,Yanghao Li,Yishan Li,Zhen Li,Dan Liu,Biyuan Lin,Yankai Lin,Xiang Long,Quanyu Lu,Yaxi Lu,Peiyan Luo,Hongya Lyu,Litu Ou,Yinxu Pan,Lushi Pu,Zekai Qu,Qundong Shi,Zijun Song,Jiayuan Su,Zhou Su,Ao Sun,Xianghui Sun,Peijun Tang,Fangzheng Wang,Feng Wang,Shuo Wang,Yudong Wang,Zheng Wang,Yesai Wu,Zhenyu Xiao,Jie Xie,Zihao Xie,Xiaoyue Xu,Yukun Yan,Jiarui Yuan,Jinqian Zhang,Kaihuo Zhang,Lei Zhang,Linyue Zhang,Xueren Zhang,Yudi Zhang,Hengyu Zhao,Weilin Zhao,Weilun Zhao,Yuanqian Zhao,Zhi Zheng,Chuyue Zhou,Ge Zhou,Jie Zhou,Wei Zhou,Yanghao Zhou,Zihan Zhou,Zixuan Zhou,Zhiyuan Liu,Guoyang Zeng,Chao Jia,Dahai Li,Maosong Sun", "background": "当前，大型语言模型（LLM）的设计主要针对云端服务器，对于端侧设备来说，效率和性能的优化尚存在挑战。MiniCPM4作为专门为端侧设备设计的大语言模型，旨在解决这一挑战，提高在末端设备上的运行效率和模型性能。", "innovation": "该论文提出了针对端侧设备优化的 MiniCPM4 模型，其创新点包括：1. 提出了 InfLLM v2 可训练稀疏注意机制，加速模型的填充和解码。2. 提出了 UltraClean 高效准确的预训练数据筛选和生成策略，以及 UltraChat v2 监督微调数据集。3. 引入 ModelTunnel v2 高效预训练策略搜索方法，改进了现有的后训练方法，包含基于分块的卷积神经网络渐进学习，并引入了三元 BitCPM 细粒度量化算法。4. 通过整合稀疏注意机制、模型量化和预测采样，提出了高效的预填充和解码系统，适用于多种设备需求。", "conclusion": "MiniCPM4 和 MiniCPM4.1 在各项基准测试中，展现出比相近规模开源模型更好的性能，特别是长序列理解和生成的加速效果显著，显示了在端侧设备上的高效实用性。"}
{"llm_update_time": "20250907", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.06971", "html_url": "https://arxiv.org/abs/2508.06971", "title": "通过集成检索和指令调优提取答案的两级古兰问答", "title_en": "Two-Stage Quranic QA via Ensemble Retrieval and Instruction-Tuned Answer Extraction", "authors": "Mohamed Basem,Islam Oshallah,Ali Hamdi,Khaled Shaban,Hozaifa Kassab", "background": "古兰经问答由于古典阿语的语法规则复杂和宗教文本的语义丰富性，提出了独特的挑战。该研究提出了一个两阶段框架，旨在解决段落检索和答案提取的问题。", "innovation": "本文提出了一种创新的两阶段框架，集合了细调过的阿拉伯语模型以提高段落检索的效果，并通过使用指令调优的大语言模型和少量提示来克服小数据集微调的局限性。这种方法显著优于以往的方法，在Quran QA 2023共享任务中取得了最佳结果，进一步证明了模型集合与指令调优语言模型结合的有效性，特别适用于低资源专门领域的问答任务。", "conclusion": "研究表明，结合模型集合和指令调优的语言模型能有效地解决低资源专门领域的问答挑战。"}
{"llm_update_time": "20250907", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.14723", "html_url": "https://arxiv.org/abs/2508.14723", "title": "移植后再生成：一种新的文本数据增强范式", "title_en": "Transplant Then Regenerate: A New Paradigm for Text Data Augmentation", "authors": "Guangzhan Wang,Hongyu Zhang,Beijun Shen,Xiaodong Gu", "background": "数据增强是深度学习的关键技术。传统的方法如反向翻译主要集中在词汇层面的重新表述，这通常会产生具有相同语义的变化。尽管大型语言模型提高了文本增强的能力，但控制这些输出的风格和结构仍然具有挑战性，需要细致的提示工程。", "innovation": "本文提出了LMTransplant，一种利用大型语言模型的新文本增强范式。该方法的核心思想是移植后再生成：将种子文本整合到由大型语言模型扩展的上下文中，并要求该模型基于扩展的上下文再生一个变体。这种方法使模型能够充分利用嵌入在大型语言模型中的知识生成更多样化和创造性的内容层次变体，同时保持原始文本的核心特性。", "conclusion": "我们在各种文本相关任务上评估了LMTransplant，并证明了其优于现有文本增强方法的优越性能。此外，LMTransplant在增强数据量增加时表现出出色的可扩展性。"}
{"llm_update_time": "20250907", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.19740", "html_url": "https://arxiv.org/abs/2508.19740", "title": " Spotlight Attention: 向基于非线性哈希的 KV 缓存检索的高效 LLM 生成努力", "title_en": "Spotlight Attention: Towards Efficient LLM Generation via Non-linear Hashing-based KV Cache Retrieval", "authors": "Wenhao Li,Yuxin Zhang,Gen Luo,Haiyuan Wan,Ziyang Gong,Fei Chao,Rongrong Ji", "background": "在大型语言模型（LLMs）中，减少关键值（KV）缓存的负担可以显著加速推理过程。现有的方法使用随机线性哈希来标识重要令牌，但由于查询和密钥在大模型中的正交分布局限于两个狭窄的锥体内，这一方法效率低下。", "innovation": "本文提出了一种新的方法——Spotlight Attention，它使用非线性哈希函数优化查询和密钥的嵌入分布，提高编码效率和鲁棒性。还设计了基于Bradley-Terry排名损失的轻量级和稳定的训练框架，在仅用16GB显存的GPU上，8小时内优化非线性哈希模块。实验结果显示，Spotlight Attention在提高检索精度的同时，将哈希码长度至少缩短了5倍，相较于传统的线性哈希检索。", "conclusion": "通过采用特定的CUDA内核实现位运算操作，Spotlight Attention在单个A100 GPU上实现512K令牌的哈希检索，耗时少于100μs，端到端吞吐量提高了3倍，远高于传统的直接解码。"}
{"llm_update_time": "20250907", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.20410", "html_url": "https://arxiv.org/abs/2508.20410", "title": "UI-Bench：评估AI文本转应用工具设计能力的基准", "title_en": "UI-Bench: A Benchmark for Evaluating Design Capabilities of AI Text-to-App Tools", "authors": "Sam Jung,Agustin Garcinuno,Spencer Mateega", "background": "AI文本转应用工具承诺在几分钟内生成高质量的应用程序和网站，然而尚无公开基准可以严谨验证这些主张。当前存在的基准未能全面评估这些工具在视觉设计上的卓越性。", "innovation": "UI-Bench 是首个大规模评估竞品AI文本转应用工具视觉设计能力的大规模基准，通过专家两两对比的方式进行评估。它涵盖了10种工具、30个提示、300个生成的站点和4000多专家判断，使用TrueSkill衍生模型进行排名，提供校准后的置信区间。", "conclusion": "UI-Bench 确立了一个可重复的标准来促进AI驱动的网页设计的进步。论文发布包括(i)完整的提示集，(ii)开源评估框架，以及(iii)公开排行榜。生成的站点评价结果将很快公开。有关UI-Bench的排行榜，请访问：this https URL"}
{"llm_update_time": "20250907", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.15478", "html_url": "https://arxiv.org/abs/2508.15478", "title": "SLM-Bench: 评估环境影响的小型语言模型综合基准--扩展版", "title_en": "SLM-Bench: A Comprehensive Benchmark of Small Language Models on Environmental Impacts--Extended Version", "authors": "Nghiem Thanh Pham,Tung Kieu,Duc-Manh Nguyen,Son Ha Xuan,Nghia Duong-Trung,Danh Le-Phuoc", "background": "小型语言模型(SLMs)在计算效率和可访问性方面表现出色，但对其性能和环境影响的系统性评估仍缺乏。现有的基准测试工具大多侧重于大型语言模型，而SLMs在准确性和环境可持续性方面未得到充分评估。因此，需要一种全面的基准测试工具来评估SLMs在多个维度上的表现，包括准确度、计算效率和可持续性指标。", "innovation": "1. SLM-Bench是首个专门用于评估SLMs的基准测试工具，涵盖了多个指标，如准确度、计算效率和消租能力等。\n2. SLM-Bench评估了15种SLMs在9项NLP任务上的表现，使用了23个数据集，覆盖14个领域。\n3. 基准测试在4种硬件配置下进行，提供了严格的比较。\n4. SLM-Bench量化了11个性能指标，涵盖了正确性、计算和消耗等方面，提供了全面的效率评估。\n5. 开发了一个开源基准测试管道，并制定了标准化评估协议，以促进可重复性和进一步研究。", "conclusion": "SLM-Bench设定了评估SLMs的新标准，通过综合考虑资源效率和实际应用，减少了SLMs与环境影响之间的差距。我们的结果表明SLMs存在多样化的权衡，在准确性和能源效率方面各有优劣。"}
{"llm_update_time": "20250907", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.20324", "html_url": "https://arxiv.org/abs/2508.20324", "title": "紧凑型语言模型能否像智能体一样搜索？基于蒸馏的策略优化以保持代理型RAG能力", "title_en": "Can Compact Language Models Search Like Agents? Distillation-Guided Policy Optimization for Preserving Agentic RAG Capabilities", "authors": "Rikuto Kotoge,Mai Nishimura,Jiaxin Ma", "background": "强化学习已作为一种后训练方法，促使语言模型展现出能够执行搜索和规划等代理型RAG行为的能力。然而，小型语言模型（如参数量为0.5B的小模型）由于推理能力较差，导致奖励稀疏，训练不稳。因此，亟需一种方法来克服这些困难。", "innovation": "本文提出了蒸馏引导策略优化(DGPO)，通过教师演示的冷启动初始化和策略优化过程中的持续教师指导，解决了这一问题。此外，还引入了详细的能力分析指标AGentic RAG Capabilities (ARC)，评估推理、搜索协调和响应合成能力。", "conclusion": "实验结果表明，DGPO使紧凑型模型能够实现复杂的代理型搜索行为，并在某些情况下超越了教师大模型，展示了在计算资源受限环境下实现代理型RAG的可能性。"}
{"llm_update_time": "20250907", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.20038", "html_url": "https://arxiv.org/abs/2508.20038", "title": "预见预防护：通过预合成类似漏洞指令增强大型语言模型的安全护栏以应对潜在攻击", "title_en": "Forewarned is Forearmed: Pre-Synthesizing Jailbreak-like Instructions to Enhance LLM Safety Guardrail to Potential Attacks", "authors": "Sheng Liu,Qiang Sheng,Danding Wang,Yang Li,Guang Yang,Juan Cao", "background": "尽管在提高大语言模型（LLM）拒绝恶意指令方面取得了进展，但广泛使用的LLM仍然容易受到攻击者的‘劫持攻击’，即生成与安全对齐语料库分布不同的指令。新的攻击揭示了LLM难以识别之前未见过的恶意指令，突显了训练数据与现实世界攻击之间的关键分布性失配，迫使开发者进入反应性的修复循环。", "innovation": "我们提出了IMAGINE，一种利用嵌入空间分布分析生成类似劫持的指令的合成框架。这种方法有效地填补了真实劫持模式和安全对齐语料库之间分布性差异。IMAGINE 采用迭代优化过程，动态演化文本生成分布，从而通过合成数据示例增强安全对齐数据分布的覆盖范围。结合通过IMAGINE增强的安全对齐语料库，我们的框架在Qwen2.5、Llama3.1和Llama3.2上显著降低了攻击成功率，同时保持了模型的有用性。", "conclusion": "IMAGINE框架通过模拟潜在的攻击指令，有效增强了LLM的安全性，展示了显著降低攻击成功率的能力，而不会牺牲模型的实用性。"}
{"llm_update_time": "20250907", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2509.01185", "html_url": "https://arxiv.org/abs/2509.01185", "title": "语言模型训练和评估中合成长文本文档生成的模块化技术", "title_en": "Modular Techniques for Synthetic Long-Context Data Generation in Language Model Training and Evaluation", "authors": "Seganrasan Subramanian,Abhigya Verma", "background": "大型语言模型（LLMs）处理和推理长文本输入的能力对于许多实际应用至关重要。然而，这一领域的进展受到高质量、多样化且可验证的长语境数据集的缺乏的限制，这些数据集既适用于训练又适用于评估。本文介绍了一种模块化、可扩展的框架，通过与大语言模型的提示式交互生成合成的长语境数据。该框架支持多种训练和对齐目标，包括监督微调（SFT）、直接偏好优化（DPO）和组相对策略优化（GRPO）。它包含了四种核心生成范式：多轮对话、基于文档的输入-输出对、可验证的指令-响应任务和长语境推理示例。", "innovation": "该工作提出了一个模块化框架，用于通过与大语言模型的提示式交互生成合成的长语境数据。该框架支持多种训练和对齐目标，并包括四种核心生成范式。通过模板提示、无模型特异性架构和元数据丰富的输出，该方法促进了扩展、可控和目标一致的数据集生成，旨在提升LLMs的长语境能力。", "conclusion": "该方法通过模板化提示、无模型特异性架构和元数据丰富的输出，支持了多种训练和对齐目标，并为大规模和可控的数据集生成提供了模块化、可扩展的方法，以促进LLMs在长语境任务上的性能提升。"}
{"llm_update_time": "20250907", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2407.01085", "html_url": "https://arxiv.org/abs/2407.01085", "title": "LLM 基础偏好评估中的长度偏差解释", "title_en": "Explaining Length Bias in LLM-Based Preference Evaluations", "authors": "Zhengyu Hu,Linxin Song,Jieyu Zhang,Zheyuan Xiao,Tianfu Wang,Zhengyu Chen,Nicholas Jing Yuan,Jianxun Lian,Kaize Ding,Hui Xiong", "background": "大规模语言模型（LLMs）在偏好比较中的应用越来越普遍，但这种应用忽视了对较长回答的偏好，影响了评价的可靠性。", "innovation": "本文提出了一种新的分解评价度量的方法，具体为将win rate拆分为desirability和information mass两个关键成分，前者与内容质量相关且与长度无关，后者依赖于长度，反映回答中包含的信息量。同时，提出了一种名为AdapAlpaca的简单而有效的调整方法，通过调整win rate来确保在等长范围内对回答质量进行公平比较。", "conclusion": "通过控制实验，研究证实了回答长度会影响评价结果，主要通过影响信息量。AdapAlpaca方法能够提供一个可靠的评价度量，以评估内容质量而不受回答长度影响。"}
{"llm_update_time": "20250907", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2509.01221", "html_url": "https://arxiv.org/abs/2509.01221", "title": "DaMoC: 基于数据和模型压缩高效选择适合微调特定领域任务的最佳大型语言模型", "title_en": "DaMoC: Efficiently Selecting the Optimal Large Language Model for Fine-tuning Domain Tasks Based on Data and Model Compression", "authors": "Wei Huang,Huang Wei,Yinggui Wang", "background": "大型语言模型（LLMs）擅长通用任务，但在特定领域任务上表现不佳，通常需要使用特定数据进行微调。随着许多开源LLMs的可用性，选择最适合微调的LLM变得更加困难，主要集中在如何快速识别最佳LLM上。当前挑战在于如何高效地在输入特定领域数据时挑选最优的LLM。DaMoC框架通过数据分析和模型压缩来解决这一问题，包括数据过滤方法的分类和模型压缩策略，从而帮助迅速找到最佳微调模型，并节省大量训练时间。", "innovation": "DaMoC框架包含两个关键创新点：1) 数据层：首先建立了数据过滤方法的系统分类，分为三大类：分布感知方法、质量感知方法以及综合了两者的方法，并且通过增强关键词汇密度实现文本压缩，然后使用LLM迭代重写文本以优化表达。2) 模型层：使用层相似性评分评估每个层的重要性，并移除不重要的层，然后引入稀疏合并策略以尽可能保留原始模型的性能。这种方法通过数据和模型压缩，显著提高了选择最佳LLM的效率，并减少了约20倍的训练时间。", "conclusion": "DaMoC框架通过数据过滤和模型压缩实现了快速有效地选择最佳LLM进行微调，为解决大型语言模型在特定领域任务上的挑战提供了一个有效的解决方案，同时也显著减少了训练时间。"}
{"llm_update_time": "20250907", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2502.17882", "html_url": "https://arxiv.org/abs/2502.17882", "title": "跨语言的科学：评估大规模语言模型多语言翻译科学论文", "title_en": "Science Across Languages: Assessing LLM Multilingual Translation of Scientific Papers", "authors": "Hannah Calzi Kleidermacher,James Zou", "background": "科学研究本质上是全球性的。然而，大多数学术期刊仅使用英语出版，这为非英语母语的研究者设定了屏障。", "innovation": "利用大型语言模型（LLMs）为学术期刊开发了一种自动化的翻译方法，同时保留其原始的JATS XML格式，将科学文章翻译成28种语言。", "conclusion": "研究表明，使用该方法翻译的论文准确传达了关键科学细节，平均性能达到95.9%。用户研究表明，翻译能够捕捉到原始信息，但部分作者希望保留一些技术术语的英文表述，避免过度翻译。通过上下文学习技术，可以调整翻译以适应特定领域的偏好，提升了LLM驱动的科学翻译的灵活性和实用性。"}
{"llm_update_time": "20250907", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2509.03020", "html_url": "https://arxiv.org/abs/2509.03020", "title": "通过双向重建训练LLMs成为更好的文本嵌入器", "title_en": "Training LLMs to be Better Text Embedders through Bidirectional Reconstruction", "authors": "Chang Su,Dengliang Shi,Siyuan Huang,Jintao Du,Changhua Meng,Yu Cheng,Weiqiang Wang,Zhouhan Lin", "background": "大型语言模型（LLMs）在作为强大的文本嵌入器方面已经被越来越广泛地探索。现有的基于LLM的文本嵌入方法通常利用最后一个标记的嵌入，通常是保留的特殊标记，如[EOS]。然而，这些令牌并没有专门训练来捕捉整个上下文的语义，这限制了它们作为文本嵌入的能力，特别是在检索和重排序任务中。", "innovation": "提出了在对比学习之前添加一个新的训练阶段，以丰富最后标记嵌入的语义。这一阶段使用了双向生成重建任务，即EBQ2D（基于嵌入的查询到文档）和EBD2Q（基于嵌入的文档到查询），这两个任务交错进行以锚定[EOS]嵌入并重建查询-文档对的每一侧。实验结果表明，额外的训练阶段显著提升了LLMs在大规模文本嵌入基准测试（MTEB）上的表现，实现了不同LLM基模和规模的新最佳结果。", "conclusion": "通过双向重建训练，LLMs在文本嵌入任务上的表现有了显著提升，特别是在大规模文本嵌入基准测试中达到了新的最佳水平，证明了这一新方法的有效性。"}
{"llm_update_time": "20250907", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2406.13923", "html_url": "https://arxiv.org/abs/2406.13923", "title": "PIN: 一种配对和交错多模态文档的密集知识数据集", "title_en": "PIN: A Knowledge-Intensive Dataset for Paired and Interleaved Multimodal Documents", "authors": "Junjie Wang,Yuxiang Zhang,Minghao Liu,Yin Zhang,Yatai Ji,Weihao Xuan,Nie Lin,Kang Zhu,Zhiqiang Lin,Yiming Ren,Chunyang Jiang,Yiyao Yu,Zekun Wang,Tiezhen Wang,Wenhao Huang,Jie Fu,Qunshu Liu,Yujiu Yang,Ge Zhang,Ruibin Yuan,Bei Chen,Wenhu Chen", "background": "近年来，大型多模态模型（LMMs）借助了大量的多模态数据集，提升了在复杂知识驱动任务中的能力。但感知和推理错误持续存在，特别是在解读复杂视觉数据和推断多模态关系方面限制了它们的应用效果。", "innovation": "为了应对这些问题，我们引入了PIN（Paired and INterleaved multimodal documents）这个新颖的数据格式，旨在促进视觉和文本知识的更深层次集成。PIN格式独特地结合了富含语义信息的Markdown文件和容量全面的图像，捕获整个文档的布局。通过遵循此格式，我们构建并发布了两个大规模的开源数据集：PIN-200M（约2亿文档）和PIN-14M（约1400万文档），这些数据集汇编自来自英语和汉语的多样化网络和科学来源。为了最大化其使用性，我们提供了详尽的统计数据并提供了质量信号，从而使研究人员能够轻松过滤和选择特定任务所需的数据。", "conclusion": "我们的工作为社区提供了一个灵活的数据格式和大量的资源，为预训练策略的研究和开发更强大的知识密集型LMMs奠定了基础。"}
{"llm_update_time": "20250907", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2509.02038", "html_url": "https://arxiv.org/abs/2509.02038", "title": "NADI 2025：首次多方言阿拉伯语音处理共享任务", "title_en": "NADI 2025: The First Multidialectal Arabic Speech Processing Shared Task", "authors": "Bashar Talafha,Hawau Olamide Toyin,Peter Sullivan,AbdelRahim Elmadany,Abdurrahman Juma,Amirbek Djanibekov,Chiyu Zhang,Hamad Alshehhi,Hanan Aldarmaki,Mustafa Jarrar,Nizar Habash,Muhammad Abdul-Mageed", "background": "该论文介绍了第六届Nuanced Arabic Dialect Identification (NADI 2025)共享任务的研究成果。任务涉及三个子任务：语音方言识别（子任务1）、语音识别（子任务2）以及语音方言的重音标记恢复（子任务3）。共有44个队伍注册参与，测试阶段收到了8个不同队伍的100份有效提交。各子任务的具体提交情况如下：子任务1收到了5个团队的34份提交，子任务2收到了6个团队的47份提交，子任务3收到了2个团队的19份提交。性能最佳的系统在子任务1中达到了79.8%的准确率，在子任务2中平均每字错误率和字符级错误率为35.68/12.20，在子任务3中为55/13。这些结果表明阿拉伯方言语音处理领域仍然存在挑战，特别是在方言识别、语音识别和重音标记恢复方面。此外，该论文还总结了参加队伍采用的方法，并简要概述了未来NADI版本的发展方向。", "innovation": "该共享任务首次针对阿拉伯语音处理进行了多任务综合评估，包括语音方言识别、语音识别和重音标记恢复，且成功吸引了44支队伍参与。", "conclusion": "尽管取得了一定的技术进步，但阿拉伯方言语音处理仍面临诸多挑战，需要进一步研究和开发。NADI共享任务计划在未来继续进行，以促进该领域的持续发展。"}
{"llm_update_time": "20250907", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.08715", "html_url": "https://arxiv.org/abs/2508.08715", "title": "MultiGen：基于LLM的儿童友好多语言语音生成模型", "title_en": "MultiGen: Child-Friendly Multilingual Speech Generator with LLMs", "authors": "Xiaoxue Gao,Huayun Zhang,Nancy F. Chen", "background": "生成式语音模型在改善人机交互方面表现出显著的潜力，尤其是在儿童语言学习等领域。然而，低资源语言中高质量、儿童友好的语音生成仍然面临挑战，特别是在多样化的语言和文化背景下。本文旨在应对这一问题。", "innovation": "提出了一种名为MultiGen的多语言语音生成模型，该模型基于LLM架构，并特别针对低资源语言设计了适合儿童的交互方式。它采用年龄适当的方法实现多语言语音生成，通过文化相关背景，在新加坡口音普通话、马来语和泰米尔语三种低资源语言中帮助年轻儿童与AI系统进行沟通。", "conclusion": "实验结果表明，所提出的MultiGen在客观指标和主观评估中均优于基线方法，展现出了更优的性能。"}
{"llm_update_time": "20250907", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2412.05248", "html_url": "https://arxiv.org/abs/2412.05248", "title": "提升FKG.in：自动化印度食物成分分析", "title_en": "Enhancing FKG.in: automating Indian food composition analysis", "authors": "Saransh Kumar Gupta,Lipika Dey,Partha Pratim Das,Geeta Trilok-Kumar,Ramesh Jain", "background": "本研究重点关注如何通过知识图谱（FKG[.]in）与大型语言模型（LLM）计算印度食谱中的食物成分数据。介绍了自动化食物成分分析的工作流程及其核心功能，包括营养数据聚合、食物成分分析、以及利用LLM增强的信息解析。此外，还阐述了印度食物表示及其数字获取的挑战，并回顾了三个主要的成分数据来源：印度食物成分表、印度营养素数据库和Nutritionix API。研究还简要介绍了用户如何使用此工作流程获得基于饮食的健康建议以及多样食谱的详细食物成分信息。进而分析了在结构、多语种和不确定性等维度上分析印度菜信息的复杂挑战，并介绍正在进行的利用LLM解决这些问题的工作。本研讨会论文中提出的方法在AI驱动的知识编纂和信息解析方面是通用的、可推广的和可以复制的，适用于任何领域的方法。", "innovation": "提出了一种新的方法，利用知识图谱（FKG[.]in）和大型语言模型（LLM）自动化计算印度食谱的食物成分数据。介绍了自动化食物成分分析的工作流程，并利用LLM增强的信息解析能力。回顾了三个主要的成分数据来源，并分析了印度菜信息分析的复杂挑战，提出了利用LLM解决这些问题的方法。这些方法旨在AI驱动的知识编纂和信息解析方面具有通用性、可推广性和可复制性，适用于任何领域。", "conclusion": "本论文的工作流致力于补充经过验证的知识库内的食物成分数据，并通过迭代补充来丰富食物成分数据。论文详细说明了从印度食物成分表、印度营养素数据库和Nutritionix API获取成分数据的方法，并探索了结构、多语种和不确定性等维度上的分析复杂性。所提出的方法将是应用无关的、通用的、可推广的，适用于任何领域。"}
{"llm_update_time": "20250907", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2505.18102", "html_url": "https://arxiv.org/abs/2505.18102", "title": "如何在不透露真实答案的情况下发布我的大语言模型基准？", "title_en": "How Can I Publish My LLM Benchmark Without Giving the True Answers Away?", "authors": "Takashi Ishida,Thanawat Lodkaew,Ikko Yamane", "background": "在互联网上发布大语言模型（LLM）基准存在风险，这些基准可能被无意间或故意地用来训练或选择模型。为了缓解这一问题，通常采用保持基准的私密性，让参与者提交模型或预测，但这需要对单一组织的信任，并且仍可能通过重复查询导致测试集过拟合。因此，提出了一个新的方法来发布基准，而不完全公开问题的真实答案，同时仍能公正地评估LLM。", "innovation": "提出了一种新的方法来发布基准，这种方法通过在答案中注入随机性（即准备多个逻辑上正确但只包含其中一种作为解决方案），降低了基准的最大可能准确率（即贝叶斯准确率），从而减少了泄露真实答案的风险，同时也提供了一种检测数据污染的测试方法。研究表明，即使完全有能力的模型也不会超过贝叶斯准确率上限。如果模型超过了这个上限，那么这很可能是数据污染的信号。", "conclusion": "实验结果表明，这种方法可以准确地检测出各种基准、模型和训练方法下的数据污染。"}
{"llm_update_time": "20250907", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.16117", "html_url": "https://arxiv.org/abs/2508.16117", "title": "扩展 FKG.in：通往食品声明可追溯网络之路", "title_en": "Extending FKG.in: Towards a Food Claim Traceability Network", "authors": "Saransh Kumar Gupta,Rizwan Gulzar Mir,Lipika Dey,Partha Pratim Das,Anirban Sen,Ramesh Jain", "background": "全球食品领域充斥着各种关于食品的科学、文化和商业声明，范围从严谨研究的健康效果（例如：益生菌改善肠道健康）到错误的代表（例如：浸泡过的杏仁使人更聪明），再到模糊的承诺（例如：超级食品增强免疫力）和文化根深蒂固的信念（例如：冷食会引起咳嗽）。尽管这些声明影响广泛，但追溯、验证和上下文化这些声明的基础设施仍然支离破碎且不完善。", "innovation": "本文提出了一个食品声明可追溯网络（FCN），将其作为我们逐步构建的印度食品知识图谱（FKG.in）的扩展。我们展示了使用Reddit数据和大型语言模型来开发FKG.in-FCN的本体设计和半自动知识汇编工作流程。FCN整合了经过筛选的数据输入、结构化的框架和具有来源感知的管道来提取和验证食品声明，从而提供了透明和可解释的食品声明和可追溯性建模方法。", "conclusion": "通过在结构化、验证和可解释的方式建模食品声明和可追溯性，我们旨在促进更透明和负责任的食品知识生态系统，支持科研人员、政策制定者，最重要的是普通消费者在这种充斥着饮食主张的世界中导航。"}
{"llm_update_time": "20250907", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2503.05720", "html_url": "https://arxiv.org/abs/2503.05720", "title": "不可接受：检视‘谴责’背后的道德基础", "title_en": "That is Unacceptable: the Moral Foundations of Canceling", "authors": "Soda Marem Lo,Oscar Araque,Rajesh Sharma,Marco Antonio Stranisci", "background": "‘谴责’是一种道德驱动的现象，阻碍了社会媒体平台的安全发展，并加剧了意识形态的极化。鉴于这一问题，本文提出了‘谴责态度检测’（CADE）数据集，这是旨在探索社交媒体中人们评价谴责态度分歧的标注语料库。特别地，本研究探讨了标注人在其看待‘谴责’现象时的道德观念对其感知的影响，表明道德是一种独立轴，用于解释对该现象的分歧。标注人的判断高度依赖于争议事件的类型以及涉及的名人。这显示了开发更事件中心的数据集的必要性，以便更好地理解社交媒体中的危害如何产生，并开发更意识到的技术来检测这些危害。", "innovation": "提出了‘谴责态度检测’（CADE）数据集，这是第一种专门针对社交媒体‘谴责’现象标注的语料库，特别是用于探索评价人们谴责态度的分歧因素，并强调道德是理解此类现象独立的解释维度", "conclusion": "研究指出，标注人在处理‘谴责’现象时的道德观念对其判断产生重大影响，基于此，建议开发更事件中心的数据集来更好地理解社交媒体中的危害及其检测技术的发展。"}
{"llm_update_time": "20250907", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2503.23746", "html_url": "https://arxiv.org/abs/2503.23746", "title": "短视频传播影响力评估：一个新的真实世界数据集和一个新的大规模图形模型", "title_en": "Short-video Propagation Influence Rating: A New Real-world Dataset and A New Large Graph Model", "authors": "Dizhan Xue,Shengsheng Qian,Chuanrui Hu,Changsheng Xu", "background": "短视频平台在全球范围内获得了巨大 popularity，吸引了数以亿计的用户。研究人员开始关注短视频传播的重要性，涉及商业价值、公众意见、用户行为等。已有研究主要集中在传播分析方面，但缺乏大规模且跨平台的短视频传播数据集，以支持相关研究。因此，提出了短视频传播影响力评估（SPIR）任务，旨在从数据集和方法的角度促进SPIR研究。", "innovation": "1. 新增了Cross-platform Short-Video (XS-Video) 数据集，这是第一个包含跨平台数据的大规模短视频数据集，提供了来自五大中国平台的117,720个视频、381,926个样本和535个话题，并标注了0到9级的传播影响力，这是前所未有的全面视角。\n2. 提出了名为NetGPT的新大型图模型（LGM），基于新颖的三阶段训练机制，将异构图形结构数据与大型语言模型的强大推理能力和知识结合。\n3. 实验结果表明，基于NetGPT的方法在分类和回归评价指标上优于其他方法，证明该方法在短视频传播影响力评估中的优越性。", "conclusion": "通过提出一个新的大型图形数据集（XS-Video）和一个基于大型语言模型的新图形模型（NetGPT），该研究显著促进了短视频传播影响力评估（SPIR）的研究进展，并展示了新方法在预测短视频长期传播影响力方面的优越性。"}
{"llm_update_time": "20250907", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2509.03312", "html_url": "https://arxiv.org/abs/2509.03312", "title": "AgenTracer: 谁在导致LLM代理系统中的故障？", "title_en": "AgenTracer: Who Is Inducing Failure in the LLM Agentic Systems?", "authors": "Guibin Zhang,Junhao Wang,Junjie Chen,Wangchunshu Zhou,Kun Wang,Shuicheng Yan", "background": "大型语言模型（LLM）基于的代理系统通常由多个模型、复杂的工具调用和编排协议组成，这些系统在性能上远超单一代理系统。然而，这种复杂性也使其更容易发生系统故障。具体来说，故障归因任务需要确定长时间执行轨迹中导致错误的具体代理或步骤，但当前最先进的基于推理的LLM在解决这一问题时表现差强人意，准确率通常低于10%。因此，本文提出了AgenTracer，这是一种自动化的框架，通过反事实回放和编程故障注入来标注失败的多代理轨迹，并构建了一个标注数据集TracerTraj。利用这一资源，AgenTracer-8B能够使用多粒度强化学习进行高效故障诊断，特别是在冗长的多代理交互中表现出色。在Who&When基准测试中，AgenTracer-8B超过了一些大型的专用LLM，如Gemini-2.5-Pro和Claude-4-Sonnet，精度提高了18.18%。更重要的是，AgenTracer-8B能为市面上的多代理系统如MetaGPT和MaAS提供实际反馈，使其性能提高了4.8-14.2%，从而帮助这种代理AI自主纠正和进化.", "innovation": "本文首次提出了AgenTracer，这是一种自动化的框架，通过反事实回放和编程故障注入来标注失败的多代理轨迹，并构建了一个标注数据集TracerTraj。AgenTracer-8B是一种使用多粒度强化学习训练的轻量级故障追踪器，能够在冗长的多代理交互中高效诊断错误。与一些大型专用LLM相比，AgenTracer-8B在Who&When基准测试中的性能更高，并且能够为市面上的多代理系统提供实际反馈，使这些系统的性能提高了4.8-14.2%.", "conclusion": "AgenTracer-8B通过多粒度强化学习获得了显著的故障诊断性能，在Who&When基准测试中超过了大型专用LLM。更重要的是，它能为多代理系统提供实际反馈，提升这些系统的性能4.8-14.2%，从而帮助代理AI自主纠错和进化，达到新的标准。"}
{"llm_update_time": "20250907", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2509.02175", "html_url": "https://arxiv.org/abs/2509.02175", "title": "理解空间：火箭科学 -- 只有顶级推理模型才能解决空间理解任务", "title_en": "Understanding Space Is Rocket Science -- Only Top Reasoning Models Can Solve Spatial Understanding Tasks", "authors": "Nils Hoehing,Mayug Maniparambil,Ellen Rushe,Noel E. O'Connor,Anthony Ventresque", "background": "当前开源和前沿商用视觉语言模型在对相对空间关系的理解上表现出明显的缺陷，现有的模型难以准确理解空间关系，而基于链式思考的推理模型在这些任务上的表现却出奇地好。这一背景下，研究团队提出了一个全新的基准测试RocketScience，旨在测试模型的空间关系理解能力。", "innovation": "RocketScience是一个开放源码的对比性视觉-语言模型基准，用于测试空间关系理解能力。它包含了全新的真实图像-文本配对数据，主要涉及相对空间理解以及物体顺序。研究团队通过实证验证了该基准对人类非常容易，却对当前视觉-语言模型极具挑战性。此外，他们还进行了去纠缠分析，揭示了基于链式思考的模型在空间推理任务上的表现由空间推理能力而非物体定位能力决定。", "conclusion": "研究显示开源和前沿商用视觉-语言模型在空间关系理解上存在显著不足，而推理模型却表现出较高的性能。RocketScience基准提供了一个新的视角来评估和改进视觉-语言模型的空间关系理解能力。"}
{"llm_update_time": "20250907", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.03609", "html_url": "https://arxiv.org/abs/2509.03609", "title": "向高效通用特征预测的掩码骨架建模", "title_en": "Towards Efficient General Feature Prediction in Masked Skeleton Modeling", "authors": "Shengkai Sun,Zefan Zhang,Jianfeng Dong,Zhiyong Cheng,Xiaojun Chang,Meng Wang", "background": "最近在掩码自编码器（MAE）方面的进展显著推动了基于关键点的动作识别的自我监督学习。然而，大多数现有方法将重建目标限制在原始关节坐标或其简单变化上，导致计算冗余和有限的语义表示。", "innovation": "文章提出了一种新颖的通用特征预测框架（GFP），用于高效掩码骨架建模。这是一种用高级特征预测（从局部动态模式到全局语义表示）取代传统低级重建的新方法。该框架利用协作学习框架，使轻量级的目标生成网络可以产生跨时空层次的多样化监督信号，避免对预计算的离线特征的依赖，并通过约束优化确保特征多样性，防止模型崩溃。", "conclusion": "在NTU RGB+D 60、NTU RGB+D 120和PKU-MMD上的实验表明，我们的方法具有计算效率（比标准的掩码骨架建模方法快6.2倍）和更好的表示质量，实现各种下游任务中的最佳性能。"}
{"llm_update_time": "20250907", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2506.01115", "html_url": "https://arxiv.org/abs/2506.01115", "title": "随机注意力是否足以进行序列建模？解构Transformer中的可训练组件", "title_en": "Is Random Attention Sufficient for Sequence Modeling? Disentangling Trainable Components in the Transformer", "authors": "Yihe Dong,Lorenzo Noci,Mikhail Khodak,Mufan Li", "background": "Transformer架构是现代大型语言模型（LLMs）成功的关键因素之一，部分原因是它在用仅基于梯度的学习进行下一个标记预测时，能够执行广泛的任务，包括数学推理、记忆和检索。虽然transformer的核心组件是自我注意力机制，作者质疑性能提升中注意力机制所占的比例和具体方面。为此，作者比较了标准transformer与初始化时冻结MLP层或注意力权重的变体，发现在某些情况下，冻结的注意力权重能够形成归纳头并表现出与语言建模相媲美的能力。为了进一步隔离注意力的作用，作者设计了一个名为MixiT的新架构，并证明了在注意力分数完全随机的情况下，可稳定信息传播，克服了先前在随机transformer中遇到的深度缩放挑战。", "innovation": "作者通过将标准transformer与在初始化时冻结MLP层或注意力权重的变体进行比较，发现冻结的注意力权重不仅能够形成归纳头，还能与语言建模竞争。作者还设计了MixiT架构，这是一种具有完全随机注意力分数的架构，表现出稳定的信息传播特性，并超越了先前随机transformer的深度缩放挑战。作者通过MixiT的成功与失败，进一步探讨了transformer各组件的作用，指出注意力主要负责情景推理，而MLPs则负责存储知识并与注意力协作。最终，作者的研究表明，transformer架构具有内置的泛化偏见，即使没有可学习的注意力权重，也能形成专门的电路结构。", "conclusion": "作者的研究结果表明，transformer架构在设计时具有形成专门电路结构的内在倾向，即使在没有可学习注意力权重的情况下也能实现这一目标。这种发现对理解和改进transformer及其变体具有重要意义。"}
{"llm_update_time": "20250907", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2509.01938", "html_url": "https://arxiv.org/abs/2509.01938", "title": "EigenBench: 一种比较性价值观对齐的行为度量方法", "title_en": "EigenBench: A Comparative Behavioral Measure of Value Alignment", "authors": "Jonathn Chang,Leonhard Piff,Suvadip Sana,Jasmine X. Li,Lionel Levine", "background": "人工智能与人类价值观的对齐是一个迫切但尚未解决的问题。由于缺乏衡量价值对齐的定量指标，本文提出了EigenBench：一种用于比较语言模型价值观的方法。该方法通过让多个模型评估其他模型在多个场景下的输出，并使用EigenTrust算法聚合判断结果，生成描述每个模型对给定价值观体系对齐程度的向量。", "innovation": "EigenBench 提出了一个黑盒的方法来比较语言模型的价值观。通过让模型互相评价其在不同场景中的输出，并应用 EigenTrust 算法来聚合这些判断，生成反映整体模型组加权平均判断结果的评分。这种方法无需真实标签，设计用于量化合理的评价者在某些特征上可能有不同的正确标签的特质。", "conclusion": "通过使用提示人设来测试 EigenBench 的评分是否更敏感于模型本身还是提示，研究发现大部分差异是由提示造成的，但仍有较小部分差异反映了模型本身的价值态度。这表明提示在影响模型评分中的重要作用，但模型固有的价值观对齐程度仍有一定影响。"}
{"llm_update_time": "20250907", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2509.01909", "html_url": "https://arxiv.org/abs/2509.01909", "title": "Oyster-I：负责任的语言模型的建设性安全对齐超越拒绝", "title_en": "Oyster-I: Beyond Refusal -- Constructive Safety Alignment for Responsible Language Models", "authors": "Ranjie Duan,Jiexi Liu,Xiaojun Jia,Shiji Zhao,Ruoxi Cheng,Fengxiang Wang,Cheng Wei,Yong Xie,Chang Liu,Defeng Li,Yinpeng Dong,Yichi Zhang,Yuefeng Chen,Chongwen Wang,Xingjun Ma,Xingxing Wei,Yang Liu,Hang Su,Jun Zhu,Xinfeng Li,Yitong Sun,Jie Zhang,Jinzhao Hu,Sha Xu,Yitong Yang,Jialing Tao,Hui Xue", "background": "大型语言模型（LLMs）通常部署了安全机制来防止生成有害内容。当前大多数方法主要针对恶意行为者带来的风险，常常将风险视为对抗事件，并依赖于防御性的拒绝。然而，在实际场景中，来自非恶意用户的风险也同样重要，这些用户可能在心理压力下寻求帮助（例如有自伤意图），在这种情况下，模型的响应会对用户的后续行为产生强烈影响。简单拒绝可能导致他们重复询问、加剧问题或转向不安全平台，从而产生更糟的结果。", "innovation": "提出了一种以人为本的建设性安全对齐（CSA）范式，旨在在保护模型免遭恶意滥用的同时，积极引导脆弱用户获得安全和有用的结果。CSA通过游戏论预测用户反应、细化风险边界发现以及可解释的推理控制，将安全转化为一种信任构建过程。Oyster-I（Oy1）实现了开放模型中的最先进安全标准，并保留了高水平的广泛能力。在建设性基准上，它表现出强大的建设性和接近GPT-5的性能，并在Strata-Sword漏洞测试集中展示了无与伦比的鲁棒性，接近于GPT-o1的水平。通过从拒绝优先转向引导优先的安全方法，CSA重新定义了模型与用户之间的关系，旨在使系统不仅安全，而且真正有用。", "conclusion": "通过Oyster-I（Oy1），CSA旨在通过信任构建过程中建立的建设性安全对齐，支持更具责任感的语言模型，促进用户为中心的AI的发展。为此，作者发布了Oyster-I、代码和基准，以支持负责任和用户中心的AI发展。"}
{"llm_update_time": "20250907", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2509.02077", "html_url": "https://arxiv.org/abs/2509.02077", "title": "基于句向量变换器的方法从攻击描述到漏洞识别", "title_en": "From Attack Descriptions to Vulnerabilities: A Sentence Transformer-Based Approach", "authors": "Refat Othman,Diaeddin Rimawi,Bruno Rossi,Barbara Russo", "background": "在安全领域，许多漏洞在被利用后仍然未被发现。本文中的漏洞指的是在Common Vulnerabilities and Exposures (CVE)报告中被公开披露的缺陷。为了实现及时的应急响应，需要建立攻击与漏洞之间的关联，以便为防御者提供即时且可操作的见解。然而，手工将攻击与CVE进行映射是不切实际的，这需要自动化的解决方案。本研究评估了14种最先进的（SOTA）句向量变换器，用以自动识别来自攻击描述的漏洞。研究表明，多问题-多段落基线点积版本（MMPNet）模型在使用攻击技术描述进行分类时表现最佳，F1分数为89.0，精确率为84.0，召回率为94.7。此外，MMPNet模型识别的56%的漏洞与攻击相关的CVE记录一致，且模型检测的61%的漏洞与CVE库中的漏洞相符。", "innovation": "本文应用了基于句向量变换器的方法来自动识别攻击描述中的漏洞。研究结果表明，MMPNet模型在攻击技术描述分类中表现最佳，其F1分数、精确率和召回率分别达到了89.0、84.0和94.7。该方法不仅增强了对软件安全事件的检测和响应能力，还减少了漏洞可利用的时间，从而促进了更安全系统的发展。", "conclusion": "自动将攻击技术与漏洞进行关联不仅有助于提高软件安全事件的检测和应对能力，还减少了漏洞可被利用的时间，从而有助于构建更安全的系统。"}
{"llm_update_time": "20250907", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.03616", "html_url": "https://arxiv.org/abs/2509.03616", "title": "通过表示学习进行多属性偏见缓解", "title_en": "Multi Attribute Bias Mitigation via Representation Learning", "authors": "Rajeev Ranjan Dwivedi,Ankur Kumar,Vinod K Kurmi", "background": "现实世界中的图像通常会表现出多种重叠的偏见，包括纹理、水印、性别妆容、场景对象配对等。这些偏见共同降低了现代视觉模型的性能，削弱了它们的鲁棒性和公平性。单独解决这些偏见是不够的，因为缓解一个偏见往往会导致或加剧其他偏见。", "innovation": "我们提出了Generalized Multi Bias Mitigation (GMBM)，这是一种轻量级的两阶段框架，仅需在训练期间使用分组标签，在测试时最小化偏见。首先，Adaptive Bias Integrated Learning (ABIL) 会通过为每个属性训练编码器并将其与主骨干集成起来，识别已知捷径的影响，迫使分类器明确识别这些偏见。然后，Gradient Suppression Fine Tuning 将那些非常偏见方向从主骨干的梯度中修剪，最后得到一个单一紧凑的网络，它忽略了它刚刚学会识别的所有捷径。此外，我们发现现有的偏见度量在子组不平衡和训练测试分布转移时失效，因此我们引入了Scaled Bias Amplification (SBA)：这是一种测试时措施，能够区分模型引发的偏见放大与分布差异。", "conclusion": "GMBM 在 FB CMNIST、CelebA 和 COCO 上得到了验证，即使在偏见复杂性增加和分布转移加剧的情况下，也能显著提升最坏组的准确性，减半多属性偏见放大，并创下了新的 SBA 低值，使其成为第一个实用的端到端多偏见视觉识别解决方案。"}
{"llm_update_time": "20250907", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.03635", "html_url": "https://arxiv.org/abs/2509.03635", "title": "Reg3D: 用于3D场景理解的重建几何指令调优", "title_en": "Reg3D: Reconstructive Geometry Instruction Tuning for 3D Scene Understanding", "authors": "Hongpei Zheng,Lintao Xiang,Qijun Yang,Qian Lin,Hujun Yin", "background": "大型多模态模型（LMMs）的迅速发展促成了2D视觉理解的显著进步，但将其能力扩展到3D场景理解依然是一个重大挑战。现有方法主要依赖文本监督，未能提供学习稳健的3D空间表示所需的几何约束。因此，需要一种能够直接将几何感知监督纳入训练过程的新框架。", "innovation": "引入了Reg3D，一种新颖的重建几何指令调优框架。该框架通过在训练过程中直接引入几何感知监督来解决现有方法的局限性。与现有方法仅在输入端注入3D信息不同，Reg3D采用一种双重监督范式，充分利用3D几何信息作为输入和明确的学习目标。通过在双编码器架构中设计对象级和帧级重建任务，并强制几何一致性，来促进空间推理能力的发展。", "conclusion": "在ScanQA、Scan2Cap、ScanRefer和SQA3D等数据集上的广泛实验表明，Reg3D带来了显著的性能提升，并为具有空间意识的多模态模型提供了新训练范式。"}
{"llm_update_time": "20250907", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.03633", "html_url": "https://arxiv.org/abs/2509.03633", "title": "treeX: 无需监督的密集森林点云中树木实例分割", "title_en": "treeX: Unsupervised Tree Instance Segmentation in Dense Forest Point Clouds", "authors": "Josafat-Mattias Burmeister,Andreas Tockner,Stefan Reder,Markus Engel,Rico Richter,Jan-Peter Mund,Jürgen Döllner", "background": "激光扫描技术可以提供森林树干的详细3D捕捉，但需要高效的软件来处理3D点云数据并提取单独的树木。虽然最近的研究引入了深度学习方法来进行树木实例分割，但这些方法需要大量标注的数据集和大量的计算资源。因此，需要一种资源高效的替代方案。", "innovation": "本文提出了修订版的树X算法，这是一种无需监督的方法，结合基于聚类的树干检测与区域生长法进行树冠界定。该论文提供了两个参数预设，一个适用于地面激光扫描（固定陆地激光扫描- TLS 和 个人激光扫描- PLS），另一个适用于无人机激光扫描（无人机激光扫描- ULS）。", "conclusion": "相比于原始的树X算法，修订版减少了运行时间并提高了准确性，特别是在地面数据上的实例检测F1-得分提高了0.11到0.49。而为了无人机数据，预设可以获得0.58的F1-得分，而原始算法未能分割任何正确的实例。总体而言，该算法在TLS和PLS数据上的准确度类似于最近的开源方法，包括深度学习方法。对于资源利用效率和用于深度学习模型的半自动标签生成，修订版的树X算法具有两个主要应用领域。"}
{"llm_update_time": "20250907", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.03614", "html_url": "https://arxiv.org/abs/2509.03614", "title": "检测和分类2025年MIDOG挑战中的分裂细胞的教师-学生模型", "title_en": "Teacher-Student Model for Detecting and Classifying Mitosis in the MIDOG 2025 Challenge", "authors": "Seungho Choe,Xiaoli Qin,Abubakr Shafique,Amanda Dy,Susan Done,Dimitrios Androutsos,April Khademi", "background": "病理学家在统计分裂图时需要耗费大量时间，并且这会导致观察者间的一致性差异。人工智能（AI）提供了一种解决方案，即通过自动检测分裂图来维持决策一致性。然而，AI工具可能会受到领域转移的负面影响，这会导致显著的性能下降，尤其是在训练集和测试集之间存在组织形态差异、物种差异和染色协议变化时。此外，分裂的数量远远少于正常细胞核的数量，这导致了检测任务中数据的高度不平衡。", "innovation": "本文将分裂检测问题定义为像素级别的分割，并提出了一种教师-学生模型，同时解决了分裂检测（Track 1）和异常分裂分类（Track 2）。该方法基于集成领域泛化模块的UNet分割骨干，包括对比表示学习和领域对抗性训练。通过教师-学生策略生成像素级伪掩码，不仅为注释的分裂和困难负例，也为正常细胞核生成，从而增强特征区分并提高对领域转移的鲁棒性。此外，提出了一种多尺度CNN分类器，利用分割模型中的特征图进行多任务学习。", "conclusion": "在初步测试集中，该算法在分裂检测赛道（Track 1）中的F1分数为0.7660，在异常分裂分类赛道（Track 2）中的平衡精度为0.8414，这表明将基于分割的检测和分类集成到统一框架中可以实现稳健的分裂分析。"}
{"llm_update_time": "20250907", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.03737", "html_url": "https://arxiv.org/abs/2509.03737", "title": "LayoutGKN：楼地板面布局图的图相似性学习", "title_en": "LayoutGKN: Graph Similarity Learning of Floor Plans", "authors": "Casper van Engelenburg,Jan van Gemert,Seyran Khademi", "background": "楼地板面布局图展示了建筑的布局，通常被表示为图以捕捉潜在的空间关系。比较这些图对于搜索、聚类和数据可视化等应用程序至关重要。最成功的图比较方法，例如图匹配网络，依赖于成本高昂的跨图节点级交互，因此在推理时间上速度较慢。现有方法在处理规模和速度上存在局限性，需要优化以提高效率和性能", "innovation": "我们引入了LayoutGKN，一种更有效的图比较方法。通过在联合嵌入架构的末尾延迟跨图节点级交互，利用可微分图核作为最终学习节点级嵌入的距离函数，使得LayoutGKN在计算相似性方面表现与图匹配网络相当或更好，同时显著提高了速度。Code和数据已开放", "conclusion": "LayoutGKN通过在联合嵌入的末尾延迟跨图节点级交互，并利用可微分图核作为距离函数，实现了与图匹配网络相当或更好的相似性计算，显著提高了速度。"}
{"llm_update_time": "20250907", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.03729", "html_url": "https://arxiv.org/abs/2509.03729", "title": "基于迁移学习的CNN模型在基于叶脉模式识别植物物种的应用", "title_en": "Transfer Learning-Based CNN Models for Plant Species Identification Using Leaf Venation Patterns", "authors": "Bandita Bharadwaj,Ankur Mishra,Saurav Bharadwaj", "background": "本文评估了三种深度学习架构（ResNet50、MobileNetV2和EfficientNetB0）在基于叶脉模式自动植物物种分类中的效果，叶脉模式是具有高分类学相关性的关键形态特征。通过使用包含15种不同物种图像的瑞典叶数据集（每种物种75张图像，总共1,125张图像），在训练和测试阶段均使用标准性能指标展示了这些模型。", "innovation": "通过对ResNet50、MobileNetV2和EfficientNetB0这三种模型进行评估，发现EfficientNetB0在测试准确率和F1评分上超过了其他两种模型，表明其在基于叶脉模式分类中具有更好的鲁棒性和准确性，尤其突显了其在开发可扩展且准确的自动化植物分类工具方面的潜力，特别是在使用迁移学习的CNN模型方面有创新之处。", "conclusion": "研究表明，通过深度学习方法，尤其是EfficientNetB0，可以在基于叶脉模式的植物分类任务中实现高性能。这强调了深度学习在这类应用中的潜力，并为未来的植物自动分类工具开发奠定了基础。"}
{"llm_update_time": "20250907", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.03631", "html_url": "https://arxiv.org/abs/2509.03631", "title": "轻量级图象分割用于超声心动图", "title_en": "Lightweight image segmentation for echocardiography", "authors": "Anders Kjelsrud,Lasse Løvstakken,Erik Smistad,Håvard Dalen,Gilles Van De Vyver", "background": "准确分割左心室在超声心动图中可实现临床测量的全自动化提取，例如容积和射血分数。尽管nnU-Net配置模型表现良好，但它们体积庞大且运行速度慢，限制了实时使用。通过消除研究和逐步评估数据增强方案、架构修改、损失函数和后处理技术，我们确定了最有效的nnU-Net组件。研究发现简单的仿射增强和深度监督能提升性能，而复杂的增强和庞大的模型容量则带来的收益递减。基于该研究，我们开发了一种轻量级U-Net（参数量为2M vs 33M），在CAMUS数据集（N=500）上的Dice分数为0.93/0.85/0.89 vs 0.93/0.86/0.89（LV/MYO/LA），同时体积仅为默认nnU-Net配置的1/16，速度为默认配置的4倍（每帧1.35ms vs 5.40ms），性能上具有统计学等效性。并且在内部数据集（N=311）上的交叉评估表明有良好的泛化能力。", "innovation": "提出了一种通过简化增强方案和降低模型容量的方法来开发轻量级U-Net，使其在保持性能的同时显著减少了计算资源需求，既适用于实时应用也具有良好的泛化能力。", "conclusion": "轻量级U-Net在左心室分割上达到了与大规模模型相当的性能，同时显著减小了模型规模和提高了处理速度，在多种评价数据集上表现出良好的泛化能力。"}
{"llm_update_time": "20250907", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.03786", "html_url": "https://arxiv.org/abs/2509.03786", "title": "SLENet: 针对水下伪装目标检测的指导增强网络", "title_en": "SLENet: A Guidance-Enhanced Network for Underwater Camouflaged Object Detection", "authors": "Xinxin Wang,Han Sun,Ningzhong Liu,Huiyu Zhou,Yinan Yao", "background": "水下伪装目标检测（UCOD）旨在识别能够无缝融入水下环境的目标物。这一任务对海洋生态学至关重要，但目前该领域尚未得到广泛探索，且准确识别受到光学畸变、水体浑浊以及海洋生物复杂特性的影响较大。", "innovation": "本文提出了UCOD任务以及DeepCamo基准数据集，并提出了一种新颖的框架——语义定位与增强网络（SLENet）。特别地，SLENet整合了Gamma-非对称增强（GAE）模块和定位指导分支（LGB），以增强多尺度特征表示同时生成包含全局语义信息的位置图，指导多尺度监督解码器（MSSD）生成更准确的预测。", "conclusion": "我们的实验结果表明，SLENet在我们的DeepCamo数据集以及三个基准目标检测数据集上的性能优于最先进的方法，进一步证明了其在更广泛的COD任务中的高度通用性。"}
{"llm_update_time": "20250907", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.03794", "html_url": "https://arxiv.org/abs/2509.03794", "title": "将图像扩散模型应用于视频数据集", "title_en": "Fitting Image Diffusion Models on Video Datasets", "authors": "Juhun Lee,Simon S. Woo", "background": "图像扩散模型在生成建模中通常采用独立抽样的静态图像进行训练。尽管这是生成模型的基本任务协议，但仅通过静态快照来捕捉时间序列世界的设计存在信息不足的局限。这一限制导致了收敛速度慢、分布覆盖不充分以及泛化能力弱。因此，有必要开发一种方法来克服这种限制。", "innovation": "本文提出了一种简单有效的训练策略，能够利用连续视频帧中的时间归纳偏差来改进扩散训练。该方法无需修改架构即可无缝集成到标准的扩散训练管道中。", "conclusion": "通过在HandCo数据集（其中手-物体交互表现出密集的时间连贯性，手指关节的微小变化通常导致有语义意义的不同运动）上评估该方法，结果表明该方法使收敛速度提高了超过2倍，并在训练和验证分布上实现了较低的FID。同时，该方法通过鼓励模型捕捉有意义的时间变化来增强生成的多样性。进一步的优化分析表明，正则项减少了梯度方差，从而促进了更快的收敛。"}
{"llm_update_time": "20250907", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.03704", "html_url": "https://arxiv.org/abs/2509.03704", "title": "QuantV2X：一种全量化多代理系统以实现协同感知", "title_en": "QuantV2X: A Fully Quantized Multi-Agent System for Cooperative Perception", "authors": "Seth Z. Zhao,Huizhi Zhang,Zhaowei Li,Juntong Peng,Anthony Chui,Zewei Zhou,Zonglin Meng,Hao Xiang,Zhiyu Huang,Fujia Wang,Ran Tian,Chenfeng Xu,Bolei Zhou,Jiaqi Ma", "background": "通过车辆对万物（V2X）通信进行协同感知具有显著增强了车辆感知的潜力，可以缓解遮挡并扩展视野。然而，过去的大多数研究主要集中在提高准确性指标方面，而未考虑系统层面的关键考量，如效率、延迟和实际部署能力。大多数现有系统依赖于全精度模型，这带来了巨大的计算和传输成本，使得它们在资源受限环境中无法实时运作。因此，对于实际部署而言，高效的量化方法是提高V2X协同感知系统性能并降低资源消耗的关键，但也面临低比特率下保持准确性及优化系统级延迟的挑战。", "innovation": "介绍了QuantV2X，这是一个专为此类准确、可扩展部署的设计的全量化多代理系统，用于多模态、多代理V2X协同感知。该系统提出了一种统一的端到端量化策略，同时在神经网络模型和传送消息表示中进行量化减少计算负担和传输带宽。在低比特率下仍能保持与全精度系统相当的准确性，系统水平延迟降低3.2倍，mAP30提高9.5%。此外，QuantV2X更具扩展性，能够使更大、更强大的模型在严格内存预算下运行。这表明，全量化的多代理系统是一种可行的、适合实际部署的解决方案。QuantV2X系统将公开发布，以促进此领域的研究：this https URL.", "conclusion": "这些结果强调了实际部署中完全量化多代理中间融合系统的可行性和有效性。QuantV2X能够提高V2X系统在分布式环境中交互和共享感知数据的能力。"}
{"llm_update_time": "20250907", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.03803", "html_url": "https://arxiv.org/abs/2509.03803", "title": "通过视觉粒化引导的因果性提示学习", "title_en": "Causality-guided Prompt Learning for Vision-language Models via Visual Granulation", "authors": "Mengyu Gao,Qiulei Dong", "background": "提示学习最近引起了对适配预训练视觉-语言模型（如CLIP）到下游识别任务的关注。然而，大多数基于CLIP的提示学习方法在处理细粒度数据集时能力有限。", "innovation": "提出了一种通过视觉粒化基于因果性引导的文本提示学习方法（称为CaPL），旨在通过因果推理构建视觉粒度集，以捕捉不同细粒度类别间的细微差异，并拆分视觉特征为非个体属性和个体属性，通过因果推理策略构建视觉粒度。", "conclusion": "通过广泛的实验，证明CaPL方法在15个数据集上显著优于最先进的提示学习方法，特别是在细粒度数据集上表现出色。"}
{"llm_update_time": "20250907", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.03740", "html_url": "https://arxiv.org/abs/2509.03740", "title": "Singular Value Few-shot Adaptation of Vision-Language Models", "title_en": "Singular Value Few-shot Adaptation of Vision-Language Models", "authors": "Taha Koleilat,Hassan Rivaz,Yiming Xiao", "background": "Vision-language models（VLMs）如CLIP展示了令人印象深刻的零样本和少样本学习能力，适用于多种应用。然而，这些模型适应新的细粒度领域依然困难，主要是依赖于提示工程技术以及全模型微调的高成本。现有的适应方法依赖于增强组件，如提示令牌和适应模块，这些组件可能会限制适应质量，使模型不稳定，并损害预训练期间学习的丰富知识。", "innovation": "CLIP-SVD是一种新颖的多模态和参数高效适应技术，利用奇异值分解（SVD）修改CLIP的内部参数空间，而不注入额外模块。该技术仅微调CLIP参数矩阵中的奇异值以重新缩放基向量，用于领域适应，同时保留了预训练模型。此设计使得只使用模型总参数的0.04%即可实现增强的适应性能，并更好地保留其泛化能力。CLIP-SVD在11个自然和10个生物医学数据集上实现了最先进的分类结果，在少量样本设置下的准确性和泛化能力均优于先前方法。此外，利用自然语言方法分析CLIP适应的有效性和动态，以提供CLIP-SVD的可解释性。", "conclusion": "CLIP-SVD在多个自然和生物医学数据集上实现了卓越的分类结果，并显著优于先前的方法。它是一种参数高效的、仅使用少量参数进行微调的领域适应技术，有助于保持模型的泛化能力。同时，通过自然语言方法分析模型适应的情况，提供了更好的可解释性。"}
{"llm_update_time": "20250907", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.03872", "html_url": "https://arxiv.org/abs/2509.03872", "title": "Focus Through Motion: RGB-Event Collaborative Token Sparsification for Efficient Object Detection", "title_en": "Focus Through Motion: RGB-Event Collaborative Token Sparsification for Efficient Object Detection", "authors": "Nan Yang,Yang Wang,Zhanwen Liu,Yuchao Dai,Yang Liu,Xiangmo Zhao", "background": "现有的RGB-事件检测方法在特征提取和融合过程中，对于两种模态（图像中的背景以及事件数据中的非事件区域）的低信息区域处理相同，导致计算成本高且性能不佳。为了减少特征提取过程中的计算冗余，研究人员分别针对图像与事件模态提出了自适应令牌稀疏化方法，但这些方法通常采用固定数量或阈值选择令牌，不能很好地适应具有不同复杂度的样例。为此，本文提出了FocusMamba方法，在多模态特征提取过程中实现了自适应协作稀疏化，更有效地融合互补信息。", "innovation": "本文提出了一种Event-Guided Multimodal Sparsification（EGMS）策略，利用事件相机感知到的场景内容变化识别并自适应地消去各模态中的低信息区域，以及一种Cross-Modality Focus Fusion（CMFF）模块，根据稀疏化结果有效获取和融合互补特征。通过在DSEC-Det和PKU-DAVIS-SOD数据集上的实验，证明了该方法在准确性和效率上都优于现有方法。", "conclusion": "实验结果表明，本文提出的FocusMamba方法在准确性和效率上都优于现有方法。"}
{"llm_update_time": "20250907", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.03883", "html_url": "https://arxiv.org/abs/2509.03883", "title": "Human Motion Video Generation: A Survey", "title_en": "Human Motion Video Generation: A Survey", "authors": "Haiwei Xue,Xiangyang Luo,Zhanghao Hu,Xin Zhang,Xunzhi Xiang,Yuqin Dai,Jianzhuang Liu,Zhensong Zhang,Minglei Li,Jian Yang,Fei Ma,Zhiyong Wu,Changpeng Yang,Zonghong Dai,Fei Richard Yu", "background": "由于其广泛的应用前景，人类运动视频生成受到了研究界的高度关注，推动了诸如逼真的唱歌头像或与音乐同步自然舞蹈的动态头像等创新。但现有的文献综述多关注单一方法，缺乏对整个生成过程的全面概述。这篇论文旨在填补这一空白，提供了对人类运动视频生成的深度综述，涵盖了超过十个子任务，并详细描述了生成过程的五个关键阶段：输入、运动规划、运动视频生成、细化和输出。", "innovation": "这是首次综述中讨论大型语言模型在增强人类运动视频生成潜力的研究，涵盖了视觉、文本和音频三种主要模态的最新发展和技术趋势，并通过综述超过两百篇论文为该领域提供了全面概述，突出了推动技术突破的重要里程碑工作。", "conclusion": "论文旨在揭示人类运动视频生成的前景，为数字人类的全面应用提供宝贵资源。相关模型的完整列表可在我们的存储库中查看：this https URL."}
{"llm_update_time": "20250907", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.03808", "html_url": "https://arxiv.org/abs/2509.03808", "title": "EGTM: 基于事件引导的高效湍流抑制", "title_en": "EGTM: Event-guided Efficient Turbulence Mitigation", "authors": "Huanan Li,Rui Fan,Juntao Guan,Weidong Hao,Lai Rui,Tong Wu,Yikai Wang,Lin Gu", "background": "湍流抑制（TM）旨在去除大气湍流对框架相机引入的随机失真和模糊。现有的基于深度学习的先进TM方法通过提取多幅降质帧中的湍流特征，找到所谓的“幸运”帧中的未受扭曲的局部区域，进行“幸运融合”。然而，这种方法在从低分辨率帧间湍流动力学中学习时需要高容量网络，且计算和存储效率较低。具有微秒级时间分辨率的事件相机通过其稀疏和异步成像机制有望解决这一瓶颈。", "innovation": "本文提出了基本的“事件幸运洞察”，揭示了湍流失真与事件流的逆空间时间分布之间的关系。基于此洞察，提出了一种新型的EGTM框架，从显式的但噪声的湍流事件中提取像素级可靠的无湍流引导，实现时间上的“幸运融合”。此外，构建了首个用于湍流数据获取的第一事件驱动TM数据集。实验证明，该方法在模型大小、推理延迟和模型复杂性方面分别提高了710倍、214倍和224倍，同时在实时EGTM数据集上实现最优的恢复质量（+0.94 PSNR和+0.08 SSIM），展示了将事件模态引入TM任务的高效性。", "conclusion": "本文的研究表明，引入事件模态到TM任务中具有显著的效率优势。在模型大小、推理延迟和模型复杂性方面具有显著优势，同时实现了最优的恢复质量。"}
{"llm_update_time": "20250907", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.03895", "html_url": "https://arxiv.org/abs/2509.03895", "title": "Attn-Adapter: 需要注意力的适配器是在线视觉-语言模型少样本学习者的全部需要", "title_en": "Attn-Adapter: Attention Is All You Need for Online Few-shot Learner of Vision-Language Model", "authors": "Phuoc-Nguyen Bui,Khanh-Binh Nguyen,Hyunseung Choo", "background": "对比视觉-语言模型在零样本图像识别中表现出色，但在少样本情景下却面临着巨大的挑战。这主要是由于需要大量计算资源的离线微调过程，使得模型容易过拟合。", "innovation": "本文提出了一种名为Attn-Adapter的新型在线少样本学习框架，通过双重注意机制增强CLIP的适应性。Attn-Adapter通过两个组件—Memory Attn-Adapter和Local-Global Attn-Adapter，分别利用支持样本细化类别嵌入，以及整合局部和全局特征增强图像嵌入，从而实现基于少量标记样本的动态适应，无需重新训练基础模型。", "conclusion": "Attn-Adapter在跨类别和跨数据集泛化方面超过了现有最先进的方法，同时保持了高效推理并适应于不同的CLIP基础架构。"}
{"llm_update_time": "20250907", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.03800", "html_url": "https://arxiv.org/abs/2509.03800", "title": "MedVista3D：减少3D CT疾病检测、理解和报告中的诊断错误的视觉-语言建模", "title_en": "MedVista3D: Vision-Language Modeling for Reducing Diagnostic Errors in 3D CT Disease Detection, Understanding and Reporting", "authors": "Yuheng Li,Yenho Chen,Yuxiang Lai,Jike Zhong,Vanessa Wildman,Xiaofeng Yang", "background": "临床实践中放射诊断错误，如遗漏局部异常、缺乏全局背景及报告语言一致性问题仍然普遍存在。这些问题在3D成像中尤为突出，因为医生必须仔细检查每幅扫描片中的大量切片。现有的解决方法尚未能同时满足精确局部检测、全面体积理解及语义一致的自然语言报告需求，尤其是在处理报告的不确定性和未标注的问题上存在困难。因此，一种能够解决这些挑战的系统成为迫切需要。MedVista3D作为一种多尺度语义增强的视觉-语言预训练框架，旨在解决3D CT分析的挑战，通过局部和全局图像-文本对齐，实现细粒度的表示学习，并通过语言模型重写和引入放射学语义匹配银行来应对报告变异性，从而提升疾病分类、报告检索和医疗视觉问答的性能，同时能够很好地迁移到器官分割和预后预测中。", "innovation": "MedVista3D通过多尺度语义增强的视觉-语言预训练框架，提出了一种新的方法来应对3D CT中的诊断挑战。该方法通过对局部和全局图像-文本的对齐，提升了细粒度表示学习的能力。同时，通过语言模型重写和引入放射学语义匹配银行的方法，解决了报告的变异性问题，从而提高了零样本疾病分类、报告检索和医疗视觉问答的性能，并且容易迁移到器官分割和预后预测中。", "conclusion": "MedVista3D在零样本疾病分类、报告检索和医疗视觉问答上达到了最先进的性能，同时能够很好地迁移到器官分割和预后预测任务中，展示了其在减少3D CT诊断错误中的有效性。代码和数据集将会公开。"}
{"llm_update_time": "20250907", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.03754", "html_url": "https://arxiv.org/abs/2509.03754", "title": "STA-Net: 一种解耦形状和纹理注意机制的轻量化植物病害分类网络", "title_en": "STA-Net: A Decoupled Shape and Texture Attention Network for Lightweight Plant Disease Classification", "authors": "Zongsen Qiu", "background": "随着全球粮食安全需求的上升，精准农业和基于深度学习的植物病害诊断变得至关重要。然而，将高精度模型部署到边缘设备上具有挑战性。大多数轻量化网络使用为通用对象识别设计的注意力机制，这些机制对于捕捉不规则病害特征（如不规则病变形状和复杂纹理）效果不佳。因此，本文提出了一种两步解决方案：首先，使用一种无需训练的神经架构搜索方法（DeepMAD）来创建适用于边缘设备的高效网络结构；其次，引入了形状-纹理注意力模块（STAM）。STAM将注意力机制分为两个分支：一个使用变形卷积（DCNv4）进行形状感知，另一个使用Gabor滤波器银行进行纹理感知。", "innovation": "本文创新性地提出了两种方法：一是无需训练的神经架构搜索方法DeepMAD，用于为边缘设备创建高效网络结构；二是提出了形状-纹理注意力模块（STAM），该模块将注意力分为形状和纹理两个分支，分别使用变形卷积和Gabor滤波器银行来感知这些特征。该方法在公共CCMT植物病害数据集上达到了89.00%的准确率和88.96%的F1分数，并通过消融研究验证了STAM显著提高了模型性能，超过了基线和标准的注意力模型。通过解耦注意力机制结合学科知识，可以为边缘部署的精确农业人工智能开辟一条前景光明的道路。", "conclusion": "本文通过引入解耦形状和纹理注意力机制的STA-Net模型，解决了现有轻量化网络在边缘设备上针对植物病害分类时存在的不足，提出了一个有效和高效的方法，并实验证明其在准确率和F1分数上均表现优异。同时，此研究表明，通过解耦注意力机制结合专业知识，可以有效改进边缘部署的精准农业AI系统。相关源代码可在提供的链接中下载。"}
{"llm_update_time": "20250907", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.03893", "html_url": "https://arxiv.org/abs/2509.03893", "title": "弱监督学习密集功能性对应关系", "title_en": "Weakly-Supervised Learning of Dense Functional Correspondences", "authors": "Stefan Stojanov,Linan Zhao,Yunzhi Zhang,Daniel L. K. Yamins,Jiajun Wu", "background": "在形状重建和机器人操作等任务中，图像对之间的密集对应关系的建立是关键。跨不同类别的配对中，物体的功能，即物体对其他物体可能产生的影响，可以指导如何建立对应关系。因为能够执行特定功能的物体部分在形状和外观上往往具有相似性。因此，基于这一观察，本文定义了密集功能性对应，并提出了一种弱监督学习框架来解决这一预测问题。", "innovation": "本文的主要创新点在于利用视觉-语言模型对多视角图像进行伪标签，以获得功能部位，然后结合像素对应关系的密集对比学习来提炼功能性和空间知识，从而训练出一个新的模型，能够建立密集的功能性对应关系。此外，还构建了合成和现实数据集作为任务基准，证明了本文方法相较于现有自监督图像表示和视觉语言模型基线方案的优势。", "conclusion": "本文展示了利用弱监督学习建立密集功能性对应关系的有效性，特别是在视觉-语言模型的帮助下获取功能部位，并通过密集像素对比学习将功能性和空间知识整合到新的模型中。"}
{"llm_update_time": "20250907", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.03873", "html_url": "https://arxiv.org/abs/2509.03873", "title": "SalientFusion: 上文感知组合零样本食品识别", "title_en": "SalientFusion: Context-Aware Compositional Zero-Shot Food Recognition", "authors": "Jiajun Song,Xiaoou Liu", "background": "食品识别引起了广泛关注，但由于新菜肴的迅速出现，需要识别未见食品类别的方法，从而推动了零样本食品学习（ZSFL）的发展。研究者将食品识别任务推广到组合零样本食品识别（CZSFR），强调菜肴和食材自然与组合零样本学习（CZSL）中的属性和对象相匹配，但面临关联背景信息冗余导致模型难以学习有意义的食品特征、主菜与辅菜角色混淆导致分类错误、以及单一属性的语义偏差导致理解混淆等挑战.", "innovation": "提出了一种上下文感知的组合零样本食品识别方法（SalientFusion），包含两个组件：SalientFormer移除背景冗余并利用深度特征解决角色混淆问题；DebiasAT通过视觉特征对齐提示减少语义偏差。SalientFusion在所提出的基准CZSFood-90和CZSFood-164，以及通用组合零样本学习基准中表现出最先进的性能.", "conclusion": "通过我们的基准数据集，SalientFusion在这些基准上获得了最先进的结果，同时在主要的通用组合零样本学习数据集上也表现最好。代码可在以下链接获取：this https URL."}
{"llm_update_time": "20250907", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.03887", "html_url": "https://arxiv.org/abs/2509.03887", "title": "OccTENS：通过时序下一尺度预测的3D占位世界模型", "title_en": "OccTENS: 3D Occupancy World Model via Temporal Next-Scale Prediction", "authors": "Bu Jin,Songen Gu,Xiaotao Hu,Yupeng Zheng,Xiaoyang Guo,Qian Zhang,Xiaoxiao Long,Wei Yin", "background": "现有的生成模型预测3D场景的未来占位情况时，面临着巨大的挑战，例如：效率低下、长期生成过程中的时间衰减以及缺乏可控性。最近基于自回归（AR）的方法虽然能同时预测车辆运动和未来占位场景，但这些方法往往在这三个方面存在问题。因此，需要一种能够高效、准确、可控地预测3D场景未来占位情况的模型，以应对上述挑战。", "innovation": "本文提出了OccTENS，一种生成的3D占位世界模型，能够在保持计算效率的同时实现可控的高保真长期占位生成。通过将占位世界模型重新形式化为时间下一尺度预测（TENS）任务，将时间序列建模问题分解为空间尺度生成和时间场景预测的建模，采用TensFormer有效管理时间和空间关系，增强姿态可控性，通过统一序列建模位于性和自我运动，实现更好的占位质量与更快的推理时间。", "conclusion": "实验表明，OccTENS在占用质量和推理时间方面优于现有最佳方法。该模型能够有效解决临域生成、时间和空间关系处理及可控性等长期存在的问题，为3D场景的预测提供了更好的解决方案。"}
{"llm_update_time": "20250907", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.03950", "html_url": "https://arxiv.org/abs/2509.03950", "title": "使用EfficientNet-B4迁移学习在U-Net架构中的胸部X光气胸分割", "title_en": "Chest X-ray Pneumothorax Segmentation Using EfficientNet-B4 Transfer Learning in a U-Net Architecture", "authors": "Alvaro Aranibar Roque,Helga Sebastian", "background": "气胸是胸膜空间异常积气的情况，若未检测到可能危及生命。胸部X光是首选的诊断工具，但对于小型病例可能难以识别。", "innovation": "提出了一种自动深度学习管道，使用EfficientNet-B4编码器的U-Net以分割气胸区域。通过SIIM-ACR数据集进行训练，结合数据增强和二元交叉熵与Dice损失的组合，该模型在独立的PTX-498数据集上的IoU达到0.7008，Dice得分为0.8241。结果显示模型可以准确定位气胸并支持放射科医生。", "conclusion": "该模型能够准确定位气胸并支持放射科医生，展示了使用EfficientNet-B4编码器的U-Net架构在胸部X光气胸分割任务中的有效性。"}
{"llm_update_time": "20250907", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.03897", "html_url": "https://arxiv.org/abs/2509.03897", "title": "SPECS: Specificity-Enhanced CLIP-Score for Long Image Caption Evaluation", "title_en": "SPECS: Specificity-Enhanced CLIP-Score for Long Image Caption Evaluation", "authors": "Xiaofu Chen,Israfel Salazar,Yova Kementchedjhieva", "background": "随着对生成详细图像描述的兴趣增加，标准评估指标变得越来越不可靠。基于N-gram的度量虽然高效，但无法捕捉语义正确性。设计用于解决这一问题的表示相似度（RS）度量，由于高计算成本，早期使用受限，在硬件进步后依然因与人类判断的相关性低而不受欢迎。相对而言，基于大型语言模型（LLMs）的度量与人类判断高度相关，但在模型开发过程中过于昂贵，无法反复使用。", "innovation": "我们提出了一种新的无参考RS度量SPECS（Specificity-Enhanced CLIPScore），专门用于长图像描述评估。SPECS通过改变CLIP的目标，强调特定性，即奖励正确细节并惩罚错误细节。实验表明，SPECS在与人类判断的相关性上与开源的LLM基度量相当，但效率远高于后者，从而为图像描述模型开发过程中的迭代评估提供了实际替代方案。", "conclusion": "SPECS提供了一种实用的替代方案，供在图像描述模型开发过程中进行迭代评估使用。相关的代码可以在此找到：[此处提供链接]。"}
{"llm_update_time": "20250907", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.03922", "html_url": "https://arxiv.org/abs/2509.03922", "title": "LMVC: 一种端到端学习的多视点视频编码框架", "title_en": "LMVC: An End-to-End Learned Multiview Video Coding Framework", "authors": "Xihua Sheng,Yingwen Zhang,Long Xu,Shiqi Wang", "background": "多视角视频是体积视频的关键数据源，能够实现沉浸式三维场景重建，但由于数据量巨大，给存储和传输带来了巨大的挑战。近期，基于深度学习的端到端视频编码取得了巨大成功，但主要集中在单视角或立体视频上，多视角场景的通用性尚被忽视。", "innovation": "提出了一个确保随机访问和向后兼容的端到端学习多视角视频编码（LMVC）框架，增强了压缩效率。关键创新在于有效利用独立视图的运动和内容信息来增强相关视图的压缩。具体提出了基于特征的跨视图运动向量预测方法，及跨视图熵模型，用于条件依赖视图运动编码。另外，提出了一种无需立体像的跨视图上下文预测模块，用于从解码的独立视图内容特征预测跨视图上下文，并结合跨视图上下文熵模型来捕获跨视图上下文先验。", "conclusion": "实验结果表明，提出的LMVC框架在与传统MV-HEVC标准参考软件的性能对比上表现出色，为该领域未来的研究建立了强有力的基线。"}
{"llm_update_time": "20250907", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.03903", "html_url": "https://arxiv.org/abs/2509.03903", "title": "胸片生成基础模型", "title_en": "A Generative Foundation Model for Chest Radiography", "authors": "Yuanfeng Ji,Dan Lin,Xiyue Wang,Lu Zhang,Wenhui Zhou,Chongjian Ge,Ruihang Chu,Xiaoli Yang,Junhan Zhao,Junsong Chen,Xiangde Luo,Sen Yang,Jin Fang,Ping Luo,Ruijiang Li", "background": "医疗健康领域缺乏注释多样化的医学图像是一个主要障碍，阻碍了可靠AI模型的开发。尽管在生成基础模型方面在自然图像上取得了显著进展，但在医疗图像上的应用较少，尤其是胸片生成方面缺乏统一框架。", "innovation": "开发了`ChexGen'，一种融合文本、掩码和边界框指导生成胸片的统一框架。利用潜在扩散变换器架构进行预训练，并构建了最大的已curated胸部X射线数据集，包含960,000张胸片报告对。通过专家评估和定量指标，ChexGen实现了对胸片的准确合成。此外，其模型能够生成多样化的患者群体，增强模型的公平性，检测和缓解了民统计偏见，提升了小样本训练数据在疾病分类、检测和分割任务中的性能。", "conclusion": "生成基础模型在构建更准确、更高效和更公平的医学AI系统中发挥着 transformative作用。"}
{"llm_update_time": "20250907", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.03961", "html_url": "https://arxiv.org/abs/2509.03961", "title": "基于文本差异增强的多模态特征融合网络在遥感变化检测中的应用", "title_en": "Multimodal Feature Fusion Network with Text Difference Enhancement for Remote Sensing Change Detection", "authors": "Yijun Zhou,Yikui Zhai,Zilu Ying,Tingfeng Xian,Wenlve Zhou,Zhiheng Zhou,Xiaolin Tian,Xudong Jia,Hongsheng Zhang,C. L. Philip Chen", "background": "尽管深层学习在遥感变化检测（RSCD）方面取得了进展，但大多数方法仅依赖图像模态，这限制了特征表示、变化模式建模和泛化能力，尤其是在光照和噪声干扰下。", "innovation": "提出了一种新的Multimodal Change（MMChange）方法，该方法结合了图像和文本模态，以增强准确性和鲁棒性。引入了Image Feature Refinement（IFR）模块以突出关键区域并抑制环境噪声。还使用Vision Language Model（VLM）生成双时相图像的语义描述，并设计了一个Textual Difference Enhancement（TDE）模块以捕获细微的语义变化。为了解决模态间的异质性，设计了Image Text Feature Fusion（ITFF）模块，实现深度跨模态融合。", "conclusion": "在LEVIRCD、WHUCD和SYSUCD上的广泛实验表明，MMChange在多个指标上均超越了现有最先进的方法，验证了其在多模态RSCD方面的有效性。代码可在该链接获取：this https URL"}
{"llm_update_time": "20250907", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.03951", "html_url": "https://arxiv.org/abs/2509.03951", "title": "ANTS: 通过MLLM塑形的自适应负文本空间用于OOD检测", "title_en": "ANTS: Shaping the Adaptive Negative Textual Space by MLLM for OOD Detection", "authors": "Zhu Wenjie,Zhang Yabin,Xin Jin,Wenjun Zeng,Lei Zhang", "background": "引入负标签（NLs）已被证明能有效提升Out-of-Distribution (OOD)检测效果。然而，现有方法往往缺乏对OOD图像的理解，难以构建准确的负空间。同时，假阴性标签的存在显著降低了它们的近OOD性能。", "innovation": "本文通过引入多模态大型语言模型（MLLMs）理解与推理能力，提出了一种自适应负文本空间（ANTS）。具体来说，通过识别出可能为OOD样本的图像作为负图像，并借助MLLM描述这些图像，生成能精确描述OOD分布和增强远OOD检测效果的表达性负句子。对于近OOD设置，本文通过MLLM生成视觉上相似的负标签，减少假阴性并提高近OOD检测性能。为此，设计了一个自适应加权分数，使得方法能在不同OOD任务设置（近OOD和远OOD）下灵活应用，无需依赖特定任务先验知识。", "conclusion": "在ImageNet基准测试上，ANTs显著降低了FPR95值4.2%，打破了之前的状态最优，并且该方法无需训练，支持零样本应用，具备高可扩展性。"}
{"llm_update_time": "20250907", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.03975", "html_url": "https://arxiv.org/abs/2509.03975", "title": "使用多任务学习和仅在模型训练期间可用的辅助数据提高血管分割", "title_en": "Improving Vessel Segmentation with Multi-Task Learning and Auxiliary Data Available Only During Model Training", "authors": "Daniel Sobotka,Alexander Herold,Matthias Perkonigg,Lucian Beer,Nina Bastati,Alina Sablatnig,Ahmed Ba-Ssalamah,Georg Langs", "background": "肝脏血管在磁共振成像数据中的分割对于血管重塑的计算分析至关重要，尤其是与多种肝病相关。现有的方法依赖于对比增强影像数据，但专用成像序列在不同环境中的获取并不一致。虽然无对比增强的影像更为常用，但血管分割依然具有挑战性，需要大量的标注数据。", "innovation": "提出了一种多任务学习框架，用于在无对比增强的肝脏MRI中进行血管分割。该框架利用仅在训练期间可用的对比增强MRI数据，减少了对大量标注训练示例的需求。该方法通过结合未标注和标注数据的原生及对比增强MRI数据进行模型训练，进一步提升分割效果，即使在推理时不使用辅助数据，也能提高血管分割的准确性。", "conclusion": "这种方法验证了在训练期间使用辅助数据来增强专家标注数据的效果，即使在推理时不使用辅助数据，也能提高血液分割的准确性。这种方法在脑肿瘤分割等不同领域的应用中也证明了其利益。"}
{"llm_update_time": "20250907", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.03986", "html_url": "https://arxiv.org/abs/2509.03986", "title": "Promptception: How Sensitive Are Large Multimodal Models to Prompts?", "title_en": "Promptception: How Sensitive Are Large Multimodal Models to Prompts?", "authors": "Mohamed Insaf Ismithdeen,Muhammad Uzair Khattak,Salman Khan", "background": "尽管近年来大型多模态模型（LMMs）在多项选择题回答（MCQA）任务上取得了成功，但LMMs的提示设计仍然存在诸多未解之谜。研究观察到即使是轻微的提示措辞和结构变化也会导致某些提示和模型的准确性偏差高达15%，极大地影响了LMMs的透明度和公平性评估，因为模型倾向于使用精心挑选的提示来报告其最佳性能。", "innovation": "本文引入了Promptception，一个系统性的框架，用于评估LMMs对提示的敏感性。该框架包含61种提示类型，跨越15个类别和6个超类别，每个类别都针对提示制定的特定方面，并用于评估10种LMMs（从轻量级开源模型到GPT-4o和Gemini 1.5 Pro）在3个MCQA基准（MMStar、MMMU-Pro、MVBench）中的表现。研究发现，专用模型对提示措辞更为敏感，反映了其与指令语义的更高一致性，而开源模型更为稳定，但在复杂的提示措辞方面则面临挑战。", "conclusion": "基于分析，文章提出了适用于专用和开源LMMs的提示原则，以促进更加稳健和公平的模型评估。"}
{"llm_update_time": "20250907", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.03938", "html_url": "https://arxiv.org/abs/2509.03938", "title": "TopoSculpt: Betti-Steered Topological Sculpting of 3D Fine-grained Tubular Shapes", "title_en": "TopoSculpt: Betti-Steered Topological Sculpting of 3D Fine-grained Tubular Shapes", "authors": "Minghui Zhang,Yaoyu Liu,Junyang Wu,Xin You,Hanxiao Zhang,Junjun He,Yun Gu", "background": "医学中的管状解剖结构是天然的三维导管，具有腔室、周围壁和复杂的分支拓扑结构。准确重建其几何形状和拓扑结构对于如支气管导航和脑动脉连接性评估等应用至关重要。现有的方法通常依赖于体素的重叠度量，这些方法无法捕捉拓扑的正确性和完整性。尽管拓扑感知的损失和持久同伦约束显示出潜力，但这些方法通常只在局部应用，无法保证全局一致性或推理时的几何错误修正。", "innovation": "我们提出了一种名为TopoSculpt的新颖框架，用于3D细粒度管状结构的拓扑精修。TopoSculpt 包括以下创新：(i) 细粒度的全面区域建模策略以捕捉完整的空间上下文；(ii) 引入了拓扑完整性Betti (TIB)约束，同时强制执行贝蒂数先验并确保全局完整性；(iii) 使用持续同伦的课程精修方案逐步从粗到细尺度修正错误。", "conclusion": "在具有挑战性的肺支气管和Willis环数据集上的大量实验表明，在几何形状和拓扑结构方面有显著改进。例如，$\beta_{0}$误差在肺支气管数据集上从69.00降低到了3.40，在Willis环数据集上从1.65降低到了0.30，树长检测和分支检测率提高了近10%。这些结果突显了TopoSculpt在修正关键拓扑错误和提高复杂3D管状解剖结构进行高保真建模方面的作用。更多相关信息可在该网址找到：this https URL。"}
{"llm_update_time": "20250907", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.03973", "html_url": "https://arxiv.org/abs/2509.03973", "title": "SAC-MIL: 融合空间意识的关联多重实例学习在组学全景切片图像分类中的应用", "title_en": "SAC-MIL: Spatial-Aware Correlated Multiple Instance Learning for Histopathology Whole Slide Image Classification", "authors": "Yu Bai,Zitong Yu,Haowen Tian,Xijing Wang,Shuo Yan,Lin Wang,Honglin Li,Xitong Ling,Bo Zhang,Zheng Zhang,Wufan Wang,Hui Gao,Xiangyang Gong,Wendong Wang", "background": "文中提出了一种用于WSI分类的Spatial-Aware Correlated Multiple Instance Learning（SAC-MIL）。传统的多重实例学习方法处理图像中实例的空间信息不够充分，且通常需要处理输入切片序列的不同长度问题。SAC-MIL方法通过引入一个位置编码模块和一个SAC块来改进这些问题，使得能够更好地处理切片中实例的空间关系，并能够有效处理不同长度的训练和测试序列。此外，SAC块使用MLP进行实例之间的全连接关联，在线性时间内完成，对于WSI分类更加易于部署，相较于基于Transformer的方法更为简便。", "innovation": "该方法创新点在于通过一个位置编码模块来编码切片中实例的位置信息，构建一个SAC块进行全实例关联，以线性的时间复杂性处理序列长度问题。具体来说，SAC-MIL通过在MLP上进行改进，使其能够在线性时间内处理长序列，不会需要定制的CUDA内核，而传统的Transformer方法则需要这些内核来处理长期依赖的问题。这种方法在CAMELYON-16、TCGA-LUNG和TCGA-BRAC数据集上达到了最新算法的性能。", "conclusion": "SAC-MIL方法通过结合位置编码模块和SAC块显著改进了WSI分类任务中的空间关联问题，并且在多个数据集上展示了卓越的性能。该方法在透明性和易于部署方面也优于基于Transformer的方法。"}
{"llm_update_time": "20250907", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.03999", "html_url": "https://arxiv.org/abs/2509.03999", "title": "SliceSemOcc：基于垂直切片的多模态3D语义占用率表示", "title_en": "SliceSemOcc: Vertical Slice Based Multimodal 3D Semantic Occupancy Representation", "authors": "Han Huang,Han Sun,Ningzhong Liu,Huiyu Zhou,Jiaquan Shen", "background": "随着自动驾驶对精确3D感知的需求，3D语义占用预测成为研究热点。与鸟瞰图(BEV)方法限于二维平面表现场景不同，语义占用预测利用完整的3D体素网格来建模各维度的空间结构，从而捕捉垂直轴上的语义变化。然而，大多数现有方法在处理体素特征时忽略了高度轴信息。与此同时，传统的SENet风格的通道注意力机制在所有高度层上赋予均匀权重，限制了它们强调不同高度特征的能力。", "innovation": "为了弥补这些限制，作者提出了一种新的垂直切片多模态框架SliceSemOcc。具体包括：1) 利用全局和局部垂直切片从高度轴中提取体素特征；2) 一个全局局部融合模块适当地结合了细微的空间细节和总体上下文信息；3) 提出SEAttention3D模块，该模块通过平均池化保留高度分辨率，并为每个高度层动态分配通道注意力权重。", "conclusion": "在nuScenes-SurroundOcc和nuScenes-OpenOccupancy数据集上的广泛实验验证了SliceSemOcc方法的优越性，尤其是在小对象类别上显著提高了平均交并比IoU。详细的消融实验进一步证明了所提SliceSemOcc框架的有效性。"}
{"llm_update_time": "20250907", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.04023", "html_url": "https://arxiv.org/abs/2509.04023", "title": "从多数标签学习：多类多项集学习中的一个新问题", "title_en": "Learning from Majority Label: A Novel Problem in Multi-class Multiple-Instance Learning", "authors": "Shiku Kaito,Shinnosuke Matsuo,Daiki Suehiro,Ryoma Bise", "background": "LML在图像分割（病理图像）、政治投票预测、客户情感分析和环境监测等多个应用场景中都有潜在的应用价值。传统的多项集学习方法在处理类不平衡和多数类主导的问题时表现不佳，因此需要一种新的方法来有效解决此问题。LML通过将袋的标签设为其中占据多数的类来简化标签过程，但如何有效估计每个实例的类以及提高多数类的比例成为挑战。", "innovation": "提出了一种新的算法Counting Network和一个新的模块Majority Proportion Enhancement Module (MPEM)。Counting Network通过计算每个类别的实例数量来估计袋的多数类标签；MPEM通过移除袋中少数类的实例来提高多数类的比例。实验结果表明，提出的算法在四个数据集上的表现优于传统的方法，并且消融研究验证了每个模块的有效性。此外，提供的代码可访问。", "conclusion": "通过解决LML问题，提出的Counting Network和MPEM模块有效提高了多数类的比例，并且在实验中证明了该方法的优越性，解决了传统多项集学习方法在处理多数类主导问题时的不足。"}
{"llm_update_time": "20250907", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.04009", "html_url": "https://arxiv.org/abs/2509.04009", "title": "通过弃用标记检测视觉变换器中的区域伪相关", "title_en": "Detecting Regional Spurious Correlations in Vision Transformers via Token Discarding", "authors": "Solha Kang,Esla Timothy Anzaku,Wesley De Neve,Arnout Van Messem,Joris Vankerschaver,Francois Rameau,Utku Ozbulak", "background": "神经网络在计算机视觉模型中的特征关联能力强，能够检测和利用数据中的非意图模式，基于统计相关但可能是错误或非意图的信号进行预测。在这种情况下，模型可能误将这些特征与预测任务关联起来，并依赖这些特征进行预测。这种现象被称为伪相关，即模式看似与任务相关，但实际上是一种巧合。因此，检测和消除伪相关对于构建可信赖、可靠和泛化的机器学习模型至关重要。这项研究重点探讨了视觉变换器中的伪相关问题。视觉变换器是近年来非常流行的神经网络架构。这项工作中展示了在ImageNet数据集上规范训练和自我监督训练模型的大规模实验验证了提出方法检测伪相关的有效性。", "innovation": "提出了一种新的方法来检测视觉变换器中的区域伪相关，这种方法使用了规范训练和自我监督训练模型，并在ImageNet数据集上进行了大规模实验。研究表明，即使使用相同的架构，训练方法对模型依赖伪相关有显著影响。该研究还揭示了ImageNet数据集中某些类别的伪信号，并讨论了这些信号的潜在原因。此外，还通过侵入性乳腺肿块分类进行了案例研究，以实证研究伪信号。", "conclusion": "研究发现了用于检测和缓解伪相关的图像列表，并建议在未来的研究中谨慎使用这些图像。通过该研究的发现，该领域内涉及这些图像的应用需要更加注意。"}
{"llm_update_time": "20250907", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.04092", "html_url": "https://arxiv.org/abs/2509.04092", "title": "TriLiteNet: 轻量级多任务视觉感知模型", "title_en": "TriLiteNet: Lightweight Model for Multi-Task Visual Perception", "authors": "Quang-Huy Che,Duc-Khai Lam", "background": "高效的感知模型对于高级驾驶辅助系统（ADAS）至关重要，因为这些应用需要快速处理和响应以确保在现实环境中的安全性和有效性。为了满足这些感知模型的实时执行需求，本文引入了TriLiteNet模型。该模型能够同时处理全景驾驶感知相关的多个任务，并且在优化性能的同时保持低计算成本。", "innovation": "TriLiteNet模型针对多任务视觉感知进行了优化，同时保持了低计算成本。实验结果表明，TriLiteNet在BDD100k数据集上的检测任务、可行驶区域分割任务和车道线分割任务上都取得了竞争力的表现，尤其是TriLiteNet_{base}仅使用2.35M参数和7.72 GFLOPs的计算成本就能实现85.6%的车辆检测召回率、92.4%的可行驶区域分割mIoU和82.3%的车道线分割准确率。此外，该模型包含一个仅有0.14M参数的小型配置，可以提供一个在计算需求极低情况下的多任务解决方案。", "conclusion": "通过平衡性能、计算效率和可扩展性，TriLiteNet提供了一种适用于现实世界自动驾驶应用的实用且可部署的解决方案。该模型在嵌入式设备上的延迟和功耗评价中表现出低延迟和合理的能耗。"}
{"llm_update_time": "20250907", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.04043", "html_url": "https://arxiv.org/abs/2509.04043", "title": "基于‘飞腾+寒武纪’的毫秒级响应无人机跟踪与凝视系统：国产化解决方案", "title_en": "Millisecond-Response Tracking and Gazing System for UAVs: A Domestic Solution Based on \"Phytium + Cambricon\"", "authors": "Yuchen Zhu,Longxiang Yin,Kai Zhao", "background": "在当前视频监控技术的前沿研究和应用中，传统摄像头系统由于自动识别算法的浅层特征提取能力和计算架构效率瓶颈，导致在动态场景下响应延迟超过200毫秒，无法满足复杂场景下的实时需求。", "innovation": "提出了一种基于飞腾处理器和寒武纪加速卡的异构计算架构，构建了具有50-100毫秒级响应能力的无人机跟踪与凝视系统。在硬件层面采用飞腾FT-2000/4处理器和MLU220加速卡协同计算架构，通过多卡并行增强计算能力；在软件层面，创新性地整合了轻量级的YOLOv5s检测网络与深层排序（DeepSORT）级联跟踪算法，形成“检测-跟踪-反馈”的闭环控制链。实验证明，该系统在1920*1080分辨率视频流处理中实现了稳定的一帧综合处理延迟，并在多尺度目标识别上达到了98.5%以上的准确率，兼具低延迟和高精度的特点。", "conclusion": "本研究为无人机监测提供了一种创新解决方案，同时实现了基于国产芯片的应用。"}
{"llm_update_time": "20250907", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.04126", "html_url": "https://arxiv.org/abs/2509.04126", "title": "MEPG：组成丰富图像生成的多专家规划与生成", "title_en": "MEPG:Multi-Expert Planning and Generation for Compositionally-Rich Image Generation", "authors": "Yuan Zhao,Liu Lin", "background": "文本到图像的扩散模型在图像质量方面已经取得了显著进展，但仍难以处理复杂的多元素提示，以及有限的风格多样性。", "innovation": "该论文提出了一种称为MEPG（多专家规划和生成框架）的新方法，结合了位置和风格感知的大语言模型（LLMs）和空间语义专家模块。MPEG框架包括两个核心组件：位置-风格感知（PSA）模块，利用监督微调的LLM将输入提示分解为精确的空间坐标和编码风格的语义指令；以及多专家扩散（MED）模块，通过区域间专家路由实现动态生成。", "conclusion": "实验结果表明，MEPG在图像质量和风格多样性方面明显优于具有相同主干的基础模型。"}
{"llm_update_time": "20250907", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.04123", "html_url": "https://arxiv.org/abs/2509.04123", "title": "TaleDiffusion: 多角色故事生成与对话渲染", "title_en": "TaleDiffusion: Multi-Character Story Generation with Dialogue Rendering", "authors": "Ayan Banerjee,Josep Lladós,Umapada Pal,Anjan Dutta", "background": "文本到故事的可视化由于需要跨帧间多个角色的一致性交互而极具挑战性。现有方法难以保证角色一致性，导致生成伪影和对话渲染不准确，从而使得故事脱节。", "innovation": "我们提出了TaleDiffusion，这是一种新的多角色故事生成框架，通过迭代过程，保持角色一致性，以及使用后处理准确匹配对话。首先，利用预训练的大语言模型进行上下文学习，生成每帧描述、角色细节和对话。然后，采用有界注意力的框掩码技术控制角色交互并减少伪影。接着，通过身份一致的自注意力机制确保帧间角色一致性，并使用区域感知的交叉注意力实现精确对象放置。最后，对话被呈现为气泡并使用CLIPSeg分配给特定角色。实验结果显示，TaleDiffusion在一致性、噪声减少和对话渲染方面优于现有方法。", "conclusion": "实验结果表明，TaleDiffusion在一致性、噪声减少和对话渲染方面优于现有方法。"}
{"llm_update_time": "20250907", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.04050", "html_url": "https://arxiv.org/abs/2509.04050", "title": "一种基于K最近邻加权融合的人员重排方法", "title_en": "A Re-ranking Method using K-nearest Weighted Fusion for Person Re-identification", "authors": "Quang-Huy Che,Le-Chuong Nguyen,Gia-Nghia Tran,Dinh-Duy Phan,Vinh-Tiep Nguyen", "background": "在人员再识别中，再排序是一个关键步骤，旨在通过细化最终排名的结果来提升整体准确性。以往的研究主要集中在单视角图像特征上，这会导致视角偏差以及姿态变化、视点变化和遮挡等问题。使用多视角特征表示人员可以帮助减少视角偏差。", "innovation": "提出了一种有效的人员再排序方法，通过使用K最近邻加权融合(KWF)方法聚合邻近样本特征。该研究还探索了特征聚合时的权重选择策略，以确定有效的策略。该方法无需对模型进行微调或额外标注，适用于大规模数据集。在Market1501、MSMT17和遮挡的DukeMTMC数据集上评估，结果表明该方法在再排序初始排行结果的前M个候选者时显著提高了Rank@1和mAP。特别是在挑战性数据集MSMT17和遮挡的DukeMTMC上，Rank@1再排序方法分别提高了9.8%/22.0%。此外，该方法在计算效率上显著优于其他再排序方法。", "conclusion": "提出的KWF方法有效提升了再识别的准确性和计算效率，尤其在MSMT17和遮挡的DukeMTMC等挑战性数据集上取得了显著的效果提升。"}
{"llm_update_time": "20250907", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.04086", "html_url": "https://arxiv.org/abs/2509.04086", "title": "TEn-CATS: Text-Enriched Audio-Visual Video Parsing with Multi-Scale Category-Aware Temporal Graph", "title_en": "TEn-CATS: Text-Enriched Audio-Visual Video Parsing with Multi-Scale Category-Aware Temporal Graph", "authors": "Yaru Chen,Faegheh Sardari,Peiliang Zhang,Ruohao Guo,Yang Xiang,Zhenbo Li,Wenwu Wang", "background": "现有的音频-视觉视频解析（AVVP）任务依赖于弱监督标注，旨在识别给定视频中的事件类别及其发生时间。现有方法主要分为两类：一类是改进基于注意力机制的架构以更好地进行时序建模，另一类是生成更丰富的伪标签以弥补帧级注解的缺失。然而，前一种方法将嘈杂的段级伪标签视为可靠的监督，而后一种方法让注意力机制在所有帧间泛化，导致初始错误在训练过程中被放大。这一问题亟需解决的方法来提高视频解析的准确性。", "innovation": "提出了一种结合了双向文本融合（BiT）模块和多尺度类别感知时间图（CATS）模块的方法来解决现有方法中存在的问题。该方法具体整合了前两种研究方向的优势：通过BiT模块对音视频模态特征进行语义注入和动态校准，以定位和净化更清洁、更丰富的语义线索；利用CATS模块进行语义传播和连接，使精准的语义信息在时间上得以有效传播。实验结果显示，提出的TEn-CATS方法在两个基准数据集LLP和UnAV-100上的多个关键指标上达到了目前最先进的性能。", "conclusion": "提出的方法在多个指标上达到了目前最先进的性能，展示了在音频-视觉视频解析任务中的显著改进，并为改进该领域的现有方法提供了新的思路。"}
{"llm_update_time": "20250907", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.04193", "html_url": "https://arxiv.org/abs/2509.04193", "title": "DUDE: 基于扩散的无监督跨域图像检索", "title_en": "DUDE: Diffusion-Based Unsupervised Cross-Domain Image Retrieval", "authors": "Ruohong Yang,Peng Hu,Yunfan Li,Xi Peng", "background": "无监督跨域图像检索(UCIR)旨在无需标注的情况下，在多样化的领域中检索相同类别的图像。现有的UCIR方法在整幅图片上对齐跨域特征，但常面临领域差距问题，由于用于检索的关键对象特征与领域特定的风格混在一起。", "innovation": "我们提出了DUDE，一种新颖的UCIR方法，基于特征解缠技术。DUDE利用文本到图像的生成模型解缠对象特征与领域特定风格，从而促进语义图像检索。DUDE通过在领域内逐渐对齐解缠对象特征，进一步实现可靠的跨领域对齐。", "conclusion": "广泛实验表明，DUDE在三个基准数据集上覆盖13个领域的性能达到了最先进的水平。代码将被发布。"}
{"llm_update_time": "20250907", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.04243", "html_url": "https://arxiv.org/abs/2509.04243", "title": "通过自我进化的偏好优化学习主动知觉以实现GUI定位", "title_en": "Learning Active Perception via Self-Evolving Preference Optimization for GUI Grounding", "authors": "Wanfu Wang,Qipeng Huang,Guangquan Xue,Xiaobo Liang,Juntao Li", "background": "视觉语言模型（VLMs）最近在将视觉感知与语言推理相结合方面取得了显著进展。然而，使VLMs在GUI定位任务中有效地对适当图像区域进行推理仍然是一个核心挑战，尤其是在高分辨率输入和复杂的多元素视觉交互下。", "innovation": "本文提出了一种自我进化的框架LASER，该框架逐步赋予VLMs多步感知能力，以实现精确的坐标预测。具体而言，该方法结合了Monte Carlo质量估计与基于iou（交并比）的区域质量评价，以同时促进高质量偏奋试据的准确性和多样性。这种方法明确地指导模型关注指令相关的关键区域，并根据任务复杂性适配性地分配推理步骤。", "conclusion": "在ScreenSpot Pro和ScreenSpot-v2基准测试上的全面实验表明，该方法获得了一致的性能提升，验证了其有效性。进一步地，当在GTA1-7B上进行微调时，LASER在ScreenSpot-Pro基准测试上得分55.7，建立了7B尺度模型的新最先进水平（SoTA）。"}
{"llm_update_time": "20250907", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.04156", "html_url": "https://arxiv.org/abs/2509.04156", "title": "基于UAV多光谱缺陷检测的YOLO集成", "title_en": "YOLO Ensemble for UAV-based Multispectral Defect Detection in Wind Turbine Components", "authors": "Serhii Svystun,Pavlo Radiuk,Oleksandr Melnychenko,Oleg Savenko,Anatoliy Sachenko", "background": "配备先进传感器的无人驾驶飞机（UAV）为监测风能发电站提供了新的机会，包括叶片、塔和其他关键组件。然而，可靠地检测缺陷需要高分辨率数据和高效的多光谱成像处理方法。这项研究旨在通过开发结合可见光和热能通道的YOLO基深度学习模型的集成方法来提高缺陷检测的准确性。研究采用了一种集成方法，将通用的YOLOv8模型与专门的热模型结合，并使用复杂的边界框融合算法组合它们的预测。实验表明，这种方法在mAP@.5上达到了0.93，并且F1分数为0.90，优于单独使用的YOLOv8模型，其mAP@.5得分为0.91。这些结果表明结合多种YOLO架构并使用融合多光谱数据可以提供更可靠的解决方案，从而改善对视觉和热缺陷的检测。", "innovation": "本文的研究创新之处在于提出了一种结合YOLOv8通用模型和专门热模型的集成方法，并使用高级边界框融合算法来组装它们的预测，从而显著提高了缺陷检测的准确性。实验结果表明，这种方法优于单独使用YOLOv8模型，显示出融合多光谱数据在风力发电机组件缺陷检测中的潜力。", "conclusion": "结合多种YOLO架构并使用融合多光谱数据提供了一种更可靠的方法，可以更准确地检测视觉和热缺陷，该方法在实际应用中显示出显著的优势。"}
{"llm_update_time": "20250907", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.04117", "html_url": "https://arxiv.org/abs/2509.04117", "title": "DVS-PedX: 基于合成与真实事件的行人数据集", "title_en": "DVS-PedX: Synthetic-and-Real Event-Based Pedestrian Dataset", "authors": "Mustafa Sakhai,Kaung Sithu,Min Khant Soe Oke,Maciej Wielgosz", "background": "事件相机如动态视觉传感器（DVS）报告微秒级亮度变化，而不是完整的图像帧，提供低延迟、高动态范围和运动鲁棒性。现有的数据集通常针对特定应用场景，缺乏适应不同天气条件和真实世界复杂背景的多样性和全面性。", "innovation": "DVS-PedX 是一个专为行人检测和过马路意图分析设计的神经形态数据集，涵盖了正常和恶劣天气条件，采用了两个互补的数据源：合成的事件流序列和真实世界的数据转换而成的事件流。同时提供了灵活的重处理选项，利用突触神经网络（SNN）展示了数据集的实用性和模拟到现实之间的差距，激发了领域适应和多模态融合的研究。", "conclusion": "DVS-PedX 的目标是加速基于事件的行人安全、意图预测和神经形态感知的研究。"}
{"llm_update_time": "20250907", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.04273", "html_url": "https://arxiv.org/abs/2509.04273", "title": "基于 Wasserstein 一致性双尺度体积先验的半监督医学图像分割", "title_en": "Dual-Scale Volume Priors with Wasserstein-Based Consistency for Semi-Supervised Medical Image Segmentation", "authors": "Junying Meng,Gangxuan Zhou,Jun Liu,Weihong Guo", "background": "在半监督医学图像分割领域，虽然取得了一定的进展，但现有的分割网络往往忽视了有效的特征提取方法和数据集中的重要先验信息。", "innovation": "该研究提出了一种结合双尺度体积先验和 Wasserstein 距离的方法，通过在基础分割网络中整合强显式体积先验和阈值动力学空间正则化，以及设计基于弱隐式体积先验的 Wasserstein 距离损失函数，增强了半监督医学图像分割性能。", "conclusion": "实验结果显示，该方法在 2017 ACDC 数据集、PROMISE12 数据集和大腿肌肉 MRI 图像数据集上明显优于现有方法。"}
{"llm_update_time": "20250907", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.04276", "html_url": "https://arxiv.org/abs/2509.04276", "title": "PAOLI：无需姿态的稀视角图像中可变形对象学习", "title_en": "PAOLI: Pose-free Articulated Object Learning from Sparse-view Images", "authors": "Jianning Deng,Kartic Subr,Hakan Bilen", "background": "当前的技术通常需要密集的多视角观测和真实相机姿态，但这种方法对输入的数据要求较高，处理稀视角图像和未加姿态的对象时存在挑战。", "innovation": "本文提出了一种新颖的自监督框架，可以从稀视角、未加姿态的图像中学习可变形物体的表示。该框架仅需要四张视角图和无需相机监督，通过独立重建每个关节、学习变形场和逐步分离静止与移动部分，实现了对相机和物体运动的鲁棒分离。最后通过自监督损失函数联合优化几何形状、外观和运动学，确保跨视角和跨姿态的一致性。", "conclusion": "在标准基准和现实世界示例上的实验表明，我们的方法在比现有方法更弱的输入假设下，能够生成准确和详细的可变形对象表示。"}
{"llm_update_time": "20250907", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.04180", "html_url": "https://arxiv.org/abs/2509.04180", "title": "VisioFirm：跨平台AI辅助注释工具", "title_en": "VisioFirm: Cross-Platform AI-assisted Annotation Tool for Computer Vision", "authors": "Safouane El Ghazouali,Umberto Michelucci", "background": "传统的注释依赖人工密集型输入，尤其在对象检测、方向边界框估计和实例分割等复杂任务中更为严重。这种人工输入限制了对于大规模数据集的可扩展性。因此，需要开发一种可以减轻人工注释负担的方法，同时保持高的注释准确性。", "innovation": "VisioFirm 是一个集成先进基础模型的开放源代码web应用，通过AI辅助自动化来简化图像标注过程。它结合了CLIP和预训练检测器（如Ultralytics模型）以及零样本模型（如Grounding DINO），通过低置信阈值生成初始注释，最大化召回率。此外，还提供了交互式工具支持边界框、方向边界框和多边形，并且具有实时分割功能，通过WebGPU加速浏览器侧效率。工具支持多种数据格式导出，并且在模型缓存后可以离线运行，增强了其易用性和灵活性。", "conclusion": "VisioFirm 已经在不同数据集上展示了高达90%的 manual 努力减少，同时保持了高注释准确性，通过集群CLIP基础组件和IoU图来抑制冗余检测。该工具提供了交互式支持和数据格式灵活性，对于计算机视觉数据标注具有强大的应用前景。"}
{"llm_update_time": "20250907", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.04150", "html_url": "https://arxiv.org/abs/2509.04150", "title": "重新审视用于野外深伪检测的简单基线方法", "title_en": "Revisiting Simple Baselines for In-The-Wild Deepfake Detection", "authors": "Orlando Castaneda,Kevin So-Tang,Kshitij Gurung", "background": "随着合成媒体的广泛使用，需要易于使用的深伪检测器和真实基准。当前大多数研究在高度控制的数据集上评估深伪检测器，而本文聚焦于最近发布的野外基准Deepfake-Eval-2024。初步报道显示，三个微调的开源模型在该基准上的准确率为61%至69%，远低于顶级商用深伪检测器的82%准确率。本文重新审视了一种基线方法，该方法由Ojha等人提出，通过微调标准预训练视觉骨干来生成泛化的深伪检测器。", "innovation": "本文通过改进超参数，展示了该简单方法的实际性能提升至81%准确率，这一结果超过了先前报告的基线方法的准确率18%，并且与商用深伪检测器竞争。此外，还讨论了性能、计算成本和可解释性之间的权衡，特别是在实际部署场景中的实用性问题。提供的代码托管在此：this https URL", "conclusion": "研究发现，通过优化简单基线方法中的超参数，可以显著提高深伪检测性能。虽然使用简单的模型可以达到不错的准确性，但仍需权衡其在实际应用中的成本和可解释性。"}
{"llm_update_time": "20250907", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.04268", "html_url": "https://arxiv.org/abs/2509.04268", "title": "差分形态学配置神经网络用于语义分割", "title_en": "Differential Morphological Profile Neural Networks for Semantic Segmentation", "authors": "David Huangal,J. Alex Hurt", "background": "语义分割技术在遥感航拍图像是重要的，可以用于地图测绘、城市规划和灾害响应中。现代最先进的分割网络通常来自于地面视角的图片，而这些网络尚未完全解决遥感硬盘的挑战，比如比例尺突变、前景与背景类别之间的不平衡和大尺寸的图像。文章关注如何将差分形态学配置（DMP）特性应用到卷积、Transformer等语义分割模型中。DMP作为一种多尺度形状解析的手段，能够为语义分割提供关键性形状信息，提升给定场景的检测和分类准确性。文章探究了怎样将DMP融入最先进的语义分割网络，并通过不同的DMP差异和结构元素测试来更有效地对模型提供形状信息。", "innovation": "作者尝试将差分形态学配置(differential morphological profile, DMP)这一多尺度形状提取方法应用到现有的最先进的卷积和变换语义分割网络中，这两种模型分别为直接输入(Direct Input)和混合型(Hybrid)。作者评估了不同DMP差值和结构元素形状的效果，发现混合型DMP效果优于直接输入型，甚至在多个评估指标上超越了非DMP模型，例如mIoU、F1和召回率(F1和召回率均为评价模型性能的重要指标，mIoU通常应用于分割任务，是准确率的平均值与召回率的平均值的调和平均数)。这种方式能够更好地解决遥感图像中存在的难点和问题，从而提升语义分割模型的性能和准确性。", "conclusion": "文章的结果表明，尽管非DMP模型在某些评估指标上普遍优于直接输入的DMP模型，但混合型DMP模型会保持良好的一致性，并且能够在mIoU、F1、召回率等多个评估指标上超过非DMP模型。这表明DMP特征的加入对于解决遥感图像中的特定挑战是有效的，例如比例尺度变化、前景与背景类别的不平衡以及大尺寸图像的问题。"}
{"llm_update_time": "20250907", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.04269", "html_url": "https://arxiv.org/abs/2509.04269", "title": "TauGenNet: 通过文本引导3D扩散模型的由血浆驱动的Tau PET图像合成", "title_en": "TauGenNet: Plasma-Driven Tau PET Image Synthesis via Text-Guided 3D Diffusion Models", "authors": "Yuxin Gong,Se-in Jang,Wei Shao,Yi Su,Kuang Gong(for the Alzheimer's Disease Neuroimaging Initiative (ADNI))", "background": "通过tau正电子发射断层扫描（PET）扫描准确量化tau病理对于诊断和监测阿尔茨海默病（AD）至关重要。然而，tau PET的高度成本和有限的可用性限制了其广泛应用。相比之下，结构磁共振成像（MRI）和基于血液的生物标志物提供了与大脑解剖结构和疾病进展情况相关的非侵入性和广泛可用的补充信息。本研究中，我们提出了一种文本引导的3D扩散模型用于3D tau PET图像合成，利用结构MRI和血浆测量的多模态条件。", "innovation": "我们提出的框架使用临床AV1451 tau PET数据进行训练和评估，来自阿尔茨海默病神经影像学倡议（ADNI）数据库。实验结果表明，我们的方法可以生成不同疾病阶段具有临床意义的真实3D tau PET图像。该框架有助于在不同设置下进行tau PET数据扩充，提供了一种非侵入性和成本效益高的替代方法来可视化tau病理，并支持在不同血浆生物标志物水平和认知条件下模拟疾病进展。", "conclusion": "提出的框架为tau PET数据增强提供了帮助，提供了一种可行的非侵入性和成本效益高的替代方案来可视化tau病理，并支持在不同血浆生物标志物水平和认知条件下模拟疾病进展。"}
{"llm_update_time": "20250907", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.04326", "html_url": "https://arxiv.org/abs/2509.04326", "title": "高效单一异常检测", "title_en": "Efficient Odd-One-Out Anomaly Detection", "authors": "Silvio Chito,Paolo Rabino,Tatiana Tommasi", "background": "最近引入的单一异常检测任务涉及在多对象场景中识别外观异常的实例，这要求现代深度学习模型进行跨多个视角的空间推理以及关系推理以理解上下文和在不同对象类别和布局间进行泛化。这些挑战要求模型在效率上进行优化，即在减少参数数量和缩短训练时间方面取得平衡，同时保持性能的竞争力。此前的基线模型在这些任务中面临诸多挑战，尤其是结构化视觉推理任务中大型语言模型的表现有限性已经引起了讨论。", "innovation": "本文提出了一种基于DINO的模型，与当前最先进的模型相比，该模型参数减少了三分之一，训练时间缩短了三倍，同时保持了竞争力的性能。此外，实验还引入了多模态大型语言模型作为基线，揭示了它在结构化视觉推理任务中的限制和不足。", "conclusion": "该研究通过提出高效且参数量更少的模型，在单一异常检测任务中实现了性能和效率的双重提升，同时为未来的研究提供了新的基线和方向。"}
{"llm_update_time": "20250907", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.04298", "html_url": "https://arxiv.org/abs/2509.04298", "title": "使用语义可靠合成图像的噪声标签精炼", "title_en": "Noisy Label Refinement with Semantically Reliable Synthetic Images", "authors": "Yingxuan Li,Jiafeng Mao,Yusuke Matsui", "background": "在图像分类数据集中，语义相似类别经常被错误标记，这给传统的监督学习方法带来了显著挑战。研究发现，尽管高质量的合成图像带有可靠的标签，但它们在训练中的直接应用受限于领域差异和多样性限制。论文探讨了利用高级文本到图像模型生成的合成图像作为可靠参考点识别并修正噪声数据集中的错误标签的可能性", "innovation": "相比于传统方法，本文提出了一种创新的方法，利用合成图像作为可靠的参考点来识别和纠正噪声数据集中的错误样本。实验结果表明，该方法在多种基准数据集下显著提高了分类准确性，特别是在语义标签噪声的挑战场景下表现尤为突出。此外，由于该方法与现有的噪声稳健学习技术相独立，因此结合最先进的噪声稳健训练方法，可以实现更优越的性能。在CIFAR-10数据集上，其准确性提高了30%，在CIFAR-100数据集上提高了11%，在ImageNet-100数据集上，实际上在现实场景噪声条件下提高了24%的准确性", "conclusion": "通过使用语义可靠的合成图像来精炼噪声标签可以显著提高分类准确性，尤其在复杂且具有语义标签噪声的场景中。这种新颖的方法可以在不改变现有噪声稳健学习技术的情况下提高模型性能。"}
{"llm_update_time": "20250907", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.04370", "html_url": "https://arxiv.org/abs/2509.04370", "title": "从身体穿戴视频中创建故事全景事件摘要：拼接故事", "title_en": "Stitching the Story: Creating Panoramic Incident Summaries from Body-Worn Footage", "authors": "Dor Cohen,Inga Efrosman,Yehudit Aperstein,Alexander Apartsin", "background": "一线响应人员广泛采用身体穿戴摄像头来记录事故现场，并支持事件后的分析。然而，在时效性要求高的情况下，审查长时间的视频素材是不切实际的。有效的态势感知需要一个简洁的视觉总结，可以快速解读。", "innovation": "该论文提出了一种基于计算机视觉的工作流，将身体摄像头录制的视频转换成 informative panoramic (全景) 图像来总结事故场景。方法利用单目 SLAM (Simultaneous Localization and Mapping) 估算摄像机轨迹并重构环境的三维布局。沿途的相机姿势被聚集在一起，确认关键的视角，并从每个聚类中选择代表性的帧。这些帧使用多帧拼接技术融合为空间上一致的全景图像。结果的总结加快了对复杂环境的理解，促进了高效的决策和事故回顾。", "conclusion": "这项工作提出的方法能够从身体穿戴摄像头的视频中生成事故场景的全景可视化摘要，使快速理解复杂环境和高效决策成为可能。"}
{"llm_update_time": "20250907", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.04334", "html_url": "https://arxiv.org/abs/2509.04334", "title": "GeoArena：一个用于全球图像地理定位任务中评估大型视觉语言模型的开源平台", "title_en": "GeoArena: An Open Platform for Benchmarking Large Vision-language Models on WorldWide Image Geolocalization", "authors": "Pengyue Jia,Yingyi Zhang,Xiangyu Zhao,Yixuan Li", "background": "图像地理定位的目标是在地球上任何地方拍摄的图片中预测其地理位置，但是其全球性质带来了显著的挑战。当前的评估方法存在两个主要问题：首先，数据泄露，先进的方法往往依赖于大型视觉-语言模型（LVLMs）来预测图片位置，但这些模型经常在测试数据集上先行预训练，这影响了对模型实际地理定位能力的准确性评估；其次，现有的评估指标主要依赖于精确的地理坐标来评估预测结果，这忽视了推断过程，并且在需要用户级位置数据时引发了隐私问题。", "innovation": "本文提出了GeoArena，这是一个首次为评估全球图像地理定位任务中的LVLMs提供开源平台，提供真正的野外和以人类为中心的基准。GeoArena允许用户上传野外图片以获得更广泛的评估数据集，并利用成对的人类判断来确定哪个模型输出更好地符合人类期望。该平台已在线部署两个月，收集了数千份投票记录，基于这些数据，进行了详细的分析，并建立了不同LVLMs在全球图像地理定位任务上的排行榜。", "conclusion": "通过GeoArena平台，首次实现了对大型视觉语言模型在全局图像地理定位任务中的公平、真实地评估。收集的数据展示了不同模型的表现，并形成了一个排行榜，为后续研究提供了实用的基准和指导。"}
{"llm_update_time": "20250907", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.04344", "html_url": "https://arxiv.org/abs/2509.04344", "title": "MICACL: 基于多实例类感知对比学习的长尾动态面部表情识别", "title_en": "MICACL: Multi-Instance Category-Aware Contrastive Learning for Long-Tailed Dynamic Facial Expression Recognition", "authors": "Feng-Qi Cui,Zhen Lin,Xinlong Rao,Anyang Tong,Shiyao Li,Fei Wang,Changlin Chen,Bin Liu", "background": "动态面部表情识别（DFER）面临显著挑战，包括长尾类分布和时空特征建模的复杂性。现有基于深度学习的方法在DFER性能方面有所提升，但未能有效解决这些问题，导致了严重模型归纳偏差。", "innovation": "提出了一种新颖的多实例学习框架，称为MICACL，该框架结合了时空依赖建模和长期对比学习优化。具体而言，设计了图增强实例交互模块（GEIIM）来通过自适应邻接矩阵和多尺度卷积捕捉相邻实例之间的复杂时空关系。为了增强实例级特征聚合，开发了加权实例聚合网络（WIAN），它根据实例的重要性动态分配权重。另外，引入了一种多尺度类别感知对比学习（MCCL）策略以平衡主要和次要类别的训练。", "conclusion": "在野生数据集（即DFEW和FERV39k）上的广泛实验表明，MICACL在性能、鲁棒性和泛化能力方面均达到最优。"}
{"llm_update_time": "20250907", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.04402", "html_url": "https://arxiv.org/abs/2509.04402", "title": "使用未知探针学习神经表示进行X射线 Ptychography 重建", "title_en": "Learning neural representations for X-ray ptychography reconstruction with unknown probes", "authors": "Tingyou Li,Zixin Xu,Zirui Gao,Hanfei Yan,Xiaojing Huang,Jizhou Li", "background": "X射线Ptychography因其出色的纳米级分辨率而在材料科学、生物学和纳米技术中得到了广泛应用。然而，其发展的关键挑战在于重建图像时无法准确恢复当照明探针未知时的图像。传统的迭代方法和深度学习方法在低信号条件下常常不尽如人意。其限制了该技术的进一步应用。", "innovation": "本文提出了一种名为Ptychographic Implicit Neural Representation (PtyINR)的自监督框架，它可以同时解决对象和探针的恢复问题。PtyINR通过参数化对象和探针为连续的神经表示，从原始衍射模式直接进行端到端的重建，无需预先确定探针特征。实验证明了PtyINR的优异重建效果，并且在低信号条件下具有出色的稳健性，此外PtyINR还为解决依赖探针的逆问题提供了通用的物理基础框架，适用于广泛的应用场景。", "conclusion": "PtyINR实现了对模拟和实验数据的优越重建质量，并且在恶劣的低信号条件下表现出显著的鲁棒性。此外，PtyINR提供了一种广泛适用且基于物理的框架，可以解决与探针相关的逆向问题，使其适用于广泛的计算显微镜问题。"}
{"llm_update_time": "20250907", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.04406", "html_url": "https://arxiv.org/abs/2509.04406", "title": "通过边缘数据传输蒸馏实现的3D生成的几步流", "title_en": "Few-step Flow for 3D Generation via Marginal-Data Transport Distillation", "authors": "Zanwei Zhou,Taoran Yi,Jiemin Fang,Chen Yang,Lingxi Xie,Xinggang Wang,Wei Shen,Qi Tian", "background": "现有的基于流的3D生成模型在推断过程中通常需要数十个采样步骤。尽管少步骤蒸馏方法，尤其是Consistency Models（CMs），在加速2D扩散模型方面取得了显著进展，但在处理更复杂的3D生成任务时仍然鲜有探索。", "innovation": "本文提出了一个新颖的框架MDT-dist，用于几步3D流的蒸馏。该方法通过两种可优化的目标Velocity Matching（VM）和Velocity Distillation（VD），将在传输级别上的优化目标转换为在速度和分布级别上的目标，从而直接学习边际-数据传输。", "conclusion": "在TRELLIS等先驱3D生成架构上进行评估时，该方法将每个流变换器的采样步骤从25减少到1或2，实现了在A800上的0.68秒（1步×2）和0.94秒（2步×2）延迟，同时维持高视觉和几何保真度。广泛的实验表明，该方法显著优于现有的CM蒸馏方法，并使TRELLIS在少数几步3D生成方面实现了卓越性能。"}
{"llm_update_time": "20250907", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.04379", "html_url": "https://arxiv.org/abs/2509.04379", "title": "SSGaussian：具有语义感知和结构保持的3D风格转移", "title_en": "SSGaussian: Semantic-Aware and Structure-Preserving 3D Style Transfer", "authors": "Jimin Xu,Bosheng Qin,Tao Jin,Zhou Zhao,Zhenhui Ye,Jun Yu,Fei Wu", "background": "近年来，神经表示技术如神经辐射场（Neural Radiance Fields）和3D高斯采样（3D Gaussian Splatting）的发展，极大地提升了将风格转移应用于3D场景的兴趣。现有方法虽然能在保持3D一致性的同时将风格模式转移到神经表示上，但无法有效地从参考风格图像中提取和转移高层语义风格。此外，生成的结果往往缺乏结构清晰度和分离度，使得难以区分3D场景中的不同实例或对象。", "innovation": "本文提出了一种新颖的3D风格转移框架，有效地结合了预训练的2D扩散模型先验知识。该框架包含两个关键阶段：首先，利用扩散先验生成关键视角的风格化渲染；其次，将这些风格化的关键视角转移到3D表示上。这包含两个创新设计：一是视角间风格对齐，通过在UNet的最后一个上采样块中插入跨视角注意力机制，促进多个关键视角之间的特征交互，从而确保扩散模型生成的风格化关键视角在保持风格保真度的同时具有实例级的一致性；二是实例级风格转移，有效利用风格化关键视角之间实例级的一致性，将其转移到3D表示上，从而实现结构更清晰、视觉更连贯的艺术增强。", "conclusion": "在广泛场景中的大量定性和定量实验表明，本文提出的3D风格转移框架显著优于最先进的方法，从正面视角到具有挑战性的360度环境都表现优异。访问我们的项目页面 <https://yourprojectpagelink.com> 以进行沉浸式可视化。"}
{"llm_update_time": "20250907", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.04437", "html_url": "https://arxiv.org/abs/2509.04437", "title": "从线到形状：基于霍夫变换的X射线准直器的几何约束分割", "title_en": "From Lines to Shapes: Geometric-Constrained Segmentation of X-Ray Collimators via Hough Transform", "authors": "Benjamin El-Zein,Dominik Eckert,Andreas Fieselmann,Christopher Syben,Ludwig Ritschl,Steffen Kappler,Sebastian Stober", "background": "X射线成像中的准直限制了对感兴趣区域（ROI）的曝光，从而减少了对患者的辐射剂量。检测准直器阴影是数字放射摄影中的一项重要图像预处理步骤，但在边缘被散射X射线辐射遮挡时构成挑战。尽管如此，准直器形成多边形阴影的先验知识是显而易见的。", "innovation": "本文提出了一种基于深度学习的分割方法，该方法本质上受到其几何约束。通过结合可微分的霍夫变换网络来检测准直边界，并增强其提取ROI中心信息的能力，在推断过程中结合两个任务的信息，生成细化的、线约束分割掩码。这项方法能够实现准直区域的稳健重构，在多种实际X射线图像的测试集上，得到的平均Hausdorff距离为4.3-5.0毫米。", "conclusion": "虽然该应用涉及最多四个阴影边界，但该方法本质上不受特定边数的限制。"}
{"llm_update_time": "20250907", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.04444", "html_url": "https://arxiv.org/abs/2509.04444", "title": "跨越鸿沟：从视角到全景视觉的综述", "title_en": "One Flight Over the Gap: A Survey from Perspective to Panoramic Vision", "authors": "Xin Lin,Xian Ge,Dizhe Zhang,Zhaoliang Wan,Xianshun Wang,Xiangtai Li,Wenjie Jiang,Bo Du,Dacheng Tao,Ming-Hsuan Yang,Lu Qi", "background": "受对空间智能和全方位场景感知需求的推动，全景图像（ODIs）提供了360度的完整视野，正在虚拟现实、自动驾驶和具身机器人等多种应用中引起广泛关注。尽管全景图像具有独特的特征，但在几何投影、空间分布和边界连续性方面与视角图像存在显著差异，这给直接从视角方法进行领域适配带来了挑战。", "innovation": "本文回顾了最新的全景视觉技术，特别强调了视角到全景的适应问题。首先回顾了全景成像管道和投影方法，以构建分析结构差异所需的先验知识。然后总结了领域适应的三大挑战：极区严重的几何失真、Equirectangular投影中的非均匀采样以及周期边界连续性。文章覆盖了来自300多篇研究论文的20多个典型任务，并对代表性策略进行了跨方法分析，针对不同任务进行了跨任务比较，将全景视觉分为视觉质量提升与评估、视觉理解、多模态理解与生成四大类别。", "conclusion": "文章讨论了数据、模型和应用方面尚存的挑战和未来方向，旨在推动全景视觉研究的发展。希望我们的工作能够为推进全景视觉技术提供新的见解和前瞻性的视角。"}
{"llm_update_time": "20250907", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.04403", "html_url": "https://arxiv.org/abs/2509.04403", "title": "自适应数据集构建以应对真实的多模态安全场景", "title_en": "Self-adaptive Dataset Construction for Real-World Multimodal Safety Scenarios", "authors": "Jingen Qu,Lijun Li,Bo Zhang,Yichen Yan,Jing Shao", "background": "当前，多模态大语言模型（MLLMs）正在快速发展，带来了更加复杂的安全挑战。现有的数据集构建方法主要以风险为导向，未能涵盖现实世界多模态安全场景（RMS）日益复杂的多样性。由于缺乏统一的安全性评估标准，这些模型的整体有效性尚未得到验证。因此，本研究旨在提出一种自适应的数据集构建方法，该方法始于图像，并最终构建配对的文字指导回应，以应对RMS。通过这种方法，研究团队自动生成了一个由35,000个图像-文本对组成的指导响应数据集。此外，还提出了一种标准化的安全数据集评估标准：微调一个安全判断模型，并评估其在其他安全场景中的能力。实验表明，该自适应图像导向的数据集构建框架在多个任务中的有效性，证实了其可扩展性和有效性，为现实世界多模态安全数据集的构建提供了新的视角和方法。", "innovation": "研究引入了一种新的图像导向、自适应的数据集构建方法，该方法从图像出发，最终构建配对的文字指导回应，以应对复杂的现实生活中的多模态安全场景。该方法通过自动生成的大型多模态数据集和标准化的安全数据集评估标准，验证了其在评估和改进多模态大型语言模型方面的重要创新。", "conclusion": "实验结果表明，提出的图像导向的数据集构建方法在多个任务中表现出色，证明了其作为应对真实世界多模态安全场景的有效性和可扩展性。这一创新为未来多模态大语言模型的设计和评估提供了新的思路和方法。"}
{"llm_update_time": "20250907", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.04376", "html_url": "https://arxiv.org/abs/2509.04376", "title": "AnomalyLMM: 融合生成知识与辨别检索的基于文本的人异常搜索", "title_en": "AnomalyLMM: Bridging Generative Knowledge and Discriminative Retrieval for Text-Based Person Anomaly Search", "authors": "Hao Ju,Hu Zhang,Zhedong Zheng", "background": "随着公众安全需求的增长，基于文本的人异常搜索已成为一个关键任务，旨在通过自然语言描述检索具有异常行为的个体。与传统的人员搜索任务相比，这一任务面临着两个独特的挑战：（1）文本异常与视觉行为的细粒度跨模态对齐；（2）在稀疏的现实世界样本下的异常检测。虽然大型多模态模型（LMMs）在多模态理解方面表现出色，但它们在细粒度异常检索中的潜力尚未被充分挖掘，受到领域脱节和部署过程中缺乏有效的适应策略的限制。", "innovation": "本文提出了AnomalyLMM框架，它是第一个利用LMMs进行基于文本的人异常搜索的框架。我们的主要贡献包括：（1）一种新颖的粗到细流水线，将LMMs集成以桥接生成世界知识与检索导向的异常检测；（2）一个无需训练的自适应烹饪书，包含掩码跨模态提示、行为显著性预测和知识感知重排，从而实现零样本聚焦于微妙的异常线索。", "conclusion": "作为首个探索LMMs的此类任务的研究，我们在公共数据集PAB上进行了严格评估。实验结果表明，所提出的方法在Recall@1精度上超过竞争对手的基线 +0.96%。值得注意的是，我们的方法揭示了文本异常和视觉行为之间的可解释对齐，通过定性分析得到验证。我们已发布代码和模型供未来研究使用。"}
{"llm_update_time": "20250907", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.04448", "html_url": "https://arxiv.org/abs/2509.04448", "title": "TRUST-VL：一种通用多模态误信检测的可解释新闻助手", "title_en": "TRUST-VL: An Explainable News Assistant for General Multimodal Misinformation Detection", "authors": "Zehong Yan,Peng Qi,Wynne Hsu,Mong Li Lee", "background": "多模态误信，包括文本、视觉和跨模态的扭曲，对社会构成了日益增加的威胁，尤其是在生成性AI的放大效应下更为严重。现有的方法通常集中于单一类型的扭曲，并难以推广到未见过的情景中。", "innovation": "本文观察到不同扭曲类型共享相同的基本推理能力，但也需要特定任务的技能。据此假设，针对多种扭曲类型进行联合训练有利于知识共享并提升模型的泛化能力。为此，引入TRUST-VL，这是一种统一且可解释的视觉-语言模型，用于通用多模态误信检测。TRUST-VL 包含一种新的问题感知视觉增强模块，用于提取特定任务的视觉特征。", "conclusion": "在多个验证集上进行全面实验表明，TRUST-VL 达到了最先进的性能，同时具有强大的泛化能力和可解释性。"}
{"llm_update_time": "20250907", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.04438", "html_url": "https://arxiv.org/abs/2509.04438", "title": "电话游戏：评估统一模型的语义漂移", "title_en": "The Telephone Game: Evaluating Semantic Drift in Unified Models", "authors": "Sabbir Mollah,Rohit Gupta,Sirnam Swetha,Qingyang Liu,Ahnaf Munir,Mubarak Shah", "background": "该研究背景在于利用单一统一模型（UM）同时进行视觉理解和视觉生成，为视觉语言模型（VLM）研究开辟了新方向。虽然统一模型可以支持更广泛的单模态任务，但该研究聚焦于图像到文本（I2T）和文本到图像（T2I）的核心双模态对，因为理解与生成的一致性对下游应用至关重要。现有的评估仅在单次通过时检验其能力，如T2I中的FID和GenEval，以及I2T中的MME、MMBench基准，这些单次评估无法体现模型理解概念是否能在视觉上再现，也不是所有的意义在二者间的切换后是否保留。", "innovation": "该研究创新性地提出了统一一致性框架-统一模型（UCF-UM）的循环评估协议，用于评估统一模型的语义漂移。该框架包括3项指标：(i) 均匀累积漂移（MCD），基于嵌入的整体语义损失度量；(ii) 语义漂移率（SDR），总结语义衰退速率；(iii) 多次通过度评估（MGG），拓展GenEval的对象级合规性评分。此外，为了超越COCO基准，该研究构建了新的ND400基准，从NoCaps和DOCCI取样，并对其七个最近的模型进行了评估。", "conclusion": "通过UCF-UM评估揭示了跨模态稳定性的显著差异：一些模型如BAGEL在多次交替下仍能保持语义，而其他模型如Vila-u尽管在单次通过中的得分较高，但在切换过程中却快速漂移。研究结果强调了循环一致性作为标准I2T和T2I评估的必要补充，并提供了衡量统一模型跨模态稳定性和共享表示强度的实用指标。"}
{"llm_update_time": "20250907", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.04446", "html_url": "https://arxiv.org/abs/2509.04446", "title": "Plot'n Polish: 零样本故事可视化及细节分离的文本到图像扩散模型", "title_en": "Plot'n Polish: Zero-shot Story Visualization and Disentangled Editing with Text-to-Image Diffusion Models", "authors": "Kiymet Akdemir,Jing Shi,Kushal Kafle,Brian Price,Pinar Yanardag", "background": "文本到图像的扩散模型已经在多个领域展现了生成多样且详尽视觉表现的能力，尤其在故事可视化方面前景广阔。然而，随着这些模型在外在创意领域中的应用增多，提供增强的控制能力、细化调整以及生成图像之后的精细修改以保持一致性的需求变得尤为重要。现有的方法往往缺乏灵活性，无法在保持视觉和叙事一致性的同时进行细粒度或粗粒度的编辑，阻碍了创作者无缝地构建和优化他们的视觉故事。", "innovation": "本文引入了Plot'n Polish，这是一种零样本框架，能够实现一致的故事生成，并在不同级别的细节上提供对故事可视化的精细控制。这种框架旨在解决现有方法的局限性，为创作者提供了更流畅的创作和精修过程，确保视觉故事在多个帧上的一致性与连贯性。", "conclusion": "Plot'n Polish通过利用文本到图像的扩散模型，提供了一种创新的方法，使故事的生成和可视化更加灵活、一致和可控。这种方法解决了故事可视化过程中的关键挑战，为创作者提供了一种新的工具，以更有效的方式创建和修改他们的视觉叙事。"}
{"llm_update_time": "20250907", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.04450", "html_url": "https://arxiv.org/abs/2509.04450", "title": "虚拟试衣间：从单张图片生成任意长度的虚拟试穿视频——技术预览", "title_en": "Virtual Fitting Room: Generating Arbitrarily Long Videos of Virtual Try-On from a Single Image -- Technical Preview", "authors": "Jun-Kun Chen,Aayush Bansal,Minh Phuoc Vo,Yu-Xiong Wang", "background": "文章介绍了虚拟试衣间(VFR)，这是一种新型的视频生成模型，能够生成任意长的虚拟试穿视频。VFR将长视频生成任务作为自回归、逐段生成的过程，从而避免了资源消耗大的生成过程和漫长的视频数据需求，同时提供生成任意长度视频的灵活性。这一任务的关键挑战是确保相邻片段之间的局部平滑性以及不同片段之间的全局时间一致性。", "innovation": "文章提出了一种VFR框架，通过前缀视频条件和锚固视频(360度视频，全面捕捉人体的整体外观)来实现平滑性和一致性。这一框架能够在各种运动下生成分钟级的虚拟试穿视频，具有局部平滑性和全局时间一致性。这是在长虚拟试穿视频生成方面的开创性工作。", "conclusion": "文章通过VFR建立了一个框架，能够在各种动作下生成既具有局部平滑性又保持全局时间一致性的虚拟试穿视频。这为其领域带来了新的技术和方法，展示了未来无限的扩展可能性。"}
{"llm_update_time": "20250907", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.03677", "html_url": "https://arxiv.org/abs/2509.03677", "title": "从梯度动态中获得的见解：梯度自动缩放归一化", "title_en": "Insights from Gradient Dynamics: Gradient Autoscaled Normalization", "authors": "Vincent-Daniel Yun", "background": "梯度动态在决定深度神经网络的稳定性和泛化能力方面扮演着核心角色。本文通过经验分析了梯度方差和标准偏差在训练过程中如何演变，展示了卷积网络中不同层和全局尺度上的一致变化。", "innovation": "提出了一种无需超参数的梯度归一化方法，使梯度缩放与其自然演变保持一致。此方法防止了意外放大的发生，稳定了优化过程，并保持了收敛保证。", "conclusion": "在具有挑战性的CIFAR-100基准测试中，使用ResNet-20、ResNet-56和VGG-16-BN，证明了该方法在强泛化条件下能维持或提高测试准确性。同时，本文的研究突显了直接跟踪梯度动态的重要性，旨在弥合理论预期与实际行为之间的差距，并为未来的优化研究提供见解。"}
{"llm_update_time": "20250907", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.03680", "html_url": "https://arxiv.org/abs/2509.03680", "title": "LuxDiT：基于视频扩散变换器的照明估计", "title_en": "LuxDiT: Lighting Estimation with Video Diffusion Transformer", "authors": "Ruofan Liang,Kai He,Zan Gojcic,Igor Gilitschenski,Sanja Fidler,Nandita Vijaykumar,Zian Wang", "background": "在计算机视觉和图形学中，仅从单张图像或视频估计场景照明一直是一个长期的挑战。基于学习的方法受到高质量真实世界HDR环境图稀缺性的限制，这些图成本高且多样性有限。尽管最近的生成模型为图像合成提供了强有力的先验，但照明估计仍然难以实现，因为其依赖间接视觉线索、需要推断全局（非局部）上下文以及恢复高动态范围输出。", "innovation": "提出了一种名为LuxDiT的新颖数据驱动方法，该方法通过微调视频扩散变换器生成与视觉输入条件相关的HDR环境图。模型通过大规模多样化照明条件的合成数据集训练，学会了从间接视觉线索推断照明，并能在真实世界场景中有效泛化。为了提高输入和预测环境图之间的语义对齐，引入了一种使用HDR全景图收集的数据集进行低秩适应微调策略。", "conclusion": "通过我们的方法能够生成具有现实性高角度高频细节的准确光照预测，在定量和定性评估中均优于现有最先进的技术。"}
{"llm_update_time": "20250907", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.03830", "html_url": "https://arxiv.org/abs/2509.03830", "title": "一个基于上海案例研究的历史城镇保护区游客感知的多维人工智能框架", "title_en": "A Multidimensional AI-powered Framework for Analyzing Tourist Perception in Historic Urban Quarters: A Case Study in Shanghai", "authors": "Kaizhen Tan,Yufan Wu,Yuxuan Liu,Haoran Zeng", "background": "历史城镇保护区在保护文化遗产的同时，也作为旅游和日常生活的活跃空间发挥着重要作用。理解游客如何感知这些环境对于可持续的人本城市规划至关重要。", "innovation": "提出了一种多维度的AI驱动框架，利用社交媒体的多模态数据来分析游客对历史城镇保护区的感知。该框架整合了焦点提取、色彩主题分析和情感挖掘，通过细调的语义分割模型从游客分享的照片中识别视觉重点区域，结合聚类方法提取主导颜色，分析其在各保护区的分布。此外，还通过社交媒体照片和实地街道视图的色彩主题比较揭示视觉期望与建成环境之间的差异，结合基于规则的方法和多任务BERT模型进行混合情感分析，评估游客满意度。", "conclusion": "研究揭示了美学吸引力和情感反应的空间变化，提供了一种综合的数据驱动方法来解码游客感知，为旅游、文化遗产保护和设计引人注目的公共空间的决策提供了依据。"}
{"llm_update_time": "20250907", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.03850", "html_url": "https://arxiv.org/abs/2509.03850", "title": "数据增强感知量化知识蒸馏", "title_en": "Data-Augmented Quantization-Aware Knowledge Distillation", "authors": "Justin Kur,Kaiqi Zhao", "background": "现有的知识蒸馏（KD）和量化感知训练（QAT）工作主要集中在通过设计更好的KD损失函数或优化QAT的前向和反向传播来提高量化模型的准确性，而较少关注输入变换，尤其是数据增强（DA）对量化感知KD的影响。", "innovation": "提出了一个新颖的度量标准，该标准根据DA对最大化上下文互信息（与图像标签无直接关系的信息）以及每个类别的预测与真实标签平均接近程度的能力进行评估，并自动对DA进行排名和选择，无需大量额外训练开销，且适用于任何KD或QAT算法。", "conclusion": "实验表明，使用我们的度量选择DA策略可以显著提高现有的QAT和KD技术在不同模型架构和数据集上的性能。"}
{"llm_update_time": "20250907", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.03775", "html_url": "https://arxiv.org/abs/2509.03775", "title": "ContraGS：紧凑且可训练的代码集高斯点云方法以实现快速、内存高效重建", "title_en": "ContraGS: Codebook-Condensed and Trainable Gaussian Splatting for Fast, Memory-Efficient Reconstruction", "authors": "Sankeerth Durvasula,Sharanshangar Muhunthan,Zain Moustafa,Richard Chen,Ruofan Liang,Yushi Guan,Nilesh Ahuja,Nilesh Jain,Selvakumar Panneer,Nandita Vijaykumar", "background": "3D Gaussian Splatting（3DGS）是一种高质量且实时渲染的技术，能够高精度地建模现实场景。然而，使用更多的3D高斯点会大大增加GPU设备内存以存储模型参数，从而导致训练过程和渲染过程中的内存访问和数据移动效率低下，训练和渲染速度变慢。", "innovation": "ContraGS提出了一种方法，可以在不减少高斯点数量的前提下直接在压缩的3DGS表示上进行训练，从而在模型质量略有下降的情况下显著降低了内存消耗。该方法利用代码本在训练过程中紧凑地存储一组高斯参数向量，通过MCMC采样方法从压缩表示的后验分布中采样，解决了代码本压缩表示中的非可微参数学习问题，提高了训练和渲染速度。", "conclusion": "通过ContraGS，我们证明了与传统的训练方法相比，训练期间峰值内存使用减少了3.49倍，训练和渲染速度分别加速了1.36倍和1.88倍，同时重新训练接近最新的技术水平。"}
{"llm_update_time": "20250907", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.03749", "html_url": "https://arxiv.org/abs/2509.03749", "title": "预算内映射：机器学习的空间数据收集优化", "title_en": "Mapping on a Budget: Optimizing Spatial Data Collection for ML", "authors": "Livia Betti,Farooq Sanni,Gnouyaro Sogoyou,Togbe Agbagla,Cullen Molitor,Tamma Carleton,Esther Rolf", "background": "在农业、生态学和人类发展等领域，卫星图像的机器学习应用受到缺乏标记训练数据稀疏性的限制。尽管卫星数据能够覆盖全球，但用于SatML的标记训练数据集通常规模小、空间聚集，并且收集目的是为了其他用途（如行政调查或实地测量）。尽管这个问题在实践中普遍存在，但过去的SatML研究大多集中在开发新的模型架构和训练算法来处理稀缺的数据，而不是直接建模数据状况。这使得希望使用SatML进行大规模监测的科学家和政策制定者对如何收集额外数据以最大化性能仍感到不确定。因此，本文提出了优化预算内空间训练数据的第一个问题表述，并引入了新型方法来解决这个问题。", "innovation": "本文提出了一种优化预算内空间训练数据的问题表述，以及一种解决该问题的新型方法。通过跨三大洲和四项任务的实验模拟，展示了解样优化策略带来的显著收益。进一步的实验还定义了优化采样特别有效的条件。提出的问题表述和方法旨在适用于卫星图像的机器学习跨应用领域；特别强调了一个特定问题设置，即作者的合作者可以立即利用该发现改进加纳的集簇农业调查，用于SatML监测。", "conclusion": "针对卫星图像的机器学习应用中存在的缺乏标记训练数据的问题，本文提出了一种新型的优化空间训练数据的方法，并且在实验中证明了这种方法的有效性，尤其适用于特定的应用场景。"}
{"llm_update_time": "20250907", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.03891", "html_url": "https://arxiv.org/abs/2509.03891", "title": "MobileRAG：利用检索增强生成提升移动代理", "title_en": "MobileRAG: Enhancing Mobile Agent with Retrieval-Augmented Generation", "authors": "Gowen Loo,Chang Liu,Qinghong Yin,Xiang Chen,Jiawei Chen,Jingyuan Zhang,Yu Tian", "background": "智能手机已经成为了人们日常生活中不可或缺的部分，几乎渗透到现代社会的每一个方面。随着大型语言模型（LLMs）的不断进步，很多基于LLM的移动代理应运而生，这些代理能够在准确解析用户查询的同时，自动帮助用户完成复杂或重复的操作。但是，现有的代理仍然存在如下问题：1）过分依赖LLM的理解能力，可能导致执行任务时的错误操作或遗漏步骤；2）缺乏与外部环境的互动，当一个应用无法满足用户的查询时任务便会终止；3）缺乏记忆能力，需要每次指令重新构建界面，并无法从之前的错误中学习和纠正。", "innovation": "提出了一个名为MobileRAG的移动代理框架，它是基于检索增强生成（RAG）的改进框架，包括InterRAG、LocalRAG和MemRAG。利用RAG，MobileRAG能更快更准确地识别用户查询并完成长序列的移动任务。此外，为了更全面地评估MobileRAG的表现，还引入了一个新的基准测试MobileRAG-Eval，它包含了众多需要外部知识支持的真实世界移动任务。实验结果显示，MobileRAG能够很好地处理真实世界的移动任务，并且比最先进的方法节省了10.3%的操作步骤。", "conclusion": "广泛的实验结果表明，MobileRAG能够轻易处理真实世界的移动任务，相对于最先进的方法在操作步骤上节省了10.3%，并且公开了代码可供研究使用。"}
{"llm_update_time": "20250907", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.04047", "html_url": "https://arxiv.org/abs/2509.04047", "title": "TensoIS: 向前馈张量逆向次表面散射方法迈出的一步 - 适用于佩林分布的非均匀介质", "title_en": "TensoIS: A Step Towards Feed-Forward Tensorial Inverse Subsurface Scattering for Perlin Distributed Heterogeneous Media", "authors": "Ashish Tiwari,Satyam Bhardwaj,Yash Bachwana,Parag Sarvoday Sahu,T.M.Feroz Ali,Bhargava Chintalapati,Shanmuganathan Raman", "background": "从图像中估计非均匀介质的散射参数是一个严重欠约束且具有挑战性的问题。大多数现有方法通过分析-合成方法建模BSSRDF，近似复杂的路径积分，或者使用可微体积渲染技术来考虑异质性。然而，只有少数研究使用基于学习的方法来估计次表面散射参数，但这些方法假定介质是均匀的。有趣的是，我们不知道任何能明确建模现实世界中非均匀散射参数的具体分布。值得注意的是，像佩林和分形佩林噪声这样的程序噪声模型在过去已被证明可以有效表示自然、有机和无机表面的细腻异质性。", "innovation": "本文提出了一种名为TensoIS的新方法，这是一种基于学习的前馈框架，用于从稀疏的多视角图像观测中估计佩林分布的非均匀散射参数。该方法没有直接预测3D散射参数体积，而是使用可学习的低秩张量组件来表示散射体积。此外，作者创建了HeteroSynth，一个包含使用分形佩林噪声建模散射参数的非均匀介质的合成数据集。", "conclusion": "本文研究了佩林噪声分布，一种文献中没有明确定义的分布，以潜在地以向前馈的方式建模现实世界的非均匀散射。该方法已在未见过的新颖的非均匀形状变化、开放源码的真实体积模拟中的烟雾和云几何形状及一些实际样本上进行了评估，证明了其反向散射的有效性。"}
{"llm_update_time": "20250907", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.04058", "html_url": "https://arxiv.org/abs/2509.04058", "title": "SMooGPT: 使用大型语言模型进行风格化运动生成", "title_en": "SMooGPT: Stylized Motion Generation using Large Language Models", "authors": "Lei Zhong,Yi Yang,Changjian Li", "background": "风格化运动生成在计算机图形学中受到广泛关注，尤其得益于扩散模型的迅速发展。该任务的目标是在尊重运动内容的同时产生新颖的运动，例如“猴子走路的环形风格”。现有研究尝试通过运动风格转移或条件运动生成来解决这一问题。尽管取得了一定进展，但这些方法存在不可解释性、控制能力有限以及对新风格泛化能力不足等问题，而且难以生成除“行走”以外的运动，原因在于公共风格化数据集的强烈偏见。", "innovation": "本文提出了从推理-合成-生成的新视角解决风格化运动生成问题的方法，基于以下观察：人体运动往往可以通过肢体中心的方式用自然语言有效描述；大型语言模型（LLMs）在理解及推理人类运动方面表现出强大的能力；人体运动具有一种固有的组合性质，这使得通过高效重组来生成新的运动内容或风格成为可能。因此，本文建议使用肢体部分文本空间作为中介表示，并提出了SMooGPT，一种微调过的LLM，在生成所需风格化运动时充当推理器、合成器和生成器。该方法在肢体部分文本空间中的执行具有更高的可解释性，能够实现细粒度的运动控制，有效解决了运动内容和风格之间潜在的冲突，并由于LLM的开放词汇量能力可以很好地泛化到新风格。", "conclusion": "全面的实验和评估，以及用户感知研究显示了我们方法的有效性，特别在纯文本驱动的风格化运动生成方面表现出色。"}
{"llm_update_time": "20250907", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.04107", "html_url": "https://arxiv.org/abs/2509.04107", "title": "FedQuad：联邦随机四元组学习以缓解数据异质性", "title_en": "FedQuad: Federated Stochastic Quadruplet Learning to Mitigate Data Heterogeneity", "authors": "Ozgu Goksu,Nicolas Pugeault", "background": "联邦学习（FL）提供了一种分散的数据训练方式，有效解决了分布式数据和隐私保护的问题。然而，全局模型的通用性常因客户端数据异质性而面临挑战，尤其是在数据集有限且类别不平衡的情况下，这一挑战尤为明显。为了应对数据异质性，我们提出了一种名为FedQuad的新型方法，该方法明确优化了较小的类内方差和较大的类间方差，减少了模型聚合对客户端表示的负面影响。该方法在相似项之间最小化距离，并在负项之间最大化距离，从而有效将客户端数据从共享特征空间中分离出来。", "innovation": "FedQuad方法通过显式优化较小的类内方差和较大的类间方差，减少了模型聚合对客户端表示的负面影响。它在相似项之间最小化距离，并在负项之间最大化距离，从而有效在共享特征空间中分离客户端数据。这种方法在CIFAR-10和CIFAR-100数据集上进行了评估，证明了与其他现有方法相比的优越性能。此外，还详细分析了基于度量学习的策略在监督学习和联邦学习环境中的有效性。", "conclusion": "我们的研究结果表明，FedQuad方法在解决联邦学习环境中的表示学习挑战方面表现出色。通过对比现有的方法，我们的方法能够更好地处理数据异质性，取得了更优的性能。"}
{"llm_update_time": "20250907", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.04145", "html_url": "https://arxiv.org/abs/2509.04145", "title": "Hyper Diffusion Avatars: 使用网络权重空间扩散进行动态人体avatar生成", "title_en": "Hyper Diffusion Avatars: Dynamic Human Avatar Generation using Network Weight Space Diffusion", "authors": "Dongliang Cao,Guoxing Sun,Marc Habermann,Florian Bernard", "background": "创建人类avatar是一个高度 desirable 且具有挑战性的任务。最近在辐射场渲染方面的进展实现了个性化动态人体avatar前所未有的逼真度和实时性能。但是，这些方法通常受限于针对单一个体的多视图视频数据训练的人人特定渲染模型，限制了它们在不同身份之间的泛化能力。另一方面，利用预训练2D扩散模型先验知识的方法可以生成卡通且静止的人体avatar，这些avatar通过简单的骨骼动画进行动画处理。因此，这些方法生成的avatar在渲染质量上低于特定个体渲染方法，并且无法捕捉到_pose-依赖变形，如布料褶皱。", "innovation": "本文提出了一种新方法，将特定个体渲染和基于扩散的生成建模的优点结合起来，实现具有高逼真度和真实姿态依赖变形的动态人类avatar生成。该方法采用两阶段流水线：首先优化一组特定个体UNets，每张网络代表一个动态人类avatar，捕捉精妙的姿态依赖变形。在第二阶段，通过优化的网络权重训练一个超扩散模型。在推理阶段，该方法能够实时、可控地渲染动态人体avatar。使用大规模跨身份多视图视频数据集，我们的方法在人类avatar生成方面优于最先进的方法。", "conclusion": "在大规模跨身份多视图视频数据集上展示了我们的方法大幅优于最先进的方法。"}
{"llm_update_time": "20250907", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.04324", "html_url": "https://arxiv.org/abs/2509.04324", "title": "OVGrasp: 开口词汇抓取辅助通过多模态意图检测", "title_en": "OVGrasp: Open-Vocabulary Grasping Assistance via Multimodal Intent Detection", "authors": "Chen Hu,Shan Luo,Letizia Gionfrida", "background": "对于肢体功能受损的个体而言，在非结构化环境中恢复自主性需要足够的抓取辅助。在这些环境中，物体类别和用户意图多种多样且难以预测。因此，需要一种既能适应多种环境又能准确识别用户意图的抓取辅助系统。", "innovation": "OVGrasp 提出了一种基于软外骨骼的分层控制框架，融合了 RGB-D 视觉、开口词汇提示和语音指令，实现稳定的多模态交互。该框架引入了视图语言基础模型和开口词汇机制，能够在开放环境中实现零样本检测，无需重新训练。此外，一个多模态决策者可以结合空间和语言线索，推断用户意图，如抓取或释放，适用于多物场景。", "conclusion": "OVGrasp 经过在自制第一人称视角穿戴式外骨骼上的部署，并在 15 种不同物体上进行三类抓取动作的系统评估，结果显示它在十个参与者的测试中实现了 87.00% 的抓取能力评分（GAS），优于现有最先进技术，并实现了与自然手部运动更好的动力学对齐。"}
{"llm_update_time": "20250907", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.04351", "html_url": "https://arxiv.org/abs/2509.04351", "title": "全局到局部或局部到全局？使用高效局部搜索和有效全局再排序提升图像检索", "title_en": "Global-to-Local or Local-to-Global? Enhancing Image Retrieval with Efficient Local Search and Effective Global Re-ranking", "authors": "Dror Aiger,Bingyi Cao,Kaifeng Chen,Andre Araujo", "background": "当前的图像检索系统主要采用全局图像特征进行大规模数据库搜索，并对初步结果使用局部图像特征匹配技术进行再排序。这种方法称为全局到局部，因为局部匹配方法的计算成本较高，仅能应用于少量检索图像。然而，新兴的高效局部特征搜索方法使得在大规模场景下进行详细检索成为可能，这有助于找到全局特征搜索可能遗漏的部分匹配。同时，基于全局特征的再排序展现了高计算效率的潜力。", "innovation": "本文利用局部和全局特征搜索与再排序的底层构建块，提出了一个局部到全局的检索范式，即高效局部特征搜索结合有效全局特征再排序。提出了一种再排序方法，通过在搜索过程中基于局部特征检索相似性实时计算全局特征。这种方法利用多维缩放技术生成尊重检索过程中获得的局部相似性的嵌入式表示，从而显著提升了再排序性能。", "conclusion": "实验结果证明了该方法的强大检索性能，取得了《Revisited Oxford》和《Revisited Paris》数据集的新最优结果。"}
{"llm_update_time": "20250907", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.04441", "html_url": "https://arxiv.org/abs/2509.04441", "title": "DEXOP: 设备用于机器人传递灵巧的人类操作", "title_en": "DEXOP: A Device for Robotic Transfer of Dexterous Human Manipulation", "authors": "Hao-Shu Fang,Branden Romero,Yichen Xie,Arthur Hu,Bo-Ruei Huang,Juan Alvarez,Matthew Kim,Gabriel Margolis,Kavya Anbarasu,Masayoshi Tomizuka,Edward Adelson,Pulkit Agrawal", "background": "介绍了perioperation这一 paradigmm，用于通过传感器化和记录人类操作来收集数据，同时最大化数据向实际机器人转移的能力。在此基础上，开发了DEXOP，一种被动手部外骨骼，旨在最大化人类在自然环境中收集丰富的触觉和视觉数据的能力，以适应多种灵巧操作任务。DEXOP机械连接人类手指和机器人手指，使用户获得直接的接触反馈，并将人类手部姿态镜像给被动机器人手，最大限度地提高所展示技能向机器人的转移。本文通过对一系列灵巧、接触丰富的任务进行评估，展示了DEXOP在大规模收集高质量示范数据方面的能力，并证明使用DEXOP数据学习的策略与基于远程操作的方法相比，在单位数据收集时间内显著提高了任务性能，使DEXOP成为提高机器人灵巧性的有力工具。", "innovation": "开发了DEXOP（Dexterous Exoskeleton for Operations），一种被动手部外骨骼，它通过机械连接人类和机器人手指，提供直接接触反馈，并实时镜像人类手部姿势，最大化技能示范向机器人的转移。相较于传统的远程操作，DEXOP使操作示范更加自然，从而提高了速度和准确性。通过大规模示范数据收集，DEXOP展示了其在多种灵巧操作任务中的应用潜力。", "conclusion": "DEXOP作为一个强大的工具，通过对大规模示范数据的收集学习策略，显著提高了任务性能，为提高机器人灵巧性提供了强有力的支持。"}
{"llm_update_time": "20250907", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.04394", "html_url": "https://arxiv.org/abs/2509.04394", "title": "转换模型：重新思考生成学习的目标", "title_en": "Transition Models: Rethinking the Generative Learning Objective", "authors": "Zidong Wang,Yiyuan Zhang,Xiaoyu Yue,Xiangyu Yue,Yangguang Li,Wanli Ouyang,Lei Bai", "background": "生成模型中存在一个根本性的困境：迭代扩散模型能够获得卓越的保真度，但计算成本高昂；而高效的少步骤替代品则受限于难以突破的质量上限。这种生成步骤与输出质量之间的冲突是由训练目标严格限制所致，这些目标仅专注于无穷小动力学（PF-ODEs）或直接端点预测之一。", "innovation": "引入了一个确切的连续时间动力学方程，该方程以分析方式定义了任意有限时间区间的状态转换。这导致提出了一种新的生成范式：转换模型（TiM），它可以适应任意步数的转换，无缝地从单个跳跃到细粒度细化过渡。尽管仅有865M参数，TiM在所有评估的抽样预算中均实现了最佳性能，超越了SD3.5（8B参数）和FLUX.1（12B参数）。与之前的少步生成器不同，TiM随着采样预算的增加显示出了单调的质量提高。此外，使用本研究的原分辨率策略时，TiM在高达4096x4096的分辨率下提供卓越的保真度。", "conclusion": "转换模型（TiM）提供了一种新颖的生成方法，能够适应任意步骤的转换，实现了在所有评估步骤中的最佳性能，兼顾了高质量和高效的计算需求。"}
{"llm_update_time": "20250907", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2312.03993", "html_url": "https://arxiv.org/abs/2312.03993", "title": "使用稳定扩散进行卡尔文和霍布斯漫画风格迁移", "title_en": "Style Transfer to Calvin and Hobbes comics using Stable Diffusion", "authors": "Asvin Kumar Venkataramanan,Sloke Shrestha,Sundar Sripada Venugopalaswamy Sriraman", "background": "该项目报告总结了我们对卡尔文和霍布斯漫画数据集进行稳定扩散微调的旅程，目的是将任何给定的输入图像转换为卡尔文和霍布斯的风格，从而进行风格转移。", "innovation": "我们使用低秩适应（LoRA）来训练stable-diffusion-v1.5，以有效地加快微调过程。扩散部分由一个变分自编码器（VAE）处理，具体来说是一个U-net。", "conclusion": "我们的结果在训练时间和输入数据质量的情况下，视觉效果令人满意。"}
{"llm_update_time": "20250907", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2311.16507", "html_url": "https://arxiv.org/abs/2311.16507", "title": "基于扩散先验的更直流通风气流匹配", "title_en": "Straighter Flow Matching via a Diffusion-Based Coupling Prior", "authors": "Siyu Xing,Jie Cao,Huaibo Huang,Haichao Shi,Xiao-Yu Zhang", "background": "流匹配作为生成模型的一种范式，在多个领域取得了显著的成功。然而，现有的方法要么使用多轮训练，要么利用小批量内部的知识，这在寻找顺畅 trajectories 的耦合策略方面提出了挑战。这些方法在需要将生成轨迹调整到几步生成任务时遇到了困难。", "innovation": "我们提出了一种新的方法，称为StraightFM，它通过整个分布层次创建图像和噪声的耦合来直通 trajectories。在训练过程中，StraightFM 使用一个扩散模型作为耦合先验来直通 trajectories，以实现几步生成。此外，这种方法可以与现有的真实数据到噪声的耦合方向结合，从而提高几步生成中的图像质量。实验结果表明，StraightFM 在像素空间和潜在空间中可以在五步内生成吸引人的样本，并且可无缝兼容无条件的多模态条件生成，保持高质量的图像生成。", "conclusion": "我们的方法不仅在步步生成中的图像质量方面有所提高，还展示了在几种应用中能快速生成高质量图像的能力。"}
{"llm_update_time": "20250907", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2309.16494", "html_url": "https://arxiv.org/abs/2309.16494", "title": "通过多感受野非局部网络和新颖对比正则化实现准确和轻量的去雾霾", "title_en": "Accurate and lightweight dehazing via multi-receptive-field non-local network and novel contrastive regularization", "authors": "Zewei He,Zixuan Chen,Jinlei Li,Ziqian Lu,Xuecheng Sun,Hao Luo,Zhe-Ming Lu,Evangelos K. Markakis", "background": "近年来，基于深度学习的方法在去雾霾领域占据了主导地位。本文提出了一种多感受野非局部网络（MRFNLN），该网络包含多流特征关注模块（MSFAB）和跨非局部块（CNLB），旨在进一步提高去雾霾性能。研究从提取更丰富的特征开始，设计了一个包含三种不同感受野（1×1、3×3、5×5）卷积的多流特征提取（MSFE）子块，以便提取多尺度特征。随后，应用注意力子块使模型能够自适应地聚焦于重要通道/区域。MSFE与注意力子块共同构成了MSFAB。之后，设计了一个跨非局部块（CNLB），能够在超出查询范围的情况下捕捉长距离依赖关系。CNLB通过利用空间金字塔下采样（SPDS）策略来减少计算量和内存消耗，同时不牺牲性能。最后，提出了一种新的细节关注对比正则化（DFCR），在专为去雾霾设计的表示空间中强调低级细节并忽略高级语义信息，从而进一步提升了性能。", "innovation": "1. 提出的MRFNLN模型结合了多流特征注意块（MSFAB）和跨非局部块（CNLB），能够捕捉长距离依赖关系，同时减少计算量和内存消耗。\n2. 通过专为去雾霾设计的表示空间中的低级细节强调和高级语义信息忽略，提出了一种新的细节关注对比正则化（DFCR），进一步提升模型性能。\n3. 该模型参数少于150万，但实验结果表明其性能超过了当前最先进的去雾霾方法。", "conclusion": "本文提出的MRFNLN模型通过结合多流特征注意块和跨非局部块，以及提出新的细节关注对比正则化方法，实现了准确和轻量的去雾霾效果。"}
{"llm_update_time": "20250907", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2409.06002", "html_url": "https://arxiv.org/abs/2409.06002", "title": "通过更强指导增强生成式数据增强以用于语义分割", "title_en": "Enhanced Generative Data Augmentation for Semantic Segmentation via Stronger Guidance", "authors": "Quang-Huy Che,Duc-Tri Le,Bich-Nga Pham,Duc-Khai Lam,Vinh-Tiep Nguyen", "background": "像素级注释任务如语义分割需要大量的手工标注工作，传统数据增强方法如旋转和翻转虽然能生成新图像但缺乏多样性和未能改变关键语义属性。为了应对这个问题，生成模型作为一种有效的方法出现了，但它们在生成反映原始图像内容和结构的合成图像时存在挑战，尤其是在创建有效提示和视觉参考方面。", "innovation": "引入了一个基于可控扩散模型的有效数据增强流水线，通过Class-Prompt Appending和Visual Prior Blending优化提示生成，增强了对真实图像中标记类别的关注，从而生成精度高的增强图像并保留分割标注类别的结构。此外，实现了类平衡算法确保合成图像和原始图像合并后的训练数据集平衡。", "conclusion": "在PASCAL VOC数据集上的评估表明，该流水线能有效生成高质量合成图像用于语义分割。代码已公开。"}
{"llm_update_time": "20250907", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2405.20188", "html_url": "https://arxiv.org/abs/2405.20188", "title": "SPARE: 对齐平面距离的对称化方法在鲁棒非刚性配准中的应用", "title_en": "SPARE: Symmetrized Point-to-Plane Distance for Robust Non-Rigid Registration", "authors": "Yuxin Yao,Bailin Deng,Junhui Hou,Juyong Zhang", "background": "现有的基于优化的非刚性配准方法通常通过点对点或点对面距离来最小化配准误差度量，但这些度量可能导致收敛速度慢或细节丢失。", "innovation": "本文提出了一种新型的SPARE方法，采用对称化的点对面距离进行鲁棒非刚性配准。这种方法利用对应点的位置和法线，提供更准确的几何逼近，并且相比现有方法可以实现更高的精度。为高效求解优化问题，引入了类似于刚性的调节项来估计变形法线，并提出了一种利用近似最大化极小化策略的交替最小化求解器。此外，通过结合变形图为基础的粗略对齐方法增强求解器的有效初始化，提高配准质量和效率。", "conclusion": "实验结果表明，所提出的方法在非刚性配准问题中显著提高了精度，并且保持了相对较高的求解效率。代码已公开，可从this https URL访问。"}
{"llm_update_time": "20250907", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2408.05750", "html_url": "https://arxiv.org/abs/2408.05750", "title": "FADE: 用于视频中检测建筑物周围坠落物体的数据集", "title_en": "FADE: A Dataset for Detecting Falling Objects around Buildings in Video", "authors": "Zhigang Tu,Zitao Gao,Zhengbo Zhang,Chunluan Zhou,Junsong Yuan,Bo Du", "background": "坠落物体从建筑物上掉下来可能会给行人造成严重伤害。尽管安装了监控摄像头，但由于坠落物体体积小且运动速度快，以及背景复杂，人类难以捕捉监控视频中的此类事件。因此，需要开发能够自动检测建筑物周围坠落物体的方法。", "innovation": "首次提出了名为FADE（FAlling Object DEtection around Buildings）的大型多样视频数据集，并开发了一种新的物体检测方法FADE-Net。FADE数据集包括1,881个视频，来自18个场景，包含8个坠落物体类别、4种天气条件和4种视频分辨率。FADE-Net利用运动信息有效地生成用于检测建筑物周围坠落物体的小但高质量的提议。", "conclusion": "提出的FADE-Net在FADE数据集上的实验结果表明，该方法显著优于其他方法，为未来研究提供了有效的基线。该数据集和代码可在以下网址公开获取：this https URL."}
{"llm_update_time": "20250907", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2411.15537", "html_url": "https://arxiv.org/abs/2411.15537", "title": "MUNBa: 使用纳什讨价还价实现机器遗忘", "title_en": "MUNBa: Machine Unlearning via Nash Bargaining", "authors": "Jing Wu,Mehrtash Harandi", "background": "机器遗忘（MU）旨在从模型中选择性地删除有害行为，同时保持模型的整体有用性。作为多任务学习问题，MU涉及到忘记特定概念或数据和保持整体性能之间的权衡。简单地结合这两个遗忘和保护目标会导致梯度冲突和主导问题，阻碍MU算法达到最优解。", "innovation": "本文将机器遗忘重新表述为两个玩家的合作博弈，分别为遗忘玩家和保护玩家。利用纳什讨价还价理论，推导出一个封闭形式的解，引导模型向帕累托稳定点前进。这种表述保证了一个均衡解，任何偏离最终状态都会降低两个玩家的整体目标，确保每个目标的最优性。", "conclusion": "评估结果表明，我们的算法在图像分类和图像生成的多个任务中表现出色，优于最先进的MU算法，实现了更好的遗忘和保护之间的权衡。实验结果还强调了模型在遗忘精度、保留泛化能力以及抵御对抗攻击方面的改进。"}
{"llm_update_time": "20250907", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2405.06911", "html_url": "https://arxiv.org/abs/2405.06911", "title": "真实时间目标检测模型的复现研究与基准测试", "title_en": "Replication Study and Benchmarking of Real-Time Object Detection Models", "authors": "Pierre-Luc Asselin,Vincent Coulombe,William Guimont-Martin,William Larrivée-Hardy", "background": "本文探讨了最新实时目标检测模型的可重复性和基准测试。由于目标检测模型在实际应用中的准确性不足以全面评估（如机器人领域），研究者需要评估模型的准确性和推理速度，本文在多种图形卡上对比了大量目标检测模型的准确性和推理速度。此外，通过从零复现DETR、RTMDet、ViTDet和YOLOv7等模型在MS COCO 2017数据集上，发现已有研究在可重复性方面普遍不足，同时MMDetection预训练模型在有限计算资源下表现较差。总的来说，研究结果表明在准确性和速度之间存在权衡，无锚目标检测模型在此方面表现尤为突出。", "innovation": "本文提出了一种统一的训练和评估管道，基于MMDetection的特点，以便更好地比较模型。此外，本文复现了DETR、RTMDet、ViTDet和YOLOv7等模型，并发现它们在不同计算资源下的表现不一，尤其是无锚模型在速度和准确性之间表现更为优异。", "conclusion": "本文通过复现实时目标检测模型的研究和基准测试，表明复现与基准测试在该领域的重要性，同时也揭示了模型在不同硬件资源下的表现差异。结果显示无锚模型在准确性和速度之间表现最好，但复现过程中的结果表明，模型在不同条件下可达到的性能存在显著差异。"}
{"llm_update_time": "20250907", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2411.06119", "html_url": "https://arxiv.org/abs/2411.06119", "title": "在设备上生成图像的硬件友好型固定尺寸可重用结构的扩散模型", "title_en": "Hardware-Friendly Diffusion Models with Fixed-Size Reusable Structures for On-Device Image Generation", "authors": "Sanchar Palit,Sathya Veera Reddy Dendi,Mallikarjuna Talluri,Raj Narayana Gadde", "background": "现有的扩散模型通常采用Vision Transformers和U-Net架构。这些架构各自在设备上实现时存在特定的挑战。Vision Transformers虽然具有固定尺寸的可重用重复块的优势，但在处理过程中需要位置嵌入以维持标记间的对应关系。U-Net架构缺乏这一特性，它通过变尺寸的中间块进行下卷积和上卷积操作，这在噪声估计回路中用于扩散过程。", "innovation": "本文提出了一种架构，其核心结构是固定尺寸、可重用的变压器块，这使其更适合硬件实现。该架构具有低复杂性、标记无关设计、无位置嵌入、一致性和可扩展性等特点，使之非常适合部署在移动和资源受限的设备上。该模型在无条件和有条件图像生成任务中表现出竞标可比且一致的性能，并在无条件图像生成任务中使用CelebA数据集实现了最佳的FID分数1.6.", "conclusion": "本文提出的一种架构，克服了Vision Transformers和U-Net架构在设备上实现的限制，通过固定尺寸和可重用的变压器核心结构，提高了模型的适应性和性能，特别适用于移动和资源受限的设备。"}
{"llm_update_time": "20250907", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2502.08352", "html_url": "https://arxiv.org/abs/2502.08352", "title": "Sat-DN: 多视角卫星图像中深度和法线监督的隐式曲面重建", "title_en": "Sat-DN: Implicit Surface Reconstruction from Multi-View Satellite Images with Depth and Normal Supervision", "authors": "Tianle Liu,Shuangming Zhao,Wanshou Jiang,Bingxuan Guo", "background": "随着卫星成像技术的发展，获取高分辨率多视角卫星图像变得越来越容易，这使得快速、地点无关的土地模型重建得以实现。然而，传统的立体匹配方法难以捕捉到细腻的细节，而神经光线场（NeRFs）虽然能实现高质量的重建，但其训练时间过长。此外，卫星图像中建筑立面的低可见性、像素之间的光照和风格差异、以及缺乏纹理区域进一步使得合理地形几何和精细建筑立面的重建变得困难。", "innovation": "本文提出了一种新颖的框架Sat-DN，利用多分辨率哈希网格重建架构，同时包含显式的深度指导和表面法线一致性约束来提升重建质量。多分辨率哈希网格加速了训练过程，而逐进策略逐渐增加了学习频率，使用粗糙的低频几何来指导高频细节的重建。深度和法线约束确保了清晰的建筑轮廓和正确的平面分布。", "conclusion": "在DFC2019数据集上的广泛实验表明，Sat-DN在定性和定量评估中均优于现有方法，取得了最先进的结果。代码可以在以下链接获取：https://github.com/your-repo/sat-dn."}
{"llm_update_time": "20250907", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2412.09465", "html_url": "https://arxiv.org/abs/2412.09465", "title": "OFTSR：具有可调保真度-现实性折衷的一步流形图像超分辨率", "title_en": "OFTSR: One-Step Flow for Image Super-Resolution with Tunable Fidelity-Realism Trade-offs", "authors": "Yuanzhi Zhu,Ruiqing Wang,Shilin Lu,Junnan Li,Hanshu Yan,Kai Zhang", "background": "最近的扩散和流动生成模型在图像恢复任务中取得了显著的成功，其感知质量优于传统的深度学习方法。然而，这些方法要么需要多次采样步骤来生成高质量的图像，导致计算成本高昂，要么依赖于常见的模型蒸馏，这通常会固定保真度-现实性的折衷，缺乏灵活性。", "innovation": "本文介绍了一种新的流动框架OFTSR，它可以在单步骤中进行图像超级分辨率，且可以产生具有可调保真度和现实性的输出。该方法首先训练一个条件流动超分辨率模型作为教师模型，然后通过应用特定约束来蒸馏教师模型。这种结构确保了学生模型从初始状态的单步预测与教师模型从更接近的中间状态的预测相匹配。实验结果表明OFTSR在一步图像超分辨率方面取得了最先进的性能，并且具有灵活调节保真度-现实性折衷的能力。", "conclusion": "通过在数据集FFHQ、DIV2K和ImageNet上的大量实验，证明了OFTSR在一步图像超分辨率上的优越性能，并展现了其在可调保真度-现实性折衷上的灵活性。"}
{"llm_update_time": "20250907", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2412.12722", "html_url": "https://arxiv.org/abs/2412.12722", "title": "通过部分知觉监督抵御视觉攻击保护LVLMs", "title_en": "Defending LVLMs Against Vision Attacks through Partial-Perception Supervision", "authors": "Qi Zhou,Tianlin Li,Qing Guo,Dongxia Wang,Yun Lin,Yang Liu,Jin Song Dong", "background": "近年来，关于大型视觉语言模型(LVMLMs)在面对恶意注入或篡改的输入图像时的脆弱性问题引起了广泛关注，此类攻击可能会误导模型的响应。现有的防御方法表明，视觉攻击对图像修改（尤其是裁剪）非常敏感，通常通过在修改后的图响应中进行多数投票来作为矫正的响应。然而，这些修改往往会导致部分图像并扭曲语义，这在投票后降低了响应质量。这种方法侧重于直接使用部分图像响应进行投票，而不是监督原始图像的预测。", "innovation": "本文提出了一种名为DPS (Defense through Partial-Perception Supervision)的新颖、不需要训练的黑盒方法，它利用一个仅感知部分图像的模型生成的响应来监督LVLMs对原始图像的响应。当模型受到攻击时，它可以基于部分图像的理解进行调整响应，而在干净输入下则充满信心地维持其原始响应。研究发现，当面对攻击输入时，较弱模型可以监督较强模型使其更加自信并调整响应，从而有效防御攻击。", "conclusion": "实验结果表明，本方法优于基线方法，其在三个流行模型的六个数据集上平均攻击成功率降低了76.3%。"}
{"llm_update_time": "20250907", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.04378", "html_url": "https://arxiv.org/abs/2509.04378", "title": "使用增强注意机制的美学图像描述", "title_en": "Aesthetic Image Captioning with Saliency Enhanced MLLMs", "authors": "Yilin Tao,Jiashui Huang,Huaze Xu,Ling Shao", "background": "美学图像描述（AIC）旨在生成描述图像美学的文本描述，成为计算美学领域的关键研究方向。近年来，预训练的多模态大型语言模型（MLLMs）发展迅速，带来了将视觉和文本模态结合起来进行美学研究的显著增长。然而，现有的大多数关于图像美学的研究主要集中在预测美学评分上，并且在AIC方面的应用有限。现有的依靠MLLMs的AIC工作主要依赖于微调方法，而没有针对目标美学内容进行具体调整。因此，为了弥补这一不足，作者提出了一个名为Aesthetic Saliency Enhanced Multimodal Large Language Model（ASE-MLLM）的端到端框架，该框架显式地将美学注意功能引入到了MLLMs中。", "innovation": "在ASE-MLLM框架中，引入了Image Aesthetic Saliency Module (IASM)，能够高效地从图像中提取美学显著性特征，并使用IAS-ViT作为图像编码器，通过交叉注意力机制将美学显著性和原始图像特征融合起来。据我们所知，ASE-MLLM是首个专门针对AIC任务将图像美学显著性整合进MLLMs的框架。实验结果表明，与传统方法和通用MLLMs相比，该方法在当前主流AIC基准上的表现显著提升，达到了最先进的（SOTA）性能。", "conclusion": "ASE-MLLM框架成功地将美学显著性引入到了MLLMs中，通过这种端到端的方式有效地促进了AIC任务的发展，展示了显著的性能提升，证明了在MLLMs中融入美学理解的重要性。"}
{"llm_update_time": "20250907", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2502.20323", "html_url": "https://arxiv.org/abs/2502.20323", "title": "ARTalk: 通过自回归模型实现语音驱动的3D头部动画", "title_en": "ARTalk: Speech-Driven 3D Head Animation via Autoregressive Model", "authors": "Xuangeng Chu,Nabarun Goswami,Ziteng Cui,Hanqin Wang,Tatsuya Harada", "background": "语音驱动的3D面部动画旨在从任意音频片段中为3D头部模型生成逼真的唇部动作和面部表情。尽管现有的基于扩散的方法能够生成自然的运动，但其生成速度较慢，限制了其应用潜力。", "innovation": "本文介绍了一种新颖的自回归模型，能够通过从语音到多尺度运动码本的学习实现实时、高度同步的唇部动作和逼真的头部姿态和眨眼。此外，该模型能够适应未见过的说话风格，使得能够创建具有独特个人风格的3D对话 avatar，超过训练中看到的身份。", "conclusion": "广泛的评估和用户研究表明，我们的方法在唇部同步精度和感知质量方面优于现有方法。"}
{"llm_update_time": "20250907", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2503.13756", "html_url": "https://arxiv.org/abs/2503.13756", "title": "在分段 Wasserstein 距离中快速刚性对齐异质图像", "title_en": "Fast rigid alignment of heterogeneous images in sliced Wasserstein distance", "authors": "Yunpeng Shi,Amit Singer,Eric J. Verbeke", "background": "计算机视觉中的许多应用依赖于对相似但非同源图像进行对齐。传统的对齐方法往往速度慢且不那么鲁棒，特别是在处理包含平移、旋转和变形的异质图像时。因此，研究者们需要一种新的方法，可以快速有效地进行图像对齐，同时具有鲁棒性，以满足这些实际需求。", "innovation": "该研究提出了一种基于最优传输的快速算法，用于对齐异质图像。该方法结合了快速傅里叶方法的速度和切片概率度量的鲁棒性，能够在 $O(L^2 \text{log } L)$ 操作中高效地计算两个 $L \times L$ 图像之间的对齐，且对图像中的平移、旋转和变形具有鲁棒性。", "conclusion": "实验结果证明了该方法的有效性和鲁棒性。该算法在处理含有平移、旋转和变形的异质图像方面具有较高的效率和鲁棒性，为计算机视觉中的图像对齐提供了新的解决方案。"}
{"llm_update_time": "20250907", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2502.10118", "html_url": "https://arxiv.org/abs/2502.10118", "title": "图像嵌入采样方法用于多样化的 captioning", "title_en": "Image Embedding Sampling Method for Diverse Captioning", "authors": "Sania Waheed,Na Min An", "background": "自深度学习模型以来，图像字幕技术取得了显著进步，但随之而来的是计算复杂度的增加，这使得它们对资源受限的应用（如移动设备和辅助技术）不太适用。相比之下，更小的视觉语言模型（VLMs）可以实现高层的场景描述，但会忽略细节能为图像提供更丰富理解的细节。", "innovation": "本文提出了一种无需额外训练框架的方法，通过将一个小的VLM（BLIP）作为骨干网络，并利用结构化分割生成层次表示来捕捉全局和局部语义，从而增强字幕的多样性和信息性，最终在图像字幕对齐、语义完整性和多样性方面实现了与大型模型相同的表现。", "conclusion": "该方法在 MSCOCO、Flickr30k 和 Nocaps 测试数据集上进行评估，分别达到 Div-2 分数 0.735、0.750 和 0.748，在不牺牲人工标注字幕的相关性和语义完整性的前提下实现了这一目标。"}
{"llm_update_time": "20250907", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2503.23746", "html_url": "https://arxiv.org/abs/2503.23746", "title": "短视频传播影响力评级：一个新的现实世界数据集和一个新的大型图模型", "title_en": "Short-video Propagation Influence Rating: A New Real-world Dataset and A New Large Graph Model", "authors": "Dizhan Xue,Shengsheng Qian,Chuanrui Hu,Changsheng Xu", "background": "短视频平台在全球范围内吸引了大量用户，近来研究者们也开始关注短视频传播过程中的商业价值、公众意见和用户行为等问题。", "innovation": "本文提出了一种新的短视频传播影响力评级（SPIR）任务，并从数据集和方法论两个角度推动SPIR研究的发展。具体包括：1）构建了一个称为Cross-platform Short-Video（XS-Video）的新数据集，包含117,720个视频、381,926个样本和涵盖5大中国平台的535个主题，并提供了从传播影响等级0到9的所有观点、点赞、分享、收藏、粉丝、评论和评论内容等信息。这是首次包含跨平台数据或涵盖所有这些信息的大型短视频数据集。2）提出了一种基于新型三阶段训练机制的大型图模型（LGM）NetGPT，利用大型语言模型的知识和强大的推理能力，理解并分析短视频传播图，预测短视频的长期传播影响力。", "conclusion": "通过在XS-Video数据集上的分类和回归指标评估，证明了本文方法在SPIR任务中的优越性。"}
{"llm_update_time": "20250907", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.03623", "html_url": "https://arxiv.org/abs/2509.03623", "title": "用物理约束神经场揭示原行星盘的精细结构", "title_en": "Revealing Fine Structure in Protoplanetary Disks with Physics Constrained Neural Fields", "authors": "Aviad Levis,Nhan Luong,Richard Teague,Katherine. L. Bouman,Marcelo Barraza-Alfaro,Kevin Flaherty", "background": "原行星盘是行星的诞生地，解析其三维结构对于理解盘的演化至关重要。ALMA（阿塔卡马大型毫米/亚毫米阵列）的前所未有的分辨率要求建模方法能够捕捉传统方法无法触及的特征。现有方法未能揭示ALMA观测到的 hd 163296 的 CO 富集层的垂直形态特征，尤其是该层自 400 au 外显示出显著的变窄和扁平化现象。因此，需要一种新的方法来提取复杂盘结构，推进我们对原行星演化的理解。", "innovation": "我们引入了一个结合物理约束神经场和可微渲染的计算框架，开发了 GPU 加速、完全可微的线辐射传输求解器 RadJAX，实现了比传统光线追踪器高达 10,000 倍的速度提升，这使得以前无法解决的高维神经重建成为可能。将该框架应用于 ALMA 的 CO 观测数据，揭示了 CO 富集层的垂直形态，显示了自 400 au 以外显著的变窄和扁平化现象，这是现有方法未发现的特征。此工作确立了一种提取复杂盘结构的新范式，推动了我们对原行星演化的理解。", "conclusion": "通过引入结合物理约束神经场和可微渲染的计算框架，我们开发了 RadJAX 求解器，并成功应用 ALMA 的 CO 观测数据，揭示了 hD 163296 的 CO 富集层的复杂垂直形态，特别是显示了该层自 400 au 外的显著变窄和扁平化现象，这为原行星盘研究提供了新的视角，推动了我们对原行星演化的理解。"}
{"llm_update_time": "20250907", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2502.14891", "html_url": "https://arxiv.org/abs/2502.14891", "title": "CoDiff: 条件扩散模型在协作三维物体检测中的应用", "title_en": "CoDiff: Conditional Diffusion Model for Collaborative 3D Object Detection", "authors": "Zhe Huang,Shuo Wang,Yongcai Wang,Lei Wang", "background": "协作三维物体检测在自动驾驶领域具有重要意义，因为它通过促进多个代理之间的信息交流，大幅提升了每个代理的感知能力。然而，实际应用中由于姿态估计误差和时间延迟，代理间的信息融合常常会导致时空噪声，进而引发检测错误。扩散模型天然具备降噪能力，启发我们探索在多代理系统中应用扩散模型解决噪声问题。已有研究中尚未有将扩散模型用于多代理协作感知的先例。针对这种情况，我们提出了一种新颖的鲁棒协作感知框架CoDiff，利用扩散模型生成更全面、更清晰的特征表示。该框架首次尝试在多代理协作感知中应用扩散模型，通过将高维特征图投影到预训练自编码器的潜在空间，利用各代理信息作为条件指导扩散模型采样，逐步去噪并优化融合特征，从而提高协作检测性能并增强鲁棒性，即使在代理的姿态和延迟信息噪声较高时也能表现出良好的性能。相关实验使用模拟和真实世界数据集验证了方法的有效性，并公开了代码。", "innovation": "首次在多代理协作感知中应用扩散模型，提出CoDiff框架，利用扩散模型生成更清晰的特征表示，提高协作检测性能并增强鲁棒性。", "conclusion": "CoDiff框架在协作检测方面表现出优势，即使在有噪声的姿态和延迟信息时也能够提供可靠的性能。相关研究成果和代码已公布。"}
{"llm_update_time": "20250907", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2503.20652", "html_url": "https://arxiv.org/abs/2503.20652", "title": "模仿放射读片：用于3D胸部CT体积多标签异常分类的全局-局部注意力模型", "title_en": "Imitating Radiological Scrolling: A Global-Local Attention Model for 3D Chest CT Volumes Multi-Label Anomaly Classification", "authors": "Theo Di Piazza,Carole Lazarus,Olivier Nempont,Loic Boussel", "background": "随着CT扫描检查的数量迅速增加，迫切需要自动化工具（如器官分割、异常分类和报告生成）来帮助放射科医生应对日益增长的工作量。基于卷积神经网络（CNNs）的现有深度学习方法难以有效捕捉长范围依赖关系，而Vision Transformers则需要大量的预训练，这对实际应用提出挑战。此外，这些现有方法没有明确建模放射科医生在查看CT扫描切片时的浏览行为，这需要全局上下文理解和局部细节意识相结合。因此，迫切需要一种新的方法来模仿放射科医生的浏览行为，以更有效地进行3D CT扫描的多标签异常分类。", "innovation": "本研究提出了一种名为CT-Scroll的新型全局-局部注意力模型，专门设计用于模仿放射科医生在分析3D CT扫描时的浏览行为。该模型结合了全局上下文理解和局部细节意识，旨在更有效地进行多标签异常分类，相比现有方法而言，在数据的长距离依赖性和局部细节处理方面具有明显优势。", "conclusion": "通过在两个公开数据集上的评估和全面实验，以及消融研究，证明了CT-Scroll模型的有效性及其各组成部分的贡献。该模型展示了在理解和分类3D CT扫描中的多标签异常方面优于现有方法的能力。"}
{"llm_update_time": "20250907", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2504.13392", "html_url": "https://arxiv.org/abs/2504.13392", "title": "POET：通过文本到图像生成的自动化扩展支持提示创意和个人化", "title_en": "POET: Supporting Prompting Creativity and Personalization with Automated Expansion of Text-to-Image Generation", "authors": "Evans Xu Han,Alice Qian Zhang,Haiyi Zhu,Hong Shen,Paul Pu Liang,Jane Hsieh", "background": "现有的先进视觉生成AI工具在创意任务的早期阶段有很大的潜力，它们能够生成高质量的独特图像，而不是搜索现有的图像，且可以满足用户的多种要求。然而，许多大规模的文本到图像系统更加关注广泛的应用性，导致生成的输出较为传统，限制了创意的探索空间。此外，这些工具的交互方式可能对初学者而言较为复杂。由于最终用户的创作方式多种多样且难以预测，因此需要更多变化和个性化。现有的系统未能满足这种多样性和个性化的需求。", "innovation": "POET 是一种实时交互工具，具有以下创新点：(1) 自动发现文本到图像生成模型中的同质维度；(2) 扩展这些维度以多样化生成图像的空间；(3) 从用户反馈中学习以个性化这些扩展。通过28名用户在四个创作任务领域的试验，结果显示，POET 能够生成更高多样性感知的结果，并帮助用户在更少的提示中达到创作任务的满足感，使他们在共同创作过程中对更多可能的结果进行更深入的思考和反思。", "conclusion": "POET 为视觉创意提供了一种新的方法，能够自动扩展文本到图像生成工具，支持和满足更多元的价值观和用户需求。这种迭代和个性化的扩展方法有助于激发用户的创造力，促进更高质量和更有创意的作品生成。这对于未来文本到图像生成工具的交互技术有重要的启示作用。"}
{"llm_update_time": "20250907", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2505.02980", "html_url": "https://arxiv.org/abs/2505.02980", "title": "通过完成空间转录组学数据来进行基因表达预测基准测试", "title_en": "Completing Spatial Transcriptomics Data for Gene Expression Prediction Benchmarking", "authors": "Daniela Ruiz,Paula Cárdenas,Leonardo Manrique,Daniela Vega,Gabriel M. Mejia,Pablo Arbeláez", "background": "空间转录组学是一种结合了组织学图像和空间分辩基因表达谱的先进技术。Visium是被广泛采用的技术之一，然而其高昂的成本、需要专门技术知识以及较慢的临床整合限制了其可及性。此外，基因捕获效率低导致数据缺失，干扰了所得数据的质量。虽然深度学习社区从组织学图像直接预测基因表达的任务有所探索，但由于数据集、预处理和训练协议的一致性问题，模型之间的公平比较受到了阻碍。", "innovation": "本文引入了一个名为SpaRED的系统性数据集，包含26个公共数据集，为模型评估提供标准化资源。进一步提出了一种基于变压器的基因表达完成模型SpaCKLE，相较于现有方法，其均方误差降低了82.5%以上。本文还建立了SpaRED基准，评估了八种最先进的预测模型在原始数据和SpaCKLE完成数据上的表现，结果显示SpaCKLE显著提高了所有基因表达预测模型的结果。此外，本文的贡献构成了迄今为止最全面的空间转录组学从组织学图像预测基因表达的基准，并为未来的研究奠定了基础。", "conclusion": "本文的工作构成了迄今为止最全面的空间转录组学从组织学图像预测基因表达的基准，并为未来的研究奠定了基础。通过SpaRED数据集和SpaCKLE模型，我们为未来在空间转录组学领域的工作提供了参考和改进的基础。"}
{"llm_update_time": "20250907", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2504.05774", "html_url": "https://arxiv.org/abs/2504.05774", "title": "可迁移遮罩变换器：基于区域自适应迁移可转移性估计的跨域语义分割", "title_en": "Transferable Mask Transformer: Cross-domain Semantic Segmentation with Region-adaptive Transferability Estimation", "authors": "Jianhua Liu,Zhengyu Li,Yanru Wu,Jingge Wang,Yang Tan,Ruizhe Zhao,Guan Wang,Yang Li", "background": "近期，视觉变换器（ViTs）在语义分割任务中取得了新的基准。然而，当将预先训练好的ViTs应用到新的目标领域时，由于分布偏移，会出现显著的性能下降，导致全局注意力效果不佳。由于自注意机制是数据驱动的，在源域和目标域之间的纹理、尺度或物体共现模式差异的情况下，它们可能无法有效地关注重要对象。虽然全局和局部领域的适应方法提供了一定的解决方案，但是针对不同图像区域的空间异质性，区域级别的自适应（具有动态形状的区域）更为关键。因此，本文介绍了一种新的区域级别的自适应框架——可迁移遮罩变换器（TMT），通过空间迁移性分析来对齐不同领域的表示。", "innovation": "TMT框架由两个关键组件组成：（1）适配的基于聚类的迁移可转移性估计器（ACTE），能够动态地将图像分割成结构和语义上连贯的区域，以进行局部迁移性评估；（2）可迁移遮罩注意力（TMA）模块，它将特定区域的迁移性图集成到ViTs的注意力机制中，优先在低迁移性和高语义不确定性区域进行自适应。", "conclusion": "全方面的评估结果显示，TMT框架在20对跨域数据集上取得了优越的性能，平均提高了2%的MIoU，与基线模型相比，相对于现有的最佳基线提高了1.28%。源代码将公开。"}
{"llm_update_time": "20250907", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2505.03522", "html_url": "https://arxiv.org/abs/2505.03522", "title": "单张图像超分辨率模块转移性优化：通用性评估与循环残差块", "title_en": "Optimization of Module Transferability in Single Image Super-Resolution: Universality Assessment and Cycle Residual Blocks", "authors": "Haotong Cheng,Zhiqi Zhang,Hao Li,Xinshang Zhang", "background": "深度学习极大地促进了单张图像超分辨率（SISR）领域的发展，现有研究大多关注性能的提升，而忽视了架构组件的转移性评估。", "innovation": "提出了“通用性”概念及其定义，扩展了传统的“泛化”概念，以涵盖模块的转移性。提出了“通用性评估方程”（UAE），量化了模块移植的难易程度，并揭示了多个现有指标对转移性的影响。设计了两种优化模块：循环残差块（CRB）和深度循环残差块（DCRB），并通过一系列实验验证了嵌入这些模块的网络优于多个最先进的方法，在降噪和参数减少方面表现出显著优势。", "conclusion": "嵌有提出的可插入模块的网络在自然场景基准、遥感数据集和其他低级别任务上优于多种最先进的方法，实现了0.83 dB的PSNR提升或参数减少了71.3%，同时几乎不影响重构保真度。这种优化方法可以应用于更多的基础模块，提供了一种新的可插拔模块设计范式。"}
{"llm_update_time": "20250907", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2505.23525", "html_url": "https://arxiv.org/abs/2505.23525", "title": "Hallo4: 通过直接偏好优化和时间运动调节实现高质量动态肖像动画", "title_en": "Hallo4: High-Fidelity Dynamic Portrait Animation via Direct Preference Optimization and Temporal Motion Modulation", "authors": "Jiahao Cui,Yan Chen,Mingwang Xu,Hanlin Shang,Yuxuan Chen,Yun Zhan,Zilong Dong,Yao Yao,Jingdong Wang,Siyu Zhu", "background": "生成高度动态且逼真的肖像动画仍然具有挑战性，主要因为需要精确的唇部同步、自然面部表情和高质量的身体动作动力学。现有的方法难以同时满足这些需求。", "innovation": "我们提出了一种人偏好对齐的扩散框架，通过以下两个关键创新来解决这些挑战：1. 引入直接偏好优化，针对以人为中心的动画，利用一个精心策划的人类偏好数据集来对生成输出进行感知度量的对齐，以实现肖像运动视频的对齐和自然表情。2. 提出的时间运动调节通过时间通道重分布和比例特征扩展将运动条件重塑为维度一致的潜在特征，从而解决时空分辨率不匹配的问题，同时保留基于扩散合成的高度运动细节的保真度。", "conclusion": "我们的方法与现有的UNet和DiT基于的肖像扩散方法相辅相成，实验结果表明，唇音同步、表情生动性和身体运动连贯性有了明显改善，同时在人类偏好度量上也取得了显著收益。我们的模型和源代码可以在以下网址找到：this https URL."}
{"llm_update_time": "20250907", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2505.07611", "html_url": "https://arxiv.org/abs/2505.07611", "title": "基于深度学习的视觉交通事故预兆进展：方法、数据集及相关方向的全面回顾", "title_en": "Deep Learning Advances in Vision-Based Traffic Accident Anticipation: A Comprehensive Review of Methods, Datasets, and Future Directions", "authors": "Ruonan Lin,Tao Tang,Yongtai Liu,Wenye Zhou,Xin Yang,Hao Zheng,Jianpu Lin,Yi Zhang", "background": "交通事故预测和检测对于提高道路安全至关重要，深度学习时代的视觉交通事故预兆（Vision-TAA）已逐渐成为一种具有前景的方法。本文回顾了147篇近期研究，重点介绍了监督、无监督和混合深度学习模型在事故预测中的应用，以及实际和合成数据集的使用。现有的方法被归类为四种主要策略：基于图像和视频特征的预测、基于时空特征的预测、场景理解以及多模态数据融合。尽管展示了显著的潜力，但数据稀缺性、复杂场景下的有限泛化能力和实时性能限制仍然是主要挑战。", "innovation": "本文总结了多模态数据融合、自我监督学习和基于Transformer的架构等未来研究机会，以提高预测准确性和扩展性。通过综合现有进步并识别关键缺口，本文为开发稳健和自适应的Vision-TAA系统提供了基础参考，为道路安全和交通管理做贡献。", "conclusion": "本文为基于深度学习的视觉交通事故预兆系统的发展提供了全面的基础，指出了未来研究的关键方向，旨在提升预测性能并扩大应用场景。"}
{"llm_update_time": "20250907", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.01587", "html_url": "https://arxiv.org/abs/2507.01587", "title": "基于相机参数实现可控实时图像降噪", "title_en": "Towards Controllable Real Image Denoising with Camera Parameters", "authors": "Youngjin Oh,Junhyeong Kwon,Keuntek Lee,Nam Ik Cho", "background": "近期基于深度学习的图像去噪方法取得了显著的效果；然而，许多方法缺乏根据噪声水平、相机设置和用户偏好调整去噪强度的灵活性。本文介绍了一种新的可控去噪框架，该框架利用来自相机参数的信息来自适应地去除图像中的噪声，特别是针对与噪声水平密切相关的ISO、快门速度和光圈数。", "innovation": "将选定的相机参数（ISO、快门速度和光圈数）转换为向量来控制和增强去噪网络的性能，实现了在标准去噪神经网络中无缝添加可控性并提升其性能。", "conclusion": "实验证明，该方法可以无缝地增强标准去噪神经网络的性能，并提高它们的可调节性。相关代码在该网址: [this https URL] 可用。"}
{"llm_update_time": "20250907", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2505.20789", "html_url": "https://arxiv.org/abs/2505.20789", "title": "将中间层优化与投影梯度下降结合以利用扩散模型解决反问题", "title_en": "Integrating Intermediate Layer Optimization and Projected Gradient Descent for Solving Inverse Problems with Diffusion Models", "authors": "Yang Zheng,Wen Li,Zhaoqiang Liu", "background": "反问题（IPs）涉及从受噪声影响的观察结果重建信号。近年来，扩散模型（DMs）作为一种强大的框架用于解决反问题，取得了显著的重建表现。然而，现有的基于DM的方法经常遇到计算量大和收敛性不佳的问题。在本作品中，基于最近提出的DMPlug概念，我们提出了两种新的方法，DMILO和DMILO-PGD，来解决这些挑战。两种方法均基于DMPlug的思想，旨在减少内存负担并通过引入稀疏偏差扩展扩散模型的应用范围，进一步探讨ILO与投影梯度下降（PGD）结合的方法以降低次优收敛的风险。", "innovation": "我们提出了两种新的方法：DMILO和DMILO-PGD。DMILO结合了中间层优化（ILO）来减轻内存负担，并通过引入稀疏偏差增强了扩散模型的应用范围。DMILO-PGD将ILO与投影梯度下降（PGD）结合，进一步降低了次优收敛的风险。我们提供了在适当条件下对这些方法的直观理论分析，并通过针对多种图像数据集进行了广泛的实验，证实了DMILO和DMILO-PGD在解决基于扩散模型的反问题中的优越性。这些方法的成功展示了它们在应对DM基反问题求解器中常见挑战的有效性。", "conclusion": "实验结果表明，我们的方法在多类图像数据集上取得了显著的性能提升，比现有最先进的方法更加有效。这表明DMILO和DMILO-PGD在解决基于扩散模型的反问题方面是有效的。"}
{"llm_update_time": "20250907", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2505.03498", "html_url": "https://arxiv.org/abs/2505.03498", "title": "Res-MoCoDiff: Residual-guided diffusion models for motion artifact correction in brain MRI", "title_en": "Res-MoCoDiff: Residual-guided diffusion models for motion artifact correction in brain MRI", "authors": "Mojtaba Safari,Shansong Wang,Qiang Li,Zach Eidex,Richard L.J. Qiu,Chih-Wei Chang,Hui Mao,Xiaofeng Yang", "background": "脑部MRI中的运动伪影主要由头部刚性运动引起，这些伪影会降低图像质量，阻碍下游应用。现有的减轻这些伪影的方法，如重复采样或运动跟踪，会增加工作流程的负担。因此，研究一种高效的降噪扩散概率模型，专门针对MRI运动伪影的问题非常重要。现有方法主要使用U-net架构，并用Swin Transformer块替换注意力层，以增强不同分辨率的鲁棒性。此外，训练过程结合了结合的l1+l2损失函数，以提高图像锐度并减少像素级错误。该研究在合成数据集和真实数据集上进行评估，包括使用CycleGAN、Pix2pix和带视觉变压器主干的扩散模型进行对比分析，以PSNR、SSIM等定量指标进行结果评价。研究证明了该方法在轻微、中度和严重伪影移除上优于现有方法，特别是在PSNR、SSIM等指标上表现最佳。而且，该方法的采样时间显著降低，优于传统方法。", "innovation": "该研究提出了Res-MoCoDiff，这是一种高效的降噪扩散概率模型，用于减轻脑部MRI中的运动伪影。该模型通过在前向扩散过程中引入一种新的残差误差转移机制，结合了受误差影响的图像信息。这种机制使得模型能够模拟与受罪数据的概率分布相近的噪声演变，从而只需要四步即可实现反向扩散过程。该研究还采用了U-net骨架，并用Swin Transformer块代替了注意力层，增强了不同分辨率的鲁棒性。此外，训练过程中结合了一种结合的l1+l2损失函数，以提高图像锐度并减少像素级错误。该模型在合成数据集和真实数据集上的表现优于现有的方法，特别是在SSIM和PSNR等定量指标上表现突出，并且采样时间显著降低。", "conclusion": "该研究通过Res-MoCoDiff模型，在减轻脑部MRI中的运动伪影方面取得了显著的成果。该模型在不同严重程度的伪影去除上表现出色，并在各种定量指标上优于现有方法。此外，该模型的采样时间显著降低，显示出在实际应用中的高效率。"}
{"llm_update_time": "20250907", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2505.10823", "html_url": "https://arxiv.org/abs/2505.10823", "title": "从嵌入到准确度：比较基础模型在放射分类中的应用", "title_en": "From Embeddings to Accuracy: Comparing Foundation Models for Radiographic Classification", "authors": "Xue Li,Jameson Merkow,Noel C. F. Codella,Alberto Santamaria-Pang,Naiteek Sangani,Alexander Ersoy,Christopher Burt,John W. Garrett,Richard J. Bruce,Joshua D. Warner,Tyler Bradshaw,Ivan Tarapov,Matthew P. Lungren,Alan B. McMillan", "background": "基础模型提供了多样任务的稳健嵌入，包括医学影像。本研究评估了来自七个通用和医学特定基础模型的嵌入（例如，DenseNet121，BiomedCLIP，MedImageInsight，Rad-DINO，CXR-Foundation）在多分类放射学分类中的应用。通过一个包含8,842张X射线片、分为七类的数据集，使用K-最近邻、逻辑回归、SVM、随机森林和MLP等算法训练了轻量级适配器。MedImageInsight嵌入与SVM或MLP适配器的结合取得了最高的平均曲线下面积（mAUC）为93.1%，在统计上优于其他模型，包括与MLP配合的MedSigLIP（91.0%）、与SVM配合的Rad-DINO（90.7%）和与逻辑回归配合的CXR-Foundation（88.6%）。其他模型如BiomedCLIP（82.8%）和Med-Flamingo（78.5%）的表现较低。", "innovation": "本研究创新性地比较了不同基础模型在放射分类中的表现，特别强调了MedImageInsight嵌入与轻量级适配器结合使用的效果，其准确率和公平性表现突出，尤其是适应临床使用，具有计算效率和实际应用价值。", "conclusion": "研究发现，针对医学影像分类任务的专门基础模型，特别是MedImageInsight，通过结合简单的轻量级适配器，可以实现准确、高效且公平的诊断工具。"}
{"llm_update_time": "20250907", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.06949", "html_url": "https://arxiv.org/abs/2507.06949", "title": "前哥伦布时期定居点在新热带山区森林棕榈林聚集群中的生态遗产", "title_en": "Ecological Legacies of Pre-Columbian Settlements Evident in Palm Clusters of Neotropical Mountain Forests", "authors": "Sebastian Fajardo,Sina Mohammadi,Jonas Gregorio de Souza,César Ardila,Alan Tapscott Baltar,Shaddai Heidgen,Maria Isabel Mayorga Hernández,Sylvia Mota de Oliveira,Fernando Montejo,Marco Moderato,Vinicius Peripato,Katy Puche,Carlos Reina,Juan Carlos Vargas,Frank W. Takes,Marco Madella", "background": "前哥伦布时期的古代人口显著改变了新热带地区的森林生态系统，但其生态影响的空间范围在高分辨率下仍较少被研究。本文提出了一种基于深度学习和遥感的方法，通过现代植被来估计前哥伦布时期森林改造的区域。该方法被应用于哥伦比亚 Sierra Nevada de Santa Marta 高分辨率卫星图像，评估棕榈树分布与考古基础设施的关系。", "innovation": "本文提出了一个基于深度学习和遥感的创新方法，通过现代植被估计前哥伦布时期森林改造的区域。该方法能够评估棕榈树分布与考古基础设施的关系，发现大型基础设施遗址附近的棕榈树显著增多，这表明古代人类管理的区域可能比现有考古证据大得多。", "conclusion": "研究表明，前哥伦布时期的人口影响了植被，促进了棕榈树的繁殖条件，留下了持久的生态印记。这可能降低了在较难达到地区建立基础设施密集型定居点的物流成本。"}
{"llm_update_time": "20250907", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.15269", "html_url": "https://arxiv.org/abs/2507.15269", "title": "高效率视频压缩中的条件视频生成", "title_en": "Conditional Video Generation for High-Efficiency Video Compression", "authors": "Fangqiu Yi,Jingyu Xu,Jiawei Shao,Chi Zhang,Xuelong Li", "background": "感知研究表明，条件扩散模型在重建与人类视觉感知相匹配的视频内容方面表现出色。基于此认识，本文提出了一种利用条件扩散模型进行感知优化重建的视频压缩框架。", "innovation": "该框架将视频压缩重新定义为一个条件生成任务，使用生成模型从稀疏但富有信息的信号中合成视频。该方法引入了三个关键模块：1）多粒度的条件模块，同时捕捉静态场景结构和动态空时线索；2）高效而具有语义丰富性的表示形式，用于高效传输；3）多条件训练以及模态 dropout 和角色感知嵌入，防止对任何单一模态的过度依赖，从而增强鲁棒性。", "conclusion": "大量的实验证明，本文的方法在弗雷歇视频距离（FVD）和 LPIPS 等感知质量指标上，相对于传统和神经码流编码算法，特别是在高压缩比下，表现显著更优。"}
{"llm_update_time": "20250907", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.12964", "html_url": "https://arxiv.org/abs/2507.12964", "title": "基于人群特征的儿童腕部骨折细粒度分类", "title_en": "Demographic-aware fine-grained classification of pediatric wrist fractures", "authors": "Ammar Ahmed,Ali Shariq Imran,Zenun Kastrati,Sher Muhammad Daudpota", "background": "儿童腕部骨折较为常见，尤其是在骨折病例中占多数。计算机视觉虽然有潜力，但需要大量数据集的支持，这对医疗成像构成挑战。现有研究大多依赖单一模态，如图像，无法充分应对多类型数据。因此，需要一种融合多种数据类型的方法来提高诊断准确度。", "innovation": "本文提出了一种整合人群特征信息的方法，将细粒度Transformer方法、细粒度预训练和人群特征信息融合应用于儿童腕部骨折识别。这是首次将人群特征信息应用于腕部病理识别领域。结果显示，该方法在小型定制数据集上提高了2%的诊断准确率，在大规模骨折数据集上提高了超过10%的准确率。", "conclusion": "综合细粒度Transformer方法、细粒度预训练和人群特征信息，可以显著提高儿童腕部骨折的诊断准确率。这种方法为医疗成像中的多模态数据融合提供了新的思路。"}
{"llm_update_time": "20250907", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2506.05195", "html_url": "https://arxiv.org/abs/2506.05195", "title": "基于ArUco导向到达角估计的视觉自主毫米波反射器", "title_en": "Vision-Based Autonomous MM-Wave Reflector Using ArUco-Driven Angle-of-Arrival Estimation", "authors": "Josue Marroquin,Nan Inzali,Miles Dillon Lantz,Campbell Freeman,Amod Ashtekar,\\\\Ajinkya Umesh Mulik,Mohammed E Eltayeb", "background": "在非视距（NLoS）条件下实现可靠的工作在毫米波（mmWave）通信是军事和民用操作中的主要挑战，尤其是在城市或基础设施受限的环境中。现有的解决方案并不能很好地满足这一需求，因此需要一种新的方法来提升毫米波链路性能，特别是在非视距条件下。为此，本研究提出了一种利用单目相机辅助的自主反射器系统，通过实时调节金属反射板的角度以动态引导信号反射，从而增强毫米波通信链路的性能。", "innovation": "该研究的核心创新在于开发了一种基于视觉和角度到达估计的自主毫米波反射器系统。通过单目相机检测ArUco标记以估计角度到达，系统能够实时调整反射器位置以进行最优信号重定向。该系统具有自主性，无需依赖外部基础设施或GPS，并且能够选择性地覆盖已认证的目标，减少信号意外泄漏的风险。研究展示了该原型在60 GHz测试下的优异性能，表明其有望在复杂和动态环境中的实现可靠的毫米波连接。", "conclusion": "实验结果表明，该系统在60 GHz频率下平均信号强度增益为23 dB，并且在室内的信号接收概率保持在-65 dB以上的阈值以上，概率为0.89。相比于静态反射器和无反射器的基线，该系统显著提升了信号接收质量，在复杂动态的环境中具有较强的适应性和鲁棒性，展示了该系统在毫米波通信中的应用潜力。"}
{"llm_update_time": "20250907", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.10868", "html_url": "https://arxiv.org/abs/2508.10868", "title": "TexVerse: 3D物体库，包含高分辨率纹理", "title_en": "TexVerse: A Universe of 3D Objects with High-Resolution Textures", "authors": "Yibo Zhang,Li Zhang,Rui Ma,Nan Cao", "background": "在大规模3D数据集的最新进展中，高分辨率几何体的生成得到了增强，但由于缺乏适合的数据集，从端到端生成高分辨率纹理仍然是未被充分探索的研究领域。", "innovation": "TexVerse创新地提供了一个包含超过858,000个独特高分辨率3D模型的大规模数据集，这些模型主要来自Sketchfab平台，并包括超过158,000个基于物理的渲染（PBR）材质的模型。此外，TexVerse还包括专门的子集，如TexVerse-Skeleton（69,000个经过骨架绑定的模型）和TexVerse-Animation（54,000个动画模型），这些模型保留了用户上传的原始骨架和动画数据。TexVerse还提供了详细的模型注释，涵盖了总体特征、结构组件和复杂特征。", "conclusion": "TexVerse提供了一个高质量的数据资源，具有广泛的应用潜力，可用于纹理合成、PBR材质开发、动画以及各种3D视觉和图形任务。"}
{"llm_update_time": "20250907", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.13238", "html_url": "https://arxiv.org/abs/2508.13238", "title": "DianJin-OCR-R1：通过一种推理与工具交错的视觉语言模型增强OCR能力", "title_en": "DianJin-OCR-R1: Enhancing OCR Capabilities via a Reasoning-and-Tool Interleaved Vision-Language Model", "authors": "Qian Chen,Xianyin Zhang,Lifan Guo,Feng Chen,Chi Zhang", "background": "近年来，大型视觉-语言模型（LVLMs）在文档图像解析任务（如OCR）中表现出色，但由于生成式LVLMs存在生成不存在于输入图像中的词语（幻觉）的问题，且它们设计较为泛化，不如专门训练的专家模型（根据领域特定数据集）在OCR任务上有效。", "innovation": "本文提出了一种名为DianJin-OCR-R1的推理增强框架，通过交错训练的可推理和工具利用方法解决上述问题。DianJin-OCR-R1模型首先利用自身的OCR能力识别输入图像的内容，然后调用其他专家模型获取参考结果，最后重新审视图像并再思考推理过程以提供最终识别结果。实验表明，DianJin-OCR-R1模型在ReST和OmniDocBench上的表现优于没有推理过程的模型和专家OCR模型，证明了该方法的有效性。", "conclusion": "通过增强专家模型，DianJin-OCR-R1模型得以为视觉语言模型带来性能提升，而这些专家模型通常较小且易于迭代。"}
{"llm_update_time": "20250907", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.22627", "html_url": "https://arxiv.org/abs/2507.22627", "title": "LOT斯时尚！通过草图-文本配对进行多条件图像生成", "title_en": "LOTS of Fashion! Multi-Conditioning for Image Generation via Sketch-Text Pairing", "authors": "Federico Girella,Davide Talon,Ziyue Liu,Zanxi Ruan,Yiming Wang,Marco Cristani", "background": "时尚设计是一个复杂的创造性过程，结合了视觉和文本表达。设计师通过草图和文本描述传达想法，草图定义空间结构和设计元素，而文本描述捕捉材料、纹理和风格细节。现有方法往往难以同时生成全局和局部设计元素，尤其是在图像生成方面表现出色的方法，这激发了本文的研究动机，提出了一种新的方法来解决这一问题。", "innovation": "本文介绍了一种名为LOCalized Text and Sketch for fashion image generation (LOTS)的方法，该方法通过局部草图+文本配对的信息来实现组合式的图像生成。利用模块化配对中心化表示将草图和文本编码到共享的潜在空间中，同时保留独立的局部特征。进一步地，引入了一种基于注意力的指导下的扩散模型的多步降噪过程中的扩散对指导阶段，实现了局部和全局条件的集成。这种方法相较于已有技术可以在多个指标上取得更好的表现，实现了前所未有的设计定制化程度，并首次建立了一个包含多个文本-草图配对的Fashionpedia数据集，用于验证方法的有效性。", "conclusion": "通过定量和定性结果的验证展示，LOTS方法在全局和局部图像生成中都达到了最优性能，并由人类评估结果进一步支持了其在设计定制化方面的优越性。"}
{"llm_update_time": "20250907", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.14904", "html_url": "https://arxiv.org/abs/2507.14904", "title": "基于CLIP的TriCLIP-3D：一种统一高效的三模态3D视觉接地框架", "title_en": "TriCLIP-3D: A Unified Parameter-Efficient Framework for Tri-Modal 3D Visual Grounding based on CLIP", "authors": "Fan Li,Zanyi Wang,Zeyi Huang,Guang Dai,Jingdong Wang,Mengmeng Wang", "background": "3D视觉接地允许具身代理根据人类指令理解实际3D环境中的视觉信息，这对具身智能至关重要。现有的3D视觉接地方法通常依赖于不同模态（如RGB图像、文本和3D点云）的独立编码器，导致模型体积庞大且训练效率低下。某些方法使用预训练的2D多模态模型（如CLIP）进行3D任务，但是它们仍然难以将点云数据对齐到2D编码器。因此，这些方法仍然依赖于3D编码器进行特征提取，进一步增加了模型复杂性和训练效率低下。", "innovation": "本文提出了一种统一的2D预训练多模态网络来处理所有三种模态（RGB图像、文本和点云），显著简化了体系结构。通过利用具有适配器基础微调的2D CLIP双模态模型，该框架有效地适应了三模态设置，提高了各模态的适应性和性能。特别设计了Geometric-Aware 2D-3D特征恢复和融合（GARF）模块来融合点云和图像的几何多尺度特征，然后集成文本特征进行最终模态融合，并引入了多模态解码器以促进深层跨模态理解。方法在三大模态中实现了统一的特征提取和融合，支持端到端的3D视觉接地模型。相比基准方法，该方法使可训练参数减少了约58%，同时在3D检测任务上取得了6.52%的改进，在3D视觉接地任务上取得了6.25%的改进。", "conclusion": "该方法实现了统一的特征提取和融合，支持端到端的3D视觉接地模型，并通过减少训练参数数量和提高性能，展示了其有效性和优越性。"}
{"llm_update_time": "20250907", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.15387", "html_url": "https://arxiv.org/abs/2508.15387", "title": "DIO: Refining Mutual Information and Causal Chain to Enhance Machine Abstract Reasoning Ability", "title_en": "DIO: Refining Mutual Information and Causal Chain to Enhance Machine Abstract Reasoning Ability", "authors": "Ruizhuo Song,Beiming Yuan", "background": "尽管当前深度学习模型在各个领域表现出色，但在抽象推理方面仍存在根本性瓶颈。学术界通过引入雷文渐进矩阵（RPM）问题来评估深度学习算法在抽象推理、模式识别和复杂问题解决等核心智能维度上的能力。因此，该论文旨在解决RPM问题，并通过因果链 modelling 的视角系统分析RPM任务中的因果链条：图像 → 抽象属性 → 进步属性模式 → 模式一致性 → 正确答案。然而，实验表明用于基准模型DIO的优化目标无法让模型真正掌握预定义的人类推理逻辑，这主要是由于低界不紧性和互信息作为统计度量无法捕捉主题与对象之间的因果关系。", "innovation": "为了解决上述限制，该论文提出了三种改进方法，逐步实现了互信息和因果链的优化，旨在提升机器的抽象推理能力。", "conclusion": "该研究通过因果链 modeling 和优化互信息的方法，系统地设计了基准模型 DIO，旨在提升深度学习模型在抽象推理任务中的表现和能力。"}
{"llm_update_time": "20250907", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.17832", "html_url": "https://arxiv.org/abs/2508.17832", "title": "HLG：基于层次布局生成的全面3D房间构建", "title_en": "HLG: Comprehensive 3D Room Construction via Hierarchical Layout Generation", "authors": "Xiping Wang,Yuxi Wang,Mengqi Zhou,Junsong Fan,Zhaoxiang Zhang", "background": "现实istic 3D室内场景生成对于虚拟现实、室内设计、沉浸式智能体和场景理解至关重要。现有方法虽在粗略的家具排列上取得了进展，但在捕捉细粒度的对象放置方面仍有困难，这限制了生成环境的真实性和实用性。这些问题妨碍了沉浸式虚拟体验和详细场景的理解。", "innovation": "提出了一种新颖的层次布局生成（HLG）方法，这是一种首次采用从粗到细的层次化方法，从大的家具布局精炼到复杂的对象排列。具体来说，通过垂直和水平分离构建层次布局，有效将复杂的3D室内场景分解成不同级别的粒度。此外，可训练的布局优化网络解决了放置问题，如定位错误、方向错误和对象重叠，确保生成的场景具有结构上的一致性和物理上的合理性。", "conclusion": "通过广泛的实验表明，HLG方法在生成逼真的室内场景方面优于现有方法。这项工作推动了场景生成领域的发展，并为需要详细3D环境的应用打开了新的可能性。我们将在发表后公开我们的代码，以鼓励未来的研究。"}
{"llm_update_time": "20250907", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.23357", "html_url": "https://arxiv.org/abs/2507.23357", "title": "现代计算机视觉中的基础与模型：里程碑架构的关键构建块", "title_en": "Foundations and Models in Modern Computer Vision: Key Building Blocks in Landmark Architectures", "authors": "Radu-Andrei Bourceanu,Neil De La Fuente,Jan Grimm,Andrei Jardan,Andriy Manucharyan,Cornelius Weiss,Daniel Cremers,Roman Pflugfelder", "background": "本文通过分析六篇具有重大影响的论文，探讨了计算机视觉领域中关键设计模式的演变。分析从图像识别的基础架构开始，回顾了ResNet，它通过引入残差连接解决了梯度消失问题，从而使深层卷积网络的训练更加有效。随后，分析了ViT，它通过将Transformer架构应用于图像补丁序列，确立了一个新的范式，展示了基于注意力机制的模型在大规模图像识别中的有效性。在视觉表示骨干的基础上，进一步探讨了生成模型，分析了GANs及其新颖的对抗训练过程，以及LDMs在感知压缩隐空间中进行逐步去噪的改进生成方法。最后，探讨了减少对标注数据依赖的自监督学习技术，如DINO和MAE。", "innovation": "本文的独特之处在于通过回顾ResNet、ViT、GANs、LDMs、DINO和MAE，全面解析了现代计算机视觉的发展趋势，其中包括残差连接用于深层网络训练、Transformer架构在图像中的应用以及对抗训练、去噪等新技术，并展示了自监督学习在减少标注数据依赖性方面的重要进展。", "conclusion": "本文总结了计算机视觉领域的里程碑式架构，并强调了自监督学习以及生成模型在提高图像合成质量和计算效率方面的突破。"}
{"llm_update_time": "20250907", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.00451", "html_url": "https://arxiv.org/abs/2509.00451", "title": "仅编码器图像配准", "title_en": "Encoder-Only Image Registration", "authors": "Xiang Chen,Renjiu Hu,Jinwei Zhang,Yuxi Zhang,Xinyao Yue,Min Liu,Yaonan Wang,Hang Zhang", "background": "基于学习的技术显著提高了变形图像配准的准确性和速度，但降低计算复杂性和处理大变形的问题仍然存在。", "innovation": "提出了仅编码器图像配准（EOIR）框架，该框架通过分离特征学习和流估计，使用只有3层的卷积神经网络进行特征提取，并使用多层流估计器构建拉普拉斯特征金字塔，逐步组合非刚性变形，并通过实验证明该框架在不同模态和解剖区域的五个数据集上具有卓越的准确性和效率。", "conclusion": "EOIR实现了一种更好的准确性和效率的权衡，在保持相似准确性的前提下提供了更好的效率和平滑性，反之亦然。该框架的源代码已公开。"}
{"llm_update_time": "20250907", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.18733", "html_url": "https://arxiv.org/abs/2508.18733", "title": "Drawing2CAD：从矢量图生成CAD模型的序列到序列学习", "title_en": "Drawing2CAD: Sequence-to-Sequence Learning for CAD Generation from Vector Drawings", "authors": "Feiwei Qin,Shichao Lu,Junhao Hou,Changmiao Wang,Meie Fang,Ligang Liu", "background": "计算机辅助设计（CAD）生成建模正在工业应用中推动显著创新。尽管有很多研究已经展示了从点云、网格和文本描述等生成实体模型的进展，但这些方法与传统的从二维工程图纸开始的工作流程差异明显。目前，从这些二维矢量图纸自动生成参数化CAD模型仍是一个未被广泛探索的领域，尽管这是工程设计中的一个关键步骤。因此，本文提出了一个创新的解决方法，将其视为序列到序列的学习问题，通过直接使用矢量绘图的基本元素来指导参数化CAD操作的生成，从而在整个转换过程中保持几何精度和设计意图不变。", "innovation": "本文提出了一个名为Drawing2CAD的框架，该框架包括三个关键技术组件：一种网络友好的矢量基本元素表示，它保留了准确的几何信息；一种双解码器变压器架构，将命令类型生成和参数生成分离开，同时保持精确的对应关系；以及一种软目标分布损失函数，以适应CAD参数的基本灵活性。为此，还创建了一个包含配对工程图纸和参数化CAD模型的数据集CAD-VGDrawing，并进行了广泛的实验，以证明方法的有效性。", "conclusion": "通过Drawing2CAD框架，本文成功解决了从二维矢量图纸自动生成参数化CAD模型的问题，证明了该方法的有效性，并为工程设计提供了新的思路。"}
{"llm_update_time": "20250907", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.19762", "html_url": "https://arxiv.org/abs/2508.19762", "title": "BuzzSet v1.0: 田间条件下传粉昆虫检测的数据集", "title_en": "BuzzSet v1.0: A Dataset for Pollinator Detection in Field Conditions", "authors": "Ahmed Emam,Mohamed Elbassiouny,Julius Miller,Patrick Donworth,Sabine Seidel,Ribana Roscher", "background": "传粉昆虫如蜜蜂和大黄蜂对全球食物生产和生态系统稳定至关重要，但因人为和环境压力，其种群正在下降。在农业环境中的可扩展、自动化监测仍是一个开放的挑战，因难以检测到小而快速移动且常被伪装的昆虫。", "innovation": "提出了BuzzSet v1.0，这是在真实田间条件下收集的高分辨率传粉昆虫图像的大型数据集，包含7856张手动验证图像，超过8000个注释实例分为三类：蜜蜂、大黄蜂和未知昆虫。初始注释使用了YOLOv12模型，随后通过开源工具的人工验证进行了细化。所有图像被预处理成256x256的瓷砖，以更好地检测小型昆虫。提供了基于RF-DETR的基于变换器的对象检测器的基线，结果表明分类准确性较强（蜜蜂和大黄蜂的F1分数分别为0.94和0.92），并对无分类实例进行了困难分析，强调了可靠的昆虫检测挑战，特别是在自然植被中的伪装昆虫。", "conclusion": "BuzzSet数据集为生态计算机视觉设定了基准，主要挑战是可靠地检测经常被自然植被伪装的昆虫，这是未来研究中的一个开放问题。未来的重点工作是扩展数据集到v2.0，增加注释并评估进一步的检测策略。"}
{"llm_update_time": "20250907", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.01563", "html_url": "https://arxiv.org/abs/2509.01563", "title": "Kwai Keye-VL 1.5 技术报告", "title_en": "Kwai Keye-VL 1.5 Technical Report", "authors": "Biao Yang,Bin Wen,Boyang Ding,Changyi Liu,Chenglong Chu,Chengru Song,Chongling Rao,Chuan Yi,Da Li,Dunju Zang,Fan Yang,Guorui Zhou,Guowang Zhang,Han Shen,Hao Peng,Haojie Ding,Hao Wang,Haonan Fang,Hengrui Ju,Jiaming Huang,Jiangxia Cao,Jiankang Chen,Jingyun Hua,Kaibing Chen,Kaiyu Jiang,Kaiyu Tang,Kun Gai,Muhao Wei,Qiang Wang,Ruitao Wang,Sen Na,Shengnan Zhang,Siyang Mao,Sui Huang,Tianke Zhang,Tingting Gao,Wei Chen,Wei Yuan,Xiangyu Wu,Xiao Hu,Xingyu Lu,Yi-Fan Zhang,Yiping Yang,Yulong Chen,Zeyi Lu,Zhenhua Wu,Zhixin Ling,Zhuoran Yang,Ziming Li,Di Xu,Haixuan Gao,Hang Li,Jing Wang,Lejian Ren,Qigen Hu,Qianqian Wang,Shiyao Wang,Xinchen Luo,Yan Li,Yuhang Hu,Zixing Zhang", "background": "近年来，大型语言模型（LLMs）的发展取得了显著进展，扩展了其能力以处理多模态任务。然而，视频理解仍然是一个具有挑战性的领域，因为视频具有动态且信息密集的特性。现有的模型在处理视频内容时很难在空间分辨率和时间覆盖之间找到平衡。", "innovation": "Keye-VL-1.5 通过三种关键创新解决了视频理解中的根本挑战。首先，引入了一种新颖的 Slow-Fast 视频编码策略，根据帧间相似性动态分配计算资源，处理具有显著视觉变化的关键帧并以高分辨率处理（Slow 路径），同时处理相对静态的帧并在低分辨率下增加时间覆盖（Fast 路径）。其次，实施了一种渐进的四阶段预训练方法，系统地将模型的上下文长度从 8K 扩展到 128K 词，从而能够处理更长的视频和更复杂的视觉内容。第三，开发了一个全面的后训练管道，专注于增强推理和人类偏好对齐，包括五个步骤的推理链数据构建过程、迭代基于 GSPO 的强化学习以适应困难案例，并进行对齐训练。", "conclusion": "通过在公共基准和严格的内部人工评估中进行广泛评估，Keye-VL-1.5 在视频理解任务上表现出显著的改进，同时在通用多模态基准上保持了竞争力。"}
{"llm_update_time": "20250907", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2406.13923", "html_url": "https://arxiv.org/abs/2406.13923", "title": "PIN: 一种用于配对和交错多模态文档的知识密集型数据集", "title_en": "PIN: A Knowledge-Intensive Dataset for Paired and Interleaved Multimodal Documents", "authors": "Junjie Wang,Yuxiang Zhang,Minghao Liu,Yin Zhang,Yatai Ji,Weihao Xuan,Nie Lin,Kang Zhu,Zhiqiang Lin,Yiming Ren,Chunyang Jiang,Yiyao Yu,Zekun Wang,Tiezhen Wang,Wenhao Huang,Jie Fu,Qunshu Liu,Yujiu Yang,Ge Zhang,Ruibin Yuan,Bei Chen,Wenhu Chen", "background": "最近大型多模态模型（LMMs）的进步通过利用大量的多模态数据集来提升处理复杂知识驱动任务的能力，但在感知和推理错误方面仍面临持续挑战，特别是在理解和推理复杂视觉数据及多模态关系方面。", "innovation": "本文引入了一种新的数据格式，PIN（配对和交错多模态文档），它独特地结合了包含丰富语义的Markdown文件和包含文档整体布局的大图，从而实现更深层次的视觉和文本知识融合。基于这个格式，作者构建并发布了两个大规模、开源数据集：PIN-200M（约2亿文档）和PIN-14M（约1400万），这些数据集从英语和中文的广泛网络和科学来源中收集而来。", "conclusion": "我们的工作提供了一种灵活的数据格式和大量资源，为基础研究和开发更具知识密集型的LMMs提供了一个基础。"}
{"llm_update_time": "20250907", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2410.02807", "html_url": "https://arxiv.org/abs/2410.02807", "title": "AutoPETIII: The Tracer Frontier. What Frontier?", "title_en": "AutoPETIII: The Tracer Frontier. What Frontier?", "authors": "Zacharia Mesbah,Léo Mottay,Romain Modzelewski,Pierre Decazes,Sébastien Hapdey,Su Ruan,Sébastien Thureau", "background": "去年AutoPET竞赛聚集了医学成像领域围绕正电子发射断层扫描(PET)扫描中的病变分割这一热点问题。不同年度，竞赛针对的问题不同；2024年的竞赛核心在于应对多样的现有和使用的显像剂，任务是开发一种无需知道显像剂的全自动算法，以在PET/CT扫描中进行病变分割，该显像剂可能是FDG或PSMA基的。", "innovation": "利用nnUNetv2框架训练了两组六折模型集合，实现了全自动的PET/CT病变分割，并通过MIP-CNN选择使用哪一组模型进行分割。", "conclusion": "通过上述方法，成功开发了一种能够自动分割未知显像剂的PET/CT病变的算法，该算法有效应对了多显像剂环境下的分割挑战。"}
{"llm_update_time": "20250907", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.02175", "html_url": "https://arxiv.org/abs/2509.02175", "title": "理解空间是火箭科学 -- 只有顶级推理模型能解决空间理解任务", "title_en": "Understanding Space Is Rocket Science -- Only Top Reasoning Models Can Solve Spatial Understanding Tasks", "authors": "Nils Hoehing,Mayug Maniparambil,Ellen Rushe,Noel E. O'Connor,Anthony Ventresque", "background": "目前开源和前沿的视觉-语言模型（VLMs）在空间关系理解方面表现出明显的不足，而推理模型却表现出出乎意料的高性能。为此，需要一个新的基准测试来对照这两个模型的表现，特别是针对空间关系的理解能力。", "innovation": "提出了名为RocketScience的开源对比性VLM基准，专门测试空间关系理解能力。该基准包含全新的现实世界图像-文本对，主要考验相对空间理解及物体顺序理解。设计上旨在对人类而言非常容易，但对当前的VLMs来说极具挑战性。此外，还进行了去混分析，将对象定位和空间推理在链式思考模型中的贡献进行了分离，发现该基准的性能瓶颈在于空间推理能力不足，而不是对象定位能力。", "conclusion": "开源和前沿商业VLMs的空间关系理解能力较差，而推理模型的性能超出预期；RocketScience基准能够有效地测试VLMs的空间关系理解能力，并为该领域未来的研究提供了坚实的基础；该基准的去混分析结果表明，在链式思考模型中，空间推理能力是限制性能的关键因素。"}
{"llm_update_time": "20250907", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2403.05702", "html_url": "https://arxiv.org/abs/2403.05702", "title": "Spatial-aware Transformer-GRU Framework for Enhanced Glaucoma Diagnosis from 3D OCT Imaging", "title_en": "Spatial-aware Transformer-GRU Framework for Enhanced Glaucoma Diagnosis from 3D OCT Imaging", "authors": "Mona Ashtari-Majlan,David Masip", "background": "青光眼是导致不可逆失明的主要原因之一，早期检测对于准确及时干预、预防不可逆视力丧失至关重要。这项研究旨在建立一种新的基于深度学习的框架，以利用3D光学相干断层扫描(OCT)成像的诊断价值，实现自动化青光眼检测。", "innovation": "该研究提出了一个结合预训练的Retina数据Vision Transformer和双向门控递归单元(Gated Recurrent Unit, GRU)的新颖框架，以实现富于层次性的切片特征提取，并捕捉跨切片的空间依赖性。这一双部件方法能够全面分析局部细微特征和全局结构完整性，对于准确诊断青光眼至关重要。实验结果表明，该方法比最先进的方法具有优越的性能，F1分数为93.01%，马修斯相关系数(MCC)为69.33%，AUC为94.20%。", "conclusion": "该框架能够利用3D OCT数据中的有价值信息，对临床决策支持系统的改进以及青光眼管理中提高患者结果具有重要意义。"}
{"llm_update_time": "20250907", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2405.20321", "html_url": "https://arxiv.org/abs/2405.20321", "title": "开放世界中的单个人类视频基于视觉操纵与对象图", "title_en": "Vision-based Manipulation from Single Human Video with Open-World Object Graphs", "authors": "Yifeng Zhu,Arisrei Lim,Peter Stone,Yuke Zhu", "background": "该论文研究了如何使机器人通过模仿人类视频中的演示来学习基于视觉的操纵技能。背景在于，传统方法往往需要大量标注数据，且难以通用到不同视觉背景、摄像头角度和物体实例的新环境中。本研究通过使用单个人类视频来训练机器人学习新的物体操作技能，从而解决了开放世界中的机器人操纵问题。", "innovation": "本文提出了一种基于对象中心的方法ORION，旨在从单个RGB或RGB-D视频中提取出操作计划，并据此生成策略。这一方法能够使机器人利用日常移动设备拍摄的视频进行学习，并在不同视觉背景、摄像头角度、布局及新物体实例的环境中进行泛化。本研究通过在不同任务和视频类型（RGB-D / RGB）上系统性地评估ORION算法的效果，展示了其在开放世界中的有效性，并达到了74.4%的平均成功率。", "conclusion": "本研究证明了ORION方法在单个开放世界人类视频数据上的学习效果，可以使机器人从人类演示中学习新的操作技能，并广泛应用于不同环境。"}
{"llm_update_time": "20250907", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2501.07681", "html_url": "https://arxiv.org/abs/2501.07681", "title": "Dataset Distillation as Pushforward Optimal Quantization", "title_en": "Dataset Distillation as Pushforward Optimal Quantization", "authors": "Hong Ye Tan,Emma Slade", "background": "数据集蒸馏是指找到一个合成训练集，使得在合成数据上训练的性能与在真实数据上训练的性能相似，同时具有数量级更低的计算要求。当前的方法可以广泛分为两种类型：一类是具有神经网络训练启发方法为低层问题的双层最优化问题；另一类是通过匹配数据分布来绕过双层最优化的解耦方法。解耦方法的优点在于速度和伸缩性，特别是在训练集和蒸馏数据集的大小方面。", "innovation": "本研究证明，当与编码器-解码器结构相结合时，现有的成功解耦数据集蒸馏方法可以被重新表述为最优量化问题，其中找到一组点来近似底层概率测度，以最小化期望投影距离。我们还将现有的解耦数据集蒸馏方法与经典的最优量化和 Wasserstein 贝叶斯中心问题联系起来，证明了蒸馏的数据集对于基于扩散的生成先验的一致性。基于潜空间中的聚类提出了数据集蒸馏通过最优量化方法，相较于之前的SOTA方法D\textsuperscript{4}M，在ImageNet-1K数据集上实现了更好的性能和跨模型通用性，同时具有更优的推理性能。", "conclusion": "使用解馏的初始噪声在更强的扩散转换器模型中，我们获得在ImageNet-1K及其子集上有SOTA的解馏性能，优于扩散指导方法。"}
{"llm_update_time": "20250907", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2502.06289", "html_url": "https://arxiv.org/abs/2502.06289", "title": "基于超大规模自然图像的基础模型是否优于专门针对视网膜的模型，用于检测眼部和系统性疾病？", "title_en": "Is an Ultra Large Natural Image-Based Foundation Model Superior to a Retina-Specific Model for Detecting Ocular and Systemic Diseases?", "authors": "Qingshan Hou,Yukun Zhou,Jocelyn Hui Lin Goh,Ke Zou,Samantha Min Er Yew,Sahana Srinivasan,Meng Wang,Thaddaeus Lo,Xiaofeng Lei,Siegfried K. Wagner,Mark A. Chia,Dawei Yang,Hongyang Jiang,An Ran Ran,Rui Santos,Gabor Mark Somfai,Juan Helen Zhou,Haoyu Chen,Qingyu Chen,Carol Y. Cheung,Pearse A. Keane,Yih Chung Tham", "background": "自基础模型（FMs）的出现，它们正在彻底改变医疗领域。在眼科中，RETFound 是一种专门针对视网膜的 FM，通过逐步预训练于 1.4 百万张自然图像和 1.6 百万张视网膜图像，它在临床应用中展现出了高适应性。相比之下，DINOv2 是一种通用视觉 FM，通过预训练于 14.2 百万张自然图像，它在非医疗领域的应用前景广阔，但在临床任务中的应用还尚未充分探索。", "innovation": "本文通过将 RETFound 和三种不同大小的 DINOv2 模型（大、基、小）分别应用于视网膜病变和多类眼病检测以及预测心脏衰竭、心肌梗死和缺血性中风的任务，进行了头对头的评估，结果发现 DINOv2 的大模型在视网膜病变检测中优于 RETFound，在多类眼病检测中也表现更佳。", "conclusion": "研究结果表明，通用型基础模型和专门针对某一领域的基础模型在各自的适用场景中表现出色。因此，选择基础模型时应与其特定任务需求相匹配，以优化临床性能。"}
{"llm_update_time": "20250907", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2506.12348", "html_url": "https://arxiv.org/abs/2506.12348", "title": "实时松垮衣物特有的虚拟试穿方法及其时间一致性", "title_en": "Real-Time Per-Garment Virtual Try-On with Temporal Consistency for Loose-Fitting Garments", "authors": "Zaiqiang Wu,I-Chao Shen,Takeo Igarashi", "background": "现有的针对每件衣物的虚拟试穿方法会收集特定于衣物的数据集并训练针对每件衣物定制的网络以获得更好的结果。然而，这些方法在处理宽松衣物时常遇到困难，主要是因为人体轮廓被宽松衣物遮挡时，人体语义图变得不可靠，从而导致结果退化；同时这些方法在每个帧上训练衣物合成网络时未利用时间信息，从而导致帧与帧间的不平滑跳跃效果。", "innovation": "为了克服上述问题，该研究提出了一种两阶段方法进行稳健的语义图估计。首先从原始输入图像提取出衣物不变的表示，然后通过辅助网络估计语义图，以增强在生成特定于衣物的数据集时在宽松衣物下的语义图估计的稳健性。此外，引入了具有时间依赖性的循环衣物合成框架，以提高帧间一致性，同时保持实时性能。", "conclusion": "通过定性和定量评估表明，该方法在图像质量和时间一致性方面均优于现有方法。消融研究进一步验证了此类方法的有效性。"}
{"llm_update_time": "20250907", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2502.07107", "html_url": "https://arxiv.org/abs/2502.07107", "title": "材料微结构图像的监督和非监督分割与分类框架", "title_en": "A Framework for Supervised and Unsupervised Segmentation and Classification of Materials Microstructure Images", "authors": "Kungang Zhang,Wei Chen,Wing K. Liu,L. Catherine Brinson,Daniel W. Apley", "background": "材料的微观结构通常通过图像分析来表征，以理解其加工-结构-性能之间的联系。随着制造和成像技术的进步，高分辨率成像技术揭示了微结构的复杂性，并且图像（即显微图像）的数量迅速增加，这要求一种更强大且自动化的框架来提取材料特性和知识。", "innovation": "本文提出了一种高度自动化的框架，该框架将无监督和监督学习方法相结合，用于根据微结构相/类对显微图像进行分类，并对多相微结构进行不同的同质区域分割。该框架包括三个步骤：（1）使用最近开发的评分方法对多相显微图像进行分割，以在无监督的方式中识别不同微结构的同质区域；（2）通过结合不确定性量化和最小的人工检查，使用分割后的显微图像及其验证过的标签来训练具有不确定性意识的监督分类网络来识别和分类显微图像的同质区域；（3）使用一种形式的数据增强训练分割网络，基于显微图像和步骤1-2的结果对多相微结构进行监督分割。该框架能够迭代地表征和分割新的同质或多相材料，并扩展数据库以提高性能。", "conclusion": "该框架已在各种材料和组织图像数据集上进行了演示，可以帮助构建特定工艺或材料组相关的微结构类别的数据库，以便进行分析并发现/识别新材料。"}
{"llm_update_time": "20250907", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2504.11249", "html_url": "https://arxiv.org/abs/2504.11249", "title": "冷冻电镜图像本质上是低维度的", "title_en": "Cryo-em images are intrinsically low dimensional", "authors": "Luke Evans,Octavian-Vlad Murad,Lars Dingeldein,Pilar Cossio,Roberto Covino,Marina Meila", "background": "模拟推理提供了一种对冷冻电镜数据分析的强大框架，利用神经网络在Cryo-SBI等方法中推断生物分子构象，通过学到的潜在表示。这些潜在空间包含丰富的信息，对物理系统和推理过程提供有价值的见解。不过，运用这些潜在表示的有效性取决于理解其中的几何结构。本文通过使用流形学习技术分析Cryo-SBI表示的血凝素（仿真和实验数据），揭示了这些高维数据本质上占据着低维度、光滑的流形结构。", "innovation": "本文通过应用流形学习技术分析Cryo-SBI的血凝素表示数据，发现高维数据实际上占据低维度、光滑的流形结构，且仿真数据能够覆盖实验数据的流形。通过使用扩散映射法来表征流形的几何结构，并使用坐标解释方法识别主要变异轴，建立了潜在结构与关键物理参数之间的直接联系。这一发现不仅验证了Cryo-SBI方法的有效性，还为从数据结构中获得更多知识提供了可能性，同时也为未来改进推断策略提供了机会。", "conclusion": "发现这些本质的低维度性和可解释的几何组织不仅验证了Cryo-SBI方法的有效性，还为从数据结构中获得更多知识提供了可能性，同时也为未来改进推断策略提供了机会。"}
{"llm_update_time": "20250907", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2504.09885", "html_url": "https://arxiv.org/abs/2504.09885", "title": "分解以协作：用于协调整奏钢琴手势合成的双流扩散模型", "title_en": "Separate to Collaborate: Dual-Stream Diffusion Model for Coordinated Piano Hand Motion Synthesis", "authors": "Zihao Liu,Mingwen Ou,Zunnan Xu,Jiaqi Huang,Haonan Han,Ronghui Li,Xiu Li", "background": "自动合成协调的双手钢琴演奏面临着重大挑战，尤其是在捕捉双手之间的细腻编排同时保持其独特的运动特征。现有方法在建模双手独立性与协调性上存在局限，特别是在捕捉复杂的手部协调模式方面遇到困难。本文以这一挑战为背景，提出了一种双流神经框架，旨在从音频输入中生成同步手部动作，解决双手独立与协调同时建模的关键问题。该框架通过双重噪声初始化和共享位置条件，独立建模每只手的运动，并利用一种称为手协调不对称注意力（HCAA）的机制来抑制对称噪声，突出显示手部特定特征，并在去噪时自适应增强双手之间的协调度。", "innovation": "该论文提出了两个创新点：（i）一种解耦的扩散基于生成框架，通过双重噪声初始化独立建模每只手的运动，并利用共享位置条件；（ii）一种手协调不对称注意力（HCAA）机制，抑制对称噪声以突出显示手部特定特征，并在去噪时自适应增强双手之间的协调度。", "conclusion": "全面的评估表明，该框架在多个指标上优于现有最先进的方法。关于该项目的更多信息，请访问：this https URL."}
{"llm_update_time": "20250907", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.04434", "html_url": "https://arxiv.org/abs/2509.04434", "title": "Durian: 双参考引导的具有属性转移的肖像动画", "title_en": "Durian: Dual Reference-guided Portrait Animation with Attribute Transfer", "authors": "Hyunsoo Cha,Byungjun Kim,Hanbyul Joo", "background": "当前对于肖像动画的生成技术还缺乏高效且能够准确转移面部属性的方法。现有的方法通常需要大量训练数据或严格约束，难以在无监督的情况下实现高保真度和空间一致性地转移面部属性。", "innovation": "本文提出了名为Durian的方法，这是一种能够在无监督条件下进行肖像动画生成，并从给定的参考图像转移到目标肖像的面部属性转化方法。通过引入双参考网络，该方法将对象和属性图像的空间特征注入到去噪过程中，从而实现了跨帧的高保真度和空间一致性。此外，提出了基于关键点的图像生成技术来扩展掩码，以及对属性和肖像图像进行空间和外观级变换以增强模型对位置对齐不准确的鲁棒性。", "conclusion": "Durian方法在具有面部属性转的肖像动画生成方面达到了最先进的性能。其双参考设计使得在单次生成过程中可以合成多个面部属性，而不需要额外的训练。"}
{"llm_update_time": "20250907", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.18826", "html_url": "https://arxiv.org/abs/2508.18826", "title": "SWiFT: 软掩码权重微调以减轻偏差", "title_en": "SWiFT: Soft-Mask Weight Fine-tuning for Bias Mitigation", "authors": "Junyu Yan,Feng Chen,Yuyang Xue,Yuning Du,Konstantinos Vilouras,Sotirios A. Tsaftaris,Steven McDonagh", "background": "近期的研究表明，机器学习模型在实际应用中可能存在偏差，这在医疗保健等伦理敏感领域构成了重大挑战。这种偏差可能影响模型的公平性、泛化能力，并且有可能加剧社会歧视。因此，去除训练模型中的偏差是必要的。现有的去偏方法通常需要访问原始训练数据并进行大量的模型重新训练，同时往往会在模型公平性和鉴别性能之间存在权衡。", "innovation": "我们提出了Soft-Mask Weight Fine-Tuning (SWiFT)，一种高效改进公平性同时保持鉴别性能的去偏框架。SWiFT只需要少量的外部数据集和少量的模型微调周期，就能实现这一目标。SWiFT的核心思想是首先确定模型参数对偏差和预测性能的相对但独特的贡献。然后，通过由其贡献定义的不同梯度流更新每个参数。我们使用三种敏感属性（性别、肤色和年龄）跨四个皮肤科和两个胸部X光数据集进行的广泛实验表明，SWiFT能够在常见的公平性和准确性度量标准下，一致地减少模型偏差，并且实现可比甚至更优的诊断准确性。特别是在多个分布外（OOD）数据集上的性能表明模型具有更好的泛化能力。", "conclusion": "SWiFT有效地减少了模型偏差，同时保持了相同的或更高的诊断准确性，并且只需要少量的微调周期和数据。与现有最先进的方法相比，SWiFT在公平性和准确性度量标准下表现出一致的性能改进，并且具有更强的模型泛化能力。"}
{"llm_update_time": "20250907", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.03594", "html_url": "https://arxiv.org/abs/2509.03594", "title": "隐藏在明处的优化器：使用损失景观诱导度量进行训练", "title_en": "The Optimiser Hidden in Plain Sight: Training with the Loss Landscape's Induced Metric", "authors": "Thomas R. Harvey", "background": "该研究论文基于在高维空间中嵌入损失场景时自然诱导的黎曼度量提出了一类新型的优化器。这种度量与常见的损失场景可视化基础相同。通过严肃地采用这种几何视角并使用诱导度量，开发出了一种新的优化器，并将其与现有的方法（如：SGD、Adam、AdamW、Muon）在多种任务和架构上进行了比较。", "innovation": "创新在于提出了一类新的基于黎曼度量的优化器，通过这种方式能够自动减少高曲率区域的学习率，提供了一个平滑形式的梯度裁剪，还可以使学习率更具计划性，并且天然的选择是解耦的权重衰减。此基本方法可以修改任何现有的预训练方法。新优化器的计算复杂度与Adam相当。", "conclusion": "实验结果表明，这种新提出的优化器在低维度情况下效果显著，并在训练神经网络方面略优于最先进的方法。因此，这些优化器具有理论上的吸引力。"}
{"llm_update_time": "20250907", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.03660", "html_url": "https://arxiv.org/abs/2509.03660", "title": "基于客户可用性预算的半去中心化联邦时间序列预测", "title_en": "Semi-decentralized Federated Time Series Prediction with Client Availability Budgets", "authors": "Yunkai Bao,Reza Safarzadeh,Xin Wang,Steve Drew", "background": "联邦学习（FL）能够促进物联网（IoT）场景中分布式客户端的协作训练并考虑隐私保护。尽管不同客户端的数据异质性较大，但它们在能量和可用性预算上也有限制。因此，有效选择参与训练的客户端对于全球模型的收敛性和客户端贡献的平衡至关重要。本文探讨了时间序列数据的客户可用性如何影响联邦学习的性能，并提出了FedDeCAB这一新的半去中心化客户端选择方法，该方法基于可用客户概率排名。当客户端与服务器断开连接时，FedDeCAB允许从最近的可用客户端获取部分模型参数进行联合优化，从而提高模型性能并减少通信开销。", "innovation": "提出了FedDeCAB，这是一种半去中心化的客户端选择方法，使用可用客户概率排名。当客户端与服务器断开连接时，方法允许从最近的可用客户获取部分模型参数进行优化，提高模型性能并减少通信开销。", "conclusion": "基于真实世界的大规模出租车和船舶轨迹数据集的实验表明，FedDeCAB在高度异质性数据分布、有限的通信预算和动态客户端断开连接或重新加入的情况下是有效的。"}
{"llm_update_time": "20250907", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.02591", "html_url": "https://arxiv.org/abs/2509.02591", "title": "2025 MIDOG 轨道 2 中病理基础模型的集成用于非典型分裂分类", "title_en": "Ensemble of Pathology Foundation Models for MIDOG 2025 Track 2: Atypical Mitosis Classification", "authors": "Mieko Ochi,Bae Yuan", "background": "核分裂像根据典型和非典型变异进行分类，非典型变异数量与肿瘤侵略性密切相关。准确的鉴别对于患者的预后判断和资源分配至关重要，但对于即使是专家病理学家来说这也是一个挑战。因此，本文利用了预训练在大规模病理图像数据集上的病理基础模型（PFMs），通过低秩适应进行参数高效微调，并结合了当前最先进的一种卷积神经网络架构——ConvNeXt V2。此外，在训练过程中应用了鱼眼变换以强调核分裂，并使用 ImageNet 目标图像的频域适应。最后，通过集成多个 PFMs 来整合互补的形态学见解，以实现对Preliminary Evaluation Phase数据集具有竞争力的均衡准确性。", "innovation": "本文的新颖之处在于使用预训练的病理基础模型（PFMs）进行参数高效的微调，引入了先进的 ConvNeXt V2 架构，应用了鱼眼变换和频域适应，以及多 PFMs 的集成以补充多方面的形态学信息。", "conclusion": "本文采用的方法，在 Preliminary Evaluation Phase 数据集上实现了具有竞争力的均衡准确性，表明这种方法在非典型分裂分类中的有效性。"}
{"llm_update_time": "20250907", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.03672", "html_url": "https://arxiv.org/abs/2509.03672", "title": "SharedRep-RLHF: A Shared Representation Approach to RLHF with Diverse Preferences", "title_en": "SharedRep-RLHF: A Shared Representation Approach to RLHF with Diverse Preferences", "authors": "Arpan Mukherjee,Marcello Bullo,Deniz Gündüz", "background": "现有的均匀奖励强化学习从人类反馈（RLHF）方法虽然能用单一奖励模型来反映所有注释者的偏好，但无法捕捉不同子群体之间的意见多样性，可能会无意中偏袒主导群体。因此，最先进的MaxMin-RLHF尝试通过学习每个子群体的特定奖励模型，并优化最低奖励群体，来促进公平性。然而，MaxMin-RLHF在最低奖励群体是少数群体时表现较差。", "innovation": "本文提出了一种新的方法，称为SharedRep-RLHF，它通过学习和利用各群体注释之间的共同特质，而不是为每个群体分别学习奖励模型来克服MaxMin-RLHF的限制。SharedRep-RLHF首先证明了MaxMin-RLHF在学习共同特质方面是无可证明地次优的，并且量化了SharedRep-RLHF的样本复杂性。", "conclusion": "在不同自然语言任务上的实验表明，与MaxMin-RLHF相比，SharedRep-RLHF在胜率上能提升最高达20%。"}
{"llm_update_time": "20250907", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2405.11491", "html_url": "https://arxiv.org/abs/2405.11491", "title": "BOSC：基于后门的开放集合成图像归因框架", "title_en": "BOSC: A Backdoor-based Framework for Open Set Synthetic Image Attribution", "authors": "Jun Wang,Benedetta Tondi,Mauro Barni", "background": "合成图像归因是追踪由生成模型生成图像的起源的问题。已有大量研究致力于探索生成模型的独特表示，并利用这些独特性将合成图像归因到生成它的模型。大多数方法在封闭集场景中分类模型或架构，但没有考虑到系统可能使用未知架构生成的样本。随着AI技术的不断进步，新的生成架构不断出现，研究人员逐渐转向开发能够在开放集场景中工作的工具。", "innovation": "本文提出了一种基于后门攻击的开放集场景下的合成图像归因框架，命名为BOSC。该框架通过在训练集的一部分图像中故意注入类别特定的触发器，诱导网络建立类别特征与触发器特征之间的匹配。在测试时，利用受触发的样本训练模型的行为实现样本拒绝，并使用特定的评分方法进行实验，表明该方法具有良好的性能和很强的图像处理鲁棒性。", "conclusion": "BOSC方法在合成图像归因任务中表现优异，总能超越当前最先进的方法。与此同时，该框架具有很强的鲁棒性，可以用于其他图像取证应用。"}
{"llm_update_time": "20250907", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.22832", "html_url": "https://arxiv.org/abs/2507.22832", "title": "揭秘ReLU网络", "title_en": "Pulling Back the Curtain on ReLU Networks", "authors": "Maciej Satkiewicz", "background": "任何ReLU网络都是分段线性的，隐藏单元可以通过其对主动子网络的拉回表示，即通过其梯度（带偏置项）。然而，深层神经元的梯度往往方向不对，掩盖了网络的内部表示。研究表明，模型可以对梯度和数据进行对齐，但这一对齐被ReLU硬门控的固有噪声所掩盖。通过仅将软门控应用于反向传播过程中，减少弱激活神经元的局部影响，研究发现，修正后的梯度（称为“激活拉回”）在多种预训练的ImageNet架构上显示出显著的感知对齐效果，而简单的像素空间梯度上升则快速生成可解释的输入和目标特定特征。这些结果启发了‘路径稳定性’假说，认为二元激活模式在训练过程中相对稳定，并在最终模型的预激活分布中编码。当这一假说为真时，激活拉回将会与主要决定网络决策的核机的梯度对齐，这为基于这些拉回进行特征归因的可信度提供了理论依据，甚至可能促进深层模型的机械可解释性。顺便说一句，研究还提供了解释批量标准化和深层特征有效性的可能原因，以及网络内部记忆和泛化特性的新视角。我们发布了代码和一个交互式应用程序，以更方便地探索激活拉回。", "innovation": "提出了仅在反向传播过程中使用软门控的方法，减少弱激活神经元的影响，生成了修正后的梯度（称为“激活拉回”），这些梯度在多种预训练的ImageNet架构上显示出显著的感知对齐效果。基于这些结果，提出了“路径稳定性”假说，认为二元激活模式在训练过程中相对稳定。这为基于激活拉回进行特征归因的可信度提供了理论依据，甚至可能促进深层模型的机械可解释性。此外，还解释了批量标准化和深层特征的有效性，并提供了一个新的视角来理解网络的内部记忆和泛化特性。", "conclusion": "“激活拉回”不仅显示出显著的感知对齐效果，还为基于这些拉回的特征归因提供了可信度的理论依据，并可能推动了深层模型的机械可解释性。此外，研究还揭示了批量标准化和深层特征有效性的潜在原因，并为网络的内部记忆和泛化特性提供了一个新的视角。"}
{"llm_update_time": "20250907", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.03673", "html_url": "https://arxiv.org/abs/2509.03673", "title": "基于机器学习的经济视角下供应链管理与金融服务链协同优化研究", "title_en": "A Machine Learning-Based Study on the Synergistic Optimization of Supply Chain Management and Financial Supply Chains from an Economic Perspective", "authors": "Hang Wang,Huijie Tang,Ningai Leng,Zhoufan Yu", "background": "本文基于经济理论并结合机器学习技术，探讨了一种协作型供应链管理与金融服务链管理（SCM-FSCM）模型，以解决效率损失、融资约束和风险传递等问题。研究结合了交易成本和信息不对称理论，并通过随机森林等算法处理多维数据，构建了以成本效率风险为三维维度的数据驱动分析框架。", "innovation": "本文将Game Theory和强化学习应用于库存采购机制的优化，并使用极端梯度提升（XGBoost）进行信用评估，使库存可以快速变现。论文提出了一种“核心企业信用赋能加动态质押融资”的FSCM模型，并使用长短期记忆（LSTM）网络进行需求预测，以及聚类/回归算法进行收益分配。", "conclusion": "研究结果表明，该模型使库存周转率提高了30%，中小企业融资成本降低了18%-22%，订单完成率稳定在95%以上，模型性能表现出色（需求预测误差≤8%，信用评估准确率≥90%）。该SCM-FSCM模型有效降低了运营成本、缓解了融资约束，支持高质量的供应链发展。"}
{"llm_update_time": "20250907", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.03652", "html_url": "https://arxiv.org/abs/2509.03652", "title": "非负矩阵分解与共同因果原则", "title_en": "Nonnegative matrix factorization and the principle of the common cause", "authors": "E. Khalafyan,A. E. Allahverdyan,A. Hovhannisyan", "background": "非负矩阵分解（NMF）是一种已知的无监督数据降维方法。共同因果原则（PCC）是概率因果关系中的基本方法论方法，旨在为两个相关随机变量的联合概率提供一个独立混合模型。研究发现这两种概念之间有着密切的关系。", "innovation": "1. PCC提供了一种预测工具，有助于稳定估计NMF的有效秩，与基于贝叶斯信息准则的估计相比，其稳定性能更好，能够抵御弱噪声。2. 在这种秩的基础上实施NMF，可以产生既稳定又能够抵御噪声和局部优化种子影响的特征（基础图像），从而有效解决了NMF的非识别性问题。3. NMF为PCC的近似实现提供了可能性，在这种模型中，更大的正相关联合概率更有可能通过独立混合模型来解释。4. 研究提出了一种聚类方法，能够将具有相同共同原因的数据点分组到同一个簇中，并展示了如何利用NMF进行数据去噪。", "conclusion": "本文发现NMF和PCC之间存在密切联系，并利用这一发现改进了NMF的应用，通过稳定估计NMF的有效秩来解决非识别性问题，并提出了一种聚类方法和数据去噪的方法。"}
{"llm_update_time": "20250907", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.03677", "html_url": "https://arxiv.org/abs/2509.03677", "title": "从梯度动力学中获得的见解：梯度自动缩放归一化", "title_en": "Insights from Gradient Dynamics: Gradient Autoscaled Normalization", "authors": "Vincent-Daniel Yun", "background": "梯度动态在决定深度神经网络的稳定性和泛化能力方面起着核心作用。本文通过对卷积网络中梯度方差和标准差在训练过程中变化的实证分析，展示了层间和全局尺度上的一致变化。基于这些观察结果，提出了一个不需要超参数的梯度归一化方法，该方法使梯度缩放与自然演变保持一致，防止不必要的放大，稳定优化，并保留收敛保证。", "innovation": "提出了一种无需超参数的梯度归一化方法，该方法使梯度缩放与自然演变保持一致，防止不必要的放大，稳定优化，并保留收敛保证。该方法在具有挑战性的CIFAR-100基准上的ResNet-20、ResNet-56和VGG-16-BN实验中显示出其维持或提高测试准确性的能力，即使在强泛化情况下也是如此。该研究还强调了跟踪梯度动态的重要性，旨在弥合理论期望与实际行为之间的差距，并为未来的优化研究提供见解。", "conclusion": "实验证明，该方法在CIFAR-100上的ResNet-20、ResNet-56和VGG-16-BN上的测试精度保持或提高。该研究还表明追踪梯度动态的重要性，为优化研究提供了新的见解，桥梁理论期望和实际行为的差距。"}
{"llm_update_time": "20250907", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.03666", "html_url": "https://arxiv.org/abs/2509.03666", "title": "AutoGrid AI: 基于深度强化学习的自主微电网管理框架", "title_en": "AutoGrid AI: Deep Reinforcement Learning Framework for Autonomous Microgrid Management", "authors": "Kenny Guo,Nicholas Eckhert,Krish Chhajer,Luthira Abeykoon,Lorne Schell", "background": "随着可再生能源的普及，微电网成为越来越多偏远社区理想的选择。然而，如何高效管理和调度微电网中的能源尤其是可再生能源，如太阳能和风能，成为了研究的重点。传统的基于规则的方法在灵活性和适应性方面显得不足，因此需要一种新的方法来优化微电网的能源调度策略，以提高能源效率和运营韧性。我们提出了一种基于深度强化学习的框架来解决这一问题，旨在为偏远社区提供高效的微电网管理解决方案。", "innovation": "我们的创新在于将变压器架构用于可再生能源发电的时间序列预测，并使用近端策略优化（PPO）代理在模拟环境中做出决策。这不仅提高了微电网管理的效率和适应性，还展示了在与传统规则基础方法相比时，显着改进的能量效率和运营韧性。此外，该方法为我们研究零碳能源系统提供了技术支持，并推动了智能电网技术的发展。", "conclusion": "实验结果表明，与传统的规则基础方法相比，我们的方法在能源效率和运营韧性方面表现出色。最后，我们提供了一个开源框架，用于模拟几种微电网环境，促使更多的研究人员和开发者参与到微电网技术的研究和应用中来。"}
{"llm_update_time": "20250907", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.03691", "html_url": "https://arxiv.org/abs/2509.03691", "title": "图随机特征应用于大规模可扩展的高斯过程", "title_en": "Graph Random Features for Scalable Gaussian Processes", "authors": "Matthew Zhang,Jihao Andreas Lin,Adrian Weller,Richard E. Turner,Isaac Reid", "background": "文章研究了图随机特征（GRFs）在离散输入空间中的应用，GRFs是一种最近引入的图节点核的概率估计方法。已有研究表明，精确内核需花费$O(N^3)$时间复杂度，而使用GRFs可以在满足轻微假设的情况下获得$O(N^{3/2})$的时间复杂度。", "innovation": "文章证明了使用图随机特征进行贝叶斯推断的Wall-clock速度显著提升，节省了大量内存空间，使得在单个计算机芯片上可以进行包含超过100万节点的图的贝叶斯优化，同时保持了竞争力。", "conclusion": "通过将图随机特征应用到高斯过程，该研究大大提升了计算效率，使得大规模图上的贝叶斯优化成为可能。"}
{"llm_update_time": "20250907", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.03643", "html_url": "https://arxiv.org/abs/2509.03643", "title": "CEHR-GPT：电子健康记录的可扩展多任务基础模型", "title_en": "CEHR-GPT: A Scalable Multi-Task Foundation Model for Electronic Health Records", "authors": "Chao Pang,Jiheum Park,Xinzhuo Jiang,Nishanth Parameshwar Pavinkurve,Krishna S. Kalluri,Shalmali Joshi,Noémie Elhadad,Karthik Natarajan", "background": "电子健康记录（EHRs）提供患者健康状况的详细、长期视角，对临床决策支持、风险预测以及数据驱动型医疗研究有很大的潜力。然而，大多数针对EHRs的人工智能（AI）模型只为特定单一任务设计，这限制了它们在实际应用中的泛化能力和实用性。因此，需要一种能够统一处理EHR数据特征表示、零样本预测和合成数据生成的通用模型，以支持临床序列的时序推理。", "innovation": "CEHR-GPT提出了一个通用的基础模型，整合了特征表示、零样本预测和合成数据生成这三项关键能力，并通过引入一种新的基于时间标记的学习框架，直接将患者的动态时间线编码到模型结构中，以支持时序推理。CEHR-GPT在所有三个任务中表现出色，并通过词汇扩展和微调，有效推广到外部数据集。该模型的适用性允许快速模型开发、群体发现和患者结果预测，而无需针对特定任务重新训练。", "conclusion": "CEHR-GPT是一种通用的EHR数据基础模型，能够有效处理特征表示、零样本预测和合成数据生成。通过引入基于时间标记的学习框架，CEHR-GPT支持临床序列的时序推理，并展现出在所有任务中的强大表现和外部数据集上的有效推广能力。这模型的应用将促进快速的模型开发和例如患者结果预测等应用，而无需对特定任务进行重新训练。"}
{"llm_update_time": "20250907", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.03709", "html_url": "https://arxiv.org/abs/2509.03709", "title": "从联邦学习到$\boldsymbol{\text{X}}$学习：通过随机游走打破去中心化壁垒", "title_en": "From Federated Learning to $\\mathbb{X}$-Learning: Breaking the Barriers of Decentrality Through Random Walks", "authors": "Allan Salihovic,Payam Abdisarabshali,Michael Langberg,Seyyedali Hosseinalipour", "background": "文章背景介绍联邦学习的概念及其局限性。联邦学习是一种分布式学习架构，但它存在一定的去中心化障碍。文章旨在提出$\boldsymbol{\text{X}}$学习($\boldsymbol{\text{X}}$L)架构，这是一种推广和扩展去中心化概念的新颖分布式学习架构，通过随机游走的概念进一步打破这些障碍。", "innovation": "文章主要创新点在于提出了$\boldsymbol{\text{X}}$学习($\boldsymbol{\text{X}}$L)架构。该架构利用随机游走的方法来连接$\boldsymbol{\text{X}}$L、图论和马尔可夫链，提出了新的设计理念和自由度，为后续研究提供了多条开放方向。", "conclusion": "文章的结论是，$\boldsymbol{\text{X}}$学习架构提供了一种新的视角，以解决去中心化带来的挑战，通过引入随机游走的概念，探索了新的研究方向，为未来的研究指明了路径。"}
{"llm_update_time": "20250907", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.03682", "html_url": "https://arxiv.org/abs/2509.03682", "title": "视频游戏中多智能体强化学习的全面回顾", "title_en": "A Comprehensive Review of Multi-Agent Reinforcement Learning in Video Games", "authors": "Zhengyang Li,Qijin Ji,Xinghong Ling,Quan Liu", "background": "多智能体强化学习（MARL）在现代游戏中的应用潜力已在近期得到证实。自基础工作到如AlphaStar在《星际争霸II》和OpenAI Five在《英雄联盟》中的里程碑成就，MARL通过自博弈、监督学习、深度强化学习等技术证明了其在多种游戏环境中的超凡表现。由于其影响不断扩大，该领域全面评审的需求日益增加。", "innovation": "本文提供了从回合制两智能体游戏到实时多人游戏，包括体育游戏、第一人称射击游戏、即时战略游戏和多人在线战斗 arena 游戏的全面分析。进一步探讨了MARL在视频游戏中面临的挑战，包括非平稳性、部分可观性、稀疏奖励、团队协调以及可扩展性，并指出在如《火箭联盟》、Minecraft、《雷神之锤III竞技场》、《星际争霸II》、《英雄联盟》、《王者荣耀》等游戏中的成功实施案例。本文提出了一个评估游戏复杂性的新型方法，并为MARL及其在游戏开发中的应用指明了未来研究方向，鼓励该领域持续创新。", "conclusion": "本文总结了MARL在视频游戏AI系统中的洞察，提出了一个新颖的游戏复杂性估计方法，并指出了未来研究方向，以推动MARL及其在游戏开发中的应用。"}
{"llm_update_time": "20250907", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.03733", "html_url": "https://arxiv.org/abs/2509.03733", "title": "不同iable熵正则化在几何和神经网络中的应用", "title_en": "Differentiable Entropy Regularization for Geometry and Neural Networks", "authors": "Ibne Farabi Shihab,Sanjeda Akter,Anuj Sharma", "background": "范围分区熵是一种最近来自计算几何的概念，它允许算法适应其输入的‘排序性’。尽管范围分区熵在算法设计中提供了强有力的保障，但迄今为止尚未被深度学习所应用。", "innovation": "本文首先提出了第一个可微范围分区熵的近似值，使其能够作为可训练损失或正则化器使用。设计了一种名为EntropyNet的神经模块，通过将数据重新组织成低熵形式来加速下游的实例最优算法。此外，还直接将熵正则化应用于Transformer注意力机制，超越了几何学。", "conclusion": "在不同任务中，该方法展示了在不降低准确性的情况下提高效率的能力：在几何任务中，实现了高达4.1倍的运行时加速，误差几乎可以忽略（<0.2%）；在深度学习中，熵正则化诱导了80%稀疏性下比L1基线更高的6%准确性。理论分析提供了估计器的逼近界，详尽的消融实验验证了设计选择的有效性。这些结果表明，熵约束计算不仅在理论上优雅，而且是一种适应性学习、高效性和结构化表示的实用机制。"}
{"llm_update_time": "20250907", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.03695", "html_url": "https://arxiv.org/abs/2509.03695", "title": "无线网络环境下跨模态多任务智能的分层联邦基础模型：边缘学习与D2D/P2P增强的雾学习架构集成", "title_en": "Hierarchical Federated Foundation Models over Wireless Networks for Multi-Modal Multi-Task Intelligence: Integration of Edge Learning with D2D/P2P-Enabled Fog Learning Architectures", "authors": "Payam Abdisarabshali,Fardis Nadimi,Kasra Borazjani,Naji Khosravan,Minghui Liwang,Wei Ni,Dusit Niyato,Michael Langberg,Seyyedali Hosseinalipour", "background": "基础模型（FMs）的发展重塑了机器学习的格局。随着这些模型逐渐扩大，利用无线设备的地理分布式数据变得越来越重要，从而产生了联邦基础模型（FFMs）。最近，FMs 进化成多模态多任务（M3T）FMs（如GPT-4），能够处理多种任务中的不同模态，这种演进促进了分层联邦多模态多任务模型（HF-FMs）这一未曾深入探索的新范式的提出。", "innovation": "1. 提出了一种未探索的M3T FFMs变体——分层联邦基础模型（HF-FMs），它可以将M3T FMs模块化的结构与雾/边缘基础设施的分层特性相结合。\n2. HF-FMs使设备间通信（D2D）成为可选使用，通过减少节点之间的通信开销和促进局部协同训练，来优化模型性能和能效。\n3. 展示了通过在无线网络中实现HF-FMs，以及开源项目的推出，为促进该领域探索所做的努力。", "conclusion": "通过深入分析HF-FMs的架构设计，作者强调了其独特的功能，并指出了若干定制化的未来研究方向。最终，通过将HF-FMs原型化并在无线网络环境中展示，作者旨在推动这一尚待开发领域的进一步研究，并向GitHub开源代码库开放使用。"}
{"llm_update_time": "20250907", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.03749", "html_url": "https://arxiv.org/abs/2509.03749", "title": "节约成本的地图绘制：优化空间数据收集以进行机器学习", "title_en": "Mapping on a Budget: Optimizing Spatial Data Collection for ML", "authors": "Livia Betti,Farooq Sanni,Gnouyaro Sogoyou,Togbe Agbagla,Cullen Molitor,Tamma Carleton,Esther Rolf", "background": "在农业、生态学和人类发展等多个领域的应用中，使用卫星影像进行机器学习（SatML）受到标注训练数据稀少的限制。尽管卫星影像覆盖全球，但是标注的数据集往往规模较小、空间分布集中且收集目的是其他方面（如行政调查或实地测量）。尽管在实践中普遍存在此问题，过去的研究主要集中在新模型架构和训练算法上，以解决数据稀缺性问题，而忽略了直接建模数据条件，科学家和政策制定者在使用SatML进行大规模监测时，不确定是否和如何收集额外的数据来最大化性能。", "innovation": "本文首次提出一种优化空间训练数据的问题形式，考虑了异质性数据收集成本和现实预算限制。引入了新的方法来解决这一问题，通过模拟三大洲、四个任务的不同问题设置，实验结果显示了优化采样带来的显著收益。进一步的实验还界定了优化采样特别有效的设置。我们提出的问题形式和方法旨在泛化到SatML的应用领域；特别强调了一个研究领域，其中我们的合著者可以立即利用研究结果来增强Togo的聚集农业调查，以增强SatML监测。", "conclusion": "本研究通过优化收集的空间数据，在预算成本考虑下显著提升了机器学习模型在SatML中的性能，并为科学家和政策制定者提供了实际可行的策略，特别是在农业监测领域。"}
{"llm_update_time": "20250907", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.03703", "html_url": "https://arxiv.org/abs/2509.03703", "title": "EmbedOR: 依靠曲率导向的随机邻居嵌入进行可证明的簇保留可视化", "title_en": "EmbedOR: Provable Cluster-Preserving Visualizations with Curvature-Based Stochastic Neighbor Embeddings", "authors": "Tristan Luca Saidi,Abigail Hickok,Bastian Rieck,Andrew J. Blumberg", "background": "标准的随机邻居嵌入（SNE）算法，如UMAP和tSNE，由于数据噪声和高维性的存在，在生成可视化时往往无法准确保留原始数据的几何结构。特别是，这些算法可能出现错误的将数据子流形的连接组件分隔开，或者在易于聚类的数据中无法找到聚类。由此带来的问题成为基于SNE算法的数据可视化的一个重要挑战，需要一个新的算法改进这一情况，确保在保留在处理这类数据时能更好地保留原始几何结构并通过可视化更好地展现数据的内在结构、支持用户更好的理解和浏览高维数据空间", "innovation": "提出了EmbedOR算法，该算法结合了基于离散图曲率的随机嵌入技术，从而增强了算法保留数据原始几何结构和聚类结构的能力。EmbedOR算法通过增强以曲率表示的距离度量来随机地嵌入数据，特别值得注意的是，作者形式证明了EmbedOR距离度量扩展了tSNE的一致性结果至更广泛的数据集类别。算法还能分割那些不正确分隔的数据流形区域，具备优于UMAP和其他SNE算法的视觉呈现能力", "conclusion": "通过广泛的实验证明，与现有的SNE算法以及UMAP相比，EmbedOR在处理连续、高密度区域时，能够显著减少不正确分割的情况。此外，该论文还展示，EmbedOR距离度量可以作为一种工具，用于标记现有可视化，特别是识别分割问题并深挖潜在几何结构。这一创新的可视化算法为我们更好地理解高维数据和增强数据可视化技术提供了一种新的视角"}
{"llm_update_time": "20250907", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.03707", "html_url": "https://arxiv.org/abs/2509.03707", "title": "在线学习最佳顺序测试策略", "title_en": "Online Learning of Optimal Sequential Testing Policies", "authors": "Qiyuan Chen,Raed Al Kontar", "background": "该论文研究在线学习问题，尤其是在数据不完整的情况下，如何为一群受试者制定最优测试策略。传统的完全测试策略虽然提供更多信息，但在测试成本高且测试之间相关的情况下，选择一个子集的测试并基于部分信息做出决策通常更为优选。研究的关键在于样本空间的联合分布未知，必须通过逐步测试来进行在线学习。不完全测试会导致数据丢失，从而可能引起偏差，使问题比标准的递增马尔可夫决策过程更加复杂。\n", "innovation": "研究首次证明了最小化遗憾法则至少需要 $T^{\frac{2}{3}}$ 的级别，这与标准的递增马尔可夫决策过程中 $\theta(\text{sqrt}(T))$ 的遗憾法则有所不同。这种更高的下界通过一种探索-然后-承诺算法 $T^{\frac{2}{3}}$ 级别的累计遗憾法则被匹配。对一个变种问题 —— 在线成本敏感最大熵抽样问题，奖励与丢失的数据独立，算法通过迭代消除法获得了 $\tilde{O}(\text{sqrt}(T))$ 的累计遗憾法则，打破了 $T^{\frac{2}{3}}$ 问题的基本界限。论文证明了在存在缺失数据的情况下，探索-利用权衡问题的结果，并为设计高效序列测试策略提供了指导。\n", "conclusion": "该研究深入探索了在数据丢失的情况下，探索-利用权衡的难题，并通过理论分析证明了一种新的学习算法的有效性。这些发现为在线学习和优化测试策略的设计提供了新的见解，丰富了相关领域的研究。\n"}
{"llm_update_time": "20250907", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.03758", "html_url": "https://arxiv.org/abs/2509.03758", "title": "通过扩散映射学习函数", "title_en": "Learning functions through Diffusion Maps", "authors": "Alvaro Almeida Gomez", "background": "该研究提出了一个基于数据驱动的方法，用于在光滑流形上逼近实值函数。该方法以流形假设为背景，在扩散映射框架下进行开发。给定点值函数的评估，该方法通过利用扩散几何及其与热方程和拉普拉斯-贝尔特拉米算子的联系，构建一个光滑的扩展到所在空间的方法。为应对高维数据的计算挑战，研究引入了基于距离矩阵低秩结构的降维策略，通过奇异值分解(SVD)来实现。此外，开发了一种在线更新机制，能够有效地整合新数据，从而提高可扩展性并降低计算成本。", "innovation": "提出了一个基于扩散映射的数据驱动方法，用于在光滑流形上逼近实值函数；通过引入基于距离矩阵低秩结构的降维策略；开发了一种在线更新机制，提高了方法的可扩展性和效率；通过数值实验验证了该方法在准确性与效率上的优越表现。", "conclusion": "所提出的方法不仅在准确性上超越了传统的前馈神经网络和插值方法，还在效率上表现优异。"}
{"llm_update_time": "20250907", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.03790", "html_url": "https://arxiv.org/abs/2509.03790", "title": "何种奖励函数的基本结构能够实现高效的稀疏奖励强化学习？", "title_en": "What Fundamental Structure in Reward Functions Enables Efficient Sparse-Reward Learning?", "authors": "Ibne Farabi Shihab,Sanjeda Akter,Anuj Sharma", "background": "研究探讨了奖励函数的基本属性如何能够使稀疏奖励强化学习更加高效。通过对奖励矩阵低秩结构的分析，研究表明这种结构可以引起样本复杂性从指数级过渡到多项式级，这是稀疏奖励RL的首个此类结果。", "innovation": "提出了Policy-Aware Matrix Completion (PAMC)框架，该框架将矩阵完成理论与强化学习相结合，通过新的策略依赖采样分析进行连接。该框架提供了以下内容：(i) 对一般稀疏奖励观测的不可实现结果，(ii) 从动力学学习无奖励表示，(iii) 分布无关置信集通过符合预测获得，(iv) 适应低秩结构近似提供的鲁棒完成保证。", "conclusion": "在系统的100个领域进行的预注册评估中，发现超过一半包含可利用结构。对比强大探索、结构化和表示学习基线，PAMC提高了样本效率1.6到2.1倍，且仅增加了约20%的计算成本。这些结果表明结构化奖励学习是一个有潜力的新范式，并立即对机器人技术、医疗保健及其他样本昂贵的应用产生影响。"}
{"llm_update_time": "20250907", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.03738", "html_url": "https://arxiv.org/abs/2509.03738", "title": "稀疏自编码器神经算子：函数空间中的模型恢复", "title_en": "Sparse Autoencoder Neural Operators: Model Recovery in Function Spaces", "authors": "Bahareh Tolooshams,Ailsa Shen,Anima Anandkumar", "background": "尽管Platonic Representation假设表明神经网络在不同架构中收敛到相似的表示，但神经算子（神经模型的一种）在表示特性方面的研究仍然较少，尽管它们在科学计算中的重要性日益增长。研究者们将神经模型中统合表示的问题，重新表述为稀疏模型恢复问题，并引入了将稀疏自编码器（SAEs）扩展到提升空间和无限维函数空间的框架，以提供大型神经算子（NO）的机械可解释性。", "innovation": "研究人员提出了一种新的框架，将其扩展到提升空间和无限维函数空间，将稀疏自编码器（SAEs）引入到神经算子中，从而增强模型的机械可解释性。该研究对比了SAEs、提升的SAEs和神经算子的推理和训练动态，展示了提升和操作模块引入了有益的归纳偏置，能够加速恢复、提高平滑概念的恢复效率，并在不同的分辨率下实现稳健的推理，这是神经算子特有的一个特性。", "conclusion": "研究展示了如何通过引入提升自编码器（lifted-SAE）和神经算子，增强模型的机械可解释性和性能。此外，还揭示了提升和操作模块的独特优势，这些优势在传统稀疏自编码器中是不存在的，这对于理解神经算子在科学计算中的应用具有重要价值。"}
{"llm_update_time": "20250907", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.03810", "html_url": "https://arxiv.org/abs/2509.03810", "title": "基于特征调整的在线时间序列预测", "title_en": "Online time series prediction using feature adjustment", "authors": "Xiannan Huang,Shuhan Qiu,Jiayuan Du,Chao Yang", "background": "时间序列预测在各个领域都具有显著的重要性，但面临由于数据分布变化带来的挑战。特别是在线部署场景中，数据按顺序到达，要求模型能够持续适应不断变化的模式。当前的在线学习方法主要集中在两个方面：选择合适的参数进行更新（如最终层权重或适配模块）和设计合适的更新策略（如使用最近批次、重放缓存或平均梯度）。", "innovation": "本文提出了ADAPT-Z（通过持续追踪Z空间中的自动Delta调整）方法，挑战传统的参数选择方法，认为分布变化源自影响数据的基本潜在因素的变化。因此，更新这些潜在因素的特征表示可能会更有效。ADAPT-Z利用适配模块结合当前特征表示历史梯度信息来实现尽管有延迟反馈的稳健参数更新。", "conclusion": "通过对多种数据集的大量实验表明，本文的方法相较于标准基线模型和最先进的在线学习方法总体表现更优。代码已开源。"}
{"llm_update_time": "20250907", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.03834", "html_url": "https://arxiv.org/abs/2509.03834", "title": "从莱登到快乐岛：常数品特模型作为一种hedonic博弈的社区检测", "title_en": "From Leiden to Pleasure Island: The Constant Potts Model for Community Detection as a Hedonic Game", "authors": "Lucas Lopes Felipe,Konstantin Avrachenkov,Daniel Sadoc Menasche", "background": "分区节点到不交社区是数据科学中的一个基本问题，常数品特模型（CPM）提供了一种分解全局哈密顿量的方法，转化为局部效用函数，使个体优化局部效用也能最大化全局效用。", "innovation": "1. 引入了hedonic博弈的新视角，将CPM重新解释为潜在的对策性游戏，证明了通过更好的反应动态进行局部优化可以在伪多项式时间内收敛到一个均衡划分。\n2. 引入和关联了两种稳定性标准：一种基于一种新的稳健性概念的严格标准，要求节点在社区内同时最大化邻居并最小化非邻居；另一种是基于这些目标的加权和的松弛效用函数，由一个分辨率参数控制。", "conclusion": "在社区跟踪场景中，使用初始分区来引导具有部分真实信息的莱登算法，实验表明，稳健分区能更准确地恢复真实社区。"}
{"llm_update_time": "20250907", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.03771", "html_url": "https://arxiv.org/abs/2509.03771", "title": "学习对抗世界模型以在多智能体强化学习中自动生成课程", "title_en": "Learning an Adversarial World Model for Automated Curriculum Generation in MARL", "authors": "Brennen Hill", "background": "拥有推断和预测环境动态的能力的世界模型对于实现具身智能至关重要。然而，它们经常受限于人工设计的训练环境的有限复杂性和隐性偏见。为了开发出真正通用且鲁棒的代理，需要能够与学习的代理一同扩展复杂性的环境。本文将环境生成重新表述为学习目标指导的生成世界模型的问题。通过这种创造性方法，在一个团队的协同防御者代理面前建立一个对抗性的生成攻击者代理，使其学习隐式世界模型来合成越来越困难的挑战。对抗性代理的目的是主动、目标驱动地互动：它建模并生成世界状态（即敌军单位的配置），以利用防御者的弱点。同时，具身的防御者团队在这些生成的世界中学习一个协同策略来克服这些挑战。这种共生演化动态创建了一种自我扩展的教学大纲，其中世界模型不断地适应挑战代理决策策略，从而提供了一个无限的新型且相关训练场景流。", "innovation": "本文提出了一种通过对抗性演化生成目标指导的生成世界模型的方法。该系统通过一种新颖的方式，攻击者代理主动学习隐式世界模型来生成复杂挑战，而防守者代理则学习应对这些生成的世界以克服这些挑战。这种共生演化动态不仅提供了有效无限的新型且相关训练场景流，还让防御者学会复杂的协同策略，如集火攻击和分散战术，以及进攻者学会了生成侧翼和保护阵型等复杂行为。这一框架揭示了对抗性共生演化作为推动代理实现更具战略深度和鲁棒性的有力方法的基础。", "conclusion": "我们展示了对抗性共生演化可以导致复杂行为的出现，例如世界模型学会了生成侧翼和保护阵型，而防守者也学会了集火和分散的战术。我们的研究得出对抗性共生演化是一种有效方法，有助于提升代理层面上的战略深度和鲁棒性。"}
{"llm_update_time": "20250907", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.03852", "html_url": "https://arxiv.org/abs/2509.03852", "title": "MillGNN：学习多尺度领先-滞后依赖关系以进行多变量时间序列预测", "title_en": "MillGNN: Learning Multi-Scale Lead-Lag Dependencies for Multi-Variate Time Series Forecasting", "authors": "Binqing Wu,Zongjiang Shang,Jianlong Huang,Ling Chen", "background": "多变量时间序列（MTS）预测对于许多应用至关重要。现有的方法因其强大的特征依赖捕捉能力展示了有希望的结果。然而，这些方法往往忽略了多分组尺度下的领先-滞后依赖关系，无法在复杂系统中捕获多层领先-滞后效应。", "innovation": "提出了MillGNN，这是一种新颖的基于图神经网络的方法，能够学习多个分组尺度下的领先-滞后依赖关系，全面捕捉变元级和组级的动力学和衰减效应。具体创新包括：1）一种针对每个尺度具有统计可解释性和数据驱动灵活性的规模特定领先-滞后图学习模块；2）一种分层领先-滞后消息传递模块，通过结构化的多分组尺度领先-滞后消息传递同时传播内部和跨分组尺度的领先-滞后效应，实现多尺度领先-滞后效应的综合与效率之间的平衡。", "conclusion": "在11个数据集上的实验结果表明，与16种最先进的方法相比，MillGNN在长短期MTS预测中展现出优越性。"}
{"llm_update_time": "20250907", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.03819", "html_url": "https://arxiv.org/abs/2509.03819", "title": "使用深度神经网络预测交通事故严重程度", "title_en": "Predicting Traffic Accident Severity with Deep Neural Networks", "authors": "Meghan Bibb,Pablo Rivas,Mahee Tayba", "background": "交通事故的数据可以通过机器学习方法进行研究，以减少未来事件的风险。最近的机器学习进展为研究与交通事故相关的数据提供了一种新的途径。研究表明，新的模型在不平衡数据上的泛化能力和预测能力都很好。本文在与交通事故相关的数据中，利用神经网络进行建模研究。前馈分析了相关的特征共线性，并通过自编码器实现了无监督的降维，继而使用密集网络来分类事故的严重程度。实验证明，提出的深度神经网络在事故严重程度分类中的交叉验证精度最高可达92%。", "innovation": "研究提出了一种包含自编码器和密集网络的神经网络模型来分析与交通事故相关的数据，用于事故严重程度的分类。模型具有良好的泛化能力和在不平衡数据上的高预测能力，通过交叉验证得到的分类准确率达到92%。", "conclusion": "使用深度神经网络能够有效分类交通事故的严重程度，实验结果表明该方法具有较高的准确性和泛化能力。"}
{"llm_update_time": "20250907", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.03845", "html_url": "https://arxiv.org/abs/2509.03845", "title": "通过概率上下文变量进行元逆强化学习在均场博弈中的应用", "title_en": "Meta-Inverse Reinforcement Learning for Mean Field Games via Probabilistic Context Variables", "authors": "Yang Chen,Xiao Lin,Bo Yan,Libo Zhang,Jiamou Liu,Neset Özkan Tan,Michael Witbrock", "background": "在实际应用中，设计适用于众多相互智能代理的奖赏函数极具挑战性。逆强化学习（IRL）在均场博弈（MFGs）中的应用提供了一种从专家示范中推断奖赏函数的实用框架。然而，现有方法假设代理是同质的，这限制了它们处理具有不同和未知目标的专家示范的能力，这在实践中很常见。", "innovation": "本文提出了一种深度潜在变量MFG模型及其相关的IRL方法。我们的方法可以在没有任何底层背景先验知识的情况下，从不同但结构相似的任务中推断出奖赏，而无需修改MFG模型本身。我们的实验在模拟场景和真实的空出租车空间价格问题中证实了该方法在MFGs中的优越性，优于现有的最佳IRL方法。", "conclusion": "我们的实验展示了该方法在模拟场景和真实世界的空出租车价格问题中的优势，证明了其在MFGs中的优越性，优于现有的最先进的IRL方法。"}
{"llm_update_time": "20250907", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.03885", "html_url": "https://arxiv.org/abs/2509.03885", "title": "Topotein: 通过对蛋白质拓扑深度学习进行蛋白质表示学习", "title_en": "Topotein: Topological Deep Learning for Protein Representation Learning", "authors": "Zhiyu Wang,Arian Jamasb,Mustafa Hajij,Alex Morehead,Luke Braithwaite,Pietro Liò", "background": "蛋白质表现学习（PRL）对于理解结构与功能的关系至关重要，但现有的基于序列和图的方法无法捕捉蛋白质结构中固有的层次组织。", "innovation": "本文提出了一种名为Topotein的综合框架，通过引入蛋白质组合性复合体（PCC）和拓扑完整感知器网络（TCPNet），利用拓扑深度学习进行PRL。PCC能够在保留每个层次几何信息的同时，从残基到二级结构再到完整的蛋白质等多个层次表示蛋白质。TCPNet使用SE(3)-等变的消息传递跨越这些层次结构，能够更有效地捕捉多尺度结构模式。在四个PRL任务的广泛实验中，TCPNet始终优于现有的基于几何图神经网络。", "conclusion": "我们的方法在需要理解二级结构排列的折叠分类等任务中表现出色，验证了层次拓扑特征对于蛋白质分析的重要性。"}
{"llm_update_time": "20250907", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.03850", "html_url": "https://arxiv.org/abs/2509.03850", "title": "数据增强意识量化知识蒸馏", "title_en": "Data-Augmented Quantization-Aware Knowledge Distillation", "authors": "Justin Kur,Kaiqi Zhao", "background": "量化感知训练(QAT)和知识蒸馏(KD)被结合以创建具有竞争力的低比特深度学习模型。现有研究主要集中在通过设计更好的KD损失函数或优化QAT的前向和反向传播来提高量化模型的输出准确性。然而，输入变换，如数据增强(DA)，对其影响的关注较少，特别是对于低精度模型而言，量化感知KD和DA的关系尚未明确研究。", "innovation": "本文提出了一种新的度量标准，它根据DA的容量来评估其最大化上下文互信息的能力，同时也保证每个类别的预测接近真实标签的平均值。该方法自动排名和选择DA，无需额外的训练开销，并与任何KD或QAT算法兼容。广泛的评估表明，使用该度量选择DA策略可以显著提升各种模型架构和数据集上的最先进的QAT和KD工作。", "conclusion": "通过引入一种新的度量标准来评估和选择DA策略，该研究显著提高了使用QAT和KD方法的低精度模型的性能。度量标准自动评估DA的效果，无需额外的训练成本，适用于多种模型架构和数据集。"}
{"llm_update_time": "20250907", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.03813", "html_url": "https://arxiv.org/abs/2509.03813", "title": "基于LiDAR的智能无线环境中室内表面分类的机器学习方法", "title_en": "Machine Learning for LiDAR-Based Indoor Surface Classification in Intelligent Wireless Environments", "authors": "Parth Ashokbhai Shiroya,Swarnagowri Shashidhar,Amod Ashtekar,Krishna Aindrila Kar,Rafaela Lomboy,Dalton Davis,Mohammed E. Eltayeb", "background": "毫米波（mmWave）和次太赫兹（sub-THz）网络中可靠的连通性依赖于周围表面的反射，因为高频信号极易受到障碍物的阻挡。表面的散射行为不仅取决于介电常数，还受其粗糙度的影响，这决定了能量是否会在镜面方向散射还是产生漫反射。本研究探讨了使用光反射率作为电磁散射行为的代理来分类室内表面的方法，重点研究了基于LiDAR的机器学习框架在室内环境分类中的应用。", "innovation": "本文提出了一种基于LiDAR的机器学习框架，用于将室内表面分类为半镜面和低镜面类别。该框架利用光反射率作为电磁散射行为的代理，收集了来自15种代表性室内材料的超过78,000个点的数据，并将其划分为3 cm x 3 cm的图块以进行分类。通过提取几何和强度特征，如仰角、自然对数缩放强度和最大值与均值的比率，训练了随机森林、XGBoost和神经网络分类器。结果表明，集成树模型在整个准确性和鲁棒性方面表现最佳，证实了LiDAR提取的特征捕捉了粗糙度引起的散射效应。", "conclusion": "所提出的框架能够生成感知散射环境图和数字孪生，支持自适应波束管理和障碍恢复，以及环境感知的连通性在下一代网络中的应用。"}
{"llm_update_time": "20250907", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.03892", "html_url": "https://arxiv.org/abs/2509.03892", "title": "带有操作限制的错误限定在线学习", "title_en": "Mistake-bounded online learning with operation caps", "authors": "Jesse Geneson,Meien Li,Linus Tang", "background": "本文研究了带有每轮操作限制的在线学习中的错误限定模型。研究证明了一般性的界，即学习任意有限错误的函数族所需的最小每轮操作数。该研究解决了关于在带宽反馈下的错误限定的无知性在线学习的问题，这个问题源自Filmus等人（2024年）和Geneson与Tang（2024年）的研究。此外，结果还被扩展到了操作受限的环境中。", "innovation": "研究在带有每轮操作限制的情况下，证明了错误限定的在线学习中的最低必需操作数。解决了有关无知性在线学习的具体问题，并将其结果扩展到操作限制的环境中。", "conclusion": "研究提供了错误限定在线学习中每轮所需最少操作数的一般性界限，并解决了带有限操作限制的在线学习问题，同时将其扩展到更多限制的应用场景。"}
{"llm_update_time": "20250907", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.03884", "html_url": "https://arxiv.org/abs/2509.03884", "title": "基于多层感知器神经网络的冠心病肽组学预测模型", "title_en": "Peptidomic-Based Prediction Model for Coronary Heart Disease Using a Multilayer Perceptron Neural Network", "authors": "Jesus Celis-Porras", "background": "冠心病是全球致死的主要原因之一，对年度医疗支出有显著贡献。开发一种非侵入性诊断方法的需求促使我们设计了一个基于多层感知器（MLP）神经网络的模型，该模型使用了基因算法选出的50个关键尿液肽生物标志物，并利用合成少数类过采样技术（SMOTE）平衡了治疗组和对照组各345名个体。", "innovation": "该研究创新性地使用多层感知器神经网络，通过选择尿液中的关键肽生物标志物，并采用合成少数类过采样技术平衡样本，建立了冠心病的非侵入性诊断模型。该模型在三个隐藏层每层60个神经元和输出层2个神经元的设置下，实现了95.67%的精确度，95.65的F1分数，两个类别的ROC曲线下的面积（AUC）达到0.9748，麦考尔茨相关系数和科恩κ系数分别为0.9134和0.9131，显示出其在冠心病检测中的可靠性。", "conclusion": "该模型提供了一种高度准确和稳健的非侵入性诊断工具，用于冠心病的检测。"}
{"llm_update_time": "20250907", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.03948", "html_url": "https://arxiv.org/abs/2509.03948", "title": "空间应用中分类算法局部鲁棒性的形式验证", "title_en": "Formal Verification of Local Robustness of a Classification Algorithm for a Spatial Use Case", "authors": "Delphine Longuet,Amira Elouazzani,Alejandro Penacho Riveiros,Nicola Bastianello", "background": "卫星组件故障成本高昂且难以处理，通常需要大量的人力和物资资源。将基于AI的故障检测系统嵌入卫星可以大幅度减少这一负担，通过提前检测故障。但是，这样的系统必须具有极其高的可靠性。为了确保这种可靠性，我们使用形式验证工具Marabou来验证AI算法中所使用的神经网络模型的局部鲁棒性。这种工具可以量化模型的输入可以被扰动到什么程度，在其输出行为变得不稳定之前，从而在不确定性条件下提高其性能的可信赖性。", "innovation": "引入了使用形式验证工具Marabou来验证AI算法中神经网络模型的局部鲁棒性，以此来提高系统的可靠性和在不确定性条件下的可信赖性。", "conclusion": "通过运用Marabou工具验证神经网络模型的局部鲁棒性，可以显著提高空间应用中AI算法的可靠性与可信赖性，从而减少卫星故障带来的高昂成本和处理难度。"}
{"llm_update_time": "20250907", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.03837", "html_url": "https://arxiv.org/abs/2509.03837", "title": "通过多模态大规模语言模型实现车对基础设施协作空间感知", "title_en": "Vehicle-to-Infrastructure Collaborative Spatial Perception via Multimodal Large Language Models", "authors": "Kimia Ehsani,Walid Saad", "background": "准确预测通信链路质量指标对于车辆对基础设施（V2I）系统至关重要，这有助于实现平滑的切换、高效的波束管理以及可靠的低延迟通信。现代车辆中越来越多的传感器数据促使利用多模态大规模语言模型（MLLMs），因为它们在不同任务中具有适应性并且具备推理能力。然而，MLLMs在三维空间理解方面存在局限性。本文为了解决这一问题，提出了一种轻量级的插件式鸟瞰图（BEV）注入模块。在这个框架中，通过邻近车辆的感测数据构建环境的BEV表示，然后将其与领航车辆的输入融合，以为空间情景提供背景。为了支持现实的多模态学习，本研究开发了一个结合CARLA模拟器和基于MATLAB的射线追踪的协同仿真环境，以生成不同场景的RGB、LiDAR、GPS和无线信号数据。结果是从射线追踪输出中编程提取指令和真实响应。研究表明，在三项V2I链路预测任务（视距versus非视距分类、链路可用性、阻塞预测）中，提出的BEV注入框架在所有任务上都改善了性能。与仅领航车辆为基础的基线相比，提出的方案在准则宏平均精度上提高了最多13.9%。在恶劣天气和夜间等挑战性条件下，这一性能提升最高可达32.7%，表明该框架在不利环境中具有鲁棒性。", "innovation": "提出了一个轻量级的插件式的多模态大型语言模型（MLLMs）鸟瞰图（BEV）注入框架，利用邻近车辆的感测数据构建环境的BEV表示，增强大型语言模型的空间理解能力。此外，创建了一个结合CARLA模拟器和基于MATLAB的射线追踪技术的协同仿真环境，用于生成不同场景下的多模式数据，以支持现实的多模态学习。最后，验证了该框架在不同的V2I链路预测任务中，特别是在恶劣环境中，表现出优于仅领航车辆的性能。", "conclusion": "提出的BEV注入框架通过集成邻近车辆的感测数据，增强了多模态大型语言模型的空间理解能力。实验结果表明，该框架在不同的V2I链路预测任务中，尤其是在恶劣条件下，其精度显著提升。"}
{"llm_update_time": "20250907", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.04107", "html_url": "https://arxiv.org/abs/2509.04107", "title": "FedQuad: Federated Stochastic Quadruplet Learning to Mitigate Data Heterogeneity", "title_en": "FedQuad: Federated Stochastic Quadruplet Learning to Mitigate Data Heterogeneity", "authors": "Ozgu Goksu,Nicolas Pugeault", "background": "联邦学习（FL）提供了一种去中心化的模型训练方式，有效解决了分布式数据和隐私保护的问题。然而，全局模型的泛化能力经常受到客户端间数据异质性的影响。当数据集规模有限且类别不平衡时，这一挑战变得更加明显。", "innovation": "本文提出了一种名为FedQuad的新方法，该方法明确优化了客户端间的小类内方差和大方间方差，从而减少模型聚合对全局模型影响的负面影响。该方法在共享特征空间中最小化相似对之间的距离，最大化负对之间的距离，有效分离客户端数据。", "conclusion": "我们在CIFAR-10和CIFAR-100数据集上评估了该方法，展示了其在各种数据分布和多个客户端场景下优于现有方法的性能。此外，我们详细分析了基于度量学习策略在监督学习和联邦学习框架下的有效性，突显了它们在联邦设置中解决表征学习挑战的能力。"}
{"llm_update_time": "20250907", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.04112", "html_url": "https://arxiv.org/abs/2509.04112", "title": "利用合成反事实标签提高有效反事实推断效率", "title_en": "Synthetic Counterfactual Labels for Efficient Conformal Counterfactual Inference", "authors": "Amirmohammad Farzaneh,Matteo Zecchin,Osvaldo Simeone", "background": "现有的符合性反事实推理（CCI）方法虽然提供了边际覆盖率保证，但在处理不平衡的处理和稀缺的反事实样本时，往往会生成过于保守的区间。", "innovation": "提出了一种基于合成数据的CCI（SP-CCI）框架，通过加入由预训练反事实模型生成的合成反事实标签来增强校准集。SP-CCI结合了风险控制预测集（RCPS）的校准过程，并通过预测驱动的推理（PPI）进行去偏差，从而实现更紧的预测区间，同时保持边际覆盖，具有理论上的保证，适用于精确和近似的重要性加权情况。", "conclusion": "在不同数据集上进行的实证结果表明，与标准CCI相比，SP-CCI在所有设置中都一致地减少了区间宽度。"}
{"llm_update_time": "20250907", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.04152", "html_url": "https://arxiv.org/abs/2509.04152", "title": "TAGAL：使用代理LLM方法生成表格数据", "title_en": "TAGAL: Tabular Data Generation using Agentic LLM Methods", "authors": "Benoît Ronval,Pierre Dupont,Siegfried Nijssen", "background": "数据生成是提高机器学习任务性能的常见方法，尤其是在分类模型的训练中。本文介绍了TAGAL，这是一种利用代理工作流生成合成表数据的方法集合。通过利用大型语言模型（LLMs）进行自动和迭代的过程，TAGAL能够根据反馈不断优化生成的数据，而无需进一步训练LLMs。这种利用LLMs的方法还允许在外生成过程中加入外部知识。", "innovation": "TAGAL通过代理工作流生成合成表数据，利用大型语言模型进行自动和迭代的过程，并在生成过程中利用反馈不断改进数据，而不需要重新训练LLMs；这种方法还能够加入外部知识，增强了生成过程的灵活性和实用性；此外，与需要训练LLMs的方法相比，TAGAL在多个数据集上表现出与最先进的方法相当的性能，甚至在某些方面优于其他不需要训练的方法。", "conclusion": "实验证明，TAGAL能够与需要LLMs训练的方法匹敌，并且普遍优于其他无需训练的方法。这些发现强调了代理工作流的潜力，并为基于LLM的数据生成方法开辟了新的研究方向。"}
{"llm_update_time": "20250907", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.04128", "html_url": "https://arxiv.org/abs/2509.04128", "title": "公平的成本：在社会负担下重新思考对策", "title_en": "Who Pays for Fairness? Rethinking Recourse under Social Burden", "authors": "Ainhize Barrainkua,Giovanni De Toni,Jose Antonio Lozano,Novi Quadrianto", "background": "基于机器学习的预测在敏感决策应用中越来越普遍，这些应用直接影响我们的生活。因此，确保分类器的公平性成为了广泛的学术研究主题。除了致力于公平分类之外，现在新兴的立法还规定，当分类器给出负面决定时，还必须提供个人可以采取的措施来逆转这一结果。这一概念被称为算法反拨。然而，许多研究人员对反拨过程中的公平性保证持保留态度。本研究提供了一个全面的理论框架，来阐释反拨过程中的不公平性，正式建立了反拨和分类中的公平性保障之间的联系，并指出了标准平等成本范式的局限性。", "innovation": "本研究引入了基于社会负担的新公平框架，并提出了一种名为MISOB的实用算法，该算法在现实条件下广泛适用。实证结果显示，MISOB能够在所有组别中降低社会负担，同时不牺牲总体分类器的准确性。这一框架和算法为解决公平性问题提供了一个新的视角和工具。", "conclusion": "本研究通过理论分析和实证研究，展示了如何在确保总体分类准确性的同时，减少所有组别中的社会负担。这不仅为公平性提供了新的保证，也对实际应用具有重要意义。"}
{"llm_update_time": "20250907", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.04053", "html_url": "https://arxiv.org/abs/2509.04053", "title": "On Aligning Prediction Models with Clinical Experiential Learning: A Prostate Cancer Case Study", "title_en": "On Aligning Prediction Models with Clinical Experiential Learning: A Prostate Cancer Case Study", "authors": "Jacqueline J. Vallon,William Overman,Wanqiao Xu,Neil Panjwani,Xi Ling,Sushmita Vij,Hilary P. Bagshaw,John T. Leppert,Sumit Shah,Geoffrey Sonn,Sandy Srinivas,Erqi Pollom,Mark K. Buyyounouski,Mohsen Bayati", "background": "过去十年，机器学习（ML）模型在医疗应用中的使用迅速增加。尽管现代ML模型表现出色，但它们并不总是捕捉到最终用户所需的数据模式。例如，一个模型可能会预测当固定所有其他特征时，癌症阶段和生存率之间呈非单调递减关系。本文旨在研究模型行为与临床经验学习之间的不一致性，并重点关注现代ML管道的欠规范问题。通过对前列腺癌结果预测案例研究，本文首先通过结合问卷调查收集的临床知识，将约束条件纳入ML模型来识别和解决这些不一致，并分析模型在不同程度欠规范下的性能和行为影响。研究表明，可以通过不牺牲性能的方式来使模型与临床经验学习保持一致。受近期生成AI相关文献的启发，本文还通过临床医生的随机实验进一步探讨了基于反馈的模型校准方法的可行性。结果表明，通过使用我们提出的方案引导医生对模型进行偏好描述，约束模型和非约束模型预测患者结果之间的差异越大，临床解释之间的差异也越明显。", "innovation": "本文提出了一种可重复的框架，用于研究ML模型与临床经验学习之间的不一致性，特别关注现代ML管道的欠规范问题。该研究通过将临床知识整合到ML模型中来识别和解决这些不一致性，并通过随机实验进一步研究了基于反馈的临床风险预测模型校准方法的可行性。研究展示了通过引导医生的偏好来调整ML模型的解释性与预测结果的关联，而不牺牲模型性能的可能性。", "conclusion": "本文通过前列腺癌的案例研究，证明了可以使ML模型与临床经验学习保持一致，而不牺牲其性能。另外，通过随机实验表明，将医生的偏好引入ML模型校准过程能够提高模型解释性，并揭示了约束和非约束模型之间的预测差异在临床解释中的重要性。"}
{"llm_update_time": "20250907", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.04185", "html_url": "https://arxiv.org/abs/2509.04185", "title": "Set Block Decoding 是一种语言模型推理加速器", "title_en": "Set Block Decoding is a Language Model Inference Accelerator", "authors": "Itai Gat,Heli Ben-Hamu,Marton Havasi,Daniel Haziza,Jeremy Reizenstein,Gabriel Synnaeve,David Lopez-Paz,Brian Karrer,Yaron Lipman", "background": "自回归下一个标记预测的语言模型虽然功能强大，但在实际部署中面临显著挑战，尤其是在推理阶段由于高计算和内存成本，特别是在解码阶段。Set Block Decoding (SBD) 是一种通过将标准下一个标记预测（NTP）和掩码标记预测（MATP）集成到单个架构中来加速生成的方法。SBD 允许模型并行地选择未来的标记，而不仅仅是连续的，这是它与先前加速方法的主要区别。", "innovation": "SBD 通过引入一种简单的并行采样策略，结合使用标准下一个标记预测和掩码标记预测，从而显著加速生成过程，同时不需要对架构进行任何更改或额外的训练超参数。此外，SBD 兼容精确 KV 缓存，并可以通过微调现有的下一个标记预测模型实现。研究表明，SBD 可以将生成所需的前向传递次数减少 3 到 5 倍，同时保持与等效 NTP 训练相同的效果。", "conclusion": "通过微调 Llama-3.1 8B 和 Qwen-3 8B，SBD 证明了其能够实现生成任务中显著的加速效果，同时保持相同的性能水平。"}
{"llm_update_time": "20250907", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.04154", "html_url": "https://arxiv.org/abs/2509.04154", "title": "作为自适应滤波器的注意力", "title_en": "Attention as an Adaptive Filter", "authors": "Peter Racioppo", "background": "该研究介绍了自适应滤波器注意力（AFA），这是一种新型注意力机制，将可学习的动力学模型直接纳入注意力权重的计算中。传统的注意力机制是通过直接比较查询和键来工作的，而AFA则将输入序列视为线性随机微分方程（SDE）的离散观测值。通过应用同时对角化的状态矩阵和噪声协方差，研究人员能够利用微分LYAPUNOV方程的闭式解来高效传播成对不确定性。通常的点积注意力机制被作为AFA在动力学和过程噪声消失且采用小角度近似时的极限结果来恢复", "innovation": "该研究创新性地将可学习的动力学模型直接嵌入注意力机制，通过线性SDE模型计算注意力权重，而非直接对查询和键进行比较。通过利用闭式解来高效传播成对不确定性的原理，提出了AFA。这为注意力机制提供了一种新的视角，并简化了注意力机制的复杂度，使其与标准的注意力机制具有相同的计算和内存复杂度", "conclusion": "在动力学和过程噪声消失且使用小角度近似时，AFA可以恢复普通的点积注意力机制。因此，AFA不仅为注意力机制提供了新的动力学视角，还保持了与标准注意力机制的计算效率。"}
{"llm_update_time": "20250907", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.04178", "html_url": "https://arxiv.org/abs/2509.04178", "title": "评注‘关于图神经网络中的过平滑现象的注记’", "title_en": "Comment on \"A Note on Over-Smoothing for Graph Neural Networks\"", "authors": "Razi Hasson,Reuven Guetta", "background": "该论文旨在评论Cai和Wang（2020年）的文章，探讨图神经网络（GNNs）中过平滑现象的问题，通过分析节点嵌入的狄利克雷能量来研究这一问题。背景是深入理解GNNs的过平滑现象对提高网络性能和稳定性具有重要意义。", "innovation": "研究发现，在温和的谱条件下（包括Leaky-ReLU），节点嵌入的狄利克雷能量随深度呈指数级减少；进一步拓展结果至谱多项式滤波器，并提供了Leaky-ReLU情况下的简短证明。实验通过边删除和权重放大来展示狄利克雷能量增加的情况，从而提示缓解过平滑的实际方法。这一研究方法和结果在理解和缓解GNNs中的过平滑现象方面有所创新。", "conclusion": "研究通过分析狄利克雷能量的变化展示了GNNs在不同深度下的行为，并通过实验提供了一些建议来解决过平滑问题，这为未来研究提供了新的思路和方向。"}
{"llm_update_time": "20250907", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.04166", "html_url": "https://arxiv.org/abs/2509.04166", "title": "跨越物种界限：从语音到动物声音的迁移学习", "title_en": "Crossing the Species Divide: Transfer Learning from Speech to Animal Sounds", "authors": "Jules Cauzinille,Marius Miron,Olivier Pietquin,Masato Hagiwara,Ricard Marxer,Arnaud Rey,Benoit Favre", "background": "自监督声音模型在语音处理方面已经展示了出色的性能，但它们在非语音数据上的有效性尚未得到充分探索。本文研究了这些模型在生物声学检测和分类任务中的迁移学习能力。研究表明，HuBERT、WavLM和XEUS等模型能够生成跨越不同类群的动物声音的丰富潜在表示。通过线性探测时间平均表示，分析了这些模型的特性。此外，将该方法扩展到考虑时间层面信息的影响，并对其他下游架构进行评估。这项研究表明声学领域的自监督学习可能成为推动生物声学研究的有效框架，并且进一步研究了频率范围和噪声对性能的影响，发现噪声稳健的预训练设置对模型性能有显著影响。", "innovation": "本文的一个主要创新在于研究了自监督的声音模型在生物声学任务中的迁移学习能力，特别是通过比较声学自监督模型与细调的生物声学预训练模型的表现，显示了其在不同类群声音表示、时间信息处理以及噪声稳健性方面的潜力。", "conclusion": "研究结果表明，基于语音的自监督学习框架在推动生物声学研究方面具有高效性和潜力，同时也揭示了频率范围和噪声对模型性能的影响，进一步证明了自监督学习在跨领域应用中的有效性。"}
{"llm_update_time": "20250907", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.04222", "html_url": "https://arxiv.org/abs/2509.04222", "title": "为什么我看不见我的聚类？基于精确度-召回率的降维验证方法", "title_en": "Why Can't I See My Clusters? A Precision-Recall Approach to Dimensionality Reduction Validation", "authors": "Diede P. M. van der Hoorn,Alessio Arleo,Fernando V. Paulovich", "background": "降维（DR）通常用于可视化高维数据，以揭示预期的聚类结构。然而，在投影中这种结构可能不会出现。现有的降维质量度量评估投影的可靠性或聚类结构质量，但无法解释为何预期结构缺失。视觉分析解决方案可以提供帮助，但由于超参数空间庞大，常常导致耗时。", "innovation": "本文提出了一个创新的框架，将降维过程分为两个阶段：关系阶段，建模相似关系；映射阶段，根据这些关系将数据投影。引入了精确度和召回率两种监督度量来评估关系阶段的表现。这种度量方法量化了建模的关系与依据一些标签代表的预期聚类结构的契合度。通过t-SNE和UMAP的应用展示了其有效性，且通过不同应用场景验证了方法的有效性。该方法可以指导超参数调优、发现投影过程中的伪影，并判断期望的结构是否捕捉到了关系中，从而使降维过程更快且更可靠。", "conclusion": "该方法可以指导超参数调优，揭露投影伪影，并判断期望的结构是否被关系捕捉到，从而加快并且使降维过程更加可靠。"}
{"llm_update_time": "20250907", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.04226", "html_url": "https://arxiv.org/abs/2509.04226", "title": "Mamba/SSM和变换器模型中的长依赖性再思考", "title_en": "Rethinking the long-range dependency in Mamba/SSM and transformer models", "authors": "Cong Ma,Kayvan Najarian", "background": "近年来，状态空间模型（尤其是Mamba）和变换器模型因其长范围依赖性而受到青睐。新模型架构正在积极开发和评估，用于需要长范围依赖性的预测任务。然而，这些模型的长范围依赖性建模能力尚未从理论角度进行研究，这限制了这一方面的系统性改进。", "innovation": "本文通过定义隐藏状态对过去输入的导数来数学定义长范围依赖性，并比较了状态空间模型与变换器模型建模长范围依赖性的能力。通过提出新的隐藏状态更新公式，并证明其在输入数据服从标准高斯分布下的稳定性，结合了变换器模型中长范围依赖性的灵活性和状态空间模型的计算效率。", "conclusion": "状态空间模型中的长范围依赖性随序列长度呈指数衰减，类似于RNN中的记忆函数衰减。而变换器模型中的注意力机制更具灵活性，理论上在充足的数据、计算资源和适当训练的情况下，能够更好地建模长范围依赖性。"}
{"llm_update_time": "20250907", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.04169", "html_url": "https://arxiv.org/abs/2509.04169", "title": "隐私风险在时间序列预测中的用户级和记录级归属攻击", "title_en": "Privacy Risks in Time Series Forecasting: User- and Record-Level Membership Inference", "authors": "Nicolas Johansson(1),Tobias Olsson(1),Daniel Nilsson(2),Johan Östman(2),Fazeleh Hoseini(2) ((1) Chalmers University of Technology, (2) AI Sweden)", "background": "归属推理攻击 (Membership Inference Attacks, MIAs) 主要针对分类模型进行研究，而对时间序列预测模型的影响则很少被探讨。本文通过引入两种新的攻击方法来填补这一空白：一种是对现有分类模型中先进的 MIA 方法 LiRA 的多变量版本进行时间序列预测环境的适应，另一种是全新的端到端学习方法 Deep Time Series (DTS) 攻击。这些方法用来与来自分类模型设置的其他领先 MIA 方法进行基准测试，并在现实环境中使用 TUH-EEG 和 ELD 数据集评估针对两个强大预测架构 LSTM 和最新的 N-HiTS 的攻击效果，评估两种威胁模型：记录级和用户级。", "innovation": "本文引入了两种新的时间序列预测模型的归属推理攻击方法：一种是对现有分类模型中先进的 LiRA 方法进行多变量版本的适应，适用于时间序列预测场景；另一种是端到端学习方法 Deep Time Series (DTS) 攻击。这些新方法相对于现有攻击方法提供了新的基准，特别是在隐私风险评估方面，证明了时间序列预测模型存在隐私风险，并且这种风险在较长预测 horizon 和较小训练群体时会增加，这情况与大型语言模型的趋势一致。", "conclusion": "时间序列预测模型暴露于隐私风险中，用户级攻击通常可以实现完美检测。所提出的方法在多个场景中表现最佳，建立了时间序列预测中的隐私风险评估的新基准。此外，随着预测 horizon 的延长和训练人群规模的缩小，模型的脆弱性也会增加。"}
{"llm_update_time": "20250907", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.04208", "html_url": "https://arxiv.org/abs/2509.04208", "title": "One-Embedding-Fits-All: 动态模型动物园实现高效零样本时间序列预测", "title_en": "One-Embedding-Fits-All: Efficient Zero-Shot Time Series Forecasting by a Model Zoo", "authors": "Hao-Nan Shi,Ting-Ji Huang,Lu Han,De-Chuan Zhan,Han-Jia Ye", "background": "时间序列基础模型（TSFMs）的兴起极大地推动了零样本预测的发展，使得预测未见过的时间序列成为可能，而无需特定任务的微调。然而，现有研究表明，并非单一的TSFM在所有情况下都表现最优，不同的模型对不同的时间模式表现出偏好。这种多样性提供了整合多个模型优势的机会。", "innovation": "该研究提出了一种名为ZooCast的方法，该方法能够识别每个模型独特的预测优势，并将其动态地组合成一个模型动物园。该方法的关键创新在于其'One-Embedding-Fits-All'范式，构建了一个统一的表示空间，其中动物园中的每个模型均由单一嵌入表示，从而实现所有任务的高效相似匹配。", "conclusion": "实验表明，ZooCast在GIFT-Eval零样本预测基准上表现出强大的性能，同时保持了单一TSFM的效率。在具有连续模型发布的实际场景中，该框架可以无缝地加入新模型，逐步提高预测准确性，几乎无需额外开销。"}
{"llm_update_time": "20250907", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.04259", "html_url": "https://arxiv.org/abs/2509.04259", "title": "RL's Razor: 为什么在线强化学习记忆较少", "title_en": "RL's Razor: Why Online Reinforcement Learning Forgets Less", "authors": "Idan Shenfeld,Jyothish Pari,Pulkit Agrawal", "background": "现有研究表明，虽然通过强化学习（RL）和监督微调（SFT）进行模型微调的两个方法在新任务上的性能相似，但RL在保留先前知识和能力方面表现更好。具体来说，RL在知识点上的遗忘程度不如SFT少。研究者通过KL散度来衡量这种遗忘的程度，并发现RL倾向于找到与原始模型KL最小解，而SFT可能会收敛到完全不同的分布。", "innovation": "发现在线强化学习（on-policy RL）能够更加有效地保留原有的知识和能力，即KL散度更小，而这种方法被研究者命名为‘RL的剃刀原则’（RL's Razor）。这个原则意味着在所有解决新任务的方法中，RL倾向于选择与原始模型最接近的一种。", "conclusion": "总之，该研究通过实验验证了在线强化学习相较于监督微调具有更好的保留先前知识和能力的优势。此外，研究为在线强化学习为何具有更小的KL变化提供了理论依据，并概括出‘RL的剃刀原则’这一核心观点。"}
{"llm_update_time": "20250907", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.04245", "html_url": "https://arxiv.org/abs/2509.04245", "title": "使用深度生成模型为心力衰竭预后生成合成生存数据", "title_en": "Synthetic Survival Data Generation for Heart Failure Prognosis Using Deep Generative Models", "authors": "Chanon Puttanawarut,Natcha Fongsrisin,Porntep Amornritvanich,Cholatid Ratanatharathorn,Panu Looareesuwan", "background": "心力衰竭（HF）研究受到大规模可共享数据访问有限的制约，这些限制由隐私法规和机构障碍造成。合成数据生成提供了一种有望克服这些挑战的方法，同时保护患者隐私。", "innovation": "从机构数据中生成包含12,552个独特患者的合成HF数据集，使用包括表格变分自编码器（TVAE）、正则化流、ADSGAN、生存生成对抗网络（SurvivalGAN）和表格去噪扩散概率模型（TabDDPM）在内的五种深度学习模型。通过统计相似度指标、生存预测和隐私评估全面评估合成数据的实用性，表明SurvivalGAN和TabDDPM具有高保真度，SurvivalGAN和TVAE在生存预测评估中表现最强，与真实数据表现相近，并且隐私评估证实了数据保护。", "conclusion": "基于深度学习的合成数据生成可以提供用于研究的高保真、隐私保护的心力衰竭数据集，解决数据共享障碍，为心力衰竭研究和预测建模提供宝贵的资源。"}
{"llm_update_time": "20250907", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.04232", "html_url": "https://arxiv.org/abs/2509.04232", "title": "重新考量层级高斯噪声注入：连接隐式目标与隐私预算分配", "title_en": "Rethinking Layer-wise Gaussian Noise Injection: Bridging Implicit Objectives and Privacy Budget Allocation", "authors": "Qifeng Tan,Shusen Yang,Xuebin Ren,Yikai Zhang(Xi'an Jiaotong University)", "background": "LGM通过在分区梯度向量中注入噪声提升了差分隐私深度学习的灵活性，但现有方法往往依赖于启发式噪声分配策略，缺乏将噪声分配与正式的隐私-效用权衡理论基础联系起来的严谨理解。现有的方法中，优化目标往往是不明确的，有的忽视了层间信噪比（SNR）的一致性，有的导致隐私预算的低效使用。", "innovation": "本文提出了一种统一的分析框架，系统性地将层间噪声注入策略与其隐含的优化目标以及相应的隐私预算分配关联起来。分析表明，现有的方法往往优化不明确的目标，要么忽略了层间SNR的一致性，要么导致隐私预算的低效使用。为此，提出了信噪比一致的噪声分配策略，统一了两方面，从而实现更好的信号保留和更高效的隐私预算使用。通过对集中式和联邦学习设置中的广泛实验，表明该方法在保持现有方法优势的同时，能够取得更好的隐私-效用权衡。", "conclusion": "本文框架不仅为现有的方法提供了诊断性的见解，还为设计深度模型中自适应且有效的噪声注入方案提供了理论指导。"}
{"llm_update_time": "20250907", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.04296", "html_url": "https://arxiv.org/abs/2509.04296", "title": "使用因果抽象加速复杂臂问题中的决策制定", "title_en": "Using causal abstractions to accelerate decision-making in complex bandit problems", "authors": "Joel Dyer,Nicholas Bishop,Anisoara Calinescu,Michael Wooldridge,Fabio Massimo Zennaro", "background": "现实世界中的决策问题往往可以被抽象为因果多臂_bandits (CMABs) 问题，这些抽象可以在不同的层次上进行。然而，缺乏一种利用每种抽象层次信息和计算优势的通用方法。因此，本文的研究背景是在不同抽象层次上利用共享信息来有效解决CMAB问题的方法。", "innovation": "本文提出了AT-UCB算法。该算法通过利用因果抽象（CA）理论在成本较低且粒度较粗的CMAB实例中进行探索，并在感兴趣的CMAB中针对潜在最优行为集使用传统的上确界（UCB）算法，从而显著减少了累积的遗憾值。此外，通过理论和实证方法，证明了AT-UCB相对于经典UCB算法的优势。", "conclusion": "通过构建一个新颖的累积遗憾的上界以及将AT-UCB应用于具有不同分辨率和计算成本的流行病学模拟器，展示了该算法在加速复杂臂问题中的决策制定方面的优越性。"}
{"llm_update_time": "20250907", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.04295", "html_url": "https://arxiv.org/abs/2509.04295", "title": "因果和统计数据集偏差 primer：公平和稳健图像分析", "title_en": "A Primer on Causal and Statistical Dataset Biases for Fair and Robust Image Analysis", "authors": "Charles Jones,Ben Glocker", "background": "机器学习方法在实际应用中常常会出现问题，尤其是在高风险情境和社会敏感领域。这些问题在医疗诊断等关键领域尤为突出，可能导致机器学习方法的采用受阻。本文旨在探讨图像分析中机器学习方法失败的原因，并提出公平性和稳健性方面的解决方案。", "innovation": "本文揭示了导致机器学习图像分析方法失败的因果和统计结构，并提出了两个未被充分重视的问题：“公平午餐问题”和“子组可分性问题”。同时，分析了当前公平表示学习方法存在的缺陷，并提出了可能的研究方向。", "conclusion": "本文强调需要进一步研究和解决上述问题，以提升机器学习方法在图像分析中的公平性和稳健性，使其能够在医疗诊断等领域安全有效应用。"}
{"llm_update_time": "20250907", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.04362", "html_url": "https://arxiv.org/abs/2509.04362", "title": "利用增强自监督学习的空间时序反转变换器融合多源数据进行停车可用性预测", "title_en": "Parking Availability Prediction via Fusing Multi-Source Data with A Self-Supervised Learning Enhanced Spatio-Temporal Inverted Transformer", "authors": "Yin Huang,Yongqi Dong,Youhua Tang,Li Li", "background": "近年来私家车的迅速增长加剧了城市停车问题，因此迫切需要精确有效的停车可用性预测来为城市规划和管理提供支持。当前的模型在表示空间-时间依赖关系以及利用多数据源方面存在关键局限性。", "innovation": "该研究提出了一种新的方法，即SST-iTransformer，它通过K-means聚类建立了停车区域集群（PCZs），并从多种交通模式（地铁、公交车、在线网约车和出租车）收集并整合了与目标停车场相关的交通需求特征。升级后的SST-iTransformer结合了掩码重构为基础的预构任务进行自监督的空间-时间表示学习，并具有创新性的双分支注意机制：系列注意通过分块操作捕捉长时间依赖性，而通道注意通过反转维度建模跨变量交互。", "conclusion": "使用中国成都的实际数据进行广泛实验表明，SST-iTransformer在最小均方误差（MSE）和具有竞争力的平均绝对误差（MAE）方面优于基准深度学习模型（包括Informer、Autoformer、Crossformer和iTransformer），实现最先进的性能。综合消除实验量化揭示了不同数据源的重要性：纳入网约车数据提供的性能提高最大，其次是出租车，而固定路线公共交通（公交/地铁）特征的贡献较小。空间相关性分析进一步证实，排除PCZ内部相关停车场的历史数据会导致性能显著下降，强调了建模空间依赖性的重要性。"}
{"llm_update_time": "20250907", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.04290", "html_url": "https://arxiv.org/abs/2509.04290", "title": "Differentially隐私的交互式框架在寻找最佳权衡中的应用", "title_en": "An Interactive Framework for Finding the Optimal Trade-off in Differential Privacy", "authors": "Yaohong Yang,Aki Rehn,Sammie Katt,Antti Honkela,Samuel Kaski", "background": "差分隐私(DP)在隐私保护分析中是标准做法，但在隐私保证和模型性能之间引入了基本折衷。选择最优平衡是关键挑战，可以被表述为多目标优化(MOO)问题，即首先发现最优折衷集(帕累托前沿)，然后学习决策者在这之中的偏好。虽然在交互式多目标优化方面已经有许多研究，但标准方法——使用通用的替代目标函数，并通过简单的两两反馈学习偏好——对于DP来说效率很低，因为它未能利用该问题的独特结构：帕累托前沿上的一个点可以通过固定隐私级别下的准确率最大化直接生成。因此，本文提出了一个基于解决此独特结构的交互式框架以直接和有效地建模帕累托前沿。", "innovation": "提出了一种新的交互式框架，该框架能够理论推导出折衷的形状，以直接且高效地建模帕累托前沿。进一步地，通过提供假设权衡曲线并请求用户选择其最偏好的曲线来替换原有的两两比较，以减轻偏好学习的效率低下问题。", "conclusion": "通过对六种真实数据集上的差分隐私逻辑回归和深度迁移学习实验表明，与基线相比，该方法在显着减少计算成本和用户交互的情况下能够更快地收敛到最优隐私-准确度折衷。"}
{"llm_update_time": "20250907", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.04363", "html_url": "https://arxiv.org/abs/2509.04363", "title": "当三个实验优于两个：通过利用新的偏差-方差权衡关系规避不可解的相关随机不确定性", "title_en": "When three experiments are better than two: Avoiding intractable correlated aleatoric uncertainty by leveraging a novel bias--variance tradeoff", "authors": "Paul Scherer,Andreas Kirsch,Jake P. Taylor-King", "background": "实验场景通常存在异方差性的随机不确定性，并且这种不确定性在批量设置下可能相关。模型与真实随机变量之间的期望均方误差可以通过偏差-方差权衡来表达，包括一个表征模型不确定性（epistemic uncertainty）的项、偏差的平方项和随机不确定性项。本文基于此关系提出了一种新的主动学习策略，旨在直接减少每轮实验之间的偏差。研究还探讨了如何通过创新性的偏差-方差关系利用历史数据的二次作用，提出了一种利用特征值分解策略进行批量化的机制。", "innovation": "本文提出了新的主动学习策略，直接减少每轮实验之间的偏差，适用于有噪声和无噪声的模型系统。提出了利用偏差-方差关系中的新关系（cobias-covariance relationship）来二次利用历史数据的方法，并通过在线性批处理设置中利用该关系和二次估计器，展示了优于经典方法的优势，如BALD和最小不确定性方法。", "conclusion": "本文通过利用新的偏差-方差关系展示了在批量实验中规避不可解的相关随机不确定性的方法，实现了利用历史数据二次作用来优化模型性能，并在实验中表现出了优越性。"}
{"llm_update_time": "20250907", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.04398", "html_url": "https://arxiv.org/abs/2509.04398", "title": "IPA: 一种用于高效基础模型适应的信息保留输入投影框架", "title_en": "IPA: An Information-Preserving Input Projection Framework for Efficient Foundation Model Adaptation", "authors": "Yuan Yin,Shashanka Venkataramanan,Tuan-Hung Vu,Andrei Bursuc,Matthieu Cord", "background": "参数高效微调（PEFT）方法，如LoRA，通过向预训练权重中注入低秩更新来减少适应成本。然而，LoRA的下投影是随机初始化的，与数据无关，会丢弃潜在有用的信息。已有分析表明，该投影在训练过程中变化不大，而上投影承载了大部分适应性，使得随机输入压缩成为性能瓶颈。", "innovation": "本文提出了IPA，一种特征感知的投影框架，明确保存在缩减隐藏空间中的信息。在线性情况下，IPA使用近似主导主成分的算法实例化，这使得投影预训练能够高效进行，几乎不影响推理开销。", "conclusion": "在各种语言和视觉基准测试中，IPA 一致地优于 LoRA 和 DoRA，在常识推理上平均提高了1.5分精度，在VTAB-1k上提高了 2.3分，同时冻结投影时与全量 LoRA 的性能相当，但参数量仅为一半。"}
{"llm_update_time": "20250907", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.04419", "html_url": "https://arxiv.org/abs/2509.04419", "title": "关于大型语言模型后续训练的统一视角", "title_en": "Towards a Unified View of Large Language Model Post-Training", "authors": "Xingtai Lv,Yuxin Zuo,Youbang Sun,Hongyi Liu,Yuntian Wei,Zhekai Chen,Lixuan He,Xuekai Zhu,Kaiyan Zhang,Bingning Wang,Ning Ding,Bowen Zhou", "background": "当前对现代语言模型进行后续训练的数据来源有两种：在线（由模型生成的游戏）数据和离线（人类或模型演示）数据。这些数据通常分别应用于强化学习（RL）和监督微调（SFT）等方法。然而，这些方法之间似乎存在矛盾，但实际反映了单一优化过程的不同方式。", "innovation": "本文提出了统一策略梯度估计器，并展示了包含不同数据分布假设和各种偏差方差折衷下的梯度计算的广泛谱，证实这些方法并非矛盾而是一个单一的优化过程的不同实例。此外，根据理论发现，提出了一种动态选择不同训练信号的混合后续训练（HPT）算法，旨在充分利用演示同时保持稳定的探索，并不牺牲学习到的推理模式。通过广泛的实验和消融研究，进一步验证了统一理论框架和HPT的有效性。", "conclusion": "通过包括六项数学推理基准和两项异常分布套装的广泛实验，表明HPT算法在不同规模和家庭的不同模型上均优于强大的基线。"}
{"llm_update_time": "20250907", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.04442", "html_url": "https://arxiv.org/abs/2509.04442", "title": "Delta Activations: A Representation for Finetuned Large Language Models", "title_en": "Delta Activations: A Representation for Finetuned Large Language Models", "authors": "Zhiqiu Xu,Amish Sethi,Mayur Naik,Ser-Nam Lim", "background": "随着强大且开源的大语言模型（LLMs）的成功，社区能够创建大量针对特定任务和领域的后训练模型集合。然而，导航和理解这些模型仍面临挑战，因为存在不一致的元数据和无结构化的存储库。", "innovation": "本文介绍了一种名为Delta Activations的方法，通过测量相对于基本模型的内部激活变化来表示后训练的LLMs作为向量嵌入。这种方法可实现有效按领域和任务的聚类，揭示模型结构，且在不同后训练设置下表现出优异的鲁棒性，并且在混合后训练数据集时具有加性性质。此外，还显示通过少量示例后训练可以嵌入任务，进一步探讨其在模型选择和合并中的应用。", "conclusion": "希望Delta Activations能够促进重新使用公共可用模型的实践。相关代码可在https://this.is/my/link中获取。"}
{"llm_update_time": "20250907", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.04377", "html_url": "https://arxiv.org/abs/2509.04377", "title": "PagedEviction: 结构化的块级KV缓存剪枝策略以提高大型语言模型的高效推理", "title_en": "PagedEviction: Structured Block-wise KV Cache Pruning for Efficient Large Language Model Inference", "authors": "Krishna Teja Chitty-Venkata,Jie Ye,Xian-He Sun,Anthony Kougkas,Murali Emani,Venkatram Vishwanath,Bogdan Nicolae", "background": "KV缓存通过存储之前处理过的标记的注意力状态，显著提高了大型语言模型（LLM）推理的效率，从而加快了后续标记的生成。然而，随着序列长度的增加，KV缓存很快成为主要的内存瓶颈。现有方法依赖于基于注意力的标记重要性或在不同的vLLM页面间移除标记来缓解这一问题，但这些方法并不总是有效，尤其是在长上下文任务中。为解决这一问题，该研究提出了一种名为PagedEviction的创新性细粒度结构化的KV缓存剪枝策略，该策略增强vLLM的PagedAttention的内存效率。PagedEviction引入了一种针对分页内存布局的高效块级移除算法，该算法与PagedAttention无缝集成，无需修改其CUDA注意力内核。研究者在Llama-3.1-8B-Instruct、Llama-3.2-1B-Instruct和Llama-3.2-3B-Instruct模型上评估了PagedEviction在LongBench基准测试套件中的表现，结果表明在长上下文任务中，PagedEviction的内存使用效率更高且准确性更优，优于基线方法。", "innovation": "提出了PagedEviction，一种专门针对分页内存布局的有效块级KV缓存剪枝策略，该策略与PagedAttention兼容且无需修改其CUDA注意力内核，从而提高大型语言模型推理的内存效率并保持更好的准确性.", "conclusion": "在Llama-3.1-8B-Instruct、Llama-3.2-1B-Instruct和Llama-3.2-3B-Instruct模型上的实验结果显示，PagedEviction在长上下文任务中具有更好的内存使用效率和准确性，优于基线方法."}
{"llm_update_time": "20250907", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.04430", "html_url": "https://arxiv.org/abs/2509.04430", "title": "揭示表征数据不确定性在表征深度学习中的作用", "title_en": "Unveiling the Role of Data Uncertainty in Tabular Deep Learning", "authors": "Nikolay Kartashev,Ivan Rubachev,Artem Babenko", "background": "最近的表征深度学习研究已经展示了卓越的实用性，但在为何这些技术实际成功方面，该领域通常缺乏清晰的理解。我们论文的重点在于强调数据不确定性对于解释近期表征深度学习方法有效性的概念重要性。研究发现，许多在表征深度学习中有益的设计选择，如数值特征嵌入、检索增强模型和高级集成策略的成功，很大程度上可以归因于它们管理高数据不确定性的隐式机制。通过剖析这些机制，我们为这些最近性能改进提供了一个统一的理解。", "innovation": "我们论文的创新之处在于通过数据不确定性视角，揭示了表征深度学习中多种有益设计选择的潜在机制。这一视角直接导致了更有效的数值特征嵌入的开发，这是一种即时的实践成果。这一研究为现代表征方法带来的好处提供了基础理解，并具体推动了现有技术的进步，同时也为表征深度学习的未来研究方向提供了指示。", "conclusion": "我们工作的主要结论在于，通过数据不确定性视角，我们为表征深度学习中的性能改进提供了一个统一的理解。这种理解有助于我们更好地理解现代表征方法的优势，并为这些方法的进一步完善和未来的研究方向提供了指导。"}
{"llm_update_time": "20250907", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.04394", "html_url": "https://arxiv.org/abs/2509.04394", "title": "过渡模型：重新思考生成学习目标", "title_en": "Transition Models: Rethinking the Generative Learning Objective", "authors": "Zidong Wang,Yiyuan Zhang,Xiaoyu Yue,Xiangyu Yue,Yangguang Li,Wanli Ouyang,Lei Bai", "background": "生成模型中存在一个基本的两难问题：迭代扩散模型虽然能够实现卓越的保真度，但计算成本高昂；而高效的多步替代方案则受限于质量天花板。这种生成步骤与输出质量之间的冲突源于专注于无限小动态或直接终点预测的限制性训练目标。现有方法仅适用于单一跳跃或精细粒度精炼中的任意一种情况。", "innovation": "本文引入了一个精确的连续时间动态方程，能够分分析定义任意时间间隔内的状态转换。这导致了一个新的生成范式——过渡模型（TiM），它可以适应任意步数转换，从单步跃进到更精细的逐步精炼，无缝跨越生成轨迹。尽管参数量仅为865M，TiM在所有评估的步骤数上均达到了最先进的性能，超越了SD3.5（8B参数）和FLUX.1（12B参数）。此外，与之前的多步生成器不同，TiM在采样预算增加时表现出单调的质量改进。当使用我们的原生分辨率策略时，TiM在4096x4096的分辨率下表现出色，提供了卓越的保真度", "conclusion": "TiM达到了前所未有的性能，同时在质量改善和计算效率上取得平衡。"}
{"llm_update_time": "20250907", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.04415", "html_url": "https://arxiv.org/abs/2509.04415", "title": "在混合观察数据中具有自适应异质因果结构学习的可解释聚类", "title_en": "Interpretable Clustering with Adaptive Heterogeneous Causal Structure Learning in Mixed Observational Data", "authors": "Wenrui Li,Qinghao Zhang,Xiaowo Wang", "background": "了解因果异质性对于生物学和医学等领域的科学研究至关重要。然而，现有的方法缺乏因果意识，在建模异质性、混杂因素和观察约束方面存在不足，这导致解释性较差，区分真正的因果异质性与虚假关联存在难度。", "innovation": "本文提出一个无监督框架，HCL (具有自适应异质因果结构学习的可解释因果机制感知聚类)，该框架可以在无需时间顺序、环境标签、干预或其它先验知识的情况下，同时从混合型观察数据中推断出潜在集群及其对应的因果结构。HCL通过引入等效表示来放松同质性和充分性假设，从而编码结构性异质性和混杂因素。此外，HCL进一步开发了一个双向迭代策略，交替优化因果聚类和结构学习，并结合自监督正则化来平衡跨集群的通用性和具体性。这些组成部分共同使HCL能够向可解释、异质性因果模式的收敛，并在理论和实证上分别证明了解识别异质性因果结构的条件以及优于现有方法的性能，特别是在集群和结构学习任务方面，并且在真实的单细胞干扰数据中恢复了生物学上有意义的机制，展示了其在发现可解释的、机制层面的因果异质性的应用价值", "conclusion": "HCL能够收敛于可解释、异质性的因果模式，理论证明在轻条件下的异质性因果结构识别性，实验表明在聚类和结构学习任务中优于现有方法，并且在真实世界单细胞干扰数据中恢复了生物上有意义的机制，展示出其在发现可解释的机制层面因果异质性的应用价值。"}
{"llm_update_time": "20250907", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.03522", "html_url": "https://arxiv.org/abs/2509.03522", "title": "一小份数据可能远胜于多份数据：临床环境中过程时长预测", "title_en": "A Small Dataset May Go a Long Way: Process Duration Prediction in Clinical Settings", "authors": "Harald Störrle,Anastasia Hort", "background": "术科的利用是医院的一大成本驱动因素。通过优化手术排期来优化这一变量，可以显著降低成本并改善医疗成果。先前的研究提出了各种复杂的模型来预测程序持续时间，这些模型需要大量的数据支持。", "innovation": "我们致力于创建一个有效且高效的模型，基于小量数据预测手术时长，并且模型结构更简单，更易于使用。我们深入临床应用领域，结合从业者经验和数据分析，进行因子分析和回归模型开发，发现常用的方法与文献中提出的方法相比有时表现更佳。结合专家知识和数据分析可以提高数据质量和模型性能，实现更准确的预测。", "conclusion": "我们通过将传统数据科学方法与临床环境和流程结构的定性研究相结合，取得了比先前研究更好的结果，因此能够利用小数据集。"}
{"llm_update_time": "20250907", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.04322", "html_url": "https://arxiv.org/abs/2509.04322", "title": "非住宅建筑能源行为特征建模", "title_en": "Characteristic Energy Behavior Profiling of Non-Residential Buildings", "authors": "Haley Dozier,Althea Henslee", "background": "由于气候变化和极端天气事件的威胁，美国陆军设施的基础设施面临风险。为支持关键任务和提高作战准备度，需要采取气候韧性的措施来保护相关设施资产。大多数位于美国本土的陆军设施依赖商用能源和水资源，因此需要提高对独立能源资源（如电力网络和天然气管道）的韧性，并理解设施内的能源使用情况。本文将提出一种数据驱动的行为模型来确定设施内能源使用的特征行为模式。该模型将用于1）评估意外中断对能源系统的影响，并2）为未来韧性措施提供基准基准。研究将使用描述各个建筑行为的模型，这些模型能够准确分析、预测和聚类从非住宅建筑能源使用中收集的多模态数据。由于陆军设施能源使用数据的特点，本文将使用结构相似的开放数据来展示该方法论。", "innovation": "本文提出的是一种数据驱动的行为模型，用于确定设施内能源使用的特征行为模式。该模型能够准确地分析、预测和聚类非住宅建筑中的能源使用数据，有助于评估意外中断对能源系统的影响，并为未来韧性措施提供基准基准。该方法使用结构相似的开放数据来展示这种方法，为改进能源管理和提高军事设施的弹性提供了新的视角。", "conclusion": "本文提出的数据驱动模型对非住宅建筑的能源行为进行了特征建模，有助于评估设施能源系统的韧性并提供基准基准。基于模型的预测和聚类能力，设施管理层可以更好地理解和应对能源使用的变化，从而提高设施的整体韧性。"}
{"llm_update_time": "20250907", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.03531", "html_url": "https://arxiv.org/abs/2509.03531", "title": "长文生成中实时检测虚构实体", "title_en": "Real-Time Detection of Hallucinated Entities in Long-Form Generation", "authors": "Oscar Obeso,Andy Arditi,Javier Ferrando,Joshua Freeman,Cameron Holmes,Neel Nanda", "background": "大型语言模型目前被广泛应用于高风险场景，如医疗咨询和法律建议，这些场景中模型的虚构信息可能导致严重伤害。现有的虚构检测方法要么仅适用于短事实查询，要么需要昂贵的外部验证，这在实际应用中是不切实际的。", "innovation": "本文提出了一种低成本、可扩展的方法，用于实时识别长文本生成中的虚构标记，并有效扩展至70B参数模型。该方法专注于实体级别的虚构，即虚构的名字、日期、引文等，并能够逐字逐句地进行检测。文章还开发了一种利用网络搜索进行标注的方法，以将模型响应与实际标记者联系起来，进而训练简单的高效分类器，如线性探针。", "conclusion": "在四种模型系列的评估中，本文的分类器在长文本响应中的表现优于基线方法，包括更昂贵的方法，如语义熵（例如AUC 0.90 vs 0.71）。此外，尽管只使用实体级别的标签进行训练，但该方法在数学推理任务中的不准确答案检测上表现出色，显示了其在实体之外的泛化能力。尽管标注方法成本高，但本文发现来自一个模型的标注响应可有效训练其他模型的分类器，因此，作者公开发布了数据集以促进再利用。"}
{"llm_update_time": "20250907", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.04445", "html_url": "https://arxiv.org/abs/2509.04445", "title": "迈向符合认知决策模型以提升AI对齐", "title_en": "Towards Cognitively-Faithful Decision-Making Models to Improve AI Alignment", "authors": "Cyrus Cousins,Vijay Keswani,Vincent Conitzer,Hoda Heidari,Jana Schaich Borg,Walter Sinnott-Armstrong", "background": "近年来，AI研究趋势是将人类中心目标融入其中，明确目标是将AI模型与个人偏好和社会价值观对齐。研究人员利用标准偏好启发式方法构建人类决策和判断的模型，进而使AI行为与人类相符。然而，这些常用模型未能捕捉人类决策的真实认知过程，特别是当人们使用启发式简化决策问题相关信息时。因此，从人类决策中学习到的模型往往不能反映其真实的认知过程，而不能作为验证学习框架并推广到其他决策任务的依据。", "innovation": "为解决这一局限，该研究采用公理化方法从成对比较中学习忠实反映认知过程的决策模型。基于广泛的认知过程特征人类决策的文献，以及最近对成对比较任务中认知过程特征的建模工作，研究团队定义了一类模型，在该模型中，个体特征首先在同一选项之间进行处理和比较，然后通过固定规则（如布拉德利-特里规则）进行汇总。这种结构化信息处理确保这类模型是现实且可行地代表人类决策过程的候选者。该研究通过肾移植分配任务展示了这种方法在学习可解释的决策模型方面的有效性，并表明所提出模型在人类成对决策的任务中匹配或超越了先前模型的准确性。", "conclusion": "这种模型能够更准确地反映人脑的决策过程，有助于AI行为与人类更一致，从而提升AI的对齐效果。"}
{"llm_update_time": "20250907", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.04422", "html_url": "https://arxiv.org/abs/2509.04422", "title": "Echo State Networks as State-Space Models: A Systems Perspective", "title_en": "Echo State Networks as State-Space Models: A Systems Perspective", "authors": "Pradeep Singh,Balasubramanian Raman", "background": "传统的Echo State Networks (ESNs)通常被视作一种高效的、通过训练读取层的循环模型，但它们的动态特性和设计往往是基于经验法则，而非第一性原理。本文重新将ESNs表述为状态空间模型（SSMs），通过系统的理论视角连接了回声状态计算与经典识别方法和现代内核化状态空间模型。这推动了对ESNs的理解，并提供了一个统一的视角来分析其性能和局限性。", "innovation": "研究表明，回声状态性质实际上是一种收缩非线性状态空间模型中的输入到状态稳定性表征，通过对泄漏、光谱扩展和激活利普希茨常数的验证条件进行了推导。本文还发展了两种互补的映射：小信号线性化模型，使其成为在局部有效的线性状态空间模型，具有可解释的极点和记忆窗口；以及提升/库曼随机特征扩展，使得ESNs在扩充的状态下成为线性模型，从而进行传递函数和卷积核分析。这种视角为频域特性提供了记忆谱的表征，并明确了ESNs模仿结构化状态空间核模型的条件。此外，还将教师强制力作为状态估计进行阐述，并提出了Kalman/EKF辅助读取学习，以及用于超参数（泄漏、光谱半径、过程/测量噪声）估计的EM方法，并提出了一种混合子空间方法，以满足收缩约束下的频谱塑造。此举推动了对ESNs的系统级理解，并改进了设计方法与训练过程。", "conclusion": "本文通过将ESNs重新定义为SSMs，提供了系统理论的统一视角，这为理解ESNs的动态特性和设计提供了新的思路。通过开发输入到状态稳定的条件、小信号线性化映射和提升/库曼随机特征扩展，研究明确了ESNs在特定条件下的性能和局限性。提出的方法不仅改进了ESNs的理论框架，还为设计和训练提供了新的工具，使其更接近经典和现代模型的分析工具。"}
{"llm_update_time": "20250907", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.03528", "html_url": "https://arxiv.org/abs/2509.03528", "title": "ProLiFIC数据集：利用大语言模型揭示意大利立法过程", "title_en": "The ProLiFIC dataset: Leveraging LLMs to Unveil the Italian Lawmaking Process", "authors": "Matilde Contestabile,Chiara Ferrara,Alberto Giovannetti,Giovanni Parrillo,Andrea Vandin", "background": "过程挖掘（PM）最初是在工业和商业环境中发展起来的，近年来也被应用于社会系统，包括法律系统。然而，PM在法律领域的应用受到了可用数据集的质量和可访问性的限制。本文介绍了一个名为ProLiFIC的数据集，记录了从1987年到2022年的意大利立法过程。该数据集来源于Normattiva门户的非结构化数据，并通过大语言模型（LLMs）进行结构化处理，这与最近将过程挖掘与大语言模型结合的努力相一致。", "innovation": "ProLiFIC数据集源自PaCMoD Research Center，并克服了数据访问和质量的限制，通过大语言模型实现非结构化数据的结构化，这使得过程挖掘在法律领域中的应用更为可行。此外，ProLiFIC还被用作过程挖掘在法律领域的基准数据集，促进了该领域的进一步研究和发展。", "conclusion": "本文提出的ProLiFIC数据集为过程挖掘在法律领域的研究提供了一个重要的基准数据集，并通过利用大语言模型提高了非结构化数据的利用价值。未来的研究方向将基于ProLiFIC数据集进行深入的法律过程挖掘分析。"}
{"llm_update_time": "20250907", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.03539", "html_url": "https://arxiv.org/abs/2509.03539", "title": "多时间步精确变分公式法用于计算穿越概率和转移速率", "title_en": "An exact multiple-time-step variational formulation for the committor and the transition rate", "authors": "Chatipat Lorpaiboon,Jonathan Weare,Aaron R. Dinner", "background": "过渡时期的穿越概率（committor）是系统动态转移到其中一个稳定状态的概率。现有的方法可以通过最小化依赖于滞后时间（lag time）的转移率表达式从轨迹数据估计穿越概率，但只能在滞后时间为单时间步时精确。论文描述了现有的方法存在的问题，并提供了新的方法以克服这些限制。", "innovation": "本文引入了一种新的表达式，该表达式能够在任何滞后时间下最小化精确的穿越概率，从而使估计结果更加稳健不依赖于选择的滞后时间。此外，还提出了一个新的转移率表达式，并将其与基于均方残差的动力统计学变分方法进行了关联。", "conclusion": "数值测试表明，采用新的穿越概率和转移率估计方法，其结果对选择的滞后时间的变化更加不敏感；还从动力模式分解的角度讨论了进一步的数值考虑。"}
{"llm_update_time": "20250907", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.04449", "html_url": "https://arxiv.org/abs/2509.04449", "title": "ChronoGraph: 一个基于现实世界的图结构多变量时间序列数据集", "title_en": "ChronoGraph: A Real-World Graph-Based Multivariate Time Series Dataset", "authors": "Adrian Catalin Lutu,Ioana Pintilie,Elena Burceanu,Andrei Manolache", "background": "背景介绍了ChronoGraph数据集的构建基础，即从实际生产微服务中创建出一个图结构的多变量时间序列预测数据集。每个节点表示一个服务，该服务会发出系统级性能指标的多变量流，涵盖了CPU、内存和网络使用模式；而有向边则记录了服务间的依赖关系。主要任务是预测这些信号在未来的服务级值。此外，ChronoGraph还提供了由专家标注的异常事件窗口作为异常标签，这有助于评估异常检测方法，并在运营中断期间评估预测的鲁棒性。", "innovation": "创新点在于ChronoGraph数据集的独特之处在于其综合了(i) 多变量时间序列，(ii) 明确的、机器可读的依赖关系图，和(iii) 与真实事件对齐的异常标签。相较现有的工业控制系统或交通和空气质量领域的基准数据集，ChronoGraph的独特结合为结构感知的预测研究和事件感知的评估提供了一个现实基准。它覆盖了预测模型、预训练时间序列基础模型及标准异常检测器的基准结果，用于结构感知预测和事件感知评估的研究。", "conclusion": "结论指出ChronoGraph为研究微服务系统中的结构感知预测和事件感知评估提供了一个现实基准。研究结果包括涵盖预测模型、预训练时间序列基础模型以及标准异常检测器的基线结果，展现了一个在微服务系统中进行结构感知预测和事件感知评估的研究方向。"}
{"llm_update_time": "20250907", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.03547", "html_url": "https://arxiv.org/abs/2509.03547", "title": "结合基于特征的方法与图神经网络和符号回归以实现协同性能和可解释性", "title_en": "Combining feature-based approaches with graph neural networks and symbolic regression for synergistic performance and interpretability", "authors": "Rogério Almeida Gouvêa,Pierre-Paul De Breuck,Tatiane Pretto,Gian-Marco Rignanese,Marcos José Leite dos Santos", "background": "在材料科学中，已经存在基于特征的方法（如MODNet）和图神经网络（GNN），但这些方法各有优势和局限。基于特征的方法透明度高，但预测能力有限；而GNN虽然预测能力强，但缺乏透明性。本研究旨在通过将基于特征的方法与GNN和符号回归结合起来，利用彼此的优势，提升预测性能，并提高模型的可解释性。", "innovation": "提出了一种名为MatterVial的创新性混合框架，用于材料科学中的基于特征的机器学习。MatterVial通过结合多种预训练的图神经网络模型（如结构基础、组成基础、对称性模型）以及计算效率高的GNN近似描述符和符号回归生成的新特征，扩展特征空间。此方法结合了传统基于特征模型的化学透明度和深度学习架构的预测能力。当应用于Matbench任务时，该方法显著降低了预测误差，提高了性能，甚至在某些情况下超越了最先进的端到端GNN。", "conclusion": "本研究通过提出MatterVial框架，提供了一个高性能且透明的工具，能够提高材料信息学中的预测能力和提供可解释性，这有助于更精确和自主的材料发现。"}
{"llm_update_time": "20250907", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.03533", "html_url": "https://arxiv.org/abs/2509.03533", "title": "LLM输入输出对中的主题识别通过信息瓶颈视角", "title_en": "Topic Identification in LLM Input-Output Pairs through the Lens of Information Bottleneck", "authors": "Igor Halperin", "background": "大型语言模型（LLMs）容易出现关键故障模式，如内在一致性的妄想（也称为虚构），即模型生成的回应在语义上偏离给定的上下文。现有的检测方法，比如语义偏移度量（SDM），依赖于识别提示和响应中共享的潜在主题，并通过应用几何聚类来表示句子的嵌入。这种方法存在断层，因为聚类优化的是空间邻近度，而不是针对下游的信息论分析。", "innovation": "本文通过使用确定性信息瓶颈（DIB）方法作为几何聚类的基础，填补了这一空白。文章的主要贡献在于将DIB方法转化为一种适用于高维数据的实用算法，通过用计算效率更高的上界替代其不可计算的KL散度项。这种方法，我们称之为UDIB，可以被解释为加了冗余项并且更稳健的K-means，倾向于具有信息量丰富的聚类。通过将UDIB应用于LLM提示和响应嵌入的联合聚类，生成了一个不仅仅空间上一致，而且实质上最大限度地阐明提示-响应关系的主题表示，为SDM框架提供了更好的基础，可以提供更为敏感的工具来检测虚构（妄想）现象。", "conclusion": "本文通过将DIB方法转化为UDIB算法，并应用于LLM的输入输出对的嵌入聚类中，生成了一个更优的主题表示，从而为SDM框架提供了一个更有针对性和敏感性的检测方法，能够更有效地识别潜在的虚构现象。"}
{"llm_update_time": "20250907", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.03537", "html_url": "https://arxiv.org/abs/2509.03537", "title": "AR$^2$: 对大型语言模型进行抽象推理的对抗性强化学习", "title_en": "AR$^2$: Adversarial Reinforcement Learning for Abstract Reasoning in Large Language Models", "authors": "Cheng-Kai Yeh,Hsing-Wang Lee,Chung-Hung Kuo,Hen-Hsen Huang", "background": "抽象能力是从复杂问题中识别和提炼出关键计算模式的能力，是计算机科学中的一项基础技能，对于人类问题解决者和面向编码的大型语言模型（LLMs）都是至关重要的。尽管最近在训练采用强化学习（RL）进行代码生成的LLM方面取得了进展，但大多数现有方法主要集中在表面模式识别上，忽视了对抽象能力的专门训练。因此，该研究提出了一种名为AR$^2$的新框架，旨在增强LLMs的抽象能力。AR$^2$框架通过教师模型将核心问题转化为具有丰富叙述的内容挑战性描述来使用，并同时训练学生编码模型以从这些复杂的叙述问题中提取其基本的计算核以求解。实验证明，AR$^2$显著提高了学生模型在先前未见过、具有挑战性的编程任务上的准确性，强调了抽象作为增强LLM泛化的关键技能的重要性。", "innovation": "该研究提出了AR$^2$框架，一种专为增强LLMs抽象能力而设计的对抗性强化学习方法。AR$^2$通过将问题转化为叙述丰富的形式来进行教学，同时训练学生模型提取重要计算模式，从而提升模型的抽象能力。这种方法基于对抗性强化学习机制，能够有效提升模型的抽象推理能力。", "conclusion": "AR$^2$实质上提高了LLMs在未见过的、具有挑战性的编程任务上的准确性，验证了抽象能力作为关键技能在提升LLM泛化上的重要作用。"}
{"llm_update_time": "20250907", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.03661", "html_url": "https://arxiv.org/abs/2509.03661", "title": "ACT: 自动化约束目标调整方法用于多目标推荐系统", "title_en": "ACT: Automated Constraint Targeting for Multi-Objective Recommender Systems", "authors": "Daryl Chang,Yi Wu,Jennifer She,Li Wei,Lukasz Heldt", "background": "推荐系统通常需要在最大化主要目标的同时确保次要目标满足最低阈值或'防护栏'。这对于保持一致的用户体验和平台生态系统非常重要，但在面对正交系统更改时强制执行这些防护栏是很困难的，往往需要手动调整超参数。", "innovation": "作者提出了自动化约束目标调整（ACT）框架，该框架自动找到满足这些防护栏所需的最小超参数更改集。ACT通过使用无偏数据进行离线成对评估来找到解决方案，并持续重新训练以适应系统和用户行为的变化。", "conclusion": "实证结果表明该方法的有效性，并描述了其在大型生产环境中的部署。"}
{"llm_update_time": "20250907", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.03617", "html_url": "https://arxiv.org/abs/2509.03617", "title": "通过量子极端学习机获取系外行星大气", "title_en": "Exoplanetary atmospheres retrieval via a quantum extreme learning machine", "authors": "Marco Vetrano,Tiziano Zingales,G.Massimo Palma,Salvatore Lorenzo", "background": "传统的系外行星大气研究依赖于前向模型，通过细调大量的化学和物理参数来计算行星光谱。然而，高维度参数空间常常导致显著的计算成本。本文介绍了利用量子极端学习机（QELMs）的新方法进行大气反演。QELMs是一种利用量子系统作为黑箱处理输入数据的量子机器学习技术。本文提出了一个利用QELMs提取系外行星大气特征的框架，采用适用于近期量子设备的内在容错策略，并在IBM Fez上直接实现了这种容错性。展示出了量子计算在处理天文数据集分析中的潜在价值，并可能在未来解锁快速、高效和更准确的系外行星大气建模工具。", "innovation": "提出了一种利用量子极端学习机（QELMs）进行大气反演的新方法，适用于近期量子设备的内在容错策略，并通过IBM Fez展示了这种容错性。", "conclusion": "量子计算框架在天文数据分析中的潜力被展示出来，并可能解锁快速、高效和更准确的系外行星大气建模工具。"}
{"llm_update_time": "20250907", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.03551", "html_url": "https://arxiv.org/abs/2509.03551", "title": "使用机器学习预测食源性病原体肠炎沙门氏菌的抗菌药物耐药性和成本负担分析", "title_en": "Predicting Antimicrobial Resistance (AMR) in Campylobacter, a Foodborne Pathogen, and Cost Burden Analysis Using Machine Learning", "authors": "Shubham Mishra, TheAnh Han,Bruno Silvester Lopes,Shatha Ghareeb,Zia Ush Shamszaman", "background": "抗菌药物耐药性（AMR）对公共卫生和经济构成了重大挑战，增加了治疗成本并降低了抗菌药物的有效性。本文通过机器学习分析来自公共数据库的基因组和流行病学数据（PubMLST）以及英国政府支持的食物标准局和食品标准苏格兰局的管理数据，对2001年至2017年从英国收集的肠炎沙门氏菌和结肠沙门氏菌分离株的耐药模式进行了研究。", "innovation": "整合了全基因组测序（WGS）数据、流行病学元数据和经济预测，以识别关键的耐药性决定因素，预测未来耐药趋势和医疗成本。通过建立基于随机森林的模型并使用自助抽样法进行验证，准确预测了AMR表型，并结合时间序列预测模型（SARIMA、SIR和Prophet）预测了到2050年病患病例数可能超过每10万人130例，若无人干预，将每年给经济带来19亿英镑以上的负担。通过分析6,683个分离株，引入了时间模式、不确定性估计和耐药性趋势建模，提高了预测准确性，显示了持续的高β-内酰胺耐药性、增加的氟喹诺酮耐药性和波动的四环素耐药性趋势。", "conclusion": "研究发现，肠炎沙门氏菌的耐药模式可预测，并通过机器学习方法能够有效进行预测，为医疗政策制定提供了科学依据，同时对未来的经济负担进行了预测分析，强调了加强对该菌耐药性管理的重要性。"}
{"llm_update_time": "20250907", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.03647", "html_url": "https://arxiv.org/abs/2509.03647", "title": "破镜之光：基于激活的LLM评估器自偏好缓解", "title_en": "Breaking the Mirror: Activation-Based Mitigation of Self-Preference in LLM Evaluators", "authors": "Dani Roytburg,Matthew Bozoukov,Matthew Nguyen,Jou Barzdukas,Simon Fu,Narmeen Oozeer", "background": "大型语言模型（LLMs）越来越多地作为自动化评估者使用，但它们存在‘自我偏好偏差’：即倾向于偏好自己的输出而非其他模型的输出。这种偏差影响了评估管道的公平性和可靠性，尤其是对于偏好调节和模型路由等任务。本文探讨了是否可以通过轻量级引导向量在推理时缓解这一问题，而不必重新训练。", "innovation": "本文引入了一个区分自我偏好偏差中的正当例和不当例的精心策划的数据集，并通过对比激活添加（CAA）和基于优化的方法来构建引导向量。结果显示，引导向量可以将不当的自我偏好偏差降低至97%，显著优于提示和直接偏好优化的基本方法。然而，引导向量在合法的自我偏好和无偏见一致方面不稳定，表明自我偏好可能涉及多个或非线性方向，强调了它们作为LLM作为裁判的保障手段的潜力与局限，进而推动了更可靠的干预手段的发展。", "conclusion": "引导向量可以减少超过97%的不正当自我偏好偏差，但它们在合法自我偏好和无偏见一致方面不稳定，表明自我偏好涉及多个或而非线性方向，这既强调了引导向量作为LLM-as-judges的保障手段的潜力，也指出了其局限性，需要进一步的研究以开发更稳健的干预措施。"}
{"llm_update_time": "20250907", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.03636", "html_url": "https://arxiv.org/abs/2509.03636", "title": "CausalARC: 基于因果世界模型的抽象推理", "title_en": "CausalARC: Abstract Reasoning with Causal World Models", "authors": "Jacqueline Maasch,John Kalantari,Kia Khezeli", "background": "推理能力要求模型在数据有限和分布偏移的情况下适应新的问题设置。本文介绍了一个实验测试平台CausalARC，用于AI在低数据和分布外情况下的推理，其灵感来源于抽象和推理语料库（ARC）。每个CausalARC推理任务都来源于一个全面指定的因果世界模型，形式上表示为结构因果模型。通过原理上数据增强，提供观察性、介入性和反事实反馈，形式为零样本、上下文学习示例。", "innovation": "提出了一种新的实验测试平台CausalARC，它基于因果世界模型来研究AI在低数据和分布外情况下的推理能力。它的创新点在于使用结构因果模型模拟真实世界，并通过原理上数据增强来提供观察性、介入性和反事实反馈，以促进模型的零样本和上下文学习能力。同时，它也通过多个语言模型评估场景展示了其实用性和有效性。", "conclusion": "本文提出了CausalARC实验测试平台，它提供了一个全新的框架来研究AI在因果世界中的抽象推理能力，在有限数据和分布偏移情况下，它能够通过模拟实际世界场景来评估模型的推理性能。这一平台的发展为未来研究提供了新视角和新的实验工具。"}
{"llm_update_time": "20250907", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.03622", "html_url": "https://arxiv.org/abs/2509.03622", "title": "使用多级迭代方法的准确且可扩展的深层麦克斯韦解算器", "title_en": "Accurate and scalable deep Maxwell solvers using multilevel iterative methods", "authors": "Chenkai Mao,Jonathan A. Fan", "background": "神经网络在作为代数偏微分方程（PDE）解算器方面具有潜力，但在高精度和可扩展性方面仍面临挑战。本文展示了如何将神经网络与迭代算法结合，以高精度解决不同尺度、分辨率和边界条件下的PDE问题。研究人员通过使用子域神经运算符模型并支持任意的Robin类型边界条件输入，开发了一种灵活的预条件器，用于解决带有界精度的子域问题，进而促进了基于迭代多重域分解来构建全局粗网格空间，实现了大规模PDE问题的加速求解。", "innovation": "开发了支持任意Robin类型边界条件输入的子域神经运算符模型；提出了一种灵活的预条件器来解决带有界精度的子域问题；通过迭代多级域分解构建全局粗网格空间，促进大规模PDE问题的加速求解；利用二维麦克斯韦方程组作为模型系统训练单个网络以模拟不同尺寸、分辨率、波长和介电分布的大规模问题；展示了该平台在准确反设计多波长纳米光子器件方面的实用性。", "conclusion": "本文为构建适用于大型实用问题的准确且可扩展的多物理场代数解算器提出了一种有前途的路径。"}
{"llm_update_time": "20250907", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.03725", "html_url": "https://arxiv.org/abs/2509.03725", "title": "MLSD: 基于度量学习的少样本学习方法以增强跨视角和跨领域立场检测", "title_en": "MLSD: A Novel Few-Shot Learning Approach to Enhance Cross-Target and Cross-Domain Stance Detection", "authors": "Parush Gera,Tempestt Neal", "background": "该研究提出了针对不同领域和目标的立场检测的新方法，通过使用基于度量学习的少样本学习（MLSD），旨在解决现有的立场检测模型在跨领域和跨目标场景下的挑战。现有的立场检测模型在处理新领域或新目标时通常表现不佳，而MLSD能够通过构造区分性嵌入空间，使跨目标或跨领域的立场检测模型能够从新的目标领域中获取有用样本，从而提升性能。", "innovation": "MLSD创新性地结合了度量学习和少样本学习，利用三重损失（triplet loss）来捕捉立场目标之间的语义相似性和差异性，从而增强领域适应性。这种方法不仅能有效提升模型在已知领域内的表现，还能使其更好地应用于未知或新领域的立场检测任务，无需大量标注数据。", "conclusion": "研究在两个数据集中的多个跨目标和跨领域场景下评估了MLSD，结果显示该方法显著提升了六种广泛使用的立场检测模型的性能。"}
{"llm_update_time": "20250907", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.03764", "html_url": "https://arxiv.org/abs/2509.03764", "title": "Pinterest 在大规模 Web 搜索评估中的基于大模型的相关性评估", "title_en": "LLM-based Relevance Assessment for Web-Scale Search Evaluation at Pinterest", "authors": "Han Wang,Alex Whitworth,Pak Ming Cheung,Zhenjie Zhang,Krishna Kamath", "background": "个性化搜索系统的相关性评估对于确保搜索结果与用户查询和意图一致至关重要。传统的相关性评估方法是人类标注，但其高成本和较长的周转时间限制了其可扩展性。", "innovation": "提出了在 Pinterest Search 中使用微调的大语言模型（LLM）自动进行相关性评估的方法，以支持在线实验。通过验证 LLM 生成的判断与人类标注之间的对齐，展示了 LLM 可以为实验提供可靠的相关性测量，同时大大提高评估效率。利用基于大模型的标注进一步解锁了扩展查询集、优化抽样设计以及大规模高效评估更广泛搜索体验的机会。", "conclusion": "此方法提高了相关性度量的质量并显著降低了在线实验测量中的最小可检测效应 (MDE)。"}
{"llm_update_time": "20250907", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.03772", "html_url": "https://arxiv.org/abs/2509.03772", "title": "高维节点协变量与网络结构之间相关性检验", "title_en": "Testing for correlation between network structure and high-dimensional node covariates", "authors": "Alexander Fuchs-Kreiss,Keith Levin", "background": "在许多应用场景中，网络观察到了节点级别的特征。在这种情况下，一个常见的问题是评估节点协变量是否与网络结构相关。目前，这种方法依赖于假设线性的模型来分析节点特征与网络结构的关系，但缺乏更灵活的方法来发现两者之间的关系。", "innovation": "本文提出了四种新颖的方法来解决这个问题。其中两种方法基于将节点级协变量与驱动网络结构的潜在节点变量联系起来的线性模型，另外两种方法则是通过将节点特征和网络结构应用典型相关分析来避免线性模型假设。所有方法都在低秩潜在空间模型生成的观测网络中提供了理论保证，允许节点特征的高维性。与以往的方法相比，本文的方法计算成本较低，需要的模型假设更少。", "conclusion": "本文通过理论证明和实际数据证明，作者提出的新方法在检验网络结构与高维节点协变量之间的相关性方面优于现有的方法，展现了该方法的优越性。"}
{"llm_update_time": "20250907", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.03780", "html_url": "https://arxiv.org/abs/2509.03780", "title": "自然潜在变量：不同概念框架下的潜变量稳定性", "title_en": "Natural Latents: Latent Variables Stable Across Ontologies", "authors": "John Wentworth,David Lorell", "background": "本文背景是关于两个贝叶斯代理各自学习同一环境的生成模型。假设两个代理已经收敛于预测分布，即环境中的某些可观察变量的分布，但它们可能具有不同的生成模型，含有不同的潜在变量。研究的问题是在什么条件下一个代理的潜在变量能够保证是另一个代理潜在变量的函数。", "innovation": "本文的研究创新点在于提出了“自然潜在条件”的简单条件，在这些条件下可以保证潜在变量之间的翻译可实现。同时证明了在没有进一步约束的情况下，这些是潜在变量可控性可实现的最一般条件。此外，本文的关键贡献在于证明这些定理对于自然潜在条件的近似误差具有鲁棒性。", "conclusion": "研究结论是，自然潜在条件下的定理对于实际应用是稳健的，它能够保证在近似误差范围内潜在变量之间的可控性。"}
{"llm_update_time": "20250907", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.03730", "html_url": "https://arxiv.org/abs/2509.03730", "title": "LLM 人格幻象：揭示 LLM 自我报告与行为间的分离", "title_en": "The Personality Illusion: Revealing Dissociation Between Self-Reports & Behavior in LLMs", "authors": "Pengrui Han,Rafal Kocielnik,Peiyang Song,Ramit Debnath,Dean Mobbs,Anima Anandkumar,R. Michael Alvarez", "background": "人格特质的研究已经表明人类具有一定的预测能力。近来，大型语言模型（LLMs）的发展也显示出了类似的模式，这些模型展示了与人类特质（如和蔼和自我调节）相类似的稳定行为倾向。尽管如此，先前的工作主要依赖简单的自我报告和启发式提示，很少有实证行为验证。本文通过对三个维度（训练阶段内性格特征的变化和演化、自我报告特质在行为任务中的预测有效性以及目标干预对自我报告和行为的影响）的系统性研究，探讨 LLM 的人格特征。", "innovation": "本文首次系统地研究了 LLM 的人格特征，通过多维度分析（1）性格特征在训练阶段的变化和演变；（2）自我报告特质在行为任务中的预测有效性；（3）目标干预（如角色注入）对自我报告和行为的影响。本研究发现，指令对齐 （例如，RLHF，指令调优）显著稳定了性格表达并增强了与人类数据相似的性格相关性。然而，自我报告的性格特质并不能可靠地预测行为，且观察到的关系常与人类模式背道而驰。研究揭示，尽管角色注入成功引导了自我报告方向，但对实际行为影响甚微。通过区分表面的性格表现和行为一致性，本研究挑战了关于 LLM 人格特征的一些假设，并强调了在对齐和可解释性方面进行更深入评估的必要性。", "conclusion": "本文揭示了 LLM 自我报告与实际行为之间存在分离的现象，说明现有评估方法可能不足以准确反映 LLM 的真正性格特征。因此，未来的研究应侧重于更深入的评估和对齐，并需增强对 LLM 行为可靠性的理解。"}
{"llm_update_time": "20250907", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.03769", "html_url": "https://arxiv.org/abs/2509.03769", "title": "数据驱动的动态系统建模中等效方程法的局限性", "title_en": "Deficiency of equation-finding approach to data-driven modeling of dynamical systems", "authors": "Zheng-Meng Zhai,Valerio Lucarini,Ying-Cheng Lai", "background": "通过数据寻找支配方程的稀疏优化方法已成为确定性建模动态系统的流行方法。然而，在存在扰动和测量误差的情况下，这些方法在物理情况下的模型往往高度依赖于测量过程，但所有模型生成的混沌吸引子几乎相同，这一现象挑战了复杂动态系统基于方程的传统建模观念。通过对科普曼频谱的研究发现，不同的方程组在其大特征值上是一致的，只有当特征值小于方程依赖的阈值时，才会出现差异。这表明，找到系统的支配方程并尝试从物理角度进行解释可能导致误导性的结论。在没有方程的情况下直接处理可用数据，如使用机器学习方法将更具用处。", "innovation": "通过分析广泛使用的稀疏优化方法在混沌系统中的局限性，指出这些方法会产生高度依赖于测量过程的模型，尽管生成的混沌吸引子几乎相同。通过计算科普曼频谱进行深入研究，探讨了不同支配方程组之间的差异，并得出了在复杂动态系统中直接使用数据进行建模比寻找支配方程更有效的方法。", "conclusion": "数据驱动的建模中直接使用数据的方法比寻找支配方程更有效。找到系统的支配方程并尝试从物理角度进行解释可能导致误导性的结论。"}
{"llm_update_time": "20250907", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.03816", "html_url": "https://arxiv.org/abs/2509.03816", "title": "通过微调AI基础模型开发亚网格尺度参数化方法：大气重力波案例研究", "title_en": "Finetuning AI Foundation Models to Develop Subgrid-Scale Parameterizations: A Case Study on Atmospheric Gravity Waves", "authors": "Aman Gupta,Aditi Sheshadri,Sujit Roy,Johannes Schmude,Vishal Gaur,Wei Ji Leong,Manil Maskey,Rahul Ramachandran", "background": "全球气候模型参数化了一系列诸如重力波、云、湿对流和湍流等大气-海洋过程，但无法充分解析。未解析过程的亚网格尺度闭合是模型不确定性的主要来源。在气候研究中，AI基础模型（FMs）尚未广泛探索。本研究通过微调一个预训练的AI基础模型，来开发大气重力波的深度学习参数化方法。", "innovation": "研究提出了通过微调AI基础模型（FMs）来开发大气重力波的亚网格尺度参数化的新方法。研究使用了NASA和IBM Research的Prithvi WxC模型的预训练编码器-解码器，该模型包含大气演化的潜在概率表示。该方法通过学习10倍高分辨率大气再分析资料中的通量，来为粗分辨率气候模型捕捉重力波效果。结果显示，与基于注意机制的U-Net模型相比，微调后的模型在大气中的预测性能更强，特别是在预训练中未覆盖的区域。", "conclusion": "研究发现AI基础模型具有灵活性和重用性，可以用于多种大气和气候应用，有助于创建观察驱动和物理准确的参数化方法，用于更多地球系统过程。微调后的模型在Hellinger距离上表现出更好的性能，为细分辨地球系统过程参数化提供了新的途径。"}
{"llm_update_time": "20250907", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.03839", "html_url": "https://arxiv.org/abs/2509.03839", "title": "未知非线性动态的蓄水库预测路径积分控制", "title_en": "Reservoir Predictive Path Integral Control for Unknown Nonlinear Dynamics", "authors": "Daisuke Inoue,Tadayoshi Matsumori,Gouhei Tanaka,Yuji Ito", "background": "神经网络能够近似复杂非线性关系，在数据驱动的非线性动态系统控制中得到了广泛应用。然而，在线快速识别未知动力学并进行控制依然是主要挑战。", "innovation": "提出了一种新的蓄水库预测路径积分控制（RPPI）方法，结合了回声状态网络（ESN）和基于模型预测控制的采样版本（MPPI）。RPPI能够快速学习非线性动力学，并在并行化MPPI控制计算中直接利用学习到的非线性特征而无需线性化近似。进一步，引入了不确定性感知RPPI（URPPI），利用ESN的不确定性在探索和开发之间实现平衡。", "conclusion": "实验结果显示，URPPI相比于基于二次规划的传统模型预测控制方法，能够显著减少控制成本，最多可减少60%。"}
{"llm_update_time": "20250907", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.03726", "html_url": "https://arxiv.org/abs/2509.03726", "title": "能量加权流匹配：解锁高效可扩展的博尔兹曼采样", "title_en": "Energy-Weighted Flow Matching: Unlocking Continuous Normalizing Flows for Efficient and Scalable Boltzmann Sampling", "authors": "Niclas Dern,Lennart Redl,Sebastian Pfister,Marcel Kollovieh,David Lüdke,Stephan Günnemann", "background": "从无归一化目标分布中采样，例如玻尔兹曼分布 μ_目标(x) ∝ exp(-E(x)/T)，在许多科学应用中是基础但计算上具有挑战性，因为复杂的高维能量景观使得采样变得困难。现有的应用现代生成模型的方法要么需要大量从目标分布中抽取的样本，要么仅使用能量评估进行训练时无法高效利用如连续归一化流等高级架构的表达能力，连续归一化流已经显示出在分子采样中的潜力。", "innovation": "本文介绍了能量加权流匹配 (EWFM)，这是一种新颖的训练目标，使得连续归一化流能够仅通过能量函数评估来模拟玻尔兹曼分布。该目标通过重要性采样重述条件流匹配，允许使用任意提议分布的样本进行训练。基于该目标，开发了两种算法：迭代 EWFM (iEWFM)，该算法通过迭代训练逐渐细化提议，并且在具有挑战性的能量景观上，加入了温度退火的annealed EWFM (aEWFM)。", "conclusion": "在包括具有挑战性的55个粒子Lennard-Jones簇在内的基准系统上，我们的算法显示出了与最先进的仅能量方法相当的样本质量，同时只需要少至三个数量级的能量评估。"}
{"llm_update_time": "20250907", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.03898", "html_url": "https://arxiv.org/abs/2509.03898", "title": "扩散生成模型与压缩传感相遇，应用于图像数据和金融时间序列", "title_en": "Diffusion Generative Models Meet Compressed Sensing, with Applications to Image Data and Financial Time Series", "authors": "Zhengyi Guo,Jiatu Li,Wenpin Tang,David D. Yao", "background": "本文提出了在合成数据生成背景下加速扩散模型推理的降维技术。将压缩传感技术整合到扩散模型中，通过将数据压缩到潜在空间、在潜在空间中训练扩散模型以及应用压缩传感算法来提高模型训练和推理的效率。", "innovation": "提出了一种结合扩散模型推理和稀疏恢复的算法，在适合的数据稀疏假设下，该算法能够更快地收敛。作为副产品，确定了潜在空间维数的最优值。此外，该研究还在图像数据（手写数字、医学图像、气候数据）和金融时间序列上进行了数值实验。", "conclusion": "在假设数据具有适当稀疏性的情况下，通过结合扩散模型推理和稀疏恢复，所提出的方法显示出更快的收敛速度。潜在空间维数的选择为优化模型性能提供了依据，并在多种数据类型上进行了验证。"}
{"llm_update_time": "20250907", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.03846", "html_url": "https://arxiv.org/abs/2509.03846", "title": "硬件感知的数据与指令映射以平衡AI任务的并行性、输入/输出和存储器权衡", "title_en": "Hardware-Aware Data and Instruction Mapping for AI Tasks: Balancing Parallelism, I/O and Memory Tradeoffs", "authors": "Md Rownak Hossain Chowdhury,Mostafizur Rahman", "background": "现有深度学习推理框架通常依赖于主机频繁的控制和大量外部存储器使用，这导致了输入/输出(I/O)开销和外部存储器使用率的增加，同时也限制了计算吞吐量。", "innovation": "提出了一个映射框架，利用可预测的神经网络行为，提前规划计算与通信。该框架生成了一个统一的指令和数据流，使得硬件能够自主执行操作和路由信息，减少了频繁的主机干预，并且减少了外部存储器的使用。通过利用可编程的、基于消息的计算架构的细粒度消息传递和局部通信技术，减少了数据移动，并优化了计算。", "conclusion": "应用于VGG-19，该框架保持了高利用率（88%到92%），超过97%的消息在内部生成，几乎89%的时间用于片上传输。在更大阵列上计算吞吐量超过1 TFLOP/s，通过重用和局部聚集减少了高达100 MB/层的流量。结果强调了基于流的计算的有效性，展示了此映射器在硬件上协调数据和指令流如何实现这种执行风格。"}
{"llm_update_time": "20250907", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.03889", "html_url": "https://arxiv.org/abs/2509.03889", "title": "基于密度意识对应和视触觉功能的反应式空中服装操作", "title_en": "Reactive In-Air Clothing Manipulation with Confidence-Aware Dense Correspondence and Visuotactile Affordance", "authors": "Neha Sunil,Megha Tippur,Arnau Saumell,Edward Adelson,Alberto Rodriguez", "background": "操纵服装具有挑战性，因为服装具有复杂的配置、多变的材料动态特性以及频繁的自遮挡现象。现有的系统通常会压平衣物或假定关键特征的可见性。", "innovation": "作者提出了一种双臂视触觉框架，该框架结合了基于置信度的大范围视觉对应关系和基于触觉的抓取功能监督，可以直接操作折叠和悬挂的衣物。该框架的关键创新在于使用一个可以捕捉布料对称性的定制高保真模拟数据集训练对应的模型，并利用分布损失生成对应关系的置信度估计。这些估计值指导一个反应性状态机，根据感知不确定性来调整折叠策略。该框架还使用自监督触觉反馈来确定哪些区域是物理上可抓取的，并在执行期间实时验证抓取。通过在低置信度状态下延迟行动，该系统可以处理高度遮挡的桌面和空中配置。", "conclusion": "作者展示了其任务无关的抓取选择模块在折叠和挂置任务中的应用，并表明其密集描述符可以作为其他规划模态的可重用中间表示，例如从人类视频示范中提取抓取目标，为更通用和可扩展的服装操纵铺平道路。"}
{"llm_update_time": "20250907", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.03899", "html_url": "https://arxiv.org/abs/2509.03899", "title": "离散时间控制屏障函数的有效认证", "title_en": "Sample Efficient Certification of Discrete-Time Control Barrier Functions", "authors": "Sampath Kumar Mulagaleti,Andrea Del Prete", "background": "控制不变（CI）集对于验证动态系统的安全性至关重要。控制障碍函数（CBFs）是计算这类集的重要工具，但计算CBFs通常涉及解决复杂的鲁棒优化问题，这往往是不可行的。为简化计算，已提出基于场景的方法。然而，在使用CBFs之前，还需要验证其是否满足鲁棒约束条件。", "innovation": "本文提出了一种依靠Lipschitz参数来进行验证的方法，并基于此方法设计了一种认证算法，旨在提高样本效率。该研究通过一个数值示例验证了所提出方法的有效性。", "conclusion": "文章展示了如何通过Lipschitz参数来验证CBFs是否满足鲁棒约束，从而形成一种样本高效的认证算法。实验证明了该方法的有效性。"}
{"llm_update_time": "20250907", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.03972", "html_url": "https://arxiv.org/abs/2509.03972", "title": "通过韩语案例研究扩大开源大规模语言模型的基础语言能力", "title_en": "Expanding Foundational Language Capabilities in Open-Source LLMs through a Korean Case Study", "authors": "Junghwan Lim,Gangwon Jo,Sungmin Lee,Jiyoung Park,Dongseok Kim,Jihwan Kim,Junhyeok Lee,Wai Ting Cheung,Dahye Choi,Kibong Choi,Jaeyeon Huh,Beomgyu Kim,Jangwoong Kim,Taehyun Kim,Haesol Lee,Jeesoo Lee,Dongpin Oh,Changseok Song,Daewon Suh", "background": "介绍了Llama-3-Motif语言模型，拥有102亿参数，专门设计用于提升韩语能力同时保持英文性能，基于Llama 3架构，采用先进的训练技术如LlamaPro和Masked Structure Growth，在大规模GPU集群上进行高效训练。使用精心挑选的数据集优化该模型，维持了韩语和英文数据的平衡比例。", "innovation": "该模型采用了LlamaPro和Masked Structure Growth等先进训练技术，并且在大规模GPU集群上通过MoAI平台进行高效训练，维持了韩语和英文数据的平衡比例。模型显示在特定韩语文本评估中的表现良好，相比现有模型更优秀，接近GPT-4的性能。", "conclusion": "Llama-3-Motif展示了韩语文本评估中的良好表现，并在竞争中超越了现有的同类产品，展现了在开源大规模语言模型上的显著进步。"}
{"llm_update_time": "20250907", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.03910", "html_url": "https://arxiv.org/abs/2509.03910", "title": "可逆生成模型在正向和反向问题中的应用", "title_en": "An invertible generative model for forward and inverse problems", "authors": "Tristan van Leeuwen,Christoph Brune,Marcello Carioni", "background": "本文将逆问题置于贝叶斯框架中，目标是训练一个生成模型，该模型可以用于模拟（即从似然中采样）和推理（即从后验中采样）。文章回顾了在这一背景下使用三角正规范化流进行条件采样的做法，展示了如何将两个这样的三角映射（一个上三角映射和一个下三角映射）组合成一个可逆映射，用于模拟和推理。进一步探讨了这个可逆生成模型的一些实用性质，并提出了一种可能的训练损失函数，用于直接训练映射。最后，通过一些设计的示例，说明了该新方法在条件生成建模中的工作原理。", "innovation": "提出了一个可逆生成模型来解决正向和逆向问题，并使用三角正规范化流组合两个三角映射，从而实现模拟和推理。并且提出了一种直接训练这种可逆映射的损失函数。", "conclusion": "通过数值示例，展示了这种方法在条件生成建模中的有效性和应用。"}
{"llm_update_time": "20250907", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.03939", "html_url": "https://arxiv.org/abs/2509.03939", "title": "LMAE4Eth: 通过探索交易语义和掩码图嵌入实现通用和稳健的以太坊欺诈检测", "title_en": "LMAE4Eth: Generalizable and Robust Ethereum Fraud Detection by Exploring Transaction Semantics and Masked Graph Embedding", "authors": "Yifan Jia,Yanbin Wang,Jianguo Sun,Ye Tian,Peng Qian", "background": "当前的以太坊欺诈检测方法依赖于上下文无关的数值交易序列，未能捕捉到账户交易的语义。此外，以太坊交易记录的普遍同质性使得学习区分性账户嵌入变得困难。当前的自监督图学习方法主要通过图重建来学习节点表示，这在节点级任务如欺诈账户检测方面表现不佳，同时这些方法还面临可扩展性的挑战。", "innovation": "该文提出了一种多视图学习框架LMAE4Eth，融合了交易语义、掩码图嵌入和专家知识。引入了交易-令牌对比语言模型（TxCLM），将上下文无关的数值交易记录转换为逻辑上一致的语言表示。通过采用标记感知对比学习预训练目标和掩码交易模型预训练目标，学习到高表达性的账户表示。还提出了生成自监督学习的掩码账户图自编码器（MAGAE），专注于重建账户节点特征，从而实现优秀的节点级账户检测性能。为了使MAGAE能够 scalable，在图中引入层-邻居采样，通过减少采样顶点的数量来提高训练质量而不损害训练质量。最后，采用了跨注意力融合网络来统一TxCLM和MAGAE的嵌入，充分利用两者的优势。", "conclusion": "在三个数据集上与21种基线方法进行评估，实验结果显示，该方法在两个数据集上的F1分数超过了最好的基线方法超过10%。"}
{"llm_update_time": "20250907", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.04063", "html_url": "https://arxiv.org/abs/2509.04063", "title": "平衡信号与方差：VLA流模型的自适应离线RL后训练", "title_en": "Balancing Signal and Variance: Adaptive Offline RL Post-Training for VLA Flow Models", "authors": "Hongyin Zhang,Shiyuan Zhang,Junxi Jin,Qixin Zeng,Yifan Qiao,Hongchao Lu,Donglin Wang", "background": "基于流匹配的视觉-语言-动作（VLA）模型已经在通用机器人操作任务中表现出色，但这些模型在复杂下游任务中的动作精度不够理想。重要的原因之一是这些模型仅依赖于模仿学习后的训练范式，难以深入理解数据质量分布特性，而强化学习（RL）恰好擅长处理这一点。", "innovation": "本文理论上提出了VLA流模型的离线RL后训练目标，并设计了一种有效的自适应离线RL微调算法——自适应强化流匹配（ARFM）。通过在VLA流模型损失中引入自适应调整的比例因子，构建了一个合理的偏差-方差trade-off目标函数以最优地控制RL信号对流损失的影响。ARFM自适应平衡RL优势保留和流损失梯度方差控制，从而实现更稳定的和高效的微调过程。", "conclusion": "广泛的模拟和现实世界实验结果表明，ARFM展示了卓越的泛化、鲁棒性、少次学习和持续学习性能。"}
{"llm_update_time": "20250907", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.03734", "html_url": "https://arxiv.org/abs/2509.03734", "title": "假设选择：高概率难题", "title_en": "Hypothesis Selection: A High Probability Conundrum", "authors": "Anders Aamand,Maryam Aliakbarpour,Justin Y. Chen,Sandeep Silwal", "background": "在假设选择问题中，我们给定一组候选分布（假设）$\boldsymbol{\text{H}} = \boldsymbol{\text{H}_1, \text{H}_2, \text{..., \text{H}_n}}$，以及来自未知分布$P$的样本。我们的目标是找到一个假设$\text{H}_i$，其与$P$的总变差距离（total variation distance）与$\boldsymbol{\text{H}}$中最近假设的距离相似。如果最优距离是$\boldsymbol{\text{OPT}}$，我们希望输出一个$\text{H}_i$，使得在至少$1-\boldsymbol{\text{δ}}$的概率下，其与$P$的总变差距离最多等于$\boldsymbol{\text{C}} \times \boldsymbol{\text{OPT}} + \boldsymbol{\text{ε}}$。尽管已经研究了数十年，但该问题的关键方面仍悬而未决，特别是实现最优样本复杂性和最佳近似因子$\boldsymbol{\text{C}}=3$的算法的最优运行时间尚未解决。此前的最佳结果是在近线性于$n$的时间复杂度下运行，但对其他参数的依赖性不理想。", "innovation": "我们改进了时间复杂度到$\tilde{O}(n/(\boldsymbol{\text{δ}} \boldsymbol{\text{ε}}^2))$，显著减少了信任度和误差参数的依赖性。此外，我们还研究了三种不同的假设选择设置，并解决了多个先前工作中的开放问题：（1）我们在输出假设的期望距离而非高概率性能时解决了最优近似因子；（2）假设$\boldsymbol{\text{OPT}}$的数值是预先知道的，我们展示了最优样本复杂性且运行时间$\tilde{O}(n/\boldsymbol{\text{ε}}^2)$的算法，且以高概率成功；（3）允许在观察样本之前对假设类别$\boldsymbol{\text{H}}$执行多项式预处理步骤，我们展示了最优近似因子$C=3$且运行时间亚二次的算法，且以高概率成功，在样本数量$n$下成功。", "conclusion": "我们通过改进时间复杂度和解决了多种假设选择设置中的开放问题，提升了算法效率和理论理解。"}
{"llm_update_time": "20250907", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.03992", "html_url": "https://arxiv.org/abs/2509.03992", "title": "Divergence-Kernel方法及其在线性响应和扩散模型中的应用", "title_en": "Divergence-Kernel method for linear responses and diffusion models", "authors": "Angxiu Ni", "background": "本文旨在推导随机动力系统的线性响应（参数对边缘分布或稳态分布的导数）的发散核公式，并在长时间尺度上形式化该公式过渡到连续时间。文中指出，该公式适用于任意时间段的乘性参数噪声，不需要假设系统的双曲性。此外，还提出了一种路径上的蒙特卡洛算法以计算线性响应，基于此提出了一种单向扩散生成模型，并在简单问题上进行了测试。", "innovation": "本文的创新点在于推导了适用于任意时间段和乘性噪声的随机动力系统线性响应的发散核公式；提出了计算线性响应的路径式蒙特卡洛算法；基于此提出了单向的扩散生成模型。", "conclusion": "本文通过推导随机系统线性响应的发散核公式，并提出相应的算法和模型，提供了一种计算有限时序差分熵的手段，并在简单问题上验证了该方法的有效性。"}
{"llm_update_time": "20250907", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.04047", "html_url": "https://arxiv.org/abs/2509.04047", "title": "TensoIS：向基于拉东噪声分布的前馈逆向次表面散射迈出一步", "title_en": "TensoIS: A Step Towards Feed-Forward Tensorial Inverse Subsurface Scattering for Perlin Distributed Heterogeneous Media", "authors": "Ashish Tiwari,Satyam Bhardwaj,Yash Bachwana,Parag Sarvoday Sahu,T.M.Feroz Ali,Bhargava Chintalapati,Shanmuganathan Raman", "background": "估测不均匀介质的散射参数是一个严重欠定且具有挑战性的问题。目前大多数方法通过分析-合成方法建模BSRDF，逼近复杂的路径积分，或使用可微体积渲染技术来处理不均匀性。然而，很少有研究应用基于学习的方法来估计次表面散射参数，且这些方法大多假设均质介质。此外，目前文献中尚未有任何明确的分布可以明确地表示真实世界的不均匀散射参数。因此，本文利用程序化噪声模型（如Perlin噪声和分形Perlin噪声），创建了HeteroSynth数据集，用于合成不均匀介质的光现实图像，并首次提出了一种名为Tensorial Inverse Scattering (TensoIS)的学习导向前馈框架，用于从稀疏多视图图像观测中估计分形Perlin分布下的不均匀散射参数。该研究旨在探索分形Perlin噪声分布，以期在前馈框架中潜在地建模现实世界的不均匀散射。", "innovation": "1. 提出了HeteroSynth数据集，包含用分形Perlin噪声建模参数的不均匀介质的光现实图像。2. 首次引入Tensorial Inverse Scattering (TensoIS)框架，利用可学习的低秩张量组件，从有限的多视角图像观测中估计不均匀介质的分形Perlin分布散射参数。3. TensoIS无需直接预测3D散射参数体积，而是推断尽量减少参数的低秩张量来表示散射体积，这为不均匀介质的逆向散射提供了新颖的方法。", "conclusion": "通过在HeteroSynth测试集中、由开源真实体积模拟得出的烟雾和云几何形状以及若干真实世界样本上进行评估，证明TensoIS框架的有效性。此研究代表了在前馈框架中探索分形Perlin噪声分布以潜在地建模真实世界不均匀散射迈出的重要一步。"}
{"llm_update_time": "20250907", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.03932", "html_url": "https://arxiv.org/abs/2509.03932", "title": "探索韩国现代诗中的情感语言编码：来自人工标注数据集和AI建模的见解", "title_en": "Decoding the Poetic Language of Emotion in Korean Modern Poetry: Insights from a Human-Labeled Dataset and AI Modeling", "authors": "Iro Lim,Haein Ji,Byungjun Kim", "background": "虽然基于大规模语言模型的文本情感分类已经取得了显著进展，但诗歌，特别是韩国诗歌，由于其修辞语言和文化特异性，仍然被探索不足。本文介绍了一个用于现代韩国诗歌计算情感分析的新数据集KPoEM (Korean Poetry Emotion Mapping)，旨在填补这一研究空白。", "innovation": "本文构建了一个包含7,662个条目的多标签情感数据集，其中7,007个线条级条目来自483首诗歌，615个工作级条目，并且使用了44个细微的情感类别，这些类别来自五位有影响力的韩国诗人。本文还提出了一种基于该数据集微调的最新韩国语言模型，该模型显著优于过去使用通用语料库训练的模型，在微小F1值上达到了0.60，从前值0.34，展示了增强的识别时间和文化特定情感表达的能力，以及稳固保留现代韩国诗歌核心情感的能力。", "conclusion": "本文连接了计算方法和文学分析，通过结构性数据深入探讨了情感在韩国文学中的定量研究的可能性，这些数据忠实保留了情感和文化的细微差别。"}
{"llm_update_time": "20250907", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.04133", "html_url": "https://arxiv.org/abs/2509.04133", "title": "变分不等式中的洗牌启发式方法：建立新的收敛保证", "title_en": "Shuffling Heuristic in Variational Inequalities: Establishing New Convergence Guarantees", "authors": "Daniil Medyakov,Gleb Molodtsov,Grigoriy Evseev,Egor Petrov,Aleksandr Beznosikov", "background": "变分不等式在机器学习和优化领域受到了广泛关注。目前，解决变分不等式问题的随机方法通常假设数据样本是独立的。然而，本文通过研究洗牌启发式方法提供了一个新的策略。这种策略包括在顺序处理前对数据集进行洗牌，从而保证所有数据点都能被同等考虑。尽管洗牌在实践中具有显著的好处，但在变分不等式中对洗牌的理论保证尚未被研究。本文填补了这一空白，首次为变分不等式中的洗牌方法提供理论收敛估计。", "innovation": "本文针对变分不等式中的洗牌启发式方法提供了首个理论收敛保证，建立了严格的界限和收敛率，为这一重要类算法的理论框架做出了扩展贡献。", "conclusion": "通过在各种变分不等式基准问题上的广泛实验验证本文理论，表明洗牌方法相比独立采样方法具有更快的收敛速度。"}
{"llm_update_time": "20250907", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.04193", "html_url": "https://arxiv.org/abs/2509.04193", "title": "DUDE：基于扩散的无监督跨域图像检索", "title_en": "DUDE: Diffusion-Based Unsupervised Cross-Domain Image Retrieval", "authors": "Ruohong Yang,Peng Hu,Yunfan Li,Xi Peng", "background": "跨域图像检索（UCIR）的目标是在没有标注信息的情况下，在不同的领域中检索相同类别的图像。现有方法经常难以处理域间差异，因为用于检索的关键对象特征往往会与领域特异性风格一同纠缠。为了解决这个问题，本文提出了一种新的无监督跨域图像检索方法DUDE，该方法基于特征解纠缠。", "innovation": "DUDE通过利用文本到图像生成模型解缠物体特征和领域特定风格，从而实现语义图像检索。为了进一步实现解纠缠物体特征的可靠对齐，DUDE采取逐步的方式，将域内邻居对齐到跨域邻居。", "conclusion": "通过在三个基准数据集上的全面实验，DUDE在13个领域中达到了最先进的性能。代码将被公开。"}
{"llm_update_time": "20250907", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.03986", "html_url": "https://arxiv.org/abs/2509.03986", "title": "Promptception: 大型多模态模型对提示有多敏感？", "title_en": "Promptception: How Sensitive Are Large Multimodal Models to Prompts?", "authors": "Mohamed Insaf Ismithdeen,Muhammad Uzair Khattak,Salman Khan", "background": "虽然近年来大型多模态模型（LMMs）在多项选择题问答（MCQA）方面取得了成功，但其提示设计仍然缺乏理解。不同的提示措辞和结构变化可能导致某些提示和模型的准确率偏差高达15%。这种变化性在透明和公正地评估LMMs方面提出了挑战，因为模型通常会报告其最佳表现，使用精心选择的提示。为了应对这一挑战，本文提出了Promptception，这是一种系统框架，用于评估LMMs对提示的敏感性。该框架包含61种提示类型，覆盖15个类别和6个超类别，并被用于评估10种LMMs，包括从轻量级开源模型到GPT-4o和Gemini 1.5 Pro，共涵盖3个MCQA基准：MMStar、MMMU-Pro和MVBench。研究发现，专有的模型在提示措辞方面更加敏感，反映出它们与指令语义的更紧密对齐，而开源模型则更加稳定但难以应对复杂和细微的措辞。", "innovation": "本文提出了Promptception，这是一种系统框架，用于评估LMMs在多个类别和超类别中的61种提示类型，涵盖了LMMs对提示的敏感性。通过这种方法，文章揭示了不同模型在提示敏感性方面存在差异，为优化prompt设计提供了新视角，有助于模型评估的透明性和公平性。", "conclusion": "基于这些分析，本文提出了针对专有和开源LMMs的提示规则，旨在提高模型评估的稳健性和公平性。"}
{"llm_update_time": "20250907", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.04194", "html_url": "https://arxiv.org/abs/2509.04194", "title": "批量随机匹配强化学习", "title_en": "Batched Stochastic Matching Bandits", "authors": "Jung-hun Kim,Min-hwan Oh", "background": "在这一研究中，我们基于多项式对数（MNL）选择模型引入了一种新颖的多臂赌博机（bandit）框架应用于随机匹配问题。在一个设置中，一对一方有N个代理（agents），另一方有K个臂（arms）。每个臂按照未知偏好随机从分配的池中选择一个代理，并根据匹配结果得到相应的奖励。目标是最小化遗憾，通过最大化所有代理成功匹配的累积收入。该问题需要基于估计的偏好解决一个组合优化问题，对于大规模问题来说是NP-hard的，会导致传统方法每次轮次的计算成本为O(K^N)。", "innovation": "我们提出了批量算法来限制匹配更新的频率，从而将每轮的平均计算成本降低到O(1)，同时仍能获得遗憾界为~O(√T)的效果。", "conclusion": "该研究提供了一种新的带批量更新机制的多臂赌博机框架，用于解决基于MNL选择模型的随机匹配问题，并通过理论分析证明了该方法的有效性和效率。"}
{"llm_update_time": "20250907", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.04089", "html_url": "https://arxiv.org/abs/2509.04089", "title": "使用广义Wasserstein距离和最优传输：从指派问题到概率数值方法", "title_en": "Gromov-Wasserstein and optimal transport: from assignment problems to probabilistic numeric", "authors": "Iman Seyedi,Antonio Candelieri,Enza Messina,Francesco Archetti", "background": "指派问题作为运筹学的核心问题，旨在找到一组最优的代理与任务的一对一映射，以最小化总成本。本文回顾了从经典形式到现代最优传输理论的发展过程，并将二次指派问题（QAP）及相关结构匹配任务置于这一框架中。论文通过Monge的传输问题、Kantorovich的松弛方法和Wasserstein距离将线性指派问题与其连接起来，进一步推广至需要Gromov-Wasserstein距离不同度量空间的情形。GW框架，包括融合GW变体，通过优化基于域内距离和跨域属性的对齐来自然解决QAP类似问题。此类应用包括图匹配、关键点对应以及基于特征的指派。", "innovation": "提出了几种最优传输和GW变体的计算方法，包括广义GW多重初始化（GW-MultiInit）策略，该策略可以降低陷入局部最优的风险，同时结合了熵SINKhorn近似和融合GW。计算实验证实GW-MultiInit方法可以在大规模问题中高效地实现接近最优的解决方案，EGW和FGW方法则提供了在精度和运行时间之间灵活平衡的选项。", "conclusion": "本文为将OT和GW方法应用于QAP和其他实际匹配问题提供了理论基础、计算见解和实践指南，这些匹配问题在机器学习和物流等领域中普遍存在。"}
{"llm_update_time": "20250907", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.04317", "html_url": "https://arxiv.org/abs/2509.04317", "title": "提高AlphaZero算法在测试时环境变化中的稳健性", "title_en": "Improving Robustness of AlphaZero Algorithms to Test-Time Environment Changes", "authors": "Isidoro Tamassia,Wendelin Böhmer", "background": "AlphaZero框架提供了一种结合蒙特卡洛规划和之前训练的策略-值神经网络提供的先验知识的标准方法。AlphaZero通常假设在测试时环境不会改变，这限制了其应用范围。本文分析了在可能发生环境变化的测试环境中部署AlphaZero代理的问题，并展示了如何通过对标准框架进行简单的修改显著提升性能，即使在可用规划预算较低的情况下也能取得良好效果。", "innovation": "本文提出了一种提高AlphaZero算法在测试时环境变化适应性的方法，通过简单的框架修改显著提升了性能，尤其是在预算有限的情况下。", "conclusion": "本文展示了通过简单修改将AlphaZero扩展到动态环境中的可行性，提高了AlphaZero在实际应用中的灵活性和鲁棒性，并且相关代码已经公开发布在GitHub上以供进一步研究和验证。"}
{"llm_update_time": "20250907", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.04210", "html_url": "https://arxiv.org/abs/2509.04210", "title": "COBRA:基于腕戴多模态传感器的远程慢性肥胖管理深度学习框架", "title_en": "COBRA: Multimodal Sensing Deep Learning Framework for Remote Chronic Obesity Management via Wrist-Worn Activity Monitoring", "authors": "Zhengyang Shen(1),Bo Gao(1),Mayue Shi(1, 2) ((1) Department of Electrical and Electronic Engineering, Imperial College London, UK, (2) Institute of Biomedical Engineering, University of Oxford, UK)", "background": "慢性肥胖管理需要持续监控能量平衡行为，但传统的自我报告方法存在显著的报告不足、回忆偏差以及与现代数字健康系统难以集成的问题。传统的自我报告方法容易受到回忆偏差的影响，数据不准确，同时在整合到现代数字健康系统时也很困难。因此，需要一种新的客观方法来监控这些行为。", "innovation": "COBRA提出了一种名为COBRA（Chronic Obesity Behavioral Recognition Architecture）的新的深度学习框架，它使用腕戴式多模态传感器进行客观行为监测。COBRA通过结合U-Net空间建模、多头自注意力机制和双向LSTM时间处理，实现对日常活动的分类，包括与肥胖相关的行为分类：食物摄入、身体活动、久坐行为和日常生活。该框架在WISDM-Smart数据集上得到了验证，这种数据集包含51名受试者执行的18种活动。", "conclusion": "COBRA框架展示了良好的泛化能力，具有很低的人口统计学差异（<3%），这使得它能够为个性化的肥胖干预措施以及持续的生活方式监控提供可扩展的部署。D-Net的总体准确度为96.86%，在特定类别的F1评分上分别达到了98.55%（身体活动）、95.53%（食物摄入）、94.63%（久坐行为）和98.68%（日常生活），比现存最先进基线提高了1.18%的准确率。"}
{"llm_update_time": "20250907", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.04372", "html_url": "https://arxiv.org/abs/2509.04372", "title": "反馈强化学习、测试时缩放和扩散指导之间的联系：综述", "title_en": "Connections between reinforcement learning with feedback,test-time scaling, and diffusion guidance: An anthology", "authors": "Yuchen Jiao,Yuxin Chen,Gen Li", "background": "本文探讨了广泛使用的后训练技术之间的一些基本关联。背景包括：反馈强化学习、内部反馈强化学习、测试时缩放（特别是软最佳- N 抽样），以及扩散指导之间的紧密联系和等价性。", "innovation": "引入了一种重新采样方法，用于对齐和奖励导向的扩散模型，避免了明确应用强化学习技术的需求。", "conclusion": "本文强调了反馈强化学习、测试时缩放和扩散指导之间的内在联系，并提出了一个重新采样方法以提高模型的对齐和导向性。"}
{"llm_update_time": "20250907", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.04213", "html_url": "https://arxiv.org/abs/2509.04213", "title": "使用UKF结合基础模型实现零样本状态估计的研究", "title_en": "Sailing Towards Zero-Shot State Estimation using Foundation Models Combined with a UKF", "authors": "Tobin Holtmann,David Stenger,Andres Posada-Moreno,Friedrich Solowjow,Sebastian Trimpe", "background": "控制与系统工程领域的状态估计通常需要大量的人工系统识别或数据采集工作。相比之下，其他领域基于变压器的基础模型通过利用预训练的一般模型来减少数据需求。开发能够零样本泛化系统动力学的基础模型可以显著减少手动部署工作。尽管最近的工作表明基于变压器的端到端方法能够在未见系统上实现零样本性能，但它们局限于训练期间看到的传感器模型。本研究介绍了一种结合变压器动力学模型和已知传感器模型的UKF基础模型（FM-UKF），以在不重新训练新传感器配置的情况下实现跨不同动力学的一般化能力。", "innovation": "本研究提出了FM-UKF，将变压器动力学模型与UKF结合，使得在不重新训练新传感器配置的情况下实现跨不同动力学的一般化能力。通过与经典方法以及基于变压器的端到端方法的比较，展示了竞争力的准确度、努力和鲁棒性权衡。同时，还公开了基准测试的平台和数据集，以支持未来关于基础模型在零样本状态估计领域的研究。", "conclusion": "FM-UKF结合了变压器动力学模型和UKF，可以有效地实现跨不同系统动力学的零样本状态估计，展示了与经典方法相比的优越性，并且还提供了开源的基准测试平台和数据集支持进一步研究。"}
{"llm_update_time": "20250907", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.04337", "html_url": "https://arxiv.org/abs/2509.04337", "title": "钉取消耦合实体表示学习用于Pinterest广告排名", "title_en": "Decoupled Entity Representation Learning for Pinterest Ads Ranking", "authors": "Jie Liu,Yinrui Li,Jiankai Sun,Kungang Li,Han Sun,Sihan Wang,Huasen Wu,Siyuan Gao,Paulo Soares,Nan Li,Zhifang Liu,Haoyang Li,Siping Ji,Ling Leng,Prathibha Deshikachar", "background": "文章介绍了基于上游-下游范式的新型框架，利用多种数据源构建用户和商品（Pin）嵌入，并通过广告和推广有效个性化内容。上游模型通过复杂架构在广泛的数据源上训练，捕捉Pinterest上用户和商品之间的复杂关系。为了保证上游模型的可扩展性，实体嵌入被学习并定期刷新，而非实时计算，使得上游和下游模型可以异步交互。这些嵌入被集成到广告检索和点击率（CTR）、转化率（CVR）预测等下游任务中作为输入特征。实验表明，该框架在多种下游任务中均实现了显著的性能提升，并在Pinterest的生产广告排名系统中部署，带来了在线指标的重大改进。", "innovation": "该框架采用了上游-下游范式，在多种数据源上进行复杂架构的训练，确保模型的可扩展性。通过实体嵌入的定期学习和刷新，实现了异步的上游-下游模型交互。嵌入被用于多个下游任务中作为输入特征，展示出在不同任务中的显著性能改进，并应用在Pinterest的实际系统中。", "conclusion": "该框架成功地在Pinterest的广告排名系统中部署，实现了显著的在线指标改进，证明了其在广告个性化和推广中的应用价值。"}
{"llm_update_time": "20250907", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.04174", "html_url": "https://arxiv.org/abs/2509.04174", "title": "通过运动模式的深度度量相似性学习进行非侵入式现场行为变化测量", "title_en": "Unobtrusive In-Situ Measurement of Behavior Change by Deep Metric Similarity Learning of Motion Patterns", "authors": "Christian Merz,Lukas Schach,Marie Luisa Fiedler,Jean-Luc Lugrin,Carolin Wienrich,Marc Erich Latoschik", "background": "本文介绍了一种无干预的在场测量方法，用于检测XR系统中用户在任意暴露下的行为变化。这种行为变化通常与身体拟合感或使用户在XR中扮演不同形象的虚拟化身产生的身体环境有关。本文提出了一种基于深度度量相似性学习的生物特征用户模型，该模型使用高维嵌入作为参考向量识别个别用户的动作变化。此方法与两种替代方法进行对比评估：一种基于运动模式中心趋势的非学习运动分析，以及经常用于各种XR暴露的主观离开后身体拟合问卷。研究中，参与者进行了采摘水果任务，而他们分别扮演不同身高的虚拟形象（矮、实际身高、高）。主观评估证实了身体方案感知的有效操纵，而基于头部和手部运动的非学习客观分析揭示了条件之间的显著差异。我们的相似性学习模型通过对动作数据的训练，成功地识别了由不同虚拟形象条件引发的行为变化，对于查询和参考数据对的不同配对情况都是如此。", "innovation": "本文的方法有以下几种优势：1) 不需要额外用户的输入即可进行现场测量，2) 适用于各种应用场景的通用和可扩展的运动分析，3) 在单个级别进行用户特定分析，4) 使用训练过的模型，可以实时添加并评估用户，研究虚拟形象变化对行为的影响。", "conclusion": "通过基于运动模式的深度度量相似性学习，本文提出的方法可以有效且精确地检测XR环境中的行为变化，且具有现场测量、通用性和可扩展性、用户特定分析，并且可以实时添加和评估用户的特点，从而更好地理解和研究虚拟形象变化对行为的影响。"}
{"llm_update_time": "20250907", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.04357", "html_url": "https://arxiv.org/abs/2509.04357", "title": "PARCO: 声学单元增强鲁棒上下文ASR通过对比实体消歧", "title_en": "PARCO: Phoneme-Augmented Robust Contextual ASR via Contrastive Entity Disambiguation", "authors": "Jiajun He,Naoki Sawada,Koichi Miyazaki,Tomoki Toda", "background": "自动语音识别（ASR）系统在处理特定领域的人名实体和同音词方面存在问题。尽管上下文ASR可以改善识别效果，但往往难以捕捉细微的音素变化，主要是因为实体多样性有限。此外，现有的方法将实体视为独立的标记进行处理，导致多标记偏置不完整。", "innovation": "提出了一种名为Phoneme-Augmented Robust Contextual ASR via Contrastive entity disambiguation (PARCO)的方法，该方法结合了声学单元感知编码、对比实体消歧、实体级别监督和层级实体筛选。这些组件增强了音素的区分度，确保了实体检索的完整性，并在不确定性下减少了误检。", "conclusion": "实验证明，PARCO在具有1000个干扰项的中文AISHELL-1和英文DATA2数据集上的CER分别为4.22%和WER分别为11.14%下显著优于基线模型。PARCO还在THCHS-30和LibriSpeech等外部领域数据集上表现出鲁棒增益。"}
{"llm_update_time": "20250907", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.04191", "html_url": "https://arxiv.org/abs/2509.04191", "title": "KubeGuard：通过配置文件和运行时日志分析使用大型语言模型辅助的Kubernetes加固", "title_en": "KubeGuard: LLM-Assisted Kubernetes Hardening via Configuration Files and Runtime Logs Analysis", "authors": "Omri Sgan Cohen,Ehud Malul,Yair Meidan,Dudu Mimran,Yuval Elovici,Asaf Shabtai", "background": "随着Kubernetes（K8s）在编排云原生应用程序中的广泛应用，安全性问题日益凸显，例如资源配置不当和过于宽松的配置，这些都会导致未经授权访问、权限提升以及集群内的横向移动。传统的K8s安全解决方案多集中于检测配置错误，通常使用静态分析或异常检测。然而，KubeGuard提出了一种全新的基于运行时日志的推荐框架，旨在通过硬化工件环境来解决过于宽松的配置问题，从而提高集群安全性。", "innovation": "KubeGuard采用大型语言模型（LLMs）分析声明文件和运行时日志，通过模块化的提示链工作流程来分析实际系统行为，提出最小权限配置建议。它分为两个任务：资源创建和资源细化，以此来增强K8s环境的安全性。KubeGuard能够生成新的最小权限配置并细化现有的声明文件，减少攻击面，并以推荐形式呈现给用户（如开发者和操作员），提高其可操作性。实验结果表明，KubeGuard能够在Roles、NetworkPolicies和Deployments等方面生成和细化K8s声明文件，并且取得了高精度、召回率和F1分数，证明其作为可以将运行时可观察性转化为可行的最小权限配置指导框架的有效性和实用性。", "conclusion": "KubeGuard通过利用大型语言模型对配置文件和运行时日志进行分析，提供了一种新的方法来硬化工件环境，减少了过高的权限配置，增强了集群的安全性，并且提高了可操作性。实验结果证明，KubeGuard在实际应用中是有效的，能够提高K8s集群的安全性。"}
{"llm_update_time": "20250907", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.04413", "html_url": "https://arxiv.org/abs/2509.04413", "title": "SAFE--MA--RRT: 多智能体运动规划与数据驱动的安全证书", "title_en": "SAFE--MA--RRT: Multi-Agent Motion Planning with Data-Driven Safety Certificates", "authors": "Babak Esmaeili,Hamidreza Modares", "background": "研究旨在为在共享且充满障碍的工作空间中运行的同质线性多智能体系统提供一种完全依赖数据的运动规划框架。这些系统无法获得系统的显式模型。", "innovation": "该论文提出了一种新的数据驱动的运动规划框架，其中每个智能体通过求解凸半正定规划问题独立地从实验数据中学习其闭环行为。该框架生成局部不变椭球体和对应的状态反馈增益，确保动态可行性和安全性。采样规划器构建了一个这样的航点树，只有当相邻椭球体重叠时才允许转换，从而确保从不变航点到不变航点的连续性，并定义了操作的安全区域。通过空间-时间预留表协调所有智能体，防止同时占据和迎面碰撞，确保各智能体的安全。", "conclusion": "通过该方法，生成的轨迹不仅在动态上可行，而且在环境约束和智能体间碰撞方面具有可证明的安全性。仿真实验结果证明了该方法在仅使用数据和凸优化工具合成多个智能体具有共享动力学和约束条件下的协调、安全轨迹的有效性。"}
{"llm_update_time": "20250907", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2402.04915", "html_url": "https://arxiv.org/abs/2402.04915", "title": "陈oco：一种组合优化学习元优化器", "title_en": "Moco: A Learnable Meta Optimizer for Combinatorial Optimization", "authors": "Tim Dernedde,Daniela Thyssens,Sören Dittrich,Maximilian Stubbemann,Lars Schmidt-Thieme", "background": "相关的组合优化问题（COPs）往往被证明为NP难问题。过去，这些问题主要通过人工手工艺的启发式方法解决，但神经网络的进步推动了从数据中学习启发式的通用方法的发展。许多方法利用了神经网络直接构建解决方案，但在推理时进一步基于已构造的解决方案进行改进的能力有限。", "innovation": "Moco定义了一个轻量级的解决方案构造过程，该过程由一个称为热图的单连续向量θ引导，并学习一个神经网络来更新θ，用于组合优化问题（COPs）的单个实例。更新基于当前搜索状态的各种特征。训练过程注重预算意识，目标是在整个搜索过程中找到最佳解决方案。Moco是一种完全可学习的元优化器，不使用特定问题的启发式方法，也不需要在训练中使用最优解决方案。", "conclusion": "我们对旅行商问题（TSP）和最大独立集（MIS）进行了Moco的测试，并展示了它显著优于基于热图的方法。"}
{"llm_update_time": "20250907", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2401.09754", "html_url": "https://arxiv.org/abs/2401.09754", "title": "超越同质性的邻居相似性保留的鲁棒图结构学习", "title_en": "Towards Robust Graph Structural Learning Beyond Homophily via Preserving Neighbor Similarity", "authors": "Yulin Zhu,Yuni Lai,Xing Ai,Wai Lun LO,Gaolei Li,Jianhua Li,Di Tang,Xingxing Zhang,Mengpei Yang,Kai Zhou", "background": "尽管基于图的学习系统在处理结构性数据方面取得了巨大成功，但它们在同质图数据对抗攻击面前表现出脆弱性。在这种背景下，一系列模型被设计以增强基于图的学习系统的抗攻击能力。然而，基于图的学习系统在异质图数据上的安全性仍然是未知的。本文旨在探索基于图的学习系统在其同质性程度不论的情况下存在的脆弱性。", "innovation": "本文理论证明了基于聚合邻居特征的配对相似性与负分类损失的更新是负相关的。这一发现启发作者设计了一种新颖的基于邻居相似性保留的鲁棒图结构学习策略，该策略包含一种双kNN图构建流程以监督邻居相似性保留传播，并通过图卷积层根据节点对的富局部结构适配性平滑或区分节点特征。", "conclusion": "本文提出的方法能够在不同图同质性条件下挖掘出更好的图拓扑结构，从而在同质图和异质图上实现更可靠的数据管理。"}
{"llm_update_time": "20250907", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2212.14641", "html_url": "https://arxiv.org/abs/2212.14641", "title": "储层核函数和Volterra级数", "title_en": "Reservoir kernels and Volterra series", "authors": "Lukas Gonon,Lyudmila Grigoryeva,Juan-Pablo Ortega", "background": "本文构建了一个通用核函数，能够在有限维欧几里得空间中逼近任意具有有界记忆特性的因果和时间不变滤波器。该核函数基于维纳级数展开在任意分析有界记忆滤波器的状态空间表示的基础上构造，因此称为Volterra储层核函数。尽管状态空间表示和相应的储层特征映射定义在无限维张量代数空间中，但该核函数通过易于特定数据集获得的显式递归公式进行定义，便于在使用表示定理进行估算问题时计算。", "innovation": "本文提出了一种基于维纳级数展开的状态空间表示构建的通用核函数——Volterra储层核函数，它能够逼近具有有界记忆特性的因果和时间不变滤波器。尽管定义在无限维空间，此核函数可通过具体数据集的显式递归公式进行计算。通过与标准静态和序列核在多维高度非线性学习任务（金融资产回报的条件协方差）中的实验性能进行比较，展示了其优势和有效性。", "conclusion": "实验结果表明，Volterra储层核在处理复杂高度非线性问题，如条件协方差估计，具有显著的优势。该方法为解决涉及复杂因果关系的时间序列分析提供了新的工具和视角。"}
{"llm_update_time": "20250907", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.04450", "html_url": "https://arxiv.org/abs/2509.04450", "title": "虚拟试衣间：基于单张图像生成任意长度的虚拟试穿视频——技术预览", "title_en": "Virtual Fitting Room: Generating Arbitrarily Long Videos of Virtual Try-On from a Single Image -- Technical Preview", "authors": "Jun-Kun Chen,Aayush Bansal,Minh Phuoc Vo,Yu-Xiong Wang", "background": "当前存在资源密集型的虚拟试穿视频生成方法，且生成的视频长度经常受限，需要大量的视频数据。这种情况下，制作任意长度的虚拟试穿视频具有挑战性。", "innovation": "提出了一个名为Virtual Fitting Room (VFR)的新型视频生成模型，该模型能够生成任意长度的虚拟试穿视频。它采用自回归、逐段生成的方式解决了资源密集型生成和数据量大的问题。此外，VFR框架通过一个预制视频条件来确保段与段之间的平滑性，并通过一个全方位捕捉人体全身影像的锚视频来保证段与段之间的全局时间一致性。这种方式使得虚拟试穿视频可以在多种动作下保持局部平滑和全局时序一致性，是对长视频虚拟试穿视频生成的一项开创性工作", "conclusion": "VFR能够生成分钟级的虚拟试穿视频，并且能够在多种动作下保持局部平滑和全局时间一致性，展示了在长视频虚拟试穿视频生成上的突破性进展。"}
{"llm_update_time": "20250907", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2407.01085", "html_url": "https://arxiv.org/abs/2407.01085", "title": "基于大语言模型的偏好评估中的长度偏差解释", "title_en": "Explaining Length Bias in LLM-Based Preference Evaluations", "authors": "Zhengyu Hu,Linxin Song,Jieyu Zhang,Zheyuan Xiao,Tianfu Wang,Zhengyu Chen,Nicholas Jing Yuan,Jianxun Lian,Kaize Ding,Hui Xiong", "background": "使用大语言模型（LLMs）作为评委，尤其是在偏好比较中，变得越来越常见。然而，这一做法暴露出了一个明显的偏差，即倾向于较长的回答，这影响了评估结果的可靠性。", "innovation": "本文提出了通过将偏好评估指标——胜利概率（win rate）分解为两个关键因素——吸引力和信息量来解释长度偏差的方法。吸引力与长度无关，与可信度（如正确性、毒性和一致性）相关；信息量与长度相关，代表了回答中的信息量。此外，还提出了AdapAlpaca，这是一种简单的有效方法，通过对比赛率（win rate）的调整确保比赛时响应质量的公平比较。", "conclusion": "通过控制实验，作者发现响应长度通过影响信息量对评估有显著影响。为此，他们提出了一种名为AdapAlpaca的简单而有效的调整方法，用于评估内容质量，而不受响应长度的影响。这种方法确保了在等长区间内的公平比较，从而提高了评估的可靠性。"}
{"llm_update_time": "20250907", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2403.03726", "html_url": "https://arxiv.org/abs/2403.03726", "title": "基于语言模型编码的蛋白质序列生成中的扩散方法", "title_en": "Diffusion on language model encodings for protein sequence generation", "authors": "Viacheslav Meshchaninov,Pavel Strashnov,Andrey Shevtsov,Fedor Nikolaev,Nikita Ivanisenko,Olga Kardymon,Dmitry Vetrov", "background": "蛋白质序列设计通过离散扩散和自回归方法取得了显著进展，但连续扩散的潜力尚未得到充分探索。现有的研究集中在利用离散扩散和自回归模型进行蛋白质序列设计，但尚未充分利用连续扩散的方法。本文的背景在于填补这一空白，提出一种适用于蛋白质语言模型表示的连续扩散框架DiMA，以实现更广泛的应用和更高的设计效率。", "innovation": "提出了DiMA框架，一种基于蛋白质语言模型编码的连续扩散方法。该框架通过系统地探索架构选择和扩散组件，实现了在不同参数量的蛋白质编码器上的一致性能。DiMA框架展示了在序列仅约束、双重解码和多模态表示下的稳定高绩效，并通过条件生成任务展示了其广泛的适用性，包括蛋白质家族生成、特征台架和填补以及特定折叠序列设计。这使得连续扩散方法在蛋白质序列生成领域具有广泛应用的前景，为各类蛋白质设计场景提供了新的方法论基础和实用方案。", "conclusion": "DiMA框架提供了一种通用的连续扩散方法，适用于蛋白质序列生成。通过广泛的评估和对比实验，证明了DiMA在生成高质量、多样性和新颖性蛋白质序列方面的优越性能，并且能够支持多种条件生成任务。该工作为蛋白质设计领域带来了全新的架构洞察和实际应用的可能性。"}
{"llm_update_time": "20250907", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2405.17527", "html_url": "https://arxiv.org/abs/2405.17527", "title": "Unisolver: PDE-Conditional Transformers Towards Universal Neural PDE Solvers", "title_en": "Unisolver: PDE-Conditional Transformers Towards Universal Neural PDE Solvers", "authors": "Hang Zhou,Yuezhou Ma,Haixu Wu,Haowen Wang,Mingsheng Long", "background": "深神经网络模型已经展示了解决偏微分方程（PDEs）的能力，被称为神经PDE求解器。虽然神经求解器可以通过模拟数据或物理信息损失进行训练，并且可以在一定程度上解决PDEs，但是它们的应用范围有限，通常只能解决特定形式的少数PDEs，例如具有特定系数的一类方程。这限制了它们对各种不同PDEs的通用性，使其不适用于作为数值求解器的实用替代模型。\n", "innovation": "本文介绍了Unisolver，这是一种新颖的Transformer模型，它在多样化数据上进行训练，并具备处理各种不同PDEs的能力。它源自对PDE求解过程的理论分析，借鉴了PDE数学结构中PDE解本质上由一系列构成部分（如方程符号和边界条件）所主导的观点。因此，定义了一整套PDE构成部分，并将它们灵活地嵌入到基于Transformer的PDE求解器的域间和点间深度条件中。将物理洞察与最近的Transformer进展相结合，Unisolver在三个大规模基准测试中表现出了一贯的领先性能，并且具有出色的表现力和泛化能力。\n", "conclusion": "Unisolver实现了对各种不同PDEs的高效求解，展示了在三个挑战性的大规模基准测试中的卓越性能和强大的泛化能力。"}
{"llm_update_time": "20250907", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2407.03951", "html_url": "https://arxiv.org/abs/2407.03951", "title": "不确定性指导下的对数似然树搜索", "title_en": "Uncertainty-Guided Likelihood Tree Search", "authors": "Julia Grosse,Ruotian Wu,Ahmad Rashid,Cheng Zhang,Philipp Hennig,Pascal Poupart,Agustinus Kristiadi", "background": "树搜索是规划的基本工具，因为它可以将许多序贯决策问题转化为在树结构空间中进行搜索。然而，由于树的大小呈组合爆炸式增长，能够获得奖励的路径有限，特别是在通过昂贵的评估（如查询大型语言模型）来获取似然性时。", "innovation": "提出了一种基于似然性的规律性假设的概率搜索启发式算法，该算法能够在保持回溯和探索与利用之间的平衡的同时，无需进行昂贵的模拟或复杂的贝叶斯推断。", "conclusion": "通过大规模的实际应用测试，证实了该方法能够在较少的昂贵评估次数下识别出具有高似然性的路径。"}
{"llm_update_time": "20250907", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.04439", "html_url": "https://arxiv.org/abs/2509.04439", "title": "ArcMemo: 使用终生LLM记忆的抽象推理组成", "title_en": "ArcMemo: Abstract Reasoning Composition with Lifelong LLM Memory", "authors": "Matthew Ho,Chen Si,Zhaoxiang Feng,Fangxu Yu,Zhijian Liu,Zhiting Hu,Lianhui Qin", "background": "在推理时对LLMs进行缩放，使它们能够执行越来越长且复杂的推理步骤，但在每次重置上下文窗口用于新查询时，这些推理过程发现的模式和见解都会立即被丢弃。外部内存可以自然地保存这些发现，且最近的研究表明，对于依赖推理的任务而言，外部内存具有明显的优势。我们发现，通过将基于实例的记忆条目（例如，精确的查询/响应对，或者与其原始问题上下文紧密相关的总结）转变为概念级别记忆：可复用且模块化的抽象条目，可以更广泛地重用和扩展这些记忆。在未来的查询中，相关概念将被有选择地检索并整合到提示中，从而实现测试时持续学习而无需更新权重。这种方法引入了从展开过程中抽取出概括的新策略，并在新的查询中检索条目，促进了记忆的复用并允许其随着额外经验的获取而扩展。在ARC-AGI这一具有挑战性的基准测试中，我们的方法在没有记忆的基础线上取得了7.5%的相对提升，并且性能随着推理计算的增加而持续增长。我们发现抽象的概念是最具一致性的记忆设计，在所有测试的推理计算规模下都优于基线。此外，我们证明，在测试过程中动态更新记忆比固定记忆具有更好的表现，这支持了解决更多的问题并将更多的模式抽象到记忆中可以促进进一步解决方案的自我改进假说。", "innovation": "我们的设计引入了从展开过程中抽取出概括的新策略，并在新的查询中检索条目，促进了记忆的复用并允许其随着额外经验的获取而扩展。该方法将基于实例的记忆条目转变为概念级别记忆，以实现更广泛且可复用的记忆设计，并在测试时持续学习而无需更新权重。这种方法适用于高度挑战性的ARC-AGI基准测试，展示了在无需额外记忆更新的情况下，通过解决更多问题和抽象更多模式来促进进一步解决方案的自我改进假说的有效性。", "conclusion": "我们的方法在ARC-AGI基准测试中展示了超越强基线的性能，尤其在抽象概念作为记忆设计时表现出色。随着推理计算的增加，性能持续增长。此外，动态更新记忆优于固定记忆，支持了解决更多问题并通过自我改进获得进一步解决方案的观点。"}
{"llm_update_time": "20250907", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.04345", "html_url": "https://arxiv.org/abs/2509.04345", "title": "AUDETER: 开放世界中的深度换声音频检测的大规模数据集", "title_en": "AUDETER: A Large-scale Dataset for Deepfake Audio Detection in Open Worlds", "authors": "Qizhou Wang,Hanxun Huang,Guansong Pang,Sarah Erfani,Christopher Leckie", "background": "生成语音系统可以生产出极其逼真的人声，难以与真人语音区分，这带来了极大的真伪性挑战。尽管已经开发了许多深度伪造检测方法，但由于训练集与测试集样本之间存在的领域差异（尤其是由多样化的人类语音和快速演进的语音合成系统造成的差异），这些方法在实际环境中的有效性仍不可靠。当前的数据集未能充分解决这一问题，因为它们缺乏包含广泛、最新真实和伪造音频的实际应用挑战。因此，需要一个全面的数据集来解决这个问题。", "innovation": "AUDETER是一个大规模的深度伪造音频数据集，专门用于全面评估和稳健开发通用的深度伪造音频检测模型。该数据集包含超过4,500小时的由11个最新的文本到语音（TTS）模型和10个声码器生成的合成语音，总共有300万个音频片段，是目前规模最大的深度伪造音频数据集。通过广泛的实验表明，使用现有数据集训练的最先进的方法难以适应新型深度伪造音频样本，并且在未见过的人声检测上具有较高的误报率，这突显了全面数据集的必要性。同时，使用AUDETER训练的方法能够实现高度通用的检测性能，将检测错误率显著降低了44.1%-51.6%，在流行的野外（In-the-Wild）数据集中达到了仅4.17%的错误率，为培训通用的深度伪造音频检测器铺平了道路。", "conclusion": "AUDETER已在GitHub上公开提供，这一数据集为全面评估深度伪造音频检测方法提供了有力支持，并为培训通用的深度伪造音频检测器提供了新的机会。"}
{"llm_update_time": "20250907", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2407.15869", "html_url": "https://arxiv.org/abs/2407.15869", "title": "长输入序列网络用于长时间序列预测", "title_en": "Long Input Sequence Network for Long Time Series Forecasting", "authors": "Chao Ma,Yikai Hou,Xiang Li,Yinggang Sun,Haining Yu", "background": "在长时间序列预测任务中，短固定长度输入是深度学习方法的主要瓶颈。延长输入长度会导致过拟合，从而迅速降低准确性。研究表明，过拟合是时间序列中的多尺度模式耦合与当前模型固定聚焦尺度的结合结果。研究人员发现时间序列在不同尺度上显示的模式反映了其多周期性质，每个尺度对应特定的周期长度。此外，模型的行为主要受其令牌大小的决定，因为这决定了模型集中关注的尺度以及其能容纳的上下文大小。", "innovation": "提出了一个新颖的序列分解模块（MPSD）和多令牌模式识别神经网络（MTPR），以使模型能够处理输入长度增加10倍的情况。充分的上下文可以提升性能（最高可提升38%的精度），而分解方法提供了较低的计算复杂度（仅为0.22倍的成本）和较高的可解释性。", "conclusion": "该研究通过引入新颖的序列分解模块和多令牌模式识别神经网络，解决了长时间序列预测中的过拟合问题，提高了模型的处理能力和解释性。"}
{"llm_update_time": "20250907", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2411.00265", "html_url": "https://arxiv.org/abs/2411.00265", "title": "基于证据理论量化神经网络的校准误差", "title_en": "Quantifying Calibration Error in Neural Networks Through Evidence-Based Theory", "authors": "Koffi Ismael Ouattara,Ioannis Krontiris,Theo Dimitrakos,Frank Kargl", "background": "神经网络在关键应用中的部署依赖于其可靠性、信心和不确定性等属性，传统性能指标如准确率和精确率无法捕捉这些特性，尤其是在模型表现过度自信的情况下。为此，本研究探讨了如何通过引入主观逻辑来量化神经网络的可信赖度，并提出了一个评估期望校准误差（ECE）的新框架，力求提供关于模型可信赖度、不信赖度和不确定性的全面度量方法，以应对传统评估方法的不足。", "innovation": "提出了一个新的框架，通过引入主观逻辑来量化神经网络的可信赖度，以衡量期望校准误差（ECE），并采用聚类预测概率和适用融合算子进行意见融合的方法，提供了一种更可解释和细腻的AI模型评估方法，适用于敏感领域如医疗和自主系统等。", "conclusion": "通过在MNIST和CIFAR-10数据集上的实验，表明该方法能够提高模型的可信赖度，为提高神经网络在关键应用中的表现提供了有效的解决方案，同时也为敏感领域中AI模型的评估与应用提供了新的思路和方法。"}
{"llm_update_time": "20250907", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2411.10438", "html_url": "https://arxiv.org/abs/2411.10438", "title": "MARS: Unleashing the Power of Variance Reduction for Training Large Models", "title_en": "MARS: Unleashing the Power of Variance Reduction for Training Large Models", "authors": "Huizhuo Yuan,Yifeng Liu,Shuang Wu,Xun Zhou,Quanquan Gu", "background": "近年来，训练深度神经网络和大规模模型需要高效的可扩展优化器。自适应梯度算法如Adam、AdamW及它们的变体一直是核心方法。尽管过去十年开发了许多减少方差的算法旨在加速凸性和非凸设置下的随机优化，但在训练深度神经网络或大规模语言模型中，方差减少尚未找到广泛应用。因此，这种方法在现代AI中仍然不受欢迎。", "innovation": "本文提出了一种统一优化框架MARS（Make vAriance Reduction Shine），该框架结合了预条件梯度方法和方差减少，通过标度随机递归动量技术实现。在框架中，引入了三种MARS实例，分别基于AdamW、Lion和Shampoo的预条件梯度更新。实验结果显示，MARS在训练GPT-2模型时，比AdamW表现出显著优势。", "conclusion": "实验结果表明，MARS在训练GPT-2模型时比AdamW表现更优。MARS的实现可通过该链接进行访问。"}
{"llm_update_time": "20250907", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2411.00515", "html_url": "https://arxiv.org/abs/2411.00515", "title": "在库存管理中的零样本泛化：先训练，再估计，后决策", "title_en": "Zero-shot Generalization in Inventory Management: Train, then Estimate and Decide", "authors": "Tarkan Temizöz,Christina Imdahl,Remco Dijkman,Douniel Lamghari-Idrissi,Willem van Jaarsveld", "background": "在现实世界中应用深度强化学习（DRL）进行库存管理时，存在动态环境和不确定的参数问题，如需求和交货时间分布不确定。这些挑战突显出一个研究缺口，即需要一个统一框架来模型化和解决在参数不确定性下的顺序决策问题。本文探讨了DRL在库存管理中一个未被充分研究的领域：在零样本泛化（ZSG）条件下训练通用能力代理（GCAs）。ZSG指的是能够在未见过的实例中应用学习到的策略，而无需重新训练，且参数未知。", "innovation": "本文提出了一种统一的超马尔可夫决策过程（Super-MDP）模型和一种称为‘训练、估计、决策’（TED）框架，用于训练并部署一个针对库存管理应用的GCAs。TED框架包括三个阶段：在不同的问题实例上训练GCAs、在部署期间持续估计问题参数、然后基于这些估计进行决策。此外，本文使用了频繁模式图（Kaplan-Meier）估计器，展示了GC-LSN策略在需求和/或交货时间分布未知时的表现超过了基于悲观性能保证的在线学习方法。", "conclusion": "在已知问题参数时，本文所训练的GC-LSN代理在周期审查库存问题中优于已知的传统策略。而在需求和/或交货时间分布初始未知需要估计的情况下，与提供最坏情况性能保证的在线学习方法进行了基准测试，发现GC-LSN策略配以Kaplan-Meier估计器表现出更优的实证性能。"}
{"llm_update_time": "20250907", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2412.16572", "html_url": "https://arxiv.org/abs/2412.16572", "title": "突破长时间序列预测中的上下文瓶颈", "title_en": "Breaking the Context Bottleneck on Long Time Series Forecasting", "authors": "Chao Ma,Yikai Hou,Xiang Li,Yinggang Sun,Haining Yu,Zhou Fang,Jiaxing Qu", "background": "长期时间序列预测在经济学、能源和交通运输等领域中对于规划和决策至关重要，因为需要远见。长久以来，这些模型必须在处理长序列时具备效率和效果。尽管最近的进展提高了这些模型的效率，但有效地利用较长的序列信息依然存在挑战。这主要在于模型在面对长时间输入时往往会过度拟合，因此必须使用较短的输入长度来保持可接受的误差极限。", "innovation": "本文研究了多尺度建模方法，并提出了Logsparse Decomposable Multiscaling (LDM)框架，用于高效且有效地处理长时间序列数据。LDM通过时间序列中不同尺度上解耦模式的方法，增强了可预测性，减少了非平稳性，通过紧凑的长输入表示提高了效率，并通过提供明确的任务分配简化了架构。", "conclusion": "实验结果显示，LDM不仅在长期预测基准中优于所有基线，还在训练时间和内存成本上降低了开支。"}
{"llm_update_time": "20250907", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2411.17941", "html_url": "https://arxiv.org/abs/2411.17941", "title": "带有标签间关系的多标签贝叶斯主动学习", "title_en": "Multi-Label Bayesian Active Learning with Inter-Label Relationships", "authors": "Yuanyuan Qi,Jueqing Lu,Xiaohao Yang,Joanne Enticott,Lan Du", "background": "多标签主动学习的主要挑战在于评估大量潜在标签的信息量，同时考虑标签间的相关性，这与多类主动学习不同。现有研究要么需要大量计算资源来利用这些相关性，要么未能充分探索标签间的依赖关系。此外，现实世界中的数据通常存在类别分布不平衡所带来的固有偏见。因此，当前多标签主动学习面临处理标签关系和数据不平衡两大挑战。", "innovation": "论文提出了一种新的多标签主动学习策略，该策略通过逐步更新的正相关和负相关矩阵，捕捉标注样本标签空间中的共现和不交关系，从而全方位评估不确定性，不再将标签视为孤立的元素。此外，该模型还通过集成伪标签和贝塔评分规则来解决数据不平衡问题，同时考虑多样性。", "conclusion": "在四个现实数据集上的广泛实验表明，该策略能够一致地获得比几种现有方法更可靠且优越的性能。"}
{"llm_update_time": "20250907", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2410.22381", "html_url": "https://arxiv.org/abs/2410.22381", "title": "使用不变统计损失对具有重尾和多元分布的隐式生成模型进行稳健训练", "title_en": "Robust training of implicit generative models for multivariate and heavy-tailed distributions with an invariant statistical loss", "authors": "José Manuel de Frutos,Manuel A. Vázquez,Pablo Olmos,Joaquín Míguez", "background": "传统的隐式生成模型能够学习高度复杂的数据分布。然而，它们的训练需要使用对抗性判别器将真实数据与合成数据区分开来，这会导致不稳定的训练动态和模式丢失问题。许多现实现象中的数据只能用重尾概率分布来适当描述，传统的隐式方法难以有效地捕捉其渐进行为。为了解决这个问题，我们提出了使用不变统计损失（ISL）方法来训练生成器，该生成器使用一般化帕累托分布（GPD）作为输入噪声。这种方法在实验中表现出对分布尾部的准确建模能力，同时仍然能够捕捉到主要特征。原有的ISL函数是为一维数据集设计的，当实际数据是n维时，直接扩展该方法变得计算上不可行且在高维空间中效果不佳。为了解决这个问题，我们使用随机投影扩展了一维方法，并定义了一个新的适合多元数据的损失函数，通过调整投影的数量使问题保持可处理的状态。我们评估了其在高维生成建模中的性能，并探索了其作为生成对抗网络（GAN）预训练技术的潜力以防止模式崩溃，报告了喜人的结果，并强调了其在各种超参数设置下的稳健性。", "innovation": "1. 引入了一种使用一般化帕累托分布作为输入噪声的生成器，称为Pareto-ISL，该方法可以准确建模分布的尾部同时捕捉其主要特征。\n2. 使用随机投影扩展了一维方法，定义了一个新的适合多元数据的损失函数，解决了高维数据处理问题，保持了问题的可处理状态，同时提高了模型性能。\n3. 评估了该方法在高维生成建模中的表现，并将其作为生成对抗网络（GAN）的预训练技术探索了防止模式崩溃的潜力。", "conclusion": "提出的Pareto-ISL方法能够有效地捕捉重尾和高维数据的特性，通过随机投影扩展了原有的ISL方法，解决了处理高维数据的计算复杂性问题，展示了其在生成建模中的有效性和稳健性，并为生成对抗网络的预训练提供了新的可能。"}
{"llm_update_time": "20250907", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2411.03562", "html_url": "https://arxiv.org/abs/2411.03562", "title": "基于Kolb的体验式学习对于实现与人类级Kaggle数据科学性能的一般性代理", "title_en": "Kolb-Based Experiential Learning for Generalist Agents with Human-Level Kaggle Data Science Performance", "authors": "Antoine Grosnit,Alexandre Maraval,Refinath S N,Zichao Zhao,James Dora,Giuseppe Paolo,Albert Thomas,Jonas Gonzalez,Abhineet Kumar,Khyati Khandelwal,Abdelhakim Benechehab,Hamza Cherkaoui,Youssef Attia El-Hili,Kun Shao,Jianye Hao,Jun Yao,Balázs Kégl,Jun Wang", "background": "人类的专业知识通过迭代的互动、反思和内部模型更新周期形成，这是科布的体验式学习和维果茨基的最近发展区理论的核心。相比之下，当前的人工智能系统，尤其是在训练的大型语言模型中，依赖于静态预训练或僵硬的工作流程，缺乏持续适应的机制。早期研究表明，这些模型表现出某些人类反思、修正和自我纠正的认知特征，标志着人类体验学习基础组件的存在。因此提出关键问题：是否可以设计出能进行类似人类过程的结构化、认知基础的自主学习的大型语言模型？", "innovation": "我们提出了一种计算框架，将科布的学习周期与维果茨基的最近发展区理论结合起来，用于自主代理。该架构将外部（环境交互）和内部（内部反思/抽象）功能分开，使代理能够进行认知基础支撑学习。最初在结构化环境中学习，然后进行开放式的泛化。此方法赋予代理解决传统调优或简单反思方法难以有效解决的复杂任务的能力。该方法通过直接对比人类在真实世界Kaggle数据科学竞赛中的表现，得到了强大的展示。Agent K系统自动完成了81个任务的全自动化数据科学代码生成，实现了1694的Elo-MMR评分，超过我们研究中Kaggle大师（用户最多200,000人中最顶尖的2%）的中位得分。Agent K在9项金牌、8项银牌和12项铜牌中表现出色，包括4项金牌和4项银牌的奖励竞赛。Agent K是首个成功融合Kolb-和维果茨基启发的人类认知学习的AI系统，标志着向通用人工智能迈出的重要一步。", "conclusion": "Agent K系统展示了基于认知学习框架的自主学习模型的潜力，能够在广泛的任务中实现与人类相当甚至更好的数据科学性能。这一突破对于推进通用人工智能的发展具有重要意义。"}
{"llm_update_time": "20250907", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2411.14783", "html_url": "https://arxiv.org/abs/2411.14783", "title": "使用TD(Δ)在SARSA行动-价值函数上进行时间尺度分割", "title_en": "Segmenting Action-Value Functions Over Time-Scales in SARSA via TD($Δ$)", "authors": "Mahammad Humayoo", "background": "在许多 episodic 强化学习环境中，基于 SARSA 的方法被用来提高目标为最大化长时间回报的策略。传统的 SARSA 算法在实现偏倚和方差的最佳平衡方面面临挑战，主要原因是它们依赖单一且固定的折现因子 η。该研究通过将 TD($\triangle$) 方法应用到 SARSA 算法，开发出 SARSA($\triangle$)，以提升长期性能。SARSA 是一种常用的随策略强化学习方法，通过时间差异更新来提升行动值函数。通过将行动值函数细分并关联到特定的折现因子，SARSA($\triangle$) 在多种时间尺度上均能提高学习效率和一致性，特别是在需要长期性能提升的情况下。研究结果表明，SARSA($\triangle$) 能降低 SARSA 更新过程中的偏倚并加速收敛，在确定性和随机环境中，包括密集奖励的 Atari 环境中也是如此。", "innovation": "该研究引入了 SARSA($\triangle$) 算法，通过将 TD($\triangle$) 方法应用到 SARSA，显著提升了长时间尺度上的学习效率，并确保一致性，尤其是在需要长期性能提升的情况下。该方法在多项基准测试中均优于现有的TD学习技术，无论是表格化还是深度学习环境中均展现出更好的性能。", "conclusion": "该研究开发的 SARSA($\triangle$) 算法通过引入特定时间尺度的折现因子，改进了 SARSA 更新偏倚和收敛速度。在定性和随机环境中，尤其是在密集奖励的 Atari 环境中，SARSA($\triangle$) 显示出优越性能。"}
{"llm_update_time": "20250907", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2410.22954", "html_url": "https://arxiv.org/abs/2410.22954", "title": "具有来源可靠性估计的检索增强生成", "title_en": "Retrieval-Augmented Generation with Estimation of Source Reliability", "authors": "Jeongyeon Hwang,Junyoung Park,Hyejin Park,Dongwoo Kim,Sangdon Park,Jungseul Ok", "background": "检索增强生成（RAG）是一种有效的方法，通过从外部数据库检索信息来增强大型语言模型（LLMs）的事实准确性，这些数据库通常由多种来源组成，用以补充LLMs有限的内部知识。然而，标准的RAG方法在检索信息时存在风险，因为它仅依赖于查询与文档的相关性，而忽略了这些来源的异质可靠性。因此，当面对不同来源可靠性时，可能会检索到不准确的信息。", "innovation": "提出了一种新的多源RAG框架——可靠性意识RAG（RA-RAG），它通过估算来源的可靠性，并利用这些信息来优先检索高可靠性和相关性文档，从而确保更稳健和准确的响应生成。具体来说，RA-RAG通过在多个来源之间交叉检查信息首先估计来源的可靠性，然后检索来自最高$\boldsymbol{\text{\textkappa}}$个可靠和相关的文档，并使用加权多数投票（WMV）聚合这些信息，以确保可扩展性的同时不牺牲性能。", "conclusion": "全面的实验证明，即使在来源可靠性各异的场景下，RA-RAG也始终优于基线方法，且随着源数量的增加，其高效可扩展性强。此外，我们展示了RA-RAG能评估实际世界来源的可靠性，突显了其实用性。我们的代码和数据可在RA-RAG页面获得。"}
{"llm_update_time": "20250907", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2501.07681", "html_url": "https://arxiv.org/abs/2501.07681", "title": "数据集蒸馏作为拉.DTO推进最优量化", "title_en": "Dataset Distillation as Pushforward Optimal Quantization", "authors": "Hong Ye Tan,Emma Slade", "background": "数据集蒸馏旨在找到一个合成分训练集，使得在合成数据上进行训练能达到与在真实数据上训练相似的效果，但所需计算资源要少得多。现有的方法可以大致分为两类：一类是涉及双层优化问题的方法，具有神经网络训练的启发式方法作为下层问题；另一类是去耦方法，通过匹配数据分布来绕过双层优化。去耦方法的优点在于速度和可扩展性，尤其是在训练集和蒸馏集大小方面。", "innovation": "研究表明，具有编码器-解码器结构的去耦方法可以重新公式化为最优量化问题，其中通过最小化期望投影距离来找到一组点来近似底层概率测量。本文将现有的去耦数据集蒸馏方法与经典的最优量化和Wasserstein平均问题联系起来，并展示了蒸馏数据集在基于扩散生成先验中的稳定性。本文提出了基于潜在空间聚类的数据集蒸馏方法，并提出了一种新的最优量化方法，这种方法在ImageNet-1K数据集上比之前最佳的方法D4M实现了更好的性能和模型间泛化能力。该方法还在高每类图像数量设置中达到了SOTA性能。通过使用蒸馏噪声初始化在更强的扩散transformer模型中，我们获得了ImageNet-1K及其子集的SOTA蒸馏性能，超过扩散引导方法。", "conclusion": "基于最优量化方法的数据集蒸馏方法，不仅在高效性和计算资源节约方面表现出色，还在大量实验中展示了优异的性能和泛化能力。"}
{"llm_update_time": "20250907", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2505.04241", "html_url": "https://arxiv.org/abs/2505.04241", "title": "使用神经网络的3D模型技术预测", "title_en": "Technology prediction of a 3D model using Neural Network", "authors": "Grzegorz Miebs,Rafał A. Bachorz", "background": "准确估计生产时间对于有效的制造调度至关重要，但传统方法依赖于专家分析或历史数据，在动态或定制生产环境中往往不够准确。", "innovation": "该论文提出了一个数据驱动的方法，直接从展示几何形状的产品3D模型中预测制造步骤及其持续时间。通过将模型渲染成多张2D图像，并利用借鉴生成查询网络的神经网络，该方法能够将几何特征映射到预定义生产步骤的时间估计上，平均绝对误差低于3秒，从而使不同类型的产品规划更加便捷。", "conclusion": "该方法通过直接利用3D模型预测生产步骤及其持续时间，降低了专家分析和历史数据的依赖，适用于动态和定制生产环境，具有较高的时间估计准确性，简化了不同类型产品的规划过程。"}
{"llm_update_time": "20250907", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2504.08821", "html_url": "https://arxiv.org/abs/2504.08821", "title": "在具备延迟容忍网络中使用条件扩散模型在潜在动力学上的概率QoS指标预测", "title_en": "Probabilistic QoS Metric Forecasting in Delay-Tolerant Networks Using Conditional Diffusion Models on Latent Dynamics", "authors": "Jianhua Liu,Zheng Liu,Yu Xiang,Yanwen Qu", "background": "在具备延迟容忍网络(DTN)中运用主动服务质量(QoS)指标预测，能够提升网络性能，包括延迟、吞吐量、能耗和可靠性。这种预测问题天然地表现为多变量时间序列预测问题，传统的时间序列均值回归方法无法充分捕捉数据复杂性，导致在DTN的路由等操作任务中表现不佳。", "innovation": "本文将QoS指标预测问题转化为一个多变量时间序列的概率预测问题，通过引入扩散模型，并将非平稳和多模式数据的潜在时间动力学融入其中，提升了预测性能，优于现有的流行的时间序列预测方法。", "conclusion": "通过广泛实验，本文提出的方法证明了其在DTN中对QoS指标预测的有效性，并且在多个任务中表现出了优越性。"}
{"llm_update_time": "20250907", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2501.12689", "html_url": "https://arxiv.org/abs/2501.12689", "title": "IC-Cache：通过上下文缓存提高高效大规模语言模型服务", "title_en": "IC-Cache: Efficient Large Language Model Serving via In-context Caching", "authors": "Yifan Yu,Yu Gan,Nikhil Sarda,Lillian Tsai,Jiaming Shen,Yanqi Zhou,Arvind Krishnamurthy,Fan Lai,Henry M. Levy,David Culler", "background": "大规模语言模型（LLMs）在各种应用中表现出色，但提供大规模服务仍然具有挑战性，因为它们对资源的需求很大且延迟较高。我们的实际研究表明，用户对LLMs的请求中，超过70%具有语义相似的对应请求，这暗示了请求之间可能存在知识传递的潜力。然而，简单地缓存并重用过去响应会导致质量大幅下降。", "innovation": "本文介绍了一种名为IC-Cache的缓存系统，该系统可以增强实时LLM功能以提高服务效率。通过利用更大模型的历史请求响应对作为上下文示例，IC-Cache使小型LLM能够模仿甚至超过其大型对应物的组合能力（如推理），从而根据需求减少成本和延迟。IC-Cache通过成本意识的缓存重放机制来优化在线缓存的效用和效率，实现在数百万真实请求上的评估表明，IC-Cache能够将LLM服务吞吐量提高1.4-5.9倍，同时将延迟降低28-71%，而不会损害响应质量。", "conclusion": "IC-Cache系统在实现实时LLM能力增强时权衡了响应质量、延迟和系统吞吐量之间的复杂权衡。对于新的请求，IC-Cache会高效地选择相似且具有高价值的示例，并把它们添加到新请求的输入中。通过集中订购的方式，IC-Cache会智能地跨不同能力的LLM路由请求，同时考虑响应质量和服务负荷。"}
{"llm_update_time": "20250907", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2502.05719", "html_url": "https://arxiv.org/abs/2502.05719", "title": "扩展的基于直方图的离群值评分（EHBOS）", "title_en": "Extended Histogram-based Outlier Score (EHBOS)", "authors": "Tanvir Islam", "background": "直方图基于离群值评分（HBOS）是一种广为使用的离群值或异常检测方法，因其计算效率和易用性而受到青睐。然而，HBOS假设特征之间相互独立，这限制了其在特征之间存在重要交互作用的数据库中检测异常的能力。", "innovation": "本文提出了扩展的基于直方图的离群值评分（EHBOS），通过引入二维直方图来捕捉特征对之间的依赖性，从而能够识别HBOS无法发现的上下文和依赖性驱动的异常。EHBOS在17个基准数据集上的评估显示，其在多种异常检测场景中表现出色且具有鲁棒性。特别是在特征交互作用对异常结构定义至关重要的数据集上，EHBOS显著提高了ROC AUC值，展示了其在复杂特征依赖建模方面的潜力。", "conclusion": "EHBOS是HBOS的一个有价值扩展，特别适用于上下文或关系异常占有重要角色的数据集，并提供了一种强大的新工具用于异常检测。"}
{"llm_update_time": "20250907", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2504.14610", "html_url": "https://arxiv.org/abs/2504.14610", "title": "使用增量特征分区在变压器中无填充学习具有缺失值的表格数据", "title_en": "Imputation-free Learning of Tabular Data with Missing Values using Incremental Feature Partitions in Transformer", "authors": "Manar D. Samad,Kazi Fuad B. Akhter,Shourav B. Rabbani,Ibna Kowsar", "background": "本文指出了使用任意填充策略准备具有变化缺失值的表格数据集以供机器学习的问题。生成的合成值可能会引起关于数据质量和数据驱动结果可靠性的担忧。为了应对这些问题，本文提出了一个无填充增量注意力学习（IFIAL）方法，用于表格数据。", "innovation": "提出了一种名为IFIAL的方法，无需填充或初始化缺失值，而是通过一对自适应掩码直接简化变压器以处理表格数据。这种方法通过增量学习重叠的固定大小特征集，提高了变压器的效率和性能。实验表明，在17个不同数据集上的平均分类性能排名中，IFIAL方法优于11种最先进的学习方法，无论是有缺失值还是无缺失值。此外，与涉及缺失值填充的方法相比，该方法在不同类型的缺失值和缺失率下表现出更强的稳健性。", "conclusion": "通过实验验证，最佳的特征分区大小为原始特征空间的一半，既在计算上也是在准确性上都是最佳选择。这是第一个无需缺失值填充就能实现深度注意力学习的解决方案。文章提供的代码是公开的。"}
{"llm_update_time": "20250907", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.05138", "html_url": "https://arxiv.org/abs/2506.05138", "title": "联邦孤立森林模型在边缘IoT系统高效异常检测中的应用", "title_en": "Federated Isolation Forest for Efficient Anomaly Detection on Edge IoT Systems", "authors": "Pavle Vasiljevic,Milica Matic,Miroslav Popovic", "background": "近年来，针对边缘系统中的用户隐私保护和效率问题，出现了如Python TestBed for Federated Learning Algorithms和MicroPython TestBed for Federated Learning Algorithms等联邦学习框架。此外，基于孤立森林的高效联邦异常检测算法FLiForest也在最近提出，提供了一种低资源消耗的、无需监督的方法，适用于边缘部署和持续学习。本文基于这些联邦学习框架，开发了基于孤立森林的温度异常检测应用，该系统适用于运行MicroPython的小型边缘设备和IoT系统。", "innovation": "该作品提出了在边缘IoT系统中应用基于孤立森林的温度异常检测的方法，利用先前提出的联邦学习框架进行开发，实现了高效的异常检测，同时保持了内存使用低于160KB，并且结果显示该系统具有超过96%的准确性区分正常和异常的读数，以及在所有测试配置中超过78%的检测精度，确保了资源限制环境和边缘系统的适用性，同时遵循了联邦学习的原则，保护数据隐私并促进协作学习。", "conclusion": "该系统在实验中证明了其在资源受限的边缘系统中的有效性，能够进行高效的温度异常检测，且符合联邦学习的隐私保护与协同学习原则。"}
{"llm_update_time": "20250907", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.01115", "html_url": "https://arxiv.org/abs/2506.01115", "title": "随机注意力是否足以进行序列建模？分离Transformer中的可训练组件", "title_en": "Is Random Attention Sufficient for Sequence Modeling? Disentangling Trainable Components in the Transformer", "authors": "Yihe Dong,Lorenzo Noci,Mikhail Khodak,Mufan Li", "background": "现代大型语言模型（LLMs）的成功部分归功于Transformer架构，其自注意力机制表现出使用基于梯度的学习来预测下一个标记可以完成广泛任务的能力，如数学推理、记忆和检索。然而，关于自注意力机制在其性能提升中的具体贡献尚不明确。因此，研究人员通过比较标准Transformer与自注意力权重在初始化时冻结的变体来探讨这一问题，希望更好地理解Transformer内部各个组件的作用机制。", "innovation": "研究人员设计了MistiT架构，该架构完全依赖随机注意力得分，具有理论上稳定的信号传播特性，克服了随机Transformer深度方向缩放的先前挑战。通过MistiT的独特表现和失败情况，研究人员能够更细致地分离Transformer中各个组件的功能，探讨自注意力和MLP层在推理、知识存储等方面的具体作用。此外，研究人员还通过证明了在自注意力权重冻结情况下的Transformer模型的新表达能力，进一步明确自注意力机制在内部建立专门电路中的潜在角色。", "conclusion": "研究结果表明，即使不使用可学习的自注意力权重，Transformer架构也具有一种内在的归纳偏见，可以自主构建专门的电路。"}
{"llm_update_time": "20250907", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2505.18102", "html_url": "https://arxiv.org/abs/2505.18102", "title": "如何发布我的大语言模型基准而不泄露正确答案？", "title_en": "How Can I Publish My LLM Benchmark Without Giving the True Answers Away?", "authors": "Takashi Ishida,Thanawat Lodkaew,Ikko Yamane", "background": "在互联网上发布大语言模型（LLM）基准存在风险，可能会无意中或有意地被用于训练或选择模型。一种常见的缓解方法是将基准保持私密，让参与者提交他们的模型或预测给组织者，但这需要对单一组织的信任，并允许通过重复查询进行测试集过拟合。", "innovation": "本文提出了一种方法，在不完全披露问题真实答案的情况下发布基准，同时仍然能够公开评估LLM。主要想法是在答案中注入随机性，准备几种逻辑上正确的答案，并在基准中仅包括其中之一作为解决方案。这种方法降低了基准的最佳可能准确性，即贝叶斯准确性。这种方法不仅有助于保持不对真实答案的披露，还提供了一种检测数据污染的测试。即使具备完全能力的模型，理论上也不应超越贝叶斯准确性。如果模型超出预期，这将是数据污染的强烈信号。实验证据表明，该方法可以在多种基准、模型和训练方法中准确检测数据污染。", "conclusion": "该方法既有助于保持真实答案的保密，又提供了一种检测数据污染的测试。尤其是在具备完全能力的模型超越预期时，这将是数据污染的强烈信号。实验结果表明该方法在多种场景下都能准确地检测数据污染，是解决基准披露问题的有效途径。"}
{"llm_update_time": "20250907", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.03690", "html_url": "https://arxiv.org/abs/2507.03690", "title": "将注意力机制引入电力网络：迈向透明的预测", "title_en": "Plugging Attention into Power Grids: Towards Transparent Forecasting", "authors": "Eloi Campagne,Itai Zehavi,Yvenn Amara-Ouali,Yannig Goude,Argyris Kalogeratos", "background": "可靠的电力需求预测在确保电网稳定和指导发电决策方面起着关键作用，随着现代系统的分散化和复杂性的增加，这一需求愈发重要。传统的广义可加模型（GAMs）等方法在广泛应用中存在不足，难以捕捉能源网络中的空间依赖性。图神经网络（GNNs）提供了一种通过直接利用图拓扑来结合这种结构的原理性框架。本文评估了包括GCN、GraphSAGE、ChebConv、TAG、APPNP、TransformerConv和图注意网络（GAT和GATv2）在内的多种GNN架构在法国和英国两个真实世界电力消费数据集上的性能。", "innovation": "研究通过多种GNN架构对现实世界的数据集进行评估，发现简单模型如GCN、SAGE或APPNP在数据量较少时往往优于复杂模型，而GAT在基准测试中表现优秀，兼具高准确性和可解释性。还展示了注意力权重的时间分析，揭示了地区互动模式随季节和气象变化而变化的规律。此外，研究证实了基于专家聚合的组合策略，特别是自底向上的组合策略，能够提高模型的稳健性，并且在两个数据集上达到最先进的性能。这些发现表明，GNNs在准确性和可解释性预测方面具有双重潜力，并且简化架构结合集成方法可以为透明能源分析提供实用的道路。", "conclusion": "研究表明，虽然注意力机制并非普遍优越，但在存在大量空间依赖性时，它可以提供重要的解释力。GNNs对于准确且可解释的预测具有双重承诺，结合简单架构和集成方法可以为透明能源分析提供实用途径。"}
{"llm_update_time": "20250907", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.06469", "html_url": "https://arxiv.org/abs/2507.06469", "title": "使用双视角图表示学习减轻欺诈检测中的消息失衡", "title_en": "Mitigating Message Imbalance in Fraud Detection with Dual-View Graph Representation Learning", "authors": "Yudan Song,Yuecen Wei(Co-first author),Yuhang Lu,Qingyun Sun,Minglai Shao,Li-e Wang,Chunming Hu,Xianxian Li,Xingcheng Fu", "background": "图表示学习已经成为图神经网络（GNN）欺诈检测中的主流方法，因为它能够通过增强邻域知识捕获来提升节点表示。但这种方法主要关注局部交互，导致全局拓扑信息的不均衡传播，并且由于欺诈节点和良性节点之间的不平衡，在聚合过程中存在节点特定信息被其覆盖的风险。因此，首先总结了拓扑结构与类别不平衡对基于GNN的欺诈检测下游任务的影响，解释了样本不均衡是由于欺诈者通过拓扑行为和身份特征的隐蔽来误导监督信息导致的。", "innovation": "该研究提出了一个新的双视角图表示学习方法来缓解欺诈检测中的消息失衡问题（MimbFD）。首先设计了一个拓扑消息可达性模块，通过高质量的节点表示学习穿透欺诈者的伪装，减少传播不足。其次，引入了一个局部混杂偏差消除模块来调整节点表示，增强节点表示与标签之间的稳定关联，平衡不同类别的影响。", "conclusion": "在三个公开的欺诈数据集中进行了实验，结果表明，MimbFD在欺诈检测方面表现出色。"}
{"llm_update_time": "20250907", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.08537", "html_url": "https://arxiv.org/abs/2507.08537", "title": "递归奖励聚合", "title_en": "Recursive Reward Aggregation", "authors": "Yuting Tang,Yivan Zhang,Johannes Ackermann,Yu-Jie Zhang,Soichiro Nishimori,Masashi Sugiyama", "background": "在强化学习中，要使智能体的行为符合特定目标通常需要精心设计奖励函数，尤其是当目标复杂时，这一过程会更加具有挑战性。", "innovation": "提出了一种不需要修改奖励函数的灵活行为对齐方法，而是通过选择适当的奖励聚合函数。通过代数视角审视马尔可夫决策过程（MDPs），展示了贝尔曼方程自然地从奖励的递归生成和聚合中产生，从而将标准折扣和总和推广到其他递归聚合方法，如折扣最大值和夏普比率。这种方法适用于确定性和随机性环境，并与基于价值和行为-批评算法无缝集成。实验证明该方法能够有效优化多样的目标，显示出其多样性和现实应用的潜力。", "conclusion": "实验结果表明，该方法可以有效优化各种目标，突显了其多样性和潜在的实际应用场景。"}
{"llm_update_time": "20250907", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.20790", "html_url": "https://arxiv.org/abs/2506.20790", "title": "Stochastic Parameter Decomposition", "title_en": "Stochastic Parameter Decomposition", "authors": "Lucius Bushnaq,Dan Braun,Lee Sharkey", "background": "反向工程神经网络的关键步骤之一是将它们分解为可以在相对孤立条件下研究的更简单的部分。线性参数分解是一种框架，旨在解决当前分解方法中存在的多个问题，它将神经网络参数分解为参数空间中稀疏使用的向量之和。然而，当前框架中的主要方法，基于归因的参数分解（APD），由于计算成本高且对超参数敏感而 impractical。本研究介绍了一种新的方法：随机参数分解（SPD），该方法在可扩展性和对超参数的鲁棒性方面优于 APD，通过分解比 APD 能够分解的稍微大且复杂的模型，我们证明了 SPD 的有效性。此外，SPD 还解决了其他问题，如所学习的参数被收缩，以及在玩具模型中更好地识别真实机制。这种方法结合了因果中介分析和网络分解方法，为使用线性参数分解方法的更大模型提供了可能性，并因此消除了机制性可解释性的新研究障碍。我们提供了一个运行 SPD 并重现实验的库，可通过以下链接访问：this https URL.", "innovation": "提出了随机参数分解（Stochastic Parameter Decomposition，SPD），这是一种比基于归因的参数分解（Attribution-based Parameter Decomposition，APD）更可扩展且对超参数更鲁棒的分解方法。SPD 能够分解比 APD 大且复杂的模型，且避免了参数收缩等问题，并更好地识别了玩具模型中的真实机制。", "conclusion": "通过结合因果中介分析与网络分解方法，SPD 克服了线性参数分解的局限性，为更大的模型提供了机制性可解释性的可能性，从而为机制性可解释性研究领域开辟了新的研究方向。"}
{"llm_update_time": "20250907", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.09523", "html_url": "https://arxiv.org/abs/2507.09523", "title": "探究学习状态值的动作值时差方法分析", "title_en": "An Analysis of Action-Value Temporal-Difference Methods That Learn State Values", "authors": "Brett Daley,Prabhat Nagarajan,Martha White,Marlos C. Machado", "background": "时差(TD)学习的核心特征是通过价值预测来生成新的价值预测，即'递归'。大部分的TD控制方法采用单一动作值函数（如Q学习和Sarsa）进行递归。相比之下，很少有方法同时利用两个不对称的价值函数进行递归，尤其将状态值作为行动值学习的中间步骤。当前研究中这类算法主要分为QV-learning和AV-learning两类。尽管这些算法在先前的研究中有所探讨，但尚不清楚是否以及在何种情况下采用两个价值函数比仅使用一个更有优势——一般而言这些方法在理论上是否站得住脚也存疑。", "innovation": "该论文在收敛性和样本效率角度分析了此类算法，并证明在控制场景下，仅AV-learning方法能显著优于Q-learning方法。此外，该论文还引入了一种新的AV-learning算法——正则化对称Q学习（RDQ），在MinAtar基准测试中表现优异，超过了对称DQN。", "conclusion": "虽然两种算法在预测设置中都比预期Sarsa更有效，但在控制设置中，只有AV-learning方法能给Q-learning方法带来显著的优势。此外，RDQ作为一种新的AV-learning算法，在实际应用中展现出卓越的效果，引入了这一新的算法解决实际问题。"}
{"llm_update_time": "20250907", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.12070", "html_url": "https://arxiv.org/abs/2507.12070", "title": "仅限各向异性函数导致的量化表示的涌现", "title_en": "Emergence of Quantised Representations Isolated to Anisotropic Functions", "authors": "George Bird", "background": "该论文基于现有的Spotlight Resonance方法，提出了一种新的方法用于确定表示结构。通过一种控制性消除研究，即仅改变激活函数，该新工具被用来探索离散表示如何在自编码模型中出现和组织。研究表明，当激活函数通过离散代数置换等变对称定义时，表示会趋向离散化；而当激活函数通过连续代数正交等变定义时，表示保持连续。这证实了网络原始模块的对称性可能携带未预期的归纳偏置，导致在表示中产生与任务无关的伪结构。此外，它揭示了当前表现形式的离散性是连续分布中离散表示产生的强预测因子——量化效应。", "innovation": "该论文首次通过一种新的方法检测激活函数对其它表示的影响，探究了连续对称性和离散对称性对表示离散化的影响。通过控制性消除研究，验证了网络原始模块的对称性可能对表示起引导作用，并解释了量化表示与重建误差之间的关联。", "conclusion": "离散对称性的存在表明量化表示与连续性输入之间的关系。这种发现促使对常用函数形式需要进一步的再评估。此外，这一机制可能为理解研究提供新的见解，并可能强烈影响下游可解释现象，如祖母神经元、离散编码方案、一般线性特征以及可能的叠加效应。初步结果显示，表示的量化确实与可重构误差增加有关，这支持了之前的猜想，这种坍塌可能有害。"}
{"llm_update_time": "20250907", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.19346", "html_url": "https://arxiv.org/abs/2507.19346", "title": "使用多模态嵌入的短视频推荐：解决冷启动和偏差挑战", "title_en": "Short-Form Video Recommendations with Multimodal Embeddings: Addressing Cold-Start and Bias Challenges", "authors": "Andrii Dzhoha,Katya Mirylenka,Egor Malykh,Marco-Andrea Buchmann,Francesca Catino", "background": "近年来，社交媒体用户在以视频为主的平台上花费了大量时间。为了吸引用户并增加他们的使用时长，电子商务等其他领域的平台也开始引入短视频内容。虽然这种短视频体验的成功不仅取决于内容本身，还依赖于独特的UI创新，即平台为用户推荐一个视频后再推荐另一个，但这给推荐系统带来了新的挑战。特别是在启动新的视频体验时，推荐系统不仅要处理有限的交互数据，还要面对由UI设计和观看时间优化引起的位置偏见和长度偏见，这些问题使得构建有效的解决方案变得困难。", "innovation": "本文强调了引入新的短视频体验所面临的挑战，并展示了即使有充足的视频交互数据，利用微调的多模态视觉语言模型来构建一个视频检索系统更为有效。这种方法在电子商务平台进行的在线实验中相较于传统的监督学习方法表现出更强的成效。通过这种方法，可以有效解决冷启动和偏差挑战。", "conclusion": "本文提出了一个利用多模态视觉语言模型进行视频检索以解决短视频推荐挑战的方法，并在电子商务平台上验证了该方法的有效性，相较于传统的监督学习方法，这种方法更加有效。"}
{"llm_update_time": "20250907", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.01426", "html_url": "https://arxiv.org/abs/2508.01426", "title": "UniExtreme: 一种通用的极端天气预测基础模型", "title_en": "UniExtreme: A Universal Foundation Model for Extreme Weather Forecasting", "authors": "Hang Ni,Weijia Zhang,Hao Liu", "background": "近年来深度学习的最新进展推动了天气预报中基础模型（FMs）的发展，但这些模型在预测极端天气事件方面的表现仍然有限。现有的方法或关注一般天气条件，或专注于特定类型的极端事件，忽视了多样化极端事件在现实世界大气模式中的表现。因此，这项工作旨在识别极端事件的两个关键特征：（1）与正常天气制度的频谱差异，（2）多样极端事件的层次驱动和地理混合机制，从而提出了一种称为UniExtreme的通用极端天气预报基础模型。", "innovation": "UniExtreme模型通过引入（1）自适应频率调制（AFM）模块，该模块采用可学习的Beta分布滤波器和多级频谱聚集来捕捉区域内正常和极端天气之间的频谱差异，以及（2）事件先验扩充（EPA）模块，该模块通过双层记忆融合网络整合区域特定极端事件先验来解决层次多样极端事件的复杂模式。实验结果表明，UniExtreme在极端天气和多种一般天气预测中均优于现有的基线模型，展现出对多种极端情景的优异适应性。", "conclusion": "广泛实验表明，UniExtreme在极端天气和一般天气预测方面都优于现有基准模型，展示了其在不同极端场景中的优越适应性。"}
{"llm_update_time": "20250907", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.04180", "html_url": "https://arxiv.org/abs/2508.04180", "title": "指纹一步之遥，质谱从头生成分子一大步", "title_en": "One Small Step with Fingerprints, One Giant Leap for De Novo Molecule Generation from Mass Spectra", "authors": "Neng Kai Nigel Neo,Lim Jing,Ngoui Yong Zhau Preston,Koh Xue Ting Serene,Bingquan Shen", "background": "质谱从头生成分子的问题通常采用两阶段方法：首先是将质谱编码成分子指纹，其次是将这些指纹解码成分子结构。研究团队使用MIST作为编码器，MolForge作为解码器，并通过额外的训练数据来提高模型性能。通过细化每个指纹位的概率阈值，关注亚结构的存在性，这种方法在MassSpecGym数据集上相较于之前的最佳方法有十倍的提升，top-1生成了28%的正确分子结构，top-10生成了36%的正确分子结构。", "innovation": "采用了MIST和MolForge作为编码和解码工具，并通过增加训练数据来优化模型的效果。特别创新之处在于细化概率阈值以突出亚结构的存在性，实现了在MassSpecGym数据集上十倍的性能提升，超越了之前的方法，显著提高了生成正确分子结构的比例。", "conclusion": "这种以指纹为基础的方法被视为质谱从头解析分子的强基准线，为进一步研究提供了重要的参考。"}
{"llm_update_time": "20250907", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.07809", "html_url": "https://arxiv.org/abs/2508.07809", "title": "EvoCoT: 克服强化学习中的探索瓶颈", "title_en": "EvoCoT: Overcoming the Exploration Bottleneck in Reinforcement Learning", "authors": "Huanyu Liu,Jia Li,Chang Yu,Taozhi Chen,Yihong Dong,Lecheng Wang,XiaoLong Hu,Ge Li", "background": "强化学习中的奖励验证方式（RLVR）已经成为改进大型语言模型（LLMs）推理能力的一个有前景的方法。然而，当在复杂问题上展开时，卷积不够准确导致奖励稀疏，限制了学习效率并造成探索瓶颈。现有的方法要么依赖于更新的LLMs进行知识蒸馏，要么过滤掉困难的问题，这限制了可扩展性或限制了通过探索改进推理能力。", "innovation": "我们提出了一种基于双重思维链推理优化的自适应课程学习框架EvoCoT。EvoCoT通过自我生成和验证思维链轨迹来限制探索空间，然后逐渐缩短这些路径，以在可控的方式内扩展空间。这使得LLMs能够在奖励稀疏的情况下，稳定地学习初始复杂问题。", "conclusion": "我们在多种LLM家族（包括Qwen、DeepSeek和Llama）上应用了EvoCoT，实验结果显示EvoCoT使LLMs能够解决以往未解决的问题，提高了推理能力，并且与各种RL微调方法兼容。我们发布了源代码以支持未来的研究。"}
{"llm_update_time": "20250907", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.17675", "html_url": "https://arxiv.org/abs/2508.17675", "title": "使用生成多模态大型语言模型合成认知评估的规范性数据", "title_en": "Towards Synthesizing Normative Data for Cognitive Assessments Using Generative Multimodal Large Language Models", "authors": "Victoria Yan,Honor Chotkowski,Fengran Wang,Xinhui Li,Jessica Saurman,Fadi Nahab,David Loring,Carl Yang,Jiaying Lu,Runze Yan,Xiao Hu,Alex Fedorov", "background": "认知评估需要基准数据来评估个体表现，而基于新型图像刺激的新认知测试的开发因缺乏现成的基准数据而具有挑战性。传统数据收集方法成本高、耗时且更新不及时，限制了其实用性。近年来，生成多模态大型语言模型（MLLMs）的进步为从现有认知测试图像生成合成基准数据提供了新方法。", "innovation": "研究使用生成多模态大型语言模型，特别是GPT-4o和GPT-4o-mini，为现有的基于图像的认知评估合成规范性文本响应，评估了不同提示策略（朴素提示和高级提示）的效果，利用嵌入分析评估其区分诊断组和人口差异的潜力。研究表明，高级提示策略生成的响应更有效地区分诊断组并捕捉人口多样性，更适合评估创造性输出。", "conclusion": "研究证明，指导性提示方法可以引导生成多模态大型语言模型生成现有认知测试的稳健合成基准数据，为开发新的基于图像的认知评估提供了基础，克服了传统方法的限制。"}
{"llm_update_time": "20250907", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.13755", "html_url": "https://arxiv.org/abs/2508.13755", "title": "RLVR深度广度协同：通过自适应探索解锁LLM推理增益", "title_en": "Depth-Breadth Synergy in RLVR: Unlocking LLM Reasoning Gains with Adaptive Exploration", "authors": "Zhicheng Yang,Zhijiang Guo,Yinya Huang,Yongxin Wang,Dongchun Xie,Yiwei Wang,Xiaodan Liang,Jing Tang", "background": "Reinforcement Learning with Verifiable Reward (RLVR) 已经成为解锁大语言模型推理能力的强大范式，但是其潜力仍未充分开发，主要受限于两个未充分探究的维度：深度（模型能解决最复杂问题的程度）和广度（每次迭代中消费的实例数量）。GRPO 算法存在系统性偏见，累积优势偏向中等准确度的样本，而忽视了低准确度的样本，这些样本对于扩大推理边界至关重要。", "innovation": "介绍了 Difficulty Adaptive Rollout Sampling (DARS)，一种针对深度的自适应采样方法，通过多阶段有针对性的滚动来重新加权困难问题，从而增加困难问题的积极滚动次数。放弃盲目增加滚动规模，主张增加批处理大小，替代 PPO 的微型批处理迭代，改为在多个时期进行全批更新，显著提升了 Pass@1 性能。还提出了 DARS-B，结合广度自适应探索，同时实现了 Pass@K 和 Pass@1 的提升。", "conclusion": "这些结果表明，深度和广度的自适应探索在 RLVR 中是相互独立的维度，被证明是释放 RLVR 推理能力的关键。"}
{"llm_update_time": "20250907", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.00616", "html_url": "https://arxiv.org/abs/2509.00616", "title": "TimeCopilot", "title_en": "TimeCopilot", "authors": "Azul Garza,Reneé Rosillo", "background": "该论文背景是针对时间序列预测(TSF)领域的需求，引入了一个综合的自动化预测框架，结合了多模态时间和语言模型来提高预测的准确性和解释性。", "innovation": "TimeCopilot是第一个开源的代理式框架，通过单一的统一API结合了多个时间序列基础模型(TSFMs)和大型语言模型(LLMs)，自动化的预测管道包括特征分析、模型选择、交叉验证和预测生成，并提供自然语言解释和直接未来的查询支持。该框架对大型语言模型是无偏见的，兼容商业和开源模型，并支持多样化的预测组合。", "conclusion": "TimeCopilot在大规模GIFTEval基准测试中达到了最先进的概率预测性能，同时具有成本效益，为可重复、可解释和可访问的代理式预测系统提供了一个实用的基础。"}
{"llm_update_time": "20250907", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.02565", "html_url": "https://arxiv.org/abs/2509.02565", "title": "以特征流形为背景理解稀疏自编码器的缩放行为", "title_en": "Understanding sparse autoencoder scaling in the presence of feature manifolds", "authors": "Eric J. Michaud,Liv Gorton,Tom McGrath", "background": "稀疏自编码器(SAEs)通过线性组合稀疏出现的变化方向(隐变量)来建模神经网络的激活。SAEs在重建激活方面遵循与隐变量数量相关的缩放定律。本文基于神经网络缩放文献中的容量分配模型（Brill, 2024）来理解SAEs的缩放行为，尤其是特征流形对缩放行为的影响。", "innovation": "引入并适应了神经网络缩放文献中的容量分配模型来解释SAEs的缩放现象，特别是研究特征流形如何影响缩放行为；发现特征流形在一种缩放状态下会导致SAEs只学习很少的特征，即数据中的特征数量远少于SAEs中的隐变量数量。", "conclusion": "本文的研究发现了一种病理性缩放状态，在这种状态下，特征流形使得SAEs只能学习很少的特征，数量远少于SAEs中隐变量的数量。同时，对实际使用中的SAEs是否处于这种病理性缩放状态进行了初步讨论。"}
{"llm_update_time": "20250907", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.03249", "html_url": "https://arxiv.org/abs/2509.03249", "title": "结构转移：一种基于推理的表示转换计算", "title_en": "Structure Transfer: an Inference-Based Calculus for the Transformation of Representations", "authors": "Daniel Raggi,Gem Stapleton,Mateja Jamnik,Aaron Stockdill,Grecia Garcia Garcia,Peter C-H. Cheng", "background": "表示选择对于有效沟通和推理至关重要。然而，如何设计一种不依赖于表示系统的表示转换技术仍然是一个未解决的问题。", "innovation": "该论文提出了一种新的计算方法，称为结构转移，它能够跨越多种表示系统进行表示转换。通过利用描述表示系统的模式，结构转移确保源表示和生成的目标表示满足指定的关系（如语义等价）。", "conclusion": "结构转移是一种通用的计算方法，可以在多种实际应用场景中识别替代表示。它基于表示系统理论，利用构建空间这一关键概念进行形式化描述，适用于形式语言、几何图形、图表以及非正式记号等各种类型的表示系统。"}
{"llm_update_time": "20250907", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.18826", "html_url": "https://arxiv.org/abs/2508.18826", "title": "SWiFT: Soft-Mask Weight Fine-tuning for Bias Mitigation", "title_en": "SWiFT: Soft-Mask Weight Fine-tuning for Bias Mitigation", "authors": "Junyu Yan,Feng Chen,Yuyang Xue,Yuning Du,Konstantinos Vilouras,Sotirios A. Tsaftaris,Steven McDonagh", "background": "近年来的研究表明，机器学习模型在实际应用中可能会出现偏见，这在如医疗保健等伦理敏感领域中提出了重大挑战。这种偏见不仅会影响模型的公平性，还会削弱其泛化能力，进一步加剧社会歧视问题。现有去偏方法通常需要访问原始训练数据，并需要大量的模型重新训练，这往往会在模型的公平性和预测性能之间产生权衡。因此，现有的去偏方法成本较高，效率低下。", "innovation": "为了应对这些挑战，我们提出了一个新的去偏框架SWiFT。SWiFT通过少量外部数据和少量模型微调来高效提高公平性，同时保持预测性能的好。其创新点在于，首先识别出每个模型参数对偏见和预测性能的相对、独特贡献，然后通过两步梯度流动更新每个参数。实验结果表明，SWiFT能够在不同公平性和准确度标准下有效减少模型偏见，同时保持甚至超越最先进的模型的诊断准确性，并且显示出更好的泛化能力，特别是在一些分布外的数据集上表现更好。", "conclusion": "我们提出的SWiFT框架能够实现显著减少模型偏见，同时保留预测性能，适用于多种真实场景，并展示出更好的泛化能力。"}
{"llm_update_time": "20250907", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.20293", "html_url": "https://arxiv.org/abs/2508.20293", "title": "Beacon：具有集成网格选择的后训练量化", "title_en": "Beacon: Post-Training Quantization with Integrated Grid Selection", "authors": "Shihao Zhang,Rayan Saab", "background": "量化是一种广泛使用的压缩技术，用于降低大型预训练模型的内存和计算成本。后训练量化（PTQ）中的按通道量化面临的关键挑战是如何选择合适的缩放因子来替换权重值，使其与缩放的整数网格中的值匹配。现有方法通常通过启发式调整或网格搜索固定缩放因子。", "innovation": "我们提出了Beacon，一种简单而有效的算法，其特点是不需要手动调整缩放因子。Beacon直接使用未缩放的网格进行按通道后训练量化，并通过利用标量量化几何形状自动确定最优缩放因子。它不依赖于反向传播或大规模校准集。", "conclusion": "尽管Beacon简单且不需要调优，但在与最先进的方法相比的性能上仍然具有竞争力，使其成为高效模型部署的实用解决方案。"}
{"llm_update_time": "20250907", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.22832", "html_url": "https://arxiv.org/abs/2507.22832", "title": "揭开ReLU网络的面纱", "title_en": "Pulling Back the Curtain on ReLU Networks", "authors": "Maciej Satkiewicz", "background": "由于任何ReLU网络都是分段仿射的，因此其隐藏单元可以通过通过激活子网络的反向传递来表征，即其梯度（除偏置项外）。然而，深层神经元的梯度通常存在偏差，这遮蔽了网络的内部表示。论文提出观点，模型确实能对梯度与数据进行对齐，但这一对齐被ReLU硬门控的固有噪声所掩盖。这通过应用仅在反向传递中使用软门控得到验证，减少对弱激活神经元的局部影响，从而获得新的梯度，称为‘激发拉回’，它们在多个ImageNet预训练架构上表现出显著的感知对齐，而原始像素空间的梯度上升则迅速产生了易于解释的输入和目标特异性特征。基于这些发现，该论文提出了‘路径稳定性’假设，认为二值激活模式在训练过程中大致稳定并编码在最终模型的预激活分布中。当这一假设为真时，‘激发拉回’将与主要决定网络决策的核机的梯度对齐。这从理论上阐述了基于这些拉回的特征归因的可信性，甚至可能实现深层模型的机制性可解释性。此外，作者解释了批归一化和深层特征的有效性，并提供了一种新的视角来理解网络的内部记忆和泛化特性。作者还发布可用于进一步探索‘激发拉回’的代码和交互式应用。", "innovation": "1. 通过应用仅在反向传递中使用的软门控，减少弱激活神经元的局部影响，得出‘激发拉回’，表现出良好的感知对齐，而原始像素空间的梯度上升则会产生易于解释的输入和目标特异性特征。2. 提出了‘路径稳定性’假设，认为二值激活模式在训练过程中大致稳定并编码在最终模型的预激活分布中。3. 为基于这些拉回的特征归因的可信性提供了理论依据，可能实现深层模型的机制性可解释性。4. 解释了批归一化和深层特征的有效性，并提供了一种新的视角来理解网络的内部记忆和泛化特性。5. 发布了代码和交互式应用，便于进一步探索‘激发拉回’。", "conclusion": "激发拉回作为一种新的解释方法，不仅在视觉上与感知对齐，还能用于生成易于解释的输入和目标特定属性。‘路径稳定性’假设为深层网络的决策提供了理论支持，可能实现对深层模型更深层次的理解和解释。此外，激发拉回的研究还可能促进对批量归一化和深层次特征的理解，提供一种关于网络内部记忆和泛化特性的新视角。"}
{"llm_update_time": "20250907", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.02846", "html_url": "https://arxiv.org/abs/2509.02846", "title": "基于奖励模型的推理时刻扩展算法：PDE基础模型的推理", "title_en": "Towards Reasoning for PDE Foundation Models: A Reward-Model-Driven Inference-Time-Scaling Algorithm", "authors": "Siddharth Mansingh,James Amarel,Ragib Arnab,Arvind Mohan,Kamaljeet Singh,Gerd J. Kunde,Nicolas Hengartner,Benjamin Migliori,Emily Casleton,Nathan A. Debardeleben,Ayan Biswas,Diane Oyen,Earl Lawrence", "background": "偏微分方程（PDEs）是现代计算科学与工程的基础，但计算成本较高。现有的PDE基础模型虽然在模拟复杂的空间-时间现象方面表现出巨大的潜力，但在预训练数据集的限制下，它们的自回归滚动性能受限，特别是在分布外（OOD）的情况。此外，这些模型还需要大量的计算资源和训练数据，这限制了它们在许多关键应用中的使用。", "innovation": "该研究引入了一种基于奖励模型的测试时计算（TTC）策略，利用推理时的计算资源来提高预测准确性，同时减少训练样本和模型大小。通过两种类型的奖励模型评估基于随机方法的模型的空间-时间一致性，从而实现更精确的预测。此方法在PDEGym基准测试的可压缩欧拉方程模拟中展示了相对于标准非自适应自回归推理的更优预测效果。", "conclusion": "TTC框架代表了更先进推理算法或PDE建模的基础步骤，包括构建基于强化学习的方法，有可能彻底改变物理和工程中的计算工作流。"}
{"llm_update_time": "20250907", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2311.16507", "html_url": "https://arxiv.org/abs/2311.16507", "title": "基于扩散先验的更直接流匹配", "title_en": "Straighter Flow Matching via a Diffusion-Based Coupling Prior", "authors": "Siyu Xing,Jie Cao,Huaibo Huang,Haichao Shi,Xiao-Yu Zhang", "background": "流匹配作为一种生成模型的范例，在多个领域取得了显著的成功。然而，现有的方法要么需要多轮训练，要么利用批次内的先验知识，这带来了在直线条状生成中找到一个有效的耦合策略的挑战。特别是在有限步骤生成中寻找一种能够引导轨迹直行的方案令人困难。", "innovation": "本文提出了一种名为StraightFM的新方法。它通过一个扩散模型作为耦合先验，来调整图像和噪声之间的耦合策略，从而直线条状生成。这种方法不仅能与现实数据中噪声的方向耦合策略相结合，还能在几步骤生成中提升图像质量。实验结果显示，使用5步内的StraightFM可以生成具有吸引力的样本，在像素空间和隐空间上均有显著效果。此外，在无需训练的情况下， StraightFM还能与多模态条件生成无缝兼容，维持高质量的几步骤生成图像能力。", "conclusion": "实验结果表明，使用StraightFM可以在5步内生成具有吸引力的样本，并且在无条件情况下可以与多模态条件生成无缝结合，维持高质量的生成能力。"}
{"llm_update_time": "20250907", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2311.17165", "html_url": "https://arxiv.org/abs/2311.17165", "title": "(不)理性在AI：现状，研究挑战与开放问题", "title_en": "(Ir)rationality in AI: State of the Art, Research Challenges and Open Questions", "authors": "Olivia Macmillan-Scott,Mirco Musolesi", "background": "‘理性’的概念在人工智能（AI）领域中至关重要。无论是模拟人类推理还是追求有边界最优性，我们的目标都是让人工代理尽可能地接近理性。尽管‘理性’在AI中的重要性不言而喻，但没有统一定义何为‘理性’的代理。本文调研了AI中的理性与非理性，并明确了该领域所面临的关键问题。本文探讨了其他学科（如经济学、哲学和心理学）对理性概念的理解如何影响AI中的观念，特别是关注人工代理的行为，研究某些情境下非理性行为可能成为最优策略。尽管已有一些方法用于识别和处理非理性代理，但这一领域的研究依然有限。", "innovation": "本文审查了AI中的理性与非理性概念，探讨了其他学科对理性理解如何影响AI中的观念，并指出了一定情境下非理性行为可能最优的问题，同时指出了处理非理性代理的方法目前仍显不足，并讨论了人工代理之间以及人类与人工代理之间的交互，和理性在这类交互中的作用。", "conclusion": "本文指出了AI中有关理性和非理性问题的现状，并提出了研究挑战与未解决的问题，强调了为人类和人工代理中的潜在非理性行为寻找解决方案的重要性。此外，虽然有一些方法适用于对抗场景中处理非理性代理，但这些方法可能需要进一步调整以符合与人工代理的交互，特别是考虑到人类行为的复杂性。"}
{"llm_update_time": "20250907", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.03056", "html_url": "https://arxiv.org/abs/2509.03056", "title": "ReLU神经网络的离散功能几何通过ReLU过渡图", "title_en": "Discrete Functional Geometry of ReLU Networks via ReLU Transition Graphs", "authors": "Sahil Rajesh Dhayalkar", "background": "本文扩展了ReLU过渡图(RTG)框架，将其转化为一个全面的图论模型，用于理解深度ReLU网络。在该模型中，每个节点表示一个线性激活区域，边连接通过单个ReLU激活翻转不同的区域，形成了网络功能行为的离散几何结构。研究表明，随机初始化的RTGs具有强扩张性、二项式度分布和紧密控制泛化的光谱性质。这些结构性的见解为通过区域熵获取容量的新界限以及通过光谱间隙和边向量KL散度获取泛化的界限提供了新的依据。实证结果显示，过参数化下区域熵饱和，光谱间隙与泛化相关，相邻区域之间的KL散度反映了功能平滑性。这项工作提供了一种统一的框架，通过离散功能几何学来分析ReLU网络，提供新的工具来理解、诊断和优化泛化能力。", "innovation": "本文通过自定义的ReLU过渡图(RTG)框架，提出了一个新的图论模型来理解深度的ReLU网络。它揭示了网络功能行为的离散几何结构。研究证明了RTGs在随机初始化时的扩展性、二项式度分布以及这些结构对泛化的控制。提出了通过区域熵、光谱间隙和边缘方式的KL散度来度量模型容量和泛化性能的新方法。", "conclusion": "本文提供了一个统一的框架，通过离散功能几何学来分析ReLU网络，这为理解、诊断和优化ReLU网络的泛化能力提供了新的工具和技术。"}
{"llm_update_time": "20250907", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.03335", "html_url": "https://arxiv.org/abs/2509.03335", "title": "EvolveSignal：一种大语言模型赋能的代码代理，用于发现交通信号控制算法", "title_en": "EvolveSignal: A Large Language Model Powered Coding Agent for Discovering Traffic Signal Control Algorithms", "authors": "Leizhen Wang,Peibo Duan,Hao Wang,Yue Wang,Jian Xu,Nan Zheng,Zhenliang Ma", "background": "固定时间的交通信号控制由于其低成本、稳定性和易解释性在交通工程中仍被广泛使用。然而，其设计依赖于手工设计的公式（例如韦伯公式）和工程师的手动调整以适应需求变化，这种方法耗时且在异质或拥堵情况下往往效果不佳。现有的交通信号控制算法主要是基于手工设计和调整，这使得难以快速适应交通需求的变化，且在处理复杂的交通流时效率不高。", "innovation": "这项论文提出了EvolveSignal，一种由大语言模型（LLMs）驱动的代码代理，用于自动发现新的交通信号控制算法。该方法将算法设计问题转化为程序合成问题，并通过迭代优化（例如使用交通模拟器进行评估和进化搜索）来生成新的算法。实验结果表明，EvolveSignal发现的算法在信号交叉口中性能优于韦伯基准算法，平均延误减少20.1%，平均停车次数减少47.1%。此外，通过消融和增量分析表明，EvolveSignal的修改（如调整周期长度上下限、引入右转需求、重新调整绿灯分配比例）可以为交通工程师提供实际意义的见解。这项研究为利用AI进行交通信号控制算法设计开辟了一个新的研究方向，将程序合成与交通工程相结合。", "conclusion": "本研究利用大语言模型驱动的代码代理，成功地自动设计了新的交通信号控制算法，在提高交通效率方面具有实际意义。这种方法可以通过较短的时间内适应不同的交通需求，并为交通工程师提供实用见解。这表明未来可以利用这些技术进行更智能和高效的交通管理系统设计，从而改善交通拥堵和提升整体交通运输效率。"}
{"llm_update_time": "20250907", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2407.15161", "html_url": "https://arxiv.org/abs/2407.15161", "title": "FFHFlow：基于流变似然推理的多样性和不确定性感知灵巧抓取生成", "title_en": "FFHFlow: Diverse and Uncertainty-Aware Dexterous Grasp Generation via Flow Variational Inference", "authors": "Qian Feng,Jianxiang Feng,Zhaopeng Chen,Rudolph Triebel,Alois Knoll", "background": "在机器人学习中，基于部分观察生成多样且不确定性感知的多指灵巧手抓取依然是一个关键挑战。现有的生成方法难以建模灵巧手复杂的抓取分布，而且往往无法处理部分点云中存在的形状不确定性，因此导致生成的抓取不可靠或过于保守。", "innovation": "FFHFlow 是一种基于流的变异框架，能够生成多样和鲁棒的多指抓取，同时明确量化部分点云中的感知不确定性。FFHFlow 利用正则化流动基的深度隐变量模型学习层次抓取流形，克服了条件变异自动编码器(cVAEs)的模式崩溃和刚性先验的局限。通过利用流动的可逆性和精确似然性，FFHFlow 反思部分观察中的形状不确定性，标识出新型物体结构，从而实现风险感知抓取合成。此外，通过结合区分度抓取评估器与流动似然性，FFHFlow 形式化一个不确定性感知的评估策略，优先考虑对形状模糊具有鲁棒性的抓取。", "conclusion": "广泛的仿真实验和现实世界设置表明，FFHFlow 在抓取多样性和成功率方面优于最先进的基线方法（包括扩散模型），并且实现了运行时效率高的采样。FFHFlow 在拥挤且受限的环境中也展示了其实用价值，通过促进多样取样使得碰撞减少（项目主页：https://example.com/）。"}
{"llm_update_time": "20250907", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.03497", "html_url": "https://arxiv.org/abs/2509.03497", "title": "全球作物类型分类中的不变特征", "title_en": "Invariant Features for Global Crop Type Classification", "authors": "Xin-Yi Tong,Sherrie Wang", "background": "准确获取全球尺度上的作物类型及其空间分布对于食品安全、农业政策制定和可持续发展至关重要。遥感技术为大规模作物分类提供了有效解决方案，但由于许多地区可靠的地面样本不足，限制了其跨地理区域的应用。为了解决地理空间变换下的性能下降问题，本研究确定了对地理变异具有不变性的遥感特征，并提出了增强跨区域一般性的策略。构建了包含300,000像素级别的来自五大洲八个国家的作物类型数据集CropGlobe，涵盖了六大主要粮食和工业作物（玉米、大豆、水稻、小麦、甘蔗、棉花）。CropGlobe广泛覆盖地理区域，使得在跨国界、跨大陆、跨半球的转移下进行系统性评估成为可能。比较了时序多光谱特征（Sentinel-2基于的一维/二维中值特征和谐波系数）和高光谱特征（来自EMIT）的可移植性，设计了针对像素级作物分类的轻量级和鲁棒的卷积神经网络CropNet，并结合了时间变化、时间缩放和幅度扭曲的时序数据增强，以模拟现实的跨区域物候变化。实验结果显示，Sentinel-2的一维中值时序特征在所有转移场景下一致性最强，并且数据增强进一步提高了鲁棒性，特别是在训练数据多样性有限时更为明显。", "innovation": "研究确定了对地理变异具有不变性的遥感特征，并提出了一个轻量级且 robust的卷积神经网络CropNet，结合了时序数据增强，以应对光谱和物候变异，提升了跨区域一般性。构建了全球作物类型数据集CropGlobe，实现了跨国界、跨大陆和跨半球的系统性评估。", "conclusion": "研究识别了更具有不变性的特征表示，以增强地理转移性，并为全球多样地区的大规模、低成本作物类型应用探索了一条有希望的道路。"}
{"llm_update_time": "20250907", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2008.07324", "html_url": "https://arxiv.org/abs/2008.07324", "title": "智能 primer", "title_en": "Intelligence Primer", "authors": "Karl Fezer,Andrew Sloss", "background": "智能对所有生命体都是基本组成部分，同时也是人工智能的基础。本文旨在探讨与智能相关的理念，以理解其潜在的影响、约束条件及未来系统的能力。人工智能通过机器学习已经极大地影响了我们的生活，在此探索中，我们将深入探讨构成智能的重要组成部分，并希望引发新的思考问题。智能不仅仅是一个可衡量的单一量，而是跨越了生物学、物理学、哲学、认知科学、神经科学、心理学和计算机科学等多个学科的主题。未来的工程师和科学家需要广泛理解包括心理学、哲学和伦理学在内的其他领域。人工智能和法律要求的出现将这些更广泛的学科带入了研究的前沿。本文旨在介绍智能的概念，并迅速进入更深层次的思想和概念。我们称之为“生命、宇宙和一切”的 primer，灵感来自道格拉斯·亚当斯的著名科幻小说《生命、宇宙及切事》。答案可能只是四十二，但问题是哪些？", "innovation": "本文试图探讨与智能相关的深层次概念和思想，跨越多个学科的研究领域，提出了智能不仅是一个单一衡量标准，而是多维度综合体的观点。强调了未来工程师和科学家需要更加广泛的学科理解，尤其是心理学、哲学和伦理学的重要性。本文还特别指出了人工智能及相关法律要求对推动这些更广泛学科研究的影响，有助于引导未来的相关研究方向。", "conclusion": "智能是一个复杂的多维度主题，不仅限于技术层面，还涵盖了生物学、物理学、哲学、认知科学、神经科学、心理学和计算机科学等多个领域。为了更好地理解和开发人工智能，未来的科学家和工程师需要更强的跨学科意识，特别是增强对于心理学、哲学和伦理学的理解。"}
{"llm_update_time": "20250907", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2405.20321", "html_url": "https://arxiv.org/abs/2405.20321", "title": "基于单个人视频的开放世界对象图视见式操作", "title_en": "Vision-based Manipulation from Single Human Video with Open-World Object Graphs", "authors": "Yifeng Zhu,Arisrei Lim,Peter Stone,Yuke Zhu", "background": "本工作研究了通过模仿人类视频来学习基于视见的操作技能的问题，特别是在开放世界场景下，机器人能够从单一视频示例中学习操作新物体。背景信息指出，现有方法通常需要大量人工标注数据或多种操作示例，而该研究旨在减少对这些需求的依赖，使机器人能够从日常移动设备拍摄的视频中学习，并能够适应不同的视觉背景、相机角度、空间布局和新对象实例。", "innovation": "本工作的创新在于提出了ORION算法，该算法能够从单一的RGB或RGB-D视频中提取以对象为中心的操作计划，并从中推导出条件依赖的策略。这种方法使机器人能够从日常使用的移动设备中捕获的视频学习，并能将策略推广到具有不同视觉背景、相机角度、空间布局和新型物体实例的部署环境。研究还在短期和长期任务中系统地评估了这种方法，使用了RGB-D和仅RGB的演示视频。结果显示，平均成功率达到了74.4%，证明了ORION在开放世界中从单个人类视频中学习的有效性。", "conclusion": "研究表明，ORION算法能够在开放世界中通过单个人类视频有效学习新的操作技能，实现了在不同任务和不同演示类型的广泛应用。该方法的优势在于它能够自适应变化的环境条件，无需大量人工干预，提高了机器人的自主操作能力。"}
{"llm_update_time": "20250907", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2405.06464", "html_url": "https://arxiv.org/abs/2405.06464", "title": "单一随机数生成的布朗路径及其积分用于自适应和高阶SDE求解器", "title_en": "Single-seed generation of Brownian paths and integrals for adaptive and high order SDE solvers", "authors": "Andraž Jelinčič,James Foster,Patrick Kidger", "background": "自适应时间步长在常微分方程（ODE）模拟中取得了成功，但在随机微分方程（SDE）模拟中应用较少。用于自适应模拟SDE的方法如虚拟布朗运动树（VBT），能够非时序地生成布朗运动（BM）。但是，在大多数应用中，仅仅知道布朗运动的值不足以实现高阶收敛，还需要计算布朗运动的时间积分，例如积分 ∫_s^t W_r dr。", "innovation": "作者扩展了VBT，使其不仅能够生成布朗运动增量，还能生成这些布朗运动的时间积分。这种方法通过JAX实现，并包含在流行库Diffrax中。这种方法通过单个伪随机数生成器（PRNG）种子生成整个布朗路径，因此之前生成的样本无需存储，从而实现恒定的内存占用，确保了实验的可重复性和误差估计的稳健性。时间复杂度通过二分搜索降低，使其与误差参数ε成对数关系。此外，作者证明了该构造可以在任何查询时间严格匹配布朗运动及其时间积分的联合分布，只要这些时间间隔至少为ε。", "conclusion": "作者利用新的VBT应用了自适应高阶求解器，进行了两个实例演示。在模拟高波动性的CIR模型时，获得了比固定时间步长高两倍的收敛阶。此外，当应用于MCMC问题时，自适应三阶欠阻尼或动能拉格朗日方程求解器达到与No-U-Turn采样器相当的性能，但仅使用其十分之一的函数评估次数。"}
{"llm_update_time": "20250907", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2411.04228", "html_url": "https://arxiv.org/abs/2411.04228", "title": "dsld：一种与社会相关联的教学统计工具", "title_en": "dsld: A Socially Relevant Tool for Teaching Statistics", "authors": "Aditya Mittal,Taha Abdullah,Arjun Ashok,Brandon Zarate Estrada,Shubhada Martha,Billy Ouattara,Jonathan Tran,Norman Matloff", "background": "数据科学在统计教育中的影响力越来越大，需要能够通过实际应用使关键概念易于理解的工具。", "innovation": "该论文介绍了名为\"数据科学考察歧视\"（dsld）的R包，提供了全面的分析和图形方法，用于研究涉及种族、性别和年龄等属性的歧视问题。通过将公平性分析作为教学工具，该工具使教师能够通过实际应用示例来展示协变量效应、模型偏见等相关主题。", "conclusion": "dsld包的函数实现已被描述，并通过示例进行了说明。为了帮助学生和法律专业人士理解这些原则并将其应用于实际数据，还提供了一本80页的Quarto书籍。此外，Python接口也已提供。"}
{"llm_update_time": "20250907", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2410.18970", "html_url": "https://arxiv.org/abs/2410.18970", "title": "WASP: 一种检测已学习的虚假相关性的权值空间方法", "title_en": "WASP: A Weight-Space Approach to Detecting Learned Spuriousness", "authors": "Cristian Daniel Păduraru,Antonio Bărbălau,Radu Filipescu,Andrei Liviu Nicolicioiu,Elena Burceanu", "background": "训练机器学习模型时，明确理解每个类别的定义至关重要。虽然已有大量研究致力于识别可能影响模型对类理解的数据集中的虚假相关性，但现有方法均仅依赖数据或错误分析，无法指出模型内未在验证或训练集的反例中揭示出的虚假相关性。因此，本文提出了一个新的方法，WASP，用于分析模型权重，进一步揭示了模型决策背后的机制，比单纯预测分析更具见解性。", "innovation": "本文提出的方法WASP能够解决现有方法的限制，从分析模型权重而非预测角度入手，用于检测已学习的虚假相关性。WASP具有以下创新点：(i) 能揭示即使在训练或验证反例未揭露的情况下存在的数据集中的虚假相关性；(ii) 适用于多种模态，包括图像和文本；(iii) 能发现ImageNet-1k模型中之前未被察觉到的虚假相关性。", "conclusion": "WASP方法通过分析模型权重，能够更深入揭示虚假相关性，适用于多模态数据，发现了未被发现的虚假相关性，为理解模型决策机制提供了更全面的视角。"}
{"llm_update_time": "20250907", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2501.14701", "html_url": "https://arxiv.org/abs/2501.14701", "title": "一种评估转诊适宜性的无监督自然语言处理管道", "title_en": "An Unsupervised Natural Language Processing Pipeline for Assessing Referral Appropriateness", "authors": "Vittorio Torri,Annamaria Bottelli,Michele Ercolanoni,Olivia Leoni,Francesca Ieva", "background": "评估诊断转诊的适宜性对于提高医疗效率和减少不必要的程序至关重要，但当转诊理由仅以自由文本形式记录而不是结构化代码时，这个任务变得具有挑战性。为了应对这一差距，该研究提出了一种完全无监督的自然语言处理（NLP）管道，能够提取和评估转诊理由，而无需依赖标记的数据集。", "innovation": "该研究提出了一种基于Transformer的预训练 embedding 和无监督聚类的 NLP 管道，它可以无需使用标签数据集直接处理自由文本的转诊理由，并且能够在不同类型的检查项目中泛化。该管道通过分析实际地区数据展示了如何有效利用此类数据，提供了一种适用于公共卫生主管当局的可部署 AI 工具，以监控实践并支持基于证据的政策。", "conclusion": "该研究介绍了一种稳健且可扩展的无监督NLP管道，用于在大型现实世界数据集中评估转诊适宜性，证实此类数据的有效利用，为公共卫生当局提供了能够部署的AI工具，以监控实践并支持基于证据的政策。"}
{"llm_update_time": "20250907", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2411.14013", "html_url": "https://arxiv.org/abs/2411.14013", "title": "通过音频指纹揭示合成语音：AI生成语音的模型归属与检测", "title_en": "Exposing Synthetic Speech: Model Attribution and Detection of AI-generated Speech via Audio Fingerprints", "authors": "Matías Pizarro,Mike Laszkiewicz,Shawkat Hesso,Dorothea Kolossa,Asja Fischer", "background": "随着语音生成技术在质量和可访问性上不断进步，恶意使用案例的风险，包括冒充、虚假信息和欺骗，也在迅速增加。本文通过介绍一种简单、无需训练且有效的方案来检测人工智能生成的语音并将其归因于其来源模型来应对这一威胁。", "innovation": "提出了一种简单、无需训练的方案，能够检测AI生成的语音并将其归因于其来源模型，具体来说，能够解决三个关键任务：在开放世界环境中进行单一模型归因、在封闭世界环境中进行多种模型归因以及检测合成语音和真实语音。该方法利用标准化平均残差作为不同的、模型无关的指纹，以一致地捕获由多种语音合成系统引入的特征。", "conclusion": "通过广泛的实验，该方法在大多数场景下实现了超过99%的AUROC分数，在增强基准数据集上对真实语音和多种合成语音进行配对评估。此外，稳健性分析展示了该方法在存在适度添加噪声的情况下仍能保持高性能。由于其简单性、效率和在语音合成系统和语言之间的强大泛化性，该技术为数字取证和安全应用提供了实用的工具。"}
{"llm_update_time": "20250907", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2408.13115", "html_url": "https://arxiv.org/abs/2408.13115", "title": "高维空间中未调整拉格朗日算法的收敛性：偏差的去局域化", "title_en": "Convergence of Unadjusted Langevin in High Dimensions: Delocalization of Bias", "authors": "Yifan Chen,Xiaoou Cheng,Jonathan Niles-Weed,Jonathan Weare", "background": "未调整拉格朗日算法常被用于在极高维设置下抽取概率分布。现有分析表明，对于强对数相凹分布，随着问题维度$d$的增加，算法在$W_2$距离内收敛所需的迭代次数与$d$或$\frac{\root \null \fn {d}\null }{\fn {4}}$呈比例关系。", "innovation": "研究表明，对于整个变量集合的$W_2$误差表现不佳的情况下，小数量变量的行为可以显著改善：算法在对数因子项与$d$相关的次数内便能收敛到所有$K$-边际所需的$W_2$误差，这种影响被称为偏差的去局域化。分析依赖于新的$W_{2,\fn {\fn {∞} \null }\null }$度量来度量收敛。解决了这一度量的一步收缩性质缺失的关键技术问题。", "conclusion": "偏差的去局域化效应在某些情况下是有效的，但对于所有分布并不普遍适用，并被证明在高斯分布和特定稀疏交互的强对数相凹分布中成立。通过渐近讨论探索了偏差去局域化效应在高斯和稀疏交互之外的潜在一般化。"}
{"llm_update_time": "20250907", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2410.01228", "html_url": "https://arxiv.org/abs/2410.01228", "title": "ConServe：细粒度GPU收获，用于LLM在线和离线协同服务", "title_en": "ConServe: Fine-Grained GPU Harvesting for LLM Online and Offline Co-Serving", "authors": "Yifan Qiao,Shu Anzai,Shan Yu,Haoran Ma,Shuo Yang,Yang Wang,Miryung Kim,Yongji Wu,Yang Zhou,Jiarong Xing,Joseph E. Gonzalez,Ion Stoica,Harry Xu", "background": "大型语言模型（LLM）需要低延迟和高吞吐量，但高负载波动使得高GPU利用率变得具有挑战性。现有的服务系统无法高效地同时处理需要低延迟的在线请求和可以容忍较大延迟的离线任务，如模型基准测试。现有的系统通常在请求或迭代级别进行粗粒度的资源管理，这无法在保证在线延迟目标的前提下充分利用毫秒级的GPU空闲周期，从而降低了GPU的使用率和吞吐量。因此，迫切需要一种新的机制，通过在更精细的粒度级别管理资源来实现高吞吐量并严格保证在线延迟目标。", "innovation": "ConServe是一个新的LLM协同服务系统，通过在更细腻的粒度级别管理资源实现了高吞吐量并严格保证了在线延迟目标。它引入了以下三种技术：(1) 一种延迟感知的标记级调度器，能够精确地调整离线批次和标记大小以适应在线延迟目标；(2) 子迭代、逐层中断机制，当遭遇在线负载高峰时可以让离线任务主动让步；(3) 增量KV缓存管理，允许在几乎不影响性能的情况下暂时中断并恢复离线请求。", "conclusion": "实验结果表明，ConServe在使用Llama-3.1和Qwen-2.5模型时提高了2.2倍的吞吐量，并且将在线服务的延迟尾部降低了2.9倍，相较于最先进的系统性能更为优越。"}
{"llm_update_time": "20250907", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2411.12736", "html_url": "https://arxiv.org/abs/2411.12736", "title": "ACING: Actor-Critic for Instruction Learning in Black-Box LLMs", "title_en": "ACING: Actor-Critic for Instruction Learning in Black-Box LLMs", "authors": "Salma Kharrat,Fares Fourati,Marco Canini", "background": "大型语言模型（LLMs）在完成任务的效果很大程度上依赖于它们的指令质量，而这通常需要大量的手工努力来制定。因此，自动化指令优化的需求变得尤为迫切。然而，在处理黑盒LLMs时，由于无法访问模型参数和梯度，优化指令变得特别具有挑战性。过去的工作在优化黑盒LLM的指令方面并没有取得很好的效果", "innovation": "我们提出了一个新的方法ACING（Actor-Critic for Instruction Learning in Black-Box LLMs），它是一个基于演员-评论家强化学习框架，将指令优化形式化为一个无状态、连续动作的问题，仅使用黑盒反馈就能探索无限的指令空间。ACING自动发现的提示在76%的任务中优于手工编写的提示，在33个任务（涵盖指令诱导、总结和因果推理）中，相对于最好的自动基线，ACING提高了最高33个百分点，中位数改善了10个百分点。", "conclusion": "广泛的经验表明，ACING在鲁棒性和效率方面具有优势。ACING的实现可以在这里找到：[提供的链接]"}
{"llm_update_time": "20250907", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2411.06119", "html_url": "https://arxiv.org/abs/2411.06119", "title": "硬件友好型设备上图像生成的固定尺寸可复用结构扩散模型", "title_en": "Hardware-Friendly Diffusion Models with Fixed-Size Reusable Structures for On-Device Image Generation", "authors": "Sanchar Palit,Sathya Veera Reddy Dendi,Mallikarjuna Talluri,Raj Narayana Gadde", "background": "Vision Transformers 和 U-Net 架构在扩散模型的实现中被广泛应用，但每种架构在设备上实现时都面临着特定的挑战。Vision Transformers 需要位置嵌入来保持变换器处理的标记之间的对应关系，虽然这种方法允许使用定尺寸、可重复使用的标记化块。而 U-Net 架构在噪声估计骨干中利用了变量尺寸的中间块进行下卷积和上卷积，缺乏这些特性。因此，需要一种新的架构解决这些问题，这种架构可以利用固定尺寸、可复用的变压器块作为核心结构，更适合硬件实施。", "innovation": "提出了一种利用固定尺寸、可复用的变换器块作为核心结构的新型架构。该方法的主要特性包括低复杂性、标记自由设计、无位置嵌入、统一性及可扩展性，使其特别适合部署在移动和资源受限的设备上。模型在无条件和有条件图像生成任务中展示了竞争力的和一致的性能，并在 CelebA 的无条件图像生成任务中实现了最先进的 FID 分数 1.6.", "conclusion": "提出的模型在无条件和有条件图像生成任务中表现出具有竞争力和一致性的性能，并在 CelebA 的无条件图像生成任务中实现了最新的 FID 分数 1.6，表明该模型在设备上的部署和应用非常合适。"}
{"llm_update_time": "20250907", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2501.18158", "html_url": "https://arxiv.org/abs/2501.18158", "title": "大型语言模型在加密货币交易分析中的应用：比特币案例研究", "title_en": "Large Language Models for Cryptocurrency Transaction Analysis: A Bitcoin Case Study", "authors": "Yuchen Lei,Yuexin Xiang,Qin Wang,Rafael Dowsley,Tsz Hon Yuen,Kim-Kwang Raymond Choo,Jiangshan Yu", "background": "加密货币在广泛使用，但现有的交易分析方法往往依赖于不透明的黑盒模型，尽管这些模型可能实现高性能，但它们的输出通常难以解释和适应，使得捕捉复杂的用户行为模式变得困难。大型语言模型（LLMs）具有填补这些空白的潜力，特别是在网络犯罪检测方面，但它们在这方面的能力尚未被充分探索。", "innovation": "本文通过将LLMs应用于实际的加密货币交易图，并集中在比特币上，提出了一种三层框架来评估LLMs的能力：基础指标、特征概述和上下文解释。该框架包括一种新的、可读的图表示格式LLM4TG和一种增强连接性交易图采样算法CETraS。这些算法大大减少了需要的代币数量，使得在严格的代币限制下使用LLMs分析多个中等规模的交易图成为可能。实验结果表明，LLMs在基础指标和特征概述方面的表现非常出色，在节点层面识别基本信息的准确性超过98.50%，且获取有意义特征的比例达到95.00%。在上下文解释方面，即使在标记数据有限的情况下，LLMs也表现出强大的分类性能，其中top-3准确率达到72.43%，并伴有解释。", "conclusion": "尽管解释有时不够完全准确，但仍显示出LLMs在这一领域的强大潜力。同时，文中讨论了存在的一些限制，并提出了未来研究的方向。"}
{"llm_update_time": "20250907", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2501.03905", "html_url": "https://arxiv.org/abs/2501.03905", "title": "MixNet: 一种适用于分布式混合专家训练的运行时可重构光-电网络", "title_en": "MixNet: A Runtime Reconfigurable Optical-Electrical Fabric for Distributed Mixture-of-Experts Training", "authors": "Xudong Liao,Yijun Sun,Han Tian,Xinchen Wan,Yilun Jin,Zilong Wang,Zhenghang Ren,Xinyang Huang,Wenxue Li,Kin Fai Tse,Zhizhen Zhong,Guyue Liu,Ying Zhang,Xiaofeng Ye,Yiming Zhang,Kai Chen", "background": "Mixture-of-Expert (MoE) 模型通过在每个令牌基础上选择性地激活不同的子网（称为专家）来超越传统的模型。这种门控计算生成了无法预先确定的动态通信模式，这挑战了现有的 GPU 互连，在分布式训练过程中保持静态。", "innovation": "本文介绍了一种名为 MixNet 的创新型系统，该系统在分布式 MoE 训练期间解锁了拓扑重构。系统采用了基于区域的可重构高带宽域，通过使用光学电路开关（OCS）在现有的电气互连上实现可扩展性与快速适应性。MixNet 支持在 32 块 A100 GPU 上对最先进的 MoE 模型进行训练，并通过在链路带宽分别为 100 Gbps 和 400 Gbps 的大规模数据包级仿真中显示出比非阻塞 fat-tree 架构性能相近的同时，使得四种代表性 MoE 模型的训练成本效率提高了 1.2x-1.5x 和 1.9x-2.3x。", "conclusion": "通过使用 MixNet 设计和实现了一个具有区域可重构性的原型，该原型利用现有硬件和自定义集体通信运行时，实现了在训练过程中对状态最前沿 MoE 模型的拓扑重构，展示了相比于现有解决方案的显著性能和成本优势。"}
{"llm_update_time": "20250907", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2502.14791", "html_url": "https://arxiv.org/abs/2502.14791", "title": "通过元内文学习快速学习新词", "title_en": "Rapid Word Learning Through Meta In-Context Learning", "authors": "Wentao Wang,Guangyuan Jiang,Tal Linzen,Brenden M. Lake", "background": "人类能够从少量示例中快速学习新的词汇，并在新情境中系统地和灵活地使用它。然而，当前语言模型在少量示例下学习新词的能力以及提高这种能力的方法尚未得到充分研究。", "innovation": "本文提出了一种新的方法——Meta-training for IN-context learNing Of Words (Minnow)。该方法利用一个特殊的占位符标记来表示新的词汇，并生成给定少量内文示例的新用法例子。这种方法在大量新的词汇上重复训练，发展了一种通用的新词学习能力。研究表明，使用Minnow从零开始训练模型在人类规模的儿童定向语言数据上，能够实现与大量预训练语言模型相当的少量示例下的新词学习能力。", "conclusion": "通过辨别性和生成性评估，我们发现使用Minnow对预训练的语言模型进行微调能够提高它们识别新词的能力、识别新词的词性类别，并基于一两个内文示例生成合理的新用法和定义。这些发现强调了Minnow的数据效率及其在语言模型新词学习任务中的潜在提升作用。"}
{"llm_update_time": "20250907", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2504.02737", "html_url": "https://arxiv.org/abs/2504.02737", "title": "RBT4DNN: 基于需求的神经网络测试", "title_en": "RBT4DNN: Requirements-based Testing of Neural Networks", "authors": "Nusrat Jahan Mozumder,Felipe Toledo,Swaroopa Dola,Matthew B. Dwyer", "background": "测试是开发人员用来确定系统是否按照预期运行的一种方法。这类系统如果包括深度神经网络（DNN），测试就会变得具有挑战性，因为DNN近似出的功能，在形式化功能需求方面是不可化简的。这使得将基于需求的测试方法应用于DNN变得困难。", "innovation": "我们提出了一个基于需求的测试方法（RBT4DNN），它使用自然语言的需求陈述。这些陈述通过一个术语表定义了语义特征空间，可以利用这些语义特征空间生成测试输入。RBT4DNN将功能需求的前提条件形式化为语义特征的逻辑组合。该方法利用匹配这些特征组合的数据进行训练，以微调生成模型，从而可靠地产生满足前提条件的测试输入。通过在训练好的DNN上执行这些测试，可以将输出与预期的需求后置条件行为进行比较。我们还提出了RBT4DNN的两种应用场景：1）根据定义DNN正确性的需求，RBT4DNN提供了一种检测故障的新方法；2）在开发过程中，基于需求的模型行为探索可以为开发人员提供关于模型泛化能力的反馈。", "conclusion": "我们的进一步评估表明，RBT4DNN生成的测试是现实的、多样化的，并且与需求的前提条件保持一致，这使得它可以针对模型行为进行有目标的分析，有效地检测故障。"}
{"llm_update_time": "20250907", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2504.04421", "html_url": "https://arxiv.org/abs/2504.04421", "title": "基于包装配置树的3D 包装精细规划", "title_en": "Deliberate Planning of 3D Bin Packing on Packing Configuration Trees", "authors": "Hang Zhao,Juzhan Xu,Kexiong Yu,Ruizhen Hu,Chenyang Zhu,Bo Du,Kai Xu", "background": "3D 二维箱体包装问题（3D-BPP）在工业自动化领域有广泛应用。现有方法通常受限于空间离散化的有限分辨率，且难以很好地处理复杂的实际约束条件。", "innovation": "提出了通过在一种新颖的层次表示——包装配置树（PCT）上学习来提高在线3D-BPP的实际适用性。PCT是一种全面的状态和动作空间描述，支持基于深度强化学习（DRL）的包装策略学习，并且能够适应连续解空间。此外，还提出了递归包装方法将大规模包装分解成更小的子树，并通过空间集成机制将局部解决方案融入全局。对于不同类型的BPP变化，还提出了一种统一的规划框架，使其能够解决各种实际约束问题。实验表明，该方法优于现有在线BPP基准方法，并且在大规模问题和不同问题变体中表现出色。还开发了一个适用于工业仓储的实物包装机器人，操作可靠且高效，每10秒可以处理一个箱子，每次平台平均可装19个箱子，空间利用率为57.4%。", "conclusion": "该方法在大规模问题和多样化的BPP变体中表现出色，能够融入各种实际约束。开发的实物包装机器人在不受保护的托盘上的操作既可靠又高效。"}
{"llm_update_time": "20250907", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2503.23746", "html_url": "https://arxiv.org/abs/2503.23746", "title": "短视频传播影响力评级：一种新的跨平台数据集和大型图模型", "title_en": "Short-video Propagation Influence Rating: A New Real-world Dataset and A New Large Graph Model", "authors": "Dizhan Xue,Shengsheng Qian,Chuanrui Hu,Changsheng Xu", "background": "短视频平台在全球范围内获得了极大的普及，吸引了数百万甚至数十亿用户。近期研究强调了分析短视频传播的重要性，旨在发现商业价值、公众意见和用户行为等。但目前缺乏用于此类研究的大型跨平台数据集，也没有大规模使用大型语言模型（LLMs）进行分析的方法。", "innovation": "提出了新的跨平台短视频（XS-Video）数据集，包含117,720个视频，381,926个样本，535个主题，覆盖5个中国主要平台，并标注了从0到9的不同传播影响力。此外，提出了基于新型三阶段训练机制的大型图模型（NetGPT），能理解和分析短视频传播图，预测短视频的长期传播影响力。", "conclusion": "通过跨平台数据集和大型图模型NetGPT，这种方法在短视频传播影响力评级（SPIR）任务上取得了优于现有方法的性能。"}
{"llm_update_time": "20250907", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2503.00648", "html_url": "https://arxiv.org/abs/2503.00648", "title": "通过从头设计肽揭示T细胞受体特异性景观", "title_en": "T-cell receptor specificity landscape revealed through de novo peptide design", "authors": "Gian Marco Visani,Michael N. Pun,Anastasia A. Minervina,Philip Bradley,Paul Thomas,Armita Nourmohammad", "background": "T细胞在适应性免疫中扮演关键角色，通过对多种病原体产生特异性反应。有效的T细胞受体（TCRs）与病原体衍生多肽结合，呈现在主要组织相容性复合体（MHCs）上，触发免疫反应。然而，由于有限的T细胞反应功能数据，预测这些相互作用仍颇具挑战性。本文介绍了一种计算方法，用于预测TCRs与MHC I类等位基因呈现的多肽的相互作用，以及设计针对特定TCR-MHC复合体的新型免疫原性多肽。该方法利用了HERMES模型，这是一种基于结构的、以物理为指导的机器学习模型，通过对蛋白质宇宙的训练来预测氨基酸偏好。尽管模型未直接训练于TCR-pMHC数据上，但仍能准确预测TCR-pMHC结合亲和力和T细胞活性，相关性高达0.72。", "innovation": "该研究开发了一种计算方法来预测TCRs与MHC I类等位基因呈现的多肽的相互作用，并设计出针对特定TCR-MHC复合体的新型免疫原性多肽。研究证明该模型可以准确预测TCRs和MHCs结合亲和力及T细胞活性，相关性高达0.72。该方法可用于设计免疫治疗和疫苗中的工程化T细胞疗法。通过实验验证，证明了基于模型的从头设计多肽的有效性，并揭示了TCR-MHC复合体的多肽识别多样化景观，为T细胞特异性提供了重要见解。", "conclusion": "本文提供了一个平台，用于设计免疫原性多肽和新抗原，并评估TCR特异性。这为工程化T细胞疗法和疫苗的设计提供了计算框架。"}
{"llm_update_time": "20250907", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2503.16561", "html_url": "https://arxiv.org/abs/2503.16561", "title": "未来生成：基于RAG的方法生成科学文章的未来工作", "title_en": "FutureGen: A RAG-based Approach to Generate the Future Work of Scientific Article", "authors": "Ibrahim Al Azher,Miftahul Jannat Mokarrama,Zhishuai Guo,Sagnik Ray Choudhury,Hamed Alhoori", "background": "未来工作部分概述了科学文章中当前研究的空白和局限性，并为早期职业研究人员提供了未探索的研究领域，也为有经验的研究人员提供了新的项目或合作机会。本研究通过相关论文的上下文，使用RAG增强了未来工作的生成过程，并通过大量语言模型（LLM）和LLM反馈机制提高了生成内容的质量。该研究比较了不同方法的效果，并通过人类评估检验了LLM作为提取器、生成器和反馈提供者的性能。", "innovation": "本研究的创新点在于使用检索增强生成（RAG）方法结合大语言模型（LLM）反馈机制来生成科学文章的未来工作。该方法利用相关文章的上下文来丰富生成过程，同时引入LLM作为评判者框架，评估新颖性、幻想性、可行性等关键方面。实验证明，采用GPT-4o mini和LLM反馈机制的RAG方法在定性和定量评估中都优于其他方法。此外，还通过人类评估全面检验了该方法的效果和性能。", "conclusion": "研究结果表明，基于RAG的方法在生成科学文章的未来工作方面表现优异，特别是结合了LLM反馈机制。这种综合方法在新颖性、可行性和质量上均表现更佳，并为未来研究提出了有潜力的新方向。"}
{"llm_update_time": "20250907", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2504.11249", "html_url": "https://arxiv.org/abs/2504.11249", "title": "冷冻电镜图像本质上是低维度的", "title_en": "Cryo-em images are intrinsically low dimensional", "authors": "Luke Evans,Octavian-Vlad Murad,Lars Dingeldein,Pilar Cossio,Roberto Covino,Marina Meila", "background": "冷冻电子显微镜（cryo-EM）是研究生物分子结构的强大工具，但其模拟推理方法需要复杂的数据处理和丰富的信息推理。CryoSBI等方法使用神经网络从高效低维潜在空间推断生物分子构象，揭示了这些数据背后的潜在几何结构对于理解物理系统和推断过程至关重要。", "innovation": "研究通过应用流形学习技术，分析了CryoSBI方法下血凝素的模拟和实验数据的高维表示。研究发现，这些数据事实上填充了低维平滑流形，并通过扩散映射和坐标解释方法刻画了流形的几何结构，揭示了潜在结构与关键物理参数之间的直接联系。这一发现不仅验证了CryoSBI方法的有效性，还为通过利用揭示的流形几何结构从数据结构中学习提供机会。", "conclusion": "通过识别数据中的固有低维度性和可解释的几何组织，研究不仅验证了CryoSBI方法的有效性，还为未来的推断策略提供了改进的机会。这一研究揭示了cryo-EM数据背后隐藏的几何结构，为进一步优化冷冻电镜数据分析提供了潜在的机会。"}
{"llm_update_time": "20250907", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2504.16943", "html_url": "https://arxiv.org/abs/2504.16943", "title": "通过深度聚类揭示燃气机组的实证灵活性", "title_en": "Revealing the empirical flexibility of gas units through deep clustering", "authors": "Chiara Fusar Bassini,Alice Lixuan Xu,Jorge Sánchez Canales,Lion Hirth,Lynn H. Kaack", "background": "发电单元的灵活性决定了其能够迅速调整电力输出的速率和频率。在能源模型中，这一灵活性依赖于对单元技术特性的假设，例如安装容量或涡轮技术。本研究通过分析五年（2019-2023）来自100 MWp安装容量的49个德国单元的每小时发电数据，揭示实际限制如何导致同类技术单元之间存在显著差异。", "innovation": "研究采用了一种新颖的深度聚类方法，将49个德国单位5年的单元级每小时发电数据转化为低维嵌入。这种方法是一种无监督的方法，能够识别出两种一般的峰段单位（高灵活性）和两种非峰段单位（低灵活性）。", "conclusion": "非峰段单位，约占样本的一半，显示出低实证灵活性，与煤单位相当。这类单位因由工业和市政公用事业所有，对低余量负载和负价格反应有限，这些时段平均发电量仅为1.3 GWh。随着可再生能源比例的增长增加市场波动性，需要监管变更来撬动这种灵活性潜力。"}
{"llm_update_time": "20250907", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2505.01751", "html_url": "https://arxiv.org/abs/2505.01751", "title": "SGD中一些异常现象的动态视角", "title_en": "A dynamic view of some anomalous phenomena in SGD", "authors": "Vivek Shripad Borkar", "background": "贝尔金等人观察到，过度参数化的神经网络表现出一种‘双下降’现象。也就是说，随着模型复杂度（通过特征数量反映）的增加，测试误差先是减少，然后增加，之后再减少。这一现象在按周期训练的时间域中也有类似表现，即测试误差最初随迭代次数增加而减少，然后增加，再减少。另一种异常现象是‘grokking’，在其中下降的两个阶段被一个阶段打断，在此阶段平均损失几乎保持不变。本笔记旨在通过使用两时间尺度随机逼近理论，应用于梯度动态的连续时间极限，提供对这些和相关现象的一种可能解释，从而为已研究多年的话题提供一种新的视角.", "innovation": "提出了使用两时间尺度随机逼近理论，应用于梯度动态的连续时间极限，作为一种解释这些异常现象的新方法，为已研究多年的话题提供了一种新的视角.", "conclusion": "通过该方法，提出了对‘双下降’现象、‘grokking’等异常现象的一种新型解释."}
{"llm_update_time": "20250907", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2504.04873", "html_url": "https://arxiv.org/abs/2504.04873", "title": "基于闭合环网络操作员的交通密度观察器", "title_en": "Closed-Loop Neural Operator-Based Observer of Traffic Density", "authors": "Alice Harting,Karl Henrik Johansson,Matthieu Barreau", "background": "该研究关注于利用站式路边传感器的稀疏测量值估计交通密度的问题。传统的观测方法往往只能提供开放环预测，缺乏对预测误差的校正机制，这在实际场景中容易受到噪声干扰，导致预测不准。因此，研究提出利用傅里叶神经操作符来学习宏观交通流动模式，并通过结合预测密度与传感器的稀疏测量值来优化观测效果。", "innovation": "论文创新地提出了一种基于闭合环的神经操作符方法，通过结合物理学习和实时校正，对开放环预测结果进行修正。这种方法不仅提高了预测的稳健性，还保证了预测误差的最终有界性。此外，该方法还展示了其在实际数据收集和处理中的准确性和有效性。", "conclusion": "使用SMU软件进行的模拟表明，与开放环观测器相比，提出的闭环观测器在噪声鲁棒性和预测误差有界性方面表现出了经典闭环系统的特点。这种结合学习物理模型与实时校正的方法不仅提高了数据驱动观测器的准确性，还增强了模型的解释性，为未来的交通监控技术提供了新的研究方向。"}
{"llm_update_time": "20250907", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2505.05122", "html_url": "https://arxiv.org/abs/2505.05122", "title": "Text2Cypher：使用困难例选择进行数据剪裁", "title_en": "Text2Cypher: Data Pruning using Hard Example Selection", "authors": "Makbule Gulcin Ozsoy", "background": "关系数据库查询语言如SQL以及图数据库查询语言如Cypher已经被广泛采用。近年来，大型语言模型的进步使得通过Text2SQL和Text2Cypher等模型实现自然语言与数据库的交互成为可能。这些模型的微调通常需要包含复杂示例的大、多样化数据集。然而，随着数据集的增大，微调的成本也在上升，因此小而高质量的数据集变得十分必要，能够在保持同等或更优效果的同时减少资源使用和成本。", "innovation": "本文提出了一种用于修剪Text2Cypher数据集的五个困难例选择技术。这些技术旨在在减少资源消耗的同时，保持或提升性能。", "conclusion": "研究结果表明，这些困难例选择方法能够将训练时间及成本减半，同时对性能的影响最小，表明困难例选择为一种成本效益高的解决方案。"}
{"llm_update_time": "20250907", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.01044", "html_url": "https://arxiv.org/abs/2507.01044", "title": "宽且浅神经网络的渐近凸性", "title_en": "Asymptotic convexity of wide and shallow neural networks", "authors": "Vivek Borkar,Parthe Pandit", "background": "研究浅而宽的神经网络模型在输入输出映射中的参数对表现出良好性能的机制。", "innovation": "提出了一种新颖的解释，将神经网络输入输出映射的上图形与凸函数的上图形在精确意义上进行类比，从而解释了宽且浅的神经网络为何表现良好。", "conclusion": "在浅而宽的神经网络中，输入输出映射的上图形可以近似为凸函数的上图形，这为理解它们的良好性能提供了一个合理的解释。"}
{"llm_update_time": "20250907", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2505.20789", "html_url": "https://arxiv.org/abs/2505.20789", "title": "通过将中间层优化和投影梯度下降集成来解决带有扩散模型的逆问题", "title_en": "Integrating Intermediate Layer Optimization and Projected Gradient Descent for Solving Inverse Problems with Diffusion Models", "authors": "Yang Zheng,Wen Li,Zhaoqiang Liu", "background": "逆问题涉及从噪声观察结果重构信号。最近，扩散模型（DMs）作为解决逆问题的强大框架出现了，取得了显著的重构性能。然而，现有的DM基方法经常面临计算负担重和收敛欠佳的问题。", "innovation": "本文基于DMPlug的思路提出了两种新型方法，DMILO和DMILO-PGD，以应对这些挑战。首先提出的DMILO使用中间层优化（ILO）来缓解DMPlug固有的内存负担。通过引入稀疏偏差，扩张了DMs的适用范围，使得潜在信号的探索可以超出扩散模型的范围。进一步提出的DMILO-PGD通过将ILO与投影梯度下降（PGD）集成，减少次优收敛的风险。并在适当条件下提供直观的理论分析，并通过在多样化的图像数据集上的大量实验验证了其优越性，展示了DMILO和DMILO-PGD在DM基逆问题求解器中的有效性，其性能超过当前最先进的方法。", "conclusion": "我们的结果表明，DMILO和DMILO-PGD在解决常见DM基逆问题中的挑战方面表现出了显著的优势，验证了其对提高DMs在逆问题解决中的性能的有效性。"}
{"llm_update_time": "20250907", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2504.11671", "html_url": "https://arxiv.org/abs/2504.11671", "title": "社会模拟中LLM决策计算基础", "title_en": "Computational Basis of LLM's Decision Making in Social Simulation", "authors": "Ji Ma", "background": "大型语言模型（LLMs）在社会科学和应用环境中越来越多地充当类似人类的决策代理。这些LLM代理通常被赋予类似人类的性格特征，并置于现实情境中。然而，这些人物特征和情境如何影响LLM的行为尚未得到充分探索。本文通过在其内部抽象的向量空间中操作特定变量来研究、量化和修改LLM在“分配者游戏”中的内部表征，这是一种经典的公平和利他行为实验。这种探索为研究和社会工程如何在基于变换器的模型中编码和构建社会概念提供了原理性的方法，对齐模型、去偏见以及为学术和商业社会模拟设计AI代理具有重要意义，增强社会理论和测量体系的研究基础和应用范围。(提到了研究背景与问题设定的必要性和意义，构建了研究的基础框架和内涵。背景详细提炼相对于原始内容有所削减，以符合解析要求。]", "innovation": "本文提出的创新点在于：通过操作LLM内部的向量空间变量，探索并量化LLM在“分配者游戏”中的决策过程；这种方法提供了一种研究和控制如何在变换器模型中编码和构建社会概念的原理性方法，具有对齐模型、去偏见以及为社会模拟设计AI代理的应用潜力。(提炼了研究的创新点和方法，需注意表述精炼且准确。]", "conclusion": "该研究提出了一种方法，通过操作内部表征的向量空间变量，深入研究了LLM在“分配者游戏”中的决策过程。这种方法不仅为探索社会概念如何在变换器模型中编码提供了理论基础，还为AI代理的设计和应用提出了新的研究方向，如去偏见和模型对齐，对社会科学和商业应用都具有重要的实践意义。(关于研究结论的提炼，进一步强化了研究的实际应用价值和对未来研究的启示意义。]"}
{"llm_update_time": "20250907", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.09401", "html_url": "https://arxiv.org/abs/2506.09401", "title": "递归训练中模拟概率分布崩溃的理论基础", "title_en": "A theoretical basis for model collapse in recursive training", "authors": "Vivek Shripad Borkar", "background": "已知从生成模型中递归训练会导致所谓的‘崩溃’现象，即模拟的概率分布会收敛于一个错误的固定点，从而导致生成样本的质量下降。本文分析了这种‘崩溃’现象背后的原因，并指出即使仅加入一个非常小的外部样本源也会改变递归训练的不同极限行为，从而影响模型的表现。", "innovation": "本文创新地提出了一个理论框架来解释递归训练中模拟概率分布的崩溃现象，并揭示了外部样本源的影响。这项研究丰富了递归训练的理论基础，对于理解和优化生成模型具有重要意义。", "conclusion": "研究表明，即使是非常小的外部样本源也会导致两种不同的极限行为。这为理解递归训练中的复杂行为提供了新的视角，有助于避免模型的崩溃和提高生成模型的质量。"}
{"llm_update_time": "20250907", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.12210", "html_url": "https://arxiv.org/abs/2506.12210", "title": "无线边缘网络中的机器智能", "title_en": "Machine Intelligence on Wireless Edge Networks", "authors": "Sri Krishna Vadlamani,Kfir Sulimany,Zhihui Gao,Tingjun Chen,Dirk Englund", "background": "边缘设备上的机器智能能够提供低延迟处理并增强隐私保护，但通常受限于数据传输和转换带来的能量消耗和延迟。当前的系统通常通过将查询发送到服务器来避免在边缘设备上存储本地模型，这会产生上行传输成本、网络延迟和隐私风险。", "innovation": "该论文提出了一种与当前做法相反的方法：通过基站将模型权重以射频波形的形式广播给客户端，客户端在接收链中使用物理计算来执行推理计算。这种方法避免了重复的信号转换和额外硬件，利用了已存在于大量边缘设备（如手机）中的射频组件。分析表明，热噪声和非线性创建了一个最佳的能量窗口，用于准确的模拟内积操作。通过针对硬件进行的不同架构链训练保持了在这一范围内的准确性。", "conclusion": "电路导向的模拟与配套实验结果一致，展示了在现实无线边缘场景中，这种方法可以减少内存和转换开销，同时保持高精度。"}
{"llm_update_time": "20250907", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.08570", "html_url": "https://arxiv.org/abs/2506.08570", "title": "自回归 vs 流匹配：文本到音乐生成建模范式比较研究", "title_en": "Auto-Regressive vs Flow-Matching: a Comparative Study of Modeling Paradigms for Text-to-Music Generation", "authors": "Or Tal,Felix Kreuk,Yossi Adi", "background": "文本到音乐生成领域近期取得了进展，使得模型能够生成高质量的音乐片段、完整的乐曲，甚至可以根据细微的控制信号，如和弦进行，进行生成。现有的最先进系统在多个维度上存在显著差异，如训练数据集、建模范式和架构选择等。这些差异使得公平评估模型和识别影响性能的设计选择变得复杂。尽管数据和架构等因素很重要，但在本研究中，我们将仅专注于建模范式。我们进行了系统性的经验分析，以揭示其效果并提供未来指导。具体来说，我们对比了两个最常使用的建模范式：自回归解码和条件流匹配。我们通过使用相同的训练数据集、配置和类似的基础架构进行了受控实验，评估了生成质量、对推理配置的鲁棒性、可扩展性、时间对齐的条件遵守情况以及音频修补编辑能力等多个维度的性能。", "innovation": "本研究专注于建模范式的比较，通过自回归解码和条件流匹配的对比实验，揭示了每种范式的优势和局限性，为未来文本到音乐生成系统的架构和训练决策提供了实用指导和见解。", "conclusion": "本研究的比较分析为每个范式的不同强项和局限性提供了见解，有助于未来的文本到音乐生成系统设计，并提供了实际可行的建议。实验结果和音频示例可在指定的网址上获取。"}
{"llm_update_time": "20250907", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.02842", "html_url": "https://arxiv.org/abs/2507.02842", "title": "关于可复制假设检验器的结构", "title_en": "On the Structure of Replicable Hypothesis Testers", "authors": "Anders Aamand,Maryam Aliakbarpour,Justin Y. Chen,Shyam Narayanan,Sandeep Silwal", "background": "可复制的假设检验算法在运行于相同分布下的两个不同样本时，能够以高概率产生相同输出。这种性质由Impagliazzo等人在2022年的STOC会议上定义，它能够增强对测试程序的信任，并且与算法稳定性、泛化及隐私紧密相关。", "innovation": "作者构建了一般工具来证明复制性测试器的样本复杂度的上下界，统一并定量改进了现有结果。他们定义了一组基本属性，并证明任何复制性测试算法都可以修改以满足这些属性，而不会影响准确性或样本复杂度。此外，作者细化并改进了复制性算法设计的常用策略，使得在非复制性设置中已经被广泛分析的测试器，能够在最小的代价下变为复制性测试器。", "conclusion": "利用新框架，作者获得了硬币测试和邻近性测试的最佳常数因子下界，并在参数范围广泛的情况下免费实现了均匀性测试的可复制性。作者还提供了复制性高斯均值测试中状态领先的边界，并且算法在多项式时间内运行。"}
{"llm_update_time": "20250907", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2505.23445", "html_url": "https://arxiv.org/abs/2505.23445", "title": "独立性无关且范式无关的强、弱和良性Goodhart定律", "title_en": "The Strong, Weak and Benign Goodhart's law. An independence-free and paradigm-agnostic formalisation", "authors": "Adrien Majka,El-Mahdi El-Mhamdi", "background": "Goodhart定律是政策制定领域的著名箴言，指出当一个衡量指标成为目标时，它将不再是一个有效的衡量指标。随着机器学习模型和训练优化能力的增长，越来越多的经验证据支持了这一定律的有效性，但尚未被严格形式化。尽管近期有研究尝试形式化Goodhart定律，但主要通过对其进行分类或研究代理指标优化如何影响预定目标的优化。大多数相关研究都依赖于代理指标与目标之间独立性的假设，并且限制在特定的学习范式上。本文旨在突破这些简化假设，探索代理指标与目标之间的耦合对Goodhart效应的影响。", "innovation": "本文的研究创新之处在于：1. 打破了现有研究中代理指标与目标之间独立性的假设；2. 摆脱了对特定学习范式的限制，进行更加通用的研究；3. 发现了在目标和误差轻尾分布的情况下，代理指标与目标之间的依赖关系不会改变Goodhart效应的本质，但在目标轻尾、误差重尾的情况下，展示了过度优化效果与误差重尾性成反比的现象。这一发现加深了我们对Goodhart定律的理解，特别是在这对学习有价值的应用场景下。", "conclusion": "研究表明，在轻尾目标和轻尾误差的情况下，代理指标与目标之间的依赖关系对Goodhart效应影响不大。而在轻尾目标和重尾误差的情况下，过度优化的效果与误差的重尾性成反比。这意味着在研究和实施优化策略时，了解目标和误差的分布特性对于预测和管理Goodhart效应至关重要。这为政策制定者和机器学习工程师提供了一种更具普适性的分析工具。"}
{"llm_update_time": "20250907", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2505.05118", "html_url": "https://arxiv.org/abs/2505.05118", "title": "提升Text2Cypher任务中的 Schema 过滤", "title_en": "Enhancing Text2Cypher with Schema Filtering", "authors": "Makbule Gulcin Ozsoy", "background": "知识图谱通过节点、关系和属性表示复杂的结构化数据。Cypher 是一种用于图数据库的强大查询语言，能够高效建模和查询数据。近年来，大型语言模型的进步使得能够将自然语言问题转化为Cypher查询，如Text2Cypher任务。常见做法是将在数据库中定义的模式融入到查询提示中。但对于复杂的模式而言，这样做可能会引入噪声、增加幻觉并提高计算成本。因此，研究者提出了一种方案，即通过选择相关模式元素实现Schema过滤，从而在提高查询生成效率的同时降低Token成本。然而，这项研究发现，尽管较大的模型受到较多的优势，但在成本削减方面，无论大小模型，Schema过滤都显得有用和必要，而且对于较小模型具有明显的优势。", "innovation": "该研究探索了各种Schema过滤方法对Text2Cypher任务的影响，并分析了这些方法在Token长度、性能及成本方面的优化效果。研究表明，Schema过滤有效优化了Text2Cypher任务，特别是在较小模型中效果显著。此外，虽然较大的语言模型具有更长的语境能力，并因此较少受益于Schema过滤，但该方法仍然有助于减少计算成本，尤其对于较小的模型。", "conclusion": "这项研究证实，Schema过滤是优化Text2Cypher任务的有效方法，可以在提高效率的同时降低成本，尤其对于较小的模型效果更为显著。虽然较大的模型从Schema过滤中受益较少，但该方法仍是一种值得推荐的成本优化策略。"}
{"llm_update_time": "20250907", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.05785", "html_url": "https://arxiv.org/abs/2507.05785", "title": "基于离线强化学习的实时通信稳健带宽估计", "title_en": "Robust Bandwidth Estimation for Real-Time Communication with Offline Reinforcement Learning", "authors": "Jian Kai,Tianwei Zhang,Zihan Ling,Yang Cao,Can Shen", "background": "准确的带宽估计（BWE）对于实时通信（RTC）系统至关重要。传统的启发式方法在动态网络下适应性有限，而在线强化学习（RL）则面临高探索成本和潜在服务中断的问题。与之相对，使用高质量数据训练的离线RL提供了一种替代方案，但仍然存在操作环境外（OOD）行为的风险、行为多样的数据集中的策略提取以及生产系统中的可靠部署等挑战。", "innovation": "本文提出了基于离线RL的稳健带宽估计框架RBWE，通过集成Q-ensemble（多个Q函数的集合）与Gauss混合策略来降低OOD风险并增强策略学习。同时，采用一个故障转移机制，在高度不确定性情况下切换到启发式方法确保部署稳定性。实验结果表明，RBWE将过估计降低了18%，并提高了第10百分位的用户体验质量（QoE）18.6%，证明了其在RTC中的实际有效性。项目被公开部署在这个 https URL.", "conclusion": "RBWE框架通过离线RL方法结合Q-ensemble与Gauss混合策略，有效减少了带宽估计中的过估计错误并提升了用户体验质量，为RTC系统的带宽管理提供了新思路。"}
{"llm_update_time": "20250907", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.00215", "html_url": "https://arxiv.org/abs/2509.00215", "title": "通过解耦反向传播的第一阶模型导向 RL", "title_en": "First Order Model-Based RL through Decoupled Backpropagation", "authors": "Joseph Amigo,Rooholla Khorrambakht,Elliot Chane-Sane,Nicolas Mansard,Ludovic Righetti", "background": "近年来，利用模拟器的导数来提高强化学习（RL）效率的方法受到了广泛关注。尽管早期基于梯度的方法在性能上优于无导数方法，但由于实现成本高昂或不可用，获取模拟器梯度往往不切实际。模型导向RL（MBRL）可以利用学习的动力学模型来近似这些梯度，但在训练滚动过程中，预测误差会累积，从而损害策略性能。", "innovation": "本文提出了一种将轨迹生成与梯度计算解耦的方法：轨迹使用模拟器展开，梯度通过差分模拟器学习的动力学模型实现反向传播来计算。这种混合设计使即使在缺乏模拟器梯度的情况下，也能够高效而一致地进行一阶策略优化，并且通过模拟滚动学习更准确的评论者。该方法在采样效率和速度上与专门优化器（如SHAC）相当，同时保持标准方法（如PPO）的通用性，避免了其他一阶MBRL方法中观察到的各种不良行为。", "conclusion": "本文方法在基准控制任务和基于真实Go2四足机器人上的各类任务中得到了实证验证，证明了其有效性和鲁棒性。"}
{"llm_update_time": "20250907", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.05972", "html_url": "https://arxiv.org/abs/2507.05972", "title": "普遍化和统一的计算硬度与伪随机性的等价关系", "title_en": "Generalized and Unified Equivalences between Hardness and Pseudoentropy", "authors": "Lunjia Hu,Salil Vadhan", "background": "伪随机性特性提供了计算硬度和计算随机性之间紧密关系的量化精准说明。本文证明了一个统一路由性的特征，它概括并加强了之前关于均匀和非均匀计算模型的结果。该特征适用于一个涵盖香农熵和最小熵等常见概念的一般熵概念家族。此外，作者表明，不同的熵概念可以同时通过一个单一的通用函数实现，这个函数可以同时见证计算硬度和计算随机性。", "innovation": "通过利用近年来算法公平文献中提出的加权限制校准的概念，并结合标准计算不可区分性（在公平文献中称为多准确性），证明了涵盖一般熵概念的伪随机性特征，实现了与Casacuberta, Dwork和Vadhan（2024）基于更强的多校准概念的伪随机性特征相比，复杂性对字母表大小依赖关系的指数级改进。同时，也证明了对字母表大小依赖关系的指数依赖是不可避免的，无论是基于多校准还是较弱的校准多准确性。", "conclusion": "通过权重限制校准增强了经典复杂性理论定理定理（Trevisan, Tulsiani和Vadhan, 2009）和泄露模拟定理（Jetchev和Pietrzak, 2014），实现了伪随机性特征的更优证明，并展示了对所有一般熵概念的适用性。"}
{"llm_update_time": "20250907", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.12964", "html_url": "https://arxiv.org/abs/2507.12964", "title": "基于人口统计信息的儿童腕部骨折细粒度分类", "title_en": "Demographic-aware fine-grained classification of pediatric wrist fractures", "authors": "Ammar Ahmed,Ali Shariq Imran,Zenun Kastrati,Sher Muhammad Daudpota", "background": "腕部病理状况在儿童中非常常见，儿童占据了骨折病例的大多数。计算机视觉技术在这一领域的应用前景广阔，但需要大量的数据集作为支持，而医学影像获取大量的数据集是一个显著的挑战。由于多种数据类型的存在，单一的数据模态如图像已经不足以满足需求。因此，需要采取多模态的方法来应对这一问题，包括结构化病人的元数据和X光片的融合，以及使用专为细粒度任务预训练的模型权重，而不是像ImageNet这样的粗粒度模型。", "innovation": "本文是首次将元数据集成应用于腕部病理识别。研究采用细粒度的Transformer方法进行诊断，即使用细粒度的预训练模型权重，并结合病人的元数据来提高诊断准确性。该方法在小规模定制数据集上提高了2%的诊断准确率，在更大的骨折数据集上提高了超过10%的诊断准确率。", "conclusion": "该研究提出了一种新的方法，通过结合细粒度的Transformer模型、细粒度预训练模型，以及患者的元数据，来实现儿童腕部骨折的细粒度分类，从而提高了诊断准确率。"}
{"llm_update_time": "20250907", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.01221", "html_url": "https://arxiv.org/abs/2509.01221", "title": "DaMoC：基于数据和模型压缩高效选择适合微调领域任务的最佳大型语言模型", "title_en": "DaMoC: Efficiently Selecting the Optimal Large Language Model for Fine-tuning Domain Tasks Based on Data and Model Compression", "authors": "Wei Huang,Huang Wei,Yinggui Wang", "background": "大型语言模型（LLMs）擅长通用任务但在特定领域任务上存在困难，需要使用特定数据进行微调。随着许多开源LLM的可用，选择最适合微调下游任务的模型变得具有挑战性，主要集中在如何快速识别最佳的LLM。", "innovation": "提出了一个数据和模型压缩框架（DaMoC），通过：1）数据层面：系统建立了数据过滤方法的分类，分为分布感知方法、质量感知方法和兼顾两者的混合方法，并进一步通过压缩关键词汇实现文本压缩，使用LLM迭代重写文本以优化表达。2）模型层面：使用层相似度评分评估每层的重要性并移除重要性较低的层，引入稀疏合并范式以尽可能保留原始模型的能力。通过四个数据集（医学问答、金融问答、通用问答和阅读理解）的广泛实验展示了可以节省约20倍的训练时间，从而选择最优的LLM。", "conclusion": "通过DaMoC框架，实现了高效选择最适合特定领域任务的LLM，显著节省了训练时间。"}
{"llm_update_time": "20250907", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.02060", "html_url": "https://arxiv.org/abs/2509.02060", "title": "基于掩码条件生成建模的特定形态肽发现", "title_en": "Morphology-Specific Peptide Discovery via Masked Conditional Generative Modeling", "authors": "Nuno Costa,Julija Zavadlav", "background": "肽自组装预测为设计生物相容性、低毒性的材料提供了一种强大的自底向上的策略，这些材料适用于广泛的生物医药和能源应用，但筛选巨大的序列空间以分类聚合形态依然难以解决。现有方法无法有效生成既易于聚集又能自组装成指定形态（如纤维状或球状）的新型肽序列。", "innovation": "提出了 PepMorph 深度学习管道，结合现有聚合倾向数据集，提取几何和物理化学的孤立肽描述符作为聚集形态的代理，生成新型肽序列。PepMorph 使用带有掩码机制的变换器条件变分自编码器进行训练，能够在任意条件下生成新型肽序列。经过筛选和粗粒度分子动力学模拟验证，PepMorph 在目标形态生成上达到了83%的准确率。", "conclusion": "PepMorph 框架展示了作为应用驱动肽发现框架的潜力，为设计特定形态的肽开辟了新的途径。"}
{"llm_update_time": "20250907", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.18464", "html_url": "https://arxiv.org/abs/2508.18464", "title": "量子变换器中的可学习编码向量注意机制", "title_en": "Vectorized Attention with Learnable Encoding for Quantum Transformer", "authors": "Ziqing Guo,Ziwen Pan,Alex Khan,Jan Balewski", "background": "目前的量子变换器依赖于深度参数化量子电路（PQCs），这使得它们容易受到量子处理单元（QPU）噪声的影响，从而阻碍了其实用性能。向量化的量子变换器（VQT）模型旨在克服这一限制，通过量子近似模拟实现理想屏蔽注意力矩阵的计算，并通过向量化的非线性量子编码器进行高效的训练，从而实现短程高效、无梯度的量子电路模拟（QCS），并减少经典采样的开销。此外，该研究还在IBM和IonQ的量子电路模拟中进行了准确性比较，并在IBM最先进的高保真Kingston QPU上进行了自然语言处理任务的基准测试，取得了具有竞争力的结果。", "innovation": "VQT 模型通过量子近似模拟实现理想屏蔽注意力矩阵的计算，并通过向量化的非线性量子编码器进行高效的训练，从而实现短程高效、无梯度的量子电路模拟（QCS），并减少经典采样的开销。这个方法使得量子变换器能够在量子噪声环境中更稳定地运行，提高了其实用性能。", "conclusion": "通过 VQT 方法，提出了一种新的架构，使端到端的机器学习能够在量子计算中进行。该方法已经在 IBM 和 IonQ 上进行了量子电路模拟的准确性比较，并且在 IBM 的先进 QPU 上实现了自然语言处理任务的具有竞争力的结果。"}
{"llm_update_time": "20250907", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.02175", "html_url": "https://arxiv.org/abs/2509.02175", "title": "理解空间是火箭科学——只有顶级推理模型才能解决空间理解任务", "title_en": "Understanding Space Is Rocket Science -- Only Top Reasoning Models Can Solve Spatial Understanding Tasks", "authors": "Nils Hoehing,Mayug Maniparambil,Ellen Rushe,Noel E. O'Connor,Anthony Ventresque", "background": "当前的视觉语言模型（VLMs）在理解空间关系方面表现不足，而传统的基准测试可能不足以充分评估这些模型的空间理解能力。", "innovation": "提出了RocketScience，一个开源对比VLM基准，专门测试空间关系理解能力。该基准涵盖了全新的真实世界的图像-文本对，主要测试相对空间理解及物体顺序。与现有模型相比，RocketScience设计得对人类来说容易理解，但对现有VLMs却极具挑战性，这一特点已经通过实验验证。此外，研究表明，链式思考模型的空间推理能力是决定其在基准测试中表现的主要因素，而不是对象定位能力。", "conclusion": "开源和前沿商业VLMs在空间关系理解任务中表现较差，而推理模型的表现却超出预期。发布数据集使用CC-BY-4.0许可，并提供评估代码供下载。"}
{"llm_update_time": "20250907", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.02349", "html_url": "https://arxiv.org/abs/2509.02349", "title": "AudioCodecBench: 一种全面的音频编解码器评估基准", "title_en": "AudioCodecBench: A Comprehensive Benchmark for Audio Codec Evaluation", "authors": "Lu Wang,Hao Chen,Siyu Wu,Zhiyue Wu,Hao Zhou,Chengfeng Zhang,Ting Wang,Haodi Zhang", "background": "多模态大型语言模型（MLLMs）在语音和音乐中的广泛应用，促使研究人员更加关注大型模型的音频分词。与仅包含语义的信息文本令牌不同，音频令牌必须同时捕捉全局语义内容并保留细微的声学细节。此外，音频令牌可以为语音和音乐提供一种离散的方法，并能够有效整合到MLLMs中。然而，现有研究在语义令牌和声学令牌的定义上存在不足，而且不同编解码器的评估通常集中在特定领域或任务，如重建或自动语音识别（ASR），这阻碍了公平和全面的比较。", "innovation": "本文提供了语义令牌和声学令牌的合适定义，并引入了一个系统的评估框架。该框架可以全面评估编解码器的能力，从四个方面进行评估：音频重建指标、码本索引（ID）稳定性、仅解码器变换器困惑度以及下游探测任务的性能。", "conclusion": "实验结果验证了提供的合适定义的正确性，并且表明重建指标、码本ID稳定性、下游探测任务和困惑度之间存在相关性。"}
{"llm_update_time": "20250907", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.11236", "html_url": "https://arxiv.org/abs/2507.11236", "title": "非对数亚定性分布的改进采样算法和普朗特尔不等式", "title_en": "Improved sampling algorithms and Poincaré inequalities for non-log-concave distributions", "authors": "Yuchen He,Zhehan Lei,Jianan Shao,Chihao Zhang", "background": "该论文研究了从具有密度$e^{-V}$的分布$\boldsymbol{\nu}$中进行采样的问题，其中$V:\boldsymbol{\boldsymbol{R}}^d \to \boldsymbol{\boldsymbol{R}}$是某个势函数，可以通过查询访问$V$和$\nabla V$两种信息。研究了采样的查询复杂度和势函数的平滑性条件以及二阶矩的假设。以前的研究结果表明采样的查询复杂度与多项式相关的$LM/d\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{ε}}}}}}$的指数次幂有关。近年来，Chen等人的研究进一步加强了这一假设，但性能仍然有限。", "innovation": "论文提出了新的更强的光滑性条件(1*)，即沿Ornstein-Uhlenbeck过程从$\boldsymbol{\nu}$出发的每一分布的势函数都是$L$-光滑的。在假设(1*)和(2)成立的情况下，展示了采样的查询复杂度可以达到$\boldsymbol{poly}(L,d)\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{⋅}}}}}}(Ld+M)/ε^2$的幂次，当$L$为常数且$M$多项式时，查询复杂度是$d$和$\frac{1}{ε}$的多项式，这改进了Huang等人发展出的准多项式查询复杂度算法。此外，通过假设(1*)及更强的二阶矩假设$\boldsymbol{\boldsymbol{X}}$是$\boldsymbol{λ}-亚高斯分布，推导出$\boldsymbol{\nu}$的普朗特尔常数最多为$\boldsymbol{O}(λ)^{2(L+1)}$。这个结果应用了提高混合高斯分布条件下普朗特尔常数的估计值。", "conclusion": "论文的研究表明条件(1)到(1*)的小幅强化导致了采样算法查询复杂度上的指数级差距。这表明采样算法的高效性可以通过合适的光滑性和矩条件来改善，进而提高了非对数亚定性分布下的采样效率和技术。"}
{"llm_update_time": "20250907", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.03317", "html_url": "https://arxiv.org/abs/2509.03317", "title": "BART for functional ANOVA model", "title_en": "Bayesian Additive Regression Trees for functional ANOVA model", "authors": "Seokhun Park,Insung Kong,Yongdai Kim", "background": "BART是能够充分利用贝叶斯推断和回归树优势的强大统计模型，适用于捕捉复杂非线性关系和预测变量间的相互作用。然而，这一模型的准确性通常伴随着可解释性较差的问题。", "innovation": "本文提出了ANOVA-BART，这是基于函数ANOVA分解的BART的新颖扩展，能够将函数的变异性分解为不同的互动，从而提高解释性。该方法还保持和扩展了BART的理论保证，并实现了卓越的预测性能。特别地，新模型的后验集中速度几乎是近似最坏情况最优的，且对于每个相互作用也提供了与BART相同的收敛速度。这项研究通过全面的实验验证，表明ANOVA-BART在准确性和不确定性量化方面超越了BART，同时展示了在组件选择方面的有效性。", "conclusion": "研究表明，ANOVA-BART通过平衡预测准确性、解释性和理论一致性，为BART提供了一个颇具吸引力的替代方案。"}
{"llm_update_time": "20250907", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.02077", "html_url": "https://arxiv.org/abs/2509.02077", "title": "基于Sentence Transformer的方法将攻击描述映射到漏洞", "title_en": "From Attack Descriptions to Vulnerabilities: A Sentence Transformer-Based Approach", "authors": "Refat Othman,Diaeddin Rimawi,Bruno Rossi,Barbara Russo", "background": "在网络安全领域，即使在攻击发生后，许多漏洞仍可能未被发现。在本论文中，漏洞是指在Common Vulnerabilities and Exposures (CVE)报告中公开披露的缺陷。建立攻击与漏洞之间的联系对于实现及时的事件响应至关重要，因为它可以为防御者提供即时和可操作的信息。然而，手动将攻击映射到CVE是不实际的，因此自动化的需求应运而生。", "innovation": "本文评估了14种最先进的(SOTA)句型变换器模型，用于从攻击描述中自动识别漏洞。结果表明，MMPNet模型在使用攻击技术描述时的分类性能最好，F1分数为89.0，精确率为84.0，召回率为94.7。进一步观察发现，MMPNet模型识别出的大约56%的漏洞也在CVE中与攻击相关联，而模型检测到的漏洞中有61%与CVE库中记录的漏洞一致。手动检查结果显示，MMPNet模型预测了275个未记录在MITRE库中的链接。因此，将攻击技术自动映射到漏洞不仅提升了与软件安全事件相关的检测和响应能力，还缩短了漏洞被利用的时间，从而有助于开发更安全的系统。", "conclusion": "本文的研究表明，使用Sentence Transformer技术可以有效地从攻击描述中识别出漏洞，并自动建立漏洞与攻击之间的关联。这种自动化方法不仅能显著提高检测和响应能力，还能减少漏洞存在的可利用窗口，促进更安全的系统开发过程。"}
{"llm_update_time": "20250907", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.01938", "html_url": "https://arxiv.org/abs/2509.01938", "title": "EigenBench：一种比较性的价值对齐行为衡量方法", "title_en": "EigenBench: A Comparative Behavioral Measure of Value Alignment", "authors": "Jonathn Chang,Leonhard Piff,Suvadip Sana,Jasmine X. Li,Lionel Levine", "background": "人工智能与人类价值观的对齐是亟待解决的关键问题。然而，缺乏量化衡量价值对齐的标准。因此，需要一种方法来评估不同语言模型的价值对齐程度，以便更好地理解它们各自的行为特性，并指导开发出更加符合人类价值观的人工智能系统。", "innovation": "提出了一种黑盒方法EigenBench，用于比较性地评估语言模型的价值对齐情况。通过让一系列模型相互评价在多种情景下的输出，并结合EigenTrust方法进行加权平均判断，从而得到每个模型在给定价值体系下的对齐程度量化得分。这种方法无需真实标签，适用于对不同的模型特性意见不一的领域。此外，通过使用提示的人格测试方法，研究发现大部分变异是由提示引起的，但仍有部分可以量化模型本身的倾向性。", "conclusion": "EigenBench为比较不同语言模型的价值对齐情况提供了一种新颖的方法，不仅揭示了模型在行为上的差异，还强调了提示在影响模型输出中的关键作用。尽管当前研究主要关注通过提示来推动评估，未来工作可以进一步探索不确定因素对于模型行为的影响。"}
{"llm_update_time": "20250907", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2509.03541", "html_url": "https://arxiv.org/abs/2509.03541", "title": "关于移动应用需求工程所使用的数据集：系统映射研究的初步发现", "title_en": "Towards the Datasets Used in Requirements Engineering of Mobile Apps: Preliminary Findings from a Systematic Mapping Study", "authors": "Chong Wang,Haoning Wu,Peng Liang,Maya Daneva,Marten van Sinderen", "background": "研究移动应用的需求工程（RE）大多利用来自用户、开发人员或供应商的数据集，但很少有人了解这些数据集的来源以及来自特定平台的RE活动的研究情况。", "innovation": "提出了一种系统映射研究的方法，通过跟踪Kitchenham等人的指南，发现Google Play和Apple App Store提供的数据集占现有移动应用RE研究的90%以上，其中主要研究的是需求获取和需求分析。", "conclusion": "主要结论是：(1) 自2012年起，用于移动应用需求工程研究的数据集使用量有所增长；(2) 移动应用的RE知识可能因过度使用Google Play和Apple App Store而有所偏差；(3) 试图用其他数据源补充应用仓库的审查；(4) 社区需要扩展其他数据源的选择，尝试多种来源的互补使用以获得更广泛的结果。还预计会进一步研究其他需求工程活动，而不仅仅是获取和分析。"}
{"llm_update_time": "20250907", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.01875", "html_url": "https://arxiv.org/abs/2509.01875", "title": "RadioDiff-Loc: 基于稀疏无线电图估计的散射认知增强扩散模型非视距定位", "title_en": "RadioDiff-Loc: Diffusion Model Enhanced Scattering Congnition for NLoS Localization with Sparse Radio Map Estimation", "authors": "Xiucheng Wang,Qiming Zhang,Nan Cheng", "background": "在非视距（NLoS）环境中，非合作信号源的准确定位仍然是一个关键挑战，广泛应用于自主导航、工业自动化和应急响应等领域。传统的定位技术依赖于视距（LoS）或协同信号传输，在这些情况下由于严重的多径传播和未知发射功率而失败。这种背景下，本文提出了一种基于条件扩散模型的新生成推理框架，用于NLoS环境中的定位。该框架充分利用了物理直觉，即衍射电磁能量集中在建筑物边缘附近，并通过采样稀疏的接收信号强度（RSS）测量值来增强性能，这些测量值是在障碍物的几何顶点处收集的，这些位置对未知信号源具有最大信道信息量。为了克服未知传输功率的问题，所有采样的RSS值被归一化为观察到的最大强度，从而可以构建一个功率不变的无线电图（RM）。", "innovation": "提出了一种基于条件扩散模型的新生成推理框架，通过采样稀疏RSS测量值来估计功率不变的无线电图。该框架利用了衍射电磁能量集中在建筑物边缘附近的物理特性，通过归一化采样的RSS值以克服未知传输功率的问题，从而实现NLoS非合作信号源的高精度定位。此外，该框架还兼容现有的RSS基定位算法，结合物理知识和数据驱动的推理进行融合，以提高定位准确性。", "conclusion": "本文通过理论分析和实验证明，提出的基于条件扩散模型的框架能够在显著降低采样成本的同时实现高精度的NLoS定位，提供了一种可扩展且基于物理原理的方法来解决非合作NLoS源的定位问题。"}
{"llm_update_time": "20250907", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2509.03668", "html_url": "https://arxiv.org/abs/2509.03668", "title": "时间推移中的解析树追踪以实现大规模编程过程分析", "title_en": "Parse Tree Tracking Through Time for Programming Process Analysis at Scale", "authors": "Matt Rau,Chris Brown,John Edwards", "background": "编程过程数据可以被利用来理解学生在编写计算机程序作业时使用的过程。过去，按键和行级别的事件日志常被用来做高层描述性统计（如时间、字符删除率等），但对于在上下文中分析学生的编程行为（例如，学生在循环上花费的时间）仍然存在困难，这主要是因为我们无法自动追踪时间上的高级代码表示（如抽象语法树），以及这些代码的不可解析状态。", "innovation": "本文设计了一个算法，能够追踪解析树节点随时间的变化，这是首次实现，同时通过应用这一算法执行了一个部分复制研究以重现先前的手工代码表示跟踪工作，还进行了大规模的新型的学生编程行为分析，如删除代码的速率在条件分支和循环内外具有相似性，大约三分之一被注释掉的代码最终会被恢复，以及学生在代码中跳转的频率可能并非代表他们陷入了困境。", "conclusion": "通过追踪解析树随时间的变化，能够揭示新的学生编程维度，比如代码结构发展的最佳实践，学生在何种语法结构上最困难，重构行为以及代码内注意力转移的具体情况。"}
{"llm_update_time": "20250907", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2509.03554", "html_url": "https://arxiv.org/abs/2509.03554", "title": "APB事务多阶段故障诊断", "title_en": "A Multi-stage Error Diagnosis for APB Transaction", "authors": "Cheng-Yang Tsai,Tzu-Wei Huang,Jen-Wei Shih,I-Hsiang Wang,Yu-Cheng Lin,Rung-Bin Lin", "background": "在现代片上系统（SoC）设计中，功能验证和调试是关键瓶颈。手动检测高级外设总线（APB）事务中的错误非常低效且容易出错，特别是在大型值变化转储（VCD）文件中。", "innovation": "本文提出了一种基于分层随机森林结构的自动化错误诊断框架，采用多阶段错误诊断策略，使用四个预训练的二元分类器依次检测超出范围访问、地址损坏和数据损坏错误。这种方法优先处理高确定性的地址相关故障，然后再处理复杂的数据错误，以提高效率。", "conclusion": "实验结果显示该方法的整体准确率为91.36%，对地址错误具有接近完美的精确度和召回率，对数据错误也有稳健的表现。尽管截至提交日期ICCAD 2025 CAD竞赛的结果尚未公布，但团队在beta阶段取得了第一名，显示出该方法的竞争优势。该研究验证了分层机器学习在电子设计自动化（EDA）硬件调试中的巨大潜力。"}
{"llm_update_time": "20250907", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2509.03848", "html_url": "https://arxiv.org/abs/2509.03848", "title": "从开发者体验驱动的视角理解软件生态系统的透明性", "title_en": "Towards an Understanding of Developer Experience-Driven Transparency in Software Ecosystems", "authors": "Rodrigo Oliveira Zacarias,Rodrigo Pereira dos Santos,Patricia Lago", "background": "软件生态系统（SECO）已成为了软件行业的主导模式，通过互补的组件和服务，允许第三方开发者共同创造价值。尽管开发者体验（DX）在可持续的SECO中被认为是至关重要的，但透明性作为一个影响开发者认知和交互的要素仍较少被研究。尽管现有研究认识到透明性是建立信任、公平和参与的基础，但它与开发者体验之间的关系尚未得到系统的概念化。", "innovation": "本文提出了SECO-TransDX（软件生态系统中从开发者体验角度理解的透明性）概念模型，该模型引入了基于开发者体验驱动的透明性的概念。该模型识别了63个相互关联的概念，包括影响开发者交互过程中透明性感知和构建的条件因子、生态系统流程、制品和关系动态。此外，SECO-TransDX模型是基于先前的研究并通过专家德尔菲研究进一步完善而成，它提供了一个结构化的视角来考察透明性在技术、社会和组织层面上如何影响开发者体验。", "conclusion": "SECO-TransDX为研究人员研究和工具开发奠定了基础，同时也为实践者设计更值得信赖的开发者为中心的平台提供了支持，这些平台能够提升透明性并促进开发者生态系统的长期参与。"}
{"llm_update_time": "20250907", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2509.03875", "html_url": "https://arxiv.org/abs/2509.03875", "title": "VulRTex: 一种基于推理的富文本问题报告中识别漏洞的方法", "title_en": "VulRTex: A Reasoning-Guided Approach to Identify Vulnerabilities from Rich-Text Issue Report", "authors": "Ziyou Jiang,Mingyang Li,Guowei Yang,Lin Shi,Qing Wang", "background": "开源软件（OSS）中的软件漏洞会影响系统的安全性。开发人员发现这些漏洞后会提交问题报告（IRs）以描述漏洞的具体细节。安全从业者需要花费大量时间手动从社区中识别与漏洞相关的IRs，但这样的时间间隔可能会被攻击者利用来对系统造成损害。尽管此前已有研究提出了自动化的识别方法，但这些方法主要依赖文本描述，缺乏对IRs丰富文本信息的全面分析。", "innovation": "本文提出了一种名为VulRTex的方法，这是一种基于推理的识别与漏洞相关的IRs的方法，能够全面分析IRs的丰富信息。VulRTex首先利用大型语言模型（LLM）的推理能力构建漏洞推理数据库，从中检索相关案例生成推理指导，引导LLM通过对目标IRs的丰富文本信息进行推理分析来识别漏洞。实验结果显示，VulRTex在不平衡数据集上的性能最佳，F1值提高了11.0%，AUPRC提高了20.2%，Macro-F1提高了10.5%，比基线方法的推理方式节省了近2倍的时间。", "conclusion": "VulRTex已被应用于在2024年GitHub的IRs中识别30个新兴漏洞，并成功为其中11个漏洞分配了CVE-ID，这表明VulRTex具有实际应用价值。"}
{"llm_update_time": "20250907", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2509.03896", "html_url": "https://arxiv.org/abs/2509.03896", "title": "由于代码气味交互而导致的依赖分布变化分析", "title_en": "Analyzing Variations in Dependency Distributions Due to Code Smell Interactions", "authors": "Zushuai Zhang,Elliott Wen,Ewan Tempero", "background": "模块间的依赖关系可能造成代码修改时引发连锁反应，增加维护的复杂性和成本，因此应当尽量减少模块间的依赖。近年来的研究表明，代码气味（即指示潜在设计问题的代码特征）之间的交互可能会增加模块间的依赖关系。本文旨在验证先前的观察结果，并探讨代码气味之间交互和代码气味与非代码气味交互对于静态依赖分布的影响。", "innovation": "该研究通过分析116个开源Java系统，量化了代码气味之间及其与非代码气味交互对于静态依赖分布的影响，揭示了特定代码气味交互对于特定依赖数量的显著影响。", "conclusion": "代码气味之间的交互通常会导致总依赖数量的增加，而代码气味构成交互与非代码气味之间交互相比影响更大。例如，特性羡方法与数据类之间的中位依赖数量是无特性羡方法的7倍，从1增加到了7。因此，开发人员应该优先处理交互的代码气味，而不是孤立存在的代码气味。"}
{"llm_update_time": "20250907", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2509.04078", "html_url": "https://arxiv.org/abs/2509.04078", "title": "RepoDebug：大型语言模型的仓库级多任务和多语言调试评估", "title_en": "RepoDebug: Repository-Level Multi-Task and Multi-Language Debugging Evaluation of Large Language Models", "authors": "Jingjing Liu,Zeming Liu,Zihao Cheng,Mengliang He,Xiaoming Shi,Yuhang Guo,Xiangrong Zhu,Yuanfang Guo,Yunhong Wang,Haifeng Wang", "background": "大语言模型（LLMs）在代码调试中表现出显著的能力，特别是在自动程序修复方面，这可能显著减少开发人员的时间消耗并提高其效率。为了促进代码调试的发展，已经取得了显著的进展，特别是在调试数据集方面。然而，这些数据集主要评估LLM的功能层面代码修复能力，而忽视了更为复杂和贴近现实的仓库级场景，导致对LLM在仓库级调试方面的挑战理解不完整。尽管已有几项仓库级数据集被提出，但这些数据集往往存在任务多样性、语言多样性以及错误类型多样性不足的问题。", "innovation": "本文提出了一种多任务、多语言的仓库级代码调试数据集RepoDebug，包含了22种类型的错误，支持8种常用的编程语言和3种调试任务。通过在10种LLM上进行评估实验，展示了最佳模型Claude 3.5 Sonnect在仓库级调试中仍然表现不佳。", "conclusion": "大型语言模型在仓库级调试中的能力有待提高，特别是在复杂和多样性的场景中。RepoDebug数据集可以为评估和改进LLM在仓库级调试中的能力提供支持。"}
{"llm_update_time": "20250907", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2509.03900", "html_url": "https://arxiv.org/abs/2509.03900", "title": "Auth Shim：一种将企业SSO与独立开源应用程序集成的轻量级架构模式", "title_en": "The Auth Shim: A Lightweight Architectural Pattern for Integrating Enterprise SSO with Standalone Open-Source Applications", "authors": "Yuvraj Agrawal", "background": "开源软件（OSS）在企业环境中广泛应用，但在缺乏对SAML或OIDC等协议的原生支持时，会形成关键的安全集成缺口。该论文介绍并正式化了Auth Shim这一轻量级架构模式，用于解决此问题。Auth Shim作为一种轻量级的外部代理服务，充当兼容性层，将企业认证提供商（IdP）的请求翻译为目标应用程序的原生会话管理机制。", "innovation": "提出了Auth Shim这一轻量级架构模式，解决开源软件缺乏对SAML或OIDC等协议原生支持的问题。Auth Shim作为兼容性层，帮助企业将孤立的开源软件工具整合到企业单点登录生态系统中，并通过定义其组件、交互以及生产部署考虑因素，提供了一种可复用、安全且成本效益高的解决方案。", "conclusion": "该论文通过在Adobe中的案例研究，展示了如何将流行的开源BI工具与Okta SAML集成，并通过IAM组映射实现了基于角色的访问控制（RBAC），并消除了手动用户配置。最终，该论文为任何孤立的开源工具与企业单一登录生态系统集成提供了可复用的安全和成本效益高的蓝本，使组织能够接受开源创新而不损害安全治理。"}
{"llm_update_time": "20250907", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2509.04328", "html_url": "https://arxiv.org/abs/2509.04328", "title": "FaaSGuard: 为 OpenFaaS 服务器less应用程序提供安全的 CI/CD", "title_en": "FaaSGuard: Secure CI/CD for Serverless Applications -- An OpenFaaS Case Study", "authors": "Amine Barrak,Emna Ksontini,Ridouane Atike,Fehmi Jaafar", "background": "服务器less计算通过抽象基础设施管理和实现快速、模块化、事件驱动的部署，极大地改变了软件开发。尽管服务器less函数提供了许多优点，如短暂性执行和细粒度的可扩展性，但也带来了独特的安全挑战，尤其是在开源平台OpenFaaS上。现有的方法通常仅解决DevSecOps生命周期中的个别阶段，缺乏一个综合的、全面的安全策略。", "innovation": "作者提出FaaSGuard，这是一种专门针对开源服务器less环境设计的统一DevSecOps管道。FaaSGuard通过在开发生命周期的每个阶段（规划、编码、构建、部署和监控）嵌入轻量级且故障闭合的安全检查，系统地解决了诸如注入攻击、硬编码的秘密和资源耗尽等威胁。通过一个涉及20个实际开源服务器less函数的案例研究，验证了FaaSGuard的有效性，其能够检测并防止关键漏洞，具有95%的精确率和91%的召回率，且不会显著干扰现有的CI/CD流程。", "conclusion": "FaaSGuard通过在服务器less开发和部署过程中嵌入轻量级的安全检查，提供了一种高效且不干涉现有CI/CD流程的整体安全策略，有助于确保开放源代码服务器less环境中的应用程序安全。"}
{"llm_update_time": "20250907", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2509.03711", "html_url": "https://arxiv.org/abs/2509.03711", "title": "Reactive Bottom-Up Testing", "title_en": "Reactive Bottom-Up Testing", "authors": "Siddharth Muralee,Sourag Cherupattamoolayil,James C. Davis,Antonio Bianchi,Aravind Machiry", "background": "现代计算系统中存在大量软件漏洞。目前，工程师们使用多种方法来检测这些漏洞，其中动态测试是最为常见和有效的手段之一。然而，大多数动态测试方法遵循自顶向下的架构，很难达到并执行调用图中的深层函数。", "innovation": "本工作中引入了一种新的范式，称为反应式自底向上的测试。该方法不仅测试函数在孤立状态下的行为，还验证其在整个程序上下文中的行为，确保检测到的漏洞是可达且可触发的。作者开发了一种三阶段的自底向上的测试方案，包括生成类型和上下文感知的框架，通过模糊测试找到崩溃并使用符号执行提取输入约束，最后通过组合约束来验证崩溃并消除假阳性。实现了自动化原型Griller，并在5个开源项目中使用48个已知漏洞进行评估，成功检测到28个已知漏洞，同时在一些现实世界的应用程序中发现了6个未知漏洞。", "conclusion": "研究结果表明，反应式自底向上的测试可以显著提高对复杂系统的漏洞检测能力，为更强大的安全实践铺平了道路。"}
{"llm_update_time": "20250907", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2509.03876", "html_url": "https://arxiv.org/abs/2509.03876", "title": "漏洞受影响版本识别：我们走了多远？", "title_en": "Vulnerability-Affected Versions Identification: How Far Are We?", "authors": "Xingchu Chen,Chengwei Liu,Jialun Cao,Yang Xiao,Xinyue Cai,Yeting Li,Jingyi Shi,Tianqi Sun,Haiming Chen ang Wei Huo", "background": "漏洞工具对于确定软件版本是否受到影响至关重要，但这些工具的实际有效性仍然存在疑问，因为目前的研究往往局限于早期的SZZ变体、过时的技术以及数据集规模小或粒度粗的问题。因此，亟需进行一次全面的实证研究来评估现有的各种工具。该研究提出了一个高质量的基准，其中包括1,128个真实的C/C++漏洞案例，并系统地评估了12种代表性工具，涵盖不同维度的评估。研究发现显示了现有工具的根本局限性，同时指出了提高工具性能的新的开发方向和研究策略。", "innovation": "该研究首次进行了全面的实证研究，识别受影响的软件版本。研究团队创建了一个包含1,128个真实C/C++漏洞的高质量基准，并评估了12种代表性的工具。评估维度包括版本层面和漏洞层面的有效性、误报和漏报的根本原因、对补丁特征的敏感度以及组合策略的潜力。研究成果揭示了工具的根本局限性，以及如何提高工具性能的新方向。此外，还发布了复制的代码和基准数据，以促进未来研究的发展。", "conclusion": "没有工具可以达到45.0%以上的准确率，关键的挑战在于算法依赖于启发式方法，缺乏语义推理能力和僵化的匹配逻辑。补丁结构，比如只增加代码和跨文件更改，进一步影响性能。虽然组合策略可以提高10.1%的表现，但总体准确率仍然低于60.0%，说明需要全新的方法。该研究为工具的发展、组合策略以及这一领域未来的研究提供了实用的指导。"}
{"llm_update_time": "20250907", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2509.04260", "html_url": "https://arxiv.org/abs/2509.04260", "title": "Python包中的漏洞及其检测方法的经验研究", "title_en": "An Empirical Study of Vulnerabilities in Python Packages and Their Detection", "authors": "Haowei Quan,Junjie Wang,Xinzhe Li,Terry Yue Zhuo,Xiao Chen,Xiaoning Du", "background": "在快速发展的软件开发行业中，Python 以其简洁性、多功能性和广泛的生态系统而受到关注。Python 包作为组织、重用和分发的单位，其漏洞报告数量众多，凸显了其重要性。由于 Python 通常与其他编程语言协同工作以提高性能或实现互操作性，这增加了 Python 包内固有的漏洞的复杂性。现有的漏洞检测工具的有效性仍待深入研究。", "innovation": "本文通过引入 PyVul，一个全面的 Python 包漏洞基准套件，填补了这一空白。PyVul 包含 1157 个公开报告、开发人员验证的漏洞，每个漏洞都链接到受影响的包，并提供了从提交级别到函数级别的注释。同时，通过一种基于大语言模型的数据清理方法来提高标签准确性，PyVul 成为目前最精确的大规模 Python 漏洞基准。此外，研究揭示了 Python 包中的漏洞具有跨语言多样性和广泛的类型，并且提出多语言 Python 包可能更容易受到漏洞的影响。这些洞见进一步验证了现有的漏洞检测工具在有效识别实际安全问题方面的不足，凸显出未来该领域研究的需求。", "conclusion": "使用此基准对现有最先进的检测器进行评估揭示了现有工具的识别能力与有效识别真实世界安全问题的需求之间的显著差异。此外，对 Python 包中观察到的顶级 CWE 进行了实证审查，揭示了现有检测工具的细粒度限制，强调了该领域未来进步的重要性。"}
{"llm_update_time": "20250907", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2509.04423", "html_url": "https://arxiv.org/abs/2509.04423", "title": "设计和开发血液捐赠管理的网络平台", "title_en": "Design and Development of a Web Platform for Blood Donation Management", "authors": "Fatima Zulfiqar Ali,Atrooba Ilyas", "background": "血液捐赠是医疗卫生的关键组成部分，但在紧急情况下找到合适的捐赠者常常面临重大挑战。", "innovation": "该论文介绍了设计和开发的血液捐赠网络平台，这是一个基于网络的系统，连接患者、捐赠者和管理员在一个集中的数字化空间内。该平台支持感兴趣的捐赠者注册个人资料，包括血型、联系方式和可用性。患者可以根据血型和位置搜索捐赠者，系统还会提供附近待愿捐赠者的列表。平台设计采用了用例图、数据库图、类图和序列图来确保结构良好和高效的系统架构。利用现代网络技术，如PHP（Laravel框架）、HTML、CSS、Bootstrap和MySQL，支持XAMPP和Visual Studio Code，实现了动态、交互且用户友好的平台。该系统通过简化捐赠登记、血液需求和通信，减轻紧急状况下的延迟和复杂性，提高血液及时可访问性并提升血液捐赠服务的整体效率。", "conclusion": "通过平台的应用，减少了紧急情况下血液供应的延误和复杂性，提高了血液可获取性和服务质量。"}
{"llm_update_time": "20250907", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2503.09002", "html_url": "https://arxiv.org/abs/2503.09002", "title": "KNighter：通过LLM合成检查器实现静态分析的转型", "title_en": "KNighter: Transforming Static Analysis with LLM-Synthesized Checkers", "authors": "Chenyuan Yang,Zijie Zhao,Zichen Xie,Haoyu Li,Lingming Zhang", "background": "静态分析是检测关键系统（如操作系统内核）中的错误的强大技术。然而，设计和实施静态分析器存在挑战，耗时，并且通常局限于预定义的错误模式。虽然大型语言模型（LLMs）在静态分析方面显示出潜力，但由于计算限制和上下文限制，直接将它们应用于大规模系统仍然不切实际。因此，KNighter是第一个通过自动从历史错误模式合成静态分析器来实现可扩展的LLM基静态分析的方法。", "innovation": "KNighter通过利用LLMs根据历史补丁知识生成专门的静态分析器的方法，而非直接使用LLMs对大规模系统进行分析。实现这一愿景的途径是多阶段合成流水线，该流水线验证检查器的正确性并采用自动化细化过程以逐步减少假阳性结果。这种方法生成的检查器不仅能检测现有手工编写分析器未发现的多种错误模式，并且已经发现了92个新的、关键的长期未发现的错误；这些错误中有77个被确认，57个被修复，30个已分配了CVE编号。", "conclusion": "这项工作为通过检查器合成为实际系统建立了一种全新的可扩展、可靠和可追溯的LLM基静态分析范式。"}
{"llm_update_time": "20250907", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2504.02737", "html_url": "https://arxiv.org/abs/2504.02737", "title": "RBT4DNN: 基于需求的神经网络测试", "title_en": "RBT4DNN: Requirements-based Testing of Neural Networks", "authors": "Nusrat Jahan Mozumder,Felipe Toledo,Swaroopa Dola,Matthew B. Dwyer", "background": "深度神经网络（DNN）在现代系统中的应用使得测试变得更加困难，因为DNN逼近的函数很难用形式化的要求来描述，这使得基于需求的传统测试方法难以适用于DNN。", "innovation": "本文提出了一种基于需求的测试方法（RBT4DNN），该方法使用自然语言需求说明以及术语词典来定义语义特征空间，以生成测试输入。RBT4DNN通过逻辑组合这些语义特征来形式化功能需求的前提条件，并利用符合这些特征组合的训练数据来微调生成模型，以可靠地生成满足前提条件的测试输入。通过对训练好的DNN执行这些测试，可以将其输出与预期的要求后条件行为进行比较。此外，RBT4DNN还可以用于开发过程中的模型行为的指导探索。", "conclusion": "我们的进一步评估表明，RBT4DNN生成的测试既现实又有多样性，并与需求前提条件保持一致，这使我们能够针对模型行为进行目标化的分析，并有效地进行故障检测。该方法能提供给开发者有关模型泛化能力的反馈，并通过一系列准确的测试确保DNN的正确性。"}
{"llm_update_time": "20250907", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2505.23684", "html_url": "https://arxiv.org/abs/2505.23684", "title": "如何获取可解释性需求？方法比较：访谈、焦点小组和在线调查", "title_en": "How to Elicit Explainability Requirements? A Comparison of Interviews, Focus Groups, and Surveys", "authors": "Martin Obaidi,Jakob Droste,Hannah Deters,Marc Herrmann,Raymond Ochsner,Jil Klünder,Kurt Schneider", "background": "随着软件系统变得愈发复杂，可解释性已逐渐成为确保透明度、用户信任和合规性的重要非功能性需求。获取这些可解释性需求具有挑战性，因为不同的方法捕捉的信息细节和结构不同。", "innovation": "本研究比较了三种常见提取方法——焦点小组、访谈和在线调查——的效率和效果，同时评估了分类法在结构化和改进提取过程中的作用。研究发现，访谈在单位时间内收集到的需求最为独特；调查虽然总体收集到了最多的需求，但存在高度冗余；及时引入分类法有助于更有效地提取需求。", "conclusion": "研究建议采用混合方法结合调查和访谈来平衡效率和覆盖范围。未来的研究应探索如何通过自动化支持获取需求，以及如何更好地将分类法整合到不同方法中。"}
{"llm_update_time": "20250907", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2501.14326", "html_url": "https://arxiv.org/abs/2501.14326", "title": "评估大型语言模型在跨内存模型理解与验证并发程序的能力", "title_en": "Assessing Large Language Models in Comprehending and Verifying Concurrent Programs across Memory Models", "authors": "Ridhi Jain,Rahul Purandare", "background": "随着并发编程的普及，有效识别和解决数据竞争、死锁等问题变得至关重要。本研究评估了几种最先进的大型语言模型（LLM），包括GPT-3.5-turbo、GPT-4、GPT-4o、GPT-4o-mini和Mistral-AI的Large2，它们在理解与分析软件程序中的并发问题的能力。考虑到现代系统广泛使用且甚至被包括ARM和x86在内的主流架构支持的放宽内存模型（如TSO和PSO），研究不仅关注顺序一致性内存模型，还关注这些放宽内存模型。实验使用SV-COMP的线程测试和25个ARM的 Litmus 测试来评估这些内存模型。", "innovation": "研究利用了SV-COMP的线程测试和25个ARM的Litmus测试，有效地评估了大型语言模型在理解与验证具有多种内存模型（包括序列一致和放宽内存模型）的并发程序方面的能力。研究发现，在顺序一致性内存模型下，GPT-4、GPT-4o和Mistral-AI的Large2表现出较稳健的并发问题理解能力，但在放宽内存模型下验证程序正确性方面面临挑战，表明现有模型在捕捉内存顺序约束方面存在不足，尤其是在复杂场景下的小型程序验证方面表现不佳。", "conclusion": "尽管大型语言模型在识别和理解序列一致内存模型下的并发问题方面表现良好，但在验证放宽内存模型中的程序正确性方面面临重大挑战。当前这些模型在捕捉内存顺序约束方面存在局限性，验证小而复杂的并发程序的能力仍然不足。"}
{"llm_update_time": "20250907", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2507.03659", "html_url": "https://arxiv.org/abs/2507.03659", "title": "使用大语言模型在Dafny程序中基于规范修复算术错误", "title_en": "Specification-Guided Repair of Arithmetic Errors in Dafny Programs using LLMs", "authors": "Valentina Wu,Alexandra Mendes,Alexandre Abreu", "background": "当程序无法进行形式验证时，调试和修复故障可能复杂且耗时。传统的自动化程序修复（APR）技术依靠测试集进行验证，但测试集可能无法捕捉所有可能的场景。相比之下，形式规范提供了严格的正确性标准，有助于更有效的自动化修复。基于此背景，本文介绍了一种针对Dafny编程语言（一种注重形式验证的编程语言，使用形式规范如前提、后置条件和不变量作为故障定位和修复的指南）的APR工具。", "innovation": "该论文提出了结合形式推理与大语言模型程序合成的技术，以实现自动程序修复，特别关注修复算术错误。通过一系列步骤，包括使用霍尔逻辑确定程序中每条语句的状态，以及应用大语言模型生成候选修复来精确定位故障。所考虑的模型包括GPT-4o mini，Llama 3，Mistral 7B和Llemma 7B。", "conclusion": "该工具在DafnyBench基准测试中的故障定位覆盖率达到了89.6%，并且GPT-4o mini 的修复成功率最高，为74.18%。这些结果表明了结合形式推理与基于大语言模型的程序合成技术在自动化程序修复中的潜力。"}
{"llm_update_time": "20250907", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2505.16590", "html_url": "https://arxiv.org/abs/2505.16590", "title": "更大的并不总比小的好：探索在日志语句生成中使用小型开源语言模型", "title_en": "Larger Is Not Always Better: Exploring Small Open-source Language Models in Logging Statement Generation", "authors": "Renyi Zhong,Yichen Li,Guangba Yu,Wenwei Gu,Jinxi Kuang,Yintong Huo,Michael R. Lyu", "background": "开发者通过日志语句创建日志来记录系统行为并辅助软件维护。因此，高质量的日志对于有效的维护至关重要。然而，手动记录经常导致错误和不一致性。最近的方法强调使用大规模语言模型（LLMs）来自动生成日志语句，但这些方法带来了隐私和资源问题，限制了它们在企业环境中的适用性。现有的方法普遍依赖大型模型，尽管这些模型可能有效，但存在隐私和资源利用的问题。因此，研究需要寻找一种隐私保护且资源效率高的人工日志记录方案。", "innovation": "本文首次进行了一项大规模的实证研究，评估小型开源语言模型（SOLMs）在自动日志语句生成中的应用。研究表明，通过LoRA和RAG进行微调的小型语言模型，在预测日志位置和生成高质量语句方面优于现有的工具和大规模语言模型基准。特别是在Qwen2.5-coder-14B模型上，这种技术组合显示出强大的跨仓库通用性。这些发现强调了SOLMs作为隐私保护且高效的替代方案的优势，特别是在自动日志记录方面相比大模型更为适合。 Innovations include the use of LoRA and RAG techniques to fine-tune SOLMs and the evaluation of these techniques across diverse repositories.", "conclusion": "研究结果表明，特别是使用LoRA和RAG提示微调的小型语言模型在生成日志语句方面表现优异，能有效解决隐私和资源问题并适用于不同开源项目的日志记录，展现了小型开源语言模型的实用价值。"}
{"llm_update_time": "20250907", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2406.01359", "html_url": "https://arxiv.org/abs/2406.01359", "title": "R2C2-Coder: Enhancing and Benchmarking Real-world Repository-level Code Completion Abilities of Code Large Language Models", "title_en": "R2C2-Coder: Enhancing and Benchmarking Real-world Repository-level Code Completion Abilities of Code Large Language Models", "authors": "Ken Deng,Jiaheng Liu,He Zhu,Congnan Liu,Jingxin Li,Jiakai Wang,Peng Zhao,Chenchen Zhang,Yanan Wu,Xueqiao Yin,Yuanxing Zhang,Zizheng Zhan,Wenbo Su,Bangyu Xiang,Tiezheng Ge,Bo Zheng", "background": "近年来，代码补全模型取得了显著进展。在现代软件开发中，基于仓库级别的代码补全方法越来越受到关注，并且已经提出了几种基线方法和基准测试。然而，现有的基于仓库级别的代码补全方法往往未能充分利用项目库中的广泛上下文，如相关文件和类层次结构的复杂性。此外，现有的基准测试通常集中在有限的代码补全场景上，无法很好地反映现有方法的仓库级代码补全能力。因此，文章旨在解决这些问题。", "innovation": "本文提出了R2C2-Coder，以提高并基准测试代码大规模语言模型在真实世界仓库级别的代码补全能力。R2C2-Coder包括一个代码提示构建方法R2C2-Enhance和一个精心设计的基准R2C2-Bench。具体来说，在R2C2-Enhance中，首先构建候选检索池，然后通过从检索池中检索来为每个完成功能光标位置组装完成提示。此外，基于R2C2-Enhance，可以构建一个更具挑战性和多样性的R2C2-Bench，其中包含了训练、验证和测试划分，并提出了上下文扰动策略以更好地模拟真实世界仓库级别的代码补全。", "conclusion": "在多个基准测试上的广泛结果表明，我们的R2C2-Coder是有效的。"}
{"llm_update_time": "20250907", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2507.08523", "html_url": "https://arxiv.org/abs/2507.08523", "title": "InferLog：通过基于ICL的前缀缓存加速在线日志解析的LLM推理", "title_en": "InferLog: Accelerating LLM Inference for Online Log Parsing via ICL-oriented Prefix Caching", "authors": "Yilun Wang,Pengfei Chen,Haiyu Huang,Zilong He,Gou Tan,Chuanfu Zhang,Jingkai He,Zibin Zheng", "background": "现代软件系统生成大量运行时日志，需要高效准确的日志解析以支持关键下游任务如异常检测和根本原因分析。大型语言模型（LLMs）在日志解析方面取得了高度准确的结果，但在生产环境中的部署面临两个主要限制：（1）商业LLMs相关的隐私风险，促使采用本地部署；（2）高流量日志流对延迟和吞吐量的严格要求，现有的LLM解析器无法满足。尽管最近的努力减少了对LLM查询的数量，但它们忽视了LLM调用的高延迟问题，同时并发日志解析请求可能导致LLM推理系统的性能下降。研究表明，推理效率成为LLM基于在线日志解析的关键瓶颈，而非解析准确性。为了解决这个问题，InferLog提出了一种LLM推理优化方法，利用基于ICL的前缀缓存加速在线日志解析。", "innovation": "InferLog 的创新点在于针对LLM的在线日志解析推理效率瓶颈，通过设计（1）前缀感知的ICL细化策略来增加前缀缓存效率，以及（2）基于元学习的快速任务特定配置调优流水线来找到动态日志解析负载下的最优LLM调度配置。实验结果表明，InferLog显著优于现有的推理优化方法，并且在不牺牲解析准确性的前提下加速了最先进的基于LLM的日志解析器。", "conclusion": "本研究提出了一种名为InferLog的方法，该方法通过设计的前缀感知ICL细化策略和基于元学习的任务特定配置调优流水线，显著优化了基于LLM的在线日志解析的推理效率，从而提升了高性能日志解析的能力。"}
