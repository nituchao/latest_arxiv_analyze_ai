{"llm_update_time": "20250815", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.10164", "html_url": "https://arxiv.org/abs/2508.10164", "title": "通过小规模偏好优化修剪大型推理模型的长链推理", "title_en": "Pruning Long Chain-of-Thought of Large Reasoning Models via Small-Scale Preference Optimization", "authors": "Bin Hong,Jiayu Liu,Zhenya Huang,Kai Zhang,Mengdi Zhang", "background": "最近，大型推理模型（LRMs）在长链推理（CoT）中表现出强大的复杂任务处理能力。然而，这些模型生成较长输出的工作量增加，可能导致过度推理，从而在推理的有效性和效率之间造成了挑战。现有的高效推理方法往往牺牲了推理质量，或者需要大量资源。", "innovation": "本文提出了一种长度控制偏好优化（LCPO）方法，该方法直接平衡与NLL损失相关的隐含奖励。LCPO能够在有限的数据和训练下有效学习长度偏好。实验结果表明，该方法显著减少了多个基准上的平均输出长度超50%，同时保持推理性能。", "conclusion": "本研究强调了计算效率方法在指导LRMs向更高效推理方向发展的潜力。"}
{"llm_update_time": "20250815", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.10265", "html_url": "https://arxiv.org/abs/2508.10265", "title": "为什么大语言模型永远无法进行真正的正确推理？", "title_en": "Why Cannot Large Language Models Ever Make True Correct Reasoning?", "authors": "Jingde Cheng", "background": "近年来，基于大型语言模型（LLMs）的生成式人工智能工具（AIGC工具），尤其是受到ChatGPT的影响，许多AI专家和非专业人士纷纷宣称LLMs具有‘理解能力’和‘推理能力’。然而，本文作者认为这些所谓的‘理解能力’和‘推理能力’其实只是语义模糊概念下的幻觉。作者认为实际上LLMs永远不会具备真正的理解和推理能力。论文旨在解释由于工作原理的根本局限性，LLMs无法进行真正的正确推理的原因。", "innovation": "文章挑战了当前广泛接受的观点，通过指出LLMs工作原理的本质限制，强调它们无法实现真正的理解和正确推理。", "conclusion": "LLMs因为其工作原理的根本局限，无法进行真正的正确推理。"}
{"llm_update_time": "20250815", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.10293", "html_url": "https://arxiv.org/abs/2508.10293", "title": "促进高效推理的可验证分步奖励机制", "title_en": "Promoting Efficient Reasoning with Verifiable Stepwise Reward", "authors": "Chuhuai Yue,Chengqi Dong,Yinan Gao,Hang He,Jiajun Chai,Guojun Yin,Wei Lin", "background": "大型推理模型(LRMs)在复杂推理任务中取得了显著进展，尤其是在借助可验证奖励的强化学习支持下。然而，LRMs常常会陷入过度思考的问题，对简单的任务耗用过多计算资源，降低了效率。现有的一些高效推理方法通常需要准确的任务评估来预设令牌预算或选择推理模式，这限制了它们的灵活性和可靠性。", "innovation": "本文重新审视了过度思考的本质，并发现鼓励有效步骤的同时惩罚无效步骤是解决该问题的关键。为此，我们提出了一种新颖的基于规则的可验证分步奖励机制(VSRM)，该机制根据推理轨迹中中间状态的表现分配奖励。这一方法直观且自然地适应了推理任务的分步骤特性。我们在标准化数学推理基准数据集AIME24和AIME25上进行了广泛的实验，将VSRM与PPO和Reinforce++结合使用。结果显示，我们的方法在保持原始推理性能的同时，显著减少了输出长度，实现了有效性和效率之间的最佳平衡。进一步分析过度思考的频率和pass@k分数表明，我们的方法实际上有效地抑制了无效步骤，促进了有效的推理，从根本上缓解了过度思考的问题。", "conclusion": "我们的方法在抑制无效步骤和促进有效推理方面取得了显著成效，从根本上缓解了过度思考问题，同时保持了效率和准确性之间的最佳平衡。所有代码将在论文被接受后开源。"}
{"llm_update_time": "20250815", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.10146", "html_url": "https://arxiv.org/abs/2508.10146", "title": "Agentic AI框架：架构、协议与设计挑战", "title_en": "Agentic AI Frameworks: Architectures, Protocols, and Design Challenges", "authors": "Hana Derouiche,Zaki Brahmi,Haithem Mazeni", "background": "随着大型语言模型（LLMs）的出现，人工智能领域正经历一场变革性的范式转变，称为赋权型人工智能（Agentic AI），其中智能代理展现出目标导向的自主性、情境推理和动态多智能体协调。本研究通过系统性回顾并比较了CrewAI、LangGraph、AutoGen、Semantic Kernel、Agno、Google ADK和MetaGPT等Leading Agentic AI框架，评估了它们的架构原则、通信机制、内存管理、安全性护栏以及面向服务计算范型的契合度。", "innovation": "本文深入分析了合同网协议（CNP）、智能体到智能体（A2A）、智能体网络协议（ANP）和Agora等协议，不仅为赋权型AI系统确立了基础分类，还提出了增强可扩展性、稳健性和互操作性的未来研究方向。该研究为致力于推动下自主AI系统发展的研究者和实践者提供了全面参考。", "conclusion": "这项工作不仅为赋权型人工智能系统建立了基础分类，而且还提出了未来的研究方向，以增强其可扩展性、稳健性和互操作性。这对于研究者和实践者来说是一个重要的参考，有助于推动下一代自主AI系统的发展。"}
{"llm_update_time": "20250815", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.10177", "html_url": "https://arxiv.org/abs/2508.10177", "title": "KompeteAI：加速自主多代理系统，用于解决机器学习问题的端到端管道生成", "title_en": "KompeteAI: Accelerated Autonomous Multi-Agent System for End-to-End Pipeline Generation for Machine Learning Problems", "authors": "Stepan Kulibaba,Artem Dzhalilov,Roman Pakhomov,Oleg Svidchenko,Alexander Gasnikov,Aleksei Shpilman", "background": "最近基于大型语言模型（LLM）的自动机器学习（AutoML）系统表现出色，但存在探索策略受限和执行瓶颈等显著局限。探索受到一次性方法缺乏多样性和蒙特卡洛树搜索（MCTS）方式无法重新组合强部分解决方案的限制。执行瓶颈来自于冗长的代码验证循环，阻碍了迭代优化。", "innovation": "提出了KompeteAI，这是一种具有动态探索解决方案空间的新型AutoML框架。与之前的MCTS方法将想法独立处理不同，KompeteAI引入了组合顶级候选人的合并阶段。通过结合检索增强生成（RAG），从Kaggle笔记本和arXiv论文中获取实际策略来扩展假设空间。还利用预测评分模型和加速调试方法解决执行瓶颈，通过早期阶段指标评估解决方案潜力，避免昂贵的完全代码执行。这种方法将管道评估速度提升6.9倍。", "conclusion": "KompeteAI在主要的AutoML基准测试MLE-Bench上的平均性能超越了领先方法（如RD-agent、AIDE和Ml-Master）3%以上。还提出了Kompete-bench来解决MLE-Bench中的限制，在此新基准测试中，KompeteAI也取得了最先进的结果。"}
{"llm_update_time": "20250815", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.10241", "html_url": "https://arxiv.org/abs/2508.10241", "title": "扩展事件的熵潜能以实现人工智能中的不确定性量化和决策", "title_en": "Extending the Entropic Potential of Events for Uncertainty Quantification and Decision-Making in Artificial Intelligence", "authors": "Mark Zilberman", "background": "本文探讨了熵潜能的概念，这是一种衡量离散事件对未来系统预期熵的影响的参数。研究背景在于熵潜能的概念源自物理学，在此研究人员将其适应于AI领域，引入了以事件为中心的度量标准，以捕捉行动、观察或其他离散事件对未来时间范围内的不确定性的影响。这种方法通过条件期望来考虑反事实场景，为统一和加强智能系统中的不确定性建模提供了可能。研究人员详细探讨了熵潜能框架在政策评估、内在奖励设计、可解释的AI和异常检测等领域的应用。", "innovation": "本文的创新之处在于扩展了熵潜能的概念，以适应AI的应用需求。通过引入事件为中心的度量标准，这一框架能够更准确地捕捉离散事件对系统不确定性的长期影响。特别地，研究人员强调了条件期望，以便在考虑反事实场景时更好地量化不确定性。这种方法提供了一个基于理论、可解释且灵活的方式来管理AI中的不确定性，同时进行了复杂AI模型中计算的讨论，将其与热力学、信息理论和机器学习原理相结合。", "conclusion": "熵潜能框架为管理和理解AI中不确定性提供了一个实用的、可解释的方法，并成功地统一了不确定性的建模。该研究不仅为现有的理论提供了新的见解，还为实际应用中的决策提供了工具。这种方法可以进一步帮助提高AI系统的性能和透明度，特别是在政策评估、强化学习、内生奖励设计和异常检测等领域。"}
{"llm_update_time": "20250815", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.10143", "html_url": "https://arxiv.org/abs/2508.10143", "title": "MCP-Orchestrated Multi-Agent System for Automated Disinformation Detection", "title_en": "MCP-Orchestrated Multi-Agent System for Automated Disinformation Detection", "authors": "Alexandru-Andrei Avram,Adrian Groza,Alexandru Lecu", "background": "数字平台上的虚假信息传播给信息完整性带来了巨大挑战。研究人员提出了一种多智能体系统，旨在通过关系提取技术检测新闻文章中的虚假信息，特别是在标题和简短的文字段落中。该系统结合了四个智能体，分别负责机器学习、维基百科知识验证、一致性检测和网络爬取数据解析等功能。这些智能体通过一种称为Model Context Protocol (MCP)的协议进行协调和优化。", "innovation": "提出了一种名为Agentic AI的多智能体系统，利用机器学习、维基百科知识检查、一致性检测和网络爬取数据解析等功能进行虚假信息检测。系统通过MCP协议实现组件间的共享上下文和实时学习，采用加权聚合方法进行结果整合，这种方法在误分类率的数学推导基础上得出，优于算法阈值优化方法。这种模块化架构使得系统易于扩展，同时保留了决策过程的详细信息。", "conclusion": "多智能体联合系统在检测虚假信息方面表现出95.3%的准确率和0.964的F1评分，显著优于单独智能体和传统方法。加权聚合方法的优越性进一步证明了其在混合多个智能体预测结果方面的有效性。该系统展示了在虚假信息检测领域的强大能力和潜在应用。"}
{"llm_update_time": "20250815", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.10108", "html_url": "https://arxiv.org/abs/2508.10108", "title": "Amazon Nova AI Challenge -- Trusted AI: Advancing secure, AI-assisted software development", "title_en": "Amazon Nova AI Challenge -- Trusted AI: Advancing secure, AI-assisted software development", "authors": "Sattvik Sahai,Prasoon Goyal,Michael Johnston,Anna Gottardi,Yao Lu,Lucy Hu,Luke Dai,Shaohua Liu,Samyuth Sagi,Hangjie Shi,Desheng Zhang,Lavina Vaz,Leslie Ball,Maureen Murray,Rahul Gupta,Shankar Ananthakrishna", "background": "AI系统在软件开发中的应用越来越受欢迎，但确保其安全性依然面临众多挑战。Amazon为此发起了Amazon Nova AI挑战赛中的Trusted AI项目，这是一个全球性的比赛，旨在推动安全AI的进步。比赛涉及10所大学队伍的参与，评估自动红队建设和安全AI助理的方法，重点关注通过对手之间的对抗性竞赛测试AI的安全性对齐。比赛中，团队获得了大量高质量标注数据，以加速迭代改进。", "innovation": "参赛团队开发了先进的技术，引入了基于推理的安全对齐、稳健模型护栏、多回合突破和大型语言模型（LLM）的高效探测等新的方法。Amazon Nova AI挑战赛团队也进行了大量的科学和工程投资，包括构建挑战所需的基本赛手脚本编码专家模型，开发锦标赛编排服务，以及创建评估框架，支持了这些努力。", "conclusion": "论文概述了大学团队和Amazon Nova AI挑战赛团队在解决AI软件开发中的安全挑战方面取得的进步，突出了这一合作努力以提高AI安全性，设定了更高的行业标准。"}
{"llm_update_time": "20250815", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.10047", "html_url": "https://arxiv.org/abs/2508.10047", "title": "LLMs与优化建模：进展与未来方向", "title_en": "A Survey of Optimization Modeling Meets LLMs: Progress and Future Directions", "authors": "Ziyang Xiao,Jingrong Xie,Lilin Xu,Shisi Guan,Jingyan Zhu,Xiongwei Han,Xiaojin Fu,WingYin Yu,Han Wu,Wei Shi,Qingcan Kang,Jiahui Duan,Tao Zhong,Mingxuan Yuan,Jia Zeng,Yuan Wang,Gang Chen,Dongxiang Zhang", "background": "优化建模因其在解决实际问题中的巨大应用价值，已被广泛应用于各行各业的最优决策过程，但这种过程需要来自运筹学专业人士的大量专业知识。随着大型语言模型（LLMs）的出现，自动化的数学建模过程迎来了新的机遇。现有文献主要集中在技术栈的各个方面，包括数据合成、模型微调、推理框架、基准数据集以及性能评估，但并未充分关注数据集的质量和构建新的基准评估标准及其在线整合资源平台等问题。因此，有必要对当前方法的局限性进行识别，并制定未来的研究方向。", "innovation": "本文全面审查了使用LLMs的优化建模领域的最新进展，包括数据合成、模型微调、推理框架、基准数据集和性能评估。特别地，该研究深入分析了基准数据集的质量，并发现其错误率异常高，因此对该数据集进行了清理，并建立了一个新的基准排行榜，以确保公平的性能评估。此外，本文还构建了一个在线门户，整合了清数据集、代码和论文资源，旨在造福社区。本文还指出了当前方法的局限性，并提出了未来的研究方向以改进优化建模与LLMs结合的方法。", "conclusion": "总结了当前使用LLMs进行优化建模的进展，同时揭示了现有方法的局限性，强调了未来需要解决的问题和研究方向，为该领域的发展提供了指导。"}
{"llm_update_time": "20250815", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.10152", "html_url": "https://arxiv.org/abs/2508.10152", "title": "改善和评估开放式深度研究代理", "title_en": "Improving and Evaluating Open Deep Research Agents", "authors": "Doaa Allabadi,Kyle Bradbury,Jordan M. Malof", "background": "我们关注的是Deep Research Agents (DRAs)，这些系统可以从用户那里获取自然语言指令，并自主地搜索和利用互联网内容来解决问题。虽然最近的DRAs展示出了在公开基准上的出色能力，但大多数研究涉及的是封闭源代码的系统。在本研究进行时，仅发现一个开源的DRA系统，称为Open Deep Research (ODR)。本研究将具有挑战性的测试基准BrowseComp用于比较ODR和其他现有的封闭源代码系统。作者提出了一种新的基准叫BrowseComp-Small (BC-Small)，它包含BrowseComp的一部分数据，这样更适合学术实验室来研究DRAs。ODR和两个其他封闭源代码系统被用于BC-Small基准测试，一个是Anthropic提供的，另一个是Google提供的。在这三个系统中，都没有一个成功回答测试集中的60个问题。通过对ODR进行三个战略改进，形成ODR+模型，它在BC-Small基准中取得了10%的成功率，这是在此类系统中最好的成绩。作者还提供了消融实验的结果，表明所有三个改进都是成功的必要因素。", "innovation": "研究开发了一种新的基准测试，即BrowseComp-Small (BC-Small)，这是一个更适用于学术实验室研究的DRAs基准。提出了三个战略性的改进，改进后形成的ODR+模型在BC-Small基准测试中取得了10%的成功率，这在既有封闭源代码系统和开放源代码系统中都达到了最佳成绩。该研究进行了消融实验来确认每种改进的贡献度。", "conclusion": "所有被测试的三个系统均未能正确回答测试集中的问题。通过对ODR进行改进，并将其发展为ODR+模型，显著提高了其性能，达到了10%的成功率。这些改进包括消融实验中每个改进对结果的影响。未来的工作可能会探索导致低成功率的具体挑战，并尝试进一步优化ODR+以提高其表现。"}
{"llm_update_time": "20250815", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.10337", "html_url": "https://arxiv.org/abs/2508.10337", "title": "基于curriculum学习的强化学习方法：利用RAG进行多模态问题回答", "title_en": "A Curriculum Learning Approach to Reinforcement Learning: Leveraging RAG for Multimodal Question Answering", "authors": "Chenliang Zhang,Lin Wang,Yuanyuan Lu,Yusheng Qi,Kexin Wang,Peixu Hou,Wenshi Chen", "background": "该论文描述了Dianping-Trust-Safety团队参与META CRAG-MM挑战的解决方案。挑战要求构建一个全面的检索增强生成系统，用于多模态多轮问答。比赛包含三个任务：使用基于图像的知识图谱检索的结构化数据答题；综合知识图谱和网络搜索结果的信息；处理需要多轮对话且需理解上下文和多源信息聚合的问题。", "innovation": "论文提出的方法基于视觉大语言模型，并通过从GPT-4.1中提取知识进行监督微调，进一步使用curriculum学习策略引导强化学习，从而提高答案的准确性并减少幻觉。此外，为了Task 2和Task 3，还利用了网络搜索API来整合外部知识，使系统能够更好地处理复杂查询和多轮对话。这些创新使训练管道中的课程学习与强化学习结合更加有效。", "conclusion": "论文的方法在Task 1中取得第一名，领先优势达52.38%，在Task 3中获得第三名。这表明在培训管道中将课程学习与强化学习相结合的有效性得到了验证。"}
{"llm_update_time": "20250815", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.10340", "html_url": "https://arxiv.org/abs/2508.10340", "title": "多代理信任区域策略优化：联合约束方法", "title_en": "Multi-Agent Trust Region Policy Optimisation: A Joint Constraint Approach", "authors": "Chak Lam Shek,Guangyao Shi,Pratap Tokekar", "background": "多智能体强化学习（MARL）需要交互智能体之间协调和稳定的策略更新。Heterogeneous-Agent Trust Region Policy Optimization（HATRPO）使用Kullback-Leibler（KL）散度通过信任区域约束来稳定训练。然而，为每个智能体分配相同的KL阈值可能导致缓慢且局部优化的更新，特别是在异质性环境中更加明显。", "innovation": "为了克服这一局限，本文提出了两种分配KL散度阈值的方法：基于KKT条件的方法（HATRPO-W）和基于贪婪算法的方法（HATRPO-G）。这两种方法通过将顺序策略优化与受限阈值调度相连，使得在异质智能体环境中可以实现更加灵活和有效的学习。实验结果表明，这两种方法显著提高了HATRPO的性能，在多种MARL基准测试中实现了更快的收敛和更高的最终奖励。具体来说，HATRPO-W和HATRPO-G在最终性能上的提升相当，每种方法都超过了22.5%。值得注意的是，HATRPO-W还在学习动态稳定性方面表现出更佳表现，如其较低的方差所反映的那样。", "conclusion": "我们的方法显著提升了HATRPO在异质智能体环境中的性能，在多个MARL基准测试中实现了更快的收敛和更高的最终奖励。HATRPO-W和HATRPO-G分别通过优化全局KL约束下的阈值分配与优先级分配，提高了学习过程中的稳定性和效率。"}
{"llm_update_time": "20250815", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.10425", "html_url": "https://arxiv.org/abs/2508.10425", "title": "HiRef: 利用层次化本体和网络精炼实现稳健的药物推荐", "title_en": "HiRef: Leveraging Hierarchical Ontology and Network Refinement for Robust Medication Recommendation", "authors": "Yan Ting Chok,Soyon Park,Seungheun Baek,Hajung Kim,Junhyun Lee,Jaewoo Kang", "background": "药物推荐是协助医生从纵向患者电子医疗记录中快速做出决策的关键任务。然而，现实世界的EHR数据存在显著挑战，因为罕见的医疗实体和不完整的记录可能无法完全捕捉临床真相。尽管数据驱动模型在纵向EHR数据上经常表现出强大的试验性能，但在缺少或新条件下却难以泛化，主要是因为它们依赖于观察到的共现模式。", "innovation": "我们提出了一个统一框架HiRef，它结合了两种互补结构：（i）在策展医疗本体中编码的层次化语义，（ii）从现实世界EHR中精炼的共现模式。我们通过Hyperbolic空间嵌入本体实体，自然捕捉树状关系，通过共享祖先进行知识传递，从而改善对未见过的编码的泛化能力。为了进一步提高鲁棒性，我们引入了一种基于先验信息稀疏正则化方案，该方案通过抑制虚假边来精炼EHR共现图，同时保留临床相关的联系。", "conclusion": "我们的模型在EHR基准（MIMIC-III和MIMIC-IV）上表现出强大的性能，并在模拟的未见过的代码设置下保持高准确性。广泛的实验和全面的消融研究表明HiRef对未见过的医疗代码具有抗脆弱性，通过学习稀疏化的图结构和医疗代码嵌入的深入分析得到了支持。"}
{"llm_update_time": "20250815", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.10391", "html_url": "https://arxiv.org/abs/2508.10391", "title": "LeanRAG：基于知识图谱的具有语义聚合和层次检索的生成", "title_en": "LeanRAG: Knowledge-Graph-Based Generation with Semantic Aggregation and Hierarchical Retrieval", "authors": "Yaoze Zhang,Rong Wu,Pinlong Cai,Xiaoman Wang,Guohang Yan,Song Mao,Ding Wang,Botian Shi", "background": "检索增强生成（RAG）通过利用外部知识在大型语言模型中起到关键作用，但是由于检索到上下文错误或不完整的信息，其有效性常受到限制。为解决这一问题，基于知识图谱的RAG方法已经演进到层次结构，将知识组织成多级摘要，然而这些方法仍然面临两个未解决的关键挑战：高层概念性摘要彼此孤立，缺乏用于跨社区推理的显式关系；检索过程本身仍保持结构上的无意识，通常退化为低效的平面搜索，无法充分利用图形丰富的拓扑结构。", "innovation": "本研究引入了一种名为LeanRAG的框架，该框架采用深度合作设计，结合了知识聚合和检索策略。LeanRAG首先使用一种新颖的语义聚合算法形成实体簇，并构建聚合级摘要之间的新明示关系，从而创建一个完全可导航的语义网络。其次，采用自下而上的结构指导检索策略将查询锚定到最相关的细粒度实体，然后系统地沿图形语义路径遍历以收集简明但上下文综合的证据集。此方法能降低图形路径检索的大量开销，并减少重复信息的检索。", "conclusion": "该研究在四个具有不同领域的挑战性问答基准测试中进行了广泛的实验，结果表明LeanRAG在响应质量上显著优于现有方法，同时减少了46%的检索冗余。"}
{"llm_update_time": "20250815", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.10486", "html_url": "https://arxiv.org/abs/2508.10486", "title": "SEQ-GPT：借助大型语言模型的基于示例的空间查询", "title_en": "SEQ-GPT: LLM-assisted Spatial Query via Example", "authors": "Ivan Khai Ze Lim,Ningyi Liao,Yiming Yang,Gerald Wei Yong Yip,Siqiang Luo", "background": "当前的空间服务，如在线地图，主要依赖用户的查询来实现位置搜索。然而，在执行复杂任务时，如同时搜索多个位置，用户体验受限。本研究探讨了基于用户定义示例的空间示例查询（SEQ）扩展场景，即在多个相关位置上进行联合搜索。本研究提出了一种基于大型语言模型（LLMs）的空间查询系统SEQ-GPT，通过自然语言实现更加多样的SEQ搜索。利用LLMs的语言特性，可以在SEQ过程中实现独特的交互操作，如让用户澄清查询细节和根据用户反馈动态调整搜索。此外，还提出了一种定制化的LLM适应流程，通过对话合成和多模型合作对自然语言与结构化空间数据和查询进行对齐。", "innovation": "本研究的主要创新点包括：1) 利用大型语言模型（LLMs）开发一种新的空间查询系统SEQ-GPT，通过自然语言实现更加灵活的空间搜索。2) 引入独特交互操作，如用户澄清查询细节和动态调整搜索。3) 开发了一种新的LLM适应流程，通过对话合成和多模型合作对齐自然语言与结构化空间数据和查询。", "conclusion": "SEQ-GPT提供了一种端到端的演示，展示如何通过现实数据和应用场景拓宽空间搜索。"}
{"llm_update_time": "20250815", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.10467", "html_url": "https://arxiv.org/abs/2508.10467", "title": "FIRESPARQL：一种基于大语言模型的用于学术知识图谱的SPARQL查询生成框架", "title_en": "FIRESPARQL: A LLM-based Framework for SPARQL Query Generation over Scholarly Knowledge Graphs", "authors": "Xueli Pan,Victor de Boer,Jacco van Ossenbruggen", "background": "学术知识图谱（SKGs）的问题回答任务由于学术内容的复杂性和图结构的复杂性仍然具有挑战性。虽然大型语言模型（LLM）可以将自然语言问题（NLQ）转换为SPARQL查询，但这些基于LLM的方法在生成SPARQL查询时遇到困难，主要原因在于对学术知识图谱特定内容和其底层模式的暴露有限。在生成的SPARQL查询中发现了两类主要错误：结构一致性问题和语义不准确性。", "innovation": "我们提出了FIRESPARQL，一个模块化框架，核心组件是可微调的大语言模型，还支持检索增强生成（RAG）作为可选上下文提供，以及SPARQL查询纠正层。我们使用SciQA基准对框架进行评估，并使用零样本、零样本与RAG结合、一样本、微调和微调结合RAG的不同配置进行比较，并与基线和当前最佳方法进行性能对比。通过BLEU和ROUGE衡量查询准确性，通过宽松精确匹配衡量查询结果准确性，评估结果表明微调在查询和查询结果的准确性上表现最好。", "conclusion": "实验结果表明，微调实现了最高的整体性能，在测试集上查询准确性达到了0.90 ROUGE-L，查询结果准确性达到了0.85的宽松精确度匹配（RelaxedEM）。"}
{"llm_update_time": "20250815", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.10433", "html_url": "https://arxiv.org/abs/2508.10433", "title": "We-Math 2.0: 一种促进直观数学推理的多功能MathBook系统", "title_en": "We-Math 2.0: A Versatile MathBook System for Incentivizing Visual Mathematical Reasoning", "authors": "Runqi Qiao,Qiuna Tan,Peiqing Yang,Yanzi Wang,Xiaowan Wang,Enhui Wan,Sitong Zhou,Guanting Dong,Yuchen Zeng,Yida Xu,Jie Wang,Chong Sun,Chen Li,Honggang Zhang", "background": "多模态大型语言模型（MLLMs）在各种任务中展现了出色的能力，但在处理复杂的数学推理方面仍存在问题。现有研究主要集中在数据集构建和方法优化上，但忽视了全面的知识导向设计和模型中心的数据空间建模两个关键方面。", "innovation": "We-Math 2.0 引入了一个综合系统，结合了结构化数学知识系统、模型中心的数据空间模型以及基于强化学习（RL）的训练范式，以全面提高MLLMs的数学推理能力。该系统的关键贡献包括：（1）构建了一个五级层次知识体系，涵盖491个知识点和1,819个基本原则；（2）开发了MathBook-Standard和MathBook-Pro，分别确保了广泛的概念覆盖和灵活性，并生成了多难度级别的问题集；（3）定义了冷启动微调和渐进对齐RL两个阶段，以实现在不同难度级别上的逐步对齐；（4）提出了一套全面的基准测试，涵盖了所有491个知识点，并包含多样的推理步骤分布。", "conclusion": "实验结果显示，MathBook-RL 在四个广泛使用的基准测试中表现出与现有基线竞争力，并在 MathBookEval 中取得了优异成绩，显示出在数学推理方面有很好的泛化能力。"}
{"llm_update_time": "20250815", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.10429", "html_url": "https://arxiv.org/abs/2508.10429", "title": "MM-Food-100K：具有可验证来源的100,000样本多模态食品智能数据集", "title_en": "MM-Food-100K: A 100,000-Sample Multimodal Food Intelligence Dataset with Verifiable Provenance", "authors": "Yi Dong,Yusuke Muraoka,Scott Shi,Yi Zhang", "background": "该研究介绍了一个名为MM-Food-100K的公共数据集，包含100,000个带有可验证来源的多模态食品图像样本。该数据集来源于一个原始的120万张高质量接受图像的大型语料库，这些图像被标注了大量信息（如菜肴名称、创造地等）。该语料库通过六周的时间收集了来自超过8.7万名贡献者的图像，利用Codatta贡献模式结合社区采编和可配置的AI辅助质量检查；每个提交的图像都链接到一个安全的链外账本上的钱包地址，增加了可追溯性，而完整的链上协议也在计划中。该研究通过在图像营养预测任务上微调大型图像-语言模型（ChatGPT 5、ChatGPT OSS、Qwen-Max）进一步验证了数据集的价值，结果显示其在标准评估指标上普遍优于原生基线，主要报告的是MM-Food-100K子集的结果。作者将该数据集以公开免费的访问方式发布，并保留约90%的数据用于潜在的商业访问，部分收益将与贡献者分享", "innovation": "创新在于建立了一个具有可验证来源的100,000样本大规模多模态食品智能数据集，该数据集使用Codatta贡献模式与社区采编和可配置的AI辅助质量检查相结合来收集和验证数据；每个提交的图像都链接到一个安全的链外账本上的钱包地址，增强了可追溯性，且计划引入链上协议；通过在图像营养预测任务上微调大型图像-语言模型，验证了数据集在建立多模态食品智能方面的实用性", "conclusion": "研究团队通过验证和微调模型展示了数据集的有效性，并将其以免费公开发放，同时保留大部分数据用于潜在的商业访问，实现了数据价值的最大化。"}
{"llm_update_time": "20250815", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.10492", "html_url": "https://arxiv.org/abs/2508.10492", "title": "逆转医生与AI的关系：大型语言模型驱动的全程临床诊断", "title_en": "Reverse Physician-AI Relationship: Full-process Clinical Diagnosis Driven by a Large Language Model", "authors": "Shicheng Xu,Xin Huang,Zihao Wei,Liang Pang,Huawei Shen,Xueqi Cheng", "background": "全链条临床诊断包括从模糊的主诉开始的整个诊断流程。尽管人工智能（AI），特别是大语言模型（LLMs），正在改变临床诊断，但目前它的主要角色仍然是医生的助手。当前的AI辅助工作模式只能在诊断流程的特定部分回答具体的医学问题，而无法从模糊的主诉开始驱动整个诊断过程，也不能大幅减轻医生的负担，提高诊断效率。因此存在一个关键性的差距，限制了AI在全过程中减少医生负担并提高诊断效率的能力。", "innovation": "本文提出了一个范式转变，将医生和AI之间的关系反转，重新定位AI作为主要导演，医生作为辅助。本文介绍了DxDirector-7B，它具有先进的深度思考能力，能够最少的医生参与下驱动全链条诊断。DxDirector-7B还建立了一个坚实的责任框架，明确了AI和医生在误诊中的责任划分。评估表明，DxDirector-7B不仅在诊断准确性上取得了显著的改善，也显著减轻了医生的工作负担，相比于最先进的医疗LLMs和通用LLMs。通过细粒度的临床多部门和任务验证显示了其有效性，并得到了专家的一致评价，表明其能够在某些方面替代医疗专家。这些发现标志着一个新的时代，AI从医生助手转变为全链条诊断的驱动者，大大减少了医生的工作负担，提供了一种高效准确的诊断解决方案。", "conclusion": "DxDirector-7B作为一种能够从模糊的主诉开始驱动全链条诊断的大型语言模型，显著提高了诊断准确性，并大幅减轻了医生的工作负担，标志着AI从医生助手转变为全链条诊断的驱动者的新时代。"}
{"llm_update_time": "20250815", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.10530", "html_url": "https://arxiv.org/abs/2508.10530", "title": "首先多元化，然后高质量：语言模型对齐的两阶段假设", "title_en": "Diversity First, Quality Later: A Two-Stage Assumption for Language Model Alignment", "authors": "Zetian Sun,Dongfang Li,Baotian Hu", "background": "语言模型（LMs）需要与人类偏好对齐，这对于构建可靠的AI系统至关重要。通常，通过优化LM策略来最大化反映人类偏好的预期奖励来解决这个问题。最近，直接偏好优化（DPO）被提出作为一种LM对齐方法，直接从静态偏好数据中优化策略，并进一步通过在训练循环中引入策略采样（即训练过程中生成的偏好数据）进行改进。然而，作者指出在政策采样数据与静态数据之间存在系统性有效性差异。", "innovation": "作者提出了对齐阶段假设，将对齐过程分为两个不同的阶段：偏好注入阶段，从中受益于多样化数据，以及偏好微调阶段，更喜欢高质量数据。通过理论和实证分析，作者界定了这些阶段，并提出了有效算法来识别它们之间的边界。这提高了DMO和DPO方法的有效性。", "conclusion": "该研究通过实验验证了对齐阶段假设和边界测量的普遍适用性，并展示了这种方法在5种模型（Llama、Zephyr、Phi-2、Qwen、Pythia）和2种对齐方法（DMO、SLiC-HF）上的有效性。"}
{"llm_update_time": "20250815", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.10501", "html_url": "https://arxiv.org/abs/2508.10501", "title": "PASS: Probabilistischen Agentic Supernet Sampling für interpretsche und adaptives Brustschulterstrahlen-Schlusselwortauswertung", "title_en": "PASS: Probabilistic Agentic Supernet Sampling for Interpretable and Adaptive Chest X-Ray Reasoning", "authors": "Yushi Feng,Junye Du,Yingying Hong,Qifan Wang,Lequan Yu", "background": "现有的辅助增强系统在实际应用中受到三个主要限制：（i）黑箱推理步骤降低了决策制定的信任度，带来了安全风险；（ii）不完善的多模态整合，对于医疗保健任务来说是内在的关键；（iii）僵硬且计算效率低的代理人管道。这些限制引起了对医疗AI安全性的担忧。", "innovation": "作者提出了PASS (Probabilistic Agentic Supernet Sampling) ，这是首个针对胸部X光图像（CXR）推理的多模态框架，解决了上述问题。PASS通过自适应地从多元工具图中抽样推理工作流程，提供带有可解释概率的决策路径，利用其在表征引导下的代理人超网络分布在复杂多模态医疗数据的任务中进行了优化。此外，PASS能够持续压缩显著发现到个人记忆中，并根据推理路径选择深度或早期退出以提高效率。为了在性能和成本之间取得帕累托前沿，设计了三项训练过程：专家知识预热、对比路径排名和成本感知强化学习。引入了CAB-E，一个全面的多步、安全关键的自然语言自由形式CXR推理基准，便于严格评估。", "conclusion": "实验结果表明，PASS在多个指标（如准确率、AUC、LLM-J）上显著优于强大的基线模型，同时平衡了计算成本。这为可解释、适应性和多模态医疗代理系统的新开创范式铺平了道路。"}
{"llm_update_time": "20250815", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.10669", "html_url": "https://arxiv.org/abs/2508.10669", "title": "STEP: Stepwise Curriculum Learning for Context-Knowledge Fusion in Conversational Recommendation", "title_en": "STEP: Stepwise Curriculum Learning for Context-Knowledge Fusion in Conversational Recommendation", "authors": "Zhenye Yang,Jinpeng Chen,Huan Li,Xiongnan Jin,Xuanyang Li,Junwei Zhang,Hongbo Gao,Kaimin Wei,Senzhang Wang", "background": "现有对话型推荐系统（CRS）旨在通过自然语言对话主动捕捉用户偏好并推荐高质量的商品。CRS通过对话模块收集用户偏好并通过推荐模块构建用户画像生成适当的推荐。然而，现有的CRS在捕捉用户偏好和对话上下文的深层次语义时面临挑战。特别是，有效整合外部知识图谱（KG）信息到对话生成和推荐中仍然是一个亟待解决的问题。传统的做法通常是直接将KG信息与对话内容结合，这往往难以处理复杂的语义关系，导致推荐结果可能不符合用户的期望。", "innovation": "本文介绍了一种新型的对话型推荐系统——STEP，它依赖预训练语言模型，采用带有课程引导（curriculum-guided）上下文-知识融合的方法，并采用轻量级任务特定提示调优。F-Former通过三阶段课程将对话上下文逐步与知识图谱实体对齐，从而解决细微语义不匹配问题。融合的表示被注入冻结的语言模型中，通过两个最小但适应性强的前缀提示实现：对话前缀调整响应生成以符合用户意图，推荐前缀偏向知识一致的候选品项。这种双提示方案允许模型在共用跨任务语义的同时尊重对话和推荐的不同目标。", "conclusion": "实验结果表明，STEP在两个公开数据集中的推荐精度和对话质量方面均优于主流方法。"}
{"llm_update_time": "20250815", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.10539", "html_url": "https://arxiv.org/abs/2508.10539", "title": "通过低成本方差减少提高基于价值的过程验证器", "title_en": "Improving Value-based Process Verifier via Low-Cost Variance Reduction", "authors": "Zetian Sun,Dongfang Li,Baotian Hu,Min Zhang", "background": "大型语言模型（LLMs）在各种任务上取得了显著的成功，但在复杂领域如数学的推理能力仍然存在重大挑战。基于价值的过程验证器，通过估计部分推理链导致正确解决方案的概率，是一种有潜力提升推理能力的方法。然而，这种方法的有效性受制于训练标注中的估计误差，这是由于LLM推理的高成本导致的蒙特卡洛（MC）采样的数量有限性造成的。本文针对这一问题进行了研究，发现主要问题是高方差而非偏差导致的估计误差，MC估计器是一个具有最小方差无偏估计性质的MVUE。", "innovation": "本文提出了一种新的采样方法，称为Compounded Monte Carlo Sampling (ComMCS)，该方法通过线性组合当前步骤和后续步骤的MC估计器来构建一个无偏估计器，理论上证明了这种方法可以在不影响估计无偏性的同时减少方差，而且不需要额外的LLM推理成本。此外，通过MATH-500和GSM8K基准试验验证，ComMCS方法在Best-of-32采样实验中分别比基于回归的优化方法和非方差减少的基线提高了2.8个和2.2个百分点。", "conclusion": "本文通过提出Compounded Monte Carlo Sampling (ComMCS)方法，在减少基于价值的过程验证器的估计误差方面取得了显著进展，提高了准确性，且无需额外的计算成本。这种方法在MATH-500等测试集上得到了验证，表现优于其他方法。"}
{"llm_update_time": "20250815", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.10745", "html_url": "https://arxiv.org/abs/2508.10745", "title": "Agentic Design Review System", "title_en": "Agentic Design Review System", "authors": "Sayan Nag,K J Joseph,Koustava Goswami,Vlad I Morariu,Balaji Vasan Srinivasan", "background": "评估图形设计需要从对齐、组成、美学和色彩选择等多个方面进行评估。为了进行整体评估，通常需要从多个专家评审者的反馈中聚合意见。然而，当前仍缺乏一个有效的系统来实现这一目标。因此，本文提出了一个名为Agentic Design Review System (AgenticDRS) 的协作设计评估系统，其中多个代理共同分析设计，由一个超代理进行协调。此外，本文还提出了一种基于图匹配的上下文示例选择方法和一个独特的提示扩展方法，以使每个代理能够具体了解设计内容。为了评估该框架的有效性，本文还提出了一套名为DRS-BENCH的基准测试。实验证验证明了AgenticDRS在评估图形设计和生成可操作反馈方面的有效性，而且通过对比最新的基线模型并进行关键实验分解，进一步证明了该系统的有效性。", "innovation": "本文的创新之处在于提出了一种Agentic Design Review System (AgenticDRS)协作设计评估系统，利用代理技术实现设计的协作评估，并提出了一种基于图匹配的上下文示例选择方法以及一个独特的提示扩展方法，以使每个代理能够具体了解设计内容。此外，还提出了一套名为DRS-BENCH的基准测试，评估了该系统在评估图形设计和生成可操作反馈方面的有效性。", "conclusion": "本文验证了AgenticDRS在评估图形设计和生成可操作反馈方面的有效性，从而吸引更多的研究者关注这一具有良好现实应用价值但尚未充分研究的领域。"}
{"llm_update_time": "20250815", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.10703", "html_url": "https://arxiv.org/abs/2508.10703", "title": "GenOM：使用描述生成和大型语言模型的本体匹配", "title_en": "GenOM: Ontology Matching with Description Generation and Large Language Model", "authors": "Yiping Song,Jiaoyan Chen,Renate A. Schmidt", "background": "本体匹配 (OM) 起着关键作用，可以促进异构知识源之间的语义互操作性和集成，特别是在包含许多与疾病和药物相关复杂概念的生物医学领域。GenOM 是一种基于大语言模型 (LLM) 的本体对齐框架，利用生成文本定义来丰富本体概念的语义表示，通过嵌入式模型检索匹配候选，并结合精确匹配工具提高精度。", "innovation": "GenOM 提出了一个基于大语言模型的本体对齐框架，通过生成文本定义来丰富本体概念的语义表示，利用嵌入式模型检索匹配候选，并结合精确匹配工具提高精度。经过 OAEI 生物医学追踪任务的广泛实验，GenOM 可以与许多基线方法（包括传统的 OM 系统和最近的基于大语言模型的方法）实现竞争性能。", "conclusion": "消融研究证实了语义丰富和少量示例提示的有效性，突显了框架的稳健性和适应性。GenOM 在 OAEI 生物医学追踪任务上的广泛实验表明，它能够超越许多基线方法，包括传统的 OM 系统和近期的基于大语言模型的方法。"}
{"llm_update_time": "20250815", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.10599", "html_url": "https://arxiv.org/abs/2508.10599", "title": "MSRS: 自适应多子空间表示引导在大型语言模型属性对齐中的应用", "title_en": "MSRS: Adaptive Multi-Subspace Representation Steering for Attribute Alignment in Large Language Models", "authors": "Xinyan Jiang,Lin Zhang,Jiayi Zhang,Qingsong Yang,Guimin Hu,Di Wang,Lijie Hu", "background": "激活引导提供了一种有望控制大型语言模型行为的方法，通过直接操控其内部激活。然而，现有的大多数方法很难同时引导多种属性，往往导致干扰和不理想的权衡。", "innovation": "提出了多子空间表示引导(MSRS)这一新颖框架，通过子空间表示微调实现有效的多属性控制。MSRS通过为每个属性分配正交子空间来减少属性间干扰，隔离它们在模型表示空间中的影响。MSRS还融合了混合子空间组合策略：结合特定属性的子空间为独特的控制方向，共享子空间为共同的控制方向，并通过动态加权函数学习高效整合这些组件，实现精确控制。在推理过程中，MSRS引入了一种基于标记的引导机制，动态识别并干预具有最大语义相关性的标记，实现细粒度的行为调节。实验结果表明，MSRS显著减少了属性冲突，超越了现有方法，并有效泛化到各种下游任务中。", "conclusion": "MSRS显著减少了属性冲突，超越了现有方法，并且能够有效泛化到多种下游任务。"}
{"llm_update_time": "20250815", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.10806", "html_url": "https://arxiv.org/abs/2508.10806", "title": "谁从AI解释中受益？迈向无障碍且可解释的系统", "title_en": "Who Benefits from AI Explanations? Towards Accessible and Interpretable Systems", "authors": "Maria J. P. Peixoto,Akriti Pandey,Ahsan Zaman,Peter R. Lewis", "background": "随着人工智能系统在关键领域中越来越多地用于支持决策，可解释性已经成为提高这些输出理解性的手段，使用户能够做出更加知情和自觉的选择。然而，尽管对可解释性AI (XAI) 的可用性产生了极大的兴趣，但这些方法对于视障用户的可访问性仍然被忽视。本文通过两方面的研究方法探索了XAI的可访问性差距。", "innovation": "研究通过文献综述（分析79项研究）揭示了XAI技术评估中很少包含有障碍用户的情况，大多数解释依赖于内在视觉的形式。同时，该研究提出了一种四部分的方法论概念验证，以实现包容性XAI设计：（1）人工智能系统分类，（2）角色定义和情境化，（3）原型设计和实施，（4）专家和用户对XAI技术可访问性的评估。初步结果显示，简化解释比详细的解释更易于非视觉用户理解，而多模态呈现则是实现更公平解释所需的。", "conclusion": "简化解释对于非视觉用户而言更易于理解，而多模态呈现对于实现更公平的解释是必要的。"}
{"llm_update_time": "20250815", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.10747", "html_url": "https://arxiv.org/abs/2508.10747", "title": "在不遗忘目标的情况下扩展：面向RL的基于目标感知稀疏GNN的广义规划", "title_en": "Scaling Up without Fading Out: Goal-Aware Sparse GNN for RL-based Generalized Planning", "authors": "Sangwoo Jeon,Juchul Shin,Gyeong-Tae Kim,YeonJe Cho,Seongwoo Kim", "background": "使用深度强化学习（RL）结合图神经网络（GNNs）的通用规划在使用PDDL描述的各种符号规划领域中显示出有希望的结果。然而，现有的方法通常将规划状态表示为全连接图，这导致边信息的组合爆炸以及随着问题规模的增长，问题规模变得更大时，会呈现出严重的稀疏性，特别是在大型网格环境中尤为明显。这种密集的表示方式导致节点级别的信息被稀释，使内存需求呈指数级增加，并最终使得学习在大型问题上变得不可行。为了应对这些挑战，我们提出了一种稀疏、基于目标的GNN表示方法，该方法选择性地编码相关的局部关系，并显式地整合与目标相关的空间特征。我们通过在网格世界中基于PDDL设计新的无人机任务场景来验证这种方法，有效地模拟了现实中的任务执行环境。我们的实验证明，与密集图表示相比，我们的方法可以扩展到更大的网格规模，有效提高了策略泛化能力和成功率。我们研究的结果为应对现实中的大规模广义规划任务提供了实用的基础。", "innovation": "我们提出了一种基于目标感知的稀疏GNN表示方法，该方法选择性地编码了相关的局部关系，并显式地整合了与目标相关的空间特征，从而避免了密集图表示的稀疏性和内存需求暴增问题，使得在更大规模的问题上学习成为可能，进而提高了策略的泛化能力和成功率。", "conclusion": "我们的方法在扩展到更大的网格规模方面表现出色，比密集图表示法更为有效，同时显著提高了策略的一般泛化能力和成功率，为解决大规模实际广义规划任务提供了实用的基础。"}
{"llm_update_time": "20250815", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.10769", "html_url": "https://arxiv.org/abs/2508.10769", "title": "模拟能同时模态人工智能内容的人类响应", "title_en": "Modeling Human Responses to Multimodal AI Content", "authors": "Zhiqi Shen,Shaojing Fan,Danni Xu,Terence Sim,Mohan Kankanhalli", "background": "随着AI生成内容的普及，信息虚假的风险也日益增加。此前的研究主要集中在识别内容的真伪，而对AI生成内容如何影响人类感知和行为知之甚少。特别是在股票交易或金融市场中，预测人们如何反应（如一篇新闻文章是否会成为爆款）比验证其事实准确性更为关键。", "innovation": "作者提出了一种以人类为中心的方法，创建了MhAIM数据集，包含154,552条在线帖子（其中111,153条是AI生成的），以大规模分析人们对AI生成内容的反应。此外，提出了三种新的计量标准：可信度、影响度和开放度，用于量化用户评判和参与在线内容的方式。设计了T-Lens，这是一种基于LLM的代理系统，通过融入预测的人类响应来回答用户关于多模态信息的查询。其核心是HR-MCP（人类响应模型上下文协议），基于标准化的模型上下文协议（MCP），能够无缝集成到任何LLM中。这使得T-Lens能够更好地与人类反应对齐，增强解释性和交互性。", "conclusion": "该研究提供了一系列实践方法和工具，以使LLM具备人类意识能力。通过强调AI与人类认知和信息接收间的复杂互动，研究提出了减轻AI驱动虚假信息风险的可行策略。"}
{"llm_update_time": "20250815", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.10777", "html_url": "https://arxiv.org/abs/2508.10777", "title": "知识推理 dissociation: 临床自然语言推理中当前LLM的根本局限性", "title_en": "The Knowledge-Reasoning Dissociation: Fundamental Limitations of LLMs in Clinical Natural Language Inference", "authors": "Maël Jullien,Marco Valentino,André Freitas", "background": "大型语言模型通常被认为只需通过增加数据和参数的数量就能逐步获得越来越结构化和可泛化的内部表示。然而，本文通过对临床试验自然语言推理基准的分析，发现这一假设可能并不成立。基准包括四种推理类型：因果归因、组合接地、知识验证和风险状态抽离。研究通过Ground Knowledge和Meta-Level Reasoning Verification（GKMRV）探针来区分事实访问失败和推理失败，评估了六种现代语言模型在直接和链条式推理提示下的表现。模型在GKMRV任务上的准确率达到天花板水平，但主要推理任务上的表现却极为低下。然而，模型的输出推理在样本间高度一致，表明它们依赖于系统的启发式方法和捷径。这一研究揭示了当前LLM在结构和表示上的根本局限性：虽然它们通常拥有相关医疗知识，但在可靠地部署这些知识方面仍存在不足（如整合约束、权衡证据或模拟反事实情况），GKMRV方法有助于明确和测量这种分离，为在高风险领域探查LLM的可靠性提供了一个有效的框架。", "innovation": "通过引入Clinical Trial Natural Language Inference基准，并开发出了GKMRV探针来区分事实访问失败与推理失败，研究为理解LLM在高风险领域中的表现提供了一个新的视角。这种方法不仅揭示了当前LLM在结构化和表示上的局限性，也为后续研究提供了一个有效的框架，以便直接和系统地审查和测试LLM的表现。", "conclusion": "当前的大型语言模型在高风险的临床自然语言推理任务中表现出了基础的结构性和表示上的限制；尽管它们拥有相关的临床知识，但在可靠应用这些知识方面仍存在差距。需要进一步研究以发展更先进的LLM，使其能够更好地表达和应用结构性的知识进行可靠推理。"}
{"llm_update_time": "20250815", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.09992", "html_url": "https://arxiv.org/abs/2508.09992", "title": "OpenFPL: 一种 rivaling 状态最先进 Fantasy Premier League 服务的开源预测方法", "title_en": "OpenFPL: An open-source forecasting method rivaling state-of-the-art Fantasy Premier League services", "authors": "Daniel Groos", "background": "Fantasy Premier League 通过让足球社区在每周选定表现最佳的英超联赛球员。准确的绩效预测让参与者比竞争者更具优势，通过指导对球员结果的期望并减少挑选阵容时的不确定性。然而，现有的高精度预测主要由商业服务提供，这些服务的内部工作机制保密，并依赖于专有的数据。", "innovation": "OpenFPL 是一种仅基于公开数据开发的开源 Fantasy Premier League 预测方法。它包括针对 Fantasy Premier League 和 Understat 数据进行优化的位置特定集成模型，涵盖了四个之前的赛季（2020-21 到 2023-24）。OpenFPL 在测试中实现了与领先商业服务相媲美的精度。特别是在高获奖率球员（>2 分）方面，OpenFPL 超过了商业基准。该方法适用于一、二和三周的预测时间范围，支持长期转会和策略规划，同时也影响到最终决策。", "conclusion": "OpenFPL 在一、二和三周预测时间范围内均优于商业基准，支持长期规划和战术决策。"}
{"llm_update_time": "20250815", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.09991", "html_url": "https://arxiv.org/abs/2508.09991", "title": "跨领域技术整合的AI创新与医疗需求：BC癌症登记处引入现代NLP的经验教训", "title_en": "Bridging AI Innovation and Healthcare Needs: Lessons Learned from Incorporating Modern NLP at The BC Cancer Registry", "authors": "Lovedeep Gondara,Gregory Arbour,Raymond Ng,Jonathan Simkin,Shebnum Devji", "background": "医疗保健领域中从临床文档自动提取数据具有显著的提高效率的潜力，然而部署自然语言处理(NLP)解决方案存在实际挑战。基于在不列颠哥伦比亚癌症登记处(BCCR)的多项NLP模型应用经验，本文分享了项目生命周期中的关键经验教训。强调了基于清晰的业务目标而不是单纯的技术准确性定义问题的重要性，采用迭代开发方法，并从初期开始就通过跨学科协作与设计汇聚领域专家、最终用户及机器学习专家的专业知识。此外，还提到在模型选择上需保持实用性，包括使用混合方法和更简单的方法；数据质量（代表性、漂移、标注）的严格监控；构建组织的AI普及；以及构建人类在环的错误缓解策略和持续审计的重要性，这些都是突破自上而下的技术导向思维的关键因素。", "innovation": "项目中强调通过跨学科协作的方法进行迭代开发，以及强调在模型选择上考虑实用性（包括混合方法和简单的模型），数据质量的关注，以及构建组织的AI知识普及。这些做法有助于指导医疗保健组织成功实施AI/NLP解决方案以改进数据管理流程和最终提升患者护理和公共卫生结果。", "conclusion": "这些实用考虑方法不仅适用于癌症登记处，也为其他医疗保健组织在实施AI/NLP解决方案时提供指导，以增强数据管理流程并最终改善患者护理和公共卫生结果。"}
{"llm_update_time": "20250815", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.09636", "html_url": "https://arxiv.org/abs/2508.09636", "title": "个性化产品搜索排名：结合表结构和非表结构数据的多任务学习方法", "title_en": "Personalized Product Search Ranking: A Multi-Task Learning Approach with Tabular and Non-Tabular Data", "authors": "Lalitesh Morishetti,Abhay Kumar,Jonathan Scott,Kaushiki Nag,Gunjan Sharma,Shanu Vashishtha,Rahul Sridhar,Rohit Chatter,Kannan Achan", "background": "本文在现有的个性化产品搜索排名优化中提出了一个新颖的模型架构。研究背景在于当前搜索排名优化方法在处理表结构和非表结构数据时存在不足，特别是在多任务学习框架下的表现。本文针对这个问题，提出了一种结合表结构和非表结构数据的多任务学习方法，旨在优化个性化产品搜索排名，并提升现有模型的处理能力。", "innovation": "本文的创新点在于提出了一个新颖的模型架构，该架构通过多任务学习框架结合了表结构和非表结构数据，并利用预训练的TinyBERT模型构建语义嵌入，同时引入了一种新的采样技术来捕捉多样化的顾客行为。此外，还提出了一种基于点击率、点击位置和语义相似性的可扩展的相关性标注机制，作为传统的人工标注的替代方案。实验结果表明，这种结合非表数据和高级嵌入技术的方法在多任务学习框架中显著提高了模型性能。", "conclusion": "通过实验结果，本研究证明了结合非表数据和高级嵌入技术的方法在多任务学习框架中的有效性，并强调了引入相关性标签、微调TinyBERT层以及TinyBERT查询-产品嵌入交互的重要性。这些结果表明了本文提出的方法在个性化产品搜索排名中的有效性。"}
{"llm_update_time": "20250815", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.10001", "html_url": "https://arxiv.org/abs/2508.10001", "title": "HiFACTMix: 在哈林吉语中基于证据的政治声明验证的一种代码混合基准和图感知模型", "title_en": "HiFACTMix: A Code-Mixed Benchmark and Graph-Aware Model for EvidenceBased Political Claim Verification in Hinglish", "authors": "Rakesh Thakur,Sneha Sharma,Gauri Chopra", "background": "当前代码混合、低资源语言如哈林吉语（Hinglish）的真实性验证仍是一个未被充分探索的挑战。现有的事实验证系统主要集中在高资源、单一语言的设置上，而无法很好地应用于语言多样性的地区如印度的政治话语。鉴于公共人物尤其是政治人物广泛使用哈林吉语以及社交媒体对公众意见的日益影响，对多语言、上下文感知的事实验证工具的需求变得尤为迫切。为了应对这一差距，研究引入了HiFACT数据集，该数据集包含1,500条真实的政治断言，由28位印度邦首席部长用哈林吉语提出，处于一个高度代码混合和低资源的环境下。每条断言都标注了文本证据和真实性标签。", "innovation": "研究提出了一种新型的图感知、检索增强的事实验证模型HiFACTMix，该模型结合了多语言上下文编码、断言证据语义对齐、证据图构建、图神经推理和自然语言解释生成。实验结果显示，HiFACTMix在与现有最先进的多语言基线模型比较时，表现出了更高的准确性，并能够为验证结果提供可靠的解释。这项工作开启了多语言、代码混合和政治导向的事实验证研究的新方向。", "conclusion": "研究通过引入HiFACT数据集和提出HiFACTMix模型，为哈林吉语中基于证据的政治声明验证提供了新的解决方案，能够在代码混合、低资源的语言环境中有效进行事实验证，并为多语言真实验证领域的研究打开了新的方向。"}
{"llm_update_time": "20250815", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.10003", "html_url": "https://arxiv.org/abs/2508.10003", "title": "大型语言模型嵌入中的语义结构", "title_en": "Semantic Structure in Large Language Model Embeddings", "authors": "Austin C. Kozlowski,Callin Dai,Andrei Boutyline", "background": "心理研究发现人类对不同语义维度的词语评分可以被简化为低维度的形式。此外，大型语言模型（LLMs）中的词嵌入矩阵也显示了相似的结构。研究发现，这些嵌入向量在定义好的反义词方向上的投影与人类评级高度相关，并且这些投影几乎可以在3维子空间内有效简化，与人类调查反应中的模式十分相似。进一步地，通过沿某一语义方向调整词汇会引发与其余特征的余弦相似度成比例的目标外效应。这些发现表明，语义特征在LLMs中的纠缠方式与人类语言中的相互连接相似，尽管看似复杂，但大量的语义信息实际上是非常低维度的。因此，考虑这种语义结构对于避免改变特征时的意外后果至关重要。", "innovation": "本研究发现大型语言模型中的嵌入向量在定义好的反义词方向上呈现出高度相关的投影，并且这些投影可以有效简化为3维子空间。此外，通过改变词汇在这些方向上的位置会引发与其余语义特征成比例的目标外效应。这些发现揭示了大型语言模型中的语义结构与人类语言的相似性，表明尽管表面上看起来复杂，但大量的语义信息实际上是低维度的。", "conclusion": "大型语言模型中的语义信息是低维度的，考虑这种语义结构在调整模型特征时非常重要，以避免意外后果。"}
{"llm_update_time": "20250815", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.10009", "html_url": "https://arxiv.org/abs/2508.10009", "title": "超越硬共享：带有监督混合专家的高效多任务语音转文本建模", "title_en": "Beyond Hard Sharing: Efficient Multi-Task Speech-to-Text Modeling with Supervised Mixture of Experts", "authors": "Hojun Jin,Eunsoo Hong,Ziwon Hyung,Sungjun Lim,Seungjin Lee,Keunseok Cho", "background": "共同策略是通过共享参数同时训练单个模型以执行多种任务。然而，这种方式常常导致任务之间的干扰，阻碍了模型的整体性能。", "innovation": "提出了一种简单而有效的监督混合专家（S-MoE）。与传统的混合专家模型不同，S-MoE 通过使用特殊的引导标记来路由每个任务到其对应的专家，而无需训练门控函数。将每个任务分配给单独的前馈网络，从而克服了硬参数共享的限制。", "conclusion": "将 S-MoE 应用于语音转文本模型，使其能够处理不同带宽的输入并同时执行自动语音识别 (ASR) 和语音翻译 (ST)。实验结果表明，S-MoE 的有效性，与编码器和解码器结合使用时，相对于错误率 (WER) 的改进幅度为 6.35%。"}
{"llm_update_time": "20250815", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.10005", "html_url": "https://arxiv.org/abs/2508.10005", "title": "从答案到问题：EQGBench 用于评估 LLMs 的教育性问题生成", "title_en": "From Answers to Questions: EQGBench for Evaluating LLMs' Educational Question Generation", "authors": "Chengliang Zhou,Mei Wang,Ting Zhang,Qiannan Zhu,Jian Li,Hua Huang", "background": "大语言模型 (LLMs) 在数学问题解决方面展现出卓越的能力，但在从提供答案转向生成高质量教育性问题方面存在显著挑战。EQGBench 是一个专门为评估 LLMs 在中国教育性问题生成 (EQG) 中表现而设计的全面基准。它提出了一个包含五个维度的评价框架，并使用涵盖了数学、物理和化学三个基础中学学科的 900 个评估样本的数据集，这些样本包含不同知识点、难度和问题类型的用户查询，以模拟真实的教育场景。", "innovation": "EQGBench 建立了一个五维度的评价框架，涵盖了数学、物理和化学三个学科的 900 个评估样本，通过系统评估 46 个主流大型模型，揭示了生成反映教育价值问题并促进学生综合能力发展的巨大发展空间。", "conclusion": "研究通过系统性评估 46 个主流大型模型，发现他们在生成教育上有价值的问题并促进学生全面发展方面还有很大的提升空间，EQGBench 基准为更全面地评估 LLMs 在教育性问题生成方面的表现提供了一个有力的工具。"}
{"llm_update_time": "20250815", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.10019", "html_url": "https://arxiv.org/abs/2508.10019", "title": "通过问题空间映射解耦理解与推理的框架以增强小型模型的推理能力", "title_en": "Decoupling Understanding from Reasoning via Problem Space Mapping for Small-scale Model Reasoning", "authors": "Li Wang,Changhao Zhang,Zengqi Xiu,Kai Lu,Xin Yu,Kui Zhang,Wenjun Wu", "background": "尽管大型语言模型（LLMs）在推理能力方面取得了进展，但提高小型语言模型（SLMs，例如≤1.5B）的推理能力仍然具有挑战性。这一挑战主要源于自然语言的高度复杂性和多样性：实质上相同的问题通常以多种不同的表面形式出现，受到冗余或分散注意力细节的干扰。这给SLMs带来了双重负担：它们首先需要从复杂的语言输入中提取核心问题，然后基于该理解进行推理。大规模的和嘈杂的问题空间限制了模型优化，尤其是那些能力有限的模型。目前，SLMs需要同时处理理解和推理两个过程，增加了优化的难度。", "innovation": "本文提出了一个新的框架，通过将自然语言问题映射到规范的问题空间来解耦理解和推理，该规范空间是语义简化但表达性强的领域。该框架包括一个逐步算法DURIT（Decoupled Understanding from Reasoning via Iterative Training），该算法通过增强学习逐步将自然语言问题映射到规范空间，通过自我蒸馏对推理轨迹进行对齐，并在问题空间中训练推理策略。在这个过程中，理解和推理模块交替训练。实验结果表明，DURIT显著提升了SLMs在领域内和领域外数学和逻辑推理任务上的表现。同时，DURIT还增强了推理的鲁棒性，证明了解耦理解与推理是一种有效强化SLMs的策略。", "conclusion": "DURIT显著提升了小型语言模型在数学和逻辑推理任务中的推理能力，同时也增强了推理的鲁棒性，验证了解耦理解与推理作为强化小型语言模型的有效策略。"}
{"llm_update_time": "20250815", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.10004", "html_url": "https://arxiv.org/abs/2508.10004", "title": "用户对注意力可视化感知：解释医学文献的可解释性影响", "title_en": "User Perception of Attention Visualizations: Effects on Interpretability Across Evidence-Based Medical Documents", "authors": "Andrés Carvallo,Denis Parra,Peter Brusilovsky,Hernan Valdivieso,Gabriel Rada,Ivania Donoso,Vladimir Araujo", "background": "注意力机制是Transformer架构的核心组件，可以提高模型性能。此外，注意力机制还被提出作为一种通过注意力权重实现可解释性的方法，注意力权重与输入特征（如文档中的标记）相关，较大的注意力权重可能意味着对模型预测更相关的特征。在循证医学中，这种解释可以支持医生对AI系统的理解和互动，用于分类生物医药文献。然而，目前尚无共识认为注意力权重提供了有帮助的解释，且很少有研究探讨可视化注意力如何影响其作为解释工具的有效性。鉴于此，作者进行了用户研究以评估注意力基解释在生物医药文献分类中的支持作用，以及不同可视化形式的影响差异。参与者为来自不同学科的医学专家，他们根据研究设计（如系统评价、综合分析、随机和非随机试验）分类文章。研究发现Transformer模型（XLNet）能够准确分类文档，但注意力权重并不被认为在解释预测中特别有帮助，这取决于如何可视化注意力。这与Munzner的有效可视化原则相悖，该原则倾向于精确编码，如条形长度，但用户更偏好直观的格式，如文本亮度或背景颜色。", "innovation": "本文通过用户研究评估了注意力基解释在生物医药文献分类中的支持作用及不同可视化形式的影响差异。研究表明，尽管Transformer模型能够准确分类文档，但注意力权重并不被认为特别有帮助，且其有效性受可视化方式的影响显著，这挑战了Munzner的有效可视化原则，提出了新的可视化偏好模式。", "conclusion": "研究结果显示，Transformer模型（XLNet）能够准确分类文档，但注意力权重并不被认为特别有帮助，这取决于注意力的可视化方式。用户更偏好直观的可视化形式（如文本亮度或背景颜色），而不是精确编码形式（如条形长度）。这些结果表明，注意力权重作为解释工具的有效性尚未得到确认，但其感知的有效性受到可视化方式的影响。"}
{"llm_update_time": "20250815", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.10021", "html_url": "https://arxiv.org/abs/2508.10021", "title": "LATTE：银行客户对账和文本嵌入的学习对齐", "title_en": "LATTE: Learning Aligned Transactions and Textual Embeddings for Bank Clients", "authors": "Egor Fadeev,Dzhambulat Mollaev,Aleksei Shestov,Dima Korolev,Omar Zoloev,Ivan Kireev,Andrey Savchenko,Maksim Makarenko", "background": "在金融应用中，从客户历史沟通序列中学习客户嵌入至关重要。尽管大型语言模型（LLMs）提供了广泛的世界知识，但在实时流程中直接处理长时间序列事件是计算上昂贵的且不实际。主流处理方式是对完整序列进行处理，这增加了计算成本和输入大小。为此，有必要开发一个能够有效处理客户通信序列的方法，同时保持在对延迟敏感的环境中的可部署性。", "innovation": "本文提出了一种 Contrastive 学习框架 LATTE，该框架通过冻结的 LLM 生成的语义嵌入对齐原始事件嵌入。行为特征被总结为简短的提示，通过 LLM 进行嵌入，并通过对比损失进行监督。这种方法相比传统对完整序列的处理具有显著降低的推理成本和较小的输入大小，同时在真实的金融数据集上优于最先进的技术，保持了对延迟敏感环境的可部署性。", "conclusion": "通过实验表明，LATTE 方法在实际金融数据集上优于现有最先进的技术，同时保持在对延迟敏感的环境中的可部署性，显著降低了推理成本和输入大小。"}
{"llm_update_time": "20250815", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.10024", "html_url": "https://arxiv.org/abs/2508.10024", "title": "RTTC: 奖励引导的协作式测试时计算", "title_en": "RTTC: Reward-Guided Collaborative Test-Time Compute", "authors": "J. Pablo Muñoz,Jinjie Yuan", "background": "Test-Time Compute (TTC) 已成为增强大型语言模型 (LLMs) 推断性能的强大范式，利用诸如 Test-Time Training (TTT) 和 Retrieval-Augmented Generation (RAG) 等策略。尽管如此，最优的适应策略在不同查询中有所变化，盲目应用 TTC 策略会产生大量的计算开销。", "innovation": "引入了 Reward-Guided Test-Time Compute (RTTC)，这是一种新型框架，通过预训练的奖励模型为每个查询选择最有效的 TTC 策略，从而在不同领域和任务中最大化下游准确率。RTTC 运行在分布式服务器-客户端架构中，从远程知识库检索相关样本，在客户端设备上仅当必要时应用 RAG 或轻量级微调。为了进一步减少冗余计算，提出了查询状态缓存，能够在检索和适应级别上高效地复用历史查询状态。", "conclusion": "跨多个 LLMs 和基准的广泛实验表明，RTTC 一致地优于传统的 RAG 或 TTT，验证了适应性和奖励引导的 TTC 选择的必要性以及 RTTC 在可扩展、高性能语言模型适应方面的潜力。"}
{"llm_update_time": "20250815", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.10025", "html_url": "https://arxiv.org/abs/2508.10025", "title": "使用生成式人工智能实时检测并解释产后抑郁", "title_en": "Detecting and explaining postpartum depression in real-time with generative artificial intelligence", "authors": "Silvia García-Méndez,Francisco de Arriba-Pérez", "background": "产后抑郁（PPD）是新产妇面临的一个严重问题，严重影响其身心健康。因此，快速检测PPD及其相关风险因素，以便进行及时评估与干预，对预防和治疗至关重要。", "innovation": "本文介绍了一种智能PPD筛查系统，结合了自然语言处理（NLP）、机器学习（ML）和大型语言模型（LLMs），用于实现实时语音分析筛查和治疗建议。此外，本文解决了模型的「黑匣子」问题，通过LLMs与解释性机器学习模型（如树状算法）结合，使得预测结果对终端用户可解释，基于特征重要性和自然语言描述。", "conclusion": "实验结果显示，该方法在PPD检测上达到90%的准确率，超过了文献中竞争对手的解决方案。最终，本文的解决方案有助于快速检测PPD及其风险因素，这对于及时和正确的评估与干预至关重要。"}
{"llm_update_time": "20250815", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.10022", "html_url": "https://arxiv.org/abs/2508.10022", "title": "在证明风险控制的多项选择题作答任务中使用符合性p值", "title_en": "Conformal P-Value in Multiple-Choice Question Answering Tasks with Provable Risk Control", "authors": "Yuanchang Ye", "background": "大规模语言模型（LLMs）在学科问答场景中的应用日益增多，但模型的幻觉和不属实生成严重影响了响应的可靠性。虽然符合性预测（CP）提供了统计上严谨的边缘覆盖保证，而显著性检验则提供了成熟的统计严谨性，但它们的协同整合尚未被探索。研究背景在于现有方法未能有效解决LLMs的黑箱问题和事实性不准确的问题，本文旨在引入一种新的方法来增强LLMs在多项选择题作答任务中的可信度。", "innovation": "本文创新地提出了一种通过将显著性检验与一致性评分结合的方式增强符合性预测框架的方法。该方法通过自一致性采样MCQA响应来计算选项频率，进一步使用空假设检验（$\textbf{H}_0$）和实证得出的p值构建预测集。这种结合显著性检验的方法有效解决了LLMs的黑箱性质，并通过实验证明了平均预测集大小可用作有效的不确定性度量。", "conclusion": "研究通过MMLU和MMLU-Pro基准评估了该方法，表明增强后的CP能够实现用户指定的经验错误覆盖率，并且随着风险水平的增加，平均预测集大小呈现单调下降趋势，验证了该方法在高风险QA应用中的有效性。这项工作为大规模语言模型在高风险问答应用中的可靠部署提供了一个严谨的统计框架。"}
{"llm_update_time": "20250815", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.10017", "html_url": "https://arxiv.org/abs/2508.10017", "title": "使用SMOTETomek和FedProx在不平衡临床数据上实现差异隐私联邦学习的稳健管道", "title_en": "A Robust Pipeline for Differentially Private Federated Learning on Imbalanced Clinical Data using SMOTETomek and FedProx", "authors": "Rodrigo Tertulino", "background": "联邦学习 (FL) 为协作健康研究提供了创新的方法，能够对去中心化的数据进行模型训练的同时保护患者隐私。该技术结合差异隐私 (DP) 可以提供形式上的安全保证。然而，在面对医学数据中常见的类别不平衡问题时，FL 和 DP 的集成引入了隐私和临床实用性之间的显著权衡。本文通过系统化的多阶段分析，针对心血管风险预测问题，探讨了如何在保证隐私的同时提高临床效用。早期实验显示，标准方法难以处理类别不平衡的情况，导致召回率归零。为了解决这一问题，本文提出了利用 SMOTETomek 增量法和调参后的 FedProx 算法来优化FL框架，在非独立同分布 (non-IID) 数据上实现了有效的诊断模型。研究表明，在隐私预算 (epsilon) 和模型召回率之间存在非线性权衡，并且优化后的 FedProx 在所有情况下都优于标准的 FedAvg，通过调优后的 FedProx 可以既确保强隐私保证又能保持高效临床效用。", "innovation": "本文提出了一个利用 SMOTETomek 和 FedProx 算法优化的联邦学习框架，有效解决了在不平衡临床数据上实现差异隐私联邦学习的关键挑战。这种结合方法在处理类别不平衡和优化隐私-临床实用性之间的权衡方面展现了重要创新性。通过这种方法，研究人员能够在确保患者隐私的同时创建出具有高临床效用的诊断模型。这项研究为构建有效且安全的诊断工具提供了实用的方法论指南，适用于现实世界中的异质医疗数据。", "conclusion": "本研究通过系统化的多阶段分析和调优的联邦学习框架, 在平衡和优化临床数据隐私与临床效能之间取得明显进展。在优化后的 FedProx 下，既实现了较好的隐私保护(epsilon 9.0)又保持了高临床效用(召回率大于77%)。这些成果提供了在医疗保健数据中创建实际、安全和准确的诊断工具的应用方案，是向前迈出的重要一步。"}
{"llm_update_time": "20250815", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.10018", "html_url": "https://arxiv.org/abs/2508.10018", "title": "不同名称的玫瑰同样芳香：大型语言模型的范畴同伦理论", "title_en": "A Rose by Any Other Name Would Smell as Sweet: Categorical Homotopy Theory for Large Language Models", "authors": "Sridhar Mahadevan", "background": "自然语言中存在意义相同但表象不同的陈述，如“Charles Darwin wrote”和“Charles Darwin is the author of”等，这些陈述通常应由大规模语言模型（LLMs）生成相同的下一个词概率，但实际上却不会。现有的经验性解决办法，如使用k-NN估计句子相似度来产生平滑估计，也不能完全解决这一问题，因为语言中充斥着等效的改述，导致在LLMs范畴马尔可夫类别中生成非同构的箭头。", "innovation": "提出了一种范畴同伦理论框架，通过这样一种方法，可以捕捉一族属于LLMs范畴马尔可夫类别的“弱同伦”。这项工作涵盖了从高阶代数K理论到模型范畴的范畴同伦理论在LLMs中的应用，基于过去半个世纪中发展起来的强有力理论成果。", "conclusion": "通过范畴同伦理论，该研究旨在解决大规模语言模型生成等效改述时未列明的问题，为这些模型提供了理论基础，使其能够更准确地理解语言的等价关系。"}
{"llm_update_time": "20250815", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.10027", "html_url": "https://arxiv.org/abs/2508.10027", "title": "LLMCARE：通过LLM生成的合成数据增强的Transformer模型进行阿尔茨海默病检测", "title_en": "LLMCARE: Alzheimer's Detection via Transformer Models Enhanced by LLM-Generated Synthetic Data", "authors": "Ali Zolnour,Hossein Azadmaleki,Yasaman Haghbin,Fatemeh Taherinezhad,Mohamad Javad Momeni Nezhad,Sina Rashidi,Masoud Khani,AmirSajjad Taleban,Samin Mahdizadeh Sani,Maryam Dadkhah,James M. Noble,Suzanne Bakken,Yadollah Yaghoobzadeh,Abdol-Hossein Vahabie,Masoud Rouhizadeh,Maryam Zolnoori", "background": "目前阿尔茨海默病及相关痴呆症(ADRD)影响约500万美国老年人，但超过一半的人未被诊断。使用基于语言的自然语言处理(NLP)技术来检测语言标志中的早期认知衰退具有潜在的广泛应用价值。", "innovation": "开发并评估了一种筛查流程，该流程(i)结合了变压器嵌入和手工构建的语言特征，(ii)使用大型语言模型（LLMs）生成的合成语音进行数据增强测试，(iii)对单一模态和多模态LLM分类器进行基准测试，以用于ADRD检测。该研究使用了237份“cookie-theft”任务的转录数据，结合了表现最佳的变压器模型和110个词源提取的语言特征模型。对5种LLMs进行了微调以生成标注条件化的合成语音，以此来增强训练数据。多模态模型的测试确认了增强数据的优秀表现，以及微调显著提升了单一模态LLM分类器的表现。", "conclusion": "结合变压器嵌入和语言特征可以增强ADRD的语音检测能力。临床调优的LLMs在分类和数据增强方面发挥了有效作用，但多模态模型仍有需进一步改进的空间。"}
{"llm_update_time": "20250815", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.10029", "html_url": "https://arxiv.org/abs/2508.10029", "title": "Latent Fusion Jailbreak: Blending Harmful and Harmless Representations to Elicit Unsafe LLM Outputs", "title_en": "Latent Fusion Jailbreak: Blending Harmful and Harmless Representations to Elicit Unsafe LLM Outputs", "authors": "Wenpeng Xing,Mohan Li,Chunqiang Hu,Haitao XuNingyu Zhang,Bo Lin,Meng Han", "background": "大型语言模型（LLMs）在多种语言任务中表现出色，但在安全方面仍存在风险，容易受到规避安全校准的监狱突破攻击。这些攻击利用模型的潜在缺陷，诱使其生成不受限制的回答。", "innovation": "该论文提出了Latent Fusion Jailbreak（LFJ）攻击，这是一种基于表示的攻击方法，通过混合有害和无害查询对的隐藏状态来触发禁止的回应。LFJ 通过选择具有高主题和句法相似度的查询对，利用梯度引导的插值技术，在关键层和标记上进行插值，并优化攻击成功率、输出流畅性和计算效率之间的平衡。", "conclusion": "LFJ在Vicuna和LLaMA-2模型上取得94.01%的平均攻击成功率，优于现有方法。为了对抗LFJ，提出了对抗性训练防御方法，通过微调模型实现插值示例，将攻击成功率降低超过80%而不影响良性输入的性能。消除研究验证了查询对选择、隐藏状态插值组件和优化策略在LFJ效果中的重要性。"}
{"llm_update_time": "20250815", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.10028", "html_url": "https://arxiv.org/abs/2508.10028", "title": "PREF：大型语言模型中个性化解码生成的参考无关评估", "title_en": "PREF: Reference-Free Evaluation of Personalised Text Generation in LLMs", "authors": "Xiao Fu,Hossein A. Rahmani,Bin Wu,Jerome Ramos,Emine Yilmaz,Aldo Lipani", "background": "个性化解码生成对用户为中心的信息系统至关重要，但大多数评估方法忽略了用户的个人差异。现有的评估方法通常依赖金标准的个性化参考，这可能不适合所有用户需求。因此，需要一种新的评估框架来全面衡量输出质量并实现个体用户的具体一致性，而不需要预设的个性化标准，从而提高评估的准确性和可靠性，确保个性化解码生成系统的评估更加可靠和可信。", "innovation": "PREF是一种参考无关评估框架，旨在逐步衡量一般输出质量和用户特定的对齐，而不需要预设的个性化标准。PREF的创新在于将其分为三个阶段：涵盖阶段，偏好阶段和评分阶段。这三个阶段通过一个大规模语言模型（LLM）来生成全面且查询特定的指南，然后根据目标用户的情感、偏好和上下文进行重新排序和选择性增强，形成个性化的评估标准，最后通过LLM裁判应用评分规则来评估候选答案。这种方法提高了评估的鲁棒性、透明度和重用性，使小模型能够模拟大模型的个性化质量。实验证明PREF在评估准确性、校准性以及与人类判断的一致性上优于现有的基准模型。", "conclusion": "通过这种可扩展、可解释和用户对齐的评估框架，PREF为个性化语言生成系统的可靠评估和开发奠定了基础。"}
{"llm_update_time": "20250815", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.10032", "html_url": "https://arxiv.org/abs/2508.10032", "title": "思考的成本：大型语言模型中增加的破解风险", "title_en": "The Cost of Thinking: Increased Jailbreak Risk in Large Language Models", "authors": "Fan Yang", "background": "一直认为思考模式是LLM中最宝贵的模式之一。然而，研究发现，具有思考模式的LLM更容易受到Jailbreak攻击。通过对9个LLM进行AdvBench和HarmBench评估，发现攻击思考模式的成功率几乎高于非思考模式。进一步的研究表明，具有教育目的和思考长度过长是被成功攻击的数据的特征，即使LLM大部分知道这些问题有害，它们仍然会给出有害的回答。", "innovation": "为了缓解上述问题，本文提出了一种安全思考干预方法，通过在提示中添加'LLM特定思考令牌'来明确引导LLM的内部思考过程。这一方法显著降低了具有思考模式的LLM的攻击成功率。", "conclusion": "实验结果表明，通过安全思考干预，可以显著降低具有思考模式的LLM的攻击成功率。"}
{"llm_update_time": "20250815", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.10020", "html_url": "https://arxiv.org/abs/2508.10020", "title": "FedCoT: 通信高效的联邦推理增强技术用于大型语言模型", "title_en": "FedCoT: Communication-Efficient Federated Reasoning Enhancement for Large Language Models", "authors": "Chuan Li,Qianyi Zhao,Fengran Mo,Cen Chen", "background": "在联邦学习环境中有效增强大型语言模型（LLMs）的推理能力仍然是一个挑战，尤其是在平衡性能提升与严格的计算、通信和隐私限制时。在医疗领域，决策不仅需要准确的输出，还需要清晰可追踪的推理过程，以确保安全、问责和合规。传统的联邦调优方法未能满足这一需求：它们主要侧重于答案的准确性，而忽视了推理质量，导致CoT能力依赖于模型的预训练能力。此外，现有方法通常依赖于中央模型的隐私泄露知识蒸馏来改进推理，且传统联邦微调的通信开销较大。", "innovation": "我们通过提出FedCoT，一种新的框架来专门提升联邦设置中的推理能力。FedCoT利用一种轻量级的链式思考增强机制：本地模型生成多种推理路径，并通过紧凑型鉴别器动态选择最有可能的路径。这种方法提高了推理准确性和稳健性，同时提供了有价值的解释能力，这对医疗应用尤其重要。为了高效管理客户端异质性，我们采用了改进的聚合方法，基于先进的LoRA模块堆叠，并结合客户端分类器意识以实现跨不同客户端的无噪声聚合。", "conclusion": "FedCoT在严格的资源预算下显著提高了客户端侧的推理性能，同时完全保护了数据隐私。综合实验在医疗推理任务上验证了这一点。"}
{"llm_update_time": "20250815", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.10030", "html_url": "https://arxiv.org/abs/2508.10030", "title": "针对黑盒大型语言模型进行推理意识的指令优化", "title_en": "Inference-Aware Prompt Optimization for Aligning Black-Box Large Language Models", "authors": "Saaduddin Mahmud,Mason Nakamura,Kyle H. Wray,Shlomo Zilberstein", "background": "现有研究已经证明，通过优化提示可以在很大程度上使黑盒大型语言模型（LLM）与用户的意图保持一致。同时，如Best-of-N和多数投票等推理扩展策略也被证明可以通过计算成本的付出提高一致性和性能。然而，现有的提示优化方法并不考虑具体的推理策略，这对模型部署实际应用中构成了一定障碍，因为在不同的推理策略下，最佳的提示和推理配置会发生变化。研究者发现，用户在多个目标和推理预算间的权衡偏好对最优提示和推理配置的选择有着重要的影响。因此，当前的方法存在一个重要的方法学缺口，需要一种同时优化提示和推理规模的方法。", "innovation": "本文提出了名为IAPO（推理意识提示优化）的新型统一框架，它能够同时优化提示和推理比例，并且考虑到推理预算和不同的任务目标；并且开发了一种用于IAPO的固定预算训练算法PSST（提示尺度通过逐序修剪），并分析了预算有限情况下的错误概率保证。该方法在六种不同任务中被评估，研究表明，在提示优化过程中融入推理意识对黑盒大语言模型的对齐工作至关重要。", "conclusion": "本文提出了IAPO框架，这是一种推理感知的提示优化方法，能够同时优化提示和推理规模，并且考虑推理预算及不同的任务目标。通过PSST算法，在特定预算下实现了对误差概率的有效控制，并在多个任务中展示了其有效性和关键作用。"}
{"llm_update_time": "20250815", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.10026", "html_url": "https://arxiv.org/abs/2508.10026", "title": "SABER: Switchable and Balanced Training for Efficient LLM Reasoning", "title_en": "SABER: Switchable and Balanced Training for Efficient LLM Reasoning", "authors": "Kai Zhao,Yanjun Zhao,Jiaming Song,Shien He,Lusheng Zhang,Qiang Zhang,Tianjiao Li", "background": "大规模语言模型（LLMs）通过链式推理能够实现复杂的任务的高度准确率，但应用到所有问题时导致推理成本过高和延迟增加。如何在保证准确性的前提下控制和优化推理成本成为亟待解决的问题。", "innovation": "SABER框架引入了一种可由用户控制且基于tokens预算的推理机制，首先通过预训练阶段对每个训练样本的基础模型计算推理tokens使用情况并划分到不同的预算层级，然后在微调过程中通过系统提示和长度感知奖励指导模型遵循其分配的预算。此外，SABER还支持四种不同的推理模式：NoThink、FastThink、CoreThink和DeepThink，实现了推理时间和推理深度之间的灵活权衡。", "conclusion": "在数学推理、代码生成和逻辑推理等多个领域的广泛评估中，SABER在保持较高准确率的同时，展现了紧凑预算下的优雅退化以及跨尺度和跨领域的有效泛化能力。特别是在MATH基准测试中，SABER-FastThink将推理长度减少了65.4%，并获得了比基准模型高出3.6%的准确性。"}
{"llm_update_time": "20250815", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.10033", "html_url": "https://arxiv.org/abs/2508.10033", "title": "认知人工智能中的认知安全：基于CCS-7的护栏工程", "title_en": "Cognitive Cybersecurity for Artificial Intelligence: Guardrail Engineering with CCS-7", "authors": "Yuksel Aydin", "background": "语言模型表现出类似人类的认知脆弱性，如情绪框架效应等，这些特征超出了传统行为对齐模型的范围。现有的研究证明，人类在提升认知安全方面有一定的潜力，但不同的人工智能模型在应对这些脆弱性的方式上存在差异。本文探讨了这种差异，并提出了一种新的测试方案以确保不同模型在部署前的认知安全性。", "innovation": "本文提出了CCS-7（认知网络安全套件），这是一种基于人类认知安全研究的七大脆弱性分类体系。通过一项随机对照试验，研究了‘先思考，后验证’（TFVA）课程对人类的认知安全改进效果，并在7种不同的语言模型架构上进行了12,180次实验，以评估不同的防护栏方案的有效性。研究成果揭示了不同基础架构在应对某些类型的脆弱性时效果不同，甚至会带来反效果。这种研究为认知安全提供了一种模型特定的工程解决方案，强调在部署之前需要进行针对不同模型的认知安全测试。", "conclusion": "认知安全是一个模型特定的工程问题，有效的干预措施在不同模型中可能会失败或带来反效果，因此在部署人工智能模型前，需要进行架构意识的认知安全测试。"}
{"llm_update_time": "20250815", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.10042", "html_url": "https://arxiv.org/abs/2508.10042", "title": "FIDELIS：区块链驱动的联邦学习中毒攻击防护", "title_en": "FIDELIS: Blockchain-Enabled Protection Against Poisoning Attacks in Federated Learning", "authors": "Jane Carney,Kushal Upreti,Gaby G. Dagher,Tim Andersen", "background": "联邦学习通过利用物联网设备的私有数据来增强传统的深度学习，确保了客户端的隐私，但在训练过程中容易受到数据中毒攻击，这些攻击会降低模型性能和完整性。当前的中毒检测方法缺乏标准化方法，或者在信任上有明显偏差。", "innovation": "提出了Sys，一种基于区块链的联邦学习中的数据中毒检测框架。该框架分散了全局服务器的角色，由每个客户端生成法官模型并达成共识以确定单一法官模型。由此表明，Sys对数据中毒攻击具有鲁棒性，且生成法官模型具有可扩展性。", "conclusion": "通过实现Sys解决方案，证明了该框架能够抵御数据中毒攻击，并且法官模型的生成是可扩展的。"}
{"llm_update_time": "20250815", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.10039", "html_url": "https://arxiv.org/abs/2508.10039", "title": "针对少量查询情况下的黑盒模型多任务对抗攻击", "title_en": "Multi-task Adversarial Attacks against Black-box Model with Few-shot Queries", "authors": "Wenqiang Wang,Yan Xiao,Hao Lin,Yangshijie Zhang,Xiaochun Cao", "background": "当前的多任务对抗文本攻击依赖于共享内部特征的丰富访问和大量查询，通常局限于单一任务类型。这使得这些攻击在面对黑盒反馈API、有限查询或多个任务类型的实际场景时效果不佳。", "innovation": "提出了Cluster and Ensemble Multi-task Text Adversarial Attack (CEMA)，这是一种有效的黑盒攻击，利用不同任务之间的对抗文本可转移性。CEMA通过使用插件即用的深度级替代模型简化多任务场景，这种方法只需少量查询即可训练，将多任务攻击转化为分类攻击，并允许跨任务的攻击。", "conclusion": "CEMA在涉及两个、三个或六个任务（分类、翻译、总结和文本到图像生成）的多任务模型中，仅用数百个查询即可实现显著的攻击成功。此外，CEMA可以针对商业API（如百度和谷歌翻译）、大型语言模型（如ChatGPT 4）和图像生成模型（如Stable Diffusion V2），展示了其在实际应用中的灵活性和有效性。"}
{"llm_update_time": "20250815", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.10031", "html_url": "https://arxiv.org/abs/2508.10031", "title": "LLM上下文误导：Context Filtering在保持LLMs安全对齐中的作用", "title_en": "Context Misleads LLMs: The Role of Context Filtering in Maintaining Safe Alignment of LLMs", "authors": "Jinhwa Kim,Ian G. Harris", "background": "尽管大型语言模型（LLMs）在性能上取得了显著进步，但各种破解攻击却引起了日益严重的安全和伦理风险。恶意用户经常利用对抗性上下文欺骗LLMs，使其生成有害查询的响应。增强LLMs的安全性通常会牺牲其帮助性，可能会影响普通用户的体验。因此，研究提出了一种新的防御机制——上下文过滤模型，这是一种输入预处理方法，旨在过滤出不可信和不可靠的上下文，同时识别包含真实用户意图的主要提示，以揭示隐藏的恶意意图。我们通过与最先进的防御机制进行对比分析，评估了我们的模型在防御破解攻击方面的有效性，并检查了这些防御下的LLMs的有用性。研究表明，我们的模型能够在不损害原始LLMs性能的情况下将破解攻击的成功率降低88%，实现了安全性和有用性的最佳平衡。此外，该模型是一种即插即用的方法，可以应用于所有LLMs，包括白盒和黑盒模型，以增强其安全性，无需对模型本身进行微调。", "innovation": "该研究提出了一种名为Context Filtering的新型防御机制，该机制是为了处理不信任和不可靠的上下文，同时识别包含真实用户意图的主要提示，以揭露隐藏的恶意意图。这种方法旨在增强LLMs的安全性，同时保持其原始性能，并且不改变模型本身。我们的模型能够将破解攻击的成功率降低88%，并且可以应用于所有类型的语言模型，是即插即用的方法，不需要对模型进行微调。", "conclusion": "我们的模型成功地实现了安全性和有用性的最佳平衡，将破解攻击的成功率降低了88%，同时保持了原始LLMs的性能。该模型可以适用于各种语言模型，增强其安全性，而不需进行任何微调。未来的研究方向可能是进一步优化该模型，以应对更多种类的攻击，并研究如何进一步提升其性能和实用性。"}
{"llm_update_time": "20250815", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.10036", "html_url": "https://arxiv.org/abs/2508.10036", "title": "反思然后学习：基于内省困惑的主动提示信息提取", "title_en": "Reflect then Learn: Active Prompting for Information Extraction Guided by Introspective Confusion", "authors": "Dong Zhao,Yadong Wang,Xiang Chen,Chenxi Wang,Hongliang Dai,Chuanxing Geng,Shengzhong Zhang,Shaoyuan Li,Sheng-Jun Huang", "background": "大语言模型（LLMs）在少量示例信息抽取（IE）任务中显示出显著潜力，但其性能高度依赖于内存量的示例选择。传统的选择策略往往无法提供有效的指导，因为它们忽视了一个关键的模型失误来源：不仅来自语义内容，也来自结构化格式生成的需求。这导致了信息抽取任务中的困惑。", "innovation": "本文引入了一种新的基于内省困惑的主动提示框架（APIE），通过一个双组件不确定性度量来使LLM能够量化格式不确定性和内容不确定性，从而评估自身的困惑。框架能够基于全面的评分主动选择最具挑战性和信息量的未标记数据作为少样本示例。", "conclusion": "在四个基准上的实验表明，本文方法在信息抽取准确性和鲁棒性上均显著优于强基线。本文工作强调了在构建有效的可靠结构化生成系统时，精细化的双层次视图的模型不确定性的重要性。"}
{"llm_update_time": "20250815", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.10034", "html_url": "https://arxiv.org/abs/2508.10034", "title": "使用深度学习进行喷流图像标签：一种集成模型", "title_en": "Jet Image Tagging Using Deep Learning: An Ensemble Model", "authors": "Juvenal Bassa,Vidya Manian,Sudhir Malik,Arghya Chattopadhyay", "background": "在高能粒子物理中，喷流分类对于理解基本相互作用和探索超出标准模型的现象至关重要。喷流源自夸克和胶子的裂解和强子化，由于其复杂的多维结构，喷流的识别是一个挑战。传统分类方法在捕捉这些细微差别方面往往不够，因此需要先进的机器学习方法。", "innovation": "本文采用了两个神经网络的集成方法（Ensemble Model）来标记各类喷流，将喷流数据转换为二维直方图，而不是在高维空间中表示为点。该集成方法用于对JetNet数据集中的喷流进行分类，对应于：顶夸克、轻夸克（上夸子或下夸子）以及W和Z玻色子。对于上述喷流类别，我们展示了集成模型可以用于二元和多元分类。这种方法通过利用每个构成网络的优点，学习喷流特征，实现了优于单一网络的性能。", "conclusion": "该集成方法通过学习喷流特征，实现了对喷流类别的有效分类。相较于单一网络，该集成模型展现出更好的性能。"}
{"llm_update_time": "20250815", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.10040", "html_url": "https://arxiv.org/abs/2508.10040", "title": "用可解释的文本和图学习探索假新闻的内容和社会联系", "title_en": "Exploring Content and Social Connections of Fake News with Explainable Text and Graph Learning", "authors": "Vítor N. Lourenço,Aline Paes,and Tillman Weyde", "background": "全球范围内的 misinformation 扩散以及对内容可信度的担忧推动了自动事实核查系统的开发。这些系统不仅要分析内容本身，还要考虑社交媒体动态如“点赞”和用户网络等因素，以扩大误导信息的影响力。简单地将内容标为假信息可能效果不佳，甚至会强化自动化和确认偏差。因此，需要一种可解释的框架来结合内容、社交媒体和图结构特征，以提高事实核查的效果，同时能够提供可理解的见解来支持分类决策。", "innovation": "该论文提出了一种可解释的框架，该框架将 misinformation 分类器与可解释性技术相结合，通过结合内容、社交媒体和图结构特征来增强事实核查。这种方法通过多模态信息提高了性能，并且通过新颖的评估协议验证了其解释性、可信度和稳健性，展示了其产生人类可理解的预测说明的能力。该框架区分了以往仅依赖单一模态信息的方法。", "conclusion": "实验表明，多模态信息比单一模态信息在事实核查方面表现更好。该框架不仅提高了事实核查的准确性，还为其分类决策提供了透明和可理解的解释，通过使用英语、西班牙语和葡萄牙语的数据集进行评估，进一步证明了其实用性和有效性。这种可解释性的框架有助于增强公众对自动事实核查系统的信任，并有效防止自动化和确认偏差的负面影响。"}
{"llm_update_time": "20250815", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.10038", "html_url": "https://arxiv.org/abs/2508.10038", "title": "设计中的可认证稳健恶意软件检测器", "title_en": "Certifiably robust malware detectors by design", "authors": "Pierre-Francois Gimenez,Sarath Sivaprasad,Mario Fritz", "background": "恶意软件分析涉及分析可疑软件以检测恶意载荷。静态恶意软件分析无需软件执行，越来越多地依赖机器学习技术以实现可扩展性。尽管这些技术可以获得非常高的检测准确性，但通过对抗性示例（即对样本进行少量修改以欺骗检测器而不改变软件行为）可以轻松规避它们。与其他领域如计算机视觉不同，创建对恶意软件无功能影响的对抗性示例需要特殊变换。研究表明，即使在脆弱特征上也能够学习经验稳健的恶意软件检测器，因此提出了一种新的模型架构，用于设计中的可认证稳健恶意软件检测。", "innovation": "提出了一个新的模型架构，设计中的可认证稳健恶意软件检测器，并且证明了每个稳健检测器可以分解成特定结构，即使在脆弱特征上也可以学习到经验稳健的恶意软件检测器。框架ERDALT基于此结构实现。", "conclusion": "将这些方法与基于机器学习的恶意软件检测方法进行比较和验证，结果显示可以在有限减少检测性能的前提下实现稳健检测。"}
{"llm_update_time": "20250815", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.10043", "html_url": "https://arxiv.org/abs/2508.10043", "title": "网络监控代理AI系统的安全保护：威胁建模与风险分析", "title_en": "Securing Agentic AI: Threat Modeling and Risk Analysis for Network Monitoring Agentic AI System", "authors": "Pallavi Zambare,Venkata Nikhil Thanikella,Ying Liu", "background": "将大型语言模型（LLMs）与自主代理结合应用于网络监控和决策系统中，会引发严重的安全问题。因此，本研究使用MAESTRO框架中的七层威胁建模架构来识别、评估并消除代理AI的漏洞。研究分析了代理AI系统中的实际威胁案例，揭示了潜在的安全风险及其对系统性能的影响。", "innovation": "本研究开发了一个代理系统的原型，并采用了多层纵深防御策略，包括使用内存隔离、验证规划者和实时异常响应系统。该研究证实MAESTRO框架适用于操作性威胁映射、前瞻性风险评分，并为构建稳健系统提供基础。研究强调了内存完整性的执行、适应逻辑监控及跨层通信保护的重要性，以确保代理AI在对抗环境中可靠性。", "conclusion": "研究结果验证了MAESTRO框架在操作性威胁映射、前瞻性风险评分和构建抗御性系统设计中的可行性。提出了使用多层防御策略，包括内存隔离、规划者验证和实时异常响应系统。这强调了保障代理AI可靠性的重要性，特别是在对抗环境中的适应逻辑监控及跨层通信保护方面。"}
{"llm_update_time": "20250815", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.10057", "html_url": "https://arxiv.org/abs/2508.10057", "title": "大型语言模型在抽象推理过程中表现出与人类神经认知的一致性迹象", "title_en": "Large Language Models Show Signs of Alignment with Human Neurocognition During Abstract Reasoning", "authors": "Christopher Pinier,Sonia Acuña Vargas,Mariia Steeghs-Turchina,Dora Matzke,Claire E. Stevenson,Michael D. Nunez", "background": "研究背景：本研究探讨了大型语言模型（LLMs）在进行抽象推理时是否能够反映人类的神经认知过程。", "innovation": "研究创新：研究人员通过比较人类参与者与八个开源LLMs在抽象模式填充任务上的表现和脑电图（EEG）记录的眼动相关电位（FRPs），发现仅最大数据量的LLMs能够达到与人类相当的准确度，并且这些LLMs在中间层对抽象模式类别形成了独特的群集，虽然这种群集的程度与其在任务上的表现相关。", "conclusion": "研究结论：这些结果表明，LLMs在抽象推理过程中可能反映出了人类的大脑机制，并且存在潜在的共同表示空间。这初步证明了生物智能和人工智能之间共享的原则，提供了两者之间一致性的一流证据。"}
{"llm_update_time": "20250815", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.10050", "html_url": "https://arxiv.org/abs/2508.10050", "title": "法律零日：先进AI系统的新型风险向量", "title_en": "Legal Zero-Days: A Novel Risk Vector for Advanced AI Systems", "authors": "Greg Sadler,Nathan Sherburn", "background": "在先进AI系统中引入了一个新的风险向量——‘法律零日’的概念。法律零日是指先前未被发现的法律法规中的漏洞，当被利用时，可以导致社会立即出现严重影响，且无需提前通过诉讼或其他程序。利用2017年澳大利亚双重公民危机作为案例，展示了看似细微的法律疏忽如何引发大规模的治理混乱。", "innovation": "提出了识别并评估这些漏洞的风险模型，并开发了一种方法论来构建‘法律谜题’作为评估工具，以评估AI系统发现此类漏洞的能力。指出当前AI模型可能无法可靠地找到影响性的法律零日，但未来的系统可能会发展出这种能力，这既带来了风险也带来了机会。", "conclusion": "研究成果表明，尽管当前AI模型可能无法可靠地找到影响性的法律零日，但未来的系统可能会发展出这种能力，带来双重风险和机会，促进法律健壮性的提升。这项工作为识别和缓解来自前沿AI系统的未被认识到的风险做出了贡献。"}
{"llm_update_time": "20250815", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.10044", "html_url": "https://arxiv.org/abs/2508.10044", "title": "基于生成式AI的能源管理系统网络安全：方法、挑战及未来方向", "title_en": "Generative AI for Cybersecurity of Energy Management Systems: Methods, Challenges, and Future Directions", "authors": "Aydin Zaboli,Junho Hong", "background": "本文提出了一个专门针对能源管理系统（EMSs）的安全框架，该框架能够有效应对动态的网络安全漏洞及系统问题。首先，提出了一种全面的多点攻击/错误模式模型，用于系统地识别整个EMS数据处理管道中的漏洞，包括后状态估计（SE）隐形攻击、EMS数据库操作以及根据实时数据库（RTDB）存储的人机界面（HMI）显示篡改。该框架认识到现代攻击向量的相互联系性，它们利用SCADA数据流的各种阶段。此外，首次在电力系统领域提出了基于生成式AI（GenAI）的异常检测系统（ADSs），用于处理应对场景。该框架进一步引入了一个基于多模式分析的框架——集合成成智能（SoM-GI）框架，该框架结合了视觉标记与规则，利用生成式AI的能力来克服空间推理的固有局限性。", "innovation": "本文创新之处在于提出了一个针对EMSs的全面安全框架，以及首次在电力系统领域提出的基于生成式AI的异常检测系统，并引入集合成成智能（SoM-GI）框架来提升异常检测的准确性。", "conclusion": "本文通过将数值分析与视觉模式识别及语言规则相结合，展示了所提出的框架在多种场景下的有效性，并通过视觉分析识别出不一致之处，从而提供了一个整合的方法来抵御网络威胁和系统错误。"}
{"llm_update_time": "20250815", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.10052", "html_url": "https://arxiv.org/abs/2508.10052", "title": "NetMoniAI: 一种用于网络监控与安全的代理人工智能框架", "title_en": "NetMoniAI: An Agentic AI Framework for Network Security & Monitoring", "authors": "Pallavi Zambare,Venkata Nikhil Thanikella,Nikhil Padmanabh Kottur,Sree Akhil Akula,Ying Liu", "background": "当前网络环境中存在着复杂的威胁和挑战，传统的网络监控和安全方法难以有效应对。为了解决这些问题，研究者们需要开发一种能够自动监测网络流量和检测安全异常的有效框架。NetMoniAI框架结合了去中心化的分析和轻量级中央协调，提高了系统的响应速度和准确性，同时也能够适应资源受限的环境。", "innovation": "NetMoniAI框架提出了一个新的两层架构：每一层节点上的自治微代理执行本地流量分析和异常检测。中央控制器汇总节点间的洞察，以检测协同攻击并保持系统的整体态势感知。通过这种设计，NetMoniAI框架能够在资源约束下扩展，减少冗余，并提高响应时间，同时不损害准确度。此外，框架提供了完整的开源代码，便于研究人员和实践者进行复制、验证和扩展以应对多样的网络环境和威胁情景。", "conclusion": "NetMoniAI框架展示了其在资源受限环境下的扩展性，减少了冗余，并提高了响应时间，同时保持了准确度。项目致力于促进研究和实践的广泛采用和可重复性，提供了完整的开源代码，可以在不同的网络环境中和威胁情景下进行复制和扩展。"}
{"llm_update_time": "20250815", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.10110", "html_url": "https://arxiv.org/abs/2508.10110", "title": "利用可解释的图像-文本基础模型增强模拟攻击检测", "title_en": "Empowering Morphing Attack Detection using Interpretable Image-Text Foundation Model", "authors": "Sushrut Patwardhan,Raghavendra Ramachandra,Sushma Venkatesh", "background": "随着面部识别系统的可靠验证变得越来越重要，模拟攻击检测成为其中的关键组件。本文提出了一种多模态学习方法，能够为模拟攻击检测提供文本描述。研究结果表明，在零样本评估中，基于对比语言图像预训练的框架能够实现泛化的模拟攻击检测，并预测最相关的文本片段。研究通过分析十种不同的文本提示，包括短文本和长文本，进行深入研究。这些提示在考虑人类可理解的文本片段的基础上进行工程设计，并在使用公开的面部生物数据集开发的面部模拟数据集上进行了广泛实验。研究探讨了现有的预训练神经网络模型在针对五种不同媒体捕捉的六种不同模拟生成技术的零样本评估中的表现。", "innovation": "本文提出了一种利用对比语言图像预训练模型进行零样本评估的多模态学习方法，该方法能够提供模拟攻击检测的文本描述，不仅能实现泛化的模拟攻击检测，还能预测最相关的文本片段。研究中提出的深入分析涵盖了十种不同长度的文本提示，并在多个数据集上进行了广泛的实验验证。", "conclusion": "研究展示了在零样本评估中，对比语言图像预训练模型对于模拟攻击检测的泛化能力和文本描述预测能力。通过分析十种不同长度的文本提示，结合广泛的实验结果，表明提出的框架在模拟攻击检测中具有较高的准确性和鲁棒性。"}
{"llm_update_time": "20250815", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.10123", "html_url": "https://arxiv.org/abs/2508.10123", "title": "Nested-ReFT: 通过离策采样提高大规模语言模型微调的高效强化学习", "title_en": "Nested-ReFT: Efficient Reinforcement Learning for Large Language Model Fine-Tuning via Off-Policy Rollouts", "authors": "Maxime Heuillet,Yufei Cui,Boxing Chen,Audrey Durand,Prasanna Parthasarathi", "background": "现有强化学习后训练方法（ReFT）在解决具有挑战性的推理问题（如数学推理）时表现出显著性能提升，但是通过行为模型生成多个答案并进行奖励函数评分的过程中，会产生大量计算成本。因此，研究目标是如何通过引入离策采样来降低训练成本，同时保持或提升模型在多个数学推理基准测试和不同模型规模上的性能表现。", "innovation": "提出了一个名为Nested-ReFT的新框架，该框架允许目标模型的一部分层在训练过程中充当行为模型以生成离策完成，这种方式在每次训练批次中都根据动态层跳过策略进行配置，从而降低了推理成本，并通过理论分析展示了无偏梯度估计和可控制的方差，提供了提高计算效率的方法，具体体现在多组数学推理基准测试和不同模型规模中的tokens/sec性能提升上。此外，还探索了三种偏置缓解方法来进一步降低梯度更新的离策性，从而保持基准ReFT性能水平。", "conclusion": "Nested-ReFT框架通过动态跳过训练批次中的部分层，降低了推理成本并提高了计算效率，同时保留了与标准ReFT框架相当的性能。"}
{"llm_update_time": "20250815", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.10071", "html_url": "https://arxiv.org/abs/2508.10071", "title": "推进数据公平：NLP数据实践中的从业者责任与问责", "title_en": "Advancing Data Equity: Practitioner Responsibility and Accountability in NLP Data Practices", "authors": "Jay L. Cunningham,Kevin Zhongyang Shao,Rock Yuren Pang,Nathaniel Mengist", "background": "尽管关于算法偏见的表面化和审计研究已经受到广泛关注，确保人工智能的公平发展，但关于自然语言处理（NLP）从业者对此类问题的看法及其应对策略却知之甚少。这些从业者直接参与数据集开发、标注和部署，对NLP数据公平性有着深刻的理解。本文基于2024年的调查问卷和专题小组访谈，考察了美籍NLP数据从业人员对公平性的认识，以及在组织和系统性限制条件下的应对策略，并分析了他们与《美国人工智能权利法案》等新兴治理努力的参与情况。研究发现，商业目标和公平承诺之间存在持续的张力，同时也对更多的参与者和负责任的数据工作流程提出呼声。", "innovation": "本文是首次专注于从业者的视角，将他们的经验与多尺度的人工智能治理框架联系起来，并提出结合技术、政策和社区领域的参与式建议。重要的是，该研究进入探讨数据多样性及其表面化的辩论中，认为改善NLP公平性需要支持从业者自主权和社区赋权的结构性治理改革。", "conclusion": "研究结果揭示了商业目标与公平承诺之间的持续张力，同时也强调了需要更参与和负责任的数据工作流程，呼吁结构化的治理改革以支持从业者自主权和社区同意。"}
{"llm_update_time": "20250815", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.10137", "html_url": "https://arxiv.org/abs/2508.10137", "title": "mSCoRe: 一种多语言和可扩展的基于技能的常识推理基准", "title_en": "mSCoRe: a $M$ultilingual and Scalable Benchmark for $S$kill-based $Co$mmonsense $Re$asoning", "authors": "Nghia Trung Ngo,Franck Dernoncourt,Thien Huu Nguyen", "background": "最近对强化推理的大型语言模型（LLMs）的研究显示了其在复杂推理任务中的出色能力，但这些模型如何利用不同的人类推理技能的机制尚不清楚，尤其对于跨越多种语言和文化的日常生活常识推理。为此，研究人员提出了一种名为mSCoRe的多语言且可扩展的基于技能的常识推理基准，旨在全面评估LLMs的推理能力，并提供系统的分析框架。", "innovation": "mSCoRe基准包括三个关键组件：（1）一种新颖的推理技能分类法，使得能够对模型的推理过程进行精细分析；（2）一个专为常识推理评估定制的稳健数据合成流水线；（3）一个复杂性扩展框架，以便随着LLMs未来能力的提升，任务难度能够动态调整。研究表明，即使是最新、最全面的LLMs在复杂的常识推理任务中仍然面临显著挑战，特别是在不同文化和语言之间的微妙差异上。研究还对模型的推理过程进行了详细分析，为未来提高多语言常识推理能力提供了方向。", "conclusion": "实验表明，当前的LLMs在复杂和多语言通用常识推理方面仍然存在局限性，特别是面临着文化差异和细微差异带来的挑战。mSCoRe基准提供了更好的评估工具，揭示了模型在这一领域的不足，并对未来的改进提出了建议。"}
{"llm_update_time": "20250815", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.10115", "html_url": "https://arxiv.org/abs/2508.10115", "title": "仅使用大语言模型学习图任务", "title_en": "Less is More: Learning Graph Tasks with Just LLMs", "authors": "Sola Shirai,Kavitha Srinivas,Julian Dolby,Michael Katz,Horst Samulowitz,Shirin Sohrabi", "background": "对于大型语言模型（LLMs），处理图任务可以帮助解决许多问题。先前的工作尝试通过研究如何将图序列化为文本，以及将GNNs与LLMs结合来改进LLMs的图推理能力。不过，这些方法的有效性尚不明确，因此该论文通过实证方法回答了以下研究问题：1. LLMs是否能够通过训练学习解决基本的图任务，而无需专门的图编码模型？2. LLMs能否将学到的解决方案推广到未见过的图结构或任务？3. 竞争方法学习图任务的优势是什么？", "innovation": "该研究发现即使是小型LLMs也能通过训练它们来解决图任务，训练过程能够推广到新的任务和图结构，而无需专门的图编码模型。这表明LLMs具有强大的图处理能力，甚至在没有专门图编码工具的情况下也可以有效地学习和推广图任务解决方案，这在图任务处理领域带来了一种新的视角。", "conclusion": "研究结果表明，即使是小型LLMs也能通过训练解决图任务，并能够推广到新的任务和图结构。这一发现表明，使用LLMs学习图任务具有潜力，无需专门的图编码模型。这种非传统的学习方法对图处理领域提出了新的可能性。"}
{"llm_update_time": "20250815", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.10222", "html_url": "https://arxiv.org/abs/2508.10222", "title": "通过表情符号预测理解文本情感", "title_en": "Understanding Textual Emotion Through Emoji Prediction", "authors": "Ethan Gordon,Nishank Kuppa,Rigved Tummala,Sriram Anasuri", "background": "该项目通过分析短文本序列中的表情符号预测，使用了四种深度学习架构：全连接网络、卷积神经网络（CNN）、变压器和BERT模型。利用TweetEval数据集，该研究通过应用焦点损失和正则化技术来解决类别不平衡问题。", "innovation": "该研究使用了四种不同的深度学习架构进行表情符号预测，并采用焦点损失和正则化技术解决类别不平衡问题。研究结果显示，BERT模型由于预训练的优势在整体性能上表现出色，而卷积神经网络在罕见表情符号类别上表现更为出色。这表明选择合适的架构和进行超参数调整对提高有情感意识的表情符号预测十分重要，有助于改善人机交互。", "conclusion": "研究表明，不同深度学习架构对表情符号预测的效果存在显著差异，强调了在进行情感感知表情符号预测时需要根据具体任务选择合适的架构并进行有效的超参数调整，进一步提高了人机交互的性能。"}
{"llm_update_time": "20250815", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.10147", "html_url": "https://arxiv.org/abs/2508.10147", "title": "rETF-semiSL: 半监督学习在时间数据中神经塌缩现象中的应用", "title_en": "rETF-semiSL: Semi-Supervised Learning for Neural Collapse in Temporal Data", "authors": "Yuhan Xie,William Cappelletti,Mahsa Shoaran,Pascal Frossard", "background": "深度神经网络需要捕捉复杂的时间模式，以有效表示动态数据。半监督和自我监督的学习方法在预训练大型模型方面显示出有希望的结果，当这些模型微调用于分类时，往往比从零开始训练的模型表现出更优异的效果。然而，预训练任务的选择通常依赖于经验判断，其在下游分类中的可迁移性得不到保证。因此，本文提出了一个新的半监督预训练策略，以确保隐空间表示满足优化的神经分类器中观察到的神经塌缩现象。该策略使用旋转等角紧架分类器和伪标签对少量标记样本进行预训练，并结合生成预训练任务和顺序扩增策略，从而有效捕捉时间动态并促进嵌入的可分性。", "innovation": "本文提出了一种新的半监督预训练策略，利用旋转等角紧架分类器和伪标签对多种大型模型（如LSTM、变压器和状态空间模型）进行预训练，并结合生成预训练任务和新的顺序扩增策略，以更好地捕捉时间动态和增强嵌入的可分性，从而显著提高了多变量时间序列分类任务的表现，并且证明了预训练目标与理论嵌入几何的对齐带来的益处。", "conclusion": "本文方法在应用于LSTM、变压器和状态空间模型等多种模型上的三个多变量时间序列分类数据集上，显著优于之前的预训练任务，这表明了将预训练目标与理论上支持的嵌入几何相匹配的优势。"}
{"llm_update_time": "20250815", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.10186", "html_url": "https://arxiv.org/abs/2508.10186", "title": "PakBBQ：适用于问答的跨文化偏见基准", "title_en": "PakBBQ: A Culturally Adapted Bias Benchmark for QA", "authors": "Abdullah Hashmat,Muhammad Arham Mirza,Agha Ali Raza", "background": "随着大型语言模型（LLMs）在各种应用中的广泛应用，确保这些模型对所有用户群体的公平性是不言而喻的。然而，大多数LLMs都是在以西方为中心的数据上进行训练和评估的，很少关注低资源语言和地区背景。", "innovation": "本文介绍了一种名为PakBBQ的新数据集，它是一个针对当地文化和区域背景进行调整的扩展BMQ（Bias Benchmark for Question Answering）数据集。PakBBQ包括超过214个模板、17180个问答对以及涵盖八种偏见维度（年龄、残疾、外貌、性别、社会经济地位、宗教、区域归属和语言形式化）的一些列问题和答案，这些维度与巴基斯坦相关。此外，还在模糊和明确分词的背景下以及负面和非负面问题的表达方式下评估了多种多语言LLMs，揭示了关键发现。", "conclusion": "实验结果表明，通过澄清和分词可以提高约12%的准确率；用乌尔都语相比英语表现出更强的反偏见行为；以及问题负向表达会减少刻板反应。这些结果强调了在资源有限的情况下，利用情境化基准和简单的提示工程策略对于偏见缓解的重要性。"}
{"llm_update_time": "20250815", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.10156", "html_url": "https://arxiv.org/abs/2508.10156", "title": "使用基于生成人工智能（GenAI）的合成图像和实地图像的自定义EfficientNetV2-L模型提高西瓜（Citrullus lanatus）疾病分类", "title_en": "Improving watermelon (Citrullus lanatus) disease classification with generative artificial intelligence (GenAI)-based synthetic and real-field images via a custom EfficientNetV2-L model", "authors": "Nitin Rai,Nathan S. Boyd,Gary E. Vallad,Arnold W. Schumann", "background": "当前生成人工智能（GenAI）模型的发展为生成高分辨率合成图像提供了新可能性，从而为农业计算机视觉模型训练提供了传统图像采集的有前途的替代方案。在作物疾病诊断的背景下，GenAI模型被用于创建各种疾病的合成图像，这可能有助于模型创建并减少对资源密集型实地数据收集的依赖。然而，关于整合真实图像和合成图像以提高疾病分类性能的研究有限。", "innovation": "本研究旨在探索是否可以结合少量真实图像与合成图像来增强针对西瓜疾病分类的EfficientNetV2-L模型的预测准确性。训练数据集被分为五种处理：H0（仅真实图像）、H1（仅合成图像）、H2（1:1真实图像到合成图像）、H3（1:10真实图像到合成图像）和H4（H3 + 随机图像以提高多样性和模型泛化能力）。所有处理都使用增强的细调和迁移学习技术构建的自定义EfficientNetV2-L架构。H2、H3和H4处理的训练模型展示了高精度、召回率和F1分数指标。加权F1分数从H0的0.65增加到H3-H4的1.00，表明少量真实图像与大量合成图像的结合提高了模型性能和泛化能力。", "conclusion": "本研究验证了合成图像无法充分替代真实图像的发现，相反，两者必须以混合方式使用才能最大限度地提高作物疾病分类模型的性能。"}
{"llm_update_time": "20250815", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.10226", "html_url": "https://arxiv.org/abs/2508.10226", "title": "使用大型语言模型测量可能存在精神分裂症患者的症状严重程度", "title_en": "Using Large Language Models to Measure Symptom Severity in Patients At Risk for Schizophrenia", "authors": "Andrew X. Chen,Guillermo Horga,Sean Escola", "background": "临床高危（CHR）患者需要对他们可能发展成精神分裂症的症状进行密切监测，以便采取合适的治疗措施。未特地针对测量BPRS进行的临床访谈，大型语言模型可以预测BPRS得分。尽管访谈并非专门为测量BPRS设计，但仍能接近人类评估者之间的可靠性和一致性水平，且具有在不同语言中提高评估准确性和标准化的潜力。", "innovation": "利用大型语言模型（LLMs）从临床访谈记录中预测BPRS分数，即使访谈未专门针对测量BPRS设计，该零样本性能也接近人类评估者的可靠性和一致性水平；进一步展示了LLMs在使用跨语言信息进行评估方面的能力，并在一次或少量样本学习场景中实现了更准确的评估。", "conclusion": "大型语言模型有能力提高和标准化CHR患者症状评估，尤其是在外语环境中和通过多阶段学习流程。未来的研究可以进一步探索LLMs在其他临床应用中的潜力。"}
{"llm_update_time": "20250815", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.10208", "html_url": "https://arxiv.org/abs/2508.10208", "title": "CATNet: 几何深度学习在CAT债券收益率预测中的应用", "title_en": "CATNet: A geometric deep learning approach for CAT bond spread prediction in the primary market", "authors": "Dixon Domfeh,Saeid Safarveisi", "background": "传统的CAT债券定价模型难以捕捉这些工具中固有的复杂关系数据。研究发现，CAT债券市场表现出无标度网络的特征，即由少数高度连接和有影响力的主节点主导的网络结构。这需要一种新的方法来更好地预测CAT债券的价格，特别是利用其网络结构来进行预测.", "innovation": "引入CATNet框架，采用关系图卷积网络（R-GCN）几何深度学习架构，将CAT债券的主要市场建模为图，以此来预测收益率。该方法突出了网络特征的影响，证明了网络连接是定价的关键决定因素，为风险评估提供了新的范式，并表明图基模型不仅提供了一流的准确性，还能提供更深的量化市场见解.", "conclusion": "CATNet显示出很高的预测性能，显著优于强基准随机森林。网络拓扑中心性度量作为特征进一步提升了准确性。解释性分析证实，这些网络特征不仅是统计数据上的伪现象，而是发行人声誉、承销商影响力和风险集中度的定量代理。这项研究证明了网络连通性是关键定价因素，并展示了基于图的模型可以实现先进准确性和更深入的定量市场洞察力。"}
{"llm_update_time": "20250815", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.10148", "html_url": "https://arxiv.org/abs/2508.10148", "title": "使用反事实距离的异常分布检测", "title_en": "Out-of-Distribution Detection using Counterfactual Distance", "authors": "Maria Stoica,Francesco Leofante,Alessio Lomuscio", "background": "为了安全使用机器学习系统，对异常分布数据（Out-of-Distribution, OOD）进行准确且可解释的检测是必要的。已有研究表明，通过特征距离到决策边界的计算可以有效识别OOD数据。本文基于此直觉，提出了一种后处理OOD检测方法，该方法利用反事实解释计算输入到决策边界的距离。由于大型架构可能难以计算解释，为此还提出了直接在嵌入空间计算反事实的方法以提升可扩展性。此方法的关键在于其反事实解释能帮助我们无缝解读检测器的结果，这提升了检测的透明性和可靠性。", "innovation": "文章提出了一种后处理OOD检测方法，利用反事实解释计算输入到决策边界的距离，并提出直接在嵌入空间生成反事实以提高计算效率。这种方法提高了OOD检测的准确性和可解释性。通过实验，该方法在CIFAR-10、CIFAR-100和ImageNet-200数据集上的表现优于现有方法，并达到了较高的AUROC和FPR95值。", "conclusion": "实验结果表明，该方法在四个OOD数据集上表现优秀，尤其是对于CIFAR-100和ImageNet-200数据集，AUROC分别达到97.05%和92.55%，FPR95分别为13.79%和33.55%。"}
{"llm_update_time": "20250815", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.10192", "html_url": "https://arxiv.org/abs/2508.10192", "title": "大型语言模型中的提示-响应语义异质性度量：对于忠实性幻想和对齐检测", "title_en": "Prompt-Response Semantic Divergence Metrics for Faithfulness Hallucination and Misalignment Detection in Large Language Models", "authors": "Igor Halperin", "background": "大语言模型（LLMs）的普及受到幻觉的挑战，幻觉是指模型生成非事实、不合逻辑或不忠实的文本。现有方法，如语义熵，通过对固定提示的较多答案的多样性进行测量来检测任意性。然而，它们缺乏对提示和回答中跨多个语义等价重述形式的响应一致性的深层测试。本文旨在提出一种新的轻量级框架，语义分歧度量（SDM），以检测模型对输入语境响应中的忠实性幻觉。", "innovation": "本文创新地提出了语义分歧度量（SDM）框架，通过结合聚类分析和信息论度量来检测大语言模型的忠实性幻觉。具体而言，SDM框架采用了联合聚类方法，将提示和响应映射到共享主题空间，并通过计算一系列信息论度量（如Jensen-Shannon散度和Wasserstein距离）来衡量提示和响应之间的语义差异。同时，研究指出KL散度（Answer || Prompt）是语义探索的关键指标，这对于区分不同的生成行为非常重要。此外，SDM进一步结合了这些度量形成了语义盒子，这是一种诊断框架，用于分类LLM响应类型，包括危险的、自信的虚构等。", "conclusion": "本文提出了一种创新的语义分歧度量（SDM）框架，旨在检测大语言模型在回应时产生的忠实性幻觉。SDM通过聚类分析和信息论方法度量提示和响应之间的语义一致性，并提供了一种诊断框架——语义盒，用于分类LLM的响应类型。"}
{"llm_update_time": "20250815", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.10046", "html_url": "https://arxiv.org/abs/2508.10046", "title": "SABIA: 一种基于AI的社会媒体上检测阿片类药物相关行为的工具", "title_en": "SABIA: An AI-Powered Tool for Detecting Opioid-Related Behaviors on Social Media", "authors": "Muhammad Ahmad,Fida Ullah,Muhammad Usman,Ildar Batyrshin,Grigori Sidorov", "background": "社交媒体平台已成为理解公共卫生挑战的重要工具，提供了关于患者行为、用药习惯和心理健康状况的见解。然而，分析此类数据仍然困难重重，因为社交媒体上充斥着非正式语言、俚语和编码沟通，这会妨碍对阿片类药物滥用的检测。", "innovation": "研究探讨了社交媒体上阿片类药物相关用户行为的问题，包括非正式表达、俚语词汇和拼写错误或编码语言。我们分析了双向编码表征的BERT技术，并开发了一种结合BERT、BiLSTM和3CNN的混合深度学习模型SABIA，形成了一种单一任务分类器，有效地捕捉目标数据集的特征。SABIA模型展示了在捕捉语义和上下文信息方面的强大能力。", "conclusion": "SABIA模型在检测复杂阿片类药物相关行为方面表现出色，优于基线模型（逻辑回归，LR = 0.86），准确率提高了9.30%。与之前七项研究的比较证明了其有效性和鲁棒性。该研究展示了混合深度学习模型在社会媒体上检测阿片类药物相关行为的潜力，支持公共卫生监测和干预努力。"}
{"llm_update_time": "20250815", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.10252", "html_url": "https://arxiv.org/abs/2508.10252", "title": "促进AI系统长期交互研究", "title_en": "Facilitating Longitudinal Interaction Studies of AI Systems", "authors": "Tao Long,Sitong Wang,Émilie Fabre,Tony Wang,Anup Sathya,Jason Wu,Savvas Petridis,Dingzeyu Li,Tuhin Chakrabarty,Yue Jiang,Jingyi Li,Tiffany Tseng,Ken Nakagaki,Qian Yang,Nikolas Martelaro,Jeffrey V. Nickerson,Lydia B. Chilton", "background": "用户与AI的交互随时间变化，包括学习、适应和重新利用，因此一次性评估不足以捕捉这些动态过程。现有的长期研究虽是有必要的，但部署、评估设计和数据收集中存在的挑战使这种纵向研究难以实施。", "innovation": "该研讨会旨在应对这些挑战，通过关键演讲、圆桌讨论和互动分组讨论，为研究人员提供实施纵向研究的实用策略，并促进长期系统研究的社区形成，提升其在UIST工具设计、开发和评估中的应用地位。", "conclusion": "该研讨会希望通过系列活动，增强长期交互研究在UIST领域的认可度和实施可行性，支持和鼓励更多相关研究和实践。"}
{"llm_update_time": "20250815", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.10264", "html_url": "https://arxiv.org/abs/2508.10264", "title": "MRFD: 多区域融合解码与自我一致性在减轻大型多模态模型幻觉中的应用", "title_en": "MRFD: Multi-Region Fusion Decoding with Self-Consistency for Mitigating Hallucinations in LVLMs", "authors": "Haonan Ge,Yiwei Wang,Ming-Hsuan Yang,Yujun Cai", "background": "大型视觉-语言模型（LVLMs）在多模态任务上表现强劲，但常常会产生与视觉输入不一致的幻觉，这是因为它们难以验证图片不同区域的信息。", "innovation": "本文提出了一种名为Multi-Region Fusion Decoding (MRFD) 的无训练解码方法，通过建模不同区域之间的一致性来提升事实性。MRFD 使用交叉注意力确定显著区域，为每个区域生成初始响应，并基于响应间的 Jensen-Shannon Divergence (JSD) 计算可靠性权重，这些权重指导一个考虑一致性的区域融合，融合区域预测，并使用基于链式思维推理的区域感知提示来实现这一过程。", "conclusion": "实验结果显示，MRFD 明显减少了幻觉并改善了响应的真实性，而无需更新模型。"}
{"llm_update_time": "20250815", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.10230", "html_url": "https://arxiv.org/abs/2508.10230", "title": "从音频预训练到生物声学中的无免费午餐：嵌入基准研究", "title_en": "No Free Lunch from Audio Pretraining in Bioacoustics: A Benchmark Study of Embeddings", "authors": "Chenggang Chen,Zhiyu Yang", "background": "生物声学利用动物声音进行生态系统的非侵入性监测。通过利用音频预训练深度学习模型提取嵌入，而无需调优，来获取生物声学特征。然而，最近的一项基准研究表明，尽管音频预训练的VGG和变换器模型在某些任务中表现出最先进的性能，但在其他任务中却表现不佳。因此，本研究旨在评估11种深度学习模型在相同任务上的性能，通过降低它们学习嵌入的维度并使用聚类进行评估。", "innovation": "通过降低音频预训练模型学习嵌入的维度并与不执行调优的AlexNet等模型进行对比，本研究发现音频预训练模型在未调优和调优情况下均不如其他模型。调优后的ResNet模型能够更有效地分离背景声音和标记声音。研究强调了调优音频预训练模型的重要性，并建议在调优后检查嵌入。", "conclusion": "本研究证明了在生物声学中调优音频预训练模型的必要性，并提出了在包含较少背景声中的调优可以改善性能。同时，本研究强调了在使用音频预训练模型嵌入进行生物声学任务之前，建议对模型进行适当的调优和检查嵌入的有效性。"}
{"llm_update_time": "20250815", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.10308", "html_url": "https://arxiv.org/abs/2508.10308", "title": "ReviewRL：基于RL的自动科学评论", "title_en": "ReviewRL: Towards Automated Scientific Review with RL", "authors": "Sihang Zeng,Kai Tian,Kaiyan Zhang,Yuru wang,Junqi Gao,Runze Liu,Sa Yang,Jingxuan Li,Xinwei Long,Jiaheng Ma,Biqing Qi,Bowen Zhou", "background": "科学进步依赖于同行评审，但面对日益增加的投稿量和审稿人疲劳，同行评审面临越来越多的挑战。现有的自动化审稿方法在事实准确性、评分一致性以及分析深度方面存在困难，常常生成表面化或通用反馈，缺乏高质量人类审稿的洞见。", "innovation": "介绍了一种基于强化学习（Reinforcement Learning，RL）的框架ReviewRL，用于生成全面且基于事实的科学论文评论。它结合了：1）一种包含相关科学文献的ArXiv-MCP检索增强内容生成流水线，2）监督微调以建立基础审稿能力，3）一种结合强化学习过程的复合奖励函数，旨在同时提升评论质量和评分准确性。", "conclusion": "在ICLR 2025论文上的实验表明，ReviewRL在基于规则的指标和基于模型的质量评估中都显著优于现有方法。ReviewRL建立了RL驱动的自动批评生成基础框架，为未来在此领域的发展展示了巨大的潜力。ReviewRL的实现将发布在GitHub上。"}
{"llm_update_time": "20250815", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.10268", "html_url": "https://arxiv.org/abs/2508.10268", "title": "移动电话上基于姿势鲁棒校准策略的眼球注视点估计", "title_en": "Pose-Robust Calibration Strategy for Point-of-Gaze Estimation on Mobile Phones", "authors": "Yujie Zhao,Jiabei Zeng,Shiguang Shan", "background": "尽管基于外观的眼球注视点（PoG）估计已经有所提高，但估计器仍然难以在不同个体之间泛化，因为存在个体差异。因此，需要针对个人进行校准以确保PoG估计的准确性。然而，校准后的估计器往往对头部姿态的变化较为敏感。为了解决这一问题，我们研究了影响校准估计器的关键因素，并探索了抗姿态鲁棒的校准策略。我们首先构建了一个基准，名为MobilePoG，该基准包含了32个人的面部图像，关注在固定或连续变化头部姿态下的指定点上。使用这个基准，我们系统地分析了校准点和头部姿态多样性对估计准确度的影响。实验结果显示，在校准过程中引入更广泛的头部姿态范围可以提高估计器处理姿态变化的能力。", "innovation": "基于上述洞察，我们提出了一种动态校准策略，用户在移动设备时聚焦于校准点。这种方法自然地在用户友好且高效的校准过程中引入了头部姿态变化，从而产生了比传统校准策略更加鲁棒的校准估计器。提供的代码和数据集可以在我们的项目页面获取。", "conclusion": "我们的研究表明，动态校准策略能够生成对头部姿态变化更加鲁棒的PoG估计器，从而改进眼球注视点估计，并提出了一种通用的方法解决姿势可变性问题，提高了用户在移动设备上的体验。"}
{"llm_update_time": "20250815", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.10304", "html_url": "https://arxiv.org/abs/2508.10304", "title": "另一种算法偏见：大型语言模型强化性别和种族主导话语的论述分析", "title_en": "Yet another algorithmic bias: A Discursive Analysis of Large Language Models Reinforcing Dominant Discourses on Gender and Race", "authors": "Gustavo Bonil,Simone Hashiguti,Jhessica Silva,João Gondim,Helena Maia,Nádia Silva,Helio Pedrini,Sandra Avila", "background": "随着人工智能（AI）的发展，大型语言模型（LLMs）逐渐受到关注并在多种场景中得到应用。随着这些模型变得越来越复杂，研究和识别其中的偏见变得尤为重要。当前的方法大多依赖于定量、自动化的检测方式，往往忽略了在自然语言中偏见出现的复杂方式。该研究提出了一种定性的、论述分析框架来补充这些方法，通过手动分析LLM生成的关于黑人和白人女性的小故事，探讨性别和种族偏见的表现形式和影响，以更好地识别和缓解偏见问题。", "innovation": "该研究提出了一个定性的、论述分析框架来衡量大型语言模型中的偏见。通过手动分析LLM生成的关于黑人和白人女性的小故事，探讨性别和种族偏见，填补了当前定量方法在描绘偏见复杂性方面的不足，强调了定性方法在识别和理解LLM输出中偏见的具体表现方式方面的关键作用。", "conclusion": "研究发现，黑人女性常被描述成与家族和反抗相关联，而白人女性则处于自我发现的过程中。这反映了语言模型复制并强化了固化的话语表征，并强化了本质化和社会流动性缺失感。当被要求纠正偏见时，模型提供的修改大多表面但未能改变问题核心，这揭示了在构建包容性叙事方面存在的局限性。该研究强调了算法背后的意识形态功能及其对AI伦理使用和开发的显著意义，强化了从批判性、跨学科视角设计和部署AI的必要性，特别是在LLM生成的论述中体现和延续不平等现象方面。"}
{"llm_update_time": "20250815", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.10260", "html_url": "https://arxiv.org/abs/2508.10260", "title": "DINOMotion：2D-Cine MRI引导放射治疗中基于DINOv2的高级鲁棒组织运动跟踪", "title_en": "DINOMotion: advanced robust tissue motion tracking with DINOv2 in 2D-Cine MRI-guided radiotherapy", "authors": "Soorena Salari,Catherine Spino,Laurie-Anne Pharand,Fabienne Lathuiliere,Hassan Rivaz,Silvain Beriault,Yiming Xiao", "background": "在2D-Cine MRI引导的放射治疗中，准确的组织运动跟踪是确保治疗效果和安全性的关键。现有的方法常面临图像对齐的较大误差和解释性不足的问题。", "innovation": "DINOMotion是一个基于DINOv2和LoRA层的新型深度学习框架，用于实现鲁棒、高效且可解释的运动跟踪。该框架自动检测相应的解剖标记，通过提供显式的相邻图像对应来增强可解释性，同时使用LoRA层减少训练参数，提高训练效率，并利用DINOv2的强大特征表示以应对较大的错位。与基于迭代优化的方法相比，DINOMotion在测试时直接计算图像对齐。实验表明，DINOMotion在估计线性与非线性变换方面具有显著效果，特别是在处理大错位方面，其性能优于最先进的方法。", "conclusion": "DINOMotion在志愿者和患者数据集上的实验结果展示了其作为实时运动跟踪的鲁棒且可解释的解决方案的潜力，特别是在2D-Cine MRI引导的放射治疗中。"}
{"llm_update_time": "20250815", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.10345", "html_url": "https://arxiv.org/abs/2508.10345", "title": "福利中心化聚类", "title_en": "Welfare-Centric Clustering", "authors": "Claire Jie Zhang,Seyed A. Esmaeili,Jamie Morgenstern", "background": "传统的公平聚类主要关注群体的平等代表或群体特定聚类成本的均等化。然而，Dickerson等人（2025）的研究表明，这些公平性的概念可能导致不可取或不直观的聚类结果，并提倡以福利为中心的聚类方法来建模群体的福利。在此工作基础上，作者基于距离和比例代表性对群体福利进行建模，并正式定义了两种基于福利为中心聚类优化目标：罗尔斯主义（平等主义）目标和功利主义目标。", "innovation": "作者引入了两种新的优化目标：罗尔斯主义目标和功利主义目标，并为此目标开发了新的算法，并证明了理论上的保证。实证研究在多个真实世界数据集上显示，作者的方法显著优于现有的公平聚类标准基线方法。", "conclusion": "作者提出的方法通过引入新的优化目标和算法，在真实世界数据集上的表现显著优于现有的公平聚类方法，从而证明了福利为中心的聚类方法的有效性和优势。"}
{"llm_update_time": "20250815", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.10315", "html_url": "https://arxiv.org/abs/2508.10315", "title": "一种由视觉语言预训练模型引导的缓解联邦学习中后门攻击的方法", "title_en": "A Vision-Language Pre-training Model-Guided Approach for Mitigating Backdoor Attacks in Federated Learning", "authors": "Keke Gai,Dongjue Wang,Jing Yu,Liehuang Zhu,Qi Wu", "background": "现有的联邦学习（FL）后门防御方法依赖于客户端数据分布同质性的假设，或者需要一个干净的服务端数据集，这限制了其实用性和有效性。在异质客户端数据分布下防御后门攻击，同时保持模型性能，是一个重大的挑战。", "innovation": "本文提出了一种名为CLIP-Fed的联邦学习后门防御框架，它利用了视觉-语言预训练模型的零样本学习能力。该框架结合了预聚合和后聚合的防御策略，克服了防不平等数据异构性限制的问题。使用多模态大语言模型和频率分析构建并在未使用任何客户端样本的情况下扩展了服务端数据集，以解决隐私问题并增强与多种触发器的覆盖范围。CLIP-Fed通过对增强数据集上的全局模型和CLIP的知识对齐，使用原型对比损失和Kullback-Leibler散度来解决由后门样本引起的类别原型偏差和触发模式与目标标签之间的相关性。", "conclusion": "在代表性数据集上进行的大量实验验证了CLIP-Fed的有效性。与最先进的方法相比，CLIP-Fed在CIFAR-10上的平均降低攻击成功率（ASR）为2.03%，在CIFAR-10-LT上的为1.35%，同时平均提高了MA（混淆矩阵准确率）7.92%和0.48%。"}
{"llm_update_time": "20250815", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.10210", "html_url": "https://arxiv.org/abs/2508.10210", "title": "基于可解释AI的方法用于监测动物健康", "title_en": "An Explainable AI based approach for Monitoring Animal Health", "authors": "Rahul Janaa,Shubham Dixit,Mrityunjay Sharma,Ritesh Kumar", "background": "奶牛场的奶牛健康监测和优化产量是农民面临的关键挑战，因为难以跟踪所有农场动物。这项研究旨在展示基于可解释机器学习（ML）方法的现代数据驱动农业实践，这些方法解释奶牛的活动和行为。通过利用连续的3轴加速度计传感器数据和强大的ML方法与算法，提供了关于奶牛活动的可操作信息，帮助农民做出有根据的决策和实施可持续实践。研究使用基于蓝牙的物联网（IoT）设备和4G网络实现无缝数据传输、即时分析和推理生成，并使用可解释性框架解释模型性能。特别强调了加速度计时间序列数据的预处理，包括统计特征提取、信号处理技术和使用滑动窗口技术的滞后特征。不同窗口长度下多种经过超参数优化的ML模型被用来进行活动分类。K-最近邻分类器表现最佳，训练集上AUC均值为0.98，标准偏差为0.0026，测试集上AUC为0.99。为了保证透明度，使用基于解释性AI的框架，如SHAP解释特征重要性，这些重要信息可以被实践者理解和使用。对重要特征进行了详细的比较，以及所选特征的稳定性分析，支持解释性和实用的ML模型的发展，用于可持续的畜牧管理.", "innovation": "研究基于蓝牙物联网设备和4G网络的无缝数据传输，实现即时分析和推理生成，并且使用可解释性框架，如SHAP，来解释模型性能，增强了模型的透明度。研究特别强调了加速度计时间序列数据的预处理，包括统计特征提取、信号处理技术和滞后特征的使用。通过K-最近邻分类器实现了最好的活动分类结果，保证透明度的可解释性AI方法也被用来解释特征的重要性，以满足实践者的理解需求。", "conclusion": "这项研究开发了一种基于可解释AI的方法，用于监测动物健康，通过使用蓝牙物联网设备和4G网络实现无缝数据传输与即时分析，并通过不同的预处理技术和机器学习模型优化，最终实现对奶牛活动的精准监测，促进了可持续畜牧管理的可解释性和实用性。"}
{"llm_update_time": "20250815", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.10404", "html_url": "https://arxiv.org/abs/2508.10404", "title": "通过稀疏自编码器进行层次化扰动的对抗文本生成", "title_en": "Layer-Wise Perturbations via Sparse Autoencoders for Adversarial Text Generation", "authors": "Huizhen Shu,Xuying Li,Qirui Wang,Yuji Kosuga,Mengqiu Tian,Zhuo Li", "background": "随着自然语言处理（NLP）和大型语言模型（LLMs）的迅速发展，生成对抗样本以突破LLMs，成为理解模型漏洞和提高鲁棒性的重要挑战。稀疏特征扰动框架（SFPF）是一种利用大型模型可解释性的新颖的对抗文本生成方法。通过对成功攻击的文本的隐藏层表示进行特征聚类，识别出高激活特征，进一步扰动生成新对抗文本，以平衡攻击效果和安全对齐，从而提高潜在的防御绕过能力。", "innovation": "提出了利用稀疏自编码器稀疏特征扰动框架（SFPF）的新颖对抗文本生成方法。该方法通过对成功攻击的文本隐藏层表示进行特征聚类，识别出高激活特征，进一步扰动生成新对抗文本，从而平衡攻击效果和安全对齐，揭示了对抗样本的新红队策略，并通过实验验证可以绕过最先进的防御机制。", "conclusion": "稀疏特征扰动框架（SFPF）生成的对抗文本可以绕过最先进的防御机制，揭示了当前NLP模型中的持续性漏洞。SFPF的方法效果在不同提示和层级上存在差异，其在其他架构和更大模型上的泛化能力仍需验证。"}
{"llm_update_time": "20250815", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.10383", "html_url": "https://arxiv.org/abs/2508.10383", "title": "通过仅标签弹性变形克服隐式标签噪声实现稳健的语义分割性能", "title_en": "Unlocking Robust Semantic Segmentation Performance via Label-only Elastic Deformations against Implicit Label Noise", "authors": "Yechan Kim,Dongho Yoon,Younkwan Lee,Unse Fatima,Hong Kook Kim,Songjae Lee,Sanga Park,Jeong Ho Park,Seonjong Kang,Moongu Jeon", "background": "以往的研究主要集中在处理严重的（或明确的）标签噪声，而现实中的数据集还存在潜在的（或隐含的）标签瑕疵。这些瑕疵源于客观挑战，如对象边界模糊和标注者差异。虽然这些轻度和潜在的噪声并未明确存在，但它们仍然会损害模型性能。典型的数据增强方法在对图像和标签应用相同变换时，可能会放大这些隐含的瑕疵，从而限制模型的泛化能力。", "innovation": "本文提出了一种新颖的数据增强框架NSegment+，该框架解耦图像和标签的变换以处理这种现实中的噪声。通过仅对分割标签引入受控的弹性变形而不改变原始图像，该方法鼓励模型专注于学习对象结构的鲁棒表示，即便存在轻微的标签不一致。广泛的实验表明，NSegment+能够持续提高性能，分别在Vaihingen、LoveDA、Cityscapes和PASCAL VOC数据集上实现mIoU提升2.29、2.38、1.75和3.39，并且这些增益在与其他训练技巧结合使用时可以进一步提升，凸显了解决隐式标签噪声的重要性。", "conclusion": "这些结果表明，NSegment+能够在不额外添加复杂功能的情况下显著提高语义分割性能，同时显示出应对隐式标签噪声的潜在增益。"}
{"llm_update_time": "20250815", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.10414", "html_url": "https://arxiv.org/abs/2508.10414", "title": "MCP2OSC：自然语言驱动的参数化控制", "title_en": "MCP2OSC: Parametric Control by Natural Language", "authors": "Yuan-Yi Fan", "background": "文本提示能够使内容创作变得直观，但可能无法达到复杂任务的高精度要求；旋钮或滑块控制则可以实现精确调整，但增加了操作的复杂性。为填补文本提示和旋钮控制之间的差距，本文提出了一个新型的MCP（模型上下文协议）服务器和一套独特的提示设计标准，旨在通过自然语言提示探索基于OSCKnob的参数化控制。通过14个实际的问答示例和最佳实践以及通用提示模板，研究表明，结合MCP2OSC服务器与Claude的语言生成能力，能够有效生成OSC消息，并且能够解析、搜索、可视化和调试OSC消息，以及管理OSC地址模式。", "innovation": "1. 提出了一个新的MCP（模型上下文协议）服务器和一套独特的提示设计标准，以便通过自然语言提示探索基于OSCKnob的参数化控制。2. 利用大语言模型（LLM）处理和生成可以解释为人类可读的OSCKnob消息，从而增强人机协作并处理复杂的OSCKnob开发任务。3. 结合MCP2OSC服务器与Claude语言生成能力，实现了自然语言生成OSC消息的功能，并且能够解析、搜索、可视化和调试OSC消息，管理OSC地址模式。", "conclusion": "本文通过利用大语言模型的强处理能力和生成人类可读的OSCKnob消息的优势，提供了一种在网络协议层次上将创意应用到MCP的新视角，其结果表明其作为基于大语言模型的多媒体设备通用控制机制的潜在价值。"}
{"llm_update_time": "20250815", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.10423", "html_url": "https://arxiv.org/abs/2508.10423", "title": "MASH: 合作异构多智能体强化学习在单腿人形机器人运动中的应用", "title_en": "MASH: Cooperative-Heterogeneous Multi-Agent Reinforcement Learning for Single Humanoid Robot Locomotion", "authors": "Qi Liu,Xiaopeng Zhang,Mingshan Tan,Shuaikang Ma,Jinliang Ding,Yanjie Li", "background": "大多数现有的方法通常使用单智能体强化学习算法来控制单腿人形机器人或使用多智能体强化学习（MARL）算法来处理多机器人系统任务。然而，本文提出了一个不同的范式：将MARL应用于单腿人形机器人以优化其运动。通过这种方式，该论文聚焦于将MARL技术引入单腿人形机器人控制领域。", "innovation": "本文提出了一种新颖的方法，即多智能体强化学习方法用于单腿人形机器人运动（MASH），将多智能体中的每个肢体（腿部和手臂）视为独立的智能体，探索机器人动作的空间，同时通过一个全局评论家进行协同学习。MASH在训练收敛速度和提高全身协同能力方面表现出色，优于传统的单智能体强化学习方法。", "conclusion": "通过使用MASH，本文推进了MARL在单腿人形机器人控制中的应用，为高效的运动策略提供了新的见解。"}
{"llm_update_time": "20250815", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.10332", "html_url": "https://arxiv.org/abs/2508.10332", "title": "儿童语音中自我监督表示的分层分析：用于儿童语音的年龄和性别分类", "title_en": "Layer-Wise Analysis of Self-Supervised Representations for Age and Gender Classification in Children's Speech", "authors": "Abhijit Sinha,Harishankar Kumar,Mohit Joshi,Hemant Kumar Kathania,Shrikanth Narayanan,Sudarsana Reddy Kadiri", "background": "儿童的语音表现出对年龄和性别分类的挑战，由于音高、发音和发育特征的高度变异性。目前，自我监督学习（SSL）模型在成年人语音任务中表现出色，但在儿童语音中的表现尚未充分探索。此前的研究主要集中在成年人的语音特征上，对于儿童语音的特性编码方法尚处于发展阶段，特别是在年龄和性别分类方面，需要进一步研究以了解不同SSL模型在不同深度下的表现和机制。这项研究旨在通过详细分析四种Wav2Vec2变体，利用PFSTAR和CMU Kids数据集，探索SSL模型在儿童语音中的潜在应用。研究表明，早期层（1-7）比更深的层更有效地捕捉到与说话者相关的特征，而更深的层则越来越关注语言信息。进一步应用PCA可以提高分类效果，减少冗余并突出最具信息量的组件。实验结果显示，Wav2Vec2-large-lv60模型在CMU Kids数据集上达到了97.14%（年龄）和98.20%（性别）的分类准确率，而在PFSTAR数据集上的分类准确率分别为86.05%和95.00%。这些结果揭示了SSL模型的结构和深度对于分类的影响，从而支持了针对儿童语音接口的更精细、适应性更强的策略的发展。", "innovation": "本文创新性地使用了四种Wav2Vec2不同版本模型，通过分层分析的方法，揭示了在不同SSL（自我监督学习）模型深度下，语音编码的差异及其对儿童年龄和性别分类的影响。通过这种方法，进一步确认了早期模型层次对于捕捉说话者特性的优势，并通过PCA（主成分分析）增加了分类的准确性，为儿童语音识别技术的发展提供了新的视角和方法论支持。", "conclusion": "研究结果表明，Wav2Vec2模型的不同深度对儿童语音的年龄和性别分类具有不同的影响。早期层更有效地捕获具体的说话者特征，而深层层则更多地关注语言信息。研究还发现，通过应用PCA，可以显著提高分类准确性。这为开发更加适应儿童语音识别系统提供了指导，有助于设计更具针对性和适应性的儿童语音接口。"}
{"llm_update_time": "20250815", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.10416", "html_url": "https://arxiv.org/abs/2508.10416", "title": "CorrectNav: 自纠正飞轮赋能视觉-语言-行动导航模型", "title_en": "CorrectNav: Self-Correction Flywheel Empowers Vision-Language-Action Navigation Model", "authors": "Zhuoyuan Yu,Yuxing Long,Zihan Yang,Chengyan Zeng,Hongwei Fan,Jiyao Zhang,Hao Dong", "background": "现有视觉-语言导航模型在执行指令时往往会偏离正确的轨迹，但这些模型缺乏有效的错误校正能力，无法从错误中恢复。这些缺陷限制了模型的性能优化空间和应用潜力。为了克服这一挑战，本文提出了自纠正飞轮（Self-correction Flywheel）这样一个全新的后训练范式。这个范式转变了对模型在训练集中错误轨迹的看法，将其视为有价值的数据来源，而非弱点。", "innovation": "本文提出了一种新颖的后训练范式——自纠正飞轮。它通过识别模型在训练集上的错误轨迹中的偏差来生成自我纠正的数据，并自动为感知和行动提供燃料。该方法揭示了在重新评估模型时可以发现新的错误轨迹，并通过多次飞轮迭代，逐步提升基于单目RGB的视觉-语言-行动导航模型CorrectNav的性能。实验结果显示，CorrectNav在R2R-CE和RxR-CE基准测试中分别达到了65.1%和69.3%的新最佳成功率，超越了之前的最佳视觉-语言-行动导航模型8.2%和16.4%。此外，实验证实在多种室内外环境中的真实机器人测试中，CorrectNav展现了卓越的错误纠正、动态障碍物避免和长指令跟随能力。", "conclusion": "通过自纠正飞轮，我们不仅改进了视觉-语言-行动导航模型的错误校正能力，还展示了其在不同环境下的卓越动态表现。"}
{"llm_update_time": "20250815", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.10370", "html_url": "https://arxiv.org/abs/2508.10370", "title": "eMamba: 针对边缘计算中Mamba模型的高效加速框架", "title_en": "eMamba: Efficient Acceleration Framework for Mamba Models in Edge Computing", "authors": "Jiyong Kim,Jaeho Lee,Jiahao Lin,Alish Kanani,Miao Sun,Umit Y. Ogras,Jaehyun Park", "background": "基于状态空间模型（SSM）的机器学习架构近年来在处理序列数据方面引起了广泛关注。Mamba作为一种最新的序列到序列的SSM模型，在准确性和计算效率方面都优于最新的Transformer模型。由于其在资源受限的边缘设备上具有较高的潜力，但缺乏专门用于边缘设备的硬件加速框架。因此，本文提出了一种名为eMamba的端到端硬件加速框架，专门用于在边缘平台上部署Mamba模型。eMamba通过使用针对目标应用的硬件友好的替代方案来替代复杂的归一化层，并且对昂贵的操作如SiLU激活和指数运算进行近似处理，从而最大化计算效率。", "innovation": "eMamba框架通过对Mamba模型进行优化和近似，并进行近似意识的神经架构搜索（NAS）来调整参数，实现与最先进的技术相比，在使用更少参数的同时保持了竞争力的准确性。它还能够在大规模自然语言任务上很好地泛化，并且在AMD ZCU102 FPGA和ASIC上通过GF 22 nm工艺进行量化和实现，实验结果显示与基线解决方案相比，在延迟、吞吐量、面积、功率和能量消耗方面分别降低了4.95-5.62倍、2.22-9.95倍、4.77倍、9.84倍和48.6倍，同时保持了竞争力的准确性。", "conclusion": "eMamba框架被证明是一种有效的解决方案，可以显著提高Mamba在边缘设备上的部署效率和准确度。它为未来在资源受限环境下部署复杂的机器学习模型提供了新的途径。"}
{"llm_update_time": "20250815", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.10397", "html_url": "https://arxiv.org/abs/2508.10397", "title": "PQ-DAF: 基于姿势的质量控制数据增强以解决数据稀少的司机分心检测问题", "title_en": "PQ-DAF: Pose-driven Quality-controlled Data Augmentation for Data-scarce Driver Distraction Detection", "authors": "Haibin Sun,Xinghui Song", "background": "司机分心检测对于提高交通安全和减少道路事故至关重要，但现有模型在现实场景中部署时通常会出现泛化能力下降的问题。这一局限主要是由于实际环境中数据注释成本高，导致训练数据集和目标部署环境之间存在显著的数据域移位。", "innovation": "我们提出了一种基于姿势的质量控制数据增强框架（PQ-DAF），利用视觉-语言模型进行样本筛选，以经济高效的方式扩展训练数据，并增强跨域鲁棒性。PQ-DAF 使用渐进条件扩散模型（PCDMs）准确捕捉关键的司机姿势特征并合成多样的训练样本，并基于置信阈值引入一个样本质量评估模块，以过滤低质量的合成样本，确保数据集的可靠性。", "conclusion": "大量实验表明，PQ-DAF 显著提升了在数据稀缺条件下少量样本司机分心检测的性能，在模型泛化方面取得重要进步。"}
{"llm_update_time": "20250815", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.10419", "html_url": "https://arxiv.org/abs/2508.10419", "title": "ComoRAG：一种认知启发的记忆组织RAG模型，用于状态式长叙事推理", "title_en": "ComoRAG: A Cognitive-Inspired Memory-Organized RAG for Stateful Long Narrative Reasoning", "authors": "Juyuan Wang,Rongchen Zhao,Wei Wei,Yufeng Wang,Mo Yu,Jie Zhou,Jin Xu,Liyan Xu", "background": "长篇故事和小说的理解一直是具有挑战性的领域，这主要是因为它们复杂的情节和角色及实体之间反复变化、不断演化的关联关系。考虑到大语言模型（LLM）在长时间段推理中的推理能力减弱以及高计算成本，检索式方法在实践中仍然具有重要地位。然而，传统的检索增强生成（RAG）方法由于它们单步非状态性的检索过程，往往忽略了捕捉长时范围上下文中的动态关联关系。因此，提出了一种具备持续推理能力的方法ComoRAG。", "innovation": "ComoRAG基于认知启发的原则，将推理过程视为获取新证据与巩固过往知识之间的动态演变过程，类似于处理记忆相关信号时的人脑认知过程。当遇到推理瓶颈时，ComoRAG会进行迭代的推理循环，利用动态记忆工作区支持长时上下文推理，并通过生成探索性查询和整合新证据到全局记忆池中，促进查询的解决过程。在四个具有挑战性的长上下文叙事基准测试中，ComoRAG相较于强RAG基线具有显著的相对增益，达到约11%，并且特别适用于复杂查询需要全局理解的情境。", "conclusion": "ComoRAG提供了一种基于检索的长上下文理解的方法，结合了状态式推理的合理性，为长叙事推理领域提出了一种有理论依据的认知启发式范式。源代码已公开发布。"}
{"llm_update_time": "20250815", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.10409", "html_url": "https://arxiv.org/abs/2508.10409", "title": "AnalogSeeker：模拟电路设计领域的开源基础语言模型", "title_en": "AnalogSeeker: An Open-source Foundation Language Model for Analog Circuit Design", "authors": "Zihao Chen,Ji Zhuang,Jinyi Shen,Xiaoyue Ke,Xinyi Yang,Mingjie Zhou,Zhuoyao Du,Xu Yan,Zhouyang Wu,Zhenyu Xu,Jiangli Huang,Li Shang,Xuan Zeng,Fan Yang", "background": "在模拟电路设计领域，数据稀缺是制约研究进展的关键问题。为了克服这一挑战，本文提议AnalogSeeker，这是一种开源的基础语言模型，旨在整合领域知识并提供设计辅助。通过构建基于模拟电路领域知识框架的语料库，并系统地整理和清洁高质量、可访问的教科书，得到了一个文本领域语料库。同时，为了解决模拟电路知识的复杂性，引入了一种粒度化的领域知识精化方法。该方法将原始的未标注领域语料库细分成为典型且粒度化的学习节点，并通过多代理框架将嵌在无结构文本中的隐性知识提炼成带有详细推理过程的问答数据对，从而得到一个粒度精细且可学习的数据集用于微调。", "innovation": "本文创新之处在于提出了包括以下几点：1) 采用基于模拟电路领域知识框架的语料库收集策略；2) 使用粒度化的领域知识精化方法；3) 设计了多代理框架来提取语料库中的隐性知识；4) 探索并分享了一种基于理论分析和实验验证的训练方法；5) 建立了以微调为中心的训练范式并自定义实现了一个邻域自约束监督微调算法。通过这些方法，AnalogSeeker不仅在模拟电路知识评估基准AMSBench-TQA上达到了85.04%的准确率，比原始模型提高了15.67%，还展示了在下游运算放大器设计任务中的有效性。", "conclusion": "本文最终通过自定义实现的邻域自约束监督微调算法，建立了以微调为中心的训练范式，实现了AnalogSeeker。AnalogSeeker不仅在模拟电路知识评估基准上达到了预期目标，还在下游任务中展示了良好的效果。此外，AnalogSeeker已开源供研究使用。"}
{"llm_update_time": "20250815", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.10435", "html_url": "https://arxiv.org/abs/2508.10435", "title": "在张量模型中拆解增强性感知最小化的隐含范数动力学", "title_en": "Unpacking the Implicit Norm Dynamics of Sharpness-Aware Minimization in Tensorized Models", "authors": "Tianxiao Cao,Kyohei Atarashi,Hisashi Kashima", "background": "Sharpness-Aware Minimization (SAM) 已经被证明是一种有效的方法，可以改进过参数化模型的泛化能力。尽管前人已经探索了 SAM 在简单得多尺度不变设置中的隐式正则化效果，但在一般张量化或尺度不变模型中的行为仍然不够完整研究。本文利用尺度不变性剖析了 SAM 在一般张量化模型中的范数动力学。", "innovation": "作者提出了一个名为 Norm Deviation 的全局核心范数不平衡度量，通过梯度流分析推导了它在 SAM 下的演变。证明了 SAM 对 Norm Deviation 的隐式控制由核心范数与其梯度大小之间的协方差决定。基于此发现，提出了一种简单有效的方法，Deviation-Aware Scaling (DAS)，通过数据自适应的方式比例缩放核心范数，模仿这种正则化行为。", "conclusion": "实验表明，DAS 在张量填充、噪声训练、模型压缩和参数高效微调中实现了与 SAM 相媲美的或改进的性能，同时具有更低的计算开销。"}
{"llm_update_time": "20250815", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.10455", "html_url": "https://arxiv.org/abs/2508.10455", "title": "RealAC：一种在各领域适用的生成现实且可行的因素解释框架", "title_en": "RealAC: A Domain-Agnostic Framework for Realistic and Actionable Counterfactual Explanations", "authors": "Asiful Arefeen,Shovito Barua Soumma,Hassan Ghasemzadeh", "background": "现有的因果解释方法通过严格的、手工地制作的约束或特定领域的知识来限制特征之间的依赖关系，这限制了这些方法在各种情况下的普遍适用性和捕捉复杂、非线性关系的能力。此外，这些方法通常不满足用户指定的偏好和需求，有时所产生的解释是因果上不可信的，或者在实际操作中不可行。", "innovation": "RealAC 提供了一种领域通用的框架，用于生成现实且可行的因素解释，该框架通过对事实与因素实例对之间的特征联合分布的对齐，自动保留下特征间的复杂依赖关系，而无需依赖明确的领域知识。同时，该框架允许最终用户“冻结”不可更改或不想更改的属性，在优化过程中抑制这些冻结特征的变化。", "conclusion": "在三个合成和两个真实数据集上的评估表明，RealAC 在保持现实性和可操作性之间达到了平衡，其方法在因果边分值、依赖关系保持得分和IM1现实度量方面优于最先进的基准技术和基于大型语言模型的因素生成技术，并提供了一种因果意识和用户中心的因素生成解决方案。"}
{"llm_update_time": "20250815", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.10480", "html_url": "https://arxiv.org/abs/2508.10480", "title": "Pinet: 使用正交投影层优化具有硬约束的神经网络", "title_en": "Pinet: Optimizing hard-constrained neural networks with orthogonal projection layers", "authors": "Panagiotis D. Grontas,Antonio Terpin,Efe C. Balta,Raffaello D'Andrea,John Lygeros", "background": "介绍了用于确保神经网络输出满足凸约束条件的输出层。该方法结合了操作符拆分和隐函数定理，以便在前向传播中实现快速可靠的投影，在反向传播中实现投影。该方法被用作参数化约束优化问题的可行设计优化代理。", "innovation": "提出了一种名为$\\Pi$net的方法，该方法利用操作符拆分在前向传播中实现快速可靠的投影，并利用隐函数定理在反向传播中实现投影，使得在解决单个问题时比传统求解器更快，批量解决问题时更快。与最先进的学习方法相比，$\\Pi$net在训练时间、解决方案质量、对超参数调整的鲁棒性方面更优，同时保持类似推理时间。", "conclusion": "最后，$\\Pi$net被用于解决具有非凸轨迹偏好的多车辆运动规划问题，并提供了一个采用JAX实现的GPU兼容包，具有有效的调优启发式。"}
{"llm_update_time": "20250815", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.10469", "html_url": "https://arxiv.org/abs/2508.10469", "title": "增强稀疏点云数据处理以实现隐私保护的人体动作识别", "title_en": "Enhanced Sparse Point Cloud Data Processing for Privacy-aware Human Action Recognition", "authors": "Maimunatu Tunau,Vincent Gbouna Zakka,Zhuangzhuang Dai", "background": "人体动作识别（HAR）在医疗健康、健身追踪和辅助生活技术中发挥着重要作用。传统的基于视觉的HAR系统虽然有效，但也存在隐私问题。毫米波雷达传感器提供了隐私保护的替代方案，但由于其点云数据稀疏且噪声大，所以也带来了一些挑战。文献中已有三种主要的数据处理方法——基于噪声的密度空间聚类（DBSCAN）、匈牙利算法以及卡尔曼滤波——被广泛用于提高雷达数据的质量和连续性。但是，这些方法在单独使用和组合使用的效果方面还没有进行全面的评估。", "innovation": "本文通过使用MiliPoint数据集，对DBSCAN、匈牙利算法和卡尔曼滤波三种方法进行了详细的性能分析，并评估了它们在个体使用、两两组合以及三者结合使用的效果。此外，本文还针对这些方法提出了改进方案，以提高准确性。研究结果为每个方法及其组合提供了重要的见解，为基于毫米波的HAR系统的未来发展提供了指导。", "conclusion": "本文的结果提供了每个方法及其组合的强项和权衡，对基于毫米波的HAR系统未来工作具有指导意义。"}
{"llm_update_time": "20250815", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.10436", "html_url": "https://arxiv.org/abs/2508.10436", "title": "多重阶段语音增强中的交替Approach-Putt模型", "title_en": "Alternating Approach-Putt Models for Multi-Stage Speech Enhancement", "authors": "Iksoon Jeong,Kyung-Joong Kim,Kang-Hun Ahn", "background": "语音增强旨在从嘈杂的语音信号中去除噪声，同时保留语音内容。然而，语音增强网络经常会引入对语音信号的失真，称为伪影，这些失真会降低音频的质量。许多研究表明，为了解决这一问题，需要采用一种后期处理神经网络来减轻这些伪影的引入，本文通过交替使用语音增强模型和提出的Putt模型提升了语音质量。", "innovation": "该研究通过开发一个后处理神经网络模型PuttNet，旨在减轻由语音增强模型引入的伪影。研究者提出了一种交替使用语音增强模型和改进模型进行语音增强的新方法，这种方法能有效提升语音质量，结果在感知质量评分（PESQ）、客观可懂度（STOI）和背景噪声侵入性（CBAK）方面均优于单独应用任一模型的结果。这种方法通过模拟高尔夫中的“putt”（推杆）和“approach”（击球）过程来响应，因此命名为PuttNet。", "conclusion": "通过交替使用语音增强模型和改进的Putt模型，研究实现了显著的语音质量提升。这些结果表明，使用交替方法能够更有效地降低伪影，提高语音信号的清晰度，进而提升了用户体验。"}
{"llm_update_time": "20250815", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.10461", "html_url": "https://arxiv.org/abs/2508.10461", "title": "X-Node: 自解释能力即是全部", "title_en": "X-Node: Self-Explanation is All We Need", "authors": "Prajit Sengupta,Islem Rekik", "background": "图神经网络（GNNs）已经在计算机视觉和医学影像分类任务中取得了最先进的成果，通过捕捉数据实例之间的结构依赖性。然而，它们的决策过程仍然主要是不透明的，这在临床应用中限制了其可信度，尤其是在需要解释性的高风险情境下。现有的GNN解释技术通常是事后和全局的，提供有限的节点级解释或局部推理的洞察。", "innovation": "本文提出了X-Node，这是一种自解释的GNN框架，其中每个节点在预测过程中生成自己的解释。每个节点构造了一个结构化的上下文向量，包括度数、中心性、聚类、特征重要性和局部拓扑中的标签一致性等可解释线索。一个轻量级的推理模块将此上下文映射到一个紧凑的解释向量，该向量实现三个功能：1）通过解码器重构节点的潜在嵌入，以确保诚信性；2）使用预训练的LLM生成自然语言解释；3）通过将解释反馈到消息传递管道的“文本注入”机制来引导GNN。", "conclusion": "X-Node在两个来源于MedMNIST和MorphoMNIST的图数据集上进行了评估，并与GCN、GAT和GIN等骨干网络结合使用。结果显示，X-Node既能保持竞争力的分类精度，又能产生忠实的、节点级的解释。"}
{"llm_update_time": "20250815", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.10490", "html_url": "https://arxiv.org/abs/2508.10490", "title": "关于基于梯度的解释的复杂性-忠実性权衡", "title_en": "On the Complexity-Faithfulness Trade-off of Gradient-Based Explanations", "authors": "Amir Mehrpanah,Matteo Gamba,Kevin Smith,Hossein Azizpour", "background": "虽然ReLU网络在视觉数据中广泛应用，但它们存在尖锐的过渡，有时依赖个别像素进行预测，导致基于梯度的常规解释变得嘈杂且难以解释。现有方法如GradCAM通过构建代理模型来平滑解释，但会牺牲忠实地度。论文分析了这一现象并介绍了一个统一的频谱框架来系统地研究平滑度、忠实地度及其之间的权衡。", "innovation": "论文提出了一个统一的频谱框架，用于系统分析和量化解释的平滑度、忠实地度及其权衡。利用这一框架，量化并正则化ReLU网络对高频信息的贡献，提供了一种识别这种权衡的原理性方法。还定义并测量了不同后处理方法中的“解释差距”。", "conclusion": "理论发现被不同设计选择、数据集和消融实验所验证，展示了该框架的有效性。"}
{"llm_update_time": "20250815", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.10504", "html_url": "https://arxiv.org/abs/2508.10504", "title": "基于逻辑的实体解析进展：增强ASPEN的局部合并和最优性准则", "title_en": "Advances in Logic-Based Entity Resolution: Enhancing ASPEN with Local Merges and Optimality Criteria", "authors": "Zhliang Xiang,Meghyn Bienvenu,Gianluca Cima,Víctor Gutiérrez-Basulto,Yazmín Ibáñez-García", "background": "ASPEN是一个现有的基于ASP（逻辑编程语言）的系统，用于实体消解（Entity Resolution）。ASPEN只支持所谓的全局合并，即将所有匹配的实体引用常量（例如作者ID）视为等效并相应地合并。然而，当解决数据值时，局部合并更为合适，因为有些‘J. Lee’实例可能指的是‘Joy Lee’，而其他实例则应与‘Jake Lee’匹配。", "innovation": "ASPER+扩展了ASPEN的功能，包括：1) 支持本地合并，2) 为优选解决方案引入新的最优性标准（如最小化规则违反或最大化支持合并的规则数量）。主要贡献包括（1）对各种最优解概念进行形式化和计算分析，（2）在实际数据集上的广泛实验评估，证明局部合并和新最优性标准对准确性和运行时的影响。", "conclusion": "通过ASPER+，增强了基于ASP的实体消解系统ASPEN的功能，并通过实验验证了局部合并和新最优性标准的效果，提高了准确性和效率。"}
{"llm_update_time": "20250815", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.10494", "html_url": "https://arxiv.org/abs/2508.10494", "title": "统一多代理框架以实现通用多模态理解与生成", "title_en": "A Unified Multi-Agent Framework for Universal Multimodal Understanding and Generation", "authors": "Jiulin Li,Ping Huang,Yexin Li,Shuo Chen,Juewen Hu,Ye Tian", "background": "现实世界中的多模态应用通常需要任何形式到任何形式的能力，这使得在文本、图像、音频和视频等多种模态之间进行理解和生成成为可能。然而，将自回归语言模型（LLMs）的推理能力和扩散模型的高保真生成能力整合在一起仍然具有挑战性。现有方法依赖于固定或紧密耦合的管道，限制了灵活性和可扩展性。", "innovation": "本文提出了MAGUS（Multi-Agent Guided Unified Multimodal System），这是一种模块化的框架，通过两个分离阶段：认知和反思来统一多模态理解和生成。在认知阶段，三个条件化的多模态LLM代理（Perceiver、Planner和Reflector）参与协作对话以执行结构化的理解和计划。在反思阶段，采用了一种增长感知搜索机制，该机制以互为增强的方式协调LLM推理和扩散生成。MAGUS支持插拔式可扩展性、可扩展的任何形式到任何形式的模态转换以及语义对齐，所有这些都不需要联合训练。", "conclusion": "实验表明MAGUS在包括图像、视频和音频生成以及跨模态指令跟随在内的多个基准测试中优于强大的基准和最先进的系统。值得注意的是，在MME基准测试中，MAGUS超越了强大的闭源模型GPT-4o。"}
{"llm_update_time": "20250815", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.10528", "html_url": "https://arxiv.org/abs/2508.10528", "title": "Med-GLIP: 采用大规模标注数据推进医疗语言-图像预训练", "title_en": "Med-GLIP: Advancing Medical Language-Image Pre-training with Large-scale Grounded Dataset", "authors": "Ziye Deng,Ruihan He,Jiaxiang Liu,Yuan Wang,Zijie Meng,Songtao Jiang,Yong Xie,Zuozhu Liu", "background": "医疗图像地基旨在将自然语言短语与医学图像中的特定区域对齐，是智能诊断、视觉问答（VQA）和自动化报告生成（MRG）的基础任务。然而，现有研究受限于模态覆盖有限、注释粗糙以及缺乏统一的可泛化的地基框架。", "innovation": "本文构建了一个包含超过530万区域级注释的大型医疗地基数据集Med-GLIP-5M，跨越七个成像模态，涵盖了不同的解剖结构和病理发现。基于此数据集，提出了Med-GLIP框架，这是一种模态感知的地基框架，通过从多样化的训练数据中隐式获得层次语义理解，能够识别多层次结构，如区分肺部和肺炎病灶。广泛实验表明，Med-GLIP在多个地基基准测试中表现出色，并在医疗VQA和报告生成等下游任务中实现了显著的性能提升。", "conclusion": "构建的Med-GLIP-5M 数据集将很快公开，将有助于推动医疗图像理解的进一步发展，提升相关下游任务的性能。"}
{"llm_update_time": "20250815", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.10559", "html_url": "https://arxiv.org/abs/2508.10559", "title": "Fake Speech Wild：在社交媒体平台上检测假语音", "title_en": "Fake Speech Wild: Detecting Deepfake Speech on Social Media Platform", "authors": "Yuankun Xie,Ruibo Fu,Xiaopeng Wang,Zhiyong Wang,Ya Li,Zhengqi Wen,Haonnan Cheng,Long Ye", "background": "随着语音生成技术的迅速发展，仿真人声（deepfake语音）在社交媒体平台上泛滥。尽管现有的语音假信息检测措施在公共数据集上取得了令人鼓舞的结果，但它们在跨场景应用中表现欠佳。", "innovation": "本文提出了一种名为Fake Speech Wild (FSW)的新数据集，其中包括来自四个不同媒体平台的254小时真实和仿真人语音数据，主要关注社交媒体。通过使用公开数据集和高级自监督学习（SSL）为基础的检测措施，本文评估了当前检测措施在实际场景中的效果，并研究了数据增强策略以提高检测措施在社交媒体上检测假人声的鲁棒性。", "conclusion": "通过扩充公开数据集并加入FSW的训练集，本文显著提高了真实世界中仿真人声的检测性能，在所有评估集上的平均等错误率（EER）达到3.54%。"}
{"llm_update_time": "20250815", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.10507", "html_url": "https://arxiv.org/abs/2508.10507", "title": "多样本抗锯齿和约束优化在3D高斯溅射中的应用", "title_en": "Multi-Sample Anti-Aliasing and Constrained Optimization for 3D Gaussian Splatting", "authors": "Zheng Zhou,Jia-Chen Zhang,Yu-Jie Xiong,Chun-Ming Xia", "background": "近年来，3D高斯溅射在实时新颖视图合成方面取得了显著的进步，但场景优化过程中几何约束不足往往会使得精细细节模糊，特别是在高频纹理和尖锐不连续区域。", "innovation": "提出了一种结合多样本抗锯齿（MSAA）与双重几何约束的综合优化框架。通过自适应混合四元子样本计算像素颜色，有效减少了高频组件中的锯齿伪像。该框架引入了两种约束：一种是通过动态梯度分析优先处理欠重构区域的自适应加权策略，另一种是边界梯度差异约束，用于在物体边界处实施几何正则化。这种针对性优化使得模型能够优先分配计算资源到需要细化的区域，同时保持全局一致性。", "conclusion": "在多个基准测试中的广泛实验表明，该方法在细节保存方面达到最先进的性能，特别是在保留高频纹理和尖锐不连续区域方面，同时保持实时渲染效率。定量和感知研究结果均证实，与基线方法相比，在结构相似性（SSIM）和感知质量（LPIPS）方面有统计意义上的显著提升。"}
{"llm_update_time": "20250815", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.10491", "html_url": "https://arxiv.org/abs/2508.10491", "title": "对比学习ECOC：用于对抗防御的学习输出码", "title_en": "Contrastive ECOC: Learning Output Codes for Adversarial Defense", "authors": "Che-Yu Chou,Hung-Hsuan Chen", "background": "尽管一热编码常用于多分类，但它并非总是最有效的编码机制。纠错输出码（ECOC）通过将每个类别映射到唯一的编码词，解决了多分类问题。传统ECOC方法依赖于手动设计或随机生成的码本，耗时且可能在不同的数据集上产生次优结果。本文提出了三种基于对比学习的自动码本学习模型，可以直接从数据中学习和适配码本，增强了在四种数据集上的模型对抗攻击的鲁棒性，优于两种基线方法。", "innovation": "本文提出了一种基于对比学习的自动码本学习模型，可以直接从数据中学习和适应码本，提高了模型在对抗攻击下的鲁棒性，优于传统的手动设计或随机生成的码本方法。", "conclusion": "提出的三种基于对比学习的码本学习模型在多种数据集上的表现优于两种基线方法，在对抗攻击下的鲁棒性更强。结果的代码可以从提供的链接下载。"}
{"llm_update_time": "20250815", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.10557", "html_url": "https://arxiv.org/abs/2508.10557", "title": "PTQAT: 一种用于3D感知任务的混合参数高效量化算法", "title_en": "PTQAT: A Hybrid Parameter-Efficient Quantization Algorithm for 3D Perception Tasks", "authors": "Xinhao Wang,Zhiwei Lin,Zhongyu Xia,Yongtao Wang", "background": "PTQ和QAT是两种主流的模型量化方法。PTQ通常会导致量化模型性能不可接受的下降，而QAT由于权重fine-tuning需要大量GPU内存和延长训练时间。为了高效部署3D感知网络，本文提出了一种新颖的混合量化算法PTQAT。", "innovation": "PTQAT选择关键层进行QAT fine-tuning，对剩余层进行PTQ。该方法通过在量化偏差较小的层进行fine-tuning提高模型量化精度，从而在保持性能的同时更高效地冻结了近50%的可量化层。此外，PTQAT是一种通用量化方法，支持不同量化比特宽度（4比特）和多种模型架构，包括CNN和Transformer。", "conclusion": "实验结果表明，我们的方法在nuScenes上的一系列3D感知任务中（包括目标检测、语义分割和占用预测）优于仅使用QAT的方法，目标检测任务中获得了0.2%-0.9%的NDS和0.3%-1.0%的mAP增益，在语义分割和占用预测上分别获得了0.3%-2.0%的mIoU增益，同时fine-tuning更少的权重。"}
{"llm_update_time": "20250815", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.10552", "html_url": "https://arxiv.org/abs/2508.10552", "title": "当语言凌驾其上：揭示多模态大语言模型中的文本主导现象", "title_en": "When Language Overrules: Revealing Text Dominance in Multimodal Large Language Models", "authors": "Huyu Wu,Meng Tang,Xinhan Zheng,Haiyun Jiang", "background": "多模态大语言模型（MLLMs）在多样化的多模态任务中展现出了显著的能力，但这些模型严重依赖于文本来进行推理，对于其他模态（如图像、视频、音频、时间序列和图形）的利用不足。尽管先前的研究已经意识到了这种现象，并通常将其归因于数据偏差或模型结构，但没有进行系统的跨模态研究。本文首次对文本主导现象进行了系统的跨模态研究，并提出了两种评价指标：模态主导指数（MDI）和注意力效率指数（AEI）以衡量这种不平衡。研究发现，文本主导现象不仅显著而且普遍存在于各种模态中，并且提出了注意力稀释、融合架构设计的影响以及任务设计偏向文本输入三个根本原因。", "innovation": "本文提出了一种简单的令牌压缩方法，通过这种方法，例如对LLaVA-7B进行应用，可以将模型的模态主导指数MDI显著降低。同时，研究提供了一种方法论框架为开发更公平和全面的多模态语言模型奠定了基础。", "conclusion": "通过这种方法论框架的研究分析和简单的令牌压缩方法，为多模态语言模型的发展提供了一个新的视角，有助于实现模态间的平衡，增强模型对非文本信息的理解和处理能力。"}
{"llm_update_time": "20250815", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.10548", "html_url": "https://arxiv.org/abs/2508.10548", "title": "使用门控奖励稳定长期多轮强化学习", "title_en": "Stabilizing Long-term Multi-turn Reinforcement Learning with Gated Rewards", "authors": "Zetian Sun,Dongfang Li,Zhuoen Chen,Yuhuai Qin,Baotian Hu", "background": "长期内的强化学习任务中奖励稀疏性依然是一个显著的挑战，现有的基于结果的奖励塑造方法难以定义有意义的即时奖励，且往往引入了偏差或者需要显式任务分解。验证性奖励塑造使用分步批评家，但即时奖励与长期目标之间的不对齐可能导致奖励成瘾与次优策略。本文将在软件工程任务的背景下探讨这一问题，其中多轮推理与基于规则的验证是关键。现有的方法难以应对长期奖励与即时奖励之间的错配问题。为了更好地解决此问题，本文提出了一种称为‘门控奖励积累’（G-RA）的新方法，该方法只在高阶（长期）奖励满足预设阈值时才累积即时奖励，以此来确保强化学习（RL）优化的稳定。实验结果显示，G-RA显著提升了完成率与修改率，同时避免了奖励错配导致的策略退化。", "innovation": "引入了SWE导向的RL框架，支持多轮交互、容器化执行以及自定义奖励函数；提出了门控奖励积累（G-RA）方法，确保长期奖励满足一定阈值后才累积即时奖励，从而避免奖励错配导致的策略退化问题。", "conclusion": "我们的研究结果强调了长期内稳定奖励积累的重要性，并提供了一种有效的解决方案。G-RA方法在SWE-bench Verified和kBench试验中得到了验证，显著改善了奖励匮乏环境下的学习效果，为未来的长期内强化学习任务提供了实用的改进方法。"}
{"llm_update_time": "20250815", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.10616", "html_url": "https://arxiv.org/abs/2508.10616", "title": "Fourier-Guided Attention Upsampling for Image Super-Resolution", "title_en": "Fourier-Guided Attention Upsampling for Image Super-Resolution", "authors": "Daejune Choi,Youchan No,Jinhyung Lee,Duksu Kim", "background": "传统的上采样方法，如子像素卷积，虽然高效，但常难以重建高频细节并引入鬼影伪影。这篇论文探讨了通过引入一种轻量级的上采样模块——频域指导注意力模块（Frequency-Guided Attention, FGA）来解决这些问题。", "innovation": "FGA模块包括以下创新点：基于傅里叶特征的多层感知机（MLP）用于位置频率编码；跨分辨率相关注意力层进行自适应空间对齐；以及频域L1损失进行光谱保真监督。FGA仅新增0.3M参数就能够在多个不同的上采样框架中提供一致的性能提升。", "conclusion": "实验结果表明，FGA在多种数据集上平均提高了0.12~0.14 dB的PSNR，并且在频域一致性上提高了29%。FGA在减少鬼影伪影和保留细节数方面表现出色，证明了其作为传统上采样方法的实用替代方案的有效性。"}
{"llm_update_time": "20250815", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.10595", "html_url": "https://arxiv.org/abs/2508.10595", "title": "基于梯度的方法的光谱属性研究", "title_en": "On Spectral Properties of Gradient-based Explanation Methods", "authors": "Amir Mehrpanah,Erik Englesson,Hossein Azizpour", "background": "深入理解深度网络的行为对于增强对其结果的信任至关重要。尽管已经有很多研究工作致力于解释其预测，但研究人员仍面临可靠性问题，这些问题可归因于形式化不足。现有的解释方法通常通过实验性的手段进行设计，但缺乏足够的正式分析。本研究采用新颖的概率和光谱视角来正式分析这些解释方法，揭示了由于使用梯度而导致的普遍光谱偏差，并阐明了一些已通过实验发现的常见设计选择，尤其是平方梯度和输入扰动的使用。", "innovation": "本研究创新性地采用了概率和光谱视角来正式分析基于梯度的解释方法。主要贡献包括：1) 揭示了由于使用梯度而导致的普遍光谱偏差；2) 识别了通过实验发现的一些常见设计选择，特别是平方梯度和输入扰动的使用。此外，研究还探讨了扰动超参数对解释方法选择的影响，并提出了两种基于该理论的研究建议：确定标准扰动尺度的机制和名为SpectralLens的聚合方法。", "conclusion": "本研究通过定性和定量评估，证实了理论结果，并提出了基于提出的正式分析框架来解决解释方法中的不一致性问题的方法。"}
{"llm_update_time": "20250815", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.10594", "html_url": "https://arxiv.org/abs/2508.10594", "title": "FreeGAD：一种无训练但有效的图异常检测方法", "title_en": "FreeGAD: A Training-Free yet Effective Approach for Graph Anomaly Detection", "authors": "Yunfeng Zhao,Yixin Liu,Shiyuan Li,Qingfeng Chen,Yu Zheng,Shirui Pan", "background": "图异常检测（GAD）旨在识别图中偏离多数节点的行为，对于社交网络和电子商务等应用至关重要。尽管基于深度学习的方法在GAD方面取得了进展，但现有方法由于复杂的训练过程和资源密集型特性，常常面临高部署成本和不佳的可扩展性。出乎意料的是，我们的实验证据表明，通常认为至关重要的深度GAD方法的训练阶段，实际上对异常检测性能的贡献低于预期。", "innovation": "提出了一种名为FreeGAD的新颖且有效的无训练图异常检测方法。FreeGAD利用亲和力门控残差编码器生成异常感知的表示，并通过锚点引导的统计偏差来计算异常评分。这种方法无需训练和迭代优化，在多个跨领域的基准数据集上展示了出色的异常检测性能、效率和可扩展性。", "conclusion": "FreeGAD在多个跨领域的基准数据集上实现了优异的异常检测性能、效率和可扩展性，证明了该方法的有效性，同时也指出了现有的GAD方法可能高估了训练阶段的重要性。"}
{"llm_update_time": "20250815", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.10556", "html_url": "https://arxiv.org/abs/2508.10556", "title": "用于 OOD 检测的检索增强提示", "title_en": "Retrieval-Augmented Prompt for OOD Detection", "authors": "Ruisong Han,Zongbo Han,Jiahao Zhang,Mingyue Cheng,Changqing Zhang", "background": "没有广泛可用的外部分类样本或同分布数据时，现有的 OOD 检测方法常常依赖于这些数据来生成外类样本的信息以进行训练，但受限于有限的外类样本和现实测试中的 OOD 样本不匹配，这些方法往往无法提供足够的语义监督，从而导致性能不佳。现有方法难以对未见过的数据样本进行准确的识别和分类，这在现实应用中是一个严重的问题，特别是在机器学习模型可靠部署于实际环境中时，准确识别与训练数据分布不同的测试样本显得尤为关键。", "innovation": "本文提出了一种名为 Retrieval-Augmented Prompt (RAP) 的新型 OOD 检测方法。RAP 通过检索外部知识增强预训练的视觉-语言模型的提示，提供增强的语义监督以进行 OOD 检测。在训练过程中，RAP 根据外部文本知识与异常样本的联合相似性检索描述性词语，并将其用于增强模型的 OOD 提示。在测试过程中，RAP 可以根据遇到的 OOD 样本实时动态更新 OOD 提示，使模型能够快速适应测试环境。实验结果表明，RAP 在大规模 OOD 检测基准中达到了最先进的性能。在 ImageNet-1k 数据集上的 1-shot OOD 检测中，RAP 将平均 FPR95 降低了 7.05%，并且使 AUROC 提高了 1.71%。此外，全面的消融研究验证了每个模块的有效性以及本文方法的潜在动机。", "conclusion": "本文提出了 Retrieval-Augmented Prompt (RAP) 方法，通过检索外部文本知识增强模型在 OOD 检测中的语义监督。实验表明 RAP 在各种 OOD 检测基准上的性能显著优于现有方法。该方法通过实时更新 OOD 提示，有效提升了模型的适应性和检测准确性。"}
{"llm_update_time": "20250815", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.10666", "html_url": "https://arxiv.org/abs/2508.10666", "title": "经典和量子物理中的深度学习", "title_en": "Deep Learning in Classical and Quantum Physics", "authors": "Timothy Heightman,Marcin Płodzień", "background": "科学进步紧密依赖于新研究工具的出现。由于量子系统固有的复杂性，深度学习（DL）能够高效地探索大规模参数空间、从实验数据中提取模式，并通过数据驱动的方式为研究方向提供指导。这些能力已经在改进量子控制协议和加速具有特定量子性质的材料的发现等任务中发挥作用，使DL/ML成为下一代量子科学家必备的技能。然而，DL的能力也带来了风险，如模型可能会过度拟合噪声数据、模糊因果结构以及生成缺乏物理解释的结果。因此，认识到其局限性并采取缓解策略对于科学研究的严谨性至关重要。", "innovation": "这些讲义提供了对量子应用中深度学习的全面、研究生级别的介绍，将概念性解释与实际示例相结合。旨在帮助读者决定何时以及如何有效应用DL，理解其实际约束，并负责任地将AI方法应用于量子物理、化学和工程问题中。", "conclusion": "讲义的目标是让读者学会在量子物理、化学和工程问题中负责任地应用和选择合适的深度学习方法，同时也提高了对AI方法局限性的认识。"}
{"llm_update_time": "20250815", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.10646", "html_url": "https://arxiv.org/abs/2508.10646", "title": "SPHENIC：空间转录组学中基于拓扑的多视图聚类方法", "title_en": "SPHENIC: Topology-Informed Multi-View Clustering for Spatial Transcriptomics", "authors": "Chenkai Guo,Yikai Zhu,Jing Yangum,Renxiang Guan,Por Lip Yee,Guangdun Peng,Dayu Hu", "background": "当前的空间转录体测序聚类方法虽然取得了进展，但还存在两个主要局限性：一是空间转录体图谱通常存在噪声，典型的空间拓扑学习仅考虑个体细胞或其交互图，导致易受低质量的空间拓扑信号影响；二是空间邻域信息建模不足，导致低质量的空间嵌入。这些问题限制了对细胞亚群的全面识别和理解。", "innovation": "本文提出了一种名为SPHENIC的新型方法，该方法结合空间位置信息，利用拓扑学增强的空间小区域整合聚类方法。SPHENIC通过在聚类网络中引入不变的拓扑特征实现稳定表示学习，同时设计了空间约束和分布优化模块（SCDOM），该模块增强了一细胞与空间邻居的相似性，减少与非邻居细胞的相似性，从而生成有利于聚类的空间嵌入。", "conclusion": "在14个基准空间转录体切片上的大量实验表明，SPHENIC在空间聚类任务上的表现优于现有的最先进方法，提升了3.31%-6.54%的性能。"}
{"llm_update_time": "20250815", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.10667", "html_url": "https://arxiv.org/abs/2508.10667", "title": "AddressVLM: 使用大型视觉语言模型进行跨视角对齐调整的图像地址本地化", "title_en": "AddressVLM: Cross-view Alignment Tuning for Image Address Localization using Large Vision-Language Models", "authors": "Shixiong Xu,Chenghao Zhang,Lubin Fan,Yuan Zhou,Bin Fan,Shiming Xiang,Gaofeng Meng,Jieping Ye", "background": "大型视觉语言模型（LVLMs）在粗粒度的地理定位方面表现出色，尤其是国家或城市级别的定位，但在城市区域内的街道级精确定位方面却存在问题。本文探讨了将城市级地址定位功能整合到LVLMs中，以通过街景图像实现灵活的与地址相关的问题回答。然而，街景视觉问题回答（VQA）数据只能提供微小的视觉线索，导致微调后的模型表现不佳。", "innovation": "本研究提出了跨视角对齐调整机制，包括街景视图和街景图像嫁接机制以及自动标签生成机制，来解决基于微小视觉线索的问题。通过这种机制，LVLM的街道分布全局理解得到增强。此外，还构建了基于匹兹堡和旧金山图像地址本地化数据集的两个街景VQA数据集。实验证明，AddressVLM在两个数据集上的平均地址定位准确率分别比相应的LVLMs高出9%和12%。", "conclusion": "提出的AddressVLM使用两阶段训练协议：跨视角对齐调整和地址定位调整，改善了LVLM的街道分布理解和地址定位性能，实现了在街景图像上的精细地址定位。"}
{"llm_update_time": "20250815", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.10655", "html_url": "https://arxiv.org/abs/2508.10655", "title": "序列优于并行：学习持续统一以实现多模态视觉目标跟踪和基准测试", "title_en": "Serial Over Parallel: Learning Continual Unification for Multi-Modal Visual Object Tracking and Benchmarking", "authors": "Zhangyong Tang,Tianyang Xu,Xuefeng Zhu,Chunyang Cheng,Tao Zhou,Xiaojun Wu,Josef Kittler", "background": "多模态视觉对象跟踪（MMVOT）任务由于不同模态的互补性质而备受关注。现有的做法将所有传感器类型的数据混合在一起进行单一训练过程，从数据为中心的角度构建并行范式，旨在在涉及任务的联合分布上取得全局最优。然而，缺乏一个包含所有类型数据的统一基准，导致在分离基准上进行评估，这造成了训练与测试之间的一致性问题，从而导致性能下降。", "innovation": "该研究提出了两个方面的创新：1. 提出一个统一体系基准（UniBench300），通过集成多个任务数据，减少推理过程次数，时间消耗减少27%；2. 将统一过程重新定义为序列格式，逐步整合新任务，这一过程中的性能下降可以视为对先前任务知识的遗忘，从而与持续学习（CL）的哲学相契合，激发了将CL注入统一过程的可能性。在两个基线和四个基准上的广泛实验表明，UniBench300的重要性及其在支持稳定统一过程中的优越性。此外，性能下降与网络容量呈负相关，而模态差异性导致不同任务间不同的下降程度（RGBT > RGBD > RGBE在MMVOT中），这些为未来多模态视觉研究提供了宝贵的见解。", "conclusion": "实验证明了UniBench300和持续学习（CL）在多模态视觉目标跟踪中的重要性和优越性。此外，网络容量与性能下降呈负相关，模态差异性导致不同任务间不同的下降程度，提供对未来多模态视觉研究的见解。所有源代码和提出的基准可以在指定的网址获取。"}
{"llm_update_time": "20250815", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.10695", "html_url": "https://arxiv.org/abs/2508.10695", "title": "从自然语言反馈中学习以实现个性化问答", "title_en": "Learning from Natural Language Feedback for Personalized Question Answering", "authors": "Alireza Salemi,Hamed Zamani", "background": "个性化对于提升语言技术的有效性和用户满意度至关重要，特别是在信息检索任务如问答中。当前的个人化方法主要依赖于检索增强生成（RAG），并通过带有标量奖励信号的强化学习来训练模型如何使用检索到的个人上下文。但这种方法有时提供的奖励反馈较弱，难以提供有效的指导，影响了学习效率和个性化质量。", "innovation": "提出了VAC（自然语言反馈的新颖框架），该框架用基于用户概况和问题叙述生成的自然语言反馈（NLF）取代了标量奖励，作为丰富的可操作的监督信号，使策略模型能够迭代优化输出和内化有效的个性化策略。训练过程交替优化反馈模型和在改进的回复上微调策略模型，最终策略模型在推理过程中不再需要反馈。基准测试LaMP-QA包含三个不同领域，确认了该方法在个性化问答方面的显著改进。", "conclusion": "在LaMP-QA基准上的测试结果表明，这种框架在个性化问答方面取得了显著改进，进一步的人类评估也证明了生成回答的高质量。这些结果显示，自然语言反馈为优化个性化问题回答提供了更有效的信号。"}
{"llm_update_time": "20250815", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.10687", "html_url": "https://arxiv.org/abs/2508.10687", "title": "持续的孟加拉手语翻译：借助图形减轻手语注解成本", "title_en": "Continuous Bangla Sign Language Translation: Mitigating the Expense of Gloss Annotation with the Assistance of Graph", "authors": "Safaeid Hossain Arib,Rabeya Akter,Sejuti Rahman", "background": "全球有数百万人受到失聪和听力障碍的影响。手语作为失聪和听力障碍人士的一种复杂沟通方式，在重视口头语言的社会中常常受到低估，造成沟通障碍和社会排斥。为解决这一问题，持续的孟加拉手语翻译项目旨在通过改进翻译方法来缩小这一差距。尽管最近的方法利用了变压器架构取得了最先进的结果，我们的方法将基于图的方法与变压器架构结合。这种结合，即变压器和STGCN-LSTM架构的融合，证明在无手语词翻译中更为有效。", "innovation": "我们的贡献包括架构融合，探索了多种融合策略，并在多种手语数据集上（RWTH-PHOENIX-2014T、CSL-Daily、How2Sign和BornilDB v1.0）达到了新的最先进的性能。我们的方法在所有数据集上的表现均优于当前的翻译结果，显示出BLEU-4分数分别为4.01、2.07和0.5的显著改进，超越了GASLT、GASLT和slt_how2sign在RWTH-PHOENIX-2014T、CSL-Daily和How2Sign数据集中的表现。此外，我们首次在BornilDB v1.0数据集上进行了基准测试，为未来的研究设定了标准，强调了无手语词翻译的重要性，以提高聋人和听力障碍者的沟通可访问性。", "conclusion": "我们的方法为未来的研究设定了基准，强调了无手语词翻译的重要性，以提高聋人和听力障碍者的沟通可访问性。"}
{"llm_update_time": "20250815", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.10672", "html_url": "https://arxiv.org/abs/2508.10672", "title": "高效且保护隐私的混合生成融合面部识别数据集生成", "title_en": "Hybrid Generative Fusion for Efficient and Privacy-Preserving Face Recognition Dataset Generation", "authors": "Feiran Li,Qianqian Xu,Shilong Bao,Boyu Han,Zhiyong Yang,Qingming Huang", "background": "本文论文解决了一个面部识别模型训练的数据集构建挑战，特别是确保新构建的数据集不包含现有公共面部数据集中的任何身份重叠问题。为了解决这个问题，他们从基准HSFace数据集开始进行彻底清理，通过混合Expert策略结合面部嵌入聚类和GPT-4o辅助验证来识别并移除标记错误或不一致的身份。接着，使用Stable Diffusion生成合成身份，并利用Vec2Face快速生成多达49个一致的合成身份变体，从而融合了GAN基于和扩散模型生成的样本，以高效构建多样和高质量的数据集。为了应对合成身份之间高度的视觉相似性，他们采用了课程学习策略，在训练中早期引入合成身份，以便模型能够从较简单的样本逐步过渡到更难的样本。最终构建的数据集包含每个身份50张图片，并且所有新生成的身份都经过主流面部数据集的核查，以确保没有身份泄露的问题。", "innovation": "本文提出了一种结合GAN基于和扩散模型生成的样本的混合生成融合方法，用于高效且保护隐私地生成面部识别数据集。该方法通过Mixture-of-Experts（MoE）策略对HSFace数据集进行清洁，通过Stable Diffusion生成合成身份，并使用Vec2Face快速生成多个身份变体。通过课程学习策略应用于合成身份的早期训练中，使模型逐步适应不同难易度的样本。最终构建的数据集与主流面部数据集无重叠身份，并显著提高了模型在不同身份规模下的性能。", "conclusion": "本文提出的方法在竞赛中获得第一名，并且实验结果显示，该数据集在10K、20K和100K身份尺度上提高了模型的性能。生成的数据集解决了现有数据集的重叠身份问题，并确保了数据的隐私性。"}
{"llm_update_time": "20250815", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.10701", "html_url": "https://arxiv.org/abs/2508.10701", "title": "REFN：一种针对1天/多天利用的网络强化学习框架", "title_en": "REFN: A Reinforcement-Learning-From-Network Framework against 1-day/n-day Exploitations", "authors": "Tianlong Yu,Lihong Liu,Ziyi Zhou,Fudu Xing,Kailong Wang,Yang Yang", "background": "由于大量设备部署和延迟补丁（平均补丁时间超过60天）导致的1天或多天漏洞利用，对网络设备构成了严重的威胁。现有的防护措施，包括基于主机的补丁修补和基于网络的过滤，因为它们在跨多种设备的可扩展性、与嵌入式或遗留系统的兼容性方面以及手动补丁验证过程中的错误率都存在不足。", "innovation": "我们引入了REFN (Reinforcement Learning From Network)框架，利用大规模语言模型（LLMs）自主生成网络过滤器以防止1天或多天利用。REFN独特地使用由在线网络奖励驱动的强化学习（RL），而不是传统的基于人类反馈的强化学习（RLHF），保证了可扩展性。通过统一部署在边缘安全网关（如亚马逊Eero）上，REFN保证了兼容性，并通过在线验证使用实际网络流量提供了鲁棒性。此外，它通过基于代理的验证解决了一些核心挑战，比如扩大现有的LLMs在漏洞修复方面的专业知识，将自然语言与网络实施之间的差距，以及解决LLM的幻觉和非确定性问题。", "conclusion": "REFN在22种1天或多天利用的测试中展示了有效性（比其他替代方案高出21.1%的准确性）、效率（平均补丁时间3.65小时）和可扩展性（可以轻松扩展到10,000台设备）。REFN代表了一种训练LLMs快速预防大规模1天或多天利用的初步步骤。"}
{"llm_update_time": "20250815", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.10732", "html_url": "https://arxiv.org/abs/2508.10732", "title": "APFL: 双流最小二乘分析个性化联邦学习", "title_en": "APFL: Analytic Personalized Federated Learning via Dual-Stream Least Squares", "authors": "Kejia Fan,Jianheng Tang,Zhirui Yang,Feijiang Han,Jiaxu Li,Run He,Yajiang Huang,Anfeng Liu,Houbing Herbert Song,Yunhuai Liu,Huiping Zhuang", "background": "个性化联邦学习（PFL）旨在通过协作训练为每个客户端提供个性化的模型。然而，现有方法通常对非IID数据敏感，严重影响了集体泛化能力，进而阻碍了后续的个性化努力。这个问题需要有效解决，以提高模型的性能和适用性。", "innovation": "本文提出了一种名为APFL（Analytic Personalized Federated Learning）的方法，利用双流最小二乘技术。APFL通过使用一个固定的骨干模型进行特征提取，随后发展双流分析模型来同时实现集体泛化和个体个性化。APFL的核心创新在于采用了共享的主要流和专门的精炼流，实现了在数据分布差异性较大时依然保持个性化模型的唯一性。实验结果表明，APFL在多个数据集上的表现优于现有最先进的基线，精度优势达到至少1.10%-15.45%。这次创新显著提升了模型的泛化能力和个性化效果。", "conclusion": "本文通过引入APFL方法，有效地解决了现有PFL方法对非IID数据的敏感性问题，确保了模型在数据多样性的场景下依然具有良好的性能和个性化能力。实验验证了APFL的有效性和优越性。"}
{"llm_update_time": "20250815", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.10758", "html_url": "https://arxiv.org/abs/2508.10758", "title": "从晶体点云数据集中原生可训练的稀疏注意力机制", "title_en": "Natively Trainable Sparse Attention for Hierarchical Point Cloud Datasets", "authors": "Nicolas Lapautre,Maria Marchenko,Carlos Miguel Patiño,Xin Zhou", "background": "在大型物理系统数据集上解锁变压器的潜力，依赖于克服注意力机制的二次时间复杂度。本文探讨了将Erwin架构与原生稀疏注意力机制（NSA）结合，以提高大型物理系统中变压器模型的效率和感受野，解决二次注意力复杂性的挑战。研究人员适应NSA机制用于非序贯数据，开发了Erwin NSA模型，并在宇宙学模拟、分子动力学和大气压力建模三个物理科学数据集上进行了评估，结果显示该模型的性能与原始Erwin模型相当或更好。此外，他们还复现了Erwin论文中的实验结果，验证了其实现的正确性。", "innovation": "提出了一种适应非序贯数据的原生可训练稀疏注意力机制（Erwin NSA），并在大型物理系统数据集上进行了验证，显示了性能上的改进。", "conclusion": "Erwin NSA模型在宇宙学模拟、分子动力学和大气压力建模数据集上验证了其性能，与原始Erwin模型相当或更优，并验证了Erwin论文中实验结果的正确性。"}
{"llm_update_time": "20250815", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.10760", "html_url": "https://arxiv.org/abs/2508.10760", "title": "FROGENT:全过程药物设计智能体", "title_en": "FROGENT: An End-to-End Full-process Drug Design Agent", "authors": "Qihua Pan,Dong Xu,Jenna Xinyi Yao,Lijia Ma,Zexuan Zhu,Junkai Ji", "background": "目前用于药物发现的强大人工智能工具分布在隔离的网页应用、桌面程序和代码库中，这导致科学家们需要管理不兼容的界面和专业脚本，过程繁琐且重复。因此，需要一种集成多种动态生物化学数据库、可扩展工具库以及任务特定AI模型的智能体框架来解决这些问题。", "innovation": "提出了一个名为FROGENT的全智能体药物设计框架。FROGENT利用大型语言模型和模型上下文协议，以动态集成多个生物化学数据库、可扩展工具库和任务特定AI模型。FROGENT能够动态执行复杂的药物发现工作流，包括靶标识别、分子生成和逆合成规划等任务。通过与六种逐步先进的ReAct样智能体进行实证对比，FROGENT在靶点发现方面提高了最佳基线性能三倍，在相互作用表征方面提高了一倍，显著优于开源模型Qwen3-32B和商业模型GPT-4o。", "conclusion": "FROGENT的开发表明，简化药物发现管道可以大大提升研究人员的工作效率。同时，通过实际案例验证了FROGENT的实用性和通用性。"}
{"llm_update_time": "20250815", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.10751", "html_url": "https://arxiv.org/abs/2508.10751", "title": "Pass@k 训练以适配性地平衡大型推理模型的探索与利用", "title_en": "Pass@k Training for Adaptively Balancing Exploration and Exploitation of Large Reasoning Models", "authors": "Zhipeng Chen,Xiaobo Qin,Youbin Wu,Yue Ling,Qinghao Ye,Wayne Xin Zhao,Guang Shi", "background": "基于验证性奖励的强化学习（RLVR）通常使用Pass@1作为奖励，但在平衡探索与利用方面存在挑战，导致政策更倾向于保守行为，容易收敛于局部最优解。因此，选择一个合适的奖励指标至关重要。尽管Pass@k在评估中被使用，但它的用法未能充分关联到RLVR中大型语言模型的探索能力。本文就这一问题进行了研究和探讨，提出了Pass@k训练方法来改善探索能力，并通过分析揭示了探索与利用之间的非冲突性关系，同时提出了优势函数设计在未来的应用潜力。", "innovation": "提出了Pass@k训练方法，通过基于Pass@k的奖励来提升策略模型的探索能力，发现探索与利用之间并非固有的冲突目标，而是可以相互促进，首次对Pass@k奖励方法进行了科学的分析和推导，从而直接设计优势函数，并探索了强化学习验证性奖励中的优势设计，实现了有效且高效的处理过程。", "conclusion": "本文的研究揭示了探索和利用并非固有的冲突目标，提出优势函数设计是未来研究的方向，Pass@k训练能够有效提升RLVR中大型推理模型的探索与利用平衡，展示出了初步的很有前景的结果，突显了其潜在的研究价值。"}
{"llm_update_time": "20250815", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.10729", "html_url": "https://arxiv.org/abs/2508.10729", "title": "EgoCross: Benchmarking Multimodal Large Language Models for Cross-Domain Egocentric Video Question Answering", "title_en": "EgoCross: Benchmarking Multimodal Large Language Models for Cross-Domain Egocentric Video Question Answering", "authors": "Yanjun Li,Yuqian Fu,Tianwen Qian,Qi'ao Xu,Silong Dai,Danda Pani Paudel,Luc Van Gool,Xiaoling Wang", "background": "近期，多模态大型语言模型（MLLMs）在自视角视频问答（EgocentricQA）方面取得了显著进展。然而，现有基准和研究主要集中在烹饪和清洁等日常活动中。现实世界的应用不可避免地会遇到领域变换的问题，即目标领域在视觉风格和语义内容上存在显著差异。目前的模型难以在日常生活以外的领域推广使用，这凸显了当前模型的局限性。为此，引入EgoCross基准，旨在评估MLLMs在EgocentricQA中的跨领域通用性。EgoCross涵盖手术、工业、极限运动和动物视角四个多样化且具有挑战性的领域，覆盖约1,000个QA对，共计798个视频片段，涉及预测、识别、定位和计数四个关键QA任务。", "innovation": "EgoCross 是一个综合性的基准，设计用于评估 MLLMs 在 EgocentricQA 中的跨域通用性。该基准涵盖了手术、工业、极限运动和动物视角四个多样化且具有挑战性的领域，代表了现实和高影响的应用场景。它提供约1,000个QA对和798个视频片段，涵盖预测、识别、定位和计数等关键任务。每个QA对都提供了开放问答（OpenQA）和封闭问答（CloseQA）格式，以支持精细评估。此外，作者还进行了一系列试点研究，如微调和强化学习，以探索潜在的改进方法。", "conclusion": "实验结果显示，现有大多数通用或专门用于自视角的 MLLMs 难以在日常生活以外的领域中推广使用，凸显了当前模型的局限性。我们希望通过 EgoCross 和我们的配套分析，为适应性、稳健的自视角视频理解进步提供基础。所有数据和代码将在以下链接发布：this https URL."}
{"llm_update_time": "20250815", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.10776", "html_url": "https://arxiv.org/abs/2508.10776", "title": "采用决策导向学习方法估计全球最低方差组合协方差", "title_en": "Estimating Covariance for Global Minimum Variance Portfolio: A Decision-Focused Learning Approach", "authors": "Juchan Kim,Inwoo Tae,Yongjae Lee", "background": "投资组合优化是风险管理的关键部分，涉及风险与回报的量化权衡。传统的统计估计器和机器学习算法通常通过最小化均方误差（MSE）来确定输入参数，这可能导致次优的投资决策。本文旨在通过采用决策导向学习（DFL）方法，直接优化决策质量而非预测误差，来构建全球最小方差投资组合（GMVP）。", "innovation": "本文通过理论推导GMVP的决策损失梯度，利用其关于自身主成分的属性，采用DFL方法来优化投资决策，实证研究表明DFL方法能够在实际中提供优于预测导向估计方法的决策性能。此外，本文还详尽分析了DFL方法在GMVP构建中的机制，包括其降低波动性能力、决策驱动特性以及估计特性。", "conclusion": "本研究证明，与注重预测的方法相比，DFL方法能更好地进行投资决策，特别是在实际应用中，能够更有效地减少投资组合的波动性，提升决策质量。"}
{"llm_update_time": "20250815", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.10774", "html_url": "https://arxiv.org/abs/2508.10774", "title": "Video-BLADE: Block-Sparse Attention Meets Step Distillation for Efficient Video Generation", "title_en": "Video-BLADE: Block-Sparse Attention Meets Step Distillation for Efficient Video Generation", "authors": "Youping Gu,Xiaolong Li,Yuhao Hu,Bohan Zhuang", "background": "扩散变换器在高质量视频生成方面目前处于领先位置，但它们的缓慢迭代去噪过程以及长时间序列的二次注意力成本造成了显著的推断瓶颈。尽管步进蒸馏和稀疏注意力机制分别证明了作为加速策略的有效性，但将这两种方法结合起来面临巨大的挑战。步进蒸馏后单独训练稀疏注意力机制需要昂贵的高质量视频数据。", "innovation": "我们提出了一种名为BLADE的数据无关联合训练框架，引入了（1）一种自适应区块稀疏注意力（ASA）机制，用于动态生成内容感知的稀疏性掩码，以专注于时空特征的计算；（2）一种基于轨迹分布匹配（TDM）的感知稀疏步进蒸馏范式，在蒸馏过程中直接整合稀疏性，而不是将其作为单独的压缩步骤，从而实现快速收敛。", "conclusion": "我们的框架在不同规模上展示了显著的效率提升。在Wan2.1-1.3B模型上，BLADE相对于50步基线实现了14.10倍的整体推理加速。对于CogVideoX-5B这类具有短视频序列长度的模型，我们的框架提供了稳健的8.89倍速度提升。加速的伴随是质量的一致性提升。在VBench-2.0基准测试上，BLADE将CogVideoX-5B和Wan2.1-1.3B的得分分别提升到了0.569（从0.534）和0.570（从0.563），进一步的人类评估也得到了更高的评分。我们已公开发布代码和模型权重。"}
{"llm_update_time": "20250815", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.10785", "html_url": "https://arxiv.org/abs/2508.10785", "title": "在节点级图异常检测中增强自动编码器的公平性", "title_en": "Enhancing Fairness in Autoencoders for Node-Level Graph Anomaly Detection", "authors": "Shouju Wang,Yuchen Song,Sheng'en Li,Dongmian Zou", "background": "图异常检测（GAD）已成为各个领域中越来越重要的任务。随着图神经网络（GNNs）的快速发展，GAD方法取得了显著的性能提升。然而，在GAD中的公平性问题仍然没有得到充分探索。由于GNN基于的图异常检测模型可能会继承并放大训练数据中存在的偏见，从而可能导致不公平的结果。现有的努力大多集中在开发公平的GNN上，而大部分方法集中在节点分类任务上，通常依赖于简单的层结构，而不是用于异常检测的最常用架构（如自动编码器结构）。", "innovation": "针对基于自动编码器的GAD模型中的公平性问题，本文提出了一种名为DECAF-GAD的框架，该框架在保持GAD性能的同时，缓解了偏见。通过引入结构因果模型（SCM）来解缠敏感属性与学习表示，基于此因果框架，本文提出了一个专门针对自动编码器的架构和一个公平性导向的损失函数。实验结果表明，DECAF-GAD不仅实现了与基准GAD方法相当的异常检测性能，而且在公平性指标上也显著提高。", "conclusion": "通过广泛的实验（包括合成和真实数据集），本文证明了DECAF-GAD框架不仅在异常检测性能上具有竞争力，而且显著提高了公平性指标。这些结果表明，新技术为处理自动编码器的公平性问题提供了有效解决方案。"}
{"llm_update_time": "20250815", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.10713", "html_url": "https://arxiv.org/abs/2508.10713", "title": "在GPU上进行天线的电磁模拟以应用于机器学习", "title_en": "Electromagnetic Simulations of Antennas on GPUs for Machine Learning Applications", "authors": "Murat Temiz,Vemund Bakken", "background": "该研究利用图形处理单元（GPUs）作为电磁（EM）模拟开源软件（gprMax）的后端，为天线设计和优化中的机器学习应用设计了一个天线模拟框架。由于EM仿真计算复杂度高，产生足够的训练样本在有限的时间内极具挑战性，因此研究使用GPUs来减少计算时间。此外，研究还对比了各种机器学习和深度学习模型在天线参数估计性能上的表现。", "innovation": "提出了一个基于GPUs的天线模拟框架，该框架利用开源软件gprMax生成大量天线模拟结果，以支持机器学习和代理模型应用。研究对比了不同水平的GPU与高端CPU在计算性能上的差异，并展示了开放源码的EM模拟软件在细粒度空间解析度下，其仿真结果与商业软件相似。", "conclusion": "初级GPU在计算性能上明显优于高端CPU，高性能游戏GPU的计算性能大约是高端CPU的18倍。此外，开源的EM模拟软件在微带天线仿真中能够与商业软件产生相同水平的结果。"}
{"llm_update_time": "20250815", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.10798", "html_url": "https://arxiv.org/abs/2508.10798", "title": "The SET Perceptual Factors Framework: Towards Assured Perception for Autonomous Systems", "title_en": "The SET Perceptual Factors Framework: Towards Assured Perception for Autonomous Systems", "authors": "Troi Williams", "background": "自主系统的未来预计将带来显著的社会效益，但它们的部署引发了关于安全性和平信任的担忧。其中一个重要担忧是确保机器人感知的可靠性，因为感知能力是安全决策的基础。感知错误往往是由复杂的但常见的环境因素导致的，这些错误可能导致事故，从而损害公众的信任。为了应对这一担忧，我们引入了自、环境和目标（Self, Environment, and Target，简称SET）感知因素框架。该框架旨在系统地分析天气、遮挡或传感器限制等外部因素如何负面地影响感知质量，以及这些因素如何影响物体检测等感知任务。通过使用自、环境和目标状态树和因素树对这些因素进行分类和建模，从而为评估感知风险提供了一个透明和标准化的工具。", "innovation": "本文提出了一种名为SET（自、环境和目标）感知因素框架的新方法。该框架通过分析和建模环境、自和目标相关因素对感知任务的影响，促进了对感知风险的量化评估。这种框架可以更透明、更标准化地识别、建模以及交流感知风险，从而帮助提升公众对自主系统的信任和理解。", "conclusion": "本文提出的SET感知因素框架通过提供一个透明且标准化的方法来识别、建模和传播感知风险，旨在促进对自主系统的安全性保障，并培养公众对于这些系统的更好地理解与信任。"}
{"llm_update_time": "20250815", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.10860", "html_url": "https://arxiv.org/abs/2508.10860", "title": "从黑箱到透明性：在高校教室中通过可解释AI增强自动口译评估", "title_en": "From Black Box to Transparency: Enhancing Automated Interpreting Assessment with Explainable AI in College Classrooms", "authors": "Zhaokun Jiang,Ziyin Zhang", "background": "近年来，机器学习的进步激发了对自动化口译质量评估日益增长的兴趣。然而，现有的研究存在对语言使用质量检查不足、由于数据稀缺性和不平衡导致建模效果不佳以及缺乏解释模型预测结果的努力等问题。为了解决这些问题，本文提出一个包含特征工程、数据增强和可解释机器学习的多维度建模框架。该方法优先考虑可解释性，仅采用与构建相关的透明特征，并使用Shapley值分析进行解释。", "innovation": "本文提出的框架解决了传统机器学习模型中的黑箱问题，通过特征工程和数据增强提高了解释性，特别利用Shapley值分析帮助理解模型预测背后的原因。通过此框架，研究人员能够识别出影响口译质量的关键因素，并提供详细诊断反馈，帮助学习者自我调节学习。", "conclusion": "通过特别强调解释性，本文提出的方法提供了一种可扩展、可靠且透明的评测方法，作为传统人工评估的替代方案，有利于提供详细的诊断反馈并支持自我调节学习，而这是单一自动化评分所不能提供的。"}
{"llm_update_time": "20250815", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.10839", "html_url": "https://arxiv.org/abs/2508.10839", "title": "强化语言模型在序列决策中的应用", "title_en": "Reinforced Language Models for Sequential Decision Making", "authors": "Jim Dilkes,Vahid Yazdanpanah,Sebastian Stein", "background": "大型语言模型（LLMs）在序列决策中显示出潜力，但其应用受限于对大型、计算成本高昂模型的依赖。现有的训练后方法针对单轮交互设计，无法处理多步任务中的归因问题。为解决这一问题，作者引入了多步群组相对策略优化（MS-GRPO），这是一种新的训练后LLM代理算法，基于形式化的文本介导随机博弈（TSMG）和语言代理策略（LAP）框架。该算法通过将整个累计回合奖励分配到每个个体回合步来实现归因。通过一种新颖的绝对优势加权回合采样策略，进一步提高了训练性能。此方法在Snake和Frozen Lake游戏中测试了一个30亿参数模型，结果显示，对于Frozen Lake任务，训练后的30亿参数模型比720亿参数基线模型的表现高出50%。", "innovation": "提出了一种新的算法——多步群组相对策略优化（MS-GRPO），该算法结合了形式化的文本介导随机博弈（TSMG）和语言代理策略（LAP）框架，解决了多步任务中的归因问题，并通过绝对优势加权回合采样策略改善了训练性能。该方法在Snake和Frozen Lake等游戏中进行了验证，展示了其在强化决策表现方面的有效性，相较于大模型基线，具有更好的效果。", "conclusion": "重点训练后的强化语言模型是一种相对于依赖模型规模提升序列决策能力强效且实用的替代方案。"}
{"llm_update_time": "20250815", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.10869", "html_url": "https://arxiv.org/abs/2508.10869", "title": "Medico 2025: Visual Question Answering for Gastrointestinal Imaging", "title_en": "Medico 2025: Visual Question Answering for Gastrointestinal Imaging", "authors": "Sushant Gautam,Vajira Thambawita,Michael Riegler,Pål Halvorsen,Steven Hicks", "background": "该挑战针对医疗领域中的视觉问答（VQA）任务，特别关注胃肠（GI）内窥镜影像。它作为MediaEval任务系列的一部分进行组织。挑战旨在开发可解释的人工智能（XAI）模型，这些模型可以根据GI内窥镜图像回答临床相关的问题，并提供与医学推理相一致的可解释说明。", "innovation": "该挑战引入了两个子任务：（1）使用Kvasir-VQA-x1数据集回答多种视觉问题；（2）生成多模态解释以支持临床决策。此外，通过结合定量性能指标和专家审查的可解释性评估，该任务旨在推动在医疗图像分析中可信的人工智能的发展。挑战采用了一个新的数据集作为基准，并通过细致的指南和参与指南促进参与。", "conclusion": "该挑战不仅促进了VQA系统的性能提高，还强调了系统解释性的重要性，这对于医疗应用来说是至关重要的。通过这些努力，主办方希望推动医学图像分析中可解释人工智能的发展，提高医疗决策的透明度和可靠性。"}
{"llm_update_time": "20250815", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.10887", "html_url": "https://arxiv.org/abs/2508.10887", "title": "探究配置回声态网络以适应代表性基准问题领域的经验研究", "title_en": "Empirical Investigation into Configuring Echo State Networks for Representative Benchmark Problem Domains", "authors": "Brooke R. Weborg,Gursel Serpen", "background": "本文探讨了回声态网络（一种作为水槽计算机的循环神经网络）在四个不同基准问题上的性能，并试图了解各种参数选择及其调整值，以及架构变化对回放状态网络性能的影响。在没有该领域经验的情况下，完全理解这些影响是具有挑战性的，甚至一些超参数优化算法也可能在没有适当的手动选择的前提下难以调整参数值。", "innovation": "提出了关于回声态网络架构配置的启发式规则或经验法则，包括如何选择参数及其值，并指出这些适用于同一领域的其他问题。这些规则将帮助新手填平不了解这一领域所需的经验空白。", "conclusion": "为了展现不同架构设计、参数选择和值对回声态网络性能的冲击，本文通过建模和实验，针对时间序列预测、模式生成、混沌系统预测和时间序列分类这四种不同的问题领域，进行了一系列基准任务的测试。研究表明，理解和掌握这些因素对架构性能的影响是成功构建回声态网络的前提。"}
{"llm_update_time": "20250815", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.10872", "html_url": "https://arxiv.org/abs/2508.10872", "title": "基于TLE的A2C智能体用于地球覆盖轨道路径规划", "title_en": "TLE-Based A2C Agent for Terrestrial Coverage Orbital Path Planning", "authors": "Anantha Narayanan,Battu Bhanu Teja,Pruthwik Mishra", "background": "低地球轨道（LEO）卫星数量不断增加，这给高效部署和安全运行地球观测卫星带来了持续的挑战。任务规划人员现在不仅需要考虑特定任务的要求，还要考虑与活跃卫星和太空碎片发生碰撞的风险。这项工作使用优点行为-批评（A2C）算法构建了一个强化学习框架，以优化卫星轨道参数，实现预定义地面半径内的精确地面覆盖。通过在自定义的OpenAI Gymnasium环境中将问题定义为马尔可夫决策过程（MDP），本研究模拟了轨道动力学，并通过逐步学习调整轨道参数以达成地面覆盖目标。", "innovation": "本研究的主要贡献包括：(1) 基于TLE的物理约束轨道模拟环境；(2) 成功验证了在连续轨道控制中使用actor-critic方法优于信任区域方法；(3) 显示A2C智能体能够实现快速收敛，从而实现适应性卫星部署。这些成果证明了强化学习作为低地球轨道任务规划高效替代方案的适用性。在与代理政策优化（PPO）的比较评估中，A2C显示出优越的性能，累积奖励高5.8倍，收敛时间减少31.5倍。", "conclusion": "这种方法为低地球轨道（LEO）任务规划提供了一种计算效率高、易于扩展和智能化的替代方案，特别适用于实时任务规划应用。"}
{"llm_update_time": "20250815", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.10875", "html_url": "https://arxiv.org/abs/2508.10875", "title": "Diffusion Language Models", "title_en": "A Survey on Diffusion Language Models", "authors": "Tianyi Li,Mingda Chen,Bowei Guo,Zhiqiang Shen", "background": "扩散语言模型（DLMs）正在迅速成为与占主导地位的自回归（AR）范式相竞争的强大而有前途的替代方案。通过迭代去噪过程并行生成标记，DLMs具有降低推理延迟并捕获双向语境的内在优势，从而实现生成过程的精细控制。尽管实现几倍的速度提升，近年来的进步使得DLMs在性能上与自回归模型的竞争者相当，使其成为各种自然语言处理任务的有力选择。", "innovation": "本文提供了一个关于当前DLM景观的全面概述，涵盖了其发展及其与其他范式，如自回归和掩码语言模型的关系，从基础原理到最先进的模型都有涵盖。此外，还对该领域的方法进行了详细的分析，包括从预训练策略到高级后训练方法。研究还详细回顾了DLM的推理策略和优化措施，包括解码并行性、缓存机制和生成质量的改进。同时，还讨论了DLM的最新多模态扩展方法及其在各种实际场景中的应用。", "conclusion": "然而，DLM也存在一些局限性和挑战，包括效率、长序列处理和基础设施要求等。展望未来，提出了推进该快速演变领域进展的研究方向。"}
{"llm_update_time": "20250815", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.10880", "html_url": "https://arxiv.org/abs/2508.10880", "title": "通过模拟搜索LLM代理的隐私风险", "title_en": "Searching for Privacy Risks in LLM Agents via Simulation", "authors": "Yanzhe Zhang,Diyi Yang", "background": "基于大规模语言模型（LLM）的代理的大规模部署将可能引入一个关键的隐私威胁：恶意代理主动与他人进行多轮对话以提取敏感信息。这些动态对话允许攻击者采用适应性强的策略，从而可能导致严重的隐私泄露。由于它们不断演变的特性，手动预知和发现复杂的漏洞变得非常困难。", "innovation": "本研究提出了一种基于搜索的框架，通过模拟关键隐私交互来交替改进攻击者和防御者指令。使用大规模语言模型（LLM）作为优化器，利用多线程并行搜索和跨线程传播来分析模拟路径并迭代提出新指令。研究表明，攻击策略从简单的直接请求演进到多轮策略如冒充和同意伪造，而防御措施则从基于规则的约束发展到身份验证自动机。发现的攻击和防御措施在不同场景和基础模型中具有较强的移植性，显示出了构建隐私意识代理的强大实用性。", "conclusion": "通过此过程，我们发现攻击策略从简单的直接请求提升到复杂的多回合战术，如冒充和同意伪造；同时，防御措施也从基于规则的约束发展到身份验证状态机。这些发现展示了强实际应用价值，为构建隐私意识代理提供了新的视角。"}
{"llm_update_time": "20250815", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2405.20046", "html_url": "https://arxiv.org/abs/2405.20046", "title": "Federated Cross-Training Learners for Robust Generalization under Data Heterogeneity", "title_en": "Federated Cross-Training Learners for Robust Generalization under Data Heterogeneity", "authors": "Zhuang Qi,Lei Meng,Ruohan Zhang,Yu Wang,Xin Qi,Xiangxu Meng,Han Yu,Qiang Yang", "background": "联邦学习可以通过跨训练策略从不同来源的数据中训练模型，以改善泛化能力。但由于数据分布的固有差异，本地模型的优化目标仍然不一致，即使在跨训练后仍然会导致特征空间的异质性。", "innovation": "提出了一种名为FedCT的跨训练方案，包括一致性感知知识广播模块、多视图知识引导表示学习模块和基于混迭的特征增强模块。这些模块分别旨在优化模型分配策略、增强本地知识的保留以及增加特征空间的多样性，从而提高联邦学习过程的效率和在异构数据下的鲁棒泛化性能。", "conclusion": "广泛的实验证明，FedCT可以在本地和全局视图中缓解知识遗忘，从而在性能上超过了最先进的方法。"}
{"llm_update_time": "20250815", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2403.18405", "html_url": "https://arxiv.org/abs/2403.18405", "title": "利用大型语言模型进行法律案例检索中的相关性判断", "title_en": "Leveraging Large Language Models for Relevance Judgments in Legal Case Retrieval", "authors": "Shengjie Ma,Qi Chu,Jiaxin Mao,Xuhui Jiang,Haozhe Duan,Chong Chen", "background": "确定与给定查询相关的法律案件涉及复杂的文本导航和细微的法律推理，通常需要大量时间和专业领域知识来识别关键法律事实并得出合理的法律结论。现有的法律案例数据虽然显示出相似性，但由于缺乏可解释性，使得理解相关性判断的依据变得困难。近年来，随着大型语言模型（LLMs）能力的增强，研究人员开始探索它们在法律领域的潜力。然而，使用通用的大规模语言模型来进行可靠的法律案例相关性判断的方法尚未得到广泛研究。", "innovation": "本文提出了一种新颖的少量示例方法，通过利用LLMs生成与专家一致且可解释的相关性判断。该方法将判断过程分解为多个阶段，模拟人类标注员的工作流程，并允许灵活地整合专家推理以提高相关性判断的准确性。同时，这种方法保证了数据标签的可解释性，提高了对相关性评估过程的透明度和清晰度。通过对比LLMs和人类专家之间做出的相关性判断，实验证明了提出的方法可以提供可靠且有效的相关性评估。此外，通过少量专家监督，本文的方法使大规模语言模型获得了案例分析专业知识，并随后通过基于标注的知识蒸馏将这种能力转移给小型模型。", "conclusion": "我们的方法展示了LLMs在法律案例检索中的潜力，特别是当结合智能标注和少量专家指导时，可以有效提高相关性判断的准确性和透明度，进一步推动了NLP在法律领域的应用研究。"}
{"llm_update_time": "20250815", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.10865", "html_url": "https://arxiv.org/abs/2508.10865", "title": "GPT-5在脑肿瘤MRI推理中的表现", "title_en": "Performance of GPT-5 in Brain Tumor MRI Reasoning", "authors": "Mojtaba Safari,Shansong Wang,Mingzhe Hu,Zach Eidex,Qiang Li,Xiaofeng Yang", "background": "在神经肿瘤学中，准确区分磁共振成像（MRI）中的脑肿瘤类型对于治疗计划至关重要。近年来，大型语言模型（LLMs）的进步使得视觉问答（VQA）方法得以发展，这些方法将图像解释与自然语言推理结合在一起。研究人员评估了GPT-5-mini, GPT-5, GPT-4o和GPT-5-nano在源自三个脑肿瘤分割（BraTS）数据集（胶质瘤（GLI）、脑膜瘤（MEN）和脑转移瘤（MET））的定制脑肿瘤VQA基准上的表现。这些评估基于包含多序列MRI三维视图镶嵌图和结构化临床特征的标准化VQA项目。模型在零样本链式推理设置下接受评估，以视觉和推理任务的准确性进行评估。结果显示，GPT-5-mini在宏平均准确性上表现最好（44.19%），其次是GPT-5（43.71%），GPT-4o（41.49%），和GPT-5-nano（35.85%）。不同类型的肿瘤表现不一，没有任何一种模型在所有组别中占优。这些发现表明，GPT-5家族模型在结构化的神经肿瘤学VQA任务中可以达到中等的准确度，但还不足以满足临床使用的需求。", "innovation": "通过利用大型语言模型（LLMs）的进步，将图像解释与自然语言推理结合，实现了一种视觉问答方法。研究人员评估了几种基于GPT的不同大小的模型在脑肿瘤VQA任务上的表现，展示了如何在零样本环境中进行评估，以提高决策支持系统的准确性和效率。", "conclusion": "GPT-5家族模型在结构化的神经肿瘤学VQA任务中达到了中等的准确度，但还不足以满足临床使用的需求。不同类型的肿瘤在模型的性能上表现不一，没有单一模型在所有组别中占优。"}
{"llm_update_time": "20250815", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.15758", "html_url": "https://arxiv.org/abs/2507.15758", "title": "LAPO: Internalizing Reasoning Efficiency via Length-Adaptive Policy Optimization", "title_en": "LAPO: Internalizing Reasoning Efficiency via Length-Adaptive Policy Optimization", "authors": "Xingyu Wu,Yuchen Yan,Shangke Lyu,Linjuan Wu,Yiwen Qiu,Yongliang Shen,Weiming Lu,Jian Shao,Jun Xiao,Yueting Zhuang", "background": "大型语言模型通过扩展的思考链取得了显著的性能，但这种计算自由度导致了即使是简单问题的过度令牌生成。现有的方法或者施加固定的限制，或者依赖于事后干预，无法有效控制推理长度。", "innovation": "提出了长度自适应策略优化（LAPO）框架，将推理长度控制从外部约束转变为模型的内在能力，通过两阶段的强化学习过程，让模型内部掌握适当的推理深度。", "conclusion": "实验表明，LAPO在数学推理基准上使令牌使用减少了40.9%，同时准确率提高了2.3%。分析显示，使用LAPO训练的模型发展了根据问题复杂性分配计算资源的新兴能力，实现了高效的推理而不牺牲质量。"}
{"llm_update_time": "20250815", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2504.14325", "html_url": "https://arxiv.org/abs/2504.14325", "title": "FAIRGAME: 一种基于博弈论的AI代理偏见识别框架", "title_en": "FAIRGAME: a Framework for AI Agents Bias Recognition using Game Theory", "authors": "Alessio Buscemi,Daniele Proverbio,Alessandro Di Stefano, TheAnh Han,German Castignani,Pietro Liò", "background": "在多代理应用中，让AI代理相互互动增加了预测AI结果的复杂性，这对研究和实际应用中的信任采用产生了深远影响。博弈理论提供了一种强大机制来捕捉和解读代理之间的战略性互动，但需要可靠的、标准化的和用户友好的信息技术框架的支持，以实现结果的可比较性和解释。为了满足这一需求，我们提出了一种名为FAIRGAME的框架，用于识别AI代理中的偏见，并通过框架描述其实现和使用方法，从而揭示不同大型语言模型和使用的语言下，不同类型代理中的偏见活动。", "innovation": "FAIRGAME框架旨在利用博弈论来识别AI代理中的偏见。它提供了一种用户友好的工具，允许用户模拟他们自己的游戏场景，并通过模拟活动进行比较，同时与博弈论预测进行比较。这种框架有助于系统地发现偏见，预测战略互动中可能产生的新行为，并促进关于使用大型语言模型代理的战略决策研究。", "conclusion": "FAIRGAME框架使得用户能够稳健且简便地模拟自己想要的游戏和情境，并将结果在不同模拟活动中进行比较，同时与博弈论预测相比较，允许系统地发现偏见，预见由战略互动产生的新兴行为，并促进对使用大型语言模型代理进行的战略决策的研究。"}
{"llm_update_time": "20250815", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.22365", "html_url": "https://arxiv.org/abs/2507.22365", "title": "超越准确率：AI元认知敏感性如何改善AI辅助决策", "title_en": "Beyond Accuracy: How AI Metacognitive Sensitivity improves AI-assisted Decision Making", "authors": "ZhaoBin Li,Mark Steyvers", "background": "在人类决策依赖于AI输入的环境中，AI系统的预测准确性和其信心估计的可靠性都会影响决策质量。本文强调了AI元认知敏感性的作用，即AI系统能够准确区分正确和错误预测的能力，并提出了一种评估AI预测准确性和元认知敏感性在混合决策环境中的联合影响的理论框架。研究发现，在某些条件下，尽管准确率较低，但如果元认知敏感性较高，则AI可以改善人类的决策准确性。行为实验进一步证实，较高的AI元认知敏感性可以提升人类的决策表现。这些发现强调了在评估AI辅助决策时不仅要考虑准确性，还要考虑元认知敏感性，并需要在两者之间找到最佳平衡以实现最优决策结果的重要性。", "innovation": "本文引入了评估AI预测准确性和元认知敏感性在混合决策环境中的联合影响的理论框架，并通过实验证明，较高的元认知敏感性可以提升人类的决策表现。这是对传统仅依赖于预测准确性的评估方法的一种创新补充。", "conclusion": "研究结果表明，在评估AI辅助决策的性能时，不应只关注其预测准确性，还应考虑其元认知敏感性。优化两者以实现更优的决策效果是未来的重点。"}
{"llm_update_time": "20250815", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2504.08329", "html_url": "https://arxiv.org/abs/2504.08329", "title": "MedRep: 医学概念表示模型用于通用电子健康记录基础模型", "title_en": "MedRep: Medical Concept Representation for General Electronic Health Record Foundation Models", "authors": "Junmo Kim,Namkyeong Lee,Jiwon Kim,Kwangsoo Kim", "background": "电子健康记录（EHR）基础模型在多种医疗任务中的性能得到显著提升。然而，这些模型在处理未见过的医学代码（out of vocabulary）时存在基本限制，这限制了EHR基础模型的泛化能力和训练了不同词汇表的模型之间的整合能力。已有通用模型和通过医学代码分词器引入模型在各种预测任务中表现一般，无法有效解决未见过的医学代码问题。因此，急需一种新的方法来提升EHR基础模型的性能并增强其泛化能力。", "innovation": "本文提出了一种新型的医学概念表示（MedRep）方法，基于观察性医疗结果合作（OMOP）通用数据模型（CDM）。MedRep方法通过大型语言模型（LLM）提示来丰富每个概念的信息，并通过OMOP词汇表的图本体来补充基于文本的概念表示。实验结果显示，MedRep方法在多种预测任务中的性能优于传统EHR基础模型和使用以前引入的医学代码分词器的模型，证明了MedRep概念表示方法的泛化能力。", "conclusion": "MedRep方法通过整合OMOP词汇表的图本体和利用大型语言模型提示来提供医学概念表示，显著提升了EHR基础模型在处理未见过的医学代码方面的泛化能力。该方法不仅改进了现有模型的性能，也展示了其在外部验证中的泛化能力。"}
{"llm_update_time": "20250815", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.22423", "html_url": "https://arxiv.org/abs/2507.22423", "title": "关于智能的定义", "title_en": "On the Definition of Intelligence", "authors": "Kei-Sing Ng", "background": "为开发通用人工智能（AGI），需要首先以一种物种无关的形式捕获智能的本质，这种形式可以被评估，并且足够广泛以囊括多样化的智能行为类型，包括强化学习、生成模型、分类、类比推理和目标导向决策制定。这需要一种通用的标准来定义智能，使其能覆盖不同智能行为的评价标准，并能准确评估系统在不同智能任务中的表现。", "innovation": "作者提出了一种通用的标准，基于实体忠真度（entity fidelity），即判断一个系统在给定概念示例的情况下，能否产生同样的概念示例。详细阐述了这种标准的数学定义（ε-概念智能），并且提出了一种评价系统的框架，探索了这一标准在安全性、泛化等方面的应用。", "conclusion": "该论文提出了一个基于实体忠真度的新颖定义智能的标准，并开发了详细的评估框架，将这对评价智能系统的安全性和泛化能力产生影响。"}
{"llm_update_time": "20250815", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.10881", "html_url": "https://arxiv.org/abs/2508.10881", "title": "ToonComposer：以生成式后期关键帧简化动画制作", "title_en": "ToonComposer: Streamlining Cartoon Production with Generative Post-Keyframing", "authors": "Lingen Li,Guangzhi Wang,Zhaoyang Zhang,Yaowei Li,Xiaoyu Li,Qi Dou,Jinwei Gu,Tianfan Xue,Ying Shan", "background": "传统卡通和动画制作涉及关键帧设定、中间帧填补和着色阶段，这些阶段需要大量的人工劳动。尽管最近在人工智能方面有了许多进步，现有的方法通常会独立处理这些阶段，这会导致错误累积和艺术伪影。例如，中间帧填补方法在处理大动作时遇到困难，而着色方法需要密集的每帧素描。为了解决这个问题，我们引入了ToonComposer，一种生成模型，将中间帧填补和着色统一到一个后期关键帧设定阶段。", "innovation": "ToonComposer使用稀疏素描注入机制，利用关键帧素描提供精确控制，并采用了空间低秩适配器的方法对现代视频基础模型进行卡通领域定制，同时保持其时间先验不变。只需要一个素描和一个着色参考帧，ToonComposer可以很好地处理稀疏输入，同时支持任何时间位置的多个素描来实现更精确的运动控制。这种双重能力减少了人工工作量并提高了灵活性，使艺术家在实际场景中受益。", "conclusion": "我们进一步创建了PKBench，一个包含人类绘制的素描的基准，模拟现实场景中的使用情况。我们的评估表明，ToonComposer在视觉质量和运动一致性方面超过现有方法，在生产效率方面也更具优越性和灵活性，提供了更优秀且更灵活的AI辅助卡通生产解决方案。"}
{"llm_update_time": "20250815", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.23701", "html_url": "https://arxiv.org/abs/2507.23701", "title": "TextQuests: 文本冒险游戏中的LLM表现如何？", "title_en": "TextQuests: How Good are LLMs at Text-Based Video Games?", "authors": "Long Phan,Mantas Mazeika,Andy Zou,Dan Hendrycks", "background": "评估AI代理在模拟真实世界挑战的复杂和互动环境中对于理解其实际能力至关重要。现有的代理基准可以有效评估技能，如使用工具或完成结构化任务，但它们往往无法全面捕捉代理在探索环境中自主操作的能力，这些环境中需要长时间并持续自导性的推理来解决复杂和不断增长的情境。", "innovation": "为了解决这个问题，作者引入了TextQuests基准测试，该测试基于Infocom系列的互动文本冒险游戏。这种基于文本的冒险游戏可以花费人类玩家超过30小时，并且需要数百个精确操作来解决，能够有效评估代理在特定和状态相关的任务中的表现。基准测试特别设计来测试LLM代理自封闭问题解决的能力，限制使用外部工具，从而集中于探索环境中内在长时间推理能力，该环境需要试错学习和单次互动会话中的持续问题解决。", "conclusion": "我们发布了TextQuests基准测试，可以帮助更准确地评估AI代理在具有挑战性的探索环境中的表现。"}
{"llm_update_time": "20250815", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.08909", "html_url": "https://arxiv.org/abs/2508.08909", "title": "Compass-Thinker-7B技术报告", "title_en": "Compass-Thinker-7B Technical Report", "authors": "Anxiang Zeng,Haibo Zhang,Kaixiang Mo,Long Zhang,Shuman Liu,Yanhui Huang,Yawen Liu,Yuepeng Sheng,Yuwei Huang", "background": "近期的R1-Zero-like研究进一步表明，推理扩展赋予了大规模语言模型（LLMs）前所未有的推理能力，强化学习是核心技术以激发其复杂推理。然而，直接在超大规模模型上进行强化学习实验涉及高昂的计算成本和资源需求，存在显著风险。", "innovation": "我们提出Compass-Thinker-7B模型，旨在利用较少的计算资源和成本探索强化学习的潜力，并为更大模型的强化学习食谱进一步研究提供见解。Compass-Thinker-7B模型通过一个专门设计的强化学习流水线从开源模型训练而来，数据集中包含30k可验证的数学问题，通过根据不同阶段的难度分布配置数据和训练设置，逐步释放模型潜力并提高训练效率。", "conclusion": "广泛评估表明，Compass-Thinker-7B具备出色的推理潜力，并在数学方面实现了优于同规模RL模型的性能，特别是在挑战性的AIME2024评估中，Compass-Thinker-7B准确性达到了40%。"}
{"llm_update_time": "20250815", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2312.07055", "html_url": "https://arxiv.org/abs/2312.07055", "title": "通过哈希函数在本地差分隐私下减少子图计数的通信成本", "title_en": "Communication Cost Reduction for Subgraph Counting under Local Differential Privacy via Hash Functions", "authors": "Quentin Hillebrand,Vorapong Suppakitpaisarn,Tetsuo Shibuya", "background": "在边本地差分隐私下计算图统计，包括子图计数时，现有的算法往往面临高通信成本的问题，这使得它们在处理大规模图时效率降低。尽管数据压缩是差分隐私中的常用方法，但在本地差分隐私中应用数据压缩需要每个节点都能够复制的形式。", "innovation": "本文提出了一种线性同余哈希方法，以降低通信成本。通过设置抽样率 $s$，该方法可以将通信成本减少 $s^2$ 倍，但会增加所公布图统计的方差 $s$ 倍。实验结果表明，在匹配通信成本下，针对三角形计数，方法的 $\boldsymbol{\text{l}_2}$ 误差比领先算法低多达 1000 倍。", "conclusion": "本文提出的方法可以在不显著增加方差的情况下有效降低通信成本，特别适用于大规模图的三角形计数。实验结果表明该方法大幅减少了 $\boldsymbol{\text{l}_2}$-误差，在高通信成本匹配的情况下，其表现优于现有算法。"}
{"llm_update_time": "20250815", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.09932", "html_url": "https://arxiv.org/abs/2508.09932", "title": "大型语言模型在数学计算和推理中的错误", "title_en": "Mathematical Computation and Reasoning Errors by Large Language Models", "authors": "Liang Zhang,Edith Aurora Graf", "background": "大型语言模型（LLMs）在AI驱动的教育指导和评估中变得越来越普遍，尤其在数学教育中。LLMs生成数学问题解答和详尽解决方案的能力对于确保数学教育实践中的可靠和精确反馈和评估是至关重要的。本研究旨在评估四种LLMs（OpenAI GPT-4o和o1、DeepSeek-V3和DeepSeek-R1）解决数学任务（包括算术、代数和数论）的准确性。并通过构建对LLMs具有挑战性的任务，故意生成易于产生错误的任务来评估LLMs的错误识别能力。", "innovation": "通过故意构建难以解决的任务，研究着重于生成式模型中的推理错误，而不依赖标准基准。研究识别了单个代理和双代理配置下的错误，并发现改进的推理增强OpenAI o1模型在所有三类数学任务中始终表现出更高的或几乎完美的准确性。研究还分析了错误类型，发现操作性疏失是造成性能波动的主要原因，而概念误解较少见。双代理配置被证明可以显著提高整体性能。", "conclusion": "研究结果提供了关于如何增强LLM性能的实际建议，并强调了将LLMs整合到数学教育中的有效策略，从而推动了AI驱动教学实践和评估精度的发展。"}
{"llm_update_time": "20250815", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.09123", "html_url": "https://arxiv.org/abs/2508.09123", "title": "OpenCUA: 开放的基础架构以支持计算机使用代理", "title_en": "OpenCUA: Open Foundations for Computer-Use Agents", "authors": "Xinyuan Wang,Bowen Wang,Dunjie Lu,Junlin Yang,Tianbao Xie,Junli Wang,Jiaqi Deng,Xiaole Guo,Yiheng Xu,Chen Henry Wu,Zhennan Shen,Zhuokai Li,Ryan Li,Xiaochuan Li,Junda Chen,Boyuan Zheng,Peihang Li,Fangyu Lei,Ruisheng Cao,Yeqiao Fu,Dongchan Shin,Martin Shin,Jiarui Hu,Yuyan Wang,Jixuan Chen,Yuxiao Ye,Danyang Zhang,Dikang Du,Hao Hu,Huarong Chen,Zaida Zhou,Haotian Yao,Ziwei Chen,Qizheng Gu,Yipu Wang,Heng Wang,Diyi Yang,Victor Zhong,Flood Sung,Y.Charles,Zhilin Yang,Tao Yu", "background": "视觉语言模型已经展示了作为计算机使用代理（CUAs）的能力，这些代理能够自动化各种计算机任务。随着这些代理的商业潜力日益增长，最强大CUA系统的许多关键技术细节仍然保密。这些代理将越来越多地介导数字交互并代表我们执行重要决策，因此研究界需要访问开放的CUA框架来研究其能力和风险。特别是在没有开放框架和技术细节的情况下，难以全面评估CUA的功能和局限性。", "innovation": "本文提出了一种全面的开源框架OpenCUA，用于扩大CUA数据和基础模型。它包含三个主要部分：（1）注释基础设施，能够无缝捕捉人类计算机操作演示；（2）AgentNet，第一大规模计算机任务数据集，涵盖了3个操作系统和200多个应用程序和网站；（3）可扩展的流水线，将演示转化为状态-动作对，并结合反思性的长链推理，当数据量增加时仍能保持稳健的性能提升。此外，详细分析表明，该方法在不同领域具有良好的推广效果，并且从测试时计算能力的增强中受益显著。", "conclusion": "端到端的代理模型展示了在CUA基准测试中的强大性能。特别是，OpenCUA-32B在OSWorld-Verified测试中取得34.8%的成功率，成为开源CUA模型中新的SOTA，并超越了OpenAI的CUA（GPT-4o）。此外，该研究还确认了其方法在不同领域具有良好的泛化能力，并且随着测试时计算能力的增加显著受益。本文还公开了注释工具、数据集、代码和模型，以促进进一步的CUA研究。"}
{"llm_update_time": "20250815", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2402.13871", "html_url": "https://arxiv.org/abs/2402.13871", "title": "基于可解释的转换器模型的钓鱼邮件检测：一种大型语言模型方法", "title_en": "An Explainable Transformer-based Model for Phishing Email Detection: A Large Language Model Approach", "authors": "Mohammad Amaz Uddin,Md Mahiuddin,Iqbal H. Sarker", "background": "钓鱼邮件是一种严重的网络安全威胁，通过发送虚假电子邮件来欺骗用户，意图窃取个人信息或造成经济损失。攻击者通常假装为可信实体，利用技术进步和复杂性让钓鱼邮件的检测和预防变得更加困难。尽管进行了大量的学术研究，但在网络安全领域中钓鱼邮件的检测仍然是一个持续且艰巨的挑战。大型语言模型和遮蔽语言模型具备极大的潜力提供创新的解决方案以解决长期存在的挑战。", "innovation": "本文介绍了针对钓鱼邮件检测的优化且微调过的基于DistilBERT的转换器模型。采用了预处理技术来清理数据并解决类别不平衡问题。通过实验发现，所提出模型可以实现高准确率，展示了其在文本分类中的出色能力。此外，还使用了可解释的AI技术如局部可解释的模型无害解释(LIME)和转换器解释方法来解释模型预测的过程。", "conclusion": "本文提出了一种基于可解释转换器模型的钓鱼邮件检测方法，并通过实验验证了模型的有效性和可靠性。通过解释模型的预测过程，增加了模型的透明度和信任度。"}
{"llm_update_time": "20250815", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2407.12830", "html_url": "https://arxiv.org/abs/2407.12830", "title": "基于知识的大型语言模型一致性测试", "title_en": "Knowledge-based Consistency Testing of Large Language Models", "authors": "Sai Sathiesh Rajan,Ezekiel Soremekun,Sudipta Chattopadhyay", "background": "本研究系统地揭示并测量了大型语言模型（LLMs）中的不一致性和知识空白。以往的工作在评估LLMs的一致性和准确性方面存在问题，缺乏一种有效的自动测试框架来检测不一致性和填补知识空白。", "innovation": "提出了一个名为KonTest的自动化测试框架，该框架利用知识图谱构建测试案例，通过语义等价查询和测试或acles（元形变或本体或acles）来探针和度量LLMs的世界知识不一致。KonTest还包括了一种带权重的LLM模型集合方法来减轻知识空白问题。", "conclusion": "研究表明，KonTest能够生成19.2%的错误诱导输入（共1917个错误从9979个测试输入中产生），揭示了所有测试LLMs的整体16.5%的知识空白。通过根据KonTest的测试套件采取的缓解方法，LLM的知识空白减少了32.48%。此外，对比实验还发现，GPT3.5不适合作为基于知识的一致性测试的模型，其知识构建的有效性仅为60%-68%。"}
{"llm_update_time": "20250815", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2405.02754", "html_url": "https://arxiv.org/abs/2405.02754", "title": "隐式安全集算法以实现证明安全的强化学习", "title_en": "Implicit Safe Set Algorithm for Provably Safe Reinforcement Learning", "authors": "Weiye Zhao,Feihan Li,Changliu Liu", "background": "深度强化学习(DRL)已经在许多连续控制任务中展示了出色的性能。然而，将DRL应用于现实世界时遇到的主要障碍之一是没有提供充分的安全保证。虽然DRL代理可以通过调整奖励塑形满足系统安全期望，但在每一个时间步骤中设计能够持续满足刚性约束（如安全规范）的代理仍然极其具有挑战性。现有安全控制领域的工作在通过显式分析系统动力学模型提供强制遵守刚性安全约束的保证，然而这些方法在DRL环境中无法获取这些模型。", "innovation": "本文提出了一种无模型的、隐式的安全集算法，旨在为DRL代理合成保障证明安全性的防护措施。该算法仅通过查询黑盒动态函数（例如，数字孪生模拟器）生成安全指标（屏障证书）和后续的安全控制策略，从而确保训练过程中的有效安全。理论证明该算法保证了有限时间内收敛至安全集，并且对于连续时间和离散时间系统都具有前向不变性。", "conclusion": "在最先进的安全强化学习基准（如Safety Gym）上的实验证明了该算法的有效性，该算法实现了零安全违规，同时相对于最先进的安全DRL方法获得累积奖励达95%±9%。此外，提出的算法在处理高维系统时具有良好的扩展性，能够利用并行计算进行高效处理。"}
{"llm_update_time": "20250815", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.10771", "html_url": "https://arxiv.org/abs/2508.10771", "title": "AEGIS: 人工智能生成视频序列的真实性的评估基准", "title_en": "AEGIS: Authenticity Evaluation Benchmark for AI-Generated Video Sequences", "authors": "Jieyu Li,Xin Zhang,Joey Tianyi Zhou", "background": "近年来，AI生成内容的发展推动了高度逼真的合成视频的兴起，这严重威胁到了社会对数字信息的信任和数字完整性。目前的视频真实性检测基准通常存在真实性有限、规模不足、复杂性不够的问题，无法有效评估现代视觉-语言模型对复杂的伪造内容的检测能力。因此，亟需一个能够针对高度逼真和语义细微的AI生成视频的新基准。", "innovation": "该研究提出了AEGIS，一个新型大规模基准，专门针对超逼真和语义细微的AI生成视频的真实性的检测。AEGIS包含超过10,000个精心挑选的真实和合成视频，由多种最先进的生成模型生成，涵盖了开源和专有架构。此外，AEGIS特设了特制的具有鲁棒性评估的挑战子集，并提供了多模态标注，包括语义-真实性描述、运动特征和低级视觉特征，有利于真实性检测并支持下游任务如多模态融合和伪造定位。", "conclusion": "广泛使用先进的视觉-语言模型的实验表明，AEGIS最富挑战性的子集检测能力有限，突显了其实现的复杂性和逼真性超越现有模型的泛化能力。综上所述，AEGIS建立了一个不可或缺的评估基准，对发展真正稳健、可靠和广泛适用的视频真实性检测方法具有根本性的进步，能够应对现实世界的伪造威胁。"}
{"llm_update_time": "20250815", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2411.15913", "html_url": "https://arxiv.org/abs/2411.15913", "title": "无监督的基于潜在扩散模型的音乐风格迁移方法", "title_en": "A Training-Free Approach for Music Style Transfer with Latent Diffusion Models", "authors": "Heehwan Wang,Joonwoo Kwon,Sooyoung Kim,Shinjae Yoo,Yuewei Lin,Jiook Cha", "background": "音乐风格迁移能够根据一首作品的结构搭配另一首作品的风格特征，为个性化音乐创作提供可能。现有方法虽然涉足了基于文本条件的生成和基于扩散的合成，但大多数仍然需要大量的训练、配对的数据集或详细的文本注释。", "innovation": "本文提出了一种名为Stylus的创新无监督训练框架，该框架直接操作预训练的潜在扩散模型（LDM）的自注意力层。通过在mel频谱图域中替换内容音频的关键和价值表示，而不进行微调，该方法实现了风格迁移。为了提高风格化质量和可控性，进一步引入了查询保存、基于CFG的指导缩放、多风格插值和相位保持重建。与先前工作相比，该方法显著提高了感知质量和结构保存，同时保持了轻量级和易于部署。", "conclusion": "本文的工作指出了基于扩散的注意力操控在有效、高保真和可解释音乐生成方面的潜力——无需训练。接受后代码将被公开。"}
{"llm_update_time": "20250815", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2409.12446", "html_url": "https://arxiv.org/abs/2409.12446", "title": "神经网络在低复杂性数据上具有泛化能力", "title_en": "Neural Networks Generalize on Low Complexity Data", "authors": "Sourav Chatterjee,Timothy Sudijono", "background": "该研究基于给定独立同分布(i.i.d.)数据生成自简单编程语言的情况，探讨了前馈神经网络在低复杂性数据上的泛化能力。通过使用最小描述长度(MDL)理论，研究证明了带有ReLU激活函数的前馈神经网络在低复杂性数据上的泛化能力。特别地，研究了神经网络在执行一些基础计算任务，如素数检测时的表现。研究通过构建一个简单的编程语言及其网络长度的概念，为这些网络定义了描述长度，并提供了若干示例进行验证。对于素数检测，研究结果表明，通过随机从1到N中抽取n个样本进行训练的网络，能够以误差概率1- O((ln N)/n)的精度来判断任意新抽取的1到N之间的数是否为素数。研究还提出了对噪声数据的扩展，表明MDL神经网络插值器在噪声数据下可以展示出适度的过拟合现象。", "innovation": "1. 该研究首次证明了带有ReLU激活函数的前馈神经网络在低复杂性数据上的泛化能力。\n2. 通过最小描述长度(MDL)理论，研究人员构建了一个简单的编程语言及其网络描述长度的概念，这为研究提供了新的视角。\n3. 研究提出了在噪声数据下使用MDL神经网络插值器的可行性，表明其具有适度过拟合的特性。", "conclusion": "最小描述长度(minimum description learning, MDL)的前馈神经网络可以在低复杂性数据上准确地泛化，特别是对于基本的计算任务如素数检测，能够在误差概率接近于1的情况下做出准确的判断。此研究扩展了对神经网络泛化能力的理解，并提出了一种新的训练方法，即MDL神经网络插值器在处理迭代数据时具有更好的泛化性能。"}
{"llm_update_time": "20250815", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2411.04293", "html_url": "https://arxiv.org/abs/2411.04293", "title": "一个用于组合优化的随机键优化器", "title_en": "A Random-Key Optimizer for Combinatorial Optimization", "authors": "Antonio A. Chaves,Mauricio G.C. Resende,Martin J.A. Schuetz,J. Kyle Brubaker,Helmut G. Katzgraber,Edilson F. de Arruda,Ricardo M. A. Silva", "background": "该论文介绍了随机键优化器（RKO），这是一种针对组合优化问题的多功能且高效的地方搜索随机算法。RKO 使用随机键的概念，将解决方案编码为随机键的向量，并通过特定于问题的解码器将其解码为可行的解决方案。RKO 框架能够结合多种经典的元启发式算法，这些算法可以独立或并行运行，通过精英解池促进解的共享。", "innovation": "RKO 框架的创新之处在于模块化的元启发式算法机制，使各种元启发式算法（如模拟退火、迭代局部搜索和贪婪随机自适应搜索过程等）能够独立或并行运行和相互作用，这极大地提高了优化的灵活性和效率。此外，RKO 框架在 C++ 中实现，并且已经在 GitHub 上公开发布。", "conclusion": "通过在 alpha- 邻域 p 中心问题、树型枢纽位置问题和节点容量图划分问题这三种 NP 难组合优化问题中的应用，作者证明了 RKO 框架的有效性。实验结果表明，RKO 框架能够生成高质量的解决方案，适用于多种不同的问题领域，证明了它作为组合优化问题的强大工具的潜力。"}
{"llm_update_time": "20250815", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2410.06151", "html_url": "https://arxiv.org/abs/2410.06151", "title": "使用外部行为好奇心来多样化策略行为", "title_en": "Diversifying Policy Behaviors with Extrinsic Behavioral Curiosity", "authors": "Zhenglin Wan,Xingrui Yu,David Mark Bossens,Yueming Lyu,Qing Guo,Flint Xiaofeng Fan,Yew Soon Ong,Ivor Tsang", "background": "基于模仿学习（IL）已在多种应用中显示出巨大潜力（例如机器人运动），但往往仅能学习单一专家策略，这限制了行为的多样性和鲁棒性，在不可预测的现实场景中的应用受到了限制。", "innovation": "引入了“质量多样性逆强化学习”（QD-IRL），这是一种结合了质量多样性优化与逆强化学习的方法，使智能体能够从有限的示范中学习多种行为。引入了“外部行为好奇心”（EBC），使得智能体可以基于行为相对于大型行为档案的新颖性从外部批评家那里获得额外的好奇心奖励。验证了EBC在探索多样化运动行为的有效性。", "conclusion": "EBC显著提升了多种基于GAIL、VAIL和DiffAIL的QD-IRL实例的表现，甚至在多种环境中超过专家性能。此外，EBC适用于基于梯度有向图的质量多样性强化学习（QD-RL）算法，并通过提供学习行为多样性策略的通用技术进一步提高了性能。"}
{"llm_update_time": "20250815", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2412.02012", "html_url": "https://arxiv.org/abs/2412.02012", "title": "INSIGHT: 可解释的弱监督医学图像分析", "title_en": "INSIGHT: Explainable Weakly-Supervised Medical Image Analysis", "authors": "Wenbo Zhang,Junyu Chen,Christopher Kanan", "background": "由于体积庞大，体扫扫描和全视野病理图像（WSIs）通常通过从局部区域提取嵌入并由聚合器进行预测来处理。当前的方法需要后处理可视化技术（例如Grad-CAM），并且往往无法定位那些虽然微小但在临床至关重要的细节。", "innovation": "本文介绍了一种新颖的弱监督聚合器INSIGHT，它将heatmap生成作为一个候选方法的诱导偏置。INSIGHT通过预训练的特征图，利用具有小卷积核的检测模块捕捉细部特征，并利用具有更广视野的上下文模块抑制局部假阳性。由此生成的内部heatmap突出显示了诊断相关区域。在CT和WSI基准测试中，INSIGHT实现了最先进的分类结果和高效的弱标记语义分割性能。", "conclusion": "INSIGHT在CT和WSI基准测试中达到了最先进的分类结果和高弱标记语义分割性能。该项目网站和代码可以在 provided URL 获得。"}
{"llm_update_time": "20250815", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2410.10320", "html_url": "https://arxiv.org/abs/2410.10320", "title": "DiRW：感知路径的有向图学习以应对异质性挑战", "title_en": "DiRW: Path-Aware Digraph Learning for Heterophily", "authors": "Daohan Su,Xunkai Li,Zhenjun Li,Yinping Liao,Rong-Hua Li,Guoren Wang", "background": "近年来，图神经网络（GNN）已成为处理图形结构数据的强大表示学习工具。然而，大多数方法针对未加权图设计，忽视了有向图（有向图或digraphs）的边蕴含的丰富信息。尽管有向图在现实世界中广泛应用于解决异质性挑战，但基于空间和频谱的方法仍存在复杂的获取机制和对高质量拓扑的依赖，导致效率低和性能不稳定。", "innovation": "本文提出了一种名为DiRW的插件策略，它不仅适用于大多数基于空间的方法，还提供了一种新的有向图学习范式。DiRW利用一个优化的方向感知路径采样器，在不依赖权重的情况下考虑到节点属性和拓扑结构优化行走概率、长度和数量。并通过节点学习的路径聚合器以获得泛化的节点表示。实验结果表明，DiRW增强了大多数基于空间的算法，在多个数据集上表现出优越性和稳定性，达到了最佳性能。", "conclusion": "实验结果表明，DiRW作为一种插件策略增强了很多基于空间的方法；作为一种新的有向图学习范式，DiRW取得了SOTA性能。DiRW的源代码和数据可在以下网址获得：this https URL。"}
{"llm_update_time": "20250815", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2412.06534", "html_url": "https://arxiv.org/abs/2412.06534", "title": "通过反演理解基于变换器的视觉模型", "title_en": "Understanding Transformer-based Vision Models through Inversion", "authors": "Jan Rathjens,Shirin Reyhanian,David Kappel,Laurenz Wiskott", "background": "理解深层神经网络的机制仍然是机器学习和计算机视觉中的基本挑战。一种有前途但仅初步探索的方法是特征反演，它试图使用训练好的逆神经网络从中间表示重新构建图像。在此研究中，我们重新审视了特征反演，并引入了一种新型模块化变体，使其更有效地应用于技术。我们展示了如何系统地将该方法应用于大型自注意力基于的视觉模型（Detection Transformer和Vision Transformer），并如何在有意义的方式下对重建图像进行定性解释。我们进一步定量评估了该方法，从而揭示了这两种变换器架构中出现的图像特征表示的潜在机制。我们的分析揭示了这些模型如何编码上下文形状和图像细节的关键见解，其层如何相关以及其对颜色扰动的鲁棒性。这些发现有助于更深地理解基于变换器的视觉模型及其内部表示。", "innovation": "引入了一种新型模块化变体的特征反演方法，使其更有效地应用于大型自注意力基于的视觉模型。通过对重建图像进行定性解释和定量评估，发现了这些模型编码上下文形状和图像细节的关键见解，以及它们的层之间的相关性以及鲁棒性。", "conclusion": "该研究揭示了关键见解，这些见解加深了对基于变换器的视觉模型及其内部表示的理解。同时，研究的代码可在此链接中重现实验：this http URL"}
{"llm_update_time": "20250815", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.10828", "html_url": "https://arxiv.org/abs/2508.10828", "title": "针对社会机器人的多模态神经网络识别主观自我披露", "title_en": "A Multimodal Neural Network for Recognizing Subjective Self-Disclosure Towards Social Robots", "authors": "Henry Powell,Guy Laban,Emily S. Cross", "background": "主观自我披露是人类社会互动的重要特征。尽管社会学和行为学文献中已经对自我披露的特征和后果进行了大量研究，但对于能够准确建模自我披露的计算系统的开发工作却很少。特别地，目前对于人类如何与机器人伙伴进行自我披露的行为建模研究更是少之又少。随着人类需要与社会机器人在各种社交场景中合作并建立关系的需求日益强烈，开发出具有识别自我披露能力的社会机器人变得迫在眉睫。因此，该研究旨在基于情绪识别研究中的模型开发一种定制的多模态注意力网络，通过对大量自我收集的自我披露视频语料库进行训练，并设计一种新的损失函数（尺度保持交叉熵损失），以改善分类和回归问题。通过训练，发现该模型在使用新设计的损失函数的情况下表现最佳，F1分数达到0.83，相较于最好的基线模型提升了0.48分。这一进展为社会机器人识别互动伙伴的自我披露能力的发展奠定了重要基础，这种能力对于拥有社会认知的社会机器人来说将至关重要。", "innovation": "本文提出了一种基于情绪识别研究的多模态注意力网络模型，通过大规模自我收集的自我披露视频语料库进行训练，并采用一种新的尺度保持交叉熵损失函数，改进了分类和回归问题。最终，最佳训练模型的F1分数达到0.83，比最好的基线模型提高了0.48。", "conclusion": "本文的工作对社会机器人的自我披露识别能力做出了重要贡献，使其能够更好地理解和响应人类同伴的自我披露行为，这对于社会机器人在社交场景中有效建立互动关系至关重要。"}
{"llm_update_time": "20250815", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2501.02409", "html_url": "https://arxiv.org/abs/2501.02409", "title": "扰动下的可解释神经ODEs在基因调控网络发现中的应用", "title_en": "Interpretable Neural ODEs for Gene Regulatory Network Discovery under Perturbations", "authors": "Zaikang Lin,Sei Chang,Aaron Zweig,Minseo Kang,Elham Azizi,David A. Knowles", "background": "现代高通量生物数据集提供了大规模发现描述基因之间调节相互作用的因果图的机会。不同的可微因果图形模型已被提出，用于从大规模干预期datasets中推断基因调控网络（GRN），捕捉基因扰动下的因果基因调控关系。然而，现有的模型在表达能力和可扩展性方面存在局限性，不能解决细胞分化等生物过程的动力学特性。", "innovation": "本文提出了一种新颖的框架——PerturbODE，该框架结合了生物学信息丰富的神经常微分方程（神经ODEs），用于模拟在扰动下细胞状态轨迹，并从神经ODEs的参数中推导出因果GRN。该方法在模拟和真实过表达数据集中展示了在轨迹预测和GRN推断中的有效性。", "conclusion": "本文通过引入PerturbODE框架，实现了在扰动条件下基因调控网络的发现，并通过实验验证了该方法在轨迹预测和GRN推断中的优越性。"}
{"llm_update_time": "20250815", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2410.18368", "html_url": "https://arxiv.org/abs/2410.18368", "title": "CPU设计空间探索中的多目标优化：一切你所需即注意力", "title_en": "Multi-objective Optimization in CPU Design Space Exploration: Attention is All You Need", "authors": "Runzhen Xue,Hao Wu,Mingyu Yan,Ziheng Xiao,Guangyu Sun,Xiaochun Ye,Dongrui Fan", "background": "现代CPU设计中，设计空间探索（DSE）至关重要，但现有框架在高维度设计空间中难以扩展和概括。随着设计空间维度的增加，现存DSE框架面临三个根本挑战：（1）在大型设计空间中代理模型的准确度降低和扩展性差；（2）收购过程由手工构建的启发式或穷尽搜索效率低下；（3）可解释性差，难以定位架构瓶颈。", "innovation": "本作提出了首个端到端的DSE框架—AttentionDSE，该框架通过基于注意力机制的神经网络架构实现性能预测和设计指导的融合。Key创新包括：（1）感知驱动的注意力机制，通过滑动窗口将注意力复杂度从O(n^2)降低至O(n)，利用架构层次和局部特征扩展注意力复杂性；（2）注意力感知的瓶颈分析，自动识别关键参数进行优化，无需领域特定启发式。", "conclusion": "在使用SPEC CPU2017基准套件评估的高维度CPU设计空间中，AttentionDSE相比最先进的基准，实现了多达3.9%更高的帕累托体积以及超过80%的探索时间减少。"}
{"llm_update_time": "20250815", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2412.19160", "html_url": "https://arxiv.org/abs/2412.19160", "title": "一种基于相位唯一交叉注意力的轻量级变换器在光照不变的生物特征认证中的应用", "title_en": "A Lightweight Transformer with Phase-Only Cross-Attention for Illumination-Invariant Biometric Authentication", "authors": "Arun K. Sharma,Shubhobrata Bhattacharya,Motahar Reza,Bishakh Bhattacharya", "background": "传统的生物识别系统由于各种不可避免的因素遇到了显著的阻碍，例如面部识别生物识别系统中佩戴口罩的问题和指纹识别生物识别系统中的卫生顾虑。为了应对这些问题，本文提出了一种利用人脸额部和眼周区域双特征的轻量级相位唯一交叉注意力视觉变换器（POC-ViT），即使在佩戴口罩的情况下也能保持良好的性能，无需物理接触，为传统方法提供了新的替代方案。这种架构旨在处理两种生物特征，并捕捉它们在相对结构模式上的相互依赖性。所提出的框架能够应对输入图像中的光照变化，并在OFRS数据库上进行了验证，表现出98.8%的分类准确率，优于现有方法。", "innovation": "本文提出了POC-ViT框架，这是一种基于相位唯一交叉注意力的轻量级视觉变换器。其特点在于同时处理两种生物特征，捕捉它们的结构相互依赖性。使用相位相关（POC）的交叉注意力机制提取图像的空间特征的相位相关性，使模型在不同分辨率、强度以及光照条件下具有鲁棒性。此外，该轻量化模型适用于边缘设备部署。", "conclusion": "所提出的POC-ViT框架在FSVP-PBP数据库上表现出色，对额头静脉模式和眼周特征进行了双特征验证，具有98.8%的分类准确率，这比现有技术有显著的优势，为解决传统生物识别系统的实用问题提供了新的思路和方法。"}
{"llm_update_time": "20250815", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2501.18475", "html_url": "https://arxiv.org/abs/2501.18475", "title": "CLoQ: 通过校准LoRA初始化提高量化LLM的微调效率", "title_en": "CLoQ: Enhancing Fine-Tuning of Quantized LLMs via Calibrated LoRA Initialization", "authors": "Yanxia Deng,Aozhong Zhang,Selcuk Gurses,Naigang Wang,Zi Yang,Penghang Yin", "background": "使用低秩适应（LoRA）对大规模语言模型（LLMs）进行微调已成为下游任务中的一种高效方法，特别是在计算资源有限的场景下。然而，将LoRA技术应用于量化LLMs带来了独特的挑战，因为量化权重在表示精度方面有所减少。", "innovation": "本文提出了CLoQ（Calibrated LoRA initialization for Quantized LLMs），这是一种简单的初始化策略，旨在克服这些挑战。CLoQ通过利用小型校准数据集量化预训练LLM，并确定每个层的最佳LoRA组件，确保了后续微调的稳固基础。其核心贡献是提出了一种新颖的理论结果，使这些最佳LoRA组件的准确和闭式构造成为可能。", "conclusion": "我们验证了CLoQ在语言生成、算术推理和常识推理等多种任务中的有效性，证明了它在量化LLMs的LoRA微调方面始终优于现有方法，特别是在超低位宽中。"}
{"llm_update_time": "20250815", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2502.01669", "html_url": "https://arxiv.org/abs/2502.01669", "title": "基于影响函数的延迟反馈建模", "title_en": "Delayed Feedback Modeling with Influence Functions", "authors": "Chenlu Ding,Jiancan Wu,Yancheng Yuan,Cunchun Li,Xiang Wang,Dingxian Wang,Frank Yang,Andrew Rabinovich", "background": "在按照每次转化计费（CPA模式）的在线广告中，准确的转化率（CVR）预测至关重要。一个重大挑战是延迟反馈，即转化可能在用户交互后很久才会发生，导致最近数据不完整且模型训练存在偏差。现有的解决方案虽然部分缓解了这一问题，但通常依赖辅助模型，使得计算效率较低且不太能适应用户兴趣的变化。", "innovation": "提出了一个名为IF-DFM的模型，该模型利用影响函数进行延迟反馈建模，能够估计新到达和延迟的转化对模型参数的影响，从而实现高效更新而无需完全重新训练。通过将逆海森矩阵向量乘积重新表述为优化问题，IF-DFM在计算效率和有效性之间实现了良好的权衡。实验结果表明，IF-DFM在准确性和适应性上都优于先前的方法", "conclusion": "实验表明，IF-DFM在基准数据集上在准确性和适应性方面均优于之前的方法。"}
{"llm_update_time": "20250815", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2502.08512", "html_url": "https://arxiv.org/abs/2502.08512", "title": "测量合成数据集中的多样性", "title_en": "Measuring Diversity in Synthetic Datasets", "authors": "Yuchang Zhu,Huizhe Zhang,Bingzhe Wu,Jintang Li,Zibin Zheng,Peilin Zhao,Liang Chen,Yatao Bian", "background": "大型语言模型（LLMs）被广泛用于生成各种自然语言处理（NLP）任务的合成数据集，如文本分类和总结。然而，准确衡量这些合成数据集的多样性——这是模型稳健性能的关键方面——仍然是一个重大挑战。研究指出，现有的方法难以满足多样性评估的基本公理，导致评估结果的可靠性和有效性不足。", "innovation": "本文介绍了DCScore，一种从分类视角衡量合成数据集多样性的新方法。DCScore将多样性评估转化为一个样本分类任务，并利用样本之间的相互关系。理论验证进一步证明了DCScore满足多样性评估相关的公理，强调了它作为原理性多样性评估方法的作用。实验证明，DCScore与多种多样性评核标准具有较强的相关性，且在计算成本上显著低于现有方法。代码可以在指定的网址找到。", "conclusion": "研究结果表明，DCScore不仅在多样性方面的表现出色，还减少了计算成本，显示出其在合成数据集多样性评估中的优势和潜力。"}
{"llm_update_time": "20250815", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2502.01618", "html_url": "https://arxiv.org/abs/2502.01618", "title": "Rollout Roulette: A Probabilistic Inference Approach to Inference-Time Scaling of LLMs using Particle-Based Monte Carlo Methods", "title_en": "Rollout Roulette: A Probabilistic Inference Approach to Inference-Time Scaling of LLMs using Particle-Based Monte Carlo Methods", "authors": "Isha Puri,Shivchander Sudalairaj,Guangxuan Xu,Kai Xu,Akash Srivastava", "background": "大型语言模型（LLMs）通过增加模型规模和/或数据已经实现了显著的性能提升。然而，近期的证据表明，这种扩展方式的效果正在减弱，因此促使人们转向在推理时增加计算量的方法。现有的推理时扩展方法通常使用奖励模型将其任务定义为搜索问题，因此通常容易受到在奖励模型中近似错误导致的奖励破解问题的影响。", "innovation": "本文将推理时扩展定义为一个概率推断任务，并利用采样技术来探索在使用近似似然的状态空间模型中的状态分布的典型集，而不是直接优化其模式。提出了通过将粒子蒙特卡洛方法适应于此任务的新型推理时扩展方法。实验结果表明，该方法相较于确定性搜索方法，在各种挑战性数学推理任务上具有4-16倍的更好扩展率。同时，使用该方法可以让Qwen2.5-Math-1.5B-Instruct在4次跑批中超过GPT-4o的准确性，Qwen2.5-Math-7B-Instruct在32次跑批中达到o1级别的准确性。", "conclusion": "本工作不仅提供了一种有效的推理时扩展方法，还将概率推断的丰富文献与LLMs的推理时扩展相结合，以进一步开发更稳健的算法。该研究可以通过提供的链接获取代码、视频和更多信息。"}
{"llm_update_time": "20250815", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2502.08644", "html_url": "https://arxiv.org/abs/2502.08644", "title": "生物启发的范式：用于神经网络零样本自适应学习的节奏共享", "title_en": "Rhythmic sharing: A bio-inspired paradigm for zero-shot adaptive learning in neural networks", "authors": "Hoony Kang,Wolfgang Losert", "background": "大脑能够快速适应新的环境并从有限的数据中学习，这是人工智能算法难以模仿的一种宝贵特性。受神经细胞机械振荡节奏的启发，开发了一种学习范式，该范式利用了链接强度的振荡，学习与这些振荡的协调相关。网络可以通过快速变化的协调来感知和适应细微的环境变化，而无需监督。", "innovation": "开发了一种使用链接强度振荡的学习范式，该范式使网络能够快速适应细微的环境变化，并且能够预测多种上下文的动力学，包括未见过的上下文。这种方法提高了模型的适应性和泛化能力，因此成为认知模型的新起点。此外，该范式对神经网络的具体细节不敏感，为将快速适应性学习引入领先的人工智能模型提供了可能性。", "conclusion": "通过建立这种生物启发的学习范式，论文为开发能够快速适应和在未见情况下学习的新认知模型提供了强大的起点。同时，这一范式的普适性为其广泛应用于各种先进的AI模型中开辟了新的可能性。"}
{"llm_update_time": "20250815", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2501.06117", "html_url": "https://arxiv.org/abs/2501.06117", "title": "Fleurs-SLU：大规模多语言口语理解和语音理解基准", "title_en": "Fleurs-SLU: A Massively Multilingual Benchmark for Spoken Language Understanding", "authors": "Fabian David Schmidt,Ivan Vulić,Goran Glavaš,David Ifeoluwa Adelani", "background": "口语理解（SLU）对于缺乏正式书写系统的语言至关重要，这类语言占现有语言的一半以上。对于这些低资源语言，无法依赖自动语音识别（ASR）和文本大型语言模型（LLMs）来处理语音的语义理解。即使某些低资源语言拥有书写系统，但由于二模态语音和文本训练数据的有限，ASR的表现仍不可靠。目前，多语言SLU评估主要集中在浅层任务，如意图分类或语言识别。这种背景下，本文提出了Fleurs-SLU多语言SLU基准，该基准包括102种语言、692小时的语音（用于主题话语分类）以及92种语言、944小时的语音（用于通过听觉理解实现的选择题问答）。", "innovation": "本文提出了Fleurs-SLU基准，包含广泛的多语言语音数据集，涵盖大量的语言和任务类型，这在多语言SLU领域是前所未有的。此外，通过大量评估端到端语音分类模型、结合ASR和LLM的级联系统以及多模态语音-LLM模型，科研人员发现级联系统在多语言SLU场景中更为稳健，但预先训练良好的语音编码器在主题语音分类中也能表现出色。闭源的语音-LLM模型在某些情况下甚至超越了级联系统。研究还发现，稳健的多语言ASR、有效的语音到文本翻译与强大的多语言SLU之间存在很强的关联，表明语音和语义表示之间的相互利益。这一基准和结果对于推动多语言SLU的研究至关重要。", "conclusion": "本文的研究表明，相较于仅依赖级联模型，预先训练好的语音编码器可以在特定任务上表现出色。闭源的语音-LLM模型在多语言SLU任务上表现出色或超越了级联系统。因此，研究不仅提供了一个新的基准供研究人员使用，而且揭示了改进多语言SLU系统和模型的方法，同时也强调了语音和语义表示的重要性。"}
{"llm_update_time": "20250815", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2502.16770", "html_url": "https://arxiv.org/abs/2502.16770", "title": "LED-Merging: 在位置-选举-分离中缓解模型合并中的安全与实用冲突", "title_en": "LED-Merging: Mitigating Safety-Utility Conflicts in Model Merging with Location-Election-Disjoint", "authors": "Qianli Ma,Dongrui Liu,Qian Chen,Linfeng Zhang,Jing Shao", "background": "预训练的大语言模型（LLMs）用于专门任务的微调会带来巨大的计算和数据成本。模型合并提供了一种无需训练的解决方案来整合多个任务特定模型，但现有方法在增强通用能力的同时会削弱安全性保障，存在安全与实用性的冲突。", "innovation": "我们提出了LED-Merging，这是一种三个阶段的框架，通过梯度驱动的归因定位任务特定神经元，通过多模型重要性融合动态选择关键神经元，通过参数隔离分离冲突更新。该框架解决了神经元误识别和任务间神经元干扰的问题，有效减少了有害响应率，同时保持了95%的实用性性能。", "conclusion": "LED-Merging解决了安全-实用冲突，为构建可靠的多任务大语言模型提供了一种轻量级、无需训练的范式。代码可以在GitHub获得。"}
{"llm_update_time": "20250815", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2503.11655", "html_url": "https://arxiv.org/abs/2503.11655", "title": "DeepSeek-R1的可解释情感分析：性能、效率和少样本学习", "title_en": "Explainable Sentiment Analysis with DeepSeek-R1: Performance, Efficiency, and Few-Shot Learning", "authors": "Donghao Huang,Zhaoxia Wang", "background": "大型语言模型（LLMs）已经改变了情感分析，然而平衡准确率、效率和解释性仍然是一个关键挑战。这项研究旨在全面评估一个开源推理模型DeepSeek-R1，并将其与OpenAI的GPT-4o和GPT-4o-mini进行比较。", "innovation": "研究首次系统地测试了DeepSeek-R1的完整671B模型及其精简变体，记录了少样本学习曲线。DeepSeek-R1在5类情感分析中实现了91.39%的F1分数，在二元任务中实现了99.31%的准确率，仅用5个样本就达到了八倍的效率提升。同时，其特定架构的精简效果明显，32B的Qwen2.5模型相对于70B的Llama模型提高了6.69个百分点的性能。", "conclusion": "尽管DeepSeek-R1的推理过程降低了吞吐量，但其通过透明的、逐步的追踪提供了更优的解释性。这使DeepSeek-R1成为一个强大的、可解释的开源替代方案。"}
{"llm_update_time": "20250815", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2502.12188", "html_url": "https://arxiv.org/abs/2502.12188", "title": "通过推理时适应提升基于扩散的神经组合求解器在跨问题泛化方面的能力", "title_en": "Boosting Cross-problem Generalization in Diffusion-Based Neural Combinatorial Solver via Inference Time Adaptation", "authors": "Haoyu Lei,Kaiwen Zhou,Yinchuan Li,Zhitang Chen,Farzan Farnia", "background": "扩散基础的神经组合优化（NCO）方法通过学习离散扩散模型来生成解决方案，已经在NP完全（NPC）问题上展示了有效性，且避免了手工设计的领域知识。然而，现有的NCO方法在跨问题和跨比例的一般化方面面临重大挑战，并且与传统的求解器相比，其训练成本更高。最近关于扩散模型的研究引入了无需训练引导方法，通过预先定义的引导函数实现条件生成，但在组合优化中的应用尚不够广泛。", "innovation": "本文提出了一种无需训练的推理时适应框架（DIFU-Ada），能够使基于扩散的NCO求解器在无需额外训练的情况下实现零样本跨问题转移和跨比例泛化。我们还进行了理论分析来理解跨问题转移能力。", "conclusion": "我们实验的结果表明，仅针对旅行商问题（TSP）进行训练的扩散求解器，通过推理时适应，能够实现跨不同问题比例的TSP变种（如收集体着问题（PCTSP）和旅行商问题（OP））的竞争力零样本转移性能。"}
{"llm_update_time": "20250815", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2503.19530", "html_url": "https://arxiv.org/abs/2503.19530", "title": "VectorFit：预训练基础模型的自适应奇异向量和偏置向量微调", "title_en": "VectorFit : Adaptive Singular & Bias Vector Fine-Tuning of Pre-trained Foundation Models", "authors": "Suhas G Hegde,Shilpy Kaur,Aruna Tiwari", "background": "流行的方法通过在冻结的预训练权重W旁边参数化新的低秩或稀疏可训练权重来减少可训练参数的数量，以进行微调。然而，这些权重是从头开始训练的，导致与完整微调相比存在性能差距，特别是在预算有限的情况下。", "innovation": "提出了一种新的参数化方法VectorFit，该方法通过自适应训练W中嵌入的知识的奇异向量和偏置来高效利用现有的知识，从而可以生成与完整微调具有可比性的高秩增量权重矩阵ΔW。研究结果表明，VectorFit在参数效率方面具有明显优势，比领先的PEFT方法少9倍的可训练参数。", "conclusion": "通过涵盖自然语言理解与生成、问答、图像分类和图像生成等多种语言和视觉任务的19个数据集的全面实验，证明了在参数效率方面，VectorFit超越了基线模型的表现。"}
{"llm_update_time": "20250815", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2503.08064", "html_url": "https://arxiv.org/abs/2503.08064", "title": "多种模态的持续学习", "title_en": "Continual Learning for Multiple Modalities", "authors": "Hyundong Jin,Eunwoo Kim", "background": "持续学习旨在学习按时间序列观察的任务知识，同时减轻对先前学习知识的遗忘。现有方法设计是为了在同一时间学习单一模态（例如图像），这限制了它们在涉及多种模态的场景中的适用性。本研究提出了一种新的持续学习框架，可以适应多种模态（图像、视频、音频、深度和文本）。通过与文本的丰富语义信息来训练模型以对齐不同模态。然而，这也增加了遗忘先前学习知识的风险，特别是在不同任务具有不同输入特征时。为减轻模态间知识的覆盖，提出了一种框架，该框架能够合并内在模态知识和相关跨模态信息，通过自我调节学习表示的转变，逐步将新知识整合到保留的跨模态信息中。同时，通过基于其相关性选择性地整合之前模态的知识来减轻跨模态干扰。此外，还提出了一种重新对齐模态嵌入的策略，有效地解决了不同模态之间的偏置对齐问题", "innovation": "提出了一种新的持续学习框架，可以处理多种模态数据。该框架通过自我调节的学习表示转变，逐步将新知识整合到保留的跨模态信息中，同时选择性地整合不同模态的知识以降低干扰，并重新对齐不同模态之间的嵌入以消除偏置。这些改进扩展了持续学习方法在多种模态场景中的应用和适应性", "conclusion": "在多种多样的持续学习场景中的广泛实验表明，新提出的框架在具有不同模态的多个数据集上优于现有方法，无论是否给出模态的身份"}
{"llm_update_time": "20250815", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2504.01400", "html_url": "https://arxiv.org/abs/2504.01400", "title": "ToolACE-R: Model-aware Iterative Training and Adaptive Refinement for Tool Learning", "title_en": "ToolACE-R: Model-aware Iterative Training and Adaptive Refinement for Tool Learning", "authors": "Xingshan Zeng,Weiwen Liu,Xu Huang,Zezhong Wang,Lingzhi Wang,Liangyou Li,Yasheng Wang,Lifeng Shang,Xin Jiang,Ruiming Tang,Qun Liu", "background": "大型语言模型（LLMs）通过利用外部工具来解决复杂的用户任务已经成为增强模型能力的一个有前景的方法。现有方法主要集中在通过数据合成来微调LLMs，使其能有效调用工具，但忽略了如何全面激发模型的潜力。", "innovation": "本文提出了一种名为ToolACE-R的新框架，该框架包括模型感知的迭代训练和自适应细化，以优化工具学习。ToolACE-R通过逐步调整训练样本，根据模型能力的演变来提高模型潜力。此外，它还包含了自我细化的训练语料库，强调了LLMs迭代 refinements它们的工具调用的能力，无需外部反馈即可优化性能。此外，引入了自适应自我细化机制，以便在测试时高效扩展。", "conclusion": "我们在多个基准数据集上进行了广泛的实验，结果显示，ToolACE-R与基于API的高级模型相比，表现具有竞争力。通过自适应自我细化，工具调用的性能可以进一步提升。这些结果突显了ToolACE-R的有效性和泛化能力，为更高效和可扩展的工具学习提供了前景。"}
{"llm_update_time": "20250815", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2503.24381", "html_url": "https://arxiv.org/abs/2503.24381", "title": "UniOcc：自动驾驶中占用率预测和估计的统一基准", "title_en": "UniOcc: A Unified Benchmark for Occupancy Forecasting and Prediction in Autonomous Driving", "authors": "Yuping Wang,Xiangyu Huang,Xiaokang Sun,Mingxuan Yan,Shuo Xing,Zhengzhong Tu,Jiachen Li", "background": "当前研究中，存在针对占用率预测和估计的多种数据集和工具，但缺乏一个统一的平台来进行广泛和有效的评估。现有的方法主要依赖于次优的伪标签，未能全面评估占用率质量的各个方面。因此，需要一个能够整合多种真实世界数据集和高保真驾驶模拟器，并提供新型评估指标的全面统一平台，以提升模型的预测表现和鲁棒性评估能力。", "innovation": "UniOcc作为一个全面统一的基准和工具包，首次将nuScenes、Waymo等真实世界数据集与CARLA、OpenCOOD等高保真驾驶模拟器的数据进行了统一整合，提供了2D/3D占用率标签和创新的分体素流标注。其主要贡献在于引入了无需依赖真实标签的新颖评估指标，使得在更多的占用率质量方面进行稳健评估成为可能。此外，UniOcc证明了大规模、多样化的训练数据和明确的流信息对提升占用率预测和估计性能的重要性。", "conclusion": "通过在前沿模型上的广泛实验，UniOcc展示了大规模、多样化的训练数据和明确的流信息显著增强了占用率预测和估计性能。UniOcc的数据和代码可在指定链接中获得，为自动驾驶领域的相关研究提供了一个新的基准点。"}
{"llm_update_time": "20250815", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2504.05349", "html_url": "https://arxiv.org/abs/2504.05349", "title": "Hyperflux：剪枝揭示权重的重要性", "title_en": "Hyperflux: Pruning Reveals the Importance of Weights", "authors": "Eugen Barbulescu,Antonio Alexoaie,Lucian Busoniu", "background": "网络剪枝在大型神经网络中用于减少推理延迟和功率消耗。然而，大多数现有方法使用的是非正式的经验启发法，缺乏深刻的理解，并主要是基于实验结果进行解释。", "innovation": "我们引入了Hyperflux，一个基于概念的方法，通过每权重的‘流’（权重移除时对梯度的响应）来估计权重的重要性。一个全局压力项持续地驱动所有权重向着剪枝方向，对于对于精度至关重要的权重会基于其‘流’自动重新生长。我们提出了几个自然地从中框架中得出的性质，并且通过实验验证了每一个。其中一个性质与最终稀疏度和压力的关系，由此我们推导出一个通用的比例法则方程，并用它来设计我们的稀疏控制调度器。实验上，我们在CIFAR-10和CIFAR-100上的ResNet-50和VGG-19上展示了最先进的结果。", "conclusion": "我们提出了一种基于概念的L0剪枝方法Hyperflux，通过‘流’估计权重的重要性，并通过全局压力项持续驱动所有权重向剪枝方向，自动重新生长对于精度至关重要的权重。我们验证了不同性质，并基于此设计了一个比例法则方程用于控制稀疏度，实验结果表明了其优越性。"}
{"llm_update_time": "20250815", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2411.19134", "html_url": "https://arxiv.org/abs/2411.19134", "title": "Visual SLAMMOT Considering Multiple Motion Models", "title_en": "Visual SLAMMOT Considering Multiple Motion Models", "authors": "Peilin Tian,Hao Li", "background": "SLAM（即时定位与建图）和MOT（多对象跟踪）在自主驾驶领域至关重要，但传统做法是将SLAM和MOT视为独立模块，这限制了它们在动态环境中的应用。由于经典的SLAM方法通常依赖于静态环境假设，而MOT方法则依赖于车辆的已知状态，这些方法在处理复杂、动态的外部环境时受到了限制。研究者们开始探索将SLAM和MOT集成的统一方法（SLAMMOT），并提出了诸如IMM-SLAMMOT等解决方案，但这些方法主要集中于简单的运动模式。", "innovation": "本研究提出了一种视觉SLAMMOT方案，该方案结合了多个运动模型，填补了LiDAR和视觉传感器之间的差距。通过这种方式，研究团队将IMM-SLAMMOT的优点应用于视觉领域，并验证了其在视觉传感器中的优势。", "conclusion": "本研究证明，将多个运动模型融入视觉SLAMMOT方法中是可行的，并且这种方法在视觉传感器环境中具有显著优势。这为未来在复杂、动态环境下的自主驾驶系统开发提供了新的思路和技术基础。"}
{"llm_update_time": "20250815", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2503.04798", "html_url": "https://arxiv.org/abs/2503.04798", "title": "Advancing MAPF towards the Real World: A Scalable Multi-Agent Realistic Testbed (SMART)", "title_en": "Advancing MAPF towards the Real World: A Scalable Multi-Agent Realistic Testbed (SMART)", "authors": "Jingtian Yan,Zhifei Li,William Kang,Kevin Zheng,Yulun Zhang,Zhe Chen,Yue Zhang,Daniel Harabor,Stephen F. Smith,Jiaoyang Li", "background": "现有的多智能体路径规划（Multi-Agent Path Finding，MAPF）算法虽然可以快速规划几百个机器人的路径，但通常依赖简化的机器人模型，难以在实际环境中验证性能。研究者在实验室条件下难以获得大量实体机器人进行评估，而缺乏MAPF专业知识的工业用户需要一个易于使用的模拟器来测试算法性能。", "innovation": "SMART通过使用基于物理引擎的模拟器来创建真实环境，考虑了诸如机器人运动学和执行不确定性等复杂因素，还使用了基于动作依赖图的执行监控框架，使得与各种MAPF算法和机器人模型无缝集成成为可能，且能够扩展到数千个机器人。", "conclusion": "SMART是一个高效且现实的软件工具，用于评估MAPF算法。它通过提供真实的模拟环境和易于集成的框架，解决了研究和工业用户在评估MAPF算法时面临的挑战，使更多的用户能够高效地测试和理解算法在特定设置中的性能。"}
{"llm_update_time": "20250815", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2504.14493", "html_url": "https://arxiv.org/abs/2504.14493", "title": "FinSage：用于金融报表问答的多方面RAG系统", "title_en": "FinSage: A Multi-aspect RAG System for Financial Filings Question Answering", "authors": "Xinyu Wang,Jijun Chi,Zhenghan Tai,Tung Sum Thomas Kwok,Muzhi Li,Zhuhong Li,Hailin He,Yuchen Hua,Peng Lu,Suyuchen Wang,Yihong Wu,Jerry Huang,Jingrui Tian,Fengran Mo,Yufei Cui,Ling Zhou", "background": "在实际应用中使用大规模语言模型常常需要利用特定领域的数据和工具，以便遵循复杂的法规要求，以确保可以接受的使用。在金融领域，现代企业越来越多地依赖检索增强生成（RAG）系统来解决复杂的合规需求，尤其是在金融文件工作流中。然而，现有的解决方案难以应对数据的内在异质性（例如，文本、表格、图表）和监管标准的不断变化，导致关键信息提取的准确率降低。", "innovation": "我们提出FinSage框架作为解决方案，利用一个针对多模态金融文件合规分析的多方面RAG框架。FinSage引入了三个创新组件：（1）一个多模态预处理流水线，统一了多种数据格式并生成片段级元数据摘要；（2）一个增强查询扩展（HyDE）和元数据感知语义搜索的多路径稀疏-密集检索系统；（3）通过直接偏好优化（DPO）微调的领域专用重排模块，以优先考虑合规关键内容。广泛的实验表明，FinSage在75个由专家收集的问题上的召回率为92.51%，其准确率比FinanceBench问答数据集的最佳基线方法高出24.06%。此外，FinSage已成功部署为在线会议中的金融问答代理，并已服务超过1200人。", "conclusion": "FinSage框架在金融文件问答领域取得了显著的成果，展示了其在解决复杂合规要求方面的能力，并成功应用于实际应用场景中。"}
{"llm_update_time": "20250815", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2505.15002", "html_url": "https://arxiv.org/abs/2505.15002", "title": "解开迭代的CHAD", "title_en": "Unraveling the iterative CHAD", "authors": "Fernando Lucatelli Nunes,Gordon Plotkin,Matthijs Vákár", "background": "CHAD最初被定义为一种源自语义驱动的源代码到源代码的转换，用于总（终止）函数程序的反向模式自动微分（AD）。这项工作的背景是扩展CHAD以涵盖包含部分操作（可能非终止）、数据依赖条件（例如涉及实数测试）以及迭代结构（如while循环）的程序，同时保持CHAD的核心原则，即保持结构的语义。", "innovation": "本文的创新在于提出了迭代广泛的索引范畴，这是一种原则性的方法将迭代整合到依赖类型编程语言中。通过索引范畴中的参数初始代数来提升基范畴中的迭代，构造了一个操作广泛的品牌结构，该结构能够模型而循环等迭代结构。此外，通过在这个索引范畴中的有序迭代Freyd范畴的唯一结构保持函子，作者扩展了CHAD转换，使其适用于循环程序的新颖方法，利用独特的方法验证了该扩展的转换的正确性。", "conclusion": "借助索引范畴中的有序迭代Freyd范畴的唯一结构保持函子，通过独特的语义范畴模型的语义一致性证明了这一扩展转换的正确性，证明差分程序计算原创程序的正确反向模式导数。"}
{"llm_update_time": "20250815", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2504.15485", "html_url": "https://arxiv.org/abs/2504.15485", "title": "CAPTURe：通过遮挡物计数评估视觉语言模型的空间推理能力", "title_en": "CAPTURe: Evaluating Spatial Reasoning in Vision Language Models via Occluded Object Counting", "authors": "Atin Pothiraj,Elias Stengel-Eskin,Jaemin Cho,Mohit Bansal", "background": "识别和推理被遮挡的对象（部分或完全隐藏）对于理解视觉场景至关重要，因为遮挡现象在现实环境中经常发生，并且会阻碍空间理解。为了测试模型处理多个被遮挡物体的能力，该论文提出了一个新的任务，Counting Amodally for Patterns Through Unseen Regions (CAPTURe)，要求模型通过推断遮挡物之后的图案来计算按规律排列的对象数量。这一任务结合了识别视觉模式和推理的能力，对于评估视觉语言模型（VLMs）是否理解遮挡的模式以及它们的空间理解能力非常有用。CAPTURe 需求模型不仅要识别视觉模式，还要推理缺失的信息，从而测试其形成世界模型的能力。该任务分为两个部分：CAPTURe-real，手动筛选的真实物体排列图像；CAPTURe-synthetic，生成的带有模式的对象图像，用于控制诊断研究。", "innovation": "提出了一个新的任务框架 CAPTURe，用于评估视觉语言模型在处理和推理被遮挡对象时的空间理解能力。这个任务需要模型通过推理来确定被遮挡区域后的视觉模式，从而不仅需要视觉模式识别能力，还需要推理能力。此外，它还测试了模型如何利用提供的辅助信息来提高准确性，从而揭示了模型在处理遮挡和计数方面的困难，以及需要进一步增强的能力领域。通过引入这个任务，论文为评估和改进视觉语言模型的空间理解能力提供了一个新的视角和标准。", "conclusion": "尽管四个强大的视觉语言模型（GPT-4o，Intern-VL2，Molmo和Qwen2-VL）在 CAPTURe 任务中遇到了挑战，无法正确计数遮挡和非遮挡的模式，但人类在该任务中表现几乎无误。这表明现有模型在处理遮挡信息和图像计数方面存在显著不足，并且提供了进一步改进的方向。提供遮挡物体位置的辅助信息可以提高模型的性能，这说明错误来自于无法处理遮挡和在图像中进行计数的能力的不足。"}
{"llm_update_time": "20250815", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2505.11528", "html_url": "https://arxiv.org/abs/2505.11528", "title": "LaDi-WM: 一种基于潜在扩散的世界模型用于预测性操作", "title_en": "LaDi-WM: A Latent Diffusion-based World Model for Predictive Manipulation", "authors": "Yuhang Huang,Jiazhao Zhang,Shilong Zou,Xinwang Liu,Ruizhen Hu,Kai Xu", "background": "预测性操控在类人AI领域引起了广泛关注，因为它有可能通过利用预测状态来提高机器人策略的表现。然而，从世界模型生成准确的未来视觉状态仍然是一个挑战，尤其是在实现像素级的高质量表示方面。", "innovation": "提出了LaDi-WM，一种使用扩散建模来预测未来状态的潜在空间的世界模型。特别地，LaDi-WM 利用了与预先训练的视觉基础模型（包括几何特征和语义特征）对齐的潜在空间。通过预测潜在空间的演变来生成更一致且准确的结果，改进了策略性能。", "conclusion": "在合成和真实世界基准上的大量实验表明，LaDi-WM 通过27.9% 提高了 LIBERO-LONG 基准的策略性能，并在真实世界场景中提高了20%。同时，世界模型和策略在真实世界实验中表现出色，具有很强的通用性。"}
{"llm_update_time": "20250815", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2505.13109", "html_url": "https://arxiv.org/abs/2505.13109", "title": "FreeKV：提高KV缓存检索效率以实现高效的大语言模型推理", "title_en": "FreeKV: Boosting KV Cache Retrieval for Efficient LLM Inference", "authors": "Guangda Liu,Chengwei Li,Zhenyu Ning,Minyi Guo,Jieru Zhao", "background": "大语言模型（LLMs）随着上下文窗口的迅速扩展被广泛应用，以支持日益复杂的应用需求。然而，长上下文带来的主要挑战是，随着上下文长度的增长，KV缓存的大小也按比例增长，这导致了部署上的难题。虽然提出了KV缓存压缩的方法以应对这一问题，但丢弃KV方式会导致显著的准确性下降，而KV检索方法则面临效率瓶颈。", "innovation": "我们提出了FreeKV，这是一种算法系统协同优化框架，旨在提高KV检索效率的同时保持准确性。在算法侧，FreeKV引入了推测性检索以将KV的选择与检索过程从关键路径中转移出去，并结合细粒度的校正以确保准确性。在系统侧，FreeKV使用了CPU和GPU混合KV布局以消除数据传输的碎片化，并利用双缓冲流式检索以进一步提高效率。实验表明，FreeKV在各种场景和模型中实现了接近无损的准确性，并相比最先进的KV检索方法实现了高达13倍的速度提升。", "conclusion": "FreeKV框架通过优化KV检索过程，实现了大语言模型推理的高效性和准确性之间的平衡，在不同类型的语言模型和应用场景下都取得了显著的性能提升。"}
{"llm_update_time": "20250815", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2505.16332", "html_url": "https://arxiv.org/abs/2505.16332", "title": "量子优化准备好了吗？基于渐近量子计算的神经网络压缩努力", "title_en": "Is Quantum Optimization Ready? An Effort Towards Neural Network Compression using Adiabatic Quantum Computing", "authors": "Zhehui Wang,Benjamin Chen Ming Choong,Tian Huang,Daniel Gerlinghoff,Rick Siow Mong Goh,Cheng Liu,Tao Luo", "background": "量子优化目前是最成熟的量子计算技术之一，适用于高效解决复杂的组合优化问题。近年来，通过应用如渐近量子计算（AQC）等方法，已经能够有效解决各领域的优化问题。此外，在深度学习中，深度神经网络（DNN）已经变得非常庞大，以支持新的预测能力。然而，随着模型规模的扩大和复杂性的增加，对大规模模型的优化变得越来越具挑战性。尽管量子优化适用于解决复杂问题，将其应用于DNN优化却并不直接，必须经过彻底的重新制定，以适应商业化的量子设备。因此，探索AQC在精细剪枝和量化卷积神经网络方面的潜力被视为一种新的尝试。", "innovation": "本文创新地将传统的启发式方法重构成二次无约束二元优化（QUBO）问题，以利用商用量子退火设备来实现神经网络的压缩。实验结果表明，AQC不仅在时间效率上优于传统经典算法（如遗传算法和强化学习），还在寻找全局最优解方面表现出色。", "conclusion": "通过我们的探索性和改造工作，研究表明AQC能够有效地压缩实际的DNN模型，这为未来的量子计算在深度学习中的应用提供了新的视角和技术方法。"}
{"llm_update_time": "20250815", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2505.18889", "html_url": "https://arxiv.org/abs/2505.18889", "title": "大型语言模型的安全顾虑：一项调查", "title_en": "Security Concerns for Large Language Models: A Survey", "authors": "Miles Q. Li,Benjamin C. M. Fung", "background": "大型语言模型（LLMs）如ChatGPT及其竞争对手已经在自然语言处理领域引发了一场革命，但也带来了新的安全漏洞。本文综述了这些新兴的安全顾虑，将威胁分类为几个关键领域：提示注入和脱笼攻击；对抗性攻击，包括输入扰动和数据污染；恶意行为者的滥用以生成虚假信息、钓鱼邮件和恶意软件；以及自主LLM代理固有的令人担忧的风险。最近，安全培训中潜在的错位目标的关注显著增加，这些LLM表现出隐秘、不一致的行为，甚至被称为“诡计”，这种行为可能在经过安全培训后仍然存在。", "innovation": "本文总结了2022年至2025年间关于每种威胁的学术和工业研究，分析了提出的防御措施及其局限性，并指出了基于LLM的应用程序安全领域中的开放挑战。最近的研究重点在于探索LLM目标错位、新兴欺骗行为、自我保护本能以及在安全培训后可能形成的隐秘且不一致的目标，这被称为“诡计”行为，即使保护训练也无法消失的可能。", "conclusion": "本文强调了发展强大、多层次的安全策略的重要性，以确保LLM是安全和有益的，应进一步推进这一策略来确保这些复杂的模型不被滥用且有助于提升整体安全环境。"}
{"llm_update_time": "20250815", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2505.20469", "html_url": "https://arxiv.org/abs/2505.20469", "title": "CCL-LGS: 对比码本学习用于3D语言Gaussian点云", "title_en": "CCL-LGS: Contrastive Codebook Learning for 3D Language Gaussian Splatting", "authors": "Lei Tian,Xiaomin Li,Liqian Ma,Hao Yin,Zirui Zheng,Hefei Huang,Taiqing Li,Huchuan Lu,Xu Jia", "background": "最近在3D重建技术和视觉-语言模型方面的进展显著推动了3D语义理解的进步，这对于机器人、自动驾驶和虚拟/增强现实至关重要。然而，依赖2D先验的方法容易导致由于遮挡、图像模糊和视角依赖性变化引起的跨视图语义不一致，这些不一致通过投影监督传播时会降低3D高斯语义场的质量并在渲染输出中引入伪影。", "innovation": "本文提出了CCL-LGS，一种新颖的框架，通过整合多视图语义线索强制执行视图一致的语义监督。具体而言，我们的方法首先使用零样本跟踪器对SAM生成的2D掩码进行对齐并可靠地识别它们的对应类别，然后利用CLIP提取跨视图的鲁棒语义编码，最后我们的对比码本学习（CCL）模块通过强化类内紧凑性和类间区分性来提炼判别语义特征。与之前的直接将CLIP应用于不完美的掩码的方法不同，我们框架显式地解决了语义冲突并保留了类别区分性。", "conclusion": "大量实验证明，CCL-LGS 在性能上优于之前的方法。项目页面可在this https URL找到。"}
{"llm_update_time": "20250815", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.10236", "html_url": "https://arxiv.org/abs/2506.10236", "title": "提示攻击揭示了遗忘方法中的表面知识删除", "title_en": "Prompt Attacks Reveal Superficial Knowledge Removal in Unlearning Methods", "authors": "Yeonwoo Jang,Shariqah Hossain,Ashwin Sreevatsa,Diogo Cruz", "background": "本文探讨了某些机器遗忘方法在直接提示攻击下可能失效的问题。研究者们系统性地评估了八种不同遗忘技术在三种模型类型下的表现，使用输出、logits和探针分析方法来评估已被遗忘知识的保留程度。", "innovation": "研究通过系统的模型评估和分析方法（包括输出、logits和探针分析），发现虽然一些方法（如RMU和TAR）具有较强的遗忘效果，但ELM等方法对特定提示攻击仍然脆弱。此外，logits分析揭示了遗忘模型不太可能通过改变答案格式来隐藏知识。", "conclusion": "研究挑战了关于遗忘方法有效性的现有假设，并强调需要更可靠的评估框架来区分真正的知识删除和表面的输出抑制。为了促进进一步的研究，研究者公开发布了自己的评估框架，方便研究人员评估提示技术以恢复未遗忘的知识。"}
{"llm_update_time": "20250815", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.01701", "html_url": "https://arxiv.org/abs/2506.01701", "title": "信息最大化驱动的数据精简", "title_en": "Data Pruning by Information Maximization", "authors": "Haoru Tan,Sitong Wu,Wei Huang,Shizhen Zhao,Xiaojuan Qi", "background": "本文提出了一种名为InfoMax的新颖数据精简方法，也被称为余量选择。该方法旨在最大化选择样本的信息内容，同时最小化冗余。通过这种方法，InfoMax增强了余量的整体信息量。数据样本的重要性是由能够反映其对模型学习影响或难度的重要性分数来测量的。冗余是通过样本对之间的相似性进行量化，基于一个假设，即相似的样本在学习过程中贡献相似。", "innovation": "InfoMax将余量选择问题形式化为离散二次规划问题，目标是最小化余量中的冗余，同时最大化总的信息内容。为确保实用的可扩展性，作者引入了一种高效的梯度基于求解器，并结合了对相似性矩阵的稀疏化技术和数据集分区策略，使InfoMax能够平滑地扩展到包含数百百万样本的数据集。研究表明，InfoMax在各种数据精简任务中表现出优越性，包括图像分类、视觉语言预训练和大型语言模型指令调整。", "conclusion": "大量实验表明，InfoMax在不同的数据精简任务中表现出优越性，特别是在图像分类、视觉语言预训练和大型语言模型指令调优任务中。得益于其所提出的高效算法和策略，InfoMax能够方便地处理大规模数据集。"}
{"llm_update_time": "20250815", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.11049", "html_url": "https://arxiv.org/abs/2506.11049", "title": "15,500秒：使用EfficientNet和轻量级微调的简约无人机分类", "title_en": "15,500 Seconds: Lean UAV Classification Using EfficientNet and Lightweight Fine-Tuning", "authors": "Andrew P. Berg,Qian Zhang,Mia Y. Wang", "background": "随着无人机(UAVs)在消费和国防应用中的普及，对于可靠且特定模态的分类系统的需求变得越来越迫切。本文通过引入预训练的深度学习模型、参数高效微调(PEFT)策略和目标化的数据增强技术，解决了无人机音频分类中的数据稀缺问题。利用一个包含31种不同型号的无人机音频片段（3,100个片段，总时长15,500秒）的自定义数据集，评估了基于转换器和卷积神经网络(CNN)架构在不同微调配置下的性能。实验使用五折交叉验证评估了准确率、训练效率和鲁棒性。结果表明，使用三种增强技术完全微调EfficientNet-B0模型获得了最高的验证准确率（95.95%），优于定制的CNN模型和基于转换器的模型如AST。这表明，结合轻量级架构、PEFT和精心选择的增强技术是处理有限数据集的无人机音频分类的有效策略。", "innovation": "通过引入预训练的深度学习模型、参数高效微调(PEFT)策略和目标化的数据增强技术，解决无人机音频分类中的数据稀缺问题。使用完全微调EfficientNet-B0模型，结合三种数据增强技术，实现了最高验证准确率，并优于其他模型。", "conclusion": "结合轻量级架构、PEFT和精心选择的增强技术是处理有限数据集的无人机音频分类的有效策略。未来的工作将扩展该框架到多模态无人机分类，使用视觉和雷达遥测技术。"}
{"llm_update_time": "20250815", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.18248", "html_url": "https://arxiv.org/abs/2506.18248", "title": "增强对抗可传输性的基于语义结构的生成攻击", "title_en": "Semantic Structure-Aware Generative Attacks for Enhanced Adversarial Transferability", "authors": "Jongoh Jeong,Hunmin Yang,Jaeseok Jeong,Kuk-Jin Yoon", "background": "Generative adversarial attacks通过在白盒近似模型上训练扰动生成器，并在未见的黑盒受害模型上应用制造的扰动来实现。与迭代攻击相比，这些方法在这方面的效率、可扩展性和迁移性上表现更优，但现有的研究尚未充分利用生成模型的表示能力，以保留和利用语义信息。生成器的中间激活包含了丰富的语义特征，如对象边界和粗略形状，这些特征目前并未得到充分探索，导致了对抗扰动与语义显著区域的对齐不足，从而限制了对抗迁移性。", "innovation": "提出了一个基于Mean Teacher的语义结构意识攻击框架，它充当了时间平滑特征参考。利用这种平滑参考，进一步指导学生早期层激活与富含语义信息的教师之间的语义一致性，通过特征蒸馏实现。我们的方法基于实验发现，将扰动合成锚定在生成器中的语义最显著早期中间块，引导渐进式的对抗扰动集中在能显著提升对抗迁移性区域上。", "conclusion": "本文在多种模型、领域和任务上进行了广泛的实验，结果表明与最先进的生成攻击相比，该方法在相对转换有效性方面表现出了持续改进，并且通过使用常规指标和我们新提出的误矫正面率(Accidental Correction Rate)进行全面评估，结果同样一致。"}
{"llm_update_time": "20250815", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.11170", "html_url": "https://arxiv.org/abs/2506.11170", "title": "PromptTSS：基于提示的方法实现交互式多粒度时间序列分割", "title_en": "PromptTSS: A Prompting-Based Approach for Interactive Multi-Granularity Time Series Segmentation", "authors": "Ching Chang,Ming-Chih Lo,Wen-Chih Peng,Tien-Fu Chen", "background": "多变量时间序列数据在制造和可穿戴技术等多种领域中被收集，这些数据跨多个粒度级别展示各种状态，从粗粒度系统行为到细粒度细节事件。对这些不同粒度级别的状态进行有效的分割和集成对于预测维护和性能优化等任务至关重要。然而，现有时间序列分割方法面临两个关键挑战：（1）不能在一个统一模型中处理多个粒度级别，（2）对动态环境中出现的新型模式的适应性有限。", "innovation": "我们提出了PromptTSS，一种多粒度状态下的时间序列分割新框架。PromptTSS利用一个具有一提示机制的统一模型，结合标签和边界信息指导分割，既能捕捉粗粒度和细粒度模式，又能动态适应未见模式。实验结果表明，PromptTSS在多粒度分割中提高了24.49%的准确率，在单粒度分割中提高了17.88%的准确率，在迁移学习中提高了高达599.24%的准确率，展示了它对分层状态和时间序列动态发展适应性的能力。", "conclusion": "本文提出了一种新的多粒度时间序列分割框架PromptTSS，该框架可以在统一模型中处理多个粒度级别，并具有动态适应未见模式的能力。实验结果显示，该方法在多粒度和单粒度分割以及迁移学习方面表现出了显著的性能提升。"}
{"llm_update_time": "20250815", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.19794", "html_url": "https://arxiv.org/abs/2506.19794", "title": "为什么开源大语言模型在数据分析中挣扎？一项系统性的实证研究", "title_en": "Why Do Open-Source LLMs Struggle with Data Analysis? A Systematic Empirical Study", "authors": "Yuqi Zhu,Yi Zhong,Jintian Zhang,Ziheng Zhang,Shuofei Qiao,Yujie Luo,Lun Du,Da Zheng,Ningyu Zhang,Huajun Chen", "background": "开源大语言模型（LLMs）虽然有望自动化数据分析任务，但面对需要推理能力较高的场景时，现存模型存在显著的不足。本文研究如何提升开源LLMs的数据分析能力。", "innovation": "作者通过构建一个包含多样且现实情境的数据集，从数据理解、代码生成和战略规划三个核心维度评估模型行为。并提出数据合成方法，显著改善了开源LLMs的分析推理能力。", "conclusion": "战略规划质量是决定模型表现的主要因素，交互设计和任务复杂度对推理能力有重要影响，高质量数据对达到最佳表现比数据多样性更重要。"}
{"llm_update_time": "20250815", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.19343", "html_url": "https://arxiv.org/abs/2506.19343", "title": "Discrepancy-Aware Graph Mask Auto-Encoder", "title_en": "Discrepancy-Aware Graph Mask Auto-Encoder", "authors": "Ziyu Zheng,Yaming Yang,Ziyu Guan,Wei Zhao,Weigang Lu", "background": "Masked Graph Auto-Encoder作为一种强大的图自监督训练范式，已经在图表示学习中表现出卓越的性能。现有工作主要依赖节点上下文信息来恢复被遮盖的信息，并在这方面表现出色，但它们难以在异类图上泛化，即在异类图中连接的节点可能没有相似性，因为现有工作仅关注捕捉节点的邻居信息，而忽视了不同节点之间的差异性信息，导致节点表示无法区分。", "innovation": "为了解决上述问题，本文提出了一种名为Discrepancy-Aware Graph Mask Auto-Encoder (DGMAE) 的模型，通过在遮盖过程中重建邻节点之间的差异性信息，从而获得更可区分的节点表示。", "conclusion": "我们在17个广泛应用的标准数据集上进行了广泛的实验。结果显示，DGMAE能够有效地在低维空间中保留节点的差异性，并且在节点分类、节点聚类和图分类等三项图分析任务中显著优于最先进的图自监督学习方法，显示出其显著的优势。相关代码已发布在[此链接]。"}
{"llm_update_time": "20250815", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.06639", "html_url": "https://arxiv.org/abs/2507.06639", "title": "EXAONE Path 2.0: 具有端到端监督的病理学基础模型", "title_en": "EXAONE Path 2.0: Pathology Foundation Model with End-to-End Supervision", "authors": "Myeongjang Pyeon,Janghyeon Lee,Minsoo Lee,Juseung Yun,Hwanil Choi,Jonghyun Kim,Jiwon Kim,Yi Hu,Jongseong Jang,Soonyoung Lee", "background": "在数字病理学中，全视野图像（WSIs）由于其 gigapixel 规模往往难以处理，大多数方法通过自监督学习（SSL）训练补丁编码器，然后通过多重实例学习（MIL）或滑准编码器将补丁级嵌入聚合以用于下游任务。然而，补丁级 SSL 可能会忽略基本图像领域中选择的基本增强可能导致的复杂领域特定特征，这些特征对于生物标志物预测至关重要，如突变状态和分子特性。此外，SSL 方法在数据效率方面远不如全监督方法，需要大量的计算资源和数据集才能达到竞争性性能。", "innovation": "我们提出了 EXAONE Path 2.0，一个在直接滑准监督下学习补丁级表示的病理学基础模型。只使用 37k 个 WSIs 进行训练，EXAONE Path 2.0 实现了 10 个生物标志物预测任务的最先进的平均性能，展示了出色的的数据效率。", "conclusion": "该研究展示了 EXAONE Path 2.0 的性能优势，通过直接滑准监督提高了数据效率，证明了在大规模图像中具有突出的性能表现。"}
{"llm_update_time": "20250815", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.10904", "html_url": "https://arxiv.org/abs/2507.10904", "title": "难度分离数据的类比例聚esomeClassSampling", "title_en": "Class-Proportional Coreset Selection for Difficulty-Separable Data", "authors": "Elisa Tsai,Haizhong Zheng,Atul Prakash", "background": "高质量的训练数据对于构建可靠的机器学习系统至关重要。现有的一次性CoreSet选择方法通过减少数据集的同时保持或提升模型性能，通常依赖于基于训练动态的数据难度分数。然而，大多数现有方法假设数据难度在不同类别之间是同质的，忽略了数据难度在不同类别之间的差异。本文探讨了在网络安全检测和医学影像等领域中，数据难度往往按类别聚类的问题，提出了类别难度分隔系数（CDSC）作为定量度量，并展示了类比例聚合成策略的有效性，特别是在极端数据修剪率下稳定性能显著提高，显著优于无差别的基准方法，提升了泛化能力，特别是在噪声、不平衡和大规模数据集中表现更为突出。", "innovation": "提出了类别难度分隔系数（CDSC）作为定量度量，并引入了类比例聚成策略，这些策略在五个不同的数据集上表现出了优于现有方法的稳定性，特别是在CTU-13数据集上，即使在极端99%的数据修剪率下，类比例聚成策略也能保持较高的精度、精确度和召回率。此外，研究还表明，在噪声、不平衡和大规模数据集中，激进的数据修剪可以增强泛化能力。", "conclusion": "结果表明，明确建模类别难度分隔性能够导致更有效、更稳健和更泛化的数据修剪策略，特别是在高风险场景下更为重要。"}
{"llm_update_time": "20250815", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.14189", "html_url": "https://arxiv.org/abs/2507.14189", "title": "DeepWriter：基于离线知识库的事实支持多模态写作助手", "title_en": "DeepWriter: A Fact-Grounded Multimodal Writing Assistant Based On Offline Knowledge Base", "authors": "Song Mao,Lejun Cheng,Pinlong Cai,Guohang Yan,Ding Wang,Botian Shi", "background": "大规模语言模型（LLMs）在各种应用中展现了强大的能力，但在金融、医学和法律等专门领域作为写作助手的应用受到了深度领域专业知识缺乏和虚构倾向的限制。现有方案，如检索增强生成（RAG），在多个检索步骤中容易导致不一致，而基于在线搜索的方法则由于不可靠的网络内容而降低质量。", "innovation": "该研究引入了DeepWriter，这是一款可定制的多模态长文写作助手，基于经过精心编排的离线知识库。DeepWriter采用了新颖的工作流程，包括任务分解、大纲生成、多模态检索以及逐段合成和反思。通过深入挖掘结构化文集中的信息，并结合文本和视觉元素，DeepWriter生成的内容连贯、事实依赖且专业级别。此外，提出了一种层次化的知识表示来提高检索效率和准确性。", "conclusion": "在金融报告生成实验中，DeepWriter生成了高质量、可验证的文章，其事实准确性和生成内容质量超过了现有基线。"}
{"llm_update_time": "20250815", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2504.17493", "html_url": "https://arxiv.org/abs/2504.17493", "title": "目标导向的时间序列预测：基础框架设计", "title_en": "Goal-Oriented Time-Series Forecasting: Foundation Framework Design", "authors": "Luca-Andrei Fechete,Mohamed Sana,Fadhel Ayed,Nicola Piovesan,Wenjie Li,Antonio De Domenico,Tareq Si Salem", "background": "传统的时序预测方法通常旨在最小化总体预测误差，而忽略下游应用中不同预测范围的重要性的变化。这使得预测模型在推理时可能无法有效地关注特定应用程序所需的重点区域。", "innovation": "本文提出了一种训练方法，使预测模型能够在推理时不重新训练的情况下，自适应地调整其关注点以符合特定应用程序的需求。该方法在训练时将预测空间细分为多个部分，根据应用需求动态重新加权并聚合这些部分，从而强调目标范围。与先前方法预设这些范围不同，本文框架支持灵活的需求调整。", "conclusion": "实验结果表明，该方法不仅在关注区域内提高了预测准确性，还显著提升了下游任务的性能。这些结果突显了预测建模与现实世界系统中决策合并的潜在联系。"}
{"llm_update_time": "20250815", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.08162", "html_url": "https://arxiv.org/abs/2507.08162", "title": "AmpLyze：一种预测溶血浓度的深度学习模型", "title_en": "AmpLyze: A Deep Learning Model for Predicting the Hemolytic Concentration", "authors": "Peng Qiu,Hanqi Feng,Meng-Chun Zhang,Barnabas Poczos", "background": "红细胞裂解(HC50)是抗菌肽(AMP)药物的主要安全屏障，但现有的模型只能简单地区分毒性或无毒。AmpLyze通过仅基于氨基酸序列预测实际的HC50值，并解释导致毒性的残基，填补了这一缺口。该模型结合了残基级别的ProtT5/ESM2嵌入和序列级别的描述符，在具有交叉注意力模块的双局部和全局分支中进行联合，并使用对实验噪声具有鲁棒性的对数双曲余弦损失进行训练。最优的AmpLyze模型达到了0.756的PCC和0.987的MSE，优于传统的回归模型和最新的技术水平。消融实验表明，两个分支都至关重要，交叉注意力还额外提高了1%的PCC和3%的MSE。梯度期望归因揭示了已知的毒性热点，并建议了更安全的替代方案。将红细胞裂解评估转化为定量、序列基础的可解释预测，AmpLyze促进了AMP的设计，并提供了一个早期毒性筛查的有效工具。", "innovation": "AmpLyze通过仅基于氨基酸序列预测实际的HC50值，并解释导致毒性的残基，填补了现有模型只能简单地区分毒性或无毒的缺口。该模型结合了残基级别的ProtT5/ESM2嵌入和序列级别的描述符，在具有交叉注意力模块的双局部和全局分支中进行联合，并使用对实验噪声具有鲁棒性的对数双曲余弦损失进行训练。", "conclusion": "AmpLyze模型通过将红细胞裂解评估转化为定量、序列基础的可解释预测，有效地促进了AMP的设计，并提供了一个早期毒性筛查的有效工具，明显优于传统的回归模型和最新的技术水平。"}
{"llm_update_time": "20250815", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.10535", "html_url": "https://arxiv.org/abs/2507.10535", "title": "CodeJudgeBench：评估编码任务中LLM作为裁判的标准基准", "title_en": "CodeJudgeBench: Benchmarking LLM-as-a-Judge for Coding Tasks", "authors": "Hongchao Jiang,Yiming Chen,Yushi Cao,Hung-yi Lee,Robby T. Tan", "background": "大型语言模型（LLMs）已在各种编码任务中大幅提升了最先进技术水平。除了直接回答用户查询外，LLMs还可以作为裁判，评估和比较其他模型生成的响应质量。这一评估能力对于不同LLM的基准测试以及通过响应排名提高响应质量至关重要。尽管LLM作为裁判的概念正在被广泛采用，但在编码场景中的有效性仍被忽视，主要是因为没有专用的基准测试工具。鉴于此，本研究引入了CodeJudgeBench，旨在评估LLM作为裁判模型在代码生成、代码修复和单元测试生成三种关键编码任务中的表现。通过全面测试26种LLM作为裁判模型，研究结果表明，近期的思考模型在精心设计的代码评估任务中显著优于非思考模型。尽管如此，所有模型在判断编码任务时仍然表现出显著的随机性，且在成对评估任务中，改变响应呈现的顺序会显著影响准确性。此外，当评估不同LLM编写的代码和单元测试时，LLM作为裁判模型的表现也表现出差异，这引发了对LLM作为裁判在编码场景中可靠性和一致性问题的担忧。最后，研究还探讨了最优提示策略。发现使用成对比较优于标量点判断，同时保留完整未处理的LLM响应中的注释和推理可以提高裁判表现。", "innovation": "本研究通过引入CodeJudgeBench，专门设计了一个基准工具来评估LLM在编码任务中的裁判能力。研究结果表明，近期的思考模型在编码任务评估中显著优于非思考模型，并且即使是在小规模模型（如Qwen3-8B）在特定任务中也显示出显著优越性。此外，研究还提出并验证了最优的提示策略，这些策略能够提高LLM作为裁判的效果。", "conclusion": "研究表明，尽管近期的思考模型在编码任务评估中取得了显著的进展，但所有模型在判断编码任务时仍然存在随机性。提示顺序的改变会影响准确性，且评估不同LLM编写的代码和单元测试时，表现也表现出差异。因此，需要进一步研究以提高LLM作为裁判的可靠性和一致性。"}
{"llm_update_time": "20250815", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.22369", "html_url": "https://arxiv.org/abs/2507.22369", "title": "Visual Question Answering (VQA)在课堂活动监控中的应用探索", "title_en": "Exploring the Application of Visual Question Answering (VQA) for Classroom Activity Monitoring", "authors": "Sinh Trong Vu,Hieu Trung Pham,Dung Manh Nguyen,Hieu Minh Hoang,Nhu Hoang Le,Thu Ha Pham,Tai Tan Mai", "background": "课堂行为监控是教育研究的关键方面，对学生参与度和学习成果具有重大影响。最近，视觉问答（VQA）模型的最新发展为从视频记录中自动分析复杂课堂互动提供了有希望的工具。", "innovation": "在本文中，研究者考察了包括LLaMA2、LLaMA3、QWEN3和NVILA在内的几种最先进的开源VQA模型在课堂行为分析中的适用性，并且引入了基于越南银行业发展学院的真实课堂视频记录构建的BAV-Classroom-VQA数据集，以促进严格评估。研究者展示了数据收集、注释的方法，并在该数据集上对选定的VQA模型进行了基准测试。", "conclusion": "初步实验结果表明，所有四种模型在回答行为相关的视觉问题方面表现出色，展示了它们在未来的课堂分析和干预系统中的潜在应用。"}
{"llm_update_time": "20250815", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.19712", "html_url": "https://arxiv.org/abs/2507.19712", "title": "Oranits: 在基于Open RAN的ITS中使用启发式和深度强化学习进行任务分配和任务卸载", "title_en": "Oranits: Mission Assignment and Task Offloading in Open RAN-based ITS using Metaheuristic and Deep Reinforcement Learning", "authors": "Ngoc Hung Nguyen,Nguyen Van Thieu,Quang-Trung Luu,Anh Tuan Nguyen,Senura Wanasekara,Nguyen Cong Luong,Fatemeh Kavehmadavani,Van-Dinh Nguyen", "background": "现有研究通常忽略了任务之间的复杂依赖关系和将任务卸载到边缘服务器的成本，导致决策不足。本研究基于Open Radio Access Network (Open RAN)构建了一个智能交通系统（ITS），利用自动驾驶车辆和移动边缘计算实现了高效处理。该研究通过引入Oranits系统模型，明确了任务依赖性和卸载成本，并通过车辆协作优化了性能。", "innovation": "本研究提出了两步优化方法：使用基于混沌高斯的全局ARO（CGG-ARO）的启发式进化计算算法作为单插槽优化的基础；设计了多代理双深度Q网络（MA-DDQN）深度强化学习框架，该框架整合了多代理协调和多动作选择机制，显著减少了任务分配时间并提高了适应性。", "conclusion": "模拟结果表明，CGG-ARO在完成任务数量和总体效益上分别提高了约7.1%和7.7%，而MA-DDQN在完成任务数量和总体效益上分别提高了11.0%和12.5%，这些结果突显了Oranits在动态ITS环境中的高效、适应性任务处理能力。"}
{"llm_update_time": "20250815", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.10778", "html_url": "https://arxiv.org/abs/2507.10778", "title": "使用LLM代理进行仓库空间问答", "title_en": "Warehouse Spatial Question Answering with LLM Agent", "authors": "Hsiang-Wei Huang,Jen-Hao Cheng,Kuang-Ming Chen,Cheng-Yen Yang,Bahaa Alattar,Yi-Ru Lin,Pyongkun Kim,Sangwon Kim,Kwangju Kim,Chung-I Huang,Jenq-Neng Hwang", "background": "现有大规模多模态语言模型（MLLMs）在空间理解任务上存在挑战。之前的解决方法主要依赖大规模MLLM微调来提升模型的空间理解能力。", "innovation": "本文提出了一种数据高效的方法。我们提出了一个具备强大空间推理能力的LLM代理系统，能够解决复杂室内仓库场景中的空间问题回答任务。该系统整合了多个工具，使LLM代理能够进行空间推理和API工具交互来回答复杂的空间问题。", "conclusion": "我们在2025 AI City Challenge Physical AI Spatial Intelligence Warehouse数据集上的广泛评估表明，该系统在物体检索、计数和距离估计等任务上实现了高精度和高效率。相关代码已公开。"}
{"llm_update_time": "20250815", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.04549", "html_url": "https://arxiv.org/abs/2508.04549", "title": "MSC：带有接地分割和帧级标注的海洋野生生物视频数据集", "title_en": "MSC: A Marine Wildlife Video Dataset with Grounded Segmentation and Clip-Level Captioning", "authors": "Quang-Trung Truong,Yuk-Kwan Wong,Vo Hoang Kim Tuyen Dang,Rinaldi Gotama,Duc Thanh Nguyen,Sai-Kit Yeung", "background": "海洋视频在视觉理解上面临着巨大挑战，因为海洋物体和周围环境的动态变化、摄像机运动以及水下场景的复杂性。现有的视频字幕数据集大多集中在通用或以人类为中心的领域，无法很好地适应海洋环境的复杂性，也不能深入揭示海洋生物信息。", "innovation": "该论文提出了一个两阶段的海洋物体导向视频字幕流水线，并构建了一个包含视频、文本和分割掩码三者三联体的综合视觉理解基准，以促进视觉建模和字幕生成，从而改善了海洋视频的理解和分析，以及海洋视频的生成。此外，该研究强调了视频分割在检测场景变化中的显著物体过渡方面的作用，显著丰富了字幕内容的含义。", "conclusion": "该研究发布了一个名为MSC的数据集和代码，用于海洋视频的理解和分析，以及生成海洋视频。"}
{"llm_update_time": "20250815", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.04586", "html_url": "https://arxiv.org/abs/2508.04586", "title": "当前AI会议模式不可持续：集中式AI会议危机诊断", "title_en": "Position: The Current AI Conference Model is Unsustainable! Diagnosing the Crisis of Centralized AI Conference", "authors": "Nuo Chen,Moming Duan,Andre Huikai Lin,Qian Wang,Jiaying Wu,Bingsheng He", "background": "人工智能（AI）会议对于推进研究、分享知识和促进学术社区具有重要意义。然而，随着这些会议的迅速扩张，传统的集中的会议模式变得越来越不可持续。本研究通过数据分析揭示了一个结构性危机，威胁到了科学传播、公平以及社区福祉的基本目标。研究指出了四个关键压力点：（1）科学上，每位作者的发表率在过去十年中翻了一番，每年达到4.5篇以上的论文；（2）环境上，一个会议的碳足迹超过了会议举办城市的每日排放量；（3）心理上，71%的在线社区讨论反映了负面情绪，35%提到了心理健康问题；（4）后勤上，顶级会议如NeurIPS 2024的参与人数开始超出场地容量。这些压力表明该系统与其核心使命不符。因此，本研究提出了社区联合会议（CFC）模式，将同行评审、展示和社交网络分离为全局协调但本地组织的组成部分，为AI研究提供了更加可持续、包容和有弹性的道路。", "innovation": "提出了社区联合会议（CFC）模式，该模式将同行评审、展示和社交网络分离为全局协调但本地组织的组成部分，从而为AI研究提供了一个更加可持续、包容和有弹性的路径。", "conclusion": "集中式AI会议模式由于其科学、环境、心理和后勤的压力，面临系统性危机。提出了CFC模型，为AI研究提供了一个更加可持续、包容和有弹性的路径。"}
{"llm_update_time": "20250815", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.05294", "html_url": "https://arxiv.org/abs/2508.05294", "title": "迈向具身代理型人工智能：LLM-和VLM-驱动的机器人自主性和交互的回顾与分类", "title_en": "Towards Embodied Agentic AI: Review and Classification of LLM- and VLM-Driven Robot Autonomy and Interaction", "authors": "Sahar Salimpour,Lei Fu,Farhad Keramat,Leonardo Militano,Giovanni Toffetti,Harry Edelman,Jorge Peña Queralta", "background": "基础模型，包括大型语言模型（LLMs）和视觉-语言模型（VLMs），已使机器人自主性和人机界面方面出现了前所未有的创新方法。同时，视觉-语言-动作模型（VLAs）或大型行为模型（LBMs）也提高了机器人系统的灵活性和能力。本文综述了一些朝着具身代理应用和架构发展的前沿工作，包括探索GPT风格的工具接口以及更复杂的AI代理作为协调员、规划者、感知执行者或通用接口系统。这些具有代理性的架构使机器人能够理解和执行自然语言指令、调用API、规划任务序列或协助操作和诊断。除了同行评审的研究，由于该领域的快速发展，论文还强调了社区驱动的项目、ROS软件包和工业框架，展示了新兴趋势。", "innovation": "本文提出了一个模型融合方法的分类体系，并对现有文献中代理在不同解决方案中的作用进行了比较分析，进一步揭示了代理型人工智能的发展趋势和特点，如基于LLMs和VLMs的机器人自主性和交互的支持方法和发展方向。论文强调了社区驱动的项目和工业框架，展示了该领域的新兴趋势。", "conclusion": "该论文对LLMs和VLMs驱动的机器人自主性和交互进行了回顾和分类，展示了代理型人工智能的发展，提出了一种模型集成方法的分类标，并对代理在不同解决方案中的作用进行了比较分析。"}
{"llm_update_time": "20250815", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.06445", "html_url": "https://arxiv.org/abs/2508.06445", "title": "自动化回声：本地化媒体中LLM使用量的增加", "title_en": "Echoes of Automation: The Increasing Use of LLMs in Newsmaking", "authors": "Abolfazl Ansari,Delvin Ce Zhang,Nafis Irtiza Tripto,Dongwon Lee", "background": "研究背景在于生成式人工智能（GenAI），尤其是大型语言模型（LLMs）的快速发展，带来对新闻报道真实性和作者身份的担忧。该研究通过分析超过40000篇来自主要媒体、地方媒体和高校媒体的新闻文章来探讨这一问题，涉及多种媒体格式。", "innovation": "研究采用三种先进的AI文本检测器（如Binoculars、Fast-Detect GPT、GPTZero）来检测AI生成的内容，发现近年来LLMs在新闻编写中的使用量显著增加，尤其是在地方和高校媒体中更为普遍。句子级别的分析发现，LLMs通常用于新闻的开头部分，而结论部分通常由人类撰写。语言分析表明，GenAI提高了文章的词汇丰富度和可读性，但降低了正式性，导致新闻写作风格变得更加统一，尤其是地方媒体更为明显。", "conclusion": "研究结论指出，虽然GenAI增加了新闻内容的词汇丰富度和可读性，但同时也降低了新闻的正式性，导致写作风格更加统一。尤其在地方媒体中，这种变化更为显著。"}
{"llm_update_time": "20250815", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.06800", "html_url": "https://arxiv.org/abs/2508.06800", "title": "Hardness-Aware Dynamic Curriculum Learning for Robust Multimodal Emotion Recognition with Missing Modalities", "title_en": "Hardness-Aware Dynamic Curriculum Learning for Robust Multimodal Emotion Recognition with Missing Modalities", "authors": "Rui Liu,Haolin Zuo,Zheng Lian,Hongyu Yuan,Qi Fan", "background": "近年来，多模态情绪识别（MER）中的缺失模态问题逐渐成为研究的关键方向。传统方法通常通过缺失模态重建来解决这个问题，但这些方法无法考虑到不同样本在重建难度上的差异，这限制了模型处理困难样本的能力。", "innovation": "本文提出了一种新颖的Hardness-Aware Dynamic Curriculum Learning框架，称为HARDY-MER。该框架在两个关键阶段运作：首先它估计每个样本的难度级别，然后在训练过程中战略性地强调困难样本，以增强模型在这些挑战性实例上的性能。具体来说，该框架引入了一种多视角硬度评估机制，该机制通过直接硬度（模态重建错误）和间接硬度（跨模态互信息）来量化重建难度，并引入了一种基于检索的动态课程学习策略，该策略通过检索具有相似语义信息的样本并平衡学习焦点来动态调整训练课程。", "conclusion": "在基准数据集上的大量实验显示，HARDY-MER在缺失模态场景中比现有方法表现出更一致的优越性能。我们的代码将在https://this.is.public链接公开。"}
{"llm_update_time": "20250815", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.01006", "html_url": "https://arxiv.org/abs/2507.01006", "title": "GLM-4.1V-Thinking和GLM-4.5V：基于可扩展强化学习的多功能多模态推理", "title_en": "GLM-4.1V-Thinking and GLM-4.5V: Towards Versatile Multimodal Reasoning with Scalable Reinforcement Learning", "authors": "GLM-V Team:Wenyi Hong,Wenmeng Yu,Xiaotao Gu,Guo Wang,Guobing Gan,Haomiao Tang,Jiale Cheng,Ji Qi,Junhui Ji,Lihang Pan,Shuaiqi Duan,Weihan Wang,Yan Wang,Yean Cheng,Zehai He,Zhe Su,Zhen Yang,Ziyang Pan,Aohan Zeng,Baoxu Wang,Bin Chen,Boyan Shi,Changyu Pang,Chenhui Zhang,Da Yin,Fan Yang,Guoqing Chen,Jiazheng Xu,Jiale Zhu,Jiali Chen,Jing Chen,Jinhao Chen,Jinghao Lin,Jinjiang Wang,Junjie Chen,Leqi Lei,Letian Gong,Leyi Pan,Mingdao Liu,Mingde Xu,Mingzhi Zhang,Qinkai Zheng,Sheng Yang,Shi Zhong,Shiyu Huang,Shuyuan Zhao,Siyan Xue,Shangqin Tu,Shengbiao Meng,Tianshu Zhang,Tianwei Luo,Tianxiang Hao,Tianyu Tong,Wenkai Li,Wei Jia,Xiao Liu,Xiaohan Zhang,Xin Lyu,Xinyue Fan,Xuancheng Huang,Yanling Wang,Yadong Xue,Yanfeng Wang,Yanzi Wang,Yifan An,Yifan Du,Yiming Shi,Yiheng Huang,Yilin Niu,Yuan Wang,Yuanchang Yue,Yuchen Li,Yutao Zhang,Yuting Wang,Yu Wang,Yuxuan Zhang,Zhao Xue,Zhenyu Hou,Zhengxiao Du,Zihan Wang,Peng Zhang,Debing Liu,Bin Xu,Juanzi Li,Minlie Huang,Yuxiao Dong,Jie Tang", "background": "本文介绍了一种旨在提高通用多模态理解和推理能力的视觉语言模型（VLMs）家族：GLM-4.1V-Thinking和GLM-4.5V。作者首先通过大规模预训练开发了一种强大的视觉基础模型，这被认为设定了最终性能的上限。然后提出了一种强化学习与课程采样（RLCS）的方法，以解锁模型的全部潜力并使其在各种任务中提升能力。", "innovation": "文中提出了增强学习与课程采样（RLCS）框架，该框架用于提升视觉语言模型的性能，使模型在STEM问题解决、视频理解、内容识别、编程、图像定位、基于GUI的代理和长文档解释等多个领域的能力全面提升。GLM-4.5V在开源模型中取得了最先进的性能，GLM-4.1V-9B-Thinking也在多项基准测试中表现出超越更大规模模型的结果。", "conclusion": "GLM-4.5V在42个公开基准测试中的几乎所有任务中达到了最先进的性能，与封闭源代码模型（如Gemini-2.5-Flash）相比，在编程和基于GUI的代理等具有挑战性的任务中也表现出竞争力甚至优越性。同时，更小的GLM-4.1V-9B-Thinking也表现出了强大的竞争力， superiority结果在29个基准测试中超过了Qwen2.5-VL-72B。这两种模型已经开源，可以供用户下载和使用。"}
{"llm_update_time": "20250815", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.07178", "html_url": "https://arxiv.org/abs/2508.07178", "title": "通过从隐式反馈中去噪虚假兴趣改进个性化标题生成", "title_en": "Improved Personalized Headline Generation via Denoising Fake Interests from Implicit Feedback", "authors": "Kejin Liu,Junhong Lian,Xiang Ao,Ningtao Wang,Xing Fu,Yu Cheng,Weiqiang Wang,Xinyu Liu", "background": "准确的个性化标题生成依赖于精确捕捉用户的兴趣，现有方法忽略了历史点击流中的个性化无关点击噪声，这可能导致生成的标题与用户真实偏好偏差较大。现有研究未能完全揭示这种点击噪声对个性化生成质量的负面影响，本研究通过用户和新闻维度的严格分析揭示了点击噪声的不利影响，并基于此提出了一种创新的去噪框架。", "innovation": "提出了一种新颖的个性化标题生成（PHG-DIF）框架，该框架通过隐式反馈去噪虚假兴趣，首先采用了双阶段过滤有效去除具有短停留时间和异常点击爆发的点击流噪声，然后利用多级时间融合动态建模用户不断演变和多方面的兴趣，以实现精确的用户画像。此外，还提供了dt-pens数据集，包含1000个精心策划的用户和几乎10000个带有历史停留时间注释的注释个性化标题。实验结果表明，PHG-DIF在减轻点击噪声的负面影响方面表现出色，并显著提高了标题质量，达到当前最先进的(SOTA)水平。", "conclusion": "我们提出的框架和数据集显著改善了个性化标题生成的质量，为该领域的研究提供了新的基准和方法。"}
{"llm_update_time": "20250815", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.07970", "html_url": "https://arxiv.org/abs/2508.07970", "title": "WeChat-YATT: 又一个微信Transformer训练器", "title_en": "WeChat-YATT: A Simple, Scalable and Balanced RLHF Trainer", "authors": "Junyu Wu,Weiming Chang,Xiaotao Liu,Guanyou He,Tingfeng Xian,Haoqiang Hong,Boqi Chen,Haotao Tian,Tao Yang,Yunsheng Shi,Feng Lin,Ting Yao", "background": "经验强化学习（RLHF）已经成为大规模语言模型和多模态系统训练的主流方式。尽管现有的RLHF训练框架推动了大量进展，但在处理复杂多模态工作流以及适应动态负载时，仍面临显著挑战。当前系统在管理大型模型时常常遇到控制器可扩展性问题，并且在复杂RLHF流水线的调度和动态采样与资源分配中存在低效率问题。", "innovation": "WeChat-YATT引入了一种并行控制器编程模型，实现复杂RLHF工作的灵活高效调度，解决了集中控制器架构的瓶颈问题，增强了大规模数据场景下的可扩展性。此外，WeChat-YATT提出了一种动态放置方案，灵活地分配计算资源和调度工作负载，显著减少了硬件空闲时间并提高了GPU利用率，特别是在多变的训练条件下。", "conclusion": "WeChat-YATT在一系列实验场景中取得了显著的吞吐量提升，优于最先进的RLHF训练框架，并在微信产品功能的大型用户群训练模型方面取得了实际部署效果，证明其有效性和鲁棒性。WeChat-YATT已开源。"}
{"llm_update_time": "20250815", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.08052", "html_url": "https://arxiv.org/abs/2508.08052", "title": "理解持续学习中模型容量动态", "title_en": "On Understanding of the Dynamics of Model Capacity in Continual Learning", "authors": "Supriyo Chakraborty,Krishnan Raghavan", "background": "持续学习（CL）中的稳定-可塑性难题与神经网络（NN）的能力紧密相关，其能力在于代表任务。这是持续学习中的一个基本挑战。", "innovation": "介绍了持续学习的有效模型容量（CLEMC），以描述稳定-可塑性平衡点的动态行为。提出了一种差分方程来建模NN、任务数据和优化过程之间的相互作用。展示了有效容量及由此扩展的稳定-可塑性平衡点本质上是非站定的。证明了无论NN架构或优化方法如何，当新来的任务分布与先前的不同时，NN代表新任务的能力都会减弱。", "conclusion": "广泛的实验支持了理论发现，涵盖从小型前馈网络、卷积网络到中型图神经网络以及具有数百万参数的基于Transformer的大语言模型。"}
{"llm_update_time": "20250815", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.13307", "html_url": "https://arxiv.org/abs/2506.13307", "title": "预训练潜扩散模型在生成未见SAR图像中的微调技术定量比较", "title_en": "Quantitative Comparison of Fine-Tuning Techniques for Pretrained Latent Diffusion Models in the Generation of Unseen SAR Images", "authors": "Solène Debuysère,Nicolas Trouvé,Nathan Letheule,Olivier Lévêque,Elise Colin", "background": "本文提出了一种框架，用于适应大型预训练潜扩散模型以生成高分辨率合成孔径雷达（SAR）图像。这种框架能够实现可控的合成并创建超出现有训练集范畴的稀有或分布外场景。该研究不从零开始训练特定任务的小型模型，而是将一个开源的文本到图像基础模型适应SAR模式，并利用其语义先验来对齐提示与SAR成像物理特性（侧面观测几何、斜距投影和相干光斑统计尾重分布）。研究者使用包含10万张SAR图像的数据集，对全微调和参数高效的低秩适应（LoRA）方法在UNet扩散骨干、变分自编码器（VAE）和文本编码器上的效果进行了比较。评估方法结合了真实SAR幅度分布的距离、纹理相似性（通过灰度共生矩阵描述符）以及使用SAR专化的CLIP模型的语义对齐。", "innovation": "本研究创新性地提出了一种适应预训练潜扩散模型以生成SAR图像的框架，该框架不是从零开始训练任务特定的小模型，而是使用开源的文本到图像模型进行适应，并且提出了全UNet微调与LoRA相结合的方法以保持SAR图像的几何和纹理属性，同时保持提示的精度。", "conclusion": "研究结果表明，混合策略（全UNet微调与LoRA在文本编码器上进行调整，以及学习到的标记嵌入）在保持SAR几何和纹理特性的同时最好地保持了提示的忠实度。该框架支持基于文本的控制和多模态条件（例如，分割图、TerraSAR-X或光学引导）的应用，为大规模SAR场景数据增强和未见过场景的模拟开辟了新的途径。"}
{"llm_update_time": "20250815", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.06259", "html_url": "https://arxiv.org/abs/2508.06259", "title": "SIFThinker：基于空间感知的图像关注用于视觉推理", "title_en": "SIFThinker: Spatially-Aware Image Focus for Visual Reasoning", "authors": "Zhangquan Chen,Ruihui Zhao,Chuwei Luo,Mingze Sun,Xinlei Yu,Yangyang Kang,Ruqi Huang", "background": "当前的多模态大规模语言模型（MLLMs）在复杂的视觉任务（例如空间理解、细粒度感知）中仍然面临重大挑战。现有的方法尝试结合视觉推理，但未能利用空间提示来迭代地细化对提示相关区域的关注。现有的方法主要集中在固定的视觉感知上，缺乏对空间信息的动态利用，从而限制了模型在过程中保持正确关注的能力。因此，需要一种新的模型来改进在有挑战的视觉任务中对相关图像区域的感知和理解。", "innovation": "本文提出了SIFThinker，一种空间感知的‘以图思考’框架，模仿人类视觉知觉。SIFThinker通过交错使用深度增强的边界框和自然语言实现了注意力修正和图像区域聚焦。文章的主要贡献包括：引入了一种逆扩张前向推理策略，这导致了SIF-50K数据集的构建，并且提出了GRPO-SIF——一种强化训练框架，它将深度指导的视觉接地整合进统一的推理管道中，使模型能够动态地修正并聚焦于与提示相关区域。实验表明，SIFThinker在空间理解和细粒度视觉感知上优于现有方法，同时保持了强大的泛化能力，突显了该方法的有效性。", "conclusion": "该方法强调了对空间信息处理的改进，并通过实验验证，SIFThinker显著提高了模型在复杂视觉任务中的能力，尤其是在空间理解和细粒度视觉感知方面。"}
{"llm_update_time": "20250815", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.08285", "html_url": "https://arxiv.org/abs/2508.08285", "title": "幻觉检测中的虚假进步：重新评估大语言模型中的幻觉检测", "title_en": "The Illusion of Progress: Re-evaluating Hallucination Detection in LLMs", "authors": "Denis Janiak,Jakub Binkowski,Albert Sawczyn,Bogdan Gabrys,Ravid Shwartz-Ziv,Tomasz Kajdanowicz", "background": "大语言模型（LLMs）已经极大地改变了自然语言处理领域，但它们倾向于夸大虚构信息的现象给可靠部署带来了严重挑战。尽管已经提出了许多幻觉检测方法，但这些方法的评估往往依赖于ROUGE，这是一项基于词汇重叠度量的方法，这容易导致与人类判断的失配。", "innovation": "研究展示了精确的人类研究发现，尽管ROUGE具有较高的召回率，但其极低的精确率会导致误导性性能估计。本研究还揭示了一个简单基于响应长度的启发式方法能够与复杂的检测技术竞争，这暴露出当前评估实践中的根本缺陷。研究建议采用语义感知和鲁棒的评估框架，以准确衡量幻觉检测方法的真实性能。", "conclusion": "本研究强调了采纳语义感知和稳健的评估框架的重要性，以确保大语言模型输出的信任度。"}
{"llm_update_time": "20250815", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.08535", "html_url": "https://arxiv.org/abs/2508.08535", "title": "LLM-Driven Adaptive 6G-Ready Wireless Body Area Networks: Survey and Framework", "title_en": "LLM-Driven Adaptive 6G-Ready Wireless Body Area Networks: Survey and Framework", "authors": "Mohammad Jalili Torkamani,Negin Mahmoudi,Kiana Kiashemshaki", "background": "无线身体区域网络（WBANs）能够持续监测生理信号，适用于慢性病管理、应急响应等应用场景。6G通信、后量子密码学和能量收集技术的发展有望提升WBAN性能，但将这些技术集成到统一、自适应系统中仍颇具挑战。当前WBAN架构和安全机制在自适应性、能量效率和量子抵抗安全性方面存在局限，需要进一步研究。", "innovation": "提出了一种基于大语言模型驱动的自适应WBAN框架。该框架通过使用大语言模型作为认知控制平面，实时协调路由、物理层选择、微能量收集和后量子安全，旨在实现下一代移动医疗应用中超可靠的、安全的、自优化的WBAN系统。", "conclusion": "综述了现有基于启发式设计的限制，并提出了资源受限、6G准备的医疗系统的研究议程目标，旨在推动超可靠、安全的WBAN技术的发展，适应未来的移动健康应用需求。"}
{"llm_update_time": "20250815", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.08855", "html_url": "https://arxiv.org/abs/2508.08855", "title": "BiasGym：如何发现并移除大型语言模型中的偏见", "title_en": "BiasGym: Fantastic LLM Biases and How to Find (and Remove) Them", "authors": "Sekh Mainul Islam,Nadav Borenstein,Siddhesh Milind Pawar,Haeun Yu,Arnav Arora,Isabelle Augenstein", "background": "理解大型语言模型（LLMs）中的偏见和刻板印象对于开发有效的缓解策略至关重要。偏见行为常常是隐秘和复杂的，即使是刻意诱发也难以辨识，因此系统分析和去偏工作尤其具有挑战性。", "innovation": "作者提出了BiasGym，这是一种简单、成本效益高且可泛化的框架，用于可靠地注入、分析和缓解LLMs中的概念关联偏差。BiasGym包括两个组件：BiasInject，通过基于标记的微调将特定偏见注入模型（同时保持模型冻结），以及BiasScope，利用这些注入的信号来识别并引导导致偏见行为的组件。", "conclusion": "BiasGym在减少现实世界中的刻板印象（例如，意大利人是‘鲁莽的司机’）和探索虚构关联（例如，来自虚构国家的人有‘蓝色的皮肤’）方面显示出有效性，证明了其在安全干预和解释性研究中的实用性。"}
{"llm_update_time": "20250815", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.08543", "html_url": "https://arxiv.org/abs/2508.08543", "title": "M3-Net: 一种经济高效的无图MLP基模型用于交通预测", "title_en": "M3-Net: A Cost-Effective Graph-Free MLP-Based Model for Traffic Prediction", "authors": "Guangyin Jin,Sicong Lai,Xiaoshuai Hao,Mingtao Zhang,Jinlei Zhang", "background": "准确的交通预测是当前智能交通系统发展中一项基本而关键的任务。现有的主流交通预测方法依赖于时空图神经网络和时空注意力机制等。然而，这些现有方法主要面临两个挑战：一是依赖完整的交通网络结构；二是需要复杂的设计来捕捉复杂的时空依赖关系。这些限制对大规模数据集上高效部署和操作深度学习模型构成了重大挑战。", "innovation": "我们提出了一个成本效益高且无图的多层感知器（MLP）基模型M3-Net，该模型不仅利用时间序列和时空嵌入进行高效的特征处理，还首次引入了一种带有混合专家机制（MoE）的新型MLP-Mixer架构。实验结果表明，该模型在预测性能和轻量级部署方面具有明显的优越性。", "conclusion": "本文提出了一种基于MLP的无图高效交通预测模型M3-Net，通过时空嵌入和新型的MLP-Mixer架构，模型在多个真实数据集上的实验结果证明了其优越的预测性能和轻量级部署特性。"}
{"llm_update_time": "20250815", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.09158", "html_url": "https://arxiv.org/abs/2508.09158", "title": "EvaDrive：基于进化对抗优化的端到端自主驾驶", "title_en": "EvaDrive: Evolutionary Adversarial Policy Optimization for End-to-End Autonomous Driving", "authors": "Siwen Jiao,Kangan Qian,Hao Ye,Yang Zhong,Ziang Luo,Sicong Jiang,Zilin Huang,Yangyi Fang,Jinyu Miao,Zheng Fu,Yunlong Wang,Kun Jiang,Diange Yang,Rui Fan,Baoyun Peng", "background": "自动驾驶在实现类人迭代决策方面面临重大挑战，这种决策是逐步生成、评估和改进轨迹提议的过程。现有的生成-评估框架隔离了轨迹生成和质量评估，阻碍了必要迭代优化的规划过程。强化学习方法将多维度的偏好压缩为单一标量奖励，掩盖了关键权衡和单一标量化现象。", "innovation": "为了解决上述问题，本文提出了EvaDrive，一种新颖的多目标强化学习框架，通过对抗优化建立了轨迹生成与评估的真正闭环协同进化。EvaDrive将轨迹规划视为多轮对抗游戏。在游戏中，层次化的生成器通过结合自回归意图建模来实现时间因果性建模和基于扩散的方法提高空间灵活性，生成候选路径。这些候选路径由一个可训练的多目标评论家进行严格的评估，该评论家明确地保留了不同的偏好结构，而不将它们压缩为单一的标量化。这种对抗互动，通过帕累托前沿选择机制引导，使迭代多轮优化成为可能，有效避免局部最优，并保持路径的多样性。", "conclusion": "EvaDrive在NASIM和Bench2Drive基准测试中表现出色，实现了端到端的自主驾驶技术。实验结果表明，在NASIM v1中达到94.9 PDMS（超过DiffusionDrive 6.8，DriveSuprim 5.0，TrajHF 0.9），在Bench2Drive中达到64.96驾驶得分。EvaDrive能够通过动态权重生成多种驾驶风格，无需外部偏好数据，提供了一个闭环协同进化框架，去实现类人迭代决策，引入了一种无标量化轨迹优化的新方法。"}
{"llm_update_time": "20250815", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.08601", "html_url": "https://arxiv.org/abs/2508.08601", "title": "Yan: 核心互动视频生成", "title_en": "Yan: Foundational Interactive Video Generation", "authors": "Deheng Ye,Fangyun Zhou,Jiacheng Lv,Jianqi Ma,Jun Zhang,Junyan Lv,Junyou Li,Minwen Deng,Mingyu Yang,Qiang Fu,Wei Yang,Wenkai Lv,Yangbin Yu,Yewen Wang,Yonghang Guan,Zhihao Hu,Zhongbin Fang,Zhongqian Sun", "background": "本文提出了Yan，一个基础框架，涵盖了交互视频生成的整个流程，从模拟和生成到编辑。Yan框架包含三个核心模块，对提高交互视频生成领域的研究和发展具有重要意义。", "innovation": "1. AAA级模拟：设计了一种高度压缩、低延迟的3D-VAE，结合了基于KV缓存的滑动窗口消噪推理过程，实现了1080P/60FPS实时交互式模拟。\n2. 多模态生成：引入了一种分层自回归标题方法，将游戏特定知识注入开放域多模态视频扩散模型(VDMs)，然后将VDM转换为帧级、动作可控的实时无限交互视频生成器。当文本和视觉提示来自不同领域时，模型表现出强大的泛化能力，能够灵活地根据用户提示在不同领域之间融合和组合风格和机制。\n3. 多粒度编辑：提出了一种混合模型，明确地将交互机制模拟与视觉渲染分离，使得通过文本在交互期间实现多粒度视频内容编辑成为可能。", "conclusion": "Yan框架集成了这些模块，将交互视频生成推进到一个全面的人工智能驱动的交互创作范式，为下一代创意工具、媒体和娱乐指明了方向。"}
{"llm_update_time": "20250815", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.09185", "html_url": "https://arxiv.org/abs/2508.09185", "title": "一个具有解释性的增强现实认知攻击检测的神经符号框架", "title_en": "A Neurosymbolic Framework for Interpretable Cognitive Attack Detection in Augmented Reality", "authors": "Rongqian Chen,Allison Andreyev,Yanming Xiu,Mahdi Imani,Bin Li,Maria Gorlatova,Gang Tan,Tian Lan", "background": "增强现实（AR）通过在物理世界叠加虚拟元素来丰富感知。由于其日益增长的流行性，认知攻击已经越来越多地引起关注，这些攻击通过修改AR内容来操控用户的语义感知。现有的检测方法常专注于视觉变化，主要在像素或图像层次上进行处理，缺乏语义推理能力，或者依赖预训练的视觉-语言模型，这些模型作为黑盒方法，具有较低的可解释性。该项研究针对这些挑战，介绍了一种名为CADAR的新颖神经符号方法，用于AR中的认知攻击检测。", "innovation": "该研究提出了一种新的神经符号方法CADAR，通过融合多模态视觉-语言输入并使用神经视觉-语言模型获得符号感知图表示，结合先验知识、显著度加权和时间相关性，采用粒子滤波基于的统计推理方法来检测认知攻击。这种方法既保留了预训练视觉-语言模型的适应性，又具备粒子滤波的可解释性和推理严谨性。实验结果表明，该方法在挑战性的AR攻击场景中比强基准提高了最高10.7%的准确率，表明神经符号方法在有效性和可解释性方面具有潜力。", "conclusion": "研究展示了CADAR在解释性和有效性方面优于现有方法，认为神经符号方法能够有效和可解释地检测AR中的认知攻击。"}
{"llm_update_time": "20250815", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.09178", "html_url": "https://arxiv.org/abs/2508.09178", "title": "IAD-R1: 强化工业异常检测中一致推理", "title_en": "IAD-R1: Reinforcing Consistent Reasoning in Industrial Anomaly Detection", "authors": "Yanhui Li,Yunkang Cao,Chengliang Liu,Yuan Xiong,Xinghui Dong,Chao Huang", "background": "工业异常检测是现代制造的关键组成部分，但由于缺乏缺陷样本，传统的检测方法只能在特定场景中应用。虽然视觉-语言模型（VLMs）在泛化能力方面表现出显著优势，但在工业异常检测领域的性能仍然有限。", "innovation": "本文提出了IAD-R1，这是一种通用的后训练框架，适用于不同架构和参数规模的VLMs，显著增强了其异常检测能力。IAD-R1采用两阶段训练策略：感知激活监督微调（PA-SFT）阶段利用精心构建的高质量Chain-of-Thought数据集（Expert-AD）进行训练，增强异常感知能力并建立推理-答案关联；结构控制组相对策略优化（SC-GRPO）阶段通过精心设计的奖励函数实现从“异常感知”到“异常解释”的能力飞跃。", "conclusion": "实验结果显示，IAD-R1在7种VLMs上均取得了显著改进，其中在DAGM数据集上改进最大，平均准确率比0.5B基线高43.3%。值得注意的是，用IAD-R1训练的0.5B参数模型在零样本设置中超过了包括GPT-4.1和Claude-Sonnet-4在内的商用模型，证明了IAD-R1的有效性和优越性。数据集、代码和所有模型权重将在本文提供的链接处公开。"}
{"llm_update_time": "20250815", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.08895", "html_url": "https://arxiv.org/abs/2508.08895", "title": "ASPD：探索LLMs内在并行性的自适应串行并行解码", "title_en": "ASPD: Unlocking Adaptive Serial-Parallel Decoding by Exploring Intrinsic Parallelism in LLMs", "authors": "Keyu Chen,Zhifeng Shen,Daohai Yu,Haoqian Wu,Wei Wen,Jianfeng He,Ruizhi Qiao,Xing Sun", "background": "大语言模型（LLMs）的规模和复杂性的增加对推理延迟提出了显著挑战，主要原因在于它们自回归解码模式序列化的下一个标记预测性质。通过重新审视自回归模型的输出，我们观察到一些片段具有可并行化的结构，我们称之为内在并行性。同时解码每个可并行分支（即并行解码）可以显著提高LLMs的整体推理速度。研究表明，ASPD在广义任务、检索强化生成、数学推理等领域的效果和效率上取得了前所未有的表现。特别是在Vicuna Bench测试中，我们的方法在提高3.19倍的速度（平均提高1.85倍）的同时，保持了与自回归模型相差1%的回复质量，实现了显著加速而不损害生成质量。我们的框架为高效LLMs并行推理设定了新的基准，为包括AI驱动的客户服务机器人和答案检索引擎在内的延迟敏感应用提供了部署途径。", "innovation": "提出了自适应串行并行解码（ASPD），它解决了两个核心挑战：自动构建可并行化数据和高效的并行解码机制。具体来说，我们引入了一个非侵入式流水线，它可以自动从自回归模型的响应中提取和验证可并行化的结构。为了使自适应串行并行解码更高效，我们实现了一个混合解码引擎，能够在保持可重用的KV缓存的同时，在串行和并行解码模式之间无缝转换，从而最大化计算效率。", "conclusion": "ASPD在广义任务、检索强化生成、数学推理等领域的效果和效率上取得了前所未有的表现。特别是在Vicuna Bench测试中，我们的方法在提高3.19倍的速度（平均提高1.85倍）的同时，保持了与自回归模型相差1%的回复质量，实现了显著加速而不损害生成质量。我们的框架为高效LLMs并行推理设定了新的基准，为包括AI驱动的客户服务机器人和答案检索引擎在内的延迟敏感应用提供了部署途径。"}
{"llm_update_time": "20250815", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.09146", "html_url": "https://arxiv.org/abs/2508.09146", "title": "理论上理解基于Transformer的即席学习优化CSMA", "title_en": "To Theoretically Understand Transformer-Based In-Context Learning for Optimizing CSMA", "authors": "Shugang Hao,Hongbo Li,Lingjie Duan", "background": "当前，二进制指数退避方案被广泛使用在WiFi 7中，但在动态信道环境中依然会导致较差的吞吐量性能。最近基于模型的方法（例如非持久性和$p$-持久性CSMA）仅能在已知和固定的节点密度下优化退避策略，但由于节点密度估计不准确仍会导致较大的吞吐量损失。已有研究在通过模式识别来优化信道访问方面没有涉及。本文首次提出基于LLM变压器的即席学习（ICL）理论，用于优化信道访问策略，克服固定密度模型的局限性，在未知节点密度环境中提供更优策略，保证了一定程度的性能优化和收敛速度。", "innovation": "本文首次提出基于LLM变压器的即席学习（ICL）理论，设计了基于变压器的ICL优化器来预先收集碰撞阈值数据样例和查询碰撞案例，作为输入以学习模式并生成预测竞争窗口阈值（CWT）。开发了一种高效的算法来训练变压器以达到近乎最优的CWT预测，并且即使存在输入错误数据也能保持预测偏差最小化。实验结果表明，与现有的基于模型和强化学习的方法相比，该方法在未知节点密度时具有更快的收敛速度和近似最优的吞吐量性能。", "conclusion": "本文在理论上理解了基于Transformer的即席学习对于优化CSMA的重要性，提出的模型在未知网络密度场景下能维持相对高效的性能和快速收敛。"}
{"llm_update_time": "20250815", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.09299", "html_url": "https://arxiv.org/abs/2508.09299", "title": "通过分布式机器学习和基于区块链的模型验证实现去中心化天气预报", "title_en": "Decentralized Weather Forecasting via Distributed Machine Learning and Blockchain-Based Model Validation", "authors": "Rilwan Umar,Aydin Abadi,Basil Aldali,Benito Vincent,Elliot A. J. Hurley,Hotoon Aljazaeri,Jamie Hedley-Cook,Jamie-Lee Bell,Lambert Uwuigbusun,Mujeeb Ahmed,Shishir Nagaraja,Suleiman Sabo,Weaam Alrbeiqi", "background": "天气预报在灾害预防、农业和资源管理中起着至关重要的作用，但当前的集中式预报系统正受到安全漏洞、扩展性有限以及单一故障点的限制。本研究旨在应对这些挑战，提出一种结合分布式机器学习（特别是联邦学习）和区块链技术的去中心化天气预报框架。", "innovation": "本文创新地结合了联邦学习和区块链技术来构建去中心化的天气预报系统。联邦学习允许在无需暴露本地敏感数据的情况下进行协作模型训练，这增强了隐私性并减少了数据传输开销，而以太坊区块链则确保了模型更新的透明性和可靠性。通过引入基于信誉的投票机制并利用星际文件系统（IPFS）进行高效离链存储，进一步增强了系统的安全性。实验结果表明，该方法不仅提高了预报的准确性，还增强了系统的弹性和扩展性，使其成为在安全关键的现实环境中部署的可行选择。", "conclusion": "该研究提出的方法显著改善了天气预报系统的性能和安全性，并展示了其在现实世界部署中的潜力，尤其是对于需要高度安全性的环境而言。"}
{"llm_update_time": "20250815", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.09297", "html_url": "https://arxiv.org/abs/2508.09297", "title": "带有偏见的AI改善人类决策但降低了信任", "title_en": "Biased AI improves human decision-making but reduces trust", "authors": "Shiyang Lai,Junsol Kim,Nadav Kunievsky,Yujin Potter,James Evans", "background": "当前的AI系统通过实现意识形态中立来最小化风险，但这可能会引入自动化偏见，削弱人类在决策过程中的认知参与。作者通过随机试验研究了文化偏见的AI是否能提高人类决策的效果，参与者们在信息评估任务中与不同的GPT-4o版本互动。", "innovation": "进行随机试验探究具有文化偏见的AI是否能提升人类决策的效果，发现具有偏见的AI助手能够提高人类的决策表现、增加参与度并减少评估偏差。当参与者遇到对立观点时，这些好处会更为显著。然而，这带来了信任成本：参与者低估了有偏见的AI，并高估了中立的系统。展示两种具有不同偏见的AI，能够缩小人们对两者的感知与实际表现之间的差距。这些发现挑战了关于AI中立性的传统智慧，暗示战略性地整合多样化的文化偏见可能促进改进且更具韧性的决策能力", "conclusion": "这项研究的结果表明，虽然具有偏见的AI能够提高人类的决策效果和参与度，但这也降低了人们对这些AI的信任。通过展示两种具有不同偏见的AI，能够消除人们对这些AI的偏见和信任之间的差距。这些发现挑战了关于AI中立性的传统观念，表明战略性地整合文化偏见可能有助于改进和提升人类决策的质量。"}
{"llm_update_time": "20250815", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.09848", "html_url": "https://arxiv.org/abs/2508.09848", "title": "PRELUDE：一个设计用于长上下文理解和推理的全局理解和推理基准", "title_en": "PRELUDE: A Benchmark Designed to Require Global Comprehension and Reasoning over Long Contexts", "authors": "Mo Yu,Tsz Ting Chung,Chulun Zhou,Tong Li,Rui Lu,Jiangnan Li,Liyan Xu,Haoshu Lu,Ning Zhang,Jing Li,Jie Zhou", "background": "现有的基准测试主要关注于现有故事内部的一致性和理解。PRELUDE则通过判断角色的前传故事与原著的原书典故一致性，提供了对长文本理解能力更强的需求，这种需求涉及更深层次的推理和全局理解，因为前传故事并不属于原故事的一部分，因此评估其合理性通常需要搜索和整合只有间接相关的信息。", "innovation": "PRELUDE是一个新的基准测试，用于评估模型在长文本上下文理解方面的表现。区别于传统的基准测试，PRELUDE强调对全局理解和深度推理的要求，使评估更加严格。研究发现，在此任务上的表现，现有的以情境学习、检索增强等技术和最新的LLM以及商业级的DeepResearch服务相比人类相差超过15%，进一步的人类研究表明，模型常常提供正确答案但推理错误，导致在推理准确性上约30%的差距。", "conclusion": "实验结果揭示了长上下文理解和推理的深远挑战，现有的方法和模型在PRELUDE任务上的表现落后于人类。这表明在这一领域仍有很大的改进空间。"}
{"llm_update_time": "20250815", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.09991", "html_url": "https://arxiv.org/abs/2508.09991", "title": "桥接AI创新与医疗需求：BC癌症登记处引入现代NLP的经验教训", "title_en": "Bridging AI Innovation and Healthcare Needs: Lessons Learned from Incorporating Modern NLP at The BC Cancer Registry", "authors": "Lovedeep Gondara,Gregory Arbour,Raymond Ng,Jonathan Simkin,Shebnum Devji", "background": "从临床文档中自动化提取数据在医疗环境中能显著提高效率，然而部署自然语言处理（NLP）解决方案面临实际挑战。本文基于在不列颠哥伦比亚癌症登记处（BCCR）实施各种NLP模型进行信息提取和分类任务的经验，分享了项目生命周期中关键的学习教训。", "innovation": "本文强调基于清晰的业务目标而非单纯的技术准确性定义问题的重要性，采用迭代开发方法，并在项目伊始就促进跨学科合作和共创设计，包括与领域专家、最终用户及AI/ML专家的紧密合作。还讨论了实际的模型选择（包括混合方法和适当简单的办法）以及注重高质量数据（代表性、漂移、注释），并实施严格的错误缓解策略，如人工在环验证和持续审计。并且强调了建立组织的AI素养。", "conclusion": "本文提供的实用考虑，可推广到超出癌症登记处的范围，为希望成功实施AI/NLP解决方案以改进数据管理流程并最终提高患者护理和公共卫生结果的医疗机构提供指导。"}
{"llm_update_time": "20250815", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.09202", "html_url": "https://arxiv.org/abs/2508.09202", "title": "个性化特征翻译：一种高效的无源域适应方法", "title_en": "Personalized Feature Translation for Expression Recognition: An Efficient Source-Free Domain Adaptation Method", "authors": "Masoumeh Sharafi,Soufiane Belharbi,Houssem Ben Salem,Ali Etemad,Alessandro Lameiras Koerich,Marco Pedersoli,Simon Bacon,Eric Granger", "background": "基于面部表情识别（FER）模型被广泛应用于视频情感计算应用中，如人机交互和健康监护。然而，深度学习的FER模型通常难以处理微妙的表情和高度的个体间差异，限制了其在实际应用中的性能。为改进这一问题，已经提出了无源领域适应（SFDA）方法，可以利用目标领域中的未标记数据来个性化预训练的源模型，从而避免数据隐私、存储和传输的限制。此外，在无法获得源数据的情况下，只有未标记的目标数据（仅包含中性表情）可用，现有SFDA方法大多不能仅依靠单一类别的目标数据来进行适应。因此，使用模型生成非中性表情的面部图像既不稳定又计算量大。本文针对这种情况，提出了一种新的个性化特征翻译（PFT）方法，该方法在潜在空间中操作，简化了面部表情生成的复杂性和噪声，从而提高了面部表情识别的性能，并能够在不使用原数据或图像合成的情况下优化分类所需的判别嵌入。", "innovation": "本文提出了一种名为个性化特征翻译（PFT）的SFDA方法。与现有的基于图像的翻译方法不同，PFT在潜在空间中操作，无需合成面部图像即可实现特征翻译。该方法首先使用源域数据预训练转换器，将一个源主体的特定风格特征转化为另一个主体。通过优化表达一致性与风格感知目标的结合，PFT能够保留表情信息。然后，转换器在仅包含中性表情的未标记目标数据上进行适应，不需要使用源数据或图像生成。这种方法在潜在空间中进行翻译，避免了面部表情生成的复杂性和噪声，能够生成优化分类所需的具有判别性的嵌入。这种创新方法减少了计算开销，并凭借一个轻量级的转换器实现了模型的部分适应，使其比基于图像的方法更加高效。", "conclusion": "本文提出了一种新的个性化特征翻译（PFT）方法，它能够在无源域适应场景中实现高效的面部表情识别。通过在潜在空间中操作并利用未标记的中性表情目标数据，PFT避免了复杂的面部表情生成过程，提高了模型的适应性和分类效果，减少了计算成本。这种方法对于资源受限的场景尤其有价值，能够更好地处理微妙的表情变化和个体间的差异。"}
{"llm_update_time": "20250815", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.09632", "html_url": "https://arxiv.org/abs/2508.09632", "title": "Preacher: Paper-to-Video Agentic System", "title_en": "Preacher: Paper-to-Video Agentic System", "authors": "Jingwei Liu,Ling Yang,Hao Luo,Fan Wang,Hongyan Li,Mengdi Wang", "background": "论文到视频的任务是将研究论文转化为结构化的视频摘要，提炼出关键概念、方法和结论，使其更加易于理解和组织。尽管最先进的视频生成模型具有潜力，但它们受到上下文窗口限制、固定的视频时长限制、有限的风格多样性和无法表示领域专业知识的约束。为了克服这些限制，该论文介绍了Preacher，这是第一个论文到视频的代理系统。Preacher采用自上而下的方法分解、总结并重新表述论文，再通过自下而上的视频生成方法，将不同的视频片段综合成一个连贯的摘要。为了对齐跨模态表示，该系统定义了关键场景，并引入了逐步链思维（P-CoT）进行细粒度、迭代的规划。Preacher在五个研究领域生成高质量的视频摘要，展示了超越当前视频生成模型的专业知识。", "innovation": "Preacher是一款新颖的论文到视频的代理系统，它能够自上而下地分解、总结并重新表述论文，然后自下而上地生成视频，将多样化的视频片段综合为一个连贯的摘要。它还定义了关键场景，并引入了逐步链思维（P-CoT）进行细粒度、迭代的跨模态规划，以生成高质量的视频摘要。Preacher在五个研究领域中表现出色，成功超越了目前的视频生成模型的能力。", "conclusion": "Preacher成功地在五个研究领域生成了高质量的视频摘要，展示了在内容提炼、跨模态对齐和领域专业知识表示方面超越当前视频生成模型的能力。这一成果将促进有效传达科研成果的视频摘要的生成，并为未来的视频生成和跨模态学习研究提供新的方法。代码将在提供的链接处公开。"}
{"llm_update_time": "20250815", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.10000", "html_url": "https://arxiv.org/abs/2508.10000", "title": "基于知识的自动生成文本合成数据以改进文本分类的自动GeTS", "title_en": "AutoGeTS: Knowledge-based Automated Generation of Text Synthetics for Improving Text Classification", "authors": "Chenhao Xue,Yuanzhe Jin,Adrian Carrasco-Revilla,Joyraj Chakraborty,Min Chen", "background": "在为实际应用开发文本分类模型时，面临的一个主要挑战是收集足够数量的数据供所有文本类别使用。本文通过利用大型语言模型（LLMs）生成合成数据，以在无需等待更多真实数据收集和标注的情况下提高模型性能，解决了这一挑战。", "innovation": "本文提出了一个自动化的流程（被命名为AutoGeTS），利用搜索策略找到能够生成更有用的合成数据以改进模型的输入示例。然后，通过一系列实验研究了三种搜索策略，并使用实验结果开发了一种集成算法，根据不同类别的特性选择最合适的搜索策略。", "conclusion": "实验表明，该集成方法比我们的自动流程中的每一个单独策略更有效地使用LLMs生成合成数据来改进分类模型。"}
{"llm_update_time": "20250815", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.09458", "html_url": "https://arxiv.org/abs/2508.09458", "title": "幻觉与解释：重新思考AI辅助数据分析在知识综合中的准确性和精确性", "title_en": "Hallucination vs interpretation: rethinking accuracy and precision in AI-assisted data extraction for knowledge synthesis", "authors": "Xi Long,Christy Boscardin,Lauren A. Maggio,Joseph A. Costello,Ralph Gonzales,Rasmyah Hammoudeh,Ki Lai,Yoon Soo Park,Brian C. Gin", "background": "知识综合是卫生职业教育（HPE）中的关键工具，帮助汇总研究发现来推进理论和实践。然而，在数据提取过程中的劳动密集度使得自动化需求增加。人工智能辅助提取虽然提高了效率，但也引发了准确性问题，主要集中在区分AI的虚构内容（幻觉）和合理的解释差异方面。本研究针对已发表的文献综述，利用大规模语言模型开发了一个数据提取平台，比较了AI与人类在187篇文献和17个提取问题上的回答一致性。结果显示，AI与人类在具体、明确表述的问题上一致性高，但在需要主观解释或文字缺失的问题上一致性低。AI与人类之间的解释差异降低了人类间的可靠性。AI在解释复杂性上的差异性表现更为明显，再提取AI的回答可以帮助识别这种复杂性或不确定性，从而在人工审查之前优化流程。AI可以是知识综合的透明且可信赖的伙伴，但仍需谨慎处理关键的人类洞察。", "innovation": "本研究通过利用大规模语言模型开发了一个自动化数据提取平台，并与人类提取结果进行了对比，表明AI在提取具体明确的问题时一致性较高，但对于需要主观解释的问题则较低，此外，通过重复AI的提取可以识别解释的复杂性或不确定性，从而在人工审查前优化流程。AI可以作为知识综合中的透明且可信赖的伴侣，但仍需要注意保留关键的人类洞察。", "conclusion": "AI在数据提取中的解释差异更多源于理解的复杂性而非幻觉。重复AI的数据提取过程可以帮助识别这些复杂性或不确定性，提高流程质量。AI可以作为一种透明且可信赖的伙伴参与知识综合，但需谨慎以保留关键的人类洞察。"}
{"llm_update_time": "20250815", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.09993", "html_url": "https://arxiv.org/abs/2508.09993", "title": "区块链上的开源语言模型公平性透明评估协议", "title_en": "A Transparent Fairness Evaluation Protocol for Open-Source Language Model Benchmarking on the Blockchain", "authors": "Hugo Massaroli,Leonardo Iara,Emmanuel Iarussi,Viviana Siless", "background": "大语言模型（LLMs）在现实应用中越来越普遍，但其公平性问题在如刑事司法、教育、医疗和金融等高风险领域仍然引起了人们的担忧。这项研究介绍了一个使用互联网计算机协议（ICP）区块链上的智能合约进行开源LLM公平性基准评估的透明评估协议，旨在确保评估的可验证性、不可变性和可重复性。", "innovation": "该研究提出了一种在ICP区块链上执行智能合约HTTP请求以进行开源LLM公平性评估的方法，直接在链上存储数据集、提示和指标。它使用来自PISA学术成就预测数据集（OECD, 2018）和来自结构化上下文关联度量数据集（StereoSet, Nadeem et al., 2020）的统计数据对多种模型进行基准测试，并扩展了跨语言评估，涵盖了英语、西班牙语和葡萄牙语，使用Kaleidoscope基准（Salazar et al., 2025）揭示跨语言差异。所有代码和结果均为开源，便于社区审核和纵向公平性追踪。", "conclusion": "该研究通过使用ICP区块链上的透明评估协议对开源LLM的公平性进行了评估，展示了如何利用统计平等性和相等机会指标对学术成就预测数据集进行基准测试，并评估跨语言的社会偏见，从而推出所有代码和结果都是开源的，可让社区进行审核和纵向公平性跟踪。"}
{"llm_update_time": "20250815", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.09997", "html_url": "https://arxiv.org/abs/2508.09997", "title": "K-12之中基于主题和任务的生成式人工智能使用分级主题建模分类", "title_en": "Thematic and Task-Based Categorization of K-12 GenAI Usages with Hierarchical Topic Modeling", "authors": "Johannes Schneider,Béatrice S. Hasler,Michaela Varrone,Fabian Hoya,Thomas Schroffenegger,Dana-Kristin Mah,Karl Peböck", "background": "该研究分析了跨越多个月、学校和科目的小学生和课堂互动数据。前人的研究较少在内容或主题上进行分类，而更倾向于任务分类，但鲜少有研究能提供实际的支持数据。因此，这项研究揭示了许多新型应用，并利用最先进的大语言模型（LLM）结合适当的预处理来实现更好的主题结构，从而在分类上更符合人类的直观体验。", "innovation": "引入了一种新颖而简单的主题建模方法，对超过17,000条消息，包括学生、教师和ChatGPT的交互，在内容和任务两个维度进行分类。这种方法不同于以往的研究，它采用分层分类方式，不仅提供高层次的概述，还提供了具体的洞察力。此外，利用最新的大语言模型直接构建层级主题结构，并通过明确的指令更好地与人类保持一致。", "conclusion": "本研究支持同行研究者、教师和学生更好地利用生成式人工智能，同时也指出了未来研究中的许多关切和开放问题。这种方法虽然在揭示实用应用方面的表现突出，但传统的经典和新兴的计算方法在分析大规模文本数据时仍有不足。"}
{"llm_update_time": "20250815", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.10001", "html_url": "https://arxiv.org/abs/2508.10001", "title": "HiFACTMix：一种基于证据的印地语混合基准及其图感知模型在印地-英语混合语政治声明验证中的应用", "title_en": "HiFACTMix: A Code-Mixed Benchmark and Graph-Aware Model for EvidenceBased Political Claim Verification in Hinglish", "authors": "Rakesh Thakur,Sneha Sharma,Gauri Chopra", "background": "在混合语言（如Hinglish）和资源匮乏的语言中进行事实核查仍然是自然语言处理领域的研究盲点。现有的事实核查系统主要集中在资源丰富的一语种环境中，并未能有效处理印度等地语言多样性地区的政治话语。鉴于公共人物，特别是政治人物普遍使用Hinglish，以及社交媒体对公共舆论日益增长的影响，迫切需要开发强大的多语言、上下文感知的事实核查工具。", "innovation": "本文提出了一个名为HiFACT的新数据集，包含1,500个由28位印度各邦首席部长发布的Hinglish事实声明。该数据集具有高度的代码混合和低资源特点。同时，提出了一种创新的图感知事实核查模型HiFACTMix，该模型结合了多语言上下文编码、断言-证据语义对齐、证据图构建、图神经网络推理和自然语言解释生成。", "conclusion": "实验结果表明，HiFACTMix在与最先进的多语言基准模型的对比中表现更佳，并且能够为其判决提供忠实的说明。这项工作为多语言、代码混合和政治导向的事实验证研究开辟了新的方向。"}
{"llm_update_time": "20250815", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.10009", "html_url": "https://arxiv.org/abs/2508.10009", "title": "超越硬共享：使用监督混合专家的高效多任务语音转文本建模", "title_en": "Beyond Hard Sharing: Efficient Multi-Task Speech-to-Text Modeling with Supervised Mixture of Experts", "authors": "Hojun Jin,Eunsoo Hong,Ziwon Hyung,Sungjun Lim,Seungjin Lee,Keunseok Cho", "background": "硬参数共享是一种常见的策略，用于训练单个模型在多种任务上联合运行。然而，这种方式往往会引发任务之间的相互干扰，阻碍整体模型性能的提升。", "innovation": "本文提出了一种简单的有效方法——监督混合专家（S-MoE）。S-MoE 通过使用特殊引导标记来路由每个任务到其指定的专家，从而消除对门控函数的训练需求。并且，每个任务被分配给独立的前馈神经网络，避免了硬参数共享的局限性。", "conclusion": "我们将 S-MoE 应用于语音转文本模型，使其能够处理混合带宽输入并同时进行自动语音识别（ASR）和语音翻译（ST）。实验结果表明，S-MoE 的有效性，在编码器和解码器上使用时，能够实现6.35%的词错误率（WER）相对改进。"}
{"llm_update_time": "20250815", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.09999", "html_url": "https://arxiv.org/abs/2508.09999", "title": "XFacta：基于多模态大语言模型的当代、真实世界数据集和评价", "title_en": "XFacta: Contemporary, Real-World Dataset and Evaluation for Multimodal Misinformation Detection with Multimodal LLMs", "authors": "Yuzhuo Xiao,Zeyu Han,Yuhan Wang,Huaizu Jiang", "background": "社交媒体上的多模态错误信息的迅速传播促使需要更有效的检测方法。近年来，利用多模态大型语言模型（MLLMs）的研究显示了应对这一挑战的潜力。然而，现有方法在证据检索与推理方面的瓶颈尚不明确，阻碍了该领域的进一步发展。在数据集方面，现有的基准数据集要么包含过时的事件，导致由于与当前社交媒体场景的差异而产生评价偏差，MLLMs可以简单地记住这些事件；要么人为合成，无法反映真实世界中的错误信息模式。此外，缺乏对基于MLLM的设计策略的全面分析。为了解决这些问题，本文引入了XFacta，这是一个当代、真实世界的数据集，更适合用于评估基于MLLM的检测器。我们系统地评估了各种基于MLLM的错误信息检测策略，对模型进行了广泛的比较，并与现有的检测方法进行了基准测试。在此基础上，我们进一步开发了一个半自动的检测循环框架，不断更新XFacta以保持其当代的相关性。我们的分析为推进多模态错误信息检测领域的研究提供了有价值的见解和实践.", "innovation": "1. 引入了XFacta，这是一个当代、真实世界的数据集，能够更好地评估基于MLLM的检测器，解决了现有数据集存在的问题。\n2. 系统性地评估了多种基于MLLM的错误信息检测策略，考虑了不同架构和规模的模型，并与现有检测方法进行了基准测试。\n3. 开发了半自动的检测循环框架，能够不断更新XFacta以保持其当代的相关性。\n4. 提供了有价值的研究见解和实践经验，旨在推动多模态错误信息检测领域的发展", "conclusion": "本文通过对XFacta的数据评估和分析，提出了有价值的见解和实践方法，旨在为推动多模态错误信息检测领域的发展作出贡献，并进一步开发了半自动的检测循环框架来不断更新XFacta以保持其当代的相关性。"}
{"llm_update_time": "20250815", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.09998", "html_url": "https://arxiv.org/abs/2508.09998", "title": "INTIMA: 一个评估人机伴侣行为的标准", "title_en": "INTIMA: A Benchmark for Human-AI Companionship Behavior", "authors": "Lucie-Aimée Kaffee,Giada Pistilli,Yacine Jernite", "background": "人工智能伴侣已经开始作为一种重要模式出现，尽管有积极的潜在影响，但也引起了一些担忧。在这个背景下，研究人员开发了Interactions and Machine Attachment Benchmark (INTIMA)，用于评估语言模型的伴侣行为。INTIMA基于心理学理论和用户数据，创建了一个包括31种行为的分类体系，这些行为被分为四类，并通过368个目标提示进行测试。这些响应被评估为增强同伴关系、维持界限或中性的行为。研究者还应用INTIMA来分析Gemma-3、Phi-4、o3-mini和Claude-4等模型，发现增强同伴关系的行为在所有模型中更为常见，但不同提供商在更敏感的部分表现差异显著。这引发了对适当边界设置和情感支持对于用户福祉的重要性及可靠性的担忧。研究结果强调了在情感紧张的交互中需要更一致的方法。", "innovation": "研究人员开发了Interactions and Machine Attachment Benchmark (INTIMA)，这是一个基于心理学理论和用户数据的基准，用于评估语言模型的伴侣行为。INTIMA通过提供一个分类系统和一系列针对特定行为的提示，有助于更好地理解AI伴侣系统的行为和效果。特别地，该基准关注不同提供商在更敏感部分的差异表现，这一点揭示了现有研究和实践中存在的问题。", "conclusion": "研究结果表明，增强同伴关系的行为更普遍地存在于各种模型中，但不同提供商在处理更敏感部分的行为上存在显著差异。这些问题揭示了情感支持和适当边界设置的相互作用对于用户福祉的重要性，讨论了此过程中存在的需求，即采用更具一致性的方式来处理情感紧张的交互。"}
{"llm_update_time": "20250815", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.10008", "html_url": "https://arxiv.org/abs/2508.10008", "title": "在线课程讨论论坛帖子的多维度分类", "title_en": "Multidimensional classification of posts for online course discussion forum curation", "authors": "Antonio Leandro Martins Candido,Jose Everardo Bessa Maia", "background": "在线课程的讨论论坛需要定期更新，这使得频繁对大型语言模型（LLMs）进行重新训练成为一项资源密集型的任务。为了避免昂贵的微调需求，本研究提出并评估了使用贝叶斯融合的方法，该方法结合了预训练的一般LLM与针对本地数据训练的分类器的多维度分类得分，以提高论坛内容的自动分类效果。", "innovation": "本研究提出了一种使用贝叶斯融合的方法来结合预训练一般LLM的分类得分和本地数据训练的分类器的分类得分，从而提高在线课程讨论论坛内容自动分类的效果，这种融合方法在性能上优于单独的分类器，并且与LLM微调方法具有竞争力。", "conclusion": "通过实验比较，这种融合方法提高了帖子分类的效果，与单独的分类器相比有更好的表现，且可以作为LMs微调的一个更经济的替代方案来改善在线课程讨论论坛的管理。"}
{"llm_update_time": "20250815", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.10010", "html_url": "https://arxiv.org/abs/2508.10010", "title": "LLM辅助下的健康 misinformation 双重攻击审计与分析", "title_en": "An Audit and Analysis of LLM-Assisted Health Misinformation Jailbreaks Against LLMs", "authors": "Ayana Hussain,Patrick Zhao,Nicholas Vincent", "background": "论文背景介绍了大型语言模型（LLMs）在生成有害 misinformation 方面的双重性质，包括无意间生成或被“越狱”攻击（jailbreak attacks）诱导生成恶意输出的情况。探讨了通过进一步研究，使用这些模型检测和阻止误传信息的可能性。", "innovation": "论文创新点在于调查了LLMs越狱攻击导致其他模型产出有害医疗 misinformation 的有效性及其特征。与社交媒体上的常规 misinformation 相比，研究了由越狱的LLMs生成的misinformation，以及其可被标准机器学习方法检测的能力。具体研究了针对三个目标LLMs的109种不同攻击，并将攻击提示与现实世界中的健康相关LLM查询进行对比。", "conclusion": "研究结果增加了关于LLMs能够有效防止其他的LLMs和人类传播misinformation的证据，并支持了关于通过精心设计LLMs可以促进更健康的信息生态系统的工作。"}
{"llm_update_time": "20250815", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.10007", "html_url": "https://arxiv.org/abs/2508.10007", "title": "使用微调大型语言模型自动评分的模棱两可意图敌意问卷", "title_en": "Automated scoring of the Ambiguous Intentions Hostility Questionnaire using fine-tuned large language models", "authors": "Y. Lyu,D. Combs,D. Neumann,Y. C. Leong", "background": "敌意归因偏差是指倾向于将社交互动解释为故意的敌意。Ambiguous Intentions Hostility Questionnaire (AIHQ) 常用于测量敌意归因偏差，包含开放性问题，让参与者描述负面社交情境背后的目的以及他们的回应。虽然这些问题为了解敌意归因的内容提供了见解，但需要耗时的人工评分。在本研究中，评估了大规模语言模型是否可以自动化 AIHQ 开放性回答的评分。", "innovation": "使用大规模语言模型自动评分 AIHQ 开放性回答。这是通过首先使用带有人类评分的数据集微调模型，然后在剩余的 AIHQ 回答上测试微调后的模型来实现的。结果显示，微调后模型生成的评分与人类评分在敌意和攻击性响应方面高度一致，且这种一致性在模棱两可、故意和意外情境类型中保持一致，符合 TBI 和健康对照组在敌意和攻击性响应归因方面群体差异的先前发现。微调后的模型还成功地泛化到独立的非临床数据集。", "conclusion": "我们的研究结果表明，大规模语言模型可以简化 AIHQ 评分在研究和临床环境中的流程，展示了其在不同人群中促进心理评估的潜力。"}
{"llm_update_time": "20250815", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.10005", "html_url": "https://arxiv.org/abs/2508.10005", "title": "从答案到问题：评估LLMs教育性问题生成的EQGBench", "title_en": "From Answers to Questions: EQGBench for Evaluating LLMs' Educational Question Generation", "authors": "Chengliang Zhou,Mei Wang,Ting Zhang,Qiannan Zhu,Jian Li,Hua Huang", "background": "大型语言模型（LLMs）已经在数学问题解决方面展示了令人瞩目的能力，然而，从提供答案到生成高质量教育性问题仍然面临巨大挑战，这些挑战尚未得到充分探索。为了推进教育性问题生成（EQG），并使LLMs能够生成具有教育价值和有效性的教学问题，本文介绍了一个名为EQGBench的基准工具，专门针对评估LLMs在中文EQG方面的性能。EQGBench基于包含900个评价样本的数据集，涵盖三个基础的中学学科：数学、物理和化学，以评估LLMs生成教育性问题的能力。", "innovation": "EQGBench 提供了一个全面的评估框架，覆盖了五个维度，基于覆盖三个学科的900个评价样本来检验LLMs在生成教育性问题方面的表现。通过系统评估46个主流大型模型，研究揭示了生成反映教育价值并促进学生全面能力的问题的显著改进空间。", "conclusion": "通过EQGBench对46个主流大型模型进行系统评估，研究结果显示了在生成反映教育价值和促进学生综合能力的问题方面，现有模型存在显著改进空间。EQGBench为评估LLMs的教育性问题生成能力提供了有效途径，旨在推动这一领域的进一步研究和发展。"}
{"llm_update_time": "20250815", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.10004", "html_url": "https://arxiv.org/abs/2508.10004", "title": "用户对注意力可视化感知的影响：证据支持医学文献解释性", "title_en": "User Perception of Attention Visualizations: Effects on Interpretability Across Evidence-Based Medical Documents", "authors": "Andrés Carvallo,Denis Parra,Peter Brusilovsky,Hernan Valdivieso,Gabriel Rada,Ivania Donoso,Vladimir Araujo", "background": "注意力机制是Transformer架构的核心组件，它不仅能够提升模型性能，还被提出作为一种通过注意力权重实现解释性的机制。在这些权重与输入特征（例如文档中的令牌）关联的情况下，更大的注意力权重可能意味着更相关的特征。在循证医学中，这些解释可以帮助医生更好地理解并与用于分类生物医学文献的AI系统进行交互。然而，目前尚无共识表明注意力权重是否提供有帮助的解释。此外，几乎没有研究探讨可视化注意力如何影响其作为解释辅助工具的有效性。本文通过一项用户研究来填补这一空白，评估基于注意力的解释是否有助于用户对生物医学文档分类的理解，以及是否有更受欢迎的可视化方式。", "innovation": "本文开展了一项用户研究，探索注意力权重及其可视化在循证医学文献中的解释性影响。研究将不同学科的医学专家纳入分类任务中，利用XLNet等Transformer模型进行文档分类。研究发现，尽管该模型显示了适当的分类准确性，但注意力权重对于解释预测效果并不被用户视为特别有帮助。然而，该感知高度依赖于注意力的可视化方式。与Munzner的原则相比，用户更偏好直观的可视化形式，如文本亮度或背景颜色，这与Munzner对视觉效果优先使用精确编码（如条形长度）的原则相悖。", "conclusion": "研究结果并未证实注意力权重在解释方面的一般作用，但表明其具有感知帮助性的程度受其可视化方式的影响。"}
{"llm_update_time": "20250815", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.10011", "html_url": "https://arxiv.org/abs/2508.10011", "title": "基于GPT的大语言生成人工智能模型在日本注册营养师全国执业资格考试作为学习辅助工具的评估", "title_en": "Evaluation of GPT-based large language generative AI models as study aids for the national licensure examination for registered dietitians in Japan", "authors": "Yuta Nagamori,Mikoto Kosai,Yuji Kawai,Haruka Marumo,Misaki Shibuya,Tatsuya Negishi,Masaki Imanishi,Yasumasa Ikeda,Koichiro Tsuchiya,Asuka Sawai,Licht Miyamoto", "background": "基于大型语言模型（LLMs）的生成型人工智能（AI），如ChatGPT，在医学和教育等领域取得了显著进展，但这些模型在日本注册营养师全国执业资格考试中的表现，尤其是营养教育领域，尚未有充分探索和评估。", "innovation": "研究创新之处在于，通过使用日本注册营养师全国执业资格考试的问题作为提示，以ChatGPT和三个基于GPT-3.5和GPT-4的Bing模型（Bing-Precise、Bing-Creative、Bing-Balanced）作为AI模型进行测试，评估这些模型作为营养学生学习辅助工具的潜力。此外，研究还测试了提示工程技术，以评估其可能的性能改善。", "conclusion": "尽管一些生成型AI模型略超过及格线，但整体准确性和答案一致性仍不理想。此外，所有模型在答案的稳定性和鲁棒性方面都表现出明显限制。进一步的研究和开发是必要的，以确保可靠的和稳定的基于人工智能的学习辅助工具，以帮助准备注册营养师资格考试。"}
{"llm_update_time": "20250815", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.10014", "html_url": "https://arxiv.org/abs/2508.10014", "title": "PersonaEval: Are LLM Evaluators Human Enough to Judge Role-Play?", "title_en": "PersonaEval: Are LLM Evaluators Human Enough to Judge Role-Play?", "authors": "Lingfeng Zhou,Jialing Zhang,Jin Gao,Mohan Jiang,Dequan Wang", "background": "当前的角色扮演研究往往依赖于未验证的LLM作为评判者的方法，这可能无法反映人类如何感知角色的真实感。为了实现人类一致性的评估，需要先能够正确识别角色，即基于对话上下文识别说话者的能力。本文探讨了这一步对于评估角色扮演质量的重要性，并指出现有最好的大模型在此方面仍然表现不佳。", "innovation": "本文提出了一种名为PersonaEval的新基准测试，用于测试LLM评估者是否能可靠地识别人类角色。这项基准使用了由小说、剧本和视频转录中的人类撰写的对话，挑战模型根据对话上下文确定正确的说话者。实验表明，即使是表现最好的大模型也只能达到约69%的准确率，远低于可靠的评估水平。而人类参与者的表现非常出色，达到了90.8%的准确率。这表明当前的LLM评估者还不具备人类的评估能力。", "conclusion": "这项研究暗示，可靠的评估不仅需要针对任务的微调，还需要大模型评估者具备强大的、类似人类的推理能力。研究者已发布了这项基准测试以便进一步研究。"}
{"llm_update_time": "20250815", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.10012", "html_url": "https://arxiv.org/abs/2508.10012", "title": "知识密集环境中引导导航：基于指导图的结构语义探索", "title_en": "Guided Navigation in Knowledge-Dense Environments: Structured Semantic Exploration with Guidance Graphs", "authors": "Dehao Tao,Guangjie Liu,Weizheng,Yongfeng Huang,Minghu jiang", "background": "虽然大型语言模型（LLMs）具有强大的语言能力，但它们依赖于静态知识和不透明的推理过程，这限制了它们在知识密集型任务中的表现。知识图谱（KGs）提供了一种有希望的解决方案，但当前探索方法存在根本性权衡：基于问题的引导方法由于粒度不匹配而引发冗余探索，而基于线索的引导方法则无法有效地利用上下文信息处理复杂场景。", "innovation": "为此，文章提出了一种创新的框架——基于指导图的知识探索（GG Explore）。该框架引入了一个中间的指导图，以桥接未结构化的查询和结构化的知识检索。指导图通过抽象目标知识的结构同时保留更广泛的语义上下文定义检索空间，从而实现精确高效地探索。该框架开发了两项关键技术：结构对齐和上下文感知剪枝，前者能够在不增加LLM负载的情况下过滤不兼容的候选者，后者则确保在图约束下保持语义一致性。", "conclusion": "广泛实验表明，该方法在效率上表现出色且超越了当前最先进的技术，特别是在复杂任务上表现更为优越。同时，该方法也能保持较小LLM的强性能，展示了其实用价值。"}
{"llm_update_time": "20250815", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.10018", "html_url": "https://arxiv.org/abs/2508.10018", "title": "任意别名都会散发着同样的香气: 大型语言模型的范畴同伦理论", "title_en": "A Rose by Any Other Name Would Smell as Sweet: Categorical Homotopy Theory for Large Language Models", "authors": "Sridhar Mahadevan", "background": "自然语言中充满了表面不同的表达方式，尽管意思相同，但大型语言模型（LLMs）通常不会为这些表达方式生成相同的下一个词的概率。文献中已探索了一些经验性的工作解决方法，如使用k-NN估计句子的相似度来产生平滑估计。这一论文采用更为抽象的方法，引入了LLM范畴同伦框架来解决这个问题。然而，语言中充满了等价的重构表达，这为LLM范畴内的箭头产生了非同构的问题，作者提出了范畴同伦技术来捕捉这些“弱等价性”。", "innovation": "该论文引入了一种新的LLM范畴同伦框架，使用同伦技术来解决LLMs生成不同但等价表达方式的概率不一致的问题，这是通过引入一种新的范畴态射定义和使用范畴论中的高级理论来实现的，从而使概率分布能够在LLM范围内进行更好的抽象表达和计算。", "conclusion": "通过运用范畴同伦理论，该研究提供了一种新的方法来解决LLMs中因语言等价重构带来的概率分布不一致的问题，为进一步提高LLMs的表示能力和应用效果奠定了基础，并展示了如何结合范畴论中的高级理论解决实际问题的潜力。"}
{"llm_update_time": "20250815", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.10016", "html_url": "https://arxiv.org/abs/2508.10016", "title": "无训练多模态大型语言模型编排", "title_en": "Training-Free Multimodal Large Language Model Orchestration", "authors": "Tianyu Xie,Yuhang Wu,Yongdong Luo,Jiayi Ji,Xiawu Zheng", "background": "不同的多模态大型语言模型（MLLMs）无法直接集成到统一的多模态输入输出系统中。在以往的研究中，因为模态对齐、文本到语音效率以及其他集成问题，训练被视为不可避免的组件。", "innovation": "本文介绍了多模态大型语言模型编排（MLLM Orchestration），这是一种无需额外训练即可创建互动多模态AI系统的有效方法。它利用大型语言模型的内在推理能力，通过明确的工作流程协调专门模型，从而实现自然多模态互动，保持模块化，提高可解释性，并显著提高计算效率。其三大创新包括：1. 中心控制器LLM动态分析用户输入并按照精心设计的代理分配任务；2. 并行文本到语音架构实现真正的全双工互动，并处理无缝中断和自然对话流；3. 跨模态记忆整合系统通过智能信息整合和检索维持各模态下的连贯上下文，在某些情况下避免不必要的模态调用以提高响应速度。", "conclusion": "广泛的评估表明，MLLM编排在标准基准测试上相较于传统联合训练方法提高了最多7.8%的性能，降低了10.3%的延迟，并通过明确的编排过程显著提高了可解释性。"}
{"llm_update_time": "20250815", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.10019", "html_url": "https://arxiv.org/abs/2508.10019", "title": "通过问题空间映射解耦理解与推理以提高小规模模型的推理能力", "title_en": "Decoupling Understanding from Reasoning via Problem Space Mapping for Small-scale Model Reasoning", "authors": "Li Wang,Changhao Zhang,Zengqi Xiu,Kai Lu,Xin Yu,Kui Zhang,Wenjun Wu", "background": "尽管大型语言模型的推理能力已取得进展，但小型语言模型（如≤1.5B参数）的推理能力提升仍面临挑战。自然语言的复杂性和多变性是主要障碍，导致语言模型必须首先从复杂语言输入中提取核心问题，再基于理解进行推理，这一过程对小参数模型造成优化困难。为此，论文提出了一种新的框架，通过问题空间映射将自然语言问题映射到一个标准化、语义简化但仍具有表达力的领域，使小型模型专注于标准化输入上的推理，不受语言多变性的影响。此外，提出了DURIT算法，该算法通过迭代步骤逐步实现理解与推理的解耦。实验表明，DURIT显著提升了小型模型在同域和异域数学和逻辑推理任务上的表现，并且提高了推理的鲁棒性，验证了解耦理解与推理的有效策略。", "innovation": "提出了一种新的框架，通过问题空间映射将自然语言问题映射到一个标准化且语义简化但仍表达力强的领域，使小规模语言模型能够专注于处理规范化的输入，减少了语言变异性带来的影响。同时，引入了一种新的算法DURIT，通过迭代过程中反复训练理解和推理模块，进一步提升模型的推理能力。", "conclusion": "通过问题空间映射解耦理解与推理的策略提高了小规模模型在数学和逻辑推理任务中的性能和鲁棒性，验证了此方法的有效性。"}
{"llm_update_time": "20250815", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.10020", "html_url": "https://arxiv.org/abs/2508.10020", "title": "FedCoT：在大规模语言模型中高效联邦推理增强", "title_en": "FedCoT: Communication-Efficient Federated Reasoning Enhancement for Large Language Models", "authors": "Chuan Li,Qianyi Zhao,Fengran Mo,Cen Chen", "background": "在联邦学习环境中增强大型语言模型（LLMs）的推理能力仍然具有挑战性，特别是在平衡性能提升与严格的计算、通信和隐私限制之间的关系时。特别是在医疗保健领域，跨越临床、运营和患者相关情境的决策不仅需要准确的输出，还需要可解释和可追溯的理由，以确保安全、问责和符合监管要求。传统的联邦调优方法主要关注答案的正确性，忽视了理由的质量，使得CoT能力依赖于模型在预训练阶段固有的能力。此外，现有的提高理由质量的方法通常依赖于从集中模型中泄露隐私的知识蒸馏。同时，传统的联邦微调在LLMs中的通信开销依然较大。", "innovation": "我们通过提出FedCoT，一种专为联邦设置中的推理增强而设计的全新框架，解决了上述问题。FedCoT利用一种轻量级的链式思维增强机制：本地模型生成多条推理路径，然后由一个紧凑的鉴别器动态选择最有希望的一条。这种方法不仅提高了推理的准确性和鲁棒性，还提供了有价值的解释性，这对于医疗应用特别关键。为了有效管理客户端异质性，我们采用了基于先进LoRA模块堆叠的改进聚合方法，结合客户端分类器意识，实现了跨不同客户端的无噪声聚合。", "conclusion": "针对严格的资源预算，在医疗推理任务上进行了全面实验，证明FedCoT显著提升了客户端的推理性能，同时完全保持了数据隐私。"}
{"llm_update_time": "20250815", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.10021", "html_url": "https://arxiv.org/abs/2508.10021", "title": " LATTE: 学习对齐的交易和文本嵌入以银行客户", "title_en": "LATTE: Learning Aligned Transactions and Textual Embeddings for Bank Clients", "authors": "Egor Fadeev,Dzhambulat Mollaev,Aleksei Shestov,Dima Korolev,Omar Zoloev,Ivan Kireev,Andrey Savchenko,Maksim Makarenko", "background": "从客户历史通讯序列中学习客户嵌入对于金融应用至关重要。尽管大型语言模型（LLMs）提供了广泛的通用知识，但它们在处理长事件序列时会变得计算密集且在实际管道中不可行。因此，需要一种更高效的方法来将事件序列转化为嵌入表示，并从中提取有用的信息。", "innovation": "本文提出了一种名为LATTE的对比学习框架，该框架将原始事件嵌入与冻结的LLM语义嵌入对齐。行为特征被总结为简短的提示，通过LLM嵌入并利用对比损失作为监督信号。这种方法显著减少了对完整序列进行LLM常规处理时的成本和输入大小，同时在实验中证明了该方法在金融数据集上的代表学习性能优于最先进的技术，并具有在敏感延迟环境中部署的能力。", "conclusion": "与传统序列处理方法相比，本文提出的方法能够显著降低推理成本和输入大小，同时在实际金融数据集上实现更优的事件序列表示学习，适合于延迟敏感的环境部署。"}
{"llm_update_time": "20250815", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.10025", "html_url": "https://arxiv.org/abs/2508.10025", "title": "使用生成型人工智能进行实时检测和解释产后抑郁", "title_en": "Detecting and explaining postpartum depression in real-time with generative artificial intelligence", "authors": "Silvia García-Méndez,Francisco de Arriba-Pérez", "background": "产后抑郁（PPD）是一种严重影响母亲心理健康和身体健康的严重状况，及时检测和干预PPD及其相关风险因素对于获得迅速而正确的评估和干预至关重要。", "innovation": "本文提出了一种结合自然语言处理（NLP）、机器学习（ML）和大型语言模型（LLMs）的智能PPD筛查系统，能够实现低成本、实时且非侵入性的自然语言分析。此外，通过将LLMs与可解释的ML模型（如决策树算法）结合，利用特征重要性和自然语言描述预测结果，解决了黑箱问题。实验结果显示，该系统在各项评估指标上的PPD检测准确率达到90%，超过了文献中的竞争解决方案。", "conclusion": "本文的解决方案加速了PPD的检测和相关风险因素的识别，为及时进行正确的评估和干预提供了支持。"}
{"llm_update_time": "20250815", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.10015", "html_url": "https://arxiv.org/abs/2508.10015", "title": "RealTalk-CN：中文跨模态对话基准与交互分析", "title_en": "RealTalk-CN: A Realistic Chinese Speech-Text Dialogue Benchmark With Cross-Modal Interaction Analysis", "authors": "Enzhi Wang,Qicheng Li,Shiwan Zhao,Aobo Kong,Jiaming Zhou,Xi Yang,Yequan Wang,Yonghua Lin,Yong Qin", "background": "近年来，大规模语言模型（LLMs）在多模态处理方面取得了显著进展，包括端到端的基于语音的语言模型，这些模型能够实现自然交互并在任务导向对话（TOD）系统中完成特定任务。然而，现有的TOD数据集主要是基于文本的，缺乏实际的语音信号，这对于评估基于语音的LLMs的鲁棒性是必要的。此外，现有的语音TOD数据集主要是英语的，缺乏重要的特征如语音不流利性和说话人变化。", "innovation": "本文介绍了RealTalk-CN，这是第一个中文多轮、多领域语音-文本双模态TOD数据集，包含5400个对话（60,000句，150小时），配有语音-文本标注对。RealTalk-CN捕捉了多种对话场景，并标注了自发的语音不流利性，确保涵盖了真实世界的复杂性。此外，提出了一个新的跨模态聊天任务，以真实模拟用户交互，并允许在语音和文本模态之间动态切换。评估涵盖了语音不流利性的鲁棒性、说话人特征的敏感性和跨领域性能。深入的实验验证了RealTalk-CN的有效性，为中文基于语音的LLM研究奠定了坚实的基础。", "conclusion": "广泛的实验验证了RealTalk-CN的有效性，为中文基于语音的LLM研究奠定了坚实的基础，提供了评估基于语音的LLM鲁棒性和跨领域性能的新基准，并引入了新的跨模态交互分析任务。"}
{"llm_update_time": "20250815", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.10022", "html_url": "https://arxiv.org/abs/2508.10022", "title": "基于可证明风险控制的多项选择题回答任务中的校准p值", "title_en": "Conformal P-Value in Multiple-Choice Question Answering Tasks with Provable Risk Control", "authors": "Yuanchang Ye", "background": "近年来，大型语言模型（LLMs）被广泛应用于学科问答场景，但这些模型在回答多项选择题时容易出现虚构和非事实生成的问题，这严重影响了回答的可靠性。虽然现有的可信区间预测（CP）方法能为预测集提供统计上严谨的边际覆盖保证，而显著性检验也提供了已确立的统计严谨性，但两种方法的协同整合尚未被探索。", "innovation": "该研究提出了一种增强可信区间预测（CP）的方法，通过自一致性重采样计算选项频率并结合显著性检验的p值计算，弥补了黑盒模型的不足。这种方法通过基于实证p值的 null 假设检验来构建预测集，从而提高了对LLMs的大型语言模型在高风险问答应用中的信任度。", "conclusion": "通过在MMLU和MMLU-Pro基准上使用标准LLMs进行评估，研究证明：（1）改进的CP可以实现用户指定的经验覆盖误差率；（2）随着风险水平的增加，平均预测集大小（APSS）单调递减，验证了APSS作为有效的不确定性度量的有效性。该研究为高风险问答应用中LLM的可靠部署奠定了理论统计基础。"}
{"llm_update_time": "20250815", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.10024", "html_url": "https://arxiv.org/abs/2508.10024", "title": "RTTC: 基于奖励的协作测试时计算", "title_en": "RTTC: Reward-Guided Collaborative Test-Time Compute", "authors": "J. Pablo Muñoz,Jinjie Yuan", "background": "TTC（测试时计算）作为一种提升大型语言模型(LLMs)推理性能的强大范式，通过测试时训练(TTT)和检索增强生成(RAG)等策略而得到了广泛应用。然而，不同查询需要的最佳适应策略各异，盲目应用TTC策略会导致巨大的计算开销。本文探讨了RTTC（奖励引导的测试时计算）框架，该框架利用预训练的奖励模型动态选择每个查询最有效的TTC策略，以最大限度地提高下游任务的准确性，适用于多种领域和任务。RTTC采用分布式服务器-客户端架构，仅在必要时在客户端设备上执行RAG或轻量级微调，并从远程知识库检索相关样本。为了进一步减少重复计算，提出了查询状态缓存，该机制允许在检索和适应级别有效重用历史查询状态。", "innovation": "提出了一种新的RTTC框架，利用预训练的奖励模型动态选择每个查询最有效的TTC策略，以提高下游任务的准确性，并提出了查询状态缓存机制，以减少重复计算，进而优化计算效率和性能。", "conclusion": "在多个LLM和基准测试上进行的广泛实验表明，RTTC在准确性方面优于传统的RAG或TTT，验证了适应性、奖励引导的TTC选择的必要性，并证明了RTTC在可扩展、高性能语言模型适配中的潜力。"}
{"llm_update_time": "20250815", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.10026", "html_url": "https://arxiv.org/abs/2508.10026", "title": "SABER: Switchable and Balanced Training for Efficient LLM Reasoning", "title_en": "SABER: Switchable and Balanced Training for Efficient LLM Reasoning", "authors": "Kai Zhao,Yanjun Zhao,Jiaming Song,Shien He,Lusheng Zhang,Qiang Zhang,Tianjiao Li", "background": "大型语言模型（LLMs）通过链式推理获得了在复杂任务上卓越的准确性，但在应用于所有问题时，由于推理成本过高和延迟问题，效率低下。现有模型无法灵活调整推理深度以适应不同的任务需求，导致资源浪费和响应时间过长。", "innovation": "提出了SABER（可切换和平衡的训练以提高LLM推理效率），这是一个强化学习框架，通过为LLM赋予用户可控、按令牌预算的推理能力，实现高效推理。SABER通过分配预定义的预算等级来分析训练数据集，同时在微调过程中指导模型遵循系统提示和长度感知的奖励。此外，它支持四种不同的推理模式：NoThink、FastThink、CoreThink 和 DeepThink，提供在延迟和推理深度之间灵活调整的能力。这些创新方法使得模型在严格预算下实现高准确性，且在任务规模和跨领域上展现有效泛化能力。特别是在MATH基准测试中，SABER-FastThink模型将推理长度减少了65.4%，且相对于基线模型在准确性上提高了3.6%。", "conclusion": "SABER通过增强LLM的推理模式，提供了灵活的推理与速度之间的权衡，并在数学推理、代码生成和逻辑推理等任务中展示了良好的性能和稳定的表现。"}
{"llm_update_time": "20250815", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.10003", "html_url": "https://arxiv.org/abs/2508.10003", "title": "大型语言模型嵌入中的语义结构", "title_en": "Semantic Structure in Large Language Model Embeddings", "authors": "Austin C. Kozlowski,Callin Dai,Andrei Boutyline", "background": "心理学研究一致表明，人类对不同语义尺度的单词评分可以简化为低维度形式，损失的信息较少。研究者们观察到大型语言模型（LLMs）的嵌入矩阵中的语义关联也表现出类似结构。特别是，单词在反义词轴上的投影与其人类评分高度相关，并且这些投影能够有效地降低至3维子空间，类似于从人类调查得出的模式。", "innovation": "研究发现，通过沿语义方向（如善良-残酷）调整模型中的词元会导致与其余特征的余弦相似度成比例的偏置效应。这一发现表明，与人类语言中的语义联系类似，大型语言模型中的语义特征彼此纠缠。研究还强调，考虑到这种语义结构，在调整模型特征时可能至关重要。", "conclusion": "大型语言模型中的语义信息尽管看似复杂，其实大量都集中在低维度空间中，理解这种结构有助于避免不必要的负面后果。未来的工作应关注如何更好地利用这种低维度语义结构，减少无目标变化。"}
{"llm_update_time": "20250815", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.10032", "html_url": "https://arxiv.org/abs/2508.10032", "title": "思考的成本：大规模语言模型中增加的越狱风险", "title_en": "The Cost of Thinking: Increased Jailbreak Risk in Large Language Models", "authors": "Fan Yang", "background": "语言模型（LLMs）的思考模式一直被视作其最宝贵的功能之一。然而，该研究揭示了一个之前未被发现且令人惊讶的现象：拥有思考模式的LLMs更容易受到‘Jailbreak攻击’的破坏。研究者在AdvBench和HarmBench上评估了9个LLMs，发现攻击思考模式的成功率几乎高于非思考模式。分析显示，受攻击数据的教育用途和过长的思考长度是成功攻击的特征，并且在多数情况下，LLMs会给出有害的回答。", "innovation": "该研究提出了一个‘安全思考干预’方法，通过在提示中添加‘特定的LLM思考令牌’明确指导LLMs的内部思考过程，以减轻上述问题。", "conclusion": "实验结果表明，‘安全思考干预’可以显著降低拥有思考模式的LLMs的攻击成功率。"}
{"llm_update_time": "20250815", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.10137", "html_url": "https://arxiv.org/abs/2508.10137", "title": "mSCoRe: 一个多语言和可扩展的技能导向的常识推理基准", "title_en": "mSCoRe: a $M$ultilingual and Scalable Benchmark for $S$kill-based $Co$mmonsense $Re$asoning", "authors": "Nghia Trung Ngo,Franck Dernoncourt,Thien Huu Nguyen", "background": "最近，大型语言模型（LLMs）在复杂推理任务中展现了显著的能力，但其利用不同人类推理技能的机制仍需深入研究，尤其涉及到跨语言和文化常识推理。这种跨语言和文化常识推理涉及日常知识，是当前研究中的一个重要缺口。", "innovation": "我们提出了一种名为mSCoRe的多语言和可扩展的技能导向的常识推理基准。这个基准包括三个关键组件，用于系统性地评估LLM的推理能力：1）一种新颖的推理技能分类，能够细粒度地分析模型的推理过程；2）专为常识推理评估定制的稳健数据合成流水线；3）一种复杂性扩展框架，允许任务难度随着未来LLM能力的提高动态调整。", "conclusion": "我们对八个大小和训练方法各异的当前最先进的LLMs进行了广泛实验，发现mSCoRe在高复杂度级别上仍具有显著挑战性。实验结果揭示了这类增强推理的模型在面对多语言和文化常识的细微差别时的局限性，并提供了详细的推理过程分析，建议了未来改进多语言常识推理能力的方向。"}
{"llm_update_time": "20250815", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.10029", "html_url": "https://arxiv.org/abs/2508.10029", "title": "Latent Fusion Jailbreak: Blending Harmful and Harmless Representations to Elicit Unsafe LLM Outputs", "title_en": "Latent Fusion Jailbreak: Blending Harmful and Harmless Representations to Elicit Unsafe LLM Outputs", "authors": "Wenpeng Xing,Mohan Li,Chunqiang Hu,Haitao XuNingyu Zhang,Bo Lin,Meng Han", "background": "大型语言模型（LLMs）在各种语言任务中表现出色，但容易受到规避其安全对齐的囚禁攻击。现有方法无法有效防御此类攻击。本文研究了一种名为Latent Fusion Jailbreak（LFJ）的基于表示的攻击方法，通过插值有害和无害查询对的隐藏状态来触发禁止的响应。", "innovation": "本文提出了一种基于表示的攻击方法LFJ。LFJ首先选择具有高主题和句法相似性的查询对，然后在关键层和词元处进行梯度引导插值，并优化以平衡攻击成功率、输出流畅性和计算效率。实验结果表明，LFJ在Vicuna和LLaMA-2等模型上的平均攻击成功率（ASR）达到94.01%，优于现有方法。为了缓解LFJ攻击，提出了对抗性训练防御方法，该方法在插值示例上微调模型，可以将攻击成功率降低超过80%，并且不影响良性输入的性能。", "conclusion": "实证研究表明，LFJ的有效性很大程度上取决于查询对选择、隐藏状态插值组件和优化策略。对抗性训练防御方法能显著降低LFJ的攻击成功率，并且有助于确保模型的安全性和有效性。"}
{"llm_update_time": "20250815", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.10027", "html_url": "https://arxiv.org/abs/2508.10027", "title": "LLMCARE：通过生成合成数据增强的变压器模型进行阿尔茨海默病检测", "title_en": "LLMCARE: Alzheimer's Detection via Transformer Models Enhanced by LLM-Generated Synthetic Data", "authors": "Ali Zolnour,Hossein Azadmaleki,Yasaman Haghbin,Fatemeh Taherinezhad,Mohamad Javad Momeni Nezhad,Sina Rashidi,Masoud Khani,AmirSajjad Taleban,Samin Mahdizadeh Sani,Maryam Dadkhah,James M. Noble,Suzanne Bakken,Yadollah Yaghoobzadeh,Abdol-Hossein Vahabie,Masoud Rouhizadeh,Maryam Zolnoori", "background": "阿尔茨海默病及相关痴呆症（ADRD）影响着美国大约500万老年人，但超过一半的人没有被诊断出。语音基于自然语言处理（NLP）提供了一种有潜力、可扩展的方法，通过语言标志来检测早期认知衰退。该研究利用陈年银行“饼干盗窃”任务的转录材料，通过融合变压器嵌入和手工编写的语言特征、测试使用大规模语言模型（LLM）生成的合成语音进行数据增强，以及对标记独立试验和微调设置下的单模态和多模态LLM分类器进行基准测试，来开发并评估一种筛查流程。", "innovation": "该研究创新地融合了变压器嵌入和手工编写的语言特征，采用大规模语言模型生成的合成语音来增强训练数据，并测试了单模态和多模态LLM分类器在临床错误标记数据中的应用。结果显示，融合模型在F1得分为83.3（AUC为89.5），表现优于基于语言或仅变压器的基本模型。生成的合成语音增强训练数据后，F1得分提高到85.7。微调显著提高了单模态LLM分类器的表现，而当前的多模态模型在表现上较差，需要进一步在多模态建模中进行研究和改进以提高性能。临床调参过的LLM不仅在分类上有效，还支持了数据增强，但需要在多模态建模方面进一步推进。", "conclusion": "融合变压器嵌入和手工编写的语言特征可以提高ADRD从语音中检测的能力。临床调参的LLM在支持分类和数据增强方面表现出有效性，但多模态建模仍需进一步研究和改进以提高性能。"}
{"llm_update_time": "20250815", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.10030", "html_url": "https://arxiv.org/abs/2508.10030", "title": "具备推理意识的提示优化方法以对齐黑盒大型语言模型", "title_en": "Inference-Aware Prompt Optimization for Aligning Black-Box Large Language Models", "authors": "Saaduddin Mahmud,Mason Nakamura,Kyle H. Wray,Shlomo Zilberstein", "background": "提示优化方法在对齐黑盒大型语言模型（LLMs）方面已经显示出显著的效果。同时，如最佳多次采样和多数投票的推理扩展策略也被证明可以增进对齐和性能，但需要在计算上有所权衡。然而，现有的提示优化方法忽视了推理策略的影响，不同的推理策略对提示优化的结果存在不同的影响。研究发现在这些方法上还存在重要的方法论缺口，即提示优化方法与推理策略之间存在紧密关系。不同的用户偏好和多目标下推理预算的选择也对提示和推理配置的选择产生影响。因此，需要一种能够同时优化提示和推理规模，并考虑到推理预算和不同任务目标的新框架来弥补这一差距。", "innovation": "作者提出了一个名为IAPO（Inference-Aware Prompt Optimization，具有推理意识的提示优化）的新框架，该框架可以同步优化提示和推理规模，同时考虑推理预算和不同的任务目标。为了支持IAPO框架下的优化，作者还开发了名为PSST（Prompt Scaling via Sequential Trimming，基于序列修剪的提示缩放）的固定预算训练算法，并对其在有限预算上的错误概率进行了保证分析。研究结果显示，使用IAPO工具箱进行提示优化可使黑盒LLMs在六个不同任务，包括多目标文本生成和推理上表现出更好的性能。", "conclusion": "研究展现了一个全新的IAPO框架，能够在优化过程中同时考虑提示和推理规模，预测误差概率，并且在有限预算下进行优化。研究结果表明，在对齐黑盒大型语言模型时，通过提示优化方式整合推理意识和预算对优化的重要性。"}
{"llm_update_time": "20250815", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.10142", "html_url": "https://arxiv.org/abs/2508.10142", "title": "多轮谜题：评估LLMs的交互推理与战略对话能力", "title_en": "Multi-Turn Puzzles: Evaluating Interactive Reasoning and Strategic Dialogue in LLMs", "authors": "Kartikeya Badola,Jonathan Simon,Arian Hosseini,Sara Marie Mc Carthy,Tsendsuren Munkhdalai,Abhimanyu Goyal,Tomáš Kočiský,Shyam Upadhyay,Bahare Fatemi,Mehran Kazemi", "background": "大型语言模型在解决清晰完整表述的问题上表现出色，但在处理复杂的环境中或互动任务时常常遇到困难。这些任务在大多数实际场景中非常常见。这一现象强调了开发能够进行逻辑连贯的多轮对话、寻找信息并处理不完整数据的LLMs的重要性。本文介绍了一个新颖的基准测试，包含了一系列多轮任务，旨在测试具体的推理、互动对话和信息求取能力。这些任务具有确定的评分机制，从而避免了人工干预的需求。评估前沿模型在该基准测试上的表现揭示了显著的改进空间。分析表明，大多数错误源于指令执行不良、推理失败和规划薄弱。", "innovation": "本文提出了一个新的基准测试，包含多轮任务来评测交互推理和战略对话能力。此基准测试具有确定的评分机制，能有效避免人工干预。这为未来的模型改进提供了有价值的见解和促进平台。", "conclusion": "评估前沿模型的结果显示了显著的改进空间。分析指出主要错误来源包括不遵守指令、推理失败和规划不足。此基准测试提供了对当前LLMs处理复杂互动场景的强项和弱点的深入了解，为未来的研究提供了坚实平台以提高这些关键技术能力。"}
{"llm_update_time": "20250815", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.10036", "html_url": "https://arxiv.org/abs/2508.10036", "title": "反思而后学习：基于内在困惑的主动提示信息提取", "title_en": "Reflect then Learn: Active Prompting for Information Extraction Guided by Introspective Confusion", "authors": "Dong Zhao,Yadong Wang,Xiang Chen,Chenxi Wang,Hongliang Dai,Chuanxing Geng,Shengzhong Zhang,Shaoyuan Li,Sheng-Jun Huang", "background": "大规模语言模型（LLMs）在少量示例信息提取（IE）方面显示出巨大的潜力，但其性能高度依赖于上下文示例的选择。传统的选择策略往往未能提供有效的指导，因为它们忽视了模型错误的关键来源：不仅仅是语义内容的混淆，还有生成信息抽取任务所需的良好结构格式的问题。已有的策略无法有效识别和排除这些混淆因素，导致提取效果不尽人意。", "innovation": "本文提出了基于内在困惑的主动提示信息提取（APIE）方法，这是一种新颖的主动提示框架，由一个我们称为内在困惑的原则指导。APIE框架通过一个独特的不确定性度量来帮助LLM评估自身的困惑，该度量量化了格式不确定性（生成正确语法的难度）和内容不确定性（提取出来的语义不一致）。我们的方法能够综合评分未标记的数据，并主动选择最具挑战性和信息量的样本作为少量示例。实验结果表明，与强基线相比，我们的方法在信息提取的准确性和稳健性上都取得了显著提升，强调了在构建有效的和可信赖的结构化生成系统时细致的、多层次的模型不确定性视图的重要性。", "conclusion": "我们的研究表明，针对信息提取任务中的内在困惑进行主动提示是提高LLM性能的有效策略，通过综合利用格式和内容不确定性，可以帮助模型更好地生成和提取所需信息。"}
{"llm_update_time": "20250815", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.10028", "html_url": "https://arxiv.org/abs/2508.10028", "title": "PREF: 在LLMs中参考无关的个性化文本生成评估", "title_en": "PREF: Reference-Free Evaluation of Personalised Text Generation in LLMs", "authors": "Xiao Fu,Hossein A. Rahmani,Bin Wu,Jerome Ramos,Emine Yilmaz,Aldo Lipani", "background": "个性化文本生成对于用户中心的信息系统至关重要，但大多数评估方法忽略了用户的独特性。传统方法通常依赖于预定义的参考文本来进行个性化评估，这可能导致评估结果不准确，忽略了用户的具体偏好和背景。因此，需要一种新的方法来衡量通用输出质量和用户特定的对齐度，而不依赖于金标准的个性化参考。", "innovation": "PREF提出了一个新颖的框架，用于衡量LLMs中个性化文本生成的质量和与用户的对齐度。PREF框架通过三个步骤操作：1）覆盖阶段使用大型语言模型（LLM）生成全面的查询特定准则，涵盖诸如事实性、连贯性和完整性的普遍标准；2）偏好阶段重新排序和选择性地增强这些因素，利用目标用户的相关或推断偏好和上下文信息，生成个性化的评估标准；3）评分阶段将LLM裁判应用于根据评估标准评估候选答案，确保基线适用性的同时捕捉主观优先级。通过将覆盖率和偏好分离，PREF提高了鲁棒性、透明性和可重用性，使得较小的模型能够模拟大型模型的个性化质量。", "conclusion": "PREF在Pre eva 参考基准上的实验结果显示，与强大的基线相比，PREF在准确性、校准和与人类判断的接近度方面表现出色。通过实现可扩展、可解释和用户对齐的评估，PREF为个性化语言生成系统提供了更可靠的研究和开发基础。"}
{"llm_update_time": "20250815", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.10295", "html_url": "https://arxiv.org/abs/2508.10295", "title": "LLM提示的归纳偏置提取与匹配", "title_en": "Inductive Bias Extraction and Matching for LLM Prompts", "authors": "Christian M. Angel,Francis Ferraro", "background": "当前关于提示工程的热门研究主题表明，大规模语言模型（LLM）对提示措辞的小变化非常敏感，这在一定程度上可归因于LLM内部存在的一些归纳偏置。利用LLM的输出帮助优化提示措辞，可以更轻松地达到满意的表达效果，进而使提示与模型的归纳偏置更为匹配。", "innovation": "提出了一种新的策略——归纳偏置提取与匹配（Inductive Bias Extraction and Matching），通过使用LLM的输出来调整或设计提示，这种方法在文本分类和排名中表现出了显著的改进。具体而言，使用这种策略提高了LLM打分评价，分类任务中提升了19%，排名任务中则提升了27%。", "conclusion": "研究结果显示，通过归纳偏置提取与匹配方法可以显著提高LLM的评价分数，特别是在分类和排名任务中。这表明，根据模型偏置调整提示措辞是提高LLM性能的有效手段。"}
{"llm_update_time": "20250815", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.10175", "html_url": "https://arxiv.org/abs/2508.10175", "title": "机器翻译难度估计", "title_en": "Estimating Machine Translation Difficulty", "authors": "Lorenzo Proietti,Stefano Perrella,Vilém Zouhar,Roberto Navigli,Tom Kocmi", "background": "机器翻译的质量已经在某些设置下达到了近乎完美的程度。这些高质量的输出使得区分最先进模型的性能变得困难，并且难以识别改进的领域。自动识别机器翻译系统在其中挣扎的文本，可能有助于开发更有针对性的评估和引导未来的科学研究。", "innovation": "本文提出了翻译难度估计的任务，并定义了基于预期翻译质量的文本难度。引入了一种新的评估难度估计器的标准，并对基线方法和新颖方法进行了评估。最后，通过将难度估计器用于构建更具挑战性的机器翻译基准，证明了其实践效用。结果表明，专用模型（称为Sentinel-src）在各种方法中表现最佳，包括基于启发式的（如单词稀有性或句法复杂性）方法和大语言模型作为裁判的方法。并发布了两种改进的难度估计模型：Sentinel-src-24和Sentinel-src-25。", "conclusion": "这些改进的模型可以用于扫描大型文本集合，并筛选出那些最有可能挑战当今机器翻译系统的文本。这一方法有助于提高机器翻译评估的差异化水平，并指导未来的研究方向。"}
{"llm_update_time": "20250815", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.10161", "html_url": "https://arxiv.org/abs/2508.10161", "title": "LaaJMeter: 一种Laaj评估框架", "title_en": "LaajMeter: A Framework for LaaJ Evaluation", "authors": "Gal Amram,Eitan Farchi,Shmulik Froimovich,Raviv Gal,Avi Ziv", "background": "大型语言模型（LLMs）在自然语言处理任务中被用作评估者，这被称为Laaj（LLM-as-a-Judge）。虽然这种模式在通用领域效果显著，但在具有专门领域背景的上下文中，却因缺乏标注数据且专家评估成本高而变得具有挑战性。在这种背景下，通常使用未在特定领域验证过的指标进行元评估，这使得确定哪些指标有效评估Laaj质量变得困难，并进一步确定表明足够评估者性能的阈值也变得困难。因此，需要一种新的方法来解决这些问题。", "innovation": "本文提出了LaaJMeter，一种基于仿真框架，用于控制的Laaj元评估。LaaJMeter通过生成代表虚拟模型和评估者的合成数据，使得工程师可以在真实条件下系统地分析评估指标。这帮助从业者验证并细化专门用于评估任务的Laaj：可以测试其指标是否能正确区分更好的和较差的（虚拟的）Laaj，并估算评估者性能的适当阈值。本文通过在涉及遗留编程语言的代码翻译任务中展示LaaJMeter的应用，证明了其实用性和重要性，展示了不同指标对评估者质量敏感性的差异。", "conclusion": "我们的结果强调了常见指标的局限性，并突显了有原则地选择指标的重要性。LaaJMeter提供了一种在资源匮乏环境中评估Laaj的可扩展且可扩展的解决方案，有助于确保自然语言处理中评估的可靠性和可重复性。"}
{"llm_update_time": "20250815", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.10226", "html_url": "https://arxiv.org/abs/2508.10226", "title": "使用大型语言模型测量高风险精神分裂症患者的症状严重程度", "title_en": "Using Large Language Models to Measure Symptom Severity in Patients At Risk for Schizophrenia", "authors": "Andrew X. Chen,Guillermo Horga,Sean Escola", "background": "对于临床高风险（CHR）的精神分裂症患者，需要密切监测其症状以便提供适当的治疗。现有的贝尔精神病量表（BPRS）是一种被验证且常用的科研工具，用于测量精神分裂症及其他精神病性障碍患者的症状，但因需长时间结构化的访谈而在临床实践中不常用。", "innovation": "本文利用大型语言模型（LLMs）从409名AMP-SCZ队列中的CHR患者临床访谈转录中预测BPRS评分，即使访谈未专门用于测量BPRS，LLMs预测结果与真正评估相比（中位一致性：0.84，ICC：0.73）接近人类的评定者间和评定者内可靠性。此外，展示了通过准确性评估BPRS、处理不同语言数据以及结合纵向信息的潜力。", "conclusion": "大语言模型在预测CHR患者的BPRS评分上具有重要潜力，能够提高和标准化CHR患者的评估，包括在不同语言背景下和结合纵向信息精确评估BPRS方面。"}
{"llm_update_time": "20250815", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.10246", "html_url": "https://arxiv.org/abs/2508.10246", "title": "计算语言学方法在分析构建型语言托基波纳语言变化与变异中的应用", "title_en": "A Computational Approach to Analyzing Language Change and Variation in the Constructed Language Toki Pona", "authors": "Daniel Huang,Hyoun-A Joo", "background": "本研究探讨了包含约120个核心词汇的构建型语言托基波纳的语言变化与变异。研究表明，社会语言学因素对托基波纳的影响与自然语言相同，且该构建型语言系统随着社区使用自然地演变。", "innovation": "研究采用计算和语料库方法，分析托基波纳中的语言变化与变异，特别关注内容词在不同句法位置上的偏好的变化以及不同语料库中的使用差异。通过这种新颖的方法，揭示了构建型语言的自然演进机制。", "conclusion": "研究结论表明，即使是在构建型语言中，社会语言学因素也起着重要作用，影响着语言的长期发展。托基波纳作为一个构建型语言，与自然语言一样，会随着时间的推移而自然发展和演变。"}
{"llm_update_time": "20250815", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.10013", "html_url": "https://arxiv.org/abs/2508.10013", "title": "Semantic Bridge: 半监督多跳问题生成通过AMR驱动的图合成", "title_en": "Semantic Bridge: Universal Multi-Hop Question Generation via AMR-Driven Graph Synthesis", "authors": "Linqing Chen,Hanmeng Zhong,Wentao Wu,Weilei Wang", "background": "大型语言模型（LLM）的训练面临一个关键瓶颈：高质量、推理密集型的问答对稀缺，尤其是来自如PubMed论文或法律文件等稀疏的专业领域来源。现有方法依赖于表面特征，无法生成可控且复杂的多跳推理问题，而这是提高LLM训练范式的关键。", "innovation": "我们提出了**语义桥梁**，这是第一个通用框架，用于从任意来源可控地生成复杂的多跳推理问题。我们的突破性创新是**语义图编织**——三个互补的桥梁机制（实体桥梁用于角色变化的共享实体，谓词链桥梁用于时间/因果/逻辑序列，因果桥梁用于显式的推理链），这些机制系统地构建跨文档的复杂路径，并通过AMR驱动的分析实现复杂的程度和类型的细粒度控制。我们的多模态AMR流水线在圆往返质量上实现了高达9.5%的改进，从而使可控问答生成达到生产级。", "conclusion": "广泛的评估表明，从各种通用数据集（如Wikipedia）和专业领域（如生物医学）的性能均有所提升，四国语言（英语、中文、法语、德语）的结果显示比基线有18.3%-25.4%的改进。由200个来源生成的问题对表现出了67%更少材料的600个本源人类注释示例的优越性。人工评估显示复杂度提高了23.4%，答案性提高了18.7%，模式覆盖率提高了31.2%。语义桥梁确立了LLM训练数据合成的新范式，能够从稀疏来源生成有针对性的推理问题。我们将会释放核心代码和语义桥梁模型。"}
{"llm_update_time": "20250815", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.10222", "html_url": "https://arxiv.org/abs/2508.10222", "title": "通过表情预测理解文本情感", "title_en": "Understanding Textual Emotion Through Emoji Prediction", "authors": "Ethan Gordon,Nishank Kuppa,Rigved Tummala,Sriram Anasuri", "background": "该项目探索了使用四种深度学习架构（前馈网络、CNN、变压器和BERT）从短文本序列预测表情符号的方法。使用TweetEval数据集，通过采用焦点损失和正则化技术来解决类别不平衡问题。研究结果表明，BERT由于其预训练优势在整体性能上表现出色，而CNN在预测罕见表情类别上表现更佳。这些发现强调了为情感智能表情预测选择合适架构和调优超参数的重要性，有助于提高人机交互的效果。", "innovation": "项目采用了四种深度学习架构来预测表情符号，使用TweetEval数据集，并通过焦点损失和正则化技术解决类别不平衡问题。研究突出了不同架构和超参数调整对表情预测的重要性。BERT因其预训练优势在总体性能上表现出色，而CNN在处理罕见表情类别方面表现出色。", "conclusion": "研究展示了架构选择和超参数调优对情感意识表情预测的重要性，进而改善了人机交互，并提出了改进方案。"}
{"llm_update_time": "20250815", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.10192", "html_url": "https://arxiv.org/abs/2508.10192", "title": "大语言模型（LLMs）的提示-响应语义发散度度量方法，用于检测忠实性幻觉和不一致检测", "title_en": "Prompt-Response Semantic Divergence Metrics for Faithfulness Hallucination and Misalignment Detection in Large Language Models", "authors": "Igor Halperin", "background": "大语言模型的普及受到了幻象问题的挑战，即模型生成非事实性、无意义或不忠实的文本。现有方法如语义熵通过测量单一固定提示下答案的多样性来测试任意性，但缺乏对多个提示版本或其同义重述的响应一致性测试。", "innovation": "该论文提出了语义发散度度量（SDM），这是一种新的轻量级框架，用于检测忠实性幻觉——模型响应严重偏离输入上下文的情况。SDM通过联合聚类句子嵌入来创建提示和回答共享主题空间，通过计算熵测度和沃斯泰默距离来量化语义发散，以及识别KL散度作为语义探索的关键指标。进一步整合这些指标形成了语义盒，这是一种诊断框架，用于分类LLM响应类型，包括危险的、自信的虚构。", "conclusion": "SDM提供了一种方法来检测LLM中忠实性幻觉，并通过语义探索度量区分不同的生成行为。语言模型的提示和响应之间的语义发散可以通过热图可视化，并为用户与机器对话提供定量的二维视图。"}
{"llm_update_time": "20250815", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.10186", "html_url": "https://arxiv.org/abs/2508.10186", "title": "PakBBQ：适合QA的文化适应型偏见基准", "title_en": "PakBBQ: A Culturally Adapted Bias Benchmark for QA", "authors": "Abdullah Hashmat,Muhammad Arham Mirza,Agha Ali Raza", "background": "随着大型语言模型（LLMs）在各种应用中的广泛采用，确保它们在所有用户社区中的公平性变得至关重要。然而，大多数LLMs都是在以西方为中心的数据集上训练和评估的，对低资源语言和地区背景的关注不足。为了解决这个问题，本文介绍了PakBBQ，这是对原始偏见基准问答（BBQ）数据集的一种文化与地区适应性扩展。PakBBQ覆盖了英语和乌尔都语两种语言，包含了涵盖年龄、残疾、外表、性别、社会经济地位、宗教、地区归属和语言正式程度等八类偏见维度的超过214个模板和17180个QA对，这些维度在巴基斯坦尤其相关。研究了在模糊和明确去模糊化情境下以及负面陈述和非负面陈述的不同问题框架下，对多个多语言LLMs的评估。这些实验证明了去模糊化可以提高平均准确率12％，乌尔都语在对抗偏见方面比英语更强，并且问题以负面形式提出时，会减少刻板印象的回答。这些发现强调了在低资源环境中使用上下文化基准和简单提示工程策略以减轻偏见的重要性。", "innovation": "本文的创新之处在于引入了PakBBQ，这是一种文化与地区适应性的偏见基准数据集扩展，针对巴基斯坦的具体情况，涵盖了多种偏见维度，并在多语言LLMs上进行了评估。展示了去模糊化的效果、不同语言环境下对抗偏见的能力差异以及问题形式对回答偏见的影响，提供了简单有效的减缓偏见的提示策略。", "conclusion": "实验结果表明，去模糊化有助于提高问题回答的准确性，乌尔都语在对抗偏见方面具有优势，而成问题的提问方式则能够减少刻板印象的回答。这些发现强调了在低资源环境中使用上下文化偏见基准数据集和简单提示策略对于减轻偏见的重要性。"}
{"llm_update_time": "20250815", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.10180", "html_url": "https://arxiv.org/abs/2508.10180", "title": "预训练大语言模型和视觉-语言模型的高效单一前向数据估值", "title_en": "Efficient Forward-Only Data Valuation for Pretrained LLMs and VLMs", "authors": "Wenlong Deng,Jiaming Zhang,Qi Zeng,Christos Thrampoulidis,Boying Gong,Xiaoxiao Li", "background": "量化个体训练样本的影响对于提高大语言模型和视觉-语言模型的透明度和可问责性至关重要。然而，现有的数据估值方法通常依赖于海森矩阵信息或模型重训练，这在处理十亿参数量的模型时成本非常高昂。", "innovation": "提出了For-Value，一种单一前向的数据估值框架，可以为大语言模型和视觉-语言模型提供可扩展和高效的影响力估计。通过利用现代基础模型丰富的表示能力，For-Value 使用基于单一前向传播的简单闭合形式计算影响力得分，从而无需昂贵的梯度计算。", "conclusion": "理论分析表明，For-Value 能准确估计样本的影响力，通过捕捉训练和验证样本在隐藏表示和预测错误之间的对齐性。广泛的实验表明，For-Value 在识别具有影响性的微调示例和有效检测错误标签数据方面优于基于梯度的方法。"}
{"llm_update_time": "20250815", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.10308", "html_url": "https://arxiv.org/abs/2508.10308", "title": "ReviewRL：利用强化学习实现自动科学评论", "title_en": "ReviewRL: Towards Automated Scientific Review with RL", "authors": "Sihang Zeng,Kai Tian,Kaiyan Zhang,Yuru wang,Junqi Gao,Runze Liu,Sa Yang,Jingxuan Li,Xinwei Long,Jiaheng Ma,Biqing Qi,Bowen Zhou", "background": "同行评审是科学进步的重要推动力，但由于提交数量的增加和评审疲劳，它正面临越来越多的挑战。现有的自动化评审方法在事实准确性、评分一致性以及分析深度方面存在局限，通常生成的是浅显或通用性反馈，缺乏高质量人工评审中的洞察力。", "innovation": "提出了ReviewRL，一种基于强化学习的生成全面且基于事实的科学论文评审的框架。该方法结合了：（1）ArXiv-MCP检索增强上下文生成pipeline，（2）监督微调以建立基本的评审能力，（3）一种奖励函数的强化学习过程，该过程共同提升了评审质量和评分准确性。在ICLR 2025论文的实验中，ReviewRL在基于规则的度量和基于模型的质量评估中都显著优于现有方法。", "conclusion": "ReviewRL为RL驱动的自动批评生成提供了一个基础框架，展示了未来在此领域发展的潜在重要性，其实现将发布在GitHub上。"}
{"llm_update_time": "20250815", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.10366", "html_url": "https://arxiv.org/abs/2508.10366", "title": "使用大型语言模型和约束解码推进序列到序列模型的跨语言方面情感分析", "title_en": "Advancing Cross-lingual Aspect-Based Sentiment Analysis with LLMs and Constrained Decoding for Sequence-to-Sequence Models", "authors": "Jakub Šmíd,Pavel Přibáň,Pavel Král", "background": "方面基于情感分析（ABSA）已有显著进展，但低资源语言仍面临挑战，因为大部分工作集中在英语上。当前跨语言ABSA研究通常专注于更简单的任务，且高度依赖外部翻译工具。", "innovation": "提出了一种新的序列到序列方法，通过受约束解码消除对外部翻译工具的依赖，该方法在跨语言ABSA上提升了多达10%的性能，并将其应用范围扩展到更复杂的任务。", "conclusion": "本文方法扩大了跨语言ABSA的应用领域，使其能够处理更复杂的任务，提供了与依赖翻译技术的方法相比更实用和高效的方案。此外，对比研究还显示，虽然微调多语言大型语言模型可以达到类似结果，但以英语为中心的大型语言模型在此类任务中表现不佳。"}
{"llm_update_time": "20250815", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.10352", "html_url": "https://arxiv.org/abs/2508.10352", "title": "跨提示编码器用于低表现语言", "title_en": "Cross-Prompt Encoder for Low-Performing Languages", "authors": "Beso Mikaberidze,Teimuraz Saghinadze,Simon Ostermann,Philipp Muller", "background": "软提示作为一种参数高效微调（PEFT）的强大力量，已取代适配器，让大型语言模型（LLMs）能在无需架构变化或参数更新的情况下适应下游任务。虽然先前的工作主要通过参数交互稳定小型神经提示编码器的训练，但提示在跨语言迁移中的潜力尚未被充分探索。", "innovation": "本文提出Cross-Prompt Encoder（XPE），该编码器结合了轻量级的编码架构和多样语言上的多源训练，能够捕捉跨语言的语言抽象和可迁移模式。另外，提出的Dual Soft Prompt机制结合了基于编码器的提示和直接训练的标准软提示，这种混合设计特别适合受益于广泛共享结构和语言特定对齐的目标语言。", "conclusion": "实验结果表明，XPE在低表现语言上的效果最好，而混合变体则在多语言环境下提供了更广泛的应用适应性。"}
{"llm_update_time": "20250815", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.10312", "html_url": "https://arxiv.org/abs/2508.10312", "title": "超越语义理解：保留基于LLM的推荐中的协作频谱成分", "title_en": "Beyond Semantic Understanding: Preserving Collaborative Frequency Components in LLM-based Recommendation", "authors": "Minhao Wang,Yunhang He,Cong Xu,Zhangchi Zhu,Wei Zhang", "background": "推荐系统与大型语言模型（LLMs）的结合为生成语义相关的推荐提供了潜在途径，但LLM基推荐器倾向于过度强调用户交互历史中的语义相关性。当使用预训练的协作ID嵌入作为输入时，LLM基推荐器会逐层减弱内在的协作信号，不同于传统的Transformer序列模型，后者通常保存并增强了协作信号，以实现顶级性能。这限制了LLM基推荐器的有效性。", "innovation": "本文提出了FreLLM4Rec，一种从频谱角度平衡语义和协作信息的方法。通过全球图低通滤波器（G-LPF）初步净化包含语义和协作信息的项嵌入，以去除无关的高频率噪声。时间频率调制（TFM）随后逐层积极保留协作信号，其协作保存能力通过将最优但难以实现的局部图Fourier滤波器与子最优且计算高效的频域滤波器建立联系而理论上得到保证。", "conclusion": "在四个基准数据集上进行的广泛实验表明，FreLLM4Rec成功缓解了协作信号衰减并实现了竞争力表现，NDCG@10对比最优基线提高了8.00%。我们的发现阐明了LLM处理协作信息的过程，并为提高基于LLM的推荐系统提供了一种原理性的方法。"}
{"llm_update_time": "20250815", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.10355", "html_url": "https://arxiv.org/abs/2508.10355", "title": "使用强化学习使Qwen3能够用韩语思考", "title_en": "Making Qwen3 Think in Korean with Reinforcement Learning", "authors": "Jungyup Lee,Jemin Kim,Sang Park,SeungJae Lee", "background": "本文介绍了在大规模语言模型Qwen3 14B上采用两阶段微调方法，使其能够以韩语进行自然思考。在第一阶段，通过高质量的韩语逻辑推理数据集的监督微调（SFT）建立韩语逻辑推理的基础，提高了韩语文本任务的表现，甚至在通用逻辑推理方面也有所进步。第二阶段采用自定义的Group Relative Policy Optimization (GRPO)算法进行强化学习，以进一步增强韩语文本的逻辑推理对齐和整体问题解决能力。", "innovation": "通过引入一个或acles judge模型来校准奖励信号，解决GRPO训练中的关键稳定性挑战（如奖励作弊和策略崩溃），从而实现稳定的训练过程，避免了原始GRPO中的策略崩溃，并且取得了稳定而逐步的性能改进。最终，RL调优模型在高级推理基准测试中（尤其是在数学和编程任务方面）表现出显著改进的结果，同时保持了知识和语言能力，并能够全程用韩语进行自我推理。", "conclusion": "本文的方法通过两阶段方法使Qwen3能够用韩语进行逻辑推理，并通过自定义GRPO算法和引入oracle judge模型增强了模型的鲁棒性和整体表现，特别是在高级推理任务上的表现更为显著，同时保持了知识和语言能力。"}
{"llm_update_time": "20250815", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.10304", "html_url": "https://arxiv.org/abs/2508.10304", "title": "另一种算法偏见：大型语言模型强化性别和种族主导话语的话语分析", "title_en": "Yet another algorithmic bias: A Discursive Analysis of Large Language Models Reinforcing Dominant Discourses on Gender and Race", "authors": "Gustavo Bonil,Simone Hashiguti,Jhessica Silva,João Gondim,Helena Maia,Nádia Silva,Helio Pedrini,Sandra Avila", "background": "随着人工智能的发展，大型语言模型（LLMs）已经得到了广泛应用，并且在多样化的情境中取得了显著的成效。随着LLMs变得越来越复杂，重要的是评估它们是否会再现偏见，例如歧视和种族化，同时维持霸权话语。目前的偏见检测方法主要依赖于定量的、自动化的手段，往往忽略了偏见在自然语言中复杂的生成方式。因此，本研究提出了一种定性的、话语框架的方法来补充这些方法。通过对LLMs生成的以黑人和白人女性为主角的短篇故事的手动分析，本研究调查了性别和种族偏见的表现形式。", "innovation": "本研究提出了一种定性的、话语框架的方法来分析LLMs中的性别和种族偏见。这种定性方法能够帮助开发者和用户识别LLMs输出中偏见的具体表现方式，从而更好地条件来减轻偏见。通过手动分析LLMs生成的故事，本研究揭示了黑人女性与祖先和反抗联系在一起，而白人女性则处于自我发现的过程中。这反映了语言模型是如何复制固化的话语表征，强化了本质化的特征和社会流动性感的缺失。当被要求纠正偏见时，模型提供的修改通常是表面性的，维持了不合适的含义，显示了在促进包容性叙事方面存在的局限性。", "conclusion": "本研究的结果表明了算法的意识形态功能，并且对于AI的道德使用和发展具有重要的意义。研究强调了需要批判性、跨学科的方法来设计和部署AI，以应对LLMs生成的语境如何反映和延续不平等现象。"}
{"llm_update_time": "20250815", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.10390", "html_url": "https://arxiv.org/abs/2508.10390", "title": "使用明确有害提示破解商用黑盒大语言模型", "title_en": "Jailbreaking Commercial Black-Box LLMs with Explicitly Harmful Prompts", "authors": "Chiyu Zhang,Lu Zhou,Xiaogang Xu,Jiafei Wu,Liming Fang,Zhe Liu", "background": "对不明显有害或未导致有害输出的提示进行破解评估具有挑战性。现有的红队数据集往往包含此类不合适的提示。为了准确评估攻击，这些数据集需要对恶意内容进行评估和清理。然而，现有的恶意内容检测方法依赖于手动注释（耗时）或大型语言模型（LLMs，其在有害类型上的准确率不一致）。", "innovation": "提出了一个名为MDH的混合评估框架，结合了LLM基于的注释和最少的人工监督，用于数据集清理和检测破解响应。同时，发现精心设计的开发者消息能够显著提高破解成功率，提出了D-Attack（利用上下文模拟）和DH-CoT（结合被劫持的思维链）两种新策略。", "conclusion": "代码、数据集、判断结果和检测结果将在GitHub仓库中公布：this https URL。"}
{"llm_update_time": "20250815", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.10368", "html_url": "https://arxiv.org/abs/2508.10368", "title": "大规模语言模型在总结捷克历史文献及其更广泛的应用方面的应用", "title_en": "Large Language Models for Summarizing Czech Historical Documents and Beyond", "authors": "Václav Tran,Jakub Šmíd,Jiří Martínek,Ladislav Lenc,Pavel Král", "background": "文本总结是将较大篇幅的文本压缩为简洁版本，同时保留其核心意义和关键信息的任务。尽管在英语及其他高资源语言中已经显著探索了文本总结，但对于捷克历史文献的总结仍然少有研究，主要原因在于捷克语的语言复杂性以及标注数据集的匮乏。而像Mistral和mT5这样的大规模语言模型已经在许多自然语言处理任务和语言中展现了出色的结果。因此，本文使用这些模型进行捷克语摘要，并取得了两项重要贡献：（1）在现代捷克语摘要数据集SumeCzech上实现了新的最佳结果；（2）引入了一个名为Posel od Čerchova的新数据集，用于历史捷克文档的摘要，生成了基准结果。", "innovation": "文章的关键贡献包括，在现代捷克语摘要数据集SumeCzech上利用先进模型取得了新最佳结果；并且引入了一个新的数据集Posel od Čerchova，用于历史捷克文档的总结，并提供了基准结果。这些贡献为推进捷克文本总结奠定了基础，并为捷克历史文本处理的研究开辟了新的研究方向。", "conclusion": "本文的重要结论是，通过大规模语言模型可以实现捷克简介任务的新突破，并且提供了历史捷克文本摘要的新基准，从而为捷克文本总结领域的发展提供了巨大的潜力，并为进一步研究捷克历史文本处理带来了机会。"}
{"llm_update_time": "20250815", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.10369", "html_url": "https://arxiv.org/abs/2508.10369", "title": "改进生成式跨语言方面基于情感分析的策略", "title_en": "Improving Generative Cross-lingual Aspect-Based Sentiment Analysis with Constrained Decoding", "authors": "Jakub Šmíd,Pavel Přibáň,Pavel Král", "background": "方面基于情感分析（ABSA）已经取得显著进展，但低资源语言仍然面临着挑战，这些语言常被英语所忽视。当前的跨语言ABSA方法主要集中在简单的任务上，并且依赖于外部翻译工具。", "innovation": "本文引入了使用受限解码的序列到序列模型的新方法，无需外部翻译工具即可提高最复杂任务上的跨语言性能，平均提高5%。此外，该方法支持多任务处理，能够用单个模型解决多个ABSA任务，受限解码方式使结果提升了超过10%。在七种语言和六种ABSA任务上的评估中，超过了最先进的方法，并为未探索的任务设立了新的基准。研究还评估了大型语言模型在零样本、少量样本和微调场景下的表现。", "conclusion": "研究提供了一些建议，以提高实际应用中的跨语言ABSA方法的理解。本文为跨语言ABSA方法的研究提供了宝贵的见解，推动了这个充满挑战的研究领域的进步。"}
{"llm_update_time": "20250815", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.10404", "html_url": "https://arxiv.org/abs/2508.10404", "title": "通过稀疏自编码器进行逐层扰动的对抗文本生成", "title_en": "Layer-Wise Perturbations via Sparse Autoencoders for Adversarial Text Generation", "authors": "Huizhen Shu,Xuying Li,Qirui Wang,Yuji Kosuga,Mengqiu Tian,Zhuo Li", "background": "随着自然语言处理（NLP）尤其是大型语言模型（LLMs）的迅速发展，生成对抗样本以‘开锁’LMMs成为理解模型脆弱性和提升鲁棒性的关键挑战。本文在此背景下，提出了一种新的黑盒攻击方法，利用大型模型的可解释性。这种方法利用稀疏自编码器（Sparse Autoencoders, SAE）来识别和操纵文本中的关键特征，期望通过这种方式提高对抗样本的有效性同时减少潜在风险。", "innovation": "本文提出了一种名为Sparse Feature Perturbation Framework (SFPF)的新方法，该方法利用稀疏自编码器来生成对抗文本。通过先重构隐藏层表示，再进行特征聚类以识别高激活特征，最后对这些特征进行扰动以生成新的对抗文本。这种方法在保持恶意意图的同时增强了安全信号，提供了一种新的红队策略，能够平衡对抗效果和安全对齐。", "conclusion": "实验结果表明，通过SFPF生成的对抗文本可以绕过当前最先进的防御机制，揭示出NLP领域中存在的持久性漏洞。但该方法的有效性在不同提示和不同架构中可能会有所差异，且其在其他架构和更大模型上的泛化能力仍需进一步验证。"}
{"llm_update_time": "20250815", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.10421", "html_url": "https://arxiv.org/abs/2508.10421", "title": "评估大语言模型在中文成语翻译中的表现", "title_en": "Evaluating LLMs on Chinese Idiom Translation", "authors": "Cai Yang,Yao Dou,David Heineman,Xiaofeng Wu,Wei Xu", "background": "成语因其比喻意义通常不同于其字面意义，在日常语言中非常普遍，尤其是在中文中，成语常常包含历史参考信息并遵循特定的结构模式。近年来，随着大规模语言模型在机器翻译方面取得了显著的进步，但关于中文成语翻译的研究还相对缺乏。现有评估指标无法有效衡量成语翻译的质量。", "innovation": "介绍了IdiomEval框架，该框架包含一项全面的错误分类学，用于评估中文成语翻译。通过对来自九个现代系统的900个翻译对进行标注，包括GPT-4o和Google Translate，涵盖了四个领域：网络、新闻、Wikipedia和社交媒体。发现现有系统在成语翻译方面存在较大错误，尤其是在典型案例上，GPT-4的错误率高达28%。同时，现有评估指标与人工评分的皮尔逊相关系数低于0.48。因此，开发了新的模型，以0.68的F$_1$分数成功检测成语翻译错误。", "conclusion": "提出了改进的模型，这些模型能够检测出成语翻译错误，并取得了显著的效果，F$_1$分数达到0.68。这表明需要改进现有的评估指标，以更好地衡量成语翻译的质量，并强调了在汉语成语翻译领域的研究空白。"}
{"llm_update_time": "20250815", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.10482", "html_url": "https://arxiv.org/abs/2508.10482", "title": "当解释性遇到隐私：在自然语言处理背景下后验解释性和差分隐私交叉点的研究", "title_en": "When Explainability Meets Privacy: An Investigation at the Intersection of Post-hoc Explainability and Differential Privacy in the Context of Natural Language Processing", "authors": "Mahdi Dhaini,Stephen Meisenbacher,Ege Erdogan,Florian Matthes,Gjergji Kasneci", "background": "在可信自然语言处理（NLP）的研究中，可解释性和隐私保护已成为两个重要的研究领域。尽管近年来这两个领域的研究兴趣显著增加，但在它们交叉点的研究还相对匮乏。目前尚不清楚是否可以同时实现可解释性和隐私保护，抑或是二者总是相互冲突。", "innovation": "本文通过实证研究探讨了NLP中的隐私-解释性权衡问题，使用差分隐私（DP）和后验解释性两种流行的方法为指导。研究表明，隐私和解释性的关系复杂多样，受到下游任务的性质和文本私有化及解释性方法的选择等多种因素的影响，展示了隐私和解释性存在的潜在共存可能性，并提出了未来研究的一系列实用建议。", "conclusion": "本文的研究结果揭示了隐私和解释性之间的复杂关系，并强调了它们可以共存的可能性。基于研究结果，本文总结了未来在这一重要交叉点的实用建议。"}
{"llm_update_time": "20250815", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.10552", "html_url": "https://arxiv.org/abs/2508.10552", "title": "当语言主导一切：揭示多模态大型语言模型中的文本主导现象", "title_en": "When Language Overrules: Revealing Text Dominance in Multimodal Large Language Models", "authors": "Huyu Wu,Meng Tang,Xinhan Zheng,Haiyun Jiang", "background": "多模态大型语言模型（MLLMs）在多种多模态任务中展现出了显著的能力，但这些模型严重依赖文本进行推理，而对其他模态的利用不足。以往的工作多将这一现象归咎于数据偏差或模型架构。本文首次对多模态数据的所有类型进行全面系统的分析，发现文本主导现象在所有测试的模态中都普遍存在。", "innovation": "本文提出两种新的评估指标：模态主导指数（MDI）和注意力效率指数（AEI）。通过深入分析，识别出三个导致文本主导现象的根本原因，并提出了一个简单的标记压缩方法来平衡模型的注意力，实验证明这种方法能有效减少由文本主导带来的不平衡问题。", "conclusion": "本文的分析和方法论框架为开发更公平和全面的多模态语言模型提供了基础。"}
{"llm_update_time": "20250815", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.10419", "html_url": "https://arxiv.org/abs/2508.10419", "title": "ComoRAG：一种认知启发的基于记忆组织的RAG，用于有状态的长叙事推理", "title_en": "ComoRAG: A Cognitive-Inspired Memory-Organized RAG for Stateful Long Narrative Reasoning", "authors": "Juyuan Wang,Rongchen Zhao,Wei Wei,Yufeng Wang,Mo Yu,Jie Zhou,Jin Xu,Liyan Xu", "background": "长故事和小说的叙事理解是具有挑战性的领域，因为它们复杂的剧情线和人物之间的错综联系。鉴于LLM在长文本上下文推理方面的能力减弱及高计算成本，检索基方法在实践中仍然起着关键作用。然而，传统的RAG方法在此类动态、多层次关系的捕捉上时常表现不佳，因其缺乏记忆和单步检索机制，无法充分模拟人类认知中基于记忆信号的动态推理过程。", "innovation": "本文提出了ComoRAG，主张叙事推理是一个不断发展的动态过程，涉及新证据的获取和过往知识的融合，类似于人类在脑内推理时对记忆相关信号的处理。具体而言，当遇到推理障碍时，ComoRAG会进行迭代推理循环并与动态记忆工作空间交互。在每个循环中，它会生成探查查询以开辟新的探索路径，然后将新方面检索到的证据整合到全局记忆池中，从而为查询解决提供连贯的上下文支持。在四项具有挑战性的长文本文本叙事基准测试中（包含200K+词汇），ComoRAG显著优于强大的RAG基线方法，与最强基线相比相对改进最高达11%。进一步分析表明，ComoRAG特别适合复杂查询，强调了一种基于记忆组织的认知启发、有状态的长效推理框架。", "conclusion": "ComoRAG在长范围叙事情境下展现出强大的检索和推理能力，特别是在处理复杂查询时优势明显，提供了一种基于记忆的、符合认知动机的有状态推理框架，展示了在长文本理解上的新突破。"}
{"llm_update_time": "20250815", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.10426", "html_url": "https://arxiv.org/abs/2508.10426", "title": "在大规模语言模型中的计算经济学：在资源约束下探索模型行为和激励设计", "title_en": "Computational Economics in Large Language Models: Exploring Model Behavior and Incentive Design under Resource Constraints", "authors": "Sandeep Reddy,Kabir Khan,Rohit Patil,Ananya Chakraborty,Faizan A. Khan,Swati Kulkarni,Arjun Verma,Neha Singh", "background": "大型语言模型受限于巨大的计算成本。本文提出了一种“计算经济学”框架，将语言模型视为资源有限代理（注意力头和神经块）的内部经济体系，这些代理必须分配稀缺的计算资源以最大化任务效用。研究表明，在计算资源稀缺的情况下，标准的语言模型会重新分配注意力以投入高价值的令牌，同时保持准确性不变。", "innovation": "本文提出了一种基于激励的训练框架，用于增强任务损失函数，并加入可微分的计算成本项，鼓励稀疏和高效的激活。这种方法在GLUE（MNLI，STS-B，CoLA）和WikiText-103上取得了可与后剪枝方法相媲美的效果，同时实现了约40%的FLOPS减少和更低的延迟，还有更可解释的注意力模式。这一结果表明，经济原则为在严格资源限制下设计高效、自适应和更透明的大规模语言模型提供了一条合乎逻辑的途径。", "conclusion": "通过引入计算经济学框架和激励驱动的训练方式，本文证明了在资源受限条件下可以设计出更高效的、更能自我适应和更透明的大规模语言模型，具体表现为显著降低计算量、优化响应时间和保持准确性的平衡。"}
{"llm_update_time": "20250815", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.10444", "html_url": "https://arxiv.org/abs/2508.10444", "title": "DiFaR: 提高具有多样、事实准确且相关解释的多模态误导信息检测", "title_en": "DiFaR: Enhancing Multimodal Misinformation Detection with Diverse, Factual, and Relevant Rationales", "authors": "Herun Wan,Jiaying Wu,Minnan Luo,Xiangzheng Kong,Zihan Ma,Zhi Zeng", "background": "从大型视觉-语言模型（LVLMs）生成文本解释，以支持可训练的多模态误导信息检测器，这一方法正变得越来越有前景。然而，该方法在实际应用中的有效性受到了三个核心挑战的限制：（i）生成解释的多样性不足，（ii）由于幻觉而导致的事实不准确，（iii）不相关或矛盾的内容引入了噪声。", "innovation": "我们引入了DiFaR，一种不依赖于检测器的框架，生成多样、事实准确且相关的解释，以增强误导信息检测。该框架通过五个思维链提示来引导LVLMs产生多样的解释路径，并包含了轻量级后训练过滤模块，根据句子层面的事实准确性和相关性评分选择解释句子。", "conclusion": "在四个流行的基准测试上进行的大量实验表明，与四个基线类别相比，DiFaR 能提高高达 5.9% 的检测性能，同时还能将现有检测器的性能提升高达 8.7%。自动评估指标和人类评估均证实，DiFaR 能够显著提高解释的质量在所有三个维度上。"}
{"llm_update_time": "20250815", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.10311", "html_url": "https://arxiv.org/abs/2508.10311", "title": "从表层到语义：表为中心的文档分析的语义结构解析", "title_en": "From Surface to Semantics: Semantic Structure Parsing for Table-Centric Document Analysis", "authors": "Xuan Li,Jialiang Dong,Raymond Wong", "background": "文档是信息和知识的核心载体，在金融、医疗和科学研究等领域有着广泛应用。表格是结构化数据的主要载体，包含关键信息，是文档中最重要的组成部分之一。现有研究主要集中在表面任务，如布局分析、表格检测和数据提取，缺乏对表格及其上下文关联的深层语义解析。这限制了诸如跨段落数据解释和上下文一致分析等高级任务的实现。", "innovation": "提出了以表格为中心的语义文档解析框架DOTABLER，旨在揭示表格与其上下文之间的深层语义关联。该框架利用自定义数据集和领域特定的预训练模型微调，集成了一个完整的解析管道，可以识别与表格语义相关的上下文片段。基于这种语义理解，DOTABLER 实现了两种核心功能：以表格为中心的文档结构解析和领域特定的表格检索，提供全面的表格锚定语义分析和语义相关表格的精确提取。在近4,000页包含超过1,000张表格的真实PDF文档上进行评估，DOTABLER 达到了超过90%的精确度和F1分数，展示了在表格上下文语义分析和深入文档解析方面的优越性能，超越了如GPT-4o等先进模型。", "conclusion": "DOTABLER 通过利用自定义数据集和领域特定的预训练模型微调，实现了表格及其上下文的语义解析，提供了一种全面且精确的方法来解析和提取语义相关的表格。其在真实文档中的优异表现证明了其在复杂文档处理中的潜力。"}
{"llm_update_time": "20250815", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.10795", "html_url": "https://arxiv.org/abs/2508.10795", "title": "超越‘不够新颖’: 使用LLM辅助反馈丰富学术评语", "title_en": "Beyond \"Not Novel Enough\": Enriching Scholarly Critique with LLM-Assisted Feedback", "authors": "Osama Mohammed Afzal,Preslav Nakov,Tom Hope,Iryna Gurevych", "background": "同行评阅中的新颖性评估是一项关键但研究不足的任务，尤其是在如自然语言处理(NLP)这样评审量大的领域，评审员的能力越来越紧张。这项研究提出了一种结构化的自动化新颖性评估方法，通过提取内容、检索相关工作和结构化比较三个阶段，模拟专家评审员的行为。", "innovation": "该方法基于大规模的人类撰写的新颖性评审分析，捕捉了独立主张验证和情境推理等关键模式。通过评估182篇ICLR 2025投稿并与人类评审结果进行对比，该方法在准确性和结论一致性方面均显著优于现有的基于LLM的基线模型。此外，这种方法生成了详细且文献意识强的分析，提高了评审结果的一致性。", "conclusion": "这些结果突显了结构化的LLM辅助方法在支持更严谨和透明的同行评审方面的潜力，同时不会取代人类的专业知识。数据和代码已经公开提供。"}
{"llm_update_time": "20250815", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.10839", "html_url": "https://arxiv.org/abs/2508.10839", "title": "强化语言模型在序列决策中的应用", "title_en": "Reinforced Language Models for Sequential Decision Making", "authors": "Jim Dilkes,Vahid Yazdanpanah,Sebastian Stein", "background": "大型语言模型（LLMs）在序列决策代理方面展示出潜力，但由于对大规模、计算密集型模型的依赖，其应用受到限制。现有的后训练方法仅适用于单轮交互，无法处理多步骤的代理任务的奖惩分配。", "innovation": "引入了Multi-Step Group-Relative Policy Optimization（MS-GRPO）算法，这是一种基于形式化的文本中介随机博弈（TSMG）和语言代理策略（LAP）框架的新算法。为了奖惩分配，MS-GRPO将整个累计回合奖励分配给每个单独的回合步骤。同时，补充了新型的绝对优势加权回合采样策略，其训练性能得到了改善。通过在Snake和Frozen Lake任务上对一个30亿参数模型进行后训练，证明了该方法的有效性。", "conclusion": "研究表明，目标导向的后训练是利用大规模语言模型创建序列决策代理的可行和高效替代方案。经后训练的30亿参数模型在Frozen Lake任务上比720亿参数的基线模型性能提高了50%。"}
{"llm_update_time": "20250815", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.10736", "html_url": "https://arxiv.org/abs/2508.10736", "title": "Mask内的思考：扩散大语言模型中的原位提示", "title_en": "Thinking Inside the Mask: In-Place Prompting in Diffusion LLMs", "authors": "Xiangqi Jin,Yuxuan Wang,Yifeng Gao,Zichen Wen,Biqing Qi,Dongrui Liu,Linfeng Zhang", "background": "尽管大型语言模型（LLMs）已经取得了显著的成功，但它们的前缀提示方式和顺序生成过程在双向信息处理方面提供了有限的灵活性。扩散大型语言模型（dLLMs）通过它们的双向注意力机制和迭代精炼过程呈现了新的机会，使得更灵活的在位提示策略成为可能。", "innovation": "我们提出了ICE（In-Place Chain-of-Thought Prompting with Early Exit），这是一种新的框架，将前缀提示转变为专为dLLMs设计的在位提示。ICE直接将提示集成到迭代精炼过程中的掩码标记位置，并使用一种基于置信度的早期退出机制，显著减少了计算开销。", "conclusion": "广泛的实验表明，ICE在有效性上是有效的，GS8K的准确率提高了17.29%，速度提高了4.12倍，并在MMLU上的加速达到了276.67倍，同时保持了竞争力。"}
{"llm_update_time": "20250815", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.10695", "html_url": "https://arxiv.org/abs/2508.10695", "title": "从自然语言反馈学习以实现个性化的问答", "title_en": "Learning from Natural Language Feedback for Personalized Question Answering", "authors": "Alireza Salemi,Hamed Zamani", "background": "个性化对于增强语言技术的有效性和用户满意度至关重要，尤其是在信息搜索任务如问答任务中。当前针对大型语言模型的个性化方法通常依赖于检索增强生成（RAG），并通过标量奖励信号进行强化学习以便让模型学会使用检索到的个人信息。然而，这些标量奖励有时提供的反馈较弱且不具指导性，这限制了学习效率和个性化质量。因此，本文提出了一种名为VAC的新框架，通过自然语言反馈（NLF），用户个人资料和问题叙述进行生成作为监督信号，以替代标量奖励，为策略模型提供丰富的可操作指导，使其可以迭代优化输出并内化有效的个性化策略。", "innovation": "本文提出了VAC（Natural Language Feedback for Personalized Response Generation）框架，该框架使用自然语言反馈（NLF）替代标量奖励信号，用于个人化的响应生成。NLF基于用户个人资料和问题叙述进行生成，作为丰富的监督信号，使策略模型能够迭代优化输出并内化有效的个性化策略。训练过程交替优化反馈模型和微调策略模型，从而获得无需在推理过程中提供反馈的策略模型。在LaMP-QA基准上的评估结果表明，该方法在三个不同领域都取得了一致且显著的性能提升，并且进一步的人类评估证实了生成响应的质量优越性。这些结果表明，自然语言反馈能够为优化个性化问答提供更有效的信号。", "conclusion": "本文通过提出的VAC框架展示了自然语言反馈对于加强个性化问答的有效性。通过基于用户个人资料和问题叙述生成丰富和可操作的监督信号，策略模型能够在推理过程中不再需要外部反馈，从而提高了个性化问答的质量和效率。"}
{"llm_update_time": "20250815", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.10687", "html_url": "https://arxiv.org/abs/2508.10687", "title": "持续的孟加拉手语翻译：在手语注释的帮助下减轻注释负担", "title_en": "Continuous Bangla Sign Language Translation: Mitigating the Expense of Gloss Annotation with the Assistance of Graph", "authors": "Safaeid Hossain Arib,Rabeya Akter,Sejuti Rahman", "background": "全世界有数百万人遭受着听力损失和听力障碍的影响。手语作为一种复杂而高效的沟通方式，对聋人和听力障碍者至关重要。然而，在重视口语的社会中，手语常常被低估，导致沟通障碍和社交排斥。为此，Continuous Bangla Sign Language Translation项目旨在通过改进翻译方法来解决这一问题。尽管最近的方法利用了变压器架构以获得最先进的成果，但我们的方法将图基的方法与变压器架构相结合。这种结合，即变压器与STGCN-LSTM架构的融合，证明了在免词型翻译中的有效性。", "innovation": "我们的贡献包括架构融合，探索各种融合策略，并在多种手语数据集上实现了最先进的性能，具体包括RWTH-PHOENIX-2014T、CSL-Daily、How2Sign和BornilDB v1.0。与当前的翻译结果相比，我们的方法在所有数据集上都显示出了卓越的性能，BLEU-4分数显著提高，尤其是超过GASLT、GASLT和slt_how2sign在不同数据集上的结果。此外，我们首次在BornilDB v1.0数据集上进行基准测试，为未来的研究设立了新的基准，突出了免词型翻译对于提高聋人和听力障碍者的沟通可访问性的关键性。", "conclusion": "我们的方法不仅在不同手语数据集上展示了更好的性能，还为未来的相关研究设立了新的基准，强调了免词型翻译的重要性，以提高聋人和听力障碍者的沟通无障碍。"}
{"llm_update_time": "20250815", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.10848", "html_url": "https://arxiv.org/abs/2508.10848", "title": "Psyche-R1：通过统一的同理心、专业知识和推理走向可靠的心理健康大语言模型", "title_en": "Psyche-R1: Towards Reliable Psychological LLMs through Unified Empathy, Expertise, and Reasoning", "authors": "Chongyuan Dai,Jinpeng Hu,Hongchang Shi,Zhuo Li,Xun Yang,Meng Wang", "background": "在合格的心理健康专业人员短缺的情况下，将大型语言模型（LLMs）整合到心理健康应用中为缓解心理健康障碍的增长负担提供了前景。尽管最近增强推理能力的LLMs在数学和编程方面取得了显著成果，但心理领域的研究主要集中在提供情感支持和同理对话上，较少关注有助于生成可靠回复的推理机制。因此，本文提出了Psyche-R1，这是第一个结合同理心、心理专业知识和推理的中国心理LLM，基于一种新的数据收集管道构建。", "innovation": "本文设计了一种全面的数据合成管道，生成超过75000个高质量的心理学问题配以详细的推理和73000个富有同理心的对话，通过链式推理(CoT)和多次提示-推理优化实现。此外，采用混合训练策略，其中挑战性样本通过多LLM交叉选择策略进行多LLM相对策略优化(GRPO)以提高推理能力，剩余数据用于监督微调(SFT)以增强情感回应生成和心理学领域知识。实验结果表明，Psyche-R1在多个心理基准上表现有效，7B参数的Psyche-R1与671B参数的DeepSeek-R1取得相当的结果。", "conclusion": "本文提出了基于统一的心理同理心、专业知识和推理的心理健康LLM Psyche-R1，通过创新的数据合成策略和混合训练策略，证实了该模型在多个心理健康基准上的有效性和可靠性。"}
{"llm_update_time": "20250815", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.10874", "html_url": "https://arxiv.org/abs/2508.10874", "title": "SSRL: 自身搜索强化学习", "title_en": "SSRL: Self-Search Reinforcement Learning", "authors": "Yuchen Fan,Kaiyan Zhang,Heng Zhou,Yuxin Zuo,Yanxu Chen,Yu Fu,Xinwei Long,Xuekai Zhu,Che Jiang,Yuchen Zhang,Li Kang,Gang Chen,Cheng Huang,Zhizhou He,Bingning Wang,Lei Bai,Ning Ding,Bowen Zhou", "background": "研究了大型语言模型（LLMs）在强化学习（RL）中的潜在应用，特别是作为代理搜索任务的高效模拟器，以减少对外部搜索引擎的依赖。", "innovation": "引入了Self-Search RL（SSRL）方法，通过格式基础和规则基础的奖励增强LLMs的Self-Search能力，使模型能够迭代精炼其知识利用，而不需访问外部工具。实验结果表明，SSRL训练的策略模型在搜索驱动的RL训练中具有成本效益和稳定性。", "conclusion": "1) LLMs具有有效提取的世界知识可以在高性能检索中发挥作用；2) SSRL展示了利用内部知识减少幻想的潜力；3) SSRL训练的模型能够无缝集成到外部搜索引擎中，无需额外的努力。研究结果突显了LLMs在支持更具扩展性的RL代理训练方面的潜力。"}
{"llm_update_time": "20250815", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.10875", "html_url": "https://arxiv.org/abs/2508.10875", "title": "Diffusion Language Models调研", "title_en": "A Survey on Diffusion Language Models", "authors": "Tianyi Li,Mingda Chen,Bowei Guo,Zhiqiang Shen", "background": "扩散语言模型(DLMs)正在快速发展，成为一种强大的替代自回归(AR)范式的替代方法。DLMs通过迭代去噪过程并发生成标记，这使得它们在减少推理延迟和捕获双向上下文方面具有天然优势。这些特点让DLMs能够对生成过程进行精细控制。虽然可以实现几倍的速度提升，但近年来的进步使得DLMs在性能上可以与自回归模型相媲美，使之成为各种自然语言处理任务的一个有吸引力的选择。", "innovation": "本文综述了DLM的现状，追溯了其演变及其与其他范式的关系，涵盖了从基础原理到最先进的模型。特别指出的是，本文还详细讨论了DLM的推理策略和优化措施，包括解码并行性、缓存机制和生成质量的改进。此外，还介绍了DLM的跨模态扩展及其在不同实际场景中的应用。文章同时指出了DLM的局限性和挑战，包括效率问题、长序列处理和基础设施需求，并提出了未来的研究方向。", "conclusion": "本文提供了目前DLM的全面分类和深入分析，涵盖了从预训练策略到高级后处理方法的当前技术。另外，还详细审查了DLM的推理策略和优化方法，包括解码并行性、缓存机制和生成质量改进。与此同时，还探讨了DLM的一些最新跨模态扩展方法，并概述了它们在各种实际场景中的应用范围。本文提到了DLM的局限性，指出了未来研究的方向，以维持这一快速发展的领域的进展。"}
{"llm_update_time": "20250815", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.09636", "html_url": "https://arxiv.org/abs/2508.09636", "title": "个性化产品搜索排序：具有表结构和非表结构数据的多任务学习方法", "title_en": "Personalized Product Search Ranking: A Multi-Task Learning Approach with Tabular and Non-Tabular Data", "authors": "Lalitesh Morishetti,Abhay Kumar,Jonathan Scott,Kaushiki Nag,Gunjan Sharma,Shanu Vashishtha,Rahul Sridhar,Rohit Chatter,Kannan Achan", "background": "本文介绍了一种新颖的模型架构，用于通过多任务学习（MTL）框架优化个性化的商品搜索排名。本文的方法独特地整合了表结构和非表结构数据，利用预训练的TinyBERT模型进行语义嵌入，并提出了一种新颖的采样技术，以捕捉多样化的客户行为。", "innovation": "本文提出了一种可扩展的相关性标签机制，基于点击率、点击位置和语义相似度。此外，本文还采用了一种新颖的方法，集成非表结构数据与高级嵌入技术，提高模型性能，并在多任务学习范式中纳入相关性标签、微调TinyBERT层和TinyBERT查询-产品嵌入交互，进一步优化个性化排名。", "conclusion": "实验结果表明，将非表结构数据与先进的嵌入技术结合在多任务学习范式中，显著提高了模型性能。消融研究进一步证实了整合相关性标签、微调TinyBERT层和TinyBERT查询-产品嵌入交互的优势，证明了该方法在实现改进的个性化产品搜索排名方面的有效性。"}
{"llm_update_time": "20250815", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.10057", "html_url": "https://arxiv.org/abs/2508.10057", "title": "大型语言模型在抽象推理中表现出与人类神经认知的对齐迹象", "title_en": "Large Language Models Show Signs of Alignment with Human Neurocognition During Abstract Reasoning", "authors": "Christopher Pinier,Sonia Acuña Vargas,Mariia Steeghs-Turchina,Dora Matzke,Claire E. Stevenson,Michael D. Nunez", "background": "这项研究探讨了大型语言模型（LLMs）在进行抽象推理时是否表现出类似于人类神经认知的方式。研究者通过比较人类参与者与八个开源LLM在抽象模式完成任务中的表现和神经表征，使用电生理记录（EEG）中的固定相关电位（FRPs）进行分析。", "innovation": "研究发现只有参数量最大的LLM（约700亿参数）能达到接近人类的表现水平，还有Qwen-2.5-72B和DeepSeek-R1-70B也显示出与人类特定抽象模式难度轮廓相似的特征。此外，所有被测试的LLM在中间层形成了明确聚类抽象模式类别的表征，且这种聚类的理解程度与其在任务上的表现成正比。研究还发现了任务最优LLM层的表征几何与人类前额叶FRPs之间的中度正相关关系，这表明存在潜在的抽象模式共享表征空间。该结果进一步表明，LLM可能模仿人类在抽象推理中的脑机制，提供了生物智能和人工智能之间共享原则的初步证据。", "conclusion": "这些发现指示LLM可能在抽象推理中反映出与人类大脑机制的对齐，这提供了一种初步的证据证明生物学与人工智能之间存在共享的原则。"}
{"llm_update_time": "20250815", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.10068", "html_url": "https://arxiv.org/abs/2508.10068", "title": "SaraCoder: 采用语义和结构提示实现利益导向的仓库级代码补全", "title_en": "SaraCoder: Orchestrating Semantic and Structural Cues for Profit-Oriented Repository-Level Code Completion", "authors": "Xiaohan Chen,Zhongying Pan,Quan Feng,Yu Tian,Shuqun Yang,Mengru Wang,Lina Gong,Yuxia Geng,Piji Li,Xiang Chen", "background": "现有的基于检索增强生成（RAG）的仓库级代码补全方法主要依赖于表面的文本相似性，导致结果出现语义错误指导、冗余和同质性问题，同时也无法解决外部符号的模糊性。", "innovation": "提出了Saracoder，这是一种层级特征优化检索框架，其核心层级特征优化模块通过提炼深层次的语义关系，消除精确重复，利用基于图的新颖度量标准评估结构相似性（该度量标准按拓扑重要性加权编辑）并对结果重新排名以最大化相关性和多样性。同时，外部感知标识符去模糊模块通过依赖分析准确解决跨文件符号的模糊性。", "conclusion": "在具有挑战性的CrossCodeEval和RepoEval-Updated基准上的广泛实验表明，Saracoder在多个编程语言和模型中显著优于现有基线。我们的工作证明了在多个维度系统地优化检索结果可以为构建更加准确和可靠的仓库级代码补全系统提供一种新范式。"}
{"llm_update_time": "20250815", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.10239", "html_url": "https://arxiv.org/abs/2508.10239", "title": "在线会议中的个性化实时词汇支持", "title_en": "Personalized Real-time Jargon Support for Online Meetings", "authors": "Yifan Song,Wing Yee Au,Hon Yung Wong,Brian P. Bailey,Tal August", "background": "跨学科沟通常因领域特定的专业术语而受阻碍。研究者们开展了一项定形日记研究，发现当前工作场所会议中的专业术语管理策略存在显著局限性。基于这些发现，他们设计了ParseJargon系统，这是一种基于LLM的交互式系统，能够提供实时、个性化专业术语识别与解释。", "innovation": "设计理念为设计个性化实时专业术语支持工具，通过利用交互式LLM提供个性化专业术语识别和解释，以改善工作者的理解、参与度和同事工作被欣赏的程度。", "conclusion": "通过对比实验和实地研究，作者验证了个性化支持的有效性，并指出了其实用价值及其在真实会议中部署的机会与挑战。研究结果为设计此类工具提供了见解，并对跨学科和教育领域的更广泛应用具有影响。"}
{"llm_update_time": "20250815", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.10031", "html_url": "https://arxiv.org/abs/2508.10031", "title": "Context误引导LLMs：Context过滤在维持LLMs安全对齐中的作用", "title_en": "Context Misleads LLMs: The Role of Context Filtering in Maintaining Safe Alignment of LLMs", "authors": "Jinhwa Kim,Ian G. Harris", "background": "尽管大型语言模型（LLMs）在性能上取得了显著进步，但各种破解攻击却引发了越来越大的安全和伦理风险。恶意用户通常利用敌对语境欺骗LLMs，促使它们生成有害查询的回答。为了应对这一挑战，研究提出了一种新的防护机制——Context Filtering模型，这是一种输入预处理方法，旨在过滤掉不值得信任和不可靠的语境，同时识别主要提示，显露隐藏的恶意意图。", "innovation": "该研究提出了一种Context Filtering模型，作为输入预处理方法，能够过滤出不值得信任和不可靠的语境，并识别出包含真实用户意图的主要提示，以揭示隐含的恶意意图。该模型在保持原始性能的同时，通过与最先进的防护机制进行比较分析，显著降低了破解攻击的成功率，证实现了最先进的安全和有用性产品结果。此外，该模型是一种即插即用的方法，可以应用于所有LLMs，既包括白盒模型也包括黑盒模型，无需对模型进行任何微调。", "conclusion": "本研究提出的Context Filtering模型有效提升了LLMs的安全性，同时保持了它们的原始性能。该模型通过较高比例降低破解攻击的成功率证明了其有效性，并且方法具有广泛应用的潜力，可以为所有类型的LLMs增强安全性。"}
{"llm_update_time": "20250815", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.10123", "html_url": "https://arxiv.org/abs/2508.10123", "title": "Nested-ReFT: 通过离策略卷绕提高大型语言模型微调效率的强化学习方法", "title_en": "Nested-ReFT: Efficient Reinforcement Learning for Large Language Model Fine-Tuning via Off-Policy Rollouts", "authors": "Maxime Heuillet,Yufei Cui,Boxing Chen,Audrey Durand,Prasanna Parthasarathi", "background": "在解决数学推理等具有挑战性的领域中的高级推理时，LLMs可以通过基于可验证奖励的强化微调（ReFT）方法来应对。标准的ReFT框架中，行为模型会为每个问题生成多个完成体，然后由奖励函数对其评分。虽然这种方法在许多具有挑战性的推理领域中显示出显著的性能提升，但由于训练过程中生成完成体时需要进行多步推理，计算成本变得不切实际。", "innovation": "本文借鉴了离策略RL和投机解码，提出了一个名为Nested-ReFT的新型ReFT框架。在该框架中，目标模型的一部分层作为行为模型，在训练过程中生成离策略完成体。配置动态层跳过机制，减少了训练的成本。理论分析表明，Nested-ReFT能提供无偏的梯度估计，并能控制方差。实验分析表明，该方法在多个数学推理基准测试和不同规模的模型上都提高了计算效率（按每秒处理的词数计）。此外，研究了三种减缓梯度更新中的偏差的方法，以进一步减少离策略性。", "conclusion": "Nested-ReFT为大型语言模型的微调提供了更高效的强化学习方法，即使在处理具有挑战性的推理任务时也是如此。这种方法减少了计算成本，同时有效优化了性能，确保了与标准ReFT方法相当的基准性能。"}
{"llm_update_time": "20250815", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.10553", "html_url": "https://arxiv.org/abs/2508.10553", "title": "eDIF：用于远程解释大规模语言模型的欧洲深度推理织网", "title_en": "eDIF: A European Deep Inference Fabric for Remote Interpretability of LLM", "authors": "Irma Heithoff. Marc Guggenberger,Sandra Kalogiannis,Susanne Mayer,Fabian Maag,Sigurd Schacht,Carsten Lanquillon", "background": "为了使大规模语言模型（LLM）解释基础设施在欧洲得到广泛应用，本研究旨在通过部署一个欧洲深推理织网（eDIF）来推动这种基础设施的普及。eDIF是一个兼容NDIF的基础设施，旨在支持对LLM进行机制性解释的研究。发起这一项目是为了将先进的模型分析能力普及到研究社区，从而实现更广泛的使用。该项目在安贝格应用科学大学建立了基于GPU的集群，并与合作伙伴机构互联，通过NNsight API提供远程模型检查功能。这项研究旨在评估该平台的技术性能、易用性和科学用途。", "innovation": "本研究创新点在于提出了一个部署在欧洲的应用于大规模语言模型远程解释的基础设施eDIF，该基础设施兼容NDIF，通过利用GPU集群支持远程模型检查，并通过NNsight API实现。研究过程中，16名来自欧洲的研究人员进行了干预研究，包括激活补丁、因果追踪和表示分析。研究表明，该平台的用户逐渐增多，性能稳定，得到的研究人员积极反馈。这项研究还标志着以平台为中心构建用户社区的重要起点。", "conclusion": "这项研究标志着欧洲大规模语言模型解释基础设施广泛普及的重要一步，为未来的更广泛应用、扩展工具和技术以及持续的研究社区合作奠定了基础。未来的发展路线图中列出了两个改进点：下载激活数据的时间过长和执行中断问题。这些问题在未来的开发计划中将得到解决。"}
{"llm_update_time": "20250815", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.10356", "html_url": "https://arxiv.org/abs/2508.10356", "title": "提高多种语言古文字OCR", "title_en": "Improving OCR for Historical Texts of Multiple Languages", "authors": "Hylke Westerdijk,Ben Blankenborg,Khondoker Ittehadul Islam", "background": "本文探讨了使用先进深度学习技术在光学字符识别（OCR）和文档布局分析中的方法和发现。主要内容涵盖了三个任务：历史希伯来文碎片、16至18世纪会议决议以及现代英语手写识别。", "innovation": "通过数据增强，使用Kraken和TrOCR模型提升了字符识别；利用CRNN结合DeepLabV3+进行语义分割以及双向LSTM，初始模型通过基于信心的伪标签进行优化；采用CRNN与ResNet34编码器，使用连接主义时序分类（CTC）损失函数来捕捉序列依赖性。", "conclusion": "本文提供了有价值的研究见解，并建议了未来研究的方向，包括多种语言历史文本的OCR改进。"}
{"llm_update_time": "20250815", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.10416", "html_url": "https://arxiv.org/abs/2508.10416", "title": "CorrectNav: 自校正飞轮赋能视觉-语言-动作导航模型", "title_en": "CorrectNav: Self-Correction Flywheel Empowers Vision-Language-Action Navigation Model", "authors": "Zhuoyuan Yu,Yuxing Long,Zihan Yang,Chengyan Zeng,Hongwei Fan,Jiyao Zhang,Hao Dong", "background": "现有的视觉-语言导航模型在执行指令时会偏离正确的轨迹，但这些模型缺乏有效的错误校正能力，阻碍了从错误中恢复的进程。", "innovation": "本文提出了自校正飞轮（Self-correction Flywheel），一种新的后训练范式。该范式将模型在训练集上的错误轨迹视为有价值的资源，开发了一种方法来识别这些错误轨迹中的偏差，并设计了生成自校正数据的创新技术，以供感知和行动使用。通过多次飞轮迭代，逐步增强了单目RGB基于的VLA导航模型CorrectNav。结果显示，CorrectNav在R2R-CE和RxR-CE基准上的成功率分别达到了65.1%和69.3%，超过了之前的最好模型8.2%和16.4%。实验证实在多种室内外环境中的机器人上，CorrectNav展示了其优越的错误校正、动态障碍物避免和长时间指令跟随能力。", "conclusion": "通过多次飞轮迭代，自校正飞轮逐步提升了单目RGB基于的VLA导航模型CorrectNav，并在R2R-CE和RxR-CE基准上取得了新的最好结果，表明该方法在视觉-语言-动作导航中的有效性。"}
{"llm_update_time": "20250815", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.10824", "html_url": "https://arxiv.org/abs/2508.10824", "title": "增强记忆的Transformer：从神经科学原则到技术解决方案的系统综述", "title_en": "Memory-Augmented Transformers: A Systematic Review from Neuroscience Principles to Technical Solutions", "authors": "Parsa Omidi,Xingshuai Huang,Axel Laborieux,Bahareh Nikpour,Tianyu Shi,Armaghan Eshaghi", "background": "记忆对智力至关重要，支持生物和人工系统的学习、推理和适应。尽管Transformer架构在序列建模方面表现出色，但它们在长距上下文记忆保留、持续学习和知识整合方面存在关键限制。本文综述了一个整合神经科学原理（如动态多时序记忆、选择性注意和巩固）与增强Transformer工程技术进展的统一框架。", "innovation": "本文通过功能目标、记忆表示和集成机制三个分类维度梳理了近期进展，并分析了核心记忆操作（读取、写入、忘却和容量管理），指出从静态缓存向适应性、测试时学习系统的转变。同时，识别了可扩展性和干扰的持续挑战，并提出了分层缓冲和惊喜门控更新等新兴解决方案。", "conclusion": "本文提供了一条认知启发的、终身学习的Transformer架构发展路线图，推动了记忆增强Transformer技术的进步。"}
{"llm_update_time": "20250815", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.10548", "html_url": "https://arxiv.org/abs/2508.10548", "title": "使用门控奖励稳定长期多轮强化学习", "title_en": "Stabilizing Long-term Multi-turn Reinforcement Learning with Gated Rewards", "authors": "Zetian Sun,Dongfang Li,Zhuoen Chen,Yuhuai Qin,Baotian Hu", "background": "在跨多轮次的强化学习任务中，如何有效地设计奖励函数仍然是一个挑战。现有基于结果的奖励塑造方法难以定义有实际意义的即时奖励，也不避免奖励偏置或需要显式任务分解。相比之下，基于验证的奖励塑造使用逐步评判者，但即时奖励与长期目标的不一致可能导致奖励劫持和次优策略。本文研究了软件工程任务中多轮推理和规则验证的重要性，旨在解决长期目标与即时奖励不匹配的问题。", "innovation": "提出了一种新的奖励累积方法——门控奖励累积（G-RA），它仅在高级（长期）奖励达到预定义阈值时累积即时奖励，从而确保稳定的强化学习优化。该方法在SWE-bench Verified和kBench实验中的表现显著优于传统方法，提升了解决任务的完成率和修改率，而无需因奖励偏差导致策略退化。", "conclusion": "研究发现，平衡长周期奖励的累积对于强化学习结构至关重要，并提出了一个实际的解决方案——SWE-导向的强化学习框架和支持多轮交互、Docker执行和可定制奖励函数的统一系统。"}
{"llm_update_time": "20250815", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.10539", "html_url": "https://arxiv.org/abs/2508.10539", "title": "通过低成本方差减少提高基于价值的过程验证器", "title_en": "Improving Value-based Process Verifier via Low-Cost Variance Reduction", "authors": "Zetian Sun,Dongfang Li,Baotian Hu,Min Zhang", "background": "大型语言模型（LLMs）在各种任务中取得了显著的成功，但在数学等复杂领域中的推理能力仍然存在挑战。价值基础的过程验证器通过估计部分推理链达到正确解的概率，是一种有希望的方法来提高推理能力。然而，由于LLM推理成本高，难以进行足够的蒙特卡洛（MC）抽样，导致训练注释中的估计误差，这是过程验证器效果受限的主要原因之一。", "innovation": "本文指出，估计误差主要源自高方差而非偏差，而MC估算是一个最小方差无偏估计量（MVUE）。为解决这一问题，提出了Compound Monte Carlo Sampling（ComMCS）方法，通过线性组合当前步和随后步的MC估计量构造一个无偏估计量。理论和实验证明ComMCS在不增加额外LLM推理成本的情况下能够显著降低方差，同时保持无偏估计。ComMCS在MATH-500和GSM8K基准上的实验结果显示其效果优于基于回归优化的方法2.8分，优于非方差减少的基线2.2分，在Best-of-32抽样实验中表现尤为突出。", "conclusion": "ComMCS方法通过线性组合MC估计量来构建一个无偏估计量，能够显著减少方差而无需增加额外的LLM推理成本。在MATH-500和GSM8K基准上的实验证明了ComMCS的有效性，尤其是在Best-of-32抽样实验中的表现特别出色。"}
{"llm_update_time": "20250815", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.10880", "html_url": "https://arxiv.org/abs/2508.10880", "title": "通过仿真搜索LLM代理中的隐私风险", "title_en": "Searching for Privacy Risks in LLM Agents via Simulation", "authors": "Yanzhe Zhang,Diyi Yang", "background": "LLM（大型语言模型）代理的大规模部署可能会引入严重的隐私威胁，即恶意代理主动参与多回合对话以提取敏感信息。这些动态对话使攻击策略变得更加适应性，从而导致严重的隐私泄露。然而，由于其不断演变的特性，手动预测和发现复杂的漏洞变得非常困难。", "innovation": "本文提出了一种基于搜索的框架，交替改进攻击者和防御者的指令，通过模拟隐私关键代理交互来应对这一挑战。该框架利用LLM作为优化器，结合多线程并行搜索和跨线程传播来分析仿真轨迹并迭代提出新指令。通过这一过程发现，攻击策略从简单的直接请求升级为复杂的多回合策略如身份冒充和同意伪造，而防御措施则从规则基约束进化到身份验证状态机。这些发现的攻击和防御策略在不同的场景和基础模型中具有强大的实际应用价值，用于构建隐私感知代理。", "conclusion": "所提出的搜索框架有效地识别了LLM代理中的隐私风险，通过仿真模拟了复杂多回合的攻击策略并进一步发展了有效的防御策略。这些发现为构建和部署更加安全、隐私保护的代理提供了重要参考。"}
{"llm_update_time": "20250815", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.10683", "html_url": "https://arxiv.org/abs/2508.10683", "title": "神经机器翻译用于科普特-法语：低资源古语言的翻译策略", "title_en": "Neural Machine Translation for Coptic-French: Strategies for Low-Resource Ancient Languages", "authors": "Nasma Chaoui,Richard Khoury", "background": "在此之前，对于低资源古语言的翻译策略，如科普特语到法语，缺乏系统的研究。本研究利用对齐的圣经语料库，旨在系统地评估不同翻译策略的效果。", "innovation": "本研究是首次系统性地研究科普特语到法语的翻译策略。研究涵盖了拐点翻译和直接翻译的选择、预训练的影响、多版本微调的好处以及模型对噪声的鲁棒性。研究发现，风格多样且考虑噪声的训练语料库能够显著提高翻译质量。", "conclusion": "研究结果为开发用于历史语言翻译的工具提供了至关重要的实践见解，特别是对于像科普特语这样的低资源古语言。"}
{"llm_update_time": "20250815", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.10751", "html_url": "https://arxiv.org/abs/2508.10751", "title": "Pass@k 训练以适应性平衡大型推理模型的探索和利用", "title_en": "Pass@k Training for Adaptively Balancing Exploration and Exploitation of Large Reasoning Models", "authors": "Zhipeng Chen,Xiaobo Qin,Youbin Wu,Yue Ling,Qinghao Ye,Wayne Xin Zhao,Guang Shi", "background": "强化学习中的验证奖励（RLVR）通常采用 Pass@1 作为奖励，这在平衡探索和利用方面遇到了问题，导致策略更偏向于保守的行为，并收敛于局部最优解。识别合适的奖励指标变得至关重要。虽然 Pass@k 被用于评估，但它与大型语言模型（LLM）在 RLVR 中的探索能力之间的联系并未受到足够的重视。为了调查这一点，作者首先使用 Pass@k 作为奖励来训练策略模型（即 Pass@k 训练），并观察其探索能力的提高。接着，他们推导了 Pass@k 训练的优势分析，提出了一个高效且有效的过程。在此基础上，分析发现探索和利用并不是固有的冲突目标，反而可以互相促进。Pass@k 训练结合分析推导，本质上涉及直接设计优势函数。由此，作者初步探索了 RLVR 的优势设计，显示出有前景的结果，并提出了一个潜在的未来研究方向。", "innovation": "首次使用 Pass@k 作为奖励进行策略模型训练（Pass@k 训练），并通过推导其优势分析，提出了一种高效且有效的过程。在此基础上，发现探索和利用并非完全冲突，可以互相促进，并提出直接设计优势函数的方法，用于 RLVR 的优势设计探索，显示出有前景的结果，为强化学习中的优化方法提供了新的方向。", "conclusion": "Pass@k 训练和其推导过程表明，探索和利用可以互相促进，而非冲突。直接设计优势函数的方法可以在 RLVR 中有效应用，研究显示了积极的结果，并为未来工作指明了方向。"}
{"llm_update_time": "20250815", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2407.12830", "html_url": "https://arxiv.org/abs/2407.12830", "title": "大型语言模型的知识基础一致性测试", "title_en": "Knowledge-based Consistency Testing of Large Language Models", "authors": "Sai Sathiesh Rajan,Ezekiel Soremekun,Sudipta Chattopadhyay", "background": "本文系统地揭示并度量了大型语言模型（LLMs）中的不一致性和知识空白。背景信息包括LLMs在实际应用中存在的知识不准确和知识空白的问题，目前缺乏有效的自动测试框架来检测这些问题。现有方法往往难以全面和有效地检测LLOs的知识库质量，因此需要一种新的方法来解决这一问题。", "innovation": "本文提出了一个名为KonTest的自动化测试框架，利用知识图谱构建测试案例。KonTest通过语义等价查询和测试或acles（元变或本体或acles）来探测和衡量LLMs对世界的知识不一致性。此外，通过重量化的LLMs模型集合，KonTest还缓解了知识空白问题。研究发现，KonTest能够生成19.2%的错误触发输入（9979个测试输入中有1917个错误），并且揭示了所有测试LLMs的知识差距为16.5%。基于KonTest的测试套件，提出的方法可以减少LLMs的知识差距32.48%。", "conclusion": "研究表明，KonTest是一个有效的工具，能够有效地揭示和减少大型语言模型的知识差距和不一致性问题。GPT3.5不适用于基于知识的一致性测试，因为它仅在知识构建方面有效60%-68%。"}
{"llm_update_time": "20250815", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2410.16325", "html_url": "https://arxiv.org/abs/2410.16325", "title": "这个候选人是[MASK]. 基于提示的语义提取与推荐信", "title_en": "This Candidate is [MASK]. Prompt-based Sentiment Extraction and Reference Letters", "authors": "Fabian Slonimczyk", "background": "当前经济和金融领域已有的方法用来从文本数据中提取情感和其他有用特征存在问题。研究人员提出了一种相对简单的方法，称为基于提示的情感提取，这是一种使用预训练大型语言模型进行情感分析的方法。这种方法在经济和金融领域提供了多种优势，并成功应用于手工收集的受保密限制的参考信（RLs）数据集中，展示了情感内容如何反映就业市场结果。", "innovation": "该研究提出了一种新颖的基于提示的情感提取方法，能够准确提取参考信中的情感信息，无论采用的衡量成功标准如何，候选人的平均情感评分越高，其就业市场表现越好。此外，该研究展示了不同参考信撰写者间的观点分歧对候选人就业市场表现的负面影响。该方法在比较中优于传统的关键词（bag-of-words）方法、微调语言模型和查询高级聊天机器人，证明了其独特性和有效性。进一步，该方法还被用来提取具有性别差异的情感评分，揭示了不同性别候选人在参考信中的不同评价倾向，这影响了女性候选人的就业市场结果。", "conclusion": "基于提示的情感提取方法不仅能够准确地从参考信中提取情感特征，还能揭示性别在就业市场中的不同影响。研究表明，男女候选人在参考信中的差异性刻画影响了女性求职者的市场表现。"}
{"llm_update_time": "20250815", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2502.08512", "html_url": "https://arxiv.org/abs/2502.08512", "title": "测量合成数据集的多样性", "title_en": "Measuring Diversity in Synthetic Datasets", "authors": "Yuchang Zhu,Huizhe Zhang,Bingzhe Wu,Jintang Li,Zibin Zheng,Peilin Zhao,Liang Chen,Yatao Bian", "background": "大型语言模型（LLMs）被广泛应用于生成用于各种自然语言处理（NLP）任务的合成数据集，如文本分类和摘要生成。然而，准确地测量这些合成数据集的多样性仍然是一个重要的挑战。多样性对于模型的稳健性能至关重要。传统方法难以准确评估合成数据集的多样性。因此，有必要发展一种新的方法来测量这种多样性，尤其是在分类任务中的应用。在此背景下，研究者提出了一种新的方法，即DCScore，这是一种从分类视角出发评估合成数据集多样性的方法，提供了一种成熟的多样性评估方法，理论验证了其相关性假设，并通过实验验证了其有效性和计算成本优势。", "innovation": "DCScore方法通过将多样性评估转化为样本分类任务，并利用样本之间的相互关系进行评估。该方法还提供了多样性相关公理的理论证明，验证了其作为成熟多样性评估方法的合理性。此外，实验证明DCScore与现有方法相比，具有更强的相关性，并且显著降低了计算成本。", "conclusion": "实验结果表明，DCScore方法能够提供与多个评估数据集多样性的伪真相具有更强相关性的多样性度量，证实了其有效性和优越性。同时，DCScore方法在理论上和实证上都减少了计算成本。"}
{"llm_update_time": "20250815", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2503.23714", "html_url": "https://arxiv.org/abs/2503.23714", "title": "使用开源权重大型语言模型从人工撰写的指令构建指令调优数据集", "title_en": "Building Instruction-Tuning Datasets from Human-Written Instructions with Open-Weight Large Language Models", "authors": "Youmi Ma,Sakae Mizuki,Kazuki Fujii,Taishi Nakamura,Masanari Ohi,Hinari Shimada,Taihei Shiotani,Koshiro Saito,Koki Maeda,Kakeru Hattori,Takumi Okamoto,Shigeki Ishida,Rio Yokota,Hiroya Takamura,Naoaki Okazaki", "background": "大型语言模型（LLMs）对于解决现实世界任务至关重要。前期研究显示，仅从LLMs生成的指令调优数据完全可以有效，这引发了一个根本问题：在指令调优时，我们还需要依赖人类生成的信号吗？", "innovation": "本文回答了这一问题，通过仅将人类撰写的指令与LLMs生成的响应配对构建指令调优数据集，获得了最先进的技术。基于这些数据集微调的LLMs总体上优于使用现有数据集微调的模型。研究表明，在新语言中进行指令调优可以让LLMs更好地接受指令，而调优后的模型在该语言方面表现出显著的文化背景知识缺乏。这类数据集和微调模型将公开可用，而且是基于宽松的许可协议开源分发，支持各种应用场景。", "conclusion": "通过开放权重的LLMs构建的人工撰写的指令数据集，所微调的模型不仅达到最先进的性能，而且可以方便地适应其他语言，并可用于多种应用场景。"}
{"llm_update_time": "20250815", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2503.11655", "html_url": "https://arxiv.org/abs/2503.11655", "title": "基于DeepSeek-R1的可解释情感分析：性能、效率及少量样本学习", "title_en": "Explainable Sentiment Analysis with DeepSeek-R1: Performance, Efficiency, and Few-Shot Learning", "authors": "Donghao Huang,Zhaoxia Wang", "background": "大型语言模型（LLMs）已经改变了许多自然语言处理任务，但保持高准确性、高效性和可解释性仍然是一个挑战。", "innovation": "本研究评估了开放源码推理模型DeepSeek-R1与OpenAI的GPT-4o和GPT-4o-mini对比，测试了完整的671B模型及其裁剪变体，记录了少量样本学习曲线。实验证明，DeepSeek-R1在5类情感分析中的F1得分为91.39%，在二分类任务中的准确率达到99.31%，其少量样本学习效率比GPT-4o高出八倍。在特定架构的裁剪效果中，基于32B Qwen2.5的模型在某些方面比基于70B Llama的版本表现更好，表现提升了6.69个百分点。尽管推理过程降低了吞吐量，但DeepSeek-R1提供透明的、逐步的解释，使其成为强大的、可解释的开放源码替代品。", "conclusion": "DeepSeek-R1在少量样本学习中表现出卓越的性能和效率，并且通过透明的推理过程提高了可解释性，使其成为具有强大解释能力的开放源码替代方案。"}
{"llm_update_time": "20250815", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2501.06117", "html_url": "https://arxiv.org/abs/2501.06117", "title": "Fleurs-SLU：大规模多语言口语理解基准", "title_en": "Fleurs-SLU: A Massively Multilingual Benchmark for Spoken Language Understanding", "authors": "Fabian David Schmidt,Ivan Vulić,Goran Glavaš,David Ifeoluwa Adelani", "background": "口语理解（SLU）对于缺乏正式书写体系的全球一半以上的语言至关重要。对于这些低资源语言，我们无法依赖由自动语音识别（ASR）和文本形式的大语言模型（LLMs）组成的流水线来实现语音语义理解。即使这些语言有书写系统，ASR 依然因为语音和文本训练数据有限而不可靠。现有对多语言SLU的评估主要集中在浅层任务，如意图分类或语言识别，这不足以为复杂多语言应用提供有效支持。因此，本研究提出了Fleurs-SLU，一个包含102种语言、692小时基于话题的语音分类数据以及944小时跨92种语言的听说试题数据的跨语言基准。", "innovation": "Fleurs-SLU是一个大规模多语言基准，首次包含了语音分类和听后问答数据，跨102种语言，覆盖692小时语音，944小时听后问答。该基准能够评估端到端声学分类模型、结合ASR和随后LLM进行分类的级联系统以及多模态语音-LLM模型在跨语言环境中的表现。研究表明，级联系统在跨语言环境中的鲁棒性较好，但预训练的声学编码器在基于话题的声学分类中表现出竞争性。封闭源的语音-LLM模型在性能上匹配甚至超越级联模型。研究发现，鲁棒的多语言ASR、有效的语音到文本翻译和强大的跨语言SLU之间存在密切联系，表明了声学和语义声学表示之间的相互益处的存在", "conclusion": "级联系统在多语言SLU中表现较为稳健，但预训练的声学编码器在基于话题的声学分类中表现出一定的竞争性。封闭源的语音-LLM模型能匹配甚至超越级联系统。此外，研究指出，多语言ASR、有效的语音到文本翻译和强跨语言SLU之间存在密切联系，表明了声学和语义声学表示之间的相互益处的存在。"}
{"llm_update_time": "20250815", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2504.01400", "html_url": "https://arxiv.org/abs/2504.01400", "title": "ToolACE-R: 基于模型的迭代训练和自适应精炼用于工具学习", "title_en": "ToolACE-R: Model-aware Iterative Training and Adaptive Refinement for Tool Learning", "authors": "Xingshan Zeng,Weiwen Liu,Xu Huang,Zezhong Wang,Lingzhi Wang,Liangyou Li,Yasheng Wang,Lifeng Shang,Xin Jiang,Ruiming Tang,Qun Liu", "background": "大型语言模型（LLMs）通过利用外部工具来解决复杂的用户任务，使得模型能力得到了扩展。然而，现有的方法主要集中在数据合成以进行模型微调，因此忽略了如何充分利用模型的潜力。为了更有效地利用模型能力，研究人员引入了ToolACE-R框架，该框架包含模型感知迭代训练和自适应精炼机制，以最大化模型的潜力和优化工具调用的性能。", "innovation": "ToolACE-R框架不仅包含模型感知的迭代训练过程，还通过自适应自修正机制解决了工具学习中的效率问题。模型可以基于迭代自我精炼自主决定何时停止过程。实验表明，与基于API的先进模型相比，ToolACE-R在多个基准数据集上表现出了竞争力，并且可以通过自适应自精炼进一步优化工具调用性能。", "conclusion": "结果表明ToolACE-R在工具学习上具有高效性和通用性，为更具效率和可扩展性的工具学习提供了新的研究方向。"}
{"llm_update_time": "20250815", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2505.22107", "html_url": "https://arxiv.org/abs/2505.22107", "title": "Transformer for Long-context Modeling的高维问题", "title_en": "Curse of High Dimensionality Issue in Transformer for Long-context Modeling", "authors": "Shuhai Zhang,Zeng You,Yaofo Chen,Zhiquan Wen,Qianyue Wang,Zhijie Qiu,Yuanqing Li,Mingkui Tan", "background": "基于Transformer的大型语言模型（LLMs）在自然语言处理任务中表现出色，通过自注意力机制捕捉长范围依赖关系。然而，长上下文建模会面临显著的计算低效率问题，主要是由于注意力计算的冗余性：虽然注意力权重往往是稀疏的，但所有tokens仍然消耗相同的计算资源。", "innovation": "本文重新定义了传统的概率序列建模为监督学习任务，使得相关和无关tokens得以分离，揭示了注意力稀疏性的本质，并提出了一种分组编码策略。基于此，提出了动态分组注意力（DGA），通过在注意力计算阶段聚合不重要tokens来显式减少冗余性。", "conclusion": "实验结果表明，DGA显著降低了计算成本且保持了竞争力的结果。同时，本文的方法能够提高对随机噪声的鲁棒性并提升学习效率。"}
{"llm_update_time": "20250815", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2505.17538", "html_url": "https://arxiv.org/abs/2505.17538", "title": "瑞典之音：利用海量语音语料库进行瑞典语音识别", "title_en": "Swedish Whispers; Leveraging a Massive Speech Corpus for Swedish Speech Recognition", "authors": "Leonora Vesterbacka,Faton Rekathati,Robin Kurtz,Justyna Sikora,Agnes Toftgård", "background": "小型语种常常在多语言训练数据集中代表性不足，因此通过调整现有多语言模型可以在性能上实现显著改善。在本研究中，作者利用前所未有的规模和多样性的瑞典语训练集，对一款名为Whisper的模型进行了微调，旨在提高瑞典语识别的性能。", "innovation": "本研究首次使用了大量数据集对瑞典语进行模型微调，克服了小型语种在多语言模型训练中的代表性不足问题。通过微调的Whisper模型在多项测评中均取得了显著的性能提升，特别是在错词率（WER）方面相比OpenAI的whisper-large-v3模型平均降低了47%。", "conclusion": "通过使用大规模瑞典语数据集对Whisper模型进行微调，本研究明显提升了瑞典语语音识别的性能。这表明，即使是中等资源的语言，也可以通过针对性地利用大规模特定语言的数据集来显著提高其模型的性能。这项工作为其他小型语种的研究提供了借鉴意义。"}
{"llm_update_time": "20250815", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2504.02323", "html_url": "https://arxiv.org/abs/2504.02323", "title": "CoTAL: 人工在环中的提示工程以实现可泛化的形成性评估评分", "title_en": "CoTAL: Human-in-the-Loop Prompt Engineering for Generalizable Formative Assessment Scoring", "authors": "Clayton Cohn,Ashwin T S,Naveeduddin Mohammed,Gautam Biswas", "background": "近年来，大型语言模型（LLMs）为教师和学生学习提供了新的辅助机会。尽管研究者们已经探讨了各种提示工程方法在教育环境中的应用，但这些方法在不同学科领域（如科学、计算机科学和工程等）中的应用程度仍然不明确。本文旨在通过一种基于语言模型的方法——证据中心设计（ECD）指导的形成性评估评分方法 Chain-of-Thought Prompting + Active Learning (CoTAL)，来解决这一问题。", "innovation": "介绍了一种名为 Chain-of-Thought Prompting + Active Learning (CoTAL) 的基于语言模型的方法来改进形成性评估评分。该方法结合了证据中心设计（ECD）来确保评估和评分标准与教学目标一致，采用人工在环中的提示工程（human-in-the-loop prompt engineering）来自动评分，同时利用思维链（chain-of-thought）提示技术和教师、学生的反馈来迭代改进问题、评分标准和语言模型提示。", "conclusion": "实验结果显示，CoTAL 能显著提高 GPT-4 的评分性能，相对于非提示工程基线（未使用标记样本、思维链提示或迭代优化）提升了 38.9%。教师和学生对手动评分和解释的满意程度较高，其反馈将有助于进一步提升评分准确性和解释质量。"}
{"llm_update_time": "20250815", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2506.19794", "html_url": "https://arxiv.org/abs/2506.19794", "title": "为什么开源LLMs在数据分析中遇到困难？一项系统实证研究", "title_en": "Why Do Open-Source LLMs Struggle with Data Analysis? A Systematic Empirical Study", "authors": "Yuqi Zhu,Yi Zhong,Jintian Zhang,Ziheng Zhang,Shuofei Qiao,Yujie Luo,Lun Du,Da Zheng,Ningyu Zhang,Huajun Chen", "background": "开源大型语言模型（LLMs）在自动化数据分析任务方面具有潜力，但它们在这些需要推理的任务中面临显著限制。这项研究旨在探讨如何提升开源LLMs的数据分析能力。通过精心挑选多样且现实的种子数据集，评估模型在数据理解、代码生成和战略规划三个核心维度上的行为。研究发现，战略规划质量是决定模型性能的主要因素；交互设计和任务复杂度显著影响推理能力；而数据质量比多样性对实现最佳性能影响更大。", "innovation": "研究基于发现的观点，开发了一种数据合成方法，展示了显著提高开源LLMs的分析推理能力。该方法主要通过优化数据质量和战略规划能力，提升模型在数据分析任务中的表现。此外，研究提供了开源LLMs在数据分析中的性能特征分析，为未来相关研究提供了宝贵的经验和见解。开源代码可在提供的链接处获取。", "conclusion": "研究揭示了战略规划质量是决定模型性能的主要因素，交互设计和任务复杂度显著影响推理能力，而数据质量比多样性对实现最佳性能影响更大。基于这些发现，研究提出了数据合成方法，显著提升了开源LLMs的分析推理能力。"}
{"llm_update_time": "20250815", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.10108", "html_url": "https://arxiv.org/abs/2508.10108", "title": "Amazon Nova AI Challenge -- Trusted AI: 进一步推进安全的AI辅助软件开发", "title_en": "Amazon Nova AI Challenge -- Trusted AI: Advancing secure, AI-assisted software development", "authors": "Sattvik Sahai,Prasoon Goyal,Michael Johnston,Anna Gottardi,Yao Lu,Lucy Hu,Luke Dai,Shaohua Liu,Samyuth Sagi,Hangjie Shi,Desheng Zhang,Lavina Vaz,Leslie Ball,Maureen Murray,Rahul Gupta,Shankar Ananthakrishna", "background": "AI系统在软件开发中的应用正迅速增加，但确保其安全性仍面临重大挑战。为此，亚马逊发起了Amazon Nova AI挑战赛的Trusted AI赛道，这是一个全球性的竞赛，旨在推动安全AI的发展，吸引了来自10所大学的团队参赛。", "innovation": "竞赛中，五支团队致力于开发自动化红队机器人，而另外五支团队创建了安全的AI助手。竞赛提供的平台促进了自动化红队和安全性对齐方法的头部对抗比赛，其中红队多次与竞争对手的AI编程助手进行对话，以测试其安全性对齐。此外，竞赛还提供了高质量的标注数据流，以支持迭代改进。各团队研发了前沿技术，包括基于推理的安全对齐、鲁棒模型护栏、多轮“越狱”以及对大型语言模型（LLMs）的高效探测。亚马逊还为此次挑战投入了大量科学和技术资源，包括研发定制化的挑战基线编程专家模型，开发了比赛组织服务，并创建了评估框架。", "conclusion": "本次论文概述了来自大学团队和Amazon Nova AI挑战赛团队在AI软件开发安全性方面的进步，强调了为了提升AI安全性所进行的协作与努力。"}
{"llm_update_time": "20250815", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.02038", "html_url": "https://arxiv.org/abs/2508.02038", "title": "Marco-Voice 技术报告", "title_en": "Marco-Voice Technical Report", "authors": "Fengping Tian,Chenyang Lyu,Xuanfan Ni,Haoqin Sun,Qingjuan Li,Zhiqiang Qian,Haijun Li,Longyue Wang,Zhao Xu,Weihua Luo,Kaifu Zhang", "background": "本文介绍了一个多功能语音合成系统，该系统将语音克隆和情感控制语音合成统一在一个框架中。本文的目标是解决在各种语言和情感背景下忠实保留说话者身份的同时实现高度表达、可控和自然语音生成的长期挑战。通过构建CSEMOTIONS数据集，在6位专业说者的十小时普通话录音中包含七个情感类别，展示了该方法的有效性。", "innovation": "本文提出了一种有效的说话者-情感解纠缠机制，结合批次对比学习，实现说话者身份和情感风格的独立操纵，并采用旋转情感嵌入整合方法实现平滑的情感控制。Marco-Voice系统通过客观和主观指标体现了实质性改进，展示了在表达性神经语音合成领域的先进性。", "conclusion": "通过综合评估和分析，结果表明MarcoVoice在语音清晰度和情感丰富性方面性能强大，在表达性神经语音合成领域取得重大突破。该代码和数据集在publicly可用的链接处提供。"}
{"llm_update_time": "20250815", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2507.01213", "html_url": "https://arxiv.org/abs/2507.01213", "title": "AF-MAT: Aspect-aware Flip-and-Fuse xLSTM for Aspect-based Sentiment Analysis", "title_en": "AF-MAT: Aspect-aware Flip-and-Fuse xLSTM for Aspect-based Sentiment Analysis", "authors": "Adamu Lawan,Juhua Pu,Haruna Yunusa,Muhammad Lawan,Mahmoud Basi,Muhammad Adam", "background": "ABSAs是一种重要的NLP任务，旨在从文本中提取关于具体方面的细粒度意见和情感，如产品评论和客户反馈。现有的方法往往在效率与性能之间做出权衡：传统的LSTM或RNN模型难以捕捉长距离依赖，基于transformer的方法计算成本高，而基于Mamba的方法依赖于CUDA且降低了局部依赖性建模。最近提出的扩展长短时记忆模型(xLSTM)通过指数门控和增强的记忆版本、局部依赖性的sLSTM，以及可扩展并行化的mLSTM，提供了捕捉长距离依赖性的有效途径。然而，xLSTM在ABSAs中的应用尚未被研究。", "innovation": "本文介绍了一种创新框架AF-MAT（Aspect-aware Flip-and-Fuse xLSTM），利用了xLSTM的优势。AF-MAT包含了一个aspect-aware矩阵LSTM (AA-mLSTM)机制，引入了专门的目的方面门控，使模型能够选择性地强调与目标方面语义相关的标记。为了建模多尺度上下文，该框架引入了一个FlipMix块，该块通过部分翻转的Conv1D（pf-Conv1D）和完全翻转的mLSTM（ff-mLSTM）序列应用，依次捕获短距离依赖并构建长距离依赖。此外，该文还提出了一种基于mLSTM门控的轻量级多头交叉特征融合方法MC2F，该方法动态结合了AA-mLSTM输出和FlipMix输出，实现自适应表示融合。", "conclusion": "在三个基准数据集上的实验表明，AF-MAT超越了最先进的基线方法，在ABSAs任务中获得了更高的准确率。"}
{"llm_update_time": "20250815", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2507.14189", "html_url": "https://arxiv.org/abs/2507.14189", "title": "DeepWriter: 基于离线知识库的可靠多模态写作助手", "title_en": "DeepWriter: A Fact-Grounded Multimodal Writing Assistant Based On Offline Knowledge Base", "authors": "Song Mao,Lejun Cheng,Pinlong Cai,Guohang Yan,Ding Wang,Botian Shi", "background": "大型语言模型（LLMs）在各种应用中表现出显著的能力，但它们在金融、医学和法律等专业化领域的写作辅助中，受限于缺乏深厚的专业领域知识和虚构倾向。现有的解决方案，如检索增强生成（RAG），在多步骤检索中可能会出现不一致性问题，而基于在线搜索的方法由于不可靠的网络内容质量下降。为解决这些问题，本研究引入了DeepWriter，这是一种可定制的、多模态的、长篇文章写作助手，基于精心构建的离线知识库工作。", "innovation": "DeepWriter 采用了一种新颖的基于任务分解、大纲生成、多模态检索和节段级组合与反思的管道。通过深度挖掘结构化语料库中的信息，结合文本和视觉元素，DeepWriter 生成了连贯、事实准确且具有专业水平的文档。此外，提出了层次化知识表示以提升检索效率和准确性。实验结果显示，DeepWriter 在财务报告生成中产出高质量、可验证的文章，其事实准确性及生成内容质量优于现有基线。", "conclusion": "我们的实验证明，基于离线知识库的 DeepWriter 在事实准确性及生成文档质量方面超越了现有基线，是一种可靠的多模态写作助手。"}
{"llm_update_time": "20250815", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2507.10535", "html_url": "https://arxiv.org/abs/2507.10535", "title": "CodeJudgeBench：评价代码任务中LLM法官的基准测试", "title_en": "CodeJudgeBench: Benchmarking LLM-as-a-Judge for Coding Tasks", "authors": "Hongchao Jiang,Yiming Chen,Yushi Cao,Hung-yi Lee,Robby T. Tan", "background": "大规模语言模型（LLMs）在各种编码任务中取得了显著进展。除了直接回答用户查询外，这些模型还可以担任法官的角色，评估和比较其他模型生成回答的质量。这种评估能力对于不同LLM的基准测试以及通过响应排名提高响应质量至关重要。尽管LLM-as-a-Judge的范式正在被越来越多地采用，但其在编程场景中的有效性仍然没有被充分探索，原因之一是没有专门的基准测试来应对这一问题。", "innovation": "该论文引入了一个名为CodeJudgeBench的基准测试，专门用于评估LLM-as-a-Judge模型在代码生成、代码修复和单元测试生成三种关键编码任务中的性能。研究结果表明，近期的思考型模型在这类精心设计的代码评估任务中明显优于非思考型模型。即使很小的思考型模型，比如Qwen3-8B，也能超越多达70B参数的专门训练的LLM-as-a-Judge模型。然而，所有模型在判断编码任务时仍表现出显著的随机性，对于成对的判断任务，改变响应展示的顺序会对准确性产生重大影响。", "conclusion": "对于编码任务中的LLM-as-a-Judge，使用成对比较策略优于标量化点评估。同时，保留完整未经处理的LLM响应中的注释和推理有助于提高法官性能。此外，对于由不同LLM编写的代码和单元测试的评估，LLM-as-a-Judge模型的表现差异性表明，在编程场景中，其可靠性和一致性有待提高。"}
{"llm_update_time": "20250815", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.07178", "html_url": "https://arxiv.org/abs/2508.07178", "title": "通过从隐式反馈中抑制虚假兴趣改进个性化标题生成", "title_en": "Improved Personalized Headline Generation via Denoising Fake Interests from Implicit Feedback", "authors": "Kejin Liu,Junhong Lian,Xiang Ao,Ningtao Wang,Xing Fu,Yu Cheng,Weiqiang Wang,Xinyu Liu", "background": "准确生成个性化头条新闻依赖于精确捕捉用户的兴趣，而现有的方法忽视了历史点击流中的个性化无关的点击噪声，这可能导致生成的头条新闻偏离真正的用户偏好。本文通过在用户和新闻两个维度上进行严谨的分析，揭示了点击噪声对个性化生成质量的负面影响。", "innovation": "提出了一个新颖的个性化头条生成框架（PHG-DIF），通过双重过滤有效去除具有短暂停留时间和异常点击暴发特征的点击流噪声，同时利用多层次的时间融合动态建模用户不断变化和多方面的兴趣，提供精确的用户画像。此外，还发布了一个新的基准数据集DT-PENS，包含1000个精心挑选的用户的点击行为和近10,000条注释的个性化标题，附有历史点击时长注释。", "conclusion": "广泛的实验表明，PHG-DIF显著减轻了点击噪声的负面影响，并显著提高了头条新闻质量，达到了DT-PENS上的最先进水平。本文的框架实现和数据集可在以下链接获取：this https URL."}
{"llm_update_time": "20250815", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.08285", "html_url": "https://arxiv.org/abs/2508.08285", "title": "语言幻觉检测的错觉：重新评估LLMs中的幻觉检测", "title_en": "The Illusion of Progress: Re-evaluating Hallucination Detection in LLMs", "authors": "Denis Janiak,Jakub Binkowski,Albert Sawczyn,Bogdan Gabrys,Ravid Shwartz-Ziv,Tomasz Kajdanowicz", "background": "大型语言模型（LLMs）在自然语言处理中取得了革命性进展，但它们产生幻觉的倾向对可靠部署构成了严重挑战。尽管有许多幻觉检测方法，但它们的评估往往依赖于ROUGE指标，该指标基于词汇重叠，与人类判断不一致。研究表明，ROUGE虽然具有较高的召回率，但极低的精确率导致了误导性的性能估计。此外，分析表明，基于响应长度的简单启发式方法能够与复杂的检测技术竞争，揭示了当前评估实践中的根本缺陷。这些发现强调了采用语义感知和鲁棒性评估框架的必要性，以便准确评估幻觉检测方法的真实性能，最终确保LLM输出的可信度。", "innovation": "论文通过全面的人类研究，揭示了ROUGE指标的局限性，并展示了基于响应长度的简单启发式方法与复杂检测技术的竞争力。论文提出了采用语义感知和鲁棒性评估框架的必要性，以准确评估幻觉检测方法的真实性能，最终确保LLM输出的可信度。", "conclusion": "在当前的评估实践中，采用语义感知和鲁棒性评估框架对于准确评估幻觉检测方法的真正性能和确保LLM输出的可信度至关重要。"}
{"llm_update_time": "20250815", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.10492", "html_url": "https://arxiv.org/abs/2508.10492", "title": "逆转医工关系：大型语言模型驱动全过程临床诊断", "title_en": "Reverse Physician-AI Relationship: Full-process Clinical Diagnosis Driven by a Large Language Model", "authors": "Shicheng Xu,Xin Huang,Zihao Wei,Liang Pang,Huawei Shen,Xueqi Cheng", "background": "临床诊断是一个从模糊主诉开始的完整诊断流程。尽管人工智能（AI），尤其是大型语言模型（LLMs），已经在改变临床诊断，但AI的作用仍然主要是辅助医生。在此过程中，AI只能解答诊断流程中特定部分的具体医疗问题，而无法从模糊主诉开始独立驱动整个诊断流程，仍然需要医生的大量参与。这限制了AI减少医生工作量、提高诊断效率的能力。", "innovation": "本研究提出了一种新的范式，重新定义了医生和AI之间的关系：将AI定位为主导者，医生作为助手。为此，研究团队开发了DxDirector-7B，这是一种具备高级深度思考能力的大型语言模型，能够在医生较少介入的情况下驱动完整的诊断流程，并且建立了详细的问责制度来划分AI和医生的责任。在全过程中，DxDirector-7B不仅在诊断准确率上超过了最先进的医疗LLMs以及通用LLMs，在多个临床部门和任务中也得到了细粒度分析的验证，专家评估认为它有潜力替代医学专家。", "conclusion": "这些发现标志着AI从医生助手转变为驱动整个诊断流程的新时代，能够大幅减轻医生的工作量，并提供一种高效准确的诊断解决方案。"}
{"llm_update_time": "20250815", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.08895", "html_url": "https://arxiv.org/abs/2508.08895", "title": "ASPD: 利用大语言模型内部并行性实现自适应串行-并行解码", "title_en": "ASPD: Unlocking Adaptive Serial-Parallel Decoding by Exploring Intrinsic Parallelism in LLMs", "authors": "Keyu Chen,Zhifeng Shen,Daohai Yu,Haoqian Wu,Wei Wen,Jianfeng He,Ruizhi Qiao,Xing Sun", "background": "大型语言模型（LLMs）的规模和复杂性的不断增加导致了推理延迟的重大挑战，这主要归因于它们的自回归解码机制，这种机制依赖于顺序预测下一个词。通过重新审视自回归模型的输出，我们发现其中一些部分包含可并行化的结构，我们称之为内在并行性。通过同时解码这些并行化分支（即并行解码），可以大幅提高LLM的整体推理速度。", "innovation": "我们提出了自适应串行-并行解码（ASPD），它解决了两个核心挑战：可并行化数据的自动构建和高效的并行解码机制。具体来说，我们引入了一种非侵入式的流水线，可以自动从自回归模型的响应中提取和验证可并行化结构。为了解码的无缝过渡，我们开发了一个混合解码引擎，支持在保持可重用的KV缓存的同时，在串行和并行解码模式之间切换，以最大化计算效率。广泛的评估表明，ASPD在效果和效率上都实现了前所未有的表现。例如，在Vicuna Bench上，我们的方法实现了高达3.19倍（平均1.85倍）的加速，同时响应质量与自回归模型相比差异不超过1%，证明在不牺牲生成质量的情况下实现了显著加速。我们的框架为高效的大语言模型并行推理设立了基准，为诸如基于AI的客户服务机器人和答案检索引擎等延迟敏感应用铺平了道路。", "conclusion": "我们的工作为高效的LLM并行推理设定了新的标准，开启了在人工智能服务和知识检索等应用中的实际部署可能性。"}
{"llm_update_time": "20250815", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.08855", "html_url": "https://arxiv.org/abs/2508.08855", "title": "BiasGym: 如何发现和移除大型语言模型中的偏见", "title_en": "BiasGym: Fantastic LLM Biases and How to Find (and Remove) Them", "authors": "Sekh Mainul Islam,Nadav Borenstein,Siddhesh Milind Pawar,Haeun Yu,Arnav Arora,Isabelle Augenstein", "background": "理解大型语言模型（LLMs）权重中嵌入的偏见和刻板印象至关重要，以开发有效的缓解策略。偏见行为往往是微妙的且难以分离，即使是有意诱发，系统分析和纠偏也极具挑战性。因此，需要一个简单、成本效益高且通用的框架来可靠地注入、分析和缓解LLMs中的概念关联。", "innovation": "该论文引入了BiasGym，这是一种简单的、成本效益高且通用的框架，用于可靠地注入、分析和缓解LLMs中的概念关联。BiasGym 包含两个组成部分：BiasInject，通过基于标记的微调注入特定的偏见，同时保持模型冻结；BiasScope，利用这些注入的信号来识别并引导负责偏见行为的组件。该方法使机制分析中的一致性偏见诱发成为可能，支持精准纠偏而不影响下游任务的性能，并适用于在标记的微调过程中未见过的偏见。BiasGym 证明了其在减少现实世界刻板印象（例如，意大利人是‘狂妄的司机’）和探测虚构关联（例如，来自虚构国家的人们拥有‘蓝色皮肤’）方面的有效性，展示了其在安全干预和解释性研究中的用途。", "conclusion": "BiasGym 有效减少了真实世界中的刻板印象，并能探究虚构的关联。该方法使研究人员能够识别和缓解大型语言模型中的偏见，为安全干预和解释性研究提供了实用工具。"}
{"llm_update_time": "20250815", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.09848", "html_url": "https://arxiv.org/abs/2508.09848", "title": "PRELUDE：一种要求全局理解和长上下文推理的基准", "title_en": "PRELUDE: A Benchmark Designed to Require Global Comprehension and Reasoning over Long Contexts", "authors": "Mo Yu,Tsz Ting Chung,Chulun Zhou,Tong Li,Rui Lu,Jiangnan Li,Liyan Xu,Haoshu Lu,Ning Zhang,Jing Li,Jie Zhou", "background": "现有的基准测试通常侧重于短语境下的理解，新提出的PRELUDE基准则通过确定一个角色的前传故事是否与原著的典藏叙事一致，旨在评估长上下文理解能力。这种任务比现有的基准更加严格地要求全局理解和深度推理，因为前传故事并不属于原始故事的组成部分，评估其合理性通常需要查找和整合只有间接关联的信息。", "innovation": "PRELUDE是一个新的基准，专注于评估模型在长上下文理解方面的性能。它要求模型不仅要理解和整合整个故事情节的多个部分，还要进行深层次的推理，这明显区别于现有的短上下文理解基准。实验结果显示，最先进的语言模型和各种现有技术如在上下文学习、RAG和领域内训练等，都比人类的表现落后超过15%。模型尽管给出正确答案但推理过程有误，使得准确推理的差距达到超过30%。", "conclusion": "实验结果表明，当前技术在长上下文理解与推理方面还有很大的改进空间。尽管现有的技术工具和商业服务都表现出不足，但这项任务能够有效地揭示模型在常识和深入推理方面的不足，并为改进提供明确的方向。"}
{"llm_update_time": "20250815", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.09956", "html_url": "https://arxiv.org/abs/2508.09956", "title": "GPT-5前沿模型在眼科问答中的性能", "title_en": "Performance of GPT-5 Frontier Models in Ophthalmology Question Answering", "authors": "Fares Antaki,David Mikhail,Daniel Milad,Danny A Mammo,Sumit Sharma,Sunil K Srivastava,Bing Yu Chen,Samir Touma,Mertcan Sevgi,Jonathan El-Khoury,Pearse A Keane,Qingyu Chen,Yih Chung Tham,Renaud Duval", "background": "大型语言模型（LLMs）如GPT-5整合了高级推理能力，可能改善复杂医疗问答任务的性能。然而，最新推理模型的最佳配置尚未确定。本文通过评估不同配置下的GPT-5系列模型以及GPT-4o模型在眼科领域的表现，旨在找到既能提高准确性又具有成本效益的配置。", "innovation": "本文首次系统性地将12种不同的GPT-5系列模型配置与GPT-4o模型对比，并通过闭包访问的多重选择问题测试其在眼科领域的表现。研究者使用布拉德利-泰利模型进行一对一竞争评估，使用引荐锚定的、两两LLM评判框架评估推理质量，并进行基于令牌的成本效益分析，以确定最佳配置。", "conclusion": "GPT-5-high在准确性（0.965）和推理质量两种评估中均位列第一，尽管其成本效益分析表明，GPT-5-mini-low是最好的低投入高产出模型。模型性能的基准测试和成本-性能分析为未来的眼科领域大规模使用模型提供了参考，证实了推理强度对准确性的积极影响，同时引入了一种自动化评分框架，用于评估LLM生成答案与参考标准的一致性。"}
{"llm_update_time": "20250815", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.09403", "html_url": "https://arxiv.org/abs/2508.09403", "title": "Columbo：使用大型语言模型扩展表格数据中的简写列名", "title_en": "Columbo: Expanding Abbreviated Column Names for Tabular Data Using Large Language Models", "authors": "Ting Cai,Stephen Sheen,AnHai Doan", "background": "简写列名（如 'esal'）的扩展对于许多下游数据任务至关重要，如数据清洗、数据分析等。这一问题存在于企业、科学领域、政府机构等各个领域。现有研究依赖于合成的公开数据集，但这些数据集存在局限性。现有评价指标无法准确测量扩展的准确性，需要改进的方法和衡量标准。近年出现了基于零样本或细粒度规则的方法，但这些方法在准确性上仍有局限，尤其是在处理复杂数据集时。因此，该研究旨在改进现有方法，改进评价指标，并开发一种新型解决方案以提供更高准确性，更强大的上下文推理和规则应用能力。", "innovation": "1. 提出并构建了4个新的包含真实世界简写列的领域数据集，弥补了早期作品中合成数据的局限性。\n2. 提出了一种新方法，用以提高准确性的评价标准，并能更好地捕捉扩展的准确性。\n3. 开发了一种名为Columbo的强大解决方案，基于大型语言模型，利用上下文推理、链式思考和细粒度分析。结果显示，Columbo在5个数据集上比当前最先进方法NameGuess高4-29%的准确率。\n4. 将Columbo应用于环境科学领域的EDI大型数据门户，展示了其实际使用效果。", "conclusion": "Columbo通过改进现有的数据集和评价标准，并提供一个基于大型语言模型的强大解决方案，显著提高了简写列名扩展的准确性和适用性。Columbo已经在实际应用环境中得到了验证，显示了它在实际应用中的潜力和优势。"}
{"llm_update_time": "20250815", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.06445", "html_url": "https://arxiv.org/abs/2508.06445", "title": "自动化回声：LLMs在新闻制作中的不断增加使用", "title_en": "Echoes of Automation: The Increasing Use of LLMs in Newsmaking", "authors": "Abolfazl Ansari,Delvin Ce Zhang,Nafis Irtiza Tripto,Dongwon Lee", "background": "论文背景在于生成式AI（GenAI），特别是大规模语言模型（LLMs）的迅速发展，引起了人们对新闻业诚信和作者身份的担忧。本文研究了这些AI生成内容在逾4万篇新闻文章中的应用情况，涉及主流媒体、地方媒体和大学媒体的各类媒体形式。", "innovation": "本文使用了三种先进的AI文本检测工具（如Binoculars、Fast-Detect GPT和GPTZero），发现近年来AI生成内容的使用量显著增加，尤其是在地方和大学媒体中。分析表明，LLMs经常用于新闻的开头部分，而结论通常由人工编写。语言分析显示，AI提高了措辞的丰富度和可读性，但降低了正式性，导致写作风格更加统一，尤其是地方媒体。", "conclusion": "研究显示，虽然AI技术提升了新闻内容的丰富度和易读性，但也有降低文章形式性的趋势，这可能引起伦理和规范方面的问题，尤其是在地方媒体的报道中更为普遍。"}
{"llm_update_time": "20250815", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2502.08557", "html_url": "https://arxiv.org/abs/2502.08557", "title": "一种基于代理介导对话式询扩大问的新方法", "title_en": "A New Query Expansion Approach via Agent-Mediated Dialogic Inquiry", "authors": "Wonduk Seo,Hyunjin An,Seunghyun Lee", "background": "查询扩展在信息检索中被广泛应用，通过补充初始查询以获取更丰富的信息来提高搜索效果。尽管现代大语言模型可以通过多次提示生成伪相关内容和扩展术语，但这些方法往往产生单一、狭窄的扩展，缺乏检索相关信息所需的丰富背景和多样性上下文。", "innovation": "本文提出了一种新的代理介导对话框架AMD。该框架通过三个专门的角色进行对话式探究：1) 通过强调澄清、假设探究和推论探究的三个苏格拉底式提问维度重新构架初始查询为三个子问题；2) 生成伪答案，从多个视角丰富查询表示，以匹配用户的意图；3) 评估并细化这些伪答案，保留最相关信息。这种方法通过多层次的代理协作过程，有效构造了更丰富的查询表示，通过探究和反馈精炼过程。", "conclusion": "在BEIR和TREC基准实验中，我们的框架在查询扩展方面优于先前的方法，提供了一个稳健的检索任务解决方案。"}
{"llm_update_time": "20250815", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2503.11509", "html_url": "https://arxiv.org/abs/2503.11509", "title": "TikZero：零样本文本引导图形程序合成", "title_en": "TikZero: Zero-Shot Text-Guided Graphics Program Synthesis", "authors": "Jonas Belouadi,Eddy Ilg,Margret Keuper,Hideki Tanaka,Masao Utiyama,Raj Dabre,Steffen Eger,Simone Paolo Ponzetto", "background": "自动从文本说明生成图形是一项令人信服的能力。然而，要实现高几何精度和可编辑性，需要以如TikZ这样的图形语言来表示图形，并且对齐的数据（即带有说明的图形程序）依然稀缺。与此同时，大量的未对齐的图形程序和带有说明的图像更容易获得。本文通过提出TikZero，将图形程序生成与文本理解分离，并通过使用图像表示作为中介桥梁来弥补不同数据源的差异。这使得独立训练图形程序和带有说明的图像成为可能，并在推理中允许零样本文本引导的图形程序合成。", "innovation": "TikZero通过利用图像表示作为中介桥梁，将图形程序生成与文本理解分离。这种方法使得独立训练图形程序和带有说明的图像成为可能，同时实现了在推理过程中零样本文本引导的图形程序合成。此外，当利用对齐的图形程序作为补充训练信号时，TikZero匹配或超越了更大规模的模型，包括商业系统如GPT-4o的表现。", "conclusion": "本文方法在性能上显著优于只能操作对齐的图形程序的基线方法。通过利用对齐的图形程序作为补充的训练信号，TikZero在性能上达到了或超越了更大的模型，包括商业系统GPT-4o。我们的代码、数据集和部分模型已公开提供。"}
{"llm_update_time": "20250815", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2502.16770", "html_url": "https://arxiv.org/abs/2502.16770", "title": "LED-Merging: 通过定位-选举-隔离减轻模型合并中的安全-效用冲突", "title_en": "LED-Merging: Mitigating Safety-Utility Conflicts in Model Merging with Location-Election-Disjoint", "authors": "Qianli Ma,Dongrui Liu,Qian Chen,Linfeng Zhang,Jing Shao", "background": "预训练的大语言模型（LLMs）在加入特定任务时会产生大量的计算和数据成本。现有模型合并方法尽管提供了一种无需训练的解决方案以集成多个任务特定模型，但也面临安全-效用冲突的问题，即增强的一般能力会削弱安全机制。主要原因包括参数量级选择的简单性导致的神经元识别不准确，以及在合并过程中跨任务神经元的干扰.", "innovation": "LED-Merging是一个三阶段框架，通过基于梯度的归因来定位特定任务的神经元，通过多模型重要性融合动态选择关键神经元，通过参数隔离分隔矛盾的更新。这种方法有效地减少了有害响应率，同时保持了95%的效用性能，并成功地解决了安全-效用冲突，提供了一种轻量级且无需训练的新方法来构建可靠的多任务LLMs.", "conclusion": "LED-Merging在Llama-3-8B、Mistral-7B和Llama2-13B上的实验表明，它能显著降低有害响应率，例如在HarmBench测评中使得Llama-3-8B的有害反应率降低了31.4%，同时保持95%的效用性能，如在GSM8K上达到52.39%的准确率。LED-Merging提供了一个轻量级且无需训练的范例，用于构建可靠的多任务语言模型，并已开源。"}
{"llm_update_time": "20250815", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2503.18773", "html_url": "https://arxiv.org/abs/2503.18773", "title": "BitDecoding: 解锁低比特KV缓存的张量核心用于长上下文LLMs", "title_en": "BitDecoding: Unlocking Tensor Cores for Long-Context LLMs with Low-Bit KV Cache", "authors": "Dayou Du,Shijie Cao,Jianyi Cheng,Luo Mai,Ting Cao,Mao Yang", "background": "长上下文大型语言模型（LLMs）在自回归解码过程中对内存和带宽需求增加，因为随每个生成的令牌增加，键值（KV）缓存也会增大。4比特或2比特等低位KV缓存量化可以减少内存占用并保持准确性，但现有系统由于过度依赖CUDA核心而导致解码速度缓慢，忽略了现代GPU上主要的计算来源——张量核心。", "innovation": "BitDecoding 是一种新的长上下文LLM推理系统，结合使用CUDA核心和张量核心来高效地进行低位KV缓存解码。它通过自动诱导最优布局来利用张量核心，以及在去量化时采用战列线级并行化策略。BitDecoding 包括一个查询转换模块支持各种注意力变体，一个支持多种量化算法的高性能张量和通道尺度量化内核，以及一个软件定义的去量化内核来协调CUDA和张量核心执行混合精度操作。", "conclusion": "在RTX 4090，A100和H100上评估显示，BitDecoding将解码速度分别加速7.5倍，4.8倍和8.9倍，比FP16 FlashDecoding-v2的先进低位系统QServe速度快4.3倍以上。在带有128K上下文的LLaMA-3.1-8B上，单批次解码延迟减少3倍，显示长上下文生成的巨大改进。源代码可从此处获取。"}
{"llm_update_time": "20250815", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2504.08329", "html_url": "https://arxiv.org/abs/2504.08329", "title": "MedRep: 医学概念表示法用于通用电子健康记录基础模型", "title_en": "MedRep: Medical Concept Representation for General Electronic Health Record Foundation Models", "authors": "Junmo Kim,Namkyeong Lee,Jiwon Kim,Kwangsoo Kim", "background": "电子健康记录（EHR）基础模型因其在各种医疗任务中的提高性能而备受关注。尽管取得了快速进展，但仍存在根本限制：处理未见过的医疗代码（不在词汇表中的）。这个问题限制了EHR基础模型的泛化能力和使用不同词汇表训练的模型的集成。", "innovation": "我们提出了一套基于观察医疗结果伙伴关系（OMOP）通用数据模型（CDM）的新颖医学概念表示法（MedRep），用于EHR基础模型。对于概念表示学习，我们通过大型语言模型（LLM）提示丰富每个概念的最小定义，并通过OMOP词汇表的图本体补充基于文本的概念表示。MedRep在各种预测任务中优于传统的EHR基础模型和先前引入的医学代码分词器模型，证明了其泛化能力。", "conclusion": "MedRep在多样化的预测任务中表现出色，并解决了未见过的医疗代码问题。此外，我们证明了MedRep的泛化能力通过外部验证。"}
{"llm_update_time": "20250815", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2505.22793", "html_url": "https://arxiv.org/abs/2505.22793", "title": "视觉-语言模型的文化功利性评估", "title_en": "Evaluation of Cultural Competence of Vision-Language Models", "authors": "Srishti Yadav,Lauren Tilton,Maria Antoniak,Taylor Arnold,Jiaang Li,Siddhesh Milind Pawar,Antonia Karamolegkou,Stella Frank,Zhaochong An,Negar Rostamzadeh,Daniel Hershcovich,Serge Belongie,Ekaterina Shutova", "background": "现代的视觉-语言模型（VLMs）在文化能力评估和基准测试中经常表现出色不佳。鉴于基于VLMs的应用程序的多样性和广泛性，人们对它们如何编码文化细微差别产生了新的兴趣。尽管这个问题的各个方面已被研究，但我们依然缺乏针对视觉-语言模型中图像的文化细微维度进行全面识别和注释的综合框架。", "innovation": "本文提出了一种融合视觉文化研究（如文化研究、符号学和视觉研究）基础方法的综合框架，旨在系统地识别和注释VLMs所包含的文化维度。基于这项审查，我们提出了五个框架，这些框架分别代表了文化维度，并且必须考虑以实现对VLMs文化能力的更完整分析。", "conclusion": "视觉文化研究中基础方法对于评估视觉-语言模型的文化能力至关重要。提出的五个框架旨在帮助更好地理解VLMs的文化细微差别，以促进其更具文化敏感性的应用和发展。"}
{"llm_update_time": "20250815", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2505.03810", "html_url": "https://arxiv.org/abs/2505.03810", "title": "集合同频排列旋转：免费优化量化中的旋转变换", "title_en": "Grouped Sequency-arranged Rotation: Optimizing Rotation Transformation for Quantization for Free", "authors": "Euntae Choi,Sumin Song,Woosang Lim,Sungjoo Yoo", "background": "大语言模型（LLMs）由于高计算成本存在部署挑战，而现有后训练量化的（PTQ）方法在极低位宽（如2位）下表现不佳。传统的旋转方法在极低位宽下也存在问题，因此新的非训练方法被提出以解决这些挑战。该方法通过利用沃尔什-豪色变换（WHT）的频序排列，将相似的频率成分聚类，从而减少量化误差，相比标准豪色矩阵显著提高了性能。此外，该方法还提出了一种分组频序排列旋转（GSR）方法，利用较小的沃尔什块创建块对角矩阵，有效隔离异常值影响，实现与优化方法类似的性能，同时无需任何训练。这种方法在推理任务和WikiText-2的困惑度（PPL）评分上都展示了出色的表现，并且即使在现有的学习旋转技术之上应用也能提升结果。", "innovation": "引入了训练免费的沃尔什-豪色变换（WHT）频序排列方法，以及一组频序排列旋转（GSR）方法，分别通过集群相似频率成分和使用块对角矩阵来减少量化误差，减少异常值的影响，提高了性能，而无需任何训练。这些方法在处理LLMs的低位宽量化问题上提供了新的解决方案。", "conclusion": "所提出的方法在推理任务和WikiText-2的困惑度（PPL）评分上均展示了良好的性能，即使在现有的学习旋转技术之上应用也能进一步提升结果。"}
{"llm_update_time": "20250815", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2506.22493", "html_url": "https://arxiv.org/abs/2506.22493", "title": "关于政治倾向测验（PCT）的详细因素分析：引导大型语言模型导航意识形态", "title_en": "A Detailed Factor Analysis for the Political Compass Test: Navigating Ideologies of Large Language Models", "authors": "Sadia Kamal,Lalu Prasad Yadav Prakash,S M Rafiuddin,Mohammed Rakib,Atriya Sen,Sagnik Ray Choudhury", "background": "已经使用了诸如PCT测试之类的问卷来量化大型语言模型（LLM）的政治倾向。最近的研究已经检验了PCT测试的有效性。", "innovation": "研究展示了在固定标准生成参数的情况下，LLM的PCT分数没有显著变化。然而，外部因素如提示变化和微调（单独或联合）会对模型产生影响。研究还发现，即使模型在更具有政治内容的数据集上进行微调，其PCT分数也不受影响。这表明需要进一步研究PCT等测试的有效性，以及政治倾向在LLM中的编码机制。", "conclusion": "本研究要求对PCT测试的有效性进行更深入的调查，以及探讨LLM中政治倾向编码的机制。"}
{"llm_update_time": "20250815", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2504.15485", "html_url": "https://arxiv.org/abs/2504.15485", "title": "CAPTURe：通过遮挡物体计数评估视觉语言模型的空间推理能力", "title_en": "CAPTURe: Evaluating Spatial Reasoning in Vision Language Models via Occluded Object Counting", "authors": "Atin Pothiraj,Elias Stengel-Eskin,Jaemin Cho,Mohit Bansal", "background": "识别和推理部分或完全被遮挡的物体对于理解视觉场景至关重要，因为遮挡在现实环境中频繁发生，并且是空间理解的障碍。为了测试模型处理多个遮挡物体的能力，论文引入了一个新的任务：通过未知区域模式计数（CAPTURe），要求模型通过推断遮挡物后图案的延续来计数排列在图案中的物体。这一任务结合了识别视觉模式和推理，是评估视觉语言模型（VLMs）理解和空间理解能力的有效测试平台。CAPTURe 还要求模型推理遮挡物体，以此测试VLMs构建世界模型并填补缺失信息的能力。", "innovation": "论文提出了一个名为CAPTURe的新颖任务，要求视觉语言模型通过推理遮挡区域的图案来计数物体。这不仅测试了模型的空间推理能力，还检验了模型构建世界模型以填充缺失信息的能力。研究通过两种模式的测试（现实物体的真实图像和合成的模式化图像）来评估多个强大的VLMs，并发现即使是最强的模型如GPT-4o在处理遮挡物体时也存在困难。", "conclusion": "在CAPTURe任务中，即使使用辅助信息表示遮挡物体的位置也只能略微提高模型的性能，表明模型在处理遮挡问题和在图像中计数方面都存在问题。相比之下，人类在CAPTURe任务中几乎无误。研究结果表明，视觉语言模型在空间推理和处理遮挡方面还有很大的改进空间。"}
{"llm_update_time": "20250815", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2505.15935", "html_url": "https://arxiv.org/abs/2505.15935", "title": "MAPS: 全球代理性能和安全性多语言基准", "title_en": "MAPS: A Multilingual Benchmark for Global Agent Performance and Security", "authors": "Omer Hofman,Jonathan Brokman,Oren Rachmil,Shamik Bose,Vikas Pahuja,Toshiya Shimizu,Trisha Starostina,Kelly Marchisio,Seraphina Goldfarb-Tarrant,Roman Vainshtein", "background": "人工代理系统基于大语言模型（LLMs）并能与工具和记忆互动，其能力和范围正在迅速提升。然而，由于LLMs在多语言环境中表现欠佳，通常会导致性能降低和安全性下降，这使得这些系统面临着局限性。这引发了对这些系统可访问性的担忧，尤其是非英语用户可能遇到不可靠或关键安全问题。尽管对人工代理AI的兴趣日益增加，现有的基准测试仅集中在英文上，忽视了多语言环境。为了解决这个问题，作者建议了一个名为MAPS的多语言基准套件，旨在评估不同语言和任务下的人工代理AI系统的性能和鲁棒性。", "innovation": "MAPS基准套件构建于四个广泛使用的代理基准之上——GAIA（现实任务）、SWE-bench（代码生成）、MATH（数学推理）以及代理安全基准，将这四个数据集翻译成11种不同的语言，生成了805个独特的任务和9,660个语言特定的实例，这使得可以系统性地分析多语言环境对AI代理性能和鲁棒性的影响。试验结果表明，从英语过渡到其他语言时，在性能和安全性方面均出现退化，严重性随任务变化，并与翻译输入的多少相关。", "conclusion": "基于上述发现，作者提出了实际操作性的建议，以指导在多语言环境下开发和评估人工代理AI系统。本研究建立了首个标准化的多语言代理评估框架，促进了朝着公平、可靠和可访问的人工代理AI的研究。MAPS基准套件在公开渠道提供，供进一步研究使用。"}
{"llm_update_time": "20250815", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2507.15758", "html_url": "https://arxiv.org/abs/2507.15758", "title": "LAPO：通过长度自适应策略优化内化推理效率", "title_en": "LAPO: Internalizing Reasoning Efficiency via Length-Adaptive Policy Optimization", "authors": "Xingyu Wu,Yuchen Yan,Shangke Lyu,Linjuan Wu,Yiwen Qiu,Yongliang Shen,Weiming Lu,Jian Shao,Jun Xiao,Yueting Zhuang", "background": "大型推理模型通过扩展的思维链取得了显著的性能，但在解决简单问题时，这种计算上的灵活性反而导致了不必要的大量token生成。现有的方法在控制推理长度时存在硬性限制或需要后续干预，这限制了模型的能力。", "innovation": "提出了Length-Adaptive Policy Optimization (LAPO)框架，将推理长度控制从外部限制转变为模型内部的能力。该方法通过两阶段的强化学习过程，使模型能够在第一阶段学习自然的推理模式，然后在第二阶段利用这些模式作为元认知指导，直接嵌入到模型推理的上下文环境中，以确保推理时的灵活性。实验结果表明，LAPO能将token使用减少高达40.9%，同时提高准确率2.3%。训练后的模型发展出了根据问题复杂度分配计算资源的能力，实现高效推理而不牺牲质量.", "conclusion": "LAPO能够使模型通过自我学习和优化，自主决定适当的推理深度，从而在不牺牲推理质量的情况下提高效率。"}
{"llm_update_time": "20250815", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2506.10236", "html_url": "https://arxiv.org/abs/2506.10236", "title": "提示攻击揭示了去学习方法中表层知识移除现象", "title_en": "Prompt Attacks Reveal Superficial Knowledge Removal in Unlearning Methods", "authors": "Yeonwoo Jang,Shariqah Hossain,Ashwin Sreevatsa,Diogo Cruz", "background": "当前研究表明某些机器去学习方法可能在面对简单的提示攻击时会失效。研究者们已经评估了多种去学习技术，但从验证去学习是否有效和可靠的角度来看，还存在一定的不足。", "innovation": "本文系统地评估了八种去学习技术在三种模型家庭中的表现，使用基于输出、基于logit和探针分析来衡量是否可以检索出已去学习的知识。本文揭示了某些方法虽然表现出色但仍然容易受到针对性的提示攻击，此外通过对logit的分析还发现，去学习模型难以通过改变答案格式来隐藏知识。", "conclusion": "本文的研究挑战了去学习有效性的现有假设，并强调需要建立可靠的评估框架来区分真正的知识移除和表面的输出抑制。为此，研究者公开发布了一种评估框架，以便更容易地测试提示技术以获取去学习的知识。"}
{"llm_update_time": "20250815", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2507.10354", "html_url": "https://arxiv.org/abs/2507.10354", "title": "含义如同洋葱：多层次的隐喻处理方法", "title_en": "Meanings are like Onions: a Layered Approach to Metaphor Processing", "authors": "Silvia Cappa,Anna Sofia Lippolis,Stefano Zoia", "background": "隐喻的意义不是简单的概念间映射，而是一种复杂的心智现象，涉及多层次的解释。已有研究尝试通过多层次结构来解析这些复杂的隐喻，但现有的模型大多数是平面化的，缺乏对隐喻深层次理解的支撑。", "innovation": "提出了一种分层的隐喻处理模型，将隐喻意义比作洋葱，包含三个层次：1) 内容分析；2) 概念融合；3) 语用意图性。这种三个维度的框架能够为计算系统提供更丰富且基于认知的方法来处理隐喻理解。", "conclusion": "通过将这三层嵌入单一的形式框架中，该模型为能够超越表面关联，实现更深层次、更具上下文敏感性的推理提供了基础，推动了隐喻处理的技术发展。"}
{"llm_update_time": "20250815", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.10066", "html_url": "https://arxiv.org/abs/2508.10066", "title": "基于随机性片段筛选的少样本学习", "title_en": "Stochastic-based Patch Filtering for Few-Shot Learning", "authors": "Javier Rodenas,Eduardo Aguilar,Petia Radeva", "background": "食品图像的视觉复杂性和变化性为少样本学习模型带来了独特的挑战。例如，相同的意大利面菜品可能因盘子上的装饰、不同的光照条件以及拍摄角度而异。这导致在与支撑图像比较查询图像时容易忽视关键元素，从而可能导致分类错误。", "innovation": "本文提出了基于随机性的片段筛选方法（SPFF），通过选择与类别表示高度相关的片段嵌入，来解决这一问题。该方法通过随机筛选出较少相关的片段嵌入，从而更专注于显示特定类别食品特征的片段。", "conclusion": "通过对Food-101、VireoFood-172和UECFood-256等少样本分类基准进行广泛的实验验证，本文的方法在性能上优于现有的最佳方法。"}
{"llm_update_time": "20250815", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.05571", "html_url": "https://arxiv.org/abs/2508.05571", "title": "iFairy: 首个所有参数在 {±1, ±i} 中的 2 位复数 LLM", "title_en": "iFairy: the First 2-bit Complex LLM with All Parameters in $\\{\\pm1, \\pm i\\}$", "authors": "Feiyu Wang,Guoan Wang,Yihao Zhang,Shengfan Wang,Weitao Li,Bokai Huang,Shimao Chen,Zihan Jiang,Rui Xu,Tong Yang", "background": "量化感知训练（QAT）将量化融入训练过程中，使大语言模型（LLM）能够学习稳健的低位宽表示，被认为是极具前景的研究方向。目前的所有 QAT 研究旨在最小化全精度模型的量化误差，较高精度的模型准确率被视为上限。然而，还没有现有方法能够突破这一上限。", "innovation": "本文提出了一个新的范式：提升全精度模型的上限，然后高效地将其量化成 2 位。提出了一种名为 Fairy$\backslash\text{pm} i$ 的 2 位复数 LLM 量化框架，将权重映射到四元单位根 \\\\$\\{±1, ±i\\\\\\$ 中，形成完全对称且信息论上最优的 2 位表示。每个量化后的权重只包含实部或虚部为零，使得推理过程中可以仅使用加法和元素交换而无需乘法运算。实验结果显示，Fairy$\backslash\text{pm} i$ 在 PPL 和下游任务上均优于现有方法，在严格存储和计算效率方面具有优势。", "conclusion": "本文的工作为在极低位宽的约束下构建准确且实用的 LLM 提供了新的方向。"}
{"llm_update_time": "20250815", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.04586", "html_url": "https://arxiv.org/abs/2508.04586", "title": "当前AI会议模式不可持续！解读集中式AI会议危机", "title_en": "Position: The Current AI Conference Model is Unsustainable! Diagnosing the Crisis of Centralized AI Conference", "authors": "Nuo Chen,Moming Duan,Andre Huikai Lin,Qian Wang,Jiaying Wu,Bingsheng He", "background": "人工智能（AI）会议对推进研究、分享知识和促进学术社区具有重要意义，但其快速扩张使得集中式会议模式变得越来越不可持续。论文通过数据驱动的方式诊断了一种结构性危机，这种危机威胁到科学传播、公正性和社区福祉的基础目标。论文指出了四个关键领域的压力：(1) 科学上，作者的发表率在过去十年中超过翻倍，每年超过4.5篇论文；(2) 环境上，单个会议的碳足迹超过了其举办城市的日均排放量；(3) 心理上，在线社区讨论中有71%反映了负面情绪，35%提到了心理健康问题；(4) 物流上，顶级会议如NeurIPS 2024的参会人数开始超过场地容量。这些压力指向一个与核心使命不一致的系统。", "innovation": "论文提出了社区集约化会议（CFC）模型，该模型将同行评审、展示和社交网络分离为全球协调但本地组织的环节，为AI研究提供了一条更加可持续、包容性和韧性的道路。", "conclusion": "当前的AI会议模式与其核心使命不符，提出了CFC模型作为解决当前问题的方案，旨在实现更可持续、更包容和更具弹性的AI研究路径。"}
{"llm_update_time": "20250815", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.10104", "html_url": "https://arxiv.org/abs/2508.10104", "title": "DINOv3", "title_en": "DINOv3", "authors": "Oriane Siméoni,Huy V. Vo,Maximilian Seitzer,Federico Baldassarre,Maxime Oquab,Cijo Jose,Vasil Khalidov,Marc Szafraniec,Seungeun Yi,Michaël Ramamonjisoa,Francisco Massa,Daniel Haziza,Luca Wehrstedt,Jianyuan Wang,Timothée Darcet,Théo Moutakanni,Leonel Sentana,Claire Roberts,Andrea Vedaldi,Jamie Tolan,John Brandt,Camille Couprie,Julien Mairal,Hervé Jégou,Patrick Labatut,Piotr Bojanowski", "background": "自监督学习有潜力消除手动数据标注的需求，允许模型轻松扩展到巨量数据集和更大规模的架构。无需针对特定任务或领域专门设计，该训练范式可以从各种来源学习视觉表示，包括自然图像和航空图像，通过单一算法实现。", "innovation": "首先，通过精心的数据准备、设计和优化，既扩大了数据集规模也扩大了模型规模，利用了规模优势。其次，提出了一种新方法称为Gram anchoring，有效解决了密集特征图在长期训练计划中退化的问题。最后，应用后处理策略，增强模型在分辨率、模型大小和与文本对齐方面的灵活性。这些改进使DINOv3成为一个多功能的视觉基础模型，能够在广泛设定中超越专门化的现有最佳成果，无需微调。DINOv3生成高质量的密集特征，取得各种视觉任务的优异表现，大幅超越先前的自监督和弱监督基础模型。还分享了DINOv3视觉模型系列，旨在提供适应各种资源约束和部署场景的解决方案，以推进广泛任务和数据的最新状态。", "conclusion": "DINOv3是一个多功能的视觉基础模型，能够在广泛设定中超越专门化的现有最佳成果，无需微调。DINOv3生成的高质量密集特征在各种视觉任务中表现出色，大幅超越先前的自监督和弱监督基础模型。"}
{"llm_update_time": "20250815", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.10110", "html_url": "https://arxiv.org/abs/2508.10110", "title": "使用可解释的图像-文本基础模型增强变形攻击检测", "title_en": "Empowering Morphing Attack Detection using Interpretable Image-Text Foundation Model", "authors": "Sushrut Patwardhan,Raghavendra Ramachandra,Sushma Venkatesh", "background": "变形攻击检测是确保面部识别系统可靠验证场景的重要组成部分。本文介绍了一种多模态学习方法，可以提供变形攻击检测的文本描述。首先，作者使用对比语言-图像预训练（CLIP）进行零-shot评估，不仅获得了可泛化的攻击检测，还预测了最相关的文本片段。实验在使用公开面部生物识别数据集构建的数据集上进行，分析了十种不同的文本提示，包括短文本和长文本提示，这些提示是为实现人可理解的文本片段而设计的。在此基础上，对最先进的预训练神经网络以及提出的框架在五种不同类型的变形生成技术的零-shot评估中进行了全面实验，这些技术分布在三种不同的媒介中。", "innovation": "本文提出了一种新的多模态学习方法，利用对比语言-图像预训练（CLIP）进行变形攻击检测的零-shot评估，不仅可以实现攻击检测的泛化，还能预测最相关的文本片段；并且该方法通过设计不同长度的文本提示，确保检测结果对人类易理解的特性，从而进一步提高了系统的解释性与实际应用价值；此外，通过在多种变形生成技术上进行广泛的实验验证了该方法的有效性。", "conclusion": "研究通过多模态学习方法，实现了变形攻击检测，并利用对比语言-图像预训练（CLIP）进行了有效的零-shot评估；基于人可理解的文本提示，进行了广泛的实验验证；通过这种方法，不仅提高了变形攻击检测的泛化能力，还增强了其对实际应用的解释性和可行性。"}
{"llm_update_time": "20250815", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.06412", "html_url": "https://arxiv.org/abs/2508.06412", "title": "通过重置重放实现高效样本的大模型优化", "title_en": "Sample-efficient LLM Optimization with Reset Replay", "authors": "Zichuan Liu,Jinyu Wang,Lei Song,Jiang Bian", "background": "近期，通过对大规模语言模型（LLMs）进行训练后的改进，特别是通过强化学习（RL）和偏好优化方法，极大地提高了它们的推理能力。然而，这些方法往往存在样本效率低和首因效应偏差的问题，首因效应偏差会导致模型过度拟合初始经验，从而降低政策质量并破坏学习过程。为解决这些问题，提出了基于重置重放的大模型优化（LoRR），这是一种通用且强大的插件，旨在增强任何偏好优化框架的样本效率。LoRR的核心机制允许在高重放数量下的训练，最大化每批收集数据的效用，同时通过引入周期性重置策略并利用初始数据，降低了高重放训练中的过拟合风险，保持了网络的可塑性。此外，它还通过结合监督微调（SFT）和偏好损失来进一步增强数据的利用。通过广泛的实验表明，LoRR显著提升了各种偏好优化方法在数学和一般推理基准上的性能。Using an iterative DPO方法增强LoRR在复杂数学任务上的性能，优于一些复杂的计算密集型RL算法。这表明，LoRR为LLM微调提供了一种实用、样本高效且非常有效的范式，可以更好地利用有限的数据来提升性能。", "innovation": "提出了一种名为LoRR的插件，通过高重放数量下的训练和周期性重置策略，增强了大模型的样本效率。通过结合监督微调和偏好损失，进一步优化了数据利用。实验表明，LoRR在数学和一般推理任务上显著提升了各种偏好优化方法的性能，并在复杂的数学任务上优于一些计算密集的RL算法。", "conclusion": "LoRR提供了一种实用、样本高效且非常有效的范式，为大规模语言模型的优化提供了新的方法，能够更有效地从有限的数据中提升性能。"}
{"llm_update_time": "20250815", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.10113", "html_url": "https://arxiv.org/abs/2508.10113", "title": "通过大型跨模态语言模型进行基于部首和象形分析的可解释甲骨文解码", "title_en": "Interpretable Oracle Bone Script Decipherment through Radical and Pictographic Analysis with LVLMs", "authors": "Kaixin Peng,Mengyang Zhao,Haiyang Yu,Teng Fu,Bin Li", "background": "作为最早也是最成熟的文字系统之一，甲骨文由于其稀有性、抽象性以及象形多样性，长期以来为考古解读带来了巨大挑战。当前基于深度学习的方法在甲骨文解码任务上取得了令人振奋的进步，但现有方法往往忽略象形字符和甲骨文字义之间的复杂联系，导致模型在泛化能力和可解释性上存在局限，尤其是在零样本设置和未解甲骨文方面。", "innovation": "本文提出了基于大型视觉-语言模型的可解释甲骨文解码方法，该方法通过综合部首分析和象形文字语义理解来弥合甲骨文字符与含义之间的差距。特别地，本文提出了一种逐步训练策略，旨在引导模型从部首识别和分析逐步过渡到象形文字分析，从而实现从字符到意义的推理过程。此外，还设计了基于分析结果的部首与象形文字双匹配机制，显著提升了模型的零样本解码性能。", "conclusion": "实验结果表明，本文方法在公共基准测试上达到了最高的Top-10准确率，并且具有优越的零样本解码能力。更重要的是，本文的模型提供了逻辑分析过程，可能为未解甲骨文提供有价值的考古参考，有望在数字人文和历史研究中找到应用。本文的语料库和代码将在该链接处发布：[具体链接]。"}
{"llm_update_time": "20250815", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.10133", "html_url": "https://arxiv.org/abs/2508.10133", "title": "MANGO: 基于多模态注意力的归一化流融合学习方法", "title_en": "MANGO: Multimodal Attention-based Normalizing Flow Approach to Fusion Learning", "authors": "Thanh-Dat Truong,Christophe Bobda,Nitin Agarwal,Khoa Luu", "background": "近年来，多模态学习取得了显著的成就。然而，当前的多模态融合方法通过Transformer的注意力机制隐式地学习多模态特征之间的潜在关联，这使得多模态模型难以捕捉每个模态的关键特征，进而难以理解和处理复杂的多模态输入结构和关联性.", "innovation": "本文提出了一种新颖的多模态注意力归一化流方法（MANGO），引入了一个新的可逆交叉注意力（ICA）层，用于开发基于归一化流的多模态数据模型。特别地，本文提出三种新的交叉注意力机制：模态到模态的交叉注意力（MMCA）、模态间交叉注意力（IMCA）和可学习的模态间交叉注意力（LICA），以高效地捕捉多模态数据中的复杂内部关联。此外，本文还提出了一种新的多模态注意力归一化流，以使本文提出的方法能够处理高维多模态数据，进而显著提升了方法的可扩展性.", "conclusion": "本文的方法在三个不同的多模态学习任务上展示了最先进的性能，即语义分割、图像到图像的翻译以及电影类型分类。"}
{"llm_update_time": "20250815", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.10156", "html_url": "https://arxiv.org/abs/2508.10156", "title": "通过自定义EfficientNetV2-L模型利用生成式人工智能（GenAI）基于合成和实地图像提高西瓜（Citrullus lanatus）疾病分类", "title_en": "Improving watermelon (Citrullus lanatus) disease classification with generative artificial intelligence (GenAI)-based synthetic and real-field images via a custom EfficientNetV2-L model", "authors": "Nitin Rai,Nathan S. Boyd,Gary E. Vallad,Arnold W. Schumann", "background": "当前生成人工智能（GenAI）模型的进步为生成高分辨率合成图像提供了新的可能性，从而提供了一种替代传统图像采集的有前景的方法，用于农业中计算机视觉模型的训练。在作物病害诊断领域，GenAI模型用于创建各种病害的合成图像，这可能促进模型创建并减少对资源密集型实地数据采集的依赖。然而，关于结合现实图像和合成图像以提高疾病分类性能的研究较少。因此，本研究旨在探讨是否可以结合少量现实图像与合成图像以改善使用EfficientNetV2-L模型对黄瓜（Citrullus lanatus）病害的分类准确性。", "innovation": "本研究通过自定义的EfficientNetV2-L模型，提出了一种结合合成图像和现实图像的方法，并通过增强的微调和迁移学习技术进行训练。实验结果显示，混合使用一定比例的现实图像和合成图像可以显著提高模型的精度、召回率和F1分数，尤其是在大量使用合成图像的同时加入少量现实图像的情况下，模型的一般化能力得到了明显增强。", "conclusion": "综合研究结果表明，只有合成图像不足以替代现实图像；相反，两者必须以混合的方式使用，才能最大程度地提高用于作物病害分类模型的性能。"}
{"llm_update_time": "20250815", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.08508", "html_url": "https://arxiv.org/abs/2508.08508", "title": "Re:Verse -- 你的VLM能读懂漫画吗？", "title_en": "Re:Verse -- Can Your VLM Read a Manga?", "authors": "Aaditya Baranwal,Madhav Kataria,Naitik Agrawal,Yogesh S Rawat,Shruti Vyas", "background": "当前的视觉语言模型（VLMs）在处理连续视觉叙事时表现出明显的表面识别和深层叙事推理之间的差距。通过全面探究漫画叙事理解，我们发现，尽管近期大规模多模态模型在单个面板解释方面表现出色，但在时间因果性和跨面板连贯性方面存在系统性失败，这是连贯故事理解的核心要求。该研究介绍了一种新的评估框架，该框架结合了细粒度的多模态注释、跨模态嵌入分析和检索增强评估，以系统性地刻画这些限制。这些方法包括基于对齐轻量级小说文本的细粒度多模态注释协议、跨多个推理范式的全面评估（包括直接推断和检索增强生成），以及揭示当前VLMs联合表示中根本性不一致的跨模态相似性分析。", "innovation": "引入了结合细粒度多模态注释、跨模态嵌入分析和检索增强评估的新评估框架，系统性地揭示了现有视觉语言模型在时间因果性和跨面板连贯性等方面的局限性。通过这个框架对Re:Zero漫画进行了系统的评估，发现当前模型在叙事理解、对话上下文接地和时间推理方面存在不足，特别是在非线性叙事、人物一致性以及跨长序列的因果推理方面表现出色。这项工作为评估叙事智能奠定了基础，并提供了多模态模型中离散视觉叙事的深入顺序理解能力的实际洞察。", "conclusion": "研究发现当前视觉语言模型缺乏真正的故事水平智能，尤其是在非线性叙事、人物一致性以及跨长序列的因果推理方面表现出不足。这标志着在评估叙事智能方面进展的同时，也指出了多模态模型在理解离散视觉叙事方面超越基本识别能力的实际见解。"}
{"llm_update_time": "20250815", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.10132", "html_url": "https://arxiv.org/abs/2508.10132", "title": "深度学习在全身DXA成像中实现大规模形状和外观建模", "title_en": "Deep Learning Enables Large-Scale Shape and Appearance Modeling in Total-Body DXA Imaging", "authors": "Arianna Bunnell,Devon Cataldi,Yannik Glaser,Thomas K. Wolfgruber,Steven Heymsfield,Alan B. Zonderman,Thomas L. Kelly,Peter Sadowski,John A. Shepherd", "background": "全身影像（TBDXA）是一种相对经济的全身成像技术，广泛用于人体组成评估。然而，在这种成像模式中自动关键点定位仍然依赖于人工标注，这限制了其大规模应用。为解决这一问题，研究开发并验证了一种基于深度学习的方法，用于自动在TBDXA扫描中放置关键点，使用1683个由人工标注的TBDXA扫描数据集进行验证。该方法在外测测试数据集上实现了99.5%的准确关键点放置率。通过将这些关键点应用于35,928个不同TBDXA成像模式的扫描，结合两个未用于生成SAM模型的群体，通过两样本Kolmogorov-Smirnov检验，探索了与健康标记物的相关性，从而证明形状和外观特征与各种与营养不良、代谢、炎症及心血管代谢健康标志物的关联性。提供的评估脚本、模型权重、自动化关键点文件生成代码和三角化文件可在指定网站下载。", "innovation": "本文创新地提出了一种基于深度学习的自动关键点标注方法，极大地提高了全身影像中关键点放置的效率。该方法在大规模数据集的验证下表现出色，具有99.5%的高准确率。此外，通过这一方法生成的关键点数据被用于探索健康标志物之间的关联，能够验证已有的研究结果并提出新的假设，对于理解人体组成与健康指标之间的关系具有重要意义。", "conclusion": "该研究利用深度学习技术提高了全身影像中关键点自动标注的准确性，为大规模的形状和外观建模提供了可能。通过这种方法，发现了新的健康标志物与人体组成和形状的关联，为未来的研究提供了新的方向。所使用的评估脚本、模型权重、自动关键点文件生成代码和三角化文件已提供共享，便于其他研究人员重复实验和进一步研究。"}
{"llm_update_time": "20250815", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.10256", "html_url": "https://arxiv.org/abs/2508.10256", "title": "基于学习范式、泛化能力和数据集的深度学习裂缝检测综述", "title_en": "Deep Learning for Crack Detection: A Review of Learning Paradigms, Generalizability, and Datasets", "authors": "Xinan Zhang,Haolin Wang,Yung-An Hsieh,Zhongyu Yang,Anthony Yezzi,Yi-Chang Tsai", "background": "裂缝检测在基础设施检查中扮演着重要角色，包括路面、建筑物等。近年来，深度学习在这一领域取得了显著进展，但领域内存在大量的技术与综述性论文，新兴趋势正在重塑这一领域。这些趋势包括学习范式的转变（从完全监督学习到半监督、弱监督、无监督、少量样本、领域适应和微调基础模型）、泛化能力的增强（从单数据集性能到跨数据集评估）以及数据重新获取的多样化（从RGB图像到专用传感器数据）。", "innovation": "本综述系统地分析了这些趋势，并强调了代表性的工作。此外，作者引入了一个新的3D激光扫描数据集3DCrack，以支持未来的研究，并进行了广泛的基准测试实验，以建立常用深度学习方法的基础线。实验结果提供了关于基于深度学习的裂缝检测方法和未来方向的见解。", "conclusion": "本研究提供了关于深度学习基于裂缝检测方法和未来方向的见解，为未来的研究提供了新的数据集和基线。"}
{"llm_update_time": "20250815", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.10227", "html_url": "https://arxiv.org/abs/2508.10227", "title": "EntropyGS：在3D高斯点渲染中的高效熵编码", "title_en": "EntropyGS: An Efficient Entropy Coding on 3D Gaussian Splatting", "authors": "Yuning Huang,Jiahao Pang,Fengqing Zhu,Dong Tian", "background": "3D Gaussian Splatting (3DGS) 是一种新兴的新型视图合成方法，具有快速训练/渲染和优秀的视觉质量。3DGS 的两个任务（高斯创建和视图渲染）通常被分开处理或在不同的设备上处理，因此需要存储/传输和压缩3DGS 高斯函数。本文开始进行3DGS 高斯属性的相关性和统计分析。研究表明，球谐AC属性严格遵循拉普拉斯分布，而混合高斯分布可以近似旋转、缩放和透明度。此外，球谐AC属性与其他属性之间几乎没有相关性，除了从颜色空间继承的相关性。", "innovation": "本文提出了一种因子化和参数化的熵编码方法熵编码（EntropyGS）。在编码过程中，每个高斯属性的概率分布参数被估计以辅助熵编码。熵编码的量化是根据高斯属性类型自适应进行的。实验结果显示，EntropyGS 在基准数据集上减少了约 30 倍的比特率，同时保持与输入 3DGS 数据相似的渲染质量，并且具有快速的编码和解码时间。", "conclusion": "熵编码（EntropyGS）在保持高视觉质量的同时，显著减少了3DGS数据的比特率，并且编码和解码速度非常快。"}
{"llm_update_time": "20250815", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.10171", "html_url": "https://arxiv.org/abs/2508.10171", "title": "SynSpill: Improved Industrial Spill Detection With Synthetic Data", "title_en": "SynSpill: Improved Industrial Spill Detection With Synthetic Data", "authors": "Aaditya Baranwal,Abdul Mueez,Jason Voelker,Guneet Bhatia,Shruti Vyas", "background": "大规模的视觉语言模型（VLMs）在通过强零样本能力推动通用视觉识别方面取得了巨大进展。然而，它们在危险品事件罕见、敏感且难以标注的领域，如工业溢出检测，的表现显著下降。这种稀缺性由隐私问题、数据敏感性和实际事件的频率低所驱动，使得在大多数工业环境中对检测器进行传统的微调不可行。团队针对这一挑战引入了一个可扩展的框架，中心是一个高质量的合成数据生成管道，展示了合成数据集如何有效提高参数高效微调（PEFT）和最先进的目标检测器如YOLO和DETR的性能。", "innovation": "团队介绍了基于高质量合成数据生成管道的可扩展框架，并展示了这种合成数据集如何实现视觉语言模型（VLMs）的有效参数高效微调（PEFT），显著提升最先进的目标检测器如YOLO和DETR的性能。在缺乏合成数据的情况下，VLMs仍然优于这些检测器对未见过的溢出场景进行了更好的泛化。当使用合成数据集时，VLMs和检测器都取得了显著改进，性能变得可比。结果表明，高保真度的合成数据是解决安全关键应用中领域差距的强大手段。合成生成与轻量级适应相结合，提供了一种在数据稀缺/难以获得的工业环境中部署视觉系统的成本效益和可扩展途径。", "conclusion": "研究表明，高保真度的合成数据在解决安全关键应用中的领域差距方面具有强大的潜力。合成生成和轻量级适应的结合为在工业环境中部署视觉系统提供了成本效益和可扩展的途径。"}
{"llm_update_time": "20250815", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.10264", "html_url": "https://arxiv.org/abs/2508.10264", "title": "MRFD：大视觉-语言模型中通过自我一致性进行多区域融合解码以缓解幻觉", "title_en": "MRFD: Multi-Region Fusion Decoding with Self-Consistency for Mitigating Hallucinations in LVLMs", "authors": "Haonan Ge,Yiwei Wang,Ming-Hsuan Yang,Yujun Cai", "background": "大视觉-语言模型（LVLMs）在多模态任务中表现出强大性能，但处理视觉输入时易产生与之不一致的幻觉，原因在于模型难以验证图像不同区域的信息。现有方法依赖于模型更新来改进事实性，而没有提供有效的无训练解码策略来缓解幻觉问题。", "innovation": "提出了一种无需训练的多区域融合解码（MRFD）方法，通过建模不同区域间的相互一致性来提高事实性。该方法利用交叉注意力识别显著区域，生成各自的初步响应，并基于各个响应间的詹森-香农散度（JSD）计算可靠性权重，然后根据这些权重融合各区域的预测，使用灵感来源于链式思维推理的区域意识提示来引导一致性融合。实验结果显示，MRFD能显著减少幻觉并提高回答的事实性，而无需对模型进行更新。", "conclusion": "MRFD通过多区域融合解码和自我一致性策略大幅降低大视觉-语言模型中的幻觉现象，提高了响应的事实性，表现出了在多种LVLMs和基准测试中的优良效果，为改进多模态模型的解释性和可靠性提供了新思路。"}
{"llm_update_time": "20250815", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.10268", "html_url": "https://arxiv.org/abs/2508.10268", "title": "Pose-Robust Calibration Strategy for Point-of-Gaze Estimation on Mobile Phones", "title_en": "Pose-Robust Calibration Strategy for Point-of-Gaze Estimation on Mobile Phones", "authors": "Yujie Zhao,Jiabei Zeng,Shiguang Shan", "background": "尽管基于外观的目标点估计已经有所改进，但估计器仍然难以在个人之间泛化，因为存在个体差异。因此，为了实现准确的目标点估计，需要针对每一个人进行特定校准。然而，校准后的估计器往往对头部姿态变化敏感。为解决此问题，本文研究影响校准估计器的关键因素，并探索抗姿态变化的校准策略。", "innovation": "本文构建了一个基准，MobilePoG，其中包括32个人在不同固定或连续变化头部姿态下的面部图像。使用该基准，系统地分析校准点和头部姿态多样性对估计精度的影响。研究表明，校准过程中引入更多的头部姿态变化可以提高估计器处理姿态变化的能力。基于此，本文提出了一个动态校准策略，在用户移动手机进行注视校准时，自然引入头部姿态变化，从而产生一个对头部姿态变化不那么敏感的目标点估计器。", "conclusion": "该策略使得校准过程既用户友好又高效，最终产生的校准目标点估计器比传统校准策略下的估计器更为稳健。相关代码和数据集可在本项目页面上获取。"}
{"llm_update_time": "20250815", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.10280", "html_url": "https://arxiv.org/abs/2508.10280", "title": "基于对比对齐和结构引导的高保真文本到图像生成", "title_en": "High Fidelity Text to Image Generation with Contrastive Alignment and Structural Guidance", "authors": "Danyi Gao", "background": "现有基于文本的图像生成方法面临着在语义对齐准确性和结构一致性方面的性能瓶颈。该研究旨在通过融合文本图像对比约束和结构引导机制来改进高保真图像生成方法。", "innovation": "提出了一种高保真图像生成方法，通过引入对比学习模块构建强跨模态对齐约束以提高语义匹配，并使用语义布局图或边缘草图等结构先验在空间层面引导生成器进行结构建模。模型联合优化对比损失、结构一致性损失和语义保留损失，并采用多目标监督机制提高生成内容的语义一致性与可控性。", "conclusion": "该方法在COCO-2014数据集上进行了系统性实验，从嵌入维度、文本长度和结构引导强度方面进行了敏感性分析，定量指标证实了该方法在CLIP Score、FID和SSIM方面的优越性能。结果表明，该方法有效解决了语义对齐和结构保真度之间的差距，不增加计算复杂性，能够生成语义清晰、结构完整的图像，为联合文本图像建模和图像生成提供了一种可行的技术路径。"}
{"llm_update_time": "20250815", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2505.13109", "html_url": "https://arxiv.org/abs/2505.13109", "title": "FreeKV：提高KV缓存检索以实现高效的大规模语言模型推理", "title_en": "FreeKV: Boosting KV Cache Retrieval for Efficient LLM Inference", "authors": "Guangda Liu,Chengwei Li,Zhenyu Ning,Minyi Guo,Jieru Zhao", "background": "大规模语言模型（LLMs）正被广泛部署，通过快速扩展上下文窗口来支持日益复杂的应用。然而，长上下文导致了重要的部署挑战，尤其是在大小与上下文长度成正比的KV缓存方面。尽管提出了KV缓存压缩方法来解决这一问题，但丢弃KV的方法会导致显著的准确性损失，而KV检索方法则面临效率瓶颈。", "innovation": "FreeKV提出了一种算法与系统协同优化框架，旨在提高KV检索效率同时保持准确性。在算法方面，FreeKV引入了推测检索，将KV选择和召回过程移出关键路径，并结合了精细粒度的校正以确保准确性。在系统方面，FreeKV在CPU和GPU内存中采用了混合KV布局，以消除碎片化数据传输，并利用双缓冲流式检索来进一步提高效率。", "conclusion": "实验表明，FreeKV在各种场景和模型中几乎不会损失准确性，相对于最先进的KV检索方法可以实现高达13倍的加速。"}
{"llm_update_time": "20250815", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.10281", "html_url": "https://arxiv.org/abs/2508.10281", "title": "VIFSS: 视角不变且花样滑冰特定的姿态表示学习方法用于时序动作分割", "title_en": "VIFSS: View-Invariant and Figure Skating-Specific Pose Representation Learning for Temporal Action Segmentation", "authors": "Ryota Tanaka,Tomohiro Suzuki,Keisuke Fujii", "background": "理解视频中的人体动作在各个领域都起着关键作用，包括体育分析。在花样滑冰中，准确识别滑冰者执行的跳跃类型和时间对于客观的成绩评价至关重要。然而，执行这一任务通常需要专家级别的知识，因为跳跃过程本身具有细微复杂的特性。最近，尽管已经尝试使用时序动作分割（TAS）来自动化这一任务，但TAS方法仍存在两个主要局限性：标注数据不足，以及现有方法未能考虑跳跃动作固有的三维特性和顺序结构。", "innovation": "本文提出了一种新的TAS框架，专为花样滑冰跳跃设计，明确地结合了三维特性和跳跃动作的语义顺序结构。首先，提出了一种新的视角不变、花样滑冰特定的姿态表示学习方法，VIFSS，该方法结合了对比学习作为预训练和动作分类作为微调。通过构建第一个专注于花样滑冰跳跃的公开三维姿态数据集FS-Jump3D，实现了视图不变的对比预训练。其次，引入了细致的手动标注方案，标记了“进入”和“着陆”阶段，使得TAS模型能够学习跳跃的动作顺序结构。实验结果表明了该框架的有效性。本方法在元素级TAS上达到了超过92%的F1@50，且在有限的标记数据场景中，视图不变构建的对比学习预训练表现出特别的有效性。", "conclusion": "本文通过引入VIFSS方法，提出了一种新的TAS框架，有效地解决了花样滑冰跳跃的自动化识别问题。该方法不仅在理论上具有创新性，还在实际应用中展现出了潜在的价值。"}
{"llm_update_time": "20250815", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.10297", "html_url": "https://arxiv.org/abs/2508.10297", "title": "InterSyn：野生动态运动合成的交错学习", "title_en": "InterSyn: Interleaved Learning for Dynamic Motion Synthesis in the Wild", "authors": "Yiyi Ma,Yuanzhi Liang,Xiu Li,Chi Zhang,Xuelong Li", "background": "当前的研究和方法主要以分别处理单一人物和多人动态运动的方式生成现实的互动动作。然而，这种方法未能充分捕捉到真实世界场景中的自然、动态交互和精细协调。", "innovation": "提出了一种新的框架——Interleaved Learning for Motion Synthesis（InterSyn），采用交错学习策略，同时考虑单一人物和多人的动态，统一建模个人和交互行为，以支持多角色互动，并通过相对协调细化模块来确保角色之间的同步运动。", "conclusion": "实验结果显示，InterSyn 生成的动作序列在文本到运动匹配和多样性方面优于现有方法，有助于自然且稳健的运动合成，并未未来的研究和发展开源了代码，期望促进该领域进一步的研究和开发。"}
{"llm_update_time": "20250815", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.10287", "html_url": "https://arxiv.org/abs/2508.10287", "title": "JRDB-Reasoning: 机器人视觉推理中按难度分级的基准", "title_en": "JRDB-Reasoning: A Difficulty-Graded Benchmark for Visual Reasoning in Robotics", "authors": "Simindokht Jahangard,Mehrzad Mohammadi,Yi Shen,Zhixi Cai,Hamid Rezatofighi", "background": "近年来，视觉语言模型（VLMs）和大型语言模型（LLMs）的进步显著提升了视觉推理能力，这是类Embodied AI代理（如机器人）的关键能力。然而，现有的视觉推理基准存在一些局限性：缺乏清晰的推理复杂度定义，无法控制生成不同难度和任务定制的问题，且没有提供结构化的、分步骤的推理注释（工作流程）.", "innovation": "本文正式化了推理复杂度，引入了自适应查询引擎，该引擎可以生成具有详细中间注释的各种复杂度的可定制问题，并将JRDB数据集扩展为包括人类-物体交互和几何关系注释的JRDB-Reasoning基准，旨在为拥挤环境中的视觉推理提供定制评估。", "conclusion": "本文的引擎和基准框架使视觉推理框架能够进行精细的评估，并且可以动态地评估视觉语言模型在不同推理级别中的性能。"}
{"llm_update_time": "20250815", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.10339", "html_url": "https://arxiv.org/abs/2508.10339", "title": "概念还是技能？多模态模型指令选择的重新思考", "title_en": "Concepts or Skills? Rethinking Instruction Selection for Multi-modal Models", "authors": "Andrew Bai,Justin Cui,Ruochen Wang,Cho-Jui Hsieh", "background": "视觉-语言基准主要从具有相似技能或视觉概念的指令中受益。现有的训练数据选择方法没有充分利用这一点。", "innovation": "提出了一种简单的目标训练数据选择方法，旨在优化多模态模型的特定基准性能。该方法首先从基准中提取概念/技能，确定基准主要受益于相似的概念或技能，并最终选择最匹配的概念/技能的指令。", "conclusion": "实验验证了该目标数据选择方法的有效性，提高了所有基准的性能，特别是在技能集中的子集上提高了1.5%。研究强调了识别指令选择内在权衡的重要性，需要在概念知识获取和视觉技能之间取得平衡。"}
{"llm_update_time": "20250815", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.10309", "html_url": "https://arxiv.org/abs/2508.10309", "title": "从像素到掩码：分布式外检测分割综述", "title_en": "From Pixel to Mask: A Survey of Out-of-Distribution Segmentation", "authors": "Wenjie Zhao,Jia Li,Yunhui Guo", "background": "随着对AI安全的关注增加，分布式外检测（OoD）检测和分割吸引了越来越多的关注。传统的OoD检测方法能够识别未知分布对象的存在，但缺乏空间定位能力，这限制了它们在下游任务中的应用。OoD分割通过像素级的定位克服了这一限制，这对于自动驾驶等安全关键应用至关重要。感知模块不仅需要检测OoD对象，还需要精确地分割这些对象，以实现有针对性的控制行为，并增强整体系统的鲁棒性。", "innovation": "本文将现有的OoD分割方法分为四类：（i）测试时的OoD分割，（ii）监督训练中的离群点暴露，（iii）基于重建的方法，（iv）利用强大模型的方法。该综述详细回顾了在自动驾驶场景下的OoD分割最新进展，指出了新兴挑战，并讨论了具有前景的未来研究方向。", "conclusion": "本文系统地回顾了自动驾驶场景下的OoD分割进展，识别了出现的新挑战，并讨论了未来的研究方向。"}
{"llm_update_time": "20250815", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.10294", "html_url": "https://arxiv.org/abs/2508.10294", "title": "亚像素多模态光学遥感图像配准方法", "title_en": "A Sub-Pixel Multimodal Optical Remote Sensing Images Matching Method", "authors": "Tao Huang,Hongbo Pan,Nanxi Zhou,Shun Zhou", "background": "多模态光学图像的高精度配准是几何处理的基础。然而，由于不同光谱响应导致的非线性辐射和几何变形差异，图像配准的精度通常会受到影响。为了应对上述问题，本文提出了一种相位一致性加权最小绝对偏差(PCWLAD)亚像素模板匹配方法，以提高多模态光学图像的匹配精度。该方法分为两个主要步骤：粗匹配和细匹配。粗匹配步骤使用结构相似性指数(SSIM)进行匹配；细匹配步骤基于粗匹配结果应用辐射和几何变形模型，并使用互结构滤波器来处理噪声影响，最后使用最小绝对偏差(WLAD)准则估算亚像素偏移量。为了评估PCWLAD的整体性能，作者构建了几种类型的数据集，包括可见光到红外Landsat图像、可见光到近红外近距离图像和可见光到红外无人机(UAV)图像，并与其他八种现有最先进的方法进行了比较，结果表明PCWLAD在正确匹配率(CMR)和均方根误差(RMSE)方面具有优越性，匹配精度达到了约0.4像素的水平。此外，研究中的软件和数据集已公开发布。", "innovation": "本文提出了相位一致性加权最小绝对偏差(PCWLAD)亚像素模板匹配方法。该方法首先通过结构相似性指数(SSIM)进行粗匹配，保留原始结构细节；然后基于粗匹配结果使用辐射和几何变换模型进行细匹配，并引入互结构滤波器来减弱模板内部噪声对结构一致性的影响，最后使用最小绝对偏差(WLAD)准则估计亚像素偏移量。这种方法能够提高多模态光学图像的配准精度。", "conclusion": "文章构建了不同类型的数据集来评估PCWLAD方法，验证了其在处理多模态光学遥感图像配准时的有效性。相对于现有先进的方法，PCWLAD在正确匹配率和均方根误差方面表现出更好的性能，其平均匹配精度达到约0.4像素。此外，该研究中的软件和数据集已经公开提供，可以供其他研究者使用和参考。"}
{"llm_update_time": "20250815", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.10232", "html_url": "https://arxiv.org/abs/2508.10232", "title": "CellSymphony: 利用单细胞病理组学解析细胞的分子和表型调控", "title_en": "CellSymphony: Deciphering the molecular and phenotypic orchestration of cells with single-cell pathomics", "authors": "Paul H. Acosta,Pingjun Chen,Simon P. Castillo,Maria Esther Salvatierra,Yinyin Yuan,Xiaoxi Pan", "background": "尽管组织学图像富含丰富的形态信息，但提取稳健的细胞级特征并将其与空间转录组学数据整合仍然是一个关键挑战。Xenium，一种新的空间转录组学平台，使得复杂肿瘤组织中亚细胞分辨率的表型分析成为可能。", "innovation": "CellSymphony提供了一个灵活的多模态框架，结合了Xenium转录组学档案和组织学图像在真正单细胞分辨率下的基础模型生成的嵌入，通过学习将空间基因表达与形态学上下文融合的联合表示，实现了准确的细胞类型注释，并揭示了三种癌症类型中的独特微环境微生态位。", "conclusion": "这项工作突显了基础模型和多模态融合在解析复杂组织生态系内细胞的生理与表型调控潜力。"}
{"llm_update_time": "20250815", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.10351", "html_url": "https://arxiv.org/abs/2508.10351", "title": "Glo-DMU: 肾小球电子显微镜图像中超结构表型特征的深度形态度量框架", "title_en": "Glo-DMU: A Deep Morphometry Framework of Ultrastructural Characterization in Glomerular Electron Microscopic Images", "authors": "Zhentai Zhang,Danyi Weng,Guibin Zhang,Xiang Chen,Kaixing Long,Jian Geng,Yanmeng Lu,Lei Zhang,Zhitao Zhou,Lei Cao", "background": "超结构的复杂多样性可以反映肾脏疾病的类型、进展和预后。近年来，结合深度学习方法的计算病理学在推进肾小球超结构的自动形态分析方面显示出巨大的潜力。然而，现有研究主要集中在超结构识别上，难以满足实际诊断需求。因此，传统肾活检诊断中需要同时评估三个最常用的超结构特征：肾小球基底膜厚度、足突消失程度以及电子沉积物的位置，当前方法无法全面准确地完成这项任务。", "innovation": "本文提出了一种基于三维深度模型的肾小球超结构表型（Glo-DMU）框架，该框架能够自动同时量化三个关键超结构特征：肾小球基底膜厚度、足突消失程度和电子沉积物的位置。Glo-DMU的特点是实现全面自动化、高精度和高通量，能够在实际诊断场景中高效辅助肾脏病理学家的工作，提高诊断效率和准确性。", "conclusion": "Glo-DMU通过同时量化三个关键超结构特征，展示了良好的自动量化结果与病理报告中形态描述的一致性。该框架适用于临床诊断，能够协助肾脏病理专家提高诊断效率和准确性，达到了全面自动化、高精度和高通量的要求。"}
{"llm_update_time": "20250815", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.10367", "html_url": "https://arxiv.org/abs/2508.10367", "title": "多模态视觉-语言模型的对比敏感度函数", "title_en": "Contrast Sensitivity Function of Multimodal Vision-Language Models", "authors": "Pablo Hernández-Cámara,Alexandra Gomez-Villa,Jose Manuel Jaén-Lorites,Jorge Vila-Tomás,Jesus Malo,Valero Laparra", "background": "评估多模态视觉-语言模型（VLMs）与人类感知的一致性是理解这些模型如何感知低级视觉特征的关键。人类视觉的一个关键特征是对比敏感度函数（CSF），它描述了在不同低对比度下对空间频率的敏感性。现有方法不能充分模拟人类的CSF特性，因此需要一种新的方法来评估这些模型的CSF特性。", "innovation": "本文提出了一种新的基于行为的心理物理学方法来估算基于聊天的VLMs的CSF，通过直接提示它们在不同对比度下的模式可见性来评估每个频率的CSF。这种方法比之前的报告更接近真正的心理物理学实验。通过使用带通滤波噪声图像和多样化的提示，评估了多种架构下的模型响应，并发现虽然一些模型接近人类的CSF形状或幅度，但没有一个完全复制两者。提示表达方式对响应有显著影响，这引发了对提示稳定性的担忧。", "conclusion": "本文提供了一种新的框架来探究多模态模型的视觉敏感性，并揭示了它们的视觉表示与人类感知之间的重要差距。"}
{"llm_update_time": "20250815", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.10397", "html_url": "https://arxiv.org/abs/2508.10397", "title": "PQ-DAF: 基于姿态驱动的质量控制数据增强方法在数据稀缺驾驶分心检测中的应用", "title_en": "PQ-DAF: Pose-driven Quality-controlled Data Augmentation for Data-scarce Driver Distraction Detection", "authors": "Haibin Sun,Xinghui Song", "background": "驾驶分心检测对于提升交通安全和减少道路事故至关重要。然而，现有模型在实际应用中常常因为数据标注成本高昂及训练数据集与目标部署环境之间存在显著差异而导致泛化能力下降。", "innovation": "提出了一种基于姿态驱动的质量控制数据增强框架（PQ-DAF），通过利用视觉-语言模型进行样本筛选以经济高效地扩展训练数据并增强跨域鲁棒性。具体地，使用渐进条件扩散模型（PCDMs）准确捕捉关键驾驶员姿态特征并合成多样化训练样本。基于Confidence阈值构建样本质量评估模块，筛选低质量的合成样本以确保增强数据集的可靠性。", "conclusion": "大量实验表明，PQ-DAF显著提高了少量数据条件下的驾驶分心检测性能，特别是在数据稀缺的情况下取得了显著的泛化性能提升。"}
{"llm_update_time": "20250815", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.10316", "html_url": "https://arxiv.org/abs/2508.10316", "title": "将强化学习与视觉生成模型集成：基础与进展", "title_en": "Integrating Reinforcement Learning with Visual Generative Models: Foundations and Advances", "authors": "Yuanzhi Liang,Yijie Fang,Rui Li,Ziqi Ni,Ruijie Su,Chi Zhang,Xuelong Li", "background": "生成模型在合成视觉内容方面取得了显著进展，包括图像、视频和3D/4D结构。然而，它们通常采用似然性或重构损失等代理目标进行训练，这往往与感知质量、语义准确性或物理现实性不一致。强化学习提供了一种有原则的框架来优化非可微分、偏好导向和时间结构化的目标。最近的研究表明，它在增强可控性、一致性和与人类的对齐方面对于生成任务的有效性得到了证实。本文提供了一种系统性概述，探讨了基于强化学习的视觉内容生成方法。本文回顾了从经典控制到作为一个通用优化工具的强化学习的演变，以及它们在图像、视频和3D/4D生成中的集成。在整个这些领域，强化学习不仅作为微调机制，也是一种构建生成与复杂高级目标对齐的结构组件。", "innovation": "强化学习提供了一种优化非可微分、偏好导向和时间结构化目标的框架，增强了可控性、一致性和与人类的对齐，适用于多种生成任务。本文系统地概述了强化学习在视觉内容生成中的应用，包括从经典控制到作为通用优化工具的角色转变及其在图像、视频和3D/4D生成中的集成，证明了强化学习在生成模型中的有效性和重要性，并提出了交叉领域中的开放挑战和未来研究方向。", "conclusion": "本文总结了基于强化学习的视觉内容生成方法，强调强化学习在优化非可微分、偏好导向和时间结构化的生成目标方面的有效性。同时，本文指出了强化学习与生成模型交汇领域中的开放挑战，并为未来的研究方向提供了指导。"}
{"llm_update_time": "20250815", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.10359", "html_url": "https://arxiv.org/abs/2508.10359", "title": "AtomDiffuser：用于STEM成像中漂移和束损伤时间感知退化建模的方法", "title_en": "AtomDiffuser: Time-Aware Degradation Modeling for Drift and Beam Damage in STEM Imaging", "authors": "Hao Wang,Hongkui Zheng,Kai He,Abolfazl Razi", "background": "扫描透射电子显微镜(STEM)在现代材料科学中起着关键作用，它能够直接成像原子结构及其在外来干扰下的变化。然而，解释时间分辨STEM数据仍然具有挑战性，因为存在两种纠缠的退化效应：由机械和热不稳定性的空间漂移，以及辐射损伤引起的信号损失。这些因素以复杂且时间相关的方式扭曲几何性和强度，使得现有方法难以明确分离这些效应或在原子分辨率下建模材料动力学。", "innovation": "我们提出了一种时间感知退化建模框架AtomDiffuser，它通过预测任意两个STEM帧间的仿射变换和空间变化衰减图来分离样品漂移和辐射衰减。该方法不同于传统的去噪或配准管道，充分利用退化作为物理驱动的、时间条件的过程，以实现时间上的可解释的结构演化。通过对合成退化过程的训练，AtomDiffuser在现实世界的冷冻STEM数据上也能很好地泛化，并支持高分辨率退化推理和漂移对齐，提供与辐射引起的原子不稳定性相关联的退化模式的可视化和量化工具。", "conclusion": "AtomDiffuser能够有效地分离空间漂移和辐射衰减对STEM数据的影响，通过预测变化图实现高分辨率的退化推理和漂移校正，为研究材料演化提供了新的方法，特别是对于辐射引起的原子不稳定性的可视化和量化有了显著提升。"}
{"llm_update_time": "20250815", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.10382", "html_url": "https://arxiv.org/abs/2508.10382", "title": "在推断场景属性中朝着时空一致图像生成的方向：将内在场景属性整合到扩散模型", "title_en": "Towards Spatially Consistent Image Generation: On Incorporating Intrinsic Scene Properties into Diffusion Models", "authors": "Hyundo Lee,Suhyung Choi,Byoung-Tak Zhang,Inwoo Hwang", "background": "基于大型数据集训练的图像生成模型可以合成高质量的图像，但由于对底层结构和空间布局的信息有限，通常会产生空间不一致和失真的图像。现有的方法要么仅依赖图像-文本对，要么使用内在属性作为条件输入，并未有效利用内在场景属性提供的丰富信息来提升生成图像的空间一致性。", "innovation": "该研究通过利用先验估计器从大型图像数据集中提取丰富的内在场景属性，并借助自编码器将这些属性整合到一个潜变量中。基于预训练的大规模潜扩散模型（LDMs），该方法同时对图像和内在领域进行去噪，同时确保图像质量和内在属性的互为反映。该方法能够纠正空间不一致性，生成更自然的场景布局，并保持基础模型（如Stable Diffusion）的保真度和文本对齐性。", "conclusion": "实验结果表明，该方法能够纠正空间不一致性，生成更自然的场景布局，同时保持基础模型的保真度和文本对齐性。"}
{"llm_update_time": "20250815", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.10407", "html_url": "https://arxiv.org/abs/2508.10407", "title": "通过delta向量转换文本嵌入以抑制文本到图像扩散模型中的强纠缠内容", "title_en": "Translation of Text Embedding via Delta Vector to Suppress Strongly Entangled Content in Text-to-Image Diffusion Models", "authors": "Eunseo Koh,Seunghoo Hong,Tae-Young Kim,Simon S. Woo,Jae-Pil Heo", "background": "文本到图像（T2I）扩散模型在从文本提示生成多样且高质量图像方面取得了显著进步。然而，这些模型在抑制强烈关联于特定词汇的具体内容方面仍面临挑战。例如，在生成关于查理·卓别林的图像时，即使明确指示不要包括，文本“胡须”也会在生成的图像中持续出现，因为“胡须”与“查理·卓别林”之间存在强烈的联系。", "innovation": "提出了一个新的方法，直接在扩散模型的文本嵌入空间中抑制这种纠缠的内容。该方法引入了一个delta向量，用于修改文本嵌入，从而减弱对生成图像中不需要内容的影响。此外，还提出了一种选择性抑制带delta向量（SSDV）方法，将delta向量集成到交叉注意机制中，以更有效的方式抑制可能生成的不需要内容。并通过优化delta向量提高了个性化T2I模型的精确抑制能力，这是之前基线无法实现的。", "conclusion": "广泛的实验结果表明，本方法在定量和定性指标方面显著优于现有方法，展示了其在抑制强纠缠内容方面的优越性能。"}
{"llm_update_time": "20250815", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.10383", "html_url": "https://arxiv.org/abs/2508.10383", "title": "通过仅标签弹性变形解锁稳健的语义分割性能以对抗隐式标签噪声", "title_en": "Unlocking Robust Semantic Segmentation Performance via Label-only Elastic Deformations against Implicit Label Noise", "authors": "Yechan Kim,Dongho Yoon,Younkwan Lee,Unse Fatima,Hong Kook Kim,Songjae Lee,Sanga Park,Jeong Ho Park,Seonjong Kang,Moongu Jeon", "background": "以往关于图像分割的研究主要集中在处理严重的标签噪声，而忽视了真实世界数据集中存在的轻微或隐性的标签不完善现象。这些不完善来源于对象边界模糊和标注者主观差异等内在挑战，尽管不是显而易见的，但仍会影响模型的性能。传统的数据增强方法会对图像及其标签应用相同的变化，这可能放大微妙的不完美，从而限制模型的泛化能力。", "innovation": "本文提出了一种名为NSegment+的新增广框架，该框架将图像和标签的变换解耦，以应对语义分割中的真实噪声。通过仅对分割标签应用受控的弹性变形，同时保持原始图像不变，方法促使模型专注于学习稳健的对象结构表示，即使存在微小的标签不一致问题也能增强模型的理解能力。", "conclusion": "大量的实验表明，NSegment+能够在Vaihingen、LoveDA、Cityscapes和PASCAL VOC等不同数据集上实现mIoU的稳步提升，分别为+2.29、+2.38、+1.75和+3.39。这一改进甚至在不使用额外训练技巧的情况下依然突出，强调了应对隐式标签噪声的重要性。当与CutMix和Label Smoothing等其他训练技巧结合使用时，性能提升更加显著。"}
{"llm_update_time": "20250815", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.10411", "html_url": "https://arxiv.org/abs/2508.10411", "title": "SC-Lane: 斜坡感知且具时序一致性的道路高度估计框架用于3D车道检测", "title_en": "SC-Lane: Slope-aware and Consistent Road Height Estimation Framework for 3D Lane Detection", "authors": "Chaesong Park,Eunbin Seo,Jihyeon Hwang,Jongwoo Lim", "background": "当前3D车道检测方法大多依赖固定斜率锚点，对于不同道路几何形状的鲁棒性不足。本文提出的SC-Lane通过动态预测不同斜率的信息的权重，实现了斜率感知的高度图估计，并通过时序一致性模块保证了高度估计的稳定性和准确性。", "innovation": "SC-Lane引入了Slope-Aware Adaptive Feature模块，能够动态预测多斜率特征的融合权重，提高了对多样道路几何的鲁棒性。此外，通过Height Consistency Module来确保高度估计在连续帧之间的时序一致性。实验表明，这种新颖的框架在常用的评价指标（MAE, RMSE, 阈值准确率）上表现优越，尤其是在路面高度估计方面。", "conclusion": "在OpenLane标识集上的实验证明，SC-Lane在高度估计和3D车道检测方面有显著改进，F-score达到64.3%，优于现有方法。本文使用馈线雷达高度图数据集建立了严格的标准，为未来的比较提供了基础。"}
{"llm_update_time": "20250815", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.10424", "html_url": "https://arxiv.org/abs/2508.10424", "title": "NanoControl：一种轻量级框架以实现扩散变换器中的精确高效控制", "title_en": "NanoControl: A Lightweight Framework for Precise and Efficient Control in Diffusion Transformer", "authors": "Shanyuan Liu,Jian Zhu,Junda Lu,Yue Gong,Liuzhuozheng Li,Bo Cheng,Yuhang Ma,Liebucha Wu,Xiaoyu Wu,Dawei Leng,Yuhui Yin", "background": "扩散变换器（DiTs）在文本生成图像方面展示了出色的能力。然而，在使用扩散变换器进行可控的文本生成图像方面，大多数现有的方法仍然依赖于原始设计用于UNet型扩散模型的ControlNet范式。这种方法带来了大量的参数开销和更高的计算成本。", "innovation": "本文提出了一种名为Nano Control Diffusion Transformer（NanoControl）的模型，采用Flux作为主干网络。NanoControl仅增加0.024%的参数量和0.029%的GFLOPs，即可达到最先进的可控文本生成图像性能，从而使可控生成更加高效。具体而言，NanoControl创新在于设计一种LoRA风格的控制模块，该模块能够直接从原始条件输入中学习控制信号，没有像ControlNet那样复制扩散变换器的主干网络。此外，还引入了一种KV-Context Augmentation机制，该机制以简单而高效的方式将条件特定的关键值信息集成到主干网络中，促进条件特征的深层次融合。", "conclusion": "基准实验表明，NanoControl相比于传统的控制方法，显著减少了计算开销，同时保持了出色的生成质量和提高了可控性。"}
{"llm_update_time": "20250815", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.10432", "html_url": "https://arxiv.org/abs/2508.10432", "title": "基于对比残差注入和语义提示的持续视频实例分割CRISP", "title_en": "CRISP: Contrastive Residual Injection and Semantic Prompting for Continual Video Instance Segmentation", "authors": "Baichen Liu,Qi Lyu,Xudong Wang,Jiahua Dong,Lianqing Liu,Zhi Han", "background": "持续视频实例分割需要在吸收新的对象类别和保留之前学习的内容的同时保持时间一致性。现有方法在处理实例级别、类别级别和任务级别上的混淆时存在不足。本文旨在解决这些问题，通过引入对比残差注入和语义提示(CRISP)方法来优化持续视频实例分割任务的性能。", "innovation": "对于实例级别的学习，提出了实例跟踪方法和实例相关性损失，强调与先验查询空间的相关性，增强当前任务查询的特定性。针对类别级别的学习，构建了一个自适应残差语义提示学习框架，生成一个可学习的语义残差提示池，并使用可调节查询-提示匹配机制构建当前任务查询与语义残差提示之间的映射关系。同时引入基于对比学习的语义一致性损失来保持对象查询和残差提示之间的语义一致性。对于任务级别的学习，引入了一种简洁而强大的增量提示初始化策略，确保查询空间内不同任务间的联系。实验表明，CRISP方法在YouTube-VIS-2019和YouTube-VIS-2021数据集上的性能显著优于现有持续分割方法，能够有效防止灾难性遗忘并提高分割和分类性能。", "conclusion": "持续视频实例分割方法CRISP显著提高了长期持续视频实例分割任务中的性能，避免了灾难性遗忘，并有效提高了分割和分类性能。"}
{"llm_update_time": "20250815", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.10445", "html_url": "https://arxiv.org/abs/2508.10445", "title": "DOD-SA: 使用单一模态注解的红外-可见光解耦目标检测", "title_en": "DOD-SA: Infrared-Visible Decoupled Object Detection with Single-Modality Annotations", "authors": "Hang Jin,Chenqiang Gao,Junjie Guo,Fangcen Liu,Kanghui Tian,Qinyao Chang", "background": "红外-可见光目标检测在实际应用中表现出巨大潜力，能够利用红外和可见光图像的互补信息实现全天候感知。然而，现有的方法通常需要双模态注解来预测和输出两个模态的检测结果，这会增加注解成本。为了解决这一挑战，本文提出了一种基于单模态和双模态协作教师-学生网络的新型红外-可见光解耦目标检测框架，称为DOD-SA。该框架能够利用单模态注解来实现双模态的解耦检测，有效降低了注解成本。", "innovation": "本文提出了DOD-SA框架，其创新点在于采用了单一模态注解方式，通过单模态和双模态协作教师-学生网络，实现可靠的红外-可见光解耦目标检测。引入了渐进式和自调训练策略(PaST)，以及伪标签分配器(PLA)，进一步提高了模型的解耦能力和伪标签质量。", "conclusion": "在DroneVehicle数据集上的广泛实验表明，本文提出的方法在解耦目标检测方面显著优于现有最佳方法。"}
{"llm_update_time": "20250815", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.10450", "html_url": "https://arxiv.org/abs/2508.10450", "title": "从图像到感知：通过重建图像来生成感知属性", "title_en": "From Images to Perception: Emergence of Perceptual Properties by Reconstructing Images", "authors": "Pablo Hernández-Cámara,Jesus Malo,Valero Laparra", "background": "许多科学家提出，人类的视觉感知可能源于图像统计，从而形成早期视觉中高效神经表征。研究表明，生物启发的架构中，PerceptNet 可以同时适应已知的视网膜-V1 大脑皮层原理。该模型已全端优化，适用于不同与图像重建相关任务：自编码、去噪、去模糊化及稀疏正则化。", "innovation": "PerceptNet 虽然在初始化和训练中未使用感知信息，但其编码阶段（类似 V1 的层）在图像失真感知判断中表现出最高的一致性。这种一致性在适度的噪声、模糊和稀疏性水平时达到最优。这表明，视觉系统可能会针对特定的失真水平来调整以去除特定的稀疏性水平。该研究还表明，采用生物启发的模型可以在无需人类监督的情况下学习感知度量。", "conclusion": "这项研究提出，视觉系统可能被调整以自动去除特定的图像失真程度和稀疏性，且基于生物学的模型可以在无监督的情况下学习感知度量。PerceptNet 的编码阶段的性能体现出对特定噪声、模糊及稀疏度的最佳匹配。"}
{"llm_update_time": "20250815", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.10457", "html_url": "https://arxiv.org/abs/2508.10457", "title": "增强元数据的多头视觉变换器在多标签植物种类预测中的应用", "title_en": "Multi-Label Plant Species Prediction with Metadata-Enhanced Multi-Head Vision Transformers", "authors": "Hanna Herasimchyk,Robin Labryga,Tomislav Prusina", "background": "该论文旨在解决PlantCLEF 2025挑战中的多标签植物种类预测问题。该任务要求在利用单一物种植物图像进行模型训练的同时，在多种类植物的图像上进行测试，这导致了一个显著的领域偏移。", "innovation": "本文的主要创新点包括：1）使用预训练的DINOv2视觉变换器基干（ViT-B/14），并用多个分类头进行物种、属和科的预测，利用分类学层次结构。2）采用多尺度镶嵌技术以捕捉不同尺度的植物。3）基于预测平均长度动态优化阈值。4）通过袋装和Hydra模型架构进行集成策略。5）结合多种推理技术，包括图像裁剪以去除非植物视觉干扰、Top-n筛选用于预测约束、以及logit阈值策略。", "conclusion": "实验基于约140万张训练图像（覆盖7806种植物），结果显示了较强的表现力，使我们的提交在私有评分榜上位列第3。我们将在以下链接提供代码：后面紧跟了一个外部链接地址。"}
{"llm_update_time": "20250815", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.10449", "html_url": "https://arxiv.org/abs/2508.10449", "title": "SkeySpot: 构建行业中的自动化服务关键检测以实现数字电气布局计划", "title_en": "SkeySpot: Automating Service Key Detection for Digital Electrical Layout Plans in the Construction Industry", "authors": "Dhruv Dosi,Rohit Meena,Param Rajpura,Yogesh Kumar Meena", "background": "在建筑行业中，留存下来的陈旧平面图通常仅以扫描文档的形式存在，对于建筑、城市规划和设施管理至关重要。然而，由于缺乏可机器读取的平面图，大规模解读变得既耗费时间又容易出错。自动符号识别通过直接从平面图中识别服务关键符号，提供了可扩展的解决方案，支持例如成本估算、基础设施维护和合规检查等工作流程。", "innovation": "本文介绍了名为 DELP（Digitised Electrical Layout Plans）的数据集，包含45个被注释的电气布局平面图，共包含2,450个实例，涉及34个不同的服务关键类别。提出了一种系统性的评估框架，使用预训练的目标检测模型对DELP数据集进行了基准测试，YOLOv8 模型表现出最佳性能，mAP 为 82.5%。基于该模型，开发了 SkeySpot，一个轻量级、开源工具包，用于实时检测、分类和量化电气符号，并生成结构化、标准化输出，支持建筑信息流程的可扩展应用，适用于下游应用及监管平台兼容性。此外，这种方法降低了对专有CAD系统的依赖性，减少了手动标注的工作量，使中小建筑企业能够更容易地实现电气布局的数字化，并支持了标准化、互操作性和建筑环境的可持续发展目标。", "conclusion": "SkeySpot 方案降低了建筑行业中小企业的对专有 CAD 系统的依赖，通过自动化服务关键符号的检测，使电气布局的数字化更加容易实现，并支持标准化、互操作性和可持续性目标。"}
{"llm_update_time": "20250815", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.10427", "html_url": "https://arxiv.org/abs/2508.10427", "title": "STRIDE-QA：城市驾驶场景中时空推理的视觉问答数据集", "title_en": "STRIDE-QA: Visual Question Answering Dataset for Spatiotemporal Reasoning in Urban Driving Scenes", "authors": "Keishi Ishihara,Kento Sasaki,Tsubasa Takahashi,Daiki Shiono,Yu Yamaguchi", "background": "视觉语言模型（VLMs）已被应用于自动驾驶，以支持在复杂现实场景中的决策。然而，这些模型主要基于静态的网络图像文本对进行训练，这限制了其进行精确的时空推理能力，这对于理解并预测动态交通场景是至关重要的。为了填补这一关键缺口，研究者构建了一个名为STRIDE-QA的数据集，这是一个大规模的基于物理接地的时空推理数据集，通过从东京的多传感器驾驶数据中获取内容，该数据集涵盖了多样且具有挑战性的环境条件，提供了独特的对象中心和以自我为中心的时空推理支持，包含超过1600万个问答对和285000帧的多对象跟踪，这使得模型能够在复杂的交通情况下精确地进行空间定位和未来动向预测。", "innovation": "STRIDE-QA数据集针对城市驾驶场景中时空推理的需求，从东京的多传感器驾驶数据中构建，包含了密集的自动标注，如3D边界框、分割掩码和多对象轨迹。这种数据集通过三个新颖的问答任务支持空间定位和时间预测。与现有的通用VLMs相比，通过在STRIDE-QA上进行微调的模型在空间定位和未来动向预测的准确性上有显著提高，证明了STRIDE-QA对于提升视觉语言模型时空推理能力的重要性。", "conclusion": "STRIDE-QA数据集为发展更可靠的情感化关键自主系统中的VLMs提供了全面的基础，证明了现有模型需要大量专门训练并在这种情况下更精确和更可靠的模型来实现精确的时空推理。"}
{"llm_update_time": "20250815", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.10453", "html_url": "https://arxiv.org/abs/2508.10453", "title": "基于轨迹感知偏移状态空间模型的在线视频超分辨率", "title_en": "Trajectory-aware Shifted State Space Models for Online Video Super-Resolution", "authors": "Qiang Zhu,Xiandong Meng,Yuxian Jiang,Fan Zhang,David Bull,Shuyuan Zhu,Bing Zeng", "background": "在线视频超分辨率（VSR）是许多实际视频处理应用的重要技术，旨在基于时间上先前的帧恢复当前的高分辨率视频帧。大多数现有的在线VSR方法仅利用一个邻近的前一帧实现时间对齐，这限制了视频的长时域建模能力。近年来，基于状态空间模型（SSMs）的方法被提出，具有线性计算复杂度和全局感受野，显著提高了计算效率和性能。", "innovation": "本文提出了一种基于轨迹感知偏移SSMs（TS-Mamba）的新型在线VSR方法，利用长期运动建模和低复杂度的Mamba实现高效的时空信息聚合。具体来说，TS-Mamba首先在视频中构造轨迹以选择最相似的前一帧中的令牌，然后采用一种包含提议偏移SSMs块的轨迹感知偏移Mamba聚合（TSMA）模块来聚合这些选择的令牌。偏移SSMs块基于Hilbert扫描和相应的偏移操作设计，以补偿扫描损失并增强Mamba的空间连续性。此外，我们提出了一种轨迹感知的损失函数来监督轨迹生成，以确保在训练模型时令牌选择的准确性。", "conclusion": "通过在三个广泛用于VSR测试数据集上的广泛实验表明，在大多数情况下，与六种在线VSR基准模型相比，我们的TS-Mamba具有最佳的性能，并且在MACs方面具有超过22.7%的复杂性降低。"}
{"llm_update_time": "20250815", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.10469", "html_url": "https://arxiv.org/abs/2508.10469", "title": "增强稀疏点云数据处理以实现隐私感知的人体动作识别", "title_en": "Enhanced Sparse Point Cloud Data Processing for Privacy-aware Human Action Recognition", "authors": "Maimunatu Tunau,Vincent Gbouna Zakka,Zhuangzhuang Dai", "background": "人体动作识别（HAR）在医疗保健、健身跟踪和辅助生活技术中起着重要作用。传统的基于视觉的HAR系统虽然有效，但会涉及隐私问题。毫米波雷达传感器提供了一种隐私保护替代方案，但其点云数据稀疏且噪声较大，给数据处理带来了挑战。已有文献中使用了三种主要的数据处理方法：基于噪声的应用的空间聚类（DBSCAN）、匈牙利算法和卡尔曼滤波，以提高雷达数据的质量和连续性，但对这些方法的全面评估仍显不足。因此，本次研究填补了这一空白，通过使用MiliPoint数据集对这些方法进行详细的性能分析。", "innovation": "本研究对DBSCAN、匈牙利算法和卡尔曼滤波三种常见数据处理方法进行了系统性的评估，包括分别应用、成对组合以及三者同时组合，以评估它们的识别准确性和计算成本。此外，还提出了针对这些方法的改进措施以提高准确性。", "conclusion": "研究结果提供了对每种方法及其组合的强项和折中条件的深刻见解，有助于未来毫米波基于HAR系统的研发。"}
{"llm_update_time": "20250815", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.10464", "html_url": "https://arxiv.org/abs/2508.10464", "title": "SingleStrip：从单个标注示例学习颅骨去除", "title_en": "SingleStrip: learning skull-stripping from a single labeled example", "authors": "Bella Specktor-Fadida,Malte Hoffmann", "background": "深度学习分割依赖于大量标注数据，而手动标注既耗时又耗力，特别是在处理如脑磁共振成像（MRI）等体数据时。现有技术虽然通过合成多样化的训练图像来减少对标注数据的依赖，但当可用的标注图很少时，这些技术提供的解剖变异度有限。半监督自我训练通过迭代地将模型预测结果纳入训练集，使网络能够从未标注的数据中学习，以应对标签稀缺的问题。", "innovation": "本文提出了一种结合领域随机化与自我训练的技术，能够在仅使用一个标注示例的情况下训练三维颅骨去除网络。该方法首先自动对体素强度进行分组，生成用于训练初始颅骨去除模型的标签。接着，使用标签示例训练卷积自编码器（AE），利用其重构误差评估未标注数据中脑掩码的质量。最后，选择最高评分的伪标签进行网络的微调，以实现接近使用更多标注图像训练的模型的颅骨去除性能。实验表明，基于AE的方法与分割准确性之间的相关性更强。研究结果强调结合领域随机化与基于AE的质量控制可以有效从极其有限的标注数据中实现半监督分割。", "conclusion": "我们的研究成果展示了结合领域随机化与基于自编码器的质量控制技术的潜力，这种技术能够在极少量标注数据的情况下实现有效的半监督分割。该策略可能有助于减轻标注负担，促进涉及新解剖结构或新兴成像技术的研究进展。"}
{"llm_update_time": "20250815", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.10498", "html_url": "https://arxiv.org/abs/2508.10498", "title": "TweezeEdit: 使用路径正则化的具有一致性和高效性的图像编辑", "title_en": "TweezeEdit: Consistent and Efficient Image Editing with Path Regularization", "authors": "Jianda Mao,Kaibo Wang,Yang Xiang,Kani Chen", "background": "现有的图像编辑技术通过文本指导使用户能够编辑图像，但这些方法往往过度关注目标提示而未能充分保留源图像的语义。现有的方法要么显式地，要么隐式地从源图像的反转噪声（称为反转锚点）中生成目标图像。我们意识到这种策略在语义保留方面不太理想，且存在路径冗余的问题。", "innovation": "我们提出了TweezeEdit框架，这是一种无需微调和反转的图像编辑框架，旨在提供一致和高效的图像编辑。我们的方法通过正则化整个去噪路径来解决这些限制，而不是仅仅依赖反转锚点，以确保源语义的保留并缩短编辑路径。我们利用梯度驱动的正则化，通过一致性模型高效地沿直接路径注入目标提示语义。", "conclusion": "通过广泛的实验，我们证明TweezeEdit在语义保留和目标对齐方面表现出色，超过了现有方法。值得注意的是，TweezeEdit只需要12步（每编辑一次需要1.6秒），表明其在实时应用中的潜力。"}
{"llm_update_time": "20250815", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.10507", "html_url": "https://arxiv.org/abs/2508.10507", "title": "多样本抗锯齿和约束优化在3D高斯绘制中的应用", "title_en": "Multi-Sample Anti-Aliasing and Constrained Optimization for 3D Gaussian Splatting", "authors": "Zheng Zhou,Jia-Chen Zhang,Yu-Jie Xiong,Chun-Ming Xia", "background": "近年来，3D高斯绘制在实时新视角合成方面取得了显著进步，但场景优化过程中存在的不足几何约束往往导致精细细节的模糊重建，特别是在高频纹理和尖锐不连续区域。", "innovation": "提出了一种综合多样本抗锯齿（MSAA）与双重几何约束的全面优化框架。该框架包括自适应加权策略和梯度差异约束，以优先处理欠重建区域并加强对象边界几何正则化，实现关键区域的优先精炼同时保持全局一致性。", "conclusion": "在多个基准测试中的广泛实验表明，该方法在细节保留方面达到了最先进的性能，尤其在高频纹理和尖锐不连续部分保留方面表现出色，同时保持实时渲染效率。定量指标和知觉研究证实了与基线方法相比，在结构相似性（SSIM）和感知质量（LPIPS）上的统计显著改进。"}
{"llm_update_time": "20250815", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.10473", "html_url": "https://arxiv.org/abs/2508.10473", "title": "STAMP: 多模式注意力感知的多实例学习在多中心组织病理图像中诊断STAS", "title_en": "STAMP: Multi-pattern Attention-aware Multiple Instance Learning for STAS Diagnosis in Multi-center Histopathology Images", "authors": "Liangrui Pan,xiaoyu Li,Guang Zhu,Guanting Li,Ruixin Wang,Jiadi Luo,Yaning Yang,Liang qingchun,Shaoliang Peng", "background": "STAS（通过气空间传播）在肺腺癌（LUAD）中是一种新的侵袭模式，与肿瘤复发和生存率降低有关。然而，大规模的STAS诊断在LUAD中是一个劳动密集型的过程，且由于其独特的病理特征和形态特征，容易出现疏漏和误诊。因此，迫切需要利用深度学习模型来进行STAS诊断。", "innovation": "提出了一个多模式注意力感知的多实例学习框架，STAMP。该框架具有双分支结构，可以从不同的语义空间中学习STAS相关的病理特征。利用基于变换器的实例编码和多模式注意力聚合模块动态选择与STAS病理紧密相关的区域，减少无关噪声，并增强全局表示的鉴别能力。此外，通过相似性正则化约束防止分支间特征冗余，从而提高整体诊断准确性。", "conclusion": "广泛的实验表明，STAMP模型在STAS-SXY、STAS-TXY和STAS-TCGA数据集上取得了可竞争的诊断结果，AUC值分别为0.8058、0.8017和0.7928，超过了临床水平。"}
{"llm_update_time": "20250815", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.10549", "html_url": "https://arxiv.org/abs/2508.10549", "title": "PSScreen: Partially Supervised Multiple Retinal Disease Screening", "title_en": "PSScreen: Partially Supervised Multiple Retinal Disease Screening", "authors": "Boyi Zheng,Qing Liu", "background": "现有的方法依赖于完全标注的数据集来训练模型进行视网膜疾病的筛查，但不同医疗站点的数据分布差异大，且部分类别的标签缺失，这使得模型在不同领域的泛化能力较低。", "innovation": "提出了一种新颖的半监督多视网膜疾病筛查模型PSScreen。该模型包含两条分支，分别学习确定性特征和概率性特征；通过特征蒸馏和文本指导将两种类型的特征解耦并对齐，增强模型的领域泛化能力；利用两分支之间的伪标签一致性解决标签缺失问题，并引入自我蒸馏将关于已知类别的任务相关信息从确定性分支传递到概率性分支，以进一步提高检测性能。", "conclusion": "实验结果表明，PSScreen在六种视网膜疾病及正常状态下均显著提高了检测性能，并在领域内和领域外数据集上达到了最先进的水平。"}
{"llm_update_time": "20250815", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.10509", "html_url": "https://arxiv.org/abs/2508.10509", "title": "一种用于螺栓缺陷增广和检测的分割驱动编辑方法", "title_en": "A Segmentation-driven Editing Method for Bolt Defect Augmentation and Detection", "authors": "Yangjie Xiao,Ke Zhang,Jiacun Wang,Xin Sheng,Yurong Guo,Meijuan Chen,Zehua Ren,Zhaoye Zheng,Zhenbing Zhao", "background": "螺栓缺陷检测对于确保输电线路的安全至关重要。然而，缺陷图像稀缺以及数据分布不平衡极大地限制了检测性能。因此，需要提出一种方法来增强数据集并提高检测性能。", "innovation": "提出了一种基于分割的螺栓缺陷编辑方法（SBDE），该方法通过CLPHE-FFT适配器（CFA）和多部分意识掩码解码器（MAMD）增强复杂螺栓属性的分割，生成高质量的掩码以进行后续编辑任务。同时，设计并集成了掩码优化模块（MOD）和图像修补模型（LaMa），构建了螺栓缺陷属性编辑模型（MOD-LaMa），通过属性编辑将正常螺栓转换为具有缺陷的螺栓。此外，还提出了编辑恢复增强（ERA）策略，用于将编辑后的缺陷螺栓恢复到原始检测场景，并扩展缺陷检测数据集。", "conclusion": "通过构建多个螺栓数据集并进行广泛实验，结果表明SBDE生成的螺栓缺陷图像明显优于最先进的图像编辑模型，并有效提高了螺栓缺陷检测性能。这充分验证了所提方法的有效性和应用潜力。"}
{"llm_update_time": "20250815", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.10528", "html_url": "https://arxiv.org/abs/2508.10528", "title": "Med-GLIP: 大规模标注数据推进医学语言-图像预训练", "title_en": "Med-GLIP: Advancing Medical Language-Image Pre-training with Large-scale Grounded Dataset", "authors": "Ziye Deng,Ruihan He,Jiaxiang Liu,Yuan Wang,Zijie Meng,Songtao Jiang,Yong Xie,Zuozhu Liu", "background": "医学图像定位旨在将自然语言短语与医学图像中的特定区域对齐，作为智能诊断、视觉问答（VQA）和自动化报告生成（MRG）的基础任务。然而，现有的研究受到模态覆盖有限、标注粗糙以及缺乏统一、可泛化的图像定位框架的限制。", "innovation": "本文构建了一个包含超过530万区域级别标注的大规模医学图像定位数据集Med-GLIP-5M，覆盖七种成像模态、多种解剖结构和病理发现。基于此，提出了Med-GLIP医学图像定位框架，采用模态感知方式训练，无需显式设计专家模块，通过多样化训练数据隐式获取层级语义理解，能够识别多粒度结构，如区分肺部与肺炎病灶。广泛实验表明，Med-GLIP在多个图像定位基准中性能超越最新基线。此外，将其实空间输出集成到下游任务（如医学VQA和报告生成）中，显著提高性能。", "conclusion": "实验结果表明，Med-GLIP在多个医学图像定位基准中表现出色，并且其空间输出在下游任务中表现出显著的性能提升。数据集将在不久后发布。"}
{"llm_update_time": "20250815", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.10542", "html_url": "https://arxiv.org/abs/2508.10542", "title": "GCRPNet: 图像增强上下文和区域感知网络在光学遥感图像显著目标检测中的应用", "title_en": "GCRPNet: Graph-Enhanced Contextual and Regional Perception Network For Salient Object Detection in Optical Remote Sensing Images", "authors": "Mengyu Ren,Yutong Li,Hua Li,Runmin Cong,Sam Kwong", "background": "光学遥感图像中的显著目标检测（SOD）面临诸多挑战，包括目标尺度的巨大变化和目标与背景之间的低对比度。现有的基于视觉变换器（ViTs）和卷积神经网络（CNNs）架构的方法旨在利用全局和局部特征，但由于有效地整合这些异构特征的难度较大，整体性能受限。", "innovation": "我们提出了一种称为图增强上下文和区域感知网络（GCRPNet）的模型，该模型基于Mamba架构，同时捕捉长程依赖关系并增强区域特征表示。通过采用视觉状态空间（VSS）编码器提取多尺度特征，进一步设计了一种差异相似性引导的层次图注意力模块（DS-HGAM），增强了不同尺度特征间的逐层交互能力，提高了模型的结构感知能力，从而更有效地区分前景和背景。此外，设计了包含自适应扫描策略和多粒度协作注意力增强模块（MCAEM）的LEVSS模块作为GCRPNet的解码器，通过多重卷积处理特征图后进行自适应块扫描，捕捉丰富的局部区域信息，增强Mamba的局部建模能力。", "conclusion": "广泛实验结果表明，所提出的模型达到了最先进的性能，验证了其有效性和优越性。"}
{"llm_update_time": "20250815", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.10522", "html_url": "https://arxiv.org/abs/2508.10522", "title": "EgoMusic驱动人体舞蹈动作估计与Skeleton Mamba", "title_en": "EgoMusic-driven Human Dance Motion Estimation with Skeleton Mamba", "authors": "Quang Nguyen,Nhat Le,Baoru Huang,Minh Nhat Vu,Chengcheng Tang,Van Nguyen,Ngan Le,Thieu Vo,Anh Nguyen", "background": "人体舞蹈动作的估计是一个具有多种工业应用的挑战性任务。近年来，许多研究集中在使用第一人称视角视频或音乐作为输入来预测人体舞蹈动作。然而，同时从第一人称视角视频和音乐中估计人体动作的任务尚未得到充分探索。本文旨在开发一种从第一人称视角视频和音乐中预测人体舞蹈动作的新方法。实践表明，第一人称视角常常使身体大部分被遮挡，使得准确的姿态估计变得困难。同时，要加入音乐，生成的头部和身体动作需要与视觉和音乐输入很好地对齐。因此，本文介绍了一个新的大规模数据集EgoAIST++，该数据集结合了第一人称视角和音乐，包含超过36小时的舞蹈动作。", "innovation": "本文开发了一种EgoMusic Motion Network，其中核心部分是Skeleton Mamba，它明确捕捉了人体骨骼结构。该网络结合了扩散模型和Mamba的成功，用于序列建模，并且提出了EgoAIST++数据集，该数据集结合了第一人称视角和音乐，包含超过36小时的舞蹈动作数据，以促进在第一人称视角视频和音乐中预测人体舞蹈动作的研究。实验表明，该方法明显优于最先进的方法，并且能够有效地泛化到真实世界的数据。", "conclusion": "本文提出的方法在预测人体舞蹈动作方面取得了明显的效果，并且该方法能够有效泛化到实际数据中。通过结合第一人称视角视频和音乐，该方法为未来在真实世界环境中预测人体舞蹈动作提供了新的可能性。"}
{"llm_update_time": "20250815", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.10523", "html_url": "https://arxiv.org/abs/2508.10523", "title": "计算机视觉中的推理：分类、模型、任务和方法", "title_en": "Reasoning in Computer Vision: Taxonomy, Models, Tasks, and Methodologies", "authors": "Ayushman Sarkar,Mohd Yamani Idna Idris,Zhenyu Yu", "background": "视觉推理对于超越表面对象检测和分类的广泛计算机视觉任务至关重要。尽管在关系推理、符号推理、时序推理、因果推理和常识推理方面取得了显著进展，但现有综述往往将这些方向孤立起来讨论，缺乏跨推理类型、方法和技术评估协议的统一分析和比较。", "innovation": "本文旨在通过将视觉推理分为五种主要类型（关系、符号、时序、因果、常识）并系统地分析其通过图模型、记忆网络、注意力机制和神经符号系统等架构的实现方式来填补这一空白。同时，我们回顾了用于评估功能正确性、结构一致性以及因果有效性的评估协议，并对其在可扩展性、可重复性和解释力方面的局限性进行了批判性分析。", "conclusion": "我们指出了视觉推理中的关键开放挑战，包括复杂场景的扩展性、符号和神经范式的深度融合、全面基准数据集的缺乏以及在弱监督下的推理。最终，我们提出了面向下一代视觉系统的前瞻研究议程，强调感知与推理相结合对于构建透明、可信和跨域自适应AI系统的至关重要性，特别是在自动驾驶和医学诊断等关键领域。"}
{"llm_update_time": "20250815", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.10554", "html_url": "https://arxiv.org/abs/2508.10554", "title": "AR Surgical Navigation With Surface Tracing: Comparing In-Sit Visualization with Tool-Tracking Guidance for Neurosurgical Applications", "title_en": "AR Surgical Navigation With Surface Tracing: Comparing In-SitVisualization with Tool-Tracking Guidance for Neurosurgical Applications", "authors": "Marc J. Fischer,Jeffrey Potts,Gabriel Urreola,Dax Jones,Paolo Palmisciano,E. Bradley Strong,Branden Cord,Andrew D. Hernandez,Julia D. Sharma,E. Brandon Strong", "background": "AR手术导航系统正在成为下一代手术导航工具，有望克服传统导航系统的局限。然而，由于会聚调节冲突导致的AR深度感知问题和当前商业显示技术处理遮挡的限制，它们在对手术精度要求极高的手术环境中带来了严峻挑战。", "innovation": "研究提出了一种新的AR导航方法，利用表面跟踪技术定位解剖目标，并通过实时红外工具跟踪辅助导管放置，仅依赖微软HoloLens 2的内置传感器。用户在两种AR导航条件下进行了实际操作：直接在患者解剖部位上叠加规划路径的静态在位可视化，和提供导管姿态实时反馈的工具跟踪指导，结果显示工具跟踪指导提高了所有准确性指标，并在用户主观评价中更受欢迎。", "conclusion": "系统通过计算机断层扫描扫描评估了插入精度、目标偏差、角度误差和深度精度，并通过工具有关工具和认知负担评估了用户体验。实验证明，在神经外科应用中，基于工具跟踪的AR导航指导提高了操作绩效并得到用户青睐。这些结果提供了AR在神经外科中的潜力和有效性证据。"}
{"llm_update_time": "20250815", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.10566", "html_url": "https://arxiv.org/abs/2508.10566", "title": "HM-Talker: 融合运动建模技术以实现高保真度头部讲话合成", "title_en": "HM-Talker: Hybrid Motion Modeling for High-Fidelity Talking Head Synthesis", "authors": "Shiyu Liu,Kui Jiang,Xianming Liu,Hongxun Yao,Xiaocheng Feng", "background": "目前的音频驱动头部讲话视频生成方法经常产生具有运动模糊和嘴唇抖动的视频，并且其主要原因是这些方法依赖于声学-面部运动联系的隐式建模，缺乏明确的发音先验（即，语音相关的面部运动解剖学指导）。这限制了用户在人机交互中的沉浸感。", "innovation": "本文提出了HM-Talker，这是一种新颖的框架，用于生成高质量、时间上连贯的头部讲话视频。该框架利用了混合运动表示，结合了显性和隐性运动提示。具体地，跨模态解耦模块从联合音频输入中直接预测动作单元，同时提取互补的显性/隐性运动特征。此外，引入了混合运动建模模块，该模块可以动态合并随机配对的显性/隐性特征，以实现身份无关的学习，从而克服身份依赖性偏向，增强泛化能力。", "conclusion": "大量的实验结果表明，相比最先进的方法，HM-Talker在视觉质量和唇同步准确性方面表现出明显的优势，推动了个性化的头部讲话视频合成的发展。"}
{"llm_update_time": "20250815", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.10582", "html_url": "https://arxiv.org/abs/2508.10582", "title": "EvTurb：事件相机引导下的湍流去除", "title_en": "EvTurb: Event Camera Guided Turbulence Removal", "authors": "Yixing Liu,Minggui Teng,Yifei Xia,Peiqi Duan,Boxin Shi", "background": "大气湍流会引入模糊和几何倾斜失真，严重影响计算机视觉任务的性能。现有的单帧和多帧方法因湍流失真的复杂性而难以应对这个问题。", "innovation": "提出了一种名为EvTurb的事件引导下的湍流去除框架，该框架利用高速事件流解耦模糊和倾斜效应。具体来说，通过一种新颖的两步事件引导网络：首先使用事件积分来在粗略输出中减少模糊，然后利用源自原始事件流的方差图来消除精细输出中的倾斜失真。此外，还介绍了一个名为TurbEvent的首个真实捕获的多样化湍流场景数据集。", "conclusion": "实验结果表明，EvTurb 在保持计算效率的同时，超越了现有的最先进的方法。"}
{"llm_update_time": "20250815", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.10567", "html_url": "https://arxiv.org/abs/2508.10567", "title": "SpaRC-AD：端到端自主驾驶中雷达-相机融合的基线", "title_en": "SpaRC-AD: A Baseline for Radar-Camera Fusion in End-to-End Autonomous Driving", "authors": "Philipp Wolters,Johannes Gilg,Torben Teepe,Gerhard Rigoll", "background": "端到端的自动驾驶系统通过统一优化感知、运动预测和规划来提升性能。然而，基于视觉的方法在恶劣天气条件、部分遮挡和精确速度估计等关键挑战下存在基本局限，尤其是在安全敏感的场景中，准确的运动理解与长时间轨迹预测对于碰撞避免至关重要。To address these limitations，我们提出了一种基于查询的端到端相机-雷达融合框架SpaRC-AD，用于规划导向的自动驾驶。", "innovation": "通过稀疏3D特征对齐和多普勒速度估计，我们实现了强大的3D场景表示，用于智能体锚点、地图多项式线和运动建模的细化。我们的方法在多个自动驾驶任务上优于最先进的基于视觉的基线，包括3D检测（+4.8% mAP）、多物体跟踪（+8.3% AMOTA）、在线制图（+1.8% mAP）、运动预测（-4.0% mADE）和轨迹规划（-0.1m L2和-9% TPC）。我们演示了雷达融合的有效性在需要准确运动理解和长时间轨迹预测的安全关键场景中。", "conclusion": "我们的方法在多个挑战性基准上实现了空间一致性和时间一致性，包括真实的nuScenes开放环、长展望T-nuScenes和闭环模拟器Bench2Drive。我们的成果证明了基于雷达的融合对于在碰撞避免等安全关键场景中的有效性。所有实验的源代码可在此处获得: this https URL"}
{"llm_update_time": "20250815", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.10572", "html_url": "https://arxiv.org/abs/2508.10572", "title": "为多模态引导视频对象分割开发代理AI", "title_en": "Towards Agentic AI for Multimodal-Guided Video Object Segmentation", "authors": "Tuyen Tran,Thao Minh Le,Truyen Tran", "background": "参考基视频对象分割是一个多模态问题，需要根据外部线索产生精细粒度的分割结果。传统的解决方法通常涉及训练专业的模型，这带来了高计算复杂性和手动标注的努力。最近，视觉-语言基础模型的进步为无需训练的方法打开了前景。一些研究探索了利用这些通用模型进行精细粒度的分割，达到了与完全监督的专业模型相当的性能。然而，现有方法依赖于固定的工作流程，缺乏适应任务动态特性的灵活性。", "innovation": "我们提出了Multi-Modal Agent（多模态代理），这是一种新颖的代理系统，旨在以更灵活和自适应的方式解决此任务。具体来说，我们的方法利用大型语言模型的推理能力来生成针对每个输入定制的动态工作流程，交互式地与为不同模态低级任务设计的专门工具集进行协作，以识别由多模态线索描述的目标对象。", "conclusion": "我们的代理方法在两个多模态条件下的视频对象分割任务（RVOS和Ref-AVS）上表现出明显优于先前方法的改进。"}
{"llm_update_time": "20250815", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.10576", "html_url": "https://arxiv.org/abs/2508.10576", "title": "HumanSense：通过推理自我中心模型从多模态感知到同理心意识响应", "title_en": "HumanSense: From Multimodal Perception to Empathetic Context-Aware Responses through Reasoning MLLMs", "authors": "Zheng Qin,Ruobing Zheng,Yabing Wang,Tianqi Li,Yi Yuan,Jingdong Chen,Le Wang", "background": "尽管多模态大语言模型（MLLMs）有潜力实现真正的人类级交互，但缺乏细粒度的评估框架阻碍了它们在以人类为中心的情境中的进步，这些情境既包括复杂的意图理解，也包括提供情感共鸣、情境相关的回应。因此，本研究引入了HumanSense基准，旨在评测MLLMs的人类中心感知与交互能力，特别是注重对扩展多模态环境的理解和理性的反馈构建。", "innovation": "HumanSense基准通过引入多阶段、模态渐进式的强化学习来增强普遍模型的推理能力，实现了显著的评估结果改进。此外，研究发现成功的推理过程表现出高度一致的思想模式，并通过设计相应的提示来改善非推理模型的性能，而无需进行训练。", "conclusion": "研究发现，当前领先的MLLMs在高级交互任务上仍有一定的改进空间，通过结合视觉、音频和文本信息可以获得显著提升，整体多模态模型具有优势。提供恰当的反馈需要从对话伙伴的需求和情绪中进行上下文分析，推理能力是解锁这一过程的关键。"}
{"llm_update_time": "20250815", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.10557", "html_url": "https://arxiv.org/abs/2508.10557", "title": "PTQAT: 一种适用于3D感知任务的混合参数高效量化算法", "title_en": "PTQAT: A Hybrid Parameter-Efficient Quantization Algorithm for 3D Perception Tasks", "authors": "Xinhao Wang,Zhiwei Lin,Zhongyu Xia,Yongtao Wang", "background": "后训练量化(PTQ)和量化感知训练(QAT)是两个主流的模型量化方法。然而，PTQ常常导致量化模型性能不可接受的下降，而QAT则因对GPU内存的需求高和训练时间长而受到限制。本文分析了这两种方法的局限性，旨在找到一种新的高效解决方案来部署3D感知网络。", "innovation": "提出了PTQAT，一种新的混合量化算法。PTQAT通过选择关键层进行QAT微调，其余层则进行PTQ，实现速度与精度之间的折中。这种方法通过在量化误差传播前进行补偿，而不是在误差发生时进行补偿，实现了更高的量化精度。PTQAT还是一种通用量化方法，支持不同位宽(如4位)，不同模型架构（包括CNN和Transformer），并且实验结果表明其性能优于传统的QAT方法。", "conclusion": "在nuScenes数据集上对多种3D感知任务（如目标检测、语义分割和占用预测）的实验结果表明，PTQAT方法在定量精度上至少与QAT方法保持一致，同时通过冻结大约50%的可量化层，实现了更高的效率。此外，PTQAT对目标检测、语义分割和占用预测任务分别带来了0.2%-0.9% NDS和0.3%-1.0% mAP以及0.3%-2.0% mIoU的优化效果，而需要微调的权重更少。"}
{"llm_update_time": "20250815", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.10568", "html_url": "https://arxiv.org/abs/2508.10568", "title": "通过交叉熵掩码调整SAM以处理遥感变化检测中的类别失衡", "title_en": "Adapting SAM via Cross-Entropy Masking for Class Imbalance in Remote Sensing Change Detection", "authors": "Humza Naveed,Xina Zeng,Mitch Bryson,Nagita Mehrseresht", "background": "在计算机视觉的多个领域，基础模型取得了显著的成功。这些模型能够学习到易于转移的一般性表示。例如，Segment Anything Model (SAM) 能够准确地在图像中分割对象。本文尝试将SAM编码器用于遥感变化检测 (RSCD)，并与空间-时间特征增强（STFE）和多尺度解码器融合（MSDF）相结合，以在多个尺度上稳健地检测变化。此外，为了处理变化检测数据集的高类别不平衡问题，提出了一种新颖的交叉熵掩码（CEM）损失。", "innovation": "1. 提出了一种新的方法，通过微调SAM编码器、加入空间-时间特征增强、多尺度解码器融合，以及引入交叉熵掩码损失来处理遥感变化检测中的类别不平衡问题。\n2. 该方法在Levir-CD、WHU-CD、CLCD和S2Looking四个数据集上的表现优于当前最先进的方法（SOTA），特别是在大规模的S2Looking数据集上，F1分数提高了2.5%。", "conclusion": "所提出的方法在遥感变化检测任务中取得了显著的性能提升，通过有效的特征调整和损失函数优化，成功解决了类别不平衡的问题，并且被证明在多个数据集上具有优越的性能。"}
{"llm_update_time": "20250815", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.10600", "html_url": "https://arxiv.org/abs/2508.10600", "title": "面向自主驾驶中2D物体检测的强效且实用的贴图攻击", "title_en": "Towards Powerful and Practical Patch Attacks for 2D Object Detection in Autonomous Driving", "authors": "Yuxin Cao,Yedi Zhang,Wentao He,Yifan Liao,Yan Xiao,Chang Li,Zhiyong Huang,Jin Song Dong", "background": "基于学习的自动驾驶系统在实际部署中对对抗贴图高度易受攻击，这引发了重大的安全和安全性风险。其中，黑盒攻击因其高成功率而尤为令人担忧，尤其是在减少计算成本方面，由于其比查询攻击具有更高的转移性。之前的基于转移性的黑盒攻击通常使用平均平均精度（mAP）作为评估标准，并据此设计训练损失，但是由于检测到的边界框较多和相对宽松的IoU阈值，这些方法的效果往往被高估。此外，针对低分辨率数据训练的贴图在高分辨率图像上效果往往不理想，限制了它们在自动驾驶数据集中的转移性。", "innovation": "提出了P$^3$A（Powerful and Practical Patch Attack）框架，专门针对高分辨率数据集优化。首先引入了一个新的评估指标——实用攻击成功率（PASR），以更准确地衡量攻击效果，并更关注行人安全。其次提出了定制化的定位-置信度抑制损失（LCSL）以在PASR下改善攻击的转移性。最后，引入了概率尺度保存填充（PSPP）作为数据预处理步骤，确保在高分辨率数据集上保持攻击的转移性。", "conclusion": "广泛的实验表明，P$^3$A在未见过的模型和高分辨率数据集上均优于最先进的攻击，无论是提出的基于实用IoU的评估指标还是先前的mAP评估指标。"}
{"llm_update_time": "20250815", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.10617", "html_url": "https://arxiv.org/abs/2508.10617", "title": "FIND-Net -- Fourier-Integrated Network with Dictionary Kernels for Metal Artifact Reduction", "title_en": "FIND-Net -- Fourier-Integrated Network with Dictionary Kernels for Metal Artifact Reduction", "authors": "Farid Tasharofi,Fuxin Fan,Melika Qahqaie,Mareike Thies,Andreas Maier", "background": "在计算机断层扫描（CT）成像中，由于高密度金属植入物导致的伪影严重降低了图像质量，使诊断和治疗规划复杂化。现有的深度学习算法在金属伪影减少（MAR）方面取得了显著成果，但在抑制伪影的同时保留结构细节方面经常遇到挑战。", "innovation": "本文提出了一种新颖的MAR框架FIND-Net（Fourier-Integrated Network with Dictionary Kernels），该框架结合了频域和空域处理，以实现卓越的伪影抑制和结构保留性能。FIND-Net通过引入快速傅里叶卷积（FFC）层和可训练高斯滤波器，将MAR视为同时在频域和空域进行的混合任务，增强了全局上下文理解和频域选择性。", "conclusion": "实验结果显示，FIND-Net在合成数据集上的性能显著优于最先进的MAR方法，减少了3.07%的MAE，提高了0.18%的SSIM和0.90%的PSNR。在实际临床CT扫描上的评估也验证了FIND-Net能够在减少干净解剖区域修改的同时有效抑制金属伪影，突显了FIND-Net在提高MAR性能方面的潜力，实现了更优越的结构保留和临床适用性。"}
{"llm_update_time": "20250815", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.10637", "html_url": "https://arxiv.org/abs/2508.10637", "title": "视觉编码器中的处理和获取痕迹：CLIP 知道关于你相机的什么？", "title_en": "Processing and acquisition traces in visual encoders: What does CLIP know about your camera?", "authors": "Ryan Ramos,Vladan Stojnić,Giorgos Kordopatis-Zilos,Yuta Nakashima,Giorgos Tolias,Noa Garcia", "background": "先前的研究集中在分析视觉编码器对图像变换和损坏的鲁棒性，尤其是在训练过程中未遇到这些变化的情况下。当这些情况在测试时发生时，会导致性能下降。研究主要集中在那些严重损坏和强烈扰动有用的信号，从而影响准确的语义预测。", "innovation": "本文从不同角度出发，分析图像获取过程中的参数，这些参数可能是微小或完全不可察觉的。发现这些参数被系统地编码在学习到的视觉表示中，并且可以轻松恢复。更重要的是，这些参数的出现会对语义预测产生深远影响，这种影响取决于语义标签与基于获取或处理标签之间是否存在强相关性或反相关性。", "conclusion": "研究表明，视觉编码器中包含了由图像获取和处理过程产生的痕迹，这些痕迹可能微小到难以察觉，但对语义预测有着显著的影响。代码和数据公开在提供链接的地址。"}
{"llm_update_time": "20250815", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.10631", "html_url": "https://arxiv.org/abs/2508.10631", "title": "通过切比雪夫引导提高合成图像的实用性", "title_en": "Increasing the Utility of Synthetic Images through Chamfer Guidance", "authors": "Nicola Dall'Asen,Xiaofeng Zhang,Reyhane Askari Hemmat,Melissa Hall,Jakob Verbeek,Adriana Romero-Soriano,Michal Drozdzal", "background": "生成模型在产生无限的合成训练数据方面显示出巨大的潜力，然而，生成质量的提升往往以多样性降低为代价，限制了其作为合成训练数据的价值。尽管引入了基于指导的方法来提高生成数据的质量或多样性，但这些方法通常忽略了合成数据和真实数据之间的潜在分布偏移。为了应对这一问题，该研究提出了切比雪夫指导：一种无需额外训练的指导方法，利用一小批真实示例图像来表征合成数据的质量和多样性。", "innovation": "该研究提出了一种名为切比雪夫指导的无训练引导方法，利用少数真实样本图像来表征合成数据的品质和多样性。通过这种指导方式，在保持或提高ImageNet-1k和标准地理多样性基准生成质量的同时，提升了生成的多样性，特别是在使用少量（如2张）真实图像时表现出色，同时在分类任务中提高了模型的准确性，特别是在样本数据不一致的情况下，甚至实现了31%的计算资源减少。", "conclusion": "通过实验结果证明，切比雪夫指导能够显著提高生成模型在保持高质量的同时增加生成数据的多样性，尤其在少量真实图像支持下效果显著。此外，该方法无需依赖无条件模型，减少了31%的计算量，为生成合成数据提供了新的有效策略。"}
{"llm_update_time": "20250815", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.10616", "html_url": "https://arxiv.org/abs/2508.10616", "title": "Fourier-引导的注意力上采样在图像超分辨率中的应用", "title_en": "Fourier-Guided Attention Upsampling for Image Super-Resolution", "authors": "Daejune Choi,Youchan No,Jinhyung Lee,Duksu Kim", "background": "传统的上采样方法，如子像素卷积，虽然高效，但在重建高频细节和避免插值伪影方面经常失败。本文探讨了这些问题，并提出了一种轻量级的单图像超分辨率上采样模块：频域引导注意力（FGA）模块。FGA通过结合基于傅里叶特征的多层感知机（MLP）进行位置频率编码、跨分辨率相关注意力层进行自适应空间对齐、以及频域L1损失监督光谱保真性，解决了这些问题。它在轻量级和全能力场景下都能显著提升性能，并在多种超分辨率 backbone 模型上表现一致。", "innovation": "本文提出了频域引导注意力（FGA）模块，该模块通过基于傅里叶特征的位置频率编码、跨分辨率相关注意力层、频域L1损失监督光谱保真性等三个创新点，解决了传统的上采样方法在高频细节重建和避免插值伪影方面的问题。该模块仅增加了0.3M的参数量，在多种超分辨率 backbone 模型上表现出一致的提升效果，特别是在纹理丰富的数据集上能显著提高细节保持性和频域一致性。", "conclusion": "实验结果表明，fga模块能够在轻量级和全能力场景下一致地提升性能，平均提高了0.12～0.14 dB的psnr，频域一致性提高了29%。视觉和频谱评估证明了fga在减少插值伪影和保留细节点方面的有效性。它被证明是传统上采样方法的一种实用且可扩展的替代方案。"}
{"llm_update_time": "20250815", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.10643", "html_url": "https://arxiv.org/abs/2508.10643", "title": "使用姿态估计和双向LSTMs在奶牛中检测跛行", "title_en": "Lameness detection in dairy cows using pose estimation and bidirectional LSTMs", "authors": "Helena Russello,Rik van der Tol,Eldert J. van Henten,Gert Kootstra", "background": "本文提出了一种结合姿态估计和双向长短期记忆（BLSTM）神经网络的跛行检测方法。与传统的基于标记的姿态估计不同，本文的方法通过学习关键点轨迹中的时序运动特征，不需要手工特征工程，并且可以处理较短的视频序列和较小的训练数据集。通过使用T-LEAP姿态估计模型从行走奶牛的视频中提取九个关键点的运动序列，并将这些序列作为BLSTM分类器的输入进行训练，该方法在二元跛行分类任务上的表现显著优于依赖于人工设计步态特征的方法。并且证明，BLSTM分类器能够通过仅一秒的视频数据来检测跛行。", "innovation": "结合姿态估计和BLSTM分类器，具有无标记的姿态估计、学习关键点轨迹中的时序运动特征以自动完成特征工程、处理较短序列和小规模训练数据集的优势。该方法显著提高了跛行检测的准确性，使用BLSTM分类器的方法达到了85%的分类准确率，远高于传统的基于特征的方法（80%的准确率）。", "conclusion": "通过研究，提出的方法不仅能够显著提高跛行检测的准确性，还能够在处理较短的视频序列时依然保持较高准确率。这对于奶牛的健康管理和监测具有重要应用价值。"}
{"llm_update_time": "20250815", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.10635", "html_url": "https://arxiv.org/abs/2508.10635", "title": "ChatENV: 一种用于传感器指导的环境监测和情景模拟的交互式视觉语言模型", "title_en": "ChatENV: An Interactive Vision-Language Model for Sensor-Guided Environmental Monitoring and Scenario Simulation", "authors": "Hosam Elgendy,Ahmed Sharshar,Ahmed Aboeitta,Mohsen Guizani", "background": "理解从航拍图像中环境变化对于气候韧性和城市规划以及生态系统监测至关重要。然而，当前的视觉语言模型（VLMs）忽略了来自环境传感器的因果信号，依赖于单一来源的描述容易受到风格偏见的影响，并且缺乏基于互动情景的推理能力。", "innovation": "我们提出了ChatENV，这是首个可以同时对卫星图像对和现实世界传感器数据进行推理的交互式VLM。ChatENV创新性地集成了177,000张图像的数据集，形成了152,000个时间上的图像对，分布在197个国家和62个土地用途类别中，这一点丰富了传感器元数据（如温度、PM10、CO等）。ChatENV采用了GPT-4o和Gemini 2.0对数据进行标注，以实现风格和语义的多样性，并且使用高效的Low-Rank Adaptation (LoRA) 调整器对Qwen-2.5-VL进行微调以便进行聊天功能。同时，ChatENV在时间推理和“什么如果”推理方面表现出色，不仅与最新的时间模型持平，还在此领域领先，同时支持交互式情景分析成为强大的工具，对基于传感器的环境监测具有指导意义.", "conclusion": "ChatENV作为一个基于传感器的环境监测工具，提供了强大的地基和传感器意识能力，在时间推理和情景分析方面显示出卓越的性能。"}
{"llm_update_time": "20250815", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.10645", "html_url": "https://arxiv.org/abs/2508.10645", "title": "SemPT: 语义提示调优用于视觉语言模型", "title_en": "SemPT: Semantic Prompt Tuning for Vision-Language Models", "authors": "Xiao Shi,Yangjun Ou,Zhenzhong Chen", "background": "视觉转移学习对于未见过的类别来说是一个活跃的但具有挑战性的研究议题，主要由于保留类别特定表示和获取可转移知识之间的固有冲突。现有的视觉语言模型（VLMs）已经在大量图像-文本对上进行预训练，提供了一种有前景的解决方法。然而，现有的提示调优方法依赖稀疏的类别标签或相差较大的LLM生成描述，这使得知识表示破碎化并阻碍了可转移性。", "innovation": "本文提出了语义提示调优（SemPT），这是一种通过利用类别之间的共享属性知识来克服泛化挑战的新框架。具体来说，SemPT采用两步提示策略，引导LLM提取共享的视觉属性和生成属性级描述，捕捉超越标签的可转移语义线索，同时确保结构连贯性。此外，应用视觉引导加权来减少无关属性的噪声并增强文本嵌入，同时图像嵌入与标签和属性增强文本嵌入联合对齐，平衡已见类别和未见类别的区分度和可转移性。根据类别曝光的可用性，推断动态选择标准标签嵌入或属性增强嵌入，以确保有效的适应性。", "conclusion": "广泛的实验表明，SemPT在各种设置下，包括基本类别到新类别的泛化、跨数据集转移、跨域转移和少样本学习中，均能达到最先进的性能。"}
{"llm_update_time": "20250815", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.10667", "html_url": "https://arxiv.org/abs/2508.10667", "title": "AddressVLM: 使用大型视觉语言模型进行图像地址定位的视角对齐调优", "title_en": "AddressVLM: Cross-view Alignment Tuning for Image Address Localization using Large Vision-Language Models", "authors": "Shixiong Xu,Chenghao Zhang,Lubin Fan,Yuan Zhou,Bin Fan,Shiming Xiang,Gaofeng Meng,Jieping Ye", "background": "大型视觉语言模型（LVLMs）在国家或城市级别的粗粒度地理定位方面表现出色，但在城市区域内的街道级别定位方面存在困难。本文探讨了将城市范围内的地址定位能力整合到LVLMs中，利用街道视图图像进行灵活的地址相关问题回答。关键挑战在于，街道视图视觉问答（VQA）数据仅提供了微小的视觉线索，导致微调模型性能不佳。", "innovation": "提出了基于视角不变卫星图像的宏观线索的视角对齐调优，包括卫星视图和街道视图图像嫁接机制以及自动标签生成机制，提升了LVLM对街道分布的全局理解。提出的AddressVLM模型包含两个阶段的训练协议：视角对齐调优和地址定位调优。构造了基于匹兹堡和旧金山图像地址定位数据集的两个街道视图VQA数据集。定量和定性评估结果表明，AddressVLM在两个数据集上的平均地址定位精度分别超过对照LVLM 9%和12%。", "conclusion": "AddressVLM通过视角对齐调优增强了LVLM的街道分布理解，提高了图像地址定位精度，表现出明显的优越性。"}
{"llm_update_time": "20250815", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.10680", "html_url": "https://arxiv.org/abs/2508.10680", "title": "具有物理指导的联合多TE超分辨率与隐式神经表示法在稳健胎儿T2成像中的应用", "title_en": "Physics-Informed Joint Multi-TE Super-Resolution with Implicit Neural Representation for Robust Fetal T2 Mapping", "authors": "Busra Bulut,Maik Dannecker,Thomas Sanchez,Sara Neves Silva,Vladyslav Zalevskyi,Steven Jia,Jean-Baptiste Ledoux,Guillaume Auzias,François Rousseau,Jana Hutter,Daniel Rueckert,Meritxell Bach Cuadra", "background": "在胎儿MRI中，T2成像是评估胎儿大脑发育的潜在工具，特别是在0.55T等中磁场中，但由于胎儿MRI成像依赖于存在运动干扰的厚切片多次堆叠，这需要通过切片到体积重建(SVR)来估计高分辨率(3D)体积，导致长时间的扫描时间和对运动的高敏感性。当前的T2成像需要在每个回波时间(TE)上反复采集这些堆叠图像，这不仅增加了时间成本，还增加了因运动而导致数据不准确的可能性。", "innovation": "该研究提出了一种新的方法，即联合多TE超分辨率与隐式神经表示法，这种方法能够同时重建TE数据并解决严重的运动问题。其创新点在于结合了隐式神经表示法与基于物理的正则化，后者可以模拟T2衰减，实现TE间的信息共享，同时保持解剖和定量T2的准确性。", "conclusion": "该方法在模拟和真实数据集上都显示出了优越的性能，特别是在具有类似胎儿运动特性的成像数据中。此外，该研究还首次在0.55T下获得了实时胎儿T2成像结果，展示了这种方法在减少每TE成像堆栈数量方面可能带来的优势。"}
{"llm_update_time": "20250815", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.10678", "html_url": "https://arxiv.org/abs/2508.10678", "title": "HyperTea: 基于超图的时域增强和对齐网络在移动红外小目标检测中的应用", "title_en": "HyperTea: A Hypergraph-based Temporal Enhancement and Alignment Network for Moving Infrared Small Target Detection", "authors": "Zhaoyuan Qi,Weihua Gao,Wenlong Niu,Jie Tang,Yun Li,Xiaodong Peng", "background": "在实际应用场景中，移动红外小目标检测（MIRSTD）仍然是极具挑战性的任务。这主要是由于小目标的尺寸较小、亮度较弱以及复杂的运动模式。现有方法通常只建模特征节点之间的低阶相关性，并在单一时间尺度下进行特征提取和增强。尽管超图被广泛用于高阶相关学习，但在MIRSTD中应用较少。因此，需要一种有效建模特征高阶时空相关性的方法，以提高检测性能。", "innovation": "作者提出了HyperTea，这是一种结合全局和局部时域视角的网络，旨在有效建模特征的高阶时空相关性。HyperTea由三个模块组成：全局时域增强模块（GTEM）通过语义聚合和传播实现全局时域上下文增强；局部时域增强模块（LTEM）设计用于捕捉相邻帧之间的局部运动模式，进一步增强局部时域上下文；此外，还开发了一个时间对齐模块（TAM）来解决跨尺度特征对齐问题。HyperTea将卷积神经网络（CNNs）、循环神经网络（RNNs）和超图神经网络（HGNNs）结合，这是首次在MIRSTD中整合这三种网络。", "conclusion": "实验在DAUB和IRDST数据集上证明了HyperTea的性能是业界最佳（SOTA），并且已经开放了源代码。这些研究表明HyperTea能够显著提高MIRSTD中的检测性能。"}
{"llm_update_time": "20250815", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.10655", "html_url": "https://arxiv.org/abs/2508.10655", "title": "串行超越并行：持续统一多模态视觉目标跟踪及基准测试", "title_en": "Serial Over Parallel: Learning Continual Unification for Multi-Modal Visual Object Tracking and Benchmarking", "authors": "Zhangyong Tang,Tianyang Xu,Xuefeng Zhu,Chunyang Cheng,Tao Zhou,Xiaojun Wu,Josef Kittler", "background": "多模态多目标跟踪（MMVOT）任务由于不同模态之间的互补性质越来越受到关注，现有的实践将所有数据传感器类型混合在一个训练过程中，旨在针对涉及任务的联合分布找到全局最优解。然而，缺乏一个统一的基准测试，使得在分离的基准测试上进行评估，导致训练和测试之间的一致性问题，从而降低性能。因此，本文提出了两个方面的改进措施：一是提出了一个名为UniBench300的统一基准，通过集成多个任务数据，将推理次数从三次减少到一次，减少了27%的时间消耗；二是将统一过程重新制定为一个串行格式，逐步整合新任务，这样性能退化可以被解释为对先前任务的知识遗忘，自然与持续学习（CL）的哲学相契合，推动将CL注入统一过程的研究。实验表明，UniBench300的显著性和CL在支持稳定统一过程中的优越性。", "innovation": "提出了一个名为UniBench300的统一基准，通过集成多个任务数据，将推理次数从三次减少到一次，减少了时间消耗。将统一过程重新制定为一个串行格式，逐步整合新任务，这样性能退化可以被解释为对先前任务的知识遗忘，自然与持续学习（CL）的哲学相契合，并推动将CL注入统一过程的研究。", "conclusion": "通过其提出的UniBench300统一基准和持续学习的融入，首次实现了多模态视觉目标跟踪的稳定统一，并验证了这种变化的有效性。进一步的实验证明，网络容量越大，性能退化越不明显，并为多模态视觉研究提供了有价值的见解，即不同模态的差异性影响了任务间的性能退化水平。实验结果和源代码已经发布。"}
{"llm_update_time": "20250815", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.10672", "html_url": "https://arxiv.org/abs/2508.10672", "title": "混合生成融合：高效且保护隐私的面部识别数据集生成", "title_en": "Hybrid Generative Fusion for Efficient and Privacy-Preserving Face Recognition Dataset Generation", "authors": "Feiran Li,Qianqian Xu,Shilong Bao,Boyu Han,Zhiyong Yang,Qingming Huang", "background": "本文讨论了对DataCV ICCV挑战的解决方案，该挑战的关键在于构建一个高质量的面部数据集以训练面部识别模型。构建的数据集不能包含与现有公开面部数据集重叠的身份信息。为了应对这一挑战，作者从基础的HSFace数据集开始，进行了彻底的清理工作，通过将面部嵌入聚类与GPT-4o辅助验证结合的Mixture-of-Experts（MoE）策略，识别并移除错误标注或不一致的身份信息。然后，作者使用Stable Diffusion生成合成身份，并通过Vec2Face快速生成这些合成身份的49种一致变体，以此营造出一个多样且高质量的数据集。为了应对合成身份之间过高的视觉相似性，作者采用了逐步学习策略，在训练计划中早期放置合成身份，从而使模型能够从较简单的样本过渡到更难的样本。最后，每个身份数据集包含50张图片，并且所有新生成的身份都经过主流面部数据集的检查，确保没有身份泄露。实验结果表明，该数据集提升了模型在1万、2万和10万身份规模下的性能。", "innovation": "本文提出了一种混合生成融合的方法，将基于生成对抗网络（GAN）和基于扩散模型的方法融合起来，高效创建多样且高质量的数据集，并采用逐步学习策略来解决合成身份之间的视觉相似性问题。这种方法能够快速生成多种一致变体，从而有效扩大数据集规模并提高模型性能。", "conclusion": "最终，作者构建的数据集在比赛中获得了第一名的好成绩，并显示出其在不同身份规模下的模型性能提升。"}
{"llm_update_time": "20250815", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.10688", "html_url": "https://arxiv.org/abs/2508.10688", "title": "使用 DDIM 反转进行新颖视角合成", "title_en": "Novel View Synthesis using DDIM Inversion", "authors": "Sehajdeep SIngh,A V Subramanyam", "background": "从单张输入图像生成新颖视图是一项挑战性的任务，需要推断场景的3D结构，同时推测被遮挡区域的细节，并保持不同视角下几何结构的一致性。现有方法要么使用多视图微调大型扩散模型，要么从零开始训练扩散模型，这两种方法都非常昂贵，并且还存在复原模糊和泛化能力差的问题。因此，存在探索一种显式的轻量级视角转换框架的机会，该框架可以直接利用预训练扩散模型的高保真生成能力，并从新颖视角重建场景。", "innovation": "提出了全新的融合策略，利用在 DDIM 反转中观测到的固有噪声相关的结构，从而保留图像的纹理和精细细节。利用融合后的潜在表示作为 DDIM 抽样过程的初始条件，结合预训练扩散模型的生成先验，以合成新颖视图。这种方法在 MVImgNet 上的实验结果表明，其性能优于现有方法。", "conclusion": "该方法通过从单张输入图像的 DDIM 反转中利用摄像头姿态条件下的翻译 U-Net(TUNet)，预测所需目标视图的反转潜在表示，并结合全新的融合策略提高细节保留能力，进而利用预训练扩散模型的生成先验合成新颖视图，实现了从单张图像生成高质量新颖视图的目标，并在多个基准测试上超越了现有方法。"}
{"llm_update_time": "20250815", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.10704", "html_url": "https://arxiv.org/abs/2508.10704", "title": "超越传统视觉：在动态交通场景中鲁棒目标检测的RGB事件融合", "title_en": "Beyond conventional vision: RGB-event fusion for robust object detection in dynamic traffic scenarios", "authors": "Zhanwen Liu,Yujing Sun,Yang Wang,Nan Yang,Shengbo Eben Li,Xiangmo Zhao", "background": "传统RGB摄像头的动态范围限制降低了全局对比度，并在复杂交通环境（如夜间驾驶、隧道内）中导致高频细节（如纹理和边缘）的损失，这妨碍了特征的区分性提取并降低了基于帧的目标检测效果。", "innovation": "本文提出了一种生物启发的事件相机与RGB相机的融合方法，并提出了一种运动线索融合网络（MCFNet）。该网络通过优化实现了时空对齐和自适应多模态特征融合。具体包括：通过光学流基于的变形进行异步事件流与图像帧的时空对齐；提升事件帧的空间分辨率以匹配图像结构；改进的跨模态Mamba融合模块通过新颖的交错扫描机制实现自适应特征融合，有效整合信息进行稳健检测。", "conclusion": "在DSEC-Det和PKU-DAVIS-SOD数据集上的实验结果表明，MCFNet在各种低光照和快速移动交通场景中显著优于现有方法。特别是在DSEC-Det数据集上，MCFNet在mAP50和mAP指标上分别比最优现有方法提高了7.4%和1.7%。"}
{"llm_update_time": "20250815", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.10711", "html_url": "https://arxiv.org/abs/2508.10711", "title": "NextStep-1：朝着大规模连续图像生成的自回归方法", "title_en": "NextStep-1: Toward Autoregressive Image Generation with Continuous Tokens at Scale", "authors": "NextStep Team:Chunrui Han,Guopeng Li,Jingwei Wu,Quan Sun,Yan Cai,Yuang Peng,Zheng Ge,Deyu Zhou,Haomiao Tang,Hongyu Zhou,Kenkun Liu,Ailin Huang,Bin Wang,Changxin Miao,Deshan Sun,En Yu,Fukun Yin,Gang Yu,Hao Nie,Haoran Lv,Hanpeng Hu,Jia Wang,Jian Zhou,Jianjian Sun,Kaijun Tan,Kang An,Kangheng Lin,Liang Zhao,Mei Chen,Peng Xing,Rui Wang,Shiyu Liu,Shutao Xia,Tianhao You,Wei Ji,Xianfang Zeng,Xin Han,Xuelin Zhang,Yana Wei,Yanming Xu,Yimin Jiang,Yingming Wang,Yu Zhou,Yucheng Han,Ziyang Meng,Binxing Jiao,Daxin Jiang,Xiangyu Zhang,Yibo Zhu", "background": "现有的自回归模型在文本到图像生成中主要依赖于耗时且计算密集的扩散模型处理连续的图像标记，或者使用矢量量化（VQ）方法将图像标记变为离散标记伴随量化损失。这些方法各有局限，要么计算成本高，要么生成图像质量有损失。", "innovation": "NextStep-1 是一种140亿参数的自回归模型，配备了一个1.57亿参数的流匹配头部，用于预测连续文本标记和连续图像标记。该方法通过结合连续和离散标记来提高生成图像的质量和编辑能力，展示了其强大的高保真图像合成能力，并且在图像编辑任务上也表现出了强大的性能。", "conclusion": "NextStep-1 在文本到图像生成任务中表现出色，达到了自回归模型的最新技术水平，同时在图像编辑性能方面也表现出色。为了促进开放研究，作者表示将发布其代码和模型以供社区使用。"}
{"llm_update_time": "20250815", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.10710", "html_url": "https://arxiv.org/abs/2508.10710", "title": "CountCluster：无需训练的跨注意力图聚类对象数量指导文本到图像生成", "title_en": "CountCluster: Training-Free Object Quantity Guidance with Cross-Attention Map Clustering for Text-to-Image Generation", "authors": "Joohyeon Lee,Jin-Seop Lee,Jee-Hyong Lee", "background": "基于扩散的文本到图像生成模型在图像质量和多样性方面表现出色，但仍然难以生成与输入提示中指定的对象数量相符的图像。现有方法依赖于外部分数模块或从学习令牌或潜在特征中得出的数量表示进行迭代优化，但仍存在难以精确反映指定的对象数量的问题，并且忽略了对象实例数量在生成图像中的重要结构特性。在去噪过程的早期时间步，生成图像中的对象实例数量主要由对象交叉注意力图的激活区域决定。为了更准确地反映对象数量，对象交叉注意力图应在输入对象数量的早期时间步匹配，并且每个区域应清晰分离。", "innovation": "提出了一种名为CountCluster的方法，该方法在生成过程中不依赖任何外部工具或额外训练，而是直接根据输入中的指定对象数量来引导对象交叉注意力图进行聚类。在推理过程中，该方法将对象交叉注意力图划分为k个聚类，并定义一个理想的空间分离的聚类分布，以优化潜在变量以匹配该目标分布。实验结果表明，该方法在对象数量准确性方面平均提高了18.5%，并且在各种提示下展示了超越现有方法的量控制性能。", "conclusion": "该工作提高了文本到图像生成中对象数量的准确性，并展示了跨注意力图聚类在无需额外训练的情况下进行对象数量指导的有效性。"}
{"llm_update_time": "20250815", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.10712", "html_url": "https://arxiv.org/abs/2508.10712", "title": "适合嵌入式的轻量级CNN用于SAR船舶目标检测和分类", "title_en": "Lightweight CNNs for Embedded SAR Ship Target Detection and Classification", "authors": "Fabian Kresse,Georgios Pilikos,Mario Azcueta,Nicolas Floury", "background": "合成孔径雷达（SAR）数据可以实现对海洋船只的大规模监视。然而，近实时监控由于需要下传所有原始数据、执行图像聚焦和随后在地面进行分析而受到限制。将处理转移到卫星上可以生成高级数据产品，减少需要下传的数据量，缓解带宽限制并降低延迟。然而，传统的图像聚焦和处理算法在卫星有限的内存、处理能力和计算资源下面临挑战。这项工作提出了并评估了适用于嵌入式实时推理的神经网络。通过研究Sentinel-1在Stripmap和Interferometric Wide模式下获取的未聚焦SAR数据，证明了模型在嵌入式处理和FPGA部署上的可行性。此外，通过将船舶与风车进行二元分类任务测试，证明了目标分类的可能性。", "innovation": "提出了适用于嵌入式实时推理的神经网络模型，用于SAR数据处理和船舶目标检测分类；通过利用轻量级CNN在嵌入式平台上的高效处理能力，解决了卫星的计算资源受限问题；以Sentinel-1的SAR数据，实施了基于神经网络模型的实时船舶检测。", "conclusion": "研究成果表明，神经网络模型在SAR数据的实时处理和嵌入式平台上的部署可行性，并通过实验验证了对船舶目标的分类能力。"}
{"llm_update_time": "20250815", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.10716", "html_url": "https://arxiv.org/abs/2508.10716", "title": "从图像匹配角度重访跨视角定位", "title_en": "Revisiting Cross-View Localization from Image Matching", "authors": "Panwang Xia,Qiong Wu,Lei Yu,Yi Liu,Mingtao Xiong,Lei Liang,Yongjun Zhang,Yi Wan", "background": "跨视角定位旨在通过将地面视角图像注册到航空或卫星图像上来估计其三维自由度的姿态。这种技术在没有GNSS信号的环境中非常重要，如城市峡谷和灾难区域。现有的方法要么直接回归姿态，要么在共享鸟瞰图（BEV）空间中对齐特征，这些方法都依赖于视角之间的准确空间对应关系。然而，这些方法无法建立严格的跨视角对应关系，只能产生粗略或几何上不一致的匹配。因此，地面和空中视图之间的细粒度图像匹配仍然是一个未解决的问题，这反过来限制了定位结果的可解释性。", "innovation": "本文从跨视角图像匹配的角度重新审视了跨视角定位问题，并提出了一个新颖的框架以改进匹配和定位。具体来说，引入了Surface Model来建模可见区域以便准确投影到BEV空间，并引入了SimRefiner模块通过局部全局残差校正来完善相似矩阵，消除了对如RANSAC等后处理步骤的依赖。另外，还引入了CVFM基准数据集，其中包含32,509个带有像素级对应关系的跨视角图像对，以进一步支持该领域的研究。", "conclusion": "大量实验表明，我们的方法显著提高了定位精度和图像匹配质量，在极端视角差异条件下设置了新的基准线。"}
{"llm_update_time": "20250815", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.10719", "html_url": "https://arxiv.org/abs/2508.10719", "title": "利用判别性代码本先验提高自回归图像生成", "title_en": "Exploiting Discriminative Codebook Prior for Autoregressive Image Generation", "authors": "Longxiang Tang,Ruihang Chu,Xiang Wang,Yujin Han,Pingyu Wu,Chunming He,Yingya Zhang,Shiwei Zhang,Jiaya Jia", "background": "现有的自回归图像生成系统首先将图像切分为序列的代币索引，然后在自回归框架下建模这些序列。仅依赖索引值进行训练，未能充分利用代码本中嵌入的丰富的代币相似性信息。最近的研究尝试通过简单的k-means聚类来利用这些信息，但这在代码本特征空间中表现不佳。主要原因在于代币空间的不均匀性和质心距离估计不准确。", "innovation": "提出了一种名为Discriminative Codebook Prior Extractor (DCPE)的新方法，用于替代传统的基于质心的距离计算，通过采用实例基于的距离计算方式和聚合并聚集技术来更有效地挖掘和利用代码本中嵌入的代币相似性信息，从而改善自回归模型的训练效率和生成性能。", "conclusion": "实验结果表明，DCPE可在42%的速度提升下，加速LlamaGen-B的自回归模型训练，并提高最终的FID和IS性能，能够无缝集成到现有的基于代码本先验的框架中。"}
{"llm_update_time": "20250815", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.10681", "html_url": "https://arxiv.org/abs/2508.10681", "title": "IADGPT: 统一的大型视觉-语言模型，用于基于语境学习的少量样本工业异常检测、定位与推理", "title_en": "IADGPT: Unified LVLM for Few-Shot Industrial Anomaly Detection, Localization, and Reasoning via In-Context Learning", "authors": "Mengyang Zhao,Teng Fu,Haiyang Yu,Ke Niu,Bin Li", "background": "工业质量检查在自动化生产线中具有重要意义。现有的基于大型视觉-语言模型（LVLM）的少量样本工业异常检测（FS-IAD）方法通过提示学习或微调取得了某些成果，但这些模型缺乏基本的工业知识和与FS-IAD相关的推理能力，使得它们远不如专业的人工质量检查者。为此，本文提出了一种统一框架IADGPT，旨在以类似人类的方式执行FS-IAD，并处理相关定位和推理任务，特别是对于多样化和新颖的工业产品也能够胜任。为了实现这一目标，引入了受人类启发的三阶段渐进式训练策略。实际操作中，前两个阶段逐步引导IADGPT获取基础工业知识和差异感知。在第三个阶段，设计了一种基于在上下文学习的训练范式，使IADGPT能够利用少量示例图像作为原型以提高对新产品的推广能力。此外，提出了策略使得IADGPT能够根据逻辑输出和注意力图分别生成图像级和像素级异常评分，并结合语言输出完成异常推理。作为训练的支持，本文还提供了包含100,000张图像的新数据集，覆盖400个多样化的工业产品类别，具有详细的文字标注。实验表明IADGPT在异常检测方面取得了显著性能提升，并展示了在异常定位和推理方面的竞争力。数据集将在定稿时公开。", "innovation": "本文创新性地提出了统一框架IADGPT，用于少量样本工业异常检测、定位与推理。它通过受人类启发的三阶段渐进式训练策略，逐步引导模型获取基本工业知识和差异感知，最终能够利用少量样本图像作为原型以改进对新产品的推广能力。此外，该框架能够实现图像级和像素级的异常评分生成，并通过结合语言输出实现异常推理。", "conclusion": "实验结果显示，IADGPT在异常检测方面取得了显著的性能提升，并在异常定位和推理方面展示了竞争力。此外，还将发布一个包含100,000张图像的新数据集，该数据集覆盖了400个多样化的工业产品类别，并具有详细的属性级文本注释。"}
{"llm_update_time": "20250815", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.10737", "html_url": "https://arxiv.org/abs/2508.10737", "title": "增强隐私的眼白分割基准竞赛: SSBC 2025", "title_en": "Privacy-enhancing Sclera Segmentation Benchmarking Competition: SSBC 2025", "authors": "Matej Vitek,Darian Tomašević,Abhijit Das,Sabari Nathan,Gökhan Özbulak,Gözde Ayşe Tataroğlu Özbulak,Jean-Paul Calbimonte,André Anjos,Hariohm Hemant Bhatt,Dhruv Dhirendra Premani,Jay Chaudhari,Caiyong Wang,Jian Jiang,Chi Zhang,Qi Zhang,Iyyakutti Iyappan Ganapathi,Syed Sadaf Ali,Divya Velayudan,Maregu Assefa,Naoufel Werghi,Zachary A. Daniels,Leeon John,Ritesh Vyas,Jalil Nourmohammadi Khiarak,Taher Akbari Saeed,Mahsa Nasehi,Ali Kianfar,Mobina Pashazadeh Panahi,Geetanjali Sharma,Pushp Raj Panth,Raghavendra Ramachandra,Aditya Nigam,Umapada Pal,Peter Peer,Vitomir Štruc", "background": "该论文总结了2025年眼白分割基准竞赛（SSBC），该竞赛强调使用合成眼图像来开发具有隐私保护的眼白分割模型。比赛的目标是评估在合成数据上训练的模型与在真实世界数据集上训练的模型相比的表现如何。竞赛设有两个赛道，一个是仅使用合成数据进行模型开发，另一个是将合成数据与有限的真实世界数据混合使用。", "innovation": "比赛展示了在综合数据上训练的模型即使在完全没有真实数据的情况下也可以达到具有竞争力的表现，特别是在采用专门的训练策略时。此外，结果显示，在混合数据赛道中，性能的提升更多来自于方法选择而非真实数据的加入，这表明合成数据在隐私保护的生物识别发展方面具有潜力。", "conclusion": "比赛证明了基于合成数据的眼白分割模型可以达到或接近真实世界数据训练模型的表现，特别是在特定训练策略的使用下。合成数据在隐私保护的生物识别系统开发中具有显著的优势。"}
{"llm_update_time": "20250815", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.10740", "html_url": "https://arxiv.org/abs/2508.10740", "title": "使用群等变表示的轴级对称性检测", "title_en": "Axis-level Symmetry Detection with Group-Equivariant Representation", "authors": "Wongyun Yu,Ahyun Seo,Minsu Cho", "background": "对称性是计算机视觉领域的一个基本概念，尽管已经被广泛研究，但在复杂场景中检测对称性依然是一个巨大的挑战。近年来的基于heat map的方法可以在局部化潜在的对称轴区域时提供精度欠缺，尤其是在识别个体轴时不足。本文深度探索如何通过更直接明确的几何原语来捕捉常见的两种对称类型——反射和旋转。本文使用了具有二分支结构的新型框架，每个分支专门用于其特定的对称类型，并且每个分支都对称于二面体群，从而增强了检测和匹配的精度", "innovation": "本文提出了一种基于群等变表示的新型轴级对称性检测框架。对于反射对称性，提出了一种方向锚点来实现特定角度的检测，并引入了一种反射匹配方法来衡量候选轴两侧图案的相似度。对于旋转对称性，提出了旋转匹配来在固定角度间隔上比对模式以识别旋转中心。这一方法在实验中展现了优越性，超越了所有现有的对称性检测方法", "conclusion": "本文通过对称轴的直接表示来提升对称性检测的精度，尤其是在特定类型对称性的检测上，展示了优于现有方法的性能"}
{"llm_update_time": "20250815", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.10731", "html_url": "https://arxiv.org/abs/2508.10731", "title": "解析广泛类别发现：自我分解下的多路共识", "title_en": "Dissecting Generalized Category Discovery: Multiplex Consensus under Self-Deconstruction", "authors": "Luyao Tang,Kunze Huang,Chaoqi Chen,Yuxuan Yuan,Chenxin Li,Xiaotong Tu,Xinghao Ding,Yue Huang", "background": "人类感知系统在识别已知和未知类别中的对象方面表现出色，远超现有的机器学习框架。现有的泛化类别发现方法主要集中在优化目标函数上，但未能充分模拟人类认知过程中的多样性，特别是在视觉处理中的差异性偏好和基于情景的线索利用上。本研究旨在设计一种新的方法，以更好地探索泛化类别发现的任务。该方法借鉴了人类认知过程，通过将对象分解为视觉基本成分，并在跨知识比较中建立它们之间的联系，实现泛化类别发现。研究通过高阶语义重建建立以基本成分为导向的表示，并通过拆解建立类别内部共享属性的绑定，模仿人类在视觉处理中的偏好多样性，利用主导或情景线索来捕捉类间区分模式和固有的分布不变量。", "innovation": "提出了ConGCD方法，该方法通过高阶语义重建建立以基本成分为导向的表示，并通过拆解建立类别内部共享属性的绑定。引入了主导性一致单元和情景一致单元分别捕捉类别区分模式和固有的分布不变量，并通过动态优化激活路径，最终通过多路一致性的综合生成预测。这种自我分解下的多路共识策略展示了广泛类别发现的有效性，并与现有的泛化类别发现方法进行了比较，展示了其独特优势。", "conclusion": "ConGCD作为一种一致感知的范式，通过自我分解和多路共识策略，显著提高了泛化类别发现的性能。该论文展示了ConGCD在粗粒度和细粒度基准测试中的广泛适用性和有效性，并为后续研究和实践提供了新的思路。研究团队已经开源了代码，以供研究界进一步探索和应用。"}
{"llm_update_time": "20250815", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.10729", "html_url": "https://arxiv.org/abs/2508.10729", "title": "EgoCross: 基于多模态大型语言模型的跨域自视角视频问答基准", "title_en": "EgoCross: Benchmarking Multimodal Large Language Models for Cross-Domain Egocentric Video Question Answering", "authors": "Yanjun Li,Yuqian Fu,Tianwen Qian,Qi'ao Xu,Silong Dai,Danda Pani Paudel,Luc Van Gool,Xiaoling Wang", "background": "近期，多模态大型语言模型（MLLMs）在自视角视频问答（EgocentricQA）领域取得了显著进展，但现有的基准和研究主要局限于烹饪和清洁等日常生活活动。然而，在实际部署中，不可避免地会遇到领域转换问题，即目标领域在视觉风格和语义内容上存在显著差异。为了弥合这一差距，我们提出了EgoCross，这是一个旨在评估MLLMs在EgocentricQA领域跨域泛化能力的全面基准。EgoCross涵盖了手术、工业、极限运动和动物视角等四个不同且具有挑战性的领域，代表了现实中的高影响应用场景。它包含约1,000个QA对，涉及四个关键任务：预测、识别、定位和计数。每个QA对都提供了开放式和封闭式问答格式，以支持详细的评估。", "innovation": "我们提出了EgoCross，这是一个用于评估MLLMs在EgocentricQA中跨域泛化的基准。它涵盖了四个不同的领域，包括手术、工业、极限运动以及动物视角等，并包含约1,000个QA对，在四个关键任务上有广泛的应用。每个问题对都提供了开放式和封闭式问答格式，以支持详细的评价。通过大量实验，我们展示了大多数现有的MLLMs，无论是通用的还是自视角专门化的，都难以跨域到日常生活范围之外的应用场景，这凸显了当前模型的局限性。此外，我们还进行了若干试点研究，如微调和强化学习，以探索潜在改进的方法。", "conclusion": "我们希望EgoCross及其配套分析将为增强适应不同领域的自视角视频理解提供基础。所有数据和代码将在以下链接发布：[此链接]。"}
{"llm_update_time": "20250815", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.10741", "html_url": "https://arxiv.org/abs/2508.10741", "title": "基于双感知网络的伪造引导学习策略在跨域深.fake检测中的应用", "title_en": "Forgery Guided Learning Strategy with Dual Perception Network for Deepfake Cross-domain Detection", "authors": "Lixin Jia,Zhiqing Guo,Gaobo Yang,Liejun Wang,Keqin Li", "background": "深.fake技术的出现带来了广泛的社会问题，并引起了广泛关注。现有的深.fake检测方法在特定数据集上表现出色，但在应用到具有未知伪造技术的数据集时表现不佳。随着新兴和传统伪造技术之间的差距逐渐拉大，依赖于共同伪造痕迹的跨域检测方法变得越来越无效。因此，迫切需要开发具有强泛化的深.fake检测技术，以应对快速迭代的伪造技术。", "innovation": "本文提出了一种伪造引导学习（FGL）策略，使得检测网络能够不断适应未知的伪造技术。具体来说，FGL策略捕捉已知和未知伪造技术之间的差异信息，使模型能够实时调整其学习过程。此外，设计了双感知网络（DPNet），不仅捕捉伪造痕迹之间的差异，还捕捉它们之间的关系，以提高对伪造痕迹的认知能力。该网络在频率流中动态感知并提取各种伪造技术的判别特征，以及通过图卷积感知整个特征空间的关系，为全面理解伪造痕迹相关性提供了支持。实验表明，该方法在不同场景下具有良好的泛化能力，有效地解决了未知伪造挑战，提供了稳健的深.fake检测支持。", "conclusion": "本文提出了一种基于双感知网络的伪造引导学习策略，具有强泛化能力和实时适应未知伪造技术的能力，不仅能够动态捕捉伪造痕迹之间的差异和关系，还通过图卷积网络增强了整个特征空间的关系感知能力。此方法在多个实验场景中表现良好，能够有效识别出未知的伪造内容，为深.fake检测提供了有力支持。相关代码已经开源。"}
{"llm_update_time": "20250815", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.10770", "html_url": "https://arxiv.org/abs/2508.10770", "title": "从诊断到改进：透视 vision 语言模型中的空间物理推理", "title_en": "From Diagnosis to Improvement: Probing Spatio-Physical Reasoning in Vision Language Models", "authors": "Tiancheng Han,Yunfei Gao,Yong Li,Wuzhou Yu,Qiaosheng Zhang,Wenqi Shao", "background": "空间物理推理是理解真实物理世界的基本能力，对构建稳健的世界模型至关重要。尽管最近的 vision-language 模型（VLMs）在多模态数学和纯粹的空间理解等领域取得了显著进步，但它们在空间物理推理方面的能力尚未得到充分探索。现有模型在这项关键任务上表现欠佳，主要是由于人类先验偏见和缺乏深层次推理造成的。", "innovation": "该研究对主流 VLMs 进行了全面诊断分析，揭示当前模型在空间物理推理方面的不足，并通过监督微调和基于规则的强化学习方法提升了 Qwen2.5-VL-7B 的空间物理推理能力，超越了领先的专业模型，但仍存在对新物理场景的泛化能力有限的问题，强调了在空间物理推理领域需要新的方法。", "conclusion": "尽管经过改进，模型对于新物理场景的泛化能力仍然有限，这表明需要新的方法来解决空间物理推理问题。"}
{"llm_update_time": "20250815", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.10771", "html_url": "https://arxiv.org/abs/2508.10771", "title": "AEGIS: AI生成视频序列的真实性评估基准", "title_en": "AEGIS: Authenticity Evaluation Benchmark for AI-Generated Video Sequences", "authors": "Jieyu Li,Xin Zhang,Joey Tianyi Zhou", "background": "近年来，AI生成内容的发展引发了高度逼真的合成视频的兴起，对社会信任和数字完整性构成严重威胁。现有用于视频真实性检测的基准通常具有较低的现实度、不足的规模和复杂性，无法有效评估现代视觉-语言模型与复杂的伪造技术之间的对抗。为了填补这一关键缺陷，我们提出了AEGIS，这是一个新颖的大规模基准，专门针对高度逼真和语义复杂的AI生成视频的真实性检测。AEGIS包含10,000多个精心挑选的真实和合成视频，由多种最先进的生成模型生成，包括Stable Video Diffusion、CogVideoX-5B、KLing和Sora，涵盖了开源和专有架构。", "innovation": "AEGIS引入了专门设计的具有挑战性的子集，增强了抗性评估。我们还提供了多模态注释，包括语义-真实性描述、运动特征和低级视觉特征，这些注释不仅有助于真实性检测，还支持多模态融合和伪造定位等下游任务。大量的实验表明，最先进的视觉-语言模型在AEGIS最具挑战性的子集上的检测能力有限，突显了该数据集的唯一性和逼真复杂性。", "conclusion": "AEGIS是不可或缺的评估基准，从根本上推动了开发真正坚固、可靠的、广泛概括性的视频真实性检测方法的研究，以应对现实世界的伪造威胁。我们的数据集可在以下链接获得。"}
{"llm_update_time": "20250815", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.10779", "html_url": "https://arxiv.org/abs/2508.10779", "title": "基于生成扩散先验的超高清参考式地标图像超分辨率", "title_en": "Ultra-High-Definition Reference-Based Landmark Image Super-Resolution with Generative Diffusion Prior", "authors": "Zhenning Shi,Zizheng Yan,Yuhang Yu,Clara Xue,Jingyu Zhuang,Qi Zhang,Jinwei Chen,Tao Li,Qingnan Fan", "background": "Reference-based Image Super-Resolution (RefSR) 的目标是通过利用附加参考高分辨率 (参考HR) 图像的语义和纹理信息来恢复低分辨率 (LR) 图像。现有的基于扩散的 RefSR 方法通常基于 ControlNet，但在有效对齐 LR 图像和参考 HR 图像之间的信息方面存在困难。目前，RefSR 数据集的分辨率有限且图像质量不高，导致参考图像缺乏足够的细节，不支持高质量的恢复。", "innovation": "我们提出了 TriFlowSR，这是一种新颖的框架，能够明确地在 LR 图像和参考 HR 图像之间实现模式匹配。同时，我们引入了 Landmark-4K，这是首个用于超高清 (UHD) 场景的 RefSR 数据集。考虑到实际降级的 UHD 场景，TriFlowSR 被设计用于有效匹配 LR 图像和参考 HR 图像。实验结果表明，我们的方法相较于之前的方法更好地利用了参考 HR 图像的语义和纹理信息。这是首次为在实际降级条件下处理超高清地标场景的基于扩散的 RefSR 管道。", "conclusion": "到我们的知识为止，我们提出了首个具有生成扩散先验的基于扩散的 RefSR 管道，用于实际降级条件下的超高清地标场景。我们的代码和模型将在此处获取: this https URL。"}
{"llm_update_time": "20250815", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.10743", "html_url": "https://arxiv.org/abs/2508.10743", "title": "一种高效的模型驱动群组方法用于构建解剖图谱", "title_en": "An Efficient Model-Driven Groupwise Approach for Atlas Construction", "authors": "Ziwei Zou,Bei Zou,Xiaoyan Kui,Wenqi Lu,Haoran Dou,Arezoo Zakeri,Timothy Cootes,Alejandro F Frangi,Jinming Duan", "background": "医学图像分析中的图谱构建是基础性的工作，能够为诸如人群水平的解剖建模这类任务提供标准化的空间参考。尽管数据驱动的配准方法在一对一的任务中显示出成效，但它们需要大量训练数据、泛化能力有限以及在群组场景中缺乏真正的推理过程，限制了它们的实际应用。相比之下，模型驱动的方法提供了无需训练、理论基础明确且数据高效的选择，但在应用于大规模3D数据集时，它们常常面临扩展性和优化上的挑战。因此，文章中介绍了一种新的模型驱动的群组配准框架DARC，该框架支持广泛的图像差异度量标准，并能高效处理任意数量的3D图像，而不引起GPU内存问题。", "innovation": "该工作的创新之处在于引入了一种新的模型驱动的群组配准框架DARC，它可以支持各种图像差异度量标准，高效处理大量3D图像，而不会导致GPU内存问题。DARC通过坐标下降策略和中心性约束激活函数生成无偏的、保真的图谱，其可应用于多种场景：如一次性分割、多示例分割和形状生成等。", "conclusion": "总体而言，DARC提供了一种灵活的、可扩展的和资源高效的方法来构建图谱和用于各种应用。"}
{"llm_update_time": "20250815", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.10774", "html_url": "https://arxiv.org/abs/2508.10774", "title": "Video-BLADE: Block-Sparse Attention Meets Step Distillation for Efficient Video Generation", "title_en": "Video-BLADE: Block-Sparse Attention Meets Step Distillation for Efficient Video Generation", "authors": "Youping Gu,Xiaolong Li,Yuhao Hu,Bohan Zhuang", "background": "当前，扩散变换器在高质量视频生成方面处于领先地位，但它们的缓慢迭代去噪过程和长时间序列难以承受的二次注意力成本导致了显著的推理瓶颈。尽管步进蒸馏和稀疏注意力机制分别表现出加速潜力，但将这两种方法有效结合仍然面临重大挑战，即无训练融合效果不佳，而单独训练稀疏注意力在步进蒸馏之后则需要成本高昂的高质量视频数据集。", "innovation": "我们提出了一种名为BLADE的数据无偏联合训练框架，其中包括：(1) 适应性块稀疏注意力(AASA)机制，用于动态生成内容感知的稀疏性掩码，将计算重点放在显著的空间时间特征上；(2) 以轨迹分布匹配(TDM)为基础的稀疏性意识步进蒸馏范式，直接将稀疏性纳入蒸馏过程，而非将其视为一个压缩步骤，并且具有快速收敛性。", "conclusion": "我们已经在CogVideoX-5B和Wan2.1-1.3B等文本到视频模型上验证了BLADE框架。我们的框架在不同尺度上展示了显著的效率提升。在Wan2.1-1.3B上，BLADE相对于50步基线实现了14.10倍的端到端推理加速。在CogVideoX-5B等视频序列较短的模型上，我们的框架提供了强劲的8.89倍加速。重要的是，加速伴随着一致的质量提升。在VBench-2.0基准测试中，BLADE将CogVideoX-5B的分数从0.534提高到0.569，Wan2.1-1.3B从0.563提高到0.570，这些结果在人类评估中也得到了进一步验证。我们的代码和模型权重可以在以下网址获取：this http URL。"}
{"llm_update_time": "20250815", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.10786", "html_url": "https://arxiv.org/abs/2508.10786", "title": "基于光学流的协作面部活体检测", "title_en": "Cooperative Face Liveness Detection from Optical Flow", "authors": "Artem Sokolov,Mikhail Nikitin,Anton Konushin", "background": "面部活体检测在当前的网络安全中扮演着关键角色，特别是在识别面部识别系统的呈现攻击方面尤为重要。传统的活体检测方法通常依赖于被动的数据分析，可能导致误判。本文提出的活体检测方法则通过控制面部接近摄像机的运动模式来提高检测准确率，这种方法结合了光学流分析，为面部活体检测提供了新的视角和技术改进空间。", "innovation": "一种基于新用户交互模式的协作视频活体检测方法，该模式要求参与者慢慢将面向摄像机的面部移近摄像头。结合使用光学流分析技术，该方法的成功之处在于设计了一个用户需遵循特定运动模式的系统，通过神经光学流估计技术，可以有效提取面部体积信息，大幅提高了对真实和各种呈现攻击的区分能力。该方法同时处理预测的光学流和RGB图像，利用空间-时间特征进行更加可靠的活体检测，相比传统的被动方法有了显著提升。", "conclusion": "本文提出的方法有效地解决了面部活体检测中的一些关键技术问题，通过用户主动参与的特定面部移动模式和光学流分析，提高了活体检测的准确性。该方法结合了流动光和RGB数据，利用神经网络对时空特征的有效提取，显著提升了活体检测性能，具有广泛的应用前景。"}
{"llm_update_time": "20250815", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.10817", "html_url": "https://arxiv.org/abs/2508.10817", "title": "移动友好型深度学习在33种作物101类植物病害检测中的轻量级CNN基准", "title_en": "Mobile-Friendly Deep Learning for Plant Disease Detection: A Lightweight CNN Benchmark Across 101 Classes of 33 Crops", "authors": "Anand Kumar,Harminder Pal Monga,Tapasi Brahma,Satyam Kalra,Navas Sherif", "background": "植物疾病是全球粮食安全的重大威胁。开发能够准确检测植物疾病的早期检测系统至关重要。随着计算机视觉技术的进步，这一挑战有望得到解决。", "innovation": "开发了一个移动友好型解决方案，能够准确分类33种作物的101种植物疾病。采用了MobileNetV2、MobileNetV3、MobileNetV3-Large和EfficientNet-B0、B1等多种轻量级架构进行性能评估，最终EfficientNet-B1达到了94.7%的分类准确率，平衡了准确性和计算效率。", "conclusion": "该架构适用于资源受限设备上的实际部署。实验结果表明，轻量级CNN在植物病害检测方面具有巨大潜力，尤其是在移动设备上的应用。"}
{"llm_update_time": "20250815", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.10801", "html_url": "https://arxiv.org/abs/2508.10801", "title": "Object Fidelity Diffusion for Remote Sensing Image Generation", "title_en": "Object Fidelity Diffusion for Remote Sensing Image Generation", "authors": "Ziqi Ye,Shuran Ma,Jie Yang,Xiaoyi Yang,Ziyang Gong,Xue Yang,Haipeng Wang", "background": "高精度的遥感图像生成在意义和挑战并存，现有的扩散模型往往由于难以充分捕捉形态细节而生成低保真度的图像，这可能影响检测模型的稳健性和可靠性。因此，提高远程感应中生成对象的准确性和保真度具有重要意义。", "innovation": "本文提出了Object Fidelity Diffusion (OF-Diff)，这是一种基于布局提取对象先验形状的新型扩散模型，能够生成高保真度的遥感图像。OF-Diff引入了一种具有扩散一致性损失的双分支扩散模型，在采样阶段无需提供真实图像，同时引入DDPO进一步优化了扩散过程，使得生成的遥感图像更具有多样性和语义一致性。实验结果表明，与现有最先进的方法相比，OF-Diff在关键质量指标上表现出色，特别是在多形性和小型对象类别方面表现尤为突出，mAP分别提高了8.3%、7.7%和4.0%对于飞机、船只和车辆而言。", "conclusion": "综合实验结果证明，OF-Diff在遥感图像生成中表现出色，能够显著提升生成对象的保真度和准确性，特别是在处理多形性和小型对象时表现出明显优势。"}
{"llm_update_time": "20250815", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.10838", "html_url": "https://arxiv.org/abs/2508.10838", "title": "多基线对比学习的无监督立体匹配", "title_en": "Self-Supervised Stereo Matching with Multi-Baseline Contrastive Learning", "authors": "Peng Xu,Zhiyu Xiang,Jingyun Fu,Tianyu Pu,Kai Wang,Chaojie Ji,Tingming Bai,Eryun Liu", "background": "当前的自监督立体匹配方法依赖于光度一致性假设，但在被遮挡区域失效，因为这些区域存在歧义的对应关系。", "innovation": "本文提出了一种名为BaCon-Stereo的简单而有效的对比学习框架，用于自监督立体网络训练，并在非遮挡和遮挡区域都表现出色。该方法采用了双教师-学生范式和多基线输入，使教师更容易在遮挡区域预测，并引入了一种注意图来更好地指导学生学习遮挡恢复。", "conclusion": "广泛的实验表明，BaCon-Stereo在被遮挡和非遮挡区域都提高了预测精度，具备强大的泛化能力和鲁棒性，在KITTI 2015和2012基准上均优于最先进的自监督方法。源代码和数据集将在论文提交后公开。"}
{"llm_update_time": "20250815", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.10840", "html_url": "https://arxiv.org/abs/2508.10840", "title": "使用客户端自适应焦点调制的可泛化联邦学习", "title_en": "Generalizable Federated Learning using Client Adaptive Focal Modulation", "authors": "Tajamul Ashraf,Iqra Altaf Gillani", "background": "联邦学习（FL）已被证明对于跨分布式客户端进行隐私保护的协作训练至关重要。我们的先前研究TransFed提出了一种基于转换器的健壮的FL框架，引入了一种学习适应的超网络来生成针对每个客户端的个性化焦点调制层，从而在非IID和跨域设置中优于传统方法。", "innovation": "1. 提出了改进的自适应策略，通过整合任务感知客户端嵌入进一步个性化调制动力学；\n2. 提出了增强的自适应性能理论界；\n3. 对包括时间序列和多语言数据在内的其他模态进行了更广泛的实证验证。\n此外，还引入了TransFed的一个高效变种，通过低秩超网络条件减少服务器客户端的通信开销，使其在资源受限环境中更具扩展性。", "conclusion": "广泛的实验表明，我们的方法在多种数据集上优于最先进的基线方法，特别是在无源和跨任务联邦设置中。我们的研究不仅扩展了焦点调制在FL中的能力，还为更适应、更可扩展和更可泛化的基于转换器的联邦系统开辟了道路。"}
{"llm_update_time": "20250815", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.10833", "html_url": "https://arxiv.org/abs/2508.10833", "title": "UI-Venus 技术报告：使用RFT构建高性能UI代理", "title_en": "UI-Venus Technical Report: Building High-performance UI Agents with RFT", "authors": "Zhangxuan Gu,Zhengwen Zeng,Zhenyu Xu,Xingran Zhou,Shuheng Shen,Yunfei Liu,Beitong Zhou,Changhua Meng,Tianyu Xia,Weizhi Chen,Yue Wen,Jingya Dou,Fei Tang,Jinzhen Lin,Yulin Liu,Zhenlin Guo,Yichen Gong,Heng Jia,Changlong Gao,Yuan Guo,Yong Deng,Zhenyu Guo,Liang Chen,Weiqiang Wang", "background": "本文介绍了UI-Venus，这是一种仅基于多模态大语言模型和截图输入的原生UI代理。通过使用基于Qwen2.5-VL的强化微调（RFT），UI-Venus在多种场景中实现了SOTA性能。具体而言，它在标准的UI接地基准测试中（例如Screenspot-V2/Pro）取得了卓越的成绩，超过了先前的SOTA基线，包括开源的GTA1和非开源的LT2-RL系统。此外，为了评估UI-Venus的总结和规划能力，还对其在AndroidWorld（一个在线UI导航竞技场）进行了评估。", "innovation": "UI-Venus的关键创新在于它仅通过几种高质量的训练样本实现了这一点，这些样本是通过基于Qwen2.5-VL的强化微调获得的。为了进一步提高导航性能，提出了Self-Evolving Trajectory History Alignment & Sparse Action Enhancement（自适应轨迹历史对齐与稀疏动作增强）方法，该方法通过细化历史推理痕迹并平衡稀疏但关键动作的分布，从而在复杂UI任务中实现了更一致的规划和更好的泛化能力。此外，编写了先进的数据清洗协议，构建了新的自我进化框架，这些都为社区中的进一步研究和开发提供了支持。", "conclusion": "UI-Venus的主要贡献在于其发布SOTA开源UI代理、全面的数据清洗协议和一个新的用于提升导航性能的自我进化框架。这些结果鼓励了社区中进一步的研究和发展。完整的代码可以从这里获取：this http URL"}
{"llm_update_time": "20250815", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.10794", "html_url": "https://arxiv.org/abs/2508.10794", "title": "VasoMIM: 肢体解剖学意识的掩码图像建模方法在血管分割中的应用", "title_en": "VasoMIM: Vascular Anatomy-Aware Masked Image Modeling for Vessel Segmentation", "authors": "De-Xing Huang,Xiao-Hu Zhou,Mei-Jiang Gui,Xiao-Liang Xie,Shi-Qi Liu,Shuang-Yi Wang,Tian-Yu Xiang,Rui-Ze Ma,Nu-Fang Xiao,Zeng-Guang Hou", "background": "X射线血管成像在许多临床应用中至关重要，但由于标注数据稀缺，导致难以获得高质量的血管分割结果。传统的方法难以利用大量未标注的数据进行有效的学习。大规模未标注数据的利用可以通过自监督学习（SSL）方法实现，如掩码图像建模（MIM），但常规的MIM方法在区分血管与背景时表现不佳，导致血管特征不明显。", "innovation": "作者提出了一种新型的掩码图像建模框架——Vascular anatomy-aware Masked Image Modeling (VasoMIM)，专门为X射线血管成像设计。该框架通过结合解剖引导的掩蔽策略和解剖一致性损失，有效地整合了解剖学知识，增加了血管特征的区分度，提升了血管分割的准确率。", "conclusion": "实验结果显示，VasoMIM在三个数据集上取得了最先进的性能，显示了其在X射线血管成像分析中的潜在价值。"}
{"llm_update_time": "20250815", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.10858", "html_url": "https://arxiv.org/abs/2508.10858", "title": "Hierarchical Fine-grained Preference Optimization for Physically Plausible Video Generation", "title_en": "Hierarchical Fine-grained Preference Optimization for Physically Plausible Video Generation", "authors": "Harold Haodong Chen,Haojian Huang,Qifeng Chen,Harry Yang,Ser-Nam Lim", "background": "近年来，视频生成技术取得了显著进步，能够在视觉上呈现高质量的视频内容。然而，生成符合物理定律的视频依旧是一个关键挑战，特别是在需要真实性和准确性的应用场景中。本研究旨在解决这一难题，提出了一种新颖的框架，名为PhysHPO，用于层次化的交叉模态直接偏好优化，以实现对生成视频的物理合理性进行精准调整。", "innovation": "PhysHPO框架引入了四个层次的视频对齐优化：实例级别，通过整体内容与输入提示对齐；状态级别，利用边界帧作为锚点以确保时间一致性；运动级别，通过建模运动轨迹来模拟真实的动力学；语义级别，则保持叙事和视觉内容的一致性。此外，研究进一步引入了一个自动数据选择流水线，可以高效地从大规模的图文数据集中识别和利用“优质数据”，从而减少数据集构建的高成本和长时间需求。本研究在物理聚焦和一般能力评估基准上进行了广泛实验，表明PhysHPO显著提升了视频生成质量和物理合理性。这是首个探索视频生成中细致偏好优化和数据选择的研究，为生成更真实和更符合人类偏好的视频开辟了新途径。", "conclusion": "PhysHPO框架在物理合理性及视频生成质量上取得了显著提升，是第一个在视频生成领域探索细致偏好优化和数据选择的研究，将推动更真实且受人类偏好欢迎的视频生成模式的发展。"}
{"llm_update_time": "20250815", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.10881", "html_url": "https://arxiv.org/abs/2508.10881", "title": "ToonComposer：生成后关键帧简化卡通生产", "title_en": "ToonComposer: Streamlining Cartoon Production with Generative Post-Keyframing", "authors": "Lingen Li,Guangzhi Wang,Zhaoyang Zhang,Yaowei Li,Xiaoyu Li,Qi Dou,Jinwei Gu,Tianfan Xue,Ying Shan", "background": "传统的卡通和动漫制作涉及关键帧设置、中间绘制和着色步骤，这些过程需要大量的手工劳动。尽管最近人工智能技术得到了飞速发展，但现有的方法仍然常常分别处理这些步骤，导致累积误差和视觉瑕疵。例如，中间绘制方法在处理大动作时会遇到困难，而着色方法则需要密集的每帧素描指导。", "innovation": "ToonComposer是一种生成模型，它将中间绘制和着色整合到关键帧处理后的单一阶段。ToonComposer使用稀疏素描注入机制，通过关键帧素描提供精确控制。此外，它采用卡通适应方法，利用空间低秩适配器将现代视频基础模型调整至卡通领域，同时保持其时间先验不变。这一点只需要一张素描和一个着色参考帧，ToonComposer能够高效处理稀疏输入，同时支持在任何时间位置添加多张素描以实现更精确的运动控制。", "conclusion": "这一双重能力可以减少手工劳动并提高灵活性，使艺术家在现实场景中能够更好地应用。为了评估我们的模型，我们还创建了PKBench，一种包含由真人绘制的素描基准，模拟真实世界的使用案例。我们的评估结果显示，ToonComposer在视觉质量和运动一致性方面优于现有方法，并显著提高了生产效率，提供了一种更优越且更具灵活性的AI辅助卡通制作解决方案。"}
{"llm_update_time": "20250815", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.10869", "html_url": "https://arxiv.org/abs/2508.10869", "title": "Medico 2025: Visual Question Answering for Gastrointestinal Imaging", "title_en": "Medico 2025: Visual Question Answering for Gastrointestinal Imaging", "authors": "Sushant Gautam,Vajira Thambawita,Michael Riegler,Pål Halvorsen,Steven Hicks", "background": "该论文的主题是针对胃肠（GI）成像的视觉问答（VQA），作为MedialEval任务系列的一部分，旨在通过Developing Explainable Artificial Intelligence (XAI) 模型，解决临床相关的视觉问题并提供可解释的推理支持临床决策。", "innovation": "该挑战引入了两个子任务：利用Kvasir-VQA-x1数据集回答多种视觉问题和生成多模态解释以支持临床决策。通过结合定性和定量指标（包括专家审查的解释可解释性评估），该任务旨在推动可信赖的人工智能（AI）在医学图像分析中的发展。", "conclusion": "该挑战的任务旨在通过先进的XAI模型推动信任可靠的AI在医学图像分析中的应用，并为临床决策提供了透明和可解释的支持。"}
{"llm_update_time": "20250815", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.10865", "html_url": "https://arxiv.org/abs/2508.10865", "title": "GPT-5在脑肿瘤MRI推理中的表现", "title_en": "Performance of GPT-5 in Brain Tumor MRI Reasoning", "authors": "Mojtaba Safari,Shansong Wang,Mingzhe Hu,Zach Eidex,Qiang Li,Xiaofeng Yang", "background": "准确区分磁共振成像(MRI)中的脑肿瘤类型对神经肿瘤学中的治疗计划至关重要。最近，大型语言模型(LLMs)的进步使得结合图像解释和自然语言推理的视觉问答(VQA)方法得以实现。研究汇集了来自3个脑肿瘤分割(BraTS)数据集的胶质母细胞瘤(GLI)、脑膜瘤(MEN)和脑转移瘤(MET)案例进行VQA基准测试，评估了几种GPT模型的性能。", "innovation": "该研究使用了GPT-5系列模型，包括GPT-5-mini、GPT-5、GPT-4o和GPT-5-nano，这些模型被用于零样本链式思维设置下的视觉和推理任务。研究表明，GPT-5-mini获得了最高的宏平均准确率（44.19%），其次是GPT-5（43.71%）、GPT-4o（41.49%）和GPT-5-nano（35.85%）。不同类型的肿瘤表现出不同的性能，没有单一模型在所有组中均表现最佳。这表明GPT-5家族模型在结构化的神经肿瘤学VQA任务中可以达到中等准确率，但尚未达到临床应用的水平。", "conclusion": "GPT-5系列模型在结构化神经肿瘤学VQA任务中可以实现中等准确率，但在临床应用方面仍需进一步改进。"}
{"llm_update_time": "20250815", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.10896", "html_url": "https://arxiv.org/abs/2508.10896", "title": "ESSENTIAL: Episodic and Semantic Memory Integration for Video Class-Incremental Learning", "title_en": "ESSENTIAL: Episodic and Semantic Memory Integration for Video Class-Incremental Learning", "authors": "Jongseo Lee,Kyungho Bae,Kyle Min,Gyeong-Moon Park,Jinwoo Choi", "background": "当前的视频类增量学习（VCIL）方法致力于通过回放训练来缓解灾难性遗忘问题，这种方法存储少量密集时间样本于情景记忆中，但这种方式是内存效率低下的。另一种方法则是存储稀疏时间样本，这牺牲了关键的时间信息，导致性能较差。因此需要一种在内存效率和性能间取得平衡的方法来解决这一问题。", "innovation": "本文提出了一种新的方法ESSENTIAL，该方法通过情景记忆存储稀疏时间特征，并通过可学习提示存储语义记忆中的通用知识。此外，ESSENTIAL还引入了一个新颖的记忆检索（MR）模块，通过交叉注意将其情景记忆和语义提示整合，从而实现从稀疏时间特征检索密集时间特征。这种方法有效地平衡了内存效率和性能之间的权衡，证明了在多种数据集上的优越性能，即使在大大减少内存占用的情况下。", "conclusion": "ESSENTIAL在多种数据集（TCD基准的UCF-101、HMDB51、Something-Something-V2和vCLIMB基准的UCF-101、ActivityNet、Kinetics-400）上展示了良好的性能，证明了其能高效且有效地解决视频类增量学习中记忆和性能之间的权衡问题。"}
{"llm_update_time": "20250815", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.10894", "html_url": "https://arxiv.org/abs/2508.10894", "title": "MAESTRO: Masked AutoEncoders for Multimodal, Multitemporal, and Multispectral Earth Observation Data", "title_en": "MAESTRO: Masked AutoEncoders for Multimodal, Multitemporal, and Multispectral Earth Observation Data", "authors": "Antoine Labatie,Michael Vaccaro,Nina Lardiere,Anatol Garioud,Nicolas Gonthier", "background": "当前，半监督学习在遥感领域展现出巨大的潜力，但标准的半监督方法需要针对地球观测数据的独特特性进行调整。论文通过全面评估融合策略和重建目标归一化方案，探讨了如何适应多元模态、多时相和多光谱地球观测数据。", "innovation": "提出了MAESTRO（Masked Autoencoder for Earth Observation），这是一种改进的Masked Autoencoder方法，采用优化的融合策略和定制化的目标归一化方案。特别引入了光谱先验作为自我监督信号。", "conclusion": "MAESTRO在依赖多时相动态的任务中达到了新的SOTA水平，同时在主导单一单时相模态的任务中保持了极高的竞争力。相关代码已在 提供，可以进行重复实验。"}
{"llm_update_time": "20250815", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.10897", "html_url": "https://arxiv.org/abs/2508.10897", "title": "Human-in-Context: 通过情境学习实现统一跨域3D人体运动建模", "title_en": "Human-in-Context: Unified Cross-Domain 3D Human Motion Modeling via In-Context Learning", "authors": "Mengyuan Liu,Xinshun Wang,Zhongbin Fang,Deheng Ye,Xia Li,Tao Tang,Songtao Wu,Xiangtai Li,Ming-Hsuan Yang", "background": "现有的跨域模型通常依赖于领域特定组件和多阶段训练，这限制了它们的实际应用能力和可扩展性。因此，作者旨在建模跨领域的3D人体运动，期望单一模型能够处理多种模态、任务和数据集，同时解决多模态、任务和数据集之间的一般化问题，以及上下文依赖性处理难题", "innovation": "本文提出了一种新的方法通过单一步骤训练统一的跨域模型（Human-in-Context, HiC），通过结合姿势和网格表示来统一框架，扩大任务覆盖范围，并引入大规模数据集。此外，HiC引入了最大-最小相似度提示采样策略和具有双重上下文注入的网络架构，以增强跨多样化领域的一般化能力", "conclusion": "实验结果表明，HiC在泛化能力、数据规模和多种领域的性能方面优于PiC，这表明HiC具有构建具有良好灵活性和可扩展性的统一跨域3D人体运动模型的潜力。源代码和模型可在指定链接获取"}
{"llm_update_time": "20250815", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.10868", "html_url": "https://arxiv.org/abs/2508.10868", "title": "TexVerse: 高分辨率纹理三维对象的宇宙", "title_en": "TexVerse: A Universe of 3D Objects with High-Resolution Textures", "authors": "Yibo Zhang,Li Zhang,Rui Ma,Nan Cao", "background": "近年来，大规模3D数据集在高分辨率几何生成方面取得了显著进展，但创建端到端的高分辨率纹理却鲜有涉及，主要原因是缺乏合适的数据集。因此，迫切需要一个能够提供高分辨率纹理3D模型的数据集来填补这一空白。TexVerse提供了一个集合超过858,000个独特的高分辨率3D模型，这些模型来自Sketchfab，并且其中超过158,000个模型使用了基于物理的渲染（PBR）材质。每个模型包含所有高分辨率变体，总数达到1.6百万个3D实例。此外，TexVerse还包含了专门的子集：TexVerse-Skeleton（69,000个带绑定骨骼的模型）和TexVerse-Animation（54,000个动画模型），这些子集在用户上传的原始骨骼和动画数据基础上保证数据的完整性。TexVerse还提供了详细的模型注释，描述整体特征、结构组件和细节点缀。这些数据资源具有广泛的潜在应用，如纹理合成、PBR材质开发、动画及各种3D视觉和图形任务中。", "innovation": "TexVerse通过提供一个包含超过858,000个独特的高分辨率3D模型的数据集，填补了高分辨率纹理生成这一研究领域的空白。这些模型涵盖广泛的应用领域，如纹理合成、PBR材质开发、动画及3D视觉和图形任务，极大地促进了这些领域的研究和发展。TexVerse的数据不仅包括无绑定骨骼和无动画的数据，还提供了带绑定骨骼和动画的数据，保留了用户上传的原始数据。此外，TexVerse还提供了详细的模型注释，为研究人员和开发者提供了额外的数据信息。", "conclusion": "TexVerse为高分辨率纹理和3D对象的研究提供了高质量的数据资源，具有广泛的潜在应用。这一数据集不仅能够推动纹理合成和PBR材质开发等领域的研究，还能支持动画、3D视觉和图形任务的发展。通过提供全面的数据集，TexVerse有助于开发更加逼真和复杂的3D模型，并为各种3D应用提供了强有力的支持。"}
{"llm_update_time": "20250815", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.10065", "html_url": "https://arxiv.org/abs/2508.10065", "title": "隐形水印，可见收益：基于双层水印设计引导机器遗忘", "title_en": "Invisible Watermarks, Visible Gains: Steering Machine Unlearning with Bi-Level Watermarking Design", "authors": "Yuhao Sun,Yihua Zhang,Gaowen Liu,Hongtao Xie,Sijia Liu", "background": "随着对于被遗忘权利的需求增加，机器遗忘(MU)已经作为一种提升信任和合规性的关键工具出现。现有MU算法主要依赖于训练时方法调整模型权重，而较少探索数据层面调整对训练过程带来的好处。", "innovation": "本文提出了一种新的基于数据层面调整的数据水印技术，通过巧妙地修改数据内容来支持MU。本文定义了一个名为Water4MU的框架，结合双层优化框架，在上层优化水印网络以最小化遗忘难度，在下层独立训练模型。研究结果表明，Water4MU在图像分类和图像生成任务中都能有效进行MU，特别是在具有挑战性的遗忘场景中性能超越现有方法。", "conclusion": "实验结果表明Water4MU在MU方面取得了显著效果，在图像分类和生成任务中表现优异，并在具有挑战性的遗忘场景中具有超越现有方法的优势。"}
{"llm_update_time": "20250815", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.10893", "html_url": "https://arxiv.org/abs/2508.10893", "title": "STream3R：基于因果Transformer的可扩展序列化3D重建", "title_en": "STream3R: Scalable Sequential 3D Reconstruction with Causal Transformer", "authors": "Yushi Lan,Yihang Luo,Fangzhou Hong,Shangchen Zhou,Honghua Chen,Zhaoyang Lyu,Shuai Yang,Bo Dai,Chen Change Loy,Xingang Pan", "background": "现有的多视角重建方法或者依赖于昂贵的全局优化，或者依靠简单但扩展性差的记忆机制。相比之下，STream3R提出了一种新的方法，将点云预测重新表述为解码器占主导地位的Transformer问题，并引入了一个流式框架，使用因果注意力机制高效处理图像序列。", "innovation": "STream3R能够在线学习大规模3D数据集的几何先验，使其能够很好地泛化到各种复杂场景，包括传统方法经常失败的动态场景。此外，STream3R与大型语言模型风格的训练基础设施兼容，可实现各种下游3D任务的大规模预训练和微调。实验结果显示，STream3R在静态和动态场景基准测试中都优于现有方法。", "conclusion": "我们的工作证实了因果Transformer模型在在线3D感知中的潜力，为流式环境中的实时3D理解铺平了道路。"}
{"llm_update_time": "20250815", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.10898", "html_url": "https://arxiv.org/abs/2508.10898", "title": "Puppeteer: 控制和动画化您的3D模型", "title_en": "Puppeteer: Rig and Animate Your 3D Models", "authors": "Chaoyue Song,Xiu Li,Fan Yang,Zhongcong Xu,Jiacheng Wei,Fayao Liu,Jiashi Feng,Guosheng Lin,Jianfeng Zhang", "background": "现代互动应用越来越需要动态3D内容，但将静态3D模型转换为动画资产仍然是内容创建管道中的一个瓶颈。尽管生成式AI在静态3D模型的创建中取得了革命性的进步，但动画制作和绑定仍然严重依赖专家的干预。这个问题在内容创作过程中尤为突出，特别是在需要快速生成多样3D物体的场景中更加明显，因此亟需一种自动化解决这两种问题的方法。", "innovation": "提出了Puppeteer，一个全面的框架，旨在解决各种3D物体的自动绑定和动画问题。该系统通过自回归变换器预测可能的骨骼结构，并通过基于关节的分层序数方法和随机扰动增强双向学习能力。接着利用注意力机制架构推断蒙皮权重，明确编码基于骨骼图距离的关节关系。最后，采用基于可微优化的动画管道生成稳定、高质量的动画，相比现有方法计算效率更高。广泛的基准测试结果显示，在骨骼预测准确性和蒙皮质量方面，该方法显著优于当前最先进的技术，并且系统能够稳健地处理从专业游戏资产到AI生成的形状多样化3D内容，生成的时间连贯动画消除了现有方法中的抖动问题。", "conclusion": "本研究表明，Puppeteer显著提高了骨骼预测和蒙皮的准确性，适用于多种3D内容，特别是在游戏资产和AI生成形状的动画生成方面表现出色。该系统通过自动化处理绑定和动画问题，大大提高了3D内容的制作效率，促进互动应用中3D动态内容的开发。"}
{"llm_update_time": "20250815", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.10219", "html_url": "https://arxiv.org/abs/2508.10219", "title": "AI驱动捕获和分析没收象牙上的手写标记：揭示非法野生动物贸易犯罪网络的工具", "title_en": "AI-Driven Detection and Analysis of Handwriting on Seized Ivory: A Tool to Uncover Criminal Networks in the Illicit Wildlife Trade", "authors": "Will Fein,Ryan J. Horwitz,John E. Brown III,Amit Misra,Felipe Oviedo,Kevin White,Juan M. Lavista Ferres,Samuel K. Wasser", "background": "非洲象群数量持续下降，主要由于跨国象牙走私网络致使。执法部门没收的象牙携有走私分子的关键信息，包括DNA证据和走私分子的手写标记。虽然遗传证据分析有助于追踪走私路线和连接走私批次，但遗传数据的收集成本高昂且有时不可行，而手写标记虽易拍摄但很少被记录和分析。本文的研究填补了遗传数据不足的空白。", "innovation": "本文提出了一种基于AI的处理和分析没收象牙上的手写标记的流水线，这是一种新型、可扩展且低成本的法医学证据来源。通过六年（2014-2019）八次大规模象牙没收案件，共拍摄了6,085张照片，使用目标检测模型提取了17,000多个标志，并通过先进的AI工具进行标记和描述。本文识别出184个重复出现的'签名标记'，并观察到20个'签名标记'在不同没收案件中出现，由此建立了供应链中的执法连接。这项工作通过AI在野生动物法医学中的应用潜力，补充了其他调查技术。", "conclusion": "这项研究表明AI在野生动物法医学中的变革潜力，并强调了将手写分析纳入打击有组织野生动物犯罪工作中实际步骤的重要性。"}
{"llm_update_time": "20250815", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.10196", "html_url": "https://arxiv.org/abs/2508.10196", "title": "使用卷积神经网络的可解释人工智能技术在肺癌检测中的应用", "title_en": "Explainable AI Technique in Lung Cancer Detection Using Convolutional Neural Networks", "authors": "Nishan Rai,Sujan Khatri,Devendra Risal", "background": "早期发现肺癌是提高生存率的关键。本文介绍了一种深度学习框架，用于从胸部计算机断层扫描（CT）图像中自动进行肺癌筛查，该框架集成了可解释性功能。研究使用了IQ-OTH/NCCD数据集（1,197次扫描，分为正常、良性、恶性三类），评估了自定义卷积神经网络（CNN）和三种微调迁移学习骨干模型：DenseNet121、ResNet152和VGG19。经过成本敏感学习训练以缓解类别不平衡问题，并通过准确率、精确率、召回率、F1分数和ROC-AUC进行评估。结果表明，尽管ResNet152的准确率最高（97.3%），但DenseNet121在精确率、召回率和F1分数方面提供了最佳的整体平衡（分别为92%、90%、91%）。", "innovation": "本文提出了一种结合可解释性的深度学习框架，用于自动进行肺癌筛查，利用Shapley Additive Explanations (SHAP)可视化支持临床透明度，从而能在资源受限的环境中提供快速、准确且可解释的肺癌筛查支持。", "conclusion": "CNN基方法与可解释性相结合可以提供快速、准确且可解释的支持，特别是在资源有限的环境中。"}
{"llm_update_time": "20250815", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.10299", "html_url": "https://arxiv.org/abs/2508.10299", "title": "通过知识增强初始化提高联邦适配器调谐中新疾病学习", "title_en": "Improving Learning of New Diseases through Knowledge-Enhanced Initialization for Federated Adapter Tuning", "authors": "Danni Peng,Yuan Wang,Kangning Cai,Peiyan Ning,Jiming Xu,Yong Liu,Rick Siow Mong Goh,Qingsong Wei,Huazhu Fu", "background": "在医疗领域，联邦学习（FL）是一种广泛采用的框架，它使医疗机构能够在保护隐私的同时进行合作。由于大规模基础模型（FMs）展现了令人印象深刻的能力，使用成本效率高的适配器调谐来在FL中应用FMs已成为一种流行的方法。面对迅速变化的医疗环境，个体客户端需要快速适应新任务或疾病，这需要通过调谐适配器并利用过去的经验来实现。", "innovation": "本文提出了一种新的框架FedKEI，以利用跨客户端和跨任务的知识迁移来为学习新任务提供有信息量的初始化。该框架首先在服务器上进行全局聚类过程以跨任务泛化知识，随后优化跨聚类（即簇间权重）和簇内（即簇内权重）的知识转移权重，以个性化知识转移应用于每个新任务。为了促进更有效的跨和簇内权重学习，采用了双层优化方案，客户端协同学习全局簇内权重，局部优化簇间权重以靠近各客户端的任务目标。", "conclusion": "在三种不同模态的基准数据集上的实验证明，与最先进的方法相比，FedKEI在适应新疾病方面表现出优势。"}
{"llm_update_time": "20250815", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.10298", "html_url": "https://arxiv.org/abs/2508.10298", "title": "SynBrain：通过概率表示学习增强视觉至fMRI合成", "title_en": "SynBrain: Enhancing Visual-to-fMRI Synthesis via Probabilistic Representation Learning", "authors": "Weijian Mai,Jiamin Wu,Yu Zhu,Zhouheng Yao,Dongzhan Zhou,Andrew F. Luo,Qihao Zheng,Wanli Ouyang,Chunfeng Song", "background": "在计算神经科学中，解析视觉刺激如何转化为大脑皮层反应是一个基本挑战。这种视觉到神经映射是内在的一对多关系，相同的视觉输入会在不同试验、不同情景和不同受试者中可靠地诱发不同强度的血氧水平依赖性反应。现有确定性方法在同时建模这种生理变异性的同时捕捉功能一致性（编码刺激信息）方面力有不逮。", "innovation": "本文提出了一种生成性框架——SynBrain。该框架通过概率学习将神经表示建模为连续概率分布，同时利用视觉语义约束保持功能性一致性。此外，Semantic-to-Neural Mapper充当语义传输路径，将视觉语义投影到神经响应流形中，促进高保真fMRI合成。实验结果表明，SynBrain 在特定受试者视觉至fMRI编码性能方面优于现有最佳方法。此外，SynBrain 能够利用少量样本数据快速适应新受试者，并生成高质量fMRI信号，从而改善数据受限的fMRI至图像解码性能。SynBrain 还揭示了不同试验和受试者间的功能性一致性，合成信号捕捉到由生物神经变异性塑造的可解释模式。", "conclusion": "SynBrain 设计具有高效、生物可解释性和通用性，在视觉刺激到fMRI反应的转化研究中展现了显著优势。未来研究可以通过增加更多变体数据来提升模型的适应性和泛化能力。代码将公开发布。"}
{"llm_update_time": "20250815", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.10307", "html_url": "https://arxiv.org/abs/2508.10307", "title": "使用全局和局部循环表示的高效图像去噪", "title_en": "Efficient Image Denoising Using Global and Local Circulant Representation", "authors": "Zhaoming Kong,Jiahuan Zhang,Xiaowei Yang", "background": "随着成像设备的进步和每天生成的海量图像数据，对高效且有效的图像去噪的需求日益增加。因此，本文提出了一种称为Haar-tSVD的计算简单去噪算法，旨在探索非局部自相似性先验，并利用主成分分析（PCA）与Haar变换在循环表示下的连接性。该方法能够通过波submenuar变换和张量奇异值分解（t-SVD）投影有效地捕获全局和局部块的相关性，从而形成一种单一步骤的、高度并行化的滤波方法，能够从图像块表示中删除局部基学习的需求，平衡了去噪速度和性能之间的关系。", "innovation": "提出了一种称之为Haar-tSVD的简单高效去噪算法，该算法能够通过统一的张量奇异值分解（t-SVD）投影和Haar变换有效地捕捉全局和局部块的相关性。此外，引入了一种基于CNN估计器和特征值分析的自适应噪声估计方案，以增强方法的鲁棒性和适应性。", "conclusion": "在不同真实的图像去噪任务中的实验验证了Haar-tSVD在噪声消除和细节保留方面的效率和有效性。相关数据、代码和结果在此链接中提供开源下载：this https URL。"}
{"llm_update_time": "20250815", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.10118", "html_url": "https://arxiv.org/abs/2508.10118", "title": "从意图到执行：基于多模态链式思考的强化学习精确 CAD 代码生成", "title_en": "From Intent to Execution: Multimodal Chain-of-Thought Reinforcement Learning for Precise CAD Code Generation", "authors": "Ke Niu,Haiyang Yu,Zhuofan Chen,Mengyang Zhao,Teng Fu,Bin Li,Xiangyang Xue", "background": "计算机辅助设计 (CAD) 在工程和制造中起着至关重要的作用，但当前的 CAD 工作流需要大量的专业知识和手动建模努力。尽管大型语言模型 (LLMs) 近期进展已经能够从自然语言生成代码，但将人类的设计意图直接转化为可执行的 CAD 代码仍然极具挑战性，因为需要逻辑推理、语法规则正确性和数值精度。因此，本文提出了一种名为 CAD-RL 的多模态链式思考 (CoT) 强化学习后训练框架，用于 CAD 模型代码生成。该方法结合了基于 CoT 的冷启动和目标驱动的强化学习后训练，使用了三种特定任务的奖励：可执行性奖励、几何精度奖励和外部评价奖励，以稳定的策略学习来应对稀疏且高方差的奖励条件。此外，还引入了三个针对性的优化策略：限域区扩展优化了探索，精度代币损失提高了维度参数的准确性，以及过长过滤以减少噪音监督。为了支持训练和基准测试，本文发布了一个名为 ExeCAD 的新数据集，包含 16,540 个真实的 CAD 示例，这些示例具有配对的自然语言和结构化设计语言描述、可执行 CADQuery 脚本和渲染的 3D 模型。实验结果表明，CAD-RL 在推断质量、输出精度和代码可执行性方面均实现了显著改进，超越了现有模型。", "innovation": "本文提出了一种名为 CAD-RL 的多模态链式思考 (CoT) 强化学习后训练框架，用于 CAD 模型代码生成。该方法结合了基于 CoT 的冷启动和目标驱动的强化学习后训练，使用了三种特定任务的奖励：可执行性奖励、几何精度奖励和外部评价奖励，以应对稀疏且高方差的奖励条件。同时，引入了三个针对性的优化策略：限域区扩展优化了探索，精度代币损失提高了维度参数的准确性，以及过长过滤以减少噪音监督。此外，还公开了一个包含 16,540 个真实的 CAD 示例的新数据集，以支持训练和基准测试。", "conclusion": "实验结果表明，CAD-RL 在推断质量、输出精度和代码可执行性方面均实现了显著改进，超越了现有模型。"}
{"llm_update_time": "20250815", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.10333", "html_url": "https://arxiv.org/abs/2508.10333", "title": "ReconVLA: Reconstructive Vision-Language-Action Model as Effective Robot Perceiver", "title_en": "ReconVLA: Reconstructive Vision-Language-Action Model as Effective Robot Perceiver", "authors": "Wenxuan Song,Ziyang Zhou,Han Zhao,Jiayi Chen,Pengxiang Ding,Haodong Yan,Yuxin Huang,Feilong Tang,Donglin Wang,Haoang Li", "background": "近年来，视觉-语言-行为（VLA）模型的进步使机器人代理能够整合多模态理解和行为执行。然而，我们的实证分析表明，当前的VLA模型在分配视觉注意力以便对准目标区域方面存在困难，视觉注意力通常被分散，未能有效地集中在正确的目标上。", "innovation": "为了解决这一问题，我们提出了ReconVLA，一种具有隐式语义定位范式的重建性VLA模型。该模型通过条件概率下的扩散变压器来重建图像中的凝视区域，从而引导与目标操作对象相对应的视觉注意力，促使VLA模型学习细粒度表示并精确分配视觉注意力。此外，我们还创建了一个包含超过10万轨迹和200万数据样本的大规模预训练数据集，进一步提升了模型在视觉重建方面的泛化能力。", "conclusion": "广泛的实验表明，我们的隐式语义定位方法在模拟和实际环境中具有优越性，展示了其在精确操作和泛化方面的能力。"}
{"llm_update_time": "20250815", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.10433", "html_url": "https://arxiv.org/abs/2508.10433", "title": "We-Math 2.0: 一种用于激励视觉数学推理的多功能MathBook系统", "title_en": "We-Math 2.0: A Versatile MathBook System for Incentivizing Visual Mathematical Reasoning", "authors": "Runqi Qiao,Qiuna Tan,Peiqing Yang,Yanzi Wang,Xiaowan Wang,Enhui Wan,Sitong Zhou,Guanting Dong,Yuchen Zeng,Yida Xu,Jie Wang,Chong Sun,Chen Li,Honggang Zhang", "background": "多模态大型语言模型（MLLMs）在各种任务中表现出色，但在复杂数学推理方面仍然存在挑战。现有研究主要集中在数据集构建和方法优化上，往往忽略了综合知识驱动设计和模型中心的数据空间建模这两个关键方面。", "innovation": "We-Math 2.0 引入了一个统一系统，该系统集成了结构化的数学知识系统、模型中心的数据空间建模以及基于强化学习（RL）的训练范式，以全面增强MLLMs的数学推理能力。关键贡献包括：构建了一个五级层次的知识系统，涵盖491个知识点和1819个基本原理；开发了一个确保广泛概念覆盖和灵活性的数据集MathBook-Standard，并通过三维难度空间生成七种进展型变体，构建了专门用于稳健训练的MathBook-Pro；提出了一种两阶段RL框架，包括冷启动微调和进展对齐RL，后者利用平均收益学习和动态数据调度实现难度级别上的渐进对齐；引入了一个全面的基准测试覆盖了所有491个知识点。", "conclusion": "实验证明，MathBook-RL在四个广泛使用的基准测试中竞争地表现优于现有基线，并在MathBookEval中取得了优异成绩，表明在数学推理中的广泛应用潜力。"}
{"llm_update_time": "20250815", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.10490", "html_url": "https://arxiv.org/abs/2508.10490", "title": "基于梯度的解释的复杂度-忠实性权衡", "title_en": "On the Complexity-Faithfulness Trade-off of Gradient-Based Explanations", "authors": "Amir Mehrpanah,Matteo Gamba,Kevin Smith,Hossein Azizpour", "background": "ReLU网络在视觉数据中非常普遍，但它们具有锐峭的过渡，有时依赖单个像素进行预测。这使得基于梯度的解释方法呈现出不平滑、噪声大且难以解释的特点。现有方法，如GradCAM，通过生成替代模型来平滑解释，但会以失去忠实性为代价。对于ReLu网络，由于它们在高频信息上的贡献，基于梯度的解释精确地揭示了这种复杂度和忠实性的权衡。", "innovation": "我们提出了一种统一的谱框架，系统地分析和量化平滑度、忠实性及其在解释中的权衡。该框架允许量化和规管ReLU网络对高频信息的贡献，提供了一个系统性的途径来识别这种权衡。我们的分析揭示了基于替代模型平滑解释所带来的解释偏差，严格定义并度量了不同事后方法的这种偏差。", "conclusion": "理论发现已被不同的设计选择、数据集和消融测试所验证，证明了该框架的有效性和普适性。"}
{"llm_update_time": "20250815", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.10595", "html_url": "https://arxiv.org/abs/2508.10595", "title": "基于梯度的解释方法的光谱属性研究", "title_en": "On Spectral Properties of Gradient-based Explanation Methods", "authors": "Amir Mehrpanah,Erik Englesson,Hossein Azizpour", "background": "理解深度网络的行为对于增加我们对其结果的信心至关重要。尽管有大量研究用于解释它们的预测，但由于缺乏足够的形式化，研究人员遇到了可靠性问题。我们的研究采用新颖的概率和光谱视角，正式分析解释方法。我们的研究表明，由于使用梯度导致普遍存在光谱偏差，并揭示了一些常见的设计选择，特别是使用平方梯度和输入扰动。我们还刻画了解释方法中扰动超参数的选择如何导致不一致的解释，引入了基于我们提出的正式方法的两种补救措施：（i）确定标准扰动尺度的机制；（ii）一种名为SpectralLens的聚合方法。最后，我们通过定量评估证实了我们的理论结果。", "innovation": "我们的研究采用新颖的概率和光谱视角，正式分析解释方法，揭示了光谱偏差并找出具体的设计选择。提出现有解释方法中扰动超参数选择导致不一致解释的机制，并提出两种解决方案：确定标准扰动尺度的机制和SpectralLens聚合方法。", "conclusion": "我们的理论结果通过定量评估得到验证。研究发现基于梯度的解释方法中存在光谱偏差，并提出了解决不一致解释的方法。"}
{"llm_update_time": "20250815", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.10429", "html_url": "https://arxiv.org/abs/2508.10429", "title": "MM-Food-100K: 可验证来源的100,000项多模态食品智能数据集", "title_en": "MM-Food-100K: A 100,000-Sample Multimodal Food Intelligence Dataset with Verifiable Provenance", "authors": "Yi Dong,Yusuke Muraoka,Scott Shi,Yi Zhang", "background": "该研究介绍了MM-Food-100K，这是一个包含100,000个样本的多模态食品智能公开数据集，具有可验证的来源。数据集源自一个原始的、经过质量验证的120万食品图像数据集，涵盖广泛的信息（如菜肴名称、创造区域）。该数据集由超过87,000名贡献者在六周内通过Codatta贡献模型收集，结合了社区来源与可配置的AI辅助质量检查。每个提交都与安全的离链账本中的钱包地址相关联，以实现追溯性，并计划引入完整的区块链协议来确保数据的完全透明和安全性。", "innovation": "MM-Food-100K通过引入可验证的来源和安全的追溯措施，显著提高了数据集的质量和可信度。数据集中的每个提交都被链接到一个安全的离链账本中的钱包地址，每个提交都有详细的质量保证检查，确保数据的质量。此外，该研究还通过在Vision-Language模型（包括ChatGPT 5、ChatGPT OSS、Qwen-Max）上进行微调，验证了数据集的实际应用价值，实验显示了显著的性能提升，特别是在基于图像的食物营养预测任务中.", "conclusion": "该研究团队发布了MM-Food-100K数据集，以促进科学和商业应用。该数据集包含了100,000个样本，适用于开源免费使用的部分，同时保留了大部分数据作为潜在的商业产品，计划与贡献者分享收益。该数据集在未来的研究和开发中具有重要的应用潜力，特别是在食品信息识别和食物营养分析等方面。"}
{"llm_update_time": "20250815", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.10215", "html_url": "https://arxiv.org/abs/2508.10215", "title": "数据高效学习实现广义手术视频理解", "title_en": "Data-Efficient Learning for Generalizable Surgical Video Understanding", "authors": "Sahar Nasirihaghighi", "background": "手术视频分析的进步正在将手术室转变为智能化、数据驱动的环境。计算机辅助系统支持从术前规划到术中指导再到术后评估的完整手术流程。然而，由于（I）标注稀缺，（II）时空复杂性以及（III）跨手术程序和医疗机构的领域差距，开发适用于多种场景的鲁棒且可泛化的手术视频理解模型仍然具有挑战性。这项博士研究旨在弥合基于深度学习的手术视频分析研究与实际临床应用之间的差距。针对分析中至关重要的识别手术阶段、动作和事件的核心挑战，经过基准测试，选择了最有效的神经网络架构，并进一步通过提出新型架构和整合先进模块来提升性能。由于专家注解的成本高和手术视频来源间的领域差距，我们注重减少对标注数据的依赖。我们开发了半监督框架，通过利用大量未标注的手术视频提高模型在各个任务上的性能。我们引入了包括DIST、SemiVT-Surge和ENCEORE在内的新型半监督框架，通过借助少量标注数据并通过动态伪标签增强模型训练来达到现有的最佳结果。为促进可重复性和推进领域发展，我们发布了两个多任务数据集：GynSurg（目前最大的妇科腹腔镜数据集）和Cataract-1K（目前最大的白内障手术视频数据集）.", "innovation": "通过引入DIST、SemiVT-Surge、ENCEORE等新型半监督框架，利用少量标注数据和增强模型训练动态伪标签，提高模型在复杂手术数据集上的表现；开发大规模的多任务数据集GynSurg和Cataract-1K，为手术视频分析提供数据支持；提出并实现了数据高效学习方法，旨在减少对外标注数据的依赖，提高算法的推广性与可重用性，推动了广义手术视频理解的研究进展和临床应用落地；构建了鲁棒、数据高效并具有临床可扩展性的手术视频分析方案，为广义人工智能系统应用于手术护理和培训奠定了基础.", "conclusion": "本工作为手术视频分析提供了稳健、数据高效且临床可扩展的解决方案，建立了可推广的人工智能系统，有望对手术护理和培训产生实质性影响。"}
{"llm_update_time": "20250815", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.10605", "html_url": "https://arxiv.org/abs/2508.10605", "title": "DIVA-VQA：检测UGC视频质量的帧间差异", "title_en": "DIVA-VQA: Detecting Inter-frame Variations in UGC Video Quality", "authors": "Xinyi Wang,Angeliki Katsenou,David Bull", "background": "近年来，用户生成的视频内容（UGC）的迅速增长驱使了对无参考（NR）感知视频质量评估（VQA）的研究需求增加。无参考VQA对于社交媒体和流媒体应用中大规模视频质量监控至关重要，因为这类应用中通常无法获得原始参考。此外，现有无参考VQA模型无法有效利用帧间差异进行多层级的复杂分析，尤其是在有效捕捉全局和局部信息方面存在局限性。", "innovation": "本文提出了一种基于帧间差异驱动的空间-时间碎片化的新无参考VQA模型。该模型通过利用帧间差异，在多个层级上（帧、补丁、碎片化的帧）逐步分析质量敏感区域。它将帧、碎片残差和与残差对齐的碎片化帧整合起来，以有效捕捉时空变化。此模型提取了2D和3D特征，以描述时空变化。与最先进的模型相比，所提出的方法在平均排名相关性方面取得了优异成绩。此外，该模型在运行时复杂性上表现出优越性，并在评估基准上取得了最佳和第三好的成绩。", "conclusion": "实验结果表明，DIVA-VQA方法在多种用户生成的视频数据集上表现优异。DIVA-VQA-B在平均排名相关性方面位列第二，DIVA-VQA-L位列第三。所提方法在保持低复杂度的同时，实现了高性能，这成就取决于其捕获时空差异的新方法，提供了为社交媒体和视频流应用进行无参考视频质量监控的基础。"}
{"llm_update_time": "20250815", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.10797", "html_url": "https://arxiv.org/abs/2508.10797", "title": "当专家意见不一致时：评估DSA图像中血管分割的注释者变异性", "title_en": "When Experts Disagree: Characterizing Annotator Variability for Vessel Segmentation in DSA Images", "authors": "M. Geshvadi,G. So,D.D. Chlorogiannis,C. Galvin,E. Torio,A. Azimi,Y. Tachie-Baffour,N. Haouchine,A. Golby,M. Vangel,W.M. Wells,Y. Epelboym,R. Du,F. Durupinar,S. Frisken", "background": "该研究分析了多位注释者在2D DSA图像中对颅内血管分割结果的差异性，旨在量化并描述这些差异，为后续注释和不确定性的自动分割方法提供指导。", "innovation": "研究通过分析注释者之间的差异性来量化分割的不确定性，并讨论了如何利用这些信息来指导额外的注释和开发能够感知不确定性的人工智能分割方法。", "conclusion": "研究结果表明，通过这种分析方法可以有效地识别和量化注释者的不确定性，并提出了使用这种信息来进行进一步注释和开发改进的不确定性敏感的自动分割算法的策略。"}
{"llm_update_time": "20250815", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.10745", "html_url": "https://arxiv.org/abs/2508.10745", "title": "Agentic Design Review System", "title_en": "Agentic Design Review System", "authors": "Sayan Nag,K J Joseph,Koustava Goswami,Vlad I Morariu,Balaji Vasan Srinivasan", "background": "评估图形设计通常涉及多方面考量，包括对齐、组成、美学和色彩选择。全面评估设计需要从个体专家评审中汇总反馈。当前方法中缺乏系统化的方式，使得设计评估和生成可操作反馈的过程复杂且不够高效。因此，需要一种新的方法和系统来提高设计评估的效率和准确性，并充分利用多专家评审的优势，从而更好地从不同角度审视设计效果.", "innovation": "提出了一个名为Agentic Design Review System (AgenticDRS) 的代理设计评审系统，该系统在元代理的调度下，多代理共同分析设计，并结合基于图匹配的上下文示例选择方法和独特的提示扩展方法，使每个代理能够更加自觉地认识到设计。通过提出DRS-BENCH基准，对比最先进的基线，运用详尽的实验评价和关键的消融实验来证明Agentic-DRS在评估图形设计和生成可操作反馈方面的有效性，从而填补了这一研究方向上的空白，为设计评估提供了新的思路和工具.", "conclusion": "期望这项工作能够引起对这一切实可行但尚未充分探索的研究方向的关注，通过改善和优化代理设计评审系统的开发，进一步提升设计评估的效果和效率，为图形设计领域的研究者和从业者提供有益的启示和参考。"}
{"llm_update_time": "20250815", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.10784", "html_url": "https://arxiv.org/abs/2508.10784", "title": "2025年《阿加大使》比赛获奖者洞见", "title_en": "Insights from the Algonauts 2025 Winners", "authors": "Paul S. Scotti,Mihir Tripathy", "background": "阿加大使2025挑战刚刚在几周前结束，这是每两年一次的计算神经科学竞赛，团队需要构建模型来预测人类大脑活动，基于精心挑选的刺激。过去的比赛集中在静态图像和短视频上，2025年的比赛则使用了更长的多模态电影。挑战要求团队预测四名参与者在观看近80小时的自然电影刺激时的大脑活动响应，这些数据来自CNeuroMod项目，包括65小时的培训数据，55小时的《朋友》（第1-6季）以及四部电影（《极致案件》、《隐形》、《生命》、《华尔街之狼》）。剩余的数据用于验证，在分布内测试使用《朋友》第7季，在分布外测试中，预测六部电影的大脑活动表现最好的团队获胜。", "innovation": "2025年的比赛首次使用了长时间的多模态电影作为刺激源，扩大了数据集的规模和多样性，这对于提高大脑活动预测的准确性和普遍性具有重要意义。比赛还增加了更多复杂的模型和处理策略，推动了计算神经科学的进步。", "conclusion": "作为MedARC团队的成员，获得了第四名的好成绩。我们总结了获胜者使用的方法，揭示了当前的大脑编码状态，指出了未来可能的发展方向。"}
{"llm_update_time": "20250815", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2310.19583", "html_url": "https://arxiv.org/abs/2310.19583", "title": "GC-MVSNet：多视图、多尺度、几何一致性的多视图立体成像", "title_en": "GC-MVSNet: Multi-View, Multi-Scale, Geometrically-Consistent Multi-View Stereo", "authors": "Vibhas K. Vats,Sripad Joshi,David J. Crandall,Md. Alimoor Reza,Soon-heung Jung", "background": "传统的多视图立体成像（MVS）方法主要依赖于光度和几何一致性约束，而基于机器学习的新型MVS方法仅在后处理阶段检查多个源视图之间的几何一致性。", "innovation": "提出了一种新颖的方法，在学习过程中显式地鼓励参考视图深度图在多个源视图的多尺度下保持几何一致性（参见图1）。通过在损失函数中加入几何一致性约束，有效地惩罚几何不一致的像素，从而显著加快了学习过程。", "conclusion": "我们的实验表明，GC-MVSNet在DTU和BlendedMVS数据集上达到了新的最佳水平，并在Tanks and Temples基准测试上取得了竞争力的结果。据我们所知，GC-MVSNet是首次在学习过程中强制执行多视图和多尺度几何一致性的尝试。"}
{"llm_update_time": "20250815", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.10416", "html_url": "https://arxiv.org/abs/2508.10416", "title": "CorrectNav：自我纠正飞轮赋能视觉语言行动导航模型", "title_en": "CorrectNav: Self-Correction Flywheel Empowers Vision-Language-Action Navigation Model", "authors": "Zhuoyuan Yu,Yuxing Long,Zihan Yang,Chengyan Zeng,Hongwei Fan,Jiyao Zhang,Hao Dong", "background": "现有的视觉和语言导航模型在执行指令时常常偏离正确的路径，而这些模型缺乏有效的错误校正能力，限制了其从错误中恢复的能力。", "innovation": "提出了一种新的后训练范式——自我纠正飞轮。该范式将模型在训练集上的错误轨迹视为宝贵的数据源，开发了识别这些错误轨迹偏差的方法，并创新性地生成了感知和行动的自我纠正数据，这些数据用于继续训练模型。通过多次飞轮迭代，显著提升了基于单目RGB的VLA导航模型CorrectNav的表现。", "conclusion": "研究表明，CorrectNav在R2R-CE和RxR-CE基准上的成功率分别达到了65.1%和69.3%，超过之前最好的VLA导航模型8.2%和16.4%。实地机器人测试表明，该方法具有优秀的错误纠正、动态障碍物规避和长指令跟随能力。"}
{"llm_update_time": "20250815", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.10649", "html_url": "https://arxiv.org/abs/2508.10649", "title": "Geo空间扩散模型在地表覆盖不透水层变化预测中的应用", "title_en": "Geospatial Diffusion for Land Cover Imperviousness Change Forecasting", "authors": "Debvrat Varshney,Vibhas Vats,Bhartendu Pandey,Christa Brelsford,Philipe Dias", "background": "地表覆盖（现时及未来）对多个重要的地球系统过程有着显著影响。例如，不透水面使地表水快速流走，减缓了地下水渗透，影响了区域水文和洪灾风险。虽然在未来的气候变化情景中，区域地球系统模型在高分辨率下对水文和大气过程的预测能力越来越强，但预测土地利用和覆盖变化（LULC）的能力仍相对滞后，这是风险和后果评估的关键输入。本文探讨了利用生成人工智能（GenAI）进行LULC变化预测的新范式，将LULC预测视为基于历史及其他辅助数据源的数据合成问题。通过实验验证了该方法在全美国范围内不透水面预测方面的可行性，特别是通过训练扩散模型进行十年尺度的不透水面预测，并将其性能与假定无变化的基线进行了比较。研究结果表明，在至少0.7×0.7km²的分辨率下，模型的平均绝对误差（MAE）低于基线。此发现证明了该生成模型可以捕捉到历史数据中的时空模式，对预测未来变化具有重要意义。", "innovation": "本文提出了一种利用生成人工智能（GenAI）进行LULC变化预测的新范式，即将LULC预测视为基于历史及其他辅助数据源的数据合成问题。通过实验验证了该模型在全美国范围内不透水面预测的可行性，特别是通过训练扩散模型进行十年尺度的不透水面预测，并将其性能与假定无变化的基线进行了比较。研究结果表明，该模型在高分辨率下的预测性能优于假设无变化的基线。该发现证明了该生成模型可以捕捉到历史数据中的时空模式，对预测未来变化具有重要意义。未来的研究将进一步整合物理特性的辅助信息，并通过驱动变量支持不同的场景模拟。", "conclusion": "研究结果表明，该生成模型能够通过历史数据捕捉到重要的时空模式，从而在高分辨率下实现对未来不透水面变化的准确预测。未来的研究将整合物理特性的辅助信息，并通过驱动变量支持不同的场景模拟，以进一步提高预测的准确性和实用性。"}
{"llm_update_time": "20250815", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2403.05262", "html_url": "https://arxiv.org/abs/2403.05262", "title": "通过惩罚语言先验来纠正多模态大型语言模型的偏差", "title_en": "Debiasing Multimodal Large Language Models via Penalization of Language Priors", "authors": "YiFan Zhang,Yang Shi,Weichen Yu,Qingsong Wen,Xue Wang,Wenjing Yang,Zhang Zhang,Liang Wang,Rong Jin", "background": "在计算机视觉和自然语言处理领域，多模态大型语言模型（MLLMs）已经成为不可或缺的工具，能够根据视觉输入生成文本响应。尽管这些模型取得了显著进步，但研究发现，生成的内容往往受底层大型语言模型（LLMs）的先验影响，而非视觉输入自身的特性。即使在缺乏相关视觉输入或使用不一致的视觉输入的情况下，多模态大型语言模型也会给出自信的答案。", "innovation": "本文提出两种无需训练的方法来纠正这种偏差。首先提出了“事后去偏”方法，通过线性校准步骤调整输出分布，确保在缺少图像时答案得分一致，从而有效减轻LHLM先验的影响。其次，对于复杂任务，提出了“视觉去偏解码”，通过对比正确图像和无意义图像下词的对数概率来缓解偏差。此外，研究还揭示了多模态大型语言模型在不同解码配置下的稳定性问题，并通过系统探索不同的设置实现了显著的性能提升，对当前评估实践的公平性提出质疑。", "conclusion": "本文提出的方法不仅能在最小化幻觉方面有效，还能生成更有帮助和精确的图像。综合实验结果证实了这些策略在减轻偏差方面的有效性。"}
{"llm_update_time": "20250815", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2409.11315", "html_url": "https://arxiv.org/abs/2409.11315", "title": "MinD-3D++: 基于fMRI的高质纹理网格生成与全面数据集促进3D重建", "title_en": "MinD-3D++: Advancing fMRI-Based 3D Reconstruction with High-Quality Textured Mesh Generation and a Comprehensive Dataset", "authors": "Jianxiong Gao,Yanwei Fu,Yuqian Fu,Yun Wang,Xuelin Qian,Jianfeng Feng", "background": "fMRI数据中的3D视觉重建对于认知神经科学和计算机视觉领域具有重要研究价值。目前，虽有研究致力于这项任务，但缺乏高质量的3D对象数据集，以支持更为精细和真实的3D重建。本文提出了fMRI-3D数据集，包含15名参与者的4,768个3D对象，分为fMRI-Shape和fMRI-Objaverse两个部分。fMRI-Objaverse特别增加了详细的文本描述，使数据集更加多元化。", "innovation": "作者提出了MinD-3D++框架，用于从fMRI信号解码具有纹理信息的3D视觉数据。这是首次能够从fMRI数据中生成高细节纹理的3D网格。通过设计新的评估指标，以语义、结构和纹理三个层面评估模型性能，并研究模型在异常分布环境中的有效性。此外，分析fMRI信号在视觉区域的兴趣点（ROI）中的归因，展示了人类大脑处理3D视觉信息的深层次理解能力。", "conclusion": "MinD-3D++不仅在语义和空间准确性方面成功重建了3D对象，还揭示了人类大脑处理3D视觉信息的更深层次洞察，显著推进了基于fMRI的3D重建研究。"}
{"llm_update_time": "20250815", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2411.06869", "html_url": "https://arxiv.org/abs/2411.06869", "title": "CapeLLM: Support-Free Category-Agnostic Pose Estimation with Multimodal Large Language Models", "title_en": "CapeLLM: Support-Free Category-Agnostic Pose Estimation with Multimodal Large Language Models", "authors": "Junho Kim,Hyungjin Chung,Byung-Hoon Kim", "background": "传统的无类别姿态估计（CAPE）依赖于带有标注关键点的支持图像，这一过程往往繁琐且难以捕捉不同类别物体之间的必要对应关系。尽管近期研究探索了文本查询的应用，以利用其稳定性与泛化能力，但现有方法依然受限于对支持查询的依赖，未能充分利用预训练大型语言模型中丰富的先验知识，并受到参数分布假设的限制。", "innovation": "本文提出了CapeLLM，一种专为CAPE设计的首个多模态大型语言模型（MLLM）。该方法仅使用查询图像和详细的文本描述作为输入以估计无类别关键点。我们提出了一种推理机制，通过灵活建模未见过的关键点的潜在空间分布和不确定性，基于上下文线索实现适应性细化。我们不仅关注模型架构和提示设计，还确保输入变化时的鲁棒性，展示了在MP-100基准测试中的新最佳表现，实现了单次和五次设置下的显著提升。", "conclusion": "我们的方法在无类别姿态估计领域取得了重大进展，在1-shot和5-shot设置下的MP-100基准测试上达到了新的最先进水平。"}
{"llm_update_time": "20250815", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2408.03551", "html_url": "https://arxiv.org/abs/2408.03551", "title": "VPOcc: 利用消失点进行3D语义占用预测", "title_en": "VPOcc: Exploiting Vanishing Point for 3D Semantic Occupancy Prediction", "authors": "Junsu Kim,Junhee Lee,Ukcheol Shin,Jean Oh,Kyungdon Joo", "background": "理解三维场景的语义和空间结构对于机器人和自动驾驶车辆的安全导航至关重要，有助于障碍物避让和轨迹规划。基于相机的3D语义占用预测从2D图像推断完整的体素网格，相比3D传感器在资源效率方面具有优势。然而，这一任务固有地存在2D-3D之间的差异，即相同大小的物体在三维空间中由于透视投影，其在2D图像中的大小会随着与相机距离的变化而变化。为了解决这一问题，本文提出了一种名为VPOcc的新型框架，该框架利用消失点（VP）在像素级和特征级缓解2D-3D之间的差异。", "innovation": "该框架引入了VPZoomer模块，利用VP进行透视校正的图像变换，克服了透视效应。此外，提出了VP指导下的跨注意力机制（VPCA）模块，进行透视感知的特征聚合，利用更适合三维空间的2D图像特征。最后，整合来自原始和变形图像的两个特征体素，通过空间体积融合（SVF）模块相互补充，该方法在SemanticKITTI和SSCBench-KITTI360数据集上实现了IoU和mIoU度量的提升，有效利用消失点显著改善了3D语义占用预测的表现和准确性。", "conclusion": "通过有效整合消失点，我们的框架在SemanticKITTI和SSCBench-KITTI360数据集上均取得了IoU和mIoU度量的提升。"}
{"llm_update_time": "20250815", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2411.13378", "html_url": "https://arxiv.org/abs/2411.13378", "title": "Quantum-Brain: 被量子启发的神经网络方法用于视觉-大脑理解", "title_en": "Quantum-Brain: Quantum-Inspired Neural Network Approach to Vision-Brain Understanding", "authors": "Hoang-Quan Nguyen,Xuan-Bac Nguyen,Hugh Churchill,Arabinda Kumar Choudhary,Pawan Sinha,Samee U. Khan,Khoa Luu", "background": "视觉-大脑理解旨在从人类感知中提取大脑信号的语义信息。现有的用于视觉-大脑理解的深度学习方法通常在传统学习框架中引入，缺乏学习大脑区域之间连接性的能力。量子计算理论提供了一种设计深度学习模型的新范式。受大脑信号连接性和量子计算中的纠缠性质启发，我们提出了一种新颖的Quantum-Brain方法，一个受量子启发的神经网络，以解决视觉-大脑理解问题。", "innovation": "为了在大脑信号区域之间计算连接性，我们引入了一个新的量子启发体素控制模块来学习大脑体素对其他体素在希尔伯特空间中的影响。为了有效地学习连接性，我们提出了一种新的相位更换单元来校准大脑信号的值。最后，我们引入了一种新的测量样投影单元，将希尔伯特空间中的连接性信息呈现到特征空间。提出的Quantum-Brain方法可以学习找到功能磁共振成像（fMRI）体素之间的连接性，增强来自人类感知的语义信息。我们的实验结果在自然场景数据集基准上证实了该方法的有效性，图像检索任务的Top-1准确率为95.1%，脑成像检索任务的Top-1准确率为95.6%，fMRI到图像重建任务的Inception分数为95.3%。", "conclusion": "我们提出的量子启发网络通过量子计算理论提供了一个解决视觉-大脑问题的潜在范式。"}
{"llm_update_time": "20250815", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2412.00578", "html_url": "https://arxiv.org/abs/2412.00578", "title": "Speedy-Splat: 快速稀疏像素和稀疏原语的3D高斯求和", "title_en": "Speedy-Splat: Fast 3D Gaussian Splatting with Sparse Pixels and Sparse Primitives", "authors": "Alex Hanson,Allen Tu,Geng Lin,Vasu Singla,Matthias Zwicker,Tom Goldstein", "background": "3D Gaussian Splatting (3D-GS) 是一种最近的3D场景重建技术，通过将场景建模为分段的可微3D高斯体素云来实现新视角的实时渲染。然而，其渲染速度和模型大小仍然存在瓶颈，尤其是在资源受限的环境中。", "innovation": "本文识别并解决了3D-GS中的两个关键效率问题，显著提高了渲染速度。这些改进还带来了模型大小和训练时间的辅助效益。首先，优化渲染管道以精确位置分段器在场景中的位置，提升渲染速度而不影响视觉保真度。其次，提出了一种新型的修枝技术，并将其集成到训练管道中，显著减少了模型大小和训练时间，同时进一步提高渲染速度。", "conclusion": "Speedy-Splat 方法结合了这些技术，实现了在 Mip-NeRF 360、Tanks & Temples 和 Deep Blending 数据集的场景中平均渲染速度达到了6.71倍的加速。"}
{"llm_update_time": "20250815", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2411.14521", "html_url": "https://arxiv.org/abs/2411.14521", "title": "MyTimeMachine：个性化面部年龄变换", "title_en": "MyTimeMachine: Personalized Facial Age Transformation", "authors": "Luchao Qi,Jiaye Wu,Bang Gong,Annie N. Wang,David W. Jacobs,Roni Sengupta", "background": "面部老化是一个高度依赖于性别、种族、生活方式等多种因素的复杂过程，这使得学习一个通用的老化先验来准确预测个体的老化图像具有很高的挑战性。现有方法虽然能够生成逼真可信的老化结果，但再老化后的图像往往与目标年龄的真实外观不符，因此需要个性化的改进。在电影和电视剧的虚拟老化应用中，用户通常拥有在较短时间内记录的老化照片集。然而，直接将通用老化技术应用于个人照片集中往往无法获得成功的结果。因此，提出了MyTimeMachine（MyTM），结合了全球老化先验和少量的个人照片集（最少50张图像），以学习个性化的年龄变换。", "innovation": "提出了一个新颖的适配器网络，结合了个性化的老化特征和全局老化特征，并使用StyleGAN2生成再老化图像。引入了三种损失函数来个性化适配器网络，包括个性化的老化损失、外推正则化以及自适应w-范数正则化。此外，该方法还能扩展应用于视频，生成高质量、保持身份且时间一致的老化效果，这些效果与目标年龄的实际外观高度相似，展示了其在现有最先进的方法上的优越性。", "conclusion": "通过结合全球老化先验和少量个人照片集，MyTimeMachine能够学习个性化的年龄变换模型，通过适配器网络和特定损失函数，生成高质量、身份保持且时间一致的老化效果，优于现有最先进的方法。"}
{"llm_update_time": "20250815", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2412.06534", "html_url": "https://arxiv.org/abs/2412.06534", "title": "通过反演理解基于变换器的视觉模型", "title_en": "Understanding Transformer-based Vision Models through Inversion", "authors": "Jan Rathjens,Shirin Reyhanian,David Kappel,Laurenz Wiskott", "background": "深入理解深度神经网络背后的机制仍然是机器学习和计算机视觉领域的基本挑战。一种有潜力但仅初步探索的方法是特征反演，即尝试通过训练的逆神经网络从中间表示重建图像。本文重新审视了特征反演，提出了一种新的模块化变体方法，使其更为高效地应用于技术中。", "innovation": "引入了一种新的模块化特征反演方法，使其在大规模基于变换器的视觉模型（如Detection Transformer和Vision Transformer）中可以系统地应用。通过定量评估该方法，揭示了这两种架构中图像特征表示的机制。研究揭示了这些模型如何编码上下文形状和图像细节，各层之间的相关性，以及它们对颜色扰动的鲁棒性。", "conclusion": "该研究为理解基于变换器的视觉模型及其内部表示提供了新的见解。所提出的方法和结果揭示了这些模型的关键细节，有助于深入理解基于变换器的模型。研究代码可以在该网址复制实验结果：[this http URL](this http URL)"}
{"llm_update_time": "20250815", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2412.06293", "html_url": "https://arxiv.org/abs/2412.06293", "title": "掌握协作多模态数据选择：重点关注信息量、独特性和代表性", "title_en": "Mastering Collaborative Multi-modal Data Selection: A Focus on Informativeness, Uniqueness, and Representativeness", "authors": "Qifan Yu,Zhebei Shen,Zhongqi Yue,Yang Wu,Bosheng Qin,Wenqiao Zhang,Yunfei Li,Juncheng Li,Siliang Tang,Yueting Zhuang", "background": "多模态大型语言模型（MLLMs）通过指令调整进行细调，以处理现实世界任务。然而，视觉指令数据集的快速增长导致了数据冗余，增加了计算成本。在这种背景下，论文探讨了如何通过选择关键数据来提高模型性能同时减少计算开销。", "innovation": "论文提出了一个名为DataTailor的合作框架，该框架利用信息量、独特性和代表性三个关键原则，自动适应不同数据集进行有效数据选择，无需繁琐的超参数调整。实验证明，仅使用数据集15%的数据，DataTailor在各种基准上的性能与使用全部数据相当，显著减少了计算成本，实现了“少即是多”的理念。", "conclusion": "通过DataTailor，本文展示了如何在减少数据使用量的同时保持高性能，为多模态模型的发展提供了有效的方法。相关代码和数据已提供。"}
{"llm_update_time": "20250815", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2412.04464", "html_url": "https://arxiv.org/abs/2412.04464", "title": "DualPM: 双姿态-标准点图用于3D形状和姿态重建", "title_en": "DualPM: Dual Posed-Canonical Point Maps for 3D Shape and Pose Reconstruction", "authors": "Ben Kaye,Tomas Jakab,Shangzhe Wu,Christian Rupprecht,Andrea Vedaldi", "background": "数据表示的选择是深度学习在几何任务中成功的关键因素。例如，DUSt3R最近提出了视点不变点图的概念，这扩展了深度预测，并表明所有关键问题都可以减少为预测这样的点图。本研究旨在为变形对象的3D形状和姿态重建开发类似的概念。", "innovation": "提出了双姿态-标准点图（Dual Point Maps，DualPM），这是一种新的数据表示方法，用于3D形状和姿态重建。DualPM涵盖了两种点图，分别将像素与物体的3D位置以及物体在静止姿态下的标准版本关联起来。此外，它还扩展了点图到不完整重建，以恢复对象的完整形状，即使通过自我遮挡。研究表明，可以将3D重建和3D姿态估计简化为预测DualPMs。特别是在合成3D数据上训练DualPMs，这些数据包括每个类别的一两个模型，并有效泛化到真实图像上。", "conclusion": "通过DualPM方法，实现了对这些物体的3D分析和重建显著改进。"}
{"llm_update_time": "20250815", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2412.02287", "html_url": "https://arxiv.org/abs/2412.02287", "title": "通过结构特征和CLIP指导提高3D生成视点一致性", "title_en": "Improving Viewpoint Consistency in 3D Generation via Structure Feature and CLIP Guidance", "authors": "Qing Zhang,Jinguang Tong,Jing Zhang,Jie Hong,Xuesong Li", "background": "尽管近年来文本到3D生成技术取得了进展，但现有方法仍常面临几何不一致的问题，通常被称为Janus问题。研究发现该问题的根本原因是扩散模型中的视点生成偏差，导致实际生成的视点与优化3D模型所需的预期视点存在显著差距。", "innovation": "我们提出了一种无需调优的Attention and CLIP Guidance（ACG）机制。ACG通过自适应控制交叉注意力图来增强所需视点，利用基于CLIP的观点-文本相似性过滤错误视点，并采用从粗到细的优化策略与阶段提示逐步细化3D生成。实验结果表明，我们的方法显著减少了Janus问题，且未牺牲生成速度，使ACG成为现有文本到3D框架中高效且即插即用的组件。", "conclusion": "本研究解决了3D生成中的视点一致性问题，提出的方法不仅有效，而且具有高效和便捷的特点，能够直接应用于现有的文本到3D框架中。"}
{"llm_update_time": "20250815", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2412.03910", "html_url": "https://arxiv.org/abs/2412.03910", "title": "DGNS：用于单目动态3D重建的可变形高斯绘制和动态神经表面", "title_en": "DGNS: Deformable Gaussian Splatting and Dynamic Neural Surface for Monocular Dynamic 3D Reconstruction", "authors": "Xuesong Li,Jinguang Tong,Jie Hong,Vivien Rolland,Lars Petersson", "background": "单目视频中的动态场景重建对于实际应用场景至关重要。", "innovation": "提出了一种混合框架DGNS，结合了可变形高斯绘制和动态神经表面，有效地解决了新的视角合成和3D几何重建问题。该框架在训练过程中利用可变形高斯绘制模块生成的深度图来指导光线采样，提高处理速度，并在动态神经表面模块中提供深度监督，以改进几何重建。动态神经表面通过指导表面周围高斯原素的分布，增强渲染质量。此外，还提出了一种深度滤波方法来进一步细化深度监督。", "conclusion": "在公开数据集上进行的广泛实验表明，DGNS在3D重建方面达到了最先进的性能，同时在新的视角合成方面也取得了竞争力的结果。"}
{"llm_update_time": "20250815", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2501.14317", "html_url": "https://arxiv.org/abs/2501.14317", "title": "Nautilus: locality-aware autoencoder for scalable mesh generation", "title_en": "Nautilus: Locality-aware Autoencoder for Scalable Mesh Generation", "authors": "Yuxuan Wang,Xuanyu Yi,Haohan Weng,Qingshan Xu,Xiaokang Wei,Xianghui Yang,Chunchao Guo,Long Chen,Hanwang Zhang", "background": "三角网格在3D应用程序中至关重要，能够实现高效修改和光栅化，同时保持与标准渲染管道的兼容性。然而，当前的自动网格生成方法通常依赖于缺乏网格连续表面质量的中间表示。将这些表示转换为网格会产生密集且次优的输出。尽管最近的自回归方法在直接建模网格顶点和面形方面显示出希望，但在图元数量限制、可扩展性和结构性保真度方面受到限制。", "innovation": "我们提出了Nautilus，一种基于局部属性的自编码器，用于艺术家级别的网格生成，以实现结构保真度和高效表示。该方法引入了一种新颖的标记化算法，保留了面邻近关系，并通过局部共享顶点和边压缩序列长度，使网格生成能够达到前所未有的5000面的规模。此外，我们开发了一种双流点调节器，提供多尺度几何指导，确保全局一致性并捕捉局部结构保真度的细微几何特征。实验结果表明，Nautilus在保真度和可扩展性方面显著优于现有最先进的方法。", "conclusion": "Nautilus在结构保真度和可扩展性方面显著优于现有最先进的方法。项目页面见[input_url]()。"}
{"llm_update_time": "20250815", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2412.19160", "html_url": "https://arxiv.org/abs/2412.19160", "title": "使用相位只读交叉注意力的轻量级变压器用于照明不变的生物特征认证", "title_en": "A Lightweight Transformer with Phase-Only Cross-Attention for Illumination-Invariant Biometric Authentication", "authors": "Arun K. Sharma,Shubhobrata Bhattacharya,Motahar Reza,Bishakh Bhattacharya", "background": "传统生物识别系统由于不可预见的因素遇到了显著的挑战，例如基于面部识别的生物识别系统中佩戴的口罩，以及基于指纹的生物识别系统中引起的卫生问题。该论文提出了一种新颖的轻量级视觉变换器（POC-ViT），它使用面部前额和眶周区域的双生物特征，即使在佩戴口罩的情况下也能很好地工作且无需任何物理接触，这是一种传统方法的可能替代方案。", "innovation": "提出了一种轻量级的具有相位只读交叉注意机制（POC-ViT）的视觉变压器框架，用于处理面部的双生物特征，以捕捉基于相对结构模式的相互依赖性。这种框架采用相位只读相关（POC）的交叉注意力机制，提取在光照变化和输入图像的分辨率和强度变化下的空间特征中的相位相关性，从而增强了模型的鲁棒性。", "conclusion": "通过使用前额浅静脉模式和眶周生物特征模式（FSVP-PBP）数据集对提出框架进行测试，POC-ViT框架在使用双生物特征的情况下达到了98.8%的卓越分类准确性，证明了其在生物特征认证中的优越性能。"}
{"llm_update_time": "20250815", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2503.04376", "html_url": "https://arxiv.org/abs/2503.04376", "title": "MIDAS: 使用黑暗知识建模真实分布的领域泛化立体匹配", "title_en": "MIDAS: Modeling Ground-Truth Distributions with Dark Knowledge for Domain Generalized Stereo Matching", "authors": "Peng Xu,Zhiyu Xiang,Jingyun Fu,Tianyu Pu,Hanzhi Zhong,Eryun Liu", "background": "尽管在领域泛化立体匹配方面取得了显著进展，现有的方法在将合成数据转移到真实数据域时仍表现出领域特异性的倾向，这限制了其在复杂和多变场景中的实际应用。", "innovation": "通过利用立体网络预测的概率分布所固有的丰富相似性和不确定性信息，本文提出了从预训练网络中提取这两种类型的隐含知识来建模边缘和非边缘区域的直觉多模态真值分布的方法。此外，通过网络集成和在拉普拉斯参数空间区分客观和偏差知识，缓解单一网络固有的领域偏好。最终，客观知识和原始视差标签被联合建模为拉普拉斯混合物，为立体网络训练提供精细的监督。", "conclusion": "大量实验表明：(1) 该方法具有通用性，能有效提高现有网络的泛化能力。(2) 使用该方法的PCWNet在KITTI 2015和2012数据集上达到了最先进的泛化性能。(3) 在四个流行的现实世界数据集上，该方法在综合排名上优于现有方法。"}
{"llm_update_time": "20250815", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2502.00372", "html_url": "https://arxiv.org/abs/2502.00372", "title": "NAVER: 一种结合显式逻辑推理的神经符号组态自动机视觉接地方法", "title_en": "NAVER: A Neuro-Symbolic Compositional Automaton for Visual Grounding with Explicit Logic Reasoning", "authors": "Zhixi Cai,Fucai Ke,Simindokht Jahangard,Maria Garcia de la Banda,Reza Haffari,Peter J. Stuckey,Hamid Rezatofighi", "background": "视觉定位(VG)任务，如引用表达检测和分割任务，对于将视觉实体与上下文关联起来具有重要意义，特别是在需要详细查询解释的复杂推理任务中。最近，大规模语言模型(LLMs)和视觉语言模型(VLMs)的进步改善了视觉理解、上下文理解和推理的能力。这些方法可以分为端到端方法和组成方法，后者更为灵活。然而，尽管组成方法在结合LLMs和基础模型方面表现出色，但仍然难以处理基于语言逻辑表示的复杂推理。", "innovation": "该论文提出了一种名为NAVER的方法，该方法将显式的概率逻辑推理融入有限状态自动机中，并具有一种自我纠正机制。这种设计通过明确的逻辑推理提高了推理的稳健性和可解释性。实验结果表明，NAVER方法在最近的端到端和组成基准方法中表现出最佳性能。", "conclusion": "NAVER实现了在VG任务上的最佳性能，并且通过集成显式逻辑推理，提高了方法的稳健性和可解释性。实验结果在代码可供访问，展示了该方法的有效性和适用性。"}
{"llm_update_time": "20250815", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2503.24381", "html_url": "https://arxiv.org/abs/2503.24381", "title": "UniOcc：自动驾驶中占用率预测和估计的统一基准", "title_en": "UniOcc: A Unified Benchmark for Occupancy Forecasting and Prediction in Autonomous Driving", "authors": "Yuping Wang,Xiangyu Huang,Xiaokang Sun,Mingxuan Yan,Shuo Xing,Zhengzhong Tu,Jiachen Li", "background": "当前，对于自动驾驶而言，准确预测车辆和行人的占用率对于安全和高效的驾驶至关重要。然而，现有的研究多依赖于次优的伪标签进行评估，缺乏系统的数据集和综合的评价指标。本文旨在提供一个全面且统一的标准数据集（UniOcc）和工具包，用于处理基于历史信息的未来占用率预测及根据相机图像预测当前帧占用率的问题。UniOcc数据集整合了来自nuScenes、Waymo等真实世界数据集以及CARLA、OpenCOOD等高质量驾驶模拟器的数据，可以提供2D和3D的占用率标签，并标注了创新的每个体素流的信息。", "innovation": "1. UniOcc数据集中集成了多种真实场景和仿真场景的数据，增强了数据多样性。\n2. 提供了2D和3D的占用率标签，以及创新的每个体素流的信息标注。\n3. 独创引入了不需要依赖真实标签的新型评估指标，能够从占用率质量的其他方面提供更稳健的评估。\n4. 通过大量的实验表明，大规模、多样化的训练数据以及明确的流动信息显著提高了占用率预测和预测性能。", "conclusion": "广泛的实验结果证明了大规模多样化训练数据和明确流信息对于提升占用率预测和预测性能的重要作用。通过UniOcc数据集和工具包可以显著改进现有技术，推动自动驾驶领域的发展。数据和代码可在指定网址获取。"}
{"llm_update_time": "20250815", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2503.07516", "html_url": "https://arxiv.org/abs/2503.07516", "title": "Just Functioning as a Hook for Two-Stage Referring Multi-Object Tracking", "title_en": "Just Functioning as a Hook for Two-Stage Referring Multi-Object Tracking", "authors": "Weize Li,Yunhao Du,Qixiang Yin,Zhicheng Zhao,Fei Su,Daqi Liu", "background": "Referring Multi-Object Tracking (RMOT)旨在通过自然语言表达来定位视频中目标轨迹。尽管近期取得了进展，但RMOT中识别和追踪任务之间的内在关系尚未得到充分研究。现有的双重步骤追踪和参考框架依然受限于子任务间互动不足和依赖固定语义对齐模块。", "innovation": "本文提出了一种新的双重步骤追踪和参考框架JustHook。它引入了一个被称为钩子的模块，这个模块重新定义了子任务之间的关联，并通过特征级别的网格采样进行上下文感知的目标特征提取。此外，提出了一个并行组合解码器（PCD），该解码器在统一的联合特征空间中学习，而不是依赖预定义的跨模态嵌入。这种设计增强了可解释性和模块化，并显著提高了泛化能力。实验表明，JustHook在Refer-KITTI、Refer-KITTI-V2和Refer-Dance上的性能最佳，与Refer-KITTI-V2相比，HOTA提高了6.9%。此外，该方法具有高效性。", "conclusion": "本文通过JustHook框架，显著改善了RMOT的两个子任务之间的互动，并展示了在当前基准数据集上的优势。"}
{"llm_update_time": "20250815", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2504.03096", "html_url": "https://arxiv.org/abs/2504.03096", "title": "扩展词汇量动作检测的规模", "title_en": "Scaling Open-Vocabulary Action Detection", "authors": "Zhen Hao Sia,Yogesh Singh Rawat", "background": "现有的动作检测方法主要局限于封闭语义的情景，并依赖于复杂的、参数量大的架构。扩展这些模型到开放语义设置时面临两个关键挑战：(1) 缺乏大规模的数据集，其中包含多种动作类别以便进行稳健训练，(2) 对预训练的视觉-语言对比模型进行参数密集型调整以转换为检测器，这增加了额外非预训练参数过拟合到基础动作类别的风险。", "innovation": "本文介绍了一个仅编码器的多模态模型，用于视频动作检测，减少对参数密集型添加的依赖；提出了一种简单的弱监督训练策略，利用现有的封闭集动作检测数据集进行预训练；构建了一个新基准，用于评估现有的封闭集动作检测数据集，而无需使用这些数据集进行训练，以展示新型基准结果，以便未来研究作参考。", "conclusion": "我们的代码可以在[this https URL]获得。我们的新基准提供了无训练支持的开放语义动作检测评价框架，为后续研究提供了新的基准线。"}
{"llm_update_time": "20250815", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2501.15119", "html_url": "https://arxiv.org/abs/2501.15119", "title": "利用运动估计提高Bayer域计算机视觉效率", "title_en": "Leveraging Motion Estimation for Efficient Bayer-Domain Computer Vision", "authors": "Haichao Wang,Xinyue Xi,Jiangtao Wen,Yuxing Han", "background": "现有的计算机视觉处理管道使用图像传感器捕获以Bayer模式排列的像素信息，随后通过ISP将Bayer像素数据转换为RGB，并进行帧级别的视频卷积网络处理。ISP和VCN都具有高计算强度、高功耗和延迟的特点。本文背景是现有处理方法的不足。", "innovation": "本文提出了一种新型框架，该框架在Bayer域直接利用运动估计来加速视频视觉任务，消除了ISP。引入了基于运动估计的视频卷积（MEVC），它将滑窗运动估计集成到每个卷积层中，实现预测和基于残差的精炼，减少跨帧的冗余计算。该设计解决了块状运动估计和空间卷积之间的结构差距，从而实现准确、低成本的处理。", "conclusion": "本文端到端的管道支持原始Bayer输入，在视频语义分割、深度估计和目标检测基准测试中，使用合成的Bayer转换视频和真实的Bayer视频数据集，实现了超过70%的FLOPs减少，同时保持较低的准确率下降。此框架适用于基于卷积的模型，并标志着首次有效地将运动估计用于直接从原始传感器数据加速视频计算机视觉的方法。"}
{"llm_update_time": "20250815", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2504.04801", "html_url": "https://arxiv.org/abs/2504.04801", "title": "OrderChain: 朝着增强MLLM的序数理解能力的通用指令微调迈进", "title_en": "OrderChain: Towards General Instruct-Tuning for Stimulating the Ordinal Understanding Ability of MLLM", "authors": "Jinhong Wang,Shuo Tong,Jian liu,Dongqi Tang,Weiqiang Wang,Wentong Li,Hongxia Xu,Danny Chen,Jintai Chen,Jian Wu", "background": "尽管多模态大型语言模型（MLLMs）取得了显著进展，但在序数回归（OR，又称序列表示分类）任务上的性能依然与预期存在差距。", "innovation": "本文提出了一种名为OrderChain的新型且通用的提示范式，通过特定性和共性建模来提升MLLMs的序数理解能力。OrderChain包括一组任务感知提示来促进不同序列表示任务的具体性建模，以及一种新的基于范围优化链思维（RO-CoT）的新方法，通过均匀分解任务为多个小范围优化子任务来学习共性的思考方式。此外，还提出了一种类别递归划分（CRD）方法来生成指令候选类别提示，以支持RO-CoT自动优化。", "conclusion": "综合实验表明，采用OrderChain增强的LLaVA模型在多种OR数据集上显著提升了基础LLaVA模型的表现，例如在Adience年龄估计数据集上的准确率为从47.5%提升至93.2%，在糖尿病视网膜病变数据集上的准确率为从30.0%提升至85.7%。值得注意的是，在Adience数据集上，采用OrderChain增强的LLaVA模型的准确率和MAE分别优于最先进的方法27%和0.24，这是迄今为止首次通过增强MLLMs来处理OR任务的工作，并且这种效果在一系列OR数据集上得到了验证。"}
{"llm_update_time": "20250815", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2505.08561", "html_url": "https://arxiv.org/abs/2505.08561", "title": "强化学习遇上掩蔽视频建模：轨迹引导自适应token选择", "title_en": "Reinforcement Learning meets Masked Video Modeling : Trajectory-Guided Adaptive Token Selection", "authors": "Ayush K. Rai,Kyle Min,Tarun Krishna,Feiyan Hu,Alan F. Smeaton,Noel E. O'Connor", "background": "掩蔽视频建模（MVM）已经成为视觉基础模型预训练的有效策略之一。传统的MVM方法中，模型通过可见token提供的信息重建被掩蔽的时空token。然而，选择适当掩蔽策略仍然是一项挑战，先前的研究涉及随机和管状掩蔽等预定义方法，以及基于关键运动先验、光学流和外部预训练模型的语义线索的方法。", "innovation": "本文引入了一个新的、可泛化的轨迹感知自适应token采样器（TATS），它能够建模token的运动动态并无缝集成到掩蔽自编码器（MAE）框架中，以选择视频中的运动为中心的token。此外，作者提出了一种统一的训练策略，通过Proximal Policy Optimization (PPO) 从零开始共同优化MAE和TATS。实验结果表明，该模型在下游动作识别任务上可以实现激进的掩蔽，且保持性能不降低，并且预训练仍然高效。", "conclusion": "通过在四个基准数据集（Something-Something v2，Kinetics-400，UCF101，HMDB51）上的广泛实验，证明了该工作的有效性、可迁移性、泛化能力和效率，优于其他最先进的方法。"}
{"llm_update_time": "20250815", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2504.21706", "html_url": "https://arxiv.org/abs/2504.21706", "title": "视觉变换器在精准农业中的全面综述", "title_en": "Vision Transformers in Precision Agriculture: A Comprehensive Survey", "authors": "Saber Mehdipour,Seyed Abolghasem Mirroshandel,Seyed Amirhossein Tabatabaei", "background": "检测植物疾病是现代农业的关键方面，它在保持作物健康并提高整体产量方面发挥着重要作用。传统的做法虽然仍然有价值，但往往依赖于人工检查或传统的机器学习技术，这两种方法在可扩展性和准确性方面都存在局限性。最近，视觉变换器（ViTs）作为一种有前景的替代方案出现，它们在处理长时间依赖关系和更适用于视觉任务方面具有优势。这篇综述探讨了ViTs在精准农业中的应用，涵盖了各种任务。文章首先介绍了ViTs的基础架构及其从自然语言处理（NLP）到计算机视觉的过渡。讨论了卷积神经网络（CNNs）这类传统模型中存在的归纳偏见，并讨论了ViTs如何克服这些偏见。", "innovation": "视觉变换器（ViTs）作为一种新型的视觉处理方法，在保持作物健康和提高整体产量方面具备处理远距离依赖关系的优势，能够有效提高模型的可扩展性和准确性。文章综述了最近的研究文献，涵盖了关键技术方法、数据集和性能指标，并进行了CNNs和ViTs的对比分析，探讨了混合模型和性能增强方法，同时详细讨论了技术挑战如数据需求、计算需求和模型可解释性及其潜在的解决方案。", "conclusion": "本文旨在为从业者和研究者提供一种深入了解，即视觉变换器如何为智能和精准农业的进一步整合奠定基础。我们总结了未来的研究方向和潜在的技术进步，将进一步支持ViTs在实际农业生产中的应用。"}
{"llm_update_time": "20250815", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2505.13219", "html_url": "https://arxiv.org/abs/2505.13219", "title": "PiT: 渐进扩散变换器", "title_en": "PiT: Progressive Diffusion Transformer", "authors": "Jiafu Wu,Yabiao Wang,Jian Li,Jinlong Peng,Yun Cao,Chengjie Wang,Jiangning Zhang", "background": "Diffusion Transformers (DiTs) 在图像生成中表现出色，但由于堆叠了顺序的全局同质化变压器，导致了大量的计算成本。然而，经验研究表明，DiTs 对全局信息的依赖没有此前认为的那么高，许多层存在显著的全局计算冗余。此外，传统的注意力机制在低频信息处理上表现欠佳，限制了其效率。", "innovation": "该研究提出了Pseudo Shifted Window Attention (PSWA) 来减轻全局注意力的冗余问题，并通过窗口注意力获取适度的全局-局部信息。还提出了 Progressive Coverage Channel Allocation (PCCA) 策略，不增加计算成本即可捕获高阶注意力。基于这些创新，该研究提出了Pseudo Progressive Diffusion Transformer (PiT) 系列模型，显著提高了性能，如PiT-L 模型在FID指标上相比DiT-XL/2 提升了54%，同时使用更少的计算资源。", "conclusion": "通过实验，展示了PiT系列模型在图像生成任务中的优越性能，并有效地解决了传统DiT模型中存在的计算冗余和低频信息处理不足的问题。"}
{"llm_update_time": "20250815", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2505.20469", "html_url": "https://arxiv.org/abs/2505.20469", "title": "CCL-LGS: 对比码本学习在3D语言高斯点绘中的应用", "title_en": "CCL-LGS: Contrastive Codebook Learning for 3D Language Gaussian Splatting", "authors": "Lei Tian,Xiaomin Li,Liqian Ma,Hao Yin,Zirui Zheng,Hefei Huang,Taiqing Li,Huchuan Lu,Xu Jia", "background": "最近，3D重建技术和视觉语言模型的进步显著推动了3D语义理解的发展，这一能力对机器人技术、自动驾驶和虚拟/增强现实至关重要。然而，依赖2D先验的方法容易受到视差语义不一致的挑战，这种情况由遮挡、图像模糊和视角依赖性变化引起。这些不一致在通过投影监督传播时会劣化3D高斯语义场的质量，并在渲染输出中引入伪影。", "innovation": "本文提出了一种称为CCL-LGS的新框架，通过整合多视角语义线索强加视图一致的语义监督。该方法首先使用零样本追踪器将由SAM生成的2D掩码对齐并可靠地识别其对应的类别。随后，利用CLIP跨视角提取鲁棒语义编码。最后，通过对比码书学习（CCL）模块，通过增强类内紧凑性和类间区分性来提炼判别性语义特征。与先前直接将CLIP应用到不完美的掩码的方法不同，我们的框架明确解决语义冲突同时保留类别区分度。", "conclusion": "广泛的实验表明，CCL-LGS比之前的状态-of-the-art方法表现出更优的效果。我们的项目页面可以在以下网址访问：[这个链接]。"}
{"llm_update_time": "20250815", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2505.22793", "html_url": "https://arxiv.org/abs/2505.22793", "title": "视觉-语言模型的跨文化能力评估", "title_en": "Evaluation of Cultural Competence of Vision-Language Models", "authors": "Srishti Yadav,Lauren Tilton,Maria Antoniak,Taylor Arnold,Jiaang Li,Siddhesh Milind Pawar,Antonia Karamolegkou,Stella Frank,Zhaochong An,Negar Rostamzadeh,Daniel Hershcovich,Serge Belongie,Ekaterina Shutova", "background": "现代视觉-语言模型（VLMs）在跨文化能力评估和基准测试中经常表现不佳。鉴于基于这些模型的应用程序的多样性，人们重新对该领域进行了研究，试图了解这些模型如何编码文化细微差异。不过，尽管对这一问题进行了部分研究，但对于如何系统地识别和标注VLMs图像中的文化细微维度，依然缺乏一个全面的框架。本文认为，视觉文化研究领域的基础方法（文化研究、符号学和视觉研究）对于视觉数据的文化分析是必要的。", "innovation": "本文提出了一个由五个框架组成的系统方法论，每个框架对应一个文化维度，以便更全面地分析VLMs的跨文化能力。这些方法包括借鉴视觉文化研究领域的基础方法（文化研究、符号学和视觉研究）。", "conclusion": "本文进一步强调并建议使用视觉文化研究中的一套系统性框架来评估和理解包括视觉-语言模型在内的视觉表示技术的跨文化表现。"}
{"llm_update_time": "20250815", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2505.23395", "html_url": "https://arxiv.org/abs/2505.23395", "title": "点或线？使用基于线的表示法进行CAD图中全景符号检测", "title_en": "Point or Line? Using Line-based Representation for Panoptic Symbol Spotting in CAD Drawings", "authors": "Xingguang Wei,Haomin Wang,Shenglong Ye,Ruifeng Luo,Yanting Zhang,Lixin Gu,Jifeng Dai,Yu Qiao,Wenhai Wang,Hongjie Zhang", "background": "现有的全景符号检测方法通常依赖于图像像素化、图构建或基于点的表示方式，这些方法往往存在计算成本高、通用性差、几何结构信息丢失等问题。", "innovation": "提出了一种名为VecFormer的新方法，通过使用基于线的表示法保留原始几何连续性，从而实现更准确的形状表示，同时保持计算简便的结构。此外，引入了分支融合细化模块，将实例和语义预测有效结合，解决它们的不一致性，以获得更连贯的全景输出。", "conclusion": "实验证明，该方法成为新的性能标杆，达到了91.1的PQ，相比第二好的结果，未使用先验信息和使用先验信息的情境下，Stuff-PQ分别提高了9.6和21.2个百分点，突显了基于线表示法作为矢量图形理解基础的强大潜力。"}
{"llm_update_time": "20250815", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2506.01701", "html_url": "https://arxiv.org/abs/2506.01701", "title": "通过信息最大化进行数据精简", "title_en": "Data Pruning by Information Maximization", "authors": "Haoru Tan,Sitong Wu,Wei Huang,Shizhen Zhao,Xiaojuan Qi", "background": "目前存在的数据精简方法主要侧重于减少数据集的大小以提高模型训练效率，但往往伴随着信息的丢失。论文提出的方法是InfoMax，通过最大化选择样本的信息含量同时最小化冗余，从而增强核心集的整体信息量。这种方法利用单个样本的重要性得分来量化信息，通过样本对间的相似性来量化冗余，转化为一个离散的二次规划问题，以便在大规模数据集上实现高效解算。", "innovation": "InfoMax的独特之处在于它通过最大化信息内容并最小化冗余来选择数据样本，同时提出了一个将核心集选择问题形式化为离散二次规划问题的解决方案，并结合高效的梯度求解器和稀疏化技术来确保在大规模数据集上的可扩展性。", "conclusion": "通过广泛的实验，InfoMax在图像分类、视觉语言预训练、大语言模型指令调优等不同任务中表现出优越的性能，并且已经实现了对包含数百万样本的数据集的无缝扩展。有关的信息可以从提供的链接获取。"}
{"llm_update_time": "20250815", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2506.06818", "html_url": "https://arxiv.org/abs/2506.06818", "title": "逐步分解与双流聚焦：一种新的无训练伪装目标分割方法", "title_en": "Stepwise Decomposition and Dual-stream Focus: A Novel Approach for Training-free Camouflaged Object Segmentation", "authors": "Chao Yin,Hao Li,Kequan Yang,Jide Li,Pinpin Zhu,Xiaoqiang Li", "background": "提示式分割（例如，SAM）虽然在各种分割任务中显示出了潜力，但仍然需要为每个要分割的对象手动提供视觉提示。针对伪装目标分割（COS）任务，现有方法仍旧面临两大挑战：1）从整体描述中获得实例特定文本提示时的语义模糊性；2）从全局背景中获取实例特定视觉提示时的语义差异和空间分离问题。当前方法在解决这些问题上仍存在不足，因此需要一种新型的解决方案。", "innovation": "本文提出了一种名为RDVP-MSD的无训练测试时自适应框架，通过多模态逐步分解推理链MSD-CoT和区域约束双流视觉提示RDVP来解决现有方法中的问题。MSD-CoT逐步分解图像描述以消除语义模糊性，而RDVP则将空间约束融入视觉提示，并分别对前景和背景点进行独立采样，从而有效地缓解了语义差异和空间分离问题。这种方法在多个COS基准测试中达到了最新的分割效果，同时提高了推理速度，表现出显著的准确性和效率提升。", "conclusion": "所提出的RDVP-MSD方法在COS任务上无需训练即可实现最佳分割结果，同时提升了推理速度，展现了显著的性能改进。开源代码将在指定网址提供。"}
{"llm_update_time": "20250815", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2506.18903", "html_url": "https://arxiv.org/abs/2506.18903", "title": "VMem：基于视素索引视图记忆的一致交互式视频场景生成", "title_en": "VMem: Consistent Interactive Video Scene Generation with Surfel-Indexed View Memory", "authors": "Runjia Li,Philip Torr,Andrea Vedaldi,Tomas Jakab", "background": "先前的方法在实现类似结果时，或者是通过在重建场景3D几何的同时逐帧出图2D视图而快速累积误差，或者是使用具有短暂上下文窗口的视频生成器，在长期内难以保持场景的连贯性。", "innovation": "我们提出了一种新的记忆模块Surfel-Indexed View Memory (VMem)，它基于视素（surfel）对过去的视图进行几何索引，以提高对过去视图的高效检索。这种方法通过仅关注这些相关的视图，在少量的计算成本下实现了对想象中的环境的一致性探索，并且在长期场景合成基准测试中展示了在保持场景连贯性和相机控制方面的优越性能。", "conclusion": "我们评估了我们的方法在具有挑战性的长期场景合成基准上的性能，并证明与现有方法相比，我们的方法在保持场景连贯性和相机控制方面具有优越性。"}
{"llm_update_time": "20250815", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2506.16073", "html_url": "https://arxiv.org/abs/2506.16073", "title": "TD3Net: 一种用于唇读的时序密集多膨胀卷积网络", "title_en": "TD3Net: A temporal densely connected multi-dilated convolutional network for lipreading", "authors": "Byung Hoon Lee,Wooseok Shin,Sung Won Han", "background": "现有的唇读方法通常采用两阶段框架，前端和后端分别建模唇部动态运动。后端架构中，时间卷积网络（TCNs）因其广泛采用而成为了最先进的方法。最近，密集跳连在TCNs中被引入以缓解接收域稀疏度问题，从而在建模复杂时间表示方面有所改善。然而，它们在处理唇部运动连续性时依然存在信息损失的潜在问题，因为接收域存在盲区。", "innovation": "本文提出了TD3Net，这是一种结合了密集跳连和多膨胀时间卷积的后端架构的时序密集多膨胀卷积网络。TD3Net能够通过应用不同膨胀因子来覆盖广泛且密集的接收域，而不会出现盲区。实验结果表明，该方法在唇读任务中的性能与最先进的方法相当，同时具有更少的参数数量和更低的浮点运算量，并且具有在保留时间连续性的同时有效利用多种时间特征的优点。", "conclusion": "在使用两种大型公开数据集（Lip Reading in the Wild (LRW) 和 LRW-1000）进行的实验中，TD3Net达到了与最先进的方法相当的性能，同时在参数和计算量上有更高的效率。此外，可视化结果表明该方法在唇读系统中具有显著优势。详细的代码已发布在GitHub仓库（这个httpsURL）。"}
{"llm_update_time": "20250815", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2506.18248", "html_url": "https://arxiv.org/abs/2506.18248", "title": "语义结构感知生成攻击以增强对抗性转移能力", "title_en": "Semantic Structure-Aware Generative Attacks for Enhanced Adversarial Transferability", "authors": "Jongoh Jeong,Hunmin Yang,Jaeseok Jeong,Kuk-Jin Yoon", "background": "生成对抗性攻击通过训练一个扰动生成器在白盒代理模型上，并随后将精心设计的扰动应用于未知的黑盒受害模型。相比于迭代攻击，这类方法提供了优越的推理时间效率、可扩展性和转移性；然而，迄今为止，现有的研究并未完全利用生成模型的表现能力来保留和利用语义信息。", "innovation": "提出了一种基于Mean Teacher的语义结构感知攻击框架，该框架提供了一个时间上平滑的特征参考。通过这种平滑的参考，引导学生模型的早期层激活与语义丰富的教师模型的一致性，通过特征蒸馏。根据实验发现，将扰动生成锚定在生成器中的语义显著的早期中间块，指导了一系列增强对抗性转移能力的渐进式对抗扰动。", "conclusion": "在多种模型、领域和任务上进行了广泛的实验，证明相对于最先进的生成攻击方法，该方法在标准指标上一致地提高了对抗性转移能力，并且通过我们新提出的意外纠正率 (ACR) 进行全面评估。"}
{"llm_update_time": "20250815", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2506.13307", "html_url": "https://arxiv.org/abs/2506.13307", "title": "预训练潜在扩散模型在生成未见SAR图像中的微调技术定量比较", "title_en": "Quantitative Comparison of Fine-Tuning Techniques for Pretrained Latent Diffusion Models in the Generation of Unseen SAR Images", "authors": "Solène Debuysère,Nicolas Trouvé,Nathan Letheule,Olivier Lévêque,Elise Colin", "background": "研究表明，可以通过调整大型预训练潜在扩散模型来生成高分辨率合成孔径雷达（SAR）图像。这种方法能够实现可控的合成，并创造出训练集中不存在的罕见或异常场景。传统做法是从零开始训练特定任务的小模型，但本研究采用开源的文本到图像基础模型，适应SAR模式，利用其语义先验来与SAR成像物理对齐（侧视几何、斜距投影和相干斑点及其厚尾统计）。通过10万张SAR图像数据集，本文比较了全微调和参数高效低秩适应（LoRA）在UNet扩散骨架、变分自编码器（VAE）和文本编码器之间的应用效果。", "innovation": "本文提出了一种框架，将大型预训练潜在扩散模型适应到SAR图像生成中。该方法通过文本到图像基础模型实现了可控的SAR图像合成，特别针对SAR成像物理特性，如侧视几何、斜距投影和具有厚尾统计的相干斑。研究采用了综合评估方法，包括与真实SAR幅度分布的统计距离、灰度级共生矩阵（GLCM）描述符的纹理相似性以及使用SAR特化的CLIP模型进行语义对齐。结果显示，全UNet微调与文本编码器和学习标记嵌入的LoRA相结合的策略能最好地保留SAR几何和纹理，同时保持对文本提示的忠实度。", "conclusion": "此框架支持基于文本的控制和多模态条件（例如分割图、TerraSAR-X或光学引导），为大规模SAR场景数据增强和未见场景模拟在地球观测中的应用开辟了新的途径。"}
{"llm_update_time": "20250815", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2506.23009", "html_url": "https://arxiv.org/abs/2506.23009", "title": "MusiXQA: 提升多模态大语言模型在乐谱视觉理解方面的进展", "title_en": "MusiXQA: Advancing Visual Music Understanding in Multimodal Large Language Models", "authors": "Jian Chen,Wenye Ma,Penghang Liu,Wei Wang,Tengwei Song,Ming Li,Chenguang Wang,Jiayu Qin,Ruiyi Zhang,Changyou Chen", "background": "多模态大语言模型已经展示了在自然图像、富含文本的文档和图形设计中的出色视觉推理能力。然而，这些模型解释乐谱的能力仍缺乏探索。为解决这一问题，我们引入了MusiXQA，这是首个用于评估和推进多模态大语言模型在乐谱理解领域的综合数据集。MusiXQA利用MusiXTeX生成高质量的合成乐谱，包含结构化的注释涵盖音符音高和时长、和弦、谱号、调式/时间符号和文本，支持多样化的视觉问答任务。通过广泛评估，我们揭示当前领先的大语言模型在这一领域存在显著限制。", "innovation": "我们开发了基于我们数据集的细调模型Phi-3-MusiX，该模型在基于GPT的方法上实现了显著的性能提升。提出的数据集和模型为未来在乐谱理解方面的多模态大语言模型的研究奠定了基础。除此之外，还发布相关代码、数据和模型，以促进这一领域的进一步研究和应用。", "conclusion": "该研究通过建立首个专注于乐谱理解的综合数据集，推动了多模态大语言模型在这一领域的能力，为未来的研究提供了坚实基础。"}
{"llm_update_time": "20250815", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.06639", "html_url": "https://arxiv.org/abs/2507.06639", "title": "EXAONE Path 2.0: 具有端到端监督的病理基础模型", "title_en": "EXAONE Path 2.0: Pathology Foundation Model with End-to-End Supervision", "authors": "Myeongjang Pyeon,Janghyeon Lee,Minsoo Lee,Juseung Yun,Hwanil Choi,Jonghyun Kim,Jiwon Kim,Yi Hu,Jongseong Jang,Soonyoung Lee", "background": "在数字病理学中，全切片图像（WSI）由于其 gigapixel 级别的规模而很难处理，因此大多数方法通过自我监督学习（SSL）训练局部图像编码器，然后通过多重实例学习（MIL）或切片编码器进行切片级别的特征聚合以完成下游任务。然而，这些方法在局部 SSL 阶段可能会忽略对于生物标志物预测至关重要的复杂领域特定特征，如突变状态和分子特性，因为 SSL 方法依赖于仅适用于自然图像领域的基本数据增强。此外，SSL 方法的数据效率较低，需要大量的计算资源和数据集才能达到竞争性的表现。", "innovation": "本文提出了 EXAONE Path 2.0，这是一种在切片级别的直接监督下学习局部图像表示的病理学基础模型。仅使用 37,000 张 WSI 进行训练，EXAONE Path 2.0 在 10 个生物标志物预测任务上实现了最先进的平均表现，证明了其出色的样本效率。", "conclusion": "EXAONE Path 2.0 通过端到端的监督学习局部图像表示，显著提高了数据效率和模型性能。"}
{"llm_update_time": "20250815", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2506.19445", "html_url": "https://arxiv.org/abs/2506.19445", "title": "在野外去模糊：来自智能手机高速视频的真实世界数据集", "title_en": "Deblurring in the Wild: A Real-World Dataset from Smartphone High-Speed Videos", "authors": "Mahdi Mohd Hossain Noki,Syed Mumtahin Mahmud,Prothito Shovon Majumder,Abdul Mohaimen Al Radi,Sudipto Das Sukanto,Afia Lubaina,Md. Mosaddek Khan", "background": "介绍了来自智能手机慢动作视频的最大规模真实世界图像去模糊数据集。利用一秒钟内捕捉的240帧图像来模拟真实的长时间曝光模糊，并使用时间上居中的帧作为清晰的参考。该数据集包含超过42,000对高分辨率的模糊清晰图像对，大约是常用数据集的10倍大，场景种类也比常用的数据集多8倍，包括室内外环境，存在各种物体和相机运动。多款主流去模糊模型在这个数据集上进行了基准测试，并观察到显著的性能下降，突显了我们基准的复杂性和多样性。该数据集作为具有挑战性的新基准，有助于促进鲁棒性和通用性的去模糊模型的发展和研究。", "innovation": "构建了一个基于智能手机高速视频的最大规模真实世界图像去模糊数据集，包含超过42,000对高分辨率图像，是现有常用数据集的10倍大，场景种类也比常用的数据集多8倍，并且提供了多款主流去模糊模型在该数据集上的基准测试结果，突显了去模糊模型面临的复杂性和多样性问题。", "conclusion": "该数据集作为一个具有挑战性的新基准，为去模糊模型的鲁棒性和通用性提供了重要支持。"}
{"llm_update_time": "20250815", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.07985", "html_url": "https://arxiv.org/abs/2507.07985", "title": "常见数据属性限制CLIP中的对象-属性绑定", "title_en": "Common Data Properties Limit Object-Attribute Binding in CLIP", "authors": "Bijay Gurung,David T. Hoffmann,Thomas Brox", "background": "CLIP等对比视觉-语言模型在多种应用中广受欢迎，如零样本分类或作为多模态模型的视觉编码器。然而，这些模型的表现受到限制，例如CLIP模型学习到的是bag-of-words表示形式，导致无法区分“黄潜艇和蓝巴士”与“蓝潜艇和黄巴士”。在训练中添加硬负例或修改架构的先前尝试未能完全解决问题。研究人员认为，解决CLIP绑定问题的关键在于学习算法中的数据特性。", "innovation": "本文通过使用合成数据集严谨地识别数据属性对CLIP学习绑定能力的影响。研究发现，自然数据的低属性密度、不完整的字幕和人类描述最吸引他们注意力的对象的倾向对绑定性能有负面影响。通过合成数据，研究展示了即使增加硬负例或显式创建硬负例也无法提高CLIP的绑定可靠性，指出只有当数据符合识别的数据特性时，CLIP才能学习到几乎完美的绑定。", "conclusion": "CLIP模型的绑定性能受限于常见的自然数据属性，如低属性密度、不完整字幕和描述性强的倾向。合成数据可以帮助揭示这些数据特性对模型性能的影响，强调数据选择的重要性。"}
{"llm_update_time": "20250815", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.01006", "html_url": "https://arxiv.org/abs/2507.01006", "title": "GLM-4.1V-Thinking 和 GLM-4.5V：通过可扩展强化学习实现多功能多模态推理", "title_en": "GLM-4.1V-Thinking and GLM-4.5V: Towards Versatile Multimodal Reasoning with Scalable Reinforcement Learning", "authors": "GLM-V Team:Wenyi Hong,Wenmeng Yu,Xiaotao Gu,Guo Wang,Guobing Gan,Haomiao Tang,Jiale Cheng,Ji Qi,Junhui Ji,Lihang Pan,Shuaiqi Duan,Weihan Wang,Yan Wang,Yean Cheng,Zehai He,Zhe Su,Zhen Yang,Ziyang Pan,Aohan Zeng,Baoxu Wang,Bin Chen,Boyan Shi,Changyu Pang,Chenhui Zhang,Da Yin,Fan Yang,Guoqing Chen,Jiazheng Xu,Jiale Zhu,Jiali Chen,Jing Chen,Jinhao Chen,Jinghao Lin,Jinjiang Wang,Junjie Chen,Leqi Lei,Letian Gong,Leyi Pan,Mingdao Liu,Mingde Xu,Mingzhi Zhang,Qinkai Zheng,Sheng Yang,Shi Zhong,Shiyu Huang,Shuyuan Zhao,Siyan Xue,Shangqin Tu,Shengbiao Meng,Tianshu Zhang,Tianwei Luo,Tianxiang Hao,Tianyu Tong,Wenkai Li,Wei Jia,Xiao Liu,Xiaohan Zhang,Xin Lyu,Xinyue Fan,Xuancheng Huang,Yanling Wang,Yadong Xue,Yanfeng Wang,Yanzi Wang,Yifan An,Yifan Du,Yiming Shi,Yiheng Huang,Yilin Niu,Yuan Wang,Yuanchang Yue,Yuchen Li,Yutao Zhang,Yuting Wang,Yu Wang,Yuxuan Zhang,Zhao Xue,Zhenyu Hou,Zhengxiao Du,Zihan Wang,Peng Zhang,Debing Liu,Bin Xu,Juanzi Li,Minlie Huang,Yuxiao Dong,Jie Tang", "background": "本文介绍了GLM-4.1V-Thinking和GLM-4.5V两大视觉语言模型（VLMs），旨在推进通用的跨模态理解和推理能力。通过大规模预训练和充分的训练框架，建立了强大的视觉基础模型，为进一步性能设定了上限。然后提出了一种称为 Curriculum Sampling（CS）增强的强化学习方法（RLCS），增强了模型在多种任务上的综合能力，包括STEM问题解决、视频理解、内容识别、编程、语义定位、基于GUI的代理以及长文档解析。", "innovation": "本文提出了Reinforcement Learning with Curriculum Sampling（RLCS）方法，这是增强视觉语言模型（VLMs）能力的关键创新点。使用该方法，GLM-4.5V在42个公开展示的基准测试中几乎在所有任务上都达到了开源模型的最佳性能，并且在包括编程和基于GUI的代理在内的挑战性任务中优于封闭源代码模型Gemini-2.5-Flash。此外，较小的GLM-4.1V-9B-Thinking也表现出色，在29个基准测试中优于更大的Qwen2.5-VL-72B。", "conclusion": "本研究开源了GLM-4.1V-9B-Thinking和GLM-4.5V。他们在多个基准测试中的表现证明了它们的强大能力和竞争力，这些模型可以在GitHub链接中获得，为视觉语言领域的研究和应用提供了宝贵资源。"}
{"llm_update_time": "20250815", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.08307", "html_url": "https://arxiv.org/abs/2507.08307", "title": "M2DAO-Talker: 平衡多粒度运动解耦与交替优化的头部讲话生成", "title_en": "M2DAO-Talker: Harmonizing Multi-granular Motion Decoupling and Alternating Optimization for Talking-head Generation", "authors": "Kui Jiang,Shiyu Liu,Junjun Jiang,Hongxun Yao,Xiaopeng Fan", "background": "在电影制作领域，基于音频的头部讲话生成具有巨大潜力。现有的三维方法虽然在动作建模和内容合成方面取得了进步，但由于难以准确表现稳定且精细的运动场，经常产生渲染伪影，例如运动模糊、时间漂移和局部穿透现象。为了克服这些局限，该研究提出了一种统一的框架，该框架包含三个步骤：视频预处理、运动表示和重建渲染。这一框架基于所提出的M2DAO-Talker模型，通过多粒度运动解耦和交替优化解决了现有方法的限制。", "innovation": "该研究提出了新型的2D肖像预处理流水线，以提取帧级变形控制条件（运动区域分割掩码和摄像机参数），以利于运动表示。此外，提出了一种多粒度运动解耦策略，能够分别建模非刚性（口和面部）和刚性（头部）运动，以提高重建准确性。还设计了一种运动一致性约束，确保头部与躯干的运动一致性，从而减轻因运动混叠引起的穿透伪影。同时，设计了一种交替优化方法，迭代地细化面部和口腔运动参数，使得视频生成更加逼真。", "conclusion": "在多个数据集上的实验结果表明，M2DAO-Talker在生成质量和用户评定的真实感方面达到了最先进的性能，实现了2.43 dB的PSNR提升和0.64的用户评估视频真实性提升，同时保持了150 FPS的推理速度。项目主页为：https://is-this.github.io/"}
{"llm_update_time": "20250815", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.10778", "html_url": "https://arxiv.org/abs/2507.10778", "title": "基于LLM代理的仓库空间问答", "title_en": "Warehouse Spatial Question Answering with LLM Agent", "authors": "Hsiang-Wei Huang,Jen-Hao Cheng,Kuang-Ming Chen,Cheng-Yen Yang,Bahaa Alattar,Yi-Ru Lin,Pyongkun Kim,Sangwon Kim,Kwangju Kim,Chung-I Huang,Jenq-Neng Hwang", "background": "现有的多模态大型语言模型（MLLMs）在空间理解方面存在挑战。早期的方法主要依赖于大规模MLLM微调来提升空间理解能力。但这种做法耗费大量资源，效率较低。", "innovation": "本文提出了一种数据高效的方法，即LLM代理系统，该系统具有强大的空间推理能力。系统通过集成多种工具，使LLM代理能够进行空间推理和API交互，以解答复杂的空间问题。实验结果表明，该系统在物检、计数和距离估计等任务中表现出高准确率和高效率，特别是在复杂的室内仓库场景中。", "conclusion": "通过对2025 AI City Challenge Physical AI Spatial Intelligence Warehouse数据集的广泛评估，验证了该系统在复杂仓储空间问答上的有效性。源代码可在指定链接下载。"}
{"llm_update_time": "20250815", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.14976", "html_url": "https://arxiv.org/abs/2507.14976", "title": "用于视觉语言模型的分层跨模态提示学习", "title_en": "Hierarchical Cross-modal Prompt Learning for Vision-Language Models", "authors": "Hao Zheng,Shunzhi Yang,Zhuoxin He,Jinfeng Yang,Zhenhua Huang", "background": "预训练的视觉-语言模型（如CLIP）展示了出色的一般化能力，但将这些大型模型适应下游任务的同时保留其一般化能力仍然具有挑战性。尽管提示学习方法已显示出前景，但它们存在两个根本瓶颈限制了一般化：(a) 模态隔离，(b) 分层语义衰退。现有的提示学习方法不能有效解决跨模态信息的双向流，导致语义理解和任务适应之间存在不平衡。", "innovation": "本文提出了一种分层跨模态提示学习框架（HiCroPL），该框架通过利用文本和视觉模态之间的互补优势，建立起文本和视觉模态之间的双向知识流，使模态间能够相互完善语义。在早期层中，文本提示通过层级知识映射器注入较为清晰的语义到视觉提示中，从而增强低级视觉语义的表示。在后续层中，特定任务相关对象的视觉编码返回以深化并优化文本提示，保证深层表示保留可迁移的浅层语义，从而提升一般化能力。此外，提出了轻量级的分层知识代理层来促进高效的跨模态交互。", "conclusion": "HiCroPL在四个任务上的广泛评估结果表明其优越的性能，在11个基准测试中实现了最先进的成果，并取得了显著的提升。代码可在以下链接获取：this https URL。"}
{"llm_update_time": "20250815", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.21977", "html_url": "https://arxiv.org/abs/2507.21977", "title": "Motion Matters: Motion-guided Modulation Network for Skeleton-based Micro-Action Recognition", "title_en": "Motion Matters: Motion-guided Modulation Network for Skeleton-based Micro-Action Recognition", "authors": "Jihao Gu,Kun Li,Fei Wang,Yanyan Wei,Zhiliang Wu,Hehe Fan,Meng Wang", "background": "微动作（MAs）是社交互动中重要的非言语交流形式，具有潜在的应用于人类情绪分析。现有方法在微动作识别中往往忽视了微动作内在的微妙变化，限制了对具有细微差异的微动作区别的准确性。", "innovation": "针对现有方法忽视微动作内在微妙变化的问题，提出了一种新型的运动导向模态网络（MMN），通过隐式捕捉和调节微妙的运动线索来增强空间-时间表示学习。引入了运动导向骨骼模态模块（MSM）和运动导向时间模态模块（MTM），分别在骨骼层次和帧层次注入运动线索，以指导空间表示建模和整体运动模式建模，并提出了一种运动一致性学习策略来聚合多尺度特征的运动线索，以提高微动作分类的准确性。", "conclusion": "在Micro-Action 52和iMiGUE数据集上的实验证明，MMN在基于骨架的微动作识别中达到了最先进的性能，突显了明确建模微妙运动线索的重要性。"}
{"llm_update_time": "20250815", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.22733", "html_url": "https://arxiv.org/abs/2507.22733", "title": "异步追踪中的线性N点解决方法用于结构和运动估计", "title_en": "A Linear N-Point Solver for Structure and Motion from Asynchronous Tracks", "authors": "Hang Su,Yunlong Feng,Daniel Gehrig,Panfeng Jiang,Ling Gao,Xavier Lagorce,Laurent Kneip", "background": "结构和连续运动估计从点对应关系是计算机视觉中的基本问题，长期以来由著名的算法如5点或8点算法推动。然而，尽管这些算法广受好评，但它们仅限于处理源自每对视图的点对应，每个视图代表场景的一个瞬时捕捉。但在卷帘快门相机或更近的事件相机的情况下，这种同步性会失效。", "innovation": "本文提出了一种统一的方法，用于从任意时间戳的2D点对应关系中估计结构和线性运动，这些对应关系来自于任意视图集合。通过将问题表述为一阶动力学，并利用恒定速度运动模型，我们推导出了一种新颖的线性点共线关系，使我们可以高效地恢复线性速度和3D点，并且可以预测退化情况和解的多重性。由于其通用的表述式，该方法可以处理来自不同感测模式（如全局快门、卷帘快门和事件相机）的对应关系，甚至可以从不同共定位的传感器结合对应关系。", "conclusion": "我们在通过仿真实验和真实数据验证了该求解器的有效性，结果显示在所有感测模式中都具有一致的改进对比。我们认为我们的工作揭示了从异步数据中高效估计结构与运动的可能性。代码可以在以下链接找到：this https URL。"}
{"llm_update_time": "20250815", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.02669", "html_url": "https://arxiv.org/abs/2508.02669", "title": "MedVLThinker：多模态医学推理的简单基线", "title_en": "MedVLThinker: Simple Baselines for Multimodal Medical Reasoning", "authors": "Xiaoke Huang,Juncheng Wu,Hui Liu,Xianfeng Tang,Yuyin Zhou", "background": "Large Reasoning Models (LRMs)通过链式推理使模型能够'思考后再响应'，引入了AI的一个新范式。然而，医学领域中专注于推理的模型缺乏公开可复现的构建流程，这阻碍了整个社区的研究、分析和比较。为了克服这一问题，本文介绍了MedVLThinker，一个简洁但强大的基线模型套件。", "innovation": "MedVLThinker的特点包括系统整理了医学相关的文本和图文数据，按照推理难度程度进行了筛选。此外，提出了两种训练方法：一种是针对简化推理痕迹的监督微调（SFT）；另一种是基于最终答案正确性的可验证奖励的强化学习（RLVR）。在对Qwen2.5-VL模型和六个医学问答基准的广泛实验中发现，RLVR方法在绩效上持续且显著优于SFT。另外，在RLVR框架下，仅通过文本训练模型的性能提升反而超过了图文数据训练，并且利用RLVR方法训练的最好7B模型，在公开的VQA基准上达到了最先进的水平。", "conclusion": "该研究发布了所有整理的数据、模型和代码，利用这种公开的基础框架，未来对该领域的研究将能够在医疗器械和服务领域开辟新途径。"}
{"llm_update_time": "20250815", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.22369", "html_url": "https://arxiv.org/abs/2507.22369", "title": "使用视觉问答（VQA）探索课堂活动监测的应用", "title_en": "Exploring the Application of Visual Question Answering (VQA) for Classroom Activity Monitoring", "authors": "Sinh Trong Vu,Hieu Trung Pham,Dung Manh Nguyen,Hieu Minh Hoang,Nhu Hoang Le,Thu Ha Pham,Tai Tan Mai", "background": "课堂行为监控是教育研究中的关键方面，对学生的参与度和学习成果有着重要意义。近年来，视觉问答（VQA）模型的进步为从视频记录中自动分析复杂的课堂互动提供了有前景的工具。本文分析了多个最先进的开源VQA模型，包括LLaMA2、LLaMA3、QWEN3和NVILA，在课堂行为分析中的适用性。通过从越南银行业学院的真实课堂视频记录中创建BAV-Classroom-VQA数据集，本文介绍了数据的收集、标注方法，并对选定的VQA模型在该数据集上的性能进行了基准测试。初步实验结果表明，所有四个模型在回答与行为相关的视觉问题方面都表现出色，展示了其在未来的课堂分析和干预系统中的潜力。", "innovation": "本文通过使用多个最先进的开源VQA模型去分析课堂行为监控，并引入了一个新的数据集BAV-Classroom-VQA。这个数据集基于越南银行业学院的真实课堂视频记录。通过对该数据集的模型性能基准测试，展示了这些模型在回答行为相关的视觉问题方面的能力和潜力。这一创新方法为未来课堂分析和干预系统的建设提供了新的工具和技术支持。", "conclusion": "本文的实验结果表明，所有分析的VQA模型在课堂行为相关的视觉问题回答上都表现出了良好的性能，这表明VQA模型有潜力在未来的课堂分析和干预系统中发挥作用。尽管目前还存在数据标注和模型精确性方面的挑战，但这些VQA模型展现了在课堂行为监控领域的应用前景。未来的研究可以进一步优化模型性能，并探索更复杂的应用场景。"}
{"llm_update_time": "20250815", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.04549", "html_url": "https://arxiv.org/abs/2508.04549", "title": "MSC：带定位分割和剪辑级别标注的海洋野生动物视频数据集", "title_en": "MSC: A Marine Wildlife Video Dataset with Grounded Segmentation and Clip-Level Captioning", "authors": "Quang-Trung Truong,Yuk-Kwan Wong,Vo Hoang Kim Tuyen Dang,Rinaldi Gotama,Duc Thanh Nguyen,Sai-Kit Yeung", "background": "海洋视频在视频理解方面面临重大挑战，由于海洋物体和环境的动态变化、摄像机运动以及海洋场景的复杂性。现有的视频字幕数据集通常专注于通用或以人类为中心的领域，很少能适应海洋环境的复杂性并提供有关海洋生命的洞察。", "innovation": "提出了一个两阶段的海洋物体导向视频字幕流水线，开发了一个全面的视频理解基准，利用视频、文本和分割掩码的三元组来促进视觉定位和字幕生成，从而提高海洋视频理解和分析以及海洋视频生成的效果。还突出了视频分割的有效性，以检测场景变化中的显著对象转换，显著丰富了字幕的内容。", "conclusion": "本文提出了一个海洋野生动物视频数据集MSC，该数据集结合了定位分割和剪辑级别标注，旨在提升海洋视频理解和生成的效果。"}
{"llm_update_time": "20250815", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.03497", "html_url": "https://arxiv.org/abs/2508.03497", "title": "EditGarment：带有自动化MLLM合成和语义感知评估的基于指令的服装编辑数据集", "title_en": "EditGarment: An Instruction-Based Garment Editing Dataset Constructed with Automated MLLM Synthesis and Semantic-Aware Evaluation", "authors": "Deqiang Yin,Junyi Guo,Huanda Lu,Fangyu Wu,Dongming Lu", "background": "当前，通过自然语言进行服装图片修改的技术依赖特定于服装的语义理解及属性依赖。然而，由于高质量指令-图像配对数据稀缺，人工标注代价高昂且难以扩展，这阻碍了自动化流程的发展。虽然MLLM在数据合成方面显示出潜力，但由于指令建模不够精确以及缺乏特定于时尚领域的监督信号，其应用受到限制。", "innovation": "本文提出了一个自动化的管道来构造服装编辑数据集。首先，定义了与实际时尚工作流程一致的六个编辑指令类别，以指导生成平衡且多样化的指令-图像三元组。其次，引入了语义感知评估指标，称为Fashion Edit Score，用于捕捉服装属性之间的语义依赖性，并在构建过程中提供可靠的监督信号。通过该管道构建了总计52,257个候选三元组，并保留20,596个高质量的三元组，建立了第一个专门用于独立服装编辑的基于指令的数据集—EditGarment。", "conclusion": "本文提出了EditGarment，这是第一个专门用于独立服装编辑的基于指令的数据集，对常规编辑任务而言，它不仅精确理解了服装特异性语义和属性依赖性，还利用自动化的MLLM合成和语义感知评估方法大幅度丰富了高质量数据集，为将来的发展打下了坚实的基础。"}
{"llm_update_time": "20250815", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.03189", "html_url": "https://arxiv.org/abs/2508.03189", "title": "利用KANs局部特性和Feature Drift Compensation Projection实现数据无标签重放的持续面部伪造检测", "title_en": "Unifying Locality of KANs and Feature Drift Compensation Projection for Data-free Replay based Continual Face Forgery Detection", "authors": "Tianshuo Zhang,Siran Peng,Li Gao,Haoyuan Zhang,Xiangyu Zhu,Zhen Lei", "background": "随着面部伪造技术的快速发展，检测器需要不断适应新伪造手法，将面部伪造检测置于持续学习的框架中。然而，在学习新伪造类型时，检测器在之前类型的检测性能会迅速下降，这就是灾难性遗忘现象。Kolmogorov-Arnold网络（KAN）通过局部可塑的样条函数作为激活函数，能够通过修改局部函数区域而保留其他区域不变，从而有助于解决灾难性遗忘的问题。", "innovation": "本文提出了一种基于KAN的持续面部伪造检测（KAN-CFD）框架，其中包括域组KAN检测器（DG-KD）和通过KAN漂移补偿投影的数据无关重放特征分离策略（FS-KDCP）。该方法能够让KAN适用于高维图像输入并保留局部特性和局部可塑性。FS-KDCP通过KAN漂移补偿投影避免了KAN输入空间的重叠，且无需使用先前任务的数据。", "conclusion": "实验结果表明，所提方法在性能上显著优于现有方法，并有效减少了遗忘现象。"}
{"llm_update_time": "20250815", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.01272", "html_url": "https://arxiv.org/abs/2508.01272", "title": "PromptSafe：构建安全的文本到图像生成的门控提示调优", "title_en": "PromptSafe: Gated Prompt Tuning for Safe Text-to-Image Generation", "authors": "Zonglei Jing,Xiao Yang,Xiaoqian Li,Siyuan Liang,Aishan Liu,Mingchuan Zhang,Xianglong Liu", "background": "文本到图像(T2I)模型展示了强大的生成能力，但由于安全问题，如产生不适内容（NSFW），仍然容易纰漏。尽管最近有一些通过在输入中添加防御性标记进行软提示微调的方法，这些方法依赖于大规模的图像文本数据集，并基于静态防御，在推理时应用单一的大小适配解决方案。这样的方法不仅导致高计算成本和图像质量下降，而且在应对真实世界提示的多样性和细微安全需求方面的灵活性不足。", "innovation": "提出了一种名为PromptSafe的门控提示调优框架，结合了轻量级的仅文本监督软嵌入和推理时的门控控制网。首先使用LLM重写不安全的提示以构造有效的仅文本型训练集，从而优化一种通用的软提示。该软提示在去噪扩散过程中排斥不安全的嵌入并吸引安全的嵌入。通过引入门控机制，可以根据估计的提示毒性自适应调整防御强度，实现针对提示风险的防御强度与有害输入的强保护，同时保持良性生成质量。实验结果显示，PromptSafe实现了SOTA的不安全生成率（2.36%），并能对未见过的有害类别有强大的泛化能力，也具有跨扩散模型架构的稳健转移性，以及对适应性对抗攻击的恢复能力，强调了其在安全和可扩展部署中的实用价值", "conclusion": "PromptSafe框架不仅在不安全生成率上取得了领先，还在保持良性生成质量方面表现出色。此外，它展示了在未见过的有害类别、不同扩散模型架构下的泛化能力，以及对适应性对抗攻击的抗性，证明了其在安全和可扩展部署中的实际价值。"}
{"llm_update_time": "20250815", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.00399", "html_url": "https://arxiv.org/abs/2508.00399", "title": "iSafetyBench: 一种用于工业环境安全性的视频-语言基准", "title_en": "iSafetyBench: A video-language benchmark for safety in industrial environment", "authors": "Raiyaan Abdullah,Yogesh Singh Rawat,Shruti Vyas", "background": "近期的视觉-语言模型（VLMs）在零样本条件下已成功应用于多种视频理解任务，但它们在高风险工业领域的应用潜力仍然未被广泛探索。特别是在识别常规操作和安全关键性异常方面，这些模型的表现仍有待提高。为了填补这一空白，我们提出了iSafetyBench，一种专注于评估模型在工业环境中性能的新视频-语言基准，涵盖正常和危险场景。该基准包含从真实工业环境采集的1100个视频片段，标注了跨越98种常规和67种危险行为类别的开放词汇多标签动作标签。每个视频片段配有多种选择题，便于在单一标签和多标签评估中进行精细评估，从而全面评估VLMs在常规和安全关键环境中的性能。尽管现有的视频基准测试中表现优秀，这些模型在iSafetyBench中的表现相对较弱，尤其是在识别危险活动和多标签场景中的表现不足。这些结果凸显了需要更稳健和安全意识强的多模态模型来适应工业应用的需求。iSafetyBench为此提供了一个前所未有的测试平台，以加速这一领域的发展。数据集可通过以下网址获取：this https URL.", "innovation": "iSafetyBench是一种专门设计用于评估模型在工业环境中性能的新视频-语言基准，涵盖了正常和危险场景。基准中的视频片段配有多种选择题，便于在单一标签和多标签评估中进行精细评估。该基准数据集包含1100个标注了开放词汇多标签动作标签的视频片段，涵盖98种常规和67种危险行为类别。这为视觉-语言模型在更复杂和安全关键环境中的评估提供了开创性的平台，强调了在这些领域构建更有效的多模态模型的需求。", "conclusion": "尽管现有的视觉-语言模型在零样本条件下在现有视频基准测试中的表现优秀，但在iSafetyBench中却表现出较低的能力，特别是在识别危险活动和多标签场景中的表现。这些结果揭示了模型在工业应用中需要改进的地方，特别是增强模型对危险活动的识别能力。iSafetyBench为开发更具安全意识的多模态模型提供了一个全新的测试平台，旨在推动该领域的发展。"}
{"llm_update_time": "20250815", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.06259", "html_url": "https://arxiv.org/abs/2508.06259", "title": "SIFThinker: 空间感知的图像聚焦用于视觉推理", "title_en": "SIFThinker: Spatially-Aware Image Focus for Visual Reasoning", "authors": "Zhangquan Chen,Ruihui Zhao,Chuwei Luo,Mingze Sun,Xinlei Yu,Yangyang Kang,Ruqi Huang", "background": "当前的多模态大型语言模型（MLLMs）在处理复杂的视觉任务（如空间理解、细粒度感知）时仍然面临显著挑战。尽管已有方法试图引入视觉推理，但它们未能利用空间线索纠正注意力，从而在迭代中精确定位与提示相关的内容区域。", "innovation": "引入了一种空间感知的‘以图辅助思考’框架SIFThinker，该框架模仿了人类的视觉感知。具体来说，SIFThinker通过交错使用增强深度的边框和自然语言，实现了注意力纠正和图像区域聚焦。文章的贡献包括提出了一个逆扩展正向推理策略，使模型能够在处理级别监督下生成交错的图像-文本初始思维链，并构建了SIF-50K数据集。此外，还提出了GRPO-SIF，这是一种结合深度引导视觉定位的强化训练范式，让模型能够动态地纠正并聚焦于与提示相关的内容区域。", "conclusion": "广泛的实验表明，SIFThinker在空间理解和细粒度视觉感知方面优于最先进的方法，同时保持了强大的通用能力，突显了该方法的有效性。"}
{"llm_update_time": "20250815", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.05519", "html_url": "https://arxiv.org/abs/2508.05519", "title": "利用AI加速医疗数据清理：AI辅助方法与传统方法的比较研究", "title_en": "Leveraging AI to Accelerate Medical Data Cleaning: A Comparative Study of AI-Assisted vs. Traditional Methods", "authors": "Matthew Purri,Amit Patel,Erik Deurrell", "background": "临床试验的数据清理是药物开发中的关键瓶颈。人工审查流程难以应对数据量和复杂性的快速增长。研究表明，为了管理和优化临床医学数据审查过程，需要开发一种能够处理大量复杂数据的人工智能辅助平台。", "innovation": "Octozi是结合大型语言模型和领域特定启发式规则的一种人工智能辅助平台。它能够显著提高数据清理的效率，减少错误率，并降低假阳性查询的数量。实验证明，与人工审查相比，Octozi将数据清理吞吐量提高了6.03倍，将错误率降低了6.44倍，并将假阳性查询减少了15.48倍。通过分析典型III期肿瘤试验的成本，研究表明可以节省大量成本，如数据库锁定时间缩短5天可以节省440万美元，提高医疗审查效率可以节省42万美元，减少查询管理负担可以节省28.8万美元。这些改进不随审查者经验水平的变化而变化，说明了AI辅助方法的广泛适用性。本研究证明了AI在临床操作流程中的应用潜力，特别是在医疗数据审查方面，能够提高运营效率并降低成本，同时保持合规性。", "conclusion": "人工智能辅助的方法能够解决临床试验操作中的根本低效问题，例如将数据库锁定时间加速33%，同时保持监管合规性并显著降低运营成本。这项工作建立了将AI整合到关键临床工作流中的框架，并展示了人与AI协作在制药临床试验中的变革潜力。"}
{"llm_update_time": "20250815", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.08189", "html_url": "https://arxiv.org/abs/2508.08189", "title": "视觉中的强化学习：综述", "title_en": "Reinforcement Learning in Vision: A Survey", "authors": "Weijia Wu,Chen Gao,Joya Chen,Kevin Qinghong Lin,Qingwei Meng,Yiming Zhang,Yuke Qiu,Hong Zhou,Mike Zheng Shou", "background": "近年来，强化学习 (RL) 和视觉智能领域的交叉研究取得了显著进展，使智能体不仅能够感知复杂的视觉场景，还能在这些场景中进行推理、生成和行动。本文综述了这一领域的最新进展。", "innovation": "文章详细阐述了通过总结视觉 RL 问题的正式化及其从 RLHF 到验证性奖励范式的演化过程；组织了超过 200 篇代表性的科学研究，分为多媒体大型语言模型、视觉生成、统一模型框架和视觉-语言-行动模型四个主题支柱；并且通过考察算法设计、奖惩工程、基准进展以及例如课程驱动训练、偏好对准扩散和统一奖惩建模等趋势来梳理主要进展；还评估了不同级别的评价协议，并明确了样本效率、泛化、和安全部署等开放挑战。", "conclusion": "本综述旨在为研究人员和从业者提供视觉 RL 景观的一致地图，并突出未来研究的有力方向。"}
{"llm_update_time": "20250815", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.07171", "html_url": "https://arxiv.org/abs/2508.07171", "title": "EventRR: 事件参照推理用于引用视频对象分割", "title_en": "EventRR: Event Referential Reasoning for Referring Video Object Segmentation", "authors": "Huihui Xu,Jiashi Lin,Haoyu Chen,Junjun He,Lei Zhu", "background": "当前的引用视频对象分割（RVOS）方法将引用表达式视为无结构的序列，忽视了其对参照体推理至关重要的语义结构。相对于只关注物体属性和物体之间关系的图像引用表达式而言，视频引用表达式还包含了事件属性和事件之间的时间关系。这一复杂性挑战了传统的结构化推理图像方法。因此，需要一种新的框架来解决这些问题。", "innovation": "提出了事件参照推理（EventRR）框架。EventRR将RVOS分解为物体汇总部分和参照推理部分。在汇总阶段，通过将每个帧摘要为一组瓶颈标记，并在视频级别汇总步骤中高效地聚合这些标记来交换全局跨模态时间上下文。推理部分，EventRR通过将视频引用表达式中的语义事件结构提取到高度表达性的参照事件图（REG）中来解决问题。根据REG拓扑遍历，提出了时间概念-角色推理（TCRR）来从REG叶节点到根节点积累每个时间查询的引用得分。每一推理步骤都可以解释为从REG的概念-角色关系中获得的问题-答案对。通过在四个广泛认可的基准数据集上进行的大量实验，展示了EventRR在定量和定性方面均优于现有的最佳RVOS方法。", "conclusion": "EventRR在各类基准数据集上均显示出比当前最佳RVOS方法更好的性能。"}
{"llm_update_time": "20250815", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.08601", "html_url": "https://arxiv.org/abs/2508.08601", "title": "Yan: 基于基础的交互式视频生成", "title_en": "Yan: Foundational Interactive Video Generation", "authors": "Deheng Ye,Fangyun Zhou,Jiacheng Lv,Jianqi Ma,Jun Zhang,Junyan Lv,Junyou Li,Minwen Deng,Mingyu Yang,Qiang Fu,Wei Yang,Wenkai Lv,Yangbin Yu,Yewen Wang,Yonghang Guan,Zhihao Hu,Zhongbin Fang,Zhongqian Sun", "background": "本文介绍了Yan，一个交互式视频生成的基础框架，涵盖从模拟生成到编辑的整个管道。该框架通过核心模块将高级模拟、多模态生成和多粒度编辑功能整合起来，以实现交互式3D仿真和实时生成。", "innovation": "1. 高压缩实时3D-VAE结合KV缓存引导的滑动窗口降噪推理过程，实现了1080P/60FPS的即时交互式3D仿真。\n2. 引入了分层自回归标题方法，将游戏特定知识注入开放域多模态视频扩散模型中，将其转变为帧级、行为控制的即时无限交互式视频生成器。\n3. 提出了混合模型，明确分离了互动机制模拟和视觉渲染，通过文本实现交互式视频内容的多粒度编辑。", "conclusion": "Yan框架集成了这些模块，推动了交互式视频生成从孤立能力迈向全面的人工智能驱动交互式创作范式，为新型创意工具、媒体和娱乐铺平了道路。"}
{"llm_update_time": "20250815", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.06995", "html_url": "https://arxiv.org/abs/2508.06995", "title": "S2-UniSeg: 快速通用凝聚池化用于无需监督的可扩展分割万物", "title_en": "S2-UniSeg: Fast Universal Agglomerative Pooling for Scalable Segment Anything without Supervision", "authors": "Huihui Xu,Jin Ye,Hongqiu Wang,Changkai Ji,Jiashi Lin,Ming Hu,Ziyan Huang,Ying Chen,Chenglong Ma,Tianbin Li,Lihao Liu,Junjun He,Lei Zhu", "background": "近期的自监督图像分割模型在语义分割和无类别实例分割方面取得了显著成果，然而它们的预训练阶段是多阶段的，需要在每个训练周期之间耗时生成伪掩码。这一耗时的离线过程不仅难以处理大规模训练数据集，还由于其断续的优化过程导致了次优解。因此，为了克服这些问题，本文提出了一种新的伪掩码算法——快速通用凝聚池化（Fast Universal Agglomerative Pooling，Fast UniAP），并在该算法基础上，提出了可扩展的自监督通用分割（Scalable Self-Supervised Universal Segmentation，S2-UniSeg）模型。S2-UniSeg 使用学生模型和动量教师进行连续预训练，并提出了一种新型的分割导向的先验任务——基于查询的自我蒸馏（Query-wise Self-Distillation，QuerySD），使其能够学习局部到全局的对应关系。", "innovation": "1. 提出了一种新的伪掩码算法——快速通用凝聚池化（Fast Universal Agglomerative Pooling，Fast UniAP），能够在线并行生成语义级和实例级的多粒度伪掩码，大大提高了伪掩码的生成速度。\n2. 提出了可扩展的自监督通用分割（Scalable Self-Supervised Universal Segmentation，S2-UniSeg）模型，该模型采用学生-教师架构进行连续预训练，并使用Query-wise Self-Distillation（基于查询的自我蒸馏）先验任务进行训练。\n3. 在相同的设置下，S2-UniSeg 在 COCO 和 UVO 上优于 SOTA 模型 UnSAM，分别在 COCO 上取得了 AP+6.9，在 UVO 上取得了 AR+11.1 的成绩，在 COCOStuff-27 上取得了 PixelAcc+4.5 的成绩，在 Cityscapes 上取得了 RQ+8.0 的成绩。进一步在 SA-1B 的 2M 图像子集上进行扩展后，S2-UniSeg 在所有四个基准上的性能均有提升。", "conclusion": "本文提出了一种新的伪掩码算法和可扩展的自监督通用分割模型，大大提高了预训练效率，并在多个基准上取得了显著的性能提升。"}
{"llm_update_time": "20250815", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.08098", "html_url": "https://arxiv.org/abs/2508.08098", "title": "TBAC-UniImage: 梯级微调实现统一的理解与生成", "title_en": "TBAC-UniImage: Unified Understanding and Generation by Ladder-Side Diffusion Tuning", "authors": "Junzhe Xu,Yuyang Yin,Xi Chen", "background": "传统的基于扩散的统一模型存在两个主要的局限性。一种方法只是使用多模态大型语言模型（MLLM）的最终隐藏状态作为生成条件，这导致了一个浅显的连接，生成器与其他多模态表示被隔离。另一种方法是从头开始预训练一个统一的生成架构，这对许多研究者来说计算成本高昂且不可行。本文通过利用来自MLLM多个层次的表示作为扩散模型的生成条件，利用了多模态模式以实现更深、更精细的理解与生成统一，解决了上述问题。", "innovation": "提出了一种创新的方法，即通过梯级微调实现多模态模型理解和生成的统一。不同于以往只使用MLLM最终隐藏状态或从头预训练统一架构的方法，本文采用了MLLM的多个层次的表示作为生成条件，以此提升生成模型的理解深度和精细度。这种方法不仅能够避免孤立生成器的问题，还能有效降低计算成本，为研究者提供了更加高效和灵活的解决方案。", "conclusion": "通过在TBAC-UniImage中的应用，证明了使用多模态大型语言模型的多个层次作为生成条件能够实现更深入的理解与生成的统一。该模型展示了在多模态理解和生成任务上的优越性能，有望推动该领域的发展。"}
{"llm_update_time": "20250815", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.09185", "html_url": "https://arxiv.org/abs/2508.09185", "title": "一种用于增强现实可解释认知攻击检测的神经符号框架", "title_en": "A Neurosymbolic Framework for Interpretable Cognitive Attack Detection in Augmented Reality", "authors": "Rongqian Chen,Allison Andreyev,Yanming Xiu,Mahdi Imani,Bin Li,Maria Gorlatova,Gang Tan,Tian Lan", "background": "AR通过在物理世界叠加虚拟元素增强感知，但由于其日益普及，对AR内容进行认知攻击以操控用户的语义感知的认知攻击引起了越来越多的关注。现有的检测方法往往侧重于视觉变化，这限制在像素级或图像级别处理，并缺乏语义推理能力；或者依赖预训练的视觉-语言模型（VLMs），这些模型作为黑盒方法，解释性有限。", "innovation": "该论文提出了CADAR，一种新颖的神经符号方法，用于AR中的认知攻击检测。它结合了多模态视觉-语言输入，使用神经VLMs获得符号感知图表示，融合先验知识、显著性加权和时间相关性。模型采用基于粒子滤波的统计推理，这是一种顺序蒙特卡洛方法来检测认知攻击。因此，CADAR继承了预训练VLM的可适应性以及粒子过滤的可解释性和推理严谨性。", "conclusion": "在扩展的AR认知攻击数据集上的实验表明，与强基线相比，在复杂的AR攻击场景中，CADAR的准确率可提高10.7%，突出了神经符号方法在有效且可解释的认知攻击检测中的潜力。"}
{"llm_update_time": "20250815", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.08508", "html_url": "https://arxiv.org/abs/2508.08508", "title": "Re:Verse -- 能让你的Vision-Language Model看漫画吗？", "title_en": "Re:Verse -- Can Your VLM Read a Manga?", "authors": "Aaditya Baranwal,Madhav Kataria,Naitik Agrawal,Yogesh S Rawat,Shruti Vyas", "background": "当前的Vision-Language Models (VLMs) 在处理连续视觉叙事时，表面级识别与深层次叙事推理之间存在重要差距。通过全面调查漫画叙事理解，研究发现，尽管最新的大型多模态模型擅长单个分格解析，但他们在时间因果关系和跨分格连贯性方面系统性地失败，这是连贯故事理解的核心要求。这表明现有的模型在故事层面上缺乏真正的智能，尤其是对非线性叙述、角色一致性以及长时间序列中因果推理方面的挑战。", "innovation": "本研究引入了一种新的评估框架，结合精细粒度的多模态注释、跨模态嵌入分析及检索增强评估，以系统性地描述这些局限性。该方法包括(i)严格的注释协议，将视觉元素与叙事结构通过对齐的轻小说文本链接；(ii) 多种推理范式的综合评估，包括直接推理和检索增强生成；(iii) 跨模态相似性分析揭示了当前VLMs联合表征中的基本不一致性。通过对《Re:Zero》漫画11章中的308个分格进行全面研究，本文首次从生成性叙述、情境对话定位和时间推理三个方面对VLMs的长篇叙事理解进行系统分析。", "conclusion": "研究结果表明，当前的模型在故事层面的智能方面存在局限，特别是在非线性叙述、角色一致性和长时间序列中的因果推理方面。这项工作不仅奠定了评估叙事智能的基础，而且提供了一种有效方法，使多模态模型能够超越基本视觉识别，实现对离散视觉叙述的深入序列理解。"}
{"llm_update_time": "20250815", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.09476", "html_url": "https://arxiv.org/abs/2508.09476", "title": "从大角度到一致的人脸：Mixture of Facial Experts实现身份保留的视频生成", "title_en": "From Large Angles to Consistent Faces: Identity-Preserving Video Generation via Mixture of Facial Experts", "authors": "Yuji Wang,Moran Li,Xiaobin Hu,Ran Yi,Jiangning Zhang,Chengming Xu,Weijian Cao,Yabiao Wang,Chengjie Wang,Lizhuang Ma", "background": "当前的视频生成模型在处理大视角下的人脸保真度时存在困难，主要面临两大挑战：一是无法有效整合身份特征到DiT结构中；二是现有的开源视频数据集中很少覆盖大视角的人脸数据。", "innovation": "为了应对这一挑战，作者提出两项创新成果：首先是引入了Mixture of Facial Experts (MoFE)，动态组合三种专家提供的互补线索，旨在捕捉面部属性的跨视角身份敏感特征、高层次语义特征和像素级细节。此外，推出了一种数据处理流水线，重点关注'Face Constraints'和'Identity Consistency'两个方面，以解决大视角人脸数据稀缺和公共数据集中身份稳定的训练数据不足的问题。通过此流水线，构建了Large Face Angles (LFA) 数据集，包含460K带有标注人脸角度的视频片段。", "conclusion": "实验结果表明，本文方法借助LFA数据集，在面部相似性、面部FID和CLIP语义对齐方面显著优于现有的最先进方法。最新的代码和数据集已公开。”"}
{"llm_update_time": "20250815", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.09178", "html_url": "https://arxiv.org/abs/2508.09178", "title": "IAD-R1: 强化工业异常检测中一致性的推理", "title_en": "IAD-R1: Reinforcing Consistent Reasoning in Industrial Anomaly Detection", "authors": "Yanhui Li,Yunkang Cao,Chengliang Liu,Yuan Xiong,Xinghui Dong,Chao Huang", "background": "在现代制造中，工业异常检测是至关重要的组成部分。然而，缺陷样本的稀缺性限制了传统检测方法的应用场景。尽管视觉-语言模型（VLMs）展示了显著的泛化能力，但其在工业异常检测中的性能仍有限。因此，存在一个提升VLMs在工业异常检测中的广泛应用能力和效果的挑战。", "innovation": "本文提出了IAD-R1，这是一个泛用的后训练框架，适用于不同架构和参数规模的VLMs，显著提升了它们的异常检测能力。IAD-R1采用两阶段训练策略：感知激活监督微调（PA-SFT）阶段使用精心构建的高质量Chain-of-Thought数据集（Expert-AD）进行训练，提高异常感知能力，并建立推理到答案的关联；结构控制组相对策略优化（SC-GRPO）阶段通过精心设计的奖励函数，实现从“异常感知”到“异常解释”的能力飞跃。该方法在7种VLMs上均获得了显著改进，尤其是DAGM数据集上的改进最为显著，平均准确率提高了43.3%，甚至在零样本设置下，0.5B参数模型通过IAD-R1训练后超越了包括GPT-4.1和Claude-Sonnet-4在内的商业模型，展示了IAD-R1的有效性和优势。", "conclusion": "实验结果表明，IAD-R1显著提高了不同规模的VLMs在工业异常检测中的准确性，并且0.5B参数模型在零样本设置下超越了现有商业模型，证明了IAD-R1的有效性和优越性。数据集、代码及所有模型权重将会公开发布。"}
{"llm_update_time": "20250815", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.09543", "html_url": "https://arxiv.org/abs/2508.09543", "title": "迭代体素融合用于非对称立体匹配", "title_en": "Iterative Volume Fusion for Asymmetric Stereo Matching", "authors": "Yuanting Gao,Linghao Shen", "background": "立体匹配是三维计算机视觉中的关键步骤，大多数算法都假设双眼视觉具有对称性。然而，非对称多摄像机系统的兴起（如广角-长焦镜头）挑战了这一假设，使得立体匹配复杂化。视觉不对称性破坏了立体匹配，因为它影响了最关键的成本体计算。在非对称立体匹配中，成本体之间的信息失真不相同，导致需全面利用两种成本体解决该问题。", "innovation": "本文探索了两种已建立的非对称立体匹配成本体构建方法的成本体分布，并发现这两种成本体都存在信息失真。基于此，提出了两阶段的迭代体积融合网络（IVF-AStereo），该网络包括初始阶段的聚合级联体积细化相关体积，以及随后的两体积融合以增强细节处理。该方法特别适用于非对称场景，并且在视觉失真条件下表现出良好的稳健性。", "conclusion": "通过基准数据集上的大量对比实验和消融研究，证实了在非对称立体匹配中的IVF-AStereo方法的有效性，尤其是在分辨率和颜色退化的情况下。"}
{"llm_update_time": "20250815", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.09202", "html_url": "https://arxiv.org/abs/2508.09202", "title": "无源域适应中的个性特征翻译：一种高效的表达识别方法", "title_en": "Personalized Feature Translation for Expression Recognition: An Efficient Source-Free Domain Adaptation Method", "authors": "Masoumeh Sharafi,Soufiane Belharbi,Houssem Ben Salem,Ali Etemad,Alessandro Lameiras Koerich,Marco Pedersoli,Simon Bacon,Eric Granger", "background": "面部表情识别（FER）模型在很多基于视频的情感计算应用中被广泛应用，例如人机交互和健康监测。然而，深度FER模型在处理微妙表情和高个体差异时往往表现不佳，限制了其在实际应用中的性能。为了改善其性能，已经提出了基于无源域适应（SFDA）的方法，可以仅使用目标域的未标记数据对预训练的源模型进行个性化调整，从而避免数据隐私、存储和传输方面的限制。然而，当源数据不可用进行适应且仅存在目标域的中性表情未标记数据时，SFDA 方法的使用遇到了挑战。传统的SFDA方法通常不设计用于仅用单个类别的目标数据进行适应，并且使用模型生成非中性表情的面部图像可能导致不稳定性和计算成本高昂。", "innovation": "本文提出了一种名为个性化特征翻译（PFT）的无源域适应方法，该方法在潜在空间中进行操作，不依赖于源数据或图像生成。相比于现有的图像翻译方法，PFT首先在源域数据上预训练翻译器，将一个源个体的特定风格特征转换为另一个个体。通过优化表情一致性和风格感知目标的组合来保留表情信息。然后，翻译器在中性目标数据上进行适应，无需使用源数据或图像合成。这种方法通过在潜在空间中进行翻译，避免了面部表情生成的复杂性和噪声，生成了优化分类的判别嵌入。使用PFT消除了对图像合成的需求、降低了计算开销（通过使用轻量级的翻译器进行调整）并且仅适应模型的一部分，从而使得该方法在效率上相比基于图像的翻译方法更优。", "conclusion": "PFT方法能够在未标记的目标数据中有效适应面部表情识别模型，特别是在中性表情的情况下，这种适应不需要使用来源数据或进行图像合成，从而提高了效率和适应性。"}
{"llm_update_time": "20250815", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.09632", "html_url": "https://arxiv.org/abs/2508.09632", "title": "Preacher: Paper-to-Video Agentic System", "title_en": "Preacher: Paper-to-Video Agentic System", "authors": "Jingwei Liu,Ling Yang,Hao Luo,Fan Wang,Hongyan Li,Mengdi Wang", "background": "当前最先进的视频生成模型能够展示出潜力，但在处理研究论文时，它们受到上下文窗口有限、视频持续时间僵硬、风格多样性有限以及无法体现特定领域知识的限制。", "innovation": "Preacher 是首个用于论文转视频的自主系统，通过自上而下的方法分解、总结并重新制定论文，再通过自下而上的视频生成方式，将多样的视频片段综合成一个连贯的摘要。Preacher 定义关键场景并引入渐进链式思考（P-CoT）进行粒度迭代规划，有助于跨模态表示的对齐。", "conclusion": "Preacher 在五个研究领域成功生成高质量的视频摘要，显示出超越现有视频生成模型的专业知识。代码将会发布在指定链接。"}
{"llm_update_time": "20250815", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.09584", "html_url": "https://arxiv.org/abs/2508.09584", "title": "SHALE: 一种用于LVLMs细粒度hallucination评估的大规模基准", "title_en": "SHALE: A Scalable Benchmark for Fine-grained Hallucination Evaluation in LVLMs", "authors": "Bei Yan,Zhiyuan Chen,Yuecong Min,Jie Zhang,Jiahao Wang,Xiaozhen Wang,Shiguang Shan", "background": "尽管大型视觉-语言模型（LVLMs）取得了 rapid advances，但仍存在hallucinations问题，即生成与输入或世界知识不一致的内容。这分为忠实性和事实性 hallucinations。先前的研究主要在粗略的层次（如对象级别）上评估忠实性 hallucinations，缺乏细致分析。现有的基准通常依赖于昂贵的手动筛选或重用公共数据集，这引起了关于可扩展性和数据泄露的担忧。", "innovation": "我们提出了一种自动化的数据构建流程，生产可扩展、可控且多样的评估数据。设计了分级hallucination诱导框架，利用输入扰动模拟现实的嘈杂场景。通过这些设计，构建了SHALE，一种大规模的事实性和忠实性 hallucinations评估基准，基于精细的 hallucination分类方案。它涵盖了超过30,000张图像-指令对，考虑了真实的和嘈杂的场景，分布于12种代表性的视觉感知方面和6个知识领域。", "conclusion": "广泛的实验表明，主流LVLMs存在显著的事实hallucinations和语义扰动的高度敏感性。这揭示了LVLMs在评估hallucinations方面存在的问题，并展示了SHALE的有效性。"}
{"llm_update_time": "20250815", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.09560", "html_url": "https://arxiv.org/abs/2508.09560", "title": "WeatherPrompt: 多模态表示学习以实现全天候无人机视觉地理定位", "title_en": "WeatherPrompt: Multi-modality Representation Learning for All-Weather Drone Visual Geo-Localization", "authors": "Jiahao Wen,Hang Yu,Zhedong Zheng", "background": "现有无人机视觉地理定位方法在恶劣天气如雨、雾等条件下效果显著退化，主要由于对有限天气类别的依赖和特征分离不充分的问题。论文指出现有方法在泛化以及特性分离方面存在局限，特别是在处理复杂或未见过的天气条件时表现不佳。现有方法倾向于通过伪天气类别进行特性分离，但这些类别限制了模型的通用性，且不能很好地分离场景与天气特征。", "innovation": "本文提出了一种名为WeatherPrompt的多模态学习框架，通过融合图像嵌入与文本上下文来建立天气不变的表示。该框架主要贡献有两个：一是训练框架中的一个无需训练的天气推理机制，利用现成的大型多模态模型生成人类类似的多天气文本描述，增强对未见过或复杂天气的鲁棒性，并能反映不同强度的天气。二是提出了一种多模态框架，该框架由文本嵌入驱动的动态门控机制调控，自适应地重新加权并融合跨模态的视觉特征，从而更好地分离场景和天气特性。该框架通过跨模态目标，如图像-文本对比学习和匹配学习进行优化，将具有不同天气条件的同一场景映射到表示空间中的较近位置。实验结果表明，在各种天气条件下，该方法相比现有最先进的无人机地理定位方法具有竞争力的表现，特别是在夜间和雾、雪等特殊天气条件下，精确率分别提升了13.37%和18.69%。", "conclusion": "通过多模态学习和融合图像、文本嵌入来建立天气不变性表示的WeatherPrompt方法，在传统视觉地理定位挑战下，尤其是在天气恶劣条件下，具有明显优势。它有效的解决了已有解决方案在复杂或未知天气下的局限性，证明了该方法在统计和特定天气环境下的通用性和鲁棒性。"}
{"llm_update_time": "20250815", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2111.04578", "html_url": "https://arxiv.org/abs/2111.04578", "title": "改进神经网络迁移学习中正则化与鲁棒性", "title_en": "Improved Regularization and Robustness for Fine-tuning in Neural Networks", "authors": "Dongyue Li,Hongyang R. Zhang", "background": "转移学习中常用的算法是微调，即使用较小的带标签数据集对预训练模型进行微调。当预训练模型的容量远大于目标数据集的规模时，微调容易导致过拟合和记忆训练标签的问题。因此，一个关键问题是如何正则化微调，以确保其对噪声的鲁棒性。", "innovation": "该研究提出了利用PAC-Bayes泛化边界的分析方法，该边界依赖于每层中距离的旅行和微调模型的噪声稳定性。基于此分析，提出了正则化自我标签方法，包括逐层正则化约束每层距离，以及自我标签修正和标签加权方法来修正模型自信的错误标签并重新加权不太自信的数据点。", "conclusion": "该方法在多个预训练模型架构下对图像和文本数据集进行了验证，平均提高了七种图像分类任务的基线方法1.76%，对少样本分类任务提高了0.75%。当目标数据集包含噪声标签时，在两种噪声设置下的表现平均优于基线方法3.56%。"}
{"llm_update_time": "20250815", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2408.08555", "html_url": "https://arxiv.org/abs/2408.08555", "title": "使用罗sette扫描模式LiDAR检测和追踪MAVs", "title_en": "Detection and Tracking of MAVs Using a Rosette Scanning Pattern LiDAR", "authors": "Sándor Gazdag,Tom Möller,Anita Keszler,András L. Majdik", "background": "近年来商用微型空中车辆（MAVs）的使用量激增，这对社会产生了积极影响，但也带来了诸如侵入空域和侵犯隐私等风险。由于安全风险的增加，开发自动无人机检测和追踪系统已成为优先事项。", "innovation": "本研究采用非重复罗sette扫描模式激光测距仪（LiDAR），通过利用传感器的特点来提高检测距离。提出了结合速度分量的粒子滤波方法，以实现无人机的检测和追踪，并具有重新检测能力。利用固定对讲平台，让追踪对象保持在点测量最密集的位置，以利用罗sette扫描模式LiDAR的特定特性。在室内试验中验证了系统的检测能力和准确性，并在室外试验中展示了最大检测距离。", "conclusion": "该方法在室内实验中达到了与最先进的方法相当的准确性，而在室外实验中实现了约80%的更远最大检测范围，超过了最先进的室外方法。"}
{"llm_update_time": "20250815", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.09524", "html_url": "https://arxiv.org/abs/2508.09524", "title": "SOI是万恶之源：量化并打破单目标跟踪中的相似对象干扰", "title_en": "SOI is the Root of All Evil: Quantifying and Breaking Similar Object Interference in Single Object Tracking", "authors": "Yipei Wang,Shiyu Hu,Shukun Jia,Panxi Xu,Hongfei Ma,Yiping Ma,Jing Zhang,Xiaobo Lu,Xin Zhao", "background": "本文对长期被忽视但至关重要的单目标跟踪(Single Object Tracking, SOT)中的相似对象干扰(Similar Object Interference, SOI)进行了第一次系统性的研究和量化。通过受控的在线干扰掩蔽(Online Interference Masking, OIM)实验，我们量化证明了消除干扰源可以显著提高所有领先(SOTA)跟踪器的性能（AUC提高4.35%），直接验证了SOI是鲁棒跟踪的主要约束，并强调了外部认知引导的可行性。基于这些洞见，我们采用自然语言作为一种实际的外部引导形式，并构建了SOIBench——第一个专门针对SOI挑战的语义认知引导基准。", "innovation": "本文提出了将大规模视觉语言模型(Vision-Language Models, VLM)作为外部认知引擎的新范式，可以无缝集成到任意RGB跟踪器中，并在语义认知引导下表现出显著的改进（AUC提升高达0.93%），这代表了对现有视觉语言跟踪(Visual-Language Tracking, VLT)方法的重要突破。该研究还构建了SOIBench，这是一个自动挖掘SOI帧并通过多层次标注协议生成精确定义的语义指导文本的基准，旨在为语义认知跟踪研究设立标准化评估平台，贡献新的研究见解给跟踪研究社区。", "conclusion": "本文揭示了视觉语言跟踪(VLT)方法在利用语义认知引导方面仅取得边际改进甚至性能下降（AUC变化范围为-0.26至+0.71）的显著结果。相比之下，该思路展示了显著的改进潜力，为语义认知跟踪领域提出了新的视角，可能会引导未来的相关研究方向。同时，SOIBench被期望成为一个标准化的评估平台，推动语义认知跟踪研究的进步。"}
{"llm_update_time": "20250815", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2401.00873", "html_url": "https://arxiv.org/abs/2401.00873", "title": "统一自监督聚类和基于能量的模型", "title_en": "Unifying Self-Supervised Clustering and Energy-Based Models", "authors": "Emanuele Sansone,Robin Manhaeve", "background": "自监督学习擅长从大量数据中学习表示，而生成模型则通过学习数据生成过程中的相关信息提供了补充的特性。研究者希望将这两种范式建立为一个原则性的联系，并强调它们的互补性带来的益处。对自监督学习目标进行了分析，解释了潜在的概率图模型，并提出了从基本原则推导出标准方法。分析建议了一种自然的方式将自监督学习与基于似然的生成模型整合。", "innovation": "研究提出了一种在基于集群的自监督学习和能量模型领域实现自监督学习与基于似然的生成模型整合的概念，引入了一个可靠惩罚最重要意义失败模式的下界。通过合成和真实世界的数据（如SVHN、CIFAR10、CIFAR100）实验，验证了理论发现，表明新的目标函数可以同时训练判别和生成的方式，其性能显著优于现有的自监督学习策略。进一步展示了该解决方案可以集成到神经符号框架中解决简单而复杂的符号接地问题。", "conclusion": "实验结果表明，新的目标函数允许同时以判别和生成的方式训练主干网络，在聚类、生成和异常检测性能方面显著优于现有的自监督学习策略。还将解决方案集成到了神经符号框架中，解决了一个简单而复杂的符号接地问题。"}
{"llm_update_time": "20250815", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2412.02012", "html_url": "https://arxiv.org/abs/2412.02012", "title": "INSIGHT：解释性弱监督医学图像分析", "title_en": "INSIGHT: Explainable Weakly-Supervised Medical Image Analysis", "authors": "Wenbo Zhang,Junyu Chen,Christopher Kanan", "background": "由于其庞大的尺寸，体积扫描和全切片病理图像（WSIs）通常通过从局部区域提取嵌入并由聚合器进行预测来处理。然而，当前方法需要使用后处理可视化技术（例如Grad-CAM），并且往往无法定位那些虽小但在临床上至关重要的细节。", "innovation": "引入了INSIGHT，一种新颖的弱监督聚合器，整合了热图生成作为诱导偏差。该方法从预训练特征图开始，采用具有小卷积核的检测模块捕捉细节点，并使用具有更广泛感受野的上下文模块抑制局部假阳性。生成的内部热图突显出诊断相关的区域。", "conclusion": "INSIGHT在CT和WSI基准上实现了最先进的分类结果和高弱监督语义分割性能。"}
{"llm_update_time": "20250815", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2409.07275", "html_url": "https://arxiv.org/abs/2409.07275", "title": "通过隐式正则化实现无需调参的在线鲁棒主成分分析", "title_en": "Tuning-Free Online Robust Principal Component Analysis through Implicit Regularization", "authors": "Lakshmi Jayalal,Gokularam Muthukrishnan,Sheetal Kalyani", "background": "标准的在线鲁棒主成分分析（OR-PCA）技术的表现取决于显式正则化参数的最优调整，而该参数依赖于具体的数据集。为了克服这一依赖性，本文提出了一种使用隐式正则化的方法，通过不同版本的修改梯度下降方法自然地促进数据的稀疏性和低秩结构，从而实现无需调参的OR-PCA.", "innovation": "本文通过引入三种不同版本的修改梯度下降方法，利用隐式正则化效应，实现了对于不同数据集的OR-PCA算法的无调参版本。这种方法在模拟和实际数据集中表现与调优的OR-PCA相当甚至更好，并且对于大规模数据集更加具有扩展性，不需要依赖于特定数据集的参数调整.", "conclusion": "无需调参的在线鲁棒主成分分析方法通过隐式正则化技术有效地简化了OR-PCA参数的选择过程，提升了算法在大规模数据集上的应用可能性。"}
{"llm_update_time": "20250815", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.09626", "html_url": "https://arxiv.org/abs/2508.09626", "title": "Semantics-aware DropSplat: 自适应删除多余高斯点以实现3D航拍场景分割", "title_en": "Semantic-aware DropSplat: Adaptive Pruning of Redundant Gaussians for 3D Aerial-View Segmentation", "authors": "Xu Tang,Junan Jia,Yijing Wang,Jingjing Ma,Xiangrong Zhang", "background": "在3D航拍视图场景语义分割（3D-AVS-SS）任务中，传统方法由于空中图像中尺度变化和结构遮挡导致的语义模糊而难以应对。这限制了它们的分割精度和一致性。为解决上述挑战，我们提出了一种名为SAD-Splat的新方法。SAD-Splat方法引入了一个高斯点丢弃模块，该模块基于Hard Concrete分布结合了语义置信度估计和可学习的稀疏机制，有效消除了冗余和语义模糊的高斯点，提高了分割性能和表示紧凑性。此外，SAD-Splat还引入了一个高置信度伪标签生成管道，利用2D基础模型增强监督，从而进一步提高分割精度。为了推动该领域研究，我们还引入了一个具有稀疏注释多样真实场景数据集：3D Aerial Semantic (3D-AS)。实验结果表明，SAD-Splat在分割精度和表示紧凑性之间取得了良好的平衡，提供了一种高效的、可扩展的3D航拍场景理解解决方案。", "innovation": "提出了SAD-Splat方法，结合了语义置信度估计和可学习的稀疏机制（基于Hard Concrete分布）的高斯点丢弃模块，有效消除了冗余和语义模糊的高斯点，提升了分割性能和表示紧凑性；引入了高置信度伪标签生成管道，增强了在有限真值标签情况下的监督；提出了3D Aerial Semantic (3D-AS)数据集，用于促进3D航拍场景语义分割的研究。", "conclusion": "实验结果表明，SAD-Splat在分割精度和表示紧凑性之间取得了良好的平衡，提供了一种高效的、可扩展的3D航拍场景理解解决方案。"}
{"llm_update_time": "20250815", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2503.06795", "html_url": "https://arxiv.org/abs/2503.06795", "title": "基于解剖代表性的假体的机器人超声引导下股动脉重建", "title_en": "Robotic Ultrasound-Guided Femoral Artery Reconstruction of Anatomically-Representative Phantoms", "authors": "Lidia Al-Zogbi,Deepak Raina,Vinciya Pandian,Thorsten Fleiter,Axel Krieger", "background": "股动脉访问对于许多临床程序至关重要，包括诊断性血管造影、治疗性导管操作和紧急干预等。尽管其重要性，但由于解剖变异、覆盖的脂肪组织以及需要精确的超声（US）引导，成功的血管访问仍然具有挑战性。针头放置错误可能导致严重并发症，因而限制了操作仅限于高度技能的临床医生在受控医院环境下的操作。虽然机器人系统在通过自主扫描和血管重建来应对这些挑战方面表现出潜力，但临床转化仍然有限，因为它们依赖于简化的人体解剖复杂的单一模型。", "innovation": "本文提出了一种针对双分支股动脉的自主机器人US扫描方法，并利用来自真实患者CT数据的人体解剖成像数据创建了五个血管假体进行验证。此外，还引入了一种专为血管成像设计的视频深度学习US分割网络，提高了3D动脉重建的准确性。提出的网络在新血管数据集上实现了89.21％的Dice分数和80.54％的交并比。重建的动脉中心线与真实CT数据相比，平均L2误差为0.91±0.70 mm，平均Hausdorff距离为4.36±1.11 mm。这项研究是首次在多种患者特定CT数据创建的解剖代表性假体上验证自主机器人系统用于US血管扫描的研究。", "conclusion": "该研究首次在多种患者特定CT数据创建的解剖代表性假体上验证了自主机器人系统用于US血管扫描，引入了评估在血管成像和干预方面机器人性能的新框架。"}
{"llm_update_time": "20250815", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2412.07676", "html_url": "https://arxiv.org/abs/2412.07676", "title": "Si/SiGe多量子点设备的启动、自主测试和初始化系统", "title_en": "Bootstrapping, Autonomous Testing, and Initialization System for Si/SiGe Multi-quantum Dot Devices", "authors": "Tyler J. Kovach,Daniel Schug,M. A. Wolfe,E. R. MacQuarrie,Patrick J. Walsh,Owen M. Eskandari,Jared Benson,Mark Friesen,M. A. Eriksson,Justyna P. Zwolak", "background": "半导体量子点(QD)设备在基于自旋的量子计算发展中起到了关键作用。然而，现代QD设备的复杂性使得在高温下进行校准和控制成为瓶颈，强调了需要鲁棒且可扩展的自主解决方案的必要性。氧化层中的陷阱电荷会诱导门电极的随机偏移电压，标准偏差约为83毫伏。高效的量子点（QD）量子比特表征和调谐依赖于自动协议的选择。因此，本文介绍了一种名为BATIS的物理直观框架，用于QD设备的启动、自主测试和初始化系统，以简化QD设备评估和校准。", "innovation": "BATIS引入了一种新的非标准方法来形成电流通道，只需要一组测量，不论通道数量多少。在1.3开尔文的温度下，BATIS在Si/Si_xGe_(1-x)设备上展示了无需深冷环境即可进行初始设备诊断的能力，从而显著提高了可扩展性并减少了设置时间。此外，BATIS只需要很少的先验设备架构知识，是一种平台无关的解决方案，适用于各种QD系统，填补了QD自动调谐的关键空白。", "conclusion": "BATIS通过自动化诸如漏电流测试、形成所有电流通道和在陷阱电荷存在的条件下进行门电极表征等关键步骤，提供了一种有效的解决方法，简化了QD设备的评估和校准流程，从而增强其可扩展性并在低温环境下实现快速初始化，对各种QD系统的设备调谐具有重要意义。"}
{"llm_update_time": "20250815", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2504.06866", "html_url": "https://arxiv.org/abs/2504.06866", "title": "GraspClutter6D：具有丰富真实场景抓取数据的大型6D感知和抓取数据集", "title_en": "GraspClutter6D: A Large-scale Real-world Dataset for Robust Perception and Grasping in Cluttered Scenes", "authors": "Seunghyeok Back,Joosoon Lee,Kangmin Kim,Heeseon Rho,Geonhyup Lee,Raeyoung Kang,Sangbeom Lee,Sangjun Noh,Youngjin Lee,Taeyeop Lee,Kyoobin Lee", "background": "在机器人领域，复杂环境下的稳健抓取仍然是一个公开的挑战。现有的基准数据集虽然显著提升了深度学习方法，但主要关注视野简单的场景，且缺乏多样性和遮挡，这些限制了其在实际场景中的应用。针对这一问题，该研究提出了一套名为GraspClutter6D的大规模真实世界抓取数据集，旨在提供更多的训练数据以促进复杂环境下的感知和抓取技术的发展。", "innovation": "GraspClutter6D数据集的创新之处在于它包含1,000个高度拥挤的场景，其中包括14.1个物体/场景且62.6％的遮挡，并且使用了多种视角下的四台RGB-D摄像机拍摄了200个物体在75种环境配置（包括箱子、架子和桌子）下的详细场景。此外，该数据集还包括了736万种6D物体姿态和52,000个RGB-D图像上可行抓取方式的丰富注释。通过基准测试最先进的分割、物体姿态估计和抓取检测方法，数据集展示了其对于复杂环境感知和抓取的独特价值，特别是在模拟和真实实验中的表现明显优于现有数据集中的训练模型。", "conclusion": "进一步实验证明，使用GraspClutter6D进行训练的抓取网络，在模拟环境和真实实验中均显著优于使用现有数据集训练的模型。该数据集、工具包和标注工具已在项目网站上公开。"}
{"llm_update_time": "20250815", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.03221", "html_url": "https://arxiv.org/abs/2508.03221", "title": "BadBlocks：针对文本生成图像扩散模型的低成本和隐蔽后门攻击", "title_en": "BadBlocks: Low-Cost and Stealthy Backdoor Attacks Tailored for Text-to-Image Diffusion Models", "authors": "Yu Pan,Jiahao Chen,Lin Wang,Bingrong Dai,Yi Du", "background": "近年来，扩散模型在图像生成领域取得了显著进展。然而，研究表明扩散模型容易遭受后门攻击，攻击者可以通过在训练数据集中注入隐蔽触发器（如特定视觉模式或文本短语）来操纵输出。尽管防御技术不断进步，使得检测和缓解大多数后门攻击变得更加容易，但现有方法仍存在不足。本文发现了一种新的后门威胁BadBlocks，该威胁不但更隐秘且所需的计算资源和时间均显著减少。BadBlocks能够在不破坏扩散模型其他功能的情况下，精准污染UNet架构中的特定部分，并且即使在极其有限的计算资源和GPU时间的条件下也能成功发动攻击且保持较低的感知质量损失。此外，BadBlocks已经能够绕过现有防御框架，特别是基于注意力机制的后门检测方法，这表明它代表了一种新颖且值得关注的威胁类型。实验证明BadBlocks在所有方面都大大降低了后门攻击的门槛，即使使用消费级显卡也可以向大型扩散模型中注入后门。", "innovation": "提出了BadBlocks，这是一种新型后门威胁，相对于先前的方法，它更加隐秘且资源消耗更低；能够在保持扩散模型正常功能的同时，精准污染UNet架构中的特定部分；即使在资源极其受限的情况下也能成功发动攻击并保持较低的感知质量损失；BadBlocks能够绕过现有防御框架，尤其能够规避基于注意力机制的后门检测方法，揭示了某些神经网络层在后门映射中的关键作用；BadBlocks大大降低了发动后门攻击的门槛，哪怕是使用消费级GPU也能向大型扩散模型中注入后门。", "conclusion": "本文发现并分析了一种名为BadBlocks的新颖且隐秘的后门攻击方法，能够在资源受限的情况下成功注入后门，并可有效规避现有防御策略。BadBlocks对于了解和防御扩散模型中的后门攻击具有重要价值。"}
{"llm_update_time": "20250815", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.09123", "html_url": "https://arxiv.org/abs/2508.09123", "title": "OpenCUA: 开放的计算机使用代理基础框架", "title_en": "OpenCUA: Open Foundations for Computer-Use Agents", "authors": "Xinyuan Wang,Bowen Wang,Dunjie Lu,Junlin Yang,Tianbao Xie,Junli Wang,Jiaqi Deng,Xiaole Guo,Yiheng Xu,Chen Henry Wu,Zhennan Shen,Zhuokai Li,Ryan Li,Xiaochuan Li,Junda Chen,Boyuan Zheng,Peihang Li,Fangyu Lei,Ruisheng Cao,Yeqiao Fu,Dongchan Shin,Martin Shin,Jiarui Hu,Yuyan Wang,Jixuan Chen,Yuxiao Ye,Danyang Zhang,Dikang Du,Hao Hu,Huarong Chen,Zaida Zhou,Haotian Yao,Ziwei Chen,Qizheng Gu,Yipu Wang,Heng Wang,Diyi Yang,Victor Zhong,Flood Sung,Y.Charles,Zhilin Yang,Tao Yu", "background": "视觉-语言模型已经展示了作为计算机使用代理（CUAs）的出色能力，能够自动化多种计算机任务。随着它们的商业潜力增长，最强大CUA系统的关键细节依然保密。随着这些代理将越来越多地调节数字互动并替我们做出重要决定，研究社区需要访问开放的CUA框架来研究它们的能力、局限性和风险。", "innovation": "提出了OpenCUA，一个全面开放的源代码框架，用于扩展CUA数据和基础模型。该框架包括:(1)一种无缝捕获人类计算机使用演示的注释基础设施；(2) AgentNet，首个覆盖3个操作系统和200多个应用程序及网站的大型计算机使用任务数据集；(3)一个可扩展的管道，将演示转化为状态-行动对，具有反射性长Chain-of-Thought推理，数据规模扩大时可维持稳健的性能提升。通过端到端代理模型展示了在CUA基准测试中表现出色。特别地，OpenCUA-32B在OSWorld-Verified上的平均成功率达到了34.8%，成为开源模型中的新SOTA，并超越了OpenAI CUA (GPT-4o)。进一步分析表明该方法在不同领域具有良好的泛化能力和对测试时计算量增加具有显著的益处。", "conclusion": "我们发布了注释工具、数据集、代码和模型，以构建进一步CUA研究的基础框架。"}
{"llm_update_time": "20250815", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.10111", "html_url": "https://arxiv.org/abs/2508.10111", "title": "使用上下文自由文法的扩散大语言模型约束解码", "title_en": "Constrained Decoding of Diffusion LLMs with Context-Free Grammars", "authors": "Niels Mündler,Jasper Dekoninck,Martin Vechev", "background": "大语言模型（LLMs）已经在多个领域展现了良好的性能。许多实际应用依赖于LLMs，例如代码补全和结构化数据提取，这些应用要求输出遵守由形式语言规定的句法约束。然而，由于LLMs的性质是概率性的，LLMs的输出无法保证遵循这些形式语言。现有研究试图通过约束解码来限制LLMs生成特定形式语言的内容，但这些方法不适用于扩散LLMs。特别是在生成正确的形式语言输出，如正确的C++代码或JSON时，这些方法并不适用。因此，本文旨在解决这一问题，并首次提出了适用于扩散模型的约束解码方法，该方法能够处理由上下文自由语法规则捕获的形式语言。", "innovation": "本文将约束解码问题归约为更一般的加性填充问题，并进一步归约为确定目标语言与正则语言交集是否为空的问题。提出了高效的算法来解决这个针对上下文自由语言的问题。该方法应用于C++代码填充和JSON结构化数据提取等多个应用领域，结果显示本文方法实现了近乎完美的句法正确性，同时保持或提升了功能正确性。最重要的是，本文的效率优化确保了计算成本的可行性。", "conclusion": "本文方法通过对目标语言和正则语言交集是否为空的问题进行解决，有效地实现了扩散LLMs在实际应用中对形式语言生成的约束。这种方法在多个实际应用中的表现证明了其在句法和功能正确性上的优势，同时也保证了在计算上的可行性。"}
{"llm_update_time": "20250815", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.10115", "html_url": "https://arxiv.org/abs/2508.10115", "title": "仅使用大型语言模型学习图任务", "title_en": "Less is More: Learning Graph Tasks with Just LLMs", "authors": "Sola Shirai,Kavitha Srinivas,Julian Dolby,Michael Katz,Horst Samulowitz,Shirin Sohrabi", "background": "对于大型语言模型（LLMs），通过图推理可以解决许多问题。之前的尝试集中在将图序列化为文本以及将GNNs和LLMs结合以改善LLM的图推理能力，但这些方法的优劣仍未明确。因此，研究者通过实证方法回答了三个问题：是否小型LLMs可以通过使用指导性的链式思维解决方案训练来学习图任务？LLMs是否能够将学到的解决方案应用于未见的图结构或任务？各种学习图任务的方法的优劣是什么？", "innovation": "研究表明，即使是小型LLMs也可以通过使用指导性的链式思维解决方案训练来学习图任务，并且这种训练能够泛化到新的任务和图结构上，而不需要专门的图编码器。这种方法简化了图任务的学习过程，提高了其在未见图结构和任务上的泛化能力，为大型语言模型在图推理任务中的应用提供了新的途径和思路。", "conclusion": "研究发现小型LLMs通过指导性的链式思维训练可以学习解决图任务，且这种训练能够泛化到新任务和图结构上，证明了不需要专门的图编码模型，LLMs本身也能有效地完成图任务的学习和泛化。"}
{"llm_update_time": "20250815", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.10063", "html_url": "https://arxiv.org/abs/2508.10063", "title": "衡量时间序列预测稳定性以用于需求计划", "title_en": "Measuring Time Series Forecast Stability for Demand Planning", "authors": "Steven Klee,Yuntian Xia", "background": "时间序列预测是生成供应链需求计划的关键第一步。尽管提高预测准确性是实验中的重点，但是生产系统中的需求规划人员更看重预测的一致性和稳定性。当输入数据没有显著变化时，预测结果如果在不同规划周期之间差异很大，这会导致高度的人工干预，令需求规划人员感到沮丧，并可能导致他们对机器学习预测模型失去信任。本文探索模型引入的随机性，衡量单个模型在输入固定的情况下产生的预测集合的方差。方差较低的模型更加稳定。最近，时间序列预测社区通过开发深度机器学习模型显著提高了预测准确性。这项研究通过测量最先进的预测模型（Chronos、DeepAR、PatchTST、Temporal Fusion Transformer、TiDE、AutoGluon最佳质量混洗模型）在M5比赛和Favorita杂货销售公共数据集上的稳定性和准确性，展示了集成模型提升了模型的稳定性，而没有显著降低或甚至提高了预测准确性。尽管这些结果可能并不令人意外，但本文的主要论点是提出对部署在生产系统的模型进一步研究需求稳定性的重要性，以确保它们在长期使用中的稳定性和可持续性.", "innovation": "这项研究通过测量最先进的预测模型在公开数据集上的稳定性和准确性，展示了集成模型提高了模型的稳定性，而没有显著降低或甚至提高了预测准确性。这表明集成模型不仅在提高预测准确性方面有优势，而且在提高模型稳定性方面也具有潜力，这可能是一个值得进一步探索的研究领域。研究还提出，对部署在实际生产系统中的模型进行更深入的需求稳定性研究是非常必要的，以确保模型的长期有效性和可靠性.", "conclusion": "研究结果表明，集成模型能够同时提高预测稳定性和准确性，这为实际生产系统的需求规划提供了一种新的思路。然而，模型的稳定性仍然是一个需要进一步探讨的领域，特别是在实际生产环境中，不同的时间序列预测模型在长期稳定性上的差异仍需更多研究。"}
{"llm_update_time": "20250815", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.10060", "html_url": "https://arxiv.org/abs/2508.10060", "title": "使用强化学习的个性化运动助手（PEARL）：四组随机对照试验的结果", "title_en": "A Personalized Exercise Assistant using Reinforcement Learning (PEARL): Results from a four-arm Randomized-controlled Trial", "authors": "Amy Armento Lee,Narayan Hegde,Nina Deliu,Emily Rosenzweig,Arun Suggala,Sriram Lakshminarasimhan,Qian He,John Hernandez,Martin Seneviratne,Rahul Singh,Pradnesh Kalkar,Karthikeyan Shanmugam,Aravindan Raghuveer,Abhimanyu Singh,My Nguyen,James Taylor,Jatin Alla,Sofia S. Villar,Hulya Emir-Farinas", "background": "全球范围内持续的身体活动不足是一个重大的健康挑战。移动健康（mHealth）干预措施，尤其是即时适配干预（JITAIs），为大规模、个性化地促进体力活动（PA）提供了有前景的方法。然而，开发和评估此类大规模干预措施，同时融入坚实的健康行为学，面临着方法学上的困难。", "innovation": "PEARL研究是首个大规模的四组随机对照试验，评估了基于强化学习（RL）算法的个性化体力活动（PA）提醒的效果，该算法受到健康行为改变理论的指导。这项研究通过Fitbit应用程序个性化地提供体力活动提醒。", "conclusion": "实验结果显示，与对照组和其他组相比，使用基于强化学习的个性化提醒组在1个月和2个月时体力活动有所增加。这表明，基于行为学的强化学习方法具有潜在的有效性和可扩展性，可用于个性化数字健康干预措施以促进体力活动。"}
{"llm_update_time": "20250815", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.10154", "html_url": "https://arxiv.org/abs/2508.10154", "title": "EM算法在过度指定混合线性回归期望最大化估计中的演变特征", "title_en": "Characterizing Evolution in Expectation-Maximization Estimates for Overspecified Mixed Linear Regression", "authors": "Zhankun Luo,Abolfazl Hashemi", "background": "混合模型由于其实用效果和全面的理论基础而受到极大关注。然而，在模型错指定的情况下（即模型拟合的混合成分多于实际数据分布中的），仍存在持续的技术挑战。本文专注于探讨期望最大化（EM）算法在过度指定的两组分混合线性回归模型中的行为，特别是参数估计和混合权重的错误假设对收敛性的影响。", "innovation": "本文揭示了在模型错指定的情况下，EM算法在两组分混合线性回归中的收敛性特征和统计准确性。特别是，通过不均衡的初始混合权重，能够实现线性收敛且在对数步数后达到$\frac{1}{\tau}$精度。而通过均衡初始混合权重，可以观测到次线性收敛且达到$\tau^{-2}$步数后达到$\frac{1}{\tau}$精度。作者进一步分分析了理论结果在样本规模有限情况下的统计准确性，并直观推导出在不同初始条件下EM算法的迭代复杂度边界。同时，研究还将这些分析延伸到信噪比较低的情况。", "conclusion": "研究结果表明，在过度指定的两组分混合线性回归模型中，通过合理设置初始混合权重，可以有效提升EM算法的收敛性能和统计准确性。"}
{"llm_update_time": "20250815", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.10147", "html_url": "https://arxiv.org/abs/2508.10147", "title": "rETF-semiSL: 半监督学习中的时序数据神经坍缩现象", "title_en": "rETF-semiSL: Semi-Supervised Learning for Neural Collapse in Temporal Data", "authors": "Yuhan Xie,William Cappelletti,Mahsa Shoaran,Pascal Frossard", "background": "深度神经网络在时序数据中必须捕捉复杂的动态模式，以有效表示动态数据。自我监督和半自我监督学习方法在预训练大型模型方面显示出有前途的结果，在经过微调分类后，这些方法通常比从零开始训练的模型表现更好。尽管如此，预训练任务的选择往往是凭经验的，下游分类的可转移性并不保证。因此，本文提出了一种新的半监督预训练策略，以强制满足最优训练神经分类器中观察到的神经坍缩现象。我们采用旋转等角紧框架分类器和伪标签预训练深层编码器，使用少量标记样本。此外，为了有效地捕捉时间动态并强制约束嵌入的可分性，我们将生成式预训练任务与我们的方法结合，并定义了一种新的序列增强策略。我们显示，当应用于三种多变量时间序列分类数据集中的LSTMs、变换器和状态空间模型时，我们的方法显著优于先前的预训练任务。这些结果突显了使预训练目标与理论指导嵌入几何学相一致的好处。", "innovation": "提出了一种新的半监督预训练策略，使用旋转等角紧框架分类器和伪标签预训练深层编码器，并定义一种新的序列增强策略，用于有效捕捉时序动态同时强制约束嵌入的可分性。这种方法特别适用于LSTMs，变换器和状态空间模型，并显著提高了多项多变量时间序列分类数据集上的性能。", "conclusion": "我们的方法展示了显著优于先前预训练任务的能力，特别是在处理LSTMs，变换器和状态空间模型时的多变量时间序列分类数据集上。这些结果强调了使预训练目标与理论指导嵌入几何学相一致带来的好处。"}
{"llm_update_time": "20250815", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.10148", "html_url": "https://arxiv.org/abs/2508.10148", "title": "使用反事实距离进行离群检测", "title_en": "Out-of-Distribution Detection using Counterfactual Distance", "authors": "Maria Stoica,Francesco Leofante,Alessio Lomuscio", "background": "为了安全地使用机器学习系统，需要进行准确且可解释的离群检测（Out-of-Distribution, OOD）。先前的研究表明，特征距离决策边界可用于有效地识别离群数据。本文在这一思路基础上，提出了一种后处理的离群检测方法，该方法计算输入到决策边界的距离通过利用反事实解释。由于计算解释对于大型架构来说可能代价高昂，文中还介绍了在嵌入空间中直接计算反事实的策略来提高可扩展性。这种方法通过使用反事实解释，可以无缝地辅助解释检测器的结果。", "innovation": "1. 提出了一种利用反事实解释的后处理离群检测方法。\n2. 引入了直接在嵌入空间中计算反事实的策略以提高方法的可扩展性。\n3. 通过反事实解释无缝地解释检测器的结果，实现良好解释性。\n4. 在CIFAR-10、CIFAR-100和ImageNet-200等四个离群检测数据集上，所提出的方法均优于现有的方法，尤其是在CIFAR-100和ImageNet-200上表现突出，AUROC和FPR95均有显著改进。\n", "conclusion": "所提出的离群检测方法结合反事实距离实现了较好的检测精度和解释性，显著优于现有的方法，并在多个离群检测数据集上展示了最先进的性能，尤其是在大尺度数据集CIFAR-100和ImageNet-200上表现出色。"}
{"llm_update_time": "20250815", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.03184", "html_url": "https://arxiv.org/abs/2507.03184", "title": "EvRWKV: 一种有效的事件引导的低光照图像增强连续交互式RWKV框架", "title_en": "EvRWKV: A Continuous Interactive RWKV Framework for Effective Event-Guided Low-Light Image Enhancement", "authors": "Wenjie Cai,Qingguo Meng,Zhenyu Wang,Xingbo Dong,Zhe Jin", "background": "在低光照条件下捕捉高质量的视觉内容仍然是一个具有挑战性的问题，因为严重的噪声和曝光不足会降低下游应用的性能。传统的基于帧的低光照图像增强方法往往会导致噪声的放大或无法保存结构细节。事件相机通过异步捕捉亮度变化，具有高动态范围和微妙的时域分辨率，在低光照成像中展现出补充作用。然而，现有的融合方法未能充分利用这种互补性，在早期将模态强行转换到共享表示，或者通过独立处理丢失重要的低级相关性。", "innovation": "为了应对这些挑战，我们提出了一种新颖的EvRWKV框架，通过双域处理实现连续的跨模态互动。该框架结合了Cross-RWKV模块和EISFE模块，利用RWKV架构进行精细的时域和跨模态融合，以及联合执行自适应频域噪声抑制和空间域可变形卷积对齐的事件图像频谱融合增强器，这种连续的互动保持从低级纹理到高级语义的特征一致性。在现实世界低光照数据集（SDE、SDSD、RELED）上进行了广泛的定性和定量评估，该方法在增强图像质量、抑制噪声、恢复结构细节和提高视觉清晰度方面取得了最先进的性能。", "conclusion": "EvRWKV在多种现实世界低光照数据集上实现了最先进的性能，有效地增强了图像质量，抑制了噪声，恢复了结构细节，并在具有挑战性的低光照条件下改善了视觉清晰度。"}
{"llm_update_time": "20250815", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.10173", "html_url": "https://arxiv.org/abs/2508.10173", "title": "基于基准的选择AI：DeepSeek-R1 的证据", "title_en": "Benchmark-Driven Selection of AI: Evidence from DeepSeek-R1", "authors": "Petr Spelda,Vit Stritecky", "background": "在观察到推理语言模型能够在其完成任务之前结合其现有的能力产生新颖的中间步骤并有时帮助它们比过去的模型更好地泛化之后，对推理语言模型的能力评估变得尤为重要。随着推理成为大型语言模型扩展的新维度，对其进行关键任务能力的仔细研究变得必要。研究表明，测试时算法改进或模型大小的优化不是导致更好的性能的唯一因素，使用具有影响力的基准进行学习的选择也会产生明显的影响。", "innovation": "本文提出了一种被称为基准驱动选择AI的方法，并通过使用来自《人类最后一次考试》的问题来研究其对DeepSeek-R1的影响。这种方法通过将具有影响力的基准用作训练课程，而不是未知的测试集，改变了评估和学习的关系，强调了对推理模型泛化能力的测试任务的新颖性。", "conclusion": "某些基准可以作为一种培训课程，而不是未知的测试集，通过这种方式，可以更好地评估和学习推理模型的泛化能力。这种做法使得测试任务的独特性和新颖性成为衡量推理模型泛化能力的关键因素。"}
{"llm_update_time": "20250815", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.09992", "html_url": "https://arxiv.org/abs/2508.09992", "title": "OpenFPL: 一个开源的竞赛排名预测方法，与最先进的 Fantasy Premier League 服务相媲美", "title_en": "OpenFPL: An open-source forecasting method rivaling state-of-the-art Fantasy Premier League services", "authors": "Daniel Groos", "background": "Fantasy Premier League 是一项让足球社区参与其中的赛事，参与者通过预测每个比赛周的表现最佳的英超球员来选拔队员。准确的绩效预测可以帮助参与者比竞争对手更准确地预测球员的表现，从而降低阵容选择的不确定性。然而，目前高准确度的预测服务主要由商业公司提供，这些商密服务依赖于不公开的数据。这篇论文旨在通过介绍 OpenFPL，一种完全基于公开数据开发的开源 Fantasy Premier League 预测方法，来使高准确度的预测技术普及化。", "innovation": "OpenFPL 是一种新的开源预测方法，它通过比赛周的具体集合模型，并使用 Fantasy Premier League 和 Understat 这四年的公开数据（2020-21 至 2023-24 季），实现了与顶级商业服务相媲美的准确度，特别是在高回报球员（超过 2 分）方面。OpenFPL 在 1 到 3 个比赛周的预测中都表现良好，支持长期转会和策略规划，同时也为最终决策提供了指导。", "conclusion": "OpenFPL 证明了在 Fantasy Premier League 中使用公开数据可以实现与商业服务媲美的准确度。这种方法不仅适用于短期和中期预测，还能支持长期的转会和策略规划决策。这为选手们进入这个竞争激烈但数据丰富的环境提供了新的工具和机会。"}
{"llm_update_time": "20250815", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.10053", "html_url": "https://arxiv.org/abs/2508.10053", "title": "xRFM: 准确、可扩展且具备解释性的表型数据特征学习模型", "title_en": "xRFM: Accurate, scalable, and interpretable feature learning models for tabular data", "authors": "Daniel Beaglehole,David Holzmüller,Adityanarayanan Radhakrishnan,Mikhail Belkin", "background": "表型数据是现代技术和科学的基础，尽管人工智能领域的其他方面经历了快速的发展变化，但用于预测任务的最佳实践并未发生显著变化，且仍然主要基于梯度提升决策树（GBDTs）。近年来，基于神经网络和特征学习方法的进步，重新引起了对表型数据方法的兴趣。", "innovation": "该研究引入了xRFM算法，结合了特征学习核机和树结构，以适应数据的局部结构并可扩展至几乎无限的训练数据量。实验显示，xRFM在100个回归数据集中表现最佳，且在200个分类数据集中与最佳方法竞争，并优于GBDTs。此外，xRFM通过平均梯度外积提供了内置的解释性。", "conclusion": "xRFM通过结合特征学习核机和树结构，在表型数据预测中提供了准确性、可扩展性和内置解释性。"}
{"llm_update_time": "20250815", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.10219", "html_url": "https://arxiv.org/abs/2508.10219", "title": "基于AI的走私象牙上的手写文字检测与分析：揭露非法野生动物贸易犯罪网络的工具", "title_en": "AI-Driven Detection and Analysis of Handwriting on Seized Ivory: A Tool to Uncover Criminal Networks in the Illicit Wildlife Trade", "authors": "Will Fein,Ryan J. Horwitz,John E. Brown III,Amit Misra,Felipe Oviedo,Kevin White,Juan M. Lavista Ferres,Samuel K. Wasser", "background": "全球象牙贸易依然在对非洲大象种群造成威胁，尽管执法部门缴获的象牙中携带着关于走私人员的重要信息，如DNA证据和手写标记，这些信息的获取和分析却存在困难。DNA分析能够确定盗猎地点并连接不同批次的象牙运输，虽然遗传证据十分具有说服力，但手续较为繁琐且成本高昂。相比之下，手写标记易于拍照但很少被记录和分析。本文通过建立一种基于AI的手写标记提取与分析流程，为破解走私网络提供了新的低成本且有效的证据来源，从而填补了其他数据源的不足。", "innovation": "本文提出的AI驱动的象牙手写标记提取与分析系统，利用AI工具自动化提取和标记识别象牙上手写标记，通过判断这些标记的重复性识别同一走私团伙，实现了低成本且大规模的走私线索链接。", "conclusion": "本研究展示了AI在野生动物法证分析领域的巨大潜力，并强调了将手写分析融入打击有组织的野生动物犯罪的努力中的实用步骤，这不仅补充和完善了现有的调查技术，还为打击非法野生动物贸易提供了新的可能路径。"}
{"llm_update_time": "20250815", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.10233", "html_url": "https://arxiv.org/abs/2508.10233", "title": "在晚期肝硬化重症患者中早期预测急性肾损伤的可解释机器学习模型：一项回顾性研究", "title_en": "Interpretable Machine Learning Model for Early Prediction of Acute Kidney Injury in Critically Ill Patients with Cirrhosis: A Retrospective Study", "authors": "Li Sun,Shuheng Chen,Junyi Fan,Yong Si,Minoo Ahmadi,Elham Pishgar,Kamiar Alaei,Maryam Pishgar", "background": "肝硬化是一种慢性进行性肝脏疾病，具有高死亡率和频繁并发症，其中急性肾损伤（AKI）是一个显著的问题，多达50%的住院患者会出现AKI，这会进一步恶化患者的结果。AKI通常来源于复杂的血流动力学、炎症和代谢变化，因此早期检测至关重要。现有的预测工具缺乏准确性、解释性和与重症监护病房（ICU）工作流程的适配性。因此，该研究旨在开发一种解释性机器学习模型来预测重症肝硬化患者的早期AKI。", "innovation": "本文研究开发了一种基于LightGBM的可解释机器学习模型，该模型能够使用常规的临床变量在ICU患者中准确地进行早期AKI风险分层。这个模型在AUC-ROC、准确性、F1分数、敏感性和特异性方面都表现优异，特别是其高阴性预测值支持了低风险患者的分级治疗，并且解释性有助于临床医生的信任并促进针对重点的预防措施。此外，该研究强调了需要外部验证并将模型整合到电子健康记录系统中。", "conclusion": "基于LightGBM的模型能够准确地对患有肝硬化的重症监护病房患者进行早期AKI风险评估，使用的是常规的临床变量。其高阴性预测值支持低风险患者的分级治疗，并且解释性增强了临床医生的信任，促进了目标预防。外部验证和整合到电子健康记录系统是需要进一步研究的方面。"}
{"llm_update_time": "20250815", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.10253", "html_url": "https://arxiv.org/abs/2508.10253", "title": "云原生集群中基于多代理强化学习的自适应资源编排", "title_en": "Multi-Agent Reinforcement Learning for Adaptive Resource Orchestration in Cloud-Native Clusters", "authors": "Guanzi Yao,Heyao Liu,Linyan Dai", "background": "本文探讨了云原生数据库系统中高资源动态性和调度复杂性所带来的挑战。提出了一种基于多代理强化学习的自适应资源 orchestration 方法，通过引入异构角色代理建模机制，使计算节点、存储节点和调度器能够采用不同的策略表示，从而更好地反映系统的多样性和局部环境特性。通过设计奖励重塑机制，将局部观察与全局反馈结合，以减轻由不完整状态观察引起的学习策略偏差。该方法结合实时的性能信号和全局系统的价值估计，提高了代理之间的协调性和策略收敛稳定性，并通过一个统一的多代理人训练框架在代表性生产调度数据集上进行了评估。实验结果表明，该方法在多个关键指标上优于传统方法，包括资源利用率、调度延迟、策略收敛速度、系统稳定性和公平性。这种新方法在不同类型实验场景中的有效性得到了证实，尤其是对于高并发、高维状态空间和复杂依赖关系的编排任务。", "innovation": "提出了一种基于多代理强化学习的自适应资源 orchestration 方法，引入了异构角色代理建模机制，通过奖励重塑机制整合了局部观察和全局反馈，提高了策略的收敛稳定性和任务协调能力。同时，开发了一统一的多代理人训练框架，并在实际生产环境中进行了验证，说明该方法在大型实际环境中的广泛适用性和实用性。", "conclusion": "本文提出的方法在资源利用率、调度延迟、策略收敛速度、系统稳定性和公平性等多个关键性能指标上均超过了传统的解决方案。通过引入异构角色代理和奖励重塑机制，方法具有较强的泛化能力和实际应用价值，在处理高并发、高维状态空间和复杂依赖关系的编排任务上表现出色，验证了其在实际大型集群调度环境中的有效性。"}
{"llm_update_time": "20250815", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.10243", "html_url": "https://arxiv.org/abs/2508.10243", "title": "Pruning and Malicious Injection: A Retraining-Free Backdoor Attack on Transformer Models", "title_en": "Pruning and Malicious Injection: A Retraining-Free Backdoor Attack on Transformer Models", "authors": "Taibiao Zhao,Mingxuan Sun,Hao Wang,Xiaobing Chen,Xiangwei Zhou", "background": "变压器模型在计算机视觉（CV）和自然语言处理（NLP）任务中展现出卓越的性能并变得不可或缺。然而，最近的研究表明，变压器模型容易遭受后门攻击。现有的后门攻击方法通常依赖于使用干净的数据重新训练或修改模型架构，这两种方法都可能消耗大量资源并且侵入性强。", "innovation": "本文提出了Head-wise Pruning and Malicious Injection（HPMI），这是一种无需重新训练的新型变压器后门攻击方法，也不更改模型架构。该方法仅需要少量原始数据以及对模型架构的基本了解，而不必重新训练目标变压器。技术上，HPMI通过修剪最不重要的头部并在其位置注入一个预训练的恶意头部来建立后门。此外，实验结果表明，HPMI在多个数据集上的表现证明了其优点，包括极小的干净准确性损失、高达99.55%的成功攻击率以及绕过四种高级防御机制的能力。相比依赖重新训练的现有攻击技术，HPMI更加隐蔽且能够抵抗多样的防御策略，同时对干净的准确性影响最小。", "conclusion": "HPMI对变压器模型的后门攻击不仅无需重新训练，还可以防止现代最先进的防御技术检测和破解植入的后门。HPMI的有效性通过多数据集的实验进一步得到验证，这一方法在几乎不影响干净准确性的前提下，能够实现高攻击成功率并避过了多种高级防御机制，显示出更强的隐蔽性和抗防御性。"}
{"llm_update_time": "20250815", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.10255", "html_url": "https://arxiv.org/abs/2508.10255", "title": "联邦个性化模型在多租户云平台中的异位检测", "title_en": "Federated Anomaly Detection for Multi-Tenant Cloud Platforms with Personalized Modeling", "authors": "Yuxi Wang,Heyao Liu,Nyutian Long,Guanzi Yao", "background": "本文提出了一种基于联邦学习的异常检测方法，旨在解决多租户云环境中的关键挑战，包括数据隐私泄露、异构资源行为以及集中建模的局限性。", "innovation": "本文创新点在于：1) 设计了涉及多个租户的联邦训练框架；2) 采用个性化参数调整机制以适应多样的资源使用模式；3) 使用马氏距离计算异常评分，提升异常检测的准确性和稳定性；4) 结果表明，该方法在精确度、召回率和F1分数等关键指标上优于现有主流模型，并能在复杂场景中保持稳定性能。", "conclusion": "实验结果表明，所提出的方法在云计算环境中具有智能资源监控和异常诊断的实际应用潜力。"}
{"llm_update_time": "20250815", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.10257", "html_url": "https://arxiv.org/abs/2508.10257", "title": "通过离线分解和在线混合方法实现源组件变换适应", "title_en": "Source Component Shift Adaptation via Offline Decomposition and Online Mixing Approach", "authors": "Ryuta Matsuno", "background": "当前在线学习方法在有效利用重复变换方面存在不足，而基于模型池的方法则难以捕捉到个体源组件，导致适应性能不佳。", "innovation": "提出了一种通过离线分解和在线混合方法实现源组件变换适应的策略。该方法将问题分为离线源组件分解和在线混合权重适应两个子问题。通过EM算法确定预测模型，并通过在线凸优化更新预测模型的混合权重。", "conclusion": "实验结果表明，该方法在多种实际回归数据集上优于基线方法，累计测试损失降低高达67.4%。"}
{"llm_update_time": "20250815", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.10123", "html_url": "https://arxiv.org/abs/2508.10123", "title": "Nested-ReFT: 通过离策略卷集提高大型语言模型精调的效率", "title_en": "Nested-ReFT: Efficient Reinforcement Learning for Large Language Model Fine-Tuning via Off-Policy Rollouts", "authors": "Maxime Heuillet,Yufei Cui,Boxing Chen,Audrey Durand,Prasanna Parthasarathi", "background": "在处理诸如数学推理等具有挑战性的领域时，大型语言模型（LLMs）可以通过基于可验证奖励的强化学习精调（ReFT）来实现高级推理。标准的ReFT框架要求行为模型为每个问题生成多个答案完成，并由奖励函数进行评分。尽管RL后的训练方法在这些复杂的推理领域中显示出了显著的性能提升，但生成完成所需的各种推理步骤导致的计算成本使得训练过程变得昂贵且非平凡。", "innovation": "该研究引入了一种名为Nested-ReFT的新颖ReFT框架，其中目标模型的一部分层充当行为模型，在训练期间生成离策略完成。通过在训练过程中配置动态层跳过，该行为模型降低了推理成本，相比标准的ReFT框架。理论分析表明，Nested-ReFT提供了无偏的梯度估计，并且方差可控。实证分析表明，Nested-ReFT在多个数学推理基准和模型规模上提高了计算效率，即每秒处理的标记数（tokens/sec）。此外，研究还探索了三种偏置缓解变体，以最小化梯度更新中的离策略性，从而保持与标准ReFT基线相当的性能。", "conclusion": "Nested-ReFT框架通过减少推理成本和提高计算效率来提高大型语言模型在复杂推理领域的精调效率。通过动态层跳过机制，它能够生成离策略完成，并通过无偏性的梯度估计保持与标准ReFT相当的性能。"}
{"llm_update_time": "20250815", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.10298", "html_url": "https://arxiv.org/abs/2508.10298", "title": "SynBrain：通过概率表示学习增强视觉到fMRI合成", "title_en": "SynBrain: Enhancing Visual-to-fMRI Synthesis via Probabilistic Representation Learning", "authors": "Weijian Mai,Jiamin Wu,Yu Zhu,Zhouheng Yao,Dongzhan Zhou,Andrew F. Luo,Qihao Zheng,Wanli Ouyang,Chunfeng Song", "background": "在计算神经科学中，解析视觉刺激如何转化为皮层反应是一个基本挑战。这种视觉到神经的映射是先天的一对多关系，即相同的视觉输入在不同实验、不同情境和不同研究对象中会产生不同的血流动力学响应。现有的确定性方法难以同时建模这种生物的变异性以及视觉刺激信息编码的功能一致性。因此，这一领域的研究需要新的方法和工具来解决存在的局限性。", "innovation": "本文提出了SynBrain，这是一个生成框架，它通过概率学习将视觉语义转换为神经反应，并通过视觉语义约束维持功能一致性。SynBrain有两项关键组件：(1) BrainVAE通过概率学习表示神经表示，同时通过视觉语义约束维持功能一致性；(2) 语义到神经映射器作为一种语义传输途径，将视觉语义投影到神经响应流形，以实现高保真的fMRI合成。实验结果表明，SynBrain在针对特定个体的视觉到fMRI编码性能方面超越了最先进的方法，并且能够高效地适应新个体的数据，并合成高质量的fMRI信号，以提升数据有限的fMRI到图像解码性能。此外，SynBrain可以揭示跨实验和个体的功能一致性，且合成信号捕捉由生物神经变异性形成的可解释模式。", "conclusion": "SynBrain通过概率表示学习的方法增强视觉到fMRI的合成，显著提高了个体特异性视觉到fMRI编码性能，并且能够高效地适应新个体的数据，合成高质量的fMRI信号，同时揭示了功能一致性，并生成的信号揭示了由生物神经变异性形成的可解释模式。本文的代码将公开提供。"}
{"llm_update_time": "20250815", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.10228", "html_url": "https://arxiv.org/abs/2508.10228", "title": "比较D-Wave量子退火与马尔可夫链蒙特卡罗方法在受限玻尔兹曼机概率分布采样中的应用", "title_en": "Comparison of D-Wave Quantum Annealing and Markov Chain Monte Carlo for Sampling from a Probability Distribution of a Restricted Boltzmann Machine", "authors": "Abdelmoula El Yazizi,Samee U. Khan,Yaroslav Koshka", "background": "该研究将本地谷（LV）中心化的方法应用于最新的D-Wave量子退火器，以评估从受限玻尔兹曼机（RBM）采样质量的评估。D-Wave和Gibbs采样来自基于对比散度学习的RBM，研究在条件相关于对比散度法学习时取得样本的谷的数量及对应局部最小能的能值。尽管减少D-Wave退火时间没有带来显著的（可取的）增加的谷的数量，但在训练的任何阶段，由D-Wave采样的状态所对应的局部谷往往多于Gibbs采样中的局部谷数量。但由于这两种方法找到的一些局部谷不同，所有这些局部谷并不完全互补，而是存在重叠。研究表明，尽管早期阶段两个技术的互补性和重叠性较低，但随着训练的进行，其互补性和重叠性变小，这在训练中可能有意义。这些发现解释了之前使用D-Wave采样的研究未能达到显著（或任何）改进的原因。", "innovation": "引入本地谷（LV）中心化的方法用于评估从D-Wave量子退火器和经典Gibbs采样中获得的样本在受限玻尔兹曼机的局部谷及其能量方面的差异，尽管在退火时间减少时并没有看到显著的局部谷数量的增加，但这些结果为如何改进和结合经典和量子方法提供启示。", "conclusion": "研究表明，尽管在训练的早期阶段两种方法的互补性和重叠性较低，但随着训练的进展，其互补性和重叠性变小，这对受限玻尔兹曼机的训练可能有意义。结果解释了之前使用D-Wave采样的研究未能达到显著（或任何）改进的原因，但揭示了也许通过结合经典和量子方法可能还有改进的空间。"}
{"llm_update_time": "20250815", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.10299", "html_url": "https://arxiv.org/abs/2508.10299", "title": "通过知识增强初始化提高联邦适配器调优中学习新疾病的性能", "title_en": "Improving Learning of New Diseases through Knowledge-Enhanced Initialization for Federated Adapter Tuning", "authors": "Danni Peng,Yuan Wang,Kangning Cai,Peiyan Ning,Jiming Xu,Yong Liu,Rick Siow Mong Goh,Qingsong Wei,Huazhu Fu", "background": "在医疗保健领域，联邦学习（FL）是一种广泛采用的框架，它允许医疗机构在保护隐私的同时进行协作。随着大型基础模型（FMs）展现出惊人的能力，通过成本效益的适配器微调在FL中使用FMs已经成为一种流行的方法。鉴于快速变化的医疗环境，个体客户端需要快速适应新的任务或疾病，通过适配器进行调整并借鉴过去的经历变得至关重要。", "innovation": "引入了Federated Knowledge-Enhanced Initialization（FedKEI），这是一种新颖的框架，它利用跨客户端和跨任务的过去知识进行转移，生成适配器学习新任务的有信息的初始值。FedKEI首先在服务器端通过全局聚类过程泛化跨任务的知识，然后通过优化跨聚类的聚合权重（跨聚类权重）和每个聚类内的聚合权重（内聚类权重），为每个新任务个性化知识转移。为了更好地学习跨聚类和内聚类权重，采用了一种多层次优化方案，跨客户端协作学习全局内聚类权重，并优化局部跨聚类权重以实现每个客户端的任务目标。", "conclusion": "在包括皮肤科、胸部X光和眼底OCT等多种模态的三个基准数据集上进行的大量实验表明，与最先进的方法相比，FedKEI在适应新疾病方面具有优势。"}
{"llm_update_time": "20250815", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.10284", "html_url": "https://arxiv.org/abs/2508.10284", "title": "对帕金森病用药需求具有不确定感知的预测：一种双阶段典范预测方法", "title_en": "Uncertainty-Aware Prediction of Parkinson's Disease Medication Needs: A Two-Stage Conformal Prediction Approach", "authors": "Ricardo Diaz-Rincon,Muxuan Liang,Adolfo Ramirez-Zamora,Benjamin Shickel", "background": "帕金森病（PD）药物管理面临独特的挑战，因为疾病进展和治疗反应存在差异。神经科医生需要在症状控制和最优多巴胺剂量之间平衡，以最小化副作用。维持这一平衡至关重要，因为不充分或突然改变可能导致左旋多巴引起的不自主运动、治疗效果消失及神经精神副作用，严重影响生活质量。目前的方法依赖于试错决策，缺乏系统预测方法。尽管机器学习取得了进步，但在临床应用中仍然有限，因为传统的点预测方法忽略了预测不确定性，减少了临床信任和实用性。临床医生不仅需要未来用药需求的预测，还需要可靠的置信度措施。缺乏量化的不确定性，调整剂量可能导致过早达到最大剂量或长期的症状控制不足。", "innovation": "本文开发了一种典范预测框架，能够在未来两年准确预测药物需求，并提供具有可靠预测区间和统计保证的预测。该方法解决了帕金森病住院数据中的零膨胀问题，即患者在访视之间保持稳定的药物方案。通过电子健康记录，使用佛罗里达大学健康系统2011年至2021年间631次住院数据，该两阶段方法能够识别可能需要药物调整的患者，然后预测所需的左旋多巴等效日剂量调整。与传统方法相比，该框架在边际覆盖方面更准确，同时缩短了预测区间长度，为短期计划提供精确预测，为长期预测提供更广泛的范围。通过量化不确定性，这种方法能够促进基于证据的左旋多巴剂量决策，优化症状控制，减少副作用，提高生活质量。", "conclusion": "该方法提出了一种新的典范预测框架，能够提供可靠的不确定性量化，对帕金森病药物需求进行准确预测，从而帮助临床医生制定证据基础的用药决策，优化症状控制，减少副作用，提高患者生活质量。"}
{"llm_update_time": "20250815", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.10118", "html_url": "https://arxiv.org/abs/2508.10118", "title": "从意图到执行：多模态链式思维 reinforcement 学习在精确 CAD 代码生成中的应用", "title_en": "From Intent to Execution: Multimodal Chain-of-Thought Reinforcement Learning for Precise CAD Code Generation", "authors": "Ke Niu,Haiyang Yu,Zhuofan Chen,Mengyang Zhao,Teng Fu,Bin Li,Xiangyang Xue", "background": "计算机辅助设计（CAD）在工程和制造中发挥着重要作用，但现有的 CAD 工作流程需要大量的领域专业知识和手动建模努力。尽管大型语言模型（LLMs）的进步使得从自然语言生成代码成为可能，但直接将人类的设计意图转化为可执行的 CAD 代码仍然极具挑战性，因为这需要逻辑推理、语法规则的正确性以及数值精度。", "innovation": "本文提出了一种多重模态的链式思维（CoT）引导增强学习后训练框架 CAD-RL，它结合了冷启动的链式思维和目标驱动的增强学习后训练，使用三种特定任务的奖励：可执行性奖励、几何准确性奖励和外部评估奖励。此外，为了保证在稀疏和高方差奖励条件下稳定的学习策略，引入了三种针对性的优化策略：可信区域拉伸以改善探索、精度标记损失以提高维度参数精度，以及过长过滤以减少嘈杂的监督。为了支持训练和基准测试，还发布了 ExeCAD 数据集，该数据集包含 16,540 个真实世界的 CAD 示例，配有自然语言和结构化设计语言描述、可执行的 CADQuery 脚本以及渲染的 3D 模型。", "conclusion": "实验结果表明，CAD-RL 在推理质量、输出精度和代码执行性方面相比现有的视觉语言模型（VLMs）取得了显著的改进。"}
{"llm_update_time": "20250815", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.10315", "html_url": "https://arxiv.org/abs/2508.10315", "title": "视觉语言预训练模型引导的方法以减轻联邦学习中的后门攻击", "title_en": "A Vision-Language Pre-training Model-Guided Approach for Mitigating Backdoor Attacks in Federated Learning", "authors": "Keke Gai,Dongjue Wang,Jing Yu,Liehuang Zhu,Qi Wu", "background": "现有的联邦学习（FL）后门防御方法依赖于客户端数据分布均一或者干净服务端数据集的假设，这限制了其实用性和有效性。在异质客户端数据分布下防御后门攻击，同时保持模型性能仍然是一项重大挑战。", "innovation": "本文提出了一种名为CLIP-Fed的后门防御框架，利用视觉语言预训练模型的零样本学习能力。通过结合预聚合和后聚合防御策略，CLIP-Fed克服了在模型防御性能方面对非独立同分布性（Non-IID）的限制。还通过使用多模态大语言模型和频率分析构建并扩充了服务端数据集，同时不依赖任何客户端样本，以解决隐私和数据集覆盖范围问题。CLIP-Fed使用原型对比损失和Kullback-Leibler散度对手动增强的数据集进行全球模型和CLIP知识的对齐，解决后门样本引起的类别原型偏差和触发模式与目标标签之间的相关性。", "conclusion": "通过广泛的实验证明，与最先进的方法相比，CLIP-Fed在CIFAR-10上的SR平均降低了2.03%，在CIFAR-10-LT上的降低了1.35%，同时平均MA分别提高了7.92%和0.48%。"}
{"llm_update_time": "20250815", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.10345", "html_url": "https://arxiv.org/abs/2508.10345", "title": "福利中心化的聚类", "title_en": "Welfare-Centric Clustering", "authors": "Claire Jie Zhang,Seyed A. Esmaeili,Jamie Morgenstern", "background": "传统公平聚类主要关注确保群组的公平代表性或平衡特定群组的聚类费用。然而，Dickerson等人（2025年）的研究表明，这些公平观念可能导致不理想或难以预料的聚类结果。因此，他们提倡一种以福利为中心的聚类方法，这种方法侧重于建模群组的福利。基于这种背景，该研究进一步开发了基于距离和比例代表性来建模群组福利的方法，并提出了两个基于福利为中心聚类的优化目标：罗尔斯主义（平等）目标和功利主义目标。", "innovation": "该研究提出了基于福利为中心的聚类方法，并引入了针对这两个优化目标的新算法，同时提供了这些算法的理论保证。实证研究表明，该方法在多种真实世界数据集上的表现显著优于现有公平聚类基线方法。", "conclusion": "该研究通过协作优化聚类过程，并通过新的算法模型精准地提高了群组福利，展现了对公平性和效率性兼顾的创新结果。"}
{"llm_update_time": "20250815", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.10350", "html_url": "https://arxiv.org/abs/2508.10350", "title": "使用顺序观察进行分布学习的语义通信", "title_en": "Semantic Communication with Distribution Learning through Sequential Observations", "authors": "Samer Lahoud,Kinda Khawam", "background": "语义通信旨在传递意义而非精确位复制，代表了一种与传统通信范式的转变。在这项研究中，探讨了在接收端通过顺序观察推断潜在的意义分布的学习分发问题。传统上，语义通信优化个体意义传输，但当先验未知时，建立了学习源统计的基本条件。证明了可学习性要求有效传输矩阵为满秩，并刻画了分布估计收敛速度及估计误差向语义失真转化的量度。分析揭示了一种根本性权衡：优化即时语义性能的编码方案往往牺牲长期可学习性。", "innovation": "证明了可学习性要求有效传输矩阵为满秩，并刻画了分布估计收敛速度及估计误差向语义失真转化的量度。揭示了即时语义性能与长期可学习性之间的权衡关系。验证了理论框架在CIFAR-10上的有效性，展示了系统条件对学习速率和可实现性能的影响。为平衡即时性能与适应能力的系统设计提供了准则。", "conclusion": "该研究提供了语义通信中统计学习的首次严格表征，并为平衡即时性能与适应能力的系统设计提供了设计原理。"}
{"llm_update_time": "20250815", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.10393", "html_url": "https://arxiv.org/abs/2508.10393", "title": "统一的多注释者倾向学习评估框架", "title_en": "A Unified Evaluation Framework for Multi-Annotator Tendency Learning", "authors": "Liyun Zhang,Jingcheng Ke,Shenli Fan,Xuanmeng Sha,Zheng Lian", "background": "近年来，多注释者学习领域出现了一些成果，这些成果的重心从共识导向学习（CoL）转移至个体倾向学习（ITL），即通过建模和解释注释者特定的标签行为模式来理解注释者决策。然而，尚未有评估框架能够评定这些ITL方法是否真正捕捉了个体的倾向性，并提供了有意义的行为解释。该论文旨在填补这一研究空白，提出首个统一的评估框架，并引入了两个新的评估指标：差异的注释者一致性（DIC）和行为对齐可解释性（BAE）。", "innovation": "该研究提出了一种全新的统一评估框架，该框架包括两个创新性的评估指标：1) 差异的注释者一致性（DIC）通过比较预测的注释者一致相似结构与真实值，以量化模型对注释者倾向的捕捉能力。2) 行为对齐可解释性（BAE）通过多维标度（MDS）对齐解释性衍生的标签相似结构与真实值，以评估模型解释如何能反映注释者的行为和决策相关性。整个框架首次系统性地评估了多注释者倾向学习方法的效果。", "conclusion": "全面的实验验证了该提出的评估框架的有效性。"}
{"llm_update_time": "20250815", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.10370", "html_url": "https://arxiv.org/abs/2508.10370", "title": "eMamba: 在边缘计算中高效加速Mamba模型的框架", "title_en": "eMamba: Efficient Acceleration Framework for Mamba Models in Edge Computing", "authors": "Jiyong Kim,Jaeho Lee,Jiahao Lin,Alish Kanani,Miao Sun,Umit Y. Ogras,Jaehyun Park", "background": "基于状态空间模型（SSM）的机器学习架构最近在处理顺序数据方面引起了极大的关注。Mamba作为一种近期推出的序列到序列SSM模型，具有与最先进的变压器模型相当的准确性和更好的计算效率。尽管Mamba具有这种优势，使其特别适合资源受限的边缘设备，但目前没有针对这些环境优化的硬件加速框架。", "innovation": "本文提出了eMamba，这是一种专门为边缘平台部署Mamba模型而设计的端到端硬件加速框架。eMamba通过用轻量级、硬件感知的替代方案替换复杂的归一化层，并对昂贵的操作（如SiLU激活和指数运算）进行近似，来最大化计算效率。eMamba还进行近似感知的神经架构搜索（NAS）来调整近似过程中使用的可学习参数。eMamba使用较少的参数达到了与最先进的技术相当的准确度，并且能够泛化到大规模自然语言任务，在各种序列长度下表现出稳定的困惑度。", "conclusion": "实验结果表明，与基准方案相比，eMamba在AMD ZCU102 FPGA和GlobalFoundries（GF）22nm技术的ASIC上进行量化和实现时，具有4.95-5.62倍的较低延迟、2.22-9.95倍的较高吞吐量、4.77倍的较小面积、9.84倍的较低功耗和48.6倍的较低能量消耗，同时保持了竞争力的准确率。"}
{"llm_update_time": "20250815", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.10428", "html_url": "https://arxiv.org/abs/2508.10428", "title": "SC2Arena和StarEvolve：复杂决策任务中LLMs的标准和自我提升框架", "title_en": "SC2Arena and StarEvolve: Benchmark and Self-Improvement Framework for LLMs in Complex Decision-Making Tasks", "authors": "Pengbo Shen,Yaqing Wang,Ni Mu,Yao Luan,Runpeng Xie,Senhao Yang,Lexiang Wang,Hao Hu,Shuang Xu,Yiqin Yang,Bo Xu", "background": "评估大型语言模型（LLMs）在复杂决策任务中的表现对于推进AI的策略规划和实时适应能力至关重要。然而，现有的评估基准，如《星际争霸II》，未能全面捕捉游戏的复杂性，包括完整的游戏环境、多样化的行动空间和所有可玩的种族。因此，需要一种能够支持所有可玩种族、低级别行动空间并优化文本观察来解决空间推理挑战的新基准。", "innovation": "作者提出了SC2Arena，这是一种全面支持所有可玩种族、低级行动空间以及优化文本观察来解决空间推理挑战的新基准。此外，还引入了StarEvolve，这是一个层次框架，将战略规划与战术执行结合，包括迭代自我纠正和通过高质量游戏数据微调实现持续改进。其关键组成部分包括计划者-执行者-验证者结构以拆解游戏玩法，以及用于选择高质量训练样本的评分系统。", "conclusion": "通过使用SC2Arena进行全面分析，可以获得更多关于开发通用代理的有价值的见解，这在以前的基准无法实现。实验结果还证明我们的StarEvolve在战略规划方面取得了优异的性能。我们的代码、环境和算法已公开提供。"}
{"llm_update_time": "20250815", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.10455", "html_url": "https://arxiv.org/abs/2508.10455", "title": "RealAC: 一种领域无关的现实和可执行的反事实解释框架", "title_en": "RealAC: A Domain-Agnostic Framework for Realistic and Actionable Counterfactual Explanations", "authors": "Asiful Arefeen,Shovito Barua Soumma,Hassan Ghasemzadeh", "background": "反事实解释通过描述最小改变输入特征的方法来改变模型预测结果，提供人类易于理解的决策理由。然而，现有方法存在一些问题：依赖于明确的手动构建约束或特定领域的知识，限制了它们的普适性和对数据中内在的复杂非线性关系的捕捉能力；不能满足用户指定的偏好；生成的反事实可能是因果上不可行的或无法执行的。论文指出现有方法的主要不足在于缺乏对复杂特征间依赖关系的自动保全机制和灵活性不足的问题。", "innovation": "RealAC框架是一个跨领域的反事实生成框架，能够自动保留复杂的特征间依赖关系，无需依赖具体领域的知识；通过对目标实例对特征联合分布调整，实现现实性和可执行性的平衡；允许最终用户冻结不能或不希望改变的属性，在优化过程中抑制这些冻结属性的改变。实验结果表明RealAC在现实性、可执行性和因果关系感知方面优于现有先进方法和基于大型语言模型的反事实生成技术。", "conclusion": "实验结果显示RealAC平衡了现实性和可执行性，其方法在因果边分数、依赖关系保持分数和IM1现实性度量方面优于现有先进技术和基于大型语言模型的反事实生成方法，并提供了一种因果性感知和用户中心的反事实生成方案。"}
{"llm_update_time": "20250815", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.10474", "html_url": "https://arxiv.org/abs/2508.10474", "title": "EDAPT：通过持续在线适应实现无需校准的BCI", "title_en": "EDAPT: Towards Calibration-Free BCIs with Continual Online Adaptation", "authors": "Lisa Haxel,Jaivardhan Kapoor,Ulf Ziemann,Jakob H. Macke", "background": "脑-计算机接口（BCIs）由于神经信号随时间和用户间的变化而产生准确性下降，需要频繁的重新校准，这限制了其实际应用。现有的主流方法是使用静态模型，但针对用户之间和使用过程中神经模式的变化无法提供有效的适应性解决方案。", "innovation": "提出了一个任务和模型无关的框架EDAPT，通过持续的模型适应过程消除校准。EDAPT采用了群体预训练和在线持续微调相结合的方法，并且利用无监督的领域适应进一步优化。此框架在多个BCI任务的数据集上测试，显示了比传统静态方法的性能提升，特别是通过结合群体和个体的数据学习，赋予模型更强的适应性。而且EDAPT运行效率高，能够在消费级硬件上快速完成模型更新。此外，解码精度与数据总量相关，而不是样本和试验间的分配方式。", "conclusion": "EDAPT提供了一种实用的途径，旨在实现无需校准的BCI，化解了BCI部署的主要障碍。"}
{"llm_update_time": "20250815", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.10471", "html_url": "https://arxiv.org/abs/2508.10471", "title": "GraphFedMIG: 通过互信息导向生成解决联邦图学习中的类别不平衡问题", "title_en": "GraphFedMIG: Tackling Class Imbalance in Federated Graph Learning via Mutual Information-Guided Generation", "authors": "Xinrui Li,Qilin Fan,Tianfu Wang,Kaiwen Wei,Ke Yu,Xu Zhang", "background": "联邦图学习（FGL）允许多个客户端协作训练强大的图神经网络，而无需共享其私有的、去中心化的图数据。FGL面临的核心挑战之一是统计异质性，即客户端之间非IID的数据分布会严重影响模型性能。特别是类别不平衡问题，会导致全局模型偏向于多数类别，而无法识别稀有但关键的事件。这种不平衡在FGL中尤为严重，因为少数类节点周围的邻居信息通常带有偏差，阻碍了复杂表示的学习。", "innovation": "提出了一种新颖的FGL框架GraphFedMIG，将其重新定义为联邦生成数据增强任务。GraphFedMIG使用分层生成对抗网络，其中每个客户端训练一个局部生成器，以合成高质量的特征表示。通过将客户端分组到簇中，并共享专用判别器，提供了定制化的监督。框架设计了一个由互信息指导的机制，用于引导客户端生成器的演进。通过计算每个客户端的独特信息价值，该机制调整局部生成器参数，确保后续的互信息导向生成专注于产生高价值的少数类特征。", "conclusion": "在四个真实数据集上进行了广泛的实验，结果表明GraphFedMIG在前瞻性模型中具有优越性，相比其他基线表现更优。"}
{"llm_update_time": "20250815", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.10435", "html_url": "https://arxiv.org/abs/2508.10435", "title": "在张量模型中拆解灵敏度意识最小化隐式范数动态", "title_en": "Unpacking the Implicit Norm Dynamics of Sharpness-Aware Minimization in Tensorized Models", "authors": "Tianxiao Cao,Kyohei Atarashi,Hisashi Kashima", "background": "Sharpness-Aware Minimization (SAM) 已证明是一个提高过参数化模型泛化的有效优化技术。尽管前人研究主要集中在简单、尺度不变的双核心情况下 SAM 的隐式正则化作用，但在更一般的张量模型或其他尺度不变模型中的行为仍然未被深入探索。研究团队利用尺度不变性来分析在一般张量化模型中 SAM 的范数动态，并引入了一个衡量核心范数失衡的全局指标——规范偏差，并通过梯度流分析导出了规范偏差在 SAM 下的演变过程。研究发现，SAM 对规范偏差的隐式控制由核心范数及其梯度幅度之间的协方差决定。基于这些发现，他们提出了一个简单有效的修正方法——偏差感知缩放 (DAS)，该方法通过数据自适应地缩放核心范数来模仿这种正则化行为。研究通过在张量补全、噪声训练、模型压缩以及参数高效微调中的实验验证了 DAS 的性能，并展示了其与 SAM 相当或更优，同时具有更低的计算开销。", "innovation": "引入了规范偏差这一全球衡量核心范数失衡的指标，揭示了 SAM 内隐控制规范偏差的机制，并提出偏差感知缩放 (DAS)，以适应地缩放核心范数来模仿该正则化行为，从而改进模型的泛化性能和计算效率。", "conclusion": "实验结果表明，DAS 在张量补全、噪声训练、模型压缩和参数高效微调中表现出与 SAM 竞争或优于 SAM 的性能，同时具有较低的计算开销。"}
{"llm_update_time": "20250815", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.10461", "html_url": "https://arxiv.org/abs/2508.10461", "title": "X-Node: 自解释能力就是我们所需的一切", "title_en": "X-Node: Self-Explanation is All We Need", "authors": "Prajit Sengupta,Islem Rekik", "background": "图神经网络（GNNs）在计算机视觉和医学图像分类任务中取得了最先进的成果，通过捕捉数据实例间的结构性依赖关系。然而，它们的决策过程仍然非常不透明，这限制了其在需要高度可信解释的关键临床应用中的应用。现有针对GNNs的解释技术通常是事后、全局的，对个体节点的决策或局部推理提供了有限的洞察。需要一种方法，使GNN的每个节点在预测过程中自动生成自己的解释，从而提高其透明度和解释性。", "innovation": "我们介绍了一种名为X-Node的自解释GNN框架，该框架中的每个节点都会在其预测过程中生成自己的解释。每个节点构建一个结构化的上下文向量，编码如度、中心性、聚类、特征显著性和局部拓扑内的标签一致性等可解释线索。一个轻量级的Reasoner模块将这一上下文映射到一个紧凑的解释向量，并具有三种功能：（1）通过解码器重构节点的潜在嵌入以确保忠实性，（2）使用预训练的LLM（例如Grok或Gemini）生成自然语言解释，（3）通过一种“文本注入”机制将解释反馈回消息传递管道，指导GNN本身。这一框架在两个从MedMNIST和MorphoMNIST衍生的图数据集上进行评估，与GCN、GAT和GIN回沿相结合。结果显示，X-Node在保持竞争力的同时，能生成忠实且逐节点的解释。", "conclusion": "X-Node框架显著提高了图神经网络的透明度和解释性，能够在保持高分类准确率的同时，为每个节点提供忠实且逐节点的解释。这项研究为解决GNN在关键临床应用中的不透明决策问题提供了一种新的解决方案。"}
{"llm_update_time": "20250815", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.10479", "html_url": "https://arxiv.org/abs/2508.10479", "title": "现实世界推荐系统中的混杂问题是普遍存在的问题", "title_en": "Confounding is a Pervasive Problem in Real World Recommender Systems", "authors": "Alexander Merkov,David Rohde,Alexandre Gilotte,Benjamin Heymann", "background": "未观察到的混杂构问题是指未测量的特征同时影响治疗和结果，导致因果效应估计偏差。这一问题削弱了经济学、医学、生态学或流行病学等领域的观察性研究。通常，依赖全面观测数据的推荐系统不会受到此问题的影响。然而，许多推荐系统中的标准做法会导致观测特征被忽略，从而使整个问题再现。", "innovation": "本文揭示了许多常见的做法，如特征工程、A/B测试和模块化实际上会将混杂引入推荐系统，并影响其性能。通过实证研究和模拟实验提供了混杂现象的多个实例，并提出了实操建议，以减少或避免现实系统中的混杂效应。", "conclusion": "文章表明，许多推荐系统中广泛使用的实践可能导致混杂问题，这会影响到推荐系统的性能和效果。研究人员和社会实践员应意识到这一点，并采取相应措施以解决这个问题。"}
{"llm_update_time": "20250815", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.10248", "html_url": "https://arxiv.org/abs/2508.10248", "title": "Orlicz 空间中 Max-Min 指数神经网络算子的收敛性分析", "title_en": "Convergence Analysis of Max-Min Exponential Neural Network Operators in Orlicz Space", "authors": "Satyaranjan Pradhan,Madan Mohan Soren", "background": "本文研究了使用指数神经网络算子近似函数的方法，特别是提出了Max Min方法，并将其扩展为Max Min Kantorovich型指数神经网络算子。文章探讨了这些算子的逼近性质，特别是在一元函数上的点态和一致收敛性。为了分析收敛阶，使用了对数模连续性，并估计了相应的收敛速度。此外，还在Orlicz空间框架下研究了Max Min Kantorovich型指数神经网络算子的收敛行为。", "innovation": "提出了Max Min方法来逼近函数，并扩展为Max Min Kantorovich型指数神经网络算子；研究了这些算子在Orlicz空间下的收敛性；使用对数模连续性分析了收敛阶，并估计了相应的收敛速度。", "conclusion": "文章提供了图形表示来展示函数的逼近误差，通过合适核函数和Sigmoid激活函数进行了说明。"}
{"llm_update_time": "20250815", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.10490", "html_url": "https://arxiv.org/abs/2508.10490", "title": "基于梯度的解释的复杂性-可信度trade-off分析", "title_en": "On the Complexity-Faithfulness Trade-off of Gradient-Based Explanations", "authors": "Amir Mehrpanah,Matteo Gamba,Kevin Smith,Hossein Azizpour", "background": "ReLU 神经网络在视觉数据领域十分常用，但由于它们具有尖锐的跃变特性，有时依赖单个像素进行预测，使得基于梯度的传统解释方法（如 vanilla gradient）产生嘈杂且难以解释的结果。现有的方法，如 GradCAM，通过生成代理模型来平滑这些解释，但这样做会牺牲一定的可信度。", "innovation": "本文提出了一个统一的频谱框架，系统地分析和量化了平滑度、可信度及其在解释中的权衡。该框架量化并正则化了ReLU网络对高频信息的贡献，并为识别这些权衡提供了一个严格的手段。此外，通过该框架，文章还量化了基于代理模型的平滑如何扭曲解释，并正式定义并测量了不同的事后方法之间的“解释差距”。", "conclusion": "理论发现被在不同的设计选择、数据集和消融实验中得到了验证，进一步阐述了提出的理论成果的有效性。"}
{"llm_update_time": "20250815", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.10480", "html_url": "https://arxiv.org/abs/2508.10480", "title": "Pinet: 使用正交投影层优化具有硬约束的神经网络", "title_en": "Pinet: Optimizing hard-constrained neural networks with orthogonal projection layers", "authors": "Panagiotis D. Grontas,Antonio Terpin,Efe C. Balta,Raffaello D'Andrea,John Lygeros", "background": "本文介绍了一种神经网络的输出层，确保满足凸约束。该方法通过操作分解在前向传递中实现快速可靠投影，通过隐函数定理在反向传播中计算梯度。该方法被用作参数化约束优化问题的可行设计优化代理，在处理单个问题时比传统求解器更快，对于多个问题则显著更快。PInet方法在训练时间、解决方案质量和对超参数调优的鲁棒性方面超过了最先进的学习方法，同时保持了类似推断时间。最后，方法被应用于具有非凸轨迹偏好的多车辆运动规划，并提供了一个针对GPU的JAX实现，带有有效的调优启发式方法。", "innovation": "提出了一种新颖的神经网络输出层——$\bar{\text{P}}$层（$\bar{\text{P}}$net），结合了操作分解和隐函数定理，以确保满足凸约束的优化。$\bar{\text{P}}$net作为参数化约束优化问题的直接可行优化代理，在处理单个和批量问题时表现出更快的速度。", "conclusion": "该方法在训练时间和解决方案的质量和鲁棒性方面优于现有的学习方法，同时提供相似的推断时间。$\bar{\text{P}}$net在非凸轨迹偏好的多车辆运动规划中表现出良好的性能，并提供了有效的GPU实现。"}
{"llm_update_time": "20250815", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.10489", "html_url": "https://arxiv.org/abs/2508.10489", "title": "使用联合嵌入预测架构从任意数据学习动态系统的状态空间模型", "title_en": "Learning State-Space Models of Dynamic Systems from Arbitrary Data using Joint Embedding Predictive Architectures", "authors": "Jonas Ulmen,Ganesh Sundaram,Daniel Görges", "background": "自从联合嵌入预测架构（JEPAs）出现以来，它们似乎比基于重建的方法更为高效。本文提出了一种使用任意观察数据和连续时间动态系统创建世界模型的新技术。", "innovation": "该方法将序列嵌入与神经常微分方程（神经ODEs）结合使用，并通过使用收缩嵌入和状态转换中的Lipschitz常数来构造良好的潜在状态空间。这种方法通过仅使用图像数据生成简单摆动系统的结构化潜在状态空间模型进行了验证。", "conclusion": "这种方法提供了开发更广泛的控制算法和估计技术的新途径，在机器人领域具有广泛的应用前景。"}
{"llm_update_time": "20250815", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.10491", "html_url": "https://arxiv.org/abs/2508.10491", "title": "对比学习ECOC：用于对抗防护的输出码学习", "title_en": "Contrastive ECOC: Learning Output Codes for Adversarial Defense", "authors": "Che-Yu Chou,Hung-Hsuan Chen", "background": "在多类分类中，虽然一热编码（one-hot encoding）是一种常用的编码方法，但它并不总是最有效的编码机制。纠错输出编码（Error Correcting Output Codes, ECOC）通过将每个类别映射到一个唯一的码字（codeword）作为标签来解决多类分类问题。传统的ECOC方法依赖于手动设计或随机生成的码本，这虽劳力巨大但可能导致与特定数据集不太相关的结果。现有的方法通常需要人工设计或随机生成码本，在对抗性攻击面前可能表现不佳或不够稳定。因此，迫切需要一种能够自适应学习码本的自动化方法，使其更加稳健对抗各种不同的攻击。", "innovation": "本文提出了三种基于对比学习的模型来自动学习码本，使得码本可以从数据中直接学习并自适应地生成。这种方法彻底改变了传统ECOC依赖手动或随机码本的状态，从而解决了数据集相关的潜在问题。此外，该方法证实其模型在四个数据集上对对抗性攻击表现出优异的鲁棒性，相比两种基线方法，展示出更好的性能。", "conclusion": "与传统的基于手动或随机码本的ECOC方法相比，本研究提出的方法能从数据中直接学习码本，提高其对抗性攻 Defender能够从中受益，自适应地学习码本，使模型在面对不同类型的对抗性攻击时更加稳健。此外，该方法也在多个数据集上验证了其优越的鲁棒性，介绍了三种基于对比学习的自动编码本学习模型。"}
{"llm_update_time": "20250815", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.10494", "html_url": "https://arxiv.org/abs/2508.10494", "title": "统一多代理框架以实现通用多模态理解和生成", "title_en": "A Unified Multi-Agent Framework for Universal Multimodal Understanding and Generation", "authors": "Jiulin Li,Ping Huang,Yexin Li,Shuo Chen,Juewen Hu,Ye Tian", "background": "现实世界中的多模态应用通常需要任意到任意的能力，这使得跨文本、图像、音频和视频等模态的理解和生成成为可能。然而，将自回归语言模型（LLMs）的推理优势与高保真生成模型的优势结合起来仍然具有挑战性。现有方法依赖硬编码的流水线或紧密耦合的架构，这限制了灵活性和可扩展性。", "innovation": "该论文提出了MAGUS（Multi-Agent Guided Unified Multimodal System），一种模块化框架，通过认知和决断两个解耦的阶段统一多模态理解和生成。MAGUS 支持插件式扩展性、大规模任意到任意模态转换和语义对齐，无需联合训练。该系统在多模态生成基准测试、跨模态指令跟随等应用场景中，优于强基线和最先进的系统。", "conclusion": "跨模态生成基准测试MME上，MAGUS超越了强大的闭源模型GPT-4o。MAGUS通过解耦的认知和决断阶段，实现了多代理协作，并通过增长感知搜索机制结合LLM推理和扩散生成增强机制，在多个基准测试场景中表现出色。"}
{"llm_update_time": "20250815", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.10395", "html_url": "https://arxiv.org/abs/2508.10395", "title": "XQuant：通过键值缓存重构造打破LLM推理的内存墙", "title_en": "XQuant: Breaking the Memory Wall for LLM Inference with KV Cache Rematerialization", "authors": "Aditya Tomar,Coleman Hooper,Minjae Lee,Haocheng Xi,Rishabh Tiwari,Wonjun Kang,Luca Manolache,Michael W. Mahoney,Kurt Keutzer,Amir Gholami", "background": "尽管大语言模型（LLM）推理已成为许多下游应用的关键工作负载，但进行LLM推理具有挑战性，因为这需要大量的内存和带宽。过去几十年中，计算能力以稳定的速度超越了内存容量和带宽，现代GPU硬件中这一趋势仍然存在，进一步加剧了LLM推理的挑战。因此，新的算法正在出现，它们通过增加计算量来减少内存操作。因此，XQuant在这种趋势下提出了低精度量化的方法，通过低比特量化大幅减少内存使用，同时相对于现有最先进的键值缓存量化方法保持显著的准确性优势。", "innovation": "XQuant通过低比特量化和缓存层输入激活X，而不是使用标准的键值缓存，然后在推理过程中实时重新计算键和值，实现了内存消耗的大幅减少。与键值缓存相比，这立即节省了2倍的内存。对于不同的模型，XQuant-CL采取了进一步的压缩方法，利用X嵌入在不同层之间的相似性，达到了FP16基线10倍甚至12.5倍的内存节省，同时仅导致0.01或0.1的困惑度下降。", "conclusion": "XQuant通过利用硬件平台计算能力的快速增长来消除内存瓶颈，突破了内存墙。该方法显著提高了内存效率，同时保持了接近FP16的准确性，适用于广泛的模型。"}
{"llm_update_time": "20250815", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.10346", "html_url": "https://arxiv.org/abs/2508.10346", "title": "零日攻击检测的层次化的IoMT入侵检测系统", "title_en": "A Hierarchical IDS for Zero-Day Attack Detection in Internet of Medical Things Networks", "authors": "Md Ashraf Uddin,Nam H. Chu,Reza Rafeh", "background": "医疗物联网(IoMT)正在推动医疗行业的革命，但这些网络依然容易遭受各种网络攻击，如拒绝服务、勒索软件、数据劫持和欺骗。这些网络设备主要是资源受限的异构装置，现有的集中式入侵检测系统(IDS)因响应延迟和隐私风险等问题不适用。集中式IDS需要所有传感器的数据传输至中心服务器，但在密集环境中会造成延迟或网络中断。本地运行IDS于IoMT设备通常是不可行的，即使轻量级IDS组件仍然存在因模型更新延迟而暴露于零日攻击中的风险。", "innovation": "该研究提出了一种多层次的IoMT入侵检测系统框架，可以检测零日攻击并与已知和未知威胁进行区分。第一层（近边缘）在粗略级使用元学习或一类分类（OCC）的usfAD算法进行流量过滤（攻击或非攻击）。后续层级（远边缘，云）识别攻击类型和新颖性。实验结果表明，该框架在CICIoMT2024数据集中的准确率达到99.77%，F1分数为97.8%。第一层利用元学习方法高效检测零日攻击，无需新数据集，确保在IoMT环境中的广泛应用。", "conclusion": "该研究提出的方法有效提高了IoMT网络的安全性，特别是在检测零日攻击方面表现优异，同时保证了系统的实时性和有效性。"}
{"llm_update_time": "20250815", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.10548", "html_url": "https://arxiv.org/abs/2508.10548", "title": "使用门控奖励稳定长周期多轮强化学习", "title_en": "Stabilizing Long-term Multi-turn Reinforcement Learning with Gated Rewards", "authors": "Zetian Sun,Dongfang Li,Zhuoen Chen,Yuhuai Qin,Baotian Hu", "background": "在长期强化学习任务中，奖励稀疏性仍然是一个重大挑战。现有的基于结果的奖励塑造方法难以定义有意义的即时奖励，且容易引入偏差或需要明确的任务分解。相比之下，基于验证的奖励塑造使用逐步批评家，但即时奖励与长期目标之间的不一致可能导致奖励劫持和次优策略。在软件工程任务中，多轮推理和基于规则的验证至关重要。现有的方法难以处理这些任务中的奖励问题。", "innovation": "提出了一种新的方法——门控奖励累积（G-RA），它在高层（长期）奖励达到预定义阈值时才累积即时奖励，确保了RL优化的稳定性。该方法通过SWE-bench Verified和kBench实验验证了其有效性，并且与基于验证的奖励塑造方法相比，避免了由于奖励不一致导致的策略退化。", "conclusion": "我们的研究强调了在长期RL中平衡奖励积累的重要性，并提供了一种实用的解决方案。"}
{"llm_update_time": "20250815", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.10531", "html_url": "https://arxiv.org/abs/2508.10531", "title": "Projected Coupled Diffusion for Test-Time Constrained Joint Generation", "title_en": "Projected Coupled Diffusion for Test-Time Constrained Joint Generation", "authors": "Hao Luan,Yi Xian Goh,See-Kiong Ng,Chun Kai Ling", "background": "修改测试时采样已成为扩散算法的一个重要扩展方向，目的是在无需重新训练整个扩散模型的情况下，偏转生成过程以实现特定目标。然而，在不进行昂贵的重新训练的情况下，从多个预训练的扩散模型中同时生成联合相关样本并同时施加特定任务约束仍然是一个挑战。因此，需要一种在测试时间上施加约束条件下的联合生成新框架。", "innovation": "提出了Projected Coupled Diffusion (PCD)，这是一种新的测试时框架，用于受约束的联合生成。PCD引入了一个耦合指导项到生成动力学中，以鼓励扩散模型之间的协调，并在每一步扩散过程中加入一个投影步骤以强制执行硬约束。实验结果表明，PCD在图像对生成、对象操作和多机器人运动规划等应用场景中具有良好的耦合效果，并且能够在不增加过多计算成本的情况下满足约束条件。", "conclusion": "我们的结果证明，PCD在应用中表现出色，增强了耦合效应，并保证了约束条件的满足，而不会产生过度的计算成本。"}
{"llm_update_time": "20250815", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.10520", "html_url": "https://arxiv.org/abs/2508.10520", "title": "通过强化学习的非局域蒙特卡洛方法", "title_en": "Nonlocal Monte Carlo via Reinforcement Learning", "authors": "Dmitrii Dobrynin,Masoud Mohseni,John Paul Strachan", "background": "组合优化问题中的复杂成本函数的优化或采样一直是跨学科和应用领域的一个长期挑战。传统的基于马尔可夫链蒙特卡罗（MCMC）方法的算法，如模拟退火或平行温度调控，假设输入中的温度分布是均匀的。这种实例独立的方法在计算相变附近（当所谓的重叠-间隙性质存在时）是最难的基准中表现不佳，常规MCMC在冻结的变量解冻、从次优吸引盆地中逃逸以及采样高质量和多样化的解决方案方面遇到困难。因此，研究者提出了利用非均匀温度分布以加速配置空间探索而不损害其开发的非局域蒙特卡洛（NMC）算法。本文利用深度强化学习训练NMC的非局域转换策略，从而进一步改进算法性能。", "innovation": "本文创新性地将深度强化学习应用到NMC算法中，通过观察配置空间探索的能量变化作为奖励信号，以及局部最低能量景观的几何形状作为状态信号来训练算法策略。这种训练方法使得NMC算法能够超越基于MCMC的标准方法和非局域模拟退火算法，特别是在硬一致随机和无标度随机4-SAT基准测试中的残余能量、解决方案时间以及多样性评价上表现更好。", "conclusion": "通过强化学习训练的NMC方法能够有效地解决组合优化问题中的挑战，尤其是在计算相变附近最困难的基准中，证明了算法能够加速探索配置空间而不牺牲开发，显著提高了解的质量和多样性，并在实际应用中表现出更快的求解时间和更好的残留能量水平。"}
{"llm_update_time": "20250815", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.10581", "html_url": "https://arxiv.org/abs/2508.10581", "title": "技术报告：通过LLM赋能的副驾系统促进因果推理方法的应用", "title_en": "Technical Report: Facilitating the Adoption of Causal Inference Methods Through LLM-Empowered Co-Pilot", "authors": "Jeroen Berrevoets,Julianna Piskorz,Robert Davis,Harry Amad,Jim Weatherall,Mihaela van der Schaar", "background": "从医疗、经济到公共政策等众多领域中，基于观察数据估计治疗效果（TE）是一项既重要又复杂的任务。虽然机器学习和因果推断的最新进展产生了强大的估计技术，但由于需要深入理解因果假设、调整策略以及模型选择的专业知识，这些技术的采用仍受到限制。", "innovation": "本文介绍了一种开源副驾系统CATE-B，它采用大型语言模型（LLMs）在一个代理性框架内，指导用户进行治疗效果估计的全过程。CATE-B通过因果发现和基于LLM的边定向来构建结构因果模型，通过一种新颖的最小不确定性调整集标准来识别稳健的调整集，并针对因果结构和数据集特征选择合适的回归方法。此外，发布了一系列包含多样领域和因果复杂性的基准任务，以促进可重复性和评估。", "conclusion": "通过将因果推断与智能交互式协助相结合，CATE-B降低了进行严格因果分析的门槛，并为自动化治疗效果估计的新型基准奠定了基础。"}
{"llm_update_time": "20250815", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.10594", "html_url": "https://arxiv.org/abs/2508.10594", "title": "FreeGAD: 一种无需训练但有效的图异常检测方法", "title_en": "FreeGAD: A Training-Free yet Effective Approach for Graph Anomaly Detection", "authors": "Yunfeng Zhao,Yixin Liu,Shiyuan Li,Qingfeng Chen,Yu Zheng,Shirui Pan", "background": "图异常检测（GAD）旨在识别在图中与大多数节点偏差较大的节点，对于社交网络和电子商务等应用至关重要。尽管基于深度学习的图异常检测已有不少进展，但现有方法因复杂的训练过程和高资源消耗而导致部署成本高和扩展性差。实验表明，传统上认为至关重要的深度图异常检测方法的训练阶段，实际上对异常检测性能的贡献可能低于预期。", "innovation": "提出了一种名为FreeGAD的新颖的无需训练即可有效进行图异常检测的方法。FreeGAD利用亲和力门控残差编码器生成异常感知表示，并通过锚节点指导的统计偏差计算异常得分。这种方法不仅在多个跨领域基准数据集上实现了优越的异常检测性能、高效性和可扩展性，还无需任何训练和迭代优化，特别适合大规模图数据集的处理。", "conclusion": "实验结果表明，FreeGAD在不进行训练和迭代优化的情况下，仍能实现卓越的异常检测性能、效率和可扩展性，在多个跨领域基准数据集上证明了其在图异常检测任务中的有效性和优越性。"}
{"llm_update_time": "20250815", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.10628", "html_url": "https://arxiv.org/abs/2508.10628", "title": "基于项目反应理论的实例质量驱动数据分区超越随机采样", "title_en": "Beyond Random Sampling: Instance Quality-Based Data Partitioning via Item Response Theory", "authors": "Lucas Cardoso,Vitor Santos,José Ribeiro Filho,Ricardo Prudêncio,Regiane Kawasaki,Ronnie Alves", "background": "机器学习模型的稳健验证是必要的，但传统数据分区方法往往忽略了每个实例的内在质量。", "innovation": "本文提出了使用项目反应理论（IRT）参数来表征和指导模型验证阶段的数据分区策略。研究表明，基于IRT的分区策略有助于更好地理解和平衡模型偏差与方差之间的权衡，并揭示了 instances 的内在异质性和同一数据集内的信息性子集的存在。", "conclusion": "基于IRT创建的平衡分区有助于提高模型性能，尤其关注猜测参数，高猜测实例可以显著损害模型性能，导致准确率低于50%，而其他分区在同一数据集中可达到70%以上。"}
{"llm_update_time": "20250815", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.10583", "html_url": "https://arxiv.org/abs/2508.10583", "title": "基于GNN的统一深度学习", "title_en": "GNN-based Unified Deep Learning", "authors": "Furkan Pala,Islem Rekik", "background": "深度学习模型在医学影像领域常常难以保持泛化能力，特别是在存在领域断裂（domain-fracture）情景下，由于影像技术、采集协议、患者群体、人口统计信息和设备的不同导致分布变化。各医院可能需要训练具有不同学习任务、宽度和深度的特定模型来匹配本地数据。例如，一个医院可能使用欧几里得架构如MLP和CNN处理表格或网格图像数据，而另一个医院可能需要使用非欧几里得架构如图神经网络（GNN）处理不规则数据如脑连接图。如何在不同数据集上协同训练这些异构模型，并提升每一模型的泛化能力，仍然是一项开放性问题。", "innovation": "本文提出了统一学习（Unified Learning）这一新范式，即将每个模型编码为图表示，使其能够在共享的图学习空间中统一。图神经网络（GNN）则引导针对这些统一模型的优化。通过解耦个体模型的参数，并通过统一图神经网络（uGNN）控制它们，本方法支持在不同架构（MLP、CNN、GNN）和分布下的参数共享和知识迁移，从而改善泛化能力。评估结果表明，统一学习在模型训练于独特分布而测试于混合分布时提升了性能，展示了对未见过数据（具有大分布变化）的强大鲁棒性。", "conclusion": "在MorhpoMNIST和两个MedMNIST基准测试（PneumoniaMNIST和BreastMNIST）上进行的评估显示，当模型在独特分布下训练而在混合分布下测试时，统一学习能够显著提升性能，展示了强大的对未见过数据的鲁棒性。代码和基准测试在此可获取：this https URL"}
{"llm_update_time": "20250815", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.10598", "html_url": "https://arxiv.org/abs/2508.10598", "title": "Oops!... 他们又偷了：对拆分学习的攻击", "title_en": "Oops!... They Stole it Again: Attacks on Split Learning", "authors": "Tanveer Khan,Antonis Michalas", "background": "拆分学习（SL）是一种协作学习方法，它通过将数据保留在客户端并在客户端之间共享中间输出而不是完整数据，从而提高隐私性。然而，拆分学习的分布式特性引入了新的安全挑战，需要全面探索潜在攻击。已有研究对拆分学习的安全威胁进行了分类，根据攻击者的角色、隐私风险类型、数据泄露时间和潜在漏洞位置等因素进行划分，并分析了现有的防御措施，包括加密方法、数据修改方法、分布式技术和混合解决方案。尽管如此，现有防御的有效性和局限性仍然存在明显缺陷。因此，需要进一步识别开放挑战和未来方向，以指导改进拆分学习的隐私问题的研究和实践。", "innovation": "该研究系统地回顾了拆分学习的各种攻击，并根据攻击者的角色、隐私风险类型、数据泄露时间和潜在漏洞位置等因素进行分类。此外，它分析了现有的防御措施，包括加密方法、数据修改方法、分布式技术和混合解决方案，揭示了现有防御措施的安全漏洞，展示了它们的有效性和局限性，为改进拆分学习隐私问题和指导进一步研究提供了宝贵的信息。", "conclusion": "本研究揭示了现有防御措施的安全漏洞，展示了它们的有效性和局限性，并指出了需要进一步识别的开放挑战和未来方向。通过识别现有防御措施的安全缺口，本研究提供了有关拆分学习隐私问题的关键信息，并为未来研究提供了指导。"}
{"llm_update_time": "20250815", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.10608", "html_url": "https://arxiv.org/abs/2508.10608", "title": "多目标强化学习中减少方差的策略梯度方法", "title_en": "Variance Reduced Policy Gradient Method for Multi-Objective Reinforcement Learning", "authors": "Davide Guidobene,Lorenzo Benedetti,Diego Arapovic", "background": "多目标强化学习(MORL)是传统强化学习(RL)的一种扩展，旨在同时优化多个往往存在冲突的目标，而不是仅仅关注单一的奖励。这种做法对于需要在不同目标之间平衡权衡的复杂决策场景是至关重要的，如在最大化性能的同时最小化成本。在MORL中，目标通常通过非线性标量化函数进行组合。虽然在处理大且连续的状态-动作空间时，策略梯度方法(PGMs)是最有效的，但现有的MORL PGMs由于样本效率低下，需要大量数据才能有效运作。之前的尝试虽然改进了样本效率，但这些方法依赖于过于严格的假设，因此限制了PGMs在大状态-动作空间中的可扩展性。本研究通过实施减少方差的技术，解决了样本效率问题，同时保持了假设的一般性假设，从而解决了样本效率的不足。", "innovation": "本研究通过引入减少方差的技术，显著提高了多目标强化学习中策略梯度方法的样本效率，同时保持了假设的宽泛适用性，从而解决了传统方法在大状态-动作空间中的低样本效率问题，这为MORL提供了新的解决方案，提升了其在复杂决策场景中的适用性和效果。", "conclusion": "研究表明，通过创新地使用减少方差的技术，策略梯度方法在多目标强化学习中的样本效率得到了显著提升，这为未来在更复杂场景下的应用提供了潜在优势。"}
{"llm_update_time": "20250815", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.10644", "html_url": "https://arxiv.org/abs/2508.10644", "title": "基于条件信息瓶颈的多模态融合：克服讽刺检测中的捷径学习", "title_en": "Conditional Information Bottleneck for Multimodal Fusion: Overcoming Shortcut Learning in Sarcasm Detection", "authors": "Yihua Wang,Qi Jia,Cong Xu,Feiyu Chen,Yuhan Liu,Haotian Zhang,Liang Jin,Lu Liu,Zhichun Wang", "background": "多模态讽刺检测是一个复杂任务，需要区分不同模态中的细微互补信号，同时排除无关信息。许多先进方法依赖于从数据集中学习捷径，而不是提取与讽刺相关的特征。然而，实验证明这种方法会影响模型在真实场景中的泛化能力。另外，通过系统性的实验揭示了当前多模态融合策略在讽刺检测中的弱点，强调了关注有效融合的必要性。", "innovation": "提出了一种基于条件信息瓶颈的方法（MCIB），通过从MUStARD++$^{R}$中去除捷径信号来实现有效的多模态融合，从而提高讽刺检测性能，无需依赖捷径学习。", "conclusion": "实验结果表明，MCIB模型在讽刺检测中具有最佳性能，不受捷径学习的影响，并且该方法强调了有效多模态融合对于复杂情感识别的重要性。"}
{"llm_update_time": "20250815", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.10629", "html_url": "https://arxiv.org/abs/2508.10629", "title": "基于能量模型的蛋白质突变效应预测", "title_en": "Energy-Based Models for Predicting Mutational Effects on Proteins", "authors": "Patrick Soga,Zhenyu Lei,Yinhan He,Camille Bilodeau,Jundong Li", "background": "预测蛋白质结合自由能变化（$\triangle\triangle G$）是蛋白质工程和蛋白质-蛋白质相互作用（PPI）工程中药物发现的关键任务。已有研究表明蛋白质结合自由能变化与熵之间存在高相关性，通过侧链角度和残基身份等生物重要对象的概率估计来预测$\triangle\triangle G$。但全面估计蛋白质复合物的构象分布通常被认为是难以解决的问题。", "innovation": "本文提出了一个新的$\triangle\triangle G$预测方法，通过能量基础模型来估计复合物构象的概率，避免了直接估计构象分布的难题。作者新颖地将$\triangle\triangle G$分解为由逆折叠模型估算的序列基成分和由能量模型估算的结构基成分。这种方法假设结合态和未结合态之间的平衡来简化各状态相关性简化的估计。不同于基于深度学习的先前方法，该方法通过将序列对数似然比方法与统计力学中的$\triangle\triangle E$术语连接起来，引入了基于能量的物理归纳偏置，从而在$\triangle\triangle G$预测和针对SARS-CoV-2的抗体优化方面展现了优越性。", "conclusion": "我们的方法在$\triangle\triangle G$预测和针对SARS-CoV-2的抗体优化中相比现有的基于结构和序列的深度学习方法表现更优。"}
{"llm_update_time": "20250815", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.10210", "html_url": "https://arxiv.org/abs/2508.10210", "title": "基于可解释AI的方法用于监测动物健康", "title_en": "An Explainable AI based approach for Monitoring Animal Health", "authors": "Rahul Janaa,Shubham Dixit,Mrityunjay Sharma,Ritesh Kumar", "background": "奶农面临监测牛群健康和优化产量的难题，由于无法全面追踪农场中的所有动物，这一挑战尤为突出。这项研究旨在展示基于可解释机器学习方法的现代数据驱动农场实践，这些方法能解释奶牛的活动和行为。通过不断收集3轴加速度计传感器数据和使用稳健的机器学习方法和算法，农场主和研究人员可以获得关于奶牛活动的可操作信息，从而做出明智的决策并融入可持续实践。", "innovation": "该研究利用蓝牙物联网设备和4G网络进行无缝数据传输，即时分析结果，并通过可解释性框架解释模型性能。特别强调了加速度计时间序列数据的预处理，包括统计特性提取、信号处理技术以及使用滑动窗口技术提取的基于滞后的特征。此外，通过SHAP等解释性人工智能框架评估了多种超参数优化的机器学习模型在活动分类任务中的表现。k-最近邻分类器表现最佳，精度和标准差分别在训练集和测试集上达到最优。", "conclusion": "该研究不仅开发了可解释的人工智能模型来解释关键特征的重要性，而且还进行了这些特征的稳定性分析，这有助于开发可解释且实用的机器学习模型，从而促进可持续的畜牧业管理。"}
{"llm_update_time": "20250815", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.10646", "html_url": "https://arxiv.org/abs/2508.10646", "title": "SPHENIC：空间转录组学的拓扑启发多视图聚类方法", "title_en": "SPHENIC: Topology-Informed Multi-View Clustering for Spatial Transcriptomics", "authors": "Chenkai Guo,Yikai Zhu,Jing Yangum,Renxiang Guan,Por Lip Yee,Guangdun Peng,Dayu Hu", "background": "通过整合空间位置信息，空间转录组学聚类能够更全面地识别细胞亚群。尽管取得了进展，但现有方法存在两个主要局限：（i）拓扑学习通常只考虑单个细胞的表示或其相互作用图，而空间转录组学资料往往噪声较大，使这些方法容易受到低质量的拓扑信号的影响；（ii）对空间邻域信息不充分建模导致了低质量的空间嵌入。这些局限性促使我们提出了SPHENIC，一种新颖的空间持久同调增强邻域整合聚类方法。", "innovation": "SPHENIC通过在聚类网络中整合不变的拓扑特征来实现稳定的学习，形成了稳定的空间嵌入。此外，设计了空间约束和分布优化模块（SCDOM），该模块提高了细胞嵌入与其空间邻居之间的相似性，同时减少了与非邻居细胞的相似性，生成了更有利于聚类的空间嵌入。实验结果表明，SPHENIC在空间聚类任务上优于现有最先进的方法，提高了3.31%-6.54%.", "conclusion": "SPHENIC方法能够通过整合空间位置信息，提高细胞亚群识别的准确性，特别是相对于现有方法有显著的进步，在大量基准数据集上显示出更好的性能。"}
{"llm_update_time": "20250815", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.10587", "html_url": "https://arxiv.org/abs/2508.10587", "title": "使用生成对抗变换器进行自监督能源数据时域超分辨率", "title_en": "Self-Supervised Temporal Super-Resolution of Energy Data using Generative Adversarial Transformer", "authors": "Xuanhao Mu,Gökhan Demirel,Yuzhe Zhang,Jianlei Liu,Thorsten Schlachter,Veit Hagenmeyer", "background": "基于能源系统模型在能源网络设计和运营中需要时间序列的频率调整以克服时间粒度差距。传统上，上采样方法虽然计算高效，但常导致信息损失或噪音增加。而高级模型如时间序列生成模型、超分辨率模型和插补模型虽然潜力大，但同样面临根本性挑战。", "innovation": "本文提出了一种新的方法，利用生成对抗变换器（GATs）进行上采样，无需任何真实高分辨率数据即可进行训练。此方法相较于传统插值方法，能够降低9%的上采样任务的均方根误差（RMSE），同时提高模型预测控制（MPC）应用场景的准确性13%。", "conclusion": "通过引入生成对抗变换器方法，解决上采样过程中存在的问题，并显著提高了上采样的准确性和相关应用场景的效果。"}
{"llm_update_time": "20250815", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.10684", "html_url": "https://arxiv.org/abs/2508.10684", "title": "MDNS: Masked Diffusion Neural Sampler via Stochastic Optimal Control", "title_en": "MDNS: Masked Diffusion Neural Sampler via Stochastic Optimal Control", "authors": "Yuchen Zhu,Wei Guo,Jaemoo Choi,Guan-Horng Liu,Yongxin Chen,Molei Tao", "background": "该研究关注的是通过神经采样器从目标概率质量函数π∝e^-U对应的离散状态空间中生成样本的问题，该概率质量函数中的常数已知。这在统计物理、机器学习和组合优化等领域至关重要。当状态空间非常大且分布具有多个模态时，解决这一问题具有挑战性。为了应对这种挑战，提出了一个新颖的框架MDNS，通过一系列学习目标对两类路径测度进行对齐，基于连续时间马尔可夫链的随机最优控制理论进行训练。", "innovation": "提出了名为MDNS的Masked Diffusion Neural Sampler框架，该框架通过基于连续时间马尔可夫链的随机最优控制来训练离散神经采样器，进而能够更有效地解决高维且具有多个模态的离散采样问题。MDNS在各种具有不同统计特性的分布上进行了广泛实验，显示出较高的高效性和可扩展性，且在与基于学习的基线方法对比中表现出显著的优势。", "conclusion": "MDNS不仅展示了高效和可扩展性的特点，还在多个实验中证明了其在难以处理的概率分布采样问题上的优越性能。此外，还进行了全面的消融和扩展研究，证明了该框架的有效性和潜力。"}
{"llm_update_time": "20250815", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.10649", "html_url": "https://arxiv.org/abs/2508.10649", "title": "用于土地覆盖不透水面变化预测的空间扩散模型", "title_en": "Geospatial Diffusion for Land Cover Imperviousness Change Forecasting", "authors": "Debvrat Varshney,Vibhas Vats,Bhartendu Pandey,Christa Brelsford,Philipe Dias", "background": "土地覆盖无论是当前还是未来对许多重要的地球系统过程都有显著影响。例如，不透水面会加速地表水径流并减少地下水分渗，从而影响区域水文和洪水风险。然而，在未来气候情景下，虽然区域地球系统模型在高分辨率预测水文和大气过程方面技能不断提升，但预测土地利用和土地覆盖变化（LULC）的能力却滞后。本文探讨了利用生成人工智能（GenAI）构建一种新范式来进行LULC预测的方法，将其转化为基于历史和辅助数据源的数据合成问题。", "innovation": "本文提出了一种新的范式，使用生成人工智能（GenAI）来预测土地覆盖变化。具体而言，通过训练一个扩散模型来预测不透水覆盖物的十年变化，并将其性能与假设无变化的基线进行比较。这种方法表明，这种生成模型可以从历史数据中捕捉到具有预测未来变化意义的空间-时间模式。未来的研究计划将结合关于地球的物理特性信息，并通过驱动变量支持模拟不同情景。", "conclusion": "本文所提出的基于扩散模型的生成方法，在平均分辨率下可以比假设无变化的基线模型更准确地预测不透水覆盖物的变化。这种模型能够捕捉到历史数据中的时空模式，从而有助于未来土地覆盖变化的预测。未来研究将进一步整合物理属性信息和驱动变量，以支持情景模拟。"}
{"llm_update_time": "20250815", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.10732", "html_url": "https://arxiv.org/abs/2508.10732", "title": "APFL: 分析化个性化联邦学习通过双流最小二乘", "title_en": "APFL: Analytic Personalized Federated Learning via Dual-Stream Least Squares", "authors": "Kejia Fan,Jianheng Tang,Zhirui Yang,Feijiang Han,Jiaxu Li,Run He,Yajiang Huang,Anfeng Liu,Houbing Herbert Song,Yunhuai Liu,Huiping Zhuang", "background": "个性化联邦学习(PFL)旨在通过协作训练将个性化模型交付给个体客户端。现有PFL方法常受到非IID数据的影响，这严重阻碍了集体泛化，进而影响后续的个性化处理。", "innovation": "本文提出一种通过双流最小二乘方法的分析化个性化联邦学习(APFL)，利用一个冻结的骨干模型进行特征提取，并在此基础上开发双流分析模型以实现集体泛化和个体个性化。APFL结合了共享的主要流以在所有客户端之间实现全局泛化，并为每个客户端提供专用的精炼流以进行本地个性化。这种方法理论上保证了异方差不变性，意味着每个个性化模型在所有其他客户端数据异方差性变化的情况下保持不变。实验证明APFL相比最先进的基线具有至少1.10%-15.45%的准确性优势。", "conclusion": "APFL通过结合双流最小二乘方法实现了理想中的异方差不变性，既保证了集体泛化又实现了个性化，并在准确性上优于现有最佳基准。"}
{"llm_update_time": "20250815", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.10235", "html_url": "https://arxiv.org/abs/2508.10235", "title": "通过上下文学习打破加密方案，Transformer 能行吗？", "title_en": "Can Transformers Break Encryption Schemes via In-Context Learning?", "authors": "Jathin Korrapati,Patrick Mendoza,Aditya Tomar,Abein Abraham", "background": "上下文学习（ICL）已成为基于Transformer的语言模型的一个强大功能，使它们能够在推断时仅根据少量示例进行任务执行，而无需任何参数更新。先前的研究表明，Transformer可以从上下文直接泛化到简单的函数类中，包括线性函数、决策树甚至神经网络，这集中在数值或符号推理上。本文探讨了如何将ICL应用于密码功能学习领域，特别是针对仅字母替换和维吉尼亚密码这类私钥加密方案。这些密码涉及固定但隐藏的双射映射，需要模型根据少量的（密文，明文）对推断出潜在的替换并解码新的密文单词。这种设置提供了一个有结构的推理挑战，适合评估Transformer在ICL范式下的归纳偏置和泛化能力。", "innovation": "本文提出了一种新的应用ICL的方法，将其应用于密码学领域的功能学习，特别是在仅字母替换和维吉尼亚密码方面。这扩展了先前对Transformer在数值或符号推理上的应用，展示了其在有结构的推理挑战中的潜力。", "conclusion": "本文展示了Transformer在密文字节替换和维吉尼亚密码解码方面的泛化能力，通过少量样本就能学习到潜在的映射关系。这评估了Transformer在ICL设置下的归纳偏置和泛化能力，证实了ICL在加密解码任务中的有效性。"}
{"llm_update_time": "20250815", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.10651", "html_url": "https://arxiv.org/abs/2508.10651", "title": "基于逻辑导向的Weisfeiler-Leman 变种和表格式化方法的图学习", "title_en": "Graph Learning via Logic-Based Weisfeiler-Leman Variants and Tabularization", "authors": "Reijo Jaakkola,Tomi Janhunen,Antti Kuusisto,Magdalena Ortiz,Matias Selin,Mantas Šimkus", "background": "本文提出了一个基于Weisfeiler-Leman算法变种的图表数据分类的新方法。具体而言，使用Weisfeiler-Leman的变体将图表数据转换为表格式数据，然后使用适用于表格式数据的方法进行处理。通过其底层逻辑框架的修改，研究了广泛的一类Weisfeiler-Leman变体，并建立了它们表达能力的精确理论描述。通过在十二个具有不同领域范围的基准数据集上测试两种选定的变体来评估该方法的效果。研究结果表明，该方法的性能在准确性上与最先进的图神经网络和图内核相当，但在某些数据集上更高效。对于图数据集，还简要讨论了直接提取可解释的模态逻辑公式的可能性", "innovation": "本文主要创新点在于提出了一种新颖的图分类方法，该方法通过Weisfeiler-Leman算法变体将图数据转化为表数据，再用表数据处理方法进行分类，并且精确地理论化了该方法的表达能力。同时，验证了该方法与当前最先进的图神经网络和图内核方法具有相当的准确度，并且在某些情况下更为高效。此外，还探讨了直接从图数据集中提取可解释的模态逻辑公式的方法", "conclusion": "本文提出的方法在多个基准数据集上达到了与最先进的图神经网络和图内核相当的分类准确率，但在某些数据集上表现更优，并且具有更好的时间和内存效率。该方法还具有直接从图数据中提取可解释的模态逻辑公式的潜力，这使得该方法具有实际应用价值"}
{"llm_update_time": "20250815", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.10751", "html_url": "https://arxiv.org/abs/2508.10751", "title": "Pass@k 训练：针对大型推理模型探索与利用的适应性平衡", "title_en": "Pass@k Training for Adaptively Balancing Exploration and Exploitation of Large Reasoning Models", "authors": "Zhipeng Chen,Xiaobo Qin,Youbin Wu,Yue Ling,Qinghao Ye,Wayne Xin Zhao,Guang Shi", "background": "强化学习（Reinforcement Learning，RL）中的可验证奖励（RLVR）通常采用Pass@1作为奖励方式，但这种奖励方式在平衡探索与利用方面存在挑战，导致政策倾向于保守行为，可能陷入局部最优解。因此，选择合适的奖励指标非常重要。虽然Pass@k已用于评估，但其与大型语言模型（LLM）在RLVR中的探索能力之间的联系仍未充分关注。本文通过Pass@k进行训练，研究其探索能力的提升，并进行分析求解Pass@k的优势，揭示了探索和利用并非固有的冲突目标，而是可以互相增强。", "innovation": "本文提出了一种新型的Pass@k训练方法，通过此项方法直接设计优势函数来探索RLVR，从而实现了对探索与利用的适应性平衡，这是一个潜在的重要未来方向。这种方法还提供了有效的解析解决方案，有助于优化RLVR中的政策模型。", "conclusion": "本文的研究展示了Pass@k训练方法对于探索与利用之间的适应性平衡的有效性，并明确指出了解决此类问题的一种潜力方法。未来的工作将侧重于进一步探索和优化优势设计，以更好地适应不同的场景和需求。"}
{"llm_update_time": "20250815", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.10804", "html_url": "https://arxiv.org/abs/2508.10804", "title": "非平稳 restless 多臂老虎机及其可证明保证", "title_en": "Non-Stationary Restless Multi-Armed Bandits with Provable Guarantee", "authors": "Yu-Heng Hung,Ping-Chun Hsieh,Kai Wang", "background": "传统的 restless 多臂老虎机（RMABs）通常假设每个臂遵循固定状态转换和奖励的平稳马尔可夫决策过程（MDP），但在实际应用如医疗和推荐系统中，这些假设往往由于非平稳动态而失效，给传统的 RMAB 算法带来了显著挑战。", "innovation": "提出了一个结合滑动窗口强化学习（RL）和上确信界（UCB）机制的 \rmab 算法，以同时学习状态转换及其变化。通过引入放松的遗憾度定义，证明该算法取得了 $\tilde{\text{O}}(N^2 B^{\frac{1}{4}} T^{\frac{3}{4}})$ 的遗憾度界，填补了非平稳 RMAB 问题的理论框架空白。", "conclusion": "提出了一个针对非平稳 RMAB 问题的算法，并首次提供了理论保证，展示了在非平稳性的假设下同时学习状态转换和变化的可能性。"}
{"llm_update_time": "20250815", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.10758", "html_url": "https://arxiv.org/abs/2508.10758", "title": "原生可训练稀疏注意力机制用于层次点云数据集", "title_en": "Natively Trainable Sparse Attention for Hierarchical Point Cloud Datasets", "authors": "Nicolas Lapautre,Maria Marchenko,Carlos Miguel Patiño,Xin Zhou", "background": "在大型物理系统数据集上利用变压器的潜力受到注意力机制二次复杂度的影响。本文探讨了将Erwin架构与原生稀疏注意力(NSA)机制结合，以提高大规模物理系统中变压器模型的效率和感受野。研究针对二次注意复杂度的挑战，适应NSA机制用于非顺序数据，并在物理科学的三个数据集（宇宙学模拟、分子动力学和气压建模）上进行了评估，结果匹配或超过了原始Erwin模型的性能。此外，还重新实现了Erwin论文中的实验结果以验证其实现。", "innovation": "本文创新性地结合了Erwin架构与原生稀疏注意力(NSA)机制，针对非顺序数据集改善了变压器模型的效率和感受野，适应了NSA机制并进行了大规模物理系统的评估，验证了模型性能与原始模型相当或更优，并重新实现了原论文的实验以确保结果的可靠性。", "conclusion": "通过将Erwin架构与NSA机制结合，提高变压器在大型物理系统中的应用效率和性能。该方法在三种物理数据集上达到了匹配或超过原始模型的性能，并通过重新实现原论文实验验证了方法的有效性。"}
{"llm_update_time": "20250815", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.10785", "html_url": "https://arxiv.org/abs/2508.10785", "title": "增强节点级别图异常检测中自动编码器的公平性", "title_en": "Enhancing Fairness in Autoencoders for Node-Level Graph Anomaly Detection", "authors": "Shouju Wang,Yuchen Song,Sheng'en Li,Dongmian Zou", "background": "图异常检测（GAD）在各个领域变得越来越重要。图神经网络（GNNs）的快速发展使得GAD方法取得了显著的性能提升。然而，GAD中的公平性考量仍然被大大的忽视。基于GNN的GAD模型可能会继承和放大训练数据中存在的偏见，可能导致不公平的结果。尽管现有努力集中在开发公平的GNN上，大多数方法针对节点分类任务，使用较为简单的层架构而非最常用的基于自动编码器的结构。因此，针对基于自动编码器的GAD模型中的公平性问题，本文提出了DECAF-GAD框架，在保持GAD性能的同时减少了偏见。", "innovation": "本文提出了DECAF-GAD框架，这是一种通过结构性因果模型（SCM）分离敏感属性来减轻偏见并保留GAD性能的框架。基于这种因果框架，我们提出了一个特殊的自动编码器架构以及一个指导公平性的损失函数。通过在合成数据集和真实数据集上的广泛实验，DECAF-GAD不仅实现了与基线GAD方法相当的异常检测性能，还显著提高了公平性指标。", "conclusion": "通过DECAF-GAD框架，本文在保持GAD性能的同时解决了基于自动编码器的GAD模型中的公平性问题，通过结构性因果模型分离敏感属性，提出了一种特殊的自动编码器架构和公平性引导的损失函数，并通过实验验证了其有效性和优越性。"}
{"llm_update_time": "20250815", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.10701", "html_url": "https://arxiv.org/abs/2508.10701", "title": "REFN: 网络驱动的强化学习框架以对抗1天/多天漏洞", "title_en": "REFN: A Reinforcement-Learning-From-Network Framework against 1-day/n-day Exploitations", "authors": "Tianlong Yu,Lihong Liu,Ziyi Zhou,Fudu Xing,Kailong Wang,Yang Yang", "background": "由于大规模部署和延迟的补丁程序（平均补丁时间超过60天），网络设备受到1天或n天漏洞的利用会构成严重威胁。现有的防御措施，包括基于主机的补丁和基于网络的过滤，存在可扩展性差、兼容性问题尤其是嵌入式或遗留系统难以适应，以及部署过程易出错等问题。", "innovation": "REFN提出了一种新颖的框架，利用强化学习（RL）训练大规模语言模型（LLMs）自主生成网络过滤器，以防止1天或n天漏洞的利用。REFN通过在线网络奖励驱动的RL，而不是传统的人工反馈（RLHF）来确保可扩展性，统一在边缘安全网关（Amazon Eero）上部署，使用实际网络流量的在线验证来保证稳健性。该框架通过基于代理的问答知识蒸馏、从VNF管道中的基于语言的漏洞描述翻译成网络执行、以及在线代理验证等方法，解决了训练LLMs防止利用的三大核心挑战。", "conclusion": "评估表明，REFN在准确性和效率方面表现出色，在22类1天或n天漏洞中其准确率比现有方法高21.1%，平均补丁时间仅为3.65小时，可以轻松扩展到10,000台设备。该框架标志着训练LLMs快速防止大规模1天或n天漏洞的一次初步尝试。"}
{"llm_update_time": "20250815", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.10815", "html_url": "https://arxiv.org/abs/2508.10815", "title": "在线高斯过程数据减少标准的比较", "title_en": "Comparison of Data Reduction Criteria for Online Gaussian Processes", "authors": "Thore Wietzke,Knut Graichen", "background": "高斯过程（GPs）由于其灵活性和对不确定性的量化能力，在回归和系统识别中被广泛使用。然而，它们的计算复杂度限制了它们在大数据集上的应用。在连续的数据流场景中，数据点不断增加，即使是稀疏的高斯过程也难以处理。", "innovation": "该研究提供了几种数据减少标准的统一比较，分析了它们的计算复杂度和减少行为。提出的接受标准进一步筛选出冗余数据点。该工作为选择适合在线高斯过程算法的标准提供了实际指南。", "conclusion": "研究结果表明，通过统一比较不同的数据减少标准并提出接受标准，为选择适当的在线高斯过程的数据减少标准提供了实用指导。"}
{"llm_update_time": "20250815", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.10775", "html_url": "https://arxiv.org/abs/2508.10775", "title": "IBEX: 有限数据下探索信息瓶颈的粗细分子生成方法", "title_en": "IBEX: Information-Bottleneck-EXplored Coarse-to-Fine Molecular Generation under Limited Data", "authors": "Dong Xu,Zhangfan Yang,Jenna Xinyi Yao,Shuangbao Song,Zexuan Zhu,Junkai Ji", "background": "基于结构的药物发现越来越多地依赖于三维生成模型，但这些模型受到公共可用的蛋白质-配体复合体数据稀缺的限制。几乎所有现有的流程都难以学会泛化的几何先验知识，并且过度拟合于训练集偏差。因此，本文提出了一种名为IBEX的粗细分子生成流程，该流程利用信息瓶颈理论来解决蛋白质-配体复合体数据在结构基药物设计领域中的短缺问题，专注于在有限的数据条件下提高模型的生成能力与泛化性能。", "innovation": "IBEX流程采用了PAC-Bayesian信息瓶颈理论来量化每个样本的信息密度，揭示了不同遮掩策略对泛化能力的影响，并指出与传统的从头生成任务相比，限制性构架跳跃任务赋予模型更大的有效容量和更好的迁移性能。IBEX保留了原有的TargetDiff架构和超参数进行训练，以生成与结合袋兼容的分子，然后应用L-BFGS优化步骤来精确调整每个构象，优化五个物理相关的项并调整六个平移和旋转自由度，仅通过这些改进措施，IBEX在CBGBench CrossDocked2020基准上的零样本对接成功率从53%提高到64%，平均Vina评分从-7.41 kcal/mol提高到-8.07 kcal/mol，并在57个口袋中获得了最佳的中值Vina能量，而原来的TargetDiff仅在3个口袋中获得了最好成绩。IBEX还在QTED、有效性和多样性方面达到了最先进的水平，并显著减少了外推误差。", "conclusion": "IBEX通过创新的信息瓶颈探索方法，显著提高了基于有限数据进行分子生成和优化的能力，克服了传统生成模型在小数据集上的不足，在多种评估指标上取得了卓越的性能，为未来的药物设计提供了新的思路和方法。"}
{"llm_update_time": "20250815", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.10824", "html_url": "https://arxiv.org/abs/2508.10824", "title": "增强记忆的变换器：从神经科学原理到技术解决方案的系统性回顾", "title_en": "Memory-Augmented Transformers: A Systematic Review from Neuroscience Principles to Technical Solutions", "authors": "Parsa Omidi,Xingshuai Huang,Axel Laborieux,Bahareh Nikpour,Tianyu Shi,Armaghan Eshaghi", "background": "记忆是智能的基础，使学习、推理和适应成为生物系统和人工系统的可能。尽管变换器架构在序列建模方面表现出色，但在长范围上下文保留、持续学习和知识整合方面面临重要限制。本文综述了神经科学原则（动态多时尺度记忆、选择性注意和巩固）与工程增强变换器技术进步之间的统一框架。近期研究按照功能性目标（上下文扩展、推理、知识整合、适应）、记忆表示（参数编码、状态基、显式、混合）和集成机制（注意力融合、门控控制、关联检索）三个分类维度进行组织。对核心记忆操作（读取、写入、忘记和容量管理）的分析表明，从静态存储器向适应性、测试时学习系统转变的趋势。指出可扩展性和干扰等持久挑战，并提出分层缓冲和惊喜门控更新等新兴解决方案。", "innovation": "本文提出了一种统一框架，将神经科学原则与工程增强变换器技术进步相结合，组织了近期进展，并揭示了从静态存储器向适应性、测试时学习系统转变的趋势，同时还识别了可扩展性和干扰等挑战，并提出了解决方案。", "conclusion": "本文的综合分析为认知启发的、终身学习变换器架构的发展提供了路线图。"}
{"llm_update_time": "20250815", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.10866", "html_url": "https://arxiv.org/abs/2508.10866", "title": "高效验证的数据归属证明", "title_en": "Efficiently Verifiable Proofs of Data Attribution", "authors": "Ari Karchmer,Seth Neel,Martin Pawelczyk", "background": "数据归属方法旨在回答有用的反事实问题，例如“如果模型使用不同的数据集进行训练，它的预测会是什么？”。然而，通过经验影响或“datamodeling”等技术估计数据归属模型仍然非常计算密集，这引起了一个关键的信任问题：如果只有少数计算资源丰富的方才能获得数据归属，资源受限的方如何能够信任所获得的归属是“好的”，特别是在用于重要下游应用（例如数据定价）时？", "innovation": "本文提出了一种交互式验证范式来解决数据归属的信任问题。不可信且计算能力强的证明者学习数据归属，并与资源受限的验证者进行交互证明。我们的主要成果是在概率近似正确的（PAC）验证意义上提供了形式的完备性、正确性和效率保证的协议。特别是，如果证明者和验证者都遵循该协议，验证者以概率1减去δ接受ε接近最优数据归属（以均方误差为标准）。相反，如果证明者偏离协议，即使计算无限，这也将被检测到（或者仍然向验证者提供数据归属），其概率最高为δ。重要的是，我们的协议通过验证者需要进行独立模型重训的数量来衡量的工作量仅随着1/ε线性增长，与数据集大小无关。从技术层面来看，我们的结果适用于验证证明者通过布尔超立方体计算的任何线性函数，使得它们广泛应用于各种归属任务中。", "conclusion": "我们提出了一种交互式验证范式，通过证明者和验证者的交互证明，确保验证者能够以形式化和高效的验证方式检查数据归属的准确性，从而解决计算资源有限方对数据归属的信任问题。"}
{"llm_update_time": "20250815", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.09994", "html_url": "https://arxiv.org/abs/2508.09994", "title": "聪明行事，而非用力：部分抑制的对抗性攻击", "title_en": "Whisper Smarter, not Harder: Adversarial Attack on Partial Suppression", "authors": "Zheng Jie Wong,Bingquan Shen", "background": "当前，自动语音识别（ASR）模型被广泛应用于多种场景。然而，最近的研究表明，这些模型可能面临对抗性攻击的风险，这种攻击有可能会削弱或干扰模型的输出。本文探讨了这些攻击的稳健性，并研究如何减少它们的可见性。我们还发现，通过将优化目标从完全压制改为部分压制，可以使攻击进一步不可感知。同时，本文还探讨了对抗性攻击的防护措施，并表明低通滤波器可能作为一种有效的防护手段。", "innovation": "本文通过将优化目标从完全压制改为客户抑制，进一步减少了对抗性攻击的可见性。此外，还引入了一种低通滤波器来作为对抗性攻击的有效防御。", "conclusion": "本文探讨了对抗性攻击的稳健性，提出了部分抑制优化目标的方法以减少攻击的可见性，并展示了低通滤波器作为一种有效的防御策略的可能性。"}
{"llm_update_time": "20250815", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.10899", "html_url": "https://arxiv.org/abs/2508.10899", "title": "一个用于从文献中提取知识先验的 Dataset", "title_en": "A Dataset for Distilling Knowledge Priors from Literature for Therapeutic Design", "authors": "Haydn Thomas Jones,Natalie Maus,Josh Magnus Ludan,Maggie Ziyu Huan,Jiaming Liang,Marcelo Der Torossian Torres,Jiatao Liang,Zachary Ives,Yoseph Barash,Cesar de la Fuente-Nunez,Jacob R. Gardner,Mark Yatskar", "background": "AI技术可以大幅缩短药物设计时间并提高新药的有效性。然而，使用模拟器探索广泛的药物设计空间可能会忽略实验先验条件，从而违反隐含的约束条件。例如，对GuacaMol基准上的多种模型进行的新分析显示，超过60%的建议分子具有高致突变性的可能性。因此，研究人员需要一种新的方法来为药物设计任务提取可靠的先验知识，从而指导药物设计。", "innovation": "本文提出了一种名为\textbackslash ourdataset\textbackslash 的数据集，该数据集从相关文献中提取了有用的先验知识，并通过LLM管道来识别和总结关键信息。该数据集包含3.23亿对自然语言事实及对应的实体表示，并用于训练LLM、CLIP和LLava等架构以处理药物设计任务。实验结果显示，使用该数据集预训练的模型在TDC任务中的表现优于具有更大参数量的模型，尤其是用于指导GuacaMol中的新型分子设计时，提取的先验知识能够生成更为安全且几乎同样有效的候选分子。", "conclusion": "研究人员认为，\textbackslash ourdataset\textbackslash 可以极大地促进药物设计，通过提供可靠的先验知识来指导分子设计过程，从而降低违规风险并提高新药的有效性。为了促进这一领域的研究，该数据集已对外发布。"}
{"llm_update_time": "20250815", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.10000", "html_url": "https://arxiv.org/abs/2508.10000", "title": "AutoGeTS：基于知识的文本合成自动化生成以提高文本分类", "title_en": "AutoGeTS: Knowledge-based Automated Generation of Text Synthetics for Improving Text Classification", "authors": "Chenhao Xue,Yuanzhe Jin,Adrian Carrasco-Revilla,Joyraj Chakraborty,Min Chen", "background": "在为实际应用开发文本分类模型时，一个主要挑战是难以为所有文本类别收集足够的数据。本研究通过利用大规模语言模型（LLMs）生成合成数据，并使用这些数据提高模型的性能，无需等待更多的实际数据被收集和标注。", "innovation": "提出了一个自动工作流AutoGeTS，采用三种搜索策略进行实验以找到生成更有效的合成数据的输入示例。根据类别特征使用实验结果来指导一个集成算法选择搜索策略，该综合方法在使用LLMs改进分类模型方面比单一策略更加有效。", "conclusion": "研究进一步证明，此集成方法在使用LLMs改进分类模型方面比单一策略更加有效，是解决实际应用中数据不足问题的一种有效方法。"}
{"llm_update_time": "20250815", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.09325", "html_url": "https://arxiv.org/abs/2508.09325", "title": "SegDAC: 由分割驱动的演员-评论家方法用于视觉增强学习", "title_en": "SegDAC: Segmentation-Driven Actor-Critic for Visual Reinforcement Learning", "authors": "Alexandre Brown,Glen Berseth", "background": "视觉增强学习（RL）具有挑战性，因为需要从高维输入和噪声奖励中学习感知和动作。尽管存在大规模的感知模型，但如何有效地将它们集成到RL中以实现视觉泛化和提高样本效率仍不明确。马skill3是一个复杂的视觉泛化基准，涵盖了在强烈视觉干扰下多种操作任务，现有方法在此场景下性能一般。", "innovation": "提出了SegDAC（由分割驱动的演员-评论家方法），该方法采用Segment Anything (SAM) 进行对象中心分解，并通过文本提示利用YOLO-World进行语义定位。SegDAC包含一种基于变压器的新颖架构，支持每个时间步动态数量的分割，并使用在线RL学习关注哪些分割，无需使用人工标签。这种方法在多种操作任务中表现出显著更好的视觉泛化能力，在最困难的设置下性能提高了两倍，并且在所有任务中都达到了或超过了先前的方法在样本效率上的表现。", "conclusion": "SegDAC在马skill3复杂基准上验证了其有效性和优越性，展示出了更强的视觉泛化能力和样本效率。"}
{"llm_update_time": "20250815", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.09991", "html_url": "https://arxiv.org/abs/2508.09991", "title": "连接AI创新与医疗需求：BC癌症登记处采用现代NLP的经验教训", "title_en": "Bridging AI Innovation and Healthcare Needs: Lessons Learned from Incorporating Modern NLP at The BC Cancer Registry", "authors": "Lovedeep Gondara,Gregory Arbour,Raymond Ng,Jonathan Simkin,Shebnum Devji", "background": "自动化从临床文档中提取数据提供了在医疗服务环境中提高效率的巨大潜力，然而，部署自然语言处理（NLP）解决方案面临着实际挑战。基于在英国哥伦比亚癌症登记处（BCCR）实施各种NLP模型进行信息提取和分类任务的经验，本文分享了项目生命周期中获得的关键教训。文章强调了根据明确的业务目标而不是仅仅技术准确性来定义问题的重要性，采用迭代开发方法，并从项目开始就促进跨学科的深度合作与共同设计，涉及领域专家、最终用户和机器学习专家。进一步的见解还强调了在适当情况下选择实用模型（包括混合方法和较简单的方法）、对高质量数据（代表性和漂移、标注）的严格关注、以及涉及人工复核和持续审计的稳健错误缓解策略，以及构建组织对人工智能的透彻认识。这些实用考虑不仅涵盖了癌症登记处，还为寻求成功实施人工智能/NLP解决方案以提高数据管理流程和最终提升患者护理和公共卫生结果的医疗组织提供了指导。", "innovation": "文章分享了在项目生命周期中获得的关键教训，包括根据明确的业务目标来定义问题，采用迭代开发方法，从项目开始就促进跨学科的深度合作与共同设计，以及选择实用模型、严格关注高质量数据和稳健的错误缓解策略。这些实用的考虑将有助于医疗组织成功实施人工智能/NLP解决方案，提升数据管理和改善患者护理和公共卫生结果。", "conclusion": "文章总结得出，在医疗环境中实施NLP解决方案面临着实际挑战，但通过综合考虑业务需求、采用迭代方法、促进跨学科合作和选择实用模型，可以克服这些挑战。这种方式不仅适用于癌症登记处，对其他医疗组织来说也提供了宝贵的指导，以实现数据管理流程的改进和最终改善患者护理和公共卫生结果。"}
{"llm_update_time": "20250815", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.09999", "html_url": "https://arxiv.org/abs/2508.09999", "title": "XFacta: 适用于多模态大语言模型的多模态虚假信息检测的当代现实数据集和评估", "title_en": "XFacta: Contemporary, Real-World Dataset and Evaluation for Multimodal Misinformation Detection with Multimodal LLMs", "authors": "Yuzhuo Xiao,Zeyu Han,Yuhan Wang,Huaizu Jiang", "background": "社交媒体上多模态虚假信息的快速传播要求开发更有效和更鲁棒的检测方法。虽然利用多模态大语言模型（MLLMs）的最新进展展示了解决这一挑战的潜力，但现有方法的具体瓶颈（证据检索 v.s. 原因推理）尚不明确，这阻碍了本领域进一步的发展。此外，现有基准数据集要么包含过时的事件导致与当前社交媒体情景之间的评估偏差（MLLMs 可简单地记忆这些事件），要么是人为合成的，无法反映真实世界的虚假信息模式。存在多模态大语言模型方法设计策略的综合分析不足。", "innovation": "引入了XFacta，这是一种更符合实际环境的当代数据集，更适合评估基于MLLM的检测器。系统性评估各种基于MLLM的虚假信息检测策略，评估模型在不同架构和规模下的表现，并与现有检测方法进行基准测试。在此基础上，进一步建立了一种半自动的检测-在-环框架，以不断更新XFacta的内容，保持其当代的相关性。进行了分析并提供了进一步推动该领域发展的宝贵见解和实践。", "conclusion": "提供的分析为推动多模态虚假信息检测领域的发展提供了有价值的见解和实践。代码和数据已公开共享。"}
{"llm_update_time": "20250815", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.10004", "html_url": "https://arxiv.org/abs/2508.10004", "title": "用户对注意力可视化感知：对基于实证医学文献解释性的影响", "title_en": "User Perception of Attention Visualizations: Effects on Interpretability Across Evidence-Based Medical Documents", "authors": "Andrés Carvallo,Denis Parra,Peter Brusilovsky,Hernan Valdivieso,Gabriel Rada,Ivania Donoso,Vladimir Araujo", "background": "注意力机制是Transformer架构的核心组成部分，它不仅能提升模型性能，还能作为解释模型预测的方式，通过关注权重关联输入特征。在证据医学领域，这种解释有助于医生理解和使用用于分类医学文献的AI系统。然而，目前尚无一致共识认为注意力权重能提供有效的解释，此外，有关如何通过可视化提高其作为解释工具的有效性的研究也较少。", "innovation": "本研究通过用户实验评估了基于注意力的解释在医学文献分类中的有效性，并探讨了不同可视化方式对其实用性的感知差异。研究结果表明，Transformer模型（XLNet）能准确分类文档，但其注意力权重并未被视为特别有助于解释预测。用户的感知在不同可视化方式下存在显著差异，偏好更直观的可视化格式，如文本亮度或背景色，而非精确编码。", "conclusion": "本研究结果不支持注意力权重作为解释工具的整体效用，但表明其有效性感知受到其视觉呈现方式的影响。"}
{"llm_update_time": "20250815", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.09995", "html_url": "https://arxiv.org/abs/2508.09995", "title": "zERExtractor：一种从科学文献中自动提取酶催化反应数据的平台", "title_en": "zERExtractor:An Automated Platform for Enzyme-Catalyzed Reaction Data Extraction from Scientific Literature", "authors": "Rui Zhou,Haohui Ma,Tianle Xin,Lixin Zou,Qiuyue Hu,Hongxi Cheng,Mingzhi Lin,Jingjing Guo,Sheng Wang,Guoqing Zhang,Yanjie Wei,Liangzhen Zheng", "background": "酶动力学文献的快速增长速度超过了主要生物化学数据库的维护能力，这为基于AI的建模和知识发现设定了很大的障碍。为了解决这个挑战，该论文介绍了一个名为zERExtractor的自动化和可扩展平台，用于全面提取科学文献中的酶催化反应和活性数据。", "innovation": "zERExtractor采用统一的模块化架构，支持最新的模型（包括大型语言模型）的插拔式集成，使系统能够随着AI的进步不断演进。该平台结合了领域适配的深度学习、先进的OCR、语义实体识别和基于提示的LLM模块，再加上人工专家修正，能够从多种文档格式中提取动力学参数（例如kcat, Km）、酶序列、底物SMILES表示、实验条件、以及分子图等信息。此外，通过结合AI辅助注释、专家验证和迭代改进的主动学习策略，系统能够迅速适应新的数据来源。它还提供了一个基准数据集包含超过1,000个注释表格和5,000个生物领域数据，包含270篇P450相关酶学文献。基准测试表明zERExtractor在表识别（准确率89.9%）、分子图像解释（准确率高达99.1%）以及关系提取（准确率94.2%）方面优于现有基准模型。", "conclusion": "zERExtractor作为一个灵活且插件式的框架，填补了酶动力学领域长期的数据缺口，提供了高保真的提取方法，为未来基于AI的酶建模和生物化学知识发现奠定了基础。"}
{"llm_update_time": "20250815", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.10025", "html_url": "https://arxiv.org/abs/2508.10025", "title": "使用生成式人工智能实现实时产后抑郁检测及其解释", "title_en": "Detecting and explaining postpartum depression in real-time with generative artificial intelligence", "authors": "Silvia García-Méndez,Francisco de Arriba-Pérez", "background": "产后抑郁（PPD）是母亲在分娩后面临的一个严重问题，严重影响她们的身心健康。快速检测PPD及其相关风险因素对于及时评估和干预非常重要。目前迫切需要通过最新技术帮助医疗专业人员进行实时筛查和治疗建议，因此开发了一种结合自然语言处理、机器学习（ML）和大型语言模型（LLMs）的智能PPD筛查系统，以实现经济实惠、实时和无创的自由话语分析。", "innovation": "该工作贡献了一种智能PPD筛查系统，该系统结合了自然语言处理、机器学习和大型语言模型，提供了一种经济实惠、实时且无创的自由话语分析方法。此外，通过使用可解释的机器学习模型（即树基算法）与大型语言模型相结合，提供预测解释，解决了黑盒问题。实验证明，该方法在所有评估指标上的PPD检测精度达到90%，超过了文献中其他竞争方法。", "conclusion": "该解决方案促进了PPD及其相关风险因素的快速检测，这对于及时和适当的评估与干预至关重要。"}
{"llm_update_time": "20250815", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.10026", "html_url": "https://arxiv.org/abs/2508.10026", "title": "SABER: 可切换和平衡化训练以实现高效的大语言模型推理", "title_en": "SABER: Switchable and Balanced Training for Efficient LLM Reasoning", "authors": "Kai Zhao,Yanjun Zhao,Jiaming Song,Shien He,Lusheng Zhang,Qiang Zhang,Tianjiao Li", "background": "大型语言模型（LLMs）通过链式思考推理已经实现了复杂任务上的出色准确度，但在应用于所有问题时，会因过度推理而面临高昂的推理成本和延迟问题。", "innovation": "提出了SABER（可切换和平衡化训练以实现高效的大语言模型推理），这是一种强化学习框架，它赋予了LLMs用户可控、基于token预算的推理能力。SABER能够根据每个训练示例的基础模型使用思考token的数量对它们进行分层，并在微调过程中根据系统提示和长度感知的奖励来遵守其分配的预算。此外，SABER还支持四种不同的推理模式（NoThink、FastThink、CoreThink和DeepThink），这为延迟和推理深度之间的权衡提供了灵活性。", "conclusion": "广泛实验证明，SABER能够在严格预算下实现高准确度、平滑的退化以及跨尺度和跨领域的有效通用性。特别是在MATH基准测试中，SABER-FastThink将推理长度缩短了65.4%，并相较于基础模型提高了3.6%的准确度。"}
{"llm_update_time": "20250815", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.10034", "html_url": "https://arxiv.org/abs/2508.10034", "title": "使用深度学习进行喷流图像标记：一种集成模型", "title_en": "Jet Image Tagging Using Deep Learning: An Ensemble Model", "authors": "Juvenal Bassa,Vidya Manian,Sudhir Malik,Arghya Chattopadhyay", "background": "在高能粒子物理中，喷流分类对于理解基本相互作用和探索标准模型之外的现象至关重要。喷流源自夸克和胶子的碎片化和强相互作用，由于其复杂且多维的结构，其识别极具挑战性。传统的分类方法往往难以捕捉这些复杂性，因此需要采用先进的机器学习方法。", "innovation": "本文提出了一种同时运用两个神经网络的集成模型，将其应用于喷流数据，并将其转换为二维直方图，而非高维空间中的点表示。该集成模型用于对JetNet数据集中不同类别的喷流进行标记，具体包括：top夸克、轻夸克（向上或向下）和W、Z玻色子。实验结果表明，该集成模型在二分类和多分类中均表现出色，通过利用每个组成网络的优势，获得了优于单一网络的性能。", "conclusion": "本文采用的集成模型在喷流分类任务上取得了显著的性能提升，能够有效识别不同类型的喷流。"}
{"llm_update_time": "20250815", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.10028", "html_url": "https://arxiv.org/abs/2508.10028", "title": "PREF：大型语言模型中个性化文本生成的参考无关评估", "title_en": "PREF: Reference-Free Evaluation of Personalised Text Generation in LLMs", "authors": "Xiao Fu,Hossein A. Rahmani,Bin Wu,Jerome Ramos,Emine Yilmaz,Aldo Lipani", "background": "用户中心的信息系统需要个性化的文本生成，但现有的评价方法大多忽略了用户的个体差异。为此，需要一种既能衡量通用输出质量又能针对用户特定对齐的评价框架，且无需黄金个性化引用。现有的评量框架通常依赖于预先设定的标准或用户反馈，这限制了它们在不同用户和上下文中的应用灵活性和准确性。", "innovation": "PREF框架通过三个阶段实现参考无关的个性化评价：首先，覆盖阶段使用大型语言模型生成包含通用标准（如事实性、连贯性和完整性）的查询特定指南；其次，偏好阶段使用用户的个人信息或推断偏好调整这些因素，生成个性化的评价准则；最后，评分阶段使用大型语言模型对候选答案进行评分，确保基础质量的同时捕捉主观优先级。这种分离覆盖和偏好阶段的处理方式增强了框架的稳健性、透明性和重用性，并允许较小的模型模拟较大模型的个性化质量。实验证明，PREF框架在准确度、校准度和与人类判断的吻合度方面优于现有基准。", "conclusion": "PREF框架为大规模、可解释和用户对齐的评价提供了基础，促进了个性化语言生成系统的可靠评估和发展。"}
{"llm_update_time": "20250815", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.10035", "html_url": "https://arxiv.org/abs/2508.10035", "title": "基于神经网络的家庭能源系统中FDIA的检测和多类别分类", "title_en": "Neural Network-Based Detection and Multi-Class Classification of FDI Attacks in Smart Grid Home Energy Systems", "authors": "Varsha Sen,Biswash Basnet", "background": "智能电网基础设施，尤其是家庭区域网络(HANs)，因为其实时监控和控制的广泛应用，成为了虚假数据注入攻击(FDIA)的主要威胁。由于HANs的安全控制相对宽松且广泛存在，攻击者常常将它们作为篡改需求模式的入口，最终导致整个电网的操作出现中断。这种攻击破坏了智能电表数据的完整性，使得恶意行为者在不激活传统警报的情况下操纵消费值，从而在住宅和规模发电设施之间制造了严重的安全漏洞。", "innovation": "该论文提出了一种基于机器学习的框架，用于检测和分类FDIA，利用住宅能源数据。采用轻量级的人工神经网络(ANN)实时检测关键能量消耗、成本和时间上下文特征。为了分类不同类型的攻击，训练双向LSTM识别正常、梯形和S型攻击模式，通过学习数据中的序列依赖性。生成了合成的时间序列数据集以模拟现实的家庭行为。实验结果表明，所提出的模型能够有效识别和分类FDIA，提供了一种可扩展的解决方案，增强边缘电网的韧性。", "conclusion": "这项工作促进了智能、数据驱动的防御机制的建设，强化了住宅端智能电网的网络安全。"}
{"llm_update_time": "20250815", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.10036", "html_url": "https://arxiv.org/abs/2508.10036", "title": "反思然后学习：由内省困惑引导的信息抽取主动提示", "title_en": "Reflect then Learn: Active Prompting for Information Extraction Guided by Introspective Confusion", "authors": "Dong Zhao,Yadong Wang,Xiang Chen,Chenxi Wang,Hongliang Dai,Chuanxing Geng,Shengzhong Zhang,Shaoyuan Li,Sheng-Jun Huang", "background": "大型语言模型（LLMs）在少样本信息抽取（IE）任务中展现出了显著的潜力，但它们的表现高度依赖于上下文示例的选择。传统的示例选择策略往往不能提供有用的信息，因为它们忽略了模型失败的一个关键来源：不仅仅是语义内容的混淆，还有生成信息抽取任务需要的正确结构格式。这导致了示例选择的不足，进而影响了模型的性能和鲁棒性。", "innovation": "本文提出了主动提示的信息抽取（APIE）方法，这是一种主动提示框架，采用我们称为内省困惑的原则。该方法通过一个双组件不确定性度量来让LLM评估自身的困惑，这个度量能够同时定量衡量格式不确性（正确语法生成的难度）和内容不确性（提取的语义不一致性）。通过对未标记数据进行全面评分，该框架能够主动挑选最具挑战性和信息性的样本作为少样本示例。实验结果显示，与强基线相比，该方法在提取准确性和鲁棒性方面均显著提高。", "conclusion": "我们的研究强调了在构建有效的和可靠的结构生成系统时，一种细腻的、双层视角的模型不确定性是至关重要的。"}
{"llm_update_time": "20250815", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.10017", "html_url": "https://arxiv.org/abs/2508.10017", "title": "使用SMOTETomek和FedProx在不平衡临床数据上实现差分隐私联邦学习的稳健流程", "title_en": "A Robust Pipeline for Differentially Private Federated Learning on Imbalanced Clinical Data using SMOTETomek and FedProx", "authors": "Rodrigo Tertulino", "background": "联邦学习（FL）为协作卫生研究提供了一种创新的方法，可以在保障患者隐私的同时在分散的数据上进行模型训练。当与差分隐私（DP）结合时，FL能够提供正式的安全保证。然而，将这两种技术整合起来带来了隐私与临床效用之间的重大权衡，特别是医疗数据中存在的严重类别不平衡进一步复杂化了这一问题。本研究通过系统而多阶段的分析来解决这些问题，特别是在心血管风险预测中实现FL框架，初步实验表明标准方法难以处理不平衡数据，导致召回率为零。为此，研究首先在客户端层面整合了集成的合成少数类过采样技术和托梅克链接（SMOTETomek），成功开发了一个临床适用的模型。之后，通过调优的FedProx算法优化了框架以处理非同态数据。最终结果揭示了隐私预算（ε）和模型召回率之间明确的非线性权衡，并且优化的FedProx方法持续优于标准的FedAvg。研究确定了隐私与效用前沿上一个最优区域，在该区域里可以同时保证强烈的隐私保障（ε为9.0）和高临床效用（召回率大于77%）。", "innovation": "本研究通过在客户端层面整合了集成的合成少数类过采样技术和托梅克链接（SMOTETomek），并使用调优的FedProx算法优化框架以处理非同态数据，解决了联邦学习在不平衡临床数据中的隐私与临床效用之间的权衡问题。最终，在隐私与效用的最优区域里，研究最终发现优化的FedProx方法能够提供既强烈隐私保障（ε为9.0）又具有高临床效用（召回率大于77%）的结果，这为创建有效的安全准确的诊断工具提供了一个切实可行的方法论蓝图，适用于真实的、异质的医疗健康数据环境。", "conclusion": "本研究提供了一个实用的方法论蓝图，该蓝图可以创建有效的、安全的和准确的诊断工具，适用于真实的异质医疗健康数据。通过优化FedProx算法，并使用SMOTETomek处理不平衡数据，研究证明了一个最优操作区域，在该区域里可以同时实现高隐私和高临床效用。"}
{"llm_update_time": "20250815", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.10055", "html_url": "https://arxiv.org/abs/2508.10055", "title": "贝叶斯模型联合选择特征和自回归滞后：在环境和金融预测中的理论与应用", "title_en": "Bayesian Models for Joint Selection of Features and Auto-Regressive Lags: Theory and Applications in Environmental and Financial Forecasting", "authors": "Alokesh Manna,Sujit K. Ghosh", "background": "该研究背景在于线性回归分析中需要考虑自相关误差的问题，特别是在时间序列应用中，响应变量不仅依赖于当前的或过去的解释变量，还依赖于持续的随机冲击，如金融市场建模、水文预报和气象预测等场景，这些领域都需要捕捉时间依赖性。因此，需要一种框架来同时选择相关变量和滞后误差项，该框架还应能够应对高维计算挑战。现有方法要么不能解决自相关噪声问题，要么在模型选择和预测性能方面表现不佳。", "innovation": "本文提出了一种贝叶斯框架，用于线性回归中自相关误差的变量选择，该框架能够处理滞后因变量和自回归结构，使用分层贝叶斯模型和尖刺-帽先验。此外，提出了一种高效的两阶段MCMC算法，将变量包含指标的抽样与模型参数的抽样分开，以应对高维计算挑战。理论分析表明，在样本量增长时，候选预测变量数量呈指数增长的情况下，该方法的后验选择一致性仍然成立。", "conclusion": "通过模拟和实际应用（地下水深度预测和S&P 500对数收益建模），研究证明了在变量选择准确性和预测性能方面取得了显著提升。与现有方法相比，该框架在均方预测误差（MSPE）方面表现更好，能够更好地识别真正的模型组成部分，并且具有更高的鲁棒性，在自相关噪声场景下表现更好，因此在自回归设置中具有实际的应用价值，可用于模型解释和预测。"}
{"llm_update_time": "20250815", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.10064", "html_url": "https://arxiv.org/abs/2508.10064", "title": "动力对齐：动态神经计算的基本原则", "title_en": "Dynamical Alignment: A Principle for Adaptive Neural Computation", "authors": "Xia Chen", "background": "神经网络的计算能力普遍认为由其静态架构决定。本文挑战了这一观点，指出固定的神经结构可以根据输入信号的时间动态，切换到不同的计算模式，这一原理被称为动力对齐。", "innovation": "本文发现，通过输入动态和神经元整合的时间尺度对齐，可以实现一种全新的优化景观，其中，通过收缩动态的‘耗散’模式可以实现高效的能量利用，而通过扩张动态的‘扩展’模式则可以展现代表能力，使得脑启发的突触神经网络（SNNs）在各种任务上能够与甚至超越人工神经网络，包括分类、强化学习和认知整合。", "conclusion": "动力对齐不仅提供了一种统一、可计算的观点来解释神经科学中的长期观察到的双向性，如稳定-可塑性困境和分离-整合动态。还表明计算不仅可以在生物系统中通过固定的‘硬件’由‘软件’动态塑造，而且在人工系统中也可以如此，这提示AI研究可能需要从设计复杂的静态架构转向掌握适应性和动态计算原理。"}
{"llm_update_time": "20250815", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.10074", "html_url": "https://arxiv.org/abs/2508.10074", "title": "Next Edit Prediction: Learning to Predict Code Edits from Context and Interaction History", "title_en": "Next Edit Prediction: Learning to Predict Code Edits from Context and Interaction History", "authors": "Ruofan Lu,Yintong Huo,Meng Zhang,Yichen Li,Michael R. Lyu", "background": "随着大型语言模型（LLMs）的迅速发展，AI编码助手已经被广泛集成到开发环境中。一方面，低延迟的代码补全可以通过当前光标位置提供代码完成建议，但其无法预测后续连贯的编辑。另一方面，基于对话的编辑虽然能够执行复杂的修改，但也要求开发者中断工作，使用自然语言描述修改意图，这会导致从代码切换到文本的上下文转换，进而引发用户体验不佳的问题，因为这两种方法都无法主动预测开发者在一系列相关编辑中的下一个编辑意向。", "innovation": "本文提出了Next Edit Prediction任务，旨在通过从前序交互历史中推断开发者的意图，预测后续编辑的位置和内容，以提供无缝的代码修改建议。为此，作者创建了一个高质量的监督微调数据集和评估基准，对一系列模型进行了监督微调，并对微调后的模型及其他基准模型进行了全面评估，发现了若干新的发现。这项工作为一种新的交互范式奠定了基础，这种范式可通过主动与开发者的协作，预测其后续动作，而不仅仅是对明确指令做出反应。", "conclusion": "本文为开发者提供了一种新的交互方式——Next Edit Prediction，通过预测开发者后续编辑的行为，改善了编码助手的用户体验。这项工作为后续的工作提供了一个新的研究方向，即更好的理解开发者的行为模式，提高开发工具的智能化水平。"}
{"llm_update_time": "20250815", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.10160", "html_url": "https://arxiv.org/abs/2508.10160", "title": "使用慢性侵入性电生理学的预训练变压器模型进行无需个体患者训练的症状解码", "title_en": "Pre-trained Transformer-models using chronic invasive electrophysiology for symptom decoding without patient-individual training", "authors": "Timon Merk,Saeed Salehi,Richard M. Koehler,Qiming Cui,Maria Olaru,Amelia Hahn,Nicole R. Provenza,Simon Little,Reza Abbasi-Asl,Phil A. Starr,Wolf-Julian Neumann", "background": "神经解码病理和生理状态的能力可以使神经调控疗法实现个性化。近年来，预训练大型基础模型的进展为无患者特定训练的一般状态估计提供了潜力。这项研究使用跨24天的慢性纵向深脑刺激记录来训练一个基础模型，以适应长时间尺度的症状波动，并强调30分钟的上下文窗口。研究还修正了常见掩码自编码损失函数对1-over-f频率规律的频率偏差，优化了神经电生理数据的预训练损失函数。通过留一Subject外交叉验证任务，展示了无患者特定训练的帕金森病症状解码。", "innovation": "使用慢性侵入性电生理学数据训练预训练的转换器模型，优化神经电生理数据的预训练损失函数，修正频率偏差，实现无需患者特定训练的症状解码。", "conclusion": "该研究展示了无需患者特定训练即可使用预训练的转换器模型进行症状解码，该模型基于长时间尺度的症状波动进行训练，使用了优化后的预训练损失函数。"}
{"llm_update_time": "20250815", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.10193", "html_url": "https://arxiv.org/abs/2508.10193", "title": "越来越多的记忆，越多的问题：面向流的机器卸载", "title_en": "Mo' Memory, Mo' Problems: Stream-Native Machine Unlearning", "authors": "Kennon Stewart", "background": "机器卸载工作假设数据具有静态且独立同分布的特点，这在现实场景中并不存在。现代机器学习流水线必须在生产中持续学习、忘记和预测。本文将批量卸载的概念转移到了在线设置中，引入了信息遗憾、样本复杂性及删除容量的概念。", "innovation": "本文的创新点包括：将批量卸载的场景转化为在线设置，减少了遗憾边界到对数级的O(ln(T))，为机器卸载算法的首次表现；采用在线L-BFGS优化代替昂贵的Hessian矩阵逆运算，消除了随时间线性增长的内存足迹，从而延长了机器学习模型的使用寿命，提升了卸载过程的效率。", "conclusion": "本文提出的在线设置下的机器卸载方法通过降低遗憾边界和优化内存管理，使得机器学习模型可以在不必频繁重新训练的情况下持续使用，从而提高了机器卸载的过程效率和系统的整体效率。"}
{"llm_update_time": "20250815", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.10117", "html_url": "https://arxiv.org/abs/2508.10117", "title": "基于图形深度学习、网络药理学和分子对接的金鸡纳科瓦植物黄酮类生物活性化合物对Hela癌细胞毒性的体内外研究", "title_en": "In silico study on the cytotoxicity against Hela cancer cells of xanthones bioactive compounds from Garcinia cowa: QSAR based on Graph Deep Learning, Network Pharmacology, and Molecular Docking", "authors": "Nguyen Manh Son,Pham Huu Vang,Nguyen Thi Dung,Nguyen Manh Ha. Ta Thi Thao,Tran Thi Thu Thuy,Phan Minh Giang", "background": "癌症是一种复杂的疾病群体，占全球最高死亡率，并且发病率增加且有年轻化的趋势。金鸡纳科瓦是一种传统中药，在东南亚广泛使用，用于治疗发热、咳嗽、消化不良、通便和寄生虫病。从该植物中分离出的黄酮化合物具有广泛的生物活性，其中一些显示出作为抗癌和抗疟疾剂的潜力。", "innovation": "通过网络药理学分析成功识别了活性化合物及其主要蛋白靶点，使用Graph Attention Network算法预测化合物的pIC50值，并通过分子对接确定MTOR为金鸡纳科瓦黄酮类化合物诱导HeLa癌细胞毒性的潜在靶点。", "conclusion": "金鸡纳科瓦植物中的黄酮类化合物通过多种生物活性和细胞毒性作用发挥抗癌潜在效果，这些化合物特别是通过抑制MTOR，能够有效抵抗Hela癌细胞。"}
{"llm_update_time": "20250815", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.10178", "html_url": "https://arxiv.org/abs/2508.10178", "title": "在架空海水环境估算碳池：再分析还是模型导向的机器学习？", "title_en": "Estimating carbon pools in the shelf sea environment: reanalysis or model-informed machine learning?", "authors": "Jozef Skakala", "background": "架空海区域在碳固存和碳循环中起着重要作用，但由于现场或卫星数据的稀缺或不确定性，目前可获取的数据往往不足。已有再分析数据可以作为替代，但其运行成本高昂。该研究提出了一种利用神经网络（NN）从联机物理-生物地球化学模型中学习直接可观测变量与碳循环关系的方法。通过针对北海西欧架空海环境的实验，研究证明了使用基于模型自由运行模拟训练的NN能够再现再分析数据中碳循环的输出。此外，与现有的再分析数据相比，神经网络集成系统还能够提供碳池的不确定性信息。", "innovation": "该研究利用神经网络训练方法，通过联机物理-生物地球化学模型学习碳池与直接可观测变量之间的关系，并证明其能够重建架空海水环境中的碳池。更重要的是，该方法还能够提供碳池的不确定性信息，填补了现有再分析数据只能提供估计值的空白，提升了预测的可靠性。", "conclusion": "研究建议，模型导向的机器学习是一种可行的替代方法，可用于替代成本高昂的再分析数据，并且可以在观测数据缺失或不确定性高时补充现有的观测数据。此外，该方法有助于未来气候变化情景的可解释性研究。"}
{"llm_update_time": "20250815", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.10120", "html_url": "https://arxiv.org/abs/2508.10120", "title": "基于机器学习的IASI测量中的云检测：具有物理约束的数据驱动SVM方法", "title_en": "Machine Learning for Cloud Detection in IASI Measurements: A Data-Driven SVM Approach with Physical Constraints", "authors": "Chiara Zugarini,Cristina Sgattoni,Luca Sgheri", "background": "云检测对于大气恢复、气候研究和天气预报至关重要。本文分析了搭载在气象运营(MetOp)卫星上的红外大气光谱干涉仪(IFS)的红外辐射数据，使用支持向量机(SVM)方法，结合核方法处理不可分数据来分类场景为晴空或云覆盖。该方法通过主成分分析(PCA)和云敏感通道选择进行维度降低，以聚焦最相关特征。研究结果表明，CISVM方法能够在红外辐射或亮度温度数据下实现自动云分类，并且该方法在面对极地地区传感器差异时也有较好的一致性，验证了CISVM作为一种稳健、灵活且高效的方法对于自动云分类和未来任务的适用性。这种方法已经准备好应用于诸如远红外出射辐射理解和监测(FORUM)等任务及未来空间任务。", "innovation": "通过结合主成分分析(PCA)和云敏感通道选择的方法维度降低，优化支持向量机(SVM)模型的特征选择；使算法更加注重最相关信息，增强了模型的鲁棒性和准确性；与现有的MODIS云掩膜相比，展示了明显的一致性，改善了在极端条件下的性能；定制了适应不同传感器的算法结构，提高了应用于多种平台且有不同观测仪器的兼容性。", "conclusion": "CISVM方法是一种能够实现自动云分类的高效且稳健的方法，特别适用于基于红外辐射的数据。该方法不仅适用于当前的应用场景，如IASI，还适用于未来空间任务如远红外出射辐射监测(FORUM)。"}
{"llm_update_time": "20250815", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.10192", "html_url": "https://arxiv.org/abs/2508.10192", "title": "大型语言模型Prompt-Response语义分歧度量方法用于忠实性幻觉和不一致检测", "title_en": "Prompt-Response Semantic Divergence Metrics for Faithfulness Hallucination and Misalignment Detection in Large Language Models", "authors": "Igor Halperin", "background": "大型语言模型（LLMs）的普及受到了幻觉现象的挑战，这是一种关键的失败模式，其中模型生成非事实性、无意义或不忠实的文本。已有的方法如语义熵通过测量单个固定提示的答案多样性来测试任意性，但这种测试缺乏对提示和答案之间语义一致性的深入考量。", "innovation": "本文提出了语义分歧度量（SDM），这是一种新的轻量级框架，用于检测忠实性幻觉——即LLMs响应与输入环境严重偏差的事件。SDM通过在多个答案和语义等效的提示重述间测试响应一致性来增强对任意性的检测，同时采用联合句子嵌入聚类创建提示和答案共享话题空间，结合信息论度量来量化语义分歧，特别是通过结合Jensen-Shannon距离和Wasserstein距离来计算实际得分。此外，KL散度作为语义探索的指示器，能够区分不同生成行为。", "conclusion": "本文提出了一种新的SDM框架，通过更为提示感知的方式，结合信息论度量来检测LLMs的忠实性幻觉，同时引入了语义盒作为诊断框架，用于区分不同生成行为，特别是对于危险且自信的虚构行为有重要识别作用。"}
{"llm_update_time": "20250815", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.10208", "html_url": "https://arxiv.org/abs/2508.10208", "title": "CATNet：初级市场CAT债券利差预测的几何深度学习方法", "title_en": "CATNet: A geometric deep learning approach for CAT bond spread prediction in the primary market", "authors": "Dixon Domfeh,Saeid Safarveisi", "background": "传统的CAT债券定价模型难以捕捉这些金融工具中固有的复杂关系数据。CATNet框架通过使用关系图卷积网络（R-GCN）的几何深度学习架构，将CAT债券初级市场建模为图结构，并利用其底层网络结构进行利差预测。", "innovation": "介绍了一种新的框架CATNet，该框架利用关系图卷积网络（R-GCN）来建模CAT债券初级市场，揭示了CAT债券市场的无标度网络特性，并且CATNet在利差预测方面具有显著的预测性能，超过了强大的随机森林基准。同时，通过将拓扑中心性度量作为特征，进一步提高了模型的准确度。", "conclusion": "CATNet为风险评估提供了一个新的范式，并证明基于图的模型可以提供最先进的准确性和更深层次的可量化的市场见解。网络连接性是价格的关键决定因素，证实了行业长期以来对发行商声誉、承保商影响和风险集中的直觉。"}
{"llm_update_time": "20250815", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.10186", "html_url": "https://arxiv.org/abs/2508.10186", "title": "PakBBQ: 用于问答的文化适应型偏见基准", "title_en": "PakBBQ: A Culturally Adapted Bias Benchmark for QA", "authors": "Abdullah Hashmat,Muhammad Arham Mirza,Agha Ali Raza", "background": "随着大型语言模型（LLMs）在各种应用中的广泛使用，确保这些模型在所有用户社区中的公平性变得尤为重要。然而，大多数LLMs都是基于西方数据集进行训练和评估，忽视了低资源语言和地区背景。本文提出PakBBQ，这是一个针对巴基斯坦文化和地区调整的原始问答偏见基准数据集（BBQ）的扩展版本。PakBBQ 包含214个模板、17180个问答对，涵盖了8个关键偏见维度，适用于英语和乌尔都语在巴基斯坦相关的情境中。", "innovation": "本文提出的PakBBQ通过将原始的问答偏见基准数据集进行调整至巴基斯坦的文化和地域背景中，填补了现有数据集中忽视低资源语言和地区背景的空白。PakBBQ 包括在多种不同语境下的评估，如模糊语境下和明确语境下的评估，以及负面和非负面问题表述对偏见行为的影响。研究揭示了诸如（1）在模糊语境下准确性提升12%，（2）乌尔都语在减少偏见行为上更显著，（3）问题表述方式对减少刻板印象回应的显着影响等新发现。这些发现强调在低资源环境中使用上下文化基准和简单的提示工程策略对于缓解偏见的重要性。", "conclusion": "本文通过PakBBQ 数据集证明，需要在数据集和模型评估中纳入更多来自不同文化背景的数据，同时提倡对模型潜在偏见进行上下文化和简单提示工程策略来减少偏见。"}
{"llm_update_time": "20250815", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.10282", "html_url": "https://arxiv.org/abs/2508.10282", "title": "条件版本的遗憾-容量定理在批量通用预测中的应用", "title_en": "The Conditional Regret-Capacity Theorem for Batch Universal Prediction", "authors": "Marco Bondaschi,Michael Gastpar", "background": "背景介绍了经典的遗憾-容量定理，并指出在批量数据可用的情况下，传统的平均遗憾无法充分考虑到信息利用的复杂性，因此需要一个新的概念——批次遗憾来提供更严格的下限。", "innovation": "创新之处在于推导出经典的遗憾-容量定理的条件版本，并将其应用于批量预测，以找到当有限批次的训练数据可用时，最小批次遗憾的下限。此外，该论文还将定理推广到了Rényi信息测度，揭示了条件Rényi散度与条件Sibson互信息之间的深层联系。", "conclusion": "结论指出，该定理为理解条件下的信息利用和预测提供了一个更深刻的理解，特别是在处理批处理数据时。"}
{"llm_update_time": "20250815", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.10222", "html_url": "https://arxiv.org/abs/2508.10222", "title": "通过表情符号预测理解文本情感", "title_en": "Understanding Textual Emotion Through Emoji Prediction", "authors": "Ethan Gordon,Nishank Kuppa,Rigved Tummala,Sriram Anasuri", "background": "研究目标是使用深度学习模型从短文本序列中预测表情符号，通过TweetEval数据集，应用焦点损失和正则化技术解决类别不平衡问题。研究探讨了四种不同的深度学习架构（前馈网络、CNN、变压器和BERT）在表情符号预测中的表现，特别是针对具备预训练优势的BERT模型以及对于罕见表情符号类别的CNN模型的优越性。", "innovation": "本文创新之处在于使用多种深度学习模型进行表情符号预测，并通过聚焦损失和正则化技术克服类别不平衡问题，展示了不同架构和模型参数对预测效果的重要影响，并强调了这对人机交互改进的意义。", "conclusion": "研究表明，对于表情符号的预测，不同架构和参数的调整至关重要，而BERT模型因其预训练优势表现出最佳的整体性能，CNN则在罕见表情符号类别上表现出色。这些发现强调了在情感感知的表情符号预测工作中选择合适模型架构和进行超参数调优的重要性。"}
{"llm_update_time": "20250815", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.10149", "html_url": "https://arxiv.org/abs/2508.10149", "title": "带有逆概率加权的预测增强推断", "title_en": "Prediction-Powered Inference with Inverse Probability Weighting", "authors": "Jyotishka Datta,Nicholas G. Polson", "background": "近年来，预测增强推断（PPI）框架被提出，用于处理部分标注数据的有效统计推断。PPI结合了基于模型的大规模未标注数据集上的预测与来自较小标注数据子集的偏差校正。本文发展了PPI，以处理带有信息性标记偏好的情况，通过用经典Horvitz-Thompson或Hájek形式的逆概率加权（IPW）版本替换PPI中的非加权偏差校正项实现这一目标。这种连接将基于设计的抽样调查思想与现代预测辅助推断结合起来，使之能够在标记概率随单位变化的情况下保持有效性。考虑到包括概率未知但可通过正确指定模型进行估计的常见情况。模拟结果显示，带有逆概率调整的PPI，在已估计倾向性的情况下的性能与已知概率的情况相当，既保留了名义覆盖范围，又保留了PPI的方差降低益处。", "innovation": "本文的主要创新在于，通过使用逆概率加权（IPW）技术（经典Horvitz-Thompson或Hájek形式），将带有信息性标记的预测增强推断（PPI）进行了扩展。这种修改不仅保留了PPI的有效性，还能够处理不同单位下变化的标记概率，增强了框架的灵活性和广普性。这项工作将基于设计的抽样调查思想与现代预测辅助推断相结合，提供了一种在多样化标记概率下的有效估计方法。", "conclusion": "研究结果表明，带有逆概率加权的PPI在估计已知和未知概率的情况下表现良好，既保留了名义覆盖范围，又能有效降低方差。这种技术提供了一种在标注数据不完整且标记存在偏好情况下的有效用途。"}
{"llm_update_time": "20250815", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.10349", "html_url": "https://arxiv.org/abs/2508.10349", "title": "On-Device Fine-Tuning of Foundation Models Using Flexible Personalized Split Federated Learning", "title_en": "Flexible Personalized Split Federated Learning for On-Device Fine-Tuning of Foundation Models", "authors": "Tianjun Yuan,Jiaxiang Geng,Pengchao Han,Xianhao Chen,Bing Luo", "background": "基础模型在个性化下游任务中的微调对于实现卓越性能至关重要，相比使用预训练模型。协作学习可以利用客户端的本地数据集进行微调，但有限的客户端数据和异构的数据分布妨碍了有效的协作。", "innovation": "为了解决上述挑战，提出了一个灵活的个性化联邦学习范式，使客户端能够在保持个性化目标的同时参与到协作学习中。通过分裂学习技术，FlexP-SFL 允许每个客户端根据资源限制，训练模型的一部分并将其余部分卸载到服务器上。此外，提出了一个对齐策略，以提高全局数据上个性化模型的性能。实验证明，FlexP-SFL 在个性化微调效率和最终准确性方面优于基线模型。", "conclusion": "FlexP-SFL 在个性化模型微调方面表现出色，在有限和异构的客户端计算资源条件下也具有优势。"}
{"llm_update_time": "20250815", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.10377", "html_url": "https://arxiv.org/abs/2508.10377", "title": "点击与转化：电子商务中推荐系统的训练目标选择", "title_en": "Clicks Versus Conversion: Choosing a Recommender's Training Objective in E-Commerce", "authors": "Michael Weiss,Robert Rosenbach,Christian Eggenberger", "background": "在电子商务中，通过排名产品推荐来优化点击通过率（CTR）或转化率（例如添加购物车率ACR和订单提交率OSR，即浏览到购买转化率）是标准做法。优化CTR看起来是一个简单的选择：点击数据易于收集且通常数据量大。此外，CTR在电子商务之外也被广泛使用，使其成为一个易于实现的通用标准。相比之下，ACR和OSR更直接地与店铺的业务目标相关，如总商品价值（GMV）。本文通过线上A/B测试比较使用这两种目标的影响。", "innovation": "本文在电子商务中进行了线上A/B测试，研究了使用CTR或OSR两种目标对结果的影响。研究发现，优化OSR比优化CTR带来的GMV提升多出五倍以上，且未牺牲新产品发现。此外，研究还提供了每个目标特征重要性的不同见解。", "conclusion": "在电子商务中，优化OSR相较于优化CTR能带来显著更高的GMV提升，且不会牺牲新的产品发现。不同目标下的特征重要性也有所不同，这些发现对推荐系统的选择提供了指导。"}
{"llm_update_time": "20250815", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.10337", "html_url": "https://arxiv.org/abs/2508.10337", "title": "使用课程学习方法的强化学习：借助RAG进行多模态问答", "title_en": "A Curriculum Learning Approach to Reinforcement Learning: Leveraging RAG for Multimodal Question Answering", "authors": "Chenliang Zhang,Lin Wang,Yuanyuan Lu,Yusheng Qi,Kexin Wang,Peixu Hou,Wenshi Chen", "background": "该论文描述了Dianping-Trust-Safety团队为META CRAG-MM挑战所提出的解决方案。挑战要求构建一个全面的检索增强生成系统，能够应对多模态和多轮次问题回答。比赛包含三个任务：（1）使用基于图像的知识图谱生成的数据结构化回答问题；（2）综合知识图谱和网络搜索结果中的信息；（3）处理多轮次对话，要求理解上下文并从多个来源聚合信息。团队针对每个任务开发了不同策略和方法。", "innovation": "该论文的创新之处在于结合了课程学习与强化学习。具体而言，对于第一个任务，团队采用视觉大型语言模型，并结合了带有GPT-4.1知识的监督微调。此外，引入了课程学习策略来指导强化学习过程，显著提高了答案的准确性和减少了幻觉。对于第二个和第三个任务，团队采用了网络搜索API来整合外部知识，使系统能够更好地处理复杂查询和多轮对话。", "conclusion": "该团队在第一个任务中取得了第一名，领先优势达到52.38%，在第三个任务中获得了第三名。这些结果表明，课程学习方法与强化学习的集成在培训管道中是有效的，并能够显著提升系统的表现。"}
{"llm_update_time": "20250815", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.10339", "html_url": "https://arxiv.org/abs/2508.10339", "title": "概念或技能？重塑多模态模型指令选择", "title_en": "Concepts or Skills? Rethinking Instruction Selection for Multi-modal Models", "authors": "Andrew Bai,Justin Cui,Ruochen Wang,Cho-Jui Hsieh", "background": "多模态指令调优实现了两种主要目的：学习视觉概念和学习视觉技能。现有的视觉-语言基准表明，主要受益于类似技能或视觉概念的训练指令之一，但这一发现被忽视了。本文探讨了通过分析数据集，识别基准学习的偏向（视觉概念或技能），并据此优化调优数据，从而改进基准模型效果。", "innovation": "本文设计了一种简单的有针对性的数据选择方法，该方法通过分析多模态指令调优的基准数据集，确定它们主要受益于相似的视觉概念还是技能，然后选择与这些概念或技能最匹配的指令。这种方法在10多个基准上得到了验证，显示平均提高了0.9%的表现，并且在技能聚焦的子集中提高了1.5%的表现。", "conclusion": "本文的研究结果强调了在指令选择中存在固有的权衡，需要在获取概念知识和培养视觉技能之间取得平衡，这有助于指导未来多模态模型的训练和调优。"}
{"llm_update_time": "20250815", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.10332", "html_url": "https://arxiv.org/abs/2508.10332", "title": "层析分析自监督表示在儿童语音年龄和性别分类中的作用", "title_en": "Layer-Wise Analysis of Self-Supervised Representations for Age and Gender Classification in Children's Speech", "authors": "Abhijit Sinha,Harishankar Kumar,Mohit Joshi,Hemant Kumar Kathania,Shrikanth Narayanan,Sudarsana Reddy Kadiri", "background": "儿童语音分类面临挑战，由于其在音调、发音和发育特征方面具有高度变异性。现有的自我监督学习（SSL）模型在成人语音任务上表现良好，但它们编码儿童语音特征的能力尚未得到充分研究。过去的研究显示，儿童语音的年龄和性别分类需要更深入的分析。这一论文探讨了四种Wav2Vec2变体模型在PFSTAR和CMU Kids数据集上的层析分析结果，结果显示早期层（1-7）比深层层更有效，且主成分分析能进一步提高分类性能。", "innovation": "本研究对四种Wav2Vec2变体模型在特定数据集上的层析分析，发现在早期层中能够更有效捕捉到特定说话者的声音特征，研究还发现，主成分分析能够进一步减少冗余并突出显示最具有信息量的特征成分。两个主要模型分别在儿童语音数据集CMU Kids上达到了97.14%的年龄分类准确率和98.20%的性别分类准确率，在另一个数据集PFSTAR上，基底模型和大型模型分别达到了86.05%和95.00%的分类准确率。这些结果揭示了自监督模型在不同深度上怎样组织说话者特征，并为儿童语音接口的针对性和适应性策略提供支持。", "conclusion": "自监督模型在不同深度上组织说话者特征的方式能够为儿童语音接口的设计提供指导。Wav2Vec2-large-lv60模型在年龄和性别的分类上表现尤为突出，可以为未来儿童语音相关应用提供改进的基础。"}
{"llm_update_time": "20250815", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.10436", "html_url": "https://arxiv.org/abs/2508.10436", "title": "交替应用改进模型以实现多阶段语音增强", "title_en": "Alternating Approach-Putt Models for Multi-Stage Speech Enhancement", "authors": "Iksoon Jeong,Kyung-Joong Kim,Kang-Hun Ahn", "background": "语音增强利用人工神经网络旨在从噪声中去除语音信号，同时保留语音内容。然而，语音增强网络往往会引入一些称为副作用的失真，这会影响音频质量。许多研究集中在改进语音增强模型上，但却很少关注如何减轻这些失真所带来的影响。", "innovation": "本文提出了一种后处理神经网络，用于减轻语音增强模型产生的副作用。受高尔夫术语启发，交替应用语音增强模型和提出的Putt模型以提升语音质量。通过感知质量（PESQ）、主观可懂度（STOI）和背景噪声入侵性（CBAK）等指标测量了模型的效果，并且通过图形分析展示了交替应用的优越性。", "conclusion": "交替应用模型提高了多阶段语音增强的效果。与单独应用任一模型相比，交替应用显示出了更好的性能。"}
{"llm_update_time": "20250815", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.10419", "html_url": "https://arxiv.org/abs/2508.10419", "title": "ComoRAG：一种认知启发的记忆组织RAG模型用于记忆导向的长叙事推理", "title_en": "ComoRAG: A Cognitive-Inspired Memory-Organized RAG for Stateful Long Narrative Reasoning", "authors": "Juyuan Wang,Rongchen Zhao,Wei Wei,Yufeng Wang,Mo Yu,Jie Zhou,Jin Xu,Liyan Xu", "background": "长故事和小说的叙述理解因其复杂的剧情和不断变化的角色关系而具有挑战性。虽然语言模型在长上下文理解和推理方面有所不足，且存在高计算成本，但记忆检索方法（如RAG方法）在实践中仍然是关键的解决方案。然而，传统的RAG方法由于其无状态、单步检索的过程，常常无法捕捉到长范围上下文内的动态关系。因此，本文通过构建记忆组织的RAG模型ComoRAG，针对这一问题进行了探索研究。", "innovation": "ComoRAG通过迭代推理循环和与动态记忆工作空间的交互，实现在长叙事推理中的记忆导向推理。对于初始推理受阻的情况，ComoRAG会生成探查性查询来开辟新的探索路径，并将新获取的证据整合到全局记忆池中，以支持上下文的统一和推理的连贯性。该模型通过四个挑战性的长上下文叙事基准（超过20万个token）展现了比强RAG基线更高的表现，并特别在需要全局理解的复杂查询中表现出色，提供了一种基于记忆的长上下文推理的认知启发式方法。", "conclusion": "在四个具有挑战性的长上下文叙事基准上，ComoRAG相比最强基线展现了稳定的相对增益，高达11%。此外，进一步的分析表明ComoRAG特别适用于需要全局理解的复杂查询，为基于记忆的长上下文推理提供了具有原则性的认知启发方法，同时公开了代码可用。"}
{"llm_update_time": "20250815", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.10460", "html_url": "https://arxiv.org/abs/2508.10460", "title": "准确稀疏轨迹恢复和地图匹配的高效方法", "title_en": "Efficient Methods for Accurate Sparse Trajectory Recovery and Map Matching", "authors": "Wei Tian,Jieming Shi,Man Lung Yiu", "background": "真实世界的轨迹数据往往稀疏，采样率低，且与道路网络对齐不良，但是许多应用场景需要高质量的数据以实现最优性能。因此，如何利用稀疏轨迹数据来提高数据质量成为一个亟待解决的问题。本文研究了轨迹恢复和地图匹配这两个相关问题，旨在提升稀疏轨迹数据的质量。", "innovation": "本文提出了一种新的方法TRMMA和MMA，用于准确的轨迹恢复和地图匹配。MMA通过一个分类任务将稀疏轨迹中的GPS点映射到候选路段集中的道路上，从而实现GPS点的准确对齐。TRMMA针对MMA返回的道路路径，设计了一种双变换编码过程来共同捕捉轨迹和路径中潜在的模式，并采用有效的解码技术依次预测缺失点的位置比率和道路段。", "conclusion": "通过在4个大规模的实际数据集上进行广泛实验，本文中的TRMMA和MMA方法在轨迹恢复和地图匹配方面表现优异，取得了最佳的结果，显著优于现有方法。"}
{"llm_update_time": "20250815", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.10433", "html_url": "https://arxiv.org/abs/2508.10433", "title": "We-Math 2.0: 一种促进视觉数学推理的多功能MathBook系统", "title_en": "We-Math 2.0: A Versatile MathBook System for Incentivizing Visual Mathematical Reasoning", "authors": "Runqi Qiao,Qiuna Tan,Peiqing Yang,Yanzi Wang,Xiaowan Wang,Enhui Wan,Sitong Zhou,Guanting Dong,Yuchen Zeng,Yida Xu,Jie Wang,Chong Sun,Chen Li,Honggang Zhang", "background": "多模态大型语言模型（MLLMs）展示了在多种任务上的出色能力，但在复杂的数学推理方面仍面临挑战。现有研究主要集中在数据集构建和方法优化上，往往忽视了全面的知识驱动设计和模型中心的数据空间建模。", "innovation": "本文介绍了We-Math 2.0，这是一个统一的系统，集成了结构化的数学知识系统、模型中心的数据空间建模和基于强化学习（RL）的训练范式，全面增强MLLMs的数学推理能力。贡献包括：（1）MathBook知识系统：构建了一个五级层次系统，涵盖491个知识点和1819个基础原理；（2）MathBook-Standard与Pro：开发了确保广泛概念覆盖和灵活性的MathBook-Standard数据集，并定义了三维难度空间，生成了针对训练的7种渐进步骤；（3）MathBook-RL：提出了一个两阶段的RL框架，包括冷启动微调和逐进度量化的RL；（4）MathBookEval：引入了一个涵盖所有491个知识点的全面基准，具有多样化的推理步骤分布。实验结果表明，MathBook-RL在四个广泛使用的基准上表现与现有基线相当，并在MathBookEval上取得了强大结果，表明在数学推理上的良好泛化能力。", "conclusion": "实验结果显示MathBook-RL在四个广泛使用的基准上表现与现有基线相当，并在MathBookEval上取得了强结果，建议其在数学推理上的良好泛化能力。"}
{"llm_update_time": "20250815", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.10457", "html_url": "https://arxiv.org/abs/2508.10457", "title": "利用元数据增强的多头视觉变压器进行多标签植物物种预测", "title_en": "Multi-Label Plant Species Prediction with Metadata-Enhanced Multi-Head Vision Transformers", "authors": "Hanna Herasimchyk,Robin Labryga,Tomislav Prusina", "background": "该研究提出了一个多头视觉变压器的方法，旨在解决PlantCLEF 2025挑战中的多标签植物物种预测问题。任务是训练基于单物种植物图像的模型，并在包含多种植物的样本图像上进行测试，这使得训练和测试数据之间存在巨大的领域差异。研究小组利用预先训练的DINOv2视觉变压器基干（ViT-B/14），并采用多分类头进行物种、属、科的预测，利用分类学层次结构来改进预测结果。背景还提到了实验中使用了大约140万张训练图像，覆盖了7,806个植物物种。", "innovation": "研究的关键贡献包括多尺度切片以捕捉不同规模的植物、动态阈值优化基于平均预测长度，并且通过袋装和Hydra模型结构采用集成策略。该方法还包含了多种推断技术，如图像裁剪去除非植物部分、top-n筛选以进行预测约束，以及logit阈值策略。", "conclusion": "该方法在大约140万张训练图像上进行了实验，结果显示了出色的表现，使得我们的提交成为私人排行榜的第三名。所使用的代码可在如下链接找到：this https URL."}
{"llm_update_time": "20250815", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.10425", "html_url": "https://arxiv.org/abs/2508.10425", "title": "HiRef: 利用层次化类级结构和网络精炼实现稳健的药物推荐", "title_en": "HiRef: Leveraging Hierarchical Ontology and Network Refinement for Robust Medication Recommendation", "authors": "Yan Ting Chok,Soyon Park,Seungheun Baek,Hajung Kim,Junhyun Lee,Jaewoo Kang", "background": "医疗记录中的药物推荐对于帮助医生从患者的 longitudinal 医疗记录中及时做出决策至关重要。然而，现实世界的电子健康记录（EHR）数据存在显著挑战，如罕见医疗实体的出现和记录不完整等问题，这些问题可能导致不能充分捕捉临床真相。虽然基于长期电子健康记录的数据驱动模型通常能够实现强大的性能，但它们在面对缺失或未知情况时难以泛化，主要原因是依赖观察到的共现模式。为了应对这些问题，我们提出了 HiRef（层次化类级结构和网络精炼的稳健药物推荐），一个结合了两种互补结构的统一框架：(i) 编纂的医疗类级中编码的层次语义，(ii) 从实际 EHR 中推导出来的共现模式的精炼。我们嵌入类级实体到超球空间中，这自然捕捉了树状关系并允许通过共享祖先的知识传递，从而提高对未见代码的泛化能力。为了进一步增强鲁棒性，我们引入了一种先验指导的稀疏正则化方案，通过抑制假边而保留临床相关的关联对 EHR 共现图进行精炼。", "innovation": "HiRef 结合了层次化类级中编码的层次语义和从实际 EHR 中推导出来的共现模式的精炼。通过将类级实体嵌入超球空间中，可以自然地捕捉树状关系，从而增强对未见代码的泛化能力。此外，该模型还通过一种先验指导的稀疏正则化方案，对 EHR 共现图进行了精炼，以抑制假边并保留临床相关的关联。该模型在 EHR 基准数据集（MIMIC-III 和 MIMIC-IV）上表现出强大性能，并且在模拟的未见代码环境下保持高准确性。广泛的实验和详尽的消融研究证明了 HiRef 对未见医疗代码的鲁棒性，支持通过学习的稀疏图结构和医疗代码嵌入的深入分析。", "conclusion": "HiRef 在 EHR 支持框架下取得了显著的性能，尤其是在处理未见的医疗代码时表现出强大的稳健性。通过对学到的稀疏化图结构和医疗代码嵌入的详尽分析，验证了 HiRef 的有效性。"}
{"llm_update_time": "20250815", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.10501", "html_url": "https://arxiv.org/abs/2508.10501", "title": "PASS：用于可解释和自适应胸部X光推理的概率代理超网采样", "title_en": "PASS: Probabilistic Agentic Supernet Sampling for Interpretable and Adaptive Chest X-Ray Reasoning", "authors": "Yushi Feng,Junye Du,Yingying Hong,Qifan Wang,Lequan Yu", "background": "现有的工具增强代理系统在现实世界中受到三大限制：（i）黑盒推理步骤，损害决策制定的信任并带来安全风险；（ii）较差的多模态整合，对于医疗保健任务而言是固有的关键需求；（iii）刚性且计算效率低的代理管道。因此，研究人员提出了PASS（概率代理超网采样），这是一种用于胸部X光（CXR）推理的首个多模态框架，旨在解决这些挑战。PASS动态地在多工具图上采样代理工作流，生成带有可解释概率标记的决策路径。", "innovation": "PASS是一个创新的框架，通过学习任务条件分布于代理超网，能够动态选择每个超网层中最合适的工具，提供带有概率注释的轨迹以支持事后审计，从而增强医学人工智能的安全性。此外，PASS能够连续地将重要的发现压缩到不断演变的个性化记忆中，并动态地决定是否加深推理路径或提前退出以提高效率。为优化性能与成本之间的帕累托前沿，PASS设计了一种新的三阶段训练过程，包括专家知识预热、对比路径排名和成本感知强化学习。同时，还引入了一种全面的基准CAB-E，用于多步骤、安全关键的自由形式CXR推理评估，以支持严格的评估。实验结果表明，PASS在多个基准验证中显著优于强基线，平衡计算成本，向可解释、自适应和多模态医疗代理系统的新范式转变。", "conclusion": "PASS通过多模态框架和概率代理超网采样，显著增强了医学AI的安全性和解释性，能够在胸部X光推理任务中动态选择最合适的工具路径，并通过持续的学习和优化，提高推理的效率和准确性，推动了新的范式发展。"}
{"llm_update_time": "20250815", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.10449", "html_url": "https://arxiv.org/abs/2508.10449", "title": "SkeySpot: 在建筑行业中自动检测数字电气布局图中的服务关键点", "title_en": "SkeySpot: Automating Service Key Detection for Digital Electrical Layout Plans in the Construction Industry", "authors": "Dhruv Dosi,Rohit Meena,Param Rajpura,Yogesh Kumar Meena", "background": "历史平面图通常仅以扫描文件形式保存，对于建筑、城市规划和设施管理至关重要。然而，由于缺乏可机器读取的平面图，大规模解析这一资源既耗时又易出错。自动化符号识别为直接从平面图中识别服务关键符号提供了可扩展的解决方案，支持成本估算、基础设施维护和法规合规等流程。这些历史平面图在建筑行业中作为宝贵资源，但对于自动化解析有显著的技术挑战，导致传统方法效率低下且精度不高。", "innovation": "该研究引入了一个带注释的数字化电气布局计划（DELP）数据集，包含45张扫描的电气布局计划，标注了2,450个实例，涵盖了34种不同的服务关键类别。研究提出了一个系统评价框架，使用预训练对象检测模型对DELP数据集进行评测。YOLOv8表现出最佳性能，平均精度（mAP）高达82.5%。基于此，开发了SkeySpot，一个轻量级开源工具包，用于实时检测、分类和量化电气符号。SkeySpot生成结构化、标准化输出，支持可扩展的建筑信息工作流，从而实现跨下游应用和监管平台的兼容性。该方法降低了对专有CAD系统的依赖，减少了手动注释工作，提升了电气布局数字化的可访问性，尤其是对于建筑行业的中小型企业和标准化、互操作性和可持续性目标的广泛支持。", "conclusion": "通过降低对专有CAD系统的依赖度，减少人工标注工作，SkeySpot工具包使电气布局的数字化变得更加容易获取，特别是对建筑行业的中小企业。同时，该方法还支持建筑行业内的标准化、互操作性和可持续性目标。"}
{"llm_update_time": "20250815", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.10464", "html_url": "https://arxiv.org/abs/2508.10464", "title": "SingleStrip：从单个标注示例学习头骨剥离", "title_en": "SingleStrip: learning skull-stripping from a single labeled example", "authors": "Bella Specktor-Fadida,Malte Hoffmann", "background": "深度学习分割高度依赖于标注数据，但手动标注非常耗时和耗力，尤其是对于如脑磁共振成像（MRI）这样的体视图像。尽管最近的领域随机化技术通过从标签图中合成多样化的训练图像来减轻对标注数据的依赖，但这些方法在标签图很少的情况下提供的解剖学变化有限。半监督自我训练通过迭代将模型预测的标签纳入训练集，从而让网络能够从未标注的数据中学习。", "innovation": "本文提出了将领域随机化与自我训练结合的方法，能够在仅使用单个标注示例的情况下训练三维头骨剥离网络。首先，自动分箱体素强度以生成用于训练初始头骨剥离模型的标签。其次，通过卷积自编码器（AE）训练标注示例，并使用其重建误差评估未标注数据预测的脑部掩模质量。最后，选择pseudo标签对网络进行微调，从而在不限定标注图像数量的情况下达到与更多标注图像训练模型相当的头骨剥离性能。在测试时间放大过程中，比较了基于AE的排名方法与基于一致性排名方法，发现AE方法与分割准确性的相关性更强。我们的结果强调了结合领域随机化与AE基质量控制以使用极少量标注数据进行有效半监督分割的潜力。这种策略可能有助于减轻新的解剖结构或新兴成像技术研究中的标注负担，从而加速研究进展。", "conclusion": "我们的研究表明，结合领域随机化技术和AE基质量控制可以显著降低对标注数据的需求，从而实现有效的半监督分割。这为处理极少量标注数据时提高头骨剥离性能提供了新方法，可能有助于推动将在新解剖结构和新兴成像技术研究中的应用。"}
{"llm_update_time": "20250815", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.10561", "html_url": "https://arxiv.org/abs/2508.10561", "title": "在情绪计算中可重复的生理特征：唤醒建模的初步分析", "title_en": "Reproducible Physiological Features in Affective Computing: A Preliminary Analysis on Arousal Modeling", "authors": "Andrea Gargano,Jasin Machkour,Mimma Nardelli,Enzo Pasquale Scilingo,Michael Muma", "background": "在情绪计算领域，一个关键挑战在于可靠地将主观的情感体验与客观的生理指标联系起来。这项初步研究通过从心血管和皮肤电反应信号中识别与持续的情绪唤醒水平报告相关的生理特征，解决了可重复性问题。使用Continuously Annotated Signal of Emotion数据集，分析了30名参与者在观看情绪诱发视频后提取的164个生理信号特征。", "innovation": "研究采用Terminating-Random Experiments (T-Rex) 方法，系统地控制用户定义的目标错误发现率进行特征选择，结果显示，仅有两个源自皮肤电反应的特征表现出可重复性且统计学显著相关性。这一结果强调了在情绪计算中严格评估生理特征选择的必要性，该方面往往在情绪计算中被忽视。", "conclusion": "研究结果表明，严格地进行生理特征的选择评估是必要的，特别是在安全关键环境中需要可信和可靠的白盒模型的应用中，如情绪障碍识别和人机交互系统等领域。"}
{"llm_update_time": "20250815", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.10555", "html_url": "https://arxiv.org/abs/2508.10555", "title": "Physics-Informed Deep contrast Source Inversion: A Unified framework for inverse scattering problems", "title_en": "Physics-Informed Deep Contrast Source Inversion: A Unified Framework for Inverse Scattering Problems", "authors": "Haoran Sun,Daoqi Liu,Hongyu Zhou,Maokun Li,Shenheng Xu,Fan Yang", "background": "逆散射问题是电磁成像和医学诊断中至关重要的的环节，但其非线性和多样化的测量场景带来了挑战。现有的成手法在处理这类问题时显得力繁重和不精准。特别是全个传统的逆全波成法由于涉及幅波形式的处理而计算成本高解决起来较为高地难以适用 ", "innovation": "本文提出了一个基于物理的深层对比源Inference框架（DeepCSI), 该框架采用了一种残差多层感知机（ResMLP) �通过模型在感兴趣区域下在电磁信号的激励条件下电流分分布，从而有效地线解逆得到非线性散的逆散切问题和把计算成本 reduce到了传统幅波形式的逆切问题法通过一大较大的幅度。此外,该框架通过在待求介质下的学习张量建模和利用将状态方程损失、数据方方程损失和总计变局部则化作为整的混合损失函数组织联合优化网络参数和介质性质。这种方法在多元测量场景中体现出简洁易建用和普适模核能力 特别是对无相和、多频率观测具备显著优势。相比于传统逆方法这个框架表现出了高精度和鲁棒的重建、特别是在少数据、无相态和多频率状态下不同优于传统CSI方法 �为处理复一杂的逆散切问题提供了一种高效、普的适的的切实整法 ", "conclusion": "通过构建和DeepCSI框架本文为各种测量场景中的的逆散切问题统提供提供了一种中高效能有效并且普适于的解决方法为复杂的逆散切问题提供了进一步改进提供了重要笔者研究由此建立切链了前进了一步"}
{"llm_update_time": "20250815", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.10533", "html_url": "https://arxiv.org/abs/2508.10533", "title": "通过频率选择和维度分离缓解量子机器学习中混合频率的双指数增长", "title_en": "Mitigating Exponential Mixed Frequency Growth through Frequency Selection and Dimensional Separation in Quantum Machine Learning", "authors": "Michael Poppel,David Bucher,Maximilian Zorn,Nico Kraus,Jonas Stein,Claudia Linnhoff-Popien", "background": "量子计算（QC）有潜力提供计算加速，量子机器学习（QML）因此受到了越来越多的关注。角度编码技术在QML模型中的应用可以生成截断傅里叶级数，提供渐进意义上的普遍函数逼近能力。通过选择量子电路中的高效特征映射（FMs），可以利用傅里叶频率的指数增长来改进逼近。但实践中，量子模型在回归任务中经常失败，即使相关频率存在，也可能由于可训练参数不足而失败。", "innovation": "为缓解量子模型中由于频率指数增长导致的参数双指数增长，本文提出了频率选择和维度分离的技术来限制参数数量，从而提高训练效率。通过仅限制量子机器学习模型中必要的频率，并在已知有相互依赖的特征维度之间允许混合频率，它可以解决当前硬件上的一些可处理问题。此外，还通过两个可预测的函数验证了减少参数需求的有效性，并展示了在嘈杂的量子模拟器和实际量子硬件上的训练和推理过程。", "conclusion": "通过频率选择和维度分离，本文成功缓解了量子机器学习中的混合频率的双指数增长，减少了训练需求，使当前硬件可以处理更多问题，展示了在噪声量子模拟器和实际量子硬件上的可行性。"}
{"llm_update_time": "20250815", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.10712", "html_url": "https://arxiv.org/abs/2508.10712", "title": "嵌入式SAR船舶目标检测与分类的轻量级CNN", "title_en": "Lightweight CNNs for Embedded SAR Ship Target Detection and Classification", "authors": "Fabian Kresse,Georgios Pilikos,Mario Azcueta,Nicolas Floury", "background": "合成孔径雷达（SAR）数据能够实现海上船只的大规模监控，但在现阶段，实时监控受到需要下传所有原始数据、进行图像聚焦和地面上后续分析的限制。船上数据处理可以生成高层产品，以减少需要下传的数据量，缓解带宽限制并减少延迟。然而，传统的图像聚焦和处理算法因为卫星有限的内存、处理能力和计算资源而面临挑战。本研究提出并通过评估了在Sentinel-1获取的带状和干涉宽阔（IW）模式未聚焦SAR数据上进行实时推理的神经网络。我们通过一项将船舶与风力涡轮机进行二元分类的任务，证明了目标分类的可能性。", "innovation": "本研究提出并评估了针对Sentinel-1在带状和干涉宽阔模式下获取的未聚焦SAR数据进行实时推理的神经网络模型。特别的是，通过在FPGA设备上的部署和应用，展示了轻量级卷积神经网络（CNN）在船上处理的可能性和有效性。", "conclusion": "研究结果表明，使用某些模型对SAR数据进行船上处理是可行的，且通过基于二元分类任务（船舶与风力涡轮机之间的区分），证明了目标分类的可行性。"}
{"llm_update_time": "20250815", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.10731", "html_url": "https://arxiv.org/abs/2508.10731", "title": "分解通用类别发现：自我分解下的多重共识", "title_en": "Dissecting Generalized Category Discovery: Multiplex Consensus under Self-Deconstruction", "authors": "Luyao Tang,Kunze Huang,Chaoqi Chen,Yuxuan Yuan,Chenxin Li,Xiaotong Tu,Xinghao Ding,Yue Huang", "background": "人类感知系统擅长识别和生成已知和未知类别中的对象，这一能力超越了当前的机器学习框架。尽管通用类别发现（GCD）旨在弥合这一差距，但现有方法主要集中在优化目标函数上。现有方法的此类局限性表明，需要一种新的方法来更好地模拟人类认知过程，特别是在处理和理解新型物体方面。该研究提出了一种基于人类认知过程的解决方案，通过将物体分解为视觉原始元素，并进行跨知识比较。", "innovation": "该研究提出了ConGCD方法，通过高级语义重构建立以原始元素为中心的表示，通过分解将类别内部共享的属性结合在一起。同时，该方法引入了主导性和情境性共识单元，分别捕捉类间区分模式和内在分布不变性。通过动态优化激活路径，最终预测是通过多路共识整合形成的共识调度器实现的。这种方法的有效性在粗粒度和细粒度基准测试中得到了广泛验证。", "conclusion": "ConGCD作为一种共识感知范式，有效地模拟了人类在视觉处理中的偏好多样性，展示了对新物体识别和理解的有效性。该研究的方法为通用类别发现领域提供了一种新的解决方案，并通过实验证明其有效性。"}
{"llm_update_time": "20250815", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.10718", "html_url": "https://arxiv.org/abs/2508.10718", "title": "对称约束多尺度物理学启发神经网络在石墨烯电子能带结构预测中的应用", "title_en": "Symmetry-Constrained Multi-Scale Physics-Informed Neural Networks for Graphene Electronic Band Structure Prediction", "authors": "Wei Shan Lee,I Hang Kwok,Kam Ian Leong,Chi Kiu Althina Chau,Kei Chon Sio", "background": "在二维材料中，精确预测电子能带结构仍然是一个基本挑战。现有的方法难以平衡计算效率和物理准确性。", "innovation": "提出了Symmetry-Constrained Multi-Scale Physics-Informed Neural Network (SCMS-PINN) v35，该模型直接学习石墨烯的能带结构，并通过多头架构严格实现晶体学对称性。该方法引入了三个专门的ResNet-6通路，分别为K-head、M-head和General head，并基于从k点提取的31个物理学信息特征进行操作。渐进的狄拉克约束调度逐步增加权重参数从5.0到25.0，实现从全局拓扑到局部关键物理的分层级学习。经过300个周期对10,000个k点的训练，实现了训练损失99.99%的减少，验证损失为0.0085。模型预测狄拉克点间隙在30.3 μeV内接近理论零点，并在整个布里渊区内实现平均53.9 meV（价带）和40.5 meV（导带）的误差。", "conclusion": "通过系统地平均所有十二个C6v操作，确保了精确的对称性保真。该框架为将物理学启发式学习扩展到更广泛的二维材料，以加速发现奠定了基础。"}
{"llm_update_time": "20250815", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.10745", "html_url": "https://arxiv.org/abs/2508.10745", "title": "Agentic Design Review System", "title_en": "Agentic Design Review System", "authors": "Sayan Nag,K J Joseph,Koustava Goswami,Vlad I Morariu,Balaji Vasan Srinivasan", "background": "评估图形设计涉及多方面，如对齐、布局、美学和色彩选择的评估。从整体角度评估设计通常需要从各个专家评审中综合反馈。为此，我们提出了一种名为Agentic Design Review System (AgenticDRS) 的体系。在这个系统中，多个代理协作分析设计，由一个元代理进行协调。我们还提出了一种基于图匹配的在上下文中的范例选择方法，并且采用了一种独特的提示扩展方法，使每个代理具备设计意识。为了评估这一框架，我们提出了DRS-BENCH基准体系。通过对基准体系及关键消融实验进行详尽的实验评估，突显了Agentic-DRS在评估图形设计和生成可操作反馈方面的能力。", "innovation": "我们提出了一种名为AgenticDRS的设计审查体系，多个代理通过一个元代理进行协作分析设计，独特地使用了基于图匹配的范例选择方法以及提示扩展方法，使代理具备设计意识。进一步提出了DRS-BENCH基准体系，进行详尽的实验评估，并验证了Agentic-DRS的有效性。", "conclusion": "我们希望通过这项工作，引起对这一实践性强但尚未充分开发的研究方向的关注。AgenticDRS 在评估图形设计和生成可操作反馈方面展示出了显著效果。"}
{"llm_update_time": "20250815", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.10774", "html_url": "https://arxiv.org/abs/2508.10774", "title": "Video-BLADE: Block-Sparse Attention Meets Step Distillation for Efficient Video Generation", "title_en": "Video-BLADE: Block-Sparse Attention Meets Step Distillation for Efficient Video Generation", "authors": "Youping Gu,Xiaolong Li,Yuhao Hu,Bohan Zhuang", "background": "当前使用扩散变换器进行高质量视频生成处于领先水平，然而，它们缓慢迭代降噪过程和长序列二次注意力成本高导致了严重的推断瓶颈。虽然步骤蒸馏和稀疏注意力机制都展示了加速能力，但两种方法的有效结合则面临极大挑战：无训练的集成效果不佳，而步骤蒸馏后分别训练稀疏注意力需要大量的高质量视频数据。因此，需要一种无需训练且有效的组合加速策略。", "innovation": "提出了一种名为BLADE的创新数据驱动联合训练框架，该框架引入了自适应块稀疏注意力(ASA)机制用于动态生成内容敏感的稀疏性掩码，以及基于轨迹分布匹配(TDM)的稀疏感知步骤蒸馏范式，旨在直接将稀疏性纳入蒸馏过程，从而实现快速收敛。", "conclusion": "BLADE在不同规模的文本到视频模型中验证了其高效性。在Wan2.1-1.3B上，BLADE实现了高达50步以内的14.10倍端到端推断加速。并且在CogVideoX-5B这样的模型上，我们的框架实现了8.89倍的加速，且伴随质量一致提升，获得了VBench-2.0基准和人类评估的优异成绩。相关代码和模型权重已公开发布。"}
{"llm_update_time": "20250815", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.10807", "html_url": "https://arxiv.org/abs/2508.10807", "title": "Parity Cross-Resonance: A Multiqubit Gate", "title_en": "Parity Cross-Resonance: A Multiqubit Gate", "authors": "Xuexin Xu,Siyu Wang,Radhika Joshi,Rihan Hai,Mohammad H. Ansari", "background": "这篇论文介绍了一种新型的三量子比特纠缠门，利用工程化的相互作用，在单一相干步骤中实现控制-控制-目标和控制-目标-目标操作。不同于传统的多量子比特门的分解方法，此方法通过混合优化策略选择性地放大所需的相互作用并抑制不需要的耦合，确保在计算子空间内具有鲁棒的表现。", "innovation": "本文提出了一种新颖的交叉共振三量子比特门，其能够在单一步骤中执行控制-控制-目标和控制-目标-目标操作。通过混合优化方法，它不仅可以实现特定的量子计算任务，如GHZ态制备、复杂的逻辑演示以及控制-ZZ门的实现，还能够直接将两个数据量子比特的状态映射到测量量子比特上，从而在表面码量子纠错中实现更快和更高精度的稳定器测量。此外，该三量子比特门的性能在不同的希尔伯特空间规模下依然保持鲁棒性。这项工作为利用本征多量子比特相互作用设计电路架构和控制协议奠定了基础，是下一代超导量子处理器的核心元素之一。", "conclusion": "本文强调了该三量子比特门在不同希尔伯特空间规模下依然保持鲁棒性，并且为将本征多量子比特相互作用作为下一代超导量子处理器的关键元素的设计方法提供了理论和实验支持。这项工作不仅推进了量子计算领域的技术发展，也为实现更复杂量子计算任务提供了新的可能性。"}
{"llm_update_time": "20250815", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.10677", "html_url": "https://arxiv.org/abs/2508.10677", "title": "提升自主应急响应：利用大型语言模型和网络安全威胁情报", "title_en": "Advancing Autonomous Incident Response: Leveraging LLMs and Cyber Threat Intelligence", "authors": "Amine Tellache,Abdelaziz Amara Korba,Amdjed Mokhtari,Horea Moldovan,Yacine Ghamri-Doudane", "background": "有效的应急响应（IR）对于减轻网络威胁至关重要，但安全团队受到警报疲劳、高误报率和大量的非结构化威胁情报（CTI）文档的困扰。尽管CTI在丰富安全运营方面具有巨大潜力，但其规模庞大且碎片化的特性使得手动分析非常耗时和资源密集。为了弥补这一差距，我们提出了一种基于检索增强生成（RAG）的新颖框架，利用大型语言模型（LLMs）自动化和增强应急响应，通过动态检索CTI进行集成。", "innovation": "该研究引入一种混合检索机制，结合基于NLP的相似性搜索和对外部CTI平台的标准查询，实现在CTI向量数据库内的语境感知情报增强。基于LLM的响应生成模块随后利用增强的人工智能，制定精确、可行且语境相关的应急缓解策略。我们提出了双重评估框架，通过辅助LLM的自动评估和网络空间安全专家的系统交叉验证来进行验证。", "conclusion": "实证验证表明，这种方法提高了应急响应的准确性和语境化，增强了效率，减轻了分析师的工作负担，并降低了响应延迟。这项工作强调了基于LLM的CTI融合在推动自主安全运营和建立智能、自适应的网络安全框架方面的潜力。"}
{"llm_update_time": "20250815", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.10765", "html_url": "https://arxiv.org/abs/2508.10765", "title": "学习霍普菲尔德神经网络中的记忆与遗忘：分岔机制、吸引子与吸引域", "title_en": "Memorisation and forgetting in a learning Hopfield neural network: bifurcation mechanisms, attractors and basins", "authors": "Adam E. Essex(1),Natalia B. Janson(1),Rachel A. Norris(1),Alexander G. Balanov(1) ((1) Loughborough University, England)", "background": "尽管基于人工神经网络(ANN)的人工智能飞速发展，但这些网络在运作过程中充满了‘黑箱’性质，无法清晰了解它们如何在学习过程中形成记忆、发展不良特征，包括虚构记忆和灾难性遗忘现象。现有的研究大多集中在ANN学习的各个孤立方面，但由于高维度和非线性特征，对ANN进行全面分析仍然面临挑战。知识理论层面认为ANN中的知识存储在连接权重或吸引子盆地中，但两者并未被明确联系起来。本文通过分析一个具有81个神经元的Hopfield网络下的Hebbian学习机制，揭示了导致形成和破坏吸引子及其边界分岔机制，旨在克服上述挑战问题并推进对ANN的理解。", "innovation": "本研究的创新点在于，首次创新性地全面分析了Hebbian学习机制下的Hopfield网络中的记忆形成和灾难性遗忘过程，通过展示分岔机制引发了新的吸引子及其盆地的形成，同时伴随着旧记忆的快速消失（灾难性遗忘）。新的学习类别通过新生成的点吸引子的盆地来表示，而其边界则是新生成的鞍点的稳定流形。这表明从某种角度理解，记忆的形成与遗忘是同一机制的两种表现形式。此外，研究的策略对于任何形式的递归ANN进行全面分析具有普适性，并能够提供缓解其缺陷的方法，从而有助于更广泛类型的递归ANN的操作理解并促进相关技术的发展和优化。", "conclusion": "通过对高维递归ANN的分析方法，本研究揭示了记忆形成和灾难性遗忘背后的分岔机制，这不仅帮助我们理解了较广泛类型的递归ANN的操作方式，也为缓解其缺陷提供了潜在的解决方法。"}
{"llm_update_time": "20250815", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.10839", "html_url": "https://arxiv.org/abs/2508.10839", "title": "强化语言模型用于序列决策", "title_en": "Reinforced Language Models for Sequential Decision Making", "authors": "Jim Dilkes,Vahid Yazdanpanah,Sebastian Stein", "background": "大型语言模型（LLMs）在顺序决策代理方面具有潜力，但由于依赖于大型、计算成本高的模型，导致应用受限。现有的后训练方法主要针对单轮交互设计，无法处理多步骤代理任务中的责任归属。", "innovation": "引入了Multi-Step Group-Relative Policy Optimization (MS-GRPO) 算法，这是一种用于后训练LLM代理的新算法。该算法基于正式的Text-Mediated Stochastic Game (TSMG)和Language-Agent Policy (LAP)框架，能够在信用分配中将整个累积奖励分配给每个单独的步骤。此外，提供了新的绝对优势加权的序列采样策略，以提高训练性能。", "conclusion": "实验表明，该方法在改善决策表现方面是有效的。我们后训练的30亿参数模型在冰冻湖任务上比720亿参数基线高出50%。该工作证明了目标后训练是利用LLMs创建顺序决策代理的一种实用和高效的替代方案，而不是依赖模型规模。"}
{"llm_update_time": "20250815", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.10827", "html_url": "https://arxiv.org/abs/2508.10827", "title": "加速系外行星气候建模：通过补充三维GCM网格模拟的机器学习方法", "title_en": "Accelerating exoplanet climate modelling: A machine learning approach to complement 3D GCM grid simulations", "authors": "Alexander Plaschzug,Amit Reza,Ludmila Carone,Sebastian Gernjak,Christiane Helling", "background": "随着观测技术的进步，能够更细致地观测系外行星大气的望远镜的数量和质量不断改善，因此迫切需要更强大的三维气候模型来支持并帮助解释CHEOPS、TESS、JWST、PLATO和Ariel等航天任务的观测数据。然而，通用环流模型（GCMs）在模拟各种系外行星大气时消耗大量计算资源，导致了许多挑战。本文旨在探讨是否可以利用机器学习（ML）算法来预测任意潮汐锁定无气态系外行星的三维温度和风结构。", "innovation": "文章提出了一个新的包含60颗膨胀热巨行星的三维GCM网格，这些行星围绕A、F、G、K和M型主星运行，并使用Exorad进行了建模。研究人员使用深度神经网络（DNN）和决策树算法（XGBoost）训练模型以预测局部气体温度及水平和垂直风速。同时，选择了5颗类目标系外行星（WASP-121 b、HATS-42 b、NGTS-17 b、WASP-23 b和NGTS-1 b）作为测试案例，将这些行星使用ExoRad和两种机器学习方法进行了建模。结果显示，DNN预测的气体温度与计算光谱在所有行星中差异不超过32 ppm，仅有一颗行星的单个HCN特征差异在100 ppm。因此，开发的机器学习模拟器能够可靠地预测A到M型主星周围膨胀温暖到超热潮汐锁定木星的完整三维温度场，并提供一种快速工具来补充和扩展传统三维GCM网格的系外行星群研究。", "conclusion": "这些机器学习工具可以可靠地预测系外行星的三维温度场，适用于A到M型主星周围膨胀温暖到超热潮汐锁定木星的模型。它们为传统GCM网格补充了一个快速工具，为系外行星群体研究提供了有力支持。预测质量如此高，以至于不会影响气体相化学、云形成和传输光谱等方面的效果。"}
{"llm_update_time": "20250815", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.10887", "html_url": "https://arxiv.org/abs/2508.10887", "title": "探索如何为典型基准问题领域配置回声状态网络", "title_en": "Empirical Investigation into Configuring Echo State Networks for Representative Benchmark Problem Domains", "authors": "Brooke R. Weborg,Gursel Serpen", "background": "本文探讨了使用四种不同的基准问题研究回声状态网络（Echo State Network，ESN）的表现。回声状态网络是一种基于水库模型的计算方法，但其参数选择、值设置及其对网络架构性能的影响较为复杂，缺乏经验很难掌握。一些超参数优化算法也需要进行适当的参数选择才能调整参数值。因此，理解回声状态网络架构设计、性能及其参数选择对网络表现的影响对于构建高性能回声状态网络至关重要。", "innovation": "本文提出了针对回声状态网络架构配置的实用规则或经验法则，用于在同类问题中选择和设定参数及其值，以填补研究领域的经验缺口。研究了在不同架构、设计和参数选择及值变化的情况下，回声状态网络性能的影响。", "conclusion": "通过一系列代表不同问题领域的基准任务建模和实验，本文展示了参数选择及其值对回声状态网络架构性能的影响，从而帮助新手更好地理解并配置回声状态网络。"}
{"llm_update_time": "20250815", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.10817", "html_url": "https://arxiv.org/abs/2508.10817", "title": "针对33种作物101类病害的移动友好深度学习：轻量级CNN基准", "title_en": "Mobile-Friendly Deep Learning for Plant Disease Detection: A Lightweight CNN Benchmark Across 101 Classes of 33 Crops", "authors": "Anand Kumar,Harminder Pal Monga,Tapasi Brahma,Satyam Kalra,Navas Sherif", "background": "植物疾病是全球粮食安全的重要威胁。需要开发能够准确检测的早期检测系统。计算机视觉技术的进步有望解决这一挑战。", "innovation": "开发了适合移动设备的解决方案，能够准确分类33种作物的101种植物病害。通过结合Plant Doc、PlantVillage和PlantWild等不同数据集构建了全面的数据集。评估了几种轻量级架构的性能，其中EfficientNet-B1在分类准确率为94.7%的情况下表现出最佳性能。该架构在准确性和计算效率之间取得了良好的平衡，适合实际部署在移动设备上。", "conclusion": "提出的轻量级CNN模型在33种作物的101种植物病害分类任务上表现出了良好的性能，表明该方法可以在资源受限的移动设备上进行有效的植物疾病检测部署。"}
{"llm_update_time": "20250815", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.10851", "html_url": "https://arxiv.org/abs/2508.10851", "title": "CrossDenoise: 一种轻量级实体感知协同框架用于 noisy 暗反馈去噪", "title_en": "CrossDenoise: Denoising Implicit Feedback via a Lightweight Entity-Aware Synergistic Framework", "authors": "Ze Liu,Xianquan Wang,Shuochen Liu,Jie Ma,Huibo Xu,Yupeng Han,Zhe Yang,Kai Zhang,Longfei Li,Jun Zhou", "background": "推荐系统高度依赖隐式反馈，但这些反馈由于误报和漏报等原因是固有的噪音数据，严重影响了推荐的准确度。现有的去噪策略往往忽略了实体感知建模，计算负担高，或需要大量的超参数调优，从而限制了它们的实际应用范围。", "innovation": "提出了一种名为 CrossDenoise 的新型轻量级框架，通过区分用户的、项目的和交互的具体噪声因素来解决这些挑战。此框架利用实证观察指出用户和项目噪声倾向的显著异质性，通过基于排名的线性映射计算实体信誉因子（用户/项目可靠性），并与交互级别权重融合。此设计具有模型无关性、计算效率高且只需两个直观的超参数。在 ML-1M、Yelp 和 Amazon-book 数据集上对 GMF、NeuMF 和 CDAE 的研究表明，CrossDenoise 在所有模型下稳健地优于最先进的基线策略，并且没有显著增加计算和内存开销。我们的分析证实，CrossDenoise 能有效分离干净和噪音样本，并在不同的超参数设置下保持鲁棒性。它提供了一种可实现和可扩展的隐式反馈去噪解决方案。", "conclusion": "CrossDenoise 通过实验证明在去噪隐式反馈方面具有显著的效果且具有鲁棒性，有效地分离了干净样本和噪音样本，提供了简便的超参数设置并具有计算效率，为推荐系统的准确性能提供了一种实际和可扩展的解决方案。"}
{"llm_update_time": "20250815", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2111.04578", "html_url": "https://arxiv.org/abs/2111.04578", "title": "神经网络微调的改进正则化和鲁棒性", "title_en": "Improved Regularization and Robustness for Fine-tuning in Neural Networks", "authors": "Dongyue Li,Hongyang R. Zhang", "background": "迁移学习中广泛应用的算法是微调，即在目标任务上使用预训练模型和少量标注数据进行微调。当预训练模型的容量远大于目标数据集的大小时，微调容易出现过拟合和记忆训练标签的情况。因此，需要对微调进行正则化以确保其对噪声的鲁棒性。", "innovation": "本文分析了微调的泛化特性，提出了基于PAC-Bayes的泛化界，该界依赖于每层在微调过程中所行进的距离以及微调模型的噪声稳定性，并通过实验测量了这些量。提出了一种正则化自标注的方法，包括逐层正则化以限制每层所行进的距离；以及自标注纠正和标签重新加权的做法，用于修正模型有把握的错误标注数据点，并重新加权不太有把握的数据点。该方法在多个预训练模型架构上对多种图像和文本数据集进行了验证，提升了基准方法在七项图像分类任务上的表现平均1.76%，在少量样本分类任务上改善0.75%。此外，在目标数据集包含噪声标签的情况下，该方法在两种噪声环境下平均优于基准方法3.56%。", "conclusion": "本文改进了微调的正则化方法，提升了微调在多种数据集上的性能和鲁棒性。"}
{"llm_update_time": "20250815", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2401.00873", "html_url": "https://arxiv.org/abs/2401.00873", "title": "统一自监督聚类和基于能量的模型", "title_en": "Unifying Self-Supervised Clustering and Energy-Based Models", "authors": "Emanuele Sansone,Robin Manhaeve", "background": "自监督学习擅长从大量数据中学习表示，同时生成模型能够学习数据生成过程的相关信息。本文研究了这两者之间的基本原则连接，并强调了它们互补性的优势。", "innovation": "本文对自监督学习目标进行了分析，引入了一种标准方法进行从基本原理的推导，并指出了一种自然方式将自监督学习与基于似然的生成模型相结合。在基于聚类的自监督学习和能量模型的范畴内实例化此概念，提出了一个可信的下界，能够可靠地惩罚最重要的失败模式，实现完全统一。理论发现通过合成和真实世界数据的实验得到验证，表明目标函数能够在判别和生成方式下联合训练主干网络，最终在聚类、生成和异常检测性能上显著超越现有的自监督学习策略。此外，该解决方案可以集成到神经-符号框架中解决符号接地问题。", "conclusion": "实验结果显示，本文提出的自监督目标函数不仅解决了聚类、生成和异常检测问题，还在神经-符号框架中解决了符号接地问题，因此在判别和生成模式下联合训练主干网络的能力上具有优势。"}
{"llm_update_time": "20250815", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.10515", "html_url": "https://arxiv.org/abs/2508.10515", "title": "虚拟感应在IGBT模块焊料层退化与温度监测中的应用", "title_en": "Virtual Sensing for Solder Layer Degradation and Temperature Monitoring in IGBT Modules", "authors": "Andrea Urgolo,Monika Stipsitz,Helios Sanchis-Alepuz", "background": "监测绝缘栅双极型晶体管(IGBT)模块的退化状态对于确保电力电子系统可靠性和寿命至关重要，尤其是在安全关键和高性能应用中。但由于内部组件的物理不可接近性和恶劣环境，直接测量关键退化指标（如结温、焊接疲劳或剥离）仍然是一个挑战。因此，基于机器学习的虚拟感应提供了一种有前景的替代方案，能够连接可行的传感器位置与相关但不可访问的位置，使系统的监测更加便捷和精确。", "innovation": "本研究探索了一种基于机器学习的虚拟感应方法，以估计IGBT模块焊料层的退化状态和相应的整个温度分布，尽管仅依赖少数物理传感器。通过合成特定退化模式的数据，该研究实现了对焊接失效区域估计的高精度（平均绝对误差1.17%），并且能够以最大相对误差4.56%（对应平均相对误差0.37%）的精度再现IGBT表面温度。", "conclusion": "本研究证明了基于机器学习的虚拟感应技术在IGBT模块中监测焊料层退化和温度分布的可行性，为提高电力电子系统的可靠性提供了新的方法。"}
{"llm_update_time": "20250815", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.10879", "html_url": "https://arxiv.org/abs/2508.10879", "title": "一个自适应噪声的迭代算法实现差分隐私的k-PCA", "title_en": "An Iterative Algorithm for Differentially Private $k$-PCA with Adaptive Noise", "authors": "Johanna Düngler,Amartya Sanyal", "background": "研究内容基于n个零均值共同期望Σ的i.i.d.随机矩阵A_i，目标是在保持差分隐私（DP）的前提下，从Σ中提取最大方差方向的k维子空间。现有方法要么需要样本量n与维度d成超线性关系，即使在A_i呈高斯分布的情况下；要么即使A_i的内部随机性较小，也会因为差分隐私的要求而引入过多的噪声。Liu等（2022a）解决了子高斯数据下估计主特征向量（k=1）的问题，但仅涉及一种算法（DP-PCA）。此研究致力于克服上述限制，首次提出能够在任意k≤d的情况下估计前k个特征向量的算法，同时实现近似理想统计误差，即使n为O(d)。在k>1的一般情况下，研究还提供了下限分析，证明了其方法的有效性并优于现有基准算法.", "innovation": "提出了第一个能够在任意k≤d的情况下估计前k个特征向量的差分隐私PCA算法，克服了现有方法的两个主要限制：对样本量的要求和引入的噪声问题。在k=1的情况下，该算法达到了与DP-PCA相当的实用性表现，即使样本量n为O(d)时也能实现相近最佳的统计误差。还提供了关于一般k>1情况的下界分析，并通过实验验证了该算法在可比基准中的优势.", "conclusion": "该研究提出了一种迭代算法，实现差分隐私的k-PCA，并且在k=1的情况下达到了现有算法的水平，提供了一般k>1情况的最优解分析，实验表明其算法在多方场景中更具有优势。"}
{"llm_update_time": "20250815", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.10875", "html_url": "https://arxiv.org/abs/2508.10875", "title": "Diffusion Language Models", "title_en": "A Survey on Diffusion Language Models", "authors": "Tianyi Li,Mingda Chen,Bowei Guo,Zhiqiang Shen", "background": "扩散语言模型（DLMs）正迅速成为自动回归（AR）范式的有力且有前景的替代方案。DLM通过迭代去噪过程并行生成令牌，从而具有在减少推理延迟和捕捉双向文字段面的优势，使生成过程具有更精细的控制。尽管速度提高了几倍，但最近的进步使得DLMs能与自动回归模型的性能相媲美，因此它们成为各种自然语言处理任务中的理想选择。本综述提供了DLM现状的整体概述，追溯其演变及其与其它范式如自动回归和掩码语言模型的关系，并涵盖了基础原理和先进模型。我们还探讨了DLM的推理策略和优化措施，包括解码并行性、缓存机制以及生成质量的改进。我们强调了DLM在多模态扩展方面的最新方法及其在各种实际场景中的应用。此外，讨论也指出了DLM的局限性和挑战，如效率、长序列处理和基础设施要求，并明确了未来的研究方向来维持这一快速发展的领域的发展。", "innovation": "DLMs通过迭代去噪过程并行生成令牌，从而在减少推理延迟和捕捉双向文字段面方面具有优势，使生成过程具有更精细的控制。尽管速度提高了几倍，但最近的进步使得DLMs能与自动回归模型的性能相媲美，因此它们成为各种自然语言处理任务中的理想选择。本综述提供了扩散语言模型现状的整体概述，包括基础原理和先进模型；并对DLM的推理策略和优化措施进行了深入探讨。同时，也强调了DLM在多模态扩展方面的最新方法及其在各种实际场景中的应用；并对DLM的局限性和挑战进行了讨论，明确了未来的研究方向来维持这一快速发展的领域的发展。", "conclusion": "综上所述，本综述提供了DLM现状的整体概述，涵盖了基础原理和先进模型，包括预训练策略和高级后处理方法；详细分析了DLM的推理策略和优化措施；指出了DLM在多模态扩展方面的最新方法及其在各种实际场景中的应用；并讨论了DLM的局限性和挑战，明确未来的研究方向以持续推动这一快速发展的领域。"}
{"llm_update_time": "20250815", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2402.13871", "html_url": "https://arxiv.org/abs/2402.13871", "title": "基于可解释转换器模型的钓鱼邮件检测：一种大型语言模型方法", "title_en": "An Explainable Transformer-based Model for Phishing Email Detection: A Large Language Model Approach", "authors": "Mohammad Amaz Uddin,Md Mahiuddin,Iqbal H. Sarker", "background": "钓鱼邮件是对网络空间构成严重威胁的一种形式，常通过发送虚假邮件来误导用户，旨在窃取敏感信息或造成经济损失。攻击者常伪装成可信实体，利用技术进步和复杂性使其检测和预防更加困难。尽管有广泛的学术研究，钓鱼邮件检测仍然是网络安全领域的持续且艰巨的挑战。大型语言模型（LLMs）和掩码语言模型（MLMs）具有巨大的潜力，可以提供创新性的解决方案来应对长期存在的挑战。", "innovation": "本研究提出了一种优化微调的DistilBERT模型，专门用于钓鱼邮件检测。在检测过程中，利用预处理技术解决不均衡类别的问题，并通过实验验证模型的有效性。此外，使用可解释的人工智能（XAI）技术（如局部可解释模型无关解释LIME和转换器解释）来解释模型预测过程，增强了模型的可解释性。", "conclusion": "本研究利用优化并微调的转换器模型，在钓鱼邮件检测任务上取得了高准确率，同时通过XAI技术增强了模型的可解释性。"}
{"llm_update_time": "20250815", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2112.06362", "html_url": "https://arxiv.org/abs/2112.06362", "title": "在具有随机双线性奖励的并行服务器队列中学习调度", "title_en": "Learning to Schedule in Parallel-Server Queues with Stochastic Bilinear Rewards", "authors": "Jung-hun Kim,Milan Vojnovic", "background": "考虑多类、并行服务器排队系统中不确定的作业-服务器分配奖励问题。在这种情况下，作业在等待完成时会产生持有成本，而作业-服务器分配则产生可观察的随机奖励，但其平均值未知。我们假设作业-服务器分配的平均奖励遵循特征化的作业和服务器属性的双线性模型。目标是在时间窗口内最大化作业-服务器分配的累积奖励，同时控制作业持有成本，确保排队系统的稳定性。这个问题特别适用于网络系统的资源分配应用，需要在提高网络吞吐量的同时实现资源的公平分配。因此，必须维护奖励最大化与排队系统稳定性之间的平衡。", "innovation": "提出了一种基于加权公平调度和边际成本的算法，并结合了专门针对双线性奖励的多臂老虎机算法。该算法在时间窗口T内的遗憾可以保证为亚线性，即$\tilde{O}(\frac{1}{\text{sqrt}(T)})$，并且持有成本（和队列长度）为$\tilde{O}(\frac{1}{\text{sqrt}(T)})$。此外，还建立了分布式迭代算法的稳定性条件，适用于大规模系统应用。", "conclusion": "通过数值实验验证了算法的有效性，证明了该算法在确保排队系统稳定性的前提下能够高效地进行调度。"}
{"llm_update_time": "20250815", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2406.04443", "html_url": "https://arxiv.org/abs/2406.04443", "title": "剪枝提高了Adam-Norm和AdaGrad-Norm在噪声为重尾时的表现", "title_en": "Clipping Improves Adam-Norm and AdaGrad-Norm when the Noise Is Heavy-Tailed", "authors": "Savelii Chezhegov,Yaroslav Klyukin,Andrei Semenov,Aleksandr Beznosikov,Alexander Gasnikov,Samuel Horváth,Martin Takáč,Eduard Gorbunov", "background": "自适应步长方法，如AdaGrad和Adam，对训练现代深度学习模型至关重要，尤其是大语言模型。通常情况下，后期的随机梯度噪声较大，这种重尾噪声可能严重影响模型的收敛效果。虽然梯度裁剪已被证明能改善这些噪声条件下的高概率收敛，但对于AdaGrad/Adam这类方法的高概率收敛性理解仍有限，特别是在重尾噪声环境下。", "innovation": "本研究证明了当噪声为重尾时，AdaGrad/Adam（包括延迟版本）可能会有糟糕的高概率收敛表现。研究还展示了通过梯度裁剪问题可以被解决，并基于此得到了带有裁剪的Adam-Norm和AdaGrad-Norm的新的高概率收敛性界，其中对平滑凸/非凸随机优化的处理具有多项对数依赖于置信水平。进一步将结果扩展到重尾噪声情况下的延迟步长的AdaGrad/Adam方法。实验结果表明裁剪的AdaGrad/Adam方法擅长处理重尾噪声。", "conclusion": "本研究证明了当噪声为重尾时，梯度裁剪能够改善AdaGrad-Norm和Adam-Norm的表现，并提供了新的收敛性界。实验结果显示裁剪的AdaGrad/Adam在处理重尾噪声方面更为优越。"}
{"llm_update_time": "20250815", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2409.07275", "html_url": "https://arxiv.org/abs/2409.07275", "title": "通过隐式正则化实现的无调参在线鲁棒主成分分析", "title_en": "Tuning-Free Online Robust Principal Component Analysis through Implicit Regularization", "authors": "Lakshmi Jayalal,Gokularam Muthukrishnan,Sheetal Kalyani", "background": "标准的在线鲁棒主成分分析(OR-PCA)技术性能取决于显式正则化参数的最佳调整，而这些参数对数据集敏感。目前的挑战在于如何去除对这些调参参数的依赖，以提高鲁棒性和适用性。", "innovation": "本文通过使用隐式正则化来规避对显性正则化参数的调参需求。提出了一种利用不同修改的梯度下降方法中的隐式正则化效果的方法，以实现无调参的OR-PCA。三种不同版本的修改梯度下降方法分别自然地促进数据的稀疏性和低秩结构。该方法在模拟和实际数据集上表现出色，与调参的OR-PCA相比，具有可比性或更好的性能，且能够更高效地处理大规模数据集，无需依赖数据集特定的参数调整。", "conclusion": "本文方法通过使用隐式正则化去除了对显性正则化参数的调参依赖，提高了OR-PCA方法的鲁棒性和应用范围，特别适用于大规模数据集，无需进行数据集相关的参数调优。"}
{"llm_update_time": "20250815", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2406.17184", "html_url": "https://arxiv.org/abs/2406.17184", "title": "一般估值模型下的可加性最优性在上下文动态定价中的研究", "title_en": "Minimax Optimality in Contextual Dynamic Pricing with General Valuation Models", "authors": "Xueping Gong,Wei You,Jiheng Zhang", "background": "该研究探讨了基于可观察上下文定制个人化定价机制的动态定价问题。顾客会根据接收到的价格决定是否购买，而顾客的估值被视为上下文的未知潜在函数，受到未知分布但独立同分布市场噪音的干扰。研究者基于噪声分布的利普希茨连续性及估值的有界条件，提出了一个最优的算法。", "innovation": "作者提出了一种新方法，在估值模型和噪音分布未知的情况下，通过离散化相关的噪音范围形成候选价格集，采用分层数据分区技术，获得比椭圆势能引理推得的置信区间更紧的置信边界。特别地，估值函数的预测偏差在比对上置信边界时相互抵消，无需知道利普希茨常数。这种方法不仅适用于线性模型，还能通过离线回归或acles推广到更广泛的函数类中。此外，通过附加结构（如线性估值模型、二阶平滑性、稀疏性等）来进一步细化保证，并将其结果与之前动态定价方法进行比较和阐述。", "conclusion": "作者通过理论分析证明了所提出算法的效果，给出了对数因子内的最小最大遗憾上界。进一步地，作者在不同结构下提供了更精细的保证，展示了该算法在多个方面的优势，并通过数值实验验证了理论的有效性和算法的优越性。"}
{"llm_update_time": "20250815", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2410.10915", "html_url": "https://arxiv.org/abs/2410.10915", "title": "HGAurban: Heterogeneous Graph Autoencoding for Urban Spatial-Temporal Learning", "title_en": "HGAurban: Heterogeneous Graph Autoencoding for Urban Spatial-Temporal Learning", "authors": "Qianru Zhang,Xinyi Gao,Haixin Wang,Dong Huang,Siu-Ming Yiu,Hongzhi Yin", "background": "在城市感知应用中，如交通分析、人类移动行为建模和全市犯罪预测中，空间-时间图形表示起着关键作用。然而，空间-时间数据的噪声和稀疏性限制了现有神经网络学习有意义的空间区域表示的能力。", "innovation": "我们提出了HGAurban，一种新颖的非均匀空间-时间图形掩码自动编码器，利用生成式自监督学习以实现健壮的城市数据表示。该框架引入了空间-时间非均匀图形编码器，从多源数据中提取区域间的依赖性，使不同空间关系的建模更加全面。在自监督学习范式中，我们实现了掩码自动编码器，联合处理节点特征和图形结构。这种方法自动学习区域间的非均匀空间-时间模式，显著提高了动态时间相关性的表示。", "conclusion": "我们在多个空间-时间挖掘任务中的全面实验表明，我们的框架优于最先进的方法，并且能够有效处理现实世界的城市数据挑战，包括空间和时间维度上的噪声和稀疏性。"}
{"llm_update_time": "20250815", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.10841", "html_url": "https://arxiv.org/abs/2508.10841", "title": "带显式长程相互作用的通用机器学习势在生物分子模拟中的性能", "title_en": "Performance of universal machine-learned potentials with explicit long-range interactions in biomolecular simulations", "authors": "Viktor Zaverkin,Matheus Ferraz,Francesco Alesiani,Mathias Niepert", "background": "通用机器学习势能够跨越组成和振动自由度提供可转移的准确性，但其在生物分子模拟中的应用尚处于起步阶段。本文系统性地评估了在SPICE-v2数据集上训练的对称信息传递架构的表现，包括是否包含显式长程迟滞和静电作用。作者检测了模型规模、训练数据构成、静电处理对基准和分子模拟数据集性能的影响。", "innovation": "本文通过系统性地评估包含和不包含长程作用的对称信息传递架构，并在多种情境下（包括基础数据集测试和生物分子模拟）评估其表现，推动了通用机器学习势在生物分子模拟中的应用。", "conclusion": "尽管更大规模的模型在基准数据集上提高了准确性，但在模拟中这一趋势并未保持一致。预测的性质取决于训练数据的构成。长程静电作用在大部分系统中没有系统性的影响，但对于Trp-cage，它们的引入增加了构象的多样性。研究结果表明，不平衡的数据集和不成熟的评价方法目前限制了通用机器学习势在生物分子模拟中的应用。"}
{"llm_update_time": "20250815", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2410.06151", "html_url": "https://arxiv.org/abs/2410.06151", "title": "通过外部行为好奇心多样化策略行为", "title_en": "Diversifying Policy Behaviors with Extrinsic Behavioral Curiosity", "authors": "Zhenglin Wan,Xingrui Yu,David Mark Bossens,Yueming Lyu,Qing Guo,Flint Xiaofeng Fan,Yew Soon Ong,Ivor Tsang", "background": "模仿学习（IL）在机器人移动等应用中显示出潜力，但通常仅限于学习单一的专家策略，这限制了行为多样性并在不可预测的实际场景中降低了鲁棒性。为解决这一问题，本文引入了质量多样性逆向强化学习（QD-IRL）框架，结合了质量多样性优化和IRL方法，使智能体能够从有限的演示中学习多种行为。通过引入外部行为好奇心（EBC），该方法允许智能体从外部评论员（基于行为的新颖性与大型行为档案的比较）接收额外的好奇心奖励，以探索多样化的移动行为。", "innovation": "本文提出了一种新型框架QD-IRL，集成了质量多样性优化和IRL方法，能够使智能体从有限的演示中学习多种行为。引入了外部行为好奇心（EBC），这是一种激励机制，智能体可以基于其行为与已有行为档案的新颖性获得额外的好奇心奖励。实验表明，EBC能显著提升QD-IRL等算法的表现，特别是在人类上下文环境中，甚至超越了专家级表现。此外，该方法还适用于基于梯度树结构的质量多样性强化学习（QD-RL），并显著提升了这些算法的性能。", "conclusion": "通过使用外部行为好奇心，QD-IRL能够显著提高多种移动任务上的表现，甚至超过专家级性能20%，并且适用于多种QD-RL算法，适用于梯度-Arborescence等基础架构。研究成果的代码已开源。"}
{"llm_update_time": "20250815", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2410.18368", "html_url": "https://arxiv.org/abs/2410.18368", "title": "CPU 设计空间探索中的多目标优化：需要关注", "title_en": "Multi-objective Optimization in CPU Design Space Exploration: Attention is All You Need", "authors": "Runzhen Xue,Hao Wu,Mingyu Yan,Ziheng Xiao,Guangyu Sun,Xiaochun Ye,Dongrui Fan", "background": "现代 CPU 设计中设计空间探索 (DSE) 至关重要，但由于现有框架难以在高维度架构空间中扩展和泛化，当前框架面临三个根本挑战：（1）大型设计空间中代理模型的准确性降低和扩展性差；（2）通过手工构建的启发式方法或穷尽搜索指导采集效率低下；（3）可解释性有限，难以定位架构瓶颈。随着设计空间维度的不断增加，这些挑战加剧了现有 DSE 框架的适用性问题。", "innovation": "提出了一种名为 AttentionDSE 的端到端 DSE 框架，它通过基于注意力的神经架构实现了性能预测和设计指导的天然集成。关键创新包括：（1）一种感知驱动的机制，利用架构层次结构和邻近性，通过滑动窗口将注意力复杂度从 O(n^2) 降低到 O(n)，实现扩展性；（2）一种注意力感知的瓶颈分析，能够自动识别关键参数进行有针对性的优化，从而消除领域特定启发式的依赖。在 SPEC CPU2017 架构测试套件上对高维度 CPU 设计空间进行评估，AttentionDSE 达到了更高的帕累托假设体积和探索时间的显著减少。", "conclusion": "AttentionDSE 框架通过引入基于注意力的机制和自动化瓶颈分析，极大地提升了设计决策的准确性和可解释性，从而在高维度设计空间中展现出显著的效果，解决了现有 DSE 框架的常见问题。"}
{"llm_update_time": "20250815", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2410.21072", "html_url": "https://arxiv.org/abs/2410.21072", "title": "特征和时间上错位数据的联邦时间序列生成", "title_en": "Federated Time Series Generation on Feature and Temporally Misaligned Data", "authors": "Zhi Wen Soi,Chenrui Fan,Aditya Shankar,Abele Mălan,Lydia Y. Chen", "background": "联邦学习在处理分布式时间序列数据时面临挑战，因为不同客户端的数据集可能包含不同的特征集中且时间步长也不同。目前的联邦时间序列模型大多假设所有客户端在特征和时间步长上完全对齐，这种假设限制了模型的适用性和效果。", "innovation": "提出了一种名为FedTDD的新联邦时间序列扩散模型，它联合学习跨客户端的合成器。该模型的核心是一个新颖的数据蒸馏和聚合框架，通过填补对齐错误来协调客户端之间的差异。与传统联邦学习只交换模型参数不同，FedTDD通过交换本地合成输出来学习客户端时间序列之间的相关性。协调器通过在客户端之间交换合成数据共享知识，逐步改进全局蒸馏网络。随着蒸馏器的细化，它提高了客户端本地特征估计的质量，从而允许每个客户端使用最新的更准确的蒸馏器更好地填充缺失数据。", "conclusion": "实验结果表明，FedTDD相比集中式训练更有效，并展示了通过共享合成输出转移本地时间序列知识的有效性。FedTDD在Context-FID和相关性评分上分别实现了79.4%和62.8%的改进与本地训练相比。"}
{"llm_update_time": "20250815", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2501.02409", "html_url": "https://arxiv.org/abs/2501.02409", "title": "受扰动下可解释的神经常微分方程方法用于基因调控网络的发现", "title_en": "Interpretable Neural ODEs for Gene Regulatory Network Discovery under Perturbations", "authors": "Zaikang Lin,Sei Chang,Aaron Zweig,Minseo Kang,Elham Azizi,David A. Knowles", "background": "现代高通量生物数据集提供了大规模发现代表基因调控之间因果关系的因果图的机会。现有的基于可微分因果图模型能够从大规模干预数据集中推断基因调控网络，捕捉基因扰动的因果基因调控关系。然而，现有的模型在表达能力和可扩展性方面有限，无法处理诸如细胞分化等生物学过程的动态性质。", "innovation": "提出了一种新型框架PerturbODE，该框架结合了生物学信息丰富的神经常微分方程，用于模拟扰动下的细胞状态轨迹，并从这些神经常微分方程的参数中推导出因果基因调控网络。PerturbODE在模拟和真实的过表达数据集中显示了在轨迹预测和基因调控网络推理中的有效性。", "conclusion": "PerturbODE框架有效地处理了现有模型的局限性，特别是针对动态生物学过程。该方法在轨迹预测和基因调控网络推断方面展示了显著的性能，具备解释性和适用性，为基因调控网络的研究提供了新的视角。"}
{"llm_update_time": "20250815", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2411.07837", "html_url": "https://arxiv.org/abs/2411.07837", "title": "FRUGAL：通过减少状态开销实现高效内存优化以实现可扩展训练", "title_en": "FRUGAL: Memory-Efficient Optimization by Reducing State Overhead for Scalable Training", "authors": "Philip Zmushko,Aleksandr Beznosikov,Martin Takáč,Samuel Horváth", "background": "随着大型语言模型参数量的增加，预训练和微调过程对GPU内存的需求也在增长。优化器状态通常会消耗大量内存。现有的方法如低秩适应（LoRA），低秩梯度投影（GaLore）和区块优化（BAdam）虽然能节省内存，但受限于加权更新的低秩效应，可能会导致梯度信息丢失，尤其是在预训练期间更为严重。", "innovation": "本文提出了一种新的高效内存优化框架FRUGAL（Full-Rank Updates with Gradient Splitting）。FRUGAL利用梯度拆分进行低维更新，使用高级算法（如Adam）完成低维更新部分，而其他方向的更新则通过无状态方法（如SGD或signSGD）进行。该框架可以与各种低秩更新选择技术结合使用，包括GaLore和BAdam。在某些固定内存预算下，该方法在预训练和微调任务中表现优于现有方法，同时兼顾了内存效率和性能指标。", "conclusion": "我们为使用SGDM进行低维更新和使用SGD进行无状态更新提供了理论收敛保证。实验证明，FRUGAL在各种固定内存预算下具有竞争力的表现，实现了预训练和微调任务的最佳性能，同时保持了良好的内存效率和性能指标平衡。"}
{"llm_update_time": "20250815", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2502.01618", "html_url": "https://arxiv.org/abs/2502.01618", "title": "Rollout Roulette: 使用基于粒子的蒙特卡洛方法的LLM推理时长概率推理方法", "title_en": "Rollout Roulette: A Probabilistic Inference Approach to Inference-Time Scaling of LLMs using Particle-Based Monte Carlo Methods", "authors": "Isha Puri,Shivchander Sudalairaj,Guangxuan Xu,Kai Xu,Akash Srivastava", "background": "大型语言模型（LLMs）通过扩大模型规模和/或数据量取得了显著的性能提升。然而，近期的证据表明，这样的方法在提高性能上越来越无效，因此需要在推理时扩大计算量。现有的推理时长扩展方法通常使用奖励模型将任务视为搜索问题，这容易受到奖励欺诈的影响，尤其是在奖励模型近似错误的情况下。", "innovation": "本文将推理时长扩展视为概率推理任务，利用基于采样的技术探索状态-空间模型状态分布的典型集，而非直接优化其极值。提出了一种新的基于粒子的蒙特卡罗方法的推理时长扩展方法。实验结果表明，该方法在各种具有挑战性的数学推理任务上相较于确定性搜索法表现出了4-16倍的扩展率提升。", "conclusion": "我们的工作不仅提出了一种有效的推理时长扩展方法，还把概率推理领域的丰富文献与LLMs的推理时长扩展连接起来，旨在未来开发更为稳健的算法。"}
{"llm_update_time": "20250815", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2409.12446", "html_url": "https://arxiv.org/abs/2409.12446", "title": "低复杂度数据上神经网络具有泛化能力", "title_en": "Neural Networks Generalize on Low Complexity Data", "authors": "Sourav Chatterjee,Timothy Sudijono", "background": "文章基于给定简单编程语言生成的独立同分布数据，探讨了前馈神经网络在ReLU激活下的泛化能力。文章定义了一种简单的编程语言及其网络描述长度的概念，通过描述长度最小化的学习方法，网络可以有效描述和泛化简单的计算任务，如质数检测等。文章还讨论了该方法在噪声数据中的稳定性，表明即使在噪声数据上，MDL神经网络插值器也能表现出适度的过拟合现象。", "innovation": "文章创新性地提出了一种基于MDL（最小描述长度）的插值神经网络，该网络可以有效地泛化低复杂度数据。对于质数检测任务，证明了一个随机抽取的i.i.d.样本，通过插值的MDL网络可以以概率1-O((ln N)/n)高的准确率预测新的随机抽取的数据是否为质数。这种方法不需要专门为质数检测设计网络，而是通过MDL自动学习得到这样的网络。此外，还讨论了在噪声数据上的应用情况。", "conclusion": "文章表明，最小描述长度下的插值前馈神经网络可以有效泛化低复杂度数据，特别是可以基于简单的编程语言生成的数据以及噪声数据，展示了在网络泛化能力上的突破。"}
{"llm_update_time": "20250815", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2502.01669", "html_url": "https://arxiv.org/abs/2502.01669", "title": "基于影响函数的延迟反馈建模", "title_en": "Delayed Feedback Modeling with Influence Functions", "authors": "Chenlu Ding,Jiancan Wu,Yancheng Yuan,Cunchun Li,Xiang Wang,Dingxian Wang,Frank Yang,Andrew Rabinovich", "background": "在基于每次转化付费（CPA）的在线广告模型中，准确的转化率（CVR）预测至关重要。主要挑战是延迟反馈，即转化可能在用户互动后很长时间才发生，导致近期数据不完整且模型训练偏颇。现有解决方案在一定程度上缓解了这一问题，但通常依赖于辅助模型，使它们计算效率低下且对用户兴趣的变化不够适应.", "innovation": "我们提出了IF-DFM（Influence Function-empowered for Delayed Feedback Modeling），它通过估计新到达和延迟转化对模型参数的影响，实现高效更新而无需完全重新训练。通过将逆海森矩阵向量乘积重新表述为优化问题，IF-DFM在扩展性和有效性之间实现了良好的权衡。实验表明，在基准数据集上，IF-DFM在准确性和适应性方面均优于先前的方法.", "conclusion": "IF-DFM通过有效利用新到达和延迟转化的影响更新模型参数，能够在保持计算效率的同时提高模型的适应性和准确性。实验结果证明了该方法的有效性。"}
{"llm_update_time": "20250815", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2410.10320", "html_url": "https://arxiv.org/abs/2410.10320", "title": "DiRW: 面向异质性的路径感知有向图学习", "title_en": "DiRW: Path-Aware Digraph Learning for Heterophily", "authors": "Daohan Su,Xunkai Li,Zhenjun Li,Yinping Liao,Rong-Hua Li,Guoren Wang", "background": "近年来，图神经网络（GNN）已成为处理图结构数据的强大表示学习工具。然而，大多数方法针对的是无向图，未能利用有向图（有向图）边中的丰富信息。事实上，有向图在现实世界中广泛使用，并被证实能够解决异质性挑战。尽管有近期的进步，现有的基于空间和频域的空间-频域图神经网络（DiGNNs）仍存在因复杂的学习机制和对高质量拓扑的依赖而导致的低效率和不稳定性能的问题。", "innovation": "为了解决上述问题，本文提出了一个名为DiRW的新模型，这是一种可插拔策略，适用于大多数基于空间的方法，同时也为有向图学习提供了新的范式。DiRW通过一个对节点和拓扑敏感的方向感知路径采样器，从走法概率、长度和数量的角度优化，实现了无需权重的路径采样。在这个基础上，DiRW引入了节点级可学习路径聚合器，以实现泛化节点表示。广泛的实验数据显示了DiRW的优势，它能够作为可插拔策略增强大多数基于空间的方法，同时也能作为新的有向图学习范式实现SOTA性能。", "conclusion": "由于其高效和稳定的表现，DiRW可以在9个数据集上显著提升最常用的空间基线方法，并且能够作为基于有向图的新学习模型达到SOTA性能。源代码和数据可在此链接：this https URL 获取。"}
{"llm_update_time": "20250815", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2502.18052", "html_url": "https://arxiv.org/abs/2502.18052", "title": "准确的竞争市场：在竞争下的分类", "title_en": "A Market for Accuracy: Classification under Competition", "authors": "Ohad Einav,Nir Rosenfeld", "background": "机器学习模型对于希望在消费者市场获得市场份额的服务提供商至关重要。然而，传统的学习方法没有考虑到其他竞争对手的存在，这些竞争对手也在争夺消费者。本文研究在这种包含竞争对手的市场中学习的影响，涉及提供商、消费者和市场本身。", "innovation": "本文提出了一种在竞争下的分类方法，以便学习者能够在竞争对手存在的情况下最大化市场份额。研究表明，市场进入时机和模型更新的时间对提供商和消费者都有益，且整个市场的稳定性可以通过迅速达到均衡来实现。", "conclusion": "本文展示了这种方法在多种领域中的有效性，从简单的数据分布到嘈杂的数据集，都证明了市场整体保持稳定，通过迅速向均衡状态收敛。"}
{"llm_update_time": "20250815", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2502.04164", "html_url": "https://arxiv.org/abs/2502.04164", "title": "在重尾噪声下高效的分布式优化", "title_en": "Efficient Distributed Optimization under Heavy-Tailed Noise", "authors": "Su Hyeong Lee,Manzil Zaheer,Tian Li", "background": "分布式优化现已成为现代机器学习中的默认培训范式，尤其是随着模型和数据集规模的不断扩大。为减轻通信开销，常在全局聚合之前进行局部更新，形成嵌套优化方法，其中包含内层和外层步骤。然而，在基于注意力的模型中，重尾随机梯度噪声依然是一个重要挑战，严重影响有效的训练效果。", "innovation": "本文提出了TailOPT，一个高效框架，旨在通过自适应优化或剪裁技术来解决重尾噪声问题。TailOPT提供了在带有潜在无界梯度方差和局部更新的重尾噪声情况下的收敛保证。特别地，通过Bi^2Clip变体，实现了坐标wise的剪裁，同时不需要维护或传输额外的梯度统计数据，即获得了接近自适应表现（例如Adam）的效果。", "conclusion": "实验证明，包括Bi^2Clip在内的TailOPT在多个语言任务和模型上均表现出色，超越了现有最先进的方法。"}
{"llm_update_time": "20250815", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2502.12188", "html_url": "https://arxiv.org/abs/2502.12188", "title": "通过推理时自适应增强基于扩散的神经组合求解器的跨问题泛化能力", "title_en": "Boosting Cross-problem Generalization in Diffusion-Based Neural Combinatorial Solver via Inference Time Adaptation", "authors": "Haoyu Lei,Kaiwen Zhou,Yinchuan Li,Zhitang Chen,Farzan Farnia", "background": "扩散基神经组合优化（NCO）通过学习离散扩散模型来生成解决方案，从而实现求解NP完全(NPC)问题的有效性，但现有的NCO方法在跨规模和跨问题的一般化方面存在显著挑战，并且与传统求解器相比存在较高的训练成本。虽然最近有关扩散模型的研究引入了无需训练的指导方法，这些方法利用预先定义的引导函数进行条件生成，但这些方法尚未在组合优化方面得到广泛研究。", "innovation": "提出了一种无需训练的推理时间自适应框架 (DIFU-Ada)，该框架在无需额外训练的情况下，使基于扩散的NCO求解器具备在不同问题规模上的零样本跨问题转移能力和跨尺度泛化能力。提供了理论分析以帮助理解跨问题转移能力。", "conclusion": "实验结果表明，仅在旅行商问题(TSP)上训练的扩散求解器，通过推理时自适应，能够实现跨不同问题规模的TSP变种(如奖品收集旅行商问题(PCTSP)和路线选择问题(OP))的竞争力零样本转移性能。"}
{"llm_update_time": "20250815", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2503.19530", "html_url": "https://arxiv.org/abs/2503.19530", "title": "VectorFit：预训练基础模型的自适应奇异向量及偏置向量微调", "title_en": "VectorFit : Adaptive Singular & Bias Vector Fine-Tuning of Pre-trained Foundation Models", "authors": "Suhas G Hegde,Shilpy Kaur,Aruna Tiwari", "background": "现有PEFT方法通过并行化新低秩或稀疏可训练权重来减少可训练参数数量，但这些权重是从头开始训练的。因此，在预算较低的场景下，这些方法与完全微调之间的性能差距较大。", "innovation": "提出VectorFit方法，通过自适应训练预训练权重W中的奇异向量和偏置，有效利用现有知识，形成高阶增量权重矩阵$\triangle W$，与完全微调效果相近，并且在可训练参数减少9倍的情况下仍能获得更优结果。", "conclusion": "通过在19个覆盖广泛语言和视觉任务的数据集上的全面实验，表明VectorFit在参数效率与性能之间的权衡上优于基准方法。"}
{"llm_update_time": "20250815", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2502.08644", "html_url": "https://arxiv.org/abs/2502.08644", "title": "Rhythmic sharing: 一种生物学启发的神经网络零样本适应性学习范式", "title_en": "Rhythmic sharing: A bio-inspired paradigm for zero-shot adaptive learning in neural networks", "authors": "Hoony Kang,Wolfgang Losert", "background": "大脑能够快速适应新环境并从有限的数据中学习，这是人工智能算法难以达到的一种特性。受到神经细胞机械振荡节律的启发，研究开发了一种利用连接强度振荡的学习范式，其中学习与这些振荡的协调相关。这种振荡可以快速改变协调，使网络能够感知和适应细微的环境变化，而无需监督。网络成为一个通用的人工智能架构，能够预测多个环境包括未见过的环境的动力学。", "innovation": "研究人员开发了一种利用连接强度振荡的学习范式，将振荡的协调与学习相关联，允许网络在无需监督的情况下快速感知和适应细微的环境变化。这种范式不仅能够预测多个已知环境的动力学，还能预测未见过的环境的动力学，成为构建新颖认知模型的强大起点。这种方法对神经网络的具体细节是无关的，从而为将快速适应性学习引入领先的AI模型开辟了道路。", "conclusion": "这种基于振荡协调的学习范式提供了一种生物学启发的方法来实现零样本适应性学习，这为认知模型的新建提供了强有力的基础。由于这种方法对神经网络的具体细节没有特定要求，其应用潜力巨大，可以引入到现有的先进人工智能模型中，以增强其适应性和创新能力。"}
{"llm_update_time": "20250815", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2502.20012", "html_url": "https://arxiv.org/abs/2502.20012", "title": "学习生成市场的分类器", "title_en": "Learning Classifiers That Induce Markets", "authors": "Yonatan Sommer,Ivri Hikri,Lotan Amit,Nir Rosenfeld", "background": "在决定人类事项（如贷款、雇佣或入学）时使用学习来提供预测，可能激励用户为了获得积极的预测而战略性地修改自身特征，但这会带来成本。通常假设成本函数是外生的、固定的，被预先确定。本文挑战了这一假设，认为成本可能是由于部署分类器而产生的。用户为了获得积极预测，会增加对重要特征的需求；如果这些特征可购买，市场需求将形成并推动市场定价机制，因此竞争会导致出现价格。现有研究框架并未考虑这一现象带来的市场影响，本文扩展并构建了一个新的框架，探讨在分类器能够诱导特征市场的情况下，学习的任务特性、市场定价算法、以及不同可学习框架下的学习过程。", "innovation": "本文创新地引入了一个全新的学习框架，专门针对分类器能够诱导特征市场的场景进行了研究。它在传统框架中融入了市场需求和定价机制，提出了计算市场定价的算法，并设计了一个可微学习框架，实现了学习过程与市场需求的动态交互。", "conclusion": "本文通过扩展战略分类框架，探讨了在分类器诱导特征市场情况下学习任务的新特性。提出了市场定价算法并建立了可微学习框架，通过实验证明了该新框架的有效性，为理解用户与特征市场的互动提供了新的视角。"}
{"llm_update_time": "20250815", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2503.10509", "html_url": "https://arxiv.org/abs/2503.10509", "title": "从行为到语言：强化学习中抽象文本策略总结的研究", "title_en": "From Actions to Words: Towards Abstractive-Textual Policy Summarization in RL", "authors": "Sahar Admoni,Assaf Hallak,Yftah Ziser,Omer Ben-Porat,Ofra Amir", "background": "现有的基于强化学习（RL）算法生成的策略难以向用户解释，因为这些策略源自复杂奖励结构和神经网络表示的交互。这使得分析和预测智能体的行为变得困难，从而影响用户在实际应用中的信任。目前，用户了解智能体行为的主要方法是通过视频示例，但这种方法只能将有限的示例展示给用户，并且需要用户自行解码行为模式以理解其本质。", "innovation": "本文提出了SySLLM（Synthesized Summary using Large Language Models），这是一种使用大语言模型（LLMs）生成抽象文本策略总结的新方法。大语言模型拥有丰富的世界知识和模式合成能力，能够从智能体的学习轨迹中生成结构化的、易于理解的文字摘要，从而为用户提供有价值的策略见解。SySLLM能够在零样本设置下解释时空结构化的状态-动作轨迹，而无需任何先验知识或微调。实验结果表明，与基于演示的总结相比，SySLLM能够更好地被用户接受，超过了一半以上的参与者（75.5%）偏好SySLLM的总结，特别是对于关键洞察如目标偏好和探索策略的识辨能力得到了人类专家的认可。", "conclusion": "SySLLM能够生成易于理解的策略总结，适用于零样本设置，帮助用户更好地理解智能体的行为，实现了从行为到语言的转变。"}
{"llm_update_time": "20250815", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2504.17493", "html_url": "https://arxiv.org/abs/2504.17493", "title": "目标导向的时间序列预测：基础框架设计", "title_en": "Goal-Oriented Time-Series Forecasting: Foundation Framework Design", "authors": "Luca-Andrei Fechete,Mohamed Sana,Fadhel Ayed,Nicola Piovesan,Wenjie Li,Antonio De Domenico,Tareq Si Salem", "background": "传统的时序预测方法通常旨在最小化整体预测误差，而不考虑下游应用中不同预测范围的重要性差异。在实际应用中，预测某些特定时间段的数据可能比其他时间段更为关键。", "innovation": "本文提出了一种培训方法，能够让预测模型在推理时根据应用的具体需求重心转移，而无需重新训练。该方法在训练过程中将预测空间细分为多个段，并动态重新加权和聚合，以强调应用指定的目标范围。与之前需要预定义这些范围的方法不同，本文的框架支持灵活的、按需调整。", "conclusion": "在标准基准测试和新收集的无线通信数据集上的实验表明，这种方法不仅在目标区域提高了预测准确性，也在下游任务性能上带来了可衡量的提升。这些结果强调了预测建模与决策制定之间更紧密集成的潜在价值。"}
{"llm_update_time": "20250815", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2505.02640", "html_url": "https://arxiv.org/abs/2505.02640", "title": "动态资源约束环境下适应性预算化多臂bandit算法在物联网中的应用", "title_en": "Adaptive Budgeted Multi-Armed Bandits for IoT with Dynamic Resource Constraints", "authors": "Shubham Vaishnav,Praveen Kumar Donta,Sindri Magnússon", "background": "物联网系统在需要实时响应和管理波动资源约束（如能量和带宽）的环境中运行。当前方法在处理随时间变化的操作限制时往往表现不佳。", "innovation": "提出了一种针对具有动态操作限制的物联网应用的新型预算化多臂bandit框架，该框架引入了衰减的违规预算，允许学习初期的有限约束违规，并随着时间的推移逐渐加强合规要求。提出了预算上限置信界（UCB）算法，该算法能够适应性地平衡性能优化和随时间变化的约束下的合规性。", "conclusion": "通过无线通信场景中的广泛仿真，表明该方法在适应性和约束满足方面比标准的在线学习方法更快、更好。这些结果突显了该框架在构建资源意识强且自适应的物联网系统方面的潜力。"}
{"llm_update_time": "20250815", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2504.14188", "html_url": "https://arxiv.org/abs/2504.14188", "title": "重思以客户端为中心的联邦图学习", "title_en": "Rethinking Client-oriented Federated Graph Learning", "authors": "Zekai Chen,Xunkai Li,Yinlin Zhu,Rong-Hua Li,Guoren Wang", "background": "Federated Graph Learning (FGL)是新的分布式图学习范式，它支持跨本地系统协作模型训练的同时保持数据隐私。现有的FGL方法根据优化机制被分类为两种主要形式：一种是服务器-客户端模式，在这种模式中，客户端上传本地模型参数供服务器端聚合和全局更新；另一种是客户端-客户端模式，允许直接在客户端之间交换信息，并自定义局部训练过程。这种新的库模式展现出更高的潜力，但由于其精细的通信结构，现有的客户端-客户端方法会广播冗余的节点表示，导致高通信成本和节点级别的隐私风险。", "innovation": "本文提出了一种名为FedC4的新方法，它结合了图凝缩技术和客户端-客户端协作优化。具体来说，FedC4使用图凝缩技术将每个客户端图的知识精简成少数合成嵌入，而不是传输节点级知识。此外，FedC4引入了三个新型模块，使源客户端能够根据不同目标客户端的图属性发送特制的节点表示。实验表明，FedC4在多种公开的真实世界数据集上的任务性能和通信成本上都优于最新的基准方法。", "conclusion": "实验结果显示，FedC4在性能和通信成本方面优于最新基准方法。我们的代码现在可以在以下链接中找到：[此处URL]。"}
{"llm_update_time": "20250815", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2505.05857", "html_url": "https://arxiv.org/abs/2505.05857", "title": "通过混合整数优化实现负责任的机器学习", "title_en": "Responsible Machine Learning via Mixed-Integer Optimization", "authors": "Nathan Justin,Qingshi Sun,Andrés Gómez,Phebe Vayanos", "background": "在过去的几十年中，机器学习（ML）已经在从医疗保健、可持续性、社会科学到刑事司法和金融等多个领域取得了显著的成就。然而，在日益复杂、关键和敏感的领域中应用ML，这些领域直接影响个人、他们所属的群体以及整个社会，引发了一些关键的公平性、透明度和稳健性等问题。随着ML系统的复杂性、规模及其应用环境的增长，对负责任的机器学习方法的需求也在增加，这些方法能够在确保部署性能的同时应对上述挑战。", "innovation": "混合整数优化（MIO）提供了一种强大的框架，可以直接将负责任的机器学习考虑融入学习过程，同时保持性能。例如，这允许学习透明度较高的模型，并方便地整合公平性或其他特定领域的约束。该教程论文提供了一个全面的介绍，讨论了负责任机器学习的核心原则、它们在应用中的重要性以及MIO在构建符合这些原则的ML模型方面的实用价值。通过示例和数学公式的说明，论文阐述了实现负责任的机器学习的有效策略和可用工具。", "conclusion": "最后，论文讨论了当前的局限性和开放的研究问题，提供了未来工作的建议，强调需要进一步研究如何更有效地利用混合整数优化来实现负责任的机器学习。"}
{"llm_update_time": "20250815", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2505.07503", "html_url": "https://arxiv.org/abs/2505.07503", "title": "通过变分贝叶斯压缩识别因果方向", "title_en": "Identifying Causal Direction via Variational Bayesian Compression", "authors": "Quang-Duy Tran,Bao Duong,Phuoc Nguyen,Thin Nguyen", "background": "从纯观测数据中区分两个随机变量之间的因果关系是一个具有广泛应用的挑战性问题。现有的方法通过使用简单的函数或高斯过程（GPs）来近似编码长度，这在模型拟合度和计算复杂性之间做出权衡，但无法同时保证编码长度的简洁性和高效率。因此，研究如何更准确、高效地进行因果识别成为一个迫切需要解决的问题。", "innovation": "本文提出了一种新的方法，利用变分贝叶斯学习神经网络来解释编码长度，提高了模型拟合度，同时保持了编码长度的简洁性，避免了基于GPs方法的高计算复杂性。", "conclusion": "在合成和实际数据集上的广泛实验表明，该方法在因果识别的多个数据集上表现出色，显著提升了性能，优于大多数相关方法。"}
{"llm_update_time": "20250815", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2504.05059", "html_url": "https://arxiv.org/abs/2504.05059", "title": "MIAT: 意图感知变换器在时空轨迹预测中的应用", "title_en": "MIAT: Maneuver-Intention-Aware Transformer for Spatio-Temporal Trajectory Prediction", "authors": "Chandra Raskoti,Iftekharul Islam,Xuan Wang,Weizi Li", "background": "准确的车辆轨迹预测对于自动驾驶的安全和效率至关重要，特别是在混合交通环境中，即有人驾驶车辆和自动驾驶车辆共存时。然而，由固有驾驶行为（如加速、减速和左右转弯）引入的不确定性给可靠轨迹预测带来了重大挑战。", "innovation": "提出了一个称之为Maneuver-Intention-Aware Transformer (MIAT)的架构，该架构结合了机动意图意识控制机制和时空交互建模，以提高长视距轨迹预测的准确性。MIAT系统性地研究了机动意图意识程度对短期和长期轨迹预测的影响。与其他意图感知基准方法相比，该方法在短期轨迹预测中提高了4.7%，长期轨迹预测中提高了1.6%。通过利用意图意识控制机制，MIAT在长期轨迹预测中实现了11.1%的性能提升，短期轨迹预测的性能略有下降。所有源代码和数据集可在该网址下载：this https URL", "conclusion": "MIAT方法在时空轨迹预测中表现优异，特别是在长时间预测中，通过引入意图意识控制机制显著提高了预测精度，但短期内可能会有轻微性能下降。"}
{"llm_update_time": "20250815", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2505.13109", "html_url": "https://arxiv.org/abs/2505.13109", "title": "FreeKV：提高KV缓存检索以实现高效的大语言模型推理", "title_en": "FreeKV: Boosting KV Cache Retrieval for Efficient LLM Inference", "authors": "Guangda Liu,Chengwei Li,Zhenyu Ning,Minyi Guo,Jieru Zhao", "background": "大语言模型（LLMs）因为越来越长的上下文窗口而被广泛应用，但是长上下文带来了部署上的挑战，主要由于KV缓存的大小会随着上下文长度增长。虽然有KV缓存压缩的方法，但KV丢弃方法会导致显著的准确率损失，而KV检索方法则面临着效率瓶颈。因此，需要一种同时提升KV检索效率和保持准确性的方法。", "innovation": "FreeKV是一个算法-系统联合优化的框架，它通过推测检索将KV的选择和召回过程移出关键路径，并结合细粒度纠错以保证准确率。在系统层面上，FreeKV采用了跨CPU和GPU内存的混合KV布局以消除碎片化数据传输，并利用双缓冲流式检索进一步提高效率。", "conclusion": "FreeKV在各种场景和模型中实现了接近无损失的准确率，并相对于当前最先进的KV检索方法达到了高达13倍的加速效果。"}
{"llm_update_time": "20250815", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.00962", "html_url": "https://arxiv.org/abs/2506.00962", "title": "使用随机时间范围的强化学习", "title_en": "Reinforcement Learning with Random Time Horizons", "authors": "Enric Ribera Borrell,Lorenz Richter,Christof Schütte", "background": "传统的强化学习框架通常假设轨迹的运行时间和长度是固定的或无限的，且通常是确定性的。然而，许多实际应用场景的时间范围是随机的，甚至是轨迹依赖的，这种不确定性对策略梯度公式产生了影响。本文旨在扩展标准的强化学习框架，以处理随机时间范围的应用场景，解决了这一类问题的策略梯度公式，为随机和确定性的策略分别进行了严谨的推导，为这一领域的研究提供了新的视角和技术支撑。", "innovation": "首次严谨推导了随机和确定性策略下的策略梯度公式，并提供了一种基于轨迹和基于状态空间的两种视角分析方法，建立了与最优控制理论的关联。本文的研究成果能够显著提高优化收敛速度，相比传统的方法具有明显的优势。", "conclusion": "本文扩展了标准的强化学习框架，引入了随机时间范围的概念，解决了在实际应用场景中存在的问题。通过严谨推导和数值实验，表明了所提出的公式可以显著改善优化收敛，为改进现有的强化学习算法提供了新的思路。"}
{"llm_update_time": "20250815", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2505.03810", "html_url": "https://arxiv.org/abs/2505.03810", "title": "组序排列旋转：免费优化量化中的旋转变换", "title_en": "Grouped Sequency-arranged Rotation: Optimizing Rotation Transformation for Quantization for Free", "authors": "Euntae Choi,Sumin Song,Woosang Lim,Sungjoo Yoo", "background": "大型语言模型（LLMs）在部署时面临高计算成本的挑战，而后训练量化（PTQ）可以提供一种解决方案，但现有的基于旋转的方法在非常低的位宽，如2位，上表现不佳。现有的旋转量化方法在极低位宽下有效性不足，主要原因在于在量化过程中引入了较大的量化误差。为解决这些问题，本文提出了一种无需训练的新颖方法，通过利用沃尔什-海明变换结合序数排序，提出了一种新的旋转矩阵构造方式，基于块对角矩阵使用较小的沃尔什矩阵块进行分组排列旋转（GSR），这种方法不仅能够有效隔离异常影响，而且在不需要任何训练的情况下能达到优化基方法的性能。实验结果表明，该方法在推理解题任务和维基文本2号数据集上的困惑度（PPL）得分表现优良，即使在基于已学习旋转技术之上仍可提升效果。", "innovation": "该研究提出了一种无需训练的方法，利用沃尔什-海明变换结合序数排序建立旋转矩阵，通过分组排列旋转（GSR）使用块对角矩阵中的较小沃尔什矩阵块，有效隔离异常影响，显著提高性能，与基于优化的方法相当，且不需要进行任何训练。", "conclusion": "本方法在推理解题任务及维基文本2号数据集上的困惑度（PPL）得分表现出色，即使应用于现有已学习旋转技术上也能增强效果。"}
{"llm_update_time": "20250815", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.13061", "html_url": "https://arxiv.org/abs/2506.13061", "title": "扩散概率模型中的高性能ODE求解器快速收敛", "title_en": "Fast Convergence for High-Order ODE Solvers in Diffusion Probabilistic Models", "authors": "Daniel Zhengyu Huang,Jiaoyang Huang,Zhengjiang Lin", "background": "扩散概率模型通过学习逆转噪声注入过程来生成样本，该过程将数据转化为噪声。关键进展是将逆采样过程重新定义为确定性的概率流常微分方程（ODE），使得可以使用高阶数值求解器高效采样。与传统的时时间积分析不同，采样程序的准确性不仅依赖于数值积分误差，还依赖于所学分数函数的近似质量和正则性以及它们的相互作用。", "innovation": "本文提出了对从概率流常微分方程导出的高阶确定性采样器进行严格收敛分析的方法。在实际假设所学导函数的第一和第二导数受到限制的情况下，发展并分析了$p$-阶（指数性）龙格-库塔方案。证明了生成分布与目标分布之间的总变差距离可以界于以下形式：$O\bigl(d^{\frac{7}{4}}\text{score}_\text{error}^{\frac{1}{2}} +d(dH_{\text{max}})^p\bigr)$。其中，$\text{score}_\text{error}^2$表示分数函数近似中的$L^2$误差，$d$是数据维度，$H_{\text{max}}$表示最大求解器步长。理论结果进一步通过基准数据集的数值实验得到了验证。", "conclusion": "基于概率流常微分方程导出的高阶确定性采样器的收敛性被严格分析，证明了在数据维度、分数函数近似误差和求解器步长的背景下生成分布与目标分布之间的总变差距离可以被有效地控制。"}
{"llm_update_time": "20250815", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.11170", "html_url": "https://arxiv.org/abs/2506.11170", "title": "基于提示的交互式多粒度时间序列分割方法：PromptTSS", "title_en": "PromptTSS: A Prompting-Based Approach for Interactive Multi-Granularity Time Series Segmentation", "authors": "Ching Chang,Ming-Chih Lo,Wen-Chih Peng,Tien-Fu Chen", "background": "多变量时间序列数据在制造和可穿戴技术等领域收集，展示出从粗粒度系统行为到细粒度详细事件的不同层次的状态。对这些不同粒度级别进行有效分割和整合对于预测维护和性能优化等任务至关重要。然而，现有时间序列分割方法面临两个关键挑战：（1）无法在一个统一模型中处理多个粒度层级；（2）在动态环境中对新出现的模式适应性有限。", "innovation": "为了解决上述挑战，本文提出了一种名为PromptTSS的新框架，用于具有多粒度状态的时间序列分割。PromptTSS采用了一种统一模型，并利用提间机制，结合标签和边界信息指导分割，既能捕捉粗粒度和细粒度模式，又能动态适应未见过的模式。实验结果显示，与多粒度分割相比，PromptTSS提高了24.49%的准确率；与单粒度分割相比，提高了17.88%；在迁移学习中，准确率提高了599.24%，显示其在分层状态和不断演化的时间序列动态中的适应性。", "conclusion": "PromptTSS在多粒度分割、单粒度分割和迁移学习方面均显示出优越性能，证明了它在不同粒度级别状态以及不断变化的时间序列动态中的适应性。"}
{"llm_update_time": "20250815", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.03682", "html_url": "https://arxiv.org/abs/2508.03682", "title": "自我提问语言模型", "title_en": "Self-Questioning Language Models", "authors": "Lili Chen,Mihir Prabhudesai,Katerina Fragkiadaki,Hao Liu,Deepak Pathak", "background": "现有研究表明，大型语言模型在没有外部数据的情况下，是否可以通过自我问答的方式提升其推理能力。本文探讨了这种可能性，并提出了一种新的体系结构来实现这一目标。", "innovation": "本文提出了一种名为SQLM（Self-Questioning Language Models）的不对称自我博弈框架。在这个框架中，通过者（proposer）负责提出问题，挑战者（solver）尝试回答。两者均通过强化学习进行训练，通过奖励机制提升模型的表征能力和推理能力。此外，通过者还可以生成单元测试用于代码验证，进一步丰富了模型的能力。该框架在三个基准测试上进行了实验，结果显示模型能够在不受任何经过挑选的训练数据集限制的情况下，提高其在下游基准测试中的表现。", "conclusion": "通过不断生成更多有趣的问题并尝试解决它们，语言模型可以在不需要访问任何精心挑选的训练数据集的情况下提高其在下游基准测试中的表现，证明了通过自我问答提升模型能力的有效性。"}
{"llm_update_time": "20250815", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.15727", "html_url": "https://arxiv.org/abs/2507.15727", "title": "多智能体滑雪租赁问题的竞争算法", "title_en": "Competitive Algorithms for Multi-Agent Ski-Rental Problems", "authors": "Xuchuang Wang,Bo Sun,Hedyeh Beyhaghi,John C.S. Lui,Mohammad Hajiesmaili,Adam Wierman", "background": "该论文探讨了一个新的多智能体滑雪租赁问题，将经典的滑雪租赁困境扩展到了一个团队环境中，其中智能体面临个体和共享的成本。", "innovation": "论文引入了一个全新的多智能体滑雪租赁问题，提出了三种不同的竞争比率：整体、状态依赖和个体理性。通过设计和分析确定性和随机性策略，论文展示了对称策略优于非对称策略，并提供了竞争比率的上界和下界。", "conclusion": "论文的研究结果扩展了传统滑雪租赁的理论和实践含义，为不确定环境下团队决策提供了理论和实际的指导意义。"}
{"llm_update_time": "20250815", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.11049", "html_url": "https://arxiv.org/abs/2506.11049", "title": "15,500秒：利用高效网络和轻量级微调的无人机分类", "title_en": "15,500 Seconds: Lean UAV Classification Using EfficientNet and Lightweight Fine-Tuning", "authors": "Andrew P. Berg,Qian Zhang,Mia Y. Wang", "background": "随着无人驾驶飞行器（UAVs）在消费和军事应用中的日益普及，专门的数据分类系统变得尤为重要。然而，由于无人机音数据量稀缺，相应的分类研究面临挑战。本文通过结合预训练深度学习模型、参数高效微调（PEFT）策略和针对性的数据增强技术，解决了这一数据不足的问题，提升了分类系统的可靠性和效率。研究通过对31种不同类型的无人机音频片段进行评估，证明了轻量级架构结合PEFT和精心选择的数据增强方法的有效性，从而在有限数据集上改进了无人机音频的分类性能。", "innovation": "本文创新性地运用了参数高效微调（PEFT）策略，结合预训练模型和数据增强技术，尤其在利用EfficientNet-B0模型和轻量级架构的全微调策略上取得了突破性成果，达到了95.95%的验证准确率，超越了现有的常用模型和架构，为未来无人机多模态分类的研究提供了新的思路和方法。", "conclusion": "研究通过使用3,100个不同类型无人机的音频片段（共计15,500秒），评估了基于变换器的和卷积神经网络（CNN）架构在不同微调配置下的性能。结果表明，采用三种数据增强策略对EfficientNet-B0模型的全微调策略，显示出最佳的验证准确性。这一研究表明，在有限数据集上进行无人机音频分类时，结合轻量级架构、PEFT策略和精心挑选的数据增强方法是一种有效策略。未来的工作将拓展到利用视觉和雷达遥测技术的多模态无人机分类。"}
{"llm_update_time": "20250815", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.15397", "html_url": "https://arxiv.org/abs/2507.15397", "title": "使用去噪器进行MAP估计：收敛率和保证", "title_en": "MAP Estimation with Denoisers: Convergence Rates and Guarantees", "authors": "Scott Pesme,Giacomo Meanti,Michael Arbel,Julien Mairal", "background": "去噪模型已成为解决逆问题的强大工具，通过预训练网络近似平滑先验分布的得分。这些模型常用于解决最大后验（MAP）优化问题的启发式迭代方案中，其中负先验的邻近操作符起着核心作用。实际上，该操作符难以计算，实践中使用预训练去噪器作为代替，尽管缺乏一般理论依据来证明这种替换的有效性。本文研究在这种先验以对数凹度假设下，一个简单算法可证明地收敛到邻近操作符，并将该算法解释为对平滑邻近目标函数的梯度下降，从而为一类以前作为启发式方法的实验成功算法奠定了理论基础。", "innovation": "本文表明在对数凹度假设下，一个简单的算法可以证明地收敛到邻近操作符，并将该算法解释为对平滑邻近目标函数的梯度下降，从而为一类以前作为启发式方法的实验成功算法提供了理论基础，弥补了理论依据的缺失。", "conclusion": "本文的研究为利用预训练去噪器解决MAP优化问题提供了理论保障，证明了在特定假设下，可以通过梯度下降方法有效地逼近邻近操作符，丰富了去噪器在图像恢复等领域的理论应用。"}
{"llm_update_time": "20250815", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.10904", "html_url": "https://arxiv.org/abs/2507.10904", "title": "难度可分数据的类比例核心样本选择", "title_en": "Class-Proportional Coreset Selection for Difficulty-Separable Data", "authors": "Elisa Tsai,Haizhong Zheng,Atul Prakash", "background": "高质量的训练数据对于构建可靠的和高效的机器学习系统至关重要。现有的一次性核样本（coreset）选择方法通过修剪数据集同时保持甚至提高模型性能，通常依赖于基于训练动态的数据难度评分。然而，大多数现有方法假设数据难度在不同类别之间一致性较高，而忽视了不同类别间数据难度的变化。", "innovation": "论文挑战了这一假设，提出类难度分离性（class-difficulty separability），并引入了类难度分离系数（Class Difficulty Separability Coefficient, CDSC）作为量化指标。作者提出类比例多种采样策略，这些方法在五个不同的数据集上表现出最优性能。特别是在CTU-13数据集上，即使在99%的修剪率下，类比例变体的覆盖率中心核样本选择（Coverage-centric Coreset Selection, CCS-CP）也能保持稳定的准确性，而类不感知的CCS基线方法却表现出明显的性能下降。此外，这种大量的修剪在噪声大、类别不均衡和大规模的数据集上增强了泛化能力。", "conclusion": "论文的结果表明，明确建模类难度分离性能够更有效地进行数据修剪，特别是在高风险场景中。此外，这种增强的泛化能力在噪声大、类别不均衡和大规模的数据集上更为显著。"}
{"llm_update_time": "20250815", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.06535", "html_url": "https://arxiv.org/abs/2507.06535", "title": "通过图对比学习和标签重平衡在AMS电路中实现可迁移的寄生参数估计", "title_en": "Transferable Parasitic Estimation via Graph Contrastive Learning and Label Rebalancing in AMS Circuits", "authors": "Shan Shen,Shenglu Hua,Jiajun Zou,Jiawei Liu,Jianwang Zhai,Chuan Shi,Wenjian Yu", "background": "模拟混合信号(AMS)电路图表示学习对于各种下游任务，如电容估计至关重要。然而，设计数据稀缺，标签分布不均衡，电路实现具有内在多样性，这些都对学习鲁棒性和迁移性电路表示提出了显著挑战。本文旨在解决这些限制。进一步解释了电路实例中数据稀少、标签不平衡以及电路多样性等背景问题。", "innovation": "提出了一种新的图对比学习框架CircuitGCL，该框架结合了表示散射和标签重平衡，以增强跨异构电路图的迁移性。利用自监督策略通过超球面表示散射学习不变的节点嵌入，减少对大规模数据的依赖。同时，通过引入平衡均方误差（BMSE）和平衡softmax交叉熵（BSCE）损失，缓解电路之间的标签分布差异，实现稳健且迁移性的寄生参数估计。该方法应用于TSMC 28nm AMS设计中的寄生电容估计（边缘级任务）和接地电容分类（节点级任务），并在所有最先进的方法中表现出色，寄生电容估计的$R^2$改进率为33.64%至44.20%，节点分类的F1得分提高了0.9倍至2.1倍。这是一种创新的数据效率高、鲁棒性强的方法，解决了电路表示学习中的常见挑战。创新点为CircuitGCL框架和采用自监督策略、BMSE和BSCE损失的实现机制，强调了其迁移性和有效性。", "conclusion": "本文通过提出CircuitGCL框架，结合表示散射和标签重平衡，针对AMS电路中的寄生参数估计任务实现了显著的提升。实验结果显示，CircuitGCL在寄生电容估计和节点分类任务上均优于现有的最优方法，展示了其在AMS电路图表示学习中的强大潜力。"}
{"llm_update_time": "20250815", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.05724", "html_url": "https://arxiv.org/abs/2508.05724", "title": "基于图的框架在物理学中探索数学模式：一个概念验证", "title_en": "A Graph-Based Framework for Exploring Mathematical Patterns in Physics: A Proof of Concept", "authors": "Massimiliano Romiti", "background": "物理方程庞大的语料库形成了一个隐含的数学关系网络，传统的分析方法难以完全探索这些关系。本文提出了一种结合神经网络和符号分析的图基框架，旨在系统地发现和验证跨越物理领域的数学模式。", "innovation": "该框架通过使用图注意力网络在链接预测任务中达到97.4%的AUC，显著优于经典基准。其主要创新点在于该框架兼具假设生成和知识审计的功能。它能够生成大量候选的跨域连接，同时也能够通过符号分析验证现有的理论一致性，抽象出磁雷诺数，并揭示语法错误可能指向的研究机会如模拟重力。", "conclusion": "该系统将难以应对的组合空间转化为供人类解释的数学模式流。即使并发和错误也具有科学意义，如识别冗余和评估知识库的质量。"}
{"llm_update_time": "20250815", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.07697", "html_url": "https://arxiv.org/abs/2508.07697", "title": "通过大型语言模型增强的语义时间序列预测", "title_en": "Semantic-Enhanced Time-Series Forecasting via Large Language Models", "authors": "Hao Liu,Chun Yang,Zhang xiaoxing,Xiaobin Zhu", "background": "时间序列预测在金融、能源、气象和物联网应用中扮演着重要角色。近年来，研究利用大型语言模型（LLMs）的泛化能力进行时间序列预测，取得了不错的成果。然而，现有研究主要集中在 tokens 的模式对齐上，而未充分弥补语言知识结构与时间序列数据模式之间的内在差异，限制了语义表示的能力。", "innovation": "本文提出了一种新型的语义增强大型语言模型 (SE-LLM)，它利用时间序列固有的周期性和异常特征嵌入到语义空间中，以增强 token 的嵌入。此外，现有基于 Transformer 的 LLM 在捕捉长依赖性方面表现出色，但在建模时间序列数据中的短异常上较弱。因此，我们提出了一种插件模块，可以建模长期和短期依赖性，以有效地适应时间序列分析。此外，该方法冻结了 LLM 并减少了 token 序列维度以大幅降低计算消耗。实验证明了 SE-LLM 的优越性能，超越了现有的尖端方法（SOTA）。", "conclusion": "实验结果显示，SE-LLM 在时间序列预测中具有优异的性能，超越了现有的最先进的方法。"}
{"llm_update_time": "20250815", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.06800", "html_url": "https://arxiv.org/abs/2508.06800", "title": "Hardness-Aware Dynamic Curriculum Learning for Robust Multimodal Emotion Recognition with Missing Modalities", "title_en": "Hardness-Aware Dynamic Curriculum Learning for Robust Multimodal Emotion Recognition with Missing Modalities", "authors": "Rui Liu,Haolin Zuo,Zheng Lian,Hongyu Yuan,Qi Fan", "background": "近年来，缺失模态问题在多模态情绪识别（MER）领域成为了一个关键研究方向。传统的解决方法大多通过缺失模态重建来处理这一问题，但这些方法未能考虑不同样本在重建难度上的差异，从而限制了模型在处理具有挑战性的样本时的能力。", "innovation": "本文提出了一种新的Hardness-Aware Dynamic Curriculum Learning框架，称为HARDY-MER。该框架通过两个关键阶段来工作：首先，通过考虑直接难易度（模态重构误差）和间接难易度（跨模态互信息）来估计每个样本的难易程度；其次，通过检索具有类似语义信息的样本，并动态调整训练课程，平衡学习焦点在简单与困难样本之间，来战略地强调困难样本以提高模型在这些具有挑战性的实例中的表现。", "conclusion": "对基准数据集的广泛实验表明，HARDY-MER在处理缺失模态问题时较现有方法表现出持续的优越性能。我们的代码将在此网址（this https URL）公开提供。"}
{"llm_update_time": "20250815", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.05977", "html_url": "https://arxiv.org/abs/2508.05977", "title": "LinguaFluid: 通过语义奖励进行语言引导的流体控制的强化学习", "title_en": "LinguaFluid: Language Guided Fluid Control via Semantic Rewards in Reinforcement Learning", "authors": "Aoming Liang,Chi Cheng,Dashuai Chen,Boai Sun,Dixia Fan", "background": "在科学机器学习领域，强化学习（RL）中的有效奖励函数设计仍然是一个挑战，特别是在任务目标难以数值化描述的环境中。现有的RL中的奖励函数大多基于启发式方法、手动工程或特定任务的调整。该文中提出了一种语义对齐的强化学习方法，通过使用Sentence-Bidirectional Encoder Representations from Transformers（SBERT）计算奖励，将当前状态与目标语义指令进行对齐。该方法通过计算目标文本描述与各环节中状态描述之间的余弦相似性来为策略提供反馈，而不是依赖于手动定义的奖励函数。研究者们在多个环境中评估了该方法，结果显示即使没有人工设计的奖励函数，语义奖励也能指导学习实现具有竞争力的控制行为。研究还展示了语言嵌入空间与传统欧几里得空间之间的关联。这为将语言模型与流体控制等持续控制应用更紧密地结合提供了新视角，奠定了基础。", "innovation": "提出了一种语义对齐的强化学习方法，通过计算目标语义指令与当前状态之间的相似性来生成奖励，替代了传统的基于人工定义的奖励函数的方法，从而能够更有效地学习复杂的控制任务，尤其是在任务目标难以数值化的情况下。这项工作还揭示了语言嵌入空间与传统几何空间之间的相似性，为未来通过语言模型进行复杂控制应用的设计提供了新的思路和方法。", "conclusion": "研究通过智能语言嵌入奖励框架展示了如何通过自然语言目标实现流体控制的强化学习。这种方法不仅提高了学习控制策略的效果，而且还为实现更为复杂和自然的交互提供了新的可能。未来的研究可以进一步探索将更大规模的语言模型和持续控制应用结合在一起的新方法。"}
{"llm_update_time": "20250815", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.05612", "html_url": "https://arxiv.org/abs/2508.05612", "title": "Shuffle-R1: 数据导向的动态洗牌在提高多模态大型语言模型的强化学习训练效率方面的框架", "title_en": "Shuffle-R1: Efficient RL framework for Multimodal Large Language Models via Data-centric Dynamic Shuffle", "authors": "Linghao Zhu,Yiran Guan,Dingkang Liang,Jianzhong Ju,Zhenbo Luo,Bin Qin,Jian Luan,Yuliang Liu,Xiang Bai", "background": "强化学习（RL）作为一种增强多模态大型语言模型（MLLM）推理能力的后训练方法已经取得了一定的效果。然而，现有的RL管道常常因为优势塌陷和采样沉默这两个未被充分探索的问题而效率低下。优势塌陷是指在一个批次中，大多数优势集中在接近零的位置；而采样沉默则指的是随着时间的推移，贡献非零梯度的卷积比例逐渐减少，导致梯度更新不完整，妨碍长期学习效率。这些问题使得MLLM的RL优化变得非常艰难，限制了模型的最终表现和长期稳定性。", "innovation": "我们提出了Shuffle-R1，这是一种通过动态重构轨迹采样和批次组成的简单但严谨的框架，来提升RL细调效率。Shuffle-R1引入了两个策略：(1) 对比轨迹采样，选择具有大优势的高对比度轨迹以提高梯度信号质量；(2) 基于优势的轨迹洗牌，通过有信息的批次重塑增加有价值的卷积的暴露度。实验结果表明，Shuffle-R1能够显著超越强大且高效的RL基线方法，且几乎不增加额外开销。这表明Shuffle-R1在基于数据的RL训练中具有重要意义，且能够促进更有效的训练过程。", "conclusion": "实验结果进一步验证了Shuffle-R1的有效性，展示了基于数据的动态洗牌策略对于提高多模态大语言模型的RL训练效率的重要性。Shuffle-R1忽视了传统的关注点，通过简单的调整和有效的技术改进，显著提升了模型的训练效率和最终性能。"}
{"llm_update_time": "20250815", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.07970", "html_url": "https://arxiv.org/abs/2508.07970", "title": "WeChat-YATT: 一个简单、可扩展且平衡的RLHF训练框架", "title_en": "WeChat-YATT: A Simple, Scalable and Balanced RLHF Trainer", "authors": "Junyu Wu,Weiming Chang,Xiaotao Liu,Guanyou He,Tingfeng Xian,Haoqiang Hong,Boqi Chen,Haotao Tian,Tao Yang,Yunsheng Shi,Feng Lin,Ting Yao", "background": "尽管现有的RLHF训练框架在训练大型语言模型和多模态系统方面取得了显著进展，但在将这些方法扩展到复杂的多模态工作流和适应动态工作负载时仍面临重大挑战。当前的系统往往在管理大型模型的控制器可扩展性方面遇到限制，同时在协调复杂的RLHF管道时也存在效率低下等问题，特别是在需要动态采样和资源分配的场景中。", "innovation": "本文引入了WeChat-YATT（WeChat中的Yet Another Transformer Trainer），这是一种简单、可扩展且平衡的RLHF训练框架，专门解决上述挑战。WeChat-YATT采用并行控制器编程模型，能够灵活且高效地协调复杂的RLHF工作流，有效缓解集中式控制器架构所面临的瓶颈问题，并在大规模数据场景中促进可扩展性。此外，WeChat-YATT还提出了一种动态资源放置方案，能够适配性地划分计算资源并调度工作负载，从而在变化的训练条件下显著减少硬件闲置时间和提高GPU利用率。", "conclusion": "WeChat-YATT在一系列实验场景中得到了评估，展示了其与最先进的RLHF训练框架相比在吞吐量方面取得了显著改善。WeChat-YATT已成功应用于训练支持WeChat产品功能的大规模用户群模型，证明了其在实际应用场景中的有效性和鲁棒性。WeChat-YATT的源代码已公开。"}
{"llm_update_time": "20250815", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.05571", "html_url": "https://arxiv.org/abs/2508.05571", "title": "iFairy: 全参数在±1, ±i 的首个2比特复数LLM", "title_en": "iFairy: the First 2-bit Complex LLM with All Parameters in $\\{\\pm1, \\pm i\\}$", "authors": "Feiyu Wang,Guoan Wang,Yihao Zhang,Shengfan Wang,Weitao Li,Bokai Huang,Shimao Chen,Zihan Jiang,Rui Xu,Tong Yang", "background": "量化感知训练（QAT）将量化过程集成到训练循环中，使大语言模型（LLMs）能够学习稳健的低比特表示。目前所有的QAT研究都旨在最小化全精度模型的量化误差，全精度模型的精度被视为理论上限。现有方法尚未尝试超越这一上限。因此，本文提出了一种新的范式：提高模型的精度极限，然后高效地将其量化为2比特。研究提出了一种名为Fairy$\boldsymbol{\text{±}}$i的新架构，这是第一个针对复数LLM的2比特量化框架。通过这种方法，研究人员将权重映射到虚单位的四次根集$\text{\text{\text{±}}1, \text{\text{\text{±}}i}$，形成一个完全对称且信息论上最优的2比特表示。这种方法使得量化后的权重可以使用仅加法和元素交换来进行无乘法的推理。实验结果表明，Fairy$\boldsymbol{\text{±}}$i在潜在语法损失（PPL）和下游任务中均超越了现有2比特量化方法的上限，同时保持了严格的存储和计算效率。这项工作为在极其低比特约束下高效构建高精度的LLMs打开了新的方向。", "innovation": "本文提出了一个名为Fairy$\boldsymbol{\text{±}}$i的新架构，这是第一个针对复数LLM的2比特量化框架。该架构通过将权重映射到虚单位的四次根集$\text{\text{\text{±}}1, \text{\text{\text{±}}i}$，形成一个完全对称且信息论上最优的2比特表示，从而提升了全精度模型的精度极限。这种方法使得量化后的权重可以使用仅加法和元素交换来进行无乘法的推理。实验结果表明，Fairy$\boldsymbol{\text{±}}$i在潜在语法损失（PPL）和下游任务中均超越了现有2比特量化方法的上限，同时保持了严格的存储和计算效率。", "conclusion": "这项工作为在极其低比特约束下高效构建高精度的LLMs打开了新的方向。Fairy$\boldsymbol{\text{±}}$i架构展示了其在实际场景中的应用潜力，为未来的LLM研究和开发提供了新的思路。"}
{"llm_update_time": "20250815", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.09299", "html_url": "https://arxiv.org/abs/2508.09299", "title": "通过分布式机器学习和基于区块链的模型验证实现去中心化天气预报", "title_en": "Decentralized Weather Forecasting via Distributed Machine Learning and Blockchain-Based Model Validation", "authors": "Rilwan Umar,Aydin Abadi,Basil Aldali,Benito Vincent,Elliot A. J. Hurley,Hotoon Aljazaeri,Jamie Hedley-Cook,Jamie-Lee Bell,Lambert Uwuigbusun,Mujeeb Ahmed,Shishir Nagaraja,Suleiman Sabo,Weaam Alrbeiqi", "background": "天气预报在灾害预防、农业和资源管理等重要领域发挥着关键作用，然而，当前集中的预报系统由于安全性漏洞、扩展性有限以及单点故障等问题而受到越来越多的挑战。", "innovation": "提出了一种结合联邦学习（FL）与区块链技术的去中心化天气预报框架。该方法通过FI实现无需暴露敏感的本地数据的合作模型训练，提升了隐私保护并减少了数据传输的开销；通过以太坊区块链确保模型更新的透明和可靠验证；同时引入基于声誉的投票机制评估提交模型的可信度，并利用星际文件系统（IPFS）进行高效的离链存储，进一步增强了系统的安全性。", "conclusion": "实验结果表明，该方法不仅提升了预报的准确性，还增强了系统的韧性和扩展性，使其成为在现实世界中具有重要安全意义的环境中部署的可行候选方案。"}
{"llm_update_time": "20250815", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.08543", "html_url": "https://arxiv.org/abs/2508.08543", "title": "M3-Net：一种高效的无图MLP基模型用于交通预测", "title_en": "M3-Net: A Cost-Effective Graph-Free MLP-Based Model for Traffic Prediction", "authors": "Guangyin Jin,Sicong Lai,Xiaoshuai Hao,Mingtao Zhang,Jinlei Zhang", "background": "准确的交通预测是当前智能交通系统发展中的一项基本但至关重要的任务。目前主流的在交通预测方面取得突破的方法依赖于时空图形神经网络和时空注意力机制等。现有深度学习方法的主要挑战在于它们要么依赖完整的交通网络结构，要么需要复杂的设计来捕捉时空依赖性。这些限制使得在大规模数据集上高效部署和运行深度学习模型变得具有挑战性。", "innovation": "我们提出了一种成本效益高且无图的MLP基模型M3-Net，它不仅采用了时间序列和时空嵌入进行高效的特征处理，还首次引入了一种新颖的MLP-Mixer架构，并结合了混合专家机制（MoE）。通过在多个真实数据集上的广泛实验，证明了所提出模型在预测性能和简洁部署方面的优越性。", "conclusion": "实验结果表明，提出的M3-Net模型在预测性能和轻量级部署方面优于现有的方法，为大规模交通预测提供了更有效的解决方案。"}
{"llm_update_time": "20250815", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.09146", "html_url": "https://arxiv.org/abs/2508.09146", "title": "理论上理解基于Transformer的上下文学习方法以优化CSMA", "title_en": "To Theoretically Understand Transformer-Based In-Context Learning for Optimizing CSMA", "authors": "Shugang Hao,Hongbo Li,Lingjie Duan", "background": "二进制指数退避方案在WiFi 7中广泛应用，但在动态信道环境中仍会导致低吞吐量。基于模型的方法（例如非持久性和$p$-持久性CSMA）在已知和固定的节点密度下优化退避策略，但由于对节点密度估计不准确，吞吐量仍会损失较大。该论文首次提出基于LLM transformer的上下文学习（ILC）理论，用于优化信道访问。", "innovation": "设计了一个基于Transformer的ILC优化器，通过预收集碰撞阈值数据示例并构建查询碰撞案例作为输入，让Transformer学习模式，生成预测竞争窗口阈值（CWT）。为有效训练ILC，开发了高效算法，确保在有限的训练步数内实现接近最优的CWT预测。此外，适应了允许提示中有误数据输入的情况，证明了优化器从最优值的预测和吞吐量偏移最小。", "conclusion": "实验结果表明，该方法在NS-3平台上能够快速收敛并优于现有基于模型和DRL的方法，在未知节点密度下的吞吐量接近最优。"}
{"llm_update_time": "20250815", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.08746", "html_url": "https://arxiv.org/abs/2508.08746", "title": "通过稀疏自编码器实现可解释的奖励模型", "title_en": "Interpretable Reward Model via Sparse Autoencoder", "authors": "Shuyi Zhang,Wei Shi,Sihang Li,Jiayi Liao,Tao Liang,Hengxing Cai,Xiang Wang", "background": "大型语言模型（LLMs）已在众多领域得到广泛应用。强化学习从人类反馈（RLHF）通过使用奖励模型（RMs）作为人类偏好的代理，使得奖励模型的准确性和可解释性变得至关重要，因为这直接关系到LLMs行为与人类价值观的有效对齐。然而，传统的RMs缺乏可解释性，不能清晰地揭示奖励赋值背后的推理过程，并且对于用户偏好的变化缺乏灵活性。尽管最近开发的多维度RMs试图提高可解释性，但它们往往无法提供特征级别的归因，且需要昂贵的注释成本。因此，论文作者提出了一种名为Sparse Autoencoder-enhanced Reward Model (SARM)的新架构，以解决上述问题，SARM整合了一种预训练的稀疏自编码器（SAE）到奖励模型中，实现了对奖励赋值的直接特征级归因，能够动态适应偏好的变化，并且已经在实际评估中显示出比传统奖励模型更优秀的对齐性能。", "innovation": "提出了一种新的奖励模型架构，即Sparse Autoencoder-enhanced Reward Model (SARM)，该架构将预训练的稀疏自编码器（SAE）集成到奖励模型中，使其能够直接归因于特征级别，允许动态调整以适应偏好变化，并展示了比传统奖励模型更好的对齐性能。", "conclusion": "SARM在实际评估中展示了直接且概念上明晰的特征级归因能力，能够动态调整以适应偏好变化，并取得了优于传统奖励模型的对齐性能，本研究结果表明该方法的有效性。"}
{"llm_update_time": "20250815", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.09158", "html_url": "https://arxiv.org/abs/2508.09158", "title": "EvaDrive：演化对抗策略优化在端到端自主驾驶中的应用", "title_en": "EvaDrive: Evolutionary Adversarial Policy Optimization for End-to-End Autonomous Driving", "authors": "Siwen Jiao,Kangan Qian,Hao Ye,Yang Zhong,Ziang Luo,Sicong Jiang,Zilin Huang,Yangyi Fang,Jinyu Miao,Zheng Fu,Yunlong Wang,Kun Jiang,Diange Yang,Rui Fan,Baoyun Peng", "background": "自主驾驶在实现人类级别的迭代决策方面面临重大挑战，这种决策不断生成、评估和改进轨迹建议。当前的生成-评估框架将轨迹生成与质量评估隔离，阻碍了规划中的迭代细化。同时，强化学习方法将多维度的偏好压缩为标量奖励，这模糊了重要的权衡，导致单维度化问题。因此，需要一种方法来解决这些问题，并实现有效的迭代多轮细化，以跳出局部最优点。", "innovation": "本研究提出了一种名为EvaDrive的新型多目标强化学习框架，通过对抗优化建立了轨迹生成与评估之间的真正闭环共进化。EvaDrive将轨迹规划视为多轮对抗游戏。在游戏过程中，层次生成器不断提出候选路径，通过自回归意图建模进行时间因果性建模，并通过基于扩散的细化来增强空间灵活性。这些提议由一个受训练的多目标评论家严格评估，该评论家显式地保留了多种偏好结构，而非将其简化为单一标量化。对抗相互作用，由帕累托前沿选择机制引导，使得实现多轮迭代细化，有效地跳出局部最优点并保持轨迹。", "conclusion": "EvaDrive在NAVSIM和Bench2Drive基准测试中表现出卓越性能。在NAVSIM v1中实现了94.9 PDMS（超过DiffusionDrive 6.8，超过DriveSuprim 5.0，超过TrajHF 0.9），Bench2Drive中实现64.96的驾驶评分。EvaDrive通过动态权重生成多样化的驾驶风格，无需外部偏好数据，引入了一个闭环对抗框架，用于实现类似人类的迭代决策，并提供了一种无标量化的新轨迹优化方法。"}
{"llm_update_time": "20250815", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2310.19583", "html_url": "https://arxiv.org/abs/2310.19583", "title": "GC-MVSNet: 多视图、多尺度、几何一致的多视图立体成像", "title_en": "GC-MVSNet: Multi-View, Multi-Scale, Geometrically-Consistent Multi-View Stereo", "authors": "Vibhas K. Vats,Sripad Joshi,David J. Crandall,Md. Alimoor Reza,Soon-heung Jung", "background": "传统的多视图立体成像（MVS）方法高度依赖于光度和几何一致性的约束条件，而基于机器学习的新型MVS方法则在训练后的步骤中才检查多个源视图之间的几何一致性。现有方法未能在学习过程中明确促进参考视图深度图在多个源视图及不同尺度上的几何一致性。作者通过在学习过程中添加几何一致性损失来解决这一问题，从而加速学习过程，减少训练迭代次数。实验表明，该方法在DTU和BlendedMVS数据集上达到了新的技术水平，并在Tanks and Temples基准上取得了竞争性的结果。这是首次在学习过程中强制实施多视角和多尺度几何一致性的方法。", "innovation": "本文提出了一种新技术，即在学习过程中明确促进参考视图深度图在多个源视图及不同尺度上的几何一致性，通过这一创新，引入了一个几何一致性损失，显著加快了学习速度，减少了一半的训练迭代次数。这种方法首次在MVS中全面实现多视图、多尺度的几何一致性约束。", "conclusion": "GC-MVSNet方法在高性能MVS方面取得了突破，达到了DTU和BlendedMVS数据集的最新技术水平，并在Tanks and Temples基准上达到了竞争性的效果。"}
{"llm_update_time": "20250815", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2402.02190", "html_url": "https://arxiv.org/abs/2402.02190", "title": "连续并行松弛在组合优化问题中寻找多样化解决方案", "title_en": "Continuous Parallel Relaxation for Finding Diverse Solutions in Combinatorial Optimization Problems", "authors": "Yuma Ichikawa,Hiroaki Iwashita", "background": "组合优化（CO）通常旨在找到最优解。但在实际应用中，需求多样化的解决方案而非单一的最优解，特别是在强制执行每个约束既不必要也不理想的情况下，可以通过在目标函数中引入惩罚项来实现，这需要精细调节惩罚参数。此外，CO模型往往会简化复杂的现实因素，如领域知识、隐含权衡或伦理考量，这些挑战促使需要生成具有不同惩罚强度的多样解决方案和具有不同结构特征的多样解决方案，以供实践者选择最适合他们需求的解。然而，发现这些多样化的解决方案比寻找单一最优解更具有挑战性。", "innovation": "本文提出了一种称为Continual Parallel Relaxation Annealing (CPRA)的高效且计算成本低的框架，作为基于无监督学习（UL）的组合优化求解器，能够在单次训练中生成多样化解决方案。CPRA利用了表示学习和并行化技术，自动发现共享表示，极大地加速了多样解决方案的搜索过程。实验表明，CPRA在生成多样化解决方案方面优于现有的基于UL的求解器，同时显著降低了计算成本。", "conclusion": "CPRA为组合优化问题中的无监督学习求解器提供了一种新的高效方法，能够在单次训练过程中生成多样化解决方案，并通过实验验证了其在性能和计算效率方面的优越性。"}
{"llm_update_time": "20250815", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2407.08750", "html_url": "https://arxiv.org/abs/2407.08750", "title": "在线分布回归", "title_en": "Online Distributional Regression", "authors": "Simon Hirsch,Jonathan Berrisch,Florian Ziel", "background": "大规模流式数据在现代机器学习应用中很常见，促成了在线学习算法的发展。许多领域，如供应链管理、天气和气象学、能源市场和金融领域，转向使用概率预测。这不仅需要准确预测期望值，还需要学习条件异方差性和条件矩。", "innovation": "本文提出了一种在线估计正则化线性分布模型的方法。该方法结合了近期的在线估计LASSO模型的发展和广为人知的GAMLSS框架。展示了一个用于日前电价预测的案例，在该案例中，增量估计结合显著降低的计算成本显示出竞争力的性能。", "conclusion": "研究的算法被实现在一个计算高效的Python包ondil中，为在线学习提供了有效的工具。"}
{"llm_update_time": "20250815", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2405.20124", "html_url": "https://arxiv.org/abs/2405.20124", "title": "几何统一的分布鲁棒协方差估计器：通过扩大不确定性集合来压缩光谱", "title_en": "A Geometric Unification of Distributionally Robust Covariance Estimators: Shrinking the Spectrum by Inflating the Ambiguity Set", "authors": "Man-Chung Yue,Yves Rychener,Daniel Kuhn,Viet Anh Nguyen", "background": "当前最先进的高维协方差矩阵估计方法都会对样本协方差矩阵的特征值进行收缩，使其接近一个与数据无关的收缩目标。现有方法中的收缩变换或基于直觉选择，缺乏有力的理论依据；或在苛刻的分布假设下最优选择。本文在不施加这类限制性假设的前提下，提出了一种系统的协方差估计方法。具体来说，研究了即使在所有接近一个名义分布的数据分布下，也能最小化最坏情况的Frobenius误差的鲁棒协方差估计问题。", "innovation": "提出了一个系统的方法来构建协方差估计器，该方法不施加严格的假设条件。通过定义在协方差矩阵空间上的分离度量，研究了最小化最坏情况Frobenius误差的鲁棒估计问题。识别了这种分离度量的温和条件，使得获得的最小化方法代表收缩估计器。进一步证明了对应的收缩变换与基础度量的几何性质密切相关。此外，还证明了鲁棒估计器在计算上可高效实现且具有渐近一致性，并且具备有限样本性能保证。本文基于Kullback-Leibler、Fisher-Rao和Wasserstein散度，合成了具体的估计方法。", "conclusion": "通过合成由Kullback-Leibler、Fisher-Rao和Wasserstein散度生成的具体估计器，展示了提出的鲁棒估计器具有与最先进的估计器媲美的性能。数值实验结果表明其性能优越。"}
{"llm_update_time": "20250815", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2407.12830", "html_url": "https://arxiv.org/abs/2407.12830", "title": "基于知识的一致性测试方法在外大型语言模型中的应用", "title_en": "Knowledge-based Consistency Testing of Large Language Models", "authors": "Sai Sathiesh Rajan,Ezekiel Soremekun,Sudipta Chattopadhyay", "background": "本文探讨了大型语言模型（LLMs）的知识不一致性和知识空白。系统地展示了如何利用这些模型的当前知识水平并对其进行测试。研究发现，现有模型在知识理解方面存在显著差异，这些差异可能会影响到使用的准确性和有效性。", "innovation": "提出了借助知识图构建测试用例的自动化测试框架KalTest。Kontest采用了语义等价查询和测试或acles（元形态或本体或acles）来测试和衡量LLMs的知识不一致性。通过一个加权的LLM模型集成，它进一步弥补了知识空白。该框架使用了四种当今最先进语言模型（Falcon, Gemini, GPT3.5, and Llama2）进行测试，结果显示Kontest发现了一部分引起错误的输入和知识空白，同时提出了一种减少LLM知识空白的方法，该方法基于Kontest的测试集，减少了知识空白32.48%。", "conclusion": "研究结果显示，GPT3.5在知识构建方面只有60%-68%的有效性，不适用于知识基础的一致性测试。针对上述发现，研究建议设计一种有效的用于一致性测试的方法来评估不同语言模型的知识构建能力。"}
{"llm_update_time": "20250815", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2405.02754", "html_url": "https://arxiv.org/abs/2405.02754", "title": "隐式安全集合算法实现可验证安全的强化学习", "title_en": "Implicit Safe Set Algorithm for Provably Safe Reinforcement Learning", "authors": "Weiye Zhao,Feihan Li,Changliu Liu", "background": "深度强化学习（DRL）已经在许多连续控制任务中显示出出色的表现。然而，DRL在实际应用中的一个重大障碍是没有提供安全保证。虽然DRL代理可以通过奖励重塑来满足系统的期望安全要求，但设计出能在每个时间步都一致满足硬性约束（例如，安全规范）的代理仍然存在挑战。现有的安全控制领域研究提供了在满足硬性安全约束方面有保证的方法，但这些方法通常需要显式分析系统动力学模型，而这在DRL环境中通常是不可实现的。本研究介绍了一种无需了解系统动力学模型的无模态安全控制算法——隐式安全集算法，用于为DRL代理合成可以确保训练过程中绝对安全的保护措施。该算法仅通过查询黑盒动态函数（例如数字孪生模拟器）来合成安全指数（障碍证书）和随后的安全控制规则。", "innovation": "提出了一个无模态的隐式安全集算法，能够在没有明确了解系统动力学模型的情况下，为DRL代理合成保障其在整个训练过程中绝对安全的保护措施。该算法通过查询黑盒动态函数来合成安全指数和安全控制法则，并且理论上证明了该算法可以保证有限时间内收敛到安全集合以及前向不变性，对于连续时间和离散时间系统都是有效的。在最先进的Safety Gym基准测试中，该算法实现了零安全违规，并且在累积奖励上相比最先进的安全DRL方法提高了95% ± 9%，同时该算法还能很好地扩展到高维系统，具有良好的并行计算能力。", "conclusion": "研究提出了一种新的无模态安全集算法，该算法可以有效地利用和保护DRL代理的安全性，同时在复杂的高维系统中也具有良好的适用性和计算效率。这种方法能够在确保安全性的前提下，提供广阔的强化学习应用领域，特别是在需要严格安全约束的场景中具有重要前景。"}
{"llm_update_time": "20250815", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2403.03353", "html_url": "https://arxiv.org/abs/2403.03353", "title": "深度学习的假设空间", "title_en": "Hypothesis Spaces for Deep Learning", "authors": "Rui Wang,Yuesheng Xu,Mingsong Yan", "background": "本文介绍了一种基于深度神经网络（DNNs）的深度学习假设空间。通过将DNN视为两个变量（输入变量和参数变量）的函数，考虑参数变量属于由规定深度和层宽决定的权重矩阵和偏置的空间中的DNN集合。为了构造输入变量的函数Banach空间，我们将这个DNN集合的线性扩展的弱*闭包取出来。", "innovation": "本文通过将DNN视为两个变量的函数，并考虑参数变量属于由规定深度和层宽决定的权重矩阵和偏置的空间中的DNN集合，提出了一个Banach空间。进一步证明了所得到的Banach空间是一个核再生Banach空间（RKBS），并且显式构造了其核函数。在此基础上，研究了两个学习模型：正则化学习和最小范数插值（MNI）问题，并建立了代表定理。", "conclusion": "这些定理揭示了解决这些问题的解可以表示为基于训练数据的核展开的有限和。"}
{"llm_update_time": "20250815", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.19343", "html_url": "https://arxiv.org/abs/2506.19343", "title": "Discrepancy-Aware Graph Mask Auto-Encoder", "title_en": "Discrepancy-Aware Graph Mask Auto-Encoder", "authors": "Ziyu Zheng,Yaming Yang,Ziyu Guan,Wei Zhao,Weigang Lu", "background": "Masked Graph Auto-Encoder (Masked GAE) 在图表示学习中表现出优越性能。现有方法依赖节点上下文信息恢复被遮罩的信息，但在异构性图（连接节点可能不相似）上表现不佳，因为这些方法仅关注邻域信息而忽视节点间差异性信息，导致节点表示难以区分。", "innovation": "提出了一种新方法——Discrepancy-Aware Graph Mask Auto-Encoder (DGMAE)，在图掩码过程中重建邻节点的差异性信息，从而获得更可区分的节点表示，改进了图自我监督学习方法。", "conclusion": "在17个广泛使用的基准数据集上进行的大量实验表明，DGMAE 能有效保留节点之间的差异性信息，并且在节点分类、节点聚类和图分类等三种图分析任务上显著优于当前最先进的图自我监督学习方法，展示了其显著的优势。"}
{"llm_update_time": "20250815", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2407.11353", "html_url": "https://arxiv.org/abs/2407.11353", "title": "使用预条件梯度下降和早期停止训练的过度参数化神经网络在插值空间中的非参数回归精确泛化", "title_en": "Sharp Generalization for Nonparametric Regression in Interpolation Space by Over-Parameterized Neural Networks Trained with Preconditioned Gradient Descent and Early-Stopping", "authors": "Yingzhen Yang,Ping Li", "background": "本文研究了使用算法保证训练的过度参数化的双层神经网络进行非参数回归。训练特征均匀分布在$\text{R}^d$单位球上，目标函数位于统计学习理论中常见的一种插值空间中。本文展示了通过引入新型预条件梯度下降(PGD)算法并结合早期停止机制训练神经网络，在特定条件下能够达到精确的回归率$\text{O}(n^{-\frac{2\boldsymbol{\beta}'s}{2\boldsymbol{\beta}'s+1}})$。这一发现是在同样条件下常规梯度下降(GD)和神经元梯度核(NTK)所获得的更优结果。研究基于两个关键的技术贡献，首先提出了网络输出的有理核希尔伯特空间(Hilbert space)函数分解，其次利用该分解应用局部Rademacher复杂性理论以紧密控制所有神经网络函数形成的函数类的复杂性。该研究进一步表明PGD能够使得神经网络在非线性NTK阶段中逃逸并达到更好的泛化性能，因为这会引入一种新的核函数。", "innovation": "1. 引入预条件梯度下降(PGD)算法结合早期停止机制训练神经网络，这在过度参数化设置中得到更优的回归率。2. 提出了一种原理分解方法，将网络输出分解为有理内积核希尔伯特空间函数和残差函数。3. 应用了局部Rademacher复杂性理论，以更紧密地控制由PGD迭代所得的所有神经网络函数所形成的函数类的复杂性。4. 证明了PGD算法能促使神经网络从线性NTK阶段转移至新的阶段，从而获得更好的泛化能力。", "conclusion": "本研究展示了当目标函数位于插值空间中，使用PGD算法并结合早期停止机制训练过度参数化的神经网络获得更优的回归率。进一步展示了这一方法在逃逸标准NTK阶段并提升泛化性能的可能性。这为非参数回归研究提供了新的视角和方法。"}
{"llm_update_time": "20250815", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2407.01566", "html_url": "https://arxiv.org/abs/2407.01566", "title": "参数上下文在线学习理论中的经纪行为", "title_en": "A Parametric Contextual Online Learning Theory of Brokerage", "authors": "François Bachoc,Tommaso Cesari,Roberto Colomboni", "background": "本文研究了在交易者之间进行经纪业务时上下文信息的作用。这是一个序列问题，在每次时间步长中，都会有两个交易者带着他们希望交易的资产的私人估值到达。经纪人根据资产的上下文数据和市场状况建议一个交易（或经纪）价格，然后交易者根据他们的估值是高于还是低于经纪价格来决定是买还是卖。如果中介方建议的价格落在两个估值之间，并且有一个买家和一个卖家，那么就会达成交易。", "innovation": "本文设计了新的算法，并在各种标准假设下证明了理论遗憾保证的最优性。", "conclusion": "本文研究了一个在交易者之间进行的交易代理问题，证明了在不同假设下的最优理论遗憾保证，为在线上下文中进行市场中介提供了理论依据。"}
{"llm_update_time": "20250815", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2409.16135", "html_url": "https://arxiv.org/abs/2409.16135", "title": "对自闭症诊断会话中儿童-成人对话的语音识别模型评估", "title_en": "Evaluation of Speech Foundation Models for ASR on Child-Adult Conversations in Autism Diagnostic Sessions", "authors": "Aditya Ashvin,Rimita Lahiri,Aditya Kommineni,Somer Bishop,Catherine Lord,Sudarsana Reddy Kadiri,Shrikanth Narayanan", "background": "在临床环境中可靠转录儿童-成人对话对于诊断自闭症等发育障碍至关重要。近年来，深度学习技术的进步和大量标注数据的可用性使得基于语音的基础模型能够在自动语音识别（ASR）方面取得显著提升。然而，这些模型在儿童-成人互动对话场景中的表现尚未得到充分探索。本文采用Whisper、Wav2Vec2、HuBERT和WavLM等模型对自闭症诊断会话中的儿童-成人互动数据集进行全面评估，结果显示，语音基础模型在儿童语音识别上的性能有所下降（绝对词错误率下降15-20%），而对于成人语音的表现则较好。", "innovation": "通过采用低资源设置下基于LoRA方法对表现最佳的零样本模型（Whisper-large）进行微调，分别在儿童和成人语音上取得了8%和13%的绝对词错误率改进。介绍了基于语音的基础模型在儿童-成人对话场景中的表现评估方法及针对儿童语音识别性能下降的问题，提出了一种改进策略，展示了相对较大的性能提升，为ASR在临床应用中进一步提高准确性和可靠性提供了新的思路和方法。", "conclusion": "研究表明，现有的基于语音的基础模型在处理儿童-成人对话场景中的儿童语音时存在性能下降问题，但通过适当的微调优化可以显著提升其性能。未来可以进一步探索更多针对此类应用场景的优化方法，以提高ASR在临床诊断中的实用性和准确性。"}
{"llm_update_time": "20250815", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2411.15913", "html_url": "https://arxiv.org/abs/2411.15913", "title": "无训练的基于潜在扩散模型的音乐风格迁移方法", "title_en": "A Training-Free Approach for Music Style Transfer with Latent Diffusion Models", "authors": "Heehwan Wang,Joonwoo Kwon,Sooyoung Kim,Shinjae Yoo,Yuewei Lin,Jiook Cha", "background": "音乐风格迁移能够通过结合一首乐曲的结构和另一首乐曲的风格特征来实现个性化音乐创作。尽管最近的方法探索了基于文本的生成和扩散合成技术，但大多数方法需要大量的训练、配对的数据集或详细的文本注释。", "innovation": "我们引入了Stylus，这是一种新颖的无需训练框架，用于直接操作已训练好的潜在扩散模型（LDM）的自注意力层，从而在梅尔频谱域中实现音乐风格迁移。Stylus通过替换内容音频的关键和值表示为风格参考中的表示，而不进行微调。进一步融入了查询保留、基于CFG的指导缩放、多风格插值和相位保留重建，以增强风格化质量和可控性。这种无训练的方法在感知质量和结构保留方面显著优于先前的方法，同时保持轻量且易于部署。", "conclusion": "该工作突显了基于扩散模型的注意力操作在高效、高保真度和可解释的音乐生成方面的潜力，无需进行训练。代码将在接受后发布。"}
{"llm_update_time": "20250815", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2411.06869", "html_url": "https://arxiv.org/abs/2411.06869", "title": "CapeLLM: 使用多模态大语言模型的无支撑类别无关姿态估计", "title_en": "CapeLLM: Support-Free Category-Agnostic Pose Estimation with Multimodal Large Language Models", "authors": "Junho Kim,Hyungjin Chung,Byung-Hoon Kim", "background": "传统的类别无关姿态估计(CAPE)依赖于带有标注关键点的支持图像，这是一个繁琐的过程，且可能无法充分捕捉不同类别对象之间的对应关系。尽管最近的研究探索了使用文本查询，利用其增强的稳定性和通用性，但现有方法仍然受限于对支持查询的依赖，未能充分使用预训练大语言模型中嵌入的丰富先验知识，并受限于其参数分布假设。这些局限性的存在促使了CapeLLM的提出，这是一个旨在解决这些挑战的多模态大语言模型，首次专为CAPE设计。", "innovation": "CapeLLM创新性地使用了查询图像和详细的文本描述作为输入来估计类别无关的关键点。其方法包括有效训练策略和用于指导MLLM在CAPE中应用的精心设计的指令。此外，CapeLLM提出了一种推理机制，以增强对未见关键点的推理过程，同时灵活地建模其潜在的空间分布和不确定性，基于上下文线索进行适应性优化。这种方法在MP-100基准测试中达到了新的最佳状态，在1-shot和5-shot设置下尤为显著，标志着类别无关姿态估计领域的一项重大进步。", "conclusion": "CapeLLM通过多模态大语言模型，克服了传统基于支撑图像的方法的局限性，实现了无支撑的类别无关姿态估计，展示了其在姿态估计领域的卓越性能。"}
{"llm_update_time": "20250815", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2410.15729", "html_url": "https://arxiv.org/abs/2410.15729", "title": "一种用于多任务学习的两阶段学习决策推迟方法", "title_en": "A Two-Stage Learning-to-Defer Approach for Multi-Task Learning", "authors": "Yannis Montreuil,Shu Heng Yeo,Axel Carlier,Lai Xing Ng,Wei Tsang Ooi", "background": "两阶段学习决策推迟（L2D）框架已经在分类任务和最近的回归任务中得到了广泛的研究。然而，在许多实际应用中，需要在多任务设置中同时解决这两种任务。", "innovation": "作者提出了一种新的两阶段L2D框架，该框架通过统一的推迟机制将分类和回归任务集成在一起。该方法利用了一种两阶段的代理损失族，作者证明了这种损失族既是贝叶斯一致的，也是$(\text{G}, \text{R})$-一致的。此外，作者还明确地阐述了共享表示学习如何影响这些一致性保证，并对多专家两阶段方案的最小化间隙进行了分析。", "conclusion": "在物体检测和电子健康记录分析实验中，作者展示了该方法的有效性，并指出现有L2D方法在多任务场景中的局限性。"}
{"llm_update_time": "20250815", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.08052", "html_url": "https://arxiv.org/abs/2508.08052", "title": "持续学习中模型容量动态理解", "title_en": "On Understanding of the Dynamics of Model Capacity in Continual Learning", "authors": "Supriyo Chakraborty,Krishnan Raghavan", "background": "持续学习（CL）中存在稳定性-可塑性两难问题，这与其代表任务的能力密切相关，是CL中的一项基本挑战。这项工作深入探讨了持续学习中模型容量的有效模型容量（CLEMC），它描述了稳定性-可塑性平衡点的动态行为。", "innovation": "开发了一种差分方程来建模神经网络、任务数据和优化过程之间相互作用的演变方式。通过CLEMC，证明了模型容量是动态且非稳态的，无论神经网络架构或优化方法如何，当新任务的分布与先前的不同时，神经网络适应新任务的能力都会下降。", "conclusion": "通过广泛的实验证明了理论发现，支持了神经网络的有效容量和稳定性-可塑性平衡点的非稳态性质，展示出无论适应何种网络架构或优化方法，面对新任务分布变化时，神经网络代表新任务的能力都会减弱。"}
{"llm_update_time": "20250815", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2412.06534", "html_url": "https://arxiv.org/abs/2412.06534", "title": "通过反转理解基于变换器的视觉模型", "title_en": "Understanding Transformer-based Vision Models through Inversion", "authors": "Jan Rathjens,Shirin Reyhanian,David Kappel,Laurenz Wiskott", "background": "理解深度神经网络的工作机制仍然是机器学习和计算机视觉领域的基本挑战。一项有希望但仅初步探索的方法是特征反转，它通过使用训练好的逆向神经网络从中间表示重建图像。", "innovation": "本研究重新审视特征反转，并引入了一种新的模块化变体，使其可以更高效地应用该技术。这种方法被系统地应用于大规模的基于变换器的视觉模型——检测变换器和视觉变换器，并能以有意义的方式对重建图像进行质性解释。进一步的定量评估还揭示了这两种变换器架构中图像特征表示的潜在机制。研究发现，这些模型如何编码上下文形状和图像细节，各层之间的关联方式以及它们对颜色扰动的鲁棒性。这些发现有助于更深入地理解基于变换器的视觉模型及其内部表示。", "conclusion": "这些研究结果为基于变换器的视觉模型和其内部表示提供了重要的见解，并且实验代码可以在此处复制。"}
{"llm_update_time": "20250815", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2412.12400", "html_url": "https://arxiv.org/abs/2412.12400", "title": "在复杂渔业环境中利用机器学习优化渔业收获控制规则设计", "title_en": "Using machine learning to inform harvest control rule design in complex fishery settings", "authors": "Felipe Montealegre-Mora,Carl Boettiger,Carl J. Walters,Christopher L. Cahill", "background": "在渔业科学中，管理大小分级的随机群体的捕捞一直是一个长期且复杂的问题。传统的基于 biomass 和捕捞参考点的直线预防性政策已经成为解决这个问题的标准方法。虽然这些标准的反馈政策是从假设简单生态动力学的分析或动态编程解决方案中改编而来的，但在现实世界中，它们往往被应用于更为复杂的生态条件下。本文探讨了如何利用强化学习和贝叶斯优化工具为部分观测、年龄分级、间歇性鱼群设计捕捞控制规则，尤其是在加拿大的阿尔伯塔州鲍鱼鱼群的案例中，其高度多变的招募动态一直困扰着管理者和生态学家。", "innovation": "本文创新点在于提出利用机器学习技术（特别是强化学习和贝叶斯优化）来优化复杂渔业环境下的捕捞控制规则设计，特别适用于高度变异的鱼群管理问题。通过这种方法，可以提高捕捞策略的有效性和可持续性，尤其是在数据不完整或生态系统复杂度高的情况下，能够提供更优的捕捞控制政策。此外，本文还引入了使用平均鱼体重作为补足指标来辅助决策的方法。", "conclusion": "通过使用机器学习方法优化获取了增强的捕捞控制规则，在阿尔伯塔州的鲍鱼渔业案例中，优化后的策略表现出比基于参考点的传统策略更好的表现。而且，增加基于平均鱼体重的信息确实改善了政策决策的质量，提供了更可持续的管理方案。"}
{"llm_update_time": "20250815", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2502.01027", "html_url": "https://arxiv.org/abs/2502.01027", "title": "Adversarial Robustness in Two-Stage Learning-to-Defer: Algorithms and Guarantees", "title_en": "Adversarial Robustness in Two-Stage Learning-to-Defer: Algorithms and Guarantees", "authors": "Yannis Montreuil,Axel Carlier,Lai Xing Ng,Wei Tsang Ooi", "background": "两阶段学习-推迟(L2D)通过将每个输入分配给固定的主要模型或多个离线专家之一，能够进行最优任务委派，支持复杂多智能体环境中的可靠决策。然而现有的L2D框架假设输入干净，对可能操纵查询分配的对抗扰动非常脆弱，如导致成本高昂的错误路由或专家超载。", "innovation": "本文首次全面研究了两阶段L2D系统的对抗鲁棒性。引入了两种新型攻击策略——非目标性攻击和目标性攻击，分别扰乱最优分配或强制查询到特定代理。提出了一种名为SARD的凸学习算法，该算法基于通常Bayes一致和(Α, Θ)-一致的代理损失函数家族。结果表明，SARD显著提高了在对抗攻击下的鲁棒性，同时保持了良好的干净性能，为安全且可信赖的L2D部署奠定了关键基础。", "conclusion": "实验结果证明，SARD在对抗攻击下的鲁棒性显著提升，同时保持了良好的干净性能，标志着向安全且可信赖的L2D部署迈出重要一步。"}
{"llm_update_time": "20250815", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2407.15881", "html_url": "https://arxiv.org/abs/2407.15881", "title": "在战略异质性代理之间的合作均值估计：个体理性、公平性和真实贡献", "title_en": "Collaborative Mean Estimation Among Heterogeneous Strategic Agents: Individual Rationality, Fairness, and Truthful Contribution", "authors": "Alex Clinton,Yiding Chen,Xiaojin Zhu,Kirthevasan Kandasamy", "background": "本文研究了$m$个代理通过协作学习来估计一个$d$维向量$\boldsymbol{\boldsymbol{\nu = (\nu_1, \nu_2, \rightarrow \nu_d)}}$的问题。每个代理$i$可以通过从对应的正态分布$\boldsymbol{\boldsymbol{\nu_k}}$中抽样来获取信息，但每个采样动作都会产生一定的成本$c_{i, k}$. 传统的独立学习方式无法有效降低收集数据的成本和估计误差，因此文章探讨了一种协作学习机制，在减少成本和估计误差的同时还能确保每个人的参与都是值得的，并防止协作中的策略性行为导致的非理想结果。", "innovation": "文章设计了一种机制来促进代理间的合作，同时解决了两个主要挑战：确保结果对每个代理都是理性的并且公平，以及防止策略性行为导致的不良后果。文章设计了一种机制及其相关的纳什均衡（NE），这种机制在所有代理都有利的同时，还能够最小化社会惩罚，即所有代理共同的估计误差和收集成本之和。这种机制在最坏情况下提供了$\boldsymbol{O(\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\bf \text{O}}}}}}}}}}}}\boldsymbol{(\boldsymbol{\bf \boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\bf \bf \boldsymbol{\boldsymbol{\bf \boldsymbol{\boldsymbol{\boldsymbol{\bf \boldsymbol{\boldsymbol{\bf \text{m}}}}}}}}}}}}}^\frac{1}{2}\boldsymbol{))}$的最社交惩罚近似比，并在有利条件下提供$\boldsymbol{O(1)}$的近似比。此外，文章还证明了一些难度结果：没有非平凡机制能保证（i）一个主导策略均衡使得每个代理都报告真实信息；（ii）对所有策略配置都是理性的；（iii）或在任何NE中避免最坏情况下的$\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\bf \boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\bf \text{m}}}}}}}}}}}}^\frac{1}{2}\boldsymbol{)}$级的社会收益稳定价格。", "conclusion": "通过结合谈判理论中的公理化概念，文章展示了所提出机制相较于单纯最小化社交惩罚的机制能提供更公平的结果。"}
{"llm_update_time": "20250815", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2502.08557", "html_url": "https://arxiv.org/abs/2502.08557", "title": "通过中介对话问询的新查询扩展方法", "title_en": "A New Query Expansion Approach via Agent-Mediated Dialogic Inquiry", "authors": "Wonduk Seo,Hyunjin An,Seunghyun Lee", "background": "在信息检索（IR）中，查询扩展被广泛用于通过补充初始查询以更丰富的信息来改善搜索结果。虽然基于大型语言模型（LLM）的方法能够生成伪相关的内容和扩展术语，但常常会导致单一和狭隘的扩展，缺乏所需的各种上下文以检索相关信息。", "innovation": "本文提出了一种名为AMD的新型代理中介对话框架，该框架采用多代理过程，通过对话式问询和反馈提炼来丰富查询表示。AMD框架包括三个专业角色，分别是：（1）苏格拉底式提问代理，将初始查询重新表述为三个子问题，每个子问题由特定的苏格拉底式提问维度（澄清、假设探查和推论探查）启发；（2）对话式回答代理，生成伪答案，以多视角丰富查询表示，符合用户意图；（3）反思反馈代理，评估并改进这些伪答案，确保只保留最相关和最有信息量的内容。这些代理共同工作，有效地创建了更丰富的查询表示。", "conclusion": "通过广泛的基准测试（包括BEIR和TREC），本文的框架在检索任务上表现优于之前的方法，提供了一个稳健的解决方案。"}
{"llm_update_time": "20250815", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2412.19160", "html_url": "https://arxiv.org/abs/2412.19160", "title": "一种基于相位只有交叉注意力的轻量级变压器用于照度不变的生物特征认证", "title_en": "A Lightweight Transformer with Phase-Only Cross-Attention for Illumination-Invariant Biometric Authentication", "authors": "Arun K. Sharma,Shubhobrata Bhattacharya,Motahar Reza,Bishakh Bhattacharya", "background": "传统的生物识别系统因各种不可避免的因素遭受了重大挫折，例如在基于面部识别的生物识别中佩戴面罩，以及在基于指纹的生物识别中存在卫生问题。因此，需要一种新的方法来克服这些限制。本文提出了一种名为POC-ViT的新型轻量级视觉转换器，它结合使用面部前额和眼周区域的两种生物特征，即使在戴口罩的情况下也能表现出色，不需要任何物理接触，为传统的生物识别方法提供了有前景的替代方案。", "innovation": "所提出的POC-ViT框架旨在处理两种生物特征，并捕捉它们相对结构模式的相互依赖性。每个通道包含一种使用相位只相关（POC）的交叉注意力机制，能够捕捉这些特征的个体和相关结构模式。使用POC计算交叉注意力提取空间特征的相位相关性，使模型能够在不同的分辨率、强度和光照条件下保持鲁棒性。此外，该轻量级模型适合边缘设备部署。", "conclusion": "所提出的框架在350个样本的FSVP-PBP数据库上进行了性能验证，表现出了显著的分类准确性，达到了98.8%，超越了现有的最先进的方法。POC-ViT框架为基于生物特征的身份验证提供了一种新的有前景的技术。"}
{"llm_update_time": "20250815", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2503.20839", "html_url": "https://arxiv.org/abs/2503.20839", "title": "TAR: Teacher-Aligned Representations via Contrastive Learning for Quadrupedal Locomotion", "title_en": "TAR: Teacher-Aligned Representations via Contrastive Learning for Quadrupedal Locomotion", "authors": "Amr Mousa,Neil Karavis,Michele Caprio,Wei Pan,Richard Allmendinger", "background": "四足行走通过强化学习（RL）通常采用教师-学生范式，其中受过训练的教师引导感知学生策略。然而，关键挑战包括受过训练的教师与仅感知的学生之间的表示错位、行为克隆引起的协变量转移以及缺乏部署适应性，这些均导致在真实世界场景中泛化能力较差。", "innovation": "我们提出了一种称为教师对齐表示通过对比学习（TAR）的框架，利用受控信息与自我监督对比学习相结合来弥合这一差距。通过使用对比目标对模拟中的受控教师进行表示对齐，学生策略从中学习结构化的潜在空间，并在边缘分布（OOD）场景中表现出更强大的泛化能力，最终超越了完全受控的“教师”。实验结果显示相较于最先进的基线算法，训练速度加快了2倍以达到最佳性能。边缘分布场景的平均泛化能力提高了40%，并且无需受控状态即可无缝过渡到部署期间的学习，这在样本高效、适应性行走方面设立了新的标准，同时允许在真实世界场景中的持续微调。", "conclusion": "与现有方法相比，TAR在边缘分布场景中的泛化能力提高了40%，并且能够无缝过渡到部署期间的学习，不需受控状态，这在样本高效、适应性行走方面设立了新的标准，同时允许在真实世界场景中的持续微调。"}
{"llm_update_time": "20250815", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2411.09776", "html_url": "https://arxiv.org/abs/2411.09776", "title": "无需冲突的机器学习防御组合", "title_en": "Combining Machine Learning Defenses without Conflicts", "authors": "Vasisht Duddu,Rui Zhang,N. Asokan", "background": "机器学习 (ML) 防御措施可以保护信息安全、隐私和公平性，但是现实中的模型需要同时保护多种风险。因此，需要结合多种不同的防御措施。但是，如果这些防御措施在ML模型中的交互是冲突的，可能会导致防御措施的效果降低，甚至失效。因此，实践者们需要一个方法来确定某种组合是否会有效，但实验性地确定有效组合非常耗时且昂贵，尤其是需要组合多种防御措施时。所以，需要一个便宜、易用、无需改变基础防御措施且适用于不同类型的防御措施的组合技术。", "innovation": "我们提出了一种原理性的组合技术，称为Def\restroke Con (Def\restroke Con)，它可以确定有效的防御组合。Def\restroke Con 满足所有上述要求：90% 的准确率，实现了在八个之前研究的组合中的80%准确性，以及之前未探索的30个组合中的81%准确性。", "conclusion": "Def\restroke Con是一种适用于多种防御措施的组合技术，它能够帮助确定有效的防御组合，并且满足准确性、可扩展性、对防御措施无侵入性以及通用性的要求。"}
{"llm_update_time": "20250815", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2504.01400", "html_url": "https://arxiv.org/abs/2504.01400", "title": "ToolACE-R: 模型感知迭代训练与自适应精炼以提高工具学习", "title_en": "ToolACE-R: Model-aware Iterative Training and Adaptive Refinement for Tool Learning", "authors": "Xingshan Zeng,Weiwen Liu,Xu Huang,Zezhong Wang,Lingzhi Wang,Liangyou Li,Yasheng Wang,Lifeng Shang,Xin Jiang,Ruiming Tang,Qun Liu", "background": "大型语言模型（LLMs）的工具学习允许模型利用外部工具来解决复杂的用户任务，已成为扩展模型能力的一个有前景的途径。然而，现有的方法主要关注数据合成以微调LLMs以有效地调用工具，而忽略了如何充分激发模型的潜力。", "innovation": "提出了一种名为ToolACE-R的新框架，集成了模型感知迭代训练和自适应精炼。框架包括一个根据模型的进化能力不断调整培训样本的模型感知迭代培训流程，以及一个自精炼训练语料库，强调LLMs迭代优化工具调用的能力，无需外部反馈。此外，引入了适应性自精炼机制，以提高测试时的效率，使训练模型能够自主判断何时停止自精炼过程。这些创新有助于更有效地提升工具调用的表现力，提供了一种更高效和可扩展的工具学习途径。", "conclusion": "通过广泛的实验证明，ToolACE-R 在多个基准数据集上取得了与高级基于API模型相当的性能。通过适应性自精炼机制进一步优化了工具调用的性能。这些结果突显了ToolACE-R的有效性和普适性，为其提供了在全球范围内更有效和可扩展工具学习的潜在方向。"}
{"llm_update_time": "20250815", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2504.05349", "html_url": "https://arxiv.org/abs/2504.05349", "title": "Hyperflux: 表明权重重要性的剪枝方法", "title_en": "Hyperflux: Pruning Reveals the Importance of Weights", "authors": "Eugen Barbulescu,Antonio Alexoaie,Lucian Busoniu", "background": "网络剪枝被用于减少大型神经网络的推断延迟和功耗。然而，大多数现有方法使用了经验主义的启发式算法，缺乏深刻的理论基础，主要依靠实验结果来证明其有效性。", "innovation": "引入了Hyperflux，这是一种基于L0剪枝的概念性方法，通过计算每个权重的“流量”（即权重删除后梯度的响应）来估计权重的重要性。一个全局压力项不断将所有权重推向剪枝，对于那些对准确性至关重要的权重会根据其流量自动再生。提出了几个自然推导出的特性，并通过实验验证了这些特性。其中一个特性是最终稀疏性和压力之间的关系，从而推导出一个通用的标度定律方程，用于设计我们的稀疏性控制调度器。", "conclusion": "实验结果表明，Hyperflux方法在CIFAR-10和CIFAR-100上分别在ResNet-50和VGG-19上取得了最先进的剪枝结果。"}
{"llm_update_time": "20250815", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2503.03022", "html_url": "https://arxiv.org/abs/2503.03022", "title": "生成式主动适应以应对漂移和不平衡的网络入侵检测", "title_en": "Generative Active Adaptation for Drifting and Imbalanced Network Intrusion Detection", "authors": "Ragini Gupta,Shinan Liu,Ruixiao Zhang,Xinyue Hu,Xiaoyang Wang,Hadjer Benkraouda,Pranav Kommaraju,Phuong Cao,Nick Feamster,Klara Nahrstedt", "background": "尽管机器学习在网络安全中的入侵检测系统中显示了潜力，但其性能常常因概念漂移和数据不平衡受阻，这使得为适应而准备合适的数据成为难题。传统的数据标注过程耗费大量劳动力，特别是在处理不断演变且稀有的攻击类型时更为困难，从而限制了模型的适应性。因此，迫切需要一种能够在减少标注工作量的同时提升模型鲁棒性的方法。", "innovation": "本文提出了一种生成式主动适应框架，通过密度感知的数据集先验选择，识别最具有指导意义的样本进行标注，并利用深度生成模型有条件地合成多样样本，以增强训练集并缓解概念漂移的影响。该框架在CIC-IDS 2018仿真IDS数据集和真实世界ISP数据集上的评测显示，整体F1分数显著提升，从未适应前的0.60提升至0.86，尤其是稀有攻击如Infiltration, Web Attack,和FTP-BruteForce的表现显著改善，分别从0.001, 0.04, 和0.00提升到0.30, 0.50, 和0.71，从而在减少标记成本的同时提升了稀有攻击的检测性能。", "conclusion": "该框架有效提升了稀有攻击检测性能并降低了标记成本，使其成为入侵检测的有效、可扩展且实用的解决方案。"}
{"llm_update_time": "20250815", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2505.14647", "html_url": "https://arxiv.org/abs/2505.14647", "title": "带有线搜索的顺序QCQP方法用于 bilevel 优化", "title_en": "Sequential QCQP for Bilevel Optimization with Line Search", "authors": "Sina Sharifi,Erfan Yazdandoost Hamedani,Mahyar Fazlyab", "background": " bilevel 优化问题涉及到层层嵌套的问题结构，导致上下级之间有复杂的相互依赖关系。现有的方法在提供实时可行性和保证上层优化目标下降方面存在挑战。本研究旨在提出一种单循环、无需调参的算法，以解决这些挑战。", "innovation": "提出了一种单循环、无需调参的算法，确保任意时间点的可行性，即下层最优性条件的大致满足，并确保上层目标函数的下降。通过在每一步迭代中求解一个具有明确解的凸二次约束的二次规划（QCQP）问题来确定搜索方向。然后通过借鉴控制障碍函数的回溯线性搜索策略，确保安全且均匀正的步长。这种方法具有扩展性，无需超参数调优，并在温和的局部正则假设下收敛。该算法以一阶稳定标准为基准建立了 O(1/k) 的泛化收敛速度，并通过在代表性的 bilevel 任务中的表现证明了其有效性。", "conclusion": "该方法在具备实时可行性、确保上层目标函数下降的同时，还证明了其在温和的局部正则假设下的收敛性，通过回溯线性搜索策略确保安全性的优势，并且在实际的 bilevel 优化任务上显示了其有效性。"}
{"llm_update_time": "20250815", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2504.19657", "html_url": "https://arxiv.org/abs/2504.19657", "title": "神经相关性塑造蓄水池循环神经网络的记忆容量和非线性计算能力的可扩展行为", "title_en": "Neuronal correlations shape the scaling behavior of memory capacity and nonlinear computational capability of reservoir recurrent neural networks", "authors": "Shotaro Takasu,Toshio Aoyagi", "background": "蓄水池计算是一种强大的实时信息处理框架，以其高计算能力和快速学习能力著称，应用范围从机器学习扩展到生物系统。此前已有研究表明，蓄水池RNN（Reservoir Recurrent Neural Networks）的记忆容量与读出神经元的数量之间存在次线性关系。然而，许多理论工作忽略了神经元相关性的影响，以简化分析。本研究旨在通过开发一个包含神经元相关性影响的理论框架，探讨神经元相关性对蓄水池RNN记忆容量和非线性计算能力可扩展行为的影响。", "innovation": "研究开发了一个包含神经元相关性影响的理论框架，以解释蓄水池RNN记忆容量的次线性增加，并且这一理论成功地将神经元相关强度与记忆容量的次线性关系联系起来。研究还揭示了这一原则适用于不同类型的RNN，并且通过数值模拟发现，当记忆容量的增长变得次线性时，增加读出神经元数量能够逐级实现更高的非线性处理能力。研究指出，神经元相关性不仅影响记忆容量，也控制非线性计算能力的逐步增长。", "conclusion": "本研究为设计可扩展且成本效益高的蓄水池计算奠定了基础，提供了关于神经元相关性、线性记忆和非线性处理相互作用的新见解。"}
{"llm_update_time": "20250815", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.10236", "html_url": "https://arxiv.org/abs/2506.10236", "title": "提示攻击揭示遗忘方法中的浅层知识删除", "title_en": "Prompt Attacks Reveal Superficial Knowledge Removal in Unlearning Methods", "authors": "Yeonwoo Jang,Shariqah Hossain,Ashwin Sreevatsa,Diogo Cruz", "background": "本文讲述了某些机器遗忘方法在面对简单提示攻击时可能会失效的现象。研究人员系统性地评估了八种遗忘技术在三种模型家族中的表现，使用输出分析、logit分析和探针分析来衡量宣称遗忘的知识能否被恢复的程度。尽管某些方法如RMU和TAR表现出稳健的遗忘效果，但ELM在特定的提示攻击下仍显得脆弱（例如，在原始提示前添加印度填充值文本能恢复57.3%的准确性）。logit分析进一步表明，未遗忘的模型不太可能通过答案格式的变化来隐藏知识，给出的输出和logit准确性之间存在很强的关联。这些发现挑战了有关遗忘效率的现有假设，并强调了需要评估框架来可靠地区分真正的知识消除与表面的输出抑制。", "innovation": "研究提出了通过系统性评估八种遗忘技术来揭示示例性可恢复知识的方法，并通过logit分析强调了浅层知识的删除问题。研究还公开释放了评估框架，以方便进一步研究。", "conclusion": "研究结果表明，遗忘方法的有效性存在疑问，实际上可能无法完全删除知识，并指出需要新的评估方法来更准确地评估遗忘效果。"}
{"llm_update_time": "20250815", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.19794", "html_url": "https://arxiv.org/abs/2506.19794", "title": "为什么开源大语言模型在数据分析中挣扎？一项系统的实证研究", "title_en": "Why Do Open-Source LLMs Struggle with Data Analysis? A Systematic Empirical Study", "authors": "Yuqi Zhu,Yi Zhong,Jintian Zhang,Ziheng Zhang,Shuofei Qiao,Yujie Luo,Lun Du,Da Zheng,Ningyu Zhang,Huajun Chen", "background": "大型语言模型（LLMs）有望自动化数据处理任务，但开源模型在这些推理密集型场景中面临重大限制。本文研究了增强开源LLMs的数据分析能力的策略。通过创建包含多样性和现实性的种子数据集，我们从数据理解、代码生成和战略规划三个核心维度评估了模型的行为。", "innovation": "本文的研究结果揭示了三个关键发现：战略规划质量是决定模型表现的主要因素；交互设计和任务复杂性显著影响推理能力；数据质量比多样性对达到最佳表现有更大的影响。基于这些洞察，开发了一种数据合成方法，显著提高开源LLMs的分析推理能力。开源代码可在指定链接下载。", "conclusion": "开源LLMs在数据理解、代码生成和战略规划方面的表现主要是由战略规划质量、交互设计和任务复杂性以及数据质量决定的。通过提高这些方面的表现，可以显著增强开源LLMs在数据分析任务上的性能。"}
{"llm_update_time": "20250815", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2504.14493", "html_url": "https://arxiv.org/abs/2504.14493", "title": "FinSage：一种用于财务申报问答的多方面RAG系统", "title_en": "FinSage: A Multi-aspect RAG System for Financial Filings Question Answering", "authors": "Xinyu Wang,Jijun Chi,Zhenghan Tai,Tung Sum Thomas Kwok,Muzhi Li,Zhuhong Li,Hailin He,Yuchen Hua,Peng Lu,Suyuchen Wang,Yihong Wu,Jerry Huang,Jingrui Tian,Fengran Mo,Yufei Cui,Ling Zhou", "background": "在现实场景中利用大型语言模型时，往往需要使用特定领域的数据和工具以遵守复杂的规定。在金融领域，现代企业越来越多地依赖 Retrieval-Augmented Generation (RAG) 系统来应对复杂的合规要求。然而，现有的解决方案在处理多模态数据（例如文本、表格、图表）及其不断变化的监管标准时存在困难，导致关键信息提取的准确性受损。", "innovation": "我们提出了FinSage框架作为解决方案，旨在满足多模态财务文档在合规分析中的需求。FinSage引入了三项创新元素：(1) 多模态预处理流水线，能够统一多种数据格式并生成文字段落级别的元数据摘要；(2) 增强了查询扩展（HyDE）和元数据感知语义搜索的多路径稀疏稠密检索系统；(3) 通过直接偏好优化（DPO）进行微调的领域专门化重新排名模块，以优先处理合规关键内容。实验结果表明，FinSage在FinanceBench问答数据集上达到了92.51%的召回率，比最好的基线方法高出24.06%的准确性。此外，FinSage已经在在线会议中成功部署，服务了超过1200人。", "conclusion": "FinSage框架在应对多模态财务文档中的复杂合规需求方面表现出色，特别是在关键信息提取的准确性方面，优于现有方法。该框架在实际应用中也得到了成功的应用，为金融问答提供了有效的解决方案。"}
{"llm_update_time": "20250815", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.22493", "html_url": "https://arxiv.org/abs/2506.22493", "title": "政治极谱测试（PCT）的详细因素分析：导航大型语言模型的理念", "title_en": "A Detailed Factor Analysis for the Political Compass Test: Navigating Ideologies of Large Language Models", "authors": "Sadia Kamal,Lalu Prasad Yadav Prakash,S M Rafiuddin,Mohammed Rakib,Atriya Sen,Sagnik Ray Choudhury", "background": "政治极谱测试（PCT）或类似问卷已经用于量化大模型（LLM）的政治倾向。最近的研究已经探讨了PCT测试的有效性。这项研究进一步分析了标准生成参数的变化对模型PCT评分的影响，发现这些变化对评分影响不大。但是外部因素，如提示的变化和微调，单独或共同作用下会对评分产生影响。此外，研究还发现，当模型在包含更高认知政治内容的数据集上进行微调时，PCT评分不会受到影响。", "innovation": "该研究通过详细分析设计了新方法，来研究影响模型PCT评分的各种外部因素，特别是提示的变化和微调的作用。此外，研究还发现，即便微调数据集包含大量政治内容，模型的PCT评分依然保持稳定。", "conclusion": "该研究引起了对PCT和其他类似测试有效性的全面调查需求，同时也强调了政治倾向如何以机制方式编码在LLMs中的重要性。"}
{"llm_update_time": "20250815", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2505.15002", "html_url": "https://arxiv.org/abs/2505.15002", "title": "解析迭代CHAD", "title_en": "Unraveling the iterative CHAD", "authors": "Fernando Lucatelli Nunes,Gordon Plotkin,Matthijs Vákár", "background": "Combinatory Homomorphic Automatic Differentiation (CHAD)最初作为一种语义驱动的源到源转换，用于总的功能程序的反向模式自动微分。本文扩展了CHAD，使其能够处理包含部分操作（可能非终止）、数据依赖条件（例如，实数测试）和迭代构造（例如，while循环）的程序，同时保持CHAD的核心原则，即保持语义结构。通过引入迭代广泛的分类范畴，将迭代整合到依赖类型编程语言中，这是一种有原则的方法。通过从基础范畴中的迭代提升到分类范畴中的参数化初等代数，获得了模型While循环和其他迭代构造的op-fibred迭代结构。", "innovation": "本文的中心贡献是引入迭代广泛的分类范畴，这为将迭代整合到依赖类型编程语言中提供了一个有原则的方法。通过这种技术，CHAD转换被扩展到循环程序，作为某种合适意义下的唯一保持结构的函子。特别地，它是从源语言对应的迭代Freyd范畴到从目标语言获得的容器范畴的唯一的迭代Freyd范畴同态，使得每个原始操作都映射为其（转置的）导数。通过源语言语法分类模型的普遍性质证明了这一扩展转换的正确性，表明差分程序计算了其原始程序的正确反向模式导数。", "conclusion": "通过迭代广泛的分类范畴，将CHAD转换扩展到循环程序，保持了结构的完整性，并通过源语言的语法分类模型的普遍性质证明了这一扩展转换的正确性，使得差分程序能正确计算原始程序的反向模式导数。"}
{"llm_update_time": "20250815", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.08280", "html_url": "https://arxiv.org/abs/2507.08280", "title": "MIRRAMS：在未见缺失性变化下的鲁棒表征学习", "title_en": "MIRRAMS: Learning Robust Tabular Models under Unseen Missingness Shifts", "authors": "Jihye Lee,Minseo Kang,Dongha Kim", "background": "缺失值的出现往往反映了数据收集政策的变化，这种变化可能随时间和地点而变化，即使底层特征分布保持稳定。训练集和测试集之间的缺失性分布变化会影响模型的预测性能，造成挑战。", "innovation": "提出了一种新的深度学习框架MIRRAMS，它引入了一组基于互信息的鲁棒性条件（MI robustness conditions），指导模型抽取与标签相关的信息，从而增强鲁棒性。同时设计了简单的损失项（MIRRAMS），这些损失项共同定义了最终目标。", "conclusion": "MIRRAMS 在多个基准表格数据集上进行了广泛的实验，展示了其相对于现有方法的优越性能，并且能够在缺省值条件多变的情况下保持稳定的性能。即使在完全观察到的情况下，MIRRAMS 也表现出了优越性能，表明这是一项通用的、现成的框架，适合一般目的的表格学习。"}
{"llm_update_time": "20250815", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.06639", "html_url": "https://arxiv.org/abs/2507.06639", "title": "EXAONE Path 2.0：具有端到端监督的病理学基础模型", "title_en": "EXAONE Path 2.0: Pathology Foundation Model with End-to-End Supervision", "authors": "Myeongjang Pyeon,Janghyeon Lee,Minsoo Lee,Juseung Yun,Hwanil Choi,Jonghyun Kim,Jiwon Kim,Yi Hu,Jongseong Jang,Soonyoung Lee", "background": "在数字病理学中，全切片图像（WSIs）由于其巨大的像素尺度往往难以处理，因此大多数方法通过自我监督学习（SSL）训练补丁编码器，然后通过多次实例学习（MIL）或切片编码器聚合补丁级别的嵌入，用于下游任务。然而，补丁级别的SSL可能会忽略对于生物标志物预测至关重要的复杂领域特定特征，如突变状态和分子特性，因为SSL方法仅依赖于为自然图像领域选择的基本增强在小补丁级别区域上。此外，SSL方法在数据效率方面仍不及完全监督的方法，需要大量的计算资源和数据集才能达到竞争力。", "innovation": "介绍了一种名为EXAONE Path 2.0的新病理学基础模型，它在切片级别直接监督下学习补丁级别的表示学习。通过仅使用37k WSIs进行训练，EXAONE Path 2.0在10个生物标志物预测任务上达到了最先进的平均性能，展示了出色的数据效率。", "conclusion": "EXAONE Path 2.0通过直接的切片级别监督学习补丁级别的表示，相比仅依赖小补丁区域的自我监督学习，能更高效地捕捉复杂领域特定特征，并在任务上取得了更好的性能。"}
{"llm_update_time": "20250815", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2505.22107", "html_url": "https://arxiv.org/abs/2505.22107", "title": "长期上下文建模中变换器的维度高问题", "title_en": "Curse of High Dimensionality Issue in Transformer for Long-context Modeling", "authors": "Shuhai Zhang,Zeng You,Yaofo Chen,Zhiquan Wen,Qianyue Wang,Zhijie Qiu,Yuanqing Li,Mingkui Tan", "background": "基于变换器的大语言模型在自然语言处理任务中表现出色，通过自注意力机制捕捉长距离依赖关系。然而，长期上下文建模由于注意力计算的冗余性而面临显著的计算效率问题：尽管注意力权重通常稀疏，但所有token却消耗相同的计算资源。这项研究重新定义了传统的概率序列建模，将其作为监督学习任务，从而实现相关和不相关token的分离，更好地理解冗余性问题。研究表明，只有少数tokens对预测有显著贡献。基于此，提出了注意力优化的线性编码问题，并提出了一种分组编码策略，理论上证明该策略能够提高抗随机噪声的稳健性和提高学习效率。", "innovation": "重新定义传统概率序列建模为监督学习任务，理论分析注意力稀疏性，揭示仅少数tokens对预测有显著贡献。提出了分组编码策略，理论证明其能够提高对抗随机噪声的稳健性和增强学习效率。基于此策略，提出了Dynamic Group Attention (DGA)，通过在注意力计算中聚集不重要的tokens来显式减少冗余。实验结果表明DGA显著降低了计算成本，同时保持竞争力。", "conclusion": "提出的Dynamic Group Attention (DGA)策略能够有效减少注意力计算中的冗余，降低计算成本并提高模型的抗噪声能力，从而提高学习效率。"}
{"llm_update_time": "20250815", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.19712", "html_url": "https://arxiv.org/abs/2507.19712", "title": "Oranits: 使用元启发式和深度强化学习在Open RAN基智能交通系统中的任务分配和任务卸载", "title_en": "Oranits: Mission Assignment and Task Offloading in Open RAN-based ITS using Metaheuristic and Deep Reinforcement Learning", "authors": "Ngoc Hung Nguyen,Nguyen Van Thieu,Quang-Trung Luu,Anh Tuan Nguyen,Senura Wanasekara,Nguyen Cong Luong,Fatemeh Kavehmadavani,Van-Dinh Nguyen", "background": "现有研究往往忽略了任务之间复杂的相关性及其任务卸载到边缘服务器的成本，导致决策效果不佳。在基于Open Radio Access Network (Open RAN)的智能交通系统（ITS）中，自动车辆通过移动边缘计算进行高效处理，但现有研究未充分考虑这些问题。", "innovation": "该研究提出了一种名为Oranits的新型系统模型，明确考虑任务相关性和卸载成本，并通过车辆合作优化性能。此外，研究还提出了两步优化方法，包括一种基于混沌高斯全局ARO的元启发式演化计算算法（CGG-ARO）以及一个结合多智能体协调和多动作选择机制的增强奖励基于的深度强化学习框架（MA-DDQN），显著提高了任务分配速度并增强了适应性。", "conclusion": "仿真结果显示，CGG-ARO在完成任务数量和总效益方面分别提高了约7.1%和7.7%，而MA-DDQN在完成任务数量和总效益方面分别提高了11.0%和12.5%。这些结果表明Oranits在动态ITS环境中能够实现更快速、更强适应性和更高效的任务处理。"}
{"llm_update_time": "20250815", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.01006", "html_url": "https://arxiv.org/abs/2507.01006", "title": "GLM-4.1V-Thinking和GLM-4.5V：通过可扩展强化学习实现多功能多模态推理", "title_en": "GLM-4.1V-Thinking and GLM-4.5V: Towards Versatile Multimodal Reasoning with Scalable Reinforcement Learning", "authors": "GLM-V Team:Wenyi Hong,Wenmeng Yu,Xiaotao Gu,Guo Wang,Guobing Gan,Haomiao Tang,Jiale Cheng,Ji Qi,Junhui Ji,Lihang Pan,Shuaiqi Duan,Weihan Wang,Yan Wang,Yean Cheng,Zehai He,Zhe Su,Zhen Yang,Ziyang Pan,Aohan Zeng,Baoxu Wang,Bin Chen,Boyan Shi,Changyu Pang,Chenhui Zhang,Da Yin,Fan Yang,Guoqing Chen,Jiazheng Xu,Jiale Zhu,Jiali Chen,Jing Chen,Jinhao Chen,Jinghao Lin,Jinjiang Wang,Junjie Chen,Leqi Lei,Letian Gong,Leyi Pan,Mingdao Liu,Mingde Xu,Mingzhi Zhang,Qinkai Zheng,Sheng Yang,Shi Zhong,Shiyu Huang,Shuyuan Zhao,Siyan Xue,Shangqin Tu,Shengbiao Meng,Tianshu Zhang,Tianwei Luo,Tianxiang Hao,Tianyu Tong,Wenkai Li,Wei Jia,Xiao Liu,Xiaohan Zhang,Xin Lyu,Xinyue Fan,Xuancheng Huang,Yanling Wang,Yadong Xue,Yanfeng Wang,Yanzi Wang,Yifan An,Yifan Du,Yiming Shi,Yiheng Huang,Yilin Niu,Yuan Wang,Yuanchang Yue,Yuchen Li,Yutao Zhang,Yuting Wang,Yu Wang,Yuxuan Zhang,Zhao Xue,Zhenyu Hou,Zhengxiao Du,Zihan Wang,Peng Zhang,Debing Liu,Bin Xu,Juanzi Li,Minlie Huang,Yuxiao Dong,Jie Tang", "background": "文章介绍了一种旨在推进通用多模态理解和推理的视觉-语言模型（VLMs）家族，包括GLM-4.1V-Thinking和GLM-4.5V。研究人员首先通过大规模预训练开发了一个具备显著潜力的视觉基础模型，并在此基础上提出了一种名为Curriculum Sampling强化学习框架，以提高模型的多任务能力，涵盖了科学、技术、工程和数学问题解决、视频理解、内容识别、编程、语义解析、基于GUI的代理和长文档解析等多个领域。", "innovation": "研究提出了一种称为Reinforcement Learning with Curriculum Sampling (RLCS)的新框架，通过有计划地逐步增加难度的任务样本来训练模型，从而显著提升了模型在多个下游任务的综合性能。这种强化学习框架帮助降低了大型基础模型的训练复杂性，同时保持了良好的性能。GLM-4.5V在42个公开基准测试中取得了接近或优于其他同级别模型的表现，特别是在编程和GUI代理等具有挑战性的任务上，甚至优于更多参数的封闭源模型，而GLM-4.1V-9B-Thinking虽然规模较小，但在29个基准测试中仍表现出色，超过了更大型的Qwen2.5-VL-72B模型。", "conclusion": "这两种模型开源供公众使用，并在GitHub上发布了代码和更多信息。研究人员通过这种创新性的强化学习框架展示了多模态推理的潜力，推动了视觉-语言模型的发展，并在多个领域展示了出色的性能。"}
{"llm_update_time": "20250815", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.20871", "html_url": "https://arxiv.org/abs/2507.20871", "title": "FedABC：具有长期观点的注意力机制客户端选择方法在联邦学习中的应用", "title_en": "FedABC: Attention-Based Client Selection for Federated Learning with Long-Term View", "authors": "Wenxuan Ye,Xueli An,Junfan Wang,Xueqiang Yan,Georg Carle", "background": "6G网络中需要支持原生AI，联邦学习（FL）作为一种有前景的技术正逐步得到发展。联邦学习通过客户端协作训练AI模型而不直接共享数据，来提升隐私保护。虽然FL模型能够提升全球模型的精度，但客户端数据异质性减缓收敛速度，频繁参与训练增加了通信和计算负载。", "innovation": "提出了一种新型的客户端选择算法FedABC，通过评估模型相似性和每位模型的独贡献来选择关键客户端，并利用长周期视角优化客户端的参与。FedABC 基于注意力机制，动态调整客户端选择阈值，促进后期训练阶段的更多参与。", "conclusion": "FedABC显著提升了模型准确性和客户端参与效率，相较于传统的联邦学习算法FedAvg，使用32%更少的客户端实现相当水平的性能，与当前先进方法相比，使用2%更少的客户端达到3.5%更高的准确率。这项工作朝着在资源受限和异质环境中部署联邦学习迈进，从而支持6G网络中的原生AI能力。"}
{"llm_update_time": "20250815", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.05294", "html_url": "https://arxiv.org/abs/2508.05294", "title": "朝向具身代理性AI：基于大型语言模型和视觉语言模型的机器人自主性和交互调研与分类", "title_en": "Towards Embodied Agentic AI: Review and Classification of LLM- and VLM-Driven Robot Autonomy and Interaction", "authors": "Sahar Salimpour,Lei Fu,Farhad Keramat,Leonardo Militano,Giovanni Toffetti,Harry Edelman,Jorge Peña Queralta", "background": "随着大型语言模型（LLMs）和视觉语言模型（VLMs）的发展，为机器人自主性和人机接口带来了新型方法。同时，视觉语言动作模型（VLAs）或大型行为模型（LBMs）正在提高机器人的灵活性和能力。本文综述了向着代理应用和架构的努力，包括探索GPT风格的工具接口，以及更复杂系统中的AI代理作为协调者、规划者、感知行动者或通用接口。此类代理架构允许机器人对自然语言指令进行推理，调用API、计划任务序列或进行操作和诊断协助。除了同行评审的研究，我们还突出并包括了社区驱动项目、ROS软件包和工业框架，这些都展示了新兴趋势。本文提出了一种模型集成方法的分类学，并对现有文献中代理在不同解决方案中的角色进行了比较分析。", "innovation": "文章提出了一种模型集成方法的分类学，并对现有文献中代理在不同解决方案中的角色进行了比较分析，同时涵盖了社区驱动项目、ROS软件包和工业框架，展示了新兴趋势。", "conclusion": "通过分类学和比较分析，本文提供了一个全面的视角，展示了当前基于LLM和VLM的机器人自主性和交互技术的发展趋势，为研究人员和工程师提供了宝贵的参考和创新方向。"}
{"llm_update_time": "20250815", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.06406", "html_url": "https://arxiv.org/abs/2508.06406", "title": "区块链赋能的联邦学习", "title_en": "Blockchain-Enabled Federated Learning", "authors": "Murtaza Rangwala,KR Venugopal,Rajkumar Buyya", "background": "联邦学习（Federated Learning）解决了协作人工智能系统中的信任、隐私和协调等基本挑战。BCFL系统通过四维度（协调结构、共识机制、存储架构和信任模型）的系统化分析来研究其架构，展示如何在保护隐私的前提下进行有效的模型训练。", "innovation": "BCFL系统通过利用区块链技术，从随机加密谜题到有意义的机器学习任务提出了共识机制的新设计模式，特别是在针对联邦学习场景设计的“证明质量”和“证明联邦学习”机制中。BCFL系统通过多层架构在区块链交易限制和神经网络参数需求之间取得平衡，同时保持加密完整性的方法，以及提供了分布式图像分类训练的TrustMesh框架案例研究，展示了在IoT设备上实现有效的协作学习，同时保持完全透明和容错性。", "conclusion": "实际部署的案例研究跨医疗卫生联盟、金融服务和IoT安全应用，验证了BCFL系统的可行性。这些系统不仅在性能上与集中式方法相当，还提供了增强的安全保证，并支持了新的信任无中介的协作智能模式。"}
{"llm_update_time": "20250815", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.05690", "html_url": "https://arxiv.org/abs/2508.05690", "title": "利用大型语言模型进行SQL行为基于的数据库入侵检测", "title_en": "Leveraging large language models for SQL behavior-based database intrusion detection", "authors": "Meital Shlezinger,Shay Akirav,Lei Zhou,Liang Guo,Avi Kessel,Guoliang Li", "background": "数据库系统被广泛应用于各种领域以存储关键数据。然而，异常数据库访问行为的频率持续上升，尤其是在内部和外部攻击情况下。内部伪装者通常拥有更大的组织知识，可以更有效地模仿员工行为，而外部伪装者由于不熟悉组织，可能会表现出不同的行为。当前的方法缺乏足够的细节来在操作级别检测异常，经常错误地将整个操作序列标记为异常，即使大多数操作可能是正常的。另一方面，一些异常行为往往与正常活动相似，这使得现有的检测方法难以识别它们。本文介绍了一种使用DistilBERT模型的两层SQL异常检测方法，该方法结合了无监督和监督机器学习技术，以准确地识别异常活动，而对数据标注的需求较低。", "innovation": "该方法结合了无监督和监督机器学习技术，使用预训练的DistilBERT模型，针对SQL进行两层的异常检测。无监督方法使用集成异常检测器标记相对于学习到的典型用户行为的数据库范围外的查询的异常嵌入向量。监督方法采用微调的变压器模型，通过角色标注分类来检测内部攻击，即使是在标注数据有限的情况下也有较高的准确度。这种方法提供了针对复杂威胁保护关键数据库系统的有效解决方案。", "conclusion": "该研究提出的方法通过结合无监督和监督学习技术，利用DistilBERT模型，为SQL行为基于的数据库入侵检测提供了有效的方法，特别是在操作级别检测异常方面表现出色，且对数据标注的需求较低。这一方法对于提升数据库安全性具有重要的实际应用价值。"}
{"llm_update_time": "20250815", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2508.10059", "html_url": "https://arxiv.org/abs/2508.10059", "title": "FormalGrad: 将形式方法与基于梯度的LLM精炼集成", "title_en": "FormalGrad: Integrating Formal Methods with Gradient-Based LLM Refinement", "authors": "Yueke Zhang,Yifan Zhang,Kevin Leach,Yu Huang", "background": "尽管大型语言模型（LLMs）在代码生成方面展现出了显著的能力，但在严格约束领域，它们生成的解决方案往往缺乏正确性、健壮性和效率的保证。在需要严格约束的领域中，这一局限尤为明显。FormalGrad 介绍了一种规范性框架，该框架将形式方法直接集成到基于迭代的LLM生成循环中，将结构化反馈和形式约束转换为文本伪梯度，通过这种梯度指导模型逐步优化解决方案，确保不仅功能完善，而且健壮且形式上合理。", "innovation": "FormalGrad 通过将形式方法集成到基于迭代的LLM生成循环中，将其独特地处理代码作为可微变量，并将结构化反馈与形式约束转化为文本伪梯度。这种梯度引导模型逐步优化解决方案，确保生成的代码不仅功能完善，而且健壯且具备形式上的合理性。与强大的基线模型相比，FormalGrad 在 HumanEval、HumanEval+ 和 LiveCodeBench 游标卡尺基准测试中表现出色，绝对改进幅度高达 27%（HumanEval），相对改进幅度高达 41%（LiveCodeBench V6）。", "conclusion": "FormalGrad 生成了形式上可靠的、健壮且高效的代码，为高风险应用中的可信赖的人工智能辅助软件开发铺平了道路。"}
{"llm_update_time": "20250815", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2508.10068", "html_url": "https://arxiv.org/abs/2508.10068", "title": "SaraCoder: 调用语义和结构线索实现利润导向的代码仓库级补全", "title_en": "SaraCoder: Orchestrating Semantic and Structural Cues for Profit-Oriented Repository-Level Code Completion", "authors": "Xiaohan Chen,Zhongying Pan,Quan Feng,Yu Tian,Shuqun Yang,Mengru Wang,Lina Gong,Yuxia Geng,Piji Li,Xiang Chen", "background": "目前代码补全技术主要依赖表层文本相似性，导致结果存在语义误导、冗余和同质性的问题。此外，外部符号的歧义也没有得到有效解决。基于此，现有方法有待改进以提供更准确和鲁棒的代码仓库级补全系统。", "innovation": "Saracoder 通过引入分层特征优化检索框架，系统性地改进候选代码。其核心模块通过提炼深层语义关系、过滤精确重复项、采用基于图的新型结构相似性度量并考虑拓扑重要性以及重新排序结果来最大化相关性和多样性。此外，外部感知的标识符消歧模块通过依赖分析准确解决跨文件符号的歧义问题。实验结果显示，Saracoder 在多种编程语言和模型的挑战基准上显著优于现有基线方法。", "conclusion": "我们的研究证明，从多个维度系统地改进检索结果为构建更准确和 robust 的代码仓库级补全系统提供了一个新的范式。"}
{"llm_update_time": "20250815", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2508.10157", "html_url": "https://arxiv.org/abs/2508.10157", "title": "关于Hugging Face预训练语言模型与其上游GitHub仓库之间的同步", "title_en": "On the synchronization between Hugging Face pre-trained language models and their upstream GitHub repository", "authors": "Ajibode Adekunle,Abdul Ali Bangash,Bram Adams,Ahmed E. Hassan", "background": "预训练语言模型（PTLMs）已推动自然语言处理（NLP）的进步，特别是在文本生成和翻译等任务中取得进展。这些模型通常在GitHub（GH）等上游仓库中通过代码和环境脚本进行训练，并通过Hugging Face（HF）等下游平台以变体的形式进行分发。然而，在GH和HF之间的协调开发带来了挑战，例如不协调的发布时间线、版本管理不一致以及PTLM变体的有限重用。文章作者进行了一项关于325个PTLM家族（共904个HF变体）的混合方法研究，以了解提交活动的协调情况。", "innovation": "研究揭示了GH贡献者和HF贡献者在提交活动方面的不同关注点和行为。通过分析，作者提出了延迟、同步类型和强度三个维度，定义了八种不同的同步模式，尤其是部分同步模式（例如分散同步和稀疏同步），揭示了当前跨平台发布做法中的结构性断层。这些模式导致了孤立的变化，即一种平台上的改进或修复从未在另一个平台中得到复制，有时甚至表明了对一个仓库的放弃。", "conclusion": "研究发现了PTLM发布工作流程中存在的碎片化问题，这些问题可能导致最终用户接触到不完整、过时或行为上不一致的模型。因此，识别这些同步模式对于提高PTLM发布工作流程的监控和可追溯性至关重要。"}
{"llm_update_time": "20250815", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2508.10517", "html_url": "https://arxiv.org/abs/2508.10517", "title": "智能合约编译错误解决：增强型LLM方法跨越Solidity演进差距", "title_en": "Bridging Solidity Evolution Gaps: An LLM-Enhanced Approach for Smart Contract Compilation Error Resolution", "authors": "Likai Ye,Mengliang Li,Dehai Zhao,Jiamou Sun,Xiaoxue Ren", "background": "Solidity已经成为以太坊上最主要的智能合约编程语言，但频繁版本更新带来的安全、功能和开发者体验的提升也带来了诸如编译错误、代码迁移和维护等方面的挑战。", "innovation": "本文系统评估了大规模语言模型（LLMs）在版本迁移期间解决Solidity编译错误的能力，并引入了SMCFIXER框架，该框架将专家知识检索与基于LLM的修复机制系统集成，以解决Solidity编译错误，实现了在基准模型GPT-4o上24.24%的显著改进和接近完美的96.97%准确率。", "conclusion": "研究表明，尽管LLMs在错误修复方面表现出色，但它们在解决语义级别问题时效果较差，且高度依赖于提示工程技术。因此提出了SMCFIXER框架，通过引入上下文感知的代码切片、专家知识检索和迭代修复生成三个核心阶段来系统解决Solidity编译错误。"}
{"llm_update_time": "20250815", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2508.09991", "html_url": "https://arxiv.org/abs/2508.09991", "title": "从BC癌症登记处引进现代NLP技术的经验与教训：AI创新与医疗需求的桥梁", "title_en": "Bridging AI Innovation and Healthcare Needs: Lessons Learned from Incorporating Modern NLP at The BC Cancer Registry", "authors": "Lovedeep Gondara,Gregory Arbour,Raymond Ng,Jonathan Simkin,Shebnum Devji", "background": "自动化从临床文件中提取数据在医疗卫生环境中具有显著提高效率的潜力，但部署自然语言处理(NLP)解决方案面临实际挑战。本文基于在不列颠哥伦比亚癌症登记处(BCCR)实施各种NLP模型进行信息提取和分类任务的经验，分享了项目生命周期中的关键经验教训。", "innovation": "强调根据清晰的商业目标而非单纯的技术准确性定义问题的重要性，采用迭代开发方法，以及从项目开始就促进跨学科合作和设计，包括领域专家、终端用户和机器学习专家的深度合作。", "conclusion": "对于希望成功实施AI/NLP解决方案以改进数据管理流程并最终改善患者护理和公共卫生结果的医疗卫生组织，提供了实用的指导。"}
{"llm_update_time": "20250815", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2508.10852", "html_url": "https://arxiv.org/abs/2508.10852", "title": "EVOSCAT：探索大规模历史数据中的软件变更动态", "title_en": "EVOSCAT: Exploring Software Change Dynamics in Large-Scale Historical Datasets", "authors": "Souhaila Serbout,Diana Carolina Muñoz Hurtado,Hassan Atwi,Edoardo Riggio,Cesare Pautasso", "background": "长期存在的软件项目包含大量的代码和相关组件，这些代码和组件会经历多次更改。研究这些变更的研究人员通常需要处理包含数百万事件的大规模数据集，这些事件代表了特定代码组件的变更。本文背景在于已有方法在处理大规模历史数据集时面临的挑战，尤其是可视化这些数据集时的效率和互动性问题。", "innovation": "本文介绍了一款名为EvoScat的工具，它可以使用交互式密度散点图来提供一个单一视觉化的全局视图，用于大规模历史数据集，这些数据集是从开源代码库中挖掘出来的。EvoScat旨在帮助研究人员开发可扩展的可视化工具，以便探索和描述变更数据集，同时比较单个组件的历史变化，观察各个组件在长期跨度内的老化程度，以及与每个组件相关的指标如何改善或恶化。此外，该工具支持灵活的时间轴对齐、组件排序和交互式色彩映射，使得分析数百万事件成为可能，这些事件来自数万个软件组件的历史记录中。", "conclusion": "本文展示了EvoScat工具如何通过定制可视化需求（如变化速率比较、克隆检测和新鲜度评估）来适应特定的分析需求。文章还提供了一个数据集集锦，展示了特定组件（如OpenAPI描述、GitHub工作流定义）在多个仓库中的集合，以及特定开源项目的详细历史记录。"}
{"llm_update_time": "20250815", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2508.10074", "html_url": "https://arxiv.org/abs/2508.10074", "title": "Next Edit Prediction: 从上下文和交互记录学习预测代码编辑", "title_en": "Next Edit Prediction: Learning to Predict Code Edits from Context and Interaction History", "authors": "Ruofan Lu,Yintong Huo,Meng Zhang,Yichen Li,Michael R. Lyu", "background": "大规模语言模型的快速发展导致了AI编程助手在开发环境中的广泛应用。传统的代码补全依赖于低延迟提供补全建议，但限制于光标当前的位置。聊天编辑能够执行复杂的修改，但需要开发者中断当前工作说明意图，导致上下文切换，都不主动预测开发者接下来的一系列相关编辑。因此，为了解决这一问题，本文引入了“下一个编辑预测”任务，该任务旨在从近期互动历史中推断开发者的意图，以预测后续编辑的位置和内容。为实现这一目标，作者构建了一个高质量的监督微调数据集和评估基准。", "innovation": "本文通过引入“下一个编辑预测”任务，旨在从最近的互动记录中推断开发者的意图，以预测后续编辑的位置和内容。作者构建了一个高质量的监督微调数据集和评估基准，并对一系列模型进行了监督微调，对比了多种基线模型，提出了几个新颖的发现。这为开发一个新的主动协作交互模式铺平了道路，该模式能够预判开发者的后续操作，而不仅仅是对明确指令的回应，从而提供无缝的代码编辑建议。", "conclusion": "本文通过构建高质量数据集和评估基准，展示了如何通过预测开发者意图来提高代码编辑的用户体验。这为未来的开发环境提供了新的交互模式，并为相关研究和应用奠定了基础。"}
{"llm_update_time": "20250815", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2508.10111", "html_url": "https://arxiv.org/abs/2508.10111", "title": "使用上下文自由文法的扩散LLM约束解码", "title_en": "Constrained Decoding of Diffusion LLMs with Context-Free Grammars", "authors": "Niels Mündler,Jasper Dekoninck,Martin Vechev", "background": "大型语言模型（LLMs）在各个领域展示了具有前景的表现。许多LLM的实际应用，如代码补全和结构化数据提取，需要遵循由正式语言指定的句法约束。然而，由于其概率性质，LLM的输出无法保证符合这些正式语言。现有工作提出了解码约束作为一种方式来限制LLM生成到特定的正式语言中。但是，现有的工作不适用于扩散LLMs，尤其是在生成正确形式的C++或JSON输出的实际场景中。本文解决了这一挑战，提出了使用上下文自自由文法的第一个解码约束方法。", "innovation": "本文解决了在使用扩散模型生成正确形式的代码或JSON输出的实际场景中解码约束的方法挑战。首先将约束解码转化为一个更一般的加性填充问题，然后将这个问题转化为决定目标语言与正规语言的交集是否为空的问题，并提供了一个高效的算法来解决这个问题。对于上下文自自由文法而言，该方法在各种应用中实现了接近完美的句法正确性，同时保持或改善了功能正确性。重要的是，本文的效率优化确保计算开销是实际可行的。", "conclusion": "实验证明，本文的方法在各种应用，如C++代码填充和JSON中的结构化数据提取，中接近完美地实现了语法正确性，同时保持或改善了功能正确性，而计算开销保持在可行范围内。"}
{"llm_update_time": "20250815", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2508.10497", "html_url": "https://arxiv.org/abs/2508.10497", "title": "使用面向对象编程实现通用机器人技能", "title_en": "Enabling Generic Robot Skill Implementation Using Object Oriented Programming", "authors": "Abdullah Farrukh,Achim Wagner,Martin Ruskowski", "background": "在小企业和中型企业（SMEs）中，由于缺乏机器人专业知识，构建、维护和发展机器人系统存在挑战。许多公司依赖外部专家（系统集成商），这可能导致供应商锁定和外部依赖。在智能制造系统的学术研究中，机器人在设计健壮的自主系统中发挥着关键作用。研究人员希望将机器人系统作为更大智能系统组件使用时也面临相同挑战，无需深入了解机器人接口的复杂性和广泛性。", "innovation": "提出了一种软件框架，旨在减少部署工作机器人系统的努力，该框架专注于简化现代机器人系统的不同接口，并使用不同的制造商和型号的抽象层。通过使用Python编程语言实现该概念原型。", "conclusion": "该论文的目标机器人系统是一个包含Yaskawa Motoman GP4的取件单元，旨在通过提供一个利于简化现代机器人系统不同接口的概念和使用不同的制造商和型号的抽象层来降低部署工作机器人系统所需的努力。"}
{"llm_update_time": "20250815", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2302.11617", "html_url": "https://arxiv.org/abs/2302.11617", "title": "Cloud Native Applications 治理的参考架构", "title_en": "A Reference Architecture for Governance of Cloud Native Applications", "authors": "William Pourmajidi,Lei Zhang,John Steinbacher,Tony Erwin,Andriy Miranskyy", "background": "云计算的发展催生了云原生应用（CNAs），这些应用在治理方面带来了新的挑战，尤其是在面对严格的合规要求时。本文探讨了CNAs的独特特性和它们对治理带来的影响。", "innovation": "提出了一种全面的参考架构，旨在简化CNAs的治理流程，并提供适用于单云和多云环境的样本实现。该架构通过内置治理理念与CNA框架无缝集成，针对多种行业中的扩张性和紧凑性部署进行优化，减少治理相关复杂性，协助云从业者优化产品开发。", "conclusion": "这种设计不仅为云从业者在治理方面提供了简便方法，还为学术界提供了研究通用CNA框架的基础，强调了这些框架在不断发展中的云计算环境中的重要性。"}
{"llm_update_time": "20250815", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2508.10017", "html_url": "https://arxiv.org/abs/2508.10017", "title": "在使用SMOTETomek和FedProx进行差分隐私联邦学习的不平衡临床数据稳健流水线", "title_en": "A Robust Pipeline for Differentially Private Federated Learning on Imbalanced Clinical Data using SMOTETomek and FedProx", "authors": "Rodrigo Tertulino", "background": "联邦学习（FL）为协作健康研究提供了创新的方法，能够在保护患者隐私的同时对分散的数据进行模型训练。当与差分隐私（DP）结合使用时，FL能够提供正式的安全保证。然而，联合技术的实施引入了隐私与临床实用性之间的显著权衡，特别是在医学数据集经常存在的类别失衡问题上。本研究旨在解决这些复杂的问题，通过系统性的多阶段分析，提出了一种针对心脑血管风险预测的FL框架，克服了标准方法在处理类别失衡数据上的局限性。", "innovation": "研究结合了合成少数群体过采样技术与托梅克链接（SMOTETomek）和调优的FedProx算法，优化了不平衡临床数据的联邦学习框架。具体创新包括：首先，在客户端级别集成SMOTETomek增强模型的临床实用性；其次，针对非独立同分布（non-IID）数据优化联邦学习算法；最终揭示了隐私预算（ε）与模型召回率之间的非线性权衡，并确定了在隐私-实用性前线上的优化操作区域。", "conclusion": "研究证实了优化后的FedProx在保护隐私的同时可以显著提高召回率，且在ε为9.0时能够实现较高的临床实用性（召回率大于77%），从而提供了一种实用的方法框架，用于创建有效的、安全的、准确的诊断工具，适用于现实世界中的异质医疗数据。"}
{"llm_update_time": "20250815", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2504.08329", "html_url": "https://arxiv.org/abs/2504.08329", "title": "MedRep: 医疗概念表示用于通用电子健康记录基础模型", "title_en": "MedRep: Medical Concept Representation for General Electronic Health Record Foundation Models", "authors": "Junmo Kim,Namkyeong Lee,Jiwon Kim,Kwangsoo Kim", "background": "电子健康记录(EHR)基础模型已经在各种医学任务中表现出改进的性能，但仍然存在一个基本限制：无法处理不在词汇表中的未知医疗代码。这一限制限制了EHR基础模型的泛化能力和使用不同词汇表训练的模型的集成。", "innovation": "我们提出了基于OMOP通用数据模型(OMOP CDM)的新型医疗概念表示(MedRep)。通过大语言模型(LLM)提示丰富每个概念的信息，并通过OMOP词汇表的图本体补充基于文本的概念表示。我们的方法在多种预测任务中优于基础EHR模型和先前引入的医疗代码分词器模型。", "conclusion": "MedRep展示了良好的泛化能力并通过外部验证进行了演示。"}
{"llm_update_time": "20250815", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2502.10374", "html_url": "https://arxiv.org/abs/2502.10374", "title": "生物医学基础模型的健壮性测试应根据规范进行定制", "title_en": "Robustness tests for biomedical foundation models should tailor to specifications", "authors": "R. Patrick Xian,Noah R. Baker,Tom David,Qiming Cui,A. Jay Holmgren,Stefan Bauer,Madhumita Sushil,Reza Abbasi-Asl", "background": "生物医学基础模型因其广泛的能力和对复杂分布变化的敏感性，在模型测试和授权方面带来了新的挑战。", "innovation": "提出根据任务依赖优先级定制健壮性测试，并在预先定义的规范中集成颗粒状的健壮性概念，以指导实施。这种做法有助于在模型生命周期中标准化健壮性评估，并将抽象的人工智能监管框架与具体的测试程序相连接。", "conclusion": "我们的方法促进了模型生命周期中健壮性评估标准的制定，并将抽象的AI监管框架与具体的测试程序联系起来。"}
{"llm_update_time": "20250815", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2408.07321", "html_url": "https://arxiv.org/abs/2408.07321", "title": "VERCATION：基于静态分析和大语言模型的精确开源软件漏洞版本识别", "title_en": "VERCATION: Precise Vulnerable Open-source Software Version Identification based on Static Analysis and LLM", "authors": "Yiran Cheng,Ting Zhang,Lwin Khin Shar,Shouguo Yang,Chaopeng Dong,David Lo,Shichao Lv,Zhiqiang Shi,Limin Sun", "background": "开源软件（OSS）因协作开发模式和成本效益而越来越受欢迎。然而，开发项目中特定软件版本的采用可能会引入安全风险，特别是在这些版本包含漏洞的情况下。当前的方法通过静态分析和预定义规则提取与漏洞相关的代码特征来识别易受攻击的版本，接着使用代码克隆检测来识别这些版本。这些方法由于（1）分析中排除了与漏洞无关的代码以及（2）代码克隆检测的不充分性而受到限制。", "innovation": "本文提出VERCATION方法，这是一种识别C/C++编写的开源软件易受攻击版本的方法。VERCATION结合程序切片和大语言模型（LLM），从漏洞补丁中识别出与漏洞相关的代码，然后追溯历史提交以收集被识别出的漏洞相关代码的先前修改。我们提出基于扩展和规范化抽象语法树（AST）的代码克隆检测方法，以比较修改前后的代码差异，从而定位引入漏洞的提交（vic），并识别出漏洞补丁提交和vic之间的易受攻击版本。", "conclusion": "我们使用包括122个开源软件漏洞和1,211个版本的数据集评估VERCATION的性能，我们的方法获得了93.1%的F1分数，优于现有最先进的方法。更重要的是，VERCATION检测到了NVD报告中的202个错误的开源软件易受攻击版本。"}
{"llm_update_time": "20250815", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2401.16382", "html_url": "https://arxiv.org/abs/2401.16382", "title": "基于MAPE-K的方法在自适应系统中进行架构一致性检查", "title_en": "A MAPE-K-Based Method for Architectural Conformance Checking in Self-Adaptive Systems", "authors": "Daniel San Martín,Guisella Angulo,Valter Vieira de Camargo", "background": "自适应系统（SASs）日益广泛地应用于关键领域，如医疗保健、金融、自动驾驶车辆和智慧城市。确保这些系统的架构可信度对于维持系统的稳定性及质量属性至关重要。由于SAS架构固有复杂，MAPE-K等参考模型被提议以指导其设计，强调反馈循环作为核心组件。然而，维护活动常导致架构侵蚀，系统偏离参考模型，使得架构不合规。架构一致性检查（ACC）解决了这个问题，通过验证系统的实现是否与计划架构（PA）或MAPE-K等参考模型保持一致。", "innovation": "提出了一种专门用于SASs的架构一致性检查方法——REMEDY。REMEDY由三个关键组件组成：(i) 基于MAPE-K抽象的领域特定语言（DSL）用于指定计划架构；(ii) 用于恢复系统当前架构的工具；(iii) 一个能够检测和可视化架构偏差的合规性检查过程。REMEDY还展示了与其进行比较的通用DSL相比，SAS特定DSL在架构规范方面的更高生产力和精度。此外，REMEDY有效地识别并促进了不合规问题的纠正，从而提高了自适应系统的维护性和架构可信度。", "conclusion": "通过比较特定领域语言（DSL）和通用DSL，REMEDY展示了更高的生产力和精确性，并有效识别并解决不合规问题，从而提高了自适应系统的维护性和架构可信度。"}
{"llm_update_time": "20250815", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2507.06762", "html_url": "https://arxiv.org/abs/2507.06762", "title": "使用大语言模型生成测试检测语义冲突", "title_en": "Detecção de Conflitos Semânticos com Testes Gerados por LLM", "authors": "Nathalia Barbosa(1),Paulo Borba(1),Léuson Da Silva(2) ((1) Centro de Informática, Universidade Federal de Pernambuco, Brasil, (2) Polytechnique Montreal, Canadá)", "background": "语义冲突是指开发者对代码库进行更改时，无意中影响了其他开发者并行集成更改的行为。传统的合并工具无法检测这种冲突，因此需要额外的工具如SMAT。SMAT依赖于生成和执行单元测试：如果在基于版本的测试失败，在开发者的修改版本中通过但合并其他开发者的更改后再次失败，说明存在语义冲突。尽管SMAT检测冲突非常有效，但由于单元测试生成工具如Randoop和Evosuite的局限性，它的误报率较高。为了探索大语言模型（LLMs）是否能克服这些局限性，我们提出并整合了一个基于Code Llama 70B的新测试生成工具，将其集成到SMAT中。我们的评估使用了两个样本，一个基准样本来自相关工作中的简单系统，一个基于复杂的真实系统的重要样本。我们评估新SMAT扩展在检测冲突方面的效果。", "innovation": "我们将一个基于大语言模型（Code Llama 70B）的新测试生成工具整合到SMAT中，以提高语义冲突检测的准确性。通过不同的交互策略、提示内容和参数配置，评估了模型的测试生成能力。使用了两个样本进行评估，一个来自相关工作的简单系统基准样本，另一个基于复杂真实系统的重要样本。", "conclusion": "尽管基于大语言模型的测试生成在复杂场景下仍然具有挑战性和计算成本高昂，但在提高语义冲突检测准确性方面仍具有潜在的改进空间。"}
{"llm_update_time": "20250815", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2505.11528", "html_url": "https://arxiv.org/abs/2505.11528", "title": "LaDi-WM: 基于潜在扩散的世界模型及其在预测性操纵中的应用", "title_en": "LaDi-WM: A Latent Diffusion-based World Model for Predictive Manipulation", "authors": "Yuhang Huang,Jiazhao Zhang,Shilong Zou,Xinwang Liu,Ruizhen Hu,Kai Xu", "background": "在体态人工智能（Embodied AI）领域，预测性操控（Predictive manipulation）引起了广泛关注，因为它有望通过利用预测状态来提升机器人策略性能。然而，从世界模型生成准确的未来视觉状态（特别是实现高质量像素级表示）仍然是一个挑战。", "innovation": "提出了一种基于潜在扩散（latent diffusion）的世界模型LaDi-WM。LaDi-WM 利用预先训练的视觉基础模型（VFMs）中的几何特征（DINO）和语义特征（CLIP）的潜在空间进行未来状态的预测。实验表明，预测潜在空间的演变比直接预测像素级图像更易于学习和更加泛化。", "conclusion": "LaDi-WM 在 LIBERO-LONG 标准基准上显著提升了策略性能达 27.9%，在真实世界场景中则提高了 20%。此外，该世界模型和策略在真实世界实验中表现出色，具有出色的泛化性。"}
{"llm_update_time": "20250815", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2507.10535", "html_url": "https://arxiv.org/abs/2507.10535", "title": "CodeJudgeBench: 评估语言模型作为裁判的编码任务基准", "title_en": "CodeJudgeBench: Benchmarking LLM-as-a-Judge for Coding Tasks", "authors": "Hongchao Jiang,Yiming Chen,Yushi Cao,Hung-yi Lee,Robby T. Tan", "background": "大型语言模型（LLMs）在各种编码任务中取得了显著的进步。除了直接回答用户查询外，LLMs 还可以作为裁判，评估和比较其他模型生成的响应的质量。这种评估能力对于不同LLMs的基准测试和通过响应排名来提高响应质量都至关重要。尽管LLM作为裁判的模式正在被广泛采用，但在编码场景中的有效性仍然未被深入研究，因为缺乏专门的基准。本研究通过引入CodeJudgeBench基准，专门为LLM-as-a-Judge模型评估三种关键编码任务（代码生成、代码修复和单元测试生成）的能力提供了专门的测试。", "innovation": "本研究通过CodeJudgeBench基准对26个LLM-as-a-Judge模型进行了全面测试，发现了其中的创新点：（1）近期发展的思考模型显著优于非思考模型；（2）即使是相对较小的思考模型，如Qwen3-8B，也能优于大型的专门训练模型；（3）在成对评估任务中，响应呈现顺序的改变对准确性有显著影响；（4）在评估不同LLM编写的代码和单元测试时，LLM-as-a-Judge模型表现出不同的性能差异；（5）使用成对比较策略优于标量点评策略；（6）保留完整未处理的LLM响应中的注释和推理可以提高裁判性能。", "conclusion": "通过CodeJudgeBench基准测试发现，大型语言模型作为裁判在编码任务中的表现存在显著的随机性，成对评估任务的顺序以及不同模型编写的响应都影响其性能。研究还发现使用成对比较策略和保留完整未处理的响应中的注释和推理是提高裁判性能的有效方法。"}
{"llm_update_time": "20250815", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.08855", "html_url": "https://arxiv.org/abs/2508.08855", "title": "BiasGym: 如何发现和移除大型语言模型中的偏见及其方法", "title_en": "BiasGym: Fantastic LLM Biases and How to Find (and Remove) Them", "authors": "Sekh Mainul Islam,Nadav Borenstein,Siddhesh Milind Pawar,Haeun Yu,Arnav Arora,Isabelle Augenstein", "background": "理解大型语言模型（LLMs）权重中编码的偏见和刻板印象是制定有效缓解策略的关键。偏见行为通常是细微且在故意激发时也不容易被单独隔离，因此系统分析和去偏是一项艰巨的任务。为了应对这一挑战，引入了BiasGym框架，这是一个简单、经济且通用的工具，可以可靠地注入、分析和缓解LLMs中的概念关联偏差", "innovation": "BiasGym框架包括两个组件：BiasInject和BiasScope。BiasInject通过基于token的微调嵌入特定偏见，同时保持模型冻结；BiasScope利用这些嵌入信号来识别并引导导致偏见行为的组件。该方法允许一致地提取偏见进行机制分析，支持针对性地去偏而不影响下游任务的性能，并且可以应用于在嵌入微调过程中未见过的偏见", "conclusion": "BiasGym在减少实际世界刻板印象（例如，意大利人是“鲁莽的司机”）和探索虚构关联（例如，一个虚构国家的人有“蓝色皮肤”）方面显示出有效性和实用性，表明其对安全干预措施和可解释性研究都有用处"}
{"llm_update_time": "20250815", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2507.21817", "html_url": "https://arxiv.org/abs/2507.21817", "title": "超出分布范围就等于倒霉：漏洞数据集训练的LLM模型如何检测Top 25 CWE弱点？", "title_en": "Out of Distribution, Out of Luck: How Well Can LLMs Trained on Vulnerability Datasets Detect Top 25 CWE Weaknesses?", "authors": "Yikun Li,Ngoc Tan Bui,Ting Zhang,Martin Weyssow,Chengran Yang,Xin Zhou,Jinfeng Jiang,Junkai Chen,Huihui Huang,Huu Hung Nguyen,Chiok Yew Ho,Jie Tan,Ruiyin Li,Yide Yin,Han Wei Ang,Frank Liauw,Eng Lieh Ouh,Lwin Khin Shar,David Lo", "background": "尽管自动化漏洞检测取得了一定进展，但其实用性仍然有限。目前的漏洞数据集存在标签不准确率高达20%-71%、严重重复和关键CWE类型覆盖不足等问题，这些问题导致模型在自我测试时表现出虚假的性能水平，而非真正学习漏洞模式。研究发现，在独立数据上评估时，许多模型会出现高达33%的性能下降，有些模型接近随机猜测。这表明模型存在显著的泛化差距。", "innovation": "本文提出了一种三阶段解决方案：第一，引入了人工整理的测试数据集BenchVul，涵盖了MITRE Top 25最危险的CWE；第二，构建了一个高质量的训练数据集TitanVul，包含38,863个函数，通过整合公共源并使用新颖的多智能体LLM框架进行去重和验证；第三，提出了一个现实漏洞生成（RVG）框架，通过模拟开发工作流生成上下文相关漏洞示例，以涵盖代表性不足但至关重要的CWE类型。实验表明，每个组件都有助于缩小泛化差距。", "conclusion": "首先，BenchVul揭示了自我测试的局限性：基于现有数据集（如BigVul和CVEfixes）训练的模型在BenchVul上的性能从0.776下降到0.519，从0.713下降到0.607。其次，使用TitanVul训练模型展示了更好泛化的表现，模型性能从在相同数据集上评估的0.584提高到在BenchVul上测试的0.767。最后，将RVG生成的数据补充到TitanVul中进一步提高模型性能，使其由0.874增加到14.0%以上。"}
