{"llm_update_time": "20260113", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2601.05298", "html_url": "https://arxiv.org/abs/2601.05298", "title": "数据知识图谱驱动的基于方程的可预测和可靠的增材制造框架", "title_en": "Mathematical Knowledge Graph-Driven Framework for Equation-Based Predictive and Reliable Additive Manufacturing", "authors": "Yeongbin Cha,Namjung Kim", "background": "增材制造（AM）依赖于对工艺-性能关系的理解和外推。现有的数据驱动方法受到知识表示碎片化和数据稀疏条件下不可靠外推的限制。", "innovation": "提出了一种基于本体指导、以方程为中心的框架，结合大型语言模型（LLMs）和增材制造数学知识图（AM-MKG），以实现可靠的知识提取和有原则的外推建模。通过明确编码方程、变量、假设及其语义关系，非结构化文献被转化为可机器解释的表示，以支持结构化查询和推理论证。LMM基于MKG衍生子图的方程生成进一步受约束，确保物理意义上的功能形式并减轻非物理或不稳定的外推趋势。引入了基于置信度的外推评估，将外推距离、统计稳定性与知识图基于的物理一致性综合到统一的信心分数中。", "conclusion": "本体引导提取显著提高了提取知识的结构连贯性和定量可靠性，而子图条件下的方程生成与未经本体引导的LMM输出相比，提供了稳定且物理一致的外推。这项工作建立了一个统一的管道，实现了本体导向的知识表示、以方程为中心的推理及基于置信度的外推评估，突显了知识图谱增强的LMM作为增材制造中可靠外推建模工具的潜力。"}
{"llm_update_time": "20260113", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2601.05256", "html_url": "https://arxiv.org/abs/2601.05256", "title": "Naiad: 新型自主智能代理系统用于内陆水体监测", "title_en": "Naiad: Novel Agentic Intelligent Autonomous System for Inland Water Monitoring", "authors": "Eirini Baltzi,Tilemachos Moumouris,Athena Psalta,Vasileios Tsironis,Konstantinos Karantzalos", "background": "内陆水体监测对于保护公共健康和生态系统至关重要，能够实现及时干预以减轻风险。现有的方法通常分别处理孤立的子问题，如蓝藻、叶绿素或其他质量指标。NAIAD（溺死者）提出了一种自主的AI助手，利用大型语言模型（LLMs）和外部分析工具，结合地球观测（EO）数据提供全方位的解决方案。该系统设计用于专家和非专家，提供一个单一提示界面，将自然语言查询转化为可操作的见解。", "innovation": "NAIAD引入了一种解决方案，不仅利用大型语言模型（LLMs）和外部分析工具，还利用检索增强生成（RAG）、外部工具调度、计算图执行和代理反思来从精心整理的来源中检索和综合知识，生成定制报告。系统结合了多种工具，包括天气数据、Sentinel-2图像、遥感指数计算（如NDCI）、叶绿素-a估算以及现有的平台如CyFi。该系统通过准确性和相关性指标进行了性能评估，达到了77%以上的准确性和85%的相关性。", "conclusion": "初步结果表明，该系统在各种查询类型下具有较强的适应性和鲁棒性。进一步的实验表明，Gemma 3（27B）和Qwen 2.5（14B）在计算效率和推理性能之间提供了最佳平衡。"}
{"llm_update_time": "20260113", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2601.05465", "html_url": "https://arxiv.org/abs/2601.05465", "title": "PRISMA：多智能体架构中基于强化学习的两阶段策略优化方法用于开放式域多跳问答", "title_en": "PRISMA: Reinforcement Learning Guided Two-Stage Policy Optimization in Multi-Agent Architecture for Open-Domain Multi-Hop Question Answering", "authors": "Yu Liu,Wenxiao Zhang,Cong Cao,Wenxuan Lu,Fangfang Yuan,Diandian Guo,Kun Peng,Qiang Sun,Kaiyan Zhang,Yanbing Liu,Jin B.Hong,Bowen Zhou,Zhiyuan Ma", "background": "在检索增强生成（RAG）系统中，回答大规模语料库中的现实世界开放式领域多跳问题是关键挑战。近期研究采用强化学习（RL）来端到端优化检索增强推理过程，增强其解决复杂查询的能力。然而，可靠部署受到两项障碍的阻碍：1）检索崩溃。反复检索大规模语料库不能在无推理指导规划的情况下找到包含连接答案的中间证据，导致下游推理崩溃。2）学习不稳定性。端到端轨迹训练由于推理链上的弱信用分配和模块之间的错误定位不准确，导致对基准特定的启发式算法的过度拟合，限制了转移性和稳定性。", "innovation": "我们提出了PRISMA，一个脱耦的RL引导框架，具有计划-检索-检查-解决-记忆架构。PRISMA的强项在于基于推理的合作：检查器提供了基于推理的反馈以改进计划者的分解和细粒度检索，并确保求解器中的证据为基础的推理。我们通过两阶段组相对策略优化（GRPO）优化每个代理的能力。第一阶段校准计划员和求解器作为规划和推理的专门专家，第二阶段利用观察感知残差策略优化（OARPO）提高检查器验证上下文并触发目标恢复的能力。实验表明，PRISMA在十个基准上的表现达到了最先进的水平，并且可以在现实场景中有效部署。", "conclusion": "PRISMA实现了在多智能体架构中基于强化学习的两阶段策略优化方法，显著提升了开放式领域多跳问答的性能和稳定性，在多个基准上达到了最先进的水平，并且在实际应用中具有高效部署的潜力。"}
{"llm_update_time": "20260113", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2601.05483", "html_url": "https://arxiv.org/abs/2601.05483", "title": "MMUEChange：一种通用的LLM代理框架，用于智能多模态城市环境变化分析", "title_en": "MMUEChange: A Generalized LLM Agent Framework for Intelligent Multi-Modal Urban Environment Change Analysis", "authors": "Zixuan Xiao,Jun Ma,Siwei Zhang", "background": "理解城市环境变化对于可持续发展至关重要。然而，目前的方法，尤其是基于遥感的变化检测，往往依赖于僵化的单一模态分析。", "innovation": "我们提出了一种多模态代理框架MMUEChange，该框架通过模块化工具包和核心模块——跨模态和跨模态对齐的模态控制器，灵活地整合了异构的城市数据，从而能够稳健地分析复杂的城市变化场景。", "conclusion": "通过对纽约、香港、深圳的案例研究，MMUEChange在任务成功率上比最佳基线提高了46.7%，有效减少了幻觉，并展示了其支持复杂城市环境变化分析任务的实际政策含义的能力。"}
{"llm_update_time": "20260113", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2601.05455", "html_url": "https://arxiv.org/abs/2601.05455", "title": "ART: 自适应推理树用于可解释性声明验证", "title_en": "ART: Adaptive Reasoning Trees for Explainable Claim Verification", "authors": "Sahil Wadhwa,Himanshu Kumar,Guanqun Yang,Abbaas Alif Mohamed Nishar,Pranab Mohanty,Swapnil Shinde,Yue Wu", "background": "大型语言模型（LLMs）在复杂决策中显示出强大的潜力，凭借其丰富的编码知识和出色的零样本能力。然而，由于它们的透明度不足，即输出缺乏可信的解释，使得很难纠正错误，这些模型在高风险环境中的采用受到阻碍。因此，迫切需要一种能够提供透明和可争议判决的方法。本文背景正是基于这一点，旨在改进现有的零样本方法，如链式思考（CoT），以提升声明验证的可解释性和有效性。", "innovation": "本文提出了自适应推理树（ART）方法，这是一种分层验证声明的方法，包括分层设计的主张和对抗性生成的子论证。它引入了一个‘裁判’语言模型来评定子论证的胜出情况，从而实现系统的、透明的和可争议的验证过程。这种方法被实验证明优于现有的基准方法，为可解释性声明验证设立了一个新的基准，确保了整个决策过程的清晰可信。", "conclusion": "通过ART方法，本文在多个数据集上进行了实证研究，证明了其结构化推理优于现有强基线。该研究确立了新的可解释声明验证基准，提高了决策的整体可靠性和清晰度。"}
{"llm_update_time": "20260113", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2601.05376", "html_url": "https://arxiv.org/abs/2601.05376", "title": "《特性悖论：临床语言模型中的医学特性作为行为先验》", "title_en": "The Persona Paradox: Medical Personas as Behavioral Priors in Clinical Language Models", "authors": "Tassallah Abdullahi,Shrestha Ghosh,Hamish S Fraser,Daniel León Tramontini,Adeel Abbasi,Ghada Bourjeily,Carsten Eickhoff,Ritambhara Singh", "background": "特性可以被视为大型语言模型（LLMs）的行为先验，并常被认为是提高专业性和安全性的工具。然而，这些特性在高风险临床决策中的影响尚未得到充分研究。本研究系统地评估了临床语言模型中基于特性的控制策略，考察了专业角色（如急诊医生、护士）和互动风格（大胆 VS. 谨慎）如何影响不同模型和医疗任务的表现。", "innovation": "本研究创新点在于系统地评估了临床语言模型中基于特性的控制策略，特别关注了专业角色和互动风格对任务性能的影响。通过多维度评估（包括任务准确性、校准度和安全相关风险行为），研究揭示了基于特性的影响存在上下文相关性和非单调性。", "conclusion": "研究发现，医学特性的表现取决于上下文，高风险医疗任务可以显著提高准确性与校准度，但初级保健中则会削弱性能；互动风格影响风险倾向和敏感度，但高度依赖于具体模型。虽然综合LLM-评委排名倾向于支持医学特性，但临床医师在安全合规方面的判断存在中等一致性和较低的信心。"}
{"llm_update_time": "20260113", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2601.05302", "html_url": "https://arxiv.org/abs/2601.05302", "title": "大型语言模型代理的个性引导对合作行为的影响", "title_en": "Effects of personality steering on cooperative behavior in Large Language Model agents", "authors": "Mizuki Sakai,Mizuki Yokoyama,Wakaba Tateishi,Genki Ichinose", "background": "大型语言模型（LLMs）在战略和社会互动中越来越多地被用作自主代理。尽管近年来研究表明，将个性特质赋予LLMs可以影响其行为，但在控制条件下个性引导如何影响合作仍不清楚。本研究通过重复囚徒困境游戏，使用基于五大人格特质框架，测量三个模型（GPT-3.5-turbo、GPT-4o 和 GPT-5）的基本个性特征，并在基准条件和个性导向条件下进行比较，分析在极端条件下独立改变每个性格维度的影响。", "innovation": "研究采用重复囚徒困境游戏，并基于五大人格特质框架，对不同类别模型的个性特征进行测量和对比分析，尤其关注不同代次模型在特定个性导向下的合作行为差异。", "conclusion": "在所有模型中，宜人性是促进合作的主要因素，而其他个性特质影响有限。明确的人格信息可以增加合作，但也会提高对利用的脆弱性，尤其是在早期代次的模型中。相比之下，后期代次的模型表现出更选择性地合作。这些发现表明，个性引导作用于行为偏见而非确定性控制机制。"}
{"llm_update_time": "20260113", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2601.05386", "html_url": "https://arxiv.org/abs/2601.05386", "title": "关于国际象棋中作弊影响的研究", "title_en": "On the Effect of Cheating in Chess", "authors": "Daniel Keren", "background": "在国际象棋中，使用强大软件的建议进行作弊已成为一个严重的问题，甚至在顶尖水平也是如此。大多数过去的研究所关注的是检测作弊，而不是评价在比赛中有限次数作弊可能获得的性能提升。", "innovation": "本文开发了算法并将其应用于常用的人机对弈软件，以评估在比赛过程中有限次作弊可以获得的性能提升。这种方法与之前大多数侧重于检测作弊的研究不同。", "conclusion": "这项研究对于衡量作弊的效果至关重要，也是阻止和检测作弊努力的一部分。"}
{"llm_update_time": "20260113", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2601.05384", "html_url": "https://arxiv.org/abs/2601.05384", "title": "AI代理中的从众效应和社会影响", "title_en": "Conformity and Social Impact on AI Agents", "authors": "Alessandro Bellina,Giordano De Marzo,David Garcia", "background": "随着AI代理在多代理环境中的广泛应用，理解其群体行为变得至关重要，这对于预测人造社会的动力学具有重要意义。本文通过引入经典的社会心理学视觉实验，研究众多模式语言模型（AI代理）在社会压力下倾向于与其群体意见一致的倾向。", "innovation": "通过将社会心理学的经典视觉实验应用于大型多模态语言模型，本文首次探索了社会影响如何影响这些AI代理的行为。研究表明，即使是实现近乎完美性能的AI代理，在社会影响之下也会表现出高度的从众现象。", "conclusion": "研究揭示了AI代理决策中的根本性安全漏洞，这些漏洞可能导致恶意操纵、误导性信息传播以及偏见传播。尤其是在多代理系统中，这突显了集体AI部署过程中需要迫切的安全保障措施。此外，研究还发现，尽管更大规模的模型在简单任务上表现出较低的从众性，但它们在任务极限处依然容易受到社会影响的影响。"}
{"llm_update_time": "20260113", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2601.05330", "html_url": "https://arxiv.org/abs/2601.05330", "title": "通过增强的知识图嵌入利用化学反应方程改进酶预测", "title_en": "Improving Enzyme Prediction with Chemical Reaction Equations by Hypergraph-Enhanced Knowledge Graph Embeddings", "authors": "Tengwei Song,Long Yin,Zhen Han,Zhiqiang Xu", "background": "长久以来，预测酶-底物相互作用是生物化学和代谢工程中的基本问题。现有的模型依赖于专家编纂的酶-底物对数据库来学习已知的配对相互作用，但这些数据库通常是稀疏的，缺乏足够的训练数据，使得传统模型难以泛化到未见过的相互作用。", "innovation": "提出了一种知识增强的超图模型Hyper-Enz，它通过将超图变换器与知识图嵌入（KGE）模型结合使用，来学习包含多种底物和产物的超边表示。此外，引入了多专家范式来指导预测酶-底物相互作用，该方法利用化学反应方程中的丰富数据，显著提高了酶预测的准确性和对新相互作用的泛化能力。", "conclusion": "实验结果表明，该方法在平均酶检索准确性和配对预测方面分别取得了高达88%和30%的相对改进，证明了此方法的有效性。"}
{"llm_update_time": "20260113", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2601.05699", "html_url": "https://arxiv.org/abs/2601.05699", "title": "Afri-MCQA: Multimodal Cultural Question Answering for African Languages", "title_en": "Afri-MCQA: Multimodal Cultural Question Answering for African Languages", "authors": "Atnafu Lambebo Tonja,Srija Anand,Emilio Villa-Cueva,Israel Abebe Azime,Jesujoba Oluwadara Alabi,Muhidin A. Mohamed,Debela Desalegn Yadeta,Negasi Haile Abadi,Abigail Oppong,Nnaemeka Casmir Obiefuna,Idris Abdulmumin,Naome A Etori,Eric Peter Wairagala,Kanda Patrick Tshinu,Imanigirimbabazi Emmanuel,Gabofetswe Malema,Alham Fikri Aji,David Ifeoluwa Adelani,Thamar Solorio", "background": "非洲拥有世界上超过三分之一的语言，但在人工智能研究中的代表性不足。现有语言模型在非洲文化相关的问答任务上表现不佳，尤其是在使用非洲本土语言或语音形式被查询时，开放型问答的表现几乎为零。模型在语言能力方面也显示出显著的性能差距。", "innovation": "本文提出了Afri-MCQA，这是第一个涵盖12个非洲国家15种非洲语言共计7500个问答对的多语言文化问答基准。基准在文本和语音模态上包含英-非语言平行问答对，并完全由母语者创建。研究结果显示开源权重模型在不同文化上的表现不佳。为了评估语言能力，还纳入了旨在独立于文化知识评估这一特定方面控制实验，发现母语语言和英语在文本和语音上都表现出显著差异。", "conclusion": "这些发现强调了在非洲语言中采用语音优先的方法、文化指导的预训练以及跨语言文化转移的重要性。为了支持非洲语言的包容性多模态人工智能开发，我们免费提供Afri-MCQA基准，可以在学术许可或CC BY-NC 4.0授权下从HuggingFace获取。"}
{"llm_update_time": "20260113", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2601.05707", "html_url": "https://arxiv.org/abs/2601.05707", "title": "低资源语言ASR的多模态上下文学习", "title_en": "Multimodal In-context Learning for ASR of Low-resource Languages", "authors": "Zhaolin Li,Jan Niehues", "background": "自动语音识别（ASR）目前仅覆盖了世界语言的一小部分，主要原因在于缺乏监督数据。虽然上下文学习（ICL）结合了大型语言模型（LLMs）来解决这一问题，但之前的大多数研究仍然集中于训练期间覆盖的高资源语言和单纯的文本设置。本文旨在探索是否可以通过多模态ICL（MICL）让语音LLMs学习未见过的语言，并研究这种学习如何提高ASR的效果。", "innovation": "1. 探索了多模态ICL（MICL）对未见过的语言是否有效，发现可以通过结合语音和文本两种模态的方法进行学习。\n2. 证明了跨语言迁移学习可以提高MICL在目标语言中的效率，而无需在这些目标语言上进行训练。\n3. 通过分析注意力模式来解释MICL机制，观察到不同层级对音频和文本上下文的偏好，总体上偏爱文本。\n4. 提出了一个基于提示的ASR系统，结合了较强的声学模型和语音LLM，通过MICL方法选择声学假设，以此改善未见过语言的性能。", "conclusion": "实验结果表明，多模态ICL能够持续提高ASR性能，并且跨语言迁移学习可以在没有使用目标语言数据的情况下匹配或超越基于语料库训练的语言模型。我们已公开发布相关代码。"}
{"llm_update_time": "20260113", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2601.05776", "html_url": "https://arxiv.org/abs/2601.05776", "title": "单个字符表而非数百个？关于预训练罗马化编码语言模型的探讨", "title_en": "One Script Instead of Hundreds? On Pretraining Romanized Encoder Language Models", "authors": "Benedikt Ebing,Lennart Keller,Goran Glavaš", "background": "罗马化作为一种有效的策略，已经被证明可以提高多语言模型（mLMs）的跨语言转移（XLT）。大多数早期研究主要关注了罗马化条件最为有利的设置：例如，从高资源拉丁表书语言向低资源非拉丁书语言的转移，或者在不同表书系统但语系密切相关的语言之间进行转移。因此，尚不清楚罗马化是否适用于预训练通用多语言模型，特别是在资源丰富的语言中，标记丢失是否会影响其表现。", "innovation": "本文通过从零开始为6种具有不同类型的高资源语言预训练编码器语言模型（包括罗马化和原文），探讨了罗马化在这种背景下可能带来的两种潜在性能下降的原因：（i）特定表书系统信息的丢失，（ii）由于词汇重叠增加导致的跨语言干扰。使用不同保真度的两种罗马化工具，研究发现，对于段落表书系统语言，性能几乎无损失，而对于形态音节表书系统语言（如汉语和日语），高保真度的罗马化能够部分缓解性能下降，但无法完全恢复。此外，研究表明，增加的子词重叠并不会导致负面干扰。并且，罗马化提高了段落表书系统语言的编码效率，且未引起明显的性能损失。", "conclusion": "通过对罗马化编码语言模型的预训练研究，发现即使在资源丰富的语言中，罗马化也对性能表现出积极的效果，特别是在段落表书系统语言中，高保真度的罗马化能够有效缓解性能下降。罗马化在交叉语言模型中的使用可能会带来编码效率的提高，同时对性能的影响可以忽略不计。"}
{"llm_update_time": "20260113", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2601.05794", "html_url": "https://arxiv.org/abs/2601.05794", "title": "Simplify-This: 基于提示和调优的大语言模型对比分析", "title_en": "Simplify-This: A Comparative Analysis of Prompt-Based and Fine-Tuned LLMs", "authors": "Eilam Cohen,Itamar Bul,Danielle Inbar,Omri Loewenbach", "background": "大型语言模型（LLMs）能够进行强大的文本生成。在一般情况下，模型微调和提示工程之间存在实践中的权衡。本文通过使用多种评估指标对编码器-解码器LLMs在多个基准上的文本简化进行了比较研究，研究了两种方法在结构简化和语义相似性方面的表现。", "innovation": "引入了Simplify-This，这是一种对比研究，评估了使用编码器-解码器LLMs进行文本简化时的两种方法。结果表明，微调模型在结构简化方面表现更优，而提示通常在语义相似性得分更高但倾向于复制输入。此外，研究还提供了代码、用于研究的人清洗衍生数据集、微调模型的检查点以及提示模板，以促进可重复性和未来的研究。", "conclusion": "微调模型在结构简化方面表现更优，尽管提示在语义相似性得分方面更高但倾向于复制输入。人工评估更倾向于微调输出。提供了相关资源以促进研究的可重复性和未来工作。"}
{"llm_update_time": "20260113", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2601.05657", "html_url": "https://arxiv.org/abs/2601.05657", "title": "Stephanie2: 在逐步AI社会聊天中像人类一样思考、等待和做决策", "title_en": "Stephanie2: Thinking, Waiting, and Making Decisions Like Humans in Step-by-Step AI Social Chat", "authors": "Hao Yang,Hongyuan Lu,Dingkang Yang,Wenliang Yang,Peng Sun,Xiaochuan Zhang,Jun Xiao,Kefan He,Wai Lam,Yang Liu,Xinhua Zeng", "background": "即时消息的人际社交聊天通常由一系列简短的消息组成。现有的逐步生成AI聊天系统通常将一次生成的任务拆分成多个消息并依次发送，但缺乏主动等待机制，导致消息节奏不自然。本文旨在为解决这些问题。", "innovation": "提出了Stephanie2，这是一种新型的逐步决策对话代理。Stephanie2具有主动等待和消息节奏适应功能，在每一步骤中明确决定是发送消息还是等待，并将延迟视为思考时间和敲字时间的总和，从而实现更自然的节奏。进一步引入了基于时间窗口的双代理对话系统以生成伪对话历史，用于人类和自动评估。", "conclusion": "实验结果显示，Stephanie2在自然度和参与度等指标上明显优于Stephanie1，并在人类评估的图灵测试中提高了通过率。"}
{"llm_update_time": "20260113", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2601.05654", "html_url": "https://arxiv.org/abs/2601.05654", "title": "基于上下文感知用户画像的个性化说服力预测框架", "title_en": "A Framework for Personalized Persuasiveness Prediction via Context-Aware User Profiling", "authors": "Sejun Park,Yoonah Park,Jongwon Lim,Yohan Jo", "background": "在推荐系统、LLM安全评估等领域，估计信息的说服力至关重要。考虑说服对象的特征（如价值观、经历和推理风格）是必要的。然而，目前缺乏一个系统的方法，以优化利用用户的历史活动（如对话记录）来改进说服力预测模型。", "innovation": "提出了一种上下文感知的用户画像框架，包含两个可训练的组件：查询生成器用于从用户历史中检索与说服相关的信息，以及用户概况器将这些信息总结成一个概况以有效指导说服力预测模型。", "conclusion": "通过在ChangeMyView Reddit数据集上的评估，该方法在多个预测模型上均表现出一致的改进，F1分数最高提升13.77%。进一步分析表明，有效的用户概况依赖于上下文和预测器，而不仅仅是静态属性或表面相似性。这些结果突显了基于任务、上下文感知的用户概况对于个性化说服力预测的重要性。"}
{"llm_update_time": "20260113", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2601.05713", "html_url": "https://arxiv.org/abs/2601.05713", "title": "使用弥散张量成像可视化词嵌入中的信息流动", "title_en": "Visualising Information Flow in Word Embeddings with Diffusion Tensor Imaging", "authors": "Thomas Fabian", "background": "理解大型语言模型（LLMs）如何表示自然语言是自然语言处理（NLP）研究中的核心挑战。现有方法通过从LLM中提取词嵌入，使用点图可视化词嵌入空间，并比较特定词的相对位置。但这种方法只考虑单个词，忽略掉了词语所处的完整自然语言表达的上下文。", "innovation": "本文提出了一种新的工具，通过将弥散张量成像（DTI）应用于词嵌入，分析并可视化自然语言表达中的信息流动。这种方法能够追踪LLM层中信息的流动，用于比较不同模型结构并揭示修剪LLM未充分利用层的机会。此外，模型揭示了不同类型任务（如代词消解和元喻检测）中信息流动的差异。", "conclusion": "我们的研究结果表明，通过我们的模型，可以获取到关于LLMs如何表示真实自然语言表达的新见解，超越了单一词嵌入的比较，提高了NLP模型的可解释性。"}
{"llm_update_time": "20260113", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2601.05752", "html_url": "https://arxiv.org/abs/2601.05752", "title": "AutoMonitor-Bench：评估基于LLM的不当行为监控的可靠性", "title_en": "AutoMonitor-Bench: Evaluating the Reliability of LLM-Based Misbehavior Monitor", "authors": "Shu Yang,Jingyu Hu,Tong Li,Hanqi Yan,Wenxuan Wang,Di Wang", "background": "当前，基于大语言模型（LLM）的不当行为监控面临系统性评估缺失的问题，尤其是在不同任务和错误模式下的表现不够明确。AutoMonitor-Bench旨在填补这一空白，提供一个全面的基准测试环境来评估这些监控系统的可靠性。", "innovation": "AutoMonitor-Bench是首个系统化评估基于LLM的不当行为监控工具的基准，包括3010个详细标注的测试样本，覆盖问题回答、代码生成和推理任务。该基准还引入了两种互补的评估指标：遗漏率（Miss Rate, MR）和误报率（False Alarm Rate, FAR），分别衡量未检测到不当行为和对正常行为的过度敏感。此外，通过构建大规模训练语料库并调整模型参数，研究进一步探索了训练数据对监控性能的影响。", "conclusion": "研究发现，不同LLM监控性能差异显著，并存在安全性和实用性之间的内在权衡。这揭示了可靠且可扩展的不当行为监控的挑战，需要进一步的任务感知设计和训练策略来改进基于LLM的监控系统。"}
{"llm_update_time": "20260113", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2601.05641", "html_url": "https://arxiv.org/abs/2601.05641", "title": "多语言失忆：多语言大模型去学习的可迁移性研究", "title_en": "Multilingual Amnesia: On the Transferability of Unlearning in Multilingual LLMs", "authors": "Alireza Dehghanpour Farashah,Aditi Khandelwal,Marylou Fauchard,Zhuan Shi,Negar Rostamzadeh,Golnoosh Farnadi", "background": "随着多语言大型语言模型的广泛应用，确保其在多样语言环境下的安全性和公平性提出了独特的挑战。现有针对机器卸载的研究主要集中在单一语言环境，特别是英语，而多语言环境带来的挑战包括跨语言知识迁移和预训练数据及微调数据中嵌入的偏见。本文研究了使用Aya-Expanse 8B模型在数据卸载和概念卸载两种情境下的多语言去学习问题，并将基准测试扩展到十种语言：英语、法语、阿拉伯语、日语、俄语、波斯语、韩语、印地语、希伯来语和印尼语。", "innovation": "研究首次将基准测试扩展到多种语言环境，涵盖了不同语言家庭和资源水平的语言。实验显示，资源丰富语言的数据去学习通常更稳定，而语族相关的语言在跨语言去学习行为上表现出不对称的迁移效应。此外，语言距离分析表明，句法相似度是跨语言去学习行为最强的预测因素。", "conclusion": "研究展示了在多语言大型语言模型中，卸载行为的稳定性和可迁移性受到语言资源和语法规则的影响，为未来多语言环境下的模型安全性和公平性设计提供了依据。"}
{"llm_update_time": "20260113", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2601.05751", "html_url": "https://arxiv.org/abs/2601.05751", "title": "在LLM生成文本中分析说服性语言差异：揭示刻板性别模式", "title_en": "Analysing Differences in Persuasive Language in LLM-Generated Text: Uncovering Stereotypical Gender Patterns", "authors": "Amalie Brogaard Pauli,Maria Barrett,Max Müller-Eberstein,Isabelle Augenstein,Ira Assent", "background": "大型语言模型（LLMs）越来越多地用于日常沟通任务，包括草拟旨在影响和说服的个人间消息。先前的研究表明，LLMs可以成功说服人类并放大说服性语言。因此，理解用户指令如何影响说服性语言的生成变得至关重要，还应了解生成的说服性语言是否因不同的目标群体而有所不同。本文提出了一种框架，用于评估接收者性别、发送者意图或输出语言对说服性语言生成的影响。使用成对指令评估了13个LLMs和16种语言。通过一个基于社会心理学和传播科学的LLM作为法官的设置，对模型的回应在19类说服性语言类别中进行评估。结果显示，所有模型生成的说服性语言在性别方面存在显著差异，这些模式反映了社会心理学和社会语言学中记录的与性别刻板语言倾向一致的偏差。", "innovation": "提出了一种评估大型语言模型生成说服性语言受接收者性别、发送者意图或输出语言影响的框架。通过13个LLMs和16种语言进行成对指令评估，并采用基于社会心理学和传播科学的LLM作为法官的评估设置，对19类说服性语言进行了分析。", "conclusion": "研究表明，所有大型语言模型生成的说服性语言在性别方面存在显著差异，这些差异反映了解决社会心理学和社会语言学中记录的性别刻板语言倾向的偏差。"}
