# 20250905
[![Subscribe_Visitors](https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss)](https://github.com/nituchao/latest_arxiv_analyze_ai)

## 1. `cs.AI` - 朝向基于图示表示的神经符号推理系统 [PDF](https://arxiv.org/pdf/2509.03644), [HTML](https://arxiv.org/abs/2509.03644)
### Authors
François Olivier,Zied Bouraoui
### Background
尽管自然语言理解取得了显著进展，但大规模语言模型（LLMs）在执行逻辑推理时仍然容易出错，尤其是缺乏人类思维中稳健的表征。研究指出，良好的逻辑理解需要人类认知中的空间基础，而现有的LLMs在这方面仍有不足。
### Innovation
本文提出了一种新的神经符号系统——Embodied-LM，该系统基于图示（image schemas）进行理解和逻辑推理。图示是源自感觉运动经验的不断重复的模式，它们构建人类认知结构。Embody-LM 通过应用回答集编程中的声明性空间推理来实现这些认知结构的空间基础。通过逻辑推理问题的评估，证明了LLMs能够通过嵌入的认知结构来解释场景，这些结构能够被形式化为可执行程序，并能支持具有更高可解释性的有效逻辑推理。
### Conclusion
当前的实现仅专注于空间基本构建块，但已经为整合更复杂和动态的表示奠定了计算基础。
## 2. `cs.AI` - PG-Agent: 由页面图驱动的智能代理 [PDF](https://arxiv.org/pdf/2509.03536), [HTML](https://arxiv.org/abs/2509.03536)
### Authors
Weizhi Chen,Ziwei Wang,Leyang Yang,Sheng Zhou,Xiaoxuan Tang,Jiajun Bu,Yong Li,Wei Jiang
### Background
图形用户界面（GUI）代理在商业和社会上具有显著的价值。当前的GUI代理通常通过一系列跨页面的多步骤操作序列作为先前的GUI知识，这种模式难以捕捉页面之间的复杂转换关系，使得代理难以深入感知GUI环境并泛化到新的场景中。
### Innovation
本文设计了一个自动流程，将顺序事件转换为页面图，明确地建模了通过动作自然连接的页面的图结构。为了充分利用页面图，引入了检索增强生成（RAG）技术，以有效检索GUI的可靠感知指南，并提出一个定制化的多代理框架PG-Agent，结合任务分解策略，注入这些指南，使其能够泛化到未见过的场景。广泛的基准测试结果展示了PG-Agent的有效性，即使在页面图构建时拥有有限的事件序列。
### Conclusion
实验结果证明了PG-Agent的有效性，即使在有限的序列事件下，也能通过页面图进行泛化。
## 3. `cs.AI` - 学习何时规划：在序列决策任务中高效分配LLM代理的测试时计算资源 [PDF](https://arxiv.org/pdf/2509.03581), [HTML](https://arxiv.org/abs/2509.03581)
### Authors
Davide Paglieri,Bartłomiej Cupiał,Jonathan Cook,Ulyana Piterbarg,Jens Tuyls,Edward Grefenstette,Jakob Nicolaus Foerster,Jack Parker-Holder,Tim Rocktäschel
### Background
当前，通过强化学习（RL）训练大型语言模型（LLMs）进行推理显著提高了它们的问题解决能力。现有的方法如ReAct促使LLMs在每次行动前进行明确规划，但这种方法在长期任务中计算成本高且性能下降。相反，从不规划导致性能受限。
### Innovation
论文引入了一个概念框架，用于正式化LLM代理的动态规划，使得它们能够在运行时灵活决定何时分配计算资源进行规划。提出了一种简单的两阶段训练管道：首先是监督微调，使用多样化的合成数据来鼓励模型进行动态规划，其次是使用RL在长期环境中改进这一能力。
### Conclusion
通过这种方法训练的动态规划代理更样本高效，并且能更一致地达成复杂的任务目标。此外，实验表明这些代理可以通过人工撰写的计划得到有效引导，超越其独立能力。据我们所知，这是首次探索训练LLM代理以在序列决策任务中高效分配测试时的计算资源，为进一步开发高效、可适应和可控的代理系统指明了方向。
## 4. `cs.AI` - 部分可识别查询在准马可维茨结构因果模型中的多线性和线性规划 [PDF](https://arxiv.org/pdf/2509.03548), [HTML](https://arxiv.org/abs/2509.03548)
### Authors
João P. Arroyo,João G. Rodrigues,Daniel Lawand,Denis D. Mauá,Junkyu Lee,Radu Marinescu,Alex Gray,Eduardo R. Laurentino,Fabio G. Cozman
### Background
本文研究了因果模型中的部分可识别查询。具体来说，关注一类无环的结构因果模型，其中每个内生变量最多只与一个外生共因相连。当内生变量已观测且分布已知，但外生变量未完全指定时，该研究探索了一种涉及场景。在这种情况下，无法唯一确定根变量的分布，所以精确计算某个概率值可能不可行。因此，研究了计算紧概率边界的问题。
### Innovation
提出了一种新的算法来简化程序的构造，通过利用内生变量的输入概率。对于单个干预的情景，采用列生成技术通过一系列的辅助线性整数规划来计算概率边界，展示了存在多项式基数的外生变量表示方法。实验表明列生成技术优于现有方法。
### Conclusion
该研究利用列生成技术计算了单个干预条件下的概率边界，并显示了存在多项式基数的外生变量表示方法，实验结果表明列生成技术更优。
## 5. `cs.AI` - 时间序列分类的SHAP解释因素的实证评估 [PDF](https://arxiv.org/pdf/2509.03649), [HTML](https://arxiv.org/abs/2509.03649)
### Authors
Davide Italo Serramazza,Nikos Papadeas,Zahraa Abdallah,Georgiana Ifrim
### Background
解释性人工智能(XAI)已成为理解和归因复杂时间序列分类(TSC)模型预测的重要课题。SHapley Additive exPlanations (SHAP)是一种广泛认为优秀的归因方法，但其计算复杂性随着特征数量的增加而呈指数增长，这在处理长时间序列时带来了实际应用中的局限性。因此，通过划分特征进行分段来计算一组连续时间点的单一归因值，显著减少了SHAP的运行时间。然而，尚未确定最佳的分段策略。本文研究了八个不同的时间序列分段算法，以了解分段组成如何影响解释质量。通过使用两种公认的XAI评估方法：InterpretTime和AUC Difference，以及对多变量和单变量时间序列的实验研究，发现分割的数量比特定的分割方法对解释质量的影响更大。其中，等长分割通常优于大多数自定义时间序列分段算法。此外，引入了一种新型的归因规范化技术，通过分割长度对分割进行加权，证明了这种方法可以持续提高归因质量。
### Innovation
研究发现了时间序列分段对于提升SHAP解释质量的贡献，并通过实验验证等长分割在多个分割算法中表现最佳。同时，引入了一种新型的归因规范化技术，通过时间序列分段长度进行加权评估，以进一步提升归因质量。
### Conclusion
时间序列分段的数量比特定的分割方法对解释质量的影响更大。等长分割策略在多个分割算法中表现最佳。通过分割长度对分割进行加权的新型归因规范化技术可以持续提高归因质量。
## 6. `cs.AI` - 基于扩散强化学习的航空交通冲突检测与解决方法 [PDF](https://arxiv.org/pdf/2509.03550), [HTML](https://arxiv.org/abs/2509.03550)
### Authors
Tonghe Li,Jixin Liu,Weili Zeng,Hao Jiang
### Background
在全球航空交通持续增长的背景下，高效安全的冲突检测与解决（CD&R）对于航空交通管理至关重要。尽管深度强化学习（DRL）为CD&R的自动化提供了有希望的方向，但现有的方法通常受到‘单模偏见’的限制，导致在面对复杂和动态的约束时决策灵活性不足，往往导致‘决策死锁’现象。
### Innovation
本文创新性地将扩散概率模型应用于安全关键任务的CD&R中，提出了一种新的自主冲突解决框架，命名为Diffusion-AC。该框架通过反向去噪过程生成多模态的动作分布，而不是传统的单一最优解方法。此外，本文还提出了一种密度渐进安全课程（DPSC）的训练机制，确保代理从稀疏到高密度交通环境中的稳定高效学习。论文实验结果表明，提出的Diffusion-AC方法在多个尖端DRL基准中表现出色，并且在高密度场景中，成功率达到94.1%，同时将接近空中相撞（NMAC）的发生率降低了约59%，显著提升了系统的安全边际。
### Conclusion
Diffusion-AC通过其独特的多模态决策能力，使代理在执行有效替代机动时具有灵活性，从而在高密度场景中显著提高了CD&R的成功率和安全性能。
## 7. `cs.AI` - CausalARC: 基于因果世界模型的抽象推理 [PDF](https://arxiv.org/pdf/2509.03636), [HTML](https://arxiv.org/abs/2509.03636)
### Authors
Jacqueline Maasch,John Kalantari,Kia Khezeli
### Background
在数据有限和分布偏移的条件下，推理需要适应新的问题设置。现有的研究多关注在充分数据和标准分布下的表现。因此，本文提出了一种新的实验测试平台CausalARC，旨在评估AI在低数据和环境分布外情况下的推理能力。该平台借鉴了Abstraction and Reasoning Corpus（ARC）的设计理念，利用完整的因果世界模型来生成抽象推理任务，并通过原理化数据增强提供观察、干预和反事实反馈，以实现少样本、上下文感知学习。
### Innovation
CausalARC 提供了一种新的测试平台，以评估 AI 在低数据和分布偏移情况下的推理能力。通过基于因果世界模型生成的抽象推理任务，它能够评估语言模型在抽象推理、反事实推理、程序合成和因果发现通过逻辑推理上的性能。此外，通过原理化数据增强，CausalARC 实现了少样本、上下文感知的学习方式。
### Conclusion
CausalARC 的提出为广大研究者提供了一种新的环境，能够更真实地评估 AI 在实际应用中的推理能力。通过在不同任务中的测试，展示了语言模型在多种推理任务上的潜力，并为进一步研究奠定了基础。
## 8. `cs.AI` - 使用KG-SMILE进行可解释的知识图谱检索增强生成 (KG-RAG) 的方法 [PDF](https://arxiv.org/pdf/2509.03626), [HTML](https://arxiv.org/abs/2509.03626)
### Authors
Zahra Zehtabi Sabeti Moghaddam,Zeinab Dehghani,Maneeha Rani,Koorosh Aslansefat,Bhupesh Kumar Mishra,Rameez Raja Kureshi,Dhavalkumar Thakker
### Background
生成式人工智能，如大型语言模型（LLMs），已经取得了显著的进展，但在敏感领域中仍然会产生幻觉和不可验证的声明，这限制了其可靠性。检索增强生成（RAG）通过将输出与外部知识相结合来提高准确性，尤其是在医疗保健等需要高精度的领域。然而，RAG仍然缺乏透明性，本质上是一个黑盒模型，高度依赖于数据质量。
### Innovation
开发了一种基于扰动的、方法中立的框架，称为KG-SMILE，以提供对Graph RAG的图实体和关系的图级别相互操作性，从而使得RAG更具有透明性。KG-SMILE通过应用受控扰动、计算相似性以及训练加权线性近似，识别出对生成输出最具有影响力的图实体和关系，并使用全面的归因度量标准（包括准确性、忠实度、一致性、稳定性和可靠性）进行评估。实验结果显示，KG-SMILE能够产生稳定且符合人类认知的解释，证明了其在保持模型效果的同时提高可解释性，从而促进对机器学习技术的透明度和信任。
### Conclusion
KG-SMILE在平衡模型效果与可解释性方面展示了其能力，从而增强了机器学习技术的透明度和信任度。
## 9. `cs.AI` - LLM代理在行为上是否一致？社会模拟中的潜在特征 [PDF](https://arxiv.org/pdf/2509.03736), [HTML](https://arxiv.org/abs/2509.03736)
### Authors
James Mooney,Josef Woldense,Zheng Robert Jia,Shirley Anugrah Hayati,My Ha Nguyen,Vipul Raheja,Dongyeop Kang
### Background
大型语言模型（LLMs）表现出色，引发了对于合成代理能否替代真实参与者进行人类主题研究的讨论。社会科学研究者主要关注LLM生成的调查数据是否与启发LLM的对应人类参与者的数据相符。然而，本研究提出了一个新的关键问题：代理在不同实验设置下是否能够保持内部一致性，即是否具有相似的行为表现。
### Innovation
本研究开发了一项研究设计来揭示代理的内部状态，并检查代理在基本对话场景下的行为表现。通过探索一系列行为假设，研究发现不同模型家族和不同模型规模下的LLMs表现出显著的内部不一致性。研究发现，虽然代理可以生成符合人类对应参与者反应的内容，但它们无法在不同实验设置下保持内部一致性。
### Conclusion
研究结果显示，尽管LLM代理能够生成与人类参与者类似的回应，但它们在不同实验设置下未能表现出内部一致性。这表明，LLM代理在替代真实参与者进行人类主题研究方面还存在重要的能力缺口。研究结果表明，提供可访问的模拟代码和数据的开放性。
## 10. `cs.AI` - 通过强化学习在大型语言模型中实现的层级式推理 [PDF](https://arxiv.org/pdf/2509.03646), [HTML](https://arxiv.org/abs/2509.03646)
### Authors
Haozhe Wang,Qixin Xu,Che Liu,Junhong Wu,Fangzhen Lin,Wenhu Chen
### Background
强化学习（RL）已被证明能够显著提升大型语言模型（LLMs）的复杂推理能力，然而其背后的机制仍然相当神秘。本研究揭示了类似“恍然大悟”、“长度缩放”和熵动态等令人困惑的现象并非独立事件，而是层级推理结构的标志性特征，类似于人类认知中高层级战略规划与低层级程序执行的分离。研究者发现，在模型学习过程中存在一种明显的两阶段动态：初始阶段，模型受到程序正确性的限制，必须改进其基础技能。随后，学习瓶颈从低级技能转变为高级战略规划的探索和掌握。现有的RL算法如GRPO无法很好地捕捉这一过程，导致优化压力在整个过程中分散，降低了学习效率。
### Innovation
本研究提出了一个新颖的算法——HIerarchy-Aware Credit Assignment (HICRA)，该算法旨在集中优化资源到具有高影响的战略规划令牌上。HICRA在多方面显著优于现有的强大基准，证明了聚焦于这一战略瓶颈是解锁高级推理的关键。此外，研究者还验证了语义熵作为衡量战略探索的更优指标，优于传统的标记级别熵指标。
### Conclusion
研究揭示了层级推理结构在LLMs中的重要性，并通过提出HICRA算法成功提升了模型的学习效率。未来工作应进一步探索层级推理机制，并优化相应的算法，从而推动LLMs的进一步发展。
## 11. `cs.AI` - 利用基于LLM的代理进行智能供应链规划 [PDF](https://arxiv.org/pdf/2509.03811), [HTML](https://arxiv.org/abs/2509.03811)
### Authors
Yongzhi Qi,Jiaheng Yin,Jianshen Zhang,Dongyang Geng,Zhengyu Chen,Hao Hu,Wei Qi,Zuo-Jun Max Shen
### Background
在供应链管理中，规划是一个关键概念。产品从供应商到仓库再到销售，最终由物流送到客户手中，涉及众多实体和多方面的工作，如需求预测、库存管理、销售运营和补货。如何从电子商务平台的角度收集相关数据，制定长期计划，并根据环境变化动态调整，同时确保计划的可解释性、效率和可靠性，是一个实际且具有挑战性的问题。
### Innovation
近期AI技术的发展，特别是大型语言模型的快速进步，为解决实际问题提供了新工具。本文构建了一个供应链规划代理(SCPA)框架，该框架能够理解领域知识，理解操作员的需求，分解任务，利用或创造新的工具，并返回基于证据的规划报告。
### Conclusion
我们在亚马逊这个真实场景中部署了这个框架，展示了LLM代理在供应链中的可行性。它有效减少了人力，并提高了准确度、库存可用性和其他关键指标。
## 12. `cs.AI` - 大型语言模型会做什么？评估大型语言模型在政策制定中的能力 [PDF](https://arxiv.org/pdf/2509.03827), [HTML](https://arxiv.org/abs/2509.03827)
### Authors
Pierre Le Coz,Jia An Liu,Debarun Bhattacharjya,Georgina Curto,Serge Stinckwich
### Background
大型语言模型（LLMs）在高风险领域中的应用日益增多。它们处理大量非结构化数据、探索灵活情况以及应对各种情境因素的能力使其成为解决社会政策制定复杂性问题的有力工具。本文探讨了LLMs如何与领域专家保持一致，为缓解全球15亿以上无家可归人口的问题提供政策建议。
### Innovation
开发了一个包含四个地理区域（美国南本德市、西班牙巴塞罗那、南非约翰内斯堡和中国澳门）的决策场景基准，涵盖政策选择，并基于人类发展的制能方法论。利用自动化流水线将基准政策与基于代理的模型连接起来，并通过模拟社会情景探索推荐政策的社会影响。研究表明，适当引入责任护栏和本地化校准，LLMs可以为人类政策制定者提供有价值的见解。
### Conclusion
研究结果表明，LLMs有利用价值以支持社会政策制定，前提是与本地领域专家合作，引入负责任的保障措施和情境校准，可以为人类提供大规模的替代政策建议。
## 13. `cs.AI` - PersonaTeaming: 探索引入人设如何提升自动化AI红队 [PDF](https://arxiv.org/pdf/2509.03728), [HTML](https://arxiv.org/abs/2509.03728)
### Authors
Wesley Hanwen Deng,Sunnie S. Y. Kim,Akshita Jha,Ken Holstein,Motahhare Eslami,Lauren Wilcox,Leon A Gatys
### Background
近年来，AI治理和安全研究的进步对有效的红队方法提出了需求，以揭示潜在的风险。许多研究强调了红队成员的身份和背景如何影响他们的策略和发现的风险类型。尽管自动化红队方法能够通过大规模探索模型行为来补充人为的红队，但当前方法并未考虑到身份的作用。因此，研究人员开发了一种名为PersonaTeaming的新方法，通过在对抗性提示生成过程中引入人设来探索更广泛的对抗策略。
### Innovation
开发了一种名为PersonaTeaming的新方法，该方法通过在对抗性提示生成过程中引入人设，来探索更广泛的对抗策略。具体地，提出了一种基于“红队专家”或“普通AI用户”人设的提示变异方法，同时开发了一个动态的人设生成算法，能够自动生成各种适应不同种子提示的人设类型。此外，还开发了一套新的指标来显式测量“变异距离”，以补充现有的对抗性提示多样性测量。结果表明，相较于最先进的自动化红队方法RainbowPlus，PersonaTeaming在对抗性提示的成功率上提高了最高144.1%，同时保持了提示的多样性。
### Conclusion
研究讨论了不同类型人设和变异方法的优点和局限性，指出了未来在自动化与人为红队策略互补方面的探索机会。
## 14. `cs.AI` - Medical概念标准化的主动模型上下文协议框架 [PDF](https://arxiv.org/pdf/2509.03828), [HTML](https://arxiv.org/abs/2509.03828)
### Authors
Jaerong Ahn,Andrew Wen,Nan Wang,Heling Jia,Zhiyi Yue,Sunyang Fu,Hongfang Liu
### Background
OMOP公共数据模型（CDM）提供了一种标准化表示异质性健康数据的方法，支持大规模、多机构研究。然而，在使用OMOP CDM进行数据标准化的过程中，将源医学术语映射到OMOP标准概念是一个劳动密集型且容易出错的任务。虽然大型语言模型（LLMs）有望简化这个过程，但由于它们容易产生幻觉，它们在临床部署中仍需要进一步的训练和专家验证。
### Innovation
本文开发了一种基于Model Context Protocol（MCP）的零训练、防止幻觉的映射系统，该协议是一种标准化且安全的框架，允许LLMs与外部资源和工具交互。该系统实现了可解释的映射，并显著提高了效率和准确性，只需最少的努力即可实现。该系统提供实时词汇查询和结构化推理输出，适合在探索和生产环境中立即使用。
### Conclusion
该系统通过提供实时词汇查询和结构化推理输出，能够显著提高医学概念标准化的任务效率和准确性。它为立即在探索和生产环境中的使用提供了可能，并为LLMs的临床应用提供了一种新的解决方式。
## 15. `cs.AI` - 基于多智能体强化学习的代理型大语言模型的协商学习 [PDF](https://arxiv.org/pdf/2509.03817), [HTML](https://arxiv.org/abs/2509.03817)
### Authors
Wei Yang,Jesse Thomason
### Background
大型语言模型（LLMs）的多智能体系统在复杂推理方面显示出潜力，但其效果往往受限于固定的合作协议。这些框架通常侧重于宏观级的协调，而忽视了智能体的内在推理能力。现有方法通常将智能体视为被动执行者，不能根据不确定性或自信等内部认知状态调整策略。
### Innovation
引入了Meta-Policy Deliberation Framework (MPDF)，该框架使智能体学习一套基于高层次元认知行动的去中心化策略：持续、细化和让步。开发了一种新的强化学习算法SoftRankPO，通过基于奖励秩的平滑正态量化来塑造优势，增强了学习过程对奖励变化的鲁棒性。实验结果显示，使用SoftRankPO的MPDF在五个数学和通用推理基准测试中，平均准确性提高了4-5%，优于六种最先进的启发式和学习型多智能体推理算法。
### Conclusion
本研究提出了一种多智能体LLM系统学习适应性和元认知策略的范式，从设计固定协议转向学习动态、推理策略。
## 16. `cs.AI` - Expedition & Expansion: Leveraging Semantic Representations for Goal-Directed Exploration in Continuous Cellular Automata [PDF](https://arxiv.org/pdf/2509.03863), [HTML](https://arxiv.org/abs/2509.03863)
### Authors
Sina Khajehabdollahi,Gautier Hamon,Marko Cvjetko,Pierre-Yves Oudeyer,Clément Moulin-Frier,Cédric Colas
### Background
在连续细胞自动机（CA）中发现多种视觉模式颇具挑战性，因为其高维行为空间既巨大又冗余。传统探索方法如新颖性搜索（NS）通过突变已知的新颖解进行局部扩展，但在当地新颖性耗尽时会停滞，难以到达远距离的未探索区域。
### Innovation
我们提出了一种称为Exploration and Expansion (E&E) 的混合策略，它交替进行局部新颖性驱动的扩展和目标导向的探险。E&E利用视觉-语言模型（VLM）生成语义目标——对有趣的但假设的模式的描述，以驱动探索向未开垦区域前进。通过在与人类感知相匹配的语义空间中操作，E&E不仅评估新颖性，还以概念上具有意义的方式生成目标，增强发现行为的可解释性和相关性。
### Conclusion
在Flow Lenia的测试中，E&E在揭露更多样化的解决方案方面比现有探索方法更有效。族谱分析进一步表明，源自探险的解决方案在长期内对探索具有不成比例的影响，为后续搜索解锁新的行为生态位。这些发现突显了E&E能够突破局部新颖性边界，并以符合人类感知的方式探索行为景观的能力，为艺术生命和更多方面的开放探索提供了有希望的模板。
## 17. `cs.AI` - FaMA: 由大语言模型驱动的面向消费者间的市场助理 [PDF](https://arxiv.org/pdf/2509.03890), [HTML](https://arxiv.org/abs/2509.03890)
### Authors
Yineng Yan,Xidong Wang,Jin Seng Cheng,Ran Hu,Wentao Guan,Nahid Farahmand,Hengte Lin,Yue Li
### Background
当前，由大规模语言模型（LLMs）驱动的‘代理型’人工智能（AI）正在从反应式生成系统向具有前瞻性和目标导向的自主代理转变，这些代理能够进行复杂的规划、记忆和工具使用。这种演变为解决复杂数字环境中的长期挑战提供了新的机会。在消费者到消费者的（C2C）电子商务平台中，消费者和商家通常需要通过复杂图形用户界面（GUI）进行导航，这使得双方的体验十分耗时。
### Innovation
本文介绍了一种通过大规模语言模型的代理辅助简化交互的新方法。该代理作为市场的新入口，改变主要的交互模式，从复杂的GUI到直观的人工智能代理。通过解析自然语言命令，代理自动执行关键的高摩擦工作流，例如简化卖家的列表更新和续订，以及买家通过会话搜索更高效的发现产品。
### Conclusion
文章提出了Facebook Marketplace Assistant (FaMA)，认为这种代理型、会话式的模式提供了一个轻量级且更易访问的替代传统应用界面的选项，能够使用户更高效地管理市场活动。实验结果表明，FaMA在解决市场上的复杂任务方面达到了98%的成功率，并使互动时间提高了两倍。
## 18. `cs.AI` - 通过最佳优先搜索与延迟部分展开处理规划中的无限域参数 [PDF](https://arxiv.org/pdf/2509.03953), [HTML](https://arxiv.org/abs/2509.03953)
### Authors
Ángel Aso-Mollar,Diego Aineto,Enrico Scala,Eva Onaindia
### Background
在自动化规划中，控制参数通过引入连续的数值决策变量扩展了标准的动作表示。当前最先进的方法主要将控制参数作为嵌入的约束与其它的时间和数值限制一起处理，因此将其隐式地视作约束而不是搜索空间中的决策点。现有方法在这种背景下处理控制参数并不完善。
### Innovation
本文提出了一种新的方法，该方法将控制参数明确地作为搜索空间中的真正决策点进行处理。开发了一种优先级搜索算法，该算法基于控制参数定义的无限决策空间工作，并在某些条件下证明了完备性。该算法使用延迟部分扩展现念，即状态不是完全展开，而是增量地展开其部分后继状态。
### Conclusion
实验结果表明，这种新型搜索算法是解决涉及控制参数的规划问题的有效替代方法，可以与现有的方法竞争。
## 19. `cs.AI` - 《LLM人格幻象：揭示LLM自我报告与行为之间的分歧》 [PDF](https://arxiv.org/pdf/2509.03730), [HTML](https://arxiv.org/abs/2509.03730)
### Authors
Pengrui Han,Rafal Kocielnik,Peiyang Song,Ramit Debnath,Dean Mobbs,Anima Anandkumar,R. Michael Alvarez
### Background
人格特质长期以来一直是预测人类行为的研究对象。随着大型语言模型（LLMs）的发展，研究表明类似的人格倾向也可能出现在人工系统中，高级LLMs表现出与人类特质（如亲和力和自我调节）相似的一致行为模式。然而，以往的研究主要依赖于简化的自评分和启发式提示，缺乏行为验证。这项研究系统地分析了LLM的人格特征，涵盖训练阶段中特质特征的动态变化、自我报告特质在行为任务中的预测有效性以及目标干预（例如个性注入）对自我报告和行为的影响等三个维度。
### Innovation
本研究提出了对LLM人格特征的系统性分析框架，强调了LLM在自我报告与实际行为之间存在差异。研究发现，指令对齐（例如RLHF，指令调整）显著稳定了特质表达，并增强了与人类数据相匹配的人格特征相关性。但自我报告的特质并不能可靠地预测行为表现，观察到的相关性往往会与人类模式产生分歧。个性化注入虽能引导自我报告向预定方向变化，但对实际行为的影响不大或不一致。这项研究区分了表面特质表达和行为一致性，挑战了对LLM人格特征的假设，并突显了在对齐和解释性方面进行深入评估的必要性。
### Conclusion
研究结果表明，不能简单地用自我报告来预测LLM的行为，需进一步深入研究对齐和可解释性。《LLM人格幻象：揭示LLM自我报告与行为之间的分歧》这一标题总结了研究的主要发现，展示了自我报告与实际行为之间的潜在分离现象。
## 20. `cs.AI` - 基于在线强化学习的定位推理胸部X光解读基础模型 [PDF](https://arxiv.org/pdf/2509.03906), [HTML](https://arxiv.org/abs/2509.03906)
### Authors
Qika Lin,Yifan Zhu,Bin Pu,Ling Huang,Haoran Luo,Jingying Ma,Zhen Peng,Tianzhe Zhao,Fangzhi Xu,Jian Zhang,Kai He,Zhonghong Ou,Swapnil Mishra,Mengling Feng
### Background
随着人工智能技术的迅速发展，医学基础模型（FMs）展现了巨大的潜力。当前的医学FMs通常以黑盒方式生成答案，缺乏透明的推理过程和局部解释能力，这阻碍了它们在临床中的实际应用。现有研究主要集中在提高模型的生成性能，而忽视了提供透明和可解释的推理过程，这对于实际临床实践至关重要。
### Innovation
本文介绍了一种名为DeepMedix-R1的全面医学基础模型，专门用于胸部X光（CXR）解读。该模型采用了一种序列训练管道：首先在编纂好的CXR指令数据上进行微调，以获得基本的CXR解读能力；然后通过高质量的合成推理样本进行冷启动推理；最后通过在线强化学习进行优化，以提高推理质量和生成性能。DeepMedix-R1可以在每次查询时产生与图像局部区域相关的推理步骤。定量评估表明，DeepMedix-R1在报告生成和视觉问答任务上取得了显著的性能提升。此外，还提出了一种新的基准测试框架Report Arena，进一步验证了DeepMedix-R1的优越性。
### Conclusion
本文的研究成果推动了医学基础模型的发展，朝着全面、透明和临床可用的模型方向前进，特别适用于胸部X光的解读。这不仅提高了模型的性能，还提供了更透明和可解释的推理过程，有助于医学实践。
## 21. `cs.AI` - CoT-Space: 通过强化学习实现内部慢思考的理论框架 [PDF](https://arxiv.org/pdf/2509.04027), [HTML](https://arxiv.org/abs/2509.04027)
### Authors
Zeyu Gan,Hao Yi,Yong Liu
### Background
强化学习（RL）已经成为增强大型语言模型（LLMs）推理能力的关键方法。然而，传统的基于令牌级别的RL框架在与复杂多步推理过程（如推理链）的推理层次特性上未能有效匹配。因此，存在显著的理论缺口。
### Innovation
为了填补这一空白，我们引入了CoT-Space，这是一种新型的理论框架，将LLMs的推理从离散的令牌预测任务重新定义为在连续的推理层级语义空间中的优化过程。通过从噪声和风险的视角进行分析，我们展示了推理链长度的收敛是基于过拟合和欠拟合的基本权衡的自然结果。大量的实验证明了我们理论发现的有效性。
### Conclusion
我们的框架不仅为诸如过度思考之类的实证现象提供了一致的解释，还为未来更有效和通用的推理代理的发展提供了坚实理论基础。
## 22. `cs.AI` - AutoPBO：基于LLM的局部搜索PBO求解器优化 [PDF](https://arxiv.org/pdf/2509.04007), [HTML](https://arxiv.org/abs/2509.04007)
### Authors
Jinyuan Li,Yi Chu,Yiwen Sun,Mengchuan Zou,Shaowei Cai
### Background
伪布尔优化（PBO）提供了一种强大的框架来通过伪布尔（PB）约束对组合问题进行建模。局部搜索求解器在PBO求解中表现出极佳的效果，其效率高度依赖于内部启发式方法来引导搜索。然而，它们的设计往往需要大量的专家努力和手动调优。尽管大型语言模型（LLMs）已经在自动化算法设计方面展示了潜力，但它们在优化PBO求解器中的应用尚未进行探索。
### Innovation
本文介绍了AutoPBO，这是一种新型的基于LLM的框架，旨在自动增强PBO局部搜索求解器。通过对四个公共基准测试（包括一个实际基准测试、PB比赛基准、整数线性规划优化基准以及一个精心构造的组合基准测试），评估了AutoPBO带来的性能提升，并将其与六个最先进的竞争对手（包括两种局部搜索PBO求解器NuPBO和OraSLS，两种完全的PB求解器PBO-IHS和RoundingSat，以及两种混合整数规划求解器Gurobi和SCIP）进行了比较。结果表明，AutoPBO在局部搜索方法上表现出显着改进，同时与最先进的竞争对手保持竞争力。
### Conclusion
结果表明，AutoPBO提供了一种自动化局部搜索求解器设计的有前途的方法。
## 23. `cs.AI` - 通过测试时植入世界模型实现拟人化代理的适应性 [PDF](https://arxiv.org/pdf/2509.03956), [HTML](https://arxiv.org/abs/2509.03956)
### Authors
Minjong Yoo,Jinwoo Jang,Sihyung Yoon,Honguk Woo
### Background
在拟人化人工智能中，持续性的挑战是如何让智能体能够在面对新颖领域时稳健地适应，而无需大量数据收集或重新训练。现有的方法未能有效解决这一问题。因此，本文旨在提出一种解决方案，即世界模型植入框架（WorMI），结合大型语言模型的推理能力和独立学习的领域特定世界模型，在测试时进行组合，从而实现跨领域的适应能力。
### Innovation
1. WorMI框架通过原型为基础的世界模型检索方法，通过高效轨迹抽象表示匹配，实现相关模型在测试时的组合。r2. 开发了一种领域智慧复合注意力方法，不仅能集成检索到的世界模型的知识，还能对其中间表示与代理策略中推理模型的表示进行对齐。r3. 该框架设计有效融合了多个世界模型的领域特定知识，确保能够稳健地适应未知领域。r4. 在虚拟家庭和ALFWorld基准测试中，WorMI在零样本和少量样本性能方面优于多种基于大型语言模型的方法，展示了其在实际应用中的潜力。
### Conclusion
WorMI框架通过利用大型语言模型的推理能力结合领域特定世界模型，在测试时动态地实现拟人化代理的跨域适应性。这种框架设计在虚拟家庭和ALFWorld评估场景中展现了更好的零样本和少量样本性能，具有在实际应用中适应性和数据效率的关键作用。
## 24. `cs.AI` - 中间语言很重要：形式语言与LLMs影响神经符号推理 [PDF](https://arxiv.org/pdf/2509.04083), [HTML](https://arxiv.org/abs/2509.04083)
### Authors
Alexander Beiser,David Penz,Nysret Musliu
### Background
大型语言模型（LLMs）在各种任务上取得了惊人的成果，但其形式推理能力仍然落后。一种有前景的方法是神经符号LLMs推理。它通过使用LLMs作为从自然语言到形式语言的翻译器，并使用符号求解器来推导正确结果。然而，神经符号LLMs推理成功的原因尚不明确。本文探讨了一个被忽视的因素——形式语言的选择。
### Innovation
本文通过引入中间语言挑战，比较了四种形式语言在三个数据集和七个LLMs上的表现，揭示了形式语言选择对语法和语义推理能力的影响。这为理解神经符号推理的成功因素提供了新的视角。
### Conclusion
研究结果表明，形式语言的选择会影响神经符号推理的能力。不同LLMs在不同形式语言下的表现各不相同，因此在进行神经符号推理任务时需要选择合适的形式语言。
## 25. `cs.AI` - 通过确定性知识图结构进行大规模生成式AI的持续监控 [PDF](https://arxiv.org/pdf/2509.03857), [HTML](https://arxiv.org/abs/2509.03857)
### Authors
Kishor Datta Gupta,Mohd Ariful Haque,Hasmot Ali,Marufa Kamal,Syed Bahauddin Alam,Mohammad Ashiqur Rahman
### Background
生成式AI（GEN AI）模型已经在多个领域革新了应用，但其可靠性引起了广泛关注，包括幻觉、语义漂移以及固有的偏差问题。当前的评估方法主要依赖主观的人类评估，这既不具有可扩展性，也不透明，也不足以为这些模型的有效性提供强有力的保证。这些模型通常作为黑盒操作，使得透明和客观的评估变得复杂。针对这一问题，本研究提出了一种系统的方法，利用确定性和大型语言模型（LLM）生成的知识图结构来持续监控和评估GEN AI的可靠性。这种方法通过构建两个并行的知识图结构：一个基于规则的方法构建的确定性KG和一个从实时文本数据流动态生成的LLM生成性KG来实现。利用实时新闻流可以确保真实性和客观性，同时减少重复训练带来的偏差并避免LLM适应性绕过预定义基准。将几个标准化的知识图结构度量（如实例化类比率ICR、实例化属性比率IPR和类实例化CI）用于量化结构偏差和语义差异，并且通过动态设置基于历史结构度量分布的异常阈值，该方法可以主动检测和标记重大偏差，从而及时发现语义异常或幻觉。这种方法通过确定性和动态生成的知识图结构之间的结构化、基于度量的比较，提供了稳健且可扩展的评估框架。
### Innovation
本研究提出了一种新的、系统的方法来持续监控和评估大规模生成式AI的可靠性。它利用确定性和大型语言模型生成的知识图结构进行实时监控，并通过动态设置基于历史结构度量分布的异常阈值促进异常检测。这种方法不仅可以检测结构偏差和语义差异，而且能够识别和标记重大偏差，从而及时发现语义异常或幻觉。利用实时新闻数据流确保数据的真实性和客观性，同时减少重复训练带来的偏差和LLM的适应性问题。利用标准化的知识图结构度量作为评估指标，实现了更为全面且可扩展的评估框架。
### Conclusion
本研究通过构建确定性和动态生成的知识图结构，并利用实时新闻数据流，提供了能够持续监控和评估大规模生成式AI可靠性的系统方法。这种方法不仅能够识别和标记重大偏差，还可以及时发现语义异常或幻觉。通过这种方法建立的评估框架能够在多个方面提供更为全面和稳健的评价，有助于生成式AI更广泛和更有效的应用。
## 26. `cs.AI` - 混合强化学习和搜索在飞行轨迹规划中的应用 [PDF](https://arxiv.org/pdf/2509.04100), [HTML](https://arxiv.org/abs/2509.04100)
### Authors
Alberto Luise,Michele Lombardi,Florent Teichteil Koenigsbuch
### Background
本文探讨了将强化学习（RL）与基于搜索的路径规划结合，以加速商用飞机飞行路径的优化，特别是在紧急情况下快速重新计算路线尤为关键。基本思路是训练一个RL代理，基于位置和大气数据预先计算近最优路径，并在运行时使用这些信息来约束路径规划求解器，寻找初始假设附近的解。这种方法有效地减少了求解器的搜索空间，显著加快了路线优化的过程。
### Innovation
提出了将RL与路径规划结合的新方法，通过预先计算近最优路径并将其用于约束路径规划求解器，从而显著提高了优化效率和计算速度，同时在保持接近最优解的同时降低了燃料消耗的波动。
### Conclusion
实验证明，与使用普通求解器相比，利用混合RL和搜索的方法可以使计算速度提高50%，且燃油消耗与未约束情况下几乎相同，偏差通常在1%以内。
## 27. `cs.AI` - 一维智能增强框架在上海历史城市区旅游感知分析中的应用：一个案例研究 [PDF](https://arxiv.org/pdf/2509.03830), [HTML](https://arxiv.org/abs/2509.03830)
### Authors
Kaizhen Tan,Yufan Wu,Yuxuan Liu,Haoran Zeng
### Background
历史文化街区在保护文化遗产的同时，作为旅游和日常生活的活跃空间发挥着至关重要的作用。理解游客对其环境的感知对于实现以人为本的城市可持续规划至关重要。现有的研究基于单一或少量的数据来源，未能充分揭示游客对历史街区的复杂感知。因此，本研究提出了一个基于人工智能的多维度框架，该框架利用来自社交媒体的多模态数据来分析游客对历史城市街区的感知，特别是在上海中心区十二个历史文化街区的应用提供了具体的实证案例。
### Innovation
该研究创新地提出了一种结合焦点区域提取、颜色主题分析和情感挖掘的多模态AI框架，旨在分析游客对历史街区的感知。具体来说，利用微调的语义分割模型从游客共享的照片中识别视觉焦点区域，并通过聚类方法提取颜色主题来评估美学偏好。此外，通过将社交媒体照片中的颜色主题与现实世界的街景进行比较，揭示了视觉期望与实际环境之间的差距。情感分析方面，该研究采用了结合规则方法和多任务BERT模型的混合方法，以全面评估游客对四个维度的满意程度。该项研究的不同之处在于，它追求集成的、数据驱动的方法，而非单凭技术革新，从而更好地理解和指导旅游、遗产保护和美观公共空间设计的相关决策。
### Conclusion
该研究发现，游客对美学吸引力和情感反应的空间分布存在显著差异。该多维度AI框架不仅能够深入挖掘游客对历史街区的感知，还为旅游业、文化遗产保护和美学公共空间设计提供了有价值的洞见，能够更好地支持决策制定。通过对实际应用案例的分析，研究证明了该框架的有效性和实用性。
## 28. `cs.AI` - 采用时间图谱构建烹饪过程的行动中心本体 [PDF](https://arxiv.org/pdf/2509.04159), [HTML](https://arxiv.org/abs/2509.04159)
### Authors
Aarush Kumbhakern,Saransh Kumar Gupta,Lipika Dey,Partha Pratim Das
### Background
由于烹饪过程本身固有的复杂性和模糊性，将其形式化仍然是一个具有挑战性的任务。
### Innovation
提出了一种可扩展的领域特定语言（DSL），用于将食谱表示为有向动作图，捕捉了过程、传输、环境、并行性及组合结构。这种方法允许精确、模块化地对复杂的烹饪工作流进行建模。初始的手动评估表明DSL的表现力和对未来自动食谱分析和执行的适用性。
### Conclusion
这项工作代表了向烹饪过程构建行动中心本体的第一步，使用时间图谱来使机器具备结构化理解、精确解释和可扩展自动化烹饪过程的能力，无论是家庭厨房还是专业烹饪环境。
## 29. `cs.AI` -  EvoEmo: 向多回合谈判中LLM代理的进化情感策略迈进 [PDF](https://arxiv.org/pdf/2509.04310), [HTML](https://arxiv.org/abs/2509.04310)
### Authors
Yunbo Long,Liming Xu,Lukas Beckenbauer,Yuhan Liu,Alexandra Brintrup
### Background
近期关于大型语言模型（LLMs）中的链式思考（CoT）推理研究显示，代理人可以进行复杂的多回合谈判，为代理型人工智能开辟了新的途径。然而，现有的LLM代理大多忽视了情感在谈判中的功能作用，生成被动的、基于偏好的情感反应，这使它们容易受到对手的操纵和策略性利用。
### Innovation
为了填补这一空白，本文提出了EvoEmo，一种进化强化学习框架，优化谈判中的动态情感表达。EvoEmo将情感状态转换建模为马尔可夫决策过程，并利用基于种群的遗传优化来进化各种谈判场景中的高回报情感策略。此外，本文还提出了一种评估框架，其中包括两种基线方法——原生策略和固定情感策略——用于情感感知谈判的基准测试。
### Conclusion
广泛的实验和消融研究表明，EvoEmo 一直优于两种基线方法，实现了更高的成功率、更高的效率以及更多的买家节省。这表明适应性情感表达在使多回合谈判的LLM代理更加有效方面的重要性。
## 30. `cs.AI` - 评估AI共创游戏叙事的质量 [PDF](https://arxiv.org/pdf/2509.04239), [HTML](https://arxiv.org/abs/2509.04239)
### Authors
Arturo Valdivia,Paolo Burelli
### Background
本文提出了一种结构化的评估方法，利用德尔菲研究结构和叙述设计专家小组，目的是评估由生成式AI生成的游戏叙事的质量。研究结合了文献中的故事质量维度和专家见解，通过Kano模型框架来理解这些维度对玩家满意度的影响。
### Innovation
创新之处在于提出了一种结合德尔菲研究方法和Kano模型框架的评估方法，来系统地评价AI生成的游戏叙事。这种方法综合了故事质量的多个维度，并通过专家意见将其与玩家满意度联系起来。
### Conclusion
研究结果可以为游戏开发者提供指引，优先考虑在生成式AI辅助的协同创作过程中故事质量的关键方面，以提升玩家的满意度。
## 31. `cs.AI` - Meta-Policy Reflexion：资源高效的大语言模型代理可复用反思记忆和规则可接纳性 [PDF](https://arxiv.org/pdf/2509.03990), [HTML](https://arxiv.org/abs/2509.03990)
### Authors
Chunlong Wu,Zhibo Qu
### Background
大型语言模型（LLM）代理在单任务上的表现非常出色，但往往会在重复任务失败、探索效率低下以及跨任务适应性不足等方面出现问题。现有的反思策略（例如Reflexion、ReAct）能够提升每轮行为的表现，但会产生临时性、特定任务的痕迹，并不会跨任务重复利用。基于强化学习的方法可以生成可以推广的策略，但需要大量的参数更新和计算资源。本文提出了Meta-Policy Reflexion (MPR)：一种混合框架，通过将LLM生成的反思合并到结构化、类似谓词的Meta-Policy Memory (MPM)中，并在推理时通过软记忆指导解码和硬规则可接纳性检查机制应用该记忆，来解决上述问题。
### Innovation
引入了Meta-Policy Reflexion（MPR）框架，该框架把来自大语言模型的反思以结构化的方式存储在元策略记忆库中，并通过软记忆指导解码和硬规则可接纳性检查来应用这种记忆。MPR在外化可复用的纠正知识时不需要模型权重更新，通过强制执行领域约束来减少不安全或无效行为，保留语言基反射的适应性。该框架提供正式化的MPM表示，呈现更新和解码算法，并用AlfWorld为基础的实验协议验证了该方法，结果显示MPR相比反思基线有稳定的改进，硬规则可接纳性进一步提高了稳定性。
### Conclusion
实验数据显示，相比反思基线，MPR在执行准确性和鲁棒性方面有持续改进；规则可接纳性进一步提高了稳定性。分析方法背后的机理，并讨论了其扩展性和失败模式，概述了未来多模态和多代理扩展的方向。
## 32. `cs.AI` - 提高AlphaZero算法在测试环境变化中的鲁棒性 [PDF](https://arxiv.org/pdf/2509.04317), [HTML](https://arxiv.org/abs/2509.04317)
### Authors
Isidoro Tamassia,Wendelin Böhmer
### Background
AlphaZero框架提供了一种将蒙特卡洛规划与预先训练的策略价值神经网络提供的先验知识结合起来的标准方法。然而，AlphaZero通常假设在测试时环境不会改变，这限制了它的应用范围。本文分析了在可能变化的测试环境中部署AlphaZero代理的问题，并展示了如何通过对标准框架进行简单的修改来显著提升性能，即使在可用的规划预算较低的情况下也是如此。
### Innovation
提出了通过简单的框架修改提高AlphaZero算法在测试环境变化中的鲁棒性的方法，即使在有限的规划预算下也能实现显著的性能提升。并公开提供了实现代码，以供验证和支持进一步研究。
### Conclusion
通过简单的框架修改，AlphaZero算法在面对测试环境中可能的变化时也能表现出更好的性能，即使资源有限。该研究为AlphaZero和类似算法在实际应用中的推广提供了新的可能性。
## 33. `cs.AI` - 人类在AI上的生物优势 [PDF](https://arxiv.org/pdf/2509.04130), [HTML](https://arxiv.org/abs/2509.04130)
### Authors
William Stewart
### Background
随着人工智能的进步，未来有可能开发出具有超越人类能力的人工通用智能(AGI)系统，这些系统在理解、推理、问题解决、创造和进化方面将远超人类，甚至人类难以匹配或理解。这引发了是否未来AI将超越人类，成为领导宇宙的“数字物种”的问题。然而，深入思考后发现，与人类的区别不在于大脑，而是中央神经系统(CNS)，它使我们能够与物理现实进行沉浸式整合，并体验包括痛苦、快乐、苦难和爱在内的各种情感。这种情感体验使我们能够理解行为的后果，从而发展出可持续的伦理系统，并成为宇宙的领导者。中央神经系统无法被制造或模拟，必须以生物构造的方式生长。即使意识的形成也不会使AI系统超越人类。因此，尽管AI系统在几乎所有方面都可能超越人类，并改变我们的社会，但领导宇宙的最坚实基础永远是DNA，而不是硅基技术。
### Innovation
提出中央神经系统是人类超越AI的重要优势，而非大脑。强调虽然AGI可能在许多功能上超越人类，但人类的情感理解和伦理系统的建立依赖于生物构造的神经系统，无法通过人造或模拟实现。此外，这是首次明确指出生物学的基础（DNA）相比电子构造（硅基）更适合成为宇宙的领导基础。
### Conclusion
即使AGI系统在精确理解和实现伦理系统方面可能超越人类，人类的生物优势（特别是情感理解和伦理系统的背景）仍然是不可替代的。因此，领导宇宙的基础应该依赖于生物学，而不是硅基技术。
## 34. `cs.AI` - Markov逻辑网络的大域大小渐近性 [PDF](https://arxiv.org/pdf/2509.04192), [HTML](https://arxiv.org/abs/2509.04192)
### Authors
Vera Koponen
### Background
这篇论文探讨了Markov逻辑网络（MLN）作为领域大小趋于无穷时的概率分布性质。背景在于MLN在一个无限领域的结构集合上确定了一个概率分布。论文聚焦于三种具体的MLN实例及其随机结构在领域大小趋于无穷时的性质。
### Innovation
创新点在于研究了不同类型的MLN在随机结构中表示的不同极限行为，并提出了一个“δ-近似的0-1法则”，特别是在图结构中限制三元环的数目。此外，论文揭示了用于MLN的软约束的不同选择可能对极限行为产生显著影响，以及量化门控MLN和提升贝叶斯网络在大域大小下的不相比较性。
### Conclusion
研究结论表明，根据MLN所使用的软约束类型，随机结构的极限行为可以非常不同，并且这些约束的权重可能或可能不会影响极限行为。利用特定例子展示了量化门控MLN和提升贝叶斯网络在大域下的不可比性质，证明了在大域上MLN的概率分布几乎完全集中在不均匀的结构空间部分。
## 35. `cs.AI` - 基于语音的认知筛查：大规模语言模型适应策略的系统评估 [PDF](https://arxiv.org/pdf/2509.03525), [HTML](https://arxiv.org/abs/2509.03525)
### Authors
Fatemeh Taherinezhad,Mohamad Javad Momeni Nezhad,Sepehr Karimi,Sina Rashidi,Ali Zolnour,Maryam Dadkhah,Yasaman Haghbin,Hossein AzadMaleki,Maryam Zolnoori
### Background
大约一半的美国成年人患有阿尔茨海默病及相关痴呆症，但尚未被诊断。基于语音的筛查方法因其可扩展性而被作为一种检测手段。该研究对比了使用DementiaBank语音数据集的大规模语言模型（LLM）适应策略，评估了九种仅文本模型和三种多模态文本-音频模型的效果。
### Innovation
研究采用了多种适应策略，包括上下文学习、示范选择策略、推理增强提示、参数高效微调以及多模态整合。这些策略显著影响了基于语音的痴呆症检测效果。结果显示，基于类中心的示范能实现最佳的上下文学习表现，推理可以提升小型模型的效果，而词级微调通常产生最佳分数。为表现不佳的模型添加分类头能大幅提升其性能。多模态模型中的音频-文本系统虽有良好表现，但未超过最佳的仅文本模型。
### Conclusion
研究强调了适应策略，包括示范选择、推理设计和调优方法，对基于语音的痴呆症检测至关重要。适当地调优的开放权重模型可以匹敌甚至超越商用系统。
## 36. `cs.AI` - 心理增强的AI代理 [PDF](https://arxiv.org/pdf/2509.04343), [HTML](https://arxiv.org/abs/2509.04343)
### Authors
Maciej Besta,Shriram Chandran,Robert Gerstenberger,Mathis Lindner,Marcin Chrapek,Sebastian Hermann Martschat,Taraneh Ghandi,Patrick Iff,Hubert Niewiadomski,Piotr Nyczyk,Jürgen Müller,Torsten Hoefler
### Background
本文介绍了一种名为MBTI-in-Thoughts的框架，通过基于心理学的人格调节来提高大型语言模型（LLM）代理的有效性，采用了迈尔斯-布里格斯类型指标（MBTI），通过提示工程将代理与特定的人格原型联系起来，从而控制行为的两个基础心理维度：认知和情感。研究表明，这种人格预处理能够一致地产生可解释的行为偏见，并且能够在不同任务中观察到成效。此外，框架支持对结构化多代理通信协议进行实验，发现互动前的自我反思能改善合作和推理质量。为确保特质持久性，集成16个性特征测试进行自动化验证。尽管主要关注MBTI，但该方法还显示了能够无缝适用于其他心理框架，如五大人格特质、HEXACO或九型人格。
### Innovation
提出了MBTI-in-Thoughts框架，利用心理测试（如MBTI）对大型语言模型进行个性化设定，以控制代理行为。该方法通过提示工程实现对认知和情感维度的调节，能在不同任务中展示一致且可解释的行为偏见。此外，还展示了该方法可以在其他心理框架中通用。
### Conclusion
通过将心理理论与LLM行为设计相结合，建立了未经过任何微调的心理增强AI代理的基础，支持对结构化多代理通信协议进行实验，并证实了互动前的自我反思能提升合作和推理质量。
## 37. `cs.AI` - 使用RAG方法及 fine-tuned Mistral 大型语言模型的多层级加密货币新闻分析 [PDF](https://arxiv.org/pdf/2509.03527), [HTML](https://arxiv.org/abs/2509.03527)
### Authors
Bohdan M. Pavlyshenko
### Background
本文研究了使用微调的 Mistral 7B 大型语言模型和检索增强生成（RAG）方法进行加密货币新闻的多层级多任务分析。微调后的模型能够生成带有情感评分的图形和文本摘要，并以 JSON 格式表示。多层级分析通过进行层次堆叠，将图形摘要和文本摘要以及摘要的摘要汇聚成综合报告，从而提供加密货币新闻的互补视角。
### Innovation
本文的创新之处在于提出了使用 Mistral 7B 预训练模型进行多层级加密货币新闻分析的新方法。该模型使用 4 位量化并通过 PEFT/LoRA 方法细调，将加密货币新闻表示为知识图，从而有效消除大型语言模型的幻觉问题。这种方法能够提供丰富的定性和定量分析，为加密货币市场分析提供重要见解。
### Conclusion
研究结果表明，使用 fine-tuned Mistral 7B 大型语言模型进行多层级加密货币新闻分析，能够进行有效的定性和定量分析，为市场参与者提供重要的参考信息。这种方法能够有效地整合多层级汇总，提供加密货币新闻的全面视角，并能够消除语言模型可能产生的幻觉。
## 38. `cs.AI` - QuesGenie：智能多模态问题生成 [PDF](https://arxiv.org/pdf/2509.03535), [HTML](https://arxiv.org/abs/2509.03535)
### Authors
Ahmed Mubarak,Amna Ahmed,Amira Nasser,Aya Mohamed,Fares El-Sadek,Mohammed Ahmed,Ahmed Salah,Youssef Sobhy
### Background
在当今信息丰富的时代，学习者可以访问丰富的教育资源，但缺乏针对这些资源定制的练习材料，这构成了一个显著的挑战。本项目通过开发一个能够从多种内容格式自动生成多样化问题类型的多模态问题生成系统，解决了这一问题。这个系统包括四个主要组件：多模态输入处理、问题生成、基于人类反馈的强化学习（RLHF）以及端到端的互动界面，以填补这一空白，为自动化、可扩展和智能的问题生成奠定基础，同时权衡资源效率、健壮的功能性和良好的用户体验。
### Innovation
本项目创新地开发了一个多模态问题生成系统，该系统能够自动从多种内容格式生成多样化的问题类型，同时通过基于人类反馈的强化学习（RLHF）来优化问题生成的质量。此外，系统还具有高效的用户界面和功能，确保了学习者的良好体验。
### Conclusion
本项目为自动化、可扩展和智能的问题生成奠定了基础，通过合理平衡资源效率、功能稳健性和用户体验，为提高学习效率提供了新的解决方案。
## 39. `cs.AI` - 通过推理时知识图构建提高LLMs的事实准确性 [PDF](https://arxiv.org/pdf/2509.03540), [HTML](https://arxiv.org/abs/2509.03540)
### Authors
Shanglin Wu,Lihui Liu,Jinho D. Choi,Kai Shu
### Background
大型语言模型（LLMs）经常难以产生事实一致的答案，主要受限于它们的参数记忆。检索增强生成（RAG）方法通过在推理过程中引入可信来源的外部知识来解决这一问题。然而，此类方法通常将知识视为无结构文本，限制了其支持组合推理和发现事实不一致的能力。
### Innovation
提出了一种新的框架，该框架在推理过程中动态构建和扩展知识图（KGs），结合了LLMs内部提取的知识和外部来源检索到的信息。该方法首先通过提示从问题中提取种子KG，然后通过LLM的潜在知识进行迭代扩展。图通过外部检索进一步细化，增强事实覆盖率并纠正错误。
### Conclusion
在三个不同的事实问答基准测试上评估了该方法，展示了在事实准确性、答案精度和可解释性方面相对于基础提示和静态KG增强方法的一致改进。研究结果表明，在结构化、解释性和可扩展的层面上增强LLMs事实准确性的一种有前途的方向为推理时构建KG。
## 40. `cs.AI` - AR$^2$: 对抗强化学习在大型语言模型中的抽象推理 [PDF](https://arxiv.org/pdf/2509.03537), [HTML](https://arxiv.org/abs/2509.03537)
### Authors
Cheng-Kai Yeh,Hsing-Wang Lee,Chung-Hung Kuo,Hen-Hsen Huang
### Background
抽象是识别和提炼复杂问题中的基本计算模式的能力，在计算机科学中是一个基础技能，对于人类问题解决者和编码导向的大型语言模型（LLMs）至关重要。尽管在使用强化学习（RL）进行代码生成的训练方面取得了进展，但现有的大多数方法主要集中在表面模式识别上，忽略了对抽象的显式训练。
### Innovation
本文提出了AR$^2$（对抗强化学习进行抽象推理），这是一种新颖的框架，明确旨在增强LLMs的抽象能力。AR$^2$利用教师模型将核心问题转化为富含叙述性和挑战性的描述，而不改变其基本逻辑。同时，学生编码模型被训练解决这些复杂叙述性问题，从而提取其背后的计算内核。实验结果显示，AR$^2$在解决未见过的、具有挑战性的编程任务方面显著提高了学生模型的准确性，表明抽象是提升LLMs泛化能力的关键技能。
### Conclusion
AR$^2$在学生模型解决未见过的、具有挑战性的编程任务上取得了显著的准确性提升，强调了抽象在增强LLMs泛化能力方面的关键作用。
## 41. `cs.AI` - ArcMemo: 通过终身LLM记忆进行抽象推理组合 [PDF](https://arxiv.org/pdf/2509.04439), [HTML](https://arxiv.org/abs/2509.04439)
### Authors
Matthew Ho,Chen Si,Zhaoxiang Feng,Fangxu Yu,Zhijian Liu,Zhiting Hu,Lianhui Qin
### Background
在推理过程中，大语言模型能够进行越来越长且能力更强的推理过程，但一旦上下文窗口重置以处理新的查询，这些过程中发现的模式和见解便会被立即丢弃。外部存储可以保留这些发现，并且最近的研究表明，这种做法在需要大量推理的任务中可以带来明显的益处。论文探讨了将这些发现从基于实例的记忆条目（如精确的查询/响应对或紧密耦合于原始问题上下文的摘要）扩展到基于概念的记忆条目，这些条目是从解决方案过程中蒸馏、以自然语言存储并且可重用的模块化抽象。未来查询中，相关概念将被选择性地检索并整合到提示中，从而实现测试时间的连续学习而无需更新权重。这种方法通过导入从进程提取抽象概念和检索用于新查询的记忆的新策略，促进了记忆的重用并使其可以随着经验的增加而扩展。在具有挑战性的ARC-AGI基准测试中，方法在无记忆基线的相对性能上提高了7.5%，并且性能随着推理计算量的增加而继续提高。更为关键的是，研究发现基于抽象概念的记忆设计最为一致，即使在所有测试的推理计算尺度上都超过了基线。此外，研究还证实了在测试时间动态更新记忆相比于固定不变的记忆会在增加尝试次数时获得更好的性能，支持了解决更多问题并通过对更多模式进行记忆可以进一步解决问题的自我改进假设。
### Innovation
论文通过引入一种基于概念的记忆机制，拓宽了大语言模型在推理能力上的应用边界。具体而言，论文提出了一种新的方法，即ArcMemo，该方法能够提取并存储简化的问题解决方案，这些简化的信息随后可以根据需要检索用于未来的查询中。这种方法不仅提高了系统在推理任务上的效率和准确性，还能够让模型在测试过程中实现持续学习，无需调整模型权重。实验结果表明，这种方法能够取得显著的性能提升，并且其效果会随着计算资源的增加而增强。此外，研究还发现，基于抽象概念的记忆设计比基于实例的记忆条目更为一致且更加有效，这种动态更新的记忆体系也比固定的记忆体系表现出更好的性能。
### Conclusion
ArcMemo方法通过引入一种新的基于概念的记忆机制，成功地提升了大语言模型在推理任务上的性能。该方法的实验结果表明，在ARC-AGI基准测试中，其相对性能提升了7.5%，并且性能随着推理计算量的增加而持续提升。最为重要的是，基于抽象概念的记忆设计在所有测试的推理计算尺度上都超过了基线，而动态更新的记忆体系在测试时间相比固定的记忆体系表现出更优的性能，这进一步证实了通过解决更多问题并记忆更多模式可以实现一种形式的自我改进。
## 42. `cs.AI` - 基于AI工具的多模态提案以增强信息跨评估 [PDF](https://arxiv.org/pdf/2509.03529), [HTML](https://arxiv.org/abs/2509.03529)
### Authors
Alejandro Álvarez Castro,Joaquín Ordieres-Meré
### Background
盈余电话是一种独特丰富且半结构化的财务交流源，融合了正式的管理层评论和分析师的非正式对话。尽管最近在财务情感分析方面的进展已经开始整合多模态信号（如文本内容和语音音调），大多数系统仍然依赖于基于文档或句子的扁平模型，未能捕捉到这些互动的分层话语结构。因此，本文旨在通过将盈余电话编码为层次话语树，引入一种新的多模态框架，旨在生成语义丰富且结构意识强烈的嵌入表示。每个节点包含一段独白或一个问题-回答对，这些内容都用到来自文本、音频和视频的情感信号以及共现得分、主题标签和答案覆盖评估的结构元数据的丰富。
### Innovation
本文提出了一种两阶段的变压器架构：第一个阶段通过对比学习在节点级别编码多模态内容和话语元数据，第二个阶段则综合生成整个会议的全局嵌入。实验结果表明，由此产生的嵌入形成了稳定且具有实际意义的表征，反映了情感语气、结构逻辑和主题一致。该方法不仅对财务报告具有实际应用价值，还能用于诸如远程医疗服务、教育和政治对话等其他高风险非正式沟通领域，提供了多模态话语表示的稳健和可解释方法，有助于下游任务如财务预测和话语评估，同时也提供了一种适用于涉及高风险沟通的其他领域的通用方法。
### Conclusion
本文提出的方法对于下游任务如财务预测和话语评估具有实际应用价值，同时也提供了一种适用于涉及高风险沟通的其他领域的通用方法。
## 43. `cs.AI` - 乌干达移动货币服务的软件安全审查： Jim博士推特情绪分析 [PDF](https://arxiv.org/pdf/2509.03545), [HTML](https://arxiv.org/abs/2509.03545)
### Authors
Nsengiyumva Wilberforce
### Background
乌干达移动货币服务的应用显著提升了金融包容性，但其安全性问题仍然非常重要。2025年8月因一名手机窃贼利用某受害者账户提取资金并获取贷款一事引发的#StopAirtelThefty 微博运动曝光了公众对移动货币安全性的深切担忧。本次研究通过定性分析研究了这段时期内公众提出的投诉，提炼出关键的安全漏洞主题和用户不满情绪，从而为理解乌干达移动货币监管与运营环境中的安全问题提供了重要视角。
### Innovation
本研究采用定性分析方法，系统地研究了#StopAirtelThefty 微博运动期间用户提出的投诉，提取了重要的安全漏洞和用户不满主题，揭示了用户的特定安全需求，填补了关于用户感知与移动货币安全性之间的知识空白。研究将公众情绪与乌干达移动货币的监管环境结合起来，为理解和改进移动货币服务的安全性提供了新的见解。
### Conclusion
本研究的结论提供了对乌干达移动货币服务中用户安全体验的具体洞见，并指出了对未来安全数字金融的政策和实践建议。研究结果为移动货币提供商、政策制定者和乌干达的数字金融未来发展提供了关键的政策建议与指导。
## 44. `cs.AI` - BiND: 用于脑-计算机接口中准确双臂轨迹预测的神经鉴别器-解码器 [PDF](https://arxiv.org/pdf/2509.03521), [HTML](https://arxiv.org/abs/2509.03521)
### Authors
Timothee Robert,MohammadAli Shaeri,Mahsa Shoaran
### Background
从颅内记录解码双侧手部运动仍然是脑-计算机接口（BCIs）中的关键挑战，因为大脑神经表征的重叠和跨手的非线性交互作用。这使得目标的手部运动类型和精确的二维手部速度预测变得复杂和困难。
### Innovation
提出了BiND（双侧神经鉴别器-解码器），这是一种两阶段模型，首先分类运动类型（单侧左或右或双侧），然后使用专门为这种任务设计的基于GRU的解码器，并辅以相对于实验时间段的时序索引，以预测连续的二维手速度。BiND在现有的六种最先进的模型（支持向量回归 SVR，极端梯度提升 XGBoost，前馈神经网络 FNN，卷积神经网络 CNN，变换器 Transformer，门控递归单元 GRU）的基础上，实现了更好的双侧路径预测性能，并表现出比其他基准模型更高的对会话间变异性鲁棒性。
### Conclusion
BiND 提出了任务感知鉴别和时间建模在提高双侧解码器性能和鲁棒性方面的重要性，从而为脑-计算机接口中的双侧手部运动解码提供了更准确的解码方案。
## 45. `cs.AI` - 长文本生成中实时检测虚构实体的方法 [PDF](https://arxiv.org/pdf/2509.03531), [HTML](https://arxiv.org/abs/2509.03531)
### Authors
Oscar Obeso,Andy Arditi,Javier Ferrando,Joshua Freeman,Cameron Holmes,Neel Nanda
### Background
大语言模型现在在高风险应用中被广泛应用，如医疗咨询或法律建议，这可能导致严重危害。现有幻觉检测方法要么只能处理短的实事查询，要么需要成本高昂的外部验证，因此在实际应用中不切实际。论文提出了一种低成本、可扩展的方法，用于实时识别长文本生成中的虚构标记，并将其有效地扩展到70B参数模型。该方法关注实体级幻觉（例如伪造的名称、日期、引用），而非声明级，自然映射到标记级别的标签，并允许实时检测。
### Innovation
开发了一种基于网络搜索的注释方法，用于标注模型响应中的实体级标签。该方法不仅适用于长文本生成，还在数学推理任务中表现出有效检测错误答案的能力，表明其具有更广泛的应用潜力。论文提供了可训练有效幻觉分类器的标记数据集，且成本较低。这些分类器在多种模型中表现出色，尤其是在处理长文本响应时。此外，即使仅使用实体级标签进行训练，它们也能有效检测错误答案，展示了模型间的泛化能力。
### Conclusion
论文提出的方法为大规模、实用的幻觉检测提供了一种前景广阔的新途径，同时公开发布了数据集以便重复利用，进一步促进了研究的发展。
## 46. `cs.AI` - Oruga：代表系统理论的形象 [PDF](https://arxiv.org/pdf/2509.04041), [HTML](https://arxiv.org/abs/2509.04041)
### Authors
Daniel Raggi,Gem Stapleton,Mateja Jamnik,Aaron Stockdill,Grecia Garcia Garcia,Peter C-H. Cheng
### Background
人类利用各种表征形式灵活地解决问题，绘制图表、转换表征，并在不同领域使用富有创意的类比方法。为了使机器更加符合人类的使用，需要赋予它们这种能力。研究人员之前开发了表示系统理论（RST），用于研究表征及其转换的结构，但尚未实现这种理论。本研究旨在将RST的概念和转换机制实际应用于Oruga系统中。Oruga借鉴了RST的核心概念，包括数据结构和一种用于传达核心信息的语言。它还具有结构转移引擎，能够执行特定的表征转换操作。这是为了更好地利用RST，促进人机交互的流畅性和效率。
### Innovation
本研究将RST的概念和原理在Oruga系统中实现，引入了一个结构转移引擎，该引擎可以执行特定的表征转换操作。这种工作方法的目标是更好地模拟人类处理不同领域信息的方式，并增强机器的灵活性和适应性，使其更加接近人类的形象。此外，Oruga通过一种新的编程语言增强了与核心的沟通方式，使得表征转换过程更为透明和可控。
### Conclusion
Oruga是代表系统理论的一个实现，通过核心数据结构、语言通信和结构转移引擎，该系统能够执行RST中的表征转换。Oruga的成功实现将推进人工智能在表征领域的发展，并改善人机交互的兼容性。
## 47. `cs.AI` - 打破镜子：基于激活的LLM评估器自我偏好缓解 [PDF](https://arxiv.org/pdf/2509.03647), [HTML](https://arxiv.org/abs/2509.03647)
### Authors
Dani Roytburg,Matthew Bozoukov,Matthew Nguyen,Jou Barzdukas,Simon Fu,Narmeen Oozeer
### Background
大型语言模型（LLMs）越来越多地作为自动化评估器使用，但它们存在‘自我偏好偏差’：倾向于偏好自己的输出而忽视其他模型的输出。这种偏差阻碍了评估管道的公平性和可靠性，特别是在偏好调优和模型路由等任务中。本文探讨了小量引导向量是否可以在推理阶段缓解这一问题，而无需重新训练。
### Innovation
本文提出了一个精心设计的数据集，将自我偏好偏差区分为合理的自我偏好和不合理的自我偏好。接着使用对比激活添加（CAA）和基于优化的方法构建了引导向量。结果显示，引导向量可以将不合理的自我偏好偏差降低97%，显著优于提示和直接偏好优化的基线方法。此外，引导向量在合法的自我偏好和无偏见一致性的稳定性较低，表明自我偏好可能涉及多个或非线性的方向。
### Conclusion
引导向量在缓解LLM作为评估器的自我偏好偏差方面具有潜力，但也显示出其在合法自我偏好和无偏见一致性上的局限性，这强调了需要更多稳健干预的重要性。
## 48. `cs.AI` - 显而易见的优化器：利用损失景观诱导度量进行训练 [PDF](https://arxiv.org/pdf/2509.03594), [HTML](https://arxiv.org/abs/2509.03594)
### Authors
Thomas R. Harvey
### Background
在训练神经网络时，通常采用的优化器如SGD、Adam、AdamW和Muon，面对损失景观时，可能无法充分利用其几何结构信息。研究者发现，当损失景观嵌入到高维空间时，存在着自然的黎曼度量，这一度量也适用于常见的损失景观可视化，因此提出了一种新型优化器，旨在直接利用这一几何视角和诱导度量进行训练.
### Innovation
该研究创新地提出了通过利用损失景观在更高维度空间中自然诱导出的黎曼度量进行优化的新方法。通过这种方法，提出了一种新型优化器，并与现有的SGD、Adam、AdamW和Muon等方法进行了对比。研究表明，这种新优化器在低维度情况下表现优异，并能够略微提升状态-of-the-art方法的性能。此外，该优化器具有理论上的良好特性，如自动调整学习率和有效剪辑梯度，以及自然选择去耦权重衰减等.
### Conclusion
实验证明，这种新型优化器在低维度情况下非常有效，并在计算复杂度与Adam相当的情况下，提供了轻微的状态-of-the-art方法改进。该基本方法还可以与其他现有预处理方法结合使用，进一步增强其性能。
## 49. `cs.AI` - 梯度动力学的见解：梯度自缩放归一化 [PDF](https://arxiv.org/pdf/2509.03677), [HTML](https://arxiv.org/abs/2509.03677)
### Authors
Vincent-Daniel Yun
### Background
梯度动力学在决定深度神经网络的稳定性和泛化能力方面起着关键作用。本文通过经验分析了梯度方差和标准差在训练过程中的演变，展示了这种变化在卷积网络中的跨层和全局一致性。
### Innovation
提出了一种无需超参数的梯度归一化方法，该方法将梯度缩放与它们的自然演变对齐，从而防止无意中的放大，稳定优化过程并保留收敛保证。
### Conclusion
实验结果表明，在具有挑战性的CIFAR-100基准测试中，本文方法在ResNet-20、ResNet-56和VGG-16-BN上保持或提高了测试精度，即使在强泛化条件下也是如此。此外，本文的研究还强调了直接跟踪梯度动力学的重要性，目的是弥合理论期望与实际情况之间的差距，并为未来优化研究提供见解。
## 50. `cs.AI` - E-ARMOR: Edge case Assessment and Review of Multilingual Optical Character Recognition [PDF](https://arxiv.org/pdf/2509.03615), [HTML](https://arxiv.org/abs/2509.03615)
### Authors
Aryan Gupta,Anupam Purwar
### Background
多语言、噪声和多样化的现实世界图像中的光学字符识别（OCR）仍然是OCR系统的一个显著挑战。大型视觉-语言模型（LVLMs）的兴起引起了人们对它们超越固定OCR管道的能力的兴趣。本研究调查了LVLMs在边缘计算环境中的应用，并评估了多种OCR系统在边缘部署中的性能及成本效率。
### Innovation
提出了一种名为Sprinklr-Edge-OCR的新型OCR系统，专门为了边缘部署优化。研究对五种最先进的LVLMs（InternVL、Qwen、GOT OCR、LLaMA、MiniCPM）和两种传统OCR系统（Sprinklr-Edge-OCR、SuryaOCR）进行了大规模对比评估，涵盖了包括准确性、语义一致性、语言覆盖率、计算效率（延迟、内存、GPU使用）和部署成本在内的多种指标。此外还特别分析了CPU环境下模型的性能，以更贴近实际应用。在结果中，Qwen在精确度上表现最佳，而Sprinklr-Edge-OCR在综合F1分数上表现最佳，在数据处理速度和成本上相对于LVLM来说具有显著优势。
### Conclusion
研究表明，即便在大规模语言模型的时代，传统的OCR系统在边缘部署中仍然是最优选择，因为它们具有较低的计算需求、低延迟和非常高的性价比。
## 51. `cs.AI` - treeX：密林点云中无监督树实例分割 [PDF](https://arxiv.org/pdf/2509.03633), [HTML](https://arxiv.org/abs/2509.03633)
### Authors
Josafat-Mattias Burmeister,Andreas Tockner,Stefan Reder,Markus Engel,Rico Richter,Jan-Peter Mund,Jürgen Döllner
### Background
近距离激光扫描能够提供详细的森林立地三维捕捉，但需要高效软件处理三维点云数据和提取单个树木。尽管最近的研究引入了深度学习方法进行树实例分割，但这些方法需要大型标注数据集和大量的计算资源。因此，存在一种资源高效的方法作为替代方案，即双重参数预设的无监督树X算法，该算法结合了基于聚类的主干检测和基于区域生长的树冠分割。该方法最初是为个人激光扫描（PLS）数据设计的，现在提供了适用于地面激光扫描（站定地面-LIDAR，TLS和PLS）和无人机载激光扫描（ULS）的数据预设参数。
### Innovation
本文提出了对树X算法的修订版本，该算法是一种结合基于聚类的主干检测和基于区域生长的树冠分割的无监督方法。修订版本减少了运行时间，提高了精度，并针对地面激光扫描和无人机载激光扫描数据提供了参数预设。此外，与当前的开源方法相比，该算法在精度上可以与最近的深度学习方法相媲美，特别是在数据特征与算法设计匹配的情况下，具有资源高效的优势，并可为深度学习模型的半自动标签生成提供辅助。
### Conclusion
该方法在六个公开数据集上进行了评估，并与六个开源方法进行了比较。对于地面激光扫描数据，我们的修订版本提高了实例检测F1分数，而我们的预设在无人机载激光扫描数据上实现了0.58的F1分数，而原始算法未能分割任何正确的实例。该方法为需要数据特征与方法设计相匹配的场景提供了一种资源高效的替代方案，并促进了深度学习模型的人工标签生成。为了促进更广泛的采用，我们提供了开源Python实现，即pointtree包。
## 52. `cs.AI` - 从联邦学习到$boldsymbol{text{X}}$学习：通过随机游走打破去中心化障碍 [PDF](https://arxiv.org/pdf/2509.03709), [HTML](https://arxiv.org/abs/2509.03709)
### Authors
Allan Salihovic,Payam Abdisarabshali,Michael Langberg,Seyyedali Hosseinalipour
### Background
本文提供了对新型分布式学习架构$boldsymbol{text{X}}$学习（$boldsymbol{text{X}}$L）的看法，该架构是对去中心化概念的一种扩展和概括。作者旨在提出$boldsymbol{text{X}}$L的愿景，介绍其尚未探索的设计考虑和自由度，强调其与图论和马尔可夫链之间的直观但并不直观的联系。
### Innovation
本文提出了一种新型的分布式学习架构$boldsymbol{text{X}}$L，它具有推广和扩展去中心化概念的目的。通过清晰介绍$boldsymbol{text{X}}$L与图论和马尔可夫链之间的联系，揭示了该架构背后的直观但不直接的机制。文章还提出了若干开放的科研方向，以激励后续研究。
### Conclusion
文章总结了$boldsymbol{text{X}}$L架构的重要性和开放性，并提出了未来研究的多个方向。作者希望通过这些进一步的研究，能够克服去中心化学习中的各种障碍。
## 53. `cs.AI` - MLSD: 一种增强跨目标和跨域立场检测的新 Few-Shot 学习方法 [PDF](https://arxiv.org/pdf/2509.03725), [HTML](https://arxiv.org/abs/2509.03725)
### Authors
Parush Gera,Tempestt Neal
### Background
当前立场检测方法往往在网络中的不同领域和目标之间表现不佳，主要原因在于如何有效地将源领域的知识迁移到新的目标领域，同时保证模型能够捕捉到不同领域和目标间的语义相似性和差异性。
### Innovation
提出了一种基于元学习的Few-Shot学习方法——MLSD，能够通过对三元组损失的学习来捕捉不同立场的目标之间的语义相似性和差异性，增强领域适应性。通过构建区分性嵌入空间，MLSD使得跨目标或跨域立场检测模型能够从新的目标领域中获取有用示例，从而提升整体的立场检测性能。
### Conclusion
通过在两个数据集中跨目标和跨域多种场景下的评估，MLSD相较于六种广泛使用的立场检测模型显示出显著的立场检测性能提升。
## 54. `cs.AI` - Efficient Virtuoso: 一种基于潜在扩散的变换器模型，用于目标导向的轨迹规划 [PDF](https://arxiv.org/pdf/2509.03658), [HTML](https://arxiv.org/abs/2509.03658)
### Authors
Antonio Guillen-Perez
### Background
自主车辆规划系统需要能够生成多样且合理的未来轨迹分布的能力，这是至关重要的。然而，尽管最近的生成模型展示了潜力，但在实现高保真度、计算效率以及精确控制方面仍面临重大挑战。该论文针对这一背景提出了一种新的方法——Efficient Virtuoso，一种条件潜在扩散模型，用于目标导向的轨迹规划。
### Innovation
该研究提出了一种新颖的两阶段归一化管线，首先按几何方面比率放缩轨迹，然后归一化得到的PCA潜在空间，以确保稳定的训练目标。降噪过程在低维度潜在空间中通过一个简单MLP降噪器高效地进行，该降噪器是基于一个强大的Transformer StateEncoder融合的丰富场景上下文进行条件化。此外，通过详细的去研究目标表示，研究提供了关键洞察：虽然单个终点目标可以解决战略模糊性，但更丰富、多步骤稀疏路线对于使能精确、高保真的战术执行是必要的，这与细腻的人类驾驶行为相呼应。本方法在一个名为‘Waymo Open Motion’的数据集上达到了最先进的性能（最小平均偏差minADE为0.25）。
### Conclusion
通过详细的目标表示的消融研究，研究揭示了，虽然单个终点目标可以解决策略上的模糊性，但更丰富、多步骤稀疏路线对于实现精确、高保真的战术执行至关重要，这与细致的人类驾驶行为相匹配。Efficient Virtuoso在其目标导向的轨迹规划任务中表现出了优越性，展示了它在生成合理和多样未来轨迹分布方面的优势。
## 55. `cs.AI` - 无线网络中的层级联邦基础模型用于多模态多任务智能：边缘学习与D2D/P2P启用雾学习架构的集成 [PDF](https://arxiv.org/pdf/2509.03695), [HTML](https://arxiv.org/abs/2509.03695)
### Authors
Payam Abdisarabshali,Fardis Nadimi,Kasra Borazjani,Naji Khosravan,Minghui Liwang,Wei Ni,Dusit Niyato,Michael Langberg,Seyyedali Hosseinalipour
### Background
基础模型(FMs)的兴起已重新塑造了机器学习的格局。随着这些模型的持续增长，利用来自无线设备的分布式数据变得越来越关键，这促使了联邦基础模型(FFMs)的出现。最近，FMs演进成为多模态多任务(M3T)FMs（例如GPT-4），能够处理多种模态和多种任务。这激发了一种新的未充分探索的范式：M3T FFMs。本文旨在探索M3T FFMs的新变体，即层级联邦基础模型(HF-FMs)。这些模型揭示了无线网络中的两个未注意的异质性维度，对这些新兴模型有直接影响：收集的模态异质性和在雾/边缘节点上执行的任务异质性。HF-FMs战略性地将M3T FMs的模块结构，包括模态编码器、提示、混合专家(MoEs)、适配器和任务头，与雾/边缘基础设施的层级特性相结合。此外，HF-FMs允许节点之间使用设备到设备(D2D)通信，这在可行时可以启用水平模块传输和节点间局部协同训练。
### Innovation
通过探索层级联邦基础模型(HF-FMs)，本文提出了新的变体，揭示了无线网络中的两个未注意到的异质性维度：收集的模态异质性和在雾/边缘节点上执行的任务异质性。HF-FMs不仅与层级雾/边缘架构相结合，而且允许在可行的情况下使用设备到设备(D2D)通信，实现水平模块传输和节点间局部协同训练。此外，本文为HF-FMs的开发提供了开源代码，旨在促进这一未充分探索领域的探索。
### Conclusion
为了展示其潜力，本文在无线网络环境中原型化了HF-FMs，并在市场上开源代码，以促进HF-FMs的探索和发展。
## 56. `cs.AI` - LuxDiT: Video 弥散变换器进行照明估计 [PDF](https://arxiv.org/pdf/2509.03680), [HTML](https://arxiv.org/abs/2509.03680)
### Authors
Ruofan Liang,Kai He,Zan Gojcic,Igor Gilitschenski,Sanja Fidler,Nandita Vijaykumar,Zian Wang
### Background
从单张图像或视频估计场景照明是计算机视觉和图形学领域的一个长期挑战。基于学习的方法受限于实际的地面真实高动态范围 (HDR) 环境图稀缺，这些图很昂贵且多样性有限。尽管最近的生成模型提供强大先验知识用于图像合成，但照明估计仍然困难，因为其依赖于间接视觉线索、需要推断全局（非局部）上下文、并恢复高动态范围输出。
### Innovation
本文提出了一种新颖的数据驱动方法 LuxDiT，该方法微调了视频弥散变换器以生成条件于视觉输入的 HDR 环境图。我们的模型在包含多种照明条件的大型合成数据集上训练，学习从间接视觉线索推断照明，并有效泛化到真实场景中。为了改进输入与预测环境图之间的语义对齐，我们提出了一种使用HDR全景数据集进行低秩适应微调的策略。LuxDiT 方法在定量和定性评估中均优于现有最先进的技术，提供了准确的照明预测，并带有实时的高角度频率细节。
### Conclusion
LuxDiT 方法通过生成条件于视觉输入的 HDR 环境图，有效解决了从单张图像或视频估计场景照明的挑战。该方法展示了在多样化的照明条件下泛化能力，并在真实场景中也能提供准确的照明预测，是现有技术的改进和提升。
## 57. `cs.AI` - 为ELA教育设计眼动分析：具有对话式AI支持的用户中心仪表盘 [PDF](https://arxiv.org/pdf/2509.03741), [HTML](https://arxiv.org/abs/2509.03741)
### Authors
Eduardo Davalos,Yike Zhang,Shruti Jain,Namrata Srivastava,Trieu Truong,Nafees-ul Haque,Tristan Van,Jorge Salas,Sara McFadden,Sun-Joo Cho,Gautam Biswas,Amanda Goodwin
### Background
眼动追踪提供丰富的学生认知和参与度的见解，但在面向课堂的教育技术中仍被低估，这是因为数据解释和访问的挑战。本文介绍了通过对五次研究的迭代设计和评估，为英语语言艺术(ELA)开发的眼动学习分析仪表板，这些研究涉及教师和学生。
### Innovation
本文探讨了用户中心设计和数据讲故事原则如何指导探究视网膜数据如何支持反思、形成性评价和教学决策。进一步展示了通过大型语言模型（LLM）驱动的对话式代理可以降低解读视网膜数据的认知障碍，通过促进与多模态学习分析的人机自然语言交互。
### Conclusion
本文提出了未来教育技术系统的设计建议，旨在整合课堂情境中的新型数据模态。
## 58. `cs.AI` - ARDO: 基于随机测试函数差分的一种弱形式深度神经网络方法用于椭圆和抛物线偏微分方程 [PDF](https://arxiv.org/pdf/2509.03757), [HTML](https://arxiv.org/abs/2509.03757)
### Authors
Wei Cai,Andrew Qing He
### Background
本文提出了一种使用深度学习技术求解偏微分方程（PDEs）及其相关问题的方法，即ARDO方法。该方法利用弱敌对形式，但将随机差分操作转移到测试函数上。这种框架的主要优点是相对于解神经网络是完全导数自洽的。这种方法特别适用于Fokker-Planck类型二阶椭圆和抛物线偏微分方程。
### Innovation
这种方法创新地将随机差分操作转移到测试函数上，而不是像传统的深度学习方法那样直接作用于解神经网络，从而使得整个框架完全导数自洽，避免了直接求解解网络导数的复杂性和不稳定性问题。
### Conclusion
该方法特别适用于Fokker-Planck类型的二阶椭圆和抛物线偏微分方程，能够提供一种新的解决问题的途径。
## 59. `cs.AI` - 自然隐变量：跨语义空间的隐变量稳定 [PDF](https://arxiv.org/pdf/2509.03780), [HTML](https://arxiv.org/abs/2509.03780)
### Authors
John Wentworth,David Lorell
### Background
假设有两个贝叶斯代理人为同一个环境各自学习了一个生成模型。这两个代理人的预测分布收敛了，即对环境中某个可观测变量的分布相同，但他们的生成模型包含不同的潜在变量。本文探讨在什么条件下，一个代理人的潜在变量可以确保是另一个代理人的潜在变量的函数。
### Innovation
给出了保证转换可能性的简单条件，即自然隐变量条件，并证明了这些条件在没有进一步约束情况下是最为通用的条件。更加关键的是，本文的定理在自然隐变量条件下的近似误差方面具有鲁棒性。
### Conclusion
自然隐变量条件是保证跨代理人的隐变量可转换性的最通用条件，并且这些结论对于实际应用来说是稳定的，即使存在近似误差时也是如此。
## 60. `cs.AI` - 不同iable熵正则化在几何和神经网络中的应用 [PDF](https://arxiv.org/pdf/2509.03733), [HTML](https://arxiv.org/abs/2509.03733)
### Authors
Ibne Farabi Shihab,Sanjeda Akter,Anuj Sharma
### Background
本文介绍了一种可微估计法，用于计算范围分段熵。范围分段熵是一种来自计算几何的新型概念，能够帮助算法适应输入数据的‘排序程度’。尽管范围分段熵在算法设计中提供了强有力的保证，但目前尚未将其用于深度学习。本文的工作在于首次提出了范围分段熵的可微近似方法，使得它可以作为可训练损失或正则化器使用，同时设计了一种新神经模块EntropyNet，能够将数据重新结构化为低熵形式，以加速下游的实例最优算法，并将熵正则化原则应用于Transformer注意力机制，直接对其施加熵正则化。
### Innovation
提出了范围分段熵的第一个可微近似方法，并设计了可重构低熵形式的EntropyNet神经模块。此外，还直接对Transformer的注意力机制施加了熵正则化，从而提高了注意力模式的结构化程度。文章的结果显示，该方法在保持准确性的前提下，可以显著提高计算效率；在几何处理中实现了最多4.1倍的运行时间加速，且误差几乎可以忽略不计；在深度学习中，则结果的精度相较于L1基线提升了6%，同时保持了80%的稀疏性。通过理论分析，提供了熵估计器的近似误差界，并通过详尽的消融实验验证了设计选择的有效性。
### Conclusion
本文的研究表明，熵限制的计算不仅在理论上具有美感，同时也是一个切实可行的学习、效率和结构化表示机制。此方法在多个领域均证明了其有效性和实用性。
## 61. `cs.AI` - STA-Net: 一种解耦形状和纹理注意力网络的轻量化植物病害分类 [PDF](https://arxiv.org/pdf/2509.03754), [HTML](https://arxiv.org/abs/2509.03754)
### Authors
Zongsen Qiu
### Background
在全球粮食安全需求上升的背景下，精确农业和基于深度学习的植物疾病诊断变得至关重要。然而，在边缘设备上部署高精度模型面临挑战。大多数轻量级网络使用适用于通用物体识别的注意力机制，这些机制难以捕捉到如不规则病斑形状和复杂纹理等细微的病理特征。为了克服这个问题，作者提出了一种两阶段的解决方案：首先，使用无训练的神经架构搜索方法（DeepMAD）来创建适用于边缘设备的有效网络基础架构；其次，引入形状-纹理注意力模块（STAM）。STAM将注意力机制分为两个分支——一个使用可变形卷积（DCNv4）进行形状感知，另一个使用Gabor小波库进行纹理感知。通过在公共的CCMT植物病害数据集上的实验验证，模型（STA-Net）以401K参数和51.1M FLOPs达到了89.00%的准确率及88.96%的F1得分，这表明STAM显著提高了性能，这里确认了通过分隔注意力机制整合领域知识是边缘部署精确农业AI的一个有前途的途径。
### Innovation
1. 提出了一个无训练的神经架构搜索方法（DeepMAD），用于为边缘设备创建高效的网络基础架构；2. 引入了形状-纹理注意力模块（STAM），该模块以分隔的方式处理形状和纹理信息，分别使用可变形卷积和Gabor小波库来进行形状感知和纹理感知。
### Conclusion
通过解耦形状和纹理注意力机制的方式，STA-Net在轻量级植物病害分类任务上取得了显著的性能提升，表明这种方法是促使精确农业AI部署在边缘设备上的一条可行路径。
## 62. `cs.AI` - 基于稀疏自动编码器的神经算子：函数空间中的模型恢复 [PDF](https://arxiv.org/pdf/2509.03738), [HTML](https://arxiv.org/abs/2509.03738)
### Authors
Bahareh Tolooshams,Ailsa Shen,Anima Anandkumar
### Background
虽然平托诺代表性假设表明神经网络在不同架构中趋于相似的表示，但神经算子的表示特性尚未得到充分探索，尽管在科学计算中的重要性日益增加，现有研究主要围绕稀疏自动编码器（SAEs）进行，而忽视了它们在提升空间和无限维函数空间中的应用潜力，缺乏对大型神经算子进行机械解释的能力。因此，本研究将统一表示问题归结为稀疏模型恢复问题，并提出了一种框架，该框架能够将稀疏自动编码器扩展到提升空间和无限维函数空间，从而增强了对大型神经算子的机械解释能力。
### Innovation
引入了一种将稀疏自动编码器扩展到提升空间和无限维函数空间的新框架，首次将稀疏自动编码器应用于神经算子的表示，以提升大型神经算子的表示性能和机械解释性。通过将稀疏自动编码器、提升自动编码器、以及神经算子进行比较，研究揭示了提升和操作模块引入了有益的归纳偏差，这有助于加快恢复过程，提高平滑概念的恢复精度，并在不同分辨率下保持鲁棒的推理能力.
### Conclusion
本研究证明了在函数空间中应用稀疏自动编码器对神经算子进行建模是一项有效的技术，不仅可以提高模型恢复的效率，还能提供对模型工作机理的更好理解，特别是在高分辨率下保持了对平滑概念的良好捕捉能力。
## 63. `cs.AI` - 学习对抗世界模型用于MARL中自动化课程生成 [PDF](https://arxiv.org/pdf/2509.03771), [HTML](https://arxiv.org/abs/2509.03771)
### Authors
Brennen Hill
### Background
世界模型能够推断和预测环境动态，这对具有实体智能的智能体至关重要。然而，这些模型的潜力往往受限于手工构建的训练环境在复杂性和隐形偏见方面的局限性。为了开发真正通用且鲁棒的智能体，需要一种环境能够与智能体一同扩展其复杂度。本文将环境生成问题重新定义为学习一个条件生成世界模型的问题。一个生成的攻击者智能体学习隐含的世界模型来为一队合作的防御者智能体合成逐步增加难度的挑战。与传统的预测不同，攻击者的目标是主动、目标导向的互动：它模拟和生成世界状态（即敌军单位的配置），以利用防御者的弱点。同时，有实体的防御者团队学习一个合作策略来克服这些生成的世界。这种共同进化机制产生一个自我扩展的学习阶梯，世界模型不断适应挑战智能体的决策策略，提供了一种有效的无穷新且相关训练场景的流。研究表明，框架促使世界模型学习生成侧翼和掩护阵型，而防御者学习协同集火和分散战术等复杂行为。我们的研究结果表明，对抗性共同进化是一个强大的方法，用以学习功能性世界模型，从而引导智能体朝更具策略深度和鲁棒性发展。
### Innovation
本文将环境生成问题重新定义为学习一个条件生成世界模型的问题，其中攻击者智能体为合作的防御者智能体生成逐步增加难度的挑战。这种共同进化机制能够自动从零开始生成动态和相关的训练场景，为智能体提供一个自我扩展的学习阶梯。这些机制有助于跟踪和挑战智能体的决策策略，从而提高它们的战略深度和鲁棒性，实现复杂行为的自然涌现，如侧翼和掩护阵型，以及协同集火和分散战术。
### Conclusion
对抗性共同进化是一个强大的方法，能够生成具有高度策略深度和鲁棒性的智能体所需的功能性世界模型。这种方法通过持续挑战智能体的决策策略，促进了复杂行为的自然发展，并为学习有效的多智能体策略提供了有效的训练范式。
## 64. `cs.AI` - SAMVAD：印度司法辩论动态模拟的多代理系统 [PDF](https://arxiv.org/pdf/2509.03793), [HTML](https://arxiv.org/abs/2509.03793)
### Authors
Prathamesh Devadiga,Omkaar Jayadev Shetty,Pooja Agarwal
### Background
理解和分析司法过程的复杂性对于评估司法系统的有效性与公平性至关重要。然而，关于司法团队的实证研究受到伦理和实践方面的显著障碍的限制。本文介绍了SAMVAD，一种创新型的多代理系统（MAS），旨在模拟印度司法系统中的司法过程。该系统通过大规模语言模型（LLM）以多方面模拟法官、检察官、辩护律师的角色，甚至多个审判法官。
### Innovation
本文的贡献在于将Retrieval-Augmented Generation (RAG)技术整合到系统中，该技术基于特定领域的印度法律知识库，包括印度刑法和印度宪法中的重要法律文件。这种RAG功能使得法官和律师代理能够生成合法的指令和论据，包括引用来源，从而提高了模拟的准确性和透明度。此外，多种审判法官代理会进行迭代的辩论轮次，处理案件事实、法律指令和论据，以达成基于共识的裁决。
### Conclusion
本文提供了可配置且可解释的MAS平台，旨在探索法律推理和群体决策动态在司法模拟中的应用，特别针对印度的法律背景，增强了法律验证性方面的能力。评估计划旨在评估系统性能、辩论质量及结果一致性。
## 65. `cs.AI` - 测量VLMs如何（而不仅仅是是否）建立共同理解 [PDF](https://arxiv.org/pdf/2509.03805), [HTML](https://arxiv.org/abs/2509.03805)
### Authors
Saki Imai,Mert İnan,Anthony Sicilia,Malihe Alikhani
### Background
当前的大规模视觉语言模型（VLMs）正在声称具有推理能力，但现有的基准测试大多在单轮或多轮问答设置中进行。然而，基础（grounding）是一个互动过程，人们通过持续的沟通逐渐建立共享的理解。现有评估模型通常关注短期目标的完成情况，而缺乏对互动过程中的长期理解建立的评估。
### Innovation
本研究引入了一套四个指标（接地效率、内容一致性、词汇适应性、人类相似性），以系统地评估VLM在互动接地环境中的表现。这套指标被应用在三种专有VLM的自我对话回合中，并与人类双人组进行比较。研究发现，任务完成分数并不能反映成功的接地过程，而图像-语句对齐度高的模型不一定能获得更好的任务表现。这为未来VLM接地的研究提供了框架。
### Conclusion
本研究表明，任务成功分数和图像-语句对齐度这两个指标并不足以全面评估VLM的互动接地能力。提出了新的评估指标和方法，并展示了这些新指标和方法可以帮助理解VLM在不同场景下的行为差异。
## 66. `cs.AI` - SiLVERScore：手语生成评估的语义感知嵌入 [PDF](https://arxiv.org/pdf/2509.03791), [HTML](https://arxiv.org/abs/2509.03791)
### Authors
Saki Imai,Mert İnan,Anthony Sicilia,Malihe Alikhani
### Background
现有的手语生成评估通常通过回译来进行，即生成的手语首先被识别回文本，然后与参考文本进行文本基础的比较。然而，这种两步的评估流程存在模糊性：它不仅无法捕捉手语的多模态特性（如面部表情、空间语法和语调），还会使得难以确定评价错误是源自手语生成模型还是用来评估它的翻译系统。
### Innovation
本文提出了SiLVERScore，这是一种新颖的语义感知嵌入评估指标，能够在联合嵌入空间中评估手语生成。贡献包括：(1) 识别现有指标的局限性，(2) 引入SiLVERScore进行语义感知评估，(3) 展示其对语义和语调变化的鲁棒性，(4) 探索跨数据集的一般化挑战。在PHOENIX-14T和CSL-Daily数据集上，SiLVERScore在正确与随机配对之间实现了近完美的区分（ROC AUC = 0.99，重叠<7%），显著优于传统指标。
### Conclusion
SiLVERScore在评估手语生成时具有更高的准确性和鲁棒性，能够更好地捕捉手语的多模态特性。
## 67. `cs.AI` - 从莱登到快乐岛：常数Potts模型作为博弈论模型的社区检测 [PDF](https://arxiv.org/pdf/2509.03834), [HTML](https://arxiv.org/abs/2509.03834)
### Authors
Lucas Lopes Felipe,Konstantin Avrachenkov,Daniel Sadoc Menasche
### Background
社区检测是数据科学中的基础问题，涉及将节点划分成不交集的社区。本研究从博弈论的角度重新审视常数Potts模型（CPM）用于网络的社区划分，强调其效率、鲁棒性和准确性。
### Innovation
1. 重新将CPM解释为潜在的和博弈，通过分解全局哈密顿量分解为局部效用函数，其中每个代理的局部效用增加与全局效用的增加相匹配。2. 利用这种等价性，证明了通过更好的反应动力学方法对CPM目标进行局部优化可以在伪多项式时间内收敛到均衡划分。3. 引入并关联了两种稳定性标准：一种是基于新型鲁棒性约束的严格标准，要求节点同时最大化邻居并最小化非邻居；另一种是基于加权和的目标函数的松弛效用函数，由一个分辨率参数控制。
### Conclusion
在使用初始划分来启动Leiden算法并带有部分真实社区信息的情景下，实验表明鲁棒划分可以帮助提高真实社区的恢复准确性。
## 68. `cs.AI` - 基于LLM的确认偏差模型的重力场回声室建模 [PDF](https://arxiv.org/pdf/2509.03832), [HTML](https://arxiv.org/abs/2509.03832)
### Authors
Joseph Jackson,Georgiy Lapin,Jeremy E. Thompson
### Background
社交媒体上的回声室在虚假信息传播中扮演着重要角色，但现有的模型往往忽视了个体确认偏差的影响。现有的回声室模型之一是「重力井」模型，它通过将回声室类比为空间重力井来建立。本文在该模型基础上引入了一个动态确认偏差变量，根据用户对信念强化内容的敏感度调整其吸引力强度。该变量通过比较用户的发帖历史和对众多观点帖子的回应来计算。这使得模型能够更准确地识别回声室并揭示信息健康度的社区层面标记。研究在19个Reddit社区上验证了该方法，表明能够更有效地检测回声室。
### Innovation
本文创新性地将基于LLM的动态确认偏差模型整合到重力井模型中，通过计算用户的确认偏差来调整用户的吸引力，从而更准确地识别回声室，支持对虚假信息传播的有效遏制。
### Conclusion
本文提出了一种系统性的框架，用于捕捉确认偏差在在线群体动态中的作用，使得能够更有效地识别回声室。通过标记这些高风险环境，该模型支持对虚假信息在最常见放大点的遏制。
## 69. `cs.AI` - Align-then-Slide：超长文档级机器翻译的完整评估框架 [PDF](https://arxiv.org/pdf/2509.03809), [HTML](https://arxiv.org/abs/2509.03809)
### Authors
Jiaxin Guo,Daimeng Wei,Yuanchang Luo,Xiaoyu Chen,Zhanglin Wu,Huan Yang,Hengchao Shang,Zongyao Li,Zhiqiang Rao,Jinlong Yang,Hao Yang
### Background
大语言模型（LLMs）带来了文档级机器翻译（doc-mt）的新时代，但其全文档输出挑战了现有的评估方法，这些方法假设句子级别的对齐。已有评估方法难以处理整个文档输出中的许多问题，因此需要新的评估框架来解决这些问题。
### Innovation
提出了Align-then-Slide框架，该框架包括两个阶段：1）对齐阶段，自动推断句子级别的源-目标对应关系，并重建目标以匹配源句子数量，解决遗漏和多对一或多对一的映射问题；2）n-Chunk滑动评价阶段，计算不同粒度下的平均评分，包括1-、2-、3-和4-Chunk。该框架在WMT基准测试和新收集的现实测试集上均与专家评估和人类判断保持高度一致，为文档级机器翻译系统提供有效的评估工具。
### Conclusion
实验结果显示，Align-then-Slide框架在与专家MQM排名和人类判断的比较中具有高度的相关性，改进了文档级机器翻译系统的评估方法，并通过产生的偏好数据有效训练了CPO并直接应用于GRPO作为奖励模型，有助于提高翻译质量，该框架是文档级机器翻译系统的准确、可靠和实用的评估工具。
## 70. `cs.AI` - INGRID: 使用大型语言模型的智能生成机器人设计 [PDF](https://arxiv.org/pdf/2509.03842), [HTML](https://arxiv.org/abs/2509.03842)
### Authors
Guanglu Jia,Ceng Zhang,Gregory S. Chirikjian
### Background
大型语言模型(LLMs)的引入加速了物理人工智能的进步，但当前的方法仍然受限于现有的机器人架构，特别是串联机构。这种硬件依赖性根本上限制了机器人智能的范围。
### Innovation
提出了INGRID（Intelligent Generative Robotic Design）框架，该框架通过深度集成互反螺纹理论和运动合成方法，实现了平行机器人机制的自动化设计。分解设计挑战为四个逐步任务：约束分析、运动关节生成、序列构建和完整机制设计。INGRID展示出生成具有固定和可变移动性的新型平行机制的能力，发现了文献中未记载的运动配置。通过三个案例研究验证方法，展示了INGRID如何帮助用户设计基于所需移动性的任务特异性平行机器人。
### Conclusion
通过在机构理论和机器学习之间架起桥梁，INGRID使没有专门机器人培训的研究人员能够创建自定义的平行机构，从而将机器人智能的进步与硬件限制脱钩。这项工作为机构人工智能奠定了基础，其中AI系统积极设计机器人硬件，可能转型地改变物理人工智能系统的开发方式。
## 71. `cs.AI` - 关于大型语言模型推理中可信度的全面综述 [PDF](https://arxiv.org/pdf/2509.03871), [HTML](https://arxiv.org/abs/2509.03871)
### Authors
Yanbo Wang,Yongcan Yu,Jian Liang,Ran He
### Background
长时推理（Long-CoT）的发展提高了各种任务中LLM的性能，包括语言理解、复杂问题解决和代码生成。这种范式使模型能够生成中间推理步骤，从而提高准确性和可解释性。然而，尽管有这些进展，CoT（基于推理）方法对语言模型可信度的影响仍缺乏全面的理解。因此，本文综述了推理模型和CoT技术的研究，从五个核心维度：真实性、安全性、鲁棒性、公平性和隐私出发，回顾了相关研究，分析了其方法、发现和局限性，并对未来的研究方向进行了总结。
### Innovation
本文创新性地汇总了推理模型和CoT技术的研究，从五个维度系统的梳理了可信度问题，并详细分析了这些方法的研究方法、成果和局限，为AI安全社区提供了最新进展的参考资源，指出了推理模型在保持模型可信度方面存在的潜在风险。
### Conclusion
尽管推理技术有望通过减轻幻觉、检测有害内容和提高鲁棒性来提升模型的可信度，但最新的推理模型在安全性、鲁棒性和隐私方面常常面临着相似或更大的风险。通过总结这篇综述文章，希望为AI安全社区提供一个及时和有价值的资源，以跟踪推理可信度领域的最新进展。
## 72. `cs.AI` - MillGNN: 学习多尺度能-滞后依赖关系以进行多变量时间序列预测 [PDF](https://arxiv.org/pdf/2509.03852), [HTML](https://arxiv.org/abs/2509.03852)
### Authors
Binqing Wu,Zongjiang Shang,Jianlong Huang,Ling Chen
### Background
多变量时间序列（MTS）预测在各种应用中至关重要。现有方法由于能够捕捉内在和跨变量依赖性而显示出有希望的结果，但这些方法通常忽略了在多分组等级上的时间序列上的能-滞后依赖性，无法捕捉复杂系统中的多层次能-滞后效应。
### Innovation
MillGNN 提出了一种基于图神经网络的新方法，用于学习多个分组级别的能-滞后依赖性以进行 MTS 预测，可以综合考虑变量之间和组之间的动态变化和衰减。MillGNN 的创新性主要表现在两个方面：(1) 层次特定的能-滞后图学习模块，该模块结合了交叉相关系数和从实时输入和时间滞后中派生的动态衰减特征，用于为每个层次学习能-滞后依赖性，可以使用统计解释性和数据驱动的灵活性建模演变中的能-滞后依赖关系；(2) 层次能-滞后消息传递模块，该模块以结构化方式传递多个分组级别的能-滞后消息，以同时传播层次内和层次间的能-滞后效应，能够用全面性和效率之间的平衡捕捉多尺度的能-滞后效应。
### Conclusion
在 11 个数据集上的实验结果表明，MillGNN 在长短期 MTS 预测方面优于 16 个最先进的方法，展示了其优越性。
## 73. `cs.AI` - 基于信心感知密集对应和视触觉能动力的空中服装操作 [PDF](https://arxiv.org/pdf/2509.03889), [HTML](https://arxiv.org/abs/2509.03889)
### Authors
Neha Sunil,Megha Tippur,Arnau Saumell,Edward Adelson,Alberto Rodriguez
### Background
操纵服装具有挑战性，因为服装的结构复杂、材料动力学变量且频繁自遮挡。现有的系统通常是将服装平面化或假设关键特征的可见性。因此，本文提出了一种结合了信心感知密集视觉对应和触觉监督动作策略的双臂视触觉框架，可以直接操作折叠和悬挂的服装。
### Innovation
该系统通过信任感知密集视觉对应模型和触觉监督抓取能动力，直接操作折叠和悬挂的服装。该模型通过自定义的高保真模拟数据集进行训练，并且利用分布性损失来捕捉布料对称性，生成对应的信任度估计。这些估计值引导活性状态机，基于感知不确定性适应折叠策略。同时，一个可通过高分辨率触觉反馈进行自我监督的视触觉抓取能动力网络，确定哪些区域是物理上可抓取的。这些创建了在低信心状态下的行动延迟，使得系统能够处理高度遮挡的桌面和空中配置。
### Conclusion
展示了我们的任务无关的抓取选择模块在折叠和吊挂任务中的应用，证明这种密集描述符提供了一种可重复使用的中间表示，适用于其他规划模式，如从人类视频演示中提取抓取目标，为更通用和可扩展的服装操作铺平了道路。
## 74. `cs.AI` - DQN和CFR在Leduc扣子牌中的欺骗行为分析 [PDF](https://arxiv.org/pdf/2509.04125), [HTML](https://arxiv.org/abs/2509.04125)
### Authors
Tarik Zaciragic,Aske Plaat,K. Joost Batenburg
### Background
在扣子牌游戏中，不可预测性（即欺骗）是一种重要的技能。人类玩家在玩游戏时会进行欺骗，但大多数计算机扣子牌研究侧重于胜率等绩效指标，而忽视了欺骗行为的研究。
### Innovation
本文研究了两种流行算法（基于强化学习的DQN和基于游戏理论的CFR）在简化版扣子牌游戏Leduc Hold'em中的欺骗行为。作者设计了一个实验，让DQN和CFR软件主体相互对战，并记录其行动。研究结果表明，两种算法都表现出了欺骗行为，但方式不同，这两种算法尝试以不同的频率进行欺骗，但成功欺骗的百分比大致相同，这表明欺骗是游戏中的一种重要方面，而不是算法所固有的。
### Conclusion
本研究表明，DQN和CFR都会表现出欺骗行为，但不同的算法会产生不同的欺骗策略。虽然两种算法尝试以不同的频率进行欺骗，但成功欺骗的百分比相似，表明欺骗是一种重要的游戏方式，而非特定算法的结果。未来的研究应探索不同风格的欺骗行为以及全盘游戏。
## 75. `cs.AI` - 基于多层感知机神经网络的肽组学预测模型在冠心病诊断中的应用 [PDF](https://arxiv.org/pdf/2509.03884), [HTML](https://arxiv.org/abs/2509.03884)
### Authors
Jesus Celis-Porras
### Background
冠心病是全球死亡的主要原因之一，增加了年度医疗支出。因此，亟需开发一种非侵入性的诊断方法来提高诊断效率和降低成本。本文利用遗传算法筛选出50个关键尿肽生物标志物，构建一个基于多层感知机神经网络的预测模型，使用合成少数类过采样技术（SMOTE）对治疗组和对照组各345人进行平衡，并采用分层验证策略进行训练。模型在三个隐藏层，每个隐藏层有60个神经元和一个输出层的配置下，达到了95.67%的精确率、95.65的F1得分、97.48的接收者操作特征曲线下面积（AUC）、0.9134的马修斯相关系数（MCC）和0.9131的科恩κ系数，表明该模型在冠心病的检测中非常准确可靠。
### Innovation
本文创新性地将肽组学与机器学习技术相结合，通过筛选尿肽生物标志物，构建了一个基于多层感知机神经网络的预测模型，能够提供一种精确的非侵入性冠心病诊断工具。该研究是利用神经网络技术在冠心病早期诊断中的初步尝试，也证明了利用尿肽生物标志物进行非侵入性诊断的可能性。
### Conclusion
本文构建的基于多层感知机神经网络的冠心病预测模型实现了较高的诊断精度，为冠心病的非侵入性诊断提供了有力支持。该模型具有广泛的应用前景，未来的研究还需要进一步验证其临床效果，并探索其他类型的生物标志物来改进诊断性能。
## 76. `cs.AI` - MTQA: Matrix of Thought for Enhanced Reasoning in Complex Question Answering [PDF](https://arxiv.org/pdf/2509.03918), [HTML](https://arxiv.org/abs/2509.03918)
### Authors
Fengxiao Tang,Yufeng Li,Zongzong Wu,Ming Zhao
### Background
复杂问题回答（QA）是自然语言处理（NLP）中的一个基础且具有挑战性的任务。虽然大规模语言模型（LLMs）在QA方面表现出色，但在面对复杂和抽象的QA任务时，由于推理能力不足，其性能会显著下降。过去的尝试如Chain-of-Thought (CoT) 和Tree-of-Thought (ToT) 虽然旨在增强LLMs的推理能力，但这些方法也面临诸如树结构中的层内冗余和链结构中的单路径等问题。尽管有些研究利用检索增强生成（RAG）方法来帮助LLMs进行推理，但有效地利用涉及到多个实体和多跳的大量信息仍然存在挑战。
### Innovation
本文提出了Matrix of Thought（MoT），这是一种新颖且高效的LLM思维结构。MoT通过“列单元通信”机制探讨问题的横向和纵向维度，使得LLMs能够进行多策略和深层次的思考，并减少列单元中的冗余性，从而增强推理能力。此外，还开发了一个事实校正机制，通过从检索的知识图三元组和原始文本中构建知识单元来增强初始知识，以提升LLMs的推理能力并纠正错误答案。此框架被命名为MTQA。
### Conclusion
实验结果显示，本框架在四个广泛使用的数据集上优于最新方法，F1和EM得分均显著提高，推理时间仅为基线方法的14.4%。证明了其在效率和准确性上的优势。相关代码可访问此链接：http://this.is.the/link.
## 77. `cs.AI` - 扩散生成模型与压缩感知相结合，应用于图像数据和金融时间序列 [PDF](https://arxiv.org/pdf/2509.03898), [HTML](https://arxiv.org/abs/2509.03898)
### Authors
Zhengyi Guo,Jiatu Li,Wenpin Tang,David D. Yao
### Background
本文开发了降维技术以加速合成数据生成中的扩散模型推断。在合成数据生成的上下文中，将压缩感知整合到扩散模型中：(1) 将数据压缩到潜在空间中；(2) 在潜在空间中训练扩散模型；(3) 对潜在空间中生成的样本应用压缩感知算法，从而提高模型训练和推断的效率。在适合数据稀疏假设的情况下，所提出的方法通过将扩散模型推断与稀疏恢复相结合，证明了更快的收敛速度。作为副产品，我们获得了潜在空间维度的最优值。在多种数据集上进行了数值实验，包括图像数据（手写数字、医学图像、气候数据）和金融时间序列的压力测试。
### Innovation
本文提出了一种将压缩感知技术应用于扩散模型的方法，包括将数据压缩到潜在空间中、在潜在空间中训练扩散模型和使用压缩感知算法处理潜在空间中生成的样本，从而加速数据生成效率和模型训练速度。进一步地，该方法在适合数据稀疏假设的情况下，实现了更快的收敛速度和潜在空间维度的最优值确定。
### Conclusion
在合适的稀疏性假设下，通过结合扩散模型训练和压缩感知，本文的算法表现出加速收敛的特性。数值实验结果表明该方法在图像数据和金融时间序列的应用中的有效性。
## 78. `cs.AI` - SPFT-SQL：通过自我博弈调优增强大规模语言模型的文本到SQL解析 [PDF](https://arxiv.org/pdf/2509.03937), [HTML](https://arxiv.org/abs/2509.03937)
### Authors
Yuhao Zhang,Shaoming Duan,Jinhang Su,Chuanyi Liu,Peiyi Han
### Background
尽管自我博弈调优（SPIN）方法可以将一个能力较弱的大规模语言模型（LLM）通过不同能力模型间的竞争互动转变为强大的模型，但它在文本到SQL（Text-to-SQL）任务上仍面临挑战。SPIN方法没有生成新信息，在自我博弈过程中对手模型产生的大量正确SQL查询会削弱主要模型生成准确SQL查询的能力。
### Innovation
提出了一种针对文本到SQL任务的新自我博弈调优方法，称为SPFT-SQL。在自我博弈之前，引入了一种基于验证的迭代调优方法，迭代生成高质量调优数据，增强模型性能，同时建立具有不同能力的模型基础。在自我博弈调优阶段，提出了一种错误驱动的损失方法，激励对手模型产生错误输出，使主要模型能够区分正确的SQL和对手模型生成的错误SQL，从而提高其生成正确SQL的能力。
### Conclusion
在六种开源LLM和五种广泛使用的基准上的广泛实验和深入分析表明，我们的方法在性能上超过了现有的最先进的（SOTA）方法。
## 79. `cs.AI` - 通过概率上下文变量的元逆强化学习在均场博弈中的应用 [PDF](https://arxiv.org/pdf/2509.03845), [HTML](https://arxiv.org/abs/2509.03845)
### Authors
Yang Chen,Xiao Lin,Bo Yan,Libo Zhang,Jiamou Liu,Neset Özkan Tan,Michael Witbrock
### Background
在现实世界的应用中，为众多相互作用的智能代理设计合适的奖励函数具有挑战性。均场博弈（MFG）中的逆强化学习（IRL）提供了一种实用框架，可以从专家演示中推断出奖励函数，但现有方法假定代理是同质的，这限制了其处理显示不同且未知目标的能力，而在实践中这是常见的问题。因此，本文提出了一种深度隐变量MFG模型及相应的逆强化学习方法，该方法可以在没有先验知识或不修改MFG模型的情况下，从不同但结构相似的任务中推断出奖励。实验结果表明，本文方法在模拟场景和现实世界的空间出租车定价问题上优于现有最先进的MFG中的IRL方法。
### Innovation
提出了一种深度隐变量MFG模型，并结合了相关IRL方法，能够在没有先验知识或不修改MFG模型的情况下，从不同但结构相似的任务中推断出奖励。这种方法可以有效处理具有不同和未知目标的专家演示，相比于现有方法具备更强的适应性和广义性。
### Conclusion
通过对模拟实验和实际的出租车定价问题进行了验证，本文方法在MFG中的IRL任务中展示了优越的效果，这表明提出的模型能够有效应用于具有复杂目标的逆强化学习任务中，并为未来的相关研究提供了新的方向。
## 80. `cs.AI` - 使用EfficientNet-B4迁移学习的U-Net架构胸部X射线气胸分割 [PDF](https://arxiv.org/pdf/2509.03950), [HTML](https://arxiv.org/abs/2509.03950)
### Authors
Alvaro Aranibar Roque,Helga Sebastian
### Background
气胸是胸膜腔内异常积聚空气的情况，若未被检测到，可能会危及生命。胸片是初步诊断工具，但小的气胸病例可能不易察觉。
### Innovation
本文提出了一种使用EfficientNet-B4编码器的U-Net深度学习管道来自动分割气胸区域。模型在SIIM-ACR数据集上经过数据增强和二元交叉熵加Dice损失的联合训练，独立的PTX-498数据集上的IoU为0.7008，Dice评分为0.8241，表明该模型可以准确地定位气胸并支持放射科医生。
### Conclusion
本研究表明，基于EfficientNet-B4迁移学习的U-Net模型能够准确分割胸部X射线中的气胸区域，并支持放射科医生的诊断工作。
## 81. `cs.AI` - SalientFusion: Context-Aware Compositional Zero-Shot Food Recognition [PDF](https://arxiv.org/pdf/2509.03873), [HTML](https://arxiv.org/abs/2509.03873)
### Authors
Jiajun Song,Xiaoou Liu
### Background
食物识别引起了广泛关注，但新菜品的快速出现要求识别未见过的食物类别，从而推动了零样本食品学习（ZSFL）。组分零样本食品识别（CZSFR）作为组分零样本学习（CZSL）的进一步发展，面临着三个挑战：冗余背景信息分散了模型对有意义食物特征的学习，主菜和配菜角色混淆导致分类错误，单一属性的语义偏见可能导致理解混淆。
### Innovation
提出了SalientFusion方法，该方法包含两个组件：SalientFormer 解除背景冗余并使用深度特征解决角色混淆问题；DebiasAT 减少语义偏见并通过视觉特征对齐提示。该方法使用CZSFood-90和CZSFood-164基准测试，在这些基准测试和一般CZSL流行数据集上取得了最先进的结果。
### Conclusion
SalientFusion在基准CZSFood-90和CZSFood-164中取得了最先进的性能，并且在流行的通用CZSL数据集上也展现了最好的结果，证明了其有效性和实用性。相关代码可以在指定的链接中获得。
## 82. `cs.AI` - VoxRole：语音角色扮演代理综合基准 [PDF](https://arxiv.org/pdf/2509.03940), [HTML](https://arxiv.org/abs/2509.03940)
### Authors
Weihao Wu,Liang Cao,Xinyu Wu,Zhiwei Lin,Rui Niu,Jingbei Li,Zhiyong Wu
### Background
近期，大型语言模型（LLMs）的显著进步极大地推动了角色扮演对话代理（RPCA）的发展。这些系统通过一致的人设来创造沉浸式的用户体验。然而，现有的RPCA研究存在两个主要的局限性。首先，现有工作主要集中在文本模态上，忽视了重要的副语言特征（如语调、语速和节奏），这对于传达人物情感和塑造鲜明的身份至关重要。其次，基于语音的角色扮演领域缺乏标准化的评估基准，大多数当前的对话数据集仅针对基本能力进行评估，不具备完整的或清晰的人物描述，这使得评估模型在维持长期的人设一致性方面无法有效量化表现.
### Innovation
为了解决这一关键问题，我们提出了VoxRole，这是第一个专门为评估基于语音的角色扮演代理设计的综合基准。该基准包括13335个多轮对话，总计65.6小时的语音数据，涉及261部电影的1228个不同角色。为了构建这一资源，我们提出了一种新颖的两阶段自动化流程，首先将电影音频与剧本对齐，然后使用LLM系统地为每个角色构建多维度的描述。利用VoxRole，我们对当前的语音对话模型进行了多维度的评估，揭示了其在保持人设一致性方面的各自优势和不足.
### Conclusion
通过这项研究，我们揭示了当前模型在维持长期人设一致性方面的具体表现，为评估语音角色扮演代理提供了重要见解。
## 83. `cs.AI` - 通过一个韩语文本案例研究，开源大规模语言模型基础能力的扩展 [PDF](https://arxiv.org/pdf/2509.03972), [HTML](https://arxiv.org/abs/2509.03972)
### Authors
Junghwan Lim,Gangwon Jo,Sungmin Lee,Jiyoung Park,Dongseok Kim,Jihwan Kim,Junhyeok Lee,Wai Ting Cheung,Dahye Choi,Kibong Choi,Jaeyeon Huh,Beomgyu Kim,Jangwoong Kim,Taehyun Kim,Haesol Lee,Jeesoo Lee,Dongpin Oh,Changseok Song,Daewon Suh
### Background
研究和开发具有强大多语言处理能力的大型语言模型。背景是现有的语言模型一般都能很好地处理英文，但对其他语言的支持可能不那么理想。Llama-3-Motif被设计来增强韩语处理能力，同时保持在英文上的良好性能。
### Innovation
Llama-3-Motif被视为一种增强韩语能力的创新性语言模型。它基于Llama 3架构，采用LlamaPro和Masked Structure Growth等先进训练技术，有效扩大了模型规模。利用MoAI平台在同一级GPU集群上进行高效训练，从而优化了模型的性能。
### Conclusion
Llama-3-Motif在韩语特定基准测试中表现出良好的性能，优于现有模型，达成与GPT-4相仿的结果。这展示了开源语言模型在特定语言能力增强上的潜力，并证明了在大规模集群上进行优化的重要性。
## 84. `cs.AI` - 多模态特征融合网络与文本差异增强用于遥感变化检测 [PDF](https://arxiv.org/pdf/2509.03961), [HTML](https://arxiv.org/abs/2509.03961)
### Authors
Yijun Zhou,Yikui Zhai,Zilu Ying,Tingfeng Xian,Wenlve Zhou,Zhiheng Zhou,Xiaolin Tian,Xudong Jia,Hongsheng Zhang,C. L. Philip Chen
### Background
尽管深度学习在遥感变化检测（RSCD）方面取得了进展，多数方法仅依赖于图像模态，从而限制了特征表示、变化模式建模和泛化能力，特别是在光照和噪声干扰下。
### Innovation
提出了一种称为MMChange的多模态RSCD方法，结合图像和文本模态以提升准确性和鲁棒性。引入了图像特征精炼（IFR）模块来突出关键区域并抑制环境噪声。为克服图像特征的语义限制，采用了视觉语言模型（VLM）生成双时相图像的语义描述。通过提取细微的语义差异，引导模型识别有意义的变化。设计了图像文本特征融合（ITFF）模块以消除模态间的异质性，实现了深度跨模态融合。
### Conclusion
在LEVIRCD、WHUCD和SYSUCD上的大量实验验证了MMChange方法的一致优越性，多项指标中始终超越了现有的先进方法，证实了其在多模态RSCD中的有效性。
## 85. `cs.AI` - SAC-MIL: 空间感知相关多实例学习在组织病理学全切片图像分类中的应用 [PDF](https://arxiv.org/pdf/2509.03973), [HTML](https://arxiv.org/abs/2509.03973)
### Authors
Yu Bai,Zitong Yu,Haowen Tian,Xijing Wang,Shuo Yan,Lin Wang,Honglin Li,Xitong Ling,Bo Zhang,Zheng Zhang,Wufan Wang,Hui Gao,Xiangyang Gong,Wendong Wang
### Background
全切片图像（WSI）分类是组织病理学领域的重要任务，传统的多实例学习（MIL）方法在处理WSI的空间相关性方面存在不足，尤其是在处理不同长度的训练和测试序列时。因此，需要提出一种能够更好地捕捉实例间空间关系的方法来提高WSI分类的性能和效率。
### Innovation
本文提出了一种空间感知相关多实例学习（SAC-MIL）方法。该方法包含一个位置编码模块，用于编码位置信息，以及一个SAC块，用于执行全面实例相关性。位置编码模块通过利用切片内的实例坐标来编码空间关系，而不仅仅是输入WSI序列中的实例索引。此外，SAC块是一个基于MLP的方法，可以在线性时间复杂度下执行全面实例相关性，相比基于Transformer的方法，无需定制CUDA内核，易于部署。SAC-MIL在CAMELYON-16、TCGA-LUNG和TCGA-BRAC数据集上取得了最先进的性能。
### Conclusion
实验结果表明，SAC-MIL方法在处理WSI分类中空间相关性方面表现出色，并且具有良好的性能和易部署性。该方法已经实现了在多个数据集上的最优性能，未来有望在更多的WSI分类任务中得到应用。
## 86. `cs.AI` - Promptception: 如何评估大型多模态模型对提示的敏感度？ [PDF](https://arxiv.org/pdf/2509.03986), [HTML](https://arxiv.org/abs/2509.03986)
### Authors
Mohamed Insaf Ismithdeen,Muhammad Uzair Khattak,Salman Khan
### Background
尽管近年来大型多模态模型（LMMs）在多项选择题回答（MCQA）方面取得了成功，但对于LMMs的提示设计仍然缺乏深入理解。提示在表达方式和结构上的微小变化可能导致某些提示和模型之间的准确率偏差高达15%。这种敏感性给LMMs的透明和公平评估带来了挑战，因为模型常常会选择性地使用能展示其最佳性能的提示。
### Innovation
本文提出了一种名为Promptception的系统框架，用于评估LMMs的提示敏感度。Promptception包含61种提示类型，覆盖15个类别和6个超类别，针对不同方面进行提示的定制化设计，并用于评估从轻量级开源模型到GPT-4o和Gemini 1.5 Pro的10种LMMs，跨越3个MCQA基准：MMStar、MMMU-Pro和MVBench。研究发现，专有模型对提示表达更为敏感，反映出与指令语义更为紧密的对齐，而开源模型则更为稳定，但在复杂的提示表达上表现挣扎。基于这一分析，提出了针对专有和开源LMMs的提示原则，以实现更强大的和公平的模型评估。
### Conclusion
根据分析，提出提示原则以适应专有和开源LMMs，使模型评估更加稳健和公平。
## 87. `cs.AI` - RTQA: 基于递归思维的大型语言模型复杂时间知识图谱问题解答 [PDF](https://arxiv.org/pdf/2509.03995), [HTML](https://arxiv.org/abs/2509.03995)
### Authors
Zhaoyan Gong,Juan Li,Zhiqiang Liu,Lei Liang,Huajun Chen,Wen Zhang
### Background
当前的时间知识图谱问题回答（TKGQA）方法主要关注隐式的时间约束，缺乏处理复杂时间查询的能力，并且在分解框架中面临着有限的推理能力和错误传播的问题。
### Innovation
提出了RTQA新颖框架，通过增强对时间知识图谱的推理能力而不需要训练，来解决这些挑战。RTQA通过递归分解问题、自底向上的求解以及多路径答案聚合来增强容错性。
### Conclusion
在MultiTQ和TimelineKGQA基准测试上，RTQA在“Multiple”和“Complex”类别中显著提高了Hits@1结果，优于最先进的方法。我们的代码和数据可在该链接获取。
## 88. `cs.AI` - NeuroBreak: 揭示大型语言模型内部旁路机制 [PDF](https://arxiv.org/pdf/2509.03985), [HTML](https://arxiv.org/abs/2509.03985)
### Authors
Chuhan Zhang,Ye Zhang,Bowen Shi,Yuyou Gan,Tianyu Du,Shouling Ji,Dazhan Deng,Yingcai Wu
### Background
在部署和应用过程中，大型语言模型（LLMs）通常会进行安全性对齐以防止非法和不道德的输出。然而，由于旨在绕过安全机制的旁路攻击技术的持续发展，这些技术利用了对抗性提示，给LLMs的安全防护带来了越来越多的压力。要增强抵御旁路攻击的能力，需要深入理解LLMs的安全机制及其漏洞，但LLMs庞大的参数数量和复杂的结构使得从内部进行安全弱点分析成为一项艰巨的任务。
### Innovation
本文提出了NeuroBreak，一个从顶部到底部的旁路分析系统，旨在从神经元级别分析安全性机制并缓解漏洞。它通过与三位AI安全领域的专家合作，仔细设计系统要求，提供了对各种旁路攻击方法的全面分析。NeuroBreak通过分层表示探查分析，提供了一个新的视角来理解模型在其生成过程中所做的决策。此外，该系统支持从语义和功能层面分析关键神经元，有助于更深入地探索安全机制。我们通过定量评估和案例研究验证了系统的有效性，为开发针对不断演变的旁路攻击的新一代防御策略提供了机制性的见解。
### Conclusion
总之，NeuroBreak 是一种高级分析系统，专注于从神经元级别分析和缓解LLMs的安全性弱点，为开发下一代防御策略提供了新的视角和机制性见解。
## 89. `cs.AI` - 通过弃用标记检测视觉变压器中的区域伪相关 [PDF](https://arxiv.org/pdf/2509.04009), [HTML](https://arxiv.org/abs/2509.04009)
### Authors
Solha Kang,Esla Timothy Anzaku,Wesley De Neve,Arnout Van Messem,Joris Vankerschaver,Francois Rameau,Utku Ozbulak
### Background
基于神经网络的计算机视觉模型因其强大的特征关联能力，能够检测和利用数据中的未预期模式，即使这些模式可能是错误或非特定意图的，但仍具有统计相关性，可能导致基于错误迹象的正确预测。这些未预期信号可能从简单的色差到图像中的小文本内容不等。当这些未预期信号与预测任务一致时，模型可能会错误地将这些特征与任务关联起来，并依赖它们进行预测。这种现象被称为伪相关，即模式看似与任务相关，但实际上只是巧合。因此，检测和缓解伪相关已成为建立可靠且通用的机器学习模型的最关键任务之一。本文探讨了如何在视觉变压器中检测此类伪相关问题。
### Innovation
本文提出了一种新的方法，通过标记弃用来检测视觉变压器中的区域伪相关。该方法在监督训练和自监督训练模型上进行了大规模实验，展示了所提出方法识别伪相关的有效性。研究还发现，即使使用相同的架构，训练方法对模型依赖伪相关的程度也有显著影响。此外，还揭示了ImageNet数据集中某些类别中容易被模型识别的伪信号，并讨论了这些伪信号的背后原因。
### Conclusion
基于研究发现，本文提供了上述图像的详尽列表，并在未来的研究中呼吁谨慎使用这些图像。此外，还通过侵入性乳腺团块分类的实际案例研究进一步探讨了伪信号问题。
## 90. `cs.AI` - 基于循环上下文过滤和离循环重建增强的神经视频压缩 [PDF](https://arxiv.org/pdf/2509.04051), [HTML](https://arxiv.org/abs/2509.04051)
### Authors
Yaojun Wu,Chaoyi Lin,Yiming Wang,Semih Esenlik,Zhaobin Zhang,Kai Zhang,Li Zhang
### Background
本文研究了增强滤波技术在神经视频压缩中的应用。这些技术根据增强表示是否影响后续编码循环被分类为在循环上下文过滤和离循环重建增强。在循环上下文过滤通过减轻逐帧编码中的误差传播来细化时间上下文，但其对当前帧和后续帧的影响提出了在整个序列中适应性应用滤波的挑战。
### Innovation
我们引入了一种自适应编码决策策略，该策略在编码过程中动态确定滤波的应用。同时，离循环重建增强被用于提高重建帧的质量，从而提供简单而有效的编码效率改进。这是首次系统地研究基于条件的神经视频压缩中的增强滤波。
### Conclusion
本研究表明，与最先进的神经视频编解码器相比，提出的这种方法在比特率上降低了7.71%，验证了所提出方法的有效性。
## 91. `cs.AI` - NER Retriever: 零样本类型感知命名实体检索 [PDF](https://arxiv.org/pdf/2509.04011), [HTML](https://arxiv.org/abs/2509.04011)
### Authors
Or Shachar,Uri Katz,Yoav Goldberg,Oren Glickman
### Background
该论文背景在于现有的命名实体识别（NER）任务往往需要预先定义实体类型，但在实际应用中，用户可能需要根据特定需求动态地检索不同类型实体。传统的方法要么依赖固定的模式，要么需要对模型进行微调，而本文提出的方法旨在通过大型语言模型（LLMs）内部表示来构建一种零样本检索框架——NER Retriever，适用于未提前定义实体类型的情况。
### Innovation
本文的创新之处在于将大型语言模型的内部表示用于嵌入实体提及和用户提供的开放类型描述到共享语义空间中。特别地，中层变压器块的值向量比常用顶部嵌入更有效地编码细化类型信息。此外，通过训练一个轻量级对比投影网络来调整兼容类型的实体并分离不相关类型，进而产生紧凑、类型感知且适合最近邻居搜索的实体嵌入。这种框架在三个基准测试中显著优于现有的基于词典和密集句子级别检索的基线。
### Conclusion
NER Retriever通过实验证明了在LLMs内部表示选择上提供的经验支持，并展示了如何实现可扩展、无模式的实体检索的实用解决方案。该代码库已公开发布。
## 92. `cs.AI` - 基于关键点的扩散在NICOL机器人运动规划中的应用 [PDF](https://arxiv.org/pdf/2509.04076), [HTML](https://arxiv.org/abs/2509.04076)
### Authors
Lennart Clasmeier,Jan-Gerrit Habekost,Connor Gäde,Philipp Allgeuer,Stefan Wermter
### Background
传统上，使用数值规划方法解决一般的运动规划问题，但这些方法具有显著的运行时间要求。通常委托深度学习来利用其强大的能力，在这些规划者生成的数据集上进行学习，以在较小的运行时间内实现良好的结果。
### Innovation
提出了一种新的基于扩散的动作模型，用于机器人的运动规划。该模型在实验中已经证明，不仅在运行时间上优于数值模型（高出一个数量级），还能达到高达90%的无碰撞解决方案成功率，即使没有使用点云编码。
### Conclusion
尽管最初的模型使用点云嵌入作为输入预测输出的基于关键点的关节序列，但在消融研究中发现将网络条件设置为点云嵌入仍然具有挑战性。通过识别数据集中的偏差并对其进行改进，模型的表现得到了提高。 
## 93. `cs.AI` - 关于LLM基准评估的稳健性和可靠性 [PDF](https://arxiv.org/pdf/2509.04013), [HTML](https://arxiv.org/abs/2509.04013)
### Authors
Riccardo Lunardi,Vincenzo Della Mea,Stefano Mizzaro,Kevin Roitero
### Background
当前对大规模语言模型（LLMs）的有效性通常通过MMLU、ARC-C或HellaSwag等基准进行评估，这些基准中的问题以固定的形式呈现。然而，真实世界的应用场景中涉及多样的语言变体，要求模型能够在不同表述形式的同一问题或查询中保持其有效性。本文通过系统性地评估LLMs对变形基准问题的鲁棒性，探讨基准评估是否能准确反映模型能力。
### Innovation
本文系统性地生成了六个常见基准的所有问题的各种变体，并测量了34种不同大小和效果的LLMs在这些变体中的表现变化。研究发现，虽然LLMs在变形输入中的排名相对稳定，但绝对有效性分数会显著下降，这表明LLMs在语言变体面前存在困难，影响其泛化能力和评估方法的有效性。
### Conclusion
研究结果揭示，尽管LLMs在变形输入中的排名相对稳定，但绝对有效性分数会显著下降，这表明其在面对语言变体时存在困难，质疑了基准评估的有效性。降级的性能挑战了基准评估的可靠性，表明高基准分数可能未能完全捕捉模型对实际输入变化的鲁棒性。本文强调了需要关注鲁棒性的基准评估，以更好地反映实际部署场景的重要性。
## 94. `cs.AI` - CANDY: 评估大语言模型在汉语虚假信息事实核查中的局限性和辅助潜力 [PDF](https://arxiv.org/pdf/2509.03957), [HTML](https://arxiv.org/abs/2509.03957)
### Authors
Ruiling Guo,Xinwei Yang,Chen Huang,Tong Zhang,Yong Hu
### Background
尽管大语言模型（LLMs）在事实核查方面的作用日益重要，但它们有效核查虚假信息的能力仍存在不确定性。本文借此机遇，构建了一个名为CANDY的基准测试体系，旨在系统性地评估LLMs在汉语虚假信息事实核查中的功能和局限性。通过精心构建含有约20000个例子的标注数据集，本文揭示出当前LLMs在生成精准事实核查结论方面存在局限，即使使用了链式推理和少量提示技术也未能显著改善。这些分析进一步强调了LLMs在独立进行事实核查时的不可靠性，但在作为辅助工具增强人类表现时，具备显著潜力。
### Innovation
本文开发了一个专门针对汉语虚假信息的事实核查基准测试CANDY，包括一个包含20000多个实例的标注数据集。这项工作还发展了一种分类法来归类LLMs生成的不准确结论，并指出了事实捏造是最常见的失败模式。文章还强调了LLMs在作为辅助工具时对提升人类事实核查能力的重要性以及其潜在价值。通过这一开创性的工作，研究人员可以更好地理解LLMs的事实核查能力及其改进建议，从而在未来的设计与应用中更加针对性地提高其表现。
### Conclusion
尽管LLMs在独立进行事实核查时表现出不可靠性，但它们与人类协作时有可能显著增强准确性和效率。该研究结果表明，通过表格化原始数据以及已识别的常见错误模式，研究人员和其他利益相关者可以更有针对性地改进和优化LLMs在未来应用于事实核查领域的表现。数据集和代码已公开，提供了一个有价值的资源，供其他研究人员和团队探索和利用。
## 95. `cs.AI` - MEPG：多专家规划和生成用于组成丰富图像的生成 [PDF](https://arxiv.org/pdf/2509.04126), [HTML](https://arxiv.org/abs/2509.04126)
### Authors
Yuan Zhao,Liu Lin
### Background
文本到图像的扩散模型在图象质量方面取得了显著进展，但仍面临复杂、多元素提示的挑战，以及样式多样性有限的问题。
### Innovation
提出了一个多专家规划和生成框架（MEPG），该框架高效地将位置和风格感知的大语言模型（LLMs）与空间语义专家模块相结合。该框架包括：(1) 位置-样式感知（PSA）模块，利用监督微调的LLM将输入提示分解为精确的空间坐标和样式编码的语义指令；以及(2) 多专家扩散（MED）模块，通过动态专家路由在局部区域和全球区域之间进行跨区域生成。通过基于注意力的门控机制激活特定于空间分区的专业模型，从而支持轻量级的专家模型集成和替换，增强扩展性。
### Conclusion
实验表明，MEPG在图像质量和风格多样性方面显著优于具有相同基本结构的基线模型。
## 96. `cs.AI` - EHVC: 效率级参考和质量结构的神经视频编码 [PDF](https://arxiv.org/pdf/2509.04118), [HTML](https://arxiv.org/abs/2509.04118)
### Authors
Junqi Liao,Yaojun Wu,Chaoyi Lin,Zhipin Deng,Li Li,Dong Liu,Xiaoyan Sun
### Background
神经视频编解码器（NVCs）利用端到端学习的力量，在编码效率上比传统视频编解码器显著提升。近期研究开始关注NVCs中的质量结构，并通过引入显式的分层设计进行优化。然而，对于参考结构设计的注意较少，这应该与分层质量结构保持一致。此外，分层质量结构仍有待进一步优化。
### Innovation
针对NVCs中的挑战，我们提出了EHVC，一种高效的分层神经视频编解码器，包含三个关键创新：(1) 一种分层多参考方案，借鉴传统视频编解码器设计来调整参考和质量结构，解决参考与质量结构不匹配的问题；(2) 采用前瞻策略利用编码端未来帧的上下文信息来增强质量结构；(3) 逐层质量尺度结合随机质量训练策略，在推理过程中稳定质量结构。
### Conclusion
通过这些改进，EHVC在性能上显著优于最先进的神经视频编解码器。
## 97. `cs.AI` - 增强RAG系统的技术文档检索 [PDF](https://arxiv.org/pdf/2509.04139), [HTML](https://arxiv.org/abs/2509.04139)
### Authors
Songjiang Lai,Tsun-Hin Cheung,Ka-Chun Fung,Kaiwen Xue,Kwan-Ho Lin,Yan-Ming Choi,Vincent Ng,Kin-Man Lam
### Background
现有的技术文档在硬件和软件开发中扮演着重要角色，但理解和检索复杂技术内容具有挑战性。传统的技术文档检索方式往往效果不佳，无法满足实际需求。为了克服这些问题，研究人员提出了利用大语言模型（LLMs）来优化技术文档的语义检索框架，并结合查询扩展和上下文总结技术来提升检索性能。
### Innovation
该论文提出了一种名为Technical-Embeddings的创新框架，用于优化技术文档的语义检索。技术创新包括：1. 通过生成扩展表示来增强用户查询，更好地捕捉用户意图并提高数据集多样性；2. 使用总结提取技术对技术文档进行编码，提炼出必要的上下文信息；3. 使用软提示Fine-tune双编码器BERT模型，并为查询和文档上下文分别设置学习参数，以捕捉细微的语义差异。这套方法在两个公开数据集上展示了优于基准模型的精确度和召回率，证明了该模型的有效性并促进了RAG系统的进步。
### Conclusion
本文通过引入Technical-Embeddings框架，结合查询扩展和上下文总结，显著提升了技术文档的检索性能。研究结果表明，这种创新方法能够在工程和产品开发工作中实现高效且精确的技术文档检索。这项工作推进了RAG系统的最新进展，并提出了新的技术文档检索途径。
## 98. `cs.AI` - 策略视角中的简洁性：反应合成中控制器的复杂性 [PDF](https://arxiv.org/pdf/2509.04129), [HTML](https://arxiv.org/abs/2509.04129)
### Authors
Mickael Randour
### Background
在基于博弈论的控制器合成方法中，我们将待控制系统的交互与其环境建模为一个博弈过程，并寻求适合的策略（例如，胜出或最优）。一个普遍的看法是简单的策略（例如，使用有限记忆）更优：这样的控制器更易设计、理解和制造，并且维护成本更低。本文回顾了策略在不同合成环境中的复杂性问题，讨论了记忆和随机性的影响，并简要探讨了超出传统策略复杂性的概念。
### Innovation
本文探讨了策略在不同合成背景下的复杂性问题，尤其是关于记忆和随机性的影响，揭示了策略的复杂性并非一概而论，而是视角依赖的。这一研究为设计更高效和灵活的控制器提供了新的视角。
### Conclusion
策略的复杂性不能一概而论，简化的策略并不总是更优。复杂性和简洁性的权衡取决于具体的应用场景，并且超越了传统对策略复杂性的理解。在反应合成中，理解策略的复杂性对于设计出更高效、更灵活的控制器至关重要，以适应不同环境的要求。
## 99. `cs.AI` - 跨越物种鸿沟：从语音到动物声音的迁移学习 [PDF](https://arxiv.org/pdf/2509.04166), [HTML](https://arxiv.org/abs/2509.04166)
### Authors
Jules Cauzinille,Marius Miron,Olivier Pietquin,Masato Hagiwara,Ricard Marxer,Arnaud Rey,Benoit Favre
### Background
自监督语音模型在语音处理方面取得了显著的性能，但这些模型在非语音数据上的效果仍然未被充分研究。本文研究了这类模型在生物声学检测和分类任务中的迁移学习能力。研究发现，HuBERT、WavLM和XEUS等模型可以生成不同物种动物声音丰富的潜在表示。通过线性探针方法，分析了模型的特性，并将该方法扩展以考虑时间信息的影响。此外，研究了频率范围和噪音对模型性能的影响。
### Innovation
研究展示了自监督语音学习应用于生物声学检测和分类任务的潜力，证明了在没有专门训练的情况下，这些模型在生物声学领域可以取得与细调预训练模型竞争的性能，并进一步探讨了噪声鲁棒预训练设置的影响。
### Conclusion
本文的研究结果表明，自监督的语音模型能够生成动物声音的丰富潜在表示，这些模型在生物声学研究中具有巨大潜力，预训练设置中的噪声鲁棒性对模型性能有显著影响。
## 100. `cs.AI` - VisioFirm：计算机视觉领域的跨平台AI辅助标注工具 [PDF](https://arxiv.org/pdf/2509.04180), [HTML](https://arxiv.org/abs/2509.04180)
### Authors
Safouane El Ghazouali,Umberto Michelucci
### Background
AI模型依赖于标注数据来学习模式和进行预测。标注通常是一个劳动密集型的工作，需要将从简单分类标签到更复杂的任务（如对象检测、带方向的边界框估计和实例分割）的标签关联起来。传统的工具往往需要大量的手动输入，这限制了大型数据集的可扩展性。
### Innovation
VisioFirm 是一个开源的网络应用程序，旨在通过AI辅助自动化来简化图像标注流程。它将最先进的基础模型集成到一个界面中，配备过滤管道，以减少人工参与的努力。该混合方法使用CLIP结合预训练探测器（如Ultralytics模型）以及零样本模型（如Grounding DINO）来生成初始标注，具有低置信度阈值，以最大化召回率。VisioFirm 还支持即时分割，通过WebGPU在浏览器端加速，支持多种导出格式，并在模型缓存后运行，提高可访问性。
### Conclusion
VisioFirm 在不同数据集上的基准测试中证明了可将手动努力减少高达90%，同时通过聚集基于CLIP的去歧义组件和IoU图来消除冗余检测，保持高注释准确性。
## 101. `cs.AI` - YOLO Ensemble for UAV-based Multispectral Defect Detection in Wind Turbine Components [PDF](https://arxiv.org/pdf/2509.04156), [HTML](https://arxiv.org/abs/2509.04156)
### Authors
Serhii Svystun,Pavlo Radiuk,Oleksandr Melnychenko,Oleg Savenko,Anatoliy Sachenko
### Background
未装备先进传感器的无人驾驶航空器(UAV)为监控风力发电厂的叶片、塔和其他关键部件提供了新的机会。然而，可靠的缺陷检测需要高分辨率的数据和能够高效处理多光谱图像的方法。这项研究旨在通过开发结合可见光和热通道的YOLO（You Only Look Once）深度学习模型的集成体系结构，提升缺陷检测的准确性。研究结果表明，结合多个YOLO架构并与融合多光谱数据相结合的方法，可以更可靠地进行视觉和热缺陷检测，优于单一使用YOLOv8模型的方法。
### Innovation
本研究提出了一种将通用的YOLOv8模型与专门的热模型结合的集成方法，并通过复杂的边界框融合算法结合预测结果。实验结果表明，这种组合方法在mAP@0.5指标上的得分达到了0.93，在F1分数上达到了0.90，优于单一使用YOLOv8模型的方法（mAP@0.5得分为0.91）。这些发现表明，结合多个YOLO架构和融合多光谱数据提供了更可靠的解决方案，有助于提高对视觉和热缺陷的检测效果。
### Conclusion
通过结合多个YOLO架构和融合多光谱数据，本研究展示了更可靠的缺陷检测方法，能够有效提升对风力发电塔组件中视觉和热缺陷的检测准确性，这项研究对于无人机监控风力发电站具有重要的实际意义。
## 102. `cs.AI` - 通过自我进化偏好优化学习主动感知以实现GUI定位 [PDF](https://arxiv.org/pdf/2509.04243), [HTML](https://arxiv.org/abs/2509.04243)
### Authors
Wanfu Wang,Qipeng Huang,Guangquan Xue,Xiaobo Liang,Juntao Li
### Background
视觉语言模型(VLMs)在连接视觉感知和语言推理方面取得了显著进展。在GUI定位中，尤其是在高分辨率输入和复杂的多元素视觉交互场景下，使VLMs能够有效推理合适的图像区域仍然是一个核心挑战。
### Innovation
本文提出了一种名为LASER的自我进化框架，该框架通过逐步赋予VLMs多步感知能力以实现精确的坐标预测。具体而言，该方法结合了蒙特卡洛质量估计和基于交并比(IoU)的区域质量评估，以联合促进构建高质量偏好数据时的准确性和多样性。这种方法明确指导模型关注与指令相关的关键区域，并根据任务复杂性动态分配推理步骤。
### Conclusion
在ScreenSpot Pro和ScreenSpot-v2基准测试上的全面实验表明，该方法具有一致的性能提升。当在GTA1-7B上进行微调时，LASER在ScreenSpot-Pro基准测试上的得分为55.7，建立了7B规模模型的新最先进的(SoTA)。
## 103. `cs.AI` - CEHR-GPT：电子健康记录的可扩展多任务基础模型 [PDF](https://arxiv.org/pdf/2509.03643), [HTML](https://arxiv.org/abs/2509.03643)
### Authors
Chao Pang,Jiheum Park,Xinzhuo Jiang,Nishanth Parameshwar Pavinkurve,Krishna S. Kalluri,Shalmali Joshi,Noémie Elhadad,Karthik Natarajan
### Background
电子健康记录（EHRs）提供了患者长期健康状况的丰富视角，具有推动临床决策支持、风险预测以及数据驱动的健康研究的潜力。然而，大多数用于EHR的人工智能（AI）模型只为特定任务设计，限制了它们在实际应用中的通用性和实用性。
### Innovation
CEHR-GPT 是一个通用的基础模型，统一了特征表示、零样本预测和合成数据生成三大关键能力于单一架构中。它通过引入一种新型的时间标记学习框架，明确编码患者动态时间线，支持临床序列的时间推理。该模型在所有三个任务上的表现强劲，并通过词汇扩展和微调有效推广到外部数据集。其灵活性能够快速开发模型、发现队列和预测患者结果，无需特定任务的重新训练。
### Conclusion
CEHR-GPT 在所有三个任务上的强表现和在外部数据集上的有效推广，证实了其通用性和适用性，这在实际应用中通过词汇扩展或微调公开数据集来促进快速模型开发和临床决策支持、风险预测及数据驱动研究能力的提升。
## 104. `cs.AI` - MAGneT：合成多回合心理健康咨询会话的协调多智能体生成 [PDF](https://arxiv.org/pdf/2509.04183), [HTML](https://arxiv.org/abs/2509.04183)
### Authors
Aishik Mandal,Tanmoy Chakraborty,Iryna Gurevych
### Background
心理咨询服务的需求不断增加，强调了使用高质量、隐私合规的数据对开源大型语言模型（LLMs）进行微调的重要性，但这样高质量的数据仍然稀缺。现有的单一智能体方法未能充分捕捉真实咨询过程中的结构和细微差别。
### Innovation
引入了MAGneT，这是一种新颖的多智能体框架，用于生成合成的心理咨询会话。该框架将咨询师回应生成分解为由专门的LLM智能体处理的协调子任务，每个智能体模拟一种关键的心理学技术。此外，还提出了一个统一的评估框架，结合多种自动和专家评分标准来解决先前评估协议中的不一致性问题，并且将以前工作中的四个评估方面扩展到九个方面，以更全面和稳健地评估数据质量。
### Conclusion
实验证明，与现有方法相比，MAGneT在生成的心理咨询会话的质量、多样性和治疗对齐方面显著优于现有方法，提高了总体咨询技能3.2%，专门的认知行为疗法（CBT）技能4.3%。此外，在所有方面中，77.2%的情况下，专家更偏好MAGneT生成的咨询会话。在使用MAGneT生成的会话微调开源模型后，其性能也有所提升，总体咨询技能提高了6.3%，专门的CBT技能提高了7.3%。研究代码和数据也已公开。
## 105. `cs.AI` - 我们能够通过LLM先验节省多少患者？ [PDF](https://arxiv.org/pdf/2509.04250), [HTML](https://arxiv.org/abs/2509.04250)
### Authors
Shota Arai,David Selby,Andrew Vargo,Sebastian Vollmer
### Background
当前临床试验需要大量患者以达到统计功效，这一过程不仅耗时耗资，而且难以实现。基于大语言模型（LLMs）的知识，研究提出了一种新的分层贝叶斯建模框架，旨在通过利用LLM提供的先验信息来减少对患者的依赖。这种方法旨在利用预先训练的LLM从模型中直接获得参数先验，从而整合外部临床专业知识，改进贝叶斯安全性建模。通过实证的温度敏感性分析和严格的交叉验证，发现LLM推导出的先验能够一致地提高预测性能，相较于传统的元分析方法更具优势。
### Innovation
提出了一种利用大语言模型（LLMs）的分层贝叶斯建模框架，直接从模型获得参数先验，从而增强贝叶斯安全建模。该方法通过提前训练的LLM系统地激发贝叶斯模型中的超参数，并将其与传统的元分析方法进行对比，证明了LLM推导出的先验能够改进预测性能，最终目标是减少临床试验所需患者数量，优化临床试验设计。
### Conclusion
LLM推导的先验方法显著提高了预测性能，有助于更加高效和专家导向的临床试验设计，减少患者需求，具有重塑药物安全性监测和监管决策的潜力。
## 106. `cs.AI` - RepoDebug：大规模语言模型在仓库级多任务和多语言调试评估 [PDF](https://arxiv.org/pdf/2509.04078), [HTML](https://arxiv.org/abs/2509.04078)
### Authors
Jingjing Liu,Zeming Liu,Zihao Cheng,Mengliang He,Xiaoming Shi,Yuhang Guo,Xiangrong Zhu,Yuanfang Guo,Yunhong Wang,Haifeng Wang
### Background
大型语言模型（LLMs）在代码调试特别是自动程序修复方面显示出显著的能力，可能大幅减少开发人员的时间成本并提升效率。为了促进代码调试的发展，已经取得了显著的数据集进展，但这些数据集主要评估LLMs的功能级代码修复能力，忽略了更复杂和现实的仓库级场景，导致对LLMs在仓库级调试中的挑战理解不完整。尽管提出了一些仓库级数据集，但它们往往存在任务、语言和错误类型多样性有限等局限性。
### Innovation
本文介绍了一个多任务、多语言的仓库级代码调试数据集RepoDebug，包含了22种错误类型，支持8种常用编程语言和3个调试任务。此外，我们在10个LLM模型上进行了评估实验，显示最佳性能的Claude 3.5 Sonnect模型在仓库级调试中表现仍不尽人意，突显了该领域的挑战性。
### Conclusion
通过RepoDebug数据集和实验，本文揭示了LLMs在仓库级调试中的不足，并为未来的研究提供了新的数据支持和挑战。
## 107. `cs.AI` - Python包中的漏洞及其检测：一项实证研究 [PDF](https://arxiv.org/pdf/2509.04260), [HTML](https://arxiv.org/abs/2509.04260)
### Authors
Haowei Quan,Junjie Wang,Xinzhe Li,Terry Yue Zhuo,Xiao Chen,Xiaoning Du
### Background
在快速发展的软件开发环境中，Python因其简洁性、多样性和广泛的生态系统而脱颖而出。Python包作为组织、重用和分发的单位，已经成为一个紧迫的问题，这由大量已报告的漏洞报告所体现。作为一种脚本语言，Python经常与其他语言合作以提高性能或实现互操作性，这增加了Python包固有漏洞的复杂性。当前的漏洞检测工具的有效性尚未得到充分探索。
### Innovation
本文引入了PyVul，这是第一个全面的Python包漏洞基准套件，包括1,157个已公开报告且开发者验证过的漏洞，每个漏洞都与其受影响的包相关联。PyVul在提交和函数级别提供了注释，并集成了基于LLM的数据清洗方法，实现100%提交层级和94%函数层级的高精度标签，确立了PyVul作为最准确的大规模Python漏洞基准的地位。此外，分析还表明多语言Python包更有可能存在漏洞。利用这个基准对最先进的检测器进行测试，显示了现有工具与有效识别Python包中的实际安全问题的能力之间存在显著差距。
### Conclusion
对Python包中观察到的顶级CWE进行实证审查，揭示了当前检测工具的细粒度局限性，并强调了该领域未来进展的必要性。评估最先进的检测器时发现，现有工具识别真实世界安全性问题的能力远远不足以满足需求。
## 108. `cs.AI` - What Fundamental Structure in Reward Functions Enables Efficient Sparse-Reward Learning? [PDF](https://arxiv.org/pdf/2509.03790), [HTML](https://arxiv.org/abs/2509.03790)
### Authors
Ibne Farabi Shihab,Sanjeda Akter,Anuj Sharma
### Background
该研究探讨了能够高效执行稀疏奖励强化学习的基本奖励函数特性。研究通过低秩结构在奖励矩阵中的视角进行，揭示这种结构如何从指数级样本复杂性过渡到多项式级样本复杂性，这是稀疏奖励强化学习领域的首个此类结果。
### Innovation
研究人员引入了Policy-Aware Matrix Completion (PAMC)方法，这是一种新的矩阵填充理论与强化学习的连接方式，通过政策相关采样进行新的分析。该框架提供了：(i) 一般稀疏奖励观测下的不可能性结果，(ii) 基于动力学的奖励自由表示学习，(iii) 通过协同比预测实现的免分布置信集，(iv) 在低秩结构只有近似时表现稳健的矩阵填充保证。
### Conclusion
实验发现，超过一半的研究领域存在可利用的结构。PAMC方法比强探索、结构化和表示学习基准提高了1.6到2.1倍的样本效率，同时增加了约20%的计算量。这些结果表明结构化奖励学习是一个有希望的新范式，对机器人技术、医疗服务以及其他关键性和样本成本高应用领域具有直接影响。
## 109. `cs.AI` - 锂离子电池系统的鲁棒年龄感知控制的强化学习方法及数据驱动形式验证 [PDF](https://arxiv.org/pdf/2509.04288), [HTML](https://arxiv.org/abs/2509.04288)
### Authors
Rudi Coppola,Hovsep Touloujian,Pierfrancesco Ombrini,Manuel Mazo Jr
### Background
可充电锂离子电池在现代技术中不可或缺。近年来，这类电池的生产、设计及其配套的充电和安全协议（称为电池管理系统BMS）成为了研究的核心。一个基本的挑战是如何在充电速度与电池老化行为（导致电池容量下降）之间找到平衡。
### Innovation
该研究提出了一种结合强化学习（RL）与数据驱动形式验证的方法，用于锂离子电池系统的鲁棒年龄感知控制。具体而言，通过反例引导归纳合成（Counterexample-Guided Inductive Synthesis）方案，将RL用于合成个体控制器，并通过数据驱动的抽象来指导控制器的分割成切换结构，依据电池初始输出测量结果。该策略实现了由RL控制器的离散选择与连续电池动力学耦合的混合系统。当设计方案达到预期标准时，抽象层能够提供闭环电池性能的概率性保证。
### Conclusion
该方法通过R//子和数据驱动形式验证实现了锂离子电池系统的鲁棒年龄感知控制。该系统能够提供电池性能的闭环概率性保证，同时解决了充电速度与电池老化之间的基本平衡问题。
## 110. `cs.AI` - HumAIne-Chatbot: 通过强化学习实现实时个性化对话AI [PDF](https://arxiv.org/pdf/2509.04303), [HTML](https://arxiv.org/abs/2509.04303)
### Authors
Georgios Makridis,Georgios Fragiadakis,Jorge Oliveira,Tomaz Saraiva,Philip Mavrepis,Georgios Fatouros,Dimosthenis Kyriazis
### Background
当前的对话AI系统通常提供通用的、一刀切的交互方式，忽视了个体用户特征，并缺乏对话管理的适应性。
### Innovation
引入了HumAIne-chatbot，这是一种通过新颖的用户画像框架进行个性化响应的AI驱动会话代理。系统预训练在多样化的GPT生成虚拟人像集上，以建立广泛先验用户类型。在实时交互期间，在线强化学习代理通过结合隐式信号（如打字速度、情感、参与时长）和显式反馈（如喜好和不喜欢）来细化个性化用户模型。该画像动态指导对话策略，实现内容和风格的实时适应。
### Conclusion
通过控制实验，使用50个合成人像在多个对话领域进行评估。结果显示，在启用个性化功能的情况下，用户满意度、个性化准确性和任务完成均有所提高。统计分析表明，在关键指标上，个性化和非个性化条件之间存在显著差异，且效应量较大。这些结果突显了基于AI的用户画像的有效性，并为未来的真实世界验证奠定了坚实的基础。
## 111. `cs.AI` - SelfAug: 通过分布自我对齐缓解检索增强生成中的灾难性遗忘 [PDF](https://arxiv.org/pdf/2509.03934), [HTML](https://arxiv.org/abs/2509.03934)
### Authors
Yuqing Huang,Rongyang Zhang,Qimeng Wang,Chengqiang Lu,Yan Gao,Yi Wu,Yao Hu,Xuyang Zhi,Guiquan Liu,Xin Li,Hao Wang,Enhong Chen
### Background
近年来，大型语言模型（LLMs）在自然语言处理中的进步通过其在理解并执行各种任务方面的出色能力彻底改变了该领域。尽管监督微调，尤其是在检索增强生成（RAG）场景中的应用，有效地提升了任务特定性能，但这也导致模型产生灾难性遗忘，即模型会忘记之前学习的知识和能力。现有解决方案需要访问一般指令数据，或者无法保留模型的原始分布。
### Innovation
我们提出了SelfAug，一种自我分布对齐的方法，通过将输入序列的概率分布对齐，保留模型的语义分布，从而缓解灾难性遗忘并提高下游性能。广泛的实验证明，SelfAug在下游学习和通用能力保留之间达到了更好的平衡。我们的实验分析揭示了分布变化与RAG场景中灾难性遗忘严重性之间的直接关系，强调了在一般指令微调中缺乏RAG能力导致的分布变化。
### Conclusion
我们的发现不仅推进了对RAG上下文中灾难性遗忘的理解，也为跨多种微调场景提供了实际解决方案。我们的代码公开可用，请访问[this https URL]查看。
## 112. `cs.AI` - 记忆消失速度很快：大型语言模型中过时医疗知识的记忆评估 [PDF](https://arxiv.org/pdf/2509.04304), [HTML](https://arxiv.org/abs/2509.04304)
### Authors
Juraj Vladika,Mahdi Dhaini,Florian Matthes
### Background
随着大型语言模型（LLMs）能力的提升，它们在医疗领域的应用潜力巨大，能够辅助医学研究人员和医生。然而，这些模型依赖于静态训练数据，而医疗建议会随着新研究和进展不断变化。如果LLMs记住的是过时的医学知识，它们可能会提供有害的建议或在临床推理任务中失败。
### Innovation
本文通过引入两个基于系统回顾的新问题-答案（QA）数据集——MedRevQA（包含16,501个QA对覆盖一般生物医学知识）和MedChangeQA（一个包含512个QA对的子集，其中医学共识随时间发生变化）——来研究这一问题；通过评估八种知名LLM在这些数据集上的表现，发现所有模型均表现出对过时知识的依赖；并分析了陈旧的预训练数据和训练策略的影响，为开发更当前可靠的医疗AI系统指明了未来方向。
### Conclusion
研究发现大型语言模型普遍存在依赖过时知识的问题，并提出未来方向来减轻这种现象，从而促进开发更当前可靠的医疗AI系统。
## 113. `cs.AI` - 从编辑器到密集几何预测器 [PDF](https://arxiv.org/pdf/2509.04338), [HTML](https://arxiv.org/abs/2509.04338)
### Authors
JiYuan Wang,Chunyu Lin,Lei Sun,Rongying Liu,Lang Nie,Mingxing Li,Kang Liao,Xiangxiang Chu,Yao Zhao
### Background
利用预训练的文本到图像（T2I）生成模型中的视觉先验在密集预测方面取得了成功。然而，密集预测本质上是图像到图像的任务，提示图像编辑模型可能比T2I生成模型更适合进行微调。
### Innovation
提出了一种名为FE2E的框架，这是一种创新的方法，使用基于扩散变换器（DiT）架构的高级编辑模型进行密集几何预测。这种方法通过重新制定编辑器的原始流动匹配损失为“一致速度”训练目标来进行适应，并使用对数量化解决编辑器本有的BFloat16格式与任务所需的高精度之间的冲突。此外，利用DiT的全局注意力在单次前向传播中实现深度和法线的无成本联合预测，增强监督信号。
### Conclusion
FE2E在多个数据集上实现了零样本单目深度和法线估计的性能提升，尤其是在ETH3D数据集上实现了超过35%的性能提升，优于深度无所不能系列，后者训练数据量是它的100倍。项目页面可以通过这个链接访问：[这里](this https URL)
## 114. `cs.AI` - PARCO: 音位增强的鲁棒上下文语音识别系统通过对比实体消歧 [PDF](https://arxiv.org/pdf/2509.04357), [HTML](https://arxiv.org/abs/2509.04357)
### Authors
Jiajun He,Naoki Sawada,Koichi Miyazaki,Tomoki Toda
### Background
ASR系统在处理领域特定的命名实体时遇到挑战，尤其是同音词。上下文ASR能够提升识别率，但常常因为实体多样性有限而未能捕捉细微的音素变化。先前的方法将实体视为独立的标记，导致多标记偏向不完整。
### Innovation
本文提出了Phoneme-Augmented Robust Contextual ASR via COntrastive entity disambiguation（PARCO），该方法融合了音位感知编码、对比实体消歧、实体级别监督和层次化实体过滤等组件。这些组件提升了音素的区分能力，确保完整的实体检索，并在不确定情况下降低了误触发。
### Conclusion
实验结果显示，PARCO在Chinese AISHELL-1上的CER为4.22%，在English DATA2上的WER为11.14%，并在1,000个干扰词下显著优于基线方法。PARCO还展示了在THCHS-30和LibriSpeech等跨领域数据集上的稳健改进。
## 115. `cs.AI` - 注意力机制作为自适应滤波器 [PDF](https://arxiv.org/pdf/2509.04154), [HTML](https://arxiv.org/abs/2509.04154)
### Authors
Peter Racioppo
### Background
现有的注意力机制通常直接比较查询和键向量来计算注意力权重。然而，这些方法可能无法有效处理输入序列的动态性质。AFA（Adaptive Filter Attention）通过引入一个可学习的动力学模型，直接将动力学模型整合到注意力权重的计算中，从而更好地处理序列的动态性。这种方法通过将输入序列视为线性随机微分方程（SDE）的离散观察值，使得可以通过封闭形式的微分李雅普诺夫方程解析传播对间不确定性。
### Innovation
AFA通过将线性动力学模型应用于SDE，提出了一个新的注意力机制。它利用了封闭形式的微分李雅普诺夫方程来有效传播对间的不确定性，并且通过最大似然估计得到了注意力权重。此外，AFA通过一个状态矩阵的特征值约束，得到了一个简化版本，该版本与标准注意力机制具有相同的计算和内存复杂度。当动力学和过程噪声趋于零时，并使用小角度近似时，可以恢复出普通的点积注意力。
### Conclusion
AFA通过将动力学模型直接整合到注意力机制中，有效地处理了序列的动态性。这种方法不仅提供了一种新的视角来理解注意力机制，还提供了一种具备相同计算复杂度和内存复杂度的简化版本，同时保留了传统注意力机制的优点。
## 116. `cs.AI` - AUDETER: 大规模开放世界环境下的伪语音检测数据集 [PDF](https://arxiv.org/pdf/2509.04345), [HTML](https://arxiv.org/abs/2509.04345)
### Authors
Qizhou Wang,Hanxun Huang,Guansong Pang,Sarah Erfani,Christopher Leckie
### Background
语音生成系统可以生成非常逼真的语音，有时甚至无法与真人语音区分开来。尽管已经有多种深度造假检测方法，但在真实世界环境中的有效性因训练样本与测试样本之间的领域差异（由多样化的人声以及迅速发展的语音合成系统引起）而不可靠。现有的数据集未能充分涵盖现实应用中的挑战，缺乏多样性和最新的真实和虚假语音样本。
### Innovation
提出了一种名为AUDETER（AUdio DEepfake TEst Range）的大规模、高度多样化的深度造假语音数据集，用于全面评估和稳健开发泛化模型。该数据集包含超过4500小时由11种最新TTS模型和10种 vocoder生成的合成语音，共产生300万条语音片段，成为规模最大的深度造假语音数据集。通过与AUDETER的广泛实验发现，现有的方法在现有数据集上的训练难以推广到新的深度造假语音样本，并在未见过的人声上导致较高的误报率，强调了全面数据集的需求。而训练于AUDETER上的方法则显著提高了泛化检测性能，降低了检测错误率44.1%至51.6%，在流行数据集In-the-Wild中实现了仅4.17%的错误率，为训练泛化式的深度造假语音检测器奠定了基础。
### Conclusion
AUDETER 提供了全面的检测基准，有助于训练能够在开放世界环境中泛化的深度造假语音检测器。
## 117. `cs.AI` - TAGAL: Tabular Data Generation using Agentic LLM Methods [PDF](https://arxiv.org/pdf/2509.04152), [HTML](https://arxiv.org/abs/2509.04152)
### Authors
Benoît Ronval,Pierre Dupont,Siegfried Nijssen
### Background
数据生成是提高机器学习任务性能的一种常见方法，特别是在模型训练分类任务中。本文介绍了一种名为TAGAL的方法，利用一种代理性的工作流程生成合成表格数据。这种方法利用大型语言模型（LLMs）进行自动化和迭代的过程，不需要进一步的LLM训练，同时也利用LLMs在生成过程中加入外部知识。该方法在多样化的数据集上进行了评估，并从生成数据的不同质量方面进行了评估。研究还包括训练分类器以及结合真实和合成数据对下游机器学习模型的效用评估，并对比了真实数据和生成数据之间的相似性。研究表明，TAGAL能够与需要LLM训练的方法保持相当的性能，并且通常优于其他不需要训练的方法，这表明代理性的工作流程具有潜力，并为基于LLM的数据生成方法开拓了新的方向。
### Innovation
TAGAL利用一种代理性的工作流程生成合成表格数据，利用大型语言模型进行自动化和迭代的过程，而不需要额外的LLM训练。这种利用LLM的方法还能够在生成过程中引入外部知识。研究结果表明，TAGAL能够与需要LLM训练的方法保持相当的性能，并且通常优于其他不需要训练的方法。这为基于LLM的数据生成方法开拓了新的方向。
### Conclusion
TAGAL能够与需要LLM训练的方法保持相当的性能，并且通常优于其他不需要训练的方法。这表明代理性的工作流程具有潜力，并为基于LLM的数据生成方法开拓了新的方向。
## 118. `cs.AI` - 大型语言模型后训练统一视角 [PDF](https://arxiv.org/pdf/2509.04419), [HTML](https://arxiv.org/abs/2509.04419)
### Authors
Xingtai Lv,Yuxin Zuo,Youbang Sun,Hongyi Liu,Yuntian Wei,Zhekai Chen,Lixuan He,Xuekai Zhu,Kaiyan Zhang,Bingning Wang,Ning Ding,Bowen Zhou
### Background
大型语言模型的训练数据主要来源于两类：在线数据（由模型生成的试运行数据）和离线数据（人类或其它模型的演示数据）。现有的方法通常是使用强化学习（RL）和监督微调（SFT）分别处理这两种数据。然而，该论文指出这些方法并不是对立的，而是统一优化过程的不同实例。
### Innovation
该论文提出了一个统一的策略梯度估计器，并展示了多种后训练方法如何在不同的数据分布假设和不同偏差-方差权衡下成为同一个目标函数的梯度。受到理论发现的启发，论文提出了混合后训练（HPT）算法，该算法可以动态选择不同的训练信号，既利用演示数据的有效利用，又能确保探索过程的稳定性，同时不会牺牲学习到的推理模式。该论文通过广泛的实验和消融研究验证了统一理论框架和HPT的有效性。
### Conclusion
HPT在六个数学推理基准和两个离分布测试集中，无论模型规模和家族如何，都超过了强大的基线。这显示了HPT在大型语言模型后训练中的有效性和重要性。
## 119. `cs.AI` - 使用自我监督学习增强的空间时间倒置变换器融合多源数据进行停车可用性预测 [PDF](https://arxiv.org/pdf/2509.04362), [HTML](https://arxiv.org/abs/2509.04362)
### Authors
Yin Huang,Yongqi Dong,Youhua Tang,Li Li
### Background
私人汽车数量的快速增长加剧了城市停车难题，因此迫切需要准确有效的停车可用性预测来支持城市规划和管理。研究指出，现有的建模方法存在时空依赖关系建模不足和多源数据利用不足的问题。
### Innovation
该研究提出了SST-iTransformer方法以解决上述问题。该方法运用K均值聚类确定停车区域集群（PCZs），并从多种交通模式（地铁、公交车、在线网约车和出租车）中提取并整合交通需求特征，结合自监督学习增强了空间时间倒置变换器的模型表现，引入了双重注意力机制，分别捕捉长期时间和跨变量交互效应，使用实际数据进行了广泛实验，表明SST-iTransformer在预测准确性上超越了基线模型，并通过削除不同数据源的重要性实现了最优表现，强调了空间依赖性的建模重要性。
### Conclusion
研究结果表明，SST-iTransformer方法在预测停车可用性上达到了最先进的性能，特别是在MSE和MAE指标上表现出色。骑乘商务数据的融合带来了最大的性能提升，其次是出租车数据，而固定路线交通数据的作用较为有限。进一步的空间相关性分析也证实了忽略集群中相关停车地点的历史数据会导致显著的性能下降，从而强调了需要建模空间依赖关系。
## 120. `cs.AI` - DEXOP: 一种用于灵巧人类操作机器人转移的设备 [PDF](https://arxiv.org/pdf/2509.04441), [HTML](https://arxiv.org/abs/2509.04441)
### Authors
Hao-Shu Fang,Branden Romero,Yichen Xie,Arthur Hu,Bo-Ruei Huang,Juan Alvarez,Matthew Kim,Gabriel Margolis,Kavya Anbarasu,Masayoshi Tomizuka,Edward Adelson,Pulkit Agrawal
### Background
该研究背景在于提供一种新的范式，通过传感器化和记录人类的操控动作，并最大化数据向实际机器人迁移的可能性。研究基于灵巧操作任务的需求，提出了DEXOP，一种被动的手部外骨骼，旨在最大程度地增强用户在自然环境中的细动作和触觉数据收集能力。
### Innovation
研究的创新点在于提出了一个称为perioperation的范式，将人类操作任务的数据收集与机器人操作数据迁移相结合。通过机械连接人类手指与机器人手指，DEXOP提供了直接的触觉反馈（通过本体感觉）和手型镜像，使任务演示更加自然，提高了人类操作的速度和准确性，从而有效提高了机器人灵巧操作的表现。
### Conclusion
研究通过DEXOP设备对于一系列灵巧且接触丰富的任务进行了评价，验证了它大规模收集高质量示范数据的能力。使用DEXOP数据学习得到的策略在单位数据收集时间内显著提升了任务性能，证明了DEXOP作为推进机器人灵巧操作的强大工具的价值。
## 121. `cs.AI` - SSGaussian: 具有语义感知和结构保留的3D风格转移 [PDF](https://arxiv.org/pdf/2509.04379), [HTML](https://arxiv.org/abs/2509.04379)
### Authors
Jimin Xu,Bosheng Qin,Tao Jin,Zhou Zhao,Zhenhui Ye,Jun Yu,Fei Wu
### Background
近年来，神经辐射场和3D格点填充等神经表示方法的进步激发了3D场景应用风格迁移的兴趣。尽管现有方法能够将风格模式应用到3D一致的神经表示上，但在从参考风格图像中提取和转移高层次风格语义方面仍然存在困难。此外，风格化结果常常缺少结构清晰度和分离度，导致难以区分3D场景中的不同实例或对象。因此，论文旨在解决这些限制，提出了一种新颖的3D风格转移管道，有效结合了预训练2D扩散模型的先验知识。
### Innovation
论文创新之处在于：提出了一种新的3D风格转移管道，包含两个关键阶段：首先利用扩散模型先验生成关键视角的风格化渲染；然后将这些风格化的关键视角转移到3D表示中。该管道采用了两种创新设计：一是视角间风格对齐，通过向UNet的最后一个上采样块中插入跨视角注意力机制，实现了跨多个关键视角的功能交互，确保扩散模型生成的风格化关键视角同时保持风格忠实度和实例级别一致性；二是实例级别风格转移，有效利用不同实例级别的风格一致性，在这些关键视角之间进行转移，最终在3D表示上产生更加结构化、视觉连贯且艺术丰富的风格化效果。
### Conclusion
大量的定性和定量实验表明，该3D风格转移管道显著优于现有的先进方法，无论是在面向前方的场景还是在具有挑战性的360度环境中都有出色表现。详情请访问项目页面：this https URL进行沉浸式可视化。
## 122. `cs.AI` - AI中的(不)理性：现状、研究挑战和开放问题 [PDF](https://arxiv.org/pdf/2311.17165), [HTML](https://arxiv.org/abs/2311.17165)
### Authors
Olivia Macmillan-Scott,Mirco Musolesi
### Background
在人工智能（AI）领域，理性概念是核心。无论是为了模拟人类推理还是追求有界最优性，我们的目标都是让人工代理尽可能地理性。尽管‘理性’在AI中至关重要，但并不存在统一的理性代理定义。该文对AI中的理性与非理性进行了综述，并总结了这一领域中的开放性问题。
### Innovation
研究了其他领域（如经济学、哲学和心理学）对理性理解如何影响AI中的理性概念，并探讨了应对非理性代理的方法，特别是在与人工代理互动时，虽然已有某些方法开发，但该领域的研究仍相对有限。
### Conclusion
文中讨论了人类与人工代理之间的相互作用以及理性在这类交互中的角色。在人类和人工代理的潜在非理性行为问题上，仍有大量问题需要解答。
## 123. `cs.AI` - Delta Activations: 一种小型语言模型表示法 [PDF](https://arxiv.org/pdf/2509.04442), [HTML](https://arxiv.org/abs/2509.04442)
### Authors
Zhiqiu Xu,Amish Sethi,Mayur Naik,Ser-Nam Lim
### Background
强大的开源大型语言模型的成功为社区创造了大量的适应特定任务和领域的后训练模型。然而，由于元数据不一致和非结构化的存储库，导航和理解这些模型仍然具有挑战性。
### Innovation
本文引入了Delta Activations方法，通过测量相对于基础模型的内部激活变化来表示后训练模型作为向量嵌入。这种方法可以有效进行领域和任务的聚类，并揭示了模型景观中的结构。此外，Delta Activations还具有稳健性和可加性等特性，能够在混合数据集的微调情况下表现良好。文章还展示了通过少量微调可以通过Delta Activations嵌入任务，并进一步探索了其在模型选择和合并中的应用。
### Conclusion
希望Delta Activations能够助力公共模型的重用实践。相关代码可以在文中提供的网址找到。
## 124. `cs.AI` - 无思考只有AI：有偏见的语言模型建议限制了在简历筛选中的人类自主权 [PDF](https://arxiv.org/pdf/2509.04404), [HTML](https://arxiv.org/abs/2509.04404)
### Authors
Kyra Wilson,Mattea Sim,Anna-Maria Gueorguieva,Aylin Caliskan
### Background
本研究通过一项简历筛选实验（参与者人数为528人），研究人们在与模拟具备种族偏见的人工智能模型合作评估16种高、低地位职业的候选人时，对不同种族候选人的偏好情况。实验中使用的模拟人工智能偏见模型反映了真实世界人工智能系统中的客观和假设的种族偏见。研究还包括利用隐含关联测试（IATs）测量人们潜意识中对种族与地位的关联，这些测试预测着可能产生的歧视性招聘决策。以往研究通常没有探讨人类与人工智能合作的具体情况。
### Innovation
本研究创新之处在于，通过实验探讨了在与模拟具备种族偏见的人工智能模型合作填写简历时，人们对不同种族候选人的偏好情况。实验结果显示，在没有使用人工智能或使用没有种族偏见人工智能模型的情况下，人们会平等选择各种族的候选人；然而，当交互的人工智能模型偏向某一特定群体时，人们也会倾向于青睐那些候选人，有高达90%的时间。此外，研究发现，在进行隐含关联测试后进行简历筛选，可以增加不与常见种族地位刻板印象相符合的候选人的被选率，增加了13%。即使人们认为人工智能的建议质量较低或不重要，在特定情况下人们的决策仍然容易受到人工智能偏见的影响。
### Conclusion
本研究的结论认为，在与人类-人工智能协同决策情况下的自主权受到人工智能偏见的影响；这为人工智能与人类决策结合情景设计和评估提供了启示，同时也提出了减轻协作决策任务中偏见的策略。政策制定者应意识到人工智能协同决策中的复杂性，以人为本地设计和监管这些系统。
## 125. `cs.AI` - IPA：一种保留信息的输入投影框架，用于高效基础模型适应 [PDF](https://arxiv.org/pdf/2509.04398), [HTML](https://arxiv.org/abs/2509.04398)
### Authors
Yuan Yin,Shashanka Venkataramanan,Tuan-Hung Vu,Andrei Bursuc,Matthieu Cord
### Background
参数高效微调（PEFT）方法，例如LoRA，通过向预训练权重中注入低秩更新来减少适应成本。然而，LoRA中的下投影是随机初始化且与数据无关的，可能会丢弃有用信息。先前的分析表明，下投影在训练过程中变化不大，而上投影则承担了主要的适应任务，使得随机输入压缩成为性能瓶颈。
### Innovation
本文 propose IPA，这是一种明确保留减少隐藏空间中的信息的特征感知投影框架。在线性情况下，IPA 使用近似主成分的算法进行实现，可实现高效的投影预训练，且几乎不影响推理推断。实验结果显示，无论是在语言还是视觉基准测试中，IPA 均优于 LoRA 和 DoRA，在常识推理方面平均提高了 1.5 分，VTAB-1k 上提高了 2.3 分。当投影固定时，IPA 还可以用约一半的可训练参数达到与完整 LoRA 相同的性能。
### Conclusion
本文提出 IPA，即一种特征感知的输入投影框架，能够明确保留减少的隐藏空间中的信息。实验结果证明，IPA 在各种基准测试中均与 LoRA 和 DoRA 展现了更好的性能，尤其是在常识推理任务和 VTAB-1k 数据集上，同时使用了更少的可训练参数。
## 126. `cs.AI` - ChronoGraph: 基于实际微服务的图结构多变量时间序列数据集 [PDF](https://arxiv.org/pdf/2509.04449), [HTML](https://arxiv.org/abs/2509.04449)
### Authors
Adrian Catalin Lutu,Ioana Pintilie,Elena Burceanu,Andrei Manolache
### Background
当前没有专门针对微服务系统的多变量时间序列预测和异常检测的数据集。大多数现有的基准数据集来自工业控制系统或交通和空气质量领域，缺乏真实微服务系统中的多变量时间序列、显式可读的依赖图以及与实际事件对齐的异常标签。
### Innovation
ChronoGraph 提供了一个名为微服务的图结构多变量时间序列预测数据集，每个节点是一个服务，这提供了系统级别的性能度量作为多变量流；并加之带有显式的、机器可读的服务依赖图进行编码；还提供了与实际事件对齐的专家标注的异常标签。与现有基准数据集相比，ChronoGraph 独特地结合了多变量时间序列、显式的机器可读依赖图以及与真实事件对齐的异常标签。
### Conclusion
ChronoGraph 为结构感知预测和事件感知评估提供了一个现实基准；并报告了涵盖预测模型、预训练时间序列基础模型和标准异常检测器的基线结果。
## 127. `cs.AI` - 智能 primer [PDF](https://arxiv.org/pdf/2008.07324), [HTML](https://arxiv.org/abs/2008.07324)
### Authors
Karl Fezer,Andrew Sloss
### Background
智能是所有生命体的基础，也是人工智能（AI）的基础。机器学习作为人工智能的一种形式已经在生活中产生了显著影响。未来的工程师和科学家将需要对心理学、哲学和伦理学等领域有更广泛的了解。早期的科幻作品中工程师和科学家在这些领域往往表现不足。现代社会对人工智能的需求和法律要求迫使这些更广泛的学科被重视。
### Innovation
本文通过讨论与智能相关的想法，帮助读者理解智能的含义及其影响和约束，潜在地概述未来系统的能力。最后一句话提出了一个开放式问题，即“42可能是正确的答案，但问题是什么？”这种方法鼓励读者思考和探索智能的更深层次含义。
### Conclusion
智能不是一个单一可度量的数量，而是生物学、物理学、哲学、认知科学、神经科学、心理学和计算机科学等多个领域的交叉学科。通过这篇 primer，作者旨在为读者提供一个关于智能的概述，并激发读者对未来智能系统的思考和讨论。
## 128. `cs.AI` - PIN：配对和交替多模态文档的密集型数据集 [PDF](https://arxiv.org/pdf/2406.13923), [HTML](https://arxiv.org/abs/2406.13923)
### Authors
Junjie Wang,Yuxiang Zhang,Minghao Liu,Yin Zhang,Yatai Ji,Weihao Xuan,Nie Lin,Kang Zhu,Zhiqiang Lin,Yiming Ren,Chunyang Jiang,Yiyao Yu,Zekun Wang,Tiezhen Wang,Wenhao Huang,Jie Fu,Qunshu Liu,Yujiu Yang,Ge Zhang,Ruibin Yuan,Bei Chen,Wenhu Chen
### Background
近期，大规模多模态模型（LMMs）通过利用庞大的多模态数据集提升了复杂知识驱动任务的能力。然而，感知和推理错误等持续存在的挑战限制了它们的效能，特别是在解释复杂的视觉数据和推导多模态关系方面。
### Innovation
本文引入了一种新的数据格式——Paired and INterleaved multimodal documents (PIN)，该格式独特地将富含语义的Markdown文件与捕捉文档整体布局的整体图像相结合，来深化视觉和文本知识的整合。基于该格式，构建并开源了两个大规模数据集：PIN-200M（约2亿份文档）和PIN-14M（约14百万份），这些数据集来自多种网络和科学来源，并支持英语和中文。
### Conclusion
本文提供了灵活的数据格式和丰富的资源，为预训练策略和开发更强大的知识密集型LMMs奠定了基础。同时提供了详细的统计分析和质量信号，使得研究人员可以轻松地筛选和选择数据用于特定任务。
## 129. `cs.AI` - 跨语言科学：评估大语言模型多语言翻译科学论文 [PDF](https://arxiv.org/pdf/2502.17882), [HTML](https://arxiv.org/abs/2502.17882)
### Authors
Hannah Calzi Kleidermacher,James Zou
### Background
科研本质上是全球化的，但大多数学术期刊仅以英语出版，这为非英语母语的研究者设定了障碍。
### Innovation
利用大型语言模型（LLMs）自动翻译已发表的科学文章，同时保留其原生JATS XML格式，开发了一种可实施的自动化方法。此方法将多学科的科学论文翻译成28种语言，并提出了一种新颖的问题和答案（QA）基准测试方法，以评估翻译准确性。
### Conclusion
基准测试结果显示平均准确率为95.9%，表明科学细节得到准确传达。用户研究显示作者普遍认为翻译准确反映了原文信息，三分之一的作者倾向于保留某些技术术语的英语版本，以使其更加熟悉。最终，展示了如何使用上下文学习技术调整翻译以适应特定领域的偏好。
## 130. `cs.AI` - WASP: 一种检测学习到的偏见的空间权重方法 [PDF](https://arxiv.org/pdf/2410.18970), [HTML](https://arxiv.org/abs/2410.18970)
### Authors
Cristian Daniel Păduraru,Antonio Bărbălau,Radu Filipescu,Andrei Liviu Nicolicioiu,Elena Burceanu
### Background
在训练机器学习模型时，确保模型清晰地理解每个类别的定义至关重要。尽管有一些研究致力于识别数据集中可能影响模型对类别的理解的虚假相关性，当前的所有方法都仅依赖于数据或错误分析。这意味着它们无法指出那些在验证或训练集反例中尚未指出的模型学习的虚假相关性。
### Innovation
提出了一种方法，称为Weight-space Approach to detecting Spuriousness (WASP)，该方法将焦点从分析模型的预测转向分析模型的权重，这解释了决策背后的机制，从而提供了更多的见解。WASP 依赖于在模型进行细调以捕捉各种（虚假）相关性时分析基础模型的权重。此方法能够（i）在训练或验证反例尚未揭示的情况下揭示数据集中的虚假相关性；（ii）适用于多种模态，如图像和文本；（iii）揭示了ImageNet-1k分类器之前未开发的虚假相关性。
### Conclusion
通过分析权重，WASP 能够发现比现有方法更多的虚假相关性，并适用于多种模态，从而提供了一种更深入、更全面的方法来检测模型中的虚假相关性。
## 131. `cs.AI` - 量子电路中的可转移信念模型 [PDF](https://arxiv.org/pdf/2410.08949), [HTML](https://arxiv.org/abs/2410.08949)
### Authors
Qianli Zhou,Hao Luo,Lipeng Pan,Yong Deng,Eloi Bosse
### Background
可转移信念模型作为一种 Dempster-Shafer 理论的语义解释，允许智能体在不精确和不完整环境中进行推理和决策。该模型通过为其处理不可靠证词提供独特的语义，与贝叶斯方法相比，提供了更合理和通用的信念转移过程。然而，由于在更新信任函数时需要同时考虑信任度和焦点集的结构，这导致在推理过程中额外的计算复杂性，使得可转移信念模型在近期的研究中逐渐失宠。
### Innovation
本文在量子电路中实现了可转移信念模型，并表明在量子计算框架中，信念函数是贝叶斯方法的更紧凑和有效的替代方案。利用量子计算的独特属性，本文还提出了一些新型的信念转移方法。此外，本文还为量子人工智能模型的基本信息表示引入了新的视角，表明在量子电路中处理不确定性时，信念函数比贝叶斯方法更合适。
### Conclusion
本文通过在量子电路中实现可转移信念模型，证明了信念函数在量子计算框架中的优势，并提出了新的信念转移方法，为量子人工智能模型的信息表示提供了新的视角。
## 132. `cs.AI` - 线性有序集中的最小元素作为 fallback 的受限选择的形式化 [PDF](https://arxiv.org/pdf/2506.03315), [HTML](https://arxiv.org/abs/2506.03315)
### Authors
Kai Sauerwald,Kenneth Skiba,Eduardo Fermé,Thomas Meyer
### Background
本文研究了如何使用线性顺序来实现选择函数，这些选择函数对潜在的选择集有所限制，即选择不发生在所有选项的全体幂集中。在某些受限设置中，通过关系对选项进行选择可能是不可行的。文章探讨了在这些受限情况下，如何通过选项集合的线性顺序来构建选择函数，即使最小元素被编码为 fallback 值也是如此。本文还为一般情况及集合闭包输入限制下的此类选择函数提供了形式化方法。受限选择结构在知识表示与推理中具有应用，文中讨论了这些结构在理论变化和抽象论辩中的应用。
### Innovation
本文展示了通过设有最小元素作为 fallback 值的选项集合的线性顺序来构建选择函数是可能的，并对一般情况和集合闭包输入限制下的此类选择函数的公理进行了阐述。
### Conclusion
受限选择结构具有知识表示和推理的应用，特别是理论变化和抽象论辩领域的应用。
## 133. `cs.AI` - Theory of Mind Using Active Inference: A Framework for Multi-Agent Cooperation [PDF](https://arxiv.org/pdf/2508.00401), [HTML](https://arxiv.org/abs/2508.00401)
### Authors
Riddhi J. Pitliya,Ozan Çatal,Toon Van de Maele,Corrado Pezzato,Tim Verbelen
### Background
理论理解（ToM）的能力使智能体能够理解其他人可能有不同的知识和目标，从而在计划自己的行动时考虑他人的信念。以往的主动推理方法在多智能体合作中主要依赖特定任务的共享生成模型或需要显式通讯。
### Innovation
本文提出了一种新颖的方法，通过在主动推理中实现ToM，解决了多智能体合作问题。该方法不依赖于特定任务的共享生成模型，也无需显式交流。智能体维护自己的信念和他人的信念及目标的独立表示，并利用扩展和适应的推理树基规划算法进行递归推理，以系统地探索联合策略空间。
### Conclusion
通过避免碰撞和觅食模拟，该方法展示了具有ToM的智能体比非ToM智能体表现出更好的合作性，通过仅从可观察的行为中推断他人的信念，并在规划自己的行动时考虑这些信念。该研究为通用和可扩展的多智能体系统提供了潜在的解决方案，同时也为理解ToM机制提供了计算见解。
## 134. `cs.AI` - 社会模拟中大语言模型决策的计算基础 [PDF](https://arxiv.org/pdf/2504.11671), [HTML](https://arxiv.org/abs/2504.11671)
### Authors
Ji Ma
### Background
大语言模型（LLMs）在社会科学研究和实际应用场景中越来越像人类决策代理。这些LLM代理通常被赋予人类角色并置于实际生活情境中。然而，这些角色和环境如何影响LLM的行为尚缺乏深入了解。为弥补这一不足，研究者提议并通过实验测试了一种方法，该方法用于探究、量化和调整LLM在博弈游戏（如分配者游戏）中的内部表示，从而研究并调节社会概念如何在变压器模型中编码和设计，这些发现对模型的对齐、去偏见以及在社会仿真模拟中设计社会性的人工智能代理具有重要影响，也能够强化社会学理论和测量。
### Innovation
提出了一种方法来探究、量化和调整LLM在博弈游戏中的内部表示，并通过操纵LLM内部状态的“变量变化向量”（例如，“男性”到“女性”）来显著改变这些变量与模型决策之间的关系。这种方法提供了一种研究和调节社会概念如何在变压器模型中编码和设计的理论框架，将对模型对齐、去偏见和在社会仿真模拟中设计社会性的人工智能代理具有重要意义。
### Conclusion
研究把社会学理论和测量方法引入到了大语言模型在社会模拟中的决策机制研究，提供了一种可操作的手段来研究和调控社会概念如何在变压器模型中被编码和设计，强调了这一领域研究的重要性，为未来更好地理解和应用大语言模型提供了新的视角。
## 135. `cs.AI` - CP-Bench: 使用大型语言模型评估约束建模 [PDF](https://arxiv.org/pdf/2506.06052), [HTML](https://arxiv.org/abs/2506.06052)
### Authors
Kostis Michailidis,Dimos Tsouros,Tias Guns
### Background
约束编程（CP）广泛用于解决组合问题，但其核心过程——约束建模——需要大量专业知识并被认为是限制其更广泛采用的瓶颈。最近的研究探索了使用大型语言模型（LLMs）将组合问题描述转换为可执行的约束模型，但现有的约束建模评估数据集通常局限于小规模、同质或特定领域的实例，无法涵盖实际场景的多样性。因此，本文通过引入CP-Bench，一种包含多样化的组合问题基准，其中这些问题来自CP社区，专为评估LLM驱动的CP建模而构建，来填补这一空白。
### Innovation
本文提出了CP-Bench，一个包含多样化和来自组合优化社区的基准问题的新颖基准。它专门用于评估LLM驱动的约束建模能力，并且研究比较了使用不同约束建模系统（在抽象级别和底层语法方面有所不同）生成模型的性能，发现使用高阶的基于Python的框架具有更好的性能。此外，研究还系统地评估了提示方法和推理时的计算方法在不同LLM中的使用效果，这进一步提高了准确性。
### Conclusion
在CP-Bench基准测试中，使用高阶的Python框架进行约束建模表现出更好的性能。并且基于提示的方法和推理时的计算方法在不同大型语言模型中的应用提高了准确性，最高可达70%。
## 136. `cs.AI` - DeepVIS：通过逐步推理连接自然语言和数据可视化 [PDF](https://arxiv.org/pdf/2508.01700), [HTML](https://arxiv.org/abs/2508.01700)
### Authors
Zhihao Shuai,Boyan Li,Siyu Yan,Yuyu Luo,Weikai Yang
### Background
数据可视化对于揭示模式和传达见解非常强大，但是创建有效的可视化通常需要熟悉制图工具且会打断分析流程。尽管大型语言模型展示出自动将分析意图转化为可视化图的能力，但现有的方法通常作为黑盒操作，缺乏透明的推理过程，这阻碍了用户理解设计原因并改进次优输出。
### Innovation
我们提出了将思维链（CoT）推理集成到自然语言到可视化（NL2VIS）管道中的方法。首先，设计了一个全面的CoT推理过程，并开发了一个自动管道，为现有数据集添加了结构化的推理步骤。其次，引入了nvBench-CoT，这是一种专有数据集，捕获从模糊自然语言描述到最终可视化逐步推理的详细信息，这使得当用于模型微调时能够实现最先进的性能。第三，开发了DeepVIS，这是一种互动视觉界面，紧密集成到CoT推理过程中，允许用户检查推理步骤、识别错误并进行有针对性的调整以改进可视化结果。
### Conclusion
定量基准评估、两个使用案例和用户研究表明我们的CoT框架有效提高了NL2VIS的质量，并为用户提供了解释性的推理步骤。
## 137. `cs.AI` - 扩展 FKG.in：迈向食品声明可追溯网络 [PDF](https://arxiv.org/pdf/2508.16117), [HTML](https://arxiv.org/abs/2508.16117)
### Authors
Saransh Kumar Gupta,Rizwan Gulzar Mir,Lipika Dey,Partha Pratim Das,Anirban Sen,Ramesh Jain
### Background
全球食品景观中充满了关于食品定义、功能、禁忌等方面的科学、文化以及商业主张。这些主张从经过研究的健康益处（如益生菌改善肠道健康）扩展到误导性（泡过的杏仁使人更聪明）、模糊承诺（超级食品增强免疫力）以及根植于文化中的信念（冷食引发咳嗽）。尽管这些主张有着深远的影响，但追踪、验证和解释这些主张的基础设施仍碎片化且不够完善。
### Innovation
本文提出了一个食品声明可追溯网络（FCN），作为我们逐步构建的印度食品知识图谱（FKG.in）的一个扩展。通过使用Reddit数据和大型语言模型，我们设计了一个本体论并制定了半自动的知识整理工作流程，开发了一个实验性实例。FCN综合了经过整理的数据、结构化模式和了解来源的管道，用于食品相关声明的提取和验证。本文的方法既与印度食品知识图谱的应用有关，又能适应其他地区、烹饪或监管环境。
### Conclusion
通过以结构化、可验证和可解释的方式建模食品声明及其追溯，我们旨在为更透明和负责任的食品知识生态系统做出贡献，支持研究人员、政策制定者和最重要的是普通消费者的饮食抉择。
## 138. `cs.AI` - EigenBench：比较行为测度的价值对齐 [PDF](https://arxiv.org/pdf/2509.01938), [HTML](https://arxiv.org/abs/2509.01938)
### Authors
Jonathn Chang,Leonhard Piff,Suvadip Sana,Jasmine X. Li,Lionel Levine
### Background
在人工智能与人类价值观对齐方面，存在一个亟待解决的难题。为了解决缺乏量化价值观对齐度量的难题，本文提出了一种名为EigenBench的方法，这是一种用于比较评估语言模型价值观的黑盒方法。
### Innovation
EigenBench方法通过给定一个模型集合、描述价值观系统的宪法以及一系列情景，返回衡量每个模型价值对齐的分数向量。这种方法使得每个模型在多个情景下评估其他模型的输出，并将这些评估与EigenTrust（Kamvar等，2003）方法进行聚合，生成全面集合权重平均的评分。区别于需要真实标签的方法，EigenBench设计为量化合理判断者可能对正确标签持有不同意见的特性。
### Conclusion
通过使用提示的人格，我们测试了EigenBench得分对模型或提示更为敏感：我们发现大部分方差由提示解释，但一小部分剩余方差量化了模型本身的态度。
## 139. `cs.AI` - 提升FKG.in：实现印度食物成分分析自动化 [PDF](https://arxiv.org/pdf/2412.05248), [HTML](https://arxiv.org/abs/2412.05248)
### Authors
Saransh Kumar Gupta,Lipika Dey,Partha Pratim Das,Geeta Trilok-Kumar,Ramesh Jain
### Background
本文介绍了使用印度食物知识图谱(FKG[.]in)和大规模语言模型(LLMs)来计算印度食谱中的食物成分数据的新方法。文章的重点在于提供自动化食物成分分析工作流程的概览，并详细描述其核心功能：营养数据聚合、食物成分分析及语言模型增强的信息解析。文章还指出了表示印度食物及其数字化获取食物成分数据的挑战，并回顾了三种关键的食物成分数据来源：印度食物成分表、印度营养数据库和Nutritionix API。此外，文章还简要介绍了用户如何与工作流程互动以获得基于饮食的健康建议和多种食谱的详细食物成分信息。文章探讨了分析印度食谱信息面临的复杂挑战，包括结构、多语言性和不确定性问题，并展示了基于LLM的技术解决方案。
### Innovation
提出的基于AI的知识管理和信息解析方法是通用的、可推广的，并且可以在任何领域复制。该工作旨在自动化获取印度食谱中的食物成分数据，并通过知识图谱增强语言模型来补充电验知识库中的数据。方法涵盖了数据聚合、成分分析和信息解析等核心功能，旨在提升FKG[.]in的功能和数据准确性。
### Conclusion
本文提出的方法是通用且可复制的，能够在任何领域应用。工作流程不仅能够自动化整合印度食谱中的食物成分数据，还能通过知识图谱补充和更新现有数据。尽管面临结构、多语言性和数据不确定性等挑战，但利用基于LLM的解决方案可以有效应对这些复杂问题。
## 140. `cs.AI` - 使用稳定扩散进行卡尔文和 Hobbes 漫画风格转换 [PDF](https://arxiv.org/pdf/2312.03993), [HTML](https://arxiv.org/abs/2312.03993)
### Authors
Asvin Kumar Venkataramanan,Sloke Shrestha,Sundar Sripada Venugopalaswamy Sriraman
### Background
该项目报告总结了我们对卡尔文和霍布斯漫画数据集进行稳定的扩散微调的过程。目的是将给定的输入图像转化为卡尔文和霍布斯的漫画风格，实现风格迁移。我们使用低秩适配（LoRA）对稳定扩散模型进行训练，以提高微调过程的效率。扩散过程由一个变分自编码器（VAE，U-net架构）处理。
### Innovation
我们使用低秩适配（LoRA）对稳定扩散模型进行训练，从而加速微调过程。同时，我们使用变分自编码器（VAE，U-net架构）处理扩散过程。
### Conclusion
我们的结果显示，在训练时间和输入数据质量的限制下，视觉效果令人满意，表明该方法在风格迁移任务中是有效的。
## 141. `cs.AI` - 使用语言模型编码的蛋白质序列生成中的扩散方法 [PDF](https://arxiv.org/pdf/2403.03726), [HTML](https://arxiv.org/abs/2403.03726)
### Authors
Viacheslav Meshchaninov,Pavel Strashnov,Andrey Shevtsov,Fedor Nikolaev,Nikita Ivanisenko,Olga Kardymon,Dmitry Vetrov
### Background
蛋白质序列设计已通过离散扩散和自回归方法取得了显著进展，但连续扩散的潜力尚未得到充分探索。现有研究主要集中在离散扩散和自回归方法上。
### Innovation
提出一种名为DiMA的基于潜伏扩散框架，该框架适用于蛋白质语言模型表示。通过系统探索架构选择和扩散组件，该框架能够在多种蛋白质编码器（从8M到3B参数）下泛化，并展示了在单一架构和训练方法下，在仅序列、双解码和多模态表示中的一致性高性能。
### Conclusion
DiMA持续生成高质量、多样且新颖的蛋白质序列，并且在各种蛋白质生成基准上表现出色。模型支持条件生成任务，包括蛋白质家族生成、保守基序支架和填充及特定折叠序列设计。该工作的研究成果提供了一个适用于蛋白质序列生成的通用连续扩散框架，具有广泛的架构见解和实际应用价值，在不同蛋白质设计场景中都具有重要性。
## 142. `cs.AI` - 基于LLM的体态AI任务完成代理的计划验证 [PDF](https://arxiv.org/pdf/2509.02761), [HTML](https://arxiv.org/abs/2509.02761)
### Authors
Ananth Hariharan,Vardhan Dongre,Dilek Hakkani-Tür,Gokhan Tur
### Background
大型语言模型（LLM）基于的任务计划和相应的人类示范在体态AI中可能存在噪音，包括不必要的动作、冗余导航和逻辑错误，这些都会降低策略质量。
### Innovation
作者提出了一种迭代验证框架，其中裁判LLM批判性地审查动作序列，规划LLM应用修订，产生越来越清洁且更空间一致的轨迹。该方法依赖于自然语言提示，能够解决各种错误类型，包括无关动作、矛盾和遗漏步骤，而不仅仅是依赖规则。在TEACh体态AI数据集的一组手动注释动作上，该框架实现了高达90%的召回率和100%的精确率，适用于四款最先进的LLM（GPT o4-mini、DeepSeek-R1、Gemini 2.5、LLaMA 4 Scout）。
### Conclusion
通过将计划验证确立为空间规划和动作精炼的可靠LLM能力，作者为体态AI中的模仿学习优质训练数据的高效率路径提供了可扩展的途径，同时保留了人类的错误恢复模式，支持未来的鲁棒纠正行为研究。
## 143. `cs.AI` - Oyster-I: 超越拒绝 —— 负责任的语言模型的建设性安全性对齐 [PDF](https://arxiv.org/pdf/2509.01909), [HTML](https://arxiv.org/abs/2509.01909)
### Authors
Ranjie Duan,Jiexi Liu,Xiaojun Jia,Shiji Zhao,Ruoxi Cheng,Fengxiang Wang,Cheng Wei,Yong Xie,Chang Liu,Defeng Li,Yinpeng Dong,Yichi Zhang,Yuefeng Chen,Chongwen Wang,Xingjun Ma,Xingxing Wei,Yang Liu,Hang Su,Jun Zhu,Xinfeng Li,Yitong Sun,Jie Zhang,Jinzhao Hu,Sha Xu,Yitong Yang,Jialing Tao,Hui Xue
### Background
大型语言模型（LLMs）通常部署了安全机制以防止生成有害内容。现有的大多数方法主要针对恶意行为者的风险，通常将这些风险视为对抗性事件，并依赖于防御性的拒绝策略。然而，在实际应用中，风险也可能来自非恶意用户在心理压力下寻求帮助（例如，自伤意图）。在这种情况下，模型的回复可能强烈影响用户的下一步操作。简单的拒绝策略可能促使他们重复尝试、升级行为，甚至转向不安全的平台，导致更糟糕的结局。
### Innovation
本文引入了建设性安全性对齐（CSA），这是一种以人为本的范式，旨在防止恶意误用的同时，积极引导脆弱用户走向安全和有益的结果。CSA 实施在 Oyster-I (Oy1) 中，结合了对用户反应的博弈论预测、细粒度的风险边界发现以及可解释的推理控制，使其安全性成为一种信任建设过程。Oy1 在开放模型中达到了最先进的安全水平，同时保留了高泛化能力。在提出的建设性基准上，它展示了强大的建设性互动，接近 GPT-5，并在 Strata-Sword 超破模型数据集上表现出无与伦比的鲁棒性，接近 GPT-o1 的水平。通过从拒绝优先转向指导优先的安全策略，CSA 重新定义了模型与用户的互动关系，目标是创建不仅安全，还有实质性帮助的系统。
### Conclusion
本研究提出了一项创新，即将从拒绝优先转变为指导优先的安全性策略，重新定义了模型与用户的互动关系，旨在创建不仅安全，还有实质性帮助的系统。我们发布了 Oyster-I、源代码以及基准测试套件，以支持负责任的人本中心 AI。
## 144. `cs.AI` - MTP: 一种AI集成编程中的意义类型语言抽象 [PDF](https://arxiv.org/pdf/2405.08965), [HTML](https://arxiv.org/abs/2405.08965)
### Authors
Jayanaka L. Dantanarayana,Yiping Kang,Kugesan Sivasothynathan,Christopher Clarke,Baichuan Li,Savini Kashmira,Krisztian Flautner,Lingjia Tang,Jason Mars
### Background
软件开发正从传统的编程方式转向利用生成型AI和大型语言模型（LLMs）的AI集成应用。然而，集成LLMs仍然存在复杂性，开发者必须手动构建提示和处理输出。现有工具试图辅助提示工程，但往往会引入额外的复杂性。
### Innovation
本文提出了意义类型编程（MTP），这是一种新型范式，通过直观的语言级构造来抽象LLMs的集成。MTP通过利用代码固有的语义丰富性，自动化的提示生成和响应处理，无需额外的开发者努力。我们引入了(1)by操作符以实现无缝的LLM调用，(2)MT-IR，一种基于意义的中间表示用于语义提取，以及(3)MT-Runtime，一种自动化的管理系统用于管理LLMs的交互。
### Conclusion
MTP 显著降低了编码复杂性，减少了代码修改所需行数，并降低了成本，同时改进了运行时性能并保持或超越现有方法的准确性。用户研究显示，使用MTP的开发人员以3.2倍的速度完成任务，代码行数减少了45%。MTP即使在多达50%命名规范被降级的情况下，也显示出面对次优代码的鲁棒性。MTP作为Jaseci开源项目的一部分开发，开源许可下提供。
## 145. `cs.AI` - 长输入序列网络用于长时间序列预测 [PDF](https://arxiv.org/pdf/2407.15869), [HTML](https://arxiv.org/abs/2407.15869)
### Authors
Chao Ma,Yikai Hou,Xiang Li,Yinggang Sun,Haining Yu
### Background
在长时间序列预测任务中，短定长输入是深度学习方法的主要瓶颈。增加输入长度会导致过拟合，准确性迅速下降。
### Innovation
本文发现过拟合是由时间序列中的多尺度模式耦合和当前模型的固定聚焦尺度共同导致的。首先，作者发现时间序列在不同尺度上表现出的模式反映了其多周期性，每个尺度对应特定的周期长度。其次，作者发现标记大小主要决定了模型的行为，因为这决定了模型关注的尺度和可以容纳的上下文大小。为此，作者提出了一种新的系列分解模块（MPSD）和多标记模式识别神经网络（MTPR），使得模型能够处理输入长度最多增加10倍的序列，这种方法提高了性能（最高38%的精度提升），同时具有较低的复杂度（减少成本0.22倍）和高可解释性。
### Conclusion
足够的上下文增强了模型性能，分尺度建模方法降低了模型复杂度并提高了可解释性。
## 146. `cs.AI` - AutoPETIII: The Tracer Frontier. What Frontier?, [PDF](https://arxiv.org/pdf/2410.02807), [HTML](https://arxiv.org/abs/2410.02807)
### Authors
Zacharia Mesbah,Léo Mottay,Romain Modzelewski,Pierre Decazes,Sébastien Hapdey,Su Ruan,Sébastien Thureau
### Background
AutoPET竞赛在过去三年吸引了医学成像领域的关注，专注于PET扫描中的病灶分割任务。每年竞赛都会聚焦不同的问题，2024年的主题是处理多种现有和使用的示踪剂，尤其是FDG和PSMA基的示踪剂，同时要求开发能够在不预先知道示踪剂类型的情况下自动进行PET/CT病灶分割的算法。
### Innovation
该研究利用了nnUNetv2框架训练了两组六折迭模型集合，用于自动进行PET/CT病灶分割。此外，引入了MIP-CNN来选择用于分割的模型集合，以便在未知示踪剂类型的情况下也能有效分割病灶。
### Conclusion
该研究成功开发了一个能够自动分割PET/CT病灶的算法，即使示踪剂类型未知也能适用。通过模型集合和MIP-CNN的选择策略，显著提高了分割的准确性和鲁棒性。
## 147. `cs.AI` - 使用不变统计损失培训具有稳健性、适用于多元和肥尾分布的隐式生成模型 [PDF](https://arxiv.org/pdf/2410.22381), [HTML](https://arxiv.org/abs/2410.22381)
### Authors
José Manuel de Frutos,Manuel A. Vázquez,Pablo Olmos,Joaquín Míguez
### Background
传统的隐式生成模型能够学习高度复杂的数据分布。然而，在训练过程中，这些模型需要使用对抗判别器来区分开真的数据和合成的数据，这可能导致训练动态不稳定和模态丢失的问题。很多实际现象生成的数据只能用肥尾概率分布来准确描述，而传统的隐式方法在捕捉这些分布的渐近行为方面效果不佳。为了解决这些问题，研究人员引入了一种名为不变统计损失（ISL）的方法，并将其扩展到处理肥尾和多元数据分布。
### Innovation
本文基于不变统计损失（ISL）方法进行改进，提出了一个生成器，该生成器使用广义帕累托分布（GPD）作为输入噪声，称为Pareto-ISL。这种方案不仅能够准确建模分布的尾巴，还能有效捕捉它们的中心特征。传统的ISL函数仅适用于一维数据集，而本文通过对一维方法使用随机投影进行扩展，提出了一个新的损失函数，适用于多元数据。这种方法通过调整投影的数量，使其在高维空间内保持可计算性和有效性。
### Conclusion
实验结果表明，Pareto-ISL在多维生成建模中表现出色，其性能在多种超参数设置下表现出高度的稳健性，并且具有作为生成对抗网络（GAN）预训练方法来防止模态崩溃的潜力。
## 148. `cs.AI` - 学习10个示范：使用定向功能框架实现通用且样本高效策略学习 [PDF](https://arxiv.org/pdf/2410.12124), [HTML](https://arxiv.org/abs/2410.12124)
### Authors
Krishan Rana,Jad Abou-Chakra,Sourav Garg,Robert Lee,Ian Reid,Niko Suenderhauf
### Background
模仿学习已使机器人能够展示出高度灵巧的行为。然而，它仍然在长时限、多目标任务上得不到很好的解决，因为模仿学习在样本效率和泛化能力上表现不佳。现有的方法需要大量的示范来覆盖任务的所有可能变异，这使得它们在现实世界的部署中代价高昂且常常不切实际。
### Innovation
本文通过引入定向功能框架，提出了一个结构化的状态和动作空间表示，它能够改善空间和分类内的推广，允许从仅10个示范中高效学习策略。更重要的是，我们展示了这种抽象如何允许独立训练的亚策略组合以解决长时限、多目标任务。为了在亚策略之间无缝过渡，我们引入了自我进展预测的概念，该概念直接源自训练示范的持续时间。实验结果表明，尽管数据集较小，但策略依然能够泛化到未见的物体外观、几何形状和空间排列，从而实现较高成功率，而无需依赖详尽的训练数据。
### Conclusion
通过定向功能框架，策略能够从少量示范中高效学习，并能够泛化应用于具有未见物体属性的长时限多目标任务中。
## 149. `cs.AI` - 通过证据理论量化神经网络的校准误差 [PDF](https://arxiv.org/pdf/2411.00265), [HTML](https://arxiv.org/abs/2411.00265)
### Authors
Koffi Ismael Ouattara,Ioannis Krontiris,Theo Dimitrakos,Frank Kargl
### Background
在关键应用中部署神经网络时，其可信度对于可靠性和决策信心至关重要。传统性能指标如精确度和精确性无法捕捉可靠性、信心和不确定性这些方面，尤其是在模型表现出过高信心时。为了解决这些限制，该论文提出了一种新的框架，通过将主观逻辑融入期望校准误差（ECE）的评估中来量化神经网络的可信度。
### Innovation
引入了一种新的方法，通过将主观逻辑应用于期望校准误差的评估来量化神经网络的可信度。此方法通过聚类预测概率和使用适当的融合运算符融合意见，提供了对校准误差、不信任和不确定性的全面衡量。
### Conclusion
通过在MNIST和CIFAR-10数据集上的实验，证明了该方法的有效性，特别是在校准后的结果中显示出提高了的可信度。提出的框架为AI模型的可解释性和细致评估提供了一种可能的应用，特别是在敏感领域如医疗和自主系统中。
## 150. `cs.AI` - Unisolver：面向通用神经PDE求解器的PDE条件变换器 [PDF](https://arxiv.org/pdf/2405.17527), [HTML](https://arxiv.org/abs/2405.17527)
### Authors
Hang Zhou,Yuezhou Ma,Haixu Wu,Haowen Wang,Mingsheng Long
### Background
深度模型最近作为解决偏微分方程（PDEs）的有前途的工具出现，被称为神经PDE求解器。虽然从模拟数据或物理内化损失训练的神经求解器能够较为有效地解决PDEs，但它们主要局限于几种PDE实例，例如某个特定方程及其有限的参数集。这限制了它们解决多样PDE的能力，阻碍了它们成为数值求解器的实用替代模型。背景指出，现有方法主要适用于特定类型的PDE，缺乏泛化能力，导致了该研究工作的出发点——开发一个能够解决广泛PDE的通用神经PDE求解器。
### Innovation
Unisolver引入了一种基于PDE求解过程的理论分析的新颖变换器模型，而不是仅仅通过扩展数据和参数来扩展规模。Unisolver借鉴了PDE数学结构的启迪，定义了一整套PDE组件，并灵活嵌入它们作为域别和点别的深度约束条件，以此为变换器PDE求解器提供条件。与最近的变换器进展结合物理洞察，Unisolver在三个具有挑战性的大型基准测试中实现了持续的最优性能，展示了出色的表现和泛化能力。
### Conclusion
Unisolver作为一种新型变换器模型，在解决广泛的PDE方面表现出了强大的性能和泛化能力。通过引入一个新的设计理念——将PDE组件作为深度约束条件，Unisolver成功地克服了传统神经求解器的局限性，并展示了对多种PDE求解的优越能力。这项研究证明了Unisolver在作为数值求解器有效替代模型方面的重要潜力。
## 151. `cs.AI` - ACING：在黑箱大语言模型中的指令学习的演员-评论家方法 [PDF](https://arxiv.org/pdf/2411.12736), [HTML](https://arxiv.org/abs/2411.12736)
### Authors
Salma Kharrat,Fares Fourati,Marco Canini
### Background
大语言模型（LLMs）任务的有效性很大程度上取决于其指令的质量，而这些指令常常需要大量的手工努力来制定。这突显了自动指令优化的需求。但在使用黑箱大语言模型时，优化指令尤其具有挑战性，因为无法访问模型参数和梯度。
### Innovation
我们提出了一种基于演员-评论家（actor-critic）强化学习框架的ACING，将其作为无状态、连续动作问题来处理指令优化，通过仅使用黑箱反馈即可探索无限的指令空间。ACING能够在76%的任务中发现优于手工撰写的提示，最高收益为33分，中位数改进为10分，优于33项任务的最佳自动基准结果。
### Conclusion
广泛的消融实验显示出ACING的稳健性和效率。ACING的实现可以在以下链接找到：this https URL。
## 152. `cs.AI` - FFHFlow：基于流变分推断的多样化和不确定性感知灵巧抓取生成 [PDF](https://arxiv.org/pdf/2407.15161), [HTML](https://arxiv.org/abs/2407.15161)
### Authors
Qian Feng,Jianxiang Feng,Zhaopeng Chen,Rudolph Triebel,Alois Knoll
### Background
对于具有多指手的机器人来说，从部分观测中生成多样且具有不确定性感知的抓取仍然是一个关键挑战。现有的生成方法难以准确建模灵巧手的复杂抓取分布，通常在处理部分点云中的形状不确定性时表现不佳，导致不可靠或过于保守的抓取结果。
### Innovation
我们提出了基于流的变分框架FFHFlow，该方法能够生成多样且稳健的多指抓取，并明确量化部分点云中的感知不确定性。我们的方法利用规范化流基于的深度潜在变量模型，学习分层的抓取流形，克服了条件变分自编码器（cVAEs）的模式塌陷和刚性先验局限性。通过利用流的可逆性和精确似然性，FFHFlow在部分观测中反思形状不确定性，发现新的物体结构，从而实现基于风险感知的抓取生成。为进一步提高可靠性，我们集成了一个辨别性抓取评估器与流似然性，制定了一个基于不确定性的排名策略，优先选择对形状模糊性具有鲁棒性的抓取。
### Conclusion
我们在仿真和实际环境中的实验显示，FFHFlow在抓取多样性和成功率方面优于当前最先进的基线（包括扩散模型），同时实现了高效的采样。我们还展示了其在复杂和受限环境中具有实际价值，通过多样化驱动的采样减少碰撞（项目页面：this https URL）
## 153. `cs.AI` - 通过部分感知监督防御大型视觉语言模型的视觉攻击 [PDF](https://arxiv.org/pdf/2412.12722), [HTML](https://arxiv.org/abs/2412.12722)
### Authors
Qi Zhou,Tianlin Li,Qing Guo,Dongxia Wang,Yun Lin,Yang Liu,Jin Song Dong
### Background
近期的研究揭示了大型视觉语言模型（LVLMs）对恶意注入或篡改输入图像的脆弱性，这些篡改可能导致模型的回答错误。现有的防御方法表明，这样的视觉攻击对图像修改特别敏感，尤其是裁剪，并且可以使用修改后的图像回应的众数投票作为更正的响应。然而，这些修改通常会造成分割开的图像并且扭曲语义，这在使用投票后的干净图像上会降低回应的质量。现有的防御方法直接使用分割开的图像的回应进行投票，本研究提出了一种无需训练的黑盒方法DPS（基于部分感知监督的防御），尝试利用这些回应来监督LVLM对原始图像的回应。
### Innovation
本研究提出了一种基于部分感知监督的无需训练的黑盒方法DPS。该方法通过使用只能感知部分图像的模型生成的回应来训练LVLM，使其在遭受攻击时可以基于部分图像的理解进行回应调整，而在干净输入时自信地保留其原始回应。研究表明，弱模型可以监督强模型：在面对攻击输入时，强模型变得不那么自信，根据弱模型的部分理解调整其回应，从而有效抵御攻击。在干净输入时，它也可以自信地保持其原始回应。实验证明，该方法优于基线方法，在三个流行模型和六组数据集上将平均攻击成功率减少了76.3%。
### Conclusion
本研究通过提出DPS方法展示了如何通过部分感知监督增强大型视觉语言模型的防御能力。这种方法在多个数据集上显著降低了视觉攻击的成功率，证明了其有效性和实用价值。
## 154. `cs.AI` - Graph Retrieval-Augmented Generation for Customized Large Language Models [PDF](https://arxiv.org/pdf/2501.13958), [HTML](https://arxiv.org/abs/2501.13958)
### Authors
Qinggang Zhang,Shengyuan Chen,Yuanchen Bei,Zheng Yuan,Huachi Zhou,Zijin Hong,Hao Chen,Yilin Xiao,Chuang Zhou,Yi Chang,Xiao Huang
### Background
大规模语言模型（LLMs）在广泛任务中展示了其卓越的能力，但它们在特定领域的应用仍然具有挑战性，因为需要深厚的专业知识。检索增强生成（RAG）作为一种方法，通过无缝集成外部知识库并实现实时访问细分领域的专业知识，缓解了这一问题。然而，传统的RAG系统基于平坦的文本检索，仍然面临三个关键挑战：专业查询理解复杂性、跨分布式来源的知识整合困难以及系统在大规模下的效率瓶颈。
### Innovation
GraphRAG作为一种新的图检索增强生成范式，通过三种关键创新解决了传统RAG的局限：(i)结构化的图知识表示，明确捕捉实体关系和领域层次结构；(ii)高效图检索技术，支持多跳推理以实现上下文保留的知识检索；(iii)结构感知知识整合算法，利用检索到的知识提高LLMs的准确性和逻辑连贯性生成能力。
### Conclusion
本文系统分析了GraphRAG的技术基础，并探讨了其在不同专业领域的当前实现情况，识别了关键的技术挑战和有前景的研究方向。所有与GraphRAG相关的资源，包括研究论文、开源数据和项目，都已在本文提供的链接中收集起来以供社区使用。
## 155. `cs.AI` - 打破长时间序列预测中的背景限制 [PDF](https://arxiv.org/pdf/2412.16572), [HTML](https://arxiv.org/abs/2412.16572)
### Authors
Chao Ma,Yikai Hou,Xiang Li,Yinggang Sun,Haining Yu,Zhou Fang,Jiaxing Qu
### Background
长期时间序列预测对于经济、能源和交通领域的规划和决策至关重要，因为这些领域需要长远的预见性。现有模型虽然在效率上有所提升，但在处理长序列时仍面临有效利用更长序列的挑战。这主要是因为这些模型在面对较长输入时容易过拟合，导致需要使用较短的输入长度以保持可接受的误差范围。因此，存在一种方法可以通过在时间序列中分解不同尺度的模式来提高可预测性、提高效率并简化架构，这对于有效地处理长时间序列至关重要。
### Innovation
提出了Logsparse Decomposable Multiscaling (LDM)框架，通过在时间序列中分解不同尺度的模式，来增强可预测性、提高效率并简化架构，从而有效地处理长时间序列。LDM框架不仅能优于所有基线方法在长期预测基准测试中，还能减少训练时间和内存成本。
### Conclusion
实验结果表明，LDM框架在长期预测基准测试中优于所有基线方法，并且能够显著减少训练时间和内存成本。
## 156. `cs.AI` - 快速通过元内文本学习新词 [PDF](https://arxiv.org/pdf/2502.14791), [HTML](https://arxiv.org/abs/2502.14791)
### Authors
Wentao Wang,Guangyuan Jiang,Tal Linzen,Brenden M. Lake
### Background
人类可以从少量示例中快速学习新词，并且能够灵活地在新的语言环境中使用这些新词，而现有的语言模型在少量示例下的词语学习能力及其改进方法研究尚为空白。
### Innovation
提出了一种名为Minnow的新方法，该方法通过元训练使语言模型能够在少量上下文示例的情况下生成新词的用法，利用特殊占位符标记表示新词，通过重复对许多新词进行训练来开发一种普遍的词语学习能力。通过对比未进行Minnow训练的模型和大规模预训练的语言模型（LLM）的表现，证明了使用Minnow预训练的模型在生成新词的用法和定义方面表现更佳。
### Conclusion
Minnow在数据效率方面表现出色，能够显著提升语言模型在词语学习任务中的表现，并且对于预训练的大规模语言模型进行Minnow微调能够提高它们区分新词、识别新词的语法类别以及生成合理的新词用法和定义的能力。
## 157. `cs.AI` - 基于超大规模自然图像的基础模型是否优于视网膜特异性模型用于检测视网膜和全身疾病？ [PDF](https://arxiv.org/pdf/2502.06289), [HTML](https://arxiv.org/abs/2502.06289)
### Authors
Qingshan Hou,Yukun Zhou,Jocelyn Hui Lin Goh,Ke Zou,Samantha Min Er Yew,Sahana Srinivasan,Meng Wang,Thaddaeus Lo,Xiaofeng Lei,Siegfried K. Wagner,Mark A. Chia,Dawei Yang,Hongyang Jiang,An Ran Ran,Rui Santos,Gabor Mark Somfai,Juan Helen Zhou,Haoyu Chen,Qingyu Chen,Carol Y. Cheung,Pearse A. Keane,Yih Chung Tham
### Background
基础模型（FMs）的出现正在改变医疗领域。在眼科领域，RETFound作为一种针对视网膜训练的基础模型，在多种临床应用中表现出高度的适应性，而DINOv2作为一种通用视觉模型，尽管在非医疗领域展现出潜力，但在临床任务中的应用仍需进一步探索。为了填补这一空白，研究者对RETFound和三种不同规模的DINOv2模型进行了直接对比，以检测眼疾和预测全身疾病。实验在多个标准化开源眼科数据集及Moorfields AlzEye和UK Biobank数据集上进行，揭示了不同基础模型在不同任务中的优劣。
### Innovation
本研究进行了RETFound与三种不同规模DINOv2模型的直接对比，分别用于眼疾病检测和全身疾病预测。实验设计采用多种眼科数据集，首次详细评估了视网膜特异性模型和通用基础模型在不同临床任务中的表现差异，为基础模型的选择提供了实践依据。
### Conclusion
研究发现，通用基础模型（如DINOv2）在糖尿病视网膜病变和多类眼疾检测中优于视网膜特异性模型（如RETFound），而在预测心力衰竭、心肌梗死和缺血性中风方面，RETFound则表现出更优的性能。这些结果强调了基础模型选择需与特定任务需求相匹配的重要性，以优化临床性能。
## 158. `cs.AI` - Extended Histogram-based Outlier Score (EHBOS), [PDF](https://arxiv.org/pdf/2502.05719), [HTML](https://arxiv.org/abs/2502.05719)
### Authors
Tanvir Islam
### Background
HBOS是一种广泛应用的异常检测方法，因其计算效率和简单性而闻名。然而，它假设特征独立的限制了其在特征间存在交互作用的数据集中的异常检测能力。
### Innovation
本文提出了一种增强的异常检测方法EHBOS，通过引入二维直方图来捕捉特征对之间的依赖性，从而能够识别HBOS无法检测到的情境和依赖驱动的异常，特别是在特征交互是异常定义关键因素的数据集中表现尤为突出，ROC AUC得分有显著提高。
### Conclusion
EHBOS能够有效并稳健地应用于各种异常检测场景中，特别是在特征交互至关重要的数据集中，EHBOS相对于HBOS有了显著改进。EHBOS为复杂的特征依赖关系提供了一种强有力的建模工具，尤其是在依赖或情境异常起重要作用的数据集中。
## 159. `cs.AI` - 超越全息图：熵量子引力在图像处理中的基础 [PDF](https://arxiv.org/pdf/2503.14048), [HTML](https://arxiv.org/abs/2503.14048)
### Authors
Ginestra Bianconi
### Background
最近，人工智能（AI）的发展使得理论物理与AI之间的关联受到了越来越多的科学关注。传统上，这些关联主要集中在弦理论与图像处理之间的关系，包括全息理论等重要的理论框架。最近，G. Bianconi提出了一种基于熵（GfE）的量子引力方法，通过几何量子相对熵（GQRE）推导出了引力。本文研究了Perona-Malik图像处理算法与GfE方法之间的重要联系，表明Perona-Malik算法是GfE作用的梯度流动。
### Innovation
该研究显示了Perona-Malik算法是几何量子相对熵（GQRE）在简化的场景下的梯度流动的结果。特别地，这是通过最小化支持图像的欧几里得度量和由图像诱导的度量之间的GQRE实现的。由于Perona-Malik算法可以保留图像的边界，这表明GfE作用不会导致在梯度流动迭代中泛化的图像，而是与复杂结构的保持一致。
### Conclusion
研究成果为Perona-Malik算法提供了几何和信息理论的基础，并可能促进GfE、机器学习和脑科学研究之间的更深层次联系。
## 160. `cs.AI` - FRIDA to the Rescue! 分析基于对象的常识推理中合成数据的有效性以应对灾难响应 [PDF](https://arxiv.org/pdf/2502.18452), [HTML](https://arxiv.org/abs/2502.18452)
### Authors
Mollie Shichman,Claire Bonial,Austin Blodgett,Taylor Hudson,Francis Ferraro,Rachel Rudinger
### Background
在灾难救援情景中的人机交互过程中，大型语言模型（LLMs）有潜力进行重要的物理推理，以协助完成任务目标。然而，这些推理能力通常仅存在于较大的模型之中，但由于尺寸限制，在现有的机器人系统上无法部署。为了满足特定场景需求，研究者提出了一种数据集和处理管道来生成Field Reasoning and Instruction Decoding Agent (FRIDA)模型。该管道通过领域专家和语言学家结合专业知识生成高质量、少量的例子提示，用于生成合成数据进行微调。研究还发现，仅仅依据对象的物理状态和功能数据进行微调的FRIDA模型，在评估中表现优于使用所有合成数据或基础模型进行微调的版本。
### Innovation
该研究创新地提出了FRIDA模型及其生成和微调的管道，通过特定的内容生成和少样本提示的微调方法，使得小型指令调优模型能够获得更好的物理常识推理能力，特别是在灾难响应场景中更为有效。同时，研究还通过对比实验确定了哪种类型的合成数据对模型性能影响最大，并基于此优化FRIDA模型的生成过程。
### Conclusion
研究结果表明，FRIDA管道能够通过少量数据训练赋予模型物理常识，并在灾难响应场景中的任务中表现出色。特别是，仅仅基于对象的物理状态和功能数据进行微调的FRIDA模型，在综合评估中表现超过了其他版本的模型。这些发现对于未来的小型化语言模型在机器人系统中的应用具有重要意义。
## 161. `cs.AI` - KNighter：通过LLM合成检查器转变静态分析 [PDF](https://arxiv.org/pdf/2503.09002), [HTML](https://arxiv.org/abs/2503.09002)
### Authors
Chenyuan Yang,Zijie Zhao,Zichen Xie,Haoyu Li,Lingming Zhang
### Background
静态分析是一种强大的技术，在操作系统的内核等关键系统中用于检测错误。然而，设计和实现静态分析工具具有挑战性，耗时且通常局限于预先定义的错误模式。尽管大型语言模型（LLMs）在静态分析方面显示出潜力，但对于扫描大规模系统而言，由于计算限制和背景限制，直接应用它们仍然是不现实的。KNighter通过自动从历史错误模式合成静态分析器，解锁了基于LLM的可扩展静态分析，这就为通过历史补丁知识生成专门化静态分析器提供了关键洞察。
### Innovation
KNighter通过一个多阶段的合成流水线实现了这一愿景，验证检查器的正确性并使用自动化精炼过程迭代地减少假阳性。评估表明，KNighter生成的检查器具有高度精度，能够检测现有的静态分析器所忽视的多种错误模式。到目前为止，KNighter合成的检查器已经在Linux内核中发现了92个新关键且长期潜伏的错误（平均4.3年），其中77个已得到确认，57个已修复，30个已分配CVE编号。这项工作建立了通过检查器合成实现可扩展、可靠和可追溯的基于LLM的静态分析的新范式，适用于实际系统.
### Conclusion
KNighter通过自动从历史错误模式合成静态分析器，实现了一种新的基于LLM的可扩展、可靠和可追溯的静态分析方法，该方法能够在实际系统中发现之前未被静态分析器发现的新、关键且长期潜伏的错误。
## 162. `cs.AI` - 图像嵌入采样方法用于多样化的图像字幕生成 [PDF](https://arxiv.org/pdf/2502.10118), [HTML](https://arxiv.org/abs/2502.10118)
### Authors
Sania Waheed,Na Min An
### Background
近年来，基于视觉语言模型（VLMs）的图像字幕生成的性能显著提高，但模型复杂性也随之增加，这限制了它们在资源受限的应用中的使用，如移动设备和辅助技术。相比之下，小型VLMs更侧重于高层次的场景描述，而忽略了对理解图像更为详细的要素。因此，研究提出了一种无需训练的框架，利用小型VLM（BLIP）和结构化分割来增强字幕的多样性和信息量。该方法通过明确关注图像的不同区域来改善字幕的生成。
### Innovation
研究提出了一种无需附加模型训练的框架，通过使用小型VLM（BLIP）及其结构化分割功能来生成具有多样性和信息性的图像字幕。这种方法能够在不额外训练模型的情况下，使小型VLM的性能与大型模型相当，提高了字幕与图像的一致性、语义完整性以及多样性。此外，该方法在MSCOCO、Flickr30k和Nocaps测试数据集上进行了评估，表现良好，具有较强的人工标注字幕的相关性和语义完整性。
### Conclusion
本研究创新性地提出了一种无需训练的小型VLM框架，该框架通过结构化分割来生成多样性和信息量兼备的图像字幕，即使是在资源受限的应用场景下也能取得与大型模型相当的性能指标。
## 163. `cs.AI` - CoDiff: 条件扩散模型在协作3D物体检测中的应用 [PDF](https://arxiv.org/pdf/2502.14891), [HTML](https://arxiv.org/abs/2502.14891)
### Authors
Zhe Huang,Shuo Wang,Yongcai Wang,Lei Wang
### Background
在自动驾驶领域，协作3D物体检测对提升每个个体智能体的感知能力具有重要意义，因为它能够促进多智能体之间的信息交换。然而，在实践中，由于姿态估计误差和时间延迟的影响，多智能体之间的信息融合通常会导致具有时空噪声的特征表示，从而引起检测错误。扩散模型具有削弱噪声的能力，这激发了我们探索利用扩散模型解决多智能体系统之间的噪声问题。因此，本文提出了一种新颖的鲁棒协作感知框架CoDiff，利用扩散模型来生成更全面和清晰的特征表示。到目前为止，这是首次将扩散模型应用于多智能体协作感知。具体地，将高维特征图投影到强大的预训练自编码器的潜在空间中，个体智能体信息在此空间中作为条件来引导扩散模型的采样过程，这一过程会消除粗糙特征图的噪声并逐步细化融合特征。在模拟和真实世界数据集上的实验研究表明，所提出的框架CoDiff在协作物体检测性能上始终优于现有的相关方法，并且在智能体的姿态和延迟信息噪声较高时表现出高度期望的鲁棒性。我们已经在此处Release: [CoDiff的代码链接](这个链接需要具体化为实际的网址)。
### Innovation
本文创新性地提出了一种名为CoDiff的新颖协作感知框架，首次结合了扩散模型处理多智能体系统中的噪声问题。通过将高维特征图投影到预训练自编码器的潜在空间中，CoDiff利用扩散模型作为引导条件进行特征表示的逐步优化，从而生成更清晰的特征图。与现有方法相比，CoDiff在协作物体检测中展示了优越的性能和对噪声的鲁棒性。
### Conclusion
实验结果表明，CoDiff框架在多项协作3D物体检测任务上表现出色，尤其是在智能体的姿态和延迟信息存在较高噪声的情况下，其鲁棒性得到了验证。研究证明扩散模型在多智能体协作感知中具有巨大的应用潜力。
## 164. `cs.AI` - 通过基于状态的轨迹缝合实现稳健的离线模仿学习 [PDF](https://arxiv.org/pdf/2503.22524), [HTML](https://arxiv.org/abs/2503.22524)
### Authors
Shuze Wang,Yunpeng Mei,Hongjie Cao,Yetian Yuan,Gang Wang,Jian Sun,Jie Chen
### Background
模仿学习（IL）已经被证明能够通过专家演示有效地使机器人获得视觉运动技能。然而，传统IL方法受限于对高质量且常常稀缺专家数据的依赖，并且面临协变量移位的问题。为解决这些挑战，最近的离线IL进展将不完美且未标记的数据集纳入训练。
### Innovation
本文提出了一种通过利用任务相关的轨迹片段和丰富的环境动态来增强从混合质量离线数据集中学习策略的新方法。具体而言，引入了一种基于状态的搜索框架，通过缝合不完美的演示中的状态-动作对，生成更多多样性和信息性的训练轨迹。
### Conclusion
实验结果表明，在标准IL基准测试和实际机器人任务上，本文提出的方法显著提高了泛化能力和性能。
## 165. `cs.AI` - 可迁移掩膜变压器：基于区域自适应迁移性评估的跨域语义分割 [PDF](https://arxiv.org/pdf/2504.05774), [HTML](https://arxiv.org/abs/2504.05774)
### Authors
Jianhua Liu,Zhengyu Li,Yanru Wu,Jingge Wang,Yang Tan,Ruizhe Zhao,Guan Wang,Yang Li
### Background
近年来，视觉变压器（ViTs）在语义分割任务中取得了显著进展，设定了新的性能基准。然而，当将预训练的ViTs应用于新的目标域时，由于分布偏移，常见的性能下降导致全局注意力效果不佳。由于自我注意机制本质上是数据驱动的，它们在源域和目标域存在纹理、尺度或对象共现模式差异时，可能无法有效地聚焦于关键对象。尽管全球和像素级的域适应方法提供了一定解决方案，但由于不同图像区域间迁移性的空间异质性，区域级的自适应和动态形状区域至关重要。
### Innovation
我们提出了可迁移掩膜变压器（TMT），这是一种新的区域级自适应迁移性框架，通过空间迁移性分析对跨域表示进行对齐。TMT由两个关键组件组成：自适应簇基迁移性估计算法（ACTE），用于动态分割图像为结构和语义上相对集中的区域以进行局部迁移性评估；以及可迁移掩膜注意模块（TMA），该模块将区域特异性迁移性图集成到ViTs的注意机制中，优先在迁移性低且语义不确定性高的区域进行自适应。
### Conclusion
跨20个跨域配对的全面评估表明，TMT优于传统的微调方法和最先进的基线，平均实现了2%的改进和1.28%的提升。源代码将公开可用。
## 166. `cs.AI` - 单图像超分辨率中模块可移植性的优化：普遍性评估与循环残差块 [PDF](https://arxiv.org/pdf/2505.03522), [HTML](https://arxiv.org/abs/2505.03522)
### Authors
Haotong Cheng,Zhiqi Zhang,Hao Li,Xinshang Zhang
### Background
深度学习极大地推动了单图像超分辨率（SISR）领域的发展，但现有研究主要集中在性能提升方面，忽略了对架构组件可移植性的量化分析。本文旨在解决这一问题，引入了“普遍性”及其定义，将传统意义上的“泛化”扩展到模块可移植性。论文提出了一种新的度量标准——普遍性评估方程（UAE），可以量化一个模块在模型之间移植的难度，并揭示多个现有度量标准在可移植性上的综合影响。通过标准残差块和其他即插即用模块的UAE结果，设计了两种优化模块：循环残差块（CRB）和深度轮次残差块（DCRB）。实验表明，嵌入这些可移植模块的网络在多个低级任务上的表现优于当前最先进的方法，PSNR提高了0.83 dB，参数减少了71.3%，而重建保真度无明显下降。
### Innovation
引入了“普遍性”概念及其定义，开发了普遍性评估方程（UAE），量化模块的移植难度；设计了两种优化模块，分别是循环残差块（CRB）和深度轮次残差块（DCRB），并展示了其在多种任务中的优越性能。
### Conclusion
提出的可移植模块在多种低级任务中表现优异，提升了PSNR值或在相同重建保真度下减少了参数数量，为设计具有更高可移植性的可移植模块提供了新思路。
## 167. `cs.AI` - RBT4DNN：基于需求的神经网络测试 [PDF](https://arxiv.org/pdf/2504.02737), [HTML](https://arxiv.org/abs/2504.02737)
### Authors
Nusrat Jahan Mozumder,Felipe Toledo,Swaroopa Dola,Matthew B. Dwyer
### Background
测试允许开发人员确定系统是否按预期运行。然而，当系统包含深度神经网络（DNN）时，测试变得具有挑战性，因为DNN近似那些难以正式化功能需求的函数。这阻止了通过基于需求的测试方法对DNN的应用。为解决这一问题，引入了一种新的基于需求的测试方法（RBT4DNN），利用自然语言需求陈述，并通过词汇表定义语义特征空间来生成测试输入。要求的先决条件被形式化为这些语义特征的逻辑组合。RBT4DNN使用匹配这些特征组合的训练数据来微调生成模型，以可靠地生成满足先决条件的测试输入。执行这些测试可以使开发人员对比DNN的输出与预期要求后条件行为。RBT4DNN提出了两个用例：一是根据定义DNN正确性属性的需求，RBT4DNN构成了检测故障的新方法；二是在开发过程中，根据需求引导模型行为的探索可以为开发人员提供模型泛化反馈。进一步的评估表明，RBT4DNN生成的测试结果具有现实性，多样性并符合需求先决条件，使得可以对模型行为进行有针对性的分析，并有效地检测故障。
### Innovation
该方法提出了基于需求的测试方法（RBT4DNN），利用自然语言需求陈述并通过词汇表定义语义特征空间来生成测试输入，这也是首次将该方法应用于深度神经网络的测试，提出了一种新的生成测试输入的方法，并且能够有效地检测系统中的故障和提供模型的反馈。
### Conclusion
RBT4DNN生成的测试是现实、多样且与需求先决条件一致，能够使开发人员对模型行为进行有针对性的分析，并有效地检测故障。
## 168. `cs.AI` - Stochastic Parameter Decomposition [PDF](https://arxiv.org/pdf/2506.20790), [HTML](https://arxiv.org/abs/2506.20790)
### Authors
Lucius Bushnaq,Dan Braun,Lee Sharkey
### Background
逆向工程神经网络的关键步骤是将其分解为更简单的部分，以便在相对隔离的情况下进行研究。参数线性分解是一种已被提议的方法，旨在解决当前分解方法中出现的多种问题，它将神经网络参数分解为参数空间中稀疏使用的向量之和。然而，当前在该框架中的主要方法，基于属性的参数分解（APD），由于其高昂的计算成本和对超参数的高度敏感性而不实用。
### Innovation
本文提出了一种比APD更具可扩展性和对超参数更加鲁棒的方法——随机参数分解（SPD），并在更庞大且复杂的模型上进行了参数分解实验，证明了SPD的效果。此外，SPD还解决了其他问题，例如学习参数的收缩现象，并在玩具模型中更好地识别了真实机制。通过将因果中介分析方法与网络分解方法相结合，SPD为可扩展线性参数分解方法的研究开辟了新的可能性。
### Conclusion
通过桥接因果中介分析和网络分解方法，本研究消除了对更大规模模型进行线性参数分解的障碍，从而在解决神经网络机制可解释性方面提供了新的研究方向。并且，已经发布了用于执行SPD和复现实验的库文件。
## 169. `cs.AI` - 评估基于LLM的推理在多目标HPC作业调度中的有效性 [PDF](https://arxiv.org/pdf/2506.02025), [HTML](https://arxiv.org/abs/2506.02025)
### Authors
Prachi Jadhav,Hongwei Jin,Ewa Deelman,Prasanna Balaprakash
### Background
HPC作业调度涉及平衡减少制造周期、等待时间、资源使用优化以及确保公平性等多种冲突目标。传统方法如先到先服务（FCFS）和最短作业优先（SJF）等启发式方法或密集优化技术往往缺乏对动态工作负载的适应性，无法在HPC系统中同时优化多种目标。
### Innovation
本文提出了一种基于大型语言模型（LLM）的新颖调度器，采用了类似于ReAct的框架（Reason + Act），实现了迭代、可解释的决策。该系统通过追踪调度历史和自然语言反馈改进决策，同时通过约束执行模块确保可行性和安全性。
### Conclusion
虽然LLM调度方法在约束满足和对多样化工作负载的适应性方面表现出色，但推理质量和计算开销之间的权衡挑战了实时部署。这项工作首次全面研究了有能力推理的LLM在HPC调度中的应用，证明了它们在处理多目标优化方面的能力，同时指出了计算效率方面的局限性。
## 170. `cs.AI` - MiniCPM4：端侧超高效大语言模型 [PDF](https://arxiv.org/pdf/2506.07900), [HTML](https://arxiv.org/abs/2506.07900)
### Authors
MiniCPM Team:Chaojun Xiao,Yuxuan Li,Xu Han,Yuzhuo Bai,Jie Cai,Haotian Chen,Wentong Chen,Xin Cong,Ganqu Cui,Ning Ding,Shengda Fan,Yewei Fang,Zixuan Fu,Wenyu Guan,Yitong Guan,Junshao Guo,Yufeng Han,Bingxiang He,Yuxiang Huang,Baoxi Ji,Cunliang Kong,Qiuzuo Li,Siyuan Li,Wenhao Li,Xin Li,Yanghao Li,Yishan Li,Zhen Li,Dan Liu,Biyuan Lin,Yankai Lin,Xiang Long,Quanyu Lu,Yaxi Lu,Peiyan Luo,Hongya Lyu,Litu Ou,Yinxu Pan,Lushi Pu,Zekai Qu,Qundong Shi,Zijun Song,Jiayuan Su,Zhou Su,Ao Sun,Xianghui Sun,Peijun Tang,Fangzheng Wang,Feng Wang,Shuo Wang,Yudong Wang,Zheng Wang,Yesai Wu,Zhenyu Xiao,Jie Xie,Zihao Xie,Xiaoyue Xu,Yukun Yan,Jiarui Yuan,Jinqian Zhang,Kaihuo Zhang,Lei Zhang,Linyue Zhang,Xueren Zhang,Yudi Zhang,Hengyu Zhao,Weilin Zhao,Weilun Zhao,Yuanqian Zhao,Zhi Zheng,Chuyue Zhou,Ge Zhou,Jie Zhou,Wei Zhou,Yanghao Zhou,Zihan Zhou,Zixuan Zhou,Zhiyuan Liu,Guoyang Zeng,Chao Jia,Dahai Li,Maosong Sun
### Background
本文介绍了MiniCPM4，一种专门针对端侧设备设计的高效率大语言模型。该模型通过在四个关键维度上进行系统创新来实现高效性：模型架构、训练数据、训练算法和推理系统。
### Innovation
在模型架构方面，提出了InfLLM v2，这是一种可训练的稀疏注意力机制，能够加速长上下文处理的预填和解码阶段。在训练数据方面，提出了UltraClean和UltraChat v2，分别是一种高效准确的预训练数据过滤和生成策略以及一个综合的监督微调数据集。训练算法方面，提出了ModelTunnel v2以搜索高效的预训练策略，并通过引入分块式展开和负载平衡强化学习以及数据高效的三元LLM（BitCPM）改进现有后训练方法。在推理系统方面，提出了一个集成稀疏注意力机制、模型量化和推测采样的系统，以实现高效的预填和解码。
### Conclusion
MiniCPM4提供参数量为0.5B和8B的两种版本，并构建了可以在深推理模式和非推理模式下使用的混合推理模型MiniCPM4.1。评估结果表明，MiniCPM4和MiniCPM4.1在基准测试中的表现优于类似的开源模型，8B版本在长序列理解和生成上显示出显著的速度改进。
## 171. `cs.AI` - 行动值时差方法的学习状态值分析 [PDF](https://arxiv.org/pdf/2507.09523), [HTML](https://arxiv.org/abs/2507.09523)
### Authors
Brett Daley,Prabhat Nagarajan,Martha White,Marlos C. Machado
### Background
时差（TD）学习的核心特点是自举：使用价值预测来生成新的价值预测。大多数TD控制方法通过从单一的动作值函数（如Q学习和Sarsa）开始自举来学习策略。相比之下，非常少有研究关注从两个不对称价值函数自举的方法，这些方法在学习动作价值之前会学习状态值作为中间步骤。现有的这类算法可以分为QV学习和AV学习两类。尽管这些算法在先前的工作中有一定的研究，但不清楚在何种情况下学习两个价值函数比学习一个更有优势，以及这类方法在一般情况下是否具有理论支撑。
### Innovation
该研究分析了行动值时差方法在收敛性和样本效率方面的表现。发现虽然两种方法都比Expected Sarsa在预测设置中更高效，但只有AV学习方法在控制设置中能提供相对于Q学习的重要优势。研究还提出了一种新的AV学习算法——正则化对胜负学习（RDQ），并展示了该算法在MinAtar基准测试中显著优于Dueling DQN。
### Conclusion
AV学习方法在控制设置中提供了相对于Q学习的重要优势。正则化对胜负学习算法（RDQ）是新的AV学习算法，其在MinAtar基准测试中的表现显著优于Dueling DQN。
## 172. `cs.AI` - 自回归解码 vs 流匹配：一种文本到音乐生成建模范式的比较研究 [PDF](https://arxiv.org/pdf/2506.08570), [HTML](https://arxiv.org/abs/2506.08570)
### Authors
Or Tal,Felix Kreuk,Yossi Adi
### Background
近期，文本到音乐生成的发展已使得模型能够合成高质量的音乐片段、完整乐曲，甚至能响应细微的控制信号，如和弦进行。现有的领先系统在多个方面存在显著差异，如训练数据集、建模范式和架构选择等。这些差异使得模型的公平评价变得复杂，难以确定哪些设计选择对性能影响最大。尽管数据和架构因素很重要，研究集中在单一的建模范式上，进行系统性经验分析，以揭示相关的权衡和新兴行为，从而指导未来文本到音乐生成系统的发展。研究人员具体比较了两种广泛认为最常用的建模范式：自回归解码和条件流匹配。通过对所有模型从零开始使用相同的训练数据集、配置和类似的基本结构进行训练来进行对比性研究
### Innovation
研究通过比较自回归解码和条件流匹配这两种最常用的建模范式，进行系统的研究，确保所有模型使用相同的训练数据集、配置和基本结构进行训练，从而揭示各个范式的优势和局限。通过对生成质量、推理配置的鲁棒性、可扩展性、跟随文本和时间对齐的条件以及音频填补能力等多个维度进行评估，研究提供建设有针对性的见解，以指导未来文本到音乐生成系统的架构和训练决策
### Conclusion
该比较研究揭示了每种范式的独特优势和局限，提供了可操作的洞见，这对未来文本到音乐生成系统的架构和训练决策具有指导意义。音频示例可在此处获取：<这个URL>。
## 173. `cs.AI` - 基于年龄分段的细粒度儿童腕部骨折分类 [PDF](https://arxiv.org/pdf/2507.12964), [HTML](https://arxiv.org/abs/2507.12964)
### Authors
Ammar Ahmed,Ali Shariq Imran,Zenun Kastrati,Sher Muhammad Daudpota
### Background
腕部损伤在儿童中较为常见，尤其是在骨折病例中占多数。计算机视觉在医学影像分析中具有潜在的应用前景，但面临大规模数据集的缺乏这一挑战。单一模态，如图像，已不足以应对多样化的数据类型。为解决这些问题，本研究采用了一个多方面的方法：将问题界定为精细分类任务，结合患者元数据和X光片，并利用针对细粒度数据集的预训练权重，而非粗粒度数据集如ImageNet。以往的研究中，没有将元数据集成用于腕部病理识别的应用。
### Innovation
首次将元数据集成应用于腕部骨折识别，结合细粒度的Transformer方法及预训练权重，以提高诊断准确性。在小型定制数据集和较大骨折数据集上的准确率分别提高了2%和超过10%。
### Conclusion
该研究通过将元数据与细粒度的图像分析相结合，显著提高了儿童腕部骨折的诊断准确率。
## 174. `cs.AI` - KG-ER概念模式语言 [PDF](https://arxiv.org/pdf/2508.02548), [HTML](https://arxiv.org/abs/2508.02548)
### Authors
Enrico Franconi,Benoît Groz,Jan Hidders,Nina Pardal,Sławek Staworko,Jan Van den Bussche,Piotr Wieczorek
### Background
本文讨论了一种用于知识图谱的概念模式语言KG-ER，该语言独立于知识图谱的表示方法（如关系数据库、属性图、RDF）来描述知识图谱的结构，同时帮助捕捉存储在知识图谱中的信息的语义。
### Innovation
提出了KG-ER概念模式语言，这是一种独立于知识图谱表示方式的知识图谱结构描述语言，有助于捕捉存储在知识图谱中的信息的语义，增强了知识图谱语义信息的提取和表达能力。
### Conclusion
KG-ER提供了一种新的方式来描述知识图谱的结构及其语义，有助于促进知识图谱中信息的准确理解和高效利用。
## 175. `cs.AI` - 高效率视频压缩的条件视频生成 [PDF](https://arxiv.org/pdf/2507.15269), [HTML](https://arxiv.org/abs/2507.15269)
### Authors
Fangqiu Yi,Jingyu Xu,Jiawei Shao,Chi Zhang,Xuelong Li
### Background
感知研究表明，条件扩散模型在重建与人类视觉感知相一致的视频内容方面表现出色。基于这一启示，我们提出了一种利用条件扩散模型进行感知优化重建的视频压缩框架。视频压缩通常被重新定义为一个条件生成任务，模型从稀疏但富有信息性的信号中生成视频。
### Innovation
该方法引入了三个关键模块：（1）多粒度条件，捕捉静态场景结构和动态时空线索；（2）高效的紧凑表示，确保传输效率而不牺牲语义丰富性；（3）多条件训练，结合模态丢弃和角色感知嵌入，避免依赖任何单一模态，增强鲁棒性。
### Conclusion
广泛的实验表明，本方法在弗雷彻视频距离（FVD）和LPIPS等感知质量指标上显著优于传统和神经编解码器，特别是在高压缩比下表现更加出色。
## 176. `cs.AI` - LOTS of Fashion! Multi-Conditioning for Image Generation via Sketch-Text Pairing [PDF](https://arxiv.org/pdf/2507.22627), [HTML](https://arxiv.org/abs/2507.22627)
### Authors
Federico Girella,Davide Talon,Ziyue Liu,Zanxi Ruan,Yiming Wang,Marco Cristani
### Background
时尚设计是一个复杂且创造性的过程，融合了视觉和文本表达。设计者通过草图传达想法，草图定义了空间结构和设计元素，并通过文字描述捕捉材料、纹理和风格细节。
### Innovation
提出了LOcalized Text and Sketch for fashion image generation (LOTS)，一种基于素描-文本配对的生成完整时尚外观的方法。LOTS采用全局描述和局部素描+文本信息对进行条件控制，并引入了一种新颖的分步合并策略以适应扩散过程。通过模块化配对中心化表示将素描和文本编码到共享潜在空间，同时保持独立的局部特征。在扩散模型的多步骤去噪过程中，通过基于注意力的指导集成局部和全局条件。为了验证方法的有效性，基于Fashionpedia建立了Sketchy数据集，该数据集首次提供每个图像的多个素描-文本配对信息。定量结果显示，LOTS在全局和局部度量指标上均取得了最先进的图像生成性能。质性案例和人类评估研究突显了其前所未有的设计自定义水平。
### Conclusion
通过引入新的模块化配对中心化表示和分步合并策略，LOTS在图像生成方面的性能超越了现有方法，能够更好地自定义设计，同时提供多条件控制。
## 177. `cs.AI` - TriCLIP-3D：基于CLIP的统一高效三模态三维视觉定位框架 [PDF](https://arxiv.org/pdf/2507.14904), [HTML](https://arxiv.org/abs/2507.14904)
### Authors
Fan Li,Zanyi Wang,Zeyi Huang,Guang Dai,Jingdong Wang,Mengmeng Wang
### Background
三维视觉定位允许具身智能实体在基于人类指令的现实世界三维环境中理解视觉信息。现有方法通常依赖于不同模态（如RGB图像、文本和3D点云）的独立编码器，这使得模型变得庞大且复杂，训练效率低下。尽管一些方法利用预训练的2D多模态模型（如CLIP）进行三维任务，但它们仍难以将点云数据对齐到2D编码器。因此，这些方法仍然依赖3D编码器进行特征提取，进一步增加了模型复杂性和训练的不效率。
### Innovation
本文提出了一种统一的2D预训练多模态网络来处理所有三种模态（RGB图像、文本和点云），显著简化了架构。通过利用具有适应器微调的2D CLIP双模态模型，该框架有效地适应了三模态设置，提高了跨模态的适应性和性能。作者提出了一个几何感知的2D-3D特征恢复和融合模块（GARF），用于融合点云和图像的几何多尺度特征，通过文本特征进行最终模态融合，并引入了多模态解码器以促进深层次的跨模态理解。这种方法实现了三个模态统一的特征提取和融合，使三维视觉定位成为端到端模型。相比baseline，该方法减少了约58%的可训练参数，在3D检测中的表现提高了6.52%，在3D视觉定位任务中的表现提高了6.25%。
### Conclusion
本文通过对统一2D预训练多模态网络及其相关模块的设计与实现，有效解决了现有方法在模型复杂性和训练效率上的问题，提出的方法实现了高效三维视觉定位。
## 178. `cs.AI` - MultiGen：基于LLM的多语言儿童友好语音生成器 [PDF](https://arxiv.org/pdf/2508.08715), [HTML](https://arxiv.org/abs/2508.08715)
### Authors
Xiaoxue Gao,Huayun Zhang,Nancy F. Chen
### Background
生成式语音模型在改善人机交互方面展示了巨大潜力，特别是在儿童语言学习应用方面。然而，实现高质量、适合儿童的语音生成仍然具有挑战性，尤其是在低资源语言和多种文化背景下。
### Innovation
提出了一种名为MultiGen的多语言语音生成模型，专门针对低资源语言和儿童友好交互进行优化。该模型利用了LLM架构进行了定制化语音生成，并通过文化相关的语境在新加坡方言普通话、马来语和泰米尔语三种低资源语言中实现了适用于儿童的多语言语音生成。
### Conclusion
实验结果表明，MultiGen在客观和主观评估方面均优于基线方法，表现出了更优的性能。
## 179. `cs.AI` - StreetViewAI：使用上下文感知多模态AI使街道视图无障碍 [PDF](https://arxiv.org/pdf/2508.08524), [HTML](https://arxiv.org/abs/2508.08524)
### Authors
Jon E. Froehlich,Alexander Fiannaca,Nimer Jaber,Victor Tsaran,Shaun Kane
### Background
交互式街道景观映射工具，如谷歌街景（GSV）和Meta Mapillary使得用户可以通过沉浸式的360度影像虚拟导航和体验现实世界的环境，但这些工具仍然对视障用户来说根本不可访问。因此，本文介绍了一个名为StreetViewAI的新工具，它是第一个专为视障用户设计可访问的街景视图工具，它结合了上下文感知的多模态AI技术、无障碍导航控制和对话式语音指令。使用StreetViewAI，视障用户可以虚拟地考察目的地、进行开放世界的探索或虚拟旅行GSV部署的220多亿张图片和100多个国家中任意一个目的地的任何一个地方。通过与有混合视觉能力团队的合作设计以及与11名视障用户进行的评估，研究表明可访问的街道视图有助于支持POI调查和远程路线规划。
### Innovation
StreetViewAI是首个专为视障用户设计的可访问的街景视图工具，综合运用了上下文感知的多模态AI技术、无障碍导航控制和对话式语音指令，使其能够满足视障用户的实际需求，对现有街道视图服务进行了重要的改进和扩展，提高了其实际应用的可及性和实用价值。
### Conclusion
本研究展示了可访问的街景视图在支持POI调查和远程路线规划方面的价值。提出了未来工作的关键指导原则，旨在进一步改善和优化可访问的街景视图系统。
## 180. `cs.AI` - 街道级AI：当前大语言模型是否准备好进行现实世界判断？ [PDF](https://arxiv.org/pdf/2508.08193), [HTML](https://arxiv.org/abs/2508.08193)
### Authors
Gaurab Pokharel,Shafkat Farabi,Patrick J. Fowler,Sanmay Das
### Background
近年来，关于大型人工智能模型在“道德”判断中所引发的伦理和社会影响的研究激增。现有研究主要集中在通过不同思想实验与人类判断的一致性上，或是关注人工智能判断的群体公平性问题。然而，AI最直接影响可能是帮助或完全取代所谓的‘街头级公务员’——决定稀缺社会资源分配或福利审批的人。长期以来，地方正义原则决定了如何在这些领域制定优先机制。因此，本文侧重于分析大语言模型（LLM）的优先级与人类判断以及现有社会和政治决定的脆弱性评分系统之间的一致性问题。研究主要采用了严格保护隐私的真实数据进行分析。
### Innovation
本文创新之处在于，以真实数据为基础，考察大语言模型在资源分配这类高风险社会决策中的应用。研究发现，大语言模型在内部运行、不同模型之间以及与现有脆弱性评分系统的优先级上表现出了极不一致的现象，但却在与常识人类判断的两两对比中显示出定性一致性。研究结论质疑当前AI系统直接融入高风险社会决策的能力，指出了当前应用中可能出现的严重问题。
### Conclusion
研究发现，大语言模型的优先级在不同方面表现出极大的不一致性。尽管在与人类常识判断的一致性方面表现出色，但其在实际应用中的稳定性和准确性仍需进一步提高。当前AI系统的应用可能尚未准备好处理高风险的社会决策。
## 181. `cs.AI` - 移植再生：一种新的文本数据增强范式 [PDF](https://arxiv.org/pdf/2508.14723), [HTML](https://arxiv.org/abs/2508.14723)
### Authors
Guangzhan Wang,Hongyu Zhang,Beijun Shen,Xiaodong Gu
### Background
数据增强是深度学习中一个关键的技术。传统方法如反向翻译主要集中在词汇层面的改写，主要产生与原意相同但形式不同的文本。尽管大型语言模型通过其‘知识涌现’能力提高了文本增强的水平，但控制这些输出的风格和结构仍是一项挑战，需要细致的提示工程。已有方法难以在保持原始文本特性的同时创造出多样且创意的内容型变体，研究现状表现出一定的局限性。
### Innovation
本文提出了一种新的文本增强范式——LMTransplant。其核心思想是：将种子文本植入由大型语言模型扩展了的上下文中，然后让模型基于扩展后的上下文再生一种变体。这种方法通过充分利用大型语言模型嵌入的知识创造出更多样且更具创意的内容，并同时保留了原始文本的核心属性。研究结果表明，LMTransplant在各种文本相关任务中的表现优于现存的文本增强方法，并且该方法还具有出色的可扩展性，随着增强数据量的增长而表现出更为显著的优势。
### Conclusion
LMTransplant展示了其在文本增强任务上的优越性与可扩展性，为文本数据增强提供了新的范式，并且它的实现效果和应用前景令人期待。
## 182. `cs.AI` - RLVR深度广度协同：通过自适应探索来解锁大语言模型推理收益 [PDF](https://arxiv.org/pdf/2508.13755), [HTML](https://arxiv.org/abs/2508.13755)
### Authors
Zhicheng Yang,Zhijiang Guo,Yinya Huang,Yongxin Wang,Dongchun Xie,Yiwei Wang,Xiaodan Liang,Jing Tang
### Background
RLVR作为一种强大的框架，已被证实能增强大语言模型的推理能力，但其潜力受到深度和广度这两个未充分探索维度的限制。传统算法如GRPO存在系统性偏差，偏好中等准确度样本而忽视低准确度样本，这不利于扩展模型的推理边界。研究者提出Difficulty Adaptive Rollout Sampling (DARS)算法，以此增加困难问题的正面采样，加速收敛并保持推理精度不变。此外，通过扩大训练数据的广度，提高批量大小和使用完整的批量更新，增强了模型的推理能力。同时，DARS-B算法整合了广度扩大和自适应探索，实现了更全面的收益提升。
### Innovation
提出了深度自适应采样(DARS)算法，通过多阶段有针对性的采样增加困难问题的正面采样次数；通过大幅增加训练数据的广度，多个批次更新从而提升了Pass@1的表现；提出DARS-B，结合了广度扩大和自适应探索，实现了在保持高准确率的同时增加更多维度的收益；证明了深度和广度是RLVR中独立但互补的维度，是发挥自身推理能力的关键。
### Conclusion
通过自适应探索和大规模训练数据，RLVR可以同时提高大语言模型的推理能力与效率，克服了深度和广度受限的问题，为提升模型推理性能提供了新的方向。
## 183. `cs.AI` - 人工智能重塑地学国际学术社区的格局吗？ [PDF](https://arxiv.org/pdf/2508.20117), [HTML](https://arxiv.org/abs/2508.20117)
### Authors
Liang Li,Yuntian Li,Wenxin Zhao,Shan Ye,Yun Lu
### Background
通过文献计量分析和主题建模，我们发现人工智能（AI）正在积极改变地学研究，近年来AI相关的科学产出显著增加。我们注意到来自发展中国家的地学家在AI for Science（AI4S）范式中获得了更好的可见性，并且人工智能正在改善地学相关研究的国际合作格局。
### Innovation
采用文献计量分析和主题建模方法来研究AI对地学研究的影响，并强调了来自发展中国家的地学家的可见度提高以及国际合作的改善作为新的研究成果。
### Conclusion
研究结果表明，AI对地学研究产生了积极影响，而且来自发展中国家的地学家在AI4S范式的参与度正在增加，同时国际合作也在得到加强。
## 184. `cs.AI` - Beacon：集成了网格选择的后训练量化 [PDF](https://arxiv.org/pdf/2508.20293), [HTML](https://arxiv.org/abs/2508.20293)
### Authors
Shihao Zhang,Rayan Saab
### Background
量化是一种广泛使用的压缩技术，用于降低大型预训练模型的内存和计算成本。后训练量化（Post-Training Quantization, PTQ）中的一个关键挑战是如何选择适当的缩放因子来用缩放整数网格中的值替换权重值。现有方法通常通过启发式调优或网格搜索固定缩放比例。然而，Beacon算法旨在简化这一过程，提出了一种不需要手动调优的简单且有效的方法。
### Innovation
Beacon算法直接使用未缩放的网格进行逐通道PTQ，并通过利用标量化几何学自动确定最优缩放因子。它不依赖于反向传播或大型校准集，尽管算法简单且不依赖于调优，但Beacon在性能上与最先进的方法相当，为高效模型部署提供了实用解决方案。
### Conclusion
Beacon通过直接使用未缩放的网格进行逐通道PTQ，以及自动确定最优缩放因子，无需手动调优，解决了PTQ中的主要挑战。与现有方法相比，Beacon实现了可竞争的性能，成为高效模型部署的实用解决方案。
## 185. `cs.AI` - 高等教育部生成式AI和批判性思维研究试点 [PDF](https://arxiv.org/pdf/2509.00167), [HTML](https://arxiv.org/abs/2509.00167)
### Authors
W. F. Lamberti,S. R. Lawrence,D. White,S. Kim,S. Abdullah
### Background
生成式AI工具在教育环境中的应用快速增加，但其在促进批判性思维方面的作用仍未得到充分研究。尽管过去的研究已经考察了生成式AI作为特定课程的辅导工具或用于完成作业的工具，但很少有人涉及到学生如何批判性地评估AI生成的答案的准确性和适宜性。这项试点研究分析了学生在入门级计算与数据科学课程中评估生成式AI输出时应用结构化批判性思维的能力。鉴于生成式AI工具通常会产生上下文不准确或事实错误的答案，我们设计了学习活动，要求学生分析、评价并修订AI生成的解决方案。
### Innovation
研究发现了学生批判性地与生成式AI内容互动的能力，并为未来课程中的更全面研究奠定了基础。这项研究创新性地将生成式AI工具的应用与批判性思维结合，为教育领域提供了新的视角和研究方法。
### Conclusion
本研究初步揭示了学生批判性评估生成式AI输出的能力，并指出了未来的发展方向。研究结果表明，生成式AI可以作为一种有效的教学工具，促进学生的批判性思维能力。
## 186. `cs.AI` - TimeCopilot [PDF](https://arxiv.org/pdf/2509.00616), [HTML](https://arxiv.org/abs/2509.00616)
### Authors
Azul Garza,Reneé Rosillo
### Background
该研究提出了一种名为TimeCopilot的新框架，旨在通过将多个时间序列基础模型（TSFMs）与大型语言模型（LLMs）整合，实现多维度的时间序列预测。背景在于现有预测方法通常需要手动调参和解释，导致效率低且难以复现和解释。TimeCopilot旨在提供一个统一的API，自动化预测流程，包括特征分析、模型选择、交叉验证、预测生成，并提供自然语言解释和直接的未来查询支持。
### Innovation
TimeCopilot的创新点在于其开放源代码的性质，提供了一个单一的统一API来结合TSFMs和LLMs，并实现了自动化的预测管道。框架具有LLM无关性，支持各种商业和开源模型，并支持跨不同预测家族的集成。研究结果显示，在大规模GIFT-Eval基准测试中，TimeCopilot实现了成本低廉但性能一流的概率预测效果。该框架为可重现、可解释和可访问的代理预测系统提供了实际基础。
### Conclusion
TimeCopilot框架提供了一种新的方法来实现多时间序列预测，通过自动化预测流程显著提高效率并增强可解释性。研究成果表明其在企业和学术界具有广泛的应用前景，并为未来的相关研究提供了坚实的基础。
## 187. `cs.AI` - 基于解耦反向传播的一阶模型导向的强化学习 [PDF](https://arxiv.org/pdf/2509.00215), [HTML](https://arxiv.org/abs/2509.00215)
### Authors
Joseph Amigo,Rooholla Khorrambakht,Elliot Chane-Sane,Nicolas Mansard,Ludovic Righetti
### Background
随着强化学习(RL)方法利用模拟器的导数以提高学习效率的兴趣不断增加，尽管早期基于梯度的方法在性能上优于无导数方法，但获取模拟器梯度往往由于实现成本或不可用性而变得不切实际。基于模型的RL(MBRL)可以通过学习动力学模型近似梯度，但在训练回放中累积的预测误差会降低策略性能。该文提出了一种方法，将轨迹生成与梯度计算解耦：使用模拟器展开轨迹，通过学习的可微模拟器模型进行反向传播计算梯度。这种混合设计即使在无法获得模拟器梯度的情况下也能实现高效且一致的一阶策略优化，并从模拟回放中学习一个更准确的评论家。
### Innovation
该方法通过解耦轨迹生成和梯度计算，使得即使在缺乏模拟器梯度的情况下也能高效且一致地实现一阶策略优化。它不仅实现了类似于SHAC等专门优化器的样本效率和速度，同时还保持了PPO等标准方法的一般性，避免了其他一阶MBRL方法中的不良行为。此外，该方法通过模拟回放学习评论家，提高了准确性。
### Conclusion
本文方法在基准控制任务上的实证验证表明其有效，同时也展示了其在现实中的四足机器人Go2上的实际效果，涵盖了四足和双足运动任务。
## 188. `cs.AI` - AImoclips: 一种评估文本到音乐生成中情绪传达的基准 [PDF](https://arxiv.org/pdf/2509.00813), [HTML](https://arxiv.org/abs/2509.00813)
### Authors
Gyehun Go,Satbyul Han,Ahyeon Choi,Eunjin Choi,Juhan Nam,Jeong Mi Park
### Background
文本到音乐（TTM）生成技术的进步使得使用自然语言提示进行可控且具表达性的音乐创造成为可能。尽管如此，TTM系统的情绪忠实度相较于人类偏好或文本对齐仍相对未被充分研究。这项研究旨在引入AImoclips，一种用于评估TTM系统如何向人类听众传达预期情绪的基准，涵盖了开源和商业模型。研究通过六种先进的TTM系统生成了超过1,000首音乐片段，总共111名参与者对每个片段的情绪价值和唤醒度进行了9点量表的评分。结果显示，商业系统倾向于生成听起来比预期更加愉悦的音乐，而开源系统则呈现相反趋势。所有系统在高唤醒条件下更准确地传达情绪，并且所有系统都表现出向情绪中性偏好的倾向，揭示了情感可控性的关键局限性。这一基准为模型特异性情绪渲染特征提供了宝贵见解，并支持未来开发情绪对齐的TTM系统的发展。
### Innovation
引入AImoclips，一种用于评估文本到音乐生成中情绪传达的基准；采用六种先进的TTM系统生成了超过1,000首音乐片段；参与者评分揭示了商业系统和开源系统在情绪传达上的不同趋势；发现所有系统在高唤醒条件下更准确地传达情绪；所有系统都表现出向情绪中性偏好的倾向，揭示了情感可控性的关键局限性。
### Conclusion
AImoclips提供有关模型特定情绪渲染特性的宝贵见解，并支持未来开发情绪对齐的TTM系统的进展。商业系统倾向于生成更多愉悦的音乐，而开源系统倾向于相反的效果。在高唤醒条件下，情绪传达更加准确。所有系统都倾向于显示出情绪中性的偏好，揭示了情感可控性的关键局限性。
## 189. `cs.AI` - 语言模型训练和评估中合成长上下文数据生成的模块化技术 [PDF](https://arxiv.org/pdf/2509.01185), [HTML](https://arxiv.org/abs/2509.01185)
### Authors
Seganrasan Subramanian,Abhigya Verma
### Background
大型语言模型（LLMs）处理和推理长文本输入的能力对于许多实际应用至关重要，但该领域的发展受到高质量、多样性和可验证的长上下文数据集不足的限制。这些数据集不仅适用于训练，而且适用于评估。本文介绍了一种通过指令式交互生成合成长上下文数据的模块化框架。该框架支持多种训练和对齐目标，包括有监督微调（SFT）、直接偏好优化（DPO）和组相对策略优化（GRPO）。
### Innovation
本文提出了通过指令式交互生成合成长上下文数据的模块化框架，支持多种训练和对齐目标，并涵盖了多轮对话、文档基础输入-输出对、可验证指令-响应任务和长上下文推理示例四种核心生成范式。通过模板提示、模型无关的架构和元数据丰富的输出，该方法促进了大规模、可控且目标导向的数据集创建，以推进LLMs的长上下文能力。
### Conclusion
该工作提供了一种灵活且可扩展的方法，通过指令式交互生成合成长上下文数据，从而支持LLMs的多种训练和对齐目标，有助于改进其处理长文本输入的能力。
## 190. `cs.AI` - DaMoC: 基于数据和模型压缩高效选择适合微调领域任务的最佳大型语言模型 [PDF](https://arxiv.org/pdf/2509.01221), [HTML](https://arxiv.org/abs/2509.01221)
### Authors
Wei Huang,Huang Wei,Yinggui Wang
### Background
大型语言模型（LLMs）在通用任务上表现出色，但在特定领域任务中表现不佳，需要通过特定数据进行细调。当前有许多开源LLM可供选择，但如何快速找到最适合细调特定任务的最佳模型是一个挑战。
### Innovation
提出了一个数据和模型压缩框架（DaMoC），通过数据层面和模型层面的改进来解决此问题。数据层面包括系统分类数据过滤方法，并提出分布感知方法、质量感知方法和混合方法等三种不同类别，同时增强了文本中关键词的密度进行压缩，并使用LLM迭代优化文本表达。模型层面则是通过层相似性评分评估每层的重要性，并移除不太重要的层，引入稀疏合并方法以保留尽可能多的原始模型能力。
### Conclusion
通过DaMoC框架，在四个数据集（医疗问答、金融问答、通用问答和阅读理解）上的实验表明，能够选择最佳的LLM同时节省大约20倍的训练时间。
## 191. `cs.AI` - 2025年MIDOG第2轨病理基础模型集成用于不典型分裂细胞分类 [PDF](https://arxiv.org/pdf/2509.02591), [HTML](https://arxiv.org/abs/2509.02591)
### Authors
Mieko Ochi,Bae Yuan
### Background
分裂象可分为典型和不典型类型，不典型的数量与肿瘤侵略性密切相关。准确区分这些分裂象对于患者的预后评估和资源分配至关重要，但即使是经验丰富的病理学家也很具有挑战性。
### Innovation
本文利用了预先在大量组织病理学数据集上训练的病理基础模型（PFM），通过低秩适应进行参数高效的微调。还采用了当前最先进的卷积神经网络架构ConvNeXt V2以增强模型性能。在训练过程中使用了鱼眼变换以强调分裂象，并结合ImageNet目标图像的Fourier域适应。最后，通过集成多个PFMs来进行互补形态学特征的综合分析，从而在初步评估阶段取得了竞争力的平衡精度。
### Conclusion
该方法通过集成多个PFMs，利用了互补的形态学见解，取得了在2025年MIDOG第2轨不典型分裂细胞分类上的竞争力平衡精度。
## 192. `cs.AI` - 结构转移：基于推理的表示转换计算 [PDF](https://arxiv.org/pdf/2509.03249), [HTML](https://arxiv.org/abs/2509.03249)
### Authors
Daniel Raggi,Gem Stapleton,Mateja Jamnik,Aaron Stockdill,Grecia Garcia Garcia,Peter C-H. Cheng
### Background
表示的选择对我们的有效交流和推理能力至关重要。本文讨论了一个尚未解决的重要问题：如何设计一种独立于表示系统的技术，以驱动表示转换和选择。本文通过一种称为结构转移的新计算方法，实现了不同表示系统的表示转换。
### Innovation
提出了一个称为结构转移的新计算方法，该方法允许在不同的表示系统中生成目标表示。这种方法的关键在于利用编码表示系统知识的模式，确保源表示和生成的目标表示满足指定的任何关系。结构转移基于表示系统理论的具体概念，如构造空间，从而使其具有广泛适用性。
### Conclusion
结构转移是一种独立于系统的计算方法，能够在各种实际应用场景中识别替代表示。通过利用构造空间的抽象性质，结构转移能够为不同类型的表示系统（包括形式语言、几何图形、图表以及非正式符号）提供一种通用的框架。
## 193. `cs.AI` - 基于科班体验学习的一般化智能体及其人类级 Kaggle 数据科学性能 [PDF](https://arxiv.org/pdf/2411.03562), [HTML](https://arxiv.org/abs/2411.03562)
### Authors
Antoine Grosnit,Alexandre Maraval,Refinath S N,Zichao Zhao,James Dora,Giuseppe Paolo,Albert Thomas,Jonas Gonzalez,Abhineet Kumar,Khyati Khandelwal,Abdelhakim Benechehab,Hamza Cherkaoui,Youssef Attia El-Hili,Kun Shao,Jianye Hao,Jun Yao,Balázs Kégl,Jun Wang
### Background
人类的专长通过迭代的互动、反思和内在模型更新而形成，这是基于柯布的体验学习和维果茨基的最近发展区的认知理论的核心。相比之下，当前的人工智能系统（特别是大型语言模型）依靠静态预训练或固定的工作流程，缺乏持续适应的机制。研究发现，大型语言模型具有早期的认知特征（反思、修订和自我改正），表明其人类经验学习的基础要素。因此，关键问题是能否设计出能够在类似于人类过程中自主学习的大型语言模型。
### Innovation
本文提出了一种以柯布学习周期为基础并与维果茨基的最近发展区相结合的计算框架，用于自主智能体。该框架将外在的环境互动和内在的内部反思/抽象功能分离，使智能体能够在已结构化的环境中学习，然后进入开放的泛化阶段，能够掌握复杂任务。系统Agent K在81个任务中实现了完全自动化的数据科学代码生成，并在Kaggle数据科学竞赛中表现出超越人类的表现。这标志着通用人工智能的一个重要步骤。
### Conclusion
我们的系统Agent K通过集成柯布和维果茨基的人类认知学习理论，在Kaggle数据科学竞赛中取得了人类级别的性能，成为了第一个成功整合柯布和维果茨基启发的学习方法的人工智能系统。
## 194. `cs.AI` - 自主化，而非自动化：欧洲事实核查者活动与需求为基础的人本化AI系统设计 [PDF](https://arxiv.org/pdf/2211.12143), [HTML](https://arxiv.org/abs/2211.12143)
### Authors
Andrea Hrckova,Robert Moro,Ivan Srba,Jakub Simko,Maria Bielikova
### Background
随着假信息的负面影响日益突出，需要开发人工智能（AI）系统来辅助事实核查人员，以更有效地减少其影响。然而，由于缺乏关注这些利益相关者的具体需求，事实核查人员对完全自动化事实核查流程持怀疑态度。研究者通过与中欧事实核查人员进行半结构化深入访谈，并结合内容分析和欧洲事实核查人员的调查结果，揭示了当前存在的问题和需求。
### Innovation
研究者深入探讨了非英语地区事实核查工作的多样性，这些地区在先前研究中尚未充分覆盖。通过与先前研究的知识相结合，建立了有助于理解事实核查流程的概念模型。此外，研究者将事实核查员的活动和需求与AI研究中的相关任务进行了匹配，并讨论了三个未被先前类似研究覆盖的AI任务。这些发现为AI研究人员和开发者提供了新的机遇，促使其在这一领域聚焦新的研究重点。
### Conclusion
通过结合事实核查员的需求和问题，为设计人本化AI系统提供了依据。研究结果强调了AI在帮助事实核查工作中通过自主化而不是简单自动化的方式提高效果的潜力。
## 195. `cs.AI` - DMN-Guided Prompting: 一种控制LLM行为的框架 [PDF](https://arxiv.org/pdf/2505.11701), [HTML](https://arxiv.org/abs/2505.11701)
### Authors
Shaghayegh Abedi,Amin Jalali
### Background
大语言模型（LLMs）在知识密集型流程的决策逻辑自动化方面显示出了显著的潜力。然而，它们的有效性在很大程度上取决于提示的策略和质量。决策逻辑通常嵌入在提示中，因此对于最终用户来说，在不改动或精细调整决策逻辑的情况下，修改提示变得具有挑战性。为了简化这一过程，研究人员提出了决策模型和注记（DMN）这一标准化的图示方法，这种方法以结构化和用户友好的方式定义决策逻辑。
### Innovation
本文提出了一种基于DMN的提示框架，该框架能够将复杂的决策逻辑分解为更小、更易于管理的部分，并引导大语言模型通过结构化的决策路径。这项研究通过在研究生课程中的实证研究，证明了这种DMN引导的提示框架在生成反馈方面优于“思维链”（CoT）提示策略。同时，学生对生成的反馈给予了高度评价，认为对他们的学习具有很高的实际价值。
### Conclusion
实施DMN引导的提示框架取得了一定的成功，在实际应用中表现出色，超过了思维链提示策略。并且学生从技术接受模型的角度对生成的反馈也给予了积极的反馈。该研究为更好地控制和优化LLM的行为提供了一种新的方法。
## 196. `cs.CL` - 通过强化行为对齐增强语音大型语言模型 [PDF](https://arxiv.org/pdf/2509.03526), [HTML](https://arxiv.org/abs/2509.03526)
### Authors
Yansong Liu,Jiateng Li,Yuan Liu
### Background
近年来，大规模语言模型（LLMs）的研究兴趣已经扩展到除了文本之外的其他模态，如语音，催生了能够处理语音或文本请求的语音基大型语言模型（SpeechLMs）。然而，由于不同模态间的差异，这些语音基大型语言模型在指令遵循方面仍然远远落后于基于文本的大型语言模型，尤其是在面临用户的动态多变的语言输入时。
### Innovation
本文提出了一种名为强化行为对齐（RBA）的框架，旨在增强语音基大型语言模型的语言生成能力。不同于依赖于人工标注的监督微调，RBA 使用一个强大的导师语言模型产生大量高质量的对齐数据。然后，通过强化学习方法使语音基大型语言模型的行为与导师模型对齐。实验结果表明，该方法有效增强了语音基大型语言模型的指令遵循能力，且优于传统知识蒸馏基准。更重要的是，该方法可以无缝应用于包括口语问答和语音转文本翻译在内的任务，并在公开基准测试中获得了最佳性能。
### Conclusion
通过RBA框架，语音基大型语言模型在指令遵循、口语问答和语音转文本翻译等任务上的性能得到了显著提升，证明了该方法的有效性和泛化能力。
## 197. `cs.CL` - 使用细调Mistral大规模语言模型和RAG方法进行多层加密货币新闻分析 [PDF](https://arxiv.org/pdf/2509.03527), [HTML](https://arxiv.org/abs/2509.03527)
### Authors
Bohdan M. Pavlyshenko
### Background
本文考虑使用细调的Mistral 7B大语言模型结合检索增强生成（RAG）方法进行加密货币新闻的多任务多层次分析。加密货币市场的复杂性和波动性要求更精细和多角度的数据分析。传统的数据分析方法可能难以捕捉到加密货币新闻中的细微变化和关联性，因此需要一种能够提供全面、互补观点的分析方法。
### Innovation
本文的创新之处在于提出了一种多层次的多任务分析方法，使用细调的Mistral 7B大语言模型进行加密货币新闻的分析。这种方法包括第一层级生成图形和文本摘要及评分，更高层级进行层次堆叠，最终形成综合报告。此外，将新闻表示为知识图谱能有效地减少大型语言模型的幻觉问题。
### Conclusion
实验结果表明，使用细调的Mistral 7B大语言模型进行多层次加密货币新闻分析能够进行信息性的定性和定量分析，提供重要见解。此方法不仅能够识别出新闻中的细微变化，还能将这些变化以图形和文本的形式有效呈现，辅助决策者更好地理解加密货币市场的复杂性。
## 198. `cs.CL` - 基于语音的认知筛查：大规模语言模型适应策略的系统评估 [PDF](https://arxiv.org/pdf/2509.03525), [HTML](https://arxiv.org/abs/2509.03525)
### Authors
Fatemeh Taherinezhad,Mohamad Javad Momeni Nezhad,Sepehr Karimi,Sina Rashidi,Ali Zolnour,Maryam Dadkhah,Yasaman Haghbin,Hossein AzadMaleki,Maryam Zolnoori
### Background
据估计，美国一半以上的阿尔茨海默病及相关痴呆症患者未被诊断。语音筛查是一种可扩展的筛查方法。研究者使用DementiaBank语音语料库，比较了九种纯文本模型和三种多模态音频-文本模型，在这些模型中评估了大型语言模型的适应策略，包括上下文学习、推理增强提示、参数高效微调和多模态集成，以检测痴呆症。结果显示，类中心示例获得了最高的上下文学习性能，推理可以改善较小模型的表现，而词元级微调通常能得到最佳分数。添加分类头显著提高了表现不佳的模型。多模态模型中的微调音频-文本系统表现出良好，但并未超越顶级的纯文本模型。这些发现强调了适应策略，包括示例选择、推理设计和调优方法对基于语音的痴呆症检测至关重要，并表明适当地调整公开权重模型可以匹配或超越商用系统。
### Innovation
研究者系统地评估了大规模语言模型在语音痴呆检测中的适应策略，包括上下文学习的不同示例选择策略、推理增强提示、参数高效微调和多模态集成等多种适应方法。研究结果表明，适当的适应策略显著影响了基于语音的痴呆检测性能，特别是类中心示例、推理推理和词元级微调的方法对模型效果有显著提高，同时，多模态模型在某些方面也有较好的表现，但并未超越最佳的纯文本模型。这些创新性的适应策略提高了语音痴呆筛查工具的有效性和准确性，具有广泛的应用前景。
### Conclusion
这些研究结果强调了大型语言模型适应策略在基于语音的痴呆筛查中的关键作用，表明适当的适应策略可以显著提升模型性能。研究指出，使用适当的适应策略可以使得公开权重模型达到或超过商用系统的效果。未来的研究应当进一步探索和优化这些适应策略，以提高基于语音的痴呆筛查的效率和准确性。
## 199. `cs.CL` - 基于AI的多模态提案以提高消息跨评估 [PDF](https://arxiv.org/pdf/2509.03529), [HTML](https://arxiv.org/abs/2509.03529)
### Authors
Alejandro Álvarez Castro,Joaquín Ordieres-Meré
### Background
 earnings calls 是一种独特的丰富半结构化财务交流源，融合了管理者制定的评论和分析员未制定的对话。尽管最近在情感分析方面的进展结合了多模态信号，如文本内容和语音语调，大多数系统仍依赖于扁平的文件或句子级别的模型，未能捕捉到这些互动的分层对话结构。因此，该研究旨在通过构建层次对话树来生成和结构化财务报告。
### Innovation
引入了一种新颖的多模态框架，为财报电话会议生成富含语义和结构意识的嵌入表示。该框架包含从文本、音频和视频中提取的情感信号，以及结构化元数据，如连贯性分数、主题标签和答案覆盖率评估。该系统采用两阶段的转换器架构，首先通过对比学习在节点级别编码多模态内容和对话元数据，然后综合整个会议的全球嵌入。
### Conclusion
实验结果表明，生成的嵌入表示形成了稳定、语义上有意义的表示，反映了情感语调、结构逻辑和主题契合度。该系统不仅适用于财务报告领域，还可推广到具有高风险且未制定沟通的其他领域，如远程医疗、教育和政治对话。该方法对下游任务如金融预测和对话评估具有实用价值，并提供了一种在涉及高风险沟通的其他领域通用的方法。
## 200. `cs.AI` - 基于可学习编码的向量化注意力机制在量子变换器中的应用 [PDF](https://arxiv.org/pdf/2508.18464), [HTML](https://arxiv.org/abs/2508.18464)
### Authors
Ziqing Guo,Ziwen Pan,Alex Khan,Jan Balewski
### Background
当前的量子变换器依赖于深度参数化量子电路，在实际性能上受量子处理器（QPU）噪声的影响，存在效率问题。需要一种能够通过量子近似模拟支持理想屏蔽注意力矩阵计算，并通过向量化非线性量子编码进行高效训练的方法，提高量子电路模拟（QCS）效率，降低经典采样开销，同时适应量子噪声的量子计算体系结构，以实现端到端的量子机器学习。
### Innovation
本文提出向量化量子变换器（VQT）模型，支持通过量子近似模拟计算理想屏蔽注意力矩阵，利用向量化非线性量子编码高效训练，实现量子电路模拟的少脉冲高效、无梯度量子电路模拟（QCS），降低了经典采样开销。展示了在IBM和IonQ的量子电路模拟以及在IBM最先进的高保真Kingston QPU上进行自然语言处理任务的基准测试中的准确性对比，表明其方法在量子噪声环境中更友好，解锁了端到端的量子机器学习架构.
### Conclusion
通过向量化量子变换器的设计和应用，验证了在可适应量子噪声、提高量子电路模拟效率和减少经典采样开销方面的有效性和可行性，有助于提升量子机器学习的实际应用效果。
## 201. `cs.CL` - 从青少年社交媒体文本中预测未来自杀意念：读取隐藏的信号 [PDF](https://arxiv.org/pdf/2509.03530), [HTML](https://arxiv.org/abs/2509.03530)
### Authors
Paul Blum,Enrico Liscio,Ruixuan Zhang,Caroline Figueroa,Pradeep K. Murukannaiah
### Background
青少年自杀是导致死亡的主要原因之一，尽管目前存在一些挑战，但预测自杀行为仍然困难。许多潜在的自杀案例由于缺乏与心理健康服务的接触而未被发现。然而，社交媒体为识别自杀风险提供了独特机会，因为年轻人经常在论坛上分享自己的想法和困难。文献中针对这种类型的行为预测研究较少，尤其在没有用户自我披露介入的情况下预测自杀倾向更为罕见。这篇论文聚焦于从论坛帖子中预测青少年未来的自杀意念（SIB），以填补这一研究空白。
### Innovation
提出了一种新的任务和方法，即利用变换器（transformer-based）模型预测青少年在未直接表达自杀想法之前是否会发布有关自杀行为的帖子。这使得在没有自我披露的情况下预测自杀意念成为可能，该方法在自杀预测领域尚属鲜有研究。文章介绍了一种名为Early-SIB的新模型，该模型能够通过处理用户在其社交媒体上发表的帖子，来预测用户是否会撰写关于自杀意念的帖子。该模型在荷兰青少年论坛上的试验表明，它具有很高的预测能力，克服了传统方法的局限性，能够在早期识别潜在的自杀风险，并具备显著的实操价值。
### Conclusion
该研究使用Early-SIB模型成功预测了荷兰青少年论坛上未来将会发表有关自杀意念的帖子，平衡准确率为0.73。这一成果表明，此类工具可以作为传统方法的有效补充，用于早期识别和干预青少年潜在的自杀风险。
## 202. `cs.AI` - 如何在不透露真实答案的情况下发布我的大语言模型基准？ [PDF](https://arxiv.org/pdf/2505.18102), [HTML](https://arxiv.org/abs/2505.18102)
### Authors
Takashi Ishida,Thanawat Lodkaew,Ikko Yamane
### Background
在互联网上发布大语言模型（LLM）基准存在风险，这些基准可能会被无意或有意地用于训练或选择模型。一种常见的缓解策略是保持基准的秘密性，让参与者提交他们的模型或预测给主办方。然而，这种方法需要对单一组织的信任，并仍有可能通过多次查询进行测试集过拟合。为了解决这些问题。
### Innovation
提出了一种不完全披露问题真实答案的方法来发布基准，同时仍然能够公开评估大语言模型。主要思想是在答案中注入随机性，准备几个逻辑上正确的答案，并且只将其中一个作为基准的解决方案。这降低了基准的最佳可能准确性，即贝叶斯准确性。这种方法不仅有助于保护真实答案，还提供了一种检测数据污染的测试。即使完全有能力的模型也不能超越贝叶斯准确性。如果模型超过了这个上限，这是数据污染的强烈信号。
### Conclusion
实验结果证明，该方法在广泛的基准、模型和训练方法上能够准确地检测数据污染。
## 203. `cs.CL` - QuesGenie：智能多模态问题生成 [PDF](https://arxiv.org/pdf/2509.03535), [HTML](https://arxiv.org/abs/2509.03535)
### Authors
Ahmed Mubarak,Amna Ahmed,Amira Nasser,Aya Mohamed,Fares El-Sadek,Mohammed Ahmed,Ahmed Salah,Youssef Sobhy
### Background
在信息丰富的时代，学习者可以接触到大量的教育资源，但缺乏针对这些资源的定制化练习材料，这是一个显著的问题。这项研究旨在通过开发一个能够从不同内容格式中自动生成多样类型问题的多模态问题生成系统来解决这一问题。
### Innovation
该项目通过开发一个多模态输入处理、问题生成、基于人类反馈的强化学习（RLHF）以及端到端交互界面的多模态问题生成系统，奠定了自动化、可扩展和智能化问题生成的基础，实现了资源效率、功能的鲁棒性和良好的用户体验之间的平衡。
### Conclusion
该项目为自动化、可扩展和智能化的问题生成奠定了基础，通过四个主要组件：多模态输入处理、问题生成、基于人类反馈的强化学习（RLHF）和端到端交互界面，平衡了资源效率、功能鲁棒性和用户界面的流畅性。
## 204. `cs.CL` - AR²：大型语言模型中的对抗性强化学习进行抽象推理 [PDF](https://arxiv.org/pdf/2509.03537), [HTML](https://arxiv.org/abs/2509.03537)
### Authors
Cheng-Kai Yeh,Hsing-Wang Lee,Chung-Hung Kuo,Hen-Hsen Huang
### Background
抽象——从复杂的任务描述中识别和提炼出关键的计算模式——是计算机科学中的基础技能，对于人类问题解决者和注重编码的大型语言模型（LLMs）来说都是至关重要的。尽管最近有训练LLMs通过强化学习（RL）进行代码生成方面的进展，但大多数方法主要集中在表面模式识别上，忽视了显式的抽象训练。
### Innovation
本文提出了一种名为AR²的新框架，这是一种专门设计来增强LLMs的抽象能力的新型框架。AR²通过教师模型将核问题转化为叙述丰富的挑战性描述，同时训练学生编码模型从复杂的叙述性问题中提取出其背后的计算核。
### Conclusion
实验结果显示，AR²显著提高了学生模型在以前未见过的具有挑战性的编程任务上的准确性，强调了抽象是提高LLMs泛化的关键技能。
## 205. `cs.CL` - 通过信息瓶颈视角识别大语言模型输入-输出对的主题 [PDF](https://arxiv.org/pdf/2509.03533), [HTML](https://arxiv.org/abs/2509.03533)
### Authors
Igor Halperin
### Background
大语言模型（LLMs）可能会出现关键的失败模式，比如内在忠实性幻觉（也称为自说自话），即模型生成的响应在语义上偏离了提供的背景信息。现有框架，如语义发散度度量（SDM），依赖于识别提示和响应之间共享的隐含主题，通常通过应用场景几何聚类到它们的句子嵌入。这种做法存在断层，因为这些主题更注重空间毗邻性，而非下游信息论分析。
### Innovation
本文提出了一个基于确定性信息瓶颈（DIB）的严谨主题识别方法，以此填补现有技术的断层。核心创新在于将DIB方法转化为适用于高维数据的实用算法，通过用计算高效的上限替换其不可解的KL散度项。这种方法命名为UDIB，可以解释为对数率正则化且更稳健的K-均值版本，更倾向于产生具有信息价值的簇。通过将UDIB应用于LLM提示和响应嵌入的联合聚类，生成结构化且能最大化反映提示-响应关系的共享主题表示，为SDM框架提供了更优的基础，并提供了一种更敏感的新工具来检测自说自话。
### Conclusion
通过应用UDIB，生成的共享主题表示不仅在空间上一致，而且从根本上结构化为最大化提示-响应关系的信息，从而为SDM框架提供更强的基础，并提供了一种更加敏感的新工具来检测自说自话。
## 206. `cs.AI` - EZhouNet: 基于图神经网络和锚间隔框架的呼吸音事件检测 [PDF](https://arxiv.org/pdf/2509.01153), [HTML](https://arxiv.org/abs/2509.01153)
### Authors
Yun Chu,Qiuhao Wang,Enze Zhou,Qian Liu,Gang Zheng
### Background
听诊是早期诊断呼吸和肺部疾病的关键方法，依赖于专业医护人员。然而，这一过程往往是主观的，不同专家之间存在显著差异。因此，出现了多种基于深度学习的自动分类方法，大多数方法集中在呼吸音分类上。相比之下，呼吸音事件检测的研究相对有限。现有的事件检测方法通常依赖于帧级预测后进行处理以生成事件级输出，这使得难以直接学习时间间隔边界。此外，许多方法只能处理固定长度的音频，限制了其在变长呼吸音上的应用。同时，呼吸音位置信息对检测性能的影响尚未得到广泛研究。
### Innovation
提出了一个基于图神经网络的框架，结合了锚间隔，能够处理变长音频并提供更精确的异常呼吸音事件的时间定位。该方法在呼吸音检测的灵活性和适用性方面有所改进。实验在SPRSound 2024和HF Lung V1数据集上证明了所提出方法的有效性，并整合呼吸音位置信息可以提高异常声音分类的区分度。
### Conclusion
实验结果表明，所提出的基于图神经网络和锚间隔框架的方法在呼吸音事件检测上表现有效，特别是在处理变长音频和提高异常声音识别精度方面。
## 207. `cs.CL` - ResearchPulse：通过多文档科学推理构建方法-实验链 [PDF](https://arxiv.org/pdf/2509.03565), [HTML](https://arxiv.org/abs/2509.03565)
### Authors
Qi Chen,Jingxuan Wei,Zhuoya Yao,Haiguang Wang,Gaowei Wu,Bihui Yu,Siyuan Li,Cheng Tan
### Background
理解科学思想的演变需要超越对单一论文的总结，更需要进行跨文档、有结构的推理。本研究正式提出了一项新的多文档科学推理任务，该任务旨在提取并对齐相关论文中的动机、方法和实验结果，以重构研究发展链。这一任务提出了时间对齐松散结构的方法和标准化异构实验表等关键挑战。
### Innovation
研究提出了一种基于代理的框架ResearchPulse，该框架能够进行指令规划、科学内容提取和结构化可视化。该框架由三个协调工作的代理组成：计划代理进行任务分解，Mmap代理构建动机-方法思维导图，Lchart代理合成实验线图。此外，研究还引入了ResearchPulse-Bench，这是一个基于引用的多文档科学推理标注论文集群基准数据集。实验结果显示，尽管使用的是7B规模的代理，该系统在语义对齐、结构一致性和视觉保真度方面始终优于GPT-4o等基准模型。
### Conclusion
本研究通过多文档科学推理提出了一个名为ResearchPulse的新型框架，能够有效地对齐并呈现论文中的动机、方法和实验结果，进而重构研究发展链。实验验证了该系统的优越性，认为其能在处理复杂的多文档推理任务上更胜一筹。
## 208. `cs.CL` - 在长文本生成中实时检测虚构实体 [PDF](https://arxiv.org/pdf/2509.03531), [HTML](https://arxiv.org/abs/2509.03531)
### Authors
Oscar Obeso,Andy Arditi,Javier Ferrando,Joshua Freeman,Cameron Holmes,Neel Nanda
### Background
大型语言模型现在在高风险应用中被常规使用，例如医疗咨询或法律建议，其中虚构可能会导致严重伤害。现有的虚构检测方法要么仅限于短的客观性查询，要么需要昂贵的外部验证，从而使它们在实际应用中不可行。本文的背景在于需要一种成本较低且可扩展的方法来实时识别长文本生成中的虚构标记，并将其有效扩展至70亿参数量的语言模型。针对的是具体实体层面的虚构，这种方法便于实现实时检测且与标记数据的粒度相匹配。为此，作者通过利用网络搜索开发了一套标注方法，能够将模型响应标记为目标实体，通过这种方法成立了数据集，使简单和高效的方法，例如线性探针，能够训练出有效的虚构分类器。研究结果表明，此类分类器在几种模型的长文本响应上表现出色，尤其是对更昂贵的方法，如语义熵，具有更高的性能。此外，尽管训练仅使用特定实体层面的标签，但实验证明探针能够识别出数学推理任务中的错误答案，显示了其对于实体之外问题的泛化能力。
### Innovation
本文提出了一种低成本且可扩展的方法，用于实时识别长形式生成中的虚构标记，并有效扩展至70亿参数的模型。通过这种方法，分类器能够在无需昂贵外部验证的情况下，准确检测和识别虚构实体，特别是在更复杂和更长的文本生成中表现优异。实现了语言模型虚构检测方法的突破，从而可以更广泛地应用于各种实际场景之中，提高使用大型语言模型的安全性与可靠性。同时，作者还发现仅凭借实体层面的标签就能够训练出针对数学推理等更大范围任务的有效探针，这意味着这种方法具有更好的泛化能力。
### Conclusion
总体而言，本文为大规模且实际应用中的虚构检测提供了一种颇具前景的新方法。作者通过有效的标注方法成立数据集，并通过这种数据集训练出简单高效的分类器，旨在实现对未来广泛应用的一种创新解决方案。这种方法不仅可以改进虚构检测的效率，还可以促进未来更广泛利用语言模型的开发和部署，尤其是在医疗咨询和法律建议等高风险领域。
## 209. `cs.CL` - E-ARMOR: 边缘情况评估和审查的多语言光学字符识别 [PDF](https://arxiv.org/pdf/2509.03615), [HTML](https://arxiv.org/abs/2509.03615)
### Authors
Aryan Gupta,Anupam Purwar
### Background
多语言、噪声大和多样的现实世界图像中的光学字符识别（OCR）仍然是OCR系统面临的一个重大挑战。随着大型视觉-语言模型（LVLM）的兴起，人们越来越多地关注其在固定OCR流水线之外的能力扩展和推理。本文旨在探讨在边缘部署条件下，大型视觉-语言模型和传统OCR系统的表现。
### Innovation
本文引入了Sprinklr-Edge-OCR，一种专为资源受限环境下的边缘部署优化的新OCR系统。研究对比评估了包括LVLM（InternVL, Qwen, GOT OCR, LLaMA, MiniCPM）和传统OCR系统（Sprinklr-Edge-OCR, SuryaOCR）在内的五种最先进LVLM和两种传统OCR系统在多语言图像上的性能。
### Conclusion
研究结果表明，即使在大型语言模型时期，传统的OCR系统在边缘部署仍然是最优选择，因为它们对计算资源的需求较低、延迟短且价格非常实惠。Qwen在精确度上表现最好，而Sprinklr-Edge-OCR在综合F1得分、效率和成本上表现最佳。
## 210. `cs.CL` - 打破镜子：基于激活的LLM评估器自偏好缓解 [PDF](https://arxiv.org/pdf/2509.03647), [HTML](https://arxiv.org/abs/2509.03647)
### Authors
Dani Roytburg,Matthew Bozoukov,Matthew Nguyen,Jou Barzdukas,Simon Fu,Narmeen Oozeer
### Background
大型语言模型（LLMs）越来越被用作自动化评估者，但它们会表现出‘自偏好偏差’：倾向于偏爱自己的输出而非其他模型的输出。这种偏差削弱了评估流程的公平性和可靠性，特别是在偏好调优和模型路由等任务中。
### Innovation
本研究探讨了是否可以在不重新训练的情况下，通过使用轻量级引导向量在推理阶段缓解这一问题。研究引入了一个精选的数据集，将自偏好偏差区分为合理的自偏好和不合理的自偏好，使用对比激活添加（CAA）和优化方法构建向量。实验结果表明，引导向量能够显著减少不合理的自偏好偏差，远超提示和直接偏好优化的基础方法，但它们可能不稳定于实际的自偏好和无偏评估，揭示了自偏好偏差可能涉及多个或非线性的方向。
### Conclusion
引导向量在保护LLM作为裁判方面既表现出希望，也有限度。它强调需要采取更 robust 的干预措施以增强LLM自偏好的缓解能力。
## 211. `cs.CL` - NoteBar: 一种个人知识管理的人工智能辅助笔记系统 [PDF](https://arxiv.org/pdf/2509.03610), [HTML](https://arxiv.org/abs/2509.03610)
### Authors
Josh Wisoff,Yao Tang,Zhengyu Fang,Jordan Guzman,YuTang Wang,Alex Yu
### Background
笔记是学术和专业领域中捕获、组织和反思信息的关键实践。虽然大型语言模型的成功促进了AI辅助工具的发展，但现有解决方案在效率方面仍存在问题。为了改进这一状况，作者提出了一款名为NoteBar的AI辅助笔记系统，该系统利用角色信息和高效语言模型自动将笔记分类并更好地支持用户的工作流程。除开其主要功能，作者还创建了一个由3,173个笔记和8,494个注释概念组成的新颖的角色条件数据集，涵盖了16个MBTI角色类型，为下游任务提供了多样性和语义丰富性。
### Innovation
NoteBar是一款结合了角色信息和高效语言模型的AI辅助笔记工具，能够自动将笔记分类，并支持用户工作流程，这对于提高笔记效率非常重要。此外，该论文还提出了一个包含3,173个笔记和8,494个注释概念的新颖数据集，用于MBTI的16个角色类型，这为下游任务提供了多样性和语义丰富性，有助于进一步研究和评估AI辅助笔记系统的发展。
### Conclusion
NoteBar及其配套数据集为人工智能辅助个人知识管理提供了可扩展和可扩展的基础，能够以实用和经济高效的方式部署，使交互使用无需依赖繁重的基础设施。
## 212. `cs.CL` - MLSD: 一种改进跨目标和跨领域观点检测的新型少样本学习方法 [PDF](https://arxiv.org/pdf/2509.03725), [HTML](https://arxiv.org/abs/2509.03725)
### Authors
Parush Gera,Tempestt Neal
### Background
在不同领域和目标间的观点检测（stance detection）中，现有方法难以有效适应新的目标领域。本文通过引入基于元度量学习的少样本学习（MLSD），意在解决这一问题，提升观点检测的性能和适应性。MLSD使用三重损失进行元度量学习，以捕捉不同立场目标之间的语义相似性和差异性，增强领域适应性。通过构建区分性的嵌入空间，MLSD使得跨目标或跨领域的观点检测模型能够从新的目标领域中获取有用示例，从而提高其表现。
### Innovation
本文提出了基于元度量学习的少样本学习（Metric Learning-Based Few-Shot Learning for Cross-Target and Cross-Domain Stance Detection, MLSD）方法。该方法通过使用三重损失进行元度量学习来捕捉不同立场目标之间的语义相似性和差异性，增强领域适应性。MLSD通过构建区分性嵌入空间，使得跨目标或跨领域的观点检测模型能够从新领域中获取有用的示例，提高特征空间的适应性和泛化能力。
### Conclusion
本文在两个数据集的多个跨目标和跨领域的场景下评估了MLSD方法，结果显示在六个广泛使用的观点检测模型中，MLSD显著提高了观点检测的性能。
## 213. `cs.CL` - Align-then-Slide: 一种超长文档级机器翻译的完整评估框架 [PDF](https://arxiv.org/pdf/2509.03809), [HTML](https://arxiv.org/abs/2509.03809)
### Authors
Jiaxin Guo,Daimeng Wei,Yuanchang Luo,Xiaoyu Chen,Zhanglin Wu,Huan Yang,Hengchao Shang,Zongyao Li,Zhiqiang Rao,Jinlong Yang,Hao Yang
### Background
文档级机器翻译(textit{doc}-mt)由于大型语言模型（LLMs）的出现进入了新时代，但其生成的整体文档输出挑战了现有的基于句子级对齐的评估方法。本文背景在于如何更准确、全面地评估这些超长文档的机器翻译。
### Innovation
引入了一种全新的评估框架——textit{Align-then-Slide}，该框架包括两个阶段：(1) 在对齐阶段，自动推断出句子级的源-目标对应关系，并重新构建目标文本使其匹配源句子数量，解决遗漏和一对多或多对一的映射问题；(2) 在n-Chunk滑动评估阶段，计算1-4个片段的平均指标得分，进行多层次的评估。
### Conclusion
实验结果显示，Align-then-Slide 方法与专家人工评估高度相关（皮尔逊相关系数为0.929），并且生成的数据能够有效改进CPO训练和作为GRPO的奖励模型，从而提高翻译质量，超越了简单的模型微调基线。证明了该框架是评估文档级机器翻译系统的准确、稳健和可行的方法。
## 214. `cs.CL` - 衡量VLMs如何（而不仅仅是是否）建立共同基础 [PDF](https://arxiv.org/pdf/2509.03805), [HTML](https://arxiv.org/abs/2509.03805)
### Authors
Saki Imai,Mert İnan,Anthony Sicilia,Malihe Alikhani
### Background
现有的大规模视觉语言模型（VLMs）越来越多地声称具备推理能力，但是当前的基准测试主要是在单轮问答环境中进行的。然而，基础是通过持续的交流和渐进的共同理解发展的交互过程。该研究引入了一个四指标套件（即，基础效率、内容一致性、词汇适应性和人类性格特征）来系统评估VLM在交互基础上的性能，并在三个定制VLM与人类双人组之间的相互指称游戏中进行了部署，比较了这些模型的表现。
### Innovation
研究提出了一个四指标套件来系统地评估大型视觉语言模型在交互基础上的表现，并将模型与人类互动进行了比较，发现尽管任务成功的分数显示了基准差异，但图像-语句对齐度并不一定能预测任务的成功率，这提供了一个未来研究视觉语言模型基础的新框架，强调了’如何’建立共同基础的重要性。
### Conclusion
目前，现有的视觉语言模型无法完全与人类交互方式相匹配，尽管GPT4o-mini的表现最为接近人类。这一发现表明，现有的基准并不一定能够完全反映模型的实际交互能力，任务成功分数并不能充分说明成功的基础是否建立，模型之间的图像-语句对齐度高低并不能完全代表模型的成功率。该研究提出的新框架为未来关于视觉语言模型基础的研究提供了指导。
## 215. `cs.CL` - 利用MIMIC-IV数据库对SNOMED CT概念共现进行语义分析 [PDF](https://arxiv.org/pdf/2509.03662), [HTML](https://arxiv.org/abs/2509.03662)
### Authors
Ali Noori,Somya Mohanty,Prashanti Manda
### Background
临床笔记包含丰富的临床叙述，但由于其非结构化格式，大规模分析面临挑战。标准化术语（如SNOMED CT）改善了互操作性，但概念间通过共现性和语义相似性的关系尚未得到充分探索。利用MIMIC-IV数据库研究SNOMED CT概念共现模式与基于嵌入的语义相似性之间的关系，通过标准化点互信息（NPMI）和预训练嵌入（如临床BERT、BioBERT），探讨共同出现的概念是否具有语义接近性，嵌入是否能提出缺失的概念，并考察这些关系随时间及在不同专业领域中的变化。
### Innovation
研究利用MIMIC-IV数据库，通过NPMI和预训练嵌入工具，探索了SNOMED CT概念共现模式与其语义相似性的关系，验证了嵌入能否捕捉并提出常见但未记录的概念，分析了这些关系随时间变化，并且探讨了其在不同专业领域中的作用。
### Conclusion
研究发现，共现和语义相似性虽有弱关联，但基于嵌入的方法能捕捉到在文件频率中未体现的临床意义。嵌入建议经常匹配到后来记录的概念，显示其在增强临床注释方面的作用。嵌入的聚类结果显示了临床主题的集合，这些主题与患者表型和护理模式相符。最后，与死亡率和再入院等结果相关的共现模式显示了这种分析方法的实际价值。综上，研究强调共现统计和语义嵌入在提高记录完整性、揭露潜在的临床关系以及为决策支持和表型研究提供信息方面的互补价值。
## 216. `cs.CL` - ProLiFIC 数据集：利用大语言模型揭示意大利立法过程 [PDF](https://arxiv.org/pdf/2509.03528), [HTML](https://arxiv.org/abs/2509.03528)
### Authors
Matilde Contestabile,Chiara Ferrara,Alberto Giovannetti,Giovanni Parrillo,Andrea Vandin
### Background
过程挖掘（PM）最初在工业和商业领域中发展，最近被应用于社会系统，包括法律系统。然而，PM 在法律领域的应用受限于数据集的可访问性和质量。论文介绍了一个从意大利立法过程1987年至2022年的事件日志，名为ProLiFIC，该数据集经过了大型语言模型的结构化处理。ProLiFIC 还与最近将过程挖掘与大型语言模型结合的尝试相吻合，为进一步的法律过程挖掘提供可能的新发展。
### Innovation
引入了一个新的事件日志数据集 ProLiFIC，该数据集来源于意大利立法过程，时间跨度长达35年。该数据集通过大型语言模型自非结构化数据中进行结构化处理，为法律过程挖掘提供了高质量、便于访问的数据集，并且展示了将过程挖掘与大型语言模型结合的方法。
### Conclusion
ProLiFIC 数据集为法律过程挖掘提供了一个基准，该数据集具有较高的质量并且可通过大型语言模型进行结构化处理。这不仅促进了新发展的法律过程挖掘研究，还使人们能够更深入地理解和分析立法过程。
## 217. `cs.CL` - 为何基于探针的恶意输入检测无法泛化：一种虚假的安全感 [PDF](https://arxiv.org/pdf/2509.03888), [HTML](https://arxiv.org/abs/2509.03888)
### Authors
Cheng Wang,Zeming Wei,Qin Liu,Muhao Chen
### Background
大语言模型(LLMs)虽然表现出色，但仍然能遵守有害指令，引发严重的安全问题。近期的研究利用探针方法研究LLMs内部表征中恶意和良性输入的可分性，并提出了使用此类探针方法进行安全性检测。然而，由于探针在分布外表现不佳，研究者假设探针可能学习了表面模式而非语义有害性。
### Innovation
研究者系统性地重新审视了这一范式，并通过受控实验验证了探针学习的是浅表模式而非语义有害性。具体发现了两种模式：指令模式和触发词。研究从显示简单n-克(A)方法的同等性能开始，到使用语义清洁数据集的受控实验，再到模式依赖性的详细分析。这些结果揭示了当前基于探针的方法的虚假安全感，并强调了重新设计模型和评估协议的必要性。
### Conclusion
研究结果表明，当前基于探针的方法可能产生虚假的安全感，需要重新设计模型和评估协议。研究者提供了进一步的讨论，希望这能为未来的研究提供负责任的方向。该研究项目代码已经开源。
## 218. `cs.CL` - 凌乱学：用具有深度的无意义话语挑战LLM [PDF](https://arxiv.org/pdf/2509.03867), [HTML](https://arxiv.org/abs/2509.03867)
### Authors
Yang Wang,Chenghao Xiao,Chia-Yi Hsiao,Zi Yan Chang,Chi-Li Chen,Tyler Loakman,Chenghua Lin
### Background
目前的大语言模型（LLMs）在许多自然语言处理（NLP）任务中表现出色，但在处理具有深度的无意义话语（Drivelology）时表现不佳。Drivelology是指那些从句法上看是连贯的，但在语用学上是悖论性的、带有强烈情感色彩或具有颠覆性修辞功能的表达。这类表达在表面上看似无意义，但其中包含了需要情境推断、道德推理或情感解读的隐含意义。尽管LLMs在许多NLP任务中表现出色，但在处理这类具有深度的无意义话语时却往往难以理解其深层含义，收录了从英语、汉语、西班牙语、法语、日语和韩语中精心挑选的超过1200个例子的小但多样化的基准数据集，专门评审这些例子的复杂性突显了Drivelology的细微和主观性质。
### Innovation
该研究创新地提出了Drivelology这一独特的语言现象，并构建了一个涵盖多种语言的基准数据集。通过评估一系列大语言模型在分类、生成和推理任务中的表现，揭示了LLMs在处理语用理解和深层意义方面的明显局限性，质疑了统计流利性是否等同于认知理解的假设。同时，研究者发布了数据集和代码，以促进进一步研究，推动深度语言建模超越表面连贯性。
### Conclusion
这项研究的结果表明，大语言模型在处理具有深度的无意义语言时存在明显局限性，这种局限性不仅仅是表面上的困惑。研究突显了大语言模型在语用理解上的差距，并挑战了依赖统计流畅性来实现认知理解的假设。为了进一步推进语言建模研究，提出了实用的数据集和代码，激励研究人员探究更深层的语义理解和表示。
## 219. `cs.CL` - MobileRAG：利用检索增强生成提升移动代理 [PDF](https://arxiv.org/pdf/2509.03891), [HTML](https://arxiv.org/abs/2509.03891)
### Authors
Gowen Loo,Chang Liu,Qinghong Yin,Xiang Chen,Jiawei Chen,Jingyuan Zhang,Yu Tian
### Background
智能手机在人们日常生活中不可或缺，几乎渗透到现代社会的各个方面。随着大型语言模型（LLMs）的不断进步，已经出现了许多基于LLM的移动代理。这些代理能够准确解析多种用户查询，并自动帮助用户完成复杂的或重复的操作。然而，当前的代理1）高度依赖LLMs的理解能力，可能导致任务执行中的误操作或遗漏步骤导致的错误，2）缺乏与外部环境的交互，通常在应用程序无法满足用户查询时终止任务，3）缺乏记忆能力，需要每次指令重构建界面，无法从过去错误中学习和纠正。
### Innovation
为了缓解上述问题，我们提出了一种由检索增强生成（RAG）增强的移动代理框架——MobileRAG，它包括InterRAG、LocalRAG和MemRAG。MobileRAG利用RAG更快更准确地识别用户查询并完成复杂的和长序列的移动任务。此外，为了更全面地评估MobileRAG的性能，引入了MobileRAG-Eval，这是一个更加挑战性的基准，包括了大量复杂的、需要外部知识协助的真实世界移动任务。MobileRAG在MobileRAG-Eval上的广泛实验结果表明，它可以轻松处理真实世界的移动任务，比最先进的方法减少了10.3%的操作步骤。
### Conclusion
我们的代码将公开发布于此网址：this https URL。
## 220. `cs.AI` - AudioCodecBench: 一种全面的音频编解码评估基准 [PDF](https://arxiv.org/pdf/2509.02349), [HTML](https://arxiv.org/abs/2509.02349)
### Authors
Lu Wang,Hao Chen,Siyu Wu,Zhiyue Wu,Hao Zhou,Chengfeng Zhang,Ting Wang,Haodi Zhang
### Background
多模态大型语言模型（MLLMs）已在语音和音乐领域得到了广泛应用，这促使了对大型模型（LMs）的音频分词方法的研究关注。相较于仅包含语义信息的文本令牌，音频令牌必须同时捕捉全局语义内容并保存细微的声学信息。此外，音频令牌提供了一种离散的方法用于建模语音和音乐，并可有效整合进MLLMs。然而，现有的研究对语义令牌和声学令牌缺乏合适的定义。此外，针对不同编解码器的评估侧重于特定领域或任务，如重建或自动语音识别（ASR）任务，这阻碍了公平和全面的比较。因此，针对这些问题，本文提供了语义令牌和声学令牌的合适定义，并引入了一个系统评价框架。该框架在四个维度上对编解码器进行评估：音频重建指标、码本索引（ID）稳定性、仅解码器变换器困惑度以及下游任务表现：音频重建指标，码本索引（ID）稳定性，下游任务表现和困惑度之间的相关性及其正确性得到了验证。
### Innovation
该研究首次明确区分了语义令牌和声学令牌，并为它们提供了合适的定义。此基础上，该研究引入了一个系统评估框架，包括四大维度：音频重建指标、码本索引（ID）稳定性、仅解码器变换器困惑度以及下游任务表现。这为全面评估不同编解码器的能力提供了新的视角，改善了现有评估方法的局限性。这一评估框架不仅提供了对音频重建性能的评估，还能更全面地评估编解码器在泛化能力、编码效率和语义准确性等方面的性能。
### Conclusion
该研究提出的AudioCodecBench评估框架为多个编码器和解码器的全面评估提供了有效工具，能够全面评价不同编解码器在音频重建、码本稳定性以及下游任务中的性能表现，验证了对语义令牌和声学令牌的定义正确性。
## 221. `cs.CL` - SiLVERScore：手语生成评估的语义感知嵌入 [PDF](https://arxiv.org/pdf/2509.03791), [HTML](https://arxiv.org/abs/2509.03791)
### Authors
Saki Imai,Mert İnan,Anthony Sicilia,Malihe Alikhani
### Background
现有的手语生成评估通常通过反向翻译完成，即将生成的手语首先识别回文本，然后再与参考文本进行比较，使用基于文本的度量标准。这种方法存在两步评估流程导致的模糊性问题：不仅未能捕捉手语的多模态特性，如面部表情、空间语法和语调，还使得难以确定评估错误是源于生成模型还是评估系统（翻译系统）的问题。
### Innovation
本文提出了SiLVERScore，这是一种新颖的语义感知嵌入为基础的评估度量标准，用于在联合嵌入空间中评估手语生成。贡献包括：（1）识别现有度量标准的局限性；（2）引入了SiLVERScore进行语义感知评估；（3）展示了其对语义和韵调变异的鲁棒性；（4）探索跨数据集的一般化挑战。在PHOENIX-14T和CSL-Daily数据集上，SiLVERScore在正确和随机配对之间的区分能力接近完美（ROC AUC = 0.99，重叠 < 7%）并显著优于传统度量标准。
### Conclusion
SiLVERScore在评估手语生成方面展示了独特的优势，特别是在克服现有评估方法的局限性方面。
## 222. `cs.CL` - SelfAug: 在检索增强生成中通过分布自我对齐缓解灾难性遗忘 [PDF](https://arxiv.org/pdf/2509.03934), [HTML](https://arxiv.org/abs/2509.03934)
### Authors
Yuqing Huang,Rongyang Zhang,Qimeng Wang,Chengqiang Lu,Yan Gao,Yi Wu,Yao Hu,Xuyang Zhi,Guiquan Liu,Xin Li,Hao Wang,Enhong Chen
### Background
大型语言模型（LLMs）近期的进展极大地改变了自然语言处理领域，尤其是在理解和执行各种任务方面表现出非凡的能力。特别是在检索增强生成（RAG）场景中，监督微调有效提升了任务特定性能，但往往也导致灾难性遗忘，即模型会失去之前学习的知识和通用能力。现有的解决方案要么需要访问通用指令数据，要么在保留模型的原始分布方面存在局限性。
### Innovation
本文提出了一种名为SelfAug的方法，该方法通过将输入序列的logits对齐，以保持模型的语义分布，从而缓解灾难性遗忘并提高下游性能。实验结果表明，SelfAug在下游学习和保留通用能力之间实现了更优的平衡。实验分析还揭示了分布变化与灾难性遗忘严重程度之间的直接关系，强调了在通用指令调整中缺乏RAG能力导致的显著分布变化。
### Conclusion
本文不仅提高了对RAG上下文中灾难性遗忘的理解，还提供了一个适用于各种细调场景的实用解决方案。相关代码已在以下网址公开可用：this https URL.
## 223. `cs.CL` - MTQA：增强复杂问答中推理的矩阵思维 [PDF](https://arxiv.org/pdf/2509.03918), [HTML](https://arxiv.org/abs/2509.03918)
### Authors
Fengxiao Tang,Yufeng Li,Zongzong Wu,Ming Zhao
### Background
复杂问答（QA）是自然语言处理（NLP）中的基础且具有挑战性的工作。尽管大型语言模型（LLMs）在问答任务上表现出色，但在面对复杂的抽象问题时，由于推理能力不足，它们的性能会显著下降。现有方法如 Chain-of-Thought（CoT）和 Tree-of-Thought（ToT）试图增强LLM的推理能力，但存在树结构内的冗余问题和链结构中的单一路径问题。虽然有些研究使用检索增强生成（RAG）方法辅助LLMs推理，但如何有效利用涉及多个实体和复杂路径的大量信息仍然是一项重大挑战。
### Innovation
本文提出了一种新颖且高效的LLM思维结构——矩阵思维（MoT）。MoT通过“列单元通信”机制在水平和垂直两个维度上探索问题，使LLMs能够主动进行多策略和深层次思考，减少了列单元内的冗余并增强了推理能力。此外，本文还开发了一种事实校正机制，通过构造从检索的知识图谱三元组和原始文本中提取的知识单元来增强LLM的初始知识并纠正错误答案。这导致了一个有效且准确的问答框架（MTQA）。
### Conclusion
实验结果显示，本框架在四个广泛使用的数据集上的F1和EM得分上均优于最先进的方法，推理时间仅为基线方法的14.4%，展示了该框架的高效性和准确性。该框架的代码可在此处找到：this https URL。
## 224. `cs.CL` - 大规模语言模型推理中的可信性综述 [PDF](https://arxiv.org/pdf/2509.03871), [HTML](https://arxiv.org/abs/2509.03871)
### Authors
Yanbo Wang,Yongcan Yu,Jian Liang,Ran He
### Background
长上下文推理(Long-CoT)的发展已经提升了各种任务（包括语言理解、复杂问题解决和代码生成）中LLM的性能。这种范式使模型能够产生中间推理步骤，从而提高准确性和可解释性。然而，尽管这些进展，人们对于基于CoT的推理如何影响语言模型的信任度的理解仍然不足。
### Innovation
本文综述了推理模型和CoT技术的最新研究，重点关注五个核心的可信推理方面：真实性、安全性、鲁棒性、公平性和隐私。对于每个方面，提供了一个清晰且结构化的概述，按时间顺序列出并详细分析了相关研究的方法、发现和局限性。同时，也提出了未来研究的方向，以备参考和讨论。
### Conclusion
尽管推理技术有希望通过减少幻觉、检测有害内容和提高鲁棒性来增强模型的信任度，但最新的推理模型在安全、鲁棒性和隐私方面也存在相似或更大的脆弱性。通过综合这些见解，我们希望这份工作能成为AI安全社区了解最新推理可信性进展的重要资源。相关论文列表可以在[这个链接]找到。
## 225. `cs.CL` - 解码韩现代诗歌中的情感语言：人工标注数据和AI建模的见解 [PDF](https://arxiv.org/pdf/2509.03932), [HTML](https://arxiv.org/abs/2509.03932)
### Authors
Iro Lim,Haein Ji,Byungjun Kim
### Background
尽管大型语言模型在基于文本的情感分类方面取得了显著进展，但诗歌尤其是韩诗由于其隐喻语言和文化特定性，仍然被严重忽视。现有研究大多集中在一般文本的情感分类上，忽略了诗歌情感分析的重要性。因此，亟需建立一个专门针对韩诗的情感数据集，以便更好地理解和分析现代韩诗中的情感表达。
### Innovation
本研究引入了KPoEM（韩诗情感映射）数据集，这是一个专门用于现代韩诗情感计算分析的新颖数据集。研究团队构建了一个包含7,662条多标签情感标注的庞大数据集，其中包括来自483首诗歌的7,007行级标注和615首作品级别的标注，标注了来自五位影响深远的韩诗人的情感类别。研究人员使用了在该数据集上进行微调的最先进韩语语言模型，该模型相比训练于通用语料库的模型，F1-micro值提高了0.26，达到了0.60。此外，KPoEM模型通过先在通用语料库上微调，再在KPoEM数据集上微调的方式，展示了识别时间和文化特定情感表达的能力，以及保留现代韩诗核心情感的能力。这为通过结构化数据定量探索诗歌情感提供了新可能性。
### Conclusion
本研究通过建立KPoEM数据集和开发能够有效分析现代韩诗情感的AI模型，将计算方法与文学分析相结合，并展示了通过结构化数据准确保留韩文学情感和文化内涵的新希望。
## 226. `cs.CL` - 通过推理时的知识图构建提高LLM的事实准确性 [PDF](https://arxiv.org/pdf/2509.03540), [HTML](https://arxiv.org/abs/2509.03540)
### Authors
Shanglin Wu,Lihui Liu,Jinho D. Choi,Kai Shu
### Background
大型语言模型（LLMs）在生成事实一致性回答时常常受限于其参数记忆的限制。检索增强生成（RAG）方法通过在推理时引入来自可信来源的外部知识来解决这一问题。然而，现有RAG方法通常将知识视为无结构的文本，这限制了它们支持组合推理和检测不一致性能力。因此，需要一种新方法能够动态构建并扩展知识图，结合内部知识与外部信息来增强LLM的事实准确性。
### Innovation
本文提出了一种新颖的框架，该框架在推理时动态构建并扩展知识图，结合LLM内部知识和外部来源检索的知识，以提高LLMs的事实准确性。该方法首先通过提示提取问题的种子知识图，然后通过LLM的潜在知识迭代扩展图，最后通过外部检索选择性地优化图，增强事实覆盖并纠正错误。通过在三个不同的事实问答基准测试上进行评估，展示了在基线提示方法和静态知识图增强方法上取得的一致改进，包括在事实准确性、答案精确性和解释性方面的提升。
### Conclusion
我们的研究表明，推理时构建知识图是一种有前景的方向，能够在结构化、可解释和可扩展的方式来增强LLM的事实准确性。
## 227. `cs.CL` - VoxRole: 用于评估基于语音的角色扮演代理的全面基准 [PDF](https://arxiv.org/pdf/2509.03940), [HTML](https://arxiv.org/abs/2509.03940)
### Authors
Weihao Wu,Liang Cao,Xinyu Wu,Zhiwei Lin,Rui Niu,Jingbei Li,Zhiyong Wu
### Background
近年来，大规模语言模型（LLMs）取得了显著进展，极大地推动了角色扮演对话代理（RPCAs）的发展。这些系统旨在通过一致的人格表演来创造沉浸式用户体验。然而，当前的RPCA研究存在两个主要限制：第一，现有工作主要集中在文本模态上，完全忽略了语音中的重要内容特征，包括语调、语势和节奏，这些特征对于传达角色情感和塑造鲜明身份至关重要。第二，基于语音的角色扮演领域长期以来缺乏标准化的评估基准。目前大多数语音对话数据集仅针对基础能力评估，且通常不具备详细的或定义明确的角色特征。由于这些数据集无法有效量化模型在长期人格一致性等关键技能上的表现。
### Innovation
为解决这一关键缺口，我们提出了VoxRole，这是一个专门为评估语音角色扮演代理设计的综合性基准。该基准包括13,335个多轮对话，总计65.6小时的来自261部电影中1228个不同角色的语音。为了构建这一资源，我们提出了一种新的两阶段自动化流程，首先将电影音频与脚本对齐，然后使用LLM系统地为每个角色构建多维度的特征画像。利用VoxRole，我们对当前的语音对话模型进行了多维度评估，揭示了它们在维持角色一致性的各自优势和局限性。
### Conclusion
我们的评估结果揭示了当前语音对话模型在维持角色一致性方面存在的关键优势和局限性，为未来的RPCA研究提供了宝贵的见解。通过VoxRole，可以更好地量化和评估模型在语音角色扮演方面的表现，从而促进这一领域的发展。
## 228. `cs.CL` - 通过一个韩语案例研究提升开源大语言模型的基础语言能力 [PDF](https://arxiv.org/pdf/2509.03972), [HTML](https://arxiv.org/abs/2509.03972)
### Authors
Junghwan Lim,Gangwon Jo,Sungmin Lee,Jiyoung Park,Dongseok Kim,Jihwan Kim,Junhyeok Lee,Wai Ting Cheung,Dahye Choi,Kibong Choi,Jaeyeon Huh,Beomgyu Kim,Jangwoong Kim,Taehyun Kim,Haesol Lee,Jeesoo Lee,Dongpin Oh,Changseok Song,Daewon Suh
### Background
文章介绍了Llama-3-Motif，这是一种包含1020亿个参数的语言模型，旨在提高韩语能力的同时保持强大的英语性能。该模型基于Llama 3架构，采用LlamaPro和Masked Structure Growth等高级训练技术，以无损地扩大模型规模。通过MoAI平台进行高效训练，使用精心筛选的韩语和英语混合适配的数据集，优化了Llama-3-Motif，使其在韩语特定基准上表现出色，甚至超过了现有模型，并与GPT-4取得了类似的结果。
### Innovation
Llama-3-Motif采用了LlamaPro和Masked Structure Growth等先进训练技术，成功地在保持其核心Transformer架构不变的情况下扩大了模型规模。Llama-3-Motif在韩语特定基准上的表现优于现有模型，甚至达到了类似于GPT-4的水平。
### Conclusion
Llama-3-Motif作为一种大型语言模型，在保持强大英语性能的同时显著增强了韩语能力，通过精心的训练技术和数据集优化，展示了在开源语言模型领域的一项重要进展。
## 229. `cs.CL` - SPFT-SQL：通过自博弈微调提升大型语言模型的Text-to-SQL解析能力 [PDF](https://arxiv.org/pdf/2509.03937), [HTML](https://arxiv.org/abs/2509.03937)
### Authors
Yuhao Zhang,Shaoming Duan,Jinhang Su,Chuanyi Liu,Peiyi Han
### Background
尽管自博弈微调（SPIN）能够通过不同能力模型之间的竞争性互动，将弱的大型语言模型（LLM）转化为强的模型，但在Text-to-SQL任务中仍然面临挑战。SPIN不能生成新的信息，且对手模型在自博弈过程中生成大量正确SQL查询，降低了主模型生成准确SQL查询的能力。因此，需要一种专门针对Text-to-SQL任务的新自博弈微调方法，以克服这些挑战。
### Innovation
提出了一种新的自博弈微调方法SPFT-SQL，用于Text-to-SQL任务。在自博弈前，采用基于验证的迭代微调方法，基于数据库模式和验证反馈生成高质量的微调数据，提升模型性能并建立不同能力的模型基础。在自博弈微调阶段，提出了一种错误驱动的损失方法，激励对手模型生成错误输出，使主模型区分正确SQL和对手生成的错误SQL，从而提高生成正确SQL的能力。实验结果显示，该方法优于现有最先进的方法。
### Conclusion
我们在六种开源LLM和五个广泛使用的基准上进行了广泛的实验和深入分析，证明了我们的方法在Text-to-SQL任务中优于现有最先进的方法，有效提升了模型生成准确SQL的能力。
## 230. `cs.CL` - 在极度低资源环境中探索NLP基准 [PDF](https://arxiv.org/pdf/2509.03962), [HTML](https://arxiv.org/abs/2509.03962)
### Authors
Ulin Nuha,Adam Jatowt
### Background
大型语言模型（LLMs）在极度低资源语言，如土著语言中的效果有限，主要是因为缺乏标注数据。尽管对这些语言的兴趣在增长，高质量的自然语言处理（NLP）数据集仍然有限，这使得开发稳健的语言技术变得困难。以濒危的罗曼语Ladin为例，该研究聚焦于Val Badia变体，利用有限的Ladin-意大利语平行短语集合，通过翻译单语意大利数据创建用于情感分析和多项选择题问答的合成数据集。为确保语言质量和可靠性，该方法应用了严格的过滤和反向翻译程序。研究结果表明，在机器翻译训练中加入这些合成数据集可以显著提高Ladin-意大利语的翻译基准线性能。
### Innovation
该研究首次创建了Ladin的公开情感分析和多项选择题问答数据集，通过严格的数据处理方法提高了合成数据的质量和可靠性，进一步通过机器翻译培训中加入这些数据集，显著提高了Ladin-意大利语的翻译性能，有助于支持更广泛的NLP研究和该语言的下游应用。
### Conclusion
该研究通过严格的数据筛选和反向翻译方法创建了首个公开的Ladin情感分析和多项选择题问答数据集，这些数据集为基础提供了重要资源，可在更广泛的语言研究和应用中支持未广泛研究的语言Ladin的成功利用。
## 231. `cs.CL` - 基于RoBERTa的功能句法标注模型 [PDF](https://arxiv.org/pdf/2509.04046), [HTML](https://arxiv.org/abs/2509.04046)
### Authors
Han Xiaohui,Zhang Yunlong,Guo Yuxi
### Background
系统功能语法及其分支卡迪夫语法，已经被广泛应用于话语分析、语义功能研究和其他多种任务，对多种语言和文本进行了应用。然而，针对中文文本的基于这一理论的自动标注系统尚未开发，这限制了相关理论的应用和推广。
### Innovation
本研究提出了一个基于RoBERTa的功能句法标注模型，用于中文文本。该研究随机从《人民日报》2014年语料库中选择4100个句子，根据功能句法理论进行标注，建立训练数据集并微调RoBERTa-Chinese wwm-ext模型来执行命名实体识别任务，测试集上的F1分数达到了0.852，显著优于其他对比模型。此模型在识别主语(S)、谓语动词(M)和补语(C)等核心句法元素方面表现优秀。
### Conclusion
作为功能句法与基于注意力的NLP模型首次整合，本研究提供了一种新的自动中文功能句法分析方法，并为后续研究奠定了坚实基础。
## 232. `cs.CL` - 基于音乐理论规则合成乐谱问题以进行评估和强化学习 [PDF](https://arxiv.org/pdf/2509.04059), [HTML](https://arxiv.org/abs/2509.04059)
### Authors
Zhilin Wang,Zhe Yang,Yun Luo,Yafu Li,Haoran Zhang,Runzhe Zhan,Derek F. Wong,Jizhe Zhou,Yu Cheng
### Background
增强大型语言模型（LLMs）和多模态大型语言模型（MLLMs）解释乐谱的能力是构建AI音乐家的重要步骤。然而，现有研究缺乏乐谱推理的评估基准和训练数据。
### Innovation
本文提出了基于音乐理论规则合成乐谱问题的想法，将其用于评估基准和强化学习中可验证奖励（RLVR）的训练数据。作者介绍了一个数据合成框架，生成文本和视觉模态下的可验证乐谱问题，从而构建了合成乐谱推理基准（SSMR-Bench）和配套训练集。Qwen3-8B-Base和Qwen2.5-VL-Instruct利用合成数据在SSMR-Bench上取得了提升，并且增强的推理能力有助于音乐创作。
### Conclusion
本文首次提出基于音乐理论规则合成乐谱问题的想法，并证明了这种方法不仅能够促进乐谱理解模型推理能力的提升，还能够开启AI辅助音乐创作的新可能性。
## 233. `cs.CL` - 阿拉伯教育聊天机器人技术概览 [PDF](https://arxiv.org/pdf/2509.04066), [HTML](https://arxiv.org/abs/2509.04066)
### Authors
Hicham Bourhil,Yacine El Younoussi
### Background
近年来，人工智能（AI）的进展和自然语言处理（NLP）领域，尤其是在教育、医疗、旅游和客户服务等行业中的应用越来越广泛。尤其是在COVID-19疫情期间，这些数字技术的需求增加，以实现远程访问。全球范围内，网上学习系统被广泛采用。大型语言模型（LLM）如BERT和GPT的出现使得聊天机器人更加流行，促使人们对教育领域中的聊天机器人技术进行研究调查。
### Innovation
本文对现有的阿拉伯教育聊天机器人进行了调查，分析了采用方法、语言多样性以及评估性能的指标。发现尽管在其他语言领域，特别是英语，聊天机器人取得了成功，但在阿拉伯语教育领域中，仍然缺乏使用现代技术的聊天机器人。文章还提出了未来研究的方向，填补了研究中的空白，具有一定的创新性。
### Conclusion
研究表明，尽管阿拉伯教育聊天机器人的使用情况有限，但与传统方法相比，它们能够提供更好的功能和交互体验。同时，文章指出了研究中的不足之处，并提出了未来研究的方向，这对于进一步提升聊天机器人的效果和适应不同用户需求具有重要意义。
## 234. `cs.CL` - 通过微调语言模型提高叙事分类和解释 [PDF](https://arxiv.org/pdf/2509.04077), [HTML](https://arxiv.org/abs/2509.04077)
### Authors
Rishit Tyagi,Rahul Bouri,Mohit Gupta
### Background
理解隐蔽叙事和隐含信息对于分析偏见和情感至关重要。传统NLP方法难以检测到微妙的表达和隐藏的议程。这项研究解决了两大关键挑战：(1) 新闻文章中的多标签叙事及其子叙事的分类；(2) 为主导叙事生成简洁且基于证据的解释。
### Innovation
该研究提出了一种基于召回的方法来细调BERT模型，用于全面的叙事检测，并通过GPT-4o流水线优化一致性预测。为此，研究提出了一个结合语义检索的少量示例提示的ReACT框架，以确保解释的扎根性和相关性。此外，通过引入结构化的分类表作为辅助知识库，该研究增强了事实准确性并减少了幻觉。结果表明，将辅助知识融入提示可以提高分类准确性和解释可靠性，并在媒体分析、教育和情报收集方面有应用价值。
### Conclusion
该研究整合了辅助知识提示，显著提高了新闻文章中多标签叙事分类的准确性和解释的一致性，为媒体分析、教育和情报收集提供了新的工具和技术。
## 235. `cs.CL` - 迈向口语人机对话中稳定且个性化的词汇对齐配置文件 [PDF](https://arxiv.org/pdf/2509.04104), [HTML](https://arxiv.org/abs/2509.04104)
### Authors
Keara Schaaij,Roel Boumans,Tibor Bosse,Iris Hendrickx
### Background
词汇对齐，即说话者在对话过程中开始使用相似词汇的现象，被认为有助于成功的沟通。尽管如此，它的在对话代理中的实现仍然未得到充分探索，特别是在考虑大型语言模型（LLMs）的最新进展之后。为了使对话代理能够实现词汇对齐，这项研究借鉴了个性化对话代理的策略，并探讨了构建稳定且个性化的词汇配置文件作为词汇对齐的基础。研究发现，包含5个形容词和连词、10个名词、代词和动词等各类别中各10个项目的较小且紧凑的配置文件，在10分钟的记录对话后，提供了最佳的性能和数据效率平衡。
### Innovation
本研究通过探讨构建稳定且个性化的词汇配置文件，作为实现对话代理中词汇对齐的基础，为对话代理中的词汇对齐策略提供了基础步骤。研究发现，使用10分钟内的记录对话数据中生成的、包含5个形容词和连词、10个名词、代词和动词的更小且更紧凑的配置文件，提供了一种性能与数据效率最佳平衡的方法。这项工作为对话代理技术中的词汇对齐策略提供了实际见解，并考虑了最小数据需求。
### Conclusion
本研究提供了构建稳定且个性化的词汇配置文件的实用见解，确保最少的数据要求，为对话代理中的词汇对齐策略奠定了基础。
## 236. `cs.CL` - 如果用另一种语言提问，是否能得到相似的回答？跨语言功能相似性测量 [PDF](https://arxiv.org/pdf/2509.04032), [HTML](https://arxiv.org/abs/2509.04032)
### Authors
Debangan Mishra,Arihant Rastogi,Agyeya Negi,Shashwat Goel,Ponnurangam Kumaraguru
### Background
本文通过使用最近提出的一种模型相似度度量$?kappa_p$来探讨这个问题，研究了不同语言模型输出的一致性。研究选择了GlobalMMLU中的20种语言和47个主题，评估了模型大小和能力对跨语言输出一致性的影响。研究表明，随着模型规模和能力的增长，模型的响应在同一主题上变得越来越一致。这一研究为多语言系统的开发和评估提供了新的视角和工具。
### Innovation
引入了$?kappa_p$模型相似度度量作为评估多语言一致性的实用工具，并发现相比于其他模型在同一语言中的回答一致性，模型内部的一致性更强。这表明该度量不仅可以用于评估多语言系统的可靠性，还有助于指导开发更一致的多语言系统。
### Conclusion
研究结果不仅突显了$?kappa_p$作为评估多语言一致性的工具的价值，还展现了它指导开发更一致多语言系统的能力。
## 237. `cs.CL` - MultiWikiQA: 超过300种语言的阅读理解基准 [PDF](https://arxiv.org/pdf/2509.04111), [HTML](https://arxiv.org/abs/2509.04111)
### Authors
Dan Saattrup Smart
### Background
当前，阅读理解数据集主要集中在特定的语言或较小的语料库上，缺乏跨越多种语言的广泛研究。MultiWikiQA 数据集旨在填补这一空白，提供了一个覆盖306种语言的阅读理解数据集。该数据集从Wikipedia文章中获取背景信息，通过大规模语言模型（LLM）生成问题，并直接在Wikipedia文章中查找准确答案，以确保数据的一致性和精度。
### Innovation
首先，MultiWikiQA 是一个跨越众多语言（306种）的阅读理解数据集，提供了一个全球多语言阅读理解的标准。其次，使用大规模语言模型自动生成问题，可以有效减轻人工成本和数据偏差。最后，该数据集不仅包含数据集本身，还进行了跨30种语言的人工评判，以确保生成问题的质量。
### Conclusion
MultiWikiQA 研究表明，不同语言的阅读理解能力存在显著差异，这为语言模型的多语言应用提供了更多的研究机会。该数据集和评估结果已被公开，未来的研究可以通过这个数据集进一步探索语言模型的多语言性能和改进方法。
## 238. `cs.CL` - 社交事件检测中的显性与隐性数据增强 [PDF](https://arxiv.org/pdf/2509.04202), [HTML](https://arxiv.org/abs/2509.04202)
### Authors
Congbo Ma,Yuxia Wang,Jia Wu,Jian Yang,Jing Du,Zitai Qiu,Qing Li,Hu Wang,Preslav Nakov
### Background
社交事件检测涉及从社交媒体中识别并分类重要事件，这依赖于标记数据，但标注数据成本高昂且劳动密集。因此，现有的基础模型在面对数据匮乏时表现不佳，需要一种有效的方法来增加数据多样性和增强模型鲁棒性。
### Innovation
本文提出了一种名为SED-Aug的插件式双增强框架，结合了显性文本基和隐性特征空间增强技术，以提高数据多样性和模型鲁棒性。显性增强利用大规模语言模型通过五种不同的生成策略来增强文本信息。隐性增强通过在结构融合嵌入的空间中设计五种新型扰动技术来操作，这些扰动技术旨在保持嵌入的语义和关系属性，从而使其更加多样化。实验结果显示，相较于基线模型，SED-Aug在Twitter2012和Twitter2018数据集上的平均F1分数分别提高了约17.67%和15.57%。
### Conclusion
该研究展示了SED-Aug在社交事件检测中的有效性和优越性，并在公开代码中提供了相关实现，进一步推动了领域内其他研究者对此问题的研究。
## 239. `cs.CL` - CANDY: Benchmarking LLMs' Limitations and Assistive Potential in Chinese Misinformation Fact-Checking [PDF](https://arxiv.org/pdf/2509.03957), [HTML](https://arxiv.org/abs/2509.03957)
### Authors
Ruiling Guo,Xinwei Yang,Chen Huang,Tong Zhang,Yong Hu
### Background
尽管大型语言模型（LLMs）在事实核查错误信息方面越来越受到重视，但其有效性仍然不确定。因此，对此进行系统性的评估非常重要，特别是在中文信息误导的事实核查这一领域。现有的LLMs在生成准确的事实核查结论上存在局限性，即使经过链式推理和少量示例提示的优化也未能显著改善这一问题。因此，需要一个基准来全面评估和理解这些局限性，并探索其作为辅助工具的潜力如何增强人类的表现。
### Innovation
本文介绍了CANDY基准，旨在系统性地评估LLMs在中文错误信息事实核查方面的功能和局限性。CANDY包含一个精心整理的包含约20,000个实例的注释数据集。通过这一基准，研究人员可以识别LLMs在生成事实核查结论时最常见的错误模式——事实捏造。此外，该研究提出了一种类别分类法来归类LLMs生成的错误解释，为进一步研究提供了理论框架。
### Conclusion
尽管现有的LLMs在独立进行错误信息事实核查时不可靠，但将它们作为辅助工具部署在特定场景下可以显著提升人类的表现。研究者进一步提供了可用于评估LLM性能的CANDY数据集和代码，这项工作为未来的研究和实践奠定了基础。
## 240. `cs.CL` - 联合建模实体和话语关系以评估连贯性 [PDF](https://arxiv.org/pdf/2509.04182), [HTML](https://arxiv.org/abs/2509.04182)
### Authors
Wei Liu,Michael Strube
### Background
语言学中的连贯性可以通过多种方式实现，包括维持句子间同一组实体的引用，以及建立它们之间的关系。然而，当前大多数关于连贯性建模的工作仅专注于实体特征或话语关系特征之一，很少有研究同时考虑这两种特征的结合。
### Innovation
研究探索了同时建模实体和话语关系的方法，以评估连贯性。实验结果表明，将这两种类型的特征结合使用可以显著提升连贯性模型的性能，证明了同时建模它们对连贯性评估的好处。
### Conclusion
在三个基准数据集上的实验显示，联合建模实体和话语关系显著提升了连贯性模型的性能，从而突显了在连贯性评估中同时建模这两种类型特征的重要性。
## 241. `cs.CL` - MAGneT: 协同多智能体生成合成多轮心理健康咨询会话 [PDF](https://arxiv.org/pdf/2509.04183), [HTML](https://arxiv.org/abs/2509.04183)
### Authors
Aishik Mandal,Tanmoy Chakraborty,Iryna Gurevych
### Background
随着对可扩展心理咨询服务需求的增长，对高质量且符合隐私要求的数据进行微调的开源大语言模型（LLMs）变得尤为重要，但相关数据仍然稀缺。本文旨在探讨如何使用一种新的多智能体框架来生成合成心理咨询服务会话，以更好地模拟真实咨询的结构和细微差别。
### Innovation
提出了名为MAGneT的新颖多智能体框架，该框架将咨询师回应生成分解为由专业LLM智能体处理的协调子任务，每个智能体模拟一种关键的心理学技术。不同于以前的单智能体方法，MAGneT可以更好地捕捉真实咨询的结构和细微差别。此外，本文还提出了一种新的综合性评估框架，整合了自动评价和专家评价指标，并将专家评价扩大到九个方面，以更全面和严格地评估数据质量。
### Conclusion
实验结果显示，MAGneT在质量、多样性和认知疗法治疗对齐方面显著优于现有方法，平均增强了3.2%的一般咨询技能和4.3%的认知疗法（CTRS）特定技能。在所有方面中，专家认为MAGneT生成的会话有77.2%的偏好。此外，使用MAGneT生成的会话对开源模型进行微调也会有更好的表现，平均而言，在一般咨询技能和认知疗法特定技能上，相对于使用基础方法生成的会话，CTRS得分分别提高了6.3%和7.3%。所有代码和数据都将公开提供。
## 242. `cs.CL` - 关于LLM基准评估的鲁棒性和可靠性 [PDF](https://arxiv.org/pdf/2509.04013), [HTML](https://arxiv.org/abs/2509.04013)
### Authors
Riccardo Lunardi,Vincenzo Della Mea,Stefano Mizzaro,Kevin Roitero
### Background
现有的大型语言模型（LLMs）有效性通常通过MMLU、ARC-C或HellaSwag等基准测试进行评估，这些基准测试中的问题以固定的形式呈现。然而，实际应用涉及到语言的多样性变化，要求模型能够适应不同版本的问题或查询。本文通过系统地生成六个常见基准测试中所有问题的各种改写版本，并评估34种不同大小和效果的最先进LLM的变化效果，研究了LLMs在改写基准问题下的鲁棒性，并探讨了基于基准的评估是否能够可靠地反映模型的能力。研究表明，虽然LLM的排名在改写输入下相对稳定，但其绝对有效性分数会降低，提请人们关注模型的泛化能力和评估方法。此外，观察到的能力下降也质疑了基准评估的可靠性，提示高基准得分可能不能全面反映模型对实际输入变化的鲁棒性。
### Innovation
本文通过系统地生成六个常见基准测试中所有问题的各种改写版本，研究了LLMs在改写基准问题下的鲁棒性，并探讨了基于基准的评估是否能够可靠地反映模型的能力。研究发现，虽然LLM的排名相对稳定，但其绝对有效性分数会显著下降。这表明LLMs对语言多样性的处理能力较弱，引发了对现有评估方法的质疑。此外，研究还提出需要开发能够更好地反映实际部署场景的鲁棒性意识基准测试方法，以提升评估的可靠性。
### Conclusion
本文研究发现，虽然LLM的排名在改写输入下相对稳定，但其绝对有效性分数会显著下降，表明LLMs对语言多样性的处理能力较弱，其评估方法可能存在不足。因此，需要开发鲁棒性意识基准测试方法，以更真实地反映模型在实际应用中的表现。
## 243. `cs.CL` - 语言模型能处理非格里高利历吗？ [PDF](https://arxiv.org/pdf/2509.04432), [HTML](https://arxiv.org/abs/2509.04432)
### Authors
Mutsumi Sasaki,Go Kamoda,Ryosuke Takahashi,Kosuke Sato,Kentaro Inui,Keisuke Sakaguchi,Benjamin Heinzerling
### Background
语言模型（LMs）需要具备时间推理和知识处理能力。尽管已有大量研究分析并改进了LMs的时间推理能力，大部分研究仅关注格里高利历。然而，许多非格里高利历系统，如日本、希吉莱和希伯来历，正被广泛应用，反映了不同文化对时间的认知。目前，这些非格里高利历系统是否能被LMs准确处理尚未进行评估。
### Innovation
本研究首次系统性评估了开放源代码LMs处理一个非格里高利历系统（日本历）的能力。研究创建了四个需要时间知识和时间推理的任务数据集，并评估了多种英语为中心和日语为中心的模型。
### Conclusion
研究结果表明，虽然一些模型可以进行历法转换，但即使是日语为中心的模型，在进行日本历算和跨历法一致性维护时也存在困难。这突显了开发更适应特定文化历法理解的LMs的重要性。
## 244. `cs.CL` - 逆IFEval：大型语言模型能否克服固定化的训练惯例以遵循实际指令？ [PDF](https://arxiv.org/pdf/2509.04292), [HTML](https://arxiv.org/abs/2509.04292)
### Authors
Qinyan Zhang,Xinping Lei,Ruijie Miao,Yu Fu,Haojie Fan,Le Chang,Jiafan Hou,Dingling Zhang,Zhongfei Hou,Ziqiang Yang,Changxin Pu,Fei Hu,Jingkai Liu,Mengyun Liu,Yang Liu,Xiang Gao,Jiaheng Liu,Tong Yang,Zaiyuan Wang,Ge Zhang,Wenhao Huang
### Background
大型语言模型（LLMs）在各种任务上表现强大，但常常表现出认知惰性，难以遵循与其监督微调标准化模式相冲突的指令。本文提出了一项名为“逆IFEval”的基准测试，以评估模型克服训练偏见并遵从反向指令的能力。该基准测试引入了八种类型的挑战，包括问题修正、故意引入文本错误、无注释的代码和反事实回答等。
### Innovation
该研究创新地构建了一个涵盖23个领域、包含1012个高质量中英文问题的数据集，并通过人工监督的流程评估现有顶级LLMs。提出了一个名为逆IFEval的基准测试，用于量化模型克服训练偏见并遵从反向指令的能力。实验结果表明，未来的对齐工作不应仅追求流畅性和事实准确性，还应考虑在非传统情境下的适应性。
### Conclusion
本文的发现强调了在未来的对齐工作中，除了追求流畅性和事实准确性之外，还需要考虑模型在非传统情境下的适应性。希望逆IFEval作为诊断工具和基础，用于开发减少认知惰性、减少对狭窄模式的过度适应，并最终增强LLMs在多样且不可预测的真实世界场景中遵循指令的可靠性的方法。
## 245. `cs.CL` - 基于方案表示的神经符号推理系统初步研究 [PDF](https://arxiv.org/pdf/2509.03644), [HTML](https://arxiv.org/abs/2509.03644)
### Authors
François Olivier,Zied Bouraoui
### Background
尽管自然语言理解取得了显著进展，但大型语言模型（LLMs）在进行逻辑推理时仍易出错，缺乏支撑人类理解能力的稳健心理表征。本文探讨了通过图像模式（源自运动知觉体验的反复出现的模式，结构化了人类认知）来构建嵌入式认知结构的方法。
### Innovation
提出了一个名为Embodied-LM的神经符号原型系统，该系统基于图像模式进行理解和逻辑推理。通过使用答案集编程中的声明性空间推理，该系统将这些认知结构的空间基础转化为可执行程序，进而支持更有效的逻辑推理，且具有更强的可解释性。当前实施主要关注空间原语，但为更复杂和动态的表示提供了计算基础。
### Conclusion
通过逻辑推理问题的评估，证明了LLMs可以通过嵌入式认知结构来理解和解释场景，这些结构可以被形式化为可执行程序，从而通过增强的可解释性支持有效的逻辑推理。
## 246. `cs.CL` - 因果ARC：基于因果世界模型的抽象推理 [PDF](https://arxiv.org/pdf/2509.03636), [HTML](https://arxiv.org/abs/2509.03636)
### Authors
Jacqueline Maasch,John Kalantari,Kia Khezeli
### Background
在有限数据和分布转移的情况下，推理需要适应新的问题设置。本文提出的CausalARC是一个实验测试平台，用于AI在低数据和边缘分布条件下的推理，它以抽象和推理语料库（ARC）为基础进行建模。每个CausalARC推理任务都来源于全面指定的因果世界模型，并以结构因果模型的形式正式表达。有原则的数据增强可以提供关于世界模型的观察性、干预性和反事实反馈，这种反馈以少量-shot、上下文学习示例的形式呈现。
### Innovation
CausalARC是一种模拟因果世界模型的实验测试床，用于AI在有限数据和分布转移条件下的推理。它通过在测试时进行训练、基于上下文学习进行反事实推理、程序合成以及因果发现与逻辑推理等四种方式进行语言模型评估。
### Conclusion
CausalARC提供了一种新的方法来评估AI在有限数据和分布转移条件下的推理能力，具体应用包括抽象推理、反事实推理、程序合成以及因果发现与逻辑推理。
## 247. `cs.CL` - 事实迅速褪色：大型语言模型记住过时医疗知识的评估 [PDF](https://arxiv.org/pdf/2509.04304), [HTML](https://arxiv.org/abs/2509.04304)
### Authors
Juraj Vladika,Mahdi Dhaini,Florian Matthes
### Background
大型语言模型（LLMs）的能力不断增强，显示出在医疗健康领域辅助医学研究者和医生的潜力。然而，它们依赖静态训练数据的问题在医疗建议不断更新时成为一个主要风险。当LLMs记住过时的医疗知识时，它们可能会提供有害建议或在临床推理任务中失败。为探究这个问题，作者引入了两个从系统性评价中派生的问答（QA）数据集：MedRevQA（涵盖一般生物医学知识的16,501个QA对）和MedChangeQA（包含医疗共识随时间发生变化的512对QA子集）。
### Innovation
作者提出了两个新的问答数据集，MedRevQA和MedChangeQA，分别用于评估LLMs在保留一般生物医学知识和跟踪医疗共识变化方面的表现。此外，作者分析了过时的预训练数据和训练策略对这一现象的影响，并提出了未来改进方向，为开发更准确可靠的医疗AI系统奠定了基础。
### Conclusion
对八种流行的LLMs进行评估结果显示，所有模型都存在依赖过时知识的问题。作者进一步分析了旧的预训练数据和训练策略的影响，并提出了未来的研究方向，旨在促进开发出更具时代表现的医疗AI系统。
## 248. `cs.CL` - 测量偏差还是测量任务：理解LLM性别偏差的脆弱性质 [PDF](https://arxiv.org/pdf/2509.04373), [HTML](https://arxiv.org/abs/2509.04373)
### Authors
Bufan Gao,Elisa Kreiss
### Background
随着大语言模型（LLMs）在社会影响较大的应用场景中的不断普及，性别偏见的问题引起了广泛的关注。为了应对这一问题，研究人员和开发者们投入了大量精力来测量和减轻这种偏见。通常，这些测量着重于特定评价任务，这些任务往往需要用精心设计的任务提示来突出显示或间接显示性别偏见相关的内容。本研究探讨了提示性内容对LLM测量性别偏见的影响，旨在理解这种测量方法的脆弱性及其对LLM性能的影响。
### Innovation
本研究的创新点在于首次系统性地检验了评价任务的目的标记如何显著改变LLM测得的性别偏见，即使很小的提示变化也能导致倾向性结果的大幅转变甚至完全逆转。此外，通过比较基于词概率和离散选择两种度量方法，研究进一步发现了这种变化的敏感性，并提出了在未来基准测试中控制测试设计的必要性及意义。
### Conclusion
研究揭示了LLM性别偏见评估的脆弱性，表明即使小的提示改变也会极大地影响偏见评估的方向。使用离散选择度量方法更容易放大偏见效应，有助于识别更多潜在的性能变动。本研究为自然语言处理（NLP）基准测试和发展社区提供了新的研究视角，强调了未来评测设计需要高度控制潜在影响，以提高评测结果的生态有效性和可靠性。
## 249. `cs.CL` - 通过强化学习在大语言模型中 emergent 分层推理 [PDF](https://arxiv.org/pdf/2509.03646), [HTML](https://arxiv.org/abs/2509.03646)
### Authors
Haozhe Wang,Qixin Xu,Che Liu,Junhong Wu,Fangzhen Lin,Wenhu Chen
### Background
强化学习 (RL) 已经证明对增强大语言模型 (LLMs) 的复杂推理能力非常有效，但其背后机制仍然很大程度上是透明的。研究揭示，如“恍然大悟”的时刻、“长度缩放”现象和熵动态等令人困惑的现象并非孤立发生，而是分层推理的一种标志，类似于人类认知中高层次的策略规划与低层次的程序执行的分离。研究指出模型经历了一个两阶段动态过程：初始阶段，模型受限于程序上的正确性，需要提升其低层次技能；然后学习瓶颈明显改变，以高层次策略规划的探索和掌握为主导，从而推动性能的提升。这种洞察表明，现有的 RL 算法（如 GRPO）缺乏识别与优化高影响力规划token的能力，这意味着它们稀释了学习信号。
### Innovation
提出一种新的算法 HIerarchy-Aware Credit Assignment (HICRA)，该算法集中优化努力在高影响规划token上。实验表明，HICRA 明显优于现有基准，证明关注这一策略瓶颈是解锁高级推理的关键。此外，研究通过验证语义熵作为战略探索的更优衡量指标，进一步证明了HICRA的有效性。
### Conclusion
通过强化学习，大语言模型中出现了一种分层推理能力，这并不是随机发生的现象，而是有其结构化的动因和过程。通过专注于高层次的策略规划学习，可以显著改善模型的性能。HICRA算法能够更有效地指导这种学习过程，从而显著提升模型的表现。
## 250. `cs.CL` - PARCO: 音素增强的鲁棒上下文ASR通过对比实体去模糊 [PDF](https://arxiv.org/pdf/2509.04357), [HTML](https://arxiv.org/abs/2509.04357)
### Authors
Jiajun He,Naoki Sawada,Koichi Miyazaki,Tomoki Toda
### Background
自动语音识别(ASR)系统在特定领域中的命名实体识别上存在困难，尤其是在处理同音词时更为明显。虽然上下文ASR可以提高识别精度，但由于缺乏多样性的实体数据，往往难以捕捉到细微的音素变化。此外，先前的方法将实体视为独立的令牌，导致多令牌偏置不完整。这些问题使得现有的ASR方法难以在复杂和多样化的实际应用场景中表现出色。
### Innovation
该论文提出了PARCO（Phoneme-Augmented Robust Contextual ASR via Contrastive entity disambiguation），它通过整合音素感知编码、对比实体去模糊、实体级监督和层级实体过滤，增强了语音特征的区分能力。该方法确保了实体检索的完整性，并在不确定性情况下减少了误报。实验证明，与基线方法相比，在 Chinese AISHELL-1 和 English DATA2 上，PARCO 的 CER（字符错误率）为 4.22%，WER（词错误率）为 11.14%，在 1,000 个干扰者下表现大幅优于基线。并且在 THCHS-30 和 LibriSpeech 等域外数据集上也表现出鲁棒性优势。
### Conclusion
PARCO 在汉语和英语数据集中的表现显著优于基线方法，并且在多个域外数据集上也表现出鲁棒性的提升，证明了该方法在处理领域特定命名实体和同音词方面的有效性。
## 251. `cs.CL` - LLM人格幻象：揭示LLM自我报告与行为之间的脱节 [PDF](https://arxiv.org/pdf/2509.03730), [HTML](https://arxiv.org/abs/2509.03730)
### Authors
Pengrui Han,Rafal Kocielnik,Peiyang Song,Ramit Debnath,Dean Mobbs,Anima Anandkumar,R. Michael Alvarez
### Background
人格特质一直被用作人类行为预测的变量。近年来，大规模语言模型（LLMs）的发展表明，这些模型可能会表现出类似的人格趋势，例如一致性的人类特质倾向。然而，先前的研究主要依赖简化自述报告和启发式提示，缺乏行为验证，这对于理解这种趋势的真实性尤为重要。因此，系统地捕捉LLM的人格特征是一个重要的研究方向，涵盖了动态特征表达、自我报告特质的预测及干预措施对行为的影响等方面。
### Innovation
本研究通过三个方面对LLM的人格特征进行了系统研究：1）训练阶段动态特征表达和演变；2）自我报告特质在行为任务中的预测有效性；3）目标干预（如角色注入）对自我报告和行为的影响。主要发现是教学对齐（例如RLHF、指令微调）能显著稳定特质表达和增强特质间的关联性，但自我报告的特质并不能可靠地预测行为，观察到的行为模式与人类有所不同。角色注入能够引导自我报告的方向，但对实际行为的影响不明显或不一致。这项研究揭示了表面特征表达和行为一致性之间的差异，挑战了LLM人格特征的假设，强调了更深入的对齐性和解释性评估的必要性。
### Conclusion
通过区分表面特征表达和行为一致性，本研究为LLM的人格特征提供了新的洞见，并强调了在对齐和解释性评估方面的深入评价的重要性。
## 252. `cs.CL` - 健康领域 adversarial 证据对检索增强生成鲁棒性的评估 [PDF](https://arxiv.org/pdf/2509.03787), [HTML](https://arxiv.org/abs/2509.03787)
### Authors
Shakiba Amirshahi,Amin Bigdeli,Charles L. A. Clarke,Amira Ghenai
### Background
检索增强生成（RAG）系统通过提供检索到的证据或背景信息来为大型语言模型（LLM）的事实依据提供支持，这有助于减少幻觉并扩大其回答范围。然而，这一设计引入了一个关键的漏洞：模型可能会吸收并复制存在于检索证据中的错误信息，尤其是在检索证据包含了旨在传播误导信息的恶意材料时，这一问题更为严重。研究者们选择在健康领域进行系统性评估，因为错误的回答可能导致严重的危害，并且由于存在大量的证据基于的正确答案，因此健康领域是理想的评估对象。
### Innovation
该论文首次对健康领域的RAG系统的鲁棒性进行了系统性评估，重点关注不同类型和结构的检索文档对模型输出准确性的影响。通过控制实验的方式，评估了不同提问方式和证据类型对RAG系统性能的影响，揭示了对抗性文档对系统性能的显著负面影响，但同时也指出在检索池中同时存在有益证据的情况下，系统鲁棒性可以被保存。
### Conclusion
实验结果表明，对抗性文档显著降低了模型输出与真实答案的一致性，但通过确保检索池中也包含有益证据，可以维持系统的鲁棒性。这一发现为设计高风险领域的更安全RAG系统提供了实际指导，强调了检索安全措施的重要性。为促进未来研究的可重复性和发展，所有实验结果已在GitHub仓库中公开共享。
## 253. `cs.CL` - CoT-Space: 通过强化学习实现内部慢思考的理论框架 [PDF](https://arxiv.org/pdf/2509.04027), [HTML](https://arxiv.org/abs/2509.04027)
### Authors
Zeyu Gan,Hao Yi,Yong Liu
### Background
强化学习（RL）在提升大型语言模型（LLMs）的推理能力方面发挥了关键作用。然而，传统基于令牌级别的RL框架无法与复杂多步骤思维过程（如链式思维）的推理级别相匹配，这表明存在重要的理论缺口。
### Innovation
本文引入了CoT-Space，这是一种新的理论框架，将LLM的推理从离散的令牌预测任务重新定义为在连续的推理级别语义空间内的优化过程。通过从噪声和风险的角度分析这一过程，表明最优CoT长度的收敛是过度拟合和欠拟合基本权衡的自然结果。此外，通过大量实验提供了对理论发现的有力实证验证。
### Conclusion
我们的框架不仅为诸如过度思考等经验现象提供了统一的解释，还为更有效的和通用化的推理代理的发展提供了坚实的基础理论指导。
## 254. `cs.CL` - 使用时间图实现烹饪程序的行动中心化本体 [PDF](https://arxiv.org/pdf/2509.04159), [HTML](https://arxiv.org/abs/2509.04159)
### Authors
Aarush Kumbhakern,Saransh Kumar Gupta,Lipika Dey,Partha Pratim Das
### Background
烹饪程序的建模因其固有的复杂性和模糊性而颇具挑战性。现有的方法难以精确描述烹饪流程中的各种细节，如处理、转移、环境、并发性和组合结构。
### Innovation
本文提出了一种扩展领域特定语言，用于以有向行动图的方式表示食谱，能够捕捉烹饪流程中的所有关键方面。该方法使复杂烹饪工作流程的精确、模块化建模成为可能。初步的手动评估表明，此DSL具有高度表达能力和未来自动食谱分析和执行的适用性。
### Conclusion
这标志着通往烹饪行动中心化本体的重要一步，通过使用时间图来实现烹饪过程的结构化机器理解、精确解读和能够扩展的自动化 - 不仅在家庭厨房，也应用在专业烹饪环境中。
## 255. `cs.CL` - Singular Value Few-shot Adaptation of Vision-Language Models [PDF](https://arxiv.org/pdf/2509.03740), [HTML](https://arxiv.org/abs/2509.03740)
### Authors
Taha Koleilat,Hassan Rivaz,Yiming Xiao
### Background
视觉-语言模型（VLMs）如CLIP展现了跨多种应用领域的零样本和少样本学习能力。然而，这些模型适应新的精细粒度领域仍存在困难，这主要是因为依赖于提示工程和全模型微调的高昂成本。现有的适应方法依赖于增强组件，如提示令牌和适配器模块，这些组件可能会限制适应质量，导致模型不稳定，并损害预训练过程中学到的丰富知识。
### Innovation
提出了一种名为CLIP-SVD的新颖的多模态且参数高效的适应技术，通过奇异值分解（SVD）修改CLIP的内部参数空间，而不引入额外的模块。具体而言，仅对CLIP参数矩阵的奇异值进行微调以重新缩放基向量进行领域适应，同时保留预训练模型。这种方法使得使用模型总参数的0.04%就能实现增强的适应性能，并能更好地保持其泛化能力。
### Conclusion
CLIP-SVD在11个自然和10个生物医学数据集上取得了当前最先进的分类效果，超越了以往方法的准确性和泛化能力表现，在少样本设置下效果更佳。此外，利用基于自然语言的方法分析CLIP适应的有效性和动态，以实现CLIP-SVD的可解释性。代码已公开发布。
## 256. `cs.CL` - NER Retriever: 基于类型感知嵌入的零样本命名实体检索 [PDF](https://arxiv.org/pdf/2509.04011), [HTML](https://arxiv.org/abs/2509.04011)
### Authors
Or Shachar,Uri Katz,Yoav Goldberg,Oren Glickman
### Background
在即席命名实体检索（Ad-hoc NER）中，感兴趣的实体类型不会提前给出，而是一种基于用户定义的开放描述来检索提及此类实体的文档的需求。现有的方法通常依赖于固定模式或微调模型，但本文提出的方法基于大型语言模型（LLMs）的内部表示来嵌入实体提及和用户提供的开放描述，将其嵌入到共享的语义空间。这表明内部表示，特别是中间层变换器块的价值向量，比常用顶层嵌入更有效地编码细粒度的类型信息。
### Innovation
本文介绍了一种名为NER Retriever的检索框架，用于即席命名实体检索任务，无需提供实体类型，而是通过用户自定义类型描述进行检索。提出的方法利用大型语言模型的内部表示来嵌入实体提及和用户提供的开放描述，并通过训练一个轻量级对比投影网络来精炼这些表示，从而实现类型感知嵌入，适用于最近邻搜索。并且该方法显著优于词法和密集句子级的检索基线，为大型语言模型内部表示选择提供了实证支持，证明了一种可扩展的无模式实体检索的实用解决方案。
### Conclusion
通过在三个基准上的评估，NER Retriever方法在即席命名实体检索中表现出色，优于词法和密集句子级的检索基线，证明了大型语言模型内部表示选择的有效性，并提供了一种可扩展的、无模式的实体检索的实用解决方案。该方法的代码已公开发布。
## 257. `cs.CL` - 跨物种界限：从语音到动物声音的迁移学习 [PDF](https://arxiv.org/pdf/2509.04166), [HTML](https://arxiv.org/abs/2509.04166)
### Authors
Jules Cauzinille,Marius Miron,Olivier Pietquin,Masato Hagiwara,Ricard Marxer,Arnaud Rey,Benoit Favre
### Background
自监督语音模型在语音处理任务中表现出令人印象深刻的性能，但它们在非语音数据上的有效性尚未得到充分探索。本文研究了这些模型在生物声学检测和分类任务上的迁移学习能力。研究表明，诸如HuBERT、WavLM和XEUS等模型能够产生涵盖不同种类的动物声音的丰富潜在表示。通过线性探测对时间平均表示进行分析，并将其扩展以考虑时间信息，研究频率范围和噪声对性能的影响。这些实验结果展现了自监督学习在生物声学研究中的巨大潜力，特别是在噪声鲁棒预训练设置方面非常有效。
### Innovation
本文创新地研究了自监督语音模型在生物声学检测和分类任务上的迁移学习能力，展示了自监督学习在生物声学研究中的优势。通过时间信息建模，提升了模型对噪声和频段变化的鲁棒性，所得结果与微调的生物声学预训练模型具有竞争力。
### Conclusion
本文的研究结果表明，基于语音的自监督学习框架在促进生物声学研究方面具有高效性和广阔潜力，并且强调了训练过程中噪声鲁棒性的重要性。
## 258. `cs.CL` - 基于上下文的标记区分方法在语音搜索查询纠错中的应用 [PDF](https://arxiv.org/pdf/2509.04393), [HTML](https://arxiv.org/abs/2509.04393)
### Authors
Junyu Lu,Di Jiang,Mengze Hong,Victor Junqiu Wei,Qintian Guo,Zhiyang Su
### Background
随着自动语音识别（ASR）系统的普及，语音搜索变得越来越流行。由于用户输入的查询可能存在拼写错误，因此查询拼写纠错是现代搜索引擎的重要功能之一，能够有效帮助用户明确表达意图。本文研究了针对语音搜索查询的拼写纠错方法。
### Innovation
本文提出了一种名为上下文区分标记法（CTD）的新方法，用于有效的语音查询纠错。CTD方法首先利用BERT生成标记级的上下文表示，然后构建一个组成部分层来增强语义信息，最后根据聚合的标记表示生成正确的查询，通过比较原始标记表示和上下文表示纠正错误的标记。
### Conclusion
大量实验结果表明，本文提出的方法在所有指标上均表现出优越的性能，并进一步提出了一个新的基准数据集，包含了错误的ASR转录，为语音查询纠错提供了全面的评估。
## 259. `cs.CL` - Promptception：大规模多模态模型对提示有多敏感？ [PDF](https://arxiv.org/pdf/2509.03986), [HTML](https://arxiv.org/abs/2509.03986)
### Authors
Mohamed Insaf Ismithdeen,Muhammad Uzair Khattak,Salman Khan
### Background
尽管近年来大型多模态模型（LMMs）在多项选择问题回答（MCQA）中的表现取得了成功，但LMMs的提示设计仍然缺乏明确的指导。提示的细微变化可能导致特定提示和模型之间的准确率偏差高达15%。这种可变性给透明和公平的LMM评估带来了挑战，因为模型通常会使用精心选择的提示来报告其最佳性能。
### Innovation
本文引入了Promptception，这是一种系统框架，用于评估LMMs的提示敏感性，它包含了61种提示类型，涵盖了15个类别和6个超类别，每种类型针对特定的提示设计方面。Promptception用于评估10种LMMs，从轻量级开源模型到GPT-4o和Gemini 1.5 Pro，并横跨3个MCQA基准：MMStar，MMMU-Pro，MVBench。研究发现，专有模型对提示表达更为敏感，反映出更紧密的指令语义对齐，而开源模型则较为稳定，但难以处理细腻且复杂的设计。基于此分析，提出了针对专有和开源LMMs的提示原则，以实现更稳健和公平的模型评估。
### Conclusion
研究揭示了LMMs对提示表达的高度敏感性，特别是专有模型和开源模型之间的差异。这促使提出了有针对性的提示原则，有助于提高模型评估的透明性和公平性。
## 260. `cs.CL` - SPECS：增强特定性的CLIP分数在长图像描述评估中的应用 [PDF](https://arxiv.org/pdf/2509.03897), [HTML](https://arxiv.org/abs/2509.03897)
### Authors
Xiaofu Chen,Israfel Salazar,Yova Kementchedjhieva
### Background
随着生成长而详细的图像描述的兴趣增加，标准评估指标变得越来越不可靠。虽然基于N-gram的评价指标虽然高效，但无法捕捉语义准确性。代表相似性（RS）指标旨在解决这一问题，但由于计算成本高，起初使用率有限，即便是今天硬件有了进步，这些指标仍然不受欢迎，因为它们与人类判断的关联度低。同时，基于大型语言模型（LLMs）的评价指标虽然与人类判断高度相关，但在模型开发过程中仍然成本过高，无法进行迭代评估。
### Innovation
我们引入了SPECS（特定性增强CLIPScore），这是一种为长图像描述定制的无参考RS指标。SPECS通过修改CLIP并加入新的目标来强调特定性：奖励正确的细节并惩罚错误的描述。结果显示，SPECS在评估与人类判断的相关性方面与开源的LLM指标相当，但效率更高，从而成为图像描述模型开发周期评估中一个实用的替代方案。SPECS代码可以在这里找到：[此链接](https://github.com/example-specs-code/tree/main/SPECS).
### Conclusion
SPECS通过增强特定性来提高长图像描述评估的准确性，在保持与人类判断相关性的同时提高了效率，为图像描述模型开发过程中提供了有效的迭代评估工具。
## 261. `cs.CL` - 心理增强的AI代理 [PDF](https://arxiv.org/pdf/2509.04343), [HTML](https://arxiv.org/abs/2509.04343)
### Authors
Maciej Besta,Shriram Chandran,Robert Gerstenberger,Mathis Lindner,Marcin Chrapek,Sebastian Hermann Martschat,Taraneh Ghandi,Patrick Iff,Hubert Niewiadomski,Piotr Nyczyk,Jürgen Müller,Torsten Hoefler
### Background
本文介绍了MBTI-in-Thoughts框架，通过基于心理的个性调整来提升大型语言模型代理的有效性。该框架借鉴了迈尔斯布里格斯类型指标（MBTI），通过提示工程引导代理具有不同的心理角色，从而在认知和情感这两个人类心理的基本轴上控制行为。研究显示，这种个性引导能够使情感表达的代理在叙事生成中表现出色，而分析性引导的代理则在博弈论环境中采用更为稳定的战略。此外，该框架支持实验性多代理沟通协议，并表明在互动前进行自我反思可以提高合作和推理质量。
### Innovation
提出了MBTI-in-Thoughts框架，通过心理个性调整来改变大型语言模型代理的行为，能够在认知和情感方面控制代理，从而在不同的任务中获得一致性和可解释性的情感偏好。同时，框架还支持结构化多代理沟通，并展示了自我反思可以提高合作和推理的质量。
### Conclusion
通过将心理理论与大型语言模型的行为设计相结合，建立了一种无需微调的心理增强型AI代理的基础框架，展示了该方法对其他心理框架（如大五人格、HEXACO或伊涅格拉姆）的有效性。
## 262. `cs.CL` - LibriQuote: 用于表达性零样本语音合成的虚构角色言语文本 [PDF](https://arxiv.org/pdf/2509.04072), [HTML](https://arxiv.org/abs/2509.04072)
### Authors
Gaspard Michel,Elena V. Epure,Christophe Cerisara
### Background
文本到语音（TTS）系统已通过扩大数据集来实现更富有表现力和自然的语音合成。然而，大型数据集中富有表现力的语音比例往往不清楚。现有的富有表现力的语音数据集规模较小，主要用于评估TTS系统的性能。
### Innovation
介绍了LibriQuote数据集，这是一个基于阅读有声书的英语语料库，旨在用于微调和评估零样本表达性TTS系统。该数据集包括12.7千小时的非表现性语音和5.3千小时的表现性语音，以及伴随的上下文、拟标签以及描述台词的动词和副词。此外，还提供了一个具有挑战性的7.5小时测试集，用于评估TTS系统的性能，以生成表现性强且保留参考语音色彩的语音。为了验证测试集的有效性，表明它含有多种情感和口音。广泛的主观和客观评估表明，基于LibriQuote微调基础TTS系统显著改善了合成语音的可理解性，而最新系统未能合成与实际台词一样富有表现力和自然的语音。
### Conclusion
该数据集和评估代码已免费提供，语音样本可在指定链接中找到。
## 263. `cs.CL` - 自适应数据集构造用于真实世界多模态安全场景 [PDF](https://arxiv.org/pdf/2509.04403), [HTML](https://arxiv.org/abs/2509.04403)
### Authors
Jingen Qu,Lijun Li,Bo Zhang,Yichen Yan,Jing Shao
### Background
随着多模态大规模语言模型（MLLMs）的快速发展，其安全挑战越来越复杂。当前的数据集构建方法侧重风险，无法覆盖现实世界多模态安全场景（RMS）的复杂性。由于缺乏统一的安全评估标准，现有方法的有效性未被验证。
### Innovation
本文提出了一种基于图像的自适应数据集构建方法来处理RMS，这种方法从图像开始，并最终构建出配对的文字和指南响应。使用基于图像的方法，自动生成了包含35,000个图文字对的数据集，并引入了一个标准化的安全数据集评估标准：在安全法官模型上进行微调，并在其他安全任务上评估其能力。实验表明提出的图像导向管道的有效性和扩展性。
### Conclusion
实验结果证实了图像导向方法的可行性和有效性，为构建实际世界多模态安全数据集提供了新的视角。
## 264. `cs.CL` - 朝向大型语言模型后训练统一视角 [PDF](https://arxiv.org/pdf/2509.04419), [HTML](https://arxiv.org/abs/2509.04419)
### Authors
Xingtai Lv,Yuxin Zuo,Youbang Sun,Hongyi Liu,Yuntian Wei,Zhekai Chen,Lixuan He,Xuekai Zhu,Kaiyan Zhang,Bingning Wang,Ning Ding,Bowen Zhou
### Background
两大训练数据源用于现代语言模型的后训练：在线的模型生成数据与离线的人类或模型演示数据。现有的方法通常将这些数据分别用于强化学习（RL）和监督微调（SFT），但文章指出这两种方法并非矛盾，而是单个优化过程的不同实例。文章研究通过共同目标函数下的不同数据分布假设和各种偏差-方差折衷来解释一段广泛的后训练方法，并提出了统一的策略梯度估计器。
### Innovation
文章提出了一种统一的策略梯度估计器，并通过分析各种后训练方法作为共同目标函数的梯度得出结论。文章还提出了Hybrid Post-Training (HPT)，一种动态选择不同训练信号的算法，旨在有效利用演示，同时保持探索的稳定性，不必牺牲学习到的推理论证模式。HPT 在多个数学推理基准和泛化测试套件中表现出色，优于多种基线模型。
### Conclusion
研究表明，现有的不同后训练方法可以统一到一个共同目标的单一优化过程之下。提出的Hybrid Post-Training (HPT)算法在多个语言和规模的模型基准测试中表现出色，特别是在利用演示数据进行有效利用及保持探索稳定性方面表现出优越性。
## 265. `cs.CL` - 探索土耳其文本可读性的语言特征 [PDF](https://arxiv.org/pdf/2306.03774), [HTML](https://arxiv.org/abs/2306.03774)
### Authors
Ahmet Yavuz Uluslu,Gerold Schneider
### Background
该论文是首个全面研究土耳其文本自动可读性评估的研究。研究者们结合最先进的神经网络模型和词汇、形态、句法和话语等层面的语言特征，开发了一个先进的可读性评估工具。同时，研究还评估了传统可读性公式与现代自动化方法的有效性，并确定了决定土耳其文本可读性的关键语言特征。
### Innovation
该研究结合了最先进的神经网络模型和多层次语言特征，首次全面研究了土耳其文本的自动可读性评估。通过对比传统方法和现代自动化方法，识别出关键的语言特征。
### Conclusion
研究展示了传统可读性公式与现代自动化方法的效果差异，并指出了影响土耳其文本可读性的关键语言特征，为进一步优化可读性评估工具提供了新的视角。
## 266. `cs.CL` - Delta Activations: 一种适应微调大型语言模型的表示方法 [PDF](https://arxiv.org/pdf/2509.04442), [HTML](https://arxiv.org/abs/2509.04442)
### Authors
Zhiqiu Xu,Amish Sethi,Mayur Naik,Ser-Nam Lim
### Background
强大的开源大型语言模型的成功使社区能够创建出适应特定任务和领域的大量元模型。然而，用户在浏览和理解这些模型时仍然面临挑战，因为存在不一致的元数据和无结构的存储库。
### Innovation
介绍了Delta Activations，这是一种通过测量微调模型相对于基模型的内部激活变化来表示微调模型为向量嵌入的方法。这种方法能够通过领域和任务对模型进行有效的聚类，揭示了模型的结构。此外，Delta Activations具有跨微调设置的鲁棒性和混合微调数据集时的加性特性。另展示了通过少样本微调嵌入任务和探索其用于模型选择和合并的方法。
### Conclusion
希望Delta Activations能够促进公共可用模型的重用实践。代码可通过此链接获取：this https URL
## 267. `cs.CL` - 无思维只有AI：偏见的LLM推荐限制了简历筛选中的人类自主权 [PDF](https://arxiv.org/pdf/2509.04404), [HTML](https://arxiv.org/abs/2509.04404)
### Authors
Kyra Wilson,Mattea Sim,Anna-Maria Gueorguieva,Aylin Caliskan
### Background
该研究通过一项涉及528人的简历筛选实验证明了当人们在评估16种高、低地位职业的候选人时与模拟AI模型合作，而这些AI模型表现出基于种族的偏好（偏见）时的人类行为。该实验探讨了人类在面对不同种族候选人的隐性关联和偏见行为，以及在没有AI、AI无偏见或AI有偏见的情况下进行决策时的行为差异。研究还发现，即使人们认为AI的推荐质量低或不重要，但在某些情况下他们的决策仍然会受到AI偏见的影响。这项研究为理解人工智能和人类决策之间的互动提供了重要的背景信息。
### Innovation
该研究首次将隐性关联测试(IATs)应用于人类与AI协作的招聘决策场景，并揭示了在不同情境下人类与AI协同工作时的行为偏差。研究通过大规模实验数据展示了在AI偏见存在的情况下，人们倾向于偏好特定种族的候选人，即使在他们认为AI的推荐质量不高的情况下，这种偏见也可能会影响他们的决策。此外，该研究发现完成隐性关联测试可以部分减少这种偏见，但这种影响有限。
### Conclusion
该研究得出结论，当人们在使用AI技术辅助决策时，人类的自主权会受到限制，特别是在AI存在偏见的情况下。组织和监管政策应考虑这一复杂性，并在实施AI-HITL系统、培训使用者和确定需要监管的对象时采取相应策略。该研究也为设计和评估AI招聘系统以及减小偏见在协作决策任务中的影响提供了重要建议。
## 268. `cs.CL` - MyProfessors: 开掘土耳其学生评价 [PDF](https://arxiv.org/pdf/2109.02325), [HTML](https://arxiv.org/abs/2109.02325)
### Authors
Ibrahim Faruk Ceylan,Necmettin Bera Calik
### Background
目前市场上缺乏针对土耳其语言的学生评价数据集，这限制了对于相关教育评价的研究。已有的一些研究通常受限于数据量不大或语言限制，无法全面了解学生对于教师的评价情况。
### Innovation
本文介绍了Hocalarim (MyProfessors)，这是首个针对土耳其语言的最大规模学生评价数据集。它收集了超过5000份学生留下的教师评价，涵盖教育的各个方面，并以星级评价进行量化。研究还探讨了评价之间的相关性，包括不同类型大学学生评价的影响因素及其趋向性。
### Conclusion
本文揭示了不同类型大学学生对教师评价的差异，并讨论了学生偏见对评价倾向性的影响。这一研究不仅丰富了土耳其教育评价领域的数据资源，也提供了研究教育反馈机制的新视角。
## 269. `cs.CL` - ArcMemo: 使用终身LLM记忆的抽象推理组合 [PDF](https://arxiv.org/pdf/2509.04439), [HTML](https://arxiv.org/abs/2509.04439)
### Authors
Matthew Ho,Chen Si,Zhaoxiang Feng,Fangxu Yu,Zhijian Liu,Zhiting Hu,Lianhui Qin
### Background
推理时的缩放使大型语言模型能够执行更长且更复杂的心算过程，但在每次查询完成后，这些发现会被立即丢弃。附加记忆是一种自然的方式来持久保存这些发现，已有研究表明，这对于需要推理的任务具有明显的好处。本文旨在通过超越基于实例的记忆条目（如精确的查询/响应对或紧密耦合于原始问题上下文的摘要），转向概念级的记忆，来使这些记忆更加广泛地重用和扩展，从而提高记忆的可重用性和扩展性。概念化的心算是最一致的记忆设计，无论推理计算规模如何，都优于基准方法。
### Innovation
本文提出了新的策略，从运行中抽象出概念并且为新查询检索条目，以此促进重用并使记忆能够随着额外经验的积累而扩展。实验结果表明，与没有记忆的基准相比，该方法在ARC-AGI基准测试上提供了7.5%的相对改进，且性能随着推理计算量的增加而继续提高。此外，动态更新测试时的记忆比固定不变的记忆设置表现更好，这支持了解决更多问题、将更多模式抽象并存储到记忆中可以实现进一步改进的假设。
### Conclusion
研究结果表明，抽象概念的记忆设计在所有测试的推理计算规模中都优于基准方法。同时，动态更新测试时的记忆能够提高性能，进一步证实了解决更多问题和抽象更多模式可以促进学习改进的假设。
## 270. `cs.CL` - DynaSaur: 大型语言模型代理超越预定义动作 [PDF](https://arxiv.org/pdf/2411.01747), [HTML](https://arxiv.org/abs/2411.01747)
### Authors
Dang Nguyen,Viet Dac Lai,Seunghyun Yoon,Ryan A. Rossi,Handong Zhao,Ruiyi Zhang,Puneet Mathur,Nedim Lipka,Yu Wang,Trung Bui,Franck Dernoncourt,Tianyi Zhou
### Background
现有的大语言模型（LLM）代理系统通常在每一步从固定的预定义动作集中选择动作。这种方法在封闭的、狭义领域的环境中是有效的，但在现实世界中的开放场景中存在两个主要挑战：（1）它显著限制了LLM代理的计划和行动能力；（2）需要大量的人力来列举和实现所有可能的动作，这对于具有大量潜在动作的复杂环境是不切实际的。
### Innovation
本文提出了一种LLM代理框架，能够动态创建和组合所需的动作。在这个框架中，代理通过生成和执行通用编程语言编写的程序与环境进行交互。此外，生成的动作会随着时间的推移积累，以便未来重用。广泛的实验结果显示，该框架显著提高了灵活性，并优于依赖固定动作集的先前方法。特别地，它使LLM代理能够适应并在预定义动作不足或由于不可预见的边缘情况失败的情况下恢复。
### Conclusion
本文展示了该框架在多个基准上的实验结果，证明其在灵活性和性能上都优于先前的方法。
## 271. `cs.CL` - ACING：在黑箱大语言模型中的指令学习的演员-评论家方法 [PDF](https://arxiv.org/pdf/2411.12736), [HTML](https://arxiv.org/abs/2411.12736)
### Authors
Salma Kharrat,Fares Fourati,Marco Canini
### Background
大语言模型（LLMs）的任务效果很大程度上依赖于它们的指令质量，这通常需要大量的人力来设计。这揭示了自动指令优化的必要性。然而，当使用黑箱LLMs时，优化指令尤为困难，因为无法访问模型参数和梯度。现有的自动优化方法在黑箱模型中的效果有限。
### Innovation
提出了一种名为ACING的演员-评论家强化学习框架，将指令优化问题定义为一个没有状态的、连续动作的优化问题，仅使用黑箱反馈就能探索无限的指令空间。ACING能够自动发现比人工设计的指令更好的提示，改进率达到33点，中位数改进率为10点，在33个涉及指令生成、总结以及推理任务的测试中表现出色。
### Conclusion
ACING在黑箱LLMs上的指令优化任务中表现出色，通过大量的消融试验展示了其鲁棒性和高效性。
## 272. `cs.CL` - R2C2-Coder: 提升代码大型语言模型在实际仓库级代码补全能力的增强和基准评估 [PDF](https://arxiv.org/pdf/2406.01359), [HTML](https://arxiv.org/abs/2406.01359)
### Authors
Ken Deng,Jiaheng Liu,He Zhu,Congnan Liu,Jingxin Li,Jiakai Wang,Peng Zhao,Chenchen Zhang,Yanan Wu,Xueqiao Yin,Yuanxing Zhang,Zizheng Zhan,Wenbo Su,Bangyu Xiang,Tiezheng Ge,Bo Zheng
### Background
近年来，代码补全模型取得了显著的进步。现代软件开发中，基于仓库级别的代码补全受到了更多关注，并提出了一些基本方法和基准。然而，现有的仓库级代码补全方法往往未能充分利用项目仓库中的丰富上下文，如相关文件和类层次结构。此外，现有的基准通常仅关注有限的代码补全场景，这无法很好地反映现有方法在仓库级代码补全方面的能力。
### Innovation
为了应对这些限制，本文提出了一种增强和基准评估仓库级代码补全能力的解决方案——R2C2-Coder。R2C2-Coder 包括代码提示构建方法 R2C2-Enhance 和精心设计的基准 R2C2-Bench。具体而言，首先在 R2C2-Enhance 中，通过构建候选检索池并根据每个补全光标位置从池中检索来构建补全提示。其次，基于 R2C2-Enhance，可以构建更具挑战性和多样性的 R2C2-Bench，并提出一种上下文扰动策略以展示良好的实际仓库级代码补全能力。在多个基准上的广泛结果表明了 R2C2-Coder 的有效性。
### Conclusion
本文提出 R2C2-Coder 方法，通过增强提示构建和设计基准来提升代码大型语言模型在实际仓库级代码补全方面的表现。该方法在多个基准上展示了明显的有效性，对于仓库级代码补全的研究具有重要贡献。
## 273. `cs.CL` - 电话游戏：评价统一模型中的语义漂移 [PDF](https://arxiv.org/pdf/2509.04438), [HTML](https://arxiv.org/abs/2509.04438)
### Authors
Sabbir Mollah,Rohit Gupta,Sirnam Swetha,Qingyang Liu,Ahnaf Munir,Mubarak Shah
### Background
目前，在视觉语言模型（VLM）研究中，采用单一统一模型（UM）同时处理视觉理解（图像到文本：I2T）和视觉生成（文本到图像：T2I）任务，这一方向有着新的探索。虽然UM也支持更广泛的单模态任务（如文本到文本、图像到图像），但该研究聚焦于核心的跨模态配对T2I和I2T，由于理解和生成的一致性对未来应用至关重要，现有的评估方法仅对这些能力进行孤立测试，无法反映理解概念的能力是否能转化成生成的结果，以及意义在图像和文本模态之间循环时是否得到保存。为了弥补这一缺陷，提出了统一一致框架（UCF-UM）与统一模型（UM），这是一种循环评估流程，在多次交替生成过程中衡量语义漂移。
### Innovation
UCF-UM框架包含三个度量标准：(i) 平均累计漂移（MCD），基于嵌入的整体语义损失；(ii) 语义漂移率（SDR），总结语义衰退率；(iii) 多代生成评估（MGG），对象级别合规度分数扩展了GenEval。该研究通过新创建ND400基准（从NoCaps和DOCCI抽样），评估了七个近期模型在COCO以外的泛化能力。这些结果揭示了一些模型（如BAGEL）可在多次交替生成中保持语义稳定，而另一些模型（如Vila-u）即使在单次生成得分较高仍快速漂移。UCF-UM指出循环一致性是常规I2T和T2I评估的必要补充，并提供了可操作的度量标准来一致评估统一模型的跨模态稳定性和共享表示的强度。
### Conclusion
UCF-UM为我们提供了一个新的视角来评估统一模型在跨模态稳定性方面的表现。虽然UCF-UM和ND400在评估统一模型的跨模态稳定性方面取得了重大进展，但未来的努力可以进一步探索如何更好地理解语义漂移的原因，并提出改进统一模型的方法以增强其语义稳定性和一致性。
## 274. `cs.CL` - 通过提示基于的文本变换缓解文本分类中的偏见 [PDF](https://arxiv.org/pdf/2305.06166), [HTML](https://arxiv.org/abs/2305.06166)
### Authors
Charmaine Barker,Dimitar Kazakov
### Background
在训练过程中，特定于某些子群体的语言信号可能会变得非常突出。在自动化决策环境中，如果模型依赖与受保护特征相关联的线索，可能会导致偏差结果。本文探讨了通过提示ChatGPT使用简化、中立化、本地化和正式化重新编写文本是否可以在减少人口统计信号的同时保持原始意义，从而减轻这种偏差。
### Innovation
本文创新之处在于研究通过提示模型重新编写文本的策略，具体包括简化、中立化、本地化和正式化，以减少文本中的人口统计学信号，同时保持原始文本的核心意义。
### Conclusion
实验结果显示，文本变换后不同模型的地理位置分类准确性显著下降，表明模型对特定群体语言的依赖性降低。同时，情感分析和评级预测任务表明，这些变换对评论的核心意义影响不大。这表明基于提示的文本变换提供了一种实用而通用的方法来缓解文本分类中的偏见。
## 275. `cs.CL` - 图检索增强生成在定制化大型语言模型中的综述 [PDF](https://arxiv.org/pdf/2501.13958), [HTML](https://arxiv.org/abs/2501.13958)
### Authors
Qinggang Zhang,Shengyuan Chen,Yuanchen Bei,Zheng Yuan,Huachi Zhou,Zijin Hong,Hao Chen,Yilin Xiao,Chuang Zhou,Yi Chang,Xiao Huang
### Background
大型语言模型（LLMs）在广泛的任务中表现出色，但在专门领域的应用仍极具挑战性，因为需要深厚的专业知识。传统的检索增强生成（RAG）系统在实现场景特定的专业领域应用时存在三个关键挑战：复杂的专业查询理解和分布式来源之间的知识整合难题，以及在大规模应用中的系统效率瓶颈。
### Innovation
GraphRAG作为一种新的范式，通过三个方面解决了传统RAG的限制：（i）结构化的图结构知识表示，可以明确捕捉实体关系和领域层次结构；（ii）高效的基于图的检索技术，能够进行多跳推理以保持上下文的一致性；（iii）结构感知的知识整合算法，利用检索到的知识进行准确且逻辑连贯的大规模LLMs生成。
### Conclusion
本综述详细分析了图检索增强生成（GraphRAG）的技术基础，并检查了在各个专业领域中当前的实现，指出了关键技术挑战和有希望的研究方向。同时，提供了GraphRAG相关的研究论文、开源数据和项目资源。
## 276. `cs.CL` - Chain-of-Reasoning: 局部推理：通过多范式视角在大型语言模型中统一数学推理 [PDF](https://arxiv.org/pdf/2501.11110), [HTML](https://arxiv.org/abs/2501.11110)
### Authors
Yiyao Yu,Yuxiang Zhang,Dongdong Zhang,Xiao Liang,Hengyuan Zhang,Xingxing Zhang,Ziyi Yang,Mahmoud Khademi,Hany Awadalla,Junjie Wang,Yujiu Yang,Furu Wei
### Background
大型语言模型在数学推理方面取得了显著进展，但仍主要依赖单一推理范式，这限制了它们在不同任务中的有效性。现有模型往往在多重任务中表现出局限性，亟需一种能够协调不同推理范式的方法来提高数学推理能力。
### Innovation
引入了一种新的统一体系结构——链式推理（CoR）框架，该框架通过自然语言推理（NLR）、算法推理（AR）和符号推理（SR）的协同合作，使模型能够处理多种推理形式。提出的渐进范式训练（PPT）策略使模型逐阶段掌握这些推理范式，从而开发出CoR-Math-7B模型。该模型在定理证明和算术任务中的表现显著优于当前最先进的模型，特别是在GPT-4o上实现了41.0%的绝对改进，在基于奖励学习的模型上实现了15.0%的改进。
### Conclusion
实验结果表明，我们的CoR模型在数学理解能力方面有所提升，能够在不同的任务中实现零样本泛化。
## 277. `cs.CL` - 小变化，大后果：分析生成式大语言模型在招聘情境中的分配公平性 [PDF](https://arxiv.org/pdf/2501.04316), [HTML](https://arxiv.org/abs/2501.04316)
### Authors
Preethi Seshadri,Hongyu Chen,Sameer Singh,Seraphina Goldfarb-Tarrant
### Background
近年来，生成式大语言模型（LLMs）在高风险应用场景如招聘中的应用越来越广泛，但它们在生成和检索设置中潜在的不公平决策仍被研究不足。本研究探讨了基于LLM的招聘系统在实际HR使用场景（简历摘要和应聘者排名）中的分配公平性问题，通过构建具有控制性扰动的合成简历数据集和精选职位描述，考察模型在不同人口群体中的行为差异。研究发现生成摘要对种族差异显示出了更频繁的意义上的差异，而检索模型对人口统计学和社会特征的变化表现出类似敏感性，说明公平性问题可能源于更广泛模型的脆弱性。实验结果揭示了LLM在招聘系统中的偏见可能带来歧视性结果。
### Innovation
本研究通过实际的HR应用场景（简历摘要和应聘者排名）分析LLM在招聘中的分配公平性，并构建具有控制性扰动的合成简历数据集和精选职位描述，直接检验不同人口群体间的模型行为差异，强调了LLM在招聘阶段可能存在的偏见及其潜在的歧视后果。
### Conclusion
研究结果表明，基于LLM的招聘系统，特别是在检索阶段，可能存在显著偏见，这可能导致实际应用中的歧视性结果。这些发现强调了在招聘中使用LLM时需要特别关注公平性问题和模型的潜在脆弱性，以便采取针对性的措施减少歧视性影响。
## 278. `cs.CL` - Autoformalization in the Wild: Assessing LLMs on Real-World Mathematical Definitions [PDF](https://arxiv.org/pdf/2502.12065), [HTML](https://arxiv.org/abs/2502.12065)
### Authors
Lan Zhang,Marco Valentino,Andre Freitas
### Background
LLMs拥有语言能力，能够将非正式的数学语言与形式化语言进行对接，但它们如何适应复杂的、自然出现的数学陈述仍然不明确。为了填补这一空白，研究者们探索了将现实世界中的数学定义进行形式化的任务，这是数学讨论的关键组成部分。为此，他们引入了两个新的资源：从维基百科收集定义（Def_Wiki）和从arXiv论文收集定义（Def_ArXiv），并对一系列LLMs进行了系统评估。
### Innovation
研究引入了两个新的资源，重新定义了现有的基准（如miniF2F），并详细评估了各种LLMs在将定义转化为Isabelle/HOL形式化语言方面的能力。此外，研究调查了通过外部Proof Assistants反馈和正式定义接地策略来增强LLMs性能的方法，以解决自我纠正和与相关数学库的对齐问题。
### Conclusion
实验证明，数学定义比现有的基准（miniF2F）更具有挑战性。LLMs在自我纠正和与相关数学库对齐方面仍存在问题。然而，结构化细化方法和定义接地策略有助于显著提高自我纠正能力（最多16%）和减少未定义错误（最多43%），这为增强基于LLM的实世界场景中的自动形式化提供了积极的方向。
## 279. `cs.CL` - HamRaz：基于文化背景的波斯语对话数据集，用于使用LLM代理进行以人为本的疗法 [PDF](https://arxiv.org/pdf/2502.05982), [HTML](https://arxiv.org/abs/2502.05982)
### Authors
Mohammad Amin Abbasi,Farnaz Sadat Mirnezami,Ali Neshati,Hassan Naderi
### Background
本文介绍了旨在为人工智能辅助心理健康支持提供文化和语言适应的人类-机器对话数据集HamRaz，该数据集基于以人为本疗法（PCT），并结合剧本对话和适应性大语言模型（LLM）角色扮演，反映了实际治疗中的挑战，捕捉了波斯语使用者的模糊性和情感细微之处。同时，提出了HamRazEval评估框架，用于从通用指标和心理学关系专门指标两个方面评估对话质量和治疗效果，并通过人类评估显示HamRaz在同理心、连贯性和现实性方面优于现有基准，旨在促进数字人文学科的发展，缩小在心理健康方面代表性不足的社区之间的差距。
### Innovation
1. 结合.script-based dialogues和适应性大语言模型（LLM）角色扮演，以反映现实生活中的心理治疗挑战并捕捉波斯语语言用户的情感细微之处。2. 提出了HamRazEval，一个双框架评估框架，用于评估对话和治疗质量，包括通用指标和专门的心理关系指标。3. HamRaz在人类评估中在同理心、连贯性和现实性方面优于现有基准，为心理健康和数字人文学科做出了贡献。
### Conclusion
HamRaz为AI辅助的波斯语心理健康支持提供了一个重要的数据资源，通过将语言、文化和心理健康联系起来，特别是针对代表性不足的社区，为发展以人为本的心理疗法和提高治疗效果提供了基础。
## 280. `cs.CL` - LLM在机器翻译中的显式学习 [PDF](https://arxiv.org/pdf/2503.09454), [HTML](https://arxiv.org/abs/2503.09454)
### Authors
Malik Marmonier,Rachel Bawden,Benoît Sagot
### Background
本研究旨在探索大语言模型（LLM）通过语法书中的解释学习新语言的能力，这一过程被称为'显式学习'。研究设计了控制实验，通过特定的加密方法从拉丁语或法语生成的构造语言，进行英语与这些构造语言之间的翻译实验，以此评估LLM的这一能力。
### Innovation
与以前的研究不同，本研究结果表明，LLM确实具备可量化的显式学习能力，但这种能力随着所学语言现象复杂度的增加而减弱。通过对特定思考链进行有监督微调可以显著提高LLM的表现，但难以推广到类型新颖或更复杂的语言特征。
### Conclusion
研究指出，需要更加多样化的训练集和不同的微调策略以进一步提高LLM的显式学习能力，尤其是针对那些在语法书中描述但缺乏大量语料库的支持的低资源语言。
## 281. `cs.CL` - FRIDA to the Rescue! 研究合成数据在基于对象的常识推理中对灾害响应的有效性 [PDF](https://arxiv.org/pdf/2502.18452), [HTML](https://arxiv.org/abs/2502.18452)
### Authors
Mollie Shichman,Claire Bonial,Austin Blodgett,Taylor Hudson,Francis Ferraro,Rachel Rudinger
### Background
在灾难救援场景中，大型语言模型（LLMs）有可能提供强大的物理推理来辅助任务目标。然而，这些推理能力通常仅存在于较大的模型中，由于尺寸限制，这些模型目前无法在机器人系统中部署。为了满足我们的问题空间需求，我们引入了一个数据集和管道来创建一个场推理和指令解码代理（FRIDA）模型。
### Innovation
我们的管道中，领域专家和语言学家结合他们的知识制作高质量、少量样本的提示，用来生成用于微调的合成数据。我们手动策划了用于这些少量样本提示和评估的数据集，以提高LLM在一般和灾害特定对象上的物理推理能力。我们同时进行了一个消融研究，以了解哪种类型的合成数据对性能影响最大。我们微调了几个小的指令调整模型，发现仅通过对象物理状态和功能数据训练的消融FRIDA模型在我们的评估中表现优于使用合成数据整体训练的FRIDA模型及基础模型。
### Conclusion
我们证明了FRIDA管道能够通过少量数据植入物理常识。
## 282. `cs.CL` - HalluEntity: 评估和理解实体级幻觉检测 [PDF](https://arxiv.org/pdf/2502.11948), [HTML](https://arxiv.org/abs/2502.11948)
### Authors
Min-Hsuan Yeh,Max Kamachee,Seongheon Park,Yixuan Li
### Background
尽管许多研究通过不确定性估计来检测大模型（LLM）生成的幻觉，但当前的许多方法主要在句子或段落级别工作，无法精确指出导致幻觉内容的具体实体或片段。这种粒度不足的问题在混合准确信息和虚构信息的长文本中尤其突出。因此，该研究旨在探讨实体级幻觉检测，并提出了名为HalluEntity的新数据集，该数据集在实体级别标注幻觉内容。基于此数据集，研究者对17种现代LLM的基于不确定性的幻觉检测方法进行了全面评估，展示了当前方法的局限性，并识别了幻觉倾向与语言特性之间的关系，指出了未来研究的关键方向。
### Innovation
该研究引入了名为HalluEntity的新数据集，该数据集在实体级别标注幻觉内容，为实体级幻觉检测提供了一个基准。研究还全面评估了基于不确定性的幻觉检测方法，揭示了不同方法在LLM中的表现差异，并通过深入的定性研究，识别了幻觉产生与语言特性之间的联系，从而为未来的研究提供了指导方向。
### Conclusion
不确定性估计方法倾向于高估幻觉，而基于上下文的方法表现出更好的但仍然不足的性能。通过深入的定性研究，研究者识别了幻觉倾向与语言特性之间的关系，强调了未来研究关键方向，包括识别和利用语言结构中与幻觉生成相关的特征，以及开发更精确和有效的幻觉检测方法。
## 283. `cs.CL` - 无需监督的自然语言处理管道用于评估转诊适当性 [PDF](https://arxiv.org/pdf/2501.14701), [HTML](https://arxiv.org/abs/2501.14701)
### Authors
Vittorio Torri,Annamaria Bottelli,Michele Ercolanoni,Olivia Leoni,Francesca Ieva
### Background
评估诊断转诊的适当性对于提高医疗服务效率和减少不必要的程序至关重要。但在意大利国家卫生服务体系中，由于转诊原因仅记录为自由文本而非结构化代码，这个任务变得复杂。为解决这一问题，该研究提出了一种完全无需监督的自然语言处理（NLP）管道，能够在一个无需标注数据集的情况下，提取并评估转诊原因，并且能够适用于不同类型检查。研究通过分析来自伦巴第地区的两个完整的区域数据集（包括2019年至2021年间的数据）进行验证，获得良好的性能结果，从而为当地的政策制定提供支持
### Innovation
该研究提出了一种无需监督的NLP管道，应用于评估诊断转诊的适当性。该管道基于预训练的意大利医学文本的转换器嵌入，无需标注数据集即可对转诊原因进行聚类和评估，并确保可跨不同类型检查推广使用。这种方法能有效分析大型真实世界数据集，并为公共卫生当局提供可用于监控实践和促成基于证据的政策实施的可部署AI工具
### Conclusion
该研究展示了一种强大的、可扩展的无需监督的NLP管道，可用于评估大范围的真实世界数据集中的转诊适当性。研究表明，即使在没有监督数据集的情况下，这种数据也可以得到有效利用，为公共健康当局提供了一种可部署的AI工具，用于监控临床实践并支持基于证据的政策制定，并通过地区分析识别了关键的非适当的转诊群体，为新的伦巴第地区决议提供了依据，以加强指南的遵循性
## 284. `cs.CL` - 通过准符号抽象改进链式思考推理 [PDF](https://arxiv.org/pdf/2502.12616), [HTML](https://arxiv.org/abs/2502.12616)
### Authors
Leonardo Ranaldi,Marco Valentino,Andrè Freitas
### Background
链式思考（CoT）是大型语言模型（LLMs）进行复杂任务推理的一种常见策略，通过将任务分解为中间推理步骤。然而，生成的解释容易产生内容偏差，影响其稳健性和真实度。为解决这一问题，最近的研究提出了结合外部符号求解器的形式化逻辑方法。然而，全符号方法存在瓶颈，即需要完全将自然语言翻译成形式语言，这影响效率和灵活性。因此，提出了一种新的方法来从逻辑推理中解构内容，而无需全面形式化。
### Innovation
本文提出了一种名为QuaSAR（Quasi-Symbolic Abstract Reasoning）的新方法，这是一种改进的链式思考形式。QuaSAR方法引导LLMs通过准符号解释在更高抽象级别上操作，仅形式化相关的变量和谓词，以便自然语言和符号元素共存。QuaSAR方法在上下文学习和构建示例以提高较小模型的推理能力方面展示出优势。方法实验证明，准符号抽象可以提高基于链式思考的方法的准确性，提高在自然语言和符号推理任务上的稳健性和一致性，最高可达8%的提升。
### Conclusion
QuaSAR 方法能够改进链式思考，通过准符号抽象提高大型语言模型的推理能力，展示出在自然语言理解和符号推理方面的潜力。该研究为如何在保持自然语言流畅性的同时增强模型的逻辑推理能力提供了新思路。
## 285. `cs.CL` - 未来生成：一种基于RAG生成科学文章未来工作的方法 [PDF](https://arxiv.org/pdf/2503.16561), [HTML](https://arxiv.org/abs/2503.16561)
### Authors
Ibrahim Al Azher,Miftahul Jannat Mokarrama,Zhishuai Guo,Sagnik Ray Choudhury,Hamed Alhoori
### Background
未来工作部分概述了科学文章中的潜在研究方向，通过识别当前研究的局限性和空白来实现。这种方法为早期职业研究人员提供了未探索领域的资源，也为经验丰富的研究人员提供了新的项目或合作机会。在这项研究中，我们使用RAG技术从相关论文中获取背景信息，以增强未来工作建议生成过程中的洞察力，并减少了遗漏重要研究方向的可能性。我们尝试了多种大型语言模型（LLMs）与检索增强生成（RAG）的集成。我们引入了LLM反馈机制以提高生成内容的质量，并提出了LLM评判者框架以进行稳健的评估，评估方面包括新颖性、幻觉和可行性。实验证明，结合RAG方法使用GPT-4o mini与LLM反馈机制的方法，在定性和定量评估中均优于其他方法。
### Innovation
我们采用RAG技术结合GPT-4o mini，并引入了LLM反馈机制和LLM评判者框架进行未来工作建议的生成。这种方法显著提高了生成内容的质量和评估的准确性。
### Conclusion
我们的人类评估表明，结合RAG方法使用GPT-4o mini与LLM反馈机制的方法在生成科学文章未来工作方面表现出色，各方面均优于其他方法。
## 286. `cs.CL` - 通过元内模学习实现快速词汇学习 [PDF](https://arxiv.org/pdf/2502.14791), [HTML](https://arxiv.org/abs/2502.14791)
### Authors
Wentao Wang,Guangyuan Jiang,Tal Linzen,Brenden M. Lake
### Background
人类可以迅速从几个示例中学到新词，并在新的语境中系统灵活地使用它。然而，当前语言模型的少量示例词汇学习能力以及提高这些能力的方法尚未得到充分探索。本文研究探讨了一种新的方法——内模训练以用于上下文中的词汇学习（Minnow），旨在让语言模型能够根据少量上下文示例生成新词汇的使用示例，通过使用特殊占位符表示新词。这种训练被广泛应用于许多新词汇上，以培养一种普遍的学习词汇能力。研究表明，使用Minnow方法从零开始训练模型，使其能够具备与预训练数据量大得多的大型语言模型相似的少量示例词汇学习能力。
### Innovation
提出了新的方法Minnow，这是一种元内模训练方法，用于训练语言模型根据少量上下文示例生成新词汇的使用示例，这种方法通过使用一个特殊的占位符表示新词汇，再通过大量新词汇重复训练，来培养语言模型的一般词汇学习能力。研究表明，通过Minnow方法从头开始训练模型，使其在大规模人类面向儿童的语言数据上进行训练，能够实现强有力的少量示例词汇学习，与大规模语言模型（LLM）的预训练数据量相比具有相当的性能。进一步通过判别性和生成性评估来证明，通过对预训练的大语言模型进行Minnow微调，可以提高它们在识别新词汇、确定新词汇的句法类别以及根据一个或几个上下文示例生成合理的新词汇使用和定义方面的表现。
### Conclusion
这项研究发现Minnow方法具有高效的数据利用能力，并且表明其有可能提高语言模型在词汇学习任务上的性能。
## 287. `cs.CL` - 从多位评委学习高效的多轮对话评估器 [PDF](https://arxiv.org/pdf/2508.00454), [HTML](https://arxiv.org/abs/2508.00454)
### Authors
Yuqi Tang,Kehua Feng,Yunfeng Wang,Zhiwen Chen,Chengfei Lv,Gang Yu,Qiang Zhang,Keyan Ding
### Background
当前评估大型语言模型（LLMs）对话能力的方法主要依赖于“LLM作为评委”的范式，即通过提示LLM作为评估者来评估对话质量。然而，这种方法经常受到各种偏差的影响，这降低了评估结果的可靠性和一致性。为减轻这些偏差，最近的方法采用了多个LLM作为评委，并综合他们的判断来选择最佳评估。虽然有效，但这种方法在推理过程中产生了显著的计算开销。
### Innovation
本文提出了一种高效的多轮对话评估器，通过将多个LLM评委的偏好知识整合到一个模型中，来捕获多元评委的集体智慧。这种方法保持了多种评委反馈的优势，同时大幅降低了评估成本，实现了快速灵活的对话质量评估。
### Conclusion
实验表明，本方法在七个单一评分和两两比较对话评估基准中均优于现有基线方法，在各种场景中展现了其高效性和稳健性。
## 288. `cs.CL` - MEDUSA：自然条件下言语情感识别的多模态深度融合多阶段训练框架 [PDF](https://arxiv.org/pdf/2506.09556), [HTML](https://arxiv.org/abs/2506.09556)
### Authors
Georgios Chatzichristodoulou,Despoina Kosmopoulou,Antonios Kritikos,Anastasia Poulopoulou,Efthymios Georgiou,Athanasios Katsamanis,Vassilis Katsouros,Alexandros Potamianos
### Background
SER是一个具有挑战性的任务，因为人类情感具有主观性，并且在自然条件下其表现形式分布不均。因此，在这种情况下实现情感识别存在困难。
### Innovation
我们提出了一种名为MEDUSA的多模态框架，它采用四阶段训练管道有效处理类别失衡和情感含糊性。框架使用DeepSER，结合并自主研发了一种深度跨模态融合机制，利用预训练自我监督的声音和语言表示。此外，还利用了Manifold MixUp方法进一步进行正则化，以及一个可训练的元分类器来整合集成预测。训练方法将人类注释分数作为软目标，结合平衡数据采样和多任务学习，有效提高了情感识别的准确度。
### Conclusion
MEDUSA在Interspeech 2025：自然条件下言语情感识别挑战赛的任务1（类别情感识别）中排名第一。
## 289. `cs.CL` - EQ-Knight: 增强记忆的LLM代理在债务回收中的战略性情感博弈 [PDF](https://arxiv.org/pdf/2503.21080), [HTML](https://arxiv.org/abs/2503.21080)
### Authors
Yunbo Long,Yuhan Liu,Liming Xu,Alexandra Brintrup
### Background
基于大规模语言模型的聊天机器人在金融谈判中增强了参与度，但它们过分依赖被动同理心会在信用回收中引入关键风险。虽然同理心驱动的方法在温和情况下能维护客户满意度，但在不诚实的债务人面前却会失败——这些债务人利用调解策略操纵条款或逃避还款。盲目优先考虑“客户服务体验”会导致债权人的弱点：收入流失、道德风险和系统性剥削。
### Innovation
我们提出了一种名为EQ-Knight的LLM代理，其动态优化情感策略以捍卫债权人的利益。EQ-Knight将情感记忆与博弈论推理相结合，利用潜马尔可夫模型（HMM）追踪和预测债务人的情感状态。通过分析实时和历史的情感线索，EQ-Knight战略性地反击负面情绪（如攻击性、假装的痛苦等）同时维持与债务人之间的建设性关系。实验表明，与传统的LLM谈判者相比，EQ-Knight减少了32%的让步损失，尤其是在债务人使用负面情绪（如恐吓、道德胁迫）来迫使让步的对抗性情况下，其恢复率并未受到影响。
### Conclusion
对于信用机构而言，EQ-Knight将LLM从高风险的“客户取悦者”转变为战略性的情感守护者——平衡情感智慧与战术严谨性以确保问责制并遏制欺诈行为。
## 290. `cs.CL` - 移植再生：一种新的文本数据增强范式 [PDF](https://arxiv.org/pdf/2508.14723), [HTML](https://arxiv.org/abs/2508.14723)
### Authors
Guangzhan Wang,Hongyu Zhang,Beijun Shen,Xiaodong Gu
### Background
数据增强是深度学习中一项关键的技术。传统的数据增强方法，如Back-translation，主要关注词汇层面的改写，从而生成同义变化。尽管大型语言模型（LLMs）通过其‘知识涌现’能力增强了文本增强的效果，但控制增强输出的风格和结构仍然具有挑战性，需要细致的提示工程。
### Innovation
本文提出了一种使用LLMs的新颖文本增强范式，名为LMTransplant。其核心思想是‘移植-再生’：将种子文本整合到LLM扩展的语境中，并要求LLM基于扩展后的语境生成变体。这种方法通过充分利用嵌入在LLMs中的知识，使模型能够生成更多样化和创造性的内容级变体，同时保留原始文本的核心属性。本文在多种文本相关任务上评估了LMTransplant，证明了其在性能上优于现有的文本增强方法。此外，LMTransplant还显示出随增强数据量增加而具有出色扩展性的能力。
### Conclusion
LMTransplant 通过利用大语言模型的知识，生成了更多样化和创造性的文本变形，同时保住了原有文本的核心特性，在多个文本相关任务中表现出色。其通过‘移植-再生’的方法显著增强了文本增强的灵活性和效果。
## 291. `cs.CL` - 通过集成检索和指令调优答案提取的两阶段古兰经问答 [PDF](https://arxiv.org/pdf/2508.06971), [HTML](https://arxiv.org/abs/2508.06971)
### Authors
Mohamed Basem,Islam Oshallah,Ali Hamdi,Khaled Shaban,Hozaifa Kassab
### Background
古兰经问答由于古阿拉伯语的语言复杂性以及宗教文本的语义丰富性而具有独特的挑战。目前的方法面临着大规模数据集训练不足的问题，导致在检索和答案提取上表现不佳。
### Innovation
本文提出了一种新颖的两阶段框架，分别针对段落检索和答案提取。段落检索阶段使用微调的阿拉伯语言模型进行集成，以实现更好的排名性能。答案提取阶段采用指令调优的大规模语言模型和少量示例提示，以克服细调在小数据集上的局限性。该方法在古兰经问答2023共享任务上取得了最优结果，特别是在检索和答案提取方面，显著优于之前的方法。这证明了结合模型集成和指令调优的语言模型能够有效解决资源匮乏领域中的问答挑战。
### Conclusion
通过将模型集成和指令调优的大规模语言模型结合，本文提出的方法取得了古兰经问答任务上的最优表现，表明这种框架能够有效应对特殊领域中资源有限的问答挑战。
## 292. `cs.CL` - MiniCPM4：终端设备上的超高效大语言模型 [PDF](https://arxiv.org/pdf/2506.07900), [HTML](https://arxiv.org/abs/2506.07900)
### Authors
MiniCPM Team:Chaojun Xiao,Yuxuan Li,Xu Han,Yuzhuo Bai,Jie Cai,Haotian Chen,Wentong Chen,Xin Cong,Ganqu Cui,Ning Ding,Shengda Fan,Yewei Fang,Zixuan Fu,Wenyu Guan,Yitong Guan,Junshao Guo,Yufeng Han,Bingxiang He,Yuxiang Huang,Baoxi Ji,Cunliang Kong,Qiuzuo Li,Siyuan Li,Wenhao Li,Xin Li,Yanghao Li,Yishan Li,Zhen Li,Dan Liu,Biyuan Lin,Yankai Lin,Xiang Long,Quanyu Lu,Yaxi Lu,Peiyan Luo,Hongya Lyu,Litu Ou,Yinxu Pan,Lushi Pu,Zekai Qu,Qundong Shi,Zijun Song,Jiayuan Su,Zhou Su,Ao Sun,Xianghui Sun,Peijun Tang,Fangzheng Wang,Feng Wang,Shuo Wang,Yudong Wang,Zheng Wang,Yesai Wu,Zhenyu Xiao,Jie Xie,Zihao Xie,Xiaoyue Xu,Yukun Yan,Jiarui Yuan,Jinqian Zhang,Kaihuo Zhang,Lei Zhang,Linyue Zhang,Xueren Zhang,Yudi Zhang,Hengyu Zhao,Weilin Zhao,Weilun Zhao,Yuanqian Zhao,Zhi Zheng,Chuyue Zhou,Ge Zhou,Jie Zhou,Wei Zhou,Yanghao Zhou,Zihan Zhou,Zixuan Zhou,Zhiyuan Liu,Guoyang Zeng,Chao Jia,Dahai Li,Maosong Sun
### Background
该论文介绍了一种名为MiniCPM4的高性能大语言模型（LLM），专为终端侧设备设计。通过在模型架构、训练数据、训练算法和推理系统等方面的系统创新，实现了高效性。特别在训练数据和模型架构上，通过UltraClean和InfLLM v2等方法优化，使得使用8万亿训练令牌就能达到满意的模型性能。
### Innovation
1. 模型架构：提出InfLLM v2，一种可训练的稀疏注意力机制，加速长上下文处理的预填充和解码阶段。2. 训练数据：提出UltraClean，一种高效和准确的预训练数据过滤和生成策略，以及UltraChat v2，一个全面的监督微调数据集。3. 训练算法：提出ModelTunnel v2，一种高效的预训练策略搜索方法，并引入chunk-wise rollout和BitCPM，一种数据高效三元LLM，增强后训练方法。4. 推理系统：提出将稀疏注意力、模型量化和推测性采样集成的推理系统，实现高效的预填充和解码。
### Conclusion
MiniCPM4和MiniCPM4.1在各种基准测试中超过同等规模的开源模型，8B版本在长序列理解和生成上有显著的速度提升。MiniCPM4提供两种版本，参数分别为0.5B和8B，并构建了可应用于深推理模式和非推理模式的MiniCPM4.1混合推理模型。
## 293. `cs.CL` - Context Reasoner：通过强化学习激励上下文隐私和安全合规的推理能力 [PDF](https://arxiv.org/pdf/2505.14585), [HTML](https://arxiv.org/abs/2505.14585)
### Authors
Wenbin Hu,Haoran Li,Huihao Jing,Qi Hu,Ziqian Zeng,Sirui Han,Heli Xu,Tianshu Chu,Peizhao Hu,Yangqiu Song
### Background
大型语言模型(LLMs)表现出色，但也带来了显著的安全和隐私风险。当前的缓解策略往往无法在风险场景中保留上下文推理能力，而是依赖敏感模式匹配来保护LLMs，这限制了其适用范围。此外，这些策略忽视了现有的安全和隐私标准，导致法律合规性存在系统风险。
### Innovation
该研究将安全和隐私问题转化为遵循上下文完整性(CI)理论的上下文化合规问题。在CI框架下，研究提出了一个能够与GDPR、欧盟AI法案和HIPAA等三个关键监管标准对齐的方法。具体地，研究采用了基于规则的奖励强化学习(RL)来激励上下文推理能力，同时提升安全和隐私标准的遵守。通过广泛的实验，研究显示该方法不仅大幅提升了法律合规性（在安全/隐私基准测试中实现了8.58%的准确率提升），还进一步提高了通用推理能力。对于更强的推理模型OpenThinker-7B，在各种主题上显著优于基础模型Qwen2.5-7B-Instruct，该方法在MMLU和LegalBench基准测试中分别实现了2.05%和8.98%的准确率提升。
### Conclusion
该方法不仅改善了OpenThinker-7B模型在安全和隐私方面的一般推理能力，也进一步展示了有效的合规性和一般推理能力改进。
## 294. `cs.CL` - 学习多源视觉提示最佳提示组合 [PDF](https://arxiv.org/pdf/2504.12311), [HTML](https://arxiv.org/abs/2504.12311)
### Authors
Jianhua Liu,Liwen Cao,Yanru Wu,Zijie Zhao,Yang Li
### Background
提示调优已经作为一种轻量级策略，用于将基础模型适应下游任务，尤其是在资源受限的系统中。随着预训练提示成为有价值的资产，通过结合多个来源的提示来利用互补知识以增强对新任务的泛化能力，提供了一种有前途的方法。然而，简单的聚合往往会忽略不同来源的提示对目标任务的不同贡献潜力。为此，我们提出了HGPrompt，一种动态框架，旨在学习优化的提示组合权重。这些权重通过同时最大化可转移性的信息论度量并利用创新的正则化策略最小化梯度冲突来优化。具体地，我们提出了一种可微损失函数来捕捉由提示引入的特征在目标任务上的判别性。同时，HGPrompt基于海森矩阵和 Fisher 信息匹配不同来源提示的梯度方差，确保稳定的、具有一致性的知识转移并抑制它们之间的梯度冲突。大规模实验在VTAB基准测试上验证了HGPrompt的优越性能，证明了其在学习高效多源提示转移优化组合的有效性。
### Innovation
HGPrompt是一种动态框架，它通过同时最大化可转移性的信息论度量和采用一种新的正则化策略来最小化梯度冲突，来学习最优的提示组合权重。它提出的可微损失函数可以捕捉由提示引发的特征在目标任务上的判别性，基于海森矩阵和 Fisher 信息，HGPrompt匹配不同来源提示的梯度方差，以确保稳定且具有一致性的知识转移，同时抑制它们之间的梯度冲突。这种方法在大规模实验中证明优于现有方法，验证了其在多源提示转移中的有效性能。
### Conclusion
在大型VTAB基准上进行的广泛实验表明，HGPrompt达到了最先进的性能，验证了其在学习有效多源提示转移优化组合的有效性。
## 295. `cs.CL` - Spotlight Attention: 通过非线性哈希基于的键值缓存检索实现高效的大语言模型生成 [PDF](https://arxiv.org/pdf/2508.19740), [HTML](https://arxiv.org/abs/2508.19740)
### Authors
Wenhao Li,Yuxin Zhang,Gen Luo,Haiyuan Wan,Ziyang Gong,Fei Chao,Rongrong Ji
### Background
大语言模型（LLMs）在进行推理时，键值（KV）缓存在很大程度上影响了其效率。当前的方法使用随机线性哈希来识别重要令牌，但这种方法由于查询和键在LLMs中的窄角锥内正交分布而效率低下。为了提升性能并减轻KV缓存的负担，研究者引入了一种新的方法来改进查询和键的嵌入分布，从而提高编码效率和鲁棒性。
### Innovation
Spotlight Attention引入了一种新颖的方法，即使用非线性哈希函数优化嵌入分布，通过布雷德利-泰利（Bradley-Terry）排名损失构建轻量级、稳定的训练框架，令非线性哈希模块能够使用16GB GPU内存进行优化，仅需8小时。实验结果表明，与传统的线性哈希相比，Spotlight Attention能够大幅提高检索精度，同时使哈希编码长度至少缩短5倍。
### Conclusion
Spotlight Attention通过非线性哈希函数的使用，实现了高效的检索，增强了编码效率和鲁棒性。此外，通过特殊的CUDA内核实现位操作计算优势，在单个A100 GPU上仅用不到100微秒完成512K令牌的哈希检索，从而实现了端到端高达3倍于原始解码的吞吐率。
## 296. `cs.CL` - 紧凑型语言模型能否像代理一样进行搜索？基于蒸馏的策略优化以维持代理型RAG能力 [PDF](https://arxiv.org/pdf/2508.20324), [HTML](https://arxiv.org/abs/2508.20324)
### Authors
Rikuto Kotoge,Mai Nishimura,Jiaxin Ma
### Background
强化学习作为后训练方法，可用于激发语言模型的积极参与式检索和规划行为。然而，小型语言模型（如参数量为0.5B的模型）由于推理能力较低，导致奖励稀疏和训练不稳定。
### Innovation
提出了一种名为Distillation-Guided Policy Optimization (DGPO)的方法，通过教师演示的冷启动初始化和策略优化过程中的持续教师指导，解决了小型模型的问题。
### Conclusion
系统实验表明，DGPO使小型语言模型能够实现复杂的积极参与式搜索行为，甚至在某些情况下可以超越教师语言模型。这使代理型RAG在计算资源受限的环境中成为可能。
## 297. `cs.CL` - DAPFAM: 一个面向领域、基于家庭级别的数据集，用于测试跨领域专利检索 [PDF](https://arxiv.org/pdf/2506.22141), [HTML](https://arxiv.org/abs/2506.22141)
### Authors
Iliass Ayaou(ICube),Denis Cavallucci(ICube),Hicham Chibane(ICube)
### Background
专利先行技术检索特别具有挑战性，当相关披露跨越技术边界时。现有的基准数据集缺乏明确的领域划分，使得难以评估检索系统如何应对这种转变。现有的基准数据集缺乏明确的领域划分，使得难以评估检索系统如何应对这种转变。因此，需要一个明确区分领域内和领域外的基准数据集来解决这个问题。
### Innovation
DAPFAM是一个基于家庭级别的数据集，引入了新的IPC3重叠方案明确定义了领域内和领域外的部分。该数据集包括1247个查询家庭和45336个目标家庭，通过引用进行了基于相关性的判断。研究通过249次受控实验，涉及词汇（BM25）和稠密（transformer）后端、文档和段落级别检索、多个查询和文档表示、聚合策略和基于互惠排名融合（RRF）的混合融合方法。研究结果表明，领域外性能始终低于领域内约五倍，而段落级别检索始终优于文档级别检索，稠密方法比BM25仅提供适度的优势，但未能关闭领域外的差距。文档级别RRF提供了强大的有效性效率权衡，具有最小的附加开销。
### Conclusion
DAPFAM公开了持续存在的跨领域检索挑战，提供了一个可重现、计算感知的测试平台，用于开发更稳健的专利信息检索系统。数据集已在Hugging Face上公开。
## 298. `cs.CL` - SLM-Bench：全面评估小型语言模型对环境影响的基准--扩展版 [PDF](https://arxiv.org/pdf/2508.15478), [HTML](https://arxiv.org/abs/2508.15478)
### Authors
Nghiem Thanh Pham,Tung Kieu,Duc-Manh Nguyen,Son Ha Xuan,Nghia Duong-Trung,Danh Le-Phuoc
### Background
小型语言模型（SLMs）虽然具有计算效率和易用性，但在它们的性能和环境影响方面的系统评估仍然缺乏。SLM-Bench 是首个专门设计来从多个维度评估 SLMs 的基准，包括准确性、计算效率和可持续性指标。SLM-Bench 使用 23 个数据集覆盖 14 个领域，评估了 15 种 SLMs 在 9 个 NLP 任务中的表现，并在 4 种硬件配置下进行评估，确保了公平的模型比较。评估使用了 11 个量化指标，包括正确性、计算和消费，提供了一个整体的效率权衡评估。本研究通过控制硬件条件，确保模型之间的公平比较，并开发了一个开源的基准测试管道，以促进可重复性和进一步的研究。
### Innovation
SLM-Bench 首次系统性地评估了 SLMs 的性能和环境影响，提出了一个新的基准标准。它覆盖了 15 种不同的 SLMs，在 9 个 NLP 任务、23 个数据集和 4 种硬件配置下进行全面评估。此外，SLM-Bench 是第一个量化 11 个效率指标的基准，包括正确性、计算和消耗，这使得效率权衡的评估更加全面。SLM-Bench 通过标准化的评估协议，确保了可重复性，并提供了一个新的评估标准来平衡资源效率和实际应用之间的关系。
### Conclusion
SLM-Bench 显示了 SLMs 中多样化的效率权衡，表明某些模型在准确性方面表现出色，而其他模型在能源效率方面更为出色。SLM-Bench 为 SLMs 的评估设立了新的标准，填补了资源效率和实际应用之间的差距。
## 299. `cs.CL` - 预警告警：通过预合成类似牢笼突破的指令增强大型语言模型安全性边界以应对潜在攻击 [PDF](https://arxiv.org/pdf/2508.20038), [HTML](https://arxiv.org/abs/2508.20038)
### Authors
Sheng Liu,Qiang Sheng,Danding Wang,Yang Li,Guang Yang,Juan Cao
### Background
尽管在改善大型语言模型（LLM）拒绝回答恶意指令方面取得了进展，但广泛使用的LLM仍然容易受到攻击者的牢笼突破攻击。这些攻击者通过生成与安全对齐语料库分布不同的指令，暴露了LLM不能识别未见过的恶意指令的能力。这种现实世界攻击与训练数据之间的分布性不符，迫使开发者进行被动的修复循环。
### Innovation
本文提出了IMAGINE，一种利用嵌入空间分布分析来生成类似牢笼突破指令的合成框架。该方法有效地填补了真实牢笼突破模式和安全对齐语料库之间的分布性差距。IMAGINE 采用迭代优化过程，在各迭代过程中动态演化文本生成分布，从而通过合成数据示例增强安全对齐数据分布的覆盖范围。
### Conclusion
通过IMAGINE增强安全对齐语料库，本文的框架在Qwen2.5、Llama3.1和Llama3.2上显著降低了攻击成功率，而不会牺牲其功能。
## 300. `cs.CL` - UI-Bench: 评估AI文本到应用工具设计能力的标准 [PDF](https://arxiv.org/pdf/2508.20410), [HTML](https://arxiv.org/abs/2508.20410)
### Authors
Sam Jung,Agustin Garcinuno,Spencer Mateega
### Background
现有的AI文本到应用工具承诺在几分钟内生成高质量的应用程序和网站，但缺乏严格的公共基准来验证这些声明。因此，需要一个能全面评估这些工具视觉设计表现的大规模基准工具。
### Innovation
UI-Bench是该领域首次提出的大规模基准工具，通过专家间的两两对比来评估竞争AI文本到应用工具的视觉卓越性。它涵盖了10种工具、30个提示、300个生成的网站和4000多次专家评估，采用了一种基于TrueSkill模型的排名方法，提供精确的信心区间。UI-Bench为推动AI驱动的网页设计提供了一个可重复的标准。此外，UI-Bench还提供了完整的提示集、开源评估框架和公共排行榜。即将提供由参与者评估的生成站点。UI-Bench的排行榜可在该网址查看：this https URL
### Conclusion
UI-Bench为AI文本到应用工具的设计能力设定了一套可重复的标准，发布了完整的提示集、开源评估框架和公共排行榜，并即将发布由参与者评级的生成站点，以促进该领域的研究和开发。
## 301. `cs.CL` - DaMoC: 基于数据和模型压缩高效选择用于微调特定领域任务的最佳大型语言模型 [PDF](https://arxiv.org/pdf/2509.01221), [HTML](https://arxiv.org/abs/2509.01221)
### Authors
Wei Huang,Huang Wei,Yinggui Wang
### Background
大型语言模型（LLMs）在通用任务上表现出色，但在特定领域任务上存在不足，需要使用特定数据进行微调。选择最适合特定下游任务的LLM很具挑战性，主要难点在于如何快速确定最佳LLM。
### Innovation
提出了一个数据和模型压缩框架（DaMoC），通过数据层面和模型层面的优化来解决这一挑战。在数据层面，构建了一个系统性的数据过滤方法分类体系，分为分布感知方法、质量感知方法和混合方法。还通过增强文本中关键词汇的密度实现了词汇压缩，并使用LLM迭代重写文本以优化其表达。在模型层面，使用层相似度得分评估每一层的重要性，移除较低重要的层，并引入稀疏合并方式以保留原模型尽可能多的性能。
### Conclusion
在医疗问答、金融问答、通用问答和阅读理解四个数据集上的实验表明，这种方法可以节省约20倍的训练时间同时选择出最佳的LLM。
## 302. `cs.CL` - 通过双向重建训练大型语言模型成为更好的文本嵌入器 [PDF](https://arxiv.org/pdf/2509.03020), [HTML](https://arxiv.org/abs/2509.03020)
### Authors
Chang Su,Dengliang Shi,Siyuan Huang,Jintao Du,Changhua Meng,Yu Cheng,Weiqiang Wang,Zhouhan Lin
### Background
大型语言模型（LLMs）已被广泛研究作为强大的文本嵌入模型。现有的基于LLM的文本嵌入方法通常使用最终标记（通常是特殊保留标记如[EOS]）的嵌入，但这些标记未经过特别训练来捕捉整个上下文的语义，限制了其作为文本嵌入的能力，特别是在检索和再排序任务中。
### Innovation
本文提出了在对比学习之前添加一个新的训练阶段，以丰富最终标记嵌入的语义。这个阶段使用双向生成重建任务，即EBQ2D（基于嵌入的查询到文档）和EBD2Q（基于嵌入的文档到查询），这两个任务交错进行以锚定[EOS]嵌入并重建查询-文档对的任意一侧。
### Conclusion
实验结果表明，额外的训练阶段显著提高了LLM在大规模文本嵌入基准（MTEB）上的性能，实现了不同LLM基础模型和规模的新最佳结果。
## 303. `cs.CL` - NADI 2025: 首个多方言阿拉伯语音处理共享任务 [PDF](https://arxiv.org/pdf/2509.02038), [HTML](https://arxiv.org/abs/2509.02038)
### Authors
Bashar Talafha,Hawau Olamide Toyin,Peter Sullivan,AbdelRahim Elmadany,Abdurrahman Juma,Amirbek Djanibekov,Chiyu Zhang,Hamad Alshehhi,Hanan Aldarmaki,Mustafa Jarrar,Nizar Habash,Muhammad Abdul-Mageed
### Background
该研究展示了第六次Nuanced Arabic Dialect Identification (NADI 2025) 共享任务的结果，任务集中于阿拉伯口音识别的三个子任务：口语方言识别（子任务1）、语音识别（子任务2）和口语方言的重音恢复（子任务3）。共有44支队伍注册，100个有效的提交来自8个不同的队伍，涵盖了三个子任务的提交数量分别如下：子任务1共34次提交（5支队伍）、子任务2共47次提交（6支队伍）、子任务3共19次提交（2支队伍）。最优秀的系统在子任务1中实现了79.8%的准确率，在子任务2的WER/CER分别为35.68/12.20，子任务3为55/13的WER/CER。这些结果突显了阿拉伯方言语音处理中的持续挑战，特别是在识别、识别以及重音恢复方面。
### Innovation
该研究提出了一个多维度的阿拉伯语音处理共享任务，首次系统地评估了和比较了阿拉伯方言识别、语音识别和重音恢复等多个关键任务的性能。汇集多个队伍的最新研究方法和成果，展示了当前技术的局限性和改进的方向。
### Conclusion
研究总结了参赛队伍所采用的方法，并提出了未来NADI系列研究的可能方向，强调了在阿拉伯方言语音处理方面仍存在的挑战。
## 304. `cs.CL` - 语言模型训练和评估中合成长时间上下文数据生成的模块化技术 [PDF](https://arxiv.org/pdf/2509.01185), [HTML](https://arxiv.org/abs/2509.01185)
### Authors
Seganrasan Subramanian,Abhigya Verma
### Background
大型语言模型（LLMs）处理和推理长文本输入的能力对于许多实际应用至关重要。然而，这一领域的发展受到高质量、多样且可验证的长上下文数据集的缺乏制约，这些数据集既可用于训练，也可用于评估。因此，迫切需要一个模块化且可扩展的框架，用于通过与LLMs的提示交互来生成合成的长上下文数据。
### Innovation
本文介绍了一个模块化的架构框架，用于通过提示交互生成合成的长上下文数据，支持多种训练和对齐目标，包括有监督微调（SFT）、直接偏好优化（DPO）和组相对策略优化（GRPO）。该框架包括四种核心生成范式：多轮对话、文档导向的输入-输出对、验证性的指令-响应任务和长上下文推理示例。通过模板提示、模型无关的架构和元数据丰富的输出，该方法实现了可扩展、可控且用途明确的数据集生成，以推进LLMs的长上下文能力。
### Conclusion
本文提出的方法通过提供一个模块化、扩展性强的框架，使生成长上下文数据变得可扩展、可控制且目标导向，从而促进了LLMs长上下文能力的发展。
## 305. `cs.CL` - 跨语言的科学：评估大语言模型多语言翻译科学论文 [PDF](https://arxiv.org/pdf/2502.17882), [HTML](https://arxiv.org/abs/2502.17882)
### Authors
Hannah Calzi Kleidermacher,James Zou
### Background
科学研究本质上是全球化的。然而，绝大多数学术期刊仅以英文出版，给非英语母语的研究者带来了障碍。
### Innovation
利用大语言模型（LLMs）进行科学论文翻译，同时保持原稿的JATS XML格式，开发了一种实用的自动化方法，供学术期刊实施。该方法采用了多语言翻译，并对科学论文进行28种语言的翻译。引入了一种新型问答基准方法评估翻译准确性，结果显示平均准确率为95.9%，证明了关键科学细节的准确传达。此外，通过用户研究，显示了翻译能够准确捕捉原始信息。最后，展示了上下文学习技术如何用于调整翻译内容，以配合特定领域偏好。
### Conclusion
该研究展示了大语言模型在多语言科学论文翻译中的应用，准确传达了科学细节，并展示了其在翻译过程中的适应性和实用性。
## 306. `cs.CL` - LLM 基础偏好评估中的长度偏见解析 [PDF](https://arxiv.org/pdf/2407.01085), [HTML](https://arxiv.org/abs/2407.01085)
### Authors
Zhengyu Hu,Linxin Song,Jieyu Zhang,Zheyuan Xiao,Tianfu Wang,Zhengyu Chen,Nicholas Jing Yuan,Jianxun Lian,Kaize Ding,Hui Xiong
### Background
在使用大型语言模型（LLMs）作为裁判，尤其是进行偏好比较时，这种做法越来越普遍。然而，这种做法暴露出对较长响应的偏好，这降低了评估结果的可靠性。这一偏好对不同长度的响应造成了不公正的评价，影响了评估的准确性。
### Innovation
本文创新地将偏好评估指标（胜率）分解为两个关键组成部分：可获得性（与正确性、毒性、一致性等可靠性因素相关，与长度无关）和信息量（取决于长度，代表响应中的信息量）。通过受控实验验证这一分解方法，表明响应长度通过影响信息量而影响评估结果。进而提出AdapAlpaca，这是一种简单有效的调整胜率评估的方法。AdapAlpaca通过等长区间对齐参考和测试模型响应，确保公平比较响应质量。
### Conclusion
研究通过控制实验，证明响应长度通过影响信息量来影响评估结果。此外，提出了AdapAlpaca方法，通过调整胜率度量，确保评估结果不受响应长度的影响，从而更准确地评估内容质量。
## 307. `cs.CL` - PIN: 配对和交错多模态文档的富含知识的数据集 [PDF](https://arxiv.org/pdf/2406.13923), [HTML](https://arxiv.org/abs/2406.13923)
### Authors
Junjie Wang,Yuxiang Zhang,Minghao Liu,Yin Zhang,Yatai Ji,Weihao Xuan,Nie Lin,Kang Zhu,Zhiqiang Lin,Yiming Ren,Chunyang Jiang,Yiyao Yu,Zekun Wang,Tiezhen Wang,Wenhao Huang,Jie Fu,Qunshu Liu,Yujiu Yang,Ge Zhang,Ruibin Yuan,Bei Chen,Wenhu Chen
### Background
近年来，大型多模态模型（LMMs）借助广泛多模态数据集提升了处理复杂知识驱动任务的能力。然而，感知和推理错误持续存在，特别是在解释复杂的视觉数据和推导多模态关系方面尤其限制了它们的效果。
### Innovation
为解决这些问题，本文提出了PIN（Paired and INterleaved multimodal documents）这一新型数据格式，旨在促进视觉和文本知识的深入整合。PIN格式将富含语义的Markdown文件与全面的整体图像相结合，这些图像捕捉文档的整体布局。基于此格式，作者构建并发布了两个大规模开源数据集：PIN-200M（约2亿文档）和PIN-14M（约1400万），这些数据集来源于英文和中文的多种网络和科学来源。为了最大化使用便利性，作者提供了详细的统计分析，并配备了质量信号，使研究人员能够轻松筛选和选择特定任务所需的数据。
### Conclusion
本文为社区提供了一种多功能的数据格式和丰富资源，为基础研究和开发更强大的知识密集型LMM提供了基础。
## 308. `cs.CL` - AgenTracer：LLM智能代理系统中引发故障的是谁？ [PDF](https://arxiv.org/pdf/2509.03312), [HTML](https://arxiv.org/abs/2509.03312)
### Authors
Guibin Zhang,Junhao Wang,Junjie Chen,Wangchunshu Zhou,Kun Wang,Shuicheng Yan
### Background
基于大型语言模型（LLM）的智能代理系统因其复杂性和多模型组成在表现上优于单一代理系统，但这也使得它们更容易发生系统故障。当前最先进的推理LLM在故障归因方面表现仍然不足，准确率通常低于10%。目前，通过反事实回放和编程注入故障来自动标注失败的多代理轨迹的框架尚未出现。
### Innovation
本文提出AgenTracer，这是一种自动化的故障追踪框架，通过反事实回放和编程注入故障来标注失败的多代理轨迹，生成了名为TracerTraj的编目数据集。利用该资源，开发了AgenTracer-8B，这是一个通过多层次强化学习进行训练的轻量级故障定位器，能够高效诊断多代理交互中的错误。在Who&When基准测试中，AgenTracer-8B优于私有大型LLM Gemini-2.5-Pro和Claude-4-Sonnet，提高了18.18%的性能，成为了LLM代理故障归因的新标准。此外，AgenTracer-8B能够为MetaGPT和MaAS等现成的多代理系统提供实际反馈，实现性能提升4.8-14.2%，从而促进自我纠正和自我演化的智能代理AI。
### Conclusion
AgenTracer-8B不仅在技术上领先同类，在实际应用中也显示出显著的性能提升，为多代理系统的故障诊断和优化提供了有效工具，推动了智能代理AI的自我演化过程。
## 309. `cs.CL` - MultiGen：利用LLMs的儿童友好数字多语言语音生成器 [PDF](https://arxiv.org/pdf/2508.08715), [HTML](https://arxiv.org/abs/2508.08715)
### Authors
Xiaoxue Gao,Huayun Zhang,Nancy F. Chen
### Background
生成式语音模型在提高人机交互方面显示出巨大潜力，并在儿童语言学习等真实世界应用中提供有价值的工具。然而，高质量和儿童友好的语音生成对于低资源语言而言仍然具有挑战性，特别是在跨语言和文化背景下。因此，当前的研究提出了一个多语言语音生成模型——MultiGen，旨在为低资源语言提供适合儿童的语言交互。
### Innovation
利用大规模语言模型（LLM）架构创造年龄适宜的多语言语音生成能力，通过在新加坡口音的普通话、马来语和泰米尔语这三种低资源语言中生成具有文化相关性的语音内容，实现与AI系统的有效沟通。
### Conclusion
实验结果表明，MultiGen 在客观度量和主观评价方面均优于基础方法，展示了在语音生成中的优越性能。
## 310. `cs.CL` - That is Unacceptable: the Moral Foundations of Canceling [PDF](https://arxiv.org/pdf/2503.05720), [HTML](https://arxiv.org/abs/2503.05720)
### Authors
Soda Marem Lo,Oscar Araque,Rajesh Sharma,Marco Antonio Stranisci
### Background
‘取缔’是一种由道德驱动的现象，阻碍了安全社交媒体平台的发展，并导致了意识形态分极。为了解决这一问题，该论文提出了取消行为态度检测（CADE）数据集，这是一个关于取缔行为的标注语料库，旨在探讨终端用户在社交媒体上评估取消行为态度时的分歧因素。研究发现，标注者的道德观念在其对取缔行为的感知中起到了独立的解释作用。标注者的判断很大程度上取决于争议事件的类型和涉及的名人。这表明为了更好地理解社交媒体中的伤害实施方式以及开发更敏感的技术进行检测，需要开发更事件中心的数据集。
### Innovation
该研究提出了CADE数据集，首个关于社交媒体上取缔行为的标注语料库，特别关注标注者的道德观念在解释其感知取缔行为中的独立作用。研究发现，标注者的判断受到争议事件类型和涉及的名人影响显著，这揭示了开发更事件中心数据集的重要性，以便更好地理解社交媒体上的危害和应对策略，发展更敏感的技术。
### Conclusion
研究强调了道德因素在取缔行为感知中的重要性，并指出了需要开发更事件中心的数据集来更好地理解社交媒体上的危害实施方式，以及开发更敏感的技术进行检测。
## 311. `cs.CL` - 增强FKG.in：自动化印度食品成分分析 [PDF](https://arxiv.org/pdf/2412.05248), [HTML](https://arxiv.org/abs/2412.05248)
### Authors
Saransh Kumar Gupta,Lipika Dey,Partha Pratim Das,Geeta Trilok-Kumar,Ramesh Jain
### Background
论文的主要背景在于当前缺乏对印度食谱的自动化分析方法，尤其是涉及到印度特有的食品和烹饪方式，存在数字化代表和访问食品成分数据的挑战。现有数据库中缺乏全面而准确的印度食品成分数据。因此，需要开发一种新的方法来自动化分析印度食品成分，提供饮食和营养指导，并确保数据的准确性和可访问性。
### Innovation
该论文的创新之处在于提出了一种结合知识图谱（FKG.in）和大语言模型（LLMs）的新方法来自动化计算印度食谱中的食品成分数据。这种方法旨在补充现有知识库中的食品成分数据，并通过营养数据聚合、食品成分分析和LLM增强的信息解析来提供全面的食品成分分析工作流。此外，该论文还探索了分析印度食谱信息的复杂挑战，例如结构复杂性、多语言性和不确定性，并提议了基于大语言模型的解决方案来应对这些挑战。
### Conclusion
本文提出的AI驱动的知识编纂和信息解析方法是应用无关的、可推广和可复制的。结论表明，该方法能够为任何领域提供解决方案，并且通过对印度食谱的分析，能够获得饮食和健康建议及详细的食品成分信息。未来将在此工作的基础上继续解决实际中的挑战，特别是如何利用自然语言处理技术更好地理解和分析复杂多样的印度食品信息。
## 312. `cs.CL` - EigenBench:一种价值对齐的比较性行为衡量标准 [PDF](https://arxiv.org/pdf/2509.01938), [HTML](https://arxiv.org/abs/2509.01938)
### Authors
Jonathn Chang,Leonhard Piff,Suvadip Sana,Jasmine X. Li,Lionel Levine
### Background
人工智能与人类价值观的对齐是一个紧迫且未解决的问题。由于缺乏衡量价值对齐的定量指标，本文提出了EigenBench：一种用于比较语言模型价值观的黑盒方法。该方法提供了衡量每个模型与给定宪法对齐程度的向量评分。
### Innovation
EigenBench 提出了一个基于黑盒方法的比较性对齐框架，通过将模型之间的判断汇总（使用EigenTrust方法），量化了模型的价值对齐程度。这种方法独特之处在于它无需参考真实标签，而是通过测试模型对不同场景的输出判断敏感性，来区分提示和模型本身的特质。
### Conclusion
实验发现，大多数差异可归因于提示，但少量差异则反映了模型本身的倾向，表明模型对提示的敏感性可能优于单纯依赖模型本身的特性来评估其价值对齐程度。
## 313. `cs.CL` - 短视频传播影响力评级：一个新的现实世界数据集和一个新的大规模图模型 [PDF](https://arxiv.org/pdf/2503.23746), [HTML](https://arxiv.org/abs/2503.23746)
### Authors
Dizhan Xue,Shengsheng Qian,Chuanrui Hu,Changsheng Xu
### Background
短视频平台获得了巨大的流行度，吸引了全球数百万甚至数十亿用户的兴趣。近期的研究强调了分析短视频传播的重要性和价值，这通常涉及到发现商业价值、公众意见和用户行为等方面。这些研究推动了对短视频传播的研究，促使人们开发新的工具和技术来量化和预测短视频的传播影响力。这项研究旨在提出一个全新的短视频传播影响力评级（SPIR）任务，并从数据集和方法论的角度促进短视频传播的研究。
### Innovation
这项研究的主要创新包括：1）提出了一个新的称为Cross-platform Short-Video (XS-Video)的数据集，包含117,720个视频、381,926个样本和535个主题，涵盖了5个最大的中国平台，并且这些数据被标注为传播影响力从0到9的级别。这是第一个包含跨平台数据或提供所有关注、点赞、分享、收藏、粉丝、评论及评论内容的大型短视频数据集。2）基于强大的判别能力和知识推理能力，该研究提出了一个新的大型图模型NetGPT，该模型采用了一种新颖的三阶段训练机制，能够理解和分析短视频传播网络，预测短视频的长期传播影响力。实验结果表明，该模型在分类和回归度量方面均优于其他方法。
### Conclusion
综合实验结果表明，提出的日GPT模型在短视频传播影响力评级任务上表现出色。该研究通过一个大规模的新数据集和一个基于大规模图模型的方法，极大地促进了短视频传播研究的发展。
## 314. `cs.CL` - 如果我不透露真正的答案，我该如何发布我的大语言模型基准？ [PDF](https://arxiv.org/pdf/2505.18102), [HTML](https://arxiv.org/abs/2505.18102)
### Authors
Takashi Ishida,Thanawat Lodkaew,Ikko Yamane
### Background
发布大语言模型（LLM）基准可能会导致未来模型受到无意或故意污染的风险，因为基准可能被用于训练或选择模型。尽管一种常见的缓解策略是保持基准的私密性，并让参与者提交他们的模型或预测给主办方，但这仍然需要对单一组织的信任，并且仍然可以通过重复查询允许测试集过拟合。此论文提出的方案是在不完全泄露正确答案的情况下发布基准，同时保持对LLM的开放评估能力。作者通过向答案中注入随机性来实现这一目标，即准备多个逻辑上正确的答案，但在基准中仅包含其中一个作为解决方案。这种方法降低了基准的最佳可能准确率，有助于防止透露真实答案，同时也提供了一种检测数据污染的方法。
### Innovation
提出了一种在不完全暴露基准问题正确答案的情况下发布问题的方法，通过准备多个逻辑上正确但仅包含一个作为基准答案的解决方案来注入随机性，这不仅减少了解决最佳的准确率，如贝叶斯准确率，还提供了一个检测数据污染的测试。即使完全有能力的模型也不应超过贝叶斯准确率，否则可以视为数据污染的强烈信号。此方法被验证适用于广泛基准、模型和训练方法，能够准确检测数据污染
### Conclusion
通过使用注入随机性的方法发布基准，可以有效避免问题真实答案的暴露问题，同时也提供了一种有效的检测数据污染的方法。实验结果表明，该方法在广泛的应用场景中能够准确地检测出数据污染。
## 315. `cs.CL` - Oyster-I：传统拒绝之外的建设性安全对齐以实现负责任的语言模型 [PDF](https://arxiv.org/pdf/2509.01909), [HTML](https://arxiv.org/abs/2509.01909)
### Authors
Ranjie Duan,Jiexi Liu,Xiaojun Jia,Shiji Zhao,Ruoxi Cheng,Fengxiang Wang,Cheng Wei,Yong Xie,Chang Liu,Defeng Li,Yinpeng Dong,Yichi Zhang,Yuefeng Chen,Chongwen Wang,Xingjun Ma,Xingxing Wei,Yang Liu,Hang Su,Jun Zhu,Xinfeng Li,Yitong Sun,Jie Zhang,Jinzhao Hu,Sha Xu,Yitong Yang,Jialing Tao,Hui Xue
### Background
大型语言模型（LLMs）通常部署了安全机制以防止有害内容的生成。目前大多数方法集中在对抗恶意行为者所造成的风险，往往将这些风险视为敌对的事件，并依赖于防御性的拒绝措施。然而，在现实应用场景中，风险也来自心理困扰下的非恶意用户，他们寻求帮助可能会有自伤的意图等。在这种情况下，模型的回应能够强烈地影响用户的后续行为。简单的拒绝可能导致用户重复请求或升级行为，甚至转向不安全的平台，恶化最终结果。
### Innovation
我们提出了建设性安全对齐（CSA），这是一个以人为中心的框架，它不仅保护免受恶意滥用，还能够积极引导脆弱用户向安全和有帮助的结果发展。CSA通过博弈论预测用户反应，精细划分风险边界和具有可解释性的推理控制，将安全转化为信任构建的过程。Oyster-I（Oy1）融合了这些功能，并展示了在保持高通用能力的同时实现了最先进的安全性能。在我们的建设性基准测试中，它表现出接近GPT-5的强建设性参与，并且在Strata-Sword突袭数据集上展示了无与伦比的鲁棒性，几乎达到了GPT-o1的水平。CSA从以拒绝为主导转变为以指导为主导的安全策略，重新定义了模型与用户之间的关系，旨在实现既安全又有意义帮助的系统。
### Conclusion
通过将CSA应用于Oyster-I（Oy1），我们重新定义了模型与用户之间的关系，目标是构建的系统不仅是安全的，而且是真正有用的。我们还发布了Oyster-I、代码和基准测试，以支持负责任和用户中心的人工智能系统的发展。
## 316. `cs.CL` - 基于句态变换器的方法从攻击描述到漏洞 [PDF](https://arxiv.org/pdf/2509.02077), [HTML](https://arxiv.org/abs/2509.02077)
### Authors
Refat Othman,Diaeddin Rimawi,Bruno Rossi,Barbara Russo
### Background
在安全领域，漏洞经常在被利用的情况下未能被及时发现。本文中的漏洞是指在Common Vulnerabilities and Exposures (CVE)报告中公开披露的技术缺陷。建立攻击与漏洞之间的关联对于及时的突发事件响应至关重要，因为这为防御者提供了即时的、有价值的洞察。然而，手动将攻击与CVE进行映射是不可行的，因此推动了自动化的需求。
### Innovation
本文评估了14种最先进的（SOTA）句态变换器模型，用于自动从攻击描述中识别漏洞。实验证明，多问答MPNet基底点积V1（MMPNet）模型在使用攻击技术描述时表现最佳，取得了89.0的F1分数，84.0的精确度和94.7的召回率。此外，MMPNet模型识别出的漏洞中有56%与MITRE漏洞仓库中的攻击描述相关，同时该模型检测到的61%的漏洞与MITRE漏洞仓库中的记录相匹配。一项手动检查结果显示，存在275个预测链接未在MITRE仓库中记录。
### Conclusion
自动化将攻击技术与漏洞关联不仅增强了软件安全事件的检测和响应能力，还缩短了漏洞可利用的时间，从而促进了更安全系统的开发。
## 317. `cs.CL` - 随机注意力是否足以进行序列建模？解离变换器中可学习组件 [PDF](https://arxiv.org/pdf/2506.01115), [HTML](https://arxiv.org/abs/2506.01115)
### Authors
Yihe Dong,Lorenzo Noci,Mikhail Khodak,Mufan Li
### Background
变换器架构是现代大型语言模型（LLMs）成功的关键部分，部分原因是它能够通过仅使用基于梯度的学习进行下一个标记预测来执行广泛的任务，包括数学推理、记忆和检索。尽管变换器的核心组件是自我注意力机制，但论文提出了一个问题：性能提升有多大程度，以及哪些方面可以归因于自我注意力机制。为了解决这个问题，研究者将标准变换器与在初始化时冻结MLP层或注意力权重的变体进行了比较。研究结果令人惊讶地发现，即使冻结键和查询权重的注意力机制仍能形成归纳头，并且能够竞争性地在语言模型上表现。通过证明一种新的表达能力结果，进一步探讨了与冻结键和查询权重的变换器模型相关的问题。为了解更好更难以分离的因素，研究者设计了一种MixiT架构，使用完全随机的注意力分数，并且能够证明稳定信号传播，解决了随机变换器的历史问题。基于MixiT的成功和失败，本文理解了每个变换器组件的作用，例如注意力在上下文推理方面发挥重要作用，而MLP对于知识存储负责，两者间存在着协作关系。研究结果表明，变换器架构具有一种内置的形成专业电路的归纳偏见，即使没有可学习的注意力权重也是如此。
### Innovation
本文设计了MixiT架构，一种具有完全随机注意力得分的架构，能够展示稳定的信号传播能力，并通过证明新的变换器模型表达能力结果来隔离注意力和MLPs的贡献。文章还探讨了变换器组件之间的协作关系及其如何影响模型的性能。研究结果表明，尽管冻结了注意力权重，但变换器模型仍能够形成高效的电路，这揭示了变换器架构自身具有的独特能力。
### Conclusion
本文研究了注意机制在序列建模中的作用，并通过设计MixiT和分析实验结果，得出了变换器架构有一种内在的倾向，能在没有学习型注意力权重的情况下形成有效电路。
## 318. `cs.CL` - 理解空间——火箭科学——只有顶级推理模型能够解决空间理解任务 [PDF](https://arxiv.org/pdf/2509.02175), [HTML](https://arxiv.org/abs/2509.02175)
### Authors
Nils Hoehing,Mayug Maniparambil,Ellen Rushe,Noel E. O'Connor,Anthony Ventresque
### Background
当前开源和前沿商业视觉-语言模型（VLMs）在相对空间理解和对象顺序理解方面表现较差，而基于链式推理的模型在推理方面表现出出乎意料的高性能。为了系统评估模型在这方面的表现，提出了RocketScience基准，该基准由全新的现实世界图像-文本对组成，主要侧重于相对空间理解和物体顺序。基准设计旨在对人类易于理解而对当前VLMs极具挑战性，这在实验中得到了验证。
### Innovation
提出了一个名为RocketScience的新颖开源对比VLM基准，完全使用全新的真实世界图像-文本对，主要测试相对空间理解和对象顺序理解。基准设计的目的是对人类易于理解而对现有VLMs极具挑战性，并且实验结果证明了这一点。此外，通过对链式推理模型进行解缠分析，分离了物体定位和空间推理的贡献，研究发现基准性能受限于空间推理而非物体定位能力。
### Conclusion
开源和商业前沿的VLMs在相对空间理解方面的表现令人震惊地差，而推理模型却有出乎意料的高表现。RocketScience基准能够有效识别这一问题，通过解缠分析发现，空间推理能力是模型性能的瓶颈。数据集采用CC-BY-4.0许可证发布，并提供了评估代码。
## 319. `cs.CL` - 扩展FKG.in：向食品声明可追溯网络迈进 [PDF](https://arxiv.org/pdf/2508.16117), [HTML](https://arxiv.org/abs/2508.16117)
### Authors
Saransh Kumar Gupta,Rizwan Gulzar Mir,Lipika Dey,Partha Pratim Das,Anirban Sen,Ramesh Jain
### Background
全球食品领域充斥着关于食品的各种科学、文化及商业宣称，从严谨研究的健康益处（如益生菌改善肠道健康）到误导性的陈述（如浸泡过的杏仁使人变得更聪明），再到模糊的承诺（如超级食品增强免疫力）和根深蒂固的文化信念（如冷食会引起咳嗽）。尽管这些宣称影响广泛，但追踪、验证和背景化这些宣称的基础设施仍碎片化且不成熟。因此，本文提出了一种食品宣称可追溯网络（FCN）作为我们正在逐步构建的印度食品知识图谱（FKG.in）的扩展。该网络整合了经过精炼的数据输入、结构化模式以及具有溯源意识的过程管线，用于食品相关宣称的提取和验证。
### Innovation
FCN通过融入结构化、可验证和可解释的方式建模食品宣称及其可追溯性，旨在为更加透明和负责任的食品知识生态系统做出贡献，支持研究人员、政策制定者以及最重要的是普通消费者在充满饮食声明的环境中导航。此外，该方法可以使FKG.in作为应用之一，但其本身是应用无感且可适应其他地理、烹饪或监管环境。本文中的方法利用了推特数据和大规模语言模型进行概念验证的开发展示.
### Conclusion
本研究通过扩展印度食品知识图谱，提出了食品宣称可追溯网络的概念，旨在建立一个更加透明和负责任的食品知识生态系统，支持各种不同用户在庞大的饮食声称中进行导航。该方法不仅适用于印度食品领域，也具有跨地理、烹饪和监管环境的应用潜力。
## 320. `cs.CV` - 通过表示学习解决多属性偏差 [PDF](https://arxiv.org/pdf/2509.03616), [HTML](https://arxiv.org/abs/2509.03616)
### Authors
Rajeev Ranjan Dwivedi,Ankur Kumar,Vinod K Kurmi
### Background
现实世界中的图像经常包含多种重叠的缺陷，如纹理、水印、性别化妆、场景对象配对等，这些缺陷会共同影响现代视觉模型的性能，削弱它们的稳健性和公平性。单独处理这些偏差是不够的，因为缓解一种偏差往往会导致其他偏差的产生或加重。
### Innovation
我们提出了Generalized Multi Bias Mitigation (GMBM)，这是一种通过训练时仅需组标签、测试时最小化偏差的精简两阶段框架。GMBM包含两个部分：Adaptive Bias Integrated Learning (ABIL) 和Gradient Suppression Fine Tuning。ABIL通过为每个属性训练编码器并将其与主干网络集成，使得分类器能够明确识别这些偏差；Gradient Suppression Fine Tuning则通过从主干网络的梯度中消除偏差方向，保留一个单一紧凑的网络，忽略所有刚才学习到的偏差。此外，由于现有的偏差度量在子群不平衡和训练测试分布变化的情况下失效，我们引入了Scaled Bias Amplification (SBA)，一种测试时的度量，用于分离模型引起的偏差增强与分布差异。
### Conclusion
我们在FB CMNIST、CelebA、COCO上的实验表明，GMBM提高了最差群体的准确性，减少了多属性偏差放大，并在SBA指标上达到了新的低点，即使偏差复杂性和分布变化加剧也是如此，这使GMBM成为第一个实用的、端到端的多属性偏差解决方案。
## 321. `cs.CV` - 用于MIDOG 2025挑战赛中检测和分类核分裂的 teacher-student 模型 [PDF](https://arxiv.org/pdf/2509.03614), [HTML](https://arxiv.org/abs/2509.03614)
### Authors
Seungho Choe,Xiaoli Qin,Abubakr Shafique,Amanda Dy,Dimitri Androutsos,Susan Done,April Khademi
### Background
对于病理学家而言，计数有丝分裂象是一个耗时的过程，容易导致观察者之间的一致性差异。人工智能（AI）有望通过自动检测有丝分裂象并同时保持决策一致性来解决这一问题。然而，AI工具容易受到领域迁移的影响，即由于训练集和测试集之间存在显著差异，包括器官形态学多样性、物种差异和染色协议变化等因素，而导致性能大幅下降。由于有丝分裂象的数量远少于正常细胞核的数量，检测任务面对的是严重不平衡的数据问题。因此，本研究提出了一个针对有丝分裂检测（Track 1）和异常有丝分裂分类（Track 2）的像素级分割方法，用以解决上述问题。
### Innovation
本文创新地将有丝分裂检测（Track 1）和有丝分裂分类（Track 2）整合到一个统一的框架中。提出的教师-学生模型以U-Net分割骨干为基础，融入了对抗性特征学习和领域对抗性训练的模块，采用教师-学生策略，不仅生成有丝分裂和正常细胞核的像素级伪标签，还增强了特征区分能力，提高了模型的鲁棒性。此外，提出了一种多尺度CNN分类器，充分利用了分割模型的特征图进行多任务学习，从而提高了有丝分裂检测和分类的准确性。
### Conclusion
在初步测试集上，算法在Track 1中的F1得分达到了0.7660，在Track 2中的平衡准确率达到了0.8414，证明了将基于分割的检测与分类集成到统一框架中的方法的有效性。
## 322. `cs.CV` - Reg3D: 用于3D场景理解的重建几何指令调整 [PDF](https://arxiv.org/pdf/2509.03635), [HTML](https://arxiv.org/abs/2509.03635)
### Authors
Hongpei Zheng,Lintao Xiang,Qijun Yang,Qian Lin,Hujun Yin
### Background
大型多模态模型（LMMs）的迅速发展促进了2D视觉理解的进步，但将其能力扩展到3D场景理解仍是一个重大挑战。现有方法主要依靠文本监督，这无法提供学习稳健3D空间表示所需的几何约束。
### Innovation
介绍了一种名为Reg3D的新颖重建几何指令调整（Reconstructive Geometry Instruction Tuning）框架，通过直接将几何意识的监督融入训练过程来解决这一限制。Reg3D采用双重监督范式，利用3D几何信息作为输入和明确的学习目标。具体来说，设计了对象级别和帧级别的重建任务，在双重编码器架构中强化几何一致性，以促进空间推理能力的发展。
### Conclusion
在ScanQA、Scan2Cap、ScanRefer和SQA3D上的实验表明，Reg3D能够显著提高性能，建立了空间意识多模态模型的新训练范式。
## 323. `cs.CV` - treeX: 无监督森林密点云树实例分割 [PDF](https://arxiv.org/pdf/2509.03633), [HTML](https://arxiv.org/abs/2509.03633)
### Authors
Josafat-Mattias Burmeister,Andreas Tockner,Stefan Reder,Markus Engel,Rico Richter,Jan-Peter Mund,Jürgen Döllner
### Background
近距离激光扫描技术能够提供森林群体的详细三维图像，但需要有效的软件来处理三维点云数据并区分单株树木。虽然最近的研究引入了深度学习方法进行树实例分割，但这些方法需要大量标注数据和强大的计算资源。因此，提供了一种资源高效的无监督树分割方法，该方法结合了基于聚类的树干检测和区域生长法来确定树冠边界，旨在提高资源效率并适应不同的激光扫描数据特点（地面激光扫描和无人机激光扫描）。
### Innovation
提出了一种修订版的树X算法，作为深度学习方法的资源高效替代方案，特别适用于地面激光扫描（TLS和PLS）和无人机激光扫描（ULS）数据。此算法通过结合聚类树干检测与区域生长法树冠划分，减少运行时间和提高准确性，在特定数据条件下，其表现优于或接近深度学习方法。该算法还提供两个参数预设，分别适用于地面激光扫描和无人机激光扫描数据。
### Conclusion
该方法对于数据特征与算法设计相匹配的场景（足够的树干可见性和点云密度）是一种资源高效的替代深度学习方法的选择，并可半自动生成用于深度学习模型的标签。为了促进更广泛的应用，该方法提供了开源的Python实现。
## 324. `cs.CV` - 基于迁移学习的CNN模型用于基于叶脉模式的植物物种识别 [PDF](https://arxiv.org/pdf/2509.03729), [HTML](https://arxiv.org/abs/2509.03729)
### Authors
Bandita Bharadwaj,Ankur Mishra,Saurav Bharadwaj
### Background
本研究评估了三种深度学习架构（ResNet50、MobileNetV2和EfficientNetB0）在基于叶脉模式的自动植物物种分类中的效果，叶脉模式是分类中重要的形态特征，具有很高的分类学意义。
### Innovation
研究采用瑞典叶子数据集（包含15种植物每种75张图像，共计1125张图像），通过训练和测试阶段使用标准性能指标展示了模型的效果。研究发现，EfficientNetB0相比其他两种模型表现最好，具有更高的精度、召回率和F1分值，显示了其在叶脉特征分类中的稳健性能。
### Conclusion
研究结果强调了深度学习，尤其是EfficientNetB0，在利用叶脉特征进行自动化植物分类工具开发中的潜在应用价值。
## 325. `cs.CV` - 向量化的骨架掩蔽建模中的高效通用特征预测 [PDF](https://arxiv.org/pdf/2509.03609), [HTML](https://arxiv.org/abs/2509.03609)
### Authors
Shengkai Sun,Zefan Zhang,Jianfeng Dong,Zhiyong Cheng,Xiaojun Chang,Meng Wang
### Background
最近，掩蔽自动编码器（MAE）的进展显著推动了基于骨架的动作识别的自监督学习。然而，当前大多数方法将重建目标局限于原始关节坐标或它们的简单变体，导致了计算冗余和有限的语义表示能力。
### Innovation
我们提出了一个新的通用特征预测（GFP）框架，用于高效的掩蔽骨架建模。我们的创新点在于，通过使用高层次特征预测替换了传统的低层次重建，预测从局部运动模式到全局语义表示的特征。此外，我们引入了一个协作学习框架，该框架能够动态地在空间-时间层次结构中生成多样化的监督信号，避免对离线计算的预设特征的依赖。框架中还包含了约束优化来保证特征的多样性和防止模型崩溃。
### Conclusion
我们在NTU RGB+D 60、NTU RGB+D 120和PKU-MMD上的实验展示了我们方法的优势：相较于标准的掩蔽骨架建模方法，训练速度提高了6.2倍，并且在表示质量方面表现更优，实现了多种下游任务中的最佳性能。
## 326. `cs.CV` - LayoutGKN：楼地板平面图的图形相似性学习 [PDF](https://arxiv.org/pdf/2509.03737), [HTML](https://arxiv.org/abs/2509.03737)
### Authors
Casper van Engelenburg,Jan van Gemert,Seyran Khademi
### Background
楼地板平面图用于描绘建筑布局，并经常以图的方式表示，以捕捉潜在的空间关系。比较这些图对于搜索引擎、聚类和数据可视化等应用至关重要。现有的最成功的图形比较方法，例如图形匹配网络，依赖于在节点级别在图之间进行昂贵的中间交互，这导致推理时间较慢。因此，需要一种更高效的方法来比较图形相似性，既要确保计算性能，又要保持准确度。
### Innovation
我们提出了LayoutGKN，一种更有效的图形相似性学习方法。LayoutGKN通过在联合嵌入架构的结束部分延迟跨图的节点级别交互来实现这一目标。具体来说，它使用可微图核作为最终学习节点级别的嵌入之间的距离函数。实验表明，LayoutGKN在计算相似性方面表现优于或不低于图形匹配网络的同时，显著提高了计算速度。
### Conclusion
LayoutGKN是为提高图形比较效率并保持算法准确性的突破性方法。该方法通过优化节点级别交互的时间点，成功地提高了图形比较的速度，同时保持或提升了相似性计算的准确性。相关代码和数据已公开。
## 327. `cs.CV` - 轻量级图像分割方法在超声心动图中的应用 [PDF](https://arxiv.org/pdf/2509.03631), [HTML](https://arxiv.org/abs/2509.03631)
### Authors
Anders Kjelsrud,Lasse Løvstakken,Erik Smistad,Håvard Dalen,Gilles Van De Vyver
### Background
超声心动图中的左心室分割精确性可以实现自动提取临床测量值如容积和射血分数。尽管nnU-Net模型表现良好，但其体积庞大且运行速度慢，限制了实时使用。因此，研究者们探索了高效的心脏分割方法，以达到在准确度和速度之间的良好平衡。
### Innovation
通过去除复杂数据增强和大型模型容量不提供显著提升的部分，研究团队发现简单的仿射增强和深度监督对性能提升至关重要。基于此，他们开发了一种轻量级U-Net模型（参数从33M减少到2M），在CAMUS数据集上的分割结果与nnU-Net相当（Diece分数分别为0.93/0.85/0.89 vs 0.93/0.86/0.89，$p>0.05$），而体积减少了16倍，处理速度提高4倍（1.35ms vs 5.40ms每帧）。实验室内部测试进一步证实了其良好的泛化能力。
### Conclusion
研究团队提出的方法能实现在保持准确率的前提下减轻模型大小和提高处理速度的目标，为实时超声心动图分析提供了有效的解决方案。
## 328. `cs.CV` - 通过视觉聚类指导的视觉语言模型提示学习 [PDF](https://arxiv.org/pdf/2509.03803), [HTML](https://arxiv.org/abs/2509.03803)
### Authors
Mengyu Gao,Qiulei Dong
### Background
提示学习近期引起了对适应预训练视觉-语言模型（如CLIP）到下游识别任务的高度关注。然而，现有的CLIP基提示学习方法在处理细粒度数据集方面能力有限。
### Innovation
提出了一种通过视觉聚类指导的提示学习方法CaPL，该方法使用因果推理技术构建视觉聚类，并通过属性解耦模块将视觉特征分解为非个体属性和个体属性；再通过粒度学习模块使用这两种因果推理策略构建视觉粒度，以提高细粒度类别识别的有效性。
### Conclusion
在15个数据集上的广泛实验表明，CaPL方法显著优于最先进的提示学习方法，特别是在细粒度数据集上表现更加出色。
## 329. `cs.CV` - SLENet：一种增强导向网络用于水下伪装目标检测 [PDF](https://arxiv.org/pdf/2509.03786), [HTML](https://arxiv.org/abs/2509.03786)
### Authors
Xinxin Wang,Han Sun,Ningzhong Liu,Huiyu Zhou,Yinan Yao
### Background
水下伪装目标检测（UCOD）旨在识别与水下环境融合度高的物体。这是一个对海洋生态学至关重要的任务。然而，光学失真、浑水和海洋生物的复杂特性使得精确识别变得非常困难。
### Innovation
为了应对这些挑战，作者提出了UCOD任务和DeepCamo基准数据集。同时，他们还提出了一种新型框架——语义定位与增强网络（SLENet）。SLENet包括Gamma-Asymmetric Enhancement (GAE) 模块、定位引导分支（LGB）以及多尺度监督解码器（MSSD），以便于增强多尺度特征表示并生成富含全局语义信息的位置图，从而指导多尺度监督解码器生成更准确的预测。
### Conclusion
实验结果证明，SLENet在DeepCamo数据集以及三个基准COD数据集上均优于最先进的方法，表明其在更广泛的COD任务中的高度通用性。
## 330. `cs.CV` - 基于视频数据集训练图像扩散模型 [PDF](https://arxiv.org/pdf/2509.03794), [HTML](https://arxiv.org/abs/2509.03794)
### Authors
Juhun Lee,Simon S. Woo
### Background
传统的图像扩散模型在独立采样的静态图像上进行训练，但在生成式建模中，这种固定的任务协议通过静态快照捕捉动态世界的信息是缺乏的。这导致了收敛速度慢、分布覆盖有限和泛化能力降低。
### Innovation
本文提出了一种简单且有效的训练策略，利用连续视频帧中存在的时间归纳偏差来改进扩散模型的训练效果。该方法无需对架构进行修改，可以无缝集成到标准扩散训练管道中。通过在HandCo数据集上的评估，该方法使模型更快地收敛（超过2倍的速度），并在训练和验证分布中实现了更低的FID分数，并提高了生成的多样性，促使模型捕捉时间差异中的有意义变化。此外，还提供了正则项优化分析，表明这种正则项减少了梯度方差，促进了更快的收敛速度。
### Conclusion
通过引入时间归纳偏差的利用，本文提出的训练策略显著提高了图像扩散模型训练效果，特别是在动态数据上的表现更为出色。
## 331. `cs.CV` - MedVista3D：基于3D CT疾病的诊断、理解和报告的视觉语言建模 [PDF](https://arxiv.org/pdf/2509.03800), [HTML](https://arxiv.org/abs/2509.03800)
### Authors
Yuheng Li,Yenho Chen,Yuxiang Lai,Jike Zhong,Vanessa Wildman,Xiaofeng Yang
### Background
在临床实践中，放射诊断错误（如阅读不足、注意盲区和沟通失败）仍然普遍。这些问题通常源于局部异常的遗漏、全球上下文的有限以及报告语言的一致性差异。在3D成像中，由于需要检查大量的切片，这些挑战被进一步放大。应对这些挑战需要具备精确局部检测、全局体积级推理和语义一致自然语言报告的系统。然而，现有的3D视觉语言模型无法同时满足这三项需求，它们在空间推理中的局部-全局理解能力不足，并且在处理未标定的放射学报告中的变异性和噪声方面存在困难。
### Innovation
本文提出了一种名为MedVista3D的多尺度语义增强视觉语言预训练框架，用于3D CT分析。MedVista3D通过局部和全局图像-文本对齐在全体积上下文中进行细粒度表示学习，以实现联合疾病检测和整体解释。为了应对报告变异性的挑战，引入了语言模型重写和放射学语义匹配银行，从而实现语义感知对齐。MedVista3D在零样本疾病分类、报告检索和医学视觉问答等任务上取得了最先进的性能，并且在器官分割和预后预测等任务上表现出良好的泛化能力。
### Conclusion
MedVista3D在3D CT疾病检测、理解和报告方面具有出色的表现，解决了现有的3D视觉语言模型不能同时满足的多种需求。通过代码和数据集的发布，该框架有望进一步改善临床放射诊断的精确性和一致性。
## 332. `cs.CV` - Singular Value Few-shot Adaptation of Vision-Language Models [PDF](https://arxiv.org/pdf/2509.03740), [HTML](https://arxiv.org/abs/2509.03740)
### Authors
Taha Koleilat,Hassan Rivaz,Yiming Xiao
### Background
现有的视觉-语言模型（VLMs），如CLIP，展示了在多种应用中具有令人印象深刻的零样本和少样本学习能力。然而，将这些模型适应新的细粒度领域仍然困难重重，主要依赖于提示工程技术，且完全微调模型成本高昂。现有适应方法依赖如提示词令牌和适配模块等增强组件，这些可能会限制适应质量，破坏模型稳定性，甚至影响预训练中学到的知识。本文提出了一种新颖的多模态且参数高效的方法CLIP-SVD，利用奇异值分解（SVD）来修改CLIP的内部参数空间，而不添加额外模块。这种方法只调整CLIP参数矩阵的奇异值，重新缩放基向量以适应特定领域，同时保留预训练模型。因此，CLIP-SVD使用不到总参数的0.04%进行微调，仍能提高适应效果并保留模型的泛化能力，同时在11个自然和社会科学以及10个生物医学数据集上取得了最先进的分类结果
### Innovation
CLIP-SVD所提出的方法利用奇异值分解（SVD）来修改CLIP的内部参数空间，不增加额外的模块。它只调整CLIP参数矩阵的奇异值，使得基础向量能够针对特定领域进行重新缩放，而保留预训练模型的基础结构。这使得CLIP-SVD能够在少于0.04%总参数的情况下实现微调，提高了适应性能，同时保留了模型的泛化能力。此外，通过自然语言分析方法，提供了对CLIP适应效果和动态过程的可解释性分析
### Conclusion
CLIP-SVD在多种自然和社会科学以及生物医学数据集上取得了最先进的分类结果，其在少样本条件下的准确性和泛化能力超过了之前的模型。此外，通过自然语言的方法分析了CLIP的适应效果，增强了模型的解释性。所提出的方法证明了较少参数调整可以实现高效的适应效果，对于促进视觉-语言模型在更复杂和精细任务的应用具有重要意义。
## 333. `cs.CV` - 通过运动的聚焦：RGB-事件协作单元稀疏化以实现高效目标检测 [PDF](https://arxiv.org/pdf/2509.03872), [HTML](https://arxiv.org/abs/2509.03872)
### Authors
Nan Yang,Yang Wang,Zhanwen Liu,Yuchao Dai,Yang Liu,Xiangmo Zhao
### Background
现有的RGB-事件检测方法在特征提取和融合过程中，对低信息区域（图像背景和事件数据中的非事件区域）进行了均匀处理，导致高计算成本和性能不佳。为了减少特征提取过程中的计算冗余，研究人员分别为图像和事件模态提出了单元稀疏化方法，但这些方法采用固定数量或阈值进行单元选择，对于不同复杂度的样本很难保留有效的单元。
### Innovation
提出了FocusMamba，实现了多模态特征的自适应协作稀疏化以及高效互补信息集成。具体而言，设计了事件引导的多模态稀疏化（EGMS）策略，通过利用事件摄像头感知的场景内容变化来识别和自适应消除每个模态内的低信息区域。基于稀疏化结果，提出了跨模态焦点融合（CMFF）模块以有效捕捉和整合来自两个模态的互补特征。
### Conclusion
在DSEC-Det和PKU-DAVIS-SOD数据集上的实验表明，所提出的方法在准确性和效率方面都优于现有方法。代码将在此提供：this https URL。
## 334. `cs.CV` - SalientFusion: Context-Aware Compositional Zero-Shot Food Recognition [PDF](https://arxiv.org/pdf/2509.03873), [HTML](https://arxiv.org/abs/2509.03873)
### Authors
Jiajun Song,Xiaoou Liu
### Background
食品识别已经引起了显著关注，但新技术的出现速度要求识别未见过的食品类别，推动了零样本食品学习（ZSFL）的发展。然而，Compositional Zero-Shot Food Recognition（CZSFR）任务面临三个挑战：(1)背景信息冗余会分散模型对有意义的食品特征的学习注意力；(2)主食与配菜的角色混淆导致分类错误；(3)单个特征的语义偏见可能导致理解混乱。
### Innovation
我们提出了SalientFusion方法，这是一种具有上下文感知功能的CZSFR方法，包括两个组成部分：(1)SalientFormer，它去除背景冗余，使用深度特征解决角色混淆问题；(2)DebiasAT，它通过与视觉特征对齐提示缩减语义偏见。此方法在我们提出的新基准CZSFood-90和CZSFood-164上表现出最佳结果，并且在通用CZSL数据集上也取得了最佳效果。
### Conclusion
通过我们的基准测试结果，SalientFusion方法在这些基准和最流行的通用CZSL数据集上都达到了最佳性能。该代码可在<这个网址>获取。
## 335. `cs.CV` - STA-Net: 一种用于轻量级植物病害分类的解耦形状和纹理注意力网络 [PDF](https://arxiv.org/pdf/2509.03754), [HTML](https://arxiv.org/abs/2509.03754)
### Authors
Zongsen Qiu
### Background
面对全球粮食安全需求的提升，精准农业和基于深度学习的植物病害诊断技术变得至关重要。然而，在边缘设备上部署高精度的模型具有挑战性。大多数轻量级网络使用设计来实现通用对象识别注意力机制，它们在捕捉植物病理特征（如不规则病变形状和复杂纹理）方面表现不佳。
### Innovation
本文提出了一种两阶段解决方案：首先，采用无需训练的神经架构搜索方法（DeepMAD）为边缘设备创建高效的网络骨干结构；其次，引入了解耦形状和纹理注意力模块（STAM）。STAM将注意力机制分为两个分支：一个使用可变形卷积（DCNv4）来提高形状意识，另一个使用Gabor滤波器组来增强纹理意识。
### Conclusion
本文提出的STA-Net模型在公共CCMT植物病害数据集上的参数量为401K，计算量为51.1M FLOPs，并达到了89.00%的准确率和88.96%的F1分数，表明解耦注意力机制通过集成领域知识，为边缘部署的精确农业AI带来了潜在的发展路径。源代码已发布。
## 336. `cs.CV` - OccTENS: 3D空间占用世界模型通过时间下一尺度预测 [PDF](https://arxiv.org/pdf/2509.03887), [HTML](https://arxiv.org/abs/2509.03887)
### Authors
Bu Jin,Songen Gu,Xiaotao Hu,Yupeng Zheng,Xiaoyang Guo,Qian Zhang,Xiaoxiao Long,Wei Yin
### Background
传统的生成模型在处理3D场景的精细三维几何和动态变化时遇到了巨大挑战，尤其是在视觉生成过程中。近年来基于自回归的模型能够预测车辆运动和未来占用场景，但这些模型通常存在计算效率低下、长时生成时间退化以及缺乏控制性的问题。
### Innovation
本文提出了一种名为OccTENS的生成型占用世界模型，该模型通过时间下一尺度预测（Temporal Next-Scale Prediction，TENS）任务，将时间序列建模问题分解为时空尺度生成建模和时间场景预测。此外，通过引入TensFormer和整体姿态聚合策略，提高了占据序列的时间因果关系和空间关系管理的灵活性和可扩展性，从而增强了姿态可控性。
### Conclusion
实验表明，OccTENS在保持占用场景高质量生成的同时，还具有更快的推理速度，超越了现有的先进方法。
## 337. `cs.CV` - EGTM: 事件引导的高效湍流抑制 [PDF](https://arxiv.org/pdf/2509.03808), [HTML](https://arxiv.org/abs/2509.03808)
### Authors
Huanan Li,Rui Fan,Juntao Guan,Weidong Hao,Lai Rui,Tong Wu,Yikai Wang,Lin Gu
### Background
湍流抑制（TM）旨在消除大气湍流对帧相机引入的随机失真和模糊。现有的先进的深度学习TM方法从多个受损的帧中提取湍流线索，以找到所谓的“幸运帧”，实现幸运融合。然而，这种方法需要高性能网络学习同步帧间粗粒度的湍流动态，因此在计算和存储效率上存在不足。事件相机由于其微秒级的时间分辨率，具备解决该瓶颈的潜力，通过高效稀疏和异步成像机制从根本上解决问题。鉴于此，本文提出了事件诱导的'幸运洞察'，揭示了湍流失真与事件流逆时空分布之间的相关性，并在此基础上提出了新的EGTM框架，能够从显式但噪声的湍流事件中提取像素级别的可靠无湍流引导，实现时空幸运融合。此外，构建了首个湍流数据采集系统，贡献了首个实际世界的事件驱动TM数据集。实验结果表明，该方法在模型大小、推理延迟和模型复杂度上分别比现有最先进的TM方法快710倍、214倍和224倍，同时在真实的EGTM数据集上达到最先进的恢复质量（+0.94 PSNR和+0.08 SSIM），证明了引入事件模态进行TM任务的巨大效率优势。
### Innovation
本文的主要创新点包括：1) 提出了'事件诱导的幸运洞察'，揭示了湍流失真与事件流逆时空分布之间的关系；2) 提出了EGTM框架，该框架能够从显式的但噪声的湍流事件中提取像素级别的无湍流引导，实现时空幸运融合；3) 构建了首个实际世界的事件驱动TM数据集。此外，该方法在计算和存储效率上显著提高，达到了最先进的恢复质量。
### Conclusion
本文通过事件相机与EGTM框架的结合，显著提高了湍流抑制的效率和效果，证明了引入事件模态对TM任务的巨大贡献。实验结果表明，该方法在多个性能指标上远超现有技术。
## 338. `cs.CV` - Human Motion Video Generation: A Survey [PDF](https://arxiv.org/pdf/2509.03883), [HTML](https://arxiv.org/abs/2509.03883)
### Authors
Haiwei Xue,Xiangyang Luo,Zhanghao Hu,Xin Zhang,Xunzhi Xiang,Yuqin Dai,Jianzhuang Liu,Zhensong Zhang,Minglei Li,Jian Yang,Fei Ma,Zhiyong Wu,Changpeng Yang,Zonghong Dai,Fei Richard Yu
### Background
人类动作视频生成因广泛应用而吸引了大量的研究兴趣，使得诸如逼真的唱歌头部或能够无缝跟随音乐起舞的动态 avatar 等创新成为可能。然而，现有研究综述集中在个别方法上，缺乏对整个生成过程的全面概述。已有研究缺少对动作视频生成各个子任务及生成过程五个关键阶段深入探讨。
### Innovation
这是首次探讨大型语言模型在提升人类动作视频生成方面的潜力的综述。调查涵盖了超过两百篇论文，涉及视觉、文本和音频三种主要模态的技术进步和趋势。该调研首次全面展示了动作视频生成的五个关键阶段：输入、动作规划、动作视频生成、细化和输出。并且调研内容提供了该领域的全面概述，同时强调了推动重要技术突破的里程碑研究。
### Conclusion
通过该综述，揭示了人类动作视频生成的前景，并可作为开发数字人类综合应用的重要资源。有关这项调查中研究的完整模型列表可以在我们的 Repository 中找到。
## 339. `cs.CV` - Attn-Adapter: 用于视觉-语言模型在线少样本学习的注意力机制 [PDF](https://arxiv.org/pdf/2509.03895), [HTML](https://arxiv.org/abs/2509.03895)
### Authors
Phuoc-Nguyen Bui,Khanh-Binh Nguyen,Hyunseung Choo
### Background
对比视觉-语言模型在零样本图像识别任务中的出色表现，它们在少样本场景中面临挑战，这主要是由于需要使用提示学习进行昂贵的离线微调，这种微调过程有过度拟合的风险。
### Innovation
本文提出了一种名为Attn-Adapter的新颖在线少样本学习框架，通过双注意力机制增强CLIP的适应性。Attn-Adapter通过两个组件——内存注意力适配器和局部-全局注意力适配器——来增强模型的灵活性。内存注意力适配器利用支持样本调整类别嵌入，而局部-全局注意力适配器则整合局部和全局特征以丰富图像嵌入。此架构允许通过少量标记样本进行动态适应，而无需重新训练基础模型。
### Conclusion
Attn-Adapter方法在跨类别和跨数据集泛化方面优于现有最佳方法，并保持了高效的推理能力，适用于不同的CLIP基模型进行扩展。
## 340. `cs.CV` - SPECS: 特定性增强的CLIP-Score在长图像标题评估中的应用 [PDF](https://arxiv.org/pdf/2509.03897), [HTML](https://arxiv.org/abs/2509.03897)
### Authors
Xiaofu Chen,Israfel Salazar,Yova Kementchedjhieva
### Background
随着对生成长而详细的图像描述的兴趣不断增加，标准评估指标变得越来越不可靠。虽然基于N-gram的度量虽然高效，但无法捕捉语义正确性。代表相似性（RS）度量旨在解决这个问题，但由于计算成本高，最初使用有限，尽管近年来硬件有所改进，它们仍然因为与人类判断的相关性较低而不受欢迎。基于大规模语言模型（LLMs）的度量与人类判断的相关性很强，但成本高昂，不适合模型开发中的迭代使用。
### Innovation
我们提出了SPECS（特定性增强的CLIPScore），一个不需要参考的RS度量，专门用于长图像标题评估。SPECS通过对CLIP进行了新的目标修改，强调特定性：奖励正确的细节并惩罚错误的信息。研究表明，SPECS在与人类判断的相关性上与开源基于LLM的度量相当，但效率更高。这使它成为一个在图像描述模型开发中的迭代检查点评估的实用替代方案。
### Conclusion
SPECS在与人类判断的相关性上与基于大规模语言模型的度量相匹配，但比它们更具效率，因此对于迭代评估图像描述模型是一个实用的选择。代码可以在这个链接找到：[https://github.com/example/SPECS]。
## 341. `cs.CV` - 胸部X光生成基础模型 [PDF](https://arxiv.org/pdf/2509.03903), [HTML](https://arxiv.org/abs/2509.03903)
### Authors
Yuanfeng Ji,Dan Lin,Xiyue Wang,Lu Zhang,Wenhui Zhou,Chongjian Ge,Ruihang Chu,Xiaoli Yang,Junhan Zhao,Junsong Chen,Xiangde Luo,Sen Yang,Jin Fang,Ping Luo,Ruijiang Li
### Background
医疗领域中高质量的多样医学图像标注稀缺是开发可靠的AI模型的一大障碍。尽管在生成基础模型方面已经取得了重大技术进步，特别是在自然图像上，但在医学影像上的应用仍需改进。为了应对这一挑战，研究人员开发了一种用于胸部X光医学图像生成的生成视觉-语言基础模型ChexGen。
### Innovation
ChexGen 是一种引入了文本、掩码和边界框指导合成胸部X光片的统一框架的生成视觉-语言基础模型。它基于潜在扩散变换器架构，并以其所使用的最大胸部X光报告-图像配对数据集为基础进行预训练。实验结果显示，该模型能够通过专家评估和定量指标实现准确的X光片合成。此外，模型还能够用于训练数据增强和监督预训练，从而提高了病种分类、检测和分割任务的性能。进一步地，该模型还能创建多样化的患者群体，这些群体增强了模型的公平性。
### Conclusion
本研究支持生成基础模型在建立更准确、数据高效和公正的医学AI系统方面的作用。通过ChexGen，研究人员提出了一个能够应对医学影像中数据稀缺性问题的新方案，并展示了其在多个医学AI任务中的实际应用潜力。
## 342. `cs.CV` - 弱监督学习密集功能对应关系 [PDF](https://arxiv.org/pdf/2509.03893), [HTML](https://arxiv.org/abs/2509.03893)
### Authors
Stefan Stojanov,Linan Zhao,Yunzhi Zhang,Daniel L. K. Yamins,Jiajun Wu
### Background
在重建形状和机器人操作等任务中，跨图像对建立密集对应关系是必要的。当在不同类别之间进行匹配时，对象的功能，即对象对其他对象可能产生的影响，可以指导对应关系的建立。因为能够实现特定功能的对象部分在形状和外观上往往具有相似性。本文基于这一观察，定义了密集功能对应，并提出了一种弱监督学习框架来应对预测任务。这一方法的主要洞察是，可以通过视觉-语言模型为多视角图像生成伪标签，从而获得功能部分。然后，这一方法与基于像素对应关系的密集对比学习相结合，将功能和空间知识结合起来，构建了一个新的模型，能够建立密集功能对应关系。为了验证模型的有效性，作者还创建了合成和真实的标准数据集。结果表明，相对于现成的自我监督图像表示和基于视觉语言模型的基础方案，本文方法具有明显优势。
### Innovation
提出了一种弱监督学习框架来建立密集功能对应关系。该方法利用视觉-语言模型为多视角图像生成伪标签，然后与密集对比学习相结合，结合功能和空间知识，构造了新的模型。此外，还创建了合成和真实的标准数据集作为任务基准。
### Conclusion
实验结果表明，本文提出的弱监督学习方法在建立密集功能对应关系方面优于现有的基础方案，展示了该方法的优势。
## 343. `cs.CV` - 使用EfficientNet-B4迁移学习在U-Net架构下的胸片气胸分割 [PDF](https://arxiv.org/pdf/2509.03950), [HTML](https://arxiv.org/abs/2509.03950)
### Authors
Alvaro Aranibar Roque,Helga Sebastian
### Background
气胸是胸膜腔内异常积气的情况，如果未被发现可能会危及生命。胸部X光是诊断首选工具，但小范围的气胸可能会不易察觉。
### Innovation
本文提出了一种自动化深度学习管道，使用U-Net架构和EfficientNet-B4编码器进行气胸区域分割。该模型经过SIIM-ACR数据集的训练，并通过数据增强以及二元交叉熵与Dice损失的组合进行优化，最终在独立的PTX-498数据集上实现了交并比IoU为0.7008和Dice分数0.8241的结果，证明了模型能够准确定位气胸并支持放射科医生的工作。
### Conclusion
实验结果表明该模型能够准确识别气胸并支持临床诊断过程。
## 344. `cs.CV` - TopoSculpt: Betti-Steered Topological Sculpting of 3D Fine-grained Tubular Shapes [PDF](https://arxiv.org/pdf/2509.03938), [HTML](https://arxiv.org/abs/2509.03938)
### Authors
Minghui Zhang,Yaoyu Liu,Junyang Wu,Xin You,Hanxiao Zhang,Junjun He,Yun Gu
### Background
医学中的管状解剖结构是天然存在的三维管道，具有腔室、封闭的墙和复杂的分支拓扑结构。这些结构的几何和拓扑准确重建对肺部导航和脑动脉连接评估等应用至关重要。现有方法通常依赖于体素级别的重叠度量，但这些方法无法捕获拓扑正确性和完整性。尽管拓扑感知损失和持久同调约束显示出潜力，但它们通常以增量方式应用，无法保证全局一致性或在推理过程中正确保留几何和拓扑特征。
### Innovation
该研究提出了一个名为TopoSculpt的新框架，专门用于提高3D细粒度管状结构的拓扑精度。TopoSculpt采取了整体区域建模策略，以捕捉完整的空间上下文，并引入了拓扑完整性的Betti约束条件来共同强化贝塔数先验和全局完整性。此外，它使用持久同调分析的课程精炼方案，从粗到细逐步纠正错误。
### Conclusion
在复杂的肺部气道和Willis环数据集上的大量实验验证了TopoSculpt的有效性，其结果极大地改善了几何形状和拓扑结构。例如，肺部气道数据集中的贝塔0误差从69.00降低到3.40，Willis环数据集中的该误差从1.65降低到0.30，树长度检测率和分支检测率分别提高近10%。这些结果突显了TopoSculpt在纠正关键拓扑错误和推进复杂3D管状解剖结构的高精度建模方面的效果。
## 345. `cs.CV` - LMVC: 一种端到端学习的多视点视频编码框架 [PDF](https://arxiv.org/pdf/2509.03922), [HTML](https://arxiv.org/abs/2509.03922)
### Authors
Xihua Sheng,Yingwen Zhang,Long Xu,Shiqi Wang
### Background
多视角视频是体积视频的关键数据源，能够实现沉浸式的3D场景重建，但其庞大的数据量也带来了存储和传输方面的重大挑战。近年来，基于深度学习的端到端视频编码取得了巨大成功，然而大多数研究集中在单视角或立体成像视频上，对一般多视角场景的关注不足。多视角视频因其独立视图和依赖视图之间的复杂关联，提出了在编码时高效的跨视图运动预测和上下文预测的需求，这包括跨视图运动先验和跨视图上下文先验的捕捉，以克服多视角视频压缩领域的挑战，建立新的基准线，为该领域未来的研究铺平道路。
### Innovation
该论文提出了一个端到端学习的多视角视频编码 （LMVC）框架，该框架确保了随机访问和向后兼容性，同时提高了压缩效率。关键创新点在于有效利用独立视图的运动和内容信息以增强依赖视图的压缩。具体地，为了利用视图间运动的相关性，提出了基于特征的跨视运动矢量预测方法，并且利用解码后的独立视图运动特征对依赖视图的运动编码进行条件化，同时提出了跨视图运动熵模型来学习跨视图运动先验。为了利用视图间内容的相关性，提出了一个无视差跨视图上下文预测模块，通过解码后的独立视图内容特征来预测跨视图上下文，并结合一个跨视图上下文熵模型来捕捉跨视图上下文先验
### Conclusion
实验结果表明，提出的LMVC框架在传统MV-HEVC标准的参考软件上取得了显著的性能优势，为该领域的未来研究奠定了坚实的基础。
## 346. `cs.CV` - QuantV2X：一种全量化多代理系统用于协同感知 [PDF](https://arxiv.org/pdf/2509.03704), [HTML](https://arxiv.org/abs/2509.03704)
### Authors
Seth Z. Zhao,Huizhi Zhang,Zhaowei Li,Juntong Peng,Anthony Chui,Zewei Zhou,Zonglin Meng,Hao Xiang,Zhiyu Huang,Fujia Wang,Ran Tian,Chenfeng Xu,Bolei Zhou,Jiaqi Ma
### Background
通过V2X通信实现的合作感知具有显著潜力，能够缓解遮挡问题并扩大视野。然而，过去的研究主要关注于提高准确性指标，而忽视了效率、延迟和实际部署性等系统层面的考虑。现有系统大多依赖于全精度模型，这导致了高昂的计算和传输成本，使其在资源受限的环境中进行实时操作不可行。
### Innovation
QuantV2X 是首个专为高效的多模态多代理 V2X 合作感知设计的全量化系统。它引入了统一的端到端量化策略，同时减少计算负载和传输带宽。尽管在低位数约束下运行，QuantV2X 的准确性与全精度系统相当，在部署指标下将系统级延迟减少了3.2倍，并且通过mAP30指标提高了9.5的改进。此外，QuantV2X 更加可扩展，能够在严格的内存预算中适应更大的和更强大的模型。
### Conclusion
这些结果表明，全量化的多代理中间融合系统在实际部署中具有可行性。该系统将公开发布以促进该领域的研究：this https URL
## 347. `cs.CV` - Promptception：大型多模态模型对提示有多敏感？ [PDF](https://arxiv.org/pdf/2509.03986), [HTML](https://arxiv.org/abs/2509.03986)
### Authors
Mohamed Insaf Ismithdeen,Muhammad Uzair Khattak,Salman Khan
### Background
尽管近年来大型多模态模型（LMMs）在多个领域取得了成功，但在多项选择题回答（MCQA）任务中LMMs的提示设计仍缺乏明确理解。即使轻微调整提示的措辞和结构，也可能导致高达15%的准确率偏差，这为透明和公平的LMM评估带来了挑战。
### Innovation
本文引入了Promptception，一个系统框架，用于评估LMMs的提示敏感性。它包含61种提示类型，涵盖15类和6个大类，旨在评估10种LMMs，从轻量级开源模型到GPT-4o和Gemini 1.5 Pro，共计3个MCQA基准：MMStar、MMMU-Pro、MVBench。研究发现，专有模型对提示措辞更为敏感，表明它们与指令语义的对齐更为紧密，而开源模型则较为稳定，但在复杂的提示措辞处理上存在困难。
### Conclusion
基于该分析，提出了针对专有和开源LMMs的提示原则，旨在促进更稳健和公平的模型评估。
## 348. `cs.CV` - 提高血管分割性能的方法，利用多任务学习和仅在训练模型期间可用的辅助数据 [PDF](https://arxiv.org/pdf/2509.03975), [HTML](https://arxiv.org/abs/2509.03975)
### Authors
Daniel Sobotka,Alexander Herold,Matthias Perkonigg,Lucian Beer,Nina Bastati,Alina Sablatnig,Ahmed Ba-Ssalamah,Georg Langs
### Background
在磁共振成像（MRI）数据中对肝脏血管进行分割对于计算分析血管重塑至关重要，血管重塑与多种弥漫性肝病有关。现有的方法依赖对比增强的成像数据，但这些专门的成像序列并没有均匀地被获取。虽然不对比增强的图像被更频繁地获取，但血管分割变得更具挑战性，并需要大规模的标注数据。因此，提出了一种多任务学习框架，无需对比增强就能在肝脏MRI中分割血管。该框架利用仅有在训练期间才可用的对比增强数据作为辅助数据，从而减少所需的标注训练样本数量。这种框架利用了配有和未配有血管注释的原生和对比增强数据来训练模型。
### Innovation
所提出的方法通过多任务学习框架利用了仅有在训练模型期间才可用的对照增强数据作为辅助数据，以减少对标注训练样本的需求，从而提高了在肝脏MRI中对血管进行分割的准确性。
### Conclusion
实验结果表明，辅助数据可以改善血管分割的准确性，即使在推理期间不可用也是如此。如果训练数据中可获得的标注较少，该辅助方式的优势最为显著，因为其特征表示得益于共享的任务结构。在脑肿瘤分割模型中对该方法的验证确认了其在不同领域的益处。即使辅助成像模态仅在训练期间可用，专家标注也可以得到补充。
## 349. `cs.CV` - 多模态文本差异增强特征融合网络在遥感变化检测中的应用 [PDF](https://arxiv.org/pdf/2509.03961), [HTML](https://arxiv.org/abs/2509.03961)
### Authors
Yijun Zhou,Yikui Zhai,Zilu Ying,Tingfeng Xian,Wenlve Zhou,Zhiheng Zhou,Xiaolin Tian,Xudong Jia,Hongsheng Zhang,C. L. Philip Chen
### Background
尽管深度学习在遥感变化检测（RSCD）方面取得了进展，大多数方法仍然依赖于单模态图像，这限制了特征表示、变化模式建模以及在光照和噪声干扰下的泛化能力。
### Innovation
提出了MMChange，这是一种结合图像和文本模态的多模态RSCD方法，通过增强准确性和鲁棒性来克服单一模态的限制。引入了图像特征细化（IFR）模块，重点突出关键区域并抑制环境噪声。为了克服图像特征的语义限制，采用视觉语言模型（VLM）生成时空图像的语义描述。随后，通过文本差异增强（TDE）模块捕捉细微的语义变化，指导模型识别有意义的变化。为了弥合不同模态之间的异质性，设计了图像文本特征融合（ITFF）模块，实现深度跨模态集成。
### Conclusion
在LEVIRCD、WHUCD和SYSUCD数据集上的广泛实验表明，MMChange在多个指标上都超越了最先进的方法，验证了其多模态RSCD的有效性。
## 350. `cs.CV` - SAC-MIL: 空间感知相关多重实例学习在组织病理学全切片图像分类中的应用 [PDF](https://arxiv.org/pdf/2509.03973), [HTML](https://arxiv.org/abs/2509.03973)
### Authors
Yu Bai,Zitong Yu,Haowen Tian,Xijing Wang,Shuo Yan,Lin Wang,Honglin Li,Xitong Ling,Bo Zhang,Zheng Zhang,Wufan Wang,Hui Gao,Xiangyang Gong,Wendong Wang
### Background
全切片图像（WSI）分类在医学诊断中非常重要，而传统的多重实例学习（MIL）方法通常不考虑实例的空间位置信息，这影响了模型的分类性能和准确性。因此，研究一种能够处理空间位置信息的WSI分类方法成为了一个关键挑战。现有的基于Transformer的方法虽然能够处理空间位置信息，但这些方法通常需要定制的CUDA内核来实现，使得部署更加复杂。
### Innovation
该论文提出了Spatial-Aware Correlated Multiple Instance Learning (SAC-MIL)，使用一个空间信息编码模块来编码实例在切片内的位置关系，替代了传统的输入序列中的实例索引编码。此外，SAC-MIL中的SAC块是一个基于MLP的方法，它可以在线性时间内执行实例间的完整相关性，且不需要定制的CUDA内核，相比基于Transformer的方法更加简单易部署。SAC-MIL在CAMELYON-16、TCGA-LUNG和TCGA-BRAC数据集上取得了最佳性能，展示了其在WSI分类中的有效性。
### Conclusion
SAC-MIL在处理WSI分类任务时，通过引入空间信息编码模块和SAC块，能够在保持性能的同时简化部署过程。该方法的成功应用展示了其在实际医学诊断中潜在的好处。论文的代码将在被接受后发布。
## 351. `cs.CV` - 从多数标签学习：多类多实例学习中的一种新型问题 [PDF](https://arxiv.org/pdf/2509.04023), [HTML](https://arxiv.org/abs/2509.04023)
### Authors
Shiku Kaito,Shinnosuke Matsuo,Daiki Suehiro,Ryoma Bise
### Background
该论文提出了一个多类多实例学习（Multiple-Instance Learning，MIL）问题的新颖实例，称为从多数标签学习（Learning from Majority Label，LML）。LML假设每个袋子的主要类别将作为袋子级别的标签。这一问题在病理图像分割、政治投票预测、客户情感分析和环境监测等多种应用场景中都有重要作用。
### Innovation
研究提出了一种新的计算网络，称为计数网络，用于生成袋子级别的多数标签，通过计算每个类别的实例数量来估计。此外，通过增加多数类别实例的比例来改进多数比例增强模块（Majority Proportion Enhancement Module，MPEM）。实验证明该方法在四个数据集上优于传统的MIL方法，并且消融研究也证实了各个模块的有效性。
### Conclusion
通过从多数标签学习的方法，该研究解决了多实例学习中的一个新颖问题，并通过实验验证了所提方法的有效性。提供的代码可在指定的url中获取。
## 352. `cs.CV` - ANTS: 利用MLLM塑造自适应负文本空间进行OOD检测 [PDF](https://arxiv.org/pdf/2509.03951), [HTML](https://arxiv.org/abs/2509.03951)
### Authors
Zhu Wenjie,Zhang Yabin,Xin Jin,Wenjun Zeng,Lei Zhang
### Background
现有的负标签（NLs）引入已被证明能有效提升Out-of-Distribution（OOD）检测。然而，现有方法往往无法透彻理解OOD图像，难以构建精确的负空间，同时，假负标签的出现显著降低了其近似OOD表现。进一步地，现有方法在处理近似OOD和远端OOD检测时表现不一。因此，论文旨在利用多模态大语言模型（MLLMs）的感知和推理能力，通过这些模型对识别出的可能为OOD样本的图像进行描述，生成能够准确刻画OOD分布且增强远端OOD检测的表达性负文本。对于近似OOD场景，MLLMs用于生成与负标签视觉相似的负标签，旨在优化近端OOD检测并降低假负率。通过设计自适应加权分数，该方法能够根据不同OOD任务设置（近似OOD和远端OOD）灵活应用，无需依赖特定任务的先验知识，从而使其具备开放环境下的高度适应性。
### Innovation
该论文创新性地提出了一种自适应负文本空间（ANTS）的概念。通过利用多模态大型语言模型（MLLMs）的感知和推理能力，识别可能为OOD样本的图像（近似和远端）并生成相应的表达性负文本，从而有效提升了两类OOD检测任务（远端和近似）的表现，且方法训练免费、零样本，具有高可扩展性。
### Conclusion
在ImageNet基准测试中，该方法显著降低了FPR95到4.2%，并且确立了新的基准。该方法的自适应加权分数和无需特定任务先验知识的设计使得它在开放环境下具有极高的适应性。
## 353. `cs.CV` - 通过逐词舍弃检测视觉变换器中的地区性伪相关 [PDF](https://arxiv.org/pdf/2509.04009), [HTML](https://arxiv.org/abs/2509.04009)
### Authors
Solha Kang,Esla Timothy Anzaku,Wesley De Neve,Arnout Van Messem,Joris Vankerschaver,Francois Rameau,Utku Ozbulak
### Background
基于神经网络的计算机视觉模型具有强大的特征关联能力，能够在数据中检测和利用未预期的模式，从而基于错误或不经意但具有统计意义的信号进行正确预测。这些未预期的信号可能从简单的颜色异常到图像中的小文字不等。当这些信号与预测任务一致时，模型可能会错误地将这些特征与任务关联起来，并依赖这些特征进行预测。这种现象称为伪相关，即表面上与任务相关的模式实际上是巧合。因此，检测和减轻伪相关已经成为构建可信赖、可靠和泛化的机器学习模型的关键任务。
### Innovation
本文提出了一种新型方法，用于检测视觉变换器中的地区性伪相关。该方法使用监督训练和自我监督训练的模型，在ImageNet数据集上进行了大规模实验，证明所提出的方法具有识别伪相关的能 力。同时发现，即使使用相同的架构，训练方法对模型依赖伪相关的程度有显著影响。而且，研究显示ImageNet数据集中某些类别的图像包含易于被模型检测到的伪信号，并讨论了这些伪信号背后的原因。
### Conclusion
基于研究发现，本文详列了上述图像，并呼吁在未来的研究中谨慎使用这些图像。最后，通过一个乳腺侵犯性肿块分类案例研究，探讨了伪信号在实际场景中的应用。
## 354. `cs.CV` - SliceSemOcc：基于垂直切片的多模态3D语义占用表示 [PDF](https://arxiv.org/pdf/2509.03999), [HTML](https://arxiv.org/abs/2509.03999)
### Authors
Han Huang,Han Sun,Ningzhong Liu,Huiyu Zhou,Jiaquan Shen
### Background
随着自动驾驶对精确3D感知的需求，3D语义占用预测已成为关键的研究主题。虽然传统的鸟瞰图（BEV）方法限制了场景表示在一个2D平面上，但占用预测利用完整的3D体素网格来建模所有维度的空间结构，从而捕获垂直轴上的语义变化。然而，大多数现有方法在处理体素特征时忽略了高度轴信息，并且传统的SENet风格的通道注意力在所有高度层上分配相同的权重，限制了它们在不同高度重点突出特征的能力。
### Innovation
本文提出了SliceSemOcc，一种基于垂直切片的多模态3D语义占用表示框架。该方法通过全局和局部垂直切片提取高度轴上的体素特征，引入了一个全局局部融合模块来适配频率的细节与整体上下文信息。此外，还提出了SEAttention3D模块，该模块通过平均池化保持高度层面的分辨率，并为每个高度层分配动态的通道注意力权重。广泛实验表明，该方法显著提高了平均IoU，特别是在大多数小物体类别上的提升尤为显著。
### Conclusion
全面的消融研究进一步验证了提出的SliceSemOcc框架的有效性，通过改进，3D语义占用预测在自动驾驶中的应用取得了显著的性能提升。
## 355. `cs.CV` - DVS-PedX: 合成与真实事件驱动的行人数据集 [PDF](https://arxiv.org/pdf/2509.04117), [HTML](https://arxiv.org/abs/2509.04117)
### Authors
Mustafa Sakhai,Kaung Sithu,Min Khant Soe Oke,Maciej Wielgosz
### Background
动态视觉传感器（DVS）这类事件摄像头报告微秒级的亮度变化，而不是完整的图像帧，提供低延迟、高动态范围和运动鲁棒性。基于此类传感器的数据集DVS-PedX设计用于正常和恶劣天气条件下的人行横道检测和过街意图分析。该数据集结合了模拟器生成的合成事件流和真实世界的视频，以支持广泛的实验研究。
### Innovation
1. 数据集设计时考虑到不同天气和照明条件下的行人检测和过街意图分析。2. 结合来自CARLA模拟器的合成事件流和真实世界的JAADdash-cam视频，以保持自然的行为和背景。3. 提供原始AEDAT文件和灵活的重处理工具，支持多样化的研究需求。4. 使用频突触神经网络（SNN）展示数据集的实用性，并揭示模拟到现实世界的差距，从而推动领域适应和多模态融合研究。
### Conclusion
DVS-PedX旨在加速基于事件的行人安全、意图预测和神经形态感知的研究。
## 356. `cs.CV` - TEn-CATS：多尺度类别意识时序图增强的文本丰富音视频视频解析 [PDF](https://arxiv.org/pdf/2509.04086), [HTML](https://arxiv.org/abs/2509.04086)
### Authors
Yaru Chen,Faegheh Sardari,Peiliang Zhang,Ruohao Guo,Yang Xiang,Zhenbo Li,Wenwu Wang
### Background
现有的AVVP任务方法通常分为两类：一是基于注意力机制设计增强架构以更好地建模时序信息；二是生成更丰富的伪标签以弥补帧级注解的缺失。然而，第一类方法将嘈杂的段级伪标签视为可靠监督，第二类方法让无差别注意力在所有帧间传播初始错误，导致错误在训练过程中被不断放大。
### Innovation
本文提出了一种结合双向文本融合（BiT）模块和类别感知时序图（CATS）模块的方法，旨在解决上述问题。该方法首先通过BiT模块对音频和视觉模态特征进行语义注入和动态校准，以定位和净化更丰富且更清晰的语义线索；然后，利用CATS模块进行语义传播和连接，以实现精确的跨时间语义信息传递。
### Conclusion
本文提出的TEn-CATS方法在两个基准数据集（LLP和UnAV-100）的多个关键指标上达到了最先进的性能。
## 357. `cs.CV` - 基于“飞腾+寒武纪”的毫秒级响应UA追视系统：一项国产方案 [PDF](https://arxiv.org/pdf/2509.04043), [HTML](https://arxiv.org/abs/2509.04043)
### Authors
Yuchen Zhu,Longxiang Yin,Kai Zhao
### Background
传统摄像头系统在动态场景中因自动识别算法的浅层特征提取能力和计算架构效率瓶颈导致响应延迟超过200ms，无法满足复杂场景下的实时需求。
### Innovation
提出基于飞腾处理器和寒武纪加速卡的异构计算架构，构建具有毫秒级响应能力的无人机追踪和注视系统，通过多卡并行计算提升硬件计算能力，并创新性地将轻量级YOLOv5s检测网络与深度SORT级联跟踪算法集成，形成“检测-跟踪-反馈”闭环控制链。实验结果表明，系统在1920×1080分辨率视频流处理中，稳定单帧综合处理延迟为50-100ms，多尺度目标识别精度超过98.5%，兼具低延迟和高精度的特点。
### Conclusion
该研究为无人机监控和国产芯片的应用提供了创新的解决方案。
## 358. `cs.CV` - TriLiteNet: 轻量级多任务视觉感知模型 [PDF](https://arxiv.org/pdf/2509.04092), [HTML](https://arxiv.org/abs/2509.04092)
### Authors
Quang-Huy Che,Duc-Khai Lam
### Background
高效的感知模型对于高级驾驶辅助系统（ADAS）至关重要，这些应用需要快速处理和响应，以确保在现实环境中的安全性和有效性。为了满足这些感知模型的实时执行需求，这项研究引入了TriLiteNet模型，该模型可以同时处理全景驾驶感知的相关任务。TriLiteNet旨在优化性能同时保持低计算成本。
### Innovation
TriLiteNet模型被设计为一种既能同时管理多个任务，又能在保持低计算成本的同时优化性能的轻量级模型。模型在BDD100k数据集上展示了在三个关键任务（车辆检测、可行驶区域分割、车道线分割）上的竞争性性能。特别是，TriLiteNet_{base}在车辆检测中的召回率为85.6%，可行驶区域分割的mIoU为92.4%，车道线分割的准确率为82.3%，仅用2.35M参数和7.72 GFLOPs的计算成本。此外，提出了一个仅包含0.14M参数的小配置模型，提供了一个在计算需求上近乎最小的多任务解决方案。在嵌入式设备上评估TriLiteNet在推断时的延迟和功耗，两种配置下的TriLiteNet都显示出了低延迟和合理的功耗。
### Conclusion
通过平衡性能、计算效率和可扩展性，TriLiteNet提供了一种适用于实际自动驾驶应用的实用且可部署的解决方案。
## 359. `cs.CV` - 使用K最近邻加权融合的人再识别重排序方法 [PDF](https://arxiv.org/pdf/2509.04050), [HTML](https://arxiv.org/abs/2509.04050)
### Authors
Quang-Huy Che,Le-Chuong Nguyen,Gia-Nghia Tran,Dinh-Duy Phan,Vinh-Tiep Nguyen
### Background
人再识别中的重排序是通过细化检索结果的初始排名来增强整体准确性的关键步骤。以往的研究主要集中在单视角图像特征上，这可能导致视角偏差及姿态变化、视角转换和遮挡等问题。使用多视角特征可以减少视角偏差。本文提出了一种高效重排序方法，通过K最近邻加权融合（KWF）方法聚合邻居特征来生成多视角特征。研究还探讨了聚合特征期间的权重选择策略，以确定有效策略。该重排序方法无需微调模型或额外标注，适用于大规模数据集。
### Innovation
提出了一种通过K最近邻加权融合方法生成多视角特征的重排序方法，此方法不需要模型微调和额外标注，并能在大规模数据集上应用。通过无监督选择K个邻居特征生成多视角特征，提高了在挑战性数据集（如MSMT17和遮挡的DukeMTMC）上的Rank@1和mAP。与现有方法相比，计算效率也有显著提高。
### Conclusion
本文提出的方法在MSMT17和遮挡的DukeMTMC数据集上，相较于初始排名，实现了17%和22%的Rank@1提升，并展示了显著的计算效率优势。
## 360. `cs.CV` - 基于YOLO集成的多光谱无人机风力发电机组件缺陷检测 [PDF](https://arxiv.org/pdf/2509.04156), [HTML](https://arxiv.org/abs/2509.04156)
### Authors
Serhii Svystun,Pavlo Radiuk,Oleksandr Melnychenko,Oleg Savenko,Anatoliy Sachenko
### Background
无人机装备有高级传感器，为风力发电厂的叶片、塔和其他关键组件的监测开辟了新机会。然而，可靠的缺陷检测需要高分辨率数据和高效的方法来处理多光谱图像。这项研究旨在通过开发结合可见光和热通道的YOLO基深度学习模型集合来提高缺陷检测准确性。
### Innovation
提出了一种面向多光谱无人机风力发电机组件缺陷检测的YOLO集成方法，结合了一种通用的YOLOv8模型和专门的热模型，使用先进的边界框融合算法来结合它们的预测。这种方法在检测视觉和热缺陷方面表现出更好的性能。
### Conclusion
将多个YOLO架构与融合的多光谱数据结合，提供了一个更可靠的方法，提高了缺陷检测的准确性。
## 361. `cs.CV` - VisioFirm: 支持跨平台的计算机视觉辅助注释工具 [PDF](https://arxiv.org/pdf/2509.04180), [HTML](https://arxiv.org/abs/2509.04180)
### Authors
Safouane El Ghazouali,Umberto Michelucci
### Background
人工标注数据是机器学习模型学习模式和执行预测的基础，但这一过程通常很耗时且需要大量的手动输入。传统的工具常受限于大规模数据集的处理能力和标注效率，因此难以满足日益增长的数据标注需求。
### Innovation
VisioFirm 是一个开源的网络应用程序，通过结合最先进的基础模型和过滤管道，旨在简化图像标记流程，并减少人工介入。它采用混合方法，利用 CLIP 结合预训练检测器（如 Ultralytics 模型）以及零样本模型（如 Grounding DINO），能够生成带有低置信度阈值的初步注释，以最大化召回率。此外，VisioFirm 还具备实时分割功能，通过 WebGPU 加速浏览器端效率，并支持多种导出格式，提供离线操作能力，从而提高了工具的可访问性。
### Conclusion
在不同的数据集上对 VisioFirm 进行基准测试表明，该工具能够将人工努力降低多达 90%，同时通过基于 CLIP 的去混淆聚类组件和 IoU 图抑制冗余检测，仍能保持高水平的注释准确性。
## 362. `cs.CV` - MEPG：组合丰富图像生成的多专家规划与生成 [PDF](https://arxiv.org/pdf/2509.04126), [HTML](https://arxiv.org/abs/2509.04126)
### Authors
Yuan Zhao,Liu Lin
### Background
文本到图像的扩散模型已经在图像质量方面取得了显著成果，但仍然难以处理复杂的多元素提示和有限的风格多样性。现有的模型在应对这些挑战方面存在局限性。
### Innovation
提出了一种名为MEPG（Multi-Expert Planning and Generation Framework）的多专家规划与生成框架，该框架将位置和风格感知的大语言模型（LLMs）与空间语义专家模块协同集成。MEPG框架包含两个核心组件：(1) 一个位置-风格感知(PSA)模块，利用监督微调的大型语言模型将输入提示分解为精确的空间坐标和风格编码的语义指令；(2) 多专家扩散(MED)模块，则通过动态专家路由在局部区域和全球范围内实现跨区域生成。这些特定模型（如现实专家、风格化专家）通过基于注意的门控机制在生成过程中根据空间分区进行选择性激活。该体系结构支持专家模型的轻量级集成和替换，具有较强的扩展性。此外，还提供了一个交互界面，允许实时空间布局编辑和从专家组合中为每个区域选择特定风格。实验表明，MEPG明显优于具有相同底层结构的基线模型，无论在图像质量还是风格多样性方面。
### Conclusion
MEPG框架显著提升了组合丰富图像的生成质量与风格多样性，展示了一种有效的解决方案来处理复杂和多元素提示，以及实现多样的风格生成。
## 363. `cs.CV` - 重新审视简单的野外深度换脸检测基线 [PDF](https://arxiv.org/pdf/2509.04150), [HTML](https://arxiv.org/abs/2509.04150)
### Authors
Orlando Castaneda,Kevin So-Tang,Kshitij Gurung
### Background
合成媒体的广泛应用需要易于访问的深度换脸检测器和现实基准。现有的大多数研究均在高度受控的数据集上评估深度换脸检测器。我们则聚焦于最近发布的野外基准Deepfake-Eval-2024。初步报告表明，三个调整后的开源模型在Deepfake-Eval-2024上的准确率介于61%至69%之间，显著落后于领先商用深度换脸检测器82%的准确率。本文重新审视了Ojha等人最初引入的一种基线方法，该方法将标准预训练视觉背骨调整为生成泛化的深度换脸检测器。我们通过优化超参数来改进这个简单的方法，并在Deepfake-Eval-2024上得到了81%的准确率，这比之前报告的准确率提高了18%，与商用深度换脸检测器竞争。
### Innovation
通过调整超参数，将标准预训练视觉背骨应用于生成泛化的深度换脸检测器，从而提高了之前简单方法的性能，达到81%的准确率，显著领先于之前报告的61%-69%的准确率，甚至接近商用深度换脸检测器的82%准确率。
### Conclusion
在准确率、计算成本和可解释性之间存在权衡。本文强调了这些深度换脸检测器在实际部署中的实用性。我们的代码可以在相应链接中找到。
## 364. `cs.CV` - 基于Wasserstein一致性约束的双尺度体积先验半监督医学图像分割 [PDF](https://arxiv.org/pdf/2509.04273), [HTML](https://arxiv.org/abs/2509.04273)
### Authors
Junying Meng,Gangxuan Zhou,Jun Liu,Weihong Guo
### Background
尽管在医学图像分割领域已经取得了显著进展，但现有的分割网络大部分忽视了有效的特征提取方法和重要数据先验信息。本文的任务是在半监督医学图像分割框架下，有效地整合空间正则化方法和体积先验信息。
### Innovation
本文提出了一种半监督医学图像分割框架，该框架整合了强显式体积先验和阈值动力学空间正则化方法。通过图像尺度上的Wasserstein距离约束，有效正则化了骨干分割网络，确保每个未标记图像的分割结果类比分布与回归网络预测一致。同时，设计了一个基于弱隐式体积先验的数据尺度Wasserstein距离损失函数，强制预测的未标记数据集的体积分布与标记数据集相似。
### Conclusion
在2017年ACDC数据集、PROMISE12数据集和大腿肌肉MRI图像数据集上的实验结果表明，所提出的方法具有优越性。
## 365. `cs.CV` - TaleDiffusion：使用对话呈现的多角色故事生成 [PDF](https://arxiv.org/pdf/2509.04123), [HTML](https://arxiv.org/abs/2509.04123)
### Authors
Ayan Banerjee,Josep Lladós,Umapada Pal,Anjan Dutta
### Background
文本到故事的可视化具有挑战性，因为需要在多帧中保持多个角色的一致性交互。现有方法在角色一致性方面存在困难，导致生成的图像中出现伪影和对话渲染不准确，从而导致讲故事连贯性不足。现有方法未能有效地解决这一问题，导致了叙事的不连续性。
### Innovation
我们提出了TaleDiffusion，这是一种新颖的生成多角色故事的框架，通过迭代过程来保持角色一致性，并通过后处理实现准确的对话分配。具体来说，通过预训练的语言模型使用上下文学习生成每帧描述、角色细节和对话，然后使用基于注意力的框控制技术来控制角色交互并最小化伪影。随后，应用一致性自注意力机制来确保每帧中角色的一致性，以及区域感知的交叉注意力来实现精确的物体放置。对话也被呈现为气泡，并通过CLIPSeg分配给角色。实验结果表明，TaleDiffusion在一致性、噪声减少和对话渲染方面优于现有方法。
### Conclusion
我们的TaleDiffusion框架在保持角色一致性、减少噪音和对话渲染方面显著优于现有的方法，实现了无缝、连贯的故事叙述。通过细致的迭代处理和后处理，成功解决了多角色序列中的对话多样性和交互的一致性问题。
## 366. `cs.CV` - TauGenNet: 通过文本引导的3D扩散模型驱动的tau PET图像合成 [PDF](https://arxiv.org/pdf/2509.04269), [HTML](https://arxiv.org/abs/2509.04269)
### Authors
Yuxin Gong,Se-in Jang,Wei Shao,Yi Su,Kuang Gong(for the Alzheimer's Disease Neuroimaging Initiative (ADNI))
### Background
准确通过tau正电子发射断层扫描(PET)定量tau病理对于诊断和监测阿尔茨海默病(AD)至关重要。然而，tau PET的高成本和有限可获得性限制了其广泛应用。相比之下，结构磁共振成像MRI和基于血浆的生物标记物提供了与大脑解剖结构和疾病进程相关的非侵入性和广泛应用的补充信息。鉴于此，本研究提出了一个文本引导的3D扩散模型来合成3D tau PET图像，结合了来自结构MRI和血浆测量的多模态条件。
### Innovation
该研究提出了一种基于文本引导的3D扩散模型，用于合成3D tau PET图像。具体而言，文本提示来自于血浆p-tau217测量值，这是AD进展的关键指标。此外，MRI提供了解剖结构的限制。该框架使用来自阿尔茨海默病神经影像研究所(ADNI)数据库的临床AV1451 tau PET数据进行训练和评估。实验结果显示，该方法能够生成不同疾病阶段具有临床意义的3D tau PET图像。
### Conclusion
提出的框架可以用于tau PET数据增强，提供非侵入性和低成本的替代方案来可视化tau病理，并支持在不同血浆生物标志物水平和认知条件下模拟疾病进展。
## 367. `cs.CV` - 高效异物识别 [PDF](https://arxiv.org/pdf/2509.04326), [HTML](https://arxiv.org/abs/2509.04326)
### Authors
Silvio Chito,Paolo Rabino,Tatiana Tommasi
### Background
最近引入了一种新的异常检测任务——在多对象场景中识别异常的实例。这一问题对现代深度学习模型提出了挑战，需要在多个视图中进行空间推理，并进行关系推理以理解上下文并在不同对象类别和布局中泛化。
### Innovation
提出了一种基于DINO的模型，该模型将参数数量减少了三分之一，并将训练时间缩短了三倍，同时保持了竞争力的表现。同时引入了多模态大型语言模型基准，揭示其在结构化视觉推理任务中的当前局限性。
### Conclusion
实验评估表明，尽管效率提高，该模型在性能上仍具有竞争力，并为未来在该领域的工作提供了见解。
## 368. `cs.CV` - Differential Morphological Profile Neural Networks for Semantic Segmentation [PDF](https://arxiv.org/pdf/2509.04268), [HTML](https://arxiv.org/abs/2509.04268)
### Authors
David Huangal,J. Alex Hurt
### Background
遥感图像的语义分割能够应用于制图、城市规划和灾害响应等领域。现有的最先进的分割网络通常是针对地面视角的相片开发和调整的，无法直接处理遥感图像中诸如极端尺度变化、前景后景不平衡和大尺寸图像等问题。已有研究表明，差异形态学特征（DMP）可以提供关键的形状信息，有助于提高顶层图像的检测和分类性能。本文进一步将DMP特征整合到三种最先进的卷积神经网络和变压器语义分割架构中，并通过iSAID基准数据集评估不同的DMP差异和形态学结构，以更有效地提供形状信息给模型。
### Innovation
本文将差分形态学特征（DMP）整合到现代语义分割网络中，并通过直接输入和混合架构两种方式将DMP特征应用到分割网络中，开发了一种DMP神经网络（DMPNet）。通过iSAID基准数据集评估了不同DMP差异和结构元素形状的效果，展示了混合DMP架构（hybrid DMP）相较于直接输入DMP架构具有更好的性能，并在mIoU、F1和召回率等指标上部分超越了没有DMP的模型。
### Conclusion
虽然非DMP模型在直接输入架构变体中通常表现更优，但混合DMP架构一致优于直接输入架构，并在某些指标上能够超越非DMP模型。
## 369. `cs.CV` - GUI Grounding via Self-Evolving Preference Optimization for Active Perception Learning [PDF](https://arxiv.org/pdf/2509.04243), [HTML](https://arxiv.org/abs/2509.04243)
### Authors
Wanfu Wang,Qipeng Huang,Guangquan Xue,Xiaobo Liang,Juntao Li
### Background
深度学习模型在视觉感知和语言推理方面的进展显著。其中，Vision Language Models (VLMs) 已经取得了重要成果。虽然 OpenAI 的 o3 模型引入了一种有效的放大幅度视觉搜索策略，提高了下游任务的表现，但要在高分辨率输入和复杂的多元素视觉交互情况下有效推理适当图像区域仍然是 GUI 地址的核心挑战。
### Innovation
本文提出了 LASER，一种自我演化的框架，逐步赋予 VLMs 多步感知能力，从而实现精确的坐标预测。该方法结合了 Monte Carlo 质量评估和基于 Intersection-over-Union (IoU) 的区域质量评估来联合促进构建高质量偏好数据的准确性和多样性。这种组合明确引导模型专注于指令相关的关键区域，并根据任务复杂性适应性分配推理步骤。
### Conclusion
在 ScreenSpot Pro 和 ScreenSpot-v2 标准时，综合实验表明该方法的一致性能改进，验证了该方法的有效性。进一步，在 GTA1-7B 上微调后，LASER 在 ScreenSpot-Pro 标准时获得了 55.7 的分数，成为 7B 规模模型中的新最佳表现。
## 370. `cs.CV` - DUDE: 基于扩散的无监督跨域图像检索 [PDF](https://arxiv.org/pdf/2509.04193), [HTML](https://arxiv.org/abs/2509.04193)
### Authors
Ruohong Yang,Peng Hu,Yunfan Li,Xi Peng
### Background
无监督跨域图像检索（UCIR）旨在在没有标签的情况下，从不同领域的图像中检索同一类别的图像。现有方法往往通过整个图像的特征对齐处理，但由于关键的检索对象特征容易与领域特定的风格混淆，导致在面对领域差异时表现不佳。
### Innovation
本文提出了DUDE，一种基于特征拆分的新颖无监督跨域图像检索方法。DUDE利用文本到图像的生成模型来拆分对象特征与领域特定的样式，以促进语义图像检索。此外，DUDE通过逐步对领域内的互邻特征进行跨领域的对齐，进一步确保拆分后对象特征的可靠对齐。
### Conclusion
通过在三个基准数据集上的广泛实验，DUDE在13个领域上展示了最先进的性能。源代码将被公开。
## 371. `cs.CV` - GeoArena：评估大规模视觉语言模型在全球图像地理定位中的开源平台 [PDF](https://arxiv.org/pdf/2509.04334), [HTML](https://arxiv.org/abs/2509.04334)
### Authors
Pengyue Jia,Yingyi Zhang,Xiangyu Zhao,Yixuan Li
### Background
图像地理定位旨在预测地球上任何地方拍摄的图像的地理位置，但其全球性质带来了重大挑战。当前的评估方法存在数据泄漏和以精确地理坐标为主要评价标准的问题。数据泄漏导致使用大型视觉语言模型（LVLMs）进行预测的高级方法往往在测试数据集上进行预训练，从而影响模型实际地理定位能力的准确评估。现有度量标准主要依赖于精确的地理坐标来评估预测结果，既忽略了推理过程，又在需要用户级别的地理位置数据时引发了隐私问题。
### Innovation
为了应对上述问题，我们提出了GeoArena，这是一个开源平台，用于在全世界图像地理定位任务中评估大型视觉语言模型。该平台提供真实的野外和以人为本的基准测试。GeoArena使用户能够上传野外图像以构成更具多样性的评价基准，并利用成对的人类判断来确定哪个模型输出更符合人类期望。平台已在线部署两个月，期间收集了数千份投票记录。基于这些数据，我们进行了详细分析并建立了不同的LVLMs在图像地理定位任务上的排行榜。
### Conclusion
GeoArena平台成功收集并评估了大量数据，为不同大型视觉语言模型在图像地理定位任务上的表现提供了详细的分析和可比较的排行榜。
## 372. `cs.CV` - 基于语义可靠合成图像的噪声标签精炼 [PDF](https://arxiv.org/pdf/2509.04298), [HTML](https://arxiv.org/abs/2509.04298)
### Authors
Yingxuan Li,Jiafeng Mao,Yusuke Matsui
### Background
图像分类数据集中存在语义噪声，同一类别的图像在视觉上相似但频繁出现误标签的情况，这对传统的监督学习方法构成了显著的挑战。本文探讨了使用由先进文本转图像模型生成的高质量合成图像来解决这一问题。这些带可靠标签的合成图像由于领域差距和多样性的约束，直接用于训练受到限制。
### Innovation
本文提出了一种新颖的方法，利用合成图像作为可靠的参考点来识别和纠正噪声数据集中的误标签样本。该方法与现有噪声鲁棒学习技术无交集，与最先进的噪声鲁棒训练方法结合使用时，能够显著提高分类准确率，特别是在具有语义标签噪声的复杂场景中。实验表明，在CIFAR-10上可提高30%的准确性，CIFAR-100上提高11%，在ImageNet-100上提高24%的准确性，适用于现实中的噪声状况。
### Conclusion
本文方法通过结合合成图像和现有的噪声鲁棒训练方法，显著提高了图像分类的准确性，在具有语义标签噪声的噪声数据集中表现尤为突出，特别是在现实世界中的噪声条件下取得了更优秀的性能。
## 373. `cs.CV` - PAOLI：基于稀疏视角图像的无姿态附着物体学习 [PDF](https://arxiv.org/pdf/2509.04276), [HTML](https://arxiv.org/abs/2509.04276)
### Authors
Jianning Deng,Kartic Subr,Hakan Bilen
### Background
研究人员正在探索从稀疏视角、未摆姿势的图像中学习附着物体表示的新方法。现有的方法通常需要密集的多视角观察和真实的摄像机姿态数据，这在实际应用中很难实现。因此，存在一个改进的方法来处理这种挑战的需求，即无需密集视角和摄像机姿态信息，仅使用少量视角和未摆姿势的图像来学习附着物体的表示方法。
### Innovation
本文提出了一种新颖的自监督框架，用于从稀疏视角、未摆姿势的图像中学习附着物体的表示。该方法只需要少量视图（每个附着部位四视图）和无需摄像机监督即可工作。首先，使用最近的稀疏视角3D重建技术独立重建每个附着部位；其次，学习一个变形场以在姿态间建立密集对应关系；然后，采用逐步解耦策略进一步分离静止部分和移动部分，从而实现相机和物体运动的稳健分离；最后，通过一个自监督损失，以强化跨视图和跨姿态一致性，共同优化几何、外观和运动学。
### Conclusion
在标准基准和现实世界示例上的实验表明，该方法在输入假设远弱于现有方法的情况下，可以生成准确且详细的附着物体表示。
## 374. `cs.CV` - MICACL: 多实例类别感知对比学习在长尾动态面部表情识别中的应用 [PDF](https://arxiv.org/pdf/2509.04344), [HTML](https://arxiv.org/abs/2509.04344)
### Authors
Feng-Qi Cui,Zhen Lin,Xinlong Rao,Anyang Tong,Shiyao Li,Fei Wang,Changlin Chen,Bin Liu
### Background
动态面部表情识别（DFER）面临显著挑战，包括类别分布的长尾现象和时空特征模型的复杂性。现有基于深度学习的方法虽然提升了DFER的表现，但在处理这些问题时往往导致了严重的模型诱导偏差。
### Innovation
提出了一个名为MICACL的新型多实例学习框架，该框架结合了时空依赖性建模和长尾对比学习优化。设计了Graph-Enhanced Instance Interaction Module (GEIIM)来通过自适应邻接矩阵和多尺度卷积捕获相邻实例之间复杂的时空关系。开发了Weighted Instance Aggregation Network (WIAN)，基于实例的重要性动态分配权重。此外，提出了Multiscale Category-aware Contrastive Learning (MCCL)策略来平衡主要和次要类别的训练。
### Conclusion
在野外数据集（DFEW和FEVR39k）上的大量实验表明，MICACL实现了最先进的性能，并且具有更高的鲁棒性和泛化能力。
## 375. `cs.CV` - 从体戴摄像 footage 缝合故事：创建事故全景摘要 [PDF](https://arxiv.org/pdf/2509.04370), [HTML](https://arxiv.org/abs/2509.04370)
### Authors
Dor Cohen,Inga Efrosman,Yehudit Aperstein,Alexander Apartsin
### Background
一线救援人员广泛采用体戴摄像头记录事故现场并支持事件后分析。然而，在时间紧迫的情况下，审查 lengthy 视频片段是不切实际的。有效的态势感知需要一个简明的视觉摘要，可以在短时间内被快速理解。为此，本研究提出了一种基于计算机视觉的管道，将体戴摄像头的视频片段转化为能概要化事故现场信息的全景图像。这种方法利用单目同时定位与建图（SLAM）来估计摄像机轨迹并重建环境的空间布局。然后，通过聚类摄像机姿态来识别关键视点，并从每个聚类中选择代表性的画面。最后，使用多帧拼接技术将这些画面融合成空间上一致的全景图像。这一过程生成的摘要使得理解和处理复杂环境变得更加迅速，并有助于提高决策效率和事故审查过程中的效率。
### Innovation
本研究提出了一种基于计算机视觉的管道，通过单目SLAM技术估计摄像机轨迹并重建环境的空间布局，进而生成事故现场的简明全景图像。这种方法强调了通过聚类摄像机姿态识别关键视点，并使用多帧拼接技术将代表性的画面融合成空间上一致的全景图像。这种技术能够有效缩短时间紧迫情况下对视频片段的审查过程，获得更加直观、快速理解事故现场的工具。
### Conclusion
本研究提出了一种能够有效生成事故现场全景图像的方法，该方法能够快速提炼高信息量的视觉摘要，并帮助提高救援人员在紧急情况下的决策效率。通过计算机视觉技术的介入，救援人员能够更好地理解和评估事故现场，从而提高应对事故的能力。
## 376. `cs.CV` - AnomalyLMM: 跨接生成知识与辨别检索的文本基础背景人物异常搜索 [PDF](https://arxiv.org/pdf/2509.04376), [HTML](https://arxiv.org/abs/2509.04376)
### Authors
Hao Ju,Hu Zhang,Zhedong Zheng
### Background
随着公众安全需求的增长，基于文本的人物异常搜索已成为一个关键任务，旨在通过自然语言描述检索具有异常行为的个体。与传统的人员搜索任务相比，此任务存在两大独特挑战：（1）文本异常与视觉行为之间的细粒度跨模态对齐，以及（2）在样本稀疏的实际世界场景下的异常识别。尽管大型多模态模型（LMMs）在多模态理解方面表现出色，但它们在详细异常检索方面的潜力仍未被充分利用，主要是由于生成知识与辨别检索之间的领域差距，以及缺乏有效的部署适应策略。
### Innovation
我们提出了AnomalyLMM，这是第一个利用LMMs的框架，用于文本基础背景人物异常搜索。我们的主要贡献包括：（1）一种新的自上而下的流水线，整合了LMMs来桥接生成世界的知识和以检索为中心的异常检测；（2）不依赖训练的适应指南，包括掩蔽跨模态提示、行为显著性预测和知识感知重新排名，从而实现零样本聚焦于细微异常线索。
### Conclusion
通过在PAB数据集上的严格评估，我们验证了所提出方法的有效性，其表现超过了对比基线+0.96%的Recall@1准确率。值得注意的是，我们的方法展示了文本异常与视觉行为之间可解释的对齐，已在定量分析中得到验证。我们的代码和模型将用于未来的研究。
## 377. `cs.CV` - 从编辑器到密集几何估计器 [PDF](https://arxiv.org/pdf/2509.04338), [HTML](https://arxiv.org/abs/2509.04338)
### Authors
JiYuan Wang,Chunyu Lin,Lei Sun,Rongying Liu,Lang Nie,Mingxing Li,Kang Liao,Xiangxiang Chu,Yao Zhao
### Background
使用预训练的文本到图像（T2I）生成模型的视觉先验在密集预测方面取得了成功。然而，密集预测本质上是图像到图像的任务，这表明图像编辑模型可能比T2I生成模型更适合进行微调。为了验证这一假设，本文对编辑器和生成器进行了一项系统分析，以研究它们在密集几何估计中的微调行为。研究发现，编辑器具有固有的结构先验，通过“改进”其内在特征，可以更稳定地收敛，并最终取得比生成器更好的性能。
### Innovation
本文提出了FE2E框架，这是一种开创性的方法，基于扩散转换器（DiT）架构将其先进编辑器应用到密集几何预测中。具体来说，为了满足这一确定性任务的需求，将编辑器原始的流匹配损失重新表述为“一致的速度”训练目标。此外，为了应对编辑器原生的BFloat16格式与任务需求的高精度之间的冲突，使用了对数量化。同时，利用DiT的全局注意力，在单次前向传输中免费地进行深度和法线的联合估计，使得监督信号相互增强。
### Conclusion
无需扩大训练数据，FE2E在零样本单目深度估计和法线估计中实现了显著性能改进，多种数据集上均表现出优异性能。特别是在ETH3D数据集上，FE2E实现了超过35%的性能提升，还优于通过100倍数据训练的DepthAnything系列。
## 378. `cs.CV` - Few-step Flow for 3D Generation via Marginal-Data Transport Distillation [PDF](https://arxiv.org/pdf/2509.04406), [HTML](https://arxiv.org/abs/2509.04406)
### Authors
Zanwei Zhou,Taoran Yi,Jiemin Fang,Chen Yang,Lingxi Xie,Xinggang Wang,Wei Shen,Qi Tian
### Background
流体基于的3D生成模型通常在推理过程中需要大量抽样步骤。尽管Few-step蒸馏方法，特别是一致性模型（CMs），已经在加速2D扩散模型方面取得了显著进展，但对于更复杂的3D生成任务，它们仍然未被充分探索。
### Innovation
本文提出了一个名为MDT-dist的新型框架，用于Few-step 3D流的蒸馏。提出了两个可优化的目标，速度匹配（VM）和速度蒸馏（VD），将优化目标从传输级别转换为速度和分布级别。
### Conclusion
在3D生成框架TRELLIS上的评估表明，该方法将每个流变换器的抽样步骤从25减少到1或2，使用A800实现了0.68s（1步x2）和0.94s（2步x2）延迟，相比提高了9.0倍和6.5倍的速度，同时保持了高视觉和几何保真度。广泛实验表明，该方法显著优于现有CM蒸馏方法，使TRELLIS在Few-step 3D生成中达到优越性能。
## 379. `cs.CV` - 自适应数据集构建以应对现实世界的多模态安全场景 [PDF](https://arxiv.org/pdf/2509.04403), [HTML](https://arxiv.org/abs/2509.04403)
### Authors
Jingen Qu,Lijun Li,Bo Zhang,Yichen Yan,Jing Shao
### Background
多模态大型语言模型（MLLMs）正在迅速发展，带来的安全挑战也随之变得日益复杂。然而，当前的风险导向型数据集构建方法未能覆盖现实中日益复杂的多模态安全场景（RMS），且缺乏统一的安全评估标准使得其整体效果未被验证。
### Innovation
本文提出了一种以图像为导向的自适应数据集构建方法，用于构建RMS。该方法从图像开始，最终构建出包含指导性回答的配对文本和图像。使用此以图像为导向的方法，自动生成了一个包含35,000个图像-文本配对的数据集。此外，还提出了一种标准化的安全数据集评估指标：通过对安全判断模型进行微调，并评估该模型在其他安全任务上的能力来衡量数据集质量。实验表明所提出的图像导向型管道的有效性和可扩展性，提供了一种新的现实世界多模态安全数据集构建视角。
### Conclusion
实验结果证实了图像导向方法在提高数据集构建效率和质量方面的可扩展性和有效性。此方法为现实世界多模态安全数据集的构建提供了新的视角。
## 380. `cs.CV` - 未知探针下X射线劈析重建的神经表示学习 [PDF](https://arxiv.org/pdf/2509.04402), [HTML](https://arxiv.org/abs/2509.04402)
### Authors
Tingyou Li,Zixin Xu,Zirui Gao,Hanfei Yan,Xiaojing Huang,Jizhou Li
### Background
X射线劈析提供纳米级的独特分辨率，在材料科学、生物学和纳米技术中广泛应用。然而，其完全潜力受限于未知照明探针准确重构图像的难题。传统迭代方法和深度学习方法在低剂量、高速实验中低信号条件下往往效率低下，影响重建保真度和该技术的广泛应用。
### Innovation
本文提出了一种新的自主监督框架Ptychographic Implicit Neural Representation (PtyINR)，可同时解决物体和探针恢复问题。通过将物体和探针参数化为连续的神经表示，PtyINR 无需探针预表征即可直接从原始衍射模式进行端到端重建。实验显示，PtyINR 对模拟和实验数据在挑战性低信号条件下表现出卓越的重建质量且具备高度鲁棒性。此外，PtyINR 提供了一种通用化的、基于物理的方法来解决依赖探针的逆向问题，使其适用于各种计算显微术问题。
### Conclusion
PtyINR 提供了一种有效的解决方法，能够在未知探针条件下进行高保真的 X 射线劈析重建，适用于各种低信号和高速实验。它不仅提高了重建质量，还增强了该技术的通用性和适应性，进一步推动了该领域的技术进步。
## 381. `cs.CV` - Durian: 双参考引导的具有属性转移的肖像动画 [PDF](https://arxiv.org/pdf/2509.04434), [HTML](https://arxiv.org/abs/2509.04434)
### Authors
Hyunsoo Cha,Byungjun Kim,Hanbyul Joo
### Background
当前在肖像动画视频生成领域中，缺乏一种能够在零样本条件下将参考图像的面部属性转移到目标肖像上的方法，且在多帧之间实现高保真度和空间一致性属性转移存在挑战。
### Innovation
提出了一种名为Durian的方法，该方法通过引入双参考网络，将面部图像和属性图像的空间特征注入到去噪模型的扩散过程中，以实现跨帧的属性转移。此外，通过提出关键点条件下的图像生成掩码扩展策略和增强属性及面部图像的空间和外观级别变换，提高了模型对位置错位的鲁棒性，从而使得模型能够有效泛化到不同属性和野外参考组合，而无需显式的三元组监督。
### Conclusion
Durian在具有属性转移的肖像动画上达到了最先进的性能，其双参考设计使得在一次生成过程中即可完成多个属性的组合，而无需额外训练。
## 382. `cs.CV` - 使用增强的注意机制的审美图像描述 [PDF](https://arxiv.org/pdf/2509.04378), [HTML](https://arxiv.org/abs/2509.04378)
### Authors
Yilin Tao,Jiashui Huang,Huaze Xu,Ling Shao
### Background
审美图像描述（Aesthetic Image Captioning, AIC）旨在生成图像审美的文本描述，成为计算美学领域的重要研究方向。近年来，预训练的多模态大型语言模型（Multimodal Large Language Models, MLLMs）快速发展，推动了结合视觉和文本模态的审美研究。然而，大多数现有的图像审美研究主要集中在预测审美评分上，在AIC应用方面表现有限。现有的利用MLLMs的AIC工作主要依赖于微调方法，未具体适应MLLMs以专注于目标审美内容。
### Innovation
本文提出了审美显性增强的多模态大型语言模型（Aesthetic Saliency Enhanced Multimodal Large Language Model, ASE-MLLM），这是一个端到端框架，明确将审美显著性纳入MLLMs。在此框架中，引入了图像审美显著性模块（Image Aesthetic Saliency Module, IASM），该模块高效有效地从图像中提取审美显著性特征。此外，设计了IAS-ViT作为MLLMs的图像编码器模块，该模块通过交叉注意机制融合了审美显著性特征和原始图像特征。研究表明，我们的方法在当前主流AIC基准上显著优于传统方法和通用MLLMs，达到最佳水平（SOTA）
### Conclusion
大量的实验表明，我们的方法在当前主流AIC基准上显著优于传统方法和通用MLLMs，实现了最先进的性能（SOTA）。
## 383. `cs.CV` - 从线到形状：基于霍夫变换的X射线准直器几何约束分割 [PDF](https://arxiv.org/pdf/2509.04437), [HTML](https://arxiv.org/abs/2509.04437)
### Authors
Benjamin El-Zein,Dominik Eckert,Andreas Fieselmann,Christopher Syben,Ludwig Ritschl,Steffen Kappler,Sebastian Stober
### Background
X射线成像中的准直限制了辐射暴露于感兴趣区域（ROI），并最大限度地减少对患者的辐射剂量。当边缘被散射的X射线辐射遮挡时，检测准直器阴影是一个挑战。尽管如此，准直器形成的多边形阴影的先验知识是显而易见的。因此，作者介绍了一种基于深度学习的分割方法，该方法自然受限于其几何形状。该方法通过集成不同的霍夫变换网络来检测准直边界，并增强其提取ROI中心信息的能力。
### Innovation
该方法通过集成不同的霍夫变换网络来检测准直边界，并增强其提取ROI中心信息的能力。在推理过程中，结合两项任务的信息来生成细化的、符合几何约束的分割掩模。该方法在多种实际X射线图像的测试集中实现了稳健的准直区域重建。
### Conclusion
该方法在多种实际X射线图像的测试集中实现了稳健的准直区域重建，获得了4.3-5.0mm的中位Hausdorff距离。此应用最多涉及四条阴影边界，但该方法基本不受边数限制。
## 384. `cs.CV` - 虚拟试衣间：从单张图片生成任意长度的虚拟试穿视频——技术预览 [PDF](https://arxiv.org/pdf/2509.04450), [HTML](https://arxiv.org/abs/2509.04450)
### Authors
Jun-Kun Chen,Aayush Bansal,Minh Phuoc Vo,Yu-Xiong Wang
### Background
文章介绍了一种全新的视频生成模型——虚拟试衣间（VFR），它可以生成任意长度的虚拟试穿视频。这种模型解决了之前需要大量时间和资源来生成长视频的问题，同时赋予了生成任意长度视频的灵活性。该任务面临的主要挑战有两个：确保相邻片段之间的局部平滑性和保持不同片段之间的时间全局一致性。
### Innovation
文章提出了VFR框架，通过前缀视频条件确保平滑性，并使用一个全面捕捉人类全身外观的360度视频（锚视频）来强制保持一致性。这种框架可以在各种动作下生成可以拥有局部平滑性和时间全局一致性的分钟级虚拟试穿视频，从而在长虚拟试穿视频生成领域中取得了先驱性的成果。
### Conclusion
VFR以其创新的视频生成方法，克服了传统视频生成方法中对大量资源和时间的依赖，成功解决了长视频生成中的挑战，为虚拟试穿视频生成开辟了新的路径。
## 385. `cs.CV` - 电话游戏：评估统一模型中的语义漂移 [PDF](https://arxiv.org/pdf/2509.04438), [HTML](https://arxiv.org/abs/2509.04438)
### Authors
Sabbir Mollah,Rohit Gupta,Sirnam Swetha,Qingyang Liu,Ahnaf Munir,Mubarak Shah
### Background
在视觉语言模型(VLM)研究中，采用单一统一模型(UM)同时处理视觉理解(图像到文本：I2T)和视觉生成(文本到图像：T2I)任务开拓了新的研究方向。现有评估方法通常孤立地考虑这两种能力，例如，在T2I任务中使用FID和GenEval，在I2T任务中使用MME和MMBench基准，但这些单次评估并未揭示模型能否从理解概念到准确生成或通过语义循环保持一致性。因此，需要一种新的评估框架来量化跨模态稳定性及其共享表示的语义一致性。
### Innovation
本文提出了统一一致性框架(UCF-UM)，这是一种循环评估协议，通过在多个生成过程中交替执行I2T和T2I任务来量化语义漂移。UCF-UM包括三个指标：(i)平均累计漂移(MCD)，一种基于嵌入的总体语义损失量化指标；(ii)语义漂移率(SDR)，用于总结语义衰减率；(iii)多代一致性评价(MGG)，这是一种扩展的GenEval，对象级合规性得分。通过建立新的基准ND400（从中采样自NoCaps和DOCCI），评估了七种最近的模型，揭示了不同模型在交替任务中的跨模态稳定性的显著差异。
### Conclusion
我们的结果强调了跨模态一致性评估作为标准I2T和T2I评估的必要补充，并提供了用于统一模型跨模态稳定性和共享表示强度的实用指标。
## 386. `cs.CV` - Plot'n Polish: 利用文本到图像扩散模型的零样本故事情景可视化和解耦编辑 [PDF](https://arxiv.org/pdf/2509.04446), [HTML](https://arxiv.org/abs/2509.04446)
### Authors
Kiymet Akdemir,Jing Shi,Kushal Kafle,Brian Price,Pinar Yanardag
### Background
文本到图像的扩散模型在生成多样性和详细视觉效果方面展示了显著的能力，尤其是在多个领域。故事情节可视化作为一种特别有前景的应用正在兴起。然而，随着其在真实世界创意领域的应用增加，需要在生成后以一致的方式提供增强的控制、细化和修改图片的能力成为一个重要挑战。现有的方法普遍缺乏在多个帧中保持视觉和叙述一致性的同时应用细粒度或粗粒度编辑的灵活性，这使创作者难以无缝地构建和细化视觉故事.
### Innovation
我们提出了Plot'n Polish，一种零样本框架，能够实现一致的故事生成，并在不同层次的细节提供对故事情节可视化的细粒度控制。这种方法解决了现有的方法普遍缺乏的在多个帧中保持视觉和叙述一致性的同时应用细粒度或粗粒度编辑的灵活性问题，使创作者能够无缝地构建和细化视觉故事.
### Conclusion
Plot'n Polish提供了一种新的方法，使创作者能够以一致的方式生成故事，并在不同层次的细节提供细粒度控制，从而提高故事情节可视化的一致性和可控性。
## 387. `cs.CV` - 从梯度动态洞察：梯度自标定规范化 [PDF](https://arxiv.org/pdf/2509.03677), [HTML](https://arxiv.org/abs/2509.03677)
### Authors
Vincent-Daniel Yun
### Background
梯度动态在决定深层神经网络的稳定性和泛化能力方面发挥着核心作用。现有的研究表明，梯度方差和标准差在训练过程中会表现出一致的变化，这些变化不仅在不同层之间存在，也在整个网络中可见。基于这一观察，论文探讨了梯度动态演化的特点，为后续研究提供了理论依据和实践指导。
### Innovation
研究提出了一种无超参数的梯度规范化方法，能够使梯度缩放与它们自然演化相匹配。该方法可以防止不必要的放大，稳定优化过程，并保持收敛保证。实验证明，在CIFAR-100基准测试上，该方法可以在不牺牲泛化能力的情况下，保持甚至提高测试精度，特别是在使用ResNet-20、ResNet-56和VGG-16-BN网络时表现尤为显著。此外，研究还强调了直接跟踪梯度动态的重要性，旨在弥合理论期望与实际行为之间的差距，并为未来的优化研究提供新的视角。
### Conclusion
实验结果表明，作者提出的方法不仅能够保持或提高测试准确率，而且能在强烈泛化的条件下稳定优化过程。这种方法为梯度规范化提供了新的思路，并有可能为未来的优化研究带来新的突破。
## 388. `cs.CV` - 在一预算下制图：优化空间数据采集以进行机器学习 [PDF](https://arxiv.org/pdf/2509.03749), [HTML](https://arxiv.org/abs/2509.03749)
### Authors
Livia Betti,Farooq Sanni,Gnouyaro Sogoyou,Togbe Agbagla,Cullen Molitor,Tamma Carleton,Esther Rolf
### Background
在农业、生态学和人类发展等领域，使用卫星图像进行机器学习（SatML）受到标记训练数据稀疏性的限制。尽管卫星数据覆盖全球，但标记训练数据集往往规模小、地理分布集中且收集目的多样（例如，行政调查或现场测量）。过去SatML研究主要集中在开发新的模型架构和训练算法来应对稀缺的训练数据，而没有直接建模数据条件。这导致希望利用SatML进行大规模监测的科学家和政策制定者对如何收集额外数据以最大化性能感到不确定。
### Innovation
本研究提出了第一种优化空间训练数据的问题表述，考虑了异质数据收集成本和现实预算约束。还介绍了处理此问题的新方法。在跨三大洲和四项任务的模拟实验中，研究策略揭示了从样本优化中获得的重要收益。进一步实验界定了哪种情况下优化采样特别有效。所提出的问题表述和方法设计旨在适用于SatML应用领域的多种情境；特别强调了一种特定问题设定，在此设定中合作者可以立即利用我们的研究成果来增强托go的农业调查，以进行SatML监测。
### Conclusion
通过优化空间数据采集，研究为在预算限制下进行精确的卫星图像机器学习提供了新的解决方案，并确定了何时使用优化采样可以提高性能，尤其是在特定的应用场景中。
## 389. `cs.CV` - TRUST-VL：通用多模态误导检测的可解释新闻助手 [PDF](https://arxiv.org/pdf/2509.04448), [HTML](https://arxiv.org/abs/2509.04448)
### Authors
Zehong Yan,Peng Qi,Wynne Hsu,Mong Li Lee
### Background
多模态误导信息，包括文本、视觉和跨模态的扭曲，对社会造成日益增长的威胁，这种威胁在生成型AI的作用下被进一步放大。现有的方法通常侧重于单一类型的扭曲，并且难以将知识泛化到未见过的情景中。
### Innovation
本文观察到不同类型的扭曲共享某些推理能力，同时还需要特定任务的能力。因此，本文假设跨类型联合训练有助于知识共享和增强模型的泛化能力。为此，本文提出了TRUST-VL，一种统一且可解释的视觉-语言模型，用于通用多模态误导检测。TRUST-VL采用了一个新的问答视觉增强模块，用于提取特定任务的视觉特征，并构建了包含198K样本的大规模指令数据集TRUST-Instruct，这些样本与人类事实核查工作流中的结构化推理链对齐。广泛的实验在领域内和零样本基准上表明，TRUST-VL在性能上达到了最先进的水平，并且具有良好的泛化能力和可解释性
### Conclusion
TRUST-VL表现出卓越的性能和解释性，并且已经在领域内和零样本基准测试中取得了最新的研究成果。
## 390. `cs.CV` - 跨越鸿沟：从视角到全景视觉的综述 [PDF](https://arxiv.org/pdf/2509.04444), [HTML](https://arxiv.org/abs/2509.04444)
### Authors
Xin Lin,Xian Ge,Dizhe Zhang,Zhaoliang Wan,Xianshun Wang,Xiangtai Li,Wenjie Jiang,Bo Du,Dacheng Tao,Ming-Hsuan Yang,Lu Qi
### Background
全景图像（ODIs）因其提供完整的360°视野，正在虚拟现实、自动驾驶和实体机器人等多元应用中受到越来越多的关注。尽管全景图像具有独特性，但在几何投影、空间分布和边界连贯性方面与视角图像存在显著差异，使得直接从中视角的方法进行领域适应变得极具挑战性。本综述回顾了近来的全景视觉技术，重点关注视角到全景的适应问题。
### Innovation
本研究涵盖超过300篇论文中的20多项代表性任务，并针对不同任务对全景方法进行了横跨分析。此外，还对全景视觉进行了跨任务比较，将其分为视觉质量增强与评估、视觉理解、多模态理解与视觉生成四大类。进一步讨论了数据、模型和应用方面的开放挑战和未来方向。
### Conclusion
本综述旨在提供新的见解和未来视角，推动全景视觉技术的发展。希望本文对全景视觉技术的研究有所助益。更多信息请参见我们的项目页面：https://github.com/danno20/panoramic-survey
## 391. `cs.CV` - LuxDiT: 使用视频扩散变换器进行照明估计 [PDF](https://arxiv.org/pdf/2509.03680), [HTML](https://arxiv.org/abs/2509.03680)
### Authors
Ruofan Liang,Kai He,Zan Gojcic,Igor Gilitschenski,Sanja Fidler,Nandita Vijaykumar,Zian Wang
### Background
计算机视觉和图形领域从单张图像或视频中估计场景照明长期是一个挑战。基于学习的方法受到真实HDR环境图数据稀缺性的限制，这些数据昂贵且种类有限。尽管最近的生成模型提供了强大的先验知识以用于图像合成，但照明估计仍然困难，因为其依赖间接视觉线索、需要推断全局（非局部）上下文以及必须恢复高动态范围输出。
### Innovation
我们提出了一种名为LuxDiT的新颖数据驱动方法，该方法对视频扩散变换器进行了微调，使其能够根据视觉输入生成HDR环境图。该模型通过一个大型合成数据集（包含多种光照条件）进行训练，学习从间接视觉线索中推断照明并有效泛化到现实场景中。为了改善输入和预测环境映射之间的语义一致性，我们引入了一种基于收集的HDR全景图数据集的低秩适应微调策略。我们的方法在定量和定性评估中都优于现有最先进的技术，能够生成准确且具有真实角度高频细节的照明预测。
### Conclusion
我们的方法能够在现实场景中实现准确的照明预测，具有真实的角度高频细节，在量化和定性评估中均优于现有的先进技术。
## 392. `cs.CV` - 数据增强感知量化知识蒸馏 [PDF](https://arxiv.org/pdf/2509.03850), [HTML](https://arxiv.org/abs/2509.03850)
### Authors
Justin Kur,Kaiqi Zhao
### Background
量化意识训练（QAT）和知识精炼（KD）已经被结合使用以创建具有竞争性能的低位深学习模型。现有的KD和QAT工作主要集中在通过设计更好的KD损失函数或优化QAT的正向和反向传播来提高量化模型的准确性。然而，对输入变换，如数据增强（DA）的影响给予了不足的注意。特别是在低精度模型中，量化意识KD和DA之间的关系仍然未被研究。
### Innovation
该论文提出了一种新的度量标准，根据数据增强策略提高上下文互信息（与图像标签直接无关的信息）的能力来评价DA。此外，该方法自动排名并选择DA，几乎不需要额外的训练开销，且适用于任何KD或QAT算法。通过广泛的评估，使用该方法选择DA策略显著提升了现有QAT和KD工作的性能。
### Conclusion
该方法能够在不同模型架构和数据集上显著提高现有QAT和KD工作的效果。
## 393. `cs.CV` - 多维AI驱动框架用于分析历史城市保护区的游客感知：以上海为例 [PDF](https://arxiv.org/pdf/2509.03830), [HTML](https://arxiv.org/abs/2509.03830)
### Authors
Kaizhen Tan,Yufan Wu,Yuxuan Liu,Haoran Zeng
### Background
历史城市保护区在保护文化遗产的同时，还为旅游业和日常活动提供了充满活力的空间。理解游客对这些环境的感知对于可持续的、以人为本的城市规划至关重要。这篇研究提出了一种基于多模态数据的AI辅助框架，用于分析历史城市保护区内的游客感知，该框架结合了焦点提取、颜色主题分析和情感挖掘。研究应用了12个上海市中心的历史保护区的具体案例，应用了微调后的语义分割模型从游客共享的照片中识别视觉聚焦区域。为了评估审美偏好，研究提取了主导色并分析了它们在各个保护区内的空间分布。颜色主题进一步在社交媒体照片和真实世界的街道视图之间进行比较，揭示了显著的差异，这些差异不仅反映了风格偏好，还反映了感知偏差。游客评论通过结合规则基础方法和多任务BERT模型的混合情感分析方法进行了评估。结果揭示了审美吸引力和情感回应在空间上的变化。
### Innovation
提出了一个基于多模态数据的多维AI框架，该框架集成焦点提取、颜色主题分析和情感挖掘，应用于上海市12个历史保护区的实际案例研究。此框架通过社交媒体数据分析游客对历史城市保护区的感知，揭示了游客视觉期望与实际环境之间的差距，强调了风格偏好和感知偏差，并利用混合情感分析方法评估游客评论，提供了审美吸引力和情感回应的空间变化视图。
### Conclusion
该框架提供的多维、基于数据的分析方法有助于理解游客对历史城市保护区的感知，并为旅游业、文化遗产保护和美观城市空间设计提供了依据。研究展示了在不依赖单一技术创新的基础上，如何通过综合的方法提供有价值的见解和实证数据支持。
## 394. `cs.CV` - MobileRAG：通过检索增强生成增强移动代理 [PDF](https://arxiv.org/pdf/2509.03891), [HTML](https://arxiv.org/abs/2509.03891)
### Authors
Gowen Loo,Chang Liu,Qinghong Yin,Xiang Chen,Jiawei Chen,Jingyuan Zhang,Yu Tian
### Background
手机已成为人们日常生活中不可或缺的一部分，渗透到现代社会的各个方面。随着大规模语言模型（LLMs）的不断进步，许多基于LLM的移动代理相继出现。这些代理能够准确解析多样化的用户查询，并自动辅助用户完成复杂的或重复的操作。然而，现有的代理仍然存在以下问题：1）高度依赖LLM的理解能力，可能会导致操作错误或遗漏步骤；2）缺乏与外部环境的互动，在应用程序无法完成用户查询时通常会终止任务；3）缺乏记忆能力，每次指令都需要重新构建界面，无法从以前的错误中学习和纠正。
### Innovation
我们提出了MobileRAG，一种增强型移动代理框架，利用检索增强生成（RAG）技术。MobileRAG包括InterRAG、LocalRAG和MemRAG三个部分，可以更快速、准确地识别用户查询并完成复杂的、长序列的移动任务。此外，为了更全面地评估MobileRAG在实际中的应用情况，我们引入了MobileRAG-Eval基准，该基准包含许多需要外部知识支援的真实世界的复杂移动任务。大量实验结果表明，MobileRAG相比最先进的方法能以更少的操作步骤更轻松地完成实际任务，提高了10.3%的效果。
### Conclusion
MobileRAG基于RAG技术，解决了现有移动代理依赖LLM解释理解能力、缺乏与外部环境互动和缺少记忆能力等问题。MobileRAG在实际移动任务中表现优异，显著降低了解决问题所需的操作步骤，且公开提供了代码。
## 395. `cs.CV` - TensoIS: 朝着前馈张量逆向次表面对具有佩林分布的异质介质的一种尝试 [PDF](https://arxiv.org/pdf/2509.04047), [HTML](https://arxiv.org/abs/2509.04047)
### Authors
Ashish Tiwari,Satyam Bhardwaj,Yash Bachwana,Parag Sarvoday Sahu,T.M.Feroz Ali,Bhargava Chintalapati,Shanmuganathan Raman
### Background
从图像估计异质介质的散射参数是一个严重欠约束的难题。大多数现有方法通过分析-合成方法对BSSRDF进行建模，或者是利用可微体积渲染技术来解释异质性。然而，绝大多数这些方法假设介质是均匀的。而且，目前我们不清楚任何可以具体模型真实世界中异质散射参数的分布。有趣的是，Perlin和分形佩林噪声这样的过程噪声模型在表示自然、有机和无机表面的复杂异质性方面非常有效。因此，作者创造了一个名为HeteroSynth的合成数据集，该数据集包括使用分形佩林噪声建模的异质介质的逼真图像。然后，作者提出了TensoIS，一个基于学习的前馈框架，用于从稀疏的多视角图像观测中估计这些佩林分布的异质散射参数。
### Innovation
提出了一个学习驱动的前馈框架TensoIS，用于从多视角稀疏图像观测中估计佩林分布的异质散射参数。TensoIS采用可学习的低秩张量分量来表示散射体积，而不是直接预测三维散射参数体。通过在HeteroSynth测试集、从开源真实体积模拟中获得的烟和云几何形状以及一些现实世界的样本上进行评估，验证了该框架的有效性。
### Conclusion
该研究尝试利用佩林噪声分布来建模现实世界的异质散射现象，为前馈逆向次表面散射提供了一种可能的解决方案。
## 396. `cs.CV` - ContraGS：压缩且可训练的高效率高保真度3D高斯点积技术 [PDF](https://arxiv.org/pdf/2509.03775), [HTML](https://arxiv.org/abs/2509.03775)
### Authors
Sankeerth Durvasula,Sharanshangar Muhunthan,Zain Moustafa,Richard Chen,Ruofan Liang,Yushi Guan,Nilesh Ahuja,Nilesh Jain,Selvakumar Panneer,Nandita Vijaykumar
### Background
3D Gaussian Splatting (3DGS) 是一种能够以高质量和实时渲染效果建模现实场景的先进技术。通常，使用大量3D高斯函数可以提高表示质量，但这会显著增加用于存储模型参数的GPU设备内存。因此，一个大型模型需要配备有高内存容量的强GPU，并且由于内存访问和数据移动的低效率问题，培训和渲染会更加缓慢。
### Innovation
ContraGS是一个能够在压缩3DGS表示的同时进行直接训练的方法，而不减少高斯计数，因此在模型质量几乎没有损失的情况下实现。ContraGS通过使用代码簿来紧凑地存储整个训练过程中的一组高斯参数向量，从而显著减少了内存消耗。对于代码簿压缩表示的参数估计，ContraGS将其问题重新表述为贝叶斯推理问题，并提供了一个框架以有效地使用MCMC抽样从这些压缩表示的后验分布中抽样。通过ContraGS，数据显示在训练期间峰值内存减少了平均3.49倍，并且加速了训练和渲染（分别加速了1.36倍和1.88倍），同时重训接近最先进的质量水平。
### Conclusion
ContraGS通过使用代码簿和MCMC抽样在压缩表示中重新估计参数，显著降低了对内存的需求，并加速了训练和渲染，而不牺牲模型的质量。
## 397. `cs.CV` - OVGrasp: 基于多模态意图检测的开放式词汇抓取辅助 [PDF](https://arxiv.org/pdf/2509.04324), [HTML](https://arxiv.org/abs/2509.04324)
### Authors
Chen Hu,Shan Luo,Letizia Gionfrida
### Background
对于躯体运动功能受损的个体，在未确定且多变的环境中，抓取辅助尤为重要，以恢复其自主能力。现有的抓取辅助技术在处理多种物体分类和用户意图的情况下表现不佳，尤其是在不确定的环境中更为困难。
### Innovation
提出了OVGrasp，一种基于软外骨骼的分层控制框架，结合了RGB-D视觉、开放式词汇提示和语音命令，实现强大的多模态交互。OVGrasp引入了视觉-语言基础模型和开放式词汇机制，支持零样本检测未见过的物体，无需重新训练。多模态决策者进一步融合空间和语言线索，以在多物体场景中推断用户意图，如抓取或释放。
### Conclusion
全框架部署在定制的以第一人称视角穿戴的外骨骼上，并在15种物体的三个抓取类型上进行了系统评估，十名参与者的结果显示，OVGrasp的抓取能力评分（GAS）达到了87.00%，显著优于现有最先进的基线，并实现了与自然手部运动更好的动态匹配。
## 398. `cs.CV` - FedQuad: 联邦随机四元组学习以减轻数据异质性 [PDF](https://arxiv.org/pdf/2509.04107), [HTML](https://arxiv.org/abs/2509.04107)
### Authors
Ozgu Goksu,Nicolas Pugeault
### Background
联邦学习（FL）提供分布式模型训练，有效解决了分布式数据和隐私保护等问题。然而，全局模型的一般化经常受到客户端间数据异质性的挑战，特别是在数据集规模有限和类别不平衡的情况下，这些挑战更为显著。为了应对数据异质性，提出了一种新颖的方法FedQuad，该方法显式优化了客户端内类别间的较小方差和类别间较大的方差，从而减少了模型聚合对客户端表示的全局模型的负面影响。该方法通过在保留特征空间中减少相似类对之间的距离并增加负类对之间的距离，有效地解耦客户端数据。
### Innovation
提出了一种名为FedQuad的新方法，该方法通过在客户端内类别间优化较小的方差和类别间的较大方差来减少模型聚合对全局模型的负面影响。通过在共享特征空间中减少相似类对之间的距离并增加负类对之间的距离，该方法有效地解耦了客户端数据。
### Conclusion
在CIFAR-10和CIFAR-100数据集上进行的评估表明，与现有方法相比，FedQuad方法在各种数据分布和大量客户端下的表现更优。此外，对基于度量学习的策略在监督学习和联邦学习框架中的分析进一步展示了其在联邦设置中解决表示学习挑战的有效性。
## 399. `cs.CV` - SMooGPT: 使用大型语言模型生成风格化运动 [PDF](https://arxiv.org/pdf/2509.04058), [HTML](https://arxiv.org/abs/2509.04058)
### Authors
Lei Zhong,Yi Yang,Changjian Li
### Background
风格化运动生成领域近年来在计算机图形学中有所发展，尤其得益于扩散模型的快速进步。该任务的目标是在保留运动内容的同时生成符合所需运动风格的新动作，例如“像猴子一样环形行走”。现有研究试图通过动作风格转换或条件动作生成来解决这一问题。他们通常将动作风格嵌入隐空间，并在隐空间中隐式引导动作，但这些方法存在低可解释性和低控制力、对新风格的一般化能力有限、并且难以生成除了“行走”之外的动作，这主要是由于公共风格化数据集中的强烈偏见。本文基于观测提出一种新的从推理-组成-生成视角解决风格化运动生成问题的方法。
### Innovation
本文提出了一种新的方法，通过自然语言在人体部位中心化的方式来描述人类动作，利用大型语言模型（LLMs）的优势作为推理者、组成者和生成者来生成所需的风格化运动。方法在人体部位文本空间执行，具有更高的可解释性，能够实现细粒度的动作控制，有效地解决了运动内容和风格之间的潜在冲突，且得益于LLMs的开放词汇量能力，方法能很好地推广到新风格上。
### Conclusion
全面的实验和评估以及用户知觉研究表明，我们的方法在纯文本驱动的风格化运动生成中尤其有效。
## 400. `cs.CV` - 全局到局部或局部到全局？通过高效局部搜索和有效全局重新排名提升图像检索 [PDF](https://arxiv.org/pdf/2509.04351), [HTML](https://arxiv.org/abs/2509.04351)
### Authors
Dror Aiger,Bingyi Cao,Kaifeng Chen,Andre Araujo
### Background
当前的图像检索系统大多基于全局图像特征搜索大型数据库，并使用局部图像特征匹配技术进行初步结果的重新排名。这种设计被称为全局到局部，它源于局部匹配方法的计算成本高，只能对少量检索结果应用。然而，新兴的高效局部特征搜索方法为大规模详细检索提供了新可能，特别是在找到全局特征搜索可能遗漏的部分匹配方面。此外，基于全局特征的重新排名方法显示出令人鼓舞的结果，具有高计算效率。本工作利用这些基础构建块，提出了一种局部到全局的检索范式，结合高效局部特征搜索和有效全局特征重新排名。
### Innovation
本文提出了局部到全局的检索范式，结合了高效局部特征搜索和有效全局特征重新排名。特别地，提出了一个基于局部特征检索相似性的全局特征计算方法，利用多维缩放技术生成嵌入，使其尊重搜索过程中获得的局部相似性，从而显著提升重新排名效果。
### Conclusion
实验证明这种方法具有良好的检索性能，在Revisited Oxford和Paris数据集上取得了新的最先进技术指标。
## 401. `cs.CV` - 基于扩散模型耦合先验的Flow Matching直行化 [PDF](https://arxiv.org/pdf/2311.16507), [HTML](https://arxiv.org/abs/2311.16507)
### Authors
Siyu Xing,Jie Cao,Huaibo Huang,Haichao Shi,Xiao-Yu Zhang
### Background
已有的生成模型方法多采用多轮训练或多批量内的知识，这在指导短期生成中找到合适的耦合策略以直行轨迹方面存在挑战。当前的Flow Matching方法在这一过程中存在问题。
### Innovation
提出了一个新的方法——StraightFM，它通过整个分布级别的耦合策略直行轨迹。StraightFM在训练过程中通过一个扩散模型计算图像和噪声的耦合先验，以改进短期生成中的图像质量。
### Conclusion
实验结果表明，StraightFM在像素空间和潜在空间中仅在5步内生成高质量的样本。此外，无条件的StraightFM与无训练的多模式条件生成无缝兼容，在短期生成中保持高质量的图像生成能力。
## 402. `cs.CV` - 使用 Stable Diffusion 进行卡尔文与 Hobbes 漫画风格转换 [PDF](https://arxiv.org/pdf/2312.03993), [HTML](https://arxiv.org/abs/2312.03993)
### Authors
Asvin Kumar Venkataramanan,Sloke Shrestha,Sundar Sripada Venugopalaswamy Sriraman
### Background
该项目总结了我们对卡尔文与霍布斯漫画集进行稳定扩散微调的过程。目的是将任意给定的输入图像转换为卡尔文与霍布斯的漫画风格，从而实现风格转换。
### Innovation
使用低秩适应（LoRA）训练稳定扩散v1.5，以有效加快微调过程；由变分自编码器（VAE）处理的扩散过程被称为 U-net。
### Conclusion
结果在训练时间和输入数据质量有限的情况下视觉上令人印象深刻。
## 403. `cs.CV` - SSGaussian：知意义向且结构保存的3D风格迁移 [PDF](https://arxiv.org/pdf/2509.04379), [HTML](https://arxiv.org/abs/2509.04379)
### Authors
Jimin Xu,Bosheng Qin,Tao Jin,Zhou Zhao,Zhenhui Ye,Jun Yu,Fei Wu
### Background
近年来，神经表示的最新进展，如神经辐射场和3D 高斯散点图，引发了将风格迁移应用于3D场景的兴趣。现有的方法可以在保持3D一致性的神经表示上转移风格模式，但难以有效地从参考风格图像中提取和转移高层次的风格语义。此外，现有的风格化结果往往缺乏结构清晰度和分离度，使得难以区分3D场景中的不同实例或对象。
### Innovation
本文提出了一种新颖的3D风格迁移管道，有效整合了预训练2D扩散模型的先验知识。该管道包含两个关键阶段：首先，利用扩散先验生成关键视点的风格化渲染图；接着将这些关键视图的风格化结果转移至3D表示。这个过程包括两项创新设计：1）视图间风格对齐，该设计在UNet的最后一个上采样模块中插入跨视图注意力机制，确保风格化视图在保留风格保真性的同时保持实例级别的连贯性；2）实例级别的风格迁移，通过利用关键视图中实例级别的连贯性，将其有效地转移至3D表示。
### Conclusion
大量的定性和定量实验表明，本文提出的3D风格迁移管道在广泛场景中显著优于现有最先进的方法，包括向前视角到具有挑战性的360度环境。更多沉浸式可视化请访问我们的项目页面：this https URL
## 404. `cs.CV` - 基于多感受野非局部网络和新颖对比正则化的轻量级去雾霾 [PDF](https://arxiv.org/pdf/2309.16494), [HTML](https://arxiv.org/abs/2309.16494)
### Authors
Zewei He,Zixuan Chen,Jinlei Li,Ziqian Lu,Xuecheng Sun,Hao Luo,Zhe-Ming Lu,Evangelos K. Markakis
### Background
近年来，基于深度学习的方法在去雾霾领域占据了主导地位。本文提出了一种由多流特征注意力模块（MSFAB）和交叉非局部块（CNLB）组成的多感受野非局部网络（MRFNLN），以进一步提升效果。首先，通过多尺度特征提取模块（MSFE）提取丰富的特征，该模块包括三个具有不同感受野（1×1，3×3，5×5）的并行卷积，以提取多尺度特征。然后，采用注意力模块使模型能够自适应地关注重要通道/区域。这两个模块构成了MSFAB，并设计了CNLB来捕捉远距离依赖性，通过融合更多先前特征来增强关键和值分支，同时通过空间金字塔下采样策略（SPDS）减少计算和内存消耗，而不会牺牲性能。最后，提出了一种新的细节聚焦对比正则化（DFCR），强调低层级细节并忽略去雾霾专用表示空间中的高层语义信息。
### Innovation
提出的MRFNLN模型结合了多尺度特征提取、自适应注意力机制和新颖的对比正则化，能够有效地捕捉远距离依赖性，同时保持轻量化，并在多个实验数据集上优于现有最先进的去雾霾方法，尽管参数量不到150万。
### Conclusion
提出的MRFNLN模型在去雾霾任务上表现出较高的准确性和较低的计算成本，同时能够有效地保留图像的细节和对比度。实验结果表明，该模型在多个去雾霾基准数据集上优于现有最先进方法。
## 405. `cs.CV` - 超扩散头像：使用网络权重空间扩散进行动态人体头像生成 [PDF](https://arxiv.org/pdf/2509.04145), [HTML](https://arxiv.org/abs/2509.04145)
### Authors
Dongliang Cao,Guoxing Sun,Marc Habermann,Florian Bernard
### Background
创建人类头像是一个高度 desirable但极具挑战性的任务。最近在辐射场渲染方面的进展在个性化动态人类头像方面实现了前所未有的逼真度和实时性能。然而，这些方法通常仅限于基于多人视角视频数据为单个个体训练的人头特定渲染模型，限制了其在不同身份间的泛化能力。另一方面，利用预训练的2D扩散模型的生成方法可以产生卡通化的静态人类头像，这些头像通过基于简单骨架的动画实现，但生成的头像的渲染质量较低，无法捕捉到基于姿态的变形，如衣物褶皱。因此，在本研究中，我们提出了一种新型方法，将人头特定渲染和基于扩散的生成建模的优势结合起来，以实现具有高度逼真度和真实的姿态依赖变形的动态人类头像生成。该方法采用两阶段流水线：首先优化了一组人头特定的UNets，每个网络代表一个动态人类头像，能够捕捉精细的姿态依赖变形；在第二阶段，我们通过优化的网络权重训练了一个超扩散模型。在推理阶段，该方法生成网络权重用于实时、可控制的动态人类头像渲染。我们使用大规模跨身份多视角视频数据集证明了该方法优于现有的最先进的动态人类头像生成方法。
### Innovation
我们将人头特定渲染和基于扩散的生成建模的优势结合起来，设计了一种两阶段流水线方法，用于实现具有高度逼真度和真实的姿态依赖变形的动态人类头像生成。具体来说，该方法首先优化了一组人头特定的UNets，每个网络代表一个动态人像，捕捉复杂的姿态依赖变形；然后，通过优化的网络权重训练了一个超扩散模型。在推理阶段，该方法能够生成网络权重，用于实时、可控的动态人类头像渲染。这种方法在性能上超越了现有的最先进的方法。
### Conclusion
通过我们的方法，可以生成具有高度逼真度和真实的姿态依赖变形的动态人类头像。实验结果证明了该方法在多视角视频数据集上的优越性，其渲染性能与其他最先进的动态人类头像生成方法相比具有显著提高。
## 406. `cs.CV` - 通过更强指导增强生成式数据增强方法在语义分割中的应用 [PDF](https://arxiv.org/pdf/2409.06002), [HTML](https://arxiv.org/abs/2409.06002)
### Authors
Quang-Huy Che,Duc-Tri Le,Bich-Nga Pham,Duc-Khai Lam,Vinh-Tiep Nguyen
### Background
像素级别的标注任务，如语义分割，需要大量的标注工作，传统的方法通过简单的变换如旋转和翻转增加了新图像，但往往缺乏关键语义维度的多样性，并且不能改变高层语义属性。生成模型通过生成合成图像为数据增强提供了解决方案，但传统的可控生成模型在创建有效提示和视觉参考方面存在困难，难以准确反映原始图像的内容和结构。
### Innovation
提出了一种使用可控扩散模型进行语义分割的数据增强管道，包括有效的提示生成方法（Class-Prompt Appending和Visual Prior Blending），以增强真实图像中标注类别的注意力，同时生成精确数量的增强图像并保留分割标记者的结构，以及实现类平衡算法确保合成图像和原始图像合并后的训练集平衡。
### Conclusion
通过对PASCAL VOC数据集的评估，展示了其在生成高质量合成图像方面的有效性用于语义分割。提供的代码可以在这个链接获取。
## 407. `cs.CV` - SPARE: Symmetrized Point-to-Plane Distance for Robust Non-Rigid Registration [PDF](https://arxiv.org/pdf/2405.20188), [HTML](https://arxiv.org/abs/2405.20188)
### Authors
Yuxin Yao,Bailin Deng,Junhui Hou,Juyong Zhang
### Background
现有的基于优化的非刚性配准方法通常基于点对点或点对面距离来最小化配准误差度量，但这可能导致收敛速度慢或细节丢失。
### Innovation
提出了SPARE，一种利用对称点到面距离的新颖公式，以实现鲁棒的非刚性配准。引入了与位置和法线相关的对称点到面距离，从而提供更准确的几何近似，并且可以比现有方法获得更高的准确性。此外，通过引入作为可能的刚性调节项来估计变形法线，并提出了一种交替最小化求解器，利用近优最小化策略。为了使求解器有效初始化，引入了一种基于变形图的粗略对准方法，以提高配准质量和效率。
### Conclusion
大量实验表明，所提出的方法在非刚性配准问题上显著提高了准确性，并且仍然保持较高的求解效率。代码已公开。
## 408. `cs.CV` - 实时目标检测模型的重现研究与基准测试 [PDF](https://arxiv.org/pdf/2405.06911), [HTML](https://arxiv.org/abs/2405.06911)
### Authors
Pierre-Luc Asselin,Vincent Coulombe,William Guimont-Martin,William Larrivée-Hardy
### Background
论文旨在评估最新实时目标检测模型的可复现性和基准性能。由于这些模型在实际应用中（如机器人技术）对推断时间有严格要求，仅依据模型的准确度进行比较是不够的。因此，本文在多种图形卡上比较了大量目标检测模型的准确度和推理速度，并重新实现了DETR、RTMDet、ViTDet和YOLOv7等模型，提出了一个统一的训练和评估管道，以便更好地进行模型比较。此外，作者指出，研究论文在可复现性方面存在普遍缺陷，并且MMDetection预训练模型在有限计算资源下表现出明显的性能下降（更大、更准确的模型表现尤为明显）。实验结果表明精度与速度之间存在显著折衷，无锚点模型（RTMDet或YOLOx模型）尤其明显。所有代码和实验都在指定的开源代码库中公开。
### Innovation
本文提出了一种统一的训练和评估管道，基于MMDetection的功能，以更好地进行模型比较，并重新实现了多个实时目标检测模型。还指出研究论文在可复现性方面存在普遍问题，特别是在使用有限计算资源时MMDetection预训练模型性能严重下降。此外，探究了模型的精度和速度之间的显著折衷，无锚点模型表现尤为明显。
### Conclusion
在多种图形卡上对大量实时目标检测模型进行了准确度和推理速度的比较，重新实现了DETR、RTMDet、ViTDet和YOLOv7等模型，发现无法完全复现原始论文中报告的性能。研究论文在可复现性方面普遍缺乏，并且MMDetection预训练模型在有限计算资源下性能大幅下降。精度与速度之间存在显著折衷，无锚点模型（如RTMDet或YOLOx）表现尤为明显。
## 409. `cs.CV` - DEXOP: 一种用于灵巧人类操作机器人转移的装置 [PDF](https://arxiv.org/pdf/2509.04441), [HTML](https://arxiv.org/abs/2509.04441)
### Authors
Hao-Shu Fang,Branden Romero,Yichen Xie,Arthur Hu,Bo-Ruei Huang,Juan Alvarez,Matthew Kim,Gabriel Margolis,Kavya Anbarasu,Masayoshi Tomizuka,Edward Adelson,Pulkit Agrawal
### Background
背景介绍了需要通过数据收集方法来提高机器人灵巧度。在手术和操作过程中，利用传感器化记录人类手动操作，最大化数据在真实机器人上的可移植性是当前研究的问题。为了解决这个问题，研究人员提出了perioperation范式，并在DEXOP（ Dexterous Exoskeleton for Operations）上进行了实施。DEXOP是一个被动手指外骨骼，旨在最大程度地收集丰富的感官数据（视觉+触觉），用于各种细巧的操纵任务。通过机械连接人类手指和机器人手指，DEXOP提供了直接的触觉反馈，并将人类手的姿态镜像到被动的机器人手上，从而最大限度地将演示技能转移到机器人身上。这种装置使得任务演示对于人类来说更加自然，提高了速度和准确性。实验结果表明，DEXOP在一系列灵巧、接触丰富的任务中能够收集高质量的示范数据。使用DEXOP数据学习的策略显著提高了任务性能，使得在单位数据采集时间内，任务表现更好，从而将DEXOP作为推进机器人灵巧度的一个有力工具成为可能。
### Innovation
创新在于提出了一种perioperation范式，以及DEXOP这一被动手指外骨骼，它直接连接人类手指与机器人手指，提供直接的触觉反馈，并优化了演示技能的转移。此外，DEXOP极大地提高了人类和机器人的任务执行效率和准确性，使得机器人在执行细巧操作任务时更为高效准确。此项研究填补了传统远程操作方法在灵巧任务执行中的效率低下这一空白。
### Conclusion
结论指出，DEXOP能够收集高质量的演示数据，表现出色。使用DEXOP数据训练的策略在单位时间内的任务表现显著优于传统的远程操作方法。DEXOP是一种强大的工具，能够促进机器人的灵巧度。
## 410. `cs.CV` - BOSC：基于后门的开放集合成图像归属框架 [PDF](https://arxiv.org/pdf/2405.11491), [HTML](https://arxiv.org/abs/2405.11491)
### Authors
Jun Wang,Benedetta Tondi,Mauro Barni
### Background
合成图像归属解决通过生成模型产生的图像溯源的问题。研究者们已经探索了生成模型的独特表示，并试图利用这些表示将合成图像与生产该图像的模型关联起来。目前的方法主要是在封闭集场景中分类模型或架构，但没有考虑到可能有未知架构产生的样本。随着AI技术的不断发展，新的生成架构不断涌现，促使研究者开始关注开发能够在开放集场景下工作的工具。现有方法在分类已知模型时效果良好，但是面对未知架构生成的样本时表现不佳，缺乏适应性。因此，如何在开放集场景下有效识别未知模型生成的合成图像成为了一个新的挑战，而这一领域目前尚缺乏相应的解决方案。开源集属性方法的研究有助于提升图像溯源的准确度和适应性，尤其是在未知生成器环境下。
### Innovation
本文提出了一个基于后门攻击的开放集合成图像归属框架BOSC。该框架利用特定触发器设计分类器，通过在训练样本中故意注入特定类别的触发器，促使模型在测试时基于触发特征和类特征建立匹配关系。基于受触发样本训练模型的行为，设计了一种特定分数算法来实现样本拒绝。实验表明，BOSC在综合性能方面超过了现有技术，并且对图像处理的鲁棒性也非常强。经过训练的模型可以有效识别未知架构生成的合成图像，从而提升了合成图像归属的准确度。
### Conclusion
BOSC框架是开放集合成图像归属的一个通用解决方案，不仅能够有效识别已知模型生成的图像，同时也能适应未知模型，满足当前和未来可能出现的新生成架构的需求。该方法为其他图像取证应用提供了可能的解决思路。
## 411. `cs.CV` - 过渡模型：重新思考生成学习目标 [PDF](https://arxiv.org/pdf/2509.04394), [HTML](https://arxiv.org/abs/2509.04394)
### Authors
Zidong Wang,Yiyuan Zhang,Xiaoyu Yue,Xiangyu Yue,Yangguang Li,Wanli Ouyang,Lei Bai
### Background
在生成建模领域存在一个根本性困境：迭代扩散模型虽然能实现卓越的真实感，但计算成本高昂；而高效、几步完成的模型则受限于质量上限。这种生成步骤与输出质量之间的矛盾来源于仅专注于无穷小动态（PF-ODEs）或直接终点预测的限制性训练目标。
### Innovation
本文引入了一种精确的连续时间动力学方程，可以分析定义任意时间段的状态转换。由此提出了名为过渡模型（TiM）的新生成范式，能够适应任意步骤的转换，既可进行单步跳跃也能进行精细粒度的改进。尽管参数量仅为865M，TiM在所有评估的步骤数量上均超过了顶级模型SD3.5（8B参数）和FLUX.1（12B参数）。此外，TiM在采样预算增加时展示出持续的质量提升，即便是在高分辨率应用中也能实现卓越的细节保真度，最多可达到4096x4096的分辨率。
### Conclusion
本文提出了一种名为TiM的新方法，通过精确的连续时间动力学方程，提高生成模型的灵活性和保真度，同时保持高效的计算性能。该方法在各个步骤数量下的表现超过了现有的几个顶级模型，并且展示了与采样预算增加同步的质量提升。
## 412. `cs.CV` - 面向硬件的具有固定大小可重用结构的扩散模型以实现本地图像生成 [PDF](https://arxiv.org/pdf/2411.06119), [HTML](https://arxiv.org/abs/2411.06119)
### Authors
Sanchar Palit,Sathya Veera Reddy Dendi,Mallikarjuna Talluri,Raj Narayana Gadde
### Background
Vision Transformers和U-Net架构被广泛应用于实现Diffusion Models。然而，每种架构在设备上实现时都存在特定的挑战。Vision Transformers需要位置嵌入来保持被处理令牌之间的对应关系，这赋予了它们固定大小、可重用的模块化结构。另一方面，U-Net架构缺乏这些特性，它利用不定大小的中间块进行降采样和上采样，在噪声估计骨干网络中用于扩散过程。为解决这些问题，本文提出了一种架构，该架构使用固定大小、可重用的变压器模块作为核心结构，使得它更适用于硬件实现。
### Innovation
本文提出了一种架构，核心结构是固定大小、可重用的变压器模块。该架构具有低复杂性、无令牌设计、无位置嵌入、统一性及可扩展性，使其非常适合部署在移动和资源受限的设备上。
### Conclusion
提出的模型在无条件和有条件图像生成任务中表现出竞争性和一致的性能。在无条件图像生成任务中，模型在CelebA数据集上实现了最先进的FID分数，为1.6。
## 413. `cs.CV` - FADE: 视频中检测建筑物周围掉落物体的数据集 [PDF](https://arxiv.org/pdf/2408.05750), [HTML](https://arxiv.org/abs/2408.05750)
### Authors
Zhigang Tu,Zitao Gao,Zhengbo Zhang,Chunluan Zhou,Junsong Yuan,Bo Du
### Background
掉落物体从建筑物坠落可能导致行人严重受伤，由于物体体积小、移动速度快且背景复杂，人工监控录像时难以捕捉此类事件。鉴于此，有必要开发自动检测建筑物周围掉落物体的方法，以辅助调查此类事件。本文提出了一种名为FADE的大型、多样化的视频数据集，包含1,881个视频，覆盖18个场景，8类掉落物体，4种天气情况和4种视频分辨率，以促进掉落物体检测的研究。这些数据为研究人员提供了宝贵资源，有助于提高检测精度和效率。
### Innovation
本文创新性地提出了FADE（FAlling Object DEtection around Buildings）数据集和新的物体检测方法FADE-Net，该方法有效地利用了运动信息并生成了高质量且体积较小的检测提案，改进了对建筑物周围掉落物体的检测能力。此外，通过与通用物体检测、视频物体检测和移动物体检测等现有方法进行比较，进一步验证了FADE-Net的有效性和优越性。结果表明，所提出的方法显著优于其他方法，为未来研究提供了有效的基准。
### Conclusion
所提出的FADE-Net方法在FADE数据集上的实验结果显示，其在检测建筑物周围掉落物体方面的性能显著优于其他方法，并为未来相关研究提供了有效基准。数据集和相关代码已公开，可供其他研究团队使用和参考。
## 414. `cs.CV` - OFTSR: One-Step Flow for Image Super-Resolution with Tunable Fidelity-Realism Trade-offs [PDF](https://arxiv.org/pdf/2412.09465), [HTML](https://arxiv.org/abs/2412.09465)
### Authors
Yuanzhi Zhu,Ruiqing Wang,Shilin Lu,Junnan Li,Hanshu Yan,Kai Zhang
### Background
最近的研究表明，扩散和流式生成模型在图像恢复任务中取得了显著的成功，能够产生优于传统深度学习方法的感官质量图像。然而，这些方法要么需要大量的采样步骤以生成高质量的图像，导致计算资源消耗大，要么依赖于常见的模型蒸馏方法，而这种方法通常会导致固定的保真度-现实度权衡，缺乏灵活性。
### Innovation
本文提出了一种新的基于流的one-step图像超分辨率框架——OFTSR，它可以生成可调节保真度和现实度的输出。OFTSR首先通过训练一个条件流式超分辨率模型作为教师模型，然后通过应用特殊的约束来蒸馏教师模型。具体来说，强制one-step学生模型的预测与其教师模型的预测在相同的采样欧拉微分方程轨迹上相符。这种对齐确保了学生模型的单步预测从初始状态与教师模型从较近的中间状态的预测匹配。实验结果表明，OFTSR在one-step图像超分辨率中的性能达到了最新水平，同时能够灵活地调节保真度-现实度权衡。
### Conclusion
通过广泛的实验，我们展示了OFTSR在one-step图像超分辨率中的优越性能，并能够灵活调节保真度-现实度权衡。论文附带了实现代码。
## 415. `cs.CV` - 基于切片Wasserstein距离快速刚性对齐异质图像 [PDF](https://arxiv.org/pdf/2503.13756), [HTML](https://arxiv.org/abs/2503.13756)
### Authors
Yunpeng Shi,Amit Singer,Eric J. Verbeke
### Background
许多计算机视觉应用依赖于相似但非标识图像之间的对齐。现有的对齐方法可能在处理异质图像时不够准确或计算效率低下。
### Innovation
本文提出了一种基于最优传输的快速对齐异质图像的算法。该算法结合了快速傅里叶方法的速度和切片概率度量的稳健性，能够在$O(L^2 text{log} L)$操作中高效计算两个$L times L$图像之间的对齐，并且对图像中的平移、旋转和形变具有鲁棒性。
### Conclusion
该研究提出的方法在进行图像对齐时既高效又稳健，适用于处理涉及大量变形的图像数据。
## 416. `cs.CV` - ARTalk：通过自回归模型实现语音驱动的3D头部动画 [PDF](https://arxiv.org/pdf/2502.20323), [HTML](https://arxiv.org/abs/2502.20323)
### Authors
Xuangeng Chu,Nabarun Goswami,Ziteng Cui,Hanqin Wang,Tatsuya Harada
### Background
现有的基于扩散的方法能够生成自然的面部动作，但生成速度慢限制了它们的应用潜力。
### Innovation
提出了一种新的自回归模型，能够实现实时生成高度同步的唇部动作和真实头部姿态以及眨眼效果，并通过学习从语音到多尺度动作代码库的映射来完成这一目标。此外，该模型能够适应未见过的说话风格，从而生成具有个人风格的3D对话化身。
### Conclusion
广泛的评估和用户研究证明，该方法在唇部同步准确性和感知质量方面优于现有方法。
## 417. `cs.CV` - 通过局部感知监督防御大规模视觉语言模型的视觉攻击 [PDF](https://arxiv.org/pdf/2412.12722), [HTML](https://arxiv.org/abs/2412.12722)
### Authors
Qi Zhou,Tianlin Li,Qing Guo,Dongxia Wang,Yun Lin,Yang Liu,Jin Song Dong
### Background
近期的研究对大型视觉语言模型（LVLMs）在面对恶意注入或扰动输入图像时的脆弱性提出了严重质疑，这些扰动可以误导模型的响应。现有的防御方法表明，这样的视觉攻击对图像修改特别敏感，尤其是裁剪操作，通过在修改后的图像响应中使用多数投票来进行纠正。然而，这些修改通常会导致部分图像，并使语义失真，进而降低了干净图像的响应质量。现有方法直接使用部分图像的响应参与投票，可能导致语义不完整或不准确的问题。为了解决这些问题，本文提出了一种无需训练的黑盒防御方法——DPS（Defense through Partial-Perception Supervision），该方法通过促使模型利用一个仅能感知部分图像的模型生成的响应来监督LVLM的原始响应，从而使模型能够在攻击下调整其响应，同时在干净输入下自信地维持其原始响应。
### Innovation
本文提出了一个无需训练的黑盒防御方法——DPS。与现有的直接利用部分图像响应进行多数投票的方法不同，DPS 使用这些响应来监督 LVLM 对原始图像的响应。这种方法使得在受到攻击时，模型可以基于部分图像的理解进行调整，而在干净输入下保持原有的自信响应，这种方法特别适用于强模型监督弱模型的场景，提升了防御效果。实验证明，该方法在三个流行模型上的六个数据集上将平均攻击成功率降低了76.3%。
### Conclusion
本文提出了一种黑盒、无需训练的方法 DPS，利用部分感知监督来有效防御针对大型视觉语言模型的视觉攻击。在干净的输入下，模型可以自信地维持其原始响应；而在受到攻击时，模型可以调整其响应以进行有效防御。实验结果表明，该方法显著降低了攻击的成功率。
## 418. `cs.CV` - MUNBa: 通过纳什讨价还价实现机器卸载 [PDF](https://arxiv.org/pdf/2411.15537), [HTML](https://arxiv.org/abs/2411.15537)
### Authors
Jing Wu,Mehrtash Harandi
### Background
机器卸载（MU）旨在从模型中选择性地删除有害行为，同时保留模型的整体实用性。MU是一个多任务学习问题，涉及忘记特定概念/数据的目标和保持整体性能之间的平衡。简单地结合这些忘记和保留的目标可能导致梯度冲突和主导关系，阻碍MU算法达到最优解。
### Innovation
本文将MU重新表述为两个玩家的合作博弈，通过梯度提案贡献最大化他们的整体收益并平衡各自的贡献。受纳什讨价还价理论的启发，我们推导出一个闭式解，指导模型向帕雷达托稳定点发展。该框架确保了收敛解，其中任何偏离最终状态都会导致双方的整体目标降低，从而确保每个目标的最优性。与现有MU算法相比，我们的方法在图像分类和图像生成等多个任务上表现出色，实现更好的忘记和保留之间的权衡，并且证明了遗忘精度、泛化保持以及对抗攻击下鲁棒性方面的改进。
### Conclusion
我们的方法在各种任务上有效，包括ResNet、vision-language模型CLIP和文本到图像扩散模型，展示了优于现有最佳MU算法的性能，实现了更好的忘记与保持的平衡，并且在遗忘精度、泛化保持以及对抗攻击鲁棒性方面有所提升。
## 419. `cs.CV` - 模仿放射学滚动：3D胸部CT体积多标签异常分类的全局-局部注意力模型 [PDF](https://arxiv.org/pdf/2503.20652), [HTML](https://arxiv.org/abs/2503.20652)
### Authors
Theo Di Piazza,Carole Lazarus,Olivier Nempont,Loic Boussel
### Background
CT扫描检查数量的快速增加为放射科医生带来了巨大的工作负担，急需自动工具来辅助，如器官分割、异常分类和报告生成。三维CT扫描的多标签分类是一个具有挑战性的任务，因为数据的特点是体积数据且需要检测的异常种类多样。现有的基于CNN的深度学习方法难以有效捕捉长距离依赖性，而Vision Transformers需要大量的预训练，这给实际应用带来挑战。此外，现有的方法没有明确建模放射科医生在浏览CT扫描切片时的导航行为，这需要全局上下文理解和局部细节意识。
### Innovation
该研究提出了CT-Scroll，一种新颖的全局-局部注意力模型，专门设计来模拟放射科医生在分析3D CT扫描时的滚动行为。该方法在两个公开数据集上进行了评估，并通过全面的实验和消融研究，突显了每个模型组件的贡献。
### Conclusion
CT-Scroll模型在3D胸部CT体积的多标签异常分类中显示出其有效性，通过全球-局部注意力机制有效捕捉了长距离依赖性，并成功模拟了放射科医生的导航行为。
## 420. `cs.CV` - CoDiff：基于条件扩散模型的协同3D目标检测 [PDF](https://arxiv.org/pdf/2502.14891), [HTML](https://arxiv.org/abs/2502.14891)
### Authors
Zhe Huang,Shuo Wang,Yongcai Wang,Lei Wang
### Background
协同3D目标检测在自动驾驶领域具有重要意义，因为它通过促进多智能体之间的信息交换，极大提升了每个个体智能体的感知能力。然而，在实践中，由于姿态估计错误和时间延迟，智能体之间的信息融合往往会生成带有空间和时间噪声的特征表示，导致检测错误。扩散模型具有去噪的能力，因此我们探索了使用扩散模型解决多智能体系统之间的噪声问题。本文基于对扩散模型和多智能体系统的理解，结合已有研究和技术背景进行分析。
### Innovation
本文提出了CoDiff，一种新颖的鲁棒协同感知框架，通过利用扩散模型生成更全面和清晰的特征表示来解决噪声问题。CoDiff首次将扩散模型应用于多智能体协同感知中，通过将高维特征图投影到强大的预训练自编码器的潜空间，并在该空间中以个体智能体信息为条件引导扩散模型采样，从而去噪和逐步细化融合的特征。实验结果表明，CoDiff在协作目标检测性能上优于现有方法，并在智能体的姿态和延迟信息具有高噪声的情况下表现出高度的鲁棒性。
### Conclusion
实验研究证明，提出的框架CoDiff在模拟和实际数据集上的协作目标检测性能优于现有方法，并且在智能体的姿态和延迟信息存在高噪声的情况下仍表现出优异的鲁棒性。该代码已发布。
## 421. `cs.CV` - 多样化的图像嵌入采样方法用于生成描述 [PDF](https://arxiv.org/pdf/2502.10118), [HTML](https://arxiv.org/abs/2502.10118)
### Authors
Sania Waheed,Na Min An
### Background
当前最先进的视觉语言模型（VLM）在图像描述方面取得了显著改善，但这也导致了更高的计算复杂性，使得这些模型在资源受限的应用中（例如移动设备和辅助技术）变得不那么实用。较小的VLM倾向于提供高层次的场景描述，但会忽略有助于更深入理解图像的细节。因此，本文提出了一种无需训练的框架，通过使用一个相对较小的VLM（BLIP）作为骨干网络，明确关注图像的不同区域，来增强描述的多样性和信息性。这种方法利用结构化分割产生层次化的表示，捕捉全局和局部语义。该框架无需额外的模型训练，在图像-描述配对、语义完整性和多样性方面表现出与大模型相当的性能，同时保持与人工标注描述的高度相关性和语义完整性，并且在MSCOCO、Flickr30k和Nocaps测试数据集上的Div-2得分为0.735、0.750和0.748.
### Innovation
本文提出了一种无需训练框架，通过利用一个相对较小的VLM（BLIP）作为骨干网络，明确关注图像的不同区域，来增强描述的多样性和信息性。这种方法利用结构化分割产生层次化的表示，捕捉全局和局部语义，从而在保持高度相关性和语义完整性的前提下，实现与大模型相当的图像-描述配对、语义完整性和多样性。
### Conclusion
该方法在MSCOCO、Flickr30k和Nocaps测试数据集上的Div-2得分为0.735、0.750和0.748，保持与人工标注描述的高度相关性和语义完整性，同时增强了描述的多样性和信息性。
## 422. `cs.CV` - 基于深度和法线监督的多视卫星图像隐式曲面重建方法Sat-DN [PDF](https://arxiv.org/pdf/2502.08352), [HTML](https://arxiv.org/abs/2502.08352)
### Authors
Tianle Liu,Shuangming Zhao,Wanshou Jiang,Bingxuan Guo
### Background
卫星成像技术的进步使得获取高分辨率多视角卫星图像变得越来越容易，这促进了地面模型的快速且地点独立的重建。然而，传统立体匹配方法难以捕捉到细节，而神经辐射场（NeRFs）虽能实现高质量的重建，但训练时间过长。此外，如建筑外立面的低可见性、像素间的照明和风格差异、卫星图像中的弱纹理区域等问题，都使得合理地形几何和详细建筑外立面的重建变得困难。
### Innovation
提出了一种名为Sat-DN的新颖框架，利用渐进训练的多分辨率散列网格重建架构，并带有明确的深度指导和表面法线一致性约束，以提高重建质量。多分辨率散列网格加速了训练，而渐进策略逐渐增加学习频率，用粗糙的低频几何结构引导高频细节的重建。深度和法线约束确保了清晰的建筑轮廓和正确的平面分布。
### Conclusion
在DFC2019数据集上的广泛实验表明，Sat-DN在定性和定量评估中均优于现有方法，达到最先进的效果。代码可以在该地址找到：this https URL.
## 423. `cs.CV` - Spatial Transcriptomics 数据完成用于基因表达预测基准 [PDF](https://arxiv.org/pdf/2505.02980), [HTML](https://arxiv.org/abs/2505.02980)
### Authors
Daniela Ruiz,Paula Cárdenas,Leonardo Manrique,Daniela Vega,Gabriel M. Mejia,Pablo Arbeláez
### Background
空间转录组学是一种将组织切片图像与空间分辨的基因表达谱相结合的创新技术。在各种空间转录组学技术中，Visium技术因其高效和准确性而受到最广泛采用，但其高昂的成本、需要专门技术知识以及临床应用缓慢等问题限制了其普及。此外，基因捕获效率低下会导致显著的数据丢失，影响了数据质量。
### Innovation
研究团队提出了一种名为SpaRED的新数据库，汇集了26个公开的数据集，为模型评估提供了一个标准化资源。此外，他们还提出了一个基于变压器的基因表达完成模型SpaCKLE，该模型将现有方法的均方误差降低了82.5%以上。研究团队建立了一个基准（SpaRED基准），对八种最先进的预测模型在原始数据和SpaCKLE完成数据上的表现进行了评估，结果显示SpaCKLE显著提高了所有基因表达预测模型的结果。这一工作构成了目前为止最全面的空间转录组学数据从组织切片图像到基因表达预测的基准。
### Conclusion
我们的贡献构成了迄今为止最全面的空间转录组学数据从组织切片图像到基因表达预测的基准，同时也为未来在空间转录组学的研究打下了基石。
## 424. `cs.CV` - 短视频传播影响力评级：一个新的现实世界数据集和一个新的大规模图模型 [PDF](https://arxiv.org/pdf/2503.23746), [HTML](https://arxiv.org/abs/2503.23746)
### Authors
Dizhan Xue,Shengsheng Qian,Chuanrui Hu,Changsheng Xu
### Background
短视频平台在全球范围内获得了极大的普及，吸引了数百万甚至数十亿用户。最近的研究强调了分析短视频传播的重要性，这通常涉及到发现商业价值、公众意见和用户行为等。此前，缺乏大规模和多平台的短视频传播网络数据集来便利相关研究，同时也缺乏有效的分析方法来评估短视频的传播影响力。
### Innovation
本文创新地提出了一个新的短视频传播影响力评级（SPIR）任务，并从数据集和方法两方面推动SPIR的发展。首先，引入了一个全新的Cross-platform Short-Video (XS-Video) 数据集，该数据集包含5个最大的中国平台的117,720个视频，381,926个样本和535个主题，这些主题经过了从0到9级传播影响力标注。其次，提出了基于新的三阶段训练机制的大规模图模型NetGPT，能够理解和分析短视频传播图，预测短视频的长期传播影响力。实验结果表明，该模型在分类和回归评估指标上均优于其他方法。
### Conclusion
提出的跨平台即时视频数据集XS-Video和NetGPT模型显著提升了短视频传播影响力评级领域的研究，为后续相关研究提供了新的数据和方法基础。
## 425. `cs.CV` - 揭示原行星盘中的细微结构：基于物理约束的神经场方法 [PDF](https://arxiv.org/pdf/2509.03623), [HTML](https://arxiv.org/abs/2509.03623)
### Authors
Aviad Levis,Nhan Luong,Richard Teague,Katherine. L. Bouman,Marcelo Barraza-Alfaro,Kevin Flaherty
### Background
原行星盘是行星形成的场所，解析其三维结构对于理解盘的演化至关重要。ALMA（阿塔卡马大型毫米/亚毫米阵列）的前所未有的分辨率需要能够捕捉传统方法无法达到的特征的建模方法。传统的建模方法难以应对原行星盘的复杂结构，因此需要新的计算框架来解决这一问题。我们介绍了一种结合物理约束神经场、可微渲染的计算框架，并提出了RadJAX，一种GPU加速的完全可微线辐射传输求解器，相比传统射线追踪器实现了高达10,000倍的速度提升，从而使以往无法解决的高维神经重建成为可能。在应用于ALMA CO观测数据的HD 163296时，该框架恢复了CO丰富的层次的垂直形态，揭示了400 au以外处发明显变窄和扁平化的特征，这是现有方法所忽略的。本研究为提取复杂的盘结构及推进我们对原行星演化理解建立了一个新范式。
### Innovation
介绍了结合物理约束神经场与可微渲染的计算框架，提出了RadJAX，一种GPU加速的完全可微线辐射传输求解器，实现了传统射线追踪器10,000倍的速度提升，使高维神经重建成为可能，揭示了原行星盘中以前无法发现的细微结构变化，拓宽了我们对原行星演化的理解。该方法可以捕捉到超越传统方法的特征，为原行星盘研究提供了一种新的工具。
### Conclusion
该研究建立了一种新的计算框架，利用结合物理约束的神经场和可微渲染的GPU加速线辐射传输求解器，首次实现了原行星盘中细微结构的揭示。通过应用于ALMA CO观测数据，研究揭示了400 au之外的CO丰富的层次的明显变化，这为理解原行星系统的演化提供了一种新的潜在途径。这一方法不仅提高了我们对盘结构的理解，还为未来的观察和理论模型提供了重要参照。
## 426. `cs.CV` - POET：通过自动扩展文本到图像生成支持和符合用户个性化需求的提示创造力 [PDF](https://arxiv.org/pdf/2504.13392), [HTML](https://arxiv.org/abs/2504.13392)
### Authors
Evans Xu Han,Alice Qian Zhang,Haiyi Zhu,Hong Shen,Paul Pu Liang,Jane Hsieh
### Background
目前，先进的视觉生成AI工具在创意任务的初始想法阶段具有巨大的潜力，可以生成高质量的、用户指定的独特图像。然而，许多大型文本到图像系统设计上比较广泛适用，产出的结果可能比较常规，限制了创作探索。这些系统还使用了一些对初学者可能较难理解的交互方式。创意最终用户常常以多样而具体的方式操作，而且往往是不可预测的，因此，需要更多的变化和个性化。因此，该研究引入了一个名为POET的实时交互工具，该工具自动化地探索文本到图像生成模型中的同质性维度，扩展这些维度以增加生成图像的多样性，并通过用户反馈学习个性化这些扩展方式，从而更好地适应用户的创作过程需求。
### Innovation
POET是一款实时交互工具，通过自动化发现文本到图像生成模型中的同质性维度，扩展它们以增加生成图像的空间，根据用户反馈来个性化这些扩展，从而提供更加多样化和个性化的图像生成结果。POET通过自动扩展生成模型的维度，使生成图像更加多样化，提高了用户的创作满意度，并且能够促进用户在共同创作过程中更广泛地考虑生成结果。这为未来文本到图像生成工具的交互技术提供了一个新的视角，可以更好地支持和适应创造性用户的多样化需求。
### Conclusion
研究表明，POET能够在创意任务中生成更具有感知多样性的结果，并帮助用户更快地达到满意的状态，从而促使他们在共同创作过程中更广泛地考虑生成结果。对于旨在支持用户表达视觉创意的工具来说，POET提供了一个示范，表明未来文本到图像生成工具的交互技术可以如何更好地支持多样化价值观和用户需求。
## 427. `cs.CV` - 将中间层优化与投影梯度下降整合以解决带有扩散模型的逆问题 [PDF](https://arxiv.org/pdf/2505.20789), [HTML](https://arxiv.org/abs/2505.20789)
### Authors
Yang Zheng,Wen Li,Zhaoqiang Liu
### Background
逆问题涉及从噪声观测中重构信号。近年来，扩散模型（DM）作为一种强大的框架，在解决逆问题中展现出卓越的重建性能。然而，现有的基于DM的方法往往面临计算需求沉重和收敛不佳的问题。
### Innovation
本文基于最近的DMPlug工作，提议了两种新的方法，即DMILO和DMILO-PGD，以解决这些问题。DMILO采用了中间层优化（ILO）来缓解DMPlug固有的内存负担，并通过引入稀疏偏差扩大了DM的应用范围，使得探索可能不在扩散模型范围内的潜在信号成为可能。DMILO-PGD结合了ILO和投影梯度下降（PGD），降低了因次优收敛而带来的风险。在适当条件下提供直观的理论分析，并通过严格的实验验证了两种方法在多种图像数据集上的优越性，特别是在线性和非线性逆问题中。
### Conclusion
结果表明，DMILO和DMILO-PGD在处理DM基于的逆问题解算器的常见挑战方面具有显著的优势，表现出色。
## 428. `cs.CV` - 深度学习在基于视觉的交通事故预知中的进展: 方法、数据集和未来方向的全面综述 [PDF](https://arxiv.org/pdf/2505.07611), [HTML](https://arxiv.org/abs/2505.07611)
### Authors
Ruonan Lin,Tao Tang,Yongtai Liu,Wenye Zhou,Xin Yang,Hao Zheng,Jianpu Lin,Yi Zhang
### Background
交通事故预测和检测对于提高道路安全至关重要，而基于视觉的交通事故预知（Vision-TAA）在深度学习时代已经发展成为一种有潜力的方法。现有的研究主要集中在监督、无监督和混合深度学习模型在事故预测中的应用，以及使用现实世界和合成数据集。这些方法展示了巨大的潜力，但数据稀缺、复杂场景下的泛化能力有限以及实时性能限制仍然是主要挑战。因此，综合现有的研究成果并识别关键缺口对于开发健壮且适应性强的Vision-TAA系统至关重要，这是为了促进道路安全和交通管理而进行的必要步骤。
### Innovation
本文回顾了147篇最近的研究，总结了基于图像和视频特征、时空特征、场景理解以及多模态数据融合的预测方法，并指出了集成多模态数据融合、自监督学习和基于Transformer的架构在未来研究中的机会，这些方法有助于提高预测准确性和可扩展性。
### Conclusion
通过综合现有的进步和确定关键缺口，本文为开发稳健且适应性强的Vision-TAA系统提供了基础参考，促进了道路安全和交通管理。
## 429. `cs.CV` - Single Image Super-Resolution中模块可移植性的优化：通用性评估与循环残差块 [PDF](https://arxiv.org/pdf/2505.03522), [HTML](https://arxiv.org/abs/2505.03522)
### Authors
Haotong Cheng,Zhiqi Zhang,Hao Li,Xinshang Zhang
### Background
深度学习已经极大地推动了单张图像超分辨率（SISR）领域的进步。然而，现有的研究主要集中在性能的提升上，对架构组件的可移植性量化分析较少涉及。长期以来，通用性主要局限于传统意义上的模型泛化能力，而对模块间可移植性的评价缺乏量化方法。本文针对这一现象提出了一种新的概念——“通用性”，并给出了定义，将其扩展到包含模块间转移的便利性。进一步通过一种新的量化方法——通用性评估方程（UAE），揭示了多种现有指标对可移植性的影响。
### Innovation
本文提出了一种新的概念——“通用性”，并通过通用性评估方程（UAE）量化了模块的可移植性。基于UAE的结果优化了标准的残差块和其他即插即用（Plug-and-Play）模块，设计了两种优化模块：循环残差块（CRB）和深度可分离循环残差块（DCRB）。通过在自然场景基准、遥感数据集和其他低级任务上的全面实验，证明了嵌入本文提出的即插即用模块的网络在性能上优于几种最先进的方法，且参数减少了71.3%的同时重建保真度几乎没有损失。这种优化方法还可能适用于其他基本模块，为即插即用模块的设计提供了新的范式。
### Conclusion
本文通过引入通用性（Universality）的概念和通用性评估方程（UAE），系统地分析了SISR中模块的可移植性问题，并通过设计优化后的循环残差块（CRB）和深度可分离循环残差块（DCRB）验证了提升模型可移植性的方法，实验结果表明新方法在多个任务上的性能更优且参数更少。这种优化方法可以应用于更广泛的模块设计中。
## 430. `cs.CV` - Res-MoCoDiff: Residual-guided diffusion models for motion artifact correction in brain MRI [PDF](https://arxiv.org/pdf/2505.03498), [HTML](https://arxiv.org/abs/2505.03498)
### Authors
Mojtaba Safari,Shansong Wang,Qiang Li,Zach Eidex,Richard L.J. Qiu,Chih-Wei Chang,Hui Mao,Xiaofeng Yang
### Background
脑部MRI成像中的运动伪差，主要由头部刚性运动引起，会降低图像质量并阻碍下游应用。传统的减少这些伪差的方法，比如重复采集或运动跟踪，会增加工作流程的负担。
### Innovation
Res-MoCoDiff是一种专门针对MRI运动伪差去噪的高效扩散概率模型，它在前向扩散过程中利用一种新颖的残差误差偏移机制来整合运动污染图像中的信息。这种机制使模型能够在概率分布与受污染数据高度匹配的情况下模拟噪声的演变，从而实现仅需四步的逆向扩散过程。此外，该模型采用U-net架构，并用Swin Transformer块取代注意力层，以增强跨分辨率的鲁棒性。模型的训练过程中还结合了l1+l2损失函数，以促进图像锐化并减少像素级错误。该方法在仿真数据集和体MRI-ART数据集上进行了评估，展示了在轻微、中等及严重伪差处理中的优越性能，尤其是在SSIM和NMSE值上表现突出。
### Conclusion
Res-MoCoDiff在提升图像质量及减少伪差方面表现出色，同时具备更快的采样速度，显著减少了传统方法所需的时间。
## 431. `cs.CV` - 从嵌入到准确性：比较用于放射分类的基础模型 [PDF](https://arxiv.org/pdf/2505.10823), [HTML](https://arxiv.org/abs/2505.10823)
### Authors
Xue Li,Jameson Merkow,Noel C. F. Codella,Alberto Santamaria-Pang,Naiteek Sangani,Alexander Ersoy,Christopher Burt,John W. Garrett,Richard J. Bruce,Joshua D. Warner,Tyler Bradshaw,Ivan Tarapov,Matthew P. Lungren,Alan B. McMillan
### Background
基模型为多样化的任务提供了稳健的嵌入，包括医学影像。研究者评估了来自七个通用和医学专门的基础模型（例如，DenseNet121、BiomedCLIP、MedImageInsight、Rad-DINO、CXR-Foundation）的嵌入，用于多类别放射学分类训练轻量级适配器。使用包含7个类别的8,842张放射图像的数据集，研究者使用K-最近邻、逻辑回归、SVM、随机森林和MLP等算法训练适配器。研究发现，将MedImageInsight嵌入与SVM或MLP适配器结合的性能最优，达到了93.1%的平均曲线下面积（mAUC），并且这项表现优于其他模型。
### Innovation
研究创新地利用了专业领域内和通用领域的基础模型嵌入训练轻量级适配器，特别是MedImageInsight嵌入框架下的SVM和MLP适配器组合，达到了卓越的准确性能。此外，研究强调了这些轻量级适配器的计算效率，能够在短时间内训练并在CPU上以秒级速度进行推理。这项研究提出了针对临床使用的准确、高效、公平的诊断工具的可行方案，这在专业领域模型中尤为重要。
### Conclusion
经过公平性分析，MedImageInsight的最佳性能适配器在不同性别和年龄组的性能差异很小，无显著统计差异。这证实了专业领域模型的嵌入，特别是MedImageInsight，可用于驱动简单且轻量级的适配器，以建立准确、高效且公平的诊断工具。
## 432. `cs.CV` - 基于相机参数的可控实时图像去噪 [PDF](https://arxiv.org/pdf/2507.01587), [HTML](https://arxiv.org/abs/2507.01587)
### Authors
Youngjin Oh,Junhyeong Kwon,Keuntek Lee,Nam Ik Cho
### Background
近年来，基于深度学习的图像去噪方法取得了显著的效果，但由于许多方法缺乏根据噪声水平、相机设置和用户偏好调整去噪强度的灵活性，因此仍存在改进空间。本文的背景在于通过引入新型可控去噪框架来解决这一问题，该框架通过利用相机参数信息，实现噪声的自适应去除，特别是在ISO、快门速度和F数值等直接影响噪声水平的参数方面进行了重点研究.
### Innovation
本文的创新之处在于开发了一种新的可控去噪框架，该框架将相机参数（如ISO、快门速度和F数值）转换为控制向量，用于调整和增强去噪网络的性能。这使得传统的去噪神经网络能够无缝添加可控性，并提升其性能。
### Conclusion
实验结果表明，本文的方法有效地增加了标准去噪神经网络的可控性，并改善了其性能。源代码可在相应链接处获取。
## 433. `cs.CV` - 针对儿科腕部骨折的年龄和性别 awareness 细粒度分类 [PDF](https://arxiv.org/pdf/2507.12964), [HTML](https://arxiv.org/abs/2507.12964)
### Authors
Ammar Ahmed,Ali Shariq Imran,Zenun Kastrati,Sher Muhammad Daudpota
### Background
腕部损伤在儿童中较为常见，尤其是构成骨折病例大部分的儿童群体。计算机视觉技术具有巨大潜力，但需要大量的数据集支持，这是目前医疗成像领域的一个显著挑战。因此，在存在多种数据类型的今天，依赖单一模态如影像学检查已显不足。该研究利用多模态方法，将细粒度识别任务与患者的元数据和X光图像融合，并利用来自细粒度数据集的权重而非粗粒度数据集（如ImageNet）进行训练，以提升诊断准确性。
### Innovation
这是首次将元数据整合应用于腕部病理识别，通过引入细粒度转器方法、细粒度预训练及元数据整合，研究在小型自定义数据集中提高了2%的诊断准确率，并在大型骨折数据集中提高了超过10%。
### Conclusion
该研究通过多模态方法，准确地识别了儿童腕部骨折，展示了细粒度转器方法、细粒度预训练及元数据整合在提高骨折诊断准确率上的有效性。
## 434. `cs.CV` - 条件生成视频压缩 [PDF](https://arxiv.org/pdf/2507.15269), [HTML](https://arxiv.org/abs/2507.15269)
### Authors
Fangqiu Yi,Jingyu Xu,Jiawei Shao,Chi Zhang,Xuelong Li
### Background
知觉研究显示无条件扩散模型在重建与人类视觉感知相匹配的视频内容方面表现出色。在此基础上，本文提出了一种利用条件扩散模型进行感知优化重构的视频压缩框架。
### Innovation
本文将视频压缩重新定义为一个条件生成任务，其中生成模型根据稀疏但具有信息性的信号生成视频。具体来说，该方法引入了三个关键模块：(1) 多粒度条件模型捕捉静态场景结构和动态空时线索；(2) 能够高效传输的同时保留语义丰富性的紧凑表示；(3) 多条件训练，包含模态dropout和角色感知嵌入，从而防止对任何一个模态的过度依赖并增强模型的鲁棒性。
### Conclusion
大量实验表明，本文方法在感知质量度量标准（如Fréchet 视频距离FVD和LPIPS）上明显优于传统和神经编解码器，特别是在高压缩比条件下。
## 435. `cs.CV` - Hallo4：通过直接偏好的优化和时间运动调制实现高质量动态肖像动画 [PDF](https://arxiv.org/pdf/2505.23525), [HTML](https://arxiv.org/abs/2505.23525)
### Authors
Jiahao Cui,Yan Chen,Mingwang Xu,Hanlin Shang,Yuxuan Chen,Yun Zhan,Zilong Dong,Yao Yao,Jingdong Wang,Siyu Zhu
### Background
生成高动态且具照片真实感的肖像动画依然具有挑战性，原因在于精准唇部同步、自然面部表情和高保真身体动作动态的需要。此类动画需解决精确的唇音同步、自然的表情以及高保真身体动态的挑战。现有研究尚未成功解决这些复杂需求的整合问题。作者提出了一个人类偏好对齐的扩散框架，采取两种创新性解决策略：一是直接偏好的优化，针对人本动画，利用一个由人类偏好的数据集，使其生成的输出与感知度量共识对齐，用于肖像运动视频对齐和表情的自然性；二是采用时间运动调制来解决时空分辨率差异，通过时间信道重分布及比例特征扩展的方式，使运动条件适配成维度对齐的潜在特征，从而在基于扩散的合成过程中保留高频运动细节的保真度。这种方法补充了现有基于UNet和DiT的肖像扩散模型方法，实验表明，本方法在唇音同步、表情生动度、身体运动一致性上优于基线方法，并且在人类偏好指标上也有显著提升
### Innovation
该研究提出了两个创新点：1. 一种针对人本动画的直接偏好优化技术，利用精心挑选的人类偏好数据集，使生成的动画与感知度量相匹配，确保唇音同步和表情的自然度；2. 一种时间运动调制技术，通过时间和空间分辨率的调整，实现在基于扩散的合成中高频运动细节的保真度
### Conclusion
通过提出的基于扩散的人类偏好对齐框架，实现了高质量的肖像动画。该方法不仅在唇音同步、表情生动度、身体运动一致性上获得了显著改进，还在人类偏好度上取得了明显提升。实验结果表明，与现有方法相比，该方法在多个方面都有更优的表现，验证了模型的有效性和优越性。
## 436. `cs.CV` - 基于ArUco角度估计算法的视觉导向自主毫米波反射器 [PDF](https://arxiv.org/pdf/2506.05195), [HTML](https://arxiv.org/abs/2506.05195)
### Authors
Josue Marroquin,Nan Inzali,Miles Dillon Lantz,Campbell Freeman,Amod Ashtekar,??Ajinkya Umesh Mulik,Mohammed E Eltayeb
### Background
毫米波（mmWave）通信在非视距（NLoS）条件下的可靠性能仍然是军事及民用操作的重大挑战，尤其是在城市或基础设施有限的环境中。现有的mmWave系统面临着信号在复杂和动态环境中的可靠传输问题。
### Innovation
本文提出了一个基于视觉的自适应折射镜系统，该系统利用单一摄像头检测盟军发射机和接收器节点上的ArUco标志，估计到达角度并实时调整轨道以实现信号的最佳折射。该方法通过仅服务于具有可见标志的认证目标来选择性地覆盖信号波束，减少无意中泄露信号的风险。系统无需依赖外部基础设施或GPS，且在Raspberry Pi 4和低功耗硬件上运行，展示了其在复杂和动态环境中的潜在鲁棒性和适应性。实验结果表明，在60 GHz频段下，系统在室内环境中的接收信号强度平均增益达到23 dB，并且有0.89的概率保持信号接收超过-65 dB的目标阈值，远超静态和无反射器的基线结果。
### Conclusion
该系统为在复杂和动态环境下实现可靠的毫米波通信提供了新的解决方案，具有潜在的应用前景。
## 437. `cs.CV` - 前哥伦布时期定居点在新热带山地森林棕榈树林集群中的生态遗产 [PDF](https://arxiv.org/pdf/2507.06949), [HTML](https://arxiv.org/abs/2507.06949)
### Authors
Sebastian Fajardo,Sina Mohammadi,Jonas Gregorio de Souza,César Ardila,Alan Tapscott Baltar,Shaddai Heidgen,Maria Isabel Mayorga Hernández,Sylvia Mota de Oliveira,Fernando Montejo,Marco Moderato,Vinicius Peripato,Katy Puche,Carlos Reina,Juan Carlos Vargas,Frank W. Takes,Marco Madella
### Background
前哥伦布时期的古代人群显著改变了热带森林，但其生态影响的空间范围在高分辨率下仍欠研究。本文采用深度学习和遥感技术，通过现代植被估计前哥伦布时期森林改造的区域。研究聚焦于哥伦比亚的 Sierra Nevada de Santa Marta，评估棕榈树在考古基础设施周围的分布情况。结果显示，接近大型基础设施投资的考古遗址，棕榈树明显更丰富。最大的棕榈林集群表明，古代人类管理的区域可能比现有考古证据说明的要大两个数量级。研究发现，前哥伦布时期的人群对植被产生了影响，促进了棕榈树的蔓延，留下了持久的生态足迹，并可能降低了在偏远地区建立基础设施密集型定居点的后勤成本。
### Innovation
采用了深度学习和遥感方法来估计前哥伦布时期森林改造的区域。以哥伦比亚的 Sierra Nevada de Santa Marta 为研究区域，评估了棕榈树与考古基础设施之间的关系，发现了古代管理的区域比现有证据要大得多。研究表明，前哥伦布时期的人群显著影响了植被，促进了棕榈树的生长，留下生态足迹，降低了在偏远地区建立基础设施的困难。
### Conclusion
前哥伦布时期的人口活动显著影响了植被，促进了棕榈树的过度生长，留下持久的生态足迹，可能降低了在偏远区域建立基础设施密集型定居点的后勤成本。这些古代活动的范围远超出现有考古证据的显示。
## 438. `cs.CV` - TriCLIP-3D: 基于CLIP的统一高效三模态3D视觉接地框架 [PDF](https://arxiv.org/pdf/2507.14904), [HTML](https://arxiv.org/abs/2507.14904)
### Authors
Fan Li,Zanyi Wang,Zeyi Huang,Guang Dai,Jingdong Wang,Mengmeng Wang
### Background
3D视觉接地技术使具身智能代理能够根据人类指令理解真实世界3D环境中的视觉信息，这对于具身智能至关重要。现有3D视觉接地方法通常依赖于不同的编码器来处理不同模态的数据（例如RGB图像、文本和3D点云），这导致了大规模且复杂的模型，训练效率低下。虽然有些方法使用预训练的2D多模态模型（如CLIP）进行3D任务，但它们仍然难以将点云数据对齐到2D编码器中。因此，这些方法继续依赖于3D编码器进行特征提取，进一步增加了模型复杂度和训练效率的低下。
### Innovation
本研究提出了一个统一的2D预训练多模态网络，能够同时处理所有三种模态（RGB图像、文本和点云）的数据，显著简化了架构。通过利用2D CLIP的生物模态模型结合基于适配器的微调，这个框架有效适应了三模态设置，提高了不同模态间的适应性和性能。我们的Geometric-Aware 2D-3D Feature Recovery and Fusion (GARF) 模块设计用于融合点云和图像的几何多尺度特征。随后整合文本特征进行最终模态融合，并引入多模态解码器以促进深度跨模态理解。共同作用下，本方法实现了三种模态下的统一特征提取和融合，构建了完整的3D视觉接地模型。相比于基线模型，该方法减少了约58%的可训练参数，并在3D检测任务上提高了6.52%的性能，在3D视觉接地任务上提高了6.25%的性能。
### Conclusion
我们的方法成功地实现了统一的2D-3D特征提取和融合，构建了端到端的3D视觉接地模型。通过采用统一的2D预训练多模态网络和创新的GARF模块，该模型不仅简化了架构，提高了训练效率，还提升了跨模态的理解能力。
## 439. `cs.CV` - 现代计算机视觉中的基础与模型：关键架构的基石 [PDF](https://arxiv.org/pdf/2507.23357), [HTML](https://arxiv.org/abs/2507.23357)
### Authors
Radu-Andrei Bourceanu,Neil De La Fuente,Jan Grimm,Andrei Jardan,Andriy Manucharyan,Cornelius Weiss,Daniel Cremers,Roman Pflugfelder
### Background
该报告通过分析六篇有影响力的论文，探讨了计算机视觉中关键设计模式的演变。分析从图像识别的基础架构开始，重点介绍了ResNet通过引入残差连接解决梯度消失问题，并使深层卷积网络能够有效训练。随后，报告研究了Vision Transformer (ViT)，这种方法通过将Transformer架构应用于图像块序列，证明了基于注意力模型在大规模图像识别中的有效性。
### Innovation
报告详细分析了Vision Transformer (ViT)、Generative Adversarial Networks (GANs)、Latent Diffusion Models (LDMs)、自监督学习方法DINO和Masked Autoencoders (MAE)。这些技术分别代表了不同的创新点，如基于注意力模型的大型图像识别、新颖的对抗训练过程、渐进去除噪声的过程、减少数据标签依赖的自监督学习框架，以及不对称编码解码设计用于重建高度掩码输入的方法。这些技术共同推动了计算机视觉领域的发展。
### Conclusion
报告总结了这些先进技术，指出自监督学习技术DINO和Masked Autoencoders（MAE）作为当前图像生成的最新前沿，展示了从图像识别到生成模型的深入研究方向，强调了计算机视觉领域在使用深层学习技术发展的最新里程碑。
## 440. `cs.CV` - DianJin-OCR-R1：通过推理和工具交替的视觉语言模型增强OCR能力 [PDF](https://arxiv.org/pdf/2508.13238), [HTML](https://arxiv.org/abs/2508.13238)
### Authors
Qian Chen,Xianyin Zhang,Lifan Guo,Feng Chen,Chi Zhang
### Background
近期大视觉-语言模型（LVLMs）的发展使端到端的文档图像解析成为可能，尤其是在光学字符识别（OCR）任务如文本、表格和公式识别上表现出色。然而，生成的LVLMs与大型语言模型（LLMs）一样，容易出现幻觉，即生成输入图像中不存在的词汇。此外，LVLMs通常是为通用目的设计的，相较于针对特定领域数据集训练的专家模型，在OCR任务上表现较差。ese问题限制了LVLMs在OCR任务中的应用。
### Innovation
本文提出了DianJin-OCR-R1，这是一种增强推理和工具交替的框架。该模型首先使用自己的OCR能力对输入图像进行识别，并调用其他专家模型作为参考，然后“重新查看”图像并重新审视推理过程以提供最终的识别内容。通过这种方式，专家模型的专用架构使其对幻觉不太敏感，从而帮助LVLMs缓解这些问题。该模型在ReST和OmniDocBench上的实验结果表明，它优于非推理模型和专家OCR模型，验证了该方法的有效性，同时显示出增强专家模型的能力，有助于提升LVLMs的表现。
### Conclusion
实验结果表明，通过适配专家模型，DianJin-OCR-R1在实现OCR任务上取得了显著的改进，证明了该模型的有效性。这些结果还表明，增强通常较小且易于迭代的专家模型能够促进LVLMs的性能提升。
## 441. `cs.CV` - LOT斯时尚！通过草图-文本配对进行多条件图像生成 [PDF](https://arxiv.org/pdf/2507.22627), [HTML](https://arxiv.org/abs/2507.22627)
### Authors
Federico Girella,Davide Talon,Ziyue Liu,Zanxi Ruan,Yiming Wang,Marco Cristani
### Background
时尚设计是一个复杂的创造性过程，结合了视觉和文本表达。设计师们通过草图和文本描述来传达创意，其中草图定义空间结构和设计元素，而文本描述则捕捉材料、纹理和风格细节。目前的相关研究集中在利用草图和文本生成完整的时尚外观，并且没有统一的方法能够同时处理全局和局部特征。因此，论文提出了LOcalized Text and Sketch for fashion image generation (LOTS) 方法，在这个方法中，通过全球描述与配对的局部草图+文本信息进行条件设定，并引入了一种新颖的逐步融合策略以适应扩散调整。这个方法结合了多个草图和文本配对，建立了第一个这样做发布的时尚数据集Sketchy，主要展示多个文本-草图配对的图像数据。这种方法在全局和局部指标上均表现出卓越的图像生成性能，并且从定性和定量的验证结果来看，表明方法具有前所未有的设计定制化水平。论文在Fashionpedia的基础上建立了Sketchy数据集，包含多对一的文本-草图配对信息。
### Innovation
LOTs方法通过全局描述和局部草图+文本信息的配对，为时尚图生成提供了一个新的视角。引入了一种模块化的配对中心表示来编码图像和文本进入共享的潜在空间，保留独立的局部特征；提出了基于注意力机制的双向序贯生成方法来整合局部和全局条件，利用宽向传播融合策略促进扩散调整。
### Conclusion
实验结果表明，LOTs方法在生成的全球和局部指标上都达到了最先进的水平。定性和定量的研究分析指出了该方法前所未有的设计定制化水平。
## 442. `cs.CV` - HLG: Comprehensive 3D Room Construction via Hierarchical Layout Generation [PDF](https://arxiv.org/pdf/2508.17832), [HTML](https://arxiv.org/abs/2508.17832)
### Authors
Xiping Wang,Yuxi Wang,Mengqi Zhou,Junsong Fan,Zhaoxiang Zhang
### Background
3D室内场景的现实生成对于虚拟现实、室内设计、具身智能和场景理解至关重要。现有的方法在粗略的家具布局方面取得了进展，但在细粒度的对象放置方面存在困难，这限制了生成环境的现实感和实用性。这阻碍了沉浸式的虚拟体验和具身AI应用中对详细场景的理解。
### Innovation
提出了一种名为Hierarchical Layout Generation (HLG)的新方法，这是第一个采用从粗到细的层次化方法，从大型家具布局到精细的物体布置逐级细化场景布局。特别地，该方法通过垂直和水平解耦构建分层布局，并通过可训练的布局优化网络解决了诸如错误的定位、方向错误和物体交集等问题，确保生成的场景具有结构上的连贯性和物理上的可行性。
### Conclusion
通过广泛的实验展示了该方法在生成逼真室内场景方面的优越性能，推动了场景生成领域的进展，并为需要详细3D环境的应用开辟了新的可能性。我们将在发表后公开代码，以促进未来的研究。
## 443. `cs.CV` - DIO: 依托因果链和互信息改进增强机器抽象推理能力 [PDF](https://arxiv.org/pdf/2508.15387), [HTML](https://arxiv.org/abs/2508.15387)
### Authors
Ruizhuo Song,Beiming Yuan
### Background
尽管当前深度学习模型在各种领域表现出色，但在抽象推理方面仍存在根本性的瓶颈。为了解决这一挑战，学术界引入了Raven's Progressive Matrices (RPM)问题作为评估深度学习算法抽象推理能力的权威基准，重点考察抽象推理、模式识别和复杂问题解决等核心智能维度。因此，本文专注于解决RPM问题，旨在提升机器智能的抽象推理能力。
### Innovation
本文从因果链建模的角度系统分析了RPM任务中的完整因果链，并基于此设计了基线模型DIO的网络架构。然而，实验发现DIO模型优化目标（最大化上下文和正确选项间互信息的变分下界）未能使模型真正获取预定义的人类推理逻辑，这是由于紧的下界显著影响了互信息最大化的有效性，且互信息作为一种统计测度不能捕捉主体和对象之间的因果关系。为解决这些问题，本文逐步提出了三种改进方法。
### Conclusion
该研究以因果链和互信息为主要改进方向，设计了DIO模型以提升机器在RPM任务上的抽象推理能力。
## 444. `cs.CV` - Encoder-Only Image Registration [PDF](https://arxiv.org/pdf/2509.00451), [HTML](https://arxiv.org/abs/2509.00451)
### Authors
Xiang Chen,Renjiu Hu,Jinwei Zhang,Yuxi Zhang,Xinyao Yue,Min Liu,Yaonan Wang,Hang Zhang
### Background
学习方法显著提高了变形图像配准的准确性和速度，但降低计算复杂性和处理大变形的挑战仍然存在。现有研究和实验证明卷积神经网络（ConvNets）在配准中的作用，其中包括局部强度线性化和全局对比度变化的调和。
### Innovation
提出Encoder-Only Image Registration (EOIR)框架，将特征学习与流估计算法分离，使用3层ConvNet进行特征提取，并通过一组3层的流估算器构造Laplacian特征金字塔。在大变形模型下逐步组合同胚变形。
### Conclusion
在五个不同模态和解剖区域的数据集上，结果表明EOIR在准确性和效率之间实现了更好的折衷，具有相当的准确度时，EOIR提供了更好的效率和光滑度，并且反之亦然。源代码已公开可在指定链接获取。
## 445. `cs.CV` - TexVerse: 一个具有高分辨率纹理的3D对象宇宙 [PDF](https://arxiv.org/pdf/2508.10868), [HTML](https://arxiv.org/abs/2508.10868)
### Authors
Yibo Zhang,Li Zhang,Rui Ma,Nan Cao
### Background
虽然最近在大型3D数据集方面的进展已经提高了高分辨率几何生成的能力，但端到端生成高分辨率纹理仍然相对未被探索，主要是因为缺乏合适的数据集。TexVerse 通过一个从Sketchfab中精心挑选的超过858,000个独特高分辨率3D模型的集合，填补了这一空白，这些模型包括超过158,000个具有物理基础渲染（PBR）材料的模型。每个模型包括所有高分辨率变形信息，总共提供1.6M个3D实例。此外，TexVerse 还包括专门的子集：TexVerse-Skeleton（69,000个绑定模型）和TexVerse-Animation（54,000个动画模型），这些子集都保留了用户上传的原始骨架和动画数据。TexVerse 还提供了详细模型注释，描述了总体特征、结构成分和复杂特征。
### Innovation
创新点包括：1）建立了一个包含超过858,000个独特高分辨率3D模型的数据集，这些模型包括超过158,000个具有物理基础渲染（PBR）材料的模型。2）提供了详细的模型注释，描述了总体特征、结构成分和复杂特征。3）包括专门子集：TexVerse-Skeleton（具有绑定模型）和TexVerse-Animation（具有动画模型），这些子集都保留了用户上传的原始骨架和动画数据。
### Conclusion
TexVerse 提供了一个高质量的数据资源，具有广泛的应用潜力，包括纹理合成、PBR材料开发、动画以及各种3D视觉和图形任务。
## 446. `cs.CV` - Drawing2CAD: 从矢量图纸生成CAD的序列到序列学习 [PDF](https://arxiv.org/pdf/2508.18733), [HTML](https://arxiv.org/abs/2508.18733)
### Authors
Feiwei Qin,Shichao Lu,Junhao Hou,Changmiao Wang,Meie Fang,Ligang Liu
### Background
计算机辅助设计（CAD）生成建模在工业应用中取得了显著的进展。现有方法能够从点云、网格和文本描述等多种输入生成实体模型，但这些方法与传统的始于二维工程图纸的工业工作流程大相径庭。尽管从二维矢量图纸自动生成参数化CAD模型是工程设计中的关键步骤，但这一领域仍然未得到充分探索。
### Innovation
本文通过将CAD生成重新定义为序列到序列的学习问题，直接利用矢量制图的基本元素来生成参数化CAD操作，以保留几何精度和设计意图，同时还提出了Drawing2CAD框架，该框架包括一个网络友好的矢量基本表示、一个双解码器转换器架构，以及一个软目标分布损失函数，以适应CAD参数的固有灵活性。
### Conclusion
为了训练和评估Drawing2CAD，作者创建了CAD-VGDrawing数据集，包含配对的工程图纸和参数化CAD模型，并进行了详尽的实验来证明其方法的有效性。代码和数据集可在指定网址获取。
## 447. `cs.CV` - BuzzSet v1.0: 在实地条件下用于传粉昆虫检测的数据集 [PDF](https://arxiv.org/pdf/2508.19762), [HTML](https://arxiv.org/abs/2508.19762)
### Authors
Ahmed Emam,Mohamed Elbassiouny,Julius Miller,Patrick Donworth,Sabine Seidel,Ribana Roscher
### Background
传粉昆虫如蜜蜂对于全球粮食生产和生态稳定至关重要，但它们因人为和环境压力而数量下降。在农业环境中进行可扩展的自动化监测仍然具有挑战性，因为这些昆虫体积小、移动快且有时难以察觉。
### Innovation
提出了BuzzSet v1.0，这是一个在真实田间条件下收集的高分辨率传粉昆虫图像的大规模数据集。该数据集包含7,856张经过人工验证的图像以及超过8,000个注释实例，分为三类：蜜蜂、熊蜂和未识别昆虫。通过使用预训练的YOLOv12模型并结合人工验证，提高小昆虫的检测性能，并提供了基于RF-DETR的变换器基础对象检测模型基准，实现了蜂蜜蜜蜂和熊蜂检测的高F1分数。
### Conclusion
总体检测性能（0.50 mAP为0.559）体现了该数据集的挑战性和其在在现实生态条件下小对象检测方面的潜在促进作用。未来工作将集中在扩展数据集至2.0版本并进一步评估检测策略。BuzzSet为生态计算机视觉设立了基准，主要挑战是可靠地检测那些经常被自然植被掩盖的昆虫。
## 448. `cs.CV` - 基于单个人类视频的开放世界对象图的视觉操纵 [PDF](https://arxiv.org/pdf/2405.20321), [HTML](https://arxiv.org/abs/2405.20321)
### Authors
Yifeng Zhu,Arisrei Lim,Peter Stone,Yuke Zhu
### Background
研究机器人从人类视频中学习基于视觉的操纵技能的方法，特别是在开放世界环境中通过模仿学习操作新型物体的问题。背景研究集中在利用日常生活中的移动设备捕获的视频数据，使机器人能够适应变化的视觉背景、相机角度、空间布局和新型物体实例，并能从单一视频演示中学习并推及到长时序任务中。
### Innovation
引入ORION算法，通过从单一RGB或RGB-D视频中提取对象为中心的操纵计划，以及生成依赖于提取计划的策略，实现从人类视频中学习视觉操控技能，并有效应用于任务多样性和视频数据类型的变化。展示了ORION在开放世界条件下的单人视频学习能力，成功率为74.4%.
### Conclusion
通过系统地评估ORION在短期和长期任务中的表现，证明ORION能够从单一人类视频中有效地学习视觉操纵技能并在开放世界环境中推广这些技能。
## 449. `cs.CV` - 理解空间——只有顶尖推理模型才能解决空间理解任务 [PDF](https://arxiv.org/pdf/2509.02175), [HTML](https://arxiv.org/abs/2509.02175)
### Authors
Nils Hoehing,Mayug Maniparambil,Ellen Rushe,Noel E. O'Connor,Anthony Ventresque
### Background
当前的视觉-语言模型（VLMs）在理解和处理空间关系方面存在显著不足，尤其是在与位置和物体顺序相关的任务上。研究人员希望通过新的基准测试来揭示这些模型的局限性，并促进领域内对此问题的深入研究。
### Innovation
提出了RocketScience，这是一个开源的对比式VLM基准测试，专门用于测试空间关系理解能力。它涵盖了全新的现实世界的图像-文本对，主要测试相对空间理解及物体顺序。基准测试对人类来说非常易懂，但对当前的VLMs来说非常困难。基准测试的设计和结果得到了实验证明。此外，针对链式思考模型的去耦析分析揭示出，这些模型的表现瓶颈在于空间推理能力而不是物体定位能力。
### Conclusion
开源和前沿商业VLMs在空间关系理解方面表现出明显的不足，而推理模型却展现出令人惊讶的高性能。RocketScience基准测试被公开发布，希望推动该领域的进一步研究和发展。
## 450. `cs.CV` - PIN：配套交织多模态文档的知识密集型数据集 [PDF](https://arxiv.org/pdf/2406.13923), [HTML](https://arxiv.org/abs/2406.13923)
### Authors
Junjie Wang,Yuxiang Zhang,Minghao Liu,Yin Zhang,Yatai Ji,Weihao Xuan,Nie Lin,Kang Zhu,Zhiqiang Lin,Yiming Ren,Chunyang Jiang,Yiyao Yu,Zekun Wang,Tiezhen Wang,Wenhao Huang,Jie Fu,Qunshu Liu,Yujiu Yang,Ge Zhang,Ruibin Yuan,Bei Chen,Wenhu Chen
### Background
近年来，大型多模态模型（LMMs）借助大规模多模态数据集，提升了在复杂知识驱动任务中的能力。然而，感知和推理错误持续存在，特别是在解读复杂的视觉数据和推导多模态关系方面限制了它们的效果。
### Innovation
本文引入了PIN（Paired and INterleaved multimodal documents）这一新型数据格式，旨在促进视觉和文本知识的更深融合。该格式将保存了精细文本结构的语义丰富的Markdown文件与捕捉文档整体布局的全方位图像相结合。基于这一格式，我们构建并发布两个大规模开源数据集：PIN-200M（约2亿份文档）和PIN-14M（约1400万份文档），来源涉及多个网络和学术领域，语言涵盖英语和中文。
### Conclusion
我们的工作为社区提供了一个多功能的数据格式和丰富资源，为预训练策略的研究以及开发更强大的知识密集型LMM奠定了基础。数据集包括详细的数据统计信息和质量信号，便于研究人员筛选和选择特定任务所需的数据。
## 451. `cs.CV` - AutoPET III: 边境的彼岸，未知的前景？ [PDF](https://arxiv.org/pdf/2410.02807), [HTML](https://arxiv.org/abs/2410.02807)
### Authors
Zacharia Mesbah,Léo Mottay,Romain Modzelewski,Pierre Decazes,Sébastien Hapdey,Su Ruan,Sébastien Thureau
### Background
过去三年，AutoPET竞赛聚集了医学成像领域的专家，致力于通过正电子发射断层扫描（PET）图像进行病变分割。每年竞赛都聚焦不同的挑战方面，2024年的挑战主要集中在多样的现有和使用的示踪剂上，要求开发一个能够在不知道具体示踪剂类型（FDG或PSMA基）的情况下，自动完成PET/CT病变分割的算法。
### Innovation
本文介绍了使用nnUNetv2框架训练了两组六折模型集合，实现了无示踪剂信息的自动PET/CT病变分割，并使用MIP-CNN选择合适的模型集合实现分割。这一创新方法能够在未知示踪剂的情况下，实现病变的准确自动分割。
### Conclusion
通过训练多套模型并结合MIP-CNN选择算法，本文成功开发了一种能够在无示踪剂信息的情况下自动完成复杂的PET/CT病变分割的技术，为医学影像自动化分析开辟了新的途径。
## 452. `cs.CV` - Kwai Keye-VL 1.5 技术报告 [PDF](https://arxiv.org/pdf/2509.01563), [HTML](https://arxiv.org/abs/2509.01563)
### Authors
Biao Yang,Bin Wen,Boyang Ding,Changyi Liu,Chenglong Chu,Chengru Song,Chongling Rao,Chuan Yi,Da Li,Dunju Zang,Fan Yang,Guorui Zhou,Guowang Zhang,Han Shen,Hao Peng,Haojie Ding,Hao Wang,Haonan Fang,Hengrui Ju,Jiaming Huang,Jiangxia Cao,Jiankang Chen,Jingyun Hua,Kaibing Chen,Kaiyu Jiang,Kaiyu Tang,Kun Gai,Muhao Wei,Qiang Wang,Ruitao Wang,Sen Na,Shengnan Zhang,Siyang Mao,Sui Huang,Tianke Zhang,Tingting Gao,Wei Chen,Wei Yuan,Xiangyu Wu,Xiao Hu,Xingyu Lu,Yi-Fan Zhang,Yiping Yang,Yulong Chen,Zeyi Lu,Zhenhua Wu,Zhixin Ling,Zhuoran Yang,Ziming Li,Di Xu,Haixuan Gao,Hang Li,Jing Wang,Lejian Ren,Qigen Hu,Qianqian Wang,Shiyao Wang,Xinchen Luo,Yan Li,Yuhang Hu,Zixing Zhang
### Background
近年来，大型语言模型（LLMs）的发展取得了显著进步，通过多模态大型语言模型（MLLMs）扩展了其能力范围，但视频理解仍然是一个具有挑战性的问题。现有模型在处理视频内容时，难以在空间分辨率和时间覆盖之间进行权衡。由于视频的动态性和信息密集性，现有模型在这方面遇到困难。
### Innovation
我们提出了Keye-VL-1.5，通过三种关键创新解决了视频理解中的根本挑战。首先，引入了一种新颖的慢速-快速视频编码策略，该策略根据帧间相似性动态分配计算资源，对具有显著视觉变化的关键帧进行高分辨率处理（慢路径），而对相对静态的帧进行增加时间覆盖度的低分辨率处理（快路径）。其次，实施了一种渐进式的四阶段预训练方法，系统地将模型的上下文长度从8K扩展到128K令牌，从而能够处理更长的视频和更复杂的视觉内容。第三，开发了专注于推理增强和人类偏好对齐的全面后训练管道，包括5步思维链数据构建过程、迭代的基于GSPO的强化学习以及不同程度提示的渐进式提示强化学习，以及对齐训练。
### Conclusion
通过在公开基准测试和严格的内部人工评估中的广泛评估，Keye-VL-1.5在视频理解任务上表现出显著改进，同时在一般多模态基准测试中保持竞争力。
## 453. `cs.CV` - Dataset Distillation as Pushforward Optimal Quantization [PDF](https://arxiv.org/pdf/2501.07681), [HTML](https://arxiv.org/abs/2501.07681)
### Authors
Hong Ye Tan,Emma Slade
### Background
数据集蒸馏旨在找到一个合成训练集，使得在合成数据上的训练能达到与使用真实数据训练相似的效果，并且在计算需求上大幅减少。现有方法可以大致分为两类：一类是双层优化问题，其中较低层级问题是神经网络的训练准则；另一类是脱氧方法，通过分布匹配的方法绕过了双层优化问题。后者在训练集和蒸馏数据集规模方面具有更高的速度和可扩展性。本研究证明，在编码器-解码器结构的基础上，成功的脱氧方法可以重新定义为一个最优量化问题，即通过最小化期望投影距离找到一组有限点来近似底层概率测度。研究者将现有的脱氧数据集蒸馏方法与经典最优量化和Wasserstein众数问题联系起来，展示了蒸馏数据集在基于扩散的生成先验模型中的一致性。
### Innovation
研究者提出了基于潜在空间聚类的最优量化数据集蒸馏方法，即Data Distillation by Optimal Quantization (DDQ)。相比前SOTA方法 D^4M，DDQ 在 ImageNet-1K 数据集上实现了更优的性能和模型间的通用性，并且在更高的每类图像设置中达到了SOTA水平的性能。使用蒸馏数据集中的噪声初始化在一个更强的扩散变换器模型中，DDQ 在 ImageNet-1K 及其子集上达到了SOTA的蒸馏效果，超越了基于扩散的引导方法。
### Conclusion
本研究通过将脱氧方法转化为最优量化问题，不仅提升了数据集蒸馏的性能，还增强了模型间的通用性。此外，引入的 DDQ 方法在多个评估指标上均取得了显著优于现有方法的性能，特别是在 ImageNet-1K 数据集上，其性能和效率都表现出了优越性。
## 454. `cs.CV` - 分离协作：用于协调钢琴手部运动合成的双重流扩散模型 [PDF](https://arxiv.org/pdf/2504.09885), [HTML](https://arxiv.org/abs/2504.09885)
### Authors
Zihao Liu,Mingwen Ou,Zunnan Xu,Jiaqi Huang,Haonan Han,Ronghui Li,Xiu Li
### Background
自动合成协调的双手动钢琴表演极具挑战性，尤其是在捕捉双手之间复杂的编排同时保持其独特的运动特征。这项研究旨在通过从音频中生成协调的手部姿态，解决建模双手独立性和协调性之间的关键挑战。现有的方法无法有效捕捉手部之间的协调性，同时保持每个手的独特性。现有的解决方案在多个评估指标上未能超越最新技术前沿。
### Innovation
本文提出了一种双重流神经框架，该框架可以在音频输入下生成同步手部姿态。该框架的两大创新点包括：（i）解耦的扩散生成框架，通过双重噪声初始化独立建模每个手的运动，并为每个手分配独特的潜在噪声，同时利用共享的空间条件；（ii）手协调不对称注意机制（HCAA），该机制抑制对称噪声以突出显示手部特有的不对称特征，并在去噪过程中自适应增强手之间的协调性.
### Conclusion
综合评估表明，本文提出的框架在多个指标上优于现有最先进的方法。研究结果通过该网址提供：this https URL.
## 455. `cs.CV` - 具有空间意识的Transformer-GRU框架用于从3D OCT成像中增强青光眼诊断 [PDF](https://arxiv.org/pdf/2403.05702), [HTML](https://arxiv.org/abs/2403.05702)
### Authors
Mona Ashtari-Majlan,David Masip
### Background
青光眼是导致不可逆失明的主要原因之一，早期检测对于准确、及时的干预以防止不可逆的视力丧失至关重要。本研究提出了一种利用3D光学相干断层成像（OCT）影像诊断价值的新型深度学习框架，用于自动化青光眼检测。该模型通过预先训练的视网膜数据Vision Transformer、丰富的切片级特征提取和双向门控循环单元（GRU）捕捉切片间空间依赖性，实现了对局部微小变化和全局结构完整性进行全面分析，被认为是检测青光眼的关键步骤。实验结果表明，该框架在大型数据集上的性能优于现有技术，F1分数达到93.01%，马修斯相关系数（MCC）为69.33%，AUC分数为94.20%。这种能够利用3D OCT数据中的有价值信息的框架为临床决策支持系统的改进和青光眼管理性能的提升提供了巨大潜力。
### Innovation
该研究提出了一种创新的框架，将预先训练的Vision Transformer与双向门控循环单元相结合，用于从3D OCT成像中进行青光眼自动化诊断。通过这种方法，该研究旨在实现对局部细节和整体结构完整性进行全面分析，从而提高青光眼诊断的准确性。该方法的创新之处在于结合了两种不同的高级模型，并且该方法在多个性能指标上优于现有的先进方法。这些改进对于开发更高效的临床决策支持系统和提高青光眼的治疗效果具有重要意义。
### Conclusion
本研究提出了一种基于3D OCT成像的新型深学习框架，通过整合预训练的Vision Transformer和双向门控循环单元（GRU），提高了青光眼的诊断性能。实验结果表明，该方法在F1分数、马修斯相关系数（MCC）和AUC上均优于现有技术。这一框架为改善临床决策支持系统和提高青光眼患者的治疗效果提供了有价值的贡献。
## 456. `cs.CV` - 可迁移掩码变换器：基于区域自适应迁移性估计的跨域语义分割 [PDF](https://arxiv.org/pdf/2504.05774), [HTML](https://arxiv.org/abs/2504.05774)
### Authors
Jianhua Liu,Zhengyu Li,Yanru Wu,Jingge Wang,Yang Tan,Ruizhe Zhao,Guan Wang,Yang Li
### Background
最近的研究表明，Vision Transformers (ViTs) 在语义分割上取得了新的基准。然而，当将预训练的ViTs应用于新的目标领域时，由于分布偏移造成的显著性能下降常常发生，这导致了注意力机制的不足。由于自注意机制本质上是数据驱动的，在源域与目标域存在纹理、尺度或对象共现模式差异的情况时，它们无法有效地关注关键对象。尽管全局和局部域自适应方法提供了一些解决方案，但是在不同图像区域间的空间异质性下，基于区域的自适应是关键需求。因此，需要一种能够在这类异质性环境中有效工作的自适应方法来改变迁移学习的局限性。
### Innovation
本文提出了一种名为Transferable Mask Transformer (TMT) 的区域自适应迁移性评估的新的区域级别自适应框架。TMT 包括两大核心组件: (1) 自适应簇基础转移性估计器 (ACTE)，能够动态地将图像分割为结构和语义一致性较强的区域，以进行局部转移性评估；(2) 可迁移屏蔽注意 (TMA) 模块，能够将区域特定的转移性图层整合到ViTs的注意力机制中，优先在转移性较低且语义不确定性较高的区域进行自适应。这使得TMT能够在不同图像区域的分布偏移中提供更精准的学习动力，从而提高语义分割性能和可迁移性。
### Conclusion
在20对跨域数据上进行的全面评估表明，TMT 在迁移性能上具有显著优势，实现了比纯微调2%的平均mIoU改进，并相比现有最先进的基准提高了1.28%。
## 457. `cs.CV` - 基于超大规模自然图像的基础模型是否优于专门针对视网膜的模型用于检测眼内和全身疾病？ [PDF](https://arxiv.org/pdf/2502.06289), [HTML](https://arxiv.org/abs/2502.06289)
### Authors
Qingshan Hou,Yukun Zhou,Jocelyn Hui Lin Goh,Ke Zou,Samantha Min Er Yew,Sahana Srinivasan,Meng Wang,Thaddaeus Lo,Xiaofeng Lei,Siegfried K. Wagner,Mark A. Chia,Dawei Yang,Hongyang Jiang,An Ran Ran,Rui Santos,Gabor Mark Somfai,Juan Helen Zhou,Haoyu Chen,Qingyu Chen,Carol Y. Cheung,Pearse A. Keane,Yih Chung Tham
### Background
基础模型（FMs）正在彻底改变医疗领域。RETFound 是一种针对视网膜的特定基础模型，经过140万自然图像和160万视网膜图像的顺序预训练，在眼科临床应用中表现出极高的适应性。相比之下，DINOv2 是一种通用视觉基础模型，经过1.42亿自然图像的预训练，在非医学领域显示出潜力，但在临床任务中的应用尚未广泛探索。针对这个问题，研究者进行了直接对比实验，评估了RETFound 和三个不同规模的DINOv2模型在眼内疾病检测和全身疾病预测任务中的性能，结果展示了通用和领域特定基础模型在不同情况下的优劣差异。
### Innovation
研究引入了具体的基础模型对比实验，评估了专门针对视网膜的模型（RETFound）与通用基础模型（DINOv2的三种不同规模版本）在临床任务中的性能差异，特别是在眼科疾病检测和全身疾病预测方面的表现。这一研究填补了基础模型在医学领域应用尤其是临床任务中的认知空白，特别是在细粒度蒸馏等多个性能指标上的直接对比分析增加了研究的创新性，强调了加速基础模型在医疗领域应用的重要性。
### Conclusion
研究发现，DINOv2 在检测糖尿病视网膜病变和多类眼内疾病方面表现出色，尤其是在一些更大的模型上。然而，在预测心脏衰竭、心肌梗死和缺血性中风方面，专门针对视网膜的模型RETFound表现出更高的一致性能。这些趋势即使在仅使用10%的微调数据的情况下依然存在。结果阐明了在选择基础模型时应根据任务特定要求进行最佳匹配的重要性，以优化临床表现。
## 458. `cs.CV` - 松散衣物实时单品虚拟试穿及时间一致性方法 [PDF](https://arxiv.org/pdf/2506.12348), [HTML](https://arxiv.org/abs/2506.12348)
### Authors
Zaiqiang Wu,I-Chao Shen,Takeo Igarashi
### Background
传统单品虚拟试穿方法通过收集单品特异数据集并训练针对每个单品优化的网络来实现更优的效果。然而，这些方法在处理松散衣物时往往存在困难，主要原因在于：1) 它们依赖于人体的语义图将衣物与身体对齐，但在松散衣物遮挡人体轮廓时，语义图变得不可靠，导致结果下降；2) 它们在帧基础上进行单品合成网络训练，不利用时间信息，从而产生明显的帧间抖动伪影。
### Innovation
本文提出了两种创新方法来解决上述问题：1) 采用两阶段方法进行鲁棒语义图估计：首先从原始输入图像中提取服饰不变表示，然后通过辅助网络估计语义图，以增强在生成单品特异数据集时在宽松衣物下的语义图估计的鲁棒性；2) 引入了包含时间依赖性的循环服装合成框架，以提高帧到帧的一致性同时保持实时性能。
### Conclusion
通过定性和定量评估证明，本文的方法在图像质量和时间一致性方面优于现有方法。消融实验进一步验证了服饰不变表示和循环合成框架的有效性。
## 459. `cs.CV` - MIDOG 2025 Tracks 2: 使用病理学基础模型的异常有丝分裂分类集成 [PDF](https://arxiv.org/pdf/2509.02591), [HTML](https://arxiv.org/abs/2509.02591)
### Authors
Mieko Ochi,Bae Yuan
### Background
有丝分裂形式被分为典型和非典型变异，非典型的计数与肿瘤的侵略性密切相关。因此，准确区分这些形式对于患者的预后和资源分配至关重要。然而，即使是专家病理学家也难以准确区分它们。
### Innovation
该研究利用大规模组织病理学数据预训练的病理学基础模型（PFMs），并通过低秩适应进行参数高效微调。此外，研究还引入了ConvNeXt V2这一前沿的卷积神经网络架构。在训练过程中，使用鱼眼变换强调有丝分裂，并使用ImageNet目标图像进行频域适应。最终，通过对多个PFMs的集成，获得了竞争性的均衡准确率。
### Conclusion
通过这种集成方法，研究在Preliminary Evaluation Phase数据集上取得了竞争力的均衡准确率，展示了这种方法在非典型有丝分裂分类中的有效性和潜力。
## 460. `cs.CV` - SWiFT: Soft-Mask Weight Fine-tuning for Bias Mitigation [PDF](https://arxiv.org/pdf/2508.18826), [HTML](https://arxiv.org/abs/2508.18826)
### Authors
Junyu Yan,Feng Chen,Yuyang Xue,Yuning Du,Konstantinos Vilouras,Sotirios A. Tsaftaris,Steven McDonagh
### Background
近年来的研究表明，机器学习模型在实际应用中可能会出现偏差，这在医疗保健等伦理敏感领域构成重大挑战。这种偏差会影响模型的公平性、泛化能力和进一步加剧社会歧视的风险。因此，需要在训练后的模型中移除偏差。现有的去偏方法通常需要访问原始训练数据，并需要大量的模型重新训练；同时，它们通常会在模型公平性和辨别性能之间进行折衷。
### Innovation
为了解决这些问题，本文提出了SWiFT（软屏蔽权值微调）框架，该框架在保持模型辨别性能的同时高效地改进了公平性，所需去偏成本极低。SWiFT只需使用少量外部数据集并进行几次模型微调即能实现。其创新点在于：首先识别模型参数对偏差和预测性能的相对但独特的贡献，然后采用两步微调过程，根据参数的贡献使用不同的梯度流动更新每个参数。
### Conclusion
通过在四个皮肤病学数据集和两个胸部X射线数据集中针对三项敏感属性（性别、肤色、年龄）进行的广泛实验，表明SWiFT可以一致地减少模型偏差，在常见的公平性和准确性指标下实现与最先进的方法相当甚至更优的诊断准确率。具体而言，SWiFT展示了模型在泛化能力方面的改进，表现为在多个离散分布（OOD）数据集上的优越表现。
## 461. `cs.LG` - 平视隐藏的优化器：使用损失景观诱导的度量进行训练 [PDF](https://arxiv.org/pdf/2509.03594), [HTML](https://arxiv.org/abs/2509.03594)
### Authors
Thomas R. Harvey
### Background
在训练神经网络时，通常使用梯度下降（SGD）、Adam、AdamW 和 Muon 等优化方法。研究人员发现，在高维空间中嵌入损失景观时，可以利用黎曼度量，这种方法与常见的损失景观可视化方法背后的度量相同。通过将这种几何视角直白地应用并利用诱导的度量，开发了一种新的优化器。
### Innovation
提出了一类新型优化器，利用高维空间中嵌入损失景观时自然诱导的黎曼度量。该优化器与常见的 SGD、Adam、AdamW 和 Muon 等优化方法进行了比较。实验结果表明，这种新型优化器在低维情况下表现出色，并且在训练神经网络方面提供了 slight improvement。此外，这些优化器具有理论上的良好性质，如自适应地减少学习率并自动应用权重衰减。
### Conclusion
新提出的优化器在低维情况下表现优秀，并且相比最先进的方法在训练神经网络方面略有改善。这些优化器还具有自主降低学习率和解耦权重衰减等理论优越性。基本方法可用于修改现有的预处理方法，且新优化器的计算复杂度与 Adam 相当。
## 462. `cs.CV` - 揭开ReLU网络的面纱 [PDF](https://arxiv.org/pdf/2507.22832), [HTML](https://arxiv.org/abs/2507.22832)
### Authors
Maciej Satkiewicz
### Background
自任何ReLU网络都是分段线性函数以来，其隐藏单元可以通过激活子网络的回拉来表征，即通过其梯度（忽略偏置项）。然而，深层神经元的梯度众所周知的不一致，这使得网络内部表示变得模糊。文章提出尽管模型中梯度与数据之间存在这种对齐，但这种对齐关系却被ReLU硬门控的固有噪声所掩盖。证明了这一直觉，通过在反向传播中仅应用软门控，减轻弱激活神经元的局部影响，得到了所称的“激活回拉”，这些回拉在多个ImageNet预训练架构上表现出明显的感知对齐，而基本的像素空间梯度上升则迅速产生了易于解释的输入和目标特定的特征。
### Innovation
提出了一种软门控方法，通过反向传递中应用软门控，减少弱激活神经元的影响，从而得到所谓的“激活回拉”。这种回拉在多个ImageNet预训练架构上表现出明显的感知对齐。还提出了“路径稳定性”假设，声称在训练过程中二进制激活模式大大稳定，并在最终模型中的预激活分布中被编码。此外，还给出了对Batch Normalization和Deep Features有效性的解释，并提供了一种新的网络内部记忆和泛化特性视角。
### Conclusion
激活回拉不仅提供了一种理论上解释基于这些回拉的特征归因的忠实性，还可能为更深层次模型的因果解释提供机制。此外，还提供了一种对网络内部记忆和泛化属性的新理解，并公开了代码和交互式应用程序以供探索激活回拉。
## 463. `cs.LG` - AutoGrid AI: 基于深度强化学习的自主微电网管理框架 [PDF](https://arxiv.org/pdf/2509.03666), [HTML](https://arxiv.org/abs/2509.03666)
### Authors
Kenny Guo,Nicholas Eckhert,Krish Chhajer,Luthira Abeykoon,Lorne Schell
### Background
提出了基于深度强化学习的自主微电网管理框架，适用于偏远社区。利用深度强化学习和时间序列预测模型优化微电网的能量调度策略，减少成本，最大化可再生能源（如太阳能和风能）的利用。
### Innovation
该框架结合了变压器架构进行可再生能源生成的预测，并使用近端策略优化（PPO）智能体在模拟环境中做出决策。实验结果表明，与传统的基于规则的方法相比，在能源效率和操作韧性方面有显著改进。
### Conclusion
这项工作推动了智能电网技术的发展，旨在实现零碳能源系统。最后，提供了模拟多个微电网环境的开源框架。
## 464. `cs.LG` - CEHR-GPT：电子健康记录的可扩展多任务基础模型 [PDF](https://arxiv.org/pdf/2509.03643), [HTML](https://arxiv.org/abs/2509.03643)
### Authors
Chao Pang,Jiheum Park,Xinzhuo Jiang,Nishanth Parameshwar Pavinkurve,Krishna S. Kalluri,Shalmali Joshi,Noémie Elhadad,Karthik Natarajan
### Background
电子健康记录（EHRs）提供了患者健康状况的丰富、纵向视角，对于临床决策支持、风险预测和数据驱动的医疗研究具有重要潜力。然而，大多数使用EHRs的人工智能（AI）模型局限于单一任务，限制了它们在实际应用中的扩展性和实用性。
### Innovation
CEHR-GPT引入了一个统一了特征表示、零样本预测和合成数据生成能力的基础模型。它通过一个新颖的时间标记学习框架，将患者的动态时间线明确地编码进模型结构中，支持临床序列的时序推理。CEHR-GPT在所有三个任务上均表现出强劲性能，并通过词汇扩展和微调有效泛化到外部数据集。其灵活性使得无需特定任务的重新训练，就可以实现快速模型开发、群体发现和患者预后预测。
### Conclusion
CEHR-GPT展示了在电子健康记录数据处理中的广泛应用和有效性，提供了一种在不同任务间通用的基础模型架构，极大地提高了AI在实际医疗场景中的适用性和解决方案的灵活性。
## 465. `cs.LG` - 具有客户可用性预算的半去中心化联邦时间序列预测 [PDF](https://arxiv.org/pdf/2509.03660), [HTML](https://arxiv.org/abs/2509.03660)
### Authors
Yunkai Bao,Reza Safarzadeh,Xin Wang,Steve Drew
### Background
联邦学习（FL）通过考虑隐私在物联网（IoT）场景中有效促进分布式客户端之间的协作训练。尽管存在数据异质性，但FL客户端也可能受到有限的能量和可用预算的限制。因此，有效选择参与训练的客户端对于全球模型的收敛和客户端贡献的平衡非常重要。本文讨论了时间序列数据的客户端可用性对联邦学习性能的影响，并设置了三种不同的场景来影响时间序列数据的可用性，提出了一个名为FedDeCAB的新颖半去中心化客户端选择方法，该方法通过应用可用客户端的概率排名来进行客户端选择。在客户端与服务器断开连接时，FedDeCAB可以从最近邻客户端获取部分模型参数进行联合优化，提高离线模型的性能并减少通信开销。基于真实大规模出租车和船舶轨迹数据集的实验表明，FedDeCAB在高度异质数据分布、有限通信预算和动态客户端离线或重新加入的情况下都是有效的。
### Innovation
提出了一种名为FedDeCAB的新颖半去中心化客户端选择方法，该方法通过应用可用客户端的概率排名来进行客户端选择。当客户端与服务器断开连接时，这种方法允许从最近邻客户端获取部分模型参数进行联合优化，以提高性能并减少通信开销。所提方法在高度异质数据分布、有限通信预算和动态客户端离线或重新加入的情况下得到了应用验证。
### Conclusion
研究结果表明，FedDeCAB在各种条件下都是有效的，可以提高联邦学习的时间序列预测性能，并有效降低通信开销。
## 466. `cs.LG` - SharedRep-RLHF: 一种多元偏好强化学习人类反馈的共享表示方法 [PDF](https://arxiv.org/pdf/2509.03672), [HTML](https://arxiv.org/abs/2509.03672)
### Authors
Arpan Mukherjee,Marcello Bullo,Deniz Gündüz
### Background
现有均匀奖励的强化学习（RLHF）方法通过训练单一奖励模型来代表所有标记者的偏好，但未能捕捉到不同子群体间的多样性意见，反而倾向于支配群体。最新的RLHF方法MaxMin-RLHF通过学习群体特定的奖励模型，并优化最低奖励的群体来促进公平。然而，该方法在最小奖励群体是少数民族时表现不佳，因此引入了一种新型框架SharedRep-RLHF来解决这一问题，它通过学习和利用各群体之间共享的特征来改进。
### Innovation
SharedRep-RLHF提出了通过学习和利用各群体之间的共享特征来改进的方法，而非为每个群体单独学习奖励模型。此外，它量化了SharedRep-RLHF的样本复杂性，并在多种自然语言任务上展示了其与MaxMin-RLHF相比的优势，有效率最高可提升20%。
### Conclusion
SharedRep-RLHF框架通过共享特征学习，在促进RLHF的公正性方面取得了显著进步，特别是在最小高奖励群体是少数群体时表现更好，并且在不同自然语言任务上展示了比MaxMin-RLHF更高的性能。
## 467. `cs.LG` - 非负矩阵分解与共同原因原则 [PDF](https://arxiv.org/pdf/2509.03652), [HTML](https://arxiv.org/abs/2509.03652)
### Authors
E. Khalafyan,A. E. Allahverdyan,A. Hovhannisyan
### Background
非负矩阵分解（NMF）是一种已知的无监督数据缩减方法。共同原因（PCC）是概率因果的基本方法论途径，旨在寻找两个相关随机变量联合概率的独立混合模型。研究表明，这两个概念密切相关。作者通过几个灰度图像的数据集探索了这种关系，将这些图像方便地映射为概率模型，进一步研究了PCC和NMF在多个数据集上的应用。
### Innovation
1. PCC提供了可预测的工具，用于稳健估计NMF的有效秩，这种估计方法对弱噪声具有稳定性，不像其他估计方法（如基于贝叶斯信息准则的方法）。2. 实现NMF以该秩为标准可以生成对噪声和局部优化种子具有稳定性的特征（基图像），从而有效解决了NMF非唯特性问题。3. NMF提供了一种实现PCC的近似方法，其中较大的并且正相关的联合概率可以通过独立混合模型更好地解释。4. 开发了一种聚类方法，将具有相同共同原因的数据点分组到同一个聚类中，并展示了如何使用NMF进行数据去噪。
### Conclusion
NMF与PCC之间的关系促进了对NMF的稳定性和去噪性能的深刻理解，并且为PCC的应用提供了新的范例。
## 468. `cs.LG` - 图随机特征用于可扩展的Gaussian过程 [PDF](https://arxiv.org/pdf/2509.03691), [HTML](https://arxiv.org/abs/2509.03691)
### Authors
Matthew Zhang,Jihao Andreas Lin,Adrian Weller,Richard E. Turner,Isaac Reid
### Background
本文研究了图随机特征（GRFs）的应用，这是一种最近引入的用于估计图节点核的随机估计器。研究将GRFs应用于离散输入空间的可扩展Gaussian过程。
### Innovation
作者证明，在温和假设下，使用GRFs的贝叶斯推理具有对节点数N的时间复杂度$O(N^{3/2})$，相比于精确核的$O(N^3)$。这带来了显著的实测时间和内存节省，使使用单一计算芯片就能在节点数超过$10^6$的图上进行贝叶斯优化，同时保持竞争性性能。
### Conclusion
该研究展示了如何利用图随机特征GRFs显著提高Gaussian过程在图数据上的可扩展性，通过大量减少计算时间和内存需求，使得之前的不可行操作成为可能。
## 469. `cs.LG` - 基于机器学习视角从经济角度研究供应链管理与金融供应链协同优化 [PDF](https://arxiv.org/pdf/2509.03673), [HTML](https://arxiv.org/abs/2509.03673)
### Authors
Hang Wang,Huijie Tang,Ningai Leng,Zhoufan Yu
### Background
基于经济学理论并结合机器学习技术，本研究探讨了一种合作的供应链管理与金融供应链管理（SCM - FSCM）模型，旨在解决效率损失、融资限制和风险传递等问题。该研究结合了交易成本和信息不对称理论，并使用随机森林算法处理多维数据，构建了一种以数据驱动的成本效率风险三维分析框架。
### Innovation
1. 将Transaction Cost和Information Asymmetry理论结合，使用随机森林算法、LSTM网络等先进技术处理多维数据并构建模型。2. 应用了“关键企业信用赋能加上动态质押融资”的FSCM模型。3. 使用LSTM网络进行需求预测，群集/回归算法进行收益分配。4. 结合博弈论和强化学习优化库存采购机制，并使用XGBoost进行信用评估，以实现库存的快速货币化。5. 在20家核心企业和100家支持企业上进行了验证，结果显示存货周转率提高了30%，中小企业融资成本降低了18%-22%，订单完成率稳定在95%以上，且模型表现出色（预测误差≤8%，信用评估准确率≥90%）.
### Conclusion
本SCM-FSCM模型有效降低了运营成本、缓解了融资限制，并支持高质量供应链的发展。
## 470. `cs.LG` - 视频游戏中多智能体强化学习的全面回顾 [PDF](https://arxiv.org/pdf/2509.03682), [HTML](https://arxiv.org/abs/2509.03682)
### Authors
Zhengyang Li,Qijin Ji,Xinghong Ling,Quan Liu
### Background
近年来，多智能体强化学习（MARL）在现代游戏中展现了其应用潜力。从基础工作到如AlphaStar在《星际争霸II》和OpenAI Five在《英雄联盟》中的里程碑成就，MARL通过自我游戏、监督学习和深度强化学习等技术，在各种游戏环境中证明了其实现超人表现的能力。随着MARL影响的不断扩大，对这一领域的全面审查变得越来越重要。本文旨在对MARL在视频游戏中的应用进行全面检视，从回合制二人游戏到实时多人视频游戏，包括体育游戏、第一人称射击游戏、实时战略游戏和多人在线战斗竞技场游戏等热门类型。进一步分析了MARL在视频游戏中的关键挑战，如非稳态、部分观测性、稀疏奖励、团队协作和可扩展性，并在《火箭联盟》、《我的世界》、《雷神之锤III竞技场》、《星际争霸II》、《英雄联盟》等游戏中突出成功的实现案例。
### Innovation
本文提供了对MARL在视频游戏AI系统中的见解，提出了一种新的方法来评估游戏复杂性，并提出了未来研究方向，以推动MARL及其在游戏开发中的应用，激发了这一快速发展的领域中的进一步创新。
### Conclusion
本文对MARL在视频游戏中的应用进行了全面审查，指出了其关键挑战，并提出了一种新方法来估计游戏复杂性，提出了未来的研究方向，旨在推动MARL及其在游戏开发中的应用。
## 471. `cs.CV` - 材料微结构图像的监督和非监督分割与分类框架 [PDF](https://arxiv.org/pdf/2502.07107), [HTML](https://arxiv.org/abs/2502.07107)
### Authors
Kungang Zhang,Wei Chen,Wing K. Liu,L. Catherine Brinson,Daniel W. Apley
### Background
材料的微观结构通常通过图像分析来表征，从而理解工艺-结构-性能关联。随着制造和成像技术的进步，高分辨率成像揭示了微结构的复杂性，同时大量成像数据的增加也对自动提取材料特征和知识提出了更强大、自动化的框架的需求。
### Innovation
提出了一种集成无监督和监督学习方法的自动化框架，用于根据微结构相/类对显微图像进行分类，并对多相微结构进行不同均匀区域的分割。此框架逐步构建一个相关于特定工艺或材料组的微结构类别的数据库，有助于新材料的分析和发现/识别。框架分为三个步骤：通过最近开发的评分方法对多相显微图像进行分割，确定不同的微观结构均匀区域；训练具有不确定性意识的监督分类网络识别和分类从步骤1分割的显微图像，并通过内置不确定性量化和最少的人工检查验证标签；训练分割网络进行多相微结构的更强大的监督分割，结合来自步骤1-2的图像和结果进行数据增强。框架展示了多种材料和纹理图像集上的效果。
### Conclusion
此框架能够迭代地表征/分割新的均匀或多相材料，同时扩展数据库以提高性能。
## 472. `cs.LG` - 从梯度动态中获得的见解：梯度自调整规范化 [PDF](https://arxiv.org/pdf/2509.03677), [HTML](https://arxiv.org/abs/2509.03677)
### Authors
Vincent-Daniel Yun
### Background
梯度动力学在决定深度神经网络的稳定性和泛化能力中扮演着核心角色。本文通过实证分析发现，在卷积网络训练过程中，梯度方差和标准差在不同层和全局范围内表现出一致的变化。这种观察促使我们提出了一种无需超参数的梯度规范化方法，该方法使梯度标准化与它们的自然演变相一致。这种方法可以防止不希望的放大，稳定优化，并保持收敛保证。
### Innovation
本文提出了一种无需超参数的梯度规范化方法，该方法使梯度标准化与它们的自然演变相一致。这种方法可以防止不希望的放大，稳定优化，并保持收敛保证。在CIFAR-100基准上进行了实验，使用ResNet-20、ResNet-56和VGG-16-BN证明了该方法可以维持或提高测试准确性，即使在强烈的泛化条件下也不例外。这种方法还强调了直接跟踪梯度动态的重要性，以弥合理论期望与实际行为之间的差距，并为未来的优化研究提供见解。
### Conclusion
实验表明，该方法在CIFAR-100基准上可以维持或提高ResNet-20、ResNet-56和VGG-16-BN的测试准确性，特别是在泛化压力较强的条件下。此外，本文通过研究强调了直接跟踪梯度动态的重要性，旨在弥合理论期望与实际行为之间的差距，并为未来的优化研究提供了见解。
## 473. `cs.LG` - 从联邦学习到$boldsymbol{X}$学习：通过随机游走打破去中心化障碍 [PDF](https://arxiv.org/pdf/2509.03709), [HTML](https://arxiv.org/abs/2509.03709)
### Authors
Allan Salihovic,Payam Abdisarabshali,Michael Langberg,Seyyedali Hosseinalipour
### Background
介绍了$boldsymbol{X}$学习（$boldsymbol{X}$L）架构，这是一种新颖的分布式学习体系结构，能够扩展并推广去中心化的概念。本文探讨了$boldsymbol{X}$L与图论和马尔可夫链之间的直观但非平凡的联系，为该领域的进一步研究提出了若干开放式研究方向。
### Innovation
提出了$boldsymbol{X}$L架构，这是一种新颖的分布式学习模型，延展了去中心化的概念。研究者揭示了$boldsymbol{X}$L与图论和马尔可夫链之间非直观的联系，并探讨了该架构的设计因素和自由度。
### Conclusion
作者通过研究$boldsymbol{X}$L，揭示了其独特的设计理念和潜在的研究方向，为进一步的研究和发展打开了新视野。
## 474. `cs.LG` - EmbedOR：基于曲率的可证簇保留可视化 [PDF](https://arxiv.org/pdf/2509.03703), [HTML](https://arxiv.org/abs/2509.03703)
### Authors
Tristan Luca Saidi,Abigail Hickok,Bastian Rieck,Andrew J. Blumberg
### Background
SNE算法如UMAP和tSNE虽然能够生成可视化图形，但在处理噪声和高维度数据时常常不能准确保留几何结构。这些问题包括错误地分离数据子流形中的连接组件，和难以识别清晰可聚类的数据中的聚类。
### Innovation
提出了一个通过引入曲率增强距离度量来强调潜在聚类结构的SNE算法EmbedOR。通过证明，EmbedOR的距离度量将tSNE的一致性结果扩展到更广泛的数据集类别中。 EmbedOR实验表明，它比其他SNE算法和UMAP更少导致数据连续、高密度区域的分裂。此外，EmbedOR距离度量可以用于标注现有的可视化，以识别分裂并提供对数据潜在几何结构的更深入洞察。
### Conclusion
研究证明，EmbedOR在保持数据几何结构方面表现出色，尤其在处理连续高密度区域时不那么容易导致数据分裂，并为已有可视化提供了理解数据潜在几何结构的工具。
## 475. `cs.LG` - Hierarchical Federated Foundation Models over Wireless Networks for Multi-Modal Multi-Task Intelligence: Integration of Edge Learning with D2D/P2P-Enabled Fog Learning Architectures [PDF](https://arxiv.org/pdf/2509.03695), [HTML](https://arxiv.org/abs/2509.03695)
### Authors
Payam Abdisarabshali,Fardis Nadimi,Kasra Borazjani,Naji Khosravan,Minghui Liwang,Wei Ni,Dusit Niyato,Michael Langberg,Seyyedali Hosseinalipour
### Background
基础模型（FMs）的兴起重塑了机器学习的格局。随着这些模型的持续增长，利用来自无线设备的地理分布数据变得越来越重要，由此催生了联邦基础模型（FFMs）。近期，FMs 发展成为处理多种跨任务模态的多模态多任务（M3T）FMs（例如，GPT-4），这促使了新型未经探索的范式：M3T FFMs。本文通过引入分层联邦基础模型（HF-FMs）展示了这一新范式的变体，同时揭示了这种新兴模型对雾/边缘网络中存在的两个未被充分认识到的异质性维度的影响：（i）收集的模态的异质性；（ii）在雾/边缘节点上执行任务的异质性。HF-FMs 策略地将 M3T FMs 的分模块结构，包括模态编码器、提示、专家混合（MoEs）、适配器和任务头，与雾/边缘基础设施的分层性质相契合。此外，HF-FMs 允许节点间设备到设备（D2D）通信，当可行时，可以实现水平模块转发和局部协同训练。通过研究 HF-FMs 的架构设计，我们强调了它们的独特功能，并提出了若干适配的研究方向。最后，为了展示其潜力，我们在无线网络环境中原型构建了 HF-FMs，并发布了开源代码，旨在促进对该未探索领域的研究（GitHub: 这个 https URL）。
### Innovation
本文提出了分层联邦基础模型（HF-FMs），这种新型联邦基础模型可以更好地适应雾/边缘网络的分层结构，并且引入了模态和任务的异质性作为未被充分认识到的维度。此外，HF-FMs 还允许采用 D2D 通信进行水平模块转发和局部协同训练，从而提升了模型性能。该工作通过原型构建展示了 HF-FMs 的潜力，并开放了相关的源代码，为该领域的进一步研究提供了支持。
### Conclusion
本文通过分层联邦基础模型（HF-FMs）展示了多模态多任务智能在无线网络中的集成，并通过 D2D/P2P 通信实现了雾/边缘网络的协同学习。通过研究 HF-FMs 的架构设计，揭示了 HF-FMs 在分层联邦学习中的潜在优势，并指出了未来的研究方向。HF-FMs 的原型构建和开源代码的发布为该领域提供了新的开发起点，促进了对该未开发领域的进一步探索。
## 476. `cs.LG` - 稀疏自动编码神经算子：函数空间中的模型恢复 [PDF](https://arxiv.org/pdf/2509.03738), [HTML](https://arxiv.org/abs/2509.03738)
### Authors
Bahareh Tolooshams,Ailsa Shen,Anima Anandkumar
### Background
虽然柏拉图的表征假设指出神经网络在不同架构中会收敛到类似表征，但神经算子的表征特性仍然没有得到充分探索，尽管它们在科学计算中的重要性日益增加。关于神经模型中统一表示的问题被表述为稀疏模型恢复的问题，并引入了一种框架，该框架将稀疏自编码器扩展到提升空间和无限维函数空间，这使得大型神经算子的机理可解释性成为可能.
### Innovation
提出了稀疏自动编码器神经算子模型，将其扩展到提升空间和无限维函数空间，比较了稀疏自编码器（SAEs）、提升稀疏自编码器（lifted-SAE）和神经算子在推断和训练动力学上的差异，特别强调提升和算子模块引入了有帮助的归纳偏置，这有助于加快恢复速度，改善光滑概念的恢复，并实现了在不同分辨率下的稳健推断，此特性是神经算子独有的特征.
### Conclusion
通过将稀疏自编码器扩展到提升空间和无限维函数空间，研究提升了大型神经算子的机理解释性，同时还展示了这些算子在不同分辨率下的稳健性和恢复光滑概念的优势，并通过与传统稀疏自编码器和提升稀疏自编码器的比较进一步证明了其有效性.
## 477. `cs.LG` - 节俭预算下的地图绘制：优化空间数据采集以供机器学习 [PDF](https://arxiv.org/pdf/2509.03749), [HTML](https://arxiv.org/abs/2509.03749)
### Authors
Livia Betti,Farooq Sanni,Gnouyaro Sogoyou,Togbe Agbagla,Cullen Molitor,Tamma Carleton,Esther Rolf
### Background
在农业、生态学和人类发展等领域，基于卫星图像的机器学习（SatML）受到标记训练数据稀疏性的限制。虽然卫星数据覆盖全球，但SatML所需的标记训练数据集通常规模较小、空间聚集且收集目的与其他任务有关（如行政调查或实地测量）。尽管这个问题在实践中普遍存在，但过去的SatML研究大多集中在新的模型架构和训练算法上，以处理稀缺的训练数据，而不是直接建模数据条件。这使希望使用SatML进行大规模监测的科学家和决策者在是否以及如何收集额外数据以最大化性能方面存在不确定性。
### Innovation
本文首次提出了在不均匀数据采集成本和现实预算限制下的空间训练数据优化问题的表述，以及解决该问题的新方法。实验结果显示，通过样本优化可以获得显著的收益。进一步的实验界定了优化采样特别有效的条件。所提出的方法旨在跨越SatML的应用领域通用；特别强调了一个我们的合作者可以在其中立即应用研究结果以增强在多哥的聚类农业调查的SatML监测的具体问题设置。
### Conclusion
通过引入问题表述和解决方法，研究解决了在现实预算限制下如何优化空间数据采集以供机器学习的问题。特别适用于处理农业监测中的聚类数据情况。未来的研究可以通过实际应用场景进一步验证这些方法的有效性。
## 478. `cs.LG` - 不同可微分熵正则化在几何与神经网络中的应用 [PDF](https://arxiv.org/pdf/2509.03733), [HTML](https://arxiv.org/abs/2509.03733)
### Authors
Ibne Farabi Shihab,Sanjeda Akter,Anuj Sharma
### Background
本文介绍了一种从计算几何中引入的可微范围分区熵估计器，它能使算法适应输入数据的排序程度。尽管范围分区熵在算法设计中提供了强大的保证，但在深度学习领域尚未得到应用。本文致力于将可微范围分区熵纳入深度学习，旨在通过一个可训练的损失函数或正则化项来提高下游实例最优算法的效率。
### Innovation
本文首次提出了范围分区熵的第一个可微分近似，这使得它可以作为可训练的损失函数或正则化项使用。此外，设计了一个名为EntropyNet的神经模块，通过重组数据以低熵形式加速下游实例最优算法。最后，将熵正则化的概念扩展到Transformer注意力机制上，直接应用于熵正则化。在不同任务中，作者展示了可微分熵提高效率而不损害正确性的效果：在几何任务上，该方法实现了至多4.1倍的运行时加速，误差微乎其微（<0.2%）；在深度学习任务上，与L1基线相比，它实现了6%的更高准确率，且稀疏度为80%。理论分析提供了估计器的近似界，详尽的消融实验验证了设计选择。这些结果表明，熵有界计算不仅是理论上的优美机制，也是一种适应性学习、效率和结构化表示的实用机制。
### Conclusion
本文的研究结果表明，可微分熵不仅可以提高几何和神经网络中的算法效率，还能够产生结构化注意力模式，从而在稀疏度很高时仍然保持较高准确性。未来的应用展示了此类熵有界计算在增强深度学习和优化算法中的巨大潜力。
## 479. `cs.LG` - 学习对手的全局模型以在多智能体强化学习中实现自动课程生成 [PDF](https://arxiv.org/pdf/2509.03771), [HTML](https://arxiv.org/abs/2509.03771)
### Authors
Brennen Hill
### Background
世界模型能够推断和预测环境动态，在嵌入式智能中起着基础性作用。然而，这些模型的能力往往受限于训练环境中由手工程设计的复杂性和潜在偏见。为了开发出真正具有泛化能力和鲁棒性的智能体，我们需要能够与其一起提升复杂度的环境。本文重新定义了环境生成的挑战，将其视为学习一个目标导向的生成式世界模型的问题。一种攻击者智能体通过学习隐式世界模型来合成对一队合作性防御者智能体而言越来越难的挑战。
### Innovation
本文提出了一种系统，其中生成式攻击者智能体学习隐式世界模型以生成越来越难的挑战，而防御者智能体学习协同策略以应对这些生成的世界。这种共生进化动态形成了一个自适应提升的课程，世界模型不断调整以挑战智能体的决策制定策略，并提供持续不断的创新且相关的训练场景。例如，研究揭示了世界模型能够学习生成侧翼包围和护盾阵型，而防御者学会了协同集火炮火和分散进攻的战术。
### Conclusion
这项研究表明，这种框架能够促进复杂行为的出现，使世界模型能够学习生成各种策略，而防御者则学习协同应对这些策略。我们的发现将共生演化的对手视为学习具有更大战略深度和鲁棒性的世界模型的有效方法。
## 480. `cs.LG` - 通过扩散映射学习函数 [PDF](https://arxiv.org/pdf/2509.03758), [HTML](https://arxiv.org/abs/2509.03758)
### Authors
Alvaro Almeida Gomez
### Background
本文提出了一种基于扩散映射框架的数据驱动方法，用于在光滑流形上近似实值函数。这种方法基于流形假设，通过扩散几何及其与热方程和Laplace-Beltrami算子的联系，利用函数点值构造一个平滑扩展到整体空间的方法。面对高维数据的计算挑战，文中引入了一种基于距离矩阵低秩结构的维数约简策略，通过奇异值分解（SVD）揭示。此外，文中还开发了一种在线更新机制，以实现新数据的有效集成，从而提高可扩展性和降低计算成本。数值实验表明，该方法在准确性和效率方面优于经典的前馈神经网络和插值方法，特别是在稀疏CT重建的应用中表现突出。
### Innovation
本文提出了一种基于扩散映射框架的数据驱动方法，该方法能够利用扩散几何和热方程及Laplace-Beltrami算子的联系，在光滑流形上近似实值函数。为了应对高维数据的计算挑战，引入了一种维度约简策略，通过SVD揭示了距离矩阵的低秩结构。此外，开发了在线更新机制以高效集成新数据，提高方法的可扩展性和降低计算成本。
### Conclusion
数值实验表明，所提出的方法在准确性和效率方面优于经典的前馈神经网络和插值方法，特别是在稀疏CT重建的应用中表现突出。通过扩散映射框架，该方法能够在保持准确性的前提下，更有效地处理高维数据。
## 481. `cs.LG` - 在奖励函数中什么是基本结构能够促进有效的稀疏奖励学习？ [PDF](https://arxiv.org/pdf/2509.03790), [HTML](https://arxiv.org/abs/2509.03790)
### Authors
Ibne Farabi Shihab,Sanjeda Akter,Anuj Sharma
### Background
研究稀疏奖励强化学习的基本性质，探讨奖励矩阵的低秩结构如何影响样例复杂度。以往对于稀疏奖励环境中的样本复杂度主要呈现指数增长，而低秩结构可以将其转换为多项式增长。
### Innovation
提出了Policy-Aware Matrix Completion (PAMC) 方法，将矩阵完成理论与强化学习相结合，通过政策依赖的采样分析，实现了：(i) 稀疏奖励观测的一般不可能结果，(ii) 基于动态的无奖励表示学习，(iii) 无需假设分布的置信集通过收敛预测，(iv) 坚韧的完成保证在低秩结构仅近似时逐渐恶化。PAMC 在100个系统采样的领域中，显示出在超过一半的领域中有可利用的结构，相比强探索、结构化和表示学习基线，PAMC 在样本效率上提高了1.6到2.1倍，增加了大约20%的计算成本。
### Conclusion
证明了结构性奖励学习的前景，对机器人技术、医疗保健及其他高安全性、高需求样本的应用领域具有重要意义。
## 482. `cs.LG` - 使用深度神经网络预测交通事故严重性 [PDF](https://arxiv.org/pdf/2509.03819), [HTML](https://arxiv.org/abs/2509.03819)
### Authors
Meghan Bibb,Pablo Rivas,Mahee Tayba
### Background
交通事故可用于减轻未来事件的风险。近年来，机器学习的进步为研究与交通事故相关的数据提供了新的方法。新的模型在不平衡数据上实现了良好的泛化能力和高预测能力。本文研究了基于神经网络的模型在交通事故数据上的应用。我们首先分析了相关特征共线性并通过自编码器进行无监督降维，接着应用密集网络。目标是对交通事故数据进行特征分析，分类交通事故严重程度。
### Innovation
研究使用自编码器进行无监督降维，采用密集网络构建深度神经网络。研究结果显示，当使用提出的深度神经网络分类交通事故严重程度时，交叉验证结果达到92%的准确率。
### Conclusion
通过使用自编码器进行特征降维和密集网络构建深度神经网络，能够有效提高对交通事故严重程度分类的准确率。
## 483. `cs.LG` - 使用特征调整的在线时间序列预测 [PDF](https://arxiv.org/pdf/2509.03810), [HTML](https://arxiv.org/abs/2509.03810)
### Authors
Xiannan Huang,Shuhan Qiu,Jiayuan Du,Chao Yang
### Background
时间序列预测在多个领域中具有重要意义，但面对分布迁移（distribution shift）的挑战。尤其是当数据在线部署时，数据按序到达，模型需要不断适应变化的模式，这是时间序列在线学习方法面临的挑战。当前的方法主要关注更新合适的参数（如最终层权重或适配模块）以及开发合适的更新策略（如使用最近的数据批次、重放缓冲或平均梯度）。这些方法的局限性在于未能从根本上解决分布迁移问题，通常基于表面参数的变化而非潜在因子的变化来调整模型参数。针对多步预测中的延迟反馈这一关键问题，以往方法能力有限，难以提供准确的预测结果。
### Innovation
本文提出了一种新颖的方法，即ADAPT-Z（Automatic Delta Adjustment via Persistent Tracking in Z-space），它使用了一个适配模块，结合当前的特征表示和历史梯度信息，能够在延迟反馈的情况下进行稳健的参数更新。这一方法特别关注的是通过调整潜在因素的特征表示来更有效地应对分布迁移问题，而不仅仅是调整表面的参数。实验结果表明，该方法在多个数据集上优于没有适应机制的标准基础模型和最先进的在线学习方法。
### Conclusion
本方法通过引入ADAPT-Z解决了多步预测中的延迟反馈问题，并且在多个数据集上优于现有的在线学习方法。
## 484. `cs.LG` - 基于概率上下文变量的元逆强化学习在均田博弈中的应用 [PDF](https://arxiv.org/pdf/2509.03845), [HTML](https://arxiv.org/abs/2509.03845)
### Authors
Yang Chen,Xiao Lin,Bo Yan,Libo Zhang,Jiamou Liu,Neset Özkan Tan,Michael Witbrock
### Background
在实际应用中，为众多相互作用的智能代理设计合适的奖励函数是具有挑战性的。逆强化学习（IRL）在均田博弈（MFGs）中的应用提供了一种从专家演示中推断奖励函数的实用框架。然而，现有的方法主要假设代理是同质的，这限制了它们处理具有不同且未知目标的演示的能力，而这种类型的实际演示是常见的。
### Innovation
本文提出了一种深层次的潜在变量MFG模型及其相关的IRL方法。该方法能够在没有先验了解底层上下文或修改MFG模型的情况下，从不同但结构相似的任务中推断出奖励函数。实验结果表明，相比现有的MFG中的IRL方法，本文的方法在模拟场景和真实世界的出租车定价问题上具有优越性。
### Conclusion
我们的实验在模拟场景和真实世界的出租车定价问题上展示了我们的方法在MFGs中的优越性，优于现有最先进的IRL方法。
## 485. `cs.LG` - 通过多模态大语言模型实现车辆基础设施协作空间感知 [PDF](https://arxiv.org/pdf/2509.03837), [HTML](https://arxiv.org/abs/2509.03837)
### Authors
Kimia Ehsani,Walid Saad
### Background
车辆到基础设施（V2I）系统的通信链路质量预测对于平滑切换、高效波束管理以及可靠的低延迟通信至关重要。现代车辆中传感器数据的日益可用性推动了使用多模态大语言模型（MLLMs），因其在任务适应性和推理能力方面的灵活性。然而，MLLMs 固有地缺乏三维空间理解。
### Innovation
为了克服此限制，提出了一种轻量级、即插即用的鸟瞰视角（BEV）注入连接器。通过收集邻近车辆的传感数据来构建环境的 BEV 表示，然后将其与自身车辆的输入结合以提供空间上下文给大语言模型。为了支持现实的多模态学习，开发了一个结合 CARLA 模拟器和基于 MATLAB 的射线跟踪的协同仿真环境，以生成各种场景下的 RGB、LiDAR、GPS 和无线信号数据。从射线跟踪输出中提取指令和真实响应。各种实验在 V2I 链路预测任务上进行，涵盖了视线（LoS）与非视线（NLoS）分类、链路可用性及遮挡预测。仿真结果表明，提出的 BEV 注入框架在所有任务上都提高了性能。
### Conclusion
相比于仅自身车辆的基线方法，提出的这种方法使准确性指标的宏均值提高了最多 13.9%。结果还显示，在恶劣的雨天和夜间条件下，性能提升最多可增加 32.7%，这证实了框架在不良环境中的稳健性。
## 486. `cs.LG` - 基于LiDAR的室内表面分类的机器学习方法 [PDF](https://arxiv.org/pdf/2509.03813), [HTML](https://arxiv.org/abs/2509.03813)
### Authors
Parth Ashokbhai Shiroya,Swarnagowri Shashidhar,Amod Ashtekar,Krishna Aindrila Kar,Rafaela Lomboy,Dalton Davis,Mohammed E. Eltayeb
### Background
毫米波（mmWave）和次太赫兹（sub-THz）网络的可靠连通性依赖于周围表面的反射，因为高频信号特别容易受到阻挡。表面的散射特性不仅由材料的介电常数决定，还由表面粗糙度决定，这决定了能量是否保持在镜面方向或进行漫散射。因此，散射行为受材料的光学反射性及表面粗糙度的共同影响。本文的研究背景是开发一种机器学习框架，利用LiDAR数据对室内表面进行分类，这有助于理解其散射特性，进而优化无线通信系统，尤其是下一代网络中的波束管理和连通性管理。
### Innovation
本文提出了一种基于LiDAR的机器学习框架，用于根据光学反射性将室内表面分类为半镜面和低镜面类别。通过收集超过78,000个点的数据，研究者将这些数据按3厘米 x 3厘米的块进行分割，以便于从部分视图中进行分类。提取了包括几何角度和强度特征，即视场角、自然对数尺度的强度和最大值与平均值比值，用于训练随机森林、XGBoost和神经网络分类器。结果表明，基于树的集成模型在准确性和鲁棒性之间提供了最优的权衡，证明了LiDAR提取的特征能够捕捉粗糙度引起的散射效应。此外，该框架能够生成散射感知的环境图和数字孪生模型，支持自适应波束管理、遮挡恢复和环境感知连通性。
### Conclusion
本文提出的方法通过机器学习和LiDAR数据，能够有效地分类室内表面，提高下一代无线网络的连通性和鲁棒性。这种散射感知的方法将对波束管理、遮挡恢复以及支持环境感知连通性具有重要意义。
## 487. `cs.LG` - 数据增强感知量化知识蒸馏 [PDF](https://arxiv.org/pdf/2509.03850), [HTML](https://arxiv.org/abs/2509.03850)
### Authors
Justin Kur,Kaiqi Zhao
### Background
量化感知训练（QAT）和知识蒸馏（KD）被结合使用，以实现低比特深度学习模型的竞争力。现有研究主要关注通过设计更佳的KD损失函数或优化QAT的前向和反向传播来提高量化模型的准确性。然而，输入变换如数据增强（DA）的影响未受到足够重视，特别是在量化感知KD与DA之间的关系尚未被充分探索的情况下。
### Innovation
论文提出了一种新的度量标准，该标准根据其能力最大化上下文互信息（与图像标签无关的信息）同时确保每个类别的预测接近真实标签的平均值，来评估和选择DA技术。该方法自动对DA进行排名和选择，且具有较低的训练开销，且适用于任何KD或QAT算法。实验结果表明，使用该度量选择DA策略能够显著提升现有QAT和KD的工作表现。
### Conclusion
研究表明，使用该度量选择DA策略可以显著提高QAT和KD在不同模型架构和数据集上的表现。
## 488. `cs.LG` - 基于多层感知机神经网络的肽组学冠心病预测模型 [PDF](https://arxiv.org/pdf/2509.03884), [HTML](https://arxiv.org/abs/2509.03884)
### Authors
Jesus Celis-Porras
### Background
冠心病是全球导致死亡的主要原因，对年度卫生保健开支有重大影响。为开发一种无创诊断手段，研究设计了一种基于多层感知机（MLP）的人工神经网络模型，该模型由50种通过遗传算法选定的关键尿液肽生物标志物训练而成。治疗组和对照组各有345人，使用合成少数类过采样技术（SMOTE）进行平衡，并用分层验证策略进行模型训练。
### Innovation
研究采用了一种基于肽组学的关键尿液肽生物标志物，结合遗传算法进行特征选择，然后使用多层感知机神经网络进行模型构建。模型使用了合成少数类过采样技术进行数据平衡，并通过分层验证策略进行训练。最终，模型在诊断冠心病方面表现出95.67%的精确性、95.65的F1分数、0.9748的AUROC、0.9134的MCC和0.9131的Kappa系数，表明其具有很高的准确性和鲁棒性，能够提供一种用于冠心病的高精度无创诊断工具。
### Conclusion
研究表明，开发的肽组学模型基于多层感知机的人工神经网络能够提供一种高精度的无创诊断工具来检测冠心病，具有较高的可靠性和准确性。
## 489. `cs.LG` - 对空间应用场景分类算法局部鲁棒性的形式验证 [PDF](https://arxiv.org/pdf/2509.03948), [HTML](https://arxiv.org/abs/2509.03948)
### Authors
Delphine Longuet,Amira Elouazzani,Alejandro Penacho Riveiros,Nicola Bastianello
### Background
卫星组件失效成本高且处理起来具有挑战性，通常需要大量的人力和物资资源。将基于混合AI的故障检测系统直接嵌入卫星中可以大大减轻这一负担，允许更早地进行检测。然而，此类系统必须具备极高的可靠性。为了确保这种可靠性，我们使用了形式验证工具Marabou来验证AI算法中所使用的神经网络模型的局部鲁棒性。该工具使得我们可以量化模型的输入可以被多少扰动，在输出行为变得不稳定之前，以便提高该算法在不确定性下的可信度。
### Innovation
引入了将基于混合AI的故障检测系统直接嵌入卫星中的方法，以降低故障检测过程的需求。通过使用形式验证工具Marabou来验证使用在AI算法中的神经网络模型的局部鲁棒性，该创新确保了系统的高可靠性，并提高了对算法执行可信度的评估。
### Conclusion
通过使用形式验证工具Marabou验证了卫星应用中的AI算法的局部鲁棒性，提高了系统的可靠性，增强了对在不确定条件下执行算法的信任度。
## 490. `cs.LG` - MillGNN：学习多尺度领先滞后依赖关系以进行多变量时间序列预测 [PDF](https://arxiv.org/pdf/2509.03852), [HTML](https://arxiv.org/abs/2509.03852)
### Authors
Binqing Wu,Zongjiang Shang,Jianlong Huang,Ling Chen
### Background
多变量时间序列（MTS）预测在多种应用中至关重要。现有的方法因其较强的能力来捕捉内变量和跨变量相关性而显示出有希望的结果。然而，这些方法往往忽略了多分组尺度上的领先滞后依赖性，未能捕捉到复杂系统中的分层领先滞后效应。
### Innovation
我们提出了MillGNN，一种新型的基于图神经网络的方法，用于学习多尺度分组的领先滞后依赖性，从而全面捕捉变量内部和组内动态和衰减带来的领先滞后效应。MillGNN包含两大创新点：（1）一种针对特定尺度的领先滞后图学习模块，该模块集成了实时输入和时间滞后中得出的交叉相关系数和动态衰减特征，用于学习每个尺度的领先滞后依赖性，可以模型随时间变化的领先滞后关系，具有统计解释性和数据驱动的灵活性；（2）一种分层的领先滞后消息传递模块，该模块以结构化的方式跨多个分组尺度传递领先滞后消息，同时传播内变量和跨变量的影响，能够用兼顾全面性与高效性的方法捕捉多尺度领先滞后效应。
### Conclusion
在11个数据集上的实验结果表明，与16种最先进的方法相比，MillGNN在长短期MTS预测中表现更优。
## 491. `cs.LG` - 将预测模型与临床经验学习对齐：一项前列腺癌案例研究 [PDF](https://arxiv.org/pdf/2509.04053), [HTML](https://arxiv.org/abs/2509.04053)
### Authors
Jacqueline J. Vallon,William Overman,Wanqiao Xu,Neil Panjwani,Xi Ling,Sushmita Vij,Hilary P. Bagshaw,John T. Leppert,Sumit Shah,Geoffrey Sonn,Sandy Srinivas,Erqi Pollom,Mark K. Buyyounouski,Mohsen Bayati
### Background
过去十年里，机器学习(ML)模型在医疗应用中的使用大幅增加。尽管这些模型表现出色，但它们通常未能捕捉到最终用户所需的模式。例如，模型在固定其他特征的情况下可能预测癌症阶段与生存率之间的非单调递减关系。本文介绍了一个可重复的框架，用于探索模型行为与临床经验学习之间的不一致之处，重点关注现代ML管道的不完全界定对这种不一致的影响。通过一个前列腺癌结果预测案例研究，作者首先通过将通过调查收集到的临床知识作为约束条件纳入到ML模型中，识别并解决了这些不一致之处，并分析了不完全界定程度对模型性能和行为的影响。
### Innovation
作者提出了一种可重复的框架，用于通过将临床知识作为约束条件纳入到ML模型中，识别并解决模型行为与临床经验学习间不一致的问题，并进一步通过随机临床试验探讨了反馈驱动的对齐方法在非生成性AI临床风险预测模型中的可行性。
### Conclusion
通过使用作者提出的推理方法促使临床医生表达自己的偏好，可以实现模型与临床经验学习的对齐，而不会损害性能。而使用具有约束条件的模型与未约束条件的模型对患者进行预测时，临床解释上的差异越大，这种差异越明显。
## 492. `cs.LG` - 运算限制下的错误限定在线学习 [PDF](https://arxiv.org/pdf/2509.03892), [HTML](https://arxiv.org/abs/2509.03892)
### Authors
Jesse Geneson,Meien Li,Linus Tang
### Background
该研究探讨了在线学习中的错误限定模型，并特别考虑了每轮操作的运算次数上限。这一研究背景基于既有的对在线学习中错误学习的理论研究，特别是在有限错误次数下的学习效果和运算需求分析。之前的文献（Filmus et al, 2024 和 Geneson & Tang, 2024）针对带资讯差分反馈的错误限定在线学习问题进行了深入探讨，但本文扩展了这一结果，引入了操作限制的概念，旨在更精准地评估在线学习中的实际运算开销。
### Innovation
该研究的主要创新点在于引入了‘运算限制’的概念，制定了更为严格的操作限制条件，从而在保证学习性能的同时，极大地优化了运算效率。此外，该研究解决了带资讯差分反馈下的错误限定在线学习问题，并成功地将其结果扩展到了运算限制的设定中，为在线学习中的资源优化提供了新的理论依据。
### Conclusion
通过引入运算限制，本研究为在线学习模型的错误限制学习提供了一种新的评估方法。论文证明了在给定运算次数上限的情况下，学习任意有限错误的函数族所需的最小运算次数的理论下界。该结论不仅丰富了在线学习的理论基础，也为实际应用中处理大规模数据的在线学习算法设计提供了重要的理论指导。
## 493. `cs.LG` - 使用合成反事实标签以提高效率的规约反事实推理 [PDF](https://arxiv.org/pdf/2509.04112), [HTML](https://arxiv.org/abs/2509.04112)
### Authors
Amirmohammad Farzaneh,Matteo Zecchin,Osvaldo Simeone
### Background
现有的规约反事实推理（CCI）方法虽然提供了边际覆盖率的保证，但在处理不平衡时，生成的预测区间往往过于保守，尤其是在反事实样本稀缺的情况下。
### Innovation
提出了合成数据驱动的CCI（SP-CCI）框架，该框架通过预训练的反事实模型生成合成反事实标签，并将其与基于风险控制预测集（RCPS）的校准过程结合，同时引入去偏见步骤，该步骤由预测驱动推理（PPI）指导。理论证明SP-CCI在保持边际覆盖率的同时，实现了更窄的预测区间，且在精确重要加权和近似重要加权下均有保证。
### Conclusion
SP-CCI在不同数据集上的一系列实证结果显示，与标准CCI方法相比，无论在何种设置下，其预测区间宽度均有显著减小。
## 494. `cs.LG` - 谁为公平买单？重新思考在社会负担下的救济 [PDF](https://arxiv.org/pdf/2509.04128), [HTML](https://arxiv.org/abs/2509.04128)
### Authors
Ainhize Barrainkua,Giovanni De Toni,Jose Antonio Lozano,Novi Quadrianto
### Background
机器学习预测模型在敏感决策领域（直接影响生活）中的应用越来越广泛，这推动了确保分类器公平性的研究。尽管如此，在救济过程中仍存在公平性保障的问题。新兴的立法要求，在分类器做出不利决定时，还应向个人提供可行的行动方案来改变结果，这即是算法救济的概念。然而，许多研究者担心救济过程中的公平性保障问题。在此背景下，本文对算法救济过程中的不公平性进行了一次全面的理论分析，探讨了救济过程与分类过程之间公平性的正式关联，以及解释了标准等成本范式的局限性。
### Innovation
本文提出了一种基于社会负担的新公平框架，并提供了一个名为MISOB的实际算法，该算法适用于现实世界的多种情况。实证结果表明，MISOB可以在不牺牲整体分类器准确性的前提下，减少所有群体的社会负担。
### Conclusion
本文通过对算法救济过程中的不公平性进行了分析研究，引入了基于社会负担的新公平框架，并通过MISOB算法在实际数据集上的实验验证了其有效性和实用性。
## 495. `cs.LG` - TAGAL: 使用代理大语言模型方法生成表数据 [PDF](https://arxiv.org/pdf/2509.04152), [HTML](https://arxiv.org/abs/2509.04152)
### Authors
Benoît Ronval,Pierre Dupont,Siegfried Nijssen
### Background
数据生成是提高机器学习任务性能的常见方法，特别是在模型训练分类上。本文介绍了TAGAL，一种使用代理工作流程生成合成表数据的方法集合。这些方法利用大语言模型（LLMs）实现自动和迭代的过程，该过程通过反馈改进生成的数据，而无需进一步的LLM训练。大语言模型还可让生成过程中加入外部知识。
### Innovation
本文主要创新点在于提出了一种名为TAGAL的方法，该方法通过利用大语言模型（LLMs）实现自动和迭代的数据生成过程，无需进一步的LLM训练，并能够添加外部知识以改进生成数据的质量。此外，该方法在不同的数据集上进行评估，比较了合成数据和真实数据之间的相似性，并展示了其在与现有的依赖LLM训练的方法相比的竞争力。
### Conclusion
实验结果显示，TAGAL不仅与需要LLM训练的最先进的方法性能相当，而且在不需要训练的情况下，通常会优于其他方法。这些结果突显了代理工作流程的潜力，并为基于LLM的数据生成方法开辟了新的方向。
## 496. `cs.LG` - 跨越物种的界限：从语音到动物声音的迁移学习 [PDF](https://arxiv.org/pdf/2509.04166), [HTML](https://arxiv.org/abs/2509.04166)
### Authors
Jules Cauzinille,Marius Miron,Olivier Pietquin,Masato Hagiwara,Ricard Marxer,Arnaud Rey,Benoit Favre
### Background
自监督的语音模型在语音处理中表现出色，但在非语音数据上的效果尚未得到充分探索。本文研究了此类模型在生物声学检测和分类任务中的迁移学习能力。
### Innovation
研究了HuBERT、WavLM和XEUS等模型生成动物声音跨物种的丰富潜在表示，并通过线性探针分析模型属性，进而扩展方法以包含时间信息的影响，探讨了频率范围和噪声对性能的影响。结果显示，这些模型在竞标生物声学预训练模型中的表现具有竞争力，并展示了噪声鲁棒预训练设置的影响。
### Conclusion
该研究突显了基于语音的自监督学习作为促进生物声学研究高效框架的潜力。
## 497. `cs.LG` - FedQuad: 联邦随机四元组学习以减轻数据异质性 [PDF](https://arxiv.org/pdf/2509.04107), [HTML](https://arxiv.org/abs/2509.04107)
### Authors
Ozgu Goksu,Nicolas Pugeault
### Background
联邦学习（FL）提供了一种去中心化的模型训练方式，有效解决了分布式数据和隐私保护等问题。然而，全局模型的一般化常常会面临来自客户端之间数据异质性的挑战。当数据集较小且类别不平衡时，这一挑战尤为突出。要应对数据异质性，本文提出了一种名为FedQuad的新型方法，该方法明确优化了小类内的方差和大类间的方差，从而减少模型聚合对客户端表示的全球模型的负面影响。FedQuad方法通过最小化相似样本对之间的距离同时最大化负样本对之间的距离，有效地在共享特征空间中拆分客户端数据。我们在CIFAR-10和CIFAR-100数据集上进行了各种数据分布和多个客户端的评估，表明该方法在现有的方法中表现出更优的性能。此外，我们对基于度量学习的策略在监督式学习和联邦学习环境中的策略进行了详细的分析，展示了它们在联邦环境中解决表示学习问题的有效性.
### Innovation
本文提出了名为FedQuad的新方法，这种方法明确优化了小类内的方差和大类间的方差，从而减少模型聚合对客户端表示的全球模型的负面影响。通过最小化相似样本对之间的距离同时最大化负样本对之间的距离，有效地在共享特征空间中拆分客户端数据，从而提高数据异质性环境下的模型性能。
### Conclusion
我们在CIFAR-10和CIFAR-100数据集上进行了评估，表明FedQuad在数据异质性场景中的表现优于现有的方法。此外，我们还分析了度量学习策略在监督式学习和联邦学习环境中的应用，展示了它们在联邦学习中的有效性。
## 498. `cs.LG` - 注意力作为一种自适应滤波器 [PDF](https://arxiv.org/pdf/2509.04154), [HTML](https://arxiv.org/abs/2509.04154)
### Authors
Peter Racioppo
### Background
本文介绍了一种新颖的注意力机制——自适应滤波器注意力(AFA)，该机制直接将可学习的动力学模型集成到注意力权值的计算中。传统的注意力机制是直接比较查询项和键项，而本文通过将输入序列建模为线性随机微分方程(SDE)的离散观测，引入了新的计算方法。这种方法允许使用微分赖托诺夫方程的封闭解来高效地传播成对的不确定性。
### Innovation
通过将线性动力学模型和同时对角化的状态矩阵及噪声协方差引入其中，文章提出了一种新的注意力机制，这种方法利用微分赖托诺夫方程的封闭解高效传播成对不确定性。这种方法自然地促进了基于残差的可重写的最大似然解，最终注意力权重对应于传播的成对精度的重加权。此外，通过对状态矩阵特征值施加额外约束，简化了该模型，使其与标准注意力机制具有相同的计算和内存复杂度。在动力学和过程噪声趋于零的极限下，并使用小角度近似，可以恢复普通的点积注意力机制。
### Conclusion
通过施加额外的约束，本文提供了一个简化版本的注意力机制，该机制与标准注意力机制具有相同的计算和内存复杂度。在某些条件下，这种方法可以恢复普通的点积注意力机制。
## 499. `cs.LG` - Set Block Decoding 是一种语言模型推理加速器 [PDF](https://arxiv.org/pdf/2509.04185), [HTML](https://arxiv.org/abs/2509.04185)
### Authors
Itai Gat,Heli Ben-Hamu,Marton Havasi,Daniel Haziza,Jeremy Reizenstein,Gabriel Synnaeve,David Lopez-Paz,Brian Karrer,Yaron Lipman
### Background
自回归下一个标记预测语言模型具有强大的功能，但在实际部署中也面临着显著的挑战，尤其是在推理阶段由于高计算和内存成本，尤其是在解码阶段。
### Innovation
介绍了Set Block Decoding（SBD），这是一种简单灵活的方法，通过将标准下一个标记预测（NTP）和掩码标记预测（MATP）结合在一个架构中来加速生成过程。SBD允许模型同时并行采样多个未来的标记，尤其是不一定连续的，这是与先前的加速方法的主要区别。这种方法灵活性地结合了离散扩散文献中的高级解算器，能够在不牺牲准确性的前提下提供显著的速度提升。SBD不需要架构上的改变或额外的训练超参数，可与精确的KV缓存保持兼容，并可以通过微调现有的下一个标记预测模型来实现。
### Conclusion
通过微调Llama-3.1 8B和Qwen-3 8B模型，证明了SBD可以将生成所需的前向传递次数减少3-5倍，同时保持与同等NTP训练相同的效果。
## 500. `cs.LG` - 评论“图神经网络的过光滑化问题的注记” [PDF](https://arxiv.org/pdf/2509.04178), [HTML](https://arxiv.org/abs/2509.04178)
### Authors
Razi Hasson,Reuven Guetta
### Background
本文主要评论了Cai和Wang（2020，arXiv:2006.13318）关于通过狄利克雷能量分析图神经网络（GNNs）中过度光滑化的工作。背景在于，GNNs在深度增加时可能遇到过度光滑化问题，这会影响模型的性能和泛化能力。本文研究狄利克雷能量如何随深度增加而变化，并将其应用于GNNs中的谱多项式滤波器，进一步探讨了Leaky-ReLU的情况。
### Innovation
文章在温和的谱条件下证明了节点嵌入的狄利克雷能量随着深度的增加呈指数减少，并将结果扩展到了谱多项式滤波器，并为Leaky-ReLU情形提供了简短的证明。此外，通过边缘删除和权重放大实验，文章表明狄利克雷能量增加时的情况，并提供了缓解过度光滑化的实用方法。
### Conclusion
研究表明，狄利克雷能量随深度增加的减少趋势可以在一定程度上解决GNNs中的过度光滑化问题，通过实验验证了理论分析的有效性，并为实际应用提供了新的见解。
## 501. `cs.LG` - 时间序列预测中的隐私风险：用户级和记录级成员推理 [PDF](https://arxiv.org/pdf/2509.04169), [HTML](https://arxiv.org/abs/2509.04169)
### Authors
Nicolas Johansson(1),Tobias Olsson(1),Daniel Nilsson(2),Johan Östman(2),Fazeleh Hoseini(2) ((1) Chalmers University of Technology, (2) AI Sweden)
### Background
成员推理攻击（MIAs）旨在确定特定数据是否被用于训练模型。尽管这类攻击在分类模型中被广泛研究，但它们对时间序列预测模型的影响仍然未被充分探索。本文填补了这一空白，通过引入两种新的攻击方法来研究这个问题，从而解决了时间序列预测模型中的隐私风险问题。
### Innovation
本文提出了两种创新的攻击方法：一是将最新最先进的多变量LiRA攻击（一种用于分类模型的MIAs）进行适应，使其能够用于时间序列预测场景；二是开发了一种全新的端到端学习方法，称为深度时间序列（DTS）攻击。此外，还对这些方法进行了基准测试，与来自分类设置的其他领先攻击版本进行对比。实验结果显示，时间序列预测模型存在严重的隐私风险，在用户级攻击中，常能达到完美的检测效果。
### Conclusion
本文的方法在多个场景中表现最强，为时间序列预测中的隐私风险评估提供了新的基准。此外，预测时间越长和训练样本越少时，模型的脆弱性会增加，这一趋势与大型语言模型中的观察结果相符。
## 502. `cs.LG` - One-Embedding-Fits-All：一种有效的模型动物园实现零样本时间序列预测 [PDF](https://arxiv.org/pdf/2509.04208), [HTML](https://arxiv.org/abs/2509.04208)
### Authors
Hao-Nan Shi,Ting-Ji Huang,Lu Han,De-Chuan Zhan,Han-Jia Ye
### Background
时间序列基础模型（TSFMs）的普及极大地推动了零样本预测的进展，使得可以对未见过的时间序列进行预测，而无需针对特定任务进行微调。然而，现有研究显示，没有一种TSFM适用于所有情况，不同的模型在处理不同的时间模式上有各自的偏好。这种多样性表明，我们可以利用TSFMs之间的互补能力。为此，本文提出了一种名为ZooCast的方法，用于刻画每个模型独特的预测优势，并能够智能地将当前的TSFMs组合成一个动态选择最佳模型以适应不同预测任务的模型动物园。
### Innovation
本文的关键创新在于提出了一种One-Embedding-Fits-All范式，构建了一个统一的表示空间，其中每个动物园中的模型都用一个嵌入表示，这使得所有任务的相似性匹配变得高效。实验结果显示，ZooCast在GIFT-Eval零样本预测基准上表现出色，同时保持了单个TSFM的效率。在现实场景中，随着模型的依次发布，该框架能够无缝地添加新模型，从而实现逐步提高的准确性，而不会产生明显的开销。
### Conclusion
本文通过ZooCast提出了一种新的方法，该方法能够智能地将不同TSFMs组合成一个动态选择最佳模型的模型动物园，从而有效地实现零样本时间序列预测，并在实际场景中保持高效率和逐步提高的准确性。
## 503. `cs.LG` - 重新审视Mamba/SSM和Transformer模型中的长程依赖性 [PDF](https://arxiv.org/pdf/2509.04226), [HTML](https://arxiv.org/abs/2509.04226)
### Authors
Cong Ma,Kayvan Najarian
### Background
近年来，状态空间模型（特别是Mamba）和Transformer模型因其对长程依赖性的需求而被广泛关注。虽然正在积极研发和测试新的模型架构，用于需要长程依赖性的预测任务，但这些模型的长程依赖性建模能力尚未从理论角度进行研究，这限制了在这方面的系统性改进。
### Innovation
本文通过对隐藏状态关于过往输入的导数定义长程依赖性，比较了Mamba/SSM和Transformer模型在长程依赖性建模上的能力。研究表明，Mamba/SSM的长程依赖性随序列长度呈指数衰减，而Transformer的注意力机制更灵活，理论上在充足的数据、计算资源和适当训练的情况下，能够更好地建模长程依赖性。为了结合注意力机制的长程依赖性灵活性和Mamba/SSM的计算效率，本文提出了一种新的隐藏状态更新公式，并证明其在输入数据呈标准高斯分布的情况下具有稳定性。
### Conclusion
Mamba/SSM的长程依赖性随序列长度呈指数衰减，与RNN中的记忆函数衰减一致。而Transformer使用注意力机制更灵活，理论上在充足的数据和计算资源条件下能够更好地建模长程依赖性。本文提出了一种新的隐藏状态更新公式，以结合注意力机制的灵活性和Mamba/SSM的计算效率，并证明了其在标准高斯分布输入下的稳定性。
## 504. `cs.LG` - 为什么我的聚类看不到？基于精确度召回率的降维验证方法 [PDF](https://arxiv.org/pdf/2509.04222), [HTML](https://arxiv.org/abs/2509.04222)
### Authors
Diede P. M. van der Hoorn,Alessio Arleo,Fernando V. Paulovich
### Background
降维(DR)广泛用于可视化高维数据，通常目的是揭示潜在的集群结构。然而，在投影过程中，这种结构可能不会显现。现有的降维质量度量可以评估投影的可靠性或聚类结构的质量，但无法解释为何预期的结构无法显现。现有视觉分析解决方案能够帮助，但往往因超参数空间庞大而耗时。该论文通过利用最近一个框架解决了这一问题，该框架将降维过程分为两个阶段：关系阶段，用于建模相似关系；映射阶段，将数据投影到适当的维度。作者引入了精度和召回率两种监督度量，以评估关系阶段的效果。这些度量可以衡量基于某些标签所期望的集群结构中，建模的关系的一致性程度。
### Innovation
提出了两种基于监督的精度和召回率度量来评估降维过程中关系建模阶段的效果，可以量化所建模关系与基于某些标签表示的期望集群结构的一致性程度。通过t-SNE和UMAP的应用实例展示了方法的有效性，并通过多种使用场景验证了方法的可行性，能够引导超参数调优、发现投影中的异常，并确定期望结构是否在关系中被捕捉，使降维过程更加高效和可靠。
### Conclusion
该方法可以加速降维过程并提高其可靠性。通过精确和召回率度量的引入，能够在关系建模阶段精确评估期望的聚类结构是否被捕捉到，从而优化超参数选择和减少投影中的错误。
## 505. `cs.LG` - 使用深度生成模型为心脏衰竭预后生成合成生存数据 [PDF](https://arxiv.org/pdf/2509.04245), [HTML](https://arxiv.org/abs/2509.04245)
### Authors
Chanon Puttanawarut,Natcha Fongsrisin,Porntep Amornritvanich,Cholatid Ratanatharathorn,Panu Looareesuwan
### Background
心脏衰竭（HF）研究受限于由于隐私法规和机构壁垒导致的大规模可共享数据集的获取有限。合成数据生成为克服这些挑战提供了一种有希望的解决方案，同时保护患者隐私。
### Innovation
该研究使用五种深度学习模型（表型变分自编码器、归一化流、ADSGAN、生存GAN和表型去噪扩散概率模型）生成心脏病发作数据集，并通过统计相似性度量、生存预测评估和隐私评估来全面评估合成数据的效用。结果表明SurvivalGAN和TabDDPM具有高保真度，生存预测和隐私评估结果良好。
### Conclusion
基于深度学习的合成数据生成可以生成高保真度、隐私保护的心脏衰竭数据集，适用于研究应用。此公开可用的合成数据集解决了重要数据共享障碍，并为心脏衰竭研究和预测建模提供了有价值的资源。
## 506. `cs.LG` - 重新思考逐层高斯噪声注入：连接隐式优化目标和隐私预算分配 [PDF](https://arxiv.org/pdf/2509.04232), [HTML](https://arxiv.org/abs/2509.04232)
### Authors
Qifeng Tan,Shusen Yang,Xuebin Ren,Yikai Zhang(Xi'an Jiaotong University)
### Background
现有的逐层高斯机制(LGM)通过向分区的梯度向量中注入噪声来增强差异化隐私下的深度学习灵活性。然而，现有方法往往依赖于启发式噪声分配策略，缺乏对噪声分配与其形式化的隐私-效用权衡之间理论联系的严谨理解。
### Innovation
本文提出了一种统一的分析框架，系统地将逐层噪声注入策略与其隐含的优化目标和相应的隐私预算分配联系起来。分析发现，一些现有方法优化的是欠定义的目标，或是忽略了层间信噪比(SNR)的一致性，或是导致了隐私预算的低效使用。针对这一问题，提出了信噪比一致的噪声分配策略，该策略统一了上述两方面，从而实现更好的信号保存和更有效的隐私预算使用。通过在中心化和联邦学习场景下的广泛实验，证明与现有分配策略相比，本方法在隐私-效用权衡中表现出更优的效果。该框架不仅提供了对现有方法诊断性的洞见，还为设计深度模型中的自适应和有效的噪声注入方案提供了理论指导。
### Conclusion
本文的方法在全局上优于现有的噪声分配策略，取得了更好的隐私-效用权衡效果。提供的分析框架对于理解和设计有效噪声注入策略具有宝贵的理论价值。
## 507. `cs.LG` - Topotein：基于拓扑深度学习的蛋白质表示学习 [PDF](https://arxiv.org/pdf/2509.03885), [HTML](https://arxiv.org/abs/2509.03885)
### Authors
Zhiyu Wang,Arian Jamasb,Mustafa Hajij,Alex Morehead,Luke Braithwaite,Pietro Liò
### Background
蛋白质结构功能关系的理解对于生物学研究至关重要，然而当前基于序列和图的方法无法捕捉蛋白质结构中的层次组织。现有方法在捕捉多尺度结构模式方面存在不足，Topotein通过引入新型的蛋白质组合复合物（PCC）和拓扑完备感知器网络（TCPNet），应用拓扑深度学习来克服这一挑战，提供了多层次的蛋白质表示，同时保留几何信息，以更好地理解蛋白质结构中的层次组织。
### Innovation
Topotein引入了蛋白质组合复合物（PCC）和拓扑完备感知器网络（TCPNet），通过SE(3)-等变消息传递在多级结构之间进行有效信息传递，从而更准确地捕捉多尺度结构模式。该方法在四个蛋白质表示学习任务上比现有的几何图神经网络表现出更优的效果，特别是在需要理解二级结构排列的折叠分类任务上验证了层次拓扑特征的重要性。
### Conclusion
Topotein方法证明了在蛋白质分析中层次拓扑特征的重要性，通过结合多层次的蛋白质表示和拓扑学习机制，显著提升了蛋白质表示学习任务中的性能。
## 508. `cs.CV` - Cryo-EM 图像是固有低维度的 [PDF](https://arxiv.org/pdf/2504.11249), [HTML](https://arxiv.org/abs/2504.11249)
### Authors
Luke Evans,Octavian-Vlad Murad,Lars Dingeldein,Pilar Cossio,Roberto Covino,Marina Meila
### Background
冷冻电子显微镜（Cryo-EM）通过神经网络等方法（如CryoSBi）进行模拟推理，以推断生物分子的构象。这些方法依赖于学习到的潜在表示空间，该空间包含关于物理系统和推理过程的重要信息。然而，理解这些潜在表示的空间几何结构对于充分利用其潜在价值至关重要。
### Innovation
本文通过应用流形学习技术来研究CryoSBI表示的血凝素数据（模拟和实验数据），发现这些高维数据实际上填充了低维、平滑的流形，模拟数据在覆盖实验数据方面表现出色。通过使用扩散映射来表征流形的几何结构，以及通过坐标解释方法识别出主要变化轴，建立了潜在结构与关键物理参数之间的直接联系。这一发现不仅验证了CryoSBI方法的有效性，还为通过这个揭示出的流形几何结构来改进未来的推断策略提供了可能。
### Conclusion
本文发现，Cryo-EM 图像具有固有低维度特性，这种固有的低维度和可解释的几何组织不仅验证了CryoSBI方法的有效性，还为从数据结构中获得更多信息提供了机会，同时也为未来提高了推理策略利用这些揭示出的流形几何结构提供了可能性。
## 509. `cs.LG` - 因果和统计数据集偏差 primer：实现公平和稳健图像分析 [PDF](https://arxiv.org/pdf/2509.04295), [HTML](https://arxiv.org/abs/2509.04295)
### Authors
Charles Jones,Ben Glocker
### Background
机器学习方法在实际应用中经常失效，尤其在高风险情境和社会敏感领域。这些问题在某些医疗诊断等场景下特别严重，限制了机器学习的广泛应用。本文介绍了导致机器学习图像分析方法失败的因果和统计结构原因。
### Innovation
本文首次提出了两个以前未被注意到的问题，被称为“无公义午餐”问题和“子群体可分性”问题。同时，指出目前的公平表示学习方法未能有效解决这些问题，并提出了未来研究方向。
### Conclusion
为了实现机器学习在图像分析中的公平性和鲁棒性，需要更深入地理解并解决这些问题。
## 510. `cs.LG` - RL的修剃刀原理：在线强化学习为何遗忘更少 [PDF](https://arxiv.org/pdf/2509.04259), [HTML](https://arxiv.org/abs/2509.04259)
### Authors
Idan Shenfeld,Jyothish Pari,Pulkit Agrawal
### Background
在将预训练模型应用于新任务时，微调模型的方法包括强化学习(RL)微调和监督微调(SFT)，这两种方法在新任务上的表现相似，但RL在保留模型的先前知识和能力方面表现出色。研究者的分析表明，遗忘的程度可以通过新任务下微调模型与基础模型的KL散度来量化，揭示了RL和SFT在任务解决方式上的差异。
### Innovation
研究发现了RL和SFT之间的关键区别：RL微调在解决新任务时倾向于最小化KL散度，即KL-minimal解，而SFT可以导致与基础模型差异极大的分布收敛。进一步的理论分析证明了基于策略的在线RL更新会导致更小的KL变化，并提出了“RL的修剃刀原理”这一概念，即在所有可行的新任务解决方案中，RL偏爱与原模型KL距离最小的那些。
### Conclusion
研究通过对大规模语言模型和机器人基础模型的实验验证了这些发现，并为基于策略的在线RL更新导致KL变化较小提供了理论解释。这一发现强调了RL方法在保留模型先前知识和能力方面的优势。
## 511. `cs.LG` - 非住宅建筑的能源行为特征建模 [PDF](https://arxiv.org/pdf/2509.04322), [HTML](https://arxiv.org/abs/2509.04322)
### Authors
Haley Dozier,Althea Henslee
### Background
由于气候变化和极端天气事件的威胁，美国陆军设施面临风险。为保护支持关键任务的设施资产并提高战备水平，需要采取气候韧性措施。大多数美国陆军本土设施依赖商业能源和水资源，因此需要确定独立能源资源（如电力网、天然气管道等）的脆弱性，并理解设施内的能源使用情况。本文提出基于数据的行为模型，以确定设施能源使用的行为特征，这将用于1）评估意外中断对能源系统的影响基线，2）未来韧性措施的基准。
### Innovation
本文创新地提出了一种基于数据的行为模型，用于刻画非住宅建筑的能源使用行为特征。该模型能够准确分析、预测和聚类非住宅建筑能源使用数据。此外，由于陆军设施能源使用数据的特性，本文使用了结构相似的开放获取数据来展示该方法。
### Conclusion
通过提出的基于数据的行为模型，可以构建能源使用行为特征，有助于评估意外中断对能源系统的影响并建立未来韧性措施的基准。这种方法为提高陆军设施的能源韧性提供了新的视角和手段。
## 512. `cs.LG` - 利用因果抽象加速复杂赏金问题中的决策 [PDF](https://arxiv.org/pdf/2509.04296), [HTML](https://arxiv.org/abs/2509.04296)
### Authors
Joel Dyer,Nicholas Bishop,Anisoara Calinescu,Michael Wooldridge,Fabio Massimo Zennaro
### Background
现实世界中的决策问题通常可以被编码为在不同抽象层次上的因果多臂赌博机（CMAB）问题，但目前缺乏一种利用每个抽象层次信息和计算优势的通用方法。因此，本文提出了AT-UCB算法，该算法能够有效地利用不同抽象层次上定义的CMAB问题实例之间的共享信息，从而显著减少累计后悔值。
### Innovation
AT-UCB算法结合了因果抽象（CA）理论，能够在低成本模拟和粗粒度的CMAB实例中标记潜在操作，然后在目标CMAB实例中使用传统的上置信界（UCB）算法，从而显著减少累积后悔值，相较于传统的UCB算法有着显著的优势。
### Conclusion
通过理论上的新边界和在流行病学模拟器上的实验结果，展示了AT-UCB算法在加速复杂赏金问题中决策过程方面的优越性。
## 513. `cs.LG` - 从莱茵德到快乐岛：常数波兹模型为社区检测的享乐游戏 [PDF](https://arxiv.org/pdf/2509.03834), [HTML](https://arxiv.org/abs/2509.03834)
### Authors
Lucas Lopes Felipe,Konstantin Avrachenkov,Daniel Sadoc Menasche
### Background
社区检测是数据科学中的基础问题之一，涉及将节点划分为不相交的社群。文章从博弈论的角度探讨了常数波兹模型（CPM）在划分网络社群中的应用，并强调了其高效性、稳健性和准确性。
### Innovation
1. 将CPM重新解释为潜力享乐博弈，通过分解其全局哈密顿量为局部效用函数，证明了局部优化CPM目标可以通过更好的反应动态收敛到均衡分区，时间复杂性为准多项式时间。2. 引入并关联了两种稳定性标准：基于新稳健性概念的严格标准和基于权重和目标的松弛效用函数标准，通过分辨率参数控制。3. 在社区跟踪场景中，通过实验证明了稳健性更优的分区在使用初始分区初始化莱茵德算法及部分事实信息时，能获得更高的准确度。
### Conclusion
文章实验结果表明，利用CPM及其稳定性标准进行社区划分能比初始分区启动的莱茵德算法更准确地恢复地面真实社群。
## 514. `cs.LG` - 交互式框架在发现差分隐私的最优权衡方面 [PDF](https://arxiv.org/pdf/2509.04290), [HTML](https://arxiv.org/abs/2509.04290)
### Authors
Yaohong Yang,Aki Rehn,Sammie Katt,Antti Honkela,Samuel Kaski
### Background
差分隐私(DP)是隐私保护分析的标准，它在隐私保证和模型性能之间引入了基本的权衡。如何选择最佳平衡是一个关键挑战，可以看作一个多目标优化(MOO)问题，即首先发现最优权衡集(帕累托前沿)，然后学习决策者的偏好。现有的大量交互式MOO工作往往采用传统的建模方法，即使用通用替代目标函数和从简单的成对反馈中学习偏好。但是，这在差分隐私问题中效率低下，因为它无法利用该问题的独特结构。通过直接最大化固定隐私级别下的准确性生成帕累托前沿中的一点。
### Innovation
作者提出了一个交互式的框架，能够直接并高效地建模帕累托前沿。为了解决偏好学习的低效率问题，作者引入了一种更有效的交互方式，即向用户展示假设的权衡曲线，让用户选择自己的偏好。这种方法在不同的实际数据集上实现了比基线方法更优的结果，并且在计算成本和用户互动上节省了大量资源。
### Conclusion
作者提出的交互式框架能够在不同情况下直接高效地找到差分隐私的最优权衡，并通过减少计算成本和用户交互实现了显著的效果提升。
## 515. `cs.LG` - PagedEviction：针对高效大语言模型推理的结构化块级KV缓存剪枝策略 [PDF](https://arxiv.org/pdf/2509.04377), [HTML](https://arxiv.org/abs/2509.04377)
### Authors
Krishna Teja Chitty-Venkata,Jie Ye,Xian-He Sun,Anthony Kougkas,Murali Emani,Venkatram Vishwanath,Bogdan Nicolae
### Background
KV缓存通过存储之前处理过的标记的注意力状态显著提升了大语言模型（LLM）推理的效率，从而加快了后续标记的生成。然而，随着序列长度的增加，KV缓存很快成为主要的内存瓶颈。
### Innovation
我们提出了PagedEviction，一种新颖的细粒度、结构化的KV缓存剪枝策略，增强vLLM的PagedAttention的内存效率。PagedEviction采用了一种有效的块级清算法，针对页式内存布局进行了优化，不同于现有依赖于注意力机制标记重要性或跨不同vLLM页面清除标记的方法。
### Conclusion
我们在Llama-3.1-8B-Instruct，Llama-3.2-1B-Instruct和Llama-3.2-3B-Instruct模型上通过LongBench基准套件评估了PagedEviction，结果表明相比于基线，在长上下文任务中内存使用有所改善且准确率更高。
## 516. `cs.LG` - 通过利用新颖的方差偏差权衡避免不可解的关联 aleatoric 不确定性，当进行三次实验比两次实验更好 [PDF](https://arxiv.org/pdf/2509.04363), [HTML](https://arxiv.org/abs/2509.04363)
### Authors
Paul Scherer,Andreas Kirsch,Jake P. Taylor-King
### Background
实境实验场景中存在异方差的 aleatoric 不确定性，并且这种不确定性在批次设置中可以是相关联的。模型的偏差-方差权衡可以被用来表达模型分布和真实随机变量之间的期望均方误差为可表的不确定度、偏差平方及 aleatoric 不确定度三者的和。
### Innovation
本文提出了一种新的主动学习策略，直接减少了实验轮次之间的偏差。当使用 cobias–covariance 关系时，以二次方式利用历史数据，提出了通过特征值分解策略自然提出的批次处理机制。当采用基于差值且利用 cobias–covariance 关系的方法在批量设置中运行时（配备二次估计器），我们超越了包括 BALD 和 Least Confidence 在内的多种经典方法。
### Conclusion
通过直接减少实验轮次之间的偏差，本文提出的方法在处理相关联的 aleatoric 不确定性时表现更优。特别是在批量设置中使用基于 cobias–covariance 的方法，显示出比现有方法更优越的效果。
## 517. `cs.LG` - 过渡模型：重新思考生成学习目标 [PDF](https://arxiv.org/pdf/2509.04394), [HTML](https://arxiv.org/abs/2509.04394)
### Authors
Zidong Wang,Yiyuan Zhang,Xiaoyu Yue,Xiangyu Yue,Yangguang Li,Wanli Ouyang,Lei Bai
### Background
生成建模中的基本困境持续存在：迭代扩散模型能够取得卓越的保真度，但需要巨大的计算成本；而高效的多步替代方案则受限于严格的质量上限。这种生成步骤和输出质量之间的矛盾源自专注于无穷小动态或直接端点预测的有限训练目标。
### Innovation
引入了一个精确的连续时间动力学方程，该方程通过自动生成状态转换函数来跨越任意时间段。这一创新提出了一种新颖的生成范式——过渡模型（TiM），能够适应任意步数转换，无缝跨越从单一跳跃到细粒度改进的整个生成轨迹。
### Conclusion
尽管只有865M个参数，TiM在所有评估的样本预算下均实现了最先进的性能，超越了如SD3.5（8B参数）和FLUX.1（12B参数）等领先模型。此外，TiM在采样预算增加时显示出单调的质量改进，并且在使用原生分辨率策略时，在4096x4096的分辨率下，在所有领域均能提供卓越的保真度。
## 518. `cs.LG` - 向着大型语言模型后训练统一视角 [PDF](https://arxiv.org/pdf/2509.04419), [HTML](https://arxiv.org/abs/2509.04419)
### Authors
Xingtai Lv,Yuxin Zuo,Youbang Sun,Hongyi Liu,Yuntian Wei,Zhekai Chen,Lixuan He,Xuekai Zhu,Kaiyan Zhang,Bingning Wang,Ning Ding,Bowen Zhou
### Background
当前大型语言模型的训练数据来源主要有两种：在线数据（模型生成的演示）和离线数据（人类或模型演示）。通常，这些数据分别用于强化学习（RL）和监督微调（SFT）方法。然而，这两种方法之间的关系并未得到充分认识，论文提出两者不是相互矛盾的，而是统一优化过程的不同表现形式。
### Innovation
论文推导出一个统一的策略梯度估计器，并展示了多种后训练方法在不同数据分布假设下的梯度为共同目标函数的梯度。提出了一个名为Hybrid Post-Training（HPT）的新算法，该算法可以根据所需动态选择不同的训练信号，有效利用演示数据、实现稳定探索，并保留学习的推理模式。
### Conclusion
HPT算法在六个数学推理基准测试和两个异常分布套件中，表现出色，能够战胜各种规模和类型的多种强基线模型。论文通过广泛的实验和消融研究验证了统一理论框架和HPT算法的有效性。
## 519. `cs.LG` - 在混合观测数据中适应性异质因果结构学习的可解释聚类 [PDF](https://arxiv.org/pdf/2509.04415), [HTML](https://arxiv.org/abs/2509.04415)
### Authors
Wenrui Li,Qinghao Zhang,Xiaowo Wang
### Background
理解因果异质性对于生物和医学等领域中的科学发现至关重要。但现有方法缺乏对因果关系的认识，未能充分建模异质性、混杂因素和观察约束，这导致解释性差，并且难以区分真实的因果异质性与伪关联。
### Innovation
本文提出了一种无监督框架HCL（交互式因果机制感知聚类与自适应异质因果结构学习），该框架可以从混合型观测数据中联合推断潜在簇及其关联的因果结构，无需时间顺序、环境标签、干预或先验知识。HCL 通过引入等价表示来放松同质性和充分性假设，同时保留结构异质性和混杂因素。进一步开发了双向迭代策略来交替优化因果聚类和结构学习，并配备了自我监督的正则化项以保持跨簇的普遍性和特定性。这些组成部分共同使HCL 能够收敛于可解释的、异质性的因果模式。
### Conclusion
理论上，我们证明在轻微条件下异质化的因果结构是可识别的。通过实验，HCL 在聚类和结构优化方面都达到了优越的表现，并且在实际单细胞扰动数据中重新构造了具有生物学意义的机制，展示了其在发现可解释的、机制层面的因果异质性的应用价值。
## 520. `cs.LG` - ChronoGraph：基于现实的图结构多变量时间序列数据集 [PDF](https://arxiv.org/pdf/2509.04449), [HTML](https://arxiv.org/abs/2509.04449)
### Authors
Adrian Catalin Lutu,Ioana Pintilie,Elena Burceanu,Andrei Manolache
### Background
该研究提出了ChronoGraph，这是一个基于真实生产微服务构建的时间序列预测数据集，每个节点是一个服务，它发出系统级别性能指标的多变量流，捕捉CPU、内存和网络使用模式，有向边表示服务之间的依赖关系。主要任务是对这些信号在未来的服务级别进行预测。此外，ChronoGraph还提供了由专家标注的异常窗口作为异常标签，这使得测试异常检测方法和评估运行中断期间预测鲁棒性成为可能。
### Innovation
ChronoGraph 数据集的独特之处在于它结合了多变量时间序列、显式的、机器可读的依赖关系图以及与实际事件对齐的异常标签，与工业控制系统的现有基准、交通、空气质量领域的数据集相比，ChronoGraph 是独一无二的。本文还报告了包括预测模型、预训练时间序列基础模型和标准异常检测器在内的基准结果。
### Conclusion
ChronoGraph 为研究结构感知预测和事件感知评估在微服务系统中的应用提供了一个现实的基准平台。
## 521. `cs.LG` - Echo State Networks作为状态空间模型：一种系统视角 [PDF](https://arxiv.org/pdf/2509.04422), [HTML](https://arxiv.org/abs/2509.04422)
### Authors
Pradeep Singh,Balasubramanian Raman
### Background
回声状态网络（ESNs）通常被展示为高效的、通过训练读出层的递归模型，然而其动力学和设计往往由经验法则而非第一性原理来引导。本文将ESNs重新表述为状态空间模型（SSMs），提供了一个统一的系统理论框架，将递归计算与经典识别理论和现代核化状态空间模型联系起来。
### Innovation
1. 证明了回声状态特性是合同非线性状态空间模型输入到状态稳定性的一个实例，并推导出可验证的条件，包括泄露、谱缩放和激活Lipschitz常数。2. 发展了两个互补的映射：（i）小信号线性化产生局部有效的线性时不变（LTI）状态空间模型，具有可解释的极点和记忆窗口；（ii）提升/库伯曼随机特征展开，使ESN在增广状态下成为线性状态空间模型，方便频率响应和卷积核分析。3. 用于教学强制作为状态估计，并提出卡尔曼/EKF辅助读出学习，以及包括超参数（泄露、谱半径、过程/测量噪声）的EM方法，和在收缩约束下的频谱塑造混合子空间程序。
### Conclusion
这种视角促进了记忆谱的频域特征描述，并澄清了ESN模拟结构状态空间核模型的条件，为更深入的理解和优化ESN提供了一个系统性的框架。
## 522. `cs.LG` - 少量数据可能事半功倍：临床环境中的过程时间预测 [PDF](https://arxiv.org/pdf/2509.03522), [HTML](https://arxiv.org/abs/2509.03522)
### Authors
Harald Störrle,Anastasia Hort
### Background
手术室的利用是医院的主要成本驱动因素之一。通过优化手术时间表来优化这个变量，可以显著降低成本并改善医疗成果。先前的研究提出了各种复杂的模型来预测手术持续时间，方法是利用大量数据。
### Innovation
本研究旨在创建一个基于少量数据的有效且高效模型来预测手术持续时间，并且希望模型结构简单易用。通过深入临床应用领域利用专业人士的经验，将因素分析与回归模型相结合，预测术前术后的持续时间。
### Conclusion
通过结合传统数据科学方法和对临床环境及过程结构的定性研究，我们能够利用小数据集，获得比以往研究更好的结果。这表明，将专家知识与数据分析相结合可以提高数据质量和模型性能，从而实现更准确的预测。
## 523. `cs.LG` - 提高AI对齐性的认知忠实决策模型 [PDF](https://arxiv.org/pdf/2509.04445), [HTML](https://arxiv.org/abs/2509.04445)
### Authors
Cyrus Cousins,Vijay Keswani,Vincent Conitzer,Hoda Heidari,Jana Schaich Borg,Walter Sinnott-Armstrong
### Background
当前AI研究趋势注重将人类中心的目标纳入考量，明确目标是使AI模型与个人偏好和社会价值观保持一致。通过传统的偏好获取方法，研究人员和从业者构建人类决策和判断的模型，然后用于使AI行为与人类行为一致。然而，传统的用于偏好获取过程的模型往往无法捕捉人的认知过程，例如当人们使用启发式简化决策问题相关的信息时。因此，从人的决策中学习到的模型通常不能反映其认知过程，也就无法验证用于泛化到其他决策任务的学习框架。
### Innovation
本文采用公理化方法从双输比较中学习认知忠实的决策过程。该方法基于描述影响人类决策的认知过程的巨大文献，并结合最近有关双输比较任务的认知过程的研究，定义了一类模型，其中各特征先在替代选择中进行处理和比较，然后通过固定规则（如布拉德利-泰利规则）进行聚合。这种结构化的信息处理确保了此类模型是代表底层人类决策过程的现实和可行候选模型。研究表明，此建模方法在学习肾脏分配任务中的人类决策模型时具有有效性，提出的新模型在匹配或超越先前人类双选决策模型准确性方面表现出色。
### Conclusion
研究证明了认知忠实的决策模型在提高AI与人类决策一致性的效果上是有效的，并为泛化到其他决策任务提供了潜在的方法论支撑。
## 524. `cs.LG` - 利用自我监督学习增强的时空倒变换器融合多源数据进行泊车可用性预测 [PDF](https://arxiv.org/pdf/2509.04362), [HTML](https://arxiv.org/abs/2509.04362)
### Authors
Yin Huang,Yongqi Dong,Youhua Tang,Li Li
### Background
随着私家车拥有量的快速增长，城市的泊车困境变得愈发严重。这就要求能够进行精确且有效的泊车可用性预测，以支持城市规划与管理。为了克服在建模时空依赖关系及利用多源数据进行泊车可用性预测方面的关键局限性，本研究表明了一种新的SST-iTransformer方法。该方法利用K-means聚类建立泊车簇区（PCZs），从多种交通方式（地铁、公交、在线叫车和出租车）中提取并整合与目标泊车场相关的交通需求特征。
### Innovation
SST-iTransformer结合了基于掩码重构的预训练任务，实现了自我监督的时空表示学习，并且引入了创新的双分支注意力机制：序列注意力通过分块操作捕捉长期的时序依赖性，而通道注意力通过倒置维度建模交叉变量交互。
### Conclusion
通过在中国成都的真实世界数据上进行的广泛实验，SST-iTransformer优于包括Informer、Autoformer、Crossformer和iTransformer在内的基准深度学习模型，实现了最先进的性能，其均方误差（MSE）最低，均绝对误差（MAE）具有竞争力。综合消融研究定量揭示了不同数据源的相对重要性：纳入在线叫车数据带来了最大的性能提升，其次是出租车，而固定路线交通特征（公交/地铁）的贡献较小。进一步的空间相关性分析表明，在泊车簇区内排除相关泊车的历史数据会显著降低模型性能，突显了建模空间依赖的重要性。
## 525. `cs.LG` - IPA：一种保留信息的输入投影框架以实现高效的基础模型适应 [PDF](https://arxiv.org/pdf/2509.04398), [HTML](https://arxiv.org/abs/2509.04398)
### Authors
Yuan Yin,Shashanka Venkataramanan,Tuan-Hung Vu,Andrei Bursuc,Matthieu Cord
### Background
参数高效微调（PEFT）方法，如LoRA，通过向预训练权重中注入低秩更新来减少适应成本。然而，LoRA的下投影基于随机初始化和数据无关性，这意味着它可能会丢弃有用的信息。之前的分析表明，在训练过程中，该投影变化不大，而上投影才是主要的适应源，随机的输入压缩成为了性能瓶颈。
### Innovation
本文提出了IPA，一种特征感知的投影框架，该框架明确地在减小的隐藏空间中保留信息。在线性情况下，通过使用近似主成分的算法实例化IPA，这种方法能够高效地预先训练投影器，同时不会增加推理开销。实验结果表明，IPA在语言和视觉基准测试中都优于LoRA和DoRA，并且在少量训练参数的条件下可以达到与全PEFT相当的性能。
### Conclusion
综上，IPA能够在保持性能的同时，减少训练参数的数量，从而实现更加高效的模型适应。该方法在通用推理和VTAB-1k基准测试中分别取得了平均1.5和2.3的更好精度。
## 526. `cs.LG` - ProLiFIC数据集：利用大语言模型揭示意大利立法过程 [PDF](https://arxiv.org/pdf/2509.03528), [HTML](https://arxiv.org/abs/2509.03528)
### Authors
Matilde Contestabile,Chiara Ferrara,Alberto Giovannetti,Giovanni Parrillo,Andrea Vandin
### Background
过程挖掘（PM）最初是在工业和商业环境中开发的，近年来已应用于社会系统，包括法律领域。然而，在法律领域中，PM的有效性受到了数据集的可访问性和质量的限制。本文介绍了ProLiFIC（Procedural Lawmaking Flow in Italian Chambers），这是一个全面记录从1987年到2022年意大利立法过程的事件日志。ProLiFIC从规范性门户的非结构化数据中创建，并使用大型语言模型（LLMs）进行了结构化处理，这与最近将PM与LLMs集成的努力相一致。数据集旨在促进新的发展和推动新的分析方法。
### Innovation
ProLiFIC是一个包括从1987年到2022年意大利立法过程的事件日志，这些数据来源于非结构化的规范性门户，并通过大型语言模型进行结构化处理。此数据集是将过程挖掘与大型语言模型相结合的一种尝试，以期提高法律领域的过程挖掘技术的有效性。
### Conclusion
ProLiFIC作为基准数据集，为法律领域的过程挖掘提供了一个工具，鼓励新的研究和发展。
## 527. `cs.LG` - 多时间步变分公式精确表示转化概率和过渡率 [PDF](https://arxiv.org/pdf/2509.03539), [HTML](https://arxiv.org/abs/2509.03539)
### Authors
Chatipat Lorpaiboon,Jonathan Weare,Aaron R. Dinner
### Background
转化概率是指系统在两个稳定状态之间发生过渡时，向其中一个状态转变的概率。现有方法通过最小化依赖延迟时间的过渡率表达式来估计转化概率，但这种方法在实际应用中存在偏差。本文旨在改进这一估计方法。
### Innovation
本文提出了一种新的表达式，能够在任何延迟时间下最小化精确的转化概率。此外，还提出了过渡率的另一个表达式，并将其与基于均方残差的变分动力学统计方法联系起来，进一步讨论了由此产生的误差分解。
### Conclusion
与现有方法相比，本文提出的方法对延迟时间的选择更加不敏感，具有更好的估计效果。这也为过渡率的精确估计提供了一种新的视角。
## 528. `cs.LG` - Delta Activations: 一种细调大型语言模型的表示 [PDF](https://arxiv.org/pdf/2509.04442), [HTML](https://arxiv.org/abs/2509.04442)
### Authors
Zhiqiu Xu,Amish Sethi,Mayur Naik,Ser-Nam Lim
### Background
强大的开源大型语言模型的成功使得社区能够创建大量针对特定任务和领域后训练的模型。然而，由于元数据不一致和无结构的存储库，导航和理解这些模型仍然具有挑战性。现有的方法不能有效地聚集这些模型，揭示模型图景中的结构。因此，本文介绍了一种称为Delta Activations的新方法，通过测量相对于基模型的内部激活变化来表示后训练模型，这种方法可以基于任务和领域进行有效聚类，揭示模型景观中的结构。
### Innovation
本文提出了一种全新的表示方法Delta Activations，通过衡量相对于基模型的内部激活变化来表示后训练模型。该方法具有以下创新点：具有鲁棒性，能够适应多种后训练设置；具有加法性质，当混合多个后训练数据集时；可以通过少样本微调将任务嵌入；可用于模型选择和合并。这将有助于促进使用公开可用模型的实践，并推动大型语言模型的广泛应用和发展。
### Conclusion
我们希望Delta Activations能够促进公共可用模型的再利用。相关代码已公开。
## 529. `cs.LG` - 通过信息瓶颈视角识别LLM输入-输出对的主题 [PDF](https://arxiv.org/pdf/2509.03533), [HTML](https://arxiv.org/abs/2509.03533)
### Authors
Igor Halperin
### Background
大型语言模型（LLMs）容易出现重要的失败模式，比如内在信仰幻觉（也称为虚构），这种现象使得模型的回复与提供的上下文在语义上产生偏差。现有的检测这些现象的框架，比如语义分离度度量（SDM），依赖于识别提示和回复之间共有的潜在主题，通常通过应用几何聚类来处理它们的句子嵌入。但是这种方式存在缺陷，因为这些潜在主题优化的是空间邻近性，而不是更下游的信息论分析。
### Innovation
本文通过发展一个基于确定性信息瓶颈（DIB）的原则性主题识别方法来解决上述问题，该方法将DIB方法转变为高维数据的实际算法，通过用计算效率高的上界替换其难以处理的KL散度项。这一方法，即UDIB，可以被解释为一种熵正则化和增强的版本的K均值，能够优先选择信息性集群的数量。通过将UDIB应用到LLM提示和回复嵌入的联合聚类中，我们生成了一个不是仅仅空间上一致，而是从根本上结构化为最大化提示和回复关系信息的共享主题表示。这种方法为SDM框架提供了更优的基础，并提供了一种新颖的、更灵敏的工具来检测虚构。
### Conclusion
通过应用UDIB方法，我们生成的共享主题表示不仅空间上一致，而且在本质上结构化为最大程度地表达提示-回复关系的信息。这一方法为SDM框架提供了更强的基础，并提供了一种更敏感的工具来检测虚构现象。
## 530. `cs.LG` - 长时间生成中的实时幻觉实体检测 [PDF](https://arxiv.org/pdf/2509.03531), [HTML](https://arxiv.org/abs/2509.03531)
### Authors
Oscar Obeso,Andy Arditi,Javier Ferrando,Joshua Freeman,Cameron Holmes,Neel Nanda
### Background
大型语言模型现在在高风险应用中广泛使用，如医疗咨询或法律建议，可能因幻觉导致严重危害。现有的幻觉检测方法在现实世界中不实用，要么仅限于短的常识性查询，要么需要昂贵的外部验证。
### Innovation
提出了一种廉价且可扩展的方法，用于实时识别长格式生成中的幻觉标记，并将此方法有效扩展到70B参数模型。该方法针对实体级幻觉，如虚构的名称、日期、引用等，自然映射到标记级别并实现了按标记流式检测。开发了一种基于网络搜索的注释方法，用于标注模型响应，标记出哪些标记与虚构实体相对应。该数据集使我们能够用简单有效的线性探针等方法训练有效的幻觉分类器。在四个模型系列的检测中，分类器在长格式响应中的表现优于基线，包括更昂贵的方法如语义熵。尽管训练仅使用实体级标签，但这些探针在数学推理任务中也非常有效，表明超出实体级别的泛化能力。注释方法虽昂贵，但发现一个模型的标注响应可以训练其他模型的有效分类器；因此，公开发布数据集以促进重复使用。
### Conclusion
我们的工作表明了一种有潜力的新方法，可以实现大规模、实际的幻觉检测。
## 531. `cs.LG` - AR$^2$:对抗强化学习在大语言模型中进行抽象推理 [PDF](https://arxiv.org/pdf/2509.03537), [HTML](https://arxiv.org/abs/2509.03537)
### Authors
Cheng-Kai Yeh,Hsing-Wang Lee,Chung-Hung Kuo,Hen-Hsen Huang
### Background
抽象是识别和提取复杂问题核心的计算模式的能力，是计算机科学中的基础技能，对于人类问题解决者和编码导向的大语言模型(LLMs)都至关重要。尽管最近使用强化学习(RL)训练LLMs进行代码生成取得了进展，但大多数现有方法主要关注表面化的模式识别，忽视了显式的抽象训练。因此，提升大语言模型的抽象能力是当前研究的重要方向。
### Innovation
本文提出了AR$^2$(Adversarial Reinforcement Learning for Abstract Reasoning)框架，这是一种专门设计来增强大语言模型抽象能力的新颖方法。AR$^2$通过使用教师模型将核心问题转化为富含叙述的信息挑战性描述，同时训练学生编程模型提取其潜在的核心计算模式，从而提升了对未见过的复杂编程任务的准确性，突显出抽象推理是增强模型泛化能力的关键技能。
### Conclusion
实验结果表明，AR$^2$显著提高了学生模型在未见过的挑战性编程任务上的准确性，证明了抽象推理在提升大语言模型泛化能力方面的重要性。
## 532. `cs.LG` - 利用量子极端学习机检索系外行星大气 [PDF](https://arxiv.org/pdf/2509.03617), [HTML](https://arxiv.org/abs/2509.03617)
### Authors
Marco Vetrano,Tiziano Zingales,G.Massimo Palma,Salvatore Lorenzo
### Background
传统的外行星大气研究依赖于前向模型，通过精细调整大量的化学和物理参数来计算外行星的光谱。然而，参数空间的高维性往往导致大量的计算负担。
### Innovation
本文提出了利用量子极端学习机（QELMs）来进行大气反演的新方法。QELMs 是一种使用量子系统作为黑箱处理输入数据的量子机器学习技术。本文提出了一种适用于短期内量子设备的固有容错框架，并在 IBM Fez 上直接实施以证明其容错性。
### Conclusion
所提出的 QELM 架构显示了量子计算在外行星大气数据分析中的潜力，并在未来可能会解锁更快速、更高效且更准确的模型来研究外行星大气。
## 533. `cs.LG` - 将基于特征的方法与图神经网络和符号回归相结合以实现协同性能和可解释性 [PDF](https://arxiv.org/pdf/2509.03547), [HTML](https://arxiv.org/abs/2509.03547)
### Authors
Rogério Almeida Gouvêa,Pierre-Paul De Breuck,Tatiane Pretto,Gian-Marco Rignanese,Marcos José Leite dos Santos
### Background
该研究旨在通过引入MatterVial框架，解决材料科学中基于特征的机器学习需求。传统的基于特征的方法虽然能够提供化学透明性，但预测能力有限；而深度学习模型虽然预测能力强，但在解释性方面不足。MatterVial通过结合图神经网络（GNN）和符号回归等先进技术，旨在实现性能和可解释性的双重提升。
### Innovation
MatterVial是一种创新的混合框架，它通过整合多种预训练的图神经网络模型（包括基于结构的MEGNet、基于组成的ROOST以及共变的ORB网络），结合高效的GNN近似描述符和符号回归生成的新特征，来扩大特征空间。该方法不仅继承了传统基于特征模型的化学透明性，还利用深度学习模型的预测能力，提高了传统基于特征模型MODNet在Matbench任务上的表现，多项任务的准确率提升超过40%，并接近甚至超越了最先进的端到端GNN模型。此外，MatterVial还配备了一个整合的可解释性模块，该模块通过代理模型和符号回归解码出GNN得出的隐含描述符，使其更具物理意义。
### Conclusion
MatterVial框架通过结合图神经网络和符号回归，提供了一个高性能且透明的工具，符合解释性人工智能的原则，有助于推动材料信息学的发展，使材料发现更加有针对性和自主性。
## 534. `cs.LG` - CausalARC：基于因果世界模型的抽象推理 [PDF](https://arxiv.org/pdf/2509.03636), [HTML](https://arxiv.org/abs/2509.03636)
### Authors
Jacqueline Maasch,John Kalantari,Kia Khezeli
### Background
推理要求AI适应有限数据和分布转移下的新型问题设置。该研究介绍了CausalARC，一种基于Abstraction and Reasoning Corpus (ARC) 的实验测试平台，用于低数据和分布外情况下的AI推理。
### Innovation
CausalARC从完全指定的因果世界模型中采样推理任务，并通过形式化的结构因果模型来表达。提供原理数据增强，利用少量的、上下文中的学习示范，提供观察性、干预性和反事实性反馈关于世界模型。研究展示了CausalARC在四大语言模型评估环境中的应用：（1）测试时训练的抽象推理、（2）使用上下文学习的反事实推理、（3）程序合成、（4）逻辑推理下的因果发现。
### Conclusion
CausalARC为AI在低数据和分布转移下的推理提供了新的实验平台，通过对四大语言模型评估环境的成功应用，表明了其在增强AI处理新颖情况能力上的潜力。
## 535. `cs.LG` - 使用机器学习预测食品borne病原体Campylobacter的耐药性和成本负担分析 [PDF](https://arxiv.org/pdf/2509.03551), [HTML](https://arxiv.org/abs/2509.03551)
### Authors
Shubham Mishra, TheAnh Han,Bruno Silvester Lopes,Shatha Ghareeb,Zia Ush Shamszaman
### Background
抗生素耐药性（AMR）对公共卫生和经济发展构成了重大挑战，增加了治疗成本并降低了抗生素的有效性。本文利用机器学习技术，分析来自公共数据库（如PubMLST）的基因组和流行病学数据，结合英国政府支持的食品安全局和苏格兰食品安全局支持的AMR监测数据，识别2001年至2017年在英国收集的Campylobacter jejuni和Campylobacter coli分离株中的耐药模式，使用全基因组测序（WGS）数据、流行病学元数据和经济预测来识别关键的耐药决定因子，并预测未来耐药趋势和医疗成本。
### Innovation
本文使用随机森林模型预测耐药性表型，通过Bootstrap抽样校验（1,000份样本，95%置信区间），准确率为74%。此外，本文还采用了时间序列预测模型（SARIMA、SIR和Prophet）预测肠出血性大肠杆菌病例的增加，以及经济负担的加重（若未加以控制，每年经济负担可能超过19亿英镑）。更重要的是，通过分析6,683个分离株的数据，建立了一个强化的随机森林系统，该系统结合了时间模式、不确定性估计和耐药趋势建模，进一步提高了预测的准确性，显示了持续高水平的β-内酰胺类耐药、不断增加的氟喹诺酮类耐药和波动的多西环素耐药性趋势
### Conclusion
本文的研究和预测模型表明，Campylobacter细菌的耐药性趋势将对公共卫生和经济产生严重影响，应采取措施应对这一问题，以降低未来医疗成本并提高公共卫生安全。
## 536. `cs.LG` - 使用多级迭代方法的精准大规模麦克斯韦求解器 [PDF](https://arxiv.org/pdf/2509.03622), [HTML](https://arxiv.org/abs/2509.03622)
### Authors
Chenkai Mao,Jonathan A. Fan
### Background
神经网络有潜力作为替代偏微分方程（PDE）求解器，但挑战在于如何使用这些方法在高准确性和可扩展性方面解决问题。现有方法难以同时满足这些问题的要求。
### Innovation
开发了一种子区域神经算子模型，该模型支持任意罗宾（Robin）类型边界条件输入，并能够作为灵活的预条件子用于迭代解决子问题，同时实现基于迭代多级子域分解的全局粗糙空间构建，从而加速大规模PDE问题的求解。
### Conclusion
通过二维麦克斯韦方程组作为模型系统，训练一个单一的网络来模拟不同大小、分辨率、波长和介电分布的大规模问题。进一步证明了该平台在准确设计多波长纳米光子器件方面的实用性，展示了构建精准和可扩展的多物理场替代求解器的有前景的道路，解决大规模实际问题。
## 537. `cs.LG` - ACT: 自动化约束目标设定以应对多目标推荐系统 [PDF](https://arxiv.org/pdf/2509.03661), [HTML](https://arxiv.org/abs/2509.03661)
### Authors
Daryl Chang,Yi Wu,Jennifer She,Li Wei,Lukasz Heldt
### Background
推荐系统往往需要在最大化主要目标的同时，确保次要目标满足最低标准或“防护栏”。这对于维护一致的用户体验和平台生态系统至关重要，但在面对正交系统变更时保持这些防护栏常需要手动调整超参数，这颇具挑战性。
### Innovation
本文提出了自动化约束目标设定（ACT）框架，该框架能够自动找到满足这些防护栏的最小超参数调整集。ACT 使用离线的成对评估方法，在未偏倚的数据集上找到解决方案，并持续重新训练以适应系统和用户行为的变化。
### Conclusion
该框架通过实际应用证明了其有效性，并展示了其在大规模生产环境中的部署情况。
## 538. `cs.LG` - 激活反光镜：基于激活的LLM评估器自我偏好缓解 [PDF](https://arxiv.org/pdf/2509.03647), [HTML](https://arxiv.org/abs/2509.03647)
### Authors
Dani Roytburg,Matthew Bozoukov,Matthew Nguyen,Jou Barzdukas,Simon Fu,Narmeen Oozeer
### Background
大型语言模型（LLMs）在自动评价中应用越来越广泛，但它们容易产生“自我偏好偏见”：倾向于偏好自己的输出而非其他模型的输出。这种偏见损害了评估流程的公平性和可靠性，尤其在偏好调整和模型路由任务中更为明显。
### Innovation
作者研究了在推理阶段是否可以使用轻量级引导向量来缓解这一问题而不需重新训练。他们引入了一个分类数据集，将自我偏好偏见分为有说服力的自我偏好和无说服力的自我偏好，并采用两种方法构建引导向量：对比激活添加（CAA）和基于优化的方法。结果显示，引导向量可以将无说服力的自我偏好偏见减少高达97%，显著优于提示和直接偏好优化的基础模型。但它们在合法的自我偏好和无偏见一致上不稳定，表明自我偏好包含多个或非线性方向。这既彰显了它们作为LLM鉴赏家保护措施的潜力，也揭示了其局限性，并激发了更稳健干预措施的研究动机。
### Conclusion
引导向量可以在评估中有效减轻一些表现不佳的自我偏好偏见，但它们在合法偏好和无偏见共识方面不稳定，自我偏好偏见可能包含多个或非线性方向。这既证明了引导向量作为LLM评估偏见的缓解措施的潜力，也提示需要更加强大的干预措施进一步提升LLM作为专业评判者的可靠性。
## 539. `cs.LG` - Efficient Virtuoso: 一种基于潜在扩散变换器的目标导向轨迹规划模型 [PDF](https://arxiv.org/pdf/2509.03658), [HTML](https://arxiv.org/abs/2509.03658)
### Authors
Antonio Guillen-Perez
### Background
自主车辆规划系统的关键能力是能够生成未来轨迹的多样且合理的分布。尽管最近的生成模型显示了一定的潜力，但在实现高保真度、计算效率和精确控制方面仍然面临重大挑战。
### Innovation
提出了一种条件潜在扩散模型Efficient Virtuoso，用于目标导向轨迹规划。该方法引入了一个新颖的两阶段归一化管道，首先按几何方面比放缩轨迹，然后通过确保稳定训练目标的标准主成分分析（PCA）潜在空间归一化。降噪过程在低维潜在空间中高效执行，由一个简单的多层感知器（MLP）降噪器完成，该降噪器受力强大的基于Transformer的状态编码器融合的丰富场景上下文条件化。
### Conclusion
该方法在Waymo开放运动数据集上取得了最先进的性能，最小平均置换误差（minADE）达到了0.25。此外，通过严格的消融研究，揭示了一个关键见解：虽然单一终点目标可以解决战略模糊性，但更丰富的多步骤稀疏路径对于实现与细腻的人类驾驶行为相媲美的精确、高保真战术执行是必不可少的。
## 540. `cs.LG` - MLSD: 基于元学习的少样本学习方法以增强跨目标和跨领域的立场检测 [PDF](https://arxiv.org/pdf/2509.03725), [HTML](https://arxiv.org/abs/2509.03725)
### Authors
Parush Gera,Tempestt Neal
### Background
本文探讨了一种针对不同领域和目标的立场检测的新方法。传统的立场检测模型在处理跨领域或跨目标的立场检测时，往往难以捕捉不同立场目标之间的语义相似性和差异性，这使得现有模型在新的目标领域中性能不佳。因此，需要一种新的方法来解决这一问题。
### Innovation
本文提出了一种基于元学习的少样本学习方法，即MLSD。MLSD利用三重损失进行元学习，以捕捉立场目标之间的语义相似性和差异性，进而增强领域适应性。该方法通过构建辨别性嵌入空间，使得跨目标或跨领域的立场检测模型可以从新目标领域中获取有用的实例。
### Conclusion
本文在两个数据集上的多个跨目标和跨领域的场景下评估了MLSD，结果显示MLSD在六种广泛使用的立场检测模型中，在立场检测性能上取得了统计上显著的改进。
## 541. `cs.LG` - 揭开表型深度学习中数据不确定性的作用 [PDF](https://arxiv.org/pdf/2509.04430), [HTML](https://arxiv.org/abs/2509.04430)
### Authors
Nikolay Kartashev,Ivan Rubachev,Artem Babenko
### Background
近年来，表型深度学习取得了极佳的实用效果，但对其为何成功仍缺乏清晰的理解。研究指出，表型DL方法的成功很大程度上归因于它们在处理高数据不确定性方面的隐式机制，包括数值特征嵌入、检索增强模型和高级集成策略等有益的设计选择。文章旨在填补这一认知缺口，探讨数据不确定性在解释近期表型DL方法有效性中的核心作用。
### Innovation
文章揭示了数据不确定性在解释表型DL方法成功中的关键作用。通过剖析这些机制，提供了对近期性能提升的统一理解，并直接促发了更有效的数值特征嵌入技术的发展。
### Conclusion
本研究为理解现代表型方法带来的好处奠定了基础，推动了现有技术的实质性进展，并指明了未来表型DL的研究方向。
## 542. `cs.LG` - LLMs的人格错觉：揭示LLMs自我报告与行为之间的分离 [PDF](https://arxiv.org/pdf/2509.03730), [HTML](https://arxiv.org/abs/2509.03730)
### Authors
Pengrui Han,Rafal Kocielnik,Peiyang Song,Ramit Debnath,Dean Mobbs,Anima Anandkumar,R. Michael Alvarez
### Background
人格特质长期被作为预测人类行为的指标。随着大型语言模型（LLMs）的进步，研究发现它们在某些方面表现出了类似人类的人格特征，例如亲和性和自我调节等。然而，先前的研究主要依赖简化的自我报告和启发式的提示，缺乏对行为的验证。
### Innovation
本研究系统地分析了LLMs人格在三个维度上的特征：（1）特质随训练阶段变化的动态出现和演变；（2）自我报告的人格特质在行为任务中的预测效度；（3）特定干预措施（如角色注入）对自我报告与行为的影响。研究发现，指令对齐（如RLHF，指令微调）显著稳定了人格表达并增强了适用于人类数据的特质相关性。但自我报告并没有可靠地预测行为，观察到的相关性往往与人类模式不同。尽管角色注入成功引导了自我报告，但在实际行为上几乎没有效果。通过区分表面的人格表达与行为一致性，本研究质疑了LLMs人格的假设，并强调了需要更深入地评估其协同性和可解释性。
### Conclusion
本研究揭示了LLMs中自我报告与行为之间的分离现象，这种现象挑战了对LLMs人格的理解，并强调了需要更加深入地评估其协同性和可解释性。
## 543. `cs.LG` - 测试网络结构与高维节点协变量之间的相关性 [PDF](https://arxiv.org/pdf/2509.03772), [HTML](https://arxiv.org/abs/2509.03772)
### Authors
Alexander Fuchs-Kreiss,Keith Levin
### Background
在许多应用领域，网络观察到具有节点级别的特征。在这种情况下，一个常见的问题是评估节点水平的协变量是否与网络结构本身相关。这项工作提供了四个新的方法来解决这个问题。
### Innovation
四个方法中有两个基于将节点水平协变量与驱动网络结构的潜在节点变量相关联的线性模型。另外两个方法基于应用典范相关分析到节点特征和网络结构上，避免了线性建模的假设。此外，这些方法在计算上更便宜，并且需要更少的建模假设，相比之前的网络依赖性测试方法而言。这些方法在模拟和实际数据上进行了测试和比较性能。
### Conclusion
当观察到的网络按照带节点级协变量的低秩潜在空间模型生成时，所有四个方法都提供了理论保证。这项工作的方法在计算成本和建模假设上都优于之前的方法，有望提高网络依赖性测试的效率和可靠性。
## 544. `cs.LG` - 使用LLM进行大规模网络搜索评估的关联性评估 [PDF](https://arxiv.org/pdf/2509.03764), [HTML](https://arxiv.org/abs/2509.03764)
### Authors
Han Wang,Alex Whitworth,Pak Ming Cheung,Zhenjie Zhang,Krishna Kamath
### Background
个性化搜索系统中的相关性评估对于确保搜索结果与用户查询和意图相匹配至关重要。传统的相关性评估方法是人工注解，但这种方法成本高且耗时，限制了其可扩展性。论文在Pinterest搜索中探讨了如何使用微调后的LLM自动进行相关性评估，以应用于在线实验，从而提高评估效率并验证其可靠性.
### Innovation
提出了使用微调后的LLM在Pinterest搜索中自动进行相关性评估的方法，通过严格验证LLM生成的判断与人类注解的一致性，展示了LLM可以在提高评估效率的同时提供可靠的相关性测量。这种方法还进一步利用LLM基础的标记解锁扩展查询集、优化抽样设计和大规模高效评估更广泛的搜索体验的机会，提高了相关性度量的质量并显著降低了在线实验测量中的最小可检测效应（MDE）.
### Conclusion
这种基于LLM的相关性评估方法提高了相关性度量的质量，并显著降低了在线实验测量中的最小可检测效应（MDE）.
## 545. `cs.LG` - 未知非线性动力学的蓄水库预测路径积分控制 [PDF](https://arxiv.org/pdf/2509.03839), [HTML](https://arxiv.org/abs/2509.03839)
### Authors
Daisuke Inoue,Tadayoshi Matsumori,Gouhei Tanaka,Yuji Ito
### Background
神经网络能够逼近复杂的非线性，广泛应用于非线性动力系统的数据驱动控制中。然而，快速在线识别和控制未知动态依然是一项核心挑战。
### Innovation
该论文将蓄水库计算模型（使用循环神经网络实现的Echo-State Networks, ESNs）和基于采样的模型预测控制方法（Model Predictive Path Integral, MPPI 控制）相结合，提出了蓄水库预测路径积分控制（Reservoir Predictive Path Integral, RPPI），该方法利用ESN进行快速学习非线性动态，并直接在并行化的MPPI控制计算中利用所学的非线性，无需线性化近似。进一步扩展了不确定性感知的RPPI（Uncertainty-aware RPPI, URPPI），利用ESN的不确定性来平衡探索和利用。
### Conclusion
实验结果表明，URPPI在控制杜芬振子和四罐系统中表现出优越的控制性能，相较于传统的基于二次规划的模型预测控制方法，控制成本降低了最多60%。
## 546. `cs.LG` - Energy-Weighted Flow Matching: 解锁连续归一化流动以实现高效可扩展的玻尔兹曼采样 [PDF](https://arxiv.org/pdf/2509.03726), [HTML](https://arxiv.org/abs/2509.03726)
### Authors
Niclas Dern,Lennart Redl,Sebastian Pfister,Marcel Kollovieh,David Lüdke,Stephan Günnemann
### Background
从未标准化的目标分布中进行采样，例如玻尔兹曼分布 μ_目标(x) ∝ exp(-E(x)/T)，是许多科学应用的基础，但由于复杂的高维能量景观而计算上具有挑战性。现有的使用现代生成模型进行玻尔兹曼采样的方法要么需要大量的目标分布样本，要么仅使用能量评估进行训练时无法有效地利用连续归一化流动等先进架构的表达能力，这些架构已显示出对分子采样的前景。
### Innovation
我们引入了能量加权流动匹配（Energy-Weighted Flow Matching, EWFM），这是一种新颖的训练目标，使连续归一化流动能够仅通过能量函数评估来建模玻尔兹曼分布。基于此目标，我们开发了两种算法：渐进式EWFM（iEWFM），通过迭代训练不断精炼提案；以及退火式EWFM（aEWFM），通过温度退火进一步处理具有挑战性的能量景观。实验表明，我们的算法在基准系统中表现出了接近最先进的仅能量方法的采样质量，同时仅需较少的能量评估次数（高达三个数量级的减少）。
### Conclusion
我们的方法在基准系统（包括具有挑战性的55粒子Lennard-Jones簇）中展示了与最先进的仅能量方法相当的采样质量，同时只需要较少的能量评估次数，并且该方法还发展了多阶段优化策略，以提高复杂能量景观的采样效率。
## 547. `cs.LG` - 自然潜在变量：跨语义的潜在变量稳定 [PDF](https://arxiv.org/pdf/2509.03780), [HTML](https://arxiv.org/abs/2509.03780)
### Authors
John Wentworth,David Lorell
### Background
该论文探讨了两个使用贝叶斯方法学习同一环境生成模型的代理，假设他们已收敛于预测分布，但可能存在不同的生成模型和潜在变量。研究条件下的一个关键问题是，如何保证一个代理的潜在变量可以表达为另一个代理潜在变量的函数。文章给出了确保这种转换可能的简单条件，即自然潜在变量条件，同时也表明，在没有额外约束的情况下，这是确保可翻译性的最一般条件。并且，该论文的定理在自然潜在变量条件下的近似误差方面表现出鲁棒性。
### Innovation
该论文提出了自然潜在变量条件，这些条件在确保代理之间的潜在变量可以相互表达方面是最简单的，同时展现出强大的鲁棒性，即使存在生成模型的近似误差。文章还强调了这些条件在应用中的普遍适用性。
### Conclusion
该论文确定了在生成模型学习环境中，不同代理的潜在变量可以在自然潜在变量条件下相互转换的必要条件，并证明这些条件是最广泛适用的。此外，定理对自然潜在变量条件下的近似错误具有鲁棒性，这对实际应用非常有利。
## 548. `cs.LG` - 为AI任务的硬件感知数据和指令映射：平衡并行性、I/O与内存权衡 [PDF](https://arxiv.org/pdf/2509.03846), [HTML](https://arxiv.org/abs/2509.03846)
### Authors
Md Rownak Hossain Chowdhury,Mostafizur Rahman
### Background
该研究提出了一种利用可预测神经网络行为的深度学习推理映射框架。该框架不仅规划计算，还规划通信，提前生成统一的操作和数据流，使得硬件能够自主执行操作和路由信息，减少主机的频繁干预和外部存储器使用。这种方法自然地减少了对外部I/O、外部存储器和主机控制的依赖。
### Innovation
该框架通过在可编程的基于消息的计算架构上利用细粒度的消息传递，保持数据移动的局部性，并通过站内权重重用、阵列内多播和阶段归约等技术协调计算活动。应用于VGG-19，该框架保持了高利用率（88%到92%），超过97%的消息在内部生成，并且接近89%的时间用于片上转移。对于更大的数组，计算吞吐量超过1 TFLOP/s，重用和局部聚合的流量减少高达每层100 MB。
### Conclusion
整体结果强调了基于流的计算的有效性，并展示了我们的映射器如何通过跨越硬件紧密协调数据和指令流动，实现这种执行风格。
## 549. `cs.LG` - 假设选择：一个高概率的困境 [PDF](https://arxiv.org/pdf/2509.03734), [HTML](https://arxiv.org/abs/2509.03734)
### Authors
Anders Aamand,Maryam Aliakbarpour,Justin Y. Chen,Sandeep Silwal
### Background
在假设选择问题中，已知一组候选分布（假设）$text{textsc{H}} = text{H}_1, text{H}_2, text{...}, text{H}_n$，以及从未知分布$P$中抽取的样本。目标是从这些假设中找到一个与$P$的总变差距离相近的假设。当最优距离为$text{OPT}$时，我们的目标是在概率至少为$1-text{textsc{d}}$的情况下，找到一个与$P$的总变差距离最多为$C times text{OPT} + text{textsc{ε}}$的假设。尽管多年来不断研究，该问题的关键方面尚未解决，特别是在算法的优化运行时间和最优样本复杂性以及最佳近似因子$C=3$方面。
### Innovation
本文改进了先前的最佳时间复杂度$tilde{O}(n/(text{textsc{d}}^3text{textsc{ε}}^3))$为$tilde{O}(n/(text{textsc{d}}text{textsc{ε}}^2))$，显著降低了对置信度和误差参数的依赖。同时，我们在三个替代场景中研究了假设选择，解决了或在先前的工作中取得了进展。具体来说，(1) 当把输出假设的期望距离作为限制时优化了最佳近似因子；(2) 已知最优距离$text{OPT}$时，提出了一个最优样本复杂性和高效运行时间的算法；(3) 在观察样本前允许多项式预处理步骤，提出一个具有高效运行时间和成功概率的算法。
### Conclusion
本文改进了假设选择问题的时间复杂度，并解决了多个现有的开放问题。改进了运行时间复杂度，并在三个替代设置中取得了进展，以优化运行时间和提高成功率。
## 550. `cs.LG` - 离散时间控制障碍函数的高效验证 [PDF](https://arxiv.org/pdf/2509.03899), [HTML](https://arxiv.org/abs/2509.03899)
### Authors
Sampath Kumar Mulagaleti,Andrea Del Prete
### Background
控制不变(CI)集在确保动态系统安全性方面至关重要。控制障碍函数(CBFs)是一种有效的工具，可计算这些集，因为CBFs的零子水平集正是控制不变集。然而，计算CBFs通常涉及解决一个复杂的鲁棒优化问题，这可能是难以处理的。为此，提出了基于场景的方法来简化这一过程。但紧接着的问题是，需要验证实际的CBF是否满足鲁棒约束条件。
### Innovation
本文提出了一种基于Lipschitz论证的方法来进行验证，构建了一个设计用于样本效率的认证算法。这种方法通过一个数值例子验证了其效率。
### Conclusion
研究提出的方法能够在保证效率的前提下，验证离散时间控制障碍函数是否满足鲁棒约束条件，为动态系统的安全性保障提供了新的思路和工具。
## 551. `cs.LG` - 数据驱动动力系统建模中的方程发现方法的缺陷 [PDF](https://arxiv.org/pdf/2509.03769), [HTML](https://arxiv.org/abs/2509.03769)
### Authors
Zheng-Meng Zhai,Valerio Lucarini,Ying-Cheng Lai
### Background
从数据中找到支配方程的方法已成为动力系统确定性建模的流行方法。然而，在实际物理情境中，由于干扰和测量误差，数据往往是不完美的。对于许多混沌系统而言，广泛使用的稀疏优化方法在发现支配方程时表现出对测量程序的高度敏感性。尽管如此，这些模型生成的混沌吸引子几乎完全相同。这种发现不对测量误差影响的动力系统建模方法提出了挑战，进而挑战了复杂的动力系统基于方程的建模传统观念。通过计算Koopman谱，发现不同的方程组在大特征值方面达成一致，而差异主要出现在小于方程依赖阈值的小特征值上。结果表明，试图从方程中解释系统行为可能导致误导性的结论，直接使用可用数据（如使用机器学习方法）可能更有助效。
### Innovation
该研究通过分析带测量误差的混沌系统的稀疏优化方法，发现这些模型尽管高度敏感于测量误差，但生成的混沌吸引子却非常相似。使用Koopman谱进一步揭示了不同方程组在特征值方面的差异，并认为直接处理数据而非解析方程可能更具优势。这种方法新颖地突出了建立复杂动力系统的模型时需谨慎处理误差影响的问题，促进了对数据驱动建模方法的深刻理解。
### Conclusion
研究揭示了使用方程发现方法进行数据驱动建模的局限性，特别是相对于混沌系统而言。尽管生成的动力学行为一致，但这些模型对测量程序的高度敏感性挑战了传统的方程模型观念。直接利用机器学习等方法处理数据可能更能适应实际测量条件，提供更可靠的模型。
## 552. `cs.LG` - 通过韩国案例研究增加开源大语言模型的基础语言能力 [PDF](https://arxiv.org/pdf/2509.03972), [HTML](https://arxiv.org/abs/2509.03972)
### Authors
Junghwan Lim,Gangwon Jo,Sungmin Lee,Jiyoung Park,Dongseok Kim,Jihwan Kim,Junhyeok Lee,Wai Ting Cheung,Dahye Choi,Kibong Choi,Jaeyeon Huh,Beomgyu Kim,Jangwoong Kim,Taehyun Kim,Haesol Lee,Jeesoo Lee,Dongpin Oh,Changseok Song,Daewon Suh
### Background
介绍了Llama-3-Motif，这是一个含有102亿参数的语言模型，专门设计来提升韩语能力，同时在英语上保持强大的性能。
### Innovation
Llama-3-Motif是在Llama 3架构上开发的，采用LlamaPro和Masked Structure Growth等高级训练技术，有效扩展模型规模，而不改变其核心Transformer架构。此外，使用MoAI平台在超大规模GPU集群中进行高效训练，并优化了模型。
### Conclusion
Llama-3-Motif在韩语特定基准测试中的表现不错，超过了现有模型，并达到了与GPT-4相当的结果。
## 553. `cs.LG` - 可逆生成模型用于前向和逆向问题 [PDF](https://arxiv.org/pdf/2509.03910), [HTML](https://arxiv.org/abs/2509.03910)
### Authors
Tristan van Leeuwen,Christoph Brune,Marcello Carioni
### Background
该论文基于贝叶斯框架对逆问题进行建模，旨在训练一种生成模型，该模型能够模拟（即从似然分布抽样）和推断（即从后验分布抽样）。论文回顾了三角归一化流在条件抽样中的应用，并展示了如何将两个这样的三角映射（一个上三角映射，一个下三角映射）结合成一个可逆的映射，用于模拟和推断。此外，论文还详细推导了这种可逆生成模型的一些有用特性，并提出了一种可能用于直接训练映射的损失函数。最后，通过几个示意性示例演示了该新方法在条件生成建模中的作用。
### Innovation
提出了一种基于可逆生成模型的方法，将两个三角归一化映射结合成一个可逆映射，用于模拟和推断。文中还提出了一种直接训练这种映射的损失函数，并验证了该方法的有效性。
### Conclusion
通过数值示例证明了此新的条件生成建模方法的有效性，并展示了其在实际应用中的潜力。
## 554. `cs.LG` - 解码韩国现代诗歌中的诗意语言：来自人工标注数据集和人工智能建模的洞见 [PDF](https://arxiv.org/pdf/2509.03932), [HTML](https://arxiv.org/abs/2509.03932)
### Authors
Iro Lim,Haein Ji,Byungjun Kim
### Background
尽管基于大规模语言模型的进步在文本情感分类方面取得了显著进展，但诗歌特别是韩国诗歌由于其富有修辞的语言和文化特性，仍旧被广泛忽视。该研究旨在利用一个新数据集KPoEM（Korean Poetry Emotion Mapping）来弥补这一空白。
### Innovation
研究构建了一个包含7662个条目的多标签情感数据集，覆盖了483首诗的7007行级条目和615个作品级条目，以及来自五位著名韩国诗人的44个细粒度情感类别注释。通过将先进的韩国语言模型在KPoEM数据集上进行微调，研究证明了比在通用语料库上训练的模型提升了0.60 F1-微平均，这表明KPoEM模型不仅提升了识别时间和文化特性特定情感表达的能力，还保留下了现代韩国诗歌的核心情感。
### Conclusion
该研究连接了计算方法与文学分析，通过结构化的数据定量探索了韩国诗歌中的情感，确保了情感和文化细微差异的忠实保留。
## 555. `cs.LG` - 基于发散核方法的线性响应和扩散模型 [PDF](https://arxiv.org/pdf/2509.03992), [HTML](https://arxiv.org/abs/2509.03992)
### Authors
Angxiu Ni
### Background
本文研究了随机动力系统的线性响应（参数导数的边缘或稳态分布），并在连续时间极限下进行了形式上的转换。背景包含随机动力系统中的线性响应理论和现有的相关方法。该研究方法适用于任何时间周期内的乘性参数噪声，且不需要具有超曲性。
### Innovation
本文推导出了发散核公式，并基于此提出了路径可预测的蒙特卡洛算法以计算线性响应。进一步地，本文提出了一种仅向前扩散生成模型，并进行了简单的实验测试。
### Conclusion
本文通过发散核公式方法和路径可预测的蒙特卡洛算法推导出随机动力系统的线性响应，不依赖于超曲性。所提出的方法能应用于任何时间周期内的乘性参数噪声。提出的仅向前扩散生成模型成功地进行了简单问题的实验测试。
## 556. `cs.LG` - Promptception：大型多模态模型对提示的敏感性研究 [PDF](https://arxiv.org/pdf/2509.03986), [HTML](https://arxiv.org/abs/2509.03986)
### Authors
Mohamed Insaf Ismithdeen,Muhammad Uzair Khattak,Salman Khan
### Background
近年来，大型多模态模型（LMMs）在多项选择题答案生成（MCQA）方面取得了显著的成功，但提示设计对LMMs的影响仍然不清楚。即使是小的提示措辞和结构的变化，也可能会导致高达15%的准确性偏差。这种变化性对透明和公平的LMM评估构成了挑战，因为模型通常会利用精心挑选的提示来报告它们的最佳性能。
### Innovation
本文引入了Promptception，这是一种系统性框架，用于评估LMM对提示的敏感性，包含61种提示类型，跨越15个类别和6个超类别，每个类型都针对提示制定的特定方面，并用于评估10种LMM，从轻量级开源模型到GPT-4o和Gemini 1.5 Pro，覆盖了3个MCQA基准：MMStar，MMMU-Pro，MVBench。研究发现，专有模型对提示措辞更敏感，反映出更强的指令语义对齐，而开源模型则较为稳定，但在复杂的措辞方面表现挣扎。
### Conclusion
基于此分析，本文提出适用于专有和开源LMM的提示原则，以实现更稳健和公平的模型评估。
## 557. `cs.LG` - 扩散生成模型与压缩感知相遇，图像数据和金融时序的应用 [PDF](https://arxiv.org/pdf/2509.03898), [HTML](https://arxiv.org/abs/2509.03898)
### Authors
Zhengyi Guo,Jiatu Li,Wenpin Tang,David D. Yao
### Background
该论文针对生成数据时的扩散模型推理加速问题，通过将压缩感知技术整合到扩散模型中，实现数据压缩、生成模型训练以及样本生成的效率提升。背景中提到在合成数据生成的上下文中发展降维技术以加速扩散模型推理。
### Innovation
提出了将压缩感知技术与扩散模型结合的方法，具体步骤包括：(i) 将数据压缩到潜在空间，(ii) 在潜在空间中训练扩散模型，(iii) 对潜在空间生成的样本应用压缩感知算法。这种方法在满足数据稀疏假设的情况下，能够通过结合扩散模型推理和稀疏恢复提高算法收敛速度，并获得潜在空间维度的最优值。
### Conclusion
通过实验在图像数据（手写数字、医疗图像、气候数据）和金融时间序列上验证了该算法的效果，并指出在适当的稀疏假设下，该算法能加快模型训练和推理的效率，同时通过实验获得了潜在空间维度的最优点。
## 558. `cs.LG` - 基于信心感知密集对应和触觉感知能力的空中服装操作 [PDF](https://arxiv.org/pdf/2509.03889), [HTML](https://arxiv.org/abs/2509.03889)
### Authors
Neha Sunil,Megha Tippur,Arnau Saumell,Edward Adelson,Alberto Rodriguez
### Background
操控服装具有挑战性，因为服装的复杂形态、材料特性的波动以及常见的自遮挡现象。先前的系统通常会拉平衣物或将关键特征假设为可见，这限制了其操作能力。本文提出了一种双臂视触觉框架，该框架结合了信心感知密集视触对应和力觉监督的抓取适用性，能够在折叠和悬置皱褶的衣物上直接操作。
### Innovation
该框架创新地采用了信心感知密集视触对应模型，通过分布损失训练生成对应信心估计值，引导反应状态机根据感知不确定性调整折叠策略。同时，用于确定可抓取区域的自监督高分辨率力觉反馈网络，实时验证抓取。系统能够处理高度遮挡的桌面和空中配置，且适用于多种任务，提供了一种可重复使用的中间表示方式，用于其他规划方法。
### Conclusion
本文展示了基于信心感知密集对应和触觉感知能力的无人值守空中服装操作模块，证明了其在折叠和悬挂任务中的有效性。同时，此项技术还为从人类视频演示中提取抓取目标以及其他规划模式提供了支持，为更泛化和可扩展的服装操控奠定了基础。
## 559. `cs.LG` - 变分不等式中的洗牌启发式方法：建立新的收敛保证 [PDF](https://arxiv.org/pdf/2509.04133), [HTML](https://arxiv.org/abs/2509.04133)
### Authors
Daniil Medyakov,Gleb Molodtsov,Grigoriy Evseev,Egor Petrov,Aleksandr Beznosikov
### Background
变分不等式在机器学习和优化研究中引起了广泛关注。尽管传统的方法假设数据样本是独立的，但本研究探讨了一种替代方案——洗牌启发式方法。该方法在处理数据前进行重新排列，确保所有数据点都被平等考虑。尽管该方法具有实用价值，但在变分不等式中关于洗牌的理论保证仍然缺失。已有研究试图填补这一空白，通过提供第一个关于洗牌方法在变分不等式中的收敛估计，建立了严格的边界和收敛速率，从而拓展了这一重要算法类别的理论框架。
### Innovation
本研究首次为变分不等式中的洗牌方法提供了理论收敛估计，建立了严格的边界和收敛速率，填补了该领域的理论空白。通过广泛的实验证明了洗牌方法相对于独立采样方法具有更快的收敛速度。
### Conclusion
研究通过分析提供了新的理论保证，证明了洗牌方法在变分不等式中的有效性和更快的收敛性，并通过实验验证了其结论。
## 560. `cs.LG` - LMAE4Eth: 探索交易语义和掩码图嵌入以实现通用且稳健的以太坊欺诈检测 [PDF](https://arxiv.org/pdf/2509.03939), [HTML](https://arxiv.org/abs/2509.03939)
### Authors
Yifan Jia,Yanbin Wang,Jianguo Sun,Ye Tian,Peng Qian
### Background
当前以太坊欺诈检测方法依赖于缺乏语义信息的上下文无关数值交易序列，无法捕捉账户之间的语义差异。以太坊交易记录的同质性使得学习区分性账户嵌入变得困难。现有的自监督图学习方法主要通过图重构来学习节点表示，对于节点级任务如欺诈账户检测的性能较差，同时这些方法还面临可扩展性挑战。
### Innovation
提出了一种新的多视图学习框架LMAE4Eth，该框架融合了交易语义、遮蔽图嵌入和专家知识。首先提出了一种交易标记对比语言模型(TxCLM)，将上下文无关的数值交易记录转换为逻辑一致的语言表示。通过标记感知的对比学习预训练目标结合遮蔽交易模型预训练目标，学习高表达力的账户表示。接着提出了一种生成自监督学习的遮蔽账户图自动编码器(MAGAE)，通过关注账户节点特征的重构实现优越的节点级账户检测。为了使MAGAE能够扩展到大规模训练，提出将层-邻居采样整合到图中，从而多次减少了采样顶点的数量而不会牺牲训练质量。最后，通过交叉注意力融合网络统一了TxCLM和MAGAE的嵌入，以充分利用两者的好处。
### Conclusion
实验结果表明，该方法在两个数据集上的F1分数比最好的基线方法高出超过10%。此项工作实现了通用且稳健的以太坊欺诈检测，通过探索交易语义和掩码图嵌入来提高欺诈检测的准确性和可扩展性。
## 561. `cs.LG` - 通过运动模式的深度度量相似性学习进行非侵入性现场行为变化测量 [PDF](https://arxiv.org/pdf/2509.04174), [HTML](https://arxiv.org/abs/2509.04174)
### Authors
Christian Merz,Lukas Schach,Marie Luisa Fiedler,Jean-Luc Lugrin,Carolin Wienrich,Marc Erich Latoschik
### Background
本文介绍了一种无侵扰的现场测量方法，用于在XR系统中检测用户行为变化，特别是在任意暴露期间。在XR环境中，用户行为变化通常与Proteus效应或由不同化身引发的身体知觉相关联。作者提出了一种基于深度度量相似性学习的生物特征用户模型，使用高维嵌入作为参考向量以识别个体用户的行为变化。
### Innovation
本文的创新之处在于提出了一种无侵扰的现场测量方法，采用基于深度度量相似性学习的生物特征用户模型，无需用户额外输入即可检测行为变化。该方法具有多个优势：1) 在现场测量过程中不需要用户的额外输入；2) 可以进行广泛且可扩展的运动分析，适用于各种用例；3) 对用户进行个体水平的具体分析；4) 可以实时添加和评估用户，研究化身变化对行为的影响。
### Conclusion
通过基于运动数据训练的相似性学习模型，作者成功地识别了由不同化身条件引起的多种查询和参考数据对的行为变化。此方法在对象分析、个性化分析和实时监测方面优于现有方法，为行为变化的研究提供了新的途径。
## 562. `cs.LG` - DUDE: 基于扩散模型的无监督跨域图像检索 [PDF](https://arxiv.org/pdf/2509.04193), [HTML](https://arxiv.org/abs/2509.04193)
### Authors
Ruohong Yang,Peng Hu,Yunfan Li,Xi Peng
### Background
无监督跨域图像检索（UCIR）的目标是在无需标注的情况下，在不同领域中检索同一类别的图像。现有方法通常采用全局图像特征对齐的方式，但由于检索关键的对象特征常与领域特定风格交织在一起，无法有效应对领域差异。因此，这些方法在处理领域gap时表现不佳。
### Innovation
本文提出了DUDE（去纠缠的无监督跨域图像检索）方法，这是一种基于特征去纠缠的新方法。DUDE采用文本到图像的生成模型来分离对象特征和领域特定风格，以便进行语义图像检索。此外，通过逐步对齐域内和域间的互邻特征来进一步实现可靠的去纠缠对象特征对齐。
### Conclusion
通过在三个基准数据集上的广泛实验，证明了DUDE在13个领域中实现了最先进的性能。研究者将公开代码。
## 563. `cs.LG` - KubeGuard: 通过配置文件和运行时日志分析辅助的Kubernetes加固 [PDF](https://arxiv.org/pdf/2509.04191), [HTML](https://arxiv.org/abs/2509.04191)
### Authors
Omri Sgan Cohen,Ehud Malul,Yair Meidan,Dudu Mimran,Yuval Elovici,Asaf Shabtai
### Background
随着Kubernetes（K8s）在云原生应用编排中广泛应用，带来了重大的安全挑战，如资源配置错误和权限过度开放。未能解决这些问题可能导致未授权访问、权限提升和集群内部的横向移动。目前大多数K8s安全解决方案集中在检测配置错误上，通常通过静态分析或异常检测实现。相比之下，本文提出了KubeGuard，这是一个基于运行时日志的推荐框架，旨在通过解决过度开放的配置问题来减轻安全风险。KubeGuard通过资源创建和资源配置改进两个互补任务来增强K8s环境的安全性。
### Innovation
KubeGuard利用大型语言模型（LLMs）分析配置文件和运行时日志，反映实际系统行为，采用模块化的提示链工作流程。这种方法允许KubeGuard为新资源创建最小特权配置，并改进现有配置以减少攻击面。KubeGuard生成的输出配置文件作为推荐供用户（如开发人员和运维人员）审查和采纳，以增强集群安全。
### Conclusion
评价表明，KubeGuard有效地生成和改进了K8s配置文件，涉及Roles、NetworkPolicies和Deployments，并利用了企业和开源大型语言模型。较高的精度、召回率和F1分数证实了KubeGuard作为将运行时可观测性转化为操作最小特权配置指导的实际框架的功效。
## 564. `cs.LG` - TensoIS: 向前馈张量逆向散射技术迈出一步，用于Perlin分布的非均匀媒质 [PDF](https://arxiv.org/pdf/2509.04047), [HTML](https://arxiv.org/abs/2509.04047)
### Authors
Ashish Tiwari,Satyam Bhardwaj,Yash Bachwana,Parag Sarvoday Sahu,T.M.Feroz Ali,Bhargava Chintalapati,Shanmuganathan Raman
### Background
从图像中估计非均匀介质的散射参数是一个严重缺乏约束且具有挑战性的问题。目前大多数方法要么通过分析-合成的方法逼近复杂的路径积分，要么使用可微体积渲染技术来处理非均匀性。然而，很少有研究采用基于学习的方法来估计次表层散射参数，且这些研究假设介质是均匀的。实际上，我们知道的具体的分布能够明确地模拟现实世界中的非均匀散射参数。尽管如此，分形Perlin噪声模型在表征自然、有机和无机表面的复杂非均匀性方面表现良好。基于此，本文提出了HeteroSynth数据集，包含使用分形Perlin噪声建模的非均匀介质的逼真图像。除此之外，我们还提出了TensoIS，一种基于学习的前馈框架，用于从稀疏多视角图像观察中估计这些Perlin分布的非均匀散射参数。我们利用TensoIS在非均匀变化方面评估了HeteroSynth测试集中的未见形状、开源的现实体积模拟产生的烟雾和云几何结构以及一些真实世界的样本，以验证其前馈逆散射的有效性。总体而言，此研究尝试探索Perlin噪声分布，因为在文献中没有这种明确定义的分布，期望能以一种前馈的方式建模现实世界中的非均匀散射参数。
### Innovation
提出了HeteroSynth数据集，包含使用分形Perlin噪声建模的非均匀介质真实图像。此外，TensoIS是一种基于学习的前馈框架，利用Perlin分布的非均匀散射参数来估计稀疏多视角图像观察中的这些参数。TensoIS通过学习低秩张量组件来表示散射体积，而不是直接预测3D的散射参数体积。
### Conclusion
TensoIS在HeteroSynth测试集中的未见形状、开源的现实体积模拟产生的烟雾和云几何结构以及一些真实世界的样本上进行了评估，验证了其在前馈逆散射中的有效性。这项研究探讨了利用Perlin噪声分布以一种前馈方式来建模现实世界中的非均匀散射参数的可能性。
## 565. `cs.LG` - AlphaZero算法在测试时环境变化下的鲁棒性改进 [PDF](https://arxiv.org/pdf/2509.04317), [HTML](https://arxiv.org/abs/2509.04317)
### Authors
Isidoro Tamassia,Wendelin Böhmer
### Background
AlphaZero框架提供了一种标准方式，将蒙特卡洛规划与之前训练的策略价值神经网络提供的先验知识相结合。AlphaZero通常假设在训练神经网络的环境中，在测试时间不会发生变化，这限制了其适用性。本文分析了在潜在变化的测试环境中部署AlphaZero代理的问题，并展示了通过对标准框架进行一些修改，可以在规划预算较低的情况下显著提高性能。
### Innovation
本文提出了通过简单修改标准框架来显著提升AlphaZero在测试时环境变化下的鲁棒性的方法，即使在规划预算有限的情况下也能显著提升性能。
### Conclusion
所提出的方法已在GitHub上公开发布，证明了即使是预算有限的场景下，也可以通过简单的框架修改来显著提高AlphaZero的性能。
## 566. `cs.LG` - 批量随机匹配赌博机 [PDF](https://arxiv.org/pdf/2509.04194), [HTML](https://arxiv.org/abs/2509.04194)
### Authors
Jung-hun Kim,Min-hwan Oh
### Background
在本研究中，我们探讨了一种基于多项式逻辑（MNL）选择模型的新型赌博机框架，用于随机匹配。设定有$N$个代理在一边，$K$个臂在另一边，每个臂根据未知偏好随机从分配的池中选择一个代理，并根据选择结果产生相应奖励。目标是在所有代理的匹配成功中最大化累积收益，以最小化后悔。由于基于估计偏好的组合优化问题是非常困难的（NP难），一个简单的解决方法会导致每轮计算成本为$O(K^N)$。
### Innovation
为了应对这一挑战，我们提出了一种批量算法，限制匹配更新的频率，从而将每轮的平均计算成本（即，平均每轮成本）降低到$O(1)$，同时仍能实现近似为$tilde{O}(text{根号} T)$的后悔界。
### Conclusion
通过提出这种批量算法框架，我们可以有效地降低计算成本，同时保持较低的后悔率，从而提供一种有效解决随机匹配问题的方法。
## 567. `cs.LG` - Gromov-Wasserstein and optimal transport: from assignment problems to probabilistic numeric [PDF](https://arxiv.org/pdf/2509.04089), [HTML](https://arxiv.org/abs/2509.04089)
### Authors
Iman Seyedi,Antonio Candelieri,Enza Messina,Francesco Archetti
### Background
《背景》运筹学中的指派问题旨在寻找最优的一对一映射，以最小化总成本。这篇论文追溯了指派问题从经典表述和算法到现代最优传输理论的发展历程，将二次指派问题（QAP）和其他结构匹配任务置于这一框架内。论文将线性指派问题与运筹学家们提出的运输问题、拉克诺维茨的松弛技术以及Wasserstein距离建立联系，然后扩展到源和目标位于不同度量空间的情形，引入了Gromov-Wasserstein（GW）距离。GW方法及其融合结构信息和特征信息的变体自然适用于QAP类型的匹配问题，通过优化基于领域内距离和跨领域属性的对齐来进行优化。
### Innovation
《创新》本文提出了GW方法及其融合变体（如融合GW变体），能有效地解决QAP及其相似问题。为了提高解的鲁棒性，文章还提出了一种多初始化策略GW-MultiInit，并结合了熵性的Sinkhorn近似方法。通过计算实验对容量约束的QAP实例进行测试，结果表明GW-MultiInit能够始终得到接近最优的解，并且在大规模问题上具有高效的可扩展性。此外，参数化的EGW和FGW变体为精度和运行时间之间提供了灵活的权衡。
### Conclusion
《结论》本文提供了GW和OT方法应用于QAP及其实际匹配问题（如机器学习和物流中的匹配问题）的理论基础、计算见解和实用指南。通过GW-MultiInit和相关方法，论文展示了如何高效地解决大规模且复杂的匹配问题，为实际应用提供了新的视角和方法。
## 568. `cs.LG` - COBRA: Multimodal Sensing Deep Learning Framework for Remote Chronic Obesity Management via Wrist-Worn Activity Monitoring [PDF](https://arxiv.org/pdf/2509.04210), [HTML](https://arxiv.org/abs/2509.04210)
### Authors
Zhengyang Shen(1),Bo Gao(1),Mayue Shi(1, 2) ((1) Department of Electrical and Electronic Engineering, Imperial College London, UK, (2) Institute of Biomedical Engineering, University of Oxford, UK)
### Background
慢性肥胖管理需要持续监测能量平衡行为，但传统的自我报告方法存在显著的应报不足和回忆偏见，以及与现代数字健康系统集成的困难。腕戴式多模态传感器可提供客观的行为监测，但缺乏有效的处理办法。
### Innovation
提出了COBRA（慢性肥胖行为识别架构），这是一种使用腕戴式多模态传感器的新型深度学习框架，用于客观行为监测。该框架结合了U-Net空域建模、多头自注意力机制和双向LSTM时序处理，能够将日常活动分类为与肥胖相关的四大类：食物摄入、体力活动、久坐行为和日常生活。通过WISDM-Smart数据集进行了验证。
### Conclusion
COBRA预处理策略包括频域时空特征提取，展现出高性能。D-Net展示了96.86%的总体准确率，各类别的F1分数分别为98.55%（体力活动）、95.53%（食物摄入）、94.63%（久坐行为）和98.68%（日常生活），其性能优于基准线。该架构展现了良好的泛化能力，用于定制化肥胖干预和个人化的生活方式监测。
## 569. `cs.LG` - 使用UKF结合基础模型实现零样本状态估计 [PDF](https://arxiv.org/pdf/2509.04213), [HTML](https://arxiv.org/abs/2509.04213)
### Authors
Tobin Holtmann,David Stenger,Andres Posada-Moreno,Friedrich Solowjow,Sebastian Trimpe
### Background
传统的控制和系统工程中的状态估计需要大量的手动系统识别或数据收集工作。然而，在其他领域，基于变换器的基础模型通过利用预训练的一般模型已经减少了数据需求。最终，开发能够实现系统动力学零样本的基础模型可以大幅减少手动部署的工作量。最近的一些研究显示基于变换器的端到端方法可以在未见过的系统上实现零样本性能，但它们仍然受到在训练期间仅见过传感器模型的限制。因此，有必要提出一种新的方法来解决这个问题。
### Innovation
提出了基础模型无迹卡尔曼滤波器（FM-UKF），将基于变换器的动力学模型与通过UKF结合的已知传感器模型结合起来，可以在不同的动力学情况下进行一般化，而无需为新的传感器配置重新训练。这一创新方法在具有复杂动力学的集装箱船模型基准上进行了评估，展示了与经典方法相比更具有竞争力的准确度、工作量和鲁棒性。
### Conclusion
通过FM-UKF，研究人员展示了在零样本状态估计方面有了显著的进步。该基准和数据集已开源，以支持未来在基础模型实现零样本状态估计方面的研究。
## 570. `cs.LG` - 分离式实体表示学习用于 Pinterest 广告排名 [PDF](https://arxiv.org/pdf/2509.04337), [HTML](https://arxiv.org/abs/2509.04337)
### Authors
Jie Liu,Yinrui Li,Jiankai Sun,Kungang Li,Han Sun,Sihan Wang,Huasen Wu,Siyuan Gao,Paulo Soares,Nan Li,Zhifang Liu,Haoyang Li,Siping Ji,Ling Leng,Prathibha Deshikachar
### Background
为了有效提供个性化的产品推荐和广告，Pinterest 寻找一种新的框架来从多种数据源构建用户和物品的嵌入表示。传统的实时嵌入计算方法在处理大规模数据时难以保持高效性和可扩展性，因此需要一种新的方法来应对这个问题。
### Innovation
提出了一种新的框架，采用上游-下游的范式从多种数据源构建用户和物品的嵌入表示，通过训练复杂的上游模型捕捉用户和物品之间的复杂关系。此外，通过学习和定期刷新实体嵌入而非进行实时计算，保证了上游和下游模型之间的异步交互，提高了模型的实时性和可扩展性。这些嵌入被用于多个下游任务，包括广告检索和点击率（CTR）及转化率（CVR）预测模型。该框架在Pinterest的生产广告排名系统中的部署显示了显著的性能提升和在线指标的改进。
### Conclusion
通过建立该新框架，Pinterest 在多种下游任务中获得了显著的性能改进，并在生产系统中实施后得到了重要的在线指标收益。
## 571. `cs.LG` - 反馈增强学习、测试时尺度调整与扩散指导之间的联系：汇编 [PDF](https://arxiv.org/pdf/2509.04372), [HTML](https://arxiv.org/abs/2509.04372)
### Authors
Yuchen Jiao,Yuxin Chen,Gen Li
### Background
本文反思了广泛使用的后训练技术之间的几个基本连接。讨论了内部反馈增强学习、从人类反馈中学习的增强学习、以及测试时的尺度调整（特别是软最佳-of-N抽样）之间的密切关系和等价性，还阐明了扩散指导与测试时的尺度调整之间固有的联系。
### Innovation
引入了重新采样方法用于对齐和奖励导向的扩散模型，避免了明确使用强化学习技术的需要。
### Conclusion
本文细化了一些与后训练技术和强化学习相关的技术之间的联系，同时也引入了一种新的重新采样方法，增强模型的效果和效率。
## 572. `cs.LG` - PARCO: 通过对比实体消歧增强的音素增强鲁棒上下文ASR [PDF](https://arxiv.org/pdf/2509.04357), [HTML](https://arxiv.org/abs/2509.04357)
### Authors
Jiajun He,Naoki Sawada,Koichi Miyazaki,Tomoki Toda
### Background
自动语音识别（ASR）系统在处理特定领域的命名实体，特别是同音词方面面临挑战。虽然上下文ASR可以改善识别效果，但在有限的实体多样性下，往往无法捕捉到细微的音素变化。此外，先前的方法将实体视为独立的令牌，导致多令牌偏见不完整。
### Innovation
本文提出了一种新的方法Phoneme-Augmented Robust Contextual ASR via COntrastive entity disambiguation（PARCO），该方法通过音素感知编码、对比实体消歧、实体级别监督和分层实体过滤，增强音节鉴别，确保实体检索的完整性，并在不确定性下减少误检。实验结果显示，PARCO在中文AISHELL-1和英语DATA2数据集上分别实现了4.22%的CER和11.14%的WER，显著优于基线方法。PARCO还展示了在THCHS-30和LibriSpeech等外部领域数据集上的鲁棒改进效果。
### Conclusion
PARCO方法在处理特定领域的人名实体识别方面显著优于现有的基线方法，特别是在同音词和强干扰环境下表现出色。
## 573. `cs.LG` - AUDETER: 开放世界中的深度伪造音频检测的数据集 [PDF](https://arxiv.org/pdf/2509.04345), [HTML](https://arxiv.org/abs/2509.04345)
### Authors
Qizhou Wang,Hanxun Huang,Guansong Pang,Sarah Erfani,Christopher Leckie
### Background
语音生成系统能够产生极具真实感的语音，很多时候难以与人类语音区分，这带来了真实性方面的挑战。尽管已经开发了多种深度伪造检测方法，但在现实世界环境中的有效性仍然难以保证，因为训练样本与测试样本之间存在领域差异。当前的数据库缺乏多样性和更新的实时和伪造音频，无法充分应对这些挑战。因此，需要一个包含大量多样性和更新音频的大型数据库来评估和开发通用化的深度伪造音频检测模型。
### Innovation
作者提出了一个名为AUDETER的大型多变深度伪造音频数据集，用于全面评估和开发通用化的深度伪造音频检测模型。它包含了超过4500小时由11个最近的文本到语音（TTS）模型和10个语音编解码器（vocoder）生成的合成音频，总数达300万条音频剪辑，是最大的深度伪造音频数据集。通过实验表明，现有最先进方法在AUDETER上的表现显著优于在现有数据集上训练的方法，降低了检测错误率，并在流行的数据集In-the-Wild上也表现出色，错误率降低至只有4.17%。 
### Conclusion
AUDETER数据库为训练通用化的深度伪造音频检测器铺平了道路，有力地证明了其在实际应用中的潜力。
## 574. `cs.LG` - 虚拟试衣间：从单张图片生成任意长度的虚拟试穿视频 — 技术预览 [PDF](https://arxiv.org/pdf/2509.04450), [HTML](https://arxiv.org/abs/2509.04450)
### Authors
Jun-Kun Chen,Aayush Bansal,Minh Phuoc Vo,Yu-Xiong Wang
### Background
该研究介绍了虚拟试衣间（VFR），这是一种新颖的视频生成模型，可以生成任意长度的虚拟试穿视频。传统的生成连续视频的过程往往消耗大量资源，并且需要较长的视频数据。本研究通过一种自回归、逐段生成的过程解决了这些问题，同时还能生成任意长度的视频。研究中的关键挑战是确保相邻视频片段之间的局部平滑性和不同的视频片段之间的全球时间一致性。
### Innovation
该研究提出了一种新的生成模型VFR，通过前缀视频条件确保了视频片段之间的平滑性，并通过锚视频（全面捕捉人体全身外观的360度视频）确保了不同片段之间的时间一致性。这种方法使得能够在多种动作下生成具有局部平滑性和全球时间一致性的分钟级虚拟试穿视频，从而成为长视频虚拟试穿视频生成的开创性工作。
### Conclusion
本研究表明，VFR框架能够生成较长的虚拟试穿视频，并且这些视频在局部平滑性和全局时间一致性方面表现良好，为虚拟试衣技术提供了新的解决方案，具有重要的理论和应用价值。
## 575. `cs.LG` - ArcMemo：具终身LLM记忆的抽象推理组合 [PDF](https://arxiv.org/pdf/2509.04439), [HTML](https://arxiv.org/abs/2509.04439)
### Authors
Matthew Ho,Chen Si,Zhaoxiang Feng,Fangxu Yu,Zhijian Liu,Zhiting Hu,Lianhui Qin
### Background
在推理时间进行缩放后，语言模型可以进行越来越长且复杂的推理，但这些推理过程中的发现会随着上下文窗口的重置被立即丢弃。外部存储可以持久保存这些发现，此前的研究已经展示了在推理密集型任务中利用外部存储的明显好处。本文提出了一种将基于实例的记忆扩展到概念级记忆的方法，即通过从解答轨迹中提取和存储自然语言形式的可重用、模块化抽象来使记忆更加广泛和可扩展。
### Innovation
本文设计了一种新的抽象推理组合方法——ArcMemo，它从推理过程中提取概念级别的抽象，并将其存储为自然语言形式的记忆。这种方法在问题解决中表现出色，在ARC-AGI基准测试中，与无记忆基线相比，取得了7.5%的相对增益，且性能随着推理计算量的增加而继续提升。这种方法还表明，动态更新测试时间的记忆性能优于固定记忆设置，进一步支持了通过解决问题和提取模式来进一步解决更多问题的自我改进假说。
### Conclusion
本文提出的方法在问题解决中取得了显著的性能提升，特别是在具有挑战性的ARC-AGI基准测试中。通过从推理体验中提取抽象概念，记忆能够更广泛地被重用，并随着经验的积累而扩展。此外，动态更新记忆的策略在测试时间的性能优于固定记忆设置，进一步证明了记忆在促进语言模型自我改进方面的价值。
## 576. `cs.LG` - SAFE--MA--RRT: 多智能体数据驱动安全性证书下的运动规划 [PDF](https://arxiv.org/pdf/2509.04413), [HTML](https://arxiv.org/abs/2509.04413)
### Authors
Babak Esmaeili,Hamidreza Modares
### Background
本文提出了一种针对具有共享障碍物工作空间的同质线性多智能体系统的完全数据驱动运动规划框架，这些系统无法访问显式系统模型。每个智能体通过求解凸半定规划独立地从实验数据中学习其闭环行为，生成局部不变椭球及其对应的状态反馈增益。这些椭球围绕基于网格的航定点进行调整，认证短程过渡的动力学可行性，并定义安全运行区域。基于采样规划器构造了一棵树形航点，只有当相邻椭球重叠时才允许过渡，以确保从不变到不变的过渡和连续安全性。所有智能体同时扩展它们的树，并通过空间时间预订表协调，以通过预防同时占用和迎面碰撞来确保智能体之间安全性。树中每个成功边都配备了自己独立的局部控制器，使运行时无需重新解决优化问题即可执行。生成的轨迹不仅在动力学上可行，而且在环境约束条件和智能体间碰撞方面具有可证明的安全性。模拟结果表明，该方法能够在共享动力学和约束条件下有效合成多个智能体同步安全轨迹，仅使用数据和凸优化工具。
### Innovation
提出的框架完全依赖于数据，无需显式系统模型；每个智能体通过求解凸半定规划独立学习闭环行为；生成的椭圆体验证了动态可行性，并定义了安全运行区域；基于采样规划器构建树形航点，确保从不变态到不变态的连续安全性；智能体通过空间时间预订表相互协调，防止碰撞；智能体树中成功边可配备独立局部控制器，确保运行时不需要重新解决优化问题；生成的轨迹在动力学和安全方面具有可证明性，仅依赖数据和凸优化工具实现多智能体同步安全轨迹生成.
### Conclusion
该方法在共享障碍物工作空间中，仅使用数据和凸优化工具，有效生成多智能体同步安全轨迹。智能体通过学习实验数据独立生成闭环行为及其安全边界，并通过空间时间协调防止智能体碰撞，从而实现既动力学上可行又安全的轨迹生成。
## 577. `cs.LG` - 超越亲和性的稳固图结构学习：基于保邻相似性的方法 [PDF](https://arxiv.org/pdf/2401.09754), [HTML](https://arxiv.org/abs/2401.09754)
### Authors
Yulin Zhu,Yuni Lai,Xing Ai,Wai Lun LO,Gaolei Li,Jianhua Li,Di Tang,Xingxing Zhang,Mengpei Yang,Kai Zhou
### Background
尽管基于图的学习系统在处理结构化数据方面取得了巨大成功，但它们在同质图数据上的脆弱性已被广泛研究，即攻击者故意修改原始图数据的姿态和拓扑信息以降低预测性能。对于异质图数据，基于图的学习系统的安全性仍是一个未知领域。本文旨在探索基于图的学习系统的脆弱性，而不考虑其亲和力程度。
### Innovation
本文理论证明了负分类损失的更新与基于幂聚合邻域特征的成对相似性呈负相关，基于此，提出了一种新颖的稳健图结构学习策略。该策略包含一个双kNN图构建管道来监督邻域相似性保留传播，并使用图卷积层根据节点对的丰富局部结构适应性地平滑或区分节点特征。这种方法在不同的图亲和性和异质图的原始图数据中可以挖掘出更好的拓扑结构，实现更可靠的数据管理。
### Conclusion
本文研究了基于图的学习系统的脆弱性，无论亲和力程度如何，并提出了一种新颖的稳健图结构学习策略，适用于同质和异质图。通过保邻相似性策略，该方法能够在多种条件下实现更可靠的拓扑结构学习。
## 578. `cs.LG` - 库塞尔内核和Volterra级数 [PDF](https://arxiv.org/pdf/2212.14641), [HTML](https://arxiv.org/abs/2212.14641)
### Authors
Lukas Gonon,Lyudmila Grigoryeva,Juan-Pablo Ortega
### Background
本文构建了一个通用内核，该内核的截面可以逼近任何具有有限维欧几里得空间输入和输出的具有因果性和时不变性的模糊记忆滤波器。内核是通过与Volterra级数扩展中的状态空间表示相关的蓄水池函数构造的，因此称为Volterra蓄水池核。尽管状态空间表示和相应的蓄水池特征映射定义在无限维张量代数空间上，但在使用代表定理解决估计问题时，内核映射由易于计算的显式递归定义。该研究展示了Volterra蓄水池内核在涉及多个维度的非线性学习任务中对金融资产收益的条件协方差预测的实证性能，并将其与标准静态和顺序内核进行了比较。
### Innovation
本文的主要创新点在于构造了一个通用的内核——Volterra蓄水池核，该内核可以近似任何具有模糊记忆性的滤波器。内核通过Volterra级数的状态空间表示中的蓄水池函数构建，解决了分析上定义在无限维空间上的计算问题，并在实际数据集上展示了该内核的有效性。
### Conclusion
实证研究结果表明，Volterra蓄水池核在处理多维和高度非线性的金融资产收益条件协方差预测任务中表现良好，并且其性能优于其他标准的静态和顺序内核。
## 579. `cs.LG` - 用另一种语言提问会产生什么影响？衡量不同语言间的功能相似性 [PDF](https://arxiv.org/pdf/2509.04032), [HTML](https://arxiv.org/abs/2509.04032)
### Authors
Debangan Mishra,Arihant Rastogi,Agyeya Negi,Shashwat Goel,Ponnurangam Kumaraguru
### Background
研究不同语言模型输出之间的相似性，尤其是在多语言环境下模型的一致性和可靠性。
### Innovation
提出了使用一个新的模型相似性度量 $boldsymbol{boldsymbol{boldsymbol{boldsymbol{boldsymbol{boldsymbol{boldsymbol{boldsymbol{boldsymbol{boldsymbol{boldsymbol{boldsymbol{boldsymbol{boldsymbol{boldsymbol{boldsymbol{boldsymbol{boldsymbol{boldsymbol{boldsymbol{boldsymbol{boldsymbol{boldsymbol{boldsymbol{boldsymbol{boldsymbol{boldsymbol{boldsymbol{boldsymbol{boldsymbol{boldsymbol{boldsymbol{boldsymbol{boldsymbol{boldsymbol{boldsymbol{boldsymbol{boldsymbol{boldsymbol{boldsymbol{boldsymbol{boldsymbol{boldsymbol{boldsymbol{boldsymbol{boldsymbol{boldsymbol{boldsymbol{boldsymbol{boldsymbol{boldsymbol{boldsymbol{boldsymbol{boldsymbol{boldsymbol{boldsymbol{boldsymbol{boldsymbol{boldsymbol{boldsymbol{boldsymbol{boldsymbol{boldsymbol{boldsymbol{boldsymbol{boldsymbol{boldsymbol{boldsymbol{boldsymbol{boldsymbol{boldsymbol{boldsymbol{boldsymbol{boldsymbol{boldsymbol{boldsymbol{boldsymbol{boldsymbol{boldsymbol{boldsymbol{boldsymbol{boldsymbol{boldsymbol{boldsymbol{boldsymbol{boldsymbol{boldsymbol{boldsymbol{boldsymbol{boldsymbol{boldsymbol{boldsymbol{boldsymbol{boldsymbol{boldsymbol{boldsymbol{boldsymbol{boldsymbol{boldsymbol{boldsymbol{boldsymbol{boldsymbol{boldsymbol{boldsymbol{boldsymbol{boldsymbol{boldsymbol{boldsymbol{boldsymbol{boldsymbol{boldsymbol{boldsymbol{boldsymbol{boldsymbol{boldsymbol{boldsymbol{boldsymbol{boldsymbol{boldsymbol{boldsymbol{boldsymbol{boldsymbol{boldsymbol{boldsymbol{boldsymbol{boldsymbol{boldsymbol{boldsymbol{boldsymbol{boldsymbol{boldsymbol{boldsymbol{boldsymbol{boldsymbol{boldsymbol{boldsymbol{boldsymbol{boldsymbol{boldsymbol{boldsymbol{boldsymbol{boldsymbol{boldsymbol{boldsymbol{boldsymbol{boldsymbol{boldsymbol{boldsymbol{boldsymbol{boldsymbol{boldsymbol{boldsymbol{boldsymbol{boldsymbol{boldsymbol{boldsymbol{boldsymbol{boldsymbol{boldsymbol{boldsymbol{boldsymbol{boldsymbol{boldsymbol{boldsymbol{boldsymbol{boldsymbol{boldsymbol{boldsymbol{boldsymbol{boldsymbol{boldsymbol{boldsymbol{boldsymbol{boldsymbol{boldsymbol{boldsymbol{boldsymbol{boldsymbol{boldsymbol{boldsymbol{boldsymbol{boldsymbol{boldsymbol{boldsymbol{boldsymbol{boldsymbol{boldsymbol{boldsymbol{boldsymbol{boldsymbol{boldsymbol{boldsymbol{boldsymbol{boldsymbol{boldsymbol{boldsymbol{boldsymbol{boldsymbol{boldsymbol{boldsymbol{boldsymbol{boldsymbol{boldsymbol{boldsymbol{boldsymbol{boldsymbol{boldsymbol{boldsymbol{boldsymbol{boldsymbol{boldsymbol{boldsymbol{boldsymbol{boldsymbol{boldsymbol{boldsymbol{boldsymbol{boldsymbol{boldsymbol{boldsymbol{boldsymbol{boldsymbol{boldsymbol{boldsymbol{boldsymbol{boldsymbol{boldsymbol{boldsymbol{boldsymbol{boldsymbol{boldsymbol{boldsymbol{boldsymbol{boldsymbol{boldsymbol{boldsymbol{boldsymbol{boldsymbol{boldsymbol{boldsymbol{boldsymbol{boldsymbol{boldsymbol{boldsymbol{boldsymbol{boldsymbol{boldsymbol{boldsymbol{boldsymbol{boldsymbol{boldsymbol{boldsymbol{boldsymbol{boldsymbol{boldsymbol{boldsymbol{boldsymbol{boldsymbol{boldsymbol{boldsymbol{boldsymbol{boldsymbol{boldsymbol{boldsymbol{boldsymbol{boldsymbol{boldsymbol{boldsymbol{boldsymbol{boldsymbol{boldsymbol{boldsymbol{boldsymbol{boldsymbol{boldsymbol{boldsymbol{boldsymbol{boldsymbol{boldsymbol{boldsymbol{boldsymbol{boldsymbol{boldsymbol{boldsymbol{boldsymbol{boldsymbol{boldsymbol{boldsymbol{boldsymbol{boldsymbol{boldsymbol{} boldsymbol{boldsymbol{boldsymbol{boldsymbol{boldsymbol{boldsymbol{boldsymbol{boldsymbol{boldsymbol{boldsymbol{boldsymbol{boldsymbol{boldsymbol{boldsymbol{boldsymbol{boldsymbol{boldsymbol{boldsymbol{boldsymbol{boldsymbol{boldsymbol{boldsymbol{boldsymbol{boldsymbol{boldsymbol{boldsymbol{boldsymbol{boldsymbol{boldsymbol{boldsymbol{boldsymbol{boldsymbol{boldsymbol{boldsymbol{boldsymbol{boldsymbol{boldsymbol{} boldsymbol k}_{p}}}$}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}{之间的相似度，具体研究了19种语言和47个主题在GlobalMMLU数据集中的模型输出一致性。
### Conclusion
研究结果揭示了模型大小和能力增加时输出的一致性增强，并突显了$boldsymbol k_{p}$作为评估多语言可靠性的实用工具的有效性及指导开发更一致的多语言系统的潜在价值。
## 580. `cs.LG` - 使用AI基础模型微调开发亚网格尺度参数化：大气重力波案例研究 [PDF](https://arxiv.org/pdf/2509.03816), [HTML](https://arxiv.org/abs/2509.03816)
### Authors
Aman Gupta,Aditi Sheshadri,Sujit Roy,Johannes Schmude,Vishal Gaur,Wei Ji Leong,Manil Maskey,Rahul Ramachandran
### Background
全球气候模型参数化了诸如重力波、云、湿对流和湍流等无法充分解析的大气-海洋过程。未解决过程的亚网格尺度闭合是模型不确定性的主要来源。在此之前，AI基础模型在气候研究中的应用尚未被广泛探索。本研究利用了一个预训练的23亿参数AI基础模型（NASA和IBM Research的Prithvi WxC），该模型包含气象演变的潜在概率表示，通过对该模型进行微调以创建大气重力波的深度学习参数化模型。这种方法通过学习细分辨率大气再分析资料中的通量，为粗分辨气候模型捕捉重力波效应。
### Innovation
本创新方法利用预训练的AI基础模型来开发大气重力波的亚网格尺度参数化模型。这种方法通过对一个23亿参数的预训练模型（Prithvi WxC）进行微调，创建了一个能够捕捉重力波效应的深度学习参数化模型。这种模型能够通过学习细分辨率大气再分析资料中的通量，为粗分辨气候模型捕捉重力波效应，即使是在预训练数据中未包括的区域也能显著提高预测性能。
### Conclusion
本研究强调了AI基础模型的多功能性和可重用性，这些模型能够用于多种大气和气候相关的应用。通过数据驱动和物理准确的参数化，这种方法有望为更多地球系统过程创建更精确的参数化模型。
## 581. `cs.LG` - Moco: 可学习的元优化器 [PDF](https://arxiv.org/pdf/2402.04915), [HTML](https://arxiv.org/abs/2402.04915)
### Authors
Tim Dernedde,Daniela Thyssens,Sören Dittrich,Maximilian Stubbemann,Lars Schmidt-Thieme
### Background
组合优化问题（COPs）通常被认为是NP难的问题。过去，这些问题主要通过手工构造的启发式方法解决，但随着神经网络的进步，人们开始开发从数据中学习启发式方法的一般方法。许多方法利用神经网络直接构建解决方案，但在推理阶段，这些方法在基于已构建的解决方案进行进一步改进方面很有限。本文通过定义一个由单个连续向量$theta$（称为热图）引导的轻量级解决方案构建过程，并让神经网络在推理阶段针对单个COP实例更新$theta$，提出了一种名为Moco的方法。
### Innovation
Moco定义了一种由单个连续向量$theta$（称为热图）引导的轻量级解决方案构建过程，并通过学习神经网络来更新$theta$。更新基于当前搜索状态的各种特征。通过预算感知的训练过程，Moco旨在在整个搜索中找到总体最佳解决方案。Moco是一个完全可学习的元优化器，不使用特定问题的启发式或需要在训练中使用最优解。
### Conclusion
我们对旅行商问题（TSP）和最大独立集（MIS）进行了Moco的测试，并展示了它在热图方法中显著的改进。
## 582. `cs.LG` - 不确定性引导的概率路径搜索 [PDF](https://arxiv.org/pdf/2407.03951), [HTML](https://arxiv.org/abs/2407.03951)
### Authors
Julia Grosse,Ruotian Wu,Ahmad Rashid,Cheng Zhang,Philipp Hennig,Pascal Poupart,Agustinus Kristiadi
### Background
树搜索是规划中的基本工具，很多序列决策问题都可以被构建成树结构的空间搜索问题。由于树的大小存在组合爆炸，能够获取奖励的路径集合稀疏，特别是在通过昂贵的评估（如查询大型语言模型）获得概率时，这一问题更为显著。
### Innovation
提出了一种基于likelihood规律性假设的概率搜索启发式算法，用于具有log-likelihood奖励函数的设置。与现有的树搜索方法不同，该方法可以在不进行昂贵的展开或复杂的贝叶斯推理的情况下，执行回溯并权衡探索与开采之间的交易。
### Conclusion
通过对及时、大规模的实际应用进行广泛的在模和离模实验，证明了该方法能够在较少的昂贵评估情况下，识别出具有高概率的路径。
## 583. `cs.LG` - Unisolver: PDE-Conditional Transformers Towards Universal Neural PDE Solvers [PDF](https://arxiv.org/pdf/2405.17527), [HTML](https://arxiv.org/abs/2405.17527)
### Authors
Hang Zhou,Yuezhou Ma,Haixu Wu,Haowen Wang,Mingsheng Long
### Background
近期，深度学习模型已经成为解决偏微分方程(PDEs)的一种有前途的工具，被称为神经PDE求解器。虽然这些求解器可以通过模拟数据或物理激励损失来进行训练，并能较好地解决PDEs，但它们通常只适用于少数几种PDE实例，例如具有特定系数的一类方程。这就限制了它们对各种PDEs的泛化能力，使得它们难以成为数值求解器的实用替代模型。
### Innovation
本文提出了一种名为Unisolver的新颖Transformer模型，该模型在多样化的数据上进行训练，并针对多样化的PDEs进行条件化，旨在成为一个通用神经PDE求解器，能够解决广泛的PDEs。Unisolver是从PDE求解过程的理论分析中衍生出来的，不受单纯扩大数据和参数数量的限制。该模型受到PDEs数学结构的启发，即PDE解本质上由一系列PDE组件（如方程符号和边界条件）来管理，因此定义了一整套PDE组件，并且能够灵活嵌入到Transformer PDE求解器中，以实现域内和点对点的深度条件。将物理洞察与最近的Transformer进展相结合，Unisolver在三个具有挑战性的大规模基准测试中均实现了持续的最新技术水平，展示了出色的性能和泛化能力。
### Conclusion
Unisolver在三个具有挑战性的大规模基准测试中均实现了持续的最新技术水平，并在所有三个测试中表现出色，展示了其在性能和泛化能力上的显著优势。
## 584. `cs.LG` - LLM为基础的偏好评估中的长度偏差解释 [PDF](https://arxiv.org/pdf/2407.01085), [HTML](https://arxiv.org/abs/2407.01085)
### Authors
Zhengyu Hu,Linxin Song,Jieyu Zhang,Zheyuan Xiao,Tianfu Wang,Zhengyu Chen,Nicholas Jing Yuan,Jianxun Lian,Kaize Ding,Hui Xiong
### Background
在使用大规模语言模型（LLMs）作为裁判，尤其是在偏好比较中，已经变得非常普遍。然而，这揭示了对较长回答的偏好偏向，从而削弱了这些评估的可靠性。这种偏向需要更好地理解，以便制定更可靠的评估标准，不被回复长度所混淆。因此，研究者试图通过分解偏好评估指标来解决这个问题，并引入了一个新的调整方法AdapAlpaca来减少长度偏差对评估结果的影响。
### Innovation
本文提出了一种新的方法AdapAlpaca，它通过调整win rate指标来公平比较测试模型和参考模型的回复质量。这种方法通过对等长度区间对回复进行对齐，避免了回复长度对评估结果的影响，从而提供了一个无偏的、可靠的内容质量评估标准。此研究尝试通过受控实验来证明该方法的有效性。
### Conclusion
通过实验分析，本文发现回答长度对评估的影响主要是通过增加信息量来实现的。为了获取一个不被回复长度所混淆的内容质量评估指标，本文提出了AdapAlpaca方法。此方法通过使参考和测试模型的回复在同一长度区间内进行比较，可以公平地评估内容质量。
## 585. `cs.LG` - 基于源可靠性估计的检索增强生成 [PDF](https://arxiv.org/pdf/2410.22954), [HTML](https://arxiv.org/abs/2410.22954)
### Authors
Jeongyeon Hwang,Junyoung Park,Hyejin Park,Dongwoo Kim,Sangdon Park,Jungseul Ok
### Background
检索增强生成（RAG）是一种通过从外部数据库检索信息来增强大语言模型（LLMs）事实准确性的有效方法。但标准的RAG可能会因为仅依赖查询与文档的相关性来检索信息，而忽视了这些来源的异质可靠性，从而存在获取不准确信息的风险。
### Innovation
提出了一个新的基于源可靠性的多源RAG框架（RA-RAG），通过跨检查多个来源的信息来估计源可靠性，并使用加权多数投票（WMV）从最可靠和相关源中检索文档并整合信息，确保响应生成的可靠性和准确性。
### Conclusion
实验表明，RA-RAG在具有异质源可靠性的场景中始终优于基准方法，且随着源数量的增加，RA-RAG的效率也十分高效。此外，证实了RA-RAG能够估计现实世界来源的可靠性，展示了其实用性。
## 586. `cs.LG` - 通过证据理论量化神经网络的校准误差 [PDF](https://arxiv.org/pdf/2411.00265), [HTML](https://arxiv.org/abs/2411.00265)
### Authors
Koffi Ismael Ouattara,Ioannis Krontiris,Theo Dimitrakos,Frank Kargl
### Background
神经网络在关键应用中的部署需要具备可靠性、信心和不确定性，而传统的性能指标如准确率和精度未能充分捕捉这些因素，尤其在模型表现出过自信的情况下更加明显。
### Innovation
本文提出了一种新的框架，通过将主观逻辑纳入期望校准误差（ECE）的评估中，量化神经网络的可信度。这种方法通过聚类预测概率并使用适当的操作符融合意见，提供了对信任、不信任和不确定性的综合性度量。
### Conclusion
通过在MNIST和CIFAR-10数据集上的实验表明，此方法在后校准结果中展示了改进的可信度。提出的框架为人工智能模型提供了一种更易于解释和复杂的评估方式，尤其是适用于医疗保健和自主系统等敏感领域。
## 587. `cs.LG` - 长输入序列网络在长时序预测中的应用 [PDF](https://arxiv.org/pdf/2407.15869), [HTML](https://arxiv.org/abs/2407.15869)
### Authors
Chao Ma,Yikai Hou,Xiang Li,Yinggang Sun,Haining Yu
### Background
在长时间序列预测任务中，短固定长度输入是深度学习方法的主要瓶颈。延长输入长度会导致过拟合，迅速下降的准确性。研究发现，过拟合是时间序列中的多尺度模式耦合和当前模型固定聚焦尺度的组合反应。时间序列在不同尺度下表现出的模式反映了其多周期性质，每个尺度对应特定的周期长度。同时，令牌大小主要决定模型的行为，因为它决定了模型聚焦的尺度和可以容纳的上下文大小。
### Innovation
提出了一种新型的系列分解模块（MPSD）和多令牌模式识别神经网络（MTPR），使模型能够处理输入长度增加到原来10倍的输入。足够的上下文可以提升性能（最大38%的精度提升），分解方法提供较低的复杂度（0.22倍的成本）和高可解释性。
### Conclusion
这种思路解耦了时间序列的多尺度时间模式，并将每个模式与其对应的周期长度作为令牌大小建模。这样的方法可以显著提高模型在长时序预测任务中的性能，并提供低复杂度和高可解释性。
## 588. `cs.LG` - 基于语言模型编码的蛋白质序列生成扩散方法 [PDF](https://arxiv.org/pdf/2403.03726), [HTML](https://arxiv.org/abs/2403.03726)
### Authors
Viacheslav Meshchaninov,Pavel Strashnov,Andrey Shevtsov,Fedor Nikolaev,Nikita Ivanisenko,Olga Kardymon,Dmitry Vetrov
### Background
蛋白质序列设计通过离散扩散和自回归方法取得了显著进展，但连续扩散的潜力尚未被充分开发。现有研究主要集中在离散扩散和自回归方法上，而连续扩散方法由于其独特的优势被忽视了。本研究引入了DiMA框架，该框架基于蛋白质语言模型表示进行操作，通过系统探索架构和扩散组件的选择，该方法能够适用于不同规模的蛋白质编码器，从8M到3B参数不等，表明其具有广泛应用的潜力。通过多个蛋白质表示方法的广泛评估，DiMA展示了其在蛋白质序列生成方面的优越性能，显著优于现有的自回归模型、离散扩散模型和流匹配语言模型，并且还具有高度的条件生成功能，如蛋白质家族生成、基序支撑和折叠特异性序列设计等。
### Innovation
提出了DiMA模型，这是一种基于语言模型编码的连续扩散框架，能够在不同规模的蛋白质编码器上进行可靠的扩散过程。DiMA模型在单一架构和训练方法下，针对不同类型的蛋白质模型表示（包括ESM-2、ESMc、CHEAP和SaProt等）都能保持高性能表现。此外，该模型能够支持多种条件生成任务，展示了其广泛的适用性和灵活性。
### Conclusion
DiMA是一个适用于蛋白质序列生成的通用连续扩散框架，不仅提供了架构上的洞察，也为各种蛋白质设计应用场景提供了实践适用性。该研究强调了连续扩散方法在蛋白质科学领域的巨大潜力，为未来的深入研究提供了新视角。
## 589. `cs.LG` - 使用不变统计损失训练具有鲁棒性的多元和重尾分布隐式生成模型 [PDF](https://arxiv.org/pdf/2410.22381), [HTML](https://arxiv.org/abs/2410.22381)
### Authors
José Manuel de Frutos,Manuel A. Vázquez,Pablo Olmos,Joaquín Míguez
### Background
传统的隐式生成模型能够学习复杂的数据分布，但其训练过程中需要使用对抗判别器将真实数据与合成数据区分开来，这可能导致不稳定的训练动态和模式漏失问题。许多现实世界现象的数据仅能用重尾概率分布来正确描述，而传统的隐式方法难以有效捕捉这些分布的渐进行为。原始的不变统计损失（ISL）方法适用于一维数据集，但扩展到高维数据时会面临计算不可行和效果不佳的问题。
### Innovation
该研究引入了一种使用一般化帕累托分布（GPD）输入噪声的生成器，并将其与不变统计损失（Pareto-ISL）结合，能够在保留数据中心特征的同时准确建模分布的尾部。研究提出了一种新的损失函数，通过随机投影方法扩展了一维ISL方法，使其适应多元数据，同时保持计算上的可行性。此外，该研究探索了Pareto-ISL作为生成对抗网络（GANs）预训练技术，以防止模式崩溃，取得了令人鼓舞的结果，并且展示了其在不同超参数设置下的鲁棒性。
### Conclusion
实验结果表明，Pareto-ISL可以在高维和重尾分布中有效地生成数据，同时保留数据的中心特征，特别是在防止模式崩溃方面表现出色。该方法通过随机投影和新的损失函数定义，成功扩展了原始一维ISL方法，使之适用于多元数据，并且在多种超参数设置下表现出稳健性。
## 590. `cs.LG` - 平衡信号与方差：VLA流模型的自适应离线RL后训练 [PDF](https://arxiv.org/pdf/2509.04063), [HTML](https://arxiv.org/abs/2509.04063)
### Authors
Hongyin Zhang,Shiyuan Zhang,Junxi Jin,Qixin Zeng,Yifan Qiao,Hongchao Lu,Donglin Wang
### Background
基于流匹配的视觉-语言-行动（VLA）模型在通用机器人操作任务中表现出色，但在复杂下游任务中的动作准确性较差。一个重要原因是，这些模型依赖于模仿学习的后训练模式，难以深入理解数据质量分布特性，而强化学习（RL）在这方面表现出色。因此，本文提出了一种针对VLA流模型的离线RL后训练目标，并提出了一个高效的自适应离线RL微调算法——自适应强化流匹配（ARFM）。
### Innovation
通过在VLA流模型损失中引入自适应调整的缩放因子，构建了一个原理上的偏差-方差权衡目标函数，以最优控制RL信号对流损失的影响。ARFM自适应平衡了RL优势保留和发展流损失梯度方差控制，从而实现更稳定和高效的微调过程。广泛的仿真和真实世界实验结果表明，ARFM展示了出色的泛化、鲁棒性、少样本学习和连续学习性能。
### Conclusion
本文提出了一种高效的自适应离线RL微调算法——ARFM，以提高VLA流模型在复杂下游任务中的动作准确性，实验结果验证了该算法的有效性。
## 591. `cs.LG` - 带有标签间关系的多标签贝叶斯主动学习 [PDF](https://arxiv.org/pdf/2411.17941), [HTML](https://arxiv.org/abs/2411.17941)
### Authors
Yuanyuan Qi,Jueqing Lu,Xiaohao Yang,Joanne Enticott,Lan Du
### Background
多标签主动学习的一个主要挑战在于评估大量不确定标签的信息价值，同时考虑到标签间的内在相关性。现有研究要么需要大量的计算资源来利用这些相关性，要么未能充分探索标签间的依赖性。此外，实际情况中还存在因数据集分布不平衡而引起的固有偏差。现有方法需要改进以解决这些挑战。
### Innovation
本文提出了一种新的多标签主动学习策略，该策略通过逐步更新正向和负向相关矩阵来捕捉注释样本标签空间中的共现和分离关系，而非将标签视为单独的元素。此外，该模型还借助集成伪标签和β评分规则来处理数据不平衡问题，并引入多样性和综合评估不确定性。
### Conclusion
实验结果表明，本文提出的方法在四个实际数据集上取得了更可靠且优越的性能，相比现有多种方法具有显著优势。
## 592. `cs.LG` - MARS: Unleashing the Power of Variance Reduction for Training Large Models [PDF](https://arxiv.org/pdf/2411.10438), [HTML](https://arxiv.org/abs/2411.10438)
### Authors
Huizhuo Yuan,Yifeng Liu,Shuang Wu,Xun Zhou,Quanquan Gu
### Background
训练深度神经网络和大型模型对高效且可扩展的优化器提出了新的要求。尽管在过去十年中开发了多种减小方差的算法来加速凸性和非凸性环境中的随机优化，但在训练深度神经网络或大型语言模型方面，减小方差仍未取得广泛成功。因此，这一方法在现代人工智能领域仍未得到广泛青睐。
### Innovation
本文提出了一种统一的优化框架MARS（Make vAriance Reduction Shine），将预条件梯度方法与减小方差技术通过缩放的随机递归动量技术相结合。MARS框架中引入了基于AdamW、Lion和Shampoo的预条件梯度更新的三种实例。同时，还将所提出的算法与现有优化器进行对比。实验结果表明，MARS在训练GPT-2模型时明显优于AdamW。
### Conclusion
MARS在训练大型模型时能够有效利用减小方差的技术，从而获得更好的性能。
## 593. `cs.LG` - 基于科布体验式学习的通用代理及其在 Kaggle 数据科学竞赛中达到人类水平的性能 [PDF](https://arxiv.org/pdf/2411.03562), [HTML](https://arxiv.org/abs/2411.03562)
### Authors
Antoine Grosnit,Alexandre Maraval,Refinath S N,Zichao Zhao,James Dora,Giuseppe Paolo,Albert Thomas,Jonas Gonzalez,Abhineet Kumar,Khyati Khandelwal,Abdelhakim Benechehab,Hamza Cherkaoui,Youssef Attia El-Hili,Kun Shao,Jianye Hao,Jun Yao,Balázs Kégl,Jun Wang
### Background
人类专业知识通过迭代循环的互动、反思和内部模型更新形成，这是认知理论如科布的经验学习和维果茨基的最近发展区的核心内容。然而，当前的人工智能系统，尤其是大型语言模型，依赖于固定的预训练或僵化的流程，缺乏持续适应的机制。最近的研究在大型语言模型中识别出了早期的认知特征（反思、修订和自我纠正），表明其具有类似于人类体验式学习的基础元素。因此，关键问题是：是否可以设计出能够进行结构化、认知基础的自主学习的大型语言模型吗？
### Innovation
提出了基于科布学习循环与维果茨基最近发展区的计算框架，以实现自主代理的认知基础的支撑学习。该架构将外部环境交互和内在的内部反思/抽象功能分离，使代理能够在结构化环境中先学习，然后进行开放式的泛化。通过直接与人类在真实的 Kaggle 数据科学竞赛中进行比较，展示了其潜力。系统 Agent K 在 81 个任务中实现了完全自动化的数据科学代码生成，并取得了超过 Kaggle 大师（前 2% 的 20 万用户）的 Elo-MMR 分数 1694，显示了卓越的竞争力。
### Conclusion
该方法代表了通用人工智能向前迈出的重要一步，标志着首个成功整合科布和维果茨基启发的人类认知学习的 AI 系统的诞生。
## 594. `cs.LG` - 打破长时序预测中的上下文瓶颈 [PDF](https://arxiv.org/pdf/2412.16572), [HTML](https://arxiv.org/abs/2412.16572)
### Authors
Chao Ma,Yikai Hou,Xiang Li,Yinggang Sun,Haining Yu,Zhou Fang,Jiaxing Qu
### Background
长期时间序列预测对于经济、能源和交通等领域中规划与决策至关重要，需要长远的视角。然而，要有效处理长期序列，模型既需要高效，也需要有效。尽管近期进展提高了模型效率，但长期序列的有效利用仍是一个挑战，主要因为模型在面对长输入时容易过拟合，导致需要使用较短的输入长度来维持可接受的误差范围。因此，如何在保证效率的同时有效利用长序列是亟待解决的问题。
### Innovation
本文探讨了多尺度建模方法，并提出了Logsparse Decomposable Multiscaling (LDM)框架，以实现长序列的有效处理。LDM框架通过在时间序列中解耦不同尺度的模式，降低非平稳性，简化架构并通过紧凑的长输入表示提高效率，从而提高了预测性。实验结果表明，LDM不仅在长期预测基准中优于所有基线，还降低了训练时间和内存成本。
### Conclusion
本文提出了LDM框架，通过多尺度建模有效处理长序列，不仅提高了长期预测的性能，还减少了训练时间和内存成本。
## 595. `cs.LG` - 通过TD($Δ$)分割SARSA的动作值函数在不同时段 [PDF](https://arxiv.org/pdf/2411.14783), [HTML](https://arxiv.org/abs/2411.14783)
### Authors
Mahammad Humayoo
### Background
在多个 episodic 环境中，SARSA 基本方法被用来优化旨在最大化长期回报的策略。传统 SARSA 算法在实现方差和偏差的最佳平衡方面面临挑战，主要是由于它们依赖于单一且不变的折扣因子 ($boldsymbol{u}$)。这就需要一种改进现有的方法来增强 TD 降解方法 TD($boldsymbol{u}$)，现在将其应用于 SARSA 算法，称之为 SARSA($boldsymbol{u}$)，以实现更好的长期改进与学习效果的平衡。
### Innovation
该研究通过将 TD($boldsymbol{u}$) 方法应用于 SARSA 算法，提出 SARSA($boldsymbol{u}$)，从而在不同的时间尺度上分裂动作值函数，使得学习更加有效且具有一致性，尤其是在需要长期改善的情况下。实验结果显示，SARSA($boldsymbol{u}$) 在确定性和随机性环境中能够降低 SARSA 更新的偏差，加快收敛速度，尤其在密集奖励的 Atari 环境中表现优异。
### Conclusion
该研究提出了 SARSA($boldsymbol{u}$) 方法，该方法通过 TD($boldsymbol{u}$) 方法分割动作值函数，增强了 SARSA 的学习效率和一致性，特别是在长期回报优化方面。研究结果表明，在多种基准设置中，SARSA($boldsymbol{u}$) 在表式和深度学习环境中均优于现有的 TD 学习技术。
## 596. `cs.LG` - 利用潜动态条件扩散模型进行延迟容忍网络中服务质量度量的概率预测 [PDF](https://arxiv.org/pdf/2504.08821), [HTML](https://arxiv.org/abs/2504.08821)
### Authors
Jianhua Liu,Zheng Liu,Yu Xiang,Yanwen Qu
### Background
在维持和操作分组延迟网络（DTN）中，常用的QoS指标预测可以提升网络性能，包括减少延迟、提高吞吐量、优化能耗和增加可靠性。这类问题通常可以被表达为多变量时间序列预测问题，吸引了大量研究兴趣。传统的时间序列均值回归方法由于无法精确捕捉数据复杂性，导致在DTN中的路由等任务上表现不佳。
### Innovation
本文将DTN中的QoS指标预测问题表述为一个多变量时间序列的概率预测问题，并通过引进扩散模型并纳入非平稳和多模态数据的潜在时间动态来提高预测效果。实验表明，这种方法在效果上优于现有的流行的时间序列概率预测方法。
### Conclusion
提出的利用潜在动态条件扩散模型的方法在DTN的QoS指标预测中表现优异，通过量化预测的不确定性并捕捉非平稳和多模态数据的潜在时间动态，提高了预测的精度与可靠性。
## 597. `cs.LG` - 使用神经网络预测3D模型技术 [PDF](https://arxiv.org/pdf/2505.04241), [HTML](https://arxiv.org/abs/2505.04241)
### Authors
Grzegorz Miebs,Rafał A. Bachorz
### Background
准确估算生产时间对于有效的制造排程至关重要，但传统的依赖专家分析或历史数据的方法，在动态或定制化生产环境中往往表现不佳。
### Innovation
提出了一种数据驱动的方法，直接从具有暴露几何形状的产品3D模型中预测制造步骤及其持续时间。该方法通过将模型渲染成多个2D图像并利用受生成查询网络启发的神经网络，学习将几何特征映射到预定义生产步骤的时间预估中，平均绝对误差低于3秒，使得不同产品类型的规划更加容易。
### Conclusion
这种方法能够准确预测生产步骤的持续时间，适用于动态和定制化生产环境，简化了不同产品类型的规划工作。
## 598. `cs.LG` - 零样本泛化在库存管理中的应用：训练，然后估计并决策 [PDF](https://arxiv.org/pdf/2411.00515), [HTML](https://arxiv.org/abs/2411.00515)
### Authors
Tarkan Temizöz,Christina Imdahl,Remco Dijkman,Douniel Lamghari-Idrissi,Willem van Jaarsveld
### Background
部署深度强化学习（DRL）在实际库存管理中面临挑战，包括动态环境和不确定的问题参数，例如需求和提前期的分布。这些挑战突显了研究上的空白，指出需要一种统一的框架来建模和解决在参数不确定性下的序列决策问题。这项研究通过探索DRL在库存管理中的一个未被充分研究的领域即训练通用能力强的代理（GCAs）在无监督泛化（ZSG）下的适用性来应对这些挑战。在此框架下，GCAs设计为能够处理各种具有不同库存挑战的问题样本。而ZSG指的是无需重新训练就能成功应用于未知参数未见过的问题实例。我们提出了一个统一的超马尔可夫决策过程（Super-MDP）框架和名为Train, Estimate and Decide（TED）框架来训练和部署一个适合库存管理应用的GCAs。TED框架包括三个阶段：训练GCAs在不同问题样本上，部署过程中持续估计问题参数，以及基于这些估计做出决策。在考虑了周期回顾库存问题、损失销售情况、周期性需求模式和随机提前期，我们的训练代理Generally Capable Lost Sales Network (GC-LSN)在问题参数已知时始终优于传统的知名策略。此外，当需求和/或提前期分布未知且必须在部署过程中估计时，我们与在线学习方法进行了对比，这些方法提供最坏情况下的性能保证，而我们的GC-LSN策略与Kaplan-Meier估计器结合使用展示了更优秀的实际性能。
### Innovation
该项研究提出了一种统一的Super-MDP以及名为TED（Train, Estimate, and Decide）框架，旨在训练和部署适合各种库存管理挑战的通用能力强的代理（GCAs）。TED框架的三个阶段分别是训练、不断估计问题参数，以及基于这些估计做决策。其创新之处在于，GCAs被设计为能够处理各种不同问题样本，GC-LSN在已知参数的周期回顾库存问题场景中表现出色，且在未知参数需要估计的情况下优于其他方法，尤其是在采用Kaplan-Meier估计器的情况下表现出卓越的实际性能。
### Conclusion
我们的研究表明，GC-LSN策略配合适当的参数估计方法，能够显著提高库存管理的效果，特别是在需求和提前期未知且需要在不重新训练模型的情况下进行参数估计和决策时，这种策略能提供卓越的实际性能。
## 599. `cs.LG` - 如何发布我的大语言模型基准而不透露真实答案？ [PDF](https://arxiv.org/pdf/2505.18102), [HTML](https://arxiv.org/abs/2505.18102)
### Authors
Takashi Ishida,Thanawat Lodkaew,Ikko Yamane
### Background
发布大语言模型（LLM）基准时存在风险，可能会无意间或故意地用其来训练或选择模型。虽然通常的做法是将基准保持私有，由参与者提交模型或预测给组织者，但这仍然需要信任单一的组织，并可能通过反复查询导致测试集过拟合。
### Innovation
提出了一种方法，可以在不完全披露问题答案的情况下发布基准测试，同时仍然能够公开评估大语言模型。主要创新之处是通过准备多个逻辑上的正确答案并仅纳入其中一个作为解决方案，来引入随机性。这种方法降低了基准的最佳可能准确度（贝叶斯准确度）。这种方法不仅可以帮助避免透露真实答案，还能作为检测数据污染的测试手段。
### Conclusion
实验结果表明，该方法可以准确地在多种基准、模型和训练方法上检测数据污染。即使是非常强大的模型，都不应超过贝叶斯准确度，若超过该上限将是数据污染的强烈信号。
## 600. `cs.LG` - IC-Cache: 通过上下文缓存实现高效大型语言模型服务 [PDF](https://arxiv.org/pdf/2501.12689), [HTML](https://arxiv.org/abs/2501.12689)
### Authors
Yifan Yu,Yu Gan,Nikhil Sarda,Lillian Tsai,Jiaming Shen,Yanqi Zhou,Arvind Krishnamurthy,Fan Lai,Henry M. Levy,David Culler
### Background
大语言模型（LLMs）在多种应用中表现出色，但由于其资源需求大和高延迟，规模化服务它们颇具挑战性。实际上，超过70%的用户请求与现有的其他请求具有语义相似性，显示出请求之间知识转移的潜力。然而，简单地缓存和重用过去响应会导致质量问题大幅下降。因此，作者深入研究了如何在保证质量的前提下提高服务效率。
### Innovation
作者提出了IC-Cache，这是一种缓存系统，能够实现实时的LLM能力增强。IC-Cache通过利用大型模型的历史请求-响应对作为上下文示例，使小型LLM能够模仿甚至超越大型模型的组合能力（例如，推理），从而实现请求选择性卸载以降低成本和延迟。该系统通过考虑响应质量和服务负载，灵活地将请求路由到不同能力的LLMs之间，采用成本意识缓存重演机制，离线精炼示例质量，以最大化在线缓存的效用和效率。实验结果表明，IC-Cache可以将LLM服务吞吐量提高1.4-5.9倍，减少28-71%的延迟，而不影响响应质量。
### Conclusion
通过IC-Cache，作者成功实现了一种有效的方法来增强小型LLMs的性能，从而降低服务成本和延迟，同时保持高质量的响应。这种系统能够根据需求实时选择高收益的示例，并根据系统负载动态路由请求。
## 601. `cs.LG` - Extended Histogram-based Outlier Score (EHBOS), [PDF](https://arxiv.org/pdf/2502.05719), [HTML](https://arxiv.org/abs/2502.05719)
### Authors
Tanvir Islam
### Background
Histogram-Based Outlier Score (HBOS) 是一种广泛应用的异常检测方法，因其计算效率高和简单性而闻名。然而，它假设特征之间独立，这限制了其在特征之间存在互动的数据集中的异常检测能力。
### Innovation
本文提出了一种扩展后的 Histogram-Based Outlier Score (EHBOS)，通过引入二维直方图来捕捉特征对之间的相关性，从而提高了异常检测的准确性，特别是在特征互动对异常定义至关重要的情况下，EHBOS 显著提升了 ROC AUC 值。
### Conclusion
EHBOS 在多种基准数据集中表现出了优越性，特别是在特征互动中异常模式复杂的数据集上。EHBOS 可作为 HBOS 的有价值的扩展，提供了一种可以很好地建模复杂特征依赖关系的强大新工具，特别是在情境或关系异常起重要作用的数据集中。
## 602. `cs.LG` - 随机注意力是否足以进行序列建模？解构Transformer中的可训练组件 [PDF](https://arxiv.org/pdf/2506.01115), [HTML](https://arxiv.org/abs/2506.01115)
### Authors
Yihe Dong,Lorenzo Noci,Mikhail Khodak,Mufan Li
### Background
变压器架构是现代大型语言模型（LLMs）成功的关键，因为它能够仅通过梯度学习来预测下一个标记执行各种任务，包括数学推理、记忆和检索。尽管变压器的核心组件是自注意力机制，但研究者质疑性能提升是否主要归因于该机制，以及哪些方面归因于此。
### Innovation
研究引入了两种变异的变压器模型，其中的MLP层或注意力权重在初始化时被冻结。证明了具有固定键和查询权重的变压器模型的表达性结果，并设计了M DixT，一种完全随机注意力分数的架构，其信号传播稳定，解决了随机变压器中的深度扩展问题。通过M DixT的成功和失败，研究者进一步分离了每个变压器组件的贡献，包括注意力在上下文推理中的主要作用，以及MLP在知识存储中的作用。
### Conclusion
研究结果表明，变压器架构具有内置的归纳偏见，能够形成特定电路，即使没有可学习的关注权重也是如此。
## 603. `cs.LG` - 不依赖填充学习具有缺失值的表格数据：使用Transformer中增量特征分区 [PDF](https://arxiv.org/pdf/2504.14610), [HTML](https://arxiv.org/abs/2504.14610)
### Authors
Manar D. Samad,Kazi Fuad B. Akhter,Shourav B. Rabbani,Ibna Kowsar
### Background
现有的机器学习使用表数据集时，常常会因为随机填补缺失值而引起数据质量和数据驱动结果可靠性的担忧。本文旨在通过提出一个不依赖填补的增量注意学习（IFIAL）方法来解决这一问题，直接处理表数据而不进行填补或初始化缺失值。
### Innovation
本文提出了一种基于Transformer的IFIAL方法，该方法通过创建并适应一对注意力掩码，直接对表格数据进行处理，而无需填补缺失值或初始化。该方法通过增量学习重叠和固定大小的特征集，提高Transformer的效率和性能。实验结果表明，IFIAL在17种不同数据集上的平均分类性能排名优于11种最先进的学习方法，无论是否包含缺失值填补。进一步的实验表明，IFIAL在应对不同类型的缺失值和比率时表现的更为稳健，优于涉及缺失值填补的方法。此外，研究表明，对于所提出的增量学习，特征分区大小最好是原始特征空间的一半。
### Conclusion
本文提出的IFIAL方法是第一个可以不依赖于缺失值填补来深度学习表格数据的解决方案。该论文的源代码已公开，并在17种不同数据集上验证了该方法的有效性。
## 604. `cs.LG` - 联邦隔离森林在边缘物联网系统中的高效异常检测 [PDF](https://arxiv.org/pdf/2506.05138), [HTML](https://arxiv.org/abs/2506.05138)
### Authors
Pavle Vasiljevic,Milica Matic,Miroslav Popovic
### Background
近期，为解决用户隐私和嵌入式系统的效率问题，出现了如Python TestBed for Federated Learning Algorithms和MicroPython TestBed for Federated Learning Algorithms等联邦学习框架。此外，基于隔离森林的高效联邦异常检测算法FLiForest最近被开发出来，提供了一种低资源、无监督的方法，适用于边缘部署和持续学习。本文在此基础上，开发了一个基于隔离森林的温度异常检测系统，应用于MicroPython等资源受限的边缘设备和物联网系统，实验结果表明该系统在区分正常和异常读数方面的准确率超过96%，检测异常的精度超过78%，同时在模型训练期间内存使用量保持在160KB以下。这些结果证明了其适用于资源受限环境和边缘系统的适用性，同时遵循联邦学习的数据隐私和协作学习原则。
### Innovation
开发了一种基于隔离森林的温度异常检测系统，应用于MicroPython等资源受限的边缘设备和物联网系统，并结合了高效的联邦学习框架，提供了低资源、无监督的方法，适用于边缘部署和持续学习，实验结果表现优异，在资源受限环境下仍能保持高的准确率和精度。
### Conclusion
本文开发的基于隔离森林的温度异常检测系统适用于资源受限的边缘设备和物联网系统，其在区分正常和异常读数方面的高准确率和精度，以及低内存使用量，表明了系统在实际应用中的高性能，并且维护了联邦学习的原则，即数据隐私和协作学习。
## 605. `cs.LG` - 利用双重视角图表示学习缓解欺诈检测中的信息不平衡 [PDF](https://arxiv.org/pdf/2507.06469), [HTML](https://arxiv.org/abs/2507.06469)
### Authors
Yudan Song,Yuecen Wei(Co-first author),Yuhang Lu,Qingyun Sun,Minglai Shao,Li-e Wang,Chunming Hu,Xianxian Li,Xingcheng Fu
### Background
图表示学习因其强大的表征能力已经成为欺诈检测领域的主流方法。这种方法侧重于通过增强局部关联附近的信息捕捉来提升节点表示。然而，这种关注局部的交互方式导致了全局拓扑信息传播的不平衡，并且容易因为欺诈和正常节点之间的信息不平衡而在聚合过程中使节点特定信息被压倒。因此，当拓扑结构不平衡和欺诈者的行为对拓扑结构的伪装及身份特征的隐藏导致监督信息不平衡时，基于图神经网络（GNN）的欺诈检测面临问题。
### Innovation
基于统计验证，本文提出了一个新的双重视角图表示学习方法（MimbFD），以缓解欺诈检测中的信息不平衡问题。具体而言，设计了一个拓扑消息可达性模块，以获得高质量的节点表示，穿透欺诈者的伪装，缓解信息传播不足的问题。同时引入了一个局部混杂纠偏模块，调整节点表示，增强节点表示与标签之间的稳定关联，平衡不同类别的影响。
### Conclusion
我们对三个公开的欺诈数据集进行了实验，结果表明，MimbFD在欺诈检测中表现出色。
## 606. `cs.LG` - 将注意力机制集成到电力网络中：迈向透明预测 [PDF](https://arxiv.org/pdf/2507.03690), [HTML](https://arxiv.org/abs/2507.03690)
### Authors
Eloi Campagne,Itai Zehavi,Yvenn Amara-Ouali,Yannig Goude,Argyris Kalogeratos
### Background
可靠的电力需求预测对于保障电网稳定性和指导发电决策至关重要，特别是在现代系统分散和复杂性增加的情况下。尽管经典的统计模型如广义加性模型（GAMs）仍被广泛使用，但它们往往无法捕捉能源网络中的空间依赖性。图卷积神经网络（GNNs）提供了一种通过直接利用图拓扑结构来包含这种结构的原则性框架。本文评估了包括GCN、GraphSAGE、ChebConv、TAG、APPNP、TransformerConv和图注意网络（GAT和GATv2）等广泛的一系列GNN架构在法国和英国的实际电力消耗数据集上的性能。
### Innovation
本文评估了多种GNN架构在实际电力消耗数据集上的应用，并展示了在数据稀少的情况下，简单的模型（如GCN、SAGE或APPNP）通常优于复杂的替代模型。此外，本文还展示了通过时间和区域注意力权重分析揭示的季节性及气象变异性的时空交互模式。研究表明，尽管注意力机制不是万能的，但在存在显著空间依赖性时，它提供了重要的解释能力。另外，本文还证明了基于专家聚合策略的集成方法，尤其是自底向上的组合方法，可以显著提高预测的鲁棒性，并在两个数据集上达到了最新的性能。
### Conclusion
本文的研究结果突出了GNNs在准确和解释性预测中的双重潜力，并暗示通过简单架构与集成方法的结合可以为透明的能源分析提供实用的道路。
## 607. `cs.LG` - 行动值时间差分方法的学习状态值分析 [PDF](https://arxiv.org/pdf/2507.09523), [HTML](https://arxiv.org/abs/2507.09523)
### Authors
Brett Daley,Prabhat Nagarajan,Martha White,Marlos C. Machado
### Background
时间差分（TD）学习的标志是自举：使用价值预测来生成新的价值预测。大多数TD控制方法通过自举从单个动作价值函数（如Q学习和Sarsa）来学习策略。相比之下，关注从两个不对称价值函数中自举的方法——即首先学习状态价值作为学习动作价值的中间步骤——得到了较少的关注。虽然一些算法已经在先前的工作中进行过研究，但对于何时以及为什么选择学习两个价值函数而不是一个仍然不清楚。此外，这些方法的理论正确性也尚未明确。
### Innovation
本文对该类算法的家庭进行了收敛性和样本效率方面的分析。研究发现，在预测设置中，两种家庭都比期望的Sarsa更加高效，但在控制设置中，只有动作值学习方法能比Q学习提供更大的优势。此外，提出了一种新的动作值学习算法：正则化对战Q学习（RDQ），并在MinAtar基准测试中取得了显著的性能提升。
### Conclusion
本文研究表明，在控制问题中，AV学习方法相较于Q学习具有较大的优势。此外，提出了一种新的AV学习算法RDQ，该算法在MinAtar基准测试中表现出色。
## 608. `cs.LG` - 指纹一步走，从质谱生成新分子一大步 [PDF](https://arxiv.org/pdf/2508.04180), [HTML](https://arxiv.org/abs/2508.04180)
### Authors
Neng Kai Nigel Neo,Lim Jing,Ngoui Yong Zhau Preston,Koh Xue Ting Serene,Bingquan Shen
### Background
现有的从质谱生成新分子的方法通常采用两阶段流程：首先将质谱编码为分子指纹，然后解码这些指纹生成分子结构。研究者们采用MIST作为编码器和MolForge作为解码器，并利用额外的训练数据提高性能。
### Innovation
创新点在于，通过阈值处理每个指纹位的概率，专注于亚结构的存在。这种方法在MassSpecGym上表现突出，相较于之前的方法提高了十倍的性能，正确生成了28%的top-1和36%的top-10分子结构。
### Conclusion
该工作设置了一个强有力的基线，对未来从质谱生成新分子的研究具有重要的指导意义。
## 609. `cs.LG` - 递归奖励聚合 [PDF](https://arxiv.org/pdf/2507.08537), [HTML](https://arxiv.org/abs/2507.08537)
### Authors
Yuting Tang,Yivan Zhang,Johannes Ackermann,Yu-Jie Zhang,Soichiro Nishimori,Masashi Sugiyama
### Background
在强化学习（RL）中，将代理行为与特定目标对齐通常需要仔细设计奖励函数，当期望目标比较复杂时，这一过程会变得尤为挑战。本研究提出了一种替代方法，通过选择合适的奖励聚合函数来实现更为灵活的行为对齐，避免了必须修改奖励函数的需求。通过从代数视角重新审视马尔可夫决策过程（MDPs），研究表明贝尔曼方程可以从递归奖励的生成和聚合中自然地推导出来，这使得标准的折扣求和能够向其他递归聚合方式推广，例如折扣最大值和夏普比率等。此方法既适用于确定性环境也适用于随机环境，并能够与基于价值的方法和基于演员-评论家的方法无缝集成。实验结果表明，该方法能够有效优化多样化的目标，展示了其在实际应用中的灵活性和潜力。
### Innovation
本方法通过选择适当的奖励聚合函数来灵活地调整代理的行为，无需修改原有的奖励函数，从而简化了优化过程并提高了目标的实现效率。通过从代数角度探索MDPs，使得标准的折扣求和方法可以推广到其他类型的折扣聚合方法，比如折扣最大值和夏普比率。该方法在确定性与随机性的环境中都能实现无缝应用，并且兼容基于价值的方法和基于演员-评论家的方法。实验验证了该方法在优化多样目标方面的有效性及其在实际应用中的潜力。
### Conclusion
该研究提出了一种新的方法，通过选择合适的奖励聚合函数来实现强化学习中代理行为与目标的灵活对齐，并展示了其在优化多样化目标方面的有效性和潜在的实际应用价值。
## 610. `cs.LG` - UniExtreme：一种用于极端天气预报的通用基础模型 [PDF](https://arxiv.org/pdf/2508.01426), [HTML](https://arxiv.org/abs/2508.01426)
### Authors
Hang Ni,Weijia Zhang,Hao Liu
### Background
近期深度学习的进步推动了气象预报中基础模型（FMs）的发展，尽管如此，人们在使用基础模型进行极端天气事件的预测时仍面临挑战。当前的方法要么专注一般的天气模式，要么专注于某一类型的极端天气，而忽视了多样化极端天气事件在现实大气模式中的表现。这项工作旨在解决这一问题，并确定极端天气事件的两个关键特征：一是与正常天气模式在频谱上的差异，二是不同极端天气事件的层次驱动因素及其地理融合方式。
### Innovation
我们提出了一种名为UniExtreme的通用极端天气预报基础模型。该模型集成了两个关键模块：一是通过学习Beta分布滤波器和多粒度频谱聚合实现区域间的频谱差异捕捉的自适应频率模调节（AFM）模块；二是引入一种事件先验增强（EPA）模块，该模块通过双重记忆融合网络将区域特定的极端天气事件先验整合进来，以解决不同层次的极端多样性和复合极端模式问题。
### Conclusion
广泛的实验表明，UniExtreme在极端天气和常规天气预报方面都优于现有最先进的基准模型，展现出在各种不同极端情境下的卓越适应性。
## 611. `cs.LG` - RLVR深度广度协同：通过自适应探索释放大语言模型推理收益 [PDF](https://arxiv.org/pdf/2508.13755), [HTML](https://arxiv.org/abs/2508.13755)
### Authors
Zhicheng Yang,Zhijiang Guo,Yinya Huang,Yongxin Wang,Dongchun Xie,Yiwei Wang,Xiaodan Liang,Jing Tang
### Background
RLVR作为一种强大的范式，在为大型语言模型解锁推理能力方面表现突出，但其潜力受到两个未充分探索的维度的阻碍：深度（模型能解决的最困难问题）和广度（单次迭代中消耗的数据实例数量）。流行算法GRPO揭示出系统性偏差：累积优势过度偏向中等准确度的样本，而减少低准确度样本的权重，这些样本对于推动推理边界至关重要。
### Innovation
引入了难度自适应采样（DARS），通过多阶段采样重新加权困难问题，增加困难问题的正面采样数量。通过深刻扩展训练数据的广度，采用全批量更新替代PPO的迷你批量迭代，显著提升Pass@1性能。展示了DARS-B，结合了广度和自适应探索，同时在Pass@K和Pass@1上取得收益。结果证实，深度和广度维度在RLVR中的协同作用和自适应探索是释放RLVR推理能力的关键。
### Conclusion
深度广度协同和自适应探索是RLVR的关键，能够在不增加推理成本的前提下实现一致的Pass@K提升，显著增强Pass@1性能。
## 612. `cs.LG` - 孤立于各向异性函数的量化表示的涌现 [PDF](https://arxiv.org/pdf/2507.12070), [HTML](https://arxiv.org/abs/2507.12070)
### Authors
George Bird
### Background
本文基于现有的Spotlight Resonance方法，提出了一种新型的方法来确定表示结构。通过控制性剔除实验，只改变激活函数，研究了如何在自动编码器模型中出现和组织离散表示。该研究探讨了函数驱动的对称性是否作为隐式归纳偏置影响表示的有效性，以及不同类型的对称性（离散代数置换对称和连续代数正交对称）对表示性质的影响。研究表明，网络子结构的对称性可能导致无意中的归纳偏置，从而在表示中产生任务无关的伪结构。这些发现促使对常用功能形式进行进一步的评估，因为它可能导致不利后果。此外，这些发现支持了一种关于如何产生离散表示的一般因果模型，这可以为下游可解释现象（如祖母神经元、离散编码方案、一般线性特征及可能的叠加）提供必要的条件。初步结果显示，表示的量化似乎与重构误差的可测量增加有关，这证实了这种坍塌可能是有害的这一假设。
### Innovation
本文提出了一种基于Spotlight Resonance的新方法，用于确定自动编码器模型中的表示结构。通过改变激活函数进行受控剔除研究，发现功能驱动的离散对称性可以作为隐式归纳偏置影响表示，而连续对称性则保持表示连续性。这是现有研究中首次深入探讨不同对称性类型对自动编码器表示的影响，为可解释性研究提供了新的洞察。通过量化和重构误差的关系，本文提出了量化表示的量化效应，并支持了对功能形式的新评估。
### Conclusion
本文提出的工具和机制为理解功能形式对表示的影响提供了新的见解。研究表明，网络子结构的对称性可能导致无意中的归纳偏置，从而在表示中产生任务无关的伪结构。离散对称性的现代形式是量化表示产生的强大预测因子。此外，量化表示与重构误差的增加有关，这进一步证实了这种坍塌可能是不利的。这些发现支持了一种关于离散表示产生的一般因果模型，并可能为包括祖母神经元、离散编码方案、一般线性特征和可能的叠加在内的下游解释现象提供了必要的条件。
## 613. `cs.LG` - 使用多模态嵌入进行短格式视频推荐：应对冷启动和偏差挑战 [PDF](https://arxiv.org/pdf/2507.19346), [HTML](https://arxiv.org/abs/2507.19346)
### Authors
Andrii Dzhoha,Katya Mirylenka,Egor Malykh,Marco-Andrea Buchmann,Francesca Catino
### Background
近年来，社交媒体用户在短视频平台上花费了大量时间。因此，电子商务等其他领域的平台也开始引入短格式视频内容以吸引用户并增加他们在平台上的停留时间。这些体验的成功不仅取决于内容本身，还在于一种独特的UI创新：平台主动为用户提供一个一个观看的内容推荐，而不是让用户点击选项。这为推荐系统带来了新的挑战，尤其是在推出新的视频体验时。为了解决因此产生的非互动数据限制、沉浸式流式体验引入的位置偏差以及优化观看时间的持续偏差问题，研究发现推荐系统中的反馈循环使构建有效的解决方案变得困难。
### Innovation
本文强调了在引入新的短格式视频体验时面临的挑战，并展示了即使有足够的视频交互数据，利用细调的多模态视觉-语言模型的视频检索系统也能更好地克服这些挑战。该方法在我们的电子商务平台上的在线实验中证明了比传统监督学习方法更高的有效性，从而表明了这种方法的优势。
### Conclusion
通过使用多模态视觉-语言模型的视频检索系统，即便没有足够多的视频互动数据，也能更加有效地解决短视频推荐中的冷启动和偏差问题。该方法在实际场景中取得了显着的效果。
## 614. `cs.LG` - Beacon：集成网格选择的后训练量化 [PDF](https://arxiv.org/pdf/2508.20293), [HTML](https://arxiv.org/abs/2508.20293)
### Authors
Shihao Zhang,Rayan Saab
### Background
量化是一种广泛使用的压缩技术，用于减少大型预训练模型的内存和计算成本。在后训练量化(PTQ)中，每通道量化的主要挑战是在不使用梯度回传或大规模校准集的情况下，选择合适的缩放因子来替换权重值为缩放整数网格中的值。
### Innovation
该论文提出了一种名为Beacon的简单而有效的算法，用于直接执行每通道后训练量化，并且无需手动调参即可自动确定最优缩放因子。Beacon通过利用标量量化几何学来确定缩放因子，从而避免了回传梯度和大规模校准集的依赖。
### Conclusion
尽管Beacon算法简单且无需调参，但在性能上仍能与最先进的方法竞争，成为高效模型部署的实用解决方案。
## 615. `cs.LG` - SWiFT: 软掩码权重微调以减轻偏差 [PDF](https://arxiv.org/pdf/2508.18826), [HTML](https://arxiv.org/abs/2508.18826)
### Authors
Junyu Yan,Feng Chen,Yuyang Xue,Yuning Du,Konstantinos Vilouras,Sotirios A. Tsaftaris,Steven McDonagh
### Background
现有研究表明，机器学习模型在真实世界的应用中可能会表现出偏差，特别是在像医疗健康这样敏感的领域，这种偏差可能对模型的公平性、泛化能力和进一步扩大社会歧视的风险产生负面影响。因此，需要从已训练的模型中去除这些偏差。现有的去偏差方法通常需要原始训练数据以及大量的模型重新训练，且往往在模型公平性和区分性能之间存在权衡。
### Innovation
本文提出了SWiFT（软掩码权重微调）框架，该框架能够高效地改善模型的公平性同时保持区分性能，且所需去偏差成本较低。SWiFT仅需少量外部数据集和少量模型微调周期。SWiFT的主要创新点在于首先确定模型参数对偏差和预测性能的相对但独特的贡献，然后通过两步微调过程使用不同的梯度流更新每个参数。
### Conclusion
通过在三个敏感属性（性别、肤色和年龄）的四个皮肤病学和两个胸部X光数据集上进行广泛实验，我们证明了SWiFT可以在保持或甚至优于最先进的公平性和准确性的条件下，有效减少模型偏差且提高模型泛化能力。特别是在离群领域（OOD）数据集上的表现优于其他方法，进一步验证了SWiFT的有效性。
## 616. `cs.LG` - TimeCopilot [PDF](https://arxiv.org/pdf/2509.00616), [HTML](https://arxiv.org/abs/2509.00616)
### Authors
Azul Garza,Reneé Rosillo
### Background
当前的时间序列预测任务主要依赖于单一的时间序列模型或手动进行特征分析、模型选择等步骤，缺乏一种综合多种时间序列基础模型（TSFMs）与大型语言模型（LLMs）的统一框架，同时缺少自动化的预测流程和自然语言解释功能。
### Innovation
TimeCopilot 是第一个开源的代理框架，将多种时间序列基础模型（TSFMs）与大型语言模型（LLMs）通过单一统一的API进行结合。它自动化了预测管道，包括特征分析、模型选择、交叉验证和预测生成，并提供了自然语言解释功能，支持直接查询未来。TimeCopilot 框架对大型语言模型不拘一格，能够兼容商业和开源模型，并支持不同时间序列预测族的集成。在GIFT-Eval基准上的大规模结果表明，TimeCopilot在低成本的情况下实现了最先进的概率预测性能。
### Conclusion
TimeCopilot框架为可重复、可解释和可访问的代理预测系统提供了一个实用的基础。
## 617. `cs.LG` - 理解特征流形存在的情况下稀疏自编码器的缩放 [PDF](https://arxiv.org/pdf/2509.02565), [HTML](https://arxiv.org/abs/2509.02565)
### Authors
Eric J. Michaud,Liv Gorton,Tom McGrath
### Background
稀疏自编码器（SAEs）将神经网络的激活表示为稀疏出现的方向（潜在因素）的线性组合。关于潜在因素数量，SAEs的重建能力遵循缩放定律。本文中，作者借鉴了神经网络缩放研究中的容量分配模型（Brill, 2024），来理解SAE的缩放特性，特别是特征流形（多维特征）如何影响这一行为。
### Innovation
作者将容量分配模型应用到SAE的缩放特性研究中，发现在某些情况下，特征流形导致SAE学到的特征远少于SAE中的潜在因素数量。这揭示了特征流形对SAE学习特征数量的复杂影响。
### Conclusion
模型揭示了存在的缩放阶段，并指出在某些情况下，特征流形可能导致SAE学习的特征数量远少于潜在因素的数量。文章初步讨论了SAE在实际应用中是否处于这种病态阶段。
## 618. `cs.LG` - 基于奖励模型的推理时缩放算法：PDE基础模型中的推理 [PDF](https://arxiv.org/pdf/2509.02846), [HTML](https://arxiv.org/abs/2509.02846)
### Authors
Siddharth Mansingh,James Amarel,Ragib Arnab,Arvind Mohan,Kamaljeet Singh,Gerd J. Kunde,Nicolas Hengartner,Benjamin Migliori,Emily Casleton,Nathan A. Debardeleben,Ayan Biswas,Diane Oyen,Earl Lawrence
### Background
偏微分方程（PDEs）作为现代计算科学和工程中的基础，虽然非常有用但计算成本高昂。现有的PDE基础模型在模拟复杂的时空现象方面显示出潜力，但由于预训练数据的限制和自回归展开性能不佳，尤其是在分布外（OOD）情况下，它们的性能受到极大限制。此外，这些模型需要大量的计算资源和训练数据，这阻碍了它们在许多关键应用中的使用。
### Innovation
受大型语言模型（LLMs）中使用“思考”策略的进展启发，本研究引入了一种PDE推理时计算（TTC）策略，利用推理过程中的计算资源，从而使用更少的训练样本和更小的模型实现更准确的预测。该方法通过两种类型的奖励模型评估基于随机模型的时空一致性预测。
### Conclusion
该TTC框架标志着向更高级推理算法或PDE建模步骤迈进的重要一步，包括构建基于强化学习的方法，可能彻底改变物理和工程中的计算流程。
## 619. `cs.LG` - ReLU网络的ReLU过渡图通过离散函数几何分析 [PDF](https://arxiv.org/pdf/2509.03056), [HTML](https://arxiv.org/abs/2509.03056)
### Authors
Sahil Rajesh Dhayalkar
### Background
本文扩展了ReLU过渡图（RTG）框架，将其转化为一个全面的图理论模型，以理解深度ReLU网络。这一模型中的每个节点代表一个线性激活区域，边连接由单个ReLU激活翻转不同的区域，形成了网络功能行为上的离散几何结构。研究表明，这些结构洞察有助于随着随机初始化，RTGs表现出强扩展性、二项式度数分布和紧密控制泛化的光谱性质。通过这些结构洞察，证明了通过区域熵获得的新能力边界估值和通过光谱间隙和边间KL散度获得的新泛化估估值。
### Innovation
通过推广ReLU过渡图（RTG）框架为一个全面的图理论模型，本文首次将ReLU网络的分析置于离散功能几何的视角下，提供了一种新的理解、诊断和改善泛化的工具。
### Conclusion
本文的结果表明，在过参数化下，区域熵饱和；光谱间隙与泛化相关；相邻区域间的KL散度反映了功能平滑性。本文为通过离散函数几何分析ReLU网络提供了统一的框架，为理解和改善泛化提供了新的工具。
## 620. `cs.LG` - EvoCoT: 克服强化学习中的探索瓶颈 [PDF](https://arxiv.org/pdf/2508.07809), [HTML](https://arxiv.org/abs/2508.07809)
### Authors
Huanyu Liu,Jia Li,Chang Yu,Taozhi Chen,Yihong Dong,Lecheng Wang,XiaoLong Hu,Ge Li
### Background
强化学习与验证奖励（RLVR）已经成为提升大型语言模型（LLMs）推理能力的一种有前景的后训练范式。然而，当在难题上展开评估的准确性较低时，奖励会变得稀疏，从而限制了学习效率并导致探索瓶颈。现有方法要么依赖更强的LLMs 进行蒸馏，要么将困难的问题过滤掉，这两种方法都限制了可扩展性或限制了通过探索改进推理能力的能力。
### Innovation
EvoCoT 提出了一种基于两阶段思维链（CoT）推理优化的自我进化课程学习框架。通过自我生成和验证CoT 轨迹来约束探索空间，然后逐渐缩短这些轨迹以在受控方式下扩大空间。这使LLMs能够在稀疏奖励的情况下稳定地从最初未解决的难题中学习。EvoCoT 已应用于包括Qwen、DeepSeek 和Llama在内的多个LLM 家族。实验表明，EvoCoT 可以使LLMs 解决之前未解决的问题，提高推理能力而不需要外部CoT 监督，并且兼容各种强化学习微调方法。我们发布了源代码以支持未来的研究。
### Conclusion
EvoCoT 使LLMs 能在稀疏奖励的情况下稳定地从最初未解决的难题中学习，能够解决之前未解决的问题，提高推理能力，兼容各种强化学习微调方法，并在未来的研究中有潜在应用价值。
## 621. `cs.LG` - 解析ReLU网络背后的机制 [PDF](https://arxiv.org/pdf/2507.22832), [HTML](https://arxiv.org/abs/2507.22832)
### Authors
Maciej Satkiewicz
### Background
由于任何ReLU网络都是分段仿射的，其隐藏单元可以通过激活子网络的反向传播拉回来表征，即通过其梯度（不包括偏差项）。然而，深层神经元的梯度错位严重，掩盖了网络的内部表示。本文假设模型确实会使得梯度与数据对齐，但这一对齐被ReLU硬门控的内在噪声所掩盖。通过在反向传播中应用软门控来降低未充分激活神经元的局部影响，研究发现这种修改后的梯度，称之为'激活拉回'，在多个ImageNet预训练架构上有显著的感知对齐效果。基本的像素空间梯度梯度上升也快速生成了易于解释的输入和目标特异性特征。基于这些发现，研究提出了'路径稳定性'假设，认为二进制激活模式在训练过程中主要稳定并被编码到最终模型的前激活分布中。当此假设成立时，激活拉回将与决定网络决策的主要核机器梯度对齐，这为基于这些拉回的特性归因的有效性和潜在的机械解释提供了理论依据，尤其是对于更深层的模型。此外，研究还为批归一化和深层特征的有效性提供了可能的解释，并提供了一个新的视角来看待网络的内部记忆和泛化能力。为了便于探索，研究人员也发布了代码和一个互动应用程序。
### Innovation
1. 在反向传播中应用软门控来减少未充分激活神经元的局部影响，提出了一种称为'激活拉回'的修改后的梯度方法，这种方法在多个ImageNet预训练架构上表现出显著的感知对齐效果。2. 提出了'路径稳定性'假设，认为二进制激活模式在训练过程中主要稳定并被编码到最终模型的前激活分布中，当此假设成立时，激活拉回将与决定网络决策的主要核机器梯度对齐，为特性归因的有效性和潜在的机械解释提供了理论依据。3. 提出了一个新视角来看待网络的内部记忆和泛化能力，给出了批归一化和深层特征的有效性的一部分可能解释，并发布了代码和一个互动应用程序，便于探索激活拉回的特性。
### Conclusion
通过基于'激活拉回'和'路径稳定性'的假设，研究为深层神经网络模型的特性归因提供了理论依据，即使在更深的模型中，也有可能实现更深入的模型机制解释。该研究还深入理解了批归一化和深层特征的有效性，并提供了用于探索内部记忆和泛化能力的工具。
## 622. `cs.LG` - 基于推理的表示转换：一种用于表示转换的结构转移算子 [PDF](https://arxiv.org/pdf/2509.03249), [HTML](https://arxiv.org/abs/2509.03249)
### Authors
Daniel Raggi,Gem Stapleton,Mateja Jamnik,Aaron Stockdill,Grecia Garcia Garcia,Peter C-H. Cheng
### Background
表示选择是我们有效沟通和推理的关键。本研究解决了在多表示系统之间转换和选择表示的技术问题，但目前尚未有通用的方法解决这一问题。
### Innovation
提出了一种新的算子结构转移，能够跨越不同表示系统实现表示转换。通过利用编码表示系统知识的模式，确保源表示和目标表示之间的特定关系得到满足（例如语义等价），实现了高通用性的转换。
### Conclusion
结构转移作为不受系统约束的技术，可以在广泛的实用场景中识别替代表示。通过形式化构建空间，进一步增强了该方法的通用性，使其能够建模各种类型的形式语言、几何图形、图表以及非正式记号等表示系统。
## 623. `cs.LG` - 使用生成多模态大型语言模型合成认知评估的规范性数据 [PDF](https://arxiv.org/pdf/2508.17675), [HTML](https://arxiv.org/abs/2508.17675)
### Authors
Victoria Yan,Honor Chotkowski,Fengran Wang,Xinhui Li,Jessica Saurman,Fadi Nahab,David Loring,Carl Yang,Jiaying Lu,Runze Yan,Xiao Hu,Alex Fedorov
### Background
认知评估需要规范性数据作为基准来评价个体表现。基于新型图像刺激的新认知测试的开发存在挑战，因为缺乏现成的规范性数据。传统数据收集方法成本高、耗时且不常更新，限制了其实际应用。近期，生成多模态大型语言模型（MLLMs）为从现有认知测试图像生成合成规范性数据提供了新途径。本文研究了使用特定的 MLLM（GPT-4o 和 GPT-4o-mini）来合成规范性文本响应的可行性，特别是应用于“饼干盗窃”图像描述任务等已建立的基于图像的认知评估。对两种不同的提示策略（基础指导和富含情境指导的复杂提示）进行了评估，并通过嵌入分析评估其诊断组和人群差异区分能力，使用 BLEU、ROUGE、BERTScore 和 LLM-as-a-judge 作为性能指标。结果表明，复杂的提示策略生成的合成响应区分诊断组和群体差异的效果更好，且模型生成的响应真实性更高、更具多样性。BERTScore 是评估上下文相似性最可靠的指标，而 BLEU 在评估创意输出时效果较差。基于生成多模态 LLM 的方法对合成规范性数据具有潜在的初步验证结果。研究表明，通过优化提示方法指导的 MLLM 可以实际生成用于现有认知测试的稳健合成规范性数据，从而为未来开发基于图像的认知评估提供了基础.
### Innovation
使用生成多模态大型语言模型（MLLMs）来合成规范性数据，这是一种新颖的方法。与传统的数据收集方法相比，这种方法可以生成高质量、多变且与现有认知测试图像相关的规范性数据，从而克服了传统方法的成本高、耗时、不常更新的限制，特别是在诊断组和群体差异区分方面的效果明显优于传统的提示策略。此外，研究还发现，BERTScore 是评估上下文相似性最可靠的指标，而 BLEU 在评估创意输出时效果较差，为后续的研究提供了参考依据。
### Conclusion
本研究证明，通过优化提示方法指导的 MLLM 可以实际生成用于现有认知测试的稳健合成规范性数据，从而为开发新的基于图像的认知评估提供了基础，克服了传统方法的限制。
## 624. `cs.LG` - EvolveSignal:由大规模语言模型驱动的编码代理用于发现交通信号控制算法 [PDF](https://arxiv.org/pdf/2509.03335), [HTML](https://arxiv.org/abs/2509.03335)
### Authors
Leizhen Wang,Peibo Duan,Hao Wang,Yue Wang,Jian Xu,Nan Zheng,Zhenliang Ma
### Background
在交通工程中，由于固定时间的交通信号控制成本低、稳定且易理解，因此被广泛使用。然而，此类控制的设计依赖于手工制作的公式（如韦伯公式）和工程师的手动调整，以适应需求变化。这种方法劳动密集且在异构或拥堵条件下通常会产生次优结果。
### Innovation
本文引入了EvolveSignal，这是一种由大规模语言模型（LLMs）驱动的编码代理，用于自动发现新的交通信号控制算法。将问题形式化为程序合成，候选算法表现为具有固定输入输出结构的Python函数，并通过外部评估（例如交通模拟器）和进化搜索进行迭代优化。
### Conclusion
实验表明，发现的算法在信号交叉路口的表现优于韦伯基准，平均延误减少了20.1%，平均停车次数减少了47.1%。进一步的消融分析和增量分析表明，EvolveSignal修改（如调整周期长度限制、结合右转需求和重新缩放绿灯分配）可以为交通工程师提供具有实际意义的见解。这项工作开创了一条新的研究路径，即利用AI进行交通信号控制算法设计，将程序合成与交通工程相结合。
## 625. `cs.LG` - 智能入门 [PDF](https://arxiv.org/pdf/2008.07324), [HTML](https://arxiv.org/abs/2008.07324)
### Authors
Karl Fezer,Andrew Sloss
### Background
智能是所有生物的基础，也是人工智能的基石。这篇文章旨在探索与智能相关的理念，深入了解其涵义、范围以及未来系统的潜力，并解释智能对我们的生活和未来的潜在影响。文章指出，智能并非单一可度量的量，而是涉及到生物学、物理学、哲学、认知科学、神经科学、心理学和计算机科学等多个领域的主题。此外，智能的发展迫使未来的工程师和科学家需要从心理学、哲学和伦理学等角度广化他们的理解。
### Innovation
介绍了将智能与多个学科领域相联系的概念框架，并强调了智能不仅仅是技术层面的问题，还涵盖了心理学、哲学和伦理学等哲学层面上的理解。通过探讨智能的多维度，文章旨在激发读者对于智能的思考。
### Conclusion
这篇文章借鉴了著名科幻小说《银河系漫游指南》中“42”的例子，提出智能是什么的问题，回顾集合了从自然智能到人工智能的宽广领域，希望为未来的工程师和科学家提供更多启示和需要深入思考的问题。
## 626. `cs.LG` - 全球作物类型分类中的不变特征 [PDF](https://arxiv.org/pdf/2509.03497), [HTML](https://arxiv.org/abs/2509.03497)
### Authors
Xin-Yi Tong,Sherrie Wang
### Background
准确获得全球范围内的作物类型及其空间分布对于粮食安全、农业政策制定和可持续发展至关重要。遥感可以有效地解决大规模作物分类问题，但许多地区的可靠地面样本不足限制了其跨区域的应用。为解决地理变化带来的性能下降问题，本文识别了对地理变异具有不变性的遥感特征，并提出提升跨区推广策略。本文构建了一个全球作物类型数据集CropGlobe，包含来自五大洲八个国家的30万像素级样本，涵盖了六大主要粮食与工业作物（玉米、大豆、水稻、小麦、甘蔗、棉花），实现了跨国家、跨洲际和跨半球的系统评估。
### Innovation
本文提出了一个轻量级且鲁棒的卷积神经网络CropNet，并结合了时序数据增强技术（时移、时尺度、幅度变换），以提高在光谱和物候变化下的推广能力。实验结果表明，基于Sentinel-2的2D中位时序特征在所有转移情景中表现出最强的不变性，且增强技术进一步提高了鲁棒性，尤其是在训练数据多样性有限的情况下。
### Conclusion
本文识别了更具有不变性的特征表示，提升了地理转移性，并提出了在全球多样化区域中实现可扩展且低成本的作物类型应用的可行路径。
## 627. `cs.LG` - AI中的(不)理性：现状、研究挑战与开放问题 [PDF](https://arxiv.org/pdf/2311.17165), [HTML](https://arxiv.org/abs/2311.17165)
### Authors
Olivia Macmillan-Scott,Mirco Musolesi
### Background
人工智能领域中理性概念至关重要。无论是模仿人类推理还是实现有限优化，目标都是使人工代理尽可能地理性。尽管理性概念在AI中至关重要，但对其构成的统一定义尚未形成。本文对AI中的理性与非理性进行了概述，并探讨了这一领域中的开放问题。此外，文章还分析了不同学科（经济学、哲学和心理学）对理性理解如何影响AI中的理性概念，并聚焦于人工代理行为中的非理性表现。
### Innovation
文章详细梳理了其他领域对理性理解如何影响AI中的理性概念，并探讨了一些处理非理性代理的方法。此外，文章指出可以利用其他领域的现有方法（如对抗性场景）来解决与人工代理的交互问题，并讨论了人与人工代理之间的互动与合理性的角色。
### Conclusion
在人工与人类代理交互中，仍有许多开放的问题需要解决，包括人类和人工代理都可能存在非理性的行为。研究领域仍需要更多工作来探索并解决这些挑战。
## 628. `cs.LG` - 基于扩散先验的Flow Matching直流程化改进 [PDF](https://arxiv.org/pdf/2311.16507), [HTML](https://arxiv.org/abs/2311.16507)
### Authors
Siyu Xing,Jie Cao,Huaibo Huang,Haichao Shi,Xiao-Yu Zhang
### Background
Flow matching作为一种生成模型范式，在多个领域取得了显著成效。然而，现有方法通常需要多轮训练或多批次内的知识，这使得找到一种有效的耦合策略以优化从多步生成的轨迹变得困难。研究者们希望通过改进这一过程，更有效地引导轨迹，提高多步生成的质量和效率。
### Innovation
本文提出了一种名为StraightFM的新方法，通过扩散模型作为耦合先验，在整个分布水平上对图像和噪声的耦合关系进行优化，从而直流程化轨迹。这种方法可以在训练过程中，通过单个扩散模型将图像和噪声耦合起来，以优化多步生成过程中的轨迹表示，并能与现有基于真实数据到噪声方向的有效耦合策略进行结合，进一步提升生成图像的质量。实验结果显示，无论是在像素空间还是潜在空间中，StraightFM均能在五步内生成具有吸引力的样本，且在无条件模式下，该方法能够无缝地应用于无需训练的多模态条件生成场景中，仍能保持高质量的图像生成能力。
### Conclusion
通过引入基于扩散先验的耦合策略，StraightFM能够在多步生成过程中显著改善图像的质量，并且在多种应用场景中保持了高效性与兼容性。
## 629. `cs.LG` - 基于单个人类视频的开放世界物体图的视觉操作 [PDF](https://arxiv.org/pdf/2405.20321), [HTML](https://arxiv.org/abs/2405.20321)
### Authors
Yifeng Zhu,Arisrei Lim,Peter Stone,Yuke Zhu
### Background
本文介绍了一种物体中心的方法，用于学习基于视觉的操作技能，并从人类视频中进行模仿。在开放世界环境下研究机器人操作的模仿问题，即通过单一视频演示来学习操作未知物体的策略。研究考虑了从日常移动设备录制的视频中学习，并将所学策略应用到具有不同视觉背景、摄像角度、空间布局和新颖物体实例的不同部署环境中。该研究在短期和长期任务中系统地评估了方法的有效性，并使用RGB-D和RGB的演示视频对不同任务和演示类型进行了测试，结果显示74.4%的成功率，证明了ORION在开放世界中从单个人类视频学习的有效性
### Innovation
引入了ORION算法，该算法能够从单一RGB或RGB-D视频中提取物体中心的操作计划，并基于提取的计划生成策略。这一方法使机器人能够从日常手机拍摄的视频中学习，并能将政策迁移到具有不同视觉背景、摄像头角度、空间布局和新颖对象实例的不同部署环境中
### Conclusion
该方法在短期和长期任务中实现了74.4%的成功率，证明了ORION在开放世界中从单一个人演示视频学习的有效性。
## 630. `cs.LG` - 单一种子生成布朗路径及其积分以适应和高阶SDE求解器 [PDF](https://arxiv.org/pdf/2405.06464), [HTML](https://arxiv.org/abs/2405.06464)
### Authors
Andraž Jelinčič,James Foster,Patrick Kidger
### Background
尽管自适应时间步长在常微分方程模拟中取得了成功，但在随机微分方程（SDEs）领域应用较少。为适应SDE模拟，尽管开发了如虚拟布朗树（VBT）等方法生成非顺序的布朗运动（BM），但对于高阶收敛，仅知道BM的值是不够的，还需要计算BM的时间积分如?(?int_s^t W_r ??)。因此，作者旨在利用高阶SDE求解器并使VBT生成这些BM的时间积分，以及布朗增量。
### Innovation
作者扩展了VBT以生成除布朗增量外的时间积分，并实现了由单一伪随机数生成（PRNG）种子确定的布朗路径，这导致内存占用恒定且便于重复实验和准确的误差估计。VBT的时间复杂度是容忍度参数?(?varepsilon?)的对数。与原始VBT算法不同，该方法在任意?(?varepsilon?)间隔的查询时间上精确匹配BM及其时间积分的联合分布。作者展示了两个新VBT的应用实例：在高波动CIR模型的自适应求解中，实现了比固定步长求解更高的收敛阶；使用自适应三阶欠阻尼拉格朗日求解器处理MCMC问题，该方法仅使用No U-Turn Sampler十分之一的函数评估。
### Conclusion
文章实现的Construct包含在流行的Diffrax库中，证明了新VBT在计算BM及其时间积分方面的新能力，展示了其在SDE模拟中的效能，特别是在CIR模型和MCMC问题中。
## 631. `cs.LG` - WASP: 一种检测学到的偏见的权重空间方法 [PDF](https://arxiv.org/pdf/2410.18970), [HTML](https://arxiv.org/abs/2410.18970)
### Authors
Cristian Daniel Păduraru,Antonio Bărbălau,Radu Filipescu,Andrei Liviu Nicolicioiu,Elena Burceanu
### Background
训练机器学习模型时，需要确保模型明确理解每个类别的定义。虽然已有许多研究致力于识别可能影响模型对类别理解的数据集中的虚假相关性，但现有方法仅依赖于数据分析或误差分析。这意味着它们无法指出模型学习但未通过验证或训练集中的反例指出的虚假相关性。本文旨在克服这一限制，将焦点从分析模型预测转向分析模型的权重，以揭示决策背后的机制，这一方法被证明更具有洞察力。
### Innovation
本文提出了一种称为WASP（Weight-space Approach to detecting Spuriousness）的方法，通过分析在特定数据集上进行微调过程中基础模型权重的变化来检测各种（虚假）关联性。与现有方法相比，WASP方法能够识别出即使反例未指出，数据集中也存在的虚假相关性，并且适用于多种模态如图像和文本。此外，它还能发现此前未被挖掘的在ImageNet-1k分类器中学习到的虚假相关性。
### Conclusion
WASP方法能够从模型的权重分析中揭示数据中被忽视的虚假相关性，用作模型理解中的补充工具，提高了系统的鲁棒性和准确性。这种方法展示了模型权重分析在检测虚假相关性方面的潜力，并证明了相比于传统数据或误差分析，该方法更能揭示模型决策背后的信息。
## 632. `cs.LG` - FFHFlow: 基于流变分推断的多样化和不确定性感知灵巧抓取生成 [PDF](https://arxiv.org/pdf/2407.15161), [HTML](https://arxiv.org/abs/2407.15161)
### Authors
Qian Feng,Jianxiang Feng,Zhaopeng Chen,Rudolph Triebel,Alois Knoll
### Background
在机器人学习中，基于部分观察合成多样且具有不确定性感知的多手指抓取仍然是一项关键挑战。先前的生成方法难以建模灵巧手的精细抓取分布，并且往往无法处理部分点云中存在的形状不确定性，这导致了不可靠或过于保守的抓取生成。
### Innovation
我们提出了FFHFlow，一种基于流的变分框架，能够生成多样且鲁棒的多手指抓取，同时明确量化部分点云中的知觉不确定性。我们的方法利用了一个归一化流为基础的深度潜变量模型来学习层次抓取流形，解决了条件变分自编码器的模式崩溃和刚性先验限制问题。通过利用流的可逆性和精确似然性，FFHFlow能够感知部分观察中的形状不确定性并识别新的物体结构，从而实现风险感知的抓取合成。为了进一步提高可靠性，我们集成了一个辨别性抓取评估器到流似然中，提出了一种不确定性感知的排名策略，优先选择对形状的模棱两可具有鲁棒性的抓取。
### Conclusion
广泛的模拟和真实环境实验表明，FFHFlow在抓取多样性和成功率方面优于最新的基线方法（包括扩散模型），且具有运行时高效采样。我们还展示了FFHFlow在杂乱和有限空间环境中的实际价值，多样驱动的采样策略通过减少碰撞而表现出色（项目页面: this https URL）.
## 633. `cs.LG` - dsld：一个与社会相关的统计教学工具 [PDF](https://arxiv.org/pdf/2411.04228), [HTML](https://arxiv.org/abs/2411.04228)
### Authors
Aditya Mittal,Taha Abdullah,Arjun Ashok,Brandon Zarate Estrada,Shubhada Martha,Billy Ouattara,Jonathan Tran,Norman Matloff
### Background
数据科学在统计教育中的影响日益增加，需要提供工具来通过实际应用使关键概念变得易于理解。现有方法需要一种能够通过实际案例展示公平分析、混杂效应等问题的教学工具。
### Innovation
作者通过推出一个名为‘Data Science Looks At Discrimination’（dsld）的R包，提供了一整套用于分析涉及种族、性别和年龄等属性的歧视问题的分析和图形方法。该包将公平性分析作为教学工具，帮助教师通过实际应用案例展示混杂变量效果和模型偏见等相关主题。此外，还附有一本80页的Quarto书，指导学生和法律专业人士理解和应用这些原则。
### Conclusion
该R包的实现及其使用已通过例子进行说明，同时还提供了Python接口。该工具旨在通过公平性分析的实际应用，向学生和法律专业人士展示公平性分析、混杂效应等相关概念。
## 634. `cs.LG` - ACING: Actor-Critic for Instruction Learning in Black-Box LLMs [PDF](https://arxiv.org/pdf/2411.12736), [HTML](https://arxiv.org/abs/2411.12736)
### Authors
Salma Kharrat,Fares Fourati,Marco Canini
### Background
大型语言模型（LLMs）在解决任务时的有效性取决于其指令的质量，这通常需要大量的人工努力来编写。因此，需要自动的指令优化方案。但对黑箱LLMs进行指令优化极具挑战性，因为模型参数和梯度不可访问。现有方法难以探索无限的指令空间，以生成优越于人工编写指令的选项。需要一种能够仅利用黑箱反馈来探索无限指令空间的自动指令优化方法，以发现超越人工指令的方法.
### Innovation
ACING提出了一种基于演员-评论家强化学习框架，将指令优化问题定义为无状态、连续动作的问题，使得能够仅使用黑箱反馈来探索无限的指令空间，从而自动发现比人工编写指令更优的方法。结果显示，ACING在76%的任务中发现了性能优越的提示，在33个任务中，比最佳自动基线平均提高了10分，最高提高33分。广泛的消融实验显示了其稳健性和效率，且已经提供了ACING的实现.
### Conclusion
ACING大幅提高了黑箱LLMs在指令优化方面的表现，展示了其在无需访问模型内部信息的情况下探索无限指令空间的有效性，为其在实际应用中的使用提供了坚实的基础。
## 635. `cs.LG` - 高维空间中未调整拉格朗日算法的收敛性：偏置的去局域化 [PDF](https://arxiv.org/pdf/2408.13115), [HTML](https://arxiv.org/abs/2408.13115)
### Authors
Yifan Chen,Xiaoou Cheng,Jonathan Niles-Weed,Jonathan Weare
### Background
未调整拉格朗日算法被广泛用于极高维概率分布采样。尽管现有分析表明，对于强对数凹分布，随着问题维度的增加，以$W_2$度量误差收敛所需的迭代次数可能线性或与$?sqrt{d}$成正比，但本文作者认为在部分变量上，迭代次数可以仅与$K$成正比，其中$K$是变量的数量，而与维度$d$的对数因子有关，即可达到所需的$W_2$误差。这一现象被定义为偏置的去局域化。
### Innovation
本文展示了偏置的去局域化效应并非普遍适用，证明了这一效应在高斯分布以及具有特定稀疏交互的强对数凹分布中成立。一种新的$W_{2,?ell^{?infty}}$度量被用于测量收敛性，并解决了这一度量在缺乏一步收缩性质这一技术挑战。此外，通过渐近方法探讨了该偏置去局域化效应在高斯和稀疏交互之外场景的一般化。
### Conclusion
对于特定的稀疏交互结构和高斯分布，偏置的去局域化效应是有效的。然而，这一现象并非在所有情况下都成立。使用$W_{2,?ell^{?infty}}$度量可以克服迭代过程中的缩放问题，并且通过构建渐近分析框架，可以探索该效应在更广泛的条件下的适用性。
## 636. `cs.LG` - ConServe: 细粒度GPU回收技术以实现LLM在线和离线协同服务 [PDF](https://arxiv.org/pdf/2410.01228), [HTML](https://arxiv.org/abs/2410.01228)
### Authors
Yifan Qiao,Shu Anzai,Shan Yu,Haoran Ma,Shuo Yang,Yang Wang,Miryung Kim,Yongji Wu,Yang Zhou,Jiarong Xing,Joseph E. Gonzalez,Ion Stoica,Harry Xu
### Background
大规模语言模型（LLM）需要低延迟和高吞吐量，但高负载波动使得达到高GPU利用率变得具有挑战性。现有的服务系统在粗粒度的资源管理下，无法高效地同时处理对延迟敏感的在线请求和延迟容忍的离线任务，如模型基准测试时避免引入违反在线延迟目标的干扰。
### Innovation
ConServe 是一种新提出的LLM协同服务系统，通过在更细粒度的层级上管理资源，实现高吞吐量和强在线延迟保障。ConServe 引入了三种技术：（1）延迟感知的令牌级调度程序，用于精确配置离线批处理和令牌以适应在线延迟目标；（2）子迭代、逐层抢占，允许离线任务在面临在线负载高峰时让位于在线任务；（3）增量KV缓存管理，使得离线请求可以在几乎零成本下被抢占并恢复。
### Conclusion
通过在真实工作负载下使用Llama-3.1和Qwen-2.5模型进行评估，发现ConServe 相比于现有先进系统的吞吐量提高了2.2倍，并将在线服务尾部延迟降低了2.9倍。
## 637. `cs.LG` - 通过元上下文学习实现快速词汇学习 [PDF](https://arxiv.org/pdf/2502.14791), [HTML](https://arxiv.org/abs/2502.14791)
### Authors
Wentao Wang,Guangyuan Jiang,Tal Linzen,Brenden M. Lake
### Background
人类能够从少量示例中快速学习新词汇，并在新语境中系统而灵活地使用它。然而，当前语言模型在少量示例中学词汇的能力及其提高方法尚未被充分研究。本研究介绍了一种新方法——Minnow（元训练以文中学词），旨在通过少量示例训练语言模型生成新词的使用示例，以培养其一般词汇学习能力。
### Innovation
引入了一种新的方法——Minnow，该方法通过使用特殊的占位符标记来代表新词，并通过少量上下文示例训练语言模型生成新词的使用示例。Minnow方法在儿童语言数据规模上的完全训练新模型，实现了与大量数据预训练的大规模语言模型相当的快速词汇学习能力，且通过微调预训练的大规模语言模型进一步提高了其在识别新词、确定新词的句法规则以及基于少量上下文示例生成合理的新用法和定义方面的性能。
### Conclusion
Minnow方法在数据效率方面表现出色，并有可能改善语言模型在词汇学习任务中的性能。
## 638. `cs.LG` - MixNet：一种用于分布式混合专家训练的运行时可重构光电fabric [PDF](https://arxiv.org/pdf/2501.03905), [HTML](https://arxiv.org/abs/2501.03905)
### Authors
Xudong Liao,Yijun Sun,Han Tian,Xinchen Wan,Yilun Jin,Zilong Wang,Zhenghang Ren,Xinyang Huang,Wenxue Li,Kin Fai Tse,Zhizhen Zhong,Guyue Liu,Ying Zhang,Xiaofeng Ye,Yiming Zhang,Kai Chen
### Background
MoE模型通过在每个token基础上选择性激活不同的子网络（称为专家）来优于传统的模型。这种门控计算生成的动态通信模式具有很强的局部性，难以预先确定，这将挑战传统的保持静态连接的GPU互连技术，特别是在分布式训练过程中。现有的方法对此无能为力，因此需要一种新的方法来重新配置网络拓扑，以更好地支持动态通信模式。
### Innovation
提出了一种名为MixNet的系统，该系统可以在分布式MoE训练过程中实时重新配置网络拓扑。MixNet通过光学电路交换（OCS）技术与现有电气互连合作，在保证快速适应性的基础上保持了可扩展性。经过大规模的包级仿真，MixNet展示了与无阻塞fat-tree fabric相当的性能，同时在100 Gbps和400 Gbps链路带宽下，改善了四种代表性MoE模型的培训成本效率（每美元性能）1.2至1.5倍和1.9至2.3倍。
### Conclusion
MixNet建立了一个完全功能的原型，使用商用硬件和定制的集体通信运行时，在32个A100 GPU上进行推理中的拓扑重新配置，可以训练最先进的MoE模型。
## 639. `cs.LG` - 一种无监督自然语言处理流水线用于评估转诊适当性 [PDF](https://arxiv.org/pdf/2501.14701), [HTML](https://arxiv.org/abs/2501.14701)
### Authors
Vittorio Torri,Annamaria Bottelli,Michele Ercolanoni,Olivia Leoni,Francesca Ieva
### Background
当前，评估诊断转诊的适当性对于提高医疗服务效率和减少不必要的程序非常重要。但是，意大利国家卫生服务系统中，转诊原因仅以自由文本记录而未使用结构化代码，这使这项任务变得具有挑战性。为解决这一问题，本文提出了一种完全无监督的自然语言处理（NLP）流程，可以在不依赖标注数据集的情况下提取并评估转诊原因，使其能够适用于不同类型的检查。
### Innovation
该研究提出了一种完全无监督的基于Transformer嵌入的NLP流程，用于根据意大利医疗文本预先训练的转诊原因聚类和评估其与适当性指南的契合度。该流程能够在无监督的情况下工作，并针对不同类型的检查可以泛化应用，从而在大规模的真实世界数据集中进行高效可靠的转诊适当性评估。
### Conclusion
研究展示了一种稳健且可扩展的无监督NLP流程，用于在大规模的真实世界数据集中评估转诊的适当性。这种方法能够有效利用数据，为公共卫生机构提供了可用于监管实践并支持基于证据的政策的部署人工智能工具。同时，该研究还对区域性不适当的转诊群组进行了分析，并在不同背景下发现了差异，为一个新的伦巴第地区决议提供了依据，以加强指南的遵守。
## 640. `cs.LG` - 通过从头设计肽揭示T细胞受体特异性景观 [PDF](https://arxiv.org/pdf/2503.00648), [HTML](https://arxiv.org/abs/2503.00648)
### Authors
Gian Marco Visani,Michael N. Pun,Anastasia A. Minervina,Philip Bradley,Paul Thomas,Armita Nourmohammad
### Background
T细胞在适应性免疫中起着关键作用，通过对抗多种病原体产生特定反应。TCR与巨细胞复杂体（MHC）上提呈的病原体衍生多肽的有效结合触发免疫反应。然而，由于关于T细胞反应的有限功能数据，预测这些相互作用仍然具有挑战性。
### Innovation
提出了一种基于物理学习的计算方法，利用HERMES模型预测TCR与MHC I类等位基因上提呈的多肽之间的相互作用，并设计针对特定TCR-MHC复合物的新免疫肽。此方法通过无需直接训练TCR-pMHC数据，利用HERMES中的隐含物理推理，实现了对TCR-pMHC结合亲和力和T细胞活力的精确预测。此外，通过从头设计肽，该方法成功激活了多达50%的T细胞。
### Conclusion
该方法为免疫肽和新抗原设计提供了一个平台，并评估了TCR的特异性，为设计工程化T细胞疗法和疫苗提供了一种计算框架。
## 641. `cs.LG` - 硬件友好的具有固定尺寸可重用结构的扩散模型在设备上进行图像生成 [PDF](https://arxiv.org/pdf/2411.06119), [HTML](https://arxiv.org/abs/2411.06119)
### Authors
Sanchar Palit,Sathya Veera Reddy Dendi,Mallikarjuna Talluri,Raj Narayana Gadde
### Background
视觉变换器和U-Net架构在实现差分模型的实施方案中被广泛采用。然而，每种架构在设备上实现时都会遇到特定的挑战。视觉变换器需要位置嵌入来保持由变换器处理的令牌之间的对应关系，虽然它们的优势在于使用固定尺寸且可重用的重复块。U-Net架构缺乏这些特性，因为它们使用变量大小的中间块进行下采样和上采样以进行噪声估计，这是在整个余量处理过程中的关键部分。
### Innovation
研究提出了一种架构，利用固定大小且可重用的变换器块作为核心结构，使其更适合硬件实现。该架构具有低复杂度、无令牌设计、无位置嵌入、均匀性和可扩展性，使其非常适合在移动和资源受限的设备上部署。提出的模型在无条件和有条件图像生成任务中表现出竞争力和一致性。该模型在无条件图像生成任务中使用CelebA数据集实现最先进的FID得分为1.6。
### Conclusion
通过采用固定大小的可重用变换器块，该模型不仅改善了在移动设备上的实现效率和性能，还展示了在无条件和有条件图像生成任务中的优异表现，特别是在CelebA数据集上取得了最先进的FID得分。
## 642. `cs.LG` - 短视频传播影响评级：一个新的现实世界数据集和一个新型大型图模型 [PDF](https://arxiv.org/pdf/2503.23746), [HTML](https://arxiv.org/abs/2503.23746)
### Authors
Dizhan Xue,Shengsheng Qian,Chuanrui Hu,Changsheng Xu
### Background
短视频平台在全世界吸引了大量用户，研究者们开始重视短视频传播的研究，包括商业价值、公众意见、用户行为等方面。
### Innovation
提出了一个新的短视频传播影响评级（SPIR）任务，包括开发了一个跨平台短视频（XS-Video）数据集和一个大型图模型（LGM，NetGPT）。数据集中包含了五个主要中国平台的大量短视频信息，并首次实现了跨平台数据集。LGM模型通过一种新颖的三阶段训练机制，结合了大型语言模型（LLMs）的强大推理能力和知识，能够理解和分析短视频传播图，预测短视频的长期传播影响。
### Conclusion
实验结果显示，提出的大型图模型NetGPT在对XS-Video数据集进行分类和回归评估中具有优越性，证明了其在短视频传播影响评级上的有效性和优势。
## 643. `cs.LG` - 揭露合成语音：通过音频指纹进行模型归属和检测AI生成的语音 [PDF](https://arxiv.org/pdf/2411.14013), [HTML](https://arxiv.org/abs/2411.14013)
### Authors
Matías Pizarro,Mike Laszkiewicz,Shawkat Hesso,Dorothea Kolossa,Asja Fischer
### Background
随着语音生成技术在质量和可访问性上的不断进步，恶意使用案例的风险迅速增加，包括假冒、误导和冒用等。因此，本文通过引入一种简单、无需训练、但有效的方法，旨在解决这一威胁，用于检测AI生成的语音并将其归因于其源模型。具体而言，该方法解决了三个关键任务：单模型开放环境下的归因、多模型封闭环境下的归因以及合成语音和真实语音的检测。该方法利用标准化平均残差，即输入音频信号与其经过低通滤波或EnCodec音频自编码器滤波后的版本之间的差异，这些残差能够有效捕捉各种语音合成系统引入的特征，作为不可知模型的指纹标识。
### Innovation
提出了利用标准化平均残差进行模型归属的方法，这是一种无需训练、简单高效且具有较强泛化的技术，适用于多种语音合成系统和语言。该方法能够以超过99%的AUROC评分在多数场景中实现优良检测性能，并且在噪声环境中依然能够保持高效率。这一技术为数字取证和安全应用提供了一种实用工具。
### Conclusion
本文方法通过利用标准化平均残差作为音频指纹，有效地解决了AI生成语音的检测与归因问题。实验结果表明，在大量扩充基准数据集上，无论是在合成与真实语音的检测，还是在不同环境下语音合成系统的模型归因，该方法均表现出色。此外，其在噪声环境下的鲁棒性也得到了验证。
## 644. `cs.LG` - 未来工作生成：基于RAG的方法 [PDF](https://arxiv.org/pdf/2503.16561), [HTML](https://arxiv.org/abs/2503.16561)
### Authors
Ibrahim Al Azher,Miftahul Jannat Mokarrama,Zhishuai Guo,Sagnik Ray Choudhury,Hamed Alhoori
### Background
未来工作部分概述了科学文章中的潜在研究方向，通过识别当前研究的空白和局限性。这部分为早教研究者提供了未探索的领域资源，也为经验丰富的研究者提供了新项目或合作的机会。为了增强未来的生成过程并减少错过重要研究方向的机会，本研究利用RAG（检索增强生成）中的相关论文上下文生成未来工作建议。研究人员尝试了各种大型语言模型（LLMs）与RAG的集成，并引入了大型语言模型反馈机制和大型语言模型作为评判者的框架来评估新颖性、幻象和可行性。实验结果表明，使用GPT-4o mini结合大型语言模型反馈机制的RAG方法，在定性和定量评估中均优于其他方法。此外，进行了人工评估来评估大型语言模型作为提取器、生成器和反馈提供者的效能。
### Innovation
本研究创新地使用RAG结合大型语言模型生成科学文章的未来工作，并引入了大型语言模型反馈机制和评判者框架，通过评估新颖性、幻象和可行性来提升生成内容的质量。结果显示这种方法在定性和定量评估中表现优异，表明了使用该方法生成科学文章未来工作时的适用性和有效性。
### Conclusion
基于RAG的GPT-4o mini方法，在结合大型语言模型反馈机制后，不仅能有效提高生成未来工作的质量，而且在定性和定量评估中均优于其他方法。研究中还通过人工评估验证了大型语言模型作为提取器、生成器和反馈提供者的实际效能，证明了该方法的有效性。
## 645. `cs.LG` - 基于闭环神经运算符的交通密度观测器 [PDF](https://arxiv.org/pdf/2504.04873), [HTML](https://arxiv.org/abs/2504.04873)
### Authors
Alice Harting,Karl Henrik Johansson,Matthieu Barreau
### Background
研究使用固定路边传感器进行稀疏测量来估计交通密度的问题。提出了使用傅里叶神经运算符从高保真数据中学习宏观交通流动力学的方法。
### Innovation
提出了一种闭环神经运算符观测器，该观测器在推理过程中作为开放环预测器工作，预测交通演变。为闭合循环，该开放环运算符与结合预测密度和传感器稀疏测量的校正运算符耦合。研究表明，与开放环观测器相比，提出的闭环观测器具有经典闭环特性，如对噪声的鲁棒性和误差的最终有界性，表明了将学习物理与实时校正相结合的优势。
### Conclusion
展示了结合学习的物理和实时校正的观测器的优势，并为准确、高效和可解释的数据驱动观测器开辟了途径。
## 646. `cs.LG` - 大语言模型在加密货币交易分析中的应用：以比特币案例研究为例 [PDF](https://arxiv.org/pdf/2501.18158), [HTML](https://arxiv.org/abs/2501.18158)
### Authors
Yuchen Lei,Yuexin Xiang,Qin Wang,Rafael Dowsley,Tsz Hon Yuen,Kim-Kwang Raymond Choo,Jiangshan Yu
### Background
加密货币在广泛使用的同时，现有的交易分析方法往往依赖于不透明的黑盒模型。尽管这些模型可能具有高性能，但其输出通常难以解释和调整，这对于捕捉复杂的用户行为模式提出了挑战。大型语言模型（LLMs）有潜力填补这一空白，但它们在这方面的应用尚未得到全面探索，尤其是在网络犯罪检测领域。本文旨在通过将LLMs应用于现实世界的比特币交易图，验证这一假设，并提出一种三层次框架来评估LLMs的能力，提高其在加密货币交易分析中的应用潜力，特别是在计算资源受限的情况下。
### Innovation
本文介绍了一种新的LLM框架用于加密货币交易分析：一种可读性较强的图表示格式——LLM4TG，以及一种增强连接性的交易图采样算法——CETraS。通过引入L4TG和CETraS，减少了令牌要求，使在严格的令牌限制条件下分析多个中等规模的交易图成为可能。实验结果显示，在基础度量和特征概述方面，LLMs表现出色，节点层面的基本信息识别准确率超过98.50%，且获得有意义特征的比例达到95.00%。在上下文解释方面，即使仅提供少量标记数据，LLMs在分类任务中的表现也非常出色，前三项准确性达到72.43%，带有说明。尽管说明有时不完全准确，但展示了LLMs在这一领域的巨大潜力。
### Conclusion
仍存在一些限制，本文也讨论了这些问题，并提出了未来研究的方向，表明需要进一步研究以充分利用LLMs在加密货币交易分析中的潜力。
## 647. `cs.LG` - 冷冻电镜图像本质上是低维度的 [PDF](https://arxiv.org/pdf/2504.11249), [HTML](https://arxiv.org/abs/2504.11249)
### Authors
Luke Evans,Octavian-Vlad Murad,Lars Dingeldein,Pilar Cossio,Roberto Covino,Marina Meila
### Background
冷冻电镜（cryo-EM）是一种强大的技术，可用于解析生物分子的结构。为了通过神经网络进行仿真等方法（如Cryo-SBI）推断生物分子的构象，仿真推断需要一种有力的框架。因此，研究这些方法中的潜空间几何结构和其与物理参数的关系显得尤为重要。
### Innovation
本文通过应用流形学习技术分析了Cryo-SBI中血凝素的模拟和实验数据的潜空间，揭示了这些高维数据实际上填充了低维、平滑的流形。通过使用扩散映射和坐标解释方法识别流形的主要变异轴，本文建立了潜结构与关键物理参数之间的直接联系。这一发现不仅验证了Cryo-SBI方法的有效性，还为未来推断策略的改进提供了新的机会。
### Conclusion
本文揭示了潜空间中内在的低维度性和可解释的几何组织，不仅验证了Cryo-SBI推断方法的有效性，还为从数据结构中提取更多信息和优化未来的推断策略提供了新的可能。
## 648. `cs.LG` - RBT4DNN: 基于需求的神经网络测试 [PDF](https://arxiv.org/pdf/2504.02737), [HTML](https://arxiv.org/abs/2504.02737)
### Authors
Nusrat Jahan Mozumder,Felipe Toledo,Swaroopa Dola,Matthew B. Dwyer
### Background
测试允许开发人员确定系统是否按预期运行。当这些系统包含深度神经网络（DNNs）时，测试变得具有挑战性，因为DNNs所逼近的函数使形式化功能需求变得难以处理，阻碍了基于需求测试的广泛应用。
### Innovation
本文提出了一种基于需求的测试方法（RBT4DNN），该方法使用自然语言需求陈述，通过词汇表定义语义特征空间，为测试输入生成提供支持。RBT4DNN通过逻辑组合这些语义特征来形式化功能需求的先决条件，并使用匹配这些特征组合的训练数据来精调生成模型，以可靠地生成满足先决条件的测试输入。对于由RBT4DNN生成的测试，可以在训练的DNN上执行，以比较其输出是否符合预期的功能要求后条件行为。此外，作者还提出了RBT4DNN的两个应用场景：（1）给定定义DNN正确性属性的需求，RBT4DNN为检测故障提供了一种新颖的方法。（2）在开发过程中，根据需求指导的模型行为探索可以为开发人员提供有关模型泛化能力的反馈。
### Conclusion
进一步评估表明，由RBT4DNN生成的测试是现实的、多样化的，且与需求先决条件保持一致，这使得对模型行为进行目标分析和有效故障检测成为可能。
## 649. `cs.LG` - 通过深度聚类揭示燃气发电单元的实际灵活性 [PDF](https://arxiv.org/pdf/2504.16943), [HTML](https://arxiv.org/abs/2504.16943)
### Authors
Chiara Fusar Bassini,Alice Lixuan Xu,Jorge Sánchez Canales,Lion Hirth,Lynn H. Kaack
### Background
发电单元的灵活性决定了它能够快速且频繁地增减负荷的能力。在能源模型中，这种灵活性依赖于对发电单元技术特性的假设，如安装容量或涡轮技术。本文通过分析5年间49个德国单位（共计100兆瓦的安装容量）的小时级发电数据，从中发现实际世界中的限制可以显著影响具有类似技术特性的发电单元之间的差异。
### Innovation
本文采用了一种新颖的无监督深度聚类方法，将5年（2019-2023年）的单位级别小时发电数据转换为低维嵌入。这种方法识别出了两种尖峰发电单元（高灵活性）和两种非尖峰发电单元（低灵活性）的簇。
### Conclusion
非尖峰发电单元占样本一半，显示出较低的实际灵活性，且与煤炭单元相当。这些非尖峰单元受工业和市政公用事业公司所有，对于低余量负荷和负电价的响应有限，在这些时段平均发电1.3吉瓦时。随着可再生能源的增加使得市场波动性增大，需要相应的政策调整来挖掘这些灵活性的潜力。
## 650. `cs.LG` - 基于包装配置树的3D箱装载细致规划 [PDF](https://arxiv.org/pdf/2504.04421), [HTML](https://arxiv.org/abs/2504.04421)
### Authors
Hang Zhao,Juzhan Xu,Kexiong Yu,Ruizhen Hu,Chenyang Zhu,Bo Du,Kai Xu
### Background
3D箱装载问题（3D-BPP）在工业自动化中有广泛的应用。现有的方法通常在有限的三维空间离散化和处理复杂实际约束方面存在局限性。该论文旨在通过学习在一种新颖的层次表示PCT（包装配置树）的基础上来增强3D-BPP的适用性。PCT能够全面描述装载箱的状态和行动空间，支持基于深度强化学习的装载策略学习，并简化行动空间使其易于训练且即使在连续解空间中也能表现出色。此外，论文还发现PCT作为基于树的规划器在解决工业关键问题方面具有潜力，如大规模包装和不同的3D-BPP设置。通过递归的包装方法和空间集成机制，论文提出了各种3D-BPP变体的有效解决方案框架，包括前瞻、缓存和离线包装。实证研究表明，该方法在处理大规模问题和不同问题变体时表现优异，并且能够灵活地整合多种实际约束条件，从而在不受保护的托盘上以每盒10秒的速度高效可靠地操作并实现较高的空间利用率。
### Innovation
PCT层次表示；递归包装方法；空间集成机制；统一规划框架适用于不同3D-BPP变体；有效解决大规模和复杂实际约束的3D-BPP问题
### Conclusion
通过递归包装方法和PCT规划设计，该研究提出了一种新的3D-BPP解决框架，能够有效地处理大规模和多种变型，同时在不受保护的托盘上可靠高效地操作，展现出广泛的应用潜力。
## 651. `cs.LG` - SGD的动态视角 [PDF](https://arxiv.org/pdf/2505.01751), [HTML](https://arxiv.org/abs/2505.01751)
### Authors
Vivek Shripad Borkar
### Background
贝尔金等人观察到，过参数化的神经网络表现出一种称为‘双重下降’的现象。即，随着模型复杂性（体现在特征数量的增加）的增加，测试错误率最初降低，然后增加，然后再次降低。在时间域中，这个现象以批量训练的方式表现出来，即测试错误率起初随着迭代次数的增加而降低，然后增加，然后再次降低。另一种异常现象是‘悟解’现象，其中，训练过程分为两个下降阶段，被一个损失均值几乎保持不变的阶段中断。这些现象以及相关的复现，已有理论方法来解释，但本文采用两时间尺度随机近似理论，并应用于梯度动态的连续时间极限，对其提供了一种新的解释框架。
### Innovation
本文创新性地使用了两时间尺度随机近似理论，将其应用于梯度动态的连续时间极限，对上述已有的理论框架进行新的解释，并提供了对这些异常现象及其相关现象的新视角。
### Conclusion
本文通过应用两时间尺度随机近似理论，并将其用于梯度动态的连续时间极限，提出了一种对已知现象的新解释框架，为其提供了新颖的洞察。
## 652. `cs.LG` - Text2Cypher：使用难例选择进行数据修剪 [PDF](https://arxiv.org/pdf/2505.05122), [HTML](https://arxiv.org/abs/2505.05122)
### Authors
Makbule Gulcin Ozsoy
### Background
关系数据库查询语言如SQL和图数据库查询语言如Cypher广泛采用。随着大型语言模型（LLMs）的发展，Text2SQL和Text2Cypher等模型使自然语言与数据库的交互成为可能。然而，这些模型的微调通常需要包含非平凡实例的大而多样化的数据集。这些数据集的大小随着问题复杂性的增加而增加，导致微调成本上升，因此，需要较小但高质量的数据集来降低成本并保持或提高性能。
### Innovation
本文提出五种难例选择技术来修剪Text2Cypher数据集。这些技术旨在通过减少资源使用来减小训练时间和成本，同时保持甚至改善性能。研究表明，使用这些难例选择方法可以将训练时间和成本减半，且对性能的影响几乎可以忽略不计，从而证明了难例选择是一种成本效益高的解决方案。
### Conclusion
难例选择技术可以显著降低Text2Cypher模型训练和资源成本，同时保持或提升性能，这一方法为数据库查询语言自然语言处理领域提供了一个经济有效的解决方案。
## 653. `cs.LG` - 使用模式过滤增强Text2Cypher [PDF](https://arxiv.org/pdf/2505.05118), [HTML](https://arxiv.org/abs/2505.05118)
### Authors
Makbule Gulcin Ozsoy
### Background
知识图谱通过节点、关系和属性表示复杂数据。Cypher 是一种用于图数据库的强大查询语言，可以高效建模和查询。近年来，大规模语言模型允许将自然语言问题转化为Cypher查询。常见的方法是在提示中包含数据库架构。然而，复杂的架构会引入噪声，增加幻觉，并提高计算成本。模式过滤通过包含仅相关模式元素来解决这些问题，从而改进查询生成并降低令牌成本。
### Innovation
该研究探讨了各种模式过滤方法在Text2Cypher任务中的应用，并分析了它们对令牌长度、性能和成本的影响。结果显示，模式过滤有效地优化了Text2Cypher，特别是对于较小的模型。我们的发现与先前的研究一致，较大的模型受益较少，因为它们具有更长的上下文能力。然而，模式过滤对于较大和较小的模型在降低成本方面仍然有价值。
### Conclusion
模式过滤方法有效地优化了Text2Cypher，尤其是在较小模型中。尽管较大的模型受益较少，但模式过滤仍然可以在降低计算成本方面为较大和较小的模型带来好处。
## 654. `cs.LG` - 社会模拟中大语言模型决策的计算基础 [PDF](https://arxiv.org/pdf/2504.11671), [HTML](https://arxiv.org/abs/2504.11671)
### Authors
Ji Ma
### Background
大语言模型（LLMs）在社会科学和实际应用中越来越像人类决策代理。这些LLM代理通常被赋予人类特征并置于现实场景中。然而，这些特征和场景如何影响LLM的行为还没有得到充分探索。为此，本研究提出并测试了在决策实验中探测、量化和修改LLM内部表示的方法，特别是在“分配者游戏”这种经典的行为实验中，评价公平性和利他行为。通过改变LLM内部状态的“变量变化向量”，可显著改变这些变量与其决策之间的关系。
### Innovation
研究提出了一种方法，通过操作LLM内部状态的向量变化来显著改变模型的决策过程，为研究和调节社会概念在变压器模型中的编码和工程提供了一个原则性框架，具有对齐、消偏和设计用于社会模拟的AI代理的实际应用意义。这不仅强化了社会学理论，还促进了社会测量的研究和发展。
### Conclusion
本研究为理解社会概念如何被编码和工程化在LLM中提供了方法论基础，且具有广泛的学术和商业应用前景，尤其在社会仿真中的AI代理人设计方面具有重要意义。
## 655. `cs.LG` - 递归训练中的模型崩溃理论基础 [PDF](https://arxiv.org/pdf/2506.09401), [HTML](https://arxiv.org/abs/2506.09401)
### Authors
Vivek Shripad Borkar
### Background
已知从生成模型中进行递归训练会导致模拟概率分布的所谓‘崩溃’现象。本文通过数学分析证明了在递归训练过程中，是否引入外部样本源会对最终行为产生显著影响，从而导致不同的渐近行为。
### Innovation
文章揭示了在递归训练过程中，即使引入极少量的外部样本源，也会导致模拟概率分布出现两种不同的渐近行为，这一发现为理解生成模型在训练过程中的行为提供了理论基础。
### Conclusion
研究表明，递归训练过程中是否会崩溃取决于是否引入外部样本源，这为预防和解决模型崩溃问题提供了新的视角。
## 656. `cs.LG` - 在解决基于扩散模型的逆问题中集成中间层优化和投影梯度下降 [PDF](https://arxiv.org/pdf/2505.20789), [HTML](https://arxiv.org/abs/2505.20789)
### Authors
Yang Zheng,Wen Li,Zhaoqiang Liu
### Background
逆问题涉及从有噪声的观察数据重构信号。近期，扩散模型已成为解决逆问题的强大框架，展现出显著的重构性能。然而，现有的基于扩散模型的方法通常面临计算量大和收敛性差等问题。论文基于DMPlug的方法，提出两种新的方法，DMILO和DMILO-PGD，以应对这些问题。
### Innovation
首先，DMILO利用中间层优化减轻了DMPlug中的内存负担；通过引入稀疏偏差，扩大了扩散模型的适用范围，能够探索可能超出扩散模型范围的底层信号。第二，DMILO-PGD结合了中间层优化与投影梯度下降，降低了次优收敛的风险。通过适当的条件提供了直观的理论分析，并通过广泛的实验验证了其优越性。
### Conclusion
实验结果表明，DMILO和DMILO-PGD在处理常见的基于扩散模型的逆问题挑战时，性能显著提升，突显了两者在解决逆问题中的有效性。
## 657. `cs.LG` - 无线边缘网络中的机器智能 [PDF](https://arxiv.org/pdf/2506.12210), [HTML](https://arxiv.org/abs/2506.12210)
### Authors
Sri Krishna Vadlamani,Kfir Sulimany,Zhihui Gao,Tingjun Chen,Dirk Englund
### Background
边缘设备上的机器智能能够实现低延迟处理和增强隐私保护，但常常受限于数据传输和转换的能量和延迟。当前系统通常通过将查询发送到服务器来规避局部模型存储，从而产生上行成本、网络延迟和隐私风险。
### Innovation
提出了相反的方法：基站将模型权重广播给客户端，客户端在无线接收链的RF波形中编码激活并使用现有的混频器和滤波器阶段进行计算，RF组件已经在数十亿的边缘设备（如手机）中存在，从而消除了重复的信号转换和额外硬件。研究显示，热噪声和非线性创造出一个最佳能量窗口，以实现准确的模拟内积。通过差分RF链的硬件定制训练可在这一范围内保持精度。电路启发式的模拟与同伴实验一致，展示了在普及无线边缘场景中减少内存和转换开销的同时，保持高精度。
### Conclusion
通过无线广播模型权重并在本地客户端进行本地推理，该策略在实际无线边缘场景中实现了减少内存和转换开销的同时保持高精度，为无线边缘网络中的机器智能应用提供了新的可能。
## 658. `cs.LG` - 强、弱与温和的Goodhart定律。基于独立性无关和框架无关的正式化 [PDF](https://arxiv.org/pdf/2505.23445), [HTML](https://arxiv.org/abs/2505.23445)
### Authors
Adrien Majka,El-Mahdi El-Mhamdi
### Background
Goodhart定律是政策制定领域的著名格言，指出当一个指标被设定为目标后，它就不再是一个好的指标。随着机器学习模型及其训练优化能力的增长，越来越多的实证证据支持了这一观点的正确性，然而并未正式化。此前的尝试仅对Goodhart定律的不同变体进行了分类或研究了优化代理指标如何影响目标优化，但大部分工作都做出了简化假设，即独立性假设和学习范式假设。
### Innovation
本研究缓解了前期研究中所做的一些简化假设，探索代理指标与目标之间的耦合效应对Goodhart定律的影响。研究结果显示，在目标和偏差均为轻尾分布的情况下，依赖关系并不改变Goodhart效应的本质。但在目标轻尾而偏差重尾的情况下，研究给出了一个由于代理指标优化过度导致目标优化受阻的反例，优化过度发生的速率与偏差重尾的程度成反比。
### Conclusion
在轻尾目标和重尾偏差的情况下，研究发现依赖性虽然对Goodhart效应的本质不产生影响，但过度优化的问题严重性会随着偏差重尾性的增加而加剧，这一发现为理解和应对Goodhart效应提供了新的视角。
## 659. `cs.LG` - 宽浅神经网络的渐近凸性 [PDF](https://arxiv.org/pdf/2507.01044), [HTML](https://arxiv.org/abs/2507.01044)
### Authors
Vivek Borkar,Parthe Pandit
### Background
该研究探讨的是浅而宽的神经网络模型，重点在于输入输出映射函数的参数变化特征。背景信息暗示了这类模型在实践中表现出良好的性能，但对其背后的理论机制尚不完全清楚，因此吸引了研究人员的兴趣以期提供更深入的理解和解释。
### Innovation
研究发现，对于浅而宽的神经网络模型，其输入输出映射函数的参数图像可以近似为某个凸函数的上图。这种发现为理解这类神经网络的优良性能提供了一个合理解释，增加了对其结构和行为的理论认识。创新点在于通过数学分析，提出了关于网络凸性的新观点，对神经科学和机器学习领域有重要影响。
### Conclusion
研究表明，浅而宽的神经网络在某种程度上可以近似为凸函数，因此在其输入输出映射上有良好的性质，解释了这类网络的优越性能。这为进一步优化和设计神经网络提供了理论依据。
## 660. `cs.LG` - 自回归生成与流匹配：文本到音乐生成中建模范式的比较研究 [PDF](https://arxiv.org/pdf/2506.08570), [HTML](https://arxiv.org/abs/2506.08570)
### Authors
Or Tal,Felix Kreuk,Yossi Adi
### Background
近年来，文字到音乐生成技术取得了显著进展，能够合成高质量的音乐片段、完整的乐曲作品乃至响应详细的控制信号（如和声进程）。目前最先进的系统在多个方面存在显著差异，如训练数据集、建模范式和架构选择。这种多样性使得评价模型性能变得复杂，难以确定哪些设计选择对性能影响最大。虽然数据和架构是重要因素，但本研究专注于建模范式的影响。通过系统性的实证分析，旨在研究不同范式之间的性能差异和伴随的权衡关系，为未来的发展提供指导。我们对比了两种最常用的建模范式，即自回归解码和条件流匹配。并在相同的训练数据集、配置和类似的基础架构下，从多个维度评估模型性能，包括生成质量、推断配置的鲁棒性、可扩展性、时间上的调节和编辑能力等。
### Innovation
本研究通过系统性的实证分析，对比了两种最常用的建模范式：自回归解码和条件流匹配，这是在完全相同的条件下进行的控制性比较。此外，该研究还首次全面地从多个维度，如生成质量、鲁棒性、可扩展性、时间上的精确度和编辑能力等方面对两种范式进行评估，提供了对每种范式独特优势和局限性的见解，为未来的模型设计和训练决策提供了行动指南。
### Conclusion
这项比较研究揭示了每种范式的独特优势和局限性，提供了对当前文本到音乐生成领域的见解，指导未来模型架构和训练决策。研究成果可以通过提供的链接聆赏音频样本。
## 661. `cs.LG` - 关于可复制假设检验器的结构 [PDF](https://arxiv.org/pdf/2507.02842), [HTML](https://arxiv.org/abs/2507.02842)
### Authors
Anders Aamand,Maryam Aliakbarpour,Justin Y. Chen,Shyam Narayanan,Sandeep Silwal
### Background
可复制假设检验算法在从同一分布抽取的两个不同样本上运行时，会产生相同输出的高概率。这种由Impagliazzo等人在STOC'22定义的概念可以增加对测试程序的信任，并且与算法稳定性、泛化能力和隐私密切相关。
### Innovation
本文构建了证明可复制测试器的样本复杂性上下界的一般工具，统一并定量改进了现有结果。发现了可复制测试算法的一组核心属性，并证明可以通过不损害精度或样本复杂性的方式对这些属性进行修改。此外，提出了统一并改进了设计可复制算法的常用策略，使得广泛分析过的测试器在最小开销下变得可复制，并得出了常数因子最优的筛子检验和接近性检验界限，为大量参数区间的均匀性测试提供了免费的可复制性。
### Conclusion
本文提高了均匀性、身份和接近性测试的下界。还为高斯均值检验提供了最先进的边界，并且算法运行在多项式时间内。
## 662. `cs.LG` - 广义和统一的计算硬度与伪熵等价性 [PDF](https://arxiv.org/pdf/2507.05972), [HTML](https://arxiv.org/abs/2507.05972)
### Authors
Lunjia Hu,Salil Vadhan
### Background
伪熵表征提供了一种精确证明计算硬度和计算随机性之间紧密关系的方法。本文证明了一个统一的伪熵表征，适用于统一性和非统一性计算模型，并且覆盖了包括香农熵和最小熵在内的通用熵概念。此外，文章表明，可以通过一个通用函数同时满足所有熵概念的伪熵表征，这一函数同时展示了计算硬度和计算随机性。
### Innovation
通过引入“受权重限制的校准”这一概念，文章证明了一种新的伪熵表征，这种表征不仅可以适用于更广泛的熵概念，而且可以实现指数级改进在字母大小依赖性方面的复杂性。文章的关键技术见解在于，这种新型的伪熵表征可以用“受权重限制的校准”和标准计算不可区分性（公平计算文献中的“多准确性”）来证明，从而极大地增强了经典复杂性理论正则性定理和泄漏模拟定理的威力。
### Conclusion
通过对计算硬度和伪熵之间关系的深入研究，文章建立了一种新的表征方法，不仅增强了被认可的复杂性理论正则性定理和泄漏模拟定理的效果，还在计算依赖性方面取得了重大的进展。这种新的研究视角为该领域带来了深远的影响，展示了伪熵表征在计算理论和公平性研究中的重要价值。
## 663. `cs.LG` - Robust Bandwidth Estimation for Real-Time Communication with Offline Reinforcement Learning [PDF](https://arxiv.org/pdf/2507.05785), [HTML](https://arxiv.org/abs/2507.05785)
### Authors
Jian Kai,Tianwei Zhang,Zihan Ling,Yang Cao,Can Shen
### Background
准确的带宽估计（BWE）对于实时通信（RTC）系统至关重要。传统的启发式方法在动态网络下适应性有限，而在线强化学习（RL）则面临探索成本高和潜在服务中断的问题。与在线RL相比，利用从真实环境收集的高质量数据的离线RL提供了有希望的替代方案，但仍面临目标任务外（OOD）动作、策略从行为多样性数据集提取、可靠生产部署等方面的技术挑战。
### Innovation
该论文提出了基于离线RL的鲁棒带宽估计框架RBWE，集成了Q-ensemble（一系列Q函数）和高斯混合策略，以减轻OO动作风险并增强策略学习。同时，设计了一种备用机制，在高不确定性情况下切换到启发式方法，确保部署稳定性。实验结果表明，RBWE能够将过度估计错误减少18%，并将第10百分位体验质量（QoE）提升18.6%，展示了其实用的有效性。
### Conclusion
RBWE框架通过借鉴离线RL的优势，成功解决了一系列挑战，并在实际RTC应用中展示了其显著效果，尤其是在降低过度估计误差和提升用户体验方面。
## 664. `cs.LG` - EigenBench: 一种价值观对齐的比较性行为测度 [PDF](https://arxiv.org/pdf/2509.01938), [HTML](https://arxiv.org/abs/2509.01938)
### Authors
Jonathn Chang,Leonhard Piff,Suvadip Sana,Jasmine X. Li,Lionel Levine
### Background
人类价值观与AI系统的对齐是一个迫切但尚未解决的问题。现有方法缺乏量化价值对齐的指标。EigenBench旨在填补这一空白，提供了一种黑盒方法，用于比较性地评估语言模型的价值观，从而推动这一领域的研究和发展。
### Innovation
EigenBench结合了EnigneTrust算法，通过模型之间的相互评估，为给定的宪法生成了一个向量得分，量化了每个模型的价值对齐情况。该方法不依赖于真实标签，而是通过广大模型间的一致性评判来客观反映模型特性。此外，研究还探索了提示对模型评分的影响，发现大部分差异来自提示，少数差异展示了模型本身的性质。
### Conclusion
EigenBench为语言模型的价值对齐提供了一种新的评估方法，通过黑盒评估模型间的相互评分，生成了一种不受人类主观判断影响的客观得分。这种新评估方法表明，提示在影响模型反馈方面起主要作用，但也间接地反映出模型本身的内在特性。这为价值对齐的研究提供了新的视角和工具。
## 665. `cs.LG` - 量子编码可学习编码的向量注意力机制用于量子变压器 [PDF](https://arxiv.org/pdf/2508.18464), [HTML](https://arxiv.org/abs/2508.18464)
### Authors
Ziqing Guo,Ziwen Pan,Alex Khan,Jan Balewski
### Background
量子块编码提供了将经典数据嵌入希尔伯特空间的方法，这为量子模型，如量子变换器（QT），提供了一条路径，这些模型用量子电路模拟取代了经典的自注意力机制，以更有效地运行。当前的QT依赖于深层可参数化量子电路（PQCs），这使得它们对量子处理单元（QPU）噪声敏感，从而阻碍了它们的实际性能。因此，为了克服这些问题，此研究围绕量子块编码和可学习的量子编码提出了一种新的模型，以提升量子变压器的性能和适用性，特别是针对噪声环境下的硬件实施。该模型允许通过量子近似模拟进行理想掩蔽注意矩阵计算，并通过向量化非线性量子编码进行高效的训练，从而减少量子电路模拟中的脉冲效率和无梯度量子电路模拟（QCS）中的经典采样开销。
### Innovation
本文提出了向量量子变换器（VQT），一种支持通过量子近似模拟进行理想掩蔽注意矩阵计算并在高效向量化非线性量子编码辅助下的精确训练的模型。VQT提供了从量子编码效率（QCS）和减少经典采样开销出发，实现量子计算中端到端机器学习的全新架构，能够用更有效的量子电路模拟及训练策略来代替传统模型。其优点包括减少对QPU噪声的依赖性，支持更强大的模型训练和更深层次的模拟。与IBM和IonQ的合作实验中展示了其对量子电路模拟的精度，以及在量子信息技术领域中的高性能，如IBM最先进的量子处理器上的自然语言处理任务。
### Conclusion
VQT通过高效的向量化非线性量子编码和精确的量子近似模拟，实现了在噪声背景下量子计算端到端的机器学习能力的突破。其显著特点是提高了量子运算效率、降低了经典采样负担，并成功在IBM的高级量子处理器上实现了自然语言处理任务的竞品性能。
## 666. `cs.LG` - RadioDiff-Loc: 基于稀疏射频图估计的散射认知增强扩散模型 NLoS 定位 [PDF](https://arxiv.org/pdf/2509.01875), [HTML](https://arxiv.org/abs/2509.01875)
### Authors
Xiucheng Wang,Qiming Zhang,Nan Cheng
### Background
在非视距（NLoS）环境中，非合作信号源的准确定位仍然是一个关键挑战，广泛应用于自主导航、工业自动化和应急响应等领域。传统依赖视距（LoS）或协作信号的定位技术由于严重的多径传播和未知发射功率而失效。因此，需要一种新的方法来克服这些限制，以实现NLoS环境中的精准定位。
### Innovation
提出了基于条件扩散模型的非视距定位新颖生成性推理框架。通过利用直徂电磁能量在建筑物边缘附近聚集的物理原理，发展目标角位置，这些位置能够最大化与未知源的相关性。在此基础上，通过归一化所采集的接收信号强度（RSS）值，并结合环境布局和稀疏RSS观测值训练条件扩散模型，重建完整的射频图（RM），最终通过识别生成的RM中最亮的点实现定位。此外，该框架可以与现有的RSS定位算法兼容，融合物理知识和数据驱动的推理以提高定位精度。
### Conclusion
理论分析和实验验证表明，我们的方法在显著降低采样成本的同时实现了高精度的定位，提供了一种可扩展并具有物理基础的非合作NLoS发射器定位解决方案。
## 667. `cs.LG` - 通过解耦反向传播实现的一阶模型导向的强化学习 [PDF](https://arxiv.org/pdf/2509.00215), [HTML](https://arxiv.org/abs/2509.00215)
### Authors
Joseph Amigo,Rooholla Khorrambakht,Elliot Chane-Sane,Nicolas Mansard,Ludovic Righetti
### Background
强化学习（RL）领域对利用模拟器的导数来提高学习效率的方法越来越感兴趣。早期基于梯度的方法已经展示了与无导数方法相比的优越性能，但访问模拟器的梯度往往由于实施成本高或不具可用性而具有挑战性。尽管模型导向的强化学习（MBRL）可以通过学习动力学模型来近似这些梯度，但在训练滚动过程中累积的预测误差会降低解算器效率并导致政策性能下降。
### Innovation
提出了一种解耦轨迹生成与梯度计算的方法。具体而言，使用模拟器展开轨迹，梯度通过模拟器的可微学模型进行反向传播来计算。这种混合设计允许在缺乏模拟器梯度时高效且一致地进行一阶策略优化，并能够从模拟滚动数据中学习一个更准确的批评家。该方法实现了与专门优化器（如SHAC）相当的样本效率和速度，同时保持了标准方法（如PPO）的通用性，避免了其他一阶MBRL方法中出现的不良行为。
### Conclusion
我们在基准控制任务上实验证明了该算法的有效性，并在真实Go2四足机器人上的四足行走和双足行走任务中展示了其效果。
## 668. `cs.LG` - 利用掩码条件生成模型进行特定形态肽的发现 [PDF](https://arxiv.org/pdf/2509.02060), [HTML](https://arxiv.org/abs/2509.02060)
### Authors
Nuno Costa,Julija Zavadlav
### Background
肽自组装预测为设计生物相容性和低毒性材料提供了一种强大的自下而上的策略，这些材料适用于广泛的生物医学和能源应用的大规模合成。然而，筛选庞大的序列空间以对聚集形态进行分类仍然是一个难以解决的问题。
### Innovation
我们引入了PepMorph，一个端到端的肽发现管道，生成不仅易于聚集还能组装成特定纤维状或球形形态的新序列。通过利用现有的聚集倾向数据集和提取几何和物理化学的孤立肽描述符来构建一个新数据集，这些描述符作为聚集形态的代理。然后使用带有掩码机制的基于Transformer的条件变分自编码器对数据进行训练，生成在任意条件下具有新序列的肽。在通过粗粒度的分子动力学模拟验证生成序列的设计规范后，PepMorph在预期形态生成上的准确率达到83%，展示了其作为一种基于应用的肽发现框架的潜力。
### Conclusion
PepMorph在特定形态生成上的高准确率证明了其作为驱动应用的肽发现框架的潜力。
## 669. `cs.LG` - 基于数据和模型压缩高效选择适合微调特定领域任务的最佳大规模语言模型(DaMoC) [PDF](https://arxiv.org/pdf/2509.01221), [HTML](https://arxiv.org/abs/2509.01221)
### Authors
Wei Huang,Huang Wei,Yinggui Wang
### Background
大语言模型（LLMs）在通用任务中表现出色，但在特定领域任务中存在不足，需要通过特定数据进行微调。在众多开源LLMs中选择最适合微调的模型是一项挑战，主要集中在如何快速找到最优的LLM。
### Innovation
提出了一种数据与模型压缩框架（DaMoC），该框架通过两方面解决选择最适合微调模型的问题：1) 数据层面：系统建立了数据过滤方法的分类，分为三大类：(1) 分布感知方法，(2) 质量感知方法，(3) 两者兼有的混合方法，并通过增强关键词密度实现了文本压缩，随后使用LLM迭代重写文本以优化表达效果。2) 模型层面：通过层相似性评分评估每层的重要性并移除低重要性层，引入稀疏合并以尽量保留原模型的性能。
### Conclusion
通过在四个数据集上的实验（医疗问答、金融问答、通用问答、阅读理解），证明DaMoC可以在节约约20倍训练时间的同时选择出最优的LLM。
## 670. `cs.LG` - 儿童腕部骨折的基于人口统计学的细粒度分类 [PDF](https://arxiv.org/pdf/2507.12964), [HTML](https://arxiv.org/abs/2507.12964)
### Authors
Ammar Ahmed,Ali Shariq Imran,Zenun Kastrati,Sher Muhammad Daudpota
### Background
儿童腕部骨折频发，尤其在骨折病例中占大多数。计算机视觉在这一领域显示出潜力，但需要大量数据集支持，这是一个明显的技术挑战。单一模态的数据，如影像，无法充分利用当前多样的数据类型。该研究采用多角度方法，将问题视为细粒度识别任务，结合患者元数据与X光片，利用来自特定细粒度数据集的预训练模型权重，而非粗粒度数据集如ImageNet。这种方法在处理儿童腕部骨折时首次整合了元数据。结果显示，结合细粒度变压器方法、细粒度预训练和元数据整合在小型定制数据集上提高了2%的诊断准确性，在较大的骨折数据集上提高了超过10%的诊断准确性。
### Innovation
首次将元数据整合应用于腕部病理识别，采用细粒度变压器方法和预训练模型，在不同大小数据集上分别提高了诊断准确率。
### Conclusion
研究采用多元方法，通过结合患者元数据和X光片，以及使用细粒度预训练模型，显著提高了腕部骨折诊断的准确性，在实际应用中具有重要的参考价值。
## 671. `cs.LG` - 理解空间——火箭科学：只有顶级推理模型才能解决空间理解任务 [PDF](https://arxiv.org/pdf/2509.02175), [HTML](https://arxiv.org/abs/2509.02175)
### Authors
Nils Hoehing,Mayug Maniparambil,Ellen Rushe,Noel E. O'Connor,Anthony Ventresque
### Background
研究表明当前的视觉和语言模型（VLMs）在空间关系的理解上表现不足。为了填补这一领域的研究空白，作者提出了RocketScience，一个开放源代码的对比VLM基准，用于测试空间关系理解能力，特别关注物体之间的相对空间理解及其顺序关系。该基准旨在对人类非常友好，但对现有的VLMs来说却极具挑战性。研究结果揭示了开源和前沿商业VLMs在这方面的不足，并展示了推理模型在解释空间理解任务上的显著性能。
### Innovation
RocketScience基准不仅提供了一种评估视觉和语言模型空间理解的新方法，而且通过分解链式思维模型中的物体定位和空间推理对基准表现的影响，进一步揭示了当前VLMs在空间推理方面的局限性，即其表现瓶颈在于空间推理能力而非物体定位能力。
### Conclusion
该研究展示了当前VLMs在空间理解任务上的不足，并提供了相应的数据集和评估代码，以促进未来的研究和改进。
## 672. `cs.SE` - 关于移动应用需求工程中使用的数据集：系统映射研究的初步发现 [PDF](https://arxiv.org/pdf/2509.03541), [HTML](https://arxiv.org/abs/2509.03541)
### Authors
Chong Wang,Haoning Wu,Peng Liang,Maya Daneva,Marten van Sinderen
### Background
研究移动应用的需求工程(RE)主要利用来自应用用户、开发者或供应商的数据集，但有关这些数据集来源的平台及基于这些数据集的研究的RE活动的详细信息仍然稀缺。
### Innovation
本研究通过系统映射研究，分析了现有移动应用RE研究中使用数据集的状态，发现Google Play和Apple App Store提供了超过90%的移动应用RE研究的数据集，最常研究的RE活动是需求获取和需求分析。
### Conclusion
主要结论包括：(1) 自2012年起，用于移动应用RE研究的数据集使用有所增长；(2) 移动应用的RE知识可能由于过度使用Google Play和Apple App Store而有所偏差；(3) 有人尝试通过数据仓库的评论补充其他数据源，以获取更多样性的数据；(4) 为了获取更加普适的结果，需要扩展其他数据源和实验，使用多种数据的组合；此外，还期望对更多的RE活动，如超越需求获取和分析的研究有所扩展。
## 673. `cs.LG` - 改进的采样算法和非对数正态分布的Poincaré不等式改进 [PDF](https://arxiv.org/pdf/2507.11236), [HTML](https://arxiv.org/abs/2507.11236)
### Authors
Yuchen He,Zhehan Lei,Jianan Shao,Chihao Zhang
### Background
本文研究了从具有密度 ∝ e^(-V) 的分布 μ 中抽取样本的问题，其中 V 是一个从 R^d 到 R 的势函数，通过查询 V 和 ∇V 来访问。研究基于两点标准假设：(1) 势函数 V 是 L-光滑的；(2) 第二矩 textbf{E}_{X textasciitilde} text{μ}[text{textnormalsizetextbf{X}}^2] text{textasciitilde} M。近期发现，即使在 Poincaré 常数可以任意大的情况下，从这种分布中采样的查询复杂性至少为 text{(LM / (dε)}^text{Ω(d)}。同时，在基于扩散的采样器研究中，一种常见的假设将光滑性条件 (1) 加强为 (1*)，即沿着从 μ 开始的 Ornstein-Uhlenbeck 过程的每个分布的势函数都是 L-光滑的。在此基础上，本文得出了在假设 (1*) 和 (2) 下的采样查询复杂性为 text{poly}(L,d)·text{(Ld + M / ε^2)}^text{textcal{O}(L + 1)} 的结果，当 L = text{O}(1) 和 M = text{poly}(d) 时，复杂性为 d 和 1/ε 的多项式形式。这改进了黄等人(COLT'24) 发展的复杂性为对数形式的采样算法。研究表明，在假设 (1*) 和更强的矩假设（当 X textasciitilde μ 时，text{textnormalsizetextbf{X}} 是 λ-次高斯的）下，μ 的 Poincaré 常数最多为 text{O}(λ)^(2(L + 1)) 的结果，这是应用本文方法的一个实际应用，可以得到高斯混合分布相同协方差下的 Poincaré 常数改进估算结果。
### Innovation
本文的关键创新是在基于扩散的采样器研究中，通过加强光滑性条件 (1) 为 (1*)，得出了复杂性显著降低的采样算法，表明这一看似适度的光滑性条件加强可以导致采样算法查询复杂性有指数级的巨大差别；利用这一条件和更强的矩假设（次高斯假设），得出了 Poincaré 常数的新上限。并通过该研究改进了高斯混合分布 Poincaré 常数的估算结果。
### Conclusion
在假设 (1*) 和特定的次高斯假设下，得到了从分布 μ 中抽取样本的有效算法及其查询复杂性的新上界。这一研究改进了对某些非对数正态分布的 Poincaré 常数估算，并为改进的采样算法设定了查询复杂性的上限。
## 674. `cs.SE` - APB交易的多阶段错误诊断 [PDF](https://arxiv.org/pdf/2509.03554), [HTML](https://arxiv.org/abs/2509.03554)
### Authors
Cheng-Yang Tsai,Tzu-Wei Huang,Jen-Wei Shih,I-Hsiang Wang,Yu-Cheng Lin,Rung-Bin Lin
### Background
现代系统级芯片（SoC）设计中的功能性验证和调试是关键瓶颈，手动在大型值变化转储（VCD）文件中检测高级外围总线（APB）事务错误效率低下且容易出错。
### Innovation
本文提出了一个基于分层随机森林的自动化错误诊断框架，采用多阶段错误诊断方式，使用四个预训练的二元分类器依次检测越界访问、地址破坏和数据破坏错误，优先处理高信心程度的地址相关故障，并逐步处理复杂的数据错误，以提高效率。实验结果显示91.36%的总体准确性，高精度和召回率针对地址错误，以及对数据错误的稳健性能。
### Conclusion
尽管ICCAD 2025 CAD竞赛的最终结果尚未公布，我们团队在内测阶段位列第一，突显了该方法的竞争优势。本文验证了分层机器学习作为电子设计自动化（EDA）硬件调试强效自动化工具的潜力。
## 675. `cs.LG` - 基于句向量变换器的方法将攻击描述映射到漏洞 [PDF](https://arxiv.org/pdf/2509.02077), [HTML](https://arxiv.org/abs/2509.02077)
### Authors
Refat Othman,Diaeddin Rimawi,Bruno Rossi,Barbara Russo
### Background
在安全领域，漏洞经常在被利用后仍被忽视。本文中的漏洞特指在Common Vulnerabilities and Exposures (CVE)报告中记录的公开披露的缺陷。将攻击与漏洞建立联系对于实现及时的事件响应至关重要，因为这能让防御者获得即时、可操作的见解。然而，手动将攻击与CVE进行关联是不切实际的，因此驱动自动化的需求。研究评估了14个最先进的（SOTA）句向量变换器模型，用以自动识别来自攻击文本描述的漏洞。研究结果表明，MMPNet模型在使用攻击Technique描述进行分类时表现最佳，F1分数为89.0、精确度为84.0、召回率为94.7。同时，发现MMPNet模型识别的56%漏洞也以某种形式与CVE库中的攻击相关联，61%的检测到的漏洞对应于CVE库中的记录。手动检查结果显示有275条预测链接未在MITRE库中列出。因此，将攻击技术与漏洞的自动化链接不仅提高了与软件安全事件相关的检测和响应能力，还缩短了漏洞的可利用时间，并有助于开发更安全的系统。
### Innovation
本文采用最先进的句向量变换器方法，自动识别来自攻击描述的漏洞。研究发现，MMPNet模型在此任务上表现出色，特别是在使用攻击Technique描述时的分类性能，这为自动化的深处演化提供了新的视角。此外，研究揭示了大量未在MITRE数据库中记录的关联，这进一步增强了自动化链接的价值。
### Conclusion
本文通过使用MMPNet模型，实现了从攻击描述自动鉴定CVE漏洞的任务，显著提升了安全防御的效率和响应速度。该研究成果有助于缩短漏洞的可利用时间，促进更安全的系统开发，同时也为未来的研究提供了新的数据集和基准。
## 676. `cs.SE` - 大规模编程过程分析中通过时间追踪语法树 [PDF](https://arxiv.org/pdf/2509.03668), [HTML](https://arxiv.org/abs/2509.03668)
### Authors
Matt Rau,Chris Brown,John Edwards
### Background
编程过程数据可以用来理解学生在编写计算机编程作业时所使用的过程。过去，键入和行级事件日志被用于各种用途，主要用于高层次的描述性统计（例如，时间、字符删除率等）。由于无法自动化跟踪历时的高级代码表示（如抽象语法树）以及时无法解析的状态，对行为进行上下文分析变得复杂。
### Innovation
本文研究有两个目标。首先，设计了第一个能跟踪语法树节点通过时间的算法。其次，利用这个算法来进行先前研究的手动代码表示跟踪部分复制研究，并进行以前无法大规模实现的学生编程行为分析。文章提出了两种算法，用于跟踪语法树节点并通过时间构建无法解析代码状态的树表示。应用这些算法到2021年CS1课程的学生课业的公共键入数据，并对生成的语法树进行了分析。发现新的可观察到的统计信息，包括代码在条件语句内外的删除率相似，并且三分之一注释掉的代码最终被恢复，学生在代码中频繁跳转并不一定代表有困难。
### Conclusion
通过时间追踪语法树的能力为理解和探索学生编程中的新维度打开了大门，例如时间上代码结构发展的最佳实践，学生在语法结构上最困难的定量测量，重构行为以及在代码内注意力转移等。
## 677. `cs.LG` - 功能ANOVA模型中的贝叶斯加性回归树 [PDF](https://arxiv.org/pdf/2509.03317), [HTML](https://arxiv.org/abs/2509.03317)
### Authors
Seokhun Park,Insung Kong,Yongdai Kim
### Background
贝叶斯加性回归树（BART）是一种强大的统计模型，结合了贝叶斯推断和回归树的优点。BART因其在捕捉复杂非线性关系和预测变量间交互方面的强大能力，受到了广泛关注。然而，BART的准确性往往以解释性为代价。为了克服这一局限性，我们提出了基于功能ANOVA分解的ANOVA-BART，该方法将函数的变异分解为不同的交互作用，每个交互作用代表不同变量或因素的一组贡献。这样，ANOVA-BART提高了解释性，同时保留并扩展了BART的理论保证，并实现了更优的预测性能。
### Innovation
我们提出的ANOVA-BART是一种基于功能ANOVA分解的新BART扩展，它将函数的变异分解为不同的交互作用，每个交互作用代表不同变量或因素的影响。与BART相比，ANOVA-BART在保持解释性和理论保证的同时，提升了预测性能。我们证明了ANOVA-BART的后验集中速率几乎达到了最小最大最优，并且为每个交互作用提供了与其他变量或因素相关的相同收敛速率，这是BART无法提供的。广泛的实验结果表明，ANOVA-BART在准确性和不确定性量化方面均超过BART，并且证明了其在组件选择方面的有效性。
### Conclusion
研究结果表明，ANOVA-BART通过平衡预测准确性、解释性和理论一致性，为BART提供了一种引人注目的替代方案。
## 678. `cs.LG` - AudioCodecBench: 音频编解码评估的全面基准 [PDF](https://arxiv.org/pdf/2509.02349), [HTML](https://arxiv.org/abs/2509.02349)
### Authors
Lu Wang,Hao Chen,Siyu Wu,Zhiyue Wu,Hao Zhou,Chengfeng Zhang,Ting Wang,Haodi Zhang
### Background
多模态大语言模型（MLLMs）在语音和音乐领域已经有了广泛应用，这导致了对大模型（LMs）的音音频量化方法的关注。音频令牌与仅依赖于语义的文本令牌不同，必须同时捕捉全局语义内容和保留细微的声学细节。现有的研究在语义令牌和声学令牌的定义上存在不足，并且在不同编解码器的评估上通常集中在特定领域或任务，如重构或自动语音识别（ASR）任务，这阻碍了公平和全面的比较。
### Innovation
本文提供了语义令牌和声学令牌的合适定义，并引入了一种系统性的评估框架。该框架可以全面评估编解码器的能力，评估维度包括音频重构度量、码本索引（ID）稳定性、仅解码器变压器的困惑度以及下游探针任务的表现。
### Conclusion
研究结果显示提供的合适定义的正确性以及重构度量、码本ID稳定性、下游探针任务和困惑度之间的关联性。
## 679. `cs.SE` - VulRTex：一种基于推理的从富文本问题报告中识别漏洞的方法 [PDF](https://arxiv.org/pdf/2509.03875), [HTML](https://arxiv.org/abs/2509.03875)
### Authors
Ziyou Jiang,Mingyang Li,Guowei Yang,Lin Shi,Qing Wang
### Background
开源软件（OSS）中存在软件漏洞，开发者发现这些漏洞后会提交问题报告（IRs）来描述漏洞细节。安全专家需要手动识别这些与漏洞相关的IRs，耗费大量时间。这种时间延迟可能被攻击者利用来损害系统。尽管已有研究人员提出自动方法来识别这些与漏洞相关的IRs，但这些工作主要关注文本描述，缺乏对IRs丰富文本信息的全面分析。
### Innovation
本文提出了一种名为VulRTex的基于推理的方法，利用大规模语言模型（LLM）的推理能力构建漏洞推理数据库，并通过准备的数据库检索相关案例为LLM生成推理指导，引导其通过对目标IRs丰富文本信息进行推理分析来识别漏洞。实验结果表明，VulRTex在不平衡数据集上识别漏洞相关的IRs和预测CWE-IDs方面表现最佳，相比最优基线提升了F1得分11.0%，AUPRC 20.2%，宏F1得分10.5%，且耗时仅为基线推理方法的二分之一。
### Conclusion
VulRTex 已应用于识别2024年GitHub IRs中的30个新兴漏洞，并成功给11个漏洞分配了CVE-ID，证明了其实用性。
## 680. `cs.SE` - Python 包中的漏洞及其检测方法的实证研究 [PDF](https://arxiv.org/pdf/2509.04260), [HTML](https://arxiv.org/abs/2509.04260)
### Authors
Haowei Quan,Junjie Wang,Xinzhe Li,Terry Yue Zhuo,Xiao Chen,Xiaoning Du
### Background
近年来，随着软件开发环境的快速变化，Python 以其简洁易用和强大的生态系统脱颖而出。Python 包作为单位组织、可重用和分发的模块，出现了许多安全漏洞报告，特别是在其与不同语言协作时，给检测工具带来了更多复杂性。目前，用于发现 Python 包漏洞的技术和工具的有效性尚未充分探索。
### Innovation
本文介绍了 PyVul，这是一个全面的 Python 包漏洞基准套件，包含 1,157 个公开报告且开发者验证的漏洞，每个漏洞都链接到受影响的包，并提供在提交和函数级别的注释，以适应多种检测技术。利用一种基于 LLM 的数据清洗方法，以提高标签准确性，这使得 PyVul 成为了最精准的大规模 Python 安全漏洞基准。
### Conclusion
通过使用此基准对现有工具进行评估，我们发现现有技术与实际世界中有效识别 Python 包安全问题的需求之间存在显著差距。此外，我们还进行了顶级 CWEs 的实证审查，以诊断当前检测工具的细微局限和强调该领域未来的进步需求。
## 681. `cs.SE` - The Auth Shim: 一种集成企业SSO与独立开源应用的轻量级架构模式 [PDF](https://arxiv.org/pdf/2509.03900), [HTML](https://arxiv.org/abs/2509.03900)
### Authors
Yuvraj Agrawal
### Background
开源软件OSS在企业环境中被广泛应用，但独立工具往往缺乏对SAML或OIDC等协议的原生支持，这导致了关键的安全集成缺口。
### Innovation
本文介绍并形式化了Auth Shim，这是一种轻量级的架构模式，用于解决该问题。Auth Shim是一种最小化且外部的代理服务，作为兼容层，将企业身份提供程序IdP的请求转化为目标应用程序的原生会话管理机制。关键前提是目标应用程序必须提供可编程和安全的管理API。通过在Adobe的案例研究中实施该模式，将一款流行的OSS BI工具与Okta SAML集成，实现了基于角色的访问控制RBAC并通过IAM组映射，并消除了手动用户配置的工作。
### Conclusion
通过定义其组件、交互以及生产部署考虑，本文提供了一个可重用、安全且经济高效的蓝图为任何独立的OSS工具集成到企业的SSO生态系统中提供了一个蓝图，从而使组织能够拥抱开源创新，同时不牺牲安全治理。
## 682. `cs.SE` - 分析代码异味交互导致的依赖分布变化 [PDF](https://arxiv.org/pdf/2509.03896), [HTML](https://arxiv.org/abs/2509.03896)
### Authors
Zushuai Zhang,Elliott Wen,Ewan Tempero
### Background
模块间的依赖关系可能导致更改一个模块时引发连锁反应，增加维护复杂性与成本。因此建议尽量减少模块间的依赖。代码气味（代码中可能指示潜在设计问题的特点）的交互可能增加模块间的依赖关系，本研究旨在验证这些观察，并探讨在代码气味交互存在时，依赖关系的分布如何变化，对比代码气味间的交互和代码气味与其他代码元素（非代码气味）的交互情况。
### Innovation
本研究通过分析116个开源Java系统，量化代码气味交互对静态依赖分布的影响。研究发现代码气味交互既会增加某些依赖关系，也会减少某些依赖关系，总体上导致总依赖关系增加。例如，特征嫉妒方法与数据类之间的依赖关系是普通方法时的7倍，依赖关系从1增加到7。这表明开发者应优先解决交互的代码气味，而非孤立存在的代码气味，从而减少复杂性和成本。
### Conclusion
研究证实了代码气味交互对依赖关系分布的影响，并强调了解决交互的代码气味的重要性。
## 683. `cs.SE` - 漏洞受影响版本识别：我们走了多远？ [PDF](https://arxiv.org/pdf/2509.03876), [HTML](https://arxiv.org/abs/2509.03876)
### Authors
Xingchu Chen,Chengwei Liu,Jialun Cao,Yang Xiao,Xinyue Cai,Yeting Li,Jingyi Shi,Tianqi Sun,Haiming Chen ang Wei Huo
### Background
识别哪些软件版本受到了漏洞的影响对于补丁的安装和风险控制至关重要。尽管存在多种工具来实现这一目标，但它们的实际效果存疑，因为这些工具的评估范围往往较窄，主要限于早期SZZ变体，过时的技术，以及小规模或粗粒度的数据集。本文研究了漏洞受影响版本识别的第一个全面实证研究。
### Innovation
作者创建了一个高质量的基准，包含1128个真实世界的C/C++漏洞，系统地评估了12种代表性的工具，涵盖了有效性、误报和漏报的根本原因、补丁特征的敏感性以及组合潜力四个方面。该研究揭示了工具的关键限制，如依赖启发式方法、有限的语义推理和严格的匹配逻辑。此外，作者还发布了复制的代码和基准数据集，以鼓励未来的研究和技术发展。
### Conclusion
研究发现，没有工具能达到45.0%以上的准确性，尽管组合策略可以改进结果，但总体准确率仍低于60.0%，表明需要根本性的新方法。此外，研究提供了工具开发、策略组合和未来研究方面的实用见解。
## 684. `cs.SE` - RepoDebug：大型语言模型在仓库级别多任务和多语言调试评估中的评价数据集 [PDF](https://arxiv.org/pdf/2509.04078), [HTML](https://arxiv.org/abs/2509.04078)
### Authors
Jingjing Liu,Zeming Liu,Zihao Cheng,Mengliang He,Xiaoming Shi,Yuhang Guo,Xiangrong Zhu,Yuanfang Guo,Yunhong Wang,Haifeng Wang
### Background
大型语言模型（LLMs）在代码调试，特别是自动程序修复方面表现出显著的专业水平，有助于大幅减少开发人员的时间消耗并提高其效率。为了推动代码调试的发展，已经在调试数据集方面取得了显著进步。然而，这些数据集主要集中在评估LLM的功能级代码修复能力，忽略了更为复杂和真实的仓库级场景，导致对LLM在仓库级调试中的挑战理解不完整。虽然提出了一些仓库级的数据集，但它们往往受限于任务、语言和错误类型多样性不足的问题。因此，论文引入了RepoDebug数据集，该数据集支持8种常用编程语言，并包含3种调试任务和22种不同类型错误的多任务、多语言仓库级代码调试数据集，以解决上述挑战。
### Innovation
论文提出了RepoDebug数据集，这是一个支持8种常用编程语言并在多任务和多语言环境下提供22种不同错误类型的仓库级代码调试数据集。此外，作者还对10种大型语言模型进行了评估实验，结果显示最佳性能的模型Claude 3.5 Sonnect在仓库级调试方面仍然表现不佳。这项工作旨在为大型语言模型在复杂且真实的仓库级调试任务中的性能评估提供一个新的标准，以帮助进一步的研究和发展。
### Conclusion
尽管现有的仓库级调试数据集存在局限性，如任务、语言和错误类型的多样性不足，但RepoDebug数据集在支持多功能和多语言调试方面填补了这一空白。然而，当前的最佳模型仍无法充分处理仓库级调试任务，这表明该领域仍有改进的空间。
## 685. `cs.SE` - 理解基于开发者体验的软件生态系统透明度 [PDF](https://arxiv.org/pdf/2509.03848), [HTML](https://arxiv.org/abs/2509.03848)
### Authors
Rodrigo Oliveira Zacarias,Rodrigo Pereira dos Santos,Patricia Lago
### Background
软件生态系统（SECO）已成为软件产业的主导模式，第三方开发者的互补组件和服务共同创造价值。尽管开发者体验（DX）已被认为对于可持续的SECO至关重要，但透明度作为影响开发者感知和互动的关键因素，尚未得到充分研究。现有研究已认识到透明度对于建立信任、公平和参与的重要性，但其与开发者体验的关系没有得到系统化研究。
### Innovation
本文提出SECO-TransDX（从开发者体验视角看软件生态系统中的透明度）的概念模型，引入了由开发者体验驱动的透明度的概念。该模型识别了63个相互关联的概念，涵盖影响透明度感知和构建的因素、生态程序、产物和关系动态等方面，丰富了对透明度的理解。该模型通过专家和从业者参与的德尔菲研究进行优化，提供了一种结构化的视角来研究透明度如何在技术和组织层面上调节开发者体验。
### Conclusion
该模型为未来研究和工具开发奠定了基础，有助于设计可靠的、以开发者为中心的平台，提高透明度并促进SECO中的长期参与。
## 686. `cs.LG` - 数据集蒸馏作为推进最优量化 [PDF](https://arxiv.org/pdf/2501.07681), [HTML](https://arxiv.org/abs/2501.07681)
### Authors
Hong Ye Tan,Emma Slade
### Background
数据集蒸馏的目标是在合成训练集上训练，使得训练效果与在真实数据上的训练效果相似，但所花费的计算资源大大减少。现有方法大致可以分为两大类：一类是具有神经网络训练启发式的双重优化问题；另一类则是通过匹配数据分布来绕过双重优化的解缠方法。解缠方法在训练和蒸馏数据集大小方面具有速度和可扩展性的优势。
### Innovation
研究中指出，当结合编码器-解码器结构时，现有的成功解缠方法可以重新表述为最优量化问题，其中发现一组有限的点来通过最小化期望投影距离来逼近潜在的概率测度。研究进一步将现有解缠数据集蒸馏方法与经典的最优量化和Wasserstein中心化问题相连接，证明了蒸馏数据集对于基于扩散的生成先验的一致性。基于聚类在隐空间中的方法，该研究提出了基于最优量化优化的数据集蒸馏方法，该方法在额外计算量微乎其微的情况下，在ImageNet-1K数据集上比以前的SOTA方法D^4M实现了更好的性能和跨模型的一般化，并在更大的每类别图像数量设置中取得了SOTA性能。该研究还展示了在更强的扩散转换器模型中使用蒸馏的噪声初始化所获得的SOTA数据集蒸馏性能，超越了扩散引导方法。
### Conclusion
该研究通过将解缠数据集蒸馏方法重新表述为最优量化问题，提出了新的方法，并在多个实验中展示了其优越性，尤其是在ImageNet-1K数据集及其实验子集上获得了SOTA性能。
## 687. `cs.SE` - FaaSGuard: 安全的持续集成/持续部署为无服务器应用程序 -- OpenFaaS 案例研究 [PDF](https://arxiv.org/pdf/2509.04328), [HTML](https://arxiv.org/abs/2509.04328)
### Authors
Amine Barrak,Emna Ksontini,Ridouane Atike,Fehmi Jaafar
### Background
无服务器计算改变了软件开发的模式，通过抽象基础设施管理，实现快速、模块化和事件驱动的应用部署。然而，无服务器函数的特性，如短暂执行和精细粒度的可缩放性，为开放源代码平台如OpenFaaS带来了独特而具体的网络安全挑战。现有方法通常仅覆盖DevSecOps生命周期的各个孤立阶段，缺乏整体和全面的安全策略。为解决这些问题，我们提出了一种名为FaaSGuard的集成DevSecOps管道，专门针对开源无服务器环境。FaaSGuard系统地嵌入了轻量级且故障安全的安全检查，覆盖开发生命周期的每个阶段：计划、编码、构建、部署和监控，有效应对注入攻击、硬编码密钥等威胁。实证研究表明，FaaSGuard能够检测并防止关键漏洞，其精准度达到95%，召回率达到91%，并未对现有的持续集成和持续部署实践造成显著干扰。
### Innovation
提出FaaSGuard，一种针对开源无服务器环境设计的统一DevSecOps管道，它系统性地将轻量级的故障安全安全检查嵌入到开发生命周期的每个阶段，有效应对各种安全威胁，且验证其在实际部署中能高效地检测和预防关键漏洞，几乎不影响当前的持续集成/持续部署流程。
### Conclusion
通过20个来自公开GitHub库的实际无服务器函数案例研究验证了FaaSGuard的有效性，其精准度高，能有效检测和预防关键漏洞，同时证明了这种方法对现有CI/CD流程影响较小。
## 688. `cs.SE` - 设计与开发用于血液捐赠管理的网络平台 [PDF](https://arxiv.org/pdf/2509.04423), [HTML](https://arxiv.org/abs/2509.04423)
### Authors
Fatima Zulfiqar Ali,Atrooba Ilyas
### Background
血液捐赠是医疗保健的关键组成部分，但在紧急情况下找到合适的献血者往往面临重大挑战。现有的血液捐赠系统缺乏有效的在线平台，导致在紧急情况下延迟和复杂性增加，影响了血液的及时获取和整体效率提高。
### Innovation
本文设计并开发了一个基于Web的血液捐赠平台，该平台集成了患者、献血者和管理人员，通过使用现代Web技术，如PHP (Laravel框架)、HTML、CSS、Bootstrap和MySQL，构建了一个动态、互动且用户友好的平台。该平台通过简化献血者注册、血液需求和通信，减少了紧急情况下的延迟和复杂性，提高了血液的及时获得性和整体效率。平台设计时采用了用例、数据库、类和序列图来确保系统架构的结构化和高效性。
### Conclusion
提出的系统在急救场景中可以有效缩短血液获取的时间，简化流程，提升效率，因此对优化现有血液捐赠服务体系具有重要作用和价值。
## 689. `cs.SE` - 评估大型语言模型在跨内存模型理解与验证并发程序的能力 [PDF](https://arxiv.org/pdf/2501.14326), [HTML](https://arxiv.org/abs/2501.14326)
### Authors
Ridhi Jain,Rahul Purandare
### Background
随着并发编程的日益普遍，有效识别和解决数据竞争和死锁等并发问题变得至关重要。本研究评估了几款主流大型语言模型（LLMs），包括GPT-3.5-turbo、GPT-4、GPT-4o、GPT-4o-mini和Mistral-AI的Large2，它们在理解和分析软件程序中的并发问题方面的性能。
### Innovation
研究不仅考察了模型在顺序一致内存模型下的能力，还考察了其在广泛应用于现代系统中的放宽内存模型（如TSO和PSO）下的表现。通过使用SV-COMP的pthread测试和25个ARM Litmus测试来评估。”这些测试旨在评测TSO和PSO内存模型的表现，结果显示GPT-4、GPT-4o和Mistral-AI的Large2具有稳健的理解并发问题的能力，但所有选定的LLMs在验证程序的正确性时面对放宽内存模型时表现出显著挑战，尤其在准确捕捉内存排序约束上存在局限，导致在复杂场景下无法验证甚至小规模程序的正确性。
### Conclusion
尽管GPT-4、GPT-4o和Mistral-AI的Large2在顺序一致内存模型下表现良好，这些LLMs在验证放宽内存模型下程序的正确性时仍面临巨大挑战。这些模型当前在验证复杂场景中的程序正确性方面能力有限。
## 690. `cs.SE` - RBT4DNN：基于需求的神经网络测试 [PDF](https://arxiv.org/pdf/2504.02737), [HTML](https://arxiv.org/abs/2504.02737)
### Authors
Nusrat Jahan Mozumder,Felipe Toledo,Swaroopa Dola,Matthew B. Dwyer
### Background
对于包含深度神经网络（DNN）的系统，测试变得困难，因为正式化功能需求是可解的，这使得基于功能需求的测试方法难以应用于DNNs。因此，需要开发一种新的基于需求的测试方法来解决这一问题.
### Innovation
提出了RBT4DNN的方法，使用自然语言需求声明，并通过词汇表定义语义特征空间来进行测试输入生成。它可以将功能需求的前提条件形式化为语义特征的逻辑组合，并利用匹配这些特征组合的训练数据对生成模型进行微调，以可靠地生成满足前提条件的测试输入。这种方法可以用于检测故障，指导模型行为的开发过程，并提供关于模型泛化效果的反馈。
### Conclusion
RBT4DNN生成的测试是现实的、多样的，并且与需求的前提条件一致，这有助于对模型行为进行目标化的分析，有效检测故障。
## 691. `cs.SE` - BIDO：解决基于图像的恶意软件检测中混淆和概念漂移挑战的统一方法 [PDF](https://arxiv.org/pdf/2509.03807), [HTML](https://arxiv.org/abs/2509.03807)
### Authors
Junhui Li,Chengbin Feng,Zhiwei Yang,Qi Mo,Wei Wang
### Background
为了识别恶意的Android应用程序，提出了多种恶意软件检测技术。其中，基于图像的方法被认为是潜在的替代方案，因其效率和可扩展性。然而，最近的研究表明，当面临混淆或概念漂移时，这些方法会遭受显著的性能下降。现有的解决方案往往将这两个挑战视为不同的问题，并提供了独立的解决方案。这些技术忽视了两个挑战共享一个共同的统计根源：即离分布现象，而从这个角度来看的研究仍然有限。
### Innovation
本文提出了BIDO，一种用于同时增强对抗混淆和概念漂移的鲁棒性的混合图像恶意软件检测器。具体来说，通过引入局部特征选择模块来提高图像特征的区分力，该模块标识出恶意软件图像中的信息子区域。其次，通过在外积空间中建模交叉模态依赖关系来增强特征的鲁棒性，从而提取出稳定共现模式。第三，通过设计可学习的度量来确保特征的紧凑性，从而在不考虑混淆或概念漂移的情况下，将具有相同标签的样本拉近，将具有不同标签的样本推开。广泛的实验证明，BIDO显著优于现有基线，在对抗概念漂移和混淆方面的鲁棒性更强。
### Conclusion
BIDO在真实世界的数据集上的广泛实验表明，它显著优于现有的基线方法，能够在两者同时面临混淆和概念漂移的情况下展现出更高的鲁棒性。源代码可在指定的网址找到。
## 692. `cs.SE` - Reactive Bottom-Up Testing [PDF](https://arxiv.org/pdf/2509.03711), [HTML](https://arxiv.org/abs/2509.03711)
### Authors
Siddharth Muralee,Sourag Cherupattamoolayil,James C. Davis,Antonio Bianchi,Aravind Machiry
### Background
现代计算系统中仍然普遍存在着软件漏洞，工程师们采用多种方法检测这些漏洞，动态测试是其中最为常见和有效的一种。然而，大多数动态测试技术遵循自顶向下的方法，难以触及并执行调用图深处的函数。近期的研究提出了一种自底向上的方法来解决这些问题，但该方法面临高误报率以及生成符合整个程序上下文的有效输入的挑战。因此，有必要开发一种系统性的方法，不仅在孤立环境中测试函数的行为，还能够在其更大的程序上下文中进行验证，确保检测出的漏洞是可访问和可触发的。
### Innovation
该研究提出了一种新的自底向上的测试方法，称为Reactive Bottom-Up Testing。该方法分为三个阶段：首先识别可能的漏洞函数并生成类型和上下文感知的桩；其次使用模糊测试找到崩溃并使用符号执行提取输入约束；最后通过结合约束来验证崩溃情况，去除误报。作者实现了一个自动原型名为Griller，并在一组基准测试中进行了评估，该基准包含来自5个开源项目的48个已知漏洞，成功检测到了其中28个漏洞。此外，Griller还被应用于Pacman等实际应用，发现了6个以前未知的漏洞。研究结果表明，Reactive Bottom-Up Testing可以显著增强复杂系统中漏洞的检测能力，为更坚固的安全实践铺平道路。
### Conclusion
Reactive Bottom-Up Testing能显著提高复杂系统中漏洞的检测能力，该方法为未来的漏洞检测技术提供了新的思路。
## 693. `cs.SE` - 如何获取可解释性需求？访谈、焦点小组与问卷调查的比较 [PDF](https://arxiv.org/pdf/2505.23684), [HTML](https://arxiv.org/abs/2505.23684)
### Authors
Martin Obaidi,Jakob Droste,Hannah Deters,Marc Herrmann,Raymond Ochsner,Jil Klünder,Kurt Schneider
### Background
随着软件系统变得越来越复杂，解释性已成为确保透明性、用户信任和合规的关键非功能性需求。然而，获取解释性需求使得不同的方法捕捉到的详细程度和结构存在差异，这使得需求获取变得具有挑战性。本研究通过在一家大型德国IT咨询公司中使用基于人员管理软件的案例研究，评估了三种常用获取方法——焦点小组、访谈和在线调查的效率和效果，并考察了分类词汇表在规范和改善需求获取过程中的作用。
### Innovation
研究通过实证数据展现了不同需求获取方法的优缺点，并推荐了一种结合问卷和访谈的混合方法，以平衡效率和覆盖面。研究还指出，引入分类词汇表可能需要分成两个阶段，并探讨了自动化在需求获取中的支持作用以及分类词汇表如何更好地整合到不同的方法中。
### Conclusion
本研究建议采用结合在线调查和访谈的混合方法来获取解释性需求，这种方法既提高了效率又保证了覆盖范围。未来的研究方向应探索自动化如何支持需求获取以及如何更好地将分类词汇表整合到各种方法中。
## 694. `cs.SE` - 较小模型未必更好：探索在日志语句生成中的开源小模型 [PDF](https://arxiv.org/pdf/2505.16590), [HTML](https://arxiv.org/abs/2505.16590)
### Authors
Renyi Zhong,Yichen Li,Guangba Yu,Wenwei Gu,Jinxi Kuang,Yintong Huo,Michael R. Lyu
### Background
开发人员通过日志语句创建日志以记录系统行为并协助软件维护。这需要高质量的日志，但手动创建日志往往会导致错误和不一致性。最近的方法侧重于使用大语言模型（LLMs）来自动化日志语句生成，但这些方法存在隐私和资源问题，限制了其在企业中的适用性。研究指出，开源小模型（SOLMs）可能提供一种隐私保护、高效的替代方案，但仍需要进一步验证其在自动化日志生成中的效果和适用性。
### Innovation
论文首次进行了大规模实证研究，评估了四种主流的开源小模型在自动化日志语句生成中的表现，使用了各种提示策略和参数高效的微调技术（如LoRA和RAG）。研究表明，经过LoRA和RAG微调的SOLMs，特别是Qwen2.5-coder-14B，在预测日志位置和生成高质量的日志语句方面表现优于现有工具和LLM基线，且具有跨不同项目的鲁棒性。
### Conclusion
研究结果表明，开源小模型可以作为一种隐私保护、高效的自动化日志生成替代方案，为日志语句生成领域提供了新视角。
## 695. `cs.SE` - InferLog：通过ICL导向的前缀缓存加速在线日志解析的LLM推理 [PDF](https://arxiv.org/pdf/2507.08523), [HTML](https://arxiv.org/abs/2507.08523)
### Authors
Yilun Wang,Pengfei Chen,Haiyu Huang,Zilong He,Gou Tan,Chuanfu Zhang,Jingkai He,Zibin Zheng
### Background
现代软件系统生成大量运行时日志，需要高效准确的日志解析以支持关键的下游任务，如异常检测和根本原因分析。近年来，大型语言模型（LLMs）在日志解析方面取得了先进的准确性，但在生产环境中部署时面临两大限制：（1）商业LLM带来的隐私风险，促使采用本地部署；（2）高流量日志流对延迟和吞吐量的要求，现有的基于LLM的日志解析器无法满足。尽管最近的努力减少了LLM查询的数量，但它们忽略了LLM调用的高延迟问题，导致并发日志解析请求可能引起LLM推理系统的性能下降。因此，迫切需要一种有效的LLM推理优化方法来解决这些问题。
### Innovation
该研究提出了一种名为InferLog的方法，这是第一个专门为在线日志解析优化的LLM推理方法。InferLog通过设计（1）前缀感知的ICL精炼策略，改进上下文学习中示例和排列的精炼过程，以提高前缀缓存效率；（2）一种基于元学习的快速且特定任务的配置调优管道，以找到适用于动态日志解析工作的最佳LLM调度相关配置。实验结果基于Loghub数据集和vLLM表明，InferLog显著优于现有的推理优化方法，并显著加速了最先进的LLM日志解析器，同时不牺牲解析准确性。
### Conclusion
InferLog通过上述策略显著提高了基于LLM的日志解析效率，解决了高流量日志流对延迟和吞吐量的需求，验证了其在实际应用中的有效性。
## 696. `cs.SE` - 基于LLMs的Dafny程序算术错误形式化指导修复 [PDF](https://arxiv.org/pdf/2507.03659), [HTML](https://arxiv.org/abs/2507.03659)
### Authors
Valentina Wu,Alexandra Mendes,Alexandre Abreu
### Background
当程序无法进行形式化验证时，故障诊断和修复过程可能非常复杂且耗时。传统自动程序修复（APR）技术依赖于测试套件进行验证，但这些测试套件可能无法涵盖所有可能的情况。相比之下，正式规格提供了强有力的正确性标准，使得更有效的自动修复成为可能。本文介绍了一种用于Dafny验证感知编程语言的自动程序修复工具，Dafny使用正式规格（包括先决条件、后置条件和不变量）作为故障定位和修复的依据。
### Innovation
基于形式化的推理和大型语言模型（LLMs）相结合的方法进行算术错误修复。具体来说，该研究提出了一个利用形式化规格和Hoare逻辑确定程序中每个语句状态，并通过LLMs生成候选修复方案的APR工具。所测试的LLMs包括GPT-4o mini、Llama 3、Mistral 7B和Llemma 7B。该工具在DafnyBench基准测试中实现了89.6%的故障定位覆盖率，并且GPT-4o mini达到了最高的修复成功率74.18%。
### Conclusion
该研究结果表明，结合形式化推理与基于LLMs的程序合成技术，在自动程序修复方面具有很大潜力。
## 697. `cs.SE` - KNighter: 利用LLM生成检查器转换静态分析 [PDF](https://arxiv.org/pdf/2503.09002), [HTML](https://arxiv.org/abs/2503.09002)
### Authors
Chenyuan Yang,Zijie Zhao,Zichen Xie,Haoyu Li,Lingming Zhang
### Background
静态分析是检测关键系统（如操作系统内核）中错误的强大技术。然而，设计和实现静态分析器是一项挑战性大且耗时的任务，并且通常局限于预定义的错误模式。虽然大型语言模型（LLMs）在静态分析方面显示出潜力，但由于计算限制和上下文限制，直接将它们应用于扫描大型系统仍然不切实际。KNighter通过自动从历史错误模式合成静态分析器，成为第一个解锁可扩展的LLM基础静态分析的方法。这种方法的灵感在于利用大型语言模型生成由历史补丁知识引导的专门静态分析器，而不是让大型语言模型直接分析庞大的系统。我们的评估表明，KNighter能够生成高精度的检查器，能够检测现有的手工编写分析器所忽视的多种错误模式。KNighter生成的检查器已经发现了92个新的、关键的、长期未被发现的内核错误（平均每4.3年一个），其中包括77个已确认、57个已修复和30个分配了CVE编号的错误。这项工作确立了一种全新的可扩展、可靠和可追溯的基于检查器生成的LLM基础静态分析范式，应用于实际系统中。
### Innovation
KNighter首次通过自动从历史错误模式合成静态分析器，将可扩展的大型语言模型基础静态分析器应用于实时大型系统。这种方法的核心在于利用大型语言模型生成由历史补丁知识引导的专门静态分析器，而不是让大型语言模型直接分析大型系统。KNighter通过多阶段合成管道验证检查器的正确性，并采用自动精炼过程逐步减少假阳性。这种方法能够生成能够检测现有手动编写分析器所忽略的多种错误模式的高精度检查器。至今，KNighter合成的检查器已经发现了一些关键且长期未被发现的Linux内核错误。
### Conclusion
这项工作确立了一种全新的可扩展、可靠和可追溯的基于检查器生成的大型语言模型基础静态分析范式，应用于实际系统中。KNighter能够生成高精度的检查器，能够检测现有的手工编写分析器所忽视的多种错误模式，并发现了一些新的关键且长期未被发现的Linux内核错误。
## 698. `cs.SE` - R2C2-Coder: 提升和评估代码大型语言模型在真实仓库级别代码补全能力 [PDF](https://arxiv.org/pdf/2406.01359), [HTML](https://arxiv.org/abs/2406.01359)
### Authors
Ken Deng,Jiaheng Liu,He Zhu,Congnan Liu,Jingxin Li,Jiakai Wang,Peng Zhao,Chenchen Zhang,Yanan Wu,Xueqiao Yin,Yuanxing Zhang,Zizheng Zhan,Wenbo Su,Bangyu Xiang,Tiezheng Ge,Bo Zheng
### Background
近年来，代码补全模型取得了显著进步。最近，仓库级别的代码补全在现代软件开发中受到了更多关注，并且已经提出了一些基线方法和基准。然而，现有的仓库级别代码补全方法在充分利用项目仓库中的上下文（如相关文件的复杂性和类层次结构）方面往往做得不够好。此外，现有的基准通常关注有限的代码补全场景，无法很好地反映出现有方法的仓库级别代码补全能力。
### Innovation
我们提出了R2C2-Coder以提升和评估代码大型语言模型在真实仓库级别代码补全的能力。R2C2-Coder包括代码提示构建方法R2C2-Enhance和精心设计的基准测试R2C2-Bench。R2C2-Enhance首先构建候选检索池，然后为每个补全光标位置从检索池中检索来组装完成提示。基于R2C2-Enhance，我们构建了一个更具挑战性和多样性的R2C2-Bench，其中提出了一种上下文扰动策略以更好地模拟真实仓库级别的代码补全场景。在多个基准上的广泛结果证明了我们R2C2-Coder的有效性。
### Conclusion
我们的R2C2-Coder在评估代码大型语言模型在真实仓库级别的代码补全能力方面表现出有效性，提出了R2C2-Enhance为代码提示构建，提出了R2C2-Bench用于更具挑战性的代码补全任务测试，更为真实地模拟了实际开发中的代码补全场景。
