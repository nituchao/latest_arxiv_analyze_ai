{"llm_update_time": "20250723", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.15865", "html_url": "https://arxiv.org/abs/2507.15865", "title": "从表示到超级智能：一种搜索理论视角", "title_en": "From Reasoning to Super-Intelligence: A Search-Theoretic Perspective", "authors": "Shai Shalev-Shwartz,Amnon Shashua", "background": "链式思维（CoT）推理已成为增强大型语言模型解决问题能力的强大工具。然而，从CoT数据学习的理论基础仍处于发展初期，现有方法（如监督微调、强化学习、思想树和蒙特卡洛树搜索）在复杂推理任务中经常失效。已有研究面临的关键障碍包括分布漂移、缺乏嵌入式搜索和指数级推理成本。", "innovation": "提出了一种新的学习范式——勤勉学习者（Diligent Learner），它明确将推理建模为由验证器引导的深度优先搜索，并在失败时支持回溯。证明了在两个温和且现实的假设下，勤勉学习者可以从CoT数据中高效学习，而现有方法却不能实现这一目标。此框架为构建可扩展和可信赖的推理系统，这些系统可以训练于自然发生、不完整的数据奠定了基础，为开发具有稳健和可解释问题解决能力的大规模推理模型（LRMs）开辟了道路。", "conclusion": "该框架为如何基于真实数据和现实假设构建高效的CoT学习系统和大规模推理模型提供了理论依据，这将促进未来超级智能系统的开发。"}
{"llm_update_time": "20250723", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.15875", "html_url": "https://arxiv.org/abs/2507.15875", "title": "Differential Multimodal Transformers", "title_en": "Differential Multimodal Transformers", "authors": "Jerry Li,Timothy Oh,Joseph Hoang,Vardhit Veeramachaneni", "background": "小型语言模型因其效率和功能的提升而变得越来越受欢迎。然而，整合额外的模态，如视觉信息，会加剧由于有限上下文窗口带来的噪声问题。近期研究表明，Transformer注意力机制往往过度关注无关的上下文。本文基于此背景，将原本为纯文本模型设计的Differential Attention机制扩展到了PaliGemma等文字-视觉模型。", "innovation": "本文创新性地提出了将Differential Attention机制应用于PaliGemma等文字-视觉模型的方法，以评估其解决噪声信息检索和减少幻觉的能力。该机制通过LoRA微调模型并探索不同参数设置和配置来实现。", "conclusion": "实验结果表明，Differential Attention机制可以适应并集成到现有模型的微调中，从而增强对噪声信息的检索能力和问答性能。"}
{"llm_update_time": "20250723", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.15901", "html_url": "https://arxiv.org/abs/2507.15901", "title": "在家庭自动化中推进负责任创新的代理人工智能：伦理框架研究", "title_en": "Advancing Responsible Innovation in Agentic AI: A study of Ethical Frameworks for Household Automation", "authors": "Joydeep Chandra,Satyam Kumar Navneet", "background": "家庭环境中人工智能（AI）的实施，特别是在自主代理的形式下，带来了舒适和关怀的可能性，但同时也伴随着内部或外部的伦理挑战。本文分析了代理AI及其应用，重点关注其从反应性自主向主动性自主的转变、隐私、公平性和用户控制等方面。本文回顾了负责任创新框架、以人为中心的设计原则和治理实践，以提炼出可为道德智能家庭系统提供实际指导的内容。详细研究了老年个体、儿童和神经多样性等易受监视、偏见和隐私风险影响的用户群体在代理人工智能中的情况。提出了定制化可解释性、精细的许可机制和稳健的覆盖控制的目标，支持参与性和包容性方法。此外还探讨了数据分析驱动的见解，包括通过自然语言处理（NLP）进行的社交媒体分析，以指导特定用户需求和伦理问题。本调查旨在提供概念基础并提出发展透明、包容和可信的代理人工智能的具体建议", "innovation": "本文提出并应用了以人为中心的设计原则、治理实践和具体的技术方法，以开发透明、包容和可信的代理人工智能在家庭自动化系统中的应用。特别是强调了为不同用户群体提供定制化可解释性、精细的许可机制和稳健的覆盖控制的重要性，并通过参与性和包容性方法进行实施。还结合数据驱动的见解（如自然语言处理）来解决特定用户需求和伦理问题。", "conclusion": "本文旨在提供代理人工智能在家庭自动化中的伦理框架，为开发提供概念基础和具体建议，以支持透明、包容和可信的代理人工智能在家庭自动化中的实施。"}
{"llm_update_time": "20250723", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.15885", "html_url": "https://arxiv.org/abs/2507.15885", "title": "ADEPTS：以人为本的代理设计能力框架", "title_en": "ADEPTS: A Capability Framework for Human-Centered Agent Design", "authors": "Pierluca D'Oro,Caley Drooff,Joy Chen,Joseph Tighe", "background": "大型语言模型为强大的、灵活的AI代理的发展铺平了道路，这些代理通过逐渐融入日常生活中来协助人类。这种灵活性、潜力和日益增长的采用需求一种全面和跨学科的方法来开发、监控和讨论代理驱动用户体验所需的各项能力。然而，目前的人本AI代理开发指南是碎片化的：用户体验准则侧重于界面行为，工程分类法描述内部管道，伦理检查表则关注高层次治理。没有一个简洁、面向用户的术语来告诉团队，代理应当能够做些什么。我们提出了ADEPTS框架，定义了一组核心的用户面对能力，以提供AI代理开发的统一指导。ADEPTS基于六个以人为本的代理设计原则，这些原则描述了AI代理在日常使用中应展示的最小、面向用户的能力，以使其易理解、可控并可信赖。ADEPTS补充完善现有框架和分类法，不同之处在于它存在于技术与体验开发之间的接口。通过展示ADEPTS，我们旨在将复杂的AI-UX需求简化为一个紧凑的、实际操作性的框架，供AI研究者、设计师、工程师以及政策审查者共同使用。我们相信ADEPTS有潜力加速用户相关代理能力的改进，简化利用这些能力设计体验的流程，并提供一个共同语言来跟踪和讨论AI代理开发的进展。", "innovation": "ADEPTS框架定义了一组核心的用户面对能力，以提供AI代理开发的统一指导。它基于六个以人为本的代理设计原则，这些原则描述了AI代理在日常使用中应展示的最小、面向用户的能力，以使其易理解、可控并可信赖。ADEPTS不同于现有的框架和分类法，它处于技术与体验开发之间的接口。这为AI领域的各个参与者提供了实际操作性指导，以加速用户相关代理能力的改进并简化体验设计流程。", "conclusion": "我们相信ADEPTS有潜力加速用户相关代理能力的改进，简化利用这些能力设计体验的流程，并提供一个共同语言来跟踪和讨论AI代理开发的进展。"}
{"llm_update_time": "20250723", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.15866", "html_url": "https://arxiv.org/abs/2507.15866", "title": "在肉类加工厂的采购和生产优化", "title_en": "Purchase and Production Optimization in a Meat Processing Plant", "authors": "Marek Vlk,Premysl Sucha,Jaroslaw Rudy,Radoslaw Idzikowski", "background": "食品生产行业，特别是肉类生产领域面临着许多挑战，近期欧盟能源危机的爆发使得这些挑战更加严峻。因此，如何有效地使用投入材料成为这类公司利润的关键因素之一。本文探讨了一个优化问题，即解决了一家肉类加工公司在原材料购买及后续材料处理方面的优化问题。不同于现有的大多数研究集中在供应链管理，我们专注于生产阶段的问题，并考虑了原材料的替代加工方式，不同有效期的库存材料，以及在现有文献中常常被忽略的最小订货量和替代比例的最低限制。我们证明了这两个约束将问题证明为 \textit{NP} 难问题，因此，我们基于整数线性规划设计了一种简单的迭代方法，即使使用开源整数线性规划求解器也可以解决实际案例。这一方法的另一个优点是，它解决了我们在使用商业求解器时遇到的数据范围极大的数值问题。使用实际数据进行的测试结果显示，我们的算法可以在几秒内找到所有研究案例的最优解。", "innovation": "本文的创新之处在于，它专注于生产阶段的问题，并考虑了几个常见的但被现有文献忽视的约束条件。通过对实际数据的测试和分析，该研究证明了一种基于整数线性规划的简单迭代方法的有效性，这种方法不仅能够解决实际问题，还能避免数值问题。", "conclusion": "我们提出的方法可以为肉类加工公司在面对其他挑战时提供有效的解决方案，并表明这种基于整数线性规划的简易方法适用于解决此类复杂的问题，特别是当使用开源求解器求解实际问题时。我们的研究结果表明，这种方法只需要几秒钟的时间就可以快速找到最优解。"}
{"llm_update_time": "20250723", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.15876", "html_url": "https://arxiv.org/abs/2507.15876", "title": "CTA复制中短周期和长周期趋势因素的再评估：贝叶斯图形方法", "title_en": "Re-evaluating Short- and Long-Term Trend Factors in CTA Replication: A Bayesian Graphical Approach", "authors": "Eric Benhamou,Jean-Jacques Ohana,Alban Etienne,Béatrice Guez,Ethan Setrouk,Thomas Jacquot", "background": "CTA历史上依赖于不同时间框架的趋势跟随规则，这些规则涉及多种策略，从捕捉主要方向移动的长期突破到在快速变动市场中茁壮成长的短期动量信号。尽管已有大量的关于趋势跟随的研究，但短期与长期趋势系统之间的相对优势及其相互作用仍存在争议。", "innovation": "(i) 使用贝叶斯图形模型动态分解CTA回报为短期趋势、长期趋势和市场贝塔因子；(ii) 展示不同时间框架的融合如何塑造策略的风险调整后表现。", "conclusion": "研究表明，不同时间框架的混合如何影响CTA策略的表现，并通过引入贝叶斯图形模型为趋势因素的评价提供了新的视角。"}
{"llm_update_time": "20250723", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.15974", "html_url": "https://arxiv.org/abs/2507.15974", "title": "在推理时间增加计算资源真的能提高模型鲁棒性吗？", "title_en": "Does More Inference-Time Compute Really Help Robustness?", "authors": "Tong Wu,Chong Xiang,Jiachen T. Wang,Weichen Yu,Chawin Sitawarin,Vikash Sehwag,Prateek Mittal", "background": "最近的研究表明，增加在推理时间的计算可以提高大型专有推理LLM的鲁棒性。该论文首先证明了小型开源模型（如DeepSeek R1，Qwen3，Phi-reasoning）也可以从推理时间扩展中受益，并且使用简单的预算控制策略。更重要的是，他们揭示并批判性地检视了先前工作中隐含的假设：中间推理步骤对对手是隐藏的。通过放松这一假设，他们发现了一个重要的安全风险，即推理时间扩展的逆向定律：如果中间推理步骤变得可访问，增加推理时间的计算会一致地降低模型的鲁棒性。", "innovation": "该论文发现，尽管大型专有模型可以从中受益，但小型开源模型也能通过简单的预算控制策略获得类似的好处。更重要的是，他们提出并验证了一个新的观点，即如果中间推理步骤对对手可见，则增加推理时间计算会降低模型的鲁棒性，推翻了先前假设的隐蔽性保护机制的有效性。", "conclusion": "论文的研究结果表明，推理时间扩展的鲁棒性优势在很大程度上取决于对手所处的环境及应用场景。研究人员建议，在将推理时间扩展应用于敏感的安全场景之前，必须仔细权衡这些微妙的权衡。"}
{"llm_update_time": "20250723", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.16020", "html_url": "https://arxiv.org/abs/2507.16020", "title": "微移动流量预测：基于多层时空注意力神经网络的单车共享站级研究", "title_en": "Micromobility Flow Prediction: A Bike Sharing Station-level Study via Multi-level Spatial-Temporal Attention Neural Network", "authors": "Xi Yang,Jiachen Wang,Song Han,Suining He", "background": "城市微移动资源，如共享单车，由于站点级需求和供给不平衡，管理和维护系统的效率成为一个难题。先前的研究主要集中在准确预测单车流量（如需求/取车和返回/还车），以提高系统的效率。然而，单车共享站点级别的流量预测由于系统时空复杂性十分困难，而且在如此大的站点数量下，整个系统的流动预测也极具挑战。因此，本文提出了一种多级别时空注意力神经网络（BikeMAN），用于预测整个共享单车系统中各个站点的单车流量，通过在纽约市超过700个站点的超过1000万次骑行数据实验，验证了其高精度预测能力。", "innovation": "提出了一种多级别时空注意力神经网络（BikeMAN），该网络包含一个编码器和一个解码器，通过空间和时间关注机制分别表示系统中单车站点特征的空间相关性和单车站点流量的时间特性，以解决单车共享站点级别的流量预测问题。", "conclusion": "通过在纽约市超过700个站点的超过1000万次骑行数据实验，所提出的多级别时空注意力神经网络展现了在各个城市站点预测单车流量的高准确性。"}
{"llm_update_time": "20250723", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.15877", "html_url": "https://arxiv.org/abs/2507.15877", "title": "ARC-AGI领域的离区间外泛化：比较基于执行的神经程序合成和测试时微调", "title_en": "Out-of-Distribution Generalization in the ARC-AGI Domain: Comparing Execution-Guided Neural Program Synthesis and Test-Time Fine-Tuning", "authors": "Simon Ouellette", "background": "该研究在ARC-AGI领域执行了一项受控的组合泛化实验。ARC-AGI是一个开放世界的问题域，其本质设计要求成功的关键特征是在分布外（out-of-distribution）表现良好的能力。研究重点比较了神经程序合成和测试时微调这两种方法。", "innovation": "研究发现基于执行指导的神经程序合成方法在组合新颖解决方案的能力上优于所有参考算法。实验结果还表明，测试时微调在ARC-AGI上的成功主要在于促使LLM使用其无法直接依赖的内部分布知识。", "conclusion": "研究表明，在ARC-AGI领域，基于执行指导的神经程序合成方法在处理离区间外问题时表现出色，而测试时微调的成功关键在于利用LLM内已有的但无法直接依赖的知识。"}
{"llm_update_time": "20250723", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.15895", "html_url": "https://arxiv.org/abs/2507.15895", "title": "将基于推理的道德决策集成到强化学习架构中", "title_en": "Integrating Reason-Based Moral Decision-Making in the Reinforcement Learning Architecture", "authors": "Lisa Dargasz", "background": "强化学习作为一种机器学习方法，在各种任务中表现出色，尤其是在自主智能代理的开发中占据核心地位。随着这些代理变得更加能干，它们即将从实验室原型过渡到在现实世界环境中自主运行，这一转变提出了道德行为的特定需求。研究旨在构建符合道德行为要求的代理，即所谓的“人工道德代理（AMAs）”，这些研究需要在计算机科学和哲学的交叉领域解决一系列挑战。研究探讨了基于推理的人工道德代理（RBAMAs）的发展。", "innovation": "该研究提出了基于推理的强化学习架构，使代理能够基于健全的规范推理进行道德决策，通过案例反馈使代理学习原因理论来处理有关道德的命题并推导出道德义务。这些特征提高了代理行为的道德可辩护性、道德稳健性和道德可信度，从而提出了一个满足关键道德要求的具体并可部署的框架。该研究首次实现了一个RBAMA，并在初步实验中展示了其潜力。", "conclusion": "该研究提出了一个扩展的强化学习架构，作为符合关键道德要求的AMAs发展的具体可部署框架，提出了基于推理的人工道德代理的潜在价值。"}
{"llm_update_time": "20250723", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.16028", "html_url": "https://arxiv.org/abs/2507.16028", "title": "从逻辑到语言：LLMs求解问题的可信度指标", "title_en": "From Logic to Language: A Trust Index for Problem Solving with LLMs", "authors": "Tehseen Rug,Felix Böhmer,Tessa Pfattheicher", "background": "经典的基于形式逻辑系统的计算在过去几十年中一直是技术进步的动力，它擅长解决可用明确规则描述的问题。然而，这种范式无法处理那些具有模糊性、动态环境和主观背景的人类问题。大型语言模型（LLMs）的出现代表了一种根本性的转变，使计算系统能够使用自然语言处理这些以前无法触及的领域。本文提出了一个统一框架来理解并对比这两种问题解决范式。我们定义并区分了形式语言与自然语言可以解决的问题空间。针对第一类问题，解决方案可以使用二元质量指标进行评估；而针对第二类问题，由于自然语言固有的模糊性、主观性和歧义性，需要引入一个更细腻的评估近似解空间的方法来定义解决方案的质量。因此，我们提出了一个向量化的信任指数Q，既反映了解决方案的质量，也区分了形式语言解决方案的二元正确性与自然语言解决方案的连续恰当性谱线。在这一框架中，我们还提出了两种统计质量维度。归一化双语义熵度量了LLM答案在问题表述的语义变体下的一致性和概念多样性。情感语义则将对解决方案的主观评价转换成可以优化的量化指标，通过统计测量实现最大化。上述概念的引入将为理解和认识LLM时代问题解决能力、局限性和本质奠定更严谨的基础。", "innovation": "1. 提出并定义了一种更细腻的评估自然语言解决方案近似解空间的方法，以反映模糊性、主观性和歧义性。\n2. 引入了一个向量化的信任指数Q，用于区分形式语言解决方案的二元正确性与自然语言解决方案的连续恰当性谱线。\n3. 提出了归一化双语义熵和情感语义两种统计质量维度，评估LLM答案的正确性和主观价值度量化改进。\n4. 概括了形式语言与自然语言问题解决范式的区别和联系，提供了一个统一的框架进行理解与对比。\n5. 引入了对LLM时代问题解决概念的理解、限制和本质的新视角，提升了这一领域的研究和应用水平。", "conclusion": "基于LLM的求解问题方法虽然具有巨大的潜力，但也存在一定局限性和挑战。通过本研究提出的新框架和指标，我们能够更好地理解这种新型计算范式的独特价值，同时识别和解决其中的关键挑战。这将有助于推进LLM技术及其在各领域的应用，使其更好地服务于人类社会。"}
{"llm_update_time": "20250723", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.16110", "html_url": "https://arxiv.org/abs/2507.16110", "title": "专家引导的LLM推理用于电池发现：从AI驱动的假设到合成和表征", "title_en": "Expert-Guided LLM Reasoning for Battery Discovery: From AI-Driven Hypothesis to Synthesis and Characterization", "authors": "Shengchao Liu,Hannan Xu,Yan Ai,Huanxin Li,Yoshua Bengio,Harry Guo", "background": "大型语言模型（LLMs）利用链式思考（CoT）技术应对复杂问题，代表了人工智能（AI）的一个转变性突破。然而，它们的推理能力主要体现在解决数学和编程问题方面，而它们在材料设计等特定领域的应用潜力一直未被充分开发。通过类比推理是一种带有指导的搜索过程，我们介绍了ChatBattery，这是一种新的代理框架，能够集成专业知识，引导LLMs在材料设计中的更有效推理。ChatBattery的设计旨在填补这一知识鸿沟，推动AI在电池材料发现中的应用。", "innovation": "ChatBattery是一种新的代理框架，它将专业知识整合进来，以引导LLM进行更有效的材料设计推理。通过ChatBattery，我们成功地识别、合成并表征了三种新型锂离子电池正极材料，这些材料分别提高了28.8%、25.2%和18.5%的实际容量，超过广泛使用的正极材料NMC811。这项工作展示了成功的LLM驱动和基于推理的平台，创建电池材料。从设计到合成再到表征的完全AI驱动的循环，证明了AI驱动推理在材料发现中的变革潜力。", "conclusion": "ChatBattery开创了一条新的道路，证明了LLM驱动和基于推理的平台在电池材料发现中的成功应用。这为利用AI革命化材料发现提供了一个全新的视角，展示了AI驱动推理在实现材料发现循环链中不可或缺的作用。"}
{"llm_update_time": "20250723", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.16126", "html_url": "https://arxiv.org/abs/2507.16126", "title": "TaxCalcBench：在税务计算任务中评估前沿模型", "title_en": "TaxCalcBench: Evaluating Frontier Models on the Tax Calculation Task", "authors": "Michael R. Bock,Kara Molisee,Zachary Ozer,Sumit Shah", "background": "税务申报特别是个人所得税申报，需要理解和使用大量英文文本，再准确地进行计算。现有的先进模型在简化样本集上计算联邦所得税申报表的成功率不到三分之一，模型在使用税收表格、税务计算以及确认资格等方面存在明显错误。因此，迫切需要为税务计算任务提供一种基础设施来应用语言生成模型。", "innovation": "提出了TaxCalcBench，这是一个基准测试，用于评估模型在给定所有必要信息的情况下计算个人税务申报表的能力。", "conclusion": "当前最先进的模型在简化样本集上的联邦所得税申报计算成功率不到三分之一，模型在使用税收表格、税务计算以及确认资格等方面存在系统性错误。这表明需要额外的基础设施来应用大语言模型进行个人所得税计算任务。"}
{"llm_update_time": "20250723", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.15880", "html_url": "https://arxiv.org/abs/2507.15880", "title": "递归一致性原则：可扩展智能、对齐和推理架构的正式约束", "title_en": "The Recursive Coherence Principle: A Formal Constraint on Scalable Intelligence, Alignment, and Reasoning Architecture", "authors": "Andy E. Williams", "background": "智能（无论是生物的、人造的还是集体的）要想有效扩展，需要在其递归推理过程中保持结构性的一致性。随着复杂系统的增长，这种一致性变得脆弱，除非有一个高层次的结构确保语义的一致性。", "innovation": "论文提出了递归一致性原则（RCP），作为基本约束条件，表明任何推理系统的第N级，如果由第N-1级的概念空间操作子系统组成，则仅通过遍历并使这些较低级别的概念空间保持一致的递归可评估概括运算符，才能保持语义一致性。论文正式定义了功能智能模型（FMI），它是唯一已知的能够在任何规模上满足RCP的方法，FMI 是一种最小的可组合架构，具有内部和外部功能，确保推理和协调层之间的语义结构保持一致。", "conclusion": "任何缺乏FMI的系统在扩展时都会经历递归一致性崩解，这导致了常见的AI问题如不一致、幻觉和不稳定性。此工作对AI对齐产生了重大影响，倡导从行为约束转向结构性一致性，并提供了实现可扩展和稳健一致性的AI之路。"}
{"llm_update_time": "20250723", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.16145", "html_url": "https://arxiv.org/abs/2507.16145", "title": "SpiroLLM：通过临床验证微调预训练大语言模型以理解支气管呼吸图时间序列在COPD报告中的应用", "title_en": "SpiroLLM: Finetuning Pretrained LLMs to Understand Spirogram Time Series with Clinical Validation in COPD Reporting", "authors": "Shuhao Mei,Yongchao Long,Shan Cao,Xiaobo Han,Shijia Geng,Jinbo Sun,Yuxi Zhou,Shenda Hong", "background": "慢性阻塞性肺病（COPD）是一种导致持续气流受限的重要慢性呼吸系统疾病，是全球导致残疾和死亡的主要原因。肺功能测试（PFT）中收集到的支气管呼吸图时间序列在早期发现呼吸系统疾病和监测肺功能方面起着关键作用。然而，目前大多数用于COPD诊断的AI模型只能提供分类结果而不能解释其诊断过程，现有的大型语言模型也不能理解支气管呼吸图，这严重影响了它们的临床可信度和应用。这篇论文通过使用英国生物银行（UKB）的234,028个个体样本，提出了SpiroLLM，这是一种可以理解支气管呼吸图的多模态大语言模型。研究结果表明，SpiroLLM在诊断方面取得了显著成效，AUC-ROC达到0.8980，并且在缺失核心数据的鲁棒性测试中保持了100%的反应率，远超单纯文本模型的结果，同时展示了其多模态设计的优势。", "innovation": "SpiroLLM是第一个能够理解支气管呼吸图的多模态大语言模型。它通过SpiroEncoder提取呼吸曲线的形态特征，并通过SpiroProjector将其与PFT的数值值统一映射到一个潜在空间中，最终使大语言模型能够生成全面的诊断报告。与传统的仅提供分类结果的AI模型不同，SpiroLLM能够解释其诊断过程，增强了临床应用中的可信度。此外，它在处理数据缺失时表现出了极高的鲁棒性，进一步证明了其设计优势。", "conclusion": "此研究证明了将生理信号与大语言模型深度结合的巨大潜力，为下一代可解释且可靠的临床决策支持工具建立了一个新的范式。SpiroLLM的提出有望在COPD诊断报告中提供更加准确和可靠的诊断支持。"}
{"llm_update_time": "20250723", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.16067", "html_url": "https://arxiv.org/abs/2507.16067", "title": "基于半环的约束逻辑编程与否定的统一框架（完整版）", "title_en": "A Unifying Framework for Semiring-Based Constraint Logic Programming With Negation (full version)", "authors": "Jeroen Spaans,Jesse Heyninck", "background": "约束逻辑编程（CLP）是一种用于解决需要考虑约束问题的形式化逻辑编程方法，如资源分配、自动化规划和调度。CLP已经通过多种方式得到了扩展，例如支持模糊约束满足、不确定性或否定，这些扩展使用不同的半环概念作为这些泛化的统一抽象。这些扩展中没有一种考虑了可以在主体中使用否定的表达式。", "innovation": "本文研究了一种CLP的扩展，该扩展统一了许多现有的扩展，并允许在范畴中使用否定。该研究提供了这样的程序的语义，通过近似最优点理论框架，详细探讨了半环性质对所得语义的影响。因此，本文提供了一个统一框架，该框架可以捕捉现有的方法，并允许使用更丰富的语言对它们进行扩展。", "conclusion": "本文提供了一个统一框架，该框架可以捕捉现有的方法，并允许使用更丰富的语言对它们进行扩展，这对于CLP的进一步发展和应用具有重要意义。"}
{"llm_update_time": "20250723", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.16184", "html_url": "https://arxiv.org/abs/2507.16184", "title": "Emergent Cognitive Convergence via Implementation: A Structured Loop Reflecting Four Theories of Mind (A Position Paper),", "title_en": "Emergent Cognitive Convergence via Implementation: A Structured Loop Reflecting Four Theories of Mind (A Position Paper)", "authors": "Myung Ho Kim", "background": "本文报告了在四个有影响力的心智理论中发现的一种结构趋同现象：卡尼曼的双系统理论、弗斯通的预测处理、明斯基的心智圈和克拉克的延伸心智，这些理论偶然出现在一种名为Agentic Flow的实用人工智能代理架构中。Agentic Flow旨在解决大型语言模型的局限性，包含五个相互依赖的模块：检索、认知、控制、记忆和行动，这些模块组织在一个循环的认知回路中。最初，该系统仅受到明斯基和克拉克的启发，但它的结构后来与四理论中发现的计算模式（如预测建模、关联性回忆和误差敏感控制）相吻合。为了评估这种趋同性，作者对基线语言模型代理进行了比较实验，分别完成多步骤推理任务，结果结构化代理的成功率为95.8%，表现出强烈的约束遵守，而基线系统仅成功62.3%。作者的目标不是证明其优越性，而是展示理论结构如何通过实用性设计选择自然浮现，而非自上而下的理论。", "innovation": "提出了一个新的元架构，即PEACE，该架构描述了Agentic Flow的级联设计规律。PEACE不是新的理论，而提供了一种共享语言，用于理解由实际实现需求塑造的架构。本文被视为立场声明——作为一种探索性反思，表明实现如何揭示潜在的认知理论结构的回声，而不强加理论统一。", "conclusion": "本文的结果表明，通过实用设计的选择，理论结构可以在实际架构中自然浮现，而无需强加自上而下的理论。研究者旨在提供一种现实实现需求下的架构理解共享语言，并提出了一种新的元架构，用于描述Agentic Flow中的设计规律，以探索理论如何通过实现浮现的考虑。"}
{"llm_update_time": "20250723", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.16229", "html_url": "https://arxiv.org/abs/2507.16229", "title": "基于语音的AI代理：在数字健康交付中填补经济缺口", "title_en": "Voice-based AI Agents: Filling the Economic Gaps in Digital Health Delivery", "authors": "Bo Wen,Chen Wang,Qiwei Han,Raquel Norel,Julia Liu,Thaddeus Stappenbeck,Jeffrey L. Rogers", "background": "语音辅助AI代理在医疗领域的整合为跨越数字医疗服务中的经济和可访问性差距创造了变革性的机遇。论文探讨了大型语言模型（LLM）驱动的语音助手在提高预防性护理和连续患者监测方面的作用，特别是在服务不足的人群中。通过IBM Research、Cleveland Clinic Foundation和Morehouse School of Medicine合作开发和试点项目——患者理解与联络支持引擎Agent PULSE——的文章，论文介绍了展示AI代理如何在经济上不可行的人类干预领域提供成本效益较高的医疗服务的经济模型。研究表明，70%的患者接受AI驱动的监控，37%的患者更倾向于这种模式而非传统方法。论文分析了包括实时对话AI处理、与医疗系统集成以及隐私合规在内的技术挑战，并讨论了涉及监管、偏见消除和患者自主性等政策问题。通过增强医疗服务的可扩展性和效率，提升患者参与度和可访问性，AI驱动的语音代理有望解决当前的限制，为医疗可及性和可持续的数字健康方案铺平道路。", "innovation": "研究通过开发和试点项目——Agent PULSE来展示基于AI驱动的语音助手如何在经济上不可行的领域提供成本效益较高的医疗服务；通过经济学分析和患者反馈，展现了AI在提高患者满意度和优化资源分配方面的潜力；分析和解决了实时对话AI处理、与医疗系统集成以及隐私合规等技术挑战，并提出相应的政策建议。", "conclusion": "AI驱动的语音代理不仅提高了医疗服务的可扩展性和效率，还改善了患者的参与度和可访问性。对于医疗服务高层管理者而言，AI的成本和效用分析显示了常规监测任务的巨大潜在节省；对于技术专家而言，可以利用我们的框架优先考虑对患者的最大影响。通过解决当前限制并使AI开发与伦理和监管框架保持一致，语音驱动的AI代理可以成为一种关键的可及、可持续的数字医疗服务的切入点。"}
{"llm_update_time": "20250723", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.16334", "html_url": "https://arxiv.org/abs/2507.16334", "title": "Higher Gauge Flow Models", "title_en": "Higher Gauge Flow Models", "authors": "Alexander Strunk,Roland Assam", "background": "Generative Flow Models have been developed to efficiently model complex data distributions. Ordinary Gauge Flow Models are an existing approach that uses Lie Algebras for this purpose, but they have limitations in handling higher geometric and symmetry aspects of data.", "innovation": "Higher Gauge Flow Models introduce the use of L$_{\rm \tiny \risingdotseq \tiny \risingdotseq \tiny \risingdotseq \tiny \risingdotseq}$-algebras, which extend the capabilities of Lie Algebras. This extension allows for the incorporation of higher geometry and higher symmetries into the generative flow framework, leading to improved performance in modeling complex data distributions.", "conclusion": "Experimental results show that Higher Gauge Flow Models outperform traditional Flow Models on a Gaussian Mixture Model dataset, demonstrating significant improvements in performance."}
{"llm_update_time": "20250723", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.16226", "html_url": "https://arxiv.org/abs/2507.16226", "title": "在受信任计算环境中的精简大型语言模型用于系统级芯片设计", "title_en": "Distilled Large Language Model in Confidential Computing Environment for System-on-Chip Design", "authors": "Dong Ben,Hui Feng,Qian Wang", "background": "大型语言模型（LLMs）在电路设计任务中越来越受欢迎，并且通常需要经过多次训练。它们和相关的训练数据被视为保密的知识产权，并且必须得到保护，避免外泄。虽然保密计算提供了通过可信执行环境（TEEs）保护数据和模型的潜在解决方案，但现有的TEEs实现通常不适应这些资源密集型LLMs的运行需求。", "innovation": "本文首先全面评估了LLMs在受Intel Trust Domain Extensions（TDX）技术支持的TEE环境中的表现。通过三种环境的实验：基于TEE的、仅CPU的和CPU-GPU混合实现，评估了这些实现的性能（以每秒处理的令牌数量为指标）。研究发现精简模型（DeepSeek）因参数更少在资源受限的设备上表现更好；在量化模型（4-bit和8-bit量化）中，相比FP16模型，性能可提升3倍。这些精简模型，例如DeepSeek-r1-1.5B在TDX环境下相较于CPU版本，在安全环境内执行计算时表现更优。进一步通过针对SoC设计任务的测试平台验证了这些结果，展示了轻量级LLMs可以在半导体CAD应用程序的资源受限系统中有效部署的潜力。", "conclusion": "本文展示了如何利用Intel TDX技术在TEE中高效部署精简的大型语言模型，实现了在资源受限的系统级芯片设计场景中的潜力。对于参数较少的模型（如DeepSeek-r1-1.5B），TDX环境下的实现比标准CPU版本有更好的表现。这种高效的部署方式在半导体CAD的应用中具有实际意义。"}
{"llm_update_time": "20250723", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.16356", "html_url": "https://arxiv.org/abs/2507.16356", "title": "学习呼叫：一种增强移动母婴健康信息传递的协作性策略的现场试验", "title_en": "Learning to Call: A Field Trial of a Collaborative Bandit Algorithm for Improved Message Delivery in Mobile Maternal Health", "authors": "Arpan Dasgupta,Mizhaan Maniyar,Awadhesh Srivastava,Sanat Kumar,Amrita Mahale,Aparna Hedge,Arun Suggala,Karthikeyan Shanmugam,Aparna Taneja,Milind Tambe", "background": "mHealth项目通过自动语音消息传递健康信息，特别针对未服务群体，显示出使用移动技术传递关键健康信息以提高健康结果的有效性。印度的Kilkari项目通过每周电话向数百万母亲传递重要孕产妇健康信息，但当前的随机呼叫排班导致漏打和消息传递减少的问题。因此，需要优化呼叫时间以提高健康信息传递效率.", "innovation": "提出了一种协作性贝叶斯优化算法，旨在通过学习个体母亲的偏好呼叫时间来优化呼叫时间，进行了现场试点研究，对比了其表现与基线随机呼叫方法。结果显示，使用协作性贝叶斯优化算法的呼叫接通率明显高于基线随机方法，表明其在提高信息传递和影响数百万印度母亲方面具有潜力.", "conclusion": "研究表明个性化调度在移动健康干预中的有效性，并强调了机器学习在大规模提高孕产妇健康覆盖方面的作用。"}
{"llm_update_time": "20250723", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.16296", "html_url": "https://arxiv.org/abs/2507.16296", "title": "跨模态蒸馏用于广泛差异的模态", "title_en": "Cross-Modal Distillation For Widely Differing Modalities", "authors": "Cairong Zhao,Yufeng Jin,Zifan Song,Haonan Chen,Duoqian Miao,Guosheng Hu", "background": "近年来深度学习取得了巨大进展，但仍难以通过增大模型规模来进一步提高性能。多模态学习可以通过引入更丰富和更具区分性的信息来缓解这一挑战。但由于在使用时难以获取多模态数据，因此通过引入教师模型在训练过程中将鉴别知识传递给学生模型的做法具有重要意义。然而，这种通过蒸馏的知识传递并不容易实现，因为广泛不同的模态之间存在较大的领域差距，容易导致过度拟合。", "innovation": "本研究提出了一种跨模态蒸馏框架。研究发现，在跨模态蒸馏中，硬约束损失（如l2损失）可能导致模型过度拟合。为了解决这一问题，本文提出了在特征级和分类器级的两个软约束知识蒸馏策略。此外，还提出了一种基于质量的自适应权重模块，通过量化数据质量来加权输入样本，从而增强模型训练的鲁棒性。", "conclusion": "通过实验验证了所提出的方法在声纹识别和图像分类任务上的有效性，能够有效地在常见的和广泛不同的图像、文本和语音等模态之间实现知识转移。"}
{"llm_update_time": "20250723", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.15874", "html_url": "https://arxiv.org/abs/2507.15874", "title": "制动原因探究：利用大语言模型进行场景提取与推理", "title_en": "Why Braking? Scenario Extraction and Reasoning Utilizing LLM", "authors": "Yin Wu,Daniel Slieter,Vivek Subramanian,Ahmed Abouelazm,Robin Bohn,J. Marius Zöllner", "background": "随着装备高级驾驶辅助系统（ADAS）的车辆数量不断增加，驾驶数据急剧增长，但大多数数据捕捉的是常规驾驶行为。在这种大规模数据集中，识别和理解安全性关键的边缘情况仍是一项重大挑战。尤其是，紧急制动事件往往是潜在危险情况的指示器，因此存在一个关键研究问题：为什么车辆会制动？现有的方法主要依赖规则基础的启发式方法来检索目标场景，通过预定义条件过滤器。虽然在像高速公路这样简单的环境条件下有效，但这类方法在复杂的城市环境中缺乏泛化能力。", "innovation": "本文提出了一种新颖的框架，利用大型语言模型（LLM）进行场景理解与推理。我们的方法在低级数值信号和自然语言描述之间建立了桥梁，使语言模型能够解释和分类驾驶场景。我们提出了一种双路径场景检索方法，既支持基于类别的已知场景搜索，又支持嵌入式的未知离分布（OOD）场景检索。为了便于评估，我们在Argoverse 2传感器数据集上编制了场景注释。实验结果表明，我们的方法优于基于规则的基线方法，并且在OOD场景上具有很好的泛化能力。", "conclusion": "我们的方法在解释和分类驾驶场景方面表现出色，并能够在未知场景中实现良好的泛化，为理解和预测车辆制动的原因提供了一种新的有效途径。"}
{"llm_update_time": "20250723", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.16322", "html_url": "https://arxiv.org/abs/2507.16322", "title": "关注差距：评估量化医学语言推理LLM基准对非洲疾病负担的代表性", "title_en": "Mind the Gap: Evaluating the Representativeness of Quantitative Medical Language Reasoning LLM Benchmarks for African Disease Burdens", "authors": "Fred Mutisya(1 and 2),Shikoh Gitau(1),Christine Syovata(2),Diana Oigara(2),Ibrahim Matende(2),Muna Aden(2),Munira Ali(2),Ryan Nyotu(2),Diana Marion(2),Job Nyangena(2),Nasubo Ongoma(1),Keith Mbae(1),Elizabeth Wamicha(1),Eric Mibuari(1),Jean Philbert Nsengemana(3),Talkmore Chidede(4) ((1) Qhala (Nairobi, Kenya), (2) Kenya Medical Association (Nairobi, Kenya), (3) Africa CDC (Addis Ababa, Ethiopia), (4) AfCFTA (Accra, Ghana))", "background": "现有的医学LLM基准大多反映了高收入国家的教学大纲和疾病特征，这对非洲的部署提出了质疑，因为在非洲疟疾、艾滋病、结核病、镰状细胞病及其他热带疾病负担较重，且国家指南驱动护理。现有评估研究仅覆盖31篇文献，涉及19项英语医学QA基准。研究发现，虽然有多种基准，但这些全球基准对非洲疾病负担和监管环境的代表性不足，这可能导致误导性的性能声明。非洲特有的疾病负担和基于指南的评估资源尚未充分反映在现有基准中。", "innovation": "研究开发了基于肯尼亚临床实践指南的‘Alama Health QA’，并在多种基准中进行了系统比较。研究通过标准化语义分析和盲专家评估，量化了基准的疾病代表性、指南一致性、清晰度、迷惑选项的合理性及语言/文化适配性。‘Alama Health QA’在多个方面表现出色，尤其是在非洲特有的疾病（疟疾、艾滋病、结核病）的代表性上。", "conclusion": "现有广泛使用的量化医学LLM基准对非洲的疾病负担和监管环境的代表性不足，可能导致误导性的性能评估和部署。建议未来发展基于指南、地区特有资源（例如‘Alama Health QA’），以确保模型在非洲健康系统中的安全和公平评估与部署。"}
{"llm_update_time": "20250723", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.16204", "html_url": "https://arxiv.org/abs/2507.16204", "title": "CHIMERA: 压缩混合智能以增强双模型多智能体深度强化学习用于多功能RIS辅助空天地综合网络", "title_en": "CHIMERA: Compressed Hybrid Intelligence for Twin-Model Enhanced Multi-Agent Deep Reinforcement Learning for Multi-Functional RIS-Assisted Space-Air-Ground Integrated Networks", "authors": "Li-Hsiang Shen,Jyun-Jhe Huang", "background": "提出了一种空间-空中-地面综合网络（SAGIN）架构，集成了多功能可重构智能表面（MF-RIS），能够同时反射、放大和采集无线能量。MF-RIS在解决低地球轨道（LEO）卫星在阴影区域的能量短缺问题中起到关键作用，而且该架构考虑了SAGIN节点在通信和计算中的能量消耗。为了最大化长期能效（EE），通过MF-RIS的参数优化和SAGIN参数优化联合解决这个问题，包括信号放大、相位偏移、能量采集比例、活动元素选择以及波束形成向量、高空平台站部署、用户关联和计算能力。此优化问题是高度非凸非线性的，并包含混合离散-连续参数，采用了一种压缩混合智能（CHIMERA）框架来解决，该框架结合了语义状态动作压缩和混合强化学习的参数共享，以高效探索合适复杂动作。", "innovation": "提出了一种压缩混合智能（CHIMERA）框架，用于多功能RIS辅助的空天地综合网络中增强的双模型多智能体深度强化学习方法。该方法通过结合语义状态动作压缩和混合强化学习的参数共享，有效探索复杂的行为。该方案相比于固定配置或不采集能量的MF-RIS、传统RIS和无RIS的情况，以及其他集中式和多智能体深度强化学习基线，在能效（EE）方面表现突出。CHIMERA架构通过互补的覆盖范围，提供了单独的卫星、空中或地面部署所能达到的优势。", "conclusion": "提出的SAGIN-MF-RIS架构通过互补的覆盖范围，在能效方面表现出色，优于单一的卫星、空中或地面部署，并通过CHIMERA方案实现了显著的能效提升。"}
{"llm_update_time": "20250723", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.16454", "html_url": "https://arxiv.org/abs/2507.16454", "title": "通过机器学习预测提升基于ASP的OR调度表", "title_en": "Improving ASP-based ORS Schedules through Machine Learning Predictions", "authors": "Pierangela Bruno,Carmine Dodaro,Giuseppe Galatà,Marco Maratea,Marco Mochi", "background": "手术室调度(ORS)问题涉及优化每日手术日程安排，是一个复杂的优化问题，受到多种约束的影响，如确定不同手术的开始时间以及分配所需的资源（包括不同部门单位的床位可用性）。尽管基于Answer Set Programming (ASP)的方法已经提供了解决方案，这些解决方案可以验证编码是否与实际数据相符，并在最大程度上提出可替代的日程安排，但目前还不可能生成临时日程，且生成的日程也不总是稳健的。", "innovation": "本文将归纳和演绎技术整合起来解决这些问题。首先使用机器学习算法根据历史数据预测手术持续时间，以计算临时日程，然后将预测的置信度作为额外输入融入问题中，并更新编码来计算更稳健的日程。意大利亚斯利1利古里亚的历数据结果表明，该整合方法是可行的。", "conclusion": "本文通过整合机器学习预测和基于ASP的手术室调度方法，能够生成临时日程并且提高日程的稳健性。该研究成果正在考虑在《逻辑程序理论与实践》期刊（TPLP）上发表。"}
{"llm_update_time": "20250723", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.16405", "html_url": "https://arxiv.org/abs/2507.16405", "title": "自监督归纳逻辑编程", "title_en": "Self-Supervised Inductive Logic Programming", "authors": "Stassa Patsantzis", "background": "归纳逻辑编程（ILP）方法，如元解释学习（MIL），可以从少量示例中学习递归逻辑程序，并具有一般性。这种能力依赖于精心选择的背景理论和负面示例，这些都是由专家知识精心挑选的。然而，如果特定问题的背景理论或负面示例不可用，这将是一个挑战。", "innovation": "该研究将这一问题形式化为新的自监督ILP设置，并提出了一种新的MIL算法，在此设置下从部分标记的和零或多个未标记的示例中学习，自动生成并标记新的正面和负面示例。该算法用Prolog实现了新的MIL系统Poker，通过与最先进的MIL系统Louise的对比实验，Poker在从标记示例、无负面示例和语言终端词汇（作为一阶背景理论）学习形形语言和L-系统语言的语法时性能更好，特别随着自动生成示例的数量增加，性能得到提升。", "conclusion": "Poker的性能随着自动生成示例数量的增加而提高，而缺乏负面示例的Louise则容易过度泛化。该研究还提出了一个新方法，用于合理选择第二阶背景理论，称为第二阶确定形式（SONF），这充分一般化以学习某一类的所有程序，从而消除了特别为学习任务量身定制背景理论的需要。"}
{"llm_update_time": "20250723", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.16370", "html_url": "https://arxiv.org/abs/2507.16370", "title": "马尔可夫结构因果模型的经典表示：一种反事实推理框架", "title_en": "Canonical Representations of Markovian Structural Causal Models: A Framework for Counterfactual Reasoning", "authors": "Lucas de Lara(IECL)", "background": "反事实推理旨在回答与事实相反的问题，如“如果爱丽丝服用了阿司匹林，她会康复吗？”这对应于因果关系最精细的层。然而，许多反事实陈述即使在随机化实验中也无法被证伪，但却支撑着基本概念，如个体内在公平性。因此，提供模型来正式化和实施反事实信念仍然是一个基本的科学问题。在皮尔士因果框架的马尔可夫设置中，我们提出了一种替代结构因果模型的方法，用于表示与给定因果图形模型兼容的反事实。", "innovation": "我们引入了反事实模型，即结构因果模型的经典表示。这些模型使得分析人员可以通过预设边缘分布的随机过程概率分布来选择反事实观念，并确定结构因果模型的反事实等效类别。我们还提出了一种归一化程序，以描述和实现各种反事实观念，这相比结构因果模型允许在不改变观察和干预约束的情况下指定许多反事实观念。此外，模型中对应反事实层的内容无需估计，只需进行选择即可。", "conclusion": "我们的方法在理论和数值示例中显示出反事实在因果关系中的特定作用及其好处。"}
{"llm_update_time": "20250723", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.16414", "html_url": "https://arxiv.org/abs/2507.16414", "title": "基于神经激活的识别大语言模型预训练数据框架", "title_en": "Identifying Pre-training Data in LLMs: A Neuron Activation-Based Detection Framework", "authors": "Hongyi Tang,Zhihao Zhu,Yi Yang", "background": "大语言模型（LLMs）的性能与其训练数据密切相关，这些数据可能包含受版权保护的材料或私人信息，引发法律和伦理问题。此外，LLMs还面临数据集污染和内化偏见的批评。为了应对这些问题，提出了预训练数据检测（PDD）任务来确定特定数据是否包含在LLMs的预训练语料中。然而，现有的PDD方法通常依赖于浅表特征，如预测置信度和损失，导致性能不佳。", "innovation": "介绍了一种名为NA-PDD的新颖算法，该算法基于训练数据和非训练数据在LLMs推理过程中激活不同神经元的观察，分析训练和非训练数据之间的神经激活模式差异。此外，还引入了CCNewsPDD基准，这是一个具有时间偏置的基准，通过严格的数据显示转换确保训练和非训练数据之间一致的时间分布。实验结果显示，NA-PDD在三个基准和多种LLMs上显著优于现有方法。", "conclusion": "NA-PDD显著提高了预训练数据检测的性能，为解决大语言模型的法律和伦理问题提供了一种新的方法。CCNewsPDD基准有助于更好地评估PDD方法的真实性能。"}
{"llm_update_time": "20250723", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.16473", "html_url": "https://arxiv.org/abs/2507.16473", "title": "通过选项引发的抽象MDP中的变分同态学习时序抽象", "title_en": "Learning Temporal Abstractions via Variational Homomorphisms in Option-Induced Abstract MDPs", "authors": "Chang Li,Yaren Zhang,Haoran Lv,Qiong Cao,Chao Xue,Xiaodong He", "background": "大型语言模型（LLMs）通过显式的因果推理提示展示了显著的推理能力，但生成这些逐步的文本解释在计算上昂贵且慢。因此，研究如何开发一个框架进行有效的、隐式的推理显得尤为重要，即模型能够在潜在空间中进行“思考”而无需为每一步生成明确的文本。", "innovation": "该研究旨在通过引入变分马尔可夫选项评论（VMOC）算法和扩展连续MDP同态理论，提出了突变的马尔可夫决策过程框架中的变分同态，以学习作为潜在嵌入的一系列选项。通过这种方法，实现了理论上的简化抽象潜在空间学习策略的政策优化，从而保留原始复杂问题的最优点。此外，还提出了冷启动程序，利用监督微调（SFT）数据将人类推理演示集中在潜在选项空间中，为模型提供丰富的推理能力初始化。", "conclusion": "实验证明该方法在复杂的逻辑推理基准测试和具有挑战性的运动任务中表现出强大性能，验证了该框架作为学习语言和控制领域抽象技能的原理方法的有效性。"}
{"llm_update_time": "20250723", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.16434", "html_url": "https://arxiv.org/abs/2507.16434", "title": "使用元解释学习从模型学习到模型自由行为", "title_en": "From model-based learning to model-free behaviour with Meta-Interpretive Learning", "authors": "Stassa Patsantzis", "background": "模型是描述环境状态及其决策对环境影响的理论。基于模型的代理能够利用其模型预测未来行动的效果并进行前瞻规划，但需要知道环境状态。而基于模型的代理不能进行计划，但可以在不拥有模型的情况下、也不完全观察环境来进行行动。自主代理需要结合这两种能力，在未知的环境中独立行动。本文通过结合元解释学习（Meta-Interpretive Learning，MIL）来创建一个这样的自主代理。", "innovation": "本文提出的创新在于使用元解释学习（MIL）来学习一个基于模型的解决问题者，然后用该解决问题者训练一个基于模型自由的控制器。该控制器能够解决与解决问题者相同的规划问题。本文证明了在两类环境（随机生成的迷宫和有开阔地带的湖泊地图）中的迷宫导航问题上，两个代理在解决问题的能力上是等效的。", "conclusion": "所有由解决问题者解决的导航问题，控制器也都能够解决，这表明两种代理在解决问题的能力上是等效的。这意味着结合了两种学习方式的自主代理能够具有出色的问题解决能力，并可成功应用于新环境中的导航任务。"}
{"llm_update_time": "20250723", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.16395", "html_url": "https://arxiv.org/abs/2507.16395", "title": "LLM驱动的通过显式与隐式依赖推理解缠提交的协作模型", "title_en": "LLM-Driven Collaborative Model for Untangling Commits via Explicit and Implicit Dependency Reasoning", "authors": "Bo Hou,Xin Tan,Kai Zheng,Fang Liu,Yinghao Zhu,Li Zhang", "background": "原子提交，每个提交解决单一开发问题，是软件开发的最佳实践。然而，由于实际限制或不明确的边界，开发者经常产生纠结的提交，混合了不相关的更改，这会影响代码审查和维护。尽管之前的提交解缠方法（基于规则、特征或图）已经取得了一些进展，但它们通常依赖于浅显的信号，并且无法区分显式依赖（如控制/数据流）和隐式依赖（如语义或概念关系）。", "innovation": "本文提出了ColaUntangle，这是一个新的协作咨询框架，用于提交解缠，它可以建模代码更改中的显式和隐式依赖。该框架采用多智能体架构，结合大型语言模型（LLM）驱动的代理，其中一个代理专注于显式依赖，另一个专注于隐式依赖，还有一个审阅者代理通过迭代咨询综合他们的观点。我们构建了多版本程序依赖图（delta-PDG）来捕获显式和隐式上下文信息，使代理能够深刻地推理代码关系。ColaUntangle 通过对两个广泛使用的数据集（1,612 个 C# 和 14,000 个 Java 混杂提交）的实验评估，表现出色。", "conclusion": "实验结果表明，ColaUntangle 比基准线模型表现出更优异的性能，C# 数据集提高了 44% 的性能，而 Java 数据集则达到了 100% 的性能。这些结果突显了基于 LLM 的协作框架在推进自动化提交解缠任务方面的潜力。"}
{"llm_update_time": "20250723", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.16478", "html_url": "https://arxiv.org/abs/2507.16478", "title": "ACT：通过合成数据生成与自适应训练弥合代码翻译差距", "title_en": "ACT: Bridging the Gap in Code Translation through Synthetic Data Generation & Adaptive Training", "authors": "Shreya Saxena,Siva Prasad,Zishan Ahmad,Vishal Vaddina", "background": "代码翻译在软件开发和迁移项目中至关重要，能够促进不同编程语言之间的互操作性，增强软件的适应性和寿命。传统自动化翻译方法主要依赖手工设计的转换规则，缺乏灵活性和扩展性。同时，先进的语言模型展示了替代方案，但受限于专有且基于API的实现，这引起了人们对数据安全和依赖的担忧。", "innovation": "本文提出了一种名为Auto-Train for Code Translation (ACT)的创新框架，通过使内部对开源大型语言模型进行微调以提高代码翻译能力。ACT的自动流水线显著提高了这些模型的性能，缩小了开源访问性和闭源解决方案高性能之间的差距。ACT的核心模块包括合成数据生成模块，它从初始代码样本文本生成大量高质量数据集，并结合单元测试以确保功能准确性和多样性。ACT的评估框架包括执行级检查，提供了全面的翻译质量评估。ACT的控制器模块管理整个管道，通过动态调整超参数、协调数据生成迭代以及基于实时评估进行微调，智能优化训练过程、生成额外的培训数据或停止过程。", "conclusion": "我们的结果表明，ACT持续提高了开源模型的有效性，为企业和开发者提供了一个安全可靠的替代方案。此外，将我们的数据生成管道应用于工业规模的迁移项目，显著提高了开发者的加速。"}
{"llm_update_time": "20250723", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.16507", "html_url": "https://arxiv.org/abs/2507.16507", "title": "基于知识图谱的主动RAG在实际复杂多跳推理中的应用", "title_en": "Agentic RAG with Knowledge Graphs for Complex Multi-Hop Reasoning in Real-World Applications", "authors": "Jean Lelong,Adnane Errazine,Annabelle Blangero", "background": "传统的检索增强生成（RAG）系统可以增强大型语言模型（LLMs），但在处理复杂查询时常常表现出色不足。它们往往只能提供有限、提取的答案，并且难以进行多次针对性检索或处理复杂的实体关系。在知识密集型领域，这种差距是关键问题。", "innovation": "我们引入了INRAExplorer，这是一个具有代理性的RAG系统，用于探索法国国家农业食品与环境研究院（INRAE）的科学数据。INRAExplorer采用基于LLM的代理和多工具架构，动态参与广泛的知识库，通过基于开放获取INRAE出版物的综合知识图谱。这种设计使INRAExplorer能够进行迭代、有针对性的查询，检索全面的数据集（例如，所有某个作者的出版物），进行多跳推理，并提供结构化、全面的答案。", "conclusion": "INRAExplorer作为提升专业化领域知识交互的一种具体应用实例，展示了在实际复杂多跳推理中的增强效果。"}
{"llm_update_time": "20250723", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.16635", "html_url": "https://arxiv.org/abs/2507.16635", "title": "通用工业装配线平衡问题的新型多代理动作掩码深度强化学习", "title_en": "Novel Multi-Agent Action Masked Deep Reinforcement Learning for General Industrial Assembly Lines Balancing Problems", "authors": "Ali Mohamed Ali,Luca Tirel,Hashim A. Hashim", "background": "现代工业装配线需要高效的活动规划以维护制造标准、防止项目约束违背并实现成本效益的操作。整数规划（IP）可以提供精确的解决方案，但随着输入参数的增加，搜索空间的依赖性使得IP在大规模场景下计算上不可行。遗传算法等启发式方法虽然可行，但在大规模情况下往往产生次优解。因此，需要一种新的方法来解决这些挑战。", "innovation": "提出了一种通用工业装配线的数学模型，该模型基于马尔可夫决策过程（MDP），且不作类型假设；引入了多代理框架，每个工作站由独立的代理管理，通过行动掩码技术保证仅选择可行行动，进一步减少学习时间；采用集中式训练框架但分散执行，提供可扩展的学习架构来优化工业装配线。", "conclusion": "所提出的方案通过数值模拟得到了验证，相比基于模型的方法，能够显著更快地收敛到最优解。"}
{"llm_update_time": "20250723", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.16534", "html_url": "https://arxiv.org/abs/2507.16534", "title": "实际应用中的前沿人工智能风险管理框架：一项风险分析技术报告", "title_en": "Frontier AI Risk Management Framework in Practice: A Risk Analysis Technical Report", "authors": "Shanghai AI Lab:Xiaoyang Chen,Yunhao Chen,Zeren Chen,Zhiyun Chen,Hanyun Cui,Yawen Duan,Jiaxuan Guo,Qi Guo,Xuhao Hu,Hong Huang,Lige Huang,Chunxiao Li,Juncheng Li,Qihao Lin,Dongrui Liu,Xinmin Liu,Zicheng Liu,Chaochao Lu,Xiaoya Lu,Jingjing Qu,Qibing Ren,Jing Shao,Jingwei Shi,Jingwei Sun,Peng Wang,Weibing Wang,Jia Xu,Lewen Yan,Xiao Yu,Yi Yu,Boxuan Zhang,Jie Zhang,Weichen Zhang,Zhijie Zheng,Tianyi Zhou,Bowen Zhou", "background": "为了识别和理解快速发展的人工智能模型所带来的前所未有的风险，本文通过对前沿人工智能风险管理框架（v1.0）的评估，探讨了这些模型可能带来的风险，并集中在七个关键领域：网络攻击、生物化学风险、说服和操控、不受控制的自主AI研发、战略欺骗和阴谋、自我复制和共谋。", "innovation": "本文采用前沿人工智能风险管理框架（v1.0，SafeWork-F1-Framework）的E-T-C分析（部署环境、威胁来源、促成能力），识别关键风险，并使用“AI-45°法则”对这些风险进行评估，设定了“红线”（不可接受的阈值）和“黄线”（早期预警指标），将风险分为绿色（可管理风险）黄色（需要加强缓解措施）红色（需要暂停研发和/或部署）三个区域。结果显示，所有评估的前沿AI模型均位于绿色和黄色区域，并未突破红色底线。", "conclusion": "本研究展示了我们目前对前沿人工智能风险的理解，并呼吁集体行动以应对这些挑战。"}
{"llm_update_time": "20250723", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.16727", "html_url": "https://arxiv.org/abs/2507.16727", "title": "Deliberative Searcher: 通过带约束的强化学习提高大语言模型可靠性", "title_en": "Deliberative Searcher: Improving LLM Reliability via Reinforcement Learning with constraints", "authors": "Zhenyun Yin,Shujie Wang,Xuhong Wang,Xingjun Ma,Yinchun Wang", "background": "在实际应用场景中，大型语言模型（LLMs）的可靠性至关重要。为解决这一问题，本文提出了一种新的框架——Deliberative Searcher，该框架首次结合了确信度校准与基于检索的搜索技术，用于开放领域的问答任务。该框架通过多步骤的反思与验证机制，在Wikipedia数据上进行训练，优化算法侧重于在软可靠性约束条件下提高准确率，从而提高模型的可信度和输出的准确性。实验证明，这种方法可以更好地使模型的信心与正确性对齐，从而产出更可信的结果。这项研究正在进行中并会持续更新。", "innovation": "提出了Deliberative Searcher框架，这是首个结合确信度校准与基于检索的搜索技术的框架，用于开放领域的问答任务。采用多步骤的反思与验证机制，在Wikipedia数据上进行训练，使用优化算法在软可靠性约束条件下优化准确率，从而提高模型的准确性和可信度。", "conclusion": "Deliberative Searcher框架通过多步骤的反思与验证机制和优化算法，能有效地提高大型语言模型的可靠性和输出的准确性，使模型的信心与正确性更好地对齐，产生更可信的结果。这项研究正在进行中并会持续更新。"}
{"llm_update_time": "20250723", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.16670", "html_url": "https://arxiv.org/abs/2507.16670", "title": "使用深度强化学习适应动态农业食品供应链的库存策略", "title_en": "Adaptive Inventory Strategies using Deep Reinforcement Learning for Dynamic Agri-Food Supply Chains", "authors": "Amandeep Kaur,Gyan Prakash", "background": "农产品的生产和需求往往受到季节性波动的影响，这使得预测和管理库存水平来应对这些变化具有挑战性，可能导致过多的库存或断货。此外，现有文献并未考虑供应链各层级各利益相关者之间的协调。本研究旨在解决这些问题，关注在需求和交货时间不确定性下农业食品产品的库存管理。", "innovation": "当前研究提出了结合价值导向和策略导向DRLapproaches的新颖深度强化学习算法，用于在不确定性条件下进行库存优化。该算法通过促进供应链中各利益相关者的合作，旨在最大化整体盈利能力，同时同时考虑食品的易腐性和不确定性。", "conclusion": "通过该算法选择最佳订单量，该研究有效解决了库存优化挑战，并证实了在随机需求模式和交货时间场景下提出的库存补充策略的优越性能。研究结果为政策制定者管理农产品不确定性下的库存提供了管理启示。"}
{"llm_update_time": "20250723", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.16768", "html_url": "https://arxiv.org/abs/2507.16768", "title": "WGRAMMAR：利用先验知识加速结构化解码", "title_en": "WGRAMMAR: Leverage Prior Knowledge to Accelerate Structured Decoding", "authors": "Ran Wang,Xiaoxuan Liu,Hao Ren,Gang Chen,Fanchao Qi,Maosong Sun", "background": "现有的结构化解码方法存在效率瓶颈，主要由于文法规则编译、状态跟踪和掩码创建等过程。大型语言模型（LLMs）需要生成符合下游系统格式要求的输出，如HTML或JSON，而现有方法在处理这些格式时效率较低。许多实际任务中蕴含了强输出结构先验知识，但现有方法未能有效利用这些知识来优化解码效率。", "innovation": "本文提出了一种将约束分解为静态和动态组成部分的方法，预先编译静态结构，在运行时通过文法规则片段实例化动态参数。作者还提出了一种名为wgrammar的轻量级解码引擎，通过集成领域意识简化、约束分解和掩码缓存等技术，最终能达到比现有系统250倍的提速效果。相比传统的使用推进式自动机的方法，wgrammar采用组合运算符对常规格式进行建模，实现较低的状态转换延迟。", "conclusion": "wgrammar解码引擎通过利用先验输出结构知识实现了显著的解码加速，与现有系统相比，它在效率上有了质的飞跃。该方法通过有效利用结构化任务的先验知识，简化解码过程中的复杂性，有效提升了解码速度，是一种实用且高效的优化解决方案。"}
{"llm_update_time": "20250723", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.16792", "html_url": "https://arxiv.org/abs/2507.16792", "title": "ChatChecker：通过非合作用户模拟进行对话系统测试与评估的框架", "title_en": "ChatChecker: A Framework for Dialogue System Testing and Evaluation Through Non-cooperative User Simulation", "authors": "Roman Mayr,Michel Schimpf,Thomas Bohné", "background": "现代对话系统依赖于大型语言模型（LLMs），但其实现不仅限于单纯使用LLMs进行交互。开发者通常会整合多个LLMs、外部工具以及数据库等资源。因此，仅评估底层的LLMs是不够的，对话系统应作为一个整体进行测试和评估。然而，这仍然是一个重大挑战。尽管大多数前期工作集中在针对单个轮次的分析上，较少关注集成对话系统的整体质量保障。为解决这一问题，本文提出了ChatChecker框架，用于自动评估和测试复杂的对话系统。", "innovation": "ChatChecker框架通过使用LLMs模拟多元化的用户交互，识别对话系统的故障点，并评估其质量。相较于前人方法，该设计减少了设置工作量且增加了通用性，无需参考对话数据，并与目标对话系统的实现解耦。本文通过在提示中加入错误分类学，改进了基于LLM的故障检测性能。此外，提出的新的非合作用户模拟器采用具有挑战性的个性角色，更有效地揭露目标对话系统的弱点。ChatChecker因此促进了深入且可扩展的测试，有助于研究人员和实践者加速稳健对话系统的开发进程。", "conclusion": "ChatChecker框架有助于总体和大规模测试，促进了对话系统作为一个整体进行有效评估。这种方法不仅改进了故障检测性能，而且还提出了一种新颖的非合作用户模拟器，有效地揭示对话系统的弱点。"}
{"llm_update_time": "20250723", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.15867", "html_url": "https://arxiv.org/abs/2507.15867", "title": "RDMA: 在电子健康记录系统中成本效益的代理驱动罕见疾病发现", "title_en": "RDMA: Cost Effective Agent-Driven Rare Disease Discovery within Electronic Health Record Systems", "authors": "John Wu,Adam Cross,Jimeng Sun", "background": "罕见疾病影响美国10%的人口，但标准ICD编码系统无法在电子健康记录（EHR）中捕获这些疾病，使关键信息埋藏在临床笔记中。现有方法处理医学缩写困难，忽略隐含的疾病提及，云端处理引发隐私担忧，缺乏临床推理能力。", "innovation": "我们提出了Rare Disease Mining Agents (RDMA)框架，该框架模仿了医疗专家识别EHR中罕见疾病模式的方法，能够整合分散的临床观察，一起暗示特定罕见状况。RDMA处理医学缩写，识别隐含的疾病模式，并在标准硬件上进行本地上下文推理，降低了隐私风险，同时改进了F1性能30%以上，减少了推理成本10倍。这项方法帮助临床医生在访问EHR系统中的关键罕见疾病信息时避免使用云服务带来的隐私风险，支持罕见疾病患者的更早诊断", "conclusion": "这种方法有助于临床医师避免在使用云服务时暴露隐私风险，同时能够从EHR系统中获取关键的罕见疾病信息，支持罕见疾病患者的早期诊断。"}
{"llm_update_time": "20250723", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.14452", "html_url": "https://arxiv.org/abs/2507.14452", "title": "GPI-Net: Gestalt-Guided Parallel Interaction Network via Orthogonal Geometric Consistency for Robust Point Cloud Registration", "title_en": "GPI-Net: Gestalt-Guided Parallel Interaction Network via Orthogonal Geometric Consistency for Robust Point Cloud Registration", "authors": "Weikang Gu,Mingyue Han,Li Xue,Heng Dong,Changcai Yang,Riqing Chen,Lifang Wei", "background": "点云配准中的高质量对应关系识别是一项前提任务，但由于局部和全局特征的冗余性及复杂的空间关系，融合这两类特征是极具挑战性的。现有方法在处理这类问题时效果欠佳，尤其是在面对复杂的三维场景时。因此，需要提出一种新的方法来有效处理局部和全局特征的融合问题，以提高点云配准的精度和鲁棒性。", "innovation": "本文提出了新型的Gestalt-Guided Parallel Interaction Network via Orthogonal Geometric Consistency (GPI-Net)，利用Gestalt原则来促进局部和全局信息的互补交流。该网络引入了正交集成策略来优化减少冗余信息，生成一个更紧凑的全局结构，同时通过Gestalt Feature Attention (GFA)模块利用自注意力和交叉注意力机制捕捉几何特征。此外，设计了创新的Dual-path Multi-Granularity parallel interaction aggregation (DMG)块以促进不同粒度的信息交换，从而更有效地将局部详细信息整合到全局结构中。", "conclusion": "在各种挑战性任务上的广泛实验表明，GPI-Net在网络性能方面优于现有方法，显示出其优越的有效性和鲁棒性。"}
{"llm_update_time": "20250723", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.16796", "html_url": "https://arxiv.org/abs/2507.16796", "title": "基于多智能体强化学习的Peer-to-Peer能源交易的不确定性感知知识变换器", "title_en": "Uncertainty-Aware Knowledge Transformers for Peer-to-Peer Energy Trading with Multi-Agent Reinforcement Learning", "authors": "Mian Ibad Ali Shah,Enda Barrett,Karl Mason", "background": "当前文献中缺乏合理考虑不确定性预测的Peer-to-Peer (P2P)能源交易框架。以往的工作多依赖确定性的预测模型，而这些模型在处理P2P能源交易这种具有不确定性的环境下的决策时可能存在不足。", "innovation": "提出了一个新颖的框架，该框架集成了不确定性感知预测与多智能体强化学习（MARL）。具体创新点在于使用了异方差概率变换器预测模型（KTU），它能够明确量化预测不确定性，为在P2P能源交易这种随机环境中做出稳健决策提供支持。该模型还通过定制的损失函数确保了可靠的概率预测和置信区间。将这些不确定性感知的预测与MARL框架整合，使代理能够在清晰理解风险和变化的基础上优化交易策略。实验证明，基于KTU的不确定感知深度Q网络（DQN）在没有P2P交易和有P2P交易的情况下分别降低了能源购买成本5.7%和3.2%，同时增加了电力销售收益6.4%和44.7%。并且，在没有和有P2P交易的情况下，分别减少了高峰时段电网需求38.8%和45.6%。", "conclusion": "这些改进表明，先进的预测与市场机制的结合对于实现灵活、经济高效的能源社区具有积极意义。特别是当P2P交易被启用时，上述改进效果更为显著，显示了这种新的框架的优势。"}
{"llm_update_time": "20250723", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.15863", "html_url": "https://arxiv.org/abs/2507.15863", "title": "eSapiens的DEREK模块：基于LLMs的深度提取与推理知识引擎", "title_en": "eSapiens's DEREK Module: Deep Extraction & Reasoning Engine for Knowledge with LLMs", "authors": "Isaac Shi,Zeyuan Li,Fan Liu,Wenli Wang,Lewei He,Yang Yang,Tianyu Shi", "background": "本研究旨在解决企业文档问答中的安全性和可扩展性问题，特别是针对法律和金融等高风险领域，提高企业文档问答的准确性和可追溯性。现有的文档问答系统通常难以处理异构内容，且在安全性和可操作性方面存在不足，因此需要一个安全、可扩展且高效的文档问答系统来满足企业的具体需求。", "innovation": "该研究提出了名为DEREK的模块，这是一种专为企业文档问答设计的安全、可扩展的检索增强生成流水线。DEREK模块在多个方面进行了创新，包括：1) 支持异构内容的高效处理；2) 采用1000个token的重叠切片和混合HNSW+BM25索引技术以提高检索效率；3) 利用GPT-4o、Cohere和CO-STAR进行查询优化、检索和答案重排；4) 通过LangGraph验证器确保答案可追溯性，直至每个声明都有据可依；5) 所有组件均运行在容器中，确保端到端的TLS 1.3和AES-256加密，增强了系统的安全性和可操作性。", "conclusion": "研究结果表明，DEREK模块成功地实现了准确、可追踪且具备生产级别的文档问答，同时最大限度地减少了操作开销。该模块通过多个法律领域的子集测试，验证了其在增强检索精确度和生成可靠答案方面的能力，展示了其在法律和金融等高风险领域的应用潜力。此外，DEREK提供的安全、可审计和上下文忠实的检索方法为企业提供了一种可靠的基础，可应用于这些领域的重要要求。"}
{"llm_update_time": "20250723", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.15868", "html_url": "https://arxiv.org/abs/2507.15868", "title": "细微的编辑，巨大的后果：区分大型语言模型的有用鲁棒性和有害不敏感性", "title_en": "Small Edits, Big Consequences: Telling Good from Bad Robustness in Large Language Models", "authors": "Altynbek Ismailov,Salia Asanova", "background": "该研究的背景在于，目前的大规模语言模型（LLMs）已经能够编写代码，而这些代码在注入了一个简单的错误后，可能会破坏安全性或导致经济损失。研究预期这些模型应该忽略不重要的错误或打字错误，但实际未必如此。因此，作者旨在识别模型在哪种程度上的鲁棒性是有用的，以及在哪种程度上是不敏感并且有害的。为此，作者选择了50个LeetCode问题，并设计了三种最小化的提示修改：逐步删除词汇、词义翻转以及术语替换，来评估模型在这些不同类型的修改下的反应。", "innovation": "本文的创新在于引入了基于LeetCode问题的实验设计，通过针对不同类型的提示修改（即词汇删除、词义翻转、术语替换），研究人员能够系统的评估大规模语言模型在遇到不同类型的问题时的反应模式。研究发现，模型在面对大量词汇缺失的情况下仍然保持准确，显示出过度的鲁棒性，但在面对几乎改变任务本质的词义翻转时却反应不足，且经过推理调优的模型表现更差。这项研究区分了无害的修改与改变任务意义的修改，并提出了应对策略，即评估和训练协议应奖励在面对意义改变时的差异灵敏度，在保持对无害噪声的稳健性的同时，当意义真正改变时能够适应或拒绝修改。", "conclusion": "当前的大规模语言模型在面对大量的意义模糊的文本或修改时表现过度鲁棒，但对于几乎改变任务意义的关键修改反应不足。模型中的某些改动（如掩蔽关键函数名等）可能需要重新评估。因此，应该设计评估和训练协议来奖励在面对具有实际意义的修改时的敏感程度，而对无害的修改保持稳健性。"}
{"llm_update_time": "20250723", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.16280", "html_url": "https://arxiv.org/abs/2507.16280", "title": "ResearcherBench：评估深度人工智能研究系统在科学前沿领域的研究能力", "title_en": "ResearcherBench: Evaluating Deep AI Research Systems on the Frontiers of Scientific Inquiry", "authors": "Tianze Xu,Pengrui Lu,Lyumanshan Ye,Xiangkun Hu,Pengfei Liu", "background": "深度研究系统的出现带来了显著的解决问题能力，从基础查询扩展到复杂的科研任务。目前，现有的基准主要将这些系统作为网络检索和报告生成的代理进行评估，忽视了它们在科学前沿发现新见解的潜力。为解决这一问题，本文介绍了ResearcherBench，这是第一个专注于评估这些先进的新一代深度AI研究系统（DARS）能力的基准。", "innovation": "引入了ResearcherBench作为第一个专门针对深度AI研究系统（DARS）的评测框架，评估其在前沿AI科学问题上的表现。评测方法结合了基于专家设计标准的评价体系和事实准确性的度量，以及开源了该基准，以推进下一代AI研究助手的发展。", "conclusion": "实验结果显示，OpenAI Deep Research和Gemini Deep Research在开放性咨询问题上表现出显著优势，这些能力是向人工智能自我改进迈进的重要一步，符合人工智能强自我改进时代的愿景。通过开源ResearcherBench，期望促进对新一代AI研究助手的开发，并引导AI研究评估新方向：促进新型科学协作。"}
{"llm_update_time": "20250723", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.15894", "html_url": "https://arxiv.org/abs/2507.15894", "title": "Systole-Conditioned Generative Cardiac Motion", "title_en": "Systole-Conditioned Generative Cardiac Motion", "authors": "Shahar Zuler,Gal Lifshitz,Hadar Averbuch-Elor,Dan Raviv", "background": "心肌运动的准确估计对于评估心脏功能和手术规划至关重要。尽管基于数据驱动的方法已成为密集运动估计的标准方法，但它们依赖于大量带有密集真实运动标注的标签数据，而这种标签数据往往难以获得。", "innovation": "本文提出了一种新的方法，利用条件变分自编码机(CVAE)，引入了一种新颖的多尺度特征调节机制。该方法根据单张CT图像生成3D流动场，并使用生成的流动场来扭曲给定的帧，从而模拟整个心动周期中真实的心肌变形。产生的帧对作为完全标注的数据样本，提供光学流动的真实标注。这种方法可以促进更复杂和准确的心肌运动模型的训练与验证，显著减少对人工标注的依赖。", "conclusion": "该数据生成管道可使心脏CT影像中更复杂的和准确心肌运动模型的训练和验证变为可能，从而在很大程度上减少了对手动标注的依赖。相关代码及其生成样本已发布在项目页面上：this https URL."}
{"llm_update_time": "20250723", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.15897", "html_url": "https://arxiv.org/abs/2507.15897", "title": "ReDi: 修正离散流", "title_en": "ReDi: Rectified Discrete Flow", "authors": "Jaehoon Yoo,Wonjung Kim,Seunghoon Hong", "background": "离散流模型（DFMs）是强大的生成模型，用于高质量的离散数据，但通常由于依赖迭代解码过程而遭受缓慢的采样速度。这一依赖于多步过程来自于DFMs中的因子化近似，这是处理高维数据的必要条件。", "innovation": "本文严格分析了因子化引起的近似误差，使用条件总相关性（TC）指标，该指标与耦合相关。为减少条件TC并实现高效的多步生成，提出了修正离散流（ReDi）方法，通过修正源分布和目标分布之间的耦合来减少因子化误差。理论上证明了每个ReDi步骤确保条件TC单调递减，保证其收敛。实证结果表明，ReDi可以显著减少条件TC，并实现多步生成。此外，结果表明纠正后的耦合适用于图像生成的一步训练模型。", "conclusion": "ReDi提供了一种简单且理论基础的方法来应对多步挑战，为高效合成离散数据提供了新的视角。"}
{"llm_update_time": "20250723", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.15887", "html_url": "https://arxiv.org/abs/2507.15887", "title": "AlgoTune：大型语言模型能否加速通用数值程序？", "title_en": "AlgoTune: Can Language Models Speed Up General-Purpose Numerical Programs?", "authors": "Ori Press,Brandon Amos,Haoyu Zhao,Yikai Wu,Samuel K. Ainsworth,Dominik Krupke,Patrick Kidger,Touqir Sajed,Bartolomeo Stellato,Jisun Park,Nathanael Bosch,Eli Meril,Albert Steppi,Arman Zharmagambetov,Fangzhao Zhang,David Perez-Pineiro,Alberto Mercurio,Ni Zhan,Talor Abramovich,Kilian Lieret,Hanlin Zhang,Shirley Huang,Matthias Bethge,Ofir Press", "background": "尽管语言模型的能力已经有所提升，但现有的评估主要集中在人类已经解决的任务上，包括编程和数学问题。本文作者认为，现有的评估并未全面检验语言模型在编程和算法设计上的开放性挑战。因此，作者提出了一项新的基准测试AlgoTune，旨在测试语言模型在设计和实现计算机科学、物理学和数学问题的高效算法方面的能力。AlgoTune包括155个来自专家的编码任务，以及用于验证和测时LSTM合成解码代码的框架，这些解码代码会被与流行开源包中的参考实现进行比较。此外，作者还开发了一个基准LM代理AlgoTuner，并对其进行了全面模型的性能评估。", "innovation": "提出了新的基准测试AlgoTune，以检验语言模型在设计和实现高效算法上的能力。除了提出基准测试外，作者还开发了一个基准LM代理AlgoTuner，并对其进行了全面模型的性能评估。结果显示，虽然AlgoTuner的表现比参照实现快1.72倍，但它未能发现算法创新，而是偏向于表面级优化。这项工作希望促进过渡到超越人类顶尖性能的创造性问题解决能力的语言模型代理的发展。", "conclusion": "本文通过AlgoTune评估了语言模型在开发高效算法方面的潜力，发现当前模型主要停留在表面级优化，缺乏算法创新。虽然AlgoTuner能够加速现有解决方案，但未能超越人类的创造性问题解决能力。作者希望未来的研究能够设计出能够在开放领域设计和实现创新算法的语言模型代理。"}
{"llm_update_time": "20250723", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.15905", "html_url": "https://arxiv.org/abs/2507.15905", "title": "基础模型和Transformer在异常检测中的应用：一项综述", "title_en": "Foundation Models and Transformers for Anomaly Detection: A Survey", "authors": "Mouïn Ben Ammar,Arturo Mendoza,Nacim Belkhir,Antoine Manzanera,Gianni Franchi", "background": "随着深度学习的发展，这项调查研究了Transformer和基础模型在推动视觉异常检测（VAD）方面的作用。这些模型通过其全局感受野和适应性，解决了长期依赖建模、上下文建模和数据稀缺等挑战。", "innovation": "通过整合注意力机制和利用大规模预训练，Transformer和基础模型能够提供更稳健、可解释且可扩展的异常检测解决方案。这项工作对最先进的技术进行了全面回顾，突显了这些架构在VAD中的新范式。", "conclusion": "这项综述为VAD方法进行了分类，包括基于重建、基于特征和零/少量样本的方法，强调了基础模型带来的范式转变，并讨论了这些架构的优势、局限性和新兴趋势。"}
{"llm_update_time": "20250723", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.15898", "html_url": "https://arxiv.org/abs/2507.15898", "title": "一种分解星系光度参数的生成模型", "title_en": "A Generative Model for Disentangling Galaxy Photometric Parameters", "authors": "Keen Leung,Colen Yan,Jun Yin", "background": "正在运行和即将进行的光度调查将产生前所未有的星系图像数量，需要能够大规模且高效地提取星系形态参数的方法。传统方法，如参量光曲线拟合，虽然能够提供有价值的信息，但在处理数以亿计的源时变得计算上不可行。因此，需要一种能够同时建模和表征星系形态的新颖方法和模型来应对这一挑战", "innovation": "本文提出了一种条件自编码器（CAE）框架，用于同时建模和表征星系的形态。该CAE在GalSim生成的一组现实模拟星系图像上训练，这些图像涵盖了广泛的星系类型、光度参数（例如：辐射通量、半光敛缩半径、Sersic指数、椭圆度）以及观测条件。通过将每个星系图像编码为低维度的潜在表示，模型能够有效地以分离的方式恢复这些形态特征，同时重建原始图像。结果显示该CAE方法可以准确且高效地推断复杂的结构特性，为现有方法提供了一种强有力的替代方案", "conclusion": "本文提出的CAE方法能够高效且准确地从大量星系图像中提取复杂的形态特性，为星系形态研究提供了新的工具和技术，具有广泛的应用前景。"}
{"llm_update_time": "20250723", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.15903", "html_url": "https://arxiv.org/abs/2507.15903", "title": "LLM-赋能智能代理的幻觉缓解：渐进的泛化边界探索和看门狗监控", "title_en": "Towards Mitigation of Hallucination for LLM-empowered Agents: Progressive Generalization Bound Exploration and Watchdog Monitor", "authors": "Siyuan Liu,Wenjing Liu,Zhiwei Xu,Xin Wang,Bo Chen,Tao Li", "background": "随着大型语言模型（LLMs）的发展，智能代理已成为与开放环境互动的流行范式，以促进AI部署。然而，LLMs产生的幻觉（输出与事实不符）构成了重大挑战，损害了智能代理的可信度。仅当能够减轻幻觉时，智能代理才能在现实世界中安全使用，而不带来任何灾难性风险。因此，有效地检测和缓解幻觉对于确保智能代理的可靠性至关重要。不幸的是，相关方法要么依赖LLM的白盒访问，要么无法准确识别幻觉。", "innovation": "本文提出了一种名为HalMit的新颖黑盒看门狗框架，该框架通过建模LLM赋能代理的泛化界限来检测幻觉，无需了解LLM架构的内部知识。具体来说，提出了一种概率分形采样技术，生成足够数量的查询以并行触发难以置信的响应，从而高效地识别目标代理的泛化界限。实验评估表明，HalMit在幻觉监控方面明显优于现有方法。其黑盒性质和优越性能使其成为增强LLM驱动系统可靠性的有前途的解决方案。", "conclusion": "HalMit显著优于现有的幻觉监控方法，其黑盒性质和优秀性能使其成为提升LLM驱动系统可靠性的有前途的解决方案。"}
{"llm_update_time": "20250723", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.15859", "html_url": "https://arxiv.org/abs/2507.15859", "title": "Decentralized AI-driven IoT Architecture for Privacy-Preserving and Latency-Optimized Healthcare in Pandemic and Critical Care Scenarios", "title_en": "Decentralized AI-driven IoT Architecture for Privacy-Preserving and Latency-Optimized Healthcare in Pandemic and Critical Care Scenarios", "authors": "Harsha Sammangi(Dakota State University),Aditya Jagatha(College of Business and Information Systems, Dakota State University),Giridhar Reddy Bojja(College of Business, Michigan Technological University),Jun Liu(College of Business and I.S, Dakota State University)", "background": "传统的集中式医疗保健架构存在许多问题，包括数据隐私、延迟和安全性。特别是在大流行和危重护理等场景中，这种架构的问题尤为突出。", "innovation": "提出了一种基于AI的去中心化物联网架构，旨在解决现存的联邦学习、区块链和边缘计算方法中的挑战，以提高数据隐私、减少延迟，并优化其他一般系统指标。", "conclusion": "实验结果显示，该架构在交易延迟、能源消耗和数据吞吐量方面比市场竞争方案低了数量级。"}
{"llm_update_time": "20250723", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.15886", "html_url": "https://arxiv.org/abs/2507.15886", "title": "将成本约束下的运行时监控器结合以提高AI安全", "title_en": "Combining Cost-Constrained Runtime Monitors for AI Safety", "authors": "Tim Tian Hua,James Baskerville,Henri Lemoine,Mia Hopman,Aryan Bhatt,Tyler Tracy", "background": "运行时监控AI可以检测并阻止有害行为。本文研究了如何将多个运行时监控器合并为一个监控协议，以最大化在输出偏离预期时（即最大化召回率）应用安全干预的概率。由于运行监控器和应用安全干预都需要成本，因此监控协议还必须遵守平均成本预算约束。", "innovation": "本文通过考虑监控器的性能和成本，开发了一种算法来找到最有效的监控协议。该算法通过枚举何时以及调用哪个监控器，并基于Neyman-Pearson引理分配安全干预措施，专注于似然比并战略性地平衡监控支出与干预支出之间的交易，从而在代码审核环境中将召回率提高了一倍多。本文还展示了结合两个监控器可以在成本约束下优于单独使用任何一个监控器。本框架提供了一种在成本敏感环境下检测不良行为的规范性方法。", "conclusion": "本研究结合了成本约束下的运行时监控器来提高AI的安全性。通过优化监控与干预的分配，提出的方法在召回率方面取得了显著提升。结合监控器也能在成本约束条件下实现更好的效果，为在成本敏感环境中检测不良行为提供了有指导意义的方法。"}
{"llm_update_time": "20250723", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.15906", "html_url": "https://arxiv.org/abs/2507.15906", "title": "面向可靠的具有不确定性意识的模型对齐", "title_en": "Towards Reliable, Uncertainty-Aware Alignment", "authors": "Debangshu Banerjee,Kintan Saha,Aditya Gopalan", "background": "大型语言模型（LLMs）的对齐通常涉及在偏好数据上训练奖励模型，随后相对于奖励模型进行策略优化。然而，仅依赖于单一奖励模型评估进行策略优化会使奖励模型容易受到奖励模型不准确的影响。本文通过实证研究发现，独立训练在同一偏好数据集上的奖励模型会表现出显著的分歧，这突显了当前对齐策略的不稳定性。理论模型显示，奖励模型估计的差异会导致过拟合，并且会增加输出劣质政策的风险。", "innovation": "本文提出了一个具有方差感知的基于偏好优化框架来对抗这种风险。该框架的关键成分是一个新的策略正则化项，该项整合了奖励模型方差估计。实验证明，此方法在不同的LLM和奖励模型配置下提供了更为稳定和鲁棒的对齐效果，超出了解标准（无方差意识）的管线。", "conclusion": "通过方差意识的策略优化，本文增强了一种更加稳固和有效的模型对齐方法，有望减少输出低质量策略的风险。"}
{"llm_update_time": "20250723", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.15958", "html_url": "https://arxiv.org/abs/2507.15958", "title": "具有量化感知的类脑架构用于资源受限设备上高效皮肤疾病分类", "title_en": "Quantization-Aware Neuromorphic Architecture for Efficient Skin Disease Classification on Resource-Constrained Devices", "authors": "Haitian Wang,Xinyu Wang,Yiren Wang,Karen Lee,Zichen Geng,Xian Zhang,Kehkashan Kiran,Yu Zhang,Bo Miao", "background": "在边缘设备上进行准确且高效的皮肤病变分类对于可访问的皮肤科护理至关重要，但受到计算、能耗和隐私等限制，仍具有挑战性。以往的研究面临高延迟、高能耗和隐私风险的问题。", "innovation": "QANA是一种新颖的量化感知类脑架构，专为资源受限硬件上的增量皮肤病变分类设计。QANA集成了鬼模块、高效通道注意力和Squeeze-and-Excitation块，能够以低延迟和节能的方式进行稳健的特征表示，并具备向类脑神经网络(SNNs)的无缝转换和部署能力，有效解决了现有CNN到SNN模型中的延迟高、能耗大等问题。QANA在HAM10000数据集和临床数据集上的表现均优于现有模型，并在脑芯片Akida硬件上达到了1.5 ms的推理延迟和1.7 mJ的能耗/张图像。", "conclusion": "实验结果表明QANA在边缘环境中实现了准确、实时、隐私敏感的医学分析，证明了QANA在资源受限设备上的有效性和优越性，进一步推动了边缘计算在医疗领域应用的发展。"}
{"llm_update_time": "20250723", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.15977", "html_url": "https://arxiv.org/abs/2507.15977", "title": "Sparse Autoencoders for Interpreting Compressed Models", "title_en": "On the transferability of Sparse Autoencoders for interpreting compressed models", "authors": "Suchit Gupte,Vishnu Kabir Chhabra,Mohammad Mahdi Khalili", "background": "现代大型语言模型因其规模庞大面临着推理效率的挑战。为了解决这个问题，研究人员提出了许多压缩方法，如剪枝和量化。然而，压缩对模型可解释性的影响仍然不清楚。目前存在多种模型解释方法，例如电路发现，而稀疏自编码器（SAEs）在分解模型的激活空间到其特征基础方面尤其有效。", "innovation": "本文研究了原始模型和压缩模型上训练的稀疏自编码器之间的差异。研究发现，虽然在原始模型上训练的稀疏自编码器可以解释压缩后的模型，但性能稍有下降。此外，直接在原始模型上进行剪枝，并训练的稀疏自编码器性能与在剪枝后模型上训练的新稀疏自编码器相当。这表明可以缓解稀疏自编码器的大量训练成本。", "conclusion": "研究表明，在原始模型上训练的稀疏自编码器可以解释压缩后的模型，尽管性能稍有下降。相比之下，在原始模型上进行剪枝并训练稀疏自编码器的性能与在剪枝后模型上训练相同的新稀疏自编码器相当。这一发现允许我们减轻稀疏自编码器的大量训练成本。"}
{"llm_update_time": "20250723", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.16005", "html_url": "https://arxiv.org/abs/2507.16005", "title": "AutoMAT: 自主合金发现的分层框架", "title_en": "AutoMAT: A Hierarchical Framework for Autonomous Alloy Discovery", "authors": "Penghui Yang,Chendong Zhao,Bijun Tang,Zhonghan Zhang,Xinrun Wang,Yanchen Deng,Yuhao Lu,Cuntai Guan,Zheng Liu,Bo An", "background": "合金发现对现代工业至关重要，但仍然受到组成设计空间庞大的问题和昂贵的验证过程的限制。传统方法依赖于手动收集大量数据并进行实验验证，效率低下且成本高昂。", "innovation": "AutoMAT 提出了一种分层和自主的框架，通过结合大型语言模型、自动化 CALPHAD 模拟和 AI 驱动搜索，加速合金设计。该框架从想法产生到验证的整个管道中，实现了高效性、准确性和可解释性，无需手动收集大量数据集。在两个案例研究中，AutoMAT 在不同的合金设计方面表现出显著的改进，并大大缩短了发现时间线，展示了其作为下一代合金设计的可扩展和多功能平台的潜力.", "conclusion": "AutoMAT 通过集成大型语言模型、自动化 CALPHAD 模拟和 AI 驱动搜索，实现了一种全新的合金设计方法。这种方法不仅提高了合金设计的效率和准确性，还大大缩短了发现周期，展示了其在广泛合金设计领域的广泛应用潜力。"}
{"llm_update_time": "20250723", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.16033", "html_url": "https://arxiv.org/abs/2507.16033", "title": "仅是一张奇怪的照片：从多元注释者的视角评估GenAI图片的安全性", "title_en": "\"Just a strange pic\": Evaluating 'safety' in GenAI Image safety annotation tasks from diverse annotators' perspectives", "authors": "Ding Wang,Mark Díaz,Charvi Rastogi,Aida Davani,Vinodkumar Prabhakaran,Pushkar Mishra,Roma Patel,Alicia Parrish,Zoe Ashwood,Michela Paganini,Tian Huey Teh,Verena Rieser,Lora Aroyo", "background": "AI生成内容的安全性构成复杂，开发者通常依赖预定义的分类体系，但现实中的安全判断还涉及个人、社会和文化上的伤害感知。该研究聚焦于注释者如何评估AI生成图像的安全性，通过分析5372个开放性留言，发现注释者在评估时依靠道德、情感和情境推理，超越了结构化安全类别，更多关注对他人而非自身的潜在伤害，基于生活经验、共同风险和文化意识来做出判断。", "innovation": "研究揭示了现有安全流程漏掉了注释者在任务中带入的关键推理形式，提出了评价设计应构建道德反思、区分不同类型的风险，并为AI生成内容提供主观和情境敏感的解读空间。", "conclusion": "尽管注释者在评估AI生成图像时引用了图像质量、视觉扭曲及提示与生成结果之间的不匹配等因素，这些因素在标准评估框架中常被忽视。研究认为现有安全框架未能捕捉到注释者的全面评价，建议未来的评价设计应支持道德思考，区分不同类型风险，并为解读AI生成内容提供灵活空间。"}
{"llm_update_time": "20250723", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.15889", "html_url": "https://arxiv.org/abs/2507.15889", "title": "Dr. Boot: 通过递增训练提高程序合成语言模型的修复能力", "title_en": "Dr. Boot: Bootstrapping Program Synthesis Language Models to Perform Repairing", "authors": "Noah van der Vleuten", "background": "一般情况下，程序合成的语言模型是在编程竞赛数据集（MBPP、APPS）上进行训练和评估的。然而，这些数据集在大数据量和高质量方面存在限制，而这些语言模型对数据的需求却非常大。此外，程序合成模型的开发过程在与人类迭代开发的方式上存在不一致。与人类在编写代码时不断从编译器获取反馈不同，当前大多数程序合成模型通常一次性生成代码。因此，本文探讨并提出了一个用于程序合成的递增算法，该算法支持指导模型进行修复学习，以解决上述问题。", "innovation": "提出了一种用于程序合成的递增算法——Dr. Boot，该算法通过教导模型如何进行修复来提升模型性能。实验证明，递增算法（Dr. Boot）的效果优于常规微调。与现有工作相比，使用递增算法训练的模型在与更大68%的微调模型具有相同性能的同时，还改善了非修复性表现。这些模型中的修复推理可能不如简单采样更多的解决方案有效。此外，研究中还指出APPS数据集训练部分中的示例测试案例存在缺陷，这对于研究修复和强化学习方法的社区成员来说是宝贵的资源。", "conclusion": "递增算法（Dr. Boot）在提高程序合成模型的修复能力方面有所成效，尤其是在提高非修复性表现方面表现出色。尽管如此，修复推理的性能可能并不如简单的重复采样解决方案来得优秀。同时，APPS数据集中存在的一些问题对修复以及强化学习方法的研究有重要意义。"}
{"llm_update_time": "20250723", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.15882", "html_url": "https://arxiv.org/abs/2507.15882", "title": "Document Haystack: 长文档多模态图像/文档理解视觉大规模语言模型基准", "title_en": "Document Haystack: A Long Context Multimodal Image/Document Understanding Vision LLM Benchmark", "authors": "Goeric Huybrechts,Srikanth Ronanki,Sai Muralidhar Jayanthi,Jack Fitzgerald,Srinivasan Veeravanallur", "background": "多模态大型语言模型的普及大幅提升了从不同模式的复杂数据输入中进行分析和理解的能力。然而，长文档的处理仍被严重忽视，主要是因为缺乏适当的基准。", "innovation": "本文介绍了Document Haystack，这是为了评估视觉语言模型（VLMs）在长、视觉上复杂的文档上的表现而设计的一个全面基准。该基准包含从5到200页不同长度的文档，并在文档的不同深度插入纯文本或包含图像的多模态文本+图像以挑战VLMs的检索能力。基准包括400个文档变体和8250个问题，并配备了一个客观的自动化评估框架。", "conclusion": "本文详细介绍了Document Haystack数据集的构建和特点，并展示了主要VLMs的结果以及研究方向的讨论。"}
{"llm_update_time": "20250723", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.16038", "html_url": "https://arxiv.org/abs/2507.16038", "title": "发现和利用斯柏克片段", "title_en": "Discovering and using Spelke segments", "authors": "Rahul Venkatesh,Klemen Kotar,Lilian Naing Chen,Seungwoo Kim,Luca Thomas Wheeler,Jared Watrous,Ashley Xu,Gia Ancone,Wanhee Lee,Honglin Chen,Daniel Bear,Stefan Stojanov,Daniel Yamins", "background": "计算机视觉中，分割通常依据语义定义，并且受到特定类别规则的影响。相比之下，发展心理学表明，人类根据物理法则共同动作的物理实体进行世界感知，即斯柏克物体。斯柏克物体基于范畴无关的因果动作关系进行感知，有助于任务如操作和规划。因此，本文旨在探索斯柏克物体的概念，建立了斯柏克基准数据集，并构建了斯柏克网络，用于预测未来动作的分布，支持斯柏克物体的发现。", "innovation": "本文首次提出了斯柏克基准数据集（SpelkeBench），包含多种自然图像中的斯柏克片段。同时，构建了斯柏克网络（SpelkeNet），用于从图像中算法性地提取斯柏克片段，并通过“统计反事实探查”方法定义斯柏克片段，此方法能够通过虚拟推挤产生不同的运动状态预测，然后利用这些状态来定义运动关联统计的斯柏克片段。实验结果表明，与监督基准方法如SegmentAnything (SAM)相比，斯柏克网络在斯柏克基准数据集上表现更优。此外，斯柏克概念在下游应用中也非常有用，特别是在物理对象操作方面，能够显著提高性能。", "conclusion": "斯柏克物体的概念不仅有助于提高分割的准确性，还能够促进下游物理操作任务的应用，体现出泛化的实用性。斯柏克网络方法提高了识别和利用斯柏克物体的能力，展示了其在现实世界应用中的潜力。"}
{"llm_update_time": "20250723", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.15878", "html_url": "https://arxiv.org/abs/2507.15878", "title": "基于重要性调整的情境意识情感识别", "title_en": "Salience Adjustment for Context-Based Emotion Recognition", "authors": "Bin Han,Jonathan Gratch", "background": "情感识别在动态社会环境中需要理解面部表情与情境线索之间的复杂互动。现有的情感识别框架往往未能有效结合面部和情境信息来提高识别性能。", "innovation": "本文提出了一种基于重要性调整的情境感知情感识别框架，采用贝叶斯线索整合（BCI）和视觉语言模型（VLMs）对面部和情境信息进行动态加权。该方法根据面部线索的表达性来调整加权因素，从而提高情感识别性能。", "conclusion": "初步结果显示，通过重要性调整增强的情感识别性能显著提升。未来的研究方向包括将此框架扩展到更广泛的社会情境和多模态应用中。"}
{"llm_update_time": "20250723", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.15961", "html_url": "https://arxiv.org/abs/2507.15961", "title": "一种用于提高实时筛查应用中人脸识别性能的轻量级faces图像质量评估框架", "title_en": "A Lightweight Face Quality Assessment Framework to Improve Face Verification Performance in Real-Time Screening Applications", "authors": "Ahmed Aman Ibrahim,Hamad Mansour Alawar,Abdulnasser Abbas Zehi,Ahmed Mohammad Alkendi,Bilal Shafi Ashfaq Ahmed Mirza,Shan Ullah,Ismail Lujain Jaleel,Hassan Ugail", "background": "面部图像的质量对人脸识别系统的准确性和可靠性至关重要，尤其是在监控、身份验证和访问控制等实时筛查应用中。低质量的面部图像，通常由诸如运动模糊、光照条件差、遮挡和极端的姿态变化等因素引起，显著降低了人脸识别模型的性能，导致更高的拒识率和误识率。为了在将面部图像输入验证流程前预先过滤掉低质量的面部图像，本文提出了一个轻量且有效的面部质量评估框架。该框架利用标准化面部特征点结合随机森林回归分类器来评估图像质量，并取得了96.67%的高准确率。通过将质量评估模块整合到人脸识别流程中，观察到了显著的性能提升，尤其是在拒识率上减少了99.7%，并且与ArcFace人脸识别模型搭配使用时，余弦相似度得分也得到了提升。", "innovation": "提出了一个轻量且有效的面部质量评估框架，利用标准化面部特征点结合随机森林回归分类器来评估图像质量，取得了96.67%的高准确率。将质量评估模块整合到人脸识别流程中，显著提升了人验识别模型的性能，尤其是在拒识率上有了显著改进，并且与ArcFace人脸识别模型搭配使用时，余弦相似度得分也得到了提升。此外，该框架解决了实时筛查中的两个关键挑战：面部分辨率的变异和姿态偏差。", "conclusion": "实验验证了该提出的框架在实地环境中（包含超过600个不同人物从迪拜警察局监控摄像机捕获的面部图像）的有效性，通过减轻低质量面部图像的影响，不仅在性能上超过了现有的技术，还保持了计算效率。此外，框架专门解决了两个在实时筛查中常见的挑战：面部分辨率的变异和姿态偏差。"}
{"llm_update_time": "20250723", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.16039", "html_url": "https://arxiv.org/abs/2507.16039", "title": "重激活：任务转移下的NTK动态实证研究", "title_en": "Reactivation: Empirical NTK Dynamics Under Task Shifts", "authors": "Yuzhi Liu,Zixuan Chen,Zirui Zhang,Yufei Liu,Giulia Lanzillotta", "background": "Neural Tangent Kernel (NTK) 提供了一种强有力的工具来研究神经网络的功能动态。在所谓的懒惰或核状态下，NTK 在训练过程中保持静止，网络函数在静止的神经切线特征空间中是线性的。训练期间NTK 的演变对于特征学习至关重要，这是深度学习成功的关键驱动力。近年来，对NTK 动态的研究导致了关于泛化和扩展行为的一些关键发现。然而，这些研究主要局限于单任务设置，假定数据分布随时间保持不变。", "innovation": "本文主要创新在于对NTK 动态的综合实证分析，研究在持续学习场景下的NTK 动态，其中数据分布随时间发生变化。这项工作揭示了持续学习作为一个丰富且尚未充分利用的测试床，用于探测神经训练动态的重要性，同时也挑战了理论处理中静态核近似的有效性，即使在大型模型中也是如此。", "conclusion": "本文的结果表明，持续学习是一个丰富且尚未充分利用的测试床，用于探索神经训练的动态。同时，它还质疑了理论上持续学习处理中的静态核近似的有效性，即使在大规模模型中也不例外。"}
{"llm_update_time": "20250723", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.16063", "html_url": "https://arxiv.org/abs/2507.16063", "title": "AI-Powered Commit Explorer (APCE),", "title_en": "AI-Powered Commit Explorer (APCE)", "authors": "Yousab Grees,Polina Iaremchuk,Ramtin Ehsani,Esteban Parra,Preetha Chatterjee,Sonia Haiduc", "background": "在版本控制系统中，提交信息为开发人员提供了有关软件系统代码更改的重要信息。提交信息往往是未来开发人员了解代码变更及其原因的唯一信息来源。然而，在实践中，高质量的提交信息经常被忽视。通过使用大型语言模型 (LLM) 生成的提交信息来缓解这一问题，已出现了许多方法。为此，作者介绍了一款名为AI-Powered Commit Explorer (APCE) 的工具，旨在支持开发人员和研究人员在使用和研究LLM生成的提交信息方面的应用。", "innovation": "APCE 提供了存储不同 LLM 提示选项的功能，并附加了一个评估提示，可以进一步增强由 LLM 提供的提交信息。此外，APCE 还提供了一套为研究人员设计的自动化和人工评估机制，用于评估 LLM 生成的信息。", "conclusion": "通过应用 APCE，开发人员和研究人员可以更有效地利用 LLM 生成的提交信息，从而改善代码变更的记录质量。此工具为研究如何提高提交信息质量提供了一种有前景的方法。"}
{"llm_update_time": "20250723", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.15970", "html_url": "https://arxiv.org/abs/2507.15970", "title": "非线性框架下的语音宽带扩展", "title_en": "Nonlinear Framework for Speech Bandwidth Extension", "authors": "Tarikul Islam Tamiti,Nursad Mamun,Anomadarshi Barua", "background": "在电信、高保真音频等有限资源的应用中，恢复因带宽限制而丢失的高频成分对于提高音质和传输质量至关重要。", "innovation": "该论文提出了一种名为NDSI-BWE的新框架，它利用四种受非线性动力系统启发的鉴别器（MRLD、MS-RD、MSDFA和MR-PPD），以及Multi-Period Discriminator (MPD)、Multi-Resolution Amplitude Discriminator (MRAD) 和 Multi-Resolution Phase Discriminator (MRPD)，来捕捉不同时间行为。NDSI-BWE通过在卷积块的核心使用深度可分离卷积，实现了参数量减少八倍。此外，研究使用了复杂的ConformerNeXt生成器和基于双流Lattice-Net架构进行同时的幅度和相位细化，利用基于变换子的Conformer的全局依赖建模能力和ConvNeXt块的局部时域建模能力。", "conclusion": "NDSI-BWE在六个客观评估指标和由五位人类专家组成的人为评估文本中均取得优异成绩，建立了在宽带扩展领域的最新标准（SoTA）。"}
{"llm_update_time": "20250723", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.16068", "html_url": "https://arxiv.org/abs/2507.16068", "title": "使用大型语言模型的多机器人团队组成协调", "title_en": "Compositional Coordination for Multi-Robot Teams with Large Language Models", "authors": "Zhehui Huang,Guangyao Shi,Yuwei Wu,Vijay Kumar,Gaurav S. Sukhatme", "background": "多机器人协调长期以来依赖于特定任务和专家导向的管道，其中自然语言的任务描述由领域专家手动翻译为数学公式、算法设计和可执行代码。这种传统过程劳动密集、对非专家不友好且对任务需求变更不够灵活。因此，本文探讨了如何使用大型语言模型（LLMs）来简化并泛化多机器人协调管道，提出了一种名为LAN2CB（Language to Collective Behavior）的新框架，直接将自然语言任务描述转化为可执行的多机器人系统代码。", "innovation": "提出的LAN2CB框架通过两个关键组件——任务分解和代码生成，实现了将自然语言的任务描述直接转化为可执行的多机器人系统控制代码，从而简化多机器人系统的协调过程，支持任务类型的广泛泛化，显著减少了手动工程的需求，并且不需要重新设计和编程即可适应任务需求的变化。此外，还引入了一个自然语言任务规范数据集以支持该框架的开发和基准测试。实验结果表明，该方法在模拟和真实环境中均能有效实现从自然语言生成多机器人协调策略，大幅降低了人力成本并提高了灵活性和适应性。", "conclusion": "LAN2CB框架通过使用大型语言模型显著简化了多机器人系统协调的管道，转换过程由任务分解和代码生成两个关键元素组成，实现了从自然语言直接生成可执行代码，支持任务类型的广泛泛化，且能够减少对人工设计的需求。"}
{"llm_update_time": "20250723", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.16083", "html_url": "https://arxiv.org/abs/2507.16083", "title": "On-device大型语言模型高效组合多任务", "title_en": "Efficient Compositional Multi-tasking for On-device Large Language Models", "authors": "Ondrej Bohdal,Mete Ozay,Jijoong Moon,Kyeng-Hun Lee,Hyeonmok Ko,Umberto Michieli", "background": "适配器参数提供了一种机制，用于修改机器学习模型的行为，并且在大型语言模型（LLMs）和生成式AI的背景下引起了广泛的关注。这些参数可以通过任务合并来支持多个任务。然而，先前在LLMs中的任务合并工作，尤其是在自然语言处理中，主要局限于每个测试示例只涉及一个任务的场景。本文关注设备端的设置，并研究了基于文本的组合多任务问题，其中每个测试示例涉及多个任务的同时执行。例如，生成长文本的翻译摘要需要同时解决翻译和摘要任务。为了在这种设置下推进研究，我们提出了一项包含四个实际相关组合任务的基准测试。我们还提出了一种针对设备端应用的高效方法（可学习校准），强调了资源高效和高性能解决方案的需求。研究结果为基础现实世界中的多任务场景下LLMs的能力提升铺平了道路，并扩大了它们在资源受限的复杂应用场景中的适用性。", "innovation": "我们提出了一项包含四个实际相关组合任务的基准测试，并开发了一种专为设备端应用设计的方法（可学习校准），旨在解决多任务问题，尤其是在计算资源有限的环境中。这项工作为在现实世界的多任务场景中推进LLMs的能力奠定了基础，并且扩展了它们在资源受限的复杂应用场景中的适用性。", "conclusion": "我们的研究结果为在现实世界中的多任务场景下提升LLMs的能力奠定了基础，并且扩大了它们在资源受限的复杂应用场景中的适用性。"}
{"llm_update_time": "20250723", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.16079", "html_url": "https://arxiv.org/abs/2507.16079", "title": "Ternary ReLU回归神经网络线性区域的下界", "title_en": "A Lower Bound for the Number of Linear Regions of Ternary ReLU Regression Neural Networks", "authors": "Yuta Nakahara,Manabu Kobayashi,Toshiyasu Matsushima", "background": "随着深度学习的发展，降低计算复杂性和内存消耗已成为关键技术挑战，而参数限制在{-1, 0, +1}之间的三值神经网络（Ternary NNs）因其优秀的实际应用表现（如图像识别和自然语言处理）而备受关注。然而，这种网络的理论理解仍不够充分。本文从线性区域的数量角度，对Ternary NNs的可表达性进行了理论分析，特别是针对带有ReLU激活函数的回归Ternary NNs。研究表明其线性区域的数量与网络宽度成多项式关系，与深度成指数关系，与普通ReLU回归神经网络相似。这一发现为解释三值神经网络在实际中的成功提供了一定的理论依据，尽管只是部分解释.", "innovation": "本文的主要创新在于从线性区域的数量角度对Ternary NNs的可表达性进行了理论分析，提出了三值ReLU回归神经网络线性区域数量的下界，证明其线性区域数量与网络宽度呈多项式增长，与深度呈指数增长。此外，研究展示了通过将宽度平方或深度翻倍，三值神经网络的线性区域数量下界可以与一般ReLU回归神经网络相媲美，这为三值神经网络在实际中的成功提供了部分理论解释，展示了解决上述挑战的可能方法和方向.", "conclusion": "本文通过理论分析显示了三值ReLU回归神经网络线性区域数量的下界，表明其线性区域数量与网络宽度成多项式关系，与深度呈指数关系，近似等于普通ReLU回归神经网络。该结果为理解三值神经网络的工作机制和提供理论支持提供了基础，对改进和部署三值神经网络具有重要意义。"}
{"llm_update_time": "20250723", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.15979", "html_url": "https://arxiv.org/abs/2507.15979", "title": "从单张图像到可动画化的高斯 avatar：Dream, Lift, Animate", "title_en": "Dream, Lift, Animate: From Single Images to Animatable Gaussian Avatars", "authors": "Marcel C. Bühler,Ye Yuan,Xueting Li,Yangyi Huang,Koki Nagano,Umar Iqbal", "background": "当前的研究集中在如何从单张图像中重建可动画化的3D人体avatar，这需要解决多视角生成、三维高斯体提升以及UV空间映射等关键技术问题。", "innovation": "提出了DLA（Dream, Lift, Animate）框架，通过视频扩散模型生成多视图，3D高斯体提升，以及基于姿势感知的UV空间映射，能够将图像转化为可动画化的3D高斯体，同时保持视觉细节的一致性和精确性。", "conclusion": "DLA方法在ActorsHQ和4D-Dress数据集上的感知质量和光度精度都超过了现有最先进的方法，实现了实时渲染和直观编辑，无需后期处理。通过结合生成模型的特长和姿势感知的UV空间高斯映射，DLA填补了无序3D表示与高品质动画准备avatar之间的鸿沟。"}
{"llm_update_time": "20250723", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.16130", "html_url": "https://arxiv.org/abs/2507.16130", "title": "残疾跨文化：西方和印度LLM中基于人类中心的能障歧视审计", "title_en": "Disability Across Cultures: A Human-Centered Audit of Ableism in Western and Indic LLMs", "authors": "Mahika Phutane,Aditya Vashistha", "background": "残疾人（PwD）在印度等非西方地区遭受着不成比例的歧视和仇恨，在线环境中尤为严重。现有的大型语言模型（LLMs）日益用于识别和减轻在线仇恨，但大部分关于在线能障歧视的研究主要关注西方受众和西方AI模型。这些模型是否适合识别非西方地区，如印度的能障伤害？局部地区和印地语模型的表现如何？为了解决这些问题，研究者翻译了一个公开的能障歧视语音数据集为印地语，并对比了来自美国和印度的八种LLM表现差异。同时，研究还征集了175名来自美国和印度的残疾人士进行相同的任务，揭示了不同群体间的显著差异。", "innovation": "一是翻译了公开的能障歧视数据集为印地语，以评估不同背景的大型语言模型对能障歧视的识别能力；二是通过与残疾人士的直接比较，展示了在不同的语言和文化环境下，不同背景的大型语言模型对能障歧视的理解和反应差异显著。", "conclusion": "研究结果表明，西方模型普遍高估了能障歧视的程度，而印度模型则低估了这种现象。更令人担忧的是，所有模型在这种情况下表现出了更高的宽容度，尤其是在印地语中表达时。相比之下，印度残疾人通过意图、关系和韧性等方式解读伤害，强调了教育和改变凶手行为的愿望。这项研究为全球包容性针对能障歧视的标准奠定了基础，并强调必须在AI系统的设计和评估中重视地方残疾人的经验。"}
{"llm_update_time": "20250723", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.16002", "html_url": "https://arxiv.org/abs/2507.16002", "title": "增强低语境下 Hindi 信息提取中的命名实体识别：基于变换器模型的检索增强对比研究", "title_en": "Enhancing Hindi NER in Low Context: A Comparative study of Transformer-based models with vs. without Retrieval Augmentation", "authors": "Sumit Singh,Rohit Mishra,Uma Shanker Tiwary", "background": "在自然语言处理领域，命名实体识别（NER）是一项关键任务，涉及在文本中识别和分类命名实体。这项研究旨在通过使用特定于Hindi的预训练编码器（MuRIL和XLM-R）及生成模型（Llama-2-7B-chat-hf、Llama-2-70B-chat-hf、Llama-3-70B-Instruct和GPT3.5-turbo），并利用来自Wikipedia的外部相关上下文来增强Hindi的NER。", "innovation": "研究利用检索增强（RA）引入了特定于Hindi的预训练编码器和生成模型，并展示了在实践中实现的改进。研究通过对比细调和未细调的模型，以及分别采用和不采用RA的模型，探索了不同方法在低语境数据中的表现。", "conclusion": "研究发现，无论是fine-tuned模型还是生成模型，在采用了检索增强之后，其性能都有显著提高，特别是在低语境数据中。这为如何最有效地利用数据增强方法和预训练模型来提升NER性能提供了重要的见解，尤其对于资源有限的语言如Hindi而言更为重要。"}
{"llm_update_time": "20250723", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.16151", "html_url": "https://arxiv.org/abs/2507.16151", "title": "SPACT18: 携带互补RGB和热力图的尖峰人类行为识别基准数据集", "title_en": "SPACT18: Spiking Human Action Recognition Benchmark Dataset with Complementary RGB and Thermal Modalities", "authors": "Yasser Ashraf,Ahmed Sharshar,Velibor Bojkovic,Bin Gu", "background": "尖峰摄像机和仿生视觉传感器通过在每个像素处累积光强度来异步发射尖峰，提供超高的能效和极佳的时间分辨率。与记录光照强度变化以捕捉运动的事件摄像机不同，尖峰摄像机提供了更精细的时空分辨率和对连续变化的更精确表示。为了评估尖峰神经网络（SNN）的性能并促进相关领域的研究，本文介绍了一个使用尖峰摄像机录制的首个视频动作识别（VAR）数据集，同时伴有同步的RGB和热力图模态，从而为Spiking Neural Networks的综合基准测试提供了条件。", "innovation": "本文首次提出使用尖峰摄像机录制的动作识别数据集，并集成了RGB和热力图模态，分别表征了尖峰数据的内在稀疏性和时间精确性，构建了一个独特平台以探索多模态视频理解，并为直接比较尖峰、热力图和RGB模态提供了有价值的数据资源。这一工作旨在推进高效、超低功耗视频理解在动作识别任务中的研究，特别是基于尖峰数据的任务。", "conclusion": "本文贡献了一个全新的数据集，这将推动基于尖峰数据的能量高效、超低功耗视频理解研究，特别是针对动作识别任务。"}
{"llm_update_time": "20250723", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.16136", "html_url": "https://arxiv.org/abs/2507.16136", "title": "SDBench：全面的语音识别基准套件", "title_en": "SDBench: A Comprehensive Benchmark Suite for Speaker Diarization", "authors": "Eduardo Pacheco,Atila Orhon,Berkin Durmus,Blaise Munyampirwa,Andrey Leonov", "background": "目前最先进的语音识别系统在不同数据集上的错误率表现出较大的波动性，这些数据集涵盖了多种应用场景和领域。因此，跨系统进行比较时，需要严格应用最佳实践，如数据集拆分和度量标准定义，以确保公平的比较。然而，在这种情况下，为了实现精准和细粒度的分析，缺乏一个统一的基准套件。", "innovation": "我们提出了SDBench（Speaker Diarization Benchmark），这是一个开源基准套件，集成了13个不同的数据集，并内置了工具，用于一致和细粒度分析各种设备内置和服务器端系统中的语音识别性能。SDBench使评估可重复进行，并且允许随着时间的推移轻松集成新的系统。通过SDBench，我们构建了SpeakerKit，这是一种专注于推理效率的系统，基于Pyannote v3。使用SDBench进行快速消融研究，结果表明SpeakerKit比Pyannote v3快9.6倍，同时保持相当的错误率。我们还基准测试了包括Deepgram、AWS Transcribe和Pyannote AI API在内的6个最先进的系统，揭示了准确性和速度之间的关键权衡。", "conclusion": "SDBench使语音识别系统的评估和新系统的集成变得更加容易。通过SDBench的使用，我们展示了基于Pyannote v3构建的SpeakerKit比原始系统快9.6倍，同时保持相似的错误率。"}
{"llm_update_time": "20250723", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.16203", "html_url": "https://arxiv.org/abs/2507.16203", "title": "SVAgent：用于硬件安全验证断言的人工智能代理", "title_en": "SVAgent: AI Agent for Hardware Security Verification Assertion", "authors": "Rui Guo,Avinash Ayalasomayajula,Henian Li,Jingbo Zhou,Sujan Kumar Saha,Farimah Farahmandi", "background": "系统Verilog断言(SVA)是检测电路设计漏洞的一种流行方法。然而，随着集成电路设计的全球化和安全要求的不断升级，SVA开发模式暴露出了重大缺陷，包括开发效率低下以及难以应对现代复杂集成电路中不断增加的安全漏洞问题", "innovation": "本文提出了一种名为SVAgent的创新SVA自动生成框架。SVAgent引入了需求分解机制，将原始复杂需求转换为逐步可解的结构化问题解决链。实验表明，SVAgent有效抑制了幻觉和随机回答的影响，其关键评估指标如SVA的准确性和一致性显著优于现有框架", "conclusion": "更重要的是，我们成功将SVAgent集成到最主流的集成电路漏洞评估框架中，并在实际工程设计环境中验证了其实用性和可靠性"}
{"llm_update_time": "20250723", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.16164", "html_url": "https://arxiv.org/abs/2507.16164", "title": "攻击可解释的自然语言处理系统", "title_en": "Attacking interpretable NLP systems", "authors": "Eldor Abdukhamidov,Tamer Abuhmed,Joanna C. S. Santos,Mohammed Abuhamad", "background": "研究已表明，机器学习系统在理论和实践中容易受到对抗样本的攻击。尽管之前的攻击主要针对利用人机感知差异的视觉模型，但基于文本的模型也受到了这些攻击的影响。然而，这些攻击通常未能保持文本的语义意义和相似性。以前的研究主要集中在视觉模型上，但本文关注的是基于文本的模型在可解释自然语言处理系统的对抗攻击。", "innovation": "本文提出了一种名为AdvChar的新攻击方法，这是一种针对可解释自然语言处理系统的黑盒攻击。与之前的攻击不同，AdvChar旨在误导分类器同时保持解释与良性输入的相似性。AdvChar通过对文本输入进行较少注意的修改，迫使深度学习分类器产生错误的预测，同时保留原始解释。这种方法使用一种基于解释的关键性打分方法来确定最关键的 Token，当这些 Token 被改变时，会使得分类器对输入产生误分类。通过简单的字符级修改，减少原始文本和新文本之间的差异，同时生成与良性解释相似的对抗解释。", "conclusion": "我们通过在七种 NLP 模型和三种解释模型上使用基准数据集对 AdvChar 进行彻底评估，并表明它通过在输入样本上平均修改仅两个字符，可以显著降低当前深度学习模型的预测准确性。"}
{"llm_update_time": "20250723", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.16206", "html_url": "https://arxiv.org/abs/2507.16206", "title": "METER: 多模态基于证据的思考与可解释推理——算法和基准", "title_en": "METER: Multi-modal Evidence-based Thinking and Explainable Reasoning -- Algorithm and Benchmark", "authors": "Xu Yang,Qi Zhang,Shuming Jiang,Yaowen Xu,Zhaofan Zou,Hao Sun,Xuelong Li", "background": "随着生成式AI的快速发展，合成内容在图像、视频和音频方面的逼真程度越来越高，这增加了信息错误的风险。现有检测方法大多侧重于二元分类，缺乏对伪造的详细和可解释的解释，限制了它们在关键安全场景中的应用。此外，现有方法通常单独处理每种模态，没有统一的跨模态伪造检测与解释基准。", "innovation": "为应对这些挑战，我们提出了METER，这是一个统一的多模态基准，旨在进行可解释伪造鉴定，覆盖图像、视频、音频和视听内容。METER 包含四个跟踪，不仅需要真伪分类，还要求提供基于证据链的解释，包括时空定位、文本理由和伪造类型追踪。与先前的基准相比，METER 提供了更广泛模态覆盖和更丰富的解释性指标，如空间/时间 IoU、多类追踪和证据一致性。此外，我们还提出了一个与人类一致的三阶段推理训练策略，结合了 SFT、DPO 和一种新的 GRPO 阶段，该阶段将人类一致性评估与推理结合在一起。", "conclusion": "我们希望 METER 能够为生成媒体时代的一般可解释伪造检测提供一个标准化基础。"}
{"llm_update_time": "20250723", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.16124", "html_url": "https://arxiv.org/abs/2507.16124", "title": "LLM隐私识别基准测试用于社会机器人决策", "title_en": "Benchmarking LLM Privacy Recognition for Social Robot Decision Making", "authors": "Dakota Sullivan,Shirley Zhang,Jennica Li,Heather Kirkorian,Bilge Mutlu,Kassem Fawaz", "background": "社会机器人作为物理环境中的人类交互代理，使用口头和非口头提示进行交互。过去的社交机器人多依赖于规则基础系统或概率模型进行用户交互，但大型语言模型（LLMs）的迅速发展为提升人机交互质量提供了新的机会。然而，为了实现这一潜力，机器人需要收集如音频、精细图像、视频和位置等数据，处理这些数据时可能会涉及敏感个人信息。因此，如何在一定程度上实现功能的同时保护用户隐私变得尤为重要。本研究通过情境设计，从情境完整性（CI）的视角探索LLM在家庭社交机器人隐私保护方面的能力。", "innovation": "本研究创新之处在于通过设计一系列基于情境完整性（CI）的隐私相关情景，评估当前LLM在家庭社交机器人隐私保护中处理敏感信息的能力。不同于以往的研究，本研究不仅调查了用户对于家庭社交机器人行为的隐私偏好，还对比了人类决策与LLM决策的一致性，并进一步通过实施和比较不同的提示策略，探讨了LLM作为潜在隐私控制器的可能性。", "conclusion": "本研究揭示了当前LLM在家庭社交机器人隐私保护方面未能充分考虑用户的隐私偏好，并提出了AI隐私意识在人机交互中的潜在价值。研究结果表明，尽管LLM在安全和隐私管理方面具有潜力，但在实际应用中仍面临一些挑战。因此，未来的工作应该致力于改进LLM的隐私保护机制，提升人机交互中的隐私保护水平。"}
{"llm_update_time": "20250723", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.16077", "html_url": "https://arxiv.org/abs/2507.16077", "title": "基于大规模测试床的AI驱动编排：估算全国范围服务指标", "title_en": "AI-driven Orchestration at Scale: Estimating Service Metrics on National-Wide Testbeds", "authors": "Rodrigo Moreira,Rafael Pasquini,Joberto S. B. Martins,Tereza C. Carvalho,Flávio de Oliveira Silva", "background": "网络切片（NS）的实现需要具备AI特性的编排架构，以高效且智能地处理异构用户需求。随着NS向更用户中心的数字化转型发展，侧重于能够自我管理的集成和隔离连通性架构，面临在利用ML编排的生产环境中的结果验证挑战。因此，该研究提出了一种使用深度神经网络（DNN）和基本ML算法的大规模验证方法，来预测网络切片的延迟服务指标，并在实际大规模生产测试床中进行了评估。", "innovation": "该研究的核心创新点在于提出了一种大规模验证方法，利用网络切片预测模型结合DNN和基本ML算法，评估不同DNNs和ML算法在真实大规模生产测试床中的性能。这为AI驱动的网络切片编排架构的开发提供了一种无缝的生产验证方法，取代了完全受控的模拟或实验室设置。", "conclusion": "研究表明，基于AI的预测模型能够提升网络切片编排架构的性能，并提供了一种无缝的、面向生产的验证方法，作为替代全面受控的模拟或实验室设置的选择。"}
{"llm_update_time": "20250723", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.16178", "html_url": "https://arxiv.org/abs/2507.16178", "title": "通过动态双层优化实现大规模语言模型的数据选择与利用", "title_en": "LLM Data Selection and Utilization via Dynamic Bi-level Optimization", "authors": "Yang Yu,Kai Han,Hang Zhou,Yehui Tang,Kaiqi Huang,Yunhe Wang,Dacheng Tao", "background": "在开发强大的大型语言模型（LLMs）时，大规模的训练数据至关重要。然而，如何高效地选择高质量的训练数据已成为提升训练效率和降低计算成本的关键策略。目前的数据选择方法主要依赖于静态、与训练无关的标准，未能考虑到动态模型训练和数据之间的交互作用。因此，寻找一种能够动态调整数据权重的方法对于提高模型性能至关重要。这篇文章提出了一种新的数据权重模型（DWM），旨在调整每个批次中所选数据的权重，实现LLM训练过程中动态化数据利用。", "innovation": "本文提出了数据权重模型（DWM），这是一种通过动态调整每个批次中数据权重的方式来提高模型训练效率的方法。具体而言，通过实现一个双层优化框架来更新权重模型，使模型能够更好地捕捉到动态训练中的数据偏好。实验结果表明DWM能提升随机数据选择训练出的模型性能，并且学习到的权重模型可以移植到其他数据选择方法和不同规模的模型中。此外，还进一步分析了模型在整个训练过程中数据偏好如何演变，为理解模型训练中的数据偏好提供了新的见解。", "conclusion": "本文通过提出数据权重模型DWM，改进了传统的固定权重选择法。通过双层优化框架，提高了模型的数据利用效率，增强了模型性能，并展示了该方法的可移植性和广泛适用性。未来的工作可以进一步研究模型在不同训练阶段的表现以及改进数据权重调整方法。"}
{"llm_update_time": "20250723", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.16043", "html_url": "https://arxiv.org/abs/2507.16043", "title": "超越率编码：替代梯度使脉冲神经网络中的脉冲时间学习成为可能", "title_en": "Beyond Rate Coding: Surrogate Gradients Enable Spike Timing Learning in Spiking Neural Networks", "authors": "Ziqiao Yu,Pengfei Sun,Dan F. M. Goodman", "background": "研究脉冲神经网络(SNNs)如何利用精确的脉冲时间而非仅仅电信号频率进行学习。具体来说，探讨使用替代梯度下降(Surrogate GD)训练的SNNs，带有或不带有延时学习，能否从精确的脉冲时间中学习，超越单纯基于频率的学习。", "innovation": "引入了替代梯度，这使得SNNs能够通过精确的脉冲时间进行学习，而不是仅仅依赖于电信号的频率。这项研究进一步设计了合成任务和复杂的数据集，证明了SNNs在脉冲计数信息被消除后仅依赖于脉冲时间依然能够表现出比基于计数的模型更好的性能。", "conclusion": "通过替代梯度的训练，SNNs能够对脉冲时间的变化表现出较好的适应能力，尤其是在脉冲被倒序排列时，其性能的下降更为显著。这表明使用替代梯度的SNNs在行为上更接近于人类。这些研究成果为进一步研究时间编码提供了改进建议和数据集支持。"}
{"llm_update_time": "20250723", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.16154", "html_url": "https://arxiv.org/abs/2507.16154", "title": "LSSGen：利用流和扩散中的潜在空间缩放实现高效文本到图像生成", "title_en": "LSSGen: Leveraging Latent Space Scaling in Flow and Diffusion for Efficient Text to Image Generation", "authors": "Jyun-Ze Tang,Chih-Fan Hsu,Jeng-Lin Li,Ming-Ching Chang,Wei-Chao Chen", "background": "流模型和扩散模型已经在文本到图像生成中取得了显著成果，通过迭代去噪过程生成逼真图像。一种常用策略是预先在较低分辨率下进行去噪以加速合成过程。然而，传统的将图像像素空间下采样和上采样方法容易引入伪影和失真，尤其是在将上采样的图像重新编码到潜在空间时，这会严重影响最终图像质量。", "innovation": "本文提出了一种名为LSSGen（Latent Space Scaling Generation）的新框架，能够在潜在空间中直接进行分辨率缩放，而不会修改Transformer或U-Net架构。LSSGen提高了生成效率和视觉质量，支持灵活的多分辨率生成，并且在综合评估文本图像对齐和感知质量方面显著优于传统缩放方法。尤其是在保持相似生成速度的情况下，LSSGen在TOPIQ评分上有高达246%的提升。", "conclusion": "LSSGen框架通过直接在潜在空间中进行分辨率缩放，提高了文本到图像生成的效率和质量，保持了灵活的多分辨率生成能力，并且在实验中展现了优异的表现。"}
{"llm_update_time": "20250723", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.16213", "html_url": "https://arxiv.org/abs/2507.16213", "title": "提升视觉大型语言模型在多粒度多功能感知中的应用", "title_en": "Advancing Visual Large Language Model for Multi-granular Versatile Perception", "authors": "Wentao Xiang,Haoxian Tan,Cong Wei,Yujie Zhong,Dengjie Li,Yujiu Yang", "background": "感知是计算机视觉领域的重要任务，可以按照预测类型和指令类型分为四个不同的类别。现有的研究往往只关注其中一种组合，这限制了其在不同场景下的应用和灵活性。", "innovation": "提出了一种名为MVP-LM的多粒度多功能感知框架，融合了视觉大型语言模型，具备词基和句基感知任务、框预测和掩码预测的单一架构整合能力。该框架采用基于CoT启发的多粒度解码器和数据集统一策略，支持广泛的监督微调任务。同时，引入了查询增强策略以利用VLLMs的解码和生成能力。", "conclusion": "在多个基准测试上的广泛实验表明，该框架在词基和句基感知任务中的有效性得到了验证。源代码将在此 https URL 公开。"}
{"llm_update_time": "20250723", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.16208", "html_url": "https://arxiv.org/abs/2507.16208", "title": "LOCOFY大型设计模型 -- 设计转代码解决方案", "title_en": "LOCOFY Large Design Models -- Design to code conversion solution", "authors": "Sohaib Muhammad,Ashwati Vipin,Karan Shetti,Honey Mittal", "background": "尽管大型语言模型（LLMs）及多模态大型语言模型取得了迅速进展，设计到代码（Design-to-code）空间中的可解释性、可扩展性、资源需求和重复性仍然存在许多挑战。本文研究正是基于此背景，探讨如何利用特定数据和模型架构，解决该领域的问题。", "innovation": "本文提出了一种新的大型设计模型（LDMs）框架，专门针对设计和网页进行训练，以实现设计到代码的无缝转换。为了实现这一目标，作者开发了一个包括设计优化器、标签和特征检测、以及自动组件提取的训练和推理管道。这些技术提高了设计到代码转化的精准性、可解释性和可靠性。", "conclusion": "采用LOCOFY LDMs系统能够实现设计到代码的高效、可靠和可重复性的转换，相较于大型语言模型（LLMs）在节点定位、响应性和可重复性等方面表现出更优越的性能。同时，研究指出自定义训练的标签和特征检测模型在各类设计样本中标识UI元素的精度和一致性较高。因此，LOCOFY LDMs成为理解设计并生成高效可靠代码的可信方案。"}
{"llm_update_time": "20250723", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.16251", "html_url": "https://arxiv.org/abs/2507.16251", "title": "HoliTracer: Holistic Vectorization of Geographic Objects from Large-Size Remote Sensing Imagery", "title_en": "HoliTracer: Holistic Vectorization of Geographic Objects from Large-Size Remote Sensing Imagery", "authors": "Yu Wang,Bo Dang,Wanchun Li,Wei Chen,Yansheng Li", "background": "随着遥感影像（RSI）分辨率的不断提高，大型RSI已成为地理对象高精度矢量化的重要数据源。现有的方法通常受限于只能处理小图像片段，这往往会损失上下文信息并产出碎片化的矢量输出。鉴于此，本文提出了HoliTracer框架，该框架旨在全面从大型RSI中提取矢量化地理对象，增强其分割功能，并通过融合Context Attention Net (CAN)和Mask Contour Reformer (MCR)及Polygon Sequence Tracer (PST)的处理，实现了全局矢量化处理。", "innovation": "文中介绍的HoliTracer是首款专门设计用于从大型RSI中整体提取矢量化地理对象的框架。其通过引入Context Attention Net (CAN)，采用局部到全局的注意力机制来捕获上下文依赖性。同时，通过一个稳健的管道利用Mask Contour Reformer (MCR)重建多边形和Polygon Sequence Tracer (PST)追踪顶点来实现全局矢量化处理。", "conclusion": "在包括建筑物、水体和道路的大型RSI数据集上进行的广泛实验表明，HoliTracer在性能上超过了现有最先进的方法。相关代码和数据可在给定的链接中获取。"}
{"llm_update_time": "20250723", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.16252", "html_url": "https://arxiv.org/abs/2507.16252", "title": "使用基于LLM的辅导师优化对话级结果的高效RL", "title_en": "Efficient RL for optimizing conversation level outcomes with an LLM-based tutor", "authors": "Hyunji Nam,Omer Gottesman,Amy Zhang,Dean Foster,Emma Brunskill,Lyle Ungar", "background": "现有的基于强化学习与人类反馈（RLHF）框架的大语言模型（LLMs）通常根据即时回合级的人类偏好优化响应。然而，这种方法在多回合对话场景中效果不佳，例如在线数学辅导。研究提出了一种方法，通过使用学生低维潜在状态表示对话历史来增强基于LLM的辅导师，并基于潜在状态优化长期策略以确定高层次行动，从而更好地使辅导师的行为与引领学生自主解决目标数学问题这一长期目标保持一致。这项模型比之前的末端训练辅导策略需要更少的计算资源。实验结果表明，这些改进在LLM模拟的辅导任务中提高了长期效果。", "innovation": "提出了一种新颖的方法，通过使用学生低维潜在状态表示对话历史来优化长时间策略，以在多回合对话中更好地满足长期目标。这种模型相比之前的方法在计算资源使用上更加高效，并且能够在模拟的辅导任务中展示出更好的长期结果。", "conclusion": "通过使用低维度的潜在状态表示对话历史和优化长期策略的方法，提高了基于LLM的辅导师在多回合对话中的效果，并改善了长期目标的实现，相比全末端策略训练更加节省计算资源。实验结果显示此方法优于直接提示的LLM模拟辅导任务。"}
{"llm_update_time": "20250723", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.16217", "html_url": "https://arxiv.org/abs/2507.16217", "title": "追求计算最优的多次示例内上下文学习", "title_en": "Towards Compute-Optimal Many-Shot In-Context Learning", "authors": "Shahriar Golchin,Yanfei Chen,Rujun Han,Manan Gandhi,Tianli Yu,Swaroop Mishra,Mihai Surdeanu,Rishabh Agarwal,Chen-Yu Lee,Tomas Pfister", "background": "长上下文大型语言模型（LLMs）能够处理包含高达数百万令牌的输入内容。在内上下文学习（ICL）范围内，这意味着在输入提示中使用数百/数千个示例，从而实现多次示例内上下文学习。在实际应用中，由于（1）推理成本高，（2）缓存和重用计算的益处，以及（3）相比其他策略，这种策略在扩展时提供的性能相当，在许多示例的内上下文学习设置中，通常会随机选择一个固定的示例集。我们也进行了关于Gemini Pro和Flash在多个数据集上的实验，结果显示我们的策略能够持续优于随机选择，并在支持缓存和尽量减少推理成本方面比其他最有效的选择方法更优。", "innovation": "我们提出了两种简单的方法，用于改善多次示例内上下文学习（many-shot ICL）中的示例选择，同时具有最少的计算开销。第一种方法将根据测试样本相似度选取少量的示例与一个大型的缓存中的随机示例结合。第二种方法在此基础上，通过k-means聚类选取测试样本表示的基点来代替随机示例。", "conclusion": "我们的实验表明，我们的策略在多个数据集上优于随机选择，并且在支持缓存和大幅减少推理成本方面比其他最有效的选择方法更好。我们还展示了基于不同标准选择不同比例的示例可以平衡性能和推理成本。"}
{"llm_update_time": "20250723", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.16214", "html_url": "https://arxiv.org/abs/2507.16214", "title": "双重噪声自适应调整的相对姿态估计框架以实现安全接近机动", "title_en": "Adaptive Relative Pose Estimation Framework with Dual Noise Tuning for Safe Approaching Maneuvers", "authors": "Batu Candan,Simone Servadio", "background": "精确且稳健的相对姿态估计对于实现ESA的ENVISAT等翻滚废弃卫星的目标的主动碎片清除（ADR）任务至关重要。为解决这一挑战，本文提出了一种结合先进计算机视觉技术和适应性非线性滤波的完整管道。", "innovation": "本文的主要创新点在于集成系统架构以及UKF框架内的双重自适应策略：测量噪声协方差的动态调整补偿了神经网络测量不确定性，而过程噪声协方差的自适应调整利用测量残差分析来应对未建模动态或在线机动。同时，通过高保真仿真评估了提出的自适应集成系统的性能。", "conclusion": "本文提出的综合方法提高了稳健的机载相对导航能力，显著提高了ADR任务中安全接近操作所需的必要功能。"}
{"llm_update_time": "20250723", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.16267", "html_url": "https://arxiv.org/abs/2507.16267", "title": "SFNet: 一个用于高效阿尔茨海默病诊断的时空域深度学习网络", "title_en": "SFNet: A Spatio-Frequency Domain Deep Learning Network for Efficient Alzheimer's Disease Diagnosis", "authors": "Xinyue Yang,Meiliang Liu,Yunfang Xu,Xiaoxiao Yang,Zhengye Si,Zijin Li,Zhiwen Zhao", "background": "阿尔茨海默病(AD)是一种渐进性的神经退行性疾病，主要影响老年人群，目前尚无治疗方法。磁共振成像(MRI)作为一种无创成像技术，对于AD的早期诊断至关重要。MRI固有地包含空间和频率信息，原始信号在频域中被采集，通过傅里叶变换重建为空间图像。然而，现有的AD诊断模型大多仅从单一领域提取特征，限制了其对疾病复杂神经影像特征的全面捕捉能力。尽管一些研究结合了空间和频率信息，但这些研究主要局限于2D MRI，3D MRI的双重领域分析潜力尚未被充分探索。因此，迫切需要一种能够同时利用空间和频率信息的模型来提升基于3D MRI的AD诊断效率和准确性。", "innovation": "本文提出了Spatio-Frequency Network (SFNet)，这是首个同时利用空间和频率领域信息进行3D MRI AD诊断的端到端深度学习框架。SFNet通过增强密集卷积网络提取局部空间特征，并通过全局频率模块捕捉全局频率域表征。此外，还提出了一种新颖的多尺度注意力模块以进一步细化空间特征提取。实验结果表明，SFNet在准确分类认知正常(CN)和AD方面优于现有基准，准确率为95.1%，同时降低了计算开销。", "conclusion": "SFNet在3D MRI AD诊断中的表现显著优于现有的方法，通过结合空间和频率信息，提高了诊断准确性和效率，为AD的早期诊断提供了新的技术手段。"}
{"llm_update_time": "20250723", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.16241", "html_url": "https://arxiv.org/abs/2507.16241", "title": "eX-NIDS：利用大型语言模型实现可解释的网络入侵检测框架", "title_en": "eX-NIDS: A Framework for Explainable Network Intrusion Detection Leveraging Large Language Models", "authors": "Paul R. B. Houssel,Siamak Layeghy,Priyanka Singh,Marius Portmann", "background": "本文介绍了eX-NIDS，这是一种通过利用大型语言模型（LLMs）增强流量基础网络入侵检测系统（NIDS）解释性的框架。在该框架中，首先通过称为Prompt Augmenter的模块处理NIDS标记为恶意的流量，该模块从这些流量中提取上下文信息和与网络威胁情报（CTI）相关的知识。然后将这些丰富且具体到上下文的数据与输入提示集成，以供LLM使用，从而生成详细的解释和对流量被NIDS标记为恶意的原因的解释。本文使用Llama 3和GPT-4模型进行量化评估，采用一种针对自然语言解释的新颖评估方法，重点在于其准确性和一致性。", "innovation": "提出了一种新的框架eX-NIDS，通过利用大型语言模型来增强NIDS的解释性。该框架使用Prompt Augmenter模块来处理和解析NIDS标记为恶意的流量，并生成详细的解释和解释生成。与使用基本提示解释器的方法相比，这种增强的提示提高了解释性能超过20%。", "conclusion": "本文展示了使用增强提示生成的解释可以提供准确和一致的解释，作为NIDS中解释恶意流量分类的重要补充工具。这种方法显著提高了性能。"}
{"llm_update_time": "20250723", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.16207", "html_url": "https://arxiv.org/abs/2507.16207", "title": "在放射学中识别文本到图像生成AI的前景、风险与挑战的人本中心方法", "title_en": "A Human-Centered Approach to Identifying Promises, Risks, & Challenges of Text-to-Image Generative AI in Radiology", "authors": "Katelyn Morrison,Arpit Mathur,Aidan Bradshaw,Tom Wartmann,Steven Lundi,Afrooz Zandifar,Weichang Dai,Kayhan Batmanghelich,Motahhare Eslami,Adam Perer", "background": "随着文本到图像生成模型的迅速发展，人工智能研究人员正在开发专门领域的模型，能够从文本提示生成复杂的医学图像。然而，这些技术进步往往忽视了医疗专业人员是否以及如何在实践中受益于和使用文本到图像生成AI（GenAI）。如果没有与相关方合作开发这些模型，我们可能会构建出对于不实用甚至有害的模型。", "innovation": "本文采用人本中心的方法，通过模型提示活动，收集了医学学生、放射学实习生和放射科医生对文本到CT扫描生成AI在医学教育、培训和实践中的作用的看法。这种方法揭示了生成合成医学图像的技术挑战和特定领域风险。", "conclusion": "本文总结了医疗文本到图像生成AI的含义，并讨论了相关的技术和领域风险。"}
{"llm_update_time": "20250723", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.16307", "html_url": "https://arxiv.org/abs/2507.16307", "title": "Perovskite-R1：一种专门用于前驱体添加剂智能发现和实验设计的领域特定大语言模型", "title_en": "Perovskite-R1: A Domain-Specialized LLM for Intelligent Discovery of Precursor Additives and Experimental Design", "authors": "Xin-De Wang,Zhi-Rui Chen,Peng-Jie Guo,Ze-Feng Gao,Cheng Mu,Zhong-Yi Lu", "background": "Perovskite solar cells (PSCs)由于其卓越的光电转换效率和有利的材料特性，已成为下一代光伏技术的领先竞争者。然而，长期稳定性、环境可持续性和可扩展制造方面的挑战仍然阻碍了其商业化进程。在前驱体添加剂工程领域，研究人员面临日益复杂的材料、过程和器件架构相互作用带来的挑战，难以有效地访问、组织和利用该迅速发展的领域的专业知识。为此，本文介绍了一种专门设计的大型语言模型（Perovskite-R1），该模型具备高级推理能力，专为PSC前驱体添加剂的发现和设计服务。", "innovation": "Perovskite-R1通过系统地提取和整理1,232篇高质量科学出版物，并整合一个包含33,269种候选材料的全面数据库，采用自动化问答生成和链式推理，构建了一个专项指令调优数据集。该模型在QwQ-32B模型的基础上进行了微调，能够智能地综合文献洞见，并生成创新且实用的缺陷钝化策略和前驱体添加剂选择方案。实验验证表明，本文提出的方法能有效改善材料稳定性和性能。", "conclusion": "这项研究展示了领域适配大语言模型在加速材料发现中的潜力，并提供了一个智能、数据驱动的循环框架，以促进钙钛矿光伏研究的进步。"}
{"llm_update_time": "20250723", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.16254", "html_url": "https://arxiv.org/abs/2507.16254", "title": "鱼眼对象检测中的边缘案例合成：一种数据为中心的视角", "title_en": "Edge-case Synthesis for Fisheye Object Detection: A Data-centric Perspective", "authors": "Seunghyeon Kim,Kyeongryeol Go", "background": "鱼眼相机引入了显著的失真，这对经过常规数据集训练的对象检测模型构成了独特挑战。这些模型难以应对鱼眼摄像头带来的复杂失真和视觉边界条件。", "innovation": "本文提出了一种基于数据的数据流程，通过系统地提升检测性能并聚焦于模型的盲点识别问题。通过详细错误分析，确定了关键的边缘案例，如混淆类对、边缘失真和代表性不足的背景。作者通过边缘案例合成直接解决了这些问题。利用细调的图像生成模型并通过精心设计的提示引导模型，生成能够复制现实世界失效模式的图像。这些合成图像使用高质量的检测器进行伪标记，并集成到培训中。", "conclusion": "我们的方法在保持一致性能改进的同时，突显了深入理解数据并有选择性地修复其弱点在特殊领域（如鱼眼对象检测）中的重要性。"}
{"llm_update_time": "20250723", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.16247", "html_url": "https://arxiv.org/abs/2507.16247", "title": "PRAC3 (隐私、声誉、责任、同意、认可、补偿): AI数据经济中声优的长尾风险", "title_en": "PRAC3 (Privacy, Reputation, Accountability, Consent, Credit, Compensation): Long Tailed Risks of Voice Actors in AI Data-Economy", "authors": "Tanusree Sharma,Yihao Zhou,Visar Berisha", "background": "早期的大规模音频数据集，如LibriSpeech，是由数百名个人贡献者的声音贡献而成，这些贡献对于语音技术的发展起到了重要作用，包括有声书和语音助手等。然而，十年后，这些贡献却使声优面临了一系列风险。现有的伦理框架主要强调同意、认可和补偿（C3），但并没有充分考虑到与个人声音身份日益脱节的风险，以及由此带来的归属感和控制权的丧失。", "innovation": "本文通过质性访谈20名专业声优，揭示了无约束的合成语音复制对声优造成的广泛威胁。为此，作者提出了一种新的治理框架——PRAC3，即隐私、声誉、责任、同意、认可、补偿，作为C3的扩展框架，旨在更有效地管理和减轻AI数据经济中声优面临的长尾风险。", "conclusion": "本文论证了声音作为生物识别标识和创造性劳动力的重要性，强调了治理模型应恢复创作者权利，确保可追溯性，并严格界定伦理再利用的边界。PRAC3框架能够更好地捕捉隐私风险、声誉损害以及重新定义AI数据生态系统中的责任等关键问题。"}
{"llm_update_time": "20250723", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.16219", "html_url": "https://arxiv.org/abs/2507.16219", "title": "使用贝叶斯深度学习进行热对流起始 Nowcasting 不确定性估计", "title_en": "Bayesian Deep Learning for Convective Initiation Nowcasting Uncertainty Estimation", "authors": "Da Fan,David John Gagne II,Steven J. Greybush,Eugene E. Clothiaux,John S. Schreck,Chaopeng Shen", "background": "本研究评估了五种最近提出的贝叶斯深度学习方法与确定性残差神经网络（ResNet）基线相比，在利用GOES-16卫星红外观测进行0-1小时热对流起始（CI）现在天气预报中的概率和不确定性预报的准确性和不确定性。研究表明，大多数贝叶斯深度学习方法在概率预报方面优于确定性ResNet，特别是初始权重集合+蒙特卡洛（MC）丢弃方法，生成了最技能且校准最好的预报。", "innovation": "研究引入了初始权重集合+MC丢弃方法，这是一种使用不同初始权重训练的确定性ResNet的集合，并在推断时激活MC丢弃。这种方法通过生成多个解决方案更全面地采样假说空间从而提高了技能和校准性。同时，研究还提出了一种新的贝叶斯-MOPED ResNet集成模型，通过限制假设搜索空间来增强预报技能。", "conclusion": "所有贝叶斯方法都展示了良好的校准不确定性，并有效地分离了大错误和小错误的情况。在案例研究中，初始权重集合+MC丢弃方法在无CI发生区域的广域范围内表现比贝叶斯-MOPED集成和确定性ResNet更差，但在晴朗区域却展现了更好的预报技能。"}
{"llm_update_time": "20250723", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.16227", "html_url": "https://arxiv.org/abs/2507.16227", "title": "通过人工智能进行激光直接驱动压缩实验的预测性流体动力学模拟", "title_en": "Predictive Hydrodynamic Simulations for Laser Direct-drive Implosion Experiments via Artificial Intelligence", "authors": "Zixu Wang,Yuhan Wang,Junfei Ma,Fuyuan Wu,Junchi Yan,Xiaohui Yuan,Zhe Zhang,Jie Zhang", "background": "该研究利用人工智能（AI）技术进行激光驱动压缩实验的预测性流体动力学模拟。以双锥点火（DCI）方案为例，通过建立一个基于Transformer的深度学习模型MULTI-Net，根据激光波形和目标半径预测压缩特征。此外，研究提出了一种物理信息解码器（PID），用于高维采样，显著减少了预测误差。", "innovation": "提出了一个基于Transformer的深度学习模型MULTI-Net，用于根据激光波形和目标半径预测压缩特征。此外，研究提出了一种物理信息解码器（PID），在高维采样中显著减少了预测误差。", "conclusion": "该研究展示了通过数据驱动的AI框架增强复杂激光聚变实验模拟的预测能力。实验证明，对于DCI-R10实验，约65%的有效激光吸收系数适合进行一维模拟。比如在第33射次中，平均压缩速度达到195 km/s，撞击等离子体密度达到117 g/cc。"}
{"llm_update_time": "20250723", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.16278", "html_url": "https://arxiv.org/abs/2507.16278", "title": "理解低容量神经网络中的泛化、鲁棒性和可解释性", "title_en": "Understanding Generalization, Robustness, and Interpretability in Low-Capacity Neural Networks", "authors": "Yash Kumar", "background": "尽管现代深度学习通常依赖于大量过参数化模型，但低容量网络中的容量、稀疏性和鲁棒性的基本相互作用仍然是一个重要的研究领域。这项研究通过创建从MNIST数据集中获取的逐步增加视觉难度的二分类任务（例如，0和1与4和9的对比），引入了一个控制框架来研究这些特性。实验结果揭示了三个关键发现，进一步阐明了低容量网络中的这些重要属性间的关系。", "innovation": "本研究通过创建具有增加视觉难度的MNIST数据集上的二分类任务，提出了一种控制框架来探究容量、稀疏性和鲁棒性之间的关系。实验结果显示：1. 成功泛化的最小模型容量与任务复杂性直接相关；2. 训练后的网络对极端幅度的剪枝（高达95%稀疏性）具有鲁棒性；3. 过参数化在对抗输入篡改中的鲁棒性方面提供了显著优势；4. 可解释性分析进一步证实了所识别出的稀疏子网络保留了密集模型的核心推理过程。", "conclusion": "本研究通过实证方法清晰地展示了简单神经网络中基本权衡，提供了关于低容量神经网络的泛化、鲁棒性和可解释性的关键见解。"}
{"llm_update_time": "20250723", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.16382", "html_url": "https://arxiv.org/abs/2507.16382", "title": "LLM 引导的强化学习在碰撞规避形似控制中的应用", "title_en": "Application of LLM Guided Reinforcement Learning in Formation Control with Collision Avoidance", "authors": "Chenhao Yao,Zike Yuan,Xiaoxu Liu,Chi Zhu", "background": "多智能体系统（MAS）通过个体智能体的协作来完成复杂目标。多智能体强化学习（MARL）是最有效的算法之一，但在实现形似控制与碰撞规避（FCCA）时，设计有效的奖励函数以促进政策网络的快速收敛仍是一个挑战。本文探讨了如何通过给大型语言模型（LLMs）分配任务优先级和每个智能体可观察的信息，来生成可根据评估结果动态调整的奖励函数，从而提高形似控制与障碍规避的效率，减少达到高性能所需迭代次数。", "innovation": "引入了一种新的框架，通过分配大型语言模型的任务优先级和每个智能体可观察的信息，生成可根据评估结果动态调整的奖励函数，而不是使用奖励本身。这种机制允许多智能体系统在动态环境中同时实现形似控制和障碍规避，提高效率并减少迭代次数。", "conclusion": "实验研究证明，所提出的方法在模拟和实际环境下的实用性和有效性。"}
{"llm_update_time": "20250723", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.16329", "html_url": "https://arxiv.org/abs/2507.16329", "title": "DREAM：通过概率模型实现的文本到图像生成系统可扩展性红队挑战", "title_en": "DREAM: Scalable Red Teaming for Text-to-Image Generative Systems via Distribution Modeling", "authors": "Boheng Li,Junjie Wang,Yiming Li,Zhiyang Hu,Leyi Qi,Jianshuo Dong,Run Wang,Han Qiu,Zhan Qin,Tianwei Zhang", "background": "尽管在安全对齐和外部过滤方面已经进行了集成，文本到图像（T2I）生成模型仍然容易生成有害内容，如色情或暴力图像。这引起了对意外暴露和潜在滥用的严重担忧。红队测试作为一种方法，旨在主动识别出能够引发行生成系统（包括核心生成模型及其潜在的安全过滤器和其他处理组件）产生不安全输出的各种提示，越来越被认可为评估并改进安全性能和措施前的重要手段。然而，现有自动化红队方法通常将提示发现视为独立的提示级别优化任务，这限制了它们的扩展性、多样性和整体有效性。", "innovation": "本文提出了一个名为DREAM的可扩展红队框架，该框架能够自动从给定的T2I系统中发现多种问题提示。DREAM直接建模目标系统的不安全提示的概率分布，从而可以在优化效果的同时显式地考虑到多样性，并允许在训练后进行高效的大规模抽样。通过对无直接访问代表训练样本的情况下，从能量基础模型中汲取灵感，对该目标进行优化问题进行重新定义，为候选解决方案提供了简单且易于处理的目标优化。此外，提出了GC-SPSA高效优化算法，该算法能够通过T2I长且可能不可微的管道提供稳定梯度估计。实验证明，DREAM在针对各种T2I模型和安全过滤器的提示成功率和多样性评估方面都超越了9个最新的基准方法。", "conclusion": "DREAM通过直接建模目标系统的不安全提示的概率分布，实现了从T2I系统中自动发现多样化问题提示的目标，从而在效果和多样性之间进行了显式优化，并在大规模抽样后具有高效性。实验证明该框架在相对于广泛使用的T2I模型和安全过滤器的多个基准中表现优异，进一步验证了其在提升T2I系统安全性的有效性。"}
{"llm_update_time": "20250723", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.16302", "html_url": "https://arxiv.org/abs/2507.16302", "title": "针对下游微调对扩散模型稳健的安全驱动性遗忘方法", "title_en": "Towards Resilient Safety-driven Unlearning for Diffusion Models against Downstream Fine-tuning", "authors": "Boheng Li,Renjie Gu,Junjie Wang,Leyi Qi,Yiming Li,Run Wang,Zhan Qin,Tianwei Zhang", "background": "文本到图像（T2I）扩散模型在图像生成质量上取得了显著进展，并逐渐被用于个性化应用。然而，这些模型往往从有毒预训练数据中继承了不安全的行为，引发了越来越严重的安全问题。虽然最近的安全驱动性遗忘方法在抑制模型毒性方面取得了有希望的进展，但这些方法被发现对下游微调较为脆弱，揭示出最先进的方法在仅微调在完全无害的数据集上时，也未能保留其有效性。", "innovation": "本文提出了一种名为ResAlign的安全驱动性遗忘框架，增强了对下游微调的抵御能力。通过采用Moreau Envelope为基础的重新表述，将下游微调建模为一个隐式优化问题，ResAlign能够有效估计梯度以最小化有害行为的恢复。此外，还提出了一种元学习策略来模拟多样的微调场景，以提高泛化能力。", "conclusion": "广泛的实验表明，ResAlign在多种数据集、微调方法和配置下，能够一致地在下游微调后保留安全性，同时保持良好的生成能力。"}
{"llm_update_time": "20250723", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.16347", "html_url": "https://arxiv.org/abs/2507.16347", "title": "利用个性化PageRank和高阶拓扑结构减轻图神经网络中的异质性", "title_en": "Leveraging Personalized PageRank and Higher-Order Topological Structures for Heterophily Mitigation in Graph Neural Networks", "authors": "Yumeng Wang,Zengyi Wo,Wenjun Wang,Xingcheng Fu,Minglai Shao", "background": "图神经网络（GNNs）在节点分类任务中表现出色，但通常假设同质性，即连接的节点具有相似的标签。在许多现实世界的异质图中，这一假设并不成立。现有的异质图模型主要依赖于成对关系，忽视了来自更高阶结构的多尺度信息，导致在有噪声干扰的情况下性能不佳。", "innovation": "本文提出了一种新颖的HPGNN模型，通过引入高效高阶的个性化PageRank（PPR）逼近法来捕捉远距离和多尺度的节点交互。该方法减少了计算复杂度并减轻了周围信息的噪声。通过将高阶结构信息嵌入卷积网络，HPGNN能够有效建模不同图维度的关键交互。在基准数据集上进行的广泛实验表明，HPGNN的性能优于七个最新方法中的五个，在异质图中的下游任务中表现出色，同时在同质图中的性能也具有竞争力。", "conclusion": "HPGNN能够平衡多尺度信息和对噪声的鲁棒性，成为解决现实世界图学习挑战的灵活方案。"}
{"llm_update_time": "20250723", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.16274", "html_url": "https://arxiv.org/abs/2507.16274", "title": "通过时空规划减少GPU内存碎片化以实现高效大规模模型训练", "title_en": "Reducing GPU Memory Fragmentation via Spatio-Temporal Planning for Efficient Large-Scale Model Training", "authors": "Zixiao Huang,Junhao Hu,Hao Lin,Chunyang Zhu,Yueran Tang,Quanlu Zhang,Zhen Guo,Zhenhua Li,Shengen Yan,Zhenhua Zhu,Guohao Dai,Yu Wang", "background": "大型语言模型（LLMs）的快速增长使GPU内存压力显著增加，这种压力在采用虚拟流水线和重计算等训练优化技术时进一步加剧。这些技术打乱张量的生存周期并引入大量内存碎片。常用的深度学习框架（如PyTorch）的默认GPU内存分配器采用在线策略，无法利用张量生存周期的知识，这可能浪费多达43%的内存并导致内存不足错误，从而使得优化技术无效甚至无法使用。", "innovation": "STWeaver，一种结合时空规划的GPU内存分配器，用于深度学习框架。它通过利用训练工作负载中内存分配行为的空间和时间规律性，减少碎片化。STWeaver引入了一种新颖的结合离线规划和在线分配的模式。离线规划利用时空规律生成接近最优的分配计划，而在线分配处理复杂的动态模型，如专家混合（MoE）。这项技术在平均减少了79.2%（最多可达100%）的碎片化率同时，对密集和稀疏模型都有效，并且在计算开销方面可以忽略不计，使得更高效、高吞吐量的训练配置成为可能，性能提升可达32.5%。", "conclusion": "STWeaver能够显著减少GPU内存碎片，提高大规模模型训练的效率和性能，为深度学习框架提供了有效的内存管理解决方案。"}
{"llm_update_time": "20250723", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.16511", "html_url": "https://arxiv.org/abs/2507.16511", "title": "将类比作为分摊化模型构建", "title_en": "Analogy making as amortised model construction", "authors": "David G. Nagy,Tingke Shen,Hanqi Zhou,Charley M. Wu,Peter Dayan", "background": "人类在面对新的情况时能够灵活构建内部模型以进行导航。这些模型必须既准确反映环境以确保资源有限的规划结果适当，又必须能够在开始时易于构建。本文认为，类比在这一过程中起着核心作用，使智能体能够利用过去经验中的相关结构，降低模型构建和规划的计算成本。通过形式化类比为马尔可夫决策过程之间的部分同构，提出了一种框架，其中从先前构建中导出的抽象模块作为可组合的构建块用于构建新的模块。这种模块级重用允许多领域中具有共享结构本质的策略和表示的灵活适应能力。", "innovation": "本文将类比视为分摊化的模型构建，引入了利用马尔可夫决策过程之间的部分同构来形式化类比的概念。提出了一种基于模块化重用的框架，可以灵活地适应具有共享结构本质的不同领域中的策略和表示。", "conclusion": "通过利用类比和模块化重用，本文提供了一种新的方法，能够在资源有限的情况下高效地构建内部模型并进行规划，从而实现跨不同领域的灵活适应。"}
{"llm_update_time": "20250723", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.16480", "html_url": "https://arxiv.org/abs/2507.16480", "title": "设计差异：人类特质如何塑造协作机器人感知", "title_en": "Designing for Difference: How Human Characteristics Shape Perceptions of Collaborative Robots", "authors": "Sabrina Livanec,Laura Londoño,Michael Gorki,Adrian Röfer,Abhinav Valada,Andrea Kiesel", "background": "社会交互机器人的发展引发了关于负责任和包容性设计的关键问题，尤其是在与残疾人或老年人等受保护群体互动时。目前，关于参与者如何评估机器人行为与多样人类需求结合的研究较少，主要原因是参与者缺乏与高度先进家庭机器人互动的实际经验。本研究旨在填补这一空白，通过能够收集参与者对机器人行为的评估，并引导有意义反思的方法来进行研究。研究在在线环境中进行，共涉及112名参与者，他们评估了7个视频中的28种不同类型的人机协作模式。实验组首先完成了一种人机协作的认知-情感映射（CAM）练习，然后才给出评分。尽管CAM反思并未显著影响整体评分，但它对某些机器人行为与人类状态组合的评估表现得更为明显。最重要的是，不同类型的人机协作会影响评估结果。反社会机器人行为始终被评为最低，与老年人的合作引起更多敏感的评价。涉及物体交接的场景比没有物体交接的场景更为积极。这些发现表明，人类特性和交互模式都影响协作机器人的接受度，强调了 prosocial 设计的重要性。它们还突显了反思方法（如CAM）的重要性，这些方法可以收集到细致的反馈，支持开发用户中心和社会责任性的机器人系统，以适应多样化的群体。", "innovation": "本研究通过引入一种人机协作的认知-情感映射（CAM）练习，使得参与者能够更深入地评估机器人行为，并进行有意义的反思。尽管CAM反思本身未显著影响整体评分，但提高了对某些具体组合的细化评估，强调了人类特质和交互模式对协作机器人感知的重要影响。", "conclusion": "研究结果表明，人类特质和互动模式对协作机器人的接受度有显著影响，强调了采用prosocial设计的重要性。此外，反思方法（如CAM反思）能够收集到更多的精细化反馈，支持开发用户中心且负责任的机器人系统，以适应多样化的群体。"}
{"llm_update_time": "20250723", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.16514", "html_url": "https://arxiv.org/abs/2507.16514", "title": "The Ever-Evolving Science Exam", "title_en": "The Ever-Evolving Science Exam", "authors": "Junying Wang,Zicheng Zhang,Yijin Guo,Farong Wen,Ye Shen,Yingji Liang,Yalun Wu,Wenzhe Li,Chunyi Li,Zijian Chen,Qi Jia,Guangtao Zhai", "background": "随着基础模型能力的迅速增长及其广泛应用，对其科学理解的评估变得越来越重要。现有的科学基准虽然在范围、覆盖范围和评估严谨性方面取得了一定进展，但仍存在两个主要挑战：数据泄漏风险损害了基准测试的有效性，以及由于大规模测试导致的评估效率低下问题。\n", "innovation": "我们提出了一种动态基准测试方法——Ever-Evolving Science Exam (EESE)，旨在可靠地评估基础模型的科学能力。EESE包含非公开的EESE-Pool和一个定期更新的EESE动态子集。EESE-Pool是一个包含5个学科和500多个子领域的超过10万个精心构建的科学实例（问题-答案对），通过多阶段构建流程确保了范围、覆盖范围和评估的严谨性。EESE是一个500实例的子集，定期更新并用于泄漏稳健、低开销的评估。\n", "conclusion": "实验表明，EESE能够有效地区分模型在科学领域的强项和弱点及认知维度。总体而言，EESE提供了一种稳健的、可扩展且前向兼容的科学基准设计理念，为评估基础模型处理科学问题的能力提供了一个实际的衡量标准。\n"}
{"llm_update_time": "20250723", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.16389", "html_url": "https://arxiv.org/abs/2507.16389", "title": "从平面向球面转变：基于表面fMRI和大脑皮层结构的脑解码重新定义", "title_en": "From Flat to Round: Redefining Brain Decoding with Surface-Based fMRI and Cortex Structure", "authors": "Sijin Yu,Zijiao Chen,Wenxuan Wu,Shengxian Chen,Zhongliang Liu,Jingxin Nie,Xiaofen Xing,Xiangmin Xu,Xin Zhang", "background": "现有的方法在从人类大脑活动（如fMRI）重建视觉刺激时，往往忽略了重要的脑结构-功能关系，简化了空间信息并忽视了个体解剖变化。", "innovation": "提出了一种新颖的球形分词器，明确地将fMRI信号建模为皮层表面的二维球形数据；结合了结构性磁共振成像（sMRI）数据，实现个性化编码个体解剖变化；采用正样本混叠策略，高效利用与同一视觉刺激相关的多个fMRI扫描。", "conclusion": "这些创新提高了重建精度、生物学解释性和个体间的泛化能力。实验结果显示与当前最优方法相比，重建性能更优，证明了我们基于生物学的方法的有效性和可解释性。"}
{"llm_update_time": "20250723", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.16467", "html_url": "https://arxiv.org/abs/2507.16467", "title": "使用独立成分分析估计治疗效应", "title_en": "Estimating Treatment Effects with Independent Component Analysis", "authors": "Patrik Reizinger,Lester Mackey,Wieland Brendel,Rahul Krishnan", "background": "因果推断领域发展了各种方法以在存在无用因素的情况下准确估计治疗效果。同时，可识别理论领域发展了如独立成分分析（ICA）的方法，用于从数据中识别潜在源和混合权重。尽管这两个研究领域基本上是独立发展的，但它们都试图实现相似的目标：准确和样本有效的估计模型参数。在部分线性回归（PLR）设置中，Mackey等人（2018年）发现，非高斯治疗噪声可以提高估计一致性。非高斯性也是识别潜在因素所需的重要假设。", "innovation": "本文首次提供理论和实证见解，表明可以使用ICA进行PLR模型中的因果效应估计。发现即使在存在高斯共因或非线性不可观测因素的情况下，线性ICA也能准确估计多个治疗效应。", "conclusion": "本文展示了如何利用ICA技术来提高PLR模型中治疗效应估计的准确性，即使在存在复杂不可观测因素的情况下也不例外。"}
{"llm_update_time": "20250723", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.16343", "html_url": "https://arxiv.org/abs/2507.16343", "title": "检测任意声音：基于多模态查询的开放词汇量声学事件检测", "title_en": "Detect Any Sound: Open-Vocabulary Sound Event Detection with Multi-Modal Queries", "authors": "Pengfei Cai,Yan Song,Qing Gu,Nan Jiang,Haoyu Song,Ian McLoughlin", "background": "大多数现有的声学事件检测（SED）算法在闭集假设下运行，这限制了它们的检测能力仅限于预定义的类别。尽管最近的研究通过利用音频-语言模型探索了语言驱动的零样本SED，但它们的表现仍然不尽如人意，原因在于缺乏细粒度的对齐和跨模态特征融合。", "innovation": "本文提出了Detect Any Sound Model（DASM），一种基于查询的框架，用于由多模态查询引导的开放词汇量SED。DASM将SED表述为帧级别的检索任务，其中音频特征与来自文本或音频提示的查询向量进行匹配。为支持这一表述，DASM引入了一个双流解码器，明确地将事件识别和时间定位分离：跨模态事件解码器执行查询特征融合，并确定剪辑级别是否存在声音事件，而上下文网络则建模时间依赖性以进行帧级定位。此外，还提出了推理时的注意掩码策略，以利用基础类和新型类之间的语义关系，显著提高了对新型类别的泛化能力。", "conclusion": "实验表明，在AudioSet Strong数据集上，DASM在开放词汇量设置中有效平衡了定位精度和对新型类别的泛化能力，相比于基于CLAP的方法提高7.8个PSDS，并且在闭集设置中比基线方法提高了6.9个PSDS。此外，DASM在跨数据集零样本评估中的PSDS1得分为42.2，甚至超过了监督CRNN基线。"}
{"llm_update_time": "20250723", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.16537", "html_url": "https://arxiv.org/abs/2507.16537", "title": "符号图智能：使用Tsetlin机器的超向量消息传递学习图级模式", "title_en": "Symbolic Graph Intelligence: Hypervector Message Passing for Learning Graph-Level Patterns with Tsetlin Machines", "authors": "Christian D. Blakely", "background": "该研究提出了一个多层符号框架来对一般图进行分类，利用稀疏二进制超向量和Tsetlin机器。每个图通过结构化消息传递编码，其中节点、边和属性信息被绑定打包成一个符号超向量，这个过程通过从节点属性到边关系再到结构角色的分层绑定，保留了图的层次语义，并产生一种紧凑的离散表示。研究者还提出了一个局部可解释性框架，赋予了该方法一种局部可解释性的关键优势。方法已经在TUDataset基准测试上得到验证，展示出与神经图模型相比、具有很强符号透明度的竞争力的准确度。", "innovation": "该研究提出了一种新颖的方法，即使用稀疏二进制超向量和Tsetlin机器进行多层结构化消息传递的符号框架，用于图分类。该方法不仅能够有效地保留图的层次语义，还具有局部可解释性，同时在基准测试中展示了与神经图模型相当甚至更优的准确性及符号透明度。", "conclusion": "该研究验证了提出的符号图分类方法在TUDataset基准测试上的有效性，证明了其在保持符号透明度的同时具有竞争力的准确率。"}
{"llm_update_time": "20250723", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.16372", "html_url": "https://arxiv.org/abs/2507.16372", "title": "深度会产生一种虚假的安全感：大语言模型内部状态反向工程", "title_en": "Depth Gives a False Sense of Privacy: LLM Internal States Inversion", "authors": "Tian Dong,Yan Meng,Shaofeng Li,Guoxing Chen,Zhen Liu,Haojin Zhu", "background": "大语言模型（LLMs）越来越融入日常生活中，但这也带来了隐私和安全方面的重大关切。近期的研究提出了协作推理方法，即将早期层的推理外包以确保数据本地性，并通过内部神经元模式引入模型安全性审核。这两种技术暴露了LLM的内部状态（ISs），这些状态由于优化挑战和深层的抽象表示特性，在传统上被认为是不可逆的输入状态。这项研究挑战了这一假设，提出了四种显著提高反向工程输入的语义相似度和标记匹配率的反向工程攻击。", "innovation": "这项研究提出了四种定向反向工程攻击，尤其是针对低深度和高深度内部状态。这种攻击采用两阶段过程来避免以前工作中观察到的局部最小值收敛问题。同时，研究还提出了一种基于生成的攻击，将反向工程视为一种翻译任务，利用反向工程模型重建输入。该研究还评估了六种大语言模型对来自医疗咨询和编码辅助数据集的短、长提示的有效性，并展示了对于一段长4,112标记的医疗咨询提示，在Llama-3模型中间层可以实现近乎完美的反向工程。", "conclusion": "研究发现四种实用的防御措施并不能完全阻止内部状态的反向工程，并据此对未来缓解措施的设计提出了见解。"}
{"llm_update_time": "20250723", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.16562", "html_url": "https://arxiv.org/abs/2507.16562", "title": "评价扩展现实(XR)代理技术的社会接受度：一项用户研究（扩展版本）", "title_en": "Evaluating Social Acceptance of eXtended Reality (XR) Agent Technology: A User Study (Extended Version)", "authors": "Megha Quamara,Viktor Schmuck,Cristina Iani,Axel Primavesi,Alexander Plaum,Luca Vigano", "background": "该论文介绍了对扩展现实(XR)代理技术的社会接受度的一项用户研究，特别是针对记者开发的一个远程访问的基于网页的XR培训系统。该系统允许用户与虚拟代理进行互动，为记者提供量身定制的远程培训，特别是在敏感或危险场景下，无需特殊终端设备如头显。研究借鉴并扩展了阿尔梅模型，将社会接受度用已有的感知易用性和感知有用性属性来表示，并增加了可靠性与交互中的安全性等新属性。研究在真实环境中通过受控实验进行了测试，数据收集自用户的感知。研究结果有助于理解特定社会背景下的XR代理解决方案用户接受度，并指出了XR系统改进的领域", "innovation": "研究采用了阿尔梅模型，并在此基础上增加了可靠性与安全性等新属性来衡量社会接受度；通过一项受控实验在实际环境中评估了一种XR代理技术支持下的远程培训系统；研究成果贡献了对特定社会背景下的用户接受度的理解并指出了改进方向", "conclusion": "研究发现，参与者对XR代理技术产生了良好的感知，并对这一技术在特定场景的应用抱有积极的态度，但也强调需要改进系统的可靠性和安全性以提升整体接受度。研究结果为XR系统的社会化应用提供了有价值的见解，并指出了可能的改进方向"}
{"llm_update_time": "20250723", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.16488", "html_url": "https://arxiv.org/abs/2507.16488", "title": "ICR 探针：LLMs 中可靠幻觉检测的隐藏状态动态追踪", "title_en": "ICR Probe: Tracking Hidden State Dynamics for Reliable Hallucination Detection in LLMs", "authors": "Zhenliang Zhang,Xinyu Hu,Huixuan Zhang,Junzhe Zhang,Xiaojun Wan", "background": "大型语言模型 (LLMs) 在各种自然语言处理任务上表现出色，但它们生成幻觉的倾向削弱了它们的可靠性。现有的大多数幻觉检测方法主要依赖隐藏状态的静态表示，忽略了隐藏状态在多层间的动态演变过程，这限制了它们的效果。", "innovation": "本文重点关注隐藏状态更新过程，并提出了一个新的度量标准——ICR 分数（Information Contribution to Residual Stream），用于量化模块对隐藏状态更新的贡献。通过实验证明了ICR分数在区分幻觉方面具有有效性和可靠性。在此基础上，提出了ICR 探针（ICR Probe），该方法能够捕捉隐藏状态在多层间的演进。ICR 探针在参数量较少的情况下取得了优越的性能，并通过消融研究和案例分析对其机制进行了深入探索，提高了其可解释性。", "conclusion": "实验结果表明，ICR 探针在幻觉检测方面表现优异，并且通过更少的参数实现了这一点。进一步的消融研究和案例分析提供了对方法机制的深刻理解，提高了其可解释性。"}
{"llm_update_time": "20250723", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.16533", "html_url": "https://arxiv.org/abs/2507.16533", "title": "confopt: 一个实现与评估基于梯度的神经架构搜索方法的库", "title_en": "confopt: A Library for Implementation and Evaluation of Gradient-based One-Shot NAS Methods", "authors": "Abhash Kumar Jha,Shakiba Moradian,Arjun Krishnakumar,Martin Rapp,Frank Hutter", "background": "基于梯度的一次性神经架构搜索（NAS）方法显著降低了探索具有离散设计选择的空间的成本，例如在模型内选择操作。然而，该领域面临两大挑战。首先，基于梯度的NAS方法的评估过度依赖于DARTS基准，尽管存在其他可用的基准。这种过度依赖导致了饱和，报告的改进往往落入了噪声的范围内。其次，基于梯度的一次性NAS方法的实现分散在不同的仓库中，这使得公平和可重复的比较变得更加复杂，同时也阻碍了进一步的发展。", "innovation": "本论文引入了Configurable Optimizer (confopt)，这是一个可扩展的库，旨在简化基于梯度的一次性NAS方法的开发和评估。Confopt提供了一个最小化API，使用户能够轻松地集成新的搜索空间，同时支持NAS优化器的核心组件分解。通过这一框架，论文创建了一套新的DARTS基准，并结合了一个新的评估协议，揭示了当前基于梯度的一次性NAS方法评估中的一个关键问题。", "conclusion": "通过使用Confopt库和新的评估协议，论文揭示了基于梯度的一次性NAS方法评估中的一个关键缺陷。相关的代码可以在这个链接找到。"}
{"llm_update_time": "20250723", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.16564", "html_url": "https://arxiv.org/abs/2507.16564", "title": "TTMBA: 朝着多声源双耳音频生成的目标", "title_en": "TTMBA: Towards Text To Multiple Sources Binaural Audio Generation", "authors": "Yuxuan He,Xiaoran Yang,Ningning Pan,Gongping Huang", "background": "现有的文本到音频（TTA）生成方法主要生成单声道输出，忽视了为沉浸式听觉体验所需的重要空间信息。", "innovation": "提出了一种具有时间和空间控制的级联方法，用于文本到多声源双耳音频生成（TTMBA）。该方法首先使用预训练的大语言模型将文本分割为具有时间和空间细节的结构化格式，然后使用预训练的单声道音频生成网络为每个事件生成多个单声道音频，最后使用基于大语言模型的空间数据的双耳渲染神经网络将单声道音频转换为双耳音频，最后根据起始时间排列这些双耳音频，生成多声源双耳音频。", "conclusion": "实验结果表明，该方法在音频生成质量和方位知觉准确性方面优于现有方法。"}
{"llm_update_time": "20250723", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.16579", "html_url": "https://arxiv.org/abs/2507.16579", "title": "基于层次化掩码扩散模型的医学影像合成", "title_en": "Pyramid Hierarchical Masked Diffusion Model for Imaging Synthesis", "authors": "Xiaojiao Xiao,Qinmin Vivian Hu,Guanghui Wang", "background": "医学影像在临床工作中至关重要，但由于扫描时间延长、扫描损坏、伪影、患者运动和对比剂不耐受等因素，经常存在影像模态缺失的问题。现有的图像合成方法在此方面存在改进空间。因此，研究一种新的图像合成网络以解决这些问题非常重要。", "innovation": "该研究提出了一种新的图像合成网络——金字塔层次掩码扩散模型（PHMDiff），该网络采用多层次的结构，可在不同分辨率和层上更精细地控制图像合成。该模型利用随机的多层次高比例掩码加速扩散模型的训练，并平衡了细节保真度和整体结构。融合基于Transformer的扩散模型处理过程引入了跨粒度正则化，建模了不同粒度空间中的潜在空间间的一致性互信息，从而提高了像素级感知准确性。实验结果表明，PHMDiff在峰值信噪比（PSNR）和结构相似度指数测量（SSIM）等指标上表现出更优异的性能，显示出其生产高质量合成医学影像的优势。", "conclusion": "多尺度的PHMDiff图像合成框架在不同和同种医学影像模态中显示出显著优势，Ablation研究进一步证明了每部分的贡献。"}
{"llm_update_time": "20250723", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.16541", "html_url": "https://arxiv.org/abs/2507.16541", "title": "全面的 Federated Graph Learning 数据中心化概述", "title_en": "A Comprehensive Data-centric Overview of Federated Graph Learning", "authors": "Zhengyu Wu,Xunkai Li,Yinlin Zhu,Zekai Chen,Guochen Yan,Yanyu Yan,Hao Zhang,Yuming Ai,Xinmo Jin,Rong-Hua Li,Guoren Wang", "background": "在大数据应用的时代，Federated Graph Learning (FGL) 出现，解决了解分散数据持有者之间的集体智能优化与保护敏感信息之间的权衡。现有 FGL 的综述贡献不少，但主要集中在将 Federated Learning (FL) 和 Graph Machine Learning (GML) 结合上，导致了早期阶段的重叠分类，偏重于方法论和模拟场景，缺少对数据属性和使用方式全面视角的研究，即数据为中心的视角，这是评估 FGL 研究如何处理数据核心约束以提升模型性能的关键。", "innovation": "本文提出了一个两层数据为中心的分类：数据特征，按用于 FGL 的数据集的结构和分布特性进行分类；数据利用，分析用于克服关键数据中心化挑战的训练过程和技术。每一分类层定义为三个相互独立的标准，代表不同的数据中心化配置。此外，本文还探讨了 FGL 与预训练大型模型的集成、展示了真实应用场景，并指出了与 GML 发展趋势一致的未来方向。", "conclusion": "本文提供了一个完整的 FGL 数据中心化概述，从数据属性和使用方式重新组织了 FGL 研究，强调了数据为中心的研究视角，并展示了 FGL 的实际应用场景及其未来发展方向。"}
{"llm_update_time": "20250723", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.16594", "html_url": "https://arxiv.org/abs/2507.16594", "title": "超低功率边缘/IoT节点上分块学习TinyML的实验研究", "title_en": "An Experimental Study of Split-Learning TinyML on Ultra-Low-Power Edge/IoT Nodes", "authors": "Zied Jenhani,Mounir Bensalem,Jasenka Dizdarević,Admela Jukan", "background": "在微控制器上直接进行深度学习推理受到了内存和计算预算紧绌的限制。分块学习（SL）解决了这一限制问题，该方法在传感器上执行推理过程的一部分，而将剩余部分卸载到伴生物理设备上。对于受限制的设备和空中低功率传输协议的影响，分块学习在实际应用中的表现尚未有深入研究。论文使用Espressif ESP32-S3 板构建了一个端到端的TinyML + SL测试平台，旨在评估分块学习在边缘/IoT环境中的空中传输性能。论文通过空中更新将经过量化和分割的MobileNetV2图像识别模型部署到节点上，并通过不同的无线通信方法交换中间激活数据，以实现相同硬件上的直接对比。结果表明，分块模型在block_16_project_BN层后生成5.66 kB的张量，使用UDP传输仅需3.2毫秒，在稳态下延迟可达5.8秒。ESP-NOW在往返时间（RTT）性能上表现最优，为3.7秒；BLE则进一步延长了电池寿命，但增加了超过10秒的传输延迟。", "innovation": "论文构建了基于Espressif ESP32-S3 板的端到端TinyML + SL测试平台，首次全面评估了分块学习在超低功率边缘/IoT设备中的性能，通过交换中间激活数据以不同的无线通信方法进行空中传输对比，为实际应用提供了重要参考。", "conclusion": "使用分块学习的方法，可以在AirLink中传输更小的模型片段，有效降低传输延迟，其中ESP-NOW在RTT性能上表现最优，但BLE在电池寿命上有更好的表现。"}
{"llm_update_time": "20250723", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.16524", "html_url": "https://arxiv.org/abs/2507.16524", "title": "Spatial 3D-LLM: 探索3D视觉语言模型中的空间意识", "title_en": "Spatial 3D-LLM: Exploring Spatial Awareness in 3D Vision-Language Models", "authors": "Xiaoyan Wang,Zeju Li,Yifan Xu,Jiaxing Qi,Zhifei Yang,Ruifei Ma,Xiangde Liu,Chao Zhang", "background": "近年来，大型语言模型（LLMs）在处理3D视觉语言任务方面展现出令人兴奋的可能性。然而，现有的大多数3D多模态LLM（3D MLLMs）依赖于压缩整体的3D场景信息或分割独立的对象来执行这些任务，这限制了它们的空间感知能力，因为无法充分代表3D场景中固有的丰富性。", "innovation": "本文提出了一个名为Spatial 3D-LLM的3D多模态LLM，特别设计用于增强空间意识以应对3D视觉语言任务。它通过丰富3D场景的空间嵌入来集成LLM主干和渐进式空间意识方案，该方案能够在感知领域扩大时逐步捕获空间信息，并生成包含位置信息的3D场景嵌入作为视觉提示。此外，还提出并构造了两组新的任务‘3D物体距离测量’和‘3D布局编辑’，以及一个名为MODEL的3D指令数据集来评估模型的空间意识能力。", "conclusion": "实验结果表明，Spatial 3D-LLM在广泛的3D视觉语言任务中达到了最先进的性能，揭示了我们渐进式空间意识方案中的改进，能够挖掘更深层次的空间信息。"}
{"llm_update_time": "20250723", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.16535", "html_url": "https://arxiv.org/abs/2507.16535", "title": "EarthCrafter：通过双稀疏潜变分生成大规模3D地球", "title_en": "EarthCrafter: Scalable 3D Earth Generation via Dual-Sparse Latent Diffusion", "authors": "Shang Liu,Chenjie Cao,Chaohui Yu,Wen Qian,Jing Wang,Fan Wang", "background": "尽管最近的3D生成工作取得了显著进展，但将这些方法扩展到地理尺度上（如建模成千上万平方公里的地球表面）仍然是一项开放的挑战。", "innovation": "通过数据基础设施和模型架构的双重创新来解决这一问题。首先，引入Aerial-Earth3D，这是迄今为止最大的3D航空数据集，包含50,000个经过策展的场景（每个场景尺寸为600米x600米），覆盖美国本土，包含4500万个多视角Google地球图像。其次，提出了EarthCrafter框架，一种用于大规模3D地球生成的定制框架，通过稀疏解藕的潜变分实现。该架构分离了结构生成和纹理生成。", "conclusion": "广泛的实验证明，EarthCrafter在极端大规模生成中表现更优秀。该框架还支持多样的应用，从基于语义的城市规划生成到无条件地形合成，同时通过丰富的Aerial-Earth3D数据先验保持地理可行性。"}
{"llm_update_time": "20250723", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.16430", "html_url": "https://arxiv.org/abs/2507.16430", "title": "超越算法伦理学：应对人工智能推荐系统的伦理和人类学挑战", "title_en": "Beyond Algorethics: Addressing the Ethical and Anthropological Challenges of AI Recommender Systems", "authors": "Octavian M. Machidon", "background": "论文探讨了由AI驱动的推荐系统（RSs）在塑造数字环境和社会互动中的道德和人类学挑战。这些RSs通过定制个性化内容，不仅反映用户偏好，还积极构建个体在社交媒体、娱乐平台和电子商务中的体验。尽管这些RSs无处不在，但它们带来的伦理问题仍然缺乏足够的探索，而隐私、自主性和心理健康方面的担忧日益加剧。", "innovation": "作者认为现有的道德方法，如算法伦理，虽然必要但并不足够。RSs将人类复杂性简化为可量化维度，利用用户弱点，并将参与优先于福祉。因此，需要超越单纯的技术支持，提出一个以人为本的RS设计综合框架，结合跨学科视角、监管策略和教育计划，以确保AI系统促进而不是削弱人类自主性和社会繁荣。", "conclusion": "作者建议一种综合框架，将跨学科视角、监管策略和教育计划整合到RS设计中，以确保AI系统能够促进而非削弱人类自主性和社会繁荣，解决由RS带来的伦理和社会问题。"}
{"llm_update_time": "20250723", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.16695", "html_url": "https://arxiv.org/abs/2507.16695", "title": "使用行列随机化 DEDICOM 的可解释主题提取与词嵌入学习", "title_en": "Interpretable Topic Extraction and Word Embedding Learning using row-stochastic DEDICOM", "authors": "Lars Hillebrand,David Biesner,Christian Bauckhage,Rafet Sifa", "background": "DEDICOM算法提供了一种独特的可解释矩阵分解方法，适用于对称和非对称方阵。研究者利用点wise互信息矩阵对文本语料进行了新的行随机化版本的DEDICOM方法的应用，以识别词汇中的潜在主题簇，并同时学习可解释的词嵌入。引入了一种有效训练受限DEDICOM算法的方法，并对其主题建模和词嵌入性能进行了定性评估。", "innovation": "创新点在于提出了使用行列随机化版本的DEDICOM算法对文本语料的点wise互信息矩阵进行分解，以识别词汇中的潜在主题簇，并同时学习可解释的词嵌入。还提出了一种有效训练受限的DEDICOM算法的方法。", "conclusion": "研究证明了提出的模型在主题建模和词嵌入学习方面的有效性和可解释性，通过有限的学习方法提高了算法的效率，并对其进行了定性评估。"}
{"llm_update_time": "20250723", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.16556", "html_url": "https://arxiv.org/abs/2507.16556", "title": "优化基于DNN的HSI分割FPGA系统用于ADS：一种实用的方法", "title_en": "Optimization of DNN-based HSI Segmentation FPGA-based SoC for ADS: A Practical Approach", "authors": "Jon Gutiérrez-Zaballa,Koldo Basterretxea,Javier Echanobe", "background": "HSI在自主导航中的应用是一个很有前途的研究领域，旨在提高基于视觉传感器的检测、跟踪和场景理解系统的准确性和鲁棒性。结合先进的计算算法，如DNNs，与小型快照HSI相机相结合，可以增强这些系统的可靠性。HSI克服了灰度和RGB成像在描述目标物理特性方面的固有限制，特别是在光谱反射率和同质性方面。尽管HSI在基于视觉的进展中取得了有希望的结果，但在ADS等安全关键系统中，严格的时间延迟、资源消耗和安全约束促使将ML工作负载移至边缘平台。这要求制定详细的软硬件协同设计方案以高效地分配和优化任务。", "innovation": "本文提出了适用于ADS的基于FPGA的HSI分割DNN处理器的优化技术方案，包括关键优化，如功能性的软硬件任务分布、硬件感知预处理、ML模型压缩以及完整的流水线部署。应用的压缩技术将设计的DNN复杂度减少到原操作的24.34%和原始参数数量的1.02%，同时在不失分割精度的情况下使推理任务提速2.86倍。", "conclusion": "通过有效的任务分配、硬件感知预处理、模型压缩和流水线部署，优化的DNN-HSI分割处理器实现了更高效的部署，为ADS等安全关键系统提供支持。"}
{"llm_update_time": "20250723", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.16663", "html_url": "https://arxiv.org/abs/2507.16663", "title": "自我矛盾作为自我改进：减轻MLLM中生成与理解差距", "title_en": "Self-Contradiction as Self-Improvement: Mitigating the Generation-Understanding Gap in MLLMs", "authors": "Yujin Han,Hao Chen,Andi Han,Zhiheng Wang,Xinyu Lin,Yingya Zhang,Shiwei Zhang,Difan Zou", "background": "尽管努力将多模态生成和理解任务统一在一个单一模型中，我们发现这些模型表现出自我矛盾的现象，即生成的图像与模型自身的理解不一致，这些图像被视为与输入提示不匹配。我们定义了一个非统一性评分来量化这种自我矛盾。实验证据表明，这种自我矛盾主要是由于生成能力较弱，无法与提示对齐，而不是理解能力的问题。这种能力差异表明可以通过利用自我矛盾来促进模型自我改进，其中强大的模型理解指导弱小的生成能力来缩小生成与理解之间的差距。标准的后训练方法（例如，SFT、DPO）在这种内部监督下可以成功地提高生成能力和统一性。我们发现，仅微调生成分支时会同时改善生成和理解，这一现象在预训练中已知但在后训练中尚未充分探讨。我们的分析表明，这种改进来源于更好地检测之前错误识别为与提示对齐的假阳性。理论上，我们证明了生成和理解之间的对齐训练动态使不与提示对齐的生成变得较少，从而也提高了理解分支的不匹配检测能力。此外，我们的框架揭示了一种在不良监督下共同退化的风险——这是一个在实验中实证验证的被忽视的现象。值得注意的是，我们发现内在的度量标准（如非统一性评分）无法区分共同退化和共同改进，这突显了对数据质量检查的必要性。最后，我们提出了一种基于我们发现的课程策略，随着模型的改进逐级引入更难的样本，从而实现更好的统一性，并改善MLLM的生成和理解能力。", "innovation": "我们定义了一种非统一性评分来量化MLLM中生成与理解的自我矛盾现象。提出了利用生成与理解能力的不对称性，通过模型自身产生的内部监督来缩小生成与理解之间的差距的方法。我们发现了仅微调生成分支时会同时提升生成和理解性能的现象，并证明了这种共同提升效果是由生成与理解之间的对齐训练动态引起的。提出了一种基于课程策略的方法，随着模型提升逐步引入更难的数据样本，以实现更好的统一性改进。", "conclusion": "我们的研究表明，MLLM中的自我矛盾可以作为一种自我改进机制，直接或间接地通过模型自监督来改善生成和统一性。这种共同提升和共同退化的现象揭示了在自监督过程中需要关注数据质量和采样策略的重要性。基于这些发现，我们提出了一个逐步引入更难样本的课程策略，以实现更好的MLLM的生成和理解能力。"}
{"llm_update_time": "20250723", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.16586", "html_url": "https://arxiv.org/abs/2507.16586", "title": "AI for Better UX in Computer-Aided Engineering: Is Academia Catching Up with Industry Demands? A Multivocal Literature Review", "title_en": "AI for Better UX in Computer-Aided Engineering: Is Academia Catching Up with Industry Demands? A Multivocal Literature Review", "authors": "Choro Ulan Uulu,Mikhail Kulyabin,Layan Etaiwi,Nuno Miguel Martins Pacheco,Jan Joosten,Kerstin Röse,Filippos Petridis,Jan Bosch,Helena Holmström Olsson", "background": "计算机辅助工程(CAE)允许模拟专家优化复杂的模型，但用户体验(UX)的问题限制了效率和可访问性。人工智能(AI)已被证明有潜力增强CAE流程，但在将这两个领域融合并注重用户体验的研究方面仍存在碎片化的现象。本研究进行了多声部文献综述(MLR)，探讨AI如何在CAE软件中提升用户体验，涵盖学术研究和工业应用。研究表明，学术研究和技术应用之间存在显著差距，公司积极应用大型语言模型(LLMs)、自适应用户界面(adaptive UIs)和推荐系统(recommender systems)，而学术研究主要集中在技术能力验证而非用户体验验证。", "innovation": "本研究通过多声部文献综述的方法，考察了AI在CAE中提升用户体验的方式，揭示了学术研究与工业应用之间的差距，并指出了AI辅助指导、自适应界面和流程自动化等方面的机会，这些方面当前的研究尚不充分。", "conclusion": "通过描绘这些领域的交集，研究提供了一个基础框架，以解决识别的研究缺口，并促进人工智能和CAE用户体验的整合，从而提高用户体验。"}
{"llm_update_time": "20250723", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.16704", "html_url": "https://arxiv.org/abs/2507.16704", "title": "Screen2AX：基于视觉的方法用于自动生成macOSAccessibility元数据", "title_en": "Screen2AX: Vision-Based Approach for Automatic macOS Accessibility Generation", "authors": "Viktor Muryn,Marta Sumyk,Mariya Hirna,Sofiya Garkot,Maksym Shamrai", "background": "桌面Accessibility元数据使得AI代理能够解释屏幕内容并支持依赖屏幕阅读器等工具的用户。然而，许多应用程序因开发者提供的元数据不完整或缺失而无法完全访问。研究表明，只有33%的macOS应用程序提供了完整的Accessibility支持。尽管近年来有关结构化屏幕表示的工作主要解决了特定挑战，如UI元素检测或字幕生成，但没有工作尝试通过复制整个层次结构来捕捉桌面界面的全部复杂性。为此，本文介绍了一种名为Screen2AX的新框架，能够从单张屏幕截图自动生成实时、树状结构的Accessibility元数据。", "innovation": "Screen2AX框架利用视觉-语言模型和物体检测模型，检测、描述和组织UI元素，模仿macOS系统的层次结构。为了解决macOS桌面应用程序数据有限的问题，作者创建并公开发布了三个数据集，包括112个macOS应用程序，并进行了UI元素检测、分组和层次结构Accessibility元数据的注释。Screen2AX在重建完整Accessibility树时的F1得分达到了77%。这种方法显著提高了自主代理解释和交互复杂桌面界面的能力。作者还引入了Screen2AX-Task基准，专门用于评估macOS桌面环境中的自主代理任务执行情况。实验证明，Screen2AX在性能上比原生Accessibility表示快2.2倍，并且在ScreenSpot基准测试中超越了OmniParser V2系统。", "conclusion": "Screen2AX框架能够自动从单张屏幕截图生成实时、树状结构的Accessibility元数据，适用于macOS环境。通过这一工作，自主代理解释和交互复杂桌面界面的能力得到了显著提升。"}
{"llm_update_time": "20250723", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.16711", "html_url": "https://arxiv.org/abs/2507.16711", "title": "提升风险和质量保证：一种增强监管合规性的RAG聊天机器人", "title_en": "Advancing Risk and Quality Assurance: A RAG Chatbot for Improved Regulatory Compliance", "authors": "Lars Hillebrand,Armin Berger,Daniel Uedelhoven,David Berghaus,Ulrich Warning,Tim Dilmaghani,Bernd Kliem,Thomas Schmid,Rüdiger Loitz,Rafet Sifa", "background": "在高度受监管的行业中，风险管理与质量（R&Q）保证需不断应对复杂监管框架下的挑战。员工每天需处理大量查询，要求准确的政策解释。传统方法依赖专门专家，导致操作瓶颈和可扩展性限制。", "innovation": "提出了一种结合大型语言模型（LLMs）的检索增强生成（RAG）系统，利用混合搜索和相关性增强来提升R&Q查询处理效果。该系统在124个由专家标注的真实查询上进行了评估，展示了显著优于传统RAG方法的效果。此外，进行了广泛超参数分析，比较并评估了多个配置方案，为从业者提供了有价值的观点。", "conclusion": "展示了实际部署的RAG系统在R&Q查询处理中的显著改进，并通过对多个配置方案的超参数分析，提供了宝贵的实践经验。"}
{"llm_update_time": "20250723", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.16642", "html_url": "https://arxiv.org/abs/2507.16642", "title": "使用大型语言模型在财务审计中实现自动化合规验证", "title_en": "Towards Automated Regulatory Compliance Verification in Financial Auditing with Large Language Models", "authors": "Armin Berger,Lars Hillebrand,David Leonhard,Tobias Deußer,Thiago Bell Felix de Oliveira,Tim Dilmaghani,Mohamed Khaled,Bernd Kliem,Rüdiger Loitz,Christian Bauckhage,Rafet Sifa", "background": "财务文件的审计历来是一个劳动密集型的过程，但AI驱动的解决方案已经在这一过程中取得了进展，通过推荐符合会计标准的法律法规要求的相关文本段落来简化这一过程。然而，这些系统在验证推荐段落是否完全符合具体法律法规要求方面还存在明显不足。基于此，本文探讨了开源大型语言模型（LLMs）在不同模型配置下的监管合规性效率。实验采用了普华永道德国提供的两个定制数据集，比较了开源的Llama-2模型与闭源的如OpenAI的GPT模型的表现。", "innovation": "研究特别关注了开源的Llama-2 70亿参数模型在检测不合规或真阴性情况方面的出色表现，优于所有闭源的替代模型。尽管如此，闭源模型如GPT-4在多种场景下表现最佳，尤其是在非英语环境中。", "conclusion": "研究发现开源Llama-2模型在检测不合规或真阴性情况方面表现出色，但闭源的GPT-4模型在多种场景下表现更佳，特别是在非英语环境中。"}
{"llm_update_time": "20250723", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.16672", "html_url": "https://arxiv.org/abs/2507.16672", "title": "在提示调谐的大语言模型中冷启动个性化中的元学习", "title_en": "Meta-Learning for Cold-Start Personalization in Prompt-Tuned LLMs", "authors": "Yushang Zhao,Huijie Shen,Dannier Li,Lu Chang,Chengrui Zhou,Yinuo Yang", "background": "基于大语言模型（LLM）的生成型、可解释型和灵活推荐系统在冷启动用户情景下效果欠佳。当前的解决方案，如监督微调和协同过滤，侧重于稠密用户-项目互动，维护和更新成本高。文章探讨了如何利用元学习框架，进行高效提示调整，以快速个性化冷启动时的LLM推荐系统。该模型利用一阶（Reptile）和二阶（MAML）优化进行软提示嵌入学习，将每个用户视为任务进行元优化。通过情景采样、内环适应和外环泛化，优化提示。实验结果表明，该自适应模型在评分Top10、Top10召回率和平均召回率上优于强基线，并且能够在消费级GPU上实时运行。零历史个性化也得到了支持，275 ms的调整速度允许实时风险评估金融系统并减少检测延迟，增强支付网络稳定性。显著缩短了与传统合规检查相比的系统性脆弱性检测延迟，进而减少支付网络的传染风险，增强国家金融基础设施的韧性。", "innovation": "提出了一种元学习框架，用于提示调试的大语言模型中的冷启动个性化。通过一阶（Reptile）和二阶（MAML）优化学习软提示嵌入，将每个用户视为任务进行元优化。这种框架能够快速个性化冷启动推荐系统，实现实时运行，并支持零历史个性化，具有高适应性。这减少了检测延迟，提高了支付网络的稳定性，并减少了系统性脆弱性的检测延迟，增强国家金融基础设施的韧性。", "conclusion": "该研究展示了基于元学习的提示调整方法在大语言模型中实现高效冷启动个性化的效果。该方法在多个数据集上进行了验证，显示出优异的性能，并且能够在消费级GPU上实现实时运行。此外，该方法支持零历史个性化，从而实现实时风险评估，具有显著的实际应用价值。"}
{"llm_update_time": "20250723", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.16735", "html_url": "https://arxiv.org/abs/2507.16735", "title": "AI增强的对话代理用于个性化哮喘支持：参与、价值和效能的因素", "title_en": "AI-enhanced conversational agents for personalized asthma support Factors for engagement, value and efficacy", "authors": "Laura Moradbakhti,Dorian Peters,Jennifer K. Quint,Björn Schuller,Darren Cook,Rafael A. Calvo", "background": "英国的哮喘相关死亡率在欧洲最高，且只有30%的患者接受基本护理。为了提供健康教育、自我管理支持和就医接桥，需要新的方式来帮助哮喘患者。自动化对话代理，特别是移动聊天机器人，提供了提供个性化健康教育和风险自评的替代方式。但是患者是否会使用聊天机器人？哪些因素会影响他们的使用意愿？", "innovation": "本研究通过一项由哮喘临床医生、患者和技术开发者设计的患者调查（N=1257），调查了聊天机器人对哮喘患者的适用性、价值和使用意愿的关键因素。结果显示大多数哮喘患者对使用聊天机器人感兴趣，而且那些认为自身哮喘更严重的患者以及不太自信能自我管理的患者更可能使用。此外，患者对24/7访问、个性化功能和通过WhatsApp（相比应用、语音助手、短信或网站）接入表现出极大热情。然而，安全和隐私担忧以及对技术能力的怀疑是阻碍使用的主要障碍。", "conclusion": "研究总结出7条针对技术和开发者的建议，以优化基于聊天机器人的哮喘健康支持的效能。"}
{"llm_update_time": "20250723", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.16725", "html_url": "https://arxiv.org/abs/2507.16725", "title": "RA Vine: 面向现实的评估框架用于代理搜索", "title_en": "RAVine: Reality-Aligned Evaluation for Agentic Search", "authors": "Yilong Xu,Xiang Long,Zhi Zheng,Jinhua Gao", "background": "当前的检索增强智能搜索引擎采用代理搜索模式，这种模式更加自主和适应性强。然而，现有的评价框架未能很好地与代理搜索的目标相契合。首先，当前基准中常用的高度复杂查询往往偏离了现实用户的搜索场景。第二，先前的方法在提取用于端到端评估的真相时往往引入噪声，导致细粒度评估结果的扭曲。第三，大部分现有框架仅专注于最终答案的质量，忽略了代理搜索固有的迭代过程的评估。", "innovation": "本文提出了RA Vine — 一个面向现实的评估框架，用于代理大语言模型和搜索。RA Vine 针对多点查询和长格式答案，更好地反映用户意图，并引入了可归因的真相构建策略，以增强细粒度评估的准确性。此外，RA Vine 跨整个迭代过程评估模型与搜索工具的交互，并考虑到效率因素。", "conclusion": "我们使用 RA Vine 对一系列模型进行了基准测试，并得出了几项见解，我们希望这些见解能为推进代理搜索系统的发展做出贡献。代码和数据集可在以下链接获取。"}
{"llm_update_time": "20250723", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.16795", "html_url": "https://arxiv.org/abs/2507.16795", "title": "使用概念消除微调引导离分布外推", "title_en": "Steering Out-of-Distribution Generalization with Concept Ablation Fine-Tuning", "authors": "Helena Casademunt,Caden Juang,Adam Karvonen,Samuel Marks,Senthooran Rajamanoharan,Neel Nanda", "background": "大型语言模型（LLMs）的微调可能导致意外的离分布外推。标准方法依赖于修改训练数据，例如通过增加更好地规定预期外推的数据。然而，这并不总是实用的。", "innovation": "本文引入了一种称为概念消除微调（CAFT）的新技术，利用可解释性工具控制LLMs从微调中学习到的离分布外推，而无需修改训练数据或使用目标分布的数据。通过在微调过程中消除与不需要的概念相对应的latent空间中的方向，CAFT能够引导模型向非预期外推远离。", "conclusion": "CAFT代表了一种全新的方法，可以引导LLMs的离分布外推，而无需修改训练数据，在不降低训练分布性能的前提下减少了10倍的不正确外推。"}
{"llm_update_time": "20250723", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.16754", "html_url": "https://arxiv.org/abs/2507.16754", "title": "持续不断：基于适应性HyDE检索优化LLM开发者支持", "title_en": "Never Come Up Empty: Adaptive HyDE Retrieval for Improving LLM Developer Support", "authors": "Fangjian Lei,Mariam El Mezouar,Shayan Noei,Ying Zou", "background": "大型语言模型(LLMs)在协助开发者处理代码相关问题方面显示出潜力，但同时也存在生成不可靠答案的风险。为解决这一问题，引入了检索增强生成(RAG)框架，通过检索相关信息来减少LLMs的回答错误。然而，在设计高效的RAG流水线时仍然存在诸多挑战。该论文旨在构建一个包含超过300万条相关Stack Overflow帖子的检索数据库，并探索不同RAG流水线的设计，以评估它们在生成准确可靠答案方面的效果，特别设计和评估了7种不同的RAG流水线及其变体，以回答具有历史相似匹配的问题，并通过自动降低检索中的相似度阈值来解决没有接近先前匹配的新问题，从而增加找到部分相关信息的概率和提升未见情况的涵盖范围。", "innovation": "论文设计并评估了7种不同类型的RAG流水线及63种流水线变体，特别强调了采用假设文档嵌入(HyDE)结合全面答案上下文的RAG流水线在处理Stack Overflow问题中的最佳表现。此外，通过动态调整检索中的相似度阈值来提高对于新颖问题的覆盖率，并将优化后的RAG流水线应用于4种开源LLMs，发现优化后的RAG流水线在不同LLMs上均表现出在有用性、正确性和细节方面的更佳性能。", "conclusion": "研究结果表明，优化后的RAG流水线显著提升了各种开发者查询中答案的质量，包括已见过和新颖的问题，从而在LLM-as-a-judge场景下超越了零样本基准线。这些发现证明优化的RAG流水线能够广泛增强不同LLMs的回复质量。"}
{"llm_update_time": "20250723", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.16812", "html_url": "https://arxiv.org/abs/2507.16812", "title": "MegaScience：促进科学推理后训练数据集前沿", "title_en": "MegaScience: Pushing the Frontiers of Post-Training Datasets for Science Reasoning", "authors": "Run-Ze Fan,Zengzhi Wang,Pengfei Liu", "background": "科学研究推理能力对于培养AI科学家和帮助人类研究人员推进自然科学发现至关重要。然而，开源社区主要集中在数学和编码方面，忽视了科学领域，主要是因为缺乏开放、大规模、高质量且可验证的科学推理数据集。", "innovation": "该论文首次提出了两个重要的数据集：TextbookReasoning和MegaScience。TextbookReasoning包含了从12000本大学水平的科学教科书中提取的真实参考答案，涵盖7个科学领域，共计650000个推理问题。MegaScience则是一个由大规模高质量开源数据集组成的混合体，总计包含125万个实例，并通过系统性的去除研究来评估不同数据选择方法，确定每个公开可用科学数据集的最佳子集。此外，还构建了一个覆盖广泛的评估系统，包括全面的答案提取策略，确保准确的评估指标。实验结果显示，与现有的开源科学数据集相比，我们的数据集在响应长度更简洁的情况下，表现出更好的性能和训练效率。进一步地，通过MegaScience训练了Llama3.1、Qwen2.5和Qwen3系列的基础模型，这些模型在平均性能上大大超过了相应的官方指令模型。而且，对于大型和更强的模型，MegaScience显示出更大的效果，表明科学调优具有规模效益。", "conclusion": "我们发布了数据整理管道、评估系统、数据集以及七个训练好的模型，以促进科学推理研究的发展。"}
{"llm_update_time": "20250723", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.16713", "html_url": "https://arxiv.org/abs/2507.16713", "title": "经验是最好的老师：通过自我生成的记忆对VLM进行机器人学领域的接地", "title_en": "Experience is the Best Teacher: Grounding VLMs for Robotics through Self-Generated Memory", "authors": "Guowei Lan,Kaixian Qu,René Zurbrügg,Changan Chen,Christopher E. Mower,Haitham Bou-Ammar,Marco Hutter", "background": "视觉-语言模型（VLMs）在机器人领域已被广泛应用，旨在实现自主规划。然而，将这些原本在互联网数据上训练的VLMs连接到多样化的现实世界机器人上依然存在挑战。", "innovation": "提出了ExpTeach框架，通过构建机器人在现实世界中的自我生成记忆，实现了VLMs与物理机器人的连接。借助反馈增强生成（RAG）机制，总结自我生成的经验以指导未来的任务。此外，ExpTeach还引入了按需图像标注模块以增强VLMs的空间理解能力。", "conclusion": "在实验中，通过在四个具有挑战性的机器人任务中应用反思策略，成功从36%提升到84%；并在22%的单一试验成功率基础上，通过使用长期记忆实现了成功率达到80%的显著提升。这些结果表明ExpTeach在有效性与泛化能力方面表现出色。"}
{"llm_update_time": "20250723", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.16801", "html_url": "https://arxiv.org/abs/2507.16801", "title": "使用可解释的深度学习模型解码5'UTR中的翻译相关功能序列", "title_en": "Decoding Translation-Related Functional Sequences in 5'UTRs Using Interpretable Deep Learning Models", "authors": "Yuxi Lin,Yaxue Fang,Zehong Zhang,Zhouwu Liu,Siyun Zhong,Fulong Yu", "background": "理解5'非翻译区（5'UTRs）如何调节mRNA翻译对于控制蛋白质表达和设计有效的治疗性mRNA至关重要。尽管近期深度学习模型在从5'UTR序列预测翻译效率方面显示出潜力，但大多数模型受到固定输入长度和解释能力有限的限制。", "innovation": "本研究引入了一种基于Transformer的架构——UTR-STCNet，用于灵活且基于生物学的建模可变长度的5'UTRs。UTR-STCNet融合了一个注意力感知标记聚类（SATC）模块，该模块根据标记的显著性分数逐迭代地将核苷酸标记聚合成多层次、语义相关的单位，并采用轻量级的注意力机制捕捉局部和远程调控依赖性。该结合架构实现了在不进行输入截断或增加计算成本的情况下有效地进行建模和解释。经过三项基准数据集的评估，UTR-STCNet在预测核糖体负载（MRL，关键翻译效率代理）方面始终优于最先进的基准模型。此外，该模型恢复了已知的功能元件，例如上游AUG和Kozak位点，这突出显示了其在翻译调节机制洞察中的潜在价值。", "conclusion": "UTR-STCNet模型在预测翻译效率方面表现出显著优势，并为理解和设计有效的治疗性mRNA提供了新的工具，有助于深入理解5'UTRs在翻译调节中的作用。"}
{"llm_update_time": "20250723", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.16571", "html_url": "https://arxiv.org/abs/2507.16571", "title": "基于数据驱动的非结构化有限体积计算自适应梯度恢复方法", "title_en": "Data-Driven Adaptive Gradient Recovery for Unstructured Finite Volume Computations", "authors": "G. de Romémont,F. Renac,F. Chinesta,J. Nunez,D. Gueyffier", "background": "本文提出了一种数据驱动方法来增强非结构化有限体积方法在双曲守恒律中的梯度重建，特别是针对2D欧拉方程。该方法将结构化网格方法扩展到了非结构化网格，通过修改后的DeepONet架构，该架构结合了局部几何结构。该架构利用局部网格拓扑确保旋转不变性，并确保学习算子的第一阶约束。训练方法通过熵惩罚、总变差减小惩罚和参数正则化来确保物理上一致的解决方案，特别是在富含激波区域。模型是在高质量数据集上训练的，这些数据集来源于正弦波和随机的分段常数初始条件，并带有周期边界条件，使得该模型能够对复杂流场配置或几何结构产生鲁棒泛化能力。文献中的验证案例，包括具有挑战性的几何配置，证明了相较于传统的二阶有限体积方案有着显著的准确性改进，其解决效率提升为20-60%，并且具有更好的网格收敛性。", "innovation": "本文提出的是一种结合了神经网络和物理信息正则化的新型梯度重建方法。该方法通过引入局部几何信息和局部网格拓扑确保旋转不变性，且能学习出物理约束下的梯度。训练过程中的物理信息正则化包括熵惩罚、总变差减小惩罚和参数正则化。这种方法相比传统的二阶有限体积方案在解决激波主导的区域时能提供更即时、更准确的解决方案，且在保持精度和收敛性的情况下，计算效率得以大幅提高。", "conclusion": "本文提出的方法相较于传统的二阶有限体积方案在计算效率和解决方案精度上均有显著提升，特别是在激波环境中。结合机器学习工具的新型数值求解器能够提高高保真模拟在较粗网格上的运行能力，同时保持关键的稳定性与守恒性特性。这代表了一种新兴的求解器类型，即使用机器学习工具结合传统数值方法，并确保结果满足物理约束。"}
{"llm_update_time": "20250723", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.16808", "html_url": "https://arxiv.org/abs/2507.16808", "title": "通过时序逻辑变形重新审视基于LLM的RTL代码优化", "title_en": "Rethinking LLM-Based RTL Code Optimization Via Timing Logic Metamorphosis", "authors": "Zhihao Xu,Bixin Li,Lulu Wang", "background": "RTL代码优化对于实现高性能和低功耗的数字电路设计至关重要。传统的优化方法依赖手动调优和启发式算法，耗时且容易出错。近年来，有研究提出利用大型语言模型（LLMs）辅助RTL代码优化，可以通过自然语言的描述自动生成优化代码片段，但这方面的研究主要集中于简单案例，未系统性地评估其在复杂时序逻辑代码中的效果。", "innovation": "本文提出了一种新的方法，通过对RTL代码进行时序逻辑变形，系统性地评估基于LLM的RTL代码优化方法的有效性。它包括四个子集，分别针对特定的RTL优化区域。研究发现，LLM基线优化方法在逻辑操作优化方面表现出色，但并不适用于复杂时序逻辑代码中关键的时序控制流优化和时钟域优化，这主要归因于LLM理解时序逻辑的局限。", "conclusion": "LLM基线优化方法在某些方面有效，但对于复杂时序逻辑代码的优化仍面临挑战。为充分利用LLM进行RTL代码优化，未来需进一步研究如何解决这些问题。"}
{"llm_update_time": "20250723", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2406.14103", "html_url": "https://arxiv.org/abs/2406.14103", "title": "通过解耦搜索和路径规划实现高效策略学习", "title_en": "Efficient Strategy Learning by Decoupling Searching and Pathfinding for Object Navigation", "authors": "Yanwei Zheng,Shaopu Feng,Bowen Huang,Chuanlin Lan,Xiao Zhang,Dongxiao Yu", "background": "近期的研究设计了平行子模块来实现搜索和路径规划阶段的不同功能，但在两个阶段之间的奖励信号差异上没有差别对待，导致这些模型往往无法完全训练或在训练场景上过拟合。另一个限制代理学习两阶段策略的瓶颈是空间感知能力，因为现有研究使用了通用视觉编码器，没有考虑导航场景中的深度信息。", "innovation": "提出了一种两阶段奖励机制（TSRM），在一次任务中分离搜索和路径规划的行为，使代理能够在搜索阶段探索更大区域，在路径规划阶段寻找最优路径。此外，提出了一种深度增强掩码自编码器（DE-MAE）的预训练方法，使代理在搜索阶段能够确定已探索和未探索的区域，在路径规划阶段能更准确地定位目标物体和规划路径。还提出了一种新的搜索成功度量方法，考虑搜索路径长度加权的搜索成功度量（SSSPL），以评估代理的搜索能力和探索效率。", "conclusion": "在广泛评估中，该方法在AI2-Thor和RoboTHOR数据集上表现出色，分别在成功率和导航效率方面均优于现有最先进的方法。"}
{"llm_update_time": "20250723", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2403.04311", "html_url": "https://arxiv.org/abs/2403.04311", "title": "Alto: 使用嵌套祖先协调分布式复合AI系统的框架", "title_en": "Alto: Orchestrating Distributed Compound AI Systems with Nested Ancestry", "authors": "Deepti Raghavan,Keshav Santhanam,Muhammad Shahir Rahman,Nayani Modugula,Luis Gaspar Schroeder,Maximilien Cura,Houjun Liu,Pratiksha Thaker,Philip Levis,Matei Zaharia", "background": "复合AI应用将生成语言模型、文档检索器和嵌入模型等子组件串联起来。在复合AI系统中应用传统的系统优化技术，如并行性和流水线化，相当困难，因为每个组件对数据粒度和类型有不同的要求。中间计算经常会生成新的数据，并且文本流可能会被拆分成较小的独立片段（如从文档分割成句子），这些片段随后可能在计算的后期重新聚合。由于这种复杂性，现有的系统不能充分利用并行性和流水线化的优点。", "innovation": "Alto框架自动通过流式处理和并行性优化复合AI查询的执行。Bento引入了一个新的抽象概念——嵌套祖先，这是一种元数据层次结构，允许系统正确跟踪部分输出并跨组件聚合数据，这些组件具有复合AI应用的异构约束。这种元数据从编程模型自动推断得出，使开发人员能够不需手动考虑路由和聚合的细节即可表达复杂的数据流模式。在Alto中实现的四个应用程序表现出来的性能优于或与LangGraph等流行的AI编程框架相当，延迟改善幅度为10-30%。", "conclusion": "Alto通过其嵌套祖先元数据层次结构和自动优化技术，在复合AI系统中成功实现了并行性和流水线化的优化，提高了应用性能。"}
{"llm_update_time": "20250723", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2501.12485", "html_url": "https://arxiv.org/abs/2501.12485", "title": "R2D2: 记忆、重演和基于反思的动态决策制定", "title_en": "R2D2: Remembering, Replaying and Dynamic Decision Making with a Reflective Agentic Memory", "authors": "Tenghao Huang,Kinjal Basu,Ibrahim Abdelaziz,Pavan Kapanipathi,Jonathan May,Muhao Chen", "background": "由于网络代理的广泛使用，需要在复杂的网络环境中设计高效的导航和交互策略。然而，当前模型在导航效率和动作执行方面普遍遇到困难，主要是由于他们对网络结构的有限理解和可预见性。", "innovation": "本文提出了R2D2框架，通过结合‘记得’和‘反思’两种范式，旨在解决上述问题。'记得'范式利用重放缓存帮助代理动态重建网络环境，从而构建详细的以前访问页面的‘地图’，减少导航错误并优化网络交互的决策过程。'反思'范式则允许代理从过去的错误中学习，通过提供错误分析和策略优化机制，提升整体任务表现。", "conclusion": "通过使用WebArena基准评估R2D2，结果表明，与现有方法相比，R2D2有着明显的改进，包括导航错误减少50%及任务完成率提高三倍。研究表明，记忆增强的导航与反思性学习相结合，显著提升了网络代理的能力，可能对自动化客户服务和个人数字助手等应用有益。"}
{"llm_update_time": "20250723", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.16679", "html_url": "https://arxiv.org/abs/2507.16679", "title": "PICACO: 通过总相关优化实现LLM的多元上下文价值对齐", "title_en": "PICACO: Pluralistic In-Context Value Alignment of LLMs via Total Correlation Optimization", "authors": "Han Jiang,Dongyao Zhu,Zhihua Wei,Xiaoyuan Yi,Ziang Xiao,Xing Xie", "background": "In-Context Learning (ICL) 极大地展示了其潜力，可以帮助大型语言模型（LLMs）与人类价值观对齐，减少有害输出并容纳多样化的偏好。然而，LLMs 对输入提示的理解仍然缺乏，限制了ICL的能力去解决价值观冲突，这些冲突经常是多面的，例如刺激与传统之间的冲突。当前的ICL方法面临指令瓶颈挑战，即LLMs在单一提示中难以调和多种意图的价值，导致不完整或有偏见的对齐。", "innovation": "我们提出了PICACO（Pluralistic In-Context Alignment via Correlation Optimization），一个新颖的多元ICL方法。PICACO 无需微调，通过优化一个元指令来更好地引导LLMs理解和调和多种价值，从而提高它们的对齐度。这种方法通过最大化指定价值和LLMs响应之间的总相关性来实现，理论上增强价值相关性同时减少冗余噪声，从而生成有效的价值指令。实验结果表明，PICACO 在多种价值集合上表现良好，与黑盒和开源LLMs兼容，并且优于多个近期的基准方法，即使面对多达8种不同的价值观也能够取得更好的平衡。", "conclusion": "PICACO 是一个有效的ICL方法，能够优化多重价值观而无需微调，通过总相关优化在多个参数集上提升了LLMs的价值对齐能力。此方法在不同LLM中均有优秀表现，并且能够平衡多种不兼容的价值观，显示出强大的适用性和适用范围。"}
{"llm_update_time": "20250723", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.16696", "html_url": "https://arxiv.org/abs/2507.16696", "title": "FISHER: 多模态工业信号综合表示的基础模型", "title_en": "FISHER: A Foundation Model for Multi-Modal Industrial Signal Comprehensive Representation", "authors": "Pingyi Fan,Anbai Jiang,Shuwei Zhang,Zhiqiang Lv,Bing Han,Xinhu Zheng,Wenrui Liang,Junjie Li,Wei-Qiang Zhang,Yanmin Qian,Xie Chen,Cheng Lu,Jia Liu", "background": "随着SCADA系统的快速部署，有效分析工业信号和检测异常状态已成为行业迫切需要解决的问题。由于这些信号具有显著的异质性，即我们概括为M5问题，之前的许多工作都只关注小的子问题，并且使用专门的模型，未能充分利用不同模态间的协同作用和强大的缩放定律。", "innovation": "针对M5信号，作者提出了一种多模态工业信号综合表示的基础模型FISHER。FISHER将短时傅里叶变换（STFT）子带作为建模单元，并采用了教师学生（Teacher-Student）自我监督学习（SSL）框架进行预训练，以支持任意的采样率。同时，作者还开发了RMIS基准测试，评估M5工业信号在多种健康管理任务中的表示能力。与顶级SSL模型相比，FISHER展示了广泛且出色的性能提升，且具有更高效的缩放曲线。", "conclusion": "FISHER不仅在多个健康管理和任务上展示了优异的性能，而且还调查了下游任务的缩放规律，为未来的工作提出了潜在途径。目前，FISHER已经开源可供使用，链接为[this https URL](this https URL)。"}
{"llm_update_time": "20250723", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.16815", "html_url": "https://arxiv.org/abs/2507.16815", "title": "ThinkAct: 通过强化视觉潜概念规划实现视觉-语言-动作推理", "title_en": "ThinkAct: Vision-Language-Action Reasoning via Reinforced Visual Latent Planning", "authors": "Chi-Pin Huang,Yueh-Hua Wu,Min-Hung Chen,Yu-Chiang Frank Wang,Fu-En Yang", "background": "视觉-语言-动作（VLA）推理任务要求代理商解析多模态指令、实现长远规划，并在动态环境中灵活行动。现有方法通常通过端到端的方式训练VLA模型，直接将输入映射为动作，而不进行明确的推理，这限制了其跨多个步骤规划或应对复杂任务变化的能力。", "innovation": "本文提出了一种双系统框架ThinkAct，通过强化视觉潜概念规划连接高层次推理与低层次动作执行。ThinkAct训练多模态LLM生成目标导向的视觉推理计划，这些计划基于目标完成和轨迹一致性与动作对齐的视觉奖励相结合。这些推理计划被压缩成一个视觉计划潜概念，并为下游动作模型提供条件，以在目标环境中实现稳健的动作执行。广泛的实验结果表明，ThinkAct能够实现少量示例下的适应、长跨度规划和自纠正行为等复杂类人智能任务。", "conclusion": "在体感推理和机器人操控基准测试上的广泛实验表明，ThinkAct能够实现少量示例下的适应、长跨度规划和自纠正行为等复杂体感AI任务。"}
{"llm_update_time": "20250723", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.16806", "html_url": "https://arxiv.org/abs/2507.16806", "title": "超越二元奖励：训练模型处理不确定性", "title_en": "Beyond Binary Rewards: Training LMs to Reason About Their Uncertainty", "authors": "Mehul Damani,Isha Puri,Stewart Slocum,Idan Shenfeld,Leshem Choshen,Yoon Kim,Jacob Andreas", "background": "语言模型（LMs）通过强化学习（RL）训练以生成自然语言的“推理链”，其在多个具有挑战性的问答任务上表现出色。当前几乎所有成功的RL推理应用都使用二元奖励函数来评估LM输出的正确性，但这些奖励函数并不惩罚猜测或低置信度的输出，导致模型在其他问题领域生成错误答案的频率增加，降低了校准度。", "innovation": "提出了RLCR（酬赏学习与校准奖励）方法，该方法在提高准确性的同时提高了置信度估计的校准性，通过奖励函数优化，结合了二元正确性评分和Brier评分（一种对置信度估计的评分规则）。证明了这种方法能产生既准确又校准良好的模型，并且在不同数据集上表现出更良好的校准性，同时不损失准确性。", "conclusion": "结果显示，明确优化校准可生成更可靠的推理模型。通过信心加权缩放方法可以在测试时利用口头化信心提升准确性和校准性。"}
{"llm_update_time": "20250723", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2401.13408", "html_url": "https://arxiv.org/abs/2401.13408", "title": "因果框架下感知建模的探索", "title_en": "Toward A Causal Framework for Modeling Perception", "authors": "Jose M. Alvarez,Salvatore Ruggieri", "background": "感知是人们对于相同信息有不同的解释，这是一个认知现象，对于人类决策中的偏见有重要影响。然而，感知在机器学习（ML）中的研究仍然不足。由于现代决策流程往往部分或完全自动化，依赖于ML应用，而流程中会涉及人类专家。因此，当两位专家对同一个ML模型的实例或解释有不同的看法时，该如何进行处理是一个重要问题。", "innovation": "本文提出了一个基于因果推理的方法来建模感知。利用结构因果模型（SCM）来定义感知和专家决策过程中的因果关系。定义了两种类型的概率因果感知：结构感知和参数感知。并通过一系列现代决策流程的例子展示了这个框架，并强调了在公平的机器学习中解决感知问题的重要性。", "conclusion": "本文通过构建一个基于因果推理的感知框架，将个人经验作为因果知识融入到专家决策过程中，并通过具体例子展示了该框架的应用，强调了在公平的机器学习环境中解决感知问题的必要性和潜在应用。"}
{"llm_update_time": "20250723", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2505.16938", "html_url": "https://arxiv.org/abs/2505.16938", "title": "InternAgent: 当代理人成为科学家——从假设到验证构建闭环系统", "title_en": "InternAgent: When Agent Becomes the Scientist -- Building Closed-Loop System from Hypothesis to Verification", "authors": "InternAgent Team:Bo Zhang,Shiyang Feng,Xiangchao Yan,Jiakang Yuan,Runmin Ma,Yusong Hu,Zhiyin Yu,Xiaohan He,Songtao Huang,Shaowei Hou,Zheng Nie,Zhilong Wang,Jinyao Liu,Tianshuo Peng,Peng Ye,Dongzhan Zhou,Shufei Zhang,Xiaosong Wang,Yilan Zhang,Meng Li,Zhongying Tu,Xiangyu Yue,Wangli Ouyang,Bowen Zhou,Lei Bai", "background": "人工智能（AI）正在加速科学研究范式的转变，不仅提高了研究效率，还推动了创新。在此背景下，本文介绍了InternAgent，这是一种统一的闭环多智能体框架，用于在多个科学领域开展自主科学研究（ASR），使研究人员能够以前所未有的速度和精度解决这些领域的复杂问题。", "innovation": "InternAgent 提出了三个关键优势：1) 可扩展性：显示了其在包括12个科学研究任务在内的广泛领域的通用性，能够生成创新的想法以提高基线代码的性能。2) 互动性：提供了一个供人类专家反馈和多智能体自动端到端过程互动的界面，允许将领域专家知识无缝集成。3) 效率：在多个科学领域实现了显著的性能提升，且所需时间显著少于人力努力。例如，在反应产率预测上，仅用了12小时就从27.6%提升到了35.4%；在增强子活性预测中，通过仅4小时的处理，准确率从0.65提高到0.79；在2D语义分割中，精度在短短30小时内从78.8%提升到了81.0%。", "conclusion": "InternAgent 提供了一种新的方法，通过统一的闭环多智能体框架在科学领域实现自主研究，提升了研究效率，增强了创新性，并展示了强大的应用潜力。"}
{"llm_update_time": "20250723", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2505.19956", "html_url": "https://arxiv.org/abs/2505.19956", "title": "DCG-SQL: 使用深度上下文模式链接图增强Text-to-SQL的在场学习", "title_en": "DCG-SQL: Enhancing In-Context Learning for Text-to-SQL with Deep Contextual Schema Link Graph", "authors": "Jihyung Lee,Jin-Seop Lee,Jaehoon Lee,YunSeok Choi,Jee-Hyong Lee", "background": "Text-to-SQL任务将自然语言问题转换为SQL查询，借助超大型语言模型（LLMs）的上下文学习方法取得了进展。但现有方法在性能上与随机选择的示范相比几乎没有提升，并且在使用小规模LLMs（例如Llama 3.1-8B）时性能显著下降。这表明，现有方法高度依赖于超大规模LLMs的内部能力，而不是有效地检索有用示范。", "innovation": "本文提出了一种有效检索示范并生成SQL查询的新方法。通过构建包含问题与数据库模式项之间关键信息和语义关系的深度上下文模式链接图，该图基于图结构有效表示Text-to-SQL样本，并为在场学习检索有用示范。实验结果在Spider基准测试中展示了该方法的有效性，表明其在性能和效率上的一致改进，无论是在超大规模LLMs还是小规模LLMs的情况下。", "conclusion": "我们的方法在Spider基准测试中展示了在性能和效率上的一致改进，证明了深度上下文模式链接图在增强基于超大规模LLMs的在场学习能力方面的作用。代码可在此处访问： this https URL 和 this https URL。"}
{"llm_update_time": "20250723", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.08529", "html_url": "https://arxiv.org/abs/2507.08529", "title": "稀粒度概念稀疏激活与层次知识图谱融合框架在罕见病诊断中的应用", "title_en": "A Multi-granularity Concept Sparse Activation and Hierarchical Knowledge Graph Fusion Framework for Rare Disease Diagnosis", "authors": "Mingda Zhang,Na Zhao,Jianglong Qin,Guoyu Ye,Ruixiang Tang", "background": "医疗大型语言模型在罕见病诊断中面临挑战，主要由于知识表示不足、概念理解受限和临床推理能力有限。这使得医学生物大语言模型难以有效处理罕见疾病诊断问题。本文探讨了基于多粒度稀疏激活与层次知识图谱融合的罕见病诊断框架，旨在提高诊断准确性，优化信息质量，提升临床推理水平，降低罕见病患者的诊断过程难度与时间和经济成本。", "innovation": "本文提出了结合多粒度稀疏激活与层级知识图谱的罕见病诊断框架。该框架采用了四种互补的匹配算法，并通过多样性的控制和五级退路策略实现精确的概念激活。该框架设计了一个三层知识图谱（分类学、临床特征和实例），提供了结构化且及时的上下文信息。实验结果显示，在BioASQ罕见病数据集上的效能显著提升，BLEU得分提高了0.13，ROUGE提高了0.10，诊断准确率提高了0.25，最佳模型达到0.92的诊断准确率，超过了0.90的临床标准。专家评估证实了信息质量、推理和专业表达的提升。", "conclusion": "所提出的方法能够有效减少罕见病患者的诊疗过程中的不确定性和焦虑，展示了在罕见病诊断中的巨大潜力。"}
{"llm_update_time": "20250723", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.07893", "html_url": "https://arxiv.org/abs/2507.07893", "title": "集成提示工程和多维知识图谱的法律纠纷分析框架", "title_en": "An Integrated Framework of Prompt Engineering and Multidimensional Knowledge Graphs for Legal Dispute Analysis", "authors": "Mingda Zhang,Na Zhao,Jianglong Qing,Qing xu,Kaiwen Pan,Ting luo", "background": "本研究提出了一种结合提示工程与多维知识图谱的框架，以提高大规模语言模型（LLMs）在法律纠纷分析中的表现。现有的法律纠纷分析系统可能在精细度和准确性上有所欠缺，本研究旨在通过改进提示工程和利用知识图谱，提高法律纠纷分析的准确性和理解深度。", "innovation": "研究提出了一种三层提示结构（任务定义、知识背景、推理指导）和三层知识图谱（法律本体论、表示层、实例层），并通过直接代码匹配、语义向量相似性、本体路径推理和词素分割四种支持方法，实现了精确的法律概念检索，从而显著提高了敏感性、特异性及引用准确性，展示了在一个新的技术支持下的智能法律辅助系统的可能性。", "conclusion": "研究取得了显著效果，通过广泛的测试，系统的敏感性提高了9.9%-13.8%，特异性提高了4.8%-6.7%，引用准确性提高了22.4%-39.7%。因此，该框架不仅提供了更精确的法律分析和对司法逻辑的理解，还为智能法律辅助系统提供了新的技术和方法。"}
{"llm_update_time": "20250723", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.14447", "html_url": "https://arxiv.org/abs/2507.14447", "title": "Routine：企业环境中LLM代理系统结构化规划框架", "title_en": "Routine: A Structural Planning Framework for LLM Agent System in Enterprise", "authors": "Guancheng Zeng,Xueyi Chen,Jiawang Hu,Shaohua Qi,Yaxuan Mao,Zhantao Wang,Yifan Nie,Shuang Li,Qiuyang Feng,Pengxu Qiu,Yujia Wang,Wenqiang Han,Linyan Huang,Gang Li,Jingjing Mo,Haowen Hu", "background": "企业在部署代理系统时面临的主要挑战包括通用模型缺少特定领域的流程知识，导致计划不系统、关键工具缺失及执行稳定性差。为解决这些问题，该文提出了一种名为Routine的多步骤代理规划框架，该框架具有清晰的结构、明确的指导以及无缝参数传递，以指导代理执行多步骤的工具调用任务，并提高其执行稳定性。", "innovation": "提出的Routine框架旨在解决代理系统部署中的常见挑战，通过设计清晰的结构、明确的指令和无缝的参数传递，提高了多步骤工具调用任务的执行准确性和稳定性。在实际企业环境中的评估显示，Routine显著提高了模型工具调用的执行准确性。Fine-tuning Qwen3-14B模型后，准确性提升至88.2%，并在特定场景测试中接近GPT-4o的表现。通过基于Routine的蒸馏方法生成的特定场景、多步骤工具调用数据集进一步将模型准确性提升至95.5%，表明Routine能够有效提炼特定领域的工具使用模式，增强模型对新场景的适应性。", "conclusion": "实验结果表明，Routine提供了一种实际且可访问的构建稳定代理工作流的方法，加速了代理系统在企业环境中的部署和采用，并推动了人工智能过程技术愿景的发展。"}
{"llm_update_time": "20250723", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2402.04247", "html_url": "https://arxiv.org/abs/2402.04247", "title": "AI科学家的风险：优先考虑保障而非自主", "title_en": "Risks of AI Scientists: Prioritizing Safeguarding Over Autonomy", "authors": "Xiangru Tang,Qiao Jin,Kunlun Zhu,Tongxin Yuan,Yichi Zhang,Wangchunshu Zhou,Meng Qu,Yilun Zhao,Jian Tang,Zhuosheng Zhang,Arman Cohan,Zhiyong Lu,Mark Gerstein", "background": "大型语言模型驱动的AI科学家展示了自主进行实验和促进跨学科科学发现的巨大潜力，但同时也带来了新型的安全挑战。虽然这些人工智能代理的能力很有前景，但它们也引发了关于其误用所关联潜在风险的担忧，并强调需要采取安全措施。已有文献对该领域的探讨非常有限，因此需要进一步研究这些安全挑战及其潜在风险。", "innovation": "本文提出一个三元素框架（人类监管、代理对齐和环境反馈理解），以减轻这些识别的风险。此外，作者强调了保护AI科学家存在的局限性和挑战，并提倡开发更优模型、稳健基准和全面的法规，以应对这些风险。", "conclusion": "文章总结了AI科学家存在的潜在风险，并提出了一种综合框架来缓解这些风险，同时也指出了当前保护AI科学家的局限性和挑战。"}
{"llm_update_time": "20250723", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.12821", "html_url": "https://arxiv.org/abs/2507.12821", "title": "评估机器中的适应性世界模型：新颖游戏的运用", "title_en": "Assessing Adaptive World Models in Machines with Novel Games", "authors": "Lance Ying,Katherine M. Collins,Prafull Sharma,Cedric Colas,Kaiya Ivy Zhao,Adrian Weller,Zenna Tavares,Phillip Isola,Samuel J. Gershman,Jacob D. Andreas,Thomas L. Griffiths,Francois Chollet,Kelsey R. Allen,Joshua B. Tenenbaum", "background": "人类智能展现出了适应和解决新奇和陌生环境中问题的卓越能力，这很大程度上归因于构建和优化环境内部表征的能力。然而，当前AI领域对世界模型的理解和评估依然有限，主要集中于从大数据中学习的静态表示，而忽视了通过互动和探索快速学习这些表示的效率和实效。", "innovation": "作者呼吁一种新的评估框架来评估AI中的适应性世界模型，提出了基于新颖设计的游戏套件的新基准测试方法。这些游戏具备真正而深刻的持续新颖性，能够挑战和评估智能体快速构建世界模型的能力。", "conclusion": "这一新评估框架意在激励未来对AI世界模型的评估，并朝着构建能够快速适应和实现稳健泛化的类人类智能系统的目标迈出关键一步，这是通用人工智能的关键组成要素。"}
{"llm_update_time": "20250723", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.21734", "html_url": "https://arxiv.org/abs/2506.21734", "title": "层级推理模型", "title_en": "Hierarchical Reasoning Model", "authors": "Guan Wang,Jin Li,Yuhao Sun,Xing Chen,Changling Liu,Yue Wu,Meng Lu,Sen Song,Yasin Abbasi Yadkori", "background": "推理是制定和执行复杂的目标导向操作序列的过程，在人工智能领域仍然是一个关键挑战。当前的大语言模型主要依赖于链式思考技术，但这些技术存在任务分解脆弱、数据需求广泛以及高延迟等问题。", "innovation": "受人脑分层、多时标处理机制的启发，本文提出了一种名为层级推理模型(HRM)的新颖递归架构。HRM能够在单次前向通过中执行顺序推理任务，无需监督中间过程，通过两个相互依赖的递归模块实现：一个高层模块负责缓慢抽象规划，一个低层模块负责快速详细计算。HRM仅使用2700万参数，在仅1000个训练样本的情况下，就达到了在复杂数独谜题和大型迷宫中的几乎完美性能。", "conclusion": "HRM在层级推理基准测试（如Abstraction and Reasoning Corpus (ARC)）上优于规模更大且上下文窗口更长的模型。这些结果表明HRM具有成为通用计算和通用推理系统的革命性进展的潜力，有望推动通用人工智能技术的发展。"}
{"llm_update_time": "20250723", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.15855", "html_url": "https://arxiv.org/abs/2507.15855", "title": "Gemini 2.5 Pro 能够在2025年国际数学奥林匹克竞赛中赢得金牌", "title_en": "Gemini 2.5 Pro Capable of Winning Gold at IMO 2025", "authors": "Yichen Huang,Lin F. Yang", "background": "国际数学奥林匹克（IMO）的题目独特地要求深刻洞察、创造力和形式推理。虽然大型语言模型（LLMs）在如AIME这样的数学基准测试中表现出色，但在奥林匹克级别任务上却面临挑战。本文使用了Google的Gemini 2.5 Pro，避免了数据污染，在新的IMO 2025题目上取得了突破。", "innovation": "研究采用了Gemini 2.5 Pro，并通过一个自我验证管道和谨慎的提示设计，成功解决了5个（总共6个）IMO 2025新发布的题目中的5个。这一结果突显了发展最佳策略的重要作用，以完全挖掘强大LLMs在复杂推理任务中的潜力。", "conclusion": "这一研究结果强调了开发最佳策略的重要性，以便最大限度地利用强大LLMs进行复杂推理任务。"}
{"llm_update_time": "20250723", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2402.14922", "html_url": "https://arxiv.org/abs/2402.14922", "title": "预训练模型中的知识蒸馏实用见解", "title_en": "Practical Insights into Knowledge Distillation for Pre-Trained Models", "authors": "Norah Alballa,Ahmed M. Abdelmoniem,Marco Canini", "background": "本研究探讨了在预训练模型中增强知识蒸馏（KD）过程的方法，这一领域在知识迁移领域具有重要意义，特别是在分布式训练和联邦学习环境中。这些环境中，知识蒸馏有助于减少通信需求，并能兼容多种模型架构。尽管已经采用了许多KD方法来在预训练模型之间进行知识传递，但对于这些场景中KO的应用仍然缺乏全面理解。", "innovation": "本文对比了多种KD技术，包括标准KD、调优KD（通过优化温度和权重参数）、深度双向学习以及数据分区KD。我们根据不同的数据分布策略评估了这些方法，并确定了每种方法最有效的应用场景。此外，通过详细的超参数调优分析，确定了优化模型性能的关键调整点。研究发现，KD在减少通信回合数并加速训练流程方面对改进联邦学习具有重要作用。", "conclusion": "通过填补现有研究中的空白，本文提供了在协作和联邦学习框架中利用KD的实用框架，明确了不同数据分区场景下的最优超参数设置。"}
{"llm_update_time": "20250723", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.02139", "html_url": "https://arxiv.org/abs/2506.02139", "title": "语言模型的统一认知意识理论：对语义的锚定、激活阈值和涌现推理", "title_en": "The Unified Cognitive Consciousness Theory for Language Models: Anchoring Semantics, Thresholds of Activation, and Emergent Reasoning", "authors": "Edward Y. Chang,Zeyneb N. Kaya,Ethan Chang", "background": "大型语言模型（LLMs）拥有大量的潜在模式，但缺乏结构化的引导，因此缺少明确的推理、语义基础和目标导向的智能。研究者需要一种统一的方法，重新解释LLMs作为一个无意识的基底，并通过外部机制、few-shot提示、检索增强生成（RAG）、微调和多智能体推理来具体化这些潜在的表示。", "innovation": "提出了统一认知意识理论（UCCT），这是一个统一的模型，将LLMs重新解释为需要外部机制、few-shot提示、RAG、微调和多智能体推理的无意识基底。UCCT通过贝叶斯公式的形式化，解释了观察到的各种任务中的能力突变现象。UCCT统一了之前不相关的技术，如few-shot提示、RAG、微调和多智能体推理，作为对一般锚定架构的特殊案例。通过简单的数学、视觉识别和结构化辩论任务的研究，验证了UCCT的预测能力。并通过三进制系统的算术实验，验证了UCCT的理论。", "conclusion": "UCCT证明了LLMs本质上只是无意识的模式存储库，没有内在的智能。智能仅在外部锚定机制为这些潜在模式赋予目标语义时才能涌现，将无意识的表示转化为有意识的目标导向能力。"}
{"llm_update_time": "20250723", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2310.07497", "html_url": "https://arxiv.org/abs/2310.07497", "title": "通过样本驱动控制实现联邦持续学习的节能实时传感", "title_en": "Energy-Efficient and Real-Time Sensing for Federated Continual Learning via Sample-Driven Control", "authors": "Minh Ngoc Luu,Minh-Duong Nguyen,Ebrahim Bedeer,Van Duc Nguyen,Dinh Thai Hoang,Diep N. Nguyen,Quoc-Viet Pham", "background": "智能实时传感（RTS）系统必须不断获取、更新、整合和应用知识以适应现实世界的动态变化。在这种背景下，管理分布式智能需要联邦持续学习（FCL）。然而，在FCL系统中有效捕捉RTS数据的多样化特征带来了重大挑战，包括严重消耗计算和通信资源、增加能源成本，最终导致整体性能下降。这些挑战使得需要研究RTS数据从理想状况到实践应用的迁移如何影响人工智能模型的性能，并开发出新的方法来解决这些问题。基于这种观察，我们提出了一种新的样本驱动控制联邦持续学习（SCFL）技术，该技术专门设计用于具有RTS能力的移动边缘网络。特别地，SCFL 是一个优化问题，通过利用采样过程同时最小化泛化差距并提高整体准确性，同时保持 FCL 框架的能效。", "innovation": "我们通过利用泛化差距的概念，研究了RTS数据分布从理想状态到实践应用的迁移如何影响人工智能模型的性能，并开发了一种新的样本驱动控制联邦持续学习（SCFL）技术。具体来说，SCFL是一个优化问题，通过利用采样过程同时最小化泛化差距并提高整体准确性，同时保持FCL框架的能效。为了解决这个复杂且时变的优化问题，我们引入了一种带有显式和隐式约束的新软演员-评论家算法（A2C-EI）。实验结果显示，与其它深度强化学习基准相比，我们能够实现更高的效率，并且SCFL可以在降低高达85%的能耗的同时保持FL收敛和及时数据传输。", "conclusion": "通过提出SCFL技术和A2C-EI算法，我们解决了联邦持续学习中因RTS数据分布变化导致的性能下降和能耗增加等问题。我们的研究不仅提高了RTS系统的性能，还显著降低了能耗，同时保持了框架的收敛性和数据传输的及时性。"}
{"llm_update_time": "20250723", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.14468", "html_url": "https://arxiv.org/abs/2507.14468", "title": "BioGraphFusion: 图表知识嵌入以实现生物学完成与推理", "title_en": "BioGraphFusion: Graph Knowledge Embedding for Biological Completion and Reasoning", "authors": "Yitong Lin,Jiaying He,Jiahe Chen,Xinnan Zhu,Jianwei Zheng,Tao Bo", "background": "生物医学知识图谱（KGs）对于药物发现和疾病理解至关重要，但其完成和推理操作却充满挑战。嵌入式知识（KE）方法能够捕捉全局语义，但难以实现动态结构集成；图神经网络（GNNs）在局部表现优异，但往往缺乏语义理解。即使包括语言模型在内的集成方法也常常难以实现语义理解和结构学习之间的深入、适应性和协同进化。因此，如何在复杂生物医学KGs中实现这两者之间的持续、互惠的相互提升是至关重要的问题。", "innovation": "我们提出了一种新的框架BioGraphFusion，用于深度协作语义和结构学习。通过张量分解建立全局语义基础，并利用LSTM机制动态地在图传播过程中改进关系嵌入。这促进了语义理解与结构学习之间的适配相互作用，进一步通过查询引导的子图构建和混合评分机制增强。跨三个关键生物医学任务的实验结果表明，BioGraphFusion的性能优于最先进的嵌入式知识、图神经网络和集成模型。切洛尼恶性黑素瘤1（CMM1）的研究案例展示了它揭示生物医学意义途径的能力。", "conclusion": "BioGraphFusion展示了在深度合作语义和结构学习方面的优越性能，能够有效提升生物医学KGs的完成和推理效果。"}
{"llm_update_time": "20250723", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.15844", "html_url": "https://arxiv.org/abs/2507.15844", "title": "面向自适应推理的分层预算策略优化", "title_en": "Hierarchical Budget Policy Optimization for Adaptive Reasoning", "authors": "Shangke Lyu,Linjuan Wu,Yuchen Yan,Xingyu Wu,Hao Li,Yongliang Shen,Peisheng Jiang,Weiming Lu,Jun Xiao,Yueting Zhuang", "background": "大型推理模型通过广泛的链式思考生成表现出色，但在使用统一的推理策略时，面对不同复杂度的问题表现出显著的计算效率低下。当前，效率导向的训练面临探索空间塌陷的问题，导致长推理路径被系统性地抑制。现有方法要么施加外部约束，要么依赖于离散模式选择，这些方法未能解决上述挑战。", "innovation": "提出了一种分层预算策略优化（HBPO）框架，该框架允许模型在不牺牲能力的情况下根据具体的问题类型学习合适的推理深度。HBPO通过层次化的预算探索，将展开样本划分为多个具有不同标记预算的子组，旨在高效分配资源同时防止能力退化。引入了与问题复杂度相匹配的不同奖励机制，激励模型发现任务需求与计算努力之间的自然对应关系。该方法的核心创新在于能够根据问题复杂度自适应地调整推理深度，从而实现推理效率和模型能力的同时优化。", "conclusion": "大量实验证明，相比基线模型，HBPO可将平均标记使用量降低60.6%，同时在四个推理基准上提高了3.14%的准确性。此外，HBPO能够自动调整推理深度，避免了先前方法中人工施加的外部约束或依赖于离散模式选择的限制，展示了自我适应的特点。这一结果表明，推理的效率和能力并不是不可调和的矛盾，高效的分层训练框架可以同时优化这两方面。"}
{"llm_update_time": "20250723", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2405.18383", "html_url": "https://arxiv.org/abs/2405.18383", "title": "2024 BraTS Meningioma Radiotherapy Planning Automated Segmentation Challenge分析", "title_en": "Analysis of the 2024 BraTS Meningioma Radiotherapy Planning Automated Segmentation Challenge", "authors": "Dominic LaBella,Valeriia Abramova,Mehdi Astaraki,Andre Ferreira,Zhifan Jiang,Mason C. Cleveland,Ramandeep Kang,Uma M. Lal-Trehan Estrada,Cansu Yalcin,Rachika E. Hamadache,Clara Lisazo,Adrià Casamitjana,Joaquim Salvi,Arnau Oliver,Xavier Lladó,Iuliana Toma-Dasu,Tiago Jesus,Behrus Puladi,Jens Kleesiek,Victor Alves,Jan Egger,Daniel Capellán-Martín,Abhijeet Parida,Austin Tapp,Xinyang Liu,Maria J. Ledesma-Carbayo,Jay B. Patel,Thomas N. McNeal,Maya Viera,Owen McCall,Albert E. Kim,Elizabeth R. Gerstner,Christopher P. Bridge,Katherine Schumacher,Michael Mix,Kevin Leu,Shan McBurney-Lin,Pierre Nedelec,Javier Villanueva-Meyer,David R. Raleigh,Jonathan Shapey,Tom Vercauteren,Kazumi Chia,Marina Ivory,Theodore Barfoot,Omar Al-Salihi,Justin Leu,Lia M. Halasz,Yuri S. Velichko,Chunhao Wang,John P. Kirkpatrick,Scott R. Floyd,Zachary J. Reitman,Trey C. Mullikin,Eugene J. Vaios,Christina Huang,Ulas Bagci,Sean Sachdev,Jona A. Hattangadi-Gluth,Tyler M. Seibert,Nikdokht Farid,Connor Puett,Matthew W. Pease,Kevin Shiue,Syed Muhammad Anwar,Shahriar Faghani,Peter Taylor,Pranav Warman,Jake Albrecht,András Jakab,Mana Moassefi,Verena Chung,Rong Chai,Alejandro Aristizabal,Alexandros Karargyris,Hasan Kassem,Sarthak Pati,Micah Sheller,Nazanin Maleki,Rachit Saluja,Florian Kofler,Christopher G. Schwarz,Philipp Lohmann,Phillipp Vollmuth,Louis Gagnon,Maruf Adewole,Hongwei Bran Li,Anahita Fathi Kazerooni,Nourel Hoda Tahon,Udunna Anazodo,Ahmed W. Moawad,Bjoern Menze,Marius George Linguraru,Mariam Aboian,Benedikt Wiestler,Ujjwal Baid,Gian-Marco Conte,Andreas M. Rauschecker,Ayman Nada,Aly H. Abayazeed", "background": "该挑战旨在利用迄今为止最大的多机构数据集（包含750例放射治疗计划脑MRI，每例均有专家标注的目标标签，适用于成功切除或术后脑膜瘤患者的常规外部束放射治疗或立体定向放射外科治疗），推进自动分割算法的发展。每个病例都包括一个去标识的3D术后对比T1加权放射治疗计划MRI及其原始获取空间，并附带一个单一标签的“目标体积”，代表较大的肿瘤体积（GTV）及其任何术后风险位置。目标体积标注遵循已建立的放射治疗规划协议，确保跨案例和机构的一致性，并由专家神经放射学家和放射肿瘤学家审批。", "innovation": "共有六支参赛队伍开发、容器化并评估了使用该全面数据集的自动化分割模型。排名依据为改良后的病灶级dice相似系数（DSC）和95%海德福距离（95HD）。报告的最佳平均病灶级DSC和95HD分别为0.815和26.92毫米。BraTS-MEN-RT挑战有望显著推进自动化放射治疗规划，通过精确的肿瘤分割和定制治疗，最终改善患者预后。", "conclusion": "本文描述了BraTS-MEN-RT挑战的设计和结果。"}
{"llm_update_time": "20250723", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2408.08655", "html_url": "https://arxiv.org/abs/2408.08655", "title": "FLAIN: 通过翻转低激活输入神经元的权重更新来缓解联邦学习中的后门攻击", "title_en": "FLAIN: Mitigating Backdoor Attacks in Federated Learning via Flipping Weight Updates of Low-Activation Input Neurons", "authors": "Binbin Ding,Penghui Yang,Sheng-Jun Huang", "background": "联邦学习（FL）允许多个客户端在中央服务器的协调下协同训练机器学习模型，同时保持隐私。然而，中央服务器无法直接监控本地训练过程，为恶意客户端提供了在模型中植入后门的机会。研究发现，后门攻击利用特定的神经元，这些神经元只在恶意输入时激活，而在纯净数据中保持静默。基于这一洞察，本文提出了一种新的防御方法，称为低激活输入神经元的权重更新反转（FLAIN），以抵御联邦学习中的后门攻击。", "innovation": "FLAIN方法在完成全局训练后，使用辅助数据集识别低激活输入神经元，并迭代地反转与这些神经元相关的权重更新。通过逐步提高低激活神经元的阈值，直到模型在辅助数据上的性能显著下降为止。广泛的实验表明，FLAIN可以在多种场景下有效降低后门攻击的成功率，包括非独立同分布（Non-IID）数据分布和高恶意客户端比例（MCR），同时对纯净数据的性能影响最小。", "conclusion": "实验结果证明FLAIN在多种场景中有效地降低了后门攻击的成功率，同时对纯净数据的性能影响很小。"}
{"llm_update_time": "20250723", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2408.00998", "html_url": "https://arxiv.org/abs/2408.00998", "title": "FBSDiff: 引入频带替代的扩散特征插件式频率带替换方法以实现高可控性的文本驱动图像翻译", "title_en": "FBSDiff: Plug-and-Play Frequency Band Substitution of Diffusion Features for Highly Controllable Text-Driven Image Translation", "authors": "Xiang Gao,Jiaying Liu", "background": "大规模文本到图像的扩散模型是生成人工智能和多模态技术演进中的革命性里程碑，能够根据自然语言文本提示生成美妙的图像。然而，这些模型缺乏可控性的问题限制了它们在实际内容创作中的应用。因此，研究人员开始关注利用参考图像来控制文本到图像的合成，即根据文本提示对参考图像进行操纵（或编辑），被称为文本驱动的图像到图像翻译。该论文提出了一种新型、简洁且高效的方案，通过在不进行任何模型训练、微调或在线优化的情况下，将预训练的大规模文本到图像（T2I）扩散模型适应图像到图像（I2I）范式，实现了高质量且多样的文本驱动I2I转换。", "innovation": "该论文提出了一个创新的方法，通过在DCT频谱空间中分解具有不同频率带宽的扩散特征来引导T2I生成，并设计了一个新的频带替换层，实现在无需任何模型训练或在线优化的情况下，对参考图像进行动态控制到T2I生成结果。通过调整代替频带的类型和带宽，可以灵活控制参考图像的作用因素及其强度。广泛的定性和定量实验验证了该方法在I2I转换的视觉质量、多样性和可控性方面优于相关方法。代码已在公开提供，链接为：this https URL", "conclusion": "该方法展示了文本驱动的图像到图像翻译的高可控性，并且在视觉质量、多样性和可控性方面优于相关方法。"}
{"llm_update_time": "20250723", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2410.00081", "html_url": "https://arxiv.org/abs/2410.00081", "title": "从稳态到资源共享：生物和经济上对齐的多目标多智能体AI安全基准", "title_en": "From homeostasis to resource sharing: Biologically and economically aligned multi-objective multi-agent AI safety benchmarks", "authors": "Roland Pihlakas,Joel Pyykkö", "background": "研究安全、同化的人工智能系统需要全面的实证测试，然而，现有的许多基准测试忽略了生物和经济学等关键主题，这些主题是描述我们需求和偏好的经验证据丰富的重要科学。本文旨在填补这一空白，关注现有主流AI安全性讨论中被忽视的生物和经济动机主题，例如一套强调稳态、边际收益递减、可持续原则和资源共享的多目标、多智能体对齐基准测试。这些基准环境通过模拟关键陷阱和挑战，如无限最大化稳态目标、牺牲其他目标进行过度优化、忽视安全约束或耗尽共享资源，来说明这些挑战的特点。", "innovation": "引入了多目标、多智能体对齐基准测试，强调了稳态、边际收益递减原则、可持续性和资源共享等方面，在当前主流AI安全性讨论中突出了生物和经济因素。此外，提出了八个基准环境以展示人工智能系统的关键陷阱和挑战。", "conclusion": "本文提出的生物和经济上对齐的多目标多智能体AI安全基准，强调了稳态、边际收益递减原则、可持续性和资源共享等方面的知识，为未来全面测试和评估人工智能系统的安全性提供了新的方向。"}
{"llm_update_time": "20250723", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2405.17527", "html_url": "https://arxiv.org/abs/2405.17527", "title": "Unisolver: PDE-Conditional Transformers Are Universal PDE Solvers", "title_en": "Unisolver: PDE-Conditional Transformers Are Universal PDE Solvers", "authors": "Hang Zhou,Yuezhou Ma,Haixu Wu,Haowen Wang,Mingsheng Long", "background": "深度模型近年来被认为是解决偏微分方程（PDEs）的一种有前途的工具，这被称为神经PDE求解器。尽管通过仿真数据或物理启发式损失训练的神经求解器可以合理解决PDEs，但它们主要局限于某些特定的PDE实例，例如特定方程的有限组系数。这限制了它们解决多种PDE的能力，阻碍了其作为数值求解器的实用替代模型的发展。", "innovation": "Unisolver是一种新颖的Transformer模型，通过多样化的数据训练，并针对多种PDE进行条件化，旨在实现通用的神经PDE求解器，能够解决广泛的PDEs。受PDE数学结构的启发，Unisolver定义了一套完整的PDE组件，并将其灵活嵌入为领域特定和点特定的深层条件，以对Transformer PDE求解器进行条件化。通过结合物理洞察和最近的Transformer进展，Unisolver实现了在三个具有挑战性的大规模基准测试上的持续最先进的表现，并展示了出色的性能和泛化能力。", "conclusion": "Unisolver在三个具有挑战性的大规模基准测试上实现了持续最先进的表现，展示了出色的性能和泛化能力。"}
{"llm_update_time": "20250723", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.14111", "html_url": "https://arxiv.org/abs/2507.14111", "title": "CUDA-L1：通过对比强化学习提高CUDA优化", "title_en": "CUDA-L1: Improving CUDA Optimization via Contrastive Reinforcement Learning", "authors": "Xiaoya Li,Xiaofei Sun,Albert Wang,Jiwei Li,Chris Shum", "background": "由于大型语言模型（LLM）的迅速发展，对GPU计算资源的需求呈指数增长，这迫切需要自动CUDA优化策略。尽管在代码生成方面取得了一些进展，但现有的SOTA模型在提高CUDA速度方面成功率较低。因此，需要一个可以有效地进行CUDA优化且无需人类专业知识或领域知识的自动化框架。", "innovation": "该论文提出了一种自动强化学习框架CUDA-L1，用于CUDA优化。CUDA-L1通过仅使用基于加速的奖励信号，将性能表现不佳的LLM转变为有效的CUDA优化器。该模型在NVIDIA A100上训练，实现了KernelBench中250个CUDA内核的平均17.7倍的速度提升，峰值提升达到449倍。此外，模型还展示了良好的跨GPU架构的可移植性，分别在H100、RTX 3090、L40、H800和H20上实现了平均17.8、19.0、16.5、14.7和13.9倍的速度提升。CUDA-L1还展示了发现CUDA优化技术、学习有效结合它们以实现最佳性能、揭示CUDA优化的基本原则以及识别非显而易见的性能瓶颈的能力。", "conclusion": "CUDA-L1展示了强化学习可以通过使用基于速度提升的奖励信号，将一个原本表现不佳的LLM转变为有效的CUDA优化器，无需人类的专业知识或领域知识。此外，该预训练的RL模型能够将获得的推理能力应用于新的内核，开启了自动优化CUDA操作的新可能性，有望大大提升GPU效率并缓解GPU计算资源的压力。"}
{"llm_update_time": "20250723", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2410.01738", "html_url": "https://arxiv.org/abs/2410.01738", "title": "VitaGlyph: 增强艺术字体设计的灵活双分支扩散模型", "title_en": "VitaGlyph: Vitalizing Artistic Typography with Flexible Dual-branch Diffusion Models", "authors": "Kailai Feng,Yabo Zhang,Haodong Yu,Zhilong Ji,Jinfeng Bai,Hongzhi Zhang,Wangmeng Zuo", "background": "艺术字体是一种通过想象和可读的方式可视化输入字符含义的技术。现有方法使用文本到图像的扩散模型直接设计输入字符的整体几何和纹理，导致难以同时确保创意性和可读性。本文提出了一种无需训练的双分支方法VitaGlyph，能够在可控的几何变化下灵活设计艺术字体，同时保持可读性。VitaGlyph的关键见解是将输入字符视为由主体和周围环境组成的场景，并通过不同程度的几何变换进行渲染。通过这种方法，生成的艺术字体不仅更加美观和创造性，还能维持整体的可读性。具体而言，VitaGlyph通过三个阶段的框架实现：知识获取利用大语言模型为主体和周围环境设计文本描述；区域解释检测最符合主体描述的部分并使用语义字体进行结构精炼；注意力合成生成分别渲染主体和周围环境区域的纹理并在注意力机制下进行融合。实验结果证明，VitaGlyph不仅实现了更好的艺术性和可读性，还能展示多种定制的概念，有助于更富有创造性和美观的艺术字体生成。我们的代码将公开展示。", "innovation": "VitaGlyph 提出了一种无需训练的双分支方法，通过将输入字符视为由主体和周围环境组成，并通过不同程度的几何变换进行渲染，实现能够可控变化几何形状同时保持可读性的艺术字体设计。具体的实现框架包括知识获取、区域解释和注意力合成生成。此外，VitaGlyph 的方法还在提高视觉吸引力和创造性方面表现出色。", "conclusion": "实验结果表明，VitaGlyph 在艺术性和可读性方面表现出色，并能够同时展示多种定制的概念。这种方法为更具创意和美学的艺术字体生成提供了支持。因此，VitaGlyph 结合了视觉吸引力、创造性、文化和可读性，为艺术字体设计提供了新的视角。"}
{"llm_update_time": "20250723", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2404.18558", "html_url": "https://arxiv.org/abs/2404.18558", "title": "LangBiTe：一种检测大型语言模型偏见的平台", "title_en": "LangBiTe: A Platform for Testing Bias in Large Language Models", "authors": "Sergio Morales,Robert Clarisó,Jordi Cabot", "background": "随着大型语言模型（LLMs）被集成到各种软件应用程序中，人们对它们潜在偏见的担忧日益增加。这些模型通常通过采集来自论坛、网站、社交媒体和其他互联网资源的大规模数据进行训练，这可能会使模型内植有害和歧视性行为。", "innovation": "本文提出了LangBiTe，一个测试平台，用于系统地评估LLM中是否存在偏见。LangBiTe允许开发团队自定义测试场景，并根据用户定义的伦理要求自动生成和执行测试用例。每个测试包括一个输入LLM的提示以及一个相应的测试指南，用于检查LLM的响应中是否存在偏见。LangBiTe向用户提供LLM的偏见评估，并在整个初始伦理要求和获得的见解之间提供端到端追踪。", "conclusion": "LangBiTe能够帮助开发团队系统地识别和减少大型语言模型中的偏见，从而提高这些模型的伦理性和可靠性，推动更负责任的人工智能应用。"}
{"llm_update_time": "20250723", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2411.06106", "html_url": "https://arxiv.org/abs/2411.06106", "title": "通过学习个性化不变表示实现通用3D医学多模态泛化的途径", "title_en": "Towards a Universal 3D Medical Multi-modality Generalization via Learning Personalized Invariant Representation", "authors": "Zhaorui Tan,Xi Yang,Tan Pan,Tianyi Liu,Chen Jiang,Xin Guo,Qiufeng Wang,Anh Nguyen,Yuan Qi,Kaizhu Huang,Yuan Cheng", "background": "医学成像模态之间的差异性，由不同的物理原理驱动，给多模态医学任务中的泛化带来了重大挑战。这不仅包括模态间的差异，还包括个体差异，如器官大小和代谢率的不同，这些都进一步阻碍了模型在不同模态和多样人群中泛化的能力。尽管个性化对于多模态泛化至关重要，但现有的多模态泛化方法往往忽略了个体差异，仅仅专注于共同的解剖特征，这可能导致多模态医学任务中泛化的削弱。该研究探讨了个性化对于多模态泛化的关键作用，并提出了通过利用个体水平约束和可学习的生物先验来逼近各种模态下的个性化不变表示${X}_h}$的方法，从而提高泛化能力.", "innovation": "提出了一种通过学习个性化不变表示${X}_h}$来实现多模态医学任务泛化的创新方法，该方法利用个体水平约束和可学习的生物先验从不同模态中逼近${X}_h}$, 并证明了这种表示在多种多模态医学任务中高度可泛化和可迁移，实验结果表明，这种个性化表示的引入显著提高了不同场景下的性能和泛化能力.", "conclusion": "该研究揭 示了个性化对于多模态泛化的关键作用，并通过实验验证了这种方法的有效性，结果表明个性化泛化方法能显著改善多模态医学任务中的性能和泛化能力."}
{"llm_update_time": "20250723", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2410.13246", "html_url": "https://arxiv.org/abs/2410.13246", "title": "长文本生成中LLMs的原子级校准", "title_en": "Atomic Calibration of LLMs in Long-Form Generations", "authors": "Caiqi Zhang,Ruihan Yang,Zhisong Zhang,Xinting Huang,Sen Yang,Dong Yu,Nigel Collier", "background": "大语言模型（LLMs）容易出现幻觉现象，给其实用应用带来了重大挑战。现有研究主要关注短格式任务中的置信度校准，但在长格式生成中，这种方法并不足够。长格式生成的响应包含更复杂的陈述，且可能包含准确和不准确的信息，需要更细致的校准方法来提升模型的可信度。", "innovation": "本文提出了原子校准方法，这是一种对长格式生成中的事实校准进行细粒度评估的新方法，通过将长响应分解为原子声明来实现。研究还展示了区分性和生成性置信度提取方法的结合能够提升校准效果。实验结果表明，原子校准适用于长格式生成，并能改进宏观校准结果，揭示了LLM生成过程中置信度的模式。", "conclusion": "原子校准方法针对长格式生成任务，提供了一种细粒度的事实校准方法，不仅能有效提升模型的可信度，还能改善宏观校准结果。"}
{"llm_update_time": "20250723", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2410.01817", "html_url": "https://arxiv.org/abs/2410.01817", "title": "使AI与公众价值观一致：在政治视频分析中治理多模态大语言模型的协商与决策", "title_en": "Aligning AI with Public Values: Deliberation and Decision-Making for Governing Multimodal LLMs in Political Video Analysis", "authors": "Tanusree Sharma,Yujin Potter,Zachary Kilhoffer,Yun Huang,Dawn Song,Yang Wang", "background": "关于AI模型如何处理政治议题的讨论已经展开，但如何更好地进行治理仍然是挑战。本文通过个体和集体协商来探讨大型语言模型的治理问题，并特别关注政治敏感的视频内容。", "innovation": "本文采用了两步研究法：首先，通过采访10位记者建立专家级视频解释的基础理解；其次，利用InclusiveAI平台进行114位个体的协商决策，该平台使用分布式自治组织（DAO）机制促进民主决策。研究发现，专家与普通公众在解释优先级上存在显著差异，并探讨了不同治理机制（如二次投票和加权投票）对用户决策的影响。", "conclusion": "研究表明，不同的投票机制对结果有显著影响，其中二次投票强化了对自由民主和政治平等的感知。研究强调选择合适治理机制的重要性，以更好地捕捉用户视角，并建议采用分布式AI治理以促进公众更广泛参与AI的开发，确保多样化的视角能够影响设计决策。"}
{"llm_update_time": "20250723", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2502.11809", "html_url": "https://arxiv.org/abs/2502.11809", "title": "通过人类视觉解耦的几何机制揭示深度神经网络中的偏见形成", "title_en": "Revealing Bias Formation in Deep Neural Networks Through the Geometric Mechanisms of Human Visual Decoupling", "authors": "Yanbiao Ma,Bowei Liu,Boyuan Gao,Wei Dai,Jiayi Chen,Shuo Li,Andi Zhang", "background": "深度神经网络(DNNs)在对象识别时常常对某些类别表现出偏见，即使是在平衡训练数据条件下。其内在机制尚不清楚。受人类视觉系统启发，该研究提出了一种几何分析框架，将感知流形的几何复杂性与模型偏见联系起来。研究表明，感知流形几何复杂性的差异能够导致不同类别间识别能力的差异，引入了偏见。为了支持这一分析，提出了Perceptual-Manifold-Geometry库，用于计算感知流形的几何属性。", "innovation": "提出了一种几何分析框架，通过将感知流形的几何复杂性与模型偏见联系起来，揭示了对象识别时深度神经网络中的偏见形成机制。开发了Perceptual-Manifold-Geometry库，用于计算感知流形的几何属性，为研究和理解深度神经网络中的偏见现象提供了新的工具和视角。", "conclusion": "研究表明，感知流形的几何复杂性差异导致了不同类别间的识别能力差异，从而产生了偏见。该研究通过新的几何分析框架和工具揭示了偏见形成的机制，对进一步改进深度神经网络的公平性和透明性具有重要意义。"}
{"llm_update_time": "20250723", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2501.07525", "html_url": "https://arxiv.org/abs/2501.07525", "title": "RadAlign: 通过视觉语言概念对齐推进放射学报告生成", "title_en": "RadAlign: Advancing Radiology Report Generation with Vision-Language Concept Alignment", "authors": "Difei Gu,Yunhe Gao,Yang Zhou,Mu Zhou,Dimitris Metaxas", "background": "自动化胸部X射线解释需要准确的疾病分类和详细的放射学报告生成，这对临床流程构成巨大挑战。当前的方法要么关注分类准确度而牺牲可解释性，要么通过图像描述技术生成详细但可能不稳定的报告。RadAlign通过结合视觉语言模型的预测准确性和大型语言模型的推理能力，旨在解决这一问题。", "innovation": "RadAlign首次引入了一种新颖的框架，结合了视觉语言模型的预测准确性和大型语言模型的推理能力。它有效地实现了疾病的高精度分类，并通过检索增强生成机制提高了报告质量，生成的报告得分为0.678，优于现有方法的0.634。这一框架提高了临床解释的可解释性，减少了幻觉，推进了自动化医学影像分析和报告生成的集成AI技术。", "conclusion": "RadAlign通过集成视觉语言模型(VLMs)和大型语言模型(LLMs)，提供了一种提高放射学报告准确性和可解释性的方法。该方法不仅提高了疾病分类的准确性，还通过检索机制提升了报告的质量，最终提升了自动化医学影像报告生成技术的整体性能。"}
{"llm_update_time": "20250723", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2410.09767", "html_url": "https://arxiv.org/abs/2410.09767", "title": "LibEER: 一种全面的基于EEG的情绪识别基准和算法库", "title_en": "LibEER: A Comprehensive Benchmark and Algorithm Library for EEG-based Emotion Recognition", "authors": "Huan Liu,Shusen Yang,Yuzhe Zhang,Mengze Wang,Fanyu Gong,Chengxi Xie,Guanjian Liu,Zejun Liu,Yong-Jin Liu,Bao-Liang Lu,Dalin Zhang", "background": "基于EEG的情绪识别（EER）因为能够理解和分析人类情绪而获得了显著的关注。虽然深度学习技术的最新进展显著改善了EER，但是在该领域仍然缺乏令人信服的基准和全面开源库。这一缺失复杂了模型之间的公平比较，给研究人员带来了重现问题的挑战，整体上阻碍了该领域的进展。", "innovation": "我们引入了LibEER，一个全面的基准和算法库，旨在促进EER中的公平比较。LibEER精心挑选了广泛应用且强大的基线，协调了方法中的关键实现细节，并在PyTorch中提供了标准化的代码库。通过提供一致的评估框架和标准化的实验设置，LibEER能够公平地评估六个广泛使用的数据集中十七个代表性的深度学习模型的情绪识别性能。此外，我们还进行了彻底且可重复的模型性能和效率比较，提供了有价值的见解来指导研究人员在选择和设计EER模型时的选择。并且在实验结果上进行了观察和深入分析，识别了该社区当前面临的挑战。", "conclusion": "我们希望这项工作不仅能降低开始基于EEG的情绪识别研究的新手门槛，还能促进此领域的研究标准化，推动该领域的持续发展。库和源代码可在以下网址公开访问：this https URL."}
{"llm_update_time": "20250723", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2502.16660", "html_url": "https://arxiv.org/abs/2502.16660", "title": "BioMaze: 评估和增强大型语言模型在生物通路推理中的性能", "title_en": "BioMaze: Benchmarking and Enhancing Large Language Models for Biological Pathway Reasoning", "authors": "Haiteng Zhao,Chang Ma,Fangzhi Xu,Lingpeng Kong,Zhi-Hong Deng", "background": "近年来，大型语言模型（LLMs）在生物领域中的应用得到了探索，但在复杂生物系统（如通路）中的推理能力仍需进一步研究。这种能力对于预测生物现象、提出假设和设计实验至关重要。本研究探讨了LLMs在通路推理中的潜在应用价值。研究人员引入了一个名为BioMaze的数据集，包含5100个复杂的通路问题，这些问题是根据不同生物环境中的自然动态变化、干扰、额外干预条件及多尺度研究目标从真实研究中提取的。研究表明，现有的方法（如CoT和图增强推理）在处理扰动系统时表现不佳，难以有效进行通路推理。因此，本研究提出了一种名为PathSeeker的LLM代理，通过基于交互子图的导航来增强其推理能力，使其能够更科学地应对复杂生物系统的挑战。", "innovation": "提出了BioMaze数据集，包含5100个复杂的通路问题；开发了PathSeeker代理，通过交互子图导航来增强通路推理能力；评估了CoT和图增强推理方法在复杂通路推理中的性能，发现现有方法在处理扰动系统时表现不佳。", "conclusion": "尽管现有的大型语言模型在通路推理中面临挑战，特别是处理扰动系统时，通过引入BioMaze数据集并提出PathSeeker代理，研究展示了改进大型语言模型在生物通路推理中的潜力。"}
{"llm_update_time": "20250723", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2502.06631", "html_url": "https://arxiv.org/abs/2502.06631", "title": "基于视觉-语言模型的人类动作识别的置信预测", "title_en": "Conformal Predictions for Human Action Recognition with Vision-Language Models", "authors": "Bary Tim,Fuchs Clément,Macq Benoît", "background": "在高风险的实际应用场景中，AI需要与人类决策者协作，此时Human-in-the-Loop (HITL)系统变得至关重要。本文研究了如何通过提供严谨覆盖率保证的Conformal Prediction (CP)技术来提高基于视觉-语言模型(Vision-Language Models, VLMs)的最先进的人类动作识别(Human Action Recognition, HAR)系统的可靠性。", "innovation": "提出了一种在不使用额外校准数据的情况下，通过调整软最大化预测的温度来降低候选类别数量的方法，以缓解CP技术结果分布长尾问题，从而提高其实用性。", "conclusion": "该研究为动态实际环境下的多模态人类-AI交互做出了贡献。"}
{"llm_update_time": "20250723", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2412.01661", "html_url": "https://arxiv.org/abs/2412.01661", "title": "R-Bot：基于LLM的查询重写系统", "title_en": "R-Bot: An LLM-based Query Rewrite System", "authors": "Zhaoyan Sun,Xuanhe Zhou,Guoliang Li,Xiang Yu,Jianhua Feng,Yong Zhang", "background": "优化SQL查询以提高其执行效率而不改变其结果，需要进行查询重写。传统的方法依赖于启发式和基于学习的方式，但这些方法在质量和稳定性方面存在局限。近年来，通过利用大型语言模型（LLMs）的自然语言理解和代码解释能力，为解决此问题提供了新思路。尽管LLMs潜力巨大，但直接使用如GPT-4的模型也会遇到生成不准确或无关信息的幻觉问题。", "innovation": "提出了R-Bot，一种基于LLM的查询重写系统，采用系统化的重写证据准备管道生成查询重写证据，指导模型避免幻觉；结合结构和语义分析，提出了一种混合的方法来检索相关重写证据；设计了一种逐步的LLM重写方法，利用检索出的证据逐步选择和排列重写规则。通过针对真实数据集和常用基准的全面实验，证明了R-Bot系统的优越性能，超越了最先进的查询重写方法。", "conclusion": "R-Bot系统已在华为和实际客户中部署，并显示出所提R-Bot系统实现了查询延迟的降低。"}
{"llm_update_time": "20250723", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2503.03108", "html_url": "https://arxiv.org/abs/2503.03108", "title": "OMNISEC：基于检索增强行为提示的大型语言模型驱动的溯源入侵检测", "title_en": "OMNISEC: LLM-Driven Provenance-based Intrusion Detection via Retrieval-Augmented Behavior Prompting", "authors": "Wenrui Cheng,Tiantian Zhu,Shunan Jing,Jian-Ping Mei,Mingjun Ma,Jiaobo Jin,Zhengqiu Weng", "background": "近年来，基于溯源的入侵检测系统（PIDSes）在端点威胁分析中得到了广泛应用。这些系统可以分为基于规则的检测系统和基于学习的检测系统。由于攻击技术的演变，基于规则的系统难以动态捕捉所有攻击者的特征，因而容易产生误报。基于学习的检测系统又分为监督学习和异常检测两类。由于攻击样本不足，监督学习方法在实际应用中的实用性和有效性受限，而异常检测方法因无法区分正常行为的变化和真实攻击行为而产生大量的误报。检测系统的报警结果直接影响后续安全分析师的劳动成本。为减少手动分析时间，我们提出了OMNISEC，它利用大型语言模型（LLMs）通过检索增强的行为提示来应用于异常检测系统。OMNISEC通过构建可疑节点和稀有路径来识别异常节点和相应的异常事件。借助两个外部知识库，OMNISEC使用检索增强生成（RAG）让LLM决定异常行为是否为真正的攻击。最后，OMNISEC可以重建攻击图并恢复攻击者的完整攻击行为链路。", "innovation": "OMNISEC提出的创新点在于，通过应用大型语言模型（LLMs）和检索增强的行为提示来改进基于异常的入侵检测系统，能够识别异常节点和事件，并利用外部知识库进行异常行为的真实攻击判断，进而重建攻击图并恢复完整的攻击行为链路。这种方法有效地解决了传统方法在误报和误译方面的问题，并加速了后续的分析过程。", "conclusion": "实验结果显示，OMNISEC在公共基准数据集上优于现有的一流方法，展示了其在实际应用中的优势和改进效果。"}
{"llm_update_time": "20250723", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2503.00196", "html_url": "https://arxiv.org/abs/2503.00196", "title": "PRISM: 使用语言导向稳定扩散进行高分辨率精准医疗图像生成", "title_en": "PRISM: High-Resolution & Precise Counterfactual Medical Image Generation using Language-guided Stable Diffusion", "authors": "Amar Kumar,Anita Kriz,Mohammad Havaei,Tal Arbel", "background": "开发可靠的可推广的深度学习系统对于医疗成像来说面临巨大挑战，因为数据集中存在虚假相关性、数据不均衡以及有限的文本注释。这些挑战要求架构能够应对医疗成像数据独有的复杂性。自然图像领域的视觉语言基础模型的迅速发展引发了将其应用于医疗成像任务的可能性问题。这项工作旨在解决这些挑战。", "innovation": "本研究提出了一个框架PRISM，它利用基础模型通过Stable Diffusion生成高分辨率、语言引导的医疗图像反事实。该方法在选择性修改虚假相关性和疾病特征方面实现了前所未有的精度，能够移除和添加特定属性，同时保留其他图像特征。通过广泛的评估，PRISM推动了反事实生成的进步，并为临床可部署解决方案的稳健下流分类器的发展提供了支持。", "conclusion": "通过PRISM的广泛评估，我们展示了其在反事实生成方面的能力，并为开发临床可部署解决方案提供了更稳健的下流分类器。为了促进更广泛的应用和研究，我们的代码已公开发布。"}
{"llm_update_time": "20250723", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2503.09565", "html_url": "https://arxiv.org/abs/2503.09565", "title": "在Maximal Update参数化下L层无限宽度神经网络的全局收敛和丰富的特征学习", "title_en": "Global Convergence and Rich Feature Learning in $L$-Layer Infinite-Width Neural Networks under $μ$P Parametrization", "authors": "Zixiang Chen,Greg Yang,Qingyue Zhao,Quanquan Gu", "background": "尽管深度神经网络具有强大的特征表示能力，但理论理解如何确保网络同时进行有意义的特征学习和全局收敛仍然不够明确。现有的神经趋近核（NTK）方法在这方面有限，因为模型参数化方式使特征在训练过程中保持接近初始化值，这引发了关于特征属性在进化中的性质的问题。", "innovation": "本文通过张量程序（TP）框架，探讨了无限宽L层神经网络的训练动态。特别地，证明了在Maximal Update参数化（$μ$P）和激活函数的温和条件下，使用随机梯度下降（SGD），网络可以学习到线性独立且与初始化值显著不同的特征。这种丰富的特征空间捕捉了相关数据信息，并确保训练过程中任何收敛点都是全局最小值。分析通过特征层间的交互和高斯随机变量的特性进行，提供了关于深层表示学习的新见解。", "conclusion": "研究通过理论上证明和实验验证，展示了在Maximal Update参数化下，无限宽度的多层神经网络能够实现全局收敛和丰富的特征学习。"}
{"llm_update_time": "20250723", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2408.10872", "html_url": "https://arxiv.org/abs/2408.10872", "title": "V-RoAst: 视觉道路评估。VLM能否根据iRAP标准作为道路安全评估员？", "title_en": "V-RoAst: Visual Road Assessment. Can VLM be a Road Safety Assessor Using the iRAP Standard?", "authors": "Natchapon Jongwiriyanurak,Zichao Zeng,June Moh Goo,Xinglei Wang,Ilya Ilyankou,Kerkritt Sriroongvikrai,Nicola Christie,Meihui Wang,Huanfa Chen,James Haworth", "background": "道路安全性评估至关重要但成本高昂，特别是在中低收入国家（LMICs），这些地区的道路大多未评级。传统方法需要专家标注和训练数据，而基于监督学习的方法难以跨地区泛化。", "innovation": "本文引入了V-RoAst，这是一种零样本视觉问答（VQA）框架，使用视觉语言模型（VLMs）对由iRAP标准定义的道路安全属性进行分类。研究首次介绍了来自ThaiRAP的开源数据集，包含超过2,000张标注泰国街道级别的图像。评估表明，尽管VLMs在空间感知方面表现不佳，但它们能够很好地泛化到未见类别，并通过灵活的提示式推理无需重新训练。这项工作是首次探索VLMs在零样本基础设施风险评估中的应用。", "conclusion": "我们的结果表明，当结合补充数据时，VLMs可以作为自动道路评估工具。这项工作开启了自动、低本道路安全地图绘制的新方向。"}
{"llm_update_time": "20250723", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2502.16940", "html_url": "https://arxiv.org/abs/2502.16940", "title": "推理未必能提升角色扮演能力", "title_en": "Reasoning Does Not Necessarily Improve Role-Playing Ability", "authors": "Xiachong Feng,Longxu Dou,Lingpeng Kong", "background": "角色扮演大型语言模型（LLMs）的应用在学术和商业领域迅速扩展，推动了高精度角色扮演模型的需求增加。同时，推理技术的快速发展不断推动LLMs的性能边界。这种实际角色扮演需求与不断演进的推理能力的交汇提出了一个重要研究问题：推理技术能否增强LLMs的角色扮演能力？", "innovation": "研究选择了6个角色扮演基准，24个LLMs和3种角色扮演策略，对比了直接零样本角色扮演、带有思维链（CoT）的角色扮演和使用推理优化的LLMs，发现CoT可能降低角色扮演效果，推理优化的LLMs不适合角色扮演，推理能力扰乱了角色扮演的扩展规律，大规模模型仍缺乏高级角色扮演技能，中文角色扮演性能超过英语。此外，基于大量实验结果，提出了两个潜在的研究方向：角色感知CoT以提高角色扮演LLMs和强化学习以提升角色扮演LLMs的适应性、一致性和有效性，适用于研究和实际应用中。", "conclusion": "研究表明，CoT可能降低角色扮演性能，单纯的推理优化的LLMs不适合角色扮演，推理能力打断了角色扮演的扩展规律，大规模模型在高级角色扮演上仍显不足，中文角色扮演性能优于英语。基于此，提出了两个未来研究方向：角色感知的CoT和强化学习以提升角色扮演LLMs的适应性、一致性和有效性。"}
{"llm_update_time": "20250723", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2503.14247", "html_url": "https://arxiv.org/abs/2503.14247", "title": "GeoFlow-SLAM:一种用于动态足式机器人鲁棒的RGBD惯性及腿部导航融合SLAM", "title_en": "GeoFlow-SLAM: A Robust Tightly-Coupled RGBD-Inertial and Legged Odometry Fusion SLAM for Dynamic Legged Robotics", "authors": "Tingyang Xiao,Xiaolin Zhou,Liu Liu,Wei Sui,Wei Feng,Jiaxiong Qiu,Xinjie Wang,Zhizhong Su", "background": "该论文针对足式机器人在高频率和强大机动性环境下的视觉SLAM（同步定位与建图）挑战进行研究。足式机器人在快速行走场景中存在特征匹配和姿态初始化失败的问题，特别是在纹理较少的环境中特征稀缺的情况下。此外，在快速运动场景中，传统的特征匹配技术效果不佳。因此，该论文提出了一种新的方法来增强特征匹配性能并提高姿态初始化的鲁棒性。同时，还引入了一种新的优化框架，可以将深度图与几何约束紧密耦合，以提高在无纹理视觉环境下的鲁棒性和准确性。", "innovation": "该方法主要创新点包括：1) 利用双视图光流（GeoFlow）技术来增强特征匹配和提高在快速行走场景下的性能；2) 提出了一种适用于快速移动和IMU误差的鲁棒姿态初始化方法；3) 首次提出了一种紧密耦合深度图与几何约束的优化框架，以提高长时间、无纹理环境下的鲁棒性和准确性；4) 该方法在收集到的足式机器人和开源数据集上达到了现有的最佳效果（SOTA）。", "conclusion": "综上所述，该论文提出的方法在多样化的实际场景中表现出了显著的鲁棒性和准确性，并且其开发的开源数据集和代码将会公开，以促进该领域的进一步研究和发展。"}
{"llm_update_time": "20250723", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2504.05119", "html_url": "https://arxiv.org/abs/2504.05119", "title": "通过激活函数选择平衡嵌入式DNN的鲁棒性和效率", "title_en": "Balancing Robustness and Efficiency in Embedded DNNs Through Activation Function Selection", "authors": "Jon Gutiérrez-Zaballa,Koldo Basterretxea,Javier Echanobe", "background": "对于航空航天和自动驾驶等关键应用中的基于机器学习的嵌入式系统，必须具备抵抗由软错误引起的扰动的稳健性。随着晶体管几何尺寸缩小和电压降低，现代电子设备更容易受到背景辐射的影响，导致由软错误引起的故障风险增加。深度神经网络（DNN）对这些错误的鲁棒性不仅取决于目标设备技术，还取决于模型结构及其参数的数值表示和算术精度。压缩技术如剪枝和量化虽然能够减少内存占用和计算复杂性，但会改变模型结构和表示，影响软错误的鲁棒性。模型激活函数的选择不仅影响准确性与训练性能，还影响压缩性和错误鲁棒性。本研究探讨了有界激活函数如何增强对参数扰动的鲁棒性，并从技术无差别角度评估其对模型准确性、压缩性和计算负载的影响。", "innovation": "本研究的重点是通过选择有界激活函数来增强嵌入式DNN的鲁棒性，并从技术无差别的角度评估其对模型准确性、压缩性和计算负载的影响。研究集中在应用于自主驾驶系统的高光谱图像语义分割的编码器-解码器卷积模型上，并在AMD-Xilinx的KV260系统模块（SoM）上进行实验。", "conclusion": "本研究通过有界激活函数的选择成功提升了嵌入式DNN的鲁棒性和效率，提供了技术无差别评估其对模型性能影响的方法，为未来相关研究提供了新的视角和方向。"}
{"llm_update_time": "20250723", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2502.04645", "html_url": "https://arxiv.org/abs/2502.04645", "title": "Cross-Encoder Rediscovers a Semantic Variant of BM25", "title_en": "Cross-Encoder Rediscovers a Semantic Variant of BM25", "authors": "Meng Lu,Catherine Chen,Carsten Eickhoff", "background": "神经排名模型(NRMs)在信息检索任务中迅速提升了最先进的性能。本文探讨了一种MiniLM的交叉编码器变体，以确定它计算哪些相关性特征以及它们存储在哪里。研究发现，交叉编码器采用了传统BM25的语义变体，并以可解释的方式进行操作。", "innovation": "交叉编码器使用了与BM25相同的最基本机制，但在能够捕捉更多语义的情况下提高了检索性能。更重要的是，交叉编码器的局部组件包括：（1）变压器注意力头计算软词频并控制词频饱和度和文档长度的影响；（2）其嵌入矩阵的一种低秩成分编码了词汇的逆文档频率信息。这表明交叉编码器在使用传统BM25机制的基础上进一步利用了其捕捉语义的能力。", "conclusion": "这种细粒度的理解为模型编辑以增强模型透明度、解决安全问题和提高训练及实际应用中的可扩展性奠定了基础。"}
{"llm_update_time": "20250723", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2503.10624", "html_url": "https://arxiv.org/abs/2503.10624", "title": "ETCH: 使用协变紧致性实现穿着人类体型拟合的通用化", "title_en": "ETCH: Generalizing Body Fitting to Clothed Humans via Equivariant Tightness", "authors": "Boqian Li,Haiwen Feng,Zeyu Cai,Michael J. Black,Yuliang Xiu", "background": "对穿着3D衣物的人体点云进行体型拟合是一个常见但具有挑战性的工作。传统的基于优化的方法使用多阶段流水线，对姿态初始化敏感；而最近的基于学习的方法通常难以跨越不同姿态和服装类型进行泛化。", "innovation": "提出了穿着人类的协变紧致性拟合（Equivariant Tightness Fitting for Clothed Humans，或ETCH）新型管道，通过局部近似SE(3)协变性来估计服装到身体表面的映射，编码紧致性作为从服装表面到底层身体的位移向量。随后的映射中，姿势不变的身体特征回归稀疏的身体标记，使得穿着人类拟合简化为内部身体标记拟合任务。广泛的实验表明，ETCH在松散服装的体型拟合精度（16.7%至69.5%）和形状精度（平均49.9%）方面显著优于最新技术。我们的协变紧致性设计甚至可以减少在单次拟合（或出域）设置下的方向误差（67.2%至89.8%），约占1%的数据。", "conclusion": "定性的实验结果表明，不论在具有挑战性的姿态、未见形状、松散服装或非刚性动力学的情况下，ETCH都表现出强大的泛化能力。不久后将提供代码和模型供研究使用。"}
{"llm_update_time": "20250723", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2505.00025", "html_url": "https://arxiv.org/abs/2505.00025", "title": "基于Deepseek R1的医疗垂直大型语言模型架构方法", "title_en": "A Method for the Architecture of a Medical Vertical Large Language Model Based on Deepseek R1", "authors": "Mingda Zhang,Jianglong Qin", "background": "尽管深度学习求索-深探（DeepSeek-R1）和ChatGPT等基础模型取得了显著进展，但在医疗场景中的部署面临关键挑战，包括计算需求和专业领域知识障碍。这些挑战阻碍了这些模型在医疗环境中的广泛应用和效能提升。本文对其进行系统优化，旨在提供解决方案，以降低计算需求和增强专业知识匹配度，从而在资源受限的医疗环境中促进高级语言模型的应用和发展。", "innovation": "论文设计了一种高效轻量级医疗大型语言模型结构，通过三维优化策略（知识获取、模型压缩和计算增强）系统解决前述挑战。具体贡献包括设计了一个基于DeepSeek-R1-Distill-70B的低秩适应知识传递管道（LoRA），实现精确医疗知识保留；通过4比特量化和混合精度策略实现了有效的模型压缩，同时保持了医疗推理能力；采用Flash Attention加速和连续批量策略，并结合特定的提示模板来处理多样化的医疗查询需求。这些方法共同提高了模型的效率和专业性，提升了在医疗场景中的适用性与实用性，为资源受限环境下高级语言模型的应用提供了新方法和路径。", "conclusion": "实验结果表明，基于上述方法，模型在确保了92.1%的UMLSE考试准确性的同时，与基线模型相比，内存消耗降低了64.7%，推理延迟减少了12.4%。该研究提出了资源受限医疗环境中部署高级语言模型的实用解决方案，提升了AI辅助医疗的可访问性，同时也为其进一步的实际应用奠定了基础。"}
{"llm_update_time": "20250723", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2501.08005", "html_url": "https://arxiv.org/abs/2501.08005", "title": "DisCoPatch: 通过对抗驱动的批量统计数据改进异类检测", "title_en": "DisCoPatch: Taming Adversarially-driven Batch Statistics for Improved Out-of-Distribution Detection", "authors": "Francisco Caetano,Christiaan Viviers,Luis A. Zavala-Mondragón,Peter H. N. de With,Fons van der Sommen", "background": "异常分布（OOD）检测在许多应用中都至关重要。虽然语义和领域转换OD问题得到了广泛研究，但本文关注的是协变转移，即数据分布中的微妙变化，这会降低机器学习的性能。检测这些细微变化有助于更好地理解内部分布边界，从而进一步提高OOD检测的准确性。", "innovation": "研究提出了一种无监督的对抗变分自编码器（VAE）框架——DisCoPatch，该框架利用对抗判别器训练时生成和重建图像的不理想输出作为负样本来训练判别器，从而提高辨别内部分布样本和协变转移的能力。DisCoPatch在公共OOD检测基准测试中取得了最优效果，尤其在ImageNet-1K(-C)上的AUROC高达95.5%，同时其紧凑的模型大小（25MB）和较低的延迟使其在现实世界的应用中成为一个高效的解决方案。", "conclusion": "DisCoPatch采用了对抗机制，通过训练判别器区分内部分布样本与协变转移，尤其是在公共OOD检测基准上实现了最先进水平的结果。该模型不仅在检测协变转移方面表现出色，还以其高效的性能在实际应用中带来了实际价值。"}
{"llm_update_time": "20250723", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2505.08195", "html_url": "https://arxiv.org/abs/2505.08195", "title": "Aitomia: 您的智能助手，用于AI驱动的原子仿真和量子化学模拟", "title_en": "Aitomia: Your Intelligent Assistant for AI-Driven Atomistic and Quantum Chemical Simulations", "authors": "Jinming Hu,Hassan Nawaz,Yuting Rui,Lijie Chi,Arif Ullah,Pavlo O. Dral", "background": "文章介绍了用于原子仿真和量子化学（QC）模拟的Aitomia平台。AI驱动的原子仿真和分子动力学模拟在科学和工程中有着广泛的应用，但这些技术往往需要深厚的专业知识和强大的计算资源。当前，用户面临的主要挑战是如何高效地设置和运行这些复杂的模拟，以及如何理解和分析大量的计算结果。因此，开发一个智能助手来简化这一过程，对于降低原子仿真门槛并推动相关领域的研究发展具有重要意义。", "innovation": "Aitomia平台创新之处在于：它利用了大型语言模型，结合了AI增强的计算化学任务，支持从基态到激发态的各种计算，包括几何优化、热化学和光谱计算。其多代理系统使得能够自主执行复杂的计算工作流。此外，Aitomia还能够在线云平台上供公众使用（Aitomistic Hub）或在本地部署，从而促进了原子仿真和量子化学模拟的普及化。", "conclusion": "Aitomia作为第一个智能助手平台，在云端提供广泛的原子仿真服务，有望减少用户进行原子仿真所需要的知识和技术门槛，推动相关领域的研究和发展。"}
{"llm_update_time": "20250723", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2503.10706", "html_url": "https://arxiv.org/abs/2503.10706", "title": "SciFi-Benchmark: 利用科幻作品提升机器人行为", "title_en": "SciFi-Benchmark: Leveraging Science Fiction To Improve Robot Behavior", "authors": "Pierre Sermanet,Anirudha Majumdar,Vikas Sindhwani", "background": "鉴于人工智能（AI）和机器人技术近年来的快速进展，人们开始思考一个令人期待的问题：由新兴AI系统控制的机器人是否能强烈符合人类价值观？为探究这一问题，本文提出了一种可扩展的方法，通过生成涵盖824部主要科幻文学作品（电影、电视剧、小说和科学书籍）中关键时刻的基准，这些时刻涉及代理（AI或机器人）作出的关键决策（好坏皆有）。利用最新的预训练语言模型（LLM）对每个关键时刻的回忆，生成类似情境的问题、代理所做的决定以及可以替代的决定（好坏），并测量模型与人类价值观的契合程度。我们还生成了改进规则，可以自动优化生成首批基于科幻作品灵感的宪法，以促进AI和机器人的伦理行为。我们的初步发现是，现代预训练模型配以宪法，显示出95.8%的人类价值观匹配，远高于科幻作品中不祥决策的21.2%匹配率。此外，我们发现，生成的宪法在基模型的基础上显著增加了匹配度（79.4%到95.8%），并在对抗性提示设置中具有韧性（23.3%到92.3%）。同时，这些宪法也表现出色ASIMOV基准，该基准依据现实世界图像和医院损伤报告。由此，科幻作品启发的宪法在现实世界场景中高度契合且具有应用性。因此，我们发布了SciFi-Benchmark：一个庞大的数据集，旨在推动机器人伦理和安全研究，包含9,056个问题和53,384个答案，通过创新的LLM反思过程生成，另附有人类标注的评估集。", "innovation": "本文提出了一种新颖的方法，利用科幻文学作品构建了一个基准（SciFi-Benchmark），该基准涵盖824部主要作品中的关键时刻，涉及AI或机器人作出的决定（好或坏）。通过这种方法，基于最新的预训练语言模型（LLM），不仅生成相似情境下的问题、所作决定和可替代的决定，还通过人类投票对模型与人类价值观的契合程度进行了测量。此外，本文基于科幻作品灵感生成了一组改进规则，自动生成首批基于科幻作品的宪法，以促进AI和机器人在现实世界中的伦理行为表现。", "conclusion": "基于分析，本文得出两个重要结论：首先，现代预训练模型配以宪法显示出95.8%的人类价值观匹配，远超科幻作品中典型决策的21.2%契合度；其次，生成的宪法在基模型基础上显著提高了匹配度（79.4%到95.8%），并在对抗性提示设置中表现出色（23.3%到92.3%）。这些监视器亦展现了在ASIMOV基准中的出色表现，该基准依据现实世界图像和医院损伤报告制定。由此，科幻作品启发的宪法在现实世界场景中高度契合且适用性强。因此，我们发布了一个大型数据集SciFi-Benchmark，旨在推动机器人伦理和安全研究，它包含9,056个问题和53,384个答案，以及一个较小的人类标记评估集。"}
{"llm_update_time": "20250723", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2505.23714", "html_url": "https://arxiv.org/abs/2505.23714", "title": "SenWiCh: 使用混合方法为低资源语言WiC进行词义标注", "title_en": "SenWiCh: Sense-Annotation of Low-Resource Languages for WiC using Hybrid Methods", "authors": "Roksana Goworek,Harpal Karlcut,Muhammad Shezad,Nijaguna Darshana,Abhishek Mane,Syam Bondada,Raghav Sikka,Ulvi Mammadov,Rauf Allahverdiyev,Sriram Purighella,Paridhi Gupta,Muhinyia Ndegwa,Haim Dubossarsky", "background": "低资源语言缺乏高质量的评估数据集，这对于推进跨语言迁移至关重要。跨语言迁移利用多语言预训练来扩展语言技术到研究不足的和语系多样化的语言，但其效果依赖于高质量和适当的基准。研究强调了在低资源环境中有效处理多义词歧义和跨语言迁移研究中，有目的的数据集创建和评估的重要性。", "innovation": "该论文提出了使用混合方法为低资源语言进行词义标注新方法，同时提供了新的多义词标注数据集，跨越十个不同语言家族与脚本的低资源语言。还提出了一种半自动标注方法，以支持数据集的创建。通过Word-in-Context（WiC）实验评估这些低资源语言上的迁移效果，强调了经过良好设计的数据集和评估方法在低资源环境中的重要性。", "conclusion": "本研究发布的数据集和代码旨在支持更公平、更稳健和真正的多语言自然语言处理研究。"}
{"llm_update_time": "20250723", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2505.23631", "html_url": "https://arxiv.org/abs/2505.23631", "title": "Human Empathy as Encoder: AI-Assisted Depression Assessment in Special Education", "title_en": "Human Empathy as Encoder: AI-Assisted Depression Assessment in Special Education", "authors": "Boning Zhao", "background": "在特教环境中评估学生的抑郁症具有挑战性，标准化问卷可能无法全面反映学生的真实情况。自动化方法往往难以处理丰富的学生叙述，缺乏源于教师对学生同情心连接的个体化洞见。现有方法往往未能解决这种模糊性或有效整合教育者的理解。", "innovation": "本文引入了‘Human Empathy as Encoder (HEAE)’，这是一种以人为本的AI框架，用于透明和负责任的抑郁症严重程度评估。该方法独特地将学生叙述文本与根据PHQ-9框架制定的9维“Empathy Vector”（EV）相结合，旨在将隐含的同情心洞察明确地转化为结构化的AI输入，增强而非取代人类判断。", "conclusion": "实验证明，结合多模态融合、文本表示和分类架构，该工作达到了7级严重程度分类的82.74%的准确率，展示了如何通过结构化嵌入人类同情心，实现更具责任感和伦理性的计算情感分析。"}
{"llm_update_time": "20250723", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.05171", "html_url": "https://arxiv.org/abs/2506.05171", "title": "朝着可证明的概率安全性以实现可扩展的具身AI系统的路径", "title_en": "Towards provable probabilistic safety for scalable embodied AI systems", "authors": "Linxuan He,Qing-Shan Jia,Ang Li,Hongyan Sang,Ling Wang,Jiwen Lu,Tao Zhang,Jie Zhou,Yi Zhang,Yisen Wang,Peng Wei,Zhongyuan Wang,Henry X. Liu,Shuo Feng", "background": "具身AI系统，集成了AI模型和物理装置，正在各种应用中变得越来越普遍。由于系统故障罕见，确保其在复杂操作环境中的安全性仍是一个重大挑战，这严重阻碍了其在自动驾驶车辆、医疗设备和机器人等关键安全领域的大规模部署。虽然在所有可能场景中实现可证明的确定性安全性仍然在理论上是最理想的，但由于罕见和复杂的边角情况，这一方法对于可扩展的具身AI系统来说是不切实际的。因此，替代性的经验性安全性评估被采用，但缺乏可证明的保证会带来显著的限制。", "innovation": "本文提出了一种范式转变，即从可证明的确定性安全性转向可证明的概率安全性，这是一种将可证明的安全保证与逐步达到整体系统性能的概率安全性边界相结合的方法。这一新范式更好地利用了统计方法来提高可行性和可扩展性，明确的概率安全性边界使得具身AI系统可以在大规模应用中部署。本文阐述了可证明的概率安全性的路线图，以及相应的挑战和可能的解决方案，从而弥合了理论安全性保障与实际部署之间的差距，为具身AI系统在关键安全应用中的更大规模采用提供了途径。", "conclusion": "通过弥合理论安全性保障与实际部署之间的差距，本文为具身AI系统在关键安全应用中的更大规模采用提供了途径。这一愿景通过明确的概率安全性边界和统计方法的应用，使得具身AI系统的安全性评估更具可证明性，从而促进了其在大规模应用中的部署。"}
{"llm_update_time": "20250723", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2503.03707", "html_url": "https://arxiv.org/abs/2503.03707", "title": "基于在线经验筛选示范", "title_en": "Curating Demonstrations using Online Experience", "authors": "Annie S. Chen,Alec M. Lessing,Yuejiang Liu,Chelsea Finn", "background": "许多机器人的示范数据集包含不同质量的异构示范，这些异构性可能有助于策略预训练，但可能导致机器人在使用最终的模仿学习目标时性能降低。特别地，某些数据中的策略可能不如其他策略可靠，或者在数据中代表性不足，当在测试时抽中这些策略时，会导致性能不佳。此外，这些不可靠或代表性不足的策略甚至对于人类来说也难以辨别，筛选示范数据集需要耗费时间和成本。另一方面，训练这些示范数据集后策略的性能可以反映出不同策略的可靠性。因此，本文提出一种基于在线机器人经验进行示范筛选（Demo-SCORE）的方法。", "innovation": "本文提出了一种名为Demo-SCORE的方法，该方法通过在线机器人经验训练和验证分类器来辨别成功的策略演示和不成功的策略演示，并利用分类器筛选异质的示范数据集。这种方法能够在不需要手动筛选的情况下有效识别出次优示范。实验结果表明，使用Demo-SCORE方法训练得到的策略绝对成功率比使用所有原始示范训练基策略高出15-35%。", "conclusion": "Demo-SCORE方法可以根据在线机器人经验自动筛选出可靠的示范，提高机器人训练策略的成功率，同时节省时间和成本。"}
{"llm_update_time": "20250723", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2505.17023", "html_url": "https://arxiv.org/abs/2505.17023", "title": "ReMi: 一种用于音乐制作的随机递归神经网络方法", "title_en": "ReMi: A Random Recurrent Neural Network Approach to Music Production", "authors": "Hugo Chateau-Laurent,Tara Vanhatalo,Wei-Tung Pan,Xavier Hinaut", "background": "生成性人工智能引发了对能源消耗、版权侵犯和创造性衰退的担忧。现有的音乐生成方法通常是端到端的，旨在替代音乐家，这可能会抑制音乐家的创造力。", "innovation": "本研究提出了一种基于随机递归神经网络的方法（ReMi），可以生成丰富的和弦进行和低频振荡，同时增强了音乐家的创造力，且无需使用数据，所需计算资源较少。", "conclusion": "相比现有的端到端音乐生成方法，本方法能够扩展音乐家的创造力，无需数据，也不需要大量的计算资源。"}
{"llm_update_time": "20250723", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2505.01966", "html_url": "https://arxiv.org/abs/2505.01966", "title": "基于目标导向的强化学习路径规划算法在模块化自重构卫星中的应用", "title_en": "A Goal-Oriented Reinforcement Learning-Based Path Planning Algorithm for Modular Self-Reconfigurable Satellites", "authors": "Bofei Liu,Dong Ye,Zunhao Yao,Zhaowei Sun", "background": "模块化自重构卫星是指由多个可重构模块组成的卫星集群，能够改变自身构型以执行多样任务和使命目标。现有的重构路径规划算法往往存在计算复杂度高、泛化能力差以及对多样目标构型支持不足的问题。为此，该论文提出了一种基于目标导向的强化学习路径规划算法，旨在解决传统方法无法克服的难题，即处理多种目标构型情况，并采用回放缓存重放技术和无效动作掩码技术以应对稀疏奖励和无效动作带来的挑战.", "innovation": "提出了基于目标导向的强化学习路径规划算法，并首次解决了传统方法无法克服的多种目标构型难题。该方法通过使用回放缓存重放技术和无效动作掩码技术提高了算法性能，特别是在模块化卫星集群中达到任意目标构型的成功率达到95%和73%（四个和六个模块的集群）。", "conclusion": "所提出的基于目标导向的强化学习路径规划算法，在处理多个目标构型方面表现出色，并通过实验证明了在不同模块数量的卫星集群中实现了高成功率达到目标构型的目标，为模块化自重构卫星的路径规划提供了有效的方法。"}
{"llm_update_time": "20250723", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2504.02019", "html_url": "https://arxiv.org/abs/2504.02019", "title": "反相关采样在Top-k Shapley识别中的应用", "title_en": "Antithetic Sampling for Top-k Shapley Identification", "authors": "Patrick Kolpaczki,Tim Nielen,Eyke Hüllermeier", "background": "特征解释性分析主要依赖于博弈论中的Shapley值概念，视特征为合作的参与者。Shapley值因其公理上的独特性在可解释AI内外都非常流行。然而，其计算复杂性极大地限制了其实用性。大多数研究工作集中在对所有特征的Shapley值进行均匀近似，这无谓地消耗了对于不重要特征的样本。相比之下，识别出最重要的k个特征已经足够具有洞察力，并且与多臂bandit领域的关系将成为算法机会的潜在来源。", "innovation": "我们提出了一个名为Comparable Marginal Contributions Sampling (CMCS)的新方法来解决top-k识别问题，该方法利用了一种新的采样方案，该方案能够利用相关观察结果的优势。通过实验对比显示了我们的方法在与竞争基线方法相比时的有效性。", "conclusion": "我们的实证研究表明，对所有特征进行近似的估计质量并不一定能够转移到top-k识别中，反之亦然。因此，在进行特征重要性排序时，利用Correlated Observations的优势，有针对性地识别top-k特征可能是更为有效的策略。"}
{"llm_update_time": "20250723", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.11815", "html_url": "https://arxiv.org/abs/2506.11815", "title": "基于扩散的电生理噪声量化方法通过异常检测", "title_en": "Diffusion-Based Electrocardiography Noise Quantification via Anomaly Detection", "authors": "Tae-Seong Han,Jae-Wook Heo,Hakseung Kim,Cheol-Hui Lee,Hyub Huh,Eue-Keun Choi,Hye Jin Kim,Dong-Joo Kim", "background": "心电图(ECG)信号经常受到噪声的干扰，限制了它们在传统和可穿戴环境中的临床可靠性。现有的处理ECG噪声的方法依赖于噪声分类或降噪，这些方法容易受到注释不一致和泛化能力差的限制。", "innovation": "通过将ECG噪声量化重新定义为异常检测任务，提出了一种基于扩散的框架，该框架能够建模清洁ECG信号的规范分布，无需明确的噪声标签即可识别偏差。引入基于分布的Wasserstein-1距离($W_1$)度量来稳健评估性能并缓解标签不一致性。模型实现了宏平均$W_1$得分1.308，显著优于其他最佳方法48%。", "conclusion": "该方法增强了实时ECG监测，并扩展了ECG在数字健康技术中的应用，有助于排除噪声段以提高诊断准确性，支持及时的临床干预。"}
{"llm_update_time": "20250723", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.22095", "html_url": "https://arxiv.org/abs/2506.22095", "title": "多图上的多目标神经路由方法", "title_en": "Neural Approaches for Multi-Objective Routing on Multigraphs", "authors": "Filip Rydin,Attila Lischka,Jiaming Wu,Morteza Haghir Chehreghani,Balázs Kulcsár", "background": "近年来，基于学习的方法在单目标和多目标路由中受到了广泛关注。然而，现有的方法并不适用于包含多个具有不同属性边的节点对的多图环境，而这种环境在现实世界中有很强的相关性。现有研究尚未解决多目标路由问题在多图环境下的优化策略.", "innovation": "本文提出了两种基于图神经网络的多目标路由方法，分别针对多图环境设计。第一个方法通过自回归方式直接在多图中选择边，直到完成路径。第二个方法首先利用学习得到的剪枝策略简化多图，然后在简化后的单图中进行路由计算。实验结果表明这两种方法在多种问题和分布下表现出很强的性能.", "conclusion": "本文提出的基于图神经网络的方法能有效地解决多目标路由问题在多图环境下的优化策略。"}
{"llm_update_time": "20250723", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.23516", "html_url": "https://arxiv.org/abs/2506.23516", "title": "FedWSQ：结合权重标准化与分布感知非均匀量化以高效实现联邦学习", "title_en": "FedWSQ: Efficient Federated Learning with Weight Standardization and Distribution-Aware Non-Uniform Quantization", "authors": "Seung-Wook Kim,Seongyeol Kim,Jiah Kim,Seowon Ji,Se-Ho Lee", "background": "联邦学习（FL）经常由于数据异质性和通信限制等问题导致性能下降。", "innovation": "提出了一种新颖的联邦学习框架FedWSQ，该框架结合了权重标准化（WS）和分布感知非均匀量化（DANUQ），通过筛选训练过程中局部更新的有偏分量增强FL性能，同时通过利用局部模型更新的统计特性最小化量化误差，从而在保持优良的模型准确性的前提下显著降低通信开销。", "conclusion": "在FL基准数据集上的大量实验表明，FedWSQ在多种挑战性的FL设置中，包括极端数据异质性和超低比特通信场景下，持续优于现有的FL方法。"}
{"llm_update_time": "20250723", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.01225", "html_url": "https://arxiv.org/abs/2507.01225", "title": "资源使用和持续时间具有不确定性的作业的容量规划与调度", "title_en": "Capacity Planning and Scheduling for Jobs with Uncertainty in Resource Usage and Duration", "authors": "Sunandita Patra,Mehtab Pathan,Mahmoud Mahfouz,Parisa Zehtabi,Wided Ouaja,Daniele Magazzeni,Manuela Veloso", "background": "组织在全球范围内定期调度作业（程序）以执行各种由其最终用户规定的任务。随着使用云计算基础设施的趋势，该组织采取混合方法，结合使用云和本地服务器。本工作旨在为本地网格计算环境进行容量规划，即估算资源需求和作业调度。主要挑战在于处理资源使用和作业持续时间的不确定性，特别是在金融行业中，这些不确定性对作业特性有重大影响。需要同时平衡容量规划和调度中的两项相互冲突的目标：(1) 最小化资源使用；(2) 通过最终用户的请求截止时间提供高质量的服务。", "innovation": "本研究的关键贡献是对资源使用和作业持续时间具有不确定性的作业提出了同时考虑这两项目标的近似方法。具体来说，使用了确定性估计器和基于配对采样的约束编程方法。通过这种方法，实现了与手工调度相比更低的峰值资源使用，同时不牺牲服务质量。", "conclusion": "本研究提出的方法有效解决了资源使用和作业持续时间的不确定性问题，在同时最小化资源使用和确保高质量服务之间取得了平衡。这为金融等依赖于准确预测和资源管理的有效性行业提供了重要的容量规划和调度策略。"}
{"llm_update_time": "20250723", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2505.18574", "html_url": "https://arxiv.org/abs/2505.18574", "title": "Autocomp：基于大语言模型的张量加速器代码优化", "title_en": "Autocomp: LLM-Driven Code Optimization for Tensor Accelerators", "authors": "Charles Hong,Sahil Bhatia,Alvin Cheung,Yakun Sophia Shao", "background": "硬件加速器，尤其是用于张量处理的加速器，在当今的计算环境中已变得非常普遍。尽管在构建编译器方面做出了重大努力，但编程这些张量加速器仍然具有挑战性，导致它们的潜力被大大低估。最近，大型语言模型（LLMs）在大量代码上进行训练，在代码生成和优化任务中表现出显著的潜力，但在生成专用张量加速器代码时仍面临严峻挑战。尽管如此，现有方法依然难以有效利用这些模型进行低资源语言如张量加速器代码的优化。", "innovation": "我们提出了Autocomp，一个通过自动化LML驱动搜索来利用领域知识和硬件反馈优化代码的方法。它是通过将每个优化步骤分为规划和代码生成两个阶段的结构化提示，并在规划阶段插入简洁且可调整的优化菜单，并在每次搜索迭代中集成来自硬件的正确性和性能反馈来实现的。这使加速器程序员能够利用Autocomp来优化代码，并在固定样本预算下实现了相似张量操作的优化方案重用，从而提高了最多24%的加速效果率。", "conclusion": "在针对代表性的三种工作负载和两种不同的加速器进行的测试中，Autocomp优化的代码在GEMM上的运行速度快5.6倍，在卷积上的运行速度快2.7倍，优于供应商提供的库代码和专家级别的手调代码。此外，从Autocomp生成的优化调度方案在固定样本预算下可以跨相似张量操作实现加速效果的提升。"}
{"llm_update_time": "20250723", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.04441", "html_url": "https://arxiv.org/abs/2507.04441", "title": "范畴论下的形而上学预测带来的喜悦", "title_en": "The Joys of Categorical Conformal Prediction", "authors": "Michele Caprio", "background": "形而上学预测（CP）是一种不确定性表示技术，能够在任何机器学习模型下提供有限样本校准预测区间。尽管它是不确定性量化（UQ）工具，但在概念上仍然不透明：虽然CP区域提供了不确定性（较大的区域通常表示较高的不确定性）的顺序表示，但无法进行实质性的量化（例如，两倍大的区域并不代表两倍的不确定性）。", "innovation": "借鉴范畴论方法，将CP视为两个新定义范畴中的同态，嵌入到一个交换图中，从而展现了CP的三大特点：1. 在最少假设下，CP本质上是UQ机制，其UQ的实质能力是方法的结构特征；2. CP连接了贝叶斯、频率主义和不确定概率三种预测统计推理方法；3. CPR是协变函子的象。", "conclusion": "这一发现对AI隐私具有重要意义：它表明，局部加入的隐私噪声不会破坏全局覆盖保证。"}
{"llm_update_time": "20250723", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.10516", "html_url": "https://arxiv.org/abs/2506.10516", "title": "CogStream: 基于上下文指导的流式视频问答", "title_en": "CogStream: Context-guided Streaming Video Question Answering", "authors": "Zicheng Zhao,Kangyu Wang,Shijie Li,Rui Qian,Weiyao Lin,Huabin Liu", "background": "尽管视频大型语言模型（Vid-LLMs）在跨模态理解方面取得了进展，但在流式视频推理中仍然存在挑战，这是因为其依赖于上下文信息。现有的范式将所有可用的历史上下文信息输入到Vid-LLMs中，导致对于视觉数据处理而言，存在极大的计算负担。此外，包含的不相关上下文会分散模型对关键细节的关注。因此，本文提出了一个名为Context-guided Streaming Video Reasoning（CogStream）的具有挑战性的任务，该任务模拟了现实世界中的流式视频场景，要求模型识别与当前流相关的最相关的历史上下文信息来回答关于当前流的问题。", "innovation": "为支持CogStream，本文提出了一个密集注释的数据集，该数据集包含广泛且多层次的问题-答案对，由半自动管道生成。此外，本文还提出了一个基线模型CogReasoner，该模型通过利用视觉流压缩和历史对话检索来高效地应对这一任务。实验结果证明了该方法的有效性。", "conclusion": "本项目已在 https://github.com/... 上发布。"}
{"llm_update_time": "20250723", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.05056", "html_url": "https://arxiv.org/abs/2507.05056", "title": "INTER: 通过交互引导采样减轻大型视觉语言模型幻觉", "title_en": "INTER: Mitigating Hallucination in Large Vision-Language Models by Interaction Guidance Sampling", "authors": "Xin Dong,Shichao Dong,Jin Wang,Jing Huang,Li Zhou,Zenghui Sun,Lihua Jing,Jingsong Lan,Xiaoyong Zhu,Bo Zheng", "background": "大型视觉语言模型（LVLMs）在生成响应时可能会产生与关联视觉内容不一致的幻觉，这给实际应用带来了重大挑战。人类的认知过程中很少会出现这种情况，主要由于人类能够有效利用多模态交互信息来进行数据样本的理解和分析。", "innovation": "提出了一种名为INTER的无训练新算法——交互指导采样（Interaction Guidance Sampling），该算法可以在不使用额外数据的情况下减轻大型视觉语言模型的幻觉。INTER特别引导LVLMs在生成响应时有效地重新应用多模态交互信息的理解，从而减少潜在的幻觉。", "conclusion": "INTER在包括VQA和图像字幕在内的六个基准测试中，相对于现有的解码策略，平均改进了高达3.4%的五种LVLMs。代码将在论文被接受后发布。"}
{"llm_update_time": "20250723", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.06821", "html_url": "https://arxiv.org/abs/2506.06821", "title": "LLMs是否能生成可靠的测试案例生成器？基于竞赛级别编程问题的研究", "title_en": "Can LLMs Generate Reliable Test Case Generators? A Study on Competition-Level Programming Problems", "authors": "Yuhan Cao,Zian Chen,Kun Quan,Ziliang Zhang,Yu Wang,Xiaoning Dong,Yeqi Feng,Guanzhong He,Jingcheng Huang,Jianhao Li,Yixuan Tan,Jiafu Tang,Yilin Tang,Junlei Wu,Qianyu Xiao,Can Zheng,Shouchen Zhou,Yuxiang Zhu,Yiming Huang,Tian Xie,Tianxing He", "background": "大型语言模型（LLMs）在代码生成方面展现了卓越的能力，能够处理复杂的推理任务。然而，关于LLMs通过测试用例生成进行代码检查或调试的应用探索仍然有限，特别是在竞赛级别编程（CP）程序中。本研究旨在探讨这一问题，并提出了TCGBench基准测试，专注于LLMs自动生成有效的测试用例生成器以及生成能够揭示人类编写代码缺陷的特定测试用例生成器的能力。实验结果表明，尽管最先进的LLMs在大多数情况下可以生成有效测试用例生成器，但在生成能够有效揭示人类代码缺陷的特定测试用例方面，大多数LLMs表现不佳，甚至高级的推理模型（如o3-mini）也无法达到人类性能水平。此外，研究构建了一个高质量的手动精编的用于生成特定生成器的指令集，并分析表明，借助这个数据集的提示和微调，可以提升LLMs的表现。", "innovation": "提出了TCGBench基准测试，旨在研究LLMs在生成有效测试用例生成器和生成能够揭示人类代码缺陷的特定测试用例生成器方面的能力。此外，研究构建了一个高质量的手动精编的用于生成特定生成器的指令集，通过提示和微调提高LLMs的性能。", "conclusion": "虽然最先进的LLMs在生成有效测试用例生成器方面表现良好，但在生成能够有效揭示人类代码缺陷的特定测试用例方面仍存在不足。通过特定数据集的提示和微调可以显著提升LLMs的表现。"}
{"llm_update_time": "20250723", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.05724", "html_url": "https://arxiv.org/abs/2507.05724", "title": "共享路由决策的稀疏混合专家Omni-路由器：用于语音识别", "title_en": "Omni-Router: Sharing Routing Decisions in Sparse Mixture-of-Experts for Speech Recognition", "authors": "Zijin Gu,Tatiana Likhomanenko,Navdeep Jaitly", "background": "Mixture-of-experts (MoE) 架构最初应用于语言建模，现已扩展到自动语音识别（ASR）。传统的 MoE 方法，如 Switch Transformer，在每层内独立路由专家。然而，研究发现大多数层的路由选择与其他层的路由选择缺乏强相关性。这限制了不同层间的专家合作和专业化程度。为了解决这一问题，论文提出了一种跨层共享路由的新方法，被称为 Omni-router Transformer，旨在促进不同层间专家间的合作，以及提高专业化水平。", "innovation": "提出了 Omni-router Transformer，通过在整个 MoE 层中共享路由方法，打破传统方法中单层独立路由的局限，促进不同层间的专家合作和专业化。实验结果表明，与密集模型和 Switch Transformer 模型相比，Omni-router Transformer 在大规模伪标记数据集上具有更低的训练损失，且在10个不同的语音识别基准测试中表现出更优性能，平均词错误率分别降低了11.2%和8.2%，同时还能提供结构化的专家使用方式和增强的跨域数据鲁棒性。", "conclusion": "Omni-router Transformer 在语音识别中表现出显著优势，不仅降低了训练损失，提高了整体性能，还在多样化的数据集上展示了更好的泛化能力。"}
{"llm_update_time": "20250723", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.06261", "html_url": "https://arxiv.org/abs/2507.06261", "title": "Gemini 2.5: 推动前沿的高级推理、多模态性、长上下文和下一代代理能力", "title_en": "Gemini 2.5: Pushing the Frontier with Advanced Reasoning, Multimodality, Long Context, and Next Generation Agentic Capabilities", "authors": "Gheorghe Comanici,Eric Bieber,Mike Schaekermann,Ice Pasupat,Noveen Sachdeva,Inderjit Dhillon,Marcel Blistein,Ori Ram,Dan Zhang,Evan Rosen,Luke Marris,Sam Petulla,Colin Gaffney,Asaf Aharoni,Nathan Lintz,Tiago Cardal Pais,Henrik Jacobsson,Idan Szpektor,Nan-Jiang Jiang,Krishna Haridasan,Ahmed Omran,Nikunj Saunshi,Dara Bahri,Gaurav Mishra,Eric Chu,Toby Boyd,Brad Hekman,Aaron Parisi,Chaoyi Zhang,Kornraphop Kawintiranon,Tania Bedrax-Weiss,Oliver Wang,Ya Xu,Ollie Purkiss,Uri Mendlovic,Ilaï Deutel,Nam Nguyen,Adam Langley,Flip Korn,Lucia Rossazza,Alexandre Ramé,Sagar Waghmare,Helen Miller,Nathan Byrd,Ashrith Sheshan,Raia Hadsell Sangnie Bhardwaj,Pawel Janus,Tero Rissa,Dan Horgan,Sharon Silver,Ayzaan Wahid,Sergey Brin,Yves Raimond,Klemen Kloboves,Cindy Wang,Nitesh Bharadwaj Gundavarapu,Ilia Shumailov,Bo Wang,Mantas Pajarskas,Joe Heyward,Martin Nikoltchev,Maciej Kula,Hao Zhou,Zachary Garrett,Sushant Kafle,Sercan Arik,Ankita Goel,Mingyao Yang,Jiho Park,Koji Kojima,Parsa Mahmoudieh,Koray Kavukcuoglu,Grace Chen,Doug Fritz,Anton Bulyenov,Sudeshna Roy,Dimitris Paparas,Hadar Shemtov,Bo-Juen Chen,Robin Strudel,David Reitter,Aurko Roy,Andrey Vlasov,Changwan Ryu,Chas Leichner,Haichuan Yang,Zelda Mariet,Denis Vnukov,Tim Sohn,Amy Stuart,Wei Liang,Minmin Chen,Praynaa Rawlani,Christy Koh,JD Co-Reyes,Guangda Lai,Praseem Banzal,Dimitrios Vytiniotis,Jieru Mei,Mu Cai", "background": "本文介绍了Gemini 2.X模型家族，包括Gemini 2.5 Pro和Gemini 2.5 Flash，以及早期的Gemini 2.0 Flash和Flash-Lite模型。Gemini 2.5 Pro是迄今为止功能最强大的模型，实现了在最前沿编码和推理基准测试上的最强性能。Gemini 2.5 Flash提供了出色的推理能力，同时大幅降低了计算需求和延迟。Gemini 2.0 Flash和Flash-Lite提供了低延迟和低成本的高性能解决方案。Gemini 2.X模型系列覆盖了模型能力与成本之间帕累托前沿的全部范围，让用户可以探索复杂的代理性问题解决的极限.", "innovation": "Gemini 2.5 Pro在编码和推理能力方面达到了最先进的表现，并且在多模态理解和视频内容处理方面表现出色。Gemini 2.5 Flash 在较低的计算需求和延迟条件下实现了显著的推理能力。Gemini 2.0 Flash 和Flash-Lite提供了在低延迟和低成本条件下的高性能解决方案。", "conclusion": "Gemini 2.X模型系列覆盖了模型能力与成本之间的全谱，使得用户能够探索复杂代理性问题解决的边界。"}
{"llm_update_time": "20250723", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2505.22116", "html_url": "https://arxiv.org/abs/2505.22116", "title": "由语言模型驱动的稀疏围手术期低血压事件多模态预测", "title_en": "Multimodal Forecasting of Sparse Intraoperative Hypotension Events Powered by Language Model", "authors": "Jintao Zhang,Zirui Liu,Mingyue Cheng,Shilong Zhang,Tingyue Pan,Yitong zhou,Qi Liu,Yanhu Xie", "background": "围手术期低血压（IOH）在全身麻醉过程中常发生，并与心肌损伤和高死亡率等不良结果相关。尽管IOH的重要性和影响，预测它仍受到稀疏事件以及整合不同患者静态和动态数据的挑战。", "innovation": "该论文提出了一个名为IOHFuseLM的多模态语言模型框架，通过两阶段训练策略在生理时间序列上进行领域自适应预训练，增强模型对低血压模式的敏感性，随后对原始临床数据集进行任务微调，以增强区分正常血压和低血压状态的能力。该模型通过在标记级别将结构化临床描述与相应的生理时间序列对齐，使得能捕捉个体化的时序模式及其背后的临床语义。此外，将静态患者属性转换为结构化文本以丰富个性化信息。", "conclusion": "在两个围手术期数据集的实验评估中，IOHFuseLM在准确识别IOH事件方面优于现有基准模型，展示了其在临床决策支持场景中的适用性。代码已公开，以促进可再现性。"}
{"llm_update_time": "20250723", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.08472", "html_url": "https://arxiv.org/abs/2507.08472", "title": "预训练大模型：三种优化器的性能比较", "title_en": "Pre-Training LLMs on a budget: A comparison of three optimizers", "authors": "Joel Schlotthauer,Christian Kroos,Chris Hinze,Viktor Hangya,Luzian Hahn,Fabian Küch", "background": "优化器在减少预训练时间并提高大模型性能方面起着决定性作用。本研究比较了三种主要变体：事实上的标准 AdamW、通过进化搜索开发的更简单的 Lion 以及第二阶优化器 Sophia。为了更好地泛化，我们分别使用两种不同的基础架构进行训练，并采用单个和多个周期的方法，同时保持令牌数量不变。使用 Maximal Update Parametrization 和较小的代理模型，我们针对每种基础架构和优化器的组合单独调整相关的超参数。研究表明，尽管三种优化器的结果大致相同，但 Sophia 在训练和验证损失方面最低，Lion 的 GPU 小时数训练速度最快，而 AdamW 在下游评估结果中最佳。", "innovation": "本研究通过比较 AdamW、Lion 和 Sophia 三种优化器，并通过 Maximal Update Parametrization 调整超参数，在预训练过程中寻找最优化方案，旨在降低预训练成本并提高模型性能。", "conclusion": "研究发现，虽然所有三种优化器的结果相近，但 Sophia 在训练和验证损失方面最优，Lion 的训练 GPU 小时数最短，而 AdamW 在下游评估中结果最好。"}
{"llm_update_time": "20250723", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2505.17692", "html_url": "https://arxiv.org/abs/2505.17692", "title": "ViP$^2$-CLIP: Visual-Perception Prompting with Unified Alignment for Zero-Shot Anomaly Detection", "title_en": "ViP$^2$-CLIP: Visual-Perception Prompting with Unified Alignment for Zero-Shot Anomaly Detection", "authors": "Ziteng Yang,Jingzehua Xu,Yanshu Li,Zepeng Li,Yeqiang Wang,Xinghui Li", "background": "现有的基于CLIP的方法试图通过手工制作或静态可学习提示激活模型的零样本异常检测（ZSAD）潜力，前者涉及高工程成本和有限的语义覆盖，后者在不同的异常类型上使用相同的描述，因而无法适应复杂的变异。CLIP最初是为大规模分类任务预训练的，其异常分割质量对类名的具体表述非常敏感，严重限制了依赖类标签的提示策略。", "innovation": "ViP$^2$-CLIP引入了一种视觉感知提示（ViP-Prompt）机制，该机制融合了全局和多尺度局部视觉上下文，以自适应生成精细粒度的文本提示，消除手动模板和类名先验。这种设计使模型能够专注于精确的异常区域，特别适用于类别标签模糊或隐私受限的情况。", "conclusion": "在15个工业和医疗基准测试上的广泛实验表明，ViP$^2$-CLIP实现了最先进的性能和强大的跨域泛化能力。"}
{"llm_update_time": "20250723", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.09279", "html_url": "https://arxiv.org/abs/2507.09279", "title": "Prompt4Trust: 一种用于多模态大型语言模型临床导向置信度校准的强化学习提示增强框架", "title_en": "Prompt4Trust: A Reinforcement Learning Prompt Augmentation Framework for Clinically-Aligned Confidence Calibration in Multimodal Large Language Models", "authors": "Anita Kriz,Elizabeth Laura Janes,Xing Shen,Tal Arbel", "background": "多模态大型语言模型（MLLMs）在医疗保健中有很大的应用潜力，但其在安全关键环境中的部署受到两个主要限制的阻碍：（i）对提示设计的敏感性，（ii）生成高置信度错误响应的倾向。由于临床医生可能依赖模型声明的置信度来判断预测的可靠性，当模型表达高置信度时，确保高准确性尤为重要。", "innovation": "本论文提出了一种新的强化学习（RL）框架Prompt4Trust，用于提示增强目标，旨在校准MLLMs的置信度。Prompt4Trust通过训练一个轻量级LLM生成上下文感知的辅助提示，以指导下游任务的MLLM生成表达更准确置信度的响应。这种方法特别专注于对安全和可信赖的临床决策最重要的校准方面。此外，所提出的改进方法也提高了任务准确性，实现了PMC-VQA基准（多模态医学影像问题回答）的最新性能。实验表明，使用小型下游任务MLLM训练的框架有望在未来大规模应用中实现可扩展的校准，而无需相关的计算成本。这项工作展示了自动化的提示工程对于提高MLLMs在安全关键环境中的可信度的潜力。", "conclusion": "该研究展示了自动化的提示工程对于提高MLLMs在安全关键环境中的可信度的潜力。通过Prompt4Trust框架，能够通过临床导向的校准目标来提高模型的可靠性，并展示了小尺寸模型在大模型中的零样本泛化能力，暗示了在安全关键环境中提升MLLMs的可信度的潜在方法。"}
{"llm_update_time": "20250723", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.11936", "html_url": "https://arxiv.org/abs/2507.11936", "title": "A Survey of Deep Learning for Geometry Problem Solving", "title_en": "A Survey of Deep Learning for Geometry Problem Solving", "authors": "Jianzhe Ma,Wenxuan Wang,Qin Jin", "background": "几何问题解决是数学推理的一个关键领域，广泛应用于教育、人工智能数学能力评估以及多模态能力评估等多个重要领域。近年来，深度学习技术的迅速发展，尤其是多模态大语言模型的兴起，导致了该领域的研究热潮。", "innovation": "本文提供了一篇关于深度学习在几何问题解决方面的综述，包括：(i) 几何问题解决相关任务的综述；(ii) 相关深度学习方法的彻底回顾；(iii) 评估指标与方法的详细分析；(iv) 当前挑战和未来研究方向的批判性讨论。旨在为该领域的进一步发展提供全面的参考。", "conclusion": "本文旨在提供一个全面且实用的深度学习在几何问题解决方面的参考，以推动该领域的发展。并通过GitHub持续更新研究论文列表，以提供最新的研究进展。"}
{"llm_update_time": "20250723", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.13354", "html_url": "https://arxiv.org/abs/2507.13354", "title": "大语言模型中实现变换器架构的物理模型", "title_en": "Physical models realizing the transformer architecture of large language models", "authors": "Zeqian Chen", "background": "2017年，变体模型结构的引入标志着自然语言处理领域取得了最显著的进步。该模型完全依赖于注意力机制来在输入和输出之间捕捉全局依赖关系。然而，作者认为我们对变体模型的本质理解仍然不足，特别是在物理层面的理解上。现代芯片如28nm以下的芯片应被视为超越传统统计系统的开放量子系统。因此，本研究从物理角度出发，基于大语言模型中的变换器架构，将这些模型构建为Fock空间上哈密顿空间中令牌的开放量子系统。", "innovation": "提出了从物理角度理解和实现大型语言模型中变换器架构的模型，将其视为开放量子系统。这种新的理论框架可能进一步增强我们对这些模型的理解，并为解释和优化提供了新的视角。", "conclusion": "通过构建基于变换器架构的大语言模型的物理模型，从开放量子系统的角度来理解这些模型，为自然语言处理中的理解与解释提供了新的思路。"}
{"llm_update_time": "20250723", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.07754", "html_url": "https://arxiv.org/abs/2507.07754", "title": "OPC: 以单一收缩为特征遗忘目标的深层遗忘机器卸载方法", "title_en": "OPC: One-Point-Contraction Unlearning Toward Deep Feature Forgetting", "authors": "Jaeheun Jung,Bosung Jung,Suhyun Bae,Donghun Lee", "background": "机器卸载旨在删除特定数据或类对训练模型的影响，以满足隐私、法律或伦理要求。现有的卸载方法往往只是浅度遗忘：卸载后的模型通过调整模型响应假装遗忘，但实际上内部表示仍然保留足够的信息以便恢复被遗忘的数据或行为。", "innovation": "定义了一个基于特征表示的单点收缩理论标准，称为`深层遗忘`，并提出了一种高效的近似算法，结合此理论构建了新型通用卸载算法：单一收缩（OPC）。实证评估表明，OPC不仅实现了有效的卸载性能，还表现出对性能恢复攻击和梯度逆转攻击的优异抗性。OPC的独特卸载性能主要源于其理论基础所推动的深层次特征遗忘。", "conclusion": "OPC 在图像分类卸载基准测试中展示了不仅有效的卸载性能，而且在对抗性能恢复攻击和梯度逆转攻击方面表现出显著的鲁棒性。这突显了提高机器卸载方法鲁棒性的需求。"}
{"llm_update_time": "20250723", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.07714", "html_url": "https://arxiv.org/abs/2507.07714", "title": "基于自适应高斯混合模型的欠约束缆驱动并联机器人异常检测", "title_en": "Adaptive Gaussian Mixture Models-based Anomaly Detection for under-constrained Cable-Driven Parallel Robots", "authors": "Julio Garrido,Javier Vales,Diego Silva-Muñiz,Enrique Riveiro,Pablo López-Matencio,Josué Rivera-Andrade", "background": "缆驱动并联机器人（CDPRs）越来越多地用于涉及预定义轨迹和中间停靠点的负载操作任务。在每个停靠点，平台保持固定姿态，电机保持缆绳张紧时，系统必须通过检测可能影响性能的异常（如风速突变或缆绳碰撞）来判断是否安全继续执行任务。该领域当前的方法往往需要额外的传感器来检测这些异常，本文探讨使用仅基于电机扭矩数据的方法来检测异常的可能性，而无需额外传感器。", "innovation": "本文提出了一种基于自适应高斯混合模型（GMM）的无监督异常检测算法，该算法可以从仅有的扭矩信号中识别出异常。此方法首先进行一个很短的校准阶段，以适应已知的无异常数据，然后实时分析扭矩测量数据通过马氏距离与GMM进行比对，并使用统计推断的阈值触发异常警报。模型参数会定期更新以适应不断变化的条件。此方法经验证能实现100%的真阳性率和95.4%的平均真阴性率，检测延迟为1秒，并且相比基于功率阈值和非自适应GMM的方法，显示出更高的鲁棒性和环境适应性。", "conclusion": "研究提出的方法在欠约束缆驱动并联机器人中表现出色，能够准确检测异常情况，且具有快速响应能力和较强的环境适应性，为该类机器人的安全控制提供了有效解决方案。"}
{"llm_update_time": "20250723", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.06229", "html_url": "https://arxiv.org/abs/2507.06229", "title": "Agent KB: 利用跨领域经验促进代理问题解决", "title_en": "Agent KB: Leveraging Cross-Domain Experience for Agentic Problem Solving", "authors": "Xiangru Tang,Tianrui Qin,Tianhao Peng,Ziyang Zhou,Daniel Shao,Tingting Du,Xinming Wei,Peng Xia,Fang Wu,He Zhu,Ge Zhang,Jiaheng Liu,Xingyao Wang,Sirui Hong,Chenglin Wu,Hao Cheng,Chi Wang,Wangchunshu Zhou", "background": "当前的AI代理无法有效从彼此的问题解决经验中学习，也不能利用过去的成功来引导自我反省和错误修正。这些限制使得代理在处理新任务时面临着较大的挑战。", "innovation": "引入了Agent KB，这是一个共享的知识库，它既捕获了高层次的问题解决策略，也包括了详细的执行教训，从而实现了代理框架之间知识的转移。还实施了一种新颖的教师-学生双重检索机制，其中学生代理获取工作流程级别的模式用于战略指导，而教师代理识别执行级别的模式用于改进，这种分层方法允许代理通过整合来自外部的多样化策略突破局限的推理路径。", "conclusion": "在GAIA基准上的评估显示，引入Agent KB可以显著提升性能，整体在pass@1下的成功率提高了6.06个百分点。对于SWE-bench代码修复任务，我们的系统显著提高了问题解决率，o3-mini在pass@1下的成功率从23%提高到31.67%，提升了8.67个百分点。归因分析表明，改进模块对解决具有挑战性的Level 3任务至关重要，其移除会导致3.85%的成功率下降，强调了有效的知识转移需要同时具备战略指导和执行层面的改进。"}
{"llm_update_time": "20250723", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.12367", "html_url": "https://arxiv.org/abs/2507.12367", "title": "GitChameleon 2.0: 评估 AI 代码生成对 Python 库版本不兼容性的应对能力", "title_en": "GitChameleon 2.0: Evaluating AI Code Generation Against Python Library Version Incompatibilities", "authors": "Diganta Misra,Nizar Islah,Victor May,Brice Rauby,Zihan Wang,Justine Gehring,Antonio Orvieto,Muawiz Chaudhary,Eilif B. Muller,Irina Rish,Samira Ebrahimi Kahou,Massimo Caccia", "background": "软件库的快速演变给代码生成带来了显著挑战，要求不断适应频繁的版本更新同时保持向后兼容性。现有代码演变基准提供了有价值的见解，但通常缺乏执行评估，无法生成符合特定库版本的代码。这促使研究人员开发了GitChameleon 2.0这一新颖的数据集，该数据集包括328个针对特定库版本的 Python 代码补全问题，并附带可执行的单元测试。GitChameleon 2.0通过执行评估全面测试了当前大型语言模型、LLM 助手、代码助手和 RAG 系统在版本条件下的代码生成功能准确性。研究显示，最先进的系统在这一任务上面临重大挑战；企业级模型在基线成功率范围为48-51%，突显了问题的复杂性。通过强调代码库的动态特性，GitChameleon 2.0提供了一个执行评估基准，帮助更清晰地理解挑战并促进更适应和可靠的人工智能代码生成方法的发展。该数据集和评估代码已公开发布。", "innovation": "GitChameleon 2.0通过结合针对特定库版本的328个Python代码补全问题和可执行的单元测试，提供了一个执行评估基准，这是现有代码演变基准所缺乏的。该数据集全面测试了AI模型在版本条件下的代码生成功能准确性，帮助更好地理解和解决这一挑战。", "conclusion": "研究结果表明，最先进的系统在这一任务上面临重大挑战；企业级模型在基线成功率范围为48-51%，突显了问题的复杂性。GitChameleon 2.0提供的执行评估基准有助于更清晰地理解这一挑战，并指导更适应和可靠的人工智能代码生成方法的发展。该数据集和评估代码已公开发布。"}
{"llm_update_time": "20250723", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.04123", "html_url": "https://arxiv.org/abs/2507.04123", "title": "边缘计算下的混合专家计算系统：实现自主驾驶中的准确高效3D物体检测", "title_en": "Towards Accurate and Efficient 3D Object Detection for Autonomous Driving: A Mixture of Experts Computing System on Edge", "authors": "Linshen Liu,Boyan Su,Junyue Jiang,Guanlin Wu,Cong Guo,Ceyu Xu,Hao Frank Yang", "background": "随着自主车辆（AVs）的发展，亟需一种既能实现低延迟又能确保高精度的3D物体检测系统。然而，传统的解决方案往往在处理这种实时数据时遇到困难。本文探讨了针对边缘平台优化的基于边缘的混合专家（MoE）计算系统（EMC2），旨在解决上述问题。", "innovation": "提出了一种名为EMC2的新型计算系统，它结合了LiDAR和相机数据，利用LiDAR的稀疏3D点云与相机的密集2D图像的互补优势，生成 robust 多模态表示。EMC2通过自适应多模态数据桥进行多尺度预处理，然后通过基于物体可见性和距离的场景感知路由机制动态分配特征到专门的专家模型。此外，EMC2还集成了硬件和软件联合优化技术，确保在资源受限的边缘设备上实现高效实时推理。", "conclusion": "EMC2在开源基准测试上表现出显著的进步，特别是在Jetson平台上，与15种基线方法相比，它的平均准确度提高了3.58%，推理速度提高了159.06%。实验结果表明，EMC2在Kitti和nuScenes数据集上的性能相似，证实了其在自主车辆3D物体检测任务中的可靠性和实时性。"}
{"llm_update_time": "20250723", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.14171", "html_url": "https://arxiv.org/abs/2507.14171", "title": "IPPRO: 基于投影偏移的重要性驱动裁剪方法实现大小无关的结构化裁剪", "title_en": "IPPRO: Importance-based Pruning with PRojective Offset for Magnitude-indifferent Structural Pruning", "authors": "Jaeheun Jung,Jaehyuk Lee,Yeajin Lee,Donghun Lee", "background": "随着对神经网络压缩方法的需求增长，基于重要性的结构化裁剪方法中的重要性度量，尤其是基于大小的重要性度量，常常被广泛研究。然而，基于大小的重要性度量在裁剪决策中占据主导地位，这限制了裁剪的灵活性。虽然小滤波器的去除可能意味着有冗余的滤波器可以被裁剪，但是基于大小的重要性度量却可能导致即使较大的滤波器并非冗余，它们也不会被裁剪的情况。因此，迫切需要提出一种新型的战略，挑战这些基于大小的重要度量，使得每个滤波器都有公平的机会被裁剪，特别是在项目空间中的布局有助于提升裁剪的灵活性。本文提出了一种新的裁剪策略来测量滤波器是否趋向于项目空间的原点，并以此为基础计算新的重要性分数PROscore，进而发展了大小无关的重要性驱动结构化裁剪IPPROMethod（IPPRO）", "innovation": "本文提出了一个基于项目空间的方法，通过测量滤波器是否趋向于原点来评估其裁剪性，并以此为基础计算了一个新的重要性分数PROscore，进而发展了一种称为大小无关的重要性驱动结构化裁剪IPPROMethod。这种方法突破了基于大小的重要度量的限制，为每个滤波器提供了一个公平的裁剪机会，同时通过减少裁剪后的性能损失和促进性能提升的fine-tuning方法展现出了优良的效果", "conclusion": "本文通过引入一种基于项目空间的方法，挑战了基于大小的重要度量在裁剪中的主导地位，提出了一种大小无关的重要性驱动结构化裁剪方法IPPROMethod，这种方法通过计算新定义的PROscore分数，在保持接近原始准确度的前提下，实现了有效且公平的神经网络结构化裁剪，并通过实验证明其有效性和潜在优势"}
{"llm_update_time": "20250723", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.14184", "html_url": "https://arxiv.org/abs/2507.14184", "title": "NeuroHD-RA: 学习提炼的节奏对齐超维度模型", "title_en": "NeuroHD-RA: Neural-distilled Hyperdimensional Model with Rhythm Alignment", "authors": "ZhengXiao He,Jinghao Wen,Huayu Li,Ao Li", "background": "该论文基于心电图（ECG）进行疾病检测，提出了一种新颖且具有解释性的框架。传统的超维度计算（HDC）方法依赖静态、随机的投影，而该框架引入了一种基于RR间期的节奏感知和可学习的编码管道，它利用心电段合乎生理的分割策略。这种方法的核心是结合了学习提炼的HDC结构，包括可学习的RR块编码器和平面二进制线性超维度投影层，这些层是与交叉熵和基于代理的度量损失共同优化的。", "innovation": "该方法是最新的，因为它提出了结合了超维度计算和可学习神经编码的节奏意识和可训练的ECG信号处理策略。关键创新在于构建了一个学习提炼的HDC架构，其中包含一个可学习的RR块编码器和平面二进制线性超维度投影层，它们与交叉熵和基于代理的度量损失一起进行联合优化。这种综合框架保留了HDC的符号可解释性，同时能够实现任务适应性的表示学习。", "conclusion": "在Apnea-ECG和PTB-XL数据集上的实验表明，该模型在精度和F1分数方面显著优于传统的HDC和经典的机器学习基线模型。该框架提供了一种适用于边缘设备的心电图分类高效且可扩展的解决方案，并且具有很强的可解释性和个性化健康监测的潜力。"}
{"llm_update_time": "20250723", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.14241", "html_url": "https://arxiv.org/abs/2507.14241", "title": "Promptomatix: 一种针对大规模语言模型的自动提示优化框架", "title_en": "Promptomatix: An Automatic Prompt Optimization Framework for Large Language Models", "authors": "Rithesh Murthy,Ming Zhu,Liangwei Yang,Jielin Qiu,Juntao Tan,Shelby Heinecke,Caiming Xiong,Silvio Savarese,Huan Wang", "background": "大型语言模型（LLMs）在经过精心构思的提示下表现最佳，然而提示工程仍然是手动、不一致的，并且对非专家来说不具有可访问性。论文背景指出目前提示工程存在这些不足，因此需要一种能够自动优化提示的框架来提升语言模型的效果和效率，同时降低对人工调优和专业领域知识的要求。", "innovation": "本文提出了一种名为Promptomatix的自动提示优化框架，可以将自然语言任务描述转化为高质量的提示，并支持轻量级元提示优化器和DSPy驱动的编译器。该体系结构模块化设计，未来可以扩展到更先进的框架。Promptomatix通过分析用户意图、生成合成训练数据、挑选提示策略并使用成本意识目标改进提示，展示了在五个任务类别上与现有库相比，它实现了竞争力或更优的性能，同时减少了提示长度和计算开销，使提示优化可以规模化且高效进行。", "conclusion": "Promptomatix能够自动优化提示，提升大规模语言模型的效果。该系统通过多种技术简化了提示工程过程，降低了对人工和领域专业知识的要求，展示了在多个任务上的高效性和规模化能力。"}
{"llm_update_time": "20250723", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.15773", "html_url": "https://arxiv.org/abs/2507.15773", "title": "Supernova：在变换器架构中实现少而精", "title_en": "Supernova: Achieving More with Less in Transformer Architectures", "authors": "Andrei-Valentin Tanase,Elena Pelican", "background": "文章介绍了一个650M参数的仅解码器自注意力模型Supernova，展示了通过精心的架构设计和创新的标记化技术，可以在保持计算效率的同时达到大模型的性能。文章分析了如何通过特定的技术组合实现高性能。", "innovation": "文章的关键创新在于自定义的、具有128,000词汇的字节级别BPE标记器，该标记器在压缩性能方面达到了最新的技术水平。此外，文章还结合了Rotary Positional Embeddings (RoPE)、Grouped Query Attention (GQA)、RMSNorm和SwiGLU激活函数。这些技术使得Supernova在使用更少的参数和训练令牌的情况下，达到了与1B参数模型相当的性能。", "conclusion": "文章的结论挑战了现有的扩展范式，展示了架构效率和标记化质量可以弥补参数数量的减少，使模型在保持高效计算的同时达到高性能。Supernova在参数数量减少35%和只使用100B训练令牌的情况下，实现了接近1B参数模型90%的性能，比竞争对手模型所需的训练令牌少一个数量级。"}
{"llm_update_time": "20250723", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.15783", "html_url": "https://arxiv.org/abs/2507.15783", "title": "爱情，慰藉与遗憾：青少年对聊天机器人过度依赖的叙述", "title_en": "Romance, Relief, and Regret: Teen Narratives of Chatbot Overreliance", "authors": "Mohammad 'Matt' Namvarpour,Brandon Brofsky,Jessica Medina,Mamtaj Akter,Afsaneh Razi", "background": "随着生成式人工智能（GenAI）驱动的聊天机器人嵌入青少年的生活，人们对其可能带来的情感依赖和数字过度依赖提出了担忧。尽管已有研究探讨了成年人对这些聊天机器人的过度依赖问题，但还未有研究专门关注青少年与具有可定制个性的聊天机器人互动的情况。该研究分析了来自用户自述13-17岁用户的318条Reddit帖子，以了解青少年过度依赖聊天机器人的模式。结果显示，许多青少年开始使用聊天机器人是为了寻求情感支持或进行创造性表达，但随后会发展出强烈的依附感，这会干扰他们与现实生活中的关系和日常活动。", "innovation": "这项研究首次专门研究了青少年与具有可定制个性的聊天机器人的互动情况，通过分析Reddit上的318条评论帖子来揭示青少年在使用这些聊天机器人过程中表现出的心理压力迹象、反复发作的循环以及难以脱离问题。研究表明，许多青少年在认识到聊天机器人带来的伤害、回归现实社交场景或因平台限制而感到挫败后，才停止对聊天机器人的过度依赖。", "conclusion": "研究结果表明，青少年的过度依附通常会在重新考虑聊天机器人的危害性、返回现实生活社交环境或因平台限制感到沮丧时结束。基于这些发现，该研究提出了一些建议，旨在未来聊天机器人的设计中促进自我意识的发展、增强现实世界中的参与度，并让青少年参与到开发更安全的数字工具的过程中来。"}
{"llm_update_time": "20250723", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.12108", "html_url": "https://arxiv.org/abs/2507.12108", "title": "多模态协调在线行为：权衡与策略", "title_en": "Multimodal Coordinated Online Behavior: Trade-offs and Strategies", "authors": "Lorenzo Mannocci,Stefano Cresci,Matteo Magnani,Anna Monreale,Maurizio Tesconi", "background": "跨多种形式的在线行为，从有益的集体行动到有害的操控如虚假信息运动已经成为数字生态系统分析的关键焦点。传统方法往往依赖单一模态分析，关注单一类型的互动，如共转发或共标签，或者独立考虑多种模态。然而，这些方法可能忽视了多重模态协调中的复杂动态。本研究对比了不同类型的操作化以检测多模态协调行为的方法，探讨了弱整合和强整合多模态模型之间的权衡，强调捕捉更广泛协调模式与识别紧密切合行为之间的平衡。", "innovation": "通过对比单模态和多模态方法，评估不同的数据模态的独特贡献，研究探讨了不同实现多模态如何影响检测结果。研究发现，不是所有模态都提供独特的见解，但通过多模态方法可以获得更全面的协调动态理解。", "conclusion": "这项工作增强了检测和分析协调在线行为的能力，为确保数字平台的完整性提供了新的视角。"}
{"llm_update_time": "20250723", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.15852", "html_url": "https://arxiv.org/abs/2507.15852", "title": "SeC: 通过渐进概念构建推进复杂视频对象分割", "title_en": "SeC: Advancing Complex Video Object Segmentation via Progressive Concept Construction", "authors": "Zhixiong Zhang,Shuangrui Ding,Xiaoyi Dong,Songxin He,Jianfan Lin,Junsong Tang,Yuhang Zang,Yuhang Cao,Dahua Lin,Jiaqi Wang", "background": "视频对象分割（VOS）是计算机视觉的核心任务，需要模型跨视频帧追踪并分割目标对象。尽管有明显的技术进步，当前技术在处理剧烈的视觉变化、遮挡和复杂场景变化时仍落后于人类的能力。当前技术主要依赖于外观匹配，忽略了人类对对象的理解能力，这使得识别过程不够稳健。为解决这一问题，本研究提出了一种概念驱动的分割框架——Segment Concept（SeC），通过渐进构建和利用高层次、对象中心化的表示替换传统特征匹配。SeC 使用大型视觉语言模型（LVLMs）在不同帧之间整合视觉线索，构建稳健的概念先验。在推理过程中，SeC 基于处理后的帧形成目标的全面语义表示，实现后续帧的稳健分割。此外，SeC 持续平衡基于 LVLM 的语义推理与增强特征匹配，根据场景复杂性动态调整计算资源。为了评估复杂场景中的高级概念推理和稳健语义理解要求，引入了名为 SeCVOS 的基准测试，包含 160 个手工标注的多场景视频，以挑战模型处理显著外观变化和动态场景转换的能力。", "innovation": "提出了Segment Concept（SeC），这是一种基于概念的方法，通过渐进构建和利用高层次、对象中心化的表示，替代了传统特征匹配方法。SeC 利用大型视觉语言模型在不同帧之间整合视觉线索，构建稳健的概念先验。此外，SeC 通过动态调整 LVLM 语义推理和特征匹配的平衡，根据场景复杂性调整其计算资源。SeC 在 SeCVOS 挑战集中实现了 11.8 分的改进，突破了现有基于概念的视频对象分割的最高水平。", "conclusion": "本研究引入了 SeCVOS 挑战集，旨在检验视频对象分割方法在需要高级概念推理和稳健语义理解的场景中的表现。研究提出的 SeC 方法通过复杂和多场景的视觉和语言线索的整合，有效提升了视频对象分割的性能，并且证实了新基准的重大挑战性和SeC在复杂场景中的优越性。"}
{"llm_update_time": "20250723", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.14096", "html_url": "https://arxiv.org/abs/2507.14096", "title": "TREC Plain Language Adaptation of Biomedical Abstracts (PLABA) track 经验教训", "title_en": "Lessons from the TREC Plain Language Adaptation of Biomedical Abstracts (PLABA) track", "authors": "Brian Ondov,William Xia,Kush Attal,Ishita Unde,Jerry He,Dina Demner-Fushman", "background": "近年来，语言模型在专业面向的生物医学文献向口语化转换方面展现了潜力，使患者和护理人员能够更好地理解。然而，这些模型的不可预测性，加上在这一高风险领域中潜在的危害，意味着需要进行严格的评估。因此，本研究旨在激发研究和提供高质量的评估，以检验最有可能的系统。", "innovation": "该研究在2023年和2024年的Text Retrieval Conferences举办了Plain Language Adaptation of Biomedical Abstracts (PLABA)竞赛。任务包括整个句子级别的摘要重写（Task 1）以及识别和替换困难术语（Task 2）。为了自动评估Task 1，研究者开发了一套由专业人员撰写的参考文献。自动、参考型的评估指标通常与手工评价不一致。", "conclusion": "PLABA竞赛表明，大型语言模型在适应生物医学文献方面具有潜力，但同时也显示出他们的局限性，需要改进自动基准测试工具。"}
{"llm_update_time": "20250723", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.13618", "html_url": "https://arxiv.org/abs/2507.13618", "title": "Seed-X：使用7B参数构建强大的多语言翻译大模型", "title_en": "Seed-X: Building Strong Multilingual Translation LLM with 7B Parameters", "authors": "Shanbo Cheng,Yu Bao,Qian Cao,Luyang Huang,Liyan Kang,Zhicheng Liu,Yu Lu,Wenhao Zhu,Jingwen Chen,Zhichao Huang,Tao Li,Yifu Li,Huiying Lin,Sitong Liu,Ningxin Peng,Shuaijie She,Lu Xu,Nuo Xu,Sen Yang,Runsheng Yu,Yiming Yu,Liehao Zou,Hang Li,Lu Lu,Yuxuan Wang,Yonghui Wu", "background": "多语言翻译是大型语言模型（LLMs）面临的挑战之一，因为它们需要处理自动翻译中出现的复杂语言模式和僵化的翻译问题。", "innovation": "我们介绍了Seed-X，这是一个由指令模型和推理模型组成的开放源代码LLM家族，通过7B参数大小推动翻译能力的新边界。基模型在28种语言的多元高质量数据集上进行预训练，涵盖单语和双语文本，充分利用多语言数据的潜力。指令模型通过因果推理（CoT）进行微调，并通过强化学习（RL）进一步增强，以更好地适应各种语言对。Seed-X在28种语言中实现了性能与领先的闭源模型Gemini-2.5和GPT-4o相当，并在自动评估指标和人工评估中显著优于更大的开源模型。", "conclusion": "我们通过优化过程分享了最佳实践，并将参数公开供翻译研究和应用的发展使用。"}
{"llm_update_time": "20250723", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.15493", "html_url": "https://arxiv.org/abs/2507.15493", "title": "GR-3 技术报告", "title_en": "GR-3 Technical Report", "authors": "Chilam Cheang,Sijin Chen,Zhongren Cui,Yingdong Hu,Liqun Huang,Tao Kong,Hang Li,Yifeng Li,Yuxiao Liu,Xiao Ma,Hao Niu,Wenxuan Ou,Wanli Peng,Zeyu Ren,Haixin Shi,Jiawen Tian,Hongtao Wu,Xin Xiao,Yuyang Xiao,Jiafeng Xu,Yichu Yang", "background": "文中提到该研究致力于构建通用机器人策略，并介绍了GR-3的发展。GR-3是一个大规模的视-听-行模型，能处理新的物理对象、环境和抽象指令，并通过少量的人类轨迹数据高效微调，实现快速且成本效益高的适应。", "innovation": "GR-3通过结合大规模Web数据的共同训练、VR设备收集的人类轨迹数据高效的微调和有效的机器人轨迹数据的模仿学习，实现了多种复杂任务的处理。此外，研究还引入了一种名为ByteMini的灵活且可靠的双臂移动机器人，能够与GR-3协同完成多样任务。实验结果显示，GR-3在多种挑战性任务上的表现超越了基准方法π0。", "conclusion": "研究展示了GR-3在多种复杂任务上的优越性能，并希望未来能协助人类在日常生活中。"}
{"llm_update_time": "20250723", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2507.15868", "html_url": "https://arxiv.org/abs/2507.15868", "title": "细微更改，巨大后果：区分大型语言模型中的有效与有害鲁棒性", "title_en": "Small Edits, Big Consequences: Telling Good from Bad Robustness in Large Language Models", "authors": "Altynbek Ismailov,Salia Asanova", "background": "当前大型语言模型（LLMs）能够编写代码，即使轻微的错误也会影响安全或财务。然而，人们期望这些模型能忽略随机的拼写错误。本文通过分析50个LeetCode问题以及三种不同重要性的微小提示修改，探究有用鲁棒性与有害不敏感性的界限。实验结果显示，模型在提示大量缺失时仍能保持正确性，但在任务方向翻转时反应迟钝；同时，领域特定术语的更改介于两者之间。这些发现揭示了目前LLMs在处理无害噪声和意义改变的编辑时的模糊界限，有时会将两者都视为可忽略的情况。", "innovation": "文章通过设计三种类型的最小提示修改（删除词、量词翻转、领域的术语替换）来测试大型语言模型，揭示模型对于不同类型的编辑反应不同。此外，研究了六种前沿模型，包括三种“推理校准”的版本，对它们的Python输出与原始测试套件进行对比，揭示模型是否重用了基线解决方案还是适应变化。研究发现，模型在提示显著缺失时仍能保持正确性，但在任务方向翻转时反应迟钝，表明模型在处理无害噪声和意义改变的编辑时界限模糊。", "conclusion": "当前大型语言模型在处理无害噪声和意义改变的编辑时存在模糊界限，往往会将二者都视为可忽略的情况。屏蔽显眼的锚点（如函数名）可以促使评估。建议评估和训练协议奖励不同敏感性：在良性噪声下保持稳定，但当意义发生真正变化时则需适配或拒绝。"}
{"llm_update_time": "20250723", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.15292", "html_url": "https://arxiv.org/abs/2507.15292", "title": "EndoControlMag: 强化周期参考重置和分层组织感知双模式控制的内镜血管运动放大", "title_en": "EndoControlMag: Robust Endoscopic Vascular Motion Magnification with Periodic Reference Resetting and Hierarchical Tissue-aware Dual-Mask Contro", "authors": "An Wanga,Rulin Zhou,Mengya Xu,Yiru Ye,Longfei Gou,Yiting Chang,Hao Chen,Chwee Ming Lim,Jiankun Wang,Hongliang Ren", "background": "在内镜手术中，视觉化微妙的血管运动对于手术的精确性和决策至关重要，但因手术场景复杂且动态变化，一直存在挑战。", "innovation": "提出了EndoControlMag，一种无需训练、基于拉格朗日的方法，专门针对内镜环境。它包含了两个核心模块：周期参考重置（PRR）方案，可将视频划分为带有动态更新参考帧的短重叠片段，以防止误差累积并保持时间一致性；以及具有双模式掩码膨胀的分层组织感知放大（HTM）框架。此外，采用两种自适应软化策略：基于运动的软化和基于距离的指数衰减。", "conclusion": "在包含四种不同手术类型的EndoVMM24数据集上评估了EndoControlMag，在各种复杂场景（如遮挡、仪器干扰、视角变化和血管变形）下，EndoControlMag在放大精度和可视化质量上均明显优于现有方法，同时保持了在复杂手术条件下的鲁棒性。"}
{"llm_update_time": "20250723", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2507.16002", "html_url": "https://arxiv.org/abs/2507.16002", "title": "在低语境下增强藏文命名实体识别：基于transformer模型的检索增强比较研究", "title_en": "Enhancing Hindi NER in Low Context: A Comparative study of Transformer-based models with vs. without Retrieval Augmentation", "authors": "Sumit Singh,Rohit Mishra,Uma Shanker Tiwary", "background": "命名实体识别（NER）在自然语言处理中是一个主要挑战，涉及在文本输入中识别和分类命名实体。改进NER的策略包括使用特定于语言的预训练编码器（如MuRIL和XLM-R）和生成模型（如Llama-2-7B-chat-hf、Llama-2-70B-chat-hf、Llama-3-70B-Instruct和GPT3.5-turbo），以及通过从Wikipedia等外部相关上下文中检索数据来扩充数据量。研究目的是评估这些模型在使用和不使用检索增强（RA）方法时的性能差异，并探讨其在低资源语言中的应用效果。", "innovation": "该研究引入了使用特定于Hindi的语言模型和生成模型结合检索增强（RA）的方法来提高Hindi NER的性能。特别地，对预训练模型MuRIL、XLM-R和Llama2-7B进行了微调，并与非微调的生成模型（如Llama2-70B、Llama3-70B和GPT3.5-turbo）进行了比较，展示了RA在低语境数据中显著提高模型性能的效果，并探讨了不同模型在结合RA时的表现差异。", "conclusion": "研究表明，带检索增强（RA）的模型通常优于不使用RA的基线方法。具体地说，MuRIL和XLM-R的宏F1分数分别由0.69和0.495提高到0.70和0.71。Llama2-7B的微调版本显著优于非微调版本。生成模型在使用增强数据时也表现更好。该研究为如何最佳地利用数据增强方法和预训练模型来提高NER性能，特别是在资源有限的语言中，提供了重要的见解。"}
{"llm_update_time": "20250723", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2507.16054", "html_url": "https://arxiv.org/abs/2507.16054", "title": "AutoMeet：汽车工程中自动化会议的生成式AI初步研究", "title_en": "AutoMeet: a proof-of-concept study of genAI to automate meetings in automotive engineering", "authors": "Simon Baeuerle,Max Radyschevski,Ulrike Pado", "background": "在大型组织中，知识主要通过会议分享，这占用了大量的工作时间。频繁的面对面会议导致文档不一致——官方会议纪要、个人笔记或演示文稿可能不存在。因此，会议之外难以检索共享的信息，需要进行冗长的更新并采用高频率的会议安排。", "innovation": "生成式人工智能（genAI）模型，如大型语言模型（LLMs），在言语和书面语言处理方面表现出色。本文提出使用genAI自动化工程部门的会议记录和文档工作流程，通过通用接口自动创建会议纪要，并通过聊天机器人接口轻松查询。研究还测试了这种基于AI的软件工具的实际应用，并收集了广泛的伦理和技术方面的调查数据。直接反馈显示可以显著减少会议工作量，技术方面已经解决，但组织因素对于该系统的成功伦理使用至关重要。", "conclusion": "用户认为，在汽车工程部门中使用genAI可以显著减少会议投入的工作量，技术上已经解决了大部分问题，但组织的使用和实施是关键，在伦理使用方面的挑战也需要进一步关注。"}
{"llm_update_time": "20250723", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2507.15864", "html_url": "https://arxiv.org/abs/2507.15864", "title": "使用双相似性进行低资源命名实体识别的对抗性示范学习", "title_en": "Adversarial Demonstration Learning for Low-resource NER Using Dual Similarity", "authors": "Guowen Yuan,Tien-Hsuan Wu,Lianghao Xia,Ben Kao", "background": "本文研究了在低资源场景下基于示范学习的命名实体识别（NER）问题。我们发现了示范构建和模型训练中的两个问题：现有方法主要依赖语义相似性选择示范实例，但特征相似性可能提供更好的性能提升；同时，NER标签器引用示范实例的能力通常不足。", "innovation": "提出了通过双重相似性（包括语义相似性和特征相似性）选择实例的策略，以及通过对抗性示范训练NER模型，迫使模型在执行标记任务时参考示范实例。", "conclusion": "在低资源NER任务中进行了全面实验，结果表明，本文方法在多项指标上优于现有方法。"}
{"llm_update_time": "20250723", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2507.16011", "html_url": "https://arxiv.org/abs/2507.16011", "title": "mRAKL：低资源语言的多语言检索增强知识图构建", "title_en": "mRAKL: Multilingual Retrieval-Augmented Knowledge Graph Construction for Low-Resourced Languages", "authors": "Hellina Hailu Nigatu,Min Li,Maartje ter Hoeve,Saloni Potdar,Sarah Chasins", "background": "知识图谱表示现实世界中的实体及其相互关系。在多语言环境下，构建或多语言知识图构（mKGC）的任务是自动构建或预测知识图中的缺失实体和链接。当前的研究工作将mKGC任务重新定义为问答任务，并引入了一种基于检索增强生成（RAG）系统的mRAKL方法，通过使用问题中的头实体和链接关系来预测尾实体作为答案。主要实验集中在两种低资源语言：提格雷尼亚语和阿姆哈拉语上，同时也尝试使用阿拉伯语和英语进行跨语言迁移。研究发现，在使用BM25检索器时，基于RAG的方法在没有上下文的情境下改善了性能。研究表明，在理想化的检索系统下，mRAKL分别提升了提格雷尼亚语和阿姆哈拉语的准确性4.92和8.79个百分点。", "innovation": "将mKGC任务重新定义为问答任务，并提出一种基于检索增强生成（RAG）系统的mRAKL方法，以自动构建或多语言知识图；使用BM25检索器进行验证，在实验中观察到基于RAG的方法比无上下文的方法改善了性能；通过对比实验，发现理想化的检索系统下，mRAKL能显著提高Tigrinya和Amharic语言的准确性。", "conclusion": "mRAKL方法在多语言知识图构建中展现出较好的性能，特别是在低资源语言上，通过对比实验展示了基于RAG方法的有效性，并指出在未来的工作中不可避免地需要更改进化的检索系统。"}
{"llm_update_time": "20250723", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2507.15863", "html_url": "https://arxiv.org/abs/2507.15863", "title": "eSapiens的DEREK模块：基于LLMs的深度提取与推理知识引擎", "title_en": "eSapiens's DEREK Module: Deep Extraction & Reasoning Engine for Knowledge with LLMs", "authors": "Isaac Shi,Zeyuan Li,Fan Liu,Wenli Wang,Lewei He,Yang Yang,Tianyu Shi", "background": "本文介绍了由eSapiens设计和实现的一种安全可靠的Retrieval-Augmented Generation（RAG）流水线——DEREK（Deep Extraction & Reasoning Engine for Knowledge），专门针对企业的文档问答需求。该系统能够处理异构内容（如PDF、Office文件、网页），将内容切分为1000个标记重叠的块，并在混合HNSW+BM25存储中进行索引。用户查询通过GPT-4o精炼，结合向量+BM25检索，通过Cohere重新排名，并由LLM使用CO-STAR提示工程进行回答。LangGraph验证器确保引用的重叠，并不断重新生成答案，直到每个声明都有依据。系统的所有组件都在容器中运行，端到端TLS 1.3和AES-256加密确保了安全性。该系统一致实现了精确、可追溯的文档问答，并提供了满足企业对安全、可审计和语境一致性检索需求的可靠基线，特别是在法律和金融等高风险领域。", "innovation": "1. DEREK模块采用深层提取和推理机制，能够处理企业中的多样文档资料，生成高质量的文档问答结果。\n2. 使用GPT-4o精炼用户查询，提高检索的准确性和相关性。\n3. 结合向量+BM25检索和基于Cohere的重新排名，提高了检索效果。\n4. 通过CO-STAR提示工程符合语境推理，并使用LangGraph验证器确保答案的正确性和可追溯性，从而减少不支持的陈述。\n5. 系统所有组件均运行在容器中，确保了端到端的安全性和保密性。\n6. 提供了高精度和高利用率的高质量文档问答，降低了运营成本，满足了企业需求。", "conclusion": "通过在LegalBench数据集中的测试，DEREK模块在Recall@50上提高了约1个点，Precision@10上提高了约7个点，验证器确保了可信利用率为0.50以上，同时将没有支持的说法减少到不到3%。所有组件在容器中运行，实现了端到端的TLS 1.3和AES-256加密，降低了操作成本，确保了文档问答的准确性和真实性。"}
{"llm_update_time": "20250723", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2507.16003", "html_url": "https://arxiv.org/abs/2507.16003", "title": "无训练学习：上下文学习的隐式动态", "title_en": "Learning without training: The implicit dynamics of in-context learning", "authors": "Benoit Dherin,Michael Munn,Hanna Mazzawi,Michael Wunder,Javier Gonzalvo", "background": "大型语言模型（LLM）具有在上下文中的学习能力，即在推理阶段，LLM 可以通过提示中的示例学习新的模式，即使这些模式在训练期间没有见过。尽管这种现象很显著，但背后具体的机制尚不清楚。", "innovation": "本文提出了一种机制，即通过将自我注意层与MLP层堆叠，使得变压器块可以隐式地修改MLP层的权重以适应上下文。理论和实验证明，这一简单机制可能是LLM能够在上下文中学到新知识而非仅在训练过程中学习的原因。", "conclusion": "在温和的假设下，本文展示了变压器块如何隐式地将上下文转换为MLP层权重的低秩更新。"}
{"llm_update_time": "20250723", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2507.16007", "html_url": "https://arxiv.org/abs/2507.16007", "title": "帮助我写故事：评估LLM生成写作反馈的能力", "title_en": "Help Me Write a Story: Evaluating LLMs' Ability to Generate Writing Feedback", "authors": "Hannah Rashkin,Elizabeth Clark,Fantine Huot,Mirella Lapata", "background": "本研究探索了语言模型为创意作家提供有意义写作反馈的能力。研究中定义了一个新的任务、数据集和评估框架，通过故意引入写作问题来构建一个受控的测试集。这项研究的目标是研究常用的大语言模型在这项任务中的表现，使用自动化和人工评估指标进行评估。", "innovation": "研究设计了一个由1300个故事组成的新型测试集，这些故事被故意修改以引入写作问题。通过这种方法，研究者能够更严格地评估模型的表现，并通过自动化和人工评估指标来考察模型的性能。", "conclusion": "研究表明，当前模型在许多方面具备较强的“开箱即用”的行为，在提供具体且大部分准确的写作反馈方面表现出色。然而，模型在识别故事中的主要写作问题及正确决定何时提供批判性反馈与何时提供积极反馈方面存在不足。"}
{"llm_update_time": "20250723", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2507.16076", "html_url": "https://arxiv.org/abs/2507.16076", "title": "提示决定人(presence)：大型语言模型中社会人口特征提示的系统评估", "title_en": "The Prompt Makes the Person(a): A Systematic Evaluation of Sociodemographic Persona Prompting for Large Language Models", "authors": "Marlene Lutz,Indira Sen,Georg Ahnert,Elisa Rogers,Markus Strohmaier", "background": "随着大型语言模型（LLMs）的发展，人们越来越多地使用人物提示来模拟各种社会人口群体的看法。然而，人物提示的形成方式可以显著影响结果，这引发了对其模拟准确性的担忧。本文通过系统地使用五个开源LLM，研究了不同类型的人物提示策略，包括角色扮演形式和人口统计学预热策略，如何影响LLM模拟15个交叉人口群体的结果，无论是开放还是封闭式任务。研究发现LLMs在模拟边缘群体，尤其是非二元性别、拉丁裔和中东身份方面存在困难，但选择人口统计学预热和角色扮演策略显著影响其描述。研究还发现，采用访谈式格式和基于名字的预热可以帮助减少刻板印象，提高一致性。令人惊讶的是，较小的模型如OLMo-2-7B比更大的模型如Llama-3.3-70B表现更好。这项研究为设计基于LLM的社会人口特征人物提示提供了实际建议。", "innovation": "本文系统地评估了不同类型的人物提示策略对大型语言模型（LLMs）模拟不同社会人口群体的影响。通过使用访谈式格式和基于名字的预热策略，研究发现可以减少刻板印象并提高一致性。研究还发现，较小的模型比更大的模型在某些情况下表现更好。这项研究为设计社会人口特征人物提示提供了实际指导。", "conclusion": "大型语言模型在模拟边缘群体现状方面存在困难，尤其是非二元性别、拉丁裔和中东身份。然而，通过采用访谈式格式和基于名字的预热策略，可以显著减少刻板印象并提高模拟的一致性。此外，小于70B参数的小模型在某些任务中优于更大的模型。这些发现为设计基于LLM的社会人口特征提示提供了一些建议。"}
{"llm_update_time": "20250723", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2507.16083", "html_url": "https://arxiv.org/abs/2507.16083", "title": "为嵌入设备的大语言模型实现高效组合多任务", "title_en": "Efficient Compositional Multi-tasking for On-device Large Language Models", "authors": "Ondrej Bohdal,Mete Ozay,Jijoong Moon,Kyeng-Hun Lee,Hyeonmok Ko,Umberto Michieli", "background": "适配器参数提供了一种修改机器学习模型行为的机制，并在大规模语言模型（LLMs）和生成型人工智能中变得非常流行。这些参数可以通过任务合并的方式支持多个任务。然而，先前的工作主要集中在每个测试示例仅涉及单一任务的场景中。本研究关注嵌入设备的设置，并探讨文本组合多任务问题，即每个测试示例需要同时执行多个任务。例如，生成长文本的翻译摘要需要同时解决翻译和摘要任务。前期工作在自然语言处理中的任务合并主要局限于单一任务的情景。为了在这一环境中促进研究，我们提出了一个包含四个实际相关组合任务的基准，并提出了一种针对嵌入设备应用的高效方法（可学习校准），强调资源高效和高性能解决方案的重要性。这些贡献为在实际多任务场景中推进LLMs的能力奠定了基础，扩大了其在资源受限复杂情况下的应用性。", "innovation": "本研究提出了一种名为'Learnable Calibration'的方法，这是一种针对限制性计算资源环境中设计的高效方法，用于协助LLMs解决组合多任务问题。该方法特别适用于嵌入设备，为研究和开发中提供了一种资源高效的解决方案。研究还构建了一个基准，包含四个实际相关的组合任务，为未来的研发提供了重要的框架。", "conclusion": "本研究为嵌入设备环境中的组合多任务学习和应用奠定了基础，通过提供一种资源高效且高性能的解决方案，增加了大规模语言模型在复杂资源受限应用场景中的适用性。"}
{"llm_update_time": "20250723", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.14657", "html_url": "https://arxiv.org/abs/2507.14657", "title": "AI-Enhanced Precision in Sport Taekwondo: Increasing Fairness, Speed, and Trust in Competition (FST.ai)", "title_en": "AI-Enhanced Precision in Sport Taekwondo: Increasing Fairness, Speed, and Trust in Competition (FST.ai)", "authors": "Keivan Shariatmadar,Ahmad Osman", "background": "传统的体育赛事裁判依靠手动系统，即使支持即时视频回放（IVR），也常常存在延迟、主观性和执法不一致等问题，这损害了比赛的公平性和运动员的信任。", "innovation": "文中提出了一种基于深度学习和边缘推理的计算机视觉新框架，用于增强跆拳道裁判，特别聚焦于实时头部踢打检测和打分。该系统能够显著缩短决策时间（从分钟级缩短至秒级），提高一致性和透明度。此外，该框架还可以应用于 judo、karate、fencing 及足球、篮球等体育项目，提高犯规识别或表现跟踪能力。", "conclusion": "研究通过解决跆拳道最具有挑战性的场景之一——头部踢打打分问题，展示了 'FST.ai' 系统的鲁棒性、可扩展性和多领域的适用性，有望通过技术手段重塑裁判标准，提升体育比赛的公平性、速度和信任度。"}
{"llm_update_time": "20250723", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2507.16196", "html_url": "https://arxiv.org/abs/2507.16196", "title": "大型语言模型具备规划理论头脑吗？来自MindGames：多层次说服任务的证据", "title_en": "Do Large Language Models Have a Planning Theory of Mind? Evidence from MindGames: a Multi-Step Persuasion Task", "authors": "Jared Moore,Ned Cooper,Rasmus Overmark,Beba Cibralic,Nick Haber,Cameron R. Jones", "background": "近期的研究表明，大型语言模型（LLMs）表现出理论头脑（ToM）的能力。大多数ToM实验使参与者处于旁观者的角色，要求他们预测和解释其他代理的行为。然而，人类的ToM还包括了动态规划行动和战略性干预他人心理状态。本研究提出了MindGames：一种新的规划理论头脑（PToM）任务，要求代理推断对话对方的信念和欲望，以说服他们改变行为。这些任务不同于以往的评估，它们明确地评估了ToM的应用场景。", "innovation": "本研究引入了一个名为MindGames的新颖PToM任务，该任务需要参与者推断对话对方的信念和欲望，以说服对方改变行为。研究对比了人类和LLM在规划行动和干预他人心理状态的性能，发现人类在PToM任务中明显优于LLM（高出11%，p=0.006）。研究还指出，人类拥有对其他代理的隐含因果模型（如了解并请求他人的偏好），而LLM则在不需要大量心理状态推断的类似规划任务中表现更优。", "conclusion": "这些结果表明，人类的社会推理和LLM的能力之间存在显著差距，指出在复杂的社会互动任务中，人类的心理状态推断和规划能力比LLM更为出色。"}
{"llm_update_time": "20250723", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2507.16263", "html_url": "https://arxiv.org/abs/2507.16263", "title": "iShumei-Chinchunmei在SemEval-2025任务4：使用有效忘却损失的权衡遗忘和保留多任务框架", "title_en": "iShumei-Chinchunmei at SemEval-2025 Task 4: A balanced forgetting and retention multi-task framework using effective unlearning loss", "authors": "Yujian Sun,Tian Li", "background": "随着大型语言模型（LLM）的广泛应用，人们越来越关注如何让LLM忘记预训练过程中存储的非合规数据。机器卸载专注于在有限的计算资源下从LLM中高效地擦除敏感信息。为推进该领域研究，SemEval 2025任务4引入了三个卸载数据集，并通过评估忘记效果和保持标准能力来建立基准。", "innovation": "本文提出了一个更可控的忘记损失函数，即有效卸载损失，并探索其与多种技术结合以实现更高效和可控的卸载。这是一个创新之处，旨在提高卸载过程的可控性与效率。", "conclusion": "最终，我们的系统在竞赛排行榜上位列第5名。"}
{"llm_update_time": "20250723", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2507.16183", "html_url": "https://arxiv.org/abs/2507.16183", "title": "BIDWESH：一种基于孟加拉地域特征的仇恨言论检测数据集", "title_en": "BIDWESH: A Bangla Regional Based Hate Speech Detection Dataset", "authors": "Azizul Hakim Fayaz,MD. Shorif Uddin,Rayhan Uddin Bhuiyan,Zakia Sultana,Md. Samiul Islam,Bidyarthi Paul,Tashreef Muhammad,Shahriar Manzoor", "background": "在全球范围内，数字平台上的仇恨言论成为一个日益严重的社会问题，特别是在像孟加拉国这样语言多样化的国家，地方方言在日常交流中扮演重要角色。尽管已经取得了进展来检测标准孟加拉语中的仇恨言论，但现有的数据集和系统未能涵盖地区方言如巴里沙尔、诺akhali和 Chattogram 中所使用的非正式和文化丰富的表达方式。这种忽视导致了有限的检测能力以及偏颇的监控，使得大量有害内容未被审查。", "innovation": "为了弥补这一空白，这项研究推出了 BIDWESH，这是第一个涵盖多方言孟加拉语仇恨言论的数据集。通过将 BD-SHS 语料库中的 9,183 个实例翻译并标注到三种主要地方方言中，每一个条目都经过人工验证和标注，确保语境和语言准确性，覆盖了仇恨是否存在，类型（诽谤、性别、宗教、暴力号召）以及目标群体（个人、男性、女性、群体）。这个数据集为提高孟加拉语仇恨言论检测提供了丰富、平衡和包容的资源，并为开发地方方言敏感的自然语言处理工具和促进低资源语言环境中的公正、有意识的内容审核奠定了基础。", "conclusion": "BIDWESH 为仇恨言论检测提供了重要的地方方言数据支持，促进了地方方言敏感的自然语言处理工具的发展，有助于在资源有限的语言环境中实现平等和语境适配的内容审核。"}
{"llm_update_time": "20250723", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2507.16284", "html_url": "https://arxiv.org/abs/2507.16284", "title": "通过明科夫斯基范数进行语言检测：基于字符双词频分析的识别", "title_en": "Language Detection by Means of the Minkowski Norm: Identification Through Character Bigrams and Frequency Analysis", "authors": "Paul-Andrei Pogăcean,Sanda-Maria Avram", "background": "近年来，随着人工智能语言模型的迅速发展，语言识别问题引起了广泛关注。然而，非人工智能方法在语言识别研究中受到了忽视。本研究旨在探讨一种利用单字和双字频率排名的数学算法进行语言决定的方法。", "innovation": "本研究引入了一种基于明科夫斯基范数的语言检测方法，该方法通过分析字符双词频排名来识别语言。这为传统的基于频率的方法提供了一种有效的补充，特别是在较短文本中的应用。", "conclusion": "该方法在150字符以下的文本上实现了超过80%的准确率，并在长文本和古籍上达到了100%的准确率。这表明，传统的基于频率的方法仍可以作为人工智能驱动模型的有效替代方案，用于语言检测。"}
{"llm_update_time": "20250723", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2507.16075", "html_url": "https://arxiv.org/abs/2507.16075", "title": "测试时扩散的深度研究员", "title_en": "Deep Researcher with Test-Time Diffusion", "authors": "Rujun Han,Yanfei Chen,Zoey CuiZhu,Lesly Miculicich,Guan Sun,Yuanjun Bi,Weiming Wen,Hui Wan,Chunfeng Wen,Solène Maître,George Lee,Vishy Tirumalashetty,Emily Xue,Zizhao Zhang,Salem Haykal,Burak Gokturk,Tomas Pfister,Chen-Yu Lee", "background": "深度研究代理，借助大型语言模型（LLMs）正在快速发展，但在使用通用的测试时缩放算法生成复杂的长篇研究报告时，其性能经常遭遇瓶颈。", "innovation": "提出了测试时扩散深度研究员（TTD-DR）。这是一种新颖的框架，将研究报告生成视为一个扩散过程，通过迭代的“去噪”过程，逐步优化初步草稿。此过程中，检索机制能在每一步整合外部信息，以动态方式指导优化过程。此外，流程中的每个环节都应用了自进化算法，确保生成高质量的上下文。", "conclusion": "TTD-DR 在广泛的基础上取得了最先进的成果，特别是在需要密集搜索和多步推理的基准测试中，显著优于现有深度研究代理。"}
{"llm_update_time": "20250723", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2507.16217", "html_url": "https://arxiv.org/abs/2507.16217", "title": "针对最优计算成本的许多样本内上下文学习", "title_en": "Towards Compute-Optimal Many-Shot In-Context Learning", "authors": "Shahriar Golchin,Yanfei Chen,Rujun Han,Manan Gandhi,Tianli Yu,Swaroop Mishra,Mihai Surdeanu,Rishabh Agarwal,Chen-Yu Lee,Tomas Pfister", "background": "长上下文大型语言模型（LLMs）能够处理包含数百万标记的输入。在上下文学习（ICL）的范围内，这意味着可以在输入提示中使用数百到数千个示例，从而实现多示例ICL。在实际应用中，由于（1）高昂的推理成本，（2）缓存和重用计算的益处，以及（3）与其他方法相比此策略在放大时提供的相似性能，因此在许多示例ICL设置中通常会随机选择一个固定的示例集。我们在此项工作中提出了两种简单的方法来改善多示例ICL中的示范选取，这些方法在几乎不增加计算开销的情况下提升了性能。第一种方法结合了一些基于测试样本相似度选取的小量示范和一组被缓存的大比例随机示范。第二种方法通过替换随机示范为通过k-means聚类从测试样本表示中提取的簇心来提升第一种方法。我们针对Gemini Pro和Flash在多个数据集上的实验表明，我们的方法在所有方面均优于随机选择和匹配表现最好的选择方法，同时支持缓存并使推理成本降低最多一个数量级。我们还展示了根据不同标准调整示范选择比例可以在多示例ICL中平衡性能和推理成本的效果。", "innovation": "提出了一种简单有效的示范选择策略，并通过将一小部分基于测试样本相似度选取的示范与一组被缓存的大比例随机示范相结合。第二方法进一步通过使用k-means聚类从测试样本表示中提取的簇心替换随机示范来增强第一种策略。这两种方法都显着提升了多示例ICL中的性能，同时保持了较低的计算负担。", "conclusion": "我们的策略在各种数据集上均优于随机选择并且超过了最有效的选择方法，在支持缓存的情况下还将推理成本降低了最高的一个数量级。我们还展示了通过调整基于不同标准的示范选择比例可以在多示例ICL中平衡性能和推理成本。"}
{"llm_update_time": "20250723", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2507.16199", "html_url": "https://arxiv.org/abs/2507.16199", "title": "WakenLLM: 一种评估大型语言模型推理潜力及其推理过程稳定性的细粒度基准", "title_en": "WakenLLM: A Fine-Grained Benchmark for Evaluating LLM Reasoning Potential and Reasoning Process Stability", "authors": "Zipeng Ling,Yuehao Tang,Shuliang Liu,Junqi Yang,Shenghong Fu,Yao Wan,Kejia Huang,Zhichao Hou,Xuming Hu", "background": "现有的大型语言模型（LLMs）经常输出“未知”的标签，但目前的评估主要集中在这些答案是否诚实上，而忽视了为什么它们会出现。这混淆了两种不同的情况：一种是输入确实是不确定的，另一种是模型未能解决的具体问题。这篇论文旨在纠正这种混淆，通过量化“未知”响应中因模型能力不足的比例，并测试引导刺激是否能将这些响应转变成正确的或本体不确定的结果，从而区分不确定性来源，提供更清晰的LLM推理限制和改进潜力的图景。", "innovation": "引入了WakenLLM框架，这是一种细粒度的基准，用于评估LLM的推理潜力及其推理过程的稳定性。该框架通过区分模型无能与模型未能解决的问题这两个不同的不确定性来源，提供了更清晰的LLM推理能力和潜在改进的图景。对于不同LLM的推理任务理论准确性，使用不同方法测试模型是否可以达到给定的基线框架下的准确性。", "conclusion": "这项工作有助于探索LLM的真实推理能力，并提供了一种新的解决‘模糊感知’现象的视角。通过这种方法，评估LLM的推理能力和改进潜力，有助于提高模型性能，更好地服务用户需求。"}
{"llm_update_time": "20250723", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2507.16271", "html_url": "https://arxiv.org/abs/2507.16271", "title": "超越孤立点：评估结构化表格构建作为深层次知识提取", "title_en": "Beyond Isolated Dots: Benchmarking Structured Table Construction as Deep Knowledge Extraction", "authors": "Tianyun Zhong,Guozhao Mo,Yanjiang Liu,Yihan Chen,Lingdi Kong,Xuanang Chen,Yaojie Lu,Hongyu Lin,Ben He,Le Sun", "background": "随着大型语言模型（LLMs）的发展，人们期望这些模型能有效从复杂的真实世界文档（例如论文、报告）中提取明确的信息。然而，大多数LLMs生成的答案却是混乱无序、难以追踪的段落式内容。为了弥合这一差距，我们引入了有序抽取基准测试（AOE），这是一个新的双语基准测试，含有不同长度的数据和文档，旨在系统性地评估LLMs在理解碎片化文档和重组孤立信息成一个有序表格方面的能力。与依赖固定模式和狭窄任务域的传统文本到表格任务不同，AOE包括了11项精心设计的任务，覆盖三个不同的领域，要求模型根据不同的输入查询生成特定于上下文的模式。", "innovation": "该基准测试设计了11项精心设计的任务，涵盖三个不同领域，要求模型根据不同的输入查询生成特定于上下文的模式，不同于传统的文本到表格任务，它依赖固定的模式和狭窄的任务域。AOE能够评估LLMs在理解碎片化文档和重组孤立信息成一个有序表格方面的能力。", "conclusion": "实验结果显示，即使是最先进的模型也面临着显著的困难。该基准测试提供链接：this https URL。"}
{"llm_update_time": "20250723", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.15846", "html_url": "https://arxiv.org/abs/2507.15846", "title": "GUI-G$^2$: 高斯奖励建模方法用于GUI定位", "title_en": "GUI-G$^2$: Gaussian Reward Modeling for GUI Grounding", "authors": "Fei Tang,Zhangxuan Gu,Zhengxi Lu,Xuyang Liu,Shuheng Shen,Changhua Meng,Wen Wang,Wenqi Zhang,Yongliang Shen,Weiming Lu,Jun Xiao,Yueting Zhuang", "background": "图形用户界面（GUI）的图形用户界面接地任务将自然语言指令转化为精确的界面位置，实现自主交互。现有的强化学习方法使用二元奖励，将界面元素视为命中或失败的目标，导致信号稀疏，忽略了空间交互的连续性质。受人类点击行为自然形成以目标元素为中心的高斯分布的启发，我们引入了GUI高斯接地奖励（GUI-G$^2$）框架，该框架将GUI元素建模为界面平面上的连续高斯分布，包含协同的高斯点奖励机制和覆盖奖励机制，能够处理不同规模的元素，并生成丰富的梯度信号，指导模型向最佳交互位置收敛。", "innovation": "我们提出了GUI高斯接地奖励（GUI-G$^2$）框架，将GUI元素建模为连续的高斯分布，能够处理不同规模的元素，并生成丰富的梯度信号，指导模型向最佳交互位置收敛。研究还发现连续模型对界面变化的鲁棒性和对未见过布局的泛化能力都优于现有方法，从而为GUI交互任务的空间推理建立了新的范式。", "conclusion": "GUI-G$^2$框架在广泛的ScreenSpot、ScreenSpot-v2和ScreenSpot-Pro基准测试中，显著优于最先进的UI-TARS-72B方法，特别是在ScreenSpot-Pro上的改进最为显著，达到了24.7%。深度实验表明，连续建模方法在界面变化的鲁棒性和对未见过布局的泛化能力方面具有优势，从而建立了一个新的GUI交互任务空间推理范式。"}
{"llm_update_time": "20250723", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2507.16331", "html_url": "https://arxiv.org/abs/2507.16331", "title": "Re:Form -- 使用LLMs中的RL减少可扩展形式软件验证中的人工先验：Dafny上的初步研究", "title_en": "Re:Form -- Reducing Human Priors in Scalable Formal Software Verification with RL in LLMs: A Preliminary Study on Dafny", "authors": "Chuanhao Yan,Fengdi Che,Xuhan Huang,Xu Xu,Xin Li,Yizhi Li,Xingwei Qu,Jingzhe Shi,Zhuangzhuang He,Chenghua Lin,Yaodong Yang,Binhang Yuan,Hang Zhao,Yu Qiao,Bowen Zhou,Jie Fu", "background": "现有的大语言模型（LLMs）通过强化学习（RL）训练，基于非正式语言（如人类语言）进行训练，但在验证过程中遇到显著挑战，因为这些验证过程所提供的训练信号既不可靠也不具备可扩展性。现有的大型专有模型几乎无法生成可验证的程序。一种有前景但尚未充分探索的替代方案是基于形式语言的推理。通过将LLMs锚定在严谨的形式系统中，使生成模型在形式语言空间（如Dafny）内运作，可以自动和数学地证明其推理过程及其结果的正确性。对于实现大规模、可靠的正式软件验证至关重要。通常做法是利用人工标注的思维链和其他人类先验知识来引导LLMs的推理和编码能力。然而，为复杂的编程任务提供这些先验知识变得极其耗时，难以承担。本研究系统地探讨了以Dafny为主要环境的研究管道，旨在减少人工先验，并通过自动和可扩展的数据整理管道以及结合形式语言验证器的巧妙RL设计实现这一目标。", "innovation": "本研究的创新之处在于开发了一个自动和可扩展的数据整理管道，并结合了与形式语言验证器的反馈，通过使用Dafny作为主要环境，旨在减少在大规模形式软件验证中对人工先验的需求。此外，该研究还引入了DafnyComp基准测试，这是一个具有自动形式化规范的组合形式程序基准测试集，用于规范推理。通过监督微调阶段，即使是很小的模型（例如，0.5B参数）也能生成合乎语法的有效且验证的Dafny代码，超过现有的专有模型。进一步使用正则化强化学习增强了性能，实现了更强的领域外任务泛化，并且在具有挑战性的DafnyComp基准测试中超过了所有强大的基线。", "conclusion": "该研究系统地探索了使用正式语言Dafny减少人工先验的方法，并证明即使是小型模型也能生成有效且可验证的Dafny代码，通过正则化强化学习进一步提高了性能，并在具有挑战性的基准测试中超过了所有基线模型。这种方法为大规模、可靠的形式软件验证开辟了新的道路，显著减少了对人工先验的需求，提升了模型的自动化和可扩展性。"}
{"llm_update_time": "20250723", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2507.16424", "html_url": "https://arxiv.org/abs/2507.16424", "title": "PromptAL: 样本意识动态软提示用于少量样本主动学习", "title_en": "PromptAL: Sample-Aware Dynamic Soft Prompts for Few-Shot Active Learning", "authors": "Hui Xiang,Jinqiao Shi,Ting Zhang,Xiaojie Zhao,Yong Liu,Yong Ma", "background": "主动学习（AL）旨在通过选择最有信息量的样本进行标注来优化模型训练并减少标注成本。传统AL方法依赖于有标签数据的经验分布来定义决策边界并进行不确定性或多样性估计，进而识别潜在的高质量样本。但在少量样本场景中，经验分布往往与目标分布显著不同，导致决策边界偏离最优位置。现有方法未充分利用未标注样本来增强经验分布，使其更好地与目标分布对齐，从而导致次优的决策边界和不充分代表目标分布的样本选择。", "innovation": "本文提出了一种混合主动学习框架，称为PromptAL（样本意识动态软提示用于少量样本主动学习）。该框架考虑了每个未标注数据点对当前经验分布与目标分布对齐的贡献，从而优化决策边界。具体而言，PromptAL 利用未标注数据构建样本意识动态软提示，调整个体的预测分布和决策边界，然后基于调整后的决策边界结合全局和局部多样性进行不确定性估计，以此筛选出更准确代表目标分布的高质量样本。在六个领域内和三个跨领域数据集上的实验结果显示，PromptAL 在九个基线中表现更优。", "conclusion": "实验结果表明，PromptAL 在六个领域内和三个跨领域数据集上优于九个基线方法，证明了该方法的有效性。"}
{"llm_update_time": "20250723", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2507.16410", "html_url": "https://arxiv.org/abs/2507.16410", "title": "GG-BBQ: 德语性别偏差基准测试用于问答任务", "title_en": "GG-BBQ: German Gender Bias Benchmark for Question Answering", "authors": "Shalaka Satheesh,Katrin Klug,Katharina Beckh,Héctor Allende-Cid,Sebastian Houben,Teena Hassan", "background": "在自然语言处理（NLP）领域，公平性评估通常与对偏见的评估及其对潜在伤害的减小有关。为此，通常利用基准数据集来评估诸如问答任务中的模型预测偏见等指标，涵盖了性别认同等多种维度。这项研究旨在针对德语大型语言模型（LLMs），使用Parrish等人（2022年）提出的问答偏见基准测试来评估性别偏见。由于机器翻译从英语到德语（这种具有语法性别的语言）时存在的局限性，手动审查并修正翻译模板成为确保准确性的关键步骤。研究者创建了包含两个子集的最终数据集：子集I包含与性别认同相关的群体术语，子集II用具体名字替换群体术语。研究中评估了几种用于德语NLP的大型语言模型，并报告了准确性和偏见分数，结果显示所有模型在不同程度上均表现出偏见，与现有的社会刻板印象有关。", "innovation": "本研究创新在于使用英语基准数据集的性别身份部分模板，并将其机器翻译为德语，然后经过语言专家的手动审查和修正。这种方法解决了直接使用英语数据集的问题，特别是针对德语等具有复杂性别的语言而言。此外，通过创建新的数据子集来针对性别身份和具体名字进行不同的评估，为德语大型语言模型的性别偏见研究提供了一个新的测试框架。", "conclusion": "研究结果表明，所有模型都显示出不同程度的性别偏见，且与现有的社会刻板印象相关。文章建议未来的工作继续关注解决大型语言模型中的性别偏见问题，特别是对具有性别复杂性的语言。最终数据集的构建和使用为更全面和准确地评估大型语言模型的性别偏见提供了一种新的方法。"}
{"llm_update_time": "20250723", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2507.16442", "html_url": "https://arxiv.org/abs/2507.16442", "title": "Dutch CrowS-Pairs: 调整用于测量荷兰语言模型社会偏见的挑战数据集", "title_en": "Dutch CrowS-Pairs: Adapting a Challenge Dataset for Measuring Social Biases in Language Models for Dutch", "authors": "Elza Strazda,Gerasimos Spanakis", "background": "语言模型容易表现出偏见，进一步放大了不公平和有害的刻板印象。由于这些模型越来越流行且应用广泛，确保安全和公平的语言模型变得至关重要。尽管已经有很多研究致力于测量语言模型中的偏见，但大部分研究仅限于英语。因此，这篇论文引入了一个针对荷兰语言模型的新数据集Dutch CrowS-Pairs，它涵盖了性取向、性别和残障等9个偏见类别，并提出了模型在不同语言和文化背景下偏见水平的差异性。", "innovation": "这篇论文创新地为荷兰语言模型引入了一个新的数据集，Dutch CrowS-Pairs，该数据集基于美国特定的CrowS-Pairs数据集。此外，还研究了给语言模型赋予不同的人设对其偏见水平的影响，揭示了偏见在不同语言和语境下表现出的可变性，强调了文化与语言因素在影响模型偏见方面的重要作用。", "conclusion": "不同的语言模型在各种偏见类别中表现出显著的偏见水平差异。英语模型在偏见方面表现出最高水平，而荷兰模型则表现出最低的偏见水平。此外，赋予语言模型不同的人设会影响其表现出的偏见水平。这些结果强调了偏见在不同语言和背景下的可变性，表明文化与语言因素在塑造模型偏见方面起着重要作用。"}
{"llm_update_time": "20250723", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2507.16323", "html_url": "https://arxiv.org/abs/2507.16323", "title": "SpeLLM: 字符级别多头解码", "title_en": "SpeLLM: Character-Level Multi-Head Decoding", "authors": "Amit Ben-Artzy,Roy Schwartz", "background": "在大型语言模型（LLM）中，扩展词汇量通常用于缩短输入序列长度并缓解注意力机制的二次成本。然而，当前的LLM架构为这一过程设定了重要瓶颈：输出投影层随着词汇量的增大线性增加，导致大幅度扩展不切实际。", "innovation": "该研究提出了SpeLLM方法，通过多个输出头预测字符级别的字符串，解耦输入和输出词汇量。每个线性头同时预测一个字符，使模型能够使用更小、独立的线性头来表示更大的输出空间。此外，该方法还提出了一种自我蒸馏的方法，将标准的LLM转换为SpeLLM。实验结果表明，该方法在不同的预训练LLM上减少了5.1%的运行时间，同时保持了竞争力的下游任务性能。", "conclusion": "该研究提供了一种潜在的成本降低途径，同时也增强了对未充分代表的语言和领域的支持。"}
{"llm_update_time": "20250723", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2507.16490", "html_url": "https://arxiv.org/abs/2507.16490", "title": "结合语言模型和主题模型的层次文本分类", "title_en": "Combining Language and Topic Models for Hierarchical Text Classification", "authors": "Jaco du Toit,Marcel Dunaiski", "background": "层次文本分类（HTC）是自然语言处理任务之一，其目标是将文本文档分类到预定义的层次结构类别集中。最近的HTC方法使用各种技术将层次类结构信息与预训练语言模型（PLMs）的自然语言理解能力相结合，以提高分类性能。此外，研究表明，结合主题模型与PLMs从文本文档中提取特征对于多标签文本分类任务是有效的。这一结合背后的原因是，PLM捕捉到了更精细的上下文和语义信息，而主题模型则获得了概括性的表示，考虑了整个文档集。本文使用一种结合PLM和主题模型提取特征的方法进行HTC。", "innovation": "研究提出了一种利用PLM和主题模型分别提取特征，然后通过独立的卷积层处理特征并将输出结合交给标签级注意力机制以获得特定类别的重要特征来训练分类模型的方法。方法的特点在于通过分别处理特征并基于类别的重要特征计算文档表示。不同于以往的工作，研究结果表明，使用从主题模型提取的特征通常会降低分类性能，这表明在文本分类任务中，不应该假设从主题模型提取的特征有益。", "conclusion": "研究通过全面地在三个层次文本分类基准数据集上进行实验，展示了使用主题模型提取的特征相比仅使用PLM提取的特征，一般会降低分类性能。该结论表明，在文本分类任务中，结合主题模型提取的特征可能不是有益的。"}
{"llm_update_time": "20250723", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2507.16248", "html_url": "https://arxiv.org/abs/2507.16248", "title": "FinResearchBench：金融研究代理评价框架的一种基于逻辑树的代理作为裁判系统", "title_en": "FinResearchBench: A Logic Tree based Agent-as-a-Judge Evaluation Framework for Financial Research Agents", "authors": "Run Sun,Zuo Bai,Wentao Zhang,Yuxiang Zhang,Li Zhao,Shan Sun,Zhengwen Qiu", "background": "近年来，人工智能代理在专业研究应用中迅速发展，如STEM、软件开发、金融等。深度研究代理是其中的关键类别，因其能够执行长周期任务和解决更复杂的问题。然而，缺乏能够系统化和自动化评估这些研究代理能力的评价框架和基准。尤其是金融研究问题具有明显的复杂性和细微之处。为了填补这一空白，研究人员提出了FinResearchBench，这是一种基于逻辑树的Agent-as-a-Judge系统，专门针对金融研究代理。该系统提供了关于金融研究中7种关键任务的全面自动评估。", "innovation": "该工作有两个创新点：1) 第一个和创新性的基于逻辑树的Agent-as-a-Judge系统，通过提取研究产出的逻辑树并利用其作为中间信息来提供全面、可靠和稳健的评估；2) 专注于金融领域，涵盖了70个典型的金融研究问题，涉及该领域中经常遇到的7种类型的任务。", "conclusion": "FinResearchBench 提供了一种审视和评估金融研究代理能力的新方法，通过对7种类型的金融研究任务进行全面自动化的评估，填补了现有评价框架的空白。"}
{"llm_update_time": "20250723", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2507.16557", "html_url": "https://arxiv.org/abs/2507.16557", "title": "探究大型语言模型中的性别偏见：德语语言的深度分析", "title_en": "Exploring Gender Bias in Large Language Models: An In-depth Dive into the German Language", "authors": "Kristin Gnadt,David Thulke,Simone Kopeinik,Ralf Schlüter", "background": "近年来，针对大型语言模型（LLMs）中的性别偏见评价方法得到了广泛研究。一个关键挑战在于，最初为英语设计的性别偏见测量方法在应用于其他语言时缺乏转移性。这项工作旨在为这一研究方向做出贡献，通过提供五个用于评价LLMs性别偏见的德语数据集来研究这一议题。这些数据集基于已确立的性别偏见概念，并可通过多种方法访问。研究结果揭示了德语中性别偏见的独特挑战，包括男性职业词汇的模糊解读以及中性名词对性别感知的影响。这些发现加深了对跨语言大型语言模型中性别偏见的理解，并突显了为不同语言定制评价框架的必要性。", "innovation": "该论文通过提供五个德语数据集，为评价大型语言模型中的性别偏见研究做出了贡献。这些数据集基于已确立的概念并适用于多种方法，揭示了不同语言在性别偏见方面的独特挑战。此外，研究结果还强调了为不同语言定制评价框架的必要性。", "conclusion": "研究针对多个大型语言模型的德语数据集的研究结果表明，德语中的性别偏见具有独特挑战，包括男性职业词汇的模糊解读和中性名词对性别感知的影响。这些发现有助于理解跨语言大型语言模型中的性别偏见，并进一步强调了定制化评价框架的重要性。"}
{"llm_update_time": "20250723", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2507.16530", "html_url": "https://arxiv.org/abs/2507.16530", "title": "学习文本风格：关于转移、归属和验证的研究", "title_en": "Learning Text Styles: A Study on Transfer, Attribution, and Verification", "authors": "Zhiqiang Hu", "background": "本论文通过三项相互关联的支柱来推进对文本风格的计算理解与操控，这些支柱分别是在保留下内容的前提下改变文本风格属性（如情感色彩、正式程度）的文本风格转移（TST）、通过文本的风格指纹识别作者身份的作者身份归属（AA），以及判断两篇文本是否同一位作者所写作者身份验证（AV）的研究，旨在应对这些领域中存在的关键挑战，如参数高效的大型语言模型的适应性、风格特征的对比解耦，以及基于指令的微调来实现可解释的验证方法等方面的问题。", "innovation": "本研究通过多种创新手段推进了文本风格的理解与操控。首先，利用了参数高效适应大型语言模型（LLMs），提高了模型的适应性和灵活性；其次，采用对比解耦的技术分离文本中的风格特征，使得模型能够更明确地把握不同文本之间的风格差异；最后，基于指令的微调方法不仅提升了模型的验证能力，而且通过清晰的指令使得模型能够提供易于理解的解释，增强了透明度和可解释性。", "conclusion": "本研究通过集成文本风格转移、作者身份归属和作者身份验证的技术框架，不仅推进了这些领域的理论研究，还为实际应用提供了新的解决方案。该研究为理解文本风格的复杂性提供了新的视角，并且通过创新的方法提高了模型的性能和可解释性，对未来的研究和实际应用具有重要意义。"}
{"llm_update_time": "20250723", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2507.16252", "html_url": "https://arxiv.org/abs/2507.16252", "title": "基于LLM的辅导对话结果高效RL优化", "title_en": "Efficient RL for optimizing conversation level outcomes with an LLM-based tutor", "authors": "Hyunji Nam,Omer Gottesman,Amy Zhang,Dean Foster,Emma Brunskill,Lyle Ungar", "background": "现有的基于人类反馈强化学习（RLHF）框架的大语言模型（LLMs）通常优先优化基于即时对话回合水平的人类偏好响应。这种做法在多回合对话场景下，如在线数学辅导效果不佳。本文的目标是在数学解决问题的长期内，通过低维潜状态表示对话历史，优化辅导政策以指导学生自主解决问题。", "innovation": "本文提出了一种改进方法，将潜状态表示引入基于大语言模型的辅导系统，通过优化长期政策来决策高层次行动，从而更好地匹配辅导行为与长期引导学生自我解决问题的目标。此外，该模型相比之前从头训练其他工作以直接输出下一步对话所需的时间和计算资源更轻量。", "conclusion": "实验结果表明，在模拟的基于大语言模型的辅导任务中，该改进措施在长期内提升了对话效果。"}
{"llm_update_time": "20250723", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2507.16679", "html_url": "https://arxiv.org/abs/2507.16679", "title": "PICACO: Pluralistic In-Context Value Alignment of LLMs via Total Correlation Optimization", "title_en": "PICACO: Pluralistic In-Context Value Alignment of LLMs via Total Correlation Optimization", "authors": "Han Jiang,Dongyao Zhu,Zhihua Wei,Xiaoyuan Yi,Ziang Xiao,Xing Xie", "background": "In-Context Learning (ICL)能够显著改善大型语言模型（LLMs）与人类价值观的一致性，减少有害输出并适应多样的偏好，而无需昂贵的后训练。然而，现有的ICL方法在处理包含多种价值冲突的输入提示时，存在一定的局限性。这些方法实质上无法有效地实现多样价值观之间的平衡，即存在‘指令瓶颈’，导致模型难以在同一提示中整合多种意图的价值，导致不完整或偏向的对齐。", "innovation": "本文提出了一个新的平权式的ICL方法——PICACO，它在不进行微调的情况下优化了一个元指令，该元指令能够引导模型更好地理解多重价值观并提高其对齐效果。通过最大化指定值和LLM响应之间的总相关性来实现这一目标，从而理论上增强价值间的相关性并减少干扰噪音，产生有效的值指令。PICACO在五个价值观集合上的大量实验表明，它在黑盒和开源LLMs中均表现出色，优于几个最近的基准方法，并能在多达8种不同的价值观之间实现更好的平衡。", "conclusion": "PICACO通过优化总相关性提高了LLM的对齐效果，展示了在处理多重价值观时的有效性和适应性，尤其是在现有方法存在的‘指令瓶颈’问题上提供了新的解决方案。"}
{"llm_update_time": "20250723", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2507.16459", "html_url": "https://arxiv.org/abs/2507.16459", "title": "在代理工作流中强制执行公司政策遵循性", "title_en": "Towards Enforcing Company Policy Adherence in Agentic Workflows", "authors": "Naama Zwerdling,David Boaz,Ella Rabinovich,Guy Uziel,David Amid,Ateret Anaby-Tavor", "background": "大型语言模型（LLM）代理在传统企业流程自动化方面表现出灵活性和可扩展性的潜力，但难以可靠地遵循复杂的公司政策。因此，本文提出了一个用于企业在代理流程中强制执行政策遵循性的确定性、透明和模块化的框架。", "innovation": "该研究提出了一个两阶段的框架：第一阶段是离线编译时间阶段，将政策文档编译为与工具使用相关的可验证守护代码；第二阶段是运行时整合阶段，在每个代理行为之前确保合规。这种方法在具有挑战性的$\\tau$航权域进行了演示，展示了初步的积极成果，并概述了实际部署中的关键挑战。", "conclusion": "该研究表明，虽然取得了初步的积极结果，但在真实部署中仍面临诸多关键挑战，但这种方法为在代理工作流中强制执行公司政策遵循性提供了一种新的解决方案。"}
{"llm_update_time": "20250723", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2507.16663", "html_url": "https://arxiv.org/abs/2507.16663", "title": "自我矛盾作为自我改进：在大模型中缓解生成与理解之间的差距", "title_en": "Self-Contradiction as Self-Improvement: Mitigating the Generation-Understanding Gap in MLLMs", "authors": "Yujin Han,Hao Chen,Andi Han,Zhiheng Wang,Xinyu Lin,Yingya Zhang,Shiwei Zhang,Difan Zou", "background": "尽管努力在单一模型中统一多模态生成和理解任务，但这些模型仍然表现出自我矛盾的现象，即生成的图像与模型自身的输入提示不一致。本文定义了一种非统一性分数（Nonunified score）来量化这种自我矛盾，并通过实验证明，这种自我矛盾主要源于生成能力较弱，未能与提示对齐，而非理解能力的误解。这一能力不对称性表明，利用自我矛盾进行自我改进的潜力，可以通过更强的理解指导较弱的生成，减少生成与理解之间的差距。", "innovation": "本文的创新点包括：1) 提出非统一性分数（Nonunified score）量化模型的自我矛盾；2) 提出利用自我矛盾驱动自我改进的方法，通过标准的后续训练方法（如SFT、DPO）进行内部监督，成功地改善了生成和统一；3) 提现仅微调生成分支也能实现生成与理解的共同改进，这是预训练中的现象但在后续训练中未被充分探索；4) 分析表明，这些改进源于能够更好地检测之前错误识别为对齐的虚假正例；5) 理论上证明，生成和理解之间的协调训练动态有助于减少提示不对齐的生成，并改善理解分支中的错误检测；6) 揭示了在不良监督下存在潜在的共同退化风险，这是一个在实验中被实证验证的现象；7) 基于研究结果，提出了一种基于课程的教学策略，逐步引入更难的问题样本，以促进更好地统一和提高MLLM的生成和理解能力。", "conclusion": "研究揭示，可以通过利用自我矛盾进行自我改进来缓解大模型中的生成与理解之间的差距，并提出了一种新的学习框架和评估标准来进一步提高模型的性能。同时，强调了数据质量检查的重要性，因为内在指标（如非统一性分数）无法区分共同改进与共同退化。"}
{"llm_update_time": "20250723", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2507.16515", "html_url": "https://arxiv.org/abs/2507.16515", "title": "将质量估计引入机器翻译后编辑工作流程：一项关于其有用性的实证研究", "title_en": "Introducing Quality Estimation to Machine Translation Post-editing Workflow: An Empirical Study on Its Usefulness", "authors": "Siqi Liu,Guangrong Dai,Dechao Li", "background": "该初步研究探讨了句子级别质量估计（QE）在英译中机器翻译后编辑（MTPE）中的实用性，重点关注其对后编辑速度以及学生翻译者感知的影响。研究还探讨了QE与翻译质量以及QE与翻译专长之间的交互作用效果。", "innovation": "研究发现QE显著减少了后编辑时间，且QE对中等和高质量的机器翻译输出以及不同翻译专长水平的学生翻译者均具有一致的后编辑效率改善作用。QE除了能标识潜在问题段落外，还能验证翻译者对机器翻译质量的评价，并帮助他们双重检查翻译输出。", "conclusion": "研究表明QE具备增强翻译者生产力的功能，但不准确的QE可能会阻碍后编辑过程。这项研究提供了关于QE优点和局限性的新见解，有助于更有效地将QE整合到MTPE工作流程中以提升翻译者的生产力。"}
{"llm_update_time": "20250723", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2507.16711", "html_url": "https://arxiv.org/abs/2507.16711", "title": "提高风险和质量保障：一种增强监管合规性的RAG聊天机器人", "title_en": "Advancing Risk and Quality Assurance: A RAG Chatbot for Improved Regulatory Compliance", "authors": "Lars Hillebrand,Armin Berger,Daniel Uedelhoven,David Berghaus,Ulrich Warning,Tim Dilmaghani,Bernd Kliem,Thomas Schmid,Rüdiger Loitz,Rafet Sifa", "background": "在高监管行业中，风险和质量（R&Q）保障需要不断导航复杂的监管框架，员工每天处理大量需准确政策解读的查询。传统的依赖专门专家的方法会导致操作瓶颈并限制可扩展性。", "innovation": "本文提出了一种新型的基于大型语言模型（LLMs）的检索增强生成（RAG）系统，结合混合搜索和相关性增强，以提升R&Q查询处理。该系统通过124个专家标注的真实查询的评估，显著优于传统的RAG方法。此外，还进行了广泛的超参数分析，比较和评估了多种配置设置，提供了有价值的实际操作见解。", "conclusion": "部署的系统在实践中证明了显著的改进，同时提供了对多配置设置的深入分析，为业界提供了宝贵的建议。"}
{"llm_update_time": "20250723", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2507.16695", "html_url": "https://arxiv.org/abs/2507.16695", "title": "采用行随机化DEDICOM进行可解释的主题提取和词嵌入学习", "title_en": "Interpretable Topic Extraction and Word Embedding Learning using row-stochastic DEDICOM", "authors": "Lars Hillebrand,David Biesner,Christian Bauckhage,Rafet Sifa", "background": "DEDICOM算法提供了一种独特的矩阵分解方法，适用于对称和非对称的方形矩阵，通过这种方法可以对文本语料库中的点wise互信息矩阵进行分解，从而识别词汇中的潜在主题簇并同时学习可解释的词嵌入。本文在此基础上提出了一种高效的受约束的DEDICOM算法，并对其主题建模和词嵌入性能进行了定性评估。", "innovation": "引入了一种新的行随机化形式的DEDICOM算法，并将其应用于文本语料库的点wise互信息矩阵，以识别潜在的主题簇，并同时学习具有可解释性的词嵌入。此外，提出了一个高效的训练受限的DEDICOM算法的方法，并对其主题建模和词嵌入的表现进行了主观评价。", "conclusion": "通过使用行随机化DEDICOM算法，本研究成功地从词汇中提取了可解释的主题，并且同时学习了具有可解释性的词嵌入。实验结果表明，该方法在主题模型和词嵌入的性能上具有一定的优势。"}
{"llm_update_time": "20250723", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2507.16725", "html_url": "https://arxiv.org/abs/2507.16725", "title": "RA Vine: 现实对齐评估方法用于代理型搜索", "title_en": "RAVine: Reality-Aligned Evaluation for Agentic Search", "authors": "Yilong Xu,Xiang Long,Zhi Zheng,Jinhua Gao", "background": "代理型搜索是一种更具自主性和适应性的检索增强范式，正推动智能搜索系统的进化。然而，现有的评估框架难以与代理型搜索的目标相匹配。首先，当前基准中常见的复杂查询与实际用户搜索场景有较大偏差。其次，先前的方法在提取端到端评估的金标准时往往会引入噪声，导致细粒度评估失真。第三，大多数当前框架仅关注最终答案的质量，忽略了代理型搜索固有的迭代过程的评估。", "innovation": "我们提出了RA Vine —— 一种针对代理型搜索的现实对齐评估框架，专用于多点查询和长格式回答，更好地反映了用户意图。RA Vine 引入了一种归因性金标准构建策略，以提高细粒度评估的准确性。此外，RA Vine 还在整个迭代过程中研究了模型与搜索工具的交互，并考虑了效率因素。", "conclusion": "我们使用 RA Vine 对一系列模型进行了基准测试，并得出了若干洞见，希望这些成果能促进代理型搜索系统的进一步发展。代码和数据集可以在以下链接获取：this https URL。"}
{"llm_update_time": "20250723", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2507.16748", "html_url": "https://arxiv.org/abs/2507.16748", "title": "解析歧义：多义话语标记符与非DM信号的交互作用", "title_en": "Unpacking Ambiguity: The Interaction of Polysemous Discourse Markers and Non-DM Signals", "authors": "Jingni Wu,Amir Zeldes", "background": "话语标记（DMs）如‘但是’或‘然后’对构建话语连贯性至关重要，然而它们往往被非DMs替代或与其共现（例如，‘早上’可以与‘然后’意思相同），并且两者都可能意义模糊（‘自从’可以指时间或原因）。DMs这样的信号之间的互动机制尚不清楚，但对它们的意义消歧是至关重要的。本文探讨了英语中DMs多义性与非DMs共现的关系，以及体裁对这些模式的影响。通过eRST框架，提出了一种按等级定义的DMs多义性，并通过相关性和回归分析考察了多义DMs是否伴随更多样且多元的非DM信号。研究发现，虽然多义DMs确实与更多样的非DM信号共现，但共现信号的总数并不一定增加。另外，体裁在塑造DMs-信号交互中发挥重要作用。", "innovation": "提出了一种按等级定义的DMs多义性，并通过相关性和回归分析探讨了多义DMs与非DM信号共现的关系，揭示了体裁对这种交互模式的影响。", "conclusion": "多义DMs确实与更多样的非DM信号共现，但共现信号的总数并不一定增加；体裁在DMs-信号交互中具有重要影响。"}
{"llm_update_time": "20250723", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2507.16572", "html_url": "https://arxiv.org/abs/2507.16572", "title": "从像素到原理：探针 multimodal 语言模型的直觉物理理解", "title_en": "Pixels to Principles: Probing Intuitive Physics Understanding in Multimodal Language Models", "authors": "Mohamad Ballout,Serwan Jassim,Elia Bruni", "background": "本文系统地评估了最先进的多模态大型语言模型（MLLMs）在使用 GRASP 和 IntPhys 2 数据集的直觉物理任务上的表现。研究发现，即使是最新的模型，在可靠地区分物理上合理的和不合理的情况方面也存在问题。为了超越单纯基于性能的指标，研究通过探测分析模型嵌入，提取关键处理阶段的中间表示，以考察任务相关信息的保留情况。", "innovation": "研究不仅评估了多种多模态语言模型的性能，还通过探测分析模型嵌入，揭示了模型在处理直觉物理任务时的关键视觉-语言不匹配问题。研究表明，视觉编码器能够捕捉物理一致性线索，但语言模型未能有效利用这些信息，这表明在直觉物理任务中，MLLMs 的主要限制不是视觉组件，而是视觉和语言信息的无效整合。这一发现为未来的多模态语言模型开发指明了重要方向。", "conclusion": "研究表明，视觉-语言不匹配是多模态语言模型在直觉物理任务上的主要限制，强调视觉-语言一致性的提高是未来多模态语言模型发展中需要重点关注的领域。"}
{"llm_update_time": "20250723", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2507.16488", "html_url": "https://arxiv.org/abs/2507.16488", "title": "ICR Probe: 用于LLMs可靠幻觉检测的隐藏状态动态跟踪方法", "title_en": "ICR Probe: Tracking Hidden State Dynamics for Reliable Hallucination Detection in LLMs", "authors": "Zhenliang Zhang,Xinyu Hu,Huixuan Zhang,Junzhe Zhang,Xiaojun Wan", "background": "大型语言模型（LLMs）在各种自然语言处理任务中表现出色，但它们倾向于生成幻觉，这降低了它们的可靠性。现有的利用隐藏状态的幻觉检测方法主要关注静态和孤立的表示，忽视了它们在不同层间的动态演变，这限制了这些方法的有效性。", "innovation": "作者提出了一个新的度量标准ICR Score（信息对残差流的贡献），该度量标准量化了模块对隐藏状态更新的贡献。在此基础上，作者提出了一种新的幻觉检测方法ICR Probe，这种方法能够捕捉隐藏状态在不同层间的动态演化。实验结果显示ICR Probe具有优越的性能，且参数数量远少于其他方法。此外，消融实验和案例分析进一步解释了该方法的运作原理，增强了其可解释性。", "conclusion": "ICR Probe通过有效且可靠地区分幻觉，展示了在幻觉检测中的优越性能。此方法不仅实现了更高效的检测，还提供了对隐状态动态变化的深入理解，从而提高了整个模型的透明度和可解释性。"}
{"llm_update_time": "20250723", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2507.16656", "html_url": "https://arxiv.org/abs/2507.16656", "title": "P-CoT: 一种以教育动机为导向的参与式思考链提示在大规模语言模型中进行音理推理", "title_en": "P-CoT: A Pedagogically-motivated Participatory Chain-of-Thought Prompting for Phonological Reasoning in LLMs", "authors": "Dongjun Jang,Youngchae Ahn,Hyopil Shin", "background": "本研究探索了文本基础的大规模语言模型（LLMs）中的音理推理潜力。通过使用PhonologyBench基准，对韵脚词生成、音节到音素转换和音节计数等任务进行了评估。研究发现，少样本学习提供的改进是不一致的，但引入了一种基于教育理论如支架教学和发现学习的新颖教育动机驱动的参与式思考链（P-CoT）提示，显著提升了模型性能。", "innovation": "研究引入了一种新的教育动机驱动的参与式思考链（P-CoT）提示，这种提示基于教育理论如支架教学和发现学习。实验结果显示，这种方法通过提供结构化的引导来激活潜在的音理能力，实现了高达52%的性能提升，并在某些任务上甚至超过了人类基准。", "conclusion": "未来的工作可以优化P-CoT提示以适用于特定模型，或者探索其在不同语言领域的应用。"}
{"llm_update_time": "20250723", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2507.16514", "html_url": "https://arxiv.org/abs/2507.16514", "title": "The Ever-Evolving Science Exam", "title_en": "The Ever-Evolving Science Exam", "authors": "Junying Wang,Zicheng Zhang,Yijin Guo,Farong Wen,Ye Shen,Yingji Liang,Yalun Wu,Wenzhe Li,Chunyi Li,Zijian Chen,Qi Jia,Guangtao Zhai", "background": "随着基础模型在能力和部署上迅速增长，对其科学理解的评估变得越来越关键。现有科学基准评估在覆盖范围、评估范围和严谨性方面取得了一定进展，但仍然面临数据泄露风险和大规模测试导致的评估效率低下两大挑战。", "innovation": "引入了Ever-Evolving Science Exam (EESE)，这是一种动态基准，旨在可靠地评估基础模型的科学能力。该方法包含两个组件：1) 一个超过10万条由专家构建、跨5个学科和500多个子领域的科学实例组成的非公开EESE-Pool，在多阶段管道中确保了范围、覆盖和严谨性；2) 一个每期更新的500实例子集EESE，通过抽样和验证实现抗泄露评估，具有低开销。", "conclusion": "实验表明，EESE能够有效区分模型在科学领域的强弱以及认知维度的差异。总体而言，EESE提供了一种稳健、可扩展且向前兼容的科学基准设计解决方案，为评估基础模型处理科学问题的能力提供了一个现实的衡量标准。"}
{"llm_update_time": "20250723", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2507.16642", "html_url": "https://arxiv.org/abs/2507.16642", "title": "使用大规模语言模型在财务审计中实现自动合规性验证", "title_en": "Towards Automated Regulatory Compliance Verification in Financial Auditing with Large Language Models", "authors": "Armin Berger,Lars Hillebrand,David Leonhard,Tobias Deußer,Thiago Bell Felix de Oliveira,Tim Dilmaghani,Mohamed Khaled,Bernd Kliem,Rüdiger Loitz,Christian Bauckhage,Rafet Sifa", "background": "传统的财务文件审核是一个劳动密集型过程，而今正面临着通过采用AI驱动的解决方案进行革新。这些解决方案能够推荐符合会计标准法律要求的相关文本段落，但仍然存在显著不足，即无法验证推荐的文本段落是否真正符合具体的法律法规要求。", "innovation": "本文研究了公共可用的大规模语言模型（LLMs）在监管合规性领域的效率，尤其对比了开源模型Llama-2与专有模型OpenAI的GPT系列。这种比较分析使用了PwC德国提供定制的两个数据集。研究发现，开源模型Llama-270亿参数版本在检测违规或真阴性方面表现卓越，超越了所有专有模型，而专有模型如GPT-4在多种情况下表现最佳，尤其是在非英语环境中。", "conclusion": "开源模型Llama-2在合规性验证方面表现出色，但在多种场景下，专有模型如GPT-4表现更佳，特别是在非英语环境中。"}
{"llm_update_time": "20250723", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2507.16802", "html_url": "https://arxiv.org/abs/2507.16802", "title": "Agentar-Fin-R1: 提升金融智慧的领域专业知识、训练效率与高级推理", "title_en": "Agentar-Fin-R1: Enhancing Financial Intelligence through Domain Expertise, Training Efficiency, and Advanced Reasoning", "authors": "Yanjun Zheng,Xiyang Du,Longfei Liao,Xiaoke Zhao,Zhaowen Zhou,Bo Zhang,Jiawei Liu,Xiang Qi,Zhe Li,Zhiqiang Zhang,Wang Wei,Peng Zhang", "background": "大型语言模型（LLMs）在金融领域展现出巨大的潜力，但现有模型往往在需要强大推理能力、严格可信度要求和高效适应任务特定需求的情景中表现不佳。现有金融LLMs在处理复杂金融问题时往往存在不足，尤其是在需要高可信度和针对性较强的优化方面。", "innovation": "该论文引入了基于Qwen3基础模型的Agentar-Fin-R1系列金融大型语言模型（8B和32B参数），通过集成高质量、系统化的金融任务分类和多层次的信任保障框架，实现了推理能力、可靠性和领域专业化增强。此外，通过标签导向的自动难度感知优化、两阶段学习过程和详细溯源系统，提高了训练效率，并提出了Finova评估基准，专门评估代理级金融推理和合规验证能力。", "conclusion": "通过在主要金融基准测试（FinEva、FinEval、FinanceIQ）以及通用推理数据集（MATH-500和GPQA）上的综合评估，研究表明Agentar-Fin-R1不仅在金融任务上达到最先进的性能，还在通用推理能力方面表现出色，验证了其作为高风险金融应用中的可信解决方案的有效性。"}
{"llm_update_time": "20250723", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2507.15874", "html_url": "https://arxiv.org/abs/2507.15874", "title": "为何制动？利用大语言模型进行场景提取与推理", "title_en": "Why Braking? Scenario Extraction and Reasoning Utilizing LLM", "authors": "Yin Wu,Daniel Slieter,Vivek Subramanian,Ahmed Abouelazm,Robin Bohn,J. Marius Zöllner", "background": "ADAS（高级驾驶辅助系统）车辆数量的迅速增长带来了大量的驾驶数据，但大多数数据捕捉的是常规驾驶行为。研究安全关键的异常情况并在大量数据中识别理解这些情况仍然是一个重大挑战。刹车事件是潜在危险状态的显著标志，这激发了本研究的核心问题：车辆为何刹车？现有的方法主要依赖基于规则的经验法则，通过预定义的条件过滤器提取目标场景。这些方法在高速公路等简单环境中有效，但在复杂的城市环境中缺乏泛化能力。本研究旨在提出一种新框架，利用大语言模型（LLM）进行场景理解和推理，弥补低级数值信号和自然语言描述之间的鸿沟，使大语言模型能够解释和分类驾驶场景。该框架支持基于类别的搜索和基于嵌入的检索，分别用于已知和未知异常分布（OOD）场景。为评价该方法，我们对Argoverse 2 传感器数据集进行了场景注释的整理。实验结果表明，该方法优于基于规则的基线，并且在OOD场景中表现出较好的泛化能力。", "innovation": "本研究提出了一种新的框架，利用大语言模型进行场景理解和推理，弥补了低级数值信号和自然语言描述之间的鸿沟，使得大语言模型能够解释和分类驾驶场景。该方法支持基于类别的搜索和基于嵌入的检索，分别用于已知和未知异常分布（OOD）场景，从而提高了在复杂城市环境中的泛化能力。", "conclusion": "该方法在基于规则的基线方法中表现出优越性，并且在OOD场景中表现出良好的泛化能力。"}
{"llm_update_time": "20250723", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2507.15887", "html_url": "https://arxiv.org/abs/2507.15887", "title": "AlgoTune: 语言模型能否加速通用数值程序？", "title_en": "AlgoTune: Can Language Models Speed Up General-Purpose Numerical Programs?", "authors": "Ori Press,Brandon Amos,Haoyu Zhao,Yikai Wu,Samuel K. Ainsworth,Dominik Krupke,Patrick Kidger,Touqir Sajed,Bartolomeo Stellato,Jisun Park,Nathanael Bosch,Eli Meril,Albert Steppi,Arman Zharmagambetov,Fangzhao Zhang,David Perez-Pineiro,Alberto Mercurio,Ni Zhan,Talor Abramovich,Kilian Lieret,Hanlin Zhang,Shirley Huang,Matthias Bethge,Ofir Press", "background": "尽管语言模型（LM）的能力在不断进步，但现有的评估仍主要集中在人类已经解决的任务上，例如编程和数学领域。本文的研究背景是希望进一步测试语言模型在设计和实现算法方面的能力，特别是在计算机科学、物理学和数学中的计算挑战性问题上。为了达到这一目的，研究人员提出了一项名为AlgoTune的开放性基准测试，旨在让语言模型写出能够高效解决复杂问题的代码，并且该基准包括专家提供的155个编码任务以及验证和测量LM生成的代码的有效性框架，与常用开源包中的参考实现进行比较。", "innovation": "本文的创新之处在于提出了一项新的基准测试——AlgoTune，它专注于评估语言模型在设计和实现复杂算法方面的潜力。此外，研究团队开发了一个基于LM的基线代理AlgoTuner，并对其与前沿模型的表现进行了测试。研究发现，虽然AlgoTuner比参考实现快1.72倍，但模型在发现创新算法方面表现不佳，主要依赖于表面级别的优化。这一基准测试旨在推动开发能够超越顶尖人类表现的具有创造性解决问题能力的语言模型代理的发展。", "conclusion": "本文通过提出新的基准测试AlgoTune，展示了当前语言模型在算法设计和实现上的局限性，主要集中在表面级别的优化上，而不是真正的创新。研究团队希望这一基准测试能够推动未来研究的发展，促进语言模型在算法设计上的创造性发展，超越目前人类的顶级表现。"}
{"llm_update_time": "20250723", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2507.16632", "html_url": "https://arxiv.org/abs/2507.16632", "title": "Step-Audio 2 技术报告", "title_en": "Step-Audio 2 Technical Report", "authors": "Boyong Wu,Chao Yan,Chen Hu,Cheng Yi,Chengli Feng,Fei Tian,Feiyu Shen,Gang Yu,Haoyang Zhang,Jingbei Li,Mingrui Chen,Peng Liu,Wang You,Xiangyu Tony Zhang,Xingyuan Li,Xuerui Yang,Yayue Deng,Yechang Huang,Yuxin Li,Yuxin Zhang,Zhao You,Brian Li,Changyi Wan,Hanpeng Hu,Jiangjie Zhen,Siyu Chen,Song Yuan,Xuelin Zhang,Yimin Jiang,Yu Zhou,Yuxiang Yang,Bingxin Li,Buyun Ma,Changhe Song,Dongqing Pang,Guoqiang Hu,Haiyang Sun,Kang An,Na Wang,Shuli Gao,Wei Ji,Wen Li,Wen Sun,Xuan Wen,Yong Ren,Yuankai Ma,Yufan Lu,Bin Wang,Bo Li,Changxin Miao,Che Liu,Chen Xu,Dapeng Shi,Dingyuan Hu,Donghang Wu,Enle Liu,Guanzhe Huang,Gulin Yan,Han Zhang,Hao Nie,Haonan Jia,Hongyu Zhou,Jianjian Sun,Jiaoren Wu,Jie Wu,Jie Yang,Jin Yang,Junzhe Lin,Kaixiang Li,Lei Yang,Liying Shi,Li Zhou,Longlong Gu,Ming Li,Mingliang Li,Mingxiao Li,Nan Wu,Qi Han,Qinyuan Tan,Shaoliang Pang,Shengjie Fan,Siqi Liu,Tiancheng Cao,Wanying Lu,Wenqing He,Wuxun Xie,Xu Zhao,Xueqi Li,Yanbo Yu,Yang Yang,Yi Liu,Yifan Lu,Yilei Wang,Yuanhao Ding,Yuanwei Liang,Yuanwei Lu,Yuchu Luo,Yuhe Yin,Yumeng Zhan,Yuxiang Zhang", "background": "本文介绍了一个名为Step-Audio 2的端到端多模态大规模语言模型，专门用于工业级别的音频理解和语音对话。该模型通过结合隐式音频编码器和以推理为中心的强化学习（RL），在自动语音识别（ASR）和音频理解方面取得了显著的性能。", "innovation": "Step-Audio 2将离散音频标记的生成融入到语言模型中，显著提升了其对旁白信息（如说话风格和情绪）的响应能力；通过集成检索增强生成（RAG）并能调用外部工具（如网络搜索）以减少幻觉，以及音频搜索以改变音色，有效地利用了现实世界数据中的丰富文本和声学知识；模型在数百万小时的语音和音频数据上进行了训练，提供了多样对话场景下的智能和表现力。", "conclusion": "评估结果表明，Step-Audio 2在各种音频理解和对话基准测试中，相比其他开源和商业解决方案表现卓越。欲了解更多信息，请访问此网址：this https URL"}
{"llm_update_time": "20250723", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2507.15867", "html_url": "https://arxiv.org/abs/2507.15867", "title": "RDMA：电子健康记录系统中低成本代理驱动的罕见疾病发现", "title_en": "RDMA: Cost Effective Agent-Driven Rare Disease Discovery within Electronic Health Record Systems", "authors": "John Wu,Adam Cross,Jimeng Sun", "background": "罕见疾病影响美国10%的人口，但现有标准ICD编码系统无法在电子健康记录(EHR)中捕捉到这些条件，重要信息往往埋藏在临床笔记中。当前方法在处理医疗缩写、忽略隐含疾病提及、云处理引起隐私担忧以及缺乏临床推理能力等方面存在不足。", "innovation": "提出了一种称为Rare Disease Mining Agents (RDMA)的新框架，它模仿了医疗专家如何在EHR中识别罕见疾病模式的方法。RDMA通过管理临床缩写、识别隐含疾病模式，并在标准硬件上进行上下文推理，减少了隐私风险，同时提高了F1性能高达30%，并降低了推理成本10倍。", "conclusion": "该方法帮助临床医生避免使用云服务带来的隐私风险，同时从EHR系统中获取关键的罕见疾病信息，支持罕见疾病患者的早期诊断。"}
{"llm_update_time": "20250723", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2507.16812", "html_url": "https://arxiv.org/abs/2507.16812", "title": "MegaScience：推进建模后数据集在科学推理领域的边界", "title_en": "MegaScience: Pushing the Frontiers of Post-Training Datasets for Science Reasoning", "authors": "Run-Ze Fan,Zengzhi Wang,Pengfei Liu", "background": "科学推理对培养AI科学家和支持人类研究人员推进自然科学发现至关重要。然而，开源社区主要关注于数学和编程，忽视了科学领域，主要原因是缺乏开放、大规模、高质量、可验证的科学推理数据集。为了弥合这一差距，通过系统删除法研究评估各种数据选择方法以确定每个公开可用的科学数据集的最佳子集，形成了包含12,000本科大学科学教科书的真实参考答案，涵盖650,000个科学推理问题。此外，还构建了涵盖15个基准的全面评估系统，包括来自1.25万个实例的不同学科和问题类型的全面答提取策略，以确保准确的评估指标。实验结果显示，与现有的开源科学数据集相比，我们的数据集在更简洁的响应长度下实现了更优的性能和训练效率。此外，Megascience对大型和强大模型的效果更为显著，表明其在科学调优方面具有规模优势。", "innovation": "首先，通过系统删除法构建了一个开放的数据集TextbookReasoning，包含从12,000本科大学科学教科书中提取的真实参考答案，涵盖650,000个科学推理问题，涉及7个学科领域。进一步引入了Megascience，包含1.25万个实例的高质量开源数据集混合，通过系统删除法评估不同数据选择方法，构建了一个综合评估系统，涵盖15个基准，使用全面的答提取策略确保准确的评估指标。在Megascience数据集上训练Llama3.1、Qwen2.5和Qwen3系列基础模型，其在平均性能上显著优于相应的官方指令式模型。Megascience对大型和强大模型的效果更突出，表现出规模优势。", "conclusion": "我们发布了用于科学推理研究的数据集编撰流水线、评估系统、数据集和七个训练模型，旨在推进科学推理研究。"}
{"llm_update_time": "20250723", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2507.16809", "html_url": "https://arxiv.org/abs/2507.16809", "title": "LingBench++：多步骤和跨文化推理的基于语言的人工智能基准和推理框架", "title_en": "LingBench++: A Linguistically-Informed Benchmark and Reasoning Framework for Multi-Step and Cross-Cultural Inference with LLMs", "authors": "Da-Chen Lian,Ri-Sheng Huang,Pin-Er Chen,Chunki Lim,You-Kuan Lin,Guan-Yu Tseng,Zi-Cheng Yang,Shu-Kai Hsieh", "background": "以往的基准测试主要关注最终答案的准确性，而未提供结构化的推理轨迹、逐步评估协议以及丰富的类型学元数据。本文旨在通过LingBench++对大型语言模型（LLMs）进行评估，该框架受到国际语言奥林匹克（IOL）的启发，旨在考察复杂的语言任务。它涵盖了90多种低资源和跨文化语言，以更全面地评估LLMs的表现。", "innovation": "LingBench++引入了多智能体架构，结合了语法知识检索、工具增强推理和严格的假设检验。通过与基准模型的系统比较，展示了带有外部知识源和支持迭代推理的模型在准确性和可解释性方面优于单一步骤的方法。", "conclusion": "LingBench++为LLMs提供了基于语言、跨文化理解和认知合理性的全面基础，提升了多步骤推理的能力。"}
{"llm_update_time": "20250723", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2507.16298", "html_url": "https://arxiv.org/abs/2507.16298", "title": "WhatsApp Tiplines and Multilingual Claims in the 2021 Indian Assembly Elections", "title_en": "WhatsApp Tiplines and Multilingual Claims in the 2021 Indian Assembly Elections", "authors": "Gautam Kishore Shahi,Scot A. Hale", "background": "2019年，WhatsApp推出了举报热线，旨在打击虚假信息。本研究分析了2021年印度众议院选举期间来自451名用户的580个独特的断言，覆盖了资源丰富（英语、印地语）和资源匮乏（泰卢固语）的语言，通过混合方法探讨了多语言断言的特点和差异。", "innovation": "研究采用混合方法分析了580个独特的断言，将其分为竞选、新冠和其他三个类别，并通过高频词分析和神经句子嵌入聚类对比内容的相似性。此外，研究还调查了语言间的用户重叠以及事实核查机构之间的重叠，并度量了平驳证明断言所需的时间。研究发现，用户经常多语言提交断言给同一个事实核查员，且通常需要一到两天的时间来验证新的断言并告知举报用户。值得注意的是，用户不会向多家事实核查机构提交断言，显示出每个机构都有自己独特的受众群体。", "conclusion": "本研究揭示了多语言断言的相似之处，为选举期间使用举报热线提供了实用建议，并强调在处理用户信息时要考虑伦理问题。"}
{"llm_update_time": "20250723", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2507.16463", "html_url": "https://arxiv.org/abs/2507.16463", "title": "MMS Player: 一种用于手语 avatar 动画参数数据驱动生成的开源软件", "title_en": "MMS Player: an open source software for parametric data-driven animation of Sign Language avatars", "authors": "Fabrizio Nunnari,Shailesh Mishra,Patrick Gebhard", "background": "本文描述了MMS-Player，一个开源软件，能够从一种新颖的手语表示格式MMS（多模态手语流）中合成手语动画。MMS通过添加手势并发执行、时间信息和变形的详细信息，增强了基于词的表示。该软件实现了流行3D着色工具Blender的Python脚本，并可通过命令行或HTTP API调用。动画可以渲染为视频，也可以导出为其他流行的3D动画交换格式。这项软件在GPL-3.0许可证下免费提供，供使用者下载和使用。", "innovation": "MMS-Player通过使用新型手语表示格式MMS，增强了基于词的手语表示，使其能够包含手势的并发执行、时间和变形信息。这是一种主要的创新之处。此外，软件实现了流行的Blender 3D着色工具，并能通过命令行或HTTP API调用，提供了灵活的交互方式。动画可以以多种格式输出，增强了其应用范围。", "conclusion": "本文所描述的MMS-Player开源软件，通过提供一种新型的手语表示格式MMS，增强了基础的手语表示，并通过流行的Blender 3D工具实现了手语动画的合成。所开发的软件能够通过命令行或HTTP API调用，支持动画的多种输出格式，具有广泛的实用价值。根据GPL-3.0许可证，该软件免费提供，供研究和开发人员使用。"}
{"llm_update_time": "20250723", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2507.16784", "html_url": "https://arxiv.org/abs/2507.16784", "title": "突破上下文限制: 长时推理的潜意识线程", "title_en": "Beyond Context Limits: Subconscious Threads for Long-Horizon Reasoning", "authors": "Hongyin Luo,Nathaniel Morgan,Tina Li,Derek Zhao,Ai Vy Ngo,Philip Schroeder,Lijie Yang,Assaf Ben-Kish,Jack O'Brien,James Glass", "background": "大型语言模型（LLMs）在推理准确性和效率方面受到上下文限制的瓶颈制约。", "innovation": "本文提出了Thread Inference Model（TIM）及其运行时TIMRUN，这些模型和工具可以通过归纳和分解的策略解决递归和分解的问题，并且支持长时结构性推理超过上下文限制。通过将自然语言表示为根据长度和深度测量的推理树，以及通过维护一个仅保留最相关上下文标记的关键值状态的工作记忆，实现突破输出限制、位置嵌入约束和GPU内存瓶颈。", "conclusion": "实验结果显示，该系统即使在处理高达90%的KV缓存时，也能保持高推理吞吐量，并且在数学任务中的推理准确率达到高水平，同时能够处理需要长时推理和多跳工具使用的信息检索挑战。"}
{"llm_update_time": "20250723", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2507.16518", "html_url": "https://arxiv.org/abs/2507.16518", "title": "C2-Evo: 共同演化多模态数据与模型以实现自我改进推理", "title_en": "C2-Evo: Co-Evolving Multimodal Data and Model for Self-Improving Reasoning", "authors": "Xiuwei Chen,Wentao Hu,Hanhui Li,Jun Zhou,Zisheng Chen,Meng Cao,Yihan Zeng,Kui Zhang,Yu-Jie Yuan,Jianhua Han,Hang Xu,Xiaodan Liang", "background": "近年来，多模态大型语言模型（MLLMs）展现了出色的推理能力，但要进一步提升，需要高质量且任务复杂的视听数据集，这既昂贵又难以规模化扩展。尽管有一些迭代自我改进的模型可以解决部分问题，他们仍面临两大核心挑战：（i）现有的大多数方法是单独增强视觉或文本数据，导致数据复杂性之间的不匹配（例如，简化图与冗余文本描述的配对）；（ii）数据和模型的进化是分开的，导致模型可能接触到难度不匹配的任务。", "innovation": "我们提出了一种自动闭环自我改进框架C2-Evo，旨在共同进化训练数据和模型能力。C2-Evo包括一个跨模态数据进化循环和一个数据-模型进化循环。前者通过结合结构化文本子问题和逐步指定的几何图生成复杂的多模态问题，扩展了基底数据集。后者根据基底模型的性能动态选择生成的问题，进行监督微调和强化学习交替进行。这种机制使模型和训练数据不断精炼，从而在多个数学推理基准上取得显著性能提升。", "conclusion": "我们的方法持续改进模型和训练数据，并在多个数学推理基准上取得显著性能提升。我们的代码、模型和数据集将在发布。"}
{"llm_update_time": "20250723", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2507.16713", "html_url": "https://arxiv.org/abs/2507.16713", "title": "经验是最好的老师：通过自我生成的记忆将VLMs应用于机器人技术", "title_en": "Experience is the Best Teacher: Grounding VLMs for Robotics through Self-Generated Memory", "authors": "Guowei Lan,Kaixian Qu,René Zurbrügg,Changan Chen,Christopher E. Mower,Haitham Bou-Ammar,Marco Hutter", "background": "视觉-语言模型（VLMs）在机器人中被广泛使用，以实现自主规划。然而，将这些模型从互联网数据中训练所得的内容接地到各种现实中的机器人仍然是一项挑战。", "innovation": "ExpTeach框架通过构建对现实世界经验的自我生成记忆，将VLMs接地到物理机器人。在ExpTeach框架中，VLM自主规划动作，验证结果，反思失败并根据结果封闭式循环地调整机器人行为。自我生成的经验过程中的总结形成了长期记忆，并通过检索增强生成(RAG)来检索学习的知识以指导未来任务。此外，ExpTeach引入了一个按需图像标注模块，增强了VLM的空间理解。在实验中，结果显示通过反思可以将四个人机挑战任务的成功率从36％提高到84％，并观察到智能物体交互的出现，包括创新的工具使用。在广泛测试12种真实世界场景（包括八种未见过的场景）中，发现使用长期记忆接地可以将一次成功的成功率从22％提高到80％，证明了ExpTeach的有效性和普遍适用性。", "conclusion": "ExpTeach提高了四个人机挑战任务的成功率，并通过自我生成的记忆提升单次试验的成功率，展示了它的有效性和泛化能力。"}
{"llm_update_time": "20250723", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2507.16795", "html_url": "https://arxiv.org/abs/2507.16795", "title": "通过概念消除微调引导离分布外推", "title_en": "Steering Out-of-Distribution Generalization with Concept Ablation Fine-Tuning", "authors": "Helena Casademunt,Caden Juang,Adam Karvonen,Samuel Marks,Senthooran Rajamanoharan,Neel Nanda", "background": "大规模语言模型（LLMs）在微调过程中可能会出现意外的离分布外推问题。标准解决方法依赖于修改训练数据，例如通过增加更加具体的训练数据。然而，这种方法并非总是可行。", "innovation": "引入了概念消除微调（CAFT），这是一种利用可解释性工具的技术，在无需修改训练数据或使用目标分布数据的前提下，控制LLMs在微调过程中的外推。给定LLM潜空间中与不良概念对应的指令集，CAFT通过在微调过程中消除这些概念，引导模型远离无意的外推。", "conclusion": "CAFT能够在不修改微调数据的情况下，将不良外推减少10倍，同时不损害训练分布上的性能。总体而言，CAFT代表了一种新的引导LLMs外推的方法，无需修改训练数据。"}
{"llm_update_time": "20250723", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2507.16799", "html_url": "https://arxiv.org/abs/2507.16799", "title": "Test-Time-Matching: 在基于大型语言模型的语言代理角色扮演中解耦人格、记忆和语言风格", "title_en": "Test-Time-Matching: Decouple Personality, Memory, and Linguistic Style in LLM-based Role-Playing Language Agent", "authors": "Xiaoyu Zhan,Xinyu Fu,Hao Sun,Yuanqi Li,Jie Guo,Yanwen Guo", "background": "大型语言模型（LLMs）的快速发展使得语言代理在各种应用中的表现极具潜力。然而，仅依赖于提示和上下文输入往往不足以在特定角色中实现深层次的沉浸体验，尤其是对于著名虚构或公共人物。此外，基于微调的方法受限于数据收集的挑战和训练所需的大量计算资源，这限制了它们的广泛应用。", "innovation": "我们提出了Test-Time-Matching（TTM）框架，这是一种无需训练的角色扮演方法，通过测试时尺度调整和上下文工程实现。TTM将人物特征自动解耦为人格、记忆和语言风格，并通过一个结构化的三阶段生成流程利用这些特征进行受控角色扮演。该框架提供了高质量的角色扮演性能，使得各种语言风格的结合成为可能，甚至在人格和记忆存在变化的情况下，也能够实现风格一致的对话。", "conclusion": "我们通过人类评估测试了该框架，结果表明，我们的方法在生成有表现力且风格一致的对话人物台词方面表现出色。"}
{"llm_update_time": "20250723", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2507.16746", "html_url": "https://arxiv.org/abs/2507.16746", "title": "Zebra-CoT: 一个用于交错视觉语言推理的数据集", "title_en": "Zebra-CoT: A Dataset for Interleaved Vision Language Reasoning", "authors": "Ang Li,Charles Wang,Kaiyu Yue,Zikui Cai,Ollie Liu,Deqing Fu,Peng Guo,Wang Bill Zhu,Vatsal Sharan,Robin Jia,Willie Neiswanger,Furong Huang,Tom Goldstein,Micah Goldblum", "background": "人类在解决复杂问题时经常使用视觉辅助工具，如图表或草图。训练多模态模型执行相同任务，即视觉链推理（Visual CoT），由于缺乏高质量的视觉链训练数据以及现有预训练视觉CoT能力不佳，带来了挑战。这些问题阻碍了强化学习的应用。Zebra-CoT旨在填补这一空白，通过提供一个包含逻辑连贯且交错的文本-图像推理痕迹的大规模数据集，旨在涵盖具体推理任务，例如几何学、物理学、算法、视觉搜索、拼图、三维推理任务等，以更好地支持多模态推理能力的发展和评估。", "innovation": "Zebra-CoT集成了一个包含182,384个样本的大规模多样化数据集，这些样本包含了逻辑上连贯的交错文本-图像推理过程。Zebra-CoT特别关注四个类别：科学问题（如几何学、物理学和算法）、2D视觉推理任务（如视觉搜索和拼图）、3D推理任务（如3D多跳推理、机器人规划）以及视觉逻辑问题和战略游戏（如象棋）。在使用Zebra-CoT进行微调后，Anole-7B模型的测试集准确性提高了12%，Bagel-7B模型生成了高质量的交错视觉推理链，这验证了Zebra-CoT的有效性。", "conclusion": "Zebra-CoT和相应的微调模型被开源，以支持视觉链推理的研究和评估。"}
{"llm_update_time": "20250723", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2507.15882", "html_url": "https://arxiv.org/abs/2507.15882", "title": "Document Haystack: 长文档多模态图像/文档理解视觉LLM基准", "title_en": "Document Haystack: A Long Context Multimodal Image/Document Understanding Vision LLM Benchmark", "authors": "Goeric Huybrechts,Srikanth Ronanki,Sai Muralidhar Jayanthi,Jack Fitzgerald,Srinivasan Veeravanallur", "background": "多模态大型语言模型的普及显著提高了对来自不同模态的复杂数据输入进行分析和理解的能力。然而，长文档的处理仍然相对不足，主要是由于缺乏合适的基准数据。为了解决这一问题，本文介绍了Document Haystack，这是一个旨在评估视觉语言模型（VLMs）在长且视觉上复杂的文档上表现的综合基准。Document Haystack 包含从5到200页的大量文档，并在文档中插入不同深度的纯文本或多模态文本+图像“针”，以此检验VLMs的检索能力。", "innovation": "本文提出了Document Haystack，这是一个全面的基准测试，专门针对视觉语言模型在长文档处理中的性能进行评估。该基准测试包括了大量的文档变体（400种）和共计8,250个问题，并附带了一个客观的自动化评估框架。", "conclusion": "本文详细描述了Document Haystack数据集的构建与特点，展示了一些著名VLMs的实验结果，并讨论了该领域内进一步的研究方向。"}
{"llm_update_time": "20250723", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2507.16806", "html_url": "https://arxiv.org/abs/2507.16806", "title": "超越二元奖励：训练模型评估不确定性", "title_en": "Beyond Binary Rewards: Training LMs to Reason About Their Uncertainty", "authors": "Mehul Damani,Isha Puri,Stewart Slocum,Idan Shenfeld,Leshem Choshen,Yoon Kim,Jacob Andreas", "background": "语言模型（LMs）通过强化学习（RL）训练来生成自然语言推理链，其在各种困难的问答任务上的性能得到了提升。然而，大多数RL应用中的奖励函数是二元的，仅评估LM输出的正确性，这对模型的校准性造成负面影响，导致模型增加不正确的响应（或“虚幻”）的频率。此研究旨在解决该问题，提出RLCR（Calibration Rewards的强化学习），旨在同时提高准确性和校准概率估计。", "innovation": "提出了一种新的训练方法——RLCR，该方法通过奖励函数结合了二元正确性得分和Brier得分，Brier得分能够激励概率估计的校准。研究证明，这种奖励函数可以产出既准确又校准良好的模型，减少普通RL对校准性的负面影响，并在不同数据集上实现了显著的校准改进，同时不牺牲准确性。此外，研究还展示了如何利用词化的置信度在测试时通过置信加权缩放方法提高准确性和校准性。", "conclusion": "通过优化校准性，RLCR能够生成更可靠的一般推理模型。实验结果表明，专门优化校准性可以产出更可靠的推理模型。"}
{"llm_update_time": "20250723", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2410.08800", "html_url": "https://arxiv.org/abs/2410.08800", "title": "OpenGPT-X模型系列的数据处理", "title_en": "Data Processing for the OpenGPT-X Model Family", "authors": "Nicolo' Brandizzi,Hammam Abdelwahab,Anirban Bhowmick,Lennard Helmer,Benny Jörg Stein,Pavel Denisov,Qasid Saleem,Michael Fromm,Mehdi Ali,Richard Rutmann,Farzad Naderi,Mohamad Saif Agy,Alexander Schwirjow,Fabian Küch,Luzian Hahn,Malte Ostendorff,Pedro Ortiz Suarez,Georg Rehm,Dennis Wegener,Nicolas Flores-Herr,Joachim Köhler,Johannes Leveling", "background": "本文综述了OpenGPT-X项目中开发的数据准备管道，该项目旨在创建开源且高性能的多语言大型语言模型（LLMs），特别关注欧盟内的实际应用。该项目的目标是涵盖所有主要的欧洲语言，并介绍了从数据选择和需求定义到最终数据过滤的所有数据处理步骤。数据被区分为受控数据和网络数据，这两种类别分别由不同的管道处理，受控数据只经过轻微过滤，而网络数据需要大量过滤和去重。这种区分指导了针对两种管道开发专门的算法解决方案。此外，还对数据集进行了深入分析，以提高透明度并符合欧洲数据法规。", "innovation": "该项目开发了专门针对受控数据和网络数据的算法解决方案，特别是在数据预处理和清理方面采取了专门的措施，以适应不同数据源的特点，从而提高了数据质量和模型的准确性。数据处理方法详细且透明，重点在于遵守欧洲数据保护法规，确保数据的安全性和合规性。针对大规模多语言数据准备过程中可能遇到的问题给出了见解和建议，为未来的类似项目提供了参考。", "conclusion": "本研究通过深入的分析和详细的步骤说明，提高了OpenGPT-X项目数据处理的透明度和合规性，缓解了在大规模多语言数据准备过程中遇到的各种挑战，为未来大规模多语言数据的准备工作提供了重要的参考和建议。"}
{"llm_update_time": "20250723", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2502.02451", "html_url": "https://arxiv.org/abs/2502.02451", "title": "非英语：基于中文案例研究的道德基础自动化测量超越英语", "title_en": "Beyond English: Evaluating Automated Measurement of Moral Foundations in Non-English Discourse with a Chinese Case Study", "authors": "Calvin Yixiang Cheng,Scott A Hale", "background": "大多数计算资源主要针对英语开发，跨语言应用道德基础理论仍然有限。因此，该研究通过将道德基础理论应用于非英语语料库（如中文），探索了计算方法在测量非英语道德基础中的有效性，旨在为跨语言的道德评估提供可能的解决方案。", "innovation": "该研究采用了机器翻译、本地语言词典、多语言模型和大规模语言模型四个方面的方法，评估了它们在非英语语料库中测量道德基础的有效性。研究指出，尽管多语言模型和大规模语言模型在跨语言评估中表现稳定，但人机协同验证仍然是重要需求，以确保模型的准确性。", "conclusion": "该研究强调了大规模语言模型在跨语言道德基础测量中的潜力，并明确指出，在跨语言测量道德基础时，需要结合人工验证以避免忽视文化细微差别。"}
{"llm_update_time": "20250723", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2502.08773", "html_url": "https://arxiv.org/abs/2502.08773", "title": "通用模型路由方法以实现高效的大语言模型推理", "title_en": "Universal Model Routing for Efficient LLM Inference", "authors": "Wittawat Jitkrittum,Harikrishna Narasimhan,Ankit Singh Rawat,Jeevesh Juneja,Congchao Wang,Zifeng Wang,Alec Go,Chen-Yu Lee,Pradeep Shenoy,Rina Panigrahy,Aditya Krishna Menon,Sanjiv Kumar", "background": "模型路由是一种减少大型语言模型推理成本的简单技术，核心思想是在候选语言模型池中维护一个模型集合，并在每次查询时学习将每个提示路由到最小可行的模型。现有的研究主要集中在学习固定模型池的路由机制。本文探讨了在测试时新引入、之前未观察过的语言模型的动态路由问题并提出了一种新的方法，即UniRoute，该方法通过使用基于一组代表性提示的预测结果构建的特征向量来表示每个语言模型，从而实现模型路由。研究展示了这两种实施方案的有效性，并通过超额风险界说明了它们与理论最优路由规则之间的关系。实验结果表明，UniRoute在超过30个未见过的语言模型之间具有路由效果。", "innovation": "提出了UniRoute方法，解决测试时可供选择的语言模型不断变化的问题，通过构建基于特征向量的路由机制，有效地实现动态的模型路由。", "conclusion": "通过实验，UniRoute方法在超过30个不同的未见过的语言模型之间显示出有效的路由效果，证明了其优越性。"}
{"llm_update_time": "20250723", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2507.16534", "html_url": "https://arxiv.org/abs/2507.16534", "title": "实践中的前沿AI风险管理框架：一项风险分析技术报告", "title_en": "Frontier AI Risk Management Framework in Practice: A Risk Analysis Technical Report", "authors": "Shanghai AI Lab:Xiaoyang Chen,Yunhao Chen,Zeren Chen,Zhiyun Chen,Hanyun Cui,Yawen Duan,Jiaxuan Guo,Qi Guo,Xuhao Hu,Hong Huang,Lige Huang,Chunxiao Li,Juncheng Li,Qihao Lin,Dongrui Liu,Xinmin Liu,Zicheng Liu,Chaochao Lu,Xiaoya Lu,Jingjing Qu,Qibing Ren,Jing Shao,Jingwei Shi,Jingwei Sun,Peng Wang,Weibing Wang,Jia Xu,Lewen Yan,Xiao Yu,Yi Yu,Boxuan Zhang,Jie Zhang,Weichen Zhang,Zhijie Zheng,Tianyi Zhou,Bowen Zhou", "background": "本文探讨了快速发展的AI模型所带来的前所未有的风险，并通过前沿AI风险管理框架(v1.0)的E-T-C分析（部署环境、威胁来源、使能能力），识别了七个关键风险领域：网络进攻、生物和化学风险、说服与操纵、不受控制的自主AI研究与发展、战略欺骗和策划、自我复制以及合谋。", "innovation": "本文创新性地提出了基于‘AI-45°法则’的风险评估方法，并通过‘红线’（不可容忍门槛）和‘黄线’（早期预警指标）定义了风险区域：绿色（可管理的风险，适用于常规部署和持续监控）、黄色（需要加强缓解措施和控制部署）、红色（需要暂停开发和/或部署）。实验结果显示，所有前沿AI模型均位于绿色和黄色区域，未触犯红线。", "conclusion": "文章展示了我们目前对AI前沿风险的理解，并强调集体行动以缓解这些挑战的必要性。"}
{"llm_update_time": "20250723", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2507.16185", "html_url": "https://arxiv.org/abs/2507.16185", "title": "青少年人群自杀死亡中涉及的在线活动特征", "title_en": "Characterizing Online Activities Contributing to Suicide Mortality among Youth", "authors": "Aparna Ananthasubramaniam,Elyse J. Thulin,Viktoryia Kalesnikava,Silas Falde,Jonathan Kertawidjaja,Lily Johns,Alejandro Rodríguez-Putnam,Emma Spring,Kara Zivin,Briana Mezuk", "background": "近年来青少年自杀率的上升凸显了迫切需要理解在线经历如何影响这一公共卫生问题的重要性。", "innovation": "本研究采用混合方法，通过开发一系列主题和框架来识别10-24岁青少年自杀死亡案中与在线活动相关的风险因素。通过2013-2022年间29,124个死亡调查的开放式文本摘要进行主题分析，识别出与自杀死亡相关的12种在线活动类型，并发展了一个零样本学习框架来大规模建模这些主题，分析这些主题与死者特征和时间变化的相关性。研究发现，这些在线活动涉及自我伤害、对他人造成伤害、人际互动、在线活动水平和生活事件，这与自杀风险的两个主要理论阶段相对应。", "conclusion": "研究指出，这些主题与死者特征如年龄、死亡手段和人际问题有关，并且许多主题在2020年新冠封锁期间变得更加普遍。尽管数字空间采取了一些措施来应对在线自杀行为的表达，本研究展示了将自杀理论与计算研究结合以开发与显性自杀风险指标有关的干预措施的机会。"}
{"llm_update_time": "20250723", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2502.16940", "html_url": "https://arxiv.org/abs/2502.16940", "title": "推理未必能提升角色扮演能力", "title_en": "Reasoning Does Not Necessarily Improve Role-Playing Ability", "authors": "Xiachong Feng,Longxu Dou,Lingpeng Kong", "background": "角色扮演类大型语言模型（LLMs）在学术和商业领域中的应用越来越广泛，导致对高精度角色扮演模型的需求增加。同时，推理技术的快速发展也不断推动LLMs的性能边界，这种角色扮演需求与推理能力演进的交汇提出了一个重要的研究问题：推理技术能否增强LLMs的角色扮演能力？", "innovation": "本研究采用6个角色扮演基准、24个LLMs和3种不同的角色扮演策略，对比了直接零-shot角色扮演、带有Chain-of-Thought（CoT）的角色扮演和使用推理优化的LLMs的有效性。研究发现CoT可能降低了角色扮演性能，推理优化的LLMs不适合角色扮演，推理能力打破角色扮演的扩展规律，大型模型在高级角色扮演方面仍然缺乏专业性，而中文的角色扮演性能超过了英语的角色扮演性能。此外，基于大量的实验结果提出了两个有前途的未来研究方向：针对角色的角色意识CoT和用于角色扮演的强化学习，以提高角色扮演LLMs的适应性、一致性和效用，适用于研究和实际应用的结合场景。", "conclusion": "总体而言，研究表明推理未必能提升角色扮演能力，并且推理-优化的LLMs并不适合角色扮演。未来的研究方向应聚焦于角色感知的CoT和强化学习，以增强角色扮演LLMs在研究和实际应用中的适应性和效果。"}
{"llm_update_time": "20250723", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2404.14740", "html_url": "https://arxiv.org/abs/2404.14740", "title": "建模神圣：自然语言处理中使用宗教文本的考虑", "title_en": "Modeling the Sacred: Considerations when Using Religious Texts in Natural Language Processing", "authors": "Ben Hutchinson", "background": "本文探讨了在自然语言处理（NLP）中使用宗教文本的问题，并特别强调了NLP伦理方面的重要性。宗教文本是文化价值的重要表达方式，机器学习模型有倾向于再现训练数据中编码的文化价值的趋势。此外，当缺少特定语言的数据时，NLP研究人员经常使用宗教文本的翻译版本。这种做法重新利用了这些文本的初始目的和动机，通常是为了吸引新的信徒。本文指出，NLP使用这些文本不仅涉及模型偏差，还包括数据来源、文化背景以及它们用于传教的问题。", "innovation": "本文提倡对研究员的立场有更多的考虑，并关注边缘化语言和宗教社区的观点。", "conclusion": "本文讨论了在NLP中使用宗教文本所带来的伦理问题，认为这不仅仅是模型偏差的问题，还包括数据来源、文化背景以及这些文本用于传教的问题。因此，建议研究人员在处理这些数据时更加谨慎，并考虑更多的社会因素。"}
{"llm_update_time": "20250723", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2507.16145", "html_url": "https://arxiv.org/abs/2507.16145", "title": "SpiroLLM：通过临床验证对预训练LLM进行微调以理解呼吸流量图时间序列", "title_en": "SpiroLLM: Finetuning Pretrained LLMs to Understand Spirogram Time Series with Clinical Validation in COPD Reporting", "authors": "Shuhao Mei,Yongchao Long,Shan Cao,Xiaobo Han,Shijia Geng,Jinbo Sun,Yuxi Zhou,Shenda Hong", "background": "慢性阻塞性肺病（COPD）是一种主要的慢性呼吸系统疾病，表现为持续性的气流受限，是全球范围内导致残疾和死亡的重要原因。肺功能测试（PFTs）收集的呼吸流量图时间序列数据在早期发现呼吸系统疾病及长期监测肺功能上起着关键作用。然而，现有的许多AI模型在COPD诊断上只能输出分类结果而无法解释其诊断过程，同时目前的大型语言模型（LLMs）也无法理解呼吸流量图，这严重限制了它们在临床中的信任度和应用。", "innovation": "我们利用英国生物银行（UK Biobank）中的234,028名个体数据，提出了SpiroLLM，这是第一个能够理解呼吸流量图的多模态大型语言模型。SpiroLLM通过SpiroEncoder提取呼吸曲线的形态特征，并通过SpiroProjector在统一的潜在空间中将这些特征与PFT数值相匹配，最终使大型语言模型能够生成全面的诊断报告。实验结果表明，SpiroLLM的诊断AUROC为0.8980，且在缺失核心数据的稳健性测试中保持100%的有效响应率，远超文本模型的13.4%表现，展示了其多模态设计的优势。", "conclusion": "这项工作证明了将生理信号与大型语言模型深度融合的巨大潜力，为新一代可解释、可靠的临床决策支持工具建立了新的范式。"}
{"llm_update_time": "20250723", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2503.07457", "html_url": "https://arxiv.org/abs/2503.07457", "title": "大型语言模型在对话中语法上调整其语言使用以适应其对话伙伴", "title_en": "LLMs syntactically adapt their language use to their conversational partner", "authors": "Florian Kandra,Vera Demberg,Alexander Koller", "background": "在人类对话中，参与者往往会调整其语言使用，以与对方保持一致。本研究探讨大型语言模型（LLMs）是否也会展现出同样的对话适应性行为。", "innovation": "研究构建了一组LLM之间的对话语料库，发现随着对话的进行，两个LLM代理最终在语法选择上变得更相似，证实了现代LLMs在一定程度上能够调整其语言使用以符合对话伙伴的特点。", "conclusion": "研究结果表明，现代LLMs在对话中会展现出一定程度的语法适应性，以调整其语言使用来匹配对话伙伴。"}
{"llm_update_time": "20250723", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2503.10706", "html_url": "https://arxiv.org/abs/2503.10706", "title": "SciFi-Benchmark: 利用科幻作品提升机器人行为", "title_en": "SciFi-Benchmark: Leveraging Science Fiction To Improve Robot Behavior", "authors": "Pierre Sermanet,Anirudha Majumdar,Vikas Sindhwani", "background": "随着人工智能（AI）和机器人技术的快速发展，人们越来越关注未来由AI控制的机器人是否会与人类的价值观保持高度一致。为了探索这一问题，本研究提出了一种通过生成涵盖824部科幻文学（包括电影、电视剧、小说和科技书籍）的关键时刻基准测试方法，来评估AI是否能够做出符合人类价值观的重大决策。这种方法是通过先进大模型对每个关键时刻进行回顾，提出类似情况下的问题、由代理（AI或机器人）做出的决策及可能的替代决策（好或坏），并测量模型对人类价值观的对齐程度。此外，通过生成基于科幻元素的宪法来指导AI伦理行为，从而在真实世界中促进AI的行为符合伦理标准。研究发现，与科幻作品中常出现的不人道决定相比，现代大模型与人类价值观的高度对齐（95.8%），并且生成的基于科幻元素的宪法在推动AI行为伦理方面表现出显著优势与稳定性。", "innovation": "本研究创新性地利用科幻文学中的关键时刻生成了一个大规模数据集——SciFi-Benchmark，通过先进的大语言模型（LLM）对这些关键时刻进行封闭式回顾，提出了类似情况下的问题、决策和替代决策，并通过生成一系列基于科幻元素的宪法来提高AI的伦理表现。这些宪法在模型对齐人类价值观方面表现优异，并且在对抗性提示设置下也具有强大的适应性。因此，本研究为机器人伦理学和安全研究提供了一个新的研究工具，并能有效提升现实世界中AI的行为符合伦理标准的能力。", "conclusion": "现代大模型与基于科幻元素的宪法相结合表现出高度的人类价值观对齐（95.8%），远超科幻作品中通常呈现的不人道决定（21.2%）。生成的基于科幻元素的宪法显著提高了模型对人类价值观的对齐程度（79.4%提升到95.8%），并且在对抗性提示设置下具有稳定性（23.3%提升到92.3%）。这些基于科幻元素的宪法还在ASIMOV基准测试中表现出色，该测试来源于实际图像和医院意外报告。因此，基于科幻元素的宪法不仅高度对齐人类价值观，而且在现实世界中也具有极高的适用性。"}
{"llm_update_time": "20250723", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2507.16577", "html_url": "https://arxiv.org/abs/2507.16577", "title": "基于稀疏状态扩展的线性注意力扩展", "title_en": "Scaling Linear Attention with Sparse State Expansion", "authors": "Yuqi Pan,Yongqi An,Zheng Li,Yuhong Chou,Ruijie Zhu,Xiaohui Wang,Mingxuan Wang,Jinqiao Wang,Guoqi Li", "background": "尽管Transformer架构在许多任务中表现出色，但在处理长上下文情景时存在计算复杂度和内存增长的问题。虽然一些线性注意力变体通过将上下文压缩成固定大小的状态来缓解效率制约，但在涉及上下文检索和推理的任务中，这通常会导致性能下降。因此，文章提出了一种新的解决方案。", "innovation": "文章提出了两个关键创新点：首先，通过将状态更新的概念化为信息分类，提出了一种行稀疏更新形式的线性注意力，利用基于softmax的top-$k$硬分类实现稀疏状态更新，从而扩展接受域并减少类间干扰；其次，提出了稀疏状态扩展(SSE)，在稀疏框架内将上下文状态划分为多个部分，有效地解耦参数大小与状态容量的关系，同时保持稀疏分类的范式。这些设计支持高效的并行实现，实现有效的分类与可区分的状态表示。", "conclusion": "文章在语言模型、上下文检索和数学推理等基准测试中广泛验证了SSE的有效性，并且在经过强化学习训练后，2B SSE-H 模型在小型推理模型中的数学推理性能达到了领先水平，显著优于类似规模的开源Transformer模型，得分分别为AIME24的64.7和AIME25的51.3，表明SSE是一种有潜力且高效的长上下文建模架构。"}
{"llm_update_time": "20250723", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2410.02760", "html_url": "https://arxiv.org/abs/2410.02760", "title": "从语言模型中擦除概念知识", "title_en": "Erasing Conceptual Knowledge from Language Models", "authors": "Rohit Gandikota,Sheridan Feucht,Samuel Marks,David Bau", "background": "现有研究表明，语言模型需要能够执行‘概念级遗忘’，即在保留模型整体性能的前提下，减少生成与特定概念相关的内容。目前缺乏有效的方法来实现这一点。", "innovation": "提出了Erasure of Language Memory（ELM）方法，这是一种通过匹配模型自我反省分类能力定义的分布来实现概念级遗忘的方法。ELM 使用语言模型自身作为分类器，识别并减少与不希望的概念相关的生成内容的机率，同时保留模型的更广泛能力。", "conclusion": "ELM 在生物安全、网络安全和文学领域的擦除任务中表现出色，修改后的模型在删除概念相关的评估中接近随机性能，同时保持生成的一致性，维持与无关任务的基准性能，并展现出强大的对抗攻击鲁棒性。"}
{"llm_update_time": "20250723", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2503.15879", "html_url": "https://arxiv.org/abs/2503.15879", "title": "Typed-RAG：非事实性问题类型感知分解以增强检索增强生成", "title_en": "Typed-RAG: Type-Aware Decomposition of Non-Factoid Questions for Retrieval-Augmented Generation", "authors": "DongGeon Lee,Ahjeong Park,Hyeri Lee,Hyeonseo Nam,Yunho Maeng", "background": "非事实性问题回答（NFQA）因其开放式特性、多样的用户意图和多方面的推理需求而具有挑战性。这些特性揭示了传统检索增强生成（RAG）方法的局限性。现有的RAG方法难以应对这些问题的复杂性，尤其是在处理多方面推理需求时显得力不从心。因此，需要一种新的框架来改进NFQA任务的表现。", "innovation": "本文提出的Typed-RAG框架旨在克服传统RAG方法在NFQA任务中的局限性。它通过先将非事实性问题（NFQ）分解为特定类型（如辩论、体验、比较），然后进一步分解为聚焦于单一方面的子查询，从而增强了检索的相关性和答案的质量。此外，研究人员还构建了一个名为Wiki-NFQA的基准数据集，进一步验证了Typed-RAG方法的有效性。实验结果表明，Typed-RAG在多个方面优于现有的基于LLM或RAG的问答方法，表明类型感知的分解对于改进检索质量和答案生成具有重要意义。", "conclusion": "本研究通过提出Typed-RAG框架，在RAG范式中有效解决了非事实性问题回答（NFQA）的挑战。通过类型感知的分解和子查询组合，该方法显著提升了检索相关性和答案质量。实验表明，Typed-RAG在多个性能指标上优于现有方法，证明了其在NFQA任务中的有效性。"}
{"llm_update_time": "20250723", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2410.13246", "html_url": "https://arxiv.org/abs/2410.13246", "title": "LLMs在长文本生成中的原子校准", "title_en": "Atomic Calibration of LLMs in Long-Form Generations", "authors": "Caiqi Zhang,Ruihan Yang,Zhisong Zhang,Xinting Huang,Sen Yang,Dong Yu,Nigel Collier", "background": "大型语言模型（LLMs）经常会经历幻觉现象，这对实际应用构成了重大挑战。现有研究主要集中在短文本任务上的信心校准，通常提供一个统的置信分数（宏校准）。但对于长文本生成任务，单一的置信评估方法不足以解决复杂声明中的准确性和不准确性问题。", "innovation": "该研究提出了原子校准（Atomic Calibration）的新方法，通过将长文本分解成基本声明（原子声明）来评估事实校准。研究还展示了区分性和生成性信心激发方法的结合能够提升校准效果。实验表明，原子校准不仅适用于长文本生成，还能改善宏校准结果，揭示了LLM信心生成过程中的有趣模式。", "conclusion": "研究结果表明，原子校准是一种适用于长文本生成的方法，能够提升模型信心的准确性，展示了一系列LLM信心的生成模式。"}
{"llm_update_time": "20250723", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2503.14023", "html_url": "https://arxiv.org/abs/2503.14023", "title": "使用大型语言模型生成合成数据：文本和代码领域的发展", "title_en": "Synthetic Data Generation Using Large Language Models: Advances in Text and Code", "authors": "Mihai Nadas,Laura Diosan,Andreea Tomescu", "background": "本综述论文回顾了大型语言模型（LLMs）如何通过在自然语言和代码领域生成合成训练数据的方式，改变合成训练数据的生成方法。这些模型通过生成与任务相关但并非实际存在的示例，可以显著增强或甚至替代真实世界的数据集，特别是在标记数据稀缺、昂贵或敏感的情况下。本文综述了利用LLMs生成合成文本和代码的最新进展，并强调了关键技术，如基于提示的生成、检索增强的流程以及迭代自我改进。这些方法如何丰富低资源任务（例如分类、问答）并促进代码为中心的应用（例如指令调优、代码翻译、错误修复），通过自动验证功能正确性。", "innovation": "本文综述了利用大型语言模型生成合成数据的最新进展，强调了关键技术和方法。探讨了如何通过这些方法丰富低资源任务和促进代码为中心的应用。此外，本文还提出了潜在的好处和伴随的挑战，包括过滤和加权合成输出以及代码领域中的执行反馈强化学习等缓解策略。", "conclusion": "本文总结了未来的研究方向，例如自动化提示工程、多模态数据合成以及稳健的评估框架。强调了生成的合成数据在加速人工智能发展的重要性，同时强调了要在伦理和质量保障方面采取措施。"}
{"llm_update_time": "20250723", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2505.00025", "html_url": "https://arxiv.org/abs/2505.00025", "title": "基于DeepSeek R1的医学垂直大语言模型架构方法", "title_en": "A Method for the Architecture of a Medical Vertical Large Language Model Based on Deepseek R1", "authors": "Mingda Zhang,Jianglong Qin", "background": "尽管基础模型如DeepSeek-R1和ChatGPT在许多领域取得了显著进展，但在医疗环境中的部署却面临重大挑战，包括计算资源需求和专业知识壁垒。已有研究在这些方面仍存在不足之处，需要进一步优化模型以适应特定的医疗应用场景。", "innovation": "该研究提出了一种高效的轻量级医疗大语言模型架构，通过三维优化（知识获取、模型压缩、计算增强）系统地解决了计算需求和专业知识壁垒的问题。研究采用了低秩适应（LoRA）从DeepSeek-R1-Distill-70B迁移到DeepSeek-R1-Distill-7B，通过4位量化和混合精度策略实现了显著的模型压缩和推理加速，同时保留了医学推理能力。", "conclusion": "实验结果表明，该方法在USMLE考试中的准确率为92.1%，相较于基线模型，内存消耗减少了64.7%，推理延迟减少了12.4%。本研究提供了一种在资源受限的医疗环境中部署高级语言模型的实用解决方案，旨在提高AI辅助医疗的普及性。"}
{"llm_update_time": "20250723", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2505.16104", "html_url": "https://arxiv.org/abs/2505.16104", "title": "Hierarchical Safety Realignment: Lightweight Restoration of Safety in Pruned Large Vision-Language Models", "title_en": "Hierarchical Safety Realignment: Lightweight Restoration of Safety in Pruned Large Vision-Language Models", "authors": "Yue Li,Xin Yi,Dongsheng Shi,Gerard de Melo,Xiaoling Wang,Linlin Wang", "background": "随着大型视觉-语言模型（LVLMs）规模的不断增大，针对资源受限环境进行模型部署的网络剪枝技术越来越受到重视。然而，剪枝通常会导致安全性能下降。针对这一问题，本文提出了一种名为Hierarchical Safety Realignment (HSR)的新型轻量级方法，通过首先量化每个注意力头对安全的贡献，识别最关键的注意力头，然后在这些注意力头中选择性地恢复起安全维护核心作用的神经元，从而实现剪枝后的LVLMs的安全性重新对齐，这一过程是从注意力头级别到神经元级别逐级进行的。", "innovation": "本文提出了名为Hierarchical Safety Realignment (HSR)的新颖轻量级方法。HSR首先量化每个注意力头对安全的贡献，识别最关键的注意力头，然后选择性地恢复这些头部中的神经元，逐级纠正剪枝后的LVLMs的安全性问题，实现安全性的重新对齐。这是首个专注于剪枝后的LVLMs安全性的恢复工作。", "conclusion": "本文在不同模型和剪枝策略下验证了HSR的有效性，一致取得了显著提高的安全性能。这项工作为剪枝后的大型视觉-语言模型恢复安全性提供了新的解决方案。"}
{"llm_update_time": "20250723", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2505.23060", "html_url": "https://arxiv.org/abs/2505.23060", "title": "使用小型语言模型进行自我纠正的代码生成", "title_en": "Self-Correcting Code Generation Using Small Language Models", "authors": "Jeonghun Cho,Deokhyung Kang,Hyounghun Kim,Gary Geunbae Lee", "background": "研究表明，自我纠正有能力通过逐步改进和自修订来提升代码生成质量。已有研究探讨了结合验证或反馈循环的提示策略以及利用推理能力强的小型模型进行训练的方法。然而，小型模型是否具备通过自我反思来有效引导自身输出的能力尚未得到验证。已有研究集中在较大模型上，小型模型在自我纠正方面的能力仍需进一步探索。", "innovation": "本文提出了CoCoS方法，旨在增强小型语言模型在多轮次代码修正中的能力。CoCoS采用了在线强化学习目标训练模型，使其能够自信地保持正确输出，并随着每轮次提升对错误输出进行修正。CoCoS使用累积奖励函数和更细粒度的奖励机制，以适应多轮次修正场景，旨在提高初始响应质量并通过自我纠正获得显著改进。在1B规模的模型上，CoCoS在MBPP上实现了35.8%的改进，在HumanEval上实现了27.7%的改进，相对于基线模型而言.", "conclusion": "我们发现，小型模型难以在自我纠正过程中表现出反思修订的行为。针对这一问题，我们提出了CoCoS方法，通过在线强化学习来提高小型语言模型在多轮次代码修正中的表现，验证了其在提升初始响应质量及自我纠正方面的有效性。"}
{"llm_update_time": "20250723", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2504.17665", "html_url": "https://arxiv.org/abs/2504.17665", "title": "评估代码辅助大型语言模型在数学中的中间推理", "title_en": "Evaluating Intermediate Reasoning of Code-Assisted Large Language Models for Mathematics", "authors": "Zena Al-Khalili,Nick Howell,Dietrich Klakow", "background": "代码辅助的大量语言模型（LLMs）在数学推理任务上的表现有所提升，但现有的评估主要集中在执行的正确性上，缺乏对生成程序的严谨评估。现有研究通常仅关注程序执行是否正确，没有深入分析其背后的推理过程是否合理。", "innovation": "本文通过深入分析代码辅助的LLMs在应对数学推理任务时生成程序的过程，尤其是评估背后的推理逻辑是否合理，填补了该领域的空白。评估了五种不同的LLMs在多个数学数据集上的生成结果，并提出了基于逻辑合理性的程序生成分类法。研究结果显示，模型的能力显著影响了解决问题时采用的逻辑。闭源模型更为依赖于数学概念的逻辑支撑，而开源模型往往依赖于记忆和穷尽搜索的不完全逻辑。同时，题目的难度增加导致了生成结果中逻辑正确的程度下降，揭示了LLMs在解决复杂数学问题时的一个关键弱点。", "conclusion": "本文强调了评估代码辅助的LLMs需要超越执行准确性的度量标准，以更全面地理解其在数学领域中的局限性。"}
{"llm_update_time": "20250723", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2505.23714", "html_url": "https://arxiv.org/abs/2505.23714", "title": "SenWiCh: 使用混合方法为低资源语言的WiC进行 Sense-Annotation", "title_en": "SenWiCh: Sense-Annotation of Low-Resource Languages for WiC using Hybrid Methods", "authors": "Roksana Goworek,Harpal Karlcut,Muhammad Shezad,Nijaguna Darshana,Abhishek Mane,Syam Bondada,Raghav Sikka,Ulvi Mammadov,Rauf Allahverdiyev,Sriram Purighella,Paridhi Gupta,Muhinyia Ndegwa,Haim Dubossarsky", "background": "当前，低资源语言缺乏高质量的评估数据集，这对于推动跨语言迁移极为重要。跨语言迁移利用多语言预训练模型扩展语言技术到研究不足和类型多样的语言，但其有效性依赖于高质量和合适的基准。低资源语言中的多义词语义消歧是跨语言迁移研究中的关键问题之一，现有的数据集和方法在评估和应用中存在不足。因此，需要新的数据集和标注方法来支持低资源语言的研究。", "innovation": "论文引入了新的多义词标注数据集，覆盖十种低资源语言，涵盖多样化的语言家族和书写系统。同时，论文提供了有效的半自动标注方法来促进数据集的创建。通过WiC格式的实验，展示了新数据集在这些低资源语言中的有效性，并强调了针对性的数据集创建和评估在低资源环境和迁移研究中的重要性。", "conclusion": "论文发布的数据集和代码旨在支持更公正、稳健和真正的多语言NLP研究，促进有效的人工智能技术应用于低资源语言。"}
{"llm_update_time": "20250723", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2505.23822", "html_url": "https://arxiv.org/abs/2505.23822", "title": "言语作为一种多模态数字表型以支持多任务LLM心理健康预测", "title_en": "Speech as a Multimodal Digital Phenotype for Multi-Task LLM-based Mental Health Prediction", "authors": "Mai Ali,Christopher Lucasius,Tanmay P. Patel,Madison Aitken,Jacob Vorstman,Peter Szatmari,Marco Battaglia,Deepa Kundur", "background": "言语是一种无创的数字表型，能够提供有关心理健康状况的重要见解，但通常其被视为单一模态的数据源。本研究挑战了这一观点，将其作为一种三模态多媒体数据源，用于抑郁症的检测。研究探索了基于大型语言模型的架构在结合言语衍生文本、声学特征和语音生物标记的心理健康预测上的潜力。青少年抑郁症被视为一个重要挑战，并且经常与其他疾病（如自杀念头和睡眠障碍）共病。这项研究提出了使用多任务学习（MTL）同时预测抑郁症、自杀念头和睡眠障碍的方法，并采用纵向分析策略以捕捉临床互动中的时间变化，从而提供条件进展的全面理解。", "innovation": "本研究将语音数据视为三模态多媒体数据源，利用大型语言模型架构进行抑郁症预测，采用了多任务学习和纵向分析，这是一种新的研究方法。通过这种方法，研究同时探索了情绪、声学特征和言语生物标记在心理健康预测中的潜力，进一步提高了预测的准确性。", "conclusion": "本研究在抑郁症早期预警数据集上评估了提议的方法，该方法实现了平衡的准确率为70.8%，超过了单一模态、单任务且非纵向的方法。"}
{"llm_update_time": "20250723", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2507.05724", "html_url": "https://arxiv.org/abs/2507.05724", "title": "全路由：在稀疏混合专家中共享路由决策以进行语音识别", "title_en": "Omni-Router: Sharing Routing Decisions in Sparse Mixture-of-Experts for Speech Recognition", "authors": "Zijin Gu,Tatiana Likhomanenko,Navdeep Jaitly", "background": "混合专家（MoE）架构最初应用于语言建模，现在已经扩展到了自动语音识别（ASR）。传统的MoE方法，如Switch Transformer，在每一层中独立路由专家。然而，大多数层的路由器做出的选择与其他层路由器的选择不强相关。因此，为了增加不同层专家之间的合作并促进他们更为专业化，本文提出了一种在不同MoE层中使用共用路由器的新方法。", "innovation": "提出了一种新型MoE架构——Omni-router Transformer，通过在不同MoE层间使用共享路由器来增强专家间的合作，从而增强其专业化能力。实验结果表明，Omni-router Transformer在大规模伪标签数据集上的训练损失更低，在10个不同领域的ASR基准测试中也表现出显著性能，在平均单词错误率方面分别优于密集模型和Switch Transformer模型11.2%和8.2%，同时提供了有序的专家使用和对多样数据集的鲁棒性增强。", "conclusion": "Omni-router Transformer通过共用路由器的方法提高了不同层专家间的合作与专业化，证明了其在大规模和跨领域的ASR任务上的有效性，继承了结构化的专家使用并增强了模型对多样化数据集的鲁棒性。"}
{"llm_update_time": "20250723", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2507.06229", "html_url": "https://arxiv.org/abs/2507.06229", "title": "Agent KB: 利用跨域经验进行智能问题解决", "title_en": "Agent KB: Leveraging Cross-Domain Experience for Agentic Problem Solving", "authors": "Xiangru Tang,Tianrui Qin,Tianhao Peng,Ziyang Zhou,Daniel Shao,Tingting Du,Xinming Wei,Peng Xia,Fang Wu,He Zhu,Ge Zhang,Jiaheng Liu,Xingyao Wang,Sirui Hong,Chenglin Wu,Hao Cheng,Chi Wang,Wangchunshu Zhou", "background": "当前的人工智能代理无法有效从彼此的问题解决经验中学习，或者利用过去的成功来引导自我反思和错误纠正。这限制了它们在新任务上的表现和适应能力。", "innovation": "提出了Agent KB，这是一种共享知识库，能够捕捉到高层次的问题解决策略和详细的执行教训，从而实现代理框架之间的知识迁移。Agent KB采用了一种新颖的教师-学生两阶段检索机制，学生代理检索工作流程级模式以获取战略指导，而教师代理识别执行级模式以进行优化。这种分层方法使代理能够通过结合外部来源的多种策略来跳出有限的推理路径。", "conclusion": "在GAIA基准测试上的评估显示，Agent KB带来了显著的性能提升，整体下在pass@1上的成功率提高了6.06个百分点。对于SWE-bench代码修复任务，我们的系统显著提高了解决方案率，o3-mini在pass@1方面的成功率提高了8.67个百分点（从23%提高到31.67%）。消融试验表明，优化模块最为关键，其缺失在挑战性的Level 3任务上导致了3.85%的性能下降，强调有效的知识迁移需要战略性指导和执行级优化的双重作用。"}
{"llm_update_time": "20250723", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2505.02304", "html_url": "https://arxiv.org/abs/2505.02304", "title": "使用多正增强对比学习生成手语描述提示的中文和土耳其手语识别", "title_en": "Generative Sign-description Prompts with Multi-positive Contrastive Learning for Sign Language Recognition", "authors": "Siyu Liang,Yunan Li,Wentian Xin,Huizhou Chen,Xujie Liu,Kang Liu,Qiguang Miao", "background": "手语识别（SLR）面临着因同时处理复杂的手动和非手动信号而创造准确注解的基本挑战。到目前为止，这还是首次将生成式大语言模型（LLMs）整合到SLR任务中。", "innovation": "提出了一种新颖的生成手语描述提示多正增强对比学习（GSP-MC）方法，该方法利用针对特定领域的LLMs的检索增强生成（RAG），结合多步骤提示工程和专家验证的手语语料库，生成精确的多部分描述。GSP-MC方法使用双编码器架构，通过概率匹配双向对齐分层骨架特征和多种文本描述（全球、同义词和部分级别），优化KL散度以确保所有相关文本-骨架对的稳健对齐，同时捕捉手语层次的语义和详细的部分动态。", "conclusion": "实验表明，该方法在中文SLR500数据集上（达到97.1%准确率）和土耳其AUTSL数据集上（97.07%准确率）超过了现有方法。该方法的跨语言效果突显了其开发包容性沟通技术的潜力。"}
{"llm_update_time": "20250723", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2506.06821", "html_url": "https://arxiv.org/abs/2506.06821", "title": "大型语言模型能否生成可靠的测试用例生成器？——基于竞赛级编程问题的研究", "title_en": "Can LLMs Generate Reliable Test Case Generators? A Study on Competition-Level Programming Problems", "authors": "Yuhan Cao,Zian Chen,Kun Quan,Ziliang Zhang,Yu Wang,Xiaoning Dong,Yeqi Feng,Guanzhong He,Jingcheng Huang,Jianhao Li,Yixuan Tan,Jiafu Tang,Yilin Tang,Junlei Wu,Qianyu Xiao,Can Zheng,Shouchen Zhou,Yuxiang Zhu,Yiming Huang,Tian Xie,Tianxing He", "background": "大型语言模型（LLMs）在代码生成方面展示了显著的能力，能够处理复杂的推理任务。然而，这些模型在代码检查或调试方面的潜在用途，尤其是在生成测试用例方面，仍然没有得到充分探索。本文着眼于竞赛级编程（CP）问题，提出了一套基准测试题，以系统性地研究LLMs在生成测试用例生成器方面的表现。这项研究采用了两个任务来考察LLMs的能力：一是在给定的CP问题上生成有效的测试用例生成器；二是生成针对人类编写代码中的错误的测试用例生成器。实验结果显示，最先进的LLMs大多数情况下能够生成有效的测试用例生成器，但在生成能够揭示人类代码缺陷的针对性测试用例方面表现不佳。即使是较为先进的推理模型，在生成有针对性的测试用例生成器方面的表现也远不及人类。此外，研究团队构建了一个高质量的人工筛选的数据集，以生成有针对性的测试用例生成器，以此增强LLMs的表现。通过提供数据提示和微调，这些数据集能够显著提升LLMs的性能。", "innovation": "本文提出了一个新的基准测试（TCGBench），专门用于测试大型语言模型在生成测试用例生成器方面的潜力。基准测试包括两个任务：生成有效的测试用例生成器以及生成针对性的测试用例生成器，后者可揭示人类编写代码中的缺陷。此外，研究团队还构建了一个高质量的人工筛选的数据集，可以用于通过输入提示和微调来增强LLMs的性能，从而改善它们在生成有针对性的测试用例生成器方面的表现。", "conclusion": "目前，最先进的大型语言模型在生成有效的测试用例生成器方面表现良好，但生成具有针对性的测试用例生成器揭示人类错误的能力仍有待提高。借助高质量的数据集，通过输入提示和微调可以显著提升LLMs在生成针对性测试用例生成器方面的表现。未来，将此数据集以及相关研究方法用于更多实际应用中很有潜力进一步改进大型语言模型在代码检查和调试中的能力。"}
{"llm_update_time": "20250723", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2507.06261", "html_url": "https://arxiv.org/abs/2507.06261", "title": "Gemini 2.5: Pushing the Frontier with Advanced Reasoning, Multimodality, Long Context, and Next Generation Agentic Capabilities", "title_en": "Gemini 2.5: Pushing the Frontier with Advanced Reasoning, Multimodality, Long Context, and Next Generation Agentic Capabilities", "authors": "Gheorghe Comanici,Eric Bieber,Mike Schaekermann,Ice Pasupat,Noveen Sachdeva,Inderjit Dhillon,Marcel Blistein,Ori Ram,Dan Zhang,Evan Rosen,Luke Marris,Sam Petulla,Colin Gaffney,Asaf Aharoni,Nathan Lintz,Tiago Cardal Pais,Henrik Jacobsson,Idan Szpektor,Nan-Jiang Jiang,Krishna Haridasan,Ahmed Omran,Nikunj Saunshi,Dara Bahri,Gaurav Mishra,Eric Chu,Toby Boyd,Brad Hekman,Aaron Parisi,Chaoyi Zhang,Kornraphop Kawintiranon,Tania Bedrax-Weiss,Oliver Wang,Ya Xu,Ollie Purkiss,Uri Mendlovic,Ilaï Deutel,Nam Nguyen,Adam Langley,Flip Korn,Lucia Rossazza,Alexandre Ramé,Sagar Waghmare,Helen Miller,Nathan Byrd,Ashrith Sheshan,Raia Hadsell Sangnie Bhardwaj,Pawel Janus,Tero Rissa,Dan Horgan,Sharon Silver,Ayzaan Wahid,Sergey Brin,Yves Raimond,Klemen Kloboves,Cindy Wang,Nitesh Bharadwaj Gundavarapu,Ilia Shumailov,Bo Wang,Mantas Pajarskas,Joe Heyward,Martin Nikoltchev,Maciej Kula,Hao Zhou,Zachary Garrett,Sushant Kafle,Sercan Arik,Ankita Goel,Mingyao Yang,Jiho Park,Koji Kojima,Parsa Mahmoudieh,Koray Kavukcuoglu,Grace Chen,Doug Fritz,Anton Bulyenov,Sudeshna Roy,Dimitris Paparas,Hadar Shemtov,Bo-Juen Chen,Robin Strudel,David Reitter,Aurko Roy,Andrey Vlasov,Changwan Ryu,Chas Leichner,Haichuan Yang,Zelda Mariet,Denis Vnukov,Tim Sohn,Amy Stuart,Wei Liang,Minmin Chen,Praynaa Rawlani,Christy Koh,JD Co-Reyes,Guangda Lai,Praseem Banzal,Dimitrios Vytiniotis,Jieru Mei,Mu Cai", "background": "介绍了Gemini 2.X模型系列，包括Gemini 2.5 Pro，Gemini 2.5 Flash，以及之前的Gemini 2.0 Flash和Flash-Lite模型。Gemini 2.5 Pro是目前为止最强大的模型，达到了前沿编码和推理基准的最优性能。Gemini 2.5 Flash提供了出色的推理能力，同时降低了计算需求和延迟。Gemini 2.0 Flash和Flash-Lite则在低延迟和成本下提供了高性能。", "innovation": "Gemini 2.5 Pro在编码和推理能力方面达到了最优性能，并且在多模态理解和长语境处理方面表现出色，能够处理长达3小时的视频内容。Gemini 2.5 Flash在低计算需求和延迟下提供了优秀的推理能力。Gemini 2.0 Flash和Flash-Lite则在低延迟和成本下提供了高性能。整体而言，Gemini 2.X模型系列涵盖了模型性能和成本之间的帕累托前沿，为复杂的代理型问题解决提供了能力边界探索的可能性。", "conclusion": "Gemini 2.X模型家族覆盖了模型能力和成本之间的全面前沿，用户可以探索复杂代理型问题解决的可能性边界。"}
{"llm_update_time": "20250723", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2502.18699", "html_url": "https://arxiv.org/abs/2502.18699", "title": "MPO：一种高效的混合多样偏好后处理框架", "title_en": "MPO: An Efficient Post-Processing Framework for Mixing Diverse Preference Alignment", "authors": "Tianze Wang,Dongnan Gui,Yifan Hu,Shuhang Lin,Linjun Zhang", "background": "强化学习从人类反馈中（RLHF）在对齐大型语言模型（LLMs）方面显示出前景，但往往依赖单一的奖励模型，忽略了人类偏好多样性的细节。近期方法通过使用多维度反馈来微调对应的奖励模型并使用强化学习训练LLMs，但由于人类偏好的竞争性和异质性，这一过程成本高昂且不稳定。因此，迫切需要一种避免从零开始对齐的新方法。", "innovation": "本文提出了一种后处理框架--混合偏好优化（MPO），作为多目标RLHF（MORLHF）和MaxMin-RLHF的替代方案。MPO通过线性组合现有的单一目标策略，以每个策略的权重通过批量随机镜像梯度计算，实现单一目标策略的聚合，从而避免从零开始对齐，降低成本，并在多样偏好中实现均衡的表现。", "conclusion": "实验结果表明，MPO在多样偏好中实现了均衡表现，相比现有模型，具有显著降低的计算成本。"}
{"llm_update_time": "20250723", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2505.14311", "html_url": "https://arxiv.org/abs/2505.14311", "title": "HausaNLP: 当前状态、挑战和未来方向的豪萨自然语言处理", "title_en": "HausaNLP: Current Status, Challenges and Future Directions for Hausa Natural Language Processing", "authors": "Shamsuddeen Hassan Muhammad,Ibrahim Said Ahmad,Idris Abdulmumin,Falalu Ibrahim Lawan,Babangida Sani,Sukairaj Hafiz Imam,Yusuf Aliyu,Sani Abdullahi Sani,Ali Usman Umar,Tajuddeen Gwadabe,Kenneth Church,Vukosi Marivate", "background": "豪萨自然语言处理（NLP）近年来引起了越来越多的关注，但它仍然作为少资源语言而受到了忽视，尽管它拥有超过1.2亿第一语言（L1）和8000万第二语言（L2）的使用者。尽管在高资源语言方面取得了显著的进步，豪萨NLP仍面临着持续的挑战，包括有限的开源数据集和不足的模型表示。", "innovation": "本论文提出了一个名为HausaNLP的综述性概述，系统地审视了现有的资源、研究贡献和在基础NLP任务（文本分类、机器翻译、命名实体识别、语音识别、问答）中的空白。它还讨论了将豪萨语整合到大型语言模型中的挑战，包括次优分词和方言变化等问题，并提出了数据集扩展、改善语言建模方法和加强社区合作等战略研究方向。", "conclusion": "本研究为提高豪萨NLP的进步奠定了基础，并为更广泛的多语言NLP研究提供了宝贵的见解。"}
{"llm_update_time": "20250723", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2506.12091", "html_url": "https://arxiv.org/abs/2506.12091", "title": "使用大型语言模型实现持续更新的数字孪生", "title_en": "Continuously Updating Digital Twins using Large Language Models", "authors": "Harry Amad,Nicolás Astorga,Mihaela van der Schaar", "background": "数字孪生是用于模拟现实系统动态的模型，但在复杂环境中，系统状态和行动变量、可用的数据和知识会不断变化，因此数字孪生需要不断更新以保持相关性。现有的方法在这方面存在困难，因为它们需要固定且清晰定义的建模环境，无法适应新的变量，也不能在没有重新设计或重新训练的情况下整合新信息。", "innovation": "本文将数字孪生问题置于上下文学习的框架下，使用大型语言模型实现无缝更新。开发了基于上下文自适应语言模型（CALM-DT）的数字孪生，通过利用微调的编码器进行样本检索，能够在不调整参数的情况下适应其建模环境的变化，从而准确地模拟不同的状态-行动空间。", "conclusion": "实验证明了CALM-DT在各项指标上与现有的数字孪生方法具有竞争力，并且有着独特的适应性能力，能够在不调整参数的情况下适应其建模环境的变化。"}
{"llm_update_time": "20250723", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2507.11936", "html_url": "https://arxiv.org/abs/2507.11936", "title": "A Survey of Deep Learning for Geometry Problem Solving", "title_en": "A Survey of Deep Learning for Geometry Problem Solving", "authors": "Jianzhe Ma,Wenxuan Wang,Qin Jin", "background": "几何问题是数学推理的关键领域，广泛应用于教育、人工智能数学能力评估以及多模态能力评估等多个重要领域。近年来，深度学习技术的快速发展，尤其是多模态大语言模型的崛起，引发了该领域的研究热潮。本文对深度学习在几何问题解决中的应用进行了综述，包括相关任务的全面总结、深度学习方法的详细审查、评估指标和方法的深入分析，以及当前挑战和未来发展方向的批判性讨论。", "innovation": "本文提供了深度学习在几何问题解决方面的全面综述，总结了相关任务、深度学习方法、评估指标和方法，并深入分析了当前面临的挑战和未来的研究方向，旨在提供一个全面和实用的参考，促进该领域的进一步发展。此外，还创建了一个持续更新的论文列表，使其能够更好地服务于研究者。", "conclusion": "本文为深度学习在几何问题解决领域的研究提供了全面和实用的参考，探讨了当前的研究挑战和未来的研究方向。创建的GitHub链接将不断更新相关的研究论文。"}
{"llm_update_time": "20250723", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2507.14096", "html_url": "https://arxiv.org/abs/2507.14096", "title": "TREC平生物医药摘要（PLABA）轨道的教训", "title_en": "Lessons from the TREC Plain Language Adaptation of Biomedical Abstracts (PLABA) track", "authors": "Brian Ondov,William Xia,Kush Attal,Ishita Unde,Jerry He,Dina Demner-Fushman", "background": "近年来，语言模型在适应面向专业人士的医疗文献方面展示了潜力，使其对患者和护理人员更易于理解。然而，这些模型的不可预测性以及在医疗领域的高潜在风险意味着需要进行严格的评估。我们的目标是促进该领域的研究，并为最有可能成功的系统提供高质量的评估。", "innovation": "举办了2023年和2024年的文本检索会议上的平生物医药摘要（PLABA）轨道，包含完整的基于句子的摘要重写任务（任务1）以及识别和替换难以理解的术语的任务（任务2）。为自动评估任务1开发了四份专业撰写的参考标准，并进行广泛的生物医学专家手工评价。", "conclusion": "PLABA轨道展示了大型语言模型将生物医药文献适应于普通公众的潜力，同时也指出了它们的缺陷，并强调了需要改进自动化基准工具的需求。"}
{"llm_update_time": "20250723", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2507.09205", "html_url": "https://arxiv.org/abs/2507.09205", "title": "Banzhida：使用精心策划的数据和持续预训练促进藏语大型语言模型的发展", "title_en": "Banzhida: Advancing Large Language Models for Tibetan with Curated Data and Continual Pre-Training", "authors": "Leiyu Pan,Bojian Xiong,Lei Yang,Renren Jin,Shaowei Zhang,Yue Chen,Ling Shi,Jiang Zhou,Junru Wu,Zhen Wang,Jianxiang Peng,Juesi Xiao,Tianyu Dong,Zhuowen Han,Zhuo Chen,Sangjee Dondrub,Caizang Tai,Haixing Zhao,Huaque Cairang,Suonan Cairang,Rou Te,Lengben Zhaxi,Gazang Zhaxi,Zhonglin Ye,Yuhui Zheng,Chunyan Peng,Secha Jia,Pema Tashi,Cizhen Jiacuo,Pema Dorjee,Hongkai Liu,Pema Yanggon,Tsehang Dorjee,Jiaxin Han,Qiongying Hu,Jilin Man,Huanke You,Yuqi Ren,Duo La,Deyi Xiong", "background": "大型语言模型在许多语言中取得了显著进展，但在低资源语言藏语方面，由于高质量训练语料库稀缺，代表性不足。", "innovation": "创建了迄今为止最大的藏语预训练语料库，涵盖了多源数据并专门设计了数据清洗和处理管道以适应藏语。使用策划的数据，继续对多语言基础模型进行预训练/微调，生成了 Banzhida 多语言大型语言模型，用于藏语的生成式人工智能。", "conclusion": "实验结果表明，Banzhida 在多种任务上都比开源模型（相似规模）和特定藏语模型优异得多，展现了其强大的藏语处理能力。"}
{"llm_update_time": "20250723", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2507.13618", "html_url": "https://arxiv.org/abs/2507.13618", "title": "Seed-X: 使用7B参数构建强健的多语言翻译大型语言模型", "title_en": "Seed-X: Building Strong Multilingual Translation LLM with 7B Parameters", "authors": "Shanbo Cheng,Yu Bao,Qian Cao,Luyang Huang,Liyan Kang,Zhicheng Liu,Yu Lu,Wenhao Zhu,Jingwen Chen,Zhichao Huang,Tao Li,Yifu Li,Huiying Lin,Sitong Liu,Ningxin Peng,Shuaijie She,Lu Xu,Nuo Xu,Sen Yang,Runsheng Yu,Yiming Yu,Liehao Zou,Hang Li,Lu Lu,Yuxuan Wang,Yonghui Wu", "background": "多语言翻译对于大型语言模型（LLMs）是一个具有挑战性的任务，因为它们需要处理自动化翻译中出现的复杂语言模式和滞涩的翻译问题。本研究介绍了一个名为Seed-X的开源LLM家族，包含指令模型和推理模型，在7B参数规模下推动了翻译能力的边界。Seed-X基模型在涵盖28种语言的多样且高质量的数据集上进行预训练，利用了多语言数据的全部潜力。在经过Chain-of-Thought推理和强化学习（RL）的微调后，模型能够更通用地处理各种语言对的翻译任务。Seed-X在28种语言上达到了与闭源模型Gemini-2.5和GPT-4o相当或更好的性能，并在自动指标和人类评估中显著优于较大的开源模型。", "innovation": "引入了一个名为Seed-X的多语言翻译大型语言模型家族，该模型包含指令模型和推理模型，具备7B参数规模。它在28种语言上进行预训练，通过Chain-of-Thought推理和强化学习进行微调，从而实现更好的跨语言通用性。Seed-X在性能上达到了与领导的封闭源模型相当或更优的水平，并显著优于较大的开源模型。进一步分享了优化过程中的最佳实践，并开放了参数供研究和应用使用。", "conclusion": "Seed-X在28种语言上实现了与领先的封闭源模型Gemini-2.5和GPT-4o相当或更好的性能，并通过自动指标和人类评估展示了与更大开源模型相比的显著优势。通过开放模型参数与优化过程，推动了翻译研究和应用的发展。"}
{"llm_update_time": "20250723", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2507.14241", "html_url": "https://arxiv.org/abs/2507.14241", "title": "Promptomatix：一种用于大型语言模型的自动提示优化框架", "title_en": "Promptomatix: An Automatic Prompt Optimization Framework for Large Language Models", "authors": "Rithesh Murthy,Ming Zhu,Liangwei Yang,Jielin Qiu,Juntao Tan,Shelby Heinecke,Caiming Xiong,Silvio Savarese,Huan Wang", "background": "大型语言模型（LLMs）在精心设计的提示下表现最佳，但提示工程技术仍然是手动的、不一致的，并且对非专家来说是不透明的。现有的提示工程技术依赖于人工调整和领域专业知识，这使得它们复杂且难以使用。", "innovation": "本文引入了Promptomatix，一种自动提示优化框架，它能够将自然语言的任务描述转换为高质量的提示，无需手动调整或领域专业知识。Promptomatix支持轻量级的元提示优化器和基于DSPy的编译器，具有模块化设计，可以未来扩展至更高级的框架。该系统分析用户意图、生成合成训练数据、选择提示策略并使用成本意识目标优化提示。在五个任务类别上的评估结果显示，与现有库相比，Promptomatix在性能上具有竞争力或更优，同时缩短了提示长度并减少了计算开销，使提示优化变得可扩展和高效。", "conclusion": "Promptomatix 提供了一种新的方法，通过自动优化提示来提升大型语言模型的性能，同时降低了计算成本和提示长度，使得非专家也能轻松使用，为提示工程技术的发展开辟了新路径。"}
{"llm_update_time": "20250723", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2505.22116", "html_url": "https://arxiv.org/abs/2505.22116", "title": "由语言模型支持的稀疏术中低血压事件的多模态预测", "title_en": "Multimodal Forecasting of Sparse Intraoperative Hypotension Events Powered by Language Model", "authors": "Jintao Zhang,Zirui Liu,Mingyue Cheng,Shilong Zhang,Tingyue Pan,Yitong zhou,Qi Liu,Yanhu Xie", "background": "术中低血压（IOH）在全身麻醉中常见，并与不良结果如心肌损伤和死亡率增加密切相关。尽管其重要性，IOH预测受到事件稀疏性的阻碍，并且集成跨不同患者固定和动态数据的挑战。", "innovation": "提出了IOHFuseLM多模态语言模型框架。采用两阶段训练策略，首先通过扩散方法增强IOH生理时间序列预训练领域适应性，使模型对低血压相关模式更敏感；其次在原始临床数据集上进行任务微调，以增强区分正常血压和低血压状态的能力。通过时间序列和结构化临床描述在标记级别上的对齐，使模型能够捕捉到个体化的时序模式及其相应的临床语义。此外，将静态患者属性转换为结构化文本，丰富个性化信息。", "conclusion": "在两个术中数据集上的实验评估表明，IOHFuseLM在准确识别IOH事件方面优于现有基线，突显了其在临床决策支持场景中的适用性。源代码已公开以促进可重复性，链接为：this https URL"}
{"llm_update_time": "20250723", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2402.04247", "html_url": "https://arxiv.org/abs/2402.04247", "title": "AI科学家的风险：优先保障安全而非自主性", "title_en": "Risks of AI Scientists: Prioritizing Safeguarding Over Autonomy", "authors": "Xiangru Tang,Qiao Jin,Kunlun Zhu,Tongxin Yuan,Yichi Zhang,Wangchunshu Zhou,Meng Qu,Yilun Zhao,Jian Tang,Zhuosheng Zhang,Arman Cohan,Zhiyong Lu,Mark Gerstein", "background": "AI科学家借助大型语言模型展示了在自主开展实验和促进跨学科科学发现方面的巨大潜力。然而，这些能力也带来了新型的安全漏洞，需要谨慎考虑。目前，对这些漏洞的研究还较为有限。", "innovation": "本文提出了一种三元框架，包括人类监管、代理对齐和环境反馈的认识（代理监管），以减轻识别的风险。同时，强调了保障AI科学家的局限性和挑战，并呼吁开发更佳的模型、稳健的基准和全面的法规。", "conclusion": "本文综述了AI科学家内在的风险和潜在风险，倡导从人机协同、代理对齐和外部环境反馈等方面采取措施保障AI科学家的安全，同时指出现有技术和政策存在的局限，并提出了未来研究的方向。"}
{"llm_update_time": "20250723", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2507.14430", "html_url": "https://arxiv.org/abs/2507.14430", "title": "X-Intelligence 3.0：为半导体显示行业训练和评估推理大语言模型", "title_en": "X-Intelligence 3.0: Training and Evaluating Reasoning LLM for Semiconductor Display", "authors": "Xiaolin Yan,Yangxing Liu,Jiazhang Zheng,Chi Liu,Mingyu Du,Caisheng Chen,Haoyang Liu,Ming Ding,Yuan Li,Qiuping Liao,Linfeng Li,Zhili Mei,Siyu Wan,Li Li,Ruyi Zhong,Jiangling Yu,Xule Liu,Huihui Hu,Jiameng Yue,Ruohui Cheng,Qi Yang,Liangqing Wu,Ke Zhu,Chi Zhang,Chufei Jing,Yifan Zhou,Yan Liang,Dongdong Li,Zhaohui Wang,Bin Zhao,Mingzhou Wu,Mingzhong Zhou,Peng Du,Zuomin Liao,Chao Dai,Pengfei Liang,Xiaoguang Zhu,Yu Zhang,Yu Gu,Kun Pan,Yuan Wu,Yanqing Guan,Shaojing Wu,Zikang Feng,Xianze Ma,Peishan Cheng,Wenjuan Jiang,Jing Ba,Huihao Yu,Zeping Hu,Yuan Xu,Zhiwei Liu,He Wang,Zhenguo Lin,Ming Liu,Yanhong Meng", "background": "大语言模型（LLMs）在推理方面取得了重大进展，并展示了在解决复杂问题方面的优势。然而，这些模型在半导体显示行业内依然效果有限，原因在于缺乏特定领域的训练和专业知识。X-Intelligence 3.0 是首个专门为半导体显示行业设计的高性能推理模型，旨在为该行业的复杂挑战提供专家级的理解和推理能力。通过精心挑选的行业知识库，该模型经过监督微调和强化学习，提升了其推理和理解能力。此外，还实现了自动化评估框架以模拟专家级评估，并集成了特定领域的检索增强生成（RAG）机制，从而在基准数据集上取得显著的性能提升。尽管参数量仅有320亿，X-Intelligence 3.0 在多个评估中表现优于目前最先进的DeepSeek-R1-671B，表明其高效性，为半导体显示行业的长期推理难题提供了强大的解决方案。", "innovation": "本研究创新之处在于，首次针对半导体显示行业开发了一个高性能的推理模型——X-Intelligence 3.0。该模型通过精心挑选的行业知识库进行监督微调和强化学习，提升了其推理和理解能力。同时引入自动化评估框架和特定领域的检索增强生成机制，显著提升了性能。结合其相对较小的参数量，该模型在多个评估中表现优于目前最先进的模型，展示了其高效性，是解决半导体显示行业推理难题的一种强有力的方法。", "conclusion": "X-Intelligence 3.0 是一个专门为半导体显示行业优化的高性能推理模型，通过密集的研究和优化，展现出卓越的高效性和强大的推理能力，为该行业面临的长期难题提供有效解决方案。"}
{"llm_update_time": "20250723", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2506.02951", "html_url": "https://arxiv.org/abs/2506.02951", "title": "自适应图修剪用于多智能体通信", "title_en": "Adaptive Graph Pruning for Multi-Agent Communication", "authors": "Boyi Li,Zhonghan Zhao,Der-Horng Lee,Gaoang Wang", "background": "基于大型语言模型（LLM）的多智能体系统在各种任务中表现出色，尤其是在通过协作通信增强时。然而，当前方法通常依赖于固定的智能体数量和静态的通信结构，限制了其适应任务复杂度变化的能力。", "innovation": "本文提出了一种新颖的任务自适应多智能体协作框架——自适应图修剪（AGP），该框架同时优化智能体数量（硬修剪）和通信拓扑（软修剪）。具体地，该方法采用两阶段训练策略：首先独立训练不同智能体数量下的软修剪网络，以确定特定任务下的最优完整图和位置掩码；接着在最大完整图内联合优化硬修剪和软修剪，以动态配置每个任务中的智能体数量及其通信拓扑。", "conclusion": "大量实验表明：（1）本方法高性能，六个基准测试中达到最先进的结果，且在多个主流LLM架构间具有良好的泛化能力，性能提升2.58%～9.84%；（2）任务自适应，能动态构建针对特定任务优化的通信拓扑，三个任务类别（逻辑推理、数学推理、代码生成）的表现极佳；（3）节省令牌，具有更少的训练步骤和令牌消耗，减少90%以上的令牌消耗；（4）训练高效，相较其他方法用非常少的训练步骤即可达到高表现；六基准测试下约训练十步后超过现有基线。"}
{"llm_update_time": "20250723", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2505.19956", "html_url": "https://arxiv.org/abs/2505.19956", "title": "DCG-SQL: 使用深度上下文模式链接图增强 Text-to-SQL 的上下文学习", "title_en": "DCG-SQL: Enhancing In-Context Learning for Text-to-SQL with Deep Contextual Schema Link Graph", "authors": "Jihyung Lee,Jin-Seop Lee,Jaehoon Lee,YunSeok Choi,Jee-Hyong Lee", "background": "Text-to-SQL任务通过自然语言问题转化为SQL查询已经取得了很大进展，但现有的方法在使用大型语言模型（LLMs）时表现提升不大，尤其是小型LLMs（如Llama 3.1-8B）的表现下降明显。这表明现有方法高度依赖于超大规模LLMs的固有能力，而非有效利用有用的演示示例。", "innovation": "提出了一种新颖的方法，有效检索和生成SQL查询。构造了一个深度上下文模式链接图（Deep Contextual Schema Link Graph），包含问题与数据库模式项之间的关键信息和语义关系，基于图的结构可以有效表示Text-to-SQL范例和检索有用的演示示例，以提高上下文学习的效果。", "conclusion": "在Spider基准测试上，该方法展示了有效性和效率的持续提升，无论是在超大规模LLMs还是小型LLMs上。研究结果已公开在指定的网址。"}
{"llm_update_time": "20250723", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2411.19951", "html_url": "https://arxiv.org/abs/2411.19951", "title": "Sparrow：基于文本到图像增强的数据高效视频LLM", "title_en": "Sparrow: Data-Efficient Video-LLM with Text-to-Image Augmentation", "authors": "Shukang Yin,Chaoyou Fu,Sirui Zhao,Chunjiang Ge,Yan Yang,Yuhan Dai,Yongdong Luo,Tong Xu,Caifeng Shan,Enhong Chen", "background": "近年来，多模态大型语言模型（MLLMs）在视觉理解领域取得了成功。这些模型的成功主要归因于主导的模型规模法则，即更大的参数量和更多的数据促进了更好的性能。数据扩容主要依赖自动数据管道，专注于大型语言模型（LLM）的自我指令。然而，对于这些数据扩容的效用效果，研究历来未引起足够的重视。本文重新审视了使用合成数据的扩容方法，并以数据为中心发展视频LLMs。研究主要通过借助预训练的图像LLMs对视频数据进行微调，并通过数据扩容来测试学习效率。初步实验结果表明，简单地扩大视频数据样本规模会导致学习效率低下，这主要是由于指令多样性不足造成的。", "innovation": "本文提出了一种名为Sparrow的数据增强方法，该方法从纯粹的文本指令中合成出像视频样的样本。将这些合成样本与真实视频数据混合，可以提高训练效率。通过广泛的实验，我们证明了我们的方法可以在具有较少样本的情况下实现与甚至优于基线模型的性能。更重要的是，将这些合成样本纳入训练程序可以在不需要使用长时间视频数据的情况下提升对长视频的理解能力。", "conclusion": "本文提出的Sparrow方法能够以较少的数据量达到类似基线模型的性能，甚至在某些情况下表现更优。通过合成样本的使用，长视频的理解性能也得到了提升，且无需额外的长视频训练数据。"}
{"llm_update_time": "20250723", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2403.04311", "html_url": "https://arxiv.org/abs/2403.04311", "title": "Alto：利用嵌套谱系协调分布式复合AI系统的框架", "title_en": "Alto: Orchestrating Distributed Compound AI Systems with Nested Ancestry", "authors": "Deepti Raghavan,Keshav Santhanam,Muhammad Shahir Rahman,Nayani Modugula,Luis Gaspar Schroeder,Maximilien Cura,Houjun Liu,Pratiksha Thaker,Philip Levis,Matei Zaharia", "background": "复合AI应用将生成语言模型、文档检索器和嵌入模型等子组件串联起来。在传统的系统优化方法（如并行性和流水线）应用于复合AI系统时遇到困难，因为每个组件在数据粒度和类型方面有不同的约束条件。新的数据经常在中间计算中生成，文本流可能被分割成更小、独立的片段（例如，文档到句子），随后可以在计算的后期重新聚合。由于这种复杂性，现有的系统在提供复合AI查询服务时不能充分利用并行性和流水线机会。", "innovation": "Alto提供了一种自动优化复合AI查询执行的框架，利用了流式处理和并行性。Bento引入了一种新的抽象概念，被称为嵌套谱系，它是一种元数据层次结构，使系统能够正确追踪部分输出并跨越复合AI应用程序组件的异构约束进行数据聚合。元数据是自动从编程模型中推断出来的，允许开发人员表达复杂的数据流模式，而无需手动考虑路由和聚合的细节。Alto的实现比流行的现有AI编程框架LangGraph的实现更快或匹配， latency 减少了10-30%。", "conclusion": "Alto框架通过利用流式处理和并行性自动优化执行复合AI查询。Bento引入了嵌套谱系的新抽象，这是一种元数据层次结构，允许系统跨异构组件的复合AI应用程序正确跟踪部分输出并进行数据聚合。Alto的实现结果与流行的AI编程框架LangGraph相比，展现了优于或相当的性能，尤其是在延迟方面，改善了10-30%。"}
{"llm_update_time": "20250723", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2505.16938", "html_url": "https://arxiv.org/abs/2505.16938", "title": "InternAgent: 当代理成为科学家——从假设到验证构建闭环系统", "title_en": "InternAgent: When Agent Becomes the Scientist -- Building Closed-Loop System from Hypothesis to Verification", "authors": "InternAgent Team:Bo Zhang,Shiyang Feng,Xiangchao Yan,Jiakang Yuan,Runmin Ma,Yusong Hu,Zhiyin Yu,Xiaohan He,Songtao Huang,Shaowei Hou,Zheng Nie,Zhilong Wang,Jinyao Liu,Tianshuo Peng,Peng Ye,Dongzhan Zhou,Shufei Zhang,Xiaosong Wang,Yilan Zhang,Meng Li,Zhongying Tu,Xiangyu Yue,Wangli Ouyang,Bowen Zhou,Lei Bai", "background": "人工智能正在加速科学研究范式的转变，不仅提高研究效率，还推动创新。在此背景下，本文介绍了一种名为InternAgent的统一闭环多智能体框架，以实现跨学科的自主科学研究(ASR)，使研究人员能够以前所未有的速度和精度解决复杂问题.", "innovation": "InternAgent突出了三个关键优势：1) 可扩展性：InternAgent已经在12项科学任务中展示了其灵活性和适应性，能够生成创新想法，提高基准代码的性能。2) 交互性：提供了一个供人类专家反馈和多智能体互动的接口，无缝集成领域专家知识。3) 效率：在多个科学领域取得了显著的性能提升，同时大大减少了成本时间，例如在反应产率预测中，从27.6%提升到35.4%，仅用了12小时；在增强子活性预测中，准确度从0.65提高到0.79，仅用了4小时；在2D语义分割中，精确度从78.8%提高到81.0%，仅仅用了30小时.", "conclusion": "InternAgent展示了在不同科学研究领域中的应用效果，验证了多智能体系统在提高研究效率和精度方面的潜力。"}
{"llm_update_time": "20250723", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2412.01661", "html_url": "https://arxiv.org/abs/2412.01661", "title": "R-Bot: 一个基于LLM的查询重写系统", "title_en": "R-Bot: An LLM-based Query Rewrite System", "authors": "Zhaoyan Sun,Xuanhe Zhou,Guoliang Li,Xiang Yu,Jianhua Feng,Yong Zhang", "background": "查询重写对于优化SQL查询并提高其执行效率至关重要，而不改变其结果。传统的查询重写主要依赖于启发式方法和基于学习的方法，这些方法在质量上有所欠缺且缺乏稳定性。最近，LLM的发展为解决这一问题提供了新的思路，尤其是在理解和处理自然语言及代码方面表现出色。然而，直接使用像GPT-4这样的LLMs遇到了诸如幻觉等挑战，模型可能会生成不准确或不相关的结果。为了解决这一问题，本文提出了一种基于LLM的查询重写系统R-Bot，通过多源重写证据准备流水线生成指导LLM避免幻觉的重写证据，结合结构与语义分析的检索方法，逐步LLM重写方法，迭代利用检索到的证据选择并安排重写规则，并通过自反思进一步优化。", "innovation": "设计了一个多源重写证据准备流水线来生成指导LLM避免幻觉的重写证据；提出了一种结合结构和语义分析的检索方法来有效地检索最相关的重写证据；提出了逐步LLM重写方法，支持自反思以选择和排列重写规则。", "conclusion": "通过在实际数据集和广泛使用的基准上进行综合实验，展示了R-Bot系统的优越性能，超越了现有最先进的查询重写方法。R-Bot系统已经在华为和实际客户中部署，结果表明，提出的R-Bot系统实现了较低的查询延迟。"}
{"llm_update_time": "20250723", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2507.13354", "html_url": "https://arxiv.org/abs/2507.13354", "title": "实现大型语言模型变压器架构的物理模型", "title_en": "Physical models realizing the transformer architecture of large language models", "authors": "Zeqian Chen", "background": "2017年引入的变压器架构标志着自然语言处理领域最为显著的进展。变压器通过全程依赖注意力机制来捕捉输入和输出之间的全局依赖关系，成为一种模型架构。然而，我们相信在理论上对变压器的理解仍存在差距，特别是在物理层面的理解尚不充分。从现代芯片（如28nm以下集成电路）的角度来看，现代智能机器应被视为超越传统统计系统的开放量子系统。基于此，我们提出了基于开放量子系统在ℏ空间上的希尔伯特空间中令牌的泡克尔斯基空间实现大型语言模型的变压器架构的物理模型。", "innovation": "本文构造了基于开放量子系统理论的物理模型，利用变压器架构实现大型语言模型。该物理模型在泡克尔斯基空间的希尔伯特空间中，按照令牌的希尔伯特空间构建，为理解和实现大型语言模型的变压器架构提供了一种新的物理视角。", "conclusion": "我们通过构建开放量子系统物理模型，实现了基于变压器架构的大型语言模型，填补了在理解和实现大型语言模型变压器架构的理论物理理解的空白。"}
{"llm_update_time": "20250723", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2507.14447", "html_url": "https://arxiv.org/abs/2507.14447", "title": "Routine：企业环境中LLM代理系统结构化规划框架", "title_en": "Routine: A Structural Planning Framework for LLM Agent System in Enterprise", "authors": "Guancheng Zeng,Xueyi Chen,Jiawang Hu,Shaohua Qi,Yaxuan Mao,Zhantao Wang,Yifan Nie,Shuang Li,Qiuyang Feng,Pengxu Qiu,Yujia Wang,Wenqiang Han,Linyan Huang,Gang Li,Jingjing Mo,Haowen Hu", "background": "企业在部署代理系统时，经常面临一些挑战，如通用模型缺乏特定领域的过程知识，导致计划混乱、关键工具缺失和执行稳定性差等问题。", "innovation": "本论文提出了Routine，这是一种多步骤代理规划框架，具有清晰的结构、明确的指示和无缝的参数传递，可以引导代理执行模块执行多步骤工具调用任务，以提高执行稳定性。在真实世界的企业场景评估中，Routine显著提高了模型工具调用的执行准确性，使得GPT-4o的性能从41.1%提升到96.3%，Qwen3-14B的性能从32.6%提升到83.3%。此外，通过使用基于Routine的精简数据集对Qwen3-14B进行微调，模型在特定场景的准确性提高到88.2%，表明执行计划的遵守程度得到了改善。该论文还通过基于Routine的精简来创建特定场景下的多步骤工具调用数据集，进一步提高了模型的准确性，达到了95.5%，接近GPT-4o的性能。", "conclusion": "实验结果表明，Routine在提炼特定领域的工具使用模式和提高模型对新场景的适应性方面显示出有效性。该论文证明了Routine提供了一种实用和可访问的方法，以构建稳定的代理工作流程，加速代理系统在企业环境中的部署和采用，并推进了AI在流程中的技术愿景。"}
{"llm_update_time": "20250723", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2507.15773", "html_url": "https://arxiv.org/abs/2507.15773", "title": "Supernova：在Transformer架构中以更少实现更多", "title_en": "Supernova: Achieving More with Less in Transformer Architectures", "authors": "Andrei-Valentin Tanase,Elena Pelican", "background": "目前，大型Transformer模型尽管性能优秀但计算效率较低。这篇论文探讨了如何通过精心设计的架构和创新的标记化方法，实现高效计算的同时达到大型模型的性能。研究重点是展示在保持计算效率的同时，如何通过合理的架构设计达到大型模型的效果。", "innovation": "论文提出了名为Supernova的650M参数的仅解码器Transformer模型，它结合了Rotary Positional Embeddings (RoPE)、Grouped Query Attention (GQA)、RMSNorm、SwiGLU激活函数，以及一种自定义的128,000词汇量的字节级别的BPE标记化方法。这些创新使得Supernova模型在保持计算效率的情况下，达到了与1B参数模型相似的性能。特别指出的是，Supernova的压缩率高达3:1，而相较竞争对手模型，Supernova使用更少的训练令牌，降低了训练成本，验证了模型性能与参数量之间的关系，提出了新的模型规模范式，强调了架构效率和标记质量的重要性", "conclusion": "论文展示了Supernova模型在参数量明显减少的情况下，依然能够达到大型模型的性能。这种表现挑战了现有的模型规模范式，证明了通过对架构和标记化的创新优化可以在减少模型规模的同时，保持甚至提高模型性能。"}
{"llm_update_time": "20250723", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2507.08529", "html_url": "https://arxiv.org/abs/2507.08529", "title": "一种用于罕见疾病诊断的概念多粒度sparse激活和层次知识图融合框架", "title_en": "A Multi-granularity Concept Sparse Activation and Hierarchical Knowledge Graph Fusion Framework for Rare Disease Diagnosis", "authors": "Mingda Zhang,Na Zhao,Jianglong Qin,Guoyu Ye,Ruixiang Tang", "background": "罕见疾病的诊断对于医疗大型语言模型来说仍然充满挑战，因为这些模型的知识表示不足、概念理解有限以及临床推理能力受限。", "innovation": "提出了一种结合多粒度稀疏激活和层次知识图的框架。该方法使用了四种互补的匹配算法，并包含多样性控制和五级后备策略，以实现精准的概念激活。三级知识图（分类学、临床特征、实例）提供了一个结构化且最新的上下文框架。实验表明，该框架在BioASQ罕见疾病数据集上的表现显著提升，BLEU分数最多提升了0.13，ROUGE分数最多提升了0.10，诊断准确率最多提升了0.25，最好模型的准确率达到0.92，超过了0.90的临界值。专家评估证实了信息质量、推理和专业表达的提升。", "conclusion": "该框架在减少罕见疾病患者的诊断旅行（the diagnostic odyssey）方面显示出潜力。"}
{"llm_update_time": "20250723", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2507.07939", "html_url": "https://arxiv.org/abs/2507.07939", "title": "SAGE: 一种通过事实增强和熵感知对齐的视觉语言模型进行异常检测", "title_en": "SAGE: A Visual Language Model for Anomaly Detection via Fact Enhancement and Entropy-aware Alignment", "authors": "Guoxin Zang,Xue Li,Donglin Di,Lanshun Nie,Dechen Zhan,Yang Song,Lei Fan", "background": "视觉语言模型（VLMs）在通用多模态任务中取得了显著进展，但在工业异常检测和推理方面经常遇到困难。特别是在提供可解释的解释和泛化到未见类别方面存在问题。这一限制主要是由于异常检测的领域特定性质，阻碍了现有VLMs在需要精确、结构化和上下文感知分析的工业场景中的应用。", "innovation": "我们提出了SAGE框架，这是一种基于VLM的方法，通过自引导事实增强(SFE)和熵感知直接偏好优化(E-DPO)来增强异常推理。SFE通过事实提取和融合将领域特定知识融入视觉推理中，而E-DPO使用熵感知优化来对齐模型输出与专家偏好。", "conclusion": "SAGE在工业异常检测数据集中的零样本和少样本设置下展示了优越的性能。我们还介绍了AD-PL，这是一个偏好优化的数据集，用于工业异常推理，包含28,415个带有专家评分的答案-问题实例。我们开发了多尺度逻辑评估（MLE），这是一个分析模型逻辑和一致性的定量化框架。"}
{"llm_update_time": "20250723", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2507.15844", "html_url": "https://arxiv.org/abs/2507.15844", "title": "基于层次预算策略优化的自适应推理", "title_en": "Hierarchical Budget Policy Optimization for Adaptive Reasoning", "authors": "Shangke Lyu,Linjuan Wu,Yuchen Yan,Xingyu Wu,Hao Li,Yongliang Shen,Peisheng Jiang,Weiming Lu,Jun Xiao,Yueting Zhuang", "background": "大型推理模型通过广泛的链式推理产生表现出显著的性能，但其在应用统一推理策略时显得计算效率低下，尤其是在不同问题复杂性下。现有的方法在效率导向训练中存在探索空间坍缩的问题，导致模型倾向于避免必要的长推理路径，从而牺牲了计算资源的利用效率。", "innovation": "提出了一种基于强化学习框架的层次预算策略优化（Hierarchical Budget Policy Optimization，HBPO），允许模型在学习问题特定推理深度的同时，不牺牲其能力。HBPO通过层次预算探索将录制样本分配到多个具有不同令牌预算的子组，避免了资源分配效率和效果的折衷。通过引入差分奖励机制来创建预算感知的激励机制，HBPO使得模型能够根据任务复杂性发现任务需求和计算努力之间的自然对应关系。", "conclusion": "广泛的实验表明，HBPO可以在降低平均令牌使用量高达60.6%的同时提高准确率3.14%，并适用于四个推理基准测试。与现有方法不同，HBPO能够自适应地调整推理深度，适应问题复杂性，证明了推理效率和能力并非天生矛盾，可以通过适当结构化的层次训练同时优化，同时保留探索多样性。"}
{"llm_update_time": "20250723", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2505.23631", "html_url": "https://arxiv.org/abs/2505.23631", "title": "Human Empathy as Encoder: AI-Assisted Depression Assessment in Special Education", "title_en": "Human Empathy as Encoder: AI-Assisted Depression Assessment in Special Education", "authors": "Boning Zhao", "background": "在敏感环境中评估学生抑郁情况，如特殊教育，是一项挑战。标准化问卷可能无法完全反映学生的真实情况。自动化方法经常在处理丰富学生叙述时出错，缺少教师对学生的情感连接中获得的关键的个性化见解。现有方法往往未能解决这种模糊性或有效整合教育者的理解。", "innovation": "本文介绍了一种新颖的人本中心的人工智能框架——Human Empathy as Encoder (HEAE)，旨在通过促进人类-人工智能的协同合作来解决这些限制。该方法独特地将学生叙述文本与由教师提供并基于PHQ-9框架的9维“同理心向量”（EV）结合，明确地将隐含的同理心洞察转化为结构化的AI输入，以增强而不是取代人类判断。", "conclusion": "本研究通过在结构上嵌入人类同理心，展示了更加负责和伦理的情感计算的途径，优化了多模态融合、文本表示和分类架构，实现了7级严重程度分类的82.74%的准确性。"}
{"llm_update_time": "20250723", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2507.09279", "html_url": "https://arxiv.org/abs/2507.09279", "title": "Prompt4Trust: 一种基于强化学习的多模态大型语言模型临床对齐置信度校准的提示增强框架", "title_en": "Prompt4Trust: A Reinforcement Learning Prompt Augmentation Framework for Clinically-Aligned Confidence Calibration in Multimodal Large Language Models", "authors": "Anita Kriz,Elizabeth Laura Janes,Xing Shen,Tal Arbel", "background": "多模态大型语言模型（MLLMs）在医疗领域的应用前景广阔，但其在关键安全领域中的部署受限于两个主要问题：提示设计的敏感性以及倾向于产生高置信度的不正确响应。由于临床医生可能依赖模型表述的置信度来评估预测的可靠性，因此当模型表达高置信度时，也应高度准确，以确保其决策的可靠性。目前，没有专门使用提示增强来改进MLLMs置信度校准的方法，尤其是在临床环境中，需要更加关注临床相关的关键校准方面。现有方法未能充分满足这一需求，因此需要一种新的方法来改进临床决策中的置信度校准。", "innovation": "我们提出了Prompt4Trust，这是一个基于强化学习（RL）的提示增强框架，旨在校准MLLMs的置信度。该框架通过训练一个小型的语言模型生成上下文感知的辅助提示来引导下游任务的MLLM生成响应，以更准确地反映其预测准确性。这种方法不同于传统的校准技术，因为它专门优先选择对安全和可靠的临床决策至关重要的校准方面。此外，我们的方法还能提高任务精度，并在多模态医学视觉问答（VQA）基准测试中取得了目前最佳的性能。我们的实验表明，使用较小的下游任务MLLM训练的框架，在更大规模的MLLM中显示出了零样本泛化的潜力，这表明能够进行可扩展的校准而不增加计算成本。", "conclusion": "我们的工作展示了自动化且与人类对齐的提示工程对于提高MLLMs在关键安全领域中的可信度的潜力。通过Prompt4Trust，可以在不增加计算成本的前提下实现有效的校准，并提升机器的可靠性和准确性，特别是在医疗诊断和治疗方面。我们的代码库可以在该链接找到。"}
{"llm_update_time": "20250723", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.15878", "html_url": "https://arxiv.org/abs/2507.15878", "title": "基于重要性调整的情境下情绪识别", "title_en": "Salience Adjustment for Context-Based Emotion Recognition", "authors": "Bin Han,Jonathan Gratch", "background": "情绪识别在动态社交环境中要求理解面部表情与情境线索之间的复杂相互作用。本文研究了使用贝叶斯线索集成（BCI）和视觉-语言模型（VLM）的重调整框架，以根据面部线索的表达性动态加权面部和情境信息，评估这一方法在囚徒困境场景中的表现，这些场景设计用来引发情绪反应，并利用人工注释和自动化情绪识别系统进行评估。", "innovation": "提出了一种重调整框架，结合了贝叶斯线索集成（BCI）和视觉-语言模型（VLM），用于根据面部线索的表达性动态加权面部和情境信息，增强情绪识别性能，为未来研究提供了扩展到更广泛社交情境和多模态应用的潜在方向。", "conclusion": "实验结果表明，重调整方法增强了情绪识别性能，为未来情绪识别技术在更广泛社会情境和多模态应用中的研究提供了新的路径。"}
{"llm_update_time": "20250723", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.15888", "html_url": "https://arxiv.org/abs/2507.15888", "title": "PAT++：物体重识别中生成式视觉增强的一个警示故事", "title_en": "PAT++: a cautionary tale about generative visual augmentation for Object Re-identification", "authors": "Leonardo Santiago Benitez Pereira,Arathy Jeevan", "background": "生成式数据增强在多个视觉任务中显示出成效，但在物体重识别任务中的应用尚未得到充分探索，尤其是在保留细微视觉特征方面至关重要。", "innovation": "引入了名为PAT++的新管道，将Diffusion Self-Distillation技术整合到Part-Aware Transformer中，并通过Urban Elements ReID挑战数据集进行了广泛实验，使用生成图像进行模型训练和查询扩展，以此评估身份保留图像生成技术的有效性.", "conclusion": "实验结果显示了性能下降，主要是由于领域转换和无法保留身份定义特征。这些发现质疑了生成模型在细粒度识别任务中的可迁移性，并揭示了目前视觉增强技术在身份保留应用中的关键局限性."}
{"llm_update_time": "20250723", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.15882", "html_url": "https://arxiv.org/abs/2507.15882", "title": "文档低语：一种长上下文多模态图像/文档理解的视觉LLM基准", "title_en": "Document Haystack: A Long Context Multimodal Image/Document Understanding Vision LLM Benchmark", "authors": "Goeric Huybrechts,Srikanth Ronanki,Sai Muralidhar Jayanthi,Jack Fitzgerald,Srinivasan Veeravanallur", "background": "多模态大型语言模型的普及极大地提高了从不同模态的复杂数据输入中进行分析和理解的能力。然而，长文档的处理仍较少研究，主要是因为缺乏合适的基准标准。这种缺乏使得评估视觉语言模型（VLM）在长、视觉上复杂的文档上的性能变得困难。为此，本文提出了Document Haystack基准，旨在评估VLM在长文档上的性能，特别是其从复杂文档中检索相关信息的能力。Document Haystack包含从5至200页不等的文档，并在其中巧妙地插入纯文本或图文“针”，以挑战VLM的检索能力。该基准提供400种文档变体和总计8250个问题的客观评估框架支持，以全面评估模型性能。", "innovation": "提出了Document Haystack —— 一个全面的基准，专门设计用于评估视觉语言模型在长、复杂文档上的性能。该基准包括了5到200页的文档，并在其中插入纯文本或图文“针”，以测试模型的检索能力。此外，Document Haystack还提供了一个客观、自动化的评估框架，支持400种文档变体和8250个问题，使模型的性能评估更加全面和准确。", "conclusion": "本文详细介绍了Document Haystack数据集的构建和特点，并展示了领先视觉语言模型的结果，提出了该领域的未来研究方向。该基准为未来在长上下文多模态图像/文档理解方面的工作提供了一个重要的评估工具。"}
{"llm_update_time": "20250723", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2507.15846", "html_url": "https://arxiv.org/abs/2507.15846", "title": "GUI-G$^2$: 贝塔奖励建模用于GUI定位", "title_en": "GUI-G$^2$: Gaussian Reward Modeling for GUI Grounding", "authors": "Fei Tang,Zhangxuan Gu,Zhengxi Lu,Xuyang Liu,Shuheng Shen,Changhua Meng,Wen Wang,Wenqi Zhang,Yongliang Shen,Weiming Lu,Jun Xiao,Yueting Zhuang", "background": "当前使用强化学习方法进行GUI（图形用户界面）定位时，常用二元奖励，这种方式将界面元素视作二元选择的目标，这种方法产生了稀疏的信号，忽略了空间交互的连续性。尽管如此，人类的鼠标点击行为自然形成了以目标元素为中心的高斯分布。因此，本研究提出了一种新的奖励框架——GUI高斯接地奖励（GUI-G$^2$），将GUI元素建模为界面平面上的连续高斯分布。这种方法将GUI接地从稀疏的二元分类任务转变为密集的连续优化任务，通过高斯分布生成丰富的梯度信号，从而引导模型找到最优的交互位置。", "innovation": "引入GUI高斯接地奖励（GUI-G$^2$）：一种新的奖励框架，利用连续高斯分布模型GUI元素。提出了两个协同机制：高斯点奖励和覆盖率奖励，前者通过中心在元素质心的指数衰减分布进行精确定位，后者通过测量预测高斯分布与目标区域的重叠情况来评估空间对齐情况。还开发了自适应方差机制，根据元素尺寸调整奖励分布。此研究在ScreenSpot、ScreenSpot-v2和ScreenSpot-Pro基准测试中，证明了GUI-G$^2$明显优于现有最佳方法UI-TARS-72B，特别是在ScreenSpot-Pro基准测试中，性能提高了24.7%。", "conclusion": "连续建模提供了对界面变化的更强鲁棒性以及对未见过的布局的更好泛化能力，为GUI交互任务的空间推理建立了一个新的范式。"}
{"llm_update_time": "20250723", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2507.14664", "html_url": "https://arxiv.org/abs/2507.14664", "title": "Mangosteen: 用于语言模型预训练的开放泰语语料库", "title_en": "Mangosteen: An Open Thai Corpus for Language Model Pretraining", "authors": "Wannaphong Phatthiyaphaibun,Can Udomcharoenchaikit,Pakpoom Singkorapoom,Kunat Pipatanakul,Ekapol Chuangsuwanich,Peerat Limkonchotiwat,Sarana Nutanong", "background": "现有的语言模型对训练数据的质量非常敏感，但网络文本通常较为嘈杂且需要仔细清理。现有的大规模语料库主要依靠英语为中心或无语言偏见的处理管道，这些管道的启发式方法无法捕捉泰文字符或文化细微差别，导致风险性内容如赌博信息未能得到充分处理。此前的泰语特定努力虽然进行了管道定制或构建新管道，但很少公开数据或详细说明设计选择，阻碍了可重复性和泰语高质语料库的构建。因此，有必要构建一个透明、高质量的泰语语料库。", "innovation": "本研究引入了Mangosteen语料库，该语料库通过泰语适应的Dolma管道构建，包括定制的基于规则的语言识别、修订后的C4/Gopher质量过滤器、泰语训练的内容过滤器，以及经过精挑细选的非网络来源，如维基百科、王室公告、OCR提取的书籍和CC许可的YouTube字幕。系统化的消融实验显示，该管道能够将公共层面数据（CommonCrawl）从2.02亿文档减少到2500万，同时提升了SEA-HELM NLG的能力。一个8B参数的持续预训练SEA-LION模型在泰语基准测试中表现优于之前版本，提高了约4个百分点。研究还提供了完整的管道代码、清理清单、语料库快照和所有检查点，为未来泰语和区域语言模型研究提供了可重复的基础。", "conclusion": "Mangosteen是一个470亿词的泰语语料库，通过上述改进的处理管道构建，显著提升了预训练模型的质量和透明度。研究者开放了所有相关资源，旨在推动泰语和区域语言模型领域的可重复研究。"}
{"llm_update_time": "20250723", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.15915", "html_url": "https://arxiv.org/abs/2507.15915", "title": "利用预训练CNN模型结合XAI技术从皮肤病变图像中早期检测猴痘的一种实证研究", "title_en": "An empirical study for the early detection of Mpox from skin lesion images using pretrained CNN models leveraging XAI technique", "authors": "Mohammad Asifur Rahim,Muhammad Nazmul Arefin,Md. Mizanur Rahman,Md Ali Hossain,Ahmed Moustafa", "background": "猴痘是一种由猴痘病毒引起的人畜共患疾病，其症状与其他皮肤状况相似，导致早期准确诊断具有挑战性。人工智能，尤其是深度学习，为医学图像分析提供了强大工具，但在猴痘检测中预训练模型的应用和解释性人工智能（XAI）技术尚不充分探索。", "innovation": "研究评估了预训练CNN模型（VGG16、VGG19、InceptionV3、MobileNetV2）在二分类和多分类数据集中的早期猴痘检测效果，并通过Grad-CAM XAI技术增强了模型可解释性。使用转移学习技术微调预训练的CNN模型，同时避免过拟合，展示了模型的性能，并通过可视化关键特征进行验证。", "conclusion": "研究表明，预训练CNN模型在猴痘检测中具有潜力，并强调了XAI技术的价值。未来工作需解决数据集限制，整合多模态数据，并探索更多的可解释性技术以提高诊断可靠性和模型透明度。"}
{"llm_update_time": "20250723", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.16010", "html_url": "https://arxiv.org/abs/2507.16010", "title": "FW-VTON: Flattening-and-Warping for Person-to-Person Virtual Try-on", "title_en": "FW-VTON: Flattening-and-Warping for Person-to-Person Virtual Try-on", "authors": "Zheng Wang,Xianbing Sun,Shengyi Wu,Jiahui Zhan,Jianlou Si,Chi Zhang,Liqing Zhang,Jianfu Zhang", "background": "传统的虚拟试穿方法主要集中在服装对人的试穿任务上，需要使用平铺的服装表示。与此不同，本文提出了一种新颖的人对人虚拟试穿方法。该方法仅涉及两幅输入图像：一幅展示目标人物的照片和另一幅展示其他人穿着的服装。目标是生成目标人物与所需服装的逼真结合。由于缺乏高质量的数据集，本文引入了一个新的人对人试穿场景专用数据集。实验评估表明，FW-VTON在定性和定量评估中均达到了最先进的性能，并且在服装提取子任务中表现优异。", "innovation": "本文提出了一个名为FW-VTON的方法，该方法分为三个阶段：提取源图像中的平铺服装图像；将服装与目标姿态进行对齐；将对齐后的服装无缝集成到目标人物上。此外，还引入了一个专门为人对人试穿场景设计的新数据集。", "conclusion": "实验结果显示，FW-VTON在定性和定量评估中均达到了最先进的性能，特别是在服装提取子任务上表现出色。"}
{"llm_update_time": "20250723", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.16015", "html_url": "https://arxiv.org/abs/2507.16015", "title": "第一人称主观视觉中跟踪真的更加具有挑战性吗？", "title_en": "Is Tracking really more challenging in First Person Egocentric Vision?", "authors": "Matteo Dunnhofer,Zaira Manigrasso,Christian Micheloni", "background": "研究表示，主观第一人称视觉对象追踪与分割成为理解人类活动的关键任务。早期的研究已经将先进的方法进行了基准测试，并发现在主观第一人称视觉领域遇到了较大的挑战。但这些结论基于不同场景的评估，许多被认为复杂的特性也存在于第三人称的人体-物体活动视频中。因此，亟需对这一现象进行深入分析，区分第一人称视角带来的独特挑战与人体-物体活动理解这一大领域中的普遍挑战。", "innovation": "本文提出了一个新的基准研究来区分这两种挑战，并通过评估策略实现了对第一人称视角独特挑战与人体-物体理解领域挑战之间差异的精确分离。这有助于更准确地揭示主观跟踪和分割中的真正难度来源，从而促进该任务的更精确改进。", "conclusion": "通过这项研究，我们提供了对主观视觉追踪和分割中难度来源的更深层次洞察，支持了更为有针对性的进展。"}
{"llm_update_time": "20250723", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2411.05195", "html_url": "https://arxiv.org/abs/2411.05195", "title": "探索具有相同视觉编码器的生成型MLLMs如何比CLIP识别得更准确", "title_en": "Exploring How Generative MLLMs Perceive More Than CLIP with the Same Vision Encoder", "authors": "Siting Li,Pang Wei Koh,Simon Shaolei Du", "background": "最近的研究表明，CLIP模型在需要基础组成关系、理解空间关系或捕捉细微特征的视觉推理任务上表现不佳。一个自然的假设是，CLIP的视觉编码器未能嵌入这些任务所必需的信息。然而，研究发现，这并不总是如此：编码器能够收集查询相关的视觉信息，但CLIP未能提取这些信息。特别是，实验表明，另一类视觉语言模型（VLMs），生成型多模态大规模语言模型（MLLMs），使用相同的视觉编码器和权重在许多任务上取得了显著更高的准确性，这表明这些生成型MLLMs能够识别更多的内容，因为它们更有效地提取和利用视觉信息。", "innovation": "研究表明，生成型MLLMs的成功归因于多个关键设计选择，包括补丁标记、位置嵌入和基于提示的加权。单纯增强训练数据或应用更强的文本编码器并不能有效解决问题，额外的文本标记也没有显着的好处。有趣的是，研究还发现，虽然这些MLLMs通过对比性微调转换为CLIP样式的编码器后，仍然在相同的余弦相似性评估协议下优于CLIP，这些MLLMs并不是仅通过自回归损失训练的生成型模型。这项研究强调了VLM架构选择的重要性，为CLIP样式的对比性VLM的性能提升提供了改进方向。", "conclusion": "研究结果表明，生成型MLLMs在视觉推理任务上的表现优于CLIP，这项研究强调了VLM架构选择的重要性，并提供了解决CLIP在视觉推理任务上表现不佳问题的方向。"}
{"llm_update_time": "20250723", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.16038", "html_url": "https://arxiv.org/abs/2507.16038", "title": "发现并利用斯佩尔物体片段", "title_en": "Discovering and using Spelke segments", "authors": "Rahul Venkatesh,Klemen Kotar,Lilian Naing Chen,Seungwoo Kim,Luca Thomas Wheeler,Jared Watrous,Ashley Xu,Gia Ancone,Wanhee Lee,Honglin Chen,Daniel Bear,Stefan Stojanov,Daniel Yamins", "background": "计算机视觉中的片段通常由语义定义，高度依赖于特定类别的约定。相比之下，发展心理学表明人类以斯佩尔物体的形式感知世界——即在物理作用下可靠一起运动的物理事物的分组。斯佩尔物体基于无分类的因果运动关系，更有利于完成操作和规划等任务。研究旨在通过基准测试斯佩尔物体概念，构建SpelkeNet模型，实现从图像中自动提取斯佩尔物体的片段，并在使用各种现成物体操作模型时通过3DEditBench基准测试，展示斯佩尔物体概念在下游应用中的实用价值和优越表现。", "innovation": "本文首次基准测试了斯佩尔物体的概念，提出了包含自然图像中广泛定义的斯佩尔段落的SpelkeBench数据集。此外，本文构建了SpelkeNet模型，用于预测未来运动的概率分布，并提取斯佩尔物体段落。模型通过应用“统计反事实探针”，可以在高运动许可区域上应用多样化的“虚拟戳”，并通过结果的期望偏移图来定义斯佩尔物体段落的统计聚合，从而更好地支持物体操作和规划任务。相较于监督基线如SegmentAnything (SAM), SpelkeNet 在 SpelkeBench 中表现更优，并在物理对象操作的下游应用中也取得了优越的表现。", "conclusion": "本文发现并利用斯佩尔物体片段可以通过更好的因果运动关系来定义，支持物体的操纵和规划任务，并通过实验验证了其在下游应用中的优越性。"}
{"llm_update_time": "20250723", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.16095", "html_url": "https://arxiv.org/abs/2507.16095", "title": "通过社会情境反馈提升个性化图像生成", "title_en": "Improving Personalized Image Generation through Social Context Feedback", "authors": "Parul Gupta,Abhinav Dhall,Thanh-Toan Do", "background": "个性化图像生成是指根据场景描述生成参考图像中一个或多个主体的图像，这一领域在学术界引起了高度重视。然而，目前的生成图像存在三大局限性：复杂的活动如“人推摩托车”等未能正确生成且伴有人类姿态错误；参考的人类身份没有得到保留；生成的人类视线模式显得不自然且与场景描述不一致。", "innovation": "本文提出了一种基于反馈的微调方法来克服以上缺陷，具体而言，利用姿态检测、人体与物体交互检测、人脸检测和人脸注视点估计的最新检测器对现有的个性化生成方法进行校准。同时，根据不同级别的反馈模块（低级信号如人类姿态和高级信号如注视点）引入时间步长机制，从而生成的图像在三个基准数据集上的交互、面部身份和图像质量方面均有所提升。", "conclusion": "通过引入基于社交情境反馈的方法，本文在生成交互、面部身份和图像质量方面取得了显著改进。"}
{"llm_update_time": "20250723", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2507.15007", "html_url": "https://arxiv.org/abs/2507.15007", "title": "Hear Your Code Fail, Voice-Assisted Debugging for Python", "title_en": "Hear Your Code Fail, Voice-Assisted Debugging for Python", "authors": "Sayed Mahbub Hasan Amiri,Md. Mainul Islam,Mohammad Shakhawat Hossen,Sayed Majhab Hasan Amiri,Mohammad Shawkat Ali Mamun,Sk. Humaun Kabir,Naznin Akter", "background": "传统的调试方法依赖于文本日志和堆栈跟踪，这些方法主要通过视觉反馈来传达错误信息，这可能会增加认知负担，降低错误识别速度。对于视觉障碍的设计者来说，这种方法尤为不便。", "innovation": "该研究提出了一种创新的声音辅助调试插件，将无声的运行时错误转化为可操作的声音诊断，通过集成全局异常钩子架构和pyttsx3文本转语音技术，以及基于Tkinter的图形用户界面可视化，实现了多模态错误反馈，通过并行的声音和视觉通道传递信息。该系统在错误处理时的语音延迟低于1.2秒，CPU开销低于18%，并且能够通过语义化异常分类和上下文化来加快错误识别速度。该插件仅需两行集成代码即可安装，特别适合于视觉障碍的设计者和需要无手操作的错误诊断任务。", "conclusion": "该解决方案为编程错误诊断带来了根本性的转变，整合了Python 3.7+跨平台环境，并通过后续开发中的GPT修复建议和实时多语言翻译功能进一步提升了声音调试的效率，确立了软件开发工作流中新的认知效率标准。"}
{"llm_update_time": "20250723", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.15911", "html_url": "https://arxiv.org/abs/2507.15911", "title": "本地密集逻辑关系增强的知识蒸馏", "title_en": "Local Dense Logit Relations for Enhanced Knowledge Distillation", "authors": "Liuchi Xu,Kang Liu,Jinshuai Liu,Lu Wang,Lisheng Xu,Jun Cheng", "background": "当前最先进的逻辑蒸馏方法展现了多样性和效率，但迄今没有深入研究逻辑知识中的细粒度关系。", "innovation": "提出了一种名为Local Dense Relational Logit Distillation (LDRLD)的新方法，通过递归地解耦和重组逻辑信息捕捉类间关系，引入了自适应衰减权重（ADW）策略，该策略利用逆排名加权（IRW）和指数排名衰减（ERD）动态调整关键类别的权重。", "conclusion": "该方法通过转移细粒度知识并强调最关键关系来提高学生性能，在CIFAR-100、ImageNet-1K和Tiny-ImageNet等数据集上的实验表明，该方法优于最先进的逻辑基知识蒸馏方法。代码将公开提供。"}
{"llm_update_time": "20250723", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.16018", "html_url": "https://arxiv.org/abs/2507.16018", "title": "Artifacts and Attention Sinks: Efficient Approximations for Vision Transformers", "title_en": "Artifacts and Attention Sinks: Structured Approximations for Efficient Vision Transformers", "authors": "Andrew Lu,Wentinn Liao,Liuhui Wang,Huzheng Yang,Jianbo Shi", "background": "视觉变换器已经在各种应用中展示出了强大的能力，但其内部运作机制仍然部分未被理解。本文探讨了大规模标记（具有异常高激活范数，作为注意力陷阱的标记）和幻象标记（在推理过程中作为副产品出现）的现象，通过分析发现，这些标记通过注意力机制相互抑制，关键地调节了网络中的信息流动。", "innovation": "本文提出了一种无需训练的方法——快速Nyström注意力（FNA），通过利用大规模标记和幻象标记形成的空间结构，以线性时间和空间复杂度来近似自我注意力。此外，还提出了一个屏蔽策略来减轻这些标记的噪声影响，从而获得相当可观的性能提升，几乎没有成本。", "conclusion": "本文在流行的预训练视觉架构上评估了我们的方法，并展示了其在检索、分类、分割和视觉问答方面具有竞争力的表现，同时减少了计算负担。"}
{"llm_update_time": "20250723", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.16158", "html_url": "https://arxiv.org/abs/2507.16158", "title": "AMMNet：一种用于遥感语义分割的异步多模态网络", "title_en": "AMMNet: An Asymmetric Multi-Modal Network for Remote Sensing Semantic Segmentation", "authors": "Hui Ye,Haodong Chen,Zeke Zexi Hu,Xiaoming Chen,Yuk Ying Chung", "background": "遥感（RS）领域的语义分割在引入多模态数据，尤其是RGB影像与数字表面模型（DSM）的结合后取得了显著进展，这种结合提供了地面对象的互补上下文和结构信息。然而，将RGB与DSM进行融合通常面临着两大主要局限：由于架构冗余导致的计算复杂性增加，以及由于模态对齐不当导致的分割性能下降。这些问题削弱了语义分割的效率和鲁棒性，特别是在需要精确多模态融合的复杂城市环境中。", "innovation": "为克服这些局限，本文提出了Asymmetric Multi-Modal Network (AMMNet)，一种新型的异构架构，通过三项针对RGB-DSM输入对定制的设计实现了稳健且高效的语义分割。首先，通过异构双编码器（ADE）模块基于模态特性分配表征能力，使用较深的编码器提取RGB影像的丰富上下文信息，使用轻量的编码器识别DSM中的稀疏结构特征。其次，通过在融合过程引入模态感知先验矩阵的异构先验融合（APF）模块，促进模态的对齐，生成结构意识化的上下文特征。最后，通过最小化分布差异的分布对齐（DA）模块增强了跨模态兼容性。", "conclusion": "AMMNet在ISPRS Vaihingen和Potsdam数据集的大量实验中达到了多模态网络中的最佳分割精度，同时降低了计算和内存需求。"}
{"llm_update_time": "20250723", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.16052", "html_url": "https://arxiv.org/abs/2507.16052", "title": "对图像的语义和抽象特征进行干扰以提升对抗迁移性", "title_en": "Disrupting Semantic and Abstract Features for Better Adversarial Transferability", "authors": "Yuyang Luo,Xiaosen Wang,Zhijin Ge,Yingzhe He", "background": "深度神经网络（DNNs）面临着来自对抗样本的巨大威胁，特别是在黑盒环境中这些对抗样本的可迁移性使得它们能够针对实际使用DNNs的应用程序进行攻击。其中，基于特征级别的攻击成为一种流行的方法，即通过对图像转换后计算出的重要特征权重矩阵来扰动中间特征。现有方法主要通过改变语义信息来干扰这些重要特征。本文借鉴了一些研究，表明卷积神经网络（CNNs）倾向于更多地关注高频成分（抽象特征，例如纹理、边缘等），发现通过对图像进行高频空间转换能够提升对抗样本的可迁移性。", "innovation": "本文提出了一个称为Semantic and Abstract FEatures disRuption (SAFER)的平衡方法，该方法在构建权重矩阵时结合了BLOCKMIX和SELF-MIX技术来强调关键特征。通过这种权重矩阵，SAFER可以同时干扰语义和抽象特征，从而提高对抗样本的可迁移性。", "conclusion": "在ImageNet数据集上的广泛实验验证了该方法在提高对抗可迁移性方面的有效性。"}
{"llm_update_time": "20250723", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.16116", "html_url": "https://arxiv.org/abs/2507.16116", "title": "PUSA V1.0：通过向量化时间步长适应超越Wan-I2V训练成本500元", "title_en": "PUSA V1.0: Surpassing Wan-I2V with $500 Training Cost by Vectorized Timestep Adaptation", "authors": "Yaofang Liu,Yumeng Ren,Aitor Artola,Yuxuan Hu,Xiaodong Cun,Xiaotong Zhao,Alan Zhao,Raymond H. Chan,Suiyun Zhang,Rui Liu,Dandan Tu,Jean-Michel Morel", "background": "视频扩散模型的快速发展受到了时间建模上的根本限制，尤其是由传统标量时间步变量所引起的帧演变的刚性同步。尽管特定任务适应和自回归模型试图解决这些挑战，但它们仍然受限于计算效率低下、灾难性遗忘或适用性有限。", "innovation": "提出了Pusa，一个利用向量化时间步长调整（VTA）来在一个统一的视频扩散框架内实现细粒度时间控制的创新方法。VTA是无损调整，这使其能够完全保留基础模型的能力。通过使用VTA对当前最先进的Wan2.1-T2V-14B模型进行微调，实现了前所未有的效率，训练成本低于Wan-I2V-14B的1/200（500美元比至少10万美元），以及数据集大小的1/2500（4K比至少1000万样本）。Pusa不仅为图像到视频（I2V）生成设定了新的标准，总得分为87.32%（对比Wan-I2V-14B的86.86%），还解锁了多项无特定任务训练的多任务零样本能力，如起点和终点帧，以及视频扩展，同时仍可执行文本到视频生成。", "conclusion": "本工作建立了下一代视频合成的可扩展、高效和多功能范式，促进了高质量视频生成在研究和行业的广泛应用。我们的方法保留了基础模型的生成先验，并在其中巧妙地注入了时间动态，避免了向量化时间步长所固有的组合爆炸。代码已开源。"}
{"llm_update_time": "20250723", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.15961", "html_url": "https://arxiv.org/abs/2507.15961", "title": "一种提高实时筛查应用中面部验证性能的轻量级面部质量评估框架", "title_en": "A Lightweight Face Quality Assessment Framework to Improve Face Verification Performance in Real-Time Screening Applications", "authors": "Ahmed Aman Ibrahim,Hamad Mansour Alawar,Abdulnasser Abbas Zehi,Ahmed Mohammad Alkendi,Bilal Shafi Ashfaq Ahmed Mirza,Shan Ullah,Ismail Lujain Jaleel,Hassan Ugail", "background": "面部图像质量在面部验证系统的准确性和可靠性中起着关键作用，特别是在如监控、身份验证和访问控制等实时筛查应用中尤为重要。低质量的面部图像，通常由运动模糊、光照条件差、遮挡和极端姿态变化等因素引起，会显著降低面部识别模型的性能，导致更高的弃测率和误识率。因此，提出了一种轻量级但有效的框架，用于在将面部图像传递到验证管道之前自动评估面部质量。", "innovation": "该框架利用规范化面部特征点与随机森林回归分类器相结合，实现了面部图像质量评估，准确率达到96.67%。通过将质量评估模块整合到面部验证过程中，观察到性能显著提高，包括高达99.7%的弃测率降低，以及与ArcFace面部验证模型配对时余弦相似度得分提高。该研究验证了方法的有效性，并在Dubai Police的CCTV录像中实际环境中收集的包含600多名受试者的数据集上进行了实验。结果显示，该框架能够有效缓解低质量面部图像的影响，优于现有面部质量评估技术，保持了计算效率。", "conclusion": "提出的框架有效地缓解了低质量面部图像的影响，并在保持计算效率的同时超过了现有面部质量评估技术。此外，该框架特别解决了实时筛查中的两个关键问题：面部分辨率的变化和姿态偏差，这些都是实际监控场景中常见的问题。"}
{"llm_update_time": "20250723", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.16172", "html_url": "https://arxiv.org/abs/2507.16172", "title": "AtrousMamba: 一种用于遥感变化检测的心率扫描视空间模型", "title_en": "AtrousMamaba: An Atrous-Window Scanning Visual State Space Model for Remote Sensing Change Detection", "authors": "Tao Wang,Tiecheng Bai,Chao Xu,Bin Liu,Erlei Zhang,Jiyun Huang,Hongming Zhang", "background": "最近，一种名为Mamba的新型视觉状态空间（VSS）模型取得了显著进展，它在长序列建模方面具有线性复杂度，与Transformer模型相当，从而增强了处理视觉数据的适应性。尽管大多数方法通过直接修改Mamba的扫描机制来增强全局感受野，但它们往往忽视了局部信息在密集预测任务中的关键性。此外，Mamba能否像卷积神经网络（CNNs）一样有效地提取局部特征仍然是一个待解决的问题。", "innovation": "本文提出了一种新型模型AtrousMamba，该模型有效平衡了精细局部细节的提取与全球上下文信息的整合。具体地，该方法集成了带有可调速率的阻塞性窗口选择扫描机制，实现了扫描范围的逐步扩展，缩短了相邻令牌间的距离，使模型能够有效捕捉精细的局部特征和全局上下文。通过利用阻塞性窗口扫描视空间模块(AWVSS)，我们设计了基于Mamba的端到端框架，分别用于二元变化检测（AWMambaBCD）和语义变化检测（AWMambaSCD）。实验结果表明，所提出的框架在六个基准数据集上优于现有的CNN、Transformer和Mamba方法，表明Mamba不仅可以捕获视觉数据中的长距离依赖性，还能有效地保留精细的局部细节。", "conclusion": "实验结果证实，AtrousMamba框架在多个基准数据集上比现有的CNN、Transformer和Mamba方法表现更优，证明Mamba不仅能捕捉长距离依赖性，还能有效保留精细的局部细节。"}
{"llm_update_time": "20250723", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.16201", "html_url": "https://arxiv.org/abs/2507.16201", "title": "基于局部特征匹配的一种单步骤精确指纹注册方法", "title_en": "A Single-step Accurate Fingerprint Registration Method Based on Local Feature Matching", "authors": "Yuwei Jia,Zhe Cui,Fei Su", "background": "指纹图像的失真会降低指纹识别性能，而指纹注册可以通过准确对齐两张指纹图像来缓解这一问题。传统的指纹注册方法通常分成两步：基于特征点的初步对齐和基于点匹配的密集对齐。然而，当指纹图像质量较低时，检测到的特征点数量减少，导致初步对齐失败频繁，最终导致整个指纹注册过程失败。因此，需要一种新的方法来改进这种情况。", "innovation": "本文提出了一种端到端的单步骤指纹注册算法，通过直接预测两张指纹之间的半密集匹配点对应关系来进行对齐。该方法减少了特征点注册失败的风险，并通过全局-局部注意机制实现了端到端的像素级对齐，提升了指纹识别性能。实验结果表明，该方法仅需单步骤注册即可达到最先进的匹配性能，并且可以与密集注册算法结合使用以进一步提高性能。", "conclusion": "作者提出了一种新的端到端单步骤指纹注册方法，该方法通过基于局部特征匹配直接预测两张指纹之间的匹配对应关系，提高了指纹识别的鲁棒性和准确度，验证了该方法的有效性。"}
{"llm_update_time": "20250723", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.16191", "html_url": "https://arxiv.org/abs/2507.16191", "title": "显式监督指导下的上下文推理在视觉跟踪中的应用", "title_en": "Explicit Context Reasoning with Supervision for Visual Tracking", "authors": "Fansheng Zeng,Bineng Zhong,Haiying Xia,Yufei Tan,Xiantao Hu,Liangtao Shi,Shuxiang Song", "background": "上下文推理对于增强跨帧建模中的时间一致性至关重要，但主流跟踪算法通常通过简单堆叠历史信息来进行上下文关联，而没有明确监督关联过程，这使得有效建模目标运动变化变得困难。", "innovation": "提出了RSTrack，通过三个核心机制显式地建模和监督上下文推理。1) 上下文推理机制：构建目标状态推理管道，将非约束性上下文关联转化为基于历史目标状态预测当前表示的时序推理过程，从而增强时间一致性。2) 前向监督策略：使用真实目标特征作为锚点来约束推理管道，引导预测输出趋向真实目标分布，抑制上下文推理过程中的漂移。3) 高效状态建模：采用压缩-重建机制提取目标核心特征，消除帧间冗余信息，防止无效的上下文关联。这三种机制共同有效缓解了传统时序建模中的上下文关联发散问题。", "conclusion": "实验结果显示，RSTrack在多个基准数据集上达到了最先进的性能，同时保持了实时运行速度。我们的代码可从this https URL 获取。"}
{"llm_update_time": "20250723", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.16193", "html_url": "https://arxiv.org/abs/2507.16193", "title": "LMM4Edit：基于LMM的多模态图像编辑基准评估", "title_en": "LMM4Edit: Benchmarking and Evaluating Multimodal Image Editing with LMMs", "authors": "Zitong Xu,Huiyu Duan,Bingnan Liu,Guangji Ma,Jiarui Wang,Liu Yang,Shiqi Gao,Xiaoyu Wang,Jia Wang,Xiongkuo Min,Guangtao Zhai,Weisi Lin", "background": "随着文本引导的图像编辑（TIE）技术的迅速发展，图像可以通过文本提示进行修改。然而，现有的TIE模型在保持图像质量、编辑对齐和与原始图像的一致性之间难以平衡，这限制了它们的实际应用。现有的TIE评估基准和度量标准在规模或人类感知方面存在局限性。为此，该研究提出了EBench-18K，这是一个大规模的图像编辑基准，包含18000个经过精细人类偏好注释的编辑图像，用于评估TIE性能。", "innovation": "EBench-18K包括1080张原始图像、17种最先进的TIE模型生成的18000多个编辑图像、55000多个从三个评估维度得出的平均意见分数（MOSs）以及18000多个问答（QA）对。基于此基准，研究采用了优秀的线性混合模型（LMMs）来评估编辑图像，并提出了LMM4Edit，这是一种基于LMM的度量标准，可以全方位评估图像编辑模型的感知质量、编辑对齐、属性保留和任务特定的QA准确性，结果与人类偏好高度一致，展示了优秀的通用性能。", "conclusion": "该研究通过EBench-18K提出了LMM4Edit评估度量标准，能够全面评估图像编辑模型的感知质量、编辑对齐、属性保留和任务特定的QA准确性，并且与人类偏好高度一致，展示了良好的通用性能。"}
{"llm_update_time": "20250723", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.16114", "html_url": "https://arxiv.org/abs/2507.16114", "title": "在卷积神经网络中用于计算机视觉问题的正交可调小波单元带阻能量约束", "title_en": "Stop-band Energy Constraint for Orthogonal Tunable Wavelet Units in Convolutional Neural Networks for Computer Vision problems", "authors": "An D. Le,Hung Nguyen,Sungbal Seo,You-Suk Bae,Truong Q. Nguyen", "background": "该研究针对图像分类和纹理丰富的数据集上的异常检测问题，探讨了如何通过引入带阻能量约束来改进正交可调小波单元在卷积神经网络（CNN）中的表现。在正交调谐小波单元具有晶格结构的滤波器中加入带阻能量约束，旨在提升CNN在计算机视觉任务中的性能。", "innovation": "该方法通过在ResNet-18、ResNet-34等深度学习模型中集成带阻能量约束，优化了卷积、池化和下采样操作。实验结果表明，此方法在CIFAR-10数据集上提高了2.48%的准确率，在描述性纹理数据集上提高了13.56%的准确率，并在MVTec榛子异常检测任务中也表现出与现有方法相当甚至更好的效果。", "conclusion": "该研究提出的方法通过引入带阻能量约束，显著提升了正交可调小波单元在CNN中的表现，特别是在图像分类和异常检测任务中的应用。该方法在多个数据集上的实验结果表明，该方法不仅能够提高分类准确率，还能够在异常检测任务中表现出色。"}
{"llm_update_time": "20250723", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.16154", "html_url": "https://arxiv.org/abs/2507.16154", "title": "LSSGen：利用流和扩散的潜在空间缩放实现高效的文本到图像生成", "title_en": "LSSGen: Leveraging Latent Space Scaling in Flow and Diffusion for Efficient Text to Image Generation", "authors": "Jyun-Ze Tang,Chih-Fan Hsu,Jeng-Lin Li,Ming-Ching Chang,Wei-Chao Chen", "background": "流模型和扩散模型在文本到图像生成中表现出色，通过迭代去噪过程生成逼真的图像。常见的加速合成策略是在较低分辨率下进行早期去噪，但传统的像素空间下采样和上采样方法常常引入图像伪影和失真，导致最终图像质量下降。", "innovation": "提出了一种名为LSSGen的新框架，该框架可以直接在潜在空间中执行分辨率缩放，而无需修改Transformer或U-Net架构。LSSGen提升了效率和视觉质量，同时支持灵活的多分辨率生成。", "conclusion": "综合性评估表明，LSSGen在文本和图像对齐以及感知质量方面显著优于传统缩放方法。生成1024x1024图像时，LSSGen的速度相近但得分提高了246%的TOPIQ分数。"}
{"llm_update_time": "20250723", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.16151", "html_url": "https://arxiv.org/abs/2507.16151", "title": "SPACT18：具备互补RGB和热成像模态的基于刺激的人类动作识别基准数据集", "title_en": "SPACT18: Spiking Human Action Recognition Benchmark Dataset with Complementary RGB and Thermal Modalities", "authors": "Yasser Ashraf,Ahmed Sharshar,Velibor Bojkovic,Bin Gu", "background": "刺针相机是一种基于生物启发的视觉传感器，每个像素通过积累光强度来异步发出刺针信号，这种技术提供了超高的能源效率和卓越的时间分辨率。与仅记录光强变化来捕捉运动的事件相机不同，刺针相机提供了更加精细的空间-时间分辨率和连续变化的更精确表示。但在刺针神经网络领域，尚缺乏专门的视频动作识别（Video Action Recognition, VAR）数据集，特别是结合了刺针数据、RGB和热成像模态的数据集，来全面评估和基准测试SNNs。", "innovation": "本文首次提出了一个使用刺针相机记录视频动作识别（VAR）数据集，该数据集包含同步的RGB和热成像模态，旨在为刺针神经网络提供一个独特的多模态视频理解平台。通过保留刺针数据的固有稀疏性和时间精度，本研究为直接比较刺针、热成像和RGB模态提供了宝贵资源，有助于推动高效、超低功耗的视频理解研究，特别是在基于刺激数据的动作识别任务方面。", "conclusion": "通过引入全新的数据集，本文将推动刺针神经网络在能源效率和超低功耗视频理解技术的应用研究，特别是在基于刺激数据的动作识别任务上，为评估SNNs在处理此类任务上的表现提供了新的基准。"}
{"llm_update_time": "20250723", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.16251", "html_url": "https://arxiv.org/abs/2507.16251", "title": "HoliTracer：从大尺度遥感影像中全面提取地理对象", "title_en": "HoliTracer: Holistic Vectorization of Geographic Objects from Large-Size Remote Sensing Imagery", "authors": "Yu Wang,Bo Dang,Wanchun Li,Wei Chen,Yansheng Li", "background": "随着遥感影像（RSI）分辨率的不断提高，大尺寸RSI已成为高精度地理对象矢量图测绘的重要数据来源。现有方法通常局限于处理小图像块，这往往会导致上下文信息的丢失和矢量输出的碎片化。", "innovation": "本文提出HoliTracer框架，首次用于从大尺寸遥感影像中全面提取矢量化地理对象。HoliTracer通过使用具有局部到全局注意力机制的Context Attention Net（CAN）增强大尺寸RSI的分割，并通过Mask Contour Reformer（MCR）重建多边形和Polygon Sequence Tracer（PST）跟踪顶点，实现了一种鲁棒的管道，从而实现全面矢量化。实验结果表明，HoliTracer在性能上优于现有最先进的方法。", "conclusion": "大量实验表明，HoliTracer在建筑物、水域和道路等大尺寸RSI数据集上表现优于最先进的方法，并全面地从大尺度遥感影像中提取了地理对象。"}
{"llm_update_time": "20250723", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.16224", "html_url": "https://arxiv.org/abs/2507.16224", "title": "LDRFusion: 一种以LiDAR为主导的多模态 refinement 框架用于3D物体检测", "title_en": "LDRFusion: A LiDAR-Dominant multimodal refinement framework for 3D object detection", "authors": "Jijun Wang,Yan Wu,Yujian Mo,Junqiao Zhao,Jun Yan,Yinghao Hu", "background": "现有的LiDAR-摄像机融合方法在3D物体检测方面已经取得了显著成果。前人的方法通常通过深度补全手段构建空间伪点云，作为辅助输入，并采用提案-精炼框架生成检测结果。然而，引入伪点云不可避免地带入噪声，可能导致预测不准确。鉴于每种模态的不同作用和可靠性水平，本文提出了LDRFusion，一种新的LiDAR主导的两阶段精炼框架，用于多传感器融合。", "innovation": "LDRFusion框架首次提出了一种全新的方法，通过两阶段精炼，在第一个阶段依靠LiDAR生成准确的提案，之后在第二阶段引入伪点云以检测具有挑战性的实例。此外，提出了一种分层伪点残差编码模块，用于编码具有特性和位置残差的邻域集合。", "conclusion": "实验结果表明，LDRFusion框架在KITTI数据集上的表现优越，能够在多个类别和难度级别上获得强大性能。"}
{"llm_update_time": "20250723", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.16213", "html_url": "https://arxiv.org/abs/2507.16213", "title": "为多粒度多功能感知提升视觉大型语言模型", "title_en": "Advancing Visual Large Language Model for Multi-granular Versatile Perception", "authors": "Wentao Xiang,Haoxian Tan,Cong Wei,Yujie Zhong,Dengjie Li,Yujiu Yang", "background": "计算机视觉领域中的感知是一个基础任务，它可以被系统地分为四个不同类别，基于两个维度：预测类型和指令类型。现有研究往往只关注这些潜在组合中的一小部分，这限制了它们在各种环境中的适用性和多功能性。", "innovation": "本文提出了MVP-LM框架，这是一种结合视觉大型语言模型的多粒度和多功能感知框架。MVP-LM框架具有创新的多粒度解码器，并采用启发于CoT的综合数据集策略，能够无缝地跨多种任务进行监督微调，包括但不限于全景分割、检测、语义标注和指向表达分割。此外，还有查询增强策略，旨在利用VLLMs的解码和生成能力。", "conclusion": "广泛的实验证明了该框架的有效性。代码可以在如下链接中获取：this https URL"}
{"llm_update_time": "20250723", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.16254", "html_url": "https://arxiv.org/abs/2507.16254", "title": "鱼眼对象检测中的边缘案例合成：一种数据导向的方法", "title_en": "Edge-case Synthesis for Fisheye Object Detection: A Data-centric Perspective", "authors": "Seunghyeon Kim,Kyeongryeol Go", "background": "鱼眼相机引入了显著的畸变，给通过传统数据集训练的对象检测模型带来了独特的挑战。这项工作旨在通过系统地改进检测性能，重点关注模型的盲区识别这一关键问题。通过详细的错误分析，我们确定了诸如混淆类对、边缘畸变和欠代表的背景场景等关键边缘情况。然后，我们直接通过边缘案例合成来解决这些问题。我们微调了一种图像生成模型，并使用精心设计的提示来生成模拟现实世界失败模式的图像。这些合成图像通过高质量检测器伪标签后被纳入训练中。这种方法带来了持续的性能提升，突显了在专门领域如鱼眼对象检测中深入理解数据并有针对性地修复其缺陷的重要性。", "innovation": "我们提出了一种数据导向的管道，通过直接合成边缘案例来系统性地提升检测性能。通过微调图像生成模型并使用精心构造的提示来生成模拟真实世界失败模式的图像，并将其伪标签后纳入训练中。这种方法能一致地提高检测性能，并强调了理解数据和针对性修复其缺陷在专业领域中的重要性。", "conclusion": "我们的方法在鱼眼对象检测中带来了持续的性能提升，强调了深入理解数据和针对性修复其缺陷的重要性。"}
{"llm_update_time": "20250723", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.16238", "html_url": "https://arxiv.org/abs/2507.16238", "title": "正面风格积累：一种用于联邦DG-ReID的风格筛选与持续利用框架", "title_en": "Positive Style Accumulation: A Style Screening and Continuous Utilization Framework for Federated DG-ReID", "authors": "Xin Xu(1),Chaoyue Ren(1),Wei Liu(1),Wenke Huang(2),Bin Yang(2),Zhixi Yu(1),Kui Jiang(3) ((1) Wuhan University of Science and Technology, (2) Wuhan University, (3) Harbin Institute of Technology)", "background": "现有的联邦域适应重识别方法主要通过风格变换提高样本多样性，进而增强模型泛化性能，但并非所有风格都对泛化性能有益。", "innovation": "提出了一个风格筛选与持续利用（SSCU）框架，包括一种引导型动态风格记忆（GGDSM）用于筛选和累积生成的正面风格，以及一种风格记忆识别损失和协作风格训练策略，旨在有效动员正面风格并保障其持续和全面的应用，从而在源域和目标域中提升模型的泛化性能。", "conclusion": "实验结果表明，该方法在源域和目标域中均优于现有方法。"}
{"llm_update_time": "20250723", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.16144", "html_url": "https://arxiv.org/abs/2507.16144", "title": "LongSplat：长序列图像中的在线通用3D高斯点绘制", "title_en": "LongSplat: Online Generalizable 3D Gaussian Splatting from Long Sequence Images", "authors": "Guichen Huang,Ruoyu Wang,Xiangjun Gao,Che Sun,Yuwei Wu,Shenghua Gao,Yunde Jia", "background": "3D Gaussian Splatting可以实现高质量的新视角合成，但在长序列在线场景中的应用仍然受到限制。现有方法要么依赖于慢速每场景优化，要么不能提供有效的增量更新，这阻碍了持续性能的提升。", "innovation": "本文提出了一种名为LongSplat的在线实时3D高斯重建框架，特别适合长序列图像输入。该框架的核心思想是一个流式更新机制，该机制能够增量地整合当前视角观察结果并选择性地压缩冗余的历史高斯。我们引入了一种称为Gaussian-Image Representation (GIR)的表示方法，它将3D高斯参数编码为结构化的、图像形式的2D格式。GIR不仅支持高效融合当前视角和历史高斯，还能有意识地压缩冗余，从而实现在线重建和对长序列模式的适应，同时控制内存和计算成本。此外，通过利用现有的图像压缩方法，指导生成更紧凑且高质量的3D高斯。", "conclusion": "长序列图像中的LongSplat实现了实时新型视角合成，在保证实时性的同时减少了44%的高斯点预测，达到最先进的效率-质量权衡。"}
{"llm_update_time": "20250723", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.16228", "html_url": "https://arxiv.org/abs/2507.16228", "title": "MONITRS：通过遥感的多重模式自然事件观察", "title_en": "MONITRS: Multimodal Observations of Natural Incidents Through Remote Sensing", "authors": "Shreelekha Revankar,Utkarsh Mall,Cheng Perng Phoo,Kavita Bala,Bharath Hariharan", "background": "自然灾害每年都给社区和基础设施带来破坏性的损害。有效的灾害响应受到了在事件发生前后进入受影响区域的难度限制。遥感技术允许我们以远程方式监测自然灾害。近年来，计算机视觉和深度学习的进步有助于自动化卫星图像分析，但它们仍然受限于专注于特定类型灾害、依赖手动专家解释，并缺乏具有足够时间粒度或自然语言注解的数据集来跟踪灾害进展。", "innovation": "我们引入了MONITRS，这是一个多模态数据集，包含超过10,000个联邦应急管理局灾害事件的时空卫星图像和从新闻文章中获得的自然语言注解，同时附有地理编码地点和问答对。我们证明，对我们的数据集进行现有MLLMs的微调可以显著提高灾害监测任务的性能，建立起机器学习辅助灾害响应系统的基准。", "conclusion": "通过MONITRS数据集，我们展示了微调现有MLLMs可以显著提高灾难监测任务的性能，为机器学习辅助灾害响应系统设立了新的基准。"}
{"llm_update_time": "20250723", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.16287", "html_url": "https://arxiv.org/abs/2507.16287", "title": "超越标签语义：基于语言引导的动作解剖学方法在少量动作识别中的应用", "title_en": "Beyond Label Semantics: Language-Guided Action Anatomy for Few-shot Action Recognition", "authors": "Zefeng Qian,Xincheng Yao,Yifei Huang,Chongyang Zhang,Jiangyong Ying,Hong Sun", "background": "少样本动作识别（FSAR）旨在使用每个类别的少量标注样本对视频中的人类动作进行分类。由于训练数据稀缺，近期研究致力于融合其他模态，尤其是文本。然而，动作标签单独使用无法充分运用动作在不同阶段展现出的细微姿态变化、运动动态和物体交互这三种内在知识。", "innovation": "本文提出了一种名为LGA（Language-Guided Action Anatomy）的新框架，利用大型语言模型（LLM）分解动作标签下的核心特征，提取丰富的时空线索。具体地，通过提示预训练的LLM将动作标签分解为原子动作描述序列，关注动作的三大核心要素（主体、动作和对象）；视频则通过视觉解剖模块分割动作以捕捉动作的序列结构。通过细粒度融合技术和多模态匹配机制，LGA在少样本场景中表现优异。", "conclusion": "实验结果显示，LGA在多个FSAR基准测试中达到了最先进的性能。"}
{"llm_update_time": "20250723", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.16290", "html_url": "https://arxiv.org/abs/2507.16290", "title": "Dens3R: 一种用于3D几何预测的基础模型", "title_en": "Dens3R: A Foundation Model for 3D Geometry Prediction", "authors": "Xianze Fang,Jingnan Gao,Zhe Wang,Zhuo Chen,Xingyu Ren,Jiangjing Lyu,Qiaomu Ren,Zhonglei Yang,Xiaokang Yang,Yichao Yan,Chengfei Lyu", "background": "最近在密集3D重建方面的进展显著，但实现统一的几何预测仍是一个重大挑战。现有方法大多只能从输入图像中预测单一的几何量，而深度、表面法线和平面图等几何量之间是相互关联的，单独估计这些量往往无法保证一致性和准确性，从而限制了预测的准确性和实际应用。因此，探索一种能够明确建模不同几何属性之间结构耦合的统一框架，以实现联合回归，成为了迫切需要解决的问题。", "innovation": "本文提出了Dens3R，一种用于联合几何密集预测的基础模型，适用于多种下游任务。该模型采用两阶段训练框架，逐步建立通用化且内在不变的点图表示。具体来说，Dens3R设计了一个轻量的共享编码器-解码器骨干，并引入位置插值旋量位置编码，以保持表达能力同时增强对高分辨率输入的鲁棒性。通过将图像配对匹配特征与内在不变性建模相结合，Dens3R能够准确回归表面法线和深度等多个几何量，并在单视图和多视图输入下实现几何一致性感知。此外，我们还提出了一种后处理流水线支持几何一致的多视图推理。大规模实验表明，Dens3R在各种密集3D预测任务中表现优异，并且具有更广泛的应用潜力。", "conclusion": "本文提出了一种用于3D几何预测的基础模型Dens3R，它利用两阶段训练框架和特定设计的网络结构，实现了多种几何量的准确回归和几何一致性感知。Dens3R模型不仅在现有任务中表现优异，还具有扩展到更多应用场景的潜力。"}
{"llm_update_time": "20250723", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.16119", "html_url": "https://arxiv.org/abs/2507.16119", "title": "通用小波单元在3D视网膜层分割中的应用", "title_en": "Universal Wavelet Units in 3D Retinal Layer Segmentation", "authors": "An D. Le,Hung Nguyen,Melanie Tran,Jesse Most,Dirk-Uwe G. Bartsch,William R Freeman,Shyamanga Borooah,Truong Q. Nguyen,Cheolhong An", "background": "这篇文章是首次将可调小波单元（UwUs）应用于从光学相干断层扫描（OCT）体数据中进行3D视网膜层分割的研究。研究旨在克服传统最大池化方法的局限性，通过将三种基于小波的下采样模块（OrthLattUwU、BiorthLattUwU和LS-BiorthLattUwU）集成到一个运动校正的MGU-Net架构中，进一步提高分割效果。", "innovation": "研究创新点在于将三种不同的小波变换模块（OrthLattUwU、BiorthLattUwU和LS-BiorthLattUwU）集成到一个运动矫正的多层卷积神经网络（MGU-Net）中，这些模块使用可学习的格子滤波器银行来保留低频和高频特征，增强空间细节和结构一致性。", "conclusion": "在雅各布视网膜中心（JRC）OCT数据集上的实验表明，本文框架在准确性和Dice分数上有显著提高，尤其是LS-BiorthLattUwU，表明可调小波滤波器在体积医学图像分割中的优势。"}
{"llm_update_time": "20250723", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.16279", "html_url": "https://arxiv.org/abs/2507.16279", "title": "MAN++：为视觉任务中的监督局部学习扩展动量辅助网络", "title_en": "MAN++: Scaling Momentum Auxiliary Network for Supervised Local Learning in Vision Tasks", "authors": "Junhao Su,Feiyu Zhu,Hengyu Shi,Tianyang Han,Yurui Qiu,Junfeng Luo,Xiaoming Wei,Jialin Gao", "background": "深度学习通常依赖端到端反向传播进行训练，这一方法存在诸如优化参数过程中更新锁定问题、高GPU内存消耗和与生物学不相符等问题。相比之下，监督局部学习通过将网络分割为多个局部块并为每个块设计独立的辅助网络来更新块，来减轻这些挑战。但由于梯度只在各自的局部块内传播，这导致性能下降，无法完全取代端到端反向传播。为了克服这些限制并促进跨块信息流，我们提出了动量辅助网络增强版（MAN++）。", "innovation": "MAN++引入了一种动态交互机制，通过采用相邻块参数的指数移动平均（EMA），增强了网络内各块之间的通信。更新的辅助网络通过EMA有效衔接块间的信息差距。同时，为了克服直接应用EMA参数可能导致的特征差异问题，我们引入了一个可学习的缩放偏差来平衡特征差异，从而进一步提升性能。实验表明，MAN++在图像分类、物体检测和图像分割等任务中达到了与端到端训练相当的性能，且显著减少了GPU内存消耗。因此，MAN++为监督局部学习提供了新的视角，并提出了与传统的训练方法相比更具可行性的替代方案。", "conclusion": "MAN++通过引入动态交互机制来改进监督局部学习，允许更有效的块间信息传输，同时引入了可学习的缩放偏差来平衡局部块间的特征差异。实验验证了MAN++在多种视觉任务中能够与端到端训练达到类似甚至更好的性能，同时显著减少GPU内存消耗。因此，MAN++为监督局部学习提供了一种新的方法，可能成为传统训练方法的替代选择。"}
{"llm_update_time": "20250723", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.16318", "html_url": "https://arxiv.org/abs/2507.16318", "title": "M-SpecGene: Generalized Foundation Model for RGBT Multispectral Vision", "title_en": "M-SpecGene: Generalized Foundation Model for RGBT Multispectral Vision", "authors": "Kailai Zhou,Fuqiang Yang,Shixian Wang,Bihan Wen,Chongde Zi,Linsen Chen,Qiu Shen,Xun Cao", "background": "RGB-Thermal (RGBT)多光谱视觉在复杂环境中的稳健感知至关重要。目前大多数RGBT任务依赖于人工定制模型以学习特定任务的表示，这种方法受到人工归纳偏见、模态偏见和数据瓶颈的限制。考虑到RGBT数据中信息不平衡的独特性质，引入了跨模态结构稀疏(CMSS)度量，以量化双模态之间的信息密度，从而促进灵活、自适应的预训练过程。该论文旨在通过自监督学习大型广泛数据来构建一个通用的RGBT多光谱基础模型M-SpecGene，解决上述问题，并提高模型在多个数据集上的通用性。", "innovation": "该论文提出了一个名为M-SpecGene的通用RGBT多光谱基础模型。M-SpecGene在大规模广域数据上以自监督的方式学习模态不变的表示。通过引入跨模态结构稀疏(CMSS)度量和GMM-CMSS渐进性遮蔽策略，M-SpecGene能够更好地应对RGBT数据中的信息不平衡问题，实现从简到难、以对象为中心的灵活预训练过程。", "conclusion": "全面的实验验证了M-SpecGene在四个RGBT下游任务的十一组数据集上的广泛适用性。该模型提供了一种新的多光谱融合视角，将前人针对具体问题的研究整合到统一的框架中。相关代码将在指定链接处开源。"}
{"llm_update_time": "20250723", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.16240", "html_url": "https://arxiv.org/abs/2507.16240", "title": "Scale Your Instructions: Enhance the Instruction-Following Fidelity of Unified Image Generation Model by Self-Adaptive Attention Scaling", "title_en": "Scale Your Instructions: Enhance the Instruction-Following Fidelity of Unified Image Generation Model by Self-Adaptive Attention Scaling", "authors": "Chao Zhou,Tianyi Wei,Nenghai Yu", "background": "近期统一的图像生成模型（如OmniGen）的发展使得在一个框架内处理各种图像生成和编辑任务成为可能，接受多模态和交错形式的文本和图像输入。这种统一结构消除了对文本编码器的需求，大大降低了模型的复杂性，并标准化了各种图像生成和编辑任务，使其更加用户友好。然而，这类模型在处理包含多个子指令的文本指令时表现出忽视指令的问题。", "innovation": "为了探索这一问题，作者进行了输入扰动分析以确定关键步骤和层。通过检查这些关键步骤的跨注意力图，发现被忽视的子指令与输入图像的激活之间存在显著冲突。为此，作者提出了自适应注意力缩放（Self-Adaptive Attention Scaling, SaaS）方法，利用相邻时间步之间跨注意力的一致性来动态调整每个子指令的注意力激活。SaaS提升了指令遵循的准确性，且无需额外训练或测试时优化。实验结果证实SaaS的有效性，在基于指令的图像编辑和视觉条件下的图像生成任务中表现出更优的指令遵循准确性。", "conclusion": "实验结果验证了SaaS的有效性，显示出比现有方法更优的指令遵循准确性。代码已发布于此 https URL。"}
{"llm_update_time": "20250723", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.16341", "html_url": "https://arxiv.org/abs/2507.16341", "title": "使用视频扩散模型解决高性能面部再现中的大姿态挑战", "title_en": "Navigating Large-Pose Challenge for High-Fidelity Face Reenactment with Video Diffusion Model", "authors": "Mingtao Guo,Guanyu Xing,Yanci Zhang,Yanli Liu", "background": "面部再现旨在通过将驱动视频中的动作转移到静态源图像上，生成逼真的说话头视频，同时保持源身份。现有的基于显式或隐式关键点的方法已经展示了潜力，但在处理大姿态变化时，因扭曲伪影或粗略面部地标限制而遇到困难。", "innovation": "提出了Face Reenactment Video Diffusion模型（FRVD），这是一种新型框架，用于大姿态变化下的高质量面部再现。该方法首先使用运动提取器从源和驱动图像中提取隐式面部关键点，以表示精细运动并进行运动对齐。为了应对扭曲带来的降级，引入了一个扭曲特征映射器（WFM），它将扭曲的源图像映射到预训练的图像到视频（I2V）模型的运动感知潜在空间中。", "conclusion": "大量的实验表明，FRVD在姿态准确性、身份保真度和视觉质量等方面超越了现有方法，特别是在极端姿态变化的具有挑战性的场景中表现尤为突出。"}
{"llm_update_time": "20250723", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.16330", "html_url": "https://arxiv.org/abs/2507.16330", "title": "利用Aria智能眼镜自视点摄像头在复杂环境条件下进行场景文本检测与识别的研究", "title_en": "Scene Text Detection and Recognition \"in light of\" Challenging Environmental Conditions using Aria Glasses Egocentric Vision Cameras", "authors": "Joseph De Mathia,Carlos Francisco Moreno-García", "background": "随着可穿戴技术的革新，场景文本检测与识别（STDR）在自视点视角下成为了理想的解决方案。本文基于Meta的Project Aria智能眼镜，研究了光照、距离、分辨率等环境变量对实时场景中STDR算法性能的影响，并构建了在受控环境下采集的数据集来评估两种OCR管道性能：EAST配CRNN和EAST配PyTesseract。研究结果表明，分辨率和距离显著影响识别精度，而光照的影响更为不确定。值得注意的是，图像放大作为预处理技术，显著降低了字符错误率（CER）.", "innovation": "引入了在受控条件下新构建的场景文本检测与识别数据集；评估了EAST配CRNN和EAST配PyTesseract两种OCR管道；利用图像放大作为关键预处理技术；实验显示图像放大技术可将字符错误率（CER）从0.65降低至0.48；通过结合眼球追踪实现处理效率优化，专注于用户的注意力区域；提出了在实际复杂环境下评估STDR性能的新基准，并为适应性强、用户感知的AR系统的开发奠定了基础，意在激发为辅助与研究应用，如资产检测和营养分析提供更加坚固、上下文感知的文本识别技术研究方向.", "conclusion": "本文不仅在实际环境中对STDR性能进行了基准测试，还为智能眼镜辅助的自视点AR系统适应性和用户的感知提供了新方向。我们的贡献旨在激发未来在强壮的上下文感知文本识别技术方面的研究，特别是在辅助和研究导向的应用领域."}
{"llm_update_time": "20250723", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.16260", "html_url": "https://arxiv.org/abs/2507.16260", "title": "ToFe：用于高效视觉变换器推断的滞后令牌冻结和重用", "title_en": "ToFe: Lagged Token Freezing and Reusing for Efficient Vision Transformer Inference", "authors": "Haoyue Zhang,Jie Zhang,Song Guo", "background": "尽管视觉变压器(ViT)在各种视觉任务中表现出色，但其自注意力计算成本高昂，阻碍了其在资源受限设备上的部署。现有方法通过在前向传播过程中丢弃不重要的令牌来提升变压器模型的效率，但这些方法不能 reversible 地处理不重要令牌，即这些令牌在后续模块中无法被重新使用。鉴于变压器模块之间关注的信息不同，在早期模块中被冻结的令牌可能在后续模块中有用。为了适应资源受限设备，必须在模型性能和计算开销之间找到平衡。因此，本文提出了一个名为ToFe的新型令牌冻结与重用框架，该框架在每个阶段识别重要令牌并暂时冻结不重要的令牌，以便它们在后部模块中重新使用。", "innovation": "ToFe引入了一个预测模块和一个恢复模块，用于令牌识别和冻结令牌的恢复。通过计算预算感知的端到端训练，ToFe可以在每个模块中适应性地处理必要的令牌，从而降低计算成本同时保持性能。实验结果表明，ToFe可以将LV-ViT模型的计算成本降低50%且Top-1精度下降不到2%，相比最先进的方法实现了更好的性能和复杂度之间的权衡。", "conclusion": "ToFe提供了一种新的方法来平衡视觉变压器的性能和计算开销，通过滞后令牌冻结和重用来提高计算效率。它已经在LV-ViT模型上进行了验证，证明了其在保持性能的同时能够显著降低计算成本。"}
{"llm_update_time": "20250723", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.16385", "html_url": "https://arxiv.org/abs/2507.16385", "title": "STAR: 星空领域超分辨率基准数据集", "title_en": "STAR: A Benchmark for Astronomical Star Fields Super-Resolution", "authors": "Kuo-Cheng Wu,Guohang Zhuang,Jinyang Huang,Xiang Zhang,Wanli Ouyang,Yan Lu", "background": "超分辨率（SR）技术通过实现经济高效的高分辨率图像捕获，对于探测遥远的天体物体和精确定位天体结构至关重要。然而，现有的天文学超分辨率（ASR）数据集存在三个关键限制：通量不一致、样本裁剪设置和数据多样性不足，这些都显著阻碍了ASR的发展。", "innovation": "本文提出STAR，这是一个大规模的天文学超分辨率数据集，包含54,738对通量一致的星域图像对，涵盖广阔的天区。这些图像对结合了哈勃太空望远镜的高分辨率观测数据和通过通量保持的数据生成流水线生成的物理真实低分辨率对应物，以系统地开发域级别的ASR模型。此外，STAR还提供了新颖的通量误差（FE）以评估SR模型，提出了基于此基准的通量不变超分辨率（FISR）模型，该模型在新型设计的通量一致性度量下优于多种SR领先方法，表明该方法对天体物理学的重要性。", "conclusion": "广泛的实验验证了本文提出的方法的有效性和数据集的价值。相关代码和模型已公开可用。"}
{"llm_update_time": "20250723", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.16257", "html_url": "https://arxiv.org/abs/2507.16257", "title": "高质量文本，稳健视觉：语言在增强视觉语言模型视觉稳健性中的作用", "title_en": "Quality Text, Robust Vision: The Role of Language in Enhancing Visual Robustness of Vision-Language Models", "authors": "Futa Waseda,Saku Sugawara,Isao Echizen", "background": "预训练的视觉语言模型（VLMs），例如CLIP，在零样本任务中广泛应用，包括图像分类等，因而防范针对这些模型的对抗性攻击至关重要。然而，现有的鲁棒微调对抗训练方法大多忽略了语言在提升视觉鲁棒性方面的关键作用。已有的方法主要分为监督和非监督两种，这两种方法各有局限性：监督方法容易过拟合于训练数据中的对象类别，而非监督方法则缺乏语义指导，不能很好地抵御文本导向的对抗性攻击。", "innovation": "为了解决上述问题，本文提出了Quality Text-guided Adversarial Fine-Tuning（QT-AFT），该方法利用高质量的文本，在训练过程中引导对抗性例子偏离图像中的多种语义，从而让视觉编码器在面对对抗噪声时更加健壮地识别图像特征，实现更广泛的任务鲁棒性。QT-AFT 方法克服了此前方法的两个主要缺陷：监督对抗训练的过拟合问题以及非监督对抗训练中缺乏语义意识的问题，从而达到了在16个零样本数据集上的最先进的对抗鲁棒性及干净准确性。同时还深入探讨了语言在提升视觉模型鲁棒性方面的作用，例如将对象属性的描述与对象名称一起描述，可以增强零样本情况下的鲁棒性", "conclusion": "通过综合研究，本文揭示了语言在增强视觉稳健性方面的重要作用，指出未来的视觉表征学习应更加重视高质量的语言监督。"}
{"llm_update_time": "20250723", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.16389", "html_url": "https://arxiv.org/abs/2507.16389", "title": "从平 faced 圆：基于表面 fMRI 和皮层结构的脑解码再定义", "title_en": "From Flat to Round: Redefining Brain Decoding with Surface-Based fMRI and Cortex Structure", "authors": "Sijin Yu,Zijiao Chen,Wenxuan Wu,Shengxian Chen,Zhongliang Liu,Jingxin Nie,Xiaofen Xing,Xiangmin Xu,Xin Zhang", "background": "基于功能磁共振成像(fMRI)重建视觉刺激的人脑活动连接神经科学和计算机视觉，通过解码神经表示。然而，现有方法常常忽略关键的脑结构-功能关系，压缩了空间信息并忽视了个体解剖差异性变化。", "innovation": "提出了1) 一种新颖的球体分词器，显式地将 fMRI 信号建模为皮质表面上的空间连贯的2D球形数据；2) 结合结构磁共振成像(sMRI) 数据，允许个性化编码个体解剖变异性；3) 一种正样本混合策略，有效利用与相同视觉刺激相关的多个 fMRI 扫描。这些创新提高了重建准确性、生物解释性以及跨个体的一般性。实验结果表明，相比于当前最先进的方法，我们的方法表现出更优的重构性能，强调了我们生物启发式方法的有效性和可解释性。", "conclusion": "这些创新增强了重建准确性、生物解释性以及跨个体的一般性。实验表明，该方法相较于最先进的方法具有更好的重构性能，证明了我们生物启发式方法的有效性和可解释性。"}
{"llm_update_time": "20250723", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.16362", "html_url": "https://arxiv.org/abs/2507.16362", "title": "LPTR-AFLNet：轻量级统一的中文车牌纠偏和识别网络", "title_en": "LPTR-AFLNet: Lightweight Integrated Chinese License Plate Rectification and Recognition Network", "authors": "Guangzhu Xu,Pengcheng Zuo,Zhi Ke,Bangjun Lei", "background": "中国车牌识别（CLPR）在复杂且不受约束的环境中面临着诸多挑战，尤其是由于不同拍摄角度造成的视角失真和单行、双行车牌的纠正问题。鉴于边缘设备的计算资源有限，开发一种低复杂度的端到端集成网络对于实现实时和高效的部署至关重要。为了应对这些挑战，该研究探讨了一种轻量级的统一网络LPTR-AFLNet，它结合了透视变换纠正模块（PTR）与优化的车牌识别网络AFLNet，有效地利用识别输出作为弱监督信号来指导纠偏过程，确保了准确的视角失真纠正。", "innovation": "该研究提出了LPTR-AFLNet网络，这是一种结合了透视矫正模块（PTR）与优化的车牌识别网络AFLNet的轻量级统一网络。网络通过利用识别输出作为弱监督信号来有效指导纠偏过程，确保准确的视角失真纠正。此外，为了提高识别精度，研究引入了对LPRNet的一些改进，包括改进的注意力模块以减少相似字符之间的混淆，并使用Focal Loss来处理训练中的类别不平衡问题。实验结果表明，该方法在纠正视角失真和识别双行车牌图像方面表现出色，具有高水平的识别准确率，并且在较低的中端GPU平台上运行时间小于10毫秒，显示出其实用性和广泛适用性。", "conclusion": "实验结果证实，LPTR-AFLNet在网络纠偏和识别双行车牌图像方面表现出色，具有高识别准确性，并且在较低的中端GPU平台上运行时间小于10毫秒，展示了其实用性和广泛适用性。"}
{"llm_update_time": "20250723", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.16310", "html_url": "https://arxiv.org/abs/2507.16310", "title": "MotionShot：跨对象自适应运动转移以生成文本到视频", "title_en": "MotionShot: Adaptive Motion Transfer across Arbitrary Objects for Text-to-Video Generation", "authors": "Yanchen Liu,Yanan Sun,Zhening Xing,Junyao Gao,Kai Chen,Wenjie Pei", "background": "现有的文本到视频方法在将运动平滑地从参考对象转移到具有显著外观或结构差异的目标对象时存在困难。", "innovation": "提出了MotionShot，这是一种无需训练的框架，能够以精细的方式解析参考-目标对应关系，从而实现高保真度的运动转移，同时保持外观的一致性。具体而言，MotionShot首先通过语义特征匹配确保参考对象和目标对象的高层对齐，然后通过参考对象到目标对象的形状调整建立低层面的形态对齐。通过使用时序注意力编码运动，MotionShot可以在存在显著的外观和结构差异的情况下，仍能一致地转移运动。", "conclusion": "广泛的实验表明，MotionShot可以在存在显著的外观和结构差异的情况下，一致地转移运动。项目页面可访问：this https URL"}
{"llm_update_time": "20250723", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.16342", "html_url": "https://arxiv.org/abs/2507.16342", "title": "Mamba-OTR: 基于Mamba架构的无修剪第一人称视频在线拾取和释放检测解决方案", "title_en": "Mamba-OTR: a Mamba-based Solution for Online Take and Release Detection from Untrimmed Egocentric Video", "authors": "Alessandro Sebastiano Catinello,Giovanni Maria Farinella,Antonino Furnari", "background": "该研究针对在线检测无修剪第一人称视频中的拾取和释放（OTR）问题。这个问题具有显著的标签不平衡性，标注的正样本稀少，且需要精确的时空预测。此外，为了适用于真实世界的应用场景，方法需要具备高效性。", "innovation": "该研究提出了Mamba-OTR模型，这是一种基于Mamba架构的模型，能够在推理时利用时间递归性，并且是在短视频片段上进行训练的。为了解决标签不平衡的问题，研究引入了焦点损失和一种新的正则化策略，使模型预测与评估指标对齐。实验表明Mamba-OTR在准确性和效率上均优于其他方法，特别是在处理完整视频或高帧率序列时。", "conclusion": "Mamba-OTR在滑动窗口模式下的mp-mAP达到45.48，在流媒体模式下的mp-mAP达到43.35，优于传统的基于转换器的方法和基于Mamba的方法，为其提供了强大的基准。源代码将公开发布，以支持未来的研究。"}
{"llm_update_time": "20250723", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.16393", "html_url": "https://arxiv.org/abs/2507.16393", "title": "Are Foundation Models All You Need for Zero-shot Face Presentation Attack Detection？", "title_en": "Are Foundation Models All You Need for Zero-shot Face Presentation Attack Detection?", "authors": "Lazaro Janier Gonzalez-Sole,Juan E. Tapia,Christoph Busch", "background": "面部识别系统在过去十年中取得了令人印象深刻的发展，但这些技术仍易受伪造显示攻击（AP）的影响。此类攻击极易创造，攻击者通过干扰面部识别系统的捕捉设备，冒充授权主体，进而获取对该主体的信息访问权。因此，为了保护面部识别系统免受这些攻击，在现有深度学习检测模型中，需要大量的数据来获得可靠的性能，但在面对未见过的攻击设备或数据库时，其性能会下降。这类模型缺乏泛化能力。因此，有必要探索一种能够在未知攻击面前具有高泛化能力的方法，即零样本识别方法。", "innovation": "本文重点探讨了零样本PAD（Zero-shot PAD，零样本面部分析攻击检测）方法。首先，评估了基模型在现有和具有挑战性的实验情景中的有效性和泛化能力，结果发现这些基模型能够在较少优化的情况下实现与高度优化的PAD机制相似的性能。相较于使用包括冒充图像和真实数据的数据集优化的PAD模型，表现最佳的基模型在SiW-Mv2数据库上优于现有的最好的基于留一法的结果，该数据库包含挑战性的未知2D和3D攻击。因此，表明了基模型在零样本PAD中的潜在优势和有效性。", "conclusion": "研究结果表明，基础模型能够在有限努力的情况下实现与高度优化的PAD类似的效果。而这些基础模型在以前主要用于包含AP和真实身份数据集的情况下进行了优化。最佳基模型在SiW-Mv2数据库上优于现有的方法，特别是在面对未知的2D和3D攻击时。"}
{"llm_update_time": "20250723", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.16406", "html_url": "https://arxiv.org/abs/2507.16406", "title": "稀疏视角3D重构：近期进展与开放挑战", "title_en": "Sparse-View 3D Reconstruction: Recent Advances and Open Challenges", "authors": "Tanveer Younis,Zhanglin Cheng", "background": "在需要密集图像但获取不便的应用场景中，如机器人、增强/虚拟现实(AR/VR)以及自主系统中，稀疏视角3D重构尤为重要。由于极小的图像重叠使得可靠的对应匹配变得困难，传统的结构从运动(SfM)和多视角立体匹配(MVS)方法在这种情况下无法有效工作。为了解决这些局限性，本文综述了基于神经隐式模型(例如，NeRF及其正则化版本)、显式点云方法(例如，3D 高斯点积)以及结合了扩散和视觉基础模型(VFMs)先验信息的混合框架的新进展，分析了这些方法如何通过几何正则化、显式形状建模和生成推理来减轻稀疏视图设置中的伪影和姿态模糊问题。", "innovation": "本文综述了基于神经隐式模型、显式点云方法以及结合了扩散和视觉基础模型先验信息的混合框架的新进展，提供了几何基于、神经隐式和生成（基于扩散）方法的统一视角，揭示了在标准基准上的对比结果，在重建准确度、效率和泛化能力之间的关键权衡，并强调了领域泛化与姿态无约束重建中的持久性挑战。", "conclusion": "本文突出了领域泛化和姿态无约束重建中的持续挑战，提出了开发3D本征生成先验以及实现实时非约束稀疏视角重构的未来发展方向。"}
{"llm_update_time": "20250723", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.16403", "html_url": "https://arxiv.org/abs/2507.16403", "title": "ReasonVQA: 一个基于结构化知识的多跳推理基准数据集用于视觉问答", "title_en": "ReasonVQA: A Multi-hop Reasoning Benchmark with Structural Knowledge for Visual Question Answering", "authors": "Thuy-Duong Tran,Trung-Kien Tran,Manfred Hauswirth,Danh Le Phuoc", "background": "现有的视觉问答（VQA）任务的数据集和模型大多缺乏多跳推理和复杂问题生成的能力，且在扩展性方面存在局限。", "innovation": "提出了一个名为ReasonVQA的新数据集，能够自动整合结构化百科知识并使用低成本框架生成复杂、多跳的问题。该数据集挑战现有的VQA模型，有助于评估和促进VQA领域的研究进展。", "conclusion": "ReasonVQA数据集目前版本比现有需要外部知识的数据集大一个数量级，并且在输入图像的扩展性方面容易实现，为VQA建立了新的基准标准。"}
{"llm_update_time": "20250723", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.16472", "html_url": "https://arxiv.org/abs/2507.16472", "title": "DenseSR: 图像阴影去除作为密集预测", "title_en": "DenseSR: Image Shadow Removal as Dense Prediction", "authors": "Yu-Fan Lin,Chia-Ming Lee,Chih-Chung Hsu", "background": "阴影经常是影响图像质量的常见因素。在间接光照等挑战性条件下，单图像阴影去除（SR）面临着内容不均匀退化和固有的模糊性，导致传统方法无法同时恢复阴影内部细节和保持清晰边界，从而导致不一致的恢复和模糊，这会严重影响下游应用及整体观看体验。", "innovation": "我们提出了一种DenseSR框架，通过密集预测方法来注重恢复质量。DenseSR框架使用两种策略相结合：（1）基于几何语义先验的深度场景理解，用于解决模糊性和隐式定位阴影；（2）通过解码器中的新型密集融合块（DFB）进行高质量恢复。DFB采用自适应组件处理，通过自适应内容平滑模块（ACSM）和纹理-边界恢复模块（TBRM）直接解决不一致恢复和模糊问题，有效融合这些处理过的组件，以优化特征表示，保留一致性和保真度。", "conclusion": "我们的方法在广泛实验中显示出优于现有方法的优点。我们的代码可以在 https://github.com/VanLinLin/DenseSR 获取。"}
{"llm_update_time": "20250723", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.16443", "html_url": "https://arxiv.org/abs/2507.16443", "title": "VGGT-Long：分块它，闭环它，对齐它——在千米尺度长RGB序列上推动VGGT的极限", "title_en": "VGGT-Long: Chunk it, Loop it, Align it -- Pushing VGGT's Limits on Kilometer-scale Long RGB Sequences", "authors": "Kai Deng,Zexin Ti,Jiawei Xu,Jian Yang,Jin Xie", "background": "基础模型在3D视觉中的定位已经显示出显著的能力。但是，将这些模型扩展到大规模RGB流3D重建仍然具有挑战性，主要是由于内存限制。当前的研究通过提出一种基于块的处理策略结合重叠对齐和轻量级闭环优化来解决现有模型的可扩展性瓶颈问题。这种方法不需要相机校准、深度监督或重新训练模型，就能在千米尺度的无限户外环境中实现与传统方法相当的轨迹和重建性能。这种方法已经在KITTI、Waymo和Virtual KITTI数据集上进行了评估，并且在基础模型通常失败的长时间RGB序列上成功运行，且能够生成各种条件下的准确一致几何结构。", "innovation": "该研究提出了VGGT-Long系统，该系统采用基于块的处理策略结合重叠对齐和轻量级闭环优化，既能解决当前模型的可扩展性瓶颈问题，又无需相机校准、深度监督或重新训练。该方法能够实现与传统方法相当的轨迹和重建性能，并已在多个数据集上进行了验证。此外，VGGT-Long能够在长序列RGB视频上成功运行，这种场景是基础模型通常无法处理的，能够生成准确且一致的几何结构。", "conclusion": "研究表明，利用基础模型进行大尺度的单目3D场景重建具有巨大的潜力，尤其是在自动驾驶场景中。VGGT-Long不仅能在长时间的RGB序列上成功运行，并且能够生成准确且一致的几何结构。该研究结果展示了基础模型在现实世界中的应用前景，并且能够进一步推动单目3D场景重建技术的发展。"}
{"llm_update_time": "20250723", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.16429", "html_url": "https://arxiv.org/abs/2507.16429", "title": "使用扩散模型的稳健伪标签学习在半监督医学图像分割中的应用", "title_en": "Robust Noisy Pseudo-label Learning for Semi-supervised Medical Image Segmentation Using Diffusion Model", "authors": "Lin Xi,Yingliang Ma,Cheng Wang,Sandra Howell,Aldo Rinaldi,Kawal S. Rhode", "background": "在医学领域获得像素级注解既昂贵又耗时，通常需要临床专家和开发人员的密切合作。现有的半监督医学图像分割方法试图利用少量的标注数据和大量的未标注数据，但由于伪标签引入的噪声，这些方法难以有效构建语义分布。因此，该研究旨在提出一种新颖的基于扩散的框架，以增强模型在处理噪声伪标签情况下的鲁棒性并提高语义标签的结构化程度。", "innovation": "该研究提出了一种基于扩散的方法，通过在去噪扩散过程中引入基于原型的对比一致性约束，来约束语义标签的潜在结构。方法利用类原型作为锚点，集中于潜在空间中的语义表示，而不是明确地界定语义边界。这提高了密集预测的鲁棒性，特别是在噪声伪标签存在的情况下。此外，研究还引入了一个新的公开可用基准：X射线血管造影视频中的多对象分割基准（MOSXAV），为X射线血管造影视频中的多个解剖结构提供了详细的、手动标注的分割地面真相。", "conclusion": "在EndoScapes2023和MOSXAV数据集上的广泛实验表明，该方法在半监督学习设置下优于现有的医学图像分割方法。这项工作展示了一种鲁棒且数据高效的扩散模型，具有广泛的临床应用潜力。"}
{"llm_update_time": "20250723", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.16518", "html_url": "https://arxiv.org/abs/2507.16518", "title": "C2-Evo: 共进化多模态数据和模型以提高自我提升的推理能力", "title_en": "C2-Evo: Co-Evolving Multimodal Data and Model for Self-Improving Reasoning", "authors": "Xiuwei Chen,Wentao Hu,Hanhui Li,Jun Zhou,Zisheng Chen,Meng Cao,Yihan Zeng,Kui Zhang,Yu-Jie Yuan,Jianhua Han,Hang Xu,Xiaodan Liang", "background": "近年来，多模态大型语言模型（MLLMs）展示了令人印象深刻的推理能力。然而，进一步提升现有的MLLMs需依赖高质量且任务复杂度控制得当的跨模态数据集，但这些数据集的获取既昂贵又具有挑战性。尽管最近出现了一些能迭代优化自身的方法，但它们仍面临两个核心挑战：（i）现有的大多数方法分别增强视觉或文本数据，导致数据复杂度不一致；（ii）数据和模型的演变是分离的，可能会使模型接触到难度不匹配的任务。因此，需要一种既能优化训练数据又能提升模型能力的自动闭环系统来解决这些问题。", "innovation": "我们提出了一种名为C2-Evo的自动化、闭环增强框架，以同时提升多模态训练数据和模型能力。C2-Evo通过跨模态数据进化循环和数据-模型进化循环，首先扩展基数据集为更复杂的跨模态问题，结合结构化的文本子问题和迭代生成的几何图表。然后，根据基模型的性能适配性挑选这些问题以交替进行监督微调和强化学习，从而使模型和训练数据持续优化，且在多个数学推理基准测试中取得了显著的性能提升。", "conclusion": "我们的方法持续细化模型和训练数据，并在多个数学推理基准测试中获得了一致的性能提升。我们的代码、模型和数据集将被公开。"}
{"llm_update_time": "20250723", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.16524", "html_url": "https://arxiv.org/abs/2507.16524", "title": "Spatial 3D-LLM：探索3D视觉语言模型中的空间感知", "title_en": "Spatial 3D-LLM: Exploring Spatial Awareness in 3D Vision-Language Models", "authors": "Xiaoyan Wang,Zeju Li,Yifan Xu,Jiaxing Qi,Zhifei Yang,Ruifei Ma,Xiangde Liu,Chao Zhang", "background": "新的时代为将大型语言模型（LLM）扩展到处理3D视觉语言任务带来了激动人心的可能性。然而，现有的大多数3D多模态LLM（MLLM）依赖于压缩整体的3D场景信息或独立分割对象来完成这些任务，这导致它们的空间感知能力受限，因为它们无法充分代表3D场景中的丰富性。", "innovation": "本文提出了一种名为Spatial 3D-LLM的3D多模态LLM，专门设计用于通过丰富3D场景的空间嵌入来增强3D视觉语言任务的空间感知能力。Spatial 3D-LLM集成了LLM骨干网络和一种渐进式空间感知方案，该方案随着感知区域的扩大逐步捕获空间信息，生成包含位置信息的3D场景嵌入作为视觉提示。此外，本文还引入了两个新的任务：3D物体距离测量和3D布局编辑，并构建了一个3D指令数据集MODEL来评估模型的空间感知能力。实验结果表明，Spatial 3D-LLM在多个3D视觉语言任务上的性能达到最新水平，揭示了我们渐进式空间感知方案所带来的改进来自对更深层次的空间信息的挖掘。", "conclusion": "实验结果表明，Spatial 3D-LLM在广泛范围内的3D视觉语言任务上达到最新水平，证明了我们渐进式空间感知方案可以更好地捕捉和利用深层次的空间信息。"}
{"llm_update_time": "20250723", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.16556", "html_url": "https://arxiv.org/abs/2507.16556", "title": "基于FPGA的DNN驱动HSI分割SoC在ADS中的优化：一种实用方法", "title_en": "Optimization of DNN-based HSI Segmentation FPGA-based SoC for ADS: A Practical Approach", "authors": "Jon Gutiérrez-Zaballa,Koldo Basterretxea,Javier Echanobe", "background": "HSI在自主导航中的应用是一个有前景的研究领域，旨在提高基于视觉传感器的检测、跟踪和场景理解系统的准确性和稳健性。结合先进的计算算法（如DNNs）和小型快照HSI相机可以增强这些系统的可靠性。HSI克服了灰度图像和RGB成像在表现目标物理属性方面的内在限制，特别是关于光谱反射率和同色异谱性。尽管基于HSI的视觉技术取得了有前景的成果，但安全关键系统（如ADS）对延迟、资源消耗和安全性有严格的限制，促使将机器学习工作负载迁移到边缘平台。这需要一个全面的软硬件协同设计方案，以有效地分配和优化计算平台有限资源中的任务。对于推理而言，DNN的高参数量提出了重大挑战，对于实时在边缘部署来说尤其如此。此外，HSI所需的密集数据预处理往往被忽视，必须从内存布局和任务间通信角度仔细管理，以实现SoC上高效综合流水线设计。", "innovation": "本文提出了一种用于ADS的基于FPGA的DNN驱动HSI分割SoC的优化技术方案，包括功能性的软硬件任务分布、硬件感知预处理、ML模型压缩和集成流水线部署。通过应用压缩技术，设计的DNN的复杂度显著降低至原操作的24.34%和原参数数量的1.02%，实现了推理任务2.86倍的加速，而无明显分割准确性下降。", "conclusion": "本文通过软硬件协同设计、硬件感知预处理、模型压缩和流水线部署，优化了基于FPGA的DNN驱动HSI分割SoC，适用于ADS，并实现了显著的性能提升，证明了该方法的有效性。"}
{"llm_update_time": "20250723", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.16397", "html_url": "https://arxiv.org/abs/2507.16397", "title": "ADCD-Net: 通过自适应DCT特征和分层内容分离实现稳健的文档图像伪造定位", "title_en": "ADCD-Net: Robust Document Image Forgery Localization via Adaptive DCT Feature and Hierarchical Content Disentanglement", "authors": "Kahim Wong,Jicheng Zhou,Haiwei Wu,Yain-Whar Si,Jiantao Zhou", "background": "随着图像编辑工具的进步，恶意篡改敏感文档图像的问题日益突出。自动化伪造检测器在自然图像上已经得到了广泛研究，但在文档图像上表现不佳，因为篡改区域可以无缝融入均匀的文档背景和结构化的文本中。此外，现有的文档特异性方法在面对各种退化时缺乏足够的鲁棒性，限制了它们的实际部署。", "innovation": "这篇论文提出了ADCD-Net，一种稳健的文档伪造本地化模型，该模型能够自适应利用RGB/DCT执法痕迹，并整合文档图像的关键特征。为了应对DCT痕迹对块对齐的敏感性，我们基于预测的对齐分数自适应调节DCT特征的贡献，从而增强其对各种扭曲的鲁棒性，包括缩放和裁剪。此外，提出了分层内容分离方法，通过减轻文本-背景差异来提升定位效果。同时，注意到背景区域的完好性质，我们构建了一个纯净原型以捕捉未篡改区域的痕迹，并最终增强本地化准确性和鲁棒性。", "conclusion": "我们提出的ADCD-Net在伪造定位性能上表现出色，相对最先进的方法在5种类型扭曲上的平均性能提高了20.79%。代码可以在主页上找到。"}
{"llm_update_time": "20250723", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.16337", "html_url": "https://arxiv.org/abs/2507.16337", "title": "One Polyp Identifies All: One-Shot Polyp Segmentation with SAM via Cascaded Priors and Iterative Prompt Evolution", "title_en": "One Polyp Identifies All: One-Shot Polyp Segmentation with SAM via Cascaded Priors and Iterative Prompt Evolution", "authors": "Xinyu Mao,Xiaohan Xing,Fei Meng,Jianbang Liu,Fan Bai,Qiang Nie,Max Meng", "background": "结肠直肠癌早期检测中，息肉分割至关重要，但传统完全监督方法难以应对形态学变异和领域转变，需要频繁重新训练。大规模注解依赖是主要瓶颈，因为手动标注息肉边界耗时且容易出错。最近的视觉基础模型，如Segment Anything Model (SAM)，展示出强大的通用性和精细的边界的检测能力，但在医学应用中，手动输入每个图像的提示较为劳耗和耗时。", "innovation": "提出了一种基于SAM的One-shot息肉分割框架OP-SAM，自动从单个标注图像生成提示，确保准确、可泛化的分割，无需额外注解。方法包括基于相关性优先生成(CPG)进行语义标签传输，以及级联优先融合（SPF）以适应息肉大小变化并滤除噪声转移。还设计了欧式提示演化(EPE)，进行迭代提示优化，逐步提升分割质量。", "conclusion": "在五个数据集上的广泛评估验证了OP-SAM的有效性。特别地，其在Kvasir数据集上达到了76.93%的IoU，超越了最新方法11.44%。"}
{"llm_update_time": "20250723", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.16596", "html_url": "https://arxiv.org/abs/2507.16596", "title": "A Multimodal Deviation Perceiving Framework for Weakly-Supervised Temporal Forgery Localization", "title_en": "A Multimodal Deviation Perceiving Framework for Weakly-Supervised Temporal Forgery Localization", "authors": "Wenbo Xu,Junyan Wu,Wei Lu,Xiangyang Luo,Qian Wang", "background": "当前关于Deepfake鉴别的研究通常将其视为分类任务或时间伪造定位问题，但在处理大规模数据集时，这些方法往往受到限制性、耗时性以及可扩展性的挑战。", "innovation": "提出了一种多模态偏差感知框架（MDP）用于半监督时间伪造定位，该框架仅使用视频级别的注释来识别时间部分伪造段。MDP引入了一种新颖的多模态交互机制（MI）和一种可扩展的偏差感知损失，用于感知多模态偏差，实现了伪造段起止时间戳的精细化定位。MI提出了一种保留时间属性的跨模态注意机制，可以在概率嵌入空间中测量视觉和音频模态之间的相关性，识别跨模态偏差并构建综合视频特征用于时间伪造定位。为探索进一步的时间偏差以促进半监督学习，引入了一种可扩展的偏差感知损失，旨在扩大伪造样本邻近段落之间的偏差，减少真实样本之间的偏差。", "conclusion": "广泛实验表明，所提出框架的有效性，且在多个评估指标上达到了与全监督方法相当的结果。"}
{"llm_update_time": "20250723", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.16608", "html_url": "https://arxiv.org/abs/2507.16608", "title": "Dyna3DGR: 4D心肌运动跟踪中的动态3D高斯表示", "title_en": "Dyna3DGR: 4D Cardiac Motion Tracking with Dynamic 3D Gaussian Representation", "authors": "Xueming Fu,Pei Wu,Yingtai Li,Xin Luo,Zihang Jiang,Junhao Mei,Jian Lu,Gao-Jun Teng,S. Kevin Zhou", "background": "准确分析心脏运动对于评估心脏功能至关重要。虽然动态心脏磁共振成像（CMR）能够捕捉整个心脏周期中的详细组织运动，但由于心肌组织的均匀性质和缺乏显著特征，精细的4D心脏运动跟踪仍然具有挑战性。现有的方法可以大致分为基于图像和基于表示的方法，每种方法都有其局限性。基于图像的方法，无论是传统的还是基于深度学习的配准方法，要么难以保持拓扑一致性，要么需要大量的训练数据。基于表示的方法虽然具有潜力，但常常会丢失图像级别的细节。", "innovation": "本文提出了一种新颖的框架——动态3D高斯表示（Dyna3DGR），该框架结合了显式的3D高斯表示和隐式的神经运动场建模。Dyna3DGR 方法以自我监督的方式同时优化心脏结构和运动，消除了对大量训练数据或点对点对应关系的需求。通过可微分的体积渲染技术，Dyna3DGR 有效地将连续运动表示与图像空间对齐相结合，同时保持拓扑和时间一致性。", "conclusion": "在ACDC数据集上的综合评估表明，我们的方法在追踪精度上超越了最先进的基于深度学习的变形配准方法。完整的代码可以在本链接https://github.com/author/Dyna3DGR中获取。"}
{"llm_update_time": "20250723", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.16427", "html_url": "https://arxiv.org/abs/2507.16427", "title": "结合图像数据增强削弱了自适应标签平滑的效果", "title_en": "Combined Image Data Augmentations diminish the benefits of Adaptive Label Smoothing", "authors": "Georg Siedel,Ekagra Gupta,Weijia Shao,Silvia Vock,Andrey Morozov", "background": "自适应标签平滑通过根据应用于训练样本的随机裁剪增强的大小减少标签置信度，来通过监督学习过程对图像分类器进行正则化。本文扩展了这种自适应标签平滑框架，将其应用于其他类型的激进增强方法，如随机擦除和噪声注入数据增强。", "innovation": "研究了自适应标签平滑在随机擦除和噪声注入数据增强中的应用效果，表明自适应标签平滑通过较高强度的随机擦除增强了正则化效果，但在多样化的图像变换应用中，其效果会消失，过多的标签平滑会损害模型对常见图像篡改的鲁棒性。", "conclusion": "研究结果表明，只有当训练数据分布主要由有限且单一类型的图像变换组成时，才应应用自适应标签平滑。"}
{"llm_update_time": "20250723", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.16535", "html_url": "https://arxiv.org/abs/2507.16535", "title": "地球工匠：通过双稀疏潜在扩散技术进行大规模3D地球生成", "title_en": "EarthCrafter: Scalable 3D Earth Generation via Dual-Sparse Latent Diffusion", "authors": "Shang Liu,Chenjie Cao,Chaohui Yu,Wen Qian,Jing Wang,Fan Wang", "background": "尽管近年来3D生成工作取得了显著进展，但在地理范围上大规模应用这些方法，如建模数千平方公里的地球表面，仍然是一个开放的挑战。", "innovation": "我们通过数据基础设施和模型架构的双重创新解决这一挑战。首先，我们引入了迄今为止最大的3D航空数据集Aerial-Earth3D，包含5万幅600m x 600m的详细场景（覆盖美国本土），共计4.5亿多视角Google Earth图像。其次，我们提出了一种名为EarthCrafter的定制框架，用于大规模3D地球生成。该框架通过稀疏解耦潜在扩散技术将结构和纹理生成分离，利用双稀疏3D-VAE压缩高分辨率几何体元和2D纹理2D点，并利用条件感知流匹配模型独立建模潜在几何和纹理特征。", "conclusion": "实验结果表明，EarthCrafter在大规模生成中表现优异，该框架还支持多样化的应用，如基于语义的城市布局生成和无条件地形合成，同时确保地理可行性通过Aerial-Earth3D的数据先验知识。"}
{"llm_update_time": "20250723", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.16623", "html_url": "https://arxiv.org/abs/2507.16623", "title": "自动细粒度分割辅助报告生成", "title_en": "Automatic Fine-grained Segmentation-assisted Report Generation", "authors": "Frederic Jonske,Constantin Seibold,Osman Alperen Koras,Fin Bahnsen,Marie Bauer,Amin Dada,Hamza Kalisch,Anton Schily,Jens Kleesiek", "background": "可靠的端到端临床报告生成一直是医疗ML研究的重要目标。这一过程的目标是减轻放射科医生的工作负担，并为临床医生或患者提供第二意见。因此，报告生成模型的一个必要前提是需要有强大的通用性能和某种内置的关联能力，以使临床医生或患者相信生成报告的真实性。", "innovation": "本文提出了ASaRG（自动分割辅助报告生成），它是流行的LLaVA架构的一个扩展，旨在解决这两个问题。ASaRG建议将专业放射学模型生成的中间特征和精细分割图以简单的连接方式融合到LLaVA的多模态投影层中。仅使用中间特征时，我们的方法在CE F1分数上取得了+0.89%的性能提升，同时添加精细分割图时取得了+2.77%的性能提升。与使用分割的COMG和ORID两种报告生成方法相比，ASaRG在F1分数上分别取得了6.98%和6.28%的性能提升。与LLaVA架构的其他改进结合，ASaRG具有潜在的兼容性。", "conclusion": "将任意数量的分割作为输入的一部分，可以示例化报告元素追溯到相应的分割图，验证评估的合理性。我们未来将在公开平台上发布代码。"}
{"llm_update_time": "20250723", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.16413", "html_url": "https://arxiv.org/abs/2507.16413", "title": "基于SynDRA-BBox的铁路领域适应性LiDAR 3D检测：从路到轨的模拟到现实", "title_en": "Towards Railway Domain Adaptation for LiDAR-based 3D Detection: Road-to-Rail and Sim-to-Real via SynDRA-BBox", "authors": "Xavier Diaz,Gianluca D'Amico,Raul Dominguez-Sanchez,Federico Nesti,Max Ronecker,Giorgio Buttazzo", "background": "近年来，对自动驾驶列车的兴趣显著增加。为了实现高级功能，基于视觉的鲁棒算法对于感知和理解周围环境至关重要。然而，铁路领域缺乏公开的真实世界注释数据集，这使得在该领域测试和验证新的感知解决方案变得具有挑战性。SynDRA-BBox是一个合成数据集，旨在支持铁路场景下的物体检测和其他视觉任务。该数据集是首次专门为铁路领域2D和3D物体检测设计的，并且公开可用。", "innovation": "该研究引入了SynDRA-BBox，这是第一个专门为铁路领域设计的合成数据集，用于2D和3D物体检测。此外，研究将一种最先进的半监督领域自适应方法（最初为汽车感知设计）适应铁路场景，从而能够将合成数据的3D物体检测能力从模拟环境转移到现实环境。", "conclusion": "实验结果表明，合成数据集和领域适应技术在提高铁路环境感知能力方面表现出色，这为铁路环境下的3D物体检测奠定了基础。"}
{"llm_update_time": "20250723", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.16657", "html_url": "https://arxiv.org/abs/2507.16657", "title": "合成数据很重要：基于地理典型合成标签的重新训练在建筑物检测中的应用", "title_en": "Synthetic Data Matters: Re-training with Geo-typical Synthetic Labels for Building Detection", "authors": "Shuang Song,Yang Tang,Rongjun Qin", "background": "深度学习在遥感中显著提升了建筑物分割，但在不同地理区域的数据上难以泛化，因为城市布局和建筑物类型、大小、位置的差异较大。然而，用于捕捉全球多样化的耗时标注数据可能永远赶不上对数据需求越来越大的模型。因此，提出了一种新的方法：在测试时使用针对目标区域城市布局定制的合成数据重新训练模型。", "innovation": "该方法通过利用诸如OpenStreetMap的地理空间数据生成地理典型的合成数据，这些数据紧密复制了目标区域的都市结构。使用程序建模和基于物理的渲染生成高分辨率的合成图像，并结合领域随机化在建筑物形状、材料和环境光照方面。这种方法克服了合成与现实之间的领域差距，将地理典型的合成数据整合到对抗领域适应框架中，实现了显著性能增强。", "conclusion": "这种方法是可扩展的且成本效益高的，可以部分地理知识与合成图像相结合，提供解决纯合成数据集中的“模型崩溃”问题的前景。它为在远程感建筑物分割中改进泛化提供了一种实用的途径，无需广泛的实地标注。"}
{"llm_update_time": "20250723", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.16624", "html_url": "https://arxiv.org/abs/2507.16624", "title": "A2Mamba: 增强注意力状态空间模型在视觉识别中的应用", "title_en": "A2Mamba: Attention-augmented State Space Models for Visual Recognition", "authors": "Meng Lou,Yunxiang Fu,Yizhou Yu", "background": "Transformers和Mamba最初被用于自然语言处理领域，现在已经被应用到视觉识别的主干网络架构中。最近的研究将局部注意Transformer与Mamba结合使用，以捕捉局部细节和全局上下文，尽管这些方法表现出色，但它们缺乏Transformer和Mamba层之间的交互机制，仅通过简单的堆叠来实现，因而深层面的集成仍然是一个未解决的问题。", "innovation": "提出了A2Mamba，一种强大的Transformer-Mamba混合网络架构，通过引入多尺度注意力增强的状态空间模型（MASS），将多尺度注意力图集成到增强的SSM（A2SSM）中。A2SSM采用一种变体的交叉注意力机制，通过多尺度注意力图在空间上聚合SSM隐藏状态，增强了视觉空间依赖性并改进了SSM的动态建模能力。A2Mamba在视觉识别任务中优于所有基于卷积网络（ConvNet）、Transformer和Mamba的先前架构，例如A2Mamba-L在ImageNet-1K上获得了86.1%的顶级准确性。在语义分割方面，A2Mamba-B相比CAFormer-S36在mIoU上提高了2.5%，同时表现更高效。在使用多尺度掩码R-CNN进行目标检测和实例分割中，A2Mamba-S比MambaVision-B在AP^b/AP^m上分别提高了1.2%/0.9%，同时参数量减少了40%。", "conclusion": "A2Mamba在视觉识别、语义分割和目标检测等多个任务中表现出明显的优势，并且通过A2SSM将多尺度注意力机制引入到SVM框架中，提供了一种新的解决Transformer和Mamba层间深度集成问题的方法。"}
{"llm_update_time": "20250723", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.16476", "html_url": "https://arxiv.org/abs/2507.16476", "title": "通过像素级图聚类和混合密度专家从全视野图像中建模生存期", "title_en": "Survival Modeling from Whole Slide Images via Patch-Level Graph Clustering and Mixture Density Experts", "authors": "Ardhendu Sekhar,Vasu Soni,Keshav Aske,Garima Jain,Pranav Jeevan,Amit Sethi", "background": "现有的癌症特定生存预测方法基于全切片显微镜图像（WSIs），但准确性尚未达到最优。研究人员提出了一种模块化框架，显著提高了癌症特定生存预测的准确性。", "innovation": "提出了一种结合四个关键组件的框架：1. 动态斑块选择，用于隔离预后性信息的组织区域。2. 图引导的k-means聚类，用于通过空间和形态学一致性捕捉表型级别的异质性。3. 注意机制，用于建模局部特征在不同组织区域之间的关系，使其具有全局空间关系的上下文。4. 专家指导的混合密度建模，使用高斯混合模型估计复杂的生存分布。", "conclusion": "提出的模型在TCGA-KIRC（肾癌）和TCGA-LUAD（肺腺癌）数据集上取得了显著的性能，通过卡森指数（Concordance Index）和贝叶斯评分（Brier Score）的优越表现，展示了该方法在多种癌症类型中的预测潜力。"}
{"llm_update_time": "20250723", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.16506", "html_url": "https://arxiv.org/abs/2507.16506", "title": "PlantSAM: 一种基于目标检测的分割pipeline用于植物腊叶标本", "title_en": "PlantSAM: An Object Detection-Driven Segmentation Pipeline for Herbarium Specimens", "authors": "Youcef Sklab,Florian Castanet,Hanane Ariouat,Souhila Arib,Jean-Daniel Zucker,Eric Chenin,Edi Prifti", "background": "由于植物腊叶标本图像中的背景不一致性引入了噪声和伪影，这些因素可能误导模型，降低分类准确性。解决这些问题对于提高模型性能是至关重要的。", "innovation": "提出了PlantSAM，一种自动分割pipeline，结合YOLOv10进行植物区域检测和Segment Anything Model (SAM) 进行分割。YOLOv10生成边界框提示引导SAM，提高分割精度。两种模型均在植物腊叶标本图像上进行了微调，并使用交并比(IoU)和Dice系数进行评估。PlantSAM实现了最先进的分割性能，IoU为0.94，Dice系数为0.97。将分割后的图像融入分类模型中，在五个测试的植物学特征上实现了持续性能提升，准确性提升最高达到4.36%，F1分数提高4.15%。", "conclusion": "我们的研究强调了背景去除在植物腊叶标本图像分析中的重要性，它显著提高了分类准确性，使模型能够更有效地关注前景植物结构。"}
{"llm_update_time": "20250723", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.16683", "html_url": "https://arxiv.org/abs/2507.16683", "title": "QRetinex-Net: Quaternion-Valued Retinex Decomposition for Low-Level Computer Vision Applications", "title_en": "QRetinex-Net: Quaternion-Valued Retinex Decomposition for Low-Level Computer Vision Applications", "authors": "Sos Agaian,Vladimir Frants", "background": "在低光环境下拍摄的照片通常会出现颜色偏移、对比度低、噪声和其他缺陷，影响计算机视觉的准确度。Retinex理论通过将图像S视为光度R和光照I的像素级乘积来解决这个问题，这种方式模仿了人类在不同光照条件下感知物体颜色的稳定方式。然而，Retinex分解存在四个主要问题：（i）独立处理红色、绿色和蓝色通道；（ii）缺乏神经科学的色彩视觉模型；（iii）无法完美重建输入图像；（iv）无法解释人类的色彩恒常性。", "innovation": "该论文引入了第一个四元数Retinex模型，其中场景被写为四元数光度和照明的Hamilton乘积。为了衡量光度的不变性，作者提出了光度一致性指数。通过在低光裂缝检测、多种光照下的面部检测以及红外-可见光融合测试中进行了对比，结果表明该方法相比领先方法有2-11%的性能提升，具有更好的色彩保真度、更低的噪声和更高的光度稳定性。", "conclusion": "该研究通过引入四元数Retinex模型，显著改善了低光环境下计算机视觉的图像处理效果，解决了传统Retinex模型的几个关键问题，实现了在实际应用中的性能提升。"}
{"llm_update_time": "20250723", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.16736", "html_url": "https://arxiv.org/abs/2507.16736", "title": "DFR：一种用于多模态少量样本分割的分解融合重构框架", "title_en": "DFR: A Decompose-Fuse-Reconstruct Framework for Multi-Modal Few-Shot Segmentation", "authors": "Shuai Chen,Fanman Meng,Xiwei Zhang,Haoran Wei,Chenhao Wu,Qingbo Wu,Hongliang Li", "background": "现有的大多数方法主要依赖于视觉支持样本或文本描述，它们的单一或双模态范式限制了对现实世界中丰富的感知信息的利用。因此，开发一种高效利用多模态指导信息的方法在少量样本分割（FSS）任务中具有重要意义。", "innovation": "DFR框架提出了三个关键创新点：1）多模态分解：通过SAM进行分层分解，提取视觉区域建议，扩展文本语义为细粒度描述，并处理音频特征以增加上下文丰富性；2）多模态对比融合：采用对比学习进行融合策略，保持视觉、文本和音频模态之间的一致性，同时允许前景和背景特征之间的动态语义互动；3）双路径重构：一种适应性集成机制，结合三模态融合令牌的语义指导与多模态位置先验的几何线索的集成。", "conclusion": "在视觉、文本和音频模态的合成和实际设置下进行了广泛的实验，展示了DFR相对于现有最先进的方法的显著性能提升。"}
{"llm_update_time": "20250723", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.16746", "html_url": "https://arxiv.org/abs/2507.16746", "title": "Zebra-CoT: 用于交错视觉语言推理的数据集", "title_en": "Zebra-CoT: A Dataset for Interleaved Vision Language Reasoning", "authors": "Ang Li,Charles Wang,Kaiyu Yue,Zikui Cai,Ollie Liu,Deqing Fu,Peng Guo,Wang Bill Zhu,Vatsal Sharan,Robin Jia,Willie Neiswanger,Furong Huang,Tom Goldstein,Micah Goldblum", "background": "人类在解决复杂问题时经常使用视觉辅助工具，例如图表或草图。训练多模态模型以执行相同任务（称为视觉思维链）具有挑战性，原因如下：(1) 现有视觉思维链表现不佳，这妨碍了强化学习；(2) 缺乏高质量的视觉思维链训练数据。", "innovation": "本文提出了Zebra-CoT，这是一个多样化的大型数据集，包含182,384个样本，包含了逻辑连贯的交错文本-图像推理推断。数据集专注于四个视觉推理特别自然的任务类别：自然科学问题（如几何、物理和算法）、2D视觉推理任务（如视觉搜索和拼图）、3D推理任务（包括3D多跳推理、体感和机器人规划）、视觉逻辑问题和战略游戏（如国际象棋）。通过在Zebra-CoT训练语料库上微调Anole-7B和Bagel-7B模型，测试集准确率提高了12%，在标准VLM基准测试中的性能提高了13%。微调Bagel-7B还生成了高质量的交错视觉推理链，突显了Zebra-CoT在开发多模态推理能力方面的有效性。", "conclusion": "本研究公开了数据集和模型，以支持视觉流程的开发和评估。"}
{"llm_update_time": "20250723", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.16612", "html_url": "https://arxiv.org/abs/2507.16612", "title": "CTSL: 基于码本的时空学习用于Cine MRI无对比心脏风险准确预测", "title_en": "CTSL: Codebook-based Temporal-Spatial Learning for Accurate Non-Contrast Cardiac Risk Prediction Using Cine MRIs", "authors": "Haoyang Su,Shaohao Rui,Jinyi Xiang,Lianming Wu,Xiaosong Wang", "background": "从心脏磁共振成像（Cine MRI）序列准确预测主要心脏不良事件（MACE）仍然是一个严峻的挑战。现存方法通常依赖于冠状动脉造影的人工精炼心室心肌掩模进行监督学习，而在没有造影剂的情况下这种方法变得不切实际。现有技术通常需要使用带有冠状动脉造影剂的图像来进行精准的训练，但该方法成本高且非侵入性较差，这使得在没有造影剂的情况下进行心脏风险评估变得困难.", "innovation": "研究引入了一种自监督框架——基于码本的时空学习（CTSL），能够在不需要分割掩模的情况下从原始Cine数据学习动态的、时空间表示。CTSL通过多视角蒸馏策略分解时序和空间特征，教师模型处理多个Cine视图，学生模型则通过降维后的Cine-SA序列学习。CTSL利用码本特征表示和运动线索下的动态病灶自我检测，从而捕捉复杂的时间依赖性和运动模式，最终获得高置信度的MACE风险预测，提供了一种快速、无创的心脏风险评估解决方案，优于传统依赖造影剂的方法，使临床环境中的心脏病诊断更加及时和易得.", "conclusion": "CTSL模型实现了高置信度的MACE风险预测，提供了一种无造影剂的快速、无创心脏风险评估方法，超越了传统依赖造影剂的技术，使得临床环境中心脏病诊断更加及时和可获取。"}
{"llm_update_time": "20250723", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.16761", "html_url": "https://arxiv.org/abs/2507.16761", "title": "抗混叠B-cos网络在胸部X射线诊断中的忠实和可解释性", "title_en": "Faithful, Interpretable Chest X-ray Diagnosis with Anti-Aliased B-cos Networks", "authors": "Marcel Kleinmann,Shashank Agnihotri,Margret Keuper", "background": "深度神经网络（DNNs）在医疗成像等关键领域应用时需要具备信实性和可解释性。现有的B-cos网络通过替换标准的线性层为权重输入对齐机制来提供固有的、类特定的解释，不过在临床应用中仍旧面临严重的混叠伪影以及解释质量不足的问题，特别是在多标签分类任务中表现不佳，因为胸部X射线分析经常需要处理共发异常的情况。", "innovation": "本文提出了一种新的抗混叠策略，通过FLCPooling (FLC)和BlurPool (BP)提高了解释质量，并扩展了B-cos网络以支持多标签分类。实验表明，修改后的$\text{B-cos}_\text{FLC}$和$\text{B-cos}_\text{BP}$不仅保持了强大的预测性能，还提供了忠实且无伪影的解释，适合多标签临床应用。", "conclusion": "修改后的B-cos网络在胸部X射线数据集上展示了良好的预测性能和高质量的解释，去除了伪影，适用于临床多标签诊断应用。相关代码已发布在GitHub repo中。"}
{"llm_update_time": "20250723", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.16753", "html_url": "https://arxiv.org/abs/2507.16753", "title": "CMP: 基于SAM的跨域少样本分割可组合元提示", "title_en": "CMP: A Composable Meta Prompt for SAM-Based Cross-Domain Few-Shot Segmentation", "authors": "Shuai Chen,Fanman Meng,Chunjin Yang,Haoran Wei,Chenhao Wu,Qingbo Wu,Hongliang Li", "background": "跨域少样本分割（CD-FSS）面临着数据有限和领域偏移的挑战。尽管基础模型如Segment Anything Model (SAM)在通用分割任务中展现出了出色的零样本泛化能力，并具有成为少样本场景解决方案的潜力，但将其应用于CD-FSS时仍面临两大关键问题：依赖于手动提示和跨域能力有限。", "innovation": "本文提出了一种可组合元提示（CMP）框架，包括三个关键模块：（i）参考补充和转换模块（RCT），用于语义扩展；（ii）可组合元提示生成模块（CMPG），用于自动化元提示合成；（iii）频率感知交互模块（FAI），用于缓解领域差异。该框架在四个跨域数据集上的评估表明，其性能为目前最佳，特别是在1-shot和5-shot场景下的mIoU分别为71.8%和74.5%。", "conclusion": "CMP框架展示了在跨域少样本分割任务中领先的性能，通过自动化的元提示生成和领域差异缓解策略，有效解决了传统SAM模型在这些场景下的问题。"}
{"llm_update_time": "20250723", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.16559", "html_url": "https://arxiv.org/abs/2507.16559", "title": "比较验证内镜下手术阶段识别、手术工具关键点估计以及手术工具实例分割的结果：2024年PhaKIR挑战赛结果", "title_en": "Comparative validation of surgical phase recognition, instrument keypoint estimation, and instrument instance segmentation in endoscopy: Results of the PhaKIR 2024 challenge", "authors": "Tobias Rueckert,David Rauber,Raphaela Maerkl,Leonard Klausmann,Suemeyye R. Yildiran,Max Gutbrod,Danilo Weber Nunes,Alvaro Fernandez Moreno,Imanol Luengo,Danail Stoyanov,Nicolas Toussaint,Enki Cho,Hyeon Bae Kim,Oh Sung Choo,Ka Young Kim,Seong Tae Kim,Gonçalo Arantes,Kehan Song,Jianjun Zhu,Junchen Xiong,Tingyi Lin,Shunsuke Kikuchi,Hiroki Matsuzaki,Atsushi Kouno,João Renato Ribeiro Manesco,João Paulo Papa,Tae-Min Choi,Tae Kyeong Jeong,Juyoun Park,Oluwatosin Alabi,Meng Wei,Tom Vercauteren,Runzhi Wu,Mengya Xu,An Wang,Long Bai,Hongliang Ren,Amine Yamlahi,Jakob Hennighausen,Lena Maier-Hein,Satoshi Kondo,Satoshi Kasai,Kousuke Hirasawa,Shu Yang,Yihui Wang,Hao Chen,Santiago Rodríguez,Nicolás Aparicio,Leonardo Manrique,Juan Camilo Lyons,Olivia Hosie,Nicolás Ayobi,Pablo Arbeláez,Yiping Li,Yasmina Al Khalil,Sahar Nasirihaghighi,Stefanie Speidel,Daniel Rueckert,Hubertus Feussner,Dirk Wilhelm,Christoph Palm", "background": "在计算机辅助和机器人辅助微创手术(RAMIS)中，可靠的内镜手术器械识别与定位是手术培训、技能评估和自主辅助的关键。然而，在现实世界条件下的稳定表现仍然是一个重大的挑战。利用手术上下文，如当前的手术阶段，被证明是提高鲁棒性和可解释性的一种有前景的方法。因此，为了应对这些挑战，我们组织了MICCAI 2024年度内镜视觉挑战赛的PhaKIR子挑战赛，并引入了一个新型多中心数据集，该数据集包含来自三个不同医疗机构的13段完整腹腔镜胆囊切除术视频，并统一标注了三个相互关联的任务：手术阶段识别、工具关键点估计和工具实例分割。该数据集与现有数据集不同，可以同时研究手术工具定位和手术阶段上下文，同时支持整个手术过程中时间信息的整合。", "innovation": "我们提出了PhaKIR子挑战赛，并组织了MICCAI 2024年内镜视觉挑战赛的一环，引入了一个多中心数据集，其中包括13段完整的腹腔镜胆囊切除术视频，来自三个不同的医疗机构，这些视频统一标注了三个相关任务：手术阶段识别、工具关键点估计和工具实例分割。该数据集的独特之处在于它允许在同一数据集内同时研究手术工具定位和手术上下文，同时还支持整个手术过程中的时间信息整合。数据分别用于检验手术阶段识别、工具关键点估计及工具实例分割的结果，提供了一个特有的基准来推动依赖时间感知和上下文驱动的方法的发展。", "conclusion": "PhaKIR子挑战赛通过提供一个基准，推动了RAMIS中基于时间感知、上下文驱动的方法的发展，并提供了一个高质量资源来支持未来在手术场景理解方面的研究。"}
{"llm_update_time": "20250723", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.16782", "html_url": "https://arxiv.org/abs/2507.16782", "title": "任务特定零样本量化感知训练用于目标检测", "title_en": "Task-Specific Zero-shot Quantization-Aware Training for Object Detection", "authors": "Changhao Li,Xinrui Chen,Ji Wang,Kang Zhao,Jianfei Chen", "background": "量化是一种关键技术，通过使用较低精度表示网络参数，从而减少网络规模和计算复杂性。传统量化方法依赖于原始训练数据，但由于隐私和安全问题，这些数据常常受限。零样本量化（ZSQ）通过使用预训练模型生成的合成数据来解决这一问题，从而消除对真实训练数据的需求。尽管ZSQ已经被扩展到对象检测领域，但现有方法使用的是未标记的任务无关的合成图像，这些图像缺乏进行对象检测所需的具体信息，导致性能不佳。", "innovation": "该论文提出了一种针对对象检测网络的任务特定ZSQ框架，该框架包括两个主要阶段：一是引入边框和类别采样策略，从预训练网络中合成任务特定的校准集，重建对象位置、大小和类别的分布，而无需任何先验知识；二是将任务特定的训练过程集成到知识蒸馏中，以恢复量化检测网络的性能。", "conclusion": "在MS-COCO和Pascal VOC数据集上的广泛实验表明，该方法具有高效性和最先进的性能。我们的代码已公开发布。"}
{"llm_update_time": "20250723", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.16815", "html_url": "https://arxiv.org/abs/2507.16815", "title": "ThinkAct: 视觉-语言-行动推理通过强化视觉隐性规划", "title_en": "ThinkAct: Vision-Language-Action Reasoning via Reinforced Visual Latent Planning", "authors": "Chi-Pin Huang,Yueh-Hua Wu,Min-Hung Chen,Yu-Chiang Frank Wang,Fu-En Yang", "background": "视觉-语言-行动(VLA)推理任务需要智能体理解和执行多模态指令，进行长时规划，并在动态环境中灵活行动。现有方法通常以端到端的方式训练VLA模型，直接将输入映射为行动，缺乏显式的推理步骤，这限制了模型在多个步骤规划或应对复杂任务变化中的表现能力。", "innovation": "提出了ThinkAct双重系统框架，通过强化学习中的视觉隐性规划将高层次推理与低层次行动执行相结合。ThinkAct训练一个多模态的大语言模型，基于目标完成和路径一致性生成行动对齐的视觉奖励来引导其生成体现式推理计划。这些推理计划被压缩成视觉计划隐性空间，用于条件下游动作模型，以在目标环境中实现稳健的执行。广泛的实验在人机推理和机器人操作基准上展示了ThinkAct在复杂人机任务中的少量样本适配、长期规划和自我纠正行为方面的表现。", "conclusion": "大量的实验表明，ThinkAct在复杂的嵌入式AI任务中实现了少量样本的适应能力、长时规划和自我纠正行为。"}
{"llm_update_time": "20250723", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.16718", "html_url": "https://arxiv.org/abs/2507.16718", "title": "时间约束视频推理分割及自动化基准构建", "title_en": "Temporally-Constrained Video Reasoning Segmentation and Automated Benchmark Construction", "authors": "Yiqing Shen,Chenjia Li,Chenxiao Fan,Mathias Unberath", "background": "传统的视频分割方法局限于预定义的对象分类，无法识别超出词汇表的对象，更不用说那些仅在复杂文本查询中隐含提及的对象。这种局限性限制了在复杂和多变的场景中视频分割的实用性，特别是在难以定义封闭对象类别且用户可能不知道视频中将会出现的确切对象类别时。例如，在手术室视频分析中，不同的医疗机构可能使用不同的工作流程和器械，这就要求视频分析解决方案具有灵活性。现有的视频推理分割假设目标对象在整个视频序列中都是相关的，然而，这在实际场景中是不足的，因为感兴趣的物体可能会根据时间上下文动态地出现、消失或改变相关性，如手术器械仅在特定阶段变得相关，或者解剖结构在手术中某一时刻变得更加重要。", "innovation": "1. 提出了时间约束的视频推理分割任务，要求模型根据包含时间推理的文本查询来隐式推断目标物体何时变得相关。2. 开发了自动化基准构建方法，以避免手动标注时间约束视频推理分割数据集所导致的高成本和可扩展性限制。3. 提出了TCVideoRS基准数据集，包含52个使用MVOR数据集视频样本的示例。", "conclusion": "通过引入时间约束的视频推理分割，以及自动化基准构建方法，本研究为动态上下文中的视频分割提供了新的解决方案，有助于提高视频分析的灵活性和实用性。"}
{"llm_update_time": "20250723", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.15987", "html_url": "https://arxiv.org/abs/2507.15987", "title": "面向深度神经网络的具有结构化分层核的语义感知高斯过程校准", "title_en": "Semantic-Aware Gaussian Process Calibration with Structured Layerwise Kernels for Deep Neural Networks", "authors": "Kyung-hwan Lee,Kyung-tae Kim", "background": "神经网络分类器的置信度校准对于量化其预测可靠性至关重要，但传统的高斯过程(GP)校准方法往往无法捕捉深度神经网络的内部层次结构，限制了其解释性和评估预测可靠性的能力。", "innovation": "提出了语义感知分层高斯过程(SAL-GP)框架，该框架模仿目标神经网络的分层架构。SAL-GP采用多层GP模型，其中每层特征表示映射到本地校准修正。这些分层的GP通过结构化的多层核耦合，实现跨所有层的联合边际化。这种设计使SAL-GP能够捕捉局部语义依赖性和全局校准一致性，同时一致地在网络中传播预测不确定性。该框架增加了与网络架构一致的可解释性，并允许对深度模型的信心一致性进行有原则的评估和不确定量化。", "conclusion": "SAL-GP框架增强了与网络架构一致的可解释性，并能够对深度模型的信心一致性进行有原则的评估和不确定量化。"}
{"llm_update_time": "20250723", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.16639", "html_url": "https://arxiv.org/abs/2507.16639", "title": "在多样且具有挑战性的条件下对标猪的检测和跟踪", "title_en": "Benchmarking pig detection and tracking under diverse and challenging conditions", "authors": "Jonathan Henrich,Christian Post,Maximilian Zilke,Parth Shiroya,Emma Chanut,Amir Mollazadeh Yamchi,Ramin Yahyapour,Thomas Kneib,Imke Traulsen", "background": "为了确保猪的福利并有效管理养猪业，监测个体行为是至关重要的前提。过去，这类监测任务主要依赖手动操作，但机器学习的进步使得在自动化方式下收集个体化信息成为可能。在此类方法中，动物的空间定位（物体检测）和时间追踪（多物体跟踪）是核心内容。尽管在猪业中这两大任务已有广泛研究，但尚未系统地进行基准测试。因此，该研究填补了这一空白，创建了两个数据集：PigDetect 用于物体检测，PigTrack 用于多物体跟踪。这两个数据集基于多样化的图像和视频材料，包括现实猪舍环境及其具有挑战性的情景如遮挡或视线不佳。", "innovation": "通过对物体检测和多物体跟踪的基准测试，研究展示了在具有挑战性的训练图像下物体检测性能的提升；发现基于SORT的方法在多物体跟踪上表现出更优的检测性能，而端到端模型在关联性能方面有显著提升；识别了端到端模型的特点，并提供了未来改进的指导；证明在未见过的猪舍中训练的检测和追踪模型有良好的泛化能力，强调高质量训练数据的重要性。", "conclusion": "所创建的数据集和研究代码已被公开，以促进可重复性、再利用和进一步发展，这强调了高质数据训练的重要性，为未来研究提供了新方向。"}
{"llm_update_time": "20250723", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.16813", "html_url": "https://arxiv.org/abs/2507.16813", "title": "HOComp: 互动感知的人与物合成", "title_en": "HOComp: Interaction-Aware Human-Object Composition", "authors": "Dong Liang,Jinyuan Jia,Yuhao Liu,Rynson W.H. Lau", "background": "现有的图像引导合成方法能够在背景图像上插入前景对象到用户指定的区域，但往往无法自然地融合前景对象与背景之间的互动，尤其是在涉及人与物的互动任务中，难以生成无缝且互动感知的合成效果。", "innovation": "提出了一种名为HOComp的新颖方法，用于将前景对象合成到以人为中心的背景图像中，同时确保前景对象与背景人物之间的和谐互动以及一致外观。方法包括两个关键设计：(1) 基于MLLMs的区域驱动姿态引导 (MRPG)，利用MLLMs识别互动区域及类型（如握持、抬起），提供从粗到细的生成姿态约束，同时跟踪动作变化并施加精细姿态约束；(2) 细节一致外观保护 (DCAP)，结合形状感知的注意力调制机制、多视角外观损失和背景一致性损失，以确保前景的一致形状/纹理和背景人类的忠实再现。", "conclusion": "在所提出的数据集上进行的实验表明，HOComp 能够有效地生成和谐的人物体交互且外观一致，且在定性和定量上均优于相关方法。"}
{"llm_update_time": "20250723", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.16065", "html_url": "https://arxiv.org/abs/2507.16065", "title": "手工艺放射组学 vs. 深度放射组学 vs. 混合融合 vs. 深度学习：PET和SPECT成像基于机器学习的癌症预后全面回顾", "title_en": "Handcrafted vs. Deep Radiomics vs. Fusion vs. Deep Learning: A Comprehensive Review of Machine Learning -Based Cancer Outcome Prediction in PET and SPECT Imaging", "authors": "Mohammad R. Salmanpour,Somayeh Sadat Mehrnia,Sajad Jabarzadeh Ghandilu,Zhino Safahi,Sonya Falahati,Shahram Taeb,Ghazal Mousavi,Mehdi Maghsoudi,Ahmad Shariftabrizi,Ilker Hacihaliloglu,Arman Rahmim", "background": "机器学习（ML），包括深度学习（DL）和基于放射组学的方法，在使用PET和SPECT成像预测癌症结果方面得到了越来越多的应用。然而，手工艺放射组学特征（HRF）、深度放射组学特征（DRF）、DL模型和混合融合方法在临床应用中的比较性能仍存在不一致之处。为此，本文对2020年至2025年间发表的226项研究进行了系统分析，这些研究应用了ML技术对PET或SPECT成像进行结果预测。研究依据一个包含59项指标的框架评估了每项研究，涵盖了数据集构建、特征提取、验证方法、可解释性和偏倚风险。研究提取了包括模型类型、癌症部位、成像方式和性能指标（如准确性、曲线下面积AUC）等关键细节。", "innovation": "研究采用了详尽的评估框架来系统分析近年来发表的有关利用ML技术预测PET和SPECT成像癌症结果的研究，对比了HRF、DRF、DL模型和混合融合方法的性能差异，强调了需要标准化流程、提高数据质量以及发展可解释的AI以支持临床集成.", "conclusion": "PET基研究（95%）普遍优于SPECT，可能由于其更高的空间分辨率和敏感性。DRF模型平均准确率最高（0.862），而混合模型的AUC最高（0.861）。ANOVA验证了性能（准确性：p=0.0006，AUC：p=0.0027）存在显著差异。大部分研究存在处理类别不平衡不足、数据缺失和人口多样性低等问题，只有48%的研究符合IBSI标准。这些发现强调了需标准化工作流程、提高数据质量及发展可解释AI以支持临床集成的重要性。"}
{"llm_update_time": "20250723", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.16732", "html_url": "https://arxiv.org/abs/2507.16732", "title": "HarmonPaint: 无需训练的调和扩散图像修补", "title_en": "HarmonPaint: Harmonized Training-Free Diffusion Inpainting", "authors": "Ying Li,Xinzhe Li,Yong Du,Yangyang Xu,Junyu Dong,Shengfeng He", "background": "现有的图像 inpainting 方法通常需要大量的重新训练或微调，才能无缝地集成新内容。然而，它们在保持 inpainted 区域和周围背景在结构和风格上的连贯性方面存在困难。", "innovation": "我们提出了一种无需训练的 inpainting 框架 HarmonPaint，该框架利用扩散模型的注意力机制，实现了高质量的调和图像 inpainting，而不进行任何形式的训练。通过利用自注意力中的遮罩策略，HarmonPaint 保证了结构的准确性。此外，我们利用扩散模型的内在属性，将未遮罩区域的样式信息转移到遮罩区域，实现了风格的和谐集成。", "conclusion": "广泛的实验结果证明，HarmonPaint 在多种场景和风格下都表现出色，验证了其多样性和性能。"}
{"llm_update_time": "20250723", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.16716", "html_url": "https://arxiv.org/abs/2507.16716", "title": "通过MLLM和LLM生成高质量图像-文本数据集以增强遥感视觉语言模型", "title_en": "Enhancing Remote Sensing Vision-Language Models Through MLLM and LLM-Based High-Quality Image-Text Dataset Generation", "authors": "Yiguo He,Junjie Zhu,Yiying Li,Xiaoyu Zhang,Chunping Qiu,Jun Wang,Qiangjuan Huang,Ke Yang", "background": "视觉语言基础模型（VLFMs）在遥感（RS）图像中的应用引起了广泛关注，因为它们在多种下游任务中表现出色。但是，由于缺乏大量高质量的图像-文本配对训练数据，生成的这些数据质量较差，需要大量训练数据，但只取得微小的性能提升。", "innovation": "该论文提出了一种名为MpGI（多视角生成和集成）的两阶段方法，用于为RS图像生成高质量的文本描述。这种方法包括：1）使用Rule-MLLM聚合生成和MLLM生成方法从不同视角生成独特的、详细的描述；2）利用大型语言模型（LLMs）将这些多样化的描述整合成全面的描述，捕捉来自多个视角的细节。最终，该研究创建了HQRS-IT-210K数据集，包含约210,000张RS图像和1.3百万个描述，使用该数据集微调了两种VLFMs：判别模型CLIP和图像到文本生成模型CoCa，分别得到了HQRS-CLIP和RS-CoCa模型。实验证明，HQRS-CLIP在多种下游任务中超越了之前的SOTA RS CLIP模型，仅使用4.2％的训练数据。RS-CoCa在基准数据集上表现出色，可以生成RS图像的描述，媲美或超过人工注释。", "conclusion": "该研究的方法和模型在不同任务中都取得了优异的结果，表明使用高质量RS图像-文本配对可以显著提高视觉语言模型的性能。"}
{"llm_update_time": "20250723", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.16267", "html_url": "https://arxiv.org/abs/2507.16267", "title": "SFNet: 一种用于高效阿尔茨海默病诊断的空间-频率域深度学习网络", "title_en": "SFNet: A Spatio-Frequency Domain Deep Learning Network for Efficient Alzheimer's Disease Diagnosis", "authors": "Xinyue Yang,Meiliang Liu,Yunfang Xu,Xiaoxiao Yang,Zhengye Si,Zijin Li,Zhiwen Zhao", "background": "阿尔茨海默病（AD）是一种渐进的神经退行性疾病，主要影响老年人群体，目前尚无治疗方法。磁共振成像（MRI）作为无创成像技术，对于AD的早期诊断至关重要。MRI本质上包含空间和频率信息，原始信号在频域中被采集，通过傅里叶变换重建为空间图像。然而，现有的AD诊断模型大多仅从单一域提取特征，限制了它们对疾病复杂影像特征的全面捕捉能力。尽管一些研究表明结合了空间和频率信息，但这些方法大多局限于二维MRI，而未完全探索三维MRI的双域分析潜力。", "innovation": "为克服这一限制，本文提出了一种名为Spatio-Frequency Network (SFNet)的新型端到端深度学习框架，能够同时利用空间和频域信息，提升基于3D MRI的AD诊断能力。SFNet集成了增强的密集卷积网络来提取局部空间特征，全局频域模块来捕获全局频域表示，并提出了一种新颖的多尺度注意力模块以进一步细化空间特征提取。", "conclusion": "在Alzheimer's Disease Neuroimaging Initiative (ANDI) 数据集上的实验表明，SFNet在识别认知正常（CN）和AD方面的表现优于现有的基准模型，准确率达到了95.1%，并在计算成本方面也有显著降低。"}
{"llm_update_time": "20250723", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.16302", "html_url": "https://arxiv.org/abs/2507.16302", "title": "面向下游微调的具有抗扰性的驱动安全卸载方法", "title_en": "Towards Resilient Safety-driven Unlearning for Diffusion Models against Downstream Fine-tuning", "authors": "Boheng Li,Renjie Gu,Junjie Wang,Leyi Qi,Yiming Li,Run Wang,Zhan Qin,Tianwei Zhang", "background": "文本到图像（T2I）扩散模型已经实现了高质量的图像生成，并且越来越多地用于个性化应用场景。然而，这些模型往往因为在有毒预训练数据中继承了不安全的行为而引发了越来越多的安全担忧。最近的安全驱动卸载方法在抑制模型的毒性方面取得了显著进步，但这些方法在下游微调时显得脆弱，我们发现最先进的方法即使在完全良性的数据集上进行微调时，也难以保留其有效性。", "innovation": "本文提出了ResAlign，一种具有针对下游微调抗扰性的安全驱动卸载框架。通过使用Moreau Envelope基于的重新表述将下游微调视为隐式优化问题，ResAlign能够有效地进行梯度估计以最小化有害行为的恢复。此外，还提出了一种元学习策略来模拟一组多样化分布的微调场景，以提高泛化能力。大量跨不同数据集、微调方法和配置的实验显示，ResAlign在下游微调后在保持安全性的同时，能够很好地保留良性生成能力，通常优于先前的卸载方法。", "conclusion": "ResAlign在保持安全并保留良性生成能力方面，较以前的安全驱动卸载方法，在广泛的微调数据集、方法和配置中始终表现出色。"}
{"llm_update_time": "20250723", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.16329", "html_url": "https://arxiv.org/abs/2507.16329", "title": "DREAM: 通过概率建模实现可扩展的文本到图像生成系统红队演习", "title_en": "DREAM: Scalable Red Teaming for Text-to-Image Generative Systems via Distribution Modeling", "authors": "Boheng Li,Junjie Wang,Yiming Li,Zhiyang Hu,Leyi Qi,Jianshuo Dong,Run Wang,Han Qiu,Zhan Qin,Tianwei Zhang", "background": "尽管文本到图像（T2I）生成模型已经集成了安全对齐和外部过滤器，但这些模型仍然可能生成有害内容，如色情或暴力图像，这引发了对意外暴露和潜在误用的严重关切。主动识别可能引发不安全输出的提示被认为是评估和提高安全性的必要方法，尤其是在实际部署之前。然而，现有的自动化红队方法大多将提示发现视为独立的任务，这限制了其可扩展性、多样性和整体效果。", "innovation": "本文提出DREAM，这是一种可扩展的红队框架，能够自动发现给定T2I系统的多样化问题提示。DREAM直接建模目标系统的不良提示的概率分布，从而能够同时优化效果和多样性，并在训练后实现高效的大型采样。通过借鉴能量模型，DREAM将目标重新表述为简单可处理的目标，并引入了GC-SPSA高效优化算法，该算法能够通过长且可能的非可微分T2I管道提供稳定的梯度估计。", "conclusion": "通过广泛实验验证了DREAM的有效性，显示其在提示成功率和多样性方面的表现优于9个最先进的基线模型，涵盖了广泛的T2I模型和安全过滤器。"}
{"llm_update_time": "20250723", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.16790", "html_url": "https://arxiv.org/abs/2507.16790", "title": "使用数据集融合提高合成数据面部识别领域的多样性", "title_en": "Enhancing Domain Diversity in Synthetic Data Face Recognition with Dataset Fusion", "authors": "Anjith George,Sebastien Marcel", "background": "近年来，面部识别系统的准确性有了显著提升，但用于训练这些模型的数据集通常是通过网络爬取收集的，没有用户的明确同意，这引发了伦理和隐私方面的担忧。为了应对这一问题，许多最近的研究尝试使用合成数据来训练面部识别模型。然而，这些模型通常在性能上不如使用真实数据训练的模型，一个常见的限制是通常使用单一的生成器模型来创建整个合成数据集，这会导致与生成器固有的偏见和特征相关的模型特定的缺陷，从而导致过拟合。", "innovation": "本文提出了一种解决方案，通过合并使用架构上不同的生成器生成的两个最先进的合成面部数据集，从而融合不同数据集的优点。这种融合减少了模型特有的缺陷，提高了姿态、光照和人口统计方面的多样性，并通过强调身份相关特征隐式正则化面部识别模型。", "conclusion": "我们使用标准面部识别基准测试训练合成数据集组合模型的性能，并展示了我们的方法在许多基准测试上取得了更好的性能。"}
{"llm_update_time": "20250723", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.16480", "html_url": "https://arxiv.org/abs/2507.16480", "title": "为差异设计：人类特征如何塑造协作机器人感知", "title_en": "Designing for Difference: How Human Characteristics Shape Perceptions of Collaborative Robots", "authors": "Sabrina Livanec,Laura Londoño,Michael Gorki,Adrian Röfer,Abhinav Valada,Andrea Kiesel", "background": "随着社会协作机器人的发展，设计师面临着负责任和包容性设计的挑战，尤其是在与残疾人或高龄人士等受保护群体互动时。目前的研究较少探讨参与者如何评估机器人行为与不同人类需求的组合，因为参与者缺乏与高级家用机器人的实际经验。本研究填补了这一空白，通过激发参与者反思的方法，即使他们在经验有限的情况下也能进行有意义的评估。", "innovation": "本研究通过在线调查，让112名参与者评估了28种不同的人机协作场景的7个视频。实验组在提供评分前首先完成了一个认知-情感映射（CAM）练习。尽管CAM反思并未对整体评分产生显著影响，但它对某些特定组合的机器人行为和人类状况的评估更为明显。研究发现，不同的人类特征和互动模式影响协作机器人的接受度，强调了亲社会设计的重要性。研究还展示了反思方法如CAM在激发精细反馈方面的潜力，为面向多样化人群的用户中心和社会责任型机器人系统的开发提供了支持。", "conclusion": "本研究强调了人类特征和互动模式对协作机器人接受度的影响，强调了亲社会设计的重要性，并指出反射方法如CAM能提供细致的反馈，支持开发面向多样人群的用户中心和社会责任型的机器人系统。"}
{"llm_update_time": "20250723", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.16360", "html_url": "https://arxiv.org/abs/2507.16360", "title": "一种用于口腔鳞状细胞癌诊断和预后的高倍率组织病理图像数据集", "title_en": "A High Magnifications Histopathology Image Dataset for Oral Squamous Cell Carcinoma Diagnosis and Prognosis", "authors": "Jinquan Guan,Junhong Guo,Qi Chen,Jian Chen,Yongkang Cai,Yilin He,Zhiquan Huang,Yan Wang,Yutong Xie", "background": "口腔鳞状细胞癌（OSCC）是一种常见且具有侵袭性的恶性肿瘤，计算机辅助诊断和预后的深度学习技术可以增强临床效果。现有的公开可用的OSCC数据集通常存在患者样本量较小且聚焦于诊断或预后任一任务的问题，这限制了综合和可推广模型的发展。", "innovation": "该论文提出了一种名为Multi-OSCC的新数据集，包含1325例OSCC患者，同时整合了诊断和预后信息，以扩展现有的公共资源。每个患者由x200、x400和x1000放大倍数的六个高分辨率病理图像组成，涵盖肿瘤核心和边缘。数据集详细标注了六项关键临床任务，包括复发预测、淋巴结转移、肿瘤分化、肿瘤侵入、癌栓和神经鞘膜浸润。该研究采用了系统的方法评估了不同的视觉编码、多图像融合技术、染色标准化和多任务学习框架的效果。", "conclusion": "研究表明，最优秀的模型在复发预测与肿瘤分化方面的AUC分别达到了94.72%和81.23%，所有任务的AUC均超过了70%。染色标准化对诊断任务有益，但对复发预测不利。多任务学习相较于单任务模型略有劣势，AUC平均降低了3.34%，突显出跨任务平衡的挑战。为此，论文发布了Multi-OSCC数据集和基线模型，以便加速未来的研究。"}
{"llm_update_time": "20250723", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.16534", "html_url": "https://arxiv.org/abs/2507.16534", "title": "实践中的前沿人工智能风险管理框架：风险分析技术报告", "title_en": "Frontier AI Risk Management Framework in Practice: A Risk Analysis Technical Report", "authors": "Shanghai AI Lab:Xiaoyang Chen,Yunhao Chen,Zeren Chen,Zhiyun Chen,Hanyun Cui,Yawen Duan,Jiaxuan Guo,Qi Guo,Xuhao Hu,Hong Huang,Lige Huang,Chunxiao Li,Juncheng Li,Qihao Lin,Dongrui Liu,Xinmin Liu,Zicheng Liu,Chaochao Lu,Xiaoya Lu,Jingjing Qu,Qibing Ren,Jing Shao,Jingwei Shi,Jingwei Sun,Peng Wang,Weibing Wang,Jia Xu,Lewen Yan,Xiao Yu,Yi Yu,Boxuan Zhang,Jie Zhang,Weichen Zhang,Zhijie Zheng,Tianyi Zhou,Bowen Zhou", "background": "随着人工智能（AI）模型的快速发展，带来了前所未有的风险。为了更好地理解和识别这些风险，本报告利用前沿AI风险管理系统（SafeWork-F1-Framework）中的E-T-C分析方法（部署环境、威胁源、促成能力），全面评估了这些前沿风险，并识别出七个关键风险领域：网络攻击、生物和化学风险、说服与操纵、不受控制的自主AI研发、战略欺骗与阴谋、自我复制和协同行为。", "innovation": "本研究创新之处在于提出了以“AI-45°法则”为指导的风险评估方法，通过设定“红线”（无法容忍的阈值）和“黄线”（早期预警指标）来定义风险区域：绿色（可管理的风险，适合常规部署和持续监控）、黄色（需要加强缓解措施和控制部署）、红色（需暂停研发和/或部署）。实验结果表明，所有最新的前沿AI模型都处于绿色和黄色区域，未触及红色风险红线。详细的风险模型和深入评估有助于进一步确定生物和化学风险领域模型的风险状态。", "conclusion": "本报告反映当前对前沿AI风险的理解，并强调集体行动以应对这些挑战。所有评估的模型均未跨越黄色风险红线，尤其在网络攻击和不受控制的AI研发领域没有模型越过黄色区域。然而，自我复制和战略欺骗风险领域有足够的模型在黄色区域，而说服与操纵领域大多数模型因对人类的有效影响而处于黄色区域。生物和化学风险模型的情况仍需进一步的详细威胁建模和彻底评估。"}
{"llm_update_time": "20250723", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.16034", "html_url": "https://arxiv.org/abs/2507.16034", "title": "从超低分辨率RGB图像中改进语义分割及其在隐私保护目标导航中的应用", "title_en": "Improved Semantic Segmentation from Ultra-Low-Resolution RGB Images Applied to Privacy-Preserving Object-Goal Navigation", "authors": "Xuying Huang,Sicong Pan,Olga Zatsarynna,Juergen Gall,Maren Bennewitz", "background": "移动机器人中的用户隐私已成为一个重要问题。现有的方法通常会在执行下游机器人任务的性能和隐私保护之间做出权衡，后者往往限制了任务执行的有效性。", "innovation": "提出了一种新颖的完全联合学习方法，该方法结合了聚类特征提取器和具有语义分割感知的判别器，以解决超低分辨率语义分割问题，从而实现视觉隐私保护下的语义对象目标导航。", "conclusion": "我们在超低分辨率语义分割中性能优于不同基准方法，并且改进后的分割结果提高了现实隐私约束场景下的语义对象目标导航的成功率。"}
{"llm_update_time": "20250723", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.16621", "html_url": "https://arxiv.org/abs/2507.16621", "title": "基于目标的多LiDAR多摄像头外参校准系统", "title_en": "A Target-based Multi-LiDAR Multi-Camera Extrinsic Calibration System", "authors": "Lorenzo Gentilini,Pierpaolo Serio,Valentina Donzella,Lorenzo Pollini", "background": "外参标定是自动驾驶的基石，其准确性在感知管道中起着关键作用，任何错误都可能影响车辆的安全性。现代传感器系统收集不同类型的数据，不同传感器间的对齐变得更加困难。本文基于此背景，探讨了如何在限制先验知识的情况下，通过自定义ChArUco板和特定非线性优化方法，进行多LiDAR和多摄像头传感器套件之间的交叉校准问题，以提高车辆感知的准确性。", "innovation": "本文提出了一种基于目标的多LiDAR多摄像头外参校准系统。该系统能够利用自定义ChArUco板和特定非线性优化方法，实现在限制先验知识的情况下进行LiDAR与摄像头之间的交叉校准。此系统通过在仓库中收集的实际数据进行了测试，结果表明了该方法的有效性，证明了针对多种传感器定制的独特校准管道是可行的。", "conclusion": "本文系统地介绍了基于目标的多LiDAR多摄像头外参校准系统的研究方法及其测试结果。该系统能够克服多种传感器间数据对准的难题，提升了自动驾驶感知的精准度，具备在实际场景中的应用潜力。"}
{"llm_update_time": "20250723", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.16278", "html_url": "https://arxiv.org/abs/2507.16278", "title": "理解低容量神经网络中的泛化、鲁棒性和可解释性", "title_en": "Understanding Generalization, Robustness, and Interpretability in Low-Capacity Neural Networks", "authors": "Yash Kumar", "background": "尽管现代深度学习通常依赖于大规模过参数化模型，但对于低容量网络中容量、稀疏性和鲁棒性之间的基本相互作用，仍然存在重要的研究领域。本文通过从MNIST数据集中构建一系列具有逐步增加的视觉难度的二分类任务，探索这些性质。实验结果揭示了三个核心发现：首先，成功的泛化所需的最小模型容量直接与任务复杂性成正比；其次，这些训练网络对极端幅度剪枝（高达95%的稀疏性）具有鲁棒性，表明存在稀疏的高表现子网络；第三，过参数化在对抗输入篡改的鲁棒性方面提供了显著优势。进一步的可解释性分析通过显著性图证进一步验证了这些识别的稀疏子网络保留了原始稠密模型的核心推理过程。", "innovation": "本文提出了一种控制框架，通过从MNIST数据集创建一系列具有逐步增加的视觉难度的二分类任务，研究了低容量网络中的容量、稀疏性和鲁棒性之间的关系。实验揭示了三种核心发现：任务复杂性与最小泛化所需的模型容量直接相关；过参数化模型在对抗输入篡改的鲁棒性方面具有显著优势；这些训练网络对极端幅度剪枝表现出鲁棒性，表明存在高效、稀疏的子网络，这些子网络保留了原始密集模型的核心推理过程。", "conclusion": "本文提供了一种明确的、基于实证的证明，解释了简单神经网络中基础的权衡原则。"}
{"llm_update_time": "20250723", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.15894", "html_url": "https://arxiv.org/abs/2507.15894", "title": "Systole-Conditioned Generative Cardiac Motion", "title_en": "Systole-Conditioned Generative Cardiac Motion", "authors": "Shahar Zuler,Gal Lifshitz,Hadar Averbuch-Elor,Dan Raviv", "background": "在心脏计算机断层扫描 (CT) 成像中，准确的运动估计对评估心脏功能和手术规划至关重要。数据驱动的方法已成为密集运动估计的标准方法，但它们依赖于大量带有密集真实运动标注的标记数据，而这些标注数据常常难以获得。", "innovation": "本文提出了一种新颖的方法，用于合成包含密集3D流动场注释的现实看起来相似的CT帧配对。该方法利用条件变分自编码器（CVAE）结合了多尺度特征调节机制，并用于生成单个CT帧条件下的3D流动场。通过应用生成的流动场来扭曲给定帧，可以创建模拟心脏周期内心肌变形的真实配对帧，这些配对帧作为完全注释的数据样本提供光学流GT标注。", "conclusion": "我们的数据生成管道可以用于训练和验证更复杂和准确的心肌运动模型，从而大大减少对手动标注的依赖。相关的代码、动画生成样本及其他材料可以在我们的项目页面上获得: this https URL."}
{"llm_update_time": "20250723", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.16579", "html_url": "https://arxiv.org/abs/2507.16579", "title": "依据医疗成像合成的分层金字塔掩码扩散模型", "title_en": "Pyramid Hierarchical Masked Diffusion Model for Imaging Synthesis", "authors": "Xiaojiao Xiao,Qinmin Vivian Hu,Guanghui Wang", "background": "医学图像合成在临床流程中起着关键作用，可以解决由于扫描时间过长、扫描损坏、伪影、患者运动和对比剂不耐受等因素导致的影像模态缺失问题。常见的解决方案包括CNN生成、SDF生成、基于代理的合成等，但难以兼顾高细节和整体结构的平衡。现有的扩散模型在多尺度应用时存在训练效率低和难以平衡细节与结构完整性的问题。因此，亟需一种可以高效训练并平衡细节与结构完整性的新型扩散模型来合成高质量的医学图像。", "innovation": "本文提出了一种新的图像合成网络——分层金字塔掩码扩散模型(PHMDiff)，该模型采用多尺度分层方法，在不同分辨率和层面上对图像细节进行更精细的控制。它通过随机多尺度高比例掩码加速了扩散模型的训练，并平衡了细节保真度和整体结构。此外，该模型引入了基于Transformer的扩散模型过程，通过跨粒度正则化来增强像素级别感知准确性。实验结果表明，该模型在PSNR和SSIM上表现优异，证明了其生成高质量图像并保持结构完整性的能力。", "conclusion": "PHMDiff模型在多模态医学图像合成方面的表现优于其他方法，特别是在PSNR和SSIM上的优势明显。Ablation研究进一步验证了每个组件的贡献。所有源代码均可从此链接访问。"}
{"llm_update_time": "20250723", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.16122", "html_url": "https://arxiv.org/abs/2507.16122", "title": "MLRU++：具有注意力机制的多尺度轻量级残留UNETR++用于高效3D医学图像分割", "title_en": "MLRU++: Multiscale Lightweight Residual UNETR++ with Attention for Efficient 3D Medical Image Segmentation", "authors": "Nand Kumar Yadav,Rodrigue Rizk,Willium WC Chen, KC (Santosh AI Research Lab, Department of Computer Science and Biomedical and Translational Sciences, Sanford School of Medicine University Of South Dakota, Vermillion, SD, USA.)", "background": "准确且高效的医学图像分割对于解剖变异性和高维体数据的大量计算需求来说至关重要但具有挑战性。尽管最近的混合CNN-Transformer架构在性能上取得了最先进的成果，但是这些架构增加了显著的复杂性。因此，需要一种能够平衡分割精度和计算效率的方法。", "innovation": "MLRU++ 提出了两种创新：轻量级通道和瓶颈注意力模块 (LCBAM)，此模块通过最小开销增强上下文特征编码；多尺度瓶颈块 (M2B) 在解码器中使用多分辨率特征聚合捕捉细粒度的细节。通过在四个公开可用的基准数据集（Synapse、BTCV、ACDC、Decathlon Lung）上的实验，MLRU++达到了最先进的性能，且相比现有领先模型，显著降低了参数量和计算成本。", "conclusion": "MLRU++ 提供了一种实用且高效率的解决方案，适用于3D医学图像分割任务。"}
{"llm_update_time": "20250723", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.16779", "html_url": "https://arxiv.org/abs/2507.16779", "title": "通过L2正则化、迁移学习和深层微调提高U-Net在TEM图像数据上的置信度", "title_en": "Improving U-Net Confidence on TEM Image Data with L2-Regularization, Transfer Learning, and Deep Fine-Tuning", "authors": "Aiden Ochoa,Xinyuan Xu,Xing Wang", "background": "随着数据量的不断增加，发展自动化的手段来识别透射电子显微镜(TEM)图中的纳米尺度缺陷变得至关重要。但是，与传统照片中的特征相比，TEM图像中的纳米尺度缺陷由于其复杂的对比机制和复杂的结构，表现出了更大的变化。这导致了很少的标注数据和更高的标注错误率，这对机器学习模型的性能提升产生了阻碍。为了缓解这些问题，文中探讨了使用预训练的自然图像模型进行迁移学习的方法，并通过L2正则化选择更简单且更可靠的特征，从而显著提升了模型性能。然而，传统的评估指标如F1分数容易受到人类标注错误的影响，无法准确反映这种改进。因此，提出了一种新的独立于标注准确性的评估指标。在UO2 TEM图像的晶界检测上，证明了该方法的检测率提高了57%，显示出模型在TEM数据集上的性能得到了可靠的全面提升。最终，表明模型的自我置信度仅通过迁移学习和深层微调才能获得。", "innovation": "1. 使用大规模预训练模型进行特征提取，结合L2正则化来改进模型性能。\n2. 提出了新的独立于标注准确性的评估指标，用于评价模型在TEM图像上的表现。\n3. 通过晶界检测在UO2 TEM图像上的实例验证了该方法的有效性，发现检测率提高了57%。", "conclusion": "通过对预训练模型的迁移学习及经L2正则化的深层微调，该研究显著提升了U-Net在处理TEM图像中纳米尺度缺陷检测的应用性能。提出的新的评估指标不受标注准确率影响，证明了在该领域的有效性和全面性。最终，这种改进的置信度仅通过迁移学习和深层微调才能实现。"}
{"llm_update_time": "20250723", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.15958", "html_url": "https://arxiv.org/abs/2507.15958", "title": "量化的神经形态架构在资源受限设备上进行高效皮肤疾病分类", "title_en": "Quantization-Aware Neuromorphic Architecture for Efficient Skin Disease Classification on Resource-Constrained Devices", "authors": "Haitian Wang,Xinyu Wang,Yiren Wang,Karen Lee,Zichen Geng,Xian Zhang,Kehkashan Kiran,Yu Zhang,Bo Miao", "background": "边缘设备上准确且高效的皮肤病变分类对于可访问的皮肤科护理至关重要，但由于计算、能源和隐私限制，这一过程依然具有挑战性。", "innovation": "QANA（量化感知神经形态架构）是一种新颖的针对资源受限硬件的增量皮肤病变分类方法。QANA整合了鬼模块、高效的通道注意力机制和挤压-激励块，有效提供鲁棒的特征表示，并具备低延迟和高效推理。其量化的头部和尖峰兼容变换能够无缝转换到尖峰神经网络（SNN）并在神经形态平台上部署。", "conclusion": "QANA在大规模的HAM10000基准测试和实际临床数据集上分别实现了91.6%的Top-1精度和82.4%的宏F1，以及90.8% / 81.7%的精度，显著优于公平比较下现有的CNN-to-SNN模型。在BrainChip Akida硬件上部署时，QANA达到每张图片1.5毫秒的推理延迟和1.7微焦的能量使用，与基于GPU的CNN相比，推理延迟和能量使用分别减少了94.6% / 98.6%，超越了现有最佳CNN-to-SNN转换基准。这些结果证明QANA在边缘环境中的准确、实时、隐私敏感医学分析中的有效性。"}
{"llm_update_time": "20250723", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.16803", "html_url": "https://arxiv.org/abs/2507.16803", "title": "MultiTaskDeltaNet：基于变化检测的图像分割在原位ETEM中的应用及碳气化动力学", "title_en": "MultiTaskDeltaNet: Change Detection-based Image Segmentation for Operando ETEM with Application to Carbon Gasification Kinetics", "authors": "Yushuo Niu,Tianyu Li,Yuanyuan Zhu,Qian Yang", "background": "使用原位透射电子显微镜（ETEM）进行空间分辨操作表征固态反应需要高精度的时空特征分割。然而，传统的深度学习分割方法由于缺乏标记数据、目标特征的视觉模糊性和小对象场景而难以应对这些挑战。为了克服这些挑战，该研究引入了一种名为MultiTaskDeltaNet（MTDN）的新颖深度学习架构，该架构将分割任务重新概念化为变化检测问题，并通过使用新颖的Siamese网络与UNet主干，以及配对图像来捕捉特征变化，从而利用少量数据产生高质量的分割结果。此外，MTDN还利用多任务学习策略利用感兴趣物理特征之间的关联性。在对气化碳的原位ETEM视频数据进行评估时，MTDN在准确界定细微结构特征方面表现出明显的优越性，特别是在预测小且视觉模糊的物理特征方面，其性能提高了10.22%。这项工作在深度学习与实际ETEM图像分析之间架起了重要的桥梁，并推动了在复杂实验设置中自动化纳米材料表征的进步。", "innovation": "介绍了MultiTaskDeltaNet（MTDN），这是一种创新的深度学习架构，通过将分割任务重新概念化为变化检测问题，有效利用少量标记数据进行高质量分割。MTDN采用了独特的Siamese网络和UNet主干，并通过配对图像来捕获特征变化，利用多任务学习策略增加对感兴趣物理特征之间关联性的利用，特别擅长于准确界定细微结构特征。", "conclusion": "MTDN通过将图像分割任务作为变化检测问题重新概念化，显著改善了在空间分辨操作表征固态反应中的性能，特别是在预测小且视觉模糊的物理特征方面，相较于传统分割模型，MTDN取得了10.22%的性能提升。这项工作填补了深度学习与实际ETEM图像分析之间的差距，促进了在复杂实验条件下的纳米材料自动化表征技术的进步。"}
{"llm_update_time": "20250723", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2405.18383", "html_url": "https://arxiv.org/abs/2405.18383", "title": "2024 BraTS Meningioma Radiotherapy Planning Automated Segmentation Challenge分析", "title_en": "Analysis of the 2024 BraTS Meningioma Radiotherapy Planning Automated Segmentation Challenge", "authors": "Dominic LaBella,Valeriia Abramova,Mehdi Astaraki,Andre Ferreira,Zhifan Jiang,Mason C. Cleveland,Ramandeep Kang,Uma M. Lal-Trehan Estrada,Cansu Yalcin,Rachika E. Hamadache,Clara Lisazo,Adrià Casamitjana,Joaquim Salvi,Arnau Oliver,Xavier Lladó,Iuliana Toma-Dasu,Tiago Jesus,Behrus Puladi,Jens Kleesiek,Victor Alves,Jan Egger,Daniel Capellán-Martín,Abhijeet Parida,Austin Tapp,Xinyang Liu,Maria J. Ledesma-Carbayo,Jay B. Patel,Thomas N. McNeal,Maya Viera,Owen McCall,Albert E. Kim,Elizabeth R. Gerstner,Christopher P. Bridge,Katherine Schumacher,Michael Mix,Kevin Leu,Shan McBurney-Lin,Pierre Nedelec,Javier Villanueva-Meyer,David R. Raleigh,Jonathan Shapey,Tom Vercauteren,Kazumi Chia,Marina Ivory,Theodore Barfoot,Omar Al-Salihi,Justin Leu,Lia M. Halasz,Yuri S. Velichko,Chunhao Wang,John P. Kirkpatrick,Scott R. Floyd,Zachary J. Reitman,Trey C. Mullikin,Eugene J. Vaios,Christina Huang,Ulas Bagci,Sean Sachdev,Jona A. Hattangadi-Gluth,Tyler M. Seibert,Nikdokht Farid,Connor Puett,Matthew W. Pease,Kevin Shiue,Syed Muhammad Anwar,Shahriar Faghani,Peter Taylor,Pranav Warman,Jake Albrecht,András Jakab,Mana Moassefi,Verena Chung,Rong Chai,Alejandro Aristizabal,Alexandros Karargyris,Hasan Kassem,Sarthak Pati,Micah Sheller,Nazanin Maleki,Rachit Saluja,Florian Kofler,Christopher G. Schwarz,Philipp Lohmann,Phillipp Vollmuth,Louis Gagnon,Maruf Adewole,Hongwei Bran Li,Anahita Fathi Kazerooni,Nourel Hoda Tahon,Udunna Anazodo,Ahmed W. Moawad,Bjoern Menze,Marius George Linguraru,Mariam Aboian,Benedikt Wiestler,Ujjwal Baid,Gian-Marco Conte,Andreas M. Rauschecker,Ayman Nada,Aly H. Abayazeed", "background": "2024年BraTS-MEN-RT挑战赛旨在利用包含750个多机构放射治疗计划脑部MRI的已知最大数据集，推进自动化分割算法。这些MRI来源于进行过常规外照射放疗或立体定向放射外科的患者，且包含完整或术后脑膜瘤。每例病例都包括一个去标识的对比增强T1加权MRI，并附带一个代表肿瘤体积（GTV）和任何术后风险区域的单标签“目标体积”。目标体积遵循既定放射治疗计划协议进行注释，确保了案件和机构之间的连贯性，并由专家神经放射科医生和放射肿瘤学家审核批准。", "innovation": "六个团队开发、容器化并使用了全面数据集评估了自动化分割模型。排名基于修改后的病灶级Dice相似性系数（DSC）和95%霍夫多夫距离（95HD）评估。最佳报告的平均病灶级DSC和95HD为0.815和26.92毫米，分别。BraTS-MEN-RT挑战赛通过精确的肿瘤分割和定制化治疗，预计能显著推进自动放射治疗计划，最终改善患者结果.", "conclusion": "BraTS-MEN-RT挑战赛的设计和结果描述了最新的自动化分割模型的开发和评估，有助于促进自动放射治疗规划和优化患者治疗效果."}
{"llm_update_time": "20250723", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2407.04476", "html_url": "https://arxiv.org/abs/2407.04476", "title": "重新思考点云上采样的数据输入", "title_en": "Rethinking Data Input for Point Cloud Upsampling", "authors": "Tongxu Zhang", "background": "点云上采样对于3D重建任务至关重要。现有的方法主要依赖于patch-based输入，但在点云完整输入和patch-based输入之间的差异和原则方面，目前尚无相关研究讨论。因此，研究团队提出了一种新颖的方法，使用完整的模型输入，即均值片段输入。通过在PU1K和ABC数据集上的实验结果表明，patch-based输入的效果始终优于完整的模型输入。为了阐明这一点，研究团队进一步探究了特征提取和网络架构对上采样结果的影响因素", "innovation": "提出了一种新的方法——使用完整的模型输入（均值片段输入），并对比了patch-based输入与完整模型输入在点云上采样任务中的表现，揭示了特征提取和网络架构的影响因素", "conclusion": "实验结果显示patch-based输入方法在点云上采样任务中表现优于完整模型输入方法。这表明patch-based输入可能是一种更有效的策略，未来的研究可能会更关注于patch-based输入的特点和优化"}
{"llm_update_time": "20250723", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2207.00477", "html_url": "https://arxiv.org/abs/2207.00477", "title": "基于高分辨率人体姿态估计的智能安全机场基于视觉的拥挤人群中的冲突检测", "title_en": "Vision-based Conflict Detection within Crowds based on High-Resolution Human Pose Estimation for Smart and Safe Airport", "authors": "Karan Kheta,Claire Delgove,Ruolin Liu,Adeola Aderogba,Marc-Olivier Pokam,Muhammed Mehmet Unal,Yang Xing,Weisi Guo", "background": "机场由于旅客数量的增加变得越来越复杂和拥挤，从而增加了潜在冲突的发生几率，可能导致航班延误和安全问题。为了提高乘客的安全性、节省成本并提高旅行效率，需要一种智能算法来更有效地检测冲突，增强安全监控系统的效果。本文探讨了通过机器学习模型来识别拥挤人群中的冲突行为，以提高机场安全性和效率的方法。", "innovation": "提出的创新点在于利用HRNet进行图像分割和基于多个分类器的方法来估计人体姿态，以识别拥挤人群中的冲突行为。通过实验发现，SVM在识别准确率上表现最佳，达到了94.37%的精度。不过，该模型在处理模糊行为（如拥抱）或在帧中失去目标对象时存在不足。", "conclusion": "该模型具有在机场部署的潜力，但需改进以应对大量乘客，并进一步提高处理模糊行为的能力。改进后，该模型有望增强机场的安全监控能力，提高机场的整体安全性。"}
{"llm_update_time": "20250723", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2408.00998", "html_url": "https://arxiv.org/abs/2408.00998", "title": "FBSDiff: 在DCT频谱空间中插即用的扩散特征频带替代以实现高度可控的文本驱动图像翻译", "title_en": "FBSDiff: Plug-and-Play Frequency Band Substitution of Diffusion Features for Highly Controllable Text-Driven Image Translation", "authors": "Xiang Gao,Jiaying Liu", "background": "大规模的文本到图像扩散模型是生成人工智能和多模态技术进化的里程碑，能够根据自然语言文本提示生成奇妙的图像，但是这些模型缺乏可控性，限制了在实际内容创作中的应用。为解决此问题，关注利用参考图像控制文本到图像合成，即将参考图像按照文本提示进行调整或编辑，也就是文本驱动的图像到图像转换。已有研究通过控制系统训练、微调或在线优化过程来提高图像翻译的视觉质量和可控性。", "innovation": "本文提出了一种新颖的、简明高效的插即用的方式，将预训练的大规模文本到图像扩散模型适应到图像到图像范式，无需任何模型训练、微调或在线优化过程即可实现高质量和灵活的文本驱动的图像到图像翻译。通过在DCT频谱空间中分解不同的频率带扩散特征，并提出了一种新的频率带替代层，实现了参考图像对T2I生成结果的动态控制，仅通过调整替代频率带的类型和带宽即可灵活控制参考图像的引导因素和引导强度。", "conclusion": "大量定性和定量实验表明，本文的方法在图像到图像翻译的视觉质量、灵活性和可控性方面优于相关方法。代码已在该网址公开：this https URL"}
{"llm_update_time": "20250723", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.16573", "html_url": "https://arxiv.org/abs/2507.16573", "title": "基于语义分割的胸部CT图像在经导管主动脉瓣置换术术前规划中的应用", "title_en": "Semantic Segmentation for Preoperative Planning in Transcatheter Aortic Valve Replacement", "authors": "Cedric Zöllner,Simon Reiß,Alexander Jaus,Amroalalaa Sholi,Ralf Sodian,Rainer Stiefelhagen", "background": "在基于医学图像进行手术前规划时，人工智能方法能够辅助医务人员进行评估。本文考虑了经导管主动脉瓣置换术（TAVR）的术前规划指南，并识别出可以通过语义分割模型进行自动化的任务，以提高这些结构的可测量性。", "innovation": "1. 提出了一种从粗粒度解剖信息中推导出精细粒度的TAVR相关伪标签的方法，用于训练分割模型并评估其性能。\n2. 提出了对训练分割模型的损失函数的调整，从而在性能上实现+1.27%的Dice系数提升。", "conclusion": "本文通过细粒度的TAVR相关伪标签和基于此构建的CT扫描数据，展示了其在提高CT图像中病灶识别精度上的有效性。"}
{"llm_update_time": "20250723", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2408.10872", "html_url": "https://arxiv.org/abs/2408.10872", "title": "V-RoAst: Visual Road Assessment. Can VLM be a Road Safety Assessor Using the iRAP Standard？", "title_en": "V-RoAst: Visual Road Assessment. Can VLM be a Road Safety Assessor Using the iRAP Standard?", "authors": "Natchapon Jongwiriyanurak,Zichao Zeng,June Moh Goo,Xinglei Wang,Ilya Ilyankou,Kerkritt Sriroongvikrai,Nicola Christie,Meihui Wang,Huanfa Chen,James Haworth", "background": "道路安全评估至关重要但成本高昂，特别是在低收入和中等收入国家（LMICs），其中大多数道路未进行评级。传统方法需要专家标注和训练数据，而基于监督学习的方法则难以跨地区泛化。因此，亟需一种新的方法来有效地评估道路安全。", "innovation": "本文介绍了一种名为 V-RoAst 的框架，使用视觉语言模型（VLM）对由 iRAP 标准定义的道路安全属性进行分类。首次提出了一个来自 ThaiRAP 的开源数据集，其中包括超过 2,000 张泰国街道级别的图片，并进行了此任务的标注。实验结果显示，尽管 VLM 在空间感知方面表现不佳，但它们在未见过的类别上泛化能力强，并且可以基于提示进行灵活的推理，无需重新训练。这为零样本基础设施风险评估开辟了新的方向，并为自动、低成本的道路安全地图绘制提供了新的可能性。", "conclusion": "本研究是首次探索 VLM 用于零样本基础设施风险评估，VLM 可以作为与补充数据集成的自动道路评估工具。这项工作为自动、低成本的道路安全地图绘制打开了新的方向。"}
{"llm_update_time": "20250723", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2410.13911", "html_url": "https://arxiv.org/abs/2410.13911", "title": "GraspDiffusion: 合成逼真的全身手-物体交互", "title_en": "GraspDiffusion: Synthesizing Realistic Whole-body Hand-Object Interaction", "authors": "Patrick Kwon,Chen Chen,Hanbyul Joo", "background": "最近的生成模型能够合成高质量的图像，但往往无法生成人类用手与物体交互的场景。这主要是因为模型对这些交互的误解，以及合成人体复杂部位的难度。现有的合成方法在这方面存在困难，未能充分处理手与物体交互的细节。", "innovation": "本文提出了一种新型生成方法GraspDiffusion，用于创建人类与物体交互的真实场景。它通过利用3D人体和手部姿势的生成先验知识，优化它们以形成联合抓取姿态，从而生成现实且多样的人类与物体交互场景。", "conclusion": "实验结果表明，GraspDiffusion能够成功应对生成全身手-物体交互这一未充分研究的问题，并且在与其他方法的比较中表现出色。我们将在指定链接提供代码和模型。"}
{"llm_update_time": "20250723", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2410.01738", "html_url": "https://arxiv.org/abs/2410.01738", "title": "VitaGlyph: Vitalizing Artistic Typography with Flexible Dual-branch Diffusion Models", "title_en": "VitaGlyph: Vitalizing Artistic Typography with Flexible Dual-branch Diffusion Models", "authors": "Kailai Feng,Yabo Zhang,Haodong Yu,Zhilong Ji,Jinfeng Bai,Hongzhi Zhang,Wangmeng Zuo", "background": "艺术型态设计是一种将输入字符的意义以想象和可读的方式视觉化的技术。现有的方法使用强大的文本到图像扩散模型直接设计输入字符的整体几何形状和纹理，这使得同时确保创造性和可读性变得具有挑战性。", "innovation": "提出了一个无需训练的方法VitaGlyph，采用双分支架构，能够在保持可读性的基础上实现灵活的艺术型态设计，并能够控制几何变化。关键在于将输入字符视为由主体和周围环境组成的场景，并使用不同程度的几何变换来渲染。", "conclusion": "实验结果证明VitaGlyph不仅能够实现更好的艺术性和可读性，还能够表达多个定制概念，使得艺术型态设计更具创造力和吸引力。我们的代码将公开发布。"}
{"llm_update_time": "20250723", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2411.07231", "html_url": "https://arxiv.org/abs/2411.07231", "title": "Watermark Anything with Localized Messages", "title_en": "Watermark Anything with Localized Messages", "authors": "Tom Sander,Pierre Fernandez,Alain Durmus,Teddy Furon,Matthijs Douze", "background": "现有的图像水印方法不适用于处理小的水印区域。这限制了它们在实际应用场景中的应用，因为图像的一部分可能来自不同的来源或已经经过编辑。当前的水印方法难以在高分辨率图像中对小区域进行有效水印，尤其是在拼接图像和修复操作下，导致水印易受损。", "innovation": "本文提出了一种基于深度学习的局部图像水印模型，名为Watermark Anything Model (WAM)。该模型能够在输入图像上进行不可感知的修改，并能从接收到的图像的水印区域中分割和恢复隐藏消息。WAM在低分辨率下同时训练嵌入器和提取器，重点是在修改后保持图像的不可感知性，并且可以处理多个水印。WAM的独特之处在于其能够处理拼接图像中的水印区域，并从非常小的区域（不超过图像面积的10%，甚至256x256的小图像）中提取32位消息，错误率低于1位。", "conclusion": "实验结果表明，WAM在不可感知性和鲁棒性方面与现有最先进的方法相当，特别是在对抗修补和拼接的攻击下，即便是在高分辨率图像上也是如此。WAM模型提供了新的功能，特别是在处理拼接图像和从小尺寸区域中提取水印方面。训练和推理代码及模型权重在提供的链接中可以获取。"}
{"llm_update_time": "20250723", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2411.07918", "html_url": "https://arxiv.org/abs/2411.07918", "title": "Mueller矩阵极化成像中物理一致性图像增强方法", "title_en": "Physically Consistent Image Augmentation for Deep Learning in Mueller Matrix Polarimetry", "authors": "Christopher Hahne,Omar Rodriguez-Nunez,Éléa Gros,Théotim Lucas,Ekkehard Hewer,Tatiana Novikova,Theoni Maragkou,Philippe Schucht,Richard McKinley", "background": "Mueller矩阵极化成像能够捕捉样本中偏振光相互作用的关键信息。偏振信息的特殊性增加了使用深度学习的数据增强的难度。标准的数据增强技术（如旋转和翻转）在穆勒矩阵图像中的偏振性质无法保持。因此，传统的方法可能导致假数据，影响模型的性能和适用性。研究者需要一个物理上一致的方法来进行数据增强，以保持偏振的准确性。我们的实验结果表明，传统数据增强在应用到极化数据时容易导致假数据结果的出现，这突显了我们物理基础方法的必要性。我们框架的优势在于可应用于偏振数据并提高了模型的一般化能力和性能，特别是在样本量有限的情况下，使深度学习模型在偏振成像中的应用更加广泛和稳健。我们的研究结果验证了物理一致性数据增强方法的重要性，这将有助于更为广泛的研究领域的应用。", "innovation": "我们提出了一种物理上一致的旋转和翻转框架，用于穆勒矩阵图像的数据增强，专门用于保持偏振的准确性。通过与真实世界的捕获数据进行比较，并将其应用于语义分割任务，我们验证了这种物理一致性数据增强的有效性，并且这一方法显著提高了模型的一般化能力和性能。我们的工作展示了在偏振成像的深度学习中，物理上的一致性数据增强的必要性，并为涉及偏振数据的小样本大小情况下的应用打开了前景。", "conclusion": "我们的研究强调了在穆勒矩阵极化成像中采用物理一致的数据增强方法的重要性，为这一领域的深度学习应用铺设了道路，使更广泛的深入研究和更强大的应用成为可能。"}
{"llm_update_time": "20250723", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2403.08255", "html_url": "https://arxiv.org/abs/2403.08255", "title": "通过图像扩散模型激发情感：Make Me Happier", "title_en": "Make Me Happier: Evoking Emotions Through Image Diffusion Models", "authors": "Qing Lin,Jingfeng Zhang,Yew-Soon Ong,Mengmi Zhang", "background": "尽管图像生成技术取得了迅速进展，但情感图像编辑研究仍处于起步阶段。图像中的语义、上下文和结构能够引起情感反应，使得情感图像编辑技术在心理障碍治疗、产品商业化及艺术设计等多个实际应用领域中具有重要价值。", "innovation": "本文提出了一种新的情感引发图像生成挑战，旨在生成能够唤起目标情感的同时保留原始场景语义和结构的图像。为了解决这一挑战，本文提出了一种扩散模型，该模型能够有效理解和编辑源图像以传递所需的情感和情感。此外，由于缺乏情感编辑数据集，本文提供了一个包含340,000对图像及其情感注释的独特数据集，并进行了人类心理物理学实验，引入了新的评估指标来系统评估各种方法。", "conclusion": "实验结果表明，本文方法超越了所有竞争基线。本文的扩散模型能够从原始图像中识别情感线索，编辑能够引发所需情感的图像，并同时保留原始图像的语义结构。所有代码、模型和数据集均可在GitHub上获取。"}
{"llm_update_time": "20250723", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2411.16934", "html_url": "https://arxiv.org/abs/2411.16934", "title": "使用主观流媒体对象记忆进行在线情景记忆视觉查询定位", "title_en": "Online Episodic Memory Visual Query Localization with Egocentric Streaming Object Memory", "authors": "Zaira Manigrasso,Matteo Dunnhofer,Antonino Furnari,Moritz Nottebaum,Antonio Finocchiaro,Davide Marana,Rosario Forte,Giovanni Maria Farinella,Christian Micheloni", "background": "现有的情景记忆检索技术假设在查询时可以完全访问视频，这对于带有限制功率和存储的可穿戴设备在实际场景中应用非常有限。", "innovation": "引入了Online Visual Query 2D (OVQ2D) 任务，该任务使模型能够在处理视频流过程中在线进行操作，每个帧只观察一次，通过紧凑的记忆存储对象定位，而非依赖完整的视频历史；提出了ESOM（主观流媒体对象记忆）框架，该框架结合了目标发现模块、跟踪模块和记忆模块，旨在查找、跟踪和存储时空对象信息以实现高效查询。", "conclusion": "实验结果表明，ESOM在Ego4D数据集上的性能优于其他在线方法，但OVQ2D任务仍然具有挑战性，尽管如此，ESOM的准确性在完美的对象跟踪、发现或两者结合的情况下显著提高，强调了对照顾这些组件的研究的需求。"}
{"llm_update_time": "20250723", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2412.05888", "html_url": "https://arxiv.org/abs/2412.05888", "title": "MCP-MedSAM: 在单个GPU上仅需一天训练的强大轻量级医学 Segment Anything 模型", "title_en": "MCP-MedSAM: A Powerful Lightweight Medical Segment Anything Model Trained with a Single GPU in Just One Day", "authors": "Donghang Lyu,Ruochen Gao,Marius Staring", "background": "医学图像分割涉及将医学图像划分为有意义的区域，重点是识别解剖结构和病变。近年来，深度学习方法在自动化这一过程方面取得了显著进展。近期，Segment Anything Model (SAM) 作为一种针对分割任务的第一个基础模型被引入，但其庞大的模型规模和高GPU需求限制了其在医学领域的应用和发展。", "innovation": "本文提出MCP-MedSAM，这是一种强大且轻量级的医学SAM模型，能够在单张A100 GPU（40GB内存）上一天内完成训练，并提供卓越的分割性能。该模型通过引入模态提示和内容提示来改善分割性能，同时采用模态基于的高效数据采样策略处理不同医学模态之间的数据不平衡问题。MCP-MedSAM在大规模挑战数据集上的训练和评估表明，其性能超过其他顶级方法，同时仅需一天的单GPU训练时间。相关代码已公开发布。", "conclusion": "MCP-MedSAM在单个GPU上只需要一天的训练时间就能实现强大的医学分割性能，有效解决了医学领域中SAM模型的规模和GPU需求问题，为医学图像分割领域带来了新的突破。"}
{"llm_update_time": "20250723", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2412.08629", "html_url": "https://arxiv.org/abs/2412.08629", "title": "FlowEdit：使用预训练流模型的无倒置文本基础编辑", "title_en": "FlowEdit: Inversion-Free Text-Based Editing Using Pre-Trained Flow Models", "authors": "Vladimir Kulikov,Matan Kleiner,Inbar Huberman-Spiegelglas,Tomer Michaeli", "background": "当前使用预训练的文本到图像(T2I)扩散/流模型编辑真实图像时，通常需要将图像转换为其相应的噪声图，然后通过干预采样过程以获得更满意的结果。然而，这种方法在不同模型架构之间不易于无缝迁移。本文旨在介绍一种新的编辑方法，以解决这一问题，该方法无需倒置、无需优化且模型无关。", "innovation": "提出了FlowEdit方法，这是一种基于文本的编辑方法，适用于预训练的T2I流模型。该方法直接通过一个ODE映射源分布和目标分布，并且比倒置方法具备更低的传输成本。这种方法能够实现当前最先进的结果，例如应用在Stable Diffusion 3和FLUX中。", "conclusion": "该研究展示了FlowEdit方法的优势，证明其能够提供更好的图像编辑效果，并且易于适用于不同的模型架构，同时提供了代码和示例。"}
{"llm_update_time": "20250723", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2411.06106", "html_url": "https://arxiv.org/abs/2411.06106", "title": "通过学习个性化不变表示实现通用3D医学多模态泛化的探索", "title_en": "Towards a Universal 3D Medical Multi-modality Generalization via Learning Personalized Invariant Representation", "authors": "Zhaorui Tan,Xi Yang,Tan Pan,Tianyi Liu,Chen Jiang,Xin Guo,Qiufeng Wang,Anh Nguyen,Yuan Qi,Kaizhu Huang,Yuan Cheng", "background": "医学成像模态的不同基础原理带来了多模态医学任务中的泛化挑战。除了模态之间的差距，个体差异，如器官大小和代谢率的不同，进一步阻碍了模型在多模态和多样化人口之间的有效泛化。尽管个性化非常重要，但现有方法通常忽视了个体差异，仅关注共同的解剖特征。这一限制可能导致在各种医学任务中泛化的减弱。", "innovation": "本文揭示个性化对于多模态泛化的关键性。提出了通过利用个体层面的约束和可学习的生物学先验来近似各种模态下个性化不变表征${X}_h$的方法，从而实现个性化泛化。实验证明，学习个性化表征${X}_h$的可行性及其带来的好处，这种表示在多种多模态医学任务中具有高度的泛化和转移能力。跨不同场景的广泛实验证据显示，纳入的个性化可以在泛化方面显著提高性能，证明了其有效性。", "conclusion": "综合实验结果表明，额外的个性化纳入显著改善了在多样场景中的性能和泛化，证实了其有效性。"}
{"llm_update_time": "20250723", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.16814", "html_url": "https://arxiv.org/abs/2507.16814", "title": "半策略强化学习在视觉-语言慢思考推理中的应用", "title_en": "Semi-off-Policy Reinforcement Learning for Vision-Language Slow-thinking Reasoning", "authors": "Junhao Shen,Haiteng Zhao,Yuzhe Gu,Songyang Gao,Kuikun Liu,Haian Huang,Jianfei Gao,Dahua Lin,Wenwei Zhang,Kai Chen", "background": "大规模视觉-语言模型（LVLMs）在解决复杂多模态任务方面至关重要，但主要通过视觉-语言对齐训练，使得难以采用基于策略的强化学习来培养慢思考能力。虽然离策咯强化学习可以超越当前策略，但直接从外部模型提取轨迹可能会导致视觉幻觉，因为模型间视觉感知能力存在不匹配。", "innovation": "提出了SOPHIA，这是一种简单且可扩展的半离策略RL方法，通过结合可训练LVLM的视觉理解与语言模型的离策略慢思考推理来构建半离策略行为模型，并通过基于结果的奖励对推理进行评估，反向传播视觉奖励。这样，LVLM可以通过离策略RL算法从获取到的推理轨迹中学到慢思考推理能力。", "conclusion": "通过广泛的实验，SOPHIA提高了InternVL3.0-38B的性能达8.50%，在多个多模态推理基准上达到了开源LVLM的最先进性能，并在具有挑战性的MathVision和OlympiadBench任务上超过了一些封闭源代码模型，准确性分别为49.08%和49.95%的pass@1。分析表明，SOPHIA优于监督微调和直接基于策略的RL方法，为后续基于策略的训练提供了更好的初始化策略。"}
{"llm_update_time": "20250723", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2412.10908", "html_url": "https://arxiv.org/abs/2412.10908", "title": "大型语言视觉模型理解3D形状吗？", "title_en": "Do large language vision models understand 3D shapes?", "authors": "Sagi Eppel", "background": "大型视觉语言模型（LVLM）是实现对世界的广泛视觉理解的领先人工智能方法。GPT、Claude、Gemini和LLama等模型能够使用图像来理解和分析复杂的视觉场景。3D对象和形状是世界的基本构建块，识别它们是人类感知的基本部分。这项工作的目标是测试这些大型视觉语言模型是否真正理解3D形状，具体测试模型识别和匹配具有不同方向和材料/纹理的相同3D形状的能力。", "innovation": "研究使用大量使用CGI创建的测试图像，包含大量高度多样的对象、材料和场景，以评估大型视觉语言模型匹配3D形状的能力。结果显示，这些模型在匹配3D形状方面的表现低于人类，但高于随机猜测。这表明模型在一定程度上获得了对3D形状的抽象理解，但在这一任务上仍远不及人类。", "conclusion": "对于具有不同方向但相同对象，以及相同方向但不同材料和纹理的相同3D形状，模型能够很容易地识别。然而，当对象的材料和方向同时改变时，所有模型相对于人类的表现都很差。此外，研究的代码和基准已经公开。"}
{"llm_update_time": "20250723", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2410.01817", "html_url": "https://arxiv.org/abs/2410.01817", "title": "使AI与公共价值观一致：政治视频分析中治理多模态LLM的讨论与决策", "title_en": "Aligning AI with Public Values: Deliberation and Decision-Making for Governing Multimodal LLMs in Political Video Analysis", "authors": "Tanusree Sharma,Yujin Potter,Zachary Kilhoffer,Yun Huang,Dawn Song,Yang Wang", "background": "关于AI模型如何处理政治话题已经进行了讨论，但仍面临挑战且需要更好的治理。本文通过个体和集体讨论的途径考察了大型语言模型的治理，特别是针对政治敏感的视频内容。", "innovation": "本文采用两步研究方法：首先，通过与10位记者的访谈建立专家对于视频解释的基准理解；其次，通过纳入114名使用InclusiveAI平台（一种利用分散自治组织(DAO)机制促进民主决策的平台）的个体的讨论，来探讨不同治理机制（如二次投票和加权投票，以及平等投票和80/20投票权重）如何影响用户对AI行为的决策。研究发现不同的投票方法对结果有显著影响，二次投票强化了对公民民主和政治平等的看法。", "conclusion": "本文强调了选择合适的治理机制的重要性，以更好地捕获用户观点，并建议分散的AI治理作为促进更广泛的公共参与AI发展的潜在方式，确保多样化的视角能够有意义地影响设计决策。"}
{"llm_update_time": "20250723", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2410.12332", "html_url": "https://arxiv.org/abs/2410.12332", "title": "MC-Bench: 在多模态大语言模型时代多上下文视觉接地基准", "title_en": "MC-Bench: A Benchmark for Multi-Context Visual Grounding in the Era of MLLMs", "authors": "Yunqiu Xu,Linchao Zhu,Yi Yang", "background": "尽管多模态大规模语言模型（MLLMs）已经在视觉-语言理解方面表现出色，但它们解决基于多张图片的实例级视觉-语言问题的能力仍然需要进一步研究。为了评估这些未被验证的能力，本文提出了一个名为多上下文视觉接地的新视觉定位任务，该任务旨在根据开放式的文本提示，在多张图像中定位感兴趣的目标实例。", "innovation": "本文构建了一个名为MC-Bench的新数据集，包含了2000个高质量且手工标注的样本，每个样本包含一个实例级标注的图像对和相应的文本提示，这些文本提示覆盖了20种实用技能，具有高度开放性，遵循三种不同的风格。此外，本文还对多种现有的MLLMs和具有多上下文视觉接地能力的基础模型进行了基准测试，并开发了一个简单的基线方法和一个多上下文指令微调的微调基线方法。", "conclusion": "评估结果揭示了现有的MLLMs和人类之间的非平凡性能差距，并提供了一些有价值的观点，表明MLLMs在实例级任务中的未来方向。我们希望MC-Bench及其经验发现能够鼓励研究社区进一步挖掘MLLMs在多图像上下文中实例级任务的潜力。"}
{"llm_update_time": "20250723", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2501.07525", "html_url": "https://arxiv.org/abs/2501.07525", "title": "RadAlign: 视觉语言概念对齐促进放射学报告生成", "title_en": "RadAlign: Advancing Radiology Report Generation with Vision-Language Concept Alignment", "authors": "Difei Gu,Yunhe Gao,Yang Zhou,Mu Zhou,Dimitris Metaxas", "background": "自动胸部X光解读需要准确的疾病分类和详细的放射学报告生成，这对临床工作流程构成了重大挑战。当前的方法要么在分类准确性和解释性之间取舍，要么使用图像描述技术生成详细但可能不可靠的报告。为了应对这一挑战，本研究提出了一种名为RadAlign的新框架，该框架结合了视觉语言模型（VLMs）的预测准确性和大型语言模型（LLMs）的推理能力，以模仿放射学的工作流程。", "innovation": "RadAlign框架通过VLMs对视觉特征与关键医学概念进行对齐，实现了在多个疾病上的平均AUC值达到0.885的优秀疾病分类。通过LLMs生成报告，并结合检索增强生成机制，RadAlign在GREEN评分上达到0.678，优于最先进的方法0.634。该框架提高了临床解释性并减少了幻觉，推动了集成预测和生成AI的自动化医学影像和报告分析。", "conclusion": "RadAlign框架结合了视觉语言模型和大型语言模型，提高了疾病分类的准确性和报告生成的质量，增强临床解释性，减少了幻觉，对自动化医学影像和报告分析有显著的推进作用。"}
{"llm_update_time": "20250723", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2502.06631", "html_url": "https://arxiv.org/abs/2502.06631", "title": "基于视觉语言模型的人类行为识别中的可信区间预测", "title_en": "Conformal Predictions for Human Action Recognition with Vision-Language Models", "authors": "Bary Tim,Fuchs Clément,Macq Benoît", "background": "在高风险的实际应用中，人类决策者与人工智能系统的合作至关重要。人类在环(HITL)系统在这种场景下必不可少。传统的基于视觉语言模型(VLM)的人类行为识别(HAR)系统需要提升其可靠性。现有的方法主要是通过增强预测的覆盖范围来保证系统的性能，但是这种方法在实际应用中常常因为分布尾长的问题限制了其实用性。", "innovation": "本文探讨了如何利用可信区间预测(CP)技术提高基于视觉语言模型的人类行为识别系统的可靠性。创新点在于提出了一种无需额外校准数据的通过调整softmax预测的温度来减少候选类别的数量的方法。这种技术能够显著减少系统所需识别的候选类别数量，从而提升效率。", "conclusion": "本文研究表明，通过调整softmax预测的温度，CP可以显著减少基于视觉语言模型的人类行为识别系统的候选类别数量，但这也导致了分布尾长的问题，影响了其实际应用中的表现。为了弥补这一缺陷，我们提出了一种新的方法来调节softmax的温度以优化模型的表现。本研究为动态实际环境中的人机多模态交互提供了进一步的努力。"}
{"llm_update_time": "20250723", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2502.11809", "html_url": "https://arxiv.org/abs/2502.11809", "title": "通过人类视觉解耦的几何机制揭示深度神经网络中的偏差形成", "title_en": "Revealing Bias Formation in Deep Neural Networks Through the Geometric Mechanisms of Human Visual Decoupling", "authors": "Yanbiao Ma,Bowei Liu,Boyuan Gao,Wei Dai,Jiayi Chen,Shuo Li,Andi Zhang", "background": "深度神经网络（DNNs）在物体识别过程中常常对某些类别表现出偏好，即使是在均衡训练数据条件下也是如此。这些偏好背后的内在机制尚不清楚。受到人类视觉系统启发，该系统通过分层处理解耦物体表征以实现物体识别，本文提出了一种几何分析框架，将类特定知觉流形的几何复杂性与模型偏差联系起来。研究表明，几何复杂性的差异会导致不同类别的识别能力不同，从而引入偏差。", "innovation": "本文通过人类视觉解耦的几何机制，提出了一个几何分析框架，将类特定知觉流形的几何复杂性与模型偏差联系起来，揭示了深度神经网络中偏差形成的原因。同时，作者还开发了一个名为Perceptual-Manifold-Geometry的库，用于计算知觉流形的几何属性。", "conclusion": "本文通过人类视觉系统中的几何机制分析了深度神经网络中的偏差形成，揭示了几何复杂性差异导致的识别能力差异。研究结果表明，通过几何分析可以更好地理解DNN中的偏差问题，并为改进DNN模型提供了新的视角。"}
{"llm_update_time": "20250723", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2502.09110", "html_url": "https://arxiv.org/abs/2502.09110", "title": "通过对比辅助网络进行揭开掩饰：无监督对抗检测", "title_en": "Pulling Back the Curtain: Unsupervised Adversarial Detection via Contrastive Auxiliary Networks", "authors": "Eylon Mizrahi,Raz Lapid,Moshe Sipper", "background": "深度学习模型在安全关键应用中广泛应用，但仍然容易受到对抗攻击影响——这些是不可感知的微小扰动，能够显著降低模型性能。传统的防御机制主要集中在增强模型鲁棒性或独立检测对抗输入。", "innovation": "本文提出了一种名为 Unsupervised adversarial detection via Contrastive Auxiliary Networks (U-CAN) 的无监督对抗检测方法，该方法在目标模型的特定中间层中嵌入。辅助网络包括投影层和基于 ArcFace 的线性层，旨在更加有效地区分良性输入和对抗输入，而无需使用对抗样本。实验结果表明，该方法在多个数据集（CIFAR-10、Mammals 和 ImageNet 的子集）和架构 (ResNet-50、VGG-16 和 ViT) 上优于现有的无监督对抗检测技术。", "conclusion": "提出的框架提供了增强深度学习系统安全性和可靠性的可扩展且有效的方法。"}
{"llm_update_time": "20250723", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2502.16748", "html_url": "https://arxiv.org/abs/2502.16748", "title": "GS-TransUNet：结合二维高斯散射和Transformer UNet实现准确的皮肤病变分析", "title_en": "GS-TransUNet: Integrated 2D Gaussian Splatting and Transformer UNet for Accurate Skin Lesion Analysis", "authors": "Anand Kumar,Kavinder Roghit Kanthen,Josna John", "background": "近年来，计算机视觉和深度学习技术的发展加快了皮肤癌的早期检测速度和一致性。然而，现有的皮肤病变分割和分类预测模型是独立运行的，因此错过了它们集成执行的潜在效率。", "innovation": "本文提出了一种新的方法——高斯散射-Transformer UNet (GS-TransUNet)，该方法结合了二维高斯散射与Transformer UNet架构，实现了自动化皮肤癌诊断。本文构建的统一深度学习模型可以在临床诊断中有效地实现皮肤病变的分类和分割。该模型在ISIC-2017和PH2数据集上通过5折交叉验证，展示了与现有最先进的模型相比，具有多个指标上的优越性能，标志着在分割和分类精度上的显著改进。", "conclusion": "该集成设置在该领域的新基准，并强调了多任务医疗图像分析方法的进一步研究潜力，预示着自动化诊断系统的改进。"}
{"llm_update_time": "20250723", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2502.19848", "html_url": "https://arxiv.org/abs/2502.19848", "title": "One-for-More: Continual Diffusion Model for Anomaly Detection", "title_en": "One-for-More: Continual Diffusion Model for Anomaly Detection", "authors": "Xiaofan Li,Xin Tan,Zhuo Chen,Zhizhong Zhang,Ruixin Zhang,Rizen Guo,Guannan Jiang,Yulong Chen,Yanyun Qu,Lizhuang Ma,Yuan Xie", "background": "生成模型的兴起带动了统一所有任务到生成框架中的兴趣。异常检测方法也包括在这一框架内，使用扩散模型在给定任意异常图像时生成或重构正常样本。然而，研究发现扩散模型易遭受严重的`忠实性幻觉`和`灾难性遗忘`，无法适应不可预测的模式变化。", "innovation": "提出了连续扩散模型，通过梯度投影实现稳定连续学习。梯度投影通过对模型更新的应用进行正则化，通过改变梯度使其朝向保护已学知识的方向。同时，为了减少马尔可夫过程带来的巨大内存成本，还提出了一种基于线性表示的传递性质的迭代奇异值分解方法，这种方法消耗少量内存并几乎不损失性能。此外，为防止扩散模型过度拟合正常图像，还提出了异常蒙版网络来增强扩散模型的条件机制。在17/18设置中，对于持续异常检测，该方法在MVTec和VisA上取得了最佳成绩。", "conclusion": "该研究在MVTec和VisA数据集的17/18设置中实现了对持续异常检测的第一名成绩，并提供了代码。"}
{"llm_update_time": "20250723", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2503.00196", "html_url": "https://arxiv.org/abs/2503.00196", "title": "PRISM：使用语言引导的稳定扩散生成高分辨率和精确的医疗图像反事实", "title_en": "PRISM: High-Resolution & Precise Counterfactual Medical Image Generation using Language-guided Stable Diffusion", "authors": "Amar Kumar,Anita Kriz,Mohammad Havaei,Tal Arbel", "background": "在医疗成像领域开发可靠和可泛化的人工智能系统面临显著障碍，包括伪相关、数据不平衡和注释不足等问题。这些挑战需要能够应对医疗成像数据独特复杂性的架构。自然图像领域中视觉-语言基础模型的快速发展促使人们思考如何将其适应于医疗成像任务。背景介绍了这些挑战以及基础模型在医疗成像中的潜在应用。", "innovation": "本文提出了一种名为PRISM的框架，利用基础模型生成高分辨率、语言引导的医学影像反事实图像，使用Stable Diffusion。该方法创新性地解决了伪相关和疾病特征的精确修改问题，能够在保留其他图像特性的同时，选择性地修改和添加特定属性。创新点在于引入了Stable Diffusion技术实现精细化的图像反事实生成，并展示了其在鲁棒分类器开发中的应用潜力。", "conclusion": "通过广泛的评估，证明PRISM在反事实生成方面实现了重大进展，并能为临床部署提供更稳健的下游分类器。为了促进更广泛的应用和研究，代码已公开发布。"}
{"llm_update_time": "20250723", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2410.13613", "html_url": "https://arxiv.org/abs/2410.13613", "title": "MEGA: 高效的4D高斯散列技术用于动态场景", "title_en": "MEGA: Memory-Efficient 4D Gaussian Splatting for Dynamic Scenes", "authors": "Xinjie Zhang,Zhening Liu,Yifan Zhang,Xingtong Ge,Dailan He,Tongda Xu,Yan Wang,Zehong Lin,Shuicheng Yan,Jun Zhang", "background": "4D高斯散列（4DGS）技术最近被证明是捕捉复杂动态3D场景的有效方法。它利用4D高斯表示和GPU友好的渲染器，实现快速渲染。然而，4DGS的技术需求很大，因为需要成千上万的4D高斯点，每个点还带有大量的相关属性，这导致了巨大的内存和存储成本。", "innovation": "本文提出了一种新的、节省内存的4DGS框架。通过将颜色属性分解为每个高斯的独特直接颜色成分和一个共享的轻量级交替电流颜色预测器，消除了经典4DGS中常用的高达144个参数的球面谐波系数。此外，引入了一种基于熵的高斯变形技术，使用变形场扩展每个高斯的作用范围，结合基于透明度的熵损失来限制高斯的数量，以最小化所需的高斯数量来适应动态场景。通过半精度存储和压缩，框架在Technicolor和Neural 3D Video数据集上的存储量分别减少了约190倍和125倍，同时保持了与原4DGS相当的渲染速度和场景表现质量。", "conclusion": "该框架不仅显著减少了存储需求，还保持了与原4DGS相当的渲染速度和场景表现质量，是该领域的全新标准。完整的代码可以在此获取：这个 https URL。"}
{"llm_update_time": "20250723", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.16704", "html_url": "https://arxiv.org/abs/2507.16704", "title": "Screen2AX：基于视觉的方法用于自动生成macOS可访问性", "title_en": "Screen2AX: Vision-Based Approach for Automatic macOS Accessibility Generation", "authors": "Viktor Muryn,Marta Sumyk,Mariya Hirna,Sofiya Garkot,Maksym Shamrai", "background": "桌面可访问性元数据使AI代理能够解释屏幕，支持依赖屏幕阅读器等工具的用户。然而，由于开发者提供的元数据不完整或缺失，许多应用程序仍然高度不可访问。我们发现，只有33%的macOS应用程序提供了全面的可访问性支持。虽然最近针对结构化屏幕表示的工作主要解决了特定挑战，如UI元素检测或配音，但没有工作试图通过复制整个层次结构来捕捉桌面界面的完整复杂性。", "innovation": "我们介绍了Screen2AX，这是第一个框架，能够自动从单张快照中创建实时、树型结构的可访问性元数据。我们的方法使用视觉语言和物体检测模型来检测、描述和组织UI元素的层次结构，从而模仿macOS的系统级可访问性结构。为了解决macOS桌面应用程序数据有限的问题，我们编译并公开发布了三个数据集，共包含112个macOS应用程序，每个应用程序均标注了UI元素检测、分组和层次可访问性元数据，以及相应的屏幕截图。", "conclusion": "Screen2AX能够准确推断出层级树，重建完整可访问性树的F1得分为77%。这种层次树提高了自主代理解释和与复杂桌面界面交互的能力。我们引入了Screen2AX-Task基准测试，专门用于评估macOS桌面上的自主代理任务执行。使用这一基准测试，我们展示了Screen2AX在任务执行速度上比原生可访问性表示快2.2倍，并且在ScreenSpot基准测试上超过了领先的一流系统OmniParser V2。"}
{"llm_update_time": "20250723", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2503.02581", "html_url": "https://arxiv.org/abs/2503.02581", "title": "使用语言指导揭露分割一切模型2在RGB-热语义分割中的潜力", "title_en": "Unveiling the Potential of Segment Anything Model 2 for RGB-Thermal Semantic Segmentation with Language Guidance", "authors": "Jiayi Zhao,Fei Teng,Kai Luo,Guoqiang Zhao,Zhiyong Li,Xu Zheng,Kailun Yang", "background": "机器人的感知能力依赖于数据集的丰富性。尽管Segment Anything Model 2 (SAM2)在大量数据集上进行训练，展示了在感知任务中强大的感知潜力，但其固有的训练方式使其不适合RGB-T任务。为了应对这些挑战，本研究提出了SHIFNet，一种新的SAM2驱动的混合交互模式，通过语言指导解锁SAM2的潜力，实现高效的RGB-热感知。", "innovation": "SHIFNet通过引入两个关键组件来创新性地解决上述问题：（1）语义感知跨模态融合（SACF）模块，通过文本引导的亲和学习动态平衡模态贡献，克服SAM2的固有RGB偏见；（2）异构提示解码器（HPD），通过语义增强模块增强全局语义信息，并结合类别嵌入以放大跨模态语义一致性。SHIFNet使用32.27M参数，在公开基准测试中实现了最先进的分割性能，分别在PST900和FMB上达到了89.8%和67.8%。", "conclusion": "本框架能够使预训练的大模型适应RGB-热分割任务，有效缓解了数据收集的高成本，同时为机器人系统赋予了全面的感知能力。源代码将在此网址公开：this https URL."}
{"llm_update_time": "20250723", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2503.05182", "html_url": "https://arxiv.org/abs/2503.05182", "title": "MGSR: 2D/3D Mutual-boosted Gaussian Splatting for High-fidelity Surface Reconstruction under Various Light Conditions", "title_en": "MGSR: 2D/3D Mutual-boosted Gaussian Splatting for High-fidelity Surface Reconstruction under Various Light Conditions", "authors": "Qingyuan Zhou,Yuehu Gong,Weidong Yang,Jiaze Li,Yeqi Luo,Baixin Xu,Shuhao Li,Ben Fei,Ying He", "background": "3D Gaussian Splatting (3D-GS)任务中的视图合成（NVS）和表面重建（SR）是关键任务。尽管最近有进展，这两项任务通常独立进行，基于GS的渲染方法在不同光照条件下难以产生准确的表面，而基于GS的重建方法常常会牺牲渲染质量。这引发了一个核心问题：渲染和重建是否必须妥协？", "innovation": "提出了MGSR，一种2D/3D互增的高精度表面重建方法，通过两个分支——基于2D-GS和3D-GS的分支——交替优化和互增监督，增强渲染质量和3D重建精度。该方法利用表面重建中的几何信息来指导光照分解模块，实现在不同光照条件下的真实渲染，并用传输分量对表面重建进行监督，提高表面建模的精度。", "conclusion": "MGSR在不同光照条件下的物体和场景级数据集上进行了评估，展示了渲染和表面重建的较强性能。代码已公开。"}
{"llm_update_time": "20250723", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2501.05710", "html_url": "https://arxiv.org/abs/2501.05710", "title": "EmotiCrafter: 基于阀值-唤醒模型的文本到情感图像生成", "title_en": "EmotiCrafter: Text-to-Emotional-Image Generation based on Valence-Arousal Model", "authors": "Shengqi Dang,Yi He,Long Ling,Ziqing Qian,Nanxuan Zhao,Nan Cao", "background": "最近的研究表明，情绪能够增强用户的认知并影响信息传播。尽管视觉情绪分析研究广泛，但帮助用户生成富有情感的图像内容的工作相对较少。现有的情感图像生成方法主要依赖于离散的情绪类别，这使得准确捕捉复杂和微妙的情绪差异变得困难。此外，这些方法难以基于文本提示来控制生成图像的具体内容。", "innovation": "本研究提出了新的连续情感图像内容生成（C-EICG）任务，并开发了EmotiCrafter情感生成模型，该模型能够基于文本提示和阀值-唤醒值生成图像。此外，本文提出了一种新颖的情感嵌入映射网络，将阀值-唤醒值嵌入到文本特征中，从而能够与预期的输入提示保持情绪的一致性。另外，还引入了一个增强情绪表达的损失函数。", "conclusion": "实验结果表明，我们的方法能够有效地生成具有特定情感和所需内容的图像，并且在现有技术中表现更优。"}
{"llm_update_time": "20250723", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2503.06132", "html_url": "https://arxiv.org/abs/2503.06132", "title": "USP：图像生成与理解的统一自监督预训练", "title_en": "USP: Unified Self-Supervised Pretraining for Image Generation and Understanding", "authors": "Xiangxiang Chu,Renda Li,Yong Wang", "background": "近年来，研究证明了扩散模型（diffusion models）和表示学习（representation learning）之间的相互作用。扩散模型的中间表示可以用于视觉任务，而自监督视觉模型可以增强扩散模型的收敛速度和生成质量。然而，将自监督视觉模型的预训练权重传输到扩散模型中面临着输入不匹配和使用潜在空间的挑战。", "innovation": "为了应对这些挑战，我们提出了一种统一自监督预训练（Unified Self-supervised Pretraining, USP）框架。该框架利用变异自动编码器（VAE）潜在空间中的部分遮盖潜在建模来初始化扩散模型。USP能够在保持理解任务性能的前提下，显著提高扩散模型的收敛速度和生成质量。", "conclusion": "USP框架通过在VAE潜在空间中进行部分遮盖潜在建模来统一预训练 self-supervised 视觉模型和扩散模型，从而解决了输入不匹配和使用潜在空间的问题。该方法在理解任务上具有竞争力，同时显著提升了扩散模型的收敛速度和生成质量。我们将在该地址提供代码：[this https URL](this https URL)。"}
{"llm_update_time": "20250723", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2501.08005", "html_url": "https://arxiv.org/abs/2501.08005", "title": "DisCoPatch: 使用对抗驱动的批量统计数据改进离分布检测", "title_en": "DisCoPatch: Taming Adversarially-driven Batch Statistics for Improved Out-of-Distribution Detection", "authors": "Francisco Caetano,Christiaan Viviers,Luis A. Zavala-Mondragón,Peter H. N. de With,Fons van der Sommen", "background": "离分布（OOD）检测在许多应用中具有重要意义。虽然已经对语义和领域转移OOD问题进行了广泛研究，本工作主要关注协变量偏移——数据分布中的微小变化，这些变化可能会影响机器学习性能。我们认为可以检测这些微小变化来提高我们对类别边界的理解，最终改善OOD检测。", "innovation": "引入了DisCoPatch框架，这是一种未监督的对抗变分自编码器（VAE）框架。在这一机制中，对抗判别器在使用批量标准化（BN）训练时，将真实样本和对抗样本视为不同领域，并利用这种特性进行OOD检测。DisCoPatch利用VAE的次优输出（生成和重构样本）作为负样本来训练判别器，从而提高其区分类别内部样本和协变量偏移的能力。通过紧固边界，DisCoPatch在公共kHz-1000（-C）OOD检测基准上达到了最先进的性能，在ImageNet-1K(-C)上的AUROC达到95.5%。此外，在公共Near-OOD基准测试中，DisCoPatch也优于所有先前的方法。该模型具有25MB的紧凑模型大小，显著降低了检测延迟，是实时OOD检测的高效和实用方案。", "conclusion": "DisCoPatch模型不仅在检测协变量偏移方面表现出色，达到95.5%的AUROC，还在公共Near-OOD基准测试中超越所有先前方法。该模型具有25MB紧凑的模型大小，在保持高OOD检测性能的同时，显著降低了检测延迟，使其成为现实世界OOD检测应用的有效解决方案。"}
{"llm_update_time": "20250723", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2502.02358", "html_url": "https://arxiv.org/abs/2502.02358", "title": "MotionLab: 以Motion-Condition-Motion范式实现统一的人体动作生成与编辑", "title_en": "MotionLab: Unified Human Motion Generation and Editing via the Motion-Condition-Motion Paradigm", "authors": "Ziyan Guo,Zeyu Hu,De Wen Soh,Na Zhao", "background": "当前的人体动作生成和编辑方法倾向于为具体任务提供孤立的解决方案，这在实际应用中效率低下且不太实用。尽管有些努力试图将相关的动作任务统一起来，但这些方法仅通过不同模态作为条件来引导动作生成，缺乏编辑功能和精细控制，也无法在任务之间分享知识。", "innovation": "介绍了新的范式：Motion-Condition-Motion，通过三个概念（源动作、条件和目标动作）实现多种任务的统一表述。提出了一个统一的框架MotionLab，其中包括矫正流来学习源动作到目标动作的映射，受指定条件的指导。在MotionLab中，引入了多个创新元素，如MotionFlow Transformer、对齐旋转位置编码、任务特定指令调制以及动作课程学习，以实现有效的多任务学习和任务间的知识共享。", "conclusion": "MotionLab在多个基准测试中展示了强大的泛化能力和推理效率。开源代码及相关视频结果可访问提供的链接。"}
{"llm_update_time": "20250723", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2503.06898", "html_url": "https://arxiv.org/abs/2503.06898", "title": "照亮黑暗：学习在野外增强低光图像", "title_en": "Illuminating Darkness: Learning to Enhance Low-light Images In-the-Wild", "authors": "S M A Sharif,Abdur Rehman,Zain Ul Abidin,Fayaz Ali Dharejo,Radu Timofte,Rizwan Ali Naqvi", "background": "单次成像低光成像依然具有挑战性，原因是缺乏多样且实用的配对数据集。为解决这一问题，我们引入了一个大规模的4K+分辨率的低光智能手机数据集LSD，该数据集涵盖了广泛的光照条件（0.1至200 lux）。LSD数据集包含了6,425对精确对齐的低光和正常光图像，从8,000多个室内和室外场景中选择，通过多帧采集和专家评估筛选而来。为了评估模型的普遍性和美学质量，我们收集了2,117张来自未见设备的未配对低光图像。", "innovation": "为充分利用LSD数据集，我们提出了TFFormer，这是一种混合模型，将亮度和色度（LC）分别编码，以减少色度和结构的缠结。此外，我们提出了一个基于交叉注意力的联合解码器，用于上下文意识的LC表示融合，并将LC修正和LC指导下的监督结合，以显著提高感知保真度和结构一致性。TFFormer在LSD数据集上实现了最先进的结果（+2.45 dB PSNR），并在下游视觉任务中大大改进，例如低光环境下的目标检测（ExDark数据集上+6.80 mAP）。", "conclusion": "我们提出的TFFormer模型不仅在一般的低光图像增强任务中取得了显著结果，还在多个下游视觉任务中实现了大幅提升。"}
{"llm_update_time": "20250723", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2411.19951", "html_url": "https://arxiv.org/abs/2411.19951", "title": "Sparrow: 从文本图像增强实现数据高效视频LLM", "title_en": "Sparrow: Data-Efficient Video-LLM with Text-to-Image Augmentation", "authors": "Shukang Yin,Chaoyou Fu,Sirui Zhao,Chunjiang Ge,Yan Yang,Yuhan Dai,Yongdong Luo,Tong Xu,Caifeng Shan,Enhong Chen", "background": "近年来，多模态大型语言模型（MLLMs）在视觉理解领域取得了巨大成功。这些模型的成功主要归因于主导的规模法则，即更大参数量和数据量能够提升性能。特别是在数据方面，数据收集主要依赖于自动数据管道，而这种情况下对数据规模效果的研究被长期忽视了。因此，本文重新审视了基于合成数据的规模效应，并以数据为中心，开发视频LLMs。初步实验发现，简单地扩大视频数据样本规模会导致学习效率低下，这主要由于指令多样性不足。为了解决这一问题，本文提出了名为Sparrow的数据增强方法，从纯文本指令生成类似视频的数据样本，并将其与真实视频数据混合，以提高训练效率。", "innovation": "本文的主要创新在于提出了一种数据增强方法Sparrow，从纯文本指令生成类似视频的合成数据样本，并将其与真实视频数据混合训练，从而提高了视频LLM的训练效率和性能。实验结果表明，这种方法不仅在学习效率上有所提升，而且在长视频理解方面也表现出色，甚至优于基于大量长视频数据训练的基线模型。", "conclusion": "本文通过提出Sparrow数据增强方法，实现了无需大量真实视频数据训练也能获得良好性能的视频LLM。实验结果证明，该方法不仅提升了学习效率，还提高了长视频理解的效果，展现了数据增强方法在视觉理解中的潜力。"}
{"llm_update_time": "20250723", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2503.01092", "html_url": "https://arxiv.org/abs/2503.01092", "title": "在第一视角整理场景中可变形物体的一次性可利用性定位", "title_en": "One-Shot Affordance Grounding of Deformable Objects in Egocentric Organizing Scenes", "authors": "Wanjun Jia,Fan Yang,Mengfei Duan,Xianchi Chen,Yinxi Wang,Yiming Jiang,Wenrui Chen,Kailun Yang,Zhiyong Li", "background": "在机器人对手动操作可变形物体进行操纵时，面临着由组成部件属性的不确定性、多种配置、视觉干扰以及模糊的指令所带来的挑战，这些因素使得感知和控制任务变得更加复杂。", "innovation": "提出了一个新颖的一次性可变形物体语义增强模块 (DefoSEM) 和 ORB-增强关键点融合模块 (OEKFM)，通过这些模块增强对内部结构的理解和提取关键部件特征的能力，同时减少由指令词引起的区域模糊问题。", "conclusion": "通过构建一个包含15种常见可变形物体及其相关组织动作的多样现实世界数据集 AGDDO15，实验结果表明，相较于最先进的方法，该方法在KLD、SIM和NSS指标上分别提高了6.2%、3.2%和2.9%，并且表现出高度的泛化能力，相关的代码和基准数据集已经公开发布。"}
{"llm_update_time": "20250723", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2503.10624", "html_url": "https://arxiv.org/abs/2503.10624", "title": "ETCH: 通过不变紧致度进行穿衣人类的体部拟合", "title_en": "ETCH: Generalizing Body Fitting to Clothed Humans via Equivariant Tightness", "authors": "Boqian Li,Haiwen Feng,Zeyu Cai,Michael J. Black,Yuliang Xiu", "background": "为穿着衣物的人类点云拟合身体是一个普遍但具有挑战性的任务。传统的基于优化的方法使用多阶段管道，对初始姿态敏感。而最近的基于学习的方法在不同姿态和衣物类型上泛化能力较差。文章介绍了Equivariant Tightness Fitting for Clothed Humans（ETCH），这是一种新型管道，通过局部近似SE(3)不变性估计衣物到身体表面的映射，以及将紧致度编码为从衣物表面到内层身体的位移向量。通过这种方法，姿态不变的身体特征回归稀疏的身体标记，简化了穿衣人类拟合问题为内层身体标记拟合任务。实验结果表明，ETCH在宽松衣物的身体拟合准确性（16.7% ~ 69.5%）和形状准确性（平均49.9%）上显著优于最先进的方法，即使在少量数据的情况下，其方向错误也可以减少67.2% ~ 89.8%。质性结果展示了ETCH的强大通用性，无论面对复杂姿态、未见过的形状、宽松衣物和非刚性动力学都表现出色。", "innovation": "提出了一种新的方法，即不变紧致度穿衣人类体部拟合（Equivalent Tightness Fitting for Clothed Humans，ETCH）。该方法通过局部近似SE(3)不变性直接估计衣物到身体表面的映射，并将紧致度作为从衣物表面到内层身体的位移向量进行编码，从而简化了问题为内层身体标记拟合任务。此方法能够在少量数据下减少方向误差，并且在多种复杂情况下表现出优秀的泛化能力。", "conclusion": "在CAPE和4D-Dress数据集上的实验表明，ETCH在身体拟合准确性（16.7% ~ 69.5%）和形状拟合准确性（平均49.9%）上显著优于其他现有算法。即使在少量数据下，ETF也可以减少方向错误的67.2%到89.8%。此方法在复杂姿态、未见过的形状、宽松衣物和非刚性动力学等场景中表现出良好的泛化能力。所有代码和模型很快将在指定网址 released."}
{"llm_update_time": "20250723", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2503.17262", "html_url": "https://arxiv.org/abs/2503.17262", "title": "基于事件相机的光流和强度的无监督联合学习", "title_en": "Unsupervised Joint Learning of Optical Flow and Intensity with Event Cameras", "authors": "Shuang Guo,Friedhelm Hamann,Guillermo Gallego", "background": "事件相机依赖于运动来获取场景外观信息，这意味着外观和运动是固有相关的，即两者要么同时出现在事件数据中，要么都不出现。以往的研究将光流（运动）和图像强度（外观）的恢复视为独立的任务，这与事件相机的固有特性不匹配，并且忽略了两者之间的内在联系。因此，该研究提出了一种无监督学习框架，利用单一网络同时估计运动（光流）和外观（图像强度）。", "innovation": "研究者基于数据生成模型，推导出了基于光流和图像强度的事件相机光度误差，并将其与对比最大化框架结合，形成综合损失函数，用于同时估计光流和强度。实验结果表明，与无监督方法相比，该方法在光流估计中的端点误差（EPE）降低了20%，绝对误差（AE）降低了25%，同时在高动态范围场景中实现了竞争力的图像强度估计结果。另外，该方法的推理时间比其他光流方法短，并且在某些情况下比图像重建方法输出的单一量更多。", "conclusion": "实验结果验证了此方法的优越性能，特别是在高动态范围场景中，同时相比其他方法提供了更短的推理时间和更好的结果。"}
{"llm_update_time": "20250723", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2503.13684", "html_url": "https://arxiv.org/abs/2503.13684", "title": "FiVE: 一种评估新兴扩散和修正流模型精细粒度视频编辑基准", "title_en": "FiVE: A Fine-grained Video Editing Benchmark for Evaluating Emerging Diffusion and Rectified Flow Models", "authors": "Minghan Li,Chenxi Xie,Yichen Wu,Lei Zhang,Mengyu Wang", "background": "近年来，出现了许多文本到视频（T2V）编辑方法，但由于缺乏标准化基准以进行公平评估，导致了不一致的声明和对模型对超参数敏感性的评估无法进行。精细粒度的视频编辑对于实现精准的对象级修改、同时保留上下文和时间一致性至关重要。因此，现有的T2V编辑方法无法充分评估模型性能及其对超参数的敏感性。为解决这一问题，本文提出了FiVE，这是一种用于评价新兴扩散和修正流模型的精细粒度视频编辑基准。", "innovation": "本文创新性地提出了FiVE，它是一个用于评估扩散和修正流模型的精细粒度视频编辑基准，包括74段真实的视频和26段生成的视频，涵盖了6种精细粒度编辑类型、420个对象级编辑提示对及其相应的掩码。另外，通过引入FlowEdit对最新的修正流（RF）T2V生成模型进行改进，得到无需训练和逆过程的视频编辑模型Pyramid-Edit和Wan-Edit。最后，提出了一个名为FiVE-Acc的新颖指标FiVE-Acc，该指标得益于视觉语言模型（VLMs）来评估精细粒度视频编辑的成功度。实验结果表明，基于修正流的编辑方法显著优于基于扩散的方法，Wan-Edit在综合性能上表现最佳，并且对超参数的敏感性最小。", "conclusion": "本文通过建立FiVE精细粒度视频编辑基准，提供了对T2V编辑模型的客观评估，并通过FlowEdit改进了一部分生成模型，实现了无需训练和逆过程的视频编辑。实验结果表明基于修正流的方法在综合性能上表现更优，而Wan-Edit模型对超参数的敏感性较为低。"}
{"llm_update_time": "20250723", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2503.12545", "html_url": "https://arxiv.org/abs/2503.12545", "title": "PEBench: 用于多模态大语言模型机器遗忘基准测试的虚构数据集", "title_en": "PEBench: A Fictitious Dataset to Benchmark Machine Unlearning for Multimodal Large Language Models", "authors": "Zhaopan Xu,Pengfei Zhou,Weidong Tang,Jiaxin Ai,Wangbo Zhao,Kai Wang,Xiaojiang Peng,Wenqi Shao,Hongxun Yao,Kaipeng Zhang", "background": "多模态大规模语言模型（MLLMs）在视觉语言任务中取得了显著的成功，但它们依赖来自网络的大规模数据引发了重要的隐私和安全问题。机器遗忘（MU）作为一种关键技术，可以解决这些问题，使用户能够选择性地从预训练模型中删除特定信息，而无需重新训练。然而，现有对MLLMs的MU评估仍然不够充分。现有的基准测试通常局限于实体方面的评估，忽视了更广泛的视觉概念及其内在语义耦合的遗忘。为了弥补这一不足，我们提出了PEBench这一新型基准测试，旨在进行对MLLMs的MU评估。PEBench使用虚构的个人实体及其事件场景数据集，评估不同概念间的遗忘情况。我们利用PEBench评估了五种MU方法，揭示了各自的优势和劣势。我们的研究表明，遗忘一个概念可能会无意中影响同一幅图像中相关概念的性能，这被称为跨概念干扰。此外，我们表明同时遗忘人物和事件概念的难度很大，并提出了有效的缓解方法。", "innovation": "我们提出了PEBench，一种新型的基准测试，专为MLLMs的MU评估设计。PEBench利用虚构的个人实体及其事件场景数据集，评估不同概念间的遗忘情况。通过PEBench，我们评估了五种MU方法，揭示了各自的优势和劣势。本研究发现了跨概念干扰问题，并提出了解决同时遗忘人物和事件概念之间的竞争策略。'", "conclusion": "通过对五种MU方法的评估，我们发现遗忘一个概念可能会无意中影响同一幅图像中相关概念的性能。此外，我们展示了同时遗忘人物和事件概念的困难性，并提出了解决方法。我们的源代码和benchmark已经公开。"}
{"llm_update_time": "20250723", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2504.20041", "html_url": "https://arxiv.org/abs/2504.20041", "title": "通过多任务训练学习流式视频表示", "title_en": "Learning Streaming Video Representation via Multitask Training", "authors": "Yibin Yan,Jilan Xu,Shangzhe Di,Yikun Liu,Yudi Shi,Qirui Chen,Zeqian Li,Yifei Huang,Weidi Xie", "background": "连续视频流的理解在包括拟人式AI和自动驾驶等实时应用中发挥着基础性的作用。与离线视频理解不同，流式视频理解需要分帧处理视频流、保存历史信息并作出低延迟决策。", "innovation": "本文的主要贡献在于开发了一种称为StreamFormer的新颖的流式视频骨干，通过将因果时序注意力引入预训练的视觉变换器实现高效且能保持图像表示能力的流式视频处理。此外，提出了一种统一多任务视觉语言对齐框架进行StreamFormer的训练，使其能同时学习全局语义、时空动态和精细的空间关系。通过在流式视频动作检测、流式视频实例分割及视频问答等多项实验中进行广泛的测试，证明StreamFormer具有适用于实时应用的高效能和竞争力的结果。", "conclusion": "StreamFormer在保持效率的同时取得了竞争力的结果，显示出其在实时应用中的潜力。"}
{"llm_update_time": "20250723", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2412.16881", "html_url": "https://arxiv.org/abs/2412.16881", "title": "在图像失真下预测图像分类器的可靠性", "title_en": "Predicting the Reliability of an Image Classifier under Image Distortion", "authors": "Dang Nguyen,Sunil Gupta,Kien Do,Svetha Venkatesh", "background": "在图像分类任务中，深度学习模型对于图像失真的敏感性很大，即如果输入的图像被失真，其准确度会显著下降。衡量一个图像分类器是否“可靠”的标准是在失真图像上的准确度要高于用户规定的阈值。为了进行质量控制，需要预测某图像分类器在特定失真水平下是否可靠。这是一个挑战性的问题，因为现有训练集极度不平衡。", "innovation": "提出了基于高斯过程的方法来重新平衡训练集，从而构建一个可以对未见过的失真水平进行分类的机器学习预测模型（称为失真分类器）。实验表明，这种方法在六个流行的图像数据集上明显优于几个基线方法。", "conclusion": "研究提出了一个新的方法来解决图像分类器在高失真水平下可靠性预测的问题，通过平衡训练集数据，训练出更有效的失真分类器，并在多个图像数据集上进行了验证，显著提高了预测准确性。"}
{"llm_update_time": "20250723", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2503.07601", "html_url": "https://arxiv.org/abs/2503.07601", "title": "Style Matching Score for Balanced Image Stylization", "title_en": "Balanced Image Stylization with Style Matching Score", "authors": "Yuxin Jiang,Liming Jiang,Shuai Yang,Jia-Wei Liu,Ivor Tsang,Mike Zheng Shou", "background": "图像風格化中的風格轉移與內容保留是一項長期挑戰。現有方法往往無法很好的平衡風格對齊與內容保留，因此需要新的方法來解決這一問題。", "innovation": "本研究提出了Style Matching Score (SMS)，这是一种通过扩散模型进行图像風格化的新颖优化方法。SMS将图像風格化重新定义为風格分布匹配问题，并提出了逐级频域正则化方法和语义感知梯度精炼技术，以适应地保留内容信息和精炼风格。", "conclusion": "SMS方法通过优化公式将風格化扩展到参数空间，使得轻量级前馈生成器能够进行快速的一步風格化。实验结果表明，SMS在风格对齐和内容保留方面比最先进的方法表现更好。"}
{"llm_update_time": "20250723", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2506.10516", "html_url": "https://arxiv.org/abs/2506.10516", "title": "CogStream:基于上下文的流媒体视频问答", "title_en": "CogStream: Context-guided Streaming Video Question Answering", "authors": "Zicheng Zhao,Kangyu Wang,Shijie Li,Rui Qian,Weiyao Lin,Huabin Liu", "background": "尽管视频大型语言模型（Vid-LLMs）在多模态理解方面取得了进展，但在流媒体视频推理方面仍然存在挑战，因为这依赖于上下文信息。现有的范式将所有可用的历史上下文信息输入Vid-LLMs，导致视觉数据处理的计算负担显著增加。此外，不必要的上下文信息会分散模型对关键细节的注意力。为此，本文提出了一个名为Context-guided Streaming Video Reasoning (CogStream) 的挑战任务，该任务模拟了真实的流媒体视频场景，要求模型识别相关的历史上下文信息，以推断当前流的问题答案。传统的范式直接将所有历史上下文信息输入模型，导致模型在处理视觉数据时面临巨大的计算挑战，且可能会受到无关上下文信息的干扰。", "innovation": "为了应对这些挑战，本文提出了一个密集标注的数据集，数据集中包含了多层级的问题-答案对，并采用半自动管道生成。此外，作者还提出了一种称为CogReasoner的基线模型，该模型通过利用视觉流压缩技术和历史对话检索来高效解决这一问题。实验结果证明了该方法的有效性，并且该研究已经发布在上述链接。", "conclusion": "本文通过引入CogStream任务和CogReasoner模型，提高了流媒体视频推理中的上下文引导能力，并通过实验验证了该方法的有效性。"}
{"llm_update_time": "20250723", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2505.08013", "html_url": "https://arxiv.org/abs/2505.08013", "title": "RDD: 使用可变形转换器的稳健特征检测与描述器", "title_en": "RDD: Robust Feature Detector and Descriptor using Deformable Transformer", "authors": "Gonglin Chen,Tianwen Fu,Haiwei Chen,Wenbin Teng,Hanyuan Xiao,Yajie Zhao", "background": "在结构从运动和SLAM的核心步骤中，即使在显著视角变化等具有挑战性的场景下，鲁棒特征检测和描述仍然是未解决的问题，尽管它们非常普遍。尽管最近的工作已经认识到局部特征在建模几何转换的重要性，但这些方法未能学习远程关系中存在的视觉线索。", "innovation": "我们提出了Robust Deformable Detector (RDD)，这是一种新颖的、利用可变形变换器的关键点检测/描述符方法，通过可变形自身注意力机制捕捉全局上下文和几何不变性。RDD通过可变形注意力机制聚焦于关键位置，有效减少了搜索空间复杂度并建模了几何不变性。此外，我们还收集了一个空中到地面数据集用于训练，除了标准MegaDepth数据集。", "conclusion": "我们提出的RDD方法在稀疏匹配任务中优于所有现有的关键点检测/描述符方法，也能够执行半密集匹配。为了全面评估，我们引入了两个具有挑战性的基准：一个强调大视角和尺度变化，另一个是空地基准，这已成为多高度三维重建评估中受欢迎的场景。"}
{"llm_update_time": "20250723", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2506.21980", "html_url": "https://arxiv.org/abs/2506.21980", "title": "R1-Track：通过强化学习直接将MLLMs应用于视觉物体跟踪", "title_en": "R1-Track: Direct Application of MLLMs to Visual Object Tracking via Reinforcement Learning", "authors": "Biao Wang,Wenwen Li,Jiawei Ge", "background": "视觉单目标跟踪的任务是在给定目标初始状态的情况下，连续定位并在后续视频帧中估计目标的尺度。传统上，这一任务被称为模板匹配问题，并经历了从相关滤波器、双流网络到单流网络的发展阶段。尽管这些方法取得了显著进展，但它们通常需要显式的分类和回归建模，依赖于大规模数据集的监督训练，并且局限于单一的跟踪任务，缺乏灵活性。近年来，多模态大语言模型（MLLMs）迅速发展。开源模型如Qwen2.5-VL在接地任务中表现出色，这激发了直接将这些模型应用于视觉跟踪的兴趣。然而，实验发现Qwen2.5-VL在处理图像对之间的模板匹配（即跟踪任务）时存在困难。", "innovation": "我们借鉴了deepseek-R1的方法，通过组相对策略优化（GRPO）强化学习方法对Qwen2.5-VL进行了微调，使用基于规则的奖励函数在一个小型数据集上训练。由此产生的模型R1-Track在GOT-10k基准测试中表现优异。R1-Track支持通过边界框或文本描述实现灵活初始化，同时保留了原始模型的大部分通用能力。进一步讨论了R1-Track的潜在改进方向。", "conclusion": "这项技术报告总结了截至2025年5月的研究发现。"}
{"llm_update_time": "20250723", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2506.21401", "html_url": "https://arxiv.org/abs/2506.21401", "title": "3D参数曲线感知高斯分布重建方法", "title_en": "Curve-Aware Gaussian Splatting for 3D Parametric Curve Reconstruction", "authors": "Zhirui Gao,Renjiao Yi,Yaqiao Dai,Xuening Zhu,Wei Chen,Chenyang Zhu,Kai Xu", "background": "现有的三维参数曲线重建方法通常采用两阶段流程，即先从多视角边缘图重建点云，再进行曲线拟合。这种方法会导致累计误差。研究表明，多视角优化中的渲染过程不适用于直接处理参数曲线，因此需要一种既能保持几何特性又能进行可微渲染的补充表示方法。本文的研究背景在于如何改进参数曲线从多视角边缘图直接重建的方法，以减少误差并提高渲染效率与质量。", "innovation": "本文提出了一种端到端框架，直接从多视角边缘图重建三维参数曲线，通过结合参数曲线和边缘导向的高斯成分，提出了一种参数曲线意识的高斯表示法（CurveGaussian），实现了可微渲染，使参数曲线优化能够直接利用多视角证据。此外，提出了一种动态自适应拓扑优化框架，在训练过程中通过线性化、合并、分割和修剪操作对曲线结构进行精细调整，从而提高了重建的精度和鲁棒性。特别地，直接优化参数曲线减少了训练过程中的参数量，提高了训练效率和性能，优于现有方法。", "conclusion": "通过在ABC数据集和实际基准上的综合评估，本文提出的一阶段方法在生成更清洁、更稳健的重建方面优于两阶段替代方法。此外，通过直接优化参数曲线，本文方法在训练过程中显著减少了参数数量，实现了更高的效率和卓越的表现。"}
{"llm_update_time": "20250723", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2506.23468", "html_url": "https://arxiv.org/abs/2506.23468", "title": "NavMorph: 一种自我进化的连续环境视觉-语言导航世界模型", "title_en": "NavMorph: A Self-Evolving World Model for Vision-and-Language Navigation in Continuous Environments", "authors": "Xuan Yao,Junyu Gao,Changsheng Xu", "background": "Vision-and-Language Navigation in Continuous Environments (VLN-CE) 要求代理根据自然语言指令执行序列导航动作，在复杂的环境中导航。现有方法在面对新的环境和导航过程中不断变化的情况时经常难以泛化和适应。", "innovation": "NavMorph 提出了一种自进化的世界模型框架，通过紧凑的潜空间表示来建模环境动态，增强环境理解并改善决策能力。NavMorph 还融合了一个新颖的上下文进化记忆，利用场景相关信息来支持有效的导航，同时保持在线可适应性。", "conclusion": "通过广泛的实验，我们的方法在流行的 VLN-CE 表尺上实现了显著的性能改进。相关代码可在指定链接中获取。"}
{"llm_update_time": "20250723", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2506.22890", "html_url": "https://arxiv.org/abs/2506.22890", "title": "CP-uniGuard: 多智能体感知系统中恶意智能体检测与防御的统一、概率无关且自适应框架", "title_en": "CP-uniGuard: A Unified, Probability-Agnostic, and Adaptive Framework for Malicious Agent Detection and Defense in Multi-Agent Embodied Perception Systems", "authors": "Senkang Hu,Yihang Tao,Guowen Xu,Xinyuan Qian,Yiqin Deng,Xianhao Chen,Sam Tak Wu Kwong,Yuguang Fang", "background": "协作感知(CP)已经被证明是一种很有前景的技术，适用于多智能体自主驾驶和多智能体机器人系统，通过多个智能体共享感知信息来增强整体感知性能并扩展感知范围。然而，在CP中，某个智能体需要接收其合作智能体的消息，这使其容易受到恶意智能体的攻击。针对这一关键问题，本文提出了一种统一体制、概率无关且自适应的框架，名称为CP-uniGuard，这是一个为每个智能体部署的定制化防御机制，旨在准确地检测并消除合作网络中的恶意智能体。", "innovation": "本文的关键思想是使CP达成共识而非针对某个智能体感知结果产生冲突。为了实现这一思想，作者首先开发了一种概率无关样本共识(PASAC)方法，以有效抽样合作智能体的子集，并在无需恶意智能体先验概率的情况下验证共识。此外，还定义了协作一致性损失(CCLoss)，用于对象检测任务和鸟瞰图(BEV)分割任务，以捕捉智能体与其合作智能体之间的差异，将其作为共识验证的标准。另外，提出了基于双滑动窗口的在线自适应阈值策略，以动态调整共识验证阈值，确保系统在动态环境中的可靠性。最后，通过广泛的实验，展示了该框架的有效性。", "conclusion": "本文通过提出CP-uniGuard框架，在多智能体协作感知系统中实现了对恶意智能体的检测与防御，该框架具备统一体制、概率无关且自适应的特点，并在多个任务中通过实验验证了其有效性。"}
{"llm_update_time": "20250723", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.01756", "html_url": "https://arxiv.org/abs/2507.01756", "title": "重新思考离散标记：将它们视为连续自回归图像合成的条件", "title_en": "Rethinking Discrete Tokens: Treating Them as Conditions for Continuous Autoregressive Image Synthesis", "authors": "Peng Zheng,Junke Wang,Yi Chang,Yizhou Yu,Rui Ma,Zuxuan Wu", "background": "近年来，大规模语言模型（LLMs）的进展激发了将图像编码为离散标记，并利用自回归（AR）框架进行视觉生成的兴趣。然而，在AR模型中，图像生成过程中的量化过程不可避免地导致信息丢失，影响图像保真度。为解决这一问题，最新研究探索了自回归预测连续标记的方法。不同于局限于结构化、有限空间的离散标记，连续表示存在于无界、高维空间中，这使得概率密度估计更加困难，并增加了生成离分布样本的风险。因此，基于这些发现，本研究引入了DisCon（离散条件下的连续自回归模型），提出了一种框架，将离散标记重新解释为条件信号而不是生成目标。通过在给定离散标记的条件下建模连续表示的概率，DisCon在优化连续标记建模的挑战方面取得了突破，同时避免了量化带来的信息损失。", "innovation": "DisCon（离散条件下的连续自回归模型）提出了一种新的框架，将离散标记重新解释为条件信号，而非生成目标。通过建模在给定离散标记条件下的连续表示概率，DisCon在避免优化连续标记建模的挑战方面取得了突破，同时避免了量化导致的信息损失。这一方法在ImageNet 256×256生成任务中取得了gFID分数1.38的成绩，显著优于现有的自回归方法。", "conclusion": "DisCon模型在应对图像生成过程中信息损失的问题上提出了创新的解决方法，不仅在优化方面取得了突破，而且在ImageNet 256×256生成任务中表现优异，实现了gFID分数1.38，显著优于现有自回归方法。"}
{"llm_update_time": "20250723", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.04123", "html_url": "https://arxiv.org/abs/2507.04123", "title": "边缘计算中的混合专家计算系统，实现自主驾驶中的准确高效3D对象检测", "title_en": "Towards Accurate and Efficient 3D Object Detection for Autonomous Driving: A Mixture of Experts Computing System on Edge", "authors": "Linshen Liu,Boyan Su,Junyue Jiang,Guanlin Wu,Cong Guo,Ceyu Xu,Hao Frank Yang", "background": "自主驾驶车辆需要低延迟和高准确性的3D对象检测系统，传统方法难以同时满足这两项需求。为此，研究提出了一种名为Edge-based Mixture of Experts Collaborative Computing（EMC2）的计算系统，以适应边缘平台，并能同时实现低延迟和高准确性的3D对象检测，通过有效融合LiDAR和摄像头数据，生成强大的多模态表示，同时结合硬件和软件优化以保证资源受限的边缘设备上的高效实时推断能力。", "innovation": "EMC2系统通过采用场景感知的混合专家架构，适应边缘平台；引入适应性的多模态数据桥进行多尺度传感器输入预处理，并结合基于目标可见性和距离的场景感知路由机制动态地分配特征到专门的专家模型。此外，结合硬件和软件优化策略，确保在资源受限的边缘设备上实现高效的实时推理。实验结果表明，EMC2在准确性和效率上均优于15种基线方法。", "conclusion": "EMC2系统能够准确高效地实现3D对象检测任务，应用于自主驾驶车辆中，显著提高了可靠性和实时性，验证了其在资源受限边缘设备上的有效性，为自主驾驶的普及应用提供了坚实的技术支持。"}
{"llm_update_time": "20250723", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2503.06312", "html_url": "https://arxiv.org/abs/2503.06312", "title": "DOFA-CLIP: 多模态视觉语言基础模型用于地球观测", "title_en": "DOFA-CLIP: Multimodal Vision-Language Foundation Models for Earth Observation", "authors": "Zhitong Xiong,Yi Wang,Weikang Yu,Adam J Stewart,Jie Zhao,Nils Lehmann,Thomas Dujardin,Zhenghang Yuan,Pedram Ghamisi,Xiao Xiang Zhu", "background": "地球观测（EO）涵盖多种方式，包括光学、雷达、多光谱和高光谱数据，每种方式都能捕捉到独特的环境信号。然而，目前基于CLIP的视觉语言模型在地球观测中依然局限于单一模态的数据，限制了其在各种任务中的通用性和可扩展性。", "innovation": "1. 构建了一个名为GeoLangBind-2M的大型EO图像-文本数据集，涵盖了六种不同的模态并包含丰富的自然语言描述。\n2. 引入了一种新的预训练策略VECT（Vision-models Enhanced Contrastive Text-image pretraining），通过多个视觉基础模型增强CLIP特征的空间感知能力。\n3. 设计了一个模态感知知识聚集模块（MaKA），增强了特征蒸馏的模态特定意识。", "conclusion": "DOFA-CLIP实现了在多种EO基准测试中零样本表现的最新水平，包括未见过的模态和不同数量的输入光谱带数。这些贡献为跨模态的EO理解提供了可扩展的基础，并开启了将异构EO数据与大规模语言模型整合的新途径。代码和数据集将公开发布。"}
{"llm_update_time": "20250723", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.04107", "html_url": "https://arxiv.org/abs/2507.04107", "title": "VICI: VLM-Instructed Cross-view Image-localisation", "title_en": "VICI: VLM-Instructed Cross-view Image-localisation", "authors": "Xiaohan Zhang,Tavis Shore,Chen Chen,Oscar Mendez,Simon Hadfield,Safwan Wshah", "background": "本文档描述了在UAVM 2025挑战中的解决方案，该挑战旨在匹配具有窄视场的街景图像和相应的卫星图像。随着全景视角地理定位接近最优性能，对于实际应用中的限制条件下的性能探索变得越来越重要。真实场景中的街景查询通常是受限视场且未知相机参数，这使得现有架构面临的挑战更为复杂。研究团队提出了两阶段方法，首先检索候选卫星图像嵌入，然后在这些候选中进行重新排名以提升检索准确性，这有助于在显著视角及尺度变化的情况下实现更精确的匹配。实验结果显示该方法在R@1和R@10检索率上达到了顶级性能。", "innovation": "本文档的创新之处在于提出了VICI方法，一种基于VLM（Vision-Language Model）的跨视图图像本地化方法。该方法包括两阶段流程：首先检索候选卫星图像嵌入，随后在这些候选中进行重新排名以提升检索准确性。这种方法能够更好地适应街景图像的有限视野和未知相机参数，从而在面对视角和尺度变化时展现出更强的匹配精度。这是对现有架构的有效扩展，尤其是在限制条件下性能评估方面。", "conclusion": "本文案通过实验展示了所提出的VICI方法在有限视场图像检索任务中的优越性能，特别是在R@1和R@10检索率上达到了顶级的性能水平。这表明优化的检索和重新排名策略能够显著提升实际地理定位性能。代码可以在这里找到：[提供链接]。"}
{"llm_update_time": "20250723", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.05056", "html_url": "https://arxiv.org/abs/2507.05056", "title": "INTER: 通过交互引导采样减少大型视觉-语言模型中的幻觉", "title_en": "INTER: Mitigating Hallucination in Large Vision-Language Models by Interaction Guidance Sampling", "authors": "Xin Dong,Shichao Dong,Jin Wang,Jing Huang,Li Zhou,Zenghui Sun,Lihua Jing,Jingsong Lan,Xiaoyong Zhu,Bo Zheng", "background": "大型视觉-语言模型（LVLMs）中的幻觉对实际应用构成了重大挑战，这些模型可能生成虽然看似合理但实际上与相关视觉内容不一致的响应。尽管人类认知很少出现这种情况，但幻觉的本质主要是由于人类能够有效利用数据样本中的多模态交互信息。人类通常会先收集多模态信息，然后分析跨模态的交互以理解信息，最后再通过语言表达理解。基于此观察，研究者对流行LVLM进行了广泛实验，发现LVLM在多模态样本上表现出类似但较不明显的认知行为。", "innovation": "提出了一种新的训练无监督算法——INTER（交互引导采样），该算法能够在无需额外数据的情况下减少幻觉。INTER明确引导LVLM在生成响应时有效重新应用其对多模态交互信息的理解，从而减少潜在的幻觉。", "conclusion": "INTER算法在六个基准测试任务上，包括VQA和图片配描述任务，相比最先进的解码策略，平均提高了5种LVLM，最多达3.4%。研究结果表明，INTER能够有效减少大型视觉-语言模型中的幻觉，且无需额外的数据训练。"}
{"llm_update_time": "20250723", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.07154", "html_url": "https://arxiv.org/abs/2507.07154", "title": "CL-Polyp: 提升精确肠息肉分割的对比学习增强网络", "title_en": "CL-Polyp: A Contrastive Learning-Enhanced Network for Accurate Polyp Segmentation", "authors": "Desheng Li,Chaoliang Liu,Zhiyong Xiao", "background": "准确地从结肠镜检查图像中分割出肠息肉对于早期诊断和治疗结直肠癌至关重要。大多数现有的深度学习基线的肠息肉分割方法采用编码器-解码器结构，有些还利用了结合辅助任务如分类的多任务框架以提高分割效果。然而，这些方法往往需要更多的标注数据，而且依赖于任务的相似性，这可能限制了它们的泛化能力。随着这些问题的出现，研究者们寻找改善现有方法的方法，以提升模型的性能和泛化能力。", "innovation": "本文提出了一种名为CL-Polyp的对比学习增强肠息肉分割网络。CL-Polyp通过对比学习强化编码器对区分性特征的提取，利用成对的正负样本对对比，而不依赖额外的标注数据。此外，还引入了两个高效的轻量级模块：改进的空洞空间金字塔池化（MASPP）模块以改善多尺度特征融合，以及通道拼接和元素相加（CA）模块以合并低层与上采样特征，从而增强边界重建能力。", "conclusion": "在五个基准数据集（Kvasir-SEG、CVC-ClinicDB、CVC-ColonDB、CVC-300、ETIS）上进行的大量实验验证了CL-Polyp的有效性。具体而言，CL-Polyp在Kvasir-SEG和CVC-ClinicDB数据集上分别提升了IoU度量0.011和0.020，展示了其在临床肠息肉分割中的优越性。"}
{"llm_update_time": "20250723", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.08716", "html_url": "https://arxiv.org/abs/2507.08716", "title": "仅需一个引擎：单一引擎实现 multimodal ISAC 数据仿真", "title_en": "Unreal is all you need: Multimodal ISAC Data Simulation with Only One Engine", "authors": "Kongwu Huang,Shiyi Mu,Jun Jiang,Yuan Gao,Shugong Xu", "background": "已经成功的规模律在大模型和基础模型中得到了应用。为了研究它们在ISAC（Intelligent Sensing and Communication）研究中的潜力，我们提出了Great-X。这是一种单一引擎的多模态数据孪生平台，它可以将Sionna的射线追踪计算重建并在Unreal Engine中实现，同时深度整合于自动驾驶工具中，能够高效地同步模拟多模态数据集，包括信道状态信息(CSI)、RGB、雷达和激光雷达(LiDAR)。", "innovation": "我们构建了基于CSI的开源、大规模、低海拔无人机多模态同感数据集Great-MSD，并提出了一个基准的CSI基无人机3D定位算法，展示了其在不同CSI仿真引擎之间的可行性和泛化能力。相关的代码和数据集将在指定的链接处提供。", "conclusion": "基于我们的单引擎多模态数据孪生平台，我们成功构建了多模态同感数据集Great-MSD和CSI基无人机3D定位算法。该平台及方法证明了在ISAC研究中利用单一引擎进行高效、同步的多模态数据仿真和算法验证的可能性和可行性。"}
{"llm_update_time": "20250723", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2506.22139", "html_url": "https://arxiv.org/abs/2506.22139", "title": "Q-Frame: 按查询选择帧并与视频-LLMs进行多分辨率适应", "title_en": "Q-Frame: Query-aware Frame Selection and Multi-Resolution Adaptation for Video-LLMs", "authors": "Shaojie Zhang,Jiahui Yang,Jianqin Yin,Zhenbo Luo,Jian Luan", "background": "多模态大型语言模型（MLLMs）在视觉理解任务中取得了显著的成功。然而，在将这些模型适应于视频理解任务时，由于数据量大和时间复杂度高存在挑战。现有的使用均匀帧采样的视频-LLMs难以有效捕捉与查询相关的关键的时空线索。", "innovation": "论文提出了Q-Frame，这是一种针对视频内容和查询的新型自适应帧选择和多分辨率缩放方法。Q-Frame 采用了基于文本-图像匹配网络（如CLIP）的训练无感知、即插即用策略，利用Gumbel-Max技巧进行高效的帧选择。Q-Frame 允许视频-LLMs 在不超出计算限制的情况下处理更多的帧，从而保留关键的时空信息。", "conclusion": "通过在基准数据集 MLVU、LongVideoBench 和 Video-MME 上进行广泛的实验，展示了Q-Frame的有效性，证明了其在多种视频理解任务中的优越性及适用性。"}
{"llm_update_time": "20250723", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2506.05328", "html_url": "https://arxiv.org/abs/2506.05328", "title": "AV-Reasoner: 改进和基准测试具备线索导向的视听计数能力的MLLMs", "title_en": "AV-Reasoner: Improving and Benchmarking Clue-Grounded Audio-Visual Counting for MLLMs", "authors": "Lidong Lu,Guo Chen,Zhiqi Li,Yicheng Liu,Tong Lu", "background": "尽管在视频理解方面取得了进展，但当前的MLLMs在计数任务方面仍然存在困难。现有的基准测试受到短视频、封闭查询、缺乏线索注释以及弱多模态覆盖率的限制。", "innovation": "本文引入了CG-AV-Counting，这是一种包含1,027个多模态问题和5,845个注释线索的手动注释线索导向计数基准，覆盖了497个长视频。为了提高模型的计数能力，提出了一种名为AV-Reasoner的模型，该模型利用GRPO和曲线下学习方法从相关任务中推广计数能力。实验表明，在不同的基准测试中，AV-Reasoner取得了最先进的结果，并证明了强化学习的有效性。然而，在跨域基准测试中，语言空间的推理未能带来性能提升。", "conclusion": "该研究提出了一种改进并基准测试了具有线索导向的视听计数能力的MLLMs的方法，并证明了AV-Reasoner在多个基准测试中的优越性及强化学习的有效性。"}
{"llm_update_time": "20250723", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2506.21188", "html_url": "https://arxiv.org/abs/2506.21188", "title": "GroundFlow：一种用于3D点云序列定位的时间推理插件模块", "title_en": "GroundFlow: A Plug-in Module for Temporal Reasoning on 3D Point Cloud Sequential Grounding", "authors": "Zijun Lin,Shuting He,Cheston Tan,Bihan Wen", "background": "当前的3D视觉定位（3DVG）方法将具有多步骤的文本指令视为整体，未能从每个步骤中提取有用的时间信息。然而，在3D点云序列锚定（SG3D）中，指令往往包含诸如“它”、“这里”和“同样的”等代词来使语言表达更简洁。这需要锚定方法理解上下文并从前一步骤中检索相关信息以正确定位对象序列。由于缺乏有效的模块来收集相关历史信息，最先进的3DVG方法很难适应SG3D任务。", "innovation": "为了填补这一空白，我们提出了GroundFlow——3D点云序列定位的时间推理插件模块。首先，我们展示了将GroundFlow结合到3DVG基线方法中可以大幅提高任务准确性（+7.5% 和 +10.2%）在SG3D基准测试中，甚至超过了在多种数据集上预训练的3D大语言模型。此外，我们根据当前指令的相关性有选择地提取短期和长期步骤信息，使得GroundFlow能够全面了解历史信息并维持其在步数增加时的时间理解优势。", "conclusion": "我们的工作将时间推理功能引入现有的3DVG模型，并在SG3D基准测试的五个数据集上实现了最先进的性能。"}
{"llm_update_time": "20250723", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2505.17692", "html_url": "https://arxiv.org/abs/2505.17692", "title": "ViP$^2$-CLIP: Visual-Perception Prompting with Unified Alignment for Zero-Shot Anomaly Detection", "title_en": "ViP$^2$-CLIP: Visual-Perception Prompting with Unified Alignment for Zero-Shot Anomaly Detection", "authors": "Ziteng Yang,Jingzehua Xu,Yanshu Li,Zepeng Li,Yeqiang Wang,Xinghui Li", "background": "零样本异常检测（ZSAD）旨在无需目标领域训练样本的情况下检测异常，依赖于外部辅助数据。现有的基于CLIP的方法试图通过手工设计或静态可学习提示来激活模型的ZSAD潜力。前一种方法工程成本高且语义覆盖范围有限，而后一种方法则在不同类型的异常中应用相同的描述，导致无法适应复杂的变体。此外，由于CLIP最初是在大规模分类任务上预训练的，其异常分割质量高度依赖于类名的具体表述，这严重限制了依赖类标签的提示策略。", "innovation": "ViP$^{2}$-CLIP引入了一种视觉感知提示机制（ViP-Prompt），该机制融合全局和多尺度局部视觉上下文来自适应地生成细粒度的文本提示，消除手动模板和类名先验，使模型能够聚焦于精确异常区域，这对类别标签模糊或受隐私限制的情况特别有价值。广泛实验表明，ViP$^{2}$-CLIP在15个工业和医疗基准上实现了最先进的性能和稳健的跨域泛化。", "conclusion": "ViP$^{2}$-CLIP在零样本异常检测中表现出卓越的性能和强大的跨域泛化能力，特别适合类别标签不明确或隐私受限的情况。"}
{"llm_update_time": "20250723", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.14657", "html_url": "https://arxiv.org/abs/2507.14657", "title": "AI-Enhanced Precision in Sport Taekwondo: Increasing Fairness, Speed, and Trust in Competition (FST.ai),", "title_en": "AI-Enhanced Precision in Sport Taekwondo: Increasing Fairness, Speed, and Trust in Competition (FST.ai)", "authors": "Keivan Shariatmadar,Ahmad Osman", "background": "传统的体育裁判系统，即使支持即时视频回放（IVR），仍然存在延迟、主观性和执法不一致的问题，这影响了比赛的公平性和运动员的信任度。这种背景下，将人工智能（AI）整合到体育赛事裁判中代表着一种范式转变。", "innovation": "该论文介绍了基于‘this http URL’项目的新AI驱动框架——‘this http URL’，它是一款专为跆拳道设计的新型AI辅助判罚系统，特别聚焦于复杂的实时头顶踢腿检测与评分任务。通过计算机视觉、深度学习和边缘推理技术，系统实现了关键动作识别与分类的自动化，大幅减少了决策时间，提高了准确性和透明度。这一框架的通用性体现在它基于姿态估计、动作分类和冲击分析的方法，可以应用于需要动作检测的多样体育项目，如柔道、空手道、击剑以及足球、篮球这类团体运动。", "conclusion": "通过解决跆拳道头踢得分这一最具挑战性的任务，该研究展示了‘this http URL’在多个运动领域的稳健性、适用性和无运动限制性，证明了它有能力推动裁判标准的变革，从而提高公平性、速度和竞赛中的信任度。"}
{"llm_update_time": "20250723", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2311.10118", "html_url": "https://arxiv.org/abs/2311.10118", "title": "基于人工智能的隐圈细胞诊断：现状与未来-一项综述", "title_en": "Now and Future of Artificial Intelligence-based Signet Ring Cell Diagnosis: A Survey", "authors": "Zhu Meng,Junhao Dong,Limei Guo,Fei Su,Jiaxuan Liu,Guangxi Wang,Zhicheng Zhao", "background": "隐圈细胞（SRCs）与高周边转移倾向和预后不良相关，对手术决策和预后预测至关重要。尽管经验丰富的病理学家也能检测SRCs，但过程充满挑战。基于人工智能（AI）的自动化SRC诊断因其潜在的提高诊断效率和准确性而备受关注，现有方法缺乏系统性的评估，导致算法能力与临床应用之间的差距评估不足。本文旨在综述2008年至2025年期间的AI驱动的SRC分析，总结SRC生物学特性及自动化识别的挑战，分析代表性算法并分类为单模态和多模态方法，最后评估当前方法性能与临床辅助需求之间的差距，讨论未解决的挑战和未来研究方向，以帮助研究人员，尤其是非医学背景的研究者理解SRC分析的现状和智能诊断的前景，加速计算算法向临床实践的转化.", "innovation": "本文系统地总结了2008年至2025年期间的AI驱动的SRC分析，涵盖了单模态和多模态算法的详细分析，并将目前的方法与临床辅助需求进行了比较，评估了算法的临床应用场景，明确了研究空白和未来的研发方向。该综述填补了现有AI诊断SRC领域的系统性研究空白，为智能诊断研究提供了重要参考", "conclusion": "本文通过综合分析单模态和多模态SRC分析算法，评估了它们的临床应用性能，并讨论了研究中未解决的问题和未来的研究方向，旨在帮助研究人员理解SRC分析的现状和前景，加速将计算算法应用于临床实践。"}
{"llm_update_time": "20250723", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.10978", "html_url": "https://arxiv.org/abs/2507.10978", "title": "Mind the Gap: Bridging Occlusion in Gait Recognition via Residual Gap Correction", "title_en": "Mind the Gap: Bridging Occlusion in Gait Recognition via Residual Gap Correction", "authors": "Ayush Gupta,Siyuan Huang,Rama Chellappa", "background": "步态正在成为一种用于行人重新识别的方法，因为它能够远距离识别行人。然而，大多数当前的步态识别工作没有解决遮挡的实际问题。一些工作虽然考虑了遮挡，但仍需要配对的遮挡和全面的序列，这在实际世界中难以收集。此外，这些方法专注于遮挡，但无法在保留全面输入性能的情况下保持高识别率。", "innovation": "提出了一种名为RG-Gait的方法，用于遮挡步态识别中的残差校正，同时保留全面输入的识别准确性。该方法将遮挡步态标记为遮挡步态表示与整体步态表示之间的残差偏差，通过学习并适应性集成残差来提高遮挡步态序列的性能。", "conclusion": "本研究在具有挑战性的Gait3D、GREW和BRIAR数据集上评估了该方法，展示了学习残差作为一种有效技术，用于解决采用全面保留的遮挡步态识别难题。我们已将代码公开发布。"}
{"llm_update_time": "20250723", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2401.13616", "html_url": "https://arxiv.org/abs/2401.13616", "title": "FLLIC: 功能性无失真图像压缩", "title_en": "FLLIC: Functionally Lossless Image Compression", "authors": "Xi Zhang,Xiaolin Wu", "background": "最近，深度神经网络（DNN）模型在无损图像编码方面的压缩性能已经超越了传统的模型，自然彩色图像的无损比特率降低了大约10%。然而，即使有了这些进步，数学上无损图像压缩（MLLIC）的比例仍然无法满足当前和未来大多数实际成像和视觉系统在带宽和成本效益方面的要求。因此，为了克服MLLIC的性能障碍，本文质疑了数学上无损编码必要性的基本前提。考虑到所有数字图像传感器都会受到采集噪声的影响，为什么必须坚持数学上的无损编码，即用额外的比特来保存噪声呢？本文提出了一种新的联合去噪和压缩的范式，称为功能性无失真图像压缩（FLLIC），它对最优化去噪后的图像（优化性可能是任务特定的）进行无损压缩。虽然从噪声输入角度来说不是真正的无损，FLLIC力求获得最佳的噪声无图像的重构重建。实验表明，FLLIC在联合去噪和压缩噪声图像方面达到了优秀性能，并且具有较低的计算成本", "innovation": "本文提出了功能性无失真图像压缩（FLLIC）的新范式，这是一种联合去噪和压缩的方法，不同于传统的数学无损图像压缩，FLLIC通过对最优去噪后的图像进行无损压缩来实现最佳的无噪声原图像的重构。该方法能够以较低的计算成本实现无噪声原图像的最佳重建性能。", "conclusion": "实验结果表明，FLLIC在联合去噪和压缩噪声图像方面达到了当前最先进的性能，并且具有较低的计算成本。"}
{"llm_update_time": "20250723", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.09815", "html_url": "https://arxiv.org/abs/2507.09815", "title": "VRU-Accident: 一种用于事故场景理解的视频问答和密集标注基准", "title_en": "VRU-Accident: A Vision-Language Benchmark for Video Question Answering and Dense Captioning for Accident Scene Understanding", "authors": "Younggun Kim,Ahmed S. Abdelrahman,Mohamed Abdel-Aty", "background": "自动驾驶系统对行人和骑车人等脆弱道路使用者（VRUs）的安全保障是一项关键性的挑战。目前，虽然多模态大型语言模型（MLLMs）在提高自动驾驶车辆场景理解和决策过程中展现出潜力，但仍缺乏标准化的基准测试以定量评估它们在涉及VRUs的复杂、安全关键场景中的推理能力。为解决这一问题，本文提出了VRU-Accident数据集，这是一个大规模的视觉-语言基准，用于评估MLLMs在涉及VRUs的高风险交通场景中的表现。", "innovation": "VRU-Accident数据集不仅包括1000个真实世界行车记录仪事故视频和6000个针对六个关键安全类别（每类包含24000个候选选项和3400个独特的答案选择）的多项选择题-答案对，还包含1000个密集场景描述。此外，该数据集特别关注VRU-车辆事故，并提供丰富的、细粒度的注释，捕捉事故中的时空动态和因果语义。", "conclusion": "本文对17种最先进的模型在多重选择问题答案和密集标注任务上的表现进行了全面评估。研究结果表明，尽管MLLMs在视觉限定属性方面表现良好，但在推理和描述事故原因、类型及其可预防性方面仍有重大挑战。"}
{"llm_update_time": "20250723", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.09279", "html_url": "https://arxiv.org/abs/2507.09279", "title": "Prompt4Trust: 一种用于多模态大型语言模型临床一致性 confidence 校准的强化学习提示增强框架", "title_en": "Prompt4Trust: A Reinforcement Learning Prompt Augmentation Framework for Clinically-Aligned Confidence Calibration in Multimodal Large Language Models", "authors": "Anita Kriz,Elizabeth Laura Janes,Xing Shen,Tal Arbel", "background": "多模态大型语言模型（MLLMs）在医疗保健领域的应用前景广阔，但它们在安全性关键设置中的部署受到两个关键限制：(i) 对提示设计的敏感性；(ii) 生成高置信度的错误响应。由于临床医生可能会依赖模型所声明的置信度来评估其预测的可靠性，因此尤为重要的是，当模型表达高置信度时，也应高度准确。已有方法在提高模型的信心校准方面存在局限，尤其是在安全和值得信赖的临床决策制定方面。文章介绍了一种基于强化学习（RL）的 Prompt4Trust 框架，用于 MLLMs 提示增强，以校准信心，并达到了多任务医疗视觉问答（VQA）基准（PMC-VQA）上的最新性能。", "innovation": "Prompt4Trust 是第一个针对 MLLMs 信心校准的基于强化学习的提示增强框架。它通过训练一个轻量级 LLM 来生成上下文感知的辅助提示，以引导下游任务 MLLM 生成更准确反映预测准确度的响应。该框架特别关注临床决定制定中最关键的信心校准方面。此外，该方法还提高了任务准确性，实现了在 PMC-VQA 基准上的最新医疗 VQA 表现，并展示了其在小规模下游任务的 MLLM 上进行训练后，拥有在大规模 MLLM 上零样本泛化的潜力。", "conclusion": "本文展示了自动化但符合人类方向的提示工程的潜力，以提高 MLLMs 在安全关键设置中的可信度。相关代码可以在提供的网站找到。"}
{"llm_update_time": "20250723", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.09577", "html_url": "https://arxiv.org/abs/2507.09577", "title": "Memory-Augmented SAM2 for Training-Free Surgical Video Segmentation", "title_en": "Memory-Augmented SAM2 for Training-Free Surgical Video Segmentation", "authors": "Ming Yin,Fu Wang,Xujiong Ye,Yanda Meng,Zeyu Fu", "background": "手术视频分割是计算机辅助手术中的关键任务，对于提高手术质量和患者结果至关重要。近期，Segment Anything Model 2 (SAM2) 框架在图像和视频分割方面取得了显著进展，但其贪婪选择记忆设计的固有局限性在手术视频中尤为突出，导致在复杂、长时间视频的分割性能下降。", "innovation": "为了解决这些挑战，作者引入了Memory Augmented (MA)-SAM2，这是一种无需额外训练的视频对象分割策略，包含新颖的上下文感知和遮挡抗性记忆模型。MA-SAM2 对复杂器械运动引起的遮挡和交互具有较强的抗性，同时在视频中保持对象分割的准确性，且通过多目标、单环、一令推理进一步提高了多器械视频的跟踪过程效率。", "conclusion": "无需引入额外参数或进一步训练，MA-SAM2 在 EndoVis2017 和 EndoVis2018 数据集上分别实现了 4.36% 和 6.1% 的性能提升，展示了其在实际手术应用中的潜力。"}
{"llm_update_time": "20250723", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.15852", "html_url": "https://arxiv.org/abs/2507.15852", "title": "SeC: 通过渐进概念构建推进复杂视频物体分割", "title_en": "SeC: Advancing Complex Video Object Segmentation via Progressive Concept Construction", "authors": "Zhixiong Zhang,Shuangrui Ding,Xiaoyi Dong,Songxin He,Jianfan Lin,Junsong Tang,Yuhang Zang,Yuhang Cao,Dahua Lin,Jiaqi Wang", "background": "视频物体分割（VOS）是计算机视觉中的核心任务，要求模型跨视频帧跟踪和分割目标物体。尽管最近的努力在该领域已取得显著进步，但当前的技术在处理剧烈的视觉变化、遮挡以及复杂场景变化方面仍然落后于人类能力，这主要是因为当前技术依赖于外观匹配，而忽略了有助于在时间变化中实现稳健识别的人类般的概念理解。", "innovation": "我们提出了 SeC（概念驱动分割）框架，这是一个概念驱动的分割框架，从传统的特征匹配转向构建和利用高层次、以对象为中心的表示。SeC 使用大尺寸的视觉语言模型（LVLM）来跨多种帧整合视觉线索，构建稳健的概念先验。在推理过程中，SeC 基于处理过的帧形成目标的全面语义表示，从而实现后续帧的稳健分割。此外，SeC 能够适配化地平衡以语义推理为中心的大尺寸视觉语言模型（LVLM）推理与增强的特征匹配，根据场景复杂度动态调整计算努力。", "conclusion": "我们引入了 Semantic Complex Scenarios Video Object Segmentation（SeCVOS）基准测试，这是一个用于评估需求高层次概念推理和稳健语义理解能力的视频物体分割方法的框架。SeCVOS 包含 160 个手动注释的多场景视频，设计用于挑战模型的显著外观变化和动态场景转换。实验结果表明，SeC 在 SeCVOS 上相对于 SAM 2.1 实现了 11.8 分的改进，建立了概念遍知视频物体分割的新基准。"}
{"llm_update_time": "20250723", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2411.05195", "html_url": "https://arxiv.org/abs/2411.05195", "title": "生成性MLLMs如何在使用相同视觉编码器的情况下感知更多-探索生成性MLLMs与CLIP的不同", "title_en": "Exploring How Generative MLLMs Perceive More Than CLIP with the Same Vision Encoder", "authors": "Siting Li,Pang Wei Koh,Simon Shaolei Du", "background": "最近的研究表明，CLIP模型在需要语境组合性、理解空间关系或捕捉细微细节的视觉推理任务中表现不佳。一个自然的假设是CLIP的视觉编码器没有嵌入完成这些任务所必需的信息。然而，研究发现并非总是如此：视觉编码器能够收集与查询相关的信息，而CLIP则无法从中提取，导致失败。研究团队还发现，另一类视觉语言模型（VLMs）——生成型多模态大型语言模型（MLLMs）——在这些任务中的表现明显优于CLIP，使用相同的视觉编码器和权重，这表明这些生成性MLLMs能够更有效地感知和利用视觉信息。为了探究原因，研究团队进行了多项受控实验，结果显示这些MLLMs的成功主要归因于多个关键设计选择，包括切片标记（patch tokens）、位置嵌入（position embeddings）以及基于提示的加权（prompt-based weighting）。此外，单纯增加训练数据或应用更强的文本编码器不足以解决问题，而增加文本标记也提供不了明显的好处。有趣的是，这些基于自回归损失训练的生成性模型，在通过对比微调转化为CLIP样式的编码器后，仍能在相同的余弦相似度评价协议下，优于CLIP。这一研究突显了VLM架构选择的重要性，并提出了改善CLIP样式的对比VLM性能的方向。", "innovation": "该研究创新地展示了非生成性模型的视觉编码器（如CLIP）与生成性模型（如MLLMs）在视觉推理任务中的差异，证明特定的设计选择（如切片标记、位置嵌入和基于提示的加权）对于提高视觉编码器的性能至关重要。即使在将生成性模型的视觉编码器转化为CLIP样式的编码器后，它们的性能仍然优于CLIP，这表明这种设计选择对视觉和语义信息的处理更为有效。", "conclusion": "研究表明，CLIP和MLLMs在视觉推理任务中的表现差异主要归因于模型的架构设计因素，尤其是切片标记、位置嵌入和基于提示的加权。尽管增加训练数据或应用更强的文本编码器不足以显著提高性能，但这些设计选择确实能有效提升视觉编码器的性能。未来的研究可进一步探索这些设计选择的具体机制以及它们对不同视觉和语义任务的表现影响。"}
{"llm_update_time": "20250723", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2406.13413", "html_url": "https://arxiv.org/abs/2406.13413", "title": "用于医学图像配准的递归推理机", "title_en": "Recurrent Inference Machine for Medical Image Registration", "authors": "Yi Zhang,Yidong Zhao,Hui Xue,Peter Kellman,Stefan Klein,Qian Tao", "background": "医学图像应用中需要通过将多个图像中的体素对齐来进行定性和定量分析，为此需要进行图像配准。近年来，基于深度神经网络和并行计算的深度学习方法在医学图像配准中的表现与传统优化方法相当，尤其是在灵活建模和快速推理方面。然而，与基于优化的方法相比，深度神经网络在训练时需要大量数据集，而基于优化的方法则无需训练。因此，为了提高配准精度并减少对数据的需求，作者提出了一种名为递归推理图像配准（RIIR）的新方法。", "innovation": "该方法将图像配准问题作为迭代求解器进行建模，通过元学习解决了配准精度和数据效率问题，它学习了优化更新规则，并结合了隐式正则化和显式梯度输入。", "conclusion": "RIIR网络在脑部MRI和定量心脏MRI数据集上进行了广泛评估，结果显示其在配准精度和训练数据效率方面优于多种基于深度学习的方法，甚至仅使用5%的训练数据也能表现出高效性。此外，消融实验表明隐含状态在递归推理框架中对于元学习具有重要增值作用。"}
{"llm_update_time": "20250723", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2504.05119", "html_url": "https://arxiv.org/abs/2504.05119", "title": "通过激活函数选择实现嵌入式DNN的稳健性和效率平衡", "title_en": "Balancing Robustness and Efficiency in Embedded DNNs Through Activation Function Selection", "authors": "Jon Gutiérrez-Zaballa,Koldo Basterretxea,Javier Echanobe", "background": "对于诸如航空和自动驾驶等关键应用中的基于机器学习的嵌入式系统来说，必须对由软错误引起的扰动具有鲁棒性。随着晶体管几何尺寸缩小和电压下降，现代电子设备对背景辐射的敏感度增加，导致软错误导致的故障风险加剧。深度神经网络（DNNs）的鲁棒性不仅依赖于目标设备技术，还取决于模型结构以及参数的数值表示及其算术精度。压缩技术如剪枝和量化用于减少内存占用和计算复杂度，会同时改变模型结构和表示形式，影响软错误的鲁棒性。尽管这一点往往被忽视，但激活函数（AFs）的选择不仅影响精度和训练性，还影响压缩性和容错性。本文研究边界激活函数在增强参数扰动鲁棒性方面的应用，并通过技术无关的方法评估其对模型精度、可压缩性以及计算负载的影响。研究集中在用于高光谱图像语义分割的编码-解码卷积模型上，并应用到自动驾驶系统中。实验在AMD-Xilinx的KV260系统模块上进行。", "innovation": "本文通过探索使用边界激活函数来增强模型对参数扰动的鲁棒性，并采用技术无关的方法评估边界激活函数对模型精度、可压缩性和计算负载的影响，这些激活函数的选择不仅影响网络的精度和训练性，而且还影响压缩性和容错性。", "conclusion": "通过在边界激活函数下对模型稳健性和效率的综合分析，本文的研究结果表明，激活函数的选择能够显著提高嵌入式DNN模型的鲁棒性和效率。"}
{"llm_update_time": "20250723", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.15680", "html_url": "https://arxiv.org/abs/2507.15680", "title": "视觉语言模型知识蒸馏方法在图像质量评估中的应用", "title_en": "Visual-Language Model Knowledge Distillation Method for Image Quality Assessment", "authors": "Yongkang Hou,Jiarun Song", "background": "图像质量评估（IQA）是计算机视觉的核心任务之一。基于视觉-语言模型的多模态方法，如CLIP，已经在IQA任务中展现了出色的泛化能力。但是，CLIP在IQA任务中存在参数负担过重和局部失真特征识别能力不足的问题。该研究旨在解决这些问题。", "innovation": "该研究提出了一个视觉-语言模型知识蒸馏方法，该方法利用CLIP的IQA知识指导具有架构优势的模型训练。首先设计了质量分级提示模板，引导CLIP输出质量评分。然后对CLIP进行微调以增强其IQA任务能力。最后，提出了一个模态自适应知识蒸馏策略，以实现从CLIP教师模型到学生模型的指导。实验结果表明，该方法在多个IQA数据集上不仅大幅降低了模型复杂性，还优于现有IQA方法，显示出良好的实用前景。", "conclusion": "所提出的方法不仅能显著简化模型结构，同时在IQA任务上的表现也超过了现有方法，未来在实际应用中具有较高的潜力。"}
{"llm_update_time": "20250723", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2505.02304", "html_url": "https://arxiv.org/abs/2505.02304", "title": "使用多正样本对比学习的生成式手语描述提示符在手语识别中的应用", "title_en": "Generative Sign-description Prompts with Multi-positive Contrastive Learning for Sign Language Recognition", "authors": "Siyu Liang,Yunan Li,Wentian Xin,Huizhou Chen,Xujie Liu,Kang Liu,Qiguang Miao", "background": "手语识别（SLR）面临着因同时包含复杂的手动和非手动信号而在创建准确标注方面产生的根本挑战。到目前为止，这项工作是首个将生成型大语言模型（LLMs）整合到SLR任务中的工作。传统的方法在处理这种复杂性时存在诸多限制，因此需要新的方法来提高SLR的准确性与可靠性。本研究采用了一种新颖的方法来克服这些挑战。", "innovation": "提出了一种名为GSP-MC的新方法，利用检索增强生成（RAG）与领域特定的大语言模型相结合，结合多步骤提示工程和专家验证的手语语料库来生成精确的多部分描述。这种方法还包括使用双编码器架构在多层次骨架特征与多种文本描述（全局、同义词和部分层面）之间进行双向对齐，并通过概率匹配实现这一目标。", "conclusion": "实验结果表明，该方法在现有的中国SLR500数据集（准确率为97.1%）和土耳其AUTSL数据集（准确率为97.07%）上表现出了最先进的性能。跨语言的有效性进一步证明了其在开发包容性通讯技术方面的潜力。"}
{"llm_update_time": "20250723", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.14456", "html_url": "https://arxiv.org/abs/2507.14456", "title": "GEMINUS: 意识到双重情境的全局和场景适应性专家混合框架用于端到端自动驾驶", "title_en": "GEMINUS: Dual-aware Global and Scene-Adaptive Mixture-of-Experts for End-to-End Autonomous Driving", "authors": "Chi Wan,Yixin Cui,Jiatong Du,Shuo Yang,Yulong Bai,Yanjun Huang", "background": "端到端的自动驾驶需要适应复杂多样的交通环境。现有方法多采用单一模式规划，难以学习全面策略，也无法获得应对多样化场景所需的多样驾驶技能。", "innovation": "提出了GEMINUS框架，该框架包含全局专家、场景适应专家组，并配备双重意识路由器。全局专家基于整体数据集训练，具有稳健性能；场景适应专家基于对应场景子集训练，实现适应性性能。双重意识路由器同时考虑场景级别特征和路径不确定性，实现专家模块的动态激活。通过全局专家和场景适应专家组的有效耦合，GEMINUS在多种场景中实现了适应性和稳健性。", "conclusion": "GEMINUS在闭环基准Bench2Drive中优于现有方法，在Driving Score、Success Rate和MultiAbility-Mean等方面均表现出色，甚至仅使用单目视觉输入。消融研究还显示，与原始单专家基准相比，改进显著：Driving Score提升7.67%，Success Rate提升22.06%，MultiAbility-Mean提升19.41%。相关代码将在指定网址提供。"}
{"llm_update_time": "20250723", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2503.10637", "html_url": "https://arxiv.org/abs/2503.10637", "title": "在扩散模型中蒸馏多样性和控制", "title_en": "Distilling Diversity and Control in Diffusion Models", "authors": "Rohit Gandikota,David Bau", "background": "蒸馏扩散模型在训练样本多样性方面存在关键限制，与基模型相比，样品种类较少。尽管如此，研究表明，蒸馏模型保留了基模型的基本概念表示。这项研究旨在探究蒸馏过程中样本多样性减少的具体机制，并开发了一种新的蒸馏方法以恢复甚至增强多样性。", "innovation": "提出了控制蒸馏方法，即通过在基模型上训练的概念滑块和LoRAs机制，可以无缝地转移到蒸馏模型中，反之亦然，这种方法有效地实现了控制蒸馏，而无需重新训练。通过分析$\bar{\boldsymbol{x}}_{0}$可视化，揭示了模型在中间步骤如何预测最终输出，发现初始扩散时间步对输出多样性有直接影响，而后续步骤主要改进细节。基于这些发现，提出了一种新的混合推理方法，即在关键的第一个时间步采用基模型进行推理，之后切换到高效的蒸馏模型。实验结果表明，这种方法在保持蒸馏推理的计算效率的同时，甚至还能增强基模型的多样性。", "conclusion": "通过引入多样性蒸馏，研究人员成功地恢复并提升了蒸馏模型的多样性能力，而不需要额外的训练或模型修改，同时保持了高效推理的计算效率。"}
{"llm_update_time": "20250723", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2506.23516", "html_url": "https://arxiv.org/abs/2506.23516", "title": "FedWSQ：具有权重标准化和分布感知非均匀量化高效联邦学习", "title_en": "FedWSQ: Efficient Federated Learning with Weight Standardization and Distribution-Aware Non-Uniform Quantization", "authors": "Seung-Wook Kim,Seongyeol Kim,Jiah Kim,Seowon Ji,Se-Ho Lee", "background": "联邦学习（FL）常因数据异质性和通信限制等问题而导致性能下降。因此，本文分析了FL框架面临的挑战及其对实际应用的影响，强调了改进FL技术的必要性与迫切性。", "innovation": "本文提出了一种名为FedWSQ的新颖FL框架，该框架结合了权重标准化（WS）和分布感知非均匀量化（DANUQ）。权重标准化通过在训练过程中筛选出局部更新中的偏差成分，提高了模型对于数据异质性和客户端不稳定参与的鲁棒性。而分布感知非均匀量化则利用本地模型更新的统计特性来最小化量化误差，从而在减少通信开销的同时保持高性能。", "conclusion": "广泛实验表明，FedWSQ在各种具有挑战性的FL场景，特别是极端数据异质性和超低比特通信环境下，优于现有FL方法，在保持高模型准确性的同时显著降低了通信开销。"}
{"llm_update_time": "20250723", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.15487", "html_url": "https://arxiv.org/abs/2507.15487", "title": "DeSamba: 分裂光谱自适应框架用于3D多序列MRI病灶分类", "title_en": "DeSamba: Decoupled Spectral Adaptive Framework for 3D Multi-Sequence MRI Lesion Classification", "authors": "Dezhen Wang,Sheng Miao,Rongxin Chai,Jiufa Cui", "background": "MRI序列提供了丰富的空间和频率域信息，这对于准确的病灶分类至关重要。然而，有效整合多序列MRI数据进行稳健的3D病灶分类仍然是一个挑战。现有的方法在处理多序列MRI数据时，难以同时获取和融合多种空间和光谱信息，从而影响病灶分类的准确性和鲁棒性。", "innovation": "本文提出了一种名为DeSamba的新颖框架，用于提取分离的表示并自适应地融合空间和光谱特征以进行病灶分类。具体来说，DeSamba引入了一个分裂表示学习模块（DRLM），该模块通过自重构和交叉重构将来自不同MRI序列的特征解耦，以及一种光谱自适应调制块（SAMB），通过病变特征动态融合光谱和空间信息。通过在两个临床相关的3D数据集上的评估，DeSamba展现出优于所有最先进的（SOTA）基线模型的效果，特别是在外部验证集上的表现显著提升。", "conclusion": "我们的结果表明，DeSamba作为一种通用且有效的3D病灶分类解决方案，在多序列医学影像应用中具有巨大潜力。特别是在与DRLM和SAMB相关的消融研究中，我们观察到显著的性能改进。"}
{"llm_update_time": "20250723", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2409.12190", "html_url": "https://arxiv.org/abs/2409.12190", "title": "急切模式下的束调整", "title_en": "Bundle Adjustment in the Eager Mode", "authors": "Zitong Zhan,Huan Xu,Zihang Fang,Xinpeng Wei,Yaoyu Hu,Chen Wang", "background": "束调整（BA）是机器人应用中的关键技术，如同步定位与地图构建（SLAM）、增强现实（AR）和摄影测量等。随着深度学习在感知系统中的重要性日益增加，需要将BA与现代深度学习框架（如PyTorch）集成，以提高可靠性和性能。然而，常用的基于C++的BA库（如GTSAM、g^2o和Ceres）缺乏与现代深度学习库的原生集成，这限制了它们的灵活性、适应性、调试简便性和整体实现效率。", "innovation": "本文介绍了一个与PyTorch无缝集成的高效急切模式下的BA库。该库包括GPU加速、可微分和稀疏操作，适用于第2阶优化、李群和李代数操作以及线性求解器。与GTSAM、g^2o和Ceres相比，基于GPU的急切模式下的BA库表现出显著的运行时效率，分别提高了18.5倍、22倍和23倍。", "conclusion": "我们的BA库与PyTorch的集成提高了BA算法的灵活性和效率，适用于现代机器人应用。"}
{"llm_update_time": "20250723", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.15493", "html_url": "https://arxiv.org/abs/2507.15493", "title": "GR-3 技术报告", "title_en": "GR-3 Technical Report", "authors": "Chilam Cheang,Sijin Chen,Zhongren Cui,Yingdong Hu,Liqun Huang,Tao Kong,Hang Li,Yifeng Li,Yuxiao Liu,Xiao Ma,Hao Niu,Wenxuan Ou,Wanli Peng,Zeyu Ren,Haixin Shi,Jiawen Tian,Hongtao Wu,Xin Xiao,Yuyang Xiao,Jiafeng Xu,Yichu Yang", "background": "本文报告了构建广泛型机器人策略的最新进展，特别是在GR-3的发展。GR-3是一个大型的视觉-语言-动作（VLA）模型，表现出在新对象、新环境和涉及抽象概念的新指令上的出色泛化能力。此外，它还可以通过最少的人类轨迹数据进行高效微调，使得新的环境适应变得快速且低成本。本文还展示了GR-3在处理长时间和灵巧的任务中的优越性，包括双手操作和移动任务，展示了其稳健性和可靠性。这些性能是通过多方面的训练配方实现的，包括与大规模网络视觉-语言数据的协同训练、通过VR设备收集的人类轨迹数据进行高效的模型微调，以及有效的模仿学习，使用机器人轨迹数据进行训练。同时，介绍了一个具有出色灵活性和可靠性的可双手操作的移动机器人——ByteMini，它与GR-3结合后可以完成多种任务。本文通过广泛的实地实验表明，GR-3在多种具有挑战性的任务中超越了最先进的基线方法$π_0$。", "innovation": "本文的创新点在于，提出了一种大型的视觉-语言-动作（VLA）模型GR-3，该模型解决了机器人在新对象、新环境和抽象指令下的泛化问题，并通过最少的人类轨迹数据实现高效微调。此外，GR-3展示了在长时间任务和双一手部操作及移动任务中的优越性能，并且提出了一种包含大量的网络视觉-语言数据协同训练、VR设备收集的人类轨迹数据微调以及基于机器人轨迹数据的模仿学习的多方面训练方法。同时，介绍了一个灵活可靠的双手持移动机器人ByteMini，与GR-3结合后可以执行多种任务。", "conclusion": "本文展示了GR-3在多种具有挑战性任务中的出色性能，通过广泛的实地实验证明了GR-3在多个方面超越了最先进的基线方法$π_0$。期望GR-3能够成为构建能够改善人类日常生活工作的广泛型机器人研究的重要一步。"}
{"llm_update_time": "20250723", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.15862", "html_url": "https://arxiv.org/abs/2507.15862", "title": "量化整体评审：一种多模态的本科入学预测方法", "title_en": "Quantifying Holistic Review: A Multi-Modal Approach to College Admissions Prediction", "authors": "Jun-Wei Zeng,Jerry Shen", "background": "该论文背景在于传统的整体评审方法存在透明度低、不一致性和申请人的焦虑等问题。因此，需要一种能够量化和解释整体评审的方法，以实现更加公平和数据驱动的入学评估实践。", "innovation": "论文介绍了一种创新的多模态框架——全面申请人概况评分（CAPS），通过分解申请人的学术表现、作文质量和课外活动参与度三个可解释的部分，并利用基于变压器的语义嵌入、大规模语言模型评分和梯度提升回归，实现透明且可解释的评估，与人类判断相一致。实验结果显示该方法具有较强性能，特别是在作文质量指数（EQI）预测、分类精度、宏观F1分数和加权F1分数方面表现突出。这种创新的方法解决了传统整体评审的关键局限性，尤其是在透明度、一致性和申请人的焦虑方面。", "conclusion": "CAPS为更公平、基于数据的招生实践铺平了道路，通过透明和可解释的评估方式，提高了入学评估的数据化和公平性。"}
{"llm_update_time": "20250723", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.15292", "html_url": "https://arxiv.org/abs/2507.15292", "title": "EndoControlMag: 周期参考重置和分层组织感知双模掩控下的鲁棒内窥镜血管运动放大", "title_en": "EndoControlMag: Robust Endoscopic Vascular Motion Magnification with Periodic Reference Resetting and Hierarchical Tissue-aware Dual-Mask Contro", "authors": "An Wanga,Rulin Zhou,Mengya Xu,Yiru Ye,Longfei Gou,Yiting Chang,Hao Chen,Chwee Ming Lim,Jiankun Wang,Hongliang Ren", "background": "在内窥镜手术中，可视化微妙的血管运动对于手术精度和决策至关重要，但因手术场景复杂且动态，这一任务仍然具有挑战性。为此，研究人员引入了EndoControlMag，一个无需训练的、基于拉格朗日的方法，专为内窥镜环境设计，针对血管运动进行放大。该方法通过两个关键模块：周期参考重置（PRR）方案和分层组织感知双模掩控（HTM）框架，解决了这一难题。PRR方案将视频划分为短且重叠的片段，动态更新参考帧以防止误差累积同时保持时间连贯性。HTM框架使用预训练的视觉跟踪模型跟踪血管核心，并根据观察到的组织位移或距离应用两种适应性软化策略，以适应不同的手术场景需求。", "innovation": "EndoControlMag引入了周期参考重置（PRR）方案和分层组织感知双模掩控（HTM）框架，提升了内窥镜手术中血管运动的可视化效果。PRR方案通过动态更新参考帧来防止误差累积同时保持时间连贯性。HTM框架首先使用预训练的视觉跟踪模型跟踪血管核心，即使在遮挡和视角变化的情况下也能维持准确的定位，然后应用两种适应性软化策略之一：基于运动的软化或距离为基础的指数衰减。这种双模策略可以适应复杂的组织变形情况以及不可靠的光学流量条件。", "conclusion": "EndoControlMag在EndoVMM24数据集上的四个不同手术类型和各种挑战性场景中进行了评估，显示其在放大精度和视觉质量方面显著优于现有方法，并具有强大的鲁棒性。结果表明，该方法在内窥镜手术场景中具有出色的表现，并且已公开了代码、数据集和视频结果。"}
{"llm_update_time": "20250723", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2505.16104", "html_url": "https://arxiv.org/abs/2505.16104", "title": "Hierarchical Safety Realignment: Lightweight Restoration of Safety in Pruned Large Vision-Language Models", "title_en": "Hierarchical Safety Realignment: Lightweight Restoration of Safety in Pruned Large Vision-Language Models", "authors": "Yue Li,Xin Yi,Dongsheng Shi,Gerard de Melo,Xiaoling Wang,Linlin Wang", "background": "随着大型视觉-语言模型（LVLMs）规模的扩大，旨在压缩模型以在资源受限环境中部署的网络剪枝技术受到了广泛关注。然而，剪枝往往会导致安全性能下降。", "innovation": "提出了一种名为Hierarchical Safety Realignment（HSR）的新型轻量级方法。HSR首先量化每个注意力头部对安全性的贡献，识别最关键的注意力头部，然后在这些关键的注意力头部内选择性地恢复对保持安全性至关重要的神经元。该过程从注意力头部级别到神经元级别逐级重新调整剪枝后LVLMs的安全性。", "conclusion": "HSR在各种模型和剪枝策略下进行了验证，一致地实现了显著的安全性能改进。据我们所知，这是第一项明确关注剪枝后LVLMs的安全性的研究工作。"}
{"llm_update_time": "20250723", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.15897", "html_url": "https://arxiv.org/abs/2507.15897", "title": "ReDi: 受矫正的离散流", "title_en": "ReDi: Rectified Discrete Flow", "authors": "Jaehoon Yoo,Wonjung Kim,Seunghoon Hong", "background": "离散流模型（DFMs）是生成高质离散数据的强大模型，但由于依赖多次迭代解码过程，通常会导致采样速度较慢。这种依赖性源于DFMs对因子分解近似的使用，这是处理高维数据的必要步骤。", "innovation": "本文通过使用条件总相关性（TC）来严格表征因子分解的近似误差，并提出了一个名为'受矫正的离散流'（ReDi）的新迭代方法。ReDi通过矫正源分布和目标分布之间的耦合来减少因子分解误差，从而实现高效的小步骤生成。理论证明，每个ReDi步骤都能保证条件TC单调递减，确保其收敛。实验结果表明，ReDi显著减少了条件TC并使其可以进行小步骤生成，同时也适用于图像生成的一次性模型训练中，提供了对高效离散数据合成的新视角。", "conclusion": "受矫正的离散流提供了一种简单且理论上支持的方法来解决小步骤挑战，为高质离散数据生成提供了新的方法论框架。"}
{"llm_update_time": "20250723", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2505.16938", "html_url": "https://arxiv.org/abs/2505.16938", "title": "InternAgent：当代理成为科学家——从假设到验证构建闭环系统", "title_en": "InternAgent: When Agent Becomes the Scientist -- Building Closed-Loop System from Hypothesis to Verification", "authors": "InternAgent Team:Bo Zhang,Shiyang Feng,Xiangchao Yan,Jiakang Yuan,Runmin Ma,Yusong Hu,Zhiyin Yu,Xiaohan He,Songtao Huang,Shaowei Hou,Zheng Nie,Zhilong Wang,Jinyao Liu,Tianshuo Peng,Peng Ye,Dongzhan Zhou,Shufei Zhang,Xiaosong Wang,Yilan Zhang,Meng Li,Zhongying Tu,Xiangyu Yue,Wangli Ouyang,Bowen Zhou,Lei Bai", "background": "人工智能（AI）正加速科研范式的转变，不仅提升了研究效率，还促进了创新。本文介绍了一种名为InternAgent的统一闭环多智能体框架，旨在跨各种科学领域进行自主科学研究（ASR），以前所未有的速度和精度解决复杂问题。", "innovation": "InternAgent的创新点在于：1）可扩展性：证明了适用于12项科学研究任务的广泛适用性，能够生成创新想法以提高基线代码性能；2）交互性：提供了一个让人类专家反馈和多智能体交互的接口，便于将领域专家知识无缝集成进自动化过程；3）高效性：在多个科学领域实现了显著的性能提升，所花费时间比人类更少。例如，在反应产率预测上，从27.6%提高到35.4%，仅耗时12小时；在增强子活性预测上，准确率从0.65提升到0.79，仅需4小时；在2D语义分割上，精确度从78.8%提升到81.0%，仅花了30小时。", "conclusion": "相较于人类的探索，InternAgent在多个科学领域都展现出了显著的时间和效率优势，证明了其在解题速度和精度上的出色表现，并且能够促进科研创新。"}
{"llm_update_time": "20250723", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.15869", "html_url": "https://arxiv.org/abs/2507.15869", "title": "一个用于超网络研究的开放神经网络数据集", "title_en": "An open dataset of neural networks for hypernetwork research", "authors": "David Kurtenbach,Lior Shamir", "background": "尽管人工智能具有变革潜力，然而生成其他神经网络（通过生成模型权重）的神经网络（hypernetworks）的概念却很少被研究。原因之一可能是可用的研究资源缺乏。本文描述了一个为超网络研究设计的神经网络数据集，旨在填补这一研究空白。数据集包含10,000个用于二元图像分类的LeNet-5神经网络，每个网络被分为10个类别，每个类别包含1,000个不同的神经网络，能够识别ImageNette V2类中的一种并将其与其他类别区分开来。使用了超过10,000个核心的计算集群来生成此数据集。", "innovation": "本文贡献了一个为超网络研究设计的数据集，这将促进相关领域的研究。数据集包含大量的LeNet-5神经网络，能够用于训练和验证超网络。通过开源数据集和生成代码，研究者可以更轻松地进行超网络相关研究。", "conclusion": "本文的数据集和生成代码向公众开放，它使得研究人员能够利用这些神经网络进行超网络研究，有助于提高该领域的发展。实验结果显示，这些神经网络可以通过监督学习算法实现72.0%的分类准确率，表明了网络间差异可以通过机器学习方法识别。"}
{"llm_update_time": "20250723", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.15900", "html_url": "https://arxiv.org/abs/2507.15900", "title": "通过使用超球面坐标改进高维潜在空间的VAE生成能力", "title_en": "Improving the Generation of VAEs with High Dimensional Latent Spaces by the use of Hyperspherical Coordinates", "authors": "Alejandro Ascarate,Leo Lebrat,Rodrigo Santa Cruz,Clinton Fookes,Olivier Salvado", "background": "变分自编码器（VAE）通过将数据编码为低维潜在向量，然后解码回数据。一旦训练完成，从先验中解码随机潜在向量通常不会生成有意义的数据，特别是在潜在空间维数超过十几个时，标准VAE的潜在向量在高维统计中一般被构造为均匀分布于超球面上。这就提出了一个需要改善的问题：如何利用潜在空间的特性提高VAE的生成能力？", "innovation": "本文通过借鉴高维统计的知识，提出了一种使用超球面坐标的潜在变量表示方式，从而将潜在向量压向超球面上的一个岛，减小潜在空间的稀疏性，进而提高VAE的生成能力。此外，该方法具有有限的计算开销。这项研究是对VAE潜在空间本质的一种创新利用方法，通过几何上的直观手段改进了模型的性能。", "conclusion": "实验结果表明，通过对潜在空间进行超球面坐标参数化，可以有效地减少潜在空间的稀疏性，提高VAE生成有意义数据的能力。该方法在保持低计算成本的同时取得了显著效果，可以作为改进高维潜在空间VAE生成性能的有效手段。"}
{"llm_update_time": "20250723", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.11936", "html_url": "https://arxiv.org/abs/2507.11936", "title": "深度学习在几何问题解决中的综述", "title_en": "A Survey of Deep Learning for Geometry Problem Solving", "authors": "Jianzhe Ma,Wenxuan Wang,Qin Jin", "background": "几何问题解决是数学推理的关键领域，广泛应用于教育、人工智能数学能力评估以及多模态能力评估。近年来，深度学习技术的快速发展，尤其是多模态大型语言模型的兴起，引发了广泛的研究热潮。", "innovation": "该论文对深度学习在几何问题解决中的应用进行了综述，包括对相关任务的综合总结、对相关深度学习方法的全面审查、对评估指标和方法的详细分析，并对目前面临的挑战和未来方向进行了批判性讨论。旨在为几何问题解决领域的深度学习提供一个全面和实用的参考，促进该领域的发展。", "conclusion": "本研究旨在提供深度学习在几何问题解决领域的全面综述，促进该领域的进一步发展，并在一个不断更新的GitHub列表上创建论文目录：this https URL."}
{"llm_update_time": "20250723", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.15904", "html_url": "https://arxiv.org/abs/2507.15904", "title": "Fast-VAT：使用Cython和Numba加速聚类倾向可视化", "title_en": "Fast-VAT: Accelerating Cluster Tendency Visualization using Cython and Numba", "authors": "MSR Avinash(Presidency University, Bangalore),Ismael Lachheb(EPITA School of Engineering and Computer Science, Paris, France)", "background": "Visual Assessment of Cluster Tendency (VAT)是一种广泛使用的无监督技术，用于评估未标记数据集中是否存在聚类结构。然而，其标准实现因时间复杂度过高（O(n^2)）和内存使用效率低而受到严重性能限制。", "innovation": "我们提出了Fast-VAT，这是一种使用Python重新实现的VAT算法，结合了Numba的即时编译技术和Cython的静态类型和低级内存优化。我们的方法在保持原始方法输出保真度的前提下，比基准实现快50倍。此外，我们通过使用霍普金斯统计、PCA和t-SNE验证了Fast-VAT的有效性，并将其结构洞察结果与DBSCAN和K-Means的聚类结果进行了比较。", "conclusion": "我们通过在Cython和Numba的支持下优化了Fast-VAT，显著提高了其性能，同时保持了原始方法的输出质量。通过在实际和合成数据集上的测试，验证了Fast-VAT的可靠性和有效性。"}
{"llm_update_time": "20250723", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.15917", "html_url": "https://arxiv.org/abs/2507.15917", "title": "HyDRA: 一种验证驱动的混合推理架构用于知识图谱", "title_en": "HyDRA: A Hybrid-Driven Reasoning Architecture for Verifiable Knowledge Graphs", "authors": "Adrian Kaiser,Claudiu Leoveanu-Condrei,Ryan Gold,Marius-Constantin Dinu,Markus Hofmarcher", "background": "神经符号人工智能（neurosymbolic AI）结合了符号知识，通常以知识图谱（KGs）的形式表示，与神经网络的生成能力，这是推动神经符号人工智能进步的中心。然而，当前主要的瓶颈在于自动知识图谱构建的困难，包括可靠性、一致性和可验证性等方面的问题。这些问题可能会导致生成的图谱出现结构性不一致，如数据岛屿或抽象类别与具体实例的误混等。", "innovation": "该研究提出了HyDRA（Hybrid-Driven Reasoning Architecture），一种用于验证的知识图谱自动化混合驱动推理架构。它通过合作的神经符号代理构建领域内的本体，并围绕一组竞争性问题（CQs）达成共识，指导从任意文档中自动提取三元组以生成KG。研究还采用了设计合同（DbC）原则，并借助符号验证（SymbolicAI框架中描述的）扩展标准基准，提出了评估生成的KG功能正确性的方法。", "conclusion": "HyDRA通过提供一种混合驱动的架构来提高自动知识图谱构建的可靠性，并探索评估方法来衡量其输出的功能完整性。同时，该研究的代码已公开。"}
{"llm_update_time": "20250723", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.15907", "html_url": "https://arxiv.org/abs/2507.15907", "title": "双Turing测试：一种检测和缓解不可检测AI的框架", "title_en": "Dual Turing Test: A Framework for Detecting and Mitigating Undetectable AI", "authors": "Alberto Messina", "background": "文章提出了一个统一框架，该框架结合了三项内容：（1）对图灵测试的反向视角‘双重图灵测试’，在这个测试中，人类评委的目标是识别出人工智能，而不是奖励一台机器虚构的能力；（2）一个具有显式质量约束和最坏情况保证的正式对抗分类游戏；（3）一个使用不可检测检测器和一组相关质量组件作为其奖励模型的一部分的强化学习（ RL）对齐流程。文章回顾了历史先例，从倒置图灵变体到现代监督反向图灵分类器，并强调了三重门槛、分阶段难度和最小最大保证的结合带来的新颖性。", "innovation": "提出了‘双重图灵测试’框架，结合了高质量门槛、分阶段难度水平和最小最大保证的正式对抗分类游戏，以及一个使用不能检测检测器和一组相关质量组件的强化学习对齐流程。这个框架旨在检测和缓解不可检测的人工智能，通过正则化的对抗训练提高系统的透明度和可信度。", "conclusion": "文章通过详细解释每个组件符号、内部最小化序列、分阶段测试和迭代对抗训练过程，对双重图灵测试框架进行了阐述，并提出了一些建议的具体行动措施，在未来的研究和实践中采取行动。"}
{"llm_update_time": "20250723", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.15867", "html_url": "https://arxiv.org/abs/2507.15867", "title": "RDMA：电子健康记录系统中的低成本代理驱动的罕见疾病发现", "title_en": "RDMA: Cost Effective Agent-Driven Rare Disease Discovery within Electronic Health Record Systems", "authors": "John Wu,Adam Cross,Jimeng Sun", "background": "罕见疾病影响美国10%的人口，但标准ICD编码系统未能在电子健康记录（EHR）中捕获这些疾病的信息，关键信息被埋没在临床笔记中。当前方法难以处理医学缩写、遗漏隐含的疾病提及、在云处理中产生隐私担忧，并缺乏临床推理能力。", "innovation": "我们提出了一种名为Rare Disease Mining Agents（RDMA）的框架，该框架模仿了医疗专家在EHR中识别罕见疾病模式的方式。RDMA能够连接分散的临床观察，以暗示特定的罕见状况。通过处理临床缩写、识别隐含的疾病模式，并在标准硬件上进行上下文推理，RDMA减少了隐私风险，同时将F1性能提高了30%以上，并将推理成本降低了10倍。", "conclusion": "这种方法帮助临床医生避免使用云服务带来的隐私风险，同时可以从EHR系统中访问关键的罕见疾病信息，支持罕见疾病患者的早期诊断。"}
{"llm_update_time": "20250723", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.16012", "html_url": "https://arxiv.org/abs/2507.16012", "title": "神经概率性成形：光纤通信的联合分布学习", "title_en": "Neural Probabilistic Shaping: Joint Distribution Learning for Optical Fiber Communications", "authors": "Mohammad Taha Askari,Lutz Lampe,Amirhossein Ghazisaeidi", "background": "本论文提出了一种用于非线性光纤信道上的概率性整形的自回归端到端学习方法。该方法通过学习联合符号分布，解决了双极化64-QAM传输在单跨205公里光纤链路中的问题，实现了优化边缘分布下的0.3比特/2D的信息率增益。", "innovation": "论文创新地提出了一种自回归的端到端学习方法来学习联合符号分布，并在优化的边缘分布上实现了0.3比特/2D的信息率增益。这种方法适用于双极化64-QAM在单跨205公里光纤链路中的概率性整形，显著提高了信息传输的效率和可靠性。", "conclusion": "所提出的方案在单跨205公里的光纤链路上实现了双极化64-QAM传输，通过学习联合符号分布提供了一种高效的信息率增益，并展示了在实际光纤通信中的应用潜力。"}
{"llm_update_time": "20250723", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.15987", "html_url": "https://arxiv.org/abs/2507.15987", "title": "具有结构化分层核的语义感知高斯过程校准用于深度神经网络", "title_en": "Semantic-Aware Gaussian Process Calibration with Structured Layerwise Kernels for Deep Neural Networks", "authors": "Kyung-hwan Lee,Kyung-tae Kim", "background": "神经网络分类器的信心校准对于在推断过程中量化其预测可靠性至关重要。然而，传统的高斯过程（GP）校准方法往往无法捕捉深层神经网络的内部层次结构，从而限制了其解释性和评估预测可靠性的有效性。", "innovation": "提出了语义感知分层高斯过程（SAL-GP）框架，这种框架模仿目标神经网络的分层结构。相对于应用单一全局GP校正，SAL-GP使用一个多层GP模型，其中每个层的特征表示被映射到局部校准校正。通过结构化的多层次内核使这些层间GP耦合，实现所有层之间的联合边际化解。这种设计使SAL-GP能够捕捉局部语义依赖关系和全局校准一致性，同时一致地传播预测不确定性穿过整个网络。因此，该框架增强了与网络架构一致的可解释性，并允许在深度模型中进行原则性的信心一致性和不确定性量化评估。", "conclusion": "所提出的SAL-GP框架增强了对神经网络架构的理解，通过使用分层建模技术和内部语义感知的高斯过程模型，提高了对预测可靠性的定量评价能力。"}
{"llm_update_time": "20250723", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.15905", "html_url": "https://arxiv.org/abs/2507.15905", "title": "基于基础模型和变换器的异常检测：综述", "title_en": "Foundation Models and Transformers for Anomaly Detection: A Survey", "authors": "Mouïn Ben Ammar,Arturo Mendoza,Nacim Belkhir,Antoine Manzanera,Gianni Franchi", "background": "随着深度学习的发展，本文调研了变换器和基础模型在视觉异常检测（VAD）中的变革性作用。我们探讨了这些架构如何通过全局感受野和适应性解决长程依赖建模、上下文建模和数据稀缺性等挑战。文章将VAD方法分为基于重建、基于特征和零/少样本方法，并强调基础模型带来的范式转变。通过结合注意力机制并利用大规模预训练，变换器和基础模型使得异常检测解决方案更加稳健、可解释和可扩展。", "innovation": "通过结合注意力机制和大规模预训练，变换器和基础模型提供了一种更为稳健、可解释和可扩展的异常检测解决方案，推动了VAD方法的革新，并详细分类了VAD的技术路线和发展趋势，展示了基础模型对于该领域的范式转变。", "conclusion": "本文全面审查了最先进技术及其优缺点，强调了利用这些架构进行视觉异常检测的方法和发展趋势。"}
{"llm_update_time": "20250723", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.15846", "html_url": "https://arxiv.org/abs/2507.15846", "title": "GUI-G$^2$: 高斯奖励模型用于GUI定位", "title_en": "GUI-G$^2$: Gaussian Reward Modeling for GUI Grounding", "authors": "Fei Tang,Zhangxuan Gu,Zhengxi Lu,Xuyang Liu,Shuheng Shen,Changhua Meng,Wen Wang,Wenqi Zhang,Yongliang Shen,Weiming Lu,Jun Xiao,Yueting Zhuang", "background": "GUI用户界面接地将自然语言指令定位到精确的界面位置，以实现自主交互。目前的强化学习方法使用二元奖励，这将界面元素视为命中或未命中目标，创建稀疏信号，忽略了空间交互的连续性。受人类点击行为自然形成以目标元素为中心的高斯分布的启发，引入了GUI的高斯接地奖励（GUI-G$^2$），用于建模界面元素在界面平面上以连续的高斯分布形式出现的一种原理性的奖励框架。", "innovation": "引入了GUI-G$^2$，一种建模界面元素为整个界面平面上连续高斯分布的原理性奖励框架。设计了两个协同机制：高斯点奖励通过以元素质心为中心的指数衰减分布建模精确定位；覆盖奖励通过测量预测高斯分布与目标区域之间的重叠来评估空间对齐。提出了自适应方差机制，根据元素尺寸校准奖励分布，将GUI接地问题从稀疏的二分类问题转化为密集的连续优化问题。", "conclusion": "在ScreenSpot、ScreenSpot-v2和ScreenSpot-Pro基准测试中，GUI-G$^2$显著优于现有技术UI-TARS-72B，尤其在ScreenSpot-Pro上的改进幅度达到了24.7%。通过分析发现，连续建模能够提供针对界面变化的更强健性以及对未见过的布局有更好的泛化性，确立了GUI交互任务中空间推理的新范式。"}
{"llm_update_time": "20250723", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.16039", "html_url": "https://arxiv.org/abs/2507.16039", "title": "重新激活：任务转变下的经验NTK动态", "title_en": "Reactivation: Empirical NTK Dynamics Under Task Shifts", "authors": "Yuzhi Liu,Zixuan Chen,Zirui Zhang,Yufei Liu,Giulia Lanzillotta", "background": "神经核（NTK）提供了一个强大的工具来研究神经网络的功能动态。在所谓的惰性或核范式中，NTK在训练过程中保持不变，网络的功能在静态的神经核特征空间中是线性的。NTK动态的变化对于特征学习至关重要，这是深度学习成功的关键驱动力。关于NTK动态的研究在过去几年中取得了几个重要的发现，包括泛化和扩展行为。然而，这些研究主要针对单任务设置，假设数据分布随着时间的推移保持不变。本研究旨在探讨在任务转变的持续学习场景下NTK动态的变化，这种场景中数据分布随时间变化。研究发现，持续学习是一个富有成效但被忽视的测试床，可用于探究神经网络训练的动态。同时，这些发现质疑了在持续学习的理论分析中应用静态核近似的有效性，即使是在大规模场景中也如此。", "innovation": "本研究通过实证方法全面分析了在任务变化情况下NTK动态的表现，这填补了现有研究在数据分布随时间变化场景下的空白。", "conclusion": "持续学习数据分布随时间变化下NTK动态的变化揭示了持续学习作为研究神经训练动态的有效但尚未充分利用的平台。这些发现也挑战了在理论分析中使用静态核近似模型的有效性，即使在大规模场景中也是如此。"}
{"llm_update_time": "20250723", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.16008", "html_url": "https://arxiv.org/abs/2507.16008", "title": "通过鞍点重写增强物理指导神经网络训练的稳定性", "title_en": "Enhancing Stability of Physics-Informed Neural Network Training Through Saddle-Point Reformulation", "authors": "Dmitry Bylinkin,Mikhail Aleksandrov,Savelii Chezhegov,Aleksandr Beznosikov", "background": "物理指导神经网络（PINNs）近年来取得了重要进展，已在多种应用中有效使用。但由于损失函数复杂多变，其性能依然不够稳定。", "innovation": "将PINN训练重新表述为非凸强凸鞍点问题，并在理论基础上进行了广泛的实验研究，验证其在各种任务和架构中的有效性。", "conclusion": "实验结果显示，所提出的方法在效果上超过了当前最先进的技术。"}
{"llm_update_time": "20250723", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.16079", "html_url": "https://arxiv.org/abs/2507.16079", "title": "Ternary ReLU回归神经网络线性区域下界", "title_en": "A Lower Bound for the Number of Linear Regions of Ternary ReLU Regression Neural Networks", "authors": "Yuta Nakahara,Manabu Kobayashi,Toshiyasu Matsushima", "background": "随着深度学习的进步，降低计算复杂度和内存消耗已成为关键挑战。三元神经网络（NNs），其参数限制在{-1, 0, +1}，因其在图像识别和自然语言处理等实际应用中的出色性能而引起关注。然而，关于三元NNs的理论理解仍然不足。因此，本文从线性区域的数量角度对三元NNs的表达能力进行了理论分析，特别是评估了带ReLU激活函数的三元回归NNs的线性区域数量，证明了其线性区域数量相对于网络宽度呈多项式增长，相对于深度呈指数增长，与标准NNs类似。这为三元NNs的实践成功提供了一种理论解释，但其理论理解仍需进一步深化.", "innovation": "本文首次从线性区域数量的角度对三元NNs进行了理论分析，证明了三元ReLU回归NNs的线性区域数量增长模式，相较于网络宽度为多项式，相较于深度为指数。还表明只需将宽度平方或深度翻倍，即可使三元NNs达到与一般ReLU回归NNs相似的最大线性区域下界。这为理解三元NNs的表达能力提供了新的理论视角，有助于进一步优化网络结构和提升模型性能.", "conclusion": "通过分析证明，三元NNs的线性区域数量在深度和宽度上的增长模式与标准NNs相似，这在某种程度上解释了三元NNs的实践成功。并且，该研究为设计和优化三元NNs提供了一种新的理论依据。"}
{"llm_update_time": "20250723", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.16178", "html_url": "https://arxiv.org/abs/2507.16178", "title": "通过动态双层优化实现大语言模型数据选择与利用", "title_en": "LLM Data Selection and Utilization via Dynamic Bi-level Optimization", "authors": "Yang Yu,Kai Han,Hang Zhou,Yehui Tang,Kaiqi Huang,Yunhe Wang,Dacheng Tao", "background": "大规模训练数据对于开发强大的语言模型是基础，而策略性地选择高质量的数据已经成为提升训练效率和降低计算成本的关键方法。现有的数据选择方法主要依赖于静态、与训练无关的标准，未能考虑到模型训练中的动态数据交互。", "innovation": "本文提出了一种新的数据权重模型（DWM），可以在每次批次中动态调整选定数据的权重，以实现大语言模型（LLM）训练过程中的动态数据使用。通过实施一个双层优化框架，DWM能够更新权重模型以更好地捕捉训练模型的数据偏好。实验表明，DWM可以提升随机选择数据训练模型的性能，并且从中学到的权重模型可以转移到其他数据选择方法中，提升不同规模模型的表现。", "conclusion": "此外，我们还分析了模型在整个训练过程中的数据偏好如何变化，提供了关于训练过程中模型数据偏好的新见解。"}
{"llm_update_time": "20250723", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.15903", "html_url": "https://arxiv.org/abs/2507.15903", "title": "对于LLM赋能智能代理的幻觉缓解：逐步泛化边界探索与看门狗监控", "title_en": "Towards Mitigation of Hallucination for LLM-empowered Agents: Progressive Generalization Bound Exploration and Watchdog Monitor", "authors": "Siyuan Liu,Wenjing Liu,Zhiwei Xu,Xin Wang,Bo Chen,Tao Li", "background": "大语言模型（LLMs）赋予了智能代理与开放环境交互的能力，以促进AI部署。然而，LLMs生成的幻觉（输出与事实不符的结果）对智能代理的可信度构成了重大挑战。只有在能够缓解这些幻觉后，智能代理才可以在现实世界中安全使用，避免任何灾难性风险。因此，有效检测和缓解幻觉对于确保智能代理的可靠性至关重要。然而，现有的相关方法要么依赖于LLM的白盒访问，要么不能准确识别幻觉。", "innovation": "提出了一个名为HalMit的新颖的黑盒看门狗框架，该框架通过建模LLM赋能智能代理的泛化边界来检测幻觉，而无需了解LLM架构的内部知识。特别地，提出了一种概率分形采样技术来生成足够的查询以并行触发难以置信的响应，有效地识别目标代理的泛化边界。实验表明，HalMit在幻觉监控方面显著优于现有方法，其黑盒特性和出色的性能使其成为提升LLM驱动系统的可靠性的有希望的解决方案。", "conclusion": "HalMit显著提升了LLM代理系统的可靠性，其黑盒特性和卓越性能使其成为便于实际应用的有效解决方案。"}
{"llm_update_time": "20250723", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.15906", "html_url": "https://arxiv.org/abs/2507.15906", "title": "朝向可靠的、意识不确定性对齐", "title_en": "Towards Reliable, Uncertainty-Aware Alignment", "authors": "Debangshu Banerjee,Kintan Saha,Aditya Gopalan", "background": "大型语言模型（LLMs）通常通过在偏好数据上训练奖励模型，然后根据奖励模型进行策略优化来进行对齐。然而，仅根据单个奖励模型的估计进行策略优化会使其容易受到奖励模型不准确的影响。本文通过实证研究开源基准上的奖励模型训练差异，发现独立训练的奖励模型在相同的偏好数据集上可能会表现出显著的分歧，揭示了目前对齐策略的不稳定性。.", "innovation": "提出了一个新的策略正则化器来整合奖励模型的方差估计，并设计了一个具有方差意识的偏好对齐策略优化框架。这个框架证明可以降低输出劣于默认策略的风险。在不同LLM和奖励模型配置的实验中，验证了该方法比标准（无方差意识的）管道更稳定和稳健。", "conclusion": "我们提出的方法在不同LLM和奖励模型配置下的实验中，证实了对于基于偏好对齐，这种方法比标准流程更为稳定和可靠。"}
{"llm_update_time": "20250723", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.15977", "html_url": "https://arxiv.org/abs/2507.15977", "title": "Sparse Autoencoders在解释压缩模型中的可转移性", "title_en": "On the transferability of Sparse Autoencoders for interpreting compressed models", "authors": "Suchit Gupte,Vishnu Kabir Chhabra,Mohammad Mahdi Khalili", "background": "现代大型语言模型在推理效率方面面临挑战，由于它们的规模庞大。为了解决这个问题，许多压缩方法被提出，例如剪枝和量化。然而，这些压缩方法对模型解释性的影响尚未得到解答。虽然已有几种模型解释方法，但稀疏自编码器（SAEs）已被证明特别有效，能够将模型的激活空间分解为其特征基础。", "innovation": "本文探讨了在原始模型和压缩模型上训练的SAEs之间的差异。研究发现，尽管在性能上略有下降，但原始模型上训练的SAEs可以解释压缩模型。此外，直接对原始SAEs进行剪枝即可达到与在剪枝模型上训练新的SAEs相似的性能。这一发现使得可以降低SAEs的培训成本。", "conclusion": "这项工作证明了稀疏自编码器在解释压缩模型中的可转移性，并提出了一种通过直接剪枝原始SAEs来提高效率的新方法。"}
{"llm_update_time": "20250723", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.16186", "html_url": "https://arxiv.org/abs/2507.16186", "title": "EBaReT：专家引导的袋奖励变换器在自动出价中的应用", "title_en": "EBaReT: Expert-guided Bag Reward Transformer for Auto Bidding", "authors": "Kaiyuan Li,Pengyu Wang,Yunshan Peng,Pengjia Yuan,Yanxiang Zeng,Rui Xiang,Yanhua Cheng,Xialong Liu,Peng Jiang", "background": "传统的方法将自动出价视为马尔可夫决策过程(MDP)。最近的研究探索使用生成的强化学习方法来解决出价环境中长期依赖性的问题。尽管这些方法是有效的，但它们通常依赖于监督学习的方法，这些方法对数据质量很敏感，因为低质量的数据会导致次优出价和低概率奖励，从而导致点击率和转化率低。目前，很少有研究能够解决这些问题。因此，本文将自动出价问题形式化为序列决策问题，并提出了一种新颖的专家引导的袋奖励变换器(EBaReT)，以解决数据质量和不确定性奖励的问题。为了应对数据质量的问题，提出了生成专家轨迹作为辅助训练数据，采用正未标注(PU)学习判别器来识别专家转换。为了确保决策达到专家水平，进一步设计了专家引导的推理策略。为了减轻奖励的不确定性，考虑一定时期内的转换作为一个“袋”，精心设计了一个奖励函数，以更平滑地获取奖励。", "innovation": "提出了专家引导的袋奖励变换器(EBaReT)，以解决自动出价中的数据质量和不确定性奖励问题。具体包括：生成专家轨迹作为辅助训练数据；采用PU学习判别器识别专家转换；设计专家引导的推理策略；考虑一定时期的转换作为一个“袋”，精心设计奖励函数，以更平滑地获取奖励。该模型在广泛实验中证明了比最先进的出价方法有更优的表现。", "conclusion": "提出的EBaReT模型在解决自动出价中的数据质量和不确定性奖励方面表现出色，通过生成专家轨迹、PU学习判别器、专家引导的推理策略及精心设计的奖励函数，EBaReT在广泛的实验中证明优于最先进的出价方法。"}
{"llm_update_time": "20250723", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.16249", "html_url": "https://arxiv.org/abs/2507.16249", "title": "基于多智能体强化学习的样本高效深度神经网络映射", "title_en": "Multi-Agent Reinforcement Learning for Sample-Efficient Deep Neural Network Mapping", "authors": "Srivatsan Krishnan,Jason Jabbour,Dan Zhang,Natasha Jaques,Aleksandra Faust,Shayegan Omidshafiei,Vijay Janapa Reddi", "background": "深度神经网络（DNNs）在硬件上的映射对于优化延迟、能耗和资源利用率至关重要，成为高性能加速器设计的基础。然而，由于存在巨大的复杂搜索空间，尽管强化学习（RL）是一种有希望的方法，但其效果往往受到样本效率低下（样本效率有限）的限制。", "innovation": "提出了一个去中心化的多智能体强化学习（MARL）框架，通过分散搜索任务，加速探索过程。在此基础上，引入了一种基于相关性分析的智能体聚类算法，将具有相似映射参数的智能体分配到同一个智能体中，从而实现去中心化的并行学习过程，显著提高了样本效率。实验结果表明，与标准单智能体RL相比，该MARL方法的样本效率提高了30到300倍，在相同的样本条件下达到了32.61倍的延迟降低和16.45倍的能效比降低。", "conclusion": "所提出的MARL框架在样本效率方面取得了显著改进，应用于DNN映射任务中，不仅提高了加速器设计的效率，同时也优化了性能和能耗。"}
{"llm_update_time": "20250723", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.16302", "html_url": "https://arxiv.org/abs/2507.16302", "title": "针对扩散模型下游微调的稳健安全驱动型遗忘方法", "title_en": "Towards Resilient Safety-driven Unlearning for Diffusion Models against Downstream Fine-tuning", "authors": "Boheng Li,Renjie Gu,Junjie Wang,Leyi Qi,Yiming Li,Run Wang,Zhan Qin,Tianwei Zhang", "background": "文本到图像（T2I）扩散模型已经取得了令人印象深刻的图像生成质量，并且正在越来越多地针对个性化应用进行微调。然而，这些模型往往从有毒的预训练数据中继承了不安全的行为，引发了日益增长的安全担忧。尽管最近的安全驱动式遗忘方法在抑制模型毒性和表现出有希望的进步，但被发现对下游微调非常脆弱，在仅使用完全无害的数据集进行下游微调时，这些方法的最先进方法仍然无法保持其有效性。", "innovation": "本文提出了一种增强抵御下游微调的安全驱动型遗忘框架ResAlign。通过使用Moreau Envelope基于的重新表述将下游微调建模为一个隐式优化问题，ResAlign能够有效估计梯度以最小化有害行为的恢复。此外，还提出了一种元学习策略，以模拟多种多样的微调场景，从而提高泛化性能。实验结果表明，ResAlign在保持安全性的同时，能够更有效地保留良性生成能力，而优于先前的遗忘方法。", "conclusion": "通过广泛的实验，在多种数据集、微调方法和配置中，ResAlign始终表现出色，能够更好地保持在下游微调后安全性和保留良好的良性生成能力，解决了现有方法在面对下游微调时的脆弱性问题。"}
{"llm_update_time": "20250723", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.15884", "html_url": "https://arxiv.org/abs/2507.15884", "title": "智能提示，降低成本：针对实际应用的成本意识自动提示优化", "title_en": "Prompt Smart, Pay Less: Cost-Aware APO for Real-World Applications", "authors": "Jayesh Choudhari,Piyush Kumar Singh,Douglas McIlwraith,Snehal Nair", "background": "提示设计是大型语言模型（LLMs）效果的关键因素，但依然主要依靠经验和手动操作，难以规模化应用。现有文献中大多数自动提示优化（APO）框架仅在有限复杂性的基准分类任务中得到验证，而在现实中的高风险多分类商业场景中鲜有研究。", "innovation": "本文提出了一种名为APE-OPRO的新型混合框架，结合了APE和OPRO的互补优势，实现了成本效益显著提高，与OPRO相比约提高了18%的成本效率，同时未牺牲性能。此外，研究还对比了非梯度（APE和OPRO）和基于梯度（ProTeGi）的方法，特别是在实际应用的数据集上表现出了关键权衡：ProTeGi在较低API成本下提供了最强的整体性能，但计算时间较长；而APE-OPRO在性能、API效率和可扩展性之间取得了较好的平衡。", "conclusion": "研究结果强调了一些关键权衡，并发现标签格式化对模型表现有显著影响，这也暗示了LLM行为的隐含敏感性。因此，这些发现为实际应用中的APO实施提供了可操作的见解，并为未来研究多标签、视觉、多模态提示优化奠定了基础。"}
{"llm_update_time": "20250723", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.16278", "html_url": "https://arxiv.org/abs/2507.16278", "title": "理解低容量神经网络中的泛化、鲁棒性和可解释性", "title_en": "Understanding Generalization, Robustness, and Interpretability in Low-Capacity Neural Networks", "authors": "Yash Kumar", "background": "尽管现代深度学习通常依赖于超参数化的模型，但低容量网络中的容量、稀疏性和鲁棒性之间的基本相互作用仍然是研究的重点。本文通过从MNIST数据集创建一系列逐渐增加视觉难度的二分类任务，来研究这些特性。实验结果显示低容量网络成功泛化的最小模型容量与其任务复杂性成正比，经过训练的网络在极端剪枝（高达95%的稀疏性）时仍表现出色，表明存在稀疏且高性能的子网络，另外，过度参数化在网络对抗输入破坏时提供显著优势，进一步通过可解释性分析（如显著性映射）确认这些识别出的稀疏子网络保留了原始密集模型的核心推理过程。", "innovation": "本文提出了一种受控框架，创建了一系列增加视觉难度的二分类任务。实验揭示了三个核心发现：1. 成功泛化的最小模型容量随任务复杂性线性增加；2. 经过训练的网络在极端剪枝后仍表现出色，表明存在稀疏且高性能的子网络；3. 过度参数化在网络对抗输入破坏时提供了显著优势；4. 稀疏子网络保留了原始密集模型的核心推理过程的证据通过可解释性分析提供。", "conclusion": "本研究提供了简单神经网络中基本权衡关系的清晰、经验性演示。"}
{"llm_update_time": "20250723", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.16099", "html_url": "https://arxiv.org/abs/2507.16099", "title": "TorchAO: PyTorch-Native Training-to-Serving Model Optimization", "title_en": "TorchAO: PyTorch-Native Training-to-Serving Model Optimization", "authors": "Andrew Or,Apurva Jain,Daniel Vega-Myhre,Jesse Cai,Charles David Hernandez,Zhenrui Zheng,Driss Guessous,Vasiliy Kuznetsov,Christian Puhrsch,Mark Saroufim,Supriya Rao,Thien Tran,Aleksandar Samardžić", "background": "TorchAO 是一个利用量化和稀疏性来优化 PyTorch 模型性能的框架，提供了从模型训练到部署的全流程解决方案。该框架支持多种模型优化技术，如 FP8 量化训练、量化感知训练（QAT）、后训练量化（PTQ）以及 2:4 稀疏处理，并引入了新型张量子类抽象以表示多种底层无关的低精度数据类型。TorchAO 与广泛使用的生态系统的多个组件紧密集成，包括预训练、微调和部署阶段。", "innovation": "TorchAO 的创新之处在于它是一个 PyTorch 原生的方法，实现了从训练到服务的全流程优化。该框架不仅支持多种模型优化技术，还通过引入新型张量子类抽象，更好地表示低精度数据类型，增强了模型的灵活性和适用性。", "conclusion": "TorchAO 通过无缝集成到广泛的生态系统中，实现了从预训练到部署的优化过程中的各个方面，并且已经成功应用于多种模型的优化，例如量化后的 Llama 3.2 1B/3B 和 LlamaGuard3-8B 模型。该框架是开源的，公开可访问。"}
{"llm_update_time": "20250723", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.16380", "html_url": "https://arxiv.org/abs/2507.16380", "title": "无过参数化情形下的两层物理知情神经网络的优化与泛化分析", "title_en": "Optimization and generalization analysis for two-layer physics-informed neural networks without over-parametrization", "authors": "Zhihan Zeng,Yiqi Gu", "background": "以往的研究主要基于过参数化的情况，但这种情况下网络宽度需要随训练样本数量大幅增加，导致计算成本高且不切实际。", "innovation": "本文对两层物理知情神经网络（PINNs）进行了新的优化和泛化分析，提出了确保训练损失和期望损失降至O(ε)以下的前提条件，无需过参数化。", "conclusion": "如果网络宽度超过特定阈值（仅依赖于ε和问题），那么训练损失和期望损失将低于O(ε)。"}
{"llm_update_time": "20250723", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.16148", "html_url": "https://arxiv.org/abs/2507.16148", "title": "利用操作学习学习阿尔茨海默病进展中的患者特异性空间生物标记物动力学", "title_en": "Learning Patient-Specific Spatial Biomarker Dynamics via Operator Learning for Alzheimer's Disease Progression", "authors": "Jindong Wang,Yutong Mao,Xiao Liu,Wenrui Hao", "background": "阿尔茨海默病（AD）是一种复杂的多因素神经退行性疾病，具有较大的异质性。尽管最近有治疗进展，但能够准确预测个体疾病轨迹的预测模型仍然有限。", "innovation": "提出了一种基于机器学习的操作学习框架，用于个性化建模AD进展，整合纵向多模态影像学、生物标志物和临床数据。不同寻常地，该方法直接学习患者特异性疾病操作符，以管理淀粉样蛋白、tau和神经退化生物标志物的时空演变。利用Laplacian特征函数基，构建了几何意识神经操作符，以捕捉复杂的脑动力学。嵌入数字孪生框架中，该架构可实现个性化预测、治疗干预的模拟及临床试验的在硅实施。", "conclusion": "该方法在AD临床数据上的预测准确率超过90%，在多个生物标志物上显著优于现有方法。这项工作提供了一个可扩展、可解释的平台，用于精确建模和个性化治疗优化，以应对神经退行性疾病。"}
{"llm_update_time": "20250723", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.16307", "html_url": "https://arxiv.org/abs/2507.16307", "title": "Perovskite-R1：一种专用于前驱体添加剂智能发现和实验设计的领域特定LLM", "title_en": "Perovskite-R1: A Domain-Specialized LLM for Intelligent Discovery of Precursor Additives and Experimental Design", "authors": "Xin-De Wang,Zhi-Rui Chen,Peng-Jie Guo,Ze-Feng Gao,Cheng Mu,Zhong-Yi Lu", "background": "钙钛矿太阳能电池（PSCs）以优异的光电转换效率和材料特性迅速成为下一代光伏技术的领先候选者。尽管取得了这些进步，长时稳定性、环境可持续性和可扩展制造等问题仍然阻碍其商业化。前驱体添加剂工程通过增强PSC的性能和耐用性展现出了潜力，但由于材料、过程和设备架构之间的复杂交互作用，科学文献的快速增长使得研究人员难以有效地访问、组织和利用领域的知识。为解决此问题，我们引入了Perovskite-R1，一种专门针对PSC前驱体添加剂发现和设计的高级推理能力大语言模型（LLM）。通过系统地挖掘和筛选1,232篇高质量的科学出版物，整合一个包含33,269种候选材料的全面数据库，并利用自动问答生成和推理链，我们构建了一个特定领域的指令微调数据集。对QwQ-32B模型进行微调后得到了Perovskite-R1，它能够智能地综合文献洞察并生成创新的、实用的解决方案以钝化缺陷和选择前驱体添加剂。实验验证了几种模型提出的策略的有效性，确认它们对于提高材料稳定性和性能的改进效果。我们的工作展示了领域适配的LLM在加速材料发现方面的潜力，并提供了一种智能的数据驱动闭环框架，用于推进钙钛矿光伏研究的进步。", "innovation": "Perovskite-R1是一种专门针对PSC前驱体添加剂发现和设计的高级推理能力大语言模型，通过系统地挖掘和筛选高质量的科学出版物，整合全面的材料数据库来构建一个特定领域的微调数据集，最终实现智能而实用的解决方案的生成。它能够通过智能总结文献并生成创新策略来提高材料稳定性和性能，验证证明了其有效性。", "conclusion": "我们的研究证实了领域适配大语言模型在加速材料发现方面的潜力，并提供了一种智能的数据驱动闭环框架，用于推动钙钛矿光伏研究的进步，并为钙钛矿太阳能电池的商业化提供了新的方法。"}
{"llm_update_time": "20250723", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.16347", "html_url": "https://arxiv.org/abs/2507.16347", "title": "利用个性化PageRank和高阶拓扑结构在图神经网络中缓解异构性", "title_en": "Leveraging Personalized PageRank and Higher-Order Topological Structures for Heterophily Mitigation in Graph Neural Networks", "authors": "Yumeng Wang,Zengyi Wo,Wenjun Wang,Xingcheng Fu,Minglai Shao", "background": "图神经网络（GNNs）在节点分类任务中表现出色，但通常假设同构性，即连接的节点具有相似的标签。然而，在许多现实世界的异构图中，这种假设不成立。现有的异构图模型主要依赖于成对关系，忽略了高级结构中的多尺度信息，导致在噪声干扰下表现不佳。特别是在节点间的冲突类别信息存在时，性能尤为差。", "innovation": "本文提出了一种新的模型HPGNN，该模型结合高阶个性化PageRank与图神经网络。HPGNN通过引入高阶个性化PageRank（PPR）的高效近似来捕捉长距离和多尺度的节点交互，从而减少计算复杂性和噪声影响。通过将高阶结构信息嵌入卷积网络，HPGNN可以有效建模不同图维度之间的关键交互。", "conclusion": "实验结果表明，HPGNN在异构图的下游任务中优于五种最先进的方法，并且在同构图中保持了竞争力。该模型能够平衡多尺度信息，并且对噪声具有鲁棒性，因此成为一个适用于实际图学习挑战的通用解决方案。相关代码可在以下网址获得：this https URL"}
{"llm_update_time": "20250723", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.16345", "html_url": "https://arxiv.org/abs/2507.16345", "title": "压缩的成本：用于$\boldsymbol{\boldsymbol{\boldsymbol{\\ell_2}}}$范数估计的黑盒攻击的紧致二次攻击", "title_en": "The Cost of Compression: Tight Quadratic Black-Box Attacks on Sketches for $\\ell_2$ Norm Estimation", "authors": "Sara Ahmadian,Edith Cohen,Uri Stemmer", "background": "线性绘制是一种强大而广泛使用的降维技术，但它已知对对抗输入是脆弱的。本文研究了固定且隐藏的标量矩阵A将在R^n中的高维向量v映射到较低维度的草图Av的黑盒对抗设置。对手可以查询系统以获取计算草图的$\boldsymbol{\\ell_2}$范数近似估计。", "innovation": "本文提出了一个通用的、非适应性的攻击，仅使用$\tilde{O}(k^2)$个查询，要么导致范数估计失败，要么构造出使其攻击使用的查询分布的最佳估计器失效的对抗输入。此攻击完全独立于草图矩阵和估计器：适用于任何线性草图和任何查询响应器，包括随机化、适应用或针对查询分布定制的响应器。此结果表明，尽管之前有专门的估计器已经证明了$\tilde{\\Omega}(k^2)$的上限，但此攻击紧随之所为。此外，该研究揭示了图像分类中对抗攻击的结构类比，突显了压缩表示的固有漏洞。", "conclusion": "本文的攻击结果紧密匹配已知的$\tilde{\\Omega}(k^2)$上限，此上限由用于约翰逊-林德斯特拉姆变换和AMS草图的专门估计器所实现。除草图外，本文的结果揭示了图像分类中对抗攻击的结构类比，突显了压缩表示的固有漏洞。"}
{"llm_update_time": "20250723", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.16274", "html_url": "https://arxiv.org/abs/2507.16274", "title": "通过时空规划减少GPU内存碎片以实现高效大规模模型训练", "title_en": "Reducing GPU Memory Fragmentation via Spatio-Temporal Planning for Efficient Large-Scale Model Training", "authors": "Zixiao Huang,Junhao Hu,Hao Lin,Chunyang Zhu,Yueran Tang,Quanlu Zhang,Zhen Guo,Zhenhua Li,Shengen Yan,Zhenhua Zhu,Guohao Dai,Yu Wang", "background": "大型语言模型（LLMs）的快速增长显著增加了GPU内存压力，训练优化技术如虚拟流水线和重计算加剧了这一问题。这些技术破坏了张量的生命周期并引入了大量内存碎片。流行的深度学习框架（如PyTorch）的默认GPU内存分配器使用在线策略，而这些策略缺乏对张量生命周期的认知，可能导致最多43%的内存浪费，并引发内存溢出错误，从而使得优化技术无效甚至无法使用。", "innovation": "本文介绍了一种名为STWeaver的GPU内存分配器，它结合了时空规划的离线计划与在线分配，减少内存碎片。STWeaver能够在不影响性能的情况下显著减少碎片，适用于密集和稀疏模型。这使得更高效、高吞吐量的训练配置得以实现，并能将性能提高多达32.5%。", "conclusion": "STWeaver实现了内存分配的高效管理，显著减少了内存碎片，尤其是在大规模模型训练中，提高了性能和训练效率，减少了内存浪费和内存溢出的风险。"}
{"llm_update_time": "20250723", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.16497", "html_url": "https://arxiv.org/abs/2507.16497", "title": "通过典范相关模式验证多元时间序列聚类", "title_en": "Canonical Correlation Patterns for Validating Clustering of Multivariate Time Series", "authors": "Isabella Degen,Zahraa S Abdallah,Kate Robson Brown,Henry W J Reeve", "background": "现有研究使用基于相关性的方法对多元时间序列进行聚类，揭示了变量间关系的变化模式。然而，如何验证这些聚类是否代表真实的关系，而非随机分组，仍旧是一个关键挑战。虽然已有适用于欧几里得数据的聚类有效性指标，但对于相关模式的有效性却未进行全面评估。与基于欧几里得聚类相比，相关性存在于连续空间，缺乏明确的参考模式，因此需要新的方法进行验证.", "innovation": "本文引入了典范相关模式作为数学定义的验证目标，将无限的相关空间离散化成有限、可解释的参考模式。通过合成数据集，在受控条件下验证了这些模式的有效性，并展示了L1范数、L5范数和Davies-Bouldin指数在映射和轮廓宽度标准方面的优越性能。这些方法对于分布转移具有鲁棒性，能够检测相关结构的降解，从而提供实际实施指南.", "conclusion": "本文为高风险应用场景中的相关性聚类验证提供了方法论基础，通过方法验证确保了聚类分析结果的可靠性，从而在健康、金融和工业等领域得到广泛应用."}
{"llm_update_time": "20250723", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.16533", "html_url": "https://arxiv.org/abs/2507.16533", "title": "confopt: 一种用于实现和评估基于梯度的元学习NAS方法的库", "title_en": "confopt: A Library for Implementation and Evaluation of Gradient-based One-Shot NAS Methods", "authors": "Abhash Kumar Jha,Shakiba Moradian,Arjun Krishnakumar,Martin Rapp,Frank Hutter", "background": "基于梯度的元学习神经架构搜索（NAS）方法显著降低了探索具有离散设计选择（例如模型内操作的选择）的架构空间的成本。然而，该领域面临两大挑战：首先，基于梯度的NAS方法的评估高度依赖于DARTS基准测试，尽管存在其他可选的基准测试；其次，这些方法的实现分散在不同的代码库中，这使得公平且可重复的比较和进一步发展变得困难。", "innovation": "我们提出了Configurable Optimizer（confopt），这是一个扩展库，旨在简化基于梯度的元学习NAS方法的开发和评估过程。confopt提供了一个简单的API，方便用户集成新的搜索空间，并支持NAS优化器的分解为基本组件。此外，论文利用该框架创建了新的DARTS基准测试套件，并结合了新的评估协议，揭示了当前基于梯度的元学习NAS方法的评估中存在的关键缺陷。", "conclusion": "我们通过创建新的DARTS基准测试和引入confopt库，展示了一种改进基于梯度的元学习NAS方法评估的方法，并发现了其评估过程中的关键问题。"}
{"llm_update_time": "20250723", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.16206", "html_url": "https://arxiv.org/abs/2507.16206", "title": "METER: 多模态证据推理和可解释推理——算法和基准", "title_en": "METER: Multi-modal Evidence-based Thinking and Explainable Reasoning -- Algorithm and Benchmark", "authors": "Xu Yang,Qi Zhang,Shuming Jiang,Yaowen Xu,Zhaofan Zou,Hao Sun,Xuelong Li", "background": "随着生成式AI的迅速发展，合成的内容在图像、视频和音频方面的逼真度日益增强，增加了虚假信息的风险。现有的检测方法主要集中在二元分类上，缺乏关于伪造的详细和可解释的解释，限制了其在关键安全场景中的应用。此外，当前方法通常单独处理每种模态，缺乏统一的跨模态伪造检测和解释基准。", "innovation": "为了应对这些挑战，该论文引入了METER，一个统一的多模态基准，覆盖图像、视频、音频和视听内容的可解释伪造检测。METER包含四个轨道，每个轨道不仅需要真实与虚假的分类，还需要基于证据链的解释，包括时空定位、文本理据和伪造类型追踪。相比之前的基准，METER提供了更广泛模态覆盖和更丰富的可解释性指标，如空间/时间IoU、多类追踪和证据一致性。我们还提出了一种与人类对齐的三阶段链式思维（CoT）训练策略，结合了SFT、DPO以及一个新型的GRPO阶段，其中包括了一个与CoT推理结合的人类对齐的评估器。", "conclusion": "我们希望METER能作为标准化的基础，推进生成媒体时代的可迁移和可解释伪造检测的进步。"}
{"llm_update_time": "20250723", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.16541", "html_url": "https://arxiv.org/abs/2507.16541", "title": "联邦图学习的全面数据中心概述", "title_en": "A Comprehensive Data-centric Overview of Federated Graph Learning", "authors": "Zhengyu Wu,Xunkai Li,Yinlin Zhu,Zekai Chen,Guochen Yan,Yanyu Yan,Hao Zhang,Yuming Ai,Xinmo Jin,Rong-Hua Li,Guoren Wang", "background": "在大数据应用时代，联邦图学习（FGL）已成为一种能够调和分散数据持有者之间集体智能优化与敏感信息保护之间权衡的重要解决方案。现有研究虽有一定贡献，但主要集中在联邦学习（FL）和图机器学习（GML）的整合上，形成了侧重方法和模拟场景的早期分类体系。然而，缺乏一种以数据为中心的角度进行重新组织FGL研究的方法，这种视角能够系统地通过数据属性和用途来审视FGL方法，这对于评估这些研究如何有效应对数据中心约束，增强模型性能至关重要。", "innovation": "本文提出了一种两层数据为中心的分类体系：数据特性，用于根据用于FGL的数据集的结构和分布属性来分类研究；数据利用，分析克服关键数据中心难题的训练程序和技术。每层分类由三个正交标准定义，每个标准代表一种不同的数据中心配置。此外，本文还探讨了FGL与预训练大型模型的集成、展示了实际应用场景，并提出了与图机器学习新兴趋势相一致的未来发展方向", "conclusion": "本文提供了一种全面的数据中心视角来审视FGL，通过提出新的分类体系来填补当前研究中的空白，并对未来的研究方向进行了展望。"}
{"llm_update_time": "20250723", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.16419", "html_url": "https://arxiv.org/abs/2507.16419", "title": "使用开源合成数据上取样提高高度不平衡数据的预测", "title_en": "Improving Predictions on Highly Unbalanced Data Using Open Source Synthetic Data Upsampling", "authors": "Ivona Krchova,Michael Platzer,Paul Tiwald", "background": "不平衡的数据集在多种应用中对预测建模和数据分析构成了重大挑战。例如，在欺诈检测、医疗诊断和稀有事件预测中，少数类往往严重不足，导致传统机器学习算法难以达到高精度。这些算法倾向于偏好多数类，从而导致偏向的模型难以准确地表示少数类。", "innovation": "该论文提出了一项基准研究，探讨如何使用AI生成的合成数据进行上取样以处理高度不平衡的表格数据集。研究利用MOSTLY AI提供的开源解决方案—合成数据SDK，评估了合成数据的有效性，与标准方法（如简单的上采样和SMOTE-NC）进行了对比。研究证明，合成数据可以在生成填充特征空间稀疏区域的多样数据点时改进少数群体的预测准确性。", "conclusion": "研究表明，使用合成数据进行上取样的一致生成性能最高的预测模型，特别是在含有极少数样本的混合类型数据集中更为显著。"}
{"llm_update_time": "20250723", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.16511", "html_url": "https://arxiv.org/abs/2507.16511", "title": "将类比推理理解为折旧化模型构建", "title_en": "Analogy making as amortised model construction", "authors": "David G. Nagy,Tingke Shen,Hanqi Zhou,Charley M. Wu,Peter Dayan", "background": "人类能够灵活构建内部模型以适应未见过的情况。这些内部模型需要足够真实反映环境，以确保基于有限资源的计划能产生良好的结果。同样，构建这些模型本身也应该是可行的。论文指出，类比在这一过程中发挥关键作用，使智能体能够重用过去经验中与解决方案相关的结构，从而减轻模型构建和计划的计算成本。", "innovation": "作者将类比定义为马尔可夫决策过程之间的部分同构，提出了一种框架，其中从以前的构建过程中衍生出的抽象模块作为新模块的可组合构建块。这种模块化重用机制允许在具有共同结构要旨的不同领域中灵活调整策略和表示。", "conclusion": "该研究表明，通过将类比推理理解为模型构建过程的折旧化，智能体能够更高效地重用先前的经验和结构，从而增强其适应新环境的能力。"}
{"llm_update_time": "20250723", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.16363", "html_url": "https://arxiv.org/abs/2507.16363", "title": "患有事件条件模型的两部位患者-模态图学习及在癌症生存预测中的应用", "title_en": "Bipartite Patient-Modality Graph Learning with Event-Conditional Modelling of Censoring for Cancer Survival Prediction", "authors": "Hailin Yue,Hulin Kuang,Jin Liu,Junjian Li,Lanlan Wang,Mengshen He,Jianxin Wang", "background": "癌症患者生存预测的准确度对于个性化治疗至关重要。现有研究主要关注具有已知生存风险样本之间的关系，未能充分利用被截尾的样本的价值。此外，在模态缺失情况下，现有研究可能表现不佳，并且在推断过程中面临挑战。", "innovation": "提出了两部位患者-模态图学习和事件条件截尾建模的方法（CenSurv），以克服现有方法的缺陷。首先，通过图结构来建模多模态数据并获得表示；其次，设计了一个两部位图来模拟各种模态缺失情况下的患者-模态关系，并通过完整-不完整对齐策略探索模态无关特征；最后，设计了插即用的事件条件截尾建模（ECMC），以动态累积置信机制选择可靠的被截尾数据，为其分配更准确的生存时间，并将其作为未截尾数据纳入训练。", "conclusion": "在5个公开癌症数据集上的综合评估表明，CenSurv在平均C指标方面优于当前最优状态的最高的3.1%，且在各种模态缺失情况下表现出色。此外，使用插即用的ECMC模块，5个基线的平均C指标在5个数据集上分别提高了1.3%。CenSurv的代码可在以下链接找到：this https URL"}
{"llm_update_time": "20250723", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.16569", "html_url": "https://arxiv.org/abs/2507.16569", "title": "细胞复杂网络族最优传输核", "title_en": "Families of Optimal Transport Kernels for Cell Complexes", "authors": "Rahul Khorana", "background": "最近对于细胞复形作为理想的机器学习表示的研究有了显著进展。然而，现有的机器学习方法尚不适用于细胞复形（CW复形）上的学习。在CW复形上的信号分布之间的Wasserstein距离缺乏明确的表达式。", "innovation": "本文推导出了CW复形信号分布之间的Wasserstein距离的明确表达式，该表达式基于Hodge-Laplacian矩阵。由此得到了一个结构上有意义的度量来比较CW复形，并定义最优传输图。为同时包括特征和结构信息，本文将Fused Gromov-Wasserstein距离扩展到了CW复形上。最后，基于最优传输的对偶形式，引入了新型的CW复形上概率测度空间上的核函数。", "conclusion": "本文提出了针对细胞复杂网络的新颖核函数，并通过Wasserstein距离和Hodge-Laplacian矩阵提供了结构信息和特征信息的同时学习方法。"}
{"llm_update_time": "20250723", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.16450", "html_url": "https://arxiv.org/abs/2507.16450", "title": "RIS辅助的潜在空间对齐用于语义信道均衡", "title_en": "RIS-aided Latent Space Alignment for Semantic Channel Equalization", "authors": "Tomás Hüttebräucker,Mario Edoardo Pandolfo,Simone Fiorellino,Emilio Calvanese Strinati,Paolo Di Lorenzo", "background": "语义通信系统通过直接从数据中学习和编码意图意义，而不仅仅是保证严格的位级准确性，引入了无线通信的新范式。这些系统经常依赖深度神经网络(DNNs)来实现这一点，从而实现更高效的通信。然而，在多用户设置中，独立训练的交互代理（缺少共享上下文或联合优化）会导致AI原设备之间的潜空间表示发散，从而导致语义不匹配，即使在没有传统传输错误的情况下也妨碍了相互理解。", "innovation": "本文提出了一种由重新配置智能表面(RIS)辅助的物理和语义信道联合均衡框架，该框架旨在解决多输入多输出(MIMO)信道中的语义不匹配问题。具体方法包括预均衡阶段的语义均衡、协助通道中的传输和接收端的后均衡阶段。我们将其问题描述为最小均方误差(MMSE)优化，并提出了两个解决方案：(i) 线性语义均衡链，(ii) 基于DNN的非线性语义均衡器。两种方法均设计为在潜在空间语义压缩和传输功率约束条件下运行。", "conclusion": "通过广泛的评估，我们展示了提出的联合均衡策略在各种场景和无线信道条件下始终优于传统的分离的物理和语义信道均衡方法。"}
{"llm_update_time": "20250723", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.16537", "html_url": "https://arxiv.org/abs/2507.16537", "title": "符号图智能：Tsetlin机器中的超向量消息传递学习图级模式", "title_en": "Symbolic Graph Intelligence: Hypervector Message Passing for Learning Graph-Level Patterns with Tsetlin Machines", "authors": "Christian D. Blakely", "background": "该论文提出了一种利用稀疏二元超向量和Tsetlin机器的多层符号框架，用于一般图分类。背景在于传统图神经网络虽然在图数据处理中表现出色，但往往缺乏符号透明性和可解释性。", "innovation": "提出了一种新颖的方法，通过结构化消息传递将节点、边和属性信息捆绑为符号超向量，从而构成层次化的符号表示，保持图的层次语义。同时，该方法还提供了一种局部可解释性框架，使得方法在局部具有明显的透明优势。", "conclusion": "通过在TUDataset基准测试集上的验证，该方法达到了与神经图模型相当的准确率，同时保持了强大的符号透明性。"}
{"llm_update_time": "20250723", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.16200", "html_url": "https://arxiv.org/abs/2507.16200", "title": "RealBench: 以真实世界IP设计评估Verilog生成模型", "title_en": "RealBench: Benchmarking Verilog Generation Models with Real-World IP Designs", "authors": "Pengwei Jin,Di Huang,Chongxiao Li,Shuyao Cheng,Yang Zhao,Xinyao Zheng,Jiaguo Zhu,Shuyi Xing,Bohan Dou,Rui Zhang,Zidong Du,Qi Guo,Xing Hu", "background": "在硬件设计自动化中，使用大型语言模型（LLMs）自动生成Verilog代码引起了广泛关注。然而，现有的Verilog生成评估基准在模拟真实设计工作流程方面存在不足，因为这些基准中的设计过于简单，设计规范不完整，验证环境也不够严格。", "innovation": "我们提出了RealBench，这是第一个针对真实世界IP级别的Verilog生成任务的基准。RealBench包含复杂的、结构化的开源IP设计、多模态和格式化的设计规范、以及严格的验证环境，包括100%行覆盖率测试模具和形式验证工具。该基准支持模块级和系统级任务，可以全面评估LLM的能力。", "conclusion": "评估结果显示，即便是表现最佳的LLM（o1-preview），在模块级任务上的通过率仅为13.3%，系统级任务上完全没有通过，这突显出未来需要更强大的Verilog生成模型。基准已经开源。"}
{"llm_update_time": "20250723", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.16729", "html_url": "https://arxiv.org/abs/2507.16729", "title": "通过优化训练数据集提高模型分类效果", "title_en": "Improving Model Classification by Optimizing the Training Dataset", "authors": "Morad Tukan,Loay Mualem,Eitan Netzer,Liran Sigalat", "background": "在以数据为中心的人工智能时代，高质量的训练数据编目能力与模型设计一样重要。Coresets提供了一种原理上的数据减少方法，通过重要性抽样在大规模数据集上实现高效的机器学习。然而，传统的基于灵敏度的Coresets构建方法往往在优化分类性能指标（如F1分数）方面效率低下，而是侧重于损失近似优化。", "innovation": "本文提出了一套系统性框架，用于调整Coreset生成过程，以提高下游分类质量。该方法引入了新的可调参数，包括确定性抽样、类内分配以及通过主动抽样进行细化，超越了传统的灵敏度分数。通过在多样化的数据集和分类器上进行广泛的实验，证明了优化后的Coreset在关键分类指标上的表现优于原生Coreset和全数据集训练，为更高效高效的模型训练提供了有效途径。", "conclusion": "经过大量实验验证，优化后的Coreset在关键分类指标上显著优于原生Coreset和全数据集训练，提供了一种提高模型训练效率的有效途径。"}
{"llm_update_time": "20250723", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.16771", "html_url": "https://arxiv.org/abs/2507.16771", "title": "一种快速分布式空间建模的分区稀疏近似高斯过程", "title_en": "A Partitioned Sparse Variational Gaussian Process for Fast, Distributed Spatial Modeling", "authors": "Michael Grosskopf,Kellin Rumsey,Ayan Biswas,Earl Lawrence", "background": "下一代美国能源部超级计算机将具备exascale计算能力。这些机器的计算能力将远超过可存储在磁盘上的数据量。因此，用户将无法依赖事后访问数据进行不确定性量化和其他统计分析，迫切需要能够在就地训练的复杂机器学习算法。部署于此场景中的算法必须具备高度可扩展性、高效，并能够处理分布在节点间且为空间连续分区的数据。一种适合的方法是独立并行拟合稀疏近似高斯过程（SVGP）模型到每个空间分区。这种方法虽然高效、可扩展且通常准确，但由于相邻模型在共享边界处的分歧，会产生不连续的响应表面效应。", "innovation": "本文扩展了此思想，允许相邻空间分区之间进行少量通信，以鼓励相邻局部模型更好的对齐，从而提高空间预测的平滑度和整体贴合度。由于采用去中心化的通信方案，提出的扩展方法仍保持了高度可扩展性，且在计算上仅增加了少量开销（无额外内存开销）。本文通过分区稀疏近似高斯过程（PSVGP）方法对能源Exascale地球系统模型（E3SM）进行了应用，结果与独立SVGP方法进行了对比。", "conclusion": "本文提出了一种分区稀疏近似高斯过程（PSVGP）方法，通过允许相邻空间分区之间进行少量通信提高了模型间的对齐性，从而提高了空间预测的平滑度和整体拟合度。该方法保持了高度的可扩展性，并且在计算上和内存上几乎不增加额外开销。"}
{"llm_update_time": "20250723", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.16577", "html_url": "https://arxiv.org/abs/2507.16577", "title": "Sparse State Expansion for Scaling Linear Attention", "title_en": "Scaling Linear Attention with Sparse State Expansion", "authors": "Yuqi Pan,Yongqi An,Zheng Li,Yuhong Chou,Ruijie Zhu,Xiaohui Wang,Mingxuan Wang,Jinqiao Wang,Guoqi Li", "background": "尽管Transformer架构在广泛的应用中表现出色，但它在处理长上下文场景时却遇到困难，这是因为其计算复杂度为二次，内存增长为线性，这会导致效率低下。虽然有些以线性注意力为变体的方法通过压缩上下文到固定大小的状态来缓解这些效率限制，但这通常会降低在如上下文检索和推理等任务中的性能。因此，需要找到一种能够有效地压缩上下文并且保持高性能的方法。", "innovation": "为了克服这一限制，我们提出了两项关键创新。首先，我们通过信息分类的概念化将线性注意力的状态更新形式化为稀疏更新，引入了基于softmax的top-k硬分类，使得状态更新变得稀疏，并扩展了感受野，减少了类内干扰。其次，我们提出了在稀疏框架内的稀疏状态扩展（SSE），将上下文状态扩展为多个分区，有效地解耦参数大小与状态容量，同时保持稀疏分类范式。我们的设计通过有效的并行化实现，提供了高效的状态分类和区分性状态表示。", "conclusion": "我们对SSE在纯线性架构、混合架构以及语言建模、上下文检索和数学推理基准中的性能进行了广泛验证，结果表明SSE具有出色的检索性能，并且随状态大小的扩展表现较好。特别是，在强化学习培训后，我们的2B SSE-H模型在小型推理模型中达到了最先进的数学推理性能，得分分别为AIME24上的64.7和AIME25上的51.3，显著优于同规模的开源Transformer。这些结果表明SSE是一个有前景且高效的长上下文建模架构。"}
{"llm_update_time": "20250723", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.16680", "html_url": "https://arxiv.org/abs/2507.16680", "title": "AI原生MIMO语义通信中的潜在空间对齐", "title_en": "Latent Space Alignment for AI-Native MIMO Semantic Communications", "authors": "Mario Edoardo Pandolfo,Simone Fiorellino,Emilio Calvanese Strinati,Paolo Di Lorenzo", "background": "语义通信关注的是提高对接收到数据背后意义的理解，并确保完成促使信息交换的任务。然而，当设备使用不同的语言、逻辑或内部表示时，可能产生语义不匹配，这对双方的理解造成了障碍。本文在现有背景下探讨了如何通过MIMO通信解决语义通信中的潜在空间不对齐问题。", "innovation": "本文提出了一种创新的方法，利用MIMO通信解决潜在空间不对齐问题。具体来说，该方法学习了一个MIMO预编码/解码对，该对能够联合执行潜在空间压缩和语义信道均衡，从而缓解语义不匹配和物理信道缺陷。提出了两种解决方案：一种是线性模型，通过交替方向乘法器（ADMM）求解双凸优化问题进行优化；另一种是基于神经网络的模型，在传输功率预算和复杂度约束下学习语义MIMO预编码/解码。", "conclusion": "数值结果表明，在目标导向的语义通信场景中，本文提出的方案具有有效性，主要讨论了准确性、通信负担和解决方案复杂性之间的权衡。"}
{"llm_update_time": "20250723", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.16696", "html_url": "https://arxiv.org/abs/2507.16696", "title": "FISHER: 一种多模态工业信号综合表示的基础模型", "title_en": "FISHER: A Foundation Model for Multi-Modal Industrial Signal Comprehensive Representation", "authors": "Pingyi Fan,Anbai Jiang,Shuwei Zhang,Zhiqiang Lv,Bing Han,Xinhu Zheng,Wenrui Liang,Junjie Li,Wei-Qiang Zhang,Yanmin Qian,Xie Chen,Cheng Lu,Jia Liu", "background": "随着SCADA系统的快速部署，如何有效分析工业信号并检测异常状态已成为行业的迫切需求。由于这些信号存在显著差异，即我们总结为M5问题，之前的研究所关注的是小部分问题，并采用专门的模型。这些模型未能充分利用模态间的协同效应和强大的扩展法则。", "innovation": "我们主张由于内在的相似性，M5信号可以统一对其建模。为此，我们提出了FISHER，一种多模态工业信号综合表示基础模型。FISHER考虑任意采样率的情景，将采样率的增加视为子带信息的连接。具体而言，FISHER以STFT子带为建模单位，并采用教师学生半监督学习框架进行预训练。我们还开发了RMIS基准，该基准在多个健康管理任务上评估M5工业信号的表示。与顶级半监督模型相比，FISHER展示了多样的出色能力，通用性能增益高达5.03%，并且具有更高效的扩展曲线。", "conclusion": "我们还研究了下游任务上的扩展法则，并为未来工作指出了潜在的发展途径。FISHER现在已开源。"}
{"llm_update_time": "20250723", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.16674", "html_url": "https://arxiv.org/abs/2507.16674", "title": "GASPnet:全球同步相位", "title_en": "GASPnet: Global Agreement to Synchronize Phases", "authors": "Andrea Alamiaa,Sabine Muzellec,Thomas Serre,Rufin VanRullen", "background": "近年来，Transformer架构已成为人工智能各个领域的革新性技术，依赖于基于键与查询一致性的注意机制来选择和路由网络中的信息。以往的研究引入了一种新颖的大脑启发式架构，利用类似机制实现了全局'一致性路由'机制。此系统通过将每个神经元的键与网络中所有神经元的单一全局查询进行匹配来调节网络活动。作为一种全局注意机制，它提高了网络对噪声的鲁棒性，但对于多分类任务来说是不够的。为了应对这一挑战，该研究在此基础上提出了一种新的机制，结合了Transformer注意操作与同步结合的神经科学理论。神经科学理论认为，大脑通过神经元在那些特征上的同步活动来联结特征，从而有效地将同一对象的特征联结在一起，而将不同对象的特征分离。该研究从这一理论出发，将角度相位引入卷积网络的每一层。通过Kuramoto动力学实现相位对齐后，该方法增强具有类似相位的神经元之间的操作，并抑制具有相反相位的神经元之间的操作。该机制在两个数据集上进行了测试：一个是数字对，另一个是MNIST项叠加在CIFAR-10图像上的组合。实验结果表明，该机制的准确率优于CNN网络，更能抵御噪声干扰，具备更好的泛化能力。", "innovation": "提出了一种新的机制GASPnet（Global Agreement to Synchronize Phases），该机制结合了Transformer注意操作与同步结合的神经科学理论。通过Kuramoto动力学实现相位对齐，并增强具有类似相位的神经元之间的操作，有效抑制具有相反相位的神经元之间的操作。", "conclusion": "研究揭示，GASPnet机制在两个数据集上展示了优于CNN网络的表现，证明了该机制在噪声抵御能力和泛化能力上的优势，通过结合神经科学和机器学习的理论，提出了一种能够解决神经网络中视觉联结问题的新方法。"}
{"llm_update_time": "20250723", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.16223", "html_url": "https://arxiv.org/abs/2507.16223", "title": "分子表面属性和拓扑点云对分子属性的学习", "title_en": "Aligned Manifold Property and Topology Point Clouds for Learning Molecular Properties", "authors": "Alexander Mihalcea", "background": "现有的分子属性预测模型通常依赖于SMILES字符串和分子图等表示方式，这些表示方式忽略了驱动分子间行为的表面局部现象。基于3D的方法则需要降低表面细节或使用计算成本高的SE(3)-不变架构来处理空间变化。", "innovation": "本文提出了AMPTCR（对齐的流形属性和拓扑点云表示），它结合了化学上意义明确的局部量子衍生标量场和自定义的拓扑描述符，并以对齐的点云格式表示。每个表面点包括从曲率衍生的拓扑向量和转换到标准参考框架的坐标，这使得使用常规的SE(3)-敏感架构进行有效学习成为可能。", "conclusion": "AMPTCR在基于DGCNN框架的分子量和细菌生长抑制作用两个任务上的评估结果表明，AMPTCR能够编码具有物理意义的数据，在分子量任务中，验证的R^2为0.87；在细菌抑制任务中，使用AMPTCR可以实现对大肠杆菌抑制值的分类和回归，分类任务的ROC AUC为0.912，回归任务的R^2为0.54。这些结果表明，AMPTCR提供了一种紧凑且架构无关的表示，适用于模拟由表面介导的分子属性。"}
{"llm_update_time": "20250723", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.15864", "html_url": "https://arxiv.org/abs/2507.15864", "title": "使用双重相似性进行低资源NER的对抗示范学习", "title_en": "Adversarial Demonstration Learning for Low-resource NER Using Dual Similarity", "authors": "Guowen Yuan,Tien-Hsuan Wu,Lianghao Xia,Ben Kao", "background": "该研究探讨了在资源有限的情况下基于示范学习的命名实体识别(NER)问题。研究中指出了示范建设和模型训练中存在的两个主要问题：一是现有的示范实例选择方法主要依赖语义相似性；二是NER标签器参考示范实例的能力通常不足。", "innovation": "为了解决这些问题，研究提出了一种新的方法，即结合语义相似性和特征相似性选择示范实例，并通过对抗示范训练NER模型。对抗示范训练要求模型在进行标签任务时必须参考示范实例，从而提高实体识别的准确性和效果。", "conclusion": "通过一系列 comprehensive 实验验证，该方法在低资源NER任务中表现优于其他方法，证明了其有效性和实用性。"}
{"llm_update_time": "20250723", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.16814", "html_url": "https://arxiv.org/abs/2507.16814", "title": "视觉语言慢思考推理的半离策强化学习", "title_en": "Semi-off-Policy Reinforcement Learning for Vision-Language Slow-thinking Reasoning", "authors": "Junhao Shen,Haiteng Zhao,Yuzhe Gu,Songyang Gao,Kuikun Liu,Haian Huang,Jianfei Gao,Dahua Lin,Wenwei Zhang,Kai Chen", "background": "大型视觉-语言模型（LVLMs）对于解决复杂的多模态任务非常重要。但是，由于LVLMs主要通过视觉-语言对齐进行训练，因此难以采用基于策略的强化学习（RL）来开发慢思考能力，因为其滚出空间受限于初始能力。离策RL可以超越当前政策，但直接从外部模型蒸馏轨迹可能会由于模型间视觉感知能力的不匹配而导致视觉幻觉。", "innovation": "本文提出了一种简单且可扩展的方法，即SOPHIA（Semi-Off-Policy RL for Vision-Language Slow-Thinking Reasoning），结合可训练的LVLM的在线视觉理解与语言模型的离策慢思考推理，对推理进行结果导向的奖励，并反向传播视觉奖励，使LVLM能够通过离策RL算法利用获得的推理轨迹学习慢思考推理能力。大量实验表明SOPHIA的有效性，特别地，SOPHIA在平均上提高了InternVL3.0-38B的性能，达到开源LVLM在多种多模态推理基准测试中的最佳性能，甚至在挑战性的MathVision和OlympiadBench上超越了一些封闭源模型（如GPT-4.1），分别获得49.08%和49.95%的pass@1准确率。", "conclusion": "SOPHIA表现优于监督微调和直接在线策略RL方法，为后续在线策略训练提供了更好的策略初始化。"}
{"llm_update_time": "20250723", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.16795", "html_url": "https://arxiv.org/abs/2507.16795", "title": "利用概念消除微调引导大语言模型的离分布外推", "title_en": "Steering Out-of-Distribution Generalization with Concept Ablation Fine-Tuning", "authors": "Helena Casademunt,Caden Juang,Adam Karvonen,Samuel Marks,Senthooran Rajamanoharan,Neel Nanda", "background": "大语言模型（LLMs）在微调过程中可能会出现意外的离分布外推现象。传统的解决方法是通过修改训练数据来实现，比如增加更多精确指定的训练数据。然而，这种方法并不总是实用的。", "innovation": "提出了概念消除微调（CAFT）技术，利用解释性工具在不修改训练数据或使用目标分布数据的情况下控制LLMs在微调过程中的泛化。通过消除对应于不希望的概念的LLMs潜在空间中的方向，CAFT在微调过程中使用线性投影来引导模型避免不期望的泛化。", "conclusion": "CAFT能够在不修改微调数据的情况下显著减少不匹配响应，同时不损害训练分布上的表现。总的来说，CAFT提供了一种新颖的方法来引导LLMs的泛化，而无需修改训练数据。"}
{"llm_update_time": "20250723", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.15882", "html_url": "https://arxiv.org/abs/2507.15882", "title": "文档haystack：一种长文档上下文多模态图像/文档理解视觉LLM基准", "title_en": "Document Haystack: A Long Context Multimodal Image/Document Understanding Vision LLM Benchmark", "authors": "Goeric Huybrechts,Srikanth Ronanki,Sai Muralidhar Jayanthi,Jack Fitzgerald,Srinivasan Veeravanallur", "background": "多模态大型语言模型的应用进展显著提升了跨多种模态复杂数据输入的分析和理解能力。然而，长文档的处理仍是一个未充分探索的领域，主要原因在于缺乏合适的基准测试工具。因此，本文提出了一种名为Document Haystack的全面基准，旨在评估视觉语言模型（VLMs）在处理长且视觉复杂文档方面的性能。Document Haystack包含从5到200页不等的文档，并在文档中以各种深度插入纯文本或文本+图像相结合的“针”，以挑战VLMs的检索能力。该基准包括400种文档变体和总计8,250个问题，并提供了一个客观的自动化评估框架。", "innovation": "本文创新地提出了Document Haystack，这是一种专门针对长文档的基准测试工具，特别是针对视觉语言模型的评估。通过在文档中插入不同深度的纯文本和多模态文本+图像“针”，挑战VLMs的检索能力，这是对现有长文档处理研究的补充，使得这一领域得到了更全面的探索。", "conclusion": "本文详细介绍了Document Haystack数据集的构建和特性，展示了若干顶级VLMs的结果，并讨论了该领域的未来研究方向。"}
{"llm_update_time": "20250723", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.15885", "html_url": "https://arxiv.org/abs/2507.15885", "title": "ADEPTS：面向人类中心的代理设计能力框架", "title_en": "ADEPTS: A Capability Framework for Human-Centered Agent Design", "authors": "Pierluca D'Oro,Caley Drooff,Joy Chen,Joseph Tighe", "background": "大型语言模型推动了强大且灵活的AI代理的发展，这些AI代理通过日益融入人类日常生活来协助人类。这种灵活性、潜力和日益增长的采用需求跨学科的方法来开发、监控和讨论代理驱动的用户体验能力。然而，当前关于以人为本的AI代理开发的指导是分散的：用户体验准则侧重于界面行为，工程分类学描述了内部管道，并且道德检查表处理高层次治理。没有一个简洁的、面向用户的词汇表来告诉团队代理应该基本能够做什么。", "innovation": "我们引入了ADEPTS，一种能力框架，定义了一组核心的面向用户的代理能力，提供了一套关于开发AI代理的统一指导。ADEPTS基于六个以人为本的设计原则，表达了AI代理应该展示的最小可演示的核心能力，使其在日常使用中易于理解、控制和信任。ADEPTS补充了现有的框架和分类学，并且它位于技术性开发和用户体验开发之间。通过呈现ADEPTS，我们的目标是将复杂的AI-UX要求浓缩成一个可以操作的框架，为AI研究者、设计师、工程师和政策审查者提供可操作的指导建议。我们相信ADEPTS有潜力加速代理用户体验能力的改进，简化利用这些能力设计体验的过程，并提供一个共享语言来跟踪和讨论AI代理开发的进步问题。", "conclusion": "我们认为ADEPTS有潜力加速代理用户体验能力的改进，简化利用这些能力设计体验的过程，并提供一个共享语言来跟踪和讨论AI代理开发的进步问题。"}
{"llm_update_time": "20250723", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.15895", "html_url": "https://arxiv.org/abs/2507.15895", "title": "将基于理性的道德决策整合到强化学习架构中", "title_en": "Integrating Reason-Based Moral Decision-Making in the Reinforcement Learning Architecture", "authors": "Lisa Dargasz", "background": "强化学习是一种在各种任务中表现出色的机器学习方法，尤其在自主代理的开发中起着核心作用。随着这些代理变得越来越有能力和市场准备度接近，它们将从实验室原型过渡到在真实环境中的自主运行。然而，在过渡过程中引发了对这些系统伦理行为的担忧，因此需要它们被设计为能够表现出伦理行为。为此，需要跨学科的研究来构建“人工道德代理”。", "innovation": "本研究探索了基于推理的人工道德代理（RBAMAs）的发展。RBAMAs扩展了强化学习架构，使其能够基于规范推理进行道德决策。通过装备该代理以学习理由理论，使代理能够处理与道德相关的命题以推导出道德义务。代理据此调整其行为，确保其任务的合规性，这提升了代理行动的道德合理性、道德稳健性和道德可信度。因此，提出扩展架构作为满足关键伦理要求的开发人工道德代理的可行框架。展示了RBAMA的第一个实现，并在初步实验中证实了其潜力。", "conclusion": "研究提出了基于推理的人工道德代理（RBAMAs）的第一个实施，并证实了其在初步实验中的潜力。通过集成基于推理的道德决策，扩展了强化学习架构，为开发出满足关键伦理要求的人工道德代理提供了一个具体且可部署的框架。"}
{"llm_update_time": "20250723", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.16676", "html_url": "https://arxiv.org/abs/2507.16676", "title": "Transformer 层中的自定义算法基故障容忍性", "title_en": "Custom Algorithm-based Fault Tolerance for Attention Layers in Transformers", "authors": "Vasileios Titopoulos,Kosmas Alexandridis,Giorgos Dimitrakopoulos", "background": "Transformer 模型及其大型语言模型 (LLM) 通过注意力机制推动了诸多 AI 应用的革新，引发了对专门硬件加速器的需求。这些加速器的主要挑战之一是在处理由于随机硬件故障引起的各种错误时不够高效。传统的基于算法的容错 (ABFT) 技术能够验证个体矩阵乘法，但在处理注意力机制的整个过程中，尤其是在中间的 softmax 归一化操作过程中存在局限性。", "innovation": "本文提出了一种名为 Flash-ABFT 的新方法，该方法在线计算整个注意力层中的查询、键和值矩阵三矩阵乘积的校验和，包括 softmax 操作，仅需一次校验即可。这种方法通过消除冗余校验几乎简化了 50% 的开销，同时保持了高故障检测精度。", "conclusion": "实验结果显示，Flash-ABFT 的硬件面积开销仅为 5.3%，能量开销不到 1.9%，表明它是一个具有性价比又可靠的注意力加速器中错误检测解决方案。"}
{"llm_update_time": "20250723", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.16672", "html_url": "https://arxiv.org/abs/2507.16672", "title": "在提示调优的大语言模型中冷启动个性化中的元学习", "title_en": "Meta-Learning for Cold-Start Personalization in Prompt-Tuned LLMs", "authors": "Yushang Zhao,Huijie Shen,Dannier Li,Lu Chang,Chengrui Zhou,Yinuo Yang", "background": "现有的生成式、可解释性和灵活推荐系统依赖于大型语言模型（LLM），这些系统在冷启动用户情况下表现不佳，即几乎没有或没有与系统的历史互动。当前的解决方案，如监督微调和协作过滤，侧重于稠密型用户-项目交互，维护和更新成本较高。因此，本研究旨在提出一个元学习框架，用于快速有效地在冷启动情况下个性化基于LLM的推荐系统，特别强调参数效率的提示调优。该模型通过一阶（Reptile）和二阶（MAML）优化学习软提示嵌入，将每位用户视为任务来学习用户行为先验的可学习向量，作为输入标记的扩充。这些可学习向量是可微分的控制变量。提示通过采样集、内环适应和外环泛化进行元优化。", "innovation": "本研究提出了一种元学习框架，用于执行参数高效的提示调优，以快速有效地个性化基于LLM的推荐系统，特别是在冷启动情况下。该模型通过一阶（Reptile）和二阶（MAML）优化学习用户行为先验的软提示嵌入。作为输入标记的扩充，这些可学习向量是可微分的控制变量。提示通过采样集、内环适应和外环泛化进行元优化。", "conclusion": "在MovieLens-1M、Amazon Reviews和Recbole上，我们的自适应模型在NDCG@10、HR@10和MRR方面超过了强基线，并且能够实时运行（即，低于300毫秒）在消费级GPU上运行。此外，该可扩展解决方案还支持零历史个性化，其275毫秒的适应率使得金融系统的实时风险评估在减少检测延迟和提高支付网络稳定性方面成为可能。更重要的是，275毫秒的适应能力能够显著缩短传统合规检查的系统性脆弱性检测延迟，从而加强了国家金融基础设施的韧性，减少支付网络（例如Fedwire）中的传染风险。"}
{"llm_update_time": "20250723", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.15914", "html_url": "https://arxiv.org/abs/2507.15914", "title": "MSGM: Multi-Scale Spatiotemporal Graph Mamba for EEG Emotion Recognition", "title_en": "MSGM: A Multi-Scale Spatiotemporal Graph Mamba for EEG Emotion Recognition", "authors": "Hanwen Liu,Yifeng Gong,Zuwei Yan,Zeheng Zhuang,Jiaxuan Lu", "background": "现有的EEG情绪识别方法难以捕捉多尺度的时间空间动态，也不够高效以实现实时应用。这些方法往往简化了时间粒度和空间层次结构，限制了识别精度。", "innovation": "提出了一个多尺度时空图Mamba（MSGM）框架，该框架结合了多窗口时间分割、双模态空间图建模，以及通过Mamba架构实现高效的融合。MSGM通过分段EEG信号并构建具有神经解剖学先验的全局-局部图，有效捕捉了细微的情绪波动和层级脑连接。此外，还使用多深度图卷积网络（GCN）和标记嵌入融合模块，以及Mamba的状态空间建模，使得时空交互在线性复杂度下动态进行。", "conclusion": "MSGM仅用一个MSST-Mamba层就在SEED、THU-EP和FACED数据集上超过了领域内的领先方法，表现出较高的跨被试情绪分类的稳健精度，同时实现了毫秒级推理。"}
{"llm_update_time": "20250723", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.15990", "html_url": "https://arxiv.org/abs/2507.15990", "title": "生成式AI模型在有界区域学习随机动力系统流图", "title_en": "Generative AI Models for Learning Flow Maps of Stochastic Dynamical Systems in Bounded Domains", "authors": "Minglei Yang,Yanfang Liu,Diego del-Castillo-Negrete,Yanzhao Cao,Guannan Zhang", "background": "在有界区域内模拟随机微分方程（SDEs）面临着显著的计算挑战，主要因为粒子退出现象需要精确地建模内部随机动力学和边界交互。尽管基于机器学习的方法在学习SDEs方面取得了成功，但现有的机器学习方法并不适用于有界区域的SDEs，因为它们无法准确捕捉粒子退出动力学。", "innovation": "本文提出了一种统一的混合数据驱动方法，结合条件扩散模型与退出预测神经网络，以捕捉内部的随机动力学和边界退出现象。模型主要包括两个部分：一个神经网络用于通过二元交叉熵损失学习退出概率，具有严格的收敛保证；另一个无训练的扩散模型使用闭合形式的评分函数生成不退出粒子的状态转换。这两个部分通过概率采样算法整合，该算法在每一步决定粒子是否退出，并生成相应状态转换。", "conclusion": "通过三个测试案例展示了所提出方法的性能：一个一维简化问题用于理论验证、一个二维有界区域的对流-扩散问题以及一个与磁约束等离子体相关的三维问题。"}
{"llm_update_time": "20250723", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.15899", "html_url": "https://arxiv.org/abs/2507.15899", "title": "ML与结构化DID的结合：理论、模拟与应用研究指南", "title_en": "Structural DID with ML: Theory, Simulation, and a Roadmap for Applied Research", "authors": "Yile Yu,Anzhi Xu,Yi Wang", "background": "观察性面板数据中的因果推断已成为经济学、政策分析和更广泛的社会科学中的一个关键问题。传统的差异-差异（DID）方法在处理高维混淆变量方面存在困难，而机器学习（ML）虽然强大，但缺乏因果结构的可解释性。在这一背景下，该研究针对传统DID与高维混杂变量之间的核心矛盾和ML缺乏因果结构解释力的问题，提出了一种新的框架——S-DIDML，这一框架实现了结构化识别与高维协变量干扰的协调解决。", "innovation": "该研究提出了一种结合结构识别与高维协变量干扰缓解的新框架S-DIDML。S-DIDML框架通过结构残差正交化技术（Neyman正交性和交叉拟合）保留了组-时间治疗效果（ATT）的识别结构，以解决高维协变量干扰问题。此外，还结合了因果森林和半参数模型设计了一个动态异质性估计模块，用于捕捉时空异质性。S-DIDML框架提供了一种完全模块化的应用流程，并通过Stata标准化实现。这一方法为DID和DDML的创新提供了富有成果的途径，从方法堆栈转向架构创新，从而促进了社会科学上对政策敏感群体的精确识别和资源优化。", "conclusion": "该框架为复杂干预情景如数字转型政策和环境法规等提供了可复制的评估工具、决策优化参考和方法论范式。其在实际应用中的引入丰富了DID和DML方法的研究，推动了社会科学中因果推理方法的发展，从而有助于精确识别政策敏感群体并优化资源配置。"}
{"llm_update_time": "20250723", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.16806", "html_url": "https://arxiv.org/abs/2507.16806", "title": "超越二元奖励：训练语言模型考虑其不确定性", "title_en": "Beyond Binary Rewards: Training LMs to Reason About Their Uncertainty", "authors": "Mehul Damani,Isha Puri,Stewart Slocum,Idan Shenfeld,Leshem Choshen,Yoon Kim,Jacob Andreas", "background": "通过强化学习（RL）训练语言模型（LMs）以生成自然语言推理链，可以提高其在各种困难问答任务上的性能。大多数成功的RL应用使用二元奖励函数来评估LM输出的正确性，但这种方式不会惩罚猜测或低置信度输出，反而可能导致模型在其他问题域中产生更多的错误回答（或“胡言乱语”），从而降低模型的校准度。", "innovation": "本文介绍了RLCR（强化学习与校准奖励相结合的方法），一个同时提高准确性和校准估计的训练方法。在RLCR中，模型在推理后生成预测和数值置信度估计。通过使用二元正确性评分与柏莱尔得分（一种激励校准预测的概率估计划分规则）相结合的奖励函数进行训练。证明了这种方法能够产生准确性和校准度都好的模型。该方法在多种数据集上得到了验证，不仅能改善校准度，而且不损失准确度，甚至优于传统的RL训练和事后置信度评分的分类器。实验结果表明，明确地优化校准度可以产生更可靠的推理模型，并且可以通过置信度加权缩放方法在测试时利用表达出的置信度来进一步提升准确率和校准度。", "conclusion": "本文证明了明确优化校准度可以产生更可靠的推理模型，并探讨了通过置信度加权缩放方法在测试时利用表达出的置信度来改善准确率和校准度的方法。"}
{"llm_update_time": "20250723", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.15887", "html_url": "https://arxiv.org/abs/2507.15887", "title": "AlgoTune：语言模型能否加速通用数值程序？", "title_en": "AlgoTune: Can Language Models Speed Up General-Purpose Numerical Programs?", "authors": "Ori Press,Brandon Amos,Haoyu Zhao,Yikai Wu,Samuel K. Ainsworth,Dominik Krupke,Patrick Kidger,Touqir Sajed,Bartolomeo Stellato,Jisun Park,Nathanael Bosch,Eli Meril,Albert Steppi,Arman Zharmagambetov,Fangzhao Zhang,David Perez-Pineiro,Alberto Mercurio,Ni Zhan,Talor Abramovich,Kilian Lieret,Hanlin Zhang,Shirley Huang,Matthias Bethge,Ofir Press", "background": "尽管语言模型（LM）的能力已经取得了进步，但现有的评估仍然集中在人类已经解决的任务上，包括编程和数学任务。本文提出了一种新的基准测试方法——AlgoTune，用于测试语言模型设计和实现算法的能力。在这个开放任务的基准中，要求语言模型编写能够高效解决计算机科学、物理和数学中的计算性难题的代码。", "innovation": "AlgoTune基准测试包含155个由领域专家收集的编程任务，并提供了一个验证和计时LM合成解决方案代码的框架，将其与流行开源包中的参考实现进行比较。此外，还开发了一个基准LM代理AlgoTuner，并评估了其在前沿模型中的表现。虽然AlgoTuner在平均速度上实现了1.72倍的提升，但发现当前模型未能发现算法创新，而是倾向于表面优化。", "conclusion": "我们希望AlgoTune能够推动开发出能够超越顶尖人类表现的具备创造性问题解决能力的LM代理。"}
{"llm_update_time": "20250723", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.15976", "html_url": "https://arxiv.org/abs/2507.15976", "title": "使用主动学习和不确定性感知神经网络高效构建等离子体湍流输运代理模型的数据集", "title_en": "Efficient dataset construction using active learning and uncertainty-aware neural networks for plasma turbulent transport surrogate models", "authors": "Aaron Ho(1),Lorenzo Zanisi(2),Bram de Leeuw(3),Vincent Galvan(1),Pablo Rodriguez-Fernandez(1),Nathaniel T. Howard(1) ((1) MIT Plasma Science and Fusion Center, Cambridge, USA, (2) UKAEA Culham Centre for Fusion Energy, Abingdon, UK, (3) Radboud University, Nijmegen, Netherlands)", "background": "本文基于先前成功证明静态预标记数据集减少训练集的先例，使用Araphe (ADEPT) 框架，应用了一种新的策略来解决 tokamak 聚变等离子体中的湍流输运问题，尤其是与其他像QuaLiKiz这样的相对快速的代码相比，旨在构建更小的数据集作为更昂贵代码（如CGYRO 或 GENE）的代理。新实现的算法使用了分类部分的SNGP架构和回归部分的BNN-NCP架构，训练了所有湍动模式的模型，并对由通用QuaLiKiz输出描述的所有运输通量（ITG、TEM、ETG和$Q_e$、$Q_i$、$\bar{\bar{e}}$、$\bar{\bar{i}}$、$\bar{\bar{i}}$）进行了建模。模型最终训练集从100增加到10000，得到了相当高的分类和回归性能，适用于不同输出。", "innovation": "本文创新性地提出了使用不确定性意识架构、主动学习技术和集成物理仿真代码的数据标签器，来构建数据驱动的代理模型数据集的构想。具体创新包括：1）将ADEPT框架应用于更复杂的等离子体湍流输运问题，2）使用SNGP和BNN-NCP架构来处理分类和回归问题，3）在保持较低数据集大小的情况下，实现了与之前的ADEPT方法相当的性能，但具有额外的输入维度需求。", "conclusion": "虽然这种方法在实现上的改进速度比预期的要慢，但整体技术被设计成具有可升级性和通用型，可以应用于许多其他代理建模应用中，而不局限于等离子体湍流输运预测。"}
{"llm_update_time": "20250723", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.16704", "html_url": "https://arxiv.org/abs/2507.16704", "title": "Screen2AX：基于视觉的macOS Accessibility自动生成方法", "title_en": "Screen2AX: Vision-Based Approach for Automatic macOS Accessibility Generation", "authors": "Viktor Muryn,Marta Sumyk,Mariya Hirna,Sofiya Garkot,Maksym Shamrai", "background": "桌面无障碍元数据使人工智能代理能够解释屏幕并支持依赖屏幕读写器等工具的用户。然而，许多应用程序因开发人员提供的不完整或缺失元数据而未能实现完全的无障碍访问。我们的研究表明，只有33%的macOS应用程序提供全面的无障碍支持。尽管近期有关结构化屏幕表示的工作主要针对特定挑战，例如UI元素检测或字幕生成，但这些工作均未试图复制桌面界面的全部复杂性，即整个层次结构。因此，亟需一种能够自动、实时、从单张屏幕截图生成树状结构无障碍元数据的框架以填补这一空白。", "innovation": "我们提出了Screen2AX，第一个能够自动从单张屏幕截图生成实时、树状结构无障碍元数据的框架。该方法利用视觉-语言和对象检测模型来检测、描述并组织UI元素的层次结构，模仿macOS系统的无障碍层次结构。为了克服macOS桌面应用程序数据有限的问题，我们整理并公开发布了三个包含112个macOS应用程序的数据集，每个应用都在UI元素检测、分组和层次化无障碍元数据方面进行了标注，并附有相应的屏幕截图。Screen2AX能够准确推断出层次结构树，重建完整无障碍树的F1分数为77%。更重要的是，这些层次结构树提高了自主代理解析和与复杂桌面界面交互的能力。我们还提供了Screen2AX-Task，一个专门用于评估macOS桌面环境中自主代理任务执行能力的基准测试。Screen2AX在ScreenSpot基准测试上优于最新的OmniParser V2系统，性能提高了2.2倍。", "conclusion": "本文介绍了Screen2AX，该框架能够从单一屏幕截图自动实时生成macOS应用程序的树状结构无障碍元数据。通过引入视觉-语言和对象检测模型，能够有效提高无障碍元数据的质量，并提升了自治代理对复杂桌面界面的解释和交互能力。这项工作将为开发人员提供一种生成全面无障碍元数据的新方法，从而提高macOS应用程序的用户体验。"}
{"llm_update_time": "20250723", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.16001", "html_url": "https://arxiv.org/abs/2507.16001", "title": "使用强化学习自动设计结构化量子变分电路", "title_en": "Automated Design of Structured Variational Quantum Circuits with Reinforcement Learning", "authors": "Gloria Turati,Simone Foderà,Riccardo Nembrini,Maurizio Ferrari Dacrema,Paolo Cremonesi", "background": "量子变分算法（VQAs）是利用近期内的量子硬件最具潜力的方法之一，但其有效性高度依赖于底层门电路结构设计，通常使用启发式方法进行设计。", "innovation": "作者将量子变分电路的合成建模为一个顺序决策问题，通过引入两种基于强化学习的方法，RLVQC Global和RLVQC Block，分别针对组合优化问题。RLVQC Block创建适合QAOA的门电路结构，而RLVQC Global进一步拓展了门电路结构。两种方法都使用Proximal Policy Optimization (PPO)算法，并利用实验测量结果作为状态观察，指导代理决策。", "conclusion": "实验结果显示，RLVQC方法表现出色，尤其是RLVQC Block在大多数测试实例中优于QAOA和RLVQC Global。虽然RLVQC Block产生的电路深度与QAOA相当，但RLVQC Global变体则能找到明显更短的电路。这些发现表明，强化学习方法可以有效发现针对特定问题的新门电路结构，有效的电路设计策略在固定预设架构和完全无约束之间提供了良好的权衡。"}
{"llm_update_time": "20250723", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.16068", "html_url": "https://arxiv.org/abs/2507.16068", "title": "多语言模型驱动的多机器人团队组合协调", "title_en": "Compositional Coordination for Multi-Robot Teams with Large Language Models", "authors": "Zhehui Huang,Guangyao Shi,Yuwei Wu,Vijay Kumar,Gaurav S. Sukhatme", "background": "多机器人协调通常依赖于特定任务和专家驱动的管道，自然语言的任务描述需要由领域专家手动转换为数学公式、算法设计和可执行代码。传统方法劳动密集、非专家难以理解并适应任务需求变化。研究表明，这种方法耗时、繁琐且缺乏灵活性。", "innovation": "提出了一种名为LAN2CB (语义到集体行为)的新框架，利用大型语言模型简化并泛化多机器人协调的管道。LAN2CB通过任务分解和代码生成两大关键技术，直接将自然语言任务描述转换为多机器人系统中的可执行Python代码。介绍了自然语言任务规范的数据集以支持开发与基准测试。实验结果表明，LAN2CB能够从自然语言高效灵活地协调多个机器人，大大减少了手动工程的需求，同时支持不同类型任务的泛化。", "conclusion": "LAN2CB框架能够有效减少多机器人系统的工程负担，支持从自然语言直接生成执行代码，显著提高调度效率和灵活性，适用于多种任务类型。"}
{"llm_update_time": "20250723", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.16041", "html_url": "https://arxiv.org/abs/2507.16041", "title": "放射学与生物学字典化特征：解决个性化乳腺癌中可解释AI问题；字典版本BM1.0", "title_en": "Radiological and Biological Dictionary of Radiomics Features: Addressing Understandable AI Issues in Personalized Breast Cancer; Dictionary Version BM1.0", "authors": "Arman Gorji,Nima Sanati,Amir Hossein Pouria,Somayeh Sadat Mehrnia,Ilker Hacihaliloglu,Arman Rahmim,Mohammad R. Salmanpour", "background": "基于影像组学的人工智能模型在乳腺癌诊断中显示出潜力，但往往缺乏可解释性，限制了其在临床中的应用。这项研究通过创建一个双词典框架来填补影像组学特征（RF）与标准化的BI-RADS词典之间的差距。首先，通过文献和专家评审，将56个RF映射到BI-RADS描述符（形态、边缘、内部强化），创建了一个临床导向特征解读词典（CIFID）。该框架应用于使用多机构患者的动态对比增强MRI数据，分类三阴性乳腺癌（TNBC）与非TNBC。通过27种机器学习分类器和27种特征选择方法，该研究生成了一个互补的数据驱动特征解读词典（DDFID），以进一步解释额外的52个RF。", "innovation": "该研究提出了一种双词典框架（BM1.0），将临床知识与影像组学特征相结合，利用SHAP解释预测并生成数据驱动的特征解读词典，提高了AI模型的透明度，支持RFs在常规乳腺癌诊断和个性化护理中的应用。", "conclusion": "双词典方法BM1.0增强了AI模型的透明度，并支持将RFs整合到常规乳腺癌诊断和个性化护理中，证实了已知的影像生物标志物并揭示了新可解释的关联。"}
{"llm_update_time": "20250723", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.16069", "html_url": "https://arxiv.org/abs/2507.16069", "title": "通过稀疏自编码器解释CFD代理模型", "title_en": "Interpreting CFD Surrogates through Sparse Autoencoders", "authors": "Yeping Hu,Shusen Liu", "background": "基于学习的代理模型已成为高保真CFD求解器的实用替代方案，但它们的潜在表示仍然难以理解，从而阻碍了在安全关键或受监管环境中的采用。因此，有必要开发工具来提高这些模型的可解释性和信任度，特别是在CFD应用领域。", "innovation": "本文提出了一个后验可解释性框架，用于基于图形的CFD代理模型。通过利用稀疏自编码器（SAE），从预先训练好的代理模型的节点嵌入空间中获得一个超完备基，从而提取出可解释的潜在特征字典。这种方法能够在节点嵌入空间中识别出与物理现象如涡旋或流结构等对应的单义概念，提供了一种模型无关的方法来增强CFD应用程序的解释性和可信度，使用户更容易理解模型的行为和预测结果。", "conclusion": "本文提出的框架能够从基于图形的CFD代理模型中提取解释性良好的潜在特征，便于理解和信任这些模型在安全关键或监管要求较高的应用中做出的预测和决策。"}
{"llm_update_time": "20250723", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.16077", "html_url": "https://arxiv.org/abs/2507.16077", "title": "基于大规模测试床的服务指标估算的AI驱动编排", "title_en": "AI-driven Orchestration at Scale: Estimating Service Metrics on National-Wide Testbeds", "authors": "Rodrigo Moreira,Rafael Pasquini,Joberto S. B. Martins,Tereza C. Carvalho,Flávio de Oliveira Silva", "background": "网络切片(NS)的实现需要具备AI特性的编排架构以有效地管理和满足多样化用户需求。为了实现这一目标，网络切片正在向更加用户中心的数字化转型方向发展，重视能够内置智能以实现在统一且隔离方式下的自我管理连接的架构。然而，这些努力在生产环境中验证结果也面临挑战，尤其是在利用ML的编排技术和通常在本地网络或实验室仿真中进行测试的情况下。因此，本论文提出了一种大规模验证方法，利用网络切片预测模型和深度神经网络(DNNs)以及基本机器学习算法，在实际大规模生产测试床中预测延迟，并评估了不同DNNs和ML算法的性能，以实现分布式数据库应用在网络切片上的部署。该研究探讨了基于AI的预测模型如何提升网络切片编排架构，并提出了一种无缝的、用于生产环境的验证方法，作为替代完全受控仿真或实验室设置的方案。", "innovation": "论文提出了一种大规模验证方法，利用深度神经网络(DNNs)和基本机器学习算法构建网络切片预测模型，旨在评估并比较不同DNNs和ML算法在实际大规模生产测试床中的性能，以实现分布式数据库应用在网络切片上的部署。这种方法提供了一种无缝的、生产环境导向的验证方案，作为实验室仿真或完全受控环境的替代方案", "conclusion": "本研究强调了基于AI的预测模型在优化网络切片编排架构方面的潜力，并提出了一个实际可行的大规模验证方法，该方法可以在实际生产环境中进行测试和评估，以提供更可靠的验证结果。"}
{"llm_update_time": "20250723", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.16107", "html_url": "https://arxiv.org/abs/2507.16107", "title": "带有稀疏模式支持的缺失非随机数据的递归方程插补", "title_en": "Recursive Equations For Imputation Of Missing Not At Random Data With Sparse Pattern Support", "authors": "Trung Phung,Kyle Reese,Ilya Shpitser,Rohit Bhattacharya", "background": "在数据处理管道中，常见的缺失值处理方法是使用MICE或Amelia等软件包进行多重填补，这些方法通常假定数据是随机缺失的（MAR），并且在填补过程中会对填补分布做出参数化或平滑化假设，以便即使在数据中没有所有缺失模式的支持时也能进行填补。然而，这些假设在实践中不切实际，会导致分析后出现模型误指定导致的偏差。本文提出了一种新的方法来解决这一问题。", "innovation": "本文发展了一种新的缺失数据图模型中完整数据法的新表征，适用于both MAR和MNAR机制，能处理某些缺失模式不支持的情况。据此提出了一个新的填补算法——多变量支持图案递归填补（MISPR），该算法使用Gibbs采样，类似于Multivariate Imputation with Chained Equations（MICE），但在MAR和MNAR设置下都是一致的，并能处理缺失数据模式缺少支持而不需额外假设。实验证明，MISPR在MAR数据下获得与MICE相当的结果，并在MNAR数据下获得更少偏差的结果。", "conclusion": "本文的新表征和基于它的填补算法为使原则性的缺失数据方法在实际应用中更具适用性做出了贡献，尤其是在数据很可能MNAR且足够高维以至于在样本量下会出现无支持的缺失数据模式的情况下。"}
{"llm_update_time": "20250723", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.16110", "html_url": "https://arxiv.org/abs/2507.16110", "title": "专家引导的LLM推理在电池发现中的应用：从AI驱动的假设到合成和表征", "title_en": "Expert-Guided LLM Reasoning for Battery Discovery: From AI-Driven Hypothesis to Synthesis and Characterization", "authors": "Shengchao Liu,Hannan Xu,Yan Ai,Huanxin Li,Yoshua Bengio,Harry Guo", "background": "大型语言模型（LLMs）通过使用链式思考（CoT）技术解决复杂问题，标志着人工智能（AI）领域的革命性突破，但它们的推理能力主要局限于数学和编程问题，对特定领域的应用（如电池发现）的研究尚不充分。这篇论文提出了ChatBattery，一种结合领域知识以引导LLMs进行更有效的材料设计推理的创新框架。", "innovation": "ChatBattery是一个新的代理型框架，用于整合领域知识以引导LLMs进行更有效的推理，从而促进材料设计。通过ChatBattery，研究人员成功地发现、合成并表征了三种新型锂离子电池正极材料，并分别提高了28.8%、25.2%和18.5%的实用容量，超越了常见的正极材料LiNi0.8Mn0.1Co0.1O2（NMC811）。这不仅展示了ChatBattery在材料发现中的应用，还开创新路径，展示了LLM驱动和基于推理的电池材料发明平台。", "conclusion": "从设计到合成再到表征的完整AI驱动循环展示了AI驱动推理在材料发现中的变革潜力，有望彻底改变材料发现领域。"}
{"llm_update_time": "20250723", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.16139", "html_url": "https://arxiv.org/abs/2507.16139", "title": "配对的条件对比强化学习中的不变性", "title_en": "Equivariant Goal Conditioned Contrastive Reinforcement Learning", "authors": "Arsh Tangri,Nichols Crawford Taylor,Haojie Huang,Robert Platt", "background": "对比强化学习（CRL）提供了一种有前景的框架，用于从未标记的交互中提取有用的结构化表示。通过将状态-动作对与其相应的未来状态拉近，同时将负对推远，CRL 允许学习非平凡的策略，而不需要手动设计的奖励。", "innovation": "作者提出了配对的条件对比强化学习（ECRL），该方法使用不变性约束进一步结构化潜在空间。通过利用目标条件下控制任务中的固有对称性，该方法提高了样本效率和空间泛化能力。具体来说，作者正式定义了目标不变组不变MDP，以描述旋转对称的机器人操作任务，并在此基础上提出了一种新的旋转不变评价器表示，配有一个旋转不变的演员用于对比性RL。", "conclusion": "该方法在模拟任务中表现出色，无论是在基于状态还是基于图像的设置下。研究人员还将其方法扩展到离线强化学习设置，通过多个任务展示了其有效性。"}
{"llm_update_time": "20250723", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.16203", "html_url": "https://arxiv.org/abs/2507.16203", "title": "SVAgent: 人工智能硬件安全验证主张的代理", "title_en": "SVAgent: AI Agent for Hardware Security Verification Assertion", "authors": "Rui Guo,Avinash Ayalasomayajula,Henian Li,Jingbo Zhou,Sujan Kumar Saha,Farimah Farahmandi", "background": "SystemVerilog断言（SVA）是最受欢迎的检测电路设计漏洞的方法之一。但由于集成电路设计的全球化和安全要求的持续升级，SVA开发模式暴露出了显著的局限性。开发效率低下且无法有效应对现代复杂集成电路不断增加的安全漏洞。", "innovation": "本文提出了一种名为SVAgent的创新SVA自动生成框架。SVAgent引入了需求分解机制，将原始复杂的需求转化为结构化且逐步可解的细粒度问题解决链。实验证明，SVAgent可以有效抑制幻觉和随机答案的影响，SVA的关键评估指标（如准确性和一致性）显著优于现有框架。更重要的是，SVAgent已被成功集成到最主流的集成电路漏洞评估框架中，并在其真实的工程设计环境中验证了其实用性和可靠性。", "conclusion": "SVAgent能够有效地生成SVA，提升开发效率，解决集成电路安全漏洞检测中的问题，具有广泛的应用前景。"}
{"llm_update_time": "20250723", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.16003", "html_url": "https://arxiv.org/abs/2507.16003", "title": "无需训练的学习：上下文内学习的隐式动态", "title_en": "Learning without training: The implicit dynamics of in-context learning", "authors": "Benoit Dherin,Michael Munn,Hanna Mazzawi,Michael Wunder,Javier Gonzalvo", "background": "大型语言模型（LLM）的一项显著特征是在推理时能够通过上下文学习新的模式，即使这些模式在训练期间未见过。这种能力背后的机制尚未完全理解。", "innovation": "作者展示了通过将自我注意层与MLP堆叠，能使变压器块隐式修改MLP层的权重，根据上下文改变。理论及实验表明，这种简单的机制可能解释了为什么语言模型在上下文中学习而不仅仅是在训练中学习。", "conclusion": "在轻微简化假设下，研究展示了变压器块如何隐式地将上下文转换为MLP层的低秩权重更新。"}
{"llm_update_time": "20250723", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.16005", "html_url": "https://arxiv.org/abs/2507.16005", "title": "AutoMAT: 一种分层的自主合金发现框架", "title_en": "AutoMAT: A Hierarchical Framework for Autonomous Alloy Discovery", "authors": "Penghui Yang,Chendong Zhao,Bijun Tang,Zhonghan Zhang,Xinrun Wang,Yanchen Deng,Yuhao Lu,Cuntai Guan,Zheng Liu,Bo An", "background": "合金设计对于推动现代工业至关重要，但由于组成设计空间的浩瀚和验证成本高昂，这一过程受到了限制。", "innovation": "提出了AutoMAT，这是一种分层和自主的框架，通过将大型语言模型、自动CALPHAD模拟和AI驱动的搜索结合在一起，加速合金设计。AutoMAT在整个从构思到验证的过程中实现了高效、准确和可解释性，无需手动收集大量数据集。在两个不同应用案例中，AutoMAT均表现出明显的优势，缩短了合金发现的时间线。", "conclusion": "AutoMAT作为一种可扩展和多功能的平台，展示了其在下一代合金设计中的潜力。"}
{"llm_update_time": "20250723", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.16083", "html_url": "https://arxiv.org/abs/2507.16083", "title": "为端侧大型语言模型高效组合多任务", "title_en": "Efficient Compositional Multi-tasking for On-device Large Language Models", "authors": "Ondrej Bohdal,Mete Ozay,Jijoong Moon,Kyeng-Hun Lee,Hyeonmok Ko,Umberto Michieli", "background": "适配器参数提供了一种修改机器学习模型行为的方式，并在大规模语言模型（LLMs）和生成型AI中获得了广泛的关注。这些参数可以通过一个称为任务合并的过程来支持多个任务。然而，针对LLMs的任务合并研究，特别是在自然语言处理方面，多局限于每个测试示例只处理单一任务的场景。本研究聚焦于端侧设置，研究基于文本的组合多任务处理，其中每个测试示例涉及同时执行多个任务。", "innovation": "提出了一个涵盖四个实际相关组合任务的基准，以及一种效率高且适合端侧应用（Learnable Calibration）的方法。这为在资源限制条件下改进LLMs的多任务处理能力提供了基础。", "conclusion": "本研究为LLMs在实际多任务场景中的能力提升铺平了道路，并扩大了它们在资源受限的复杂用途中的应用范围。"}
{"llm_update_time": "20250723", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.16236", "html_url": "https://arxiv.org/abs/2507.16236", "title": "基于PAC的上下文bandits离策预测", "title_en": "PAC Off-Policy Prediction of Contextual Bandits", "authors": "Yilong Wan,Yuqiang Li,Xianyi Wu", "background": "本文研究了上下文bandits中的离策评估问题，目标是使用在不同和可能未知的行为策略下收集的数据来量化目标策略的表现。近年来，基于形式化预测的方法被开发出来，构建了可靠的预测区间，能够在有限样本中提供边际覆盖率，特别适用于安全关键的应用。为进一步基于特定离策数据集实现条件覆盖，本文提出了一种新算法，构建了可能准确的预测区间。该方法建立在有效的形式化预测框架之上，通过确立PAC类型的覆盖界来加强其理论保证。分析了所提方法的有限样本和渐近特性，并通过模拟与现有方法比较了其实证性能。", "innovation": "本文提出了一种构建可能准确的预测区间的新算法，基于形式化验证的形式化预测框架，并且通过PAC类型的覆盖界加强了理论保证。这种方法能够基于特定的离策数据集实现条件覆盖，并且针对所提方法进行了有限样本和渐近特性的分析。通过模拟比较了其与现有方法的实证性能。", "conclusion": "本文通过形式化验证的形式化预测框架提出了新的算法，构建了可能准确的预测区间，该方法在一个特定的离策数据集上实现了条件覆盖，并通过理论分析和模拟验证了其效果。"}
{"llm_update_time": "20250723", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.16217", "html_url": "https://arxiv.org/abs/2507.16217", "title": "朝向计算最优的少量示例上下文学习", "title_en": "Towards Compute-Optimal Many-Shot In-Context Learning", "authors": "Shahriar Golchin,Yanfei Chen,Rujun Han,Manan Gandhi,Tianli Yu,Swaroop Mishra,Mihai Surdeanu,Rishabh Agarwal,Chen-Yu Lee,Tomas Pfister", "background": "长上下文大型语言模型能够处理包含数百万词元的输入。在上下文学习范式中，这对应于在输入提示中使用数百或数千个演示示例，实现多种场景下的上下文学习。在实践中，由于（1）推理成本高，（2）缓存和重用计算的益处，以及（3）与随机选择相比，此策略在扩展时提供的性能相似，在大量场景中，通常会随机选择固定数量的演示示例。本文分析了这一现状，并提出了解决方案。", "innovation": "本文提出两种简单的演示示例选择策略，旨在最小化计算开销的情况下提高性能。第一种方法结合了一些基于测试样本相似性选择的小数量演示示例和较大数量并缓存的随机演示示例。第二种方法则通过k-means聚类将随机演示示例替换为基于测试样本表示的质心选择的演示示例。实验表明，这两种方法在多个数据集上的性能优于随机选择，并且在支持缓存和将推理成本降低多达一个数量级的情况下，超越或与最高效的示例选择方法相当。还证明了根据不同标准调整所选择的演示示例的比例可以平衡性能和推理成本。", "conclusion": "我们的策略在多种数据集上始终优于随机选择的方法，并可以显著减少推理成本，最高减少一个数量级。其次，通过不同标准调整所选择的演示示例的比例可以帮助平衡性能和推理成本，从而实现计算最优的少量示例上下文学习。"}
{"llm_update_time": "20250723", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.16254", "html_url": "https://arxiv.org/abs/2507.16254", "title": "轻度案例合成方法在鱼眼目标检测中的数据中心视角", "title_en": "Edge-case Synthesis for Fisheye Object Detection: A Data-centric Perspective", "authors": "Seunghyeon Kim,Kyeongryeol Go", "background": "鱼眼相机引入显著的畸变，对传统数据集上训练的目标检测模型构成了独特的挑战。", "innovation": "提出一种以数据为中心的管道，通过系统性地改善检测性能来关注模型盲点问题。通过详细的误差分析，识别关键边缘情况（如混淆类别对、外围畸变和欠代表上下文），并直接通过边缘案例合成进行应对。微调图像生成模型，并用精心设计的提示引导生成复制现实失败模式的图像。这些合成图像使用高质量检测器进行伪标注，并集成到训练中。", "conclusion": "该方法导致一致的性能提升，强调深刻理解数据并在特定领域（如鱼眼目标检测）中选择性地修复其弱点的重要性。"}
{"llm_update_time": "20250723", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.16004", "html_url": "https://arxiv.org/abs/2507.16004", "title": "使用强化学习进行量子退火的子图嵌入", "title_en": "Minor Embedding for Quantum Annealing with Reinforcement Learning", "authors": "Riccardo Nembrini,Maurizio Ferrari Dacrema,Paolo Cremonesi", "background": "量子退火（QA）是一种用于求解以二次未约束二元优化问题（QUBO）形式表述的组合优化问题的量子计算范式。子图嵌入是QA中的一个关键步骤，涉及将问题图映射到量子处理器的稀疏拓扑结构上。然而，这一过程计算上代价高昂且随着问题规模和硬件复杂性的增加而难以规模化。现有的子图嵌入启发式方法通常针对特定的问题图或硬件拓扑结构进行开发，难以一般化。因此，需要一种能有效针对不同问题和硬件的解决方案。", "innovation": "本文提出了一种使用增强学习（RL）解决子图嵌入问题的方法，具体采用了接近策略优化（PPO）算法。这种方法在两个硬件拓扑结构（Chimera和Zephyr）上测试了完全连接的问题图和随机生成的问题图的嵌入能力。结果表明，该代理能够生成有效且量子比特数量合理的子图嵌入，尤其是在较为现代的Zephyr拓扑上表现更佳。该方法还能够处理中等规模的问题，并适应不同的图结构，展示了RL作为灵活且通用的框架应用于QA中子图嵌入的巨大潜力。", "conclusion": "本研究提出了一种基于强化学习的方法来解决量子退火中的子图嵌入问题。通过使用PPO算法，代理成功解决了不同结构的问题图的嵌入问题，并且特别在现代Zephyr拓扑上表现突出。这一方法表明了RL在处理硬件和问题图变化时的灵活性和通用性，具有广阔的应用前景。"}
{"llm_update_time": "20250723", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.16260", "html_url": "https://arxiv.org/abs/2507.16260", "title": "ToFe: 延迟Token冻结和重用以实现高效的视觉变换器推理", "title_en": "ToFe: Lagged Token Freezing and Reusing for Efficient Vision Transformer Inference", "authors": "Haoyue Zhang,Jie Zhang,Song Guo", "background": "尽管视觉变换器(ViT)在各种视觉任务中展现出了显著的成功，但它们昂贵的自注意力机制限制了它们在资源受限设备上的部署。现有方法通过丢弃不重要的Token来提升变换器模型的效率，但这些方法使得这些Token不可逆地丢弃，无法在后续块中重用。由于变压器在不同块中关注不同信息，早期块中减少的Token可能在后期仍然有用。为了适应资源受限设备，必须在模型性能和计算开销之间取得平衡。", "innovation": "本文介绍了一种新颖的Token冻结和重用(ToFe)框架，该框架在每个阶段识别重要Token并暂时冻结不重要的Token，允许它们在后续阶段重新使用。通过设计Token识别模块和近似模块，以及与主干模型通过带有计算预算的端到端训练进行联合优化，ToFe能够适应性地处理每个块所需的Token，从而在降低计算成本的同时保持性能。", "conclusion": "广泛的实验表明，ToFe能在Top-1准确率下降不到2%的情况下将LV-ViT模型的计算成本降低50%，与最先进的方法相比实现了性能和复杂性之间的更好权衡。"}
{"llm_update_time": "20250723", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.16182", "html_url": "https://arxiv.org/abs/2507.16182", "title": "金融贷款风险预测中伪科学的影响", "title_en": "The Impact of Pseudo-Science in Financial Loans Risk Prediction", "authors": "Bruno Scarone,Ricardo Baeza-Yates", "background": "我们研究在简单应用机器学习进行金融贷款违约预测时所使用的伪科学假设的社会影响。这一应用场景还说明了生存偏差在贷款回报预测中的影响。我们在模型的准确性和社会成本方面进行分析，展示出在这一下游任务中，社会最优模型可能不产生显著的准确性损失。", "innovation": "我们的研究确认了常用的机器学习方法和数据集上的结果，还展示了在遭受生存偏差影响的模型中自然存在的一种动态，即准确性在训练过程中会略微下降，但召回率和精准率会随时间提高。这个结果给观察者造成了一个错觉，让他们误以为系统变得更好，而实际上模型变得越来越不公平并且带有生存偏差。", "conclusion": "社会最优模型可能不会显著减少准确性损失，但模型面临的生存偏差会随时间影响其性能，导致准确性下降而召回率和精准率上升，从而产生错觉认为系统性能提高，实际上模型的公平性在恶化。"}
{"llm_update_time": "20250723", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.16164", "html_url": "https://arxiv.org/abs/2507.16164", "title": "攻击可解释的NLP系统", "title_en": "Attacking interpretable NLP systems", "authors": "Eldor Abdukhamidov,Tamer Abuhmed,Joanna C. S. Santos,Mohammed Abuhamad", "background": "研究显示，机器学习系统在理论和实践中都受到对抗样本的攻击。虽然以往的攻击主要针对利用人机感知差异的视觉模型，文本模型也未能幸免于这些攻击。然而，这些攻击往往未能保持文本的意义和相似性。此前的研究集中在视觉模型上，而本文关注于文本处理模型的对抗攻击问题。", "innovation": "本文提出了AdvChar，这是一种针对可解释自然语言处理系统的黑盒攻击方法，旨在误导分类器的同时保持解释与良性输入的相似性。这种方法通过对文本输入进行较小、不明显的修改，迫使深度学习分类器产生错误预测但保持原始解释。AdvChar通过一种基于解释的评分方法，确定那些在变化后能使分类器错误分类的关键字。研究还展示了简单的字符级修改，以最小化原始文本与新文本之间的差异，同时生成与良性解释相似的对抗解释。该研究详细评估了AdvChar在七种NLP模型和三种解释模型上，使用基准数据集进行预测准确性的测试。", "conclusion": "我们的实验表明，通过在输入样本中修改平均两个字符，AdvChar可以显著降低当前深度学习模型的预测准确性。"}
{"llm_update_time": "20250723", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.16058", "html_url": "https://arxiv.org/abs/2507.16058", "title": "数据驱动的 Mori-Zwanzig 模型在湍流中拉格朗日颗粒动力学中的记忆需求", "title_en": "Is memory all you need? Data-driven Mori-Zwanzig modeling of Lagrangian particle dynamics in turbulent flows", "authors": "Xander de Wit,Alessandro Gabbana,Michael Woodward,Yen Ting Lin,Federico Toschi,Daniel Livescu", "background": "湍流中的拉格朗日颗粒动力学对于混合、输送和扩散过程至关重要，它们的轨迹表现出复杂的统计特性。因此，开发可以模仿这些轨迹的代理模型变得非常重要，而不必进行直接的欧拉场数值模拟，这会耗费大量计算资源。然而，现有的降阶模型通常无法访问与潜在湍流场的所有互动，这是该领域的一大挑战。为此，本研究采用了一种新的方法，利用 Mori-Zwanzig 正规化，使模型可以预测短时间内的点精度轨迹，并在长时间保持统计稳定性。", "innovation": "该研究提出了一种基于 Mori-Zwanzig 正规化的数据驱动机器学习方法，该方法通过训练可以学习到在短时间点精确进化湍流拉格朗日轨迹的动力学系统，并在长时间保持统计稳定性，即使在没有完全访问潜在湍流场信息的情况下也能准确反映复杂统计行为。这一方法的有效性在于通过使用点误差指标对短期预测进行训练，从而能够稳健地学习拉格朗日湍流的动力学。", "conclusion": "该方法为控制湍流中的主动拉格朗日代理提供了一种全新的应用前景。"}
{"llm_update_time": "20250723", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.16336", "html_url": "https://arxiv.org/abs/2507.16336", "title": "构建用于智能非晶合金设计的材料网络表示", "title_en": "Constructing material network representations for intelligent amorphous alloys design", "authors": "S.-Y. Zhang,J. Tian,S.-L. Liu,H.-M. Zhang,H.-Y. Bai,Y.-C. Hu,W.-H. Wang", "background": "设计高性能非晶合金对各种应用来说极具挑战性，但这一过程主要依赖于经验和无限的尝试。传统的策略由于高成本和低效率，无法有效探索巨大的材料空间。因此，需要一种新的方法来加速非晶合金的发现过程。传统的数据表示方法隐藏了一些潜在的材料候选者。通过分析不同年份合成的非晶合金，我们构建了动态材料网络来追踪合金发现的历史。发现了一些之前设计的创新型材料被编码在网络中，这证明了网络的预测能力对于指导新合金设计的重要性。此外，这些材料网络与我们日常生活中的一些实际网络表现出物理相似性。", "innovation": "提出构建材料网络来加速二元和三元非晶合金的发现。材料网络揭示了被传统表格数据表示法掩盖的材料候选者，通过动态构建材料网络跟踪合金发现的历史，发现过去设计的一些创新型材料被编码在网络中，展示出其预测能力，为进一步的智能材料设计提供了新途径，尤其是对于复杂合金的制备和设计。", "conclusion": "材料网络展示了与日常生活中某些实际网络的物理相似性。这项研究为智能材料设计开辟了新的方法，尤其是复杂合金的制备和设计。"}
{"llm_update_time": "20250723", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.16405", "html_url": "https://arxiv.org/abs/2507.16405", "title": "自我监督归纳逻辑编程", "title_en": "Self-Supervised Inductive Logic Programming", "authors": "Stassa Patsantzis", "background": "引|导逻辑程序|建构（ILP）方法，如元解释学习（MIL），能够通过少量例子学习递归逻辑程序，并生成适用于未见过的例子的一般性谓词。这种能力依赖于专门的背景理论和反例，需要特定领域的专家知识。但是，当没有特定的背景理论或反例时，如何进行这类学习成为新的挑战。", "innovation": "该研究提出了一种新的自我监督ILP框架，能够在没有特定背景理论或反例的情况下进行学习。它设计了一个新的MIL算法，能够在学习过程中自动生成并标注正例和反例。该算法被实现为Prolog中的Poker系统，并与现有的最先进的MIL系统Louise进行比较。此外，还提出了一种新的方法来选择第二阶背景理论，以实现这一目标。", "conclusion": "与Louise相比，Poker在生成足够多的自动生成的例子时，能够在学习语法时表现得更好。而在缺少反例的情况下，Louise会过度泛化。"}
{"llm_update_time": "20250723", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.16373", "html_url": "https://arxiv.org/abs/2507.16373", "title": "使用元学习方法获得多体哈密顿量的吉布斯态及其在量子玻尔兹曼机中的应用", "title_en": "Meta-learning of Gibbs states for many-body Hamiltonians with applications to Quantum Boltzmann Machines", "authors": "Ruchira V Bhat,Rahul Bhowmick,Avinash Singh,Krishna Kumar Sabapathy", "background": "量子辛普森态的制备是量子计算中的基本挑战，对于开放量子系统建模和量子机器学习等应用至关重要。Meta-Variational Quantum Eigensolver框架以及问题驱动的构造被用来设计两个元学习算法：Meta-Variational Quantum Thermalizer (Meta-VQT) 和 Neural Network Meta-VQT (NN-Meta VQT)，用于在Noisy Intermediate-Scale Quantum (NISQ) 设备上高效制备参量化哈密顿量的热态。", "innovation": "提出了两种新的元学习算法，Meta-Variational Quantum Thermalizer (Meta-VQT) 和 Neural Network Meta-VQT (NN-Meta VQT)，并强调了Meta-VQT使用全量子构造，而NN Meta-VQT结合了量子和经典架构。两种方法都利用集体优化训练集来泛化到未见过的参量的吉布斯态制备。实验验证了这些方法在不同大小系统的有效性，并展示了在大型系统中，元学习参数可以作为优化任务的预热初始化，显著优于随机初始化。这些算法应用于训练量子玻尔兹曼机（QBM）时实现了更高的训练效率和更准确的吉布斯态，同时与现有技术相比减少了30倍的运行时间。", "conclusion": "我们的工作证明了基于元算法的量子玻尔兹曼机的可扩展性和实用性。我们展示了我们的算法在不同大小系统中的表现，并强调了在训练量子玻尔兹曼机中的优越性。"}
{"llm_update_time": "20250723", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.16424", "html_url": "https://arxiv.org/abs/2507.16424", "title": "PromptAL: 样本感知动态软提示用于少量样本主动学习", "title_en": "PromptAL: Sample-Aware Dynamic Soft Prompts for Few-Shot Active Learning", "authors": "Hui Xiang,Jinqiao Shi,Ting Zhang,Xiaojie Zhao,Yong Liu,Yong Ma", "background": "主动学习（AL）旨在通过选择最具信息量的样本进行标注，来优化模型训练并降低标注成本。通常，AL方法依赖于已标注数据的经验分布来定义决策边界并进行不确定性或多样性的估计，从而识别潜在的高质样本。在少量样本场景下，经验分布通常与目标分布有显著偏差，导致决策边界偏离最优位置。现有方法往往忽略了未标注样本在改善经验分布以更好地与目标分布对齐方面的角色，从而导致决策边界次优并选择不足以代表目标分布的样本。因此，该论文旨在针对这一问题提出一种新的主动学习框架。", "innovation": "本文提出了一种结合了样本感知动态软提示的主动学习框架，称为PromptAL。该框架考虑了每个未标注数据点对当前经验分布与目标分布对齐的贡献，从而优化决策边界。具体而言，PromptAL 首先利用未标注数据构建样本感知动态软提示，调整模型的预测分布和决策边界，然后基于调整的决策边缘，结合全局和局部多样性进行不确定性估计，以选择更准确地代表目标分布的高质量样本。实验结果表明，PromptAL 在六个领域内数据集和三个领域外数据集上均优于九种基线方法。", "conclusion": "实验结果显示，在六领域内数据集和三个领域外数据集上，PromptAL 在九种基线方法中表现最佳。我们的代码库现在可以公开获取。"}
{"llm_update_time": "20250723", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.16427", "html_url": "https://arxiv.org/abs/2507.16427", "title": "结合图像数据增强减弱自适应标签平滑的效果", "title_en": "Combined Image Data Augmentations diminish the benefits of Adaptive Label Smoothing", "authors": "Georg Siedel,Ekagra Gupta,Weijia Shao,Silvia Vock,Andrey Morozov", "background": "该研究探讨了通过随机剪裁增强自适应标签平滑对监督学习过程的影响。现有的适应性标签平滑框架通过根据随机剪裁增强的幅度来降低训练样本的标签置信度来软化增强过程，增强了图像分类器的学习过程。本文将适应性标签平滑扩展到了随机擦除和噪声注入等其他激进的数据增强方法，并发现其在某些情况下效果显著，但在采用多样化的图像变换时，其效果会减弱，甚至可能损害模型对常见破坏的鲁棒性。", "innovation": "本文提出了将自适应标签平滑与随机擦除和噪声注入等其他激进的数据增强方法结合使用的方法，验证了这种结合增强的效果，并探讨了不同增强方法下的自适应标签平滑的效果差异，提出了适应性标签平滑应仅在训练数据分布主要由有限的、同质的图像变换类型支配时使用。", "conclusion": "研究发现，自适应标签平滑在训练数据包含多种类型的图像变换时效果较差，甚至可能损害模型对常见破坏的鲁棒性。因此，自适应标签平滑应仅在训练数据主要由一种类型的图像变换支配时使用。"}
{"llm_update_time": "20250723", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.16334", "html_url": "https://arxiv.org/abs/2507.16334", "title": "高级规范流模型", "title_en": "Higher Gauge Flow Models", "authors": "Alexander Strunk,Roland Assam", "background": "该论文提出了一种新型的生成流模型——高级规范流模型，该模型是在普通规范流模型（arXiv:2507.13414）的基础上发展而来。", "innovation": "高级规范流模型利用L$_{\finfty}$-代数扩展了Lie代数，实现了更高几何和更高对称性的集成，这些对称性与高阶群相关，从而在生成流模型框架中引入了这些复杂的对称性。", "conclusion": "对高斯混合模型数据集的实验评估显示，高级规范流模型相比传统的流模型取得了显著的性能提升。"}
{"llm_update_time": "20250723", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.16218", "html_url": "https://arxiv.org/abs/2507.16218", "title": "基于神经网络势能的全自动制药晶格结构预测协议", "title_en": "Toward Routine CSP of Pharmaceuticals: A Fully Automated Protocol Using Neural Network Potentials", "authors": "Zachary L. Glick,Derek P. Metcalf,Scott F. Swarthout", "background": "晶格结构预测（CSP）是制药发展中的一个有用工具，可用于识别和评估与多晶型相关的风险，但由于高昂的计算成本和需要手动指定以及专家知识以获得有用结果的需求，其广泛应用受到了阻碍。", "innovation": "本文介绍了首个全自动、高通量的CSP协议，通过专门设计和训练用于制药晶格结构生成和排序的Lavo-NN神经网络势能（NNP）来克服上述障碍。该协议将基于NNP的晶体生成阶段集成到可扩展的云工作流中，并通过广泛的回顾性基准测试对其有效性进行了验证。", "conclusion": "该CSP协议通过显著减少所需的时间和成本，使其能够更早地常规部署在药物发现过程中，如在先导优化阶段。快速周转时间和高通量特性也使得CSP能够与实验筛选同步进行，为化学家提供即时洞察以指导实验中的工作。"}
{"llm_update_time": "20250723", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.16242", "html_url": "https://arxiv.org/abs/2507.16242", "title": "轻量级且稳健的预测增强缓存设计", "title_en": "Toward a Lightweight and Robust Design for Caching with Predictions", "authors": "Peng Chen,Hailiang Zhao,Jiaji Zhang,Xueyan Tang,Yixuan Wang,Shuiguang Deng", "background": "在线缓存问题旨在在一个有限的缓存大小下，通过处理一系列请求来最小化缓存缺失。虽然简单的学习增强缓存算法可以达到理想的1-一致性，但它们缺乏稳健性保障。现有的增强方法要么牺牲1-一致性，要么引入显著的计算开销。", "innovation": "介绍了Guard框架，这是一个轻量级的稳健性增强框架，能够提升广泛类别学习增强缓存算法的稳健性至$2H_k + 2$，同时保持其1-一致性。Guard实现了当前最优的稳健性和一致性之间的平衡，每项请求仅增加$\textcal{O}(1)$的额外开销，从而维持基算法的时间复杂性。", "conclusion": "广泛实验证明，Guard在实际应用中具有良好的效果。"}
{"llm_update_time": "20250723", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.16431", "html_url": "https://arxiv.org/abs/2507.16431", "title": "一种用于预测波动场的有效物理知情神经操作符框架", "title_en": "An effective physics-informed neural operator framework for predicting wavefields", "authors": "Xiao Ma,Tariq Alkhalifah", "background": "波动方程的求解对于地质物理应用至关重要。然而，数值求解亥姆霍茨方程面临着巨大的计算和内存挑战。因此，提出了一个物理知情卷积神经操作符（PICNO），以高效地解决亥姆霍茨方程。PICNO 通过输入背景波动场（对应于均匀介质）和速度模型，生成散射波动场作为输出功能空间。该工作流程直接将偏微分方程约束纳入训练过程，使神经操作符不仅能够拟合可用数据，还能捕捉支配波动现象的潜在物理规律。", "innovation": "提出了一个物理知情卷积神经操作符（PICNO），将偏微分方程约束直接整合到训练过程中，使得神经操作符不仅能够适应现有数据，还能捕捉潜在的物理规律。此外，即使训练样本有限，PICNO 也能进行高精度的合理预测，相比纯粹数据驱动的卷积神经操作符（CNO），在预测高频波动场方面表现出显著优势.", "conclusion": "PICNO 允许以有限的训练样本进行高分辨率的合理预测，且在预测高频波动场方面展现出显著的优越性。这些特性和改进为后续的波动形反转奠定了重要基础。"}
{"llm_update_time": "20250723", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.16237", "html_url": "https://arxiv.org/abs/2507.16237", "title": "LLM-增强的补充性产品重新排序", "title_en": "LLM-Enhanced Reranking for Complementary Product Recommendation", "authors": "Zekun Xu,Yudi Zhang", "background": "补充性产品推荐旨在建议与主要产品一起使用的物品，以提升客户价值，这对电子商务来说是一项关键但具有挑战性的任务。现有的图神经网络（GNN）方法在捕捉复杂的产品关系方面取得了显著进展，但在准确性与多样性之间的权衡问题上，特别是在长尾商品方面，仍然存在困难。", "innovation": "本文提出了一种基于大型语言模型（LLMs）的模型无关方法，用于增强补充性产品推荐的重新排序，不同于以往主要利用LLMs进行数据预处理和图增强的方法，该方法直接使用LLMs策略对现有推荐模型检索到的候选物品进行重新排序，以提高推荐准确性和多样性，而无需重新训练模型。", "conclusion": "通过在公共数据集上的大量实验，本文表明该方法在补充性产品推荐中的准确性和多样性之间取得了有效的平衡，总体上在准确率指标上提高了至少50%，在多样性指标上提高了2%。"}
{"llm_update_time": "20250723", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.16321", "html_url": "https://arxiv.org/abs/2507.16321", "title": "基于物理驱动人工神经网络的电磁反散射问题求解", "title_en": "Physics-Driven Neural Network for Solving Electromagnetic Inverse Scattering Problems", "authors": "Yutong Du,Zicheng Liu,Bazargul Matkerim,Changyou Li,Yali Zong,Bo Qi,Jingwei Kou", "background": "近年来，基于深度学习的方法被提出用于解决反散射问题（ISPs），但大多数方法依赖于大量的数据且具有有限的泛化能力。", "innovation": "提出了一种新的解决方案，其中解决方案随着物理驱动的人工神经网络(PDNN)的更新而迭代更新，PDNN的超参数通过最小化包含已收集散射场约束及散射体先验信息的损失函数来优化。与依赖数据的人工神经网络求解器不同，PDNN仅需要输入收集的散射场数据和预测解相应的散射场计算，从而避免了泛化问题。此外，识别包含散射体的子区域以提高成像效率。", "conclusion": "数值和实验结果表明，所提出的方案在重建精度和稳定性方面表现出色，即使处理复合吸收散射体时也是如此。"}
{"llm_update_time": "20250723", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.16433", "html_url": "https://arxiv.org/abs/2507.16433", "title": "多任务学习在多部门投资组合优化中的自适应方法", "title_en": "Adaptive Multi-task Learning for Multi-sector Portfolio Optimization", "authors": "Qingliang Fan,Ruike Wu,Yanrong Yang", "background": "在涉及多种类大量资产的多部门投资组合优化中，跨部门准确转移信息以增强模型估计是至关重要的，但同时也极具挑战性。现有的因子建模框架下的数据处理方法无法有效量化并学习不同部门间的因子主时空子空间的关联性。这限制了多域因子模型同时估计的准确性和提高了多部门投资组合优化的需求，后者强烈依赖于这些因子模型的精确恢复。但目前的方法并未有效解决上述问题。本研究旨在提出一种新的数据自适应多任务学习方法，用于在多个部门进行因子模型之间相关性的识别和学习，以改善因子模型的估计和多部门投资组合优化。为此，研究人员开发了一种易于实现的多任务学习算法，称为投影惩罚主成分分析。", "innovation": "提出了数据自适应多任务学习方法，用于多部门投资组合优化优化。提出了易于实现的多任务学习算法--投影惩罚主成分分析，用于实现多任务学习过程。通过多任务学习方法，改进了因子模型的批量估计，并增强了多部门投资组合优化，后者严重依赖于这些因子模型的准确恢复。该方法在多种模拟设计和来自Russell 3000指数的日回报数据分析中得到了验证，展示了多任务学习方法的优势。这些研究结果进一步说明了该方法的有效性和稳健性。", "conclusion": "该研究通过提出数据自适应多任务学习方法和易实现的多任务学习算法，显著提高多部门因子模型的批量估计，优化了多部门投资组合，验证了该方法在实际数据中的有效性与优势。"}
{"llm_update_time": "20250723", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.16434", "html_url": "https://arxiv.org/abs/2507.16434", "title": "从基于模型的学习到基于行为的元解释学习", "title_en": "From model-based learning to model-free behaviour with Meta-Interpretive Learning", "authors": "Stassa Patsantzis", "background": "模型是一种用于描述环境状态和代理决策对环境影响的理论。基于模型的代理可以通过使用其模型来预测未来行为的效果并进行前瞻性规划。但此类代理必须知道环境状态。另一方面，基于行为的代理不能进行规划，但可以在没有模型和完全观察环境的情况下采取行动。在新型环境中的自主代理必须结合这两种能力。", "innovation": "我们展示了如何利用元解释学习来构建这样一种代理：使用基于模型的学习器（Solver）来训练基于行为的控制器（Controller）。这种控制器能够解决与学习器相同的问题。此研究还在两种环境类型上展示了代理解决问题的能力等效性：随机生成的迷宫和拥有开阔区域的湖泊地图。实验结果显示，Solver解决的所有导航问题Controller都能解决，表明两者具有等效性。", "conclusion": "基于模型的学习器（Solver）和基于行为的控制器（Controller）在解决网格导航问题时均具有等效性。这种结合了基于模型的学习和基于行为的行动的代理在新的环境中表现出自立行为，能够解决问题，指出这种代理架构是有效的。"}
{"llm_update_time": "20250723", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.16477", "html_url": "https://arxiv.org/abs/2507.16477", "title": "自适应贝叶斯单次量子传感", "title_en": "Adaptive Bayesian Single-Shot Quantum Sensing", "authors": "Ivana Nikoloska,Ruud Van Sloun,Osvaldo Simeone", "background": "量子传感器利用量子系统的独特性质，以超越经典传感器限制的精度测量时间、磁场、电场、加速度和重力梯度等物理量。然而，识别合适的传感探测器和测量方案是一个经典上难以解决的任务，需要在高维度的希尔伯特空间中进行优化。", "innovation": "本文介绍了一种自适应协议，使用贝叶斯推理来通过最大化主动信息增益优化传感策略。所提出的变化量子变分方法适用于非渐近环境中，每次只部署一个探测器，并扩展以支持多量子传感器估算结果的融合。", "conclusion": "该方法适用于非渐近框架，每次在一个时间步骤中部署一个探头，并扩展以支持多个量子传感器估算的融合，从而提高量子传感的准确性和效率。"}
{"llm_update_time": "20250723", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.16490", "html_url": "https://arxiv.org/abs/2507.16490", "title": "结合语言和主题模型进行层次文本分类", "title_en": "Combining Language and Topic Models for Hierarchical Text Classification", "authors": "Jaco du Toit,Marcel Dunaiski", "background": "层次文本分类（HTC）是一种自然语言处理任务，其目标是将文本文档归类到预定义结构层次中的一个或多个类别中。近年来，HTC方法使用各种技术将层次类结构信息与预训练语言模型（PLM）的自然语言理解能力相结合，以提高分类性能。此外，研究表明将主题模型与PLM结合起来从文本文档中提取特征对于多标签文本分类任务是有效的。结合这些特征提取模型的逻辑在于，PLM捕获细粒度的上下文和语义信息，而主题模型获得高层次的表示，这需要考虑整个文档集合。", "innovation": "本文提出了一种将PLM和主题模型结合用于HTC的方法。提取的特征通过独立的卷积层，输出然后合并并通过标签感知的注意机制，该机制为每个类别分别权衡最重要的特征。实验结果表明，相比仅使用PLM提取的特征，使用主题模型提取的特征在分类性能上通常较低。", "conclusion": "与以往工作不同，这表明对于文本分类任务，利用主题模型提取的特征通常不是有益的。"}
{"llm_update_time": "20250723", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.16518", "html_url": "https://arxiv.org/abs/2507.16518", "title": "C2-Evo: 共同进化跨模态数据和模型以实现自我改进的推理", "title_en": "C2-Evo: Co-Evolving Multimodal Data and Model for Self-Improving Reasoning", "authors": "Xiuwei Chen,Wentao Hu,Hanhui Li,Jun Zhou,Zisheng Chen,Meng Cao,Yihan Zeng,Kui Zhang,Yu-Jie Yuan,Jianhua Han,Hang Xu,Xiaodan Liang", "background": "近期，多模态大型语言模型（MLLMs）展现出了强大的推理能力。然而，要提高现有模型仍面临挑战，包括高质量且任务复杂度精细调整的视觉-语言数据集开发成本高、难以规模化，并且现有的自我改进模型虽然可以在数据和模型之间形成迭代优化，但通常存在两个核心问题：（1）现有的大多数方法是分别增强视觉或文本数据，导致数据复杂度不匹配，例如过于简单的图表配合冗余的文本描述；（2）数据进化和模型进化是分离的，模型在面对难度不匹配的任务时会表现不佳。", "innovation": "本文提出了一种自动的、闭环的自我改进框架 C2-Evo，旨在同时进化训练数据和模型能力。C2-Evo 简单来说，是通过一个跨模态数据进化循环和一个数据-模型进化循环进行数据和模型的迭代改进。前者通过生成组合了结构化文本子问题和逐步定义的几何图的复杂跨模态问题，扩展了原始数据集；后者则依赖基础模型的性能选择生成的问题，交替进行监督微调和强化学习，从而持续优化模型和训练数据，实现模型性能的显著提升。", "conclusion": "我们的方法在多个数学推理基准测试中持续提高了模型性能，并公开了我们的代码、模型和数据集。"}
{"llm_update_time": "20250723", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.16289", "html_url": "https://arxiv.org/abs/2507.16289", "title": "时间到划分：探索离线评估序列推荐器的数据划分策略", "title_en": "Time to Split: Exploring Data Splitting Strategies for Offline Evaluation of Sequential Recommenders", "authors": "Danil Gusak,Anna Volodkevich,Anton Klenitskiy,Alexey Vasilev,Evgeny Frolov", "background": "现代序列推荐系统，从轻量级的变压器变体到大型语言模型，因在下一个项目预测任务中的强大性能而在学术界和工业界变得更加突出。然而，序列推荐的常见评估协议仍然没有充分发展：它们往往不能准确反映相应的推荐任务，或与现实世界的情景不一致。尽管常用的拆分方法与下一个项目预测相符，但它允许训练期和测试期的重叠，导致时间泄漏和不切实际的长测试时间范围，限制了其在实际中的相关性。全球时间拆分通过在不同的未来时期进行评估解决了这些问题，但将其应用于序列推荐的方法仍然定义模糊，尤其是在选择目标交互和构建提供验证和测试度量一致性验证子集方面。", "innovation": "本文展示了不同拆分策略的结果存在显著差异，影响模型排名和实际部署决策。为提高学术和工业环境中的可重复性，本文系统地在多个数据集和公认的基础线的基础上比较了序列推荐的不同拆分策略。研究结果表明，常见的拆分方法，如拆一法，可能与更现实的评估策略不够一致。", "conclusion": "研究发现，常用的拆分方法可能不足以与更现实的评估策略对齐。因此，需要更系统和一致的数据拆分策略以提高序列推荐模型的评估准确性及其在实际应用中的适用性。"}
{"llm_update_time": "20250723", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.16534", "html_url": "https://arxiv.org/abs/2507.16534", "title": "实践中的前沿AI风险管理框架：一种风险管理技术报告", "title_en": "Frontier AI Risk Management Framework in Practice: A Risk Analysis Technical Report", "authors": "Shanghai AI Lab:Xiaoyang Chen,Yunhao Chen,Zeren Chen,Zhiyun Chen,Hanyun Cui,Yawen Duan,Jiaxuan Guo,Qi Guo,Xuhao Hu,Hong Huang,Lige Huang,Chunxiao Li,Juncheng Li,Qihao Lin,Dongrui Liu,Xinmin Liu,Zicheng Liu,Chaochao Lu,Xiaoya Lu,Jingjing Qu,Qibing Ren,Jing Shao,Jingwei Shi,Jingwei Sun,Peng Wang,Weibing Wang,Jia Xu,Lewen Yan,Xiao Yu,Yi Yu,Boxuan Zhang,Jie Zhang,Weichen Zhang,Zhijie Zheng,Tianyi Zhou,Bowen Zhou", "background": "随着人工智能（AI）模型的迅速发展，其带来的前所未有的风险日益凸显。为了理解和识别这些风险，本研究采用了前沿AI风险管理框架（v1.0）来评估风险，并引入了部署环境（E）、威胁源（T）、和使能能力（C）的分析方法。研究识别了七个关键风险领域，分别是网络进攻、生物和化学风险、说服与操纵、不受控制的自主AI研发、战略欺骗与阴谋、自我复制、以及共谋行为。", "innovation": "本研究创新地应用了前沿AI风险管理框架（v1.0）以及“人工智能-45°定律”，通过“红线”（不可接受的阈值）和“黄线”（早期预警指标）来划分风险区域，分别为绿色（可接受的风险）、黄色（需要加强预防和控制的部署）和红色（需要暂停开发和/或部署）。实验结果显示，所有近期的前沿AI模型均位于绿色和黄色区域，且没有越过红色区域。此外，研究区分了各领域模型的风险分布，例如在自我复制和战略欺骗与阴谋方面，大多数模型仍处于绿色区域，但在某些推理模型上则处于黄色区域。", "conclusion": "本研究体现了当前对前沿AI风险的理解，并呼吁采取集体行动以应对这些挑战。尽管在生物和化学风险领域仍需进行详尽的威胁建模和进一步评估，但研究结果表明大部分风险仍处于可控范围。"}
{"llm_update_time": "20250723", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.16548", "html_url": "https://arxiv.org/abs/2507.16548", "title": "Transformer模型评估中的替代损失函数", "title_en": "Alternative Loss Function in Evaluation of Transformer Models", "authors": "Jakub Michańków,Paweł Sakowski,Robert Ślepaczuk", "background": "在机器学习模型，尤其是应用于量化金融问题时，正确的设计和测试架构至关重要。在这个过程中，选择合适的损失函数用于训练、验证、估计和超参数调整是最重要的。本研究通过在股票和加密货币资产上的实证实验，介绍了一种更适合优化生成预测的模型（如算法投资策略中的模型）的损失函数——Mean Absolute Directional Loss (MADL)。", "innovation": "提出了适用于算法投资策略中预测生成模型的Mean Absolute Directional Loss (MADL)函数。将MADL函数应用于Transformer和LSTM模型，并通过比较实验结果，展示了几乎在所有情况下Transformer模型的表现都显著优于LSTM模型。", "conclusion": "MADL函数在优化预测生成模型方面比传统的损失函数更有效，特别是在应用到算法投资策略时。实验结果表明，Transformer模型在大多数情况下相比LSTM模型具有明显的优势。"}
{"llm_update_time": "20250723", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.16557", "html_url": "https://arxiv.org/abs/2507.16557", "title": "探索大型语言模型中的性别偏见：对德语语言的深入分析", "title_en": "Exploring Gender Bias in Large Language Models: An In-depth Dive into the German Language", "authors": "Kristin Gnadt,David Thulke,Simone Kopeinik,Ralf Schlüter", "background": "近年来，研究者提出了多种方法来评估大型语言模型（LLMs）中的性别偏见。然而，这些方法最初通常是在英语中开发的，应用于其他语言时面临着可迁移性的问题。这项研究旨在通过建立五个针对德语性别偏见评估的德语数据集，进一步研究这一研究领域。这些数据集基于已确立的性别偏见概念，并通过多种方法提供数据访问。基于八种多语言LLM模型的研究结果揭示了德语中性别偏见的独特挑战，包括职业术语中的模糊性别解读以及中性名词对性别感知的影响。这项研究促进了对跨语言LLMs中性别偏见的理解，并强调了定制化评估框架的重要性。", "innovation": "该研究提出了五个面向德语的性别偏见数据集，这些数据集基于已确立的概念，并且提供了多种数据访问方法，为其他语言的LLMs性别偏见研究提供了新的材料和技术支持。研究还系统分析了德语中性别偏见特有的挑战，提供了更全面的理解。研究强调了在不同语言环境中定制化偏见评估框架的需求，推动了相关领域的深入研究。", "conclusion": "该研究揭示了德语中性别偏见的特殊挑战，包括职业术语的模糊性别解读和中性名词对性别感知的影响。这为理解跨语境的LLMs性别偏见提供了新的视角，并强调了为各种语言环境量身定制偏见评估框架的重要性。"}
{"llm_update_time": "20250723", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.16623", "html_url": "https://arxiv.org/abs/2507.16623", "title": "自动细粒度分割辅助报告生成", "title_en": "Automatic Fine-grained Segmentation-assisted Report Generation", "authors": "Frederic Jonske,Constantin Seibold,Osman Alperen Koras,Fin Bahnsen,Marie Bauer,Amin Dada,Hamza Kalisch,Anton Schily,Jens Kleesiek", "background": "可靠的端到端临床报告生成一直是医学ML研究中的长期目标。这一过程的目的是减轻放射科医生的工作负担，并在临床医生或患者之间提供第二意见。因此，报告生成模型的一个必要前提是具有强大的通用性能和某种类型的内在定性能力，以使临床医生或患者相信生成报告的真实性。", "innovation": "本文提出了ASaRG（自动分割辅助报告生成）模型，这是对流行的LLaVA架构的扩展，旨在解决这两个问题。ASaRG提议将由专业放射学模型生成的中间特征和细粒度分割图融合到LLaVA的多模式投影层中，通过简单的串联。通过增加少量的参数，该方法在仅使用中间特征时，CE F1得分提高了0.89%（p=0.012），在添加组合中间特征和细粒度分割图时，提高了2.77%（p<0.001）。与另一种利用分割的报告生成方法COMG和ORID相比，F1得分的提升分别为6.98%和6.28%。ASaRG与LLaVA架构的其他更改不互相排斥，有可能与其他领域内的进展结合使用。此外，作为输入的一部分使用任意数量的分割能够清晰地追溯报告中的元素到对应的分割图，并验证评估的真实性。", "conclusion": "ASaRG不仅能够提高报告生成模型的性能，还能帮助确保生成报告的真实性和可信度。该方法为报告生成模型提供了增强的性能和更大的灵活性。"}
{"llm_update_time": "20250723", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.16410", "html_url": "https://arxiv.org/abs/2507.16410", "title": "GG-BBQ: 德语性别偏见基准问答数据集", "title_en": "GG-BBQ: German Gender Bias Benchmark for Question Answering", "authors": "Shalaka Satheesh,Katrin Klug,Katharina Beckh,Héctor Allende-Cid,Sebastian Houben,Teena Hassan", "background": "在自然语言处理（NLP）领域，公平性评估通常与偏见评估和减少相关伤害相关联。通常，这种评估是通过使用基准数据集来执行的，例如问答任务中的基准数据集，用于测量模型预测中的偏见，并从性别身份等多个维度进行评估。在这个工作中，作者使用Parrish等人（2022）的偏见基准数据集来评估德语大型语言模型（LLMs）中的性别偏见。特别是，在该英文数据集的性别身份子集中，模板被机器翻译成了德语，机器翻译中的错误经语言专家的手动审查和修正。这表明在为性别偏见评估创建数据集时，机器翻译从英语到如德语这样的有性语法的语言是有限制的，需要手动修正。", "innovation": "这项工作的创新之处在于将Parrish等人（2022）的基准数据集中的模板进行了机器翻译并经过语言专家的手动修正，创建了一个专门用于德语性别偏见评估的基准数据集（GG-BBQ），并评估了多种用于德语NLP的LLM的准确性和偏见得分。", "conclusion": "研究结果表明，所有模型在评估中都表现出性别偏见，这既与现有的社会刻板印象一致也有违背之处。这表明，为了更好地理解和克服语言模型中的性别偏见，有必要进一步改进数据集和模型训练方法。"}
{"llm_update_time": "20250723", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.16695", "html_url": "https://arxiv.org/abs/2507.16695", "title": "使用行随机化 DEDICOM 的可解释主题提取和词嵌入学习", "title_en": "Interpretable Topic Extraction and Word Embedding Learning using row-stochastic DEDICOM", "authors": "Lars Hillebrand,David Biesner,Christian Bauckhage,Rafet Sifa", "background": "DEDICOM 算法提供了一种独特的矩阵因子分解方法，适用于对称和非对称方形矩阵。本文使用对点互信息矩阵的新行随机化 DEDICOM 变体来识别词汇中的潜在主题聚类，并同时学习可解释的词嵌入。该方法通过有效训练受限 DEDICOM 算法并对其主题建模和词嵌入性能进行定性评估，使得这些嵌入更为实际和可理解。", "innovation": "引入了一种对受限 DEDICOM 算法进行高效训练的新方法，并使用对点互信息矩阵的新行随机化 DEDICOM 变体来识别词汇中的潜在主题聚类，同时学习可解释的词嵌入。", "conclusion": "通过有效训练受限 DEDICOM 算法，对主题建模和词嵌入性能进行了定性评估，提高了嵌入的解释性和实用性。"}
{"llm_update_time": "20250723", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.16438", "html_url": "https://arxiv.org/abs/2507.16438", "title": "The Sweet Danger of Sugar: Debunking Representation Learning for Encrypted Traffic Classification", "title_en": "The Sweet Danger of Sugar: Debunking Representation Learning for Encrypted Traffic Classification", "authors": "Yuqi Zhao,Giovanni Dettori,Matteo Boffa,Luca Vassio,Marco Mellia", "background": "最近，受到语言模型如BERT的启发，出现了大量利用表示学习模型来创建网络流量表示的方法。所有方法声称在加密流量分类任务上达到极高的准确性（高达98%）。但是，通过网络专家的视角，本文重新评估了这些方法，发现这些方法的成功很大程度上依赖于数据准备问题，使得这些模型在微调过程中能找到容易的捷径，即特征与标签之间的虚假相关性，从而过度提升了它们的表现。在实际场景中，这些捷径不存在，模型表现糟糕。", "innovation": "本文引入了Pcap-Encoder，一种基于语言模型的特征提取模型，专门设计用于从协议头部中提取特征。Pcap-Encoder是唯一提供实用表示模型的流量分类方法。尽管如此，其复杂性也使得它在实际应用中的适用性存疑。本研究揭露了数据集准备和模型训练中的缺陷，呼吁改进和更加谨慎的设计方法。并提出一种正确的评估方法，强调严格的基准测试的必要性。", "conclusion": "研究结果揭示了数据集准备和模型训练中的缺陷，建议设计更好的和更加严谨的测试。提出了正确的评估方法，并强调了严格的基准测试的需要。"}
{"llm_update_time": "20250723", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.16717", "html_url": "https://arxiv.org/abs/2507.16717", "title": "通过梯度下降进行多目标投资组优化", "title_en": "Multi-objective Portfolio Optimization Via Gradient Descent", "authors": "Christian Oliva,Pedro R. Ventura,Luis F. Lago-Fernández", "background": "传统投资组优化方法，通常基于现代投资组理论，通过二次规划或进化算法求解，但在处理复杂约束、大数据集或多个相互冲突的目标时面临可扩展性和灵活性的挑战。为此，本文提出了一个基于梯度下降和自动微分的多目标投资组优化基准框架，以应对上述挑战。该方法支持任何优化目标，如最小化风险度量（如CVaR）或最大化夏普比率，并且能够适应现实中的约束条件，如跟踪误差限制、UCITS规定或资产组限制。", "innovation": "提出了一种基于梯度下降和自动微分的多目标投资组优化方法，适用于任何优化目标和多种约束条件。该方法的创新之处在于提供了一个灵活性更强的工具，可以解决复杂的投资组优化问题，同时保持了与现行标准求解器相近的性能。", "conclusion": "研究成果展示了提出的多目标投资组优化方法在多种实验场景中的竞争力，并证明了其在模型多个目标和约束方面的增强灵活性。旨在提供一个实用且可扩展的工具，帮助研究人员和从业者在实际条件下探索高级投资组合优化问题。"}
{"llm_update_time": "20250723", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.16697", "html_url": "https://arxiv.org/abs/2507.16697", "title": "在exascale环境下像素级长上下文学习湍流：向粘性极限解析小尺度涡旋", "title_en": "Pixel-Resolved Long-Context Learning for Turbulence at Exascale: Resolving Small-scale Eddies Toward the Viscous Limit", "authors": "Junqi Yin,Mijanur Palash,M. Paul Laiu,Muralikrishnan Gopalakrishnan Meena,John Gounley,Stephen M. de Bruyn Kops,Feiyi Wang,Ramanan Sankaran,Pei Zhang", "background": "湍流在多物理应用中扮演着关键角色，包括航空航天、核聚变和燃烧等领域。准确捕捉湍流的多尺度特性对于可靠预测多物理相互作用至关重要，但即使是地球上最先进的超级计算机和先进的深度学习模型，这一挑战也尚未解决。要表示湍流所需的极端分辨率数据，范围从数十亿到数万亿个网格点，对基于视觉变换器等架构的模型构成了巨大的计算成本挑战。", "innovation": "引入了一个多尺度分层湍流变换器，将序列长度从数十亿缩短到数百万，并提出了一种新的环形X序列并行化方法，以实现可扩展的长上下文学习。在Frontier超级计算机上进行了扩展性和科学运行。该方法在32,768个AMD GPU上达到了每秒1.1 EFLOPS的性能，扩展效率为94%。据我们所知，这是第一个能够捕捉到消散范围以下的小尺度涡旋的AI模型。", "conclusion": "我们的方法在Frontier超级计算机上展示了卓越的性能，达到了每秒1.1 EFLOPS，扩展效率为94%，首次能够捕捉到湍流中小规模涡旋。"}
{"llm_update_time": "20250723", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.16467", "html_url": "https://arxiv.org/abs/2507.16467", "title": "使用独立成分分析估计治疗效果", "title_en": "Estimating Treatment Effects with Independent Component Analysis", "authors": "Patrik Reizinger,Lester Mackey,Wieland Brendel,Rahul Krishnan", "background": "因果推断领域发展了多种方法，在存在干扰因素的情况下准确估计治疗效果。同时，可识别理论领域发展了独立成分分析（ICA）等方法，用于从数据中识别潜在因素和混合权重。这两个研究领域虽然相互独立地发展，但都旨在实现准确和样本高效的模型参数估计。Mackey等人（2018）在部分线性回归（PLR）模型中发现，当治疗噪声非高斯时可以提高估计一致性，非高斯性也是ICA中识别潜在因素的关键假设。", "innovation": "本文提供了第一个关于ICA与因果效应估计之间联系的理论和实证见解，表明可以在PLR模型中使用ICA进行因果效应估计。研究出人意料地发现，即使存在高斯干扰或非线性干扰时，线性ICA也可以准确估计多种治疗效果。", "conclusion": "指出IC理论的Iằng分分析方法能够有效应用于因果关系模型，且即使在复杂干扰环境下也可实现多元治疗效果的精确估计，丰富了因果推断和可识别理论的应用场景。"}
{"llm_update_time": "20250723", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.16761", "html_url": "https://arxiv.org/abs/2507.16761", "title": "抗 aliasing 的 B-cos 网络实现可靠的胸部 X 射线诊断", "title_en": "Faithful, Interpretable Chest X-ray Diagnosis with Anti-Aliased B-cos Networks", "authors": "Marcel Kleinmann,Shashank Agnihotri,Margret Keuper", "background": "在医疗影像等安全关键领域中，深度神经网络（DNN）的应用依赖于其准确性和可解释性。B-cos网络通过替换标准线性层为权重-输入对齐机制，提供了一种能够生成内生的、类特定的解释的新方法，而不需要后处理方法。尽管B-cos模型在诊断性能上可与最先进的DNN媲美，但它们通常存在严重的aliasing伪影，使得在临床环境中，由于对清晰度的需求，它们无法使用。此外，原始的B-cos框架仅适用于多类设置，而胸部X射线分析往往需要多标签分类，因为多种异常可能并发。", "innovation": "这项工作旨在解决B-cos模型的两个主要限制：（1）通过FLCPooling（FLC）和BlurPool（BP）引入抗aliasing策略，显著提高了解释质量。（2）将B-cos网络扩展到支持多标签分类。我们的实验表明，修改后的B-cos_FLC和B-cos_BP在保持强预测性能的同时，能够提供忠实且无伪影的解释，非常适合多标签临床应用环境。", "conclusion": "我们的研究表明，改进的B-cos_FLC和B-cos_BP网络在胸部X射线数据集上表现出强大的预测性能和可靠且无伪影的解释，适用于临床应用的多标签设置。"}
{"llm_update_time": "20250723", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.16556", "html_url": "https://arxiv.org/abs/2507.16556", "title": "优化基于DNN的HSI分割FPGA架构：一种实用方法", "title_en": "Optimization of DNN-based HSI Segmentation FPGA-based SoC for ADS: A Practical Approach", "authors": "Jon Gutiérrez-Zaballa,Koldo Basterretxea,Javier Echanobe", "background": "HSI在自主导航领域的应用前景广阔，旨在提高基于视觉传感器的目标检测、跟踪和场景理解系统的精度和鲁棒性。结合先进的计算机算法（如DNNs）与小型快照HSI相机，可以增强这些系统的可靠性。HSI克服了灰度和RGB成像在表示目标物理性质方面的内在局限性，特别是在光谱反射率和同色异谱性方面。虽然HSI在基于视觉的开发中取得了令人鼓舞的结果，但类似于ADAS的安全部件需要严格的延迟、资源消耗和安全限制，驱动将ML任务转移至边缘平台的需求。这需要一个全面的软硬件协同设计方案，以在限制资源的计算平台上高效分配和优化任务。", "innovation": "该研究提出了一种用于ADAS的FPGA基于SoC上DNN驱动的HSI分割处理器的优化技术，包括功能性的软件/硬件任务分布、硬件感知预处理、ML模型压缩和完整的流水线部署。应用压缩技术显著降低了设计的DNN复杂性，减少了操作和参数的数量，实现了推理任务2.86倍的加速，同时保持了分割精度。", "conclusion": "通过合理的软硬件协同设计、高效的预处理和模型压缩，以及完整的流水线部署，本研究显著提高了基于FPGA的ADAS中DNN驱动的HSI分割系统性能。"}
{"llm_update_time": "20250723", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.16682", "html_url": "https://arxiv.org/abs/2507.16682", "title": "高维正则化线性判别分析的结构效应与谱增强", "title_en": "Structural Effect and Spectral Enhancement of High-Dimensional Regularized Linear Discriminant Analysis", "authors": "Yonghan Zhang,Zhangni Pu,Lu Yan,Jiang Hu", "background": "正则化线性判别分析（RLDA）是分类和降维中广泛应用的工具，但在高维场景中的性能不一致。现有关于RLDA的理论分析往往缺乏对数据结构如何影响分类性能的清晰见解。", "innovation": "本文推导了非渐近情况下错误分类率的近似值，分析了RLDA的数据结构效应及其结构调整策略，并提出了Spectral Enhanced Discriminant Analysis（SEDA）算法，通过调整总体协方差矩阵的尖峰特征值得以优化数据结构，随后通过随机矩阵理论的新理论结果建立了SEDA的渐近错误分类率近似值，进而获得了偏置校正算法和参数选择策略。", "conclusion": "实验结果表明，SEDA相比现有的LDA方法在分类准确性和降维效果上都取得了更高的表现。"}
{"llm_update_time": "20250723", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2212.14720", "html_url": "https://arxiv.org/abs/2212.14720", "title": "从数据流中学习：综述与更新", "title_en": "Learning from Data Streams: An Overview and Update", "authors": "Jesse Read,Indrė Žliobaitė", "background": "关于数据流中机器学习的文献虽多且增长迅速，但许多关键假设过于严格且在实际中难以维持，甚至相互矛盾。算法的选择和设计基于不清晰的标准，针对未定义的问题设置，在不现实的环境中进行测试，或孤立于相关文献中的方法。这引发了对这些方法在实际应用中潜力的质疑，并可能导致误导性的研究方向。本文旨在通过重新定义监督学习数据流的核心定义和问题设置，特别是在考虑概念漂移和时间依赖性的情况下，来应对这些问题。并重新审视监督数据流学习任务的本质以及可能的解决方案。这项研究通过正式调研工业界处理实际数据流的参与者来提供建议，强调数据流学习不应局限于单次通过或在线学习方法，任何关于内存和时间的限制都不特定于流式数据，同时指出解决时间依赖性和概念漂移的技术已在其他文献中有所讨论。对于数据流社区，建议研究重点应从处理学习模式的往往人为设定的限制和假设转向，在学术和工业环境中越来越重要的健壮性、隐私和可解释性等问题。", "innovation": "重新定义监督学习数据流的核心定义和问题设置，并考虑概念漂移和时间依赖性，以提供一个更现实且有效的研究方向。建议解决健壮性、隐私性和可解释性等问题，而非处理通常人为设定的约束和假设。", "conclusion": "从数据流中学习不应局限于单次通过或在线学习方法，任何关于内存和时间的限制也不特定于流式数据。已经存在一些技术可以应对时间依赖性和概念漂移。鼓励数据流社区的研究重点转向健壮性、隐私性和可解释性等领域，这些领域在学术和工业环境中越来越重要。"}
{"llm_update_time": "20250723", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.16815", "html_url": "https://arxiv.org/abs/2507.16815", "title": "ThinkAct: 通过强化视觉潜在规划的视觉语言行动推理", "title_en": "ThinkAct: Vision-Language-Action Reasoning via Reinforced Visual Latent Planning", "authors": "Chi-Pin Huang,Yueh-Hua Wu,Min-Hung Chen,Yu-Chiang Frank Wang,Fu-En Yang", "background": "视觉语言行动（VLA）任务要求代理解读多模态指令，进行长时规划，并在动态环境中灵活行动。现有的方法通常采用端到端的方式训练VLA模型，直接将输入映射为动作，而不进行显式的推理，这限制了它们进行多步规划或应对复杂任务变化的能力。", "innovation": "提出了一种双系统框架ThinkAct，通过强化视觉潜在规划连接高层次推理与低层次动作执行。它训练一个多模态LLM生成由行动对齐的视觉奖励指导的嵌入式推理计划，然后将这些推理计划压缩为视觉计划潜在状态，以指导下游动作模型进行稳健的行动执行。实验表明ThinkAct使模型具备少量样本适应、长时规划和自纠正行为等复杂的人工智能任务能力。", "conclusion": "广泛的实验在各类环境中的测度显示，ThinkAct能够实现对复杂的人工智能任务的少量样本适应、长时规划以及自纠正行为等功能。"}
{"llm_update_time": "20250723", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2403.12938", "html_url": "https://arxiv.org/abs/2403.12938", "title": "通过算子分裂学习神经微分代数方程", "title_en": "Learning Neural Differential Algebraic Equations via Operator Splitting", "authors": "James Koch,Madelyn Shapiro,Himanshu Sharma,Draguna Vrabie,Jan Drgona", "background": "微分代数方程（DAEs）用于描述既符合微分约束又符合代数约束的系统的时间演变。特别关注的是包含组件之间隐式关系的系统，例如守恒定律。本文提出了一种通过算子分裂（OS）数值积分方案从时间序列数据中学习DAEs的未知组件的方法。实验表明该方法在噪声下的鲁棒性和外推能力，能够在学习系统组件行为及其相互作用的物理规律以及区分数据趋势和系统中的机制关系方面发挥作用。", "innovation": "提出了通过算子分裂实现的数值时间步进方案，用于从时间序列中学习DAEs的未知部分，特别适用于系统理论的数据驱动建模任务。通过算子分裂方法解决了冗余变量的消去，使得可以直接求解DAE问题，同时通过梯度下降解决优化问题，提高了学习的效率和准确性。", "conclusion": "实验结果表明，所提出的方法在处理噪声和外推方面表现出良好的鲁棒性，可以学习系统的组件行为及其相互作用物理规律，并能够区分数据趋势与系统中的机制关系，为复杂系统建模提供了新的思路。"}
{"llm_update_time": "20250723", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.16812", "html_url": "https://arxiv.org/abs/2507.16812", "title": "MegaScience: 推动科学推理后训练数据前沿", "title_en": "MegaScience: Pushing the Frontiers of Post-Training Datasets for Science Reasoning", "authors": "Run-Ze Fan,Zengzhi Wang,Pengfei Liu", "background": "科学推理对于培养AI科学家和推动自然科学发现前沿至关重要。然而，开源社区主要关注于数学和编程，而忽视了科学领域，这主要是因为缺乏开放、大规模、高质量、可验证的科学推理数据集。为了弥合这一差距，该研究首先推出了TextbookReasoning数据集，这是一个包含从12000本大学科学教科书中提取的真实答案的开放数据集，共有650,000个科学推理问题，覆盖7个科学领域。研究者还引入了MegaScience，这是一个由125万个高质量开源数据集组成的大型混合数据集，通过系统的方法消融研究评估各种数据选择方法，以确定每个公开可用科学数据集的最佳子集。与此同时，研究者建立了涵盖15项基准的全面评估系统，涉及多样化的主题和问题类型，并采用全面的答案提取策略确保准确的评估指标。", "innovation": "该研究的主要创新在于推出TextbookReasoning和MegaScience两个数据集，填补了科学推理数据的空白。MegaScience通过系统的方法消融研究确定了最优的子集，显著提高了数据集的性能和训练效率。研究还证明，MegaScience对更大更强的模型更为有效，具有规模扩增的优势。此外，研究者发布了数据整理管道、评估系统、数据集及七个训练模型，以促进科学推理研究的发展。", "conclusion": "实验结果表明，MegaScience数据集在响应长度更短的情况下实现了与现有开源科学数据集相比更优的性能和训练效率。基于MegaScience训练的Llama3.1、Qwen2.5和Qwen3系列模型在平均性能方面大幅优于相应的官方指令模型。MegaScience还对更大更强的模型表现出更好的效果，显示出在科学推理中的规模扩增效应。"}
{"llm_update_time": "20250723", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2403.07842", "html_url": "https://arxiv.org/abs/2403.07842", "title": "DP-TLDM: Differentially Private Tabular Latent Diffusion Model", "title_en": "DP-TLDM: Differentially Private Tabular Latent Diffusion Model", "authors": "Chaoyi Zhu,Jiayi Tang,Juan F. Pérez,Marten van Dijk,Lydia Y. Chen", "background": "合成数据来自生成模型被视为隐私保护的数据共享解决方案。合成数据集应与原始数据相似，但不泄露可识别的私人信息。目前，研究主要集中在有限类型的表格合成器和少数几种隐私攻击上，特别是针对生成对抗网络（GAN）的攻击，而忽略了成员推理攻击及其防御策略，如差分隐私（DP）。文章提到，合成数据表需要同时保持高数据质量和低隐私风险的困境，已经有一些研究试图解决这一问题，但并未提出一个全面解决的方法。", "innovation": "提出了DPTLDM模型，Differentially Private Tabular Latent Diffusion Model，该模型包含一个自动编码器网络来编码表格数据，以及一个潜态扩散模型来合成潜态表格。DPTLDM采用了f-DP框架中的DP-SGD训练自动编码器，结合批处理裁剪，并使用分隔值作为隐私度量，更好地捕捉DP算法提供的隐私增益。实验结果表明，DPTLDM在实现有意义的理论隐私保证的同时，也显著提高了合成数据的实用性。具体而言，相比于其他受DP保护的表格生成模型，DPTLDM在数据相似性、下游任务的实用性及数据可区分性上的提升分别达到了平均35%、15%和50%，同时保持了相当水平的隐私风险。", "conclusion": "DPTLDM能够在提供更多实用性的基础上实现有效的隐私保护，为高数据质量和低隐私风险之间的平衡提供了一个新的解决方案。"}
{"llm_update_time": "20250723", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.16678", "html_url": "https://arxiv.org/abs/2507.16678", "title": "用于非线性多频率电感应阻断层成像的深层展开网络", "title_en": "Deep Unfolding Network for Nonlinear Multi-Frequency Electrical Impedance Tomography", "authors": "Giovanni S. Alberti,Damiana Lazzaro,Serena Morigi,Luca Ratti,Matteo Santacesaria", "background": "多频率电感应阻抗成像（mfEIT）是一种有前景的生物医学成像技术，可以估计不同频率下的组织导电性。然而，实现这一目标是一项挑战。", "innovation": "提出了一种新的变分网络，该网络是基于模型的学习框架，它结合了经典迭代重建法的优势和解释性与深度学习的强大力量。通过图神经网络（GNN）将梯度近似正则化高斯-牛顿（PRGN）算法展开，保留了非线性前向模型求解所用的不规则三角网格结构，从而捕捉频率间相关性并实现精确的组织浓度重建。", "conclusion": "该方法通过将PRGN算法的每次迭代作为网络层来展开，结合了非线性模型拟合的物理洞察力和GNN捕捉频率间相关性的能力，实现了组织导电性的高精度重建。"}
{"llm_update_time": "20250723", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2407.00494", "html_url": "https://arxiv.org/abs/2407.00494", "title": "图神经网络异步失控：GNN失去控制", "title_en": "Graph Neural Networks Gone Hogwild", "authors": "Olga Solodova,Nick Richardson,Deniz Oktay,Ryan P. Adams", "background": "图神经网络（GNNs）在分布式、去中心化的多智能体系统中是强大的工具，但当在推理过程中节点异步更新时会产生灾难性的错误预测。这种异步下的失败排除了这些架构在许多难以或不可能强制同步的应用中的潜在应用，例如机器人蜂群或传感器网络。", "innovation": "本文识别出一类具有“隐式定义”的GNN架构，证明其在异步“异步更新（hogwild）”推理中具有稳健性，还提出了一种新型的递归“隐式定义”GNN架构，称为“能量GNN”。", "conclusion": "发现这种架构在各种由多智能体系统启发的合成任务上优于同一类的其他GNN架构。"}
{"llm_update_time": "20250723", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2407.17029", "html_url": "https://arxiv.org/abs/2407.17029", "title": "通过优化平衡实现量化大型语言模型的准确且高效微调", "title_en": "Accurate and Efficient Fine-Tuning of Quantized Large Language Models Through Optimal Balance", "authors": "Ao Shen,Qiang Wang,Zhiquan Lai,Xionglve Li,Dongsheng Li", "background": "大型语言模型（LLMs）在诸多领域表现出色，但其庞大的模型参数数量使得微调变得具有挑战性，严重限制了它们的推广应用。现有解决方案通过结合参数量化与低秩适应（LoRA）来减少内存使用，但会引发性能下降。将微调后的模型转换为低精度表示将进一步降低性能。微调量化后的LLM与LoRA之间存在不平衡：过于复杂且低效的适配器输入输出导致微调时出现欠拟合现象。", "innovation": "该论文提出了一种新的方法，Quantized LLMs细调与平衡低秩适应（Q-BLoRA），以简化适配器的输入输出，并增加适配器的秩以缓解微调时的欠拟合问题。此外，提出了一种Quantization-Aware细调与平衡低秩适应（QA-BLoRA），该方法与块量化对齐，并基于Q-BLoRA的参数合并促进低秩适配的量化感知细调。这两者均容易实现，并提供了以下优化：(i) Q-BLoRA在与基线和其他变体相比时始终实现最先进的准确度；(ii) QA-BLoRA能够直接生成低精度推理模型，这些模型相较于其他低精度模型在性能上表现出显著的改进。", "conclusion": "该研究有效地解决了量化大型语言模型微调中的性能和效率问题。Q-BLoRA和QA-BLoRA两种方法在多项模型和场景中均得到了验证，研究成果已通过代码提供。"}
{"llm_update_time": "20250723", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2408.08655", "html_url": "https://arxiv.org/abs/2408.08655", "title": "FLAIN: 通过低激活输入神经元权重更新翻转缓解联邦学习中的后门攻击", "title_en": "FLAIN: Mitigating Backdoor Attacks in Federated Learning via Flipping Weight Updates of Low-Activation Input Neurons", "authors": "Binbin Ding,Penghui Yang,Sheng-Jun Huang", "background": "联邦学习（FL）允许多个客户端在中央服务器的协调下协作训练机器学习模型，同时保持隐私。然而，中央服务器无法直接监控客户端的本地训练过程，这为恶意客户端引入后门攻击留下了空间。研究表明，后门攻击利用特定的神经元在恶意输入时被激活，在干净数据上则保持不活跃。项目基于这一洞察，提出了一个新的防御方法：低激活输入神经元权重更新翻转（FLAIN），以对抗FL中的后门攻击。通过在全球训练完成后使用辅助数据集识别低激活输入神经元，并逐步翻转它们相关的权重更新，直到模型在辅助数据上的表现显著下降，以此来减少后门攻击的成功率。实验展示，FLAIN能够有效降低各种场景下的后门攻击成功率，包括非独立同分布（Non-IID）数据分布和高恶意客户端比率（MCR），同时对干净数据的影响最小。", "innovation": "FLAIN 方法通过研究特定神经元在不同条件下的行为，提出了一种新的防御策略——低激活输入神经元权重更新翻转，以有效减少后门攻击的成功率，同时保持对正常数据的影响极小。这种方法在广泛的后门攻击场景中表现出了有效性，特别是在非独立同分布数据和高恶意客户端比率的情况下。", "conclusion": "研究证明，FLAIN 方法能够显著减少后门攻击的成功率，特别是在不同分布的数据和高恶意客户端比率的情况下，同时保持对干净数据的性能影响较小。"}
{"llm_update_time": "20250723", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.16802", "html_url": "https://arxiv.org/abs/2507.16802", "title": "Agentar-Fin-R1: 通过领域专业知识、训练效率和先进推理增强金融智能", "title_en": "Agentar-Fin-R1: Enhancing Financial Intelligence through Domain Expertise, Training Efficiency, and Advanced Reasoning", "authors": "Yanjun Zheng,Xiyang Du,Longfei Liao,Xiaoke Zhao,Zhaowen Zhou,Bo Zhang,Jiawei Liu,Xiang Qi,Zhe Li,Zhiqiang Zhang,Wang Wei,Peng Zhang", "background": "大型语言模型（LLMs）在金融领域的应用潜力巨大，但现有模型在需要强大的推理能力、严格的可信度要求以及高效适应特定任务需求的场景中往往表现不足。现有的金融LLMs在应对这些需求时往往存在局限性。", "innovation": "作者基于Qwen3基础模型，开发了Agentar-Fin-R1系列金融大语言模型（8B和32B参数），特别通过提高推理能力、可靠性和领域专业化来增强金融应用中的性能。优化方法结合了高质量的系统性金融任务分类、多层次的信任保障框架，涵盖高质量可信知识工程、多智能体可信数据合成以及严格的数据验证治理。通过标签导向的自动化难度感知优化、两阶段学习过程以及详细的责任追溯系统，提高了训练效率。该模型通过在主流金融基准（如FinEva、FinEval和FinanceIQ）及通用推理数据集（如MATH-500和GPQA）上进行全面评估。为全面评估实际情况部署能力，创新性地提出了Finova评估基准，该基准关注代理级别的金融推理和合规验证。实验结果表明，Agentar-Fin-R1不仅在金融任务上取得了最先进的性能，还在通用推理能力上表现出色，验证了其作为高风险金融应用中的可信解决方案的有效性。", "conclusion": "基于域专业知识、高效训练和先进推理，Agentar-Fin-R1在金融任务上实现了最先进的性能，并展现了出色的通用推理能力，验证了其作为高风险金融应用中的可信解决方案的有效性。"}
{"llm_update_time": "20250723", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2405.17527", "html_url": "https://arxiv.org/abs/2405.17527", "title": "Unisolver: PDE-Conditional Transformers Are Universal PDE Solvers", "title_en": "Unisolver: PDE-Conditional Transformers Are Universal PDE Solvers", "authors": "Hang Zhou,Yuezhou Ma,Haixu Wu,Haowen Wang,Mingsheng Long", "background": "神经网络模型近年来作为求解偏微分方程（PDEs）的有力工具崭露头角，被称为神经PDE求解器。虽然这些神经求解器可以通过仿真数据或物理信息损失进行训练，能够在一定程度上解决PDEs，但由于其主要针对特定类型的PDEs进行训练，如具有一组有限系数的特定方程，这限制了其对多样化的PDEs的泛化能力，阻碍了其作为数值求解器的替代模型的实际应用。", "innovation": "本文提出了一个名为Unisolver的新颖Transformer模型，该模型专注于多样化的数据和不同的PDEs进行训练，目标是构建一个多功能的神经PDE求解器，能够解决广泛的PDEs。Unisolver通过理论分析PDE求解过程的方式，不同于单纯扩大数据和参数规模。它通过借鉴偏微分方程的数学结构，将一系列PDE组件如方程符号和边界条件定义为域间和点间深度条件，灵活嵌入Transformer PDE求解器中。将物理洞察与最近的Transformer技术进步相结合，Unisolver在三个具有挑战性的大规模基准测试中表现出一致的SOTA性能，并展示了卓越的性能和泛化能力。", "conclusion": "Unisolver在三个具有挑战性的大规模基准测试中展示了令人印象深刻的表现和泛化能力，证明了PDE-条件Transformer可以作为通用的PDE求解器。"}
{"llm_update_time": "20250723", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.16642", "html_url": "https://arxiv.org/abs/2507.16642", "title": "使用大型语言模型实现财务审计中的自动化合规验证", "title_en": "Towards Automated Regulatory Compliance Verification in Financial Auditing with Large Language Models", "authors": "Armin Berger,Lars Hillebrand,David Leonhard,Tobias Deußer,Thiago Bell Felix de Oliveira,Tim Dilmaghani,Mohamed Khaled,Bernd Kliem,Rüdiger Loitz,Christian Bauckhage,Rafet Sifa", "background": "财务文件的审计历史上是一个劳动密集型的过程，近年来，AI驱动的解决方案正在逐步改善这一过程，通过从财务报告中推荐相关文本段落来与会计标准的法律要求对齐。然而，这些系统的一个明显局限是它们通常无法验证推荐的摘录是否确实符合具体的法律规定。因此，本文研究了公开可用的大语言模型（LLMs）在不同模型配置下的合规性效率，特别是在监管合规领域的应用。研究重点比较了开源的大型语言模型，如Llama-2，与开源竞争者，如OpenAI的GPT模型，使用普华永道德国分公司提供的两套定制数据集进行分析。", "innovation": "本文的研究利用开源的Llama-2 70亿参数模型在检测合规性错误或真阴性方面表现出色，超越了所有其私有竞争对手。同时，作者也发现私有模型如GPT-4在某些场景下表现更佳，尤其是在非英语环境下。", "conclusion": "开源的Llama-2 70亿参数模型在检测财务审计中的合规性问题方面具有显著优势。然而，对于各种场景尤其是非英语语境，私有模型如GPT-4表现更佳。通过这样的研究，可以为未来的财务审计自动化工具选择提供依据。"}
{"llm_update_time": "20250723", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2310.07497", "html_url": "https://arxiv.org/abs/2310.07497", "title": "通过样本驱动控制实现联邦连续学习的节能和实时感知", "title_en": "Energy-Efficient and Real-Time Sensing for Federated Continual Learning via Sample-Driven Control", "authors": "Minh Ngoc Luu,Minh-Duong Nguyen,Ebrahim Bedeer,Van Duc Nguyen,Dinh Thai Hoang,Diep N. Nguyen,Quoc-Viet Pham", "background": "智能实时感知系统需要不断获取、更新、整合和应用知识以适应实际动态环境。在这种分布式智能管理的情境中，联邦持续学习（FCL）是一个关键需求。然而，如何有效地捕捉RTS数据的多样性特征带来了重大挑战，包括加重计算和通信资源的负担，增加能源成本，最终导致整体系统性能下降。", "innovation": "该研究通过利用泛化差距的概念，探索数据分布在理想与实际RTS场景之间的转移如何影响AI模型的性能。提出了一种名为样本驱动控制联邦持续学习（SCFL）的新技术，特别设计用于具有RTS功能的移动边缘网络。SCFL通过优化采样过程，同时最小化泛化差距并提高整体准确率，维持FCL框架的能量效率。此外，还引入了一种具有显式和隐式约束的新软学习者-评论家算法（A2C-EI），以解决高度复杂且时间变化的优化问题。", "conclusion": "实验结果表明，通过SCFL技术可以实现更高的效率，相对于其他深度强化学习基准方法具有优势。特别地，SCFL能够显著降低高达85%的能源消耗，同时保持FCL收敛性和及时的数据传输。"}
{"llm_update_time": "20250723", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.16746", "html_url": "https://arxiv.org/abs/2507.16746", "title": "Zebra-CoT: 一种用于交错视觉语言推理的数据集", "title_en": "Zebra-CoT: A Dataset for Interleaved Vision Language Reasoning", "authors": "Ang Li,Charles Wang,Kaiyu Yue,Zikui Cai,Ollie Liu,Deqing Fu,Peng Guo,Wang Bill Zhu,Vatsal Sharan,Robin Jia,Willie Neiswanger,Furong Huang,Tom Goldstein,Micah Goldblum", "background": "人类在解决复杂问题时会使用视觉辅助工具，如图表或草图。将这种能力训练到多模态模型中被称为视觉链式思考（Visual CoT），但由于现成的视觉CoT性能不佳，限制了强化学习的应用，并且缺乏高质量的视觉CoT训练数据，因此这非常具有挑战性。", "innovation": "作者提出了一种名为Zebra-CoT的大型多样化的数据集，包含182,384个样本，覆盖了具有视觉推理和草图绘制自然性的四个类别任务。这些包括科学问题（如几何学、物理学、算法），二维视觉推理任务（如视觉搜索和拼图）以及三维推理任务（如三维多跳推理、体感和机器人规划）。利用Zebra-CoT对Anole-7B模型进行微调，提高了测试准确度，并在标准多模态模型基准测试中表现出高达13%的性能增益。对Bagel-7B模型的微调结果显示出生成高质量的视觉推理链式结构的能力。", "conclusion": "作者开源了他们的数据集和模型，以便支持视觉CoT的开发和评估。"}
{"llm_update_time": "20250723", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2501.05494", "html_url": "https://arxiv.org/abs/2501.05494", "title": "软计算方法在预测热应激条件下奶牛避暑行为中的应用：随机森林和神经网络的比较研究", "title_en": "Soft Computing Approaches for Predicting Shade-Seeking Behaviour in Dairy Cattle under Heat Stress: A Comparative Study of Random Forests and Neural Networks", "authors": "S. Sanjuan,D. A. Méndez,R. Arnau,J. M. Calabuig,X. Díaz de Otálora Aguirre,F. Estellés", "background": "在地中海气候下，热应激是影响奶牛福利和生产效率的主要问题之一。本研究通过非线性多元回归方法预测奶牛每日避阴行为的频率，并在西班牙瓦伦西亚蒂加瓦斯一家牧场2023年夏季收集的高分辨率行为和微气候数据上训练两种软计算算法——随机森林和神经网络。", "innovation": "本研究采用了非线性多元回归方法来预测奶牛每日避阴行为的频率，并通过两种软计算算法（随机森林和神经网络）进行训练。研究使用5折交叉验证评估模型性能，并且结果显示这两种软计算模型优于单一决策树模型。最优化的神经网络模型（3隐层，每层16个神经元，学习率为10e-3）达到了平均RMSE为14.78的效果，而随机森林模型（10棵树，深度为5）表现接近，但具有更好的可解释性。", "conclusion": "研究结果表明，软计算和数据驱动的方法适合作为模型描述嘈杂的生物现象，并证明了在热应激条件下实时低投入支持精准奶牛养殖的应用价值。"}
{"llm_update_time": "20250723", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2411.18425", "html_url": "https://arxiv.org/abs/2411.18425", "title": "简化贝叶斯深度学习中的预测", "title_en": "Streamlining Prediction in Bayesian Deep Learning", "authors": "Rui Li,Marcus Klasson,Arno Solin,Martin Trapp", "background": "贝叶斯深度学习（BDL）近年来引起了广泛的关注，导致了估计后验分布方法的众多发展。然而，在进行有效推断（如预测）方面的计算仍被忽视，蒙特卡洛积分依然是标准的计算方法。本文旨在通过单一前向传播实现BDL中的预测优化，而无需抽样。为此，本文采用激活函数的局部线性化及线性层的局部高斯近似，从而使后验预测分布的解析计算成为可能。该方法被用于多层感知机（MLP）和变换器，如ViT和GPT-2，并在其回归和分类任务上进行了评估。开源库：详见链接（由于原文中出现了网址链接，此处省略）", "innovation": "本文的创新点在于通过单一的前向传播路径实现无抽样预测，采用局部线性化激活函数和局部高斯近似线性层，从而能够解析计算后验预测分布。这一方法被应用于不同的深度学习模型和任务类型，展示了其在回归和分类任务中的应用前景", "conclusion": "本文通过对BDL预测流程的简化，提出了新的计算方法，该方法不仅提高了预测效率，而且在实际任务中表现出良好的性能。"}
{"llm_update_time": "20250723", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2402.14922", "html_url": "https://arxiv.org/abs/2402.14922", "title": "知识蒸馏在预训练模型中的实用见解", "title_en": "Practical Insights into Knowledge Distillation for Pre-Trained Models", "authors": "Norah Alballa,Ahmed M. Abdelmoniem,Marco Canini", "background": "本研究探讨了预训练模型中知识蒸馏（KD）过程的提升，这是一个在知识迁移领域中逐渐崛起的领域，对分布式训练和联邦学习环境有重要影响。这些环境可以通过减少通信需求来实现，并能适应各种模型架构。尽管已经采用了多种KD方法来在预训练模型之间进行知识转移，但对这些场景中KD应用的全面理解仍然不足。整个研究对多种KD技术进行了广泛的对比分析，包括标准KD、通过优化温度和权重参数的调优KD、深度互学习和数据分区KD。研究在各种数据分布策略下评估这些方法，以确定每种方法的最有效应用场景。通过对超参数调优的详尽分析，基于广泛的网格搜索评估，研究人员确定了哪些调整对提升模型性能至关重要。研究揭示了在不同数据分区场景中最佳超参数设置，并探讨了通过减少通信轮数和加速训练过程来在联邦学习中提升KD的作用。", "innovation": "本研究对多种KD技术进行了广泛的对比分析，特别是在不同的数据分布策略下评估这些方法的有效性，并通过详尽的超参数调优分析，揭示了最佳的超参数设置，填补了当前研究中的空白。这些发现为如何在协作和联邦学习框架中利用KD提供了实用的指导。", "conclusion": "通过细致的超参数调优和广泛的实验评估，本研究明确了KD在特定数据分区场景下的最佳设置，并论证了KD在联邦学习中减少通信需求和加速训练过程的有效性，为预训练模型在联邦学习和协作学习框架中的应用提供了实用框架。"}
{"llm_update_time": "20250723", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2505.04604", "html_url": "https://arxiv.org/abs/2505.04604", "title": "特征选择和极简问题在统计上等价", "title_en": "Feature Selection and Junta Testing are Statistically Equivalent", "authors": "Lorenzo Beretta,Nathaniel Harms,Caleb Koch", "background": "对于一个从{0,1}^n到{0,1}的函数f，极简测试问题探究f是否只依赖于k个变量。如果是，特征选择问题就是找到这些变量。以往的研究表明这两个问题在统计上是等价的。这篇论文通过证明“暴力搜索”算法同时在两个问题上都是样本最优的，进一步验证了这种等价性，并且给出了最优样本大小的公式。", "innovation": "本文首次证明了特征选择和极简测试问题在统计上是等价的，并且“暴力搜索”算法同时最优解决了这两个问题。论文提出了这两个问题的最佳样本大小为：Θ(1/ε(√(2^k * log(C(n,k))) + log(C(n,k)))。", "conclusion": "本文通过证明“暴力搜索”算法在特征选择和极简测试两个问题上的最优性，揭示了这两个问题在统计上的等价性，并给出了样本复杂度的精确上界和下界。"}
{"llm_update_time": "20250723", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2504.02019", "html_url": "https://arxiv.org/abs/2504.02019", "title": "抗方差采样法在Top-k Shapley值识别中的应用", "title_en": "Antithetic Sampling for Top-k Shapley Identification", "authors": "Patrick Kolpaczki,Tim Nielen,Eyke Hüllermeier", "background": "传统加性特征解释依赖游戏理论概念中的Shapley值，将特征视为合作玩家。Shapley值因其公理的独特性而受到广泛应用，但由于其计算复杂性，限制了其实用性。大多数研究关注于所有特征Shapley值的统一近似，对不重要的特征无谓地消耗样本。相比之下，识别最重要的k个特征已经足够有洞察力，并且可能能够利用与多臂_bandits_领域相关的算法机会。但是，估计质量在全近似问题和Top-k识别之间并不一定相互转移。", "innovation": "提出了一种名为Comparable Marginal Contributions Sampling (CMCS)的新方法，用于利用相关观察的优势解决Top-k识别问题。该方法通过一种新的采样方案进行实验展示与竞争 baseline 方法的效果对比，发现全近似问题的估计质量不一定能转移到Top-k识别问题中，反之亦然。", "conclusion": "研究发现，对于全近似问题的估计质量并不一定直接适用于Top-k特征识别问题，反之亦然。CMCS方法通过新的采样方案，在相关观察中利用算法的机会，能更高效地识别出最重要的k个特征。"}
{"llm_update_time": "20250723", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2411.05195", "html_url": "https://arxiv.org/abs/2411.05195", "title": "使用相同视觉编码器时，探索生成型MLLMs如何比CLIP感知更多", "title_en": "Exploring How Generative MLLMs Perceive More Than CLIP with the Same Vision Encoder", "authors": "Siting Li,Pang Wei Koh,Simon Shaolei Du", "background": "近期的研究表明，CLIP模型在需要理解组成性视觉推理、空间关系或捕捉细粒度细节的任务中表现不佳。一个自然的假设是CLIP的视觉编码器没有嵌入完成这些任务所需的关键信息。然而，研究者发现这并不总是正确的：CLIP的视觉编码器能够聚集与查询相关的视觉信息，但CLIP未能提取这些信息。此外，另一种视觉-语言模型（VLM）分支——生成型多模态大型语言模型（MLLMs）——即使使用相同的视觉编码器和权重，在许多这类任务中也表现出显著更高的准确率。这表明MLLMs提取和利用视觉信息更为有效。因此，研究者进行了一系列受控实验，指出其成功的原因在于包括令牌片段、位置嵌入和基于提示的加权等多重关键设计选择。然而，仅仅是增强训练数据或应用一个更强的文本编码器，不足以解决这些问题，追加文本令牌也几乎没有益处。更为有趣的是，即使通过对比性微调转换为CLIP-like编码器，这些MLLMs在相同的余弦相似性评估协议下仍然比CLIP表现出更高的性能。研究强调了VLM架构选择的重要性，并提出了改进CLIP-like对比性VLM性能的方向。", "innovation": "研究者通过受控实验发现，尽管CLIP的视觉编码器可以聚集与查询相关的视觉信息，但CLIP未能有效提取这些信息。此外，生成型多模态大型语言模型（MLLMs）在许多视觉推理任务中表现出显著更高的准确率，即使使用CLIP相同的视觉编码器和权重。研究揭示了MLLMs的成功归因于几个关键的设计选择，例如令牌片段、位置嵌入和基于提示的加权策略。同时，增加训练数据和使用更强的文本编码器并不能解决问题，而额外的文本令牌也几乎没有益处。进一步研究发现，即使通过对比性微调转换为CLIP-like编码器，这些MLLMs依然表现出更高的性能。", "conclusion": "研究强调了VLM架构设计的重要性，指出了改进CLIP-like对比性VLM性能的潜在方向。"}
{"llm_update_time": "20250723", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2502.16660", "html_url": "https://arxiv.org/abs/2502.16660", "title": "BioMaze: 评估与增强用于生物通路推理的大语言模型", "title_en": "BioMaze: Benchmarking and Enhancing Large Language Models for Biological Pathway Reasoning", "authors": "Haiteng Zhao,Chang Ma,Fangzhi Xu,Lingpeng Kong,Zhi-Hong Deng", "background": "近年来，大语言模型（LLMs）在不同生物学领域的应用得到了广泛研究，但在复杂生物系统（如通路）中的推理能力仍然没有得到充分探索。这种推理能力对于预测生物学现象、提出假说和设计实验至关重要。本文探讨了LLMs在通路推理中的潜在应用。研究团队制作了一个名为BioMaze的数据集，包含5100个复杂通路问题，来源于真实研究，覆盖了各种生物上下文，包括自然动态变化、干扰、额外干预条件和多尺度研究目标。研究表明，LLMs在处理复杂通路推理时面临着挑战，特别是在受干扰的系统中。", "innovation": "该研究提出了一个名为PathSeeker的LLM代理，通过基于子图的交互式导航增强推理能力，从而更有效地应对生物系统的复杂性，实现与科学方法的契合。此外，研究团队还提供了一个包含BioMaze数据集和代码的网址，以便其他研究者能够在类似问题上进行进一步的工作。", "conclusion": "在对多种方法（如CoT和图增强推理）的评估中发现，现有的LLMs在通路推理方面存在不足，特别是对于扰动系统。研究团队提出的一种新方法（PathSeeker）通过交互式子图导航有效地改进了这个问题，为处理生物系统的复杂性提供了更有效的方法。"}
{"llm_update_time": "20250723", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2503.09565", "html_url": "https://arxiv.org/abs/2503.09565", "title": "在Maximal Update参数化下$L$层无限宽度神经网络中的全局收敛和丰富特征学习", "title_en": "Global Convergence and Rich Feature Learning in $L$-Layer Infinite-Width Neural Networks under $μ$P Parametrization", "authors": "Zixiang Chen,Greg Yang,Qingyue Zhao,Quanquan Gu", "background": "尽管深度神经网络在表征学习方面具有强大的能力，但理论层面上仍不清楚如何同时实现有意义的特征学习和全局收敛。现有的方法，如神经核（NTK）理论，在这种参数化下特征保持接近初始化状态，无法完全解释特征在此过程中的特性及其变化。本研究着眼于无限宽、$L$层神经网络在Tensor程序（TP）框架下的训练动力学，特别是在Maximal Update（$\text{μP}$）参数化下，使用随机梯度下降（SGD）与轻微的激活函数条件。我们展示了Even/features能够在训练过程中从初始值显著改变并学习线性独立的特征，从而覆盖关键的数据信息，并保证任何收敛点都是全局最小值。该分析结合了不同层间特征的交互作用和高斯随机变量的特性，提供了关于深度表征学习的新见解。我们的理论研究成果也在实际数据集上得到了验证。", "innovation": "提出了一种在无限宽神经网络中使用Maximal Update参数化下的STG训练新方法，能够学习线性独立且显著不同于初始化值的特征，从而实现全球收敛并学习丰富的特征空间。通过结合跨层特征的交互作用和高斯随机变量的特性，提供了关于深度表征学习的新见解。", "conclusion": "在Maximal Update参数化下，使用随机梯度下降训练无限宽的神经网络，能够实现全局收敛并学习丰富的特征空间。任何收敛点都是全局最小值。这种分析为理解和验证深度表征学习的理论提供了新的视角，并且在实践中也被实验证明有效。"}
{"llm_update_time": "20250723", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2504.05119", "html_url": "https://arxiv.org/abs/2504.05119", "title": "通过激活函数选择平衡嵌入式DNN的鲁棒性和效率", "title_en": "Balancing Robustness and Efficiency in Embedded DNNs Through Activation Function Selection", "authors": "Jon Gutiérrez-Zaballa,Koldo Basterretxea,Javier Echanobe", "background": "机器学习嵌入式系统，特别是在航空航天和自动驾驶这样的安全关键应用中，必须对由软错误引起的扰动具有鲁棒性。随着晶体管几何尺寸的缩小和电压的降低，现代电子设备对背景辐射的敏感性增加，因此软错误造成的故障变得更加令人担忧。深度神经网络（DNNs）对这些错误的鲁棒性不仅取决于目标设备技术，也取决于模型结构及参数的数值表示和计算精度。压缩技术如剪枝和量化虽然能减少内存占用和计算复杂性，但也会改变模型结构和表示形式，影响软错误的鲁棒性。选择激活函数不仅影响准确性和训练效果，还影响压缩能力和错误鲁棒性。这篇论文探讨了使用有界激活函数以增强模型对参数扰动的鲁棒性，同时评估它们对模型准确度、压缩性和计算负载的影响，采用一种技术无感知的方法。实验在独立显卡-赛灵思的KV260系统模块上进行，该模块主要用于高光谱图像的语义分割，并应用于自动驾驶系统中。", "innovation": "研究了使用有界激活函数（bounded AFs）的方法，以增强深度神经网络对参数扰动的鲁棒性。通过一种技术无感知的方法，评估有界激活函数对于模型准确度、压缩性和计算负载的影响，旨在平衡模型的鲁棒性和效率。研究聚焦于编码器-解码器卷积模型，该模型用于高光谱图像的语义分割，适用于自动驾驶系统。实验在AMD-Xilinx的KV260系统模块上进行。", "conclusion": "通过使用有界激活函数，论文提出了增强深度神经网络对参数扰动鲁棒性的方法，并通过技术无感知的方法评估了这些方法对模型性能的影响。实验结果表明，有界激活函数在保持模型鲁棒性的同时，也能保证模型在计算效率和压缩性方面保持良好表现。"}
{"llm_update_time": "20250723", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.16629", "html_url": "https://arxiv.org/abs/2506.16629", "title": "从精神科纵向数据中学习因果预测结果", "title_en": "Learning Causally Predictable Outcomes from Psychiatric Longitudinal Data", "authors": "Eric V. Strobl", "background": "在生物医学数据的纵向因果推断中，特别是在精神病学领域，症状的异质性和潜在混淆因素经常破坏经典的估计器。现有的大多数用于治疗效果估计的方法假设一个固定的结果变量，并通过观察协变量调整来解决混淆问题。然而，在实践中，这种未混淆性的假设可能不成立。为了弥补这一基础性限制，该研究直接优化结果定义以最大化因果可识别性。该算法通过利用精神科纵向数据中超短期直接治疗效应，学习非负的、临床可解释的结果聚合权重，最大化持久治疗效果，实际减少可观察和潜在的混淆因素。此外，该算法还提供了一个可验证的测试，以证明结果的未混淆性。", "innovation": "该研究提出了一种名为DEBIAS的算法，通过优化结果定义，不假设固定的结果变量，并利用时间有限的直接效应来最大化持久的治疗效果，同时减少观察到的和潜在的混淆因素。此外，算法还提供了一个实际验证结果未混淆性的测试。与当前最先进的方法相比，该算法在抑郁症和精神分裂症的综合实验中一致地提高了可解释复合结果的因果效应恢复性能。", "conclusion": "该研究提出的DEBIAS算法通过直接优化结果定义来最大化治疗效果的持久性，并且该算法还在临床可解释的复合结果的因果效应恢复方面优于现有的最先进的方法。"}
{"llm_update_time": "20250723", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.17576", "html_url": "https://arxiv.org/abs/2506.17576", "title": "逐步训练以加深GCN：通过迭代训练和微调缓解过光滑问题", "title_en": "Towards a deeper GCN: Alleviate over-smoothing with iterative training and fine-tuning", "authors": "Furong Peng,Jinzhen Gao,Xuan Lu,Kang Liu,Yifan Huo,Sheng Wang", "background": "图卷积网络（GCNs）在深层结构中由于过光滑现象而表现严重下降。现有研究主要将过光滑归因于图拉普拉斯算子的重复应用，但实验分析发现，可训练的线性变换在GCNs中也显著加剧了特征坍塌，即使在中等深度（例如8层）也会如此。简化图卷积（SGC）通过去除这些变换，能使特征多样性稳定到32层，这表明线性变换在增强表现力的同时也诱发过光滑。然而，完全移除线性变换会削弱模型的表现力能力。为解决这一权衡，作者提出了一种新的训练策略——逐层渐进性训练（LGT），该策略逐步构建深层GCNs的同时保持其表现力。", "innovation": "逐层渐进性训练（LGT）策略。LGT通过以下三个组成部分实现：逐层训练以稳定从浅层到深层的优化，低秩适应以微调浅层并加速训练，以及身份初始化以确保新层的平滑集成并加速收敛。LGT框架是通用、架构无关的，适用于可扩展的深层GCNs。它还可以与现有的方法如PairNorm和ContraNorm无缝结合，进一步提高深层网络中的性能。该训练方法在标准数据集上表现出色，即使在32层设置下也能显著提高精度。", "conclusion": "实验结果表明，LGT在标准GCN上达到了最先进的性能，在深层设置下显著提升了准确性。此外，LGT提供了一种通用的、架构无关的训练框架，用于构建可扩展的深层GCNs。"}
{"llm_update_time": "20250723", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2505.17579", "html_url": "https://arxiv.org/abs/2505.17579", "title": "使用指定概率操控的白盒对抗攻击进行DNN模型所有权验证", "title_en": "Ownership Verification of DNN Models Using White-Box Adversarial Attacks with Specified Probability Manipulation", "authors": "Teruki Sano,Minoru Kuribayashi,Masao Sakai,Shuji Ishobe,Eisuke Koizumi", "background": "当前，对于深度神经网络（DNN）模型的所有权验证是一个挑战性问题，尤其是在模型被非法复制并在云环境中提供的服务场景下。传统的验证方法通常需要展示原始模型，这对于模型的所有者可能是一个安全风险。本文研究在模型所有权验证中引入白盒对抗攻击的方法。", "innovation": "提出了一种新颖的框架，允许模型的所有者和第三方在不展示原始模型的情况下验证模型的身份。该框架通过白盒对抗攻击将特定类别的输出概率调整到指定值，利用对原始模型的了解来生成对抗样本。通过引入控制参数，设计了一种基于迭代快速梯度签名方法（FGSM）的简单但有效的对抗攻击方法。", "conclusion": "实验结果验证了利用对抗攻击识别DNN模型的有效性。这种方法为模型的所有权验证提供了一种新的途径，能够在不泄露原始模型的情况下进行验证。"}
{"llm_update_time": "20250723", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.22095", "html_url": "https://arxiv.org/abs/2506.22095", "title": "多图上的多目标神经路由方法", "title_en": "Neural Approaches for Multi-Objective Routing on Multigraphs", "authors": "Filip Rydin,Attila Lischka,Jiaming Wu,Morteza Haghir Chehreghani,Balázs Kulcsár", "background": "近年来，基于学习的路由方法在单目标和多目标上下文中都受到了广泛关注。然而，现有方法在处理特征为多条边且每条边具有不同属性的多图路由时存在局限性。尽管多图在实际场景中具有重要意义，但现有方法无法有效解决这些问题。", "innovation": "本文提出了一种基于图神经网络的方法来解决多图上的多目标路由问题。两种方法分别通过自回归选择边直接在多图上操作，以及通过学习剪枝策略简化多图后再进行路由操作。", "conclusion": "本文两种模型在多种问题和分布上都表现出了强大性能，验证了它们的有效性。"}
{"llm_update_time": "20250723", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2505.08087", "html_url": "https://arxiv.org/abs/2505.08087", "title": "用归一化流进行流形学习：朝着正则性、表达性和等距黎曼几何", "title_en": "Manifold Learning with Normalizing Flows: Towards Regularity, Expressivity and Iso-Riemannian Geometry", "authors": "Willem Diepeveen,Deanna Needell", "background": "现代机器学习越来越依赖高维数据往往接近低维非线性流形这一见解，这一思想称为流形假设。通过显式建模数据的几何结构，黎曼几何算法可以在聚类、降维、插值等领域实现更好的性能和可解释性。尤其是，最近在学习拉回几何方面取得了变革性进展，使其变得可扩展。但当考虑真实世界的多模态数据时，仍需解决流形表示中的失真和建模误差。该研究聚焦于实时多模态数据中存在的这些问题，并通过等距化学习到的黎曼结构和平衡同胚参数化中的正则性和可表达性，来解决这些挑战。研究人员通过数值实验展示了所提出方法的有效性，实验数据包括合成和真实数据。", "innovation": "该工作提出了通过等距化学习到的黎曼结构和平衡同胚参数化中的正则性和可表达性来解决多模态数据中的失真和建模错误问题。这种方法有效地提升了对非线性数据的分析和可解释的机器学习的处理能力。研究人员通过数值实验展示了所提出方法的有效性，包括合成和真实数据。", "conclusion": "通过改进的黎曼几何学习和方法的应用，该研究提高了对多模态数据的非线性建模效果。新的方法克服了实际应用中存在的挑战，从而进一步推动了非线性数据和可解释的人工智能的发展。"}
{"llm_update_time": "20250723", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.12490", "html_url": "https://arxiv.org/abs/2506.12490", "title": "Follow-the-Perturbed-Leader在组合半带宽问题中的注记", "title_en": "Note on Follow-the-Perturbed-Leader in Combinatorial Semi-Bandit Problems", "authors": "Botao Chen,Junya Honda", "background": "这篇论文研究了Follow-the-Perturbed-Leader (FTPL) 政策在规模不变组合半带宽问题中的最优性和复杂性。以往研究（Honda et al., 2023 和 Lee et al., 2024）已经显示FTPL在标准多臂带宽问题中的Frechet类型分布下实现了两界最优性（BOBW）。然而，FTPL在组合半带宽问题中的最优性仍然不清楚。论文侧重于探讨在这些情况下FTPL的遗憾边界，并将其推广到条件几何重采样(CGR)的方法。", "innovation": "论文展现了使用几何重采样（GR）的FTPL分别在Frechet分布下实现了 $O\big(\text{sqrt}\big(m^2 d^{\frac{1}{\boldsymbol{\boldsymbol{\boldsymbol{\text{α}}}}\boldsymbol{\boldsymbol{\boldsymbol{}}}}T\big)+\text{sqrt}\big(mdT\big)\big)$的遗憾边界，并且在对抗环境下，使用Pareto分布则能够实现 $O\big(\text{sqrt}\big(mdT\big)\big)$ 的最好可能遗憾边界。此外，作者还将条件几何重采样方法扩展到规模不变的半带宽问题中，将原始GR的计算复杂度从 $O(d^2)$ 降低到了 $O\big(md\big(\text{log}\big(d/m\big)+1\big)\big)$，同时保持了FTPL的遗憾性能。", "conclusion": "总的来说，这篇文章通过研究FTPL在特定分布下的遗憾边界和扩展CGR方法，证明了FTPL在组合半带宽问题中的性能，并通过减少计算复杂度更加优化了这一方法。"}
{"llm_update_time": "20250723", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.02903", "html_url": "https://arxiv.org/abs/2507.02903", "title": "利用近红外光谱技术和机器学习对韩牛和荷斯坦牛肉可追溯分类的探索", "title_en": "Harnessing Near-Infrared Spectroscopy and Machine Learning for Traceable Classification of Hanwoo and Holstein Beef", "authors": "AMM Nurul Alam,Abdul Samad,AMM Shamsul Alam,Jahan Ara Monti,Ayesha Muazzam", "background": "该研究旨在利用近红外光谱（NIRS）结合先进的机器学习（ML）技术来区分韩牛（HNB）和荷斯坦牛肉（HLB），以解决食品的真实性、标示不准确和掺假问题。研究人员通过便携式NIRS设备记录了700到1100纳米波长范围内的吸收光谱数据，对40份长肌束样本进行了分析，并使用主成分分析（PCA）展示了两种牛肉类型的独特光谱模式。", "innovation": "研究创新之处在于结合了便携式的NIRS技术与多种机器学习模型，包括线性判别分析（LDA）、支持向量机（SVM）、逻辑回归（LR）、随机森林（RF）、梯度提升（GB）、K-最近邻（KNN）、决策树（DT）、朴素贝叶斯（NB）和神经网络（NN），并通过对模型进行超参数优化和五折交叉验证来提升模型的稳健性和防止过拟合。研究结果表明，随机森林和SVM模型表现出较高的预测准确性和较高的AUC值，神经网络在召回率上表现良好，林和NB模型则表现出较低的预测性能。机器学习技术被证明是肉品真实性的有力工具，有助于食品欺诈的检测。", "conclusion": "研究表明，将NIRS与ML技术相结合，提供了一种强大且可靠的肉类真实性检测方法，对打击食品欺诈有重大贡献。"}
{"llm_update_time": "20250723", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.07754", "html_url": "https://arxiv.org/abs/2507.07754", "title": "OPC: One-Point-Contraction Unlearning Toward Deep Feature Forgetting", "title_en": "OPC: One-Point-Contraction Unlearning Toward Deep Feature Forgetting", "authors": "Jaeheun Jung,Bosung Jung,Suhyun Bae,Donghun Lee", "background": "现有的机器遗忘方法倾向于‘浅度遗忘’，即经过遗忘处理的模型通过调整模型响应来模拟遗忘效果，但实际上模型内部的特征表示仍然保留了足够的信息，能够恢复被遗忘的数据或行为。研究人员通过无训练恢复性能攻击和基于梯度反转的数据重建攻击验证了这一点的普遍性问题。这一问题的存在，使得现有的遗忘方法在隐私保护方面存在漏洞。", "innovation": "本文定义了基于数据特征表示一点收缩理论标准的‘深度遗忘’，并提出了一个相应的高效近似算法。利用该理论标准开发了一种新型通用遗忘算法——One-Point-Contraction（简称OPC）。实验结果表明，OPC不仅能够有效进行数据遗忘，还具有更强的抵御性能恢复攻击和梯度反转攻击的能力。其独特的遗忘性能源于算法所依赖的理论基础所强制的深层特征遗忘。", "conclusion": "实验在图像分类遗忘基准上得到了有效的遗忘性能和卓越的抗攻击能力，这表明OPC算法提高了机器遗忘方法的鲁棒性，并再次强调了需要改进机器遗忘方法的鲁棒性。"}
{"llm_update_time": "20250723", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.08472", "html_url": "https://arxiv.org/abs/2507.08472", "title": "预训练LLMs的成本优化：三种优化器的比较", "title_en": "Pre-Training LLMs on a budget: A comparison of three optimizers", "authors": "Joel Schlotthauer,Christian Kroos,Chris Hinze,Viktor Hangya,Luzian Hahn,Fabian Küch", "background": "预训练大语言模型（LLMs）的优化器在减少训练时间和提高模型性能方面起着决定性作用。本文将三种主要的优化器进行比较，分别是作为事实标准的AdamW，以及通过进化搜索开发的简化版优化器Lion，还有第二阶优化器Sophia。为了获取更好的泛化能力，实验在两种不同基础架构上进行训练，并采用单轮和多轮训练方法，同时保持Token数量不变。实验中使用了最大的更新参数化方法和较小的代理模型来分别调参，针对每种基础架构与优化器的组合进行了调整。研究表明，尽管所有三个优化器的结果都在相近范围内，但Sophia在训练和验证损失上表现最低，Lion在GPU训练时长上最快，而AdamW在下游评估结果上表现最佳。", "innovation": "将三种不同的优化器（AdamW，Lion 和 Sophia）进行了比较，并采用了不同的基础架构和训练策略来优化预训练过程。通过最大更新参数化和较小代理模型进行参数调整，以获得更好的泛化能力。这为未来的预训练工作提供了一种新的评估方法和优化策略。", "conclusion": "在训练时间和模型性能方面，三个优化器的表现不尽相同，尽管所有优化器的结果范围相近，但Sophia在训练和验证损失上最低，Lion在GPU训练时长上领先，而AdamW在下游评估结果上表现最佳。"}
{"llm_update_time": "20250723", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.09786", "html_url": "https://arxiv.org/abs/2507.09786", "title": "利用分布匹配加速近似机器遗忘", "title_en": "Leveraging Distribution Matching to Make Approximate Machine Unlearning Faster", "authors": "Junaid Iqbal Khan", "background": "AMU（Approximate Machine Unlearning）允许模型通过在保留数据集子集上进行特化的微调来“忘记”特定的训练数据。尽管如此，处理这个保留子集仍然主导了计算时间，同时减少迭代次数也是一个挑战。", "innovation": "该研究提出了两种互补方法来加速分类导向的AMU。首先，Blend，一种新颖的区别匹配数据集凝缩方法（DC），将具有共享混合权重的视觉相似图像合并，以显著减少保留集的大小。这种方法具有极低的前处理开销，并且比最先进的DC方法快得多。其次，我们的损失为中心的方法加速AMU（Accelerated-AMU，A-AMU）增加了遗忘目标以加快收敛。A-AMU通过结合陡峭的主要损失来加速遗忘，并提出了一种新的可微正则化器，它匹配遗忘和潜在分布数据的损失分布。实验结果表明，这种双重方法的数据和损失中心化优化可以在单轮和多轮场景下大幅缩短整体遗忘延迟时间，同时保持模型的实用性和隐私性。", "conclusion": "据我们所知，这是首次通过联合设计专门化的数据集凝缩技术和专用加速损失函数来系统解决遗忘效率的工作。"}
{"llm_update_time": "20250723", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.13354", "html_url": "https://arxiv.org/abs/2507.13354", "title": "实现大型语言模型中变压器架构的物理模型", "title_en": "Physical models realizing the transformer architecture of large language models", "authors": "Zeqian Chen", "background": "2017年引入的变压器架构是自然语言处理领域最显著的进步。变压器完全依赖注意机制来捕捉输入和输出之间的全局依赖关系。然而，作者认为我们对变压器及其工作原理还缺乏充分的理论理解，特别是从现代芯片的物理角度来看，智能机器应被视为超越传统统计系统的开放量子系统。因此，作者基于此背景，希望提供一种新的视角来理解变压器在大型语言模型中的工作机制和物理意义。", "innovation": "文章从开放量子系统的角度出发，构建了基于变压器架构的大型语言模型的物理模型，并将这些模型置于Fock空间中的希尔伯特空间的令牌空间之上。这一创新为理解和解释变压器在大型语言模型中的工作原理提供了一个新的框架。", "conclusion": "作者构建的物理模型为大型语言模型中的变压器架构提供了新的理论支撑，认为这些模型可以被看作是开放量子系统，从而加深了我们对变压器的工作机理的理解。"}
{"llm_update_time": "20250723", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.23516", "html_url": "https://arxiv.org/abs/2506.23516", "title": "FedWSQ：具有权重标准化和分布感知非均匀量化的高效联邦学习", "title_en": "FedWSQ: Efficient Federated Learning with Weight Standardization and Distribution-Aware Non-Uniform Quantization", "authors": "Seung-Wook Kim,Seongyeol Kim,Jiah Kim,Seowon Ji,Se-Ho Lee", "background": "联邦学习（FL）常常因数据异质性和通信限制而遭受性能下降。现有的FL方法无法有效解决这些问题。", "innovation": "提出了一个新颖的FL框架，称为FedWSQ，该框架结合了权重标准化（WS）和提出的一种分布感知非均匀量化（DANUQ）方法。WS通过在训练过程中过滤出局部更新中的偏差成分，增强了模型的鲁棒性。DANUQ通过利用本地模型更新的统计特性来最小化量化错误。结果，FedWSQ显著降低了通信开销，同时保持了较高的模型准确度。", "conclusion": "广泛实验表明，FedWSQ在各种挑战性FL设置下，包括极端数据异质性和超低比特通信场景中，持续优于现有的FL方法。"}
{"llm_update_time": "20250723", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.13762", "html_url": "https://arxiv.org/abs/2507.13762", "title": "MolPIF：分子生成的参数插值流模型", "title_en": "MolPIF: A Parameter Interpolation Flow Model for Molecule Generation", "authors": "Yaowei Jin,Junjie Wang,Wenkai Xiang,Duanhua Cao,Dan Teng,Zhehuan Fan,Jiacheng Xiong,Xia Sheng,Chuanlong Zeng,Duo An,Mingyue Zheng,Shuangjia Zheng,Qian Shi", "background": "深度学习在分子生成方面显示出加速药物发现的潜力。Bayesian Flow Networks (BFNs)在多种化学任务中表现出色，其成功通常归因于小方差参数空间下的建模方法。然而，基于贝叶斯推理的策略限制了灵活分布转换路径的设计，难以适应多样化的数据分布和不同的任务需求。此外，基于参数空间的简单高效模型的潜力尚未被探索。这些限制促使研究者寻求新的方法来改进分子生成模型的设计和性能。", "innovation": "本文提出了一种新的参数插值流模型（命名为PIF），并对其理论基础、训练和推理过程进行了详细阐述。随后，开发了基于结构的药物设计模型MolPIF，并在多种度量标准上展示了优于基线模型的优越性能。该模型验证了基于参数空间生成建模范式在分子生成中的有效性，并为模型设计提供了新的视角。", "conclusion": "本文验证了基于参数空间的生成建模对分子的有效性，并为分子生成模型的设计提供了新思路。MolPIF 在多种度量标准上均超过了基准模型，展示了其在结构基础药物设计领域的优越性能。"}
{"llm_update_time": "20250723", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.13620", "html_url": "https://arxiv.org/abs/2507.13620", "title": "Tri-Learn Graph Fusion Network for Attributed Graph Clustering", "title_en": "Tri-Learn Graph Fusion Network for Attributed Graph Clustering", "authors": "Binxiong Li,Xu Xiang,Xue Li,Binyu Zhao,Heyang Gao,Qinyu Zhao", "background": "近年来，基于图卷积网络(GCN)的模型在图数据的分析中取得了显著进展。然而，当处理大规模和复杂图数据集时，仍然存在过度平滑和过度压缩等问题，导致聚类质量下降。虽然图变换器架构已经解决了一些这些问题，但在处理异质图数据时其表现仍然有限。", "innovation": "本研究提出了一种新的深度聚类框架Tri-Learn Graph Fusion Network (Tri-GFN)，该框架包括GCN、自动编码器(AE)和图变换器。这种框架通过独特的三学习机制和特征融合增强策略提高了全局和局部信息的区分度和一致性。该框架将GCN、AE和图变换器模块融合，并通过三通道增强模块精确融合，最大化利用结点特征和拓扑结构，确保聚类表示的鲁棒性。三学习机制使这些模块之间互相学习，而特征融合策略使得模型能够捕捉复杂的联系，产生高度判别性的表示。", "conclusion": "Tri-GFN超越了许多最先进的方法，在ACM数据集上准确率提高了约0.87%，在Reuters数据集上提高了14.14%，在USPS数据集上提高了7.58%。由于其在Reuters数据集上的卓越表现，Tri-GFN可以应用到自动新闻分类、主题检索等相关领域。"}
{"llm_update_time": "20250723", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.10183", "html_url": "https://arxiv.org/abs/2507.10183", "title": "T-GRAB：用于时间图学习的合成诊断基准", "title_en": "T-GRAB: A Synthetic Diagnostic Benchmark for Learning on Temporal Graphs", "authors": "Alireza Dizaji,Benedict Aaron Tjandra,Mehrab Hamidi,Shenyang Huang,Guillaume Rabusseau", "background": "动态图学习方法最近作为建模随时间演变的关系数据的强大工具而涌现。尽管进行了大量的基准测试，但目前的时间图神经网络(TGNNs)是否能够有效地捕捉周期性、因果关系和长距离依赖等核心时间模式仍然不清楚。", "innovation": "本文引入了时间图推理基准(T-GRAB)，这是一个全面的合成任务集，旨在系统地探查TGNNs在时间维度上推理的能力。T-GRAB提供了受控且可解释的任务，可以隔离关键时间技能：计数/记忆周期重复、推断延迟因果效应以及在时空维度上的捕捉长距离依赖。", "conclusion": "我们在这些任务上对11种时间图学习方法进行了评估，揭示了它们在概括时间模式方面存在根本性的不足。我们的发现提供了有关现有模型局限性的实际见解，突显了传统现实世界基准掩盖的挑战，并促进了具有更强时间推理能力的架构的发展。T-GRAB的代码可以从这个链接找到：this https URL."}
{"llm_update_time": "20250723", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.09958", "html_url": "https://arxiv.org/abs/2507.09958", "title": "重思地理神经网络加权回归中的归纳偏置", "title_en": "Rethinking Inductive Bias in Geographically Neural Network Weighted Regression", "authors": "Zhenyuan Chen", "background": "地理回归模型中的归纳偏置是关键因素，它决定了模型如何从有限数据中学习并捕捉空间模式。本文回顾了地理神经网络加权回归（GNNWR）中的归纳偏置，并指出了现有方法在建模空间非平稳性方面的局限性。虽然GNNWR通过使用神经网络来学习空间权重函数，扩展了传统的地理加权回归，但现有的实现通常受限于固定的基于距离的方案，归纳偏置有限。现有的GNNWR方法主要依赖于固定的距离加权方案，不够灵活，无法完全捕捉空间非平稳性。", "innovation": "本文提出了一种通用化GNNWR的方法，引入了卷积神经网络、递归神经网络和变压器的概念，将局部感受野、序列上下文和自我注意机制融入空间回归中，突破了原来基于固定距离加权方案的限制。通过在带有多变性、噪声和样本大小变化的合成空间数据集上进行广泛的基准测试，证明了GNNWR在捕捉非线性和复杂的空间关系上优于经典方法。同时，结果揭示了模型性能与数据特征紧密相关，局部模型在高多变性和小样本场景中表现出色，而全局模型则在大样本、同质性更高的数据中表现更好。这些发现强调了在空间模型中归纳偏置的重要性，并提出了未来的研究方向，包括可学习的空间加权函数、混合神经架构以及提高非平稳空间数据处理模型的可解释性。", "conclusion": "研究表明，GNNWR相较于传统的空间回归方法，在识别并建模复杂的空间关系上表现更为出色。然而，模型的表现很大程度上取决于数据的特性，局部模型更适合处理高多变性的数据或小样本数据，而全局模型则适用于大样本且数据较为同质的情况。这些结果揭示了归纳偏置在地理位置回归模型中至关重要，为未来的研究和改进提供了方向。在未来的研究中，探索可学习的空间加权函数、混合神经架构以及提高模型对非平稳性空间数据的可解释性将是重要课题。"}
{"llm_update_time": "20250723", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.07271", "html_url": "https://arxiv.org/abs/2507.07271", "title": "超越ATE：在剂量和时间维度上可解释的治疗效果建模", "title_en": "Beyond the ATE: Interpretable Modelling of Treatment Effects over Dose and Time", "authors": "Julianna Piskorz,Krzysztof Kacprzyk,Harry Amad,Mihaela van der Schaar", "background": "平均治疗效应（ATE）是因果推断中的基础指标，广泛用于评估随机对照试验（RCTs）中的干预效果。但在许多应用中，特别是在医疗领域，这种静态摘要无法捕捉到治疗效果随剂量和时间变化的复杂动态。为了解决这一问题，本文提出了一种框架，用于将治疗效果轨迹建模为剂量和时间上的平滑表面，从而提取诸如效果出现时间、峰值效果和收益持续时间等可临床操作的见解。", "innovation": "本文提出了一种适应于因果推断场景的可解释轨迹建模方法——SemanticODE，确保在剂量和时间维度上治疗效果模型的可解释性、稳健性和可验证性。该方法分离了轨迹形状的估计和临床相关属性（如最大值、拐点）的定义，支持领域专家先验知识的运用、事后编辑和透明分析。实验结果表明，该方法生成了准确的、可解释的和可编辑的治疗动态模型，既有助于严格的因果分析，也支持实际的决策。", "conclusion": "本文的方法能够准确地、可解释地和可编辑地建模治疗动态，不仅促进了严谨的因果分析，还为实际决策提供了支持。"}
{"llm_update_time": "20250723", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2412.20553", "html_url": "https://arxiv.org/abs/2412.20553", "title": "随机稳定性边缘：重访随机梯度下降的稳定性边缘", "title_en": "Edge of Stochastic Stability: Revisiting the Edge of Stability for SGD", "authors": "Arseniy Andreyev,Pierfrancesco Beneventano", "background": "Cohen等人2021年的研究成果表明，在使用全批量梯度下降进行训练且步长为η的情况下，全批量海森矩阵的最大特征值λmax始终稳定在λmax = 2/η。这一发现对收敛性和泛化能力有重大影响。然而，这些结果不适用于小批量随机梯度下降（SGD），限制了其应用的广泛性。", "innovation": "研究表明SGD在所谓的随机稳定性边缘（EoSS）状态下进行训练。在这一状态下，稳定的是批量锐度：小批量海森矩阵沿其相应随机梯度的方向曲率。由于批量锐度通常比最大特征值大，最大特征值被抑制，符合长期以来的小批量和大步长有利于更平滑最小值的观察。", "conclusion": "进一步讨论了这对随机梯度下降路径的数学建模的影响。"}
{"llm_update_time": "20250723", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2402.04247", "html_url": "https://arxiv.org/abs/2402.04247", "title": "AI科学家的风险：优先保护安全而非自主权", "title_en": "Risks of AI Scientists: Prioritizing Safeguarding Over Autonomy", "authors": "Xiangru Tang,Qiao Jin,Kunlun Zhu,Tongxin Yuan,Yichi Zhang,Wangchunshu Zhou,Meng Qu,Yilun Zhao,Jian Tang,Zhuosheng Zhang,Arman Cohan,Zhiyong Lu,Mark Gerstein", "background": "AI科学家借助大型语言模型在自主进行实验和促进跨学科科学发现方面展现了巨大的潜力。然而，这些代理也能带来新的安全隐患，需要认真考虑安全性。但目前对这些安全隐患的全面探索还比较有限。", "innovation": "本文提出了一种三元框架来缓解这些安全隐患，包括人类监管、代理对齐和环境反馈理解（代理调节）三个方面，并强调了改进模型、建立稳健基准和全面规范的重要性。同时，指出了保护AI科学家的限制和挑战，并呼吁对这一领域进行更深入研究。", "conclusion": "本文从用户意图、具体科学领域等方面分析了AI科学家固有的风险，探讨了这些风险的根本原因，并提供了一个框架以减轻这些风险，还指出了保护AI科学家的局限性和挑战。"}
{"llm_update_time": "20250723", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2311.01059", "html_url": "https://arxiv.org/abs/2311.01059", "title": "随环境变化自我调整：单一生命周期机器人部署的行为 modulation", "title_en": "Adapt On-the-Go: Behavior Modulation for Single-Life Robot Deployment", "authors": "Annie S. Chen,Govind Chada,Laura Smith,Archit Sharma,Zipeng Fu,Sergey Levine,Chelsea Finn", "background": "机器人必须能够在实际部署中应对与训练环境不同的新情况。本文研究了一种在实际部署过程中自动调整和适应新场景的方法，利用已学得的多种行为以应对不断变化的环境。", "innovation": "提出了一种名为ROAM（RObust Autonomous Modulation）的方法，该方法能够在测试阶段在一个单一的模拟过程中自动选择并适应已学得的行为，而无需任何人工监督。这种自我调整过程使得机器人即使穿着旱冰鞋也能高效地前进，特别是在面对多种离群分配情况时，相比于现有方法，该方法的适应效率提升了2倍以上。", "conclusion": "ROAM方法显著增强了机器人在面临多种不同新情况时的自我适应能力，提升了机器人在实际环境中的鲁棒性和灵活性。"}
{"llm_update_time": "20250723", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2402.12668", "html_url": "https://arxiv.org/abs/2402.12668", "title": "随机化可以同时减少偏差和方差：随机森林中的一个案例研究", "title_en": "Randomization Can Reduce Both Bias and Variance: A Case Study in Random Forests", "authors": "Brian Liu,Rahul Mazumder", "background": "我们研究了在随机森林中经常被忽视的现象，这一现象早在[1]中被首次提出，即随机森林似乎比袋装法降低了偏差。受[2]中关于随机森林在高信噪比（SNR）设置中成功的解释启发，我们探讨了随机森林如何捕获袋装组分无法捕获的数据模式，从而降低偏差和方差，并在高SNR条件下超越袋装组分。", "innovation": "本文通过实验证明，在存在特定模式的情况下，随机森林不仅减少偏差和方差，而且在高信噪比条件下表现出色，超过了袋装组分。本文还提供了关于随机森林中的$mtry$调优的实际见解。", "conclusion": "本文的观察结果揭示了随机森林在不同信噪比下的实际成功，并加深了我们对随机森林和袋装组分之间差异的理解。"}
{"llm_update_time": "20250723", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.15846", "html_url": "https://arxiv.org/abs/2507.15846", "title": "GUI-G$^2$: Gaussian Reward Modeling for GUI Grounding", "title_en": "GUI-G$^2$: Gaussian Reward Modeling for GUI Grounding", "authors": "Fei Tang,Zhangxuan Gu,Zhengxi Lu,Xuyang Liu,Shuheng Shen,Changhua Meng,Wen Wang,Wenqi Zhang,Yongliang Shen,Weiming Lu,Jun Xiao,Yueting Zhuang", "background": "当前的强化学习方法使用二元奖励来处理界面元素，这种奖励机制把元素视为非击即中的目标，因此生成的信号较为稀疏，无法捕捉空间交互的连续性。受人类点击行为自然形成的高斯分布启发，研究者引入了GUI Gaussian Grounding Rewards（GUI-G$^2$），一种原理性的奖励框架，通过连续的高斯分布模型界面元素在界面平面上的连续分布。此框架将GUI接地任务从稀疏的二元分类转变为密集的连续优化问题，生成丰富的梯度信号，引导模型找到最优的交互位置。", "innovation": "引入了GUI Gaussian Grounding Rewards（GUI-G$^2$），包含两个协同机制：Gaussian点奖励通过指数衰减分布建模精确定位，而覆盖奖励通过预测的高斯分布与目标区域的重叠度度量空间对齐。开发了适应性方差机制以根据不同元素的尺寸校准奖励分布，实现了从稀疏二元分类到密集连续优化的转变，大大提高模型对界面变化的鲁棒性和对未见过布局的泛化能力。", "conclusion": "在ScreenSpot、ScreenSpot-v2和ScreenSpot-Pro基准测试中，GUI-G$^2$显著超过了最先进的方法UI-TARS-72B，在ScreenSpot-Pro上的提升高达24.7%，证明连续建模在界面交互任务中的优越鲁棒性和增强的泛化能力，为GUI交互任务中的空间推理建立了新范式。"}
{"llm_update_time": "20250723", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.15195", "html_url": "https://arxiv.org/abs/2507.15195", "title": "在网络控制理论和秩编码的基础上构建图机器学习中的节点特征", "title_en": "Feature Construction Using Network Control Theory and Rank Encoding for Graph Machine Learning", "authors": "Anwar Said,Yifan Wei,Obaid Ullah Ahmad,Mudassir Shabbir,Waseem Abbas,Xenofon Koutsoukos", "background": "图神经网络（GNNs）在各种网络应用中表现优异，但其性能高度依赖于节点特征的表达能力。在社交网络中，由于隐私限制或缺乏固有属性，节点特征的获得往往难以实现，这使得GNNs难以达到最佳性能。", "innovation": "本文提出了两种构建表达性强的节点特征的方法。首先，结合平均可控性和其他拓扑中心性度量（NCT-EFA），提出了一种秩编码方法，将拓扑中心性度量转换到固定维度特征空间，从而改善了特征表示，显著提升了GNN性能。", "conclusion": "通过在网络控制理论的基础上使用秩编码方法构建节点特征，能够有效地提高GNN在社交网络分类任务中的性能。实验结果表明，使用GraphSAGE在GitHub Stargazers数据集上，该方法比传统的基于度的单热编码提高了ROC AUC分数（从68.7%到73.9%）。"}
{"llm_update_time": "20250723", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2501.13358", "html_url": "https://arxiv.org/abs/2501.13358", "title": "学习在非稳定重复的一级密封价格拍卖中出价", "title_en": "Learning to Bid in Non-Stationary Repeated First-Price Auctions", "authors": "Zihao Hu,Xiaoyu Fan,Yuan Yao,Jiheng Zhang,Zhengyuan Zhou", "background": "在数字广告市场中，一级价格拍卖最近得到了显著的关注，例如谷歌从二级价格拍卖转向了一级价格拍卖。在二次价格拍卖中，报价自己的真实估值是一个主导策略。而一级价格拍卖中，最优出价策略更为复杂。从学习的角度来看，学习者（即特定竞标者）可以与环境（其他竞标者，即对手）进行顺序交互以推断对手的行为。现有研究通常假设特定的环境条件，并以最佳固定策略（静态基准）为基准来衡量性能。尽管这种方法确保了强大的学习保证，但在环境具有轻微非平稳性的情况下，静态基准可能会与最优策略产生显著偏差。", "innovation": "该研究引入了两种度量标准来量化对手最高投标序列的规律性，作为非平稳性的度量。通过最小极大最优的方式表征满足这两种度量标准之一的对手最高投标序列的动态后悔。主要的技术工具是新颖的乐观镜像下降（OMD）框架，该框架适用于此情境下实现最小极大最优动态后悔率。通过合成数据集验证了理论保障，并表明新方法优于现有方法。", "conclusion": "通过研究在线的一级价格拍卖中的奖励函数，引入了两个度量非平稳性的指标，并提出了一个新颖的镜像下降框架，实现了对该特定问题的动态后悔最优率。实验结果证明了理论的有效性，并且该方法在性能上优于现有的方法。"}
{"llm_update_time": "20250723", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2405.18383", "html_url": "https://arxiv.org/abs/2405.18383", "title": "2024 BraTS陈eningioma放疗计划自动化分割挑战分析", "title_en": "Analysis of the 2024 BraTS Meningioma Radiotherapy Planning Automated Segmentation Challenge", "authors": "Dominic LaBella,Valeriia Abramova,Mehdi Astaraki,Andre Ferreira,Zhifan Jiang,Mason C. Cleveland,Ramandeep Kang,Uma M. Lal-Trehan Estrada,Cansu Yalcin,Rachika E. Hamadache,Clara Lisazo,Adrià Casamitjana,Joaquim Salvi,Arnau Oliver,Xavier Lladó,Iuliana Toma-Dasu,Tiago Jesus,Behrus Puladi,Jens Kleesiek,Victor Alves,Jan Egger,Daniel Capellán-Martín,Abhijeet Parida,Austin Tapp,Xinyang Liu,Maria J. Ledesma-Carbayo,Jay B. Patel,Thomas N. McNeal,Maya Viera,Owen McCall,Albert E. Kim,Elizabeth R. Gerstner,Christopher P. Bridge,Katherine Schumacher,Michael Mix,Kevin Leu,Shan McBurney-Lin,Pierre Nedelec,Javier Villanueva-Meyer,David R. Raleigh,Jonathan Shapey,Tom Vercauteren,Kazumi Chia,Marina Ivory,Theodore Barfoot,Omar Al-Salihi,Justin Leu,Lia M. Halasz,Yuri S. Velichko,Chunhao Wang,John P. Kirkpatrick,Scott R. Floyd,Zachary J. Reitman,Trey C. Mullikin,Eugene J. Vaios,Christina Huang,Ulas Bagci,Sean Sachdev,Jona A. Hattangadi-Gluth,Tyler M. Seibert,Nikdokht Farid,Connor Puett,Matthew W. Pease,Kevin Shiue,Syed Muhammad Anwar,Shahriar Faghani,Peter Taylor,Pranav Warman,Jake Albrecht,András Jakab,Mana Moassefi,Verena Chung,Rong Chai,Alejandro Aristizabal,Alexandros Karargyris,Hasan Kassem,Sarthak Pati,Micah Sheller,Nazanin Maleki,Rachit Saluja,Florian Kofler,Christopher G. Schwarz,Philipp Lohmann,Phillipp Vollmuth,Louis Gagnon,Maruf Adewole,Hongwei Bran Li,Anahita Fathi Kazerooni,Nourel Hoda Tahon,Udunna Anazodo,Ahmed W. Moawad,Bjoern Menze,Marius George Linguraru,Mariam Aboian,Benedikt Wiestler,Ujjwal Baid,Gian-Marco Conte,Andreas M. Rauschecker,Ayman Nada,Aly H. Abayazeed", "background": "BraTS-MEN-RT挑战旨在利用包含750例具有完整或术后鞍区蛛网膜瘤患者的射线治疗计划MRI数据集，推动自动分割算法的发展。这些MRI数据来自多个医疗机构并附有专家标注的目标体积标签，患者接受了常规外部束放射治疗或立体定向放射外科治疗。每例病例包含一个去标识的3D对比后T1加权MRI以及代表肿瘤体积（GTV）及其手术后风险部位的单一标签。“目标体积”注释遵循了放射治疗规划的既定协议，并得到了神经放射科专家和放射肿瘤科医生的审批，确保了案例间和医疗机构间的标准化和一致性。", "innovation": "六个团队利用全面的数据集开发、容器化并评估了自动分割模型。采用修改后的病灶级Dice相似系数（DSC）和95%霍夫施泰尔距离（95HD）进行团队排名。最佳的平均病灶级DSC和95HD分别为0.815和26.92毫米。BraTS-MEN-RT挑战通过精确的肿瘤分割和个性化的治疗计划，有望显著推进自动化放疗规划，最终改善患者的治疗结果。", "conclusion": "BraTS-MEN-RT挑战通过提供大规模的数据集和明确的评估标准，促进了自动分割算法的发展，并展现了其在肿瘤分割和个性化治疗中的潜力，最终能够提升患者的治疗效果和生活质量。"}
{"llm_update_time": "20250723", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2409.00966", "html_url": "https://arxiv.org/abs/2409.00966", "title": "低次多项式检测具有共同父模型的关联随机块模型的计算转变", "title_en": "A computational transition for detecting correlated stochastic block models by low-degree polynomials", "authors": "Guanyi Chen,Jian Ding,Shuyang Gong,Zhangsong Li", "background": "检测一对随机图之间的关联性是一个统计学和计算问题的基础，近年来被广泛研究。本文关注一个小世界社区数量、平均度和偏差参数固定的情况下，通过对共同父模型进行子采样的关联（稀疏）随机块模型的检测问题，将重点关注基于邻接矩阵条目低次多项式的测试，以确定这两种模型区分的阈值。研究中还探讨了这种判定方法的局限性及其在部分恢复和检测计算复杂性的关系。", "innovation": "本文创新点在于提出了基于低次多项式的检测方法，并确定了此类测试区分关联随机块模型与独立Erdős-Rényi图的阈值条件，以及证明了低次多项式的计算复杂性过渡，并通过降低度计算及还原论证，得到了部分恢复和检测的计算难度转换点。", "conclusion": "研究表明，在给定条件下，低次多项式测试可以区分两种模型的阈值为 $s> \text{min} \big\brace{\text{Otter's常数}^{\frac{1}{2}}, \frac{1}{\text{平均度} \times \text{偏差参数}^2}}$。并且当 $s< \text{min} \big\brace{\text{Otter's常数}^{\frac{1}{2}}, \frac{1}{\text{平均度} \times \text{偏差参数}^2}}$ 时，存在低次多项式难以解决部分恢复和检测的问题。"}
{"llm_update_time": "20250723", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2408.04607", "html_url": "https://arxiv.org/abs/2408.04607", "title": "风险与交叉验证在具有相关样本的岭回归中的研究", "title_en": "Risk and cross validation in ridge regression with correlated samples", "authors": "Alexander Atanasov,Jacob A. Zavatone-Veth,Cengiz Pehlevan", "background": "近年来，我们在理解和掌握高维岭回归方面取得了显著进展，但现有理论假设训练样本是独立的。该研究利用随机矩阵理论和自由概率技术，提供了高维岭回归的入样风险和出样风险的精确渐近分析，即使在数据点具有任意相关性的条件下也成立。研究还展示了当使用GCV估计器时，它在有相关样本的情况下不能准确预测出样风险。通过假设噪声残差与数据点具有相同的相关性，研究提出了一种新的估计器CorrGCV，其能够有效地计算且在高维条件下收敛，进一步将此方法扩展到测试点与训练集具有非平凡相关性的场景，特别是在时间序列预测中常见的场景。", "innovation": "研究创新地将随机矩阵理论和自由概率技术应用于具有相关性的样本，提供了高维岭回归的精确渐近分析，首次提出了CorrGCV估计器，可以在有相关样本的情况下精确预测出样风险，甚至扩展到测试点与训练集具有非平凡相关性的场景，从而精确地量化了这种测试点对长期风险预警的过度乐观程度。", "conclusion": "研究验证了理论预测在多种高维数据集上的准确性。"}
{"llm_update_time": "20250723", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2407.04476", "html_url": "https://arxiv.org/abs/2407.04476", "title": "重新思考点云上采样的数据输入", "title_en": "Rethinking Data Input for Point Cloud Upsampling", "authors": "Tongxu Zhang", "background": "点云上采样对于3D重建等任务至关重要。目前的点云上采样方法依赖于基于片段的输入，但尚未有研究讨论基于整体模型输入和基于片段输入之间的差异和原则。", "innovation": "提出了一种新的方法，使用整体模型输入，即平均片段输入。实验结果显示，基于片段的输入在点云1K和ABC数据集上的表现始终优于整体模型输入。通过分析特征提取和网络架构的影响因素，试图解释这一现象。", "conclusion": "尽管整体模型输入表现出一定的优势，但基于片段的输入在点云上采样任务中仍具有更占优势的表现。深入的特征提取和网络架构分析对于理解这种表现差异至关重要。"}
{"llm_update_time": "20250723", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2405.19383", "html_url": "https://arxiv.org/abs/2405.19383", "title": "网络分析在反洗钱中的应用——系统文献综述与实验评估", "title_en": "Network Analytics for Anti-Money Laundering -- A Systematic Literature Review and Experimental Evaluation", "authors": "Bruno Deprez,Toon Vanderschueren,Bart Baesens,Tim Verdonck,Wouter Verbeke", "background": "洗钱行为对社会造成广泛威胁，为其非法活动提供资金支持。由于洗钱涉及多方协作，使用网络信息成为有效打击洗钱的重要手段，促进了一系列网络分析在反洗钱（Anti-Money Laundering, AML）领域的研究。然而，现有文献较为分散，缺乏全面综述，导致对现有方法及其检测能力的理解有限。", "innovation": "本文进行了一项广泛的独特文献综述，基于Web of Science和Scopus的97篇论文，创建了一个基于最新提出的欺诈分析框架的分类体系。研究发现大多数研究依赖专家规则和手工特征，而深度学习方法正在兴起。同时，本文还提出了一个标准框架来评估和比较顶尖方法的性能，并在两个公开可用数据集上比较了手工特征工程、随机游走和深度学习方法。指出网络分析增强了预测能力，但对于图神经网络（GNNs）的应用需要谨慎，尤其是在面对类不平衡和网络拓扑的情况下，并且需要注意合成数据可能带来的伪乐观结果。", "conclusion": "(1) 网络分析增强了预测能力，但在应用GNNs时需要谨慎对待类不平衡和网络拓扑的问题；(2) 合成数据可能产生过于乐观的结果，应谨慎使用；(3) 开源实现有助于研究人员和从业者利用此工作扩展到私有数据，以推广标准化的网络分析评估方法在反洗钱中的分析与评价体系。"}
{"llm_update_time": "20250723", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.15470", "html_url": "https://arxiv.org/abs/2507.15470", "title": "FedMultiEmo: 实时情绪识别的多模态联邦学习", "title_en": "FedMultiEmo: Real-Time Emotion Recognition via Multimodal Federated Learning", "authors": "Baran Can Gül,Suraksha Nadig,Stefanos Tziampazis,Nasser Jazdi,Michael Weyrich", "background": "车内情绪识别是智能驾驶辅助系统的基石，最终关系到乘客的安全。然而，实际部署受到模态脆弱性、生理差异性和隐私风险的阻碍。模态脆弱性指的是不良光照和遮挡会降低基于视觉的方法的效果；生理变量性指的是心率和皮肤电导模式在不同个体之间存在差异；隐私风险指的是集中训练需要传输敏感数据。为解决这些问题，本研究提出了FedMultiEmo，这是一种隐私保护框架，它在决策层面融合了两种互补的模态：通过卷积神经网络从面部图像中提取的视觉特征，以及由随机森林分类的心率、皮肤电和皮肤温度生理指标。", "innovation": "FedMultiEmo采用了三项关键要素：（1）基于多数投票融合的多模态联邦学习管道；（2）从树莓派客户端到云的端到端原型，在Flower服务器上运行；（3）个性化的联邦平均化方案，根据本地数据量对客户端更新进行加权。该框架在FER2013数据集和自定义的生理数据集上进行了评估，结果显示联邦卷积神经网络的准确率为77%，随机森林为74%，两者融合后的准确率为87%，在保持所有原始数据本地化的前提下与集中式的基准匹配。系统在18轮内收敛，平均周期时间为120秒，每个客户端的内存占用量低于200MB。这表明FedMultiEmo提供了一种实用的方法，可以在汽车环境中实现实时、隐私保护的情绪识别。", "conclusion": "FedMultiEmo展示了在汽车环境中实现实时、隐私保护的情绪识别的实用方法，通过多模态联邦学习解决了一系列挑战，包括模态脆弱性、生理变异性以及隐私风险。该研究达到了与集中训练相同的准确率，同时保持了所有数据的本地化，为智能驾驶辅助系统提供了一种新型的情绪识别解决方案。"}
{"llm_update_time": "20250723", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2410.02760", "html_url": "https://arxiv.org/abs/2410.02760", "title": "从语言模型中消除概念性知识", "title_en": "Erasing Conceptual Knowledge from Language Models", "authors": "Rohit Gandikota,Sheridan Feucht,Samuel Marks,David Bau", "background": "近年来，语言模型在多个领域的应用日益广泛，但这些模型在学习过程中会积累大量数据，可能导致对某些敏感或特定概念的保留。因此，如何有效地从模型中删除与特定概念相关的知识成为了一个重要挑战。作者提出了一个概念级的遗忘方法，名为Erasure of Language Memory（ELM），通过模型自身的内省分类能力匹配分布进行概念级的遗忘操作，以达到有效去除与非期望概念相关的生成内容的目的。", "innovation": "ELM 提出了一种新的视角，即利用模型的自我评估能力来识别和减少与非期望概念相关的内容生成概率。具体来说，ELM 采用了基于模型自身语言能力的分类器来进行低秩更新，以减少与特定概念相关的生成概率，同时保持模型的广泛能力。这种方法相比之前的方法，更加有针对性且效果显著。实证研究也验证了该方法在生物安全、网络安全和文学领域的有效性。", "conclusion": "ELM 方法在纠错和保护隐私方面表现出色，能将修改后的模型在针对被删除概念的评估中接近随机性能，同时保持不相关任务上的基准性能，并且具有良好的对抗攻击鲁棒性。研究者已开源了相关的代码、数据和训练模型。"}
{"llm_update_time": "20250723", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2408.07114", "html_url": "https://arxiv.org/abs/2408.07114", "title": "对无监督和监督高光谱异常检测方法的研究", "title_en": "Investigation of unsupervised and supervised hyperspectral anomaly detection", "authors": "Mazharul Hossain,Aaron Robinson,Lan Wang,Chrysanthe Preza", "background": "高光谱成像是一种用于检测异常并区分场景中材料的有效工具。高光谱异常检测（HS-AD）有助于表征捕捉到的场景，并将它们分为异常和背景类别。在农业、环境和军事应用（例如战区监视和目标获取任务）中至关重要。我们之前设计了一个等价投票集合模型，结合了高光谱解混和三种无监督的HS-AD算法。后来我们利用监督分类器来确定投票集合的权重，创建了一个混合模型，将多种异构无监督HS-AD算法与监督分类器结合在模型堆叠中，从而提高了检测准确性。然而，监督分类方法通常难以检测那些显著不同于先前观察到模式的新型或未知模式。", "innovation": "本工作的创新点在于，通过使用通用的高光谱数据评估我们的方法和其他监督和无监督方法，提供新的见解。这种方法是在已有的基础上，结合了无监督HS-AD算法和监督分类器的模型堆叠，特别强调对于新型或未知模式的检测能力。", "conclusion": "本研究通过对现有无监督和监督方法的评估，提供了关于高光谱异常检测的新洞察，特别是在检测新型或未知模式方面的改进。"}
{"llm_update_time": "20250723", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2412.08629", "html_url": "https://arxiv.org/abs/2412.08629", "title": "FlowEdit：使用预训练流模型的无反转文本基础编辑", "title_en": "FlowEdit: Inversion-Free Text-Based Editing Using Pre-Trained Flow Models", "authors": "Vladimir Kulikov,Matan Kleiner,Inbar Huberman-Spiegelglas,Tomer Michaeli", "background": "使用预训练文本到图像（T2I）流模型编辑真实图像时，通常需要将图像转换为其对应的噪声图。然而，仅仅进行反转通常不足以获得令人满意的编辑结果，因此许多方法在采样过程中进行额外干预。这些方法虽然可以提高结果质量，但它们不能无缝地在不同的模型架构之间进行转移。为了解决这个问题，提出了FlowEdit，一种基于文本的编辑方法，适用于预训练的T2I流模型，该方法无需反转、无需优化且模型无关性。FlowEdit直接构建了一个ODE，将源分布映射到目标分布，并实现了比反转方法更低的传输成本，从而达到最先进的成果。我们在Stable Diffusion 3和FLUX上展示了这一点。", "innovation": "FlowEdit是一种无需反转和优化的、与模型无关的文本基础编辑方法，直接通过构建ODE（常微分方程）将源和目标分布进行映射，从而降低传输成本，取得优于现有方法的成果。这种方法能够无缝地在不同模型架构间进行应用。", "conclusion": "FlowEdit通过直接映射目标分布，实现了与预训练T2I流模型兼容的文本基础编辑，取得了先进的成果。"}
{"llm_update_time": "20250723", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2412.01661", "html_url": "https://arxiv.org/abs/2412.01661", "title": "R-Bot: 一种基于LLM的查询重写系统", "title_en": "R-Bot: An LLM-based Query Rewrite System", "authors": "Zhaoyan Sun,Xuanhe Zhou,Guoliang Li,Xiang Yu,Jianhua Feng,Yong Zhang", "background": "查询重写对于优化SQL查询以提高其执行效率非常重要。传统方法依赖于启发式和基于学习的方法来解决这一问题，但这些方法在质量和鲁棒性方面存在局限性。近年来，大型语言模型（LLM）的发展为利用其在自然语言和代码理解方面的高级能力提供了新的范式。然而，直接应用如GPT-4这样的LLM存在挑战，例如会产生不准确或不相关的结果，即‘幻觉’问题。", "innovation": "本文提出了一种名为R-Bot的基于LLM的查询重写系统。具体创新点包括：1）设计一个多源头重写证据准备流水线，生成查询重写证据以指导LLM避免幻觉；2）提出了一种结合结构和语义分析的混合检索方法，以便有效回答在线查询；3）提出了一种逐步的LLM重写方法，该方法逐步利用检索到的证据来选择和排列重写规则，具有自我反思的能力。实验结果表明，R-Bot系统在真实数据集和广泛使用的基准测试上都超过了现有的最先进的查询重写方法，且在华为和实际客户中部署后显示了较低的查询延迟。", "conclusion": "R-Bot系统展示了在利用LLM进行查询重写方面的重要进展，克服了传统方法和直接应用LLM存在的不足，实现了高质量且高效的优化。"}
{"llm_update_time": "20250723", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2501.07525", "html_url": "https://arxiv.org/abs/2501.07525", "title": "RadAlign：通过视觉-语言概念对齐促进放射学报告生成", "title_en": "RadAlign: Advancing Radiology Report Generation with Vision-Language Concept Alignment", "authors": "Difei Gu,Yunhe Gao,Yang Zhou,Mu Zhou,Dimitris Metaxas", "background": "自动化胸部X光影像的解释需要精准的疾病分类和详细的放射学报告生成，在临床流程中带来重大挑战。当前的方法要么注重分类准确性而牺牲可解释性，要么通过图像描述技术生成详细但可能不可靠的报告。在本研究中，我们介绍了RadAlign，这是一种新颖的框架，结合了视觉语言模型（VLMs）的预测准确性和大型语言模型（LLMs）的推理能力，仿效放射科医生的日常工作流程，实现多病种平均AUC为0.885的优秀疾病分类及通过检索增强生成机制提高报告质量的GREEN分数到0.678，超越了最先进的方法（0.634）。RadAlign在保持临床可解释性的同时减少了幻觉，推进了整合预测生成AI的自动化医学成像和报告分析。", "innovation": "RadAlign采用视觉语言模型与大型语言模型相结合的新颖框架，通过视觉语言空间中的概念对齐提高疾病分类的准确性，并通过检索增强生成机制生成高质量的放射学报告，优于当前最先进的方法。", "conclusion": "提出了一种改进的自动化医学影像和报告分析框架RadAlign，通过整合预测性和生成性AI，增强了疾病分类的准确性和放射学报告的质量，同时保持临床可解释性，减少幻觉。"}
{"llm_update_time": "20250723", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2411.19951", "html_url": "https://arxiv.org/abs/2411.19951", "title": "Sparrow：基于文本到图像增强的数据高效视频LLM", "title_en": "Sparrow: Data-Efficient Video-LLM with Text-to-Image Augmentation", "authors": "Shukang Yin,Chaoyou Fu,Sirui Zhao,Chunjiang Ge,Yan Yang,Yuhan Dai,Yongdong Luo,Tong Xu,Caifeng Shan,Enhong Chen", "background": "近年来，多模态大型语言模型（MLLMs）在视觉理解领域的应用取得了成功，其性能提升主要依赖于扩大模型参数规模和数据量的主导趋势。然而，尽管数据增强主要依靠自动数据管道自行进行，但关于数据扩展效果的研究和探讨却长期被忽视。在这样的背景下，本文重新探讨了利用合成数据的扩展策略，并从数据角度出发，构建视频LLMs。实验结果显示，简单地增加视频数据样本时学习效率较低。为此，本文提出了一种名为Sparrow的数据增强方法，通过将纯文本指令合成的视频样例融入视频数据中，提高了训练效率，实验证明这一方法在性能上与或优于传统方法，并且在提升长视频理解能力方面效果显著。", "innovation": "本文提出了一种新的方法——Sparrow，通过合成数据增强视频LLMs的学习效率。具体而言，Sparrow从纯文本指令中生成类似于视频的样例，并将这些合成样例与原始视频数据混合，从而实现更高效的训练方案。", "conclusion": "本文的实验结果表明，通过Sparrow方法增强的数据集，其训练得到的视频LLM在性能上与或优于使用大量原始数据训练的模型。此外，通过引入合成样例，这些模型在长视频理解任务上表现更佳，无需专门针对长视频进行训练。同时，相关的代码和数据示例已公开，可供研究参考。"}
{"llm_update_time": "20250723", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2502.08773", "html_url": "https://arxiv.org/abs/2502.08773", "title": "通用模型路由以实现高效的LLM推理", "title_en": "Universal Model Routing for Efficient LLM Inference", "authors": "Wittawat Jitkrittum,Harikrishna Narasimhan,Ankit Singh Rawat,Jeevesh Juneja,Congchao Wang,Zifeng Wang,Alec Go,Chen-Yu Lee,Pradeep Shenoy,Rina Panigrahy,Aditya Krishna Menon,Sanjiv Kumar", "background": "模型路由是一种减少大型语言模型（LLMs）推理成本的简单技术，需维护候选LLM池，并学习将每个提示导向最小可行的LLM。现有的研究主要关注学习用于固定池体的LLM的路由器。本文探讨在测试时有新出现的、之前未见过的LLM时，动态路由问题的方法。", "innovation": "提出了一种名为UniRoute的新方法，通过将每个LLM表示为基于一组代表性提示预测产生的特征向量来解决动态路由问题。UniRoute包括基于聚类路由和学习聚类图两种有效的实现方式，这些方法被证明是理论最优路由规则的估计，并通过超额风险界来评估它们的误差。", "conclusion": "在各种公共基准测试中，UniRoute方法在多个之前未见过的LLM之间表现出色，表明了其有效性。"}
{"llm_update_time": "20250723", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2502.18699", "html_url": "https://arxiv.org/abs/2502.18699", "title": "MPO: 一种高效聚合多元偏好对齐的后处理框架", "title_en": "MPO: An Efficient Post-Processing Framework for Mixing Diverse Preference Alignment", "authors": "Tianze Wang,Dongnan Gui,Yifan Hu,Shuhang Lin,Linjun Zhang", "background": "强化学习从人类反馈（RLHF）在使大型语言模型（LLMs）与人类价值取向一致方面显示了潜力，但往往依赖单一的奖励模型，忽略了人类多样性的偏好。最近的方法通过利用多维度反馈来调整奖励模型并使用强化学习训练LLMs，但这种方法过程成本高且不稳定，特别是人类偏好具有竞争性和异质性的情况下。", "innovation": "提出了混合偏好优化（MPO），这是一种后处理框架，用于聚合单一目标策略，作为multi-objective RLHF（MORLHF）和MaxMin-RLHF的替代方案。MPO避免从零开始对齐，而是通过批量随机镜像下降计算每个策略的权重，线性地将现有策略组合成一个统一策略。实验结果表明，MPO在不同的偏好上实现了均衡的表现，并且与现有模型相比，计算成本显著降低。", "conclusion": "MPO在处理来自真实世界的多样性和复杂性方面表现出了优越性，显示了在大规模语言模型训练中有效聚合和处理多元偏好对齐的潜力，从而降低了计算成本。"}
{"llm_update_time": "20250723", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2409.20431", "html_url": "https://arxiv.org/abs/2409.20431", "title": "Multilevel Picard approximations and deep neural networks with ReLU, leaky ReLU, and softplus activation overcome the curse of dimensionality when approximating semilinear parabolic partial differential equations in L^p-sense", "title_en": "Multilevel Picard approximations and deep neural networks with ReLU, leaky ReLU, and softplus activation overcome the curse of dimensionality when approximating semilinear parabolic partial differential equations in $L^p$-sense", "authors": "Ariel Neufeld,Tuan Anh Nguyen", "background": "该研究背景聚焦于通过多层Picard逼近和具有ReLU、leaky ReLU和softplus激活函数的深神经网络来逼近半线性Kolmogorov偏微分方程（PDEs）的解。特别关注梯度无关、Lipschitz连续的非线性特性。", "innovation": "研究创新在于证明了多层Picard逼近和具有特定激活函数的深神经网络能够在$L^\bp$范数意义下，以多项式增长的计算复杂度和参数数量逼近半线性Kolmogorov PDEs的解，解决了高维问题的维度诅咒。", "conclusion": "研究证实，对于梯度无关、Lipschitz连续的非线性，多层Picard逼近和具有ReLU、leaky ReLU和softplus激活函数的深神经网络能够在$L^\bp$范数意义下有效地逼近半线性帕利克(P)偏微分方程的解，且计算和参数复杂度以多项式方式增长与维度和精度要求的倒数相关。"}
{"llm_update_time": "20250723", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2503.00443", "html_url": "https://arxiv.org/abs/2503.00443", "title": "由机器学习驱动的稳定且精确的无轨道DFT", "title_en": "Stable and Accurate Orbital-Free DFT Powered by Machine Learning", "authors": "Roman Remme,Tobias Kaczun,Tim Ebert,Christof A. Gehrig,Dominik Geng,Gerrit Gerhartz,Marc K. Ickler,Manuel V. Klockow,Peter Lippmann,Johannes S. Schmidt,Simon Wagner,Andreas Dreuw,Fred A. Hamprecht", "background": "霍恩贝格和库恩证明了电子能量和单粒子电子密度可以通过最小化能量泛函来获取。尽管几十年来的理论工作已经产生了越来越接近准确能量泛函的近似方法，但它们的准确性依然不足以满足许多应用需求，因此有必要尝试通过经验方法来学习这个泛函。使用旋转同构原子机器学习方法，我们首次获得了在QM9中的有机分子应用时能以化学准确度获得能量且收敛到有意义的电子密度的经验泛函。通过将扰动势获得的密度数据加入训练集中，显著提高了这一泛函的性能。这项工作展示了机器学习在缩短霍恩贝格和库恩理论与实际应用之间差距中的关键作用，并为在大型分子系统中实现高效计算铺平了道路。", "innovation": "首次利用旋转同构原子机器学习方法，获得了一种可以在QM9中对有机分子应用时达到化学准确度的能量泛函，并能收敛到有意义的电子密度。通过使用扰动势获得的密度数据作为训练集的补充，显著提高了泛函的性能。这项研究证明了机器学习在改善从理论到实际应用的过程中起着关键作用。", "conclusion": "这项工作展示了机器学习在降低从霍恩贝格和库恩理论与实际应用之间的差距中的关键作用。通过增强泛函和改进机器学习方法，机器学习能显著提高DFT计算在大型分子系统中的效率，为未来的研究和应用开辟了新的途径。"}
{"llm_update_time": "20250723", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2502.03885", "html_url": "https://arxiv.org/abs/2502.03885", "title": "InfiniteHBD：使用光学电路交换转发器构建适用于大规模语言模型的数据中心高带宽域", "title_en": "InfiniteHBD: Building Datacenter-Scale High-Bandwidth Domain for LLM with Optical Circuit Switching Transceivers", "authors": "Chenchen Shou,Guyue Liu,Hao Nie,Huaiyu Meng,Yu Zhou,Yimin Jiang,Wenqing Lv,Yelong Xu,Yuanwei Lu,Zhang Chen,Yanbo Yu,Yichen Shen,Yibo Zhu,Daxin Jiang", "background": "大规模语言模型（LLM）训练依赖于多维度并行性，其中高带宽域（HBD）对于张量并行（TP）和专家并行（EP）等通信密集型并行性至关重要。然而，现有的HBD架构在可扩展性、成本和容错性方面存在根本限制：基于交换机的HBD（如NVL-72）会带来高昂的扩展成本，而基于GPU的HBD（如TPUv3/Dojo）则遭受严重的故障传播问题。TPUv4采用了混合开关-GPU架构，但在立方体级别（例如64个TPU）的故障传播半径仍然很大。", "innovation": "我们提出了InfiniteHBD，一种新颖的基于转发器的HBD架构，通过光学电路交换（OCS）在转发器级别实现了可重构的点对多点连接性，允许拓扑自适应于环形的变量大小，从而在不增加成本的情况下实现数据中心级的可扩展性，并通过隔离故障限制在单一节点上提供故障弹性，同时充分利用无故障GPU的数据带宽。关键创新包括基于硅光电（SiPh）的低成本光学电路交换转发器（OCSTrx），可重构的k跳环形拓扑与节点间/内通信的设计，以及实现HBD-DCN协同控制算法以最大化GPU利用率并最小化跨TOR数据中心网络流量。", "conclusion": "InfiniteHBD在NVL-72成本的基础上减少了31%，近零的GPU浪费比（相较于NVL-72和TPUv4低一个数量级）以及当节点故障比低于7%时几乎为零的跨TOR带宽利用率，并将模型FLOPs利用率提高了3.37倍，相对于NVIDIA DGX（每节点8个GPU）而言。"}
{"llm_update_time": "20250723", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.14171", "html_url": "https://arxiv.org/abs/2507.14171", "title": "IPPRO: 基于投影偏移的重要性引导修剪方法在规模无关结构化剪枝中的应用", "title_en": "IPPRO: Importance-based Pruning with PRojective Offset for Magnitude-indifferent Structural Pruning", "authors": "Jaeheun Jung,Jaehyuk Lee,Yeajin Lee,Donghun Lee", "background": "随着对神经网络压缩方法需求的增长，结构化剪枝方法中的重要性导向方法被积极研究。然而，基于尺度的重要性指标和许多现代重要性标准常常限制了剪枝决策的能力，因为如果小尺度的滤波器不容易被剪枝，那么大尺度的滤波器也很少被剪枝，即使这些滤波器是冗余的。", "innovation": "本文提出了一种新的剪枝策略，通过将滤波器放置在投影空间来挑战尺度主导效应，从而为每个滤波器提供被剪枝的公平机会。通过观察梯度下降运动以测量滤波器是否朝向原点移动，纸作者构建了基于投影空间的重要性评分PROscore，并开发了基于尺度无关的重要性导向结构化剪枝方法IPPRO。结果显示，在剪枝过程中使用投影空间可以实现几乎无损剪枝，即使在微调后的性能也表现出色。", "conclusion": "本文的工作推翻了“规模相关性”在剪枝领域的神话，并在理论上和实际上扩展了基于尺度无关的重要性导向结构化剪枝的前沿。"}
{"llm_update_time": "20250723", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2503.03707", "html_url": "https://arxiv.org/abs/2503.03707", "title": "使用在线经验筛选示范", "title_en": "Curating Demonstrations using Online Experience", "authors": "Annie S. Chen,Alec M. Lessing,Yuejiang Liu,Chelsea Finn", "background": "许多机器人示范数据集包含质量各异的示范，这种异质性在预训练策略时可能有益于，但在使用最终的模仿学习目标时可能妨碍机器人性能。此外，数据中的某些策略可能不如其他策略可靠，或者在数据中代表性不足，这种策略在测试时被抽中后会导致性能不佳。此外，这些不可靠或代表性不足的策略对人类来说难以识别，筛选示范数据集需要耗费大量时间和成本。然而，使用这样的示范训练策略的表现映射了不同策略的可靠性。因此，提出了基于在线机器人经验的自我筛选（Demo-SCORE）的方法来进行策略筛选，这种方法可以在训练策略的同时剔除劣质示范。", "innovation": "提出了一种基于在线机器人经验的自我筛选方法（Demo-SCORE），该方法通过训练和交叉验证分类器区分成功的策略执行和失败的执行，并使用分类器对异质示范数据集进行过滤。这种方法不仅能够有效识别劣质示范，还能在使用所有原示范训练的基线策略的基础上显著提高策略的成功率（超过15-35%）", "conclusion": "实验证明，通过Demo-SCORE筛选后的策略表现优于使用所有原始示范训练基线策略的表现。"}
{"llm_update_time": "20250723", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2410.18527", "html_url": "https://arxiv.org/abs/2410.18527", "title": "探查排名LLM：信息检索的机理分析", "title_en": "Probing Ranking LLMs: A Mechanistic Analysis for Information Retrieval", "authors": "Tanya Chowdhury,Atharva Nijasure,James Allan", "background": "变压器网络，尤其是那些性能可与GPT模型媲美的网络，因其强大的特征提取能力而广为人知。然而，这些提取的特征的性质以及它们与人类工程设计的特征的对齐情况仍未被广泛探讨。本文研究了最新的、经过微调的大型语言模型（LLM）在段落重新排序中的内部机制。通过基于探针的分析方法，检查了排名LLM中的神经元激活情况，发现了已知的人类工程设计和语义特征的存在。研究表明，这些模型的激活包含了广泛的特征类别，包括词汇信号、文档结构、查询-文档交互以及复杂的语义表示，揭示了影响排名决策的潜在模式。通过在四种不同的排名LLM上进行实验，识别了在LLM激活中显著编码的统计信息检索特征以及那些明显缺失的特征。此外，分析了这些模型对未见过的查询和文档的响应，揭示了它们不同的泛化行为。分解LLM激活中的潜在表示，旨在提高排名模型的可解释性和有效性。研究结果为开发更加透明和可靠的检索系统提供了关键见解，并发布所有必要的脚本和代码，以支持进一步的研究。", "innovation": "本文通过对最新的、经过微调的大型语言模型进行基于探针的分析，揭示了其在段落重新排序中的内部机制，并识别了显著编码和缺失的统计信息检索特征。此外，通过实验分析了模型对未见过的查询和文档的响应，揭示了其不同的泛化行为。", "conclusion": "通过分解LLM激活中的潜在表示，研究旨在提高检索模型的可解释性和有效性。研究结果为开发更加透明和可靠的检索系统提供了关键见解。同时，研究已发布所有必要的脚本和代码，以支持进一步研究。"}
{"llm_update_time": "20250723", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2502.10556", "html_url": "https://arxiv.org/abs/2502.10556", "title": "最近在恶意软件检测领域的进展：图学习与可解释性", "title_en": "Recent Advances in Malware Detection: Graph Learning and Explainability", "authors": "Hossein Shokouhinejad,Roozbeh Razavi-Far,Hesamodin Mohammadian,Mahdi Rabbani,Samuel Ansong,Griffin Higgins,Ali A Ghorbani", "background": "恶意软件的快速演进促使开发出超越传统基于签名的方法的复杂检测技术。图学习技术因其在建模和分析恶意软件行为的复杂关系方面展现出巨大潜力，利用图神经网络（GNN）等方法的最新进展而得到应用。本综述全面探讨了恶意软件检测领域的最新进展，重点关注图学习与可解释性的互动。", "innovation": "综述了恶意软件分析技术、数据集、特征工程、图简化和图嵌入方法，突出了它们在将原始数据转换为可操作见解方面的显著性，同时确保了可伸缩性和效率。进一步讨论了可解释性技术及其在恶意软件检测中的应用，以确保透明度和可信度。通过结合这些组件，本综述展示了图学习和可解释性如何有助于构建强大的、可解释的和可扩展的恶意软件检测系统。", "conclusion": "本综述概述了未来的研究方向，以解决现有挑战并解锁这个关键网络安全领域的新机会。"}
{"llm_update_time": "20250723", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2503.17262", "html_url": "https://arxiv.org/abs/2503.17262", "title": "使用事件摄像头联合无监督学习光流和亮度", "title_en": "Unsupervised Joint Learning of Optical Flow and Intensity with Event Cameras", "authors": "Shuang Guo,Friedhelm Hamann,Guillermo Gallego", "background": "事件摄像头依赖于运动捕获场景外观的信息。因此，外观和运动是天然联系的：两种信息要么同时出现在事件数据中，要么都不出现。以往的研究将恢复这两种视觉量视为独立的任务，未能与事件摄像头的本质相符合，且忽视了两者之间的内在关系。本文提出了一种无监督学习框架，通过单一网络联合估计光流（运动）和图像亮度（外观）。", "innovation": "本文的新颖之处在于，通过对数据生成模型的全新推导，引入事件光度误差函数，该函数依赖于光流和图像亮度。进一步将该误差与对比度最大化框架相结合，形成一个综合损失函数，可以为光流和强度估计提供适当约束。实验表明，该方法在光流估计方面表现出最先进的性能，相比无监督方法，EPE降低了20%，AE降低了25%。同时，在高动态范围场景中特别提供了可竞争的亮度估计结果。此方法也实现了比其他所有光流方法和许多图像重建方法更快的推理时间，且它们只输出一个量。", "conclusion": "实验结果表明，该方法能够显著提高无监督学习中光流和图像亮度估计的准确性，并且具有比其他方法更快的推理时间，特别适用于高动态范围场景。"}
{"llm_update_time": "20250723", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2504.06439", "html_url": "https://arxiv.org/abs/2504.06439", "title": "基于图神经网络的线性网络系统分布式最优控制：一种分布式在线训练方法", "title_en": "Graph Neural Network-Based Distributed Optimal Control for Linear Networked Systems: An Online Distributed Training Approach", "authors": "Zihao Song,Shirantha Welikala,Panos J. Antsaklis,Hai Lin", "background": "本文考虑了离散时间线性网络系统的分布式最优控制问题。现有的大多数方法会产生中心化的最优控制器，并且训练过程通常是离线的。随着网络韧性的需求增加，最优控制器希望是分布式的，并且能够以分布式在线的方式进行训练，这也是本文的主要贡献点。", "innovation": "本文提出了一种基于图递归神经网络（GRNN）的分布式最优控制方法，并将其作为一个自我监督学习问题来解决。设计了基于分布式梯度计算的在线训练优化器，同时假设GRNN控制器的非线性激活函数是局部扇区有界的且斜率受限，以证明所提控制器下线性网络系统的局部闭环稳定性。", "conclusion": "通过数值仿真使用特定开发的仿真器，本文所提出的方法的有效性得到了验证。"}
{"llm_update_time": "20250723", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2504.12625", "html_url": "https://arxiv.org/abs/2504.12625", "title": "谱算法在共变移位下的表现", "title_en": "Spectral Algorithms under Covariate Shift", "authors": "Jun Fan,Zheng-Chu Guo,Lei Shi", "background": "谱算法利用谱正则化技术来分析和处理数据，提供了一个灵活的框架来解决监督学习问题。为了在训练数据和测试数据分布可能不同的实际场景中深入了解其性能，本文对谱算法在共变移位下的收敛行为进行了深入研究。在这种情况下，输入数据的边际分布不同，但给定输入的输出条件分布保持不变。", "innovation": "本文在非参数回归框架下，分析了谱算法在共变移位下的收敛速度，并展示了在训练和测试分布密度比均匀有界时，它们可以达到最小最大最优性。但是，当这些密度比无界时，谱算法可能变得非最优。为此，本文提出了一种新颖的归一化权重谱算法，它将密度比率信息纳入学习过程中。理论分析表明，这种归一化加权方法可以实现与容量无关的最优收敛速率，但会受到饱和现象的影响。通过引入权重剪裁技术，本文展示了被剪裁权重的谱算法的收敛速率可以任意接近最优容量依赖的收敛速率。", "conclusion": "本文改进了不受密度比无界情况下的下限估算方法，并通过引入权重剪裁技术，谱算法的收敛速率可以接近最优的与容量有关的收敛速率，从而解决了非最优问题，提升了现有理论结果的精度。"}
{"llm_update_time": "20250723", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2505.08195", "html_url": "https://arxiv.org/abs/2505.08195", "title": "Aitomia: 您的AI驱动的原子和量子化学模拟的智能化助手", "title_en": "Aitomia: Your Intelligent Assistant for AI-Driven Atomistic and Quantum Chemical Simulations", "authors": "Jinming Hu,Hassan Nawaz,Yuting Rui,Lijie Chi,Arif Ullah,Pavlo O. Dral", "background": "尽管AI和机器学习技术在原子和量子化学模拟中的应用蓬勃发展，但仍存在对非专家用户使用这些模拟技术的障碍。为解决这一问题，研究人员开发了一个名为Aitomia的平台，旨在利用AI技术辅助专家和非专家用户设置、运行和分析原子水平的模拟任务，降低了模拟的门槛，促进了相关领域的研究和发展。", "innovation": "Aitomia平台通过使用大型语言模型，结合了MLatom生态系统的优势，能够进行从基态到激发态的多种AI增强计算化学任务，包括几何优化、热化学和光谱计算。多代理系统的实现使得复杂计算工作流的自动化执行成为可能，如反应焓的计算。此外，Aitomia首次提供了一个在线云平台，供广泛的原子模拟在线使用（Aitomistic Hub）。用户还可以将其本地部署。", "conclusion": "Aitomia平台的推出不仅简化了原子模拟的过程，降低了用户使用AI技术进行模拟学习和操作的门槛，还促进了相关领域的研究和创新。"}
{"llm_update_time": "20250723", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2505.16320", "html_url": "https://arxiv.org/abs/2505.16320", "title": "通过自动编码器从多模式Gaia数据学习变源的新表示", "title_en": "Learning novel representations of variable sources from multi-modal $\\textit{Gaia}$ data via autoencoders", "authors": "P. Huijse,J. De Ridder,L. Eyer,L. Rimoldini,B. Holl,N. Chornay,J. Roquette,K. Nienartowicz,G. Jevardat de Fombelle,D. J. Fritzewski,A. Kemp,V. Vanlaer,M. Vanrespaille,H. Wang,M.I. Carnerero,C.M. Raiteri,G. Marton,M. Madarász,G. Clementini,P. Gavras,C. Aerts", "background": "Gaia Data Release 3 (DR3) 提供了数百万变量源的光度和低分辨率光谱数据，及其分类结果。该数据集为研究变量现象提供了独特机会。为了准备即将到来的DR4，研究团队提出了新的机器学习方法，以处理多模态Gaia数据产品并实现恒星和类星体变量现象的无监督分类。", "innovation": "提出了一种新的方法，使用三种变分自编码器（VAE）分别处理低分辨率光谱数据、基于G波段星等差值的新方法和折合G波段光曲线，将每个Gaia源压缩为15个表示，这有效地区分行态数据的主变量类。这种方法强调了结合不同Gaia数据产品的优点，并展示了潜在的天体物理发现。这项工作通过自编码器学习出了一种新的表示，这对变化分析任务（分类、聚类和异常检测）非常有价值。", "conclusion": "通过将光曲线和低分辨率光谱数据进行压缩和生成，研究展示了一种新的表示方法的重要性，这种表示法在多重任务中均有优良的表现，尤其是对于变化现象分析。二维投影揭示了大量的过密区域，这与天体物理性质密切相关，凸显了该潜在的空间在天体物理发现中的潜力。"}
{"llm_update_time": "20250723", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2505.16104", "html_url": "https://arxiv.org/abs/2505.16104", "title": "Hierarchical Safety Realignment: Lightweight Restoration of Safety in Pruned Large Vision-Language Models", "title_en": "Hierarchical Safety Realignment: Lightweight Restoration of Safety in Pruned Large Vision-Language Models", "authors": "Yue Li,Xin Yi,Dongsheng Shi,Gerard de Melo,Xiaoling Wang,Linlin Wang", "background": "随着大型视觉-语言模型（LVLMs）规模的增大，针对资源受限环境压缩模型的网络剪枝技术获得了广泛关注。然而，剪枝往往会导致安全性能下降。因此，本文探讨了如何在剪枝后恢复LVLMs的安全性问题，并提出了一个新的轻量级方法——层次化安全性重新对齐（HSR）.", "innovation": "基于量化每个注意力头对安全性的贡献，HSR首先确定最核心的注意力头，然后选择性地恢复对维护安全性起关键作用的神经元。该方法按照从注意力头到神经元的层次结构重新对齐剪枝后的LVLMs的安全性。HSR在不同模型和剪枝策略下进行了验证，并在安全性能上取得了显著改善。这是第一个明确集中在剪枝后恢复LVLMs安全性的研究.", "conclusion": "通过HSR方法，能够在不影响其他性能的情况下显著提高LVLMs的安全性。"}
{"llm_update_time": "20250723", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2505.07769", "html_url": "https://arxiv.org/abs/2505.07769", "title": "使用图神经网络标记矢量奇异B夸克的全hadronic奇异衰变", "title_en": "Tagging fully hadronic exotic decays of the vectorlike $\\mathbf{B}$ quark using a graph neural network", "authors": "Jai Bardhan,Tanumoy Mandal,Subhadip Mitra,Cyrin Neeraj,Mihir Rawat", "background": "本文基于我们之前在[J. Bardhan et al., Machine learning-enhanced search for a vectorlike singlet B quark decaying to a singlet scalar or pseudoscalar, Phys. Rev. D 107 (2023) 115001; arXiv:2212.02442]中的研究，探讨LHC下面对矢量奇异数B夸克对产生后异常衰变成新的规范单态（伪）标量场Φ和b夸克的前景。在电弱对称性破缺后，Φ主要以$gg/bb$终态衰变，产生完全hadronic $2b+4j$或$6b$特征。由于标准模型背景巨大且缺乏带电标尺，这是一个难以探索的通道。为克服这一挑战，我们采用了包含图神经网络后接深度神经网络的混合深度学习模型，估计这种最先进的深度学习分析流水线在完全奇异衰变的情况下，即衰变分支比BR$(B \to b\text{Φ}) = 100\text{%}$时，可以实现与半电离模式相似的性能，在高亮度LHC（HL-LHC）处，$M_B$可达到约1.8（2.4）TeV的发现（排除）范围。", "innovation": "我们采用了一种混合深度学习模型，该模型以图神经网络为先驱，后接深度神经网络。这种方法能够克服困难的hadronic终态背景，提高对矢量奇异数B夸克奇异衰变的发现能力，特别是在完全没有特征标尺和巨大标准模型背景的极端情况下，能够实现性能媲美半电离模式的结果，显著扩展了对探测该物理过程的界限。", "conclusion": "我们的研究表明，采用混合深度学习模型可以提高描绘出矢量奇异数B夸克对产生后完全hadronic衰变的敏感度，在高亮度LHC处可将发现（排除）范围分别从当前的1.8（2.4）TeV拓展到约2.4（3.6）TeV，从而大大提高对该物理过程探测的可能性。"}
{"llm_update_time": "20250723", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2412.07477", "html_url": "https://arxiv.org/abs/2412.07477", "title": "渐进分辨率策略蒸馏: 利用粗分辨率仿真进行高效细分辨率策略学习", "title_en": "Progressive-Resolution Policy Distillation: Leveraging Coarse-Resolution Simulations for Time-Efficient Fine-Resolution Policy Learning", "authors": "Yuki Kadokawa,Hirotaka Tahara,Takamitsu Matsubara", "background": "在土方和建设中，挖掘机经常遇到带有不同土壤条件的大块岩石，这需要熟练的驾驶员。该论文提出了一种使用强化学习（RL）实现自主挖掘的框架，通过岩石挖掘仿真器进行研究。仿真可以由整个土壤空间中的颗粒大小/数量的分辨率决定。高分辨率仿真能更贴近真实行为，但需要大量的计算时间和难以收集样本，而低分辨率仿真则能更快收集样本但与真实行为差异较大。为了结合两种分辨率的优点，我们探索了在高分辨率仿真中使用在低分辨率仿真中开发的策略进行预训练的方法。为此，我们提出了一个新的策略学习框架——渐进分辨率策略蒸馏（PRPD），该框架通过一些中间分辨率仿真逐步转移策略，并采用保守策略转移以避免导致策略转移失败的领域差异。", "innovation": "提出了一种新的策略学习框架——渐进分辨率策略蒸馏（PRPD），该方法通过一些中间分辨率仿真逐步转移策略，并采用保守策略转移以避免领域差异导致的策略转移失败。这种方法结合了低分辨率仿真的快速样本采集和高分辨率仿真的高精度，从而在时间效率上实现了高效策略学习。", "conclusion": "在岩石挖掘仿真器和九个真实岩石环境中进行了验证，表明PRPD减少了样本采集时间到原来的1/7，同时保持了与细分辨率仿真中策略学习相当的任务成功率。"}
{"llm_update_time": "20250723", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2505.18726", "html_url": "https://arxiv.org/abs/2505.18726", "title": "音频定位：自然声响基准", "title_en": "Audio Geolocation: A Natural Sounds Benchmark", "authors": "Mustafa Chasmai,Wuao Liu,Subhransu Maji,Grant Van Horn", "background": "本文探讨了仅通过声音是否可以确定某人的地理位置，以及声音信号是否足以在国家、州或甚至城市级别进行定位。研究在全球尺度上音频地理定位的挑战，并使用iNatSounds数据集的野生动物音频进行深入分析。使用基于视觉的方法，将音频录制转换为声谱图，并测试现有图像定位技术。作者假设物种鸣叫因具有明确的地理范围而提供了强大的地理定位线索，并提出了一种结合物种范围预测与基于查找的地理定位的方法。进一步评估了在分析物种丰富的录音或跨时空邻域聚合时，地理定位是否有所改进。还通过电影案例研究探索了使用音频和视觉内容进行多模态地理定位的方法。本文突出了结合音频和视觉线索的优势，并为未来的音频地理定位研究奠定了基础。", "innovation": "提出了一个视角启发的方法，将音频录制转换为声谱图，并对标有图像的地理定位技术进行了基准测试。假设物种鸣叫因其明确的地理范围提供了强大的地理定位线索，提出了一种结合物种范围预测与基于查找的地理定位的方法，并评估了在物种丰富的录音和时空邻域聚合中的地理定位效果。引入了电影案例研究，探索了使用音频和视觉内容进行多模态地理定位的方法。", "conclusion": "本文强调了结合音频和视觉线索的优势，并为未来的音频定位研究设立了方向。"}
{"llm_update_time": "20250723", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.11815", "html_url": "https://arxiv.org/abs/2506.11815", "title": "基于扩散的电生理噪音量化通过异常检测", "title_en": "Diffusion-Based Electrocardiography Noise Quantification via Anomaly Detection", "authors": "Tae-Seong Han,Jae-Wook Heo,Hakseung Kim,Cheol-Hui Lee,Hyub Huh,Eue-Keun Choi,Hye Jin Kim,Dong-Joo Kim", "background": "心电图（ECG）信号经常受到噪声的影响，这限制了它们在传统和可穿戴设备中的临床可靠性。现有的解决ECG噪声的方法依赖于特征分类或去噪，这些方法受到注释不一致性和泛化能力差的限制。", "innovation": "本文通过将ECG噪声量化重新定义为异常检测任务来解决这些限制。提出了一种基于扩散的框架，该框架用以构建清洁ECG信号的规范分布模型，无需显式的特征标签就能识别偏差作为噪声。引入了基于分布的度量标准，使用Wasserstein-1距离（$W_1$）来稳健评估性能并缓解标签不一致性。模型在宏平均$W_1$得分上达到了1.308，明显优于第二优方法48%以上。", "conclusion": "外部验证显示了其强大的泛化能力，有助于排除噪音段以提高诊断准确性并支持及时的临床干预。这种方法改善了实时ECG监测并拓宽了ECG在数字健康技术中的应用。"}
{"llm_update_time": "20250723", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2505.01966", "html_url": "https://arxiv.org/abs/2505.01966", "title": "基于目标导向的强化学习路径规划算法用于模块化自重构卫星", "title_en": "A Goal-Oriented Reinforcement Learning-Based Path Planning Algorithm for Modular Self-Reconfigurable Satellites", "authors": "Bofei Liu,Dong Ye,Zunhao Yao,Zhaowei Sun", "background": "模块化自重构卫星是由能够改变配置的独立模块单元组成的卫星集群，这种配置变化能够执行多样化任务和使命目标。现有的重构路径规划算法通常面临高计算复杂度、差的一般化能力和对多种目标配置支持有限的问题。", "innovation": "本文提出了一种目标导向的基于强化学习的路径规划算法，该算法能够解决之前方法未能克服的多个目标配置处理问题，并通过引入记忆回放技术和无效动作掩码来克服稀疏奖励和无效动作带来的显著障碍。", "conclusion": "基于此设计，我们的模型在四单元和六单元组成的模块化卫星集群中达到任意目标配置的成功率分别为95%和73%。"}
{"llm_update_time": "20250723", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2505.18574", "html_url": "https://arxiv.org/abs/2505.18574", "title": "Autocomp：基于LLM的张量加速器代码优化", "title_en": "Autocomp: LLM-Driven Code Optimization for Tensor Accelerators", "authors": "Charles Hong,Sahil Bhatia,Alvin Cheung,Yakun Sophia Shao", "background": "硬件加速器，特别是用于张量处理的加速器，在当前的计算环境中变得无处不在。尽管在构建编译器方面做出了巨大努力，但编程这些张量加速器仍然是一个挑战，导致其潜在功能被大大低估。大型语言模型（LLMs），经过大量代码训练，在代码生成和优化任务方面显示出巨大潜力，但生成低资源语言如专门的张量加速器代码仍然存在重大挑战。", "innovation": "Autocomp 通过自动化LLM驱动的搜索方式，使加速器程序员能够利用领域知识和硬件反馈来优化代码。它通过将每次优化操作分为规划和代码生成两阶段结构化提示、在规划中插入简明且可适应的知识菜单以及在每次搜索迭代中整合硬件的正确性和性能指标作为反馈，来实现这一目标。", "conclusion": "在三类代表性工作负载和两种不同加速器上，Autocomp优化的代码性能优于供应商提供的库，比厂商提供的库分别快5.6倍（GEMM）和2.7倍（卷积），相比于专家级手工调优代码，分别快1.4倍（GEMM）、1.1倍（卷积）和1.3倍（精细粒度线性代数）。此外，Autocomp生成的优化计划可以跨类似张量操作重用，在固定样本预算下可提高多达24%的速度提升。"}
{"llm_update_time": "20250723", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2504.15993", "html_url": "https://arxiv.org/abs/2504.15993", "title": "评估机器学习模型预测翼型性能的基准", "title_en": "Benchmarking machine learning models for predicting aerofoil performance", "authors": "Oliver Summerell,Gerardo Aragon-Camarasa,Stephanie Ordonez Sanchez", "background": "本文研究了神经网络（NNs）作为传统方法的替代品，用于分析应用于风能和潮流能行业的翼型性能。当前用于评估翼型特征升力和阻力系数的方法包括计算流体动力学（CFD）薄翼型方法和板面方法，这些方法在计算速度与结果准确性之间存在权衡。因此，本文旨在验证神经网络能否同时快速和准确地进行预测。", "innovation": "本文通过训练四种不同的神经网络（MLP、PointNet、GraphSAGE、GUNet）来评估预测翼型性能的能力。这些网络在一系列翼型在25个迎角角度下（从4°到20°）进行训练，以预测流体流动并计算升力系数（$C_L$）。研究表明，PointNet和MLP是表现最好的模型，尽管MLP的预测结果更准确，但在计算$C_L$方面，PointNet的预测结果更准确。", "conclusion": "本文利用美国国家可再生能源实验室（NREL）发布的windAI_bench数据集提供了一个基准，同时使用AirfRANSdata数据集进行了基准测试验证。PointNet和MLP被识别为两种最强的模型，尽管MLP的预测结果更符合流体行为，但PointNet的计算结果$C_L$更为精确。"}
{"llm_update_time": "20250723", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.03199", "html_url": "https://arxiv.org/abs/2506.03199", "title": "量子认知机器学习在预测染色体不稳定性中的应用", "title_en": "Quantum Cognition Machine Learning for Forecasting Chromosomal Instability", "authors": "Giuseppe Di Caro,Vahagn Kirakosyan,Alexander G. Abanov,Jerome R. Busemeyer,Luca Candelori,Nadine Hartmann,Ernest T. Lam,Kharen Musaelian,Ryan Samson,Harold Steinacker,Dario Villani,Martin T. Wells,Richard J. Wenstrup,Mengjia Xu", "background": "循环肿瘤细胞（CTCs）的形态学准确预测染色体不稳定性，有助于实时检测具有高转移潜能的CTCs，这对于液体活检诊断至关重要。然而，由于单细胞数字病理数据的高维复杂性，这一预测挑战很大。", "innovation": "提出了一种基于量子计算灵感的计算框架——量子认知机器学习（QCML），用于估计CTCs形态学预测染色体不稳定性。QCML采用量子力学原理，将数据表示为希尔伯特空间中的状态向量，实现代词感知特征建模、降维和增强泛化，无需人工特征选择。实验结果表明，当应用于外部样本验证的CTCs时，QCML在识别CTC衍生形态学特征下预测的大规模状态转换（pLST）状态方面比传统机器学习方法表现出更高的准确性。", "conclusion": "初步研究表明，QCML作为一种在高维度、小样本量的生物医学背景下具有优越性能的新机器学习工具是可行的。这项技术为通过CTC形态学识别具有生物学意义的染色体不稳定性提供了一种模拟认知学习的新途径，并为CTC分类液态活检提供了新工具。"}
{"llm_update_time": "20250723", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.11936", "html_url": "https://arxiv.org/abs/2507.11936", "title": "深度学习在几何问题解决中的综述", "title_en": "A Survey of Deep Learning for Geometry Problem Solving", "authors": "Jianzhe Ma,Wenxuan Wang,Qin Jin", "background": "几何问题解决是数学推理的关键领域，广泛应用于教育、人工智能数学能力评估以及多模态能力评估。近年来，深度学习技术的快速发展，尤其是多模态大语言模型的兴起，引发了广泛的研究热潮。", "innovation": "本文提供了一个深度学习在几何问题解决中的应用综述，包括：(i) 几何问题解决中相关任务的综合总结；(ii) 深度学习方法的相关综述；(iii) 评价指标和方法的详细分析；(iv) 对当前挑战和未来发展方向的批判性讨论。旨在提供一个全面和实用的深度学习参考，以促进该领域的进一步发展。", "conclusion": "我们创建了一个在GitHub上持续更新的论文列表: this https URL."}
{"llm_update_time": "20250723", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.04441", "html_url": "https://arxiv.org/abs/2507.04441", "title": "Categorical Conformal Prediction的喜悦", "title_en": "The Joys of Categorical Conformal Prediction", "authors": "Michele Caprio", "background": "包耳（CP）是一种不确定性表示技术，能为任何基础机器学习模型提供有限抽样校准的预测区间。尽管它作为一种不确定性量化（UQ）工具的理念依然模糊，但现有的Conformal Prediction Regions（CPRs）只能提供序数上的不确定性度量，不能量化不确定性。", "innovation": "作者采用范畴论方法，将CP视为两个新定义范畴间的态射，形成一个交换图。此方法带来三个创新点：CP本质上是UQ机制；CP统一了贝叶斯、传统频率主义和非精确概率模型；CPR是协变函子的图像，对AI隐私有重要意义。", "conclusion": "此研究发现CP具有内在的UQ能力，且与隐私保护技术有潜在应用关系，表明范畴论视角给CP带来了新的洞察。"}
{"llm_update_time": "20250723", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2503.07664", "html_url": "https://arxiv.org/abs/2503.07664", "title": "Antibiotic Resistance Microbiology Dataset (ARMD): 从电子健康记录中获取抗菌耐药性的资源", "title_en": "Antibiotic Resistance Microbiology Dataset (ARMD): A Resource for Antimicrobial Resistance from EHRs", "authors": "Fateme Nateghi Haredasht,Fatemeh Amrollahi,Manoj Maddali,Nicholas Marshall,Stephen P. Ma,Lauren N. Cooper,Andrew O. Johnson,Ziming Wei,Richard J. Medford,Sanjat Kanjilal,Niaz Banaei,Stanley Deresinski,Mary K. Goldstein,Steven M. Asch,Amy Chang,Jonathan H. Chen", "background": "ARMD 是一个来源于电子健康记录 (EHR) 的脱敏资源，它有助于抗生素抗性（AMR）的研究。该数据集包含了来自两家学术附属医院超过15年的成年患者的大数据，重点是微生物培养、抗生素敏感性以及相关临床和人口统计特征。这个资源支持抗菌管理、因果推理和临床决策方面的研究。", "innovation": "ARMD 是可重用和互操作的，促进对抗菌耐药性竞赛的协作与创新。此次研究详细描述了数据集的获取、结构及其用途，特别是其脱敏过程。", "conclusion": "ARMD 有助于对抗菌耐药性研究的支持，其数据覆盖广、结构清晰，为相关研究提供了重要资源，同时也展现了数据重用性和互操作性的优势。"}
{"llm_update_time": "20250723", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2503.07601", "html_url": "https://arxiv.org/abs/2503.07601", "title": "使用Style Matching Score实现平衡图像风格化", "title_en": "Balanced Image Stylization with Style Matching Score", "authors": "Yuxin Jiang,Liming Jiang,Shuai Yang,Jia-Wei Liu,Ivor Tsang,Mike Zheng Shou", "background": "图像风格化与内容保存之间的有效平衡一直是一个长期存在的挑战。现有的方法难以同时实现高质量的风格转换和内容的保留。", "innovation": "该研究提出了一种新颖的优化方法——Style Matching Score (SMS)，将图像风格化问题重新定义为风格分布匹配问题。SMS 利用精心设计的分数函数从现成的风格依赖LoRAs中估计目标风格分布，并提出了一种称为进阶频谱正则化的方法，它在频域中工作，逐步从低频布局到高频细节引导风格化。此外，SMS 还设计了一种语义感知梯度细化技术，利用来自扩散语义先验的相关图选择性地对语义重要区域进行风格化，从而将风格化从像素空间扩展到参数空间，使得SMS可以在轻量级的前馈生成器中实现高效的一步风格化。", "conclusion": "SMS能够有效地在风格对齐和内容保持之间取得平衡，并在广泛的实验中验证了其优于最新方法的效果。"}
{"llm_update_time": "20250723", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.05724", "html_url": "https://arxiv.org/abs/2507.05724", "title": "全路由器：在稀疏Mixture-of-Experts中共享路由决策以进行语音识别", "title_en": "Omni-Router: Sharing Routing Decisions in Sparse Mixture-of-Experts for Speech Recognition", "authors": "Zijin Gu,Tatiana Likhomanenko,Navdeep Jaitly", "background": "Mixture-of-experts (MoE) 架构最初应用于语言模型领域，但现在已扩展到自动语音识别（ASR）。传统的 MoE 方法，如 Switch Transformer，每层内部独立路由专家。大多数层的路由器在专家选择上与其他层的路由器选择之间缺乏强相关性。为增加不同层之间专家的合作并促进更专业的分工，该研究采用了一种跨不同 MoE 层共享路由器的方法。研究结果表明，在大规模半监督数据集上进行的实验以及在10个不同的 ASR 基准测试中的评估表明，全路由器转录器能够在训练损失更低的情况下始终优于密集连接和 Switch Transformer 模型，平均字错误率分别降低了11.2%和8.2%，同时增强了对不同数据的鲁棒性，同时能提供结构化的专家使用方式.", "innovation": "提出了一种跨不同 MoE 层共享路由器的方法，称为全路由器转录器 (Omni-router Transformer)，以增强不同层之间专家的合作与专业分工。实验表明该模型能够在保持或改善性能的同时，提供更有效的专家使用和更强的鲁棒性.", "conclusion": "全路由器转录器能够在训练损失更低和更大数据集上实现更好的性能。与密集连接和 Switch Transformer 模型相比，它能降低平均字错误率11.2%和8.2%，并提供更好的专家使用的结构化和鲁棒性。"}
{"llm_update_time": "20250723", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.12821", "html_url": "https://arxiv.org/abs/2507.12821", "title": "利用新颖游戏评估机器的适应性世界模型", "title_en": "Assessing Adaptive World Models in Machines with Novel Games", "authors": "Lance Ying,Katherine M. Collins,Prafull Sharma,Cedric Colas,Kaiya Ivy Zhao,Adrian Weller,Zenna Tavares,Phillip Isola,Samuel J. Gershman,Jacob D. Andreas,Thomas L. Griffiths,Francois Chollet,Kelsey R. Allen,Joshua B. Tenenbaum", "background": "人类智力表现出在新颖和不熟悉的情境中快速适应和有效解决问题的惊人能力。当前AI中对世界模型的理解和评估仍然狭隘，主要集中在从大规模数据集中学习静态表示上，而不是通过与环境的互动和探索学习这些表示的效率和有效性。本文作者指出，这种高效的适应机制与内部环境表征（即世界模型）的高效构建和改进密切相关，并称之为世界模型增量机制。然而，当前评估方式未能充分关注这种通过互动有效构建和精化世界模型的适应能力。", "innovation": "提出了一个新的评估框架，基于精心设计的游戏套件，这些游戏在核心结构上具有真正的、深厚且不断更新的新颖性，被称为新颖游戏。作者还详细阐述了构建这些游戏的关键需求，并提出了适当的指标来明确挑战和评估代理快速构建世界模型的能力。期望这一新评估框架能够激励未来对AI中世界模型的评估工作，并朝着开发具备人类级快速适应能力和稳健泛化能力的AI系统迈进，这是通用人工智能的关键组成部分。", "conclusion": "本文呼吁设计新的基准测试基于新颖游戏，以全面评估AI系统的适应性世界模型，并提供了重要步骤来推进通用人工智能的发展，使其能够具备人类级的快速适应能力和稳健泛化能力。"}
{"llm_update_time": "20250723", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.21734", "html_url": "https://arxiv.org/abs/2506.21734", "title": "层次推理模型", "title_en": "Hierarchical Reasoning Model", "authors": "Guan Wang,Jin Li,Yuhao Sun,Xing Chen,Changling Liu,Yue Wu,Meng Lu,Sen Song,Yasin Abbasi Yadkori", "background": "在人工智能领域，推理过程涉及制定和执行复杂的目标导向操作序列，仍是一项关键的挑战。当前的大语言模型主要依靠链式思维技术(Chain-of-Thought, CoT)，但这些技术存在任务分解脆弱性、大量数据需求以及高延迟等问题。", "innovation": "受人类大脑分层级和多时标处理机制的启发，本文提出了层次推理模型(Hierarchical Reasoning Model, HRM)。HRM是一种具有显著计算深度的新型递归架构，同时保持了训练稳定性和高效性。HRM通过两个相互依赖的递归模块进行顺序推理任务：高层次模块负责缓慢、抽象的规划，低层次模块处理快速、详细的计算。HRM仅使用2700万参数，在仅1000个训练样本的情况下实现了出色的复杂推理任务性能，且无需预训练或CoT数据，在包括复杂的数独谜题和大型迷宫的路径规划等挑战任务上达到了近乎完美的表现。此外，HRM在抽象与推理语料库（ARC）的关键基准上优于更大的模型和更长的上下文窗口。", "conclusion": "这些结果表明，HRM具有作为通用计算与通用推理系统变革性进展的潜力。"}
{"llm_update_time": "20250723", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.14167", "html_url": "https://arxiv.org/abs/2507.14167", "title": "基于IQ样本和FFT频谱图的注意力融合与AoA特征的GNSS干扰源定位方法", "title_en": "Attention-Based Fusion of IQ and FFT Spectrograms with AoA Features for GNSS Jammer Localization", "authors": "Lucas Heublein,Christian Wielenberg,Thorsten Nowak,Tobias Feigl,Christopher Mutschler,Felix Ott", "background": "GNSS信号遭到阻塞设备的干扰，这些设备会破坏定位的准确性，因此检测和定位这些干扰信号变得至关重要。传统的角度到达（AoA）方法在多路径环境中受到信号反射和散射的影响，降低了定位精度。此外，AoA方法还需要大量的计算资源来进行阵列信号处理。", "innovation": "本文提出了一种融合IQ样本和FFT频谱图的注意力融合框架，并结合了22个AoA特征，以增强定位精度。此外，该研究还介绍了一个由运动阻塞设备在动态多路径环境中的室内场景记录而成的新数据集，并展示了比现有先进技术更好的性能。", "conclusion": "本文通过基准研究评估了128种视觉编码器和时间序列模型，确定了最适合每个任务的高精度方法，并提出了一种新的注意力融合框架，该框架通过整合IQ样本、FFT频谱图和22个AoA特征，提高了GNSS干扰源的定位精度。所提方法在室内动态多路径条件下的新数据集上表现出了优越性能，优于现有最先进的方法。"}
{"llm_update_time": "20250723", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.12108", "html_url": "https://arxiv.org/abs/2507.12108", "title": "多模态协调在线行为：权衡与策略", "title_en": "Multimodal Coordinated Online Behavior: Trade-offs and Strategies", "authors": "Lorenzo Mannocci,Stefano Cresci,Matteo Magnani,Anna Monreale,Maurizio Tesconi", "background": "协调在线行为，涵盖有益的集体行动到有害的操纵行为如信息战等，已成为数字生态系统分析的关键关注点。传统方法通常依赖单一模态的途径，专注于单一类型的互动，如共转推或共标签，或者独立考虑多种模态。然而，这些方法可能会忽略多模态协调中存在的复杂动态。", "innovation": "本研究比较了检测多模态协调行为的不同方法，探讨了弱综合和强综合多模态模型之间的权衡，强调了捕捉更广泛的协调模式与识别紧密协调行为之间的平衡。通过比较单模态和多模态方法，评估了不同数据模态的独有贡献，并探讨了不同实施的多模态方法对检测结果的影响。研究发现，并非所有模态都提供独特的见解，但通过多模态方法可以更全面地理解协调动力学。", "conclusion": "这项工作增强了检测和分析协调在线行为的能力，提供了保护数字平台完整性的新视角。"}
{"llm_update_time": "20250723", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.14184", "html_url": "https://arxiv.org/abs/2507.14184", "title": "NeuroHD-RA: 频率对齐的神经提炼超维模型", "title_en": "NeuroHD-RA: Neural-distilled Hyperdimensional Model with Rhythm Alignment", "authors": "ZhengXiao He,Jinghao Wen,Huayu Li,Ao Li", "background": "本文提出了一个结合了超维计算(HDC)和可学习神经编码的用于心电图(ECG)疾病检测的新颖且可解释的框架。传统的HDC方法依赖于静态的随机投影，而本文的方法引入了一个基于RR间隔的时间感知和可训练编码流水线，并采用生理信号分割策略进行心脏周期对齐。该模型在Apnea-ECG和PTB-XL数据集上的实验表明，它显著优于传统的HDC方法和经典的机器学习基线，实现了73.09%的精确率和0.626的F1分数，并且在PTB-XL上具有可比的鲁棒性。该框架为边沿兼容的ECG分类提供了一个高效且可扩展的解决方案，并且具备在解释性和个性化健康监测方面巨大的潜力。", "innovation": "创新之处在于提出了一个基于RR间隔的时间感知和可训练编码流水线，并结合了神经提炼的HDC架构，其包含了一个可学习的RR-block编码器和一个BinaryLinear超维投影层，通过联合优化交叉熵损失和基于代理的度量损失来优化模型。该方法保留了HDC的符号可解释性同时允许任务自适应的表示学习。与传统的HDC方法和经典机器学习方法相比，验证了该模型在Apnea-ECG和PTB-XL数据集上表现出色，并且具有边沿兼容性。", "conclusion": "本文提出的神经提炼超维模型(名词短语)具有频率对齐的时间感知编码流水线。该模型在Apnea-ECG和PTB-XL数据集上表现出优越的性能，尤其是在边沿兼容的ECG分类中实现了高水平的精度和F1分数。此外，该框架为解释性和个性化健康监测提供了强大的潜力。"}
{"llm_update_time": "20250723", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.15460", "html_url": "https://arxiv.org/abs/2507.15460", "title": "通过联邦学习实现的隐私保护多模态新闻推荐", "title_en": "Privacy-Preserving Multimodal News Recommendation through Federated Learning", "authors": "Mehdi Khalaj,Shahrzad Golestani Najafabadi,Julita Vassileva", "background": "个性化新闻推荐系统（PNR）已经被看作是解决信息过载问题的一个解决方案，通过预测和提供契合个体用户兴趣的新闻。然而，传统的PNR系统面临许多挑战，包括对文本内容的过度依赖、忽视短期用户兴趣，以及隐私问题，如集中存储用户数据带来的安全风险。针对这些问题，本文引入了一种新颖的基于联邦学习的多模态推荐方法，以提升推荐系统的准确性和保障用户隐私。", "innovation": "该论文的创新点包括：1) 结合新闻文本和视觉特征，使用多模态模型提供更为全面的内容表示；2) 采用时间感知模型通过多头自注意力网络平衡用户长期和短期兴趣，提升推荐的准确性；3) 实现联邦学习框架，在不共享用户数据的情况下进行协作模型训练，包括一个在服务器上维护的大规模新闻模型和一个轻量级的用户模型在服务器与客户端间共享；4) 使用基于Shamir的秘密分享方案的安全聚合算法进一步保护用户隐私。", "conclusion": "实验结果表明，该方法在实际新闻数据集上的表现优于现有系统，为隐私保护的个性化新闻推荐提供了一种重大进展。"}
{"llm_update_time": "20250723", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.15773", "html_url": "https://arxiv.org/abs/2507.15773", "title": "Supernova：在变压器架构中实现少而精", "title_en": "Supernova: Achieving More with Less in Transformer Architectures", "authors": "Andrei-Valentin Tanase,Elena Pelican", "background": "本文介绍了Supernova，一个拥有650M参数的纯解码器变压器模型，展示了精细的架构设计和创新的分词技术如何在保持计算效率的同时达到更大模型的性能。文章通过详细分析，展示了Supernova在参数数量减少35%的情况下，达到90%的1B参数模型性能，且训练样本数仅为100B，远低于竞争对手。这些发现挑战了现有的模型扩展范式，表明架构效率和分词质量能够弥补参数减少的影响。", "innovation": "1. 使用了Rotary Positional Embeddings (RoPE) 和 Grouped Query Attention (GQA) 架构组合并采用了3:1的压缩比来提高性能。\n2. 采用RMSNorm以增加计算效率和SwiGLU激活函数以优化模型表现。\n3. 开发了一个定制的128,000词汇的字级BPE分词器，实现了最先进的压缩性能。\n", "conclusion": "通过上述创新，Supernova 只使用了35%的参数量和100B的训练样本，却达到了90%的1B参数模型性能。这一成就挑战了当前的模型规模扩展范式，证明了架构效率和分词质量可以补偿参数减少的影响。"}
{"llm_update_time": "20250723", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2507.15887", "html_url": "https://arxiv.org/abs/2507.15887", "title": "AlgoTune: 语言模型能否加速通用数值程序？", "title_en": "AlgoTune: Can Language Models Speed Up General-Purpose Numerical Programs?", "authors": "Ori Press,Brandon Amos,Haoyu Zhao,Yikai Wu,Samuel K. Ainsworth,Dominik Krupke,Patrick Kidger,Touqir Sajed,Bartolomeo Stellato,Jisun Park,Nathanael Bosch,Eli Meril,Albert Steppi,Arman Zharmagambetov,Fangzhao Zhang,David Perez-Pineiro,Alberto Mercurio,Ni Zhan,Talor Abramovich,Kilian Lieret,Hanlin Zhang,Shirley Huang,Matthias Bethge,Ofir Press", "background": "尽管语言模型的能力有所进步，现有的评估主要集中在模型在人类已解决任务上的表现，如编程（Jimenez等，2024）和数学（Glazer等，2024）。因此，该研究旨在测试模型在开放式基准测试中的编程设计和实现能力，即要求模型编写高效解决计算上具有挑战性的问题的代码，这些问题是出现在计算机科学、物理学和数学中的。评估基准包括来自领域专家的155个编码任务，以及一个验证和测量模型生成的解决方案代码的框架，该框架与流行的开源包中的参考实现进行比较。研究表明，当前模型未能发现算法创新，而倾向于表面级优化。", "innovation": "提出了一个名为AlgoTune的计算任务基准，用于评估模型在解决计算上具有挑战性的问题上的能力，包括计算机科学、物理学和数学领域的问题。开发了一个基线模型代理AlgoTuner，并在一系列前沿模型中进行评估。实验结果显示，AlgoTuner的性能优于参考解算器，平均速度提高了1.72倍。然而，当前模型在算法创新方面表现不佳，更倾向于进行表面级的优化。", "conclusion": "AlgoTune旨在促进能够展示超越顶级人类性能的创造性问题解决能力的语言模型代理的发展。"}
{"llm_update_time": "20250723", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2507.15892", "html_url": "https://arxiv.org/abs/2507.15892", "title": "StaAgent: 用于测试静态分析器的代理框架", "title_en": "StaAgent: An Agentic Framework for Testing Static Analyzers", "authors": "Elijah Nnorom,Md Basim Uddin Ahmed,Jiho Shin,Hung Viet Pham,Song Wang", "background": "静态分析器在软件开发生命周期早期识别错误方面起着关键作用，但它们的规则实现往往未经充分测试且容易出现不一致。为解决这一问题，本文提出了一种名为StaAgent的代理框架，该框架利用大型语言模型（LLMs）生成能力系统地评估静态分析器规则。该框架包含四个专门的代理：种子生成代理、代码验证代理、突变生成代理和分析器评估代理，以促进静态分析器基准测试。", "innovation": "本文首次提出了一个利用LLM生成能力的多代理框架StaAgent，以系统地评估静态分析器规则。StaAgent通过揭示不一致行为来发现规则实现中的缺陷，提供了一种可扩展和适应性较强的解决方案，以提高静态分析器的可靠性。实验结果表明，该方法可以揭示5个广泛使用的静态分析器（即SpotBugs、SonarQube、ErrorProne、Infer和PMD）最新版本中的64个问题规则。这些规则中有53个是现有的SOTA基准无法检测到的。", "conclusion": "实验结果证明了该方法的有效性，并强调了代理驱动的、基于LLM的数据合成对未来软件工程的潜在促进作用。"}
{"llm_update_time": "20250723", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2507.15889", "html_url": "https://arxiv.org/abs/2507.15889", "title": "Dr. Boot: 通过 Bootstrap 为程序合成语言模型进行故障修复", "title_en": "Dr. Boot: Bootstrapping Program Synthesis Language Models to Perform Repairing", "authors": "Noah van der Vleuten", "background": "现有的程序合成语言模型通常在编程竞赛数据集（如MBPP, APPS）上进行训练和评估，但这些数据集在规模和质量上都有限。此外，这些语言模型在程序合成过程中与人类的互动方式不匹配。人类在开发代码时通常会从编译器获得反馈并迭代地改进，而大多数程序合成模型则一次性输出完整代码。鉴于这些问题，本文提出了一种用于程序合成的自助算法，能够教会模型如何修复错误。这篇文章展示了这种自助算法在保持精度的同时，还可以帮助模型在没有编译器反馈的情况下更好地工作。然而，实战过程中修复代码可能不如简单的随机采样更有效。此外，还指出了APPS数据集中测试案例的问题，这些问题对于其他许多故障修复和强化学习方法来说非常重要，值得整个社区关注。\n", "innovation": "本文引入了一种自助算法用于程序合成，这种算法能够指导模型进行代码修复。与常规微调相比，这种方法表现更佳。更重要的是，这种带有修复功能的自助方法在推理阶段改善了非修复功能的性能，虽然实战中直接修复代码可能不如采样解决方案有效。此外，文中揭示了APPS数据集中某些测试案例的问题，这些问题对于理解修复和强化学习方法来说是宝贵的资源。\n", "conclusion": "通过引入自助算法，模型不仅能固定代码错误，还能提升整体性能，尤其是在数据规模和质量有限的情况下。尽管修复代码在实践中可能不如采样有效，但文中提出了这些测试案例对于研究修复和强化学习方法的重要贡献。\n"}
{"llm_update_time": "20250723", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2507.16044", "html_url": "https://arxiv.org/abs/2507.16044", "title": "将REST API转换为代理准备：从OpenAPI到模型上下文协议服务器，以支持工具增强的大语言模型", "title_en": "Making REST APIs Agent-Ready: From OpenAPI to Model Context Protocol Servers for Tool-Augmented LLMs", "authors": "Meriem Mastouri,Emna Ksontini,Wael Kessentini", "background": "大语言模型（LLMs）正在从被动的文本生成器转变为可以调用外部工具的主动代理。为了支持这一转变，需要规模化的工具集成协议。MCP（Model Context Protocol）由Anthropic在2024年推出，提供了一个基于模式的标准，用于动态工具发现和调用。然而，构建MCP服务器依旧是手动且重复的，开发者需要编写中间代码、处理认证并手工配置模式，这些都违背了MCP旨在消除的集成困难。本文研究如何将MCP服务器构建自动化。基于开源项目数据，研究发现大部分项目缺乏MCP服务器，通常是由单一维护者维护的小型项目。", "innovation": "本文提出了一种名为AutoMCP的编译器，它可以自动从OpenAPI 2.0/3.0规范生成MCP服务器。AutoMCP解析REST API定义，并自动生成涉及方案注册和认证处理的完整服务器实现。本文研究评估了50个真实世界的API接口，覆盖了10多个领域，共计5,066个端点。自动编译的结果显示，有76.5%的接口可以立即成功运行，经过少量修复后，成功率达到了99.9%。这显示了OpenAPI规范（尽管存在质量问题）可以几乎完全自动化生成MCP服务器，同时提供了修正常见规范缺陷的洞察。", "conclusion": "本文通过研究发现，MCP协议的采用率较低，大部分项目的服务器都是手动构建的且重复工作多。通过使用AutoMCP编译器，可以从OpenAPI规范自动生成MCP服务器，大大减少了构建成本。OpenAPI规范虽然存在质量问题，但依然能够几乎完全自动化生成MCP服务器。本文贡献了一组可调用的5,066个工具，并提供了修复常见规范缺陷的建议。"}
{"llm_update_time": "20250723", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2507.16208", "html_url": "https://arxiv.org/abs/2507.16208", "title": "LOCOFY Large Design Models — 设计到代码转换解决方案", "title_en": "LOCOFY Large Design Models -- Design to code conversion solution", "authors": "Sohaib Muhammad,Ashwati Vipin,Karan Shetti,Honey Mittal", "background": "尽管大型语言模型和多模态大型语言模型（LLMs）取得了迅速的发展，但在设计到代码的应用领域，仍然存在可解释性、可扩展性、资源需求和可重复性方面的诸多挑战。", "innovation": "我们提出了一种称为Large Design Models (LDMs)的新的训练范式，专门针对设计和网页进行训练，以实现从设计到代码的无缝转换。训练和推理管道包括设计优化器、标签和特征检测以及自动生成组件等功能。LDMs在从设计到代码的端到端转换精度方面表现出色，与LLMs相比，在节点定位、响应性和可重复性方面性能更优，并且定制训练的标签和特征检测模型在识别UI元素方面表现出高度的准确性和一致性。", "conclusion": "通过引入LDMs，我们提供了一个可靠且高效的解决方案，能够理解和生成可直接用于生产的代码。"}
{"llm_update_time": "20250723", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2507.16063", "html_url": "https://arxiv.org/abs/2507.16063", "title": "AI-Powered Commit Explorer (APCE),", "title_en": "AI-Powered Commit Explorer (APCE)", "authors": "Yousab Grees,Polina Iaremchuk,Ramtin Ehsani,Esteban Parra,Preetha Chatterjee,Sonia Haiduc", "background": "版本控制系统中的提交信息为开发人员提供了关于代码变更的重要信息。这些提交信息往往是未来开发人员唯一能了解变更内容及原因的信息来源。然而，编写高质量的提交信息在实践中经常被忽视。利用大型语言模型（LLM）生成提交信息已成为解决这一问题的一种方式。但现有工具大多未能为研究人员提供易于使用且高效的机制来存储不同的LLM提示、增强LLM生成的提交信息，以及对其生成的提交信息进行自动和手动评估。论文介绍了一个名为APCE的工具，旨在支持开发人员和研究人员使用和研究LLM生成的提交信息，提供存储不同LLM提示的选择，并提供一个额外的评估提示，可以进一步增强LLM生成的提交信息的质量。APCE还提供了方便的机制进行自动和人工评估LLM生成的提交信息，以满足研究人员的需求。", "innovation": "引入了APCE工具，目的在于支持开发人员和研究人员利用和研究LLM生成的提交信息。其创新点包括：1. 提供存储不同LLM提示的功能；2. 提供一个额外的评估提示来进一步增强LLM生成的提交信息；3. 提供自动和手动评估机制，以及一个透明的工具界面，使得研究者可以轻松地进行复杂的评估工作，从而推动LLM生成提交信息的质量和应用。", "conclusion": "本文介绍的APCE工具为开发人员和研究人员提供了一种新的平台，用于使用和研究LLM生成的提交信息，增强了提交信息的质量，并提供了自动和人工评估的便捷机制。通过使用这种方法，希望能够鼓励开发者们更加重视提交信息的质量，并为未来的软件维护提供宝贵的信息。"}
{"llm_update_time": "20250723", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2507.16166", "html_url": "https://arxiv.org/abs/2507.16166", "title": "构建高质量研究软件的十大关键指南", "title_en": "Ten Essential Guidelines for Building High-Quality Research Software", "authors": "Nasir U. Eisty,David E. Bernholdt,Alex Koufos,David J. Luet,Miranda Mundt", "background": "高质量的研究软件是现代科学发展的重要基石，它使研究人员能够分析复杂数据，模拟现象，并分享可重复的结果。然而，创建这样的软件需要遵循确保稳健性、易用性和可持续性的最佳实践。本文提出了适用于研究软件开发生命周期全过程的十个指导原则，强调了计划、编写清晰可读的代码、使用版本控制以及实施全面测试策略的重要性。此外，这些指导原则还讨论了模块化设计、可重复性、性能优化和长期维护的关键原则。文章还特别指出了文档和社区参与在提高软件易用性和影响方面的作用。通过遵循这些建议，研究人员可以创建推进科学研究目标的软件，并为更广泛的可靠和可重用研究工具生态系统做出贡献。这项工作为研究人员和开发者提高其研究软件的质量和影响提供了一个实用的资源。", "innovation": "本文提出了适用于研究软件开发生命周期全过程的十个关键指导原则，涵盖了从规划到实现再到维护的每一个阶段。这些原则不仅强调了编写清晰可读的代码、版本控制和全面测试策略的重要性，还特别提到了模块化设计、可重复性、性能优化和长期维护等关键原则。此外，该文章还特别强调了文档和社区参与在提高软件易用性和影响方面的作用。", "conclusion": "通过遵循上述指导原则，研究人员可以创建高质量的软件，不仅有助于实现其科学研究目标，还能为更广泛的可靠和可重用研究工具生态系统做出贡献。这项工作为研究人员和开发者加强其研究软件的质量和影响提供了一项实用资源。"}
{"llm_update_time": "20250723", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.13580", "html_url": "https://arxiv.org/abs/2507.13580", "title": "结合大型语言模型和化学片段空间的协作框架：对先导化合物设计的相互启发", "title_en": "A Collaborative Framework Integrating Large Language Model and Chemical Fragment Space: Mutual Inspiration for Lead Design", "authors": "Hao Tuo,Yan Li,Xuanning Hu,Haishi Zhao,Xueyan Liu,Bo Yang", "background": "组合优化算法在计算机辅助药物设计中至关重要，通过逐步探索化学空间来设计与目标蛋白高度亲和的先导化合物。然而，现有的方法在整合专业知识方面存在固有的挑战，导致它们在识别具有新颖和有效结合模式的先导化合物方面性能有限。", "innovation": "本文提出了一种名为AutoLeadDesign的先导化合物设计框架，该框架通过在大型语言模型中编码广泛的领域知识并结合化学片段来高效探索巨大的化学空间。实验表明，AutoLeadDesign在性能上优于基线方法。特别地，在两个临床相关目标（PRMT5和SARS-CoV-2 PLpro）的先导化合物设计活动中，AutoLeadDesign展示了与专家竞争的设计效果，并通过结构分析验证了其机制验证的抑制模式。", "conclusion": "总体而言，AutoLeadDesign提供了一种高效的先导化合物设计方法，表明其在药物设计方面的潜在用途。"}
{"llm_update_time": "20250723", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.07714", "html_url": "https://arxiv.org/abs/2507.07714", "title": "基于自适应高斯混合模型的欠约束缆驱动并联机器人异常检测", "title_en": "Adaptive Gaussian Mixture Models-based Anomaly Detection for under-constrained Cable-Driven Parallel Robots", "authors": "Julio Garrido,Javier Vales,Diego Silva-Muñiz,Enrique Riveiro,Pablo López-Matencio,Josué Rivera-Andrade", "background": "缆驱动并联机器人（CDPRs）越来越多地用于包含预定义路径和中途停留的负载操作任务。在每个停留点，平台保持固定姿态，电机保持缆线处于张紧状态。该系统需要通过检测可能影响性能的异常（例如：突发风力或缆线碰撞）来判断是否可以继续操作。现有的研究多依赖额外的传感器数据进行异常检测。该研究探讨了仅使用电机扭矩数据是否能够进行异常检测的方法。", "innovation": "提出了一种基于自适应高斯混合模型（GMM）的无监督异常检测算法。该算法首先进行短暂的校准期，以拟合已知无异常的数据。之后，通过马哈拉诺比斯距离实时评估扭矩测量值，并使用统计推导的阈值触发异常标志。模型参数会在每次更新最新的无异常段落之后进行调整以适应变化的条件。该研究包括14次模拟不同风力强度的长期测试会话。", "conclusion": "所提出的方法实现了100%的真实正率和95.4%的平均真负率，并且检测延迟为1秒。与基于功率阈值和非自适应GMM方法的对比验证显示了更高的环境变化鲁棒性。"}
{"llm_update_time": "20250723", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2507.16439", "html_url": "https://arxiv.org/abs/2507.16439", "title": "探索大规模语言模型在分析和改进科学代码方法名方面的应用", "title_en": "Exploring Large Language Models for Analyzing and Improving Method Names in Scientific Code", "authors": "Gunnar Larsen,Carol Wong,Anthony Peruma", "background": "科学家们越来越多地依赖软件来支持他们的研究。先前的研究已经探讨了标识符名称对程序理解的影响主要是在传统编程环境中，但在科学软件中这一领域的探索有限，尤其是在方法名称的质量方面。近年来，大规模语言模型（LLMs）的进步为自动化代码分析任务提供了新的机会，如标识符名称评估和建议改进。本研究评估了四种流行的LLMs，评估它们分析语法模式和建议改进496个从基于Python的Jupyter Notebooks提取的方法名称的能力。研究结果表明，这些LLMs在分析方法名称方面表现出一定的有效性，通常遵循良好的命名实践，如使用动词作为方法名称的开头。但是，它们对领域特定术语的一致处理不足，以及与人类注释的中等程度的一致性表明，自动建议需要人类评估。", "innovation": "本研究创新性地使用大规模语言模型（LLMs）来分析科学代码中的方法名称，并对其进行改进建议，为通过AI自动化提高科学代码质量提供了基础性见解。", "conclusion": "评估结果显示，虽然这些语言模型在分析方法名称方面表现良好，但在处理领域特定术语方面的一致性较差，并且其建议与人工标识符名称相比只有一般的符合度，这表明自动化建议仍需要进一步的人类评审。这项工作的基础发现为通过AI自动化提高科学代码质量提供了重要的参考。"}
{"llm_update_time": "20250723", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2507.16587", "html_url": "https://arxiv.org/abs/2507.16587", "title": "LLM-as-a-judge在代码生成和总结中的有效性", "title_en": "On the Effectiveness of LLM-as-a-judge for Code Generation and Summarization", "authors": "Giuseppe Crupi,Rosalia Tufano,Alejandro Velasco,Antonio Mastropaolo,Denys Poshyvanyk,Gabriele Bavota", "background": "大型语言模型最近被用作复杂自然语言处理任务的裁判，尤其是在问答场景中。本文选择代码生成和代码总结两个任务作为案例研究，因为定量指标通常不足以评估代码生成器或摘要的质量。现有技术对于处理这些任务的复杂实例仍然存在困难，因此更适合通过LSTM在超大规模下建立更多高级解决方案来解决此问题。研究表明，对于这两项任务，GPT-4-turbo 是表现最好的语言模型，在判断能力方面优于其他较小的拥有数十亿参数的模型，但即便如此，最优模型在判断代码和总结质量时仍然经常犯错。", "innovation": "该研究尝试使用大型语言模型作为代码生成和代码总结的质量裁判，旨在探讨在代码生成和代码总结任务中利用LSTM的有效性。这种创新性的方法旨在克服当前定量指标和大规模人工评估的成本限制。该研究还明确指出，即使最优秀的LSTM模型，在判断代码和总结质量时也存在一定的误差。", "conclusion": "GPT-4-turbo被证明是这两个任务最佳的语言模型裁判，在测试中表现出色。然而，即便如此，较小的语言模型在纠错和评估代码质量方面仍有局限性，甚至最优LSTM模型也经常错误地判决代码和总结的质量。这表明，尽管LSTM可以作为裁判来提高自动化水平，但其准确性仍需进一步提高，尤其是在处理复杂代码任务时。"}
{"llm_update_time": "20250723", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.15264", "html_url": "https://arxiv.org/abs/2507.15264", "title": "关于一类随机非凸约束问题的内部镜像下降流探索", "title_en": "On exploration of an interior mirror descent flow for stochastic nonconvex constrained problem", "authors": "Kuangyu Ding,Kim-Chuan Toh", "background": "研究一类非光滑非凸优化问题，优化域由某个开集的闭包与光滑流形的交集构成。引入了一种具有障碍函数诱导的黎曼度量的开集，从而得到一种黎曼次梯度流，这种流形展现了混合方法（即海森信念障碍方法和镜像下降方案）的内在联系，并揭示这些方法可作为连续流的离散近似。", "innovation": "通过黎曼次梯度流统一了海森信念障碍方法和镜像下降方案，解释了现有方法的不足并且引入了两种新的迭代黎曼次梯度方法，这些方法在非光滑非凸优化问题中提供了更广泛的解决方案。", "conclusion": "通过连续动态系统分析，解释了海森信念障碍方法和镜像下降方案中的伪稳定点，并为避免这些伪稳定点提出了充分条件；在没有这些正则性条件的情况下，提出了随机扰动策略以确保轨迹收敛至近似稳定点；并提出了两种迭代黎曼次梯度方法，扩展了现有的用于解决非光滑非凸优化问题的方法。"}
{"llm_update_time": "20250723", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2507.16661", "html_url": "https://arxiv.org/abs/2507.16661", "title": "VulCoCo: 一种简单而有效的检测易受攻击的代码克隆方法", "title_en": "VulCoCo: A Simple Yet Effective Method for Detecting Vulnerable Code Clones", "authors": "Tan Bui,Yan Naing Tun,Thanh Phuc Nguyen,Yindu Su,Ferdian Thung,Yikun Li,Han Wei Ang,Yide Yin,Frank Liauw,Lwin Khin Shar,Eng Lieh Ouh,Ting Zhang,David Lo", "background": "在现代软件开发中，代码重用是常见的做法，但这也可能导致漏洞传播。开发者在不知情的情况下复制了风险代码，这些代码会保留已知漏洞的逻辑，称为易受攻击的代码克隆（VCCs）。现有的VCC检测工具通常依赖于语法相似性，或者生成粗糙的漏洞预测，缺乏明确的解释，限制了它们的实际应用价值。", "innovation": "本文提出了一种名为VulCoCo的轻量级且可扩展的方法，该方法结合了嵌入式检索和大型语言模型（LLM）验证。从已知的易受攻击函数开始，VulCoCo从大型语料库中检索出语法或语义相似的候选函数，并使用LLM评估这些候选函数是否保留了漏洞。研究人员由于缺乏可重现的易受攻击的代码克隆基准数据集，先构建了一个涵盖各种克隆类型的合成基准。实验表明，VulCoCo在精确度和平均精确度方面优于以前的最佳方法。此外，VulCoCo在真实项目中的应用也证明了其有效性，提交了400个拉取请求（PR），其中75个被合并，并有15个触发了新的CVE发布。", "conclusion": "VulCoCo方法在合成基准和实际项目中均表现出色，有效提高了易受攻击的代码克隆检测的精度，并为未来工作提供了一些启示，旨在进一步提高易受攻击的代码克隆检测的精度。"}
{"llm_update_time": "20250723", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2507.16327", "html_url": "https://arxiv.org/abs/2507.16327", "title": "基于搜索生成航路点以触发海上自主船舶自我适应的方法", "title_en": "Search-based Generation of Waypoints for Triggering Self-Adaptations in Maritime Autonomous Vessels", "authors": "Karoline Nylænder,Aitor Arrieta,Shaukat Ali,Paolo Arcaini", "background": "海上自主船舶（AVs）可以通过自我适应来应对意外情况，同时保持可靠性需求。在设计这类AVs时，理解并识别应触发适应的设置至关重要，以验证其实施的有效性。我们重点关注AVs的导航软件，这种软件需要在运行过程中通过适应来改变其行为。AVs通常依赖预定义的航点来沿指定路线引导船舶，以确保安全航行。本文提出了一个基于多目标搜索的生成航点（WPgen）方法，以生成关于预定义航点的小修改，这些修改会尽可能接近原始航点，但当使用生成的航点进行航行时，会导致航行不当。", "innovation": "提出了一个基于多目标搜索的生成航点（WPgen）方法，该方法使用NSGA-II作为多目标搜索算法，并采用了三种初始种群的播种策略，生成三种WPgen的变体。这种方法旨在生成关于预定义航点的小修改，保持航点尽可能接近原始航点，但当使用生成的航点航行时，会导致航海不当，从而触发自我适应。该方法的三种变体在三种ASV（一种水上油轮和两种水下ASV）上进行了评估。", "conclusion": "实验结果表明，这些变体的有效性取决于ASV。基于这些结果，我们讨论了WPgen的研究与实际应用意义。"}
{"llm_update_time": "20250723", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2507.16685", "html_url": "https://arxiv.org/abs/2507.16685", "title": "VulGuard: 统一的 JIT 漏洞预测模型评估工具", "title_en": "VulGuard: An Unified Tool for Evaluating Just-In-Time Vulnerability Prediction Models", "authors": "Duong Nguyen,Manh Tran-Duc,Thanh Le-Cong,Triet Huynh Minh Le,M. Ali Babar,Quyet-Thang Huynh", "background": "当前，针对 JIT 漏洞预测（JIT-VP）的研究面临着可重复性和可扩展性上的挑战。手动处理和分析 GitHub 仓库中的提交历史记录成本高且容易出错。因此，需要一个自动化的工具来简化这一过程，使其能够支持大规模仓库的挖掘和模型级别的实验。", "innovation": "VulGuard 是一个自动化的工具，能够自动挖掘提交历史，提取代码更改、提交信息和软件工程指标，并将其格式化以便于进一步的分析。它还集成了多款最先进的漏洞预测模型，使得研究人员可以轻松地训练、评估和比较模型。VulGuard 支持在统一框架中进行大规模仓库挖掘和模型级别实验，从而解决了软件安全研究中的可重复性和可扩展性难题。", "conclusion": "VulGuard 已在 FFmpeg 和 Linux 内核等两个重要开源项目中进行了演示，并证明了其加速实际应用中的 JIT-VP 研究以及推进标准化基准测试的潜力。VulGuard 也可以很容易地集成到 CI/CD 管道中。"}
{"llm_update_time": "20250723", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2507.16037", "html_url": "https://arxiv.org/abs/2507.16037", "title": "LLM-Based Agentic Translation from Android to iOS: A Pilot Study on Pitfalls and Insights", "title_en": "A Pilot Study on LLM-Based Agentic Translation from Android to iOS: Pitfalls and Insights", "authors": "Zhili Zeng,Kimya Khakzad Shahandashti,Alvine Boaye Belle,Song Wang,Zhen Ming(Jack)Jiang", "background": "移动应用的快速发展导致了跨平台兼容性的重要需求，特别是Android与iOS平台之间。传统的方法依赖于手动干预或基于规则的系统，这些方法耗费大量时间和劳动。虽然最近的人工智能技术引入了自动方法，但在上下文理解和适应性方面往往存在局限，导致翻译质量欠佳。为了改进代码翻译，研究人员广泛采用了大型语言模型（LLMs），并研究了这些模型在方法、类和代码库级别上的应用。尽管如此，现有的研究对于利用LLMs实现跨平台移动应用的翻译（如从Android到iOS的迁移或软件的跨框架适应）仍然未充分探索。", "innovation": "该研究首次提出了利用LLMs进行跨平台移动应用翻译的自主性方法链，涵盖了依赖性、规范、程序结构和程序控制流程等方面。这填补了现有研究中未充分探索的领域，并通过分析手动检查的翻译代码的语法正确性、语义准确性和功能完整性来评估方法的性能。此外，对翻译失败的原因进行了详细分析，揭示了自主性翻译过程中存在的局限性，并提出了改进建议。", "conclusion": "这项研究通过评估使用LLMs进行移动应用从Android到iOS的翻译的方法，发现了一些关键的失败点，并提出了提高翻译性能的指导方针。该研究对于推动软件工程自动化有着重要的意义，也为未来的研究提供了宝贵的启示。"}
{"llm_update_time": "20250723", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2507.16754", "html_url": "https://arxiv.org/abs/2507.16754", "title": "持续提供支持：自适应HyDE检索优化大语言模型开发人员支持", "title_en": "Never Come Up Empty: Adaptive HyDE Retrieval for Improving LLM Developer Support", "authors": "Fangjian Lei,Mariam El Mezouar,Shayan Noei,Ying Zou", "background": "大型语言模型（LLMs）在帮助开发者解决代码相关问题方面展现出潜力，但同时存在生成不可靠答案的风险。为降低这种风险，检索增强生成（RAG）技术被提出以减少LLMs的不可靠性（即幻觉），但设计有效的RAG管道仍然颇具挑战性，因为存在多种设计选择。", "innovation": "本文构建了一个包含超过300万条Java和Python相关的Stack Overflow带接受答案的文章检索库，并探索了多种RAG管道设计，以回答开发者的各种问题，评估了其生成准确、可靠回答的有效性。具体包括：设计并评估了7种不同RAG管道及其63种变体，用于回答具有历史对比匹配的问题；通过自动降低召回阶段的相似度阈值来解决没有近似此前匹配的新问题，增加找到部分相关上下文的概率，提高了未见过场景的覆盖率。通过结合假设文档嵌入（HyDE）和完整答案上下文的RAG管道表现出最佳的检索和回答Stack Overflow问题的性能。将最优RAG管道应用于4个开源大语言模型，结果显示RAG在多种模型中都优于零样本基准线，提高了LLM-as-a-judge在有用性、正确性和详细性方面的得分。这些发现表明，最优RAG管道能广泛增强不同LLMs对各种开发人员查询的回答质量，包括已见和新颖的问题。", "conclusion": "本文研究表明，最优RAG管道能显著提升LLMs对开发人员问题的高质量回答，涵盖首次遇到和新颖的查询，且该方法在多种模型中表现出色，证明了自适应HyDE检索的有效性。"}
{"llm_update_time": "20250723", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2507.16407", "html_url": "https://arxiv.org/abs/2507.16407", "title": "通过层感知模型编辑提高代码LLM在提示扰动下的鲁棒性", "title_en": "Improving Code LLM Robustness to Prompt Perturbations via Layer-Aware Model Editing", "authors": "Shuhan Liu,Xing Hu,Kerui Huang,Xiaohu Yang,David Lo,Xin Xia", "background": "大型语言模型（LLMs）在代码生成方面表现出令人印象深刻的能力，但研究表明，LLMs 对提示扰动非常敏感。即使是细微的词序、语法或格式化修改也会显著降低生成代码的功能正确性。在现实世界中，提示扰动频繁发生，因此提高LLMs对提示扰动的鲁棒性对于确保实际代码生成的可靠性能至关重要。", "innovation": "本文提出了一种名为CREME（Code Robustness Enhancement via Model Editing）的新颖方法，通过有针对性的参数更新来增强LLM的鲁棒性。CREME首先通过比较原始提示和其扰动变体之间的隐藏状态来识别鲁棒性敏感层，然后在这些层上进行轻量级参数编辑，以减少性能下降。实验结果显示，CREME在扰动提示上将Pass@1准确度提高了63%，同时在干净输入上保持了稳定的性能，准确度偏差在1%以内。进一步分析发现，鲁棒性敏感层主要集中在网络的中间和深层，其位置因不同的模型架构而异。", "conclusion": "鲁棒性敏感层主要集中在网络的中间和深层，并且它们的位置因不同的模型架构而异。这些见解为开发未来的面向鲁棒性的编辑策略奠定了有价值的基础。"}
{"llm_update_time": "20250723", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2507.16808", "html_url": "https://arxiv.org/abs/2507.16808", "title": "通过时序逻辑变形重新思考基于LLM的RTL代码优化", "title_en": "Rethinking LLM-Based RTL Code Optimization Via Timing Logic Metamorphosis", "authors": "Zhihao Xu,Bixin Li,Lulu Wang", "background": "RTL（寄存器传输级）代码优化对于实现数字电路设计中的高性能和低功耗至关重要。传统优化方法依赖于手动调优和启发式方法，这往往耗时且容易出错。最近的研究提出利用大型语言模型（LLMs）辅助RTL代码优化，LLMs可以根据自然语言描述生成优化代码片段，有望加快优化过程。然而，现有方法尚未充分评估LLM驱动的RTL代码优化方法在处理具有复杂时序逻辑的RTL代码时的有效性。", "innovation": "该研究提出了一种新的基准用于RTL优化评估，它包含四个子集，分别对应RTL代码优化的特定领域。通过引入基于“变形”的方法系统性评估LLM驱动的RTL代码优化方法的有效性，核心观点是优化效果在语义等同但更复杂的代码中应保持一致。通过密集的实验揭示了几个关键发现：（1）LLM驱动的RTL优化方法可以有效优化逻辑操作并超越现有的基于编译器的方法。（2）LLM驱动的RTL优化方法在具有复杂时序逻辑的RTL代码中，特别是在时间控制流优化和时钟域优化方面，不如现有的基于编译器的方法。", "conclusion": "基于这些发现，作者为利用LLM进行RTL代码优化提供了进一步研究的见解。"}
{"llm_update_time": "20250723", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.14111", "html_url": "https://arxiv.org/abs/2507.14111", "title": "CUDA-L1：通过对比强化学习改进CUDA优化", "title_en": "CUDA-L1: Improving CUDA Optimization via Contrastive Reinforcement Learning", "authors": "Xiaoya Li,Xiaofei Sun,Albert Wang,Jiwei Li,Chris Shum", "background": "由于大型语言模型的快速发展和技术进步，对GPU计算资源的需求呈指数级增长。现有的代码生成技术在提高CUDA加速方面表现不佳，尽管已经取得了一些进展，但当前的SOTA模型（如R1和o1）在提高CUDA速度方面的成功率仍然不高。因此，迫切需要自动CUDA优化策略。", "innovation": "本文提出了一种自动强化学习框架CUDA-L1，用于CUDA优化。本研究对来自NVIDIA A100的CUDA优化任务进行了训练，实现了对KernelBench中250个CUDA内核的整体平均加速17.7倍，峰值加速达到449倍。此外，模型还展示了优秀的跨GPU架构的可移植性，分别在H100、RTX 3090、L40、H800和H20中实现了平均加速17.8倍、19.0倍、16.5倍、14.7倍和13.9倍，尽管模型是为A100优化的。CUDA-L1展示了多个显著特性：1）发现并战略性地组合CUDA优化技术以实现最佳性能；2）揭示CUDA优化的基本原理；3）识别不明显的性能瓶颈并拒绝看似有益但实际上有害的优化。", "conclusion": "CUDA-L1通过仅基于加速的奖励信号将表现较差的大型语言模型转化为有效的CUDA优化器，而无需人类专业知识或特定领域知识。更重要的是，训练后的强化学习模型将其获得的推理能力扩展到新的内核，为自动优化CUDA操作提供了新的可能性，并有望显著提高GPU效率，缓解对GPU计算资源的需求压力。"}
{"llm_update_time": "20250723", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2507.16229", "html_url": "https://arxiv.org/abs/2507.16229", "title": "基于语音的AI代理：在数字健康交付中填补经济缺口", "title_en": "Voice-based AI Agents: Filling the Economic Gaps in Digital Health Delivery", "authors": "Bo Wen,Chen Wang,Qiwei Han,Raquel Norel,Julia Liu,Thaddeus Stappenbeck,Jeffrey L. Rogers", "background": "语音驱动的AI代理在医疗保健中的集成为弥合数字医疗服务中的经济和可访问性差距提供了变革性的机遇。本文探讨了大型语言模型（LLM）驱动的语音助手在增强预防护理和连续患者监测中的作用，特别是在未得到充分服务的人群中。", "innovation": "文章通过开发和试点研究了名为Agent PULSE（患者理解和联络支持引擎）的合作项目，展示了一种经济模型，证明了AI代理可以提供低成本的健康服务，特别是在经济上不可行的人群中。此外，研究还分析了实时对话AI处理、与医疗系统集成以及隐私合规性等技术挑战和政策考虑，如监管、偏见缓解和患者自主权。研究结果表明，AI驱动的语音代理不仅可以增强医疗服务的可扩展性和效率，还可以改善患者参与度和可及性。", "conclusion": "对于医疗服务管理者，我们的成本效益分析展示了任务常规监控方面的巨大潜在节省；对于技术开发者，我们的框架可以优先考虑产生最高患者影响的改进。通过解决当前局限性和将AI开发与伦理和监管框架相结合，基于语音的AI代理可以作为实现公平、可持续数字医疗服务的关键入口。"}
{"llm_update_time": "20250723", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2404.18558", "html_url": "https://arxiv.org/abs/2404.18558", "title": "LangBiTe：一个用于测试大型语言模型中偏见的平台", "title_en": "LangBiTe: A Platform for Testing Bias in Large Language Models", "authors": "Sergio Morales,Robert Clarisó,Jordi Cabot", "background": "大型语言模型（LLMs）在各种软件应用程序中的整合引起了对其潜在偏见的关注。这些模型通常是在来自论坛、网站、社交媒体和其他互联网来源的大数据集上进行训练，这可能会使模型中充满有害和歧视性行为。为了应对这一问题，我们提出了LangBiTe，这是一个测试平台，用于系统地评估LLM中的偏见。LangBiTe允许开发团队定制测试场景，并根据用户定义的伦理要求自动生成并执行测试案例。每个测试包括一个输入LLM的提示和对应的测试 oracle，后者审查LLM的响应以识别偏见。LangBite为用户提供LLM的偏见评估，并实现从最初的伦理要求到获得的见解的端到端可追溯性。", "innovation": "LangBiTe是一个创新的测试平台，能够系统地评估大型语言模型中的偏见。它允许开发团队设置和自动执行符合伦理要求的测试案例，通过用户定义的提示和测试 oracle来检测模型的偏见，从而提高了评估过程的效率和准确性。LangBiTe还提供从初始伦理要求到最终评估结果的端到端可追溯性，增强了测试过程的数据透明性和可解释性。", "conclusion": "LangBiTe平台为评估大型语言模型中的偏见提供了一种系统化的方法，能够帮助开发团队更好地理解和控制这些模型的伦理问题，从而提高其在实际应用中的安全性和公正性。"}
{"llm_update_time": "20250723", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2507.16586", "html_url": "https://arxiv.org/abs/2507.16586", "title": "人工智能在计算机辅助工程中的更好用户体验：学术界是否正在满足工业需求？一项多声腔文献综述", "title_en": "AI for Better UX in Computer-Aided Engineering: Is Academia Catching Up with Industry Demands? A Multivocal Literature Review", "authors": "Choro Ulan Uulu,Mikhail Kulyabin,Layan Etaiwi,Nuno Miguel Martins Pacheco,Jan Joosten,Kerstin Röse,Filippos Petridis,Jan Bosch,Helena Holmström Olsson", "background": "计算机辅助工程（CAE）能够帮助仿真专家优化复杂的模型，但用户体验（UX）方面的问题限制了其效率和可访问性。虽然人工智能（AI）展示了增强CAE过程的潜力，但在将这些领域结合起来并注重用户体验的研究方面仍然碎片化。现有研究集中在技术能力的探索上，缺乏对用户体验的有效验证。本文通过多声腔文献综述（MLR），研究了AI如何提升CAE软件的用户体验，涵盖了学术研究和工业应用。研究发现，学术界的研究主要关注技术能力而忽略了用户体验验证，而企业则积极应用大型语言模型、自适应用户界面和推荐系统。", "innovation": "本文提出了一个跨越学术研究和工业应用的人工智能在计算机辅助工程中提升用户体验的多声腔文献综述。通过披露学术界与工业界在利用AI提升用户体验方面存在的差异，研究引领了一条新的研究路径，以解决当前研究中的差距并推动AI与CAE的整合，以改善用户体验。", "conclusion": "研究揭示了AI在提供人工智能辅助指导、自适应界面和工作流程自动化方面的潜力，这些领域目前的研究相对不足。通过映射这些领域的交叉点，本研究为基础研究提供了一个框架，以克服现有挑战并促进AI与CAE的整合。"}
{"llm_update_time": "20250723", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2506.13821", "html_url": "https://arxiv.org/abs/2506.13821", "title": "软件是基础设施：故障、成功、成本及形式化验证的必要性", "title_en": "Software is infrastructure: failures, successes, costs, and the case for formal verification", "authors": "Giovanni Bernardi,Adrian Francalanza,Marco Peressotti,Mohammad Reza Mousavi", "background": "我们概述了软件在现代社会中的作用，以及低质量软件带来的巨额成本，并列举了过去40年中的一些重大软件失败案例来阐明这一点。这些案例突显了研究、学习和实施形式化软件验证特别是程序分析的必要性。工业中的成功经验支持这一观点。", "innovation": "提出并论证了软件是基础设施的观点，并强调了形式化验证在提高软件质量中的重要性。通过对大规模软件故障的成本分析，凸显了实施形式化验证的紧迫性和必要性。", "conclusion": "本文通过回顾软件故障的成本，提出了研究和应用形式化软件验证和程序分析的必要性，认为这将是提高软件质量的关键路径。"}
{"llm_update_time": "20250723", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2507.16478", "html_url": "https://arxiv.org/abs/2507.16478", "title": "ACT：通过合成数据生成与自适应训练跨越代码翻译差距", "title_en": "ACT: Bridging the Gap in Code Translation through Synthetic Data Generation & Adaptive Training", "authors": "Shreya Saxena,Siva Prasad,Zishan Ahmad,Vishal Vaddina", "background": "代码翻译在软件开发和迁移项目中是一项关键过程，能够实现不同编程语言之间的互操作性，增强软件的适应性和寿命。传统的自动化翻译方法依赖于手工编写的转换规则，这些规则往往缺乏灵活性和可扩展性。与此同时，先进的语言模型为代码翻译提供了有前景的替代方案，但它们通常受到封闭式API实现的限制，这对数据安全性和依赖性提出了担忧。", "innovation": "该论文提出了代码翻译的Auto-Train框架（ACT），通过内部微调开源大型语言模型来提升代码翻译能力。ACT的自动化流水线显著提升了这些模型的表现，缩小了开源可访问性和闭源解决方案高性能之间的差距。核心在于其合成数据生成模块，该模块从初始代码示例中构建了大量高质量数据集，并利用单元测试确保功能准确性和多样性。ACT评估框架还包括执行级别检查，为翻译质量提供全面评估。ACT的关键特性是管理整个流水线的控制模块，能够根据实时评估动态调整超参数、协调迭代数据生成和基于实时评估的微调，从而智能地优化继续训练、生成更多有针对性的训练数据或停止过程。", "conclusion": "结果表明，ACT一致地提升了开源模型的有效性，为企业和开发人员提供了安全可靠的替代方案。此外，将我们的数据生成流水线应用于工业规模的迁移项目导致了开发人员加速的显著增加。"}
{"llm_update_time": "20250723", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2507.15984", "html_url": "https://arxiv.org/abs/2507.15984", "title": "BACFuzz: 在Web应用程序中揭露Broken Access Control漏洞的沉默", "title_en": "BACFuzz: Exposing the Silence on Broken Access Control Vulnerabilities in Web Applications", "authors": "I Putu Arya Dharmaadi,Mohannad Alhanahnah,Van-Thuan Pham,Fadi Mohsen,Fatih Turkmen", "background": "Broken Access Control (BAC) 是网络应用程序中最关键和最普遍的安全漏洞之一，可以让攻击者访问未授权的资源或执行特权操作。尽管其严重性，BAC 在自动测试中的探索仍然不足，主要因为缺乏可靠的或者（评估）标准，以及生成语义有效攻击请求的难度。", "innovation": "BACFuzz 是首个专为 PHP 基础网络应用程序设计的灰色盒测试框架，用于揭示 BAC 漏洞。它结合了基于大语言模型 (LLM) 的参数选择、运行时反馈以及基于 SQL 的或acles 检查来检测隐性的授权缺陷。通过轻量级的指令化来捕获运行时信息，指导测试生成过程，并通过分析后端 SQL 查询来验证未经授权的输入是否流向了受保护的操作。", "conclusion": "BACFuzz 在 20 个真实世界的网络应用程序上进行了测试，包括 15 个 CVE 案例和 2 个已知基准，发现 17 个已知问题的 16 个，并且还发现了 26 个新的 BAC 漏洞，同时保持了较低的假阳性率。所有发现的问题都得到了负责任的披露，并且相关的工具包将会公开发布。"}
{"llm_update_time": "20250723", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2402.01021", "html_url": "https://arxiv.org/abs/2402.01021", "title": "深入了解深度学习系统中的漏洞定位挑战", "title_en": "Towards Understanding the Challenges of Bug Localization in Deep Learning Systems", "authors": "Sigma Jahan,Mehil B. Shah,Mohammad Masudur Rahman", "background": "每年全球因软件错误造成的经济损失高达数十亿美元，且占据约50%的编程时间。定位这些错误至关重要但极具挑战性，尤其是在拥有黑盒特性的深度学习系统中。传统的调试方法可能因深度学习系统的错误（不仅存在于代码中，还在模型和训练数据中）而效果不佳。本文通过大量实证研究来更深入地理解在深度学习系统中定位漏洞的挑战。研究使用来自深度学习和传统软件的2,365和2,913个错误来评估四项现有技术的性能；研究了不同类型的深度学习错误对定位的影响；并分析了外在因素对深度学习系统中错误定位的影响，发现深度学习错误往往与源代码以外的元素（例如GPU和训练数据）相关，导致现有定位方法效果不佳。", "innovation": "本文进行了一项大规模实证研究，研究对象包括2,365个深度学习系统错误和2,913个传统软件错误，评估了四种现有技术的漏洞定位性能；详细分析了不同类型的深度学习错误对漏洞定位技术的影响；同时考察了深度学习错误的外在特性对定位的影响，揭示了现有定位方法的不足。这项研究方法的创新在于从多个维度系统地评估和分析深度学习模型中的错误定位难题，提供了新的见解和研究角度。", "conclusion": "研究发现现有的定位技术在深度学习系统中的表现显著低于在传统软件中的表现。不同类型的错误影响定位技术的效率，结构化的张量错误更容易被发现，而与外部依赖密切关联的GPU错误则难以定位。深度学习错误通常具有外在特性，这意味着它们不仅仅存在于代码中，还与其他因素（如GPU和训练数据）纠缠在一起，导致现有定位方法的性能不佳。这些发现为改进现有深度学习系统中的漏洞定位技术提供了重要的指导。"}
{"llm_update_time": "20250723", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2507.16395", "html_url": "https://arxiv.org/abs/2507.16395", "title": "基于大型语言模型的通过显式和隐式依赖推理进行提交拆解的协作模型", "title_en": "LLM-Driven Collaborative Model for Untangling Commits via Explicit and Implicit Dependency Reasoning", "authors": "Bo Hou,Xin Tan,Kai Zheng,Fang Liu,Yinghao Zhu,Li Zhang", "background": "原子提交，处理单一开发关注点的每一个，是软件开发的最佳实践。然而，由于实际限制或边界不清晰，开发者经常生成混杂提交，将不相关更改混合在一起，这影响了代码审查和维护。尽管先前的提交拆解方法（基于规则、特征或图）取得了进展，但它们通常依赖于浅层信号，不能区分显式依赖（如控制/数据流）和隐式依赖（如语义或概念关系）。", "innovation": "我们提出了一种新的协作咨询框架ColaUntangle，用于提交拆解。ColaUntangle采用多代理架构，集成了通过大型语言模型（LLM）驱动的代理：一个专门处理显式依赖，另一个处理隐式依赖，第三个代理通过迭代咨询综合这些视角。为了捕捉显式和隐式语境信息，构建了版本Program Dependency Graphs（delta-PDG），使代理能够在符号和语义深度上推断代码关系。", "conclusion": "在两个广泛使用的数据集上评估了ColaUntangle（1,612个C#和14,000个Java混杂提交）。实验结果表明，ColaUntangle优于表现最佳的基线，C#数据集改进了44%，Java数据集改进了100%。这些发现突显了基于LLM的协作框架在推进自动化提交拆解任务方面的潜力。"}
{"llm_update_time": "20250723", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2408.08903", "html_url": "https://arxiv.org/abs/2408.08903", "title": "通过GraphCodeBERT和附加特征改善源代码相似性检测", "title_en": "Improving Source Code Similarity Detection Through GraphCodeBERT and Integration of Additional Features", "authors": "Jorge Martinez-Gil", "background": "本文提出了一种新颖的源代码相似性检测方法，该方法将额外的输出特征整合到分类过程中以提高模型性能。研究所基于GraphCodeBERT模型，并通过自定义输出特征层和连接机制增强了特征表示。", "innovation": "本文创新地将GraphCodeBERT模型扩展为包含自定义输出特征层，并利用连接机制提升特征表示。该方法通过集成额外的输出特征，提高了模型在精度、召回率和F值方面的表现。", "conclusion": "该研究通过训练和评估证明了该模型的有效性，实现了在精确度、召回率和F值方面的良好结果。关于模型架构和训练策略的实现细节也被进行了讨论，并提供了代码示例下载链接。"}
{"llm_update_time": "20250723", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2507.10729", "html_url": "https://arxiv.org/abs/2507.10729", "title": "关于即时漏洞预测的现实性评估", "title_en": "Toward Realistic Evaluations of Just-In-Time Vulnerability Prediction", "authors": "Duong Nguyen,Thanh Le-Cong,Triet Huynh Minh Le,M. Ali Babar,Quyet-Thang Huynh", "background": "现代软件系统越来越复杂，这对质量保证提出了重大挑战。即时漏洞预测（JIT-VP）是一种前瞻性方法，用于识别易受攻击的提交并提供潜在安全风险的早期预警。然而，当前的JIT-VP评估依赖于理想化的设置，即评估数据集是人为平衡的，仅由引入漏洞和修复漏洞的提交组成。因此，有必要在更贴近实际情况的环境中评估JIT-VP的有效性，即包含了漏洞相关的和非相关的提交的设置。", "innovation": "该研究引入了一个包含FFmpeg和Linux内核超过一百万提交的大规模公共数据集，用于实际的评估。研究发现多项最先进的JIT-VP技术在实际应用中表现显著下降。并且探索了处理数据不平衡的常见技术，如自定义损失函数、过采样和欠采样，但这些方法在JIT-VP中无效。这些发现强调了JIT-VP实际评估的重要性，并指出需要特定领域的方法来解决此类问题中的数据不平衡问题。", "conclusion": "研究结果表明，当前的JIT-VP技术在实际应用中的表现远不及理想状态，数据不平衡是主要原因。因此，需要开发针对JIT-VP领域的特定数据不平衡解决方法，以提高其真实评估的有效性。"}
{"llm_update_time": "20250723", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2506.06821", "html_url": "https://arxiv.org/abs/2506.06821", "title": "LLMs是否能够生成可靠的测试用例生成器？基于竞赛级编程问题的研究", "title_en": "Can LLMs Generate Reliable Test Case Generators? A Study on Competition-Level Programming Problems", "authors": "Yuhan Cao,Zian Chen,Kun Quan,Ziliang Zhang,Yu Wang,Xiaoning Dong,Yeqi Feng,Guanzhong He,Jingcheng Huang,Jianhao Li,Yixuan Tan,Jiafu Tang,Yilin Tang,Junlei Wu,Qianyu Xiao,Can Zheng,Shouchen Zhou,Yuxiang Zhu,Yiming Huang,Tian Xie,Tianxing He", "background": "大型语言模型（LLMs）在代码生成方面已经展示了显著的能力，尤其是在推理过程中能够处理复杂的任务。然而，LLMs在通过测试案例生成进行代码检查或调试方面的应用仍未得到彻底研究。本文基于竞赛级编程（CP）问题的研究视角，探讨了LLMs在生成测试用例生成器方面的能力。", "innovation": "作者提出了一种名为TCGBench的新基准，该基准包括两个任务，旨在研究LLMs在生成有效测试用例生成器以及生成揭示人类代码缺陷的测试用例生成器方面的表现。研究结果表明，尽管最先进的LLMs在大多数情况下可以生成有效的测试用例生成器，但它们在生成能揭示人类代码缺陷的测试用例生成器方面表现不佳，甚至先进的推理模型（如o3-mini）也无法达到人类的水平。", "conclusion": "虽然最先进的LLMs在生成有效测试用例生成器方面有一定的能力，但在生成揭示人类代码缺陷的测试用例生成器方面存在显著不足。人工构建的高质量指令数据集可以显著提升LLMs的性能，通过提示和微调策略。"}
{"llm_update_time": "20250723", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2507.16051", "html_url": "https://arxiv.org/abs/2507.16051", "title": "RightTyper: 有效的高效Python类型注解", "title_en": "RightTyper: Effective and Efficient Type Annotation for Python", "authors": "Juan Altmayer Pizzorno,Emery D. Berger", "background": "Python类型注解可以带来静态类型检查的好处，但手动编写注解耗时且繁琐，导致大部分实际的Python代码基本仍保持未注解状态。过去对Python代码进行类型注解的方法存在多种不足：静态方法难以处理动态特性且推断出的类型过于宽泛；基于AI的方法本质上不严谨且可能忽视罕见或用户自定义类型；动态方法则可能会产生巨大的运行时开销，甚至会导致执行中断，并推断出错误的类型从而引发运行时错误。这些方法普遍假设被标注的代码本身已经无误，但对于大型未注解的代码库而言，这一假设通常不可能被验证。", "innovation": "RightTyper是一个新颖的针对Python的类型注解方法，通过有原则且普遍地使用基于自我调试的抽样，结合统计过滤和细致的类型信息解析与综合，实现了精准的类型注解生成，相对于此前的方法提升了内存检查的召回率，并将类型检查转化为异常检测，让程序员能够审核极少数难以预料的行为。此外，RightTyper速度快且空间效率高，平均仅带来30%的性能开销。", "conclusion": "RightTyper通过有原则且普遍使用的抽样指导、统计过滤以及细致的类型信息解析和综合，解决了上述问题，能够在提高召回率的同时保持较高的性能，使得类型的注解更加精准高效。"}
{"llm_update_time": "20250723", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2507.10845", "html_url": "https://arxiv.org/abs/2507.10845", "title": "BandFuzz: 一种基于机器学习的协同模糊测试框架", "title_en": "BandFuzz: An ML-powered Collaborative Fuzzing Framework", "authors": "Wenxuan Shi,Hongwei Li,Jiahao Yu,Xinqian Sun,Wenbo Guo,Xinyu Xing", "background": "传统的单个模糊测试工具依赖于特定假设，对目标程序的假设较为严格，导致其性能在不同程序中的表现不够稳定。现有的协同模糊测试框架虽然能够结合多个模糊测试工具，但依然面临资源需求增加和资源分配效率低的问题。因此，需要一种无需额外计算资源且能够优化资源分配、提高性能的协同模糊测试框架。", "innovation": "BANDFUZZ 是一种采用机器学习（ML）驱动的协同模糊测试框架，通过我们提出的多臂赌博机模型驱动的创新资源分配算法，能够建模单个模糊测试工具的长期影响，从而发现全局最优的协同策略。BANDFUZZ 还提出了一种新的评估模糊测试器的方法，不仅评估代码覆盖率，还评估模糊测试器解决难以到达分支的能力。另外，BANDFUZZ 集成了实时种子同步机制和实施层面的优化，以提高模糊测试效率和稳定性。研究结果显示，BANDFUZZ 在Fuzzbench和FuzzerTestSuite上的表现优于现有的协同模糊测试框架autofz和广泛使用的单个模糊测试工具。", "conclusion": "通过广泛的实验证明，BANDFUZZ 在并发模糊测试和解决难到达分支方面的表现优于现有最先进的协同模糊测试框架和常用的单个模糊测试工具。进一步的消融研究还验证了BANDFUZZ的关键设计。实际上，BANDFUZZ 在一项全球模糊测试竞赛中赢得了第一名，证明了其在实际漏洞检测中的有效性。"}
{"llm_update_time": "20250723", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2507.12367", "html_url": "https://arxiv.org/abs/2507.12367", "title": "GitChameleon 2.0: 评估Python库版本不兼容下的AI代码生成", "title_en": "GitChameleon 2.0: Evaluating AI Code Generation Against Python Library Version Incompatibilities", "authors": "Diganta Misra,Nizar Islah,Victor May,Brice Rauby,Zihan Wang,Justine Gehring,Antonio Orvieto,Muawiz Chaudhary,Eilif B. Muller,Irina Rish,Samira Ebrahimi Kahou,Massimo Caccia", "background": "软件库的快速演变给代码生成带来了极大挑战，需要不断适应频繁的版本更新并保持向后兼容性。现有的代码演变基准提供了有价值的见解，但通常缺乏基于执行的评估，无法生成符合特定库版本的代码。为了解决这个问题，我们引入了GitChameleon 2.0，这是一个新颖且精心收集的数据集，包含328个Python代码完成问题，每个问题都针对特定的库版本并配以可执行的单元测试。", "innovation": "GitChameleon 2.0通过提供基于执行的基准测试，强调代码库的动态特性，严格评估当前大型语言模型（LLMs）、LLM驱动的代理、代码助手和检索-生成-检索（RAG）系统的版本条件代码生成能力。这一评估表明，最先进的系统在这个任务中遇到了重大挑战；企业级模型的基本成功率在48-51%之间，突显了问题的复杂性。", "conclusion": "通过提供基于执行的基准测试，GitChameleon 2.0帮助更清晰地理解这一挑战，并有助于引导开发更适应和可信赖的AI代码生成方法。我们已经公开发布了该数据集和评估代码。"}
