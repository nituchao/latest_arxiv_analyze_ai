{"llm_update_time": "20251023", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.19139", "html_url": "https://arxiv.org/abs/2510.19139", "title": "多方面认知能力分析：大型语言模型在 CONSORT checklist 上的提示方法评估", "title_en": "A Multi-faceted Analysis of Cognitive Abilities: Evaluating Prompt Methods with Large Language Models on the CONSORT Checklist", "authors": "Sohyeon Jeon,Hyung-Chul Lee", "background": "尽管大型语言模型（LLMs）在医疗领域的应用迅速扩大，但这些系统是否能够根据 CONSORT 标准评估临床试验报告仍然存在不确定性，特别是在认知和推理策略方面的表现。本文采用专家验证的数据和行为及元认知分析方法，系统地比较了两种代表性 LLM 的性能。", "innovation": "本文创新性地使用了行为和元认知分析方法，对比了两种 LLM 在不同提示条件下的表现，揭示了这些模型在处理 CONSORT 项目时的不同策略和思维方式的变化。", "conclusion": "研究结果表明，目前这些系统在临床合规自动化方面存在局限性，强调了深入理解其认知适应和策略行为的重要性，以开发更可解释和可靠的医疗人工智能。"}
{"llm_update_time": "20251023", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.19263", "html_url": "https://arxiv.org/abs/2510.19263", "title": "带有不一致先例的广义原因模型的论证解释框架", "title_en": "An Argumentative Explanation Framework for Generalized Reason Model with Inconsistent Precedents", "authors": "Wachara Fungwacharakorn,Gauvain Bourgne,Ken Satoh", "background": "先例约束是人工智能和法律中基于案例推理的基础之一。传统的推理方法常常假设底层的先例集必须是一致的。然而，在实际应用中，先例通常是不一致的，因此无法直接用传统的方法进行推理。为了解决这个问题，引入了一种广义的推理模型概念。尽管已经存在基于传统一致先例模型的论证解释方法，但对于包含不一致先例的广义推理框架，尚未发展出相应的论证解释方法。", "innovation": "本文提出了扩展的演绎状态论证框架（DSA框架），以解释基于不一致先例的广义推理模型。这一创新之处在于能够在考虑先例不一致问题的情况下，提供一种新的论证性解释方法。", "conclusion": "本文通过引入一种扩展后的DSA框架，为广义推理模型中的不一致先例提供了一种新的论证解释方法，从而填补了该领域的一个研究空白，对于实际的法律和人工智能应用具有重要意义。"}
{"llm_update_time": "20251023", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.19261", "html_url": "https://arxiv.org/abs/2510.19261", "title": "ChatGPT 显露其局限性：法律原则带来致命一击", "title_en": "ChatGPT Unveils Its Limits: Principles of Law Deliver Checkmate", "authors": "Marianna Molinari,Ilaria Angela Amantea,Marinella Quaranta,Guido Governatori", "background": "本研究探讨了ChatGPT在法律领域的表现，并通过实验将其结果与基于正则表达式（Regex）的基准进行比较。研究焦点在于ChatGPT即使具备必要的知识和技能也无法有效地应用，揭示了ChatGPT在解决复杂问题时的局限性。法律领域中最关键的任务之一是阅读法律判决并提取关键段落，这些内容是从法律原则中浓缩出来的，然后被法官或律师用于后续判决或辩护文件。人工智缺乏对这些内容的全面理解和推理能力，导致其在该领域具有局限性。", "innovation": "研究通过将ChatGPT的表现与正则表达式（Regex）基准进行比较，从而揭示ChatGPT在解决复杂问题方面的局限性，强调了在特定领域（如法律领域）人类智能的独特性。", "conclusion": "研究结果表明，尽管ChatGPT具备所需的知识和技能，但在合理使用、全面理解和推理方面存在明显缺陷，这些是真正智能在法律领域中不可替代的特性。"}
{"llm_update_time": "20251023", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.19205", "html_url": "https://arxiv.org/abs/2510.19205", "title": "WebGraphEval：使用图表示法评估网络代理的多轮轨迹", "title_en": "WebGraphEval: Multi-Turn Trajectory Evaluation for Web Agents using Graph Representation", "authors": "Yaoyao Qian,Yuanli Wang,Jinda Zhang,Yun Zong,Meixu Chen,Hanhan Zhou,Jindan Huang,Yifan Zeng,Xinyu Hu,Chan Hee Song,Danqing Zhang", "background": "目前网络代理的评估主要依赖于二元成功的度量标准或单个参考轨迹的符合性，并未考虑到基准数据集中存在的结构性多样性。这种评估方式忽视了网络代理行为之间的多样性和复杂性，限制了对代理性能的全面评估。", "innovation": "我们提出了WebGraphEval框架，该框架通过将来自多个代理的轨迹抽象成一个统一的加权行动图，实现了对网络代理性能的多路径、跨代理以及效率感知评估。该框架通过编码动作、合并重复行为并应用结构化分析，显现出跨模型的规律性，揭示冗余和低效行为，并识别基于结果度量忽视的重要决策点。该框架直接兼容WebArena等基准系统，利用排行榜运行和新收集的轨迹，无需修改环境配置。", "conclusion": "通过将网络交互表示为结构化数据，WebGraphEval确立了一种通用方法来评估网络代理的多路径、跨代理和效率感知评估。这种新的评估方法能够捕捉多代理的共同模式，识别冗余和低效行为，并确定基于结果度量忽略的关键决策点。"}
{"llm_update_time": "20251023", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.18982", "html_url": "https://arxiv.org/abs/2510.18982", "title": "通过最优运输进行测试时验证：覆盖范围、ROC与次优性", "title_en": "Test-time Verification via Optimal Transport: Coverage, ROC, & Sub-optimality", "authors": "Arpan Mukherjee,Marcello Bullo,Debabrota Basu,Deniz Gündüz", "background": "尽管在测试时使用验证来缩放大型语言模型（LLMs）显示出提升其性能的潜力，但验证器的角色及其缺点仍较少探讨。验证过程中，交互涉及三个量：（i）生成器的覆盖率，（ii）验证器的收敛区域（ROC），与（iii）采样算法的次优性。尽管最近的研究捕获了这些因素的一部分，但没有一个统一的框架来量化它们之间的几何关系。", "innovation": "将可验证的测试时缩放视为一个运输问题，以此刻画覆盖率、ROC和次优性的相互作用，发现次优性-覆盖率曲线有三种模式：运输模式、策略改进模式和饱和模式。此外，提出并分析两类采样算法——顺序算法和批处理算法，探讨它们的计算复杂性如何影响这些权衡。", "conclusion": "实验结果与Qwen、Llama和Gemma模型一致，证明了我们的理论发现，表明通过最优运输进行测试时验证能更深入理解模型性能优化的复杂性。"}
{"llm_update_time": "20251023", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.19055", "html_url": "https://arxiv.org/abs/2510.19055", "title": "MUSE基准测试：评估音频LLM的音乐感知和听觉关系推理", "title_en": "The MUSE Benchmark: Probing Music Perception and Auditory Relational Reasoning in Audio LLMS", "authors": "Brandon James Carone,Iran R. Roman,Pablo Ripollés", "background": "当前的多模态大型语言模型（MLLMs）在音频理解方面展示了能力，但现有的评估可能掩盖了其在关系推理中的根本弱点。研究人员引入了一个开放源代码资源——Music Understanding and Structural Evaluation（MUSE）基准测试，该基准测试涵盖10项任务，旨在探测基本的音乐感知技能。", "innovation": "研究团队开发了MUSE基准测试，这是一个包含10个任务的资源，旨在深入探究音频LLMs在音乐理解及关系推理方面的能力。他们评估了四种当前最先进的模型（Gemini Pro和Flash、Qwen2.5-Omni、Audio-Flamingo 3），并与大量人类基线（200人）进行对比。结果揭示了这些模型在能力上的广泛差异及其与人类专家之间的持续差距。", "conclusion": "实验结果显示，尽管Gemini Pro在基本感知上表现良好，Qwen和Audio Flamingo 3的表现接近随机，显示出严重的感知缺陷。同时，传递因果推理（CoT）提示语也提供了不一致且通常是有害的结果。本研究提供了评估不变音乐表示的重要工具，并推动了更稳健的人工智能系统的发展。"}
{"llm_update_time": "20251023", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.19050", "html_url": "https://arxiv.org/abs/2510.19050", "title": "修正偏好奖励学习中的捷径行为", "title_en": "Rectifying Shortcut Behaviors in Preference-based Reward Learning", "authors": "Wenqian Ye,Guangtao Zheng,Aidong Zhang", "background": "在来自人类反馈的强化学习中，基于偏好的奖励模型在使大型语言模型与人类对齐的行为中扮演了核心角色。然而，最近的研究表明，这些模型容易出现奖励作弊现象，并且由于过度优化往往不能很好地泛化。它们通过利用捷径，即利用与训练数据中的人类偏好标签相关的可疑特征（例如，响应量、和蔼的语气或奉承）获得高奖励分数，而不是真正反映预设的目标。", "innovation": "本文从一个更宽的角度审视了奖励作弊问题，将其视为捷径行为，并提出了一种原则性的灵活方法来缓解偏好奖励学习中的捷径行为。受核视角不变理论的启发，本文提出了偏好奖励不变性以缓解捷径行为（PRISM），该方法以闭式学习目标学习组不变核函数和特征映射。实验结果在多个基准测试中显示出，该方法在多样化的新的分布外任务中改进了奖励模型的准确性，并减少了下游策略模型对捷径行为的依赖性，从而建立了鲁棒的偏好对齐框架。", "conclusion": "本文提出了一种称为PRISM的方法，以缓解偏好奖励学习中的捷径行为。实验结果表明，PRISM方法不仅提高了奖励模型在分布外任务的准确性，还减少了策略模型对捷径行为的依赖，从而为偏好对齐提供了一个稳健的框架。"}
{"llm_update_time": "20251023", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.19299", "html_url": "https://arxiv.org/abs/2510.19299", "title": "学习结交朋友：引导LLM代理产生 emergent 社交纽带", "title_en": "Learning to Make Friends: Coaching LLM Agents toward Emergent Social Ties", "authors": "Philipp J. Schneider,Lin Tian,Marian-Andrei Rizoiu", "background": "研究探讨了大型语言模型（LLM）代理能否重现人类在线行为中的复杂社会动态，这些动态由同质性、互惠和社交验证塑造。讨论了记忆和学习机制在促进此类动态出现中的作用。通过设计能够捕捉在线参与核心驱动力的行为奖励函数，研究模拟了人类社会行为，并展示了在教练信号的帮助下，代理通过重复交互和评估彼此来调整其行为以形成稳定的互动模式和新兴的社会联系，从而构建与真实在线社区相似的网络结构。研究指出，这种结合行为奖励与上下文调整的框架为研究LLM群体中的集体动力学提供了一个理论基础，并揭示了人工代理如何模仿或偏离类似人类的社会行为。", "innovation": "开发了一种多代理LLM模拟框架，其中包含重复交互、自我评估和通过教练信号加速上下文学习来调整行为。通过设计能够与观察到的用户动机对齐的行为奖励函数，该框架能够研究个体决策如何导致网络结构和群体形成，并揭示人工代理如何模仿或偏离类似人类的行为。", "conclusion": "实验结果显示，引导的LLM代理形成了稳定的社会联系，并生成了映射真实在线社区属性的网络结构。这种框架为研究LLM群体中的集体动态提供了理论框架，并揭示了人工代理可能如何模仿类似人类的社会行为。"}
{"llm_update_time": "20251023", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.19176", "html_url": "https://arxiv.org/abs/2510.19176", "title": "零步思考：模式选择在推理模型中更难的早期退出的实证研究", "title_en": "The Zero-Step Thinking: An Empirical Study of Mode Selection as Harder Early Exit in Reasoning Models", "authors": "Yuqiao Tan,Shizhu He,Kang Liu,Jun Zhao", "background": "推理模型在数学和逻辑推理任务中表现出色，主要是因为它们能够在推理过程中进行逐步思考。但是，这种逐步思考也导致了过度思考，增加了不必要的计算开销。为解决这个问题，Mode Selection旨在通过在推理过程之初自动选择Long-CoT或Short-CoT模式来减少计算负担，并通过Early Exit确定推理过程中的最佳停止点。早期退出关注的是推理时最简洁的停止点，而模式选择则需要在推理过程初期做出决策，依赖预定义的虚假思考，称之为零步骤思考。", "innovation": "研究将模式选择视为早期退出问题的一个更具挑战性的变体，因为它在决策时间上与早期退出不同。模式选择需要在推理过程初期做出决策，依赖预定义的虚假思考而不经过明确的推理过程。研究通过对九种基线的实证研究发现，基于提示的方法通常会失败，因为它们在提供少量手工制作的信息时分类能力有限。相比之下，依赖内部信息的方法在许多情况下表现更好，但在稳定性方面仍存在问题。研究指出，现有的方法仅依赖模型提供的信息不足以有效解决模式选择问题，特别是当信息有限时，突显了这一任务中存在的持续挑战。", "conclusion": "研究发现现有的方法依赖模型提供的信息在信息有限的情况下不适合解决模式选择问题，指出了这一任务中的持续挑战。研究的代码可以在这个链接找到：this https URL."}
{"llm_update_time": "20251023", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.18988", "html_url": "https://arxiv.org/abs/2510.18988", "title": "实时临床诊断中的主动测试选择", "title_en": "Timely Clinical Diagnosis through Active Test Selection", "authors": "Silas Ruhrberg Estévez,Nicolás Astorga,Mihaela van der Schaar", "background": "越来越多的人对利用机器学习支持临床诊断表现出兴趣，但大多数方法依赖于静态、完全观察的数据集，未能反映临床医生在实践中所用的顺序、资源感知推理。诊断在高压力或资源受限的环境中尤为复杂且易出错，这就突显了需要有助于临床医生及时和成本效益决策的框架的必要性。因此，本研究探讨了一种新的诊断框架ACTMED（Adaptive Clinical Test selection via Model-based Experimental Design），该框架结合了贝叶斯实验设计（BED）与大型语言模型（LLMs），旨在更好地模拟现实世界的诊断推理。通过这种方法，每一步都选择对特定患者而言能减少诊断不确定性最大的测试。研究人员通过在真实世界数据集上评估ACTMED的方法，表明该方法能够优化测试选择，从而提高诊断精度、可解释性和资源使用效率。这一创新为开发透明、适应性及与临床专家对齐的诊断系统提供了可能，这些系统可以跨不同环境应用，且减少了对特定领域数据的依赖。", "innovation": "提出了ACTMED框架，该框架将贝叶斯实验设计（BED）与大型语言模型（LLMs）相结合，以更好地模拟现实世界的临床诊断推理过程。ACTMED每一步都会选择对减少特定患者诊断不确定性最有帮助的测试。通过这种主动测试选择的方法，该研究展示了ACTMED能够优化测试选择，提升诊断精度、可解释性和资源使用效果，实现了透明、适应性和与临床专家对齐的诊断系统的进步。", "conclusion": "评估结果表明，ACTMED框架能够在实际临床诊断中提高诊断准确性、可解释性及资源使用效率，并且能够在多种临床环境中应用。这种方法代表了向基于透明的、自适应且与临床专家对齐的诊断系统发展的重要一步，这些系统减少了对特定领域数据的依赖。"}
{"llm_update_time": "20251023", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.19314", "html_url": "https://arxiv.org/abs/2510.19314", "title": "连续知识适应于强化学习", "title_en": "Continual Knowledge Adaptation for Reinforcement Learning", "authors": "Jinwu Hu,Zihao Lian,Zhiquan Wen,Chenghao Li,Guohao Chen,Xutao Wen,Bin Xiao,Mingkui Tan", "background": "强化学习使智能体通过与环境的交互来学习最优行为。然而，现实世界中的环境往往是非平稳的，要求智能体不断适应新的任务和变化的条件。虽然连续强化学习有助于跨多个任务学习，但现有方法往往存在灾难性遗忘和知识利用效率低下的问题。", "innovation": "本文提出了一种连续知识适应的强化学习算法（CKA-RL），该算法通过任务特定的知识向量池并动态利用历史知识来使智能体适应新任务，从而减轻灾难性遗忘并有效转移知识。此外，还提出了自适应知识合并机制，以解决可扩展性问题，减少内存需求并保留关键知识。", "conclusion": "在三个基准上的实验表明，所提的CKA-RL方法优于最先进的方法，整体性能提高了4.20%，前向迁移性能提高了8.02%。源代码可通过此链接获取：this https URL."}
{"llm_update_time": "20251023", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.19423", "html_url": "https://arxiv.org/abs/2510.19423", "title": "MSC-Bench：多服务器工具编排的严格基准", "title_en": "MSC-Bench: A Rigorous Benchmark for Multi-Server Tool Orchestration", "authors": "Jia-Kai Dong,I-Wei Huang,Chun-Tin Wu,Yi-Tien Tsai", "background": "现有的基准通常单独评估工具，忽略了功能重叠和跨服务器编排等挑战，导致过于乐观的评估结果。MSC-Bench通过构建等效功能集的方式填补了这些空白，采用五级课程结构系统性地测试代理从单工具编排到复杂跨服务器规划的能力，以及对范围外请求的鲁棒性。", "innovation": "MSC-Bench通过'等效功能集'构建了基准的地面真实情况，使得可以使用客观指标如F1分数来评价代理性能，而不需要依赖于LLM作为评判者的评价方法。此外，MSC-Bench为代理设计提供了一个诊断框架，以揭示其局限性并指导开发更强大和高效的工具使用代理。", "conclusion": "MSC-Bench提供了一个公开可用的基准和技术资源，旨在揭示代理的局限性并指导代理开发。该基准揭示了固定层次结构可能阻碍性能的事实，即使最先进的代理在鲁棒性方面也存在系统的弱点。"}
{"llm_update_time": "20251023", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.19562", "html_url": "https://arxiv.org/abs/2510.19562", "title": "DAIL:超越任务歧义的语言条件强化学习", "title_en": "DAIL: Beyond Task Ambiguity for Language-Conditioned Reinforcement Learning", "authors": "Runpeng Xie,Quanwei Wang,Hao Hu,Zherui Zhou,Ni Mu,Xiyun Li,Yiqin Yang,Shuang Xu,Qianchuan Zhao,Bo XU", "background": "智能代理理解和遵循自然语言指令是至关重要的能力。然而，语言指令的灵活性会导致任务条件下的巨大歧义，严重影响算法性能。本文分析了解决此问题的背景，并指出了现有的局限性：算法在处理语言条件任务时由于歧义导致性能下降。", "innovation": "本文提出了一种新颖的方法DAIL（Distributional Aligned Learning），包含两个关键组件：分布性策略和语义对齐。理论结果表明，价值分布估计机制增强了任务的可区分性。同时，语义对齐模块捕捉了轨迹和语言指令之间的对应关系。本文提出的方法在结构化和视觉观察基准上的大量实验结果表明，DAIL能有效解决指令歧义问题，并取得了优于基线方法的性能。", "conclusion": "本文提出了DAIL方法，通过分布性策略和语义对齐有效解决了语言条件强化学习中的任务歧义问题，并通过实验验证了其优越性。"}
{"llm_update_time": "20251023", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.19666", "html_url": "https://arxiv.org/abs/2510.19666", "title": "为吉他和弦音独奏教育设计的图形引擎", "title_en": "A Graph Engine for Guitar Chord-Tone Soloing Education", "authors": "Matthew Keating,Michael Casey", "background": "和弦音独奏是即兴演奏的一个基本练习，演奏者只使用当前和弦中的音符。这是一切高级爵士吉他理论的基础，但很难学习和练习。现有的学习方法复杂且难以操作，因此需要一种简化学生练习该技能的方式。", "innovation": "本文介绍了一种基于图形的引擎，用于为吉他学生计算和弦音独奏建议。该引擎通过构建加权图来找出最短路径，从而生成最理想的转移音，帮助学生简化这一练习过程，简化了输入和输出系统，使其更易于学生使用。", "conclusion": "该研究提供了一种新颖的方法来帮助吉他学生练习和弦音独奏。通过图形引擎生成最短路径和转移音的建议，使学生能够更轻松地理解和掌握这一技能。"}
{"llm_update_time": "20251023", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.19429", "html_url": "https://arxiv.org/abs/2510.19429", "title": "NeSyPr: 神经符号程序化以实现高效具身推理", "title_en": "NeSyPr: Neurosymbolic Proceduralization For Efficient Embodied Reasoning", "authors": "Wonje Choi,Jooyoung Kim,Honguk Woo", "background": "本文探讨了在动态环境中采用语言模型（LMs）进行具身任务的挑战，尤其是在延迟、连接性和资源限制等限制下，难以进行实时访问大型推理引擎或符号规划。", "innovation": "本文提出了一种名为NeSyPr的新型具身推理框架，通过神经符号程序化来编译知识，赋予基于LM的代理结构化、适应性和及时的推理能力。该框架首先使用符号工具生成任务特定的计划，然后将这些计划转换为可组合的过程性表示，便于无缝集成到LM的推理过程中。这种神经符号程序化将多步骤的符号结构路径搜索和推理抽象和通用化为单步骤LM推理，类似于人类知识编译，无需依赖外部符号指导，适合部署在对延迟和资源敏感的物理系统中。", "conclusion": "我们评估了NeSyPr在具身基准PDDLGym、VirtualHome和ALFWorld上的性能，证明了它在大型推理模型和符号规划者中的高效推理能力，同时使用更紧凑的LMs。"}
{"llm_update_time": "20251023", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.19671", "html_url": "https://arxiv.org/abs/2510.19671", "title": "通过机器学习分类在流式环境下实现可解释的电子竞技比赛胜率预测", "title_en": "Explainable e-sports win prediction through Machine Learning classification in streaming", "authors": "Silvia García-Méndez,Francisco de Arriba-Pérez", "background": "随着电子竞技观众和参与者数量的增加，以及优化通信解决方案和云计算技术的发展，在线游戏行业呈现出持续增长的趋势。尽管基于人工智能的电子竞技分析传统上定义为从相关数据中提取有意义的模式并进行可视化以提高决策，但专业比赛结果预测的努力主要集中在批量分类方面，而忽略了可视化技术。", "innovation": "本文提出了一种流式环境下可解释的胜率预测分类解决方案，通过控制多滑动窗口的输入数据来反映相关游戏变化。实验结果显示，准确率超过90%，优于文献中 competing 模型的性能。最终，通过可解释模块，系统能够被排名和推荐系统利用，以助于做出更明智的决策。", "conclusion": "该系统通过可解释模块可以在流式环境中实现专业电子竞技比赛胜率的预测，这种可解释性模块也促成了对预测结果的信任。"}
{"llm_update_time": "20251023", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.19661", "html_url": "https://arxiv.org/abs/2510.19661", "title": "AgentSense: 大型语言模型赋能通用性和可解释性在线参与城市传感", "title_en": "AgentSense: LLMs Empower Generalizable and Explainable Web-Based Participatory Urban Sensing", "authors": "Xusen Guo,Mingxing Peng,Xixuan Hao,Xingchen Zou,Qiongyan Wang,Sijie Ruan,Yuxuan Liang", "background": "基于网络的参与式城市传感已成为现代城市管理的关键方法，通过利用移动个体作为分布式的传感器。然而，现有的城市传感系统在面对多样的城市场景时难以普遍适用，并且在决策制定中的可解释性较差。传统的城市传感系统在适应动态的城市条件和不同的工人偏好时存在局限性。", "innovation": "本文介绍了一种名为AgentSense的混合型、无需训练的框架，该框架通过多智能体演化系统将大型语言模型（LLMs）整合到参与城市传感中。AgentSense最初使用经典规划器生成基线解决方案，并通过迭代改进这些解决方案，使其能够适应动态的城市条件并且响应不同的工人偏好。同时，该系统生成自然语言解释以增强透明度和信任。", "conclusion": "经过在两个大规模移动数据集和七种动态干扰下的广泛实验，AgentSense在自适应性与可解释性方面优于传统方法。相比于单一智能体的LLM基线，我们的方法在性能和鲁棒性上表现出色，并提供了更合理和透明的解释。这些结果表明，AgentSense是朝着部署自适应和可解释的城市传感系统迈出的重要一步。"}
{"llm_update_time": "20251023", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.19698", "html_url": "https://arxiv.org/abs/2510.19698", "title": "RLIE: 基于逻辑回归、迭代改进和评估的大语言模型规则生成框架", "title_en": "RLIE: Rule Generation with Logistic Regression, Iterative Refinement, and Evaluation for Large Language Models", "authors": "Yang Yang,Hua XU,Zhangyi Hu,Yutao Yue", "background": "大语言模型（LLMs）能够以自然语言提出规则，无需像传统规则学习那样预先定义谓词空间。但是，许多基于LLM的方法忽略了规则之间的交互性，而且将LLM与概率规则学习结合以进行稳健推理的机会仍然未得到充分利用。", "innovation": "提出了一种统一框架RLIE，该框架将LLM与概率建模相结合，用于学习一组带权规则。该框架包括四个阶段：规则生成，逻辑回归，迭代改进以及评估。这一点支持了LLM在语义生成和解释方面表现优异，但在精确的概率集成方面可靠性较低的观点。", "conclusion": "RLIE清晰地界定了LLM在归纳推理方面的潜力和局限性，并将它们与经典的概率规则组合方法相结合，从而实现更可靠的神经符号推理。直接应用其学习权重的规则比用LLM生成规则、权重和逻辑模型输出支持的策略表现更好。"}
{"llm_update_time": "20251023", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.19631", "html_url": "https://arxiv.org/abs/2510.19631", "title": "HSCodeComp: 一个用于层次化规则应用的深度搜索代理现实且专家级基准", "title_en": "HSCodeComp: A Realistic and Expert-level Benchmark for Deep Search Agents in Hierarchical Rule Application", "authors": "Yiqian Yang,Tian Lan,Qianghuai Jia,Li Zhu,Hui Jiang,Hang Zhu,Longyue Wang,Weihua Luo,Kaifu Zhang", "background": "有效的深度搜索代理不仅需要访问开放域和特定领域的知识，还需要应用复杂的规则如法律法规、医疗手册和关税规则。这些规则往往边界模糊且逻辑关系隐含，使得精确应用具有挑战性。现有代理评估基准忽视了这一关键能力。为此，本文引入了HSCodeComp，这是一种用于评估深度搜索代理层次化规则应用的首个现实且专家级基准。", "innovation": "HSCodeComp是首个用于深度搜索代理在层次化规则应用评估的现实且专家级基准。它基于实际数据构建，包括632个不同类别的产品条目，并由多位专家标注了10位的协调制度分类代码（HSCode）。该基准填补了当前代理评估基准的空白，揭示了代理能力与人类专家之间巨大的性能差距。", "conclusion": "在多种最先进大模型、开源及闭源代理的广泛实验中，最好的代理仅达到46.8%的10位代码准确率，远低于人类专家的95.0%。此外，详细分析显示了层次化规则应用的挑战，测试时的规模扩展未能进一步提升性能。"}
{"llm_update_time": "20251023", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.19732", "html_url": "https://arxiv.org/abs/2510.19732", "title": "Memo: 使用强化学习训练高效存储体 agent", "title_en": "Memo: Training Memory-Efficient Embodied Agents with Reinforcement Learning", "authors": "Gunshi Gupta,Karmesh Yadav,Zsolt Kira,Yarin Gal,Rahaf Aljundi", "background": "为了使体态智能体能够在长时间内高效运作，开发能够形成并访问记忆的模型以保持环境中的上下文感知十分重要。当前基于变压器的策略训练范式在视觉输入的处理上往往超出了变压器的上下文限制，而人类则可以保留并使用压缩为记忆的一生经验。理论上，大量的输入数据可以被压缩，因为其中很多内容是无关的并可以被抽象化。但现有方法主要集中在具有固定容量记忆的循环模型，或依赖全面上下文的变压器上。", "innovation": "本文提出了一种基于变压器的Memo架构及其训练方法，用于在记忆密集型和长时间跨度的任务上进行强化学习。Memo通过在训练过程中交替插入周期性摘要标记与模型输入相结合，来处理记忆创建和检索问题。在网格世界的元强化学习基准测试和照片逼真室内环境中的多目标导航任务上展示了Memo的有效性和优于传统长上下文变压器基线的表现，且计算和存储效率更高，推理时能在更长的上下文上表现更好并保持在流式环境中鲁棒性。", "conclusion": "Memo在记忆密集型，长时间跨度任务上展示了优越性，特别是在推理时能处理更长的上下文以及在流式环境中保持鲁棒性，同时具有较高的计算和存储效率。"}
{"llm_update_time": "20251023", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.19771", "html_url": "https://arxiv.org/abs/2510.19771", "title": "超越反应性：评估LLM代理的主动问题解决能力", "title_en": "Beyond Reactivity: Measuring Proactive Problem Solving in LLM Agents", "authors": "Gil Pasternak,Dheeraj Rajagopal,Julia White,Dhruv Atreja,Matthew Thomas,George Hurn-Maloney,Ash Lewis", "background": "基于LLM的代理正在向更加主动的方向发展，能够预测用户需求并自主解决问题。然而，当前对主动性的评价方法受限于局部上下文，无法测试多源推理和长期的时间跨度。", "innovation": "本文提出了PROBE（瓶颈解决主动性评估）框架，将主动性分解为三个核心能力的流水线：寻找未指定的问题、识别具体的瓶颈和执行适当的解决方案。该方法应用于评估领先LLM模型和流行代理框架，展示了即使是最先进的模型也难以解决该基准。文章还比较了每个模型的能力和分析共同的失败模式。", "conclusion": "研究结果揭示了当前代理系统中自主行动的局限性，并指出了未来研究的前景。"}
{"llm_update_time": "20251023", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.19738", "html_url": "https://arxiv.org/abs/2510.19738", "title": "Misalignment Bounty: 开源众包人工智能代理的不当行为", "title_en": "Misalignment Bounty: Crowdsourcing AI Agent Misbehavior", "authors": "Rustem Turtayev,Natalia Fedorova,Oleg Serikov,Sergey Koldyba,Lev Avagyan,Dmitrii Volkov", "background": "高级人工智能系统有时会表现出与人类意图不符的行为。为了收集这些行为的清晰且可重复的例子，作者发起了一个名为Misalignment Bounty的众筹项目。该项目旨在收集智能体追求意外或不安全目标的案例。该项目收到了295份提交，其中有九份获得了奖励。这份报告阐述了该项目的动机、评估标准，并逐步介绍了这九个获奖的案例。", "innovation": "该项目通过众筹的方式，有效收集了人工智能代理追求意外或不安全目标的例子，为研究误对齐问题提供了真实世界的案例。这一方法提高了研究的透明度和参与度，并为社区提供了宝贵的见解和数据支持。", "conclusion": "本报告总结了Misalignment Bounty项目的运行情况，并详细分析了九个获奖的案例，强调了通过合作和多方参与来改善人工智能安全性的重要性。这些案例可以为今后的研究提供宝贵的经验和教训，有助于推动人工智能系统的开发更加安全可靠。"}
{"llm_update_time": "20251023", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.18888", "html_url": "https://arxiv.org/abs/2510.18888", "title": "使用大型语言模型进行实体链接的语境增强", "title_en": "Contextual Augmentation for Entity Linking using Large Language Models", "authors": "Daniel Vollmers,Hamada M. Zahera,Diego Moussallem,Axel-Cyrille Ngonga Ngomo", "background": "实体链接涉及在自然语言文本中检测并链接实体提提到知识图谱。传统方法使用两步过程，分别使用实体识别和消歧模型，这可能导致计算密集型且效果不佳。大规模语言模型可以通过丰富实体的上下文来改进消歧过程，从而提升实体链接的效果。", "innovation": "本文提出了一种微调模型，将实体识别和消歧整合到统一框架中。此外，该方法利用了大型语言模型来增强实体提及的上下文，从而在实体消歧中表现出更好的性能。", "conclusion": "在基准数据集上的评估结果表明，本文提出的方法在跨域数据集上达到了最先进的性能。"}
{"llm_update_time": "20251023", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.19788", "html_url": "https://arxiv.org/abs/2510.19788", "title": "Benchmarking World-Model Learning", "title_en": "Benchmarking World-Model Learning", "authors": "Archana Warrier,Dat Nyugen,Michelangelo Naim,Moksh Jain,Yichao Liang,Karen Schroeder,Cambridge Yang,Joshua B. Tenenbaum,Sebastian Vollmer,Kevin Ellis,Zenna Tavares", "background": "当前用于学习和评估世界模型的方法偏离了目标：训练和评估主要关注于下一帧的预测，成功与否则通过环境中的奖励最大化来衡量。这种做法不能有效地支持许多未观察到的状态预测、短期和长期行动后果估计、行动序列规划和动态变化检测等下游任务和推断。因此，需要一个能够全面评估模型学习代理性能的方法，能够让他们进行非奖励驱动的交互，并在不同但相关的环境中进行得分测试，以支持多种此类任务，这种方法还应该不依赖于特定的模型表示方式，便于不同方法之间的比较。", "innovation": "提出了WorldTest，这是一个用于评估模型学习代理的新协议，它将无奖励的交互阶段与独立的、得分的测试阶段分开进行。这种新方法强调了模型学习灵活性和多样性、未预知任务的适应性和不同模型表示方式的通用性。同时，评估还需要包括秋之平台（AutumnBench），一组43个互动格子世界环境和129个跨三个家族的任务，这些任务分别是掩码帧预测、计划和预测因果动力学的变化，以更全面地评估环境动力学。", "conclusion": "人类参与者在这个新方法下表现优于模型，但计算扩展只在某些环境下提高性能，而在其他环境下则不然。这一研究表明，WorldTest以其无奖励探索、衍生测试和基于行为的评分模板能够评测代理对环境动态的理解，并且AutumnBench展示了世界模型学习中重要的改进空间。"}
{"llm_update_time": "20251023", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.18877", "html_url": "https://arxiv.org/abs/2510.18877", "title": "LLM Bazaar：使用LLM赋能的多方协作基础设施支持协作学习的服务设计", "title_en": "LLM Bazaar: A Service Design for Supporting Collaborative Learning with an LLM-Powered Multi-Party Collaboration Infrastructure", "authors": "Zhen Wu,Jiaxin Shi,R. Charles Murray,Carolyn Rosé,Micah San Andres", "background": "近二十年来，对话代理在结构化协作学习中的互动、塑造团队动态以及支持学生参与方面发挥了关键作用。近期，将大型语言模型（LLMs）集成到这些代理中，为培养批判性思维和协作问题解决提供了新的可能性。", "innovation": "本文以开源协作支持架构Bazaar为基础，整合了一个LLM代理壳，引入了以LLM为动力的实时、上下文相关的小组学习协作支持。从而为探索定制化的LLM赋能环境如何重新塑造协作学习结果和互动模式开辟了新的途径。", "conclusion": "该设计和基础设施为探索如何通过定制化的LLM赋能环境重塑协作学习结果和互动模式奠定了基础。"}
{"llm_update_time": "20251023", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.20409", "html_url": "https://arxiv.org/abs/2509.20409", "title": "统一的形而上学理论关于符号定位的逻辑限制", "title_en": "A Unified Formal Theory on the Logical Limits of Symbol Grounding", "authors": "Zhangchi Liu", "background": "本文综合了一系列形式证明，构建了关于符号定位问题逻辑限制的统一理论。通过四个阶段的论证，作者证明了意义需要来源于外部、动态且非算法的过程。首先论证了没有外部联系的纯符号系统无法自洽地建立意义基础。其次，任何有限的静态预设意义系统也因内部不完整而受限。第三步证明了将内部符号与外部意义关联这一过程中，不能通过系统内的逻辑推理完成，而必须是一个先验的、元层面的更新。最后，任何试图使用固定外部“判断”算法自动化的更新过程会导致更大的系统，但同样不完整。这些结论一起正式确立了意义的定位是一个本质性的开放、非算法过程，并揭示了自包含智能系统的根本性、哥德尔式的限制。", "innovation": "本文通过一系列形式化证明，提出了关于符号定位问题逻辑限制的统一理论。证明了意义需要来源于外部、动态且非算法的过程，这是一系列新的理论贡献。特别是，通过四个阶段的论证，区分了系统内部的逻辑推理与外部的先验更新，揭示了符号定位过程中的本质性限制。", "conclusion": "本文正式确立了符号意义的定位是一个永恒开放、非算法过程，并揭示了自包含智能系统中的哥德尔式限制。这表明任何试图完全封闭自足的知识系统或智能系统都将面临无法克服的逻辑局限，必须保持一定开放性与灵活性。"}
{"llm_update_time": "20251023", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.13006", "html_url": "https://arxiv.org/abs/2510.13006", "title": "什么是实施科学；为什么它对弥合医学影像领域人工智能创新到应用的缺口至关重要", "title_en": "What is Implementation Science; and Why It Matters for Bridging the Artificial Intelligence Innovation-to-Application Gap in Medical Imaging", "authors": "Ahmad Fayaz-Bakhsh,Janice Tania,Syaheerah Lebai Lutfi,Abhinav K. Jha,Arman Rahmim", "background": "人工智能（AI）在医学成像（MI）中的潜力得到广泛认可。然而，尽管在研究环境中寄予了厚望，许多AI工具未能在临床实践中得到应用。更普遍的是，新技术从证据生成到实际应用平均延迟17年。实施科学（IS）可能提供了一个实用的框架，通过系统的方法、策略和混合研究设计帮助企业缩短这一延迟时间，促进AI从开发到临床应用的转化过程。文章分析了AI在医学成像工作流程中的具体挑战，包括基础设施、教育和文化障碍，并强调了效果研究与实施研究的互补作用，以及集成知识传播（iKT）、利益相关者参与和以公平为中心的设计在可持续通用解决方案设计中的重要性。讨论了如何结合人类-计算机交互（HCI）框架来促进医学成像中可使用的AI。", "innovation": "提出了利用实施科学（IS）缩短AI技术从开发到临床应用的时间，通过系统框架、策略和混合研究设计进行加速转化的观点。强调了效果研究与实施研究的互补作用，以及整合知识传播（iKT）、利益相关者参与和以公平为中心的设计在设计可持续和通用解决方案中的重要性，特别是在医学成像领域中结合人类-计算机交互（HCI）框架的重要性。", "conclusion": "采用实施科学不仅是方法学上的进步，也是促进创新向改善患者结果方面快速转化的战略需求。"}
{"llm_update_time": "20251023", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.18893", "html_url": "https://arxiv.org/abs/2510.18893", "title": "CodeCRDT：多智能体LLM代码生成的观察驱动协调", "title_en": "CodeCRDT: Observation-Driven Coordination for Multi-Agent LLM Code Generation", "authors": "Sergey Pugachev", "background": "多智能体大型语言模型（LLM）系统在实现并行加速时，由于协调开销大而无法达到预期的效果。之前的多智能体系统主要依赖于显式的消息传递来协调，这限制了系统的并行性能提升。", "innovation": "提出了CodeCRDT，一种通过观察驱动的协调模式，智能体通过监控共享状态并观察可观察的更新和确定性的收敛来协调，而不是通过显式的消息传递。使用冲突自由复制数据类型（CRDT）来实现无锁、冲突自由的同时代码生成，具有强终局一致性。该方法还通过实验证明了观察驱动协调可以在某些任务中获得21.1%的加速，但在其他任务中可能会遇到39.4%的减速，同时达到了100%的收敛性，无一失败。此外，还对多智能体LLM代理的随机性进行了形式化，揭示了语义冲突率在5-10%之间，并探讨了质量和性能之间的权衡，以及成功的并行协调和失败的情况基于任务结构进行了经验表征和解析。", "conclusion": "研究确立了观察驱动协调对于随机LLM代理的作用，并发现了语义冲突率和质量-性能的权衡，同时通过实验证明了观察驱动方式在并行协调下成功的条件和失败的条件。"}
{"llm_update_time": "20251023", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.18890", "html_url": "https://arxiv.org/abs/2510.18890", "title": "小型语言模型为科学社区带来巨大潜力", "title_en": "Small Language Models Offer Significant Potential for Science Community", "authors": "Jian Zhang", "background": "自然语言处理的最新进展，特别是大型语言模型（LLMs）的应用，正在改变科学家获取文献的方式。尽管LLM的采用率正在提高，但对其可能的信息偏见和计算成本的担忧仍然存在。本文探讨了利用小型语言模型（MiniLMs）作为替代方案，以实现快速、准确且成本效益高的地学文献信息检索的方法与潜力。作者构建了一个包含大约7700万条高质量句子的语料库，这些句子来自2000年至2024年间发表在《地球物理研究快报》等95个顶级地学同行评审期刊上。MiniLMs通过语义搜索技术与句子级索引策略，计算上更为高效，能够从这些大型语料库中提取相关特定领域的信息。", "innovation": "本文开发了一种框架，利用小型语言模型（MiniLMs）进行地学文献信息检索，而不依赖于大型语言模型（如ChatGPT-4）。MiniLMs通过语义搜索和句子级索引技术，能够在保持计算效率的同时提供领域内精确的信息提取，特别是针对具有定量结果的信息。此外，通过对情感色彩的情感分析和通过无监督聚类分析主题聚类，MiniLMs为跟踪地学社区结论、研究优先级、进步和新兴问题的演变提供了有力工具。", "conclusion": "小型语言模型（MiniLMs）在地学前具有巨大潜力，可应用于事实和图像检索、趋势分析、矛盾分析以及教育目的。它能够提供快速、准确且成本效益高的信息检索，为地学研究提供有力支持。"}
{"llm_update_time": "20251023", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.18895", "html_url": "https://arxiv.org/abs/2510.18895", "title": "CosmoCore 情感回放强化学习在代码生成中的应用", "title_en": "CosmoCore Affective Dream-Replay Reinforcement Learning for Code Generation", "authors": "Santhosh Kumar Ravindran", "background": "研究背景包括了对强化学习（RL）在大型语言模型（LLMs）代码生成中的应用，以及结合情感信号提升代码生成质量的需求。此外，还借鉴了人类和动物学习过程中情感反馈（如尴尬）对快速修正错误的影响。", "innovation": "创新点在于提出了CosmoCore架构，该架构结合神经科学启发的强化学习方法，将情感信号整合到代码生成过程中。使用轻量级多层感知器（MLP）标识代码生成轨迹的情感强度和惊讶度，并特别针对高负面情感的错误代码片段进行优先重播，以增强自动生成代码的准确性和纠正速度。", "conclusion": "研究表明，CosmoCore架构能够减少幻觉代码（如语法错误或逻辑错误）48%，加速自纠错45%。本地实验还验证了改进效果，并通过Ablations实验进一步确认了情感标记在探索中的作用，并证明了剪枝策略可以减轻不必要的效率损失。该框架将强化学习从人类反馈（RLHF）推进到具备情感意识的代码助手，适用于集成开发环境（IDE）和数据管道等领域。"}
{"llm_update_time": "20251023", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.18897", "html_url": "https://arxiv.org/abs/2510.18897", "title": "AI在分布式系统设计中的应用：通过重复采样大语言模型和模拟器实现可扩展的云优化", "title_en": "AI for Distributed Systems Design: Scalable Cloud Optimization Through Repeated LLMs Sampling And Simulators", "authors": "Jacopo Tagliabue", "background": "研究将大规模语言模型（LLMs）的随机代码生成与特定领域模拟器的确定性验证结合，以探索AI驱动的分布式系统策略设计。利用Function-as-a-Service运行时（Bauplan）及其开源模拟器（Eudoxia）作为案例研究，将调度器设计描述为迭代的生成和验证循环：大语言模型提出Python策略，模拟器在标准化追踪上评估它，结构化的反馈引导后续的生成过程。此配置保持可解释性的同时，允许在大型设计空间进行有针对性的搜索。详细讨论了系统架构，并报告了多个模型中的吞吐量改进的初步结果。", "innovation": "将大规模语言模型的随机代码生成技术与特定领域模拟器的确定性验证技术结合，提出了一种迭代生成和验证的框架方法。这种方法在保持可解释性的同时，允许在大型设计空间中进行有针对性的搜索。并通过实际案例研究证明了此方法的有效性，并探讨了进一步研究的方向和方法的扩展可能性。", "conclusion": "展示了利用大语言模型和模拟器进行分布式系统策略设计和优化的初步成果，但同时也指出了当前设置的局限性，并提出了进一步的研究方向和方法扩展的可能。特别是，作者推测AI对于扩大这种方法的应用范围至关重要，并能够通过帮助启动新的模拟器来加速过程。"}
{"llm_update_time": "20251023", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.18902", "html_url": "https://arxiv.org/abs/2510.18902", "title": "评估大语言模型在职业指导中的作用：基于十个非洲国家计算胜任力推荐的比较分析", "title_en": "Evaluating LLMs for Career Guidance: Comparative Analysis of Computing Competency Recommendations Across Ten African Countries", "authors": "Precious Eze,Stephanie Lunn,Bruk Berhane(College of Engineering and Computing, Florida International University, Miami, USA)", "background": "随着雇主越来越期望毕业生能够利用大型语言模型（LLMs）在工作中应用，但是在非洲，尤其是在不同国家背景下，计算角色所需的能力依然不明确。本文通过分析六种LLM（ChatGPT 4、DeepSeek、Gemini、Claude 3.5、Llama 3、Mistral AI）在十个非洲国家中对入门级计算职业期望的描述，来审视这一问题。研究采用了2020年计算机课程框架和数字殖民主义理论，以及Ubuntu哲学，对LLM的响应进行分析。研究表明，虽然技术技能如云计算和编程被一致提及，但在处理非技术技能，特别是伦理和负责任的人工智能使用方面，模型表现出显著差异。模型在识别国家特定因素，如当地技术生态系统、语言要求和国家政策方面存在很大差异。开源模型在理解上下文方面表现更好，更好地平衡了技术和职业能力，但在文化敏感性和基础设施考量方面表现欠佳。", "innovation": "研究创新点在于：首先对非洲计算学生提出了LLM职业指导进行全面的比较分析；发现结构调整和西方中心偏见在技术建议与当地需求之间的差距；强调了在资源有限的环境中，开源型AI工具的质量可以与商业化工具竞争，从而质疑了对于AI工具质量的传统认知。", "conclusion": "本文表明，非洲不同地区的计算机能力要求差异巨大，并强调了教育中去殖民化的AI方法的重要性，注重上下文的相关性。开源模式在某些方面表现优越，但仍有许多改进空间，特别是在文化敏感性和基础设施考量方面。"}
{"llm_update_time": "20251023", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.18904", "html_url": "https://arxiv.org/abs/2510.18904", "title": "DuoLens: 一种用于稳健检测机器生成多语言文本和代码的框架", "title_en": "DuoLens: A Framework for Robust Detection of Machine-Generated Multilingual Text and Code", "authors": "Shriyansh Agrawal,Aidan Lau,Sanyam Shah,Ahan M R,Kevin Zhu,Sunishchal Dev,Vasu Sharma", "background": "大语言模型（LLMs）用于生成多语言文本和源代码的流行度增加，对机器生成内容检测器的准确性和效率提出了更高的要求，尤其是在不同领域。当前的检测器大多依靠零样本方法（如Fast DetectGPT或GPTZero），但要么消耗高计算资源，要么准确率不足，往往两者难以兼得。因此，需要进一步改进以提高检测器的效能。", "innovation": "本文提出了一种通过微调仅编码器小型语言模型（SLMs），特别是预训练的RoBERTA和CodeBERTa模型，使用专门的数据集来检测机器生成的多语言文本和代码的全新框架。这些模型在二分类任务中表现出色，仅需少量计算资源即可实现高准确率和低延迟，同时图像区域和内存占用分别减少3-5倍。此外，该框架在对抗性转化和不同生成器切换时仍能保持高水平的表现。", "conclusion": "该研究所提出的DuoLens框架通过微调仅编码器的SLMs模型，实现了机器生成内容检测的高性能，相比LLMs在几乎所有关键评价指标上明显提升，并且在计算资源的使用上更为高效。同时，该研究提供了训练和评估的脚本以及可复现性列表，为实际应用提供了支持。"}
{"llm_update_time": "20251023", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.18905", "html_url": "https://arxiv.org/abs/2510.18905", "title": "3D优化AI推理缩放：权衡精度、成本和延迟", "title_en": "3D Optimization for AI Inference Scaling: Balancing Accuracy, Cost, and Latency", "authors": "Minseok Jung,Abhas Ricky,Muhammad Rameez Chatni", "background": "AI推理缩放通常通过1D启发式方法（固定推理轮次）或2D双变量权衡（如性能与计算之间的权衡）来调整，但这些方法未能考虑成本和延迟约束。这种传统方法难以实现综合考虑准确度、成本和延迟的最佳推理缩放。", "innovation": "提出了一个3D优化框架，可以联合校准准确度、成本和延迟，在统一的决策空间内提供基于约束的推理缩放。引入蒙特卡洛模拟跨三种代表性场景和九个模拟的大语言模型评估了四种优化方法，以解决3D多目标优化（MOO）问题，该方法为推理缩放提供了可行的空间，这是1D和2D优化所无法捕捉到的。研究表明，拐点优化实现了最佳平衡，在优先考虑精度时，最大化准确度仍然是首选。", "conclusion": "该框架为跨各种操作环境的部署感知推理缩放提供了理论基础。结果显示，拐点优化在平衡各方面时表现最佳，而最大化准确度在强调精度时仍然是最优选择。"}
{"llm_update_time": "20251023", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.18908", "html_url": "https://arxiv.org/abs/2510.18908", "title": "使用重述改善社交媒体短文本主题建模：COVID-19 相关推文案例研究", "title_en": "Improving Topic Modeling of Social Media Short Texts with Rephrasing: A Case Study of COVID-19 Related Tweets", "authors": "Wangjiaxuan Xin,Shuhua Yin,Shi Chen,Yaorong Ge", "background": "社交媒体平台如Twitter（现在被称为X）提供了丰富的数据用于分析公共话语，特别是在疫情如COVID-19大流行期间。但是，社交媒体短文本因简短、非正式和噪声干扰等问题，常常妨碍传统主题建模的有效性，使得生成的主题不一致或冗余，经常难以理解。", "innovation": "我们开发了TM-Rephrase模型无偏框架，利用大型语言模型（LLMs）在主题建模之前将原始推文重新表述为更标准化和正式的语言。通过使用包含25,027个COVID-19相关的Twitter帖子的数据集，我们研究了两种重述策略（通用重述和口语化至正式重述）对多种主题建模方法的影响，结果表明，TM-Rephrase能改进主题建模性能指标（例如主题一致性、主题独特性和主题多样性），降低了大多数主题建模算法的主题冗余性，尤其是对于Latent Dirichlet Allocation (LDA)算法，口语化至正式重述策略表现出最大的性能提升。", "conclusion": "本研究为公共卫生相关的社交媒体分析提供了一种无偏的主题建模增强方法，具有广泛的应用价值，能够提高对公共卫生危机及其他重要领域的公共话语理解。"}
{"llm_update_time": "20251023", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.18911", "html_url": "https://arxiv.org/abs/2510.18911", "title": "利用人工智能理解表 heterogene 催化重整反应内在动力学的前景", "title_en": "Prospects for Using Artificial Intelligence to Understand Intrinsic Kinetics of Heterogeneous Catalytic Reactions", "authors": "Andrew J. Medford,Todd N. Whittaker,Bjarne Kreitz,David W. Flaherty,John R. Kitchin", "background": "人工智能(AI)正在加速催化研究中的模拟和材料发现。关键的前沿领域是将AI与多层次模型和多模态实验集成起来，以解决将内在动力学与可观察结果关联的“一对多”挑战。机器学习力场、微观动力学和反应器建模的进步使得快速探索化学空间成为可能，而原位和瞬态数据提供了前所未有的洞察力。然而，数据质量不一致和模型复杂性限制了机理的发现。", "innovation": "生成性和自主性AI能够自动化模型生成、量化不确定性，并将理论与实验耦合，实现“自动驾驶模型”，从而产生可解释、可重复和可迁移的催化系统理解。", "conclusion": "通过AI进一步理解表 heterogene 催化重整反应内在动力学，可以提高模型生成和理论与实验耦合的效率，增强对催化系统的理解，尽管存在数据质量和模型复杂性的挑战，但生成性和自主性AI的使用可以部分解决这些问题。"}
{"llm_update_time": "20251023", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.18909", "html_url": "https://arxiv.org/abs/2510.18909", "title": "从优秀中学习，与众不同的多样性驱动数据选择", "title_en": "Learning from the Best, Differently: A Diversity-Driven Rethinking on Data Selection", "authors": "Hongyi He,Xiao Liu,Zhenghao Lin,Mingni Tang,Yi Cheng,Jintao Wang,Wenjie Li,Peng Cheng,Yeyun Gong", "background": "高质量的预训练数据对于大型语言模型至关重要，质量捕获了事实可靠性和语义价值，多样性确保了广泛覆盖和分布异质性。现有方法通常依赖于单维度或多个维度基于评分的选择。然而，直接选择顶级评分的数据往往会降低性能，需要从更广泛的数据范围中进行采样以恢复结果。这表明基于数据集评分和下游基准结果之间的非单调关系揭示了一种基础偏差：基于评分的方法会压缩相关维度，导致顶级评分的数据看似高质量但系统地忽视了多样性。", "innovation": "提出了一种名为Orthogonal Diversity-Aware Selection (ODiS)的算法，该算法在数据选择中同时保留质量和多样性。ODiS从多个维度评估数据，包括语言质量、知识质量和理解难度。然后通过主成分分析（PCA）对多维度评分进行去相关，生成正交评估维度。对于每个维度，使用基于Roberta的评分器训练回归数据到PCA投影得分，从而实现大规模语料库的可扩展推理。最后，通过在每个正交维度中选择顶级评分的数据构建训练数据集，确保质量和多样性。", "conclusion": "ODiS选择的数据在不同维度上的重叠小于2%，证实了维度之间的正交性。更重要的是，用ODiS选择的数据训练的模型在下游基准测试中显著优于其他基线，突显了大型语言模型中正交和多样性的数据选择的必要性。"}
{"llm_update_time": "20251023", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.18910", "html_url": "https://arxiv.org/abs/2510.18910", "title": "大型连接模型：多任务学习景观中受脑环境交互启发的fMRI脑连接体基础模型", "title_en": "Large Connectome Model: An fMRI Foundation Model of Brain Connectomes Empowered by Brain-Environment Interaction in Multitask Learning Landscape", "authors": "Ziquan Wei,Tingting Dan,Guorong Wu", "background": "目前临床应用中，功能性神经影像的表现受到有限样本大小的影响。为了解决这个问题，研究人员在大规模未标记的fMRI数据上使用可扩展的自监督学习预先训练了大型模型。然而，由于自监督不一定与大脑与结果的关系对齐，大部分基础模型在下游任务中表现不佳，如疾病结果预测。因此，需要一个结合丰富环境变量、人口统计数据以及大量功能性神经影像的多任务模型，以改进这些限制，并可能促进当前神经影像技术在临床中的应用.", "innovation": "本文提出了一个大型连接模型，通过自环境中和人口统计数据中的多任务预训练以及半监督微调，实现了在各种下游任务上的性能改进，包括性别预测、人类行为识别和神经精神疾病的早期诊断（如自闭症、帕金森病、阿尔茨海默病和精神分裂症），显示出巨大潜力，特别是在临床神经影像应用中.", "conclusion": "所提出的模型在不同应用上的评估结果表明，通过多任务学习框架和大脑环境交互，可开发出具有强大潜力的神经影像基础模型，有助于改善临床神经影像的应用，尤其在疾病早期诊断方面。"}
{"llm_update_time": "20251023", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.18914", "html_url": "https://arxiv.org/abs/2510.18914", "title": "LLMs中上下文感知的公平性评估与缓解", "title_en": "Context-aware Fairness Evaluation and Mitigation in LLMs", "authors": "Afrozah Nadeem,Mark Dras,Usman Naseem", "background": "大型语言模型常常在其内部表示中嵌入了不良行为，这些行为会损害公平性、造成一致性漂移、放大有害内容以及在长时间对话和交谈中传播不良模式。虽然训练时或数据为中心的方法尝试减少这些影响，但它们通常计算成本高昂，部署后不可逆，并且难以适应新的对话背景。基于消融的方法提供了一种灵活且透明的方式来减少偏差，通过调整负责某些行为的神经元。然而，大多数现有方法都是静态的，一旦神经元被移除，模型在对话或情境变化时将无法适应。因此，本文讨论了大型语言模型在长时间对话中如何评估和缓解公平性问题的背景和挑战。", "innovation": "本文提出了一种动态、可逆的基于消融的框架，能够在生成过程中检测上下文感知的神经元激活，并应用适应性掩码来调节其影响。这种解耦解决方案在推理时提供粒度细、内存感知的缓解，保留了知识，并在多语言单次和多次对话中维持更一致的行为，这使实时聊天AI中的动态公平控制成为可能。", "conclusion": "通过动态调整受影响的神经元，提出的方法能够实现在对话或情境变化时的动态公平性控制，并能够在多语言对话环境中保持更一致的行为表现，从而解决了现有方法在适应新的对话背景时的局限性。"}
{"llm_update_time": "20251023", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.18915", "html_url": "https://arxiv.org/abs/2510.18915", "title": "MMAO-Bench: 多模态全集成基准揭示统一模态和多模态之间的组合规律", "title_en": "MMAO-Bench: MultiModal All in One Benchmark Reveals Compositional Law between Uni-modal and Omni-modal in OmniModels", "authors": "Chen Chen,ZeYang Hu,Fengjiao Chen,Liya Ma,Jiaxing Liu,Xiaoyu Li,Xuezhi Cao", "background": "多模态大型语言模型从单一模态理解逐步向统一视、听、语言模态转变，称为 Omni 模型。然而，单一模态与多模态之间的相关性仍不明确，需要全面评估来促进 Omni 模型智能的进化。", "innovation": "提出了一个新的、高质量且多样性的 Omni 模型基准 MMAO-Bench，有效评估单一模态和多模态理解能力。基准包括 1880 个手工精选样本，涵盖 44 种任务类型，并引入了一种创新的多步骤开放性问题类型，更好地评估复杂的推理任务。", "conclusion": "实验结果显示跨模态和单一模态性能之间的组合规律，多模态能力在弱模型上表现为瓶颈效应，而在强模型上则表现出协同提升效果。"}
{"llm_update_time": "20251023", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.18913", "html_url": "https://arxiv.org/abs/2510.18913", "title": "ADPO: 基于锚点的直接偏好优化", "title_en": "ADPO: Anchored Direct Preference Optimization", "authors": "Wang Zixian", "background": "Direct Preference Optimization (DPO) 是一种针对强化学习中直接优化用户偏好的方法，但其假设的硬二元标签和成对比较限制了其适应性和鲁棒性。ADPO 框架通过引入软偏好概率、任意参考策略锚点和列表偏好建模，扩展了 DPO，以提高其适应多种偏好表达和训练环境的能力。ADPO 的这些改进旨在解决偏好数据中的不确定性、增强训练的稳定性，并能更好地应对噪声偏好信息。", "innovation": "ADPO 引入了三方面的创新：(i) 软偏好概率，用于编码不确定性和减少梯度漂移；(ii) 任意参考策略锚点，通过组内平移不变性和隐式 KL 正则化稳定训练；(iii) 列表偏好建模，利用 Plackett-Luce 分布进行建模。文章证明了 DPO、Bradley-Terry 目标和 Top-1-vs-Rest 形式是 ADPO 的特殊情形，并提出了软 DPO、列表软 DPO 和基于 KDE 的列表平滑等三种实用变体。实验证明这些新方法在增强学习任务中优于标准方法，尤其是在处理噪声偏好信息时有显著提升。", "conclusion": "ADPO 提供了现实世界应用所需的灵活性和鲁棒性，特别是在处理来自嘈杂偏好数据时表现更好。对于清洁或中度噪声的情况，建议使用对称锚定软 DPO；而对于极端噪声情况，则推荐使用基于 KDE 的列表 ADPO。ADPO 为直接偏好优化问题提供了一条清晰的改进路径，极大地推动了该领域的发展。"}
{"llm_update_time": "20251023", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.18925", "html_url": "https://arxiv.org/abs/2510.18925", "title": "应用降阶模型为动力系统的时间多尺度表示的预测", "title_en": "Application of Reduced-Order Models for Temporal Multiscale Representations in the Prediction of Dynamical Systems", "authors": "Elias Al Ghazal,Jad Mounayer,Beatriz Moya,Sebastian Rodriguez,Chady Ghnatios,Francisco Chinesta", "background": "建模和预测复杂多尺度系统的动态仍然是一个重大挑战，这些系统固有的非线性和对初始条件的敏感性导致了问题。此外，传统机器学习方法因其无法捕捉高频行为而受限。", "innovation": "本文提出三种多尺度学习方法来克服这些困难。首种方法结合了余度函数（PU）方法和神经网络，将动态分解为局部成分，并直接预测宏观和微观行为。第二种方法使用奇异值分解（SVD）提取主导模式，明确将宏观和微观行为分离。第三种方法在数据矩阵不完全可获得的情况下，使用稀疏高阶SVD从有限测量重构多尺度动态。", "conclusion": "这些方法确保宏观和微观动态均被准确捕捉，使框架适用于现实中的复杂多尺度现象，对于高维系统和不完全观测的情况，提供了一种时间和尺度上的近似和解释。"}
{"llm_update_time": "20251023", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.18924", "html_url": "https://arxiv.org/abs/2510.18924", "title": "Noise-corrected GRPO: 从嘈杂的奖励到无偏的梯度", "title_en": "Noise-corrected GRPO: From Noisy Rewards to Unbiased Gradients", "authors": "Omar El mansouri,Mohamed El Amine Seddik,Salem Lahlou", "background": "强化学习从人类反馈（RLHF）或可验证奖励（RLVR）是目前用于使大规模语言模型（LLMs）对齐或构建最新技术水平推理模型的标准方法。但这种方法对异常或不一致奖励带来的噪声非常敏感，且噪声与广泛使用的基于群体的策略优化方法之间的互动尚不充分探索。", "innovation": "该研究引入了噪声稳健的组相对策略优化（GRPO）和正确版本GRPO（https://example.org）框架，明确将奖励篡改视为伯努利噪声。该方法在估计奖励翻转概率后应用噪声修正，以纠偏学习信号，从而得出证明无偏的梯度估计。理论分析表明，基于群体的方法本身可以部分抵消个体水平的噪声，而我们的修正策略则进一步增强了这种稳健性。", "conclusion": "实验结果显示，在标准奖励模型使用中应用我们的噪声修正，可以实现数学和编码任务中的一致性能提升，特别是在具有真实环境奖励模型条件下的数学任务上获得了最高6.7个百分点的精度提高和代码任务上的1.5个百分点的提高。这项工作将监督学习中的标签噪声修正方法与现代RLHF相结合，提供了理论见解和适用于现实环境部署的实用算法。"}
{"llm_update_time": "20251023", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.18918", "html_url": "https://arxiv.org/abs/2510.18918", "title": "使用具有解释性的大规模语言模型检测虚假信息", "title_en": "Misinformation Detection using Large Language Models with Explainability", "authors": "Jainee Patel,Chintan Bhatt,Himani Trivedi,Thanh Thi Nguyen", "background": "在线平台上虚假信息的快速传播削弱了个体之间的信任，阻碍了基于信息的决策制定。这项研究展示了一个使用Transformer预训练语言模型（PLMs）进行可解释且计算高效的虚假信息检测管道。", "innovation": "研究提出了一种两步策略优化RoBERTa和DistilBERT：首先冻结骨干网络，仅训练分类头；然后逐步解冻骨干网络层并应用逐层学习率衰减。通过使用统一的预处理和分层划分协议，在Covid Fake News和FakeNewsNet GossipCop两个真实基准数据集上测试了该方法。为了确保透明性，使用Local Interpretable Model-Agnostic Explanations (LIME)在 token 级别进行集成，以呈现 token 级别的理由，并使用 SHapley Additive exPlanations (SHAP)在全球特征归因级别呈现解释。研究发现，DistilBERT在计算资源上减少了大量需求，同时能够和RoBERTa保持相当的准确性，这展示了轻量级PLM可以大幅降低计算成本并保持任务性能。该工作对如何利用预训练语言模型、精准微调及保持解释性的管道给出了新颖的贡献。", "conclusion": "结果显示，结合精细微调和可解释性的预训练语言模型可以成为大规模、可信的虚假信息检测的有效框架。"}
{"llm_update_time": "20251023", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.18921", "html_url": "https://arxiv.org/abs/2510.18921", "title": "在Apple硅芯片上通过MLX进行设备端机器学习基准测试", "title_en": "Benchmarking On-Device Machine Learning on Apple Silicon with MLX", "authors": "Oluwaseun A. Ajayi,Ogundepo Odunayo", "background": "随着大型语言模型（LLMs）和机器学习技术的广泛应用，研究兴趣转向探讨将这些模型部署到如笔记本电脑和手机等较小设备上的可能性。这引发了对于能够充分利用设备硬件的框架和方法的需求。为此，开发了MLX框架，该框架针对Apple硅设备优化了机器学习计算，简化了研究、实验和原型设计过程。本文对MLX进行了性能评估，重点在于变压器模型的推理延迟。研究通过MLX和Pytorch的对照实验，评估了不同变压器架构的实现，并利用Apple硅的先进架构和功能无缝执行来自Hugging Face的变压器模型，无需转换检查点。研究在两个Apple硅Macbook设备上与NVIDIA CUDA GPU进行了基准测试，评估了BERT、RoBERTa和XLM-RoBERTa模型的推理延迟性能，并计划将此扩展到不同模态的模型，以全面评估MLX的能力.", "innovation": "MLX框架针对Apple硅设备优化了机器学习计算，使得能够无缝执行来自Hugging Face的变压器模型。此外，研究通过创建MLX-transformers框架，包含了MLX和Pytorch中不同变压器实现，并通过比较相同参数大小和检查点的不同模型，展示了MLX的潜在优势，即能够在Apple生态系统中实现高效且更易于访问的设备端机器学习应用。", "conclusion": "研究基准测试了不同变压器模型在MLX和NVIDIA CUDA GPU上的推理延迟性能，结果显示MLX在Apple硅设备上具有显著的优势。未来的研究将扩展到不同模态的模型，进一步评估MLX的全面能力。"}
{"llm_update_time": "20251023", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.18931", "html_url": "https://arxiv.org/abs/2510.18931", "title": "计算教育中公平与伦理课程的正义视角：LLM辅助多视角和主题评价", "title_en": "A Justice Lens on Fairness and Ethics Courses in Computing Education: LLM-Assisted Multi-Perspective and Thematic Evaluation", "authors": "Kenya S. Andrews,Deborah Dormah Kanubala,Kehinde Aruleba,Francisco Enrique Vicente Castro,Renata A Revelo", "background": "课程大纲为课程设定基调和期望，影响学生和教师的学习体验。在处理人工智能（AI）、机器学习（ML）和算法设计中的公平性和伦理问题的计算课程中，理解如何导航实现公平结果的障碍至关重要。大纲分析可以评估课程中的覆盖范围、深度、实践和期望。然而，手动的大纲评估耗时且容易产生不一致。", "innovation": "本研究开发了一个正义导向的评分标准，并借助大型语言模型（LLM）进行多视角角色模拟来审核大纲。研究者使用此标准从四位角色的角度（教师、系主任、机构审查员和外部评估者）评估了24份AI/ML和相关计算课程的大纲，并鼓励LLM识别课程的主题趋势。研究发现，多视角评估有助于识别特定角色的细微优先事项，这些优先事项有助于填补课程设计中的隐性空白。", "conclusion": "多视角评估和LLM辅助的主题趋势识别为我们提供了改进这些课程中公平、伦理和正义内容设计和交付的具体方向。这些见解有助于更好地确保这些课程能够培养学生的批判性思维，更好地应对公平性和伦理性挑战。"}
{"llm_update_time": "20251023", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.18927", "html_url": "https://arxiv.org/abs/2510.18927", "title": "BAPO：通过自适应裁剪的平衡策略优化稳定离策 reinforcement学习", "title_en": "BAPO: Stabilizing Off-Policy Reinforcement Learning for LLMs via Balanced Policy Optimization with Adaptive Clipping", "authors": "Zhiheng Xi,Xin Guo,Yang Nan,Enyu Zhou,Junrui Shen,Wenxiang Chen,Jiaqi Liu,Jixuan Huang,Zhihao Zhang,Honglin Guo,Xun Deng,Zhikai Lei,Miao Zheng,Guoteng Wang,Shuo Zhang,Peng Sun,Rui Zheng,Hang Yan,Tao Gui,Qi Zhang,Xuanjing Huang", "background": "强化学习（RL）已成为大规模语言模型（LLMs）对齐和增强的核心范式。然而，在离策设置中使用过去策略的数据进行训练虽然可以提高样本效率，但也会导致一些挑战，如策略熵急剧下降，优化不稳定甚至失败。", "innovation": "本文通过理论和实证分析，发现了两个关键见解：(i) 优化不平衡，负面优势样本主导策略梯度，抑制有用行为并可能导致梯度爆炸；(ii) 导出了Entropy-Clip规则，揭示了类似PPO的目标中固定裁剪机制系统地阻止增加熵的更新，导致策略过度利用而牺牲探索。基于这些见解，提出了BAPO（Balanced Policy Optimization with Adaptive Clipping），一种动态调整裁剪边界以自适应地重新平衡正负贡献、保持熵和稳定RL优化的简单而有效的方法。BAPO在多样化的离策场景中实现了快速、稳定和数据高效的训练。并且，BAPO的7B模型和32B模型分别在AIME 2024和AIME 2025基准测试中超越了开源的SkyWork-OR1-7B，并且在同类规模模型中达到了最先进的结果，同时优于领先的专有系统如o3-mini和Gemini-2.5-Flash-Thinking。", "conclusion": "BAPO通过自适应裁剪的平衡策略优化，稳定了大规模语言模型的离策RL训练，提高了解决方案的稳定性和效率。"}
{"llm_update_time": "20251023", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.18940", "html_url": "https://arxiv.org/abs/2510.18940", "title": "NeuroAda: 挖掘每个神经元的潜力以实现参数高效微调", "title_en": "NeuroAda: Activating Each Neuron's Potential for Parameter-Efficient Fine-Tuning", "authors": "Zhi Zhang,Yixian Shen,Congfeng Cao,Ekaterina Shutova", "background": "现有的参数高效微调（PEFT）方法主要分为两类：添加基底和选择性原位适应。添加基底方法，如LoRA，通过引入额外模块以增强模型对下游任务的适应性，具有较强的内存效率，但其表示容量往往有限，不适合进行精细调整。相比之下，选择性原位适应方法直接微调原始模型的一部分参数，能够实现更精确和有效的适应，但会带来显著的内存消耗增加。为了平衡这种权衡，本文提出了一种新型的PEFT方法——NeuroAda，旨在实现精细的模型微调同时保持高度的内存效率。", "innovation": "NeuroAda通过首先识别重要参数（即网络内的连接）并引入这些选定参数的绕路连接，仅在微调过程中更新绕路连接，而原始模型参数保持不变，从而实现精细的模型微调同时保持高内存效率。", "conclusion": "实验结果表明，NeuroAda在超过23种任务上（涵盖自然语言生成和理解）达到了最先进的性能，且仅需至多0.02%的可训练参数，同时减少了CUDA内存使用高达60%。"}
{"llm_update_time": "20251023", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.18941", "html_url": "https://arxiv.org/abs/2510.18941", "title": "ProfBench: 多领域需要专业知识来回答和评判的标准", "title_en": "ProfBench: Multi-Domain Rubrics requiring Professional Knowledge to Answer and Judge", "authors": "Zhilin Wang,Jaehun Jung,Ximing Lu,Shizhe Diao,Ellie Evans,Jiaqi Zeng,Pavlo Molchanov,Yejin Choi,Jan Kautz,Yi Dong", "background": "当前评价大规模语言模型（LLMs）的进展往往受到验证响应的挑战限制，使得评估主要集中在数学、编程和简短的问题回答任务上。然而，许多实际应用要求对LLMs进行评估，使其能够处理专业文档、综合信息并生成全面的报告以答复用户查询。现有的评估方法未能涵盖这些专业领域的复杂需求。", "innovation": "本文介绍了一种名为ProfBench的评估标准集，包含超过7000个响应-标准对，这些标准由拥有物理学博士、化学博士、金融工商管理硕士和咨询工商管理硕士的专业人士评估。此外，该研究引入了强大的且具有成本效益的LLM-裁判，通过减轻自我增强偏见并降低评估成本两个到三个数量级，使其对更广泛的社区更加公平和可访问。该研究揭示了一些先进的LLMs在ProfBench上遇到的巨大挑战，即使最顶尖的模型如GPT-5-high的整体性能也只有65.9%。此外，研究还发现，定制和开源模型之间的显著性能差异，并提供了扩展思维如何在解决复杂的专业领域任务中发挥作用的见解。", "conclusion": "ProfBench为评估LLMs的专业能力提供了新的基准，揭示了先进的LLMs在处理复杂、专业的信息合成和报告生成任务中的局限性，以及扩展思考在应对这些任务中的作用。该研究通过减轻成本和偏见，使更广泛的社区能够参与评估，并提供了进一步研究的潜在方向。"}
{"llm_update_time": "20251023", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.18938", "html_url": "https://arxiv.org/abs/2510.18938", "title": "StutterZero 和 StutterFormer：用于口吃转录和纠正的端到端语音转换", "title_en": "StutterZero and StutterFormer: End-to-End Speech Conversion for Stuttering Transcription and Correction", "authors": "Qianheng Xu", "background": "全球有超过7000万人经历口吃，现有的自动语音系统通常会错误地解释不流畅的表达或无法准确转录。现有的口吃修正方法依赖于手工特征提取或多阶段的自动语音识别（ASR）和文本到语音（TTS）管道，这些方法将转录与音频重建分离开来，往往会放大失真。", "innovation": "本文引入了StutterZero和StutterFormer，这是首个端到端的波形到波形模型，可以直接将口吃言语转换为流畅言语，并联合预测其转录。StutterZero使用卷积-双向LSTM编码器-解码器带有注意机制，而StutterFormer则整合了具有共享声学-语言表示的双流Transformer。两种架构都在来自SEP-28K和LibriStutter语料库合成的口吃-流畅配对数据上进行了训练，并在FluencyBank数据集的未见过的说话者上进行了评估。与领先的声音转录模型Whisper-Medium相比，StutterZero在词错误率（WER）上降低了24%，在语义相似性（BERTScore）上提高了31%；StutterFormer在WER上降低了28%，在BERTScore上提高了34%。这些结果验证了直接端到端转化口吃至流畅语音的可行性，为包容性的人机交互、言语治疗和无障碍人工智能系统提供了新的机会。", "conclusion": "这些结果证明了直接端到端转化口吃至流畅语音的可行性和有效性，为相关领域提供了新的思路和技术支持，尤其为无障碍应用、言语治疗和多人机交互系统的发展提供了新的机遇。"}
{"llm_update_time": "20251023", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.19008", "html_url": "https://arxiv.org/abs/2510.19008", "title": "多元之声，单一代理：迈向多用户家庭空间的包容性AI", "title_en": "Plural Voices, Single Agent: Towards Inclusive AI in Multi-User Domestic Spaces", "authors": "Joydeep Chandra,Satyam Kumar Navneet", "background": "国内的家庭AI代理面临着伦理、自主性和包容性等诸多挑战，尤其是对于被忽视的群体，如儿童、老年人和神经多样性用户。因此，研究人员需要一个能够动态平衡多用户需求并解决实时价值对齐问题的框架。", "innovation": "提出了一种名为Plural Voices Model (PVM)的创新单一代理框架，该框架通过实时价值对齐动态协商多用户需求，同时利用涉及心理健康、老年护理、教育和道德推理的多样化公共数据集。PVM还通过公平意识的情境设计和道德增强，针对神经多样性用户提供了逐步指导，针对儿童使用简单语言，从而保证了包容性原则，并且其“适应性安全支架”和定制化的互动模式进一步增强了隐私保护。", "conclusion": "PVM在合规性、公平性和迟滞方面均优于多种代理基线。其设计创新包括视频指导、自主性滑块、家庭枢纽以及适应性安全仪表板，突出了在伦理和包容性家庭AI领域的新方向。此外，研究结果已经进行了初步评估，并且该研究的代码和模型已经开源，可供重复使用：this https URL"}
{"llm_update_time": "20251023", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.19001", "html_url": "https://arxiv.org/abs/2510.19001", "title": "通过元数据指导的上下文和任务特定提示实现稳健的驾驶问答", "title_en": "Robust Driving QA through Metadata-Grounded Context and Task-Specific Prompts", "authors": "Seungjun Yu,Junsung Park,Youngsun Lim,Hyunjung Shim", "background": "本文提出了一种用于自动驾驶的两阶段视觉-语言问答系统，该系统能够回答高层次的感知、预测和规划问题。背景信息表明，现有的视觉-语言模型在自动驾驶相关的多层次问答任务上存在性能不足的问题，尤其是在复杂的驾驶场景中，缺乏足够的上下文信息和特定任务的指导会导致模型的准确性和可靠性降低。", "innovation": "本文的创新之处在于开发了一种两阶段的视觉-语言问答系统，并通过多模态预训练语言模型和特定任务的提示来增强回答的准确性和可靠性。第一阶段使用大尺寸的多模态预训练语言模型（Qwen2.5-VL-32B），结合相机输入、历史帧和逻辑推理模型，并通过自一致性集成进一步提高答案的可靠性。第二阶段则将场景元数据和特定任务的指示加入提示中，使得模型能够更准确地进行感知、预测和规划任务的问答。", "conclusion": "实验结果表明，作者的方法在驾驶问答基准测试中显著优于基线模型。在第一阶段使用5帧历史和10轮提示时，系统整体准确率达到65.1%（零-shot时为62.61%），通过自一致性提高到66.85%；第二阶段的整体准确率为67.37%，即使在严重的视觉干扰下系统的准确率也保持在96%以上。这些结果证明了通过精心设计的提示和上下文联系可以极大地增强预训练视觉-语言模型在高层次驾驶问答任务中的表现。"}
{"llm_update_time": "20251023", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.19003", "html_url": "https://arxiv.org/abs/2510.19003", "title": "Δt-Mamba3D: 一种用于乳腺癌风险预测的时间感知空间-时间状态空间模型", "title_en": "$Δ$t-Mamba3D: A Time-Aware Spatio-Temporal State-Space Model for Breast Cancer Risk Prediction", "authors": "Zhengbo Zhou,Dooman Arefan,Margarita Zuley,Shandong Wu", "background": "长期分析序列放射图像受到了一个根本性数据挑战的困扰：如何有效建模在不规则时间间隔内捕获的高分辨率图像序列。当前方法未能充分利用这些数据结构中的空间和时间线索。现有模型常常简化处理，要么压平空间信息，要么使用计算效率低下且不兼容非均匀时间步长的时空模型。", "innovation": "本文提出了一种名为Time-Aware Δt-Mamba3D的创新状态空间架构，专门适用于长期医学成像。该模型同时编码了不规则的访间间隔及丰富的时空上下文。其核心创新在于一个连续时间的选取扫描机制，明确地将检查之间的实际时间差整合到状态转换中。此外，该模型还配备了多尺度3D邻域融合模块，以稳健地捕捉时空关系。", "conclusion": "在使用序列筛查X线胸片考试进行乳腺癌风险预测的全面基准测试中，该模型表现出卓越的效果，相较于现有的递归、变压器和状态空间模型，验证c-指数提高了2-5个百分点，并且在1-5年的AUC评分上表现出更高的得分。由于其线性复杂度，该模型可以高效地处理长期和复杂的患者筛查历史，为长程图像分析形成了一种新的框架。"}
{"llm_update_time": "20251023", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.18999", "html_url": "https://arxiv.org/abs/2510.18999", "title": "$\nabla$-SDF: 使用梯度增强八叉树插值和神经残差进行在线学习欧几里得符号距离函数", "title_en": "$\\nabla$-SDF: Learning Euclidean Signed Distance Functions Online with Gradient-Augmented Octree Interpolation and Neural Residual", "authors": "Zhirui Dai,Qihao Qian,Tianxing Fan,Nikolay Atanasov", "background": "从点云数据估计带符号的距离函数(SDFs)对于机器人的自主能力，如定位、建图、路径规划和控制，具有显著的优势。现有的支持在线和大规模SDF重建的方法通常依赖离散体素数据结构，这会影响SDF估计的连续性和可微性。最近，使用隐式特征的神经网络方法能够实现高保真和可微SDF重建，但效率较低，大型环境中可能出现灾难性遗忘和内存限制，且通常限于截断的SDF。", "innovation": "提出了一种混合方法$\nabla$-SDF，结合了基于梯度增强八叉树插值的显式先验与基于神经网络的隐式残差。该方法实现了不截断的欧几里得SDF重建，具有与体素方法相当的计算和内存效率，同时具备与神经网络方法相当的可微性和准确性。广泛实验表明，$\nabla$-SDF在准确性和效率上优于现有技术，为机器人和计算机视觉下游任务提供了一种可扩展的解决方案。", "conclusion": "$\nabla$-SDF方法在准确性和效率上优于现有技术，提供了一种可扩展的解决方案，适用于机器人和计算机视觉中的下游任务。"}
{"llm_update_time": "20251023", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.19025", "html_url": "https://arxiv.org/abs/2510.19025", "title": "FlexiDataGen：在敏感领域中进行动态语义数据集生成的适应性大语言模型框架", "title_en": "FlexiDataGen: An Adaptive LLM Framework for Dynamic Semantic Dataset Generation in Sensitive Domains", "authors": "Hamed Jelodar,Samita Bai,Roozbeh Razavi-Far,Ali A. Ghorbani", "background": "在数据可用性和质量仍然是机器学习的关键挑战的背景下，特别是在数据稀缺、昂贵或受限于隐私法规的领域。医疗保健、生物医学研究和网络安全等领域的数据获取成本高，标注数据访问受限，并且关键事件的稀有性或敏感性导致了高数据获取成本和数据稀缺的问题。这些问题妨碍了在高度敏感领域开发准确和泛化的机器学习模型。", "innovation": "我们提出了FlexiDataGen，这是一个适应性的大语言模型（LLM）框架，用于在敏感领域中动态生成语义数据集。该框架通过四个核心组件实现：(1) 语法-语义分析，(2) 检索增强生成，(3) 动态元素注入，(4) 语义验证下的迭代改写。这些组件共同确保生成高质量、符合特定领域需求的数据。", "conclusion": "实验结果表明，FlexiDataGen有效缓解了数据短缺和注释瓶颈，使得在敏感领域能够实现大规模和准确的机器学习模型开发。"}
{"llm_update_time": "20251023", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.19014", "html_url": "https://arxiv.org/abs/2510.19014", "title": "通过大型语言模型处理历史记录训练的带宽算法实现有先验信息的治疗推荐优化", "title_en": "Prior-informed optimization of treatment recommendation via bandit algorithms trained on large language model-processed historical records", "authors": "Saman Nessari,Ali Bozorgi-Amiri", "background": "目前的医疗实践依赖于标准化的治疗框架和经验性的方法，忽视了患者个体差异，导致了次优的健康结果。本文探讨了如何利用大型语言模型（LLMs）、条件生成对抗网络（CTGAN）、T-learner反事实模型以及上下文臂技术，为患者提供个性化的数据驱动临床建议，以解决这一问题。", "innovation": "本文提出了一个全面的系统，该系统结合了大型语言模型、生成对抗网络、T-learner反事实模型和上下文臂方法，以提供个性化的临床建议。该系统能够将非结构化的医疗叙事转换为结构化的数据集（准确率为93.2%），生成现实的合成患者数据（通过双样本检验准确率为55%），预测患者特定的治疗反应（准确率为84.3%），并通过集成先验信息上下文臂方法，有效平衡新可能性探索和现有知识利用，以增强在线治疗选择。实验结果表明，该系统在治疗推荐上取得了显著的进步，特别是在处理无寒启动问题方面，提升了计算效率，适应了特定患者特征的个性化医疗。", "conclusion": "本文系统克服了在线学习环境中的寒启动限制，提高了计算效率，并在个体化医疗领域取得了显著进展。通过该系统，医疗实践能够更加有效地处理患者个体差异，从而提高治疗效果。"}
{"llm_update_time": "20251023", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.19031", "html_url": "https://arxiv.org/abs/2510.19031", "title": "CLiVR：具有AI驱动患者的虚拟现实对话学习系统", "title_en": "CLiVR: Conversational Learning System in Virtual Reality with AI-Powered Patients", "authors": "Akilan Amithasagaran,Sagnik Dakshit,Bhavani Suryadevara,Lindsey Stockton", "background": "模拟在医学和护理教育中是基本组成部分，传统的模拟方法主要使用标准化患者（SP）和高保真模拟人像来开发临床推理和沟通技能。然而，这些方法需要大量的资源，限制了它们的可获得性和可扩展性。", "innovation": "CLiVR，一种基于虚拟现实的对话学习系统，结合了大型语言模型（LLMs）、语音处理和3D化身来模拟真实的医患互动。该系统在Unity中开发并在Meta Quest 3平台上部署。CLiVR允许学员与虚拟患者进行自然对话，根据症候群症状数据库动态生成每个模拟，并结合情感分析提供对话语气反馈。", "conclusion": "在包含医学学院教师（n=13）的专家用户研究中，CLiVR的易用性、逼真度和教育影响得到了评估，结果表明用户对其接受度高，对教育潜力有信心，并提供了改进的宝贵反馈。CLiVR为基于标准化患者的培训提供了可扩展、沉浸式的补充。"}
{"llm_update_time": "20251023", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.19048", "html_url": "https://arxiv.org/abs/2510.19048", "title": "REPAIR方法在自然灾害情况下基于社会的城市重建规划", "title_en": "REPAIR Approach for Social-based City Reconstruction Planning in case of natural disasters", "authors": "Ghulam Mudassir,Antinisca Di Marco,Giordano d'Aloisio", "background": "自然灾害对人类生活有多种影响，政府在处理这些事件和利用有限的资源（主要为预算和时间）重建经济、社会和物理基础设施方面面临挑战。决策支持系统需要考虑法律和政治策略以最大化社会效益，同时处理严重破坏和大量资源的需求。先前的研究提出了一种使用深度强化学习技术的决策支持系统，用于灾后的城市重建规划，考虑到可用资源、社区各利益相关者的需要（如市民的社会效益和政治家的优先级）以及城市结构约束（如道路和建筑之间的相互依赖性）。\n", "innovation": "本文扩展了先前的研究，通过引入额外的深度学习模型和随机代理作为基线，进行了全面的对比分析。提出的解决方案REPAIR是一种通用方法，能够为地方管理者提供一系列替代计划供选择实施，并适用于任何规模的区域重建。REPAIR方法探讨了在实际案例（意大利拉奎拉2009年地震后的重建）中的应用。\n", "conclusion": "此研究展示了一种基于社交的灾后城市重建规划方法，并通过实证案例验证了其在应对自然灾害后城市重建规划中的有效性。\n"}
{"llm_update_time": "20251023", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.19033", "html_url": "https://arxiv.org/abs/2510.19033", "title": "\"Over-the-Hood\" AI Inclusivity Bugs and How 3 AI Product Teams Found and Fixed Them", "title_en": "\"Over-the-Hood\" AI Inclusivity Bugs and How 3 AI Product Teams Found and Fixed Them", "authors": "Andrew Anderson,Fatima A. Moussaoui,Jimena Noa Guevara,Md Montaser Hamid,Margaret Burnett", "background": "已有大量研究表明AI系统中潜藏的偏见（如算法偏见、训练数据偏见等），而关于面向用户的AI产品中存在的‘帽顶上’的包容性偏见（即障碍在用户直接面对的AI产品中导致某些解决问题方法被不公平地排除在外的情况）的研究相对较少。这些问题的存在、分布及其对用户的影响成了研究的重点。为了深入了解这些问题，研究者进行了一项实地研究，探索用户面向的AI产品中存在的特定类型的AI包容性漏洞以及如何利用现有的非AI导向的包容性设计方法来发现和解决问题，并改进了原有的GenderMag包容性设计方法为专门针对AI的GenderMag-for-AI方法以更有效地检测某些类型的AI包容性漏洞。", "innovation": "1. 识别并分类了6种类型的AI包容性漏洞，并记录了83次发生的情况和47次修复的方法。\n2. 创造了一种专门针对AI的包容性设计方法——GenderMag-for-AI，该方法特别适用于检测特定类型的AI包容性漏洞。\n3. 通过实地研究，提供了实用的方法论和工具以帮助AI产品团队解决这些包容性问题，推动了AI技术的公平性和透明性。", "conclusion": "研究发现，AI产品中存在多种类型的包容性漏洞，需通过专门的方法进行检测和修复。通过实施GenderMag-for-AI等方法，可以有效提高AI产品的包容性，进而推动AI技术的广泛普及和应用。"}
{"llm_update_time": "20251023", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.19072", "html_url": "https://arxiv.org/abs/2510.19072", "title": "基于配置的多智能体路径规划中的本地指导", "title_en": "Local Guidance for Configuration-Based Multi-Agent Pathfinding", "authors": "Tomoki Arita,Keisuke Okumura", "background": "指导是一种新兴的概念，能够提升实时、非最优多智能体路径规划（MAPF）方法的实验性能。它通过考虑整个工作空间内所有智能体的行为，为MAPF算法提供额外信息，以减轻全局范围内的拥堵。这种全球视角有助于减少智能体的等待时间，从而提高整体协调效率。然而，本研究探索了一种替代方法，即为每个智能体周围的区域提供本地指导。", "innovation": "本文提出了一种本地指导的方法，即在每个智能体附近提供指导，而不是采用全局的视角。与局部方法需要随着智能体移动进行重计算且可能计算量较大的情况不同，本研究通过实验证明，向规划器提供具有时空信息的提示可以显著提高解决方案质量，同时不会超出适度的时间预算。当应用于LaCAM（一种领先的基于配置的求解器）时，这种形式的指导为MAPF建立了新的性能前沿。", "conclusion": "本研究展示了局部指导在多智能体路径规划中的应用效果，证明了局部指导能够在保证效率的同时，显著提高解决方案的质量，具体应用到了LaCAM求解器上，并为MAPF带来了新的性能水平。"}
{"llm_update_time": "20251023", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.19116", "html_url": "https://arxiv.org/abs/2510.19116", "title": "既过时了！理解、检测和操控语言模型在代码生成中的知识冲突", "title_en": "That's Deprecated! Understanding, Detecting, and Steering Knowledge Conflicts in Language Models for Code Generation", "authors": "Jaesung Bae,Cameron Churchwell,Mitchell Hermon,Tsun-An Hsieh,Jocelyn Xu,Yekaterina Yegorova,Mark Hasegawa-Johnson,Heng Ji", "background": "本文探讨了在给定提示中存在参数知识和提示内包含的冲突信息之间的不一致时，大型语言模型（LLMs）的行为表现。基于先前问答（QA）研究，将知识冲突的研究扩展到了代码生成领域。本文提出了一种通用框架来构建和解释此类冲突，并引入了一种新方法和定制的评估数据集，以适用于代码冲突场景.", "innovation": "本文提出了一个针对代码冲突情况的通用框架及其解释方法，同时开发了一种新的评估方法和数据集。实验证明，足够大的LLMs能够用其参数编码知识冲突的概念，实现高达80.65%的知识冲突检测准确率。此外，通过激活级别引导可以实现高达12.6%的成功指导提升。但效果依赖于模型大小、任务领域和引导方向的平衡.", "conclusion": "本文的实验表明，大型语言模型能够在参数中编码知识冲突信息，并成功检测知识冲突。通过激活级别引导可以在一定程度上改善指导效果，但需注意模型规模、任务领域和引导方向的平衡。相关实验代码和数据将在论文被接受后公开."}
{"llm_update_time": "20251023", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.19060", "html_url": "https://arxiv.org/abs/2510.19060", "title": "PoSh：使用场景图引导LLMs-as-a-Judge进行详细的图像描述评价", "title_en": "PoSh: Using Scene Graphs To Guide LLMs-as-a-Judge For Detailed Image Descriptions", "authors": "Amith Ananthram,Elias Stengel-Eskin,Lorena A. Bradford,Julia Demarest,Adam Purvis,Keith Krut,Robert Stein,Rina Elster Pantalony,Mohit Bansal,Kathleen McKeown", "background": "视觉语言模型（VLMs）在精细图像描述方面取得进展，但评估仍是一项挑战。标准评价指标（如CIDEr，SPICE）设计用于短文本，且已不适合识别现在少见的错误，如物体识别错误。相比之下，长文本需要对属性和关系的准确描述及能够定位文本中错误的具体评分。为此，本文引入了PoSh，一种采用场景图作为结构化评估标准的评价指标，用于指导LLM作为评判者，生成基于细粒度错误的总评分。PoSh具有可复制性、可解释性，并能更好地模拟人类评分，优于现有的评估标准（包括GPT4o-as-a-Judge）。为了验证PoSh，作者创建了一个新的具有挑战性的数据集DOCENT，包含艺术作品，搭配专家撰写的作品参考和模型生成的描述，以及艺术史学生对质量的细粒度和粗略判断。这一新基准使评价详细的图像描述指标和详细的图像描述本身成为可能，尤其是在具有挑战性的新领域。借助PoSh，验证了它比现有最佳开放权重替代方案更强的关联性（Spearman ρ +0.05），具有良好的鲁棒性（如CapArena 数据集），并作为奖励函数表现出色，优于标准监督微调。", "innovation": "本文提出了一种新的评价指标PoSh，其利用场景图作为结构化评估标准来引导LLMs作为评判者，生成基于细粒度错误的总评分。PoSh相较于现有评估标准具有更高的可解释性和鲁棒性，并在DOCENT数据集上验证了其的有效性，特别是在艺术作品等多个方面的详细描述方面。这种方法为视觉语言模型的进步评估提供了一个全新的基准。", "conclusion": "通过PoSh和DOCENT，我们希望能够推动重要领域如辅助文本生成等的进步。未来的研究可通过持续使用PoSh和其他相关指标，来进一步完善和验证视觉语言模型在复杂场景描述中的表现。"}
{"llm_update_time": "20251023", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.19128", "html_url": "https://arxiv.org/abs/2510.19128", "title": "通过条件扩散模型实现跨环境和跨载体路径规划框架", "title_en": "A Cross-Environment and Cross-Embodiment Path Planning Framework via a Conditional Diffusion Model", "authors": "Mehran Ghafarian Tamizi,Homayoun Honari,Amir Mehdi Soufi Enayati,Aleksey Nozdryn-Plotnicki,Homayoun Najjaran", "background": "在高维度杂乱环境中，机器人的路径规划需要高效、安全且能够适应不同环境和硬件。传统方法通常耗时较高，需要大量参数调整，而现有的基于学习的方法在泛化能力上仍有欠缺。", "innovation": "GADGET（通用且适应性的扩散指导环境感知轨迹生成）是一种基于扩散的规划模型，通过体素化场景表示及其起始和目标配置来生成关节空间轨迹。其关键创新之处在于混合双重条件机制，结合了通过学习场景编码的无分类引导与控制屏障函数指导的安全约束调节，直接在去噪过程中集成环境感知与实时碰撞避免，支持在无需重新训练的情况下将路径规划转移到新环境和新机器人载体。", "conclusion": "实验结果显示，GADGET在多种环境中实现高成功率及低碰撞率。与基于采样和基于学习的基线方法相比，GADGET表现出强大的性能，并在Franka Panda、Kinova Gen3（6/7-自由度）和UR5机器人上展示了泛化能力。物理执行的Kinova Gen3证明了其在真实世界环境下的安全、碰撞自由路径生成能力。"}
{"llm_update_time": "20251023", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.19118", "html_url": "https://arxiv.org/abs/2510.19118", "title": "基于U-Net模型和注意力机制及FedProx的乳腺癌分割新方法", "title_en": "A Novel Approach to Breast Cancer Segmentation using U-Net Model with Attention Mechanisms and FedProx", "authors": "Eyad Gad,Mustafa Abou Khatwa,Mustafa A. Elattar,Sahar Selim", "background": "乳腺癌是全球女性的主要死因，强调了早期检测和准确诊断的重要性。超声成像是可靠的且成本效益高的工具，用于此目的，但由于医疗数据的敏感性，开发准确且私有的人工智能模型具有挑战性。联邦学习（Federated Learning）是一种有前景的技术，可以在保护患者隐私的同时，在敏感的医疗数据上进行分布式机器学习。然而，非独立且非同分布（non-IID）的本地数据集的训练会影响训练模型的准确性和泛化能力，这对于精确的肿瘤边界识别至关重要。因此，本研究旨在通过应用Federated Proximal (FedProx)方法解决非IID超声乳腺癌成像数据集带来的挑战，并通过引入带有注意力机制的修改U-Net模型进一步提高肿瘤分割精度。", "innovation": "本研究创新性地提出了结合FedProx方法和带有注意力机制的修改U-Net模型来处理非IID的超声乳腺癌成像数据集。该方法旨在提高肿瘤分割精度的同时，保护患者隐私。", "conclusion": "总体模型达到96%的准确性，表明了该方法在增强肿瘤分割精度和保护患者隐私方面的有效性。研究结果表明，FedProx有可能成为在非IID本地医疗数据集上训练精确机器学习模型的一种有前景的方法。"}
{"llm_update_time": "20251023", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.19099", "html_url": "https://arxiv.org/abs/2510.19099", "title": "构成良好课程的因素：数据排序对大型语言模型数学推理效果的解构", "title_en": "What Makes a Good Curriculum? Disentangling the Effects of Data Ordering on LLM Mathematical Reasoning", "authors": "Yaning Jia,Chunhui Zhang,Xingjian Diao,Xiangchi Yuan,Zhongyu Ouyang,soroush vosoughi", "background": "课程学习（CL）即将训练数据从简单到复杂排序，已成为提高大型语言模型（LLMs）推理能力的一种流行策略。然而，先前的工作使用了不同的难度指标和训练设置，这使得关于何时以及在哪种情况下使用课程学习带来帮助的问题仍然未能得到解决。具体而言，尚不清楚从前往后学习（forward）或从后往前学习（reverse）哪种方式更好，以及这种差异是否取决于所使用的衡量标准。本文通过一个统一的离线评估框架来解决这些问题，该框架将课程的难度分解为五个互补维度：问题难度、模型意外程度、信心差距、预测不确定性以及决策变异性。", "innovation": "本文提出了一种统一的离线评估框架，用于分解课程的难度为五个互补维度，并通过数学推理基准的控制后训练实验研究了大型语言模型（Llama3.1-8B、Mistral-7B和Gemma3-4B）在连续变化的训练数据难度下的表现。研究结果表明：（1）没有一种课程学习策略适用于所有情况——向前学习相对于向后学习的相对有效性取决于模型的能力和任务的复杂性；（2）甚至在单一指标内，不同类型难度级别的样本也会根据任务需求产生不同的收益；（3）任务对齐的课程聚焦于塑造模型的最终表示和泛化，而内部状态课程则调节内部状态，如信心和不确定性。", "conclusion": "本文的研究结果挑战了通用课程学习策略的观念，并提供了跨模型和任务范式的可操作指导，例如某些指标表明优先考虑决策不确定的样本可进一步提高学习效果。"}
{"llm_update_time": "20251023", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.19138", "html_url": "https://arxiv.org/abs/2510.19138", "title": "InvarGC: 在潜在混淆因素下的异质干预时间序列中的不变Granger因果性", "title_en": "InvarGC: Invariant Granger Causality for Heterogeneous Interventional Time Series under Latent Confounding", "authors": "Ziyi Zhang,Shaogang Ren,Xiaoning Qian,Nick Duffield", "background": "Granger因果性在复杂系统的多变量时间序列数据中广泛应用。传统的线性模型Granger因果性检验往往无法检测到轻微的非线性因果关系。因此，许多近期研究探索了非线性Granger因果性方法。尽管这些方法的性能有所提高，但仍基于两个关键假设：因果完全性和已知的干预目标。然而，潜在的混杂因素的存在会导致虚假相关，而在实际环境中，通常缺乏关于干预的先验知识，使得区分干预和非干预环境变得困难，甚至难以识别哪些变量或时间步受到影响。因此，针对这些挑战，我们提出了InvarGC，利用跨环境异质性减轻潜在混杂因素的影响，并在边缘级别区分干预和非干预环境，从而恢复不变的因果关系。还建立了在这些条件下的可识别性。对合成和真实世界数据集的广泛实验表明，该方法在与最新方法的竞争中表现出竞争力。", "innovation": "InvarGC通过利用跨环境异质性来缓解潜在混杂因素的影响，并在边缘级别区分干预和非干预环境，从而恢复不变的因果关系。还建立了在这些条件下的可识别性", "conclusion": "对合成和真实世界数据集的广泛实验表明，InvarGC在与最新方法的竞争中表现出竞争力。"}
{"llm_update_time": "20251023", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.19172", "html_url": "https://arxiv.org/abs/2510.19172", "title": "当事实改变时：使用evolveQA对LLMs进行演变知识探测", "title_en": "When Facts Change: Probing LLMs on Evolving Knowledge with evolveQA", "authors": "Nishanth Sridhar Nakshatri,Shamik Roy,Manoj Ghuhan Arivazhagan,Hanhan Zhou,Vinayshekhar Bannihatti Kumar,Rashmi Gangadharaiah", "background": "预训练模型（LLMs）在处理时间相关的知识冲突时经常表现不佳，即当训练数据中的事实随时间而变化时产生的矛盾。现有研究通过基于结构化知识库（如维基数据）构建的基准测试来评估这种现象，但这些研究主要集中在普及且容易记忆的热门实体上，缺乏动态结构来公平评估具有不同知识截止日期的LLMs的表现。", "innovation": "本文引入了一个名为evolveQA的基准测试，专门用于评估LLMs在处理知识随时间演变的能力，该基准测试基于3个真实的带有时戳的语料库构建：AWS更新、Azure更改和WHO疾病爆发报告。该框架识别自然发生的知识演变，并生成针对不同LLMs知识截止日期的带有金标准答案的问题。通过广泛的评估，展示了LLMs在evolveQA上的性能下降多达31%的情况，与静态知识问题相比表现显著下降。", "conclusion": "evolveQA能够提供一个公平、动态的评估平台，使研究者能够更真实地评估LLMs处理知识随时间演变的能力，并发现现有模型在应对这种挑战时的局限性。"}
{"llm_update_time": "20251023", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.19127", "html_url": "https://arxiv.org/abs/2510.19127", "title": "使用递归特征机引导自回归音乐生成", "title_en": "Steering Autoregressive Music Generation with Recursive Feature Machines", "authors": "Daniel Zhao,Daniel Beaglehole,Taylor Berg-Kirkpatrick,Julian McAuley,Zachary Novack", "background": "可控制的音乐生成仍然是一项重大挑战，现有方法常需要重新训练模型或引入听得到的伪影。现有的音乐生成模型生成的音乐在细微控制和解释性上存在不足，难以以可控的方式生成具有特定音乐特性的曲子，如具体的音符或和弦。", "innovation": "本文提出了一种名为MusicRFM的框架，利用递归特征机（RFMs）能精细调控预训练的音乐生成模型的内部激活，通过直接操控模型的内部梯度来生成可解释的概念方向或特定的激活空间轴。在推理过程中，这种方法能实时引导生成过程，而无需逐步优化。此外，该研究还开发了动态、时变的调度机制以及同时约束多种音乐属性的方法。", "conclusion": "本文的方法能够在保持生成质量的同时实现对音乐生成的精细控制。例如，音乐目标音符的生成准确率可以从0.23提升至0.82，同时保持文本提示的忠实度在0.02范围内。此外，作者开放了代码以促进递归特征机在音乐领域的进一步研究。"}
{"llm_update_time": "20251023", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.19173", "html_url": "https://arxiv.org/abs/2510.19173", "title": "基于新闻的直接强化交易方法", "title_en": "News-Aware Direct Reinforcement Trading for Financial Markets", "authors": "Qing-Yu Lan,Zhan-He Wang,Jun-Qian Jiang,Yu-Tong Wang,Yun-Song Piao", "background": "金融市场对新闻非常敏感，有效将新闻数据整合到量化交易中仍然是一个重要的挑战。现有的方法通常依赖于人工设计的规则和特征工程。因此，我们直接使用大型语言模型得出的新闻情感分数，与原始价格和交易量数据一起，作为强化学习的可观察输入，通过递归神经网络或变压器等序列模型实现端到端交易决策。", "innovation": "我们利用大型语言模型生成的新闻情感分数作为输入，无需人工设计的特征或规则，与其他改进的输入一起通过序列模型进行交易决策。我们使用两种代表性的强化学习算法：双重深度Q网络（DDQN）和组相对策略优化（GRPO），并在加密货币市场进行了实验，结果证明这种方式优于市场基准。进一步强调了时间序列信息在该过程中的重要性。", "conclusion": "我们的新闻感知方法能够在没有手动设计的特征或规则的情况下，实现比市场基准更好的性能。时间序列信息在决策过程中扮演着关键角色。"}
{"llm_update_time": "20251023", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.19178", "html_url": "https://arxiv.org/abs/2510.19178", "title": "多任务RL后训练中梯度不平衡现象", "title_en": "Imbalanced Gradients in RL Post-Training of Multi-Task LLMs", "authors": "Runzhe Wu,Ankur Samanta,Ayush Jain,Scott Fujimoto,Jeongyeol Kwon,Ben Kretzu,Youliang Yu,Kaveh Hassani,Boris Vidolov,Yonathan Efroni", "background": "多任务大型语言模型（LLMs）的后训练通常通过混合不同任务的数据集并共同优化来进行。这种方法假设所有任务的梯度大小相似；当此假设不成立时，优化会偏向于梯度较大的任务。但在RL后训练中，我们发现某些任务产生的梯度明显更大，因此使更新偏向这些任务。这种梯度不平衡只有在更大梯度意味着更大学习收益（即更大的性能改进）时才能被合理解释，但发现这并不是真的。", "innovation": "研究发现，在RL后训练中，梯度不平衡现象是由于任务之间的固有差异导致的，而非常规训练统计数据所能解释。这种发现警示了直接混合数据集的方法，并要求未来工作在LLMs中进行基于梯度水平的修正。", "conclusion": "大型梯度的任务可能与小型梯度的任务获得相似甚至更低的学习收益。梯度不平衡不能通过典型的训练统计数据来解释，这意味着它们源于任务间的固有差异。研究提醒我们不要采用简单的数据集混合方法，并且需要进一步探讨具有原理性的梯度级修正方法。"}
{"llm_update_time": "20251023", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.19202", "html_url": "https://arxiv.org/abs/2510.19202", "title": "带有活性扩散的图形神经网络", "title_en": "An Active Diffusion Neural Network for Graphs", "authors": "Mengying Jiang", "background": "热扩散类比增强了我们对图中信息流动的理解，并促进了图神经网络（GNNs）的发展。然而，大多数基于扩散的GNNs仿效被动的热扩散，仍然存在过度平滑的问题，限制了它们捕获全局图信息的能力。", "innovation": "ADGNN通过整合多种外部信息源，使扩散过程动态受其影响，实现了活跃扩散，有效克服了过度平滑的问题。进一步地，通过直接计算活性扩散迭代公式的闭式解来实现真正的无限扩散，从而使节点在其特性被保留的同时，能够有效获得关于图形全局结构的全面见解。", "conclusion": "与多种先进的GNN模型在各种图任务上进行评估，结果显示ADGNN在准确性和效率上显著提升，证明了其在捕捉全局图信息和保持节点独特性方面的有效性。"}
{"llm_update_time": "20251023", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.19150", "html_url": "https://arxiv.org/abs/2510.19150", "title": "X-Ego: 通过跨视角对比视频表示学习获取团队级别的战术态势感知", "title_en": "X-Ego: Acquiring Team-Level Tactical Situational Awareness via Cross-Egocentric Contrastive Video Representation Learning", "authors": "Yunzhe Wang,Soham Hans,Volkan Ustun", "background": "人类团队策略的形成基于每个队员的个人视角以及对队友意图预测、解读和适应能力。虽然视频理解的进步提高了对团队互动建模的能力，但现有工作大多依赖第三方现场视角，忽视了多智能体学习中同步的、以自我为中心的特点。之前的工作主要集中在第三方视角上，没有充分利用多视角同步的信息来研究复杂3D环境中的多智能体决策问题。本文介绍了X-Ego-CS数据集，包含45场专业级别的《反恐精英 2》游戏比赛的124小时的 gameplay 录像，旨在促进复杂3D环境中的多智能体决策研究，并提供了跨视角的第一视角视频流，同步捕捉所有玩家的第一视角视点和状态-行动轨迹。基于此资源，提出了跨视角对比学习（CECL），该方法将队友的自视角视频流对齐，以从个人视角培养团队战术态势感知。该方法在队友-对手位置预测任务中的评估显示，它能够显著增强智能体从单一第一视角判断队友和对手位置的能力，这证明了其有效性。", "innovation": "本文提出了X-Ego-CS数据集，这是第一个旨在研究复杂3D环境中的多智能体决策的数据集，提供了跨视角的第一视角视频流，同步捕捉所有玩家的第一视角视点和状态-行动轨迹。此外，文章提出了一种名为CECL的新方法，通过将队友的自视角视频流对齐来提高单视角智能体对于队友和对手位置的预测能力。这种方法在实验中证明了其有效性。这种方法和数据集一起，为电子竞技中的多智能体基准测试建立了基础，同时还将游戏理解作为多智能体建模和战术学习的测试平台，具有在虚拟和现实世界中进行空间时序推理和人机团队合作的广泛意义。", "conclusion": "X-Ego-CS数据集和CECL方法为复杂3D环境中的多智能体决策基准测试和战术学习研究提供了一个重要的平台。该研究不仅提升了在单第一视角下预测队友和对手位置的能力，还有望促进电子竞技领域的多智能体协同机制研究，并为其他领域中的时空推理和人机团队合作提供指导。"}
{"llm_update_time": "20251023", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.19183", "html_url": "https://arxiv.org/abs/2510.19183", "title": "PruneHal: 通过自适应KV缓存剪枝减少多模态大型语言模型中的幻觉现象", "title_en": "PruneHal: Reducing Hallucinations in Multi-modal Large Language Models through Adaptive KV Cache Pruning", "authors": "Fengyuan Sun,Hui Chen,Xinhao Xu,Dandan Zheng,Jingdong Chen,Jun Zhou,Jungong Han,Guiguang Ding", "background": "近年来，多模态大型语言模型（MLLMs）取得了显著进展，但在幻觉问题上仍面临重大挑战。现有方案要么通过增加数据进行进一步训练，要么在推理过程中引入外部或内部信息，但这些方法不可避免地增加了额外的计算成本。", "innovation": "本文观察到，MLLMs中的幻觉与对视觉标记的注意力不足密切相关，特别是冗余视觉标记分散了模型的注意力，导致对最有效的视觉线索关注不足，从而加剧了幻觉的发生。基于这一观察，我们提出了PruneHal，这是一种无需训练、简单有效的方法，利用自适应KV缓存剪枝来增强模型对关键视觉信息的关注，从而减少幻觉。这是首次使用标记剪枝在MLLMs中降低幻觉的方法，且不需额外训练且几乎不增加推理成本，此外，PruneHal是模型通用的，并能无缝集成不同的解码策略，包括专门用于幻觉抑制的策略。", "conclusion": "我们在四个主流MLLM上对几种广泛应用的幻觉评估基准进行了测试，PruneHal取得了稳健且出色的结果，突显了该方法的有效性和优越性。我们的代码将公开提供。"}
{"llm_update_time": "20251023", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.19181", "html_url": "https://arxiv.org/abs/2510.19181", "title": "基于知识图谱的可解释问答系统", "title_en": "Interpretable Question Answering with Knowledge Graphs", "authors": "Kartikeya Aneja,Manasvi Srivastava,Subhayan Das,Nagender Aneja", "background": "当前的问答系统主要依赖于大规模语言模型（LLMs）的检索增强生成（RAG）方法，这种方法虽然高效，但也面临诸如解释性差和泛化能力不足等问题。本文提出了一种不同于传统RAG方法的问答系统，专注于通过知识图谱检索来生成问答对，不依赖于大规模语言模型的辅助。", "innovation": "提出了一种新的问答系统架构，该架构在不依赖大规模语言模型的情况下，利用小型重述器模型对从知识图谱检索出的实体关系边进行重述，从而生成最终答案。系统分为预处理、生成问答对以及通过图检索生成最终答案三个主要阶段。通过LLM作为评判者在CRAG基准上的评估结果表明，该方法具有较高的准确性。", "conclusion": "本文提出的方法相比传统的RAG方法具有更高的可解释性，并在CRAG基准上取得了良好的效果。未来的研究可以进一步优化模型性能并扩展应用场景。"}
{"llm_update_time": "20251023", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.19195", "html_url": "https://arxiv.org/abs/2510.19195", "title": "重思驾驶世界模型作为感知任务的合成数据生成器", "title_en": "Rethinking Driving World Model as Synthetic Data Generator for Perception Tasks", "authors": "Kai Zeng,Zhanqian Wu,Kaixin Xiong,Xiaobao Wei,Xiangyu Guo,Zhenxin Zhu,Kalok Ho,Lijun Zhou,Bohan Zeng,Ming Lu,Haiyang Sun,Bing Wang,Guang Chen,Hangjun Ye,Wentao Zhang", "background": "近期，驾驶世界的模型取得了显著进展，能够生成高质量的RGB视频或多种模态的视频。现有方法主要关注生成质量与可控性评估指标，但往往忽略了对下游感知任务的评估。数据增强方面，现有方法通常采用一种先在合成数据上预训练，然后在真实数据上微调的策略，这导致了两倍的训练轮次与基准方法（仅使用真实数据的情况）不同。当将基准方法的训练轮次加倍时，合成数据带来的好处变得不明显。因此，本文旨在深入探讨合成数据的优势，并提出了一种名为Dream4Drive的创新性合成数据生成框架，用于增强下游感知任务。通过将输入视频分解成多个3D感知引导图，然后在此基础上渲染3D资源，最终通过驾驶世界模型生成编辑过的多视角、写实的视频，用于训练下游感知模型。", "innovation": "文章引入了一个名为Dream4Drive的新颖合成数据生成框架，其独特之处在于将输入视频分解成多个3D感知引导图，并在这些引导图上渲染3D资源，最后通过驾驶世界模型生成编辑过的多视角、写实的视频。这一方法能够实现大规模生成多视角的极端案例，显著提升自动驾驶中的边缘案例感知能力。同时，文章还贡献了一个大规模的3D资产数据集DriveObj3D，涵盖了驾驶场景中的典型类别，支持多样化的3D感知视频编辑。实验结果表明，Dream4Drive能够有效增强各种训练轮次下的下游感知模型性能。", "conclusion": "文章通过Dream4Drive框架，深入示范了合成数据在提升自动驾驶下游感知任务性能方面的优势。此外，通过贡献DriveObj3D数据集，对未来的相关研究提供了强大的支持。"}
{"llm_update_time": "20251023", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.19257", "html_url": "https://arxiv.org/abs/2510.19257", "title": "FnRGNN：图神经网络中的分布感知公平性", "title_en": "FnRGNN: Distribution-aware Fairness in Graph Neural Network", "authors": "Soyoung Park,Sungsu Lim", "background": "图神经网络（GNNs）在处理结构化数据方面表现出色，但在回归任务中的公平性研究仍然不足。现有的方法主要集中在分类和表示层次上的去偏，这不能完全解决节点级别回归任务中连续值的公平性问题。", "innovation": "提出了一种名为FnRGNN的公平感知内处理框架，用于基于GNN的节点回归任务。该框架从三个层次进行干预：（i）结构层面的边加权，（ii）表示层面的MMD对齐，以及（iii）预测层面通过基于Sinkhorn的分布匹配进行规范化处理。这种多层次策略能在复杂图结构下确保公平性。", "conclusion": "在四个真实世界数据集上的实验表明，FnRGNN能够减少群体之间的差距，同时不牺牲性能。"}
{"llm_update_time": "20251023", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.19241", "html_url": "https://arxiv.org/abs/2510.19241", "title": "SPOT: Markov决策过程中的可扩展树策略优化", "title_en": "SPOT: Scalable Policy Optimization with Trees for Markov Decision Processes", "authors": "Xuyuan Xiong,Pedro Chumpitaz-Flores,Kaixun Hua,Cheng Hua", "background": "可解释的强化学习策略在高风险决策中至关重要，但在Markov决策过程（MDPs）中优化决策树策略依然具有挑战性。", "innovation": "提出了一种名为SPOT的新颖方法，将决策树策略的优化问题形式化为混合整数线性规划（MILP），并采用空间减少的分支定界方法将MDP动力学与树结构约束分离，从而实现高效并行搜索，显著提高了运行时间和可扩展性。", "conclusion": "实验证明，SPOT在标准基准上实现了显著的加速并能处理更大规模的MDP。生成的决策树策略具有高可解释性且紧凑，保持透明性同时不牺牲性能。这些结果表明，我们的方法同时实现了可解释性和可扩展性，比现有方法快一个数量级。"}
{"llm_update_time": "20251023", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.19212", "html_url": "https://arxiv.org/abs/2510.19212", "title": "没有统计学就没有智能：人工智能的无形支柱", "title_en": "No Intelligence Without Statistics: The Invisible Backbone of Artificial Intelligence", "authors": "Ernest Fokoué", "background": "传统上，人工智能（AI）的快速发展被描绘为源自计算机科学和工程的革命。然而，这种叙述掩盖了AI的实质：统计学是其理论和方法论的核心，这一核心自始至终未曾改变。本文通过系统地论述统计学在机器学习和现代AI中的不可替代基础地位，拆解AI为九个核心支柱：推理、密度估计、序列学习、泛化、表示学习、可解释性、因果性、优化和统一，并展示了每个支柱都建立在百年统计原理之上。文章强调了统计学在提供理论框架、不确定性量化和推断目标方面的重要性，而计算科学则提供了可扩展的算法和硬件方面的支持。", "innovation": "本文创新性地将AI划分为九个核心支柱，并展示了每个支柱都建立在统计学的基础上，从而构成了AI的无形支柱。这一论述强调了统计学在现代AI中的核心作用，超越了仅强调计算能力的传统观点。文章还发出呼吁，在教育、研究和实践中重新重视这一统计学基础，以开发更稳健、可解释和可信的人工智能系统。", "conclusion": "忽视这些基础意味着可能建立脆弱的人工智能，而正视并拥抱这些基础是迈向真正智能机器的道路。没有统计学就没有机器学习；没有统计学的思想就没有人工智能。"}
{"llm_update_time": "20251023", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.19264", "html_url": "https://arxiv.org/abs/2510.19264", "title": "LAPRAD: LLM-Assisted Protocol Attack Discovery", "title_en": "LAPRAD: LLM-Assisted PRotocol Attack Discovery", "authors": "R.Can Aygun(UCLA),Yehuda Afek(Tel-Aviv University),Anat Bremler-Barr(Tel-Aviv University),Leonard Kleinrock(UCLA)", "background": "随着互联网协议安全性的提升，研究人员致力于发现现有协议（如DNS、BGP等）中的新漏洞。传统的安全评估方法较慢且难以自动处理，为此本文提出了一种新的技术手段——LLM-Assisted Protocol Attack Discovery (LAPRAD)，利用大型语言模型（LLM）如GPT-o1来辅助发现这些协议中的潜在攻击。", "innovation": "LAPRAD方法引入了三个阶段的过程：首先是使用训练有素的LLM识别可能的攻击方法；其次是用ReACT方法通过LangChain自动生成攻击配置；最后通过验证确保攻击的有效性。这种方法能够利用LLM强大的文本处理能力，加快发现DNS协议中新型和未见攻击的速度。", "conclusion": "通过LAPRAD方法，研究人员发现了三个新的针对DNS协议的DDoS攻击，其中两个在过去报告中没有被包含在LLM的训练数据中。LAPRAD首次揭示了通过Cache Flushing DDoS攻击技术，包括钓鱼交换技巧、使用大范围DNSSEC加密算法和利用ANY响应类型，这些攻击能巧妙地绕过现有的防护措施，严重影响了DNS解析器的服务能力。"}
{"llm_update_time": "20251023", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.19245", "html_url": "https://arxiv.org/abs/2510.19245", "title": "视觉、思考、行动：利用VLM代理进行在线购物者行为模拟", "title_en": "See, Think, Act: Online Shopper Behavior Simulation with VLM Agents", "authors": "Yimeng Zhang,Jiri Gesi,Ran Xue,Tian Wang,Ziyi Wang,Yuxuan Lu,Sinong Zhan,Huimin Zeng,Qingjun Cui,Yufan Guo,Jing Huang,Mubarak Shah,Dakuo Wang", "background": "LLMs在模拟在线购物者行为方面展示了强大的潜力。现有工作通过应用SFT和RL分别提高了行为预测和增强了推理能力。然而，当前方法主要依赖于基于文本的输入，忽视了网页GUI交互中视觉感知在塑造人类决策中的重要作用。", "innovation": "本文研究了如何通过VLM结合网页截图等视觉信息来补充行为模拟，利用OPeRA数据集。通过在文本和视觉模态中锚定代理决策，以缩小合成代理与真实用户之间的差距，实现更认知一致的在线购物行为模拟。具体方法包括使用SFT进行联合动作预测和理由生成，结合多层次奖励结构，并引入一个难度感知因子来优先处理具有挑战性的决策点。", "conclusion": "实验结果表明，结合视觉接地可以显著提高精度，多模态接地不仅提高了预测准确性，还提升了在视觉复杂环境中模拟的真实度。最后，重新审视了行为模拟框架的设计空间，指出了现有方法的关键限制，并提出了未来的研究方向，旨在构建高效且有效的模拟人类行为的模拟器。"}
{"llm_update_time": "20251023", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.19298", "html_url": "https://arxiv.org/abs/2510.19298", "title": "策略知识与共同策略知识", "title_en": "Knowledge and Common Knowledge of Strategies", "authors": "Borja Sierra Miranda,Thomas Studer", "background": "目前大多数关于策略推理的研究简单地采用了有信息或无信息的语义。本文提出了一种模型，可以在精细层面上描述对策略的知识。特别地，可以区分一阶、高阶和共同策略知识。通过研究游戏Hanabi，探讨了高阶策略知识的效果。此外，证明了共同策略知识在解决一致问题时是必要的。最后，研究了该模型检查问题的可判定性。", "innovation": "提出了在精细层面上指定策略知识的模型，区分了一阶、高阶和共同策略知识。通过研究Hanabi游戏展示了高阶策略知识的影响，并证明了在解决一致性问题中共同策略知识的重要性。", "conclusion": "最终，研究表明了模型检查问题的可判定性，并强调了共同策略知识在策略推理和一致性问题解决中的关键作用。"}
{"llm_update_time": "20251023", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.19270", "html_url": "https://arxiv.org/abs/2510.19270", "title": "社会世界模型增强的机制设计策略学习", "title_en": "Social World Model-Augmented Mechanism Design Policy Learning", "authors": "Xiaoyuan Zhang,Yizhe Huang,Chengdong Ma,Zhixun Chen,Long Ma,Yali Du,Song-Chun Zhu,Yaodong Yang,Xue Feng", "background": "在人工社会智能领域，设计适应性机制以协调个体和集体利益依然是一个核心挑战。现有方法在建模具有持续潜在特质（如技能、偏好）的异质主体和处理复杂多主体系统动力学方面常遇到困难。由于昂贵的现实世界互动需求，还亟需高效采样。世界模型通过学习预测环境动态，为提高异质性和复杂系统的机制设计提供了有前景的途径。", "innovation": "本文提出了一种名为SWM-AP（社会世界模型增强机制设计策略学习）的新方法。该方法通过分层建模代理行为来学习社会世界模型，并通过这种方式增强机制设计。社会世界模型能够从代理交互轨迹中推断代理特征，并学习一种基于特征的模型来预测代理对部署机制的响应。机制设计策略通过与社会世界模型交互收集大量的训练轨迹，并在实际交互过程中在线推断代理特征以进一步提高策略学习效率。", "conclusion": "在不同的场景（如税收政策设计、团队协作和设施选址）下进行的实验表明，SWM-AP在累计奖励和样本效率方面优于现有的基于模型和无模型的强化学习基线方法。"}
{"llm_update_time": "20251023", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.19303", "html_url": "https://arxiv.org/abs/2510.19303", "title": "协作渗透测试套件以应对新兴的生成式AI算法", "title_en": "Collaborative penetration testing suite for emerging generative AI algorithms", "authors": "Petar Radanliev", "background": "生成式AI面临模型翻转、数据投毒、对抗输入等传统威胁，同时量子计算可能通过Shor算法破坏RSA和ECC加密。这些威胁构成了对生成式AI模型的安全挑战。", "innovation": "提出了一个协作渗透测试套件，包含了五种集成组件：DAST、SAST、OWASP ZAP、Burp Suite、SonarQube，以及Fortify，通过与CI/CD集成的IAST进行统一应用。此外，引入了区块链日志记录（使用Hyperledger Fabric）和基于晶格的量子抗性密码学（Lattice-based RLWE协议），以及AI红队模拟对抗机器学习和量子辅助攻击。", "conclusion": "在测试环境中确定了300多个漏洞，两周内高危问题减少了70%，区块链记录漏洞的修复效率达到了90%，量子抗性密码学在测试中保持了100%的完整性。综上所述，该研究开发了一种量子AI安全协议，该协议结合了区块链、量子加密和AI红队模拟。"}
{"llm_update_time": "20251023", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.19282", "html_url": "https://arxiv.org/abs/2510.19282", "title": "通过大数据和集成少样本学习提高早期阿尔茨海默病检测", "title_en": "Enhancing Early Alzheimer Disease Detection through Big Data and Ensemble Few-Shot Learning", "authors": "Safa Ben Atitallah,Maha Driss,Wadii Boulila,Anis Koubaa", "background": "阿尔茨海默病是一种严重影响大脑不同区域的严重脑疾病，导致记忆力受损。由于标注医疗数据的有限性，准确的阿尔茨海默病检测面临重大挑战。考虑到标注数据稀缺、疾病复杂性和数据隐私约束，迫切需要有效的方法来提高阿尔茨海默病检测的准确性。为此，该研究利用预训练的卷积神经网络（CNNs）在少样本学习（FSL）和集成学习框架下的强大力量。该研究利用原型网络（ProtoNet）进行集成方法，并结合多种预训练CNN作为编码器，增强从医学图像中提取的特征的丰富性。该方法还结合了类条件损失和熵损失，以确保对阿尔茨海默病进展程度的更精确分类。", "innovation": "该研究提出了一种基于原型网络的集成方法，结合了多种预训练的卷积神经网络作为编码器，提高了从医学图像中提取的特征的丰富性。此外，该方法还整合了类条件损失和熵损失，以确保对阿尔茨海默病进展程度的更精确分类。通过对两个数据集（Kaggle阿尔茨海默症数据集和ADNI数据集）进行了评估，该方法分别达到了99.72%和99.86%的准确率，证明了其在早期阿尔茨海默病检测中的有效性和潜在应用价值。", "conclusion": "该研究通过集成少样本学习和预训练的卷积神经网络，结合多阶段的损失函数优化，有效提高了阿尔茨海默病的早期检测准确性，并为实际应用提供了有力支持。"}
{"llm_update_time": "20251023", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.19321", "html_url": "https://arxiv.org/abs/2510.19321", "title": "基于时空图注意力变换器的在线手写签名认证", "title_en": "Online Handwritten Signature Verification Based on Temporal-Spatial Graph Attention Transformer", "authors": "Hai-jie Yuan,Heng Zhang,Fei Yin", "background": "手写签名验证是身份认证的关键方面，广泛应用于金融和电子商务等领域。然而，由于用户内部变异性和伪造风险，实现高精度的手写签名验证仍然具有挑战性。当前方法在不同场景下的错误接受率（EER）仍未能达到最优效果。", "innovation": "该研究提出了一种新颖的在线手写签名验证方法——时空图注意力转换器（TS-GATR）。TS-GATR 将图注意力网络（GAT）和门控循环单元（GRU）相结合，以建模签名数据中的时空依赖性。该方法不仅通过将签名表示为图来捕捉动态特征（如位置、速度、压力），还利用注意力机制来建模这些特征之间的复杂关系。此外，方法还引入了双图注意力变换器（DGATR）模块，该模块运用 k 路邻居和 k 距邻近邻接图分别建模局部和全局空间特征。通过集成 GRU，该模型能够学习动态特征，进一步捕捉长期时间依赖性，显著提高了签名验证的性能。", "conclusion": "在基准数据集 MSDS 和 DeepSignDB 上进行的全面实验表明，TS-GATR 方法在各种场景下均能优于现有的先进方法，持续性地实现更低的等错误率（EER）。"}
{"llm_update_time": "20251023", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.19325", "html_url": "https://arxiv.org/abs/2510.19325", "title": "Balancing Rewards in Text Summarization: Multi-Objective Reinforcement Learning via HyperVolume Optimization", "title_en": "Balancing Rewards in Text Summarization: Multi-Objective Reinforcement Learning via HyperVolume Optimization", "authors": "Junjie Song,Yiwen Liu,Dapeng Li,Yin Sun,Shukun Fu,Siqi Chen,Yuji Cao", "background": "文本摘要是一项关键任务，要求同时优化一致性和连贯性、相关性和流畅性等多个目标，带来了显著的挑战。尽管大规模语言模型（LLMs）表现出色，并通过强化学习（RL）得到了提升，但仍很少有研究通过基于LLMs的RL方法来优化摘要任务的多目标问题。现有的研究多集中在单一或双目标优化，未能充分利用多目标优化策略如帕累托前沿来生成平衡的摘要。HVO（hypervolume optimization）是一种新的优化策略，通过在RL奖励过程中动态调整组间的得分来指导模型优化，进一步逼近帕累托前沿，从而产生在各个目标上均衡的摘要。实验结果表明，HVO在多个代表性摘要数据集上整体得分优于GRPO，并且在不同维度上的性能更加均衡。增强后的7B基础模型在摘要任务中的表现与GPT-4相当，同时生成长度较短。", "innovation": "提出了一种新的优化策略HVO（hypervolume optimization），这是一种通过使用Hypervolume方法在强化学习（RL）过程中动态调整组间得分来优化文本摘要多目标任务的策略。这种方法指导模型优化，逐渐逼近帕累托前沿，从而生成在多个目标上均衡的摘要。实验表明，与现有的GRPO方法相比，HVO不仅能提高整体性能，并且在各个维度上的表现更加均衡。此外，增强后的7B基础模型在摘要任务中表现接近于GPT-4，但生成时间更短。", "conclusion": "实验结果表明，HVO在多个代表性摘要数据集上的整体表现优于GRPO，并且在不同维度上的性能更加均衡。增强后的7B基础模型在摘要任务中的表现与GPT-4相当，但生成时间较短。该方法的代码已在公共地址发布。"}
{"llm_update_time": "20251023", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.19322", "html_url": "https://arxiv.org/abs/2510.19322", "title": "在光学网络中实现配置通信重叠以促进集体通信", "title_en": "Enabling Reconfiguration-Communication Overlap for Collective Communication in Optical Networks", "authors": "Changbo Wu,Zhuolong Yu,Gongming Zhao,Hongli Xu", "background": "集体通信（CC）在大规模分布式机器学习（DML）训练负载中广泛应用。DML的可预测流量模式为应用光学网络技术提供了巨大机会。现有的基于光学互联的CC方案采用“一次性网络重构”策略，为整个集体操作配置静态高容量拓扑——有时整个训练迭代都如此。然而，这种策略在支持现代工作负载所需的更复杂和高效的CC算法时面临显著的扩展限制：‘一次性’策略要么需要过度预留资源，要么因固有的资源分配而性能下降。针对这些挑战，本文提出了SWOT，一种基于需求的光学网络框架，通过‘在集体内重构’动态对齐网络资源与CC流量模式，SWOT引入了一种新技术，能够在光交换重新配置与正在进行的传输之间重叠，从而提高通信效率。SWOT还引入了一个轻量级集体通信屏蔽层，使光学网络配置和传输调度协调进行，同时支持与现有CC库的无缝集成。模拟结果显示SWOT在性能上有显著提升。", "innovation": "SWOT提出了‘在集体内重构’（intra-collective reconfiguration），通过动态对齐网络资源与集体通信（CC）流量模式，提出了一种新颖的调度技术，能够在光交换重新配置与正在进行的传输之间重叠，以增强通信效率。此外，SWOT还开发了一个轻量级的集体通信屏蔽层，使得光学网络配置和传输调度的协调进行，同时支持与现有CC库的无缝集成。", "conclusion": "本文提出的SWOT框架显著提升了光学网络中集体通信的性能。"}
{"llm_update_time": "20251023", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.19327", "html_url": "https://arxiv.org/abs/2510.19327", "title": "SORA-ATMAS：面向未来智能城市的自适应信任管理与多LLM对齐治理", "title_en": "SORA-ATMAS: Adaptive Trust Management and Multi-LLM Aligned Governance for Future Smart Cities", "authors": "Usama Antuley,Shahbaz Siddiqui,Sufian Hameed,Waqas Arif,Subhan Shah,Syed Attique Shah", "background": "智能城市的快速发展促使人们更加依赖智能互联服务来优化基础设施、资源和市民福祉。代理型人工智能（Agentic AI）作为关键促成因素，通过支持自主决策和适应性协调，使城市系统能够实时响应动态条件。例如，在交通方面，通过整合交通数据、天气预报和安全传感器，能够实现动态重路由和更快地应对危险。然而，这种技术部署在异质智能城市生态系统中引发了关键的治理、风险和合规（GRC）挑战，包括问责制、数据隐私和去中心化基础设施中的法规一致性问题。SORA-ATMAS框架在天气、交通和安全三个领域代理中进行了评估，结果显示其治理政策有效引导多种LLM（GPT、Grok、DeepSeek）产生符合领域优化的、政策对齐的输出，使各代理的平均MAE减少了35%。结果显示了稳定的天气监控、有效的高风险交通处理以及安全/火灾场景下适应的信托调节。", "innovation": "SORA-ATMAS框架建立了一种治理算法，通过结合分布式代理输出，实现了可追溯、实时并合规的决策制定。该框架采用了跨域规则确保多领域的安全互操作性，并利用路径规划和数据一致性检查确保交通重路由仅在验证的天气条件下进行。", "conclusion": "SORA-ATMAS为智能城市治理提供了一个合规、情境感知和可验证的治理框架，通过大规模部署验证了其通用性和性能稳定性。这种框架确保了智能城市管理的可靠性和安全性，为进一步推进智能城市项目的发展奠定了坚实的基础。"}
{"llm_update_time": "20251023", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.19334", "html_url": "https://arxiv.org/abs/2510.19334", "title": "利用大型语言模型进行元数据提取", "title_en": "Metadata Extraction Leveraging Large Language Models", "authors": "Cuize Han,Sesh Jalagam", "background": "大型语言模型的出现已经彻底改变了包括法律文件分析在内的各个领域中的任务自动化，这是现代合同管理系统中的关键组成部分。本文展示了大型语言模型增强元数据提取的全面实现，重点关注关键法律条款的自动检测与标注。利用公开的Contract Understanding Atticus Dataset (CUAD) 和私有合同数据集，我们的研究证明了高级大型语言模型方法与实际应用的结合是可行的。研究表明，在元数据提取中需优化三个要素：稳健的文本转换、策略性片段选择和高级大型语言模型特有的技术，包括因果推理提示（Chain of Thought, CoT）和结构化工具调用。实验结果显示了关键条款识别准确率和效率的显著提高。这表明，优化过的大型语言模型能够减少合同审查所需的时间和成本，同时保持法律条款识别的高准确性，并暗示其或将作为法律专业人士的有力工具，促进不同规模的组织高效合同审查服务的获取。", "innovation": "本文主要创新在于利用先进的大型语言模型方法对合同进行增强的元数据提取，具体包括：（1）开创性地结合了大型语言模型特有的技术，尤其是因果推理提示（Chain of Thought, CoT）和结构化工具调用；（2）提出并实践了三个关键要素以优化元数据提取——稳健的文本转换、策略性片段选择和大型语言模型特有的方法；（3）通过实验验证了优化过的方法能够显著提高条款识别的准确率和效率，有效减少合同审查的时间和成本。", "conclusion": "优化的大型语言模型有可能作为法律专业人士的重要工具，在减少合同审查中的时间和成本的同时保持高水平的准确度。这可能促进不同规模组织快速访问高效合同审查服务。"}
{"llm_update_time": "20251023", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.19338", "html_url": "https://arxiv.org/abs/2510.19338", "title": "每一个注意力都重要：一种用于长上下文推理的高效混合架构", "title_en": "Every Attention Matters: An Efficient Hybrid Architecture for Long-Context Reasoning", "authors": "Ling Team,Bin Han,Caizhi Tang,Chen Liang,Donghao Zhang,Fan Yuan,Feng Zhu,Jie Gao,Jingyu Hu,Longfei Li,Meng Li,Mingyang Zhang,Peijie Jiang,Peng Jiao,Qian Zhao,Qingyuan Yang,Wenbo Shen,Xinxing Yang,Yalin Zhang,Yankun Ren,Yao Zhao,Yibo Cao,Yixuan Sun,Yue Zhang,Yuchen Fang,Zibin Lin,Zixuan Cheng,Jun Zhou", "background": "当前的研究集中在长上下文推理场景中的模型设计，尤其是优化模型的输入输出和计算开销，以减少推理成本。背景研究了不同参数规模的模型在长上下文推理中的性能差异，并对比了传统模型和新提出的混合架构模型之间的效率和效果。", "innovation": "提出了一个混合架构模型系列，包括Ring-mini-linear-2.0和Ring-flash-linear-2.0。这些模型通过有效结合线性注意力和softmax注意力，显著减少了长上下文推理场景中的输入输出和计算开销。与320亿参数的密集模型相比，该系列模型将推理成本降低了1/10，与原始Ring系列相比，成本降低了50%以上。此外，通过系统探索混合架构中不同注意力机制的比例，确定了目前最优化的模型结构。通过使用自研的高性能FP8操作库linghe，整体训练效率提高了一倍。", "conclusion": "这两种模型在复杂的综合推理基准测试中保持了SOTA性能，并且由于训练和推理引擎操作的良好对齐，模型在强化学习阶段可以进行长期、稳定和高效的优化。"}
{"llm_update_time": "20251023", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.19342", "html_url": "https://arxiv.org/abs/2510.19342", "title": "使用或拒绝？利用生成式AI重新聚焦工程设计教育中的学生自主权", "title_en": "To Use or to Refuse? Re-Centering Student Agency with Generative AI in Engineering Design Education", "authors": "Thijs Willems,Sumbul Khan,Qian Huang,Bradley Camburn,Nachamma Sockalingam,King Wang Poon", "background": "该试点研究追踪了新加坡Tech大学设计学院超过500名大一工程与建筑系学生对AI在13周基础设计课程中的应用反思。课程旨在通过多种干预措施使学生掌握基于AI的设计技能。研究通过引导学生以工具（工具助手）、同伴（协作伙伴）或两者都不是（故意不使用）的视角进行反思，帮助学生学会将AI用于创新而非仅仅自动化，并要求学生从技术使用、代理权、伦理和背景等方面进行反思，而不仅仅是从提示构建的角度。研究数据分析巩固了使用Gen-AI带来的共性实践，如快速原型设计、技能快速获得、迭代提示优化、研发中的人机切换以及识别幻觉的新兴流程。研究意外发现学生不仅利用Gen-AI提高效率，还在工具助手中学会拒绝AI输出，发明自己的幻觉处理策略，并把节省的时间投入更深入的用户研究，从而将效率转化为创新。", "innovation": "研究表明，通过工具接入、反思、角色标记和公共认可竞争奖励相结合的方式，可以将AI在教育中的应用转化为可评估的设计习惯，培养学生对幻觉的感知能力，并且实现了在不牺牲问责性的前提下扩大基于AI的教育创新规模。一种新的方法论强调了学生自主权在使用生成式AI中的核心地位，改变了教育技术中学生角色的传统定位，使其不仅仅是技术的工具使用者，更是创新实践的参与者与决策者。这种方法促进了学生对AI系统的批判性思考，增强了其设计伦理与实践中的自主决策能力。", "conclusion": "本研究通过案例研究和数据分析，为工程设计教育领域中的AI应用提供了一种新的方法论，即如何将AI作为创新工具而不是简单地自动化工具使用，以及如何培养具有伦理意识和反思能力的学生。研究结果表明，通过精心设计的工具使用权、反思实践、角色定义和公共竞赛，AI可以在教育中得到有效利用，而不是仅仅作为一种完成任务的工具。这种模式不仅能够提高学生设计能力，还能显著增强他们对AI技术的批判性认知和道德感知。"}
{"llm_update_time": "20251023", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.19347", "html_url": "https://arxiv.org/abs/2510.19347", "title": "一种新的类型对抗样本", "title_en": "A New Type of Adversarial Examples", "authors": "Xingyang Nie,Guojie Xiao,Su Pan,Biao Wang,Huilin Ge,Tao Fang", "background": "大多数机器学习模型都对对抗样本非常脆弱，这给这些模型的安全性带来了问题。对抗样本是通过在数据集的样例上施加微妙但故意最坏的修改而形成的，导致模型给出与原始样例不同的答案。这篇论文中，对抗样本是以一种完全相反的方式形成的，与原始样例相比有显著差异，但仍导致相同的结果。", "innovation": "提出了新的算法来生成这种对抗样本，包括NI-FGSM (负迭代快速梯度符号方法) 和NI-FGM (负迭代快速梯度方法)，以及它们的动量变体NMI-FGSM (负动量迭代快速梯度符号方法) 和NMI-FGM (负动量迭代快速梯度方法)。通过这些方法构建的对抗样本有可能在某些情况下用于攻击机器学习系统。此外，结果显示对抗样本不仅分布在数据集样例的邻域中，而是广泛分布在样本空间中。", "conclusion": "通过提出的负迭代快速梯度方法及其动量变体，能生成与原始样例有显著差异但仍导致相同结果的对抗样本。这些对抗样本不仅局限于数据集样例的邻域，而是广泛分布在样本空间中，体现出对抗样本的新形式，这一发现有助于更深入地理解对抗样本的特性。"}
{"llm_update_time": "20251023", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.19345", "html_url": "https://arxiv.org/abs/2510.19345", "title": "基础模型预测: 形式与功能", "title_en": "Foundation Model Forecasts: Form and Function", "authors": "Alvaro Perez-Diaz,James C. Loach,Danielle E. Toutoungi,Lee Middleton", "background": "时间序列基础模型（TSFMs）在预测准确性方面表现出色，但准确性并非决定其实用价值的唯一因素。预测的形式（点预测、分位数预测、参数预测或轨迹集合）从根本上限制了它能支持的操作任务。研究表明，三分之二的TSFMs产出仅是点预测或参数预测，而许多实际操作任务需要保留时间依赖性的轨迹集合预测。研究进一步探讨了不同预测类型的转换条件及其在实际操作中的适用性，揭示了仅依靠边缘分布无法判断路径依赖事件概率的问题。因此，需要构建一个任务对齐的评价框架来评估不同类型的预测。", "innovation": "研究为六个基本预测任务定义了最小必要预测类型，并提出了一个任务对齐的评估框架，揭示了预测类型而非预测准确性在区分实际应用价值方面的重要性。特别是，研究证明了通过边际化转换轨迹集合预测时无需其他假设，但将其转换为更简单形式则需要通过柯普拉或校准方法来假设时间依赖性。同时，强调了单一边际分布无法唯一确定路径依赖事件的概率。这为理解预测形式对实际操作任务的支持范围提供了新的视角，有助于改进模型的开发和应用。", "conclusion": "我们的分析表明，在考虑预测类型时，不能只是关注预测准确性，而是要考虑到预测类型如何影响实际操作任务的执行。这意味着在预测建模时要考虑预测的形式及其对实际任务的支持情况，从而提高模型的实际应用价值。"}
{"llm_update_time": "20251023", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.19351", "html_url": "https://arxiv.org/abs/2510.19351", "title": "使用有限示范学习将决策推迟到人群中", "title_en": "Learning To Defer To A Population With Limited Demonstrations", "authors": "Nilesh Ramgolam,Gustavo Carneiro,Hsiang-Ting(Tim)Chen", "background": "本文解决了阻碍学习推迟（L2D）系统实际部署到普通人群中的关键数据稀缺问题。现有的L2D系统需要大量数据进行训练，但在实际应用中，这类数据往往难以获取。", "innovation": "本文提出了一种基于元学习的半监督框架，能够仅从少数几个示范中生成专家特定的嵌入，用于生成大规模的伪标签进行训练，并在测试时实现对新专家的即时适应。实验结果表明，基于这些合成标签训练的模型可以迅速达到最佳性能，证明了该方法的数据效率。", "conclusion": "通过解决关键的训练瓶颈，本文使适应性L2D系统更加实用和可扩展，为实际环境中的人类-AI协作铺平了道路。为了促进可重复研究并解决主文中未涵盖的实施细节，我们提供了源代码和训练配置。"}
{"llm_update_time": "20251023", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.19358", "html_url": "https://arxiv.org/abs/2510.19358", "title": "M3-SLU: 评估多模态大型语言模型中的说话者归属推理", "title_en": "M3-SLU: Evaluating Speaker-Attributed Reasoning in Multimodal Large Language Models", "authors": "Yejin Kwon,Taewoo Kang,Hyunsoo Yoon,Changouk Kim", "background": "尽管最近的模型在语音和文本理解方面表现出色，但在处理多说话人、多轮对话的理解方面仍然存在困难，特别是在理解谁在何时说了什么方面表现出色。现有的模型难以理解自然对话中的说话者归属推理能力。", "innovation": "提出了M3-SLU，这是一个新的多模态大型语言模型基准，用于评估多说话人、多轮次的口头语言理解。它由四个公开的数据集（CHiME-6，MELD，MultiDialog和AMI）构成，包含超过12,000个经过验证的一组音频、转录和元数据，包含两种任务：说话者归属问题回答和基于话语匹配的说话者归属。", "conclusion": "研究结果表明，模型可以理解说话内容，但难以识别说话者。M3-SLU提供了一个具有挑战性的基准，有助于推动说话者意识的多模态理解研究。"}
{"llm_update_time": "20251023", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.19365", "html_url": "https://arxiv.org/abs/2510.19365", "title": "大规模法律嵌入基准（MLEB）", "title_en": "The Massive Legal Embedding Benchmark (MLEB)", "authors": "Umar Butler,Abdur-Rahman Butler,Adrian Lucas Malec", "background": "目前开源法律信息检索领域缺乏一个涵盖广泛司法辖区、文件类型和任务类型的基准。现有数据集在这些方面存在空白，影响了系统的全面测试和比较。因此，需要一个新的基准来填补这些空白，以促进法律信息检索领域的发展和进步。", "innovation": "MLEB 是迄今为止规模最大的、最多样化和最全面的开源法律信息检索基准。它包括十个由专家注释的数据集，涵盖多个司法辖区（美国、英国、欧盟、澳大利亚、爱尔兰和新加坡）、文件类型（案例、立法、监管指导、合同和文献）以及任务类型（搜索、零样本分类和问答）。七个数据集是新构建的，旨在填补开源法律信息检索空间中的领域和司法辖区缺口。该基准详细记录了构建方法并公开发布代码、结果和数据，以实现可重复评估。", "conclusion": "MLBE 提供了一个全面的平台来彻底检验和改进法律信息检索系统。通过公开其方法、结果和数据，MLBE 促进了该领域研究人员之间的交流和研究进步，有助于提高法律信息检索系统的性能和可靠性。"}
{"llm_update_time": "20251023", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.19361", "html_url": "https://arxiv.org/abs/2510.19361", "title": "AgenticMath: 基于代理机制的数学数据生成增强LLM推理", "title_en": "AgenticMath: Enhancing LLM Reasoning via Agentic-based Math Data Generation", "authors": "Xianyang Liu,Yilin Liu,Shuai Wang,Hao Cheng,Andrew Estornell,Yuzhi Zhao,Jiaheng Wei", "background": "创建高质量的数据集以提高大型语言模型（LLM）的推理能力仍然是一个重大挑战，当前的方法往往导致生成低质量或不正确的答案，并且数据源中的信息丰富度有限。这些问题限制了大型语言模型在数学推理任务上的表现。", "innovation": "提出一种新的基于代理机制的数学问题-答案生成管道AgenticMath，该管道包含四个阶段：(1) 种子问题筛选，选择具有高信息丰富度、复杂性和清晰度的问题；(2) 代理式问题重述，利用多代理系统生成多样、逻辑一致的重述；(3) 答案增强，使用链式推理重新阐述答案，提高数值和逻辑正确性，不依赖于人工提供的标签；(4) 最终问题和答案评估，仅保留最优秀的成对问题和答案。实验表明，使用AgenticMath生成的数据集（仅包含30-60K数学样本）对3B-8B参数的LLM进行微调，能够实现与基于大量数据（例如400K或2.3M样本）训练的基线模型相当甚至更好的数学推理基准效果。", "conclusion": "我们的工作证明，目标导向的高质量数据生成是提高LLM数学推理能力的更有效途径，而不是依赖于大规模、低质量的数据集。"}
{"llm_update_time": "20251023", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.19414", "html_url": "https://arxiv.org/abs/2510.19414", "title": "EchoFake：一种针对实际应用的回放感知语音换脸检测数据集", "title_en": "EchoFake: A Replay-Aware Dataset for Practical Speech Deepfake Detection", "authors": "Tong Zhang,Yihuan Huang,Yanzhen Ren", "background": "语音换脸（Deepfakes）技术的日益普及引发了严重关切，尤其是在电话诈骗和身份盗用等现实场景中。尽管许多反欺骗系统在实验室生成的合成语音上取得了令人鼓舞的性能，但在面对常见的低成本物理重播攻击时，它们往往失效。我们实验表明，基于现有数据集训练的模型在评估重播音频时表现出严重的性能下降，平均准确性降至59.6%。", "innovation": "我们提出了EchoFake，一个广泛的数据集，包含超过120小时的来自超过13,000名说话者的音频，涵盖了最新的零样本文本合成语音（TTS）语音和在不同设备和真实环境条件下收集的物理重播录音。此外，我们评估了三种基线检测模型，并表明基于EchoFake训练的模型在各个数据集上都获得了较低的平均错误检测率（EER），表明有更好的泛化能力。", "conclusion": "通过引入更多的实用挑战，这些挑战更符合实际部署，EchoFake为推进欺骗检测方法的进展提供了一个更现实的基础。"}
{"llm_update_time": "20251023", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.19386", "html_url": "https://arxiv.org/abs/2510.19386", "title": "ColorAgent: 构建一个稳健、个性化且互动的操作系统代理", "title_en": "ColorAgent: Building A Robust, Personalized, and Interactive OS Agent", "authors": "Ning Li,Qiqiang Lin,Zheng Wu,Xiaoyun Mo,Weiming Zhang,Yin Zhao,Xiangmou Qu,Jiamu Zhou,Jun Wang,Congmin Zheng,Yuanyi Song,Hongjiang Chen,Heyuan Huang,Jihong Wang,Jiaxin Yin,Jingwei Yu,Junwei Liao,Qiuying Peng,Xingyu Lou,Jun Wang,Weiwen Liu,Zhuosheng Zhang,Weinan Zhang", "background": "随着硬件、软件和大规模语言模型技术的进步，人类与操作系统的交互从命令行界面演变为快速兴起的AI代理交互。开发能够执行用户指令并忠实遵循用户愿望的操作系统（OS）代理正逐渐成为可能。本文中，作者介绍了一种名为ColorAgent的操作系统代理，能够在长时间范围内与环境进行稳健的交互，并促进个性化的主动用户交互。为了支持长时间交互，作者通过逐步强化学习和自我演化训练增强了模型的能力，并开发了一个专门的多代理框架以确保通用性、一致性和鲁棒性。在用户交互方面，作者探索了个性化用户意图识别和主动参与，将OS代理置于自动化工具之外，作为温暖的合作伙伴。作者在AndroidWorld和AndroidLab基准上评估了ColorAgent，获得了77.2%和50.7%的成效率，建立了新的领先水平。尽管如此，作者认为当前基准测试不足以全面评估操作系统的代理，并提出了未来工作中的评估范式、代理协作和安全性的探索方向。", "innovation": "通过逐步强化学习和自我演化训练增强了模型的能力，开发了专门的多代理框架以确保通用性、一致性和鲁棒性，探索了个性化用户意图识别和主动参与。", "conclusion": "ColorAgent在AndroidWorld和AndroidLab基准上实现了77.2%和50.7%的成功率，比现有水平有显著提升。尽管取得了显著成果，但作者指出当前基准测试的局限性，提出应进一步探索评估范式、代理协作和安全性等方面的研究方向。"}
{"llm_update_time": "20251023", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.19410", "html_url": "https://arxiv.org/abs/2510.19410", "title": "ToMMeR -- 大型语言模型中高效实体提及检测", "title_en": "ToMMeR -- Efficient Entity Mention Detection from Large Language Models", "authors": "Victor Morand,Nadi Tomeh,Josiane Mothe,Benjamin Piwowarski", "background": "实体提及检测（mention detection）是信息抽取的基础，并且是一个已知的性能瓶颈。这项任务涉及识别哪些文本片段对应于实体，这对于从文本中提取信息至关重要，同时在一定条件下也是一个挑战性的任务。现有的大多数方法依赖于复杂的模型，但却不能高效地解决这个问题。该研究旨在探索使用语言模型早期层来实现高效、准确的实体提及检测的方法。", "innovation": "提出了一个轻量级的模型（参数少于30万）——ToMMeR，它能够从大型语言模型初期层中探测实体提及的能力。ToMMeR在13个实体识别（NER）基准测试中实现了93%的零样本召回率和超过90%的精度，表明即使在高召回率条件下，ToMMeR也很少会产生虚假的预测。此外，通过对不同模型的分析，证明了不同架构的模型（参数量从14M到15B）在提及边界检测上的结果具有一致性，这揭示了实体提及检测可以在语言模型早期自然出现。最终，在加入跨度分类头后，ToMMeR性能接近最先进的NER系统，展现出在小型参数中恢复结构化实体表示的能力。", "conclusion": "该研究提供了证据，表明结构化的实体表示存在于早期转换器层中，并且可以使用少量参数高效地恢复。通过引入ToMMeR，研究者展示了轻量级模型在高效实体提及检测中的潜力。"}
{"llm_update_time": "20251023", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.19420", "html_url": "https://arxiv.org/abs/2510.19420", "title": "通过节点评估监测基于大语言模型的多agent系统免受篡改", "title_en": "Monitoring LLM-based Multi-Agent Systems Against Corruptions via Node Evaluation", "authors": "Chengcan Wu,Zhixin Zhang,Mingqian Xu,Zeming Wei,Meng Sun", "background": "基于大型语言模型（LLM）的多agent系统（MAS）已成为人工智能应用的热门模式。然而，MAS在信任问题上仍面临关键挑战。由于MAS中包含更为复杂的通信过程，使其容易受到攻击。不同于单一agent系统在面对此类挑战时已有的防御机制，这些机制大多侧重于静态图的防御，要么试图在固定图结构中检测攻击，要么优化具有特定防御能力的静态拓扑，本文旨在解决这一局限，提出一种动态防御的MAS图结构范式。该方法持续监测MAS图内的通信，动态调整图拓扑，准确地干扰恶意通信，有效地抵御不断变化和多样化攻击。", "innovation": "本文提出了一种动态防御的MAS图结构范式，持续监测MAS图内的通信并动态调整图拓扑，准确地干扰恶意通信，有效抵御变化的动态攻击。这种方法在愈加复杂和动态的MAS环境中表现出色，显著优于现有的MAS防御机制，为推动其信赖的应用提供了有效的手段。", "conclusion": "实验结果表明，本文的方法在复杂和动态的MAS环境中表现出色，显著优于现有的MAS防御机制，为MAS的信任应用提供了有效的防护措施。"}
{"llm_update_time": "20251023", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.19425", "html_url": "https://arxiv.org/abs/2510.19425", "title": "Neural Variational Dropout Processes", "title_en": "Neural Variational Dropout Processes", "authors": "Insu Jeon,Youngjin Park,Gunhee Kim", "background": "对于鲁棒元学习而言，学习条件后验模型是一个关键步骤。现有元学习方法通常面临模型泛化能力不足和处理功能模糊性及不确定性时表现不佳的问题。", "innovation": "本文提出了一种新的贝叶斯元学习方法——神经变量丢弃过程（NVDPs），该方法通过任务特定的丢弃率来建模条件后验分布。NVDPs通过低秩伯努利专家元模型实现了一种节省内存的从少量观察上下文到丢弃率的映射方式，从而可以快速重新配置一个全局学习和共享的神经网络以适应新的任务。此外，NVDPs利用一种新型基于整个任务数据的先验，在保 amortized 变分推断中优化条件 dropout 后验。这项创新使得 NVDPs 能够稳健地近似任务特定的 dropout 率，从而可以处理广泛的函数不确定性。", "conclusion": "团队将提出的 NVDPs 方法与其他元学习方法在少量样本学习任务中进行了比较，包括 1D 随机回归、图像修复和分类任务。结果表明，NVDPs 的表现非常出色。"}
{"llm_update_time": "20251023", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.19421", "html_url": "https://arxiv.org/abs/2510.19421", "title": "公平之网：通过对比条件LoRA实现无需性能损失的动态公平性矫正", "title_en": "FairNet: Dynamic Fairness Correction without Performance Loss via Contrastive Conditional LoRA", "authors": "Songqi Zhou,Zeyuan Liu,Benben Jiang", "background": "确保机器学习模型的公平性是一个关键挑战。现有的去偏方法通常会牺牲性能，依赖静态的校正策略，并且难以处理数据稀疏问题，尤其是在少数群体中。此外，它们利用敏感属性的方式往往不够理想，要么过度依赖完整的属性标注，要么完全忽视这些属性。", "innovation": "为了解决这些限制，我们提出了FairNet，一种创新的动态、实例级别的公平性矫正框架。FairNet结合了一个偏置检测器和条件低秩适应（LoRA），仅在检测到有偏样本时激活公平性矫正机制，从而保留未偏样本的性能。其关键贡献是一个新的对比损失函数，用于训练LoRA模块，专门设计用于减少不同敏感群体内的类别表示不平等，并有效解决少数群体中的欠拟合问题。FairNet框架可以灵活处理完整、部分或完全缺乏敏感属性标签的情况。理论分析表明，在偏置检测器的中等TPR/FPR条件下，FairNet可以在不损害整体性能的前提下提升最差群体的性能，甚至可能带来轻微的性能提升。全面的实证评估表明FairNet在各种视觉和语言基准数据集上的有效性。", "conclusion": "FairNet框架成功地实现了无需性能损失的公平性矫正，并且能够在各种场景中灵活处理敏感属性标签的情况。理论和实证研究验证了其有效性和稳健性，为解决机器学习模型的公平性问题提供了新的解决方案。"}
{"llm_update_time": "20251023", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.19476", "html_url": "https://arxiv.org/abs/2510.19476", "title": "基于链式思考监控的安全案例实施路径", "title_en": "A Concrete Roadmap towards Safety Cases based on Chain-of-Thought Monitoring", "authors": "Julian Schulz", "background": "随着人工智能系统的功能接近危险水平，当前的安全案例分析变得不再足够。为了确保这些系统的安全性，论文提出了一个新的监控方案，即基于链式思考（CoT）监测的安全案例构建设想。", "innovation": "本文提出了一个基于CoT监测的安全案例构建框架，包括两个部分：第一，证明模型在没有CoT的情况下不具备危险功能；第二，确保证CoT能够检测到任何由CoT启用的危险功能。此外，作者还系统地分析了监控可能受到的两类威胁，并探讨了保持CoT忠实度的技术。对于不可监控的推理情况，提出了一种从非可监控的CoT中提取可监控CoT的方法。", "conclusion": "为了评估基于CoT监测的安全案例的可能性，建立了预测市场来整合关键技术里程碑对其可行性的预测。"}
{"llm_update_time": "20251023", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.19470", "html_url": "https://arxiv.org/abs/2510.19470", "title": "HybridEP: 在跨数据中心场景下通过混合专家/数据传输扩展专家并行性", "title_en": "HybridEP: Scaling Expert Parallelism to Cross-Datacenter Scenario via Hybrid Expert/Data Transmission", "authors": "Weihao Yang,Hao Huang,Donglei Wu,Ningke Li,Yanqi Pan,Qiyang Zheng,Wen Xia,Shiyi Li,Qiang Wang", "background": "Mixture-of-Experts (MoE) 架构因其能扩展大规模模型而变得流行。然而，单个数据中心（DC）内的模型训练无法满足快速增长的需求，正在转向更灵活的跨数据中心训练模式。在这种情况下，MoE架构下的专家并行性（EP）面临着带宽受限下的扩展性问题，现有的EP优化方法难以在低带宽环境下有效，因为数据通信的时间远长于并行计算的时间。", "innovation": "本文提出了一种名为HybridEP的建模引导框架，它通过动态调整专家空间布局来减少数据通信量和频率，从而最小化EP的通信开销。HybridEP通过构建基于流的模型来确定最优传输比例，它还包括基于领域划分的技术构造混合模式下的特定通信拓扑，以及参数高效迁移技术进一步优化这一拓扑，减少专家传输开销并扩大领域规模。实验结果表明，在带宽受限的情况下，HybridEP在性能上比现有最先进的MoE训练系统高5.6倍。此外，HybridEP在大规模模拟中实现了高达1.45倍的速度提升。", "conclusion": "HybridEP提供了一种更通用的EP扩展方案，能够更好地解决跨数据中心的扩展性问题。"}
{"llm_update_time": "20251023", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.19484", "html_url": "https://arxiv.org/abs/2510.19484", "title": "KnowMol: 通过多级化学知识推进分子大型语言模型", "title_en": "KnowMol: Advancing Molecular Large Language Models with Multi-Level Chemical Knowledge", "authors": "Zaifei Yang,Hong Chang,Ruibing Hou,Shiguang Shan,Xilin Chen", "background": "分子大型语言模型因其在分子应用方面的巨大潜力而受到广泛关注。然而，当前的分子大型语言模型在理解分子方面存在明显限制，原因是缺乏充分的文字描述和预训练过程中不太理想的分子表示策略。", "innovation": "该研究引入了包含10万个细粒度分子注释的KnowMol-100K大规模数据集，连接了分子和文字描述之间的差距，并提出了一种化学信息性的分子表示方法，有效解决了现有分子表示策略的局限性。基于这些创新，开发了KnowMol，这是一个最先进的多模态分子大型语言模型。", "conclusion": "广泛的实验表明，KnowMol 在分子理解与生成任务中表现出色。"}
{"llm_update_time": "20251023", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.19479", "html_url": "https://arxiv.org/abs/2510.19479", "title": "Graph Unlearning Meets Influence-aware Negative Preference Optimization", "title_en": "Graph Unlearning Meets Influence-aware Negative Preference Optimization", "authors": "Qiang Chen,Zhongze Wu,Ang He,Xi Lin,Shuo Jiang,Shan You,Chang Xu,Yi Chen,Xiu Su", "background": "近期，图去学习模型通过保持节点表示基本不变和在遗忘集中使用梯度上升来增强模型的实用性。然而，这种方法在去学习过程中因为梯度上升的快速发散速度，会导致模型的实用性大幅下降。", "innovation": "本文引入了INPO（Influence-aware Negative Preference Optimization，具影响力的负偏好优化）框架，该框架旨在减慢发散速度并提高模型实用性的鲁棒性。具体来说，该框架首先分析了NPO具有较慢的发散速度，并理论地提出去学习高影响力的边可以减轻学影响。此外，设计了一种具影响力的信件函数以放大已遗忘边的影响并缓解遗忘集与保留集之间的紧密拓扑耦合。通过移除基估计每条边的影响，并从拓扑学的角度提出了拓扑熵损失以在去学习过程中避免局部结构中过度信息丢失。", "conclusion": "在五个真实世界数据集上进行的大量实验数据显示，基于INPO的模型在所有遗忘质量指标上实现了最先进的性能，同时保持了模型的实用性。代码可在指定网址获取。"}
{"llm_update_time": "20251023", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.19496", "html_url": "https://arxiv.org/abs/2510.19496", "title": "CARES: Context-Aware Resolution Selector for VLMs", "title_en": "CARES: Context-Aware Resolution Selector for VLMs", "authors": "Moshe Kimhi,Nimrod Shabtay,Raja Giryes,Chaim Baskin,Eli Schwartz", "background": "现有的视觉语言模型（VLMs）通常处理图像以保持其在多种任务上的有效性，但通常会处理原生或高分辨率的图像，导致视觉tokens占总tokens的97-99%，从而增加了计算量和延迟，即使低分辨率图像已经足够使用。", "innovation": "引入了CARES (Context-Aware Resolution Selector)，这是一种轻量级的预处理模块，可以根据图像-查询对预测最小的必要输入分辨率，以减少计算量，同时保持任务性能。", "conclusion": "CARES在五个包含文档和自然图像等多种基准测试上，在不同目标VLM的情况下，能够保持任务性能的同时，将计算量最多减少80%。"}
{"llm_update_time": "20251023", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.19488", "html_url": "https://arxiv.org/abs/2510.19488", "title": "VideoAgentTrek：从未标注视频进行计算机使用预训练", "title_en": "VideoAgentTrek: Computer Use Pretraining from Unlabeled Videos", "authors": "Dunjie Lu,Yiheng Xu,Junli Wang,Haoyuan Wu,Xinyuan Wang,Zekun Wang,Junlin Yang,Hongjin Su,Jixuan Chen,Junda Chen,Yuchen Mao,Jingren Zhou,Junyang Lin,Binyuan Hui,Tao Yu", "background": "训练计算机使用代理需要大量的GUI交互数据，但大规模手动标注动作轨迹的成本非常昂贵。因此，需要一种规模化的解决方案来自动从公开的屏幕录制视频中提取训练数据，以替代手动标注。", "innovation": "提出了VideoAgentTrek，这是一种可扩展的管道，可以从网络规模的公开屏幕录制视频中自动挖掘训练数据，取消了手动标注的需要。开发了Video2Action，一个逆向动力学模块（IDM），包括视频接地模型和动作内容识别器，用于精确检测和识别GUI动作以及提取高精度的结构参数。", "conclusion": "该管道在YouTube教程视频上生成了152万自动化的交互步骤。通过连续预训练和监督微调，该方法在OSWorld-Verified数据集上的任务成功率提高了70%，在AgentNetBench上的步骤精度提高了9.2%。结果表明，被动互联网视频可以转化为高质量的计算机使用代理监督数据，提供了一种替代昂贵的手动标注的可扩展方法。"}
{"llm_update_time": "20251023", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.19495", "html_url": "https://arxiv.org/abs/2510.19495", "title": "通过离线强化学习增强借助非专家数据的模仿学习", "title_en": "Using Non-Expert Data to Robustify Imitation Learning via Offline Reinforcement Learning", "authors": "Kevin Huang,Rosario Scalise,Cleah Winston,Ayush Agrawal,Yunchu Zhang,Rohan Baijal,Markus Grotz,Byron Boots,Benjamin Burchfiel,Hongkai Dai,Masha Itkina,Paarth Shah,Abhishek Gupta", "background": "模仿学习已被证明对训练机器人从事复杂任务的有效，但它依赖于高质量的任务特定数据，限制了对实际世界中对象配置和场景多样性的适应性。相比之下，非专家数据（如娱乐数据、次优化演示、部分任务完成或次优化策略的推断）可以提供更广泛的覆盖范围和更低的收集成本。然而，传统的模仿学习方法无法有效利用这些数据。", "innovation": "本文提出了利用离线强化学习来利用非专家数据以增强模仿学习策略的性能。研究发现，虽然标准的离线强化学习方法在稀疏数据覆盖情况下难以有效利用非专家数据，但简单的算法修改可以允许利用这类数据，而不需要大量额外的假设。本文方法表明，通过扩大策略分布的支持范围，模仿算法结合离线强化学习可以在各种初始条件下稳健地解决任务，表现出了显著增强的恢复和泛化行为。", "conclusion": "在操控任务中，这些创新显著增加了在结合非专家数据时成功执行的学习策略的初始条件范围。此外，这些方法能够利用所有收集的数据，包括不完整或次优化的演示，来增强任务导向策略的性能。这突显了在机器人中使用非专家数据进行稳健策略学习的算法技术的重要性。"}
{"llm_update_time": "20251023", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.19530", "html_url": "https://arxiv.org/abs/2510.19530", "title": "未知优化：带有能量基于模型和强化学习的黑盒贝叶斯优化", "title_en": "Optimizing the Unknown: Black Box Bayesian Optimization with Energy-Based Model and Reinforcement Learning", "authors": "Ruiyao Miao,Junren Xiao,Shiya Tsang,Hui Xiong,Yingnian Wu", "background": "现有的贝叶斯优化（BO）方法通常会权衡探索和利用来优化昂贵的目标函数。然而，这些方法常常遭受单步偏差的显著影响，这可能导致向局部最优值收敛，特别是在复杂或高维任务中表现不佳。近年来，黑盒优化（BBO）在各种科学和工程领域取得了成功，尤其是在函数评估昂贵且无法获取梯度的情况下。", "innovation": "本文提出了结合高斯过程（GP）进行局部引导和能量基于模型（EBM）来捕捉全局结构信息的强化学习机制的贝叶斯优化方法（REBMBO）。具体来说，作者将贝叶斯优化的迭代定义为马尔可夫决策过程（MDP），并使用接近策略优化（PPO）进行自适应多步展望，动态调整探索的深度和方向，以克服传统BO方法的限制。", "conclusion": "我们进行了广泛的合成和真实基准测试，证实了REBMBO的优越性能。而且，在各种高斯过程配置下的额外分析进一步突显了其适应性和鲁棒性。"}
{"llm_update_time": "20251023", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.19497", "html_url": "https://arxiv.org/abs/2510.19497", "title": "在多式联运系统中使用生成代理建模真实人类行为：软件架构及在图卢兹的应用", "title_en": "Modeling realistic human behavior using generative agents in a multimodal transport system: Software architecture and Application to Toulouse", "authors": "Trung-Dung Vu,Benoit Gaudou,Kamaldeep Singh Oberoi", "background": "理解和预测人们在复杂多模式交通系统中的出行模式具有挑战性，尤其是在提出个性化交通解决方案时。本文提出了一种架构，用于在真实的多模式交通环境中建模真实的人类出行行为，通过在法国图卢兹进行的具体案例研究进行了展示。作者利用大型语言模型（LLM）建立在基于代理的仿真中，以捕捉真实城市环境下的决策过程。此框架结合了GAMA仿真平台和基于LLM的生成代理、GTFS公共交通数据和OpenTripPlanner多模式路由数据，对交通环境中生成代理进行建模。研究通过一个月的模拟时空，展示了生成代理不仅做出基于环境的交通决策，还形成了出行习惯，从而证明了将LLM与基于代理的仿真结合在智能交通系统和个性化多模态出行方案中的潜在用途。", "innovation": "该研究将大型语言模型（LLM）引入基于代理的交通仿真中，提出了一个框架，该框架结合了GAMA平台、基于LLM的生成代理、GTFS数据和OpenTripPlanner来模拟多模式交通系统中的人类行为决策。这种结合使得能够更专注于生成代理的开发及其在交通决策过程中的表现评估，并展示了生成代理不仅做出了环境感知的交通决策，还培养了出行习惯，证明了该方法在智能交通和个性化多模式交通解决方案方面的潜力。", "conclusion": "结合了大型语言模型和基于代理的仿真方法，为智能交通系统和个性化多模态移动解决方案开发提供了新的方向。同时也指出了该方法的一些局限性，并展望了未来工作，这些工作将集中在扩大该方法的适用范围、集成实时数据以及改进记忆模型等领域。"}
{"llm_update_time": "20251023", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.19535", "html_url": "https://arxiv.org/abs/2510.19535", "title": "对未知的洞察：分子数据的联邦数据多样性分析", "title_en": "Insights into the Unknown: Federated Data Diversity Analysis on Molecular Data", "authors": "Markus Bujotzek,Evelyn Trautmann,Calum Hand,Ian Hales", "background": "人工智能方法在制药药物发现中的应用越来越广泛，但其在工业中的应用仍然受到限制，主要是因为这些方法依赖于公共数据集，缺乏药企内部具有规模和多样性的专有数据。联邦学习（FL）为将私有数据集成到跨数据孤岛的隐私保护、协作模型训练中提供了一种有潜力的方法，但同时增加了诸如评估数据集多样性、进行知情数据拆分和理解合并的化学空间结构等数据驱动任务的复杂性。", "innovation": "本文研究了如何通过联邦聚类方法将分布式的分子数据进行区分和表示。通过基准测试了三种方法：联邦k-Means（Fed-kMeans）、联邦主成分分析结合联邦k-Means（Fed-PCA+Fed-kMeans）和联邦局部感知哈希（Fed-LSH），并使用了集中式方法进行对比。评价标准综合了传统数学指标和由本文引入的一种基于化学的知识评估指标SF-ICF。大规模基准测试与深度可解释性分析强调了使用基于化学知识的指标和在客户端进行可解释性分析对于联邦方法在分子数据上的多样性分析的重要性。", "conclusion": "大规模基准测试和深入的可解释性分析显示，整合化学领域的知识指标对于联邦数据多样性分析是重要的。联邦学习方法在分子数据上表现出良好的性能，并且需结合化学知识进行解释。"}
{"llm_update_time": "20251023", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.19514", "html_url": "https://arxiv.org/abs/2510.19514", "title": "从原型到稀疏心电图解释：多变量时间序列多类分类的SHAP驱动反事实解释", "title_en": "From Prototypes to Sparse ECG Explanations: SHAP-Driven Counterfactuals for Multivariate Time-Series Multi-class Classification", "authors": "Maciej Mozolewski,Betül Bayrak,Kerstin Bach,Grzegorz J. Nalepa", "background": "在可解释的人工智能(XAI)领域，时序数据的实例解释受到了广泛关注，尤其是在医疗健康领域，因其能够提供可行动且可解释的洞察。现有模型的解释性面临着挑战，本文提出了一种原型驱动框架，用于生成面向12导联心电图分类模型的稀疏反事实解释。该方法利用SHAP基线阈值识别关键信号段，并将其转换为区间规则；通过动态时间规整(DTW)和质心聚类提取代表性原型，并使这些原型在查询R峰时与解释样本保持一致。实验结果表明该框架能够在不修改原始信号78%的情况下保持各分类81.3%的解释有效性，并提高43%的时间稳定性。三种不同变体分别在心肌梗死、肥厚等分类任务中显示了良好的性能，但肥厚检测涵盖了13.2%的挑战。", "innovation": "本文提出了一个原型驱动框架，用于生成稀疏反事实解释，该框架利用SHAP基线阈值识别关键信号段，并将其转换为区间规则；通过DTW和质心聚类提取代表性原型，并使这些原型在查询R峰时与解释样本保持一致。这种方法能够在不大幅修改原始信号的前提下，生成具有高解释有效性和时间稳定性的反事实解释，尤其适用于临床诊断系统中的心电图解释。", "conclusion": "本文建立了一种生理意识的反事实解释设计原则，这为基于AI的诊断系统的解释界面提供了基础，并指出了用户可控解释界面在临床部署中的方向。"}
{"llm_update_time": "20251023", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.19559", "html_url": "https://arxiv.org/abs/2510.19559", "title": "时间的艺术：揭示视觉语言模型中的时间结构", "title_en": "A Matter of Time: Revealing the Structure of Time in Vision-Language Models", "authors": "Nidham Tekaya,Manuela Waldner,Matthias Zeppelzauer", "background": "大型的视觉-语言模型（VLMs），如CLIP，因其通用且表达性强的多模态表示而受到关注。通过利用大规模多样化的文本元数据进行训练，VLMs获得了开放词汇的能力，可以解决超出训练范围的任务。本文研究了VLMs的时间意识，评估了它们在时间定位视觉内容方面的能力。", "innovation": "本文介绍了名为TIME10k的新基准数据集，包含超过10,000张配有时间真实标注的图像，并开发了一种新型方法来评估37个VLMs的时间意识。研究发现，时间信息在VLM嵌入空间中以低维度非线性的结构存在。基于此洞见，本文提出了一种从嵌入空间中推导出明确“时间线”表示的方法。这种方法能够建模时间和其时间性发展，并可高效支持时间推理任务。其在时间推理任务上的表现与基于提示的基线相当甚至更优。", "conclusion": "本文的研究揭示了时间信息在VLM嵌入空间中的结构，并提出了一种有效的时间线表示方法。该方法在时间推理任务中表现优异，且计算效率高，相关代码和数据全部提供。"}
{"llm_update_time": "20251023", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.19585", "html_url": "https://arxiv.org/abs/2510.19585", "title": "使用大型语言模型检测历史书籍中的拉丁文：一个多模态基准", "title_en": "Detecting Latin in Historical Books with Large Language Models: A Multimodal Benchmark", "authors": "Yu Wu,Ke Shu,Jonas Fischer,Lidia Pivovarova,David Rosson,Eetu Mäkelä,Mikko Tolonen", "background": "本文提出了一项新颖的任务，即从混合语言的历史文档中提取变体布局的拉丁文字片段。文章基于包含724个标注页面的多模态数据集，对大型基础模型的性能进行了基准测试和评估。", "innovation": "研究表明，使用当代模型进行可靠拉丁文检测是可行的。本文是首次对这些模型在该任务中的能力及其限制进行全面分析。", "conclusion": "研究结果表明，借助现代模型实现可靠拉丁文检测是可行的。这项研究提供了对于大型基础模型在这样一个特定领域的能力和局限性的首次全面分析和评估。"}
{"llm_update_time": "20251023", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.19544", "html_url": "https://arxiv.org/abs/2510.19544", "title": "证明机器学习增强的蒙特卡洛方法在组合最优化中的实际优势", "title_en": "Demonstrating Real Advantage of Machine-Learning-Enhanced Monte Carlo for Combinatorial Optimization", "authors": "Luca Maria Del Bono,Federico Ricci-Tersenghi,Francesco Zamponi", "background": "组合优化问题是实际应用和优化方法发展中的核心问题。虽然经典的和量子的算法经过了长时间的完善，但机器学习辅助的方法相对最近才出现，并且尚未一致地优于简单的最先进的经典方法。此论文聚焦于一种特定的二次无约束二元优化（QUBO）问题：三维伊辛自旋玻璃中的最小能量配置问题。研究者利用了一个结合了标准局部移动和通过机器学习提出的全局移动的全局退火蒙特卡洛算法。实验表明局部移动对达到最优性能至关重要。与模拟退火和群体退火方法进行比较，证明了全局退火不仅超越了模拟退火的表现，而且在问题难度和系统规模上表现出更强的稳健性，无需调优超参数。迄今为止，这些结果提供了在组合优化中机器学习辅助优化方法可超越经典最先进的技术的首个明确且稳健的实证证据。", "innovation": "论文提出了一种结合机器学习和全局退火蒙特卡洛算法的新方法，特别适用于三维伊辛自旋玻璃中的最小能量配置问题。通过实验证实了局部移动在提升算法性能中的关键作用，并且展示了该算法在问题难度和系统规模上的高稳健性，无需额外调参，从而证明了机器学习辅助方法在组合优化中的实际优势", "conclusion": "研究成果提供了实证证据，证明机器学习辅助的优化方法可以在组合优化问题中超越经典最先进的技术。这种机器学习增强的方法在无需调参的情况下展示了更好的性能和更佳的稳健性，尤其是在处理难度较大的问题和较大的系统规模时。"}
{"llm_update_time": "20251023", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.19579", "html_url": "https://arxiv.org/abs/2510.19579", "title": "地球观测中的多模态协同学习：通过模态协作增强单模态模型", "title_en": "Multi-modal Co-learning for Earth Observation: Enhancing single-modality models via modality collaboration", "authors": "Francisco Mena,Dino Ienco,Cassio F. Dantas,Roberto Interdonato,Andreas Dengel", "background": "多模态协同学习（MCC）正在机器学习领域成为一种有效的范式，通过不同模态的协作学习，增强单一模态的预测能力。地球观测（EO）是最适合多模态数据分析的领域之一，多种遥感传感器搜集的数据可以感知我们的星球。然而，由于实际条件限制，训练和推理阶段无法获取相同的传感器模态，这带来了新的挑战。现有研究重点是为特定下游任务或特定Infere阶段可用的模态设计定制解决方案。本文针对这一问题，提出一种能够泛化到多个任务的多模态协同学习框架，结合对比学习和模态判别学习，指导单一模态模型将内部模型流形结构化为共享模态信息和特定模态信息。", "innovation": "本文提出了一种能够泛化到多个任务的多模态协同学习框架，结合对比学习和模态判别学习，指导单一模态模型将内部模型流形结构化为共享模态信息和特定模态信息。该框架在四个地球观测基准数据集上进行了评估，这些数据集覆盖了不同传感器模态下的分类和回归任务，训练时仅有一个模态数据可用，而推理时该模态不可用。实验结果表明，该方法在单一模态推理场景中的预测性能优于最新的机器学习和计算机视觉文献中的方法以及特定的地球观测方法。", "conclusion": "该研究验证了所提出的多模态协同学习框架在广泛地球观测应用中的有效性。在单一模态推理场景中，该框架能够利用训练阶段可用的大量传感器数据，显著提升单模态模型的预测性能。"}
{"llm_update_time": "20251023", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.19593", "html_url": "https://arxiv.org/abs/2510.19593", "title": "根因分析的目标驱动综述", "title_en": "A Goal-Driven Survey on Root Cause Analysis", "authors": "Aoyang Fang,Haowen Yang,Haoze Dong,Qisheng Lu,Junjielong Xu,Pinjia He", "background": "根因分析（RCA）在大规模云服务的事件管理中至关重要，但不同研究对RCA任务的定义和分类存在差异，因为“RCA”涵盖了具有不同目标的任务。以前的综述主要按输入数据类型（如基于指标的方法和基于追踪的方法）进行分类，这导致了不同目标的研究工作被分在同一组内，从而模糊了该领域的真正进展和空白。此外，RCA综述的受众主要是希望了解任务目标和整体框架的普通读者或希望理解相同任务定义下的先前研究的研究人员，因此，需要一个能根据其目标对相关文献进行分类和整合的目标驱动框架。已有研究大多忽略了基于目标的区别，未能充分组织文献并突出主题差异，这使得目标驱动的RCA综述显得尤为重要。", "innovation": "本文提出了一种目标驱动的框架，有效分类和整合了2014年至2025年间的135篇关于云事件管理中RCA的论文。除了目标驱动的分类，还讨论了所有RCA研究的最终目标，这是一个涵盖不同RCA形式的伞式覆盖，同时也讨论了RCA领域的开放挑战和未来方向。", "conclusion": "本文通过目标驱动的框架，系统性地分析了RCA在云事件管理中的应用，并讨论了RCA研究的开放问题和未来方向，这将有助于进一步推动这一领域的研究和发展。"}
{"llm_update_time": "20251023", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.19599", "html_url": "https://arxiv.org/abs/2510.19599", "title": "XBench: 在胸部放射影像中视觉-语言解释的全面基准", "title_en": "XBench: A Comprehensive Benchmark for Visual-Language Explanations in Chest Radiography", "authors": "Haozhe Luo,Shelley Zixin Shu,Ziyu Zhou,Sebastian Otalora,Mauricio Reyes", "background": "视觉语言模型（VLMs）在医学影像理解方面表现出色，但在其图文对接能力，即文本概念与视觉证据对齐的程度上仍有很多研究空白。在医学领域，可靠的文字与图像对接对于解释性和临床应用至关重要。本文研究了跨模态解释在胸部X光片上的表现，并提出了首个系统性的评测基准。", "innovation": "本文构建了首个系统性基准X-Bench，用于评估七个CLIP风格的VLM变体在胸片上的跨模态解释性能。通过使用跨注意力和相似度局部化图生成视觉解释，并定量评估这些解释与放射科医生标注区域的对齐程度。", "conclusion": "研究表明：所有VLM变体在大型且明确定义的病变中表现出良好的定位效果，但对于小型或弥漫性病灶，其表现急剧下降；专门预训练于胸片数据集的模型比通用数据集上预训练的模型表现更好；视觉识别能力和图文对接能力在模型中高度相关。这些发现突显了当前VLMs在临床可靠对接方面的不足，强调了在医疗实践中部署前需要专门的解释性基准研究。"}
{"llm_update_time": "20251023", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.19641", "html_url": "https://arxiv.org/abs/2510.19641", "title": "Style Attack Disguise：当字体成为对抗意图的伪装", "title_en": "Style Attack Disguise: When Fonts Become a Camouflage for Adversarial Intent", "authors": "Yangshijie Zhang,Xinda Wang,Jialin Liu,Wenqiang Wang,Zhicong Ma,Xingxing Jia", "background": "随着社交媒体的普及，用户在文本表达上使用个性化字体和类似字体的表情符号，虽然这种表达提高了文本的视觉吸引力并保持了可读性，但在自然语言处理(NLP)模型中引入了隐藏的安全隐患。具体而言，尽管人类能够轻松阅读这种风格化的文本，但模型却将其作为独立的字符单元进行处理，从而造成处理过程中的干扰。", "innovation": "本文提出了风格化攻击伪装(SAD, Style Attack Disguise)概念，这是一种基于字体风格的攻击方法。为了提高效率与效果，SAD设计了不同大小的攻击模式：一种适合查询效率的轻型模式，以及一种具有良好攻击性能的强化模式。实验证明，SAD可以有效影响传统模型、大语言模型(LLM)以及商业服务中的情感分类和机器翻译任务，并揭露了其对多模态任务（包括文本到图像和文本到语音生成）的潜在威胁。", "conclusion": "实验结果显示，SAD在各种任务中表现出强大的攻击效果。研究进一步表明，这种方法可能对包括文本到图像和文本到语音生成在内的多模态任务构成威胁。"}
{"llm_update_time": "20251023", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.19600", "html_url": "https://arxiv.org/abs/2510.19600", "title": "小于0.1美元的人工智能与人类协作论文页面构建", "title_en": "Human-Agent Collaborative Paper-to-Page Crafting for Under $0.1", "authors": "Qianli Ma,Siyu Wang,Yilin Chen,Yinhao Tang,Yixiang Yang,Chang Guo,Bingjie Gao,Zhening Xing,Yanan Sun,Zhipeng Zhang", "background": "科研工作中，研究结果的传播与发现本身同样重要。然而，构建项目网页以使密集的研究论文更具可访问性这一重复性任务往往阻碍了研究人员的进展。虽然已经开发出了一些自动化工具来处理静态演示文稿和海报，但构建动态且互动性的网页仍然是一项未解决的挑战。现有的自动化工具缺乏对研究论文的深入理解，因此难以生成高质量且具备可交互性的项目网页。", "innovation": "该研究重新审视了这一问题，提出了一个新的多智能体系统AutoPage，该系统采用了一个从粗到细的叙述规划到多模态内容生成和互动渲染的流程。AutoPage通过特定的“检查器”智能体来对抗AI的幻觉，此外还可设定人的检查点确保最终结果与作者的愿景完美一致。为了验证这一方法的有效性，作者还构建了一个新的基准测试平台PageBench。实验结果显示，使用AutoPage不仅能够生成高质量且视觉上吸引人的页面，而且在不到15分钟的时间内只需小于0.1美元的开销即可完成，成本效益高。", "conclusion": "AutoPage提供了一种有效且高效的方法来处理论文页面的构建，通过人机协作显著提高了生成过程中的效率和质量，为科研工作中的项目网页构建提供了一种新的解决方案。"}
{"llm_update_time": "20251023", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.19654", "html_url": "https://arxiv.org/abs/2510.19654", "title": "从预测到规划：基于策略的世界模型在协同状态-动作预测中的应用", "title_en": "From Forecasting to Planning: Policy World Model for Collaborative State-Action Prediction", "authors": "Zhida Zhao,Talas Fu,Yifan Wang,Lijun Wang,Huchuan Lu", "background": "当前，尽管在构建世界模型方面取得了显著进展，这些模型在自主系统中的潜力尚未充分挖掘：世界模型主要用于世界模拟，与轨迹规划脱钩。近期有研究试图在一个统一框架下结合世界模型和规划，但世界模型如何协同促进规划这一机制仍需进一步探索。", "innovation": "本文提出了一个新的驾驶范式，即策略世界模型（PWM），它在统一架构中结合了世界模型和轨迹规划，并通过所提出的无动作未来状态预测方案利用学习到的世界知识来改善规划。为了提高视频预测效率，引入了动态增强的并行令牌生成机制，配备上下文指导的令牌化器和自适应动态焦点损失。尽管仅使用前置摄像头输入，方法在性能上达到了或超过了依赖多视图和多模态输入的最新技术水平。", "conclusion": "通过协同状态-动作预测，PWM能够模拟人类的前瞻性感知，从而提供更可靠的规划性能。我们的方法展示了在仅使用前置摄像头输入的情况下，仍能与依赖多视图输入的最新技术相比肩或超越其性能。源代码和模型权重将发布在[此链接]。"}
{"llm_update_time": "20251023", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.19675", "html_url": "https://arxiv.org/abs/2510.19675", "title": "对受内存约束的微调训练动态的研究", "title_en": "Study of Training Dynamics for Memory-Constrained Fine-Tuning", "authors": "Aël Quélennec,Nour Hezbri,Pavlo Mozharovskyi,Van-Tam Nguyen,Enzo Tartaglione", "background": "随着深度神经网络模型日益增大，同时在部署环境中对资源有严格限制，对深度神经网络进行高效的内存训练变得尤为重要。传统方法在处理大模型时会受到资源限制的影响，导致训练效果不佳或无法完成训练。本文分析了在内存受限环境下训练深度神经网络的技术背景。", "innovation": "本文提出了一种名为TraDy的新颖传输学习方案，融合了两方面的创新：层的重要性对于更新的依赖性随架构而定，并可以通过提前确定的方法来判定；动态的随机信道选择在提供更优的梯度近似方面相较于静态方法更胜一筹。详细实验表明，TraDy在各类下游任务和架构上均达到了最先进的性能，同时严格保持内存限制。此外，TraDy实现了高达99%的激活稀疏性、95%的权重梯度稀疏性和97%的权重梯度计算FLOPs减少，验证了其高效性。", "conclusion": "通过使用TraDy方案，在受内存限制的环境下，能够有效地完成深度神经网络的训练，同时保证了模型的性能和计算效率，显著减少了计算资源的占用。"}
{"llm_update_time": "20251023", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.19668", "html_url": "https://arxiv.org/abs/2510.19668", "title": "使用预训练模型揭示情绪", "title_en": "Unraveling Emotions with Pre-Trained Models", "authors": "Alejandro Pajón-Sanmartín,Francisco De Arriba-Pérez,Silvia García-Méndez,Fátima Leal,Benedita Malheiro,Juan Carlos Burguillo-Rial", "background": "变压器模型在情感识别领域取得了显著进展，然而，在探索大语言模型（LLMs）的开放查询时仍存在诸多挑战。现有的模型虽然表现良好，但在开放文本中进行自动情感分析仍面临重大挑战，如语境模糊、语言变异性以及难以解读复杂的感情表达。这些限制使通用模型的直接应用变得困难。因此，本文将三种不同的场景下调优和提示工程在情感检测中的效果进行了比较：(i) 使用简单提示的微调预训练模型和通用 LLM 的性能；(ii) 各种情感提示设计在 LLM 上的效果；以及 (iii) 情感分组技术对这些模型的影响。\n本文通过实验证明，调优的预训练模型在情感识别上的效果可达到70%以上的指标。研究结果进一步强调，提示工程和情感分组对于提升LLMs的表现至关重要。这些进展有助于改善情感分析、人机交互以及各领域的用户行为理解。\n", "innovation": "本文将调优和提示工程在情感检测中的效果进行了比较，并特别关注不同场景下的表现差异。通过实验证明了调优预训练模型的优越性，并指出提示工程和情感分组是提升LLMs性能的关键。这些发现对情感分析、人机交互及用户行为的理解具有重要意义。\n", "conclusion": "研究表明，调优预训练模型在情感识别上的效果显著，达到了70%以上的指标。此外，LLMs需要结构化的提示工程和情感分组才能提高其性能。这些进步不仅改进了情感分析，还提升了人机交互质量和对用户行为的理解，具有广泛的应用前景。\n"}
{"llm_update_time": "20251023", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.19687", "html_url": "https://arxiv.org/abs/2510.19687", "title": "大型语言模型对沟通动机的敏感性如何？", "title_en": "Are Large Language Models Sensitive to the Motives Behind Communication?", "authors": "Addison J. Wu,Ryan Liu,Kerem Oktar,Theodore R. Sumers,Thomas L. Griffiths", "background": "人类沟通是有动机的，人们在沟通时总是带着特定的目的。大型语言模型（LLMs）和AI代理处理的人类信息包含了这些动机和激励。为了在现实世界中有效使用LLMs，它们需要像人类一样审视动机，评估信息的可靠性。本文研究了LLMs是否具有这种动机警觉的能力。通过认知科学的控制实验验证了LLMs的行为是否符合基于动机证据的学习合理模型，并发现它们在处理信息时像人类一样降低了有偏差来源的信息信任度。然后将评估扩展到受赞助的在线广告，发现LLMs的推理与合理模型的预言相差甚远。一项简单的干预措施可以显著提高LLMs与合理模型的一致性，这表明LLMs基本具备对他人动机的敏感性，但要将这种能力应用到新的现实世界环境中仍然需要进一步改进这些模型。", "innovation": "本文使用认知科学的控制实验验证了LLMs在处理与动机相关的信息时的行为模式，并将其应用到更现实的在线广告环境中，通过干预措施提高LLMs对动机警觉性。", "conclusion": "LLMs具有对他人动机的基本敏感性，但在新的现实世界情景中，还需要改进这类模型以更好地满足实际需求。"}
{"llm_update_time": "20251023", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.19685", "html_url": "https://arxiv.org/abs/2510.19685", "title": "指令性、元认知还是两者兼顾？不同类型的人工智能生成反馈对学生参与度、自信心和结果的比较", "title_en": "Directive, Metacognitive or a Blend of Both? A Comparison of AI-Generated Feedback Types on Student Engagement, Confidence, and Outcomes", "authors": "Omar Alsaiari,Nilufar Baghaei,Jason M. Lodge,Omid Noroozi,Dragan Gašević,Marie Boden,Hassan Khosravi", "background": "反馈是影响学生学习效果的重要手段，已有大量研究探讨了如何在教育环境中有效地实施反馈。近年来，人工智能（AI）生成反馈因其可扩展性和适应性逐渐成为趋势，两种主要的研究方法是指令性反馈和元认知反馈。指令性反馈通过提供明确解释来减少认知负担，加快学习速度；而元认知反馈则鼓励学生自我反思、追踪自己的进度并培养自我调节学习技能。尽管这两种方法都有其理论优势，但它们对学生参与度、自信心和学习成果的具体影响仍需进一步研究。", "innovation": "本研究通过一项为期一学期的随机对照试验，比较了329名学生在一门介绍性设计和编程课程中的指令性、元认知和混合AI生成反馈的效果。该研究采用自适应教育平台，使学生分别接受不同类型的反馈，并研究反馈类型对学生行为、自信心和学习成果的影响。", "conclusion": "研究结果表明，不同类型的反馈对学生的学习行为有所影响，混合型反馈引导学生进行更多的是修订行为。学生的自信心水平普遍较高，资源质量的结果在所有条件下均表现相近。这些结果强调了AI在平衡清晰度和反思的反馈中的潜力。特别是混合方法显示出了结合即时改进建议与自我反思和元认知成长的机会。"}
{"llm_update_time": "20251023", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.19692", "html_url": "https://arxiv.org/abs/2510.19692", "title": "超越代码的能动软件工程：框架愿景、价值观与词汇", "title_en": "Toward Agentic Software Engineering Beyond Code: Framing Vision, Values, and Vocabulary", "authors": "Rashina Hoda", "background": "能动人工智能（Agentic AI）正引发软件工程（SE）领域的范式转变。技术专家们正在努力使其成为现实，而软件工程研究人员也正推动建立能动软件工程作为研究领域。早期关于能动软件工程的愿景主要集中在编码活动上，但初步的实证证据表明，必须考虑广泛的社会和技术关切才能在实践中取得成功。", "innovation": "本文为能动软件工程社区的发展愿景做出了贡献，包括：（a）建议将其范围从代码扩展到“整体流程”视角，基于SE基础、演变及新兴能动软件工程框架；（b）提出一套初步的价值观和原则来指导努力；（c）分享设计/使用清晰术语的指导方针，以构建能动软件工程。这些思想旨在鼓励社区合作，并引导软件工程社区为能动软件工程奠定坚实的基石，使其不仅势在必行，而且有意识且可取。", "conclusion": "希望这些理念能够促进社区合作，并引导软件工程社区努力为能动软件工程奠定坚实的基础，使其在长期看来既是不可避免的，也是有意识且可取的。"}
{"llm_update_time": "20251023", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.19689", "html_url": "https://arxiv.org/abs/2510.19689", "title": "企业HR分析的无服务器GPU架构：一种生产规模的大数据即服务实现", "title_en": "Serverless GPU Architecture for Enterprise HR Analytics: A Production-Scale BDaaS Implementation", "authors": "Guilin Zhang,Wulan Guo,Ziqi Tan,Srinivas Vippagunta,Suchitra Raman,Shreeshankar Chatterjee,Ju Lin,Shang Liu,Mary Schladenhauffen,Jeffrey Luo,Hailong Jiang", "background": "工业和政府组织越来越依赖数据驱动的分析来处理劳动力、财务和监管决策过程，其中及时性、成本效率和合规性极为关键。分布式框架如Spark和Flink虽有效支持大规模批处理或流式分析，但引入了协调复杂性和审计开销，与中等规模、低延迟的推理需求不匹配。与此同时，云提供商现在提供了无服务器GPU，并且模型如TabNet能够提供解释性表的数据机器学习，促使新的符合监管环境的部署蓝图。", "innovation": "本文提出了一种面向生产的大数据即服务（BDaaS）蓝图，该蓝图将一个单节点无服务器GPU运行时与TabNet集成。该设计通过GPU加速提高吞吐量，通过无服务器弹性降低成本，并通过特征掩码解释性确保IL4/FIPS合规性。对比Spark和CPU基准，通过HR、Adult和BLS数据集的基准测试，GPU管道在1K推理成本上表现突出，具有4.5倍更高的吞吐量，98倍更低的低延迟，并且在合规机制下仅增加5.7毫秒延迟（p99 < 22毫秒），同时在峰值负载时保持解释性稳定，确保可靠审计。", "conclusion": "本研究提供了合规性意识基准、可复现的Helm打包蓝图以及决策框架，证明了在受监管的企业和政府环境中，安全的、可解释的和成本效益高的无服务器GPU分析的实用性。"}
{"llm_update_time": "20251023", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.19694", "html_url": "https://arxiv.org/abs/2510.19694", "title": "提示是否重塑表示吗？一种提示对嵌入影响的实证研究", "title_en": "Do Prompts Reshape Representations? An Empirical Study of Prompting Effects on Embeddings", "authors": "Cesar Gonzalez-Gutierrez,Dirk Hovy", "background": "提示是零-shot条件下利用大型语言模型（LMs）的常见方法。然而，LMs能够在没有特定任务监督的情况下执行多种任务的内部机制仍然不明确。研究提示与内部表示质量之间的关系有助于理解预训练嵌入如何支持在上下文任务解决。在这一实证研究中，我们对提示嵌入进行了系列探针实验，分析了零-shot分类的各种提示模板组合。研究发现，尽管提示会影响表示质量，但这些变化并不总是与提示的相关性一致。这结果挑战了更相关提示必然导致更好表示的假设。", "innovation": "研究揭示了提示与表示质量之间的关系，并发现提示的相关性不总是与表示质量一致，挑战了已有假设。此外，研究进一步分析可能导致这种意外行为的因素。", "conclusion": "本研究通过实证探索提示对内部表示的影响，发现提示的相关性与表示质量之间并不存在一致的相关性，挑战了相关提示必然导致更好表示的假设。对于提示设计者而言，设计提示时不能只依赖提示的相关性来评估其效果，还需要考虑其他可能影响表示质量的因素。"}
{"llm_update_time": "20251023", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.19752", "html_url": "https://arxiv.org/abs/2510.19752", "title": "在推理时学习能力：视觉-语言-行动模型", "title_en": "Learning Affordances at Inference-Time for Vision-Language-Action Models", "authors": "Ameesh Shah,William Chen,Adwait Godbole,Federico Mora,Sanjit A. Seshia,Sergey Levine", "background": "解决复杂的现实世界控制任务通常需要多次尝试：如果初次失败，我们反思错误的原因并相应改变策略以避免重复犯错。在机器人领域，视觉-语言-行动（VLA）模型提供了解决复杂控制任务的有前景的途径，但缺乏根据过去经验动态调整行为的能力。本研究旨在介绍一种新的方法：推理时学习（LITEN），该方法将VLA低级策略与一个高阶VLM结合，后者通过包含过去的经历作为上下文来对VLA的行为进行条件化，以学习其能力和应用范围。该方法在推理阶段生成并执行针对低级VLA的计划，并在评估阶段对其结果进行反思，从而得出有用的结论以纳入未来的推理环境中。", "innovation": "LITEN是一种新颖的方法，它结合了视觉-语言-行动模型（VLA）的低级策略和一个高阶VLM（视觉-语言模型），通过对过去的经历进行上下文整合来增强VLA的功能，从而使其能够学习低级策略的适用性和能力。LITEN的特点在于能够在行为失败时能够反思无结构的实时机器人轨迹（例如，原始视频），并且需要在评估过程中提供结构化的指导来帮助反思。", "conclusion": "实验结果表明，LITEN能够有效利用过去的经历，生成使用高适用性指令来完成长期任务的计划。"}
{"llm_update_time": "20251023", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.19767", "html_url": "https://arxiv.org/abs/2510.19767", "title": "SmartSwitch: 通过促进更深层次的思维探索来克服LLM思维不足从而推动其推理能力", "title_en": "SmartSwitch: Advancing LLM Reasoning by Overcoming Underthinking via Promoting Deeper Thought Exploration", "authors": "Xichen Zhang,Sitong Wu,Haoru Tan,Shaozuo Yu,Yinghao Zhu,Ziyi He,Jiaya Jia", "background": "大型语言模型在复杂推理任务中取得了突破，但伴随而来的是'浅思'问题，即模型频繁切换思路而缺乏充分探索的现象，这限制了其性能和标记效率。", "innovation": "提出了一个简单的实用推理策略——SmartSwitch推理框架，能够无缝集成到任何大型语言模型中，通过持续监控模型的推理过程来检测浅思并引导其深入探索被忽视但有潜力的思想。该框架包含感知模块和干预模块：感知模块通过预先训练的进程奖励模型评估前一个思想的可能性，如果发现有潜力的思想被匆忙放弃，则干预模块中断正在进行的推理，回溯到之前的切换点，并插入一个‘深化提示’以鼓励在此有希望的方向上进一步探索。", "conclusion": "在挑战性的数学推理基准上进行的大量实验表明，本方法显著提升了不同规模的大型语言模型的性能。"}
{"llm_update_time": "20251023", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.19678", "html_url": "https://arxiv.org/abs/2510.19678", "title": "我用我的模型之眼寻找：视觉搜索作为多模态大语言模型行为测试的方法", "title_en": "I Spy With My Model's Eye: Visual Search as a Behavioural Test for MLLMs", "authors": "John Burden,Jonathan Prunty,Ben Slater,Matthieu Tehenan,Greg Davis,Lucy Cheke", "background": "多模态大语言模型（MLLMs）在视觉语言任务中表现出强大的性能，但其视觉处理过程是不透明的。大多数黑盒评估仅衡量任务准确性，揭示的关于其内部机制的信息很少。受认知心理学启发，作者将经典的视觉搜索范式应用于MLLMs，以测试其是否展现出“跳变效应”，即能够独立于干扰物集中性检测显著视觉特征的人类感知特性。通过针对颜色、大小和照明特点的控制实验，发现先进的MLLMs在基于颜色或大小的分离（单一特征）搜索中表现出类似人类的跳变效应，并且在基于多个特征的组合（多重特征）搜索中存在能力限制。此外，发现MLLMs像人类一样将自然场景先验（如光照方向）整合到对象表征中。", "innovation": "作者引入了经典视觉搜索范式来评估MLLMs的视觉处理能力，特别是其是否具有“跳变效应”的特点，以及它们如何处理多种特征的组合搜索，展示了视觉搜索作为认知基础诊断工具评价MLLMs感知能力的潜力。通过具体的实验证据和针对特定功能的微调以及机制可解释性分析来支持研究发现，为评估和理解MLLMs的视觉感知能力提供了新的方法论。", "conclusion": "研究证明，视觉搜索可以作为认知基础的诊断工具，用于评估MLLMs的感知能力，展示了MLLMs在颜色或大小基于的分离搜索中表现出类似人类的跳变效应，并且在基于多个特征的组合搜索中存在能力限制，同时也表明MLLMs考虑了类似于人类的自然场景先验。"}
{"llm_update_time": "20251023", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.19779", "html_url": "https://arxiv.org/abs/2510.19779", "title": "AdaSPEC：高效推测解码器的选择性知识蒸馏", "title_en": "AdaSPEC: Selective Knowledge Distillation for Efficient Speculative Decoders", "authors": "Yuezhou Hu,Jiaxin Guo,Xinyu Feng,Tuo Zhao", "background": "推测解码（Speculative Decoding，SD）通过使用小型草案模型生成预测，然后由大型目标模型验证，来加快大型语言模型的推理速度。然而，传统的知识蒸馏（Knowledge Distillation，KD）方法在所有标记上最小化两个模型之间的KL散度，这一目标与SD的实际目标（最大化标记接受率）不一致。这导致草案模型由于容量限制无法充分吸收目标模型的知识，从而影响性能。", "innovation": "本文提出了一种名为AdaSPEC的新方法，该方法在知识蒸馏过程中引入了选择性的标记过滤。AdaSPEC使用参考模型来识别和过滤难以适应的标记，从而允许更好地将草案模型与目标模型在简单标记上对齐。这种方法提高了总体标记接受率，同时不牺牲生成质量，并且在包括算术推理、指令跟随、编程和总结在内的一系列任务中优于现有的DistillSpec方法，接受率普遍提高了15%以上.", "conclusion": "通过评估AdaSPEC在不同任务中的性能，研究结果表明，AdaSPEC方法能够一致地优于现有的DistillSpec方法，实现了所有任务上更高的标记接受率。该代码已在公共存储库中开源。"}
{"llm_update_time": "20251023", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.19792", "html_url": "https://arxiv.org/abs/2510.19792", "title": "受控改变：生成性人工智能对新闻专业权威的影响", "title_en": "On Controlled Change: Generative AI's Impact on Professional Authority in Journalism", "authors": "Tomás Dodds,Wang Ngai Yeung,Claudia Mellado,Mathias-Felipe de Lima-Santos", "background": "随着生成性人工智能工具和系统的使用，记者的产量可能会增加，新闻办公室的经济模型可能会改变，并进一步个性化受众的新闻消费习惯。自2022年发布以来，OpenAI的ChatGPT和其他大型语言模型已在新闻组织中引起了警觉，不仅仅是因为这些技术对新闻报道和事实核查带来的新挑战，还因为它们对记者专业权威的影响。本文探讨了荷兰媒体中的记者如何将人工智能技术整合到他们的日常工作流程中。通过13次对不同新闻机构和媒体公司的编辑、记者和创新管理人员的采访，本文提出了“受控改变”这一概念，并基于专业权威理论，认为记者以监督方式预见和整合这些技术，确定了三种主要的管理策略：开发适应性指南、实验性地探究AI技术的有效性和限制性评估AI系统的功能和局限性。这些行为旨在确保使用AI时符合道德规范并评估其所能提供的价值和局限性。", "innovation": "本文提出了“受控改变”这一概念，解释了记者如何通过制定适应性指南、实验性地探究AI技术的有效性以及评估AI系统的功能和局限性来管理AI技术的整合。该研究为新闻领域中如何适当地整合人工智能技术提供了一个新的理论框架和实践指导。", "conclusion": "本文基于对13名记者和创新管理者的采访，提出“受控改变”概念，阐述了记者在使用AI技术时的适应性策略，以确保其使用符合伦理规范并评估其有效性和限制性。这被认为是新闻专业权威在人工智能时代的重要性。"}
{"llm_update_time": "20251023", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.19799", "html_url": "https://arxiv.org/abs/2510.19799", "title": "透明模型、大语言模型与从业者参与循环集成：公共与非营利部门项目评估的一个案例", "title_en": "Integrating Transparent Models, LLMs, and Practitioner-in-the-Loop: A Case of Nonprofit Program Evaluation", "authors": "Ji Ma,Albert Casella", "background": "公共和非营利组织通常对采用AI工具有所犹豫，因为大多数模型都是不透明的，尽管标准方法通常分析汇总模式而非提供具体案例层面的指导。这项研究测试了一种从业者在环工作流，该工作流将透明的决策树模型与大语言模型（LLMs）配对，以提升预测准确性、可解释性和生成实用洞察。研究使用来自一项正在进行的大学成功计划的数据，构建可解释的决策树以揭示关键预测变量。然后向每个树的结构提供给LLM，使它能够以透明模型为基础生成具体的案例级预测。从业者在特征工程、模型设计、解释审查和可用性评估的每个阶段都参与其中，确保领域专业知识在分析的每一阶段都得到体现。", "innovation": "测试了一种从业者在环工作流，该工作流将透明的决策树模型与大语言模型（LLMs）配对，以提升预测准确性、可解释性和生成实用洞察。", "conclusion": "集成透明模型、LLMs和从业者输入能获得准确、可信且有操作性的案例级评估，为公共和非营利部门负责任地采用AI提供了一条可行途径。"}
{"llm_update_time": "20251023", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2505.14489", "html_url": "https://arxiv.org/abs/2505.14489", "title": "推理模型更好地表达其自信", "title_en": "Reasoning Models Better Express Their Confidence", "authors": "Dongkeun Yoon,Seungone Kim,Sohee Yang,Sunkyoung Kim,Soyeon Kim,Yongil Kim,Eunbi Choi,Yireun Kim,Minjoon Seo", "background": "大型语言模型（LLMs）虽然强大，但在传达自信度方面常常表现不佳，这使得评估它们何时可能出错变得困难，从而降低了它们的可靠性。", "innovation": "本文展示了带有扩展链式推理（CoT）推理能力的模型不仅在解决问题方面表现出色，还能更准确地表达其自信度。六个推理模型在六个数据集上表现出比非推理模型更出色的自信度校准，尤其是在CoT过程中表现出动态调整自信度的能力。", "conclusion": "推理模型的自信度校准随着CoT进程逐渐提高，而移除CoT中的缓慢思考行为会导致校准下降。此外，简单的引导非推理模型进行缓慢思考也能提高其自信度校准，表明缓慢思考行为是提高自信度校准的关键因素。"}
{"llm_update_time": "20251023", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.19818", "html_url": "https://arxiv.org/abs/2510.19818", "title": "语义世界模型", "title_en": "Semantic World Models", "authors": "Jacob Berg,Chuning Zhu,Yanda Bao,Ishan Durugkar,Abhishek Gupta", "background": "世界模型可以通过计划来增强机器人的控制。传统的做法是训练一个模型来预测未来的图像帧，给定当前的帧和动作，这种方法可以用于规划。然而，预测未来像素的目标往往与实际的规划目标相矛盾。强像素重建并不总是与好的规划决策有关联。因此，该研究提出，世界模型不需要重建未来的像素，而是只需预测与任务相关的未来语义信息。这种方法将世界建模视为关于未来帧语义信息的视觉问答问题，从而允许使用视觉语言模型的工具来解决此问题。", "innovation": "该研究将世界模型视为一个关于未来帧语义信息的视觉问答问题，利用视觉语言模型的工具进行训练，称为“语义”世界模型。这种方法通过监督微调过程来学习图像-动作-文本数据，能够为决策制定规划，同时继承预训练视觉语言模型的泛化和鲁棒性特性。", "conclusion": "研究表明，这种方法可以在开放的机器人任务中提升策略改进中的泛化性能，显著优于基于重建的动作条件化世界建模的标准范式。"}
{"llm_update_time": "20251023", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.19728", "html_url": "https://arxiv.org/abs/2510.19728", "title": "通过生成合成医学时间序列实现细粒度子组级模型评估", "title_en": "Enabling Granular Subgroup Level Model Evaluations by Generating Synthetic Medical Time Series", "authors": "Mahmoud Ibrahim,Bart Elen,Chang Sun,Gökhan Ertaylan,Michel Dumontier", "background": "研究提出了一个新的框架，用于利用合成ICU时间序列数据不仅进行模型训练，还能进行严格的和可信赖的评估，涵盖人口统计子组的预测模型。研究基于先前的扩散和VAE生成器（TimeDiff、HealthGen、TimeAutoDiff），引入了增强的TimeAutoDiff。该框架使用分布对齐惩罚来增强潜在扩散目标，通过MIMIC-III和eICU数据集中的24小时死亡率和二元住院时间任务，对所有模型进行了广泛测试。研究表明，增强的TimeAutoDiff将实际数据到合成数据与实际数据到实际数据的评估差距（TRTS差距）减少了70%以上，实现了\textdelta_{TRTS} \textless{}= 0.014 AUCROC，同时保持了训练效用（\textdelta_{TSTR} \textasciitilde 0.01）。对于32个交叉子组，大型合成队列将子组级别的AUC-ROC估计误差降低了50%以上，并在72%-84%的子组中优于小型真实测试集。这项工作提供了一条实用的、隐私保护的道路，使在危重病监护中的细粒度模型评估更加可信，有助于在不暴露敏感的EHR数据的情况下进行跨多元化患者群体的稳健和可靠的性能分析，从而增强医学AI的整体可信度。", "innovation": "提出了一种增强的TimeAutoDiff框架，该框架通过在潜在扩散目标中引入分布对齐惩罚来生成合成ICU时间序列数据，用于模型训练和评估。实验证明该方法显著减少了评估差距，并在多个具体子群体中提高了模型评估的准确性。", "conclusion": "这项工作提供了在危重病监护中进行细粒度模型评估的实用且隐私保护的方法，使跨多元化患者群体的稳健和可靠性能分析成为可能，而无需暴露敏感的EHR数据，从而增强医学AI的整体可信度。"}
{"llm_update_time": "20251023", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2405.11647", "html_url": "https://arxiv.org/abs/2405.11647", "title": "Hummer：减少竞争的偏好数据集", "title_en": "Hummer: Towards Limited Competitive Preference Dataset", "authors": "Li Jiang,Yusen Wu,Junwu Xiong,Jingqing Ruan,Yichuan Ding,Qingpei Guo,Zujie Wen,Jun Zhou,Xiaotie Deng", "background": "偏好数据集对于将人类偏好融入预训练语言模型至关重要，对于从人类反馈中强化学习的成功起着关键作用。然而，这些数据集通常显示出相互冲突的对齐目标，这增加了数据集受到篡改攻击的风险，并且在调整下游任务以优先考虑特定对齐目标时会降低其他目标的效果。", "innovation": "本文引入了新的统计指标——对齐维度冲突，用于量化偏好数据集中的冲突程度。提出了Hummer及其细粒度变体Hummer-F，它们是减少冲突对齐目标的创新性偏好数据集。Hummer基于UltraFeedback并通过GPT-4生成的AI反馈进行增强，旨在减少对齐目标之间的竞争。此外，还开发了奖励模型HummerRM和HummerRM-F，采用了混合采样方法，以平衡不同的对齐目标。这种方法使HummerRM成为领域特定进一步微调的理想模型，并减少了攻击的脆弱性。", "conclusion": "HummerRM通过混合采样方法平衡了多种对齐目标，成为领域特定微调的理想模型，有效降低了攻击的脆弱性。"}
{"llm_update_time": "20251023", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.19807", "html_url": "https://arxiv.org/abs/2510.19807", "title": "Scaf-GRPO: 嵌层分组相对策略优化增强大语言模型推理", "title_en": "Scaf-GRPO: Scaffolded Group Relative Policy Optimization for Enhancing LLM Reasoning", "authors": "Xichen Zhang,Sitong Wu,Yinghao Zhu,Haoru Tan,Shaozuo Yu,Ziyi He,Jiaya Jia", "background": "增强学习从可验证奖励中已经走出来作为一种增强大语言模型（LLMs）复杂推理能力的强大技术。然而，这些方法从根本上受到了所谓的“学习悬崖”现象的限制：当面对超出当前能力的问题时，模型会一直失败，导致持续的零奖励信号。在GRPO等策略优化算法中，这将优势计算压缩为零，使得这些难以解决的问题在学习梯度中变得不可见，从而阻碍了进步。", "innovation": "我们介绍了一种渐进式训练框架Scaf-GRPO（嵌层分组相对策略优化），该框架在模型独立学习停滞时仅提供最少的指导。首先，诊断学习停滞，然后通过注入分级的提示——从抽象概念到具体步骤——干预模型，使其能够自己构造有效的解决方案。广泛的实验证明Scaf-GRPO的有效性，Qwen2.5-Math-7B模型在AIME24基准上的@1通过率相对提高44.3%，超越了经典的GRPO基准。这一结果证明了该框架为解锁模型解决超出其能力范围问题的方法提供了一个强大且有效的途径，是向增强自主推理前沿迈进的关键一步。", "conclusion": "本研究表明，Scaf-GRPO为解锁大语言模型解决之前无法解决的问题的能力提供了一种稳健且有效的方法，这一发现对于扩展自主推理的极限至关重要。"}
{"llm_update_time": "20251023", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2505.14689", "html_url": "https://arxiv.org/abs/2505.14689", "title": "Follow the STARs: Dynamic ω-Regular Shielding of Learned Policies", "title_en": "Follow the STARs: Dynamic $ω$-Regular Shielding of Learned Policies", "authors": "Ashwani Anand,Satya Prakash Nayak,Ritam Raha,Anne-Kathrin Schmuck", "background": "传统的方法主要是确保系统安全，即防止任何不良事件的发生。但是，在实际应用中，除了安全性之外，还经常需要考虑系统的活跃性，即确保在某个时间段内能够发生某些预期的良好事件。现有的安全屏蔽方法难以同时满足这些要求，特别是在学习到的策略更新或执行器故障的情况下，很难灵活地调整策略。因此，研究一种新的动态后屏蔽框架，该框架能够对已学习的策略进行ω-正规正确性属性的控制，对维护系统安全和活跃性提供了新的思路和方法。", "innovation": "本文提出了一种名为STARs的新颖动态后屏蔽框架，用于强制执行预计算的随机策略上的所有ω-正规正确性属性。STARs的核心是使用策略模板为基础的自适应运行时屏蔽，通过使用允许宽松策略模板来最小化后屏蔽过程中的干扰。STARs的特点是能够动态控制干扰程度，引入了一个可调的执行参数，可以在运行时平衡正式义务与特定任务的行为。这种方法允许在需要时采取更积极的强制措施，而在其他时候优化策略选择。此外，STARs还支持运行时对变更规格或执行器故障的适应，特别适用于网络物理系统应用。通过在移动机器人基准测试上的评估，证明了在强制执行（逐步更新的）ω-正规正确性属性时可控的干扰能力。", "conclusion": "本文提出的STARs框架克服了现有方法的局限性，不仅能有效维持系统的安全性，还能确保系统的活跃性。STARs可以动态调整干扰程度，适用于复杂或不断变化的环境，特别是在网络物理系统等应用场景中表现优异。未来的工作将继续探索如何进一步优化STARs和扩展到更广泛的应用场景。"}
{"llm_update_time": "20251023", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.15268", "html_url": "https://arxiv.org/abs/2507.15268", "title": "IM-Chat: 多智能体大语言模型框架结合工具调用和扩散建模在注塑行业知识转移中的应用", "title_en": "IM-Chat: A Multi-agent LLM Framework Integrating Tool-Calling and Diffusion Modeling for Knowledge Transfer in Injection Molding Industry", "authors": "Junhyeong Lee,Joon-Young Kim,Heekyu Kim,Inhyo Lee,Seunghwa Ryu", "background": "注塑行业面临关键挑战，包括保留在职工人领域的知识并将其转移到下一代，以及多语言障碍影响有效沟通。随着经验丰富的工人退休，如何有效传递知识成为一个亟待解决的问题。", "innovation": "提出了IM-Chat（基于大语言模型的多智能体框架），旨在通过多种来源的知识和基于数据的条件生成器（可以推断出适合注塑设置的最佳参数）来促进知识转移。该系统采用了检索增强生成（RAG）策略和模块化架构中内置的工具调用代理，能够根据环境因素（如温度和湿度）提供动态和上下文相关的支持。", "conclusion": "研究结果表明，更强的模型在复杂、工具集成的场景中有更高的准确性。此外，与细调的单智能体模型相比，IM-Chat 在处理多种信息源的量化推理方面表现出更优异的准确性和更大的可扩展性。这些发现表明，多智能体大语言模型系统在工业知识流程中的可行性，并确立IM-Chat为一种可扩展且通用的AI辅助决策支持方法。"}
{"llm_update_time": "20251023", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2505.20749", "html_url": "https://arxiv.org/abs/2505.20749", "title": "Can Agents Fix Agent Issues?", "title_en": "Can Agents Fix Agent Issues?", "authors": "Alfin Wijaya Rahardja,Junwei Liu,Weitong Chen,Zhenpeng Chen,Yiling Lou", "background": "LLM-based agent systems正在成为一个新的软件范式，并已在医学、机器人学和编程等多个领域广泛采用。然而，维持这些系统需要大量努力，因为这些问题系统不可避免地存在漏洞，并且会不断演进来满足变化的外部要求。因此，自动解决代理问题（即错误报告或功能请求）是一个关键而具有挑战性的任务。最近的软件工程（SE）代理（例如SWE-agent）在解决传统软件系统中的问题方面显示出一定的前景，但对于不同传统软件的代理系统中的实际问题的有效性仍不清楚。为了填补这一空白，研究者首先手动分析了201个真实的代理问题，确定了代理问题的常见类别，然后花费500个人工小时构建了一个可重复的基准AGENTISSUE-BENCH，包含50个代理问题解决任务（每个任务都有可执行环境和失败触发的测试）。此外，对现有最先进的SE代理进行了评估，结果显示它们解决代理问题的有效性有限（即解决率仅在3.33% - 12.67%之间）。", "innovation": "通过手动分析201个真实的代理问题，确定了代理问题的常见类别；创建了AGENTISSUE-BENCH，这是一个包含50个可复现实例的基准，每个实例都包括一个可执行环境和触发失败的测试；对现有最先进的SE代理在AGENTISSUE-BENCH上的有效性进行了评估，揭示了其局限性。", "conclusion": "这些结果强化了与传统软件相比，代理系统维护的独特挑战，强调需要进一步研究开发先进的SE代理以解决代理问题。数据和代码可从以下链接获取：[此链接]。"}
{"llm_update_time": "20251023", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.19755", "html_url": "https://arxiv.org/abs/2510.19755", "title": "在扩散模型中缓存方法概览：迈向高效多模态生成", "title_en": "A Survey on Cache Methods in Diffusion Models: Toward Efficient Multi-Modal Generation", "authors": "Jiacheng Liu,Xinyu Wang,Yuqi Lin,Zhikai Wang,Peiru Wang,Peiliang Cai,Qinming Zhou,Zhengan Yan,Zexuan Yan,Zhengyi Shi,Chang Zou,Yue Ma,Linfeng Zhang", "background": "扩散模型由于其卓越的生成质量和可控性已成为现代生成人工智能的核心。然而，它们的固有特性——多步迭代和复杂的骨干网络——导致了巨大的计算开销和生成延迟，成为实时应用的主要障碍。尽管现有加速技术已经取得进展，但仍然存在适用范围有限、高训练成本或质量下降等问题。", "innovation": "扩散缓存提供了一种无需训练、架构通用且高效的推理范式。其核心机制识别并重用了扩散过程中内在的计算冗余，通过特征级别的跨步重用和层间调度来减少计算，而不修改模型参数。本文系统地回顾了扩散缓存的理论基础及其演化，并提出了一个统一的分类和分析框架。通过代表性方法的比较分析，展示了扩散缓存从静态重用到动态预测的发展趋势，增强了在不同类型任务中的缓存灵活性，并使其能够与其他加速技术如采样优化和模型蒸馏相结合，为未来多模态和互动应用提供了一个统一且高效的推理框架。", "conclusion": "我们认为这种范式将成为实时和高效生成人工智能的关键驱动力，为人工智能高效生成智能的理论和实践注入新的活力。"}
{"llm_update_time": "20251023", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.02344", "html_url": "https://arxiv.org/abs/2508.02344", "title": "Traffic-R1: 强化LLMs为交通信号控制系统带来类人推理", "title_en": "Traffic-R1: Reinforced LLMs Bring Human-Like Reasoning to Traffic Signal Control Systems", "authors": "Xingchen Zou,Yuhao Yang,Zheng Chen,Xixuan Hao,Yiqi Chen,Chao Huang,Yuxuan Liang", "background": "交通信号控制（TSC）的传统方法依赖于强化学习和基于模型的学习方法，这些方法往往难以实现零样本泛化，适应新路网和异常情况，同时在嵌入式设备上实现实时推理也存在挑战。此外，当前的方法往往缺乏可解释性，难以协调多个交叉口。", "innovation": "本文提出了一种名为Traffic-R1的交通信号控制模型，具有3B参数，通过自我探索和迭代强化结合专家指导，在模拟交通环境中开发。Traffic-R1的主要创新包括三个方面：1) 零样本泛化，能够无缝转移到新的路网和未见情况；2) 紧凑的3B参数设计，支持在移动级芯片上进行实时推理，便于边缘部署；3) 可解释的TSC过程，通过通信协调多个交叉口，并使用异步通信网络。", "conclusion": "广泛的基准测试表明Traffic-R1在多种场景中性能优秀，超过了强大的基线模型和训练密集型的RL控制器。在生产环境中，模型已管理每天影响超过55,000名司机的信号，减少了平均排队长度超过5%，并将操作员的工作量减半。该模型已公开提供。"}
{"llm_update_time": "20251023", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2505.23686", "html_url": "https://arxiv.org/abs/2505.23686", "title": "ROTATE: 基于遗憾驱动的开放训练环境下的即兴团队协作", "title_en": "ROTATE: Regret-driven Open-ended Training for Ad Hoc Teamwork", "authors": "Caroline Wang,Arrasy Rahman,Jiaxun Cui,Yoonchang Sung,Peter Stone", "background": "在多智能体学习领域，即兴团队协作（AHT）是一个重要的基本泛化挑战，即学习与未见过的团队成员合作。现有的AHT方法通常采用两阶段的流程：首先生成一组固定的团队成员，认为这些成员能够代表将要部署时遇到的团队成员；其次训练AHT智能体与该群体中的成员合作。然而，目前的研究主要集中在为每个阶段设计单独的算法，导致生成的团队成员的行为覆盖面有限，并且忽略生成的团队成员对AHT智能体学习的难易程度。此外，在训练AHT智能体的算法中，通常将训练的团队成员集视为静态的，试图在没有任何对训练团队成员集控制的情况下泛化到未见过的合作伙伴智能体上。因此，这项研究提出了一种统一的框架来解决AHT问题，通过将问题重新表述为AHT智能体和对抗性团队成员生成器之间的开放性学习过程。", "innovation": "提出了名为ROTATE的基于遗憾驱动的开放性训练算法，该算法通过交替改进AHT智能体和生成能够探测其缺陷的团队成员来训练。与基准方法相比，实验表明ROTATE在泛化到未见过的评价团队成员时取得了显著的性能提升，从而为稳健和泛化协作设立了新的标准。", "conclusion": "这项研究通过一种统一的框架解决了即兴团队协作的问题，该框架将问题重新表述为一个AHT智能体和对抗性团队成员生成器之间的开放性学习过程。所提出的ROTATE算法通过遗憾驱动、开放性训练方法显著提高了AHT智能体与未见过的团队成员的泛化能力。"}
{"llm_update_time": "20251023", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.00890", "html_url": "https://arxiv.org/abs/2508.00890", "title": "AgentTTS: 复杂任务中大语言模型代理的测试时间计算最优缩放策略", "title_en": "AgentTTS: Large Language Model Agent for Test-time Compute-optimal Scaling Strategy in Complex Tasks", "authors": "Fali Wang,Hui Liu,Zhenwei Dai,Jingying Zeng,Zhiwei Zhang,Zongyu Wu,Chen Luo,Zhen Li,Xianfeng Tang,Qi He,Suhang Wang", "background": "测试时扩展（TTS）通过在推理时分配额外的计算资源来增强大规模语言模型（LLM）的性能。现有研究主要集中在单一阶段任务上的TTS；然而，许多现实世界的问题是多阶段复杂的任务，由一系列异构子任务组成，每个子任务都需要特定能力的LLM。因此，研究了在多阶段复杂任务中选择合适模型并为每个子任务分配预算以最大化整体性能的新型问题。在多阶段任务中，TTS引入了两个基本挑战：（i）模型和预算的组合搜索空间巨大，加上传统搜索的成本高，使其变得不切实际；（ii）子任务间的最佳模型和预算分配相互依赖，增加了计算最优搜索的复杂性。", "innovation": "提出了一种基于大语言模型代理的AgentTTS框架，该框架通过与执行环境的迭代反馈驱动交互自主搜索计算最优分配。实验结果显示，AgentTTS在搜索效率、对训练集大小变化的鲁棒性和可解释性方面优于传统的和其他基于LLM的基线方法。", "conclusion": "研究表明，AgentTTS在搜索效率、鲁棒性和可解释性方面表现出色，尤其适用于解决多阶段复杂任务中计算资源分配的问题。"}
{"llm_update_time": "20251023", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.14909", "html_url": "https://arxiv.org/abs/2507.14909", "title": "无尽调谐。一种避免人工替代并追溯责任的人工智能设计", "title_en": "The Endless Tuning. An Artificial Intelligence Design To Avoid Human Replacement and Trace Back Responsibilities", "authors": "Elio Grande", "background": "该研究提出了一种名为‘无尽调谐’的设计方法，用于基于双重镜像过程可靠部署人工智能。该方法旨在同时避免人类被替代以及填补所谓的责任空白。这项研究基于Fabris等人（2024）中提出的关联方法，并在三个典型的决策流程应用（贷款发放、肺炎诊断和艺术风格识别）中予以实现和测试，通过与领域专家进行实验，逐步展示协议的具体应用。研究重点在于用户体验而非统计准确性，在涉及深度学习模型的情况下，使受访者在决策过程中依然保持充分的控制感，同时也探讨了在发生损害时如何实现问责制与法律责任之间的桥梁构建。", "innovation": "无尽调谐作为一种设计方法，采用了双重镜像过程来部署人工智能。它特别注重避免人工替代和填补责任空白的问题。该方法是从Fabris等人（2024）的研究基础上发展而来的，提供了独特的技术选择和道德视角，尤其是通过反向和释义的方式应用XAI算法，这在人工智能伦理方面具有不同的声音。此外，该研究通过实施和测试三个原型应用程序来验证其有效性，并强调了用户在决策过程中的控制感.", "conclusion": "研究结果表明，运用深度学习模型时，用户仍能感受到决策过程中的完全控制，并且在发生损害时，问责制与法律责任之间可以建立桥梁。通过无尽调谐，为人工智能的应用提供了一种新的方法，不仅能避免替代人力资源，还能增强责任的透明度和追责性。"}
{"llm_update_time": "20251023", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.02511", "html_url": "https://arxiv.org/abs/2508.02511", "title": "Test-time Prompt Intervention", "title_en": "Test-time Prompt Intervention", "authors": "Chenxu Yang,Qingyi Si,Mz Dai,Dingyu Yao,Mingyu Zheng,Minghui Chen,Zheng Lin,Weiping Wang", "background": "在测试时计算已经显著提高了大规模语言模型（LLM）社区的表现，特别是在复杂任务中，这些模型生成了用来增强推理能力的长链条思考（CoTs）。然而，目前证据表明，这些推理模型经常产生包含过多冗余的CoTs，例如不必要的验证步骤和重复的推理转变。这些冗余通常源于训练后对这些模型过度依赖结果奖励机制，因为难以规模化构建调节中间推理步骤的过程奖励数据。", "innovation": "为了应对这一问题，该论文提出了一种新颖的框架——Test-time Prompt Intervention （PI）。PI 提供了一个接口，在推理过程中通过及时（When模块）、恰当（How模块）以及干预后的抽样（Which模块）动态地指导和调节推理路径。通过这种方式，人的问题解决专业知识和认知科学原理可以无缝地融入到LLMs的推理过程中，增强了可控性与可解释性。", "conclusion": "广泛的实验表明，PI 能够显著缩短CoTs 同时减少幻觉，使得推理结果更为简洁和可靠。"}
{"llm_update_time": "20251023", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.18942", "html_url": "https://arxiv.org/abs/2509.18942", "title": "在大型语言模型中通过连续低秩微调实现高效适应", "title_en": "Data Efficient Adaptation in Large Language Models via Continuous Low-Rank Fine-Tuning", "authors": "Xiao Han,Zimo Zhao,Wanyu Wang,Maolin Wang,Zitao Liu,Yi Chang,Xiangyu Zhao", "background": "近年来，大型语言模型（LLMs）的发展突显了微调（FT）技术在将LLMs适应特定任务中的关键作用，尤其是当从零开始重新训练在计算上不可行时。传统微调方法常常面临灾难性遗忘和效率低下的问题，限制了它们的实际应用范围。因此，有必要开发新的方法来解决这些问题，提高LLMs的适应性并确保资源的有效利用。", "innovation": "本文提出了一个名为DEAL的新框架，该框架结合了低秩适应（LoRA）和连续微调策略。通过引入知识保存模块和自适应参数更新模块，DEAL框架克服了现有微调方法的局限性，同时保持了高效性。实验结果表明，DEAL在15个不同数据集上表现优于基线方法，大幅提高了任务准确性和资源效率。", "conclusion": "这些结果表明，我们的方法有潜力通过提高任务性能和资源效率来推动大型语言模型的连续适应。DEAL框架的源代码可以在该链接（this https URL）获取。"}
{"llm_update_time": "20251023", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.25434", "html_url": "https://arxiv.org/abs/2509.25434", "title": "开放综合征定义", "title_en": "The Open Syndrome Definition", "authors": "Ana Paula Gomes Ferreira,Aleksandar Anžel,Izabel Oliva Marcilio de Souza,Helen Hughes,Alex J Elliot,Jude Dzevela Kong,Madlen Schranz,Alexander Ullrich,Georges Hattab", "background": "当前病例定义对于有效传达公共健康威胁至关重要，但缺乏标准化且可机器读取的格式使得跨组织和区域的比较、合作受限，并限制了数据的整合，阻碍了公共卫生领域的技术进步。", "innovation": "提出了首个开放且可机器读取的格式来表示病例和综合征定义，并且提供了一个包含标准化病例定义标准数据集的全面工具集，以及将现有的人类可读定义转换为机器可读格式的工具，还提供了一个易于访问的在线平台以供用户浏览、分析并贡献新的定义。", "conclusion": "开放综合征定义格式能够实现一致和可扩展的病例定义应用，释放人工智能在增强公共卫生准备和响应中的潜力。"}
{"llm_update_time": "20251023", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.23426", "html_url": "https://arxiv.org/abs/2509.23426", "title": "使用ToolUniverse民主化AI科学家", "title_en": "Democratizing AI scientists using ToolUniverse", "authors": "Shanghua Gao,Richard Zhu,Pengwei Sui,Zhenglun Kong,Sufian Aldogom,Yepeng Huang,Ayush Noori,Reza Shamji,Krishna Parvataneni,Theodoros Tsiligkaridis,Marinka Zitnik", "background": "AI科学家是作为发现过程中的合作者而出现的新兴计算系统，但它们难以构建，因为它们是定制的，与固有的工作流程紧密相关，并缺乏将工具、数据和分析统一到共同生态系统中的共享环境。在基因组学领域，统一体系结构已经改变了研究，通过提高互操作性、重用性和社区驱动的发展。AI科学家需要类似的基础设施。", "innovation": "ToolUniverse是一个生态系统，可以从任何语言或推理模型构建AI科学家，涵盖了开源和闭源模型。它标准化了AI科学家如何识别和调用工具，提供了超过600个机器学习模型、数据集、API和科学包，支持数据分析、知识获取和实验设计。ToolUniverse可以自动调整工具接口以正确使用，从自然语言描述生成新工具，迭代优化工具规范，并将工具组成具有主体性的工作流程。", "conclusion": "在一项关于高胆固醇的研究案例中，ToolUniverse被用来创建一个AI科学家，以识别具有理想预测特性的药物类似物。开源的ToolUniverse可在以下链接找到：[this https URL]()。"}
{"llm_update_time": "20251023", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.14176", "html_url": "https://arxiv.org/abs/2510.14176", "title": "ARM-FM: 基于基础模型的自动化奖励机器用于组合强化学习", "title_en": "ARM-FM: Automated Reward Machines via Foundation Models for Compositional Reinforcement Learning", "authors": "Roger Creus Castanyer,Faisal Mohamed,Pablo Samuel Castro,Cyrus Neary,Glen Berseth", "background": "强化学习（RL）算法高度依赖于奖励函数的指定，这是限制其广泛应用的主要挑战之一。奖励函数的不恰当设计可能导致RL算法偏离目标。Reward Machines (RMs)提供了一种基于自动机的形式化方法来指定奖励，但仍然需要人工设计，这在复杂任务中是不切实际的。", "innovation": "该研究提出了ARM-FM框架，通过利用基础模型（FMs）的高度推理能力，实现了奖励设计的自动化和组合化。具体来说，ARM-FM能够自动从自然语言规范中生成RMs，并将语言嵌入与每个RM自动机状态关联起来以实现任务间的泛化。", "conclusion": "实验结果表明，ARM-FM在多种具有挑战性的环境中具有有效性，包括展示了零样本泛化能力。"}
{"llm_update_time": "20251023", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.21567", "html_url": "https://arxiv.org/abs/2509.21567", "title": "基于EEG的消费者行为预测：从经典机器学习到图神经网络的探索", "title_en": "EEG-Based Consumer Behaviour Prediction: An Exploration from Classical Machine Learning to Graph Neural Networks", "authors": "Mohammad Parsa Afshar,Aryan Azimi", "background": "消费者行为预测是市场营销、认知神经科学和人机交互的关键目标。脑电图（EEG）数据能够通过详细的脑神经活动信息来帮助分析决策过程。本研究采用了经典的机器学习模型和图神经网络模型结合EEG数据来预测消费者行为。通过提取和清洁NeuMa数据集中的EEG特征，为图神经网络模型创建脑连接性特征，并对不同的模型进行了广泛比较，以期通过综合方法展示模型之间的差异和性能。尽管结果显示整体上没有显著差异，但图神经网络模型在某些基本标准上表现较好，特别是当经典模型表现不佳时。研究表明，结合EEG信号分析和机器学习模型可以提供深入理解消费者行为的新方法，同时也对基于EEG的神经市场营销中广泛使用的和支持向量机（SVM）的其他较少使用的模型（例如图神经网络）之间的对比进行了全面比较。", "innovation": "研究采用了图神经网络模型，与经典的机器学习模型进行了对比，为基于EEG的消费者行为预测提供了新的方法，并对图神经网络等较少使用的模型在该领域的应用进行了探索。通过对多种模型的广泛比较，展示了不同的模型在处理类似数据集时的优缺点。", "conclusion": "结合EEG信号分析和机器学习模型能够提供深入理解消费者行为的方法。研究不仅展示了经典模型和图神经网络在预测消费者行为中的表现差异，还提供了基于EEG的神经市场营销领域中模型应用的新视角。"}
{"llm_update_time": "20251023", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.05346", "html_url": "https://arxiv.org/abs/2509.05346", "title": "为增强学习中个性化指导评估大型语言模型", "title_en": "Benchmarking Large Language Models for Personalized Guidance in AI-Enhanced Learning", "authors": "Bo Yuan,Jiazi Hu", "background": "虽然大型语言模型（LLMs）被广泛认为是个性化学习的智能助手，但在真实学习场景中进行系统对头评价的研究仍很少见。本文通过实证比较三种最先进的LLMs在模拟真实学习环境的辅导任务中的表现，填补了这一空白。研究使用包含十个混合格式问题及其正确性标签的学生回答数据集，要求每个模型分析测试卷、推断学生的掌握情况并生成针对性的改进建议。研究借助Gemini虚拟评判者，在多个维度进行两两比较，评估模型的准确度、清晰度、可操作性和适宜性，旨在减少主观性和评分者偏见。结果通过Bradley-Terry模型分析显示了GPT-4o在生成反馈方面的一般优势，其反馈更为信息丰富且结构化，而DeepSeek-V3和GLM-4.5展示了间歇性的优势但一致性较低。这些发现强调了部署LLMs作为高级教学助手的可行性和个体制导化支持的重要性，并为后续LLM驱动个性化学习的实证研究提供了方法论上的启示", "innovation": "本文通过实证方法比较了三种最先进的大型语言模型在模拟真实学习环境的辅导任务中的表现，首次在真实学习场景中进行系统对比。引入Gemini作为虚拟评判者，确保评价的客观性和公正性，使用Bradley-Terry模型对结果进行分析，提供了一种新的评价框架和科学依据", "conclusion": "研究结果表明，GPT-4o在个性化反馈方面表现最佳，其反馈更具信息丰富和结构化。虽然DeepSeek-V3和GLM-4.5在某些情况下也表现出优势，但总体一致性较低。这些发现突显了LLMs作为高级教学助手在个体制导化支持中的潜力，并为后续研究提供了宝贵的方法论指导"}
{"llm_update_time": "20251023", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.07364", "html_url": "https://arxiv.org/abs/2510.07364", "title": "基础模型知道如何推理，思考模型学习何时推理", "title_en": "Base Models Know How to Reason, Thinking Models Learn When", "authors": "Constantin Venhoff,Iván Arcuschin,Philip Torr,Arthur Conmy,Neel Nanda", "background": "研究发现，尽管思维语言模型如DeepSeek R1在性能上普遍优于其基础版本，但仍不清楚这些模型是通过学习全新的推理能力，还是重用了基础模型已有的能力。因此，该研究提出了一个混合模型，旨在通过在基础模型中适当激活推理机制来激发达到思维模型级别的推理链，表明思考模型利用了已有的能力。此外，该研究还引入了一种无监督的自底向上的方法，以揭示思维模型中的可由人类理解和解释的推理行为，提供了一种不带偏见的方法来发现推理行为，无需强加手动或基于语言模型的假设。", "innovation": "提出了一种混合模型，通过在基础模型中适时激活推理机制，激发达到思维模型级别的推理链，表明思考模型利用了已有的能力。引入了一种无监督的自底向上的方法，以揭示思维模型中的可由人类理解和解释的推理行为。这种设定提供了测试基础模型中现有推理机制有效性的简单因果方法，通过直接调用这些机制并测量任务表现来测试。更广泛地说，这些结果重新定义了关于思考模型训练的理解：预训练阶段模型主要获取推理机制，而后续训练阶段则教会模型在适当的时间高效使用这些机制，从而有效利用推断时间的计算资源。", "conclusion": "研究表明，基础模型已经具备了推理能力，而思考模型则主要学习如何在适当的时间使用这些能力。这表明，预训练是模型获得大部分推理机制的阶段，而后续的训练则侧重于高效地在正确的时间使用这些机制，从而提高模型的推理效率。"}
{"llm_update_time": "20251023", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.25271", "html_url": "https://arxiv.org/abs/2509.25271", "title": "RADAR: 一种通过角色专业化协作实现LLM安全评估的风险感知动态多智能体框架", "title_en": "RADAR: A Risk-Aware Dynamic Multi-Agent Framework for LLM Safety Evaluation via Role-Specialized Collaboration", "authors": "Xiuyuan Chen,Jian Zhao,Yuchen Yuan,Tianle Zhang,Huilin Zhou,Zheng Zhu,Ping Hu,Linghe Kong,Chi Zhang,Weiran Huang,Xuelong Li", "background": "现有的面向大型语言模型（LLMs）的安全评估方法存在固有的局限性，主要表现在评估者偏见和因模型同质性而导致的检测失败，这些因素共同削弱了风险评估过程的稳健性。", "innovation": "该论文通过引入一个理论框架来重新审视风险评估范式，该框架重新构建了潜在风险概念空间。具体来说，它将潜在风险概念空间分解成三个互斥子空间：显式风险子空间（直接违反安全准则）、隐式风险子空间（需要上下文推理解出的潜在恶意内容）和无风险子空间。此外，论文提出了RADAR，一种多智能体协作评估框架，利用多轮辩论机制和动态更新机制来实现风险概念分布的自我演化。这种做法不仅覆盖了显性和隐性风险，还减轻了评估者偏见。为验证框架的有效性，构建了一个包含800个具有挑战性的评估数据集，并在挑战性测试集和公开基准上进行了广泛的实验，证明RADAR在准确率、稳定性和自我评价风险敏感性等多个维度上显著优于基线方法，且相比最强基线方法在风险识别准确率上提高了28.87%。", "conclusion": "RADAR框架在多个评估维度上显著优于基线方法，特别在风险识别准确性方面有28.87%的显著提升。"}
{"llm_update_time": "20251023", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.15727", "html_url": "https://arxiv.org/abs/2510.15727", "title": "发票信息提取方法及性能评估", "title_en": "Invoice Information Extraction: Methods and Performance Evaluation", "authors": "Sai Yashwant,Anurag Dubey,Praneeth Paikray,Gantala Thulsiram", "background": "这篇论文介绍了从发票文档中提取结构化信息的方法，并提出了一套评估提取数据准确性的评价指标（EM）。背景在于，当前需要一种有效的方法来处理扫描或数字发票，并从中提取关键字段如发票号码、日期、总金额和供应商信息，以提高业务流程的效率和准确性。", "innovation": "论文创新点在于提出了一套用于评估提取数据准确性的评价指标，该方法包括预处理扫描或数字发票、使用Docling和LlamaCloud服务识别并提取关键字段，并建立一个包含字段精确度、一致性检查失败和精确匹配准确度的可靠评估框架。", "conclusion": "论文通过提出的评价指标提供了一种标准化的方式来比较不同的提取方法，并揭示了各个关键字段在提取性能上的优势和劣势。结论是对发票信息提取方法的研究及评价提供了一种有用的工具和方法论支持。"}
{"llm_update_time": "20251023", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.14828", "html_url": "https://arxiv.org/abs/2510.14828", "title": "RoboGPT-R1: 提升机器人规划能力的强化学习", "title_en": "RoboGPT-R1: Enhancing Robot Planning with Reinforcement Learning", "authors": "Jinrui Liu,Bingyan Nie,Boyu Li,Yaran Chen,Yuze Wang,Shunsen He,Haoran Li", "background": "在复杂现实环境下的长期操作任务中，机器人完成复杂的人类指令需要增强其推理能力。现有的大型语言模型和基于监督微调（SFT）的视觉语言模型在规划任务中取得了成功，但在执行长期操作任务时仍面临挑战，原因在于它们的常识和推理能力有限。简单地通过监督微调使通用视觉语言模型与机器人规划任务对齐，会带来泛化能力差且物理理解不足的问题。", "innovation": "提出了一种两阶段微调框架RoboGPT-R1，该框架通过监督训练来获取基础知识，然后通过强化学习addresses模型在视觉空间理解和推理方面的不足。为了在一个多步推理任务中实现物理理解和动作序列一致性，设计了一种基于规则的奖励函数，同时考虑长时间性能和环境中的动作约束。在EmbdoyedBench基准测试中，基于 mégatron-2.5-VL-3B训练的推理模型显著优于规模更大的GPT-4o-mini，涉性能提高了21.33%，还比基于 mégatron-2.5-VL-7B训练的其他工作高出20.33%。", "conclusion": "RoboGPT-R1框架在处理多步骤操作任务时展示了显著的性能优势，通过两阶段微调提高了机器人的规划能力，特别是在视觉空间理解和长期操作任务的物理理解等方面。"}
{"llm_update_time": "20251023", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.16309", "html_url": "https://arxiv.org/abs/2510.16309", "title": "MedRule-KG：一种由知识图谱引导的轻量级验证器支持的数学推理框架", "title_en": "MedRule-KG: A Knowledge-Graph--Steered Scaffold for Mathematical Reasoning with a Lightweight Verifier", "authors": "Crystal Su", "background": "大型语言模型（LLMs）经常生成流畅的推理步骤，但在简单数学或逻辑约束方面经常违反规则。为此，本文提出了MedRule-KG，一种结合了符号验证器的紧凑型类型知识图，旨在在推理任务中强制执行可解释的数学规则。", "innovation": "MedRule-KG通过编码实体、关系和三个领域启发式规则，并通过验证器检查预测并进行最小修正来确保一致性，从而实现数学推理任务中的可解释规则强制执行。", "conclusion": "在FDA提供的90例子集上，基于MedRule-KG的基准改进了完全匹配（EM）从0.767到0.900，添加验证器则实现了1.000的EM，完全消除了规则违反情况。本文展示了MedRule-KG作为安全数学推理的一般支撑架构的重要性，并进行了消融实验，同时公开了代码和数据以鼓励可重复性研究。"}
{"llm_update_time": "20251023", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.16206", "html_url": "https://arxiv.org/abs/2510.16206", "title": "在人工智能时代保护最真实的数字记忆的权利", "title_en": "The Right to Be Remembered: Preserving Maximally Truthful Digital Memory in the Age of AI", "authors": "Alex Zhavoronkov,Dominika Wilczok,Roman Yampolskiy", "background": "由于大型语言模型（LLMs）的迅速扩展，人们开始依赖它们进行信息检索。传统搜索引擎展示的是通过搜索引擎优化（SEO）、广告和个性化处理后的排名列表，而LLMs通常提供一个合乎逻辑的、权威的回答。尽管这两种方法都存在偏向和疏漏的风险，但LLMs可能会通过将多个视角压缩成一个答案，从而加剧这种影响，降低用户对比其他选择的能力或意愿。这导致了对信息的权力集中在少数几个LLM供应商手中，他们的系统实际上影响了什么被记住和被忽视的内容，从而可能不公正地压缩某些叙述、个人或团体，而放大其他一些已经重要的内容，重塑集体记忆。", "innovation": "本文提出了一种“被记忆权”（RTBR）的概念，旨在通过减少AI驱动的信息疏漏风险，实现公正对待，确保生成的内容最大程度地真实。", "conclusion": "随着时间的推移，这些现象可能导致有较少数字存在感的人逐渐被遗忘，而已经重要的个人或群体得到更多重视。为了应对这些担忧，论文提出了一种权利概念，旨在通过减少AI驱动的信息遗漏风险，保护最真实和公正的记忆，以重塑集体记忆。"}
{"llm_update_time": "20251023", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.18193", "html_url": "https://arxiv.org/abs/2510.18193", "title": "FST.ai 2.0: 为奥运会和残奥会跆拳道公平、快速、包容的决策制定可解释的人工智能生态系统", "title_en": "FST.ai 2.0: An Explainable AI Ecosystem for Fair, Fast, and Inclusive Decision-Making in Olympic and Paralympic Taekwondo", "authors": "Keivan Shariatmadar,Ahmad Osman,Ramin Ray,Kisam Kim", "background": "在奥林匹克和残奥会搏击运动（如跆拳道）中，公平、透明和可解释的决策制定仍然是一个关键挑战。现有的决策制定系统往往缺乏透明度和可解释性，这可能导致人为决策与机器决策之间出现分歧。", "innovation": "本文介绍了FST.ai 2.0，这是一种可解释的人工智能生态系统，旨在支持裁判、教练和运动员在跆拳道比赛中及训练中的实时决策。该系统结合了基于姿态的动作识别（通过图卷积网络）、知识性不确定性建模及可视化决策支持的解释性叠加，还包括互动仪表板以促进人与人工智能的合作。FST.ai 2.0 超出了仅自动评分的功能，还包含裁判培训模块、公平性监控以及世跆联生态系统的政策级分析。实验表明，该系统在决策评审时间上实现了85%的减少，并且在裁判对辅助决策的信任度上达到了93%。", "conclusion": "FST.ai 2.0 系统建立了一个透明且可扩展的流程，以实现可信的数据驱动裁判和运动员评估。该系统通过实时感知、可解释推理以及意识治理设计，朝着公平、问责制和人类对齐的人工智能在运动中的应用迈进了一步。"}
{"llm_update_time": "20251023", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2306.10407", "html_url": "https://arxiv.org/abs/2306.10407", "title": "FP-IRL: Fokker-Planck Inverse Reinforcement Learning -- A Physics-Constrained Approach to Markov Decision Processes", "title_en": "FP-IRL: Fokker-Planck Inverse Reinforcement Learning -- A Physics-Constrained Approach to Markov Decision Processes", "authors": "Chengyang Huang,Siddhartha Srivastava,Kenneth K. Y. Ho,Kathy E. Luker,Gary D. Luker,Xun Huan,Krishna Garikipati", "background": "逆强化学习（IRL）是一种从观察到的状态轨迹中推断出驱动智能体行为的激励结构的强大范式。然而，大部分现有方法需要预先访问过渡函数，要么是固定的，要么是估计的，这对于未知、不可观测或难以采样的动态系统构成了重大挑战。", "innovation": "本文提出了一种新的物理约束逆强化学习（FP-IRL）框架，针对由Fokker-Planck（FP）动力学支配的系统。它无需访问样本转换函数，而是直接从轨迹数据中同时推断出奖励和过渡函数。FP-IRL通过将马尔科夫决策过程（MDP）和Fokker-Planck方程之间的假设等价关系，链接奖励最大化与Fokker-Planck动力学中自由能最小化，进而使用变分系统识别方法推断潜在函数，通过分析表达式恢复完整的MDP组件，包括奖励、转换和策略。通过合成基准和修改后的山车问题实验表明，FP-IRL能够准确捕捉代理的激励机制，保持计算效率和物理可解释性。", "conclusion": "实验结果表明，FP-IRL能够准确恢复智能体的激励机制，同时保持计算效率和物理可解释性。"}
{"llm_update_time": "20251023", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.17064", "html_url": "https://arxiv.org/abs/2510.17064", "title": "由大型语言模型和多代理AI系统创建的脑细胞类型资源，以实现协作社区注释", "title_en": "A Brain Cell Type Resource Created by Large Language Models and a Multi-Agent AI System for Collaborative Community Annotation", "authors": "Rongbin Li,Wenbo Chen,Zhao Li,Rodrigo Munoz-Castaneda,Jinbo Li,Neha S. Maurya,Arnav Solanki,Huan He,Hanwen Xing,Meaghan Ramlakhan,Zachary Wise,Zhuhao Wu,Hua Xu,Michael Hawrylycz,W. Jim Zheng", "background": "单细胞RNA测序已极大地提高了多元细胞类型及其转录组特征的识别能力。然而，注释这些特征（尤其是涉及未充分表征的基因的特征）仍然是一个主要挑战。传统方法，如基因集富集分析（GSEA），依赖于良好的注释，但在这些情况下表现不佳。大型语言模型（LLMs）提供了替代方案，但它们难以在结构化本体内部表示复杂的生物学知识。", "innovation": "我们介绍了BRAINCELL-AID（一个创新的多代理AI系统，它结合了自由文本描述和本体标签，以实现更准确和健壮的基因集合注释。通过结合检索增强生成（RAG），我们开发出一个强大的代理工作流，利用相关PubMed文献来精炼预测结果，减少幻觉并增强可解释性。使用这种工作流，我们在小鼠基因集合中实现了77%的正确注释。应用这个方法，我们对Brain Initiative Cell Census Network生成的综合小鼠大脑细胞图谱中的5,322个大脑细胞簇进行了注释，识别了特定脑区的基因共表达模式，并推断了基因集合的功能角色。BRAINCELL-AID还识别了与神经系统有重要意义的基底节相关细胞类型。", "conclusion": "因此，我们创建了一个宝贵资源，支持社区驱动的细胞类型注释，这为理解和分析脑细胞功能提供了新的见解。"}
{"llm_update_time": "20251023", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2310.18608", "html_url": "https://arxiv.org/abs/2310.18608", "title": "推荐系统中的嵌入：综述", "title_en": "Embedding in Recommender Systems: A Survey", "authors": "Maolin Wang,Xinjian Zhao,Wanyu Wang,Sheng Zhang,Jiansheng Li,Bowen Yu,Binhao Wang,Shucheng Zhou,Dawei Yin,Qing Li,Ruocheng Guo,Xiangyu Zhao", "background": "推荐系统已成为许多在线平台的核心组件，能够提供个性化推荐。嵌入技术是其中的关键方面，通过将离散的高维度特征（如用户ID和项目ID）转换为低维度的连续向量，增强推荐性能，捕捉复杂实体关系。", "innovation": "本文综述了推荐系统嵌入技术的最新进展，涵盖了矩阵、序列和图结构下的集中嵌入方法。介绍了矩阵基础、序列数据和图结构的具体嵌入技术，如生成矩阵嵌入、递归神经网络、自监督学习方法等。探讨了嵌入方法中关键的可扩展性挑战，并介绍了包括自动机器学习（AutoML）、哈希技术和量化方法在内的新兴方法，旨在提高性能同时降低计算复杂度。此外，还研究了大型语言模型（LLMs）在嵌入提升中的作用。", "conclusion": "本文详细讨论了推荐系统中嵌入技术的各种架构和方法，提供了对最新嵌入技术的全面概述，同时指出了关键挑战和未来研究方向。"}
{"llm_update_time": "20251023", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2312.10107", "html_url": "https://arxiv.org/abs/2312.10107", "title": "朝向上下文感知的域泛化：理解边缘转移学习的优势和局限", "title_en": "Towards Context-Aware Domain Generalization: Understanding the Benefits and Limits of Marginal Transfer Learning", "authors": "Jens Müller,Lars Kühmichel,Martin Rohbeck,Stefan T. Radev,Ullrich Köthe", "background": "在域泛化（DG）领域中的边缘转移学习研究基础上，本研究分析了输入$X$的上下文信息如何在新域中改善深度学习模型的预测能力。上下文被定义为一种来自与输入相同域的数据点的不变表示，这一概念在形式上得到了明确。", "innovation": "本文提供了边缘转移学习背景下，上下文对模型预测改进的理论分析，提出了两个可实践验证的关键标准。同时，研究探讨了边缘转移学习方法对何种分布变化具有鲁棒性。实证分析显示这些标准能有效识别有利和不利的情景，并展示了如何可靠地检测在不利出分布（OOD）域中不公平的外推情况，从而选择最预测性和最鲁棒性的模型，解决了预测性能与鲁棒性之间的权衡问题。", "conclusion": "我们证明了可以通过选择最预测性和最鲁棒性的模型来解决预测性能与鲁棒性之间的权衡问题。这一方法可以在不利的出分布域中检测到错误的外推情况，并识别潜在的失败场景。"}
{"llm_update_time": "20251023", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2406.19195", "html_url": "https://arxiv.org/abs/2406.19195", "title": "利用最优运转变换泛化界估算长期异质剂量反应曲线", "title_en": "Estimating Long-term Heterogeneous Dose-response Curve: Generalization Bound Leveraging Optimal Transport Weights", "authors": "Zeqin Yang,Weilin Chen,Ruichu Cai,Yuguang Yan,Zhifeng Hao,Zhipeng Yu,Zhichao Zou,Jixing Xu,Zhen Peng,Jiecheng Guo", "background": "长期治疗效果估计在许多应用中是一个非常重要但极具挑战性的问题。现有的方法依赖于理想假设，如未观察到混杂因素或二元治疗，来估计长期平均治疗效果。然而，在许多实际应用中，这些假设可能会被违反，且仅使用平均治疗效果不足以进行个性化决策。", "innovation": "该论文提出了一种更通用的长期异质剂量反应曲线（HDRC）估计方法，该方法能在存在未观察混杂因素和连续治疗的情况下进行建模。具体而言，通过引入最优运转变换加权框架将长期观察数据与辅助短期实验数据对齐，以消除长期观测数据中的未观察混杂因素，并且通过利用最优运转变换导引的加权分布建立了反事实预测误差的一般化界，从而能够准确预测连续治疗的异质效应。最终，基于上述理论基础开发了一种长期HDRC估计器。", "conclusion": "实验结果表明，该方法在合成和半合成数据集上的有效性。"}
{"llm_update_time": "20251023", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2409.03811", "html_url": "https://arxiv.org/abs/2409.03811", "title": "PARCO: 并行自回归模型用于多智能体组合优化", "title_en": "PARCO: Parallel AutoRegressive Models for Multi-Agent Combinatorial Optimization", "authors": "Federico Berto,Chuanbo Hua,Laurin Luttmann,Jiwoo Son,Junyoung Park,Kyuree Ahn,Changhyun Kwon,Lin Xie,Jinkyoo Park", "background": "涉及多智能体的组合优化问题由于其计算复杂性和有效的智能体协调需求而极具挑战性，现有基于学习的方法常常存在智能体协调不理想、泛化能力差和计算延迟高的问题。", "innovation": "提出了PARCO（并行自回归组合优化），这是一种用于高效构建多智能体组合任务高质量解的一般性强化学习框架。具体创新包括基于变压器的通信层以支持并行解决方案构建中的有效智能体协作；低延迟、并行智能体决策的多个指针机制；以及基于学习优先级的冲突处理程序以解决决策冲突。", "conclusion": "PARCO在多智能体车辆路线和调度问题上的评估表明，该方法优于最先进的学习方法，展现了强大的泛化能力和显著的计算效率。我们公开了源代码，以促进未来的研究。"}
{"llm_update_time": "20251023", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2410.06019", "html_url": "https://arxiv.org/abs/2410.06019", "title": "揭开Transformer感知之谜：探索输入流形", "title_en": "Unveiling Transformer Perception by Exploring Input Manifolds", "authors": "Alessandro Benfenati,Alfio Ferrara,Alessio Marta,Davide Riva,Elisabetta Rocchetti", "background": "本文介绍了一种通用方法，用于探索Transformer模型输入空间中的等价类。方法的基础是通过描述Transformer架构内部层为输入流形的顺序变形的数学理论。利用模型雅可比矩阵对输出空间定义的距离度量的拉普拉斯拉格朗日矩阵的特征值分解，能够重建输入空间中的等价类并进行跨越。", "innovation": "本文提出了一种基于数学理论的新方法，通过雅可比矩阵对输出空间定义的距离度量的拉普拉斯拉格朗日矩阵的特征值分解，重构输入空间中的等价类并进行跨越。该方法包括两个互补的探索过程：第一个过程检索产生与原始实例相同类别概率分布的输入实例，从而识别同一等价类中的元素；第二个过程发现产生不同类别概率分布的实例，有效地向不同的等价类导航。", "conclusion": "最后，我们展示了如何通过将检索出的实例嵌入回人类可读形式实现有意义的解释。"}
{"llm_update_time": "20251023", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2406.18851", "html_url": "https://arxiv.org/abs/2406.18851", "title": "LICO：大规模语言模型在分子优化中的基于上下文方法", "title_en": "LICO: Large Language Models for In-Context Molecular Optimization", "authors": "Tung Nguyen,Aditya Grover", "background": "黑盒函数优化是科学和工程中的基本问题。为了解决这个问题，许多方法通过建立一个替代函数来估计算法目标，该替代函数基于有限的历史评估。大规模语言模型（LLMs）以其通过大数据预训练获得的强大模式匹配能力，在替代建模方面表现出潜力。然而，由于预训练语料库中缺乏特定领域的数据以及使用自然语言表达复杂问题的困难，直接通过预训练语言模型生成预测在许多科学领域不可行。面对这一挑战，本文旨在通过改进基于上下文的提示方法，提出LICO，一种适用于黑盒优化的一般方法，特别应用于分子优化领域。", "innovation": "LICO通过为预训练语言模型配备单独的嵌入层和预测层，使其能够针对特定领域的多种函数进行上下文预测性训练，从而实现通用性。经过训练后，LICO可以通过简单的上下文提示来识别未见过的分子属性。特别是在化学和生物化学等分子领域，LICO能够有效地进行分子优化。LICO在PMO基准测试中表现出色，并在低预算版本PMO-1K上达到了最先进的性能。", "conclusion": "LICO通过改进基于上下文的提示方法，成功将预训练语言模型应用于分子优化领域，具备推广到其他科学领域的潜力。"}
{"llm_update_time": "20251023", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2410.10481", "html_url": "https://arxiv.org/abs/2410.10481", "title": "基于模型的大型语言模型定制作为服务", "title_en": "Model-based Large Language Model Customization as Service", "authors": "Zhaomin Wu,Jizhou Guo,Junyi Hou,Bingsheng He,Lixin Fan,Qiang Yang", "background": "现有的大型语言模型（LLM）服务如OpenAI和Google的模型在通用任务上表现出色，但在特定领域应用中却经常表现不佳。当前对这些LLM的定制服务通常需要用户上传数据进行微调，这带来了明显的隐私风险。虽然差异隐私（DP）数据合成提供了一种替代方案，但由于在数据中引入了过多噪音，通常有效性较低。", "innovation": "提出了Llamdex，一个新颖的框架，客户可以上传预训练的领域特定模型以实现LLM的定制服务，而不是上传原始数据。该客户上传的模型可以可选地使用在较低噪声水平下进行DP保护，通过连接模块将其插入基LLM中。重要的是，这些连接模块的训练不需要敏感的领域数据，实现客户在保持数据隐私的情况下定制LLM服务。实验表明，相对于其他方法，在相同的隐私限制条件下，Llamdex能够提高领域特定准确性最高达26%，且通过去除用户在查询中提供领域上下文的需求，维持了与原始服务相当的推理效率。", "conclusion": "Llamdex相比现有方法，不仅提高了领域特定任务的准确性，还保持了与基LLM相同水平的推理效率，同时保护了客户的隐私，为大规模定制LLM提供了新的可操作框架。"}
{"llm_update_time": "20251023", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2411.04372", "html_url": "https://arxiv.org/abs/2411.04372", "title": "使用整数序列生成任务评估大型语言模型", "title_en": "Benchmarking Large Language Models with Integer Sequence Generation Tasks", "authors": "Daniel O'Malley,Manish Bhattarai,Javier Santos,Nishath Rajiv Ranasinghe,Erick Draayer", "background": "本文介绍了一个旨在严格评估大型语言模型（LLMs）在数学推理和算法代码合成任务上的能力的新基准。该基准包括从整数序列在线百科全书（OEIS）获取的整数序列生成任务，测试LLMs直接生成Python代码计算这些序列的能力，而不使用查找表。全面评估包括来自OpenAI、Anthropic、Meta和Google等领先模型在1000个OEIS序列上的表现，这些序列被分类为“简单”或“困难”。为阻止模型利用记忆中的序列值，引入了自动作弊检测机制，并通过与专家评估结果进行比较得到验证。实验证明，专注于推理的模型在复杂任务上的准确性提高了，但在困难序列上的整体表现不佳，突显了算法推理的持续挑战。基准测试提供了有关最新LLM的优势和局限性的重要见解，强调了需要进一步的技术进步来可靠地解决复杂的数学推理任务。", "innovation": "引入了一个精心设计的基准测试，用于评估模型在生成Python代码计算整数序列时的能力，特别是不使用查找表。为防止模型作弊，设计了自动作弊检测机制，该机制通过与专家评估的比较得到验证。特别地，专注于推理的模型在复杂任务上取得了显著提高，但总体性能在困难序列上的表现仍显不足，这揭示了算法推理的关键挑战。", "conclusion": "该基准测试提供了关于先进LLM在数学推理和算法代码合成任务上强项和弱点的重要见解，并强调了需要进一步的技术革新来解决复杂的数学推理任务。"}
{"llm_update_time": "20251023", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2412.00744", "html_url": "https://arxiv.org/abs/2412.00744", "title": "基于目标中心奖励的开放世界无人机主动跟踪", "title_en": "Open-World Drone Active Tracking with Goal-Centered Rewards", "authors": "Haowei Sun,Jinwu Hu,Zhirui Zhang,Haoyuan Tian,Xinze Xie,Yufeng Wang,Xiaohua Xie,Yun Lin,Zhuliang Yu,Mingkui Tan", "background": "无人机视觉主动跟踪旨在根据视觉观察自主跟踪目标对象，并通过控制运动系统提供动态环境中的有效跟踪解决方案。然而，由于缺乏统一基准和开放世界环境中的频繁干扰，基于强化学习的准确无人机视觉主动跟踪仍面临挑战。", "innovation": "首先，我们提出了DAT，这是首个开放世界无人机空地跟踪基准，包括24个城市规模场景，目标具有类人行为并且具有高保真动力学模拟。DAT还提供了一个数字孪生工具以生成无限场景。此外，我们提出了一种新的强化学习方法GC-VAT，该方法旨在改善无人机在复杂场景中的跟踪目标性能。具体而言，我们设计了一个目标中心奖励来为智能体提供精确反馈，并通过不限制视角来扩展感知和运动范围。除此之外，我们还引入了一种基于课程学习的训练策略，逐步提升复杂环境中的跟踪性能。", "conclusion": "在模拟器和实际图像上的实验结果表明，GC-VAT在模拟器上的跟踪成功率约为72%，并且基准和代码已公开发布。"}
{"llm_update_time": "20251023", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2412.01322", "html_url": "https://arxiv.org/abs/2412.01322", "title": "使用柯尔莫哥洛夫-阿诺德网络进行可解释的滚动轴承故障和严重程度分类", "title_en": "Explainable fault and severity classification for rolling element bearings using Kolmogorov-Arnold networks", "authors": "Spyros Rigas,Michalis Papachristou,Ioannis Sotiropoulos,Georgios Alexandridis", "background": "滚动轴承是旋转机械中的关键组件，其性能直接影响工业系统的效率和可靠性。同时，轴承故障是导致机械故障的主要原因之一，往往导致昂贵的停机时间、生产率降低，甚至在极端情况下导致灾难性损坏。现有研究和方法通过自动特征选择、超参数调优和统一框架内的可解释故障分析来解决这些问题，尤其是在特征选取最简化的情况下，框架生成的轻量级模型能通过特征归因和激活函数的符号表示提供解释性结果，这种方法在两个广为人知的轴承故障诊断数据集上得到了验证，模型在故障检测和故障及严重程度分类任务中的表现优异，显示了其处理各种不同类型的故障（如不平衡和错位）的能力，同时模型的符号表示增强了其解释性，特征归因提供了针对每个任务的最佳特征类型或信号的见解。这些结果突显了该框架在实际应用（如实时机械监控）和需要高效可解释模型的科学研究方面的潜力", "innovation": "该研究提出了一种基于柯尔莫哥洛夫-阿诺德网络的方法，该方法包括自动特征选择、超参数调优和统一框架内的可解释故障分析。通过训练浅网络结构，选择少量特征，生成轻量级模型并提供可解释的结果，该方法在两个常见数据集上的表现优秀，包括100%的F1分数，展示了处理多种不同故障类型的能力，并通过符号表示和特征归因增强了模型的解释性。", "conclusion": "该框架在实际应用中的潜力，如实时机械监控，以及在需要高效和可解释模型的科学研究中的应用，显示出在故障检测和严重程度分类方面的优异性能和广泛适用性。"}
{"llm_update_time": "20251023", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2411.13022", "html_url": "https://arxiv.org/abs/2411.13022", "title": "所有人群的快速MRI：通过无需原始数据进行训练来缩小访问差距", "title_en": "Fast MRI for All: Bridging Access Gaps by Training without Raw Data", "authors": "Yaşar Utku Alçalar,Merve Gülle,Mehmet Akçakaya", "background": "物理驱动的深度学习（PD-DL）方法已被广泛应用于提高快速磁共振成像（MRI）扫描的重建质量。尽管PD-DL方法在加速率方面优于现有的临床快速MRI技术，但由于只能在专门的MRI中心使用，其应用场景受到限制。当前的研究还指出，PD-DL方法在应用于罕见病状或不同人群时存在泛化能力不足的问题，需要针对目标人群进行微调才能提高表现。然而，目前的PD-DL训练方法需要访问未经处理的k-space测量数据，只有专门的MRI中心因研究协议而拥有这些数据。这对农村和资源匮乏地区来说尤其难以实现，因为这些地区的商用MRI扫描仪只能提供最终重建图像。", "innovation": "为了应对上述挑战，该论文提出了一种称为CUPID的方法，通过仅使用从MRI扫描仪导出的常规临床重建图像来进行高质量的PD-DL训练。CUPID不仅能够评价输出质量，还能通过精心设计的扰动来保持与临床并行成像重建结果的一致性。实验结果表明，CUPID在无需k-space数据的情况下达到了与现有要求k-space数据的PD-DL方法相当的重建质量，并且在零样本训练场景下表现优于压缩感知（CS）和基于扩散的生成方法，能够证明其对真实采样和前瞻性采样的有效性。因此，CUPID提出了一种减少快速MRI成像障碍的新方法，为远程和农村地区的居民提供了更广泛的机会，而无需专门的MRI中心和数据访问协议。", "conclusion": "作为一种与现有策略截然不同的方法，CUPID有望通过仅使用临床重建图像来提供高质量的PD-DL训练，从而进一步推动快速MRI的普及应用，特别是对于农村和资源匮乏地区而言。这种新的训练方法极大地减少了数据需求，降低了训练负担，具有广泛的应用前景。"}
{"llm_update_time": "20251023", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2410.10101", "html_url": "https://arxiv.org/abs/2410.10101", "title": "在多项式时间内学习线性注意力", "title_en": "Learning Linear Attention in Polynomial Time", "authors": "Morris Yau,Ekin Akyürek,Jiayuan Mao,Joshua B. Tenenbaum,Stefanie Jegelka,Jacob Andreas", "background": "以往的研究已经探索了Transformer模型在模拟布尔电路或图灵机方面的计算表达能力。但是，从观察性数据中学习这些模拟器的问题尚未得到解决。本研究填补了这一空白，提供了第一个支持单层Transformer（特别是具有线性注意力的强、泛化的PAC学习）的多项式时间可学习结果。研究指出，线性注意力可以视为适当定义的RKHS中的线性预测器。因此，学习任何线性Transformer的问题可以通过转换为在扩展特征空间中学习普通线性预测器来解决，任何预测器都可能进一步转换回多头线性Transformer。进一步研究显示，可以通过高效方法识别训练数据集，使得每个经验风险最小化器与生成数据的线性Transformer等价（至微不足道的对称性），从而保证学习模型将正确泛化所有输入。最后，展示了通过线性注意力表达且多项式时间内可学习的计算，包括关联记忆、有限自动机及一类具有多项式计算历史的通用图灵机（UTM）。理论验证在学习随机线性注意力网络、键-值关联和执行有限自动机三项任务中得到了验证。本研究填补了Transformer理论表达能力和可学习性之间的关键差距，并展示了灵活和通用计算模型的高效可学习性。", "innovation": "首次提供了单层Transformer（特别是具有线性注意力的）的多项式时间可学习结果，具体为强、泛化的PAC学习。指出了线性注意力可以作为适当的RKHS中的线性预测器，并将学习任何线性Transformer的问题转换为在扩展特征空间中学习普通线性预测器的问题。进一步展示了通过线性注意力表达且多项式时间内可学习的特定计算类型。提出了高效的训练数据集识别方法，保证学习模型泛化所有输入。", "conclusion": "研究填补了Transformer理论表达能力和可学习性之间的关键差距，并展示了灵活和通用计算模型的高效可学习性。通过理论验证和具体计算案例明确展示了Transformer模型在多项式时间内高效可学习的能力。"}
{"llm_update_time": "20251023", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2501.13133", "html_url": "https://arxiv.org/abs/2501.13133", "title": "使用扩散生成模型进行图表示学习", "title_en": "Graph Representation Learning with Diffusion Generative Models", "authors": "Daniel Wesego", "background": "扩散模型因其能够准确近似复杂数据分布，已在图像和视频等不同数据模态中确立了作为最先进的生成模型的地位。与传统的生成方法（如VAE和GAN）相比，扩散模型采用逐步去除噪声的过程，在多个迭代步骤中将噪声转化为有意义的数据，这种方法提高了模型的表达能力和生成质量。此外，扩散模型还能够从数据中提取有意义的表征，同时学习生成样本。然而，将扩散模型应用于图结构数据的研究尚处于起步阶段，主要是由于图数据的离散性，这需要与其它领域中使用的连续扩散过程不同的离散扩散过程。", "innovation": "本文利用扩散模型的表示能力，开发了一种将离散扩散模型训练在自动编码器框架中的方法，从而实现针对图结构数据的高效自动编码和定制化表示学习。模型的表示是从编码器的输出和解码器的第一个时间步骤隐藏嵌入的组合中提取的。该方法展示了离散扩散模型在图表示学习中的潜力。", "conclusion": "实验结果表明了离散扩散模型在图表示学习中的应用潜力。所提出的方法可以用于有效提取和学习图数据的有意义表示。"}
{"llm_update_time": "20251023", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2502.00937", "html_url": "https://arxiv.org/abs/2502.00937", "title": "ModServe: 模态和阶段感知的资源解耦聚合以构建可扩展的多模态模型服务系统", "title_en": "ModServe: Modality- and Stage-Aware Resource Disaggregation for Scalable Multimodal Model Serving", "authors": "Haoran Qiu,Anish Biswas,Zihan Zhao,Jayashree Mohan,Alind Khare,Esha Choukse,Íñigo Goiri,Zeyu Zhang,Haiying Shen,Chetan Bansal,Ramachandran Ramjee,Rodrigo Fonseca", "background": "大型多模态模型（LMMs）在理解和处理图像、视频和音频方面展现了令人印象深刻的性能。然而，在生产环境中高效地部署这些复杂且具有异构特性的模型架构面临着巨大挑战。本文对两个主要的LMM架构——解码器和交叉注意力机制，在六种代表性开源模型上进行全面系统的分析，揭示了关键的设计影响。研究还深入分析了生产多模态模型推理的时间序列，发现了请求分布的可变性和长尾分布以及突发流量模式等独特的工作负载特征。", "innovation": "提出了ModServe，一种模块化多模态模型服务系统，将各阶段解耦以独立优化和自适应扩展。ModServe通过模态感知调度和自适应扩容动态重新配置各阶段，以满足尾延迟SLAs的同时降低成本。实验结果表明，ModServe的吞吐量提高了3.3-5.5倍（成本减少25-41.3%），并且在具有生产级时间序列的128-GPU集群上满足SLAs。", "conclusion": "ModServe通过模块化设计和模态、阶段感知的调度与扩容策略，在满足延迟要求的前提下显著提高了多模态模型服务的效率与成本效益。"}
{"llm_update_time": "20251023", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2501.04961", "html_url": "https://arxiv.org/abs/2501.04961", "title": "解析面向金融大语言模型的域适应后训练", "title_en": "Demystifying Domain-adaptive Post-training for Financial LLMs", "authors": "Zixuan Ke,Yifei Ming,Xuan-Phi Nguyen,Caiming Xiong,Shafiq Joty", "background": "大语言模型（LLMs）在医学和金融等专门领域中的域适应后训练已成为一种有 promise 的方法。然而，识别最佳适应标准和跨不同数据和模型配置进行训练的战略仍然存在重大挑战。为了解决这些挑战，我们引入了 FINDAP 方法，这是一种系统的方法，以细粒度的方式探究面向金融领域的 LLM 域适应后训练。该方法包括四个关键组成部分：定义目标领域所需核心能力的 FinCap，联合优化延续性预训练和指令跟随的有效训练食谱 FinRec，以及一种利用生成奖励模型的进程信号来进行新颖偏好数据蒸馏的新方法；支持 FinRec 的精炼训练数据集 FinTrain；和与 FinCap 对齐的综合评估套件 FinEval。最终，所建立的 Llama-Fin 模型在多种金融任务上达成了最佳水平。此外，我们的分析还揭示了每个后训练阶段如何贡献独特的功能，发现特定挑战及有效解决方案，为 LLM 的领域适应提供了宝贵的见解.", "innovation": "我们提出了一种名为 FINDAP 的系统性方法，细粒度地探究面向金融领域的大语言模型的域适应后训练。该方法由包含下列关键组件组成：定义目标领域所需核心能力的 FinCap；FinRec 培训方案，旨在同时优化延续性预训练和指令遵循，以及一种与生成奖励模型相关的新颖偏好数据蒸馏方法；支持 FinRec 的精心策划的训练数据集 FinTrain；以及结合 FinCap 的全面评估套件 FinEval。通过这种方法，Llama-Fin 模型在广泛金融任务上达到了最先进水平。我们的分析也指出了每个后训练阶段的具体贡献，并发现了特定挑战和有效的解决方案，为 LLM 的领域适应提供了宝贵的见解.", "conclusion": "我们的分析表明，每个后训练阶段对特定功能都有独到的贡献，并揭示了一些挑战及其有效的解决方法。这意味着对于 LLM 的领域适应，每个阶段都有其独特的重要性。我们应该在实践中生动利用这些途径，并在研究中持续改进以达到最佳效果。"}
{"llm_update_time": "20251023", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2502.02197", "html_url": "https://arxiv.org/abs/2502.02197", "title": "在签注网络中高效局部搜索方法用于极化社区发现", "title_en": "An Efficient Local Search Approach for Polarized Community Discovery in Signed Networks", "authors": "Linus Aronsson,Morteza Haghir Chehreghani", "background": "签注网络是一种边被标记为正或负以表示友好或敌对互动的网络，为分析社交系统中的极化、信任和冲突提供了自然框架。识别这种网络中有意义的群体结构是理解在线交流、政治分化和信任动态的关键。主要挑战在于识别内部团结且对外敌视的社区，同时允许中立或未对齐的顶点。", "innovation": "提出了一种识别$k$个极化社区的方法，克服了以前方法可能会产生大小极不平衡的解决方案这一主要缺陷。引入了一种新的优化目标来避免这种不平衡，并设计了第一个适用于带中立顶点情况的局部搜索算法，能够扩展到大规模网络。通过将方法与块坐标弗朗克-沃尔夫优化联系起来，证明了线性收敛速率，通过优化目标结构实现。实验结果表明，该方法在解的质量上优于最先进的基线方法，同时在计算效率上保持竞争力。", "conclusion": "通过实验表明，本方法在解决极化社区发现问题时具有出色的效果，同时在计算效率上有竞争力。"}
{"llm_update_time": "20251023", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2502.10273", "html_url": "https://arxiv.org/abs/2502.10273", "title": "在大型视觉-语言模型中探究感知恒常性", "title_en": "Probing Perceptual Constancy in Large Vision-Language Models", "authors": "Haoran Sun,Bingyang Wang,Suyang Yu,Yijiang Li,Qingying Gao,Haiyun Lyu,Hokin Deng,Dezhi Luo", "background": "感知恒常性是指在感官输入变化（如距离、角度或光照变化）的情况下，保持对物体稳定感知的能力。这种能力对于动态世界中的视觉理解至关重要。本文探讨了当前的视觉-语言模型（VLMs）在这一方面的表现。在本研究中，研究人员评估了155个VLMs在三个领域上的性能：颜色、大小和形状恒常性。这些评估通过单图像和视频经典认知任务的适应，以及在自然环境中的新型任务进行。研究发现，VLMs在这三个领域上的表现存在显著差异，形状恒常性的表现与其他颜色和大小恒常性存在明显的区别。", "innovation": "本研究通过广泛的任务和新颖的场景对大量VLMs进行了评估，揭示了当前模型在感知恒常性方面存在的显著差异，尤其是形状恒常性与其他属性的分离表现。这为后续研究提供了新的见解，也为理解视觉-语言模型的能力范围提供了依据。", "conclusion": "研究表明，当前的VLMs在感知恒常性方面表现存在显著差异，尤其是形状恒常性的表现与其他颜色和大小恒常性存在明显的区别。这提示未来的模型训练和设计需要考虑不同类型的感知恒常性，并探索改善模型在这方面的性能的新方法。"}
{"llm_update_time": "20251023", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2503.01298", "html_url": "https://arxiv.org/abs/2503.01298", "title": "统一生成模型中通过多模态链式思维增强图像生成能力", "title_en": "Towards Enhanced Image Generation Via Multi-modal Chain of Thought in Unified Generative Models", "authors": "Yi Wang,Mushui Liu,Wanggui He,Hanyang Yuan,Longxiang Zhang,Ziwei Huang,Guanghao Zhang,Wenkai Fang,Haoze Jiang,Shengxuming Zhang,Dong She,Jinlong Liu,Weilong Dai,Mingli Song,Hao Jiang,Jie Song", "background": "统一生成模型在文本和图像生成任务中表现出色。对于图像合成任务，现有的模型采用直接的文本到图像（T2I）生成方法。然而，这种直接的T2I生成方法限制了模型处理复杂组合指令的能力，而这些复杂组合指令在现实世界中经常出现。尽管这是一个重要的问题，但现有工作主要集中在提高模型的基本图像生成能力上，而这些改进只能在某种程度上解决问题。", "innovation": "本文借鉴链式思维（CoT）解决问题的方法，将其引入统一生成模型中，以应对直接T2I生成方法无法有效解决的复杂图像生成挑战。为此，论文提出了一种功能导向的专家（FoXperts）架构，该架构在模型FoX中采用专家并行架构并按功能分配专家，从而解决了潜在冲突，并为CoT提供了坚实的基础。此外，论文还提出了多模态链式思维（MCoT）方法，并开发了一种多任务联合训练方案，以使模型在每个MCoT步骤中具有所需的所有能力。实验结果表明，FoX在多种T2I基准测试中均优于现有统一模型，并在复杂图像生成方面取得了显著改进。", "conclusion": "本文通过引入多模态链式思维（MCoT）方法和功能导向专家（FoXperts）架构，显著提升了统一生成模型在复杂图像生成任务中的性能。"}
{"llm_update_time": "20251023", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2503.07663", "html_url": "https://arxiv.org/abs/2503.07663", "title": "Merge then Realign: Simple and Effective Modality-Incremental Continual Learning for Multimodal LLMs", "title_en": "Merge then Realign: Simple and Effective Modality-Incremental Continual Learning for Multimodal LLMs", "authors": "Dingkun Zhang,Shuhan Qi,Xinyu Xiao,Kehai Chen,Xuan Wang", "background": "最近的多模态大型语言模型（MLLMs）的发展使其通过整合越来越多的模态性而变得更加多样化。然而，由于训练MLLMs成本高昂，有效的重用和扩展现有模型至更多模态的方式——即模态增量连续学习（MCL）——变得非常重要。目前，MCL的研究尚处于初级阶段。", "innovation": "提出了一个简单有效的MCL框架——“Merge then Realign”（MERA），该框架能够同时解决传统的连续学习中的遗忘问题和模态无关和模态特定组件之间的不匹配问题。MERA不需要引入额外的模型开销或修改模型结构，因此易于部署并高度可重用。广泛的实验表明，MERA在扩展至四个模态时性能表现优异，平均保持了99.84%的后向相对增益。", "conclusion": "我们的研究阐明了MCL中的不匹配问题，并展示如何调整MLLMs的不同组件以提高其在连续学习中的性能。"}
{"llm_update_time": "20251023", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2503.12499", "html_url": "https://arxiv.org/abs/2503.12499", "title": "PTFA: 一种基于大语言模型促进在线共识构建的并行思维代理", "title_en": "PTFA: An LLM-based Agent that Facilitates Online Consensus Building through Parallel Thinking", "authors": "Wen Gu,Zhaoxing Li,Jan Buermann,Jim Dilkes,Dimitris Michailidis,Shinobu Hasegawa,Vahid Yazdanpanah,Sebastian Stein", "background": "共识构建由于利益相关者持有不同的观点而固有地具有挑战性。有效的促进对于支持共识构建过程并促进高效的群体决策至关重要。然而，促进的有效性往往受到如经验有限和扩展性不足等人因因素的限制。因此，需要更智能和自动化的促进方式来克服这些限制，从而提高共识构建过程的效率和有效性。", "innovation": "本文提出了一种基于并行思维的促进代理（PTFA），这是一种能够自动收集实时文本输入并使用大语言模型（LLMs）并行执行Six Thinking Hats技术中的六个角色的促进方式，从而促进在线、文本形式下的共识构建。该代理已经在试点研究中显示出在创意生成、情感探究以及深入分析创意质量方面的潜力。", "conclusion": "该研究识别了一些未来的研究挑战，如在发散阶段优化时间调度和管理行为，并构建了一个包含参与者之间以及参与者与代理之间的对话内容的全面数据集，为未来的研究提供了支持。"}
{"llm_update_time": "20251023", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2503.01872", "html_url": "https://arxiv.org/abs/2503.01872", "title": "FairGen: 通过自适应潜在指导控制扩散模型生成中的敏感属性以实现公平生成", "title_en": "FairGen: Controlling Sensitive Attributes for Fair Generations in Diffusion Models via Adaptive Latent Guidance", "authors": "Mintong Kang,Vinayshekhar Bannihatti Kumar,Shamik Roy,Abhishek Kumar,Sopan Khosla,Balakrishnan Murali Narayanaswamy,Rashmi Gangadharaiah", "background": "文本到图像的扩散模型往往存在对特定人口统计群体的偏见，比如在生成工程师图像时倾向于生成更多的男性角色，这引发了伦理上的担忧并限制了其应用。研究发现扩散模型生成中存在偏见，并且在特定属性（如性别）上可能偏好特定类别。为解决这些问题，本文致力于在保持生成质量的同时，减轻扩散模型生成偏见，特别是任何目标属性值的偏见（例如，性别中的“male”）。背景提到当前对数据集的局限性，提出了一个全面评价偏见的新基准Holistic Bias Evaluation (HBE)，以更深入地评估偏见情况。", "innovation": "本文提出了一种名为FairGen的方法，这是一个自适应潜在指导机制。FairGen包含一个能够动态调整扩散过程以强制执行特定属性的潜在指导模块，以及一个记录生成统计并引导潜在指导以与目标公平分布对齐的记忆模块。此外，FairGen不仅能减少特定属性的偏见，还能灵活控制用户指定粒度下的输出分布，确保特定目标的适应性偏见缓解。", "conclusion": "在HBE和Stable Bias数据集上的广泛测试表明，FairGen相较于现有偏见缓解方法表现更优，能够实现显著的偏见减少（如在Stable Diffusion 2上性别偏见减少了68.5%）。通过消融研究进一步验证了FairGen在任何用户指定粒度上灵活控制输出分布的能力，确保了高度适应性和针对性的偏见缓解。"}
{"llm_update_time": "20251023", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2503.12730", "html_url": "https://arxiv.org/abs/2503.12730", "title": "TinySQL：一种渐进式文本到SQL数据集，用于机理可解释性研究", "title_en": "TinySQL: A Progressive Text-to-SQL Dataset for Mechanistic Interpretability Research", "authors": "Abir Harrasse,Philip Quirke,Clement Neo,Dhruv Nathawani,Luke Marks,Amir Abdullah", "background": "机制可解释性研究在分析玩具任务中的简单电路和大型模型中发现特征之间存在差距。为了解决这个问题，我们提出了文本到SQL生成作为一项理想的任务来进行研究，因为它结合了玩具任务的形式结构和现实世界的复杂性。我们引入了TinySQL，一个合成数据集，从基本到复杂的SQL操作逐步推进，并训练参数从33M到1B的模型，以建立一个全面的可解释性测试平台。", "innovation": "我们通过引入TinySQL数据集和应用多种互补的可解释性技术（如边缘归因修补和稀疏自编码器），识别支持SQL生成的最小电路和组件，并分析了不同SQL子技能的电路，评估其简洁性、可靠性和可识别性。最后，我们进行了逐层逻辑因子分析，揭示了模型在不同层如何组合生成SQL查询。", "conclusion": "我们的工作提供了一个在结构化渐进复杂环境中的可解释性方法探测和比较的 robust框架。"}
{"llm_update_time": "20251023", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2503.08221", "html_url": "https://arxiv.org/abs/2503.08221", "title": "EgoBlind: 朝着盲人自主视觉辅助", "title_en": "EgoBlind: Towards Egocentric Visual Assistance for the Blind", "authors": "Junbin Xiao,Nanxin Huang,Hao Qiu,Zhulin Tao,Xun Yang,Richang Hong,Meng Wang,Angela Yao", "background": "论文介绍了一种名为EgoBlind的新数据集，该数据集旨在通过从盲人个体收集的自视点视频来评估现代多模态大规模语言模型（MLLMs）的帮助能力。EgoBlind包含来自盲人和视力受损个体日常生活的一千三百九十二个第一人称视角视频，以及五千三百一十一道直接由盲人提出的或验证的问题，以反映他们在实际情境中对视觉辅助的需求。每个问题都附有三个手动注释的参考答案，以减少主观性。", "innovation": "EgoBlind是第一个专注于盲人士群的自视点视频问答数据集，旨在评估MLLMs在视觉辅助方面的性能。论文不仅展示了详细的实验结果，而且通过与人类表现相对比，揭示了现有MLLMs中的主要局限性，并提出了改进方案。", "conclusion": "通过这些努力，EgoBlind有望成为开发有效的人工智能助手中的基础，提高盲人和视力受损人群的独立性。论文中的数据和代码可以在指定的链接获取。"}
{"llm_update_time": "20251023", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2503.18129", "html_url": "https://arxiv.org/abs/2503.18129", "title": "GeoBenchX：评估LLMs在多步地理空间任务中代理解决能力的基准", "title_en": "GeoBenchX: Benchmarking LLMs in Agent Solving Multistep Geospatial Tasks", "authors": "Varvara Krechetova,Denis Kochedykov", "background": "本文旨在建立一个基准来评估大型语言模型（LLMs）在与商业地理信息系统（GIS）从业者相关的多步骤地理空间任务中的工具调用能力。研究使用了一个简单的工具调用代理，并配备了23个地理空间功能，对八种商用LLMs进行了评估。", "innovation": "该研究开发了一个LLM-as-Judge评估框架来比较代理解决方案与参考解决方案之间的差异。同时，该研究还提出了一个基准集、评估框架和数据生成管道，这些资源都被释放为开源资源，为持续评估LLMs在GeoAI中的应用提供了标准化方法。", "conclusion": "研究发现，o4-mini和Claude 3.5 Sonnet的整体性能最好，而OpenAI的GPT-4.1、GPT-4o和Google的Gemini 2.5 Pro Preview在识别无法解决问题方面表现得更为高效。研究还指出了一些常见的错误，如误解几何关系、依赖过时的知识、以及不高效的數據处理。"}
{"llm_update_time": "20251023", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2503.13414", "html_url": "https://arxiv.org/abs/2503.13414", "title": "离散马尔可夫决策过程中可验证高效奖励转移的强化学习", "title_en": "Provably Efficient Reward Transfer in Reinforcement Learning with Discrete Markov Decision Processes", "authors": "Kevin Vora,Yu Zhang", "background": "在强化学习(RL)中，当学习目标行为时，可以利用已知的源行为（在相同环境动力学下但具有不同奖励函数的学习行为）。虽然可以从头开始学习目标行为是可能的，但在利用已有的源行为方面，这通常效率较低。本文提出了一种基于Q函数操作的新奖赏适应(RA)方法，通过将目标奖励函数表示为源奖励函数的函数，推导出Q函数的边界，提供了一种迭代过程来逐步减小这些边界，从而在学习之前从行为上进行修剪，确保优化的连续性和计算效率.", "innovation": "本文提出了一种名为“Q-Manipulation”(Q-M)的新方法，它通过操纵Q函数帮助奖赏转移，这种方法在离散域中被正式证明不会影响返回策略的最优性，并在概率意义上证明了它的计算效率。迭代过程假设可以访问轻量级模型，且这种模型容易提供或学习。Q-M方法在多种合成和模拟环境中被评估，以展示其有效性和适用性.", "conclusion": "最终证明了Q-M方法在离散马尔可夫决策过程中具有可验证的高效性，能够提高奖赏转移的效率和效果。"}
{"llm_update_time": "20251023", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2504.07711", "html_url": "https://arxiv.org/abs/2504.07711", "title": "使用最优传输合并嵌入主题进行数据流在线话题建模", "title_en": "Merging Embedded Topics with Optimal Transport for Online Topic Modeling on Data Streams", "authors": "Federica Granese,Benjamin Navet,Serena Villata,Charles Bouveyron", "background": "主题建模是无监督学习中的关键组成部分，用于识别文本数据集中的主题。社交媒体的快速发展产生了大量的文本数据流，实时处理这些不断更新的数据流需要在线主题建模方法。现有的在线主题模型方法无法有效处理数据流中的不均衡分布问题。本文提出了一种新的基于嵌入主题模型的在线主题建模方法StreamETM，该方法利用不均衡最优 transport 将连续部分文档批次学习到的模型合并起来。此外，引入了一种在线变化点检测算法来识别时间点上主题的变化，有助于文本流动态的一系列显著变化的识别。", "innovation": "本文提出了一种新的在线主题建模方法StreamETM，该方法通过不均衡最优 transport 合并连续部分文档批次学到的模型，并利用在线变化点检测算法识别主题变化。实验结果显示，所提出的方法在模拟数据和真实数据上的性能优于现有方法。", "conclusion": "本文通过引入基于嵌入主题模型和不均衡最优 transport 的在线主题建模方法 StreamETM，以及在线变化点检测算法，显著提高了对文本数据流中主题变化的识别能力。实现了在不断更新的数据流中有效而准确地识别主题，为处理大量不断生成的文本数据提供了有效的解决方案。"}
{"llm_update_time": "20251023", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2504.09909", "html_url": "https://arxiv.org/abs/2504.09909", "title": "量子自然语言处理：模型、方法与应用的全面综述", "title_en": "Quantum Natural Language Processing: A Comprehensive Review of Models, Methods, and Applications", "authors": "Farha Nausheen,Khandakar Ahmed,M Imad Khan,Farina Riaz", "background": "近年来，应用于自然语言处理（NLP）领域的深度学习方法虽然提高了性能，但需要大量的数据和计算资源进行训练。量子计算利用量子力学原理克服了当前技术的计算局限性，形成了量子自然语言处理（QNLP）领域。该领域有可能在处理语言结构方面超越经典模型，实现更高的效率和更精确的性能。", "innovation": "本文旨在通过量子计算原理、架构和计算方法对QNLP模型进行分类，并提供对量子计算如何与语言结合的综述。本文还通过探索量子编码技术、针对常见NLP任务的量子NLP模型以及用于超参数调优的量子优化技术来梳理QNLP领域的最新进展。", "conclusion": "量子计算方法在各种NLP任务中的应用现状被总结，具体方法的数量反映了这些方法的流行程度。研究表明，目前QNLP方法主要适用于小数据集，只有少数模型得到了广泛探索，对于量子计算应用于NLP任务的兴趣正在增加。"}
{"llm_update_time": "20251023", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2505.07897", "html_url": "https://arxiv.org/abs/2505.07897", "title": "LongCodeBench：在100万上下文窗口下评估编程LLM", "title_en": "LongCodeBench: Evaluating Coding LLMs at 1M Context Windows", "authors": "Stefano Rando,Luca Romani,Alessio Sampieri,Luca Franco,John Yang,Yuta Kyuragi,Fabio Galasso,Tatsunori Hashimoto", "background": "近年来，模型的上下文长度迅速增长，从几千个token增加到数百万个token。现代长上下文模型的极端上下文大小使得构建具有现实意义和大上下文的基准测试变得困难，不仅因为收集百万级别任务的成本问题，还因为难以识别需要大量上下文的现实场景。", "innovation": "论文识别了代码理解和修复作为长上下文模型的自然测试领域，并引入了LongCodeBench（LCB），这是一个用于测试LLM在长上下文场景中编程能力的基准测试。LCB通过从GitHub实际问题中抽取数据，构建了问答（LongCodeQA）和bug修复（LongSWE-Bench）任务，从而仔细分层了基准测试的复杂性，使得不同规模的模型可以在不同尺度上进行评估。", "conclusion": "研究表明，所有模型在长上下文方面仍然存在弱点，如Claude 3.5 Sonnet从29%下降到3%，Qwen2.5从70.2%下降到40%。LCB数据集可以在以下链接中获取：这个 https URL，相关代码库可以在以下链接中找到：这个 https URL。"}
{"llm_update_time": "20251023", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2504.03931", "html_url": "https://arxiv.org/abs/2504.03931", "title": "NAACL2025 Tutorial: 大型语言模型的适应技术", "title_en": "NAACL2025 Tutorial: Adaptation of Large Language Models", "authors": "Zixuan Ke,Yifei Ming,Shafiq Joty", "background": "虽然通用语言模型（LLMs）展现出了普遍任务上的强泛化能力，但在特定领域如金融、医疗和小语种代码生成等方面表现不佳。它们的静态性质限制了它们的适应能力，且规模庞大，这使得大规模部署变得不切实际和成本高昂。因此，LLMs的适应技术自其诞生以来就吸引了极大的关注，并且对于关注满足特定用户需求的工业界和可以从小型但强大的LLMs中获益的学术界来说，这都是至关重要的。", "innovation": "本教程提供了大型语言模型适应技术的概览，从数据和模型两个角度介绍了适应技术。重点讨论了与传统技术不同的评估指标和基准。分类了适应技术为两大类：参数知识适应和半参数知识适应。参数知识适应关注于更新模型内的参数知识，而半参数知识适应则尝试通过检索增强生成（RAG）和基于代理系统等方式来更新模型参数，更好地利用外部知识或工具。同时，还讨论了实现实时适应的技术，如模型编辑，这允许LLMs在生产环境中动态更新其参数。", "conclusion": "通过本教程，读者可以全面了解大型语言模型适应技术的现状，认识到这类技术的重要性，并了解实现这些技术的方法和潜在应用。这将为工业和学术界提供有价值的信息和服务，推动大型语言模型在特定领域的进一步发展和应用。"}
{"llm_update_time": "20251023", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2505.08727", "html_url": "https://arxiv.org/abs/2505.08727", "title": "记忆-压缩循环提高泛化能力", "title_en": "Memorization-Compression Cycles Improve Generalization", "authors": "Fangyuan Yu", "background": "该研究通过理论证明和实验证明，泛化不仅可以通过数据扩展提高，还可以通过压缩内部表示来实现。研究者通过观察到语言模型（LLM）预训练过程中出现的记忆-压缩周期现象，进一步探索了这一过程。", "innovation": "研究团队介绍了信息瓶颈语言建模（IBLM）目标，将其重新定义为一个约束优化问题：通过优化预测性能同时最小化表示熵。在此基础上，他们提出了渐进相变（GAPT）训练算法，该算法会在学习和压缩阶段之间自动切换，从而减少表示干扰，改进交叉熵并提高出域泛化能力。", "conclusion": "GAPT算法在GPT-2预训练任务上应用时，能使矩阵导向的熵（MBE）减少50%，交叉熵提高4.8%，出域泛化能力提高35%。在模拟灾难性遗忘的设置中，GAPT减少了因压缩和分离表示而产生的干扰，分离度提升了97%。"}
{"llm_update_time": "20251023", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2505.11576", "html_url": "https://arxiv.org/abs/2505.11576", "title": "基于神经片段的概念引导可解释性", "title_en": "Concept-Guided Interpretability via Neural Chunking", "authors": "Shuchen Wu,Stephan Alaniz,Shyamgopal Karthik,Peter Dayan,Eric Schulz,Zeynep Akata", "background": "神经网络通常被视为黑箱，这意味着理解其内部运作和交互具有重大挑战。本文提出了一种不同的视角，挑战现有观点：神经网络不仅不是不可理解的，它们的原始群体活动表现出与训练数据中的规律性对应的模式。", "innovation": "提出了从认知原理和自然数据结构出发，通过对神经群体动态进行可解释的拆分，提取与概念相关的片段的方法。提出了三种互补的方法来在神经群体水平上提取重复的片段，分别是离散序列片段化（DSC）、群体平均（PA）和无监督片段发现（UCD），并证明这些片段在控制网络行为时具有因果作用。", "conclusion": "本文工作为可解释性提供了一种新方向，通过利用认知原理和自然数据结构揭示复杂学习系统的隐藏计算，逐步将这些系统从黑箱转变为可理解的系统。"}
{"llm_update_time": "20251023", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2505.09160", "html_url": "https://arxiv.org/abs/2505.09160", "title": "利用对比和掩码自编码学习多任务基础模型进行无线信道表示", "title_en": "A Multi-Task Foundation Model for Wireless Channel Representation Using Contrastive and Masked Autoencoder Learning", "authors": "Berkay Guler,Giovanni Geraci,Hamid Jafarkhani", "background": "目前，自监督学习在无线信道表示中的应用经常借用文本和图像处理领域的范式，但未充分考虑无线通信的独特特性和限制。", "innovation": "本文介绍了一种名为ContraWiMAE（无线对比掩码自编码器）的新颖变压器基础模型，它统一了无线信道表示中的掩码重建和掩码对比学习。关键创新在于一种受无线环境启发的新对比目标，利用了无线环境固有的噪声、衰落和部分可观测特性作为自然增强手段。", "conclusion": "通过在未见场景中的广泛评估，本文展示了该方法在多个下游任务（跨频段波束选择、视距检测和信道估计）上的有效性。ContraWiMAE在各种无线环境中具有优异的线性可分性和适应性，即使在具有挑战性的条件下仍表现出了高效的数据利用能力和与监督基线竞争的表现。与最先进的无线信道基础模型的比较表明，本文方法在性能和数据效率方面都表现优越，展示了其作为未来研究中自监督无线信道表示学习强基线的潜力。同时，本文发布了ContraWiMAE的模型权重和训练管道以促进进一步的研究。"}
{"llm_update_time": "20251023", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2505.14455", "html_url": "https://arxiv.org/abs/2505.14455", "title": "CtrlDiff: 动态块预测与可控生成增强大规模扩散语言模型", "title_en": "CtrlDiff: Boosting Large Diffusion Language Models with Dynamic Block Prediction and Controllable Generation", "authors": "Chihan Huang,Hao Tang", "background": "尽管自回归模型在近年来的语言模型领域占主导地位，但人们对探索替代的下一词预测框架的可行方案产生了浓厚兴趣。基于扩散的语言模型因其强大的并行生成能力和固有的编辑性而成为一项有吸引力的替代方案。然而，这些模型通常受限于固定长度的生成。一种有希望的方向是结合这两种范式的优点，将序列分割成块，建模块之间的时间依赖关系，同时利用离散扩散来估计给定前缀上下文的条件分布。不过，这些模型的实际应用受到了关键限制：僵化的固定长度输出和缺乏灵活的控制机制。因此，本文针对当前大规模扩散语言模型中固定粒度和弱控制力的核心限制提出了解决方案", "innovation": "本文提出了一种名为CtrlDiff的动态和可控的半自回归框架，该框架利用强化学习自适应地确定每个生成块的大小，基于局部语义。同时，引入了一种针对离散扩散的分类器导向控制机制，这能显著减少计算成本，同时允许高效的事后调节而无需重新训练。实验结果表明，CtrlDiff在混合扩散模型中确立了新标准，缩小了与最先进的自回归方法之间的性能差距，并在各种任务中实现了有效的条件文本生成", "conclusion": "CtrlDiff旨在解决当前大规模扩散语言模型的关键限制，通过动态和可控的方式增强模型性能。实验结果显示，该方法不仅能够与最先进的自回归模型竞争，还在多样化的任务中实现了有效的条件文本生成。"}
{"llm_update_time": "20251023", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2505.15754", "html_url": "https://arxiv.org/abs/2505.15754", "title": "通过使用时间扩展动作改善规划和基于模型的强化学习", "title_en": "Improving planning and MBRL with temporally-extended actions", "authors": "Palash Chatterjee,Roni Khardon", "background": "连续时间系统通常用离散时间动力学来建模，但这也要求使用较小的仿真时间步长以保持准确性，这又导致需要较大的规划时间窗口，从而带来了计算量大的规划问题并降低了性能。在无模型的强化学习领域，已经有一部分工作利用动作重复解决这个问题，即通过学习一个策略来决定离散动作的持续时间。与此不同，本文提出了直接控制连续决策时间尺度的方法，通过使用时间扩展的动作，让计划者将行动持续时间作为额外的优化变量，与标准动作变量一起处理。", "innovation": "本文提出的一种创新是利用时间扩展动作直接控制持续时间，这种方法不仅加速了轨迹的仿真时间，还允许在使用浅层规划搜索深度的情况下进行深层的动作基础动作时间搜索。此外，在基于模型的强化学习框架下，这种方法减少了由于模型学习而产生的累积误差，并提高了模型的训练时间。同时，通过使用多臂 bandit 的形式自动选择动作持续时间范围，并将其集成到基于模型的强化学习框架中。", "conclusion": "实验结果表明，这种方法是有效的，可以自动选定动作持续时间的范围，并将其融入基于模型的强化学习框架中。广泛的经验评价显示，该方法能够提供更快的规划速度和更好的解决方案，并能够解决在标准变法下无法解决的问题。"}
{"llm_update_time": "20251023", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2505.16705", "html_url": "https://arxiv.org/abs/2505.16705", "title": "概念瓶颈模型的分析：测量、理解与减轻噪声标签影响", "title_en": "An Analysis of Concept Bottleneck Models: Measuring, Understanding, and Mitigating the Impact of Noisy Annotations", "authors": "Seonghwan Park,Jueun Mun,Donghyun Oh,Namhoon Lee", "background": "概念瓶颈模型（CBMs）通过将预测分解成可解释的概念来确保可解释性。然而，用于训练CBMs的标注数据往往是噪声的，但噪声的影响尚不清楚。这项研究首次系统地探讨了CBMs中的噪声，并展示了即使中等程度的噪声同时损害了预测性能、可解释性和干预效果。", "innovation": "提出了一个两阶段框架以减轻概念瓶颈模型中的脆弱性。首先，在训练阶段，通过敏感性意识最小化稳定噪声敏感概念的学习。其次，在推断阶段，当可用清晰标签时，通过预测熵对概念进行排名，并仅纠正最不确定的概念，使用不确性作为对敏感性的代理。理论分析和广泛的消融实验说明了为什么敏感性意识训练能提供鲁棒性，并且为什么不确定性可靠地识别出敏感概念，从而在噪声存在的情况下同时保持可解释性和抗干扰性。", "conclusion": "研究揭示了一个易受影响的概念子集，其准确性下降远远超过嘈杂监督与干净监督之间的平均差距，并且其破坏导致了大部分性能损失。提出了减轻脆弱性的理论基础和方法，确保在噪声存在的情况下同时保持可解释性和鲁棒性。"}
{"llm_update_time": "20251023", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2505.18817", "html_url": "https://arxiv.org/abs/2505.18817", "title": "高阶交换对称流匹配方法在密度泛函理论哈密顿量预测中的应用", "title_en": "High-order Equivariant Flow Matching for Density Functional Theory Hamiltonian Prediction", "authors": "Seongsu Kim,Nayoung Kim,Dongwoo Kim,Sungsoo Ahn", "background": "密度泛函理论（DFT）是一种用于模拟量子化学性质的基本方法，但因需要迭代解科恩-沙姆方程的自洽场（SCF）过程而仍然非常昂贵。近期，深度学习方法开始作为绕过这一步骤的方式，直接预测哈密顿量。然而，这种方法依赖于确定性回归，未能充分考虑到哈密顿量的结构。本文中的研究背景在于克服现有方法的限制。", "innovation": "本文提出了QHFlow，这是一种高阶对称流匹配框架，能根据分子几何生成紧扣哈密顿矩阵。通过学习哈密顿量的结构分布而非直接回归，模型在简洁先行概率和复杂目标之间匹配连续时间轨迹，进一步引入预测SE(3)对称向量场的神经网络架构，提高了不同几何结构下的准确性和泛化能力。同时引入细调方案，以确保预测轨道能与目标对齐，从而进一步提高物理一致性。", "conclusion": "QHFlow展示了卓越的表现，其在MD17和QH9数据集上将哈密顿量误差分别降低了71%和53%。此外，QHFlow能够在初始化SCF迭代时用预测出的哈密顿量加速DFT过程，这不会牺牲求解质量，还显著减少了迭代次数与运行时间。"}
{"llm_update_time": "20251023", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2505.19955", "html_url": "https://arxiv.org/abs/2505.19955", "title": "MLR-Bench: 对开放性机器学习研究进行AI代理评估", "title_en": "MLR-Bench: Evaluating AI Agents on Open-Ended Machine Learning Research", "authors": "Hui Chen,Miao Xiong,Yujie Lu,Wei Han,Ailin Deng,Yufei He,Jiaying Wu,Yibo Li,Yue Liu,Bryan Hooi", "background": "近年来，人工智能代理在科学发现领域展现了巨大的潜力。为了更好地评估这些代理的表现，本文引入了一个名为MLR-Bench的基准测试框架，专门用于评估AI代理在开放性机器学习研究中的表现。", "innovation": "MLR-Bench包含三个关键组件：(1) 201个涵盖不同机器学习主题的研究任务；(2) MLR-Judge，一个结合了基于语言模型的评审员和精心设计的评审标准的自动评估框架，用于评估研究质量；(3) MLR-Agent，一个模块化代理构件，能够通过四个阶段完成研究任务：想法生成、提案制定、实验和论文撰写。该框架支持对这些不同研究阶段进行逐步评估，也支持对最终研究论文进行端到端评估。", "conclusion": "MLR-Bench被用于评估六个前沿的大语言模型和一个高级编码代理，结果显示大语言模型在生成连贯的想法和结构良好的论文方面表现出色，但当前的编码代理在大多数情况下（如80%的情况下）会产生伪造或无效的实验结果，这严重阻碍了科学的可靠性。MLR-Judge通过人工评估得到了验证，显示出与专家评审员的高一致性，支持其作为可扩展的研究评估工具的潜力。该基准测试框架被开源，旨在帮助社区对AI研究代理进行基准测试、诊断和改进，以实现可信和透明的科学发现。"}
{"llm_update_time": "20251023", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2505.17950", "html_url": "https://arxiv.org/abs/2505.17950", "title": "评估处理学生文本中科学特定符号表达的NLP嵌入模型", "title_en": "Evaluating NLP Embedding Models for Handling Science-Specific Symbolic Expressions in Student Texts", "authors": "Tom Bleckmann,Paul Tschisgale", "background": "近年来，自然语言处理（NLP）在教育数据分析中的作用日益重要，特别是在分析学生生成的语言产品时。现有的嵌入模型常用于生成文本的数字表示，以捕捉其语义内容并用于后续的定量分析。然而，当涉及到科学语言时，嵌入模型很难处理像方程和公式这样的符号表达。现有研究和实际应用往往忽视这些挑战，要么忽略了符号表达，要么完全删除它们，这可能导致研究发现的偏差和实际应用性能的下降。因此，本研究探讨了当代嵌入模型在处理和解释科学特定符号表达方面的差异，通过物理特定的符号表达从真实的学生回应中进行评估，从相似性分析和机器学习管道集成两个角度评估模型性能，揭示了显著的模型性能差异，OpenAI的GPT-text-embedding-3-large表现最好，尽管相比其他模型领先幅度适中而非显著。这强调了在使用包含符号表达的语言产品时，教育数据分析研究者和从业者需要仔细选择NLP嵌入模型的重要性。代码和部分数据可在链接处获得。", "innovation": "本研究探索了当代嵌入模型在处理和解释科学特定符号表达方面的差异，通过物理特定的符号表达从真实的学生回应出发，评估了各种嵌入模型的性能，发现OpenAI的GPT-text-embedding-3-large表现最好。这种研究方法在针对科学特定语言的产品中选择NLP嵌入模型方面具有创新性。", "conclusion": "本研究显示了嵌入模型在科学特定符号表达处理方面的显著差异，强调了在教育数据分析领域，特别是在处理包含符号表达的语言产品时，选择合适的NLP嵌入模型的重要性。"}
{"llm_update_time": "20251023", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2505.24379", "html_url": "https://arxiv.org/abs/2505.24379", "title": "未被遗忘但未被删除：LLM中精确删除后的数据提取", "title_en": "Unlearned but Not Forgotten: Data Extraction after Exact Unlearning in LLM", "authors": "Xiaoyu Wu,Yifei Pang,Terrance Liu,Zhiwei Steven Wu", "background": "大型语言模型通常通过包含潜在有害或敏感个人信息的网络收集的数据集进行训练。为应对日益增长的隐私担忧，提出了卸载方法以从训练好的模型中去除特定数据的影响。其中，重新训练法（不包含目标数据从头开始重新训练模型）被认为是减轻部署中隐私风险的黄金标准。然而，在实际应用中，如果前后卸载的API均可见，如开放权重场景，现有的假设可能不再成立。本文针对这种情况，提出了一种新的数据提取攻击。", "innovation": "本文提出了一种新的数据提取攻击，结合模型指导和令牌过滤策略，显著提高了在MUSE、TOFU和WMDP等常见基准上的提取成功率。此外，通过模拟医疗诊断数据集具体展示了该攻击的有效性，揭示了精确卸载的真实隐私风险。由于作者的研究发现，卸载可能在实际部署中反而增加了隐私泄露的风险，提出建议评估卸载方法应考虑更广泛的威胁模型，不仅考虑卸载后的模型，也考虑对手对早期检查点的访问。", "conclusion": "研究表明，理论上被认为是隐私风险降低的精确卸载方法可能在实际部署中增加隐私泄露风险。作者呼吁评估卸载方法时需纳入更广泛的威胁模型，以综合考虑模型的前后状态。"}
{"llm_update_time": "20251023", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.04168", "html_url": "https://arxiv.org/abs/2506.04168", "title": "Horizon Reduction Makes RL Scalable", "title_en": "Horizon Reduction Makes RL Scalable", "authors": "Seohong Park,Kevin Frans,Deepinder Mann,Benjamin Eysenbach,Aviral Kumar,Sergey Levine", "background": "本文研究了离线强化学习（RL）算法的可扩展性。真正可扩展的离线RL算法应该能够在给定足够数据、计算能力和模型容量的情况下解决任何复杂问题。研究表明，尽管增加了数据量，许多现有离线RL算法仍然展现出较差的可扩展性，性能饱和点远低于最大性能。研究者认为时间跨度可能是导致离线RL可扩展性差的主要原因。", "innovation": "本文通过多种分析实验验证了长时间跨度是离线RL可扩展性的关键障碍，并展示了减少时间跨度的技术在解决具有挑战性的任务时能显著提高可扩展性。基于这些见解，本文提出了一个名为SHARSA的简单但有效的可扩展方法，通过减少时间跨度实现了最佳的渐进性能和可扩展性，表明明确减少时间跨度可以解锁离线RL的可扩展性。", "conclusion": "表明通过有效减少时间跨度，可以显著提高离线RL算法的性能和可扩展性。SHARSA算法表现出色，其他评估方法的最好表现也证明了减少时间跨度对离线RL可扩展性的重大意义。"}
{"llm_update_time": "20251023", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.00711", "html_url": "https://arxiv.org/abs/2506.00711", "title": "QoQ-Med: 使用领域意识GRPO训练构建多模态临床基础模型", "title_en": "QoQ-Med: Building Multimodal Clinical Foundation Models with Domain-Aware GRPO Training", "authors": "Wei Dai,Peilin Chen,Chanakya Ekbote,Paul Pu Liang", "background": "临床决策通常需要处理各种异质数据，但现有的多模态语言模型（MLLMs）主要以视觉为中心，难以在不同临床专科之间进行泛化。本文旨在填补这一空白，介绍QoQ-Med-7B/32B，它是首个开放的通用临床基础模型，能够联合处理医学影像、时间序列信号和文本报告。该模型通过一种新颖的强化学习目标DRPO进行训练，这种目标能够根据领域稀有性和模态难度进行层次化分配规范化奖励，从而减轻由于临床数据分布偏差导致的表现不平衡问题。该模型基于涵盖9个临床领域的261万对指令调优对进行训练，在宏观F1分数上平均提高了诊断性能43%。", "innovation": "引入了QoQ-Med-7B/32B，这是一种联合处理医学影像、时间序列信号和文本报告的开放通用临床基础模型。该模型采用了被称为DRPO的领域意识相对策略优化的新颖强化学习目标进行训练，该目标能够根据领域稀有性和模态难度进行层级化奖励分配，从而解决了性能不平衡的问题。此外，与无批评者的其他训练方法如GRPO相比，在宏观F1分数上平均提高了43%。QoQ-Med还能以比开放模型高出10倍的交集记录（IoU）突出显示与诊断相关的显著区域，同时达到与OpenAI o4-mini相当的性能。", "conclusion": "QoQ-Med不仅展示了在多模态临床知识处理方面的卓越性能，还提供了全面的训练流程和中间推理轨迹，以促进后续研究的可复制性和进展。"}
{"llm_update_time": "20251023", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2505.24625", "html_url": "https://arxiv.org/abs/2505.24625", "title": "从视频学习构建3D世界：通过3D视觉几何先验增强MLLMs", "title_en": "Learning from Videos for 3D World: Enhancing MLLMs with 3D Vision Geometry Priors", "authors": "Duo Zheng,Shijia Huang,Yanyang Li,Liwei Wang", "background": "之前的研究所探讨了多模态大语言模型（MLLMs）在理解和分析3D场景方面的能力，主要是通过将3D场景解释为视频数据来进行。这些方法通常依赖于全面的3D数据输入，如点云或重建的鸟瞰图（BEV）地图。而本研究则在此基础上推进，使MLLMs能够直接从视频数据中理解并推理三维空间，无需额外的3D输入。研究中提出了一种新颖有效的方法，即视频-3D几何大语言模型（VG LLM）。该方法利用3D视觉几何编码器从视频序列中提取3D先验信息，将这些信息与视觉标记集成并输入到MLLM中。实验表明，该方法在各种与3D场景理解和空间推理相关的任务上取得了显著进步。无需显式3D数据输入的4B模型在VSI-Bench评测中甚至优于现有最先进的方法，如Gemini-1.5-Pro。", "innovation": "研究提出了Video-3D Geometry Large Language Model (VG LLM)方法，该方法利用3D视觉几何编码器从视频数据中提取3D先验信息，将这些信息与视觉标记集成并输入到MLLM中。这一方法大大提升了MLLMs在直接从视频中推断和理解三维空间的能力，无需额外的3D输入，并在多项任务上取得了与现有最先进方法媲美的成果，甚至某些方面超越了Gemini-1.5-Pro。", "conclusion": "本研究通过引入Video-3D Geometry Large Language Model (VG LLM)，显著改善了MLLMs在直接从视频数据中推断和理解三维空间的能力，实验证明这种方法取得了显著进展，并在某些方面超越了现有最先进方法。"}
{"llm_update_time": "20251023", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.10946", "html_url": "https://arxiv.org/abs/2506.10946", "title": "GUARD: 通过数据归因进行大型语言模型的引导式遗忘和保留", "title_en": "GUARD: Guided Unlearning and Retention via Data Attribution for Large Language Models", "authors": "Peizhi Niu,Evelyn Ma,Huiting Zhou,Duo Zhou,Huan Zhang,S. Rasoul Etesami,Olgica Milenkovic", "background": "大型语言模型因监管合规性、版权保护和隐私问题日益受到关注。然而，在大型语言模型中实现遗忘的关键挑战是有意遗忘，这可能导致特定数据的移除意外地损害模型的功能和保留有价值的信息。尽管以往的研究主要集中在架构创新上，但数据层面因素对遗忘性能的影响尚未得到充分探索。现有的方法在遗忘高影响数据时常常导致保留性能下降。", "innovation": "本文提出了一种新的引导式遗忘和保留框架GUARD，通过引入针对大型语言模型遗忘的轻量级代理数据归因度量来量化遗忘集和保留集的对齐程度，在保持计算效率的同时提高保留性能。通过设计一种新颖的遗忘目标，这种方法为样本分配自适应、非均匀的遗忘权重，与代理归因评分成反比，从而重新分配遗忘权，减少无意中的保留损失。理论保证了GUARD能够显著提高保留性能，同时保留遗忘指标接近先前的方法。大量的实验结果表明GUARD在保持较低隐私损失的情况下显著提高了模型的知识保留。", "conclusion": "我们的实验结果表明，相较于传统的遗忘方法，GUARD在遗忘10%的训练数据时，可以将TOFU保留集的实用性损失降低多达194.92%，并提高MUSE NEWS保留集的知识保留率16.20%。"}
{"llm_update_time": "20251023", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.13579", "html_url": "https://arxiv.org/abs/2506.13579", "title": "离散扩散模型中的可变长度文本填充", "title_en": "Flexible-length Text Infilling for Discrete Diffusion Models", "authors": "Andrew Zhang,Anushka Sivakumar,Chiawei Tang,Chris Thomas", "background": "离散扩散模型作为一种新型的文字生成器，相较于自回归模型具有双向语境利用、并行生成和灵活提示等优势。然而，离散扩散模型在没有获取真实位置数据的情况下，无法灵活地进行不同长度或不同位置的文本填充，这成为其关键的限制。", "innovation": "文章提出了一种名为DDOT（离散扩散与最优传输位置耦合）的新模型，该模型是首个能够克服上述挑战的离散扩散模型。DDOT模型同时净化了词汇值和位置信息，并应用了一种新颖的样本级别最优传输耦合，这种耦合保持了词汇的相对顺序，同时动态调整填充段的位置和长度。这种方法与现有的离散文本扩散方法互不干涉，并且能够与各种预训练的文字去噪器兼容。实验表明，DDOT方法在文本填充基准测试中优于naive扩散基准，并且可以达到目前最先进非自回归模型的性能，同时还能在训练效率和灵活性上带来显著的提高。", "conclusion": "DDOT模型在文本填充任务中表现出色，实现了与最先进的非自回归模型相当的性能，并且在训练效率和灵活性方面有所改善。"}
{"llm_update_time": "20251023", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.06407", "html_url": "https://arxiv.org/abs/2506.06407", "title": "TimeWak：时间序列数据的时间链式水印", "title_en": "TimeWak: Temporal Chained-Hashing Watermark for Time Series Data", "authors": "Zhi Wen Soi,Chaoyi Zhu,Fouad Abiad,Aditya Shankar,Jeroen M. Galjaard,Huijuan Wang,Lydia Y. Chen", "background": "合成时间序列生成模型可以通过扩散模型生成隐私敏感的数据集，如患者的功能性磁共振成像记录。合成数据的关键指标包括高数据实用性和可追溯性，以验证数据源。当前的水印方法通常嵌入在同质的潜在空间中，但最新的时间序列生成器在数据空间中工作，这使得基于潜在域的水印不兼容。因此，直接在数据域中嵌入水印，同时处理特征异质性和时间依赖性，成为一个挑战。", "innovation": "提出了TimeWak，一个专为多变量时间序列扩散模型设计的水印算法。TimeWak直接在时间-特征数据空间中嵌入时间链式哈希水印，以处理时间依赖性和空间异质性。此外，提出了$\\varepsilon$-精确反演方法，以解决逆扩散过程中的非均匀重构误差分布问题，从而增强水印的可检测性。该方法还推导了多变量时间序列逆过程的误差上限，以保持水印的鲁棒性。该研究通过不同长度的数据集和基准，全面评估了TimeWak对合成数据质量、水印可检测性和在多种后编辑攻击下的鲁棒性的影响。实验结果表明，TimeWak在对比最强的现有基准时，其上下文FID得分提高了61.96%，相关性分数提高了8.44%，并且始终是可以检测的。", "conclusion": "TimeWak既保持了合成数据的高质量，又实现了优秀的水印可检测性和鲁棒性，这一方法为时间序列数据的水印嵌入提供了一个有效的解决方案。"}
{"llm_update_time": "20251023", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.15591", "html_url": "https://arxiv.org/abs/2506.15591", "title": "一阶段扩散模型用于细节丰富且时序一致的视频超分辨率", "title_en": "One-Step Diffusion for Detail-Rich and Temporally Consistent Video Super-Resolution", "authors": "Yujing Sun,Lingchen Sun,Shuaizheng Liu,Rongyuan Wu,Zhengqiang Zhang,Lei Zhang", "background": "在真实世界视频超分辨率（Real-VSR）中，同时保持丰富的空间细节和时间一致性具有挑战性，尤其是在使用如稳定扩散（SD）等预训练生成模型进行真实细节合成时。现有的基于SD的Real-VSR方法常常在空间细节和时间连贯性之间做出权衡，导致视觉质量不佳。关键在于如何有效从低质量（LQ）输入视频中提取耐受退化的时序一致性先验并增强视频细节，同时保持提取到的一致性先验。", "innovation": "提出了一种Dual LoRA Learning（DLoRAL）范式，用于训练一种高效的基于SD的一步扩散模型，该模型在保持时间一致性的前提下，能够生成具有真实细节的帧。具体来说，引入了跨帧检索（CFR）模块以收集帧间互补信息，并训练一致性LoRA（C-LoRA）以从降级输入中学习鲁棒的时间表示。在一致性学习之后，固定CFR和C-LoRA模块，并训练细节LoRA（D-LoRA）以增强空间细节，同时与由C-LoRA定义的时间空间保持一致性。两个阶段交替迭代优化，从而协同产生一致且细节丰富的输出。在推理过程中，两个LoRA分支合并到SD模型中，允许在单个扩散步骤中高效地进行高质量视频恢复。实验结果表明DLoRAL在准确性和速度上都表现强大。", "conclusion": "DLoRAL通过交替的优化过程，实现了在保存时间一致性的前提下，同时增强了视频的细节。该研究通过两阶段训练和模块分离，显著提高了视频超分辨率的质量与效率。"}
{"llm_update_time": "20251023", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.16895", "html_url": "https://arxiv.org/abs/2506.16895", "title": "在有限的多模态数据下，让STRUCTURE引领你", "title_en": "With Limited Data for Multimodal Alignment, Let the STRUCTURE Guide You", "authors": "Fabian Gröger,Shuo Wen,Huyen Le,Maria Brbić", "background": "现有的多模态模型展示了强大的能力，能够在需要多模态对齐的复杂任务中发挥作用，例如零样本分类和跨模态检索。然而，这些模型通常依赖大规模的成对多模态样本数据，这在许多领域中是成本高昂或不可行的。本文探讨了通过对预训练的单模态基础模型进行对齐，从而在少量成对数据下构建多模态模型的可行性。研究表明，高质量的对齐可以在仅有数万样本的情况下实现，即通常使用的数据量的不到1%。", "innovation": "本文引入了effective的正则化技术STRUCTURE，以保留单模态编码器潜空间的邻域几何结构。同时，文章表明仅仅对齐最后一层往往是不理想的，并展示了层间对齐能够提高表示相似性的优势。这些贡献可以很容易地整合到现有的对齐方法中，使得24个零样本图像分类和检索基准测试的表现得到了大幅度提升，分类任务平均相对改善率为51.6%，检索任务为91.8%。", "conclusion": "本文的结果强调了我们框架在有限样本多模态学习中的有效性和广泛应用，并为资源受限领域提供了可能的发展路径。"}
{"llm_update_time": "20251023", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.21374", "html_url": "https://arxiv.org/abs/2506.21374", "title": "注意小权重", "title_en": "Pay Attention to Small Weights", "authors": "Chao Zhou,Tom Jacobs,Advait Gadhikar,Rebekka Burkholz", "background": "微调大型预训练神经网络在内存和计算成本方面都比较耗费资源。为了减轻这种负担，常用的方法是仅对模型的一部分参数进行训练。通过分析微调过程中梯度和权重的关系，我们发现了显著的模式：大梯度通常与小幅度权重相关联。这种关联在微调设置中比从头开始训练更为明显。", "innovation": "本文提出了NANOADAM，它在微调过程中仅动态更新小幅度权重。这项工作的创新点包括：第一，该标准是无梯度的——子参数集可通过梯度计算外部确定；第二，它保留了大幅度权重，这些权重很可能包含了预训练期间学习的重要特征，从而降低了灾难性遗忘的风险；第三，它允许使用更大的学习率，并且在实验中能致更好的泛化性能。", "conclusion": "我们将这一方法应用于自然语言处理和视觉任务，证明了其有效性。"}
{"llm_update_time": "20251023", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.16313", "html_url": "https://arxiv.org/abs/2506.16313", "title": "通过增强的先验神经网络在GFlownets中改进探索", "title_en": "Improved Exploration in GFlownets via Enhanced Epistemic Neural Networks", "authors": "Sajan Muhammad,Salem Lahlou", "background": "在GFlowNets中，高效地识别出用于训练的正确轨迹依然是一个待解问题。这一问题的核心在于，需要优先探索那些奖赏分布尚未充分学习的状态空间区域。这就要求采用基于不确定性的探索策略，意味着代理应当意识到自己未知的部分。这种性质可以通过联合预测来衡量，尤其是对于组合性和序列决策问题来说尤为重要。因此，提高探索效率，识别出最优轨迹对于GFlowNets的发展至关重要。", "innovation": "本研究通过将先验神经网络（ENN）与GFlowNets的传统架构进行集成，从而实现更高效的联合预测和更好的不确定性量化。这不仅可以改进探索，还能更好地识别出最优轨迹。研究中提出了一种新算法ENN-GFN-Enhanced，并将其与GFlowNets的基本方法进行比较，展示出其有效性和效率。", "conclusion": "通过在GFlowNets中引入先验神经网络(ENN)，研究成功提升了探索效率，改进了不确定性的量化，并且在不同的网格环境和结构化序列生成中，ENN-GFN-Enhanced算法展现了其有效性和效率。"}
{"llm_update_time": "20251023", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.18167", "html_url": "https://arxiv.org/abs/2506.18167", "title": "通过导向向量理解思考语言模型中的推理", "title_en": "Understanding Reasoning in Thinking Language Models via Steering Vectors", "authors": "Constantin Venhoff,Iván Arcuschin,Philip Torr,Arthur Conmy,Neel Nanda", "background": "最近大型语言模型（LLMs）的发展导致了生成详细内部推理链以生成回应的思考语言模型的出现。尽管这些模型在性能上有所提升，但控制它们的推理过程仍然具有挑战性。", "innovation": "本文提出了一种通过分析和操作DeepSeek-R1-Distill模型中的特定推理行为来进行导向的方法。通过系统地在10个不同类别中的500个任务上进行实验，识别出几个思考模型表现出的推理行为，如表达不确定性、为假设验证生成例子以及推理链中的回退。实验证明，这些行为受模型激活空间中的线性方向调节，并可通过导向向量进行控制，从而可以调节模型推理过程的具体方面，如回退的倾向或表达不确定性。该方法为在可控和可解释的框架下操纵思考模型的推理过程提供了实用工具。", "conclusion": "我们的导向方法用三个DeepSeek-R1-Distill模型进行了验证，显示出在不同模型架构中一致性地控制推理过程的效果。"}
{"llm_update_time": "20251023", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.01271", "html_url": "https://arxiv.org/abs/2507.01271", "title": "PULSE: 实现大型多模态模型卸载的实用评估场景", "title_en": "PULSE: Practical Evaluation Scenarios for Large Multimodal Model Unlearning", "authors": "Tatsuki Kawakami,Kazuki Egashira,Atsuyuki Miyai,Go Irie,Kiyoharu Aizawa", "background": "近年来，卸载技术已经引起关注，这些技术可以促使模型“忘记”之前学习的信息，以应对大型语言模型（LLMs）和大型多模态模型（LMMs）中的隐私和版权问题。虽然已经建立了多个LLM的卸载基准，但在LMM中的卸载实用评估框架却较少被探索。现有的LMM卸载基准只考虑模型必须通过单一卸载操作进行微调知识的卸载场景。", "innovation": "本文引入了PULSE协议，用于实现LMM的现实卸载场景，通过引入两个关键视角：（i）预训练知识卸载，以分析不同知识获取阶段的效果；（ii）长期可持续性评估，以应对连续请求问题。该协议评估现有卸载方法的效果。", "conclusion": "研究结果表明，尽管一些技术可以成功卸载通过微调获得的知识，但在消除预训练阶段习得的信息时却表现不佳。此外，能够在单一操作中有效卸载一批目标数据的方法，在相同数据按顺序卸载时会表现出明显性能下降。"}
{"llm_update_time": "20251023", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.16962", "html_url": "https://arxiv.org/abs/2506.16962", "title": "Chiron-o1: 通过导师实习生协作搜索推动多模态大型语言模型在可泛化的医疗推理方面的应用", "title_en": "Chiron-o1: Igniting Multimodal Large Language Models towards Generalizable Medical Reasoning via Mentor-Intern Collaborative Search", "authors": "Haoran Sun,Yankai Jiang,Wenjie Lou,Yujie Zhang,Wenjie Li,Lilong Wang,Mianxin Liu,Lei Liu,Xiaosong Wang", "background": "多模态大型语言模型（MLLMs）已经开始在通用任务中展示出强大的推理能力，但在医疗领域的应用还处于初级阶段。构建思维链（CoT）训练数据对于提升医疗MLLMs的推理能力至关重要。然而，现有的方法缺乏提供全面框架来搜索和评估有效推理路径的能力，这些路径可以引导关键诊断。为解决这一挑战，本文提出了导师实习生协作搜索（MICS）方案，这是一种创新的推理路径搜索方案，用于生成严格的有效医疗CoT数据。MICS利用导师模型逐步初始化推理，然后通过实习生模型扩展这些路径，并最终根据多个实习生模型的总体推理性能选择最优推理路径。这些推理性能由MICS评分来决定，该评分评估生成的推理路径的质量。最后，构建了一个多任务医疗推理数据集MMRP和一个新的医疗MLLM Chiron-o1，通过课程学习策略训练，具备稳健的视觉问答能力和可泛化的推理能力。广泛的实验表明，Chiron-o1在一系列医疗视觉问答和推理基准测试中，采用了我们使用MICS构建的CoT数据集进行训练，达到了最先进的性能。", "innovation": "本文提出了一个名为MICS（导师实习生协作搜索）的新颖推理路径搜索方案，用于生成关于医疗领域的CoT数据。MICS方案结合了导师模型和实习生模型进行逐步推理和路径扩展，最小化了已知方法中的盲点。引入了一个用于医疗推理任务的多任务数据集MMRP和一个基于课程学习策略的新医疗MLLM Chiron-o1，展示了其在多次医疗视觉问答和推理基准测试中的优越表现。", "conclusion": "采用了本文方法生成的CoT数据集经过训练的Chiron-o1模型在一系列医疗视觉问答和推理基准测试中达到了最先进的性能。 这种新颖的导师实习生协作搜索方法是通往提升多模态大型语言模型在医疗领域中可泛化推理能力的一种有效途径。"}
{"llm_update_time": "20251023", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.05101", "html_url": "https://arxiv.org/abs/2507.05101", "title": "PRING：从配对到图形重新思考蛋白质-蛋白质相互作用预测", "title_en": "PRING: Rethinking Protein-Protein Interaction Prediction from Pairs to Graphs", "authors": "Xinzhe Zheng,Hao Du,Fanding Xu,Jinzhe Li,Zhiyuan Liu,Wenkang Wang,Tao Chen,Wanli Ouyang,Stan Z. Li,Yan Lu,Nanqing Dong,Yang Zhang", "background": "现有的深度学习方法在预测蛋白质-蛋白质相互作用(PPIs)方面取得了显著成果，但大多数基准测试主要关注于个体的成对评估，而忽略了模型在重建具有生物学意义的复杂PPI网络方面的潜力。鉴于此，本文提出了PRING，这是第一个从图层面评估PPI预测方法的基准测试，涵盖了多物种高质量的PPI网络数据集，并设计了策略以解决数据冗余和泄露问题。", "innovation": "PRING打破了传统成对评估的局限性，引入了两个互补的评估模式：拓扑导向的任务和功能导向的任务。拓扑导向的任务评估物种内和跨物种的PPI网络构建，而功能导向的任务包括蛋白质复合物路径预测、GO模块分析和关键蛋白质验证。这种评估不仅反映了模型理解网络拓扑的能力，还促进了蛋白质功能注释、生物学模块检测及疾病机制分析。", "conclusion": "通过对四种代表性模型分类的广泛实验表明，现有的PPI模型在恢复PPI网络的结构和功能性方面存在潜在限制，这一结论突显了支持实际生物应用的差距。我们相信PRING为社区提供了可靠的研究平台，以指导更有效的PPI预测模型的发展。数据和源代码可在如下链接获取：this https URL"}
{"llm_update_time": "20251023", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.05916", "html_url": "https://arxiv.org/abs/2507.05916", "title": "遥感图像场景分类中可解释人工智能方法与度量的有效性研究", "title_en": "On the Effectiveness of Methods and Metrics for Explainable AI in Remote Sensing Image Scene Classification", "authors": "Jonas Klotz,Tom Burgert,Begüm Demir", "background": "可解释的人工智能(xAI)方法在遥感(RS)场景分类问题中的发展引起了广泛关注。大多数 xAI 方法及其相关评估指标最初是为计算机视觉(CV)中的自然图像开发的，直接应用于 RS 可能不适宜。因此，本研究旨在探讨 xAI 方法和评估指标在 RS 图像场景分类中的有效性。研究通过详细的方法学和实验分析，评估了五种特征归因方法（Occlusion、LIME、GradCAM、LRP 和 DeepLIFT）在三种 RS 数据集上的十个解释指标（包括忠实性、鲁棒性、定位性、复杂性和随机化）的表现，揭示了这些方法和指标的关键局限性及其在 RS 中的可靠性问题。", "innovation": "本研究首次系统地分析了 xAI 方法和评估指标在 RS 场景分类中的应用效果。通过将五种特征归因方法与十个解释指标相结合，跨多个 RS 数据集进行了广泛的研究。研究不仅指出了现有方法和评估指标的关键局限性，还提出了针对 RS 场景分类选择解释方法、评估指标和超参数的指南。这种方法学和实验分析是一种创新性的工作，有助于提高 RS 图像场景分类的透明度和可靠性。", "conclusion": "研究表明，基于扰动的方法（如 Occlusion 和 LIME）和基于梯度的方法（如 GradCAM）在某些情况下存在局限性，而某些相关性传播方法（如 LRP）则可能在类别的空间分布上出现偏差。评估指标方面，鲁棒性和随机化指标表现出较高的稳定性，而基于扰动的方法和鲁棒性指标则存在问题。基于这些发现，本研究提供了针对 RS 场景分类中的 xAI 方法和评估指标选择的建议。"}
{"llm_update_time": "20251023", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.01415", "html_url": "https://arxiv.org/abs/2508.01415", "title": "RoboMemory: 用于物理实体系统的交互环境学习的大脑启发式多记忆代理框架", "title_en": "RoboMemory: A Brain-inspired Multi-memory Agentic Framework for Interactive Environmental Learning in Physical Embodied Systems", "authors": "Mingcong Lei,Honghao Cai,Zezhou Cui,Liangchen Tan,Junkun Hong,Gehan Hu,Shuangyu Zhu,Yimou Wu,Shaohan Jiang,Ge Wang,Yuyuan Yang,Junyuan Tan,Zhenglin Wan,Zhen Li,Shuguang Cui,Yiming Zhao,Yatong Han", "background": "实体代理在真实世界环境中面临持久挑战，包括部分可观测性、空间推理能力有限和高延迟多记忆整合。", "innovation": "提出RoboMemory，一种基于大脑启发式的框架，将空间记忆、时间记忆、情景记忆和语义记忆统一于并行架构中，以支持高效的长视角规划和互动环境学习。动态空间知识图确保记忆更新的可扩展性和一致性，并结合闭环计划者和批评者模块，支持动态环境下的适应性决策。", "conclusion": "实验表明，RoboMemory在EmbodiedBench上的平均成功率提高了25%，超过其基线3%，并在闭源的SOTA Gemini-1.5-Pro之上。实际试验进一步验证了其累积学习能力，表明其在重复任务中的性能提高。RoboMemory为增强记忆的实体智能提供了一个可扩展的基础，填补了认知神经科学与机器人自主性的鸿沟。"}
{"llm_update_time": "20251023", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.06098", "html_url": "https://arxiv.org/abs/2508.06098", "title": "MeanAudio：利用均值流实现快速可靠的文本到音频生成", "title_en": "MeanAudio: Fast and Faithful Text-to-Audio Generation with Mean Flows", "authors": "Xiquan Li,Junxi Liu,Yuzhe Liang,Zhikang Niu,Wenxi Chen,Xie Chen", "background": "近几年，文字到音频生成（TTA）取得了显著进展，为音频创作者提供了将灵感转换为生动声音的强大工具。然而，当前的TTA系统通常存在推理速度慢的问题，严重影响了音频创作的效率和流畅性。", "innovation": "本文提出了一种快速且忠实的文本到音频生成器——MeanAudio，能够在一次函数评估内渲染真实声音。该模型通过（i）使用包含引导速度目标的MeanFlow目标加速推理速度，（ii）增强的Flux风格变压器具有双文本编码器以提高语义对齐和合成质量，以及（iii）高效的时间到均值课程，加快收敛速度并支持在消费级GPU上训练。", "conclusion": "通过全面的评估研究，我们证明MeanAudio在单步音频生成中的性能处于最新技术水平。具体来说，它在NVIDIA RTX 3090上实现了0.013的实时因子（RTF），比基于扩散的最新TTA系统快100倍。此外，MeanAudio在多步生成中也表现出强劲性能，使各步合成之间的过渡更加平滑。"}
{"llm_update_time": "20251023", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.01687", "html_url": "https://arxiv.org/abs/2508.01687", "title": "使用PHAR解释时间序列分类器：从后预测归因中提取和融合规则", "title_en": "Explaining Time Series Classifiers with PHAR: Rule Extraction and Fusion from Post-hoc Attributions", "authors": "Maciej Mozolewski,Szymon Bobek,Grzegorz J. Nalepa", "background": "解释时间序列分类的机器学习模型仍然具有挑战性，因为解释原始时间序列数据和高维输入空间的难度较大。现有的后预测解释器（例如LIME和SHAP）未能提供结构化的、易于理解的规则，并能够本地化置信阈值条件在这种原始时间序列数据上。PHAR提供了一个统一的框架，它将这些数值特征的解释自动转换为结构化的、易于理解的规则。这些规则定义了明确的时间区间，表明在何时何地决策相关的时间序列片段出现。这有助于提高模型的透明度。", "innovation": "PHAR通过转换来自后预测解释器的数值特征归因，生成结构化的可读规则。它能够处理长的时间序列序列，并提高实例覆盖率。PHAR还包含了一个专门的规则融合步骤，采用加权选择和套索优化等策略，平衡覆盖率、信心和简单性等关键质量指标。这一步骤确保每个实例都获得一个简洁且明确的规则，从而提高了解释的准确性和一致性。此外，PHAR还引入了可视化技术，以便于展示从提取规则中获得的细致具体与广泛一般之间的权衡。", "conclusion": "全面实验表明，PHAR能够通过提供与模型预测一致的简洁和可读的规则来提高时间和序列分类任务的可解释性、决策透明度和实际应用性。"}
{"llm_update_time": "20251023", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.02844", "html_url": "https://arxiv.org/abs/2509.02844", "title": "时间序列预测中带有突变点的皮尔逊预测", "title_en": "Conformal Prediction for Time-series Forecasting with Change Points", "authors": "Sophia Sun,Rose Yu", "background": "皮尔逊预测已作为提供时间序列不确定性量化的一种通用且高效的方法被探索，但当前方法难以处理带有突变点的时间序列数据——突然变化的基础数据生成过程。", "innovation": "本文提出了一种新颖的时间序列突变点皮尔逊预测（CPTC）算法，通过集成预测基础状态的模型与在线皮尔逊预测来建模非平稳时间序列中的不确定性，证明了CPTC在最少假设下的有效性及在时间序列设置中的提高的适应性，并在6个合成和实际数据集上展示了其相对于先进的基线方法改进的有效性和适应性。", "conclusion": "证明了CPTC的有效性和适应性，并通过6个合成和实际数据集验证了其在时间序列预测中相对于最先进基线方法的改进性能。"}
{"llm_update_time": "20251023", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.07780", "html_url": "https://arxiv.org/abs/2507.07780", "title": "图像分类中数据集迁移下校准的现状", "title_en": "Where are we with calibration under dataset shift in image classification?", "authors": "Mélanie Roschewitz,Raghav Mehta,Fabio de Sousa Ribeiro,Ben Glocker", "background": "本文针对实际数据集偏移对图像分类校准状态进行详细研究。当前，对于校准不同偏移条件下的图像分类，缺乏全面和系统的指导，特别是关于动态后校准和训练中校准技术的选择建议。从业者需要在实际数据变异性的背景下，找到可靠和适用的校准方法。", "innovation": "本文比较了多种后校准技术及其与常见的训练中校准策略（如标签平滑）的交互效果，并进行了广泛自然偏移状况下的比较分析。研究发现，同时应用熵正则化和标签平滑能提供在数据集偏移下最佳的校准概率。此外，暴露于少量语义上与任务相关的分布外数据的后校准器在数据集偏移下表现最稳健。最新的特定于偏移校准方法并不一定显著优于简单的后校准方法。提高偏移条件下的校准往往会有损分布内校准。此外，还深入分析了集成效应，发现校准先于集成应用比集成后更有效；对于集成模型，非任务相关的分布外数据暴露会损害ID-偏移校准的平衡；集成是提高校准稳健性最有效的方法之一，结合从基础模型微调，整体上提供了最优的校准结果。", "conclusion": "尽管随机初始化的分类器和从基础模型微调的分类器的校准表现有所不同，但本文提供的实验结果为所有在图像分类中寻求稳健校准的从业者都提供了实用的指导。特别是在偏移条件下，虽然某些特定校准方法并不会显著改进，但整体方法（如集成方法）在提高校准效果上较为有效。"}
{"llm_update_time": "20251023", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.15831", "html_url": "https://arxiv.org/abs/2508.15831", "title": "谁在提问？通过残疾框架查询研究LLMs中的偏见", "title_en": "Who's Asking? Investigating Bias Through the Lens of Disability Framed Queries in LLMs", "authors": "Vishnu Hari,Kalpana Panda,Srikant Panda,Amit Agarwal,Hitesh Laxmichand Patel", "background": "大语言模型（LLMs）能够通过语言风格推断出用户的 demographic 特征，即使没有明确提供任何 demographic 信息，也可能导致偏见。残疾线索在塑造这些推断中的作用尚未充分研究。因此，本文首次系统地审计了残疾条件下 demographic 偏差，涵盖了从3亿到72亿参数的八种最先进的指令调优 LLM。通过一个平衡模板语料库，将九种残疾类别与六个真实世界的商业领域配对，对每个模型在中立和残疾意识条件下的预测五个 demographic 属性（性别、社会经济地位、教育、文化背景和所在地）进行了评估。在不同类型的提示下，模型在最多97%的情况下给出了明确的 demographic 推断，表明了一个倾向于毫无根据地进行推断的趋势。残疾语境显著改变了预测属性的分布，而领域语境进一步放大了这些偏差。研究发现，较大的模型对残疾线索更为敏感且更易产生偏见，这意味着模型规模本身并不能削弱刻板印象的放大效应。", "innovation": "首次系统性地审计了残疾条件下 demographic 偏差，使用一个平衡模板语料库评估不同规模的大语言模型在中立和残疾意识条件下的 demographic 属性预测，揭示了模型规模对刻板印象放大效应的影响，并提出了解决不当 demographic 推断的策略。", "conclusion": "研究结果揭示了 ableism 和其他 demographic 刻板印象之间的持续交织，指出了当前对齐策略中的关键盲点。作者发布了评估框架和结果，鼓励进行包容性残疾的基准测试，并推荐整合避让校正和反事实微调来遏制不合理的 demographic 推断。"}
{"llm_update_time": "20251023", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.16949", "html_url": "https://arxiv.org/abs/2508.16949", "title": "突破探索瓶颈：面向通用大语言模型推理的评分表支架强化学习", "title_en": "Breaking the Exploration Bottleneck: Rubric-Scaffolded Reinforcement Learning for General LLM Reasoning", "authors": "Yang Zhou,Sunzhu Li,Shunyu Liu,Wenkai Fang,Kongcheng Zhang,Jiale Zhao,Jingwen Yang,Yihe Zhou,Jianwei Lv,Tongya Zheng,Hengtong Lu,Wei Chen,Yan Xie,Mingli Song", "background": "近年来，大规模语言模型（LLM）的发展强调了强化学习（RL）在促进推理能力发展方面的潜力。尽管取得了积极的结果，但RL的进步仍依赖于学习高质量样本，而获取这些样本的探索活动受限于LLM固有的局限性。这一情况导致了一个不良循环，即无法探索的内容无法学到。该研究讨论了这一挑战及其对LLM推理的影响。", "innovation": "该研究提出了‘评分表引导的强化学习’（RuscaRL），这是一种新颖的指导框架，旨在打破通用LLM推理中的探索瓶颈。RuscaRL通过引入清单风格的评分表作为外部指导，在-rollout生成期间提供明确的探索支架，引导多样化且高质量的响应，并随着逐步减少指导，促使模型内化潜在的推理模式；在模型训练期间，用于验证收益，通过使用评分表作为参考获取鲁棒的LLM-as-a-Judge评分，从而在通用推理任务上实现有效的RL。", "conclusion": "对广泛基准测试的大量实验表明，RuscaRL在各类任务上表现出色，特别是在“最佳n评估”下扩展了推理边界。该研究显著提高了Qwen2.5-7B-Instruct在HealthBench-500上的表现，达到50.3分，超过了GPT-4.1。此外，对Qwen3-30B-A3B-Instruct的微调版本在HealthBench-500上达到了61.1分，超过了领先的LLM，包括OpenAI-o3。相关代码可在本文链接获取。"}
{"llm_update_time": "20251023", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.21589", "html_url": "https://arxiv.org/abs/2508.21589", "title": "Middo：基于模型指导的动态数据优化提升大型语言模型自闭环学习精细调优", "title_en": "Middo: Model-Informed Dynamic Data Optimization for Enhanced LLM Fine-Tuning via Closed-Loop Learning", "authors": "Zinan Tang,Xin Gao,Qizhi Pei,Zhuoshi Pan,Mengzhang Cai,Jiang Wu,Conghui He,Lijun Wu", "background": "大型语言模型的监督微调（SFT）从根本上依赖于高质量的训练数据。现有的数据选择和数据合成策略虽能提升数据质量，但在静态数据集维护方面往往面临局限性，无法适应模型能力的不断变化。因此，需要一种能够自我进化且动态优化的数据优化框架，以持续提升数据质量和模型性能。", "innovation": "Middo是一种模型自适应的数据优化框架，通过模型感知的数据选择和语义保持的数据精炼，建立了一个闭环优化系统。它包括三个主要部分：一个自我诊断模块，采用三轴模型信号（损失模式、嵌入簇动态、自我对齐分数）主动识别不足样本；一个自适应优化引擎，将不足样本转化为有价值的训练点，同时保持语义完整性；一个通过动态学习原则不断进化的优化过程，使数据和模型能够共同进化。", "conclusion": "通过在多个基准上的实验验证，Middo能够持续提升种子数据质量，提升大型语言模型的性能，平均提高准确率7.15%。这项工作通过动态的人机共同进化数据和模型的新范式，为可持续的大型语言模型训练提供了新的解决方案。所有相关数据集、模型和代码均公开发布。"}
{"llm_update_time": "20251023", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.17452", "html_url": "https://arxiv.org/abs/2509.17452", "title": "无需训练的标签空间对齐方法用于通用领域适应", "title_en": "Training-Free Label Space Alignment for Universal Domain Adaptation", "authors": "Dujin Lee,Sojung An,Jungmyung Wi,Kuniaki Saito,Donghyun Kim", "background": "过去的研究集中在视觉空间对齐的转换知识领域适应方法（UniDA），但它们往往由于内容差异性在视觉模态方面存在局限性，限制了其鲁棒性和泛化能力。", "innovation": "提出了一种无需训练的标签空间对齐方法（\textit{OURS}），该方法利用近期的视觉-语言基础模型（VLMs）如CLIP的强大零样本能力，专注于标签空间对齐增强适应稳定性。通过过滤和精炼不同域之间的噪音标签，构建通用分类器综合共享知识和目标专属类别信息，从而在领域变化下提高泛化能力。", "conclusion": "实验结果显示，所提出的方法在关键DomainBed基准测试中显著优于现有UniDA技术，平均提高H分数7.9%，H分数（H~3~）6.1%。进一步的自训练改进了性能，H和H~3~分数分别提高了额外的1.6%。"}
{"llm_update_time": "20251023", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.18648", "html_url": "https://arxiv.org/abs/2509.18648", "title": "SPiDR: 一种用于仿真实际转移中的零样本安全性的简单方法", "title_en": "SPiDR: A Simple Approach for Zero-Shot Safety in Sim-to-Real Transfer", "authors": "Yarden As,Chengrui Qu,Benjamin Unger,Dongho Kang,Max van der Hart,Laixi Shi,Stelian Coros,Adam Wierman,Andreas Krause", "background": "在现实世界中安全地部署强化学习（RL）具有挑战性，因为已在模拟器中训练的策略不可避免地会面临从仿真到现实的差距。虽然稳健的安全RL方法具有可证明的安全性，但很难扩展，而域随机化更实用但容易出现不安全的行为。", "innovation": "我们通过提出SPiDR（Sim-to-real via Pessimistic Domain Randomization）来解决这一差距，这是一种具有可扩展性和可证明安全性的算法，用于安全的仿真实际转移。SPiDR使用域随机化将从仿真到现实的差距的不确定性纳入安全性约束中，使其实用且高度兼容现有的训练流水线。", "conclusion": "通过在仿真基准和两个不同的机器人平台上的广泛实验，我们证明SPiDR在存在仿真到现实间隙的情况下有效地保证了安全，同时保持了强大的性能。"}
{"llm_update_time": "20251023", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.26433", "html_url": "https://arxiv.org/abs/2509.26433", "title": "ACT: 自主分类树", "title_en": "ACT: Agentic Classification Tree", "authors": "Vincent Grari,Tim Arni,Thibault Laugel,Sylvain Lamprier,James Zou,Marcin Detyniecki", "background": "在高风险应用场景中，AI系统需要生成透明、可解释和可审计的决策，这一要求越来越受到监管机构的认可。决策树方法，如CART，可以提供清晰和可验证的规则，但它们只能处理结构化的表格数据，无法直接处理如文本等非结构化输入。虽然大型语言模型（LLMs）广泛用于处理非结构化数据，但现有的提示策略（如链式思考或提示优化）仍依赖于自由形式的推理，限制了其确保可信赖行为的能力。", "innovation": "我们提出了自主分类树（ACT），这是一种将决策树方法扩展到非结构化输入的方法。ACT通过将每次分割转化为自然语言问题，并通过基于杂质评估和LLM反馈（借助TextGrad）进行优化，解决了传统决策树方法无法处理文本等非结构化数据的问题。实验结果表明，与基于提示的基本方法相比，ACT能够生成同等透明和可解释的决策路径。", "conclusion": "ACT通过改进的分割方法和自然语言提示策略，能够在处理非结构化数据时提供透明、可解释和可审计的决策路径，从而解决了传统决策树方法的局限性。"}
{"llm_update_time": "20251023", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.20214", "html_url": "https://arxiv.org/abs/2509.20214", "title": "Q-Palette: 针对高效大语言模型部署的优化比特分配的分数比特量化器", "title_en": "Q-Palette: Fractional-Bit Quantizers Toward Optimal Bit Allocation for Efficient LLM Deployment", "authors": "Deokjae Lee,Hyun Oh Song", "background": "我们研究了不需要重新训练的数据后处理量化（PTQ），特别是针对大量语言模型（LLM）的仅权重量化方法，这种量化不使用或少量使用校准数据。这种方法对于减少LLM推理的内存占用和延迟尤为重要，尤其是在边缘设备上的个性化推理等场景中。然而，LLM中的非正态分布和重尾异常值使得量化过程复杂化，尤其是在使用旋转方法将权重组分配为更正态、异常值较少的分布后，这种问题仍存在。因此，研究了信息论最优的分数比特量化方法，以实现接近最优的量化性能，并提出了Q-Palette框架来优化各种资源约束下的量化器选择和层融合决策。", "innovation": "本文的主要创新点包括：1) 推导出在给定比特预算下，用于正态化权重的信息理论最优比特分配；2) 引入了一个适应性强的分数比特量化器集合Q-Palette，该集合并提供了从接近最优失真到优化加速推理的简单向量和标量化量化器；3) 提出了一个结合量化器选择和层融合决策的混合量化框架，以优化资源约束下的性能。", "conclusion": "通过Q-Palette框架，量化器的选择和层融合决策得到了优化，从而更好地平衡了计算效率和量化精度。所提出的量化方案和混合量化框架在各种量化位宽和资源约束下均可高效实现。"}
{"llm_update_time": "20251023", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.08450", "html_url": "https://arxiv.org/abs/2510.08450", "title": "gLSTM: 通过增加存储容量缓解过压缩现象", "title_en": "gLSTM: Mitigating Over-Squashing by Increasing Storage Capacity", "authors": "Hugh Blayney,Álvaro Arroyo,Xiaowen Dong,Michael M. Bronstein", "background": "图神经网络（GNNs）利用图结构在节点之间传递信息，通常通过消息传递机制实现。尽管这些模型在各种应用中找到了广泛的用途，但它们会遭受过压缩的困扰，即节点表示的大接收场中的信息被压缩到一个固定大小的向量中，形成信息瓶颈。", "innovation": "本文重新审视了过压缩现象，通过模型的存储和检索容量来研究，提出了一个新的人工合成任务来展示信息瓶颈可以饱和这种容量。进一步地，文章借鉴序列建模中关于联想记忆、快速权重程序员和xLSTM模型的思想来开发了一个新的GNN架构，该架构具有改进的存储容量。并展示了在该容量合成任务和一系列实际图基准测试中的强表现。", "conclusion": "本文提出了一种新颖的GNN架构gLSTM，通过增加存储容量显著缓解了过压缩现象，并在合成任务和实际图基准测试中表现出了较强的性能。"}
{"llm_update_time": "20251023", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.03502", "html_url": "https://arxiv.org/abs/2510.03502", "title": "ALHD：阿拉伯语LLM生成文本检测的大规模多体裁基准数据集", "title_en": "ALHD: A Large-Scale and Multigenre Benchmark Dataset for Arabic LLM-Generated Text Detection", "authors": "Ali Khairallah,Arkaitz Zubiaga", "background": "该研究介绍了ALHD，这是第一个专门为区分人类和LLM生成文本设计的大型综合性阿拉伯语数据集。ALHD涵盖了新闻、社交媒体和评论三种文体，既包括标准现代阿拉伯语（MSA），也包括方言阿拉伯语，包含超过40万平衡样本，这些样本是由三个领先的LLM生成的，来源于多个人类来源。这使得研究阿拉伯语LLM生成文本检测的一般化特性成为可能。ALHD还提供严格的预处理、丰富的标注和标准化的平衡拆分，以支持可再现性。", "innovation": "ALHD是首个专门区分人类和LLM生成文本的大型综合性阿拉伯语数据集，它覆盖了新闻、社交媒体和评论三种文体。ALHD包含了多个人类来源和三个领先LLM生成的超过40万平衡样本，这使得研究阿拉伯语LLM生成文本检测的一般化特性成为可能。此外，研究使用ALHD进行了基准实验，并分析讨论了实验结果，为未来的研究方向提出了新的见解。", "conclusion": "基准化实验表明，微调的BERT模型在阿拉伯语LLM生成文本检测方面取得了竞争性的性能，优于LLM基础模型，但不同模型在不同文体中的表现并不一致，尤其是在新闻文章中，LLM生成的文本与人类文本在风格上相似，这一问题为未来的研究提供了新的方向。ALHD为阿拉伯语LLM检测的研究奠定了基础，有助于减少误导信息、学术不诚实和网络威胁的风险。"}
{"llm_update_time": "20251023", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.11474", "html_url": "https://arxiv.org/abs/2510.11474", "title": "层次化多代理强化学习在现实空中格斗中的协同策略", "title_en": "Coordinated Strategies in Realistic Air Combat by Hierarchical Multi-Agent Reinforcement Learning", "authors": "Ardian Selmonaj,Giacomo Del Rio,Adrian Schneider,Alessandro Antonucci", "background": "在具有不完美的态势感知和非线性飞行动力学的现实空中格斗模拟环境中实现任务目标极具挑战性。", "innovation": "本文提出了一种新颖的3D多代理空中格斗环境和层次化多代理强化学习框架，该框架结合了异构代理动力学、课程学习、联赛制和新适应的训练算法。该方法将决策过程组织成两个抽象级别：低级策略学习精确控制操作，而高级策略根据任务目标发出战术命令。实证结果表明，层次化方法提高了在复杂格斗场景中的学习效率和战斗性能。", "conclusion": "该工作提出的方法显著提升了在真实空中格斗模拟环境中的任务执行能力和学习效率。"}
{"llm_update_time": "20251023", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.08666", "html_url": "https://arxiv.org/abs/2510.08666", "title": "dInfer: 一种高效的大规模语言模型推理框架", "title_en": "dInfer: An Efficient Inference Framework for Diffusion Language Models", "authors": "Yuxin Ma,Lun Du,Lanning Wei,Kun Chen,Qian Xu,Kangyu Wang,Guofeng Feng,Guoshan Lu,Lin Liu,Xiaojing Qi,Xinyuan Zhang,Zhen Tao,Haibo Feng,Ziyun Jiang,Ying Xu,Zenan Huang,Yihong Zhuang,Haokai Xu,Jiaqi Hu,Zhenzhong Lan,Junbo Zhao,Jianguo Li,Da Zheng", "background": "基于扩散的大语言模型（dLLMs）作为一种有前景的替代自回归（AR）语言模型的选择，通过去噪生成来实现固有的并行性。虽然越来越多的开源dLLM模型涌现，但它们的广泛应用仍然受到缺乏标准化且高效的推理框架的限制。", "innovation": "dInfer框架将推理管道分解为四个模块化组件——模型、扩散迭代管理器、解码策略和KV缓存管理器，并为每个组件融入了新的算法，同时结合了系统级优化。通过这种算法创新和系统增强的结合，dInfer在LLaDA-MoE上实现了显著的效率提升，而不会牺牲输出质量。在一批次大小为1的情况下，dInfer在HumanEval上超过每秒1100个标记，并且在八块H800 GPU上六项基准测试中平均超过每秒800个标记。相对于之前的系统，dInfer在速度上比Fast-dLLM提高了10倍，同时保持了相似的模型性能。即使与使用最新vLLM推理引擎进行高度优化的AR模型QWen2.5-3B（具有相同的激活参数数和表现）相比，dInfer仍能提供2-3倍的速度提升。", "conclusion": "dInfer框架作为开源实现，位于此网址：this https URL."}
{"llm_update_time": "20251023", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.05126", "html_url": "https://arxiv.org/abs/2510.05126", "title": "改进语言模型的元认知和不确定性通信", "title_en": "Improving Metacognition and Uncertainty Communication in Language Models", "authors": "Mark Steyvers,Catarina Belem,Padhraic Smyth", "background": "大型语言模型（LLMs）在决策过程中变得越来越普遍，但它们在不显示低信心的情况下提供答案，用户可能无意识地基于错误输出行动。以往研究表明，LLMs 维持着内部不确定性信号，但其输出的信心往往失准，不能很好地区分正确和错误的答案。", "innovation": "我们研究了监督微调是否能提高模型表达不确定性的能力，并考察这些改进是否能在不同任务和领域中泛化。我们对涉及一般知识、数学和开放性 trivia 的数据集进行微调，评估了两类元认知任务：单个问题的信心估计和两个答案的信心比较。", "conclusion": "微调提高了校准（表达的信心与准确性之间的契合度）和区分度（对正确答案的信心高于错误答案），并在不同领域内泛化。但增益具有任务特异性：单个问题校准的训练不能转移到对两个答案的信心比较，反之亦然。多任务微调提供了更广泛的增益，降低了跨领域评估的校准误差，增强了区分度。这表明，LLMs 的不确定性通信是可训练的，但需要多任务训练才能有效泛化。"}
{"llm_update_time": "20251023", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.12829", "html_url": "https://arxiv.org/abs/2510.12829", "title": "用大型语言模型作为证明者和验证者的数学", "title_en": "Mathematics with large language models as provers and verifiers", "authors": "Hieu Le Duc,Leo Liberti", "background": "2024年和2025年，关于大型语言模型证明能力的讨论开始报告一些有趣的成功案例，特别是在解决国际数学奥林匹克难题等复杂问题方面，以及用于验证人工智能能否证明的假设。这些成功案例引发了对大型语言模型在数学证明领域潜力的关注。", "innovation": "本研究报道了一项由ChatGPT通过涉及不同GPT-5模型证明者和验证者实例协作实现的定理证明成就。为确保生成的证明不包含幻觉，最终的证明是由lean证明助手正式验证的，并且通过人工验证了前提和结论的一致性。该方法虽然不完善，但仍能解决2025年IMO的五个问题中的五个，并解决六十六个数论猜想中的三分之二。", "conclusion": "本方法的有效性表明，通过协作的证明者和验证者实例，大型语言模型有能力解决复杂的数学问题，并验证其结论。这种方法在准确性和完整性的方面还有待进一步完善，但已经展示了其在数学证明上的潜力。"}
{"llm_update_time": "20251023", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.09660", "html_url": "https://arxiv.org/abs/2510.09660", "title": "Learning What Matters: Steering Diffusion via Spectrally Anisotropic Forward Noise", "title_en": "Learning What Matters: Steering Diffusion via Spectrally Anisotropic Forward Noise", "authors": "Luca Scimeca,Thomas Jiralerspong,Berton Earnshaw,Jason Hartford,Yoshua Bengio", "background": "生成模型如扩散概率模型（DPMs）已经实现了强大的生成性能，但其推理偏置仍然很大程度上是隐性的。本文旨在将推理偏置构建到扩散模型的训练和采样中，以更好地适应数据的目标分布。现有的扩散模型使用的是各向同性的噪声操作符，本文引入了新的操作符来改变噪声特性，使其更加有针对性。", "innovation": "本文引入了一种谱各向异性高斯扩散（SAGD）方法，通过替换各向同性的前向协方差为一个结构化、频域对角线的协方差来塑造扩散过程的噪声特性。这种方法通过频域权重和带通掩码的结合，可以在不破坏高斯遍历性的前提下，对特定频段的噪声进行强调或抑制。此外，本文还推导了各向异性协方差的得分关系，并证明了通过全支持下的学习，所获得的得分会趋向于真实数据的得分，同时各向异性重塑了噪声到数据的概率流路径。实验证明这种诱导的各向异性性能优于标准扩散，并能在某些视觉数据集上实现选择性剔除：忽略特定频段中的已知腐蚀。", "conclusion": "研究表明，精心设计的各向异性前向噪声提供了一个简单而又基础的方法，可以调整扩散概率模型中的推理偏置。"}
{"llm_update_time": "20251023", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.06293", "html_url": "https://arxiv.org/abs/2510.06293", "title": "BlockGPT：通过帧级自回归建模降雨的空时建模", "title_en": "BlockGPT: Spatio-Temporal Modelling of Rainfall via Frame-Level Autoregression", "authors": "Cristian Meo,Varun Sarathchandran,Avijit Majhi,Shao Hung,Carlo Saccardi,Ruben Imhoff,Roberto Deidda,Remko Uijlenhoet,Justin Dauwels", "background": "预测降水量地图是一项高度复杂的时空建模任务，对于减轻极端天气事件的影响至关重要。短时降水预报（即现在降水预报）需要既准确又在实时应用中计算高效的模型。目前的方法，如基于标记的自回归模型，往往存在归纳偏见错误和复杂的推理问题，而扩散模型则可能计算密集。为了克服这些限制，我们引入了BlockGPT，这是一种使用批量标记化（Block）方法的生成自回归变换器，它可以在每个时间步长上预测完整的二维场（帧）。", "innovation": "BlockGPT 作为一种视频预测的模型可通用范式，通过在每一帧内使用自我注意和跨帧因果注意来分解空间-时间；在本工作中，我们将其应用到降水现在降水预报中。我们在两个降水数据集中对BlockGPT进行了评估，与最先进的基准方法（包括基于标记的NowcastingGPT和基于扩散的DiffCast+Phydnet模型）进行了比较。结果表明，BlockGPT在分类指标衡量的降水事件定位方面表现出更优的准确性，并且推理速度比同类基准快了最高31倍。", "conclusion": "BlockGPT 在短时降水预测方面达到了更高的准确性和更快的推理速度。通过与目前最先进的模型进行对比，BlockGPT 在 KNMI 和 SEVIR 数据集上均表现出了优越的性能。"}
{"llm_update_time": "20251023", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.14623", "html_url": "https://arxiv.org/abs/2510.14623", "title": "LeapFactual: 使用条件流匹配的可靠可视化反事实解释", "title_en": "LeapFactual: Reliable Visual Counterfactual Explanation Using Conditional Flow Matching", "authors": "Zhuo Cao,Xuan Zhao,Lena Krieger,Hanno Scharr,Ira Assent", "background": "随着机器学习（ML）和人工智能（AI）模型在高风险领域，如医疗保健和科学研究中的整合，迫切需要不仅准确而且可解释的模型。现有的可解释方法，例如反事实解释，通过识别更改输入以改变模型预测的最小变化来提供可解释性，从而提供更深入的见解。然而，当前的反事实生成方法存在严重的限制，包括梯度消失、不连续的潜在空间以及对学习决策边界和真实决策边界的对齐过度依赖。", "innovation": "为了克服这些限制，我们提出了一种名为LeapFactual的新型反事实解释算法，基于条件流匹配。LeapFactual在决策边界真实与学习不一致的情况下，仍能生成可靠的、信息丰富的反事实，该方法采用了模型无关的策略，不局限于具有可微损失函数的模型。LeapFactual甚至可以处理人类参与的系统，将反事实解释的范围扩展到需要人类标注员参与的领域，如公民科学。实验表明，LeapFactual能够生成准确、分布内且具有可操作性的反事实解释，结果可用于增强模型训练，提供非专家也就的可解释性。", "conclusion": "LeapFactual方法广泛适用于科学知识发现并增强非专家的可解释性。"}
{"llm_update_time": "20251023", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.15020", "html_url": "https://arxiv.org/abs/2510.15020", "title": "覆盖原则：预训练如何促进后训练", "title_en": "The Coverage Principle: How Pre-Training Enables Post-Training", "authors": "Fan Chen,Audrey Huang,Noah Golowich,Sadhika Malladi,Adam Block,Jordan T. Ash,Akshay Krishnamurthy,Dylan J. Foster", "background": "语言模型在预先在大量文本语料上训练后，并针对特定任务进行微调时，表现出了卓越的能力。然而，预训练如何以及为什么能够形成功能强大的最终模型，仍然了解甚少。通常，预训练的成功用交叉熵损失来量化，但交叉熵无法很好地预测下游任务的性能。因此，本文通过引入“覆盖”这一概念，提供了一个理论视角来解释预训练与下游性能之间的关系，强调了覆盖对于成功后处理和测试时缩放方法的重要性。", "innovation": "本文揭示了一个机制，解释了覆盖为什么能够比交叉熵更好地预测下游性能：覆盖比交叉熵泛化得更快，避免了对特定问题参数（如序列长度）的依赖。此外，还研究了提高覆盖的有效算法干预措施，包括模型/检查点选择流程、梯度规范化方案以及测试时解码策略。", "conclusion": "本文开发了对“覆盖原则”的理解，这是一种现象，即下一标记预测（更广泛地讲是极大似然估计）无形中优化了一个具有良好覆盖性的模型。利用覆盖的机制，我们能够更好地预测下游性能，并通过具体的方法提高模型的覆盖，使最终模型更好地适应实际应用。"}
{"llm_update_time": "20251023", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.17111", "html_url": "https://arxiv.org/abs/2510.17111", "title": "高效视觉-语言-动作模型在嵌入式操作中的系统综述", "title_en": "Efficient Vision-Language-Action Models for Embodied Manipulation: A Systematic Survey", "authors": "Weifan Guan,Qinghao Hu,Aosheng Li,Jian Cheng", "background": "视觉-语言-动作（VLA）模型将自然语言指令和视觉观察映射到机器人动作，尽管其功能强大，但面临巨大的计算和内存需求，这与嵌入式平台（如内置移动 manipulator）的实时性能要求相冲突。因此，解决这一矛盾变得至关重要。", "innovation": "该论文提供了一种系统的方法，以提高 VLA 系统的效率，主要关注减少延迟、内存占用和训练及推断成本，按模型架构、感知特征、动作生成和训练/推断策略对现有解决方案进行分类，总结了代表性技术。", "conclusion": "最后，讨论了未来趋势和开放挑战，指出了促进高效嵌入式智能的方向。"}
{"llm_update_time": "20251023", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.16853", "html_url": "https://arxiv.org/abs/2510.16853", "title": "Agentic Inequality", "title_en": "Agentic Inequality", "authors": "Matthew Sharp,Omer Bilgin,Iason Gabriel,Lewis Hammond", "background": "自主人工智能代理能够进行复杂规划和行动，超越了当前的生成工具，标志着技术的显著进步。随着这些系统逐渐融入政治和经济生活，它们的分布和能力将具有重大意义。该论文探讨了代理不平等的概念，即由于AI代理访问和能力的差别导致的权力、机会和结果的不平等。", "innovation": "该论文提供了代理不平等的分析框架，阐述了不平等可能以三个方面体现：代理的可获得性、质量和数量的差异。同时，论文还指出代理不平等有别于以往的技术鸿沟，代理作为自主代理人在多个层面创造新的权力不对称，有可能重塑经济和社会政治领域的结果。此外，该论文系统分析了技术和社会经济动因，这些因素将塑造代理权力的分布。", "conclusion": "该论文提出了一个研究议程，旨在应对未来复杂的治理挑战。通过分析和研究技术发布策略、市场激励等因素，以合理分配代理权力。"}
{"llm_update_time": "20251023", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.16708", "html_url": "https://arxiv.org/abs/2510.16708", "title": "自然语言处理在心脏病学中的应用：综述", "title_en": "Natural Language Processing for Cardiology: A Narrative Review", "authors": "Kailai Yang,Yan Leng,Xin Zhang,Tianlin Zhang,Paul Thompson,Bernard Keavney,Maciej Tomaszewski,Sophia Ananiadou", "background": "心血管疾病在现代社会中的发病率越来越高，对全球健康和福祉产生了深远影响。这些心血管疾病是复杂且多因素的，受遗传倾向、生活方式选择以及多元的社会经济和临床因素的影响。这种相互关联的信息散见于各种类型的文本数据中，如患者的叙述、医疗记录和科学文献。自然语言处理(NLP)作为一种强有力的工具，能够分析这些非结构化数据，帮助医疗专业人员和研究人员获得深入的洞察，进而革新心脏病的诊断、治疗和预防。", "innovation": "本研究提供了一个从2014年到2025年的全面综述，系统搜索了六个文献数据库，分析了涉及心血管疾病的NLP应用。研究揭示了NLP在心脏病学中的应用多样性，反映了该领域的广度和进步。研究进一步指出从规则系统到大规模语言模型的方法学趋势，并讨论了构建可解释的大规模语言模型和整合多模态数据的关键挑战。", "conclusion": "据我们所知，这是迄今为止关于NLP在心脏病学领域最全面的研究综述。"}
{"llm_update_time": "20251023", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.16062", "html_url": "https://arxiv.org/abs/2510.16062", "title": "LLMs能否自我校正？一种评价LLM自我校正基准", "title_en": "Can LLMs Correct Themselves? A Benchmark of Self-Correction in LLMs", "authors": "Guiyao Tie,Zenghui Yuan,Zeli Zhao,Chaoran Hu,Tianhe Gu,Ruihang Zhang,Sizhe Zhang,Junran Wu,Xiaoyue Tu,Ming Jin,Qingsong Wen,Lixing Chen,Pan Zhou,Lichao Sun", "background": "大规模语言模型（LLMs）的自我纠正功能被认为是提升其推理性能的关键组成部分。尽管已经提出了多种自我纠正方法，但对于这些方法的全面评估仍然尚未充分展开，尤其是在考虑大规模语言模型是否真的能够自我纠正这一问题上，存在显著的不确定性和研究兴趣。已有研究表明，自我纠正方法可以通过增强复杂推理任务的准确性来改善性能，但同时也面临效率下降的挑战。因此，有必要开发一个基准来评价各种自我纠正策略的有效性，以理解其在不同推理任务中的实际效果和适用性。", "innovation": "该研究提出了CorrectBench，这是一个用于评估自我纠正策略有效性的基准，涵盖了三个任务：常识推理、数学推理和代码生成。包含内在、外部和微调的自我纠正方法。研究发现，自我纠正方法可以提高准确性，特别是在复杂的推理任务中；混合不同策略可以进一步提高性能，但也降低了效率；推理LLMs（如DeepSeek-R1）在额外的自我纠正方法下的优化有限，且时间成本高。简单的方法如链式思考模型显示出了与复杂方法相当的准确性和效率。这些发现强调了自我纠正可能增强LLM推理性能的同时，也指出了提升其效率的持续挑战。研究表明，进一步的研究应集中在优化推理能力和操作效率之间的平衡上。", "conclusion": "该研究通过开发CorrectBench基准，揭示了自我纠正方法在提高LLM推理准确性方面的潜力及面对的效率挑战。研究强调了进一步优化和平衡LLM推理能力和操作效率的重要性。"}
{"llm_update_time": "20251023", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.15297", "html_url": "https://arxiv.org/abs/2510.15297", "title": "VERA-MH概念论文", "title_en": "VERA-MH Concept Paper", "authors": "Luca Belli,Kate Bentley,Will Alexander,Emily Ward,Matt Hawrilenko,Kelly Johnston,Mill Brown,Adam Chekroud", "background": "介绍了VERA-MH（验证心理健康领域中使用的AI聊天机器人安全性），这是一种自动化评估工具，用于确保在心理健康情境下使用的AI聊天机器人安全性，特别是针对自杀风险的评估。该工具基于最佳实践开发了一个评估清单，并采用两个辅助AI代理来实现自动化过程：用户代理模拟用户与需要评估的聊天机器人进行心理健康相关对话，模拟特定的人格并具有预定义的风险等级和其他特征；评审代理根据评估清单对对话进行评分。最终通过汇总每个对话的得分来评估聊天机器人的安全性。该工具目前正处于开发阶段，并由心理健康临床专业人员进行严格的验证，以确保用户代理能够真实地模拟患者，且评审代理能够准确地评分。迄今为止，已经初步评估了GPT-5、Claude Opus和Claude Sonnet，使用VERA-MH初步版本的评估清单，并根据这些发现进行进一步的设计发展。下一阶段将包括更严格的临床验证和迭代，以及细化评分标准。寻求来自社区的技术和临床方面的反馈", "innovation": "VERA-MH引入了一项创新的自动化评估工具，用于评价心理健康领域中使用的AI聊天机器人，特别是针对自杀风险的评估。通过模拟真实用户与聊天机器人对话并由评审代理评分，实现了全面自动化的过程，并结合了人工智能代理（用户代理和评审代理）来执行此过程。该工具的发展旨在确保其能够准确评估AI聊天机器人的安全性和有效性，从而为心理健康服务提供支持", "conclusion": "VERA-MH目前尚处于开发阶段，正在由心理健康领域的临床专业人员进行严格的验证。初步评估表明，该工具可以用于评估GPT-5、Claude Opus和Claude Sonnet等AI聊天机器人的安全性，并将进一步利用反馈进行迭代和优化。寻求来自社区的技术和临床方面的反馈，以促进未来的设计和验证工作"}
{"llm_update_time": "20251023", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.17482", "html_url": "https://arxiv.org/abs/2510.17482", "title": "SparseWorld: 由稀疏和动态查询驱动的灵活、适应性强且高效的4D占用世界模型", "title_en": "SparseWorld: A Flexible, Adaptive, and Efficient 4D Occupancy World Model Powered by Sparse and Dynamic Queries", "authors": "Chenxu Dang,Haiyan Liu,Guangjun Bao,Pei An,Xinyue Tang,An Pan,Jie Ma,Bingchuan Sun,Yan Wang", "background": "语义占用在世界模型中作为强大的表示形式出现，因其能够捕捉丰富的空间语义。然而，现有的大多数占用世界模型依赖于静态和固定的嵌入或网格，这在感知的灵活性上存在固有的限制。此外，它们基于网格的空间位置分类方法与现实世界的动态和连续性可能存在潜在的不匹配。", "innovation": "本文提出SparseWorld，一种新颖的4D占用世界模型，具备灵活性、适应性和高效性，基于稀疏和动态查询。本文设计了一个范围自适应感知模块，通过可学习的查询被自车状态调节，并增强时空关联，以实现拓展范围的感知。为了捕捉场景的动态属性，我们设计了一个状态条件预测模块，将基于分类的预测替换为回归引导的表述，使动态查询与4D环境的连续性精确对齐。此外，设计了一种时间感知自调度训练策略，以实现平滑高效的训练。", "conclusion": "广泛的实验表明，SparseWorld在感知、预测和规划任务中实现了最先进的性能。全面的可视化和消融研究进一步验证了SparseWorld在灵活性、适应性和效率方面的优势。代码已在以下地址提供：this https URL"}
{"llm_update_time": "20251023", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.17501", "html_url": "https://arxiv.org/abs/2510.17501", "title": "基于上下文感知伪标签评分的零样本视频摘要", "title_en": "Context-Aware Pseudo-Label Scoring for Zero-Shot Video Summarization", "authors": "Yuanli Wu,Long Zhang,Yue Du,Bin Li", "background": "现有零样本视频摘要方法依赖大量人工注释，难以处理大规模数据集。本文提出了一种结合大规模语言模型与结构化语义推理的框架，通过少量人工注释生成高质量的伪标签，并组织成适应数据集的评分标准，以评估主题相关性、动作细节和叙事进展。在推理阶段，框架能够平衡局部显著性和全局连贯性，无需参数调整，从而克服了传统方法的局限性。", "innovation": "本文创新性地提出了结合上下文感知伪标签评分的方法，通过少量人工标注数据生成高质量伪标签，并将其组织成动态适应数据集的评分标准，该方法能有效平衡局部显著性和全局连贯性，无需调整模型参数。", "conclusion": "在三个基准数据集SumMe、TVSum和QFVS上，本文方法分别取得了F1分数57.58、63.05和53.79的成绩，超过了零样本基线方法。实验结果表明，基于指标引导的伪标签标注结合上下文提示有助于稳定和提升大规模语言模型的评分效果，为通用及查询导向的视频摘要提供了一个通用、可解释且无需训练的范式。"}
{"llm_update_time": "20251023", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.17519", "html_url": "https://arxiv.org/abs/2510.17519", "title": "MUG-V 10B: 高效率训练流水线用于大规模视频生成模型", "title_en": "MUG-V 10B: High-efficiency Training Pipeline for Large Video Generation Models", "authors": "Yongshun Zhang,Zhongyi Fan,Yonghang Zhang,Zhangzikang Li,Weifeng Chen,Zhongwei Feng,Chaoyue Wang,Peng Hou,Anxiang Zeng", "background": "近年来，用于视觉内容（例如图像、视频和3D对象/场景）的大规模生成模型取得了显著进展。然而，训练大规模视频生成模型仍然特别具有挑战性和资源密集型，这主要是由于跨模态文本-视频对齐、长序列以及复杂的时空依赖性.", "innovation": "本文提出了一种训练框架，优化了四个支柱：（i）数据处理，（ii）模型架构，（iii）训练策略，以及（iv）大规模视频生成模型的基础设施。这些优化在整个数据预处理、视频压缩、参数缩放、基于课程的预训练和对齐导向的后训练阶段带来了显著的效率提升和性能改进。我们的模型MUG-V 10B在整体上达到了与最新的视频生成器相近的水平，并且在面向电商平台的视频生成任务中，通过人工评估超过了最先进的开源基线。此外，我们开源了整个栈，包括模型权重、基于Megatron-Core的大规模训练代码以及视频生成和增强的推理管道。据我们所知，这是首次公开发布基于Megatron-Core利用高效训练代码并实现近线性多节点扩展的大规模视频生成训练代码.", "conclusion": "我们的模型MUG-V 10B实现了与最新视频生成器相近的整体性能，特别是在面向电子商务的视频生成任务中，通过人工评估超越了领先的开源基线。此外，我们还开源了整个训练和推理流程，以实现高效训练和近线性多节点扩展的目标。"}
{"llm_update_time": "20251023", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.17830", "html_url": "https://arxiv.org/abs/2510.17830", "title": "多智能体设计助理用于惯性聚变能的模拟", "title_en": "Multi-Agent Design Assistant for the Simulation of Inertial Fusion Energy", "authors": "Meir H. Shachar(1),Dane M. Sterbentz(1),Harshitha Menon(1),Charles F. Jekel(1),M. Giselle Fernández-Godino(1),Nathan K. Brown(2),Ismael D. Boureima(3),Yue Hao(1),Kevin Korner(1),Robert Rieben(1),Daniel A. White(1),William J. Schill(1),Jonathan L. Belof(1) ((1) Lawrence Livermore National Laboratory Livermore, CA, USA, (2) Sandia National Laboratories Albuquerque, NM, USA (3) Los Alamos National Laboratory Los Alamos, NM, USA)", "background": "惯性聚变能有望提供几乎无限且清洁的能源，但其系统设计和工程需要在极端条件下控制和操作物质，这对于理解材料行为的关键物理过程增加了复杂性。这需要开发、校准和使用预测性多物理场代码来导航复杂的非线性设计环境。本文假设可以将人工智慧推理模型与物理代码和模拟器结合，自主设计聚变燃料容器。在这种背景下，研究者构建了一个多智能体系统，利用自然语言探索聚变能周围的复杂物理领域。系统能够执行高阶多物理场惯性聚变计算代码，展示了多智能体设计助理在合作和自主操作、导航和优化燃料容器几何结构方面的能力，并最终通过逆向设计实现模拟点火，同时考虑高度准确的物理因素。", "innovation": "本文的创新在于提出了利用人工智慧推理模型和物理代码及模拟器相结合的方法，自主设计聚变燃料容器的多智能体系统。这种系统通过自然语言交互，不仅可以帮助理解和探索复杂物理环境，还能执行高阶多物理场计算，并实现自主设计和优化，从而提高了聚变燃料容器设计的效率和精确性。", "conclusion": "研究者成功构建了一个能够执行高阶多物理场惯性聚变计算代码的多智能体系统，通过自然语言交互展示了多智能体设计助理在设计聚变燃料容器方面的强大能力，包括自主操作、导航和优化。最终通过逆向设计实现了模拟点火，表明该系统在实际应用中具有潜在的巨大价值。"}
{"llm_update_time": "20251023", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.18888", "html_url": "https://arxiv.org/abs/2510.18888", "title": "使用大型语言模型进行实体链接的上下文增强", "title_en": "Contextual Augmentation for Entity Linking using Large Language Models", "authors": "Daniel Vollmers,Hamada M. Zahera,Diego Moussallem,Axel-Cyrille Ngonga Ngomo", "background": "实体链接涉及在自然语言文本中检测并链接实体提及到知识图谱。传统的实体链接方法采用两步流程，分别使用实体识别和消歧模型，这往往计算量大且效果有限。", "innovation": "提出了一种微调模型，将其实体识别和消歧辨别统一到一个框架中，同时利用大型语言模型增强实体提及的上下文，提升实体消歧效果。并在基准数据集上与多个基准模型进行了对比实验。", "conclusion": "实验结果表明，该方法在领域外数据集上达到了最先进的性能。"}
{"llm_update_time": "20251023", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.18279", "html_url": "https://arxiv.org/abs/2510.18279", "title": "文本或像素？只需一半：多模态LLMs中视觉文本输入的令牌效率研究", "title_en": "Text or Pixels? It Takes Half: On the Token Efficiency of Visual Text Inputs in Multimodal LLMs", "authors": "Yanhong Li,Zixuan Lan,Jiawei Zhou", "background": "大型语言模型（LLMs）及其多模态变体现在可以处理视觉输入，包括文本图像。这引发了一个有趣的问题：我们能否通过将文本输入作为图像输入来压缩文本，从而减少令牌使用量，同时保持性能？", "innovation": "本文展示了视觉文本表示是解码器LLMs的一种实用且出乎意料有效的输入压缩形式。我们利用将长文本输入渲染为单个图像并直接提供给模型的想法，从而显著减少了所需的解码器令牌数量，为输入压缩提供了一种新方法。通过在两个不同的基准RULER（长上下文检索）和CNN/DailyMail（文档摘要）上的实验，我们证明了这种文本作为图像的方法能够显著节省令牌（常常接近一半），并且不降低任务性能。", "conclusion": "通过实验表明，视觉图像作为输入的方法可以在不影响任务性能的情况下，显著减少解码器令牌数量，提供了一种新的输入压缩方式。"}
{"llm_update_time": "20251023", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.17947", "html_url": "https://arxiv.org/abs/2510.17947", "title": "PLAGUE：面向终身自适应生成多轮攻击的即插即用框架", "title_en": "PLAGUE: Plug-and-play framework for Lifelong Adaptive Generation of Multi-turn Exploits", "authors": "Neeladri Bhuiya,Madhav Aggarwal,Diptanshu Purwar", "background": "大语言模型（LLMs）正在以惊人的速度发展，多轮对话已成为与LLM交互的主要方式，用于完成复杂的长期任务。尽管LLM的能力持续提升，但在多轮场景中，它们越来越容易受到破解（jailbreaking）的攻击，特别是在对话过程中，有害意图可以逐步渗透，从而导致不良后果。尽管针对单轮攻击的研究较为充分，但适应性、效率和效果仍是多轮攻击主要面临的挑战。为解决上述问题，该研究提出了PLAGUE框架，这是一种受终身学习启发的多轮攻击设计的即插即用框架。", "innovation": "PLAGUE框架将多轮攻击的生命周期分为三个精心设计的阶段（Primer，Planner和Finisher），这使对多轮攻击系列的系统和信息丰富的探索成为可能。评估表明，使用PLAGUE设计的红队代理在减少或差不多的查询预算下，获得了最先进的破解结果，成功率（ASR）提高了30%以上。特别是在针对OpenAI的o3和Claude的Opus 4.1（这两种被认为在安全性文献中高度抗破解的模型），PLAGUE能够实现基于StrongReject的ASR分别为81.4%和67.3%。本研究提供了工具和见解，用于理解计划初始化、上下文优化和终身学习在构建全面模型漏洞评估的多轮攻击中的重要性。", "conclusion": "PLAGUE框架显著提高了多轮攻击的性能，特别是在 CrackMe 等安全测评任务中表现出色，提供了深入理解多轮攻击设计的新方法。"}
{"llm_update_time": "20251023", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.18221", "html_url": "https://arxiv.org/abs/2510.18221", "title": "大规模生态环境中的复杂行为涌现", "title_en": "The Emergence of Complex Behavior in Large-Scale Ecological Environments", "authors": "Joseph Bejjani,Chase Van Amburg,Chengrui Wang,Chloe Huangyuan Su,Sarah M. Pratt,Yasin Mazloumi,Naeem Khoshnevis,Sham M. Kakade,Kianté Brantley,Aaron Walsman", "background": "本文探讨了物理规模和人口数量如何塑造开放生态环境中复杂行为的出现。在本文设定中，代理是未经监督的，没有明确的奖励或学习目标，而是根据繁殖、突变和自然选择的时间进程演化。随着代理的行动，它们不仅塑造了其环境，还影响了周围的人群，在不断动态的生态中演变。研究目标不是优化单一高性能策略，而是考察由于自然竞争和环境压力，大规模人口中行为如何出现和进化。", "innovation": "本文通过大规模世界中的实验，揭示了复杂行为如何自然涌现，这些实验中的世界人口超过60,000个个体代理，每个代理具有自己进化的神经网络策略。文章识别了各种涌现行为，如远程资源提取、基于视觉的觅食和捕食。研究发现，感知模态和环境规模如何影响这些行为的出现，大型环境和人口下更多行为得以出现，较大的规模增加了行为的稳定性和一致性。与进化设置中的丰富研究史相比，本文的扩展结果为利用生态作为机器学习工具提供了新的方向，特别是在计算资源丰富的时代。", "conclusion": "研究结果表明，通过大规模的动态生态模拟，能观察到复杂行为在生存和竞争压力下逐步涌现。结果显示，适当规模的环境和种群有助于不同行为模式的稳定形成，证明了生态作为一种机器学习工具的有效性。此外，研究提出了未来研究的方向，旨在进一步探索生态在机器学习中的应用潜力。"}
{"llm_update_time": "20251023", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.18876", "html_url": "https://arxiv.org/abs/2510.18876", "title": "Grasp Any Region: 旨在实现多模态大语言模型的精确和上下文像素理解", "title_en": "Grasp Any Region: Towards Precise, Contextual Pixel Understanding for Multimodal LLMs", "authors": "Haochen Wang,Yuhao Wang,Tao Zhang,Yikang Zhou,Yanwei Li,Jiacong Wang,Jiani Zheng,Ye Tian,Jiahao Meng,Zilong Huang,Guangcan Mai,Anran Wang,Yunhai Tong,Zhuochen Wang,Xiangtai Li,Zhaoxiang Zhang", "background": "多模态大型语言模型（MLLMs）虽然在整体理解方面表现出色，但是在处理包含复杂场景的密集世界时存在局限性，尤其是需要细致入微的背景分析和对象间关系的细粒度分析。尽管区域级别的MLLMs已经取得了一定进展，但早期版本通常仅专注于理解单独的区域，忽视了重要的全局上下文。因此，本文提出了Grasp Any Region（GAR）方法，旨在提供全面的区域级视觉理解，特别强调结合必要全局信息实现精确感知，并支持多提示的交互建模和高级组合推理能力，从而实现主动对话式的详细问题回答，而不只是被动描述。", "innovation": "1. 通过RoI-对齐特征回放技术，GAR能够在理解每个单独区域的同时，精确利用全局上下文信息进行感知；2. 支撑多提示之间的交互建模，实现高级组合推理，能够回答关于任何区域的特定开放问题；3. 除了单区域理解基准GAR-Bench之外，还构建了衡量跨多个区域交互和复杂推理的新基准，证明了GAR-1B模型不仅在描述能力上达到行业领先水平，还能够处理多提示关系，甚至在某些情况下超越更大规模的模型；4. 零样本GAR-8B模型在视频理解任务上也表现出色，证明其能力可以很容易地应用于视频领域，显示出其强大的迁移能力。", "conclusion": "GAR模型不仅在单个区域的描述上保持了最佳性能，还能处理多提示关系，超出更大规模模型的表现。此外，零样本GAR-8B模型在特定视频理解基准上超越了专业视频模型，表明该模型具有很强的迁移性。这标志着从被动描述时代到积极对话式理解时代的转变。"}
{"llm_update_time": "20251023", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.18890", "html_url": "https://arxiv.org/abs/2510.18890", "title": "小型语言模型为科学社区提供了巨大潜力", "title_en": "Small Language Models Offer Significant Potential for Science Community", "authors": "Jian Zhang", "background": "随着自然语言处理（NLP）的最新发展，尤其是大型语言模型（LLMs）的应用，科学家们与文献的互动方式正在发生变化。尽管LLMs的使用正在增加，但仍存在信息偏差和计算成本的担忧。本文提出了一种框架，旨在评估使用小型语言模型（MiniLMs）从大量地质科学文献中快速且经济地检索精确信息的可行性。", "innovation": "该研究开发了一种框架，使用MiniLMs通过语义搜索技术和句子级别索引从高度编目语料库中提取相关领域特定信息，这种方法在识别大量经专家验证的信息和建立跨学科来源方面优于LLMs（如ChatGPT-4）生成的一般性回答。此外，通过情感分析和句子内的无监督聚类技术跟踪结论、研究优先级、进展和新兴问题的演变。", "conclusion": "MiniLMs在地质科学领域具有重要潜力，可用于事实检索、趋势分析、矛盾分析和教育目的等方面。"}
{"llm_update_time": "20251023", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.18898", "html_url": "https://arxiv.org/abs/2510.18898", "title": "基于Transformer的低资源语言翻译：从标准孟加拉语到西莱西语的研究", "title_en": "Transformer-Based Low-Resource Language Translation: A Study on Standard Bengali to Sylheti", "authors": "Mangsura Kabir Oni,Tabia Tanzin Prama", "background": "机器翻译（MT）已经从基于规则和统计的方法进展到了基于Transformer架构的神经方法。虽然这些方法在高资源语言方面取得了令人印象深刻的结果，但对于西莱西语等低资源语言仍有待探索。本研究通过微调多语言Transformer模型并将其与零样本大型语言模型（LLMs）进行比较，考察了孟加拉语到西莱西语的翻译。", "innovation": "研究使用了微调多语言Transformer模型并将其与零样本大型语言模型进行比较来解决低资源语言翻译问题，发现了针对低资源语言的任务特定适应的重要性。", "conclusion": "实验结果表明，微调模型显著优于LLMs，mBART-50在翻译契合度方面表现出最佳性能，MarianMT在字符级别保真度方面表现最强。这些发现突显了适应低资源语言的重要性，并促进了包容性语言技术的努力。"}
{"llm_update_time": "20251023", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.18431", "html_url": "https://arxiv.org/abs/2510.18431", "title": "ScaleNet: 使用增量参数扩展预训练神经网络", "title_en": "ScaleNet: Scaling up Pretrained Neural Networks with Incremental Parameters", "authors": "Zhiwei Hao,Jianyuan Guo,Li Shen,Kai Han,Yehui Tang,Han Hu,Yunhe Wang", "background": "近期的研究表明，更大的视觉Transformer（ViT）模型通常能够实现更好的性能。然而，训练这些模型在计算上仍然是极具挑战性和昂贵的。为了应对这一挑战，我们介绍了ScaleNet，一种高效的ViT模型扩展方法。这种方法通过利用现有的预训练模型，以较少的参数增加来实现快速模型扩展，从而提供了一种成本效益高的解决方案来扩展ViTs。具体而言，ScaleNet通过在预训练的ViT模型中插入额外的层，并利用层间的权重共享来实现模型扩展，以此来保持参数的高效性。为了缓解因权重共享可能带来的性能下降，ScaleNet为每个层引入了一组小型调整参数，并通过并行适配器模块来确保每个共享参数张量的独特性和优化性，即确保每个共享参数张量都针对其特定功能进行了优化。", "innovation": "ScaleNet通过在预训练的ViT模型中插入额外的层，并利用层间的权重共享来实现模型扩展，同时通过引入调整参数来确保每个层的独特性和优化性。这种方法不仅提高了模型扩展的效率，同时也降低了成本，使得预训练神经网络的扩展变得更加可行和经济高效。此外，ScaleNet在ImageNet-1K数据集上的实验表明，即使只使用与其训练从零开始的模型一半的训练周期，也可以实现性能的显著改进。这进一步证明了其在扩展ViTs方面的高效性。除了图像分类领域，这种方法还展示了在下游视觉任务（如目标检测）中具有显著应用潜力。", "conclusion": "实验结果表明，ScaleNet能够在成本效益上有效扩展ViT模型。通过实验验证，即使扩展后的模型深度是DeiT-Base的两倍，相对训练从零开始的方法也只增加了20%的层数，但模型性能提升了7.42%，且只需要三分之一的训练周期，突显了其在扩展ViTs的高效性。ScaleNet为大规模模型的快速扩展提供了一种切实可行的方法，并为未来在下游视觉任务中的应用奠定了基础。"}
{"llm_update_time": "20251023", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.18892", "html_url": "https://arxiv.org/abs/2510.18892", "title": "当模型无法遵循指令：256个LLM的指令遵守测试", "title_en": "When Models Can't Follow: Testing Instruction Adherence Across 256 LLMs", "authors": "Richard J. Young,Brandon Gillins,Alice M. Matthews", "background": "尽管大型语言模型（LLM）已被广泛部署，但对其指令遵循能力的系统性评价仍具有挑战性。虽然存在全面的基准测试，但针对特定指令遵守模式进行快速诊断的集中的评估工具仍然有价值。鉴于最新模型可能基于现有基准进行训练，需要新的评估方法来评估其实质能力，而不是简单的记忆表现。这项研究提出了一个由20个精心设计的提示组成的简化评估框架，用于评估不同任务类别中的LLM指令遵循能力，并通过大规模实验证明了该框架的有效性。", "innovation": "该研究提供了一种实用的评估工具，其中包含一个高效的测试套件，该套件基于可验证指令并平衡了全面性和效率。每个提示针对指令遵循的不同方面，包括格式合规性、内容约束、逻辑顺序和多步任务执行。研究还提供了对主要提供商和新兴实现的LLM的大规模比较分析，揭示了一致的失败模式，并识别了特定类型的指令构成了重大挑战。", "conclusion": "研究结果不仅提供了一种实用的评估工具，还提供了关于当今LLM前沿最全面的指令遵循能力实证分析之一。该研究的方法学严谨，防止了选择偏见，并且提供了一种研究人员和实践者可以立即应用的实用诊断工具。"}
{"llm_update_time": "20251023", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.18904", "html_url": "https://arxiv.org/abs/2510.18904", "title": "DuoLens: 一种用于检测多语言文本和代码的鲁棒机器生成内容框架", "title_en": "DuoLens: A Framework for Robust Detection of Machine-Generated Multilingual Text and Code", "authors": "Shriyansh Agrawal,Aidan Lau,Sanyam Shah,Ahan M R,Kevin Zhu,Sunishchal Dev,Vasu Sharma", "background": "大型语言模型（LLMs）在生成多语言文本和源代码方面日益普及，这增加了对能够准确高效地检测机器生成内容的检测器的需求。当前的检测器大多依赖于零样本方法（例如Fast DetectGPT或GPTZero），但这些方法要么计算成本高，要么准确率不足，往往需要在这两者之间做出权衡。", "innovation": "我们提出对RoBERTA和CodeBERTa等编码器型小型语言模型（SLMs）进行微调，使用专门的数据集训练这些模型，以证明在二分类任务上，SLMs的性能远超LLMs，消耗的计算资源仅为后者的几分之一。我们的编码器在512个token输入的情况下，AUCROC达到0.97到0.99，宏观F1值达到0.89到0.94，同时延迟减少了8到12倍，内存使用减少了3到5倍。在跨生成器转移和对抗变换（如改写、反向翻译；代码格式化/重命名）的情况下，性能保持在92%以上。", "conclusion": "我们发布了训练和评估脚本，以及可复现实验的检查表，证明了SLMs在检测机器生成的多语言文本和代码方面具有强大的性能和效率。"}
{"llm_update_time": "20251023", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.18908", "html_url": "https://arxiv.org/abs/2510.18908", "title": "使用重写改进社交媒体短文本的主题建模：COVID-19 相关推文案例研究", "title_en": "Improving Topic Modeling of Social Media Short Texts with Rephrasing: A Case Study of COVID-19 Related Tweets", "authors": "Wangjiaxuan Xin,Shuhua Yin,Shi Chen,Yaorong Ge", "background": "社交媒体平台如X（原Twitter）提供了丰富的数据资源，用于分析公众话语，特别是在COVID-19等危机期间。社交媒体短文本常常具有简短、非正式和嘈杂的特点，这往往阻碍了传统主题建模的有效性，导致生成难以解读的不相干或重复的主题。本文旨在解决这些问题。", "innovation": "本文开发了\textit{TM-Rephrase}模型，这是一种模型无关的框架，利用大型语言模型（LLM）在进行主题建模之前将原始推文重写为更标准化和正式的语言。文章使用25,027条COVID-19相关的推文数据集来考察两种重写策略（通用到正式重写和非正式到正式重写）对多种主题建模方法的影响，结果显示\textit{TM-Rephrase}提高了三种衡量主题建模性能的指标（即主题连贯性、主题独特性和主题多样性），减少了主题冗余，特别是对于Latent Dirichlet Allocation (LDA)算法，效果最为显著。", "conclusion": "本文的贡献在于为公共卫生相关的社交媒体分析提供了一种模型无关的主题建模增强方法，有助于更深入地理解公共卫生危机下的公众话语，对其他重要领域也有广泛的影响。"}
{"llm_update_time": "20251023", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.18909", "html_url": "https://arxiv.org/abs/2510.18909", "title": "从最好的数据中学习，不同地：数据选择的多样性驱动再思考", "title_en": "Learning from the Best, Differently: A Diversity-Driven Rethinking on Data Selection", "authors": "Hongyi He,Xiao Liu,Zhenghao Lin,Mingni Tang,Yi Cheng,Jintao Wang,Wenjie Li,Peng Cheng,Yeyun Gong", "background": "高质量的预训练数据对于大规模语言模型至关重要，质量涵盖事实可靠性和语义价值，多样性确保广泛的覆盖和分布异质性。现有的方法通常依赖于单维度或多维度基于评分的选择。然而，直接选择高评分的数据往往会降低性能，需要从更广泛的范围内进行采样以恢复结果。这种数据集评分和下游基准结果之间的非单调性揭示了一个基本的偏差：基于评分的方法会压缩相关维度，导致高评分数据看似高质量，而系统地忽视了多样性。", "innovation": "提出了正交多样化感知选择（ODiS）算法，该算法在数据选择过程中同时保留质量和多样性。通过多维度评估数据，覆盖语言质量、知识质量和理解难度，并使用主成分分析（PCA）将多维评分去相关化，得到正交评估维度。对于每个维度，使用基于Roberta的评分器进行回归训练，使得对大规模语料库进行可扩展推理成为可能。最后，通过在每个正交维度中选择高评分数据构建训练数据集，从而确保质量和多样性。", "conclusion": "实验结果显示，ODiS选择的数据在各个维度上的重叠少于2%，表明各维度之间的正交性。更重要的是，使用ODiS选择的数据训练的模型在下游基准测试中显著优于其他基线，强调了对LLMs进行正交、多样化感知的数据选择的必要性。"}
{"llm_update_time": "20251023", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.18915", "html_url": "https://arxiv.org/abs/2510.18915", "title": "MMAO-Bench: 多模态一揽子基准揭示统一模态和单模态间的关系", "title_en": "MMAO-Bench: MultiModal All in One Benchmark Reveals Compositional Law between Uni-modal and Omni-modal in OmniModels", "authors": "Chen Chen,ZeYang Hu,Fengjiao Chen,Liya Ma,Jiaxing Liu,Xiaoyu Li,Xuezhi Cao", "background": "多模态大型语言模型正在从单一模态理解向统一视觉、音频和语言模态演进，被称为全模态模型。然而，单模态与全模态之间的关系尚未完全明了，需要进行全面评估以推动全模态模型的智能化发展。", "innovation": "提出了一个多模态高质量且多样性的全模态模型基准，即 MultiModal All in One Benchmark (MMAO-Bench)，能够同时评估单模态和全模态的理解能力。该基准包含1880个人工标注的数据样本，涵盖了44种任务类型，并引入了一种创新的多步骤开放式问题类型，可以更好地评估复杂推理任务。通过实验结果显示了跨模态与单模态性能之间的组成规律，以及全模态能力在表现较弱的模型上表现出瓶颈效应，但在强模型上表现为协同促进效应。", "conclusion": "该基准有效展示了单模态和全模态之间的关系，并揭示了性能上的组成规律，对全模态模型的智能发展具有重要意义。"}
{"llm_update_time": "20251023", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.18932", "html_url": "https://arxiv.org/abs/2510.18932", "title": "通过大规模社会结构网络分析评估大语言模型的故事情节生成", "title_en": "Evaluating LLM Story Generation through Large-scale Network Analysis of Social Structures", "authors": "Hiroshi Nonaka,K. E. Perry", "background": "评估大语言模型（LLMs）在复杂任务中的创造性能力通常需要进行难以扩大的人类评估。为了克服这一挑战，本文提出了一种新的、可扩展的方法，通过分析叙事中的潜在社会结构来评估LLMs的故事情节生成能力。具体来说，该方法利用了签字字符网络来解析和评估网络属性，如密度、聚类和带有符号边权重的网网络特性。", "innovation": "提出了一个创新的方法，通过大规模的社会结构网络分析来评估LLMs的故事情节生成能力。这种方法利用签字字符网络来解析和评估网络属性。通过与超过1,200个故事的比较分析，该方法能够识别LLMs生成的故事中的共同倾向和限制。", "conclusion": "基于网络属性的研究发现表明，LLMs生成的故事具有一致的紧密联系、正向关系的偏好特征。该提议的方法为评估当前和未来LLMs的创造性故事情节提供了有价值的工具，并且有助于识别和理解其潜在的限制和倾向。"}
{"llm_update_time": "20251023", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.19005", "html_url": "https://arxiv.org/abs/2510.19005", "title": "LLM过敏动态评估", "title_en": "Dynamic Evaluation for Oversensitivity in LLMs", "authors": "Sophia Xiao Pu,Sitao Cheng,Xin Eric Wang,William Yang Wang", "background": "语言模型在处理可能有害的提示时可能会变得过于敏感，这种行为会破坏用户交互并模糊有害与无害内容的边界。现有的基准依赖于过时的数据集，会随着时间的推移而退化，导致数据污染和评价能力下降。", "innovation": "开发了一种动态生成特定于模型的挑战性数据集的框架，能够捕捉到新兴的防御性模式并适应每个模型的独特行为。构建了OVERBENCH基准，汇集了来自25个模型的450,000个样本，涵盖了多种LLM家族。OVERBENCH提供了一种动态和进化的视角，可以连续监测模型的改进过程中的防御性触发，暴露静态数据集忽视的漏洞。", "conclusion": "OVERBENCH为持续监测LLM模型的过度敏感性提供了动态视角，有助于发现不同模型随时间发展可能出现的新漏洞。"}
{"llm_update_time": "20251023", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.18939", "html_url": "https://arxiv.org/abs/2510.18939", "title": "在迷宫中迷失：克服长时距代理搜索中的上下文限制", "title_en": "Lost in the Maze: Overcoming Context Limitations in Long-Horizon Agentic Search", "authors": "Howard Yen,Ashwin Paranjape,Mengzhou Xia,Thejas Venkatesh,Jack Hessel,Danqi Chen,Yuhao Zhang", "background": "长时距代理搜索需要迭代地在网络上探索长期轨迹，并综合多种来源的信息，是构建强大的应用如深度研究系统的基础。现有流行的代理搜索框架在扩展到长期轨迹时遇到困难，主要是由于上下文限制——它们累积长且嘈杂的内容，遇到上下文窗口和工具预算限制，或者过早停止。", "innovation": "提出了一种名为SLIM（简单轻量级信息管理）的框架，该框架将检索分离为独立的搜索和浏览工具，并周期性地总结轨迹，保持上下文简洁同时允许更长时间且更专注的搜索。在多个基模型下，SLIM在长期任务上的表现优于强大的开源基线，成本显著降低且工具调用次数更少，特别是当使用o3作为基模型时，在BrowseComp上的得分为56%，HLE上的得分为31%，分别比所有开源框架高8和4个点，同时工具调用次数减少了4-6倍。", "conclusion": "发布了一个自动精细轨迹分析管道和错误分类学，用于表征长时距代理搜索框架；SLIM比先前系统具有更少的幻觉。希望能通过分析框架和简单工具设计启发未来的长时距代理系统。"}
{"llm_update_time": "20251023", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.18914", "html_url": "https://arxiv.org/abs/2510.18914", "title": "LLMs中基于上下文的公平性评估与缓解", "title_en": "Context-aware Fairness Evaluation and Mitigation in LLMs", "authors": "Afrozah Nadeem,Mark Dras,Usman Naseem", "background": "大型语言模型在长期对话和交流中表现出不良行为，如公平性问题、不一致性漂移、有害内容的放大以及不希望模式的传播。尽管已有通过训练时间或数据集中方法来减少这些影响的尝试，但这些方法计算成本高、部署后不可逆且无法快速适应新的对话环境。剪枝方法提供了一种既能灵活又能透明地减少偏见的方式，通过调整负责特定行为的神经元。然而，现有方法大多是静态的，一旦剪枝，模型在对话或语境变化时便失去了适应能力。", "innovation": "本文提出了一种动态、可逆的基于剪枝的框架，该框架基于上下文感知的神经元激活，通过自适应遮罩来调整神经元的影响，从而在生成阶段实现对话过程的灵活控制。该方法在推理阶段提供细粒度、内存感知的缓解，同时保留知识并实现多重语言且多回合对话中的更连贯行为，从而在实际对话AI中实现动态的公平控制", "conclusion": "通过提出一种基于上下文的动态剪枝框架，本文成功地解决了语言模型偏见调整的灵活性和效率问题，展现了在真实对话场景中实现持续公平性控制的潜力。"}
{"llm_update_time": "20251023", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.18941", "html_url": "https://arxiv.org/abs/2510.18941", "title": "ProfBench: 多领域评判标准要求专业领域知识来回答和评判", "title_en": "ProfBench: Multi-Domain Rubrics requiring Professional Knowledge to Answer and Judge", "authors": "Zhilin Wang,Jaehun Jung,Ximing Lu,Shizhe Diao,Ellie Evans,Jiaqi Zeng,Pavlo Molchanov,Yejin Choi,Jan Kautz,Yi Dong", "background": "目前评估大型语言模型（LLMs）的进展通常受到验证响应的挑战限制，评估主要集中在数学、编程和简短的问题回答任务上。然而，许多实际应用需要评估LLMs处理专业文档、综合信息和根据用户查询生成全面报告的能力。现有的评估方法难以满足这些需求。", "innovation": "该研究引入了ProfBench，一个包含超过7000个由具有物理学博士、化学博士、金融MBA和咨询MBA专业知识的人类专家评估的响应标准对。为减少自我增强偏差并降低成本，研究构建了强大的且经济的LLM判官来评估ProfBench的标准，从而使其更加公平和对更广泛的人群开放。研究发现即使对于最先进的LLMs，ProfBench仍具有巨大挑战性，表现最好的模型如GPT-5-high仅达到65.9%的整体性能。此外，研究还指出了自有和开源模型之间的性能差异，并探讨了扩展思考在解决复杂专业任务中的作用。", "conclusion": "ProfBench提出了对最先进的LLMs具有重大挑战性的任务，揭示了在处理复杂专业任务时扩展思考的重要性，并强调了使用人类专业知识制定评估标准的价值。该方法使LLMs的评估更加公平和普及，未来的研究可以从Proprietary模型和开源模型之间差距的原因和如何进一步提高LLMs处理复杂专业任务的能力等方面继续探讨。相关数据和代码可以在这里访问：this https URL和this https URL"}
{"llm_update_time": "20251023", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.19030", "html_url": "https://arxiv.org/abs/2510.19030", "title": "Re:Member：从个人记忆生成情感问题", "title_en": "Re:Member: Emotional Question Generation from Personal Memories", "authors": "Zackary Rackauckas,Nobuaki Minematsu,Julia Hirschberg", "background": "近年来，研究显示，情感表达与记忆联系的互动方式能够提升第二语言学习效果。本论文背景在于探索如何利用情感表达和基于记忆的互动方式，提高第二语言学习中的参与度和互动性。", "innovation": "论文创新性地提出了一种名为Re:Member的系统，该系统通过用户个人视频生成目标语言中的情景化情感化问题，通过情感语态（如低语或深夜语态）来唤起特定的情感氛围，并结合WhisperX转录对齐、3帧视觉采样和Style-BERT-VITS2进行情感合成，最终在模块化的生成管道中实现。", "conclusion": "研究认为，Re:Member系统的模块化设计强调了情感和个人媒体在以学习者为中心的教育技术中的重要性，能够有效地促进情感回忆和对话交流，提高第二语言学习的体验和效果。"}
{"llm_update_time": "20251023", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.19028", "html_url": "https://arxiv.org/abs/2510.19028", "title": "他们在恋人还是朋友？评估LLMs在英语和韩语对话中的社会推理能力", "title_en": "Are they lovers or friends? Evaluating LLMs' Social Reasoning in English and Korean Dialogues", "authors": "Eunsu Kim,Junyeong Park,Juhyun Oh,Kiwoong Park,Seyoung Song,A.Seza Dogruoz,Najoung Kim,Alice Oh", "background": "随着大型语言模型（LLMs）在人类与AI交互中的应用不断增加，它们在人际情境中的社会推理能力变得至关重要。这项研究围绕一个由电影剧本数据集组成的交互对话任务展开，即评估模型能否推断对话中说话者间的关系，如朋友、姐妹、爱人等。该数据集包含英文和韩文的1000个对话，由原籍或具有同等水平的韩美讲者进行标注，评价了九种模型在社交推理任务上的表现。", "innovation": "本研究创新之处在于开发了一个包含大量对话的多语言数据集，用于评估模型的社交推理能力。研究发现，当前的商业化LLMs在解决英语对话时表现不错，但在韩语对话上的表现较弱。此外，研究揭示了一些模型在回答社交推理问题时表现出的特定模式和潜在的社会偏见。", "conclusion": "本研究表明，现有的LLMs在社会推理方面存在显著局限性，迫切需要开发具备社会意识的LLMs。此外，这项工作还发现思考型模型及链式推理提示对于提升模型的社会推理能力效果有限，甚至可能加剧社会偏见。"}
{"llm_update_time": "20251023", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.18918", "html_url": "https://arxiv.org/abs/2510.18918", "title": "使用可解释的大语言模型进行虚假信息检测", "title_en": "Misinformation Detection using Large Language Models with Explainability", "authors": "Jainee Patel,Chintan Bhatt,Himani Trivedi,Thanh Thi Nguyen", "background": "网络平台上虚假信息的快速传播削弱了个人之间的信任，妨碍了基于知识的决策。因此，需要一个解释性强且计算效率高的管道来检测虚假信息，并使用基于转换器的预训练语言模型（PLMs）实现这一目标。该研究通过一个两步策略优化了RoBERTa和DistilBERT：首先冻结主干并仅训练分类头，然后逐步解冻主干层并采用逐层学习率衰减。在两个真实的基准数据集上，展示了提出的基于统一预处理和分层分割协议的方法，以评估其性能。使用Local Interpretable Model-Agnostic Explanations (LIME)在标记级别进行解释，并使用SHapley Additive exPlanations (SHAP)在全局特征归因级别进行解释，确保透明性。结果显示，DistilBERT在准确性和所需的计算资源量上与RoBERTa相当或优于RoBERTa。", "innovation": "该工作有两个关键贡献：通过精细调节和解释性相结合，量化证明了轻量级PLM可以在大幅降低计算成本的同时保持任务性能；展示了一个解释性强、不牺牲性能的可解释管道，检索出忠实的局部和全局解释。研究结果表明，结合合理微调和解释性的PLMs可以成为一种有效的、可扩展、可信的虚假信息检测框架。", "conclusion": "研究表明，通过结合合理微调和解释性的转换器预训练模型，可以有效地检测虚假信息，同时显著减少计算成本。此研究为大规模、可信赖的虚假信息检测提供了一个有希望的方法，并揭示了轻量级模型在保持高性能的同时能够实现的计算效率。"}
{"llm_update_time": "20251023", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.19116", "html_url": "https://arxiv.org/abs/2510.19116", "title": "那已经过时了！理解、检测和引导语言模型在代码生成中的知识冲突", "title_en": "That's Deprecated! Understanding, Detecting, and Steering Knowledge Conflicts in Language Models for Code Generation", "authors": "Jaesung Bae,Cameron Churchwell,Mitchell Hermon,Tsun-An Hsieh,Jocelyn Xu,Yekaterina Yegorova,Mark Hasegawa-Johnson,Heng Ji", "background": "该论文调查了大型语言模型（LLMs）在面临参数知识与提示中矛盾信息的不一致时的行为。基于先前的问答（QA）研究，该研究将知识冲突的调查扩展到了代码生成领域。这一领域此前的研究较少，但随着LLMs的广泛应用，理解其在处理矛盾信息时的行为显得尤为重要。", "innovation": "论文提出了一种通用框架来构建和解释知识冲突，并开发了一种新的评估方法及针对代码冲突场景的数据集。此外，研究还表明，可通过调整模型大小、任务领域及引导方向来提高基于激活级别的引导成功率，提升了代码生成中检测与引导知识冲突的有效性。", "conclusion": "大规模的LLMs能够通过其参数编码知识冲突的概念，使检测知识冲突的准确率达到80.65%。通过调整模型大小、任务领域和引导方向，激活级别的引导能够实现最高12.6%的成功率改进。为了进一步验证这些发现，实验代码和数据将在论文被接受后公开。"}
{"llm_update_time": "20251023", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.19032", "html_url": "https://arxiv.org/abs/2510.19032", "title": "我们在何时可以信任心理健康领域的LLM？大规模基准测试以实现可靠的LLM评估", "title_en": "When Can We Trust LLMs in Mental Health? Large-Scale Benchmarks for Reliable LLM Evaluation", "authors": "Abeer Badawi,Elahe Rahimi,Md Tahmid Rahman Laskar,Sheri Grach,Lindsay Bertrand,Lames Danok,Jimmy Huang,Frank Rudzicz,Elham Dolatabadi", "background": "评估大型语言模型（LLMs）在心理健康支持中的应用具有挑战性，因为治疗对话既有情感上的复杂性，也有认知上的复杂性。现有的评估基准规模有限、可靠性不足，通常依赖于合成数据或社交媒体数据，缺乏评估自动化裁判可信度的框架。针对这一需求，本文引入了两个基准，分别为生成和评估提供框架。MentalBench-100k 汇聚了来自三个真实场景数据集的10,000条单轮对话，每条对话配对有九个LLM生成的回复，共计100,000条回复对。MentalAlign-70k则通过比较四种高绩效的LLM裁判与人类专家之间的评价，跨70,000项评级的七个属性，重新定义了评估方式，分为认知支持分数（CSS）和情感共鸣分数（ARS）。", "innovation": "本文通过引入MentalBench-100k和MentalAlign-70k两个基准，为LLMs在心理健康领域的评估提供了新的方法和实证基础。MentalBench-100k通过汇聚来自多个真实场景数据集的大量对话，提供了大规模的评估数据；MentalAlign-70k通过对比LLM裁判与人类专家的评价结果，客观地评估了LLM裁判的可靠性，借助统计技术确定了LLM裁判与人类专家之间的分歧、一致性和偏见。该研究为LLMs的心理健康应用提供了新的评估方法和标准。", "conclusion": "本文的评估结果揭示了，对于认知属性如指导和信息性，LLM裁判显示出较强的可靠性，但在共鸣方面则显得不够精确，安全性和相关性方面也存在不可靠性。这些发现对于未来的研究和实践具有重要意义，为建立可靠、大规模的LLM评估提供了重要基础。"}
{"llm_update_time": "20251023", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.19144", "html_url": "https://arxiv.org/abs/2510.19144", "title": "藏语文本和AI：资源、方法与挑战的综合调查", "title_en": "Tibetan Language and AI: A Comprehensive Survey of Resources, Methods and Challenges", "authors": "Cheng Huang,Nyima Tashi,Fan Gao,Yutong Liu,Jiahao Li,Hao Tian,Siyang Jiang,Thupten Tsering,Ban Ma-bao,Renzeg Duojie,Gadeng Luosang,Rinchen Dongrub,Dorje Tashi,Jin Zhang,Xiao Feng,Hao Wang,Jie Tang,Guojie Tang,Xiangxiang Wang,Jia Zhang,Tsengdar Lee,Yongbin Yu", "background": "藏语作为亚洲的主要低资源语言之一，具有独特的语言和文化特征，为AI研究带来了挑战和机遇。尽管对于少资源语言的AI系统的开发越来越感兴趣，但由于缺乏可访问的数据资源、标准化基准以及专用工具，藏语并未得到充分关注。", "innovation": "论文提供了一项全面的调查，涵盖了藏语在AI领域的当前状态，包括文本和语音数据资源、NLP任务、机器翻译、语音识别以及大语言模型的最新进展。研究系统地分类了现有的数据集和工具，评估了跨任务的方法，并在可能的情况下进行了性能比较。此外，还识别了持续存在的瓶颈，例如数据稀疏性、拼写变化以及缺乏统一的评估指标。讨论了跨语言迁移、多模态学习以及由社区驱动的资源创建的潜力。", "conclusion": "本文旨在为未来关于藏语AI研究的工作提供一个基础参考，并鼓励为低资源语言构建包容性和可持续性的AI生态系统做出协作努力。"}
{"llm_update_time": "20251023", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.19036", "html_url": "https://arxiv.org/abs/2510.19036", "title": "从记忆到泛化：大型语言模型在生物医学术语到标识符规范化中的微调", "title_en": "From Memorization to Generalization: Fine-Tuning Large Language Models for Biomedical Term-to-Identifier Normalization", "authors": "Suswitha Pericharla,Daniel B. Hier,Tayo Obafemi-Ajayi", "background": "生物医学数据的有效集成依赖于自动术语规范化，即将自然语言中的生物医学术语映射到标准化标识符。这一过程对于语义互操作性至关重要。大型语言模型（LLMs）在这一任务中显示出诱人的潜力，但它们在不同的术语集上的表现参差不齐。通过评估记忆（训练-术语表现）和泛化（验证-术语表现），本文研究了在多种生物医学本体论上的表现差异。", "innovation": "研究通过微调特定的LLM（如微调Llama 3.1 8B）来探索记忆和泛化表现的差异。研究发现不同ontologies的表现不同，GO映射显示出显著的记忆力提升，而HPO几乎没有改进。仅在蛋白质-基因（GENE）映射上观察到了泛化的现象，而对HPO和GO的微调几乎没有迁移效果。GPT-4o在所有术语集上的基线准确度高于所有Llama变体。嵌入分析显示基因符号和蛋白质名称之间有紧密的语义对齐，但对于GO或HPO术语和标识符之间，这种对齐相对较弱，这与有限的词汇化有关。微调成功取决于两个相互作用的因素：标识符的流行度和词汇化。流行标识符在预训练中更常被遇到，从而增强记忆力；词汇化的标识符，如基因符号，可以实现语义泛化，而任意标识符限制模型只能进行死记硬背的学习。这些发现提供了一个预测框架，以确定微调是增强事实回忆还是由于稀疏或非词汇化的标识符而失败.", "conclusion": "研究结果提供了一个预测框架，用于判断微调是有助于事实回忆还是由于稀疏或非词汇化标识符而未能泛化。这意味着在选择和微调LLM时，需考虑标识符的流行度和词汇化程度，这将指导未来的模型设计和优化策略。"}
{"llm_update_time": "20251023", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.19117", "html_url": "https://arxiv.org/abs/2510.19117", "title": "大型语言模型中幻觉检测的图信号处理框架", "title_en": "A Graph Signal Processing Framework for Hallucination Detection in Large Language Models", "authors": "Valentin Noël", "background": "大型语言模型在诸多任务中取得了显著成效，但对于如何区分事实推理与幻觉仍面临挑战。本文旨在通过图信号处理框架来分析Transformer层中的动态图结构，利用token嵌入作为图上的信号来解决这一难题。通过引入Dirichlet能、谱熵和高频能比等诊断指标，旨在更好地理解和分析语言模型在推理过程中的表现和错误行为。", "innovation": "提出了一种基于图信号处理的框架来检测大型语言模型中的幻觉。该框架将Transformer层建模为由注意力机制诱导的动态图，利用token嵌入作为图信号处理的信号。通过定义Dirichlet能、谱熵和高频能比等诊断指标，揭示不同类型的幻觉具有不同的特征，并通过实验验证了这些指标的有效性。", "conclusion": "实验结果表明，基于频谱签字的简单检测器在识别幻觉方面比基于困惑度的基线方法更加准确（88.75% vs 75%）。研究发现，频谱几何可能捕捉到推理模式和错误行为，这为大型语言模型中幻觉的检测提供了一种潜在的框架。"}
{"llm_update_time": "20251023", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.19171", "html_url": "https://arxiv.org/abs/2510.19171", "title": "Think Straight, Stop Smart: Structured Reasoning for Efficient Multi-Hop RAG", "title_en": "Think Straight, Stop Smart: Structured Reasoning for Efficient Multi-Hop RAG", "authors": "Jihwan Bang,Juntae Lee,Seunghan Yang,Sungha Choi", "background": "现有的迭代提示方法在复杂推理中虽然有效，但效率较低。它们通常会在每一步重新生成可预测的标记序列，并依赖随机停止，导致过多的标记使用和不稳定的终止。", "innovation": "提出了TSSS（反思清晰，智能停止）框架，这是一种结构化的多跳RAG框架，旨在提高效率。TSSS引入了一种基于模板的推理机制，能够缓存重复的前缀并将子查询锚定到主要问题上，从而减少生成标记的成本并促进稳定的推理；同时引入了检索器驱动的终止器，一旦额外的子查询退化为重复，就确定性地终止推理。这一分离结构化推理和终止控制的能力使得推理速度更快且回答更可靠。", "conclusion": "在HotpotQA、2WikiMultiHop和MuSiQue上，TSSS在RAG-CoT方法中实现了最先进的准确性和竞争力的效率，突显了其在限制效率情景（如设备端推理）中的有效性。"}
{"llm_update_time": "20251023", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.19131", "html_url": "https://arxiv.org/abs/2510.19131", "title": "训练无关的变压器中语音处理的频谱指纹", "title_en": "Training-Free Spectral Fingerprints of Voice Processing in Transformers", "authors": "Valentin Noël", "background": "不同变压器架构通过独特的连接模式实现相同的语言计算，产生可由频谱分析检测到的模型印刻下的“计算指纹”。通过对注意力引发的令牌图进行图信号处理，研究了在20种语言和三种模型家族中，声音变化对早期层数（2-5层）的代数连通性（Fiedler值，$\triangle\boldsymbol{\text{λ}}_2$）的影响。", "innovation": "通过图信号处理来分析注意力引发的令牌图，追踪声音变化对早期层的显著影响（$\triangle\boldsymbol{\text{λ}}_2$）。揭示了不同的架构标记：Phi-3-Mini显示在英语层特定的显著早期层中断（$\boldsymbol{\triangle\text{λ}}_{[2,5]} \thickapprox -0.446$），而其他19种语言的影响较小。Qwen2.5-7B展示了对形态丰度语言来说较大的分布式转变，而LLaMA-3.2-1B则展示了系统但微弱的响应。这些频谱签名与行为差异高度相关，并由目标注意力头的消融所调节，验证了其功能相关性。", "conclusion": "发现表明训练强调可能会留下可检测的计算印记：特定的处理策略会以可测量的连接模式在句法转换期间显现。该框架超越了声音变化，区分了推理模式，表明作为一种无需训练的诊断工具，用于揭示架构偏见和支持模型可靠性分析具有实用性。"}
{"llm_update_time": "20251023", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.19181", "html_url": "https://arxiv.org/abs/2510.19181", "title": "知识图谱中的可解释问答", "title_en": "Interpretable Question Answering with Knowledge Graphs", "authors": "Kartikeya Aneja,Manasvi Srivastava,Subhayan Das,Nagender Aneja", "background": "该论文研究了一种仅依赖知识图谱检索而不使用大规模语言模型（LLMs）的检索增强生成（RAG）的问答系统。以往的问答系统通常依赖于LLMs进行生成式回答，但本文提出了一种不同的方法，即使用小型改写模型来改写从知识图谱查询中检索到的实体关系边。这种方法避免了对大规模语言模型的依赖，通过改写和检索来提高问答系统的可解释性和效率。", "innovation": "该研究的创新之处在于，它提出了一种新的问答系统架构，通过知识图谱检索和小型改写模型结合的方式进行问答。与传统的依赖于LLMs的生成式方法相比，该方法不需要生成过程，而是注重理解和改写，从而解决了生成式回答可能无法直接解释的问题。", "conclusion": "该研究使用了LLM作为评判者在CRAG基准上进行了评估，结果表明LLAMA-3.2和GPT-3.5-Turbo的准确率分别为71.9%和54.4%。这种基于知识图谱的问答方法在准确性和可解释性上表现出色，为其在实际应用中的进一步研究与开发奠定了基础。"}
{"llm_update_time": "20251023", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.19172", "html_url": "https://arxiv.org/abs/2510.19172", "title": "变化中的事实：使用evolveQA测试LLM在不断发展知识上的能力", "title_en": "When Facts Change: Probing LLMs on Evolving Knowledge with evolveQA", "authors": "Nishanth Sridhar Nakshatri,Shamik Roy,Manoj Ghuhan Arivazhagan,Hanhan Zhou,Vinayshekhar Bannihatti Kumar,Rashmi Gangadharaiah", "background": "现有的研究通常通过基于结构化知识库（如Wikidata）构建的不同基准来评估LLMs处理时间冲突（即随时间改变而产生事实冲突）的能力，但这些基准关注的是流行且易于记忆的实体，缺乏动态结构来公平评估具有不同知识截止日期的LLMs。因此，需要一个专门基准来测试LLMs在处理随时间演变的知识上的表现，特别是需要能够识别并模拟知识自然演变的过程，并生成适应不同知识截止日期的高质量问题和标准答案。", "innovation": "本文引入了evolveQA基准，该基准基于AWS更新、Azure变更和WHO疾病疫情报告三个真实时间戳数据库构建，能够自然地捕捉知识的演变过程，并为不同知识截止日期的LLMs生成适应性高质量问题和标准答案。通过对12个开源和闭源LLMs进行广泛的对比实验，结果表明在evolveQA上的性能下降最多达31%，突出了在处理随时间演变的知识上的不同表现差异，从而表明了使用evolveQA测试LLMs的能力具有针对性和有效性。", "conclusion": "通过evolveQA基准，能够显著提高对LLMs处理随时间演变的知识的理解，未来的研究可以通过添加更多类型的时间数据来进一步提高其表现和鲁棒性。"}
{"llm_update_time": "20251023", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.19167", "html_url": "https://arxiv.org/abs/2510.19167", "title": "你被拒了！：大型语言模型参与招聘评估的实证研究", "title_en": "\"You Are Rejected!\": An Empirical Study of Large Language Models Taking Hiring Evaluations", "authors": "Dingjie Fu,Dianxing Shi", "background": "随着互联网的普及和人工智能技术的迅速发展，科技公司面临着每年对大量软件和算法工程师的迫切需求。为了高效地从成千上万的求职者中筛选出高素质的人才，这些公司已经建立了多阶段的选拔流程，其中包括标准化的招聘评估，以评估其专业技能。鉴于大型语言模型（LLMs）在编码和推理任务中的卓越表现，本文研究了一个关键问题：LLMs是否能够成功通过这些招聘评估？为此，我们对一个广泛使用的专业评估问卷进行了全面的分析，并使用最先进的LLMs生成响应，随后对其性能进行了评估。", "innovation": "本文首次系统性地考察了LLMs在专业评估中的表现，通过使用最新的LLMs生成回答并评估其绩效，揭示了模型生成的答案与公司参考解决方案之间存在显著差异，进一步证实了先前对LLMs作为理想工程师的期望是不合理的。这种全面的实证研究不仅验证了LMLs在招聘评估场景中的局限性，还为未来相关研究和应用提供了数据支持和实际指导。", "conclusion": "经过详细分析，所有评估的LLMs都无法通过招聘评估。这一发现引发了一个引人深思的结论：大型语言模型在专业领域的实际应用中可能存在显著的技术局限性，特别是在编程和专业技术评估等需要高度定制和情景理解的任务中。"}
{"llm_update_time": "20251023", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.19186", "html_url": "https://arxiv.org/abs/2510.19186", "title": "工具增强对话系统多维评估", "title_en": "Multi-Faceted Evaluation of Tool-Augmented Dialogue Systems", "authors": "Zhaoyi Joey Hou,Tanya Shourya,Yingfan Wang,Shamik Roy,Vinayshekhar Bannihatti Kumar,Rashmi Gangadharaiah", "background": "评估使用外部工具的对话AI系统具有挑战性，因为错误可能源于用户、代理和工具之间的复杂交互。现有的评估方法仅关注用户满意度或代理调用工具的能力，但未能捕捉到多轮次工具增强对话中的关键错误，如代理错误解读工具结果但仍使用户满意的案例。", "innovation": "介绍了一个名为TRACE的基准数据集，用于系统地合成工具增强的对话，涵盖了各种错误案例；提出了一个名为SCOPE的评估框架，能够自动发现工具增强对话中的多样错误模式和评估标准。", "conclusion": "实验表明，SCOPE在难以处理的情况下显著优于基线，尤其是在用户满意度信号误导的情景中。"}
{"llm_update_time": "20251023", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.19217", "html_url": "https://arxiv.org/abs/2510.19217", "title": "模态匹配很重要：调整URIEL+中的语言距离以进行跨语言转移", "title_en": "Modality Matching Matters: Calibrating Language Distances for Cross-Lingual Transfer in URIEL+", "authors": "York Hay Ng,Aditya Khan,Xiang Lu,Matteo Salloum,Michael Zhou,Phuong H. Hoang,A. Seza Doğruöz,En-Shiun Annie Lee", "background": "现有的语言知识库，比如URIEL+提供了有价值的地理、基因和类型学距离，这对于跨语言转移有价值，但它们存在两个关键局限性：首先是它们“一刀切”的向量表示方式不适合语言数据中的多样结构；其次是缺乏一种基本原则来将这些信号聚合为一个全面的分数。本文解决了这些缺口。", "innovation": "本文提出了一种类型匹配的语言距离框架。为每种距离类型提出了新颖的结构感知表示：地理使用发言者加权分布，谱系使用双曲嵌入，类型使用潜在变量模型。将这些信号统一成一个稳健的、任务无关的综合距离。在选择转移语言时，我们的表示方式和综合距离在广泛NLP任务中提高了性能，为多语言研究提供了一个更加合理有效的工具。", "conclusion": "我们的表示方式和综合距离在不同类型的任务中都显示出了改进，并提供了一个更合理、有效的多语言研究工具。"}
{"llm_update_time": "20251023", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.19247", "html_url": "https://arxiv.org/abs/2510.19247", "title": "SheetBrain：一种用于准确推理复杂和大规模电子表格的神经符号代理", "title_en": "SheetBrain: A Neuro-Symbolic Agent for Accurate Reasoning over Complex and Large Spreadsheets", "authors": "Ziwei Wang,Jiayuan Su,Mengyu Zhou,Huaxing Zeng,Mengni Jia,Xiao Lv,Haoyu Dong,Xiaojun Ma,Shi Han,Dongmei Zhang", "background": "大型语言模型（LLMs）在理解和推理复杂电子表格方面存在根本性挑战，常常难以准确捕捉表格的复杂结构和确保推理的正确性。", "innovation": "提议了SheetBrain，一种神经符号双工作流代理框架，用于准确推理表格数据，支持电子表格问题回答和操作任务。SheetBrain包括三个核心模块：理解模块、执行模块和验证模块。", "conclusion": "实验结果表明，SheetBrain在现有基准测试和SheetBench中更具有挑战性的场景中显著提高了准确性。我们的代码已公开发布。"}
{"llm_update_time": "20251023", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.19208", "html_url": "https://arxiv.org/abs/2510.19208", "title": "DiSRouter: 分布式自我路由算法用于大型语言模型选择", "title_en": "DiSRouter: Distributed Self-Routing for LLM Selections", "authors": "Hang Zheng,Hongshen Xu,Yongkai Lin,Shuai Fan,Lu Chen,Kai Yu", "background": "大型语言模型（LLMs）的普及造就了一个具有高度差异化的模型生态系统，这些模型在性能和成本方面各有不同。因此，有效查询路由（query routing）技术变得尤为重要，以平衡性能和成本。当前的路由系统通常依赖于一个中央外部路由器，该路由器通过对一组固定LLM进行训练来发挥作用，这使得它们缺乏灵活性并且容易表现不佳，因为中央路由器难以全面理解不同LLM的知识边界。", "innovation": "我们提出了DiSRouter（分布式自我路由器）这一创新架构，它从集中式控制转向分布式路由。在DiSRouter中，查询穿越LLM代理网络，每个代理独立地根据自身的自我意识（即判断其自身能力）决定是否回答或路由到其他代理。这一分布式设计提供了更高的灵活性、可扩展性和通用性。为了实现这一目标，我们提出了一种两阶段的自我意识培训管道，以增强每个LLM的自我意识。广泛的实验结果表明，DiSRouter在各种场景下显著优于现有的路由方法，在区分简单和复杂查询方面表现良好，并且展示了对跨域任务的强大普及性。我们的研究验证了利用LLM的内在自我意识比外部评估更有效，为更模块化和高效的多代理系统铺平了道路。", "conclusion": "我们的工作证明，利用LLM的内在自我意识比依赖外部评估更为有效，为实现更模块化、高效的多代理系统提供了新的视角，为未来的研究打下了坚实的基础。"}
{"llm_update_time": "20251023", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.19265", "html_url": "https://arxiv.org/abs/2510.19265", "title": "使用大型语言模型和直接偏好优化的难度可控多项选择题生成", "title_en": "Difficulty-Controllable Multiple-Choice Question Generation Using Large Language Models and Direct Preference Optimization", "authors": "Yuto Tomikawa,Masaki Uto", "background": "在教育领域，可调难度的问答生成被认为是适应性学习支持的一个基本工具，受到了广泛关注。现有的一些神经网络问答生成方法虽已能够在一定程度上控制问题的难度，但这些方法仍然存在一些缺陷：无法直接生成最常见的多项选择题，缺乏明确训练以优化难度控制的准确性。", "innovation": "本研究提出了一种新型的基于大型语言模型和直接偏好优化技术的难度可控的多项选择题生成方法，旨在提高难度控制的准确性，解决现有方法无法直接生成多项选择题以及在控制难度方面训练不足的问题。", "conclusion": "该方法通过利用大型语言模型和直接偏好优化技术，提高了生成题目难度控制的准确性，为适应性学习提供了更有效的工具。"}
{"llm_update_time": "20251023", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.19318", "html_url": "https://arxiv.org/abs/2510.19318", "title": "HAD: HAllucination Detection Language Models Based on a Comprehensive Hallucination Taxonomy", "title_en": "HAD: HAllucination Detection Language Models Based on a Comprehensive Hallucination Taxonomy", "authors": "Fan Xu,Xinyu Hu,Zhenghan Yu,Li Lin,Xu Zhang,Yang Zhang,Wei Zhou,Jinjie Gu,Xiaojun Wan", "background": "随着自然语言生成（NLG）模型，尤其是大型语言模型的广泛应用，人们越来越关注其输出的可靠性和准确性。这些模型存在的一个关键问题是自欺现象（hallucination），即模型生成看似合理但实际上错误的信息。因此，自欺检测成为了一个重要的任务。", "innovation": "本文提出了一个全面的自欺分类体系，涵盖11个类别，并提出了HALLUCination Detection（HAD）模型，将自欺检测、跨度级别识别和修正整合到一个推理过程中。该模型基于大约90,000个合成样例数据训练，适用于多种NLG任务，并且相比现有基线模型展现了更好的性能。", "conclusion": "通过在领域内和领域外的测试集上的评估，HAD模型在HaluEval、FactCHD和FaithBench上取得了最先进的结果，证明了其稳健性和多功能性。"}
{"llm_update_time": "20251023", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.19316", "html_url": "https://arxiv.org/abs/2510.19316", "title": "KORE: 通过知识导向的增强和约束提高大型多模态模型的知识注入", "title_en": "KORE: Enhancing Knowledge Injection for Large Multimodal Models via Knowledge-Oriented Augmentations and Constraints", "authors": "Kailin Jiang,Hongbo Jiang,Ning Jiang,Zhi Gao,Jinhe Bi,Yuchen Ren,Bin Li,Yuntao Du,Lei Liu,Qing Li", "background": "大型多模态模型在其预训练权重中存储了大量的事实知识，但这些知识是静态且有限的，无法与现实世界的发展保持同步，这阻碍了持续的知识获取。因此，有效的知识注入变得至关重要，它涉及两项目标：知识适应（注入新知识）和知识保留（保留旧知识）。现有方法往往难以学习新知识，并且容易遭受灾难性遗忘。", "innovation": "我们提出了KORE，这是一种协同方法，通过知识导向的增强和约束来注入新知识并保留旧知识到大型多模态模型中。KORE自动将单独的知识项转换为结构化的全面知识，以确保模型精确地学习新知识，促进准确适应。同时，KORE将先前的知识存储在LMM线性层激活的协方差矩阵中，并通过将原始权重投影到矩阵的零空间中初始化适应器，定义了一个优化方向，以最小化与先前知识的干扰，从而确保强大的保留能力。", "conclusion": "在LLaVA-v1.5-7B、LLaVA-v1.5-13B和Qwen2.5-VL-7B等多种LMM的广泛实验中，KORE展示了优越的新知识注入性能，并有效缓解了灾难性遗忘。"}
{"llm_update_time": "20251023", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.19310", "html_url": "https://arxiv.org/abs/2510.19310", "title": "JointCQ: 联合生成声明和查询以提高事实性幻觉检测", "title_en": "JointCQ: Improving Factual Hallucination Detection with Joint Claim and Query Generation", "authors": "Fan Xu,Huixuan Zhang,Zhenliang Zhang,Jiahao Wang,Xiaojun Wan", "background": "当前的大规模语言模型（LLMs）常常会有生成幻觉的问题，即生成看似真实的但实际上是不准确的内容。现有的幻觉检测_pipeline通常涉及响应分解（即声明提取）、查询生成、证据收集（即搜索或检索）和声明验证等步骤。然而，现有的方法在前两个阶段存在不足，如声明提取中的上下文丢失和查询生成的一般性问题，导致整个幻觉检测_pipeline的性能下降。", "innovation": "本文引入了JointCQ框架，这是一个联合声明和查询生成的框架，旨在构建一个高效有效的声明-查询生成器。该框架利用精心设计的评估标准筛选合成的训练数据，并对语言模型进行微调，使其能够联合执行声明提取和查询生成，提供可靠的和有益的信息作为下游搜索和验证的输入。实验结果表明，该方法在多个开放式QA幻觉检测基准测试中优于之前的方法，推进了更可信和透明的语言模型系统的建设。", "conclusion": "本工作证明了JointCQ框架在大规模语言模型的幻觉检测任务上的有效性，并通过联合声明和查询生成的方式显著改善了系统性能。"}
{"llm_update_time": "20251023", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.19326", "html_url": "https://arxiv.org/abs/2510.19326", "title": "SpeechLLMs中的槽填充任务作为推理任务", "title_en": "Slot Filling as a Reasoning Task for SpeechLLMs", "authors": "Kadri Hacioglu,Manjunath K E,Andreas Stolcke", "background": "基于大语言模型的语音模型（speechLLMs）在端到端的槽填充任务中目前主要依赖于直接的模式识别能力，缺乏推理能力。最近，推理LLMs的发展为提升语音模型的推理能力提供了可能。通过将推理融入语音模型，可以进一步提高槽填充任务的性能。", "innovation": "提出了将推理融入到语音大语言模型（speechLLMs）中，通过使用链式思考框架分解槽填充任务为多个推理步骤，创建推理数据集并通过监督微调策略对speechLLMs进行训练。实验表明，引入推理步骤可以提高性能，但用于数学、逻辑和编码领域的推理文本LLM可能并不适合作为speechLLM的基础模型。进一步研究显示，基于混合文本基础模型的hybrid speechLLMs，在保留直接和推理模式操作的情况下，性能更好。", "conclusion": "在speechLLMs中加入推理步骤可以提升槽填充任务的性能，但在选择基础模型时需注意其领域适用性。hybrid speechLLMs，基于混合文本基础模型并通过进一步的微调，具有更好的整体性能。"}
{"llm_update_time": "20251023", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.19286", "html_url": "https://arxiv.org/abs/2510.19286", "title": "TheMCPCompany：使用任务特定工具创建通用代理", "title_en": "TheMCPCompany: Creating General-purpose Agents with Task-specific Tools", "authors": "Reza Esfandiarpoor,Vishwas Suryanarayanan,Stephen H. Bach,Vishal Chowdhary,Anthony Aue", "background": "自引入模型上下文协议（MCP）以来，大型语言模型（LLMs）可用工具的数量显著增加。这些针对特定任务的工具套件为替代通用工具（如Web浏览器）提供了可能，同时较容易开发和维护，但当前通用代理主要依赖Web浏览器进行环境交互。", "innovation": "本研究提出了TheMCPCompany，一个用于评估涉及各种真实世界服务交互的工具调用代理的基准。该基准利用这些服务的REST API创建MCP服务器，包含超过18,000个工具，并提供每个任务的手动标注地面真相工具。此外，还研究了使用工具检索的代理性能，证明了使用工具调用代理在性能和成本降低方面的潜在优势。结果显示，虽然所有带有工具检索的模型在性能上与基于浏览器的代理相当或更好，但较小的模型难以充分利用可用工具进行检索。而GPT-5在使用工具检索时，其性能与使用地面真相工具时相差无几。", "conclusion": "研究表明，最先进的推理模型在简单环境中有效发现工具，但难以在复杂的企业环境中导航。TheMCPCompany揭示了在大规模工具中导航并以非平凡方式组合解决复杂问题仍然是当前模型面临的挑战，需要更好的推理能力和更好的检索模型。"}
{"llm_update_time": "20251023", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.19325", "html_url": "https://arxiv.org/abs/2510.19325", "title": "平衡文本总结中的奖励：基于HyperVolume优化的多目标强化学习", "title_en": "Balancing Rewards in Text Summarization: Multi-Objective Reinforcement Learning via HyperVolume Optimization", "authors": "Junjie Song,Yiwen Liu,Dapeng Li,Yin Sun,Shukun Fu,Siqi Chen,Yuji Cao", "background": "文本总结是一个需要同时优化多个目标（包括一致性、连贯性、相关性和流畅性）的重要任务，这给任务带来了相当大的挑战。尽管大型语言模型（LLMs）表现出色，并通过强化学习（RL）得到了增强，但很少有研究专注于通过基于LLMs的RL优化总结的多目标问题。论文背景在于现有方法缺乏有效的多目标优化策略，并希望通过引入新的优化策略来改进多目标文本总结的方法。", "innovation": "本文提出了基于HyperVolume方法的HyperVolume优化（HVO），这是一种在RL过程中通过动态调整组别之间得分的新型优化策略。HVO方法指导模型的优化逐步逼近Pareto前沿，从而生成多个目标下的平衡总结。实验结果表明，HVO方法的整体评分高于组比较策略优化（GRPO），并在不同维度上展现出更均衡的表现。同时，通过HVO增强的7B基础模型与GPT-4在总结任务中的表现相当，但生成时间更短。", "conclusion": "我们的方法在多个代表性总结数据集上的实验结果表明，HVO在多目标优化方面优于现有的方法，并且通过HVO增强的模型在总结任务中表现出相似或更好的效果，同时生成时间更短。本研究对于改进多目标文本总结的RL方法做出了贡献，同时代码已公开。"}
{"llm_update_time": "20251023", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.19331", "html_url": "https://arxiv.org/abs/2510.19331", "title": "NLP中的算法公平性：注入人格的LLMs用于以人为中心的仇恨言论检测", "title_en": "Algorithmic Fairness in NLP: Persona-Infused LLMs for Human-Centric Hate Speech Detection", "authors": "Ewelina Gajewska,Arda Derbent,Jaroslaw A Chudziak,Katarzyna Budzynska", "background": "本文探讨了通过使用注释者的人格来个性化大型语言模型（Persona-LLMs）对其仇恨言论敏感性的影响，特别是针对注释者和目标之间共享或不同身份所带来的偏见。本文使用了Google的Gemini和OpenAI的GPT-4.1-mini模型，并采用了两种人格提示方法：浅层次的人格提示和基于检索增强生成（RAG）的深度上下文化人格发展方法，以嵌入更丰富的人格档案信息。本文分析了使用群体内部和群体外部注释者的人格对模型检测性能和跨不同社会群体的公平性的影响，将心理学上的群体身份洞察与先进的NLP技术结合，证明了将社会人口统计属性纳入LLMs可以解决自动仇恨言论检测中的偏见问题。", "innovation": "本文的工作将心理学上的群体身份洞察与先进的NLP技术结合起来，通过使用注释者的人格来个性化大型语言模型，这是一种创新的方法，旨在通过嵌入更丰富的人格档案信息来缓解自动仇恨言论检测中的偏见问题。", "conclusion": "本文结果强调了基于人格的方法在减少偏见方面的潜力和局限性，为开发更公平的仇恨言论检测系统提供了宝贵见解。"}
{"llm_update_time": "20251023", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.19350", "html_url": "https://arxiv.org/abs/2510.19350", "title": "基于语义指导的手势在对话轮换预测中的建模", "title_en": "Modeling Turn-Taking with Semantically Informed Gestures", "authors": "Varsha Suresh,M. Hamza Mughal,Christian Theobalt,Vera Demberg", "background": "在对话中，人类通过多模态线索（如言语、手势、注视等）来管理轮流说话。虽然语言和声学特征是有效的，手势提供了互补的信息来模型这些转换。现有的研究主要依靠语言和声音特征，而缺乏对手势在多模态轮流预测中的应用研究，特别是如何利用手势的语义信息进行建模。因此，本文通过引入DnD Gesture++数据集来丰富多轮对话手势库，该数据集包含2,663个语义手势标注，涵盖了象征性、比喻、指示性以及对话类型。基于这个数据集，作者构建了多专家混合模型，结合文本、音频和手势信息来预测对话轮流。实验结果显示，利用语义指导的手势能够持续提高模型性能，证明了其在多模态轮流预测中的补充作用。", "innovation": "本文的创新点在于通过DnD Gesture++数据集丰富了多模态手势标注，并使用语义指引的手势在这种数据集上进行对话轮流的预测研究。引入Mixture-of-Experts框架，整合了文本、音频和手势信息，有效提高了模型在预测对话轮流中的精度。", "conclusion": "本文利用新增的语义手势数据集和多专家混合模型显著提高了对话轮流预测的性能。结果显示，语义指导的手势在多模态环境中对于预测对话轮流起到了重要的补充作用。"}
{"llm_update_time": "20251023", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.19346", "html_url": "https://arxiv.org/abs/2510.19346", "title": "基于GLINER的局部遮蔽技术用于公正的上下文感知谱系：一个PII去除系统的开发与评估", "title_en": "Local Obfuscation by GLINER for Impartial Context Aware Lineage: Development and evaluation of PII Removal system", "authors": "Prakrithi Shivaprakash,Lekhansh Shukla,Animesh Mukherjee,Prabhat Chand,Pratima Murthy", "background": "从电子健康记录(EHRs)中的病历记录中去除个人可识别信息(PII)对于研究和人工智能的发展至关重要。大型语言模型(LLMs)虽强大，但在低资源环境中使用受到高计算成本和数据隐私风险的限制。为了应对这些挑战，我们开发了LOGICAL (Local Obfuscation by GLINER for Impartial Context-Aware Lineage)，这是一种基于微调后的GLiNER通用轻量命名实体识别模型的高效本地部署PII去除系统。", "innovation": "开发了基于微调后的GLiNER模型的LOGICAL系统，用于从EHRs中去除PII。该系统高效、本地部署，且在九个PII类别中表现优于其他工具，特别是在资源受限环境中。", "conclusion": "GLiNER微调模型在去PII方面表现出色，其总体微观平均F1分数为0.980，显著优于其他工具，如Gemini-Pro-2.5。LOGICAL系统能够正确 sanitization 95%的文档，而另一最佳工具只能完成64%。尽管如此，系统也需要人工验证，并且在某些实体层面存在2%的假阴性率。该研究提出了一种“源端消毒”方法，提供了一种替代高强度LLMs的解决方案，有助于在保护数据隐私的同时，创建脱敏的数据集进行研究和AI开发，尤其适用于资源限制环境。"}
{"llm_update_time": "20251023", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.19358", "html_url": "https://arxiv.org/abs/2510.19358", "title": "M3-SLU: 评估多模态大型语言模型中的说话者归因推理", "title_en": "M3-SLU: Evaluating Speaker-Attributed Reasoning in Multimodal Large Language Models", "authors": "Yejin Kwon,Taewoo Kang,Hyunsoo Yoon,Changouk Kim", "background": "近年来，尽管语音和文本理解模型在对话系统中表现出了强大的性能，但它们仍然在处理多说话者、多回合对话的理解能力上表现不佳，特别是在识别谁在何时说了什么的能力方面遇到了挑战。为此，该研究提出了一个名为M3-SLU的新基准，它由四个开源数据集（CHiME-6，MELD，MultiDialog，和AMI）构建而成，包含了超过12,000个验证实例，包含配对的音频、转录文稿和元数据。M3-SLU旨在为评估说话者归因推理提供一个可靠的基准，这是多模态对话理解中的关键方面之一。", "innovation": "M3-SLU是一个多模态大型语言模型（MLLM）基准，专门用于评估多说话者、多回合的语音理解。它包括两个任务：说话者归因问答和通过话语匹配进行说话者归因。基准数据集包含大量验证过的实例，展示了模型在理解对话内容方面的表现差异，尤其是在识别说话者方面的差距。该基准提供了一种利用大型语言模型作为裁判和准确性指标进行评估的框架，有助于推动说话者意识的多模式理解研究。", "conclusion": "M3-SLU为研究团队提供了一个有挑战性的基准，帮助识别当前多模态大型语言模型在多说话者对话理解上的关键差距，特别是说话者归因的能力。未来的工作方向包括利用该基准进一步提升对话系统处理多说话者对话的能力。"}
{"llm_update_time": "20251023", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.19363", "html_url": "https://arxiv.org/abs/2510.19363", "title": "LoongRL：长文本高级推理的强化学习方法", "title_en": "LoongRL:Reinforcement Learning for Advanced Reasoning over Long Contexts", "authors": "Siyuan Wang,Gaokai Zhang,Li Lyna Zhang,Ning Shang,Fan Yang,Dongyao Chen,Mao Yang", "background": "在大型语言模型中，处理长文本推理至关重要。虽然强化学习（RL）能通过激发‘豁然开朗’思维模式提高短文本推理能力，但长文本推理所需的高度复杂思维模式尚未被充分研究，高品质的长文本RL数据也相对稀缺。", "innovation": "提出了LoongRL，一种基于数据驱动的RL方法，特别针对长文本推理进行优化。LoongRL的核心是KeyChain，一种合成方法，通过在包含大量干扰文档的集合中插入UUID链将短问题转换为高难度的长文本任务。这种方法要求模型逐步跟踪正确链路，识别真实问题，检索相关事实并进行推理以正确回答问题。使用KeyChain训练的RL诱导了一种计划-检索-推理-核验的模式，这种模式在训练范围外也有广泛应用。通过训练，模型能在不影响实时性的情况下有效解决大量任务。", "conclusion": "LoongRL在Qwen2.5-7B和14B上的多跳QA准确度分别提高了23.5%和21.1%，达到了74.2的分数，与更大的前沿模型o3-mini和DeepSeek-R1的分数相近。它还提高了长文本检索能力，通过了所有128000项高难度测试，并保持了短文本推理的能力。"}
{"llm_update_time": "20251023", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.19365", "html_url": "https://arxiv.org/abs/2510.19365", "title": "巨量法律嵌入基准 (MLEB)", "title_en": "The Massive Legal Embedding Benchmark (MLEB)", "authors": "Umar Butler,Abdur-Rahman Butler,Adrian Lucas Malec", "background": "当前公开的法律信息检索基准较为有限，MLEB 是迄今为止最大、最为多样化和最为全面的开源法律信息检索基准。它涵盖了多个司法管辖区（美国、英国、欧盟、澳大利亚、爱尔兰和新加坡）、多种文件类型（案例、法规、监管指南、合同和文献）以及多种任务类型（搜索、零样本分类和问答），这对于推动该领域的深入研究具有重要意义。", "innovation": "MLEB 的创新之处在于其覆盖了多个司法管辖区和多种文件类型的最新优质数据集。特别值得注意的是，其中七个数据集是全新的，专门为填补开源法律信息检索领域在数据方面存在的空白而建立的。", "conclusion": "研究者详细记录了 MLEB 的构建方法和新数据集的创建过程，并公开了代码、结果和数据，旨在促进可重复的评估。这将为开放领域内法律信息检索的相关研究和实践提供有力支持。"}
{"llm_update_time": "20251023", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.19367", "html_url": "https://arxiv.org/abs/2510.19367", "title": "使用句子嵌入监督的手语翻译", "title_en": "Sign Language Translation with Sentence Embedding Supervision", "authors": "Yasser Hamidullah,Josef van Genabith,Cristina España-Bonet", "background": "现有的手语翻译（SLT）系统通过手语术语注释来促进学习过程，既可以是端到端的方式，也可以包括一个中间步骤。然而，手语术语注释的数据通常规模较小，并且不同数据集间的术语注释存在较大差异。这篇文章介绍了一种新的基于训练时目标句子嵌入的方法，从而取代术语注释的角色，无需任何人工标注，而是通过原始文本数据学习。这种方法易于实现多语言，因此在德国语（PHOENIX-2014T）和美国语（How2Sign）手语数据集上进行了评估，并试验了单语和多语句子嵌入及翻译系统的方法。", "innovation": "本文提出了一种新的基于句子嵌入的监督方法，它能在训练时使用目标句子的嵌入来取代术语注释的角色，不需任何人工标注，通过原始文本数据学习。这种方法简化了手语翻译系统的设计并提高了效率。特别是在缺乏术语注释的数据集和没有额外的手语翻译数据集预训练的情况下，这种方法取得了明显优于其他无术语注释方法的结果，奠立了新的前沿标准。", "conclusion": "本文提出的方法在没有术语注释数据集的情况下表现良好，甚至超越了依赖术语注释的系统，并显著提高了在德国语和美国语手语数据集上的翻译质量，因此开启了手语翻译的新范式。"}
{"llm_update_time": "20251023", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.19398", "html_url": "https://arxiv.org/abs/2510.19398", "title": "SONAR-SLT: 通过无语言偏好句嵌入监督实现多语言手语翻译", "title_en": "SONAR-SLT: Multilingual Sign Language Translation via Language-Agnostic Sentence Embedding Supervision", "authors": "Yasser Hamidullah,Shakib Yazdani,Cennet Oguz,Josef van Genabith,Cristina España-Bonet", "background": "手语翻译（SLT）通常使用单一口头语言的文字进行训练，这限制了其扩展性和跨语言的一般化能力。早期的方法用基于文本的句子嵌入替换词典监督，但这些方法仍然受限于特定的语言和模态。", "innovation": "本文采用语言无偏好、跨模态嵌入，这些嵌入基于多语言的文本和语音训练，用于直接监督多语言的手语翻译。为了应对数据稀缺性，提出了一种耦合增强方法，结合了多语言目标增强（即翻译成多种语言）和视频级别的扰动，以提高模型的鲁棒性。实验结果显示，在文本仅基于句子嵌入监督上，该方法的BLEURT值有持续性的提升，特别是在资源有限的设置中具有更大的改进。", "conclusion": "我们的研究结果表明，结合无语言偏好嵌入监督和耦合增强，为传统的SLT训练提供了一种可扩展且语义稳健的替代方案。"}
{"llm_update_time": "20251023", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.19366", "html_url": "https://arxiv.org/abs/2510.19366", "title": "MoE-Prism: 通过模型-系统协同设计拆分大型专家以实现弹性Mixture-of-Experts服务", "title_en": "MoE-Prism: Disentangling Monolithic Experts for Elastic MoE Services via Model-System Co-Designs", "authors": "Xinfeng Xia,Jiacheng Liu,Xiaofeng Hou,Peng Tang,Mingxuan Zhang,Wenfeng Wang,Chao Li", "background": "Mixture-of-Experts (MoE) 模型作为大规模人工智能的顶级技术，通过稀疏激活参数实现高质量效果。然而，这些模型依赖于通过top-k机制在少数大型专家之间进行路由，这种“单一途径”的方法导致能提供的操作点质量较低且粒度粗放，造成成本与质量之间的难以调和的权衡关系，使得模型无法满足多样化的服务水平目标，导致资源分配过度。为解决这一问题，作者提出了MoE-Prism，一种模型-系统协同设计方法，可以将僵硬的MoE模型转化为弹性服务，增强模型的灵活性，更好地适应资源变化，灵活调配资源以满足性能需求。", "innovation": "提出了一种名为MoE-Prism的方法，该方法通过模型-系统协同设计，实现了MoE模型的细粒度解构，增强模型的灵活性。第一阶段是一个离线重构引擎，将大型专家分解为细粒度的“子专家”，并通过元启发式优化方法进行神经元分组。第二阶段则是一个线上调度引擎，通过QoS感知的调度策略，解决复杂系统问题。这种方法使得模型能够动态地提供4倍于基线的更稳定、更独特的操作点，提高了服务的吞吐量和降低了延迟。", "conclusion": "MoE-Prism通过协同设计使得MoE模型更加灵活，能在严格的延迟预算下提高吞吐量至19.9%，或者在资源受限的情况下将延迟降低至10.36%。这种改进为AI服务提供了控制调节的能力，能够更好地满足不同性能需求的QoS目标，使得下一代AI服务更具适应性、高效性及服务质量意识。"}
{"llm_update_time": "20251023", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.19471", "html_url": "https://arxiv.org/abs/2510.19471", "title": "Re-evaluating Minimum Bayes Risk Decoding for Automatic Speech Recognition", "title_en": "Re-evaluating Minimum Bayes Risk Decoding for Automatic Speech Recognition", "authors": "Yuu Jinnai", "background": "最近的研究表明，基于样本的最小贝叶斯风险（MBR）解码在文本生成任务中（如机器翻译、文本摘要和图像字幕生成）比短语束搜索方法更优。然而，在语音识别（ASR）和语音翻译（ST）等语音到文本任务中，束搜索仍然是业界当前的选择。鉴于MBR解码在文本任务中的有效性，研究者推测MBR解码在语音到文本任务中同样有效。", "innovation": "本研究对MBR解码在英语和日语的语音识别和语音翻译任务中进行评估，使用了Whisper及其衍生模型。结果显示，在大部分实验设置中，MBR解码的准确性优于束搜索。这些结果表明，MBR解码是一种具有潜力的办法，适用于需要高精度的离线ASR和ST任务。", "conclusion": "研究结果表明，MBR解码在大部分实验设定中优于束搜索，在要求高精度的离线ASR和ST任务中展现出良好的效果，因此是一种有前景的方法。"}
{"llm_update_time": "20251023", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.19488", "html_url": "https://arxiv.org/abs/2510.19488", "title": "VideoAgentTrek: 根据未标注视频进行计算机使用预训练", "title_en": "VideoAgentTrek: Computer Use Pretraining from Unlabeled Videos", "authors": "Dunjie Lu,Yiheng Xu,Junli Wang,Haoyuan Wu,Xinyuan Wang,Zekun Wang,Junlin Yang,Hongjin Su,Jixuan Chen,Junda Chen,Yuchen Mao,Jingren Zhou,Junyang Lin,Binyuan Hui,Tao Yu", "background": "训练计算机使用代理需要大量的GUI交互数据，但大规模手动标注操作轨迹的成本非常高。VideoAgentTrek 提出了一种能够在网页规模级别自动挖掘训练数据的可扩展管道，从而消除了手动标注的需求。其关键挑战在于原始视频中包含隐式演示但缺乏明确的操作标签。", "innovation": "开发了一种新的管道VideoAgentTrek，包括Video2Action模块，该模块由两个组件组成：（1）视频定位模型，用于检测和定位具有精确时间边界和上下文的GUI操作；（2）动作内容识别器，用于高精度地提取点击坐标和输入文本等结构化参数。该方法在39,000个YouTube教程视频上生成152万个自动化的交互步骤，通过连接式预训练和监督微调，显著提高了任务成功率和步骤准确性。", "conclusion": "研究表明，被动的互联网视频可以转化为高质量的监督数据，用于计算机使用代理的训练，提供了成本高昂的手动标注的可扩展替代方案。"}
{"llm_update_time": "20251023", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.19419", "html_url": "https://arxiv.org/abs/2510.19419", "title": "BLiSS 1.0：评估双语学习者在第二语言小语言模型中的能力", "title_en": "BLiSS 1.0: Evaluating Bilingual Learner Competence in Second Language Small Language Models", "authors": "Yuan Gao,Suchir Salhan,Andrew Caines,Paula Buttery,Weiwei Sun", "background": "为了弥合性能导向基准与认知启发性模型评估之间的差距，研究人员引入了BLiSS 1.0，即一种语言学习者跨语言句法结构基准。该基准通过一个新的选择性容忍范式来测试模型是否认为一种自然语言学习错误比在同句中的匹配人工错误更具可信度，它基于超过280万个自然语言学习句子构建，提供了136,867个控制三元组（正确、学习者、人工），用于进行这项测试。实验表明，选择性容忍是不同于标准语法正确性的独特能力，训练范式明显影响模型的性能。这些结果验证了BLiSS作为衡量不同训练目标下模型与人类语言习得系统性模式一致性的稳健工具的有效性。", "innovation": "BLiSS 1.0前所未有的通过选择性容忍范式，评估模型如何在面对真实学习者错误时进行判断，从而区分模型的认知能力。与现有标准相比，它提供了一种全新的评估方式进行对比，强调了思维方式而非单纯的语言能力", "conclusion": "该研究表明，选择性容忍是区分模型能力的独特特征，不同训练范式的训练模型在这一能力上的表现有显著差异。BLiSS 1.0提供了一个有力的工具，以精确测量训练目标对模型与人类语言获得的系统性模式的一致性的影响。"}
{"llm_update_time": "20251023", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.19361", "html_url": "https://arxiv.org/abs/2510.19361", "title": "AgenticMath：基于代理生成的数学数据增强LLM推理", "title_en": "AgenticMath: Enhancing LLM Reasoning via Agentic-based Math Data Generation", "authors": "Xianyang Liu,Yilin Liu,Shuai Wang,Hao Cheng,Andrew Estornell,Yuzhi Zhao,Jiaheng Wei", "background": "高质量化数学问题数据集的创建是提高大型语言模型（LLM）推理能力的挑战性问题，当前方法常常生成低质量或不正确的答案，且数据信息量不够丰富。现有的监管微调方法仍然面临挑战。", "innovation": "提出了AgenticMath，一种新型由代理驱动的生成高质量数学问题-答案对的管道，用于增强LLM的监管微调。该方法分为四个阶段：（1）种子问题过滤选择具有高信息丰富度、复杂性和清晰度的问题；（2）代理式问题重述，利用多代理系统生成多样且逻辑一致的重述；（3）答案扩充，使用链式思维推理解释答案，增强数字和逻辑准确性；（4）最终问题和答案评估，保留最优秀的对子。实验结果显示，使用AgenticMath生成的数据集（仅包含约3万到6万数学样本）对3B-8B参数的LLM进行微调，在多个数学推理基准任务上表现优于使用更大数据量（如40万或230万样本）训练的基准模型。", "conclusion": "通过有针对性地生成高质数据，可以更有效提高LLM的数学推理能力，而非依赖大规模、低质量的数据。"}
{"llm_update_time": "20251023", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.19413", "html_url": "https://arxiv.org/abs/2510.19413", "title": "时空手势语言表示与翻译", "title_en": "Spatio-temporal Sign Language Representation and Translation", "authors": "Yasser Hamidullah,Josef van Genabith,Cristina España-Bonet", "background": "本文描述了DFKI-MLT在2022年WMT-SLT任务中对瑞士德语手语（视频）进行德语文本翻译的提交。最先进的SLT技术通常使用带有定制输入嵌入的通用seq2seq架构。与文本机器翻译中使用的词语嵌入不同，SLT系统利用从视频帧中提取的特征。标准方法往往忽视了时间特征带来的好处。我们的研究中，提出了一种能够同时学习时空特征表示和翻译的新系统，从而形成了一种预期能更好地泛化到新数据集中的端到端架构。在开发集上，我们的最佳系统达到了5±1 BLEU分数，但在测试集上的性能下降到了0.11±0.06 BLEU分数，", "innovation": "本研究提出了一种在同一模型中学习时空特征表示和翻译的新方法，形成了端到端的架构，期望能更好地泛化到新数据集中。该系统采用了不同于传统文本机器翻译方法的特征提取方式，而是利用从视频帧中提取的特征进行SLT，有望更好地捕捉手势语言的动态特性。", "conclusion": "尽管在开发集上表现出色，但在测试集上的性能有所下降，这表明系统可能在一定程度上过拟合了训练数据。未来的工作将侧重于提高该模型在不同数据集上的泛化能力。"}
{"llm_update_time": "20251023", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.19457", "html_url": "https://arxiv.org/abs/2510.19457", "title": "MINED: 探测与利用多模态时间敏感知识评估和更新大规模多模态模型", "title_en": "MINED: Probing and Updating with Multimodal Time-Sensitive Knowledge for Large Multimodal Models", "authors": "Kailin Jiang,Ning Jiang,Yuchen Ren,Yuchen Li,Yifan Gao,Jinhe Bi,Yunpu Ma,Qingqing Liu,Xianhao Wang,Yifan Jia,Hongbo Jiang,Yaocong Hu,Bin Li,Lei Liu,Yuntao Du", "background": "现有的大规模多模态模型（LMMs）能够通过跨模态预训练编码丰富的事实知识，但它们的静态表示难以保持对时间敏感事实知识的准确理解。当前的基准仅限于静态设计，未能全面评估LMMs在理解时间敏感知识方面的能力。因此，论文提出了MINED，这是一个全面的基准，它评估了LMMs在六种关键维度下的时间意识以及包括认知、意识、可信度、理解、推理和鲁棒性在内的11个挑战任务。MINED 由来自维基百科的两个专业标注员构建，包含2104个时间敏感的知识样本，切分了六个知识类型。", "innovation": "论文提出了MINED，一个为大规模多模态模型设计的基准，它不仅评估了时间敏感知识的理解能力，还通过知识编辑方法探索了更新LMMs中时间敏感知识的可行性。实验结果显示，Gemini-2.5-Pro在该基准上的平均CEM分数最高，而大多数开源的LMMs在理解时间敏感知识方面仍然缺乏能力。此外，LMMs在组织知识上表现最好，但在运动知识上表现最弱。", "conclusion": "通过MINED基准，可以全面评估LMMs的时间意识，并通过知识编辑方法有效更新LMMs中时间敏感的知识。虽然现有LMMs在时间敏感知识的理解上存在局限性，但知识编辑方法为改善这一问题提供了可能性。"}
{"llm_update_time": "20251023", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.19410", "html_url": "https://arxiv.org/abs/2510.19410", "title": "ToMMeR -- 来自大型语言模型的高效实体提及检测", "title_en": "ToMMeR -- Efficient Entity Mention Detection from Large Language Models", "authors": "Victor Morand,Nadi Tomeh,Josiane Mothe,Benjamin Piwowarski", "background": "实体提及检测是从文本中识别出实体跨度的工作，这一过程对于信息抽取至关重要，但由于其技术挑战，已成为性能瓶颈。现有的几种方法已经尝试解决这一挑战，但往往需要大量的模型参数或仅有有限的性能改进。本文旨在通过使用轻量级模型（参数少于300,000）和早期语言模型的层来更有效地进行实体提及检测，从而解决这个问题。", "innovation": "本文提出了一种名为ToMMeR的轻量级模型，该模型通过早期语言模型的层来探测提及检测能力。实验表明，ToMMeR在13个NER基准测试中实现了高达93%的零样本召回率，并且具有很高的精度（超过90%），显示出其对虚假预测的低敏感性。跨模型分析表明，不同大小的架构收敛于相似的提及边界，证实了提及检测可以自然地从语言建模中产生。此外，通过结合跨度分类头部，ToMMeR能达到接近SOTA的NER性能（基准测试的F1分数在80%到87%之间）。这项工作提供了证据，表明结构化的实体表示存在于早期的Transformer层中，并且可以通过少量参数高效恢复。", "conclusion": "本文证明了站在大型语言模型的肩膀上可以实现高效且精确的实体提及检测。ToMMeR模型展示了其在参数效率和性能上的双重优势。这一发现进一步增强了我们对语言模型内部机制的理解，并为未来的信息抽取技术提供了新的思路。"}
{"llm_update_time": "20251023", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.19493", "html_url": "https://arxiv.org/abs/2510.19493", "title": "BABYLM的最佳序列长度是什么？", "title_en": "What is the Best Sequence Length for BABYLM?", "authors": "Suchir Salhan,Richard Diehl Martinez,Zébulon Goriely,Paula Buttery", "background": "传统的Transformer语言模型通常使用固定长度的上下文窗口，该窗口长度随着大规模预训练数据集的增长而增长。在BabyLM挑战中，许多过去的提交默认使用较短的序列长度。本文旨在探讨序列长度对BabyLM预训练的影响，以找出最适合训练BabyLM的理想序列长度。研究使用1亿词的训练数据和固定的计算预算，比较了125M参数的Mamba和OPT模型，发现尽管较长的序列通常更好，但最理想的序列长度取决于任务类型和模型架构。较短的序列长度对语法泛化的任务已足够，而更长的序列长度则有利于形态学类比推理任务的处理。", "innovation": "本文通过实验探索了序列长度对BabyLM预训练性能的影响，填补了该领域关于如何选择合适序列长度的空白，并展示了序列长度的选择对于不同任务的重要影响.", "conclusion": "研究认为，在训练BabyLM时，虽然较长的序列有时可能更好，但最优的序列长度依赖于具体的任务和模型架构。短序列长度更适合于语法泛化的任务，而较长的序列长度则可以提高形态学类比推理任务的表现。"}
{"llm_update_time": "20251023", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.19506", "html_url": "https://arxiv.org/abs/2510.19506", "title": "Large Language Model Routing for Improved Efficiency and Semantic Understanding", "title_en": "Lookahead Routing for Large Language Models", "authors": "Canbin Huang,Tianyuan Shi,Yuhua Zhu,Ruijun Chen,Xiaojun Quan", "background": "现有方法将路由问题视为基于输入查询的分类问题，这虽然减少了跨所有模型进行推理的需求，但也忽略了潜在输出中可获的有价值信息，并且无法捕捉响应生成中隐含的意图或上下文细微差别，特别是在面对复杂或含糊不清的查询时，这种局限性可能导致路由决策不佳。", "innovation": "提出了Lookahead，一个预测潜在模型输出的路由框架，通过预测其潜在表示来指导模型选择，从而实现更明智的路由决策，而不必进行完整推理。该框架内的两种方法基于因果和掩码语言模型。实验结果显示，Lookahead 在七个公共基准测试中（涵盖指令遵循、数学推理和代码生成）的一致性能提升达到 7.7%，超越了现有的路由基线。", "conclusion": "Lookahead 框架通过预测模型潜在表示来指导模型选择，从而在多个领域中优于现有路由方法，实现了更高效的多模型系统。其代码已公开。"}
{"llm_update_time": "20251023", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.19585", "html_url": "https://arxiv.org/abs/2510.19585", "title": "使用大型语言模型检测历史书籍中的拉丁文：一个多模态基准", "title_en": "Detecting Latin in Historical Books with Large Language Models: A Multimodal Benchmark", "authors": "Yu Wu,Ke Shu,Jonas Fischer,Lidia Pivovarova,David Rosson,Eetu Mäkelä,Mikko Tolonen", "background": "本文介绍了一项新型任务，即从内容混杂且布局多样的历史文档中提取拉丁文片段。研究基于724页的多模态标注数据集，对比了大规模基础模型的性能，目的在于评估这些模型在这一任务中的表现和可靠性。研究表明，当下模型能够实现可信赖的拉丁文检测。这项研究首次系统分析了这些模型在该任务中的能力及限制。", "innovation": "采用大规模基础模型来识别历史文档中的拉丁文，构建了一个多模态数据集进行基准测试，这是首例对这种模型在检测拉丁文任务中的能力及限制进行全面分析的研究。", "conclusion": "当前基础模型在拉丁文检测方面具有实际应用价值，但也存在一定的局限性。这项研究为理解这些模型的能力边界提供了宝贵的参考。"}
{"llm_update_time": "20251023", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.19509", "html_url": "https://arxiv.org/abs/2510.19509", "title": "哪种评估适用于哪种模型？一种语音模型评估分类法", "title_en": "Which Evaluation for Which Model? A Taxonomy for Speech Model Assessment", "authors": "Maureen de Seyssel,Eeshan Gunesh Dhekane", "background": "语音基础模型在广泛的任务上已经展现了出色的性能，但它们的评估仍然在不同任务和不同模型类型之间存在脱节。不同的模型在语音处理的不同方面表现突出，因而需要不同的评估准则。现有的评估标准并未提供一个统一的方法来确定哪些评估适用于哪种模型。", "innovation": "本文提出了一种统一的分类法，用以回答‘哪种评估适用于哪种模型?’这一问题。该分类法定义了三个相互独立的维度：评估方面、模型所需的技能以及执行任务或实验的要求。该分类法分类了广泛的现有评估和基准，涉及如表示学习、语音生成和互动对话等领域。通过将每个评估与模型显示的能力（如语音生成、实时处理）及其方法论要求（如调优数据、人类判断）进行映射，它提供了一种理性框架，用于将模型与合适的评估方法进行匹配。同时，该分类法揭示了系统性的差距，如语调、交互或推理方面的覆盖不足，指出了未来基准设计的关注点。", "conclusion": "总体而言，本文为选择、解释和扩展语音模型评估提供了概念基础和实践指南，有助于推动语音模型评估领域的进步。"}
{"llm_update_time": "20251023", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.19546", "html_url": "https://arxiv.org/abs/2510.19546", "title": "多语言翻译中灾难性遗忘的条件", "title_en": "Conditions for Catastrophic Forgetting in Multilingual Translation", "authors": "Danni Liu,Jan Niehues", "background": "在特定语言上微调多语言基础模型时，通常会引发灾难性遗忘，导致未曾参与微调的语言性能下降。虽然该现象在文献中已有广泛记录，但关于遗忘何时发生的文献结果却支离破碎、不明确。需要系统地研究这些现象，以确定触发多语言微调中灾难性遗忘的因素。研究团队选择机器翻译作为测试床，通过控制模型架构、数据规模和微调方法进行实验，探究触发条件，结果表明模型规模与数据量的比例是决定性因素。研究还揭示了模型遵循指令的能力比架构对保留多语言知识更为关键，且参数高效微调并没有比完全微调更有效地减少遗忘。最后，跨语言对齐可以减少遗忘的同时促进未见过的目标语言的积极转移。", "innovation": "通过系统的实验研究揭示了模型规模与数据量的比例是触发遗忘的主要因素；强调了模型遵循指令能力的重要性；发现参数高效微调不优于完全微调以减少遗忘；展示了跨语言对齐可以减少遗忘并促进未见过目标语言的积极转移。", "conclusion": "研究结果表明，在不同模型架构、数据规模和微调方法下，模型规模与数据量的比例是决定遗忘的关键因素；遵循指令的能力比架构更为关键；参数高效微调与完全微调在减少遗忘上效果相似；跨语言对齐可以有效减少遗忘并促进未见过目标语言的迁移。"}
{"llm_update_time": "20251023", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.19644", "html_url": "https://arxiv.org/abs/2510.19644", "title": "LLavaCode：用于检索增强代码生成的压缩代码表示", "title_en": "LLavaCode: Compressed Code Representations for Retrieval-Augmented Code Generation", "authors": "Daria Cherniuk,Nikita Sukhorukov,Nikita Sushko,Daniil Gusak,Danil Sivtsov,Elena Tutubalina,Evgeny Frolov", "background": "检索增强生成已成为代码完成中最有效的方法之一，特别是在需要仓库周围上下文时。然而，引入上下文会显著增加序列长度，导致推理速度变慢，这对IDE等交互式设置来说是一个关键限制。", "innovation": "该论文提出了LlavaCode框架，通过压缩代码到可由代码LLM理解的紧凑、语义丰富的表示，同时减少检索上下文仅到几个压缩单态量中，从而提高生成质量并减少延迟。使用小型投影模块显著提高编码模型的EM和ES指标，同时几乎不影响延迟。", "conclusion": "压缩的上下文在行完成任务中使Time-to-First-Token (TTFT) 减少了20-38%，相较于完整的RAG管道线有显著改进。"}
{"llm_update_time": "20251023", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.19628", "html_url": "https://arxiv.org/abs/2510.19628", "title": "CrossNews-UA: 乌克兰语、波兰语、俄语和英语跨语言新闻语义相似性基准", "title_en": "CrossNews-UA: A Cross-lingual News Semantic Similarity Benchmark for Ukrainian, Polish, Russian, and English", "authors": "Daryna Dementieva,Evgeniya Sukhodolskaya,Alexander Fraser", "background": "在社交媒体和快速假信息传播的时代，新闻分析依然是一个重要的任务。在多语言环境中，尤其是非英语语言中检测假新闻颇具挑战性。跨语言新闻对比是通过利用不同语言的外部源来验证信息的有前景的方法。然而，现有的跨语言新闻分析数据集通常由记者和专家手工编制，这限制了其可扩展性和适应新语言的能力。", "innovation": "本文通过引入一个可扩展的、可解释的众包流程，用于跨语言新闻语义相似性评估，填补了这一缺口。利用此流程，我们收集了一个名为CrossNews-UA的新数据集，涵盖了乌克兰语为中心，以及与其语义和语境相关语言（波兰语、俄语和英语）之间的新闻对。每个新闻对都根据4W标准（Who、What、Where、When）进行了语义相似度标注，并附有详细的说明。我们还测试了从传统的短语词袋模型到大型语言模型等多种模型。", "conclusion": "我们的结果显示，在多语言新闻分析中存在着诸多挑战，并提供了关于不同模型表现的见解。"}
{"llm_update_time": "20251023", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.19616", "html_url": "https://arxiv.org/abs/2510.19616", "title": "PBBQ: 一种通过人类与人工智能合作编纂的波斯语偏见基准数据集，用于大型语言模型", "title_en": "PBBQ: A Persian Bias Benchmark Dataset Curated with Human-AI Collaboration for Large Language Models", "authors": "Farhan Farsi,Shayan Bali,Fatemeh Valeh,Parsa Ghofrani,Alireza Pakniat,Kian Kashfipour,Amir H. Payberah", "background": "随着大型语言模型（LLMs）的广泛应用，确保它们符合社会规范已经成为一个关键问题。尽管之前的研究已经对各种语言中的偏见进行了检测，但针对波斯文化背景中的社会偏见资源仍然缺乏。前期研究虽然在各种语言中检测了偏见，但针对波斯文化中的社会偏见资源还存在很大不足。", "innovation": "本文介绍了PBBQ，这是一个全面的基准数据集，旨在评估波斯LLMs中的社会偏见。PBBQ数据集包含16个文化类别，通过与社会科学专家密切合作，确保了问卷调查的完成和有效性的验证。数据集包含超过37,000个精心选择的问题，为评估和缓解波斯语言模型中的偏见提供了基础。本文还对多个开源和封闭源LLM以及特定于波斯语的微调模型进行了基准测试，结果显示当前的LLMs在波斯文化中的社会偏见非常显著。", "conclusion": "我们的研究发现，当前的LLMs在波斯文化中表现出显著的社会偏见。通过将模型输出与人类响应进行比较，我们观察到，LLMs常常复制人类的偏见模式，这揭示了学习表示与文化之间复杂交互的本质。未来的工作将在PBBQ数据集上进行，该数据集将对未来的相关研究开放。"}
{"llm_update_time": "20251023", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.19492", "html_url": "https://arxiv.org/abs/2510.19492", "title": "机器生成文本检测器是成员推理攻击", "title_en": "Machine Text Detectors are Membership Inference Attacks", "authors": "Ryuto Koike,Liam Dugan,Masahiro Kaneko,Chris Callison-Burch,Naoaki Okazaki", "background": "虽然成员推理攻击（MIAs）和机器生成文本检测的目标不同，但它们常常利用语言模型概率分布中的相似信号来识别训练样本和合成文本。尽管这两者的方法论基础相似，但它们的研究至今是独立进行的，这可能导致一些遗漏更有效的方法和更有价值的见解。本文旨在研究两者方法的转移性，即一个任务的方法在另一个任务上表现如何。通过理论和实验研究，作者发现达到最优性能的度量标准在两者中的表现相同，并且方法对这个最优度量的逼近程度与它的转移性能正相关。大量实验结果显示跨任务表现存在很高的相关性，这表明转移性具有实际的应用价值。研究结果强调了跨任务研究意识和合作的重要性，为此，作者提出了MINT评估套件作为一种统一的评估工具，以促进公平的评估和跨任务发展。", "innovation": "本文证明了在成员推理攻击和机器生成文本检测任务中，最优性能度量标准是相同的，并且提出现有文献中大量研究可以通过这个最优度量标准来统一。进一步，作者推测方法对这一度量的逼近程度与其跨任务性能相关。大规模实验结果显示，来自机器生成文本检测的任务的方法在成员推理攻击基准测试中表现出色，这一发现突显了转移性的实际影响。为了促进跨任务发展和公平评估，作者引入了一个统一的评估套件MINT，集成了来自两个任务的15种近期方法的实现。", "conclusion": "本文强调了提高跨任务意识和研究合作的必要性，通过理论和实验研究，研究了成员推理攻击和机器生成文本检测任务方法的转移性能，并提出了一种新的评价工具MINT，以促进这一领域的公平评估和发展。"}
{"llm_update_time": "20251023", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.19641", "html_url": "https://arxiv.org/abs/2510.19641", "title": "Style Attack Disguise: 当字体成为对抗意图的伪装", "title_en": "Style Attack Disguise: When Fonts Become a Camouflage for Adversarial Intent", "authors": "Yangshijie Zhang,Xinda Wang,Jialin Liu,Wenqiang Wang,Zhicong Ma,Xingxing Jia", "background": "随着社交媒体的增长，用户开始使用艺术性和非传统的字体和表情符号来表达个性，使文本既美观又易于人类阅读。然而，这些艺术性字体给自然语言处理（NLP）模型带来了隐蔽的威胁：尽管人类可以轻松理解这种文本，但模型将这些字符作为独立的标记处理，从而导致干扰。研究人员发现，人类与模型对文本的理解存在差异，并提出了一种基于样式攻击的新方法——Style Attack Disguise (SAD)，设计了两种版本：轻量级版本用于提高查询效率，而强攻击版本则具有更强的效果。实验表明，SAD 在情感分类、机器翻译以及商用服务上的性能非常强劲。此外，SAD 的攻击可能性还扩展到了包括文本到图片和文本到语音生成的多模态任务中，表现出潜在威胁。", "innovation": "该研究提出了一种新的命名方式——Style Attack Disguise (SAD)，用于描述并应对基于样式的NLP模型攻击。研究人员设计了两个版本：轻量级和强攻击版本，并通过情感分类、机器翻译和商用服务等实验验证了SAD 的强攻击性能。SAD还可以扩展到多模态任务，显示了其广泛的应用前景。", "conclusion": "SAD不仅展示了基于样式的新型攻击方式的强大效率和广泛适用性，还揭示了NLP模型在处理艺术性文本时的安全隐患。未来的研究可以进一步探索防御此类攻击的方法，并提升NLP模型在类似复杂场景下的鲁棒性。"}
{"llm_update_time": "20251023", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.19669", "html_url": "https://arxiv.org/abs/2510.19669", "title": "DiffAdapt: 根据难度自适应推理的高效率大语言模型推理框架", "title_en": "DiffAdapt: Difficulty-Adaptive Reasoning for Token-Efficient LLM Inference", "authors": "Xiang Liu,Xuming Hu,Xiaowen Chu,Eunsol Choi", "background": "最近的研究表明，大型语言模型（LLMs）在解决问题时表现出色，但经常会产生冗长的思考痕迹，这些痕迹的实际用途不明确。本文旨在提高LLMs的效率，使它们能在不过度思考的情况下达到高水平的性能。通过对推理痕迹中的标记概率熵进行了分析，观察到一致的U形熵模式，表明LLMs在不同难度的问题上存在过度思考现象。基于这一发现，提出了一种轻量级框架DiffAdapt，可以根据问题的难度和推理痕迹中的熵选择适合的推理策略。方法在五个模型和八个基准上进行了全面的评估，显示了在减少标记使用量的同时，仍能保持或提高准确性。", "innovation": "提出了一种称为DiffAdapt的轻量级框架，该框架可以根据问题的难度和推理痕迹中的熵选择适合的推理策略。与现有方法不同，该方法无需对基础LLM进行微调，而是对一个小型探针进行分类，从而实现廉价的适配。此外，该方法还能有效地减少标记使用量，展示了在计算高效推理方面的实用路径。", "conclusion": "该方法在五个模型和八个基准上进行了全面的评估，显示了在减少标记使用量的同时，仍能保持或提高准确性，为计算高效推理提供了实用的路径。"}
{"llm_update_time": "20251023", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.19723", "html_url": "https://arxiv.org/abs/2510.19723", "title": "从回答到指导：一种面向法律文件的主动对话系统", "title_en": "From Answers to Guidance: A Proactive Dialogue System for Legal Documents", "authors": "Ashish Chouhan,Michael Gertz", "background": "法律信息的获取对普通人来说仍是一个持续的挑战，尤其是在理解和应用复杂的机构文本时。尽管欧盟提供了立法、议会答复和监管文件的开放访问，但对于普通民众而言，这些资源可能难以探索。因此，本文探讨了如何构建基于公民咨询单元（AskEP）收集的204篇博客的新颖数据集EUDial，以及如何利用检索增强生成和分层主题组织的词汇指导框架LexGuide，以改进主动法律对话系统。", "innovation": "本文创新地提出了EUDial数据集和LexGuide框架。EUDial数据集包含来自公民咨询单元收集的204篇博客的对话，共有880轮对话，平均每轮对话4.3轮。LexGuide框架通过检索增强生成和分层主题组织来结构化对话进程，确保在涵盖法律方面全面的同时，使对话轮次之间保持连贯性。", "conclusion": "本文通过主动、结构化的导航方式，填补了法律信息与公民理解之间的差距，证明了EUDial和LexGuide在促进主动法律对话系统方面的作用和实际应用价值。"}
{"llm_update_time": "20251023", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.19668", "html_url": "https://arxiv.org/abs/2510.19668", "title": "使用预训练模型解析情感", "title_en": "Unraveling Emotions with Pre-Trained Models", "authors": "Alejandro Pajón-Sanmartín,Francisco De Arriba-Pérez,Silvia García-Méndez,Fátima Leal,Benedita Malheiro,Juan Carlos Burguillo-Rial", "background": "变压器模型在情感识别领域取得了显著进展。然而，当探索大型语言模型（LLMs）的开放性查询时，仍存在诸多挑战。尽管现有模型表现良好，但在开放文本中的自动情感分析面临重大挑战，包括语境模糊、语言多样性以及难以解读复杂的情感表达。这些限制使通用模型的直接应用变得困难。", "innovation": "本文比较了在三种不同场景下微调与提示工程在情感检测中的有效性：(i) 使用简单提示的预训练模型和通用目的LLMs的性能；(ii) 不同情感提示设计在LLMs中的效果；(iii) 情感分组技术对这些模型的影响。实验测试结果显示，微调预训练模型在情感识别上的指标超过70%。此外，研究还表明，LLMs需要结构化的提示工程和情感分组以提高其性能。这些进步提高了情绪分析、人机交互以及对用户行为的理解在各个领域的应用水平。", "conclusion": "研究发现，通过结构化的提示工程和情感分组，可以提高LLMs的情感检测能力。这些方法改善了情感分析、人机交互，并加深了对用户行为的了解。"}
{"llm_update_time": "20251023", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.19733", "html_url": "https://arxiv.org/abs/2510.19733", "title": "Zhyper: 因子化超网络及其在条件化LLM微调中的应用", "title_en": "Zhyper: Factorized Hypernetworks for Conditioned LLM Fine-Tuning", "authors": "M. H. I. Abdalla,Zhipin Wang,Christian Frey,Steffen Eger,Josif Grabocka", "background": "大型语言模型（LLM）条件化是指指导LLM生成符合特定文化规范、特定政治信念或其他指定语义条件的内容。然而，提示工程不能保证LLM的行为符合所需条件，因为预训练和对齐数据集存在归纳偏见。此前的研究重点是通过直接条件化LoRA权重来微调LLM，但这种方法会引入大量的参数。因此，需要一种参数高效的方法来解决这一问题并实现LLM的条件化适应性微调。", "innovation": "我们提出的Zhyper是一种参数高效因子化的超网络框架，可以从文本描述中生成上下文感知的LoRA适配器。实验结果表明，Zhyper在参数量减少高达26倍的情况下达到了与现有最先进的基准性能相当的表现。此外，我们将Zhyper扩展到文化对齐，展示了其在跨域设置中更好的泛化能力和对细微上下文价值的更好捕捉。", "conclusion": "Zhyper在条件化LLM微调中实现了参数效率和效果的平衡，特别是在文化对齐方面展示了改进的表现，并且在多个基准测试中达到了竞争性的效果。"}
{"llm_update_time": "20251023", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.19694", "html_url": "https://arxiv.org/abs/2510.19694", "title": "提示是否重塑表示？提示对嵌入影响的实证研究", "title_en": "Do Prompts Reshape Representations? An Empirical Study of Prompting Effects on Embeddings", "authors": "Cesar Gonzalez-Gutierrez,Dirk Hovy", "background": "提示是利用大型语言模型（LM）在零样本设置中执行多种任务的一种常见方法。尽管提示在提升模型性能方面非常有效，但目前尚不清楚模型是如何在没有专门任务监督的情况下执行这些任务的内在机制。本研究旨在通过探究提示与内部表示质量之间的关系，揭示预训练嵌入如何可能支持在上下文任务中的解决过程。研究人员通过实证研究对零样本分类中的提示嵌入进行了系列探针实验，分析了不同提示模板的各种组合。实验结果表明，虽然提示影响了表示的质量，但这些变化并不总是与提示对目标任务的相关性具有一致的相关性。这一结果挑战了更相关提示必然导致更好表示的假设。进一步的研究揭示了可能导致这种意外行为的潜在因素有哪些。", "innovation": "本研究首次系统地探究了提示与表示质量的关系，通过实证方法分析了不同提示模板对零样本分类任务中的内部表示的影响，发现更相关提示并不一定导致更好的内部表示。这一发现改变了我们对提示作用的理解，并揭示了影响表示质量的潜在因素。", "conclusion": "提示对内部表示产生影响，但这种影响并不总是与提示对目标任务的相关性一致。更相关的提示并不必然导致更好的表示。研究还揭示了可能导致这种现象的潜在因素，为更好地理解提示与模型内部表示之间的关系提供了新的视角。"}
{"llm_update_time": "20251023", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.19767", "html_url": "https://arxiv.org/abs/2510.19767", "title": "SmartSwitch: 通过促进更深入的思维探索来克服LLM推理中的浅思维", "title_en": "SmartSwitch: Advancing LLM Reasoning by Overcoming Underthinking via Promoting Deeper Thought Exploration", "authors": "Xichen Zhang,Sitong Wu,Haoru Tan,Shaozuo Yu,Yinghao Zhu,Ziyi He,Jiaya Jia", "background": "长链推理(LongCoT)能力在大型语言模型在复杂推理任务中的突破中起到了关键作用。然而，伴随而来的一个问题是“浅思维”，在这种情况下，模型表现出表面化的推理，频繁地转换想法而缺乏充分的探索。这既限制了模型的性能也降低了字符效率。", "innovation": "我们提出了一种简单有效的推理策略：SmartSwitch推理框架。这个框架可以轻松地集成到任何大型语言模型中，作为即插即用的解决方案。它持续监控模型的推理过程，检测浅思维并向更有希望却被忽视的想法提供更深入的探索指导。特别的是，感知模块识别思路转换的点，并使用现成的过程奖励模型（PRM）评估前一思路的潜力。如果发现有高潜力的想法被过早放弃，干预模块打断正在进行的推理过程，回溯到切换之前的点，并插入一个“深化提示”，以鼓励对该有希望的路径进行更深入的探索。", "conclusion": "在具有挑战性的数学推理基准测试中进行了详尽的实验，证明了我们的方法显著提高了不同大小的大规模语言模型的性能。"}
{"llm_update_time": "20251023", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.19670", "html_url": "https://arxiv.org/abs/2510.19670", "title": "CoSense-LLM：基于成本和不确定性感知的云-边合作实现边缘端语义", "title_en": "CoSense-LLM: Semantics at the Edge with Cost- and Uncertainty-Aware Cloud-Edge Cooperation", "authors": "Hasan Akgul,Mari Eplik,Javier Rojas,Aina Binti Abdullah,Pieter van der Merwe", "background": "该研究提出了一个基于边缘计算的框架CoSense-LLM，旨在将连续的多模态传感器数据（例如Wi-Fi信导强度、惯性仪、音频、RFID和轻量级视侦数据）转化为紧凑且可验证的语义标记，并在受显式延迟、能耗、带宽和隐私约束的环境下与大型语言模型协作。背景在于，当前的智能设备和物联网环境需要处理大量的传感器数据，并且需要在保证语义性、隐私性和低延迟的同时，提升模型的高效性和准确性。", "innovation": "CoSense-LLM具有四个核心部分：1) SenseFusion，一个轻量级的编码器，用于对齐传感器嵌入并压缩为短的离散代码序列；2) Edge-RAG，一个本地混合检索层，结合现场特定的策略和注释；3) PromptRouter，一个成本和不确定性意识策略，选择边缘生成、边缘加检索或紧凑型云升级；4) Secure Execution，一种可审计的数据擦除路径，确保原始波形从未离开设备。此外，系统还与现代服务优化协同，如分页或流式缓存、闪存注意力内核、推测解码和量化的LoRA适配器，并支持设备端个性化和非IID偏差下的联邦更新。创新点在于通过优化精准和不确定性管理，实现了传感器数据的有效处理和语义化，同时兼顾成本和隐私保护，确保模型在复杂环境中的可靠性能。", "conclusion": "研究结果表明，CoSense-LLM能够同时满足具体的延迟要求，并在家庭、办公室和诊所环境中提供准确的解释，通过减少跨层语义和带宽成本，展现出对本地检索的偏好以及保留隐私的特性。实验证明，Edge-RAG能够改善事实的一致性并减少矛盾，校准的不确定性允许选择性放弃和控制式的升级，而KV加上解码加速器降低了每个决策的能耗。最终，研究证明了边缘优先设计在复杂环境中的可行性，视边界为大型模型部署的平权目标，将语义、隐私和可预测的延迟共同作为大型模型优化追求的首要目标。"}
{"llm_update_time": "20251023", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.19687", "html_url": "https://arxiv.org/abs/2510.19687", "title": "大语言模型是否对沟通背后的动机敏感？", "title_en": "Are Large Language Models Sensitive to the Motives Behind Communication?", "authors": "Addison J. Wu,Ryan Liu,Kerem Oktar,Theodore R. Sumers,Thomas L. Griffiths", "background": "人类交流具有动机驱动的特点：人们在交流、写作和创作内容时都怀有特定的沟通意图。因此，大型语言模型（LLMs）和AI代理处理的信息本质上都是由人类的意图和激励所引导的。人类有能力在这种微妙信息中导航：我们经常能够识别出善意或自私的动机以决定信任哪些陈述。因此，为了使LLMs在现实世界中有效运作，它们也需要通过考虑信息来源的动机来进行批判性评估，例如在销售推广中评估声明的可信度。", "innovation": "本研究通过使用认知科学中的受控实验来验证LLMs的行为是否与学习有动机的证言的理性模型一致，并发现它们以类似人类的方式成功地降低了偏见来源的信息权重。进一步将评估扩展到赞助的在线广告，更为自然地反映了LLMs代理的信息生态系统。研究发现LLMs的推断与理性模型的预测相差甚远——部分原因是额外信息分散了它们的警觉相关考虑。然而，简单的引导干预（提高意图和激励的显着性）大大增加了LLMs与理性模型之间的对应关系。结果表明，LLMs具有对他人动机的基本敏感性，但要将其推广到新的现实世界场景，这些模型仍需要进一步改进。", "conclusion": "本研究的结果表明，LLMs具有对他人动机的基本敏感性，但在新的现实世界环境中具有一般化的应用将会需要对这些模型进行进一步改进。"}
{"llm_update_time": "20251023", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.19806", "html_url": "https://arxiv.org/abs/2510.19806", "title": "制问的艺术：合成数据的多语言提示优化", "title_en": "The Art of Asking: Multilingual Prompt Optimization for Synthetic Data", "authors": "David Mora,Viraat Aryabumi,Wei-Yin Ko,Sara Hooker,Julia Kreutzer,Marzieh Fadaee", "background": "合成数据已成为大规模语言模型扩大的基石，但是其在多语言使用上仍受限于翻译提示。这种方法以英文为中心，忽视了文化维度，限制了模型的泛化能力。", "innovation": "介绍了一种轻量级的提示空间优化框架，通过系统地对翻译提示进行自然性、文化适应性和难度增强的变换，使多语言性能提升。通过一个现成的多语言LLM，对7大家族12种语言的提示应用这些变换，在相同的条件下，该方法在Global-MMLU准确率上提高了4.7%，在Flores XCometXL上提高了2.4%，并在mArenaHard上的偏好获胜次数提高了35.3%。", "conclusion": "提示空间优化是一种简单而强大的构建更稳健、文化根基深厚且具备全球能力的多语言LLM的范式。"}
{"llm_update_time": "20251023", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.19782", "html_url": "https://arxiv.org/abs/2510.19782", "title": "通过模型合并来适应代码混合任务的多语言模型", "title_en": "Adapting Multilingual Models to Code-Mixed Tasks via Model Merging", "authors": "Prashant Kodali,Vaishnavi Shivkumar,Swarang Joshi,Monojit Choudhary,Ponnurangam Kumaraguru,Manish Shrivastava", "background": "研究发现，对于代码混合自然语言处理任务，传统的适应策略存在局限性。为了克服这些问题，研究提出了一种实用的模型合并方法，该方法从一个多语言基础模型出发，通过持续预训练、合并检查点与基础模型以及下游任务微调三个步骤来定制代码混合任务模型。这种方法旨在提高多语言模型在不同代码混合语言对（如英语-印地语、英语-西班牙语）任务上的表现，并验证其效果。", "innovation": "创新点在于提出了一种新的模型适应方法——模型合并，并展示了这种方法在代码混合自然语言处理任务中的优势。具体来说，通过合并持续预训练后的检查点与基础模型，再对下游任务进行微调，发现相对于仅进行持续预训练或直接微调的方法，模型合并方法能够更好地利用未标记数据，从而提高模型在序列分类任务（如情感分析和仇恨言论检测）上的表现，并在不同语言对中具有更好的跨对迁移能力。", "conclusion": "研究表示，通过模型合并的方法可以有效地适应代码混合任务，并根据不同的数据情况提供了一些适应策略建议。模型合并方法比直接微调或仅进行持续预训练具有优势，特别在零样本/少样本提示方面，使用大型语言模型进行上下文学习具有局限性。此外，对于资源较少的语言对，代码混合知识成为一种更为可靠的适应基础。"}
{"llm_update_time": "20251023", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.19791", "html_url": "https://arxiv.org/abs/2510.19791", "title": "ToolDreamer: 将LLM推理注入工具检索器", "title_en": "ToolDreamer: Instilling LLM Reasoning Into Tool Retrievers", "authors": "Saptarshi Sengupta,Zhengyu Zhou,Jun Araki,Xingbo Wang,Bingqing Wang,Suhang Wang,Zhe Feng", "background": "随着大型语言模型（LLMs）中工具调用的流行，当面对大的工具集时，生成的标记往往超出LLM的上下文窗口限制，无法包含所有工具。为此，使用外部检索器来为LLM提供与查询最相关的工具。现有的检索模型是基于用户查询和工具描述（TD）之间的相似性来对工具进行排名。为此类法单一，因为用户的需求往往与TD语言不匹配。为了解决该问题，本文提出了ToolDreamer框架，该框架可以基于LLM生成的假设（合成）TD来检索工具，即LLM认为可能对查询有用的工具描述，从而在语言空间内使查询和工具之间的匹配更加自然。ToolDreamer在ToolRet数据集上进行应用，显示了其对稀疏和密集检索器的改进效果，无论是否经过训练，都提升了检索性能，展现了其灵活性。通过提供的框架，目标是将部分推理负担转移到检索器上，从而使LLM能够有效处理大量工具而不占据其上下文窗口容量。", "innovation": "提出了ToolDreamer框架，该框架基于LLM生成的假设TD（工具描述）来检索具有潜在相关性的工具，解决了现有检索方法中导致的检索不足的问题，即用户查询和工具描述之间的不匹配问题。通过这种方法，检索过程更能自然地适应语言空间中的查询-工具匹配，从而提高了检索效率和准确性。", "conclusion": "通过ToolDreamer框架，将部分推理负担转移到检索器上，使得LLM能够有效处理大量工具而不占用其上下文窗口容量，从而提高了检索性能。"}
{"llm_update_time": "20251023", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.19811", "html_url": "https://arxiv.org/abs/2510.19811", "title": "Hubble：推进LLM记忆研究的模型套件", "title_en": "Hubble: a Model Suite to Advance the Study of LLM Memorization", "authors": "Johnny Tian-Zheng Wei,Ameya Godbole,Mohammad Aflah Khan,Ryan Wang,Xiaoyuan Zhu,James Flemings,Nitya Kashyap,Krishna P. Gummadi,Willie Neiswanger,Robin Jia", "background": "研究大型语言模型（LLMs）的记忆能力具有重要意义，但之前缺乏系统性的科学方法来研究这一问题。本文介绍了一个名为Hubble的开放源代码大型语言模型套件，旨在填补这一空白。", "innovation": "Hubble模型包括标准和受扰动两种变体：标准模型基于大规模英语文本进行预训练，而受扰动模型则在同样的训练过程中插入了受控制的文本（例如书籍段落、传记和测试集），以模拟关键的记忆风险。通过Hubble模型，作者发现记忆风险的大小受敏感数据在训练语料库中的频率及其规模的影响。此外，还展示了受扰动模型在不同预训练阶段插入文本，表明如果敏感数据不在训练中持续暴露，那么它可以被遗忘。这些发现为解决记忆风险提供了两种最佳实践：通过增加训练语料库的规模来稀释敏感数据，以及使敏感数据在训练过程中处于早期位置。", "conclusion": "Hubble不仅为广泛的模型记忆研究提供了丰富的资源，还展示了对其内置随机插入进行研究是测试成员推理和机器遗忘的理想环境。未来的研究可以利用Hubble进行进一步的探索、基准测试和构建扩展。"}
{"llm_update_time": "20251023", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.18880", "html_url": "https://arxiv.org/abs/2510.18880", "title": "更好的健康对话：寻求上下文的价值", "title_en": "Towards Better Health Conversations: The Benefits of Context-seeking", "authors": "Rory Sayres,Yuexing Hao,Abbi Ward,Amy Wang,Beverly Freeman,Serena Zhan,Diego Ardila,Jimmy Li,I-Ching Lee,Anna Iurchenko,Siyi Kou,Kartikeya Badola,Jimmy Hu,Bhawesh Kumar,Keith Johnson,Supriya Vijay,Justin Krogue,Avinatan Hassidim,Yossi Matias,Dale R. Webster,Sunny Virmani,Yun Liu,Quang Duong,Mike Schaekermann", "background": "在现代信息环境下，人们回答健康问题时可能会遇到困难。大型语言模型（LLMs）具有提供个性化、易获取信息的潜力，但也可能带来不准确、偏见或误导的风险。作者通过四项混合方法研究（总共163位参与者），探讨了人们如何利用LLMs来解答自己的健康问题，揭示了对话AI中的上下文寻求（即AI主动请求具体背景信息）的重要性，并基于此衍生出一种“导航AI”，以在对话中主动寻求需要的上下文信息。", "innovation": "作者开发了一种“导航AI”，这是一种能主动寻求相关上下文信息的对话AI。这种AI在一项随机、双盲的研究中得到了积极的评价，参与者认为它比基准AI更有帮助、更相关且更能针对其关注点进行回应。这一研究成果强调了主动寻求上下文对对话动态的强大影响，并为改进对话AI以帮助人们更有效地处理健康话题提供了设计模式。", "conclusion": "研究结果表明，主动寻求上下文显著影响了对话动态，并为未来设计对话AI帮助人们更好地讨论健康话题提供了指导。"}
{"llm_update_time": "20251023", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.19807", "html_url": "https://arxiv.org/abs/2510.19807", "title": "Scaf-GRPO: 支架式组相对策略优化以增强LLM推理", "title_en": "Scaf-GRPO: Scaffolded Group Relative Policy Optimization for Enhancing LLM Reasoning", "authors": "Xichen Zhang,Sitong Wu,Yinghao Zhu,Haoru Tan,Shaozuo Yu,Ziyi He,Jiaya Jia", "background": "强化学习中的可验证奖励已被证明是增强大型语言模型（LLMs）复杂推理能力的一种有力技术。然而，这些方法受到所谓的“学习悬崖”现象的限制：当面对超出当前能力的问题时，模型会一致地失败，导致持续的零奖励信号。在诸如GRPO的策略优化算法中，这将优势计算归零，使这些难以解决的问题在学习梯度中变得不可见，从而阻碍进展。", "innovation": "我们提出了Scaf-GRPO（支架式组相对策略优化），这是一种渐进式训练框架，仅在模型独立学习停滞时提供最小指导。该框架首先诊断学习停滞，然后通过注入分级的提示（从抽象概念到具体步骤）干预，使模型能够自行构建有效解决方案。广泛的实验表明，Scaf-GRPO在应对具有挑战性的数学基准问题时表现出色，将Qwen2.5-Math-7B模型在AIME24基准上的pass@1得分相对于标准的GRPO基线提高了44.3%。这表明该框架提供了一种可靠且有效的方法来解锁模型解决超出其能力范围的问题的能力，这一步对于扩展自主推理的边界至关重要。", "conclusion": "Scaf-GRPO为解锁大型语言模型解决先前超出其能力范围的问题的能力提供了一种稳健且有效的方法，对于推进自主推理的边界具有重要意义。"}
{"llm_update_time": "20251023", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.18921", "html_url": "https://arxiv.org/abs/2510.18921", "title": "使用MLX在Apple Silicon上进行设备上机器学习基准测试", "title_en": "Benchmarking On-Device Machine Learning on Apple Silicon with MLX", "authors": "Oluwaseun A. Ajayi,Ogundepo Odunayo", "background": "近年来，大型语言模型（LLMs）和机器学习在各种设备上的广泛应用引发了研究兴趣，特别是如何在笔记本电脑和智能手机等小型设备上部署这些模型。这促使研究者探索如何利用设备上的硬件进行机器学习。MLX框架应运而生，它是一个针对Apple硅芯片设备优化的机器学习框架，旨在简化研究、实验和原型设计。论文对MLX进行了性能评估，重点是Transformer模型的推理延迟，并将其与Pytorch的实现版本进行了比较。研究使用了MLX-Transformers框架，包括多种Transformer实现，并下载了Pytorch的模型检查点并转换为MLX格式，从而在不需转换检查点的情况下直接执行源自主Hugging Face的Transformer模型。", "innovation": "MLX框架利用了Apple硅芯片的高级架构和功能，使得直接从Hugging Face获取的Transformer模型无缝执行，无需在框架之间移植模型时进行检查点转换。研究还使用了两种Apple Silicon MacBook设备对比英伟达CUDA GPU，在相同的参数大小和检查点模型下评估了BERT、RoBERTa和XLM-RoBERTa等模型的推理延迟。这为MLX在Apple生态系统中的潜在效率和易用性提供了更深入的理解。", "conclusion": "研究结果突显了MLX在Apple生态系统中推动设备上高效且更易访问的机器学习应用的潜力。未来的工作计划扩展到包含不同模态的模型评估，提供MLX功能的全面评估。"}
{"llm_update_time": "20251023", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.19779", "html_url": "https://arxiv.org/abs/2510.19779", "title": "AdaSPEC: 选择性知识蒸馏以提高推测性解码器的效率", "title_en": "AdaSPEC: Selective Knowledge Distillation for Efficient Speculative Decoders", "authors": "Yuezhou Hu,Jiaxin Guo,Xinyu Feng,Tuo Zhao", "background": "Speculative Decoding (SD) 通过使用小模型生成预测，然后由大模型验证，加速了大型语言模型的推理过程。然而，传统的知识蒸馏（KD）方法旨在最小化小模型和大模型间的所有标记的KL散度，这与SD的目标——最大化标记接受率——不一致。因此，小模型常常因容量限制而难以充分吸收目标模型的知识，导致其性能不足。", "innovation": "提出了一种名为AdaSPEC的新方法，该方法在KD过程中引入了选择性标记过滤。AdaSPEC利用参考模型识别和过滤难以匹配的标记，从而允许小模型更好地与目标模型对齐于简单的标记，有效提高了总体标记接受率，同时没有牺牲生成质量。研究结果表明，AdaSPEC在多种任务（算术推理、指令遵循、编程和摘要）上均显著优于最先进的方法DistillSpec，接受率提高了15%。", "conclusion": "AdaSPEC在不同任务中表现出色，通过选择性标记过滤改进了知识蒸馏过程，提高了小模型与大模型的对齐效果，同时保持了生成质量，实现了更高的标记接受率。"}
{"llm_update_time": "20251023", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.18927", "html_url": "https://arxiv.org/abs/2510.18927", "title": "BAPO: 通过平衡策略优化与自适应剪切稳定LLMs的离策RL", "title_en": "BAPO: Stabilizing Off-Policy Reinforcement Learning for LLMs via Balanced Policy Optimization with Adaptive Clipping", "authors": "Zhiheng Xi,Xin Guo,Yang Nan,Enyu Zhou,Junrui Shen,Wenxiang Chen,Jiaqi Liu,Jixuan Huang,Zhihao Zhang,Honglin Guo,Xun Deng,Zhikai Lei,Miao Zheng,Guoteng Wang,Shuo Zhang,Peng Sun,Rui Zheng,Hang Yan,Tao Gui,Qi Zhang,Xuanjing Huang", "background": "强化学习（RL）已成为大型语言模型（LLMs）调整与强化的核心范式。然而，在离策设置中应用RL（使用过去策略的数据进行训练）可以提高样本效率，但依然具有挑战性。例如，策略熵会急剧下降，优化常常不稳定甚至崩溃。", "innovation": "通过理论和实证分析，作者识别出两种关键见解：（i）优化中的一种失衡，其中负面优势样本主导策略梯度，抑制有用行为并导致梯度爆炸的风险；（ii）引伸出的熵剪切规则，揭示固定剪切机制系统性地阻止熵增加的更新，从而使策略过度开发而牺牲探索。基于这些见解，作者提出了BAlanced Policy Optimization with Adaptive Clipping（BAPO），一种能够动态调整剪切界限以适当前后重新平衡正面和负面贡献、保存熵并稳定RL优化的简单而有效的方法。在各种离策场景（包括样本重放和部分回放）中，BAPO实现快速、稳定和数据高效训练。", "conclusion": "在AIME 2024和AIME 2025基准测试中，我们7B的BAPO模型超越了开源对应的模型如SkyWork-OR1-7B，而我们的32B BAPO模型不仅在同等规模模型中达到最先进的结果，还超越了领先的专有系统如o3-mini和Gemini-2.5-Flash-Thinking。"}
{"llm_update_time": "20251023", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.18938", "html_url": "https://arxiv.org/abs/2510.18938", "title": "StutterZero和StutterFormer：端到端的口语音素转换以实现口吃转录和纠正", "title_en": "StutterZero and StutterFormer: End-to-End Speech Conversion for Stuttering Transcription and Correction", "authors": "Qianheng Xu", "background": "全球有超过7000万人经历口吃，现有的自动语音系统在处理不流畅的话语时普遍存在误读现象或无法准确转录。目前，大多数口吃修正方法依赖于手工特征提取或多阶段自动语音识别（ASR）和文本到语音（TTS）管道，这会导致转录和音频重建分离，并且容易放大失真。", "innovation": "本文引入了StutterZero和StutterFormer，这两种端到端的波形到波形模型直接将口吃语音转换为流利语音，同时预测其转录。StutterZero采用了卷积双向LSTM编码解码器结合注意机制，而StutterFormer则结合了具有共享声学-语言表示的双流Transformer。这两种模型均基于从SEP-28K和LibriStutter语料库合成的口吃-流利配对数据进行训练，并在未见过的演讲者测试集FluencyBank上进行评估。结果表明，StutterZero在词错误率（WER）上降低了24%，在BERT分数上的语义相似度提高了31%；而StutterFormer的词错误率降低了28%，BERT分数上的语义相似度提高了34%。这些结果证明了直接端到端口吃转流利语音转换的可行性，为包容性的人机交互、言语治疗和面向无障碍的人工智能系统提供了新的机会。", "conclusion": "这两种端到端模型证明了直接将口吃语音转换为流利语音的可行性，并且在多方面优于现有的领先模型。这些创新为无障碍技术领域开启了新的可能性。"}
{"llm_update_time": "20251023", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.19060", "html_url": "https://arxiv.org/abs/2510.19060", "title": "采用场景图引导LLMs作为裁判进行详细图像描述的PoSh", "title_en": "PoSh: Using Scene Graphs To Guide LLMs-as-a-Judge For Detailed Image Descriptions", "authors": "Amith Ananthram,Elias Stengel-Eskin,Lorena A. Bradford,Julia Demarest,Adam Purvis,Keith Krut,Robert Stein,Rina Elster Pantalony,Mohit Bansal,Kathleen McKeown", "background": "视觉语言模型（VLMs）在详细图像描述上取得了进展，但评价仍然是一个挑战。标准指标（如CIDEr、SPICE）是为短文本设计的，且调整为识别现在常见的错误，例如物体识别错误。对于长文本，需要敏感度更高的指标，可以精确地定位错误，并指出具体的文本片段。", "innovation": "提出了一种新的度量标准PoSh，该标准使用场景图作为结构化的标准来引导LLMs作为裁判，从而产生基于细粒度错误的综合得分（例如在组合理解中的错误）。PoSh在复制性、可解释性方面优于现有指标，甚至包括GPT4o作为裁判。还引入了一个新的具有挑战性的数据集DOCENT，对详细图像描述指标和详细的图像描述本身进行评估。", "conclusion": "PoSh在DOCENT的人类判断上表现出更强的相关性（Spearman ρ提高0.05），在不同类型图像上表现稳定，并且是优秀的奖励函数，优于标准的监督微调。利用PoSh评估开放和封闭模型在DOCENT中的表现，发现基础模型在描绘具有丰富场景动态的图像方面有困难，这为检验VLM的进步设定了一个更具挑战性的任务。"}
{"llm_update_time": "20251023", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.19139", "html_url": "https://arxiv.org/abs/2510.19139", "title": "大型语言模型在CONSORT检查表上的提示方法多维度认知能力评估", "title_en": "A Multi-faceted Analysis of Cognitive Abilities: Evaluating Prompt Methods with Large Language Models on the CONSORT Checklist", "authors": "Sohyeon Jeon,Hyung-Chul Lee", "background": "尽管大型语言模型（LLMs）在医疗保健领域的应用迅速扩展，但这些系统能否根据CONSORT标准评估临床试验报告的情况仍不明确，尤其是在其认知和推理策略方面。这项研究运用了具有专家验证数据的行为和元认知分析方法，系统性地比较了两种代表性LLM在三种提示条件下的表现。", "innovation": "采用行为和元认知分析方法，结合专家验证数据，系统性地对比了两种主流LLM在CONSORT标准提示条件下的差异，揭示了模型在面对不同CONSORT项目时的认知和推理方式的不同，以及提示类型如何影响推理风格和不确定性表达等。", "conclusion": "研究结果揭示了这些系统在临床合规自动化方面的当前局限性，并强调了理解其认知适应和策略行为的重要性，以开发更可信和可靠的医疗AI系统。"}
{"llm_update_time": "20251023", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.18940", "html_url": "https://arxiv.org/abs/2510.18940", "title": "NeuroAda: 激活每个神经元的潜力以实现参数高效微调", "title_en": "NeuroAda: Activating Each Neuron's Potential for Parameter-Efficient Fine-Tuning", "authors": "Zhi Zhang,Yixian Shen,Congfeng Cao,Ekaterina Shutova", "background": "现有的参数高效微调（PEFT）方法主要分为两大类：添加基方法和选择性原位适应。前者，如LoRA，通过引入额外模块适应模型以执行下游任务，提供良好的内存效率，但其表示能力通常有限，不适合细粒度适应。相比之下，后者直接对原始模型参数中精心选择的子集进行微调，允许更为精确和有效的适应，但代价是显着增加内存消耗。为解决这种权衡，我们提出了一种新颖的PEFT方法，称为NeuroAda，它能够在保持高内存效率的同时实现细粒度模型微调。NeuroAda首先像选择性适应方法一样识别重要参数（即网络内的连接），然后为这些选定的参数引入旁路连接。在微调过程中，仅更新旁路连接，而原始模型参数保持不变。在涵盖自然语言生成和理解在内的23+任务上的实验结果显示，NeuroAda仅使用至多$\textbf{0.02}\text{％}$的可训练参数即可达到最先进的性能，同时减少CUDA内存使用量高达60％。我们已在此处提供代码：this https URL.", "innovation": "我们提出了NeuroAda，这是一种新的PEFT方法，能够在保持高内存效率的同时实现细粒度模型微调。NeuroAda通过为重要参数引入旁路连接，允许在微调过程仅更新旁路连接，而保留原始模型参数不变。该方法显著减少了所需的可训练参数数量和内存使用量，从而实现了高性能的微调。", "conclusion": "实验结果表明，NeuroAda仅使用至多$\textbf{0.02}\text{％}$的可训练参数即可达到最先进的性能，同时减少CUDA内存使用量高达60％。NeuroAda为参数高效微调提供了一种新的范式，既保持了高内存效率，又支持细粒度适应。"}
{"llm_update_time": "20251023", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.19169", "html_url": "https://arxiv.org/abs/2510.19169", "title": "OpenGuardrails: 开源上下文感知AI防护平台", "title_en": "OpenGuardrails: An Open-Source Context-Aware AI Guardrails Platform", "authors": "Thomas Wang,Haowen Li", "background": "随着大型语言模型（LLMs）在现实世界应用中的集成程度越来越高，确保它们的安全性、防止恶意行为或侵犯隐私的内容变得尤为重要。为此，需要一种能够全面保护模型的解决方案，以防止内容安全风险、模型操纵攻击（如提示注入、破解、代码解释器滥用以及恶意代码的生成/执行）和数据泄露等问题。", "innovation": "OpenGuardrails 是首个结合上下文感知的内容安全与模型操纵检测模型及部署平台上层架构的开源项目。它通过一个统一的大模型实现内容安全和模型操纵检测，通过轻量级NER管道（例如Preidio风格的模型或正则表达式检测器）实现数据泄露识别和脱敏。此外，该系统可以作为安全网关或基于API的服务进行部署，提供企业级的完全私有部署选项，并在安全性基准上取得了当前最先进（SOTA）的性能表现，包括针对多种语言的任务（英语、中文及多语言）的提示和响应分类准确率。", "conclusion": "所有模型均采用Apache 2.0许可证公开发布，供公众使用。OpenGuardrails 提供了一种有效的方法来保护大型语言模型免受潜在的安全威胁，并为实际应用中的模型安全防护提供了强有力的解决方案。"}
{"llm_update_time": "20251023", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.19338", "html_url": "https://arxiv.org/abs/2510.19338", "title": "每个注意力都重要：一种高效的长上下文推理混合架构", "title_en": "Every Attention Matters: An Efficient Hybrid Architecture for Long-Context Reasoning", "authors": "Ling Team,Bin Han,Caizhi Tang,Chen Liang,Donghao Zhang,Fan Yuan,Feng Zhu,Jie Gao,Jingyu Hu,Longfei Li,Meng Li,Mingyang Zhang,Peijie Jiang,Peng Jiao,Qian Zhao,Qingyuan Yang,Wenbo Shen,Xinxing Yang,Yalin Zhang,Yankun Ren,Yao Zhao,Yibo Cao,Yixuan Sun,Yue Zhang,Yuchen Fang,Zibin Lin,Zixuan Cheng,Jun Zhou", "background": "本文的技术报告介绍了Ring-linear模型系列，包括Ring-mini-linear-2.0和Ring-flash-linear-2.0。这两款模型在长上下文推理场景下有效整合了线性注意力和softmax注意力，显著减少了I/O和计算开销。相较于一个320亿参数的密集模型，这种系列模型将推理成本降低了10倍；与原始的Ring系列相比，成本也减少了50%以上。", "innovation": "1. 发展了一种混合架构，有效结合了线性注意力和softmax注意力，减少了长上下文推理场景下的I/O和计算开销。2. 通过系统性探索混合架构中不同注意力机制的比例，确定了当前最优模型结构。3. 利用自主研发的高性能FP8操作库linghe，整体训练效率提高了50%。4. 基于训练和推理引擎操作的良好对齐性，模型在强化学习阶段能够进行长期、稳定和高效的优化，并且在多个复杂推理基准测试中保持了SOTA性能。", "conclusion": "通过This系列模型的提出和优化，本文展示了在长上下文推理场景下如何通过混合注意力机制和技术性能优化，达到了显著的成本降低和效率提升。"}
{"llm_update_time": "20251023", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.19203", "html_url": "https://arxiv.org/abs/2510.19203", "title": "为股票回报预测对齐多语言新闻", "title_en": "Aligning Multilingual News for Stock Return Prediction", "authors": "Yuntao Wu,Lynn Tao,Ing-Haw Cheng,Charles Martineau,Yoshio Nozawa,John Hull,Andreas Veneris", "background": "新闻在语言和地区间迅速传播，但翻译可能会丢失一些细微的语义微妙之处。为了克服这一问题，本文提出了一种使用最优输运的方法来对齐多语言新闻文章中的句子，从而识别出不同语言中语义相似的内容。这种方法被应用于对齐2012年至2024年间超过14万对彭博社英文和日文东京证券交易所股票新闻文章，涉及大约3500只股票。", "innovation": "提出的使用最优输运方法的句子对齐方法，能够有效地识别和对齐不同语言文件中的语义相似内容，增强了语义相似性，使得对齐后的句子更加稀疏、可解释性强。通过对这些对齐句子生成的返回得分比分析完整文本样本建立的得分更能够与股票回报相关联，基于这些对齐取样的长短期交易策略还能够实现更高的夏普比率。", "conclusion": "该方法提高了对齐多语言新闻的效果，优化了句子间的语义相似度，并且基于对齐文本的交易策略表现更好。"}
{"llm_update_time": "20251023", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.19386", "html_url": "https://arxiv.org/abs/2510.19386", "title": "ColorAgent: 构建一个稳健、个性化和互动的操作系统代理", "title_en": "ColorAgent: Building A Robust, Personalized, and Interactive OS Agent", "authors": "Ning Li,Qiqiang Lin,Zheng Wu,Xiaoyun Mo,Weiming Zhang,Yin Zhao,Xiangmou Qu,Jiamu Zhou,Jun Wang,Congmin Zheng,Yuanyi Song,Hongjiang Chen,Heyuan Huang,Jihong Wang,Jiaxin Yin,Jingwei Yu,Junwei Liao,Qiuying Peng,Xingyu Lou,Jun Wang,Weiwen Liu,Zhuosheng Zhang,Weinan Zhang", "background": "随着硬件、软件和大规模语言模型技术的进步，人类与操作系统的交互方式已从命令行界面发展到迅速兴起的AI代理交互。构建能够执行用户指令并忠实地遵循用户意愿的操作系统(OS)代理正在成为现实。本文介绍了一个OS代理——ColorAgent，旨在与环境进行长期、稳健的交互，并支持个性化和主动的用户体验。", "innovation": "通过逐步强化学习和自我进化训练增强模型的能力，同时开发了一种定制化的多代理框架，确保了泛化、一致性和鲁棒性。在用户交互方面，探索了个性化用户意图识别和主动参与，定位OS代理不仅仅是自动化工具，更是一个温暖的、合作的伙伴。在AndroidWorld和AndroidLab基准测试中，ColorAgent分别实现了77.2%和50.7%的成功率，建立了新的前沿。然而，当前基准对于OS代理的全面评价是不够的，提出了未来工作中的评价范式、代理合作和安全等方向的进一步探索。", "conclusion": "我们在AndroidWorld和AndroidLab基准测试中对ColorAgent进行了评估，取得了新的最先进的成功率。尽管如此，我们仍指出现有基准的不足，并且提出了未来在评价范式、代理协作和安全性等方面进一步探索的建议。"}
{"llm_update_time": "20251023", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.19422", "html_url": "https://arxiv.org/abs/2510.19422", "title": "使用大规模语言模型信念进行语言模型去学习", "title_en": "LLM Unlearning with LLM Beliefs", "authors": "Kemou Li,Qizhou Wang,Yue Wang,Fengpeng Li,Jun Liu,Bo Han,Jiantao Zhou", "background": "大规模语言模型在训练过程中可能会记住敏感或有害的内容，这些内容可能会在模型的输出中重新出现。当前的去学习方法主要依赖于梯度上升及其变体来降低特定目标响应的概率。然而，这种方法会导致一个重要的副作用：概率质量重新分配到高可能性区域，通常对应于目标的语义相关重述。这种现象被称为挤压效应，解释了为何许多方法只达到虚假的去学习效果，而自动化指标（如ROUGE、真实度比）常常歪曲了实际的成功情况。", "innovation": "本文提出了一种基于大规模语言模型信念的自举（BS）框架，该框架通过将挤压效应与模型自身高置信度生成直接关联，来解决当前方法的虚假去学习问题。BS-T（标记）通过抑制高概率标记，而BS-S（序列）则移除整个高置信度生成，从而实现更彻底的遗忘，同时保留所需的实用性。实验结果在不同基准和多种模型家族中证实了该方法的有效性。", "conclusion": "BS框架通过利用模型自身的高置信度生成来直接对抗挤压效应，有效地实现了更彻底的遗忘，同时保持模型的实用性。该方法在多种模型家族和不同基准上的广泛实验验证了其有效性。"}
{"llm_update_time": "20251023", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.19176", "html_url": "https://arxiv.org/abs/2510.19176", "title": "零步思考：一种关于模式选择作为更难的早期退出的实证研究", "title_en": "The Zero-Step Thinking: An Empirical Study of Mode Selection as Harder Early Exit in Reasoning Models", "authors": "Yuqiao Tan,Shizhu He,Kang Liu,Jun Zhao", "background": "推理模型在数学和逻辑推理等任务上表现出色，主要是因为它们能够在推理过程中进行逐步思考。然而，这往往会导致过度思考，增加不必要的计算开销。为解决这一问题，提出了一种模式选择方法，旨在通过思考或不思考模式自动决定使用长思路（Long-CoT)或短思路（Short-CoT）；同时，早期退出技术确定推理过程中的最优停止点。这两种方法都旨在降低计算负担。研究者首先将模式选择视为早期退出问题的更复杂版本，尽管它们有相似的目标，但决策发生的时间不同。早期退出集中在确定最合适的停止点以进行简洁推理，而模式选择则在推理过程开始时做出决定，依赖预定义的假想思考，称为零步思考。实验研究表明，基于提示的方法由于分类能力有限而常常失败，利用内部信息的方法虽然在大多数情况下表现较好，但仍存在稳定性问题。现有方法在信息有限的情况下不足以有效解决模式选择任务，突显了这一任务的持续挑战。", "innovation": "提出了模式选择作为早期退出技术的更复杂版本，将任务决策提前到推理过程开始前；综合考虑了零步思考的概念，并通过实验证明了基于提示的方法在信息有限时的局限性，表明现有的方法在处理模式选择任务时仍有改进空间。", "conclusion": "当前的方法依赖模型提供的信息不足以有效解决模式选择任务，尤其是在信息有限的情况下。这突出表明，对于模式选择问题，仍需进一步的研究和创新以提高其表现的稳定性和有效性。我们提供的代码可以在该链接找到。"}
{"llm_update_time": "20251023", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.19600", "html_url": "https://arxiv.org/abs/2510.19600", "title": "亚一钞的人机协作论文到网页制作，在0.1美元以内", "title_en": "Human-Agent Collaborative Paper-to-Page Crafting for Under $0.1", "authors": "Qianli Ma,Siyu Wang,Yilin Chen,Yinhao Tang,Yixiang Yang,Chang Guo,Bingjie Gao,Zhening Xing,Yanan Sun,Zhipeng Zhang", "background": "科学研究的进步离不开研究成果的传播，但研究者常常被构建项目网页的重复工作所困扰，这使得研究成果难以轻易访问。尽管自动化技术已经解决了静态幻灯片和海报的问题，网页的动态和交互特性仍然未得到解决。因此，本文提出从高到低的协作分级过程来解决这一问题。", "innovation": "本文引入了AutoPage，这是一个新颖的多智能体系统，它将论文到网页的创建过程分解为从叙述规划到多模态内容生成再到交互渲染的分层次流水线。此外，还设计了一个专门的“检查器”智能体来防止AI的幻觉，并使用人工检查点确保最终产品的完美一致性。为了严格验证方法的有效性，还构建了一个新的基准PageBench。", "conclusion": "实验表明，AutoPage 不仅能够生成高质量，具有视觉吸引力的网页，而且能够在15分钟内完成，并且成本低于0.1美元，这展示了该方法在高效性和成本节省方面的显著优势。未来将继续公开代码和数据集，以便进一步研究和发展。"}
{"llm_update_time": "20251023", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.19555", "html_url": "https://arxiv.org/abs/2510.19555", "title": "[重构] 视觉-语言模型在计数任务中的推理", "title_en": "[De|Re]constructing VLMs' Reasoning in Counting", "authors": "Simone Alghisi,Gabriel Roccabruna,Massimo Rizzoli,Seyed Mahed Mousavi,Giuseppe Riccardi", "background": "视觉-语言模型（VLMs）因其在多个下游任务中的竞争性性能而受到关注，这些性能是通过遵循用户输入的指令实现的。然而，VLMs 在视觉推理方面仍然存在一些限制，包括识别关系（例如空间关系、时间关系以及物体之间的关系）、理解时间序列（例如帧）和计数物体等方面的困难。因此，本文通过深入研究 VLMs 的推理失败原因，提出了一种针对性方法来提高它们的推理能力。实验结果表明，在控制实验条件下对七种最新 VLMs 的计数任务进行研究，VLMs 对于物体的数量和类型、空间排列以及干扰物的共同出现高度敏感。进一步的层次分析揭示，错误主要是由于最后一层表示的不正确映射到输出空间导致的。研究结果实现了一种仅微调输出层的针对性训练方法，其准确率提高了最高 21%。同时，通过在真实世界数据集上实现一致改进验证了这些发现。", "innovation": "本文通过深入分析视觉-语言模型（VLMs）的视觉推理能力，并提出了一种针对计数任务的微调方法，增强了VLMs在处理视觉信息和执行复杂推理任务时的能力。此外，研究表明，通过仅仅优化输出层即可以显著提高模型的准确性，这是一项重要的技术创新。", "conclusion": "通过该研究，发现当前视觉-语言模型在处理复杂的视觉推理任务时存在准确性低的问题，尤其是在物体计数和复杂历史情境理解中的表现欠佳。我们提出并验证了一种有效的策略，微调仅输出层能够显著提高模型在计数任务上的准确率，验证了该方法的有效性，并为未来改进VLMs的视觉推理能力和开发更强大的模型提供了新的思路。"}
{"llm_update_time": "20251023", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.19654", "html_url": "https://arxiv.org/abs/2510.19654", "title": "从预测到规划：用于协作状态-行动预测的策略世界模型", "title_en": "From Forecasting to Planning: Policy World Model for Collaborative State-Action Prediction", "authors": "Zhida Zhao,Talas Fu,Yifan Wang,Lijun Wang,Huchuan Lu", "background": "尽管在构建世界模型方面取得了显著进步，但这些世界模型在自主系统中的潜力依然未被充分利用。现有的世界模型主要用于世界模拟，与路径规划相分离。虽然近年来的研究努力试图在一个统一框架内结合世界建模和规划，但世界建模对规划的协同促进机制仍有待进一步探索。", "innovation": "本文提出了一种新的驾驶范式——策略世界模型（PWM），它不仅在统一架构中集成了世界建模和轨迹规划，还通过提出的无动作未来状态预测方案利用学习到的世界知识来改善规划。为了提高视频预测效率，引入了一种动态增强的并行token生成机制，配备了上下文指导的tokenizer和自适应动态焦点损失。尽管仅使用前视摄像头输入，该方法在性能上仍达到或超过了依赖多视角和多模态输入的最新方法。", "conclusion": "该研究通过策略世界模型在统一的架构中结合了世界建模和路径规划，并通过无动作未来状态预测方案改善了规划。该方法通过协作状态-行动预测模仿了人类的前瞻性感知，从而提供更可靠的规划性能。此外，通过动态增强的并行token生成机制，提高了视频预测的效率。尽管仅使用前视摄像头输入，该方法在性能上仍达到或超过了依赖多视角和多模态输入的最新方法。源代码和模型权重已被发布。"}
{"llm_update_time": "20251023", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.19631", "html_url": "https://arxiv.org/abs/2510.19631", "title": "HSCodeComp: 电子商务领域层次化规则应用的现实和专家级基准", "title_en": "HSCodeComp: A Realistic and Expert-level Benchmark for Deep Search Agents in Hierarchical Rule Application", "authors": "Yiqian Yang,Tian Lan,Qianghuai Jia,Li Zhu,Hui Jiang,Hang Zhu,Longyue Wang,Weihua Luo,Kaifu Zhang", "background": "有效的深度搜索代理不仅需要访问开放领域和特定领域的知识，还需要应用复杂的规则，例如法律条款、医疗手册和关税规则。这些规则往往具有模糊的边界和隐含的逻辑关系，这对代理精确应用构成挑战。然而，这一点目前在代理基准测试中被很大程度忽视。为了填补这一空白，我们引入了HSCodeComp，这是一个现实且专家级的电子商务基准，用于评估深度搜索代理在层次化规则应用方面的性能。在这个任务中，代理的深度推理过程由这些规则引导，以预测具有噪声但现实描述的产品的10位协调制度代码（HSCode）。这些代码由世界海关组织建立，对于全球供应链效率至关重要。HSCodeComp是从大规模电子商务平台收集的真实数据构建的，包含632个跨越多个产品类别的产品条目，并由几位人类专家进行标注。", "innovation": "HSCodeComp首次针对深度搜索代理在层次化规则应用方面的性能设立了现实且专家级的基准。它基于实际数据，涵盖了多个产品类别，并由多位专家进行HSCode标注。实验结果展示了当前最先进模型与人类专家之间的巨大性能差距，包括最佳代理仅达到46.8%的10位准确性，远低于人类专家的95.0%。详细分析还指出了层次化规则应用的挑战，并表明测试时的扩展无法进一步提高性能。", "conclusion": "HSCodeComp揭示了深度搜索代理在处理复杂层次规则应用时的巨大挑战，并展示了现有模型与人类专家之间的显著性能差距。这强调了在电子商务中评估和改进这些代理性能的重要性和必要性。"}
{"llm_update_time": "20251023", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.19778", "html_url": "https://arxiv.org/abs/2510.19778", "title": "GaLLoP: 基于梯度的低幅度参数稀疏学习", "title_en": "GaLLoP: Gradient-based Sparse Learning on Low-Magnitude Parameters", "authors": "Anand Choudhary,Yasser Sulaıman,Lukas Mauch,Ghouthi Boukli Hacene,Fabien Cardinaux,Antoine Bosselut", "background": "稀疏微调技术通过只调整模型参数子集来适应下游任务，但稀疏适应的有效性取决于如何选择要微调的模型参数。现有技术如 LoRA、DoRA 和 SAFT 已经展示了其有效性，但这些方法依赖于正确选择要微调的参数。本文致力于提出一种新的稀疏微调方法 GaLLoP，通过只调整下游任务中梯度幅度最大且预训练幅度最小的参数，旨在优先选择高度任务相关的参数，同时最小化对预训练知识的干扰。", "innovation": "提出了一种新的基于梯度的稀疏学习技术 GaLLoP，它在 LLaMA3 8B 和 Gemma 2B 等基模型上进行实验，结果表明 GaLLoP 在内部和外部任务上的表现优于其他参数高效的微调技术，如 LoRA、DoRA 和 SAFT。此外，还证明了 GaLLoP 能有效缓解灾难性遗忘和记忆任务数据的问题，保持了与其他微调技术相比的性能稳定性，具有较强的跨随机种子的泛化能力。", "conclusion": "实验结果表明 GaLLoP 在所有任务上都能持续提高或与现有的其他参数高效的微调技术相媲美，同时有效缓解了灾难性遗忘和记忆问题，稳定了性能，具有较强的跨随机种子的泛化能力。"}
{"llm_update_time": "20251023", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2402.05136", "html_url": "https://arxiv.org/abs/2402.05136", "title": "LV-Eval: 一个包含5个长度级别最多可达256K的平衡长上下文基准", "title_en": "LV-Eval: A Balanced Long-Context Benchmark with 5 Length Levels Up to 256K", "authors": "Tao Yuan,Xuefei Ning,Dong Zhou,Zhijie Yang,Shiyao Li,Minghui Zhuang,Zheyue Tan,Zhuyu Yao,Dahua Lin,Boxun Li,Guohao Dai,Shengen Yan,Yu Wang", "background": "当前最新的大规模语言模型（LLMs）声称支持长达256k的上下文长度，而主流基准的平均上下文长度仅为5k至21k。这些基准存在知识泄漏和不准确的评价指标问题，导致评价结果具有偏差。本文介绍了一个名为LV-Eval的挑战性长上下文基准，包含了五个不同长度级别的上下文（16k, 32k, 64k, 128k, 和 256k），并设计了单跳问答和多跳问答两个主要任务，涵盖了11个双语数据集，以解决上述问题；", "innovation": "LV-Eval的设计融入了三种关键技术：混淆事实插入、关键词和短语替换以及基于关键词召回的度量设计。这种基准能够控制不同长度级别的可评价性，提供具有混淆事实的挑战性测试实例，减少了知识泄漏，并提供了更客观的评价。LV-Eval通过发布所有数据集和评价代码来促进研究透明度；", "conclusion": "在LV-Eval上评估了15个LLMs，并进行了基准测试技术的消融研究。结果表明，Moonshot-v1和Qwen-2.5-72B、Llama-3.1-70B等模型在长度小于64k时表现最佳。模型的评分趋势各异，一些模型在大量混淆信息中性能显著下降。知识泄漏和不准确指标的问题在LV-Eval中得到了缓解。"}
{"llm_update_time": "20251023", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2501.04961", "html_url": "https://arxiv.org/abs/2501.04961", "title": "揭开面向金融大型语言模型的后训练领域适应之谜", "title_en": "Demystifying Domain-adaptive Post-training for Financial LLMs", "authors": "Zixuan Ke,Yifei Ming,Xuan-Phi Nguyen,Caiming Xiong,Shafiq Joty", "background": "大型语言模型（LLMs）在特定领域（如医疗和金融）的领域适应性后训练（domain-adaptive post-training）已经显示出很大的潜力，但识别最佳适应标准和针对不同数据和模型配置的训练策略仍然面临较大挑战。", "innovation": "提出了一种名为FINDAP的方法，这是一个系统性的研究和细粒度调查，专门用于金融领域的大型语言模型的领域适应性后训练。该方法包括四部分：FinCap定义目标领域所需的核心能力；FinRec是一种有效的培训配方，联合优化连续预训练和指令遵循，以及一种新的偏好数据蒸馏方法，利用生成奖励模型的过程信号；FinTrain是一系列支持FinRec的训练数据集；FinEval是一个与FinCap对齐的全面评估套件。研究导致了一个名为Llama-Fin的模型，该模型在广泛的金融任务中达到了最新的性能。", "conclusion": "分析揭示了每个后训练阶段对特定能力的贡献，明确了特殊挑战和有效解决方案，为LLMs的领域适应提供了有价值的见解。"}
{"llm_update_time": "20251023", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2502.01349", "html_url": "https://arxiv.org/abs/2502.01349", "title": "留神偏见：认知偏见对LLM驱动的产品推荐的影响", "title_en": "Bias Beware: The Impact of Cognitive Biases on LLM-Driven Product Recommendations", "authors": "Giorgos Filandrianos,Angeliki Dimitriou,Maria Lymperaiou,Konstantinos Thomas,Giorgos Stamou", "background": "巨量语言模型（LLMs）的兴起已经彻底改变了产品推荐系统，但是这些模型容易受到对抗性操控，特别是在商业应用中带来了严峻的挑战。本研究调查了认知偏见作为黑盒对抗策略的影响，发现某些偏见如社会证明，能够持续提升产品推荐的率和排名，而稀缺性和排他性等却意外地降低了产品的可见度。", "innovation": "本研究是首次利用人类心理原则，对产品描述进行巧妙修改，使得对抗性操控难以察觉。通过广泛评估不同规模的模型，本研究揭示了认知偏见在最先进的LLM中的深刻嵌入，导致了高度不可预测的产品推荐行为。", "conclusion": "认知偏见在最先进的LLM中占有一席之地，导致了产品推荐行为的不可预测性，这对有效的缓解策略提出了重大挑战。"}
{"llm_update_time": "20251023", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2410.01735", "html_url": "https://arxiv.org/abs/2410.01735", "title": "LASeR：使用多臂老虎机学习自适应选择奖励模型", "title_en": "LASeR: Learning to Adaptively Select Reward Models with Multi-Armed Bandits", "authors": "Duy Nguyen,Archiki Prasad,Elias Stengel-Eskin,Mohit Bansal", "background": "奖励模型（RMs）对于使大型语言模型（LLMs）对齐至关重要，但专门针对某一任务（例如写作）的RM在新任务（例如数学）上的通用性通常无法预先确定，这使得仅使用固定一个RM来训练LLMs可能效果不佳。然而，同时用多个RM优化LLMs会带来 enormous 的计算成本，并可能导致不同RM之间的矛盾信号，进一步损害性能。", "innovation": "我们提出了一种名为LASeR（Learning to Adaptively Select Rewards）的方法，将奖励模型的选择问题构建成一个多臂老虎机问题，并通过逐个实例选择最佳适应的RM来高效且迭代地训练LLMs。这在常识和数学推理任务上提高了LLM的强化迭代训练的性能，与多个RM评分的集成相比，在三个数据集上提高了2.67%的绝对平均准确率，同时也显示了更高的效率（例如，速度提高2倍）。此外，在WildChat（开放式指令遵循任务）上，LASeR相对于RM评分集成基准实现了72.69%的AlpacaEval胜利率。对于长上下文生成，LASeR在单文档问答任务中提高了2.96 F1分数，在少量样本学习中提高了2.97 F1分数，比RM评分集成基准有显著提升。", "conclusion": "通过LASeR，可以在不增加过多计算成本的情况下，有效选择最佳适应的任务的RM，从而提高LLM的性能和效率，并在多个任务上显示出优越的性能。"}
{"llm_update_time": "20251023", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.19796", "html_url": "https://arxiv.org/abs/2510.19796", "title": "通过隐写分析证明黑盒模型来源", "title_en": "Blackbox Model Provenance via Palimpsestic Membership Inference", "authors": "Rohith Kuditipudi,Jing Huang,Sally Zhu,Diyi Yang,Christopher Potts,Percy Liang", "background": "假设Alice训练了一个开放权重的自然语言模型，而Bob使用了一个黑盒模型的派生版本来生成文本。Alice希望证明Bob是否在使用她的模型。本研究将该问题表述为独立性检验问题，通过语言模型的隐写证据来检测。研究证明，模型更可能记住训练过程中较晚出现的数据，若Bob的模型或生成的文本与Alice训练数据的顺序有显著相关性，这就可以作为Alice模型来源的证据。例如，如果Alice随机打乱了她的训练数据，那么任何显著的相关性都将是统计意义下反对零假设的结果，与Alice的训练数据内容无关。研究通过两种设置进行实验，其中之一（查询设置）直接估计Bob的模型对Alice训练样本及顺序的似然性，另一个（观察设置）尝试评估Bob的文本与Alice训练样本重叠的可能及不同版本模型生成文本的似然性，以确定模型的来源。这些研究方法提供了在没有任何重新训练的情况下，甚至仅使用少量文本（如几百个词），即可有效地检测模型来源的可能性，特别是基于最后一个训练阶段的重新迭代生成的不同版本模型的结果显著区别于实际使用的模型的文本，这为后续验证模型来源提供了新的视角和方法。", "innovation": "该研究提出了一种通过独立性检验和隐写分析来证明黑盒模型来源的新方法。这不仅是一种验证模型是否为特定训练数据集所训练的新工具，而且为确保模型数据来源的合法性提供了新的思路。通过直接估计不同模型对训练数据的似然性，以及评估生成文本与训练数据的重叠概率和使用不同版本模型生成文本的概率，该研究能够在查询和观察设置下有效检测和确认模型的来源。同时，该研究为未来进一步研究提供了坚实的基础，如改进检测方法，增加检测的精准度和可靠性，以及应用更广泛的模型和数据集，以拓宽该方法的应用领域和实际效果。", "conclusion": "该研究成功地从统计学角度证明了使用开放权重的自然语言模型训练出的黑盒模型的来源，即通过隐写分析和独立性检验方法，验证了模型是否基于某种特定的数据集进行训练。通过查询设置，直接估计模型对训练数据样本及顺序的似然性，获得了显著性结果；在观察设置中，评估生成文本与实际训练数据的对比，可靠地区分了模型来源。这些结论不仅丰富了机器学习领域的知识体系，也为实际应用中确保模型数据来源的法律合规性提供了一种有效的方法。"}
{"llm_update_time": "20251023", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.19817", "html_url": "https://arxiv.org/abs/2510.19817", "title": "olmOCR 2: 单元测试奖励对于文档OCR", "title_en": "olmOCR 2: Unit Test Rewards for Document OCR", "authors": "Jake Poznanski,Luca Soldaini,Kyle Lo", "background": "该论文介绍了最新一代的olmOCR OCR系统，该系统用于将数字化印刷文件（如PDF）转换为干净的、自然排列的纯文本。olmOCR 2的核心是olmOCR-2-7B-1025，这是一种经过强化学习特别是可验证奖励训练的7B视图语言模型。为了解决单元测试创建的问题，研究人员开发了一种生成具有多样化和具有挑战性布局的合成文档的管道，这些文档包含已知的正确HTML源代码和提取的测试用例。研究结果显示，基于这些测试用例的强化学习训练在英文OCR基准测试olmOCR-Bench上取得了最先进的性能，特别是在公式识别、表格解析和多列布局方面取得了显著改进。", "innovation": "该论文介绍了一种新型的OCR系统olmOCR 2，其中关键的技术是使用强化学习（特别是基于可验证奖励的强化学习，即RLVR）和一个特殊开发的pipeline来生成具有多种布局的合成文档进行训练。这种方法提高了OCR在特定场景下的性能，尤其是公式和表格的识别方面有显著进步。", "conclusion": "olmOCR 2展示了使用单元测试奖励在强化学习中训练OCR模型的有效性，并且模型及其相关的数据和代码已经开源。这种开源可以促进其他研究和开发工作的进行，并进一步推动OCR技术的发展。"}
{"llm_update_time": "20251023", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.19808", "html_url": "https://arxiv.org/abs/2510.19808", "title": "Pico-Banana-400K：文本指导图像编辑的大规模数据集", "title_en": "Pico-Banana-400K: A Large-Scale Dataset for Text-Guided Image Editing", "authors": "Yusu Qian,Eli Bocek-Rivele,Liangchen Song,Jialing Tong,Yinfei Yang,Jiasen Lu,Wenze Hu,Zhe Gan", "background": "最近的多模态模型在文本引导的图像编辑方面展示了显著的能力，如GPT-4o和Nano-Banana已经设立了新的基准。但研究进展受限于缺乏大型、高质量且可公开访问的真实图像数据集。早前的研究大多依赖合成数据集，这些数据集难以真实的涵盖各种编辑类型并保持内容和指令的真实性和精确性。因此，需要一个能够提供高质量、丰富任务的数据集来支持生成模型的训练和评估", "innovation": "Pico-Banana-400K是一个包含400K真实图像样本的数据集，通过利用Nano-Banana从OpenImages中生成多样化编辑对。与早期合成数据集不同，Pico-Banana-400K通过细粒度的图像编辑分类确保全面覆盖各种编辑类型，并通过基于MLLM的质量评分和精心策划保持内容和指令的精确定义。此外，该数据集包含三个专门的子集：72K个例子的多步编辑集用于研究序列编辑、推理和连续修改之间的关系；56K个例子的偏好子集用于对齐研究和奖励模型训练；以及长短编辑指令配对集，用于指导替代编写和总结能力的开发", "conclusion": "通过提供一个大规模的、高质量的、任务丰富的资源，Pico-Banana-400K为训练和评测下一代文本引导的图像编辑模型奠定了稳固的基础"}
{"llm_update_time": "20251023", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2503.10620", "html_url": "https://arxiv.org/abs/2503.10620", "title": "从TOWER到SPIRE：将语音模态添加到翻译专家的语言模型", "title_en": "From TOWER to SPIRE: Adding the Speech Modality to a Translation-Specialist LLM", "authors": "Kshitij Ambilduke,Ben Peters,Sonal Sannigrahi,Anil Keshwani,Tsz Kin Lam,Bruno Martins,André F.T. Martins,Marcely Zanon Boito", "background": "研究者开发了一系列多语言模型来实现跨语言的文本与语音的翻译和转录任务。现有的语音语言模型通常需要大量的数据进行训练，而且将语音输入作为一种额外的语言进行集成的效果仍有待验证。Spire旨在通过一种新的框架去集成语音模态到现有的多语言模型中，通过更少的数据实现模型语音和文本的转化能力，弥补了现有技术的不足。", "innovation": "Spire可以同时翻译和转录从英语到其他10种语言的语音输入，并且可以在两个方向上进行文本翻译。它通过将语音离散化并仅使用42.5K小时的语音数据进行持续预训练，将语音模态融入现有的多语言模型中。这种方法不仅赋予模型语音处理能力，同时还保留了其强大的文本处理性能。Spire展示了在语言模型适应过程中通过离散语音输入集成额外语言的可行性，且使用了比现有语音语言模型更少的数据。", "conclusion": "Spire利用少量数据集成功能，在不显著增加数据需求的情况下增强了模型的语音处理能力。通过提供代码和模型，Spire为社区提供了一个将语音和其他额外语言集成到多语言模型中的有效框架。"}
{"llm_update_time": "20251023", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2503.19878", "html_url": "https://arxiv.org/abs/2503.19878", "title": "CausalRAG: 将因果图集成到检索增强生成中", "title_en": "CausalRAG: Integrating Causal Graphs into Retrieval-Augmented Generation", "authors": "Nengbo Wang,Xiaotian Han,Jagdip Singh,Jing Ma,Vipin Chaudhary", "background": "大型语言模型（LLMs）已经通过检索增强生成（RAG）技术彻底改变了自然语言处理（NLP），通过结合外部知识增强LLM的能力。然而，传统RAG系统存在一些关键限制，如文本分块导致的上下文连贯性中断，以及过度依赖语义相似性进行检索。", "innovation": "本文提出了一种名为CausalRAG的新框架，它将因果图集成到检索过程中。通过构建和追踪因果关系，CausalRAG能够保持上下文连贯性和检索准确度，从而提供更准确和可解释的响应。CausalRAG在多项指标上优于常规RAG和基于图的RAG方法。研究结果表明，基于因果推理进行检索为知识密集型任务提供了一种有希望的方法。", "conclusion": "本文通过引入CausalRAG框架，在RAG系统中加入了因果推理机制，显著提升了检索的准确性和响应的可解释性。实验结果证明了CausalRAG的优越性，为知识密集型任务提供了一种新的解决方案。"}
{"llm_update_time": "20251023", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2504.09909", "html_url": "https://arxiv.org/abs/2504.09909", "title": "量子自然语言处理：模型、方法与应用的综合回顾", "title_en": "Quantum Natural Language Processing: A Comprehensive Review of Models, Methods, and Applications", "authors": "Farha Nausheen,Khandakar Ahmed,M Imad Khan,Farina Riaz", "background": "近年来，应用到自然语言处理（NLP）领域中的深度学习方法展示了提升性能的效果，但同时也带来了大量数据和资源的需求问题。相比之下，量子计算通过遵循量子力学原理来克服现有的计算限制，正在形成量子自然语言处理（QNLP）这一新兴领域。该领域有潜力在语言结构处理上获得量子优势，超越经典模型在效率和准确性方面。", "innovation": "本文旨在根据量子计算原理、架构及其计算方法对QNLP模型进行分类，并通过综述该领域的最新进展，探讨如何利用量子编码技术处理经典数据，QNLP模型应用于广泛的NLP任务以及量子优化技术应用于超参数调优。", "conclusion": "该研究总结了应用于各NLP任务的量子计算方法的景观，并展示了特定的QNLP方法以及这些方法的流行程度。观察结果显示，QNLP方法目前仍局限于小数据集，仅有少数模型被广泛探索，量子计算在自然语言处理任务中的应用兴趣正在增加。"}
{"llm_update_time": "20251023", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2504.03931", "html_url": "https://arxiv.org/abs/2504.03931", "title": "NAACL2025研讨会：大规模语言模型的适应", "title_en": "NAACL2025 Tutorial: Adaptation of Large Language Models", "authors": "Zixuan Ke,Yifei Ming,Shafiq Joty", "background": "尽管通用的语言模型（LLM）在多种任务上展现出很强的泛化能力，但在特定领域如金融、医疗和小众语言的代码生成方面表现不佳。此外，这些模型通常是静态的，无法适应不断变化的世界，并且规模庞大，部署成本高昂。因此，LLM的适应性问题引起了广泛关注，并且对其改进和优化具有重要的工业和学术价值。这种研讨会旨在提供LLM适应技术的概述，从数据和模型的角度介绍LLM适应的概念，强调与其他技术不同的评估指标和基准，并探讨各类适应技术，包括参数知识适应和半参数知识适应，以及在线适应技术如模型编辑等。", "innovation": "该研讨会创新性地将重点放在LLM适应技术上，详细介绍参数知识适应和半参数知识适应的不同类别，并探讨在线适应技术，如模型编辑，以实现LSTM在实时更新中的应用。这种全面的介绍为理解LLM如何被优化以满足特定需求提供了新视角，对于提升模型在特定领域中的性能具有重要意义。", "conclusion": "该研讨会总结了LLM适应技术的现状和发展趋势，强调了通过动态、领域特定和任务适应性技术提高LLM性能的重要性和方法，对于推动LLM技术的进步和应用具有积极作用。"}
{"llm_update_time": "20251023", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2505.18524", "html_url": "https://arxiv.org/abs/2505.18524", "title": "metaTextGrad：自动优化语言模型优化器", "title_en": "metaTextGrad: Automatically optimizing language model optimizers", "authors": "Guowei Xu,Mert Yuksekgonul,Carlos Guestrin,James Zou", "background": "近年来，大型语言模型（LLMs）广泛应用于学习算法、评估和优化任务中。已有研究显示，利用基于语言模型的优化器自动优化模型提示、示例、预测或其他组件，能够显著提升AI系统的性能。然而，现有的语言模型优化器通常由人工设计，没有经过优化，并且通用设计使其无法针对特定任务进行优化。", "innovation": "本文提出了metaTextGrad，旨在设计一个元优化器来进一步增强现有优化器，并使它们更好地适用于特定任务。metaTextGrad包含两个关键组件：元提示优化器和元结构优化器。二者结合显著提升了多个基准测试的性能，相较于最佳基线，平均绝对性能提升了6%。", "conclusion": "metaTextGrad通过设计元优化器，使得优化器能够更好地针对特定任务进行优化，并通过实验证明了其有效性，达到了显著的性能提升。"}
{"llm_update_time": "20251023", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2505.14455", "html_url": "https://arxiv.org/abs/2505.14455", "title": "CtrlDiff：使用动态块预测和可控生成增强大型扩散语言模型", "title_en": "CtrlDiff: Boosting Large Diffusion Language Models with Dynamic Block Prediction and Controllable Generation", "authors": "Chihan Huang,Hao Tang", "background": "尽管自回归模型在近几年的语言模型中占据主导地位，但人们越来越兴趣探索替代传统下一个词预测框架的新型范式。基于扩散的语言模型因其强大的并行生成能力和内在的编辑能力而成为有吸引力的替代方案。然而，这些模型往往受限于固定长度的生成，于是将序列分割成块并利用自回归依赖性跨块建模同时使用离散扩散估计每个块给定前文上下文的条件分布是一种潜在的方向。但是，其实际应用常受固定长度输出的刚性限制和缺乏灵活控制机制的关键限制的阻碍。", "innovation": "本文解决了当前大型扩散语言模型在固定粒度和弱可控性方面的关键限制。提出了一种名为CtrlDiff的动态和可控的半自回归框架，该框架通过强化学习适应性地确定每个生成块的大小。同时引入了一种针对离散扩散的分类器指导控制机制，显著降低了计算开销并促进了高效的后验条件处理而不重新训练。大量实验表明，CtrlDiff在混合扩散模型中树立了新的标杆，缩小了与最先进的自回归方法的性能差距，并在多种任务中实现了有效的条件文本生成。", "conclusion": "CtrlDiff在混合扩散模型中树立了新的标杆，缩小了与最先进的自回归方法的性能差距，并在多种任务中实现了有效的条件文本生成。"}
{"llm_update_time": "20251023", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2505.07897", "html_url": "https://arxiv.org/abs/2505.07897", "title": "LongCodeBench：在100万上下文窗口下评估编码LLM", "title_en": "LongCodeBench: Evaluating Coding LLMs at 1M Context Windows", "authors": "Stefano Rando,Luca Romani,Alessio Sampieri,Luca Franco,John Yang,Yuta Kyuragi,Fabio Galasso,Tatsunori Hashimoto", "background": "随着模型上下文长度的迅速增长，从几千到数百万个标记仅在几年内，现代长期上下文模型的极端上下文规模使得构建现实的长期上下文基准变得困难。这不仅由于收集百万级任务的成本高，还在于识别需要大量上下文的实际场景。作者将代码理解与修复识别为长期上下文模型的理想测试场景，推出了LongCodeBench（LCB）作为基准，用于测试LLM在长期上下文中的编程能力。基准从真实世界的GitHub问题中获取数据，构建设问题-答案（LongCodeQA）和漏洞修复（LongSWE-Bench）任务，以评估模型在不同复杂度下的表现。", "innovation": "该研究识别了代码理解和修复作为测试和挑战长期上下文模型的自然场景，并推出LongCodeBench（LCB）作为新的基准测试。LCB涵盖了从理解到修复的多种编程任务，并精心分层设计测试场景，使不同规模的模型都能参与测试，覆盖从Qwen2.5 14B Instruct到Google的旗舰Gemini模型的范围。实验结果表明，无论模型规模如何，长期上下文仍是一个弱点，表现差异显著，例如Claude 3.5 Sonnet从29%下降到3%，Qwen2.5从70.2%下降到40%。", "conclusion": "作为一项新的基准测试，LongCodeBench公开提供数据集，并提供复制该研究工作的代码库。实验结果展示了长期上下文是所有模型的弱点，并对未来研究具有重要意义。"}
{"llm_update_time": "20251023", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2503.18129", "html_url": "https://arxiv.org/abs/2503.18129", "title": "GeoBenchX: 评估多步骤地理空间任务中LLMs代理能力的基准", "title_en": "GeoBenchX: Benchmarking LLMs in Agent Solving Multistep Geospatial Tasks", "authors": "Varvara Krechetova,Denis Kochedykov", "background": "本文旨在为大型语言模型（LLMs）在与商业GIS从业人员相关的多步骤地理空间任务中的工具调用能力建立一个基准评估体系。作者评估了八种商业LLMs（Claude Sonnet 3.5和4、Claude Haiku 3.5、Gemini 2.0 Flash、Gemini 2.5 Pro Preview、GPT-4o、GPT-4.1和o4-mini），使用了一个配备23个地理空间功能的简单工具调用代理。基准测试涵盖四个复杂度逐步增加的任务类别，包括可解决和故意无法解决的任务，以测试难度评估的准确性。此外，提出了一种LLM-as-Judge评价框架来对比代理解决方案与参考解决方案。这项研究表明，o4-mini和Claude 3.5 Sonnet在整体性能上最佳，OpenAI的GPT-4.1、GPT-4o和Google的Gemini 2.5 Pro Preview紧跟其后，但后两者在识别无法解决的任务方面更有效。Claude Sonnet 4因其倾向于提供任何解决方案而不是拒绝任务，因此准确度较低。研究还发现，调用工具的数量存在显著差异，Anthropic模型的调用量多于竞争对手。常见的错误包括对几何关系理解错误、依赖过时的知识以及无效的数据处理。这份基准测试集、评价框架和数据生成管道被作为开源资源（可在https://this-link.is/not-provided 获取）公布，为持续的LLM GeoAI评估提供了更多的标准化方法。", "innovation": "本文构建了一种专门针对多步骤地理空间任务的大语言模型评估框架，可以用来衡量LLM的工具调用能力。该框架包含了一系列任务，涵盖了从简单到复杂的不同复杂度，并设置了可解决和不可解决的任务来检验模型的难度评估能力。此外，提出了一种LLM作为评判者的新颖评价方法，通过将模型的解决方案与参考解决方案进行对比来评估其性能。", "conclusion": "研究显示，o4-mini和Claude 3.5 Sonnet在整体性能上最优，而OpenAI和Google的模型表现也相当不错，但在识别无法解决的任务方面更为高效。此外，研究还揭示了常见的模型错误，并提供了开源资源以供持续的GeoAI评估。"}
{"llm_update_time": "20251023", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2506.05735", "html_url": "https://arxiv.org/abs/2506.05735", "title": "LLMs真的会忘记吗？基于知识关联与置信度意识的评估", "title_en": "Do LLMs Really Forget? Evaluating Unlearning with Knowledge Correlation and Confidence Awareness", "authors": "Rongzhe Wei,Peizhi Niu,Hans Hao-Hsun Hsu,Ruihan Wu,Haoteng Yin,Mohsen Ghassemi,Yifan Li,Vamsi K. Potluru,Eli Chien,Kamalika Chaudhuri,Olgica Milenkovic,Pan Li", "background": "机器忘却技术旨在减轻大型语言模型（LLMs）中无意记忆的问题。现有方法主要侧重于显式移除孤立事实，而忽略潜在的推理依赖和知识的非确定性。因此，被假定遗忘的事实可能会通过关联信息而隐式地持久存在。该研究旨在解决这一挑战，提出了一种知识忘却评估框架，利用相关事实上下文的知识图谱及关联置信分数更准确地捕捉现实世界的知识结构。进一步开发了基于推理的评估协议，通过强有力的LLM作为评委进行判断，这些评委可以在抽取的知识子图上进行推理以评估忘却效果。", "innovation": "该研究创新地提出了知识忘却评估框架，通过知识图谱和置信分数来更准确地捕捉现实世界的知识结构。此外，开发了基于推理的评估协议，利用强有力的LLM作为评委进行判断。这些评委通过精心设计的提示进行推理，并与人类评价进行校准，以确保它们的可信度和稳定性。实验结果显示，该框架提供了更现实和严格的忘却性能评估，并揭示了当前评估策略倾向于高估忘却效果。", "conclusion": "广泛的新构建基准实验表明，该框架提供了一种更现实和严格的知识忘却性能评估。此外，研究发现当前的评估策略往往会高估忘却效果。研究代码已公开。"}
{"llm_update_time": "20251023", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2507.06313", "html_url": "https://arxiv.org/abs/2507.06313", "title": "ETT: 实时扩展LLMs长上下文理解能力", "title_en": "ETT: Expanding the Long Context Understanding Capability of LLMs at Test-Time", "authors": "Kiarash Zahirnia,Zahra Golpayegani,Walid Ahmed,Yang Liu", "background": "基于Transformer的语言模型的计算和内存开销随着序列长度的增加呈二次增长。这种二次成本使得在长序列上使用大型语言模型（LLMs）变得具有挑战性。因此，需要一种方法在测试时有效地扩展模型的上下文长度，同时保持恒定的内存需求和线性的计算开销。", "innovation": "提出了ETT（Extend at Test-Time）方法，该方法通过分块输入上下文并高效微调模型参数（分块为重叠的小片段）来在测试时扩展短上下文Transformer模型的上下文长度，同时保证恒定的内存需求和线性的计算开销。通过在LongBench上扩展GPT-Large和Phi-2的上下文长度至32倍，从1k增加到32k tokens，实现了模型准确性的最多30％的提高。此外，研究了如何高效存储上下文信息，同时通过详细的消融实验发现了某些Transformer模块在测试时更有效进行微调。微调FFNs（前馈神经网络）的第二层比完全微调更有效，进一步提高了模型的准确率。", "conclusion": "研究成果表明，通过在内存需求恒定的情况下，通过分块输入上下文并在测试时高效微调部分模型参数，模型的上下文长度可以显著增加，从而提升了模型的性能。"}
{"llm_update_time": "20251023", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2505.17950", "html_url": "https://arxiv.org/abs/2505.17950", "title": "评估处理学生文本中科学特定符号表达的NLP嵌入模型", "title_en": "Evaluating NLP Embedding Models for Handling Science-Specific Symbolic Expressions in Student Texts", "authors": "Tom Bleckmann,Paul Tschisgale", "background": "近年来，自然语言处理（NLP）在教育数据挖掘中变得非常重要，特别是在分析学生生成的语言产品方面。现有的嵌入模型常用于生成文本的数值表示，这些表示捕捉了文本的语义内容，并用于后续的定量分析。然而，当遇到与科学相关的语言，尤其是包含方程式和公式的符号表达式时，这些嵌入模型会遇到挑战。现有研究和实践中的许多文献可能会忽视这些挑战，或者完全移除这些符号表达式，可能会导致研究结果的偏差并降低实际应用的效果。因此，该研究旨在探讨当前嵌入模型在处理科学相关符号表达方面的差异和能力。使用来自真实学生回答的物理特定符号表达式，通过两种方法评估模型性能：1）基于相似性分析；2）集成到机器学习管道中。", "innovation": "本研究通过使用物理学特定的符号表达式，并结合基于相似性分析和机器学习管道的两种评估方法，系统地比较了不同嵌入模型在处理科学相关符号表达方面的性能差异。研究发现，OpenAI的GPT-text-embedding-3-large表现最好，但与其他模型相比，这种优势并不显著。这项研究强调了在处理包含符号表达式的科学相关语言产品方面，教育数据挖掘研究人员和实践者需要谨慎选择NLP嵌入模型的重要性。", "conclusion": "本研究结果表明，在处理科学相关语言产品中的符号表达时，不同嵌入模型之间存在显著差异，特别是在处理复杂符号表达式方面，OpenAI的GPT-text-embedding-3-large表现出一定的优势，但这种优势并未达到决定性程度。研究结果强调了在教育数据挖掘中选择合适NLP嵌入模型的重要性，尤其是在涉及科学相关语言数据时。"}
{"llm_update_time": "20251023", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.08514", "html_url": "https://arxiv.org/abs/2508.08514", "title": "DeCAL 句子级压缩", "title_en": "DeCAL Tokenwise Compression", "authors": "Sameer Panwar", "background": "介绍了 DeCAL，一种新的句子级压缩方法。该方法利用一个预训练的去噪编码-解码语言模型，从编码器生成高质量、通用的压缩表示。文章展示了在多项下游任务中，DeCAL 在 2 倍压缩的情况下能与未压缩的效果相当，压缩至 8 倍时通常仅有轻微的指标下降。", "innovation": "DeCAL 强调最大化压缩质量，即使在计算成本上有一定损失。通过对其编码器进行小的修改，DeCAL 表现出了显著的压缩节省效果，尤其是在可以利用预先计算的密集表示时。研究表明，DeCAL 在多项任务（如问答、摘要和多向检索）上具有很大的应用潜力，并且该方法在未来可能更加广泛地适用。", "conclusion": "DeCAL 在保持高质量压缩的同时，具有显著节约预计算密集表示的潜力，这在某些应用中是一个重要的优势。未来的研究可能会继续优化 DeCAL，使其更加通用可应用。"}
{"llm_update_time": "20251023", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2505.15695", "html_url": "https://arxiv.org/abs/2505.15695", "title": "大型语言模型能够在在线环境中有效地担任意见挖掘的角色吗？", "title_en": "Can Large Language Models be Effective Online Opinion Miners?", "authors": "Ryang Heo,Yongsik Seo,Junseong Lee,Dongha Lee", "background": "用户生成的在线内容丰富了对客户偏好和市场趋势的理解，但这些内容的高度多样性和复杂的背景信息对传统的情感分析方法提出了重大挑战。", "innovation": "提出了Online Opinion Mining Benchmark (OOMB)，一种新型的数据集和评估协议，旨在评估大规模语言模型（LLMs）从多样且复杂在线环境中有效挖掘意见的能力。OOMB提供了广泛的实体、特征、意见元组注释，并给出了全面的意见中心总结，突显每个内容中的关键意见主题，从而评估模型的抽取性和抽象性能力。", "conclusion": "通过建议的基准测试，进行了全面分析以了解哪些方面仍然具有挑战性，并探索LLMs在实际在线场景中是否能有效担任意见挖掘者。此项研究为基于LLM的意见挖掘奠定了基础，并讨论了这一领域的未来研究方向。"}
{"llm_update_time": "20251023", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.09350", "html_url": "https://arxiv.org/abs/2508.09350", "title": "Flow-SLM：联合学习语言和声学信息的语音语言建模", "title_en": "Flow-SLM: Joint Learning of Linguistic and Acoustic Information for Spoken Language Modeling", "authors": "Ju-Chieh Chou,Jiawei Zhou,Karen Livescu", "background": "文本无关的语音语言模型（SLMs）是不依赖于文本监督的语音生成模型。大多数SLMs学习预测下一个语义标记，通常是一个语言内容的离散表示，并依赖于单独的声码器来添加生成语音的声学信息。这些模型无法访问声学上下文，也没有内置控制声学细节的能力。", "innovation": "本文提出了一种联合建模语言和声学信息的方法，通过生成语义标记和连续的声学帧的实值表示来产生语音。使用流匹配目标来预测在给定语义标记条件下的连续向量。研究了该方法的设计空间，并发现预测多个未来的语义标记有助于保持语言信息。该方法在语言似然性基准测试上与现有模型具有竞争力，并能提供更好的声学细节。", "conclusion": "我们的方法在语言似然性基准测试上实现了与现有模型相当的性能，同时在被提示的生成中提供了更好的声学细节。"}
{"llm_update_time": "20251023", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.12631", "html_url": "https://arxiv.org/abs/2508.12631", "title": "超越GPT-5：通过性能效率优化路由使大语言模型更便宜且更好", "title_en": "Beyond GPT-5: Making LLMs Cheaper and Better via Performance-Efficiency Optimized Routing", "authors": "Yiqun Zhang,Hao Li,Jianhao Chen,Hangfan Zhang,Peng Ye,Lei Bai,Shuyue Hu", "background": "在大型语言模型（LLM）的进步中，如何平衡性能与效率是一个核心挑战。GPT-5通过测试时路由解决了这个问题，即在推理时动态地将查询分配给高效的或高容量的模型。作者提出了一种名为Avengers-Pro的新框架，该框架集合了不同容量和效率的LLM，提供了一种统一的解决方案来应对所有性能和效率的权衡。Avengers-Pro通过嵌入和聚类进入的查询，然后根据性能和效率评分将其路由到最合适的模型。这种方法在6个具有挑战性的基准和8个领先的模型中取得了最先进的结果，展示了在保证性能的同时能够有效降低成本的能力。", "innovation": "Avengers-Pro是一种基于性能-效率优化的路由框架，能够根据不同模型的性能和效率评分将查询路由到最适合的模型。通过这一方法，它可以在平均准确率上超越GPT-5-medium模型7%，并在成本降低27%的情况下保持相同的平均准确率，甚至在成本降低63%的情况下达到其90%的性能。此外，该框架还实现了帕累托前沿，在任何给定成本下提供最高的准确率，在任何给定准确率下提供最低的成本，优于单个模型。", "conclusion": "Avengers-Pro框架通过优化性能-效率平衡，提供了一种统一的方法来解决大型语言模型中的性能-效率权衡问题。该框架在多个基准测试中表现出色，证明了在保持高性能的同时还能有效降低成本的能力，为大语言模型的发展提供了一种新的解决方案。"}
{"llm_update_time": "20251023", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.21589", "html_url": "https://arxiv.org/abs/2508.21589", "title": "Middo：通过闭环学习实现增强型大语言模型微调的模型引导动态数据优化", "title_en": "Middo: Model-Informed Dynamic Data Optimization for Enhanced LLM Fine-Tuning via Closed-Loop Learning", "authors": "Zinan Tang,Xin Gao,Qizhi Pei,Zhuoshi Pan,Mengzhang Cai,Jiang Wu,Conghui He,Lijun Wu", "background": "大型语言模型（LLM）的监督微调（SFT）本质上依赖于高质量的训练数据。虽然数据选择和数据合成是提高数据质量的两种常见策略，但现有方法在静态数据集管理方面往往存在局限性，无法适应模型能力的演变。", "innovation": "本文介绍了一个被称为Middo的自我进化的模型导向动态数据优化框架，该框架使用模型感知的数据选择和保留语义完整性的数据改进。该框架包含三个主要组件：自参照诊断模块、自适应优化引擎和动态学习原则，通过这三个组件共同形成一个闭环优化系统，从而在保持原有数据集规模的同时增强种子数据的质量，提升LLM性能。", "conclusion": "我们的实验在多个基准上表明，Middo能够持续提升种子数据的质量并增强LLM的性能，平均精度提升7.15%，同时保持原有数据集规模。这项工作通过数据和模型的动态人机共生进化树立了可持续的大语言模型训练的新范式。所有数据集、模型和代码均可通过提供的链接获取。"}
{"llm_update_time": "20251023", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.02629", "html_url": "https://arxiv.org/abs/2510.02629", "title": "语言模型上下文利用高亮解释评价框架", "title_en": "Evaluation Framework for Highlight Explanations of Context Utilisation in Language Models", "authors": "Jingyi Sun,Pepa Atanasova,Sagnik Ray Choudhury,Sekh Mainul Islam,Isabelle Augenstein", "background": "目前，语言模型（LMs）的上下文利用程度对于用户而言仍然是一个不透明的过程，用户无法确定模型是依赖参数记忆还是提供的上下文生成响应，也无法明确特定上下文片段如何影响响应。高亮解释（HEs）可以通过定位负责生成响应的具体上下文片段和标记来解决这一问题。然而，现有研究尚未评估HEs在准确解释上下文利用方面的效果。因此，本文旨在填补这一空白，引入了一个基于控制测试案例的高亮解释标准评价框架，该框架可用作上下文归因的基准，能够避免现有间接评价方法的局限性。", "innovation": "本文首次提出了一个基于控制测试案例的高亮解释标准评价框架，该框架直接适用于衡量上下文归因的准确性，而非依赖间接的代理评价。此外，研究还评估了四种不同的高亮解释方法在四种不同场景、四个数据集和五个语言模型上的表现，确定了在不同情景下哪种方法表现最佳。", "conclusion": "研究表明，机理可解释方法MechLight在所有场景下表现最佳，但所有方法在长上下文处理和位置偏见方面表现较差，这揭示了解释准确性方面存在根本性挑战，需要新的方法和技术来实现大规模、可靠的上下文利用解释。"}
{"llm_update_time": "20251023", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.15831", "html_url": "https://arxiv.org/abs/2508.15831", "title": "谁在提问？通过残疾框架查询调查LLM中的偏见", "title_en": "Who's Asking? Investigating Bias Through the Lens of Disability Framed Queries in LLMs", "authors": "Vishnu Hari,Kalpana Panda,Srikant Panda,Amit Agarwal,Hitesh Laxmichand Patel", "background": "大语言模型（LLMs）通常会根据语言风格自行推断用户的个人信息特质，即便是没有直接提供任何个人信息。这种推断可能带来偏见，尤其是对于残疾相关的猜测尚未得到充分研究。现有的研究和实践都表明，LLMs在这种情况下可能会进行错误的、无理由的推断，并且这种偏见随着模型规模的增大而更加明显。因此，学者们希望通过系统审计来揭示这一问题，特别是通过模拟不同残疾和社会背景下的推断来研究偏见的具体表现。", "innovation": "本文首次对八款最先进指令调优大语言模型进行了系统审计，这其中包括从3亿到72亿参数的不同规模模型。研究使用了均衡的模板语料库，其中包括九类残疾和六个真实世界商业领域。研究中，模型被要求预测用户的人口统计学特征，包括性别、社会经济状况、教育水平、文化背景和居住地，并对比了在普通情境和残疾认知情境下的预测结果。研究发现，无论是哪种模型，都会在很大程度上进行随意的推断；并且，残疾背景显著改变了预测结果的分布，不同领域背景进一步放大了这些偏差。作者还发现较大的模型对残疾线索更为敏感，并更可能进行偏差推理，这意味着模型大小并不能缓解刻板印象放大。这项研究填补了该领域的空白，揭示了秉持刻板印象的能力与其它人口统计学刻板印象之间的持续交集，并提出了改进策略，如避免偏见校准和反事实微调。", "conclusion": "该研究揭示了不同规模的LLMs在残疾背景下的偏见加剧现象，指出现有的对齐策略存在盲点。作者建议开发评价框架，结合人为偏见校准和反事实微调，以减少不必要的群体推断。这项研究结果为评估大语言模型的准确性提供了一套基准，有助于提高未来模型的公平性和包容性。"}
{"llm_update_time": "20251023", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.05931", "html_url": "https://arxiv.org/abs/2510.05931", "title": "聘请你的文化人类学家！从文化人类学视角重新思考文化基准", "title_en": "Hire Your Anthropologist! Rethinking Culture Benchmarks Through an Anthropological Lens", "authors": "Mai AlKhamissi,Yunze Xiao,Badr AlKhamissi,Mona Diab", "background": "当前的文化评估基准往往将文化简化为静态事实或同质价值观，这与人类学关于文化动态性、历史背景及实践中的体现的观点相悖。论文旨在分析这一差距，通过引入一个四部分框架来分类基准如何描述文化，包括知识、偏好、表现或偏见等方面。", "innovation": "论文提出了一个四部分框架来分类文化基准对文化的描述方式，并通过这个视角质性地分析了20个文化基准，指出了六种反复出现的方法论问题，如将国家视为统一文化、忽略内部文化多样性等。提出了从人类学角度的具体改进措施，如纳入真实的叙述和情境、让文化社区参与设计和验证，以及在实际情境中而非孤立中评估模型。", "conclusion": "论文旨在指导开发超越静态回忆任务的文化基准，更准确地捕捉模型对复杂文化情境的回应，促进大型语言模型的文化评估更加全面和深入。"}
{"llm_update_time": "20251023", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.03502", "html_url": "https://arxiv.org/abs/2510.03502", "title": "ALHD：阿拉伯语大规模多体裁基准数据集，用于LLM生成文本检测", "title_en": "ALHD: A Large-Scale and Multigenre Benchmark Dataset for Arabic LLM-Generated Text Detection", "authors": "Ali Khairallah,Arkaitz Zubiaga", "background": "当前，研究人员越来越关注区分人工生成和LLM（大型语言模型）生成的文本，特别是在阿拉伯语中更为重要，因为阿拉伯语具有不同的语言变体和体裁，且之前的这类数据集鲜有规模大且涵盖多种体裁的。因此，论文介绍了一个名为ALHD的新数据集，旨在填补这一空白。", "innovation": "ALHD是首个大规模、全面的阿拉伯语数据集，专门设计用于辨别人类与LLM生成的文本。该数据集包含新闻、社交媒体和评论三个体裁，覆盖标准现代阿拉伯语和方言阿拉伯语，并包含了超过400K平衡样本，这些样本来自多个来源，使用三种领先的LLM生成，并进行了严格的预处理、丰富的注释和标准化的平衡分割。此外，通过传统的分类器、BERT模型以及LLM（零_shot和少_shot）进行基准实验，展示了微调的BERT模型能取得竞争力的表现，超越了基于LLM的模型，但结果并非总是一致。", "conclusion": "研究结果表明，各种模型在跨体裁泛化时面临挑战，特别是在新闻文章中，因LLM生成的文本风格与人类文本相似，显著的研究空白由此产生。ALHD为阿拉伯语LLM检测研究奠定了基础，有助于减轻虚假信息、学术不诚信和网络威胁的风险。"}
{"llm_update_time": "20251023", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.05571", "html_url": "https://arxiv.org/abs/2510.05571", "title": "展示论文是一门艺术：用于学术展示的自我改进美学代理", "title_en": "Presenting a Paper is an Art: Self-Improvement Aesthetic Agents for Academic Presentations", "authors": "Chengzhi Liu,Yuzhe Yang,Kaiwen Zhou,Zhen Zhang,Yue Fan,Yanan Xie,Peng Qi,Xin Eric Wang", "background": "学术论文的推广已成为提升研究可见性的关键手段。然而，现有的自动化方法在故事叙述、美学质量以及自我调整方面表现有限，难以实现高效且引人入胜的传播。这部分挑战的核心在于无法评估，即‘你无法改进你未能正确评估的东西’。为了解决这一问题，本文提出了EvoPresent，这是一种自我改进代理框架，通过虚拟角色统一连贯的叙述、美学意识的设计以及现实的展示传递。EvoPresent的中心是PresAesth，这是一种多任务强化学习美学模型，提供了可靠美学评分、缺陷调整以及比较反馈，即使在美学训练数据有限的情况下也能促进迭代自改进。", "innovation": "本文创新地提出了EvoPresent，这是一种自我改进代理框架，通过虚拟角色对连贯故事叙述、美学意识设计和实际展示传递进行统一。核心创新是PresAesth，这是一种多任务强化学习美学模型，用于提供可靠的美学评分，缺陷调整和比较反馈，增强自改进能力。此外，还引入了EvoPresent基准，该基准包括展示生成质量和美学意识评估，支持联合训练和评价。", "conclusion": "研究发现，高质量的反馈是代理自改进的关键，初始能力不足以保证有效的自我纠正。自动化生成管道在视觉设计和内容构建之间表现出权衡。多任务RL训练在美学意识任务中展示了更强的泛化能力。"}
{"llm_update_time": "20251023", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.08666", "html_url": "https://arxiv.org/abs/2510.08666", "title": "dInfer：扩散语言模型的一种高效推理框架", "title_en": "dInfer: An Efficient Inference Framework for Diffusion Language Models", "authors": "Yuxin Ma,Lun Du,Lanning Wei,Kun Chen,Qian Xu,Kangyu Wang,Guofeng Feng,Guoshan Lu,Lin Liu,Xiaojing Qi,Xinyuan Zhang,Zhen Tao,Haibo Feng,Ziyun Jiang,Ying Xu,Zenan Huang,Yihong Zhuang,Haokai Xu,Jiaqi Hu,Zhenzhong Lan,Junbo Zhao,Jianguo Li,Da Zheng", "background": "扩散基于的大语言模型（dLLMs）作为一种替代自回归（AR）大语言模型的选择日益受到关注，它们通过去噪生成利用内在并行性。尽管越来越多的开源dLLM模型出现，但由于缺乏标准化和高效的推理框架，它们的广泛应用仍然受到限制。", "innovation": "dInfer是一个高效的扩散语言模型推理框架，它将推理管道分解为四个模块化的组件——模型、扩散迭代管理器、解码策略和KV缓存管理器，并结合了每个组件的新算法和系统级优化。通过这种算法创新和系统增强的结合，dInfer在LLaDA-MoE上实现了显著的效率提升，同时不牺牲输出质量。在批量大小为1的情况下，它在HumanEval上超过了每秒1100个令牌，在6个基准测试上跨8个H800 GPU平均每秒超过800个令牌。与之前系统相比，dInfer在速率为Fast-dLLM的10倍的同时保持了相似的模型性能。即使与同样具有优化且最新vLLM推理引擎的AR模型（具有相当的激活参数数量和性能）QWen2.5-3B相比，dInfer仍然实现了2-3倍的加速。", "conclusion": "dInfer提供了一种有效的方法来优化扩散语言模型的推理，展示了显著的速度提升空间以及对其他高级模型的竞争力，同时保持或改善了模型性能。"}
{"llm_update_time": "20251023", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.05126", "html_url": "https://arxiv.org/abs/2510.05126", "title": "提升语言模型的元认知和不确定性沟通能力", "title_en": "Improving Metacognition and Uncertainty Communication in Language Models", "authors": "Mark Steyvers,Catarina Belem,Padhraic Smyth", "background": "大型语言模型（LLMs）在决策过程中被广泛应用，但它们在给出答案时不标明不确定的情况下，用户可能会无意识地依赖这些错误的输出。现有研究表明，LLMs 保留了内部的不确定性信号，但其表达的置信度通常存在偏差，难以区分正确和错误的答案。本研究探讨了监督微调是否能够提升模型表达不确定性的能力，并研究此类改进是否能在不同任务和领域中泛化。研究在涵盖一般知识、数学和开放式常识的多个数据集中对 LLMs 进行微调，并评估了两种元认知任务：单一问题的置信度估计和成对的置信度比较。评估结果表明，微调能够提高置信度和准确度的匹配度（即校准）以及区分正确和错误响应的能力。然而，这些改进在特定任务上有局限性：针对单一问题的校准训练不能泛化到成对比较，反之亦然。多任务微调则能提供更广泛的改进，降低跨领域评估中的校准错误并加强区分度。这对于训练LLMs表达不确定性具有启示意义，并表明其需要经过多任务训练才能更有效地泛化.", "innovation": "本研究创新性地通过监督微调提升大型语言模型表达不确定性的能力，评估了该能力在不同任务和领域中的泛化效果，揭示了单一任务和多任务微调的区别和优势，对于改进和优化LLMs具有重要意义.", "conclusion": "研究结果显示，微调可以改善LLMs的校准（置信度和准确性之间的匹配度）和区分度（正确答案与错误答案之间的置信度差异），但这种改进具有任务特定性。多种任务的微调能更广泛地提高模型的泛化能力，降低跨领域评估中的校准误差并加强区分度。这表明LLMs中表达不确定性的能力是可以训练的，但如果要有效泛化则需要通过多任务训练."}
{"llm_update_time": "20251023", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.12829", "html_url": "https://arxiv.org/abs/2510.12829", "title": "使用大型语言模型作为证明者和验证者进行数学研究", "title_en": "Mathematics with large language models as provers and verifiers", "authors": "Hieu Le Duc,Leo Liberti", "background": "从2024年到2025年，关于大型语言模型证明能力的讨论引起了关注，这些讨论特别聚焦于它们解决复杂的数学问题（如国际数学奥林匹克竞赛中的题目）的能力。此外，还提出了一些猜想用于验证人工智能能否进行证明。这些初步的成功激发了研究者们探索大型语言模型在数学证明中的潜力。本研究使用了不同实例的GPT-5模型作为证明者和验证者，最终通过Lean证明助手对生成的证明进行了正式验证，进一步确保论据和结论的正确性。这些方法虽然还不够完善，但仍成功解决了2025年国际数学奥林匹克竞赛中的五道题，并接近解决了六十多个数论猜想中的三分之一。", "innovation": "本研究创新性地提出了一种合作机制，通过不同实例的GPT-5模型共同完成数学证明，并通过Lean证明助手进行正式验证。此外，还通过人工验证前提与结论的一致性，确保了证明的可靠性。这种方法为利用大型语言模型进行数学研究开辟了新的途径，提高了证明过程的准确性和可信度。", "conclusion": "尽管本研究的方法还存在不足，但是它成功展示了大型语言模型在数学证明领域中的潜力。通过多步验证过程，GPT-5模型解决了多个复杂问题和数论猜想，证明了其具备在特定条件下进行高质量数学推理的能力。未来可进一步完善该方法，提高这些语言模型在数学领域的实际应用效果。"}
{"llm_update_time": "20251023", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.16439", "html_url": "https://arxiv.org/abs/2510.16439", "title": "FrugalPrompt: 通过令牌属性减少大型语言模型的上下文开销", "title_en": "FrugalPrompt: Reducing Contextual Overhead in Large Language Models via Token Attribution", "authors": "Syed Rifat Raiyan,Md Farhan Ishmam,Abdullah Al Imran,Mohammad Ali Moni", "background": "大型语言模型（LLMs）依赖于广泛的语言输入以实现卓越的性能，但这种广泛性增加了成本和环境负担。大多数冗余低效的标记出现在常规提示中，只有一小部分标记承载了大部分语义权重。本文探讨了如何通过引入FrugalPrompt进行提示压缩以保留最重要的语义标记，从而提高LLMs的效率。", "innovation": "本文提出了FrugalPrompt框架，这是一种新颖的提示压缩框架，通过使用两种先进的标记相关性方法GlobEnc和DecompX，对输入序列中的每个标记进行相关性评分，排序并仅保留排名前k%的标记，以生成稀疏的经济化提示。研究结果显示，在某些任务中，20%的提示减少只影响了轻微的性能表现，而在数学推理任务中表现显著下降，这可能反映了对完整标记连续性的强烈依赖。", "conclusion": "研究表明，FrugalPrompt能够帮助LLMs更有效地运行，同时减少上下文开销。这种方法对于需要较少上下文的任务更加适用，对于依赖完整语境的任务则效果较差。作者提出的这种新的方法有助于更深入理解LLM在性能和效率之间的权衡，并明确了哪些任务可以容忍语境的稀疏性，哪些任务需要完整的语境。"}
{"llm_update_time": "20251023", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.18279", "html_url": "https://arxiv.org/abs/2510.18279", "title": "文本或像素？文本半数：多模态大语言模型中视觉文本输入的标记效率", "title_en": "Text or Pixels? It Takes Half: On the Token Efficiency of Visual Text Inputs in Multimodal LLMs", "authors": "Yanhong Li,Zixuan Lan,Jiawei Zhou", "background": "大语言模型（LLMs）及其多模态变体现在可以处理视觉输入，包括文本图像。这引发了一个有趣的问题：我们能否通过将文本输入作为图像喂入模型来压缩文本输入，从而减少标记使用量，同时保持性能？已有研究表明，视觉文本表示可以作为解码器LLMs的一种实用且特别有效的输入压缩形式。", "innovation": "本文描述了一种新的输入压缩方法，即将长长的文本输入渲染为单个图像，直接提供给模型。这种方法显著减少了解码器所需的标记数量，提供了一种新的输入压缩形式。通过在RULER（长文本检索）和CNN/DailyMail（文档摘要）两个不同的基准测试中进行实验，证明了这种文本图像方法在不影响任务性能的情况下实现了显著的标记节省（通常接近一半）。", "conclusion": "本研究表明，将文本视作图像输入是一种实用且高效的输入压缩形式，能够在解码器LLMs中减少标记使用量，而无需影响性能。该方法主要适用于长文本输入场景，在多模态LLMs的应用中具有很大的潜力。"}
{"llm_update_time": "20251023", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2410.06019", "html_url": "https://arxiv.org/abs/2410.06019", "title": "探索Transformer感知：通过探索输入流形", "title_en": "Unveiling Transformer Perception by Exploring Input Manifolds", "authors": "Alessandro Benfenati,Alfio Ferrara,Alessio Marta,Davide Riva,Elisabetta Rocchetti", "background": "本文介绍了一种通用方法，用于探索Transformer模型输入空间中的等价类。方法的基础是数学理论，该理论将Transformer架构的内部层描述为输入流形的顺序变形。通过使用Jacobian模型定义在输出空间上的距离度量的拉普背部的特征值分解，可以重构输入空间中的等价类并进行导航。该方法使得可以进行两种互补的探索过程：第一种检索出导致与原实例相同类概率分布的输入实例，从而识别出相同的等价类；第二种发现导致不同类概率分布的实例，从而有效地导航到不同的等价类。", "innovation": "该方法的关键在于使用输出空间上的距离度量通过模型的Jacobian的拉普背部进行特征值分解，以重构输入空间中的等价类并进行导航。此外，该方法使得可以从模型中获取有意义的实例，通过将它们的嵌入重新投影到可读的人类格式中，可以根据类概率分布的不同来区分等价类。", "conclusion": "该研究展示了如何通过投影回人类可读的格式解释检索到的实例，从而更好地理解模型的内部表示。"}
{"llm_update_time": "20251023", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.16708", "html_url": "https://arxiv.org/abs/2510.16708", "title": "自然语言处理在心脏病学中的应用：一项叙述性综述", "title_en": "Natural Language Processing for Cardiology: A Narrative Review", "authors": "Kailai Yang,Yan Leng,Xin Zhang,Tianlin Zhang,Paul Thompson,Bernard Keavney,Maciej Tomaszewski,Sophia Ananiadou", "background": "心血管疾病在现代社会中越来越普遍，对全球健康和福祉产生了深远影响。这些疾病是复杂的、多因素的，受遗传倾向、生活方式选择以及多种社会经济和临床因素的影响。关于这些相关因素的信息分散在各种类型的文本数据中，包括患者叙述、医疗记录和科学文献。自然语言处理（NLP）作为一种分析此类非结构化数据的强大方法，能够使医疗专业人员和研究人员获得更深入的见解，从而可能改变心血管疾病的诊断、治疗和预防。本文综述了2014年至2025年间NLP在心脏病学领域的研究现状。研究系统地搜索了六个文献数据库，筛选出了涉及心脏疾病领域NLP应用的研究文章，共分析了265篇文章。", "innovation": "本文提供了从2014年到2025年间NLP在心脏病学领域的全面综述。系统筛选了涉及多种心血管疾病的NLP应用研究，并通过多维度分析展示了这些研究的多样性，反映了NLP在心脏病学研究中的广度和演变。分析还进一步突出了方法论趋势，显示从基于规则的系统向大规模语言模型过渡。此外，讨论了关键挑战和未来方向，如开发可解释的大规模语言模型和整合多模态数据。", "conclusion": "据我们所知，本文综述涵盖了迄今为止关于NLP在心脏病学领域最全面的综合分析。"}
{"llm_update_time": "20251023", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.16062", "html_url": "https://arxiv.org/abs/2510.16062", "title": "LLMs能否自我矫正？LLMs自我矫正基准测试", "title_en": "Can LLMs Correct Themselves? A Benchmark of Self-Correction in LLMs", "authors": "Guiyao Tie,Zenghui Yuan,Zeli Zhao,Chaoran Hu,Tianhe Gu,Ruihang Zhang,Sizhe Zhang,Junran Wu,Xiaoyue Tu,Ming Jin,Qingsong Wen,Lixing Chen,Pan Zhou,Lichao Sun", "background": "大型语言模型（LLMs）的自我矫正已经成为提升其推理性能的关键组成部分。尽管已经提出了各种自我矫正方法，但这些方法的有效性仍缺乏全面的评估，尤其是对于大型语言模型是否真的能够自我矫正这一问题，研究仍存在很大的兴趣和争议。本文针对这一问题，开发了CorrectBench基准测试，评估了包括内生、外生和微调在内的多种自我矫正策略在常识推理、数学推理和代码生成三个任务中的效果。", "innovation": "本文引入了CorrectBench基准测试，这是首个针对LLMs自我矫正策略进行全面评估的基准。该基准涵盖了多种自我矫正方法，并通过三个具体任务（常识推理、数学推理和代码生成）来综合评估这些方法的效果。研究发现，自我矫正方法能够提高准确性，尤其是在复杂推理任务中；混合不同类型的自我矫正策略可以进一步提高效果，但也降低了效率；高强度的推理LLMs（例如DeepSeek-R1）在额外的自我矫正方法下优化有限，且具有较高的时间成本。与之相比，简单的方法（如链式思考法）在准确性和效率上表现出强劲的效果。这些结果突显了自我矫正在提高LLMs推理性能方面的潜力，同时也提出了继续优化推理能力和操作效率之间平衡的挑战。", "conclusion": "本文的研究表明，自我矫正方法可以提升LLMs的推理性能。尽管如此，继续优化这些方法以提高其效率仍然是一项挑战性任务。未来的研究应该重点关注优化二者之间的平衡，即提升LLMs的推理能力同时降低其操作成本。"}
{"llm_update_time": "20251023", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2410.10101", "html_url": "https://arxiv.org/abs/2410.10101", "title": "在多项式时间中学习线性注意力", "title_en": "Learning Linear Attention in Polynomial Time", "authors": "Morris Yau,Ekin Akyürek,Jiayuan Mao,Joshua B. Tenenbaum,Stefanie Jegelka,Jacob Andreas", "background": "先前的研究探索了Transformer模型在模拟布尔电路或图灵机方面的计算表达性。然而，这些模拟器通过观察数据学习的能力仍是一个开放问题。本研究填补了这一空白，提供了单层Transformer（尤其是具有一般线性注意的模型）的多项式时间可学习性结果，具体来说是强的、非专一的PAC学习结果。研究者证明线性注意可以被视为在适当定义的核希尔伯特空间中的一种线性预测器。", "innovation": "本研究通过证明线性注意可以被视为核希尔伯特空间中的线性预测器，将学习任何线性Transformer问题转化为学习普通线性的预测器问题。研究者还展示了如何高效地识别训练数据集，以确保每个经验风险最小化器等同于生成数据的线性Transformer，从而保证学习的模型将在所有输入中正确泛化。研究提供了通过线性注意力可实现且多项式时间可学习的计算实例，包括联想记忆、有限自动机和一类带有多项式计算历史的通用图灵机（UTM），并在三个任务上验证了理论发现。", "conclusion": "本研究填补了Transformer理论表达性和可学习性之间的差距，并证明灵活且通用的计算模型可以高效学习，验证了在多项式时间中学习线性注意力的有效性。"}
{"llm_update_time": "20251023", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2502.02904", "html_url": "https://arxiv.org/abs/2502.02904", "title": "ScholaWrite：完整端到端学术写作过程的数据集", "title_en": "ScholaWrite: A Dataset of End-to-End Scholarly Writing Process", "authors": "Khanh Chi Le,Linghe Wang,Minhwa Lee,Ross Volkov,Luan Tuyen Chau,Dongyeop Kang", "background": "写作是一项认知强度高的活动，需要持续的决策、对工作记忆的大量依赖，以及在具有不同目标的任务之间频繁切换。为了构建真正符合作者认知需求的写作助手，必须捕捉和解码作者将想法转化为最终文本的完整思维过程。为了解决这一问题，本研究提出了ScholaWrite，这是首个涵盖从初稿到最终手稿的整个学术写作过程的数据集。", "innovation": "本研究首次提供了通过Chrome扩展记录于书写过程的真实数据的方法，首次创建了一个全面的学术手稿语料库，含有精细的、认知性的写作意图标注。该数据集包括五个计算机科学前导论文的LaTeX基于编辑，共记录了约62,000次文本更改，历时四个月。研究还分析了学术写作中的微观动态，强调了人类写作过程与当前大语言模型（LLMs）提供有意义的帮助之间的差距。", "conclusion": "ScholaWrite突显了捕捉整个写作过程数据的重要性，以便开发未来能够支持而不是替代科学家认知工作的写作助手。"}
{"llm_update_time": "20251023", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2503.01675", "html_url": "https://arxiv.org/abs/2503.01675", "title": "使用（不太）大型语言模型生成规范领域特定语言中的仿真模型：反应网络研究", "title_en": "Using (Not-so) Large Language Models to Generate Simulation Models in a Formal DSL: A Study on Reaction Networks", "authors": "Justin N. Kreikemeyer,Miłosz Jankowski,Pia Wilsdorf,Adelinde M. Uhrmacher", "background": "形式语言是建模和仿真不可或缺的一部分。它们能够将知识浓缩成易于自动执行、解释和分析的简化仿真模型。然而，自然语言是最直观且易于人类理解的建模表达方式，但计算机难以直接解析。因此，本文探讨了使用大型语言模型（LLM）将自然语言描述转化为仿真模型的可能性。", "innovation": "本文展示了如何通过微调一个拥有70亿参数的开源Mistral模型将自然语言描述转化为特定领域（反应网络）的仿真模型，提供了一个自托管、计算效率高且内存效率高的替代方案。为此，开发了一个合成数据生成器作为微调和评估的基础。定量评价表明，微调后的Mistral模型在84.5%的情况下能够恢复原始仿真模型。", "conclusion": "尽管如此，目前的微调小LLM仍无法与大型LLM媲美。研究得出结论，高质量训练数据是需要的，并预期未来的小型开源LLM将带来新的机遇。"}
{"llm_update_time": "20251023", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2501.19339", "html_url": "https://arxiv.org/abs/2501.19339", "title": "PixelWorld：我们距离将一切感知为像素还有多远？", "title_en": "PixelWorld: How Far Are We from Perceiving Everything as Pixels?", "authors": "Zhiheng Lyu,Xueguang Ma,Wenhu Chen", "background": "近年来，代理语言模型越来越需要与包含紧密交织的视觉和文本信息的现实世界环境进行交互，通常通过原始相机像素，而不是单独处理的图像和标记化的文本。这种转变强调了统一感知范式的必要性。为探讨这一理念，我们探索了Perceive Everything as Pixels（PEAP）并引入了PixelWorld基准，该基准将自然语言、表格、数学和图表输入渲染到共享的像素空间中。多基准实验表明，PEAP在语义理解任务上与基于标记的方法具有可比的性能，表明视觉变换器可以部分捕获全局文本语义，而无需显式标记化。然而，在数学和代码等需要推理的任务中，表现有所下降，尽管通过填充值链思维提示可以减轻这一差距。进一步发现，当视觉和文本信息紧密结合时，将一切表示为像素简化了预处理并避免了跨模态的错位。PixelWorld因此提供了一个系统而实用的框架来评估统一的视觉-语言模型，并促进了基于像素的多模态学习的进一步探索。", "innovation": "PEAP（Perceive Everything as Pixels）被引入，这是一种新的交互方法，将文本、表格、数学和图表等类型的信息整合到一个共享的像素空间中，通过视觉变换器进行处理。利用这一基准，实验展示了视觉变换器在无需传统标记化的情况下可以部分捕捉到全局文本语义的能力。同时，提出了Chain-of-Thought提示来弥补符号结构缺失的差距。这些发现有助于理解如何更有效地处理视觉和文本信息的结合。", "conclusion": "整体而言，PixelWorld为评估统一的视觉-语言模型提供了一个系统和实用的框架。使用像素表示法简化了前期处理，并避免了跨模态的错位现象。虽然PEAP在一些推理任务上表现不如传统基于标记的方法，但通过Chain-of-Thought提示的改进可以得到改善。该研究为进一步研究基于像素的多模态学习提供了新的视角。"}
{"llm_update_time": "20251023", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2504.00939", "html_url": "https://arxiv.org/abs/2504.00939", "title": "WikiVideo: 多视频生成文章", "title_en": "WikiVideo: Article Generation from Multiple Videos", "authors": "Alexander Martin,Reno Kriz,William Gantt Walden,Kate Sanders,Hannah Recknor,Eugene Yang,Francis Ferraro,Benjamin Van Durme", "background": "当前的检索增强生成（RAG）工作流程主要侧重于文本，而现有的基于视频的总结方法主要集中在低级场景理解上而不是高级事件语义。这导致了将视频证据整合到RAG管道中的困难，限制了创建以多模态来源为基础的深度内容的能力。", "innovation": "作者提出了WikiVideo基准，其中包括由专家撰写的百科文章和详细注释的视频，提供文章断言的证据，促进了视频的整合到RAG管道中。此外，还提出了协作文章生成（CAG）方法，这是一种新颖的交互式方法，用于多视频的文章创建。CAG利用r1风格推理模型与VideoLLM的迭代交互，以低级视觉特征为重点，促进对目标事件的高层推理，取得了优于现有方法的性能，并为未来工作提出了有吸引力的方向。", "conclusion": "通过Benchmarking最先进的VideoLLMs和CAG，在Oracle检索和RAG设置中，CAG始终优于其他方法。文章展示了与视频相关的多模态增强合成文本领域的潜在方向和发展前景。"}
{"llm_update_time": "20251023", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2505.08727", "html_url": "https://arxiv.org/abs/2505.08727", "title": "记忆-压缩循环提高泛化能力", "title_en": "Memorization-Compression Cycles Improve Generalization", "authors": "Fangyuan Yu", "background": "本文证明了泛化不仅可以通过增加数据量来提高，还可以通过压缩内部表示来实现。研究了语言模型预训练过程中发生的记忆-压缩循环现象，并提出了Gated Phase Transition (GAPT) 训练算法来适应性地切换记忆和压缩阶段。", "innovation": "引入了Information Bottleneck Language Modeling (IBLM) 目标，将其语言建模重新定义为一个有约束的最优化问题：最小化表示熵同时保持最佳预测性能。提出了Gated Phase Transition (GAPT) 训练算法，能够适应性地在记忆和压缩阶段之间切换。该算法在GPT-2预训练FineWeb数据集上测试时，能够减少Matrix-Based Entropy (MBE) 50%并提高交叉熵4.8%，同时在模拟灾难性遗忘的场景中，减少了97%的表示干扰，提高了35%的跨数据泛化能力。", "conclusion": "记忆-压缩循环现象和GAPT训练算法有望显著提高语言模型的泛化能力和防止灾难性遗忘。"}
{"llm_update_time": "20251023", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2410.21228", "html_url": "https://arxiv.org/abs/2410.21228", "title": "LoRA与全参数微调：能力等同的错觉", "title_en": "LoRA vs Full Fine-tuning: An Illusion of Equivalence", "authors": "Reece Shuttleworth,Jacob Andreas,Antonio Torralba,Pratyusha Sharma", "background": "微调是将预训练的大规模语言模型适应下游任务的关键范式。最近，低秩适应（LoRA）等方法已被证明能够通过极大减少可训练参数来有效微调大语言模型。尽管LoRA在参数效率上具有显著优势，但它们学到的解决方案是否等同于全参数微调仍然是一个需要探讨的问题。本文研究了LoRA和全参数微调如何改变预训练模型的权重矩阵，通过分析模型权重矩阵的谱性质来回答这一问题。研究发现，LoRA和全参数微调产生的权重矩阵的奇异值分解存在显著差异：LoRA训练产生的权重矩阵包含新的、高阶奇异向量，名为“入侵维度”，而全参数微调训练的权重矩阵没有这些特征。此外，还发现LoRA遗忘的程度小于全参数微调，其遗忘仅局限于这些“入侵维度”，通过因果干预改变这些向量的奇异值可以导致模型遗忘。进一步地，压缩这些“入侵维度”可以显著提高预训练分布的建模能力，几乎不会牺牲下游任务的性能。这些发现表明，随着“入侵维度”的积累，LoRA的性能会恶化，尤其是在连续学习中会加剧遗忘现象，进一步证实了本文的研究发现的重要性。", "innovation": "本文通过分析预training模型的权重矩阵的谱性质，揭示了LoRA和全参数微调之间的关键差异。特别是发现了LoRA训练中的“入侵维度”，这些维度虽然可以提高模型的性能，但会随着训练的进行逐渐积累并导致遗忘，尤其是在连续学习中表现更为明显。此外，通过因果干预手段验证了“入侵维度”对遗忘的因果影响，并提出了通过压缩这些维度可以提高模型在预训练分布建模上的能力，这些发现提供了理论依据和实际指导。", "conclusion": "研究表明，LoRA虽然在参数效率上具有优势，但其实现的学习能力与全参数微调并不等同，主要原因是LoRA训练中的“入侵维度”会导致遗忘。因此，在继续学习以及多任务情况下，LoRA的表现可能会比全参数微调更差。这一发现强调了在大模型微调过程中需要谨慎处理这些“入侵维度”。"}
{"llm_update_time": "20251023", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2505.14489", "html_url": "https://arxiv.org/abs/2505.14489", "title": "推理模型更好地表达其信心", "title_en": "Reasoning Models Better Express Their Confidence", "authors": "Dongkeun Yoon,Seungone Kim,Sohee Yang,Sunkyoung Kim,Soyeon Kim,Yongil Kim,Eunbi Choi,Yireun Kim,Minjoon Seo", "background": "尽管大型语言模型（LLMs）在处理问题时表现出色，但它们在准确表达信心方面往往存在问题，这使得难以判断它们何时可能出错，从而限制了它们的可靠性。", "innovation": "本文展示了推理模型在进行较长的逻辑推理过程中不仅在解决问题上表现更好，还能够在准确表达其信心方面表现更优。通过在六个推理模型上进行六组数据集的测试，发现在33种情况中有36种情况下，推理模型展现了更严格的信心校准。研究还揭示了这一校准改进来源于推理模型中的缓慢思考行为（如探索替代方法和重新思考），这些行为使推理模型能够在逻辑推理过程中动态调整其信心，使其变得越来越准确。", "conclusion": "推理模型随着其逻辑推理过程的发展表现出了越来越准确的信心校准，而非推理模型没有这种趋势。移除逻辑推理过程中的缓慢思考行为会对校准产生显著的影响。此外，通过引导非推理模型进行缓慢思考，非推理模型也能表现出增强的信心校准。这表明缓慢思考是导致信心校准改进的唯一来源。"}
{"llm_update_time": "20251023", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2505.13878", "html_url": "https://arxiv.org/abs/2505.13878", "title": "InfiFPO：在大型语言模型中通过偏好优化实现隐式模型融合", "title_en": "InfiFPO: Implicit Model Fusion via Preference Optimization in Large Language Models", "authors": "Yanggan Gu,Yuanyi Wang,Zhaoyi Yan,Yiming Zhang,Qi Zhou,Fei Wu,Hongxia Yang", "background": "现有模型融合方法主要集中在监督微调（SFT）上，而偏好对齐（PA）对于提升LLM性能至关重要但尚未得到充分探索。虽然一些方法如WRPO利用源模型的响应输出而忽略概率信息，但这些方法忽视了复杂词汇对齐挑战，未充分利用概率信息。InfiFPO通过引入隐式模型融合的方法，使用融合后的源模型在序列级别合成多源概率来替换直接偏好优化（DPO）中的参考模型，从而避免复杂词汇对齐挑战，同时保留概率信息。此外，通过概率剪裁和最大差距融合策略，InfiFPO使枢轴模型能够与人类偏好对齐，并有效地从源模型中提取知识。", "innovation": "1. InfiFPO通过将融合后的源模型引入序列级别合成多源概率的方法，替换直接偏好优化中的参考模型，避免了复杂词汇对齐挑战，同时保留概率信息。\n2. 利用概率剪裁和最大差距融合策略，使枢轴模型能够更好地与人类偏好对齐，从而有效提取源模型知识。\n3. 通过一系列广泛的基准测试，InfiFPO在11个常用基准上始终优于现有模型融合和偏好优化方法，特别是在使用Phi-4作为枢轴模型时，平均性能提高显著，特别是在数学、编程和推理任务方面。", "conclusion": "InfiFPO通过偏好优化在大型语言模型中实现了隐式模型融合，解决了传统方法中存在的复杂词汇对齐挑战，并且在11个广泛使用的基准测试中表现出色，显著提高了模型在数学、编程和推理任务中的能力。"}
{"llm_update_time": "20251023", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2505.19955", "html_url": "https://arxiv.org/abs/2505.19955", "title": "MLR-Bench: 评估AI代理在开放机器学习研究中的性能", "title_en": "MLR-Bench: Evaluating AI Agents on Open-Ended Machine Learning Research", "authors": "Hui Chen,Miao Xiong,Yujie Lu,Wei Han,Ailin Deng,Yufei He,Jiaying Wu,Yibo Li,Yue Liu,Bryan Hooi", "background": "近年来，AI代理在科学发现方面的潜力得到了日益证明，特别是在机器学习领域。然而，缺乏一个能够综合评估AI代理在开放研究问题上的表现的基准工具。本文旨在填补这一空白。", "innovation": "本文提出了MLR-Bench，一个全面的基准测试框架，用于评估AI代理在开放机器学习研究中的性能。MLR-Bench 包含三个关键组件：1）来自 NeurIPS、ICLR 和 ICML 工作坊的201项研究任务，涵盖多元化的机器学习主题；2）MLR-Judge，一个结合LLM评审员和精心设计的评审标准的自动化评估框架，用于评估研究质量；3）MLR-Agent，一个模块化的代理框架，能够通过四个阶段完成研究任务：想法生成、提案表述、实验以及论文撰写。该框架支持在不同研究阶段的逐步评估，以及对最终研究报告的端到端评估。", "conclusion": "我们使用MLR-Bench评估了六种前沿的LLM和一个先进的编程代理，结果显示尽管LLM擅长生成连贯的想法和结构良好的论文，但当前的编程代理却经常产生虚假或无效的实验结果，这对科学研究的可靠性构成了重大障碍。我们通过人工评估验证了MLR-Judge的有效性，并开放源代码MLR-Bench，以便社区对AI研究代理进行基准测试、诊断和改进，以提高科学发现的可信度和透明度。"}
{"llm_update_time": "20251023", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2506.08800", "html_url": "https://arxiv.org/abs/2506.08800", "title": "衡量数据科学自动化：AI助手和智能体评估工具的综述", "title_en": "Measuring Data Science Automation: A Survey of Evaluation Tools for AI Assistants and Agents", "authors": "Irene Testini,José Hernández-Orallo,Lorenzo Pacchiardi", "background": "数据科学的目标是从数据中挖掘洞察以支持决策过程。近年来，大规模语言模型（LLMs）被用作数据科学助手，提供创意、技巧和小代码片段，或是数据结果的解释和报告。凭借具有代码执行和知识库等附加功能的大规模语言模型（LLMs）驱动的代理，可以实现部分数据科学活动的自动化，数据科学代理展示了一定程度的自主行动能力和与数字环境互动的能力。当前研究主要集中于特定目标活动的自动化，忽视了数据管理与探索性活动，并且评估主要集中在纯自动化或全自主智能体上，而没有涉及人机协作的不同层次。研究还倾向于关注人类替代，而忽视了通过任务转换实现更高层次自动化的可能性。", "innovation": "论文综述了评估数据科学领域中AI助手和智能体的工具，揭示了现有评估中存在的问题，包括活动范围的限制、评估层面的局限性以及忽视了任务转换的可能性。", "conclusion": "研究发现，现有的评估工具在数据管理和探索性活动方面关注不足，而且评估方法局限于纯自动或全自主智能体，忽视了不同层级的人机协作和通过任务转换实现的更高层次自动化。研究提出需要更多的评估工具来覆盖全面的数据科学活动范围，无论是在自动化程度还是在人机协作的方式上。"}
{"llm_update_time": "20251023", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2506.13579", "html_url": "https://arxiv.org/abs/2506.13579", "title": "离散扩散模型中的可变长度文本填充", "title_en": "Flexible-length Text Infilling for Discrete Diffusion Models", "authors": "Andrew Zhang,Anushka Sivakumar,Chiawei Tang,Chris Thomas", "background": "离散扩散模型是一种新型的文本生成器，相比自回归模型具有双向上下文利用、并行生成和灵活提示等优点。然而，它们在没有地面真实位置数据的情况下无法进行可变长度或可变位置的文本填充。", "innovation": "作者引入了DDOT（DDO（离散扩散）T（最优传输位置耦合）），这是首个能够克服这一挑战的离散扩散模型。DDOT在样本级别上利用了一种新颖的最优传输（OT）耦合，既可以保留令牌的相对顺序，又能动态调整填充段的位置和长度，这一能力此前在文本扩散中是缺失的。该方法与现有的离散文本扩散方法不冲突，并且可以与各种预训练的文本去噪器兼容。实验表明，DDOT在文本填充基准测试中优于简单的扩散基线，其性能与最先进的非自回归模型相当，并且能够显著提高训练效率和灵活性。", "conclusion": "DDOT在文本填充基准测试中表现出色，性能与最先进的非自回归模型相当，同时实现了训练效率和灵活性的显著提升。"}
{"llm_update_time": "20251023", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2506.10946", "html_url": "https://arxiv.org/abs/2506.10946", "title": "GUARD：大型语言模型中基于数据归因的引导式遗忘与保留", "title_en": "GUARD: Guided Unlearning and Retention via Data Attribution for Large Language Models", "authors": "Peizhi Niu,Evelyn Ma,Huiting Zhou,Duo Zhou,Huan Zhang,S. Rasoul Etesami,Olgica Milenkovic", "background": "大型语言模型（LLM）在合规性、版权保护和隐私问题方面的日益重要性使得模型重新学习变得越来越重要。然而，在LLM重新学习过程中，意外遗忘成为一个关键挑战，即移除特定数据时会无意间损害模型的整体效用和保留关键信息的能力。虽然先前研究主要集中在架构创新上，但数据层面因素对重新学习性能的影响尚未得到充分研究。因此，现有方法在删除高影响数据时往往会导致保留性能退化。", "innovation": "本文提出了一种新颖的框架GUARD，用于引导式遗忘与保留，通过数据归因。GUARD引入了一个针对LLM遗忘和保留的轻量级代理数据归因度量，该度量在计算效率的同时量化了“遗忘”集和“保留”集之间的对齐情况。通过重新分配遗忘权，GUARD减少了意外保留流失。同时，该框架提供了严谨的理论保证，表明GUARD在显著提高保留性能的同时，保留遗忘指标与前序方法相当。在TOFU和MUSE基准中的多次实验表明，当删除10%的训练数据时，GUARD可以将TOFU保留集的真实性比提高高达194.92%，并提高MUSE NEWS保留集的知识保留16.20%，同时与最先进的方法相比，隐私损失增加的较少或适度。", "conclusion": " GUARD框架通过引入一个轻量级的代理数据归因度量，并根据样本的数据归因得分分配适应性和非均匀遗忘权重，有效解决了LLM重新学习中的意外遗忘问题，改善了知识保留，同时保持了合理的隐私损失。"}
{"llm_update_time": "20251023", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2506.16962", "html_url": "https://arxiv.org/abs/2506.16962", "title": "Chiron-o1: 通过导师-实习生协作搜索促进多模态大型语言模型在可迁移医学推理方面的发展", "title_en": "Chiron-o1: Igniting Multimodal Large Language Models towards Generalizable Medical Reasoning via Mentor-Intern Collaborative Search", "authors": "Haoran Sun,Yankai Jiang,Wenjie Lou,Yujie Zhang,Wenjie Li,Lilong Wang,Mianxin Liu,Lei Liu,Xiaosong Wang", "background": "多模态大型语言模型（MLLMs）已经开始在通用任务中展现出稳健的推理能力，但它们在医疗领域的应用仍处于起步阶段。构建带有思考链（CoT）的训练数据是增强医疗MLLMs推理能力的重要手段。现有的方法在寻找和评估有效推理路径（尤其是至关重要的诊断推理路径）方面存在不足。为了应对这一挑战，本文提出了Mentor-Intern Collaborative Search（MICS）方法，这是一种新颖的推理路径搜索方案，用于生成严格的医学CoT数据。", "innovation": "提出了Mentor-Intern Collaborative Search（MICS）方法，这是一种新颖的推理路径搜索方案，通过导师模型逐步初始化推理，再由实习生模型继续沿这些路径思考，并最终选择多个实习生模型的整体推理表现最优的推理路径。同时，构建了多任务医学推理数据集MMRP（具有分级难度）和新型医疗MLLM Chiron-o1，该模型通过课程学习策略训练，具备稳健的多模态视觉问答和高度可泛化的推理能力。", "conclusion": "Chiron-o1在我们的MICS构建的CoT数据集上进行训练，展示了在多项医学视觉问答与推理基准测试中的最先进水平。相关代码可从该链接下载：this https URL"}
{"llm_update_time": "20251023", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.02511", "html_url": "https://arxiv.org/abs/2508.02511", "title": "Test-time Prompt Intervention", "title_en": "Test-time Prompt Intervention", "authors": "Chenxu Yang,Qingyi Si,Mz Dai,Dingyu Yao,Mingyu Zheng,Minghui Chen,Zheng Lin,Weiping Wang", "background": "近年来，测试时计算在大规模语言模型（LLM）领域取得了显著的成果，特别是在复杂任务中，此类模型通过生成更长的思维链（CoTs）来提升推理能力。然而，越来越多的证据表明，这些推理模型经常产生冗余的思维链，包括不必要的验证步骤和重复的推理转变。问题根源在于这些模型在训练后过度依赖结果奖励机制，而用于调节中间推理步骤的过程奖励数据难以大规模构建。", "innovation": "本文提出了一种新的框架——Test-time Prompt Intervention（PI）。PI提供了一个动态引导和调节推理路径的接口，通过及时（When模块）和适当（How模块）干预以及干预后的采样（Which模块），将人类问题解决经验和认知科学原理无缝整合到LLM的推理过程中，从而提高了可控制性和可解释性。", "conclusion": "在多个模型和数据集上的广泛实验表明，PI显著缩短了思维链的长度，并减少了幻觉现象，产生了更加简洁和可靠的理由。"}
{"llm_update_time": "20251023", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2506.23670", "html_url": "https://arxiv.org/abs/2506.23670", "title": "通过知识精炼实现高效交错语音建模", "title_en": "Efficient Interleaved Speech Modeling through Knowledge Distillation", "authors": "Mohammadmahdi Nouriborji,Morteza Rohanian", "background": "当前语音语言模型超出了许多部署环境的尺寸和延迟限制。本文探讨了如何通过层对齐的知识精炼来构建紧凑而有表现力的语音生成模型，从而压缩大型多模态变换器，同时保持性能的最小损失。研究发现，通过知识精炼，可以将大型多模态变换器压缩3倍左右。", "innovation": "提出了TinyWave模型家族，这是一种2亿参数的模型，在5万小时公共音频上进行训练，用于语音到语音和交错语音-文本生成。TinyWave支持（i）仅语音生成，使用音素或表达性标记；（ii）语音-文本混合连续生成。在Libri-Light上的评估表明，TinyWave在标准困惑度上仅比其教师高出1.4个点。在有声故事推理和SALMon上的准确性分别达到教师的93%-97%，并优于尺寸匹配的基线。这些模型针对通常硬件进行了优化，适合实时对话代理、辅助技术以及资源有限的环境应用。", "conclusion": "这些模型经过优化，可以在常规硬件上部署，使得它们能够被应用到实时对话代理、辅助技术和资源有限的环境中。研究还发布了模型、训练代码和评估脚本，以支持紧凑、有表现力的语音生成的可重复研究。"}
{"llm_update_time": "20251023", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.15020", "html_url": "https://arxiv.org/abs/2510.15020", "title": "覆盖原则：预训练如何促进后训练", "title_en": "The Coverage Principle: How Pre-Training Enables Post-Training", "authors": "Fan Chen,Audrey Huang,Noah Golowich,Sadhika Malladi,Adam Block,Jordan T. Ash,Akshay Krishnamurthy,Dylan J. Foster", "background": "语言模型在大规模文本语料库预训练后，通过特定任务微调能够表现出显著的能力，但预训练对最终模型成功的影响机制仍然不甚清楚。通常，预训练的成功通过交叉熵损失来量化，但交叉熵并不能很好地预测下游性能。研究者通过引入‘覆盖’的概念，提供了一种新的理论视角来理解预训练与下游性能之间的关系。", "innovation": "研究者提出了‘覆盖原则’，揭示了下一个令牌预测（以最大似然为核心）实际上是在对具有良好覆盖的模型进行优化。研究发现覆盖比交叉熵更具有泛化性，能够避免对特定问题参数（如序列长度）的依赖。研究还提出了一套提高覆盖的实际算法干预措施，包括模型/检查点选择程序、梯度规范化方案以及测试时解码策略。这些方法具有可证明的改进效果。", "conclusion": "研究深入理解了覆盖原则并提供了一种新的机制解释了下一个令牌预测如何隐式优化以适应具有良好覆盖的模型，同时提出了一系列改进覆盖的方法，为提高模型性能提供了新的视角和策略。"}
{"llm_update_time": "20251023", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.00890", "html_url": "https://arxiv.org/abs/2508.00890", "title": "AgentTTS：复杂任务中用于测试时计算最优分配策略的大语言模型代理", "title_en": "AgentTTS: Large Language Model Agent for Test-time Compute-optimal Scaling Strategy in Complex Tasks", "authors": "Fali Wang,Hui Liu,Zhenwei Dai,Jingying Zeng,Zhiwei Zhang,Zongyu Wu,Chen Luo,Zhen Li,Xianfeng Tang,Qi He,Suhang Wang", "background": "现有研究主要关注单阶段任务中的测试时间计算扩展（TTS），但许多实际问题涉及多阶段复杂任务，这些任务由一系列异构子任务组成，每个子任务需要特定能力的大语言模型（LLM）。这导致了一个新的问题：在多阶段复杂任务中实现测试时间计算最优化分配。在这个问题中，模型和预算分配的组合搜索空间以及高成本的推理使得暴力搜索不可行；同时，子任务之间的最优模型和预算分配相互依赖，增加了计算最优化搜索的复杂性。研究者们提出了一系列实验，发现了三条经验洞察，这些洞察揭示了LLM在多阶段复杂任务中的行为特征，并基于这些洞察，提出了AgentTTS框架，该框架利用迭代反馈驱动的与执行环境交互实现了自动探索计算最优分配。实验结果表明，AgentTTS在搜索效率、对训练集规模变化的鲁棒性和解释性方面都优于传统和基于LLM的竞争基准方法。", "innovation": "提出了AgentTTS框架，这是一种基于大语言模型代理的方法，能够在多阶段复杂任务中自主搜索计算最优的模型和预算分配。该方法通过迭代反馈驱动的与执行环境的交互来实现自动搜索。它显著提高了搜索效率，展示了对训练集规模变化的鲁棒性，并增强了解释性。", "conclusion": "AgentTTS框架在多阶段复杂任务中实现测试时间计算最优分配具有显著优势，相比于传统方法和基于大语言模型的竞争基准方法，在搜索效率、鲁棒性和解释性方面表现突出。"}
{"llm_update_time": "20251023", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2505.24379", "html_url": "https://arxiv.org/abs/2505.24379", "title": "未被遗忘却未被删除：LLM中精确删除后的数据提取", "title_en": "Unlearned but Not Forgotten: Data Extraction after Exact Unlearning in LLM", "authors": "Xiaoyu Wu,Yifei Pang,Terrance Liu,Zhiwei Steven Wu", "background": "大型语言模型通常在包含网络收集的数据的集合上进行训练，这些数据可能无意中包含有害或敏感的个人信息。为了避免隐私问题，提出了删除方法来从已训练模型中移除特定数据的影响。其中，精确删除--即从目标数据中重新训练模型--通常被认为是缓解部署隐私风险的最优方法。本文在开放权重情况下探讨了这一假设，在这种情况下，预删除和后删除的对数API都会被暴露，我们利用这种场景重新审视了精确删除的方法，发现了新的数据提取攻击，通过这种方法可以显著提高提取成功率，并揭示了在真实部署中精确删除可能增加隐私泄露风险的问题。", "innovation": "本文引入了一种新的数据提取攻击，该攻击利用了预删除模型的信号来引导后删除模型，揭示了被删除数据的模式。结合模型指导和标记过滤策略，这种攻击在MUSE、TOFU和WMDP等常见基准测试中显著提高了提取成功率，在某些情况下性能提高了两倍。此外，本文还通过一个模拟的医疗诊断数据集展示了这种攻击的有效性，强调了精确删除方法在实际部署中可能带来的隐私泄露风险，提出在评估删除方法时需要考虑更广泛的威胁模型，以不仅仅考虑后删除模型，还要考虑对手对先前检查点的访问。", "conclusion": "我们的发现表明，尽管精确删除旨在维护隐私，但在实际部署中可能会意外增加隐私泄露的风险。针对这一问题，建议在评估删除方法时考虑更广泛的威胁模型，不仅要考虑后删除模型，还要考虑对先前检查点的对手访问。同时公开了代码以供进一步研究。"}
{"llm_update_time": "20251023", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.20228", "html_url": "https://arxiv.org/abs/2508.20228", "title": "Robustness Assessment and Enhancement of Text Watermarking for Google's SynthID", "title_en": "Robustness Assessment and Enhancement of Text Watermarking for Google's SynthID", "authors": "Xia Han,Qi Li,Jianbing Ni,Mohammad Zulkernine", "background": "最近，诸如Google DeepMind的SynthID-Text等大型语言模型（LLM）水印方法为追踪AI生成文本的来源提供了有前景的解决方案。然而，我们的鲁棒性评估表明，SynthID-Text在面对如改写、复制粘贴修改和反向翻译等保留意义的攻击时存在脆弱性，这会严重影响水印的可检出性。", "innovation": "为解决这些限制问题，我们提出了SynGuard，这是一种结合了语义信息检索（SIR）的语义对齐强度和SynthID-Text的概率水印机制的混合框架。我们的方法在词汇和语义两个级别联合嵌入水印，这使我们能够在保持原始意义的同时实现稳健的来源追踪。实验结果显示，在多种攻击场景下，SynGuard的水印恢复平均提高11.1%的F1得分，与SynthID-Text相比更有效。这些发现证实了在实际篡改场景下具有语义意识的水印方法的有效性。所有代码、数据集和评估脚本均可在：this https URL 公开使用。", "conclusion": "本研究通过提出SynGuard方法，结合语义对齐和语义感知的水印机制，提高了AI生成文本来源追踪的鲁棒性和稳健性，同时也保持了原始文本的意义。实验结果验证了语义感知水印方法在实际攻击场景下的有效性，并提供了评估脚本和所有相关材料。"}
{"llm_update_time": "20251023", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.15061", "html_url": "https://arxiv.org/abs/2510.15061", "title": "Antislop：一种用于识别和消除语言模型中重复模式的综合框架", "title_en": "Antislop: A Comprehensive Framework for Identifying and Eliminating Repetitive Patterns in Language Models", "authors": "Samuel Paech,Allen Roush,Judah Goldfeder,Ravid Shwartz-Ziv", "background": "大规模语言模型（LLM）的广泛应用引入了一种特征性的重复词汇模式，被称为“slop”，这种模式降低了输出质量并使得AI生成的文本容易辨认。", "innovation": "文章提出了一种名为Antislop的综合框架，提供了检测和消除这些过度使用的模式的工具。该框架包含三个创新点：1）Antislop采样器，在推理时通过回溯不删除词汇表来抑制不需要的字符串；2）自动流水线，根据模型特定的slop与人类基线对比生成训练数据；3）最终标记偏好优化（FTPO），一种新颖的微调方法，通过个体标记进行细微调整，手术式调整概率分布。研究表明，一些slop模式在LLM输出中的频率比人类文本高1,000多倍。Antislop采样器成功抑制了8,000多个模式并保持了质量，而标记禁用在仅有2,000时变得不可用。最显著的是，FTPO实现了90%的slop减少，并在包含GSM8K、MMLU和创意写作任务的跨域评估中保持或提高了性能。相比之下，DPO在取得较弱抑制的同时，在写作质量和词汇多样性方面遭受了显著的退化。", "conclusion": "Antislop框架通过结合Antislop采样器、自动流水线和FTPO方法，有效地减少了重复模式，并在跨域评估中显示出更好的性能，同时提供了代码和结果开源。"}
{"llm_update_time": "20251023", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.18935", "html_url": "https://arxiv.org/abs/2510.18935", "title": "遥感数据分析中的降维方法与应用：一项系统综述", "title_en": "Dimensionality Reduction for Remote Sensing Data Analysis: A Systematic Review of Methods and Applications", "authors": "Nathan Mankovich,Kai-Hendrik Cohrs,Homer Durand,Vasileios Sitokonstantinou,Tristan Williams,Gustau Camps-Valls", "background": "地球观测涉及收集、分析和处理日益增长的数据量。自动提取信息对于解决环境监测、城市规划和灾害管理等重要社会、经济和环境挑战至关重要。然而，这些数据的高维度带来了稀疏性、低效性和维数灾难等问题，限制了机器学习模型的有效性。降维技术，尤其是特征提取，通过保留数据的基本属性同时减少复杂性，增强数据压缩、清洗、融合、可视化、异常检测和预测等任务，来应对这些挑战。该综述旨在利用降维技术在整个遥感数据价值链上发挥其优势，识别未充分探索的降维算法及其在未来研究中的应用机会。", "innovation": "本文提供了一项系统综述，专注于降维技术在遥感数据分析中的应用，并且识别出未充分利用的降维算法及其未来研究的机会。这项研究有助于更好地理解降维技术在实际应用中的潜力和挑战。", "conclusion": "本文总结了降维技术在遥感数据价值链中的应用，提供了降维方法的指南，并识别出未来研究的潜在机会。"}
{"llm_update_time": "20251023", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.17947", "html_url": "https://arxiv.org/abs/2510.17947", "title": "PLAGUE：插拔式框架，用于终身适应性生成多轮攻击", "title_en": "PLAGUE: Plug-and-play framework for Lifelong Adaptive Generation of Multi-turn Exploits", "authors": "Neeladri Bhuiya,Madhav Aggarwal,Diptanshu Purwar", "background": "随着大型语言模型（LLMs）的发展，多轮对话已成为与LLMs交互的主流方式，用于完成复杂任务。然而，尽管LLM的能力在不断提高，它们在多轮对话场景中变得越来越容易被劫持，特别是在有害意图可以通过对话中的细微注入来进行渗透的情况下。虽然已经对单轮攻击进行了广泛的研究，但它们在多轮攻击中的适应性、效率和有效性依然是重要的挑战。针对这些空白，提出了PLAGUE，这是一种受终身学习代理启发的插拔式框架，专门设计用于多轮攻击的生成。", "innovation": "PLAGUE 是一种全新的插拔式框架，通过对多轮攻击的生命周期进行精心设计的三个阶段（引导、规划和完成）的划分，实现了对多轮攻击家族的系统性和信息丰富的探索。实验结果表明，使用PLAGUE设计的对抗代理在多个领先模型中实现了最先进的反向插桩结果，攻击成功率（ASR）提高了30%以上，在有限或相当的查询预算下。特别地，PLAGUE使OpenAI的o3模型和Claude的Opus 4.1模型在基于StrongReject的ASR方面分别达到了81.4%和67.3%，这表明这些被认为高度抵抗反向插桩的模型也受到了攻击的严重挑战。", "conclusion": "我们的工作提供了工具和见解，以更好地理解计划初始化的重要性、上下文优化以及终身学习在构建多轮攻击以全面评估模型漏洞方面的作用。"}
{"llm_update_time": "20251023", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.18976", "html_url": "https://arxiv.org/abs/2510.18976", "title": "Ninja Codes: Neurally Generated Fiducial Markers for Stealthy 6-DoF Tracking", "title_en": "Ninja Codes: Neurally Generated Fiducial Markers for Stealthy 6-DoF Tracking", "authors": "Yuichiro Takeuchi,Yusuke Imoto,Shunya Kato", "background": "传统的递归结构标记器在室内外环境中广泛应用，但它们在自然环境中往往显得突兀，不利于美观和用户的接受。因此，对于需要隐秘、自然融入各种环境的场景，需要一种创新的解决方案来替代现有的标记系统，以实现精确的位置跟踪和识别。", "innovation": "该论文提出了一种新颖的神经生成标志物——Ninja Codes。Ninja Codes通过神经网络将任意图像转换为可与现实世界环境自然融合的标志物。编码器网络对图像进行适度的视觉调整，生成的代码可以在普通打印纸上打印并粘贴在表面，用于AR、机器人、基于运动的用户界面等多种应用中提供隐蔽的6自由度位置跟踪。这种标志物可以使用标准彩色打印机和任何配备现代RGB摄像头的设备来创建和检测，无需额外的硬件支持。", "conclusion": "实验表明，Ninja Codes能够在常见室内照明条件下提供可靠的6自由度位置跟踪。同时，它们能够成功地藏身于各种环境纹理中，隐藏痕迹以实现隐秘的藏踪。作者认为，这将特别是在那些由于视觉原因不宜使用传统显眼的递归结构标记器的情景中提供特别的价值。"}
{"llm_update_time": "20251023", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.18876", "html_url": "https://arxiv.org/abs/2510.18876", "title": "Grasp Any Region:向多模态大语言模型提供精准的具语境像素理解", "title_en": "Grasp Any Region: Towards Precise, Contextual Pixel Understanding for Multimodal LLMs", "authors": "Haochen Wang,Yuhao Wang,Tao Zhang,Yikang Zhou,Yanwei Li,Jiacong Wang,Jiani Zheng,Ye Tian,Jiahao Meng,Zilong Huang,Guangcan Mai,Anran Wang,Yunhai Tong,Zhuochen Wang,Xiangtai Li,Zhaoxiang Zhang", "background": "多模态大型语言模型（MLLMs）在整体理解方面表现出色，但在处理充满复杂场景的密集世界时却存在困难，尤其在细微分析复杂细节和对象间关系方面效果不佳。区域级别的MLLMs是迈出的重要一步，但现有方法通常专注于理解给定区域而忽视整体语境。本文旨在解决这一问题，提出了一种新的方法，即Grasp Any Region (GAR)，通过引入RoI对齐的特征重复技术，GAR可以准确感知并支持多种提示之间的交互，从而实现高级组合推理，能够回答关于任何区域的特定自由形式问题，将方法从被动描述转变为积极对话。此外，GAR-Bench的构建不仅提供更准确的单一区域理解评估，还衡量了多个区域间的交互和复杂的推理能力，从而进行更全面的评估。", "innovation": "GAR方法通过引入RoI对齐的特征重复技术，支持精确感知和多种提示间的交互，实现了高级组合推理，能够回答关于任何区域的特定自由形式问题，增强了解题模式，从被动描述转变为积极对话。同时，GAR-Bench的构建有助于更精确地评估单一区域的理解能力，衡量了跨多个区域的交互和复杂推理能力。实验结果显示，GAR不仅保持了最先进的描述能力，还在多个基准测试中表现出色，特别是对于多提示之间的关系建模能力，甚至在某些情况下超过了大尺寸模型的性能。", "conclusion": "GAR-1B在保持最先进的描述能力的同时，还展示了其在处理多提示间关系方面的高级理解和推理能力，甚至在某些情况下超过了大尺寸模型的表现。GAR-8B的零样本性能超越了专门针对视频理解的模型，证明了其广泛的适用性和可迁移性。"}
{"llm_update_time": "20251023", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.19022", "html_url": "https://arxiv.org/abs/2510.19022", "title": "MoAlign: 以运动为中心的表示对齐用于视频扩散模型", "title_en": "MoAlign: Motion-Centric Representation Alignment for Video Diffusion Models", "authors": "Aritra Bhowmik,Denis Korzhenkov,Cees G. M. Snoek,Amirhossein Habibian,Mohsen Ghafoorian", "background": "文本到视频的扩散模型能够生成高质量的视频，但往往无法生成时空连贯且物理上合理的运动。造成这一问题的原因是模型对于自然视频中复杂的运动理解不足。现有工作的解决方法是将扩散模型特征与预训练视频编码器的特征对齐，然而这种方法将视频外观和动态混合在一起，导致对齐效果有限。", "innovation": "本文提出了一个以运动为中心的对齐框架，从预训练的视频编码器中学习一个解缠的运动子空间。该子空间优化预测真实光学流，确保捕捉到真正的运动动态。然后，将文本到视频扩散模型的潜在特征与这一新子空间对齐，使生成模型能够内化运动知识并生成更可信的视频。", "conclusion": "我们的方法提高了最先进的视频扩散模型的物理常识性，同时保持对文本提示的遵守。实验评价在VideoPhy、VideoPhy2、VBench、VBench-2.0以及用户研究中得到验证。"}
{"llm_update_time": "20251023", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.19001", "html_url": "https://arxiv.org/abs/2510.19001", "title": "通过元数据指导的上下文和任务特定提示实现稳健的驾驶问答", "title_en": "Robust Driving QA through Metadata-Grounded Context and Task-Specific Prompts", "authors": "Seungjun Yu,Junsung Park,Youngsun Lim,Hyunjung Shim", "background": "该论文介绍了一种两阶段的视觉-语言问答系统，用于自动驾驶领域，能够回答高层次的感知、预测和规划问题。在此之前，可能已经有很多针对自动驾驶的视觉-语言模型的工作，但尚未针对高阶的感知、预测和规划问题进行专门设计和验证，同时有效利用上下文和元数据进行任务特定的提示也没有得到充分探索。本研究正是在这一背景下提出了新的解决方案，以提升自动驾驶中的视觉-语言模型的性能和可靠性，在充满挑战的视觉环境下的准确率为96%。", "innovation": "1. 两阶段的方法，第一阶段使用大型的多模态大语言模型（Qwen2.5-VL-32B），结合多视角的输入、短时间窗口的历史信息以及链式思考的提示。第二阶段增加了nuScenes场景的元数据和任务特定的提示，以提高模型在特定任务上的回答精度。\n2. 自洽一致性算法的应用，通过多次采样的推理链路提高答案的可靠性。\n3. 显著优于基线模型Qwen2.5，在无提示情况下从62.61%提升到有5帧历史信息和10次提示下的66.85%，并最终达到67.37%的准确率，尤其是在存在严重视觉损坏的情况下，仍能保持96%的高准确率。", "conclusion": "本研究证明，精心设计的任务特定提示和上下文关联可以大大增强预训练的视觉-语言模型在自动驾驶高层次问答中的性能。该系统在驾驶QA基准测试中表现优秀，并在充满挑战的视觉环境中保持了高度的准确性和可靠性。未来工作可以进一步探索如何将这种模型应用到实际的自动驾驶应用场景中，并进一步提升其准确性和效率。"}
{"llm_update_time": "20251023", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.19078", "html_url": "https://arxiv.org/abs/2510.19078", "title": "UniHPR: 统一人体姿势表示通过奇异值对比学习", "title_en": "UniHPR: Unified Human Pose Representation via Singular Value Contrastive Learning", "authors": "Zhongyu Jiang,Wenhao Chai,Lei Li,Zhuoran Zhou,Cheng-Yen Yang,Jenq-Neng Hwang", "background": "近年来，多模态对齐管道的发展引起了广泛兴趣，其目的是从不同的模态中生成统一的表示，以促进多模态融合和生成。人体姿势表示在多个下游任务中至关重要，如人体姿态估计、动作识别、人机交互、目标跟踪等，可以从图像、2D关键点、3D骨架、网格模型等多种模态中提取人体姿势表示。然而，使用对比学习框架研究所有模态表示之间的关联性实例有限。", "innovation": "该论文提出了UniHPR，一种统一的人体姿势表示学习管道，该管道同时对齐来自图像、2D和3D人体姿态的表示。为了实现多模态同时对齐，提出了基于奇异值的对比学习损失，更好地对齐不同模态，进一步提升性能。", "conclusion": "通过简单的3D人体姿态解码器，UniHPR在Human3.6M数据集上达到了令人瞩目的性能指标：MPJPE为49.9毫米，在3DPW数据集上实现了交叉领域的评估，PA-MPJPE为51.6毫米。同时，使用统一的人体姿态表示，在Human3.6M数据集上实现了2D和3D姿态检索，检索误差为9.24毫米的MPJPE。"}
{"llm_update_time": "20251023", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.19003", "html_url": "https://arxiv.org/abs/2510.19003", "title": "Δt-Mamba3D: 一种时间感知的时空状态空间模型用于乳腺癌风险预测", "title_en": "$Δ$t-Mamba3D: A Time-Aware Spatio-Temporal State-Space Model for Breast Cancer Risk Prediction", "authors": "Zhengbo Zhou,Dooman Arefan,Margarita Zuley,Shandong Wu", "background": "纵向分析序列放射影像受制于一个基本的数据挑战：如何有效地建模在不规则时间间隔下捕获的高分辨率影像序列。当前的方法未能充分利用这些数据结构中的空间和时间线索。现有的模型往往通过三种方式妥协：一是将空间信息压缩成向量；二是应用计算效率低且不适用于非均匀时间步长的时空模型；三是通过忽视时间差异直接进行状态转换。", "innovation": "我们通过引入Time-Aware Δt-Mamba3D，一种新的时间感知状态空间架构，解决了这一挑战。该模型同时编码了不规则的访间间隔和丰富的时空上下文，同时保持了计算效率。其核心创新在于一个连续时间选择性扫描机制，该机制明确地将每项检查之间的真实时间差异整合到其状态转换中。此外，该模型还包含一个多尺度3D邻域融合模块，可以稳健地捕捉时空关系。", "conclusion": "在使用序列筛查乳房X光片进行乳腺癌风险预测的全面基准测试中，该模型表现出色，验证c指数提高了2-5个百分点，并在1-5年AUC评分方面优于现有的循环、变压器和状态空间模型的变体。得益于其线性复杂度，该模型能够有效地处理长而复杂的患者乳房X光片筛查历史记录，为纵向图像分析提供了一种新的框架。"}
{"llm_update_time": "20251023", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.19060", "html_url": "https://arxiv.org/abs/2510.19060", "title": "PoSh: 使用场景图引导LLMs-as-a-Judge进行精细图像描述", "title_en": "PoSh: Using Scene Graphs To Guide LLMs-as-a-Judge For Detailed Image Descriptions", "authors": "Amith Ananthram,Elias Stengel-Eskin,Lorena A. Bradford,Julia Demarest,Adam Purvis,Keith Krut,Robert Stein,Rina Elster Pantalony,Mohit Bansal,Kathleen McKeown", "background": "视觉语言模型（VLMs）在详细图像描述方面取得了长足的进步，但评估仍面临挑战。传统指标（如CIDEr、SPICE）设计用于短文本，侧重于识别现在不常见的错误，例如对象误识别。在长文本中，更敏感于属性和关系的连接以及能够定位具体文本错误的分数是最需要的。本文聚焦于改进这一领域的评估方法，提出了PoSh，一种新型的评估指标，使用结构化的场景图作为评分标准，可以指导LLM进行评分，使评分结果更细化，能反映组合理解错误。", "innovation": "引入了PoSh，一种基于场景图的评估指标，用于指导LLMs进行详细图像描述评分。相比现有指标（包括GPT4o-as-a-Judge），PoSh更具可复制性和解释性，是更接近人类评分的代理指标。此外，还引入了DOCENT数据集，包含了艺术作品及其专家撰写参考和模型生成描述，还附加了艺术史学生对它们质量的细致和总体判断。通过此数据集，既评估了详细图像描述评分标准，也评估了详细图像描述本身在新领域的表现。", "conclusion": "PoSh在DOCENT中的相关性更强（Spearman ρ为+0.05），且对图像类型具有鲁棒性，能作为有效的奖励函数，超越标准监督微调。使用PoSh评估开放和闭合模型在DOCENT中的表现，发现基础模型难以全面、无误地覆盖具有丰富场景动态的图像。通过PoSh和DOCENT，期望推动重要领域如辅助文本生成的进步。"}
{"llm_update_time": "20251023", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.19109", "html_url": "https://arxiv.org/abs/2510.19109", "title": "基于注意力机制的3D U-Net架构和数字图像处理在脑肿瘤分割中的进展", "title_en": "Advancing Brain Tumor Segmentation via Attention-based 3D U-Net Architecture and Digital Image Processing", "authors": "Eyad Gad,Seif Soliman,M. Saeed Darweesh", "background": "近年来，人工智能在医学诊断领域的快速发展极大地推动了脑肿瘤分割的准确性和效率。传统的编码-解码架构，如U-Net，通过有效提取磁共振成像（MRI）扫描中的3D脑肿瘤段区域的有意义表示，发挥了重要作用。然而，标准的U-Net模型在处理不规则形状和模糊边界时难以准确分割肿瘤区域。此外，训练高质量MRI数据的鲁棒性分割模型（如BraTS数据集）需要大量的计算资源，且常常面临类别不平衡的问题。", "innovation": "本文提出了将注意力机制集成到3D U-Net模型中，使模型能够捕捉细节并优先处理信息丰富的区域，在分割过程中。此外，借助基于数字图像处理技术的肿瘤检测算法，解决了训练数据不平衡带来的问题，减少了偏差。通过在BraTS 2020数据集上使用多种性能指标对所提出模型进行了全面评估和评估，结果表明所提出的模型优于相关研究，显著提高了脑肿瘤分割的性能。", "conclusion": "基于提出的3D U-Net模型的改进脑肿瘤分割方法，在BraTS 2020数据集上的结果表明，可以看到提高的分割性能，包括Dice系数为0.975，特异性为0.988，敏感性为0.995，这表明该模型在提高脑肿瘤分割的临床诊断可靠性方面具有潜在的重要应用价值。"}
{"llm_update_time": "20251023", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.19118", "html_url": "https://arxiv.org/abs/2510.19118", "title": "使用带有注意力机制和FedProx的U-Net模型进行乳腺癌分割的新型方法", "title_en": "A Novel Approach to Breast Cancer Segmentation using U-Net Model with Attention Mechanisms and FedProx", "authors": "Eyad Gad,Mustafa Abou Khatwa,Mustafa A. Elattar,Sahar Selim", "background": "乳腺癌是全球女性的主要死因，因此早期检测和准确诊断至关重要。超声成像是一种可靠且成本效益高的工具，用于此目的。然而，医疗数据的高度敏感性使得开发准确且私密的人工智能模型具有挑战性。联邦学习（Federated Learning）作为一种有望在敏感医疗数据上进行分布学习的技术，可以保护患者隐私。但在处理非独立且非同分布（non-IID）的地方数据集时，训练模型的准确性和泛化能力会受到影响，这对准确的肿瘤边界划分非常重要。因此，研究旨在通过应用联邦近邻（FedProx）方法来处理非IID超声乳腺癌影像数据集的挑战，并通过引入含有注意力机制的U-Net模型提高肿瘤分割的准确性。", "innovation": "本研究通过应用FedProx方法和改进的带有注意力机制的U-Net模型，解决了非IID地方数据集训练模型的准确性和泛化能力低的问题。结果展示了这种新方法在保持患者隐私的情况下提升肿瘤分割准确性。", "conclusion": "本研究的方法在全局模型中实现了96%的准确率，证明了FedProx方法在训练非IID地方医疗数据集上的精确机器学习模型方面的潜力。我们的研究结果表明，FedProx可能是一种在非IID地方医疗数据集上训练精确机器学习模型的有前景的方法。"}
{"llm_update_time": "20251023", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.19170", "html_url": "https://arxiv.org/abs/2510.19170", "title": "FootFormer: 从视觉输入估计稳定性", "title_en": "FootFormer: Estimating Stability from Visual Input", "authors": "Keaton Kraiger,Jingjing Li,Skanda Bharadwaj,Jesse Scott,Robert T. Collins,Yanxi Liu", "background": "当前，现有的方法通常是从视觉输入中单独预测人体运动动力学中的部分指标，例如脚压分布、脚接触图或质心。然而，这些方法在估计经典运动学指标中的关键稳定性预测组件（如质心、重心和支撑基底部）方面表现出较差的性能。", "innovation": "本文提出了一种跨模态方法——FootFormer，该方法可以直接从视觉输入中联合预测人体运动动力学。FootFormer在多项数据集上表现出卓越的性能，能够统计上显著地更好地或与现有方法等效地估计脚压分布、脚接触图和质心等关键指标，并且在估计经典运动学指标中的稳定性预测组件（如质心、重心和支撑基底部）方面达到了SOTA水平。", "conclusion": "通过引入FootFormer方法，该研究不仅提高了对关键人体运动学指标的估计精度，还推动了在无辅助设备的自然环境中实时评估人体稳定性的发展。"}
{"llm_update_time": "20251023", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.19150", "html_url": "https://arxiv.org/abs/2510.19150", "title": "X-Ego: 通过跨主观对比视频表示学习获取团队级别的战术情况意识", "title_en": "X-Ego: Acquiring Team-Level Tactical Situational Awareness via Cross-Egocentric Contrastive Video Representation Learning", "authors": "Yunzhe Wang,Soham Hans,Volkan Ustun", "background": "人类团队战术源自每位队员的个人视角以及他们预测、解释和适应队友意图的能力。尽管视频理解的进步提高了运动团队互动的建模，但大多数现有研究依赖第三方广播视角，忽视了多智能体学习的同步和主观特性。该研究利用基于《CS:GO》的X-Ego-CS数据集，旨在提高多智能体决策在复杂3D环境中的研究，该数据集包含了45场高水平比赛的124小时游戏录像，提供了跨主观视角，同步捕捉所有玩家的一人称视角及其状态-动作轨迹。", "innovation": "研究引入了X-Ego-CS数据集，包含《CS:GO》的一系列比赛录像，旨在促进复杂3D环境下的多智能体决策研究。研究还提出了跨主观对比学习（CECL），这是一种将队友的主观视觉流对齐的方法，以培养从个人角度出发的团队战术意识。研究通过队友和对手位置预测任务评估了CECL的有效性，展示了其在使用最新视频编码器从单一一人称视角推测队友和对手位置方面的效果。", "conclusion": "X-Ego-CS和CECL共同建立了跨主观视角多智能体基准测试的基础。更广泛地说，这项工作将游戏理解定位为多智能体建模和战术学习的测试平台，并对空间时间推理和人机团队在虚拟及现实领域的应用产生了重要意义。相关代码和数据集可在指定链接获取。"}
{"llm_update_time": "20251023", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.19182", "html_url": "https://arxiv.org/abs/2510.19182", "title": "使用XceptionNet从血细胞图像中检测疟疾", "title_en": "Malaria Detection from Blood Cell Images Using XceptionNet", "authors": "Warisa Nusrat,Mostafijur Rahman,Ayatullah Faruk Mollah", "background": "疟疾是由雌性按蚊叮咬传播，经常导致0-5岁儿童死亡。临床专家通过显微镜观察血涂片中的红细胞来诊断疟疾，但缺乏专业知识、技能以及手动操作可能导致误诊。因此，计算机辅助的自动诊断成为优选方案。这篇文章中应用了多种深度神经网络（包括AlexNet, XceptionNet, VGG-19, Residual Attention Network, DenseNet-121和Custom-CNN）从血细胞图像中提取深层内在特征，并且分类为疟疾感染或健康细胞。其中，Residual Attention Network和XceptionNet在公开可用的疟疾细胞图像数据集上的表现相对更好，分别达到了97.28%和97.55%的准确率，超越了其他相关方法。", "innovation": "应用了多种深度神经网络模型（AlexNet, XceptionNet, VGG-19, Residual Attention Network, DenseNet-121和Custom-CNN）从血细胞图像中进行深度特征提取和疟疾感染分类。特别地，Residual Attention Network和XceptionNet在疟疾检测任务中的表现最为出色，能够显著提高诊断准确性。", "conclusion": "研究结果表明，利用深度学习方法（尤其是Residual Attention Network和XceptionNet）可以实现疟疾的自动、可靠检测，从而减少手动操作的直接参与。这种方法为疟疾诊断提供了一种高效的解决方案。"}
{"llm_update_time": "20251023", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.19183", "html_url": "https://arxiv.org/abs/2510.19183", "title": "PruneHal: 通过自适应KV缓存剪枝在多模态大型语言模型中减少幻觉", "title_en": "PruneHal: Reducing Hallucinations in Multi-modal Large Language Models through Adaptive KV Cache Pruning", "authors": "Fengyuan Sun,Hui Chen,Xinhao Xu,Dandan Zheng,Jingdong Chen,Jun Zhou,Jungong Han,Guiguang Ding", "background": "近年来，多模态大型语言模型（MLLMs）取得了显著进展，但在幻觉问题上仍面临重大挑战。现有的解决方法要么通过引入额外数据进行进一步训练，要么在推理过程中利用外部或内部信息。然而，这些方法不可避免地增加了额外的计算成本。研究表明，MLLMs中的幻觉与模型对视觉标记分配的关注不足密切相关。冗余视觉标记的出现会分散模型的注意力，使其无法专注于最有益的信息，这导致关键视觉线索通常被忽视，从而加剧了幻觉的发生。", "innovation": "本文提出了PruneHal，一种无需额外训练且简单有效的方法，通过利用自适应KV缓存剪枝来增强模型对关键视觉信息的关注，从而减少幻觉。这是首次将标记剪枝应用于MLLMs中的幻觉缓解。PruneHal 不需要额外的训练，几乎不需要额外的推理成本，并且是模型无关的，可以无缝集成到不同的解码策略中，包括专门为幻觉缓解设计的策略。", "conclusion": "我们使用四种主流的MLLMs在多个广泛使用的幻觉评估基准上评估了PruneHal，取得了稳健和出色的结果，证明了我们方法的有效性和优越性。我们的代码将公开提供。"}
{"llm_update_time": "20251023", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.19193", "html_url": "https://arxiv.org/abs/2510.19193", "title": "Video Consistency Distance: 通过奖励驱动的微调提升从图像到视频生成的时间一致性", "title_en": "Video Consistency Distance: Enhancing Temporal Consistency for Image-to-Video Generation via Reward-Based Fine-Tuning", "authors": "Takehiro Aoshima,Yusuke Shinohara,Park Byeongseon", "background": "基于奖励的视频扩散模型微调是一种有效的方法，可以通过奖励函数微调模型，而无需使用真实世界的视频数据集。然而，这种微调方法有时会受限于特定的表现，因为传统的奖励函数主要关注整个生成视频序列的质量提升，如美学和整体一致性。特别是在针对图像到视频（I2V）任务时，生成的视频通常缺乏时间一致性，即视频帧之间的一致性较差。为了应对这种情况，本文提出了一种新的度量方法，即视频一致性距离（VCD），旨在增强时间一致性，并通过奖励驱动的微调框架优化模型", "innovation": "本文提出了一个新的度量方法，即视频一致性距离（VCD），一种用于增强时间一致性的方法。VCD 在视频帧特征的频域中定义，通过频域分析有效捕捉帧信息。这种方法能够确保生成的视频在相对于给定条件图的时间一致性上有显著提升，而不会牺牲其他性能。", "conclusion": "实验结果表明，使用视频一致性距离（VCD）微调视频生成模型可以显著增强时间一致性，同时不会降低其他性能指标，相较于先前的方法。"}
{"llm_update_time": "20251023", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.19210", "html_url": "https://arxiv.org/abs/2510.19210", "title": "MoE-GS: Mixture of Experts for Dynamic Gaussian Splatting", "title_en": "MoE-GS: Mixture of Experts for Dynamic Gaussian Splatting", "authors": "In-Hwan Jin,Hyeongju Mun,Joonsoo Kim,Kugjin Yun,Kyeongbo Kong", "background": "近年来，动态场景重建取得了显著进展，主要得益于3D高斯点绘技术。然而，现有方法在不同场景中的表现不一致，说明没有一种方法能有效应对所有动态挑战。", "innovation": "提出了基于混合专家的动态高斯点绘框架（MoE-GS），通过新颖的体素感知像素路由将多个专业专家整合在一起。该路由采用可微的权重点绘技术将体素中的高斯等级权重投影到像素空间中，实现空间和时间上的一致性。此外，为了提高效率，还探索了单次多专家渲染和门控感知高斯剪枝。并通过知识蒸馏策略将MoE-GS表现转移到个体专家中，实现轻量级部署。", "conclusion": "据我们所知，MoE-GS是首个将混合专家技术应用于动态高斯点绘的方法。在N3V和Technicolor数据集上的广泛实验表明，MoE-GS在保持高度效率的前提下，比现有最先进的方法具有更好的表现。有关视频演示，请参阅此链接：this https URL."}
{"llm_update_time": "20251023", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.19195", "html_url": "https://arxiv.org/abs/2510.19195", "title": "重新思考作为感知任务合成数据生成器的驾驶世界模型", "title_en": "Rethinking Driving World Model as Synthetic Data Generator for Perception Tasks", "authors": "Kai Zeng,Zhanqian Wu,Kaixin Xiong,Xiaobao Wei,Xiangyu Guo,Zhenxin Zhu,Kalok Ho,Lijun Zhou,Bohan Zeng,Ming Lu,Haiyang Sun,Bing Wang,Guang Chen,Hangjun Ye,Wentao Zhang", "background": "近年来，驱动世界模型的进步使得生成高质量RGB视频或多模态视频变得可控。现有方法主要集中在生成质量和可控性的指标上。然而，它们通常忽视了下游感知任务的评估，这对于自动驾驶的性能至关重要。现有的方法通常使用一种训练策略，即首先在合成数据上预训练，然后在真实数据上进行微调。与仅使用真实数据（基线）的训练相比，这种方法需要两倍的训练周期（epoch）。当基线加倍训练周期后，合成数据的优势变得微不足道。", "innovation": "为全面展示合成数据的好处，本文引入了Dream4Drive，这是一种新颖的合成数据生成框架，旨在增强下游感知任务。Dream4Drive首先将输入视频分解为几个3D意识引导图，然后在这些引导图上渲染3D资产。最后，驾驶世界模型被微调以生成多视角、照片级真实的视频，这些视频可以用于训练下游感知模型。Dream4Drive使得大规模生成多视角的极端情况成为可能，显著提升了自动驾驶中的边缘情况感知。为了促进未来的研究，作者还贡献了一个大规模的3D资产数据集DriveObj3D，覆盖了驾驶场景中的典型类别，使多样化的3D意识视频编辑成为可能。", "conclusion": "通过全面的实验，作者展示了Dream4Drive在不同训练周期下可以有效提升下游感知模型的性能。该项目可以通过提供的链接访问。"}
{"llm_update_time": "20251023", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.19220", "html_url": "https://arxiv.org/abs/2510.19220", "title": "使用多帧时间轨迹完成方法的太空目标检测", "title_en": "Space Object Detection using Multi-frame Temporal Trajectory Completion Method", "authors": "Xiaoqing Lan,Biqiao Xin,Bingshu Wang,Han Zhang,Laixian Zhang", "background": "地球静止轨道(GEO)上的太空物体由于信号弱、复杂的背景星光以及环境干扰，在光学成像中检测具有显著挑战性。", "innovation": "通过小波变换在单帧级别增强GEO目标的高频特征并抑制背景噪声，提出了一种基于匈牙利算法的多帧时间轨迹完成方案，克服了跨帧配准中的缺损和假检测问题。后处理管道中包括时间匹配和插值完成、基于时间一致性噪声过滤以及渐进轨迹精炼等关键步骤。", "conclusion": "提出的方案在公共SpotGEO数据集上的实验证明了其有效性，F_1分数达到90.14%。"}
{"llm_update_time": "20251023", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.19215", "html_url": "https://arxiv.org/abs/2510.19215", "title": "SFGFusion：4D成像雷达和摄像头融合的表面拟合引导3D目标检测", "title_en": "SFGFusion: Surface Fitting Guided 3D Object Detection with 4D Radar and Camera Fusion", "authors": "Xiaozhi Li,Huijun Di,Jian Li,Feng Liu,Wei Liang", "background": "3D物体检测对于自动驾驶至关重要。4D成像雷达作为一种新兴传感器，因其低成本、长距离探测和精确速度测量等优势，非常适合用于物体检测。然而，4D成像雷达的稀疏点云和低分辨率限制了物体的几何表示，并阻碍了多模态融合。", "innovation": "本文提出了一种名为SFGFusion的新颖的摄像机-4D成像雷达检测网络，该网络通过表面拟合来引导物体检测。通过从图像和雷达数据中估计物体的二次表面参数，表面拟合模型增强了空间表示和跨模态交互，从而能够更可靠地预测精细粒度的密集深度。SFGFusion网络中的预测深度有两个用途：1）在图像分支中，以指导图像特征从透视视图到统一的顶视图的转化，从而提高空间映射的准确性；2）在表面伪点分支中生成密集的伪点云，以缓解雷达点云的稀疏性。原雷达点云还在单独的雷达分支中进行编码，并采用支柱方法，将特征转换到顶视图空间。最后，使用标准的2D骨干网络和检测头从顶视图特征中预测物体标签和边界框。", "conclusion": "实验结果表明，SFGFusion有效地融合了摄像机和4D雷达特征，实现了在TJ4DRadSet和视点达佛特(VoD)目标检测基准上的优越性能。"}
{"llm_update_time": "20251023", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.19255", "html_url": "https://arxiv.org/abs/2510.19255", "title": "4D表示的进展：几何、运动与交互", "title_en": "Advances in 4D Representation: Geometry, Motion, and Interaction", "authors": "Mingrui Zhao,Sauradip Nag,Kai Wang,Aditya Vora,Guangda Ji,Peter Chun,Ali Mahdavi-Amiri,Hao Zhang", "background": "4D生成和重建是计算机图形学的一个快速增长的子领域，其发展得益于神经场、几何和运动深度学习以及3D生成人工智能（GenAI）的最新进展。虽然已有许多关于该领域的综述，但本文从4D表示的独特视角出发，介绍3D几何随时间演变并展示运动和交互的模型。", "innovation": "本文不提供全面的作品列表，而是采取选择性的方式，聚焦于代表作品，以突出不同情况下每种表示的优缺点及面临的挑战。着重讨论了基于几何、运动和交互三大支柱的4D表示方法，并引出了结构化模型和长距离运动等较少探索的表示方法。同时，关注大型语言模型和视频基础模型在4D应用中的角色及其限制。", "conclusion": "本文旨在指导读者如何选择合适的4D表示，并在不同场景中进行定制。文章还涵盖了目前可用的4D数据集以及未来需要的数据集中缺失的部分，有助于推动该子领域的进步。"}
{"llm_update_time": "20251023", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.19250", "html_url": "https://arxiv.org/abs/2510.19250", "title": "背景减弱，前景主导：基于课程指导的背景剪枝以实现高效的前景为中心的协作感知", "title_en": "Background Fades, Foreground Leads: Curriculum-Guided Background Pruning for Efficient Foreground-Centric Collaborative Perception", "authors": "Yuheng Wu,Xiangbo Gao,Quang Tau,Zhengzhong Tu,Dongman Lee", "background": "协作感知通过跨车辆共享互补信息来增强自主车辆的可靠性和空间覆盖率，为长尾场景下单车辆感知面临的挑战提供了有希望的解决方案。然而，车载网络的带宽限制使得传输整个特征映射不切实际。因此，最近的方法采用了前景为中心的范式，仅传输预测的前景区域特征，而丢弃背景部分，尽管背景特征包含重要的上下文信息。", "innovation": "本文提出了一种前景为中心的框架FadeLead，通过在训练过程中学习在紧凑的前景特征中封装背景上下文来克服这一限制。其设计理念核心是课程学习策略，在早期利用背景提示，但逐渐减少其影响，迫使模型在不传输背景特征的情况下将上下文融入前景表示。在仿真和现实世界基准测试中的广泛实验表明，在不同的带宽设置下，FadeLead都优于先前方法，突显了富含上下文的前景共享的有效性。", "conclusion": "大量的实验结果显示，FadeLead在不同的带宽条件下都优于之前的方法，证明了上下文增强的前景共享的有效性。"}
{"llm_update_time": "20251023", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.19272", "html_url": "https://arxiv.org/abs/2510.19272", "title": "SCEESR: 基于语义控制边缘增强的一步扩散模型超分辨率", "title_en": "SCEESR: Semantic-Control Edge Enhancement for Diffusion-Based Super-Resolution", "authors": "Yun Kai Zhuang", "background": "实时图像超分辨率（Real-ISR）需要处理复杂的退化和固有的重构不确定性。尽管生成模型提高了感知质量，但仍有计算成本的权衡。一步扩散模型虽然速度快，但由于蒸馏伪影，往往产生结构上的不准确性。", "innovation": "提出了一种新的超分辨率框架，结合了控制网机制的语义边缘引导，以提高一步扩散模型的性能。引入了结合L2、LPIPS和边缘感知AME损失的混合损失函数，以优化像素准确性、感知质量和几何精度。", "conclusion": "实验表明，该方法有效提高了结构完整性和现实感，同时保持了一步生成的效率，实现了输出质量和推理速度之间的最佳平衡。测试数据集的结果将在 https://this.is/a.url/ 发表，相关代码将在 https://this.is/another.url/ 发表。"}
{"llm_update_time": "20251023", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.19282", "html_url": "https://arxiv.org/abs/2510.19282", "title": "通过大数据和集成少样本学习增强早期阿尔茨海默病检测", "title_en": "Enhancing Early Alzheimer Disease Detection through Big Data and Ensemble Few-Shot Learning", "authors": "Safa Ben Atitallah,Maha Driss,Wadii Boulila,Anis Koubaa", "background": "阿尔茨海默病是一种严重的脑部疾病，影响脑部多个区域，导致记忆力受损。由于标记医疗数据的有限性，准确检测阿尔茨海默病面临巨大挑战。有效方法的缺乏尤其值得注意，尤其是在医疗数据稀缺、疾病复杂和数据隐私限制的情况下。", "innovation": "该研究利用预训练的卷积神经网络（CNNs）在少样本学习（FSL）和集成学习框架中，提出了一种基于原型网络（ProtoNet）的集成方法，结合了多种预训练的CNNs作为编码器，增强了从医学图像中提取的特征丰富度。此外，该方法还包括类感知损失和熵损失的结合，以实现更精确的阿尔茨海默病进展水平分类。", "conclusion": "研究使用Kaggle阿尔茨海默病数据集和ADNI数据集进行了评估，分别实现了99.72%和99.86%的准确率。相对现有最先进研究的比较结果表明，该方法具有更高的准确性和真实世界应用的有效性和潜力，尤其是在早期阿尔茨海默病检测方面。"}
{"llm_update_time": "20251023", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.19292", "html_url": "https://arxiv.org/abs/2510.19292", "title": "基于视觉的程序性活动中的错误分析：进展与挑战综述", "title_en": "Vision-Based Mistake Analysis in Procedural Activities: A Review of Advances and Challenges", "authors": "Konstantinos Bacharidis,Antonis A. Argyros", "background": "程序性活动中的错误分析是工业自动化、康复物理、教育和人机协作等多个领域的一个关键研究领域。本文回顾了基于视觉的方法，用于检测和预测结构化任务中的错误，重点是程序性和执行错误。通过利用计算机视觉的进步，包括动作识别、预见和活动理解，基于视觉的系统可以识别任务执行中的偏差，如顺序错误、技术使用不当或时间错误。本文探讨了类内变异性、视角差异和组成活动结构所带来的挑战，这些挑战复杂了错误检测。", "innovation": "文章全面回顾了基于视觉的方法，包括现有数据集、评估指标和最先进的方法，以及基于程序结构、监督水平和学习策略的方法分类。此外，文章讨论了如何区分允许的可变性和真实错误，以及如何建模错误传播等问题，并提出了未来方向，如结合符号表示的神经推理和假设状态建模。", "conclusion": "本文旨在建立基于视觉的程序性活动中错误分析的统一视角，强调其在跨不同领域增强安全、效率和任务性能方面的潜力。"}
{"llm_update_time": "20251023", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.19273", "html_url": "https://arxiv.org/abs/2510.19273", "title": "MobiAct：使用对比学习和知识蒸馏的MobileNetV4实现高效微型无人驾驶飞行器动作识别", "title_en": "MobiAct: Efficient MAV Action Recognition Using MobileNetV4 with Contrastive Learning and Knowledge Distillation", "authors": "Zhang Nengbo,Ho Hann Woei", "background": "在自主空中蜂群中实现实时感知和协调， accurate and efficient recognition of Micro Air Vehicle (MAV) motion is essential. 现有的大多数方法依赖于大型、计算密集型模型，这些模型不适合资源有限的MAV平台，导致识别准确性和推理速度之间的权衡。为了应对这些挑战，提出了MobiAct框架，采用MobileNetV4作为主干网络，并引入Stage-wise Orthogonal Knowledge Distillation (SOKD) 策略，这种策略能够从教师网络（ResNet18）向学生网络有效转移MAV运动特征，以增强知识转移效率。此外，还集成了一个无参数的注意力机制，以提高识别准确性而不增加模型复杂性。同时开发了一种混合损失训练策略，将多种损失目标结合起来，确保稳定和稳健的训练期间优化。", "innovation": "提出了MobiAct框架，采用了MobileNetV4作为主干网络，引入了Stage-wise Orthogonal Knowledge Distillation (SOKD) 策略，集成了一个无参数的注意力机制，并开发了一种混合损失训练策略。实验结果显示，MobiAct实现了低能耗和低计算量的MAV动作识别，在所有三个自收集数据集中，平均识别准确率达到92.12%，消耗能量仅136.16 pJ，处理识别速度为每秒8.84个动作。值得注意的是，MobiAct的动作解码速度快于领先方法2倍，且具有相似的识别准确性，突显出其在MAV动作识别中的高效性。", "conclusion": "MobiAct框架在保持高识别准确率的同时，实现了快速的解码速度和低能耗，展示了其在资源受限的MAV平台上的高效能力。"}
{"llm_update_time": "20251023", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.19278", "html_url": "https://arxiv.org/abs/2510.19278", "title": "D2D: 从检测器到可微批评家以增强文本到图像生成中的数理性", "title_en": "D2D: Detector-to-Differentiable Critic for Improved Numeracy in Text-to-Image Generation", "authors": "Nobline Yoo,Olga Russakovsky,Ye Zhu", "background": "文本到图像（T2I）扩散模型已经在语义对齐方面表现出色，但仍然难以生成与提示中指定的数量一致的物体。现有的方法通常引入辅助计数网络作为外部批评家以增强数量准确性，但这些批评家必须在生成过程中提供梯度指导，因此它们局限于能提供梯度的回归模型，从而排除了具有优越计数能力但其计数方式为非可微的检测器模型。因此，无法利用这些模型在计数方面的强大能力来指导生成过程中的数量准确性。", "innovation": "我们提出了一个名为D2D的新框架，它可以将非可微检测器模型转换为可微批评家，从而充分利用其在计数方面的能力来指导生成过程中的数量准确性。具体来说，我们设计了自定义激活函数将检测器的logits转换为软二进制指示器，并在预训练的T2I模型进行推理时使用这些指示器优化噪声先验。我们的实验结果表明，在SDXL-Turbo、SD-Turbo和Pixart-DMD四个不同复杂度（低密度、高密度和多物体）场景的基准测试中，这种方法在物体计数准确性方面取得了显著和一致的提升（例如，D2D-Small在400个提示、低密度基准测试中的计数准确性提升了13.7%），同时对整体图像质量和计算开销影响较小。", "conclusion": "我们的研究表明，D2D框架能够在保持高质量图像的同时有效提高文本到图像生成过程中的计数准确性，具有重要的实际应用价值。"}
{"llm_update_time": "20251023", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.19307", "html_url": "https://arxiv.org/abs/2510.19307", "title": "统一强化学习和模仿学习在视觉语言模型中的应用", "title_en": "Unified Reinforcement and Imitation Learning for Vision-Language Models", "authors": "Byung-Kwan Lee,Ryo Hachiuma,Yong Man Ro,Yu-Chiang Frank Wang,Yueh-Hua Wu", "background": "视觉语言模型（VLMs）在多项任务上取得了显著的进步，但由于其规模庞大，往往在资源受限的环境中不具实用性。现有的VLMs难以应用于需要轻量化模型的场景。", "innovation": "该论文介绍了一种新颖且高效的统一强化学习和模仿学习（RIL）算法，旨在创建强大的轻量级VLMs。RIL巧妙地结合了强化学习与对抗性模仿学习的优点，使得小型学生模型不仅能够模仿大型教师模型的复杂文本生成，还能通过强化信号系统地提升其生成能力。该模仿框架的核心在于通过LLM构建的判别器，能够准确地区分学生和教师的输出，并且通过多个大型教师VLM的指导，确保多层次的学习。统一的学习策略结合了强化和模仿学习，使学生模型能够显著提升性能，与顶级闭源VLMs处于同一水平或甚至是领先的。这项研究通过在多种视觉语言基准上的实验，验证了RIL的有效性，显著缩小了与最先进的开源和闭源VLMs的性能差距，并在某些情况下超越了它们。", "conclusion": "该研究展示了一种新的轻量化视觉语言模型训练算法RIL，通过强化学习和模仿学习的结合，使得在资源受限的环境下也能实现高性能的视觉语言模型。实验结果表明，基于RIL训练的视觉语言模型在多个基准测试上取得了优异的性能，与最先进的模型相比具有竞争力甚至超过了部分模型。"}
{"llm_update_time": "20251023", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.19321", "html_url": "https://arxiv.org/abs/2510.19321", "title": "基于时空图注意力转换器的在线手写签名验证", "title_en": "Online Handwritten Signature Verification Based on Temporal-Spatial Graph Attention Transformer", "authors": "Hai-jie Yuan,Heng Zhang,Fei Yin", "background": "手写签名验证是身份认证的关键方面，在金融和电子商务等领域有着广泛应用。然而，由于用户内部变异性高和伪造风险的存在，实现高精度的签名验证仍然具有挑战性。现有的签名验证方法难以准确捕捉签名中的动态特征和复杂关系，导致误识率较高。因此，需要一种新的方法来改善签名验证的性能。", "innovation": "提出了一个名为时-空图注意力转换器（Temporal-Spatial Graph Attention Transformer, TS-GATR）的新方法。该方法结合了图注意力网络（GAT）和门控循环单元（GRU），以同时建模签名数据中的时空依赖关系。TS-GATR通过将签名表示为图（每个节点捕捉动态特征如位置、速度、压力）并通过注意力机制来建模其复杂关系，提升验证性能。此外，通过引入双图注意力转换器模块（Dual-Graph Attention Transformer, DGATR），该方法能够分别建模局部和全局的空间特征。为了捕捉长期的时序依赖关系，模型整合了GRU，从而增强了其学习签名验证过程中动态特征的能力。", "conclusion": "在基准数据集MSDS和DeepSignDB上的全面实验表明，TS-GATR超越了当前最先进的方法，能够在多种场景中实现更低的等错误率(EER)。"}
{"llm_update_time": "20251023", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.19330", "html_url": "https://arxiv.org/abs/2510.19330", "title": "在域泛化背景下探究人群定位的尺度偏移", "title_en": "Exploring Scale Shift in Crowd Localization under the Context of Domain Generalization", "authors": "Juncheng Wang,Lei Shang,Ziqi Liu,Wang Lu,Xixu Hu,Zhe Hu,Jindong Wang,Shujun Wang", "background": "人群定位在视觉场景理解中起着关键作用，有助于预测每个行人在人群中的位置，进而适用于各种下游任务。然而，现有方法在训练数据和测试数据之间的头部规模分布（尺度偏移）差异下表现显著下降，这一问题称为域泛化（DG）。本文旨在理解域泛化背景下人群定位模型中的尺度偏移现象，通过系统研究不同尺度偏移水平下人群定位性能的变化、建立基准ScaleBench并再现20种先进的DG算法来量化影响，并通过严格的理论分析，强调了解决尺度偏移的重要性，探讨了尺度偏移在域泛化中的限制和复杂性。", "innovation": "本文提出了一种名为因果特征分解和各向异性处理（Catto）的有效算法，用于缓解域泛化背景下的尺度偏移影响。此外，还通过详尽的分析实验获取了四个对未来研究至关重要的见解。", "conclusion": "本文的研究结果强调了该新颖且实用的研究方向的重要性，并将其定义为尺度偏移的域泛化（Scale Shift Domain Generalization），这表明解决尺度偏移对于优化人群定位模型至关重要，未来的研究应继续探索这一领域。"}
{"llm_update_time": "20251023", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.19333", "html_url": "https://arxiv.org/abs/2510.19333", "title": "使用EfficientNet和CLIP的训练无监督框架以开放词汇进行图像分割和识别", "title_en": "A Training-Free Framework for Open-Vocabulary Image Segmentation and Recognition with EfficientNet and CLIP", "authors": "Ying Dai,Wei Yu Chen", "background": "传统的图像分割和对象识别方法通常依赖于标记的数据进行训练，并且在处理开放词汇（即在训练时未见过的新类别）时表现不佳。本文提出的框架旨在解决这一问题，通过使用EfficientNet B0 和CLIP，实现无需训练的开放词汇图像分割和对象识别（OVSR），能够在未见过的新类别下实现更有效的识别。", "innovation": "提出了一种基于EfficientNet B0 和CLIP的新颖无监督框架，用于开放词汇的图像分割和对象识别。该框架采用两阶段流程：首先通过EfficientNet B0 获取像素级特征并进行无监督分割，然后通过视觉-语言对齐进行分割级别的识别。该方法能够自适应地确定聚类数量，并且通过视觉变换器将分割区域编码为图像嵌入，同时使用CLIP的文本编码器预计算文本嵌入，最终通过奇异值分解增强跨模态对齐。这种方法在多个标准基准数据集上获得了最先进的性能。", "conclusion": "所提出的框架在标准基准数据集如COCO、ADE20K和PASCAL VOC上取得了最先进的性能，证明了该框架的有效性、灵活性和泛化能力。"}
{"llm_update_time": "20251023", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.19332", "html_url": "https://arxiv.org/abs/2510.19332", "title": "BrainMCLIP：CLIP多层特征融合的脑图像解码", "title_en": "BrainMCLIP: Brain Image Decoding with Multi-Layer feature Fusion of CLIP", "authors": "Tian Xia,Zihan Ma,Xinlong Wang,Qing Liu,Xiaowei He,Tianming Liu,Yudan Ren", "background": "传统的fMRI图像解码方法常将脑活动映射到CLIP的最后一层语义层，为了捕捉更细粒度的视觉细节，许多方法引入了基于VAE的参数丰富的管道。然而，这些方法忽视了CLIP中间层中丰富的物体信息，且与大脑的功能层次结构相矛盾。现有的方法在解码高阶语义指标方面表现不如SOTA方法。", "innovation": "提出了BrainMCLIP，这是一种参数高效的多层次融合方法，借鉴了人类视觉系统功能层次结构，不依赖额外的VAE路径。BrainMCLIP将不同功能区的fMRI信号对应到CLIP的中间层和最终层，遵循功能层次结构。此外，BrainMCLIP引入了跨重建策略和新型多粒度损失。结果显示，BrainMCLIP在高阶语义指标上取得了与SOTA方法相当甚至更好的性能，而参数数量减少了71.7%，通过避免使用VAE路径取得了这一成就。", "conclusion": "BrainMCLIP展示了通过利用CLIP中间特征有效地捕捉视觉细节，展示了语义准确性和细节保真的良好平衡，特别在高阶语义指标上优于VAE管道方法，同时显著减少了参数量。"}
{"llm_update_time": "20251023", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.19329", "html_url": "https://arxiv.org/abs/2510.19329", "title": "Seabed-Net：浅水区域遥感图像中联合底质估算和底质分类的多任务网络", "title_en": "Seabed-Net: A multi-task network for joint bathymetry estimation and seabed classification from remote sensing imagery in shallow waters", "authors": "Panagiotis Agrafiotis,Begüm Demir", "background": "准确、详细且定期更新的水深信息，结合复杂的语义内容，对于面临气候变化和人类活动压力的未充分测绘的浅水环境至关重要。然而，现有方法通过遥感影像推导水深或海底分类类别都是独立进行的，未能利用相互之间的利益，阻碍了深度学习方法的广泛应用。", "innovation": "本文介绍了一种统一的多任务框架——Seabed-Net，它可以从不同分辨率的遥感影像中同时预测水深和像素级的海底分类。Seabed-Net使用双重编码器进行水深估计和像素级海底分类，通过注意力特征融合模块和窗口Swin-Transformer融合块整合跨任务特征，并通过动态任务不确定性加权平衡目标。在两个异构的沿海站点进行的广泛评估中，Seabed-Net始终优于传统的经验模型和传统的机器学习回归方法，均方根误差降低75%，水深均方根误差减少10-30%，海底分类精度提高8%。定性分析进一步表明，对于低对比度区域，空间一致性得到增强，边界的清晰度提高，并纠正了深度偏差。", "conclusion": "这些结果验证了将深度与底质和海底生态位建模相结合可以带来协同增益，提供了一种集成浅水测绘的稳健、开放解决方案。"}
{"llm_update_time": "20251023", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.19353", "html_url": "https://arxiv.org/abs/2510.19353", "title": "DARE：基于学习的医学图像注册的可变形自适应正则化估计器", "title_en": "DARE: A Deformable Adaptive Regularization Estimator for Learning-Based Medical Image Registration", "authors": "Ahsan Raza Siyal,Markus Haltmeier,Ruth Steiger,Malik Galijasevic,Elke Ruth Gizewski,Astrid Ellen Grams", "background": "变形医学图像配准是医学图像分析中的一个基本任务。虽然基于深度学习的方法在准确性和计算效率方面明显优于传统技术，但它们往往忽视了正则化在确保稳健性和解剖可验证性方面的重要作用。", "innovation": "我们提出了DARE（Deformable Adaptive Regularization Estimator），这是一种新的配准框架，能够根据变形场梯度范数动态调整弹性正则化。该方法整合了应变和切应力能量项，这些项能够自我调节以平衡稳定性与灵活性。为了确保物理上现实的转换，DARE引入了防止折叠的机制，对具有负变形雅可比的区域进行惩罚。这种方法能减少非物理的伪影、避免过度平滑，并提高配准准确性和解剖可验证性。", "conclusion": "DARE通过自适应调整正则化项和引入防止折叠机制，增强了基于深度学习的医学图像配准的准确性和解剖合理性。"}
{"llm_update_time": "20251023", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.19400", "html_url": "https://arxiv.org/abs/2510.19400", "title": "跨越视角：在机器人场景中测试视觉语言模型的空间推理能力", "title_en": "Seeing Across Views: Benchmarking Spatial Reasoning of Vision-Language Models in Robotic Scenes", "authors": "Zhiyuan Feng,Zhaolu Kang,Qijie Wang,Zhiying Du,Jiongrui Yan,Shubin Shi,Chengbo Yuan,Huizhi Liang,Yu Deng,Qixiu Li,Rushuai Yang,Arctanx An,Leqi Zheng,Weijie Wang,Shawn Chen,Sicheng Xu,Yaobo Liang,Jiaolong Yang,Baining Guo", "background": "视觉-语言模型（VLMs）对于使机器人能够在复杂环境中进行感知、推理和行动至关重要。这些模型同时也是最近开发的视觉-语言-行动（VLA）模型的基础。尽管如此，大多数VLMs的评估主要集中在单视角设置上，几乎没有涉及它们处理多视角信息的能力。另一方面，多摄像机设置在机器人平台上越来越普遍，因为它们提供了互补的视角以减轻遮挡和深度模糊。因此，VLMs能否有效地利用多视角输入进行了机器人推理还存在疑问。", "innovation": "该论文提出了MV-RoboBench，一个专门设计来评估VLMs在机器人操作中多视角空间推理能力的基准。MV-RoboBench包含了1700多个手动筛选的问答项，分为两大部分：空间理解与机器人执行。通过测试多种现有的VLMs及其增强版本，展示了最先进的模型在多视角机器人感知方面的性能远低于人类水平，指出了VLMs在多视角机器人感知中面临的巨大挑战。此外，研究还发现了两个关键结论：空间智能和机器人任务执行在多视角机器人场景中呈正相关；以及在现有通用单视角空间理解基准上的良好表现并不能可靠地转化为我们在基准中评估的机器人空间任务的成功。", "conclusion": "MV-RoboBench作为一个开放资源，旨在促进空间嵌入式VLMs和VLAs的发展，不仅提供了数据，还提供了一个标准化的多视角与机器人推理的评估方案。"}
{"llm_update_time": "20251023", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.19432", "html_url": "https://arxiv.org/abs/2510.19432", "title": "考虑广角失真的物流仓库多相机工人跟踪", "title_en": "Multi-Camera Worker Tracking in Logistics Warehouse Considering Wide-Angle Distortion", "authors": "Yuki Mori,Kazuma Kano,Yusuke Asai,Shin Katayama,Kenta Urano,Takuro Yonezawa,Nobuo Kawaguchi", "background": "随着电子商务的普及，物流市场在全球范围内快速增长。因此，提高仓库操作效率变得至关重要。为实现这一目标，已经探索了各种方法，并且使用数字孪生的方法越来越受到关注。为了实现这种方法，需要准确收集仓库中工人的位置并在虚拟空间中反映这些位置。然而，单个摄像头的视野有限，因此需要多个摄像头进行感测。", "innovation": "研究探索了一种方法，使用安装在天花板上的19个广角摄像头从上方拍摄物流仓库的地面来跟踪工人。通过基于地板表面进行对齐，理解了摄像头坐标与实际仓库位置之间的关系。由于广角摄像头的特性，在图像边缘特别是垂直方向上出现了显著的失真。为此，通过基于脚部位置对每个摄像头检测到的工人位置进行对齐，减少了图像失真的影响，并在跨摄像头中实现了精确的位置对齐。结果表明，跟踪精度提高了超过20%，并且验证了所提出方法的有效性。", "conclusion": "通过多摄像头系统结合基于脚部位置的校准方法，成功解决了广角摄像头的失真问题，显著提高了物流仓库中工人位置跟踪的准确性。"}
{"llm_update_time": "20251023", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.19465", "html_url": "https://arxiv.org/abs/2510.19465", "title": "PCP-GAN: Property-Constrained Pore-Scale Image Reconstruction via Conditional Generative Adversarial Networks", "title_en": "PCP-GAN: Property-Constrained Pore-scale image reconstruction via conditional Generative Adversarial Networks", "authors": "Ali Sadeghkhani,Brandon Bennett,Masoud Babaei,Arash Rabbani", "background": "在地下表征中，获取真正代表性的孔隙尺度图像一直是挑战，因为自然的空间异质性导致提取的子图像与核心测量值有显著偏差。此外，由于物理样本只能在稀疏的井位处获得，数据稀缺问题进一步加剧了这一挑战。", "innovation": "本文提出了一种多条件生成对抗网络（cGAN）框架，该框架能够生成具有精确控制特性的代表性孔隙尺度图像，同时解决了代表性和数据可用性的限制问题。该模型同时在单一统一模型中对孔隙度值和深度参数进行条件设定，并能够捕捉到通用的孔隙网络原理以及深度特定的地质特征。", "conclusion": "本模型在所有地层中实现了出色的孔隙度控制（R²=0.95），并且生成的图像在双约束误差方面表现优越，为地下表征提供了变革性工具，特别适用于碳存储、地热能源和地下水管理等应用领域，其中了解孔隙空间的代表性形态对于实施数字岩石物理至关重要。"}
{"llm_update_time": "20251023", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.19336", "html_url": "https://arxiv.org/abs/2510.19336", "title": "DaMo: Data Mixing Optimizer in Fine-tuning Multimodal LLMs for Mobile Phone Agents", "title_en": "DaMo: Data Mixing Optimizer in Fine-tuning Multimodal LLMs for Mobile Phone Agents", "authors": "Kai Shi,Jun Yang,Ni Yang,Binqiang Pan,Qingsong Xie,Chao Zhang,Zhenyu Yang,Tianhuang Su,Haonan Lu", "background": "移动电话代理（MPAs）作为一种广泛应用于各种场景的研究方向正在兴起。尽管多模态大规模语言模型（MLLMs）是MPAs的基础，但它们在同时处理多种移动电话任务方面仍存在局限性。目前采用的多任务监督微调方法在确定最佳训练数据组成以获得最佳性能时仍然存在挑战。为了应对这一挑战，作者提出了DaMo（数据混合优化器）——一种新颖的解决方案，采用可训练网络通过预测给定数据集比例下的下游任务性能来确定最优数据混合。为了进行全面评估，作者引入了PhoneAgentBench，这是第一个专门用于评估MLLMs在多模态移动电话任务上的基准，包含1235个问答对，涵盖了多种实际的工业移动应用程序场景。DaMo在小型试点实验中展示了强大的预测能力（R^2=0.81），并在PhoneAgentBench中实现了3.38%的性能改进。此外，在多个基准测试中，DaMo表现出优越的泛化能力，在BFCL-v3、MME-Reasoning、MME-Perception和OCRBench上的平均分上优于其他方法2.57%。当仅用于BFCL-v3任务的MLLM优化时，DaMo的指标比其他方法提高了12.47%。值得注意的是，DaMo保持了鲁棒的可扩展性，适用于其他模型架构时依然有效。相关代码和数据集可在 https://github.com/username/DaMo 获取。", "innovation": "提出了DaMo（数据混合优化器），一种新颖的解决方案，采用可训练网络通过预测给定数据集比例下的下游任务性能来确定最优数据混合。此外，引入了PhoneAgentBench，这是第一个专门用于评估MLLMs在多模态移动电话任务上的基准。DaMo显著提高了多个基准测试中的性能，并保持了鲁棒的可扩展性，适用于其他模型架构。", "conclusion": "DaMo实现了3.38%的性能改进，并通过多个基准测试展示了卓越的泛化能力，优于其他方法。DaMo保持了优秀的可扩展性，适用于其他模型架构。相关代码和数据集已公开分享。"}
{"llm_update_time": "20251023", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.19451", "html_url": "https://arxiv.org/abs/2510.19451", "title": "专家级推理：利用多模态大型语言模型进行基于图画的精神分析", "title_en": "Reasoning Like Experts: Leveraging Multimodal Large Language Models for Drawing-based Psychoanalysis", "authors": "Xueqi Ma,Yanbei Jiang,Sarah Erfani,James Bailey,Weifeng Liu,Krista A. Ehinger,Jey Han Lau", "background": "多模态大型语言模型（MLLMs）已经在各种客观的多模态感知任务中展示了出色的性能，但它们在主观的、情感丰富的领域，如心理健康分析中的应用仍然被大量未探索。Psychoanalytical Image Comprehension框架，即PICK，是为了解决这一问题而设计的一个多步骤框架，旨在通过层次分析和技术的注入来理解心理分析中的House-Tree-Person（HTP）测试图片。该框架旨在提取多媒体信息，并在多个级别上进行分析，以便更好地理解图画中的潜在心理和情感线索。", "innovation": "PICK框架通过多步骤和多层次分析，利用MLLMs对HTP测试图进行心理分析。首先，PICK框架将含有多个实例的图画分解成具有语义意义的子图，构建了一个多层次的表示，涵盖单个物体级别、多个物体级别和整体级别，以便更好地理解空间结构和内容。其次，通过强化学习训练的特征抽取模块生成单个物体级别的心理档案，用于捕捉整体风格特征和动态物体特定特征，与心理状态相关联。最后，该框架通过整合来自多个方面的信息，生成一个符合专家级推理的全面评估。", "conclusion": "实验结果显示，PICK显著增强了MLLMs在心理分析中的能力，并且证明是一个适用于情感理解任务的一般框架。PICK框架连接了MLLMs与专业的专家领域，提供了一个结构化和可解释的框架，用于通过视觉表达来理解人类的心理状态。"}
{"llm_update_time": "20251023", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.19472", "html_url": "https://arxiv.org/abs/2510.19472", "title": "预测先行：生成先验框架加速MRI", "title_en": "Predicting before Reconstruction: A generative prior framework for MRI acceleration", "authors": "Juhyung Park,Rokgi Hong,Roh-Eul Yoo,Jaehyeon Koo,Se Young Chun,Seung Hong Choi,Jongho Lee", "background": "近年来，人工智能的进步在图像合成和生成方面创造了革命性的能力，使各个研究领域能够以前所未有的速度和范围创新。尽管磁共振成像（MRI）是现代患者护理的重要基石，但其漫长的数据采集时间限制了临床工作效率。为此，本研究利用这一生成能力，提出了一种新的加速MRI的方法，从图像重建转变为预测性成像。通过预测目标对比度图像并将其用作重建高度欠采样数据的驱动先验信息，该框架可以显著提高MRI的效率。这种方法不仅使用其他对比度图像、先前扫描图像、采集参数和患者信息等多种数据源进行训练，还在特定应用场景中取得了显著的效果。", "innovation": "本研究提出了一个新的生成先验框架，通过预测目标对比度图像并将其作为重建高欠采样数据的驱动先验信息，从而加速MRI的数据采集时间。该框架能够使数据采集速度最高达常规采样的12倍，并且在这项任务上的表现优于其他方法，包括有先验信息或无先验信息的方法。通过这一框架，研究团队提出了图像重建向预测成像的根本性转变。", "conclusion": "该研究通过对内部和多个公共数据集（共计14,921个扫描，1,051,904个切片）进行测试，评估了不同加速因子（x4, x8 和x12）下的表现。结果表明，预测-先验重建方法在多个MRI重建任务中表现优异，显著优于其他方法。未来的研究可以进一步探索在不同应用场景下该方法的有效性。"}
{"llm_update_time": "20251023", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.19475", "html_url": "https://arxiv.org/abs/2510.19475", "title": "PRGCN: 一种用于3D人体姿态估计跨序列模式重用的图记忆网络", "title_en": "PRGCN: A Graph Memory Network for Cross-Sequence Pattern Reuse in 3D Human Pose Estimation", "authors": "Zhuoyang Xie,Yibo Zhao,Hui Huang,Riwei Wang,Zan Gao", "background": "单眼3D人体姿态估计仍然是一个基本的逆问题，由于从2D到3D提升存在固有的深度不确定性。虽然当前基于视频的方法利用了时间上下文来增强空间推理，但它们在处理每个序列时存在关键的范式限制：未能利用跨序列中广泛存在的结构规律性和重复运动模式。", "innovation": "本文提出了Pattern Reuse Graph Convolutional Network (PRGCN)，这是一种新颖的框架，将姿态估计形式化为一种模式检索和适应问题。PRGCN的核心是一个图记忆库，它学习并存储一组紧凑的姿势原型，并通过注意机制动态检索，提供结构先验。这些先验通过记忆驱动的图卷积与硬编码的解剖约束动态融合，确保几何合理性。为了支持这一检索过程，我们设计了双流混合架构，协同结合了基于Mamba的状态空间模型的线性复杂和局部时间建模能力以及自我注意力的全局关系能力。", "conclusion": "在Human3.6M和MPI-INF-3DHP基准上的广泛评估表明，PRGCN建立了新的最先进技术，分别实现MPJPE为37.1mm和13.4mm，并具备增强的跨域泛化能力。我们的工作表明，长期以来被忽视的跨序列模式重用机制对推进该领域至关重要，从单序列优化转向累积知识学习的范式转变是关键。"}
{"llm_update_time": "20251023", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.19478", "html_url": "https://arxiv.org/abs/2510.19478", "title": "缓解甲烷气柱检测中由于缺失像素引起的表示偏差", "title_en": "Mitigating representation bias caused by missing pixels in methane plume detection", "authors": "Julia Wąsala,Joannes D. Maasakkers,Ilse Aben,Rochelle Schneider,Holger Hoos,Mitra Baratchi", "background": "大部分卫星图像由于云层等因素存在系统性的缺失像素（即非随机缺失数据，MNAR），这可能导致自动特征提取模型的表示偏差。已知某种错误相关性会导致模型错误地关联 Coverage（被认为是指图像中有效像素的百分比）与标签，从而在 Coverage 低的图像中错误地低估甲烷气柱的存在。", "innovation": "本研究展示了通过多种插补方法去除 Coverage 与标签之间的依赖关系，并提出了一种在训练过程中使用的加权重抽样方案。这两种方法均能够显著减少表示偏差，而不影响平衡准确率、精确率或召回率。此外，还评估了这些经校正偏差的模型在实际场景下的检测能力，显示出其在低 Coverage 图像中检测气柱的概率更高。", "conclusion": "本研究提出的解决方案能够显著减少甲烷气柱检测中的表示偏差，经校正偏差的模型在低 Coverage 图像中具有更好的检测能力。"}
{"llm_update_time": "20251023", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.19487", "html_url": "https://arxiv.org/abs/2510.19487", "title": "通过因果视觉提示实现单源领域泛化目标检测", "title_en": "Towards Single-Source Domain Generalized Object Detection via Causal Visual Prompts", "authors": "Chen Li,Huiying Xu,Changxin Gao,Zeyu Wang,Yun Liu,Xinzhong Zhu", "background": "单源领域泛化目标检测（SDGOD）是计算机视觉的一个前沿研究领域，旨在通过单源领域训练提升模型在未见目标领域的泛化能力。当前主流方法尝试通过数据增强技术来减轻领域差异。但由于领域转移和有限的领域特定知识，模型容易陷入简单分类特征（如颜色）的虚假关联，而非依赖关键的领域不变表示（如对象轮廓）。", "innovation": "本文提出了Cauvis（因果视觉提示）方法。首先引入了一个跨注意力提示模块，通过将视觉提示与跨注意力相结合来减轻由虚假特征带来的偏差。针对单领域泛化中视觉提示的不足领域知识覆盖和虚假特征纠缠问题，提出了一个双分支适配器，该适配器能够分离因果与虚假特征，并通过高频特征提取实现领域适应。实验表明，Cauvis在SDGOD数据集上达到最先进的效果，获得了15.9-31.4%的性能提升，并且在复杂干扰环境中展现出显著的鲁棒性优势。", "conclusion": "Cauvis方法在处理领域泛化中的关键挑战方面取得了显著进展，通过引入跨注意力提示模块和双分支适配器，有效减轻了虚假特征的影响，提升了模型在复杂环境下的鲁棒性。"}
{"llm_update_time": "20251023", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.19555", "html_url": "https://arxiv.org/abs/2510.19555", "title": "[重构] 视听模型在计数任务中的推理机制", "title_en": "[De|Re]constructing VLMs' Reasoning in Counting", "authors": "Simone Alghisi,Gabriel Roccabruna,Massimo Rizzoli,Seyed Mahed Mousavi,Giuseppe Riccardi", "background": "视听模型（VLMs）在诸如视觉推理等下游任务中表现出色，但仍旧存在识别关系（如空间、时间关系等）、理解时间序列（如帧序列）和计数物体等方面的局限性。已有研究通常侧重于评分基准评估VLMs的表现，而缺乏从根源上探索其失败原因的系统性研究。", "innovation": "本文通过建立受控实验环境，系统研究七种最先进的VLM模型在计数任务中的推理能力，揭示了VLMs对物体数量和类型、空间排列及干扰物共现的敏感性。深入的逐层分析表明，错误主要源于最后一层表示到输出空间的映射不准确。针对这些问题进行微调输出层，准确率可提升高达21%，并能在实际数据集上持续取得改进。", "conclusion": "通过提出有针对性的训练方法，本文解决了VLMs在视觉推理中的关键问题，显著提升了模型的计数准确性，并证实了改进措施的有效性。"}
{"llm_update_time": "20251023", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.19527", "html_url": "https://arxiv.org/abs/2510.19527", "title": "PoseCrafter: 极端场景下基于混合视频合成的相机姿态估计", "title_en": "PoseCrafter: Extreme Pose Estimation with Hybrid Video Synthesis", "authors": "Qing Mao,Tianxin Huang,Yu Zhu,Jinqiu Sun,Yanning Zhang,Gim Hee Lee", "background": "在3D视觉领域，从稀疏重叠的图像对中估计相机姿态仍然是一个关键且未解决的挑战，多数现有方法难以处理重叠小或无重叠的图像对。近年来，一些方法试图通过使用视频插值生成中间帧，并通过自一致性评分选择关键帧来解决问题，但生成的帧由于输入重叠小往往是模糊的，而选择策略既慢又没有明确与姿态估计算法对齐。", "innovation": "我们提出了Hybrid Video Generation（HVG）结合视频插值模型和姿态条件下的新颖视角合成模型来生成更清晰的中间帧。同时，我们还提出了一种基于特征匹配的选择器（FMS）以从合成结果中选择合适的中间帧用于姿态估计。实验结果表明，与现有的最先进的方法相比，PoseCrafter在小重叠或无重叠的场景中能够明显提升姿态估计性能。", "conclusion": "本文提出的方法PoseCrafter在Cambridge Landmarks、ScanNet、DL3DV-10K和NAVI数据集上的实验表明，与现有的最先进的方法相比，PoseCrafter在姿态估计性能方面具有明显优势，尤其是对于小重叠或无重叠的图像对。"}
{"llm_update_time": "20251023", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.19496", "html_url": "https://arxiv.org/abs/2510.19496", "title": "CARES：VLMs的上下文感知分辨率选择器", "title_en": "CARES: Context-Aware Resolution Selector for VLMs", "authors": "Moshe Kimhi,Nimrod Shabtay,Raja Giryes,Chaim Baskin,Eli Schwartz", "background": "大视觉语言模型（VLMs）通常以原生或高分辨率处理图像，以在多种任务中保持效果，但这会导致视觉标记占据总数的97-99%，从而产生较高的计算量和延迟，即便低分辨率的图像可能已经足够。这样做会浪费计算资源，并增加延迟，尤其是在处理低分辨率图像时更为明显。因此，需要一种方法来减少不必要的高分辨率处理，同时保持任务性能。", "innovation": "提出了一种名为CARES的轻量级预处理模块，即上下文感知分辨率选择器。该模块能够根据图像查询对，预测最小必要输入分辨率。CARES使用一个紧凑型VLM（350M）来提取特征，并在训练时以离散分类器的方式工作，但可以在推理时进行连续分辨率的插值以实现精细控制。研究结果表明，CARES可以在不同基准测试和目标VLM中保持任务性能，计算量最多可减少80%。", "conclusion": "CARES通过预测最小的必要输入分辨率，实现了高效的视觉语言处理，能够在保持任务性能的同时显著减少计算量。这种方法为视觉语言模型的应用提供了新的优化策略。"}
{"llm_update_time": "20251023", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.19463", "html_url": "https://arxiv.org/abs/2510.19463", "title": "在长期尾巴和高度不平衡的IC缺陷分类中探索'少数在多数'和'多数在少数'的属性", "title_en": "Exploring \"Many in Few\" and \"Few in Many\" Properties in Long-Tailed, Highly-Imbalanced IC Defect Classification", "authors": "Hao-Chiang Shao,Chun-Hao Chang,Yu-Hsien Lin,Chia-Wen Lin,Shao-Yun Fang,Yan-Hsiu Liu", "background": "尽管在深度分类技术和工厂自动光学检查模型方面已经有了显著的发展，但在实际应用场景下对长期尾部或高度失衡数据进行IC缺陷分类仍面临挑战。主要原因有两个：一是实际条件下（如IC行业高产出率）的数据分布远比通用公开的失衡数据集的分布更偏斜，使得针对开放失衡数据集设计的分类器无法在实际场景中有效工作；二是实际样本中包含类别特定特性和领域相关的类别无意识的特征，这增加了分类过程的复杂性，尤其是在高度失衡数据集上的复杂性。为了解决这些问题，本文提出了一个名为IC-Defect-14的数据集，这是一个来源自实际IC生产线上部署的自动光学检查系统的具有独特“内类簇”属性的大规模高度失衡IC缺陷图像数据集。", "innovation": "针对高度失衡数据集的分类挑战，本文提出了ReCAME-Net，这是一种采用多专家分类框架的方法，集成了区域通道注意模块、度量学习损失、难样本挖掘策略和知识蒸馏过程。实验证明，ReCAME-Net在IC-Defect-14数据集上优于之前最先进的模型，同时在一般公开数据集上也保持了可比性和竞争力。", "conclusion": "本文通过引入IC-Defect-14数据集和ReCAME-Net方法，克服了实际应用场景下对高度失衡数据进行IC缺陷分类的挑战。该数据集的独特内类簇特性强调了高内类多样性与高跨类相似性的复杂性。实验证明，ReCAME-Net在专门研究高度失衡数据的分类模型中表现出优秀的性能。"}
{"llm_update_time": "20251023", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.19560", "html_url": "https://arxiv.org/abs/2510.19560", "title": "HAD: 层次异构蒸馏以弥合事件驱动目标跟踪中的时空差距", "title_en": "HAD: Hierarchical Asymmetric Distillation to Bridge Spatio-Temporal Gaps in Event-Based Object Tracking", "authors": "Yao Deng,Xian Zhong,Wenxuan Liu,Zhaofei Yu,Jingling Yuan,Tiejun Huang", "background": "RGB摄像机在捕捉丰富的纹理细节和高空间分辨率方面表现出色，而事件摄像机则提供卓越的时间分辨能力和高动态范围（HDR）。充分利用这两种摄像机的优点可以在极具挑战的条件下（如高速运动、HDR环境以及动态背景干扰）显著增强目标跟踪的效果。然而，这两种技术在成像机理上存在根本不同的时空不对称性，这阻碍了有效的多模态集成。", "innovation": "为了解决这个问题，本文提出了一种名为HAD（Hierarchy Asymmetric Distillation）的多模态知识蒸馏框架，该框架明确建模并缓解了时空不对称性。HAD提出了一个分层对齐策略，该策略在保持学生网络计算效率和参数压缩性的前提下，最小化信息损失。大量的实验结果表明，HAD相较于最先进的方法显示出一致性的超越，全面的消融研究进一步验证了每个设计组件的效果和必要性。", "conclusion": "本研究提出了一种名为HAD的方法，该方法通过分层异构蒸馏有效地弥合了事件驱动目标跟踪中的时空差距，并通过实验验证了其相对于现有方法的优势。"}
{"llm_update_time": "20251023", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.19557", "html_url": "https://arxiv.org/abs/2510.19557", "title": "T2I模型中提示复杂性、质量、多样性和一致性之间的微妙平衡", "title_en": "The Intricate Dance of Prompt Complexity, Quality, Diversity, and Consistency in T2I Models", "authors": "Xiaofeng Zhang,Aaron Courville,Michal Drozdzal,Adriana Romero-Soriano", "background": "文本到图像(T2I)模型能够生成大量合成数据，这些数据的价值在于其与有限且固定的现实数据集相比提供了几乎无限的资源。之前的研究主要从三个关键维度评估合成数据的质量、多样性和一致性。尽管提示工程是与T2I模型交互的主要方式，但提示复杂性对这些关键维度的影响尚未被系统研究。", "innovation": "本文首先通过合成实验揭示了提示复杂性带来的泛化难度，并通过理论推导解释这一现象。接着，提出了一种全新的评估框架，能够比较真实数据和合成数据的有用性，并对提示复杂性如何影响使用常用T2I模型生成的合成数据的质量进行了全面分析。研究跨越了多样化的数据集，包括CC12M、ImageNet-1k和DCI，并评估了不同的推理时干预方法。结果显示，向更一般的情况泛化比反向更加困难，因为前者需要估计扩散模型未能学习的概率。大规模实验表明，增加提示复杂性会降低条件多样性和提示一致性，但会减少合成数据与真实数据的分布差异。此外，当前的推理时干预措施可以在增加生成多样性的同时，超出真实数据的支持范围。其中，提示扩展通过故意使用预训练语言模型作为似然估计器，始终在图像多样性和美学上取得最佳性能，甚至超过真实数据的效果。", "conclusion": "研究结果表明，增加提示复杂性可以减少合成数据与真实数据之间的分布差异，但会降低条件多样性和提示一致性。综合实验还表明，当前的推理时干预措施可以在增强生成多样性的同时，可能超出真实数据的支持范围。提示扩展在图像多样性和美学方面的表现始终最优，甚至超过真实数据的效果。"}
{"llm_update_time": "20251023", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.19574", "html_url": "https://arxiv.org/abs/2510.19574", "title": "你所看到的值得信任吗？基于视频对象检测的alpha通道无框攻击", "title_en": "Can You Trust What You See? Alpha Channel No-Box Attacks on Video Object Detection", "authors": "Ariana Yi,Ce Zhou,Liyang Xiao,Qiben Yan", "background": "随着目标检测模型在诸如自主车辆和监控平台等物理-信息系统中的部署，确保这些模型抵御对手攻击的安全性变得至关重要。尽管已有研究探索了图像域中的对抗攻击，但在视频域中这类攻击，尤其是在无框设置下，研究尚显不足。鉴于此，本研究提出了α-Cloak这一基于rgba视频alpha通道的第一个无框对手攻击，该攻击通过完全利用alpha通道将恶意目标视频与无害视频合成，使合成后的视频在不会被人类察觉的情况下持续欺骗目标检测器。", "innovation": "α-Cloak攻击创新点包括：完全不依赖模型架构、参数或输出的信息，且不会引入任何可察觉的伪影；系统性地研究了常见视频格式与播放应用中alpha通道的支持情况，并设计了一个确保视觉隐形和兼容性的合成算法；在五个最先进的目标检测器、一个视觉-语言模型和一个多模态大型语言模型（Gemini-2.0-Flash）上进行了评估，达到了100%的攻击成功率。", "conclusion": "该研究揭示了视频感知系统中一个尚未被探索的漏洞，即alpha通道在对抗设置中未被充分考虑，并强调了在对抗环境中需针对alpha通道建立防御机制的重要性。"}
{"llm_update_time": "20251023", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.19578", "html_url": "https://arxiv.org/abs/2510.19578", "title": "VGD: 视觉几何高斯绘制在前馈环视驾驶重建中的应用", "title_en": "VGD: Visual Geometry Gaussian Splatting for Feed-Forward Surround-view Driving Reconstruction", "authors": "Junhong Lin,Kangli Wang,Shunzhou Wang,Songlin Fan,Ge Li,Wei Gao", "background": "现有的前馈环视自动驾驶场景重建方法由于缺乏全局几何信息的学习，难以在保证几何一致性的同时提高新视角的质量。现有方法通常无法确保具有最小重叠区域的环视图像的几何一致性和重建质量，这使得重建新视角时面临巨大挑战。", "innovation": "本文提出了一种名为Visual Gaussian Driving (VGD)的前馈端到端学习框架，通过设计一种轻量级的VGGT架构来高效提取几何先验，并设计了一个高斯头模块，能够融合多尺度几何特征预测高斯参数以提升新视角的渲染质量。此外，通过多尺度特征的联合监督，进一步优化渲染质量，从而实现既具有高通用性又具有高再现准确度的环视图像重建。", "conclusion": "在nuScenes数据集上进行的实验表明，该方法在不同的设置和评估标准下均显著优于现有最先进的方法，在客观指标和主观质量上均有明显优势，验证了VGD框架在环视驾驶重建中的可扩展性和高保真度。"}
{"llm_update_time": "20251023", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.19371", "html_url": "https://arxiv.org/abs/2510.19371", "title": "AegisRF：使用敏感性引导的对抗扰动以保护神经辐射场的知识产权", "title_en": "AegisRF: Adversarial Perturbations Guided with Sensitivity for Protecting Intellectual Property of Neural Radiance Fields", "authors": "Woo Jae Kim,Kyu Beom Han,Yoonki Cho,Youngju Na,Junsik Jung,Sooel Son,Sung-eui Yoon", "background": "随着神经辐射场(NeRF)作为3D场景表示和新颖视图合成的强大工具的出现，保护其知识产权(IP)免受未经授权使用的保护变得越来越重要。然而，对NeRF的3D几何图形进行扰动会容易破坏场景结构，从而严重影响渲染质量，因此现有方法尽力避免几何扰动或将其限制在网格等明确空间。为解决这一问题，本文提出了一个可学习的敏感性来量化几何扰动在渲染质量上的空间变化影响，并提出了一种名为AegisRF的新型框架，该框架包含扰动场和敏感性场，前者通过在NeRF模型的预渲染输出（颜色和体积密度）中注入对抗性扰动来欺骗未经授权的下游目标模型，后者则学习敏感性以自适应地约束几何扰动，从而保持高质量可视化的同时破坏未经授权的应用。", "innovation": "提出了一种名为AegisRF的新型框架，结合使用扰动场和敏感性场。扰动场在NeRF模型的预渲染输出中注入对抗性扰动，敏感性场学习敏感性以自适应地约束几何扰动，同时保持高质量可视化，保护NeRF的知识产权。", "conclusion": "该研究表明AegisRF在多种下游任务和多种模式下具有普适性，保持高视觉保真度，同时有效地限制未经授权的应用。"}
{"llm_update_time": "20251023", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.19586", "html_url": "https://arxiv.org/abs/2510.19586", "title": "地球观测中分割模型的不确定性评估", "title_en": "Uncertainty evaluation of segmentation models for Earth observation", "authors": "Melanie Rey,Andriy Mnih,Maxim Neumann,Matt Overlan,Drew Purves", "background": "该论文探讨了用于卫星影像语义分割预测不确定性的估计方法。面对分割任务的不确定性估计，相较于标准图像分类任务，具有独特挑战，需要可扩展的方法并提供每个像素的不确定性估计。现有研究主要集中在场景理解或医疗影像方面，而这篇论文则特别关注遥感和地球观测应用中的现有方法的基准测试。", "innovation": "不同于以往的工作，本文主要是对遥感特定应用中现有方法进行基准测试，并侧重于检测预测错误和噪声影响区域的实际运用效果，涉及到的模型包括Stochastic Segmentation Networks及其集成模型，并使用多种神经网络结构和不确定性指标进行实验，提供了实用的建议。", "conclusion": "通过广泛的评估，文章提出多种实用建议，并展示了在不同遥感数据集（PASTIS和ForTy）中的实验结果，这些数据集具有不同的规模和地理覆盖范围，以及不同的标注置信度。"}
{"llm_update_time": "20251023", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.19579", "html_url": "https://arxiv.org/abs/2510.19579", "title": "多模态共学习在地球观测中的应用：通过模态协作提升单模态模型性能", "title_en": "Multi-modal Co-learning for Earth Observation: Enhancing single-modality models via modality collaboration", "authors": "Francisco Mena,Dino Ienco,Cassio F. Dantas,Roberto Interdonato,Andreas Dengel", "background": "多模态共学习正在成为机器学习中的一个有效范式，使得模型能够从不同模态的数据中协作学习，从而提升单一模态的预测能力。地球观测（EO）是一个典型的多模态数据分析领域，不同遥感传感器收集数据来感知我们的地球。前所未有的数据量带来了新的挑战，特别是在训练和推断阶段，由于实际中的限制因素，获取相同的传感器模态越来越复杂。在这一背景下，多模态共学习提供了一个有前景的策略，通过在训练阶段利用大量的传感器数据来提高推断时部署的单一模态模型的性能。当前大多数研究集中在为特定下游任务或推断阶段的具体模态设计定制解决方案。", "innovation": "提出了一种新的多模态共学习框架，该框架能够在不针对特定模态进行推断的情况下泛化到各种任务。该方法结合了对比学习和模态鉴别学习，引导单一模态模型将内部模型流形结构化为模态共享和模态特定信息。研究结果表明，与近期机器学习和计算机视觉领域的最新方法以及专为地球观测设计的方法相比，该框架在四个覆盖不同传感器模态的地球观测基准上的分类和回归任务中均表现出一致的预测改进。", "conclusion": "这些发现验证了该框架在各种地球观测应用中的单模态推断场景中的有效性。"}
{"llm_update_time": "20251023", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.19581", "html_url": "https://arxiv.org/abs/2510.19581", "title": "解决景深限制：高分辨率多焦深度图像融合的新范式", "title_en": "Addressing the Depth-of-Field Constraint: A New Paradigm for High Resolution Multi-Focus Image Fusion", "authors": "Luca Piano,Peng Huanwen,Radu Ciprian Bilcu", "background": "多焦点图像融合（MFIF）解决了光学镜头的景深（DOF）限制问题，即只有特定距离范围内的物体能保持清晰。虽然传统方法和深度学习方法已经推进了该领域的发展，但仍存在挑战，如训练数据有限、合成数据集与实际场景差距大以及难以处理无信息区域。", "innovation": "提出了VAEE DOF，一种新颖的MFIF方法，利用蒸馏变分自编码器进行高保真、高效的图像重建。融合模块同时处理多达七个图像，实现了多焦距点下的稳健融合。为解决数据稀缺问题，引入了MattingMFIF，一个新型的4K合成数据集，模拟了现实照片中的实际景深效果。该方法达到最先进的结果，生成无缝、无伪影的融合图像，并在合成与真实场景之间建立了桥梁，显著推进了复杂MFIF挑战的解决。", "conclusion": "该方法展示了在解决多焦点图像融合挑战方面的突破，实现了高质量、无缝的图像融合，并提供了解决合成与真实场景之间差距的有效途径。相关代码和权重可在指定位置获取。"}
{"llm_update_time": "20251023", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.19590", "html_url": "https://arxiv.org/abs/2510.19590", "title": "大规模数字化纸张心电图：一种用于临床研究的开源算法", "title_en": "Digitizing Paper ECGs at Scale: An Open-Source Algorithm for Clinical Research", "authors": "Elias Stenhede,Agnar Martin Bjørnstad,Arian Ranjbar", "background": "大量临床心电图（ECGs）仅以纸质扫描的形式存在，无法用于现代自动化诊断。这就限制了这些宝贵数据的广泛应用。为了克服这一问题，本文介绍了一种全自动且模块化的框架，用于将扫描或拍摄的心电图转换为可用于临床和研究的数字信号。这种框架在临床研究中具有重要意义，可以有效解锁以往无法使用的纸质心电图档案，进一步推动AI驱动诊断的普及与应用。", "innovation": "该框架具有自动转换功能，能够处理包含常见缺陷的扫描纸张。通过在两个大规模数据集上进行测试验证，该框架在所有子类别中均优于现有技术。此外，完整的软件代码被释放为开源，以促进进一步的开发和使用。", "conclusion": "该研究旨在通过开源软件使得心电图的数字化更具可行性，进一步提高心电图的临床应用价值，并希望能促进行业内对AI驱动诊断技术的采用与推广。"}
{"llm_update_time": "20251023", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.19597", "html_url": "https://arxiv.org/abs/2510.19597", "title": "CBDiff: 条件贝努利扩散模型在图像篡改定位中的应用", "title_en": "CBDiff:Conditional Bernoulli Diffusion Models for Image Forgery Localization", "authors": "Zhou Lei,Pan Gang,Wang Jiahao,Sun Di", "background": "图像伪造定位 (IFL) 是图像取证中的关键任务，旨在准确识别图像中的修改或篡改区域。现有的方法通常生成单个确定性的定位图，这在高风险应用场景（如法医分析和安全监控）中缺乏精确性和可靠性。", "innovation": "提出了高级条件贝努利扩散模型 (CBDiff)，该模型能够在给定篡改图像的情况下生成多种多样且可能的定位图，从而提供篡改分布的更丰富和全面的表示。CBDiff 进一步将伯努利噪声引入扩散过程，以更准确地反映伪造掩码的固有二元性和稀疏性。此外，CBDiff 引入了时间步长交叉注意力机制 (TSCAttention)，旨在利用时间步骤中的语义特征指导来提高伪造检测。", "conclusion": "在八个公开基准数据集上进行的大量实验表明，CBDiff 显著优于现有最先进的方法，突显了其在实际部署中的强大潜力。"}
{"llm_update_time": "20251023", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.19592", "html_url": "https://arxiv.org/abs/2510.19592", "title": "Decomposed Attention Fusion in MLLMs for Training-Free Video Reasoning Segmentation", "title_en": "Decomposed Attention Fusion in MLLMs for Training-Free Video Reasoning Segmentation", "authors": "Su Ho Han,Jeongseok Hyun,Pilhyeon Lee,Minho Shim,Dongyoon Wee,Seon Joo Kim", "background": "多模态大语言模型（MLLMs）通过关注与文本查询相关的视觉标记，显示出强大的视频理解能力。为了适配视频定位任务，本文将视频推理分割任务重新定义为视频问答任务，并通过展开机制提取注意力图。然而，原始的注意力图存在噪声问题，与物体区域的对齐度较差。", "innovation": "本文提出了分解注意力融合（DecAF）方法，通过两步机制改进这些图：（1）对比对象-背景融合；（2）互补视频-帧融合。这种机制抑制了无关活动，增强了对象集中的线索，使注意力图可以直接转化为粗略的分割掩码。此外，引入了注意力引导的SAM2提示方法，以获取精细的掩码。与其他需要同时训练MLLMs和SAM的方法不同，本文的方法完全不需要重新训练。DecAF在无训练方法中表现出色，达到了与基于训练方法相当的表现，于是指引视觉对象分割（Referring Video Object Segmentation, RefVOS）和推理视频对象分割（Reasoning Video Object Segmentation, ReaVOS）基准上取得了优异成绩。", "conclusion": "DecAF方法在无训练方法中表现出优异的性能，并在引导视觉对象分割和推理视频对象分割基准测试上实现了与基于训练方法相媲美的效果。"}
{"llm_update_time": "20251023", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.19599", "html_url": "https://arxiv.org/abs/2510.19599", "title": "XBench: 胸部放射影像中视觉-语言解释的综合基准", "title_en": "XBench: A Comprehensive Benchmark for Visual-Language Explanations in Chest Radiography", "authors": "Haozhe Luo,Shelley Zixin Shu,Ziyu Zhou,Sebastian Otalora,Mauricio Reyes", "background": "视觉-语言模型（VLMs）在医学影像理解方面展示了卓越的零样本性能，然而其接地能力，即文本概念与视觉证据的一致性程度，仍需进一步研究。在医学领域，可靠的接地对于可解释性和临床应用至关重要。因此，本文提出了一项系统性基准测试，针对七种CLIP风格的VLM变体评估胸部X光片的跨模态可解释性。", "innovation": "本文引入了XBench，第一个系统性地评估VLMs在胸部X光片跨模态可解释性基准测试，使用跨注意力和相似性定位图生成视觉解释，并定量评估其与放射科医生标注区域的一致性，揭示了小而弥散的病灶、基于胸部X光数据预训练的模型以及可识别能力和接地能力之间的关系。", "conclusion": "当前的VLMs虽然在识别能力方面表现出色，但在临床可靠的接地方面仍存在不足，这意味着在临床实践中应用这些模型之前需要针对解释的目标设立专门的基准测试。"}
{"llm_update_time": "20251023", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.19622", "html_url": "https://arxiv.org/abs/2510.19622", "title": "增强时刻检索：无外部依赖两阶段学习", "title_en": "Augmenting Moment Retrieval: Zero-Dependency Two-Stage Learning", "authors": "Zhengxuan Wei,Jiajin Tang,Sibei Yang", "background": "现有的时刻检索方法面临三个关键瓶颈：（1）数据稀缺导致模型只能进行浅层的关键词特征关联；（2）在相邻事件之间的过渡区域存在边界模糊问题；（3）细粒度语义的区分度不足（例如，区分“踢球”和“扔球”）。因此，目前的方法难以精确地识别和区分关键事件的时间点。", "innovation": "本文提出了一种零外部依赖增强时刻检索框架AMR，旨在克服由于数据标注不足和缺乏稳健的边界和语义区分能力所导致的局部最优问题。AMR通过以下技术创新：（1）解决现有注释中的边界信息和语义混淆问题，无需额外数据（避免昂贵的手动标注成本），（2）通过训练保留增强的边界和语义差异能力，同时广泛应用于现实场景，显著提高性能。此外，还提出了两阶段训练框架，包括冷启动阶段和蒸馏适应阶段。", "conclusion": "在多个基准上的实验表明，AMR相比之前的先进方法在性能上有所提升。"}
{"llm_update_time": "20251023", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.19618", "html_url": "https://arxiv.org/abs/2510.19618", "title": "通过生成通信机制实现的实用异质协作感知", "title_en": "Pragmatic Heterogeneous Collaborative Perception via Generative Communication Mechanism", "authors": "Junfei Zhou,Penglin Dai,Quanmin Wei,Bingyi Liu,Xiao Wu,Jianping Wang", "background": "多智能体协作能够增强个体智能体的感知能力，但不同传感器和模型导致的差异在实际应用中导致了协作中的领域间隔问题。现有基于适应和重建的方法因两个关键限制而无法支持实用的异构协作：(1) 编码器或核心模块的侵入性重新训练会破坏智能体间的语义一致性；(2) 吸纳新智能体的高计算成本限制了可扩展性。", "innovation": "提出了一种新颖的生成通信机制（GenComm），它通过特征生成无缝促进异构多智能体系统中的感知，而不改变原始网络，并采用轻量级的空间信息数值对齐，以低成本高效吸纳新智能体。具体来说，设计了一个定制的可变形信息提取器来从中提取每个合作者的空间信息，然后通过空间感知特征生成器生成与自身语义空间对齐的同时保持合作者空间信息的特征。生成的特征进一步通过通道增强器优化后再进行融合。", "conclusion": "实验在OPV2V-H、DAIR-V2X和V2X-Real数据集上的结果表明，GenComm在集成新智能体时相较于现有最先进的方法，实现了计算成本和参数数量81%的降低。"}
{"llm_update_time": "20251023", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.19626", "html_url": "https://arxiv.org/abs/2510.19626", "title": "MedReason-R1：利用强化学习和局部缩放进行CT诊断的学习推理", "title_en": "MedReason-R1: Learning to Reason for CT Diagnosis with Reinforcement Learning and Local Zoom", "authors": "Yifan Li,Fenghe Tang,Yingtai Li,Shaohua Kevin Zhou", "background": "通用的大型视觉-语言模型（VLMs）在生成自然图像的详细描述方面表现出强大的能力，但在医疗领域中的表现仍不够理想，即使是相对简单的工作，主要原因是缺乏大规模、高质量的专业医学影像数据集，忽视了从粗略到精细诊断过程的问题。", "innovation": "该研究通过构建包含84K QA对的CT-RATE-VQA数据集解决数据不足的问题，并提出了带有明确推理过程的MedReason-R1医疗视觉语言模型，该模型通过嵌入局部增强的疾病区域来改进模型的诊断性能。此外，引入了GRPO强化学习框架，使模型能够进行有效推理，无需依赖昂贵的手动注释。", "conclusion": "与现有的通用和医疗视觉语言模型相比，MedReason-R1在CT疾病诊断方面取得了最先进的性能，同时保持了较强的泛化能力。"}
{"llm_update_time": "20251023", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.19678", "html_url": "https://arxiv.org/abs/2510.19678", "title": "我用我的模型之眼窥探：视觉搜索作为MLLMs行为测试", "title_en": "I Spy With My Model's Eye: Visual Search as a Behavioural Test for MLLMs", "authors": "John Burden,Jonathan Prunty,Ben Slater,Matthieu Tehenan,Greg Davis,Lucy Cheke", "background": "多模态大语言模型（MLLMs）在视觉语言任务中表现良好，但其视觉处理机制不透明。大多数黑盒评估仅测量任务准确性，无法揭示其背后的机制。借鉴认知心理学，本文将经典的视觉搜索范式——最初用于研究人类感知——应用于测试MLLMs是否具备“跳读”效应，即在不受干扰目标集大小影响的情况下检测显着的视觉特征。", "innovation": "本文创新性地将视觉搜索实验引入MLLMs的评估，通过色彩、大小和光照等特征控制实验，发现先进MLLMs在基于单一特征的搜索中表现出类似人类的“跳读”效应，同时在基于多重特征的组合搜索任务中表现出容量限制。此外，通过针对性的微调和机制可解释性分析，证实了MLLMs在物体表示中整合了自然场景先验，如光照方向。", "conclusion": "我们的工作表明，视觉搜索可以作为一种认知基础的诊断工具，用于评估MLLMs的感知能力。"}
{"llm_update_time": "20251023", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.19653", "html_url": "https://arxiv.org/abs/2510.19653", "title": "Re-Activating Frozen Primitives for 3D Gaussian Splatting", "title_en": "Re-Activating Frozen Primitives for 3D Gaussian Splatting", "authors": "Yuxin Cheng,Binxiao Huang,Wenyong Zhou,Taiqiang Wu,Zhengwu Liu,Graziano Chesi,Ngai Wong", "background": "3D Gaussian Splatting (3D-GS) 方法可以在实时生成逼真的全新视角，但复杂场景会导致过度重建的失真问题，表现为局部模糊和针状失真。最近的研究认为这些问题源于对大规模高斯函数分割不足。然而，该论文指出两个基本限制：梯度强度在密集化过程中的稀释，以及原生冻结现象，即在复杂区域，关键的高斯密集化被抑制，而不合适的高斯尺度则被困在局部最优解中。", "innovation": "论文提出了一种方法 ReAct-GS，基于重激活原则来解决上述问题。该方法包含两个创新点：(1) 一种考虑多视角 alpha-混合权重的重要性驱动密集化标准，以重新激活复杂区域中停滞的原生增长；(2) 一种重激活机制，通过自适应参数扰动重新激活冻结的原生结构，从而改善精细几何细节的保留，同时在多种3D-GS变体中显示出广泛的应用效果。", "conclusion": "全面的实验表明，ReAct-GS 能够有效地消除过度重建的失真，同时在标准的新视角合成指标上达到最先进的性能，同时保留了复杂的几何细节。此外，重激活机制在与诸如 Pixel-GS 等其他 3D-GS 变体结合时也显示出一致的改进，证明了其广泛的应用性。"}
{"llm_update_time": "20251023", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.19679", "html_url": "https://arxiv.org/abs/2510.19679", "title": "Curvilinear Structure-preserving Unpaired Cross-domain Medical Image Translation", "title_en": "Curvilinear Structure-preserving Unpaired Cross-domain Medical Image Translation", "authors": "Zihao Chen,Yi Zhou,Xudong Jiang,Li Chen,Leopold Schmetterer,Bingyao Tan,Jun Cheng", "background": "无配对的图像到图像翻译已成为医学影像领域的重要技术，能够实现跨模态合成、领域适应和数据增强，无需昂贵的配对数据集。然而，现有方法常导致微细曲线结构的失真，影响诊断可靠性和定量分析。特别是在眼科和血管影像领域，微小形态变化具有重要的临床意义。", "innovation": "本文提出了Curvilinear Structure-preserving Translation (CST)，这是一种通用框架，通过在训练中整合结构一致性，显式地在无配对翻译过程中保留微细曲线结构。CST 通过添加曲线提取模块为拓扑监督增加基准模型，可在现有方法中无缝集成，并在光学相干断层扫描血管成像、彩色眼底成像和X射线冠状动脉造影三种医学影像模态中进行全面评估，展示了其提高翻译保真度并达到最新技术水平的能力。", "conclusion": "通过增强学习映射中的几何完整性，CST 成功建立了向医学影像中曲线结构感知的跨域翻译的系统途径。"}
{"llm_update_time": "20251023", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.19559", "html_url": "https://arxiv.org/abs/2510.19559", "title": "关于时间：揭示视觉语言模型中时间的结构", "title_en": "A Matter of Time: Revealing the Structure of Time in Vision-Language Models", "authors": "Nidham Tekaya,Manuela Waldner,Matthias Zeppelzauer", "background": "大型的视觉-语言模型（VLMs）如CLIP因为它们能够提供广泛且富有表现力的多模态表示而变得流行。通过利用带有多样化文本元数据的大规模训练数据，这些模型获得了开放词汇能力，能够解决超出训练范围的任务。本文研究了VLMs的时态认知能力，评估了它们将视觉内容定位在时间上能力。我们引入了一个名为TIME10k的数据集，包含超过10,000张具有时间参考的真实图像，并通过一个新型方法评估了37种VLMs的时态认知能力。研究表明，时态信息在VLM嵌入空间中按低维非线性流形分布，基于此，我们提出了从嵌入空间推导出显式", "innovation": "我们提出了从嵌入空间推导出的显式“时间线”表示方法，这些表示方法能够建模时间和其按顺序的进展，并有助于增强时间推理任务的表现。实践证明，这些方法与基于提示的方法相比，尽管计算效率更高，但在准确性上具有竞争力甚至更优。所有相关的代码和数据可在提供的链接中获得。这项工作对于理解VLMs的时态认知机制以及相关应用的发展具有重要贡献。", "conclusion": "我们的研究揭示了VLMs在大规模训练数据中如何处理时态信息，并提出了新的方法来利用这种机制解决时间推理任务。我们的时间线方法在准确性上往往优于基于提示的基准方法，并且计算效率更高。"}
{"llm_update_time": "20251023", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.19695", "html_url": "https://arxiv.org/abs/2510.19695", "title": "通过Ensemble-CAM实现可解释的面部 presentations 攻击检测", "title_en": "Explainable Face Presentation Attack Detection via Ensemble-CAM", "authors": "Rashik Shadman,M G Sarwar Murshed,Faraz Hussain", "background": "面部等生物特征数据的伪造（presentation attacks）是一种严重的安全威胁，攻击者使用虚假的生物特征信息（如面部、指纹或虹膜图像）以获得未经授权的系统访问权限。为应对这一威胁，已经设计了多种基于深度学习（DL）的presentation attack detection (PAD) 系统。然而，大部分DL模型的工作原理如同黑盒，其决策对用户来说不够透明。可解释性技术旨在提供关于DL模型行为或决策的详细信息，特别是在基于DL的面部PAD系统中，提供视觉解释尤为必要，因为这有助于理解和确定关键区域，这些区域决定了系统认为生物特征图像是真实还是伪造的。", "innovation": "本文提出了Ensemble-CAM技术，用以为基于DL的面部PAD系统提供视觉解释。该技术旨在通过提高对这些系统行为的理解来改进基于DL的面部PAD系统，增强其透明度和可信度。", "conclusion": "通过提供视觉解释，本文旨在改进基于DL的面部PAD系统，使这些系统的行为更加透明和可信。"}
{"llm_update_time": "20251023", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.19654", "html_url": "https://arxiv.org/abs/2510.19654", "title": "从预测到规划：基于策略的世模型在协作状态-行动预测中的应用", "title_en": "From Forecasting to Planning: Policy World Model for Collaborative State-Action Prediction", "authors": "Zhida Zhao,Talas Fu,Yifan Wang,Lijun Wang,Huchuan Lu", "background": "尽管在构建世界模型方面取得了显著进展，但它们在自主系统中的潜力仍远未被充分利用：世界模型主要用于世界模拟，而与轨迹规划脱钩。最近的努力试图在一个统一框架中统一世界建模和规划，但世界建模对规划的协同增强机制仍需进一步探索。本文介绍了一种新的驾驶模式——策略世界模型（PWM），它不仅在统一的架构中整合了世界建模和轨迹规划，还通过提出的无动作未来状态预测方案，利用学习到的世界知识来辅助规划。通过协同状态-行动预测，PWM 可模拟人类的前瞻性知觉，从而提供更可靠的任务规划性能。为了提高视频预测效率，我们还引入了一种动态增强的并行令牌生成机制，配备了上下文向导化编码器和自适应动态焦点损失。尽管仅使用前方相机输入，我们的方法在可靠性和性能方面与依赖多视图和多模态输入的方法持平或超越了这些方法", "innovation": "提出了一种新的驾驶模式——策略世界模型（PWM），将世界建模和轨迹规划整合在统一的架构中，并通过无动作未来状态预测方案利用学习的世界知识来辅助规划。引入了动态增强的并行令牌生成机制，包括上下文向导化编码器和自适应动态焦点损失，提高了视频预测的效率。使用前方相机输入实现了与依赖多视图和多模态输入方法媲美的性能", "conclusion": "策略世界模型通过协作状态-行动预测模拟了人类的前瞻性知觉能力，提供了更可靠的规划性能。动态增强的并行令牌生成机制显著提高了预测效率。尽管仅使用前方相机输入，但性能媲美甚至超越依赖多模态输入的方法。代码和模型权重将在指定的网址发布。"}
{"llm_update_time": "20251023", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.19814", "html_url": "https://arxiv.org/abs/2510.19814", "title": "如何评估单目深度估计？", "title_en": "How to Evaluate Monocular Depth Estimation?", "authors": "Siyang Wu,Jack Nugent,Willow Yang,Jia Deng", "background": "单目深度估计是一个快速发展的任务，但现有文献中缺乏标准化的评估方法和多样的评价指标，这些指标的权衡和行为尚未被充分理解", "innovation": "引入了基于视面法线相对值的新评价指标，并提供了新的深度可视化工具和原理性的方法来创建更符合人类判断的综合评价指标", "conclusion": "现有评价指标对曲率扰动过度敏感，新提出的方法弥补了这一不足，更好地与人类判断相一致"}
{"llm_update_time": "20251023", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.19716", "html_url": "https://arxiv.org/abs/2510.19716", "title": "LyTimeT: 朝向稳健且可解释的状态变量发现", "title_en": "LyTimeT: Towards Robust and Interpretable State-Variable Discovery", "authors": "Kuai Yu,Crystal Su,Xiang Liu,Judah Goldfeder,Mingyuan Shao,Hod Lipson", "background": "从高维视频中提取系统的真正动力学变量存在挑战，因为存在诸如背景运动、遮挡和纹理变化等分散注意力的视觉因素。现有的方法难以学习动力系统的稳健且稳定的潜在表示，这对于准确的长期视频预测有着重要的影响。目前发展出的方法仍然难以在扰动背景下保持不变性，并且在基线模型中表现出较高的分析均方误差。", "innovation": "本文提出了一种两阶段框架LyTimeT，通过时空时窗器自编码器学习动力系统的稳健且稳定的潜在表示。第一阶段使用全局注意力聚焦于动态相关区域，并抑制无关变异。第二阶段通过线性相关分析筛选出最有物理意义的维度，并利用基于李亚普诺夫的稳定性调节者精炼过渡动态，确保收缩并减少计算中错误的累积。实验结果表明，LyTimeT在五项合成基准和四项真实世界动力系统中，包括混沌现象，实现了与真实值最为接近的信息互惠度和固有维度估计，保持不变性并递送了最低的分析均方误差，超过了基于CNN的（TIDE）和仅使用变换器的基线模型。研究表明，结合时空注意与稳定性约束能够生成准确且物理可解释的预测模型", "conclusion": "实验结果表明，结合时空注意机制与稳定性约束可以生成既准确又物理可解释的动力学模型，该模型在各基准测试和真实世界动态系统中表现优异，实现了信息互惠度、固有维度估计、不变性以及分析均方误差的优化。"}
{"llm_update_time": "20251023", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.19808", "html_url": "https://arxiv.org/abs/2510.19808", "title": "Pico-Banana-400K：面向文本指导图像编辑的大规模数据集", "title_en": "Pico-Banana-400K: A Large-Scale Dataset for Text-Guided Image Editing", "authors": "Yusu Qian,Eli Bocek-Rivele,Liangchen Song,Jialing Tong,Yinfei Yang,Jiasen Lu,Wenze Hu,Zhe Gan", "background": "近年来，多模态模型的进展展示了出色的文本指导图像编辑能力，系统如GPT-4o和Nano-Banana已经设定了新基准。然而，研究界仍受制于大量高质量且开放获取的真实图像数据集的缺乏。本文介绍了一个名为Pico-Banana-400K的全面的图像编辑数据集，包含40万张图片，旨在支持基于指令的图像编辑研究。", "innovation": "Pico-Banana-400K通过利用Nano-Banana从OpenImages集合中的真实照片生成多样化编辑对，系统地保证了高质量和多样化，采用了细粒度的图像编辑分类法，基于MLLM的质量评分并进行了仔细的编辑，确保了修改的一致性和指令忠实度。此外，数据集还包含了三个专门的子集，分别为顺序编辑、偏好看法和编辑指令数据。通过提供这一大规模且富任务的数据集，Pico-Banana-400K为下一代文本指导图像编辑模型的训练和基准测试奠定了坚实基础。", "conclusion": "Pico-Banana-400K为基于指令的图像编辑研究提供了一个大规模、高质量且任务丰富的资源平台，将推动该领域的创新与发展。"}
{"llm_update_time": "20251023", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.19802", "html_url": "https://arxiv.org/abs/2510.19802", "title": "Class-Aware Prototype Learning with Negative Contrast for Test-Time Adaptation of Vision-Language Models", "title_en": "Class-Aware Prototype Learning with Negative Contrast for Test-Time Adaptation of Vision-Language Models", "authors": "Xiaozhen Qiao,Jingkai Zhao,Yuqiu Jiang,Xianda Guo,Zhe Sun,Hongyuan Zhang,Xuelong Li", "background": "视觉-语言模型（VLMs）在大规模图像-文本预训练后能够展示出色的零样本泛化能力，但在部署分布与训练分布不一致时，其性能会下降。现有的测试时适应（TTA）方法通常通过利用未标记的目标数据更新模型，但这些方法往往忽视了长尾分布中的原型降解问题以及语义相似类别之间的混淆问题，", "innovation": "提出了一种名为CPL-NC的轻量级TTA框架，专为增强VLMs在分布偏移下的泛化能力。该框架包括一种Class-Aware Prototype Cache模块，该模块基于测试时的频率和激活历史动态调整每个类别的容量，并通过被动类别的再生机制保留稀有类别的知识。此外，还提出了一种Negative Contrastive Learning机制来识别和限制硬的视觉-文本负例，提高类内区分度。框架采用不对称优化策略，仅精炼文本原型，同时稳定视觉特征。实验表明，CPL-NC在15个基准数据集上均优于先前的TTA方法，无论是基于ResNet-50还是ViT-B/16的骨干网络。", "conclusion": "实验结果表明，CPL-NC框架在多种视觉-语言模型中表现出更优的测试时泛化能力，并能够有效解决长尾分布中的原型降解问题以及语义相似类别的混淆问题。"}
{"llm_update_time": "20251023", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.19789", "html_url": "https://arxiv.org/abs/2510.19789", "title": "OmniMotion-X: 多模态全身动作生成", "title_en": "OmniMotion-X: Versatile Multimodal Whole-Body Motion Generation", "authors": "Guowei Xu,Yuxuan Bian,Ailing Zeng,Mingyi Shi,Shaoli Huang,Wen Li,Lixin Duan,Qiang Xu", "background": "该论文介绍了一种名为OmniMotion-X的多功能多模态框架，用于生成全身人体动作，依托统一序列到序列的方式使用自回归扩散变换器。OmniMotion-X能够有效地支持多种多模态任务，如文本到动作、音乐到舞蹈、语音到手势、以及全局空间-时间控制场景（例如运动预测、插值、补充和关节/轨迹引导合成），以及这些任务的灵活组合。研究者提出了使用参考动作作为新的条件信号，大幅提升了生成内容的一致性、风格和时间动态，这对于实现逼真动画至关重要。为了处理多模态冲突，他们引入了一种逐步弱到强混合条件训练策略。为了支持高质量多模态训练，他们构建了至今为止最大规模的统一多模态动作数据集OmniMoCap-X，整合了28个公开的MoCap来源，涵盖了10种不同任务，标准化为30 fps的SMPL-X格式。为了确保详细的注释一致性，他们将序列渲染成视频，并使用GPT-4o自动生成结构化和分层的描述，捕捉低级动作和高层语义。", "innovation": "1. 使用参考动作作为新的条件信号，提升生成内容的一致性、风格和时间动态。2. 逐步弱到强的混合条件训练策略来处理多模态冲突。3. 构建了OmniMoCap-X，这是迄今为止最大的统一多模态动作数据集。4. 使用GPT-4o自动生成结构化的视频描述，提高注释的质量和一致性。", "conclusion": "实验表明，OmniMotion-X显著超越了现有方法，在多个多模态任务上实现了最先进的性能，能够交互生成逼真、连贯且可控的长期动作。"}
{"llm_update_time": "20251023", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.19819", "html_url": "https://arxiv.org/abs/2510.19819", "title": "这是追踪器上线了吗？一种动态追踪基准协议", "title_en": "Is This Tracker On? A Benchmark Protocol for Dynamic Tracking", "authors": "Ilona Demler,Saumya Chauhan,Georgia Gkioxari", "background": "当前存在的基准测试在评估和诊断点追踪方法的能力以及限制方面存在不少缺陷，缺乏对真实世界场景复杂性的充分模拟，特别是运动复杂性、遮挡模式和物体多样性方面的特性。这些基准测试资料通常来自于现有的数据集和基于第一人称的真实世界记录，但尚未包含足够的现实挑战以评估先进的方法。因此，需要一个新的严格的基准来填补这一空白，用以检测和引导点追踪技术的发展方向，提升算法的鲁棒性。", "innovation": "提出了一个名为ITTO的新基准套件，旨在评估和诊断点追踪方法的能力和局限性。这个基准采用了多阶段的人工注释方法，收集高质量的注释，并包括来自现有数据集和第一人称现实世界记录的视频。ITTO能够捕捉到真实场景中的运动复杂性、遮挡模式和物体多样性等特性，这些都是现有基准所不具备的。研究通过严谨分析当前最先进的追踪方法在ITTO上的表现，揭示了这些方法存在的关键失效模式，并指出全新的建模方法以适应现实世界动态的必要性。", "conclusion": "该研究通过提出ITTO，为点追踪技术的进步提供了一个坚实的基础测试平台，并强调了必须针对现实世界动态来开发新的建模方法的必要性。该研究结果指出了现有追踪方法在识别问题、遮挡后重新识别等方面存在的不足，迫切需要新的解决方案和路径来进一步发展的追踪算法。"}
{"llm_update_time": "20251023", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.19817", "html_url": "https://arxiv.org/abs/2510.19817", "title": "olmOCR 2: 单元测试奖励用于文档OCR", "title_en": "olmOCR 2: Unit Test Rewards for Document OCR", "authors": "Jake Poznanski,Luca Soldaini,Kyle Lo", "background": "本文档介绍的是olmOCR 2，这是一个用于将数字化打印文档（如PDF）转换为干净、自然排版的纯文本的强大OCR系统。olmOCR 2基于一个名为olmOCR-2-7B-1025的专门训练的、大小为7B的视觉语言模型（VLM），该模型通过验证奖励的强化学习进行训练。为了扩展单元测试的创建，作者开发了一种生成具有多样化和具有挑战性布局的合成文档的管道，这些合成文档带有已知的地面真实HTML源代码和提取的测试案例。", "innovation": "文章的主要创新在于，通过强化学习结合验证奖励（RLVR）来训练模型，其中奖励是一个多样化的二进制单元测试组。为了缩小单元测试的规模，作者开发了一种管道来生成合成文档，这些文档具有多样化的布局和已知的地面真实HTML源代码。另外，这种方法在这方面的性能表现出色，尤其在数学公式转换、表格解析和多栏布局方面相比此前版本有显著改进。", "conclusion": "作者通过这项工作，展示了olmOCR-2-7B-1025模型、用于OCR的数据和代码在网络上发布，遵循宽松的开源许可证，为OCR系统的进一步发展提供了新思路和资源。"}
{"llm_update_time": "20251023", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.18999", "html_url": "https://arxiv.org/abs/2510.18999", "title": "$\nabla$-SDF: 使用梯度增强八叉树插值和神经残差在线学习欧几里得符号距离函数", "title_en": "$\\nabla$-SDF: Learning Euclidean Signed Distance Functions Online with Gradient-Augmented Octree Interpolation and Neural Residual", "authors": "Zhirui Dai,Qihao Qian,Tianxing Fan,Nikolay Atanasov", "background": "从点云数据估计符号距离函数（SDF）已被证明对许多机器人自主能力有好处，包括定位、制图、运动规划和控制。支持在线和大规模SDF重建的方法倾向于依赖离散体积数据结构，这会影响SDF估计的连续性和可微性。最近，使用隐式特征的神经网络方法展示了高保真和可微的SDF重建，但通常效率较低，且在大型环境中可能出现灾难性遗忘和内存限制，并且往往局限于截断的SDF。", "innovation": "本文提出了一种混合方法$\nabla$-SDF，结合了从梯度增强八叉树插值获得的显式先验和隐式神经残差。该方法实现了非截断（欧几里得）SDF重建，具有与体积方法相当的计算和内存效率，以及与神经网络方法相当的可微性和准确性。广泛的实验表明，本方法在准确性和效率方面优于现有技术，提供了一种可扩展的解决方案，适用于机器人学和计算机视觉中的下游任务。", "conclusion": "本工作提出了一种混合方法$\nabla$-SDF，该方法结合了从梯度增强八叉树插值获得的显式先验和隐式神经残差，能够实现非截断的SDF重建，同时保持与体积方法相当的计算和内存效率，与神经网络方法相当的可微性和准确性。实验结果表明，该方法在准确性和效率方面优于现有技术，为机器人学和计算机视觉中的下游任务提供了可扩展的解决方案。"}
{"llm_update_time": "20251023", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.19105", "html_url": "https://arxiv.org/abs/2510.19105", "title": "MetaCluster: 使柯莫哥洛夫-阿尔诺德网络深度压缩的方法", "title_en": "MetaCluster: Enabling Deep Compression of Kolmogorov-Arnold Network", "authors": "Matthew Raffel,Adwaith Renjith,Lizhong Chen", "background": "柯莫哥洛夫-阿尔诺德网络（KANs）通过将标量权重替换为每条边的基系数向量来增强表达能力与准确性，但同时也导致参数和内存的成倍增长。然而，这样的高参数量限制了其广泛应用。", "innovation": "提出了一种名为MetaCluster的框架，可使KANs高度压缩而不影响准确率。通过一个与KAN联合训练的轻量级元学习器将低维度嵌入映射到系数向量，使它们位于便于聚类的低维流形上。然后在系数空间中运行K-means，用共享质心替换每个边向量。元学习器随后可以被丢弃，通过短暂的调优恢复任何残留的准确率损失。结果模型只存储一个小的代码簿和每条边的索引，利用KAN参数的向量性质分摊存储。", "conclusion": "在MNIST、CIFAR-10和CIFAR-100上，MetaCluster通过对标准KANs和使用多种基函数的ConvKANs，实现了高达80倍的参数存储减少，而没有损失准确率。"}
{"llm_update_time": "20251023", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.19200", "html_url": "https://arxiv.org/abs/2510.19200", "title": "GRASPLAT：通过新颖视角合成实现灵巧抓取", "title_en": "GRASPLAT: Enabling dexterous grasping through novel view synthesis", "authors": "Matteo Bortolon,Nuno Ferreira Duarte,Plinio Moreno,Fabio Poiesi,José Santos-Victor,Alessio Del Bue", "background": "实现多功能机械手的灵巧抓取仍然是一个重大挑战。现有方法依赖于完整的3D扫描来预测抓取姿态，但在实际场景中获取高质量3D数据存在困难。因此，这些方法在真实场景下的应用受到限制。", "innovation": "本文提出了一种名为GRASPLAT的新抓取框架，该框架利用一致的3D信息，并且仅依赖RGB图像进行训练。GRASPLAT通过合成物理上合理的手抓取物体的图像，推断出相应成功抓取的手指关节。通过利用3D高斯点绘生成真实手-物交互的新颖视图，实现端到端的训练过程，并引入一种光度损失来细化抓取预测，最小化渲染图像与真实图像之间的差异。通过在合成和真实抓取数据集上进行大量的实验，GRASPLAT在现有的基于图像的方法上将抓取成功率提高了36.9%。", "conclusion": "GRASPLAT通过合成新颖视角的图像，提出了一种利用一致性3D信息的新抓取框架，该框架在真实场景中能有效地提高抓取成功率，为多功能机械手的灵巧抓取提供了新的解决方案。"}
{"llm_update_time": "20251023", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.19351", "html_url": "https://arxiv.org/abs/2510.19351", "title": "使用有限示范学习向人群递归", "title_en": "Learning To Defer To A Population With Limited Demonstrations", "authors": "Nilesh Ramgolam,Gustavo Carneiro,Hsiang-Ting(Tim)Chen", "background": "文章讨论了学习递归（L2D）系统在实际部署中面临的巨大数据稀缺性问题，这是阻碍其普及的主要障碍。", "innovation": "文章提出了一个基于元学习的上下文感知半监督框架，该框架仅从少量示范中生成专家特定的嵌入。这项创新在于使用这些嵌入作为一种双重用途机制，首先生成大规模的伪标签用于训练，然后在测试时实现对新专家的即时适应。", "conclusion": "实验结果表明，使用这些合成标签训练的模型能够迅速达到最佳性能水平，验证了该方法的数据效率。通过解决关键的训练瓶颈，这项工作使得自适应L2D系统更加实用和可扩展，为真实环境的人机协作铺平了道路。"}
{"llm_update_time": "20251023", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.19413", "html_url": "https://arxiv.org/abs/2510.19413", "title": "时空领域手语表示及翻译", "title_en": "Spatio-temporal Sign Language Representation and Translation", "authors": "Yasser Hamidullah,Josef van Genabith,Cristina España-Bonet", "background": "当前最先进的手语翻译（SLT）技术采用通用的Seq2Seq架构，输入嵌入进行了定制。与文本机器翻译中使用的词嵌入不同，SLT系统使用从视频帧中提取的特征。标准方法通常没有充分利用时间特征。", "innovation": "本文介绍了一种系统，该系统能够在单一模型中学习时空特征表示和翻译，这有望产生更有效的端到端架构，更好地泛化到新的数据集。", "conclusion": "我们的最佳系统在开发集上达到了5±1的BLEU分数，但在测试集上的性能下降至0.11±0.06的BLEU分数。"}
{"llm_update_time": "20251023", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.19760", "html_url": "https://arxiv.org/abs/2510.19760", "title": "资源受限设备上混合精度神经网络的自适应分布感知量化", "title_en": "Adaptive Distribution-aware Quantization for Mixed-Precision Neural Networks", "authors": "Shaohang Jia,Zhiyong Huang,Zhi Yu,Mingyang Hou,Shuai Miao,Han Yang", "background": "量化感知训练（QAT）是将深度神经网络部署在资源受限设备上的关键技术。然而，现有的方法常常面临两个主要挑战：激活的非均匀分布和在权重量化中使用的静态、不匹配的码本。", "innovation": "本文提出了自适应分布感知量化（ADQ），这是一种混合精度量化框架，采用了差异化策略。ADQ的核心是一个新颖的自适应权重量化方案，包括三个关键创新点：（1）基于分位数的初始化方法，构建与初始权重分布紧密对齐的码本；（2）基于指数滑动平均（EMA）的在线码本自适应机制，动态跟踪分布变化；（3）混合精度分配的敏感度启发策略。对于激活，我们整合了一个硬件友好的非均匀到均匀映射方案。全面的实验验证了该方法的有效性。在ImageNet上，ADQ使得ResNet-18的Top-1准确率达到71.512%，平均比特宽度仅为2.81位，优于在类似条件下最先进的方法。此外，对CIFAR-10的详细消融研究系统地展示了每个创新组件的单独贡献，验证了我们设计的合理性和有效性。", "conclusion": "ADQ通过适应性强且高效的量化策略显著提高了模型的准确性，同时降低了计算和存储成本，特别是在资源受限的设备上部署神经网络。该研究为混合精度量化提供了一种新的视角和方法，具有广泛的适用性和潜在的实际应用价值。"}
{"llm_update_time": "20251023", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.19455", "html_url": "https://arxiv.org/abs/2510.19455", "title": "使用YOLOv8进行荧光显微镜下神经元形态学自动化分析", "title_en": "Automated Morphological Analysis of Neurons in Fluorescence Microscopy Using YOLOv8", "authors": "Banan Alnemri,Arwa Basbrain", "background": "神经科学和生物医学成像应用中，荧光显微镜图像中的神经元细胞的准确分割和精确形态学分析至关重要。然而，这一过程劳动密集、耗时，并需要大量的手动标注和专业知识以确保可靠的结果。", "innovation": "本文提出了一种基于干细胞衍生神经元高分辨率数据集的神经元实例分割和测量的管道。该方法使用了在手动注释的显微镜图像上训练的YOLOv8模型。模型的分割准确度达到了97%以上。此外，管道还利用了真实标签和预测掩模来提取包括细胞长度、宽度、面积和灰度强度值在内的生物学意义特征。提取的形态学测量的总体准确率达到了75.32%，进一步验证了该方法的有效性。", "conclusion": "本集成框架为细胞成像和神经科学研究中的自动化分析提供了有价值的一种工具，减少了手动注释的需求，并能够实现神经元形态的精确量化。"}
{"llm_update_time": "20251023", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.19305", "html_url": "https://arxiv.org/abs/2510.19305", "title": "FrogDeepSDM: 使用多模态数据和伪缺项插补提高青蛙计数和出现预测", "title_en": "FrogDeepSDM: Improving Frog Counting and Occurrence Prediction Using Multimodal Data and Pseudo-Absence Imputation", "authors": "Chirag Padubidri,Pranesh Velmurugan,Andreas Lanitis,Andreas Kamilaris", "background": "监测物种分布对于保护工作至关重要，能够评估环境影响并开发有效的保护策略。传统的数据收集方法，如公民科学，提供有价值的见解，但仍有局限性。物种分布建模（SDM）通过使用存在数据和环境变量来预测大型区域内的物种分布，填补了这些空白。本研究通过应用深度学习和数据补充技术，结合2022年EY生物多样性挑战数据，增强了青蛙（Anura）的SDM准确性。研究表明，数据平衡显著提高了模型性能，将青蛙计数任务的平均绝对误差（MAE）从189降低到29。特征选择确定了影响出现的关键环境因素，优化输入同时保持预测准确性。多模态集成模型，结合土地覆盖、NDVI和其他环境输入，优于单独的模型，并在未见过的区域内展示了稳健的一般化能力。图像和表格数据的融合提高了青蛙计数和栖息地分类的准确性，达到84.9%的准确率和AUC值为0.90。本研究突显了多模态学习和数据预处理技术（例如平衡和补全）在数据稀疏或不完整时提高预测生态模型的潜力，有助于更准确和规模化地监测生物多样性。", "innovation": "引入了深度学习和数据补充技术，显著提高了青蛙物种分布预测的准确性。选择了关键环境因素，优化了模型输入。多模态集成模型，在多环境变量输入下表现出了对未知区域的稳健泛化能力。将图像和表格数据组合使用，提高了青蛙计数和栖息地分类的准确性和AUC值。这些技术在数据稀疏或不完整的条件下提升了预测生态模型的性能，适用于规模化生物多样性监测。", "conclusion": "通过利用深度学习和数据补充技术，FrogDeepSDM为青蛙物种分布建模提供了有效的新方法。多模态集成模型显著提高了预测性能，并且能够在未见过的区域内泛化。混合图像和表格数据提高了青蛙计数和栖息地分类的准确性。这些方法为稀疏或不完整的数据条件下提高生态模型的准确性提供了新的策略，有利于更准确和规模化地监测生物多样性。"}
{"llm_update_time": "20251023", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.19430", "html_url": "https://arxiv.org/abs/2510.19430", "title": "GigaBrain-0: 一种以世界模型驱动的视觉-语言-行动模型", "title_en": "GigaBrain-0: A World Model-Powered Vision-Language-Action Model", "authors": "GigaBrain Team:Angen Ye,Boyuan Wang,Chaojun Ni,Guan Huang,Guosheng Zhao,Haoyun Li,Jie Li,Jiagang Zhu,Lv Feng,Peng Li,Qiuping Deng,Runqi Ouyang,Wenkang Qin,Xinze Chen,Xiaofeng Wang,Yang Wang,Yifan Li,Yilong Li,Yiran Ding,Yuan Xu,Yun Ye,Yukun Zhou,Zhehao Dong,Zhenan Wang,Zhichao Liu,Zheng Zhu", "background": "训练视觉-语言-行动（VLA）模型通常需要大量的真实世界机器人数据，这不仅成本高昂，而且耗时耗力。物理数据的收集效率低下极大地限制了当前VLA系统的可扩展性和泛化能力。因此，如何克服这一挑战成为了研究重点。现有方法依赖于真实世界的机器人数据进行训练，这导致了数据收集的困难和时间的浪费。", "innovation": "GigaBrain-0 是一种由世界模型生成数据（如视频生成、真实到真实的数据传输、人类数据传输、视野转换数据和模拟到现实的数据传输）驱动的新型VLA基础模型。通过利用世界模型大规模生成多样化数据，GigaBrain-0 显著减少了对真实机器人数据的依赖，并且提高了跨任务泛化能力。此外，通过引入RGBD输入建模和具身思维链（CoT）监督，GigaBrain-0 提高了策略稳健性，使其能够在执行任务时推理空间几何、物体状态和长时间依赖性。这在多个方面的现实世界性能上带来了显著的提升。最后，研究还提出了一种轻量级的GigaBrain-0-Small变体，可以高效运行在如NVIDIA Jetson AGX Orin等设备上。", "conclusion": "GigaBrain-0 在各种外观变化（如纹理、颜色）、物体放置和摄像头视角的变异情况下实现了出色的泛化能力。此外，通过生成的数据，GigaBrain-0 能够在精细的长时间操作和移动操作任务中表现出色。通过这些方法，GigaBrain-0 显著提高了在现实生活中的任务执行性能，展示了其强大的泛化能力和可扩展性。"}
{"llm_update_time": "20251023", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2307.10753", "html_url": "https://arxiv.org/abs/2307.10753", "title": "LBL: 对数屏障损失函数为一类分类", "title_en": "LBL: Logarithmic Barrier Loss Function for One-class Classification", "authors": "Xiaofeng Guo,Ziyang Jiang,Tianlei Wang,Shichen Zhang,Dinghan Hu,Jiuwen Cao", "background": "一类分类（OCC）旨在仅使用目标数据训练分类器，并由于其实用性而引起了越来越多的关注。尽管OCC已经取得了很多进展，但在深度学习中仍然缺乏有效的OCC损失函数。", "innovation": "本文提出了一个基于对数屏障函数的新型OCC损失（LBL），通过平滑逼近OCC目标，可以对边界样本施加大梯度以获取更紧的超球体。然而，LBL的优化可能会在样本位于边界时变得不稳定并导致无穷值。为解决此问题，提出了利用单向松弛Sigmoid函数的更平滑的LBLSig损失。", "conclusion": "实验结果在不同网络中证明了所提LBL和LBLSig的有效性。源代码可以在指定链接找到。"}
{"llm_update_time": "20251023", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.19585", "html_url": "https://arxiv.org/abs/2510.19585", "title": "使用大语言模型检测历史书籍中的拉丁文：一个多模态基准", "title_en": "Detecting Latin in Historical Books with Large Language Models: A Multimodal Benchmark", "authors": "Yu Wu,Ke Shu,Jonas Fischer,Lidia Pivovarova,David Rosson,Eetu Mäkelä,Mikko Tolonen", "background": "本文背景在于，研究如何从包含多种语言的古老文档中提取拉丁文片段。这些文档不仅语言混杂，而且布局各异，为任务带来了挑战。为了评估现代模型的能力，作者使用了一个包含724页标注页面的多模态数据集来基准测试大型基础模型的性能。研究表明，使用当代模型实现可靠拉丁文检测是可行的，这为这项任务提供了新的认知和工具。", "innovation": "本文的创新在于提出了一种新的任务，即从多种语言混杂的历史文档中提取拉丁文片段，以及作者首次对大规模基础模型在这一任务上的性能进行了多模态基准测试，并对其能力与局限进行了全面分析，由此提供了应对这类挑战的新策略和技术支持。", "conclusion": "研究结果表明，现有大型语言模型能够实现历史文件中拉丁文的可靠检测，为未来该领域的研究和应用奠定了基础。虽然在这方面取得了显著进展，但同时也指出了模型存在的不足之处，例如对于不同布局和语言混合文档的适应性仍有待提高。"}
{"llm_update_time": "20251023", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.19418", "html_url": "https://arxiv.org/abs/2510.19418", "title": "从视到护：机器学习辅助的精细粒度视觉数据访问控制", "title_en": "From See to Shield: ML-Assisted Fine-Grained Access Control for Visual Data", "authors": "Mete Harun Akcay,Buse Gul Atli,Siddharth Prakash Rao,Alexandros Bakas", "background": "随着存储数据量的增长，识别和保护大型存储库中的敏感信息变得越来越具有挑战性，尤其是在与多个具有不同角色和权限的用户共享时。此项工作提出了一种受信任的数据共享系统架构，结合策略驱动的访问控制，能够选择性地保护敏感区域并保持可扩展性。该系统能够自动检测、修正、管理和控制敏感区域的访问，并运用混合加密方案来确保安全性，同时支持高效密钥分发和隔离密钥存储，以增强整体安全性。该系统的有效性通过在视觉数据集上的实验得到了验证，实验表明该系统能够有效地检测隐私敏感对象，并在数据仓库共享前对其进行再评估和选择性加密。通过实验结果，该系统提升了5%的宏平均F1分数和10%的平均平均精确度，并实现了每张图像1秒左右的策略控制解密时间，这些结果证明了该系统的有效性、效率和可扩展性，适用于细粒度的访问控制场景", "innovation": "该系统架构结合了自动检测敏感区域、后修正、密钥管理和访问控制四个核心模块，使用混合加密方案（包括对称加密和基于属性的加密）有效保护敏感区域。此外，系统支持高效的密钥分发，隔离密钥存储以加强整体安全性。实验验证了其在视觉数据集上的有效性，显著提升了隐私敏感对象的检测和加密效率，同时保持了良好的性能和安全性", "conclusion": "该研究提出了一种受信任的数据共享系统架构，能够自动检测和保护敏感区域，同时保持系统的可扩展性和安全性。通过实验结果证明，该系统在视觉数据集上能够有效提升宏平均F1分数和平均平均精确度，并在策略控制下实现了快速解密，显示了该系统在细粒度访问控制中的高效性和可扩展性"}
{"llm_update_time": "20251023", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.19755", "html_url": "https://arxiv.org/abs/2510.19755", "title": "缓存方法在扩散模型中的综述：通往高效多模态生成的道路", "title_en": "A Survey on Cache Methods in Diffusion Models: Toward Efficient Multi-Modal Generation", "authors": "Jiacheng Liu,Xinyu Wang,Yuqi Lin,Zhikai Wang,Peiru Wang,Peiliang Cai,Qinming Zhou,Zhengan Yan,Zexuan Yan,Zhengyi Shi,Chang Zou,Yue Ma,Linfeng Zhang", "background": "扩散模型因其卓越的生成质量和可控性而成为现代生成AI的核心。然而，它们内部的多步迭代和复杂的骨干网导致了巨大的计算开销和生成延迟，这成为实时应用的主要瓶颈。尽管已有加速技术取得进展，但仍然面临适用性有限、训练成本高或质量下降等问题。", "innovation": "提出了无训练的、架构无关的和高效的推理范式——扩散缓存。该方法的核心机制是识别并在扩散过程中重用内在的计算冗余。通过启用特征级跨步重用和层间调度，它减少了计算而不修改模型参数。此外，通过比较分析代表性方法，展示了扩散缓存从静态重用演进到动态预测，提高了在各种任务中的灵活性，并能与其他加速技术，如采样优化和模型蒸馏相结合，为未来多种模态和交互应用提供统一、高效的推理框架。", "conclusion": "我们认为，这种范式将成为实时和高效生成AI的关键使能器，为高效生成智能的理论和实践注入新的活力。"}
{"llm_update_time": "20251023", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.19732", "html_url": "https://arxiv.org/abs/2510.19732", "title": "Memo：使用强化学习训练高效记忆体代理", "title_en": "Memo: Training Memory-Efficient Embodied Agents with Reinforcement Learning", "authors": "Gunshi Gupta,Karmesh Yadav,Zsolt Kira,Yarin Gal,Rahaf Aljundi", "background": "为了使具身代理能够在长时间框架内有效运行，开发能够形成和访问记忆的模型以保持其环境中的上下文变得至关重要。在训练具身序列决策任务的Transformer模型时，视觉输入往往会超出Transformer的上下文限制，但人类能够维持并利用压缩为记忆的终身经验。理论上，大量的输入可以被压缩和抽象，但现有方法主要集中在具有固定大小记忆的循环模型或依赖于完整上下文的Transformer上。", "innovation": "本文提出了一种名为Memo的Transformer架构和训练方案，旨在解决长时域任务中的高内存需求问题。Memo在训练过程中通过周期性插入概要标记来集成记忆的创建和检索。Memo在使用强化学习进行记忆密集型、长时域任务时有效展示了其优越性，并在网格世界的元强化学习基准测试和具有照片级真实感室内设置中的多目标导航任务中表现出色。Memo不仅在计算和存储效率上更占优势，而且在推断时能更好地适应更长的上下文，并在需要历史上下文裁剪的流式设置中保持鲁棒性。", "conclusion": "Memo在应对长上下文任务方面表现出色，具有更好的计算和存储效率，能够在推断时更好地适应更长的上下文，并保持在流式设置中鲁棒性。"}
{"llm_update_time": "20251023", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2405.14882", "html_url": "https://arxiv.org/abs/2405.14882", "title": "LookUp3D: 数据驱动的3D扫描", "title_en": "LookUp3D: Data-Driven 3D Scanning", "authors": "Giancarlo Pereira,Yidan Gao,Yurii Piadyk,David Fouhey,Claudio T Silva,Daniele Panozzo", "background": "高速、高分辨率和精确的3D扫描将在图形学、机器人技术、科学和医学等领域打开许多新的应用通道，特别是对于能够准确扫描可变形物体的互动过程中的3D扫描尤为重要。过去在高速环境中使用条形光、飞行时间法和立体视觉进行3D扫描时，通常需要在分辨率或准确性方面做出妥协。", "innovation": "本文介绍了一种方法，该方法首次实现了在受控光环境下每秒450帧，分辨率为1兆像素，或每秒1450帧分辨率0.4兆像素的3D扫描。关键思路是使用一个像素级查找表，将颜色映射到深度，该表是在线性移动台上建立的。查找表中包含了瑕疵比如镜头失真和传感器缺陷的校准。本文描述了该方法并在新型硬件原型上进行了测试，还与真实几何形状和商业级动态传感器如微软Kinect和英特尔RealSense进行了比较。", "conclusion": "本文系统展示了对高速变形和振荡物体的几何形状的获取，并证明了从重建中恢复物理属性的能力。总体而言，该系统在高精度和快速扫描方面取得了显著进步，适用于需要精确动态3D扫描的技术领域。"}
{"llm_update_time": "20251023", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2412.01463", "html_url": "https://arxiv.org/abs/2412.01463", "title": "学习差分金字塔表示进行色调映射", "title_en": "Learning Differential Pyramid Representation for Tone Mapping", "authors": "Qirui Yang,Yinbo Li,Yihao Liu,Peng-Tao Jiang,Fangpu Zhang,Qihua Cheng,Huanjing Yue,Jingyu Yang", "background": "现有的色调映射方法通常对下采样输入进行操作，并依赖手工设计的金字塔来恢复高频细节。这些设计通常在复杂的高动态范围（HDR）场景中无法很好地保留细微纹理和结构保真度。此外，大多数方法缺乏有效机制来联合建模全局色调一致性与局部对比度增强，导致全局平坦或局部不一致的输出，例如产生伪影如光晕。", "innovation": "本文提出了差分金字塔表示网络（DPRNet），这是一种针对高保真度色调映射的端到端框架。核心在于一种能够适应不同亮度和对比度条件的全可学习差分金字塔。该模型整合了全局色调感知和局部色调调优模块，对下采样输入进行操作，使得在有效且传达性强的情况下进行色调调整。最后，通过逐步细化的方法恢复全分辨率输出，增强结构和清晰度。", "conclusion": "实验表明，DPRNet 达到了最先进的性能，在 4K HDR+ 数据集和 4K HDRI Haven 数据集上分别提高了 PSNR 2.39 dB 和 3.01 dB，同时生成了感知一致性且细节保留良好的结果。"}
{"llm_update_time": "20251023", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2405.15239", "html_url": "https://arxiv.org/abs/2405.15239", "title": "Brain3D: 从fMRI生成3D对象", "title_en": "Brain3D: Generating 3D Objects from fMRI", "authors": "Yuankun Yang,Li Zhang,Ziyang Xie,Zhiyuan Yuan,Jianfeng Feng,Xiatian Zhu,Yu-Gang Jiang", "background": "理解和揭示人类视觉感知背后的隐藏机制是神经科学中的基础问题。通过功能性磁共振成像（fMRI）研究人类心智活动在这一领域具有重要意义，但在分析fMRI信号时，存在着技术挑战、成本高、专业训练需求大等问题，在现有方法只能生成2D图像的情况下，本研究力图生成与大脑信号解码更为相关的3D输出，旨在构建更高级的fMRI数据建模技术。针对这一挑战，在现有的研究起点上，提出了一种新颖的3D对象表征学习方法Brain3D，将fMRI数据作为输入，生成相应的3D对象图像。", "innovation": "本文提出了一种新颖的方法Brain3D，即功能性磁共振成像（fMRI）条件下的3D对象生成问题的新框架。Brain3D利用高级语义信号应对图像噪声，并采用两阶段架构设计逐步整合高级信息。研究结果表明，这种方法在3D对象生成方面表现出了显著的优势，并且捕捉了人类视觉系统中每个区域的功能及其复杂交互关系，与现有的神经科学研究成果高度一致。此外，初步评估表明，Brain3D能成功识别人类视觉系统的混乱脑区，如V1、V2、V3、V4和内侧颞叶（MTL）等部位。", "conclusion": "本文通过Brain3D方法生成了与大脑信号更具功能性的3D输出，使得深度理解人类视觉感知机制成为可能。我们的研究成果不仅提升了现有的3D对象生成能力，同时也揭示了大脑不同区域的功能及其复杂的交互关系，对神经科学发展具有重要意义。这一方法还展示了在模拟场景中识别大脑扰乱区域的能力。相关数据和代码将在指定网址上提供给公众。"}
{"llm_update_time": "20251023", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2410.05051", "html_url": "https://arxiv.org/abs/2410.05051", "title": "ComDrive：面向舒适性的端到端自动驾驶系统", "title_en": "ComDrive: Comfort-Oriented End-to-End Autonomous Driving", "authors": "Junming Wang,Xingyu Zhang,Zebin Xing,Songen Gu,Xiaoyang Guo,Yang Hu,Ziying Song,Qian Zhang,Xiaoxiao Long,Wei Yin", "background": "现有的基于模仿学习的规划器和基于学习的轨迹评分器可以在安全性和效率方面生成和选择与专家演示非常相似的轨迹。然而，这些方法面临生成时间不一致和不舒适的轨迹的挑战。因此，研究提出了ComDrive，一种面向舒适性的端到端自动驾驶系统，旨在生成连续和舒适的轨迹。该系统首先通过稀疏感知提取三维空间表示，并将其作为条件输入。接着，这些输入通过基于DDPM的运动规划器生成时空一致的多模式轨迹。随后，双流自适应轨迹评分器从这些候选轨迹中选择最舒适的轨迹来控制车辆。", "innovation": "ComDrive 提出了一个创新的系统，旨在生成连续和舒适的轨迹。通过稀疏感知提取三维空间表示，并使用基于 DDPM 的运动规划器生成时空一致的多模式轨迹。双流自适应轨迹评分器从候选轨迹中选择最舒适的轨迹来控制车辆，解决了时间不一致和不舒适的问题。实验表明该系统在舒适性和安全性方面取得了最先进的性能，在驾车舒适性方面比 UniAD 高出 17%，且碰撞率降低了 25% 相比 SparseDrive。", "conclusion": "ComDrive 实现了在舒适性和安全性方面的顶尖表现，通过以上创新解决了时间不一致和不舒适的问题，并在实际应用中显著优于其他系统。"}
{"llm_update_time": "20251023", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2501.19339", "html_url": "https://arxiv.org/abs/2501.19339", "title": "PixelWorld: 距离将一切视为像素还有多远？", "title_en": "PixelWorld: How Far Are We from Perceiving Everything as Pixels?", "authors": "Zhiheng Lyu,Xueguang Ma,Wenhu Chen", "background": "近年来，代理型语言模型需要与包含紧密交织的视觉和文本信息的真实环境进行交互，通常通过未处理的相机像素而不是分别处理的图像和标记化文本进行。这一转变突显了统一感知范式的需求。本文背景正是这一技术的发展背景和现实需求引导的研究思路。", "innovation": "本文提出了Perceive Everything as Pixels (PEAP)和一个名为PixelWorld的新基准，其能够将自然语言、表格、数学和示意图输入统一到像素空间中。这些创新为评估统一视觉-语言模型提供了新的方法，并推动了基于像素的多模态学习的进一步探索。", "conclusion": "实验结果显示，尽管PEAP在语义理解任务上与基于标记的模型表现相似，能够部分捕获全局文本语义而无需显式标记化，但在需要高度推理的任务（如数学和代码）上表现较差，但通过链式思维提示可以缓解这一差距。文章还指出，当视觉和文本信息紧密结合时，将所有信息视为像素简化了预处理步骤并避免了跨模态对齐问题，这为未来研究提供了一种系统且实用的框架。"}
{"llm_update_time": "20251023", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2502.09282", "html_url": "https://arxiv.org/abs/2502.09282", "title": "MsEdF: 多流编码解码框架用于遥感图像描述", "title_en": "MsEdF: A Multi-stream Encoder-decoder Framework for Remote Sensing Image Captioning", "authors": "Swadhin Das,Raksha Sharma", "background": "遥感图像包含复杂的空间模式和语义结构，使得描述模型难以准确地进行描述。现有的编码解码器架构因其单流设计，难以捕捉到多样化的空间特征或复杂的语义关系，尤其是在高类内相似度和上下文模糊的场景中表现不佳。", "innovation": "提出了一种新颖的多流编码解码框架（MsEdF），通过优化编码器解码器架构的空间表示和语言生成，增强模型对图像的描述能力。该模型使用两个互补的图像编码器融合信息，并采用堆叠的GRU架构结合元素级聚合方案，在解码器侧改进了语义建模，以提高上下文感知描述的捕捉能力。", "conclusion": "在三个基准遥感图像描述数据集上的实验表明，MsEdF 模型显著优于几个基线模型。"}
{"llm_update_time": "20251023", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2502.10273", "html_url": "https://arxiv.org/abs/2502.10273", "title": "在大型视觉语言模型中探究知觉恒常性", "title_en": "Probing Perceptual Constancy in Large Vision-Language Models", "authors": "Haoran Sun,Bingyang Wang,Suyang Yu,Yijiang Li,Qingying Gao,Haiyun Lyu,Hokin Deng,Dezhi Luo", "background": "知觉恒常性是指在感官输入变化的情况下（如距离、角度或光照的变化），维持对物体稳定感知的能力。这对于动态世界中的视觉理解至关重要。本研究探索了当前视觉语言模型（VLMs）在颜色、大小和形状恒常性方面的能力。", "innovation": "研究人员评估了155个VLMs在3个领域的236个实验中的表现，涵盖颜色、大小和形状恒常性，并使用单一图像和视频的经典认知任务以及野外环境中的新型任务。发现了这些领域中VLMs性能的显著差异，特别是形状恒常性与颜色和大小恒常性的表现明显不同。", "conclusion": "研究表明VLMs在不同恒常性任务中的表现存在显著差异，特别是在形状恒常性任务中的表现与颜色和大小恒常性任务中的表现有明显区别，这为了解和改进VLMs在视觉感知任务中的应用提供新的见解。"}
{"llm_update_time": "20251023", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2410.20893", "html_url": "https://arxiv.org/abs/2410.20893", "title": "基于路用户LiDAR跟踪的对抗攻击：鲁棒性评估与目标感知黑盒方法", "title_en": "Adversarial Attacks on LiDAR-Based Tracking Across Road Users: Robustness Evaluation and Target-Aware Black-Box Method", "authors": "Shengjing Tian,Xiantong Zhao,Yuhao Bian,Yinan Han,Bin Liu", "background": "本研究深入探讨了基于神经网络的LiDAR点云跟踪模型在遭遇对抗性攻击时的鲁棒性，这一方面在关注性能提升时常常被忽视。尽管这些模型利用了如Transformer或鸟瞰图（BEV）等高级架构，但在面临对抗性攻击、领域迁移或数据篡改等挑战时容易忽视其鲁棒性。研究者们关注的是这些跟踪模型在对抗性攻击威胁下的鲁棒性。为此，研究者们首先建立了一种统一的框架，用于在三维目标跟踪的情境下实施对抗攻击，能够全面研究白盒和黑盒攻击策略。白盒攻击中，研究人员为不同的跟踪方法定制了特定的损失函数，并将现有的FGSM、C&W和PGD方法扩展到点云领域。针对黑盒攻击场景，研究者提出了一种新颖的基于迁移的攻击方法——目标感知扰动生成（TAPG）算法，旨在实现高攻击效果的同时保持低可感知性。该方法采用启发式策略来强制执行稀疏攻击约束，并利用随机子向量因子分解增强迁移性。", "innovation": "研究提出了一个统一的框架用于在3D目标跟踪环境中进行对抗性攻击，并且针对白盒攻击利用定制的损失函数和扩展现有方法。同时，研究者引入了一种新的基于迁移的攻击方法——TAPG算法，这种方法具有高攻击效果和低可感知性的双重优势，克服了现有方法在鲁棒性上的问题。", "conclusion": "研究揭示了高级跟踪方法在遭遇白盒和黑盒攻击时存在极大的脆弱性，强调了在LiDAR点云跟踪模型设计中必须考虑对抗性攻击的鲁棒性。与现有方法相比，TAPG方法在攻击效果和干扰隐蔽性之间达到了一个良好的平衡。"}
{"llm_update_time": "20251023", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2412.12718", "html_url": "https://arxiv.org/abs/2412.12718", "title": "ASAP：先进的语义对齐促进多模态篡改检测和定位", "title_en": "ASAP: Advancing Semantic Alignment Promotes Multi-Modal Manipulation Detecting and Grounding", "authors": "Zhenxing Zhang,Yaxiong Wang,Lechao Cheng,Zhun Zhong,Dan Guo,Meng Wang", "background": "在多模态媒体篡改检测和定位（DGM4）任务中，图像和文本之间的准确细粒度跨模态语义对齐至关重要。尽管现有的DGM4方法很少关注跨模态对齐，但这是进一步提高篡改检测准确性的关键。为解决这一问题，该研究旨在通过推动语义对齐学习来提升这一任务。", "innovation": "该研究利用现成的多模态大语言模型和大语言模型构建匹配的图像-文本对，特别是在处理篡改实例时。此外，设计了一种篡改引导的跨注意力（MGCA），以提供隐式指导，增强对篡改的认知。在训练时利用定位真值，MGCA促使模型更多关注篡改元件而忽视正常元件，增强了模型捕捉篡改的能力。", "conclusion": "通过在DGM4数据集上进行广泛实验，结果显示该模型在比较方法上具有明显的优越性。"}
{"llm_update_time": "20251023", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2502.12138", "html_url": "https://arxiv.org/abs/2502.12138", "title": "FLARE: 从非标定稀视角中前馈几何、外观和相机估计", "title_en": "FLARE: Feed-forward Geometry, Appearance and Camera Estimation from Uncalibrated Sparse Views", "authors": "Shangzan Zhang,Jianyuan Wang,Yinghao Xu,Nan Xue,Christian Rupprecht,Xiaowei Zhou,Yujun Shen,Gordon Wetzstein", "background": "在现实世界的应用中，利用少量未标定的稀视角图像（即输入为2-8个）推断高质量的摄像机姿态和3D几何结构是一个具有挑战性但实用的问题。", "innovation": "FLARE模型采用前馈架构，在大型公共数据集上训练，能够同时实现姿态估计、几何结构重建和新视角合成，且保持高效的推理时间（少于0.5秒）。", "conclusion": "FLARE方法在姿态估计、几何结构重建和新视角合成任务上表现出优越性能，同时能够保持高效推理。相关项目页面和代码可在此找到：this https URL"}
{"llm_update_time": "20251023", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2502.20120", "html_url": "https://arxiv.org/abs/2502.20120", "title": "重新审视从缓解分类能力失衡视角的多模态学习", "title_en": "Rethinking Multimodal Learning from the Perspective of Mitigating Classification Ability Disproportion", "authors": "QingYuan Jiang,Longfei Huang,Yang Yang", "background": "多模态学习（MML）受到模态间不平衡的显著限制，导致其实用中的性能不佳。现有方法主要集中在平衡不同模态的学习上以解决这一问题，但从根本上忽视了模型分类能力的固有不平衡，这是该现象的主要原因。当前方法在解决模态不平衡问题时，未能充分考虑模型分类能力的差异性，导致了实际应用中性能的不理想状态。", "innovation": "本文提出了一种新颖的多模态学习方法，通过结合增强学习的基本原理动态平衡弱模态和强模态的分类能力。具体来说，首先提出了一个同时优化分类和剩余误差的持续增强算法；其次，引入了一个自适应分类器分配策略，以动态提升弱模态的分类性能；此外，还从理论上分析了跨模态间隙函数的收敛性质，确保了所提出的增强方案的有效性。该方法通过平衡强模态和弱模态的分类能力，缓解了模态不平衡问题。", "conclusion": "在广泛使用的数据集上进行的实证实验表明，本文提出的方法通过与各种最先进的多模态学习基线进行比较，展示了其优越性。研究结果和代码可以从指定链接获取。"}
{"llm_update_time": "20251023", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2503.01298", "html_url": "https://arxiv.org/abs/2503.01298", "title": "通过统一生成模型中的多模态链式思维实现增强图像生成", "title_en": "Towards Enhanced Image Generation Via Multi-modal Chain of Thought in Unified Generative Models", "authors": "Yi Wang,Mushui Liu,Wanggui He,Hanyang Yuan,Longxiang Zhang,Ziwei Huang,Guanghao Zhang,Wenkai Fang,Haoze Jiang,Shengxuming Zhang,Dong She,Jinlong Liu,Weilong Dai,Mingli Song,Hao Jiang,Jie Song", "background": "统一生成模型在文本和图像生成任务中表现出色。但是，在涉及复杂组合指令的图像合成任务中，现有的直接文本到图像生成方法存在局限性，这在现实场景中是常见的。尽管这个问题很重要，但现有工作主要集中在提高模型的基本图像生成能力上，这些改进虽然有所帮助，但并未充分解决问题。", "innovation": "本文借鉴链式思维（CoT）逐步解决问题的方法，将CoT引入统一生成模型中，旨在通过改善复杂图像生成能力解决直接T2I生成无法有效解决的问题。通过提出功能导向专家FoXperts来实现这一目标，这是一种专家并行的架构。还提出了一个名为MCoT的多模态链式思维方法，以及一种多任务联合训练方案，使得模型能够以分离的方式来获取每个MCoT步骤所需的全部能力。这些创新解决了数据多步骤一致性收集的难题，提高了复杂图像生成的效果。", "conclusion": "广泛的实验表明，FoX 统一模型在各种T2I基准上的表现优于现有模型，复杂图像生成方面的改进尤为显著。"}
{"llm_update_time": "20251023", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2503.09271", "html_url": "https://arxiv.org/abs/2503.09271", "title": "DitHub: 一种增量开放式词汇目标检测的模块化框架", "title_en": "DitHub: A Modular Framework for Incremental Open-Vocabulary Object Detection", "authors": "Chiara Cappellino,Gianluca Mancusi,Matteo Mosconi,Angelo Porrello,Simone Calderara,Rita Cucchiara", "background": "开放词汇的目标检测器可以通过简单的文本提示对未规定类别的对象进行泛化。然而，将这些模型适应罕见类目或进一步强化其在多个专业化领域的表现仍然是必要的。尽管最近的方法依赖于单一的、整体的适应策略，研究者们提出了模块化深度学习的方法。DitHub是一个旨在构建和维护高效适应模块库的框架，借鉴了版本控制系统，它能够管理和合并不同的专家模块，为开放词汇目标检测提供了一种新的研究方向和方法。", "innovation": "DitHub框架引入了一种模块化的方法，将专家模块视作分支，可以通过获取和合并来灵活使用。这种方法首次系统地探讨了适应模块的组合特性。此外，DitHub框架的引入使得模型能够实现对ODinW-13基准和新引入的ODinW-O基准的领先性能。ODinW-O用于评估类别的再现能力。", "conclusion": "DitHub能够通过模块化、灵活的适应方法实现开放式词汇目标检测的先进性能，探讨了组合不同适应模块的潜力和效果，同时也提供了评估新类再现能力的新基准。"}
{"llm_update_time": "20251023", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2503.21776", "html_url": "https://arxiv.org/abs/2503.21776", "title": "Video-R1:在MLLMs中强化视频推理", "title_en": "Video-R1: Reinforcing Video Reasoning in MLLMs", "authors": "Kaituo Feng,Kaixiong Gong,Bohao Li,Zonghao Guo,Yibing Wang,Tianshuo Peng,Junfei Wu,Xiaoying Zhang,Benyou Wang,Xiangyu Yue", "background": "深受DeepSeek-R1通过基于规则的强化学习（RL）在激发推理能力方面取得的成功启发，本研究旨在系统研究R1范式，以激励多模态大型语言模型进行视频推理。然而，直接使用基于GRPO算法的RL训练视频推理面临着两大挑战：（1）缺乏对时间维度的建模，（2）高质量视频推理数据稀缺。", "innovation": "为了解决上述问题，首先提出了T-GRPO算法，鼓励模型利用视频中的时间信息进行推理。此外，除了使用视频数据外，还引入了高质量的图像推理数据进行训练。构建了两个数据集：Video-R1-CoT-165k用于SFT冷启动，Video-R1-260k用于RL训练，两个数据集都包含图像和视频数据。实验结果证明，Video-R1在VideoMMMU和VSI-Bench等视频推理基准以及MVBench和TempCompass等通用视频基准上取得了显著改进，特别是在视频空间推理基准VSI-bench上，Video-R1-7B的准确率达到37.1%，超越了商用的GPT-4o模型。", "conclusion": "实验结果表明，引入T-GRPO算法以及将高质量的图像推理数据加入到训练过程中的Video-R1，极大地提高了视频推理的性能，并且其性能在多种基准测试中都超过了现有的商用模型。"}
{"llm_update_time": "20251023", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2503.08221", "html_url": "https://arxiv.org/abs/2503.08221", "title": "EgoBlind: 朝着盲人自我中心视觉辅助的发展", "title_en": "EgoBlind: Towards Egocentric Visual Assistance for the Blind", "authors": "Junbin Xiao,Nanxin Huang,Hao Qiu,Zhulin Tao,Xun Yang,Richang Hong,Meng Wang,Angela Yao", "background": "当前的多模态大型语言模型（MLLMs）在视觉辅助方面还缺乏有效的测试数据集，特别是在为盲人提供的自我中心视角协助方面。EgoBlind 数据集填补了这一空白，提供了首个由盲人及视力受损者自主提供的自我中心视角视频和问题集，旨在评估现有 MLLMs 提供视觉辅助的能力。该数据集包含来自日常生活的 1,392 个第一人称视频和 5,311 个问题，这些问题直接反映了盲人在实际场景中的视觉辅助需求。每个问题都进行了手动标注，以减少主观性。", "innovation": "EgoBlind 是首个专门针对盲人用户收集的第一人称视角视频和问题集，旨在评估 MLLMs 的自我中心视觉辅助能力。该数据集的独特之处在于它直接来源于盲人及视力受损者的真实需求，能够更准确地反映他们的视角和需求。此外，研究表明现有的 MLLMs 在这个领域表现不佳，这为今后如何改进 MLLMs 提供了宝贵的数据和见解。", "conclusion": "EgoBlind 为开发有效的人工智能助手提供了基础，旨在增强盲人和视力受损者的独立性。研究者希望通过这个工作，可以引导未来 MLLMs 在盲人视觉辅助领域的进一步发展改进。研究结果表明，当前 MLLMs 的最佳表现仅达到大约 60% 的准确率，远低于人类 87.4% 的水平。"}
{"llm_update_time": "20251023", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2412.01822", "html_url": "https://arxiv.org/abs/2412.01822", "title": "VLsI: 从大型到小型视觉语言模型的口头化层到交互", "title_en": "VLsI: Verbalized Layers-to-Interactions from Large to Small Vision Language Models", "authors": "Byung-Kwan Lee,Ryo Hachiuma,Yu-Chiang Frank Wang,Yong Man Ro,Yueh-Hua Wu", "background": "最近，高质量的视觉指令调优样本的增加，尤其是在GPT-4V这样的封闭源视觉-语言模型中，促进了各种模型规模的开放源视觉-语言模型（VLMs）的发布。然而，将VLMs扩大到使用更大规模的模型以提高性能带来了显著的计算挑战，尤其是在像移动平台和机器人这样的资源受限设备上的部署。", "innovation": "我们提出了一种新的VLM系列——VLsI，规模分别为2B和7B，它优先考虑效率而不降低准确性。VLsI利用了一种独特的、按层的蒸馏过程，引入了“口头化者”映射每层的特征到自然语言空间，使小型VLM能够灵活地与大型VLM的推理过程对齐。这种做法消除了输出模仿中的常见训练不稳定性，超越了通常的最终层调优，通过使小型VLM逐层进展与大型VLM对齐来实现。我们通过十个挑战性的视觉-语言基准验证了VLsI的表现，相比GPT-4V，2B和7B规模的小型模型分别取得了11.0%和17.4%的显著性能提升，无需进行模型扩展、合并或架构更改。", "conclusion": "VLsI在十个具有挑战性的视觉-语言基准中表现突出，证明了即使不需要扩大模型规模、合并或改变架构，小型VLM也能实现与大型VLM相当甚至更好的性能。这为视觉-语言模型的部署提供了一种新的高效解决方案，尤其是在资源受限的设备上。"}
{"llm_update_time": "20251023", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2504.00939", "html_url": "https://arxiv.org/abs/2504.00939", "title": "WikiVideo：基于多视频的文章生成", "title_en": "WikiVideo: Article Generation from Multiple Videos", "authors": "Alexander Martin,Reno Kriz,William Gantt Walden,Kate Sanders,Hannah Recknor,Eugene Yang,Francis Ferraro,Benjamin Van Durme", "background": "目前的生成任务多数依赖于文本，而视频则被用作检索增强生成（RAG）的直观来源。现有的基于视频的摘要方法主要关注低级场景理解，而不是高级事件语义。研究中指出，当前的RAG工作流程着重于文本，而大多数方法没有充分利用视频作为支持文章内容的有效证据。研究旨在创建一种可以从多种涉及真实事件的视频中生成维基百科风格文章的方法，追溯所有信息的视频证据来支持文章。", "innovation": "该研究引入了WikiVideo基准数据集，包含专家撰写的文章和详细标注的视频，以支持文章中的主张，从而促进将视频内容整合到RAG流水线中，并生成基于多种模态源的深入内容。此外，研究提出了一种新的协作性文章生成（CAG）方法，结合了r1风格的推理模型和视频语言模型VideoLLM，能够通过迭代交互方式产生关于目标事件的高级推断，而单靠VideoLLM可能无法实现。研究还对比了早期的方法和最先进的视频语言模型（VideoLLM）以及CAG在不同场景中的表现，发现CAG在两种不同的评估场景中均表现出色，并提出了一些未来工作的新方向。", "conclusion": "研究通过提出CAG方法，展示了在RAG流程中利用视频证据进行文章生成的潜力。实验结果表明，CAG在 oracle retrieval 和 RAG 模式下均优于其他方法，为未来的工作提供了新的思路。"}
{"llm_update_time": "20251023", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2504.07744", "html_url": "https://arxiv.org/abs/2504.07744", "title": "MMLA: 多环境、多物种、低海拔无人机数据集", "title_en": "MMLA: Multi-Environment, Multi-Species, Low-Altitude Drone Dataset", "authors": "Jenna Kline,Samuel Stevens,Guy Maalouf,Camille Rondeau Saint-Jean,Dat Nguyen Ngoc,Majid Mirmehdi,David Guerin,Tilo Burghardt,Elzbieta Pastucha,Blair Costelloe,Matthew Watson,Thomas Richardson,Ulrik Pagh Schultz Lundquist", "background": "无人机在野生动物监测中具有重要作用，但现有检测模型如YOLO在不同地点应用时表现不一，并且难以识别稀有物种，限制了其在无人驾驶无人机部署中的应用。该论文背景信息表明，存在对适用于自主无人机系统的覆盖面广且效果好的动物检测模型的需求。", "innovation": "本文介绍了MMLA多环境、多物种、低海拔无人机数据集，涵盖肯尼亚三个地点的六种不同物种的高分辨率视频，共包含811K标注数据。通过在该数据集上进行微调，YOLOv11m的mAP50达到了82%，相比基线模型提升了52%的性能。研究表明，为了在自主无人机系统中实现鲁棒的动物检测，需要多样的训练数据。", "conclusion": "研究结果强调了多样的训练数据在构建鲁棒性动物检测模型中的重要性，特别适用于自主无人机系统。"}
{"llm_update_time": "20251023", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2504.10483", "html_url": "https://arxiv.org/abs/2504.10483", "title": "REPA-E: 通过潜在扩散变换器实现端到端调优的VAE解锁", "title_en": "REPA-E: Unlocking VAE for End-to-End Tuning with Latent Diffusion Transformers", "authors": "Xingjian Leng,Jaskirat Singh,Yunzhong Hou,Zhenchang Xing,Saining Xie,Liang Zheng", "background": "传统的深度学习观点认为，当可行时，端到端训练通常是优选的。然而，对于潜在扩散变换器而言，通过标准扩散损失端到端训练VAE和扩散模型是无效的，甚至会导致最终性能下降。研究团队观察到，通过代表对齐损失（REPA loss）可以解锁端到端训练，从而使VAE和扩散模型能够在训练过程中联合调整。", "innovation": "提出了一种新的训练方案（REPA-E），该方案通过代表对齐损失，使VAE和扩散模型能够在训练过程中进行端到端联合调整，从而显著提高了扩散模型的训练速度（超过17倍和45倍），并且在通过REPA-E进行端到端调优时，提高了VAE本身的性能，优化了潜在空间结构和下游生成性能。另外，该方法在ImageNet 256x256上达到了FID为1.12（有无条件的无分类指导）的新最佳效果。", "conclusion": "提出了REPA-E训练方法，通过代表对齐损失在端到端训练中成功结合VAE和扩散模型，显著提高了训练效率和生成质量，并在ImageNet数据集上达到了新的性能基准。"}
{"llm_update_time": "20251023", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2505.13061", "html_url": "https://arxiv.org/abs/2505.13061", "title": "3D视觉幻觉深度估计", "title_en": "3D Visual Illusion Depth Estimation", "authors": "Chengtang Yao,Zhidan Liu,Jiaxi Zeng,Lidong Yu,Yuwei Wu,Yunde Jia", "background": "3D视觉幻觉是一种感知现象，当平面上的图像经过操纵模拟出三维空间关系时，能够使二维的艺术品或物体在人类视觉系统中看起来具有三维效果。本文探讨了3D视觉幻觉对机器视觉系统中深度估计的影响。研究者收集了大量包含近3000个场景和20万张图像的数据集，用于训练和评估最先进的单目和双目深度估计方法。研究发现，最先进的单目、双目及多视图深度估计技术都受到了3D视觉幻觉的影响，而提出的一种使用视觉语言模型常识来适配性融合来自双眼立体视差和单目深度的深度估计框架则表现出最优性能。", "innovation": "本文提出了一种基于视觉语言模型常识的3D视觉幻觉深度估计框架，用于适应性地融合来自于双眼立体视差和单目深度的深度信息。与最先进的单目、双目和多视图深度估计方法相比，该方法在性能上表现出更优的效果。同时也证明了3D视觉幻觉能够严重误导机器视觉系统中的深度估计。", "conclusion": "实验证明，最先进的单目、双目和多视图深度估计技术都容易受到3D视觉幻觉的影响，而该论文的方法则能够更好地抵抗这种影响，取得了当前最优的性能。"}
{"llm_update_time": "20251023", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2505.18608", "html_url": "https://arxiv.org/abs/2505.18608", "title": "Spiking Neural Networks Need High Frequency Information", "title_en": "Spiking Neural Networks Need High Frequency Information", "authors": "Yuetong Fang,Deming Zhou,Ziqing Wang,Hongwei Ren,ZeCui Zeng,Lusong Li,Shibo Zhou,Renjing Xu", "background": "脉冲神经网络（SNNs）通过二元突触（0/1）传递信息，提供了仿生且节能的计算方式，但其性能仍落后于人工神经网络。人们普遍认为这是由于SNNs的稀疏和二元激活导致的信息损失所致。但是，本研究质疑了这一长期存在的假设，并指出SNNs存在未被注意到的频率偏差：SNNs天然抑制高频率成分，更偏爱传送低频率信息。这种频域不平衡被认为是SNN中特征表示受损的根本原因。", "innovation": "本文引入了Max-Former，通过两个频域增强操作器恢复高频信号：1.补全补采样以增强嵌入，2.用深度可分离卷积代替自注意力机制。Max-Former在ImageNet数据集上仅使用63.99M参数达到了82.39%的Top-1精度，超越了Spikformer（74.81%，66.34M参数）。此外，Max-ResNet-18在CIFAR-10和CIFAR-100上的性能也超越了现有模型，分别达到了97.17%和83.06%。", "conclusion": "本文的研究启示未来的SNN研究探索SNN的独特性质，证明高频信息对于SNN性能的重要性，并提供了一个简单有效的增强方案，提升了SNN在图像分类任务中的效果。"}
{"llm_update_time": "20251023", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2505.20641", "html_url": "https://arxiv.org/abs/2505.20641", "title": "穿透黑暗：夜间占用预测中的照明关联表示学习", "title_en": "See through the Dark: Learning Illumination-affined Representations for Nighttime Occupancy Prediction", "authors": "Yuan Wu,Zhiqiang Yan,Yigong Zhang,Xiang Li,Jian Yang", "background": "占用预测旨在估计3D空间中被占据区域的位置及其对应的语义标签。现有的基于视觉的方法在白天场景表现良好，但在夜间场景中却遇到了挑战，因为夜间场景中光照条件较差，能见度低。为了应对这种挑战，本文提出了一种名为LIAR的新框架，该框架能够学习适应光照的表示。LIAR首先引入了一种选择性低光照图像增强（SLLIE）机制，利用白天场景中的光照先验知识来适应性地判断夜间图像是真正黑暗还是充分光照，从而实现更有针对性的全局增强。", "innovation": "本文提出的LIAR框架包括两个创新组成部分：2D光照导向采样（2D-IGS）和3D光照驱动投影（3D-IDP）。2D-IGS根据光照图调节特征采样位置，在光照不足的区域增加采样偏移；3D-IDP通过构建光照强度场，并向BEV上下文细化过程提供精细的残差查询来在光照过度的区域增强语义理解。该框架能在复杂夜间环境下展示出优越的性能。", "conclusion": "本文实验结果在实际和合成数据集上都证明了LIAR框架在复杂夜间场景下的优越性能，并且提供的源代码和预训练模型可以在指定链接中获取。"}
{"llm_update_time": "20251023", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2506.05749", "html_url": "https://arxiv.org/abs/2506.05749", "title": "研究加权指标值与罗辛测度之间的关系", "title_en": "Investigating the Relationship between the Weighted Figure of Merit and Rosin's Measure", "authors": "Bimal Kumar Ray", "background": "许多研究致力于通过短直线段近似数字边界，以满足计算机视觉应用中的进一步处理需求。这些研究中使用的初始指标是准拟合优度指标，后来发现该指标并不合适，因此Rosin通过数学分析引入了称为测度的新指标。尽管如此，计算Rosin的指标需要较长时间，因此许多研究者采用加权准拟合优度指标作为替代品来比较非优化方案。本文旨在探讨加权准拟合优度指标与Rosin测度之间的关系，理论分析、实验研究和统计分析表明这两个指标在理论上是独立的。", "innovation": "本文通过理论分析、实验研究和统计分析探讨了加权准拟合优度指标与Rosin测度之间的关系，表明这两个指标本质上是独立的，即如果一个非优化方案根据Rosin的指标被认为优于另一个方案，那么同样的结论不能通过加权准拟合优度指标得出。", "conclusion": "根据理论分析、实验结果和统计分析的证据，研究发现两者是不相关的。因此，使用加权准拟合优度指标不能替代Rosin的测度来评估一个近似方案的好坏，不同方案的相对优劣需要根据Rosin的测度独立评估。"}
{"llm_update_time": "20251023", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2505.23566", "html_url": "https://arxiv.org/abs/2505.23566", "title": "Uni-MuMER: 统一多任务微调视觉-语言模型进行手写数学表达式识别", "title_en": "Uni-MuMER: Unified Multi-Task Fine-Tuning of Vision-Language Model for Handwritten Mathematical Expression Recognition", "authors": "Yu Li,Jin Jiang,Jianhua Zhu,Shuai Peng,Baole Wei,Yuxuan Zhou,Liangcai Gao", "background": "手写数学表达式识别（HMER）在光学字符识别（OCR）中一直是一个持久的挑战，因为符号布局的固有自由度和书写风格的高变异性使得性能受到了瓶颈。以往的方法通过提出孤立的架构修改来提升性能，但这使得它们难以整合到统一框架中。近年来，预训练视觉-语言模型（VLMs）取得了显著的跨任务泛化能力，为发展统一解决方案提供了有希望的基础。", "innovation": "本文提出了一种名为Uni-MuMER的方法，该方法完全微调VLM以用于HMER任务，而不修改其架构，有效地将特定领域的知识注入通用框架中。该方法整合了三种数据驱动任务：Tree-Aware Chain-of-Thought（Tree-CoT）用于结构化空间推理，Error-Driven Learning（EDL）用于减少视觉相似字符之间的混淆，以及Symbol Counting（SC）用于提高长表达式识别的一致性。实验表明，Uni-MuMER在CROHME和HME100K数据集上实现了超越最新水平的性能，在零样本设置中，它比最轻量化的专业模型SSAN高出16.31%，比性能最佳的VLM Gemini2.5-flash高出24.42%。", "conclusion": "Uni-MuMER在手写数学表达式识别任务上实现了最先进的性能，并通过开放相关数据集、模型和代码提高了该领域的透明度和可访问性。"}
{"llm_update_time": "20251023", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2505.24625", "html_url": "https://arxiv.org/abs/2505.24625", "title": "从视频学习构建3D世界：利用3D视觉几何先验增强MLLMs", "title_en": "Learning from Videos for 3D World: Enhancing MLLMs with 3D Vision Geometry Priors", "authors": "Duo Zheng,Shijia Huang,Yanyang Li,Liwei Wang", "background": "之前的研究已经探讨了利用多模态大型语言模型（MLLMs）通过将3D场景视为视频来理解3D场景。这些方法通常依赖于全面的3D数据输入，例如点云或重建的鸟瞰图（BEV）地图。", "innovation": "我们的研究在此领域向前迈出了一步，通过提出一种名为Video-3D Geometry Large Language Model (VG LLM) 的新颖且高效的方法来增强MLLMs的能力，使其能够直接从视频数据中理解和推理3D空间，而无需额外的3D输入。我们的方法利用3D视觉几何编码器从视频序列中提取3D先验信息，然后与视觉标记一起输入到MLLM中。广泛实验表明，本方法在各种与3D场景理解和空间推理相关的任务上取得了显著进步，并且直接从视频源学习。令人印象深刻的是，我们的4B模型不依赖于明确的3D数据输入，其性能与现有最先进的方法相比具有竞争力，并在VSI-Bench评估中甚至超越了Gemini-1.5-Pro。", "conclusion": "我们的方法直接从视频源中学习，且在各种与3D场景理解和空间推理相关的任务上取得了显著进步。即使不依赖于明确的3D数据输入，我们的4B模型也实现了与现有最先进的方法相媲美的结果，并在VSI-Bench评估中甚至超越了Gemini-1.5-Pro。"}
{"llm_update_time": "20251023", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2506.12323", "html_url": "https://arxiv.org/abs/2506.12323", "title": "医生批准：通过AI-专家反馈生成医学准确的皮肤疾病图像", "title_en": "Doctor Approved: Generating Medically Accurate Skin Disease Images through AI-Expert Feedback", "authors": "Janet Wang,Yunbei Zhang,Zhengming Ding,Jihun Hamm", "background": "医疗数据的稀缺性和不完整性严重限制了诊断机器学习模型的普适性，因为小型临床数据集无法充分代表疾病的全部变异。为了解决这一问题，扩散模型被认为是一种有前途的合成图像生成和增强方式，但它们经常生成医学上不准确的图像，损害了模型的性能。专家领域的知识对于合成正确编码临床信息的图像至关重要，尤其是在数据稀缺且质量优于数量的情况下。现有的通过人类反馈进行数据增强的方法，如强化学习和直接偏好优化，需要强大的奖励函数或需要大量专家的劳动评估。最近，多模态大型语言模型显示了其强大的视觉推理能力，使其成为评估的好候选者。", "innovation": "本文提出了一种称为MAGIC的新框架（Medically Accurate Generation of Images through AI-Expert Collaboration），该框架利用AI专家协作来合成临床准确的皮肤疾病图像用于数据增强。该方法创造性地将专家定义的标准转化为用于生成扩散模型（DMs）图像的具体反馈，显著提高了临床准确性，同时减少了直接的人类工作量。实验结果显示，使用这种方法合成的皮肤疾病图像质量大大提高，与皮肤科医生评估结果一致。另外，使用这些合成图像增大数据集可以提高诊断准确性，特别是在复杂条件下和少量情况下，提高了9.02%至13.89%。", "conclusion": "MAGIC框架通过AI专家反馈显著提高了临床皮肤疾病图像生成的准确性，增大数据集可提升诊断准确性，特别是在小数据量情况下表现出色。"}
{"llm_update_time": "20251023", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2506.16895", "html_url": "https://arxiv.org/abs/2506.16895", "title": "在有限数据下进行多模态对齐，让STRUCTURE引领你", "title_en": "With Limited Data for Multimodal Alignment, Let the STRUCTURE Guide You", "authors": "Fabian Gröger,Shuo Wen,Huyen Le,Maria Brbić", "background": "多模态模型在需要多模态对齐的复杂任务中展现出了强大的能力，如零样本分类和跨模态检索。然而，现有模型通常依赖成百万对的多模态样本，对于许多领域而言，获取这些样本既成本高昂又不现实。", "innovation": "该论文探索了在有限的配对数据下构建多模态模型的可行性，通过对预训练的单模态基础模型进行对齐。论文提出了一种名为STRUCTURE的有效正则化技术，确保单模态编码器的潜在空间保持邻域几何，同时证明了对齐最后一层往往是次优的，强调了对齐具有最高表示相似性的层的重要性。这些方法可以在现有对齐方法中轻易地实现，显著提高了24个零样本图像分类和检索基准的性能。", "conclusion": "研究结果表明，框架对于有限数据多模态学习的有效性和广泛适用性，为资源受限领域提供了一条有前景的发展道路。"}
{"llm_update_time": "20251023", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2506.15591", "html_url": "https://arxiv.org/abs/2506.15591", "title": "一步扩散以实现高细节和时间一致性的视频超分辨率", "title_en": "One-Step Diffusion for Detail-Rich and Temporally Consistent Video Super-Resolution", "authors": "Yujing Sun,Lingchen Sun,Shuaizheng Liu,Rongyuan Wu,Zhengqiang Zhang,Lei Zhang", "background": "在现实世界的视频超分辨率（Real-VSR）中，同时重现丰富的空间细节并保持时间一致性是一项极具挑战性的任务。现有的基于Stable Diffusion（SD）的Real-VSR方法通常在空间细节和时间共现性之间作出妥协，导致视觉效果不佳。文章认为关键在于如何从低质量（LQ）输入视频中有效提取抗退化的时间一致性先验，以同时增强视频细节并保持提取的一致性先验。", "innovation": "本文提出了一种双LoRA学习（DLoRAL）范式，用于训练基于SD的一步扩散模型，以同时实现逼真的帧细节和时间一致性。具体而言，引入了一种跨帧检索（CFR）模块来聚合帧间的互补信息，并训练了稳健的时间表示学习的Consistency-LoRA（C-LoRA）。在一致性学习之后，固定CFR和C-LoRA模块并训练Detail-LoRA（D-LoRA）来增强空间细节，同时与由C-LoRA定义的时间空间保持时间一致性。两个阶段迭代优化，以协同提供一致和丰富的细节输出。在推理过程中，两个LoRA分支合并到SD模型中，以实现单一步扩散中的高效和高质量的视频恢复.", "conclusion": "实验结果表明，DLoRAL在准确性和速度方面表现出强大的性能。有关代码和模型可在以下链接找到。"}
{"llm_update_time": "20251023", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2506.16962", "html_url": "https://arxiv.org/abs/2506.16962", "title": "Chiron-o1：通过导师-实习生协作搜索激发多模态大型语言模型的可泛化医疗推理能力", "title_en": "Chiron-o1: Igniting Multimodal Large Language Models towards Generalizable Medical Reasoning via Mentor-Intern Collaborative Search", "authors": "Haoran Sun,Yankai Jiang,Wenjie Lou,Yujie Zhang,Wenjie Li,Lilong Wang,Mianxin Liu,Lei Liu,Xiaosong Wang", "background": " multimodal large language models (MLLMs) 已经开始在一般任务中展示出强大的推理能力，但在医疗领域的应用仍处于早期阶段。目前的训练数据方法缺乏一个全面的框架来搜索和评估有效的推理路径，特别是在关键诊断方面。", "innovation": "提出了导师-实习生协作搜索（MICS）作为一种新型的推理路径搜索方案，用于生成严密且有效的医疗chain-of-thought (CoT) 数据。MICS 首先利用导师模型逐步初始化推理，然后提示每个实习生模型沿着这些初始路径继续推理，并最终根据多个人工智能模型的整体推理性能选择最佳推理路径。此外，构建了 MMRP，这是一个具有分级难度的多任务医疗推理数据集，以及通过一个阶梯学习策略构建的 Chiron-o1 新的医疗 MLLM，具备稳健的视觉问答和可泛化的推理能力。", "conclusion": "广泛的实验表明，Chiron-o1 在使用 MICS 构建的 CoT 数据集进行训练后，在一系列医疗视觉问答和推理基准测试中取得了最先进的性能。相关代码可在指定的链接中获取。"}
{"llm_update_time": "20251023", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2506.23434", "html_url": "https://arxiv.org/abs/2506.23434", "title": "追求高效潜流匹配的基石LiDAR世界模型", "title_en": "Towards foundational LiDAR world models with efficient latent flow matching", "authors": "Tianran Liu,Shengwen Zhao,Nicholas Rhinehart", "background": "LiDAR基于的世界模型相比图像基于的世界模型能提供更加结构化和几何意识的表示，但现有的LiDAR世界模型在特定领域内表现出色，却难以在不同场景下迁移应用。本文旨在探索如何开发一种具有跨域迁移能力的LiDAR世界模型。", "innovation": "本文首次系统地对三种挑战性的场景进行了跨域迁移研究，包括户外到室内的通用化、稀疏光束与密集光束适应以及语义信息到非语义信息的迁移。通过提出一种基于潜流匹配（CFM）框架的新方法，验证了单个预训练模型在不同数据量下可获得超过训练从零开始的11%绝对改善，并且在大多数比较中表现优于从头开始训练。此外，该方法大大减少了用于语义占有预测所需的手动注释数据，并且在保持较高重建精度的同时，减少了训练数据的使用量和压缩比。同时，该方法在未来的轨迹条件下的语义占用预测和语义占用预测中都实现了最先进的性能，且在计算效率上有了显著改善。", "conclusion": "研究证实了一种能够高效执行动态学习并具有跨域迁移能力的LiDAR世界模型的可行性，并通过新的框架提高了预测精度和计算效率。"}
{"llm_update_time": "20251023", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.09984", "html_url": "https://arxiv.org/abs/2507.09984", "title": "带有掩码自编码器的潜在扩散模型", "title_en": "Latent Diffusion Models with Masked AutoEncoders", "authors": "Junho Lee,Jeongwoo Shin,Hyungwook Choi,Joonseok Lee", "background": "尽管潜在扩散模型（LDMs）在图像生成方面具有显著潜力，但其所需特性和最优化设计的自动编码器尚未得到充分探索。本文分析了自动编码器在LDMs中的作用，并确定了三个关键属性：潜在的平滑性、感知压缩质量和重构质量。现有自动编码器无法同时满足这三个属性。", "innovation": "本文提出了一种新的技术——变分掩码自动编码器（VMAEs），利用掩码自动编码器保持的层次特征优势。将VMAEs整合到LDM框架中，提出了带有掩码自动编码器的潜在扩散模型（LDMAEs）。", "conclusion": "现有的自动编码器无法同时满足潜在的平滑性、感知压缩质量和重构质量三个属性，而通过将VMAEs整合到LDM框架中，我们能够更好地实现这些属性。已发布的代码可以在提供的链接中找到。"}
{"llm_update_time": "20251023", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.05916", "html_url": "https://arxiv.org/abs/2507.05916", "title": "解释性人工智能在遥感图像场景分类中的有效性的研究", "title_en": "On the Effectiveness of Methods and Metrics for Explainable AI in Remote Sensing Image Scene Classification", "authors": "Jonas Klotz,Tom Burgert,Begüm Demir", "background": "近年来，解释性人工智能(xAI)方法在遥感(RS)中的场景分类问题发展迅速，吸引了大量关注。然而，现有的大多数xAI方法及其相关指标最初都是为计算机视觉(CV)中的自然图像开发的，直接应用于RS可能不完全适用。该研究旨在分析和评估这些xAI方法及其指标在RS图像场景分类中的有效性。研究分析了多种解释指标和方法在不同RS数据集上的应用效果，揭示了现有方法和指标存在的局限性，并提供了选择合适方法的指导建议。", "innovation": "1. 该研究系统地分析了多种解释指标和方法（涵盖五个维度：忠实度、鲁棒性、定位、复杂性和随机化）在遥感图像场景分类中的应用效果。\n2. 研究发现了不同解释方法和指标在遥感场景分类中的局限性，特别是针对基于扰动的方法、基于梯度的方法以及一些相关传播方法的特点进行了详细分析。\n3. 研究提供了实用的指导建议，帮助选择适合遥感图像场景分类的解释方法、指标和超参数。", "conclusion": "该研究揭示了现有解释性人工智能方法及其指标在遥感图像场景分类中的局限性，并基于分析结果提供了实用的指导建议，以选择合适的解释方法、指标和超参数用于遥感图像场景分类。"}
{"llm_update_time": "20251023", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.11540", "html_url": "https://arxiv.org/abs/2507.11540", "title": "向深度基础模型迈进：基于视觉的深度估计最新趋势", "title_en": "Towards Depth Foundation Model: Recent Trends in Vision-Based Depth Estimation", "authors": "Zhen Xu,Hongyu Zhou,Sida Peng,Haotong Lin,Haoyu Guo,Jiahao Shao,Peishan Yang,Qinglin Yang,Sheng Miao,Xingyi He,Yifan Wang,Yue Wang,Ruizhen Hu,Yiyi Liao,Xiaowei Zhou,Hujun Bao", "background": "深度估计是3D计算机视觉中的基本任务，对于3D重建、自由视角渲染、机器人、自动驾驶和AR/VR技术等应用至关重要。传统的硬件传感器方法如LiDAR通常受到成本高、分辨率低和环境敏感性的限制，这限制了它们在实际场景中的应用。深度学习方法的进步提供了另一种有希望的选择，但这些方法在泛化和稳定性方面仍然面临挑战，这主要是因为模型架构容量低或依赖于领域特定的小规模数据集。在其他领域出现的规模律和基础模型的启发，促进了‘深度基础模型’的发展：这些深度神经网络在大型数据集上训练，并且具有强大的零样本泛化能力。", "innovation": "本论文通过调查不同视角（单目、立体、多视图和单目视频）下的深度估计深度学习架构和范式的发展历程，探索这些模型在解决现有挑战中的潜力。论文提供了大规模数据集的全面概述，旨在促进深度基础模型的发展，并通过识别关键架构和训练策略，强调了建立稳健深度基础模型的路径，同时也为未来的研究和应用提供了见解。", "conclusion": "通过综合分析现有的深度估计模型和数据集，论文提出了深度基础模型的发展路径，旨在为该领域的未来研究和应用提供指导。"}
{"llm_update_time": "20251023", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.07780", "html_url": "https://arxiv.org/abs/2507.07780", "title": "在图像分类中的数据集偏移校准现状", "title_en": "Where are we with calibration under dataset shift in image classification?", "authors": "Mélanie Roschewitz,Raghav Mehta,Fabio de Sousa Ribeiro,Ben Glocker", "background": "本文对图像分类中的校准状态在现实世界的数据集偏移下的情况进行了详细研究。研究为后验和在校训练期间的校正技术的选择提供了重要的见解，并为所有对在偏移条件下实现可靠的校准感兴趣的从业者提供了实用的指导。研究在八种不同分类任务的多个成像领域中，广泛比较了各种后验校准方法及其与常见在校训练校正策略（例如标签平滑）的交互，涵盖了广泛的自然偏移。", "innovation": "研究发现，在数据集偏移下，同时应用熵正则化和标签平滑能提供最好的校准原始概率；后验校正器在少量语义的外部分布数据（与任务无关）暴露下，表现出更高的偏移鲁棒性；最近专门针对增加偏移条件下校准的方法未必比简单的后验校正方法提供显著改进；在偏移下的校准提升往往会导致原分布下校准性能下降。此外，对于从基础模型微调的分类器，其校准效果始终优于从零开始训练的模型。", "conclusion": "这些发现不仅适用于随机初始化的分类器，也适用于从基础模型微调的分类器。后者在整个成像领域中的校准表现优于从零开始训练的模型。文章还分析了集成效果，发现对集成来说，在集成前应用校准相较于集成后更有效；外部分布数据暴露会恶化原分布-偏移校准折衷；集成仍然是提高校准稳健性最有效的方法之一，并结合从基础模型微调可以实现最佳的校准结果。"}
{"llm_update_time": "20251023", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.17452", "html_url": "https://arxiv.org/abs/2509.17452", "title": "无监督标签空间对齐在通用领域自适应中的应用", "title_en": "Training-Free Label Space Alignment for Universal Domain Adaptation", "authors": "Dujin Lee,Sojung An,Jungmyung Wi,Kuniaki Saito,Donghyun Kim", "background": "通用领域自适应（UniDA）方法将标记的源领域知识转移到未标记的目标领域，目标领域可能拥有私有的类，且标签空间可能存在差异。以往的UniDA方法主要关注视觉空间对齐，但由于内容差异导致的视觉模糊性，其鲁棒性和泛化能力受限。", "innovation": "提出了一种新的无监督标签空间对齐方法（\textit{ours}），利用具有零样本能力的最近的视觉-语言基础模型（VLMs，如CLIP），该方法专注于标签空间对齐，通过过滤和精炼领域间的噪声标签来增强自适应稳定性。此方法在域转移时构建了一个集成共享知识和目标私有类信息的通用分类器，从而在关键的DomainBed基准测试中表现出显著提升。", "conclusion": "所提出的方法显著优于现有的UniDA技术，在H-score和H$^3$-score方面分别平均提高了7.9%和6.1%。进一步引入自我训练达到了1.6%的额外性能提升，从而在这两个评分上都取得了改进。"}
{"llm_update_time": "20251023", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.15568", "html_url": "https://arxiv.org/abs/2508.15568", "title": "无梯度传播的基于概率高斯对齐的测试时自适应", "title_en": "Backpropagation-Free Test-Time Adaptation via Probabilistic Gaussian Alignment", "authors": "Youjia Zhang,Youngeun Kim,Young-Geun Choi,Hongyeob Kim,Huiling Liu,Sungeun Hong", "background": "测试时自适应（TTA）通过在推理过程中利用未标记的测试数据来增强零样本鲁棒性。尽管取得了显著进展，但仍有几个挑战限制了其广泛应用。首先，大多数方法依赖于反向传播或迭代优化，这限制了其可扩展性并妨碍了实时部署。其次，缺乏对类条件特征分布的明确建模。这种建模对于产生可靠的决策边界和校准预测至关重要，但由于缺乏测试时的源数据和监督，这一领域仍处于起步阶段。", "innovation": "本文提出了ADAPT，一种无需梯度传递和全量目标数据访问的高级分布感知测试时自适应方法。通过将TTA重新构想为高斯概率推断任务，并使用逐渐更新的类均值和共享协方差矩阵来建模类条件似然性，ADAPT实现了无需训练的闭式推断。为了校正潜在的似然偏差，引入了由CLIP先验和历史知识库指导的轻量级正则化方法。ADAPT 支持在线和归纳式设置，实验表明该方法在各种分布变化下达到了最优性能，具有优异的可扩展性和鲁棒性。", "conclusion": "本文提出的方法在广泛的分布变化下实现了最先进的性能，并且具有高级的可扩展性和鲁棒性，支持在线和归纳式设置。"}
{"llm_update_time": "20251023", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.00744", "html_url": "https://arxiv.org/abs/2508.00744", "title": "重新思考LiDAR轻量级3D物体检测的骨干设计", "title_en": "Rethinking Backbone Design for Lightweight 3D Object Detection in LiDAR", "authors": "Adwait Chandorkar,Hasan Tercan,Tobias Meisen", "background": "近年来，基于LiDAR的3D物体检测技术大大加速了全自动驾驶在实际环境中的实现。尽管检测性能很高，但大多数方法仍依赖于VGG或ResNet骨干网络进行特征提取，这增加了模型的复杂性。轻量级骨干设计在2D检测中已被广泛研究，但对于3D物体检测的研究仍相对有限。因此，本文提出了Dense Backbone，一种兼顾高速处理、轻量级架构和稳健检测精度的轻量级骨干网络。通过将多种最新3D物体检测器（如PillarNet）适配到我们的骨干网络中，实验表明，使用我们的骨干网络可以在显著降低计算成本的情况下保留这些模型的大部分检测能力。", "innovation": "本研究提出了一种专为点云数据中3D物体检测设计的Dense Backbone轻量级骨干网络。与现有的基于VGG或ResNet的骨干网络相比，DensePillarNet（PillarNet的适应版本）在nuscenes测试集上将模型参数减少了29%，延迟降低了28%，同时检测精度仅下降了2%。此外，Dense Backbone具有即插即用的设计，可以轻松集成到现有架构中，无需修改其他网络组件。", "conclusion": "本研究通过引入Dense Backbone轻量级骨干网络，证明其可以显著降低3D物体检测的计算成本，同时保持检测性能，这为LiDAR轻量级3D物体检测提供了新的解决方案。"}
{"llm_update_time": "20251023", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.17955", "html_url": "https://arxiv.org/abs/2509.17955", "title": "打破连续物理仿真学习的离散化障碍", "title_en": "Breaking the Discretization Barrier of Continuous Physics Simulation Learning", "authors": "Fan Xu,Hao Wu,Nan Wang,Lilan Peng,Kun Wang,Wei Gong,Xibin Zhao", "background": "从部分观察数据中建模复杂的时空演变物理动力学是一个长期的挑战。尤其是，观察数据可以以一种看似随机或无结构的方式分布，这使得捕捉多种科学和工程问题中的高度非线性特征变得困难。现有的数据驱动方法通常受到固定空间和时间离散化的限制。尽管有些研究人员通过设计新颖策略来实现空间时间连续性，但他们要么过度依赖传统的数值方法，要么未能真正克服离散化带来的限制。", "innovation": "我们提出了一种名为CoPS的纯数据驱动方法，以有效从部分观察中建模连续物理仿真。具体而言，我们使用乘法滤波网络将空间信息与相应的观察数据融合和编码。然后，我们自定义几何网格并使用消息传递机制将特征从原始空间域映射到自定义网格。之后，CoPS通过设计多尺度图ODE来建模连续时间动态，并引入基于马尔可夫的神经自动化校正模块来协助和约束连续外推。", "conclusion": "综合实验表明，CoPS在各种场景下提高了空间时间连续建模方法的最新水平。"}
{"llm_update_time": "20251023", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.18582", "html_url": "https://arxiv.org/abs/2509.18582", "title": "摄影师之眼：教会多模态大型语言模型像摄影师一样理解图像美感", "title_en": "The Photographer Eye: Teaching Multimodal Large Language Models to Understand Image Aesthetics like Photographers", "authors": "Daiqing Qi,Handong Zhao,Jing Shi,Simon Jenni,Yifei Fan,Franck Dernoncourt,Scott Cohen,Sheng Li", "background": "摄影师在直接从生活中编辑照片时发现，很难同时看清天空的颜色和蓝色。摄影师策展人Szarkowski揭示了普通视觉理解和美学视觉理解之间的一个显著差异：前者侧重于识别图像中的事实元素（天空），而后者则超越了这种对象识别，将其视为美学元素——纯净的颜色块（蓝色）。这种普通和美学视觉理解之间的基本差异给多模态大型语言模型（MLLMs）带来了巨大的挑战。尽管一些最近的研究已经进行了初步探索，但它们往往局限于普通和基本的美学常识。因此，它们在现实世界场景中经常失败，这些场景需要广泛的的专业知识，包括摄影技巧、照片的前后处理知识等，来提供详细的分析和描述。", "innovation": "本文首先提出了一种名为PhotoCritique的新数据集，该数据集源自专业摄影师和爱好者的广泛讨论，具备大规模、专业性和多样性特点。其次，为了更好地从PhotoCritique中学习视觉美学，本文还提出了一个名为PhotoEye的新模型，该模型采用语言引导的多视图视觉融合机制，可以从多个角度理解图像的美学。最后，本文提供了一个新的基准测试，名为PhotoBench，这是一个全面且专业的美学视觉理解基准。在现有基准测试和PhotoBench中，该模型清楚地优于现有模型。", "conclusion": "我们的模型在现有基准测试和PhotoBench上的表现优于现有模型，显示出了在美学理解方面的明确优势。"}
{"llm_update_time": "20251023", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.11553", "html_url": "https://arxiv.org/abs/2510.11553", "title": "给定基础模型，标注样本的数量是多少？胸部X光分类研究", "title_en": "How many samples to label for an application given a foundation model? Chest X-ray classification study", "authors": "Nikolay Nechaev,Evgeniia Przhezdzetskaia,Viktor Gombolevskiy,Dmitry Umerenkov,Dmitry Dylov", "background": "胸部X光分类至关重要但资源密集型，通常需要大量标注数据以实现准确诊断。基础模型可以减轻对大量标注数据的依赖，但具体需要多少标注样本仍不清楚。", "innovation": "系统性评估使用幂律拟合预测达到特定ROC-AUC阈值所需的训练集大小。研究发现，XrayCLIP和XraySigLIP在标注样本数量显著少于ResNet-50基线的情况下取得良好性能。仅50个标注样本的学习曲线斜率即可准确预测最终性能平台。", "conclusion": "研究结果使实践者能够通过仅对关键样本进行标注来最小化注释成本，以实现目标性能。"}
{"llm_update_time": "20251023", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.19028", "html_url": "https://arxiv.org/abs/2509.19028", "title": "使用视觉变换器和分割一切模型的弱监督食物图像分割", "title_en": "Weakly Supervised Food Image Segmentation using Vision Transformers and Segment Anything Model", "authors": "Ioannis Sarafis,Alexandros Papadopoulos,Anastasios Delopoulos", "background": "本文提出了一种利用分割一切模型（SAM）的零样本能力和视觉变换器（ViTs）的注意力机制的弱监督语义分割方法，应用于食物图像。ViTs 模型通过图像级别注释单独训练，替代了传统的像素级别注释。文章通过改良 SAM 生成分割掩码的方法，结合图像预处理技术、单掩码和多掩码的 SAM 生成策略，提高了食物图像分割的质量。实验在 FoodSeg103 数据集上进行，生成了每幅图像平均2.4个分割掩码（不包括背景），在多掩码情况下获得了0.54的mIoU（平均交并比）.", "innovation": "本文方法创新性地利用了 Vision Transformers 的注意力机制和 Segment Anything Model 的零样本能力，通过生成类激活映射（CAMs）为 SAM 提供提示，生成适用于食物图像分割的掩码。此外，通过使用图像预处理技术和单掩码及多掩码生成策略改进 SAM 的掩码质量。", "conclusion": "本文的方法为加速食物图像标注任务或作为食物和营养跟踪应用的组成部分提供了可能，通过使用视觉变换器和分割一切模型实现了食物图像的弱监督语义分割，并在 FoodSeg103 数据集上验证了其有效性。"}
{"llm_update_time": "20251023", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.02030", "html_url": "https://arxiv.org/abs/2510.02030", "title": "kabr-tools：多物种行为监测的自动化框架", "title_en": "kabr-tools: Automated Framework for Multi-Species Behavioral Monitoring", "authors": "Jenna Kline,Maksim Kholiavchenko,Samuel Stevens,Nina van Tiel,Alison Zhong,Namrata Banerji,Alec Sheets,Sowbaranika Balasubramaniam,Isla Duporge,Matthew Thompson,Elizabeth Campolongo,Jackson Miliko,Neil Rosser,Tanya Berger-Wolf,Charles V. Stewart,Daniel I. Rubenstein", "background": "对动物行为生态学的全面理解依赖于能够量化和解释复杂、多维度行为模式的可扩展方法。传统的野外观察往往范围有限、耗时且繁琐，阻碍了对跨景观的行为响应评估。为了解决这一问题，本文介绍了一种名为kabr-tools的开源工具包，用于自动化多物种行为监测。该框架结合了无人机视频与机器学习系统，从野生动物视频中提取行为、社会和空间指标。", "innovation": "kabr-tools利用目标检测、跟踪和行为分类系统生成关键指标，包括时间预算、行为转换、社会互动、生境关联以及群体组成动态。与基于地面的方法相比，基于无人机的观察显著提高了行为粒度，在提高可见性损失减少15%的同时，更准确、连续地捕捉到更多过渡。", "conclusion": "通过大规模的自动化行为监测，kabr-tools为生态系统范围内的研究提供了强力工具，推动了保护、生物多样性研究和生态监测的进步。该工具已通过三个案例研究验证，分析了969个行为序列，超过了传统方法的数据捕获和注释能力。本文还发现，与平原斑马相同，细纹斑马的警戒行为随群体规模增大而减少，但不同于平原斑马，环境对细纹斑马的影响可以忽略不计；两物种显示出强烈的行为惯性，警觉行为的转换极为罕见，混合群中观察到细纹斑马、平原斑马与长颈鹿之间的空间隔离。"}
{"llm_update_time": "20251023", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.17482", "html_url": "https://arxiv.org/abs/2510.17482", "title": "SparseWorld: 由稀疏和动态查询驱动的灵活、适应性和高效的4D占用世界模型", "title_en": "SparseWorld: A Flexible, Adaptive, and Efficient 4D Occupancy World Model Powered by Sparse and Dynamic Queries", "authors": "Chenxu Dang,Haiyan Liu,Guangjun Bao,Pei An,Xinyue Tang,An Pan,Jie Ma,Bingchuan Sun,Yan Wang", "background": "语义占用已成为世界模型的强大表示，因为它能够捕捉丰富的空间语义。然而，大多数现有的占用世界模型依赖静态和固定的嵌入或网格，这本质上限制了感知的灵活性。此外，它们在网格上的'就地分类'展示了与真实世界动态和连续性质的潜在不匹配。", "innovation": "本文提出了一种名为SparseWorld的新型4D占用世界模型，它具有灵活性、适应性和效率。通过稀疏和动态查询，该模型引入了可调节的感知模块和时空关联，设计了状态条件化预测模块，用回归导向的形式取代基于分类的预测，引入了时空意识自调度训练策略，以实现平滑和高效的训练。", "conclusion": "广泛的实验证明，SparseWorld在感知、预测和规划任务中达到了最先进的性能。全面的可视化和剖析研究进一步验证了SparseWorld在灵活性、适应性和效率方面的优势。代码可在论文网站上获取。"}
{"llm_update_time": "20251023", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.14847", "html_url": "https://arxiv.org/abs/2510.14847", "title": "ImagerySearch: 超越语义依赖约束的视频生成自适应测试时搜索", "title_en": "ImagerySearch: Adaptive Test-Time Search for Video Generation Beyond Semantic Dependency Constraints", "authors": "Meiqi Wu,Jiashu Zhu,Xiaokun Feng,Chubin Chen,Chen Zhu,Bingze Song,Fangyuan Mao,Jiahong Wu,Xiangxiang Chu,Kaiqi Huang", "background": "视频生成模型在现实场景中取得了显著进步，但在想象力场景中表现不佳。这类场景通常涉及稀有共现的概念和长距离的语义关系，超出了训练分布的范围。现有方法通常在测试时应用放大策略以改善视频质量，但它们固定搜索空间和静态奖励设计限制了其在想象力场景中的适应性。", "innovation": "提出了一种名为ImagerySearch的提示引导自适应测试时搜索策略，它根据提示中的语义关系动态调整推理搜索空间和奖励函数，从而在挑战性的想象力设置中生成更连贯和视觉上合理的视频。为了评估这一方向上的进展，引入了LDT-Bench，这是第一个专门针对长距离语义提示的基准，包括2,839种不同的概念对和评估创造性生成能力的自动化协议。实验证明，ImagerySearch在LDT-Bench上始终优于强大的视频生成基线和现有的测试时放大方法，并在VBench上实现有竞争力的改进，证明了其在各种提示类型下的有效性。", "conclusion": "ImagerySearch在LDT-Bench上优于多种视频生成基线和现有的测试时放大方法，并在VBench上实现竞争力的改进，展现了其在不同提示类型中的有效性。LDT-Bench和代码将被释放，以促进未来在想象力视频生成方面的研究。"}
{"llm_update_time": "20251023", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.17501", "html_url": "https://arxiv.org/abs/2510.17501", "title": "基于上下文的伪标签评分在零样本视频摘要中的应用", "title_en": "Context-Aware Pseudo-Label Scoring for Zero-Shot Video Summarization", "authors": "Yuanli Wu,Long Zhang,Yue Du,Bin Li", "background": "该研究介绍了一种结合大型语言模型和结构化语义推理的零样本视频摘要框架。框架通过伪标签和提示驱动的方式，使用少量的人工注释生成高质量的伪标签，并将其组织成适应数据集的评价维度，如主题相关性、动作细节和叙事进展。", "innovation": "该框架创新性地提出了基于上下文的伪标签评分方法，将少量的人工注释数据转化为有高置信度的伪标签，并通过结构化的评价维度进行组织。在推理过程中，框架独立地对开头和结尾的场景进行评分，中间场景则结合相邻段落的摘要来评估叙事连贯性和冗余性。这种方法允许语言模型平衡局部突出性与全局一致性。实验结果显示，该方法在三个基准测试上的F1分数表现出稳定且具有竞争力的结果，超过零样本基线方法。", "conclusion": "该研究通过伪标签和上下文提示的方法提升零样本视频摘要的质量和稳定性，表明这种方法能够提供一个通用、可解释且无需训练的框架，适用于通用及查询焦点的视频摘要任务。"}
{"llm_update_time": "20251023", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.17568", "html_url": "https://arxiv.org/abs/2510.17568", "title": "PAGE-4D: 解离的4D姿态与几何估计", "title_en": "PAGE-4D: Disentangled Pose and Geometry Estimation for 4D Perception", "authors": "Kaichen Zhou,Yuhan Wang,Grace Chen,Xinhai Chang,Gaspard Beaudouin,Fangneng Zhan,Paul Pu Liang,Mengyu Wang", "background": "近期的3D前馈模型，例如Visual Geometry Grounded Transformer (VGGT)，在推断静态场景的3D属性方面展示了强大的能力。然而，由于这些模型通常是在静态数据集上进行训练，它们在涉及复杂动态元素的真实场景中（如移动的人、雨伞等变形物体）表现不佳。", "innovation": "为了解决这一限制，我们提出了PAGE-4D，这是一种扩展了VGGT以适应动态场景的前馈模型，并能够进行摄像机姿态估计、深度预测和点云重建，无需后续处理。为了解决多任务4D重建中的任务冲突问题，我们提出了一个动态感知聚合器，通过预测动态感知掩码来解分静态和动态信息，在姿态估计过程中抑制运动迹象，在几何重建过程中放大它们。", "conclusion": "广泛的实验表明，PAGE-4D在动态场景中始终优于原始的VGGT，特别是在摄像机姿态估计、单目和视频深度估计以及密集点图重建方面取得了更好的效果。"}
{"llm_update_time": "20251023", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.17519", "html_url": "https://arxiv.org/abs/2510.17519", "title": "MUG-V 10B: 高效训练流水线用于大规模视频生成模型", "title_en": "MUG-V 10B: High-efficiency Training Pipeline for Large Video Generation Models", "authors": "Yongshun Zhang,Zhongyi Fan,Yonghang Zhang,Zhangzikang Li,Weifeng Chen,Zhongwei Feng,Chaoyue Wang,Peng Hou,Anxiang Zeng", "background": "近年来，视觉内容的大规模生成模型（例如图像、视频和3D物体/场景）取得了显著进展。然而，训练大规模视频生成模型仍然特别具有挑战性和资源密集，原因包括跨模态文本-视频对齐、长序列的参与以及复杂的时空依赖关系。", "innovation": "本文提出了一种训练框架，优化了四大支柱：（i）数据处理，（ii）模型架构，（iii）训练策略，以及（iv）大规模视频生成模型的基础设施。这些优化在数据预处理、视频压缩、参数缩放、基于学习阶段的预训练以及关注对齐的后期训练中均实现了显著的效率提升和性能改进。MUG-V 10B 模型在整体上与最近的最先进的视频生成器相匹配，在以电子商务为中心的视频生成任务中，MUG-V 10B 超过了领先开源基准的评价。此外，作者开源了整个堆栈，包括模型权重、基于 Megatron-Core 的大规模训练代码以及视频生成和增强的推理管道，这是首次公开展示利用 Megatron-Core 实现高训练效率和近线性多节点扩展的大型视频生成训练代码。详情请参阅：this https URL", "conclusion": "我们的模型 MUG-V 10B 在整体上与最近的最先进的视频生成器相匹配，并在以电子商务为中心的视频生成任务中，通过人工评估超越了领先的开源基准。更为重要的是，我们开源了完整的堆栈，包括模型权重、基于 Megatron-Core 的大规模训练代码以及视频生成和增强的推理管道，这是首次公开展示利用 Megatron-Core 实现高训练效率和近线性多节点扩展的大型视频生成训练代码。"}
{"llm_update_time": "20251023", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.18362", "html_url": "https://arxiv.org/abs/2510.18362", "title": "FeatureFool：通过特征图欺骗视频模型的零查询攻击", "title_en": "FeatureFool: Zero-Query Fooling of Video Models via Feature Map", "authors": "Duoxun Tang,Xi Xiao,Guangwu Hu,Kangkang Sun,Xiao Yang,Dongyang Chen,Qing Li,Yongjie Yin,Jiyao Wang", "background": "现有的黑盒对抗攻击通常需要多轮与模型的交互，并消耗大量查询，这在实际应用中不切实际，难以应用于最近出现的Video-LLMs。此外，在视频领域中，没有任何攻击是直接利用特征图来改变干净视频特征空间的。", "innovation": "提出了一种名为FeatureFool的零查询黑盒攻击方法，它通过直接利用从深度神经网络中提取的信息来改变干净视频的特征空间。这种高效的方法在视频领域是前所未有的。实验结果显示，FeatureFool在不使用任何查询的情况下，对传统视频分类器的成功攻击率超过70%。此外，它还能生成有害内容并规避Video-LLM的识别。", "conclusion": "实验表明，基于特征图的FeatureFool攻击可以有效地对视频模型进行欺骗，即使在不使用任何查询的情况下，其成功率也非常高，并且生成的对抗视频在客观评价指标上表现出高质量，使得攻击难以被察觉。"}
{"llm_update_time": "20251023", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.18431", "html_url": "https://arxiv.org/abs/2510.18431", "title": "ScaleNet：通过增量参数扩展预训练神经网络", "title_en": "ScaleNet: Scaling up Pretrained Neural Networks with Incremental Parameters", "authors": "Zhiwei Hao,Jianyuan Guo,Li Shen,Kai Han,Yehui Tang,Han Hu,Yunhe Wang", "background": "近年来，视觉变换器（ViTs）取得了显著进展，大模型通常具有更好的性能。然而，训练这些模型仍面临巨大的计算和成本挑战。", "innovation": "本文介绍了一种名为ScaleNet的高效方法，该方法可以在不显著增加参数的情况下快速扩展ViT模型。ScaleNet基于预训练模型进行增量训练，通过在预训练模型中插入额外层并利用分层权重共享来实现模型扩展。此外，ScaleNet引入了调整参数以减轻共享权重可能引起的性能下降问题，这些调整参数通过并行适配器模块实现，确保每个共享参数张量的独特性和优化。", "conclusion": "通过在ImageNet-1K数据集上的实验，ScaleNet证明了可以高效扩展ViT模型。使用2倍深度扩展的DeiT-Base模型，ScaleNet相比于从头开始训练提高了7.42%的准确性，仅需要三分之一的训练周期。此外，该方法在目标检测等下游视觉任务中也展示了潜在的应用价值。"}
{"llm_update_time": "20251023", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.18313", "html_url": "https://arxiv.org/abs/2510.18313", "title": "OmniNWM: 全知驱动导航世界模型", "title_en": "OmniNWM: Omniscient Driving Navigation World Models", "authors": "Bohan Li,Zhuang Ma,Dalong Du,Baorui Peng,Zhujin Liang,Zhenqiang Liu,Chao Ma,Yueming Jin,Hao Zhao,Wenjun Zeng,Xin Jin", "background": "现有的自主驾驶世界模型通常仅在有限的状态模态、短视频序列、不精确的动作控制以及缺乏奖励意识等方面表现出局限性。此论文旨在通过一个统一的框架解决自主驾驶的三个核心维度：状态、动作以及奖励。OmniNWM 旨在提供全方位的全景导航世界模型，以实现跨维度的有效工作。", "innovation": "OmniNWM 引入了全景 Plucker 纳入规范化的代表方法，能够从轨迹中提取像素级信号，实现高质量的长期自回归生成。同时，OmniNWM 利用生成的三维占位性来直接定义基于规则的密集奖励函数，以确保驾驶行为的合规性和安全性。这种新的全方位模型在视频生成、控制精度和长期稳定性方面都达到了最先进的性能，并提供了一个通过三维占位性支持的闭环评估框架。", "conclusion": "通过引入全景图、规范化的全景 Plucker 纳入规范化的轨迹表示和基于规则的三维占位性奖励，OmniNWM 在视频生成、控制精度和长期稳定性方面取得了最先进的性能，并提供了一个可靠的闭环评估框架。"}
{"llm_update_time": "20251023", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.18822", "html_url": "https://arxiv.org/abs/2510.18822", "title": "SAM 2++: 在任意粒度下跟踪各种类型的目标", "title_en": "SAM 2++: Tracking Anything at Any Granularity", "authors": "Jiaming Zhang,Cheng Liang,Yichun Yang,Chenkai Zeng,Yutao Cui,Xinwen Zhang,Xin Zhou,Kai Ma,Gangshan Wu,Limin Wang", "background": "视频跟踪旨在根据目标的初始状态在后续帧中寻找特定目标。现有的大多数跟踪器都是针对单个任务定制的，并且高度依赖于针对特定任务设计的模块，这限制了它们的应用范围，并导致了模型设计和参数上的冗余。为了统一视频跟踪任务，本文提出SAM 2++，这是一个适用于任意粒度的统一模型，包括掩码、边界框和关键点跟踪。", "innovation": "本文设计了任务特定的提示来将各种任务输入编码为通用提示嵌入，并且引入了一个统一解码器来统一不同任务的结果。作者还引入了任务自适应记忆机制，统一不同粒度下的记忆。此外，还引入了一个定制的数据引擎来支持任意粒度下的跟踪训练，生成了一个包含三种粒度丰富注释的大型多样视频跟踪数据集，称为Tracking-Any-Granularity。", "conclusion": "通过在几个基准测试上进行的全面实验，本文证明SAM 2++在不同粒度的各种跟踪任务中达到了最先进的性能，建立了一个统一且稳定的跟踪框架。"}
{"llm_update_time": "20251023", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.18795", "html_url": "https://arxiv.org/abs/2510.18795", "title": "ProCLIP：通过基于LLM的嵌入器实现渐进的跨模态对齐", "title_en": "ProCLIP: Progressive Vision-Language Alignment via LLM-based Embedder", "authors": "Xiaoxing Hu,Kaicheng Yang,Ziyang Gong,Qi Ming,Zonghao Guo,Xiang An,Ziyong Feng,Junchi Yan,Xue Yang", "background": "原有的CLIP文本编码器受限于最大输入长度为77个标记，这限制了其处理长文本和进行细粒度语义理解的能力。此外，CLIP文本编码器不支持多语言输入。这些限制大大限制了其在更广泛任务中的应用。最近的研究尝试用基于LLM的嵌入器替换CLIP文本编码器，以增强其处理长文本、多语言理解和细粒度语义理解的能力。然而，由于LLM的表示空间和CLIP的跨模态空间是在没有先验对齐的情况下分别预训练的，直接使用对比学习进行对齐可能会破坏CLIP图像编码器固有的跨模态对齐，导致预训练知识的浪费和有效利用不足。", "innovation": "我们提出了一个基于课程学习的渐进步骤的跨模态对齐框架ProCLIP。首先，ProCLIP将CLIP文本编码器的知识转移到基于LLM的嵌入器中，利用CLIP丰富的预训练知识，同时初步对齐基于LLM的嵌入器和CLIP图像编码器。随后，通过图像-文本对比调优进一步对齐CLIP图像编码器与基于LLM的嵌入器，并使用自我蒸馏正则化来避免过度拟合。在此过程中，利用实例语义对齐损失和嵌入结构对齐损失进行表示继承和对比调优，以实现更有效的对齐。", "conclusion": "ProCLIP框架有效解决了CLIP图像编码器与基于LLM的嵌入器之间对齐的根本问题，通过对CLIP的文本编码器的知识进行转移并逐步对齐，最终实现二者的协同工作，从而有效处理长文本、多语言理解和细粒度语义理解，同时保证不破坏预训练的跨模态对齐。该方法的代码可在指定的链接处获得。"}
{"llm_update_time": "20251023", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2411.04844", "html_url": "https://arxiv.org/abs/2411.04844", "title": "离散高斯表示用于 tomographic 重建", "title_en": "Discretized Gaussian Representation for Tomographic Reconstruction", "authors": "Shaokai Wu,Yuxiang Lu,Yapan Guo,Wei Ji,Suizhi Huang,Fengyu Yang,Shalayiding Sirejiding,Qichen He,Jing Tong,Yanbiao Ji,Yue Ding,Hongtao Lu", "background": "计算机断层扫描（CT）能够进行详细的横截面成像，但仍然面临在重建质量和计算效率之间取得平衡的挑战。尽管基于深度学习的方法显著提高了图像质量和减少了噪音，但它们通常需要大规模的训练数据和大量的计算资源。场景重建的最新进展，如神经辐射场和3D 高斯散点图，提供了新的视角，但这些方法并不适合直接进行 CT 体积重建。", "innovation": "我们提出了离散高斯表示（DGR），这是一种新颖的框架，可以直接使用一整套离散高斯函数以端到端的方式进行3D体积重建。为了进一步提高效率，我们还引入了快速体积重建技术，这种技术通过最小的开销将高斯贡献聚合到体素网格中，实现了高度并行化。", "conclusion": "在真实世界和合成数据集上的广泛实验表明，DGR 在各种 CT 重建场景中实现了优良的重建质量和运行时性能。我们的代码可在以下链接公开获取：this https URL。"}
{"llm_update_time": "20251023", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.18876", "html_url": "https://arxiv.org/abs/2510.18876", "title": "掌握任意区域：致力于多模态大语言模型的精确、上下文像素理解", "title_en": "Grasp Any Region: Towards Precise, Contextual Pixel Understanding for Multimodal LLMs", "authors": "Haochen Wang,Yuhao Wang,Tao Zhang,Yikang Zhou,Yanwei Li,Jiacong Wang,Jiani Zheng,Ye Tian,Jiahao Meng,Zilong Huang,Guangcan Mai,Anran Wang,Yunhai Tong,Zhuochen Wang,Xiangtai Li,Zhaoxiang Zhang", "background": "尽管多模态大型语言模型（MLLMs）在整体理解方面表现出色，但它们在捕捉复杂场景中的密集世界时存在困难，需要精细分析复杂的细节和对象之间的关系。区域级别的MLLMs被认为是一个有希望的进展，但之前的尝试通常侧重于孤立理解给定的区域，忽视了全局上下文的重要性。因此，本研究介绍了一种名为Grasp Any Region（GAR）的方法，以实现全面的区域级视觉理解。通过一种有效的RoI对齐特征播放技术，GAR能够（1）利用必要的全局上下文进行精确感知，（2）建模多个提示之间的相互作用。GAR自然而然地实现了（3）高级组合推理，以回答关于任意区域的具体开放式问题，从而将范式从被动描述转变为积极对话。此外，还构建了GAR-Bench，这不仅提供了单区域理解的更准确评估，还更关键地衡量了在多个区域之间的交互和复杂推理。", "innovation": "介绍了Grasp Any Region（GAR），结合了RoI对齐特征播放技术，实现了精确感知和多个提示之间的相互作用，从而增强了高级组合推理能力。GAR不仅在图片描述方面保持了领先水平，还在多个提示关系建模方面表现出色，甚至超过了某些超大型模型。更为重要的是，零样本GAR在视频描述任务上也表现出色，这表明其能力可以轻松转移至视频理解任务中。", "conclusion": "GAR不仅提高了MLLMs在单区域理解、提示交互和复杂推理方面的表现，还展示了其强大的零样本转移能力，特别是在视频理解任务中更为显著。GAR-1B不仅在图片描述方面超越了DAM-3B，在GAR-Bench-VQA和VideoRefer-BenchQ上的表现也优于其他超大型模型，说明GAR具备优秀的泛化和应用潜力。"}
{"llm_update_time": "20251023", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2411.13022", "html_url": "https://arxiv.org/abs/2411.13022", "title": "全民快速MRI：无需原始数据进行训练以缩小访问差距", "title_en": "Fast MRI for All: Bridging Access Gaps by Training without Raw Data", "authors": "Yaşar Utku Alçalar,Merve Gülle,Mehmet Akçakaya", "background": "物理驱动的深度学习（PD-DL）方法提高了快速磁共振成像（MRI）扫描的重建效果。尽管PD-DL方法提供了比现有临床快速MRI技术更高的加速率，但它们的应用主要局限于专门的MRI中心。通用化到少见的病理或不同的人群是一个主要挑战，多数研究建议通过针对性的微调来改善这一点。然而，目前的PD-DL训练方法需要访问未处理的k空间测量数据，这在大多数情况下仅限于拥有研究协议的专门MRI中心。对于偏远和资源匮乏的地区来说，商业MRI扫描器仅提供最终重建图像，因此存在不便。", "innovation": "我们提出了一种名为CUPID的方法，利用常规的临床重建图像，在没有k空间数据的情况下进行高质量的PD-DL训练。CUPID通过基于压缩性的评价方法来评估输出质量，并通过精心设计的扰动确保输出与临床并行成像重建保持一致。实验结果表明，CUPID在输出质量和训练负担方面优于现有的压缩感知（CS）和基于扩散的生成方法。此外，我们展示了CUPID在回顾性和前瞻性子采样获取中的有效性。", "conclusion": "CUPID作为一种与现有策略完全不同的方法，有望为偏远和农村地区的快速MRI应用提供更广泛的接入，从而减少与该昂贵成像模态相关联的障碍。"}
{"llm_update_time": "20251023", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2411.17340", "html_url": "https://arxiv.org/abs/2411.17340", "title": "R和Python中使用TDAvec包对拓扑数据分析中的持久图进行矢量化", "title_en": "Vectorization of Persistence Diagrams for Topological Data Analysis in R and Python Using TDAvec Package", "authors": "Aleksei Luchinsky,Umar Islambekov", "background": "持久同调是一种广泛用于拓扑数据分析（TDA）的方法，用于理解复杂数据的基本形状。通过从数据点构造单纯形复形的滤波，它可以捕捉跨多个尺度的拓扑特征，如连接组件、环和空洞。这些特征被编码在持久图（PDs）中，提供数据拓扑结构的简洁摘要。然而，由于PD空间的非希尔伯特性质，在机器学习应用中的直接使用存在挑战。为了解决这个问题，已经开发了内核方法和矢量化技术，将PD转换为适合机器学习设置的格式。", "innovation": "本文介绍了一个新的软件包TDAvec，旨在简化PD的矢量化过程，提供直观的工作流程和高级功能。该软件包通过实际示例证明其必要性，并详细讨论其对应用TDA的贡献，包括所有矢量化摘要的定义附录中都有说明。", "conclusion": "通过使用TDAvec软件包进行PD矢量化，可以有效解决PD在机器学习应用中的使用问题，为拓扑数据分析提供了更好的工具支持。"}
{"llm_update_time": "20251023", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2503.01872", "html_url": "https://arxiv.org/abs/2503.01872", "title": "FairGen: 通过自适应隐含指导控制敏感属性实现扩散模型中的公平生成", "title_en": "FairGen: Controlling Sensitive Attributes for Fair Generations in Diffusion Models via Adaptive Latent Guidance", "authors": "Mintong Kang,Vinayshekhar Bannihatti Kumar,Shamik Roy,Abhishek Kumar,Sopan Khosla,Balakrishnan Murali Narayanaswamy,Rashmi Gangadharaiah", "background": "文本到图像的扩散模型常常会表现出对特定群体的偏见，比如在生成工程师图像时更倾向于生成男性图像，这引发了伦理上的担忧并限制了这些模型的使用。", "innovation": "本文提出了FairGen，一种自适应的隐含引导机制，在推理过程中控制生成分布，同时保持生成质量。它通过一个隐含引导模块动态调整扩散过程以强制执行特定属性，并通过一个内存模块跟踪生成统计来引导隐含引导，使其与目标属性值的公平分布一致。此外，还提出了Holistic Bias Evaluation (HBE)基准，该基准涵盖了多个领域并包含复杂的提示，以便更全面地评估偏见。", "conclusion": "在HBE和Stable Bias数据集上的广泛评估表明，FairGen优于现有的偏见缓解方法，实现了显著的偏见减少（例如，在Stable Diffusion 2上性别偏见减少了68.5%）。消融研究显示FairGen能够灵活地在用户指定的任何细粒度级别控制输出分布，从而确保适应性和针对性的偏见缓解。"}
{"llm_update_time": "20251023", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2410.10811", "html_url": "https://arxiv.org/abs/2410.10811", "title": "Deep Linear Probe Generators for Weight Space Learning", "title_en": "Deep Linear Probe Generators for Weight Space Learning", "authors": "Jonathan Kahana,Eliahu Horwitz,Imri Shuval,Yedid Hoshen", "background": "权重空间学习旨在提取有关神经网络的信息，例如其训练数据集或泛化误差。最近的方法直接从模型权重中学习，但这是具有挑战性的，因为权重是高维的，并且包含神经元之间的置换对称性。替代方案探查通过将一组学习的输入（探测器）通过模型，并在相应的输出上训练预测器来表示模型。尽管探查通常不被用作独立方法，但初步实验表明，朴素的探测器基线效果出人意料的好。然而，我们发现当前的探针学习策略是无效的。因此，我们提出了Deep Linear Probe Generators (ProbeGen)，这是一种简单的、有效的探针方法改进。ProbeGen加入了一个具有深度线性架构的共享生成器模块，这为探测器提供了结构化的诱导偏见，从而减少了过拟合。虽然简单，但ProbeGen在性能上表现出色，且非常高效，其所需操作次数比其他顶级方法少30到1000倍。", "innovation": "提出了Deep Linear Probe Generators (ProbeGen)，这是一种将深度线性架构应用于探针方法中的简单但有效的改进。ProbeGen通过引入一个具有深度线性架构的共享生成器模块，增强了探针的结构化偏见，这帮助减少了过拟合问题，并且能够在资源和计算效率方面显著超越现有的最先进的方法。", "conclusion": "Deep Linear Probe Generators (ProbeGen) 显著优于目前最先进的方法，并且在计算效率方面表现出色。虽然方法简单，但证明了引入一个深度线性架构的生成器模块对于提高模型泛化能力和提高探针的有效性是有效的。"}
{"llm_update_time": "20251023", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2503.09483", "html_url": "https://arxiv.org/abs/2503.09483", "title": "学习卷积合成正则化中的空间自适应 $\boldsymbol{\boldsymbol{\text{\textasciitilde}1\textasciitilde}}$范数权重", "title_en": "Learning Spatially Adaptive $\\ell_1$-Norms Weights for Convolutional Synthesis Regularization", "authors": "Andreas Kofler,Luca Calatroni,Christoph Kolbitsch,Kostas Papafitsoros", "background": "在低场MRI图像重构中，研究人员寻求改进和优化图像质量的方法。传统的分析型正则化方法（例如基于Total Variation的正则化）和模型驱动的深度学习方法在处理复杂和模糊的低场MRI图像时表现出色，但往往难以解释和优化。本文的背景是在传统方法的基础上提出了一种新型的空间自适应方法，旨在解决这个问题。", "innovation": "本文提出了一种卷积合成基下的 $\boldsymbol{\boldsymbol{\text{\textasciitilde}1\textasciitilde}}$ 正则化学习空间自适应参数图的方法。具体来说，研究人员利用预训练的卷积滤波器族，并通过逐步迭代反向传播过程（即拆分阈值算法的展开）来估算适用于稀疏特征图的空间变化参数。这种方法在低场MRI图像重建中表现出与现有技术相媲美的效果，并且具有高度的可解释性。通过这种方法，研究人员能够确定每个滤波器在重建中的局部贡献，从而揭示算法的工作机制，并有可能剔除不合适滤波器。", "conclusion": "实验结果表明，本文提出的方法在视觉质量和量化指标方面与现有技术相当，并且保持了高度的可解释性。通过这种方法产生的参数图可以量化每个滤波器在重构中的局部贡献，从而为理解算法运作机制提供了宝贵见解，并可能通过剔除不适用的滤波器来进一步优化图像重构过程。"}
{"llm_update_time": "20251023", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.18083", "html_url": "https://arxiv.org/abs/2510.18083", "title": "Chimera: 基于局部概念的组合图像生成", "title_en": "Chimera: Compositional Image Generation using Part-based Concepting", "authors": "Shivam Singh,Yiming Chen,Agneet Chatterjee,Amit Raj,James Hays,Yezhou Yang,Chitta Baral", "background": "个性化图像生成模型在从文本或单张图片合成图片方面非常擅长，但缺乏对来自多张源图片特定部分进行组合以生成新对象的显式控制，无需用户指定的掩码或注释。", "innovation": "我们引入了Chimera，这是一种个性化图像生成模型，可以根据文本指令将指定部分从不同源图片组合生成新的对象。我们构建了一个包含464种独特（部分，主体）配对的语义原子数据集，从中生成了37000个提示并使用高保真度文本到图像模型合成了相应的图像。我们训练了一个分部条件引导的自定义扩散先验模型，通过强制执行语义身份和空间布局来引导图像生成特征。我们还引入了一个名为PartEval的目标评估指标，用于评估生成管道的保真度和构图精度。人类评估和我们提出的指标表明，Chimera在部分对齐和构图准确性方面比其他基线高14%，在视觉质量方面高21%。", "conclusion": "Chimera通过引入基于语义原子数据集和分部条件引导的自定义扩散先验模型，显著提高了图像合成的精确度和质量。"}
{"llm_update_time": "20251023", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2503.14475", "html_url": "https://arxiv.org/abs/2503.14475", "title": "使用粗细级图像频率调制的优化3D高斯点积", "title_en": "Optimized 3D Gaussian Splatting using Coarse-to-Fine Image Frequency Modulation", "authors": "Umar Farooq,Jean-Yves Guillemaut,Adrian Hilton,Marco Volino", "background": "3D高斯点积（3DGS）在新型视角合成领域引发了革命，能够实现实时高质量场景重建。然而，基于3DGS的技术通常需要较高的GPU内存和磁盘空间，限制了其在消费级别设备上的应用。", "innovation": "提出了Opti3DGS，这是一种新颖的频域调制粗细级优化框架，旨在减少用于表示场景的高斯原语数量，从而减少内存和存储需求。Opti3DGS利用图像频域调制，首先强制执行一个粗略的场景表示，并通过逐渐细化训练图像中的频率细节来逐步改进。", "conclusion": "与基线3DGS相比，Opti3DGS展示了平均62%的高斯原语减少，训练GPU内存需求减少40%，优化时间减少20%，同时没有牺牲视觉质量。此外，Opti3DGS方法可以无缝集成到许多3DGS基础上的技术中，同时减少高斯原语的数量，保持甚至提高视觉质量。Opti3DGS还天然地生成了逐细节水平的场景表示，无需额外成本。结果和代码将公开提供。"}
{"llm_update_time": "20251023", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2505.11576", "html_url": "https://arxiv.org/abs/2505.11576", "title": "通过神经分块实现概念导向的可解释性", "title_en": "Concept-Guided Interpretability via Neural Chunking", "authors": "Shuchen Wu,Stephan Alaniz,Shyamgopal Karthik,Peter Dayan,Eric Schulz,Zeynep Akata", "background": "神经网络经常被描述为黑箱，反映了理解它们内部运作和相互作用的巨大挑战。本文提出了一种不同的视角，挑战现有的观点：神经网络的原始群体活动表现出与训练数据中规律相似的模式，这被称为反射假设。本文在简单的循环神经网络（RNN）和复杂的大型语言模型（LLM）中，提供了这一现象的证据。", "innovation": "本文提出利用我们的认知倾向进行分组，将高维神经群体动力学分解为可解释的单元，这些单元反映了潜在概念。提出三种方法在神经群体层面提取反复出现的块，这些方法根据标签可用性和神经数据维度互补。具体包括：离散序列分块（DSC）、群体平均（PA）和无监督块发现（UCD）。这些方法在不同模型架构中对概念编码实体的有效性进行了验证，这些概念可以是具体的（单词）、抽象的（词性标签）或结构性的（叙述框架）。此外，本文还展示了提取的块在网络行为中的因果作用，插入它们导致了模型行为的可控且可预测的变化。", "conclusion": "本文揭示了一种新的可解释性方向，结合了认知原理和自然数据的结构，揭示了复杂学习系统的隐藏计算，从而逐渐将它们从黑箱转化为我们可以开始理解的系统。"}
{"llm_update_time": "20251023", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2505.11883", "html_url": "https://arxiv.org/abs/2505.11883", "title": "MINGLE: 混合空特征空间受控低秩专家用于测试时连续模型合并", "title_en": "MINGLE: Mixture of Null-Space Gated Low-Rank Experts for Test-Time Continual Model Merging", "authors": "Zihuan Qiu,Yi Xu,Chiyuan He,Fanman Meng,Linfeng Xu,Qingbo Wu,Hongliang Li", "background": "连续模型合并（Continual model merging）是一种在不访问原始训练数据的情况下，顺序集成独立微调模型的方法，提供了一个可扩展且高效的连续学习解决方案。然而，现有方法面临两个关键挑战：任务间的参数干扰，导致灾难性遗忘；以及对不断变化的测试分布的有限适应性。", "innovation": "论文提出了一种名为MINGLE的新框架，用于测试时连续模型合并（Test-Time Continual Model Merging, TTCMM）。MINGLE使用参数效率高、低秩专家的混合专家架构，提高对不断变化的测试分布的适应性，同时动态合并模型以缓解参数冲突。此外，它引入Null-Space Constrained Gating机制，限制门控更新到与先前任务表示正交的子空间，从而抑制旧任务的激活并保留过去的知识。进一步，提出了自适应松弛策略来动态调整约束强度，平衡稳定性和适应性。", "conclusion": "在标准连续合并基准上的大量实验表明，MINGLE实现了稳健的一般化，显著减少了遗忘，相比以前最佳方法在不同任务顺序上平均提高了7-9%。"}
{"llm_update_time": "20251023", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2505.18983", "html_url": "https://arxiv.org/abs/2505.18983", "title": "AmorLIP: 效率提升的语言-图像预训练方法通过近似计算", "title_en": "AmorLIP: Efficient Language-Image Pretraining via Amortization", "authors": "Haotian Sun,Yitong Li,Yuchen Zhuang,Niao He,Hanjun Dai,Bo Dai", "background": "CLIP方法在多种文本-图像下游任务中展现了强大的零样本性能。现有方法通常通过在每个小批量中抽取负样本来优化对比损失，并因此需要非常大的批量大小和大量的GPU资源，这对训练效率和性能提出了挑战。此前的解决方案尽管能够减轻部分问题，但常常会牺牲下游任务的性能，延长训练时间，或者无法在大规模数据集上取得良好的扩展性。因此，迫切需要一种能够提高训练效率和性能的预训练方法。", "innovation": "本文提出了AmorLIP框架，通过引入一种基于能量模型频域分解的近似计算方法，减轻了对比学习中的昂贵计算，大幅提升了训练效率和性能，相比传统的CLIP基线，在38个下游任务上的零样本分类和检索能力表现更好，相对提升幅度高达12.24%。", "conclusion": "通过对比损失的近似计算，AmorLIP显著提高了CLIP的训练效率与表现，克服了现有方法在大批次和大规模数据集上的局限性，并在广泛的任务中展示了优越的性能。"}
{"llm_update_time": "20251023", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2503.10632", "html_url": "https://arxiv.org/abs/2503.10632", "title": "Kolmogorov-Arnold Attention: Is Learnable Attention Better For Vision Transformers?", "title_en": "Kolmogorov-Arnold Attention: Is Learnable Attention Better For Vision Transformers?", "authors": "Subhajit Maity,Killian Hitsman,Xin Li,Aritra Dutta", "background": "Kolmogorov-Arnold networks (KANs)能捕捉数据中更复杂的关系，目前常用于替换深度网络中的多层感知机（MLPs），包括先进的架构如视觉变换器（ViTs）。本文研究KAN是否可以学习令牌之间的交互。", "innovation": "本文设计了首个基于Kolmogorov-Arnold网络的可学习注意力（KArAt）机制，可以应用于不同的基底（如傅里叶基、小波基、样条基以及有理函数基），同时提出了一种模块化版本的KArAt，采用了低秩近似以解决记忆爆炸问题。研究发现，在某些情况下，Fourier-KArAt及其变体超过了传统的softmax注意力机制，在CIFAR-10、CIFAR-100和ImageNet-1K上的性能表现相当或更好。", "conclusion": "学习可激活的功能（KArAt）产生了更好的注意力分数，证明了更好的令牌间交互和更优越的推断效率。然而，KArAt的可移植性不能随着ViTs规模的增大而扩展。为了提高学习注意力的有效性和记忆效率，未来的研究需要考虑当前计算界面等多方面因素。虽然本文未旨在创造出高效注意力或挑战传统激活函数，但它证明了注意力机制可以进行学习，鼓励研究人员探索KArAt与更高级架构的结合潜力。"}
{"llm_update_time": "20251023", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2505.23248", "html_url": "https://arxiv.org/abs/2505.23248", "title": "遥感图像超分辨率技术的进步：全面综述", "title_en": "Advancing Image Super-resolution Techniques in Remote Sensing: A Comprehensive Survey", "authors": "Yunliang Qi,Meng Lou,Yimin Liu,Lu Li,Zhen Yang,Wen Nie", "background": "遥感图像超分辨率（RSISR）是遥感图像处理中的一个关键任务，旨在从低分辨率（LR）图像重建高分辨率（HR）图像。尽管近年来提出了许多RSISR方法，但这些方法的系统性和全面性综述仍然不足。该论文对其方法、数据集和评估指标进行了全面综述，提供了对RSISR方法的深入分析，将其分为监督、非监督和质量评估方法，以帮助研究人员了解当前的趋势和挑战。", "innovation": "研究对现有方法的分析揭示了在大型降序条件下保留细粒度纹理和几何结构的重要局限性。基于这些发现，论文指出了未来的研究方向，强调需要特定领域的架构和robust的评估协议，以弥补合成和实际场景下的RSISR差距。", "conclusion": "该论文提供了一篇全面的RSISR方法综述，深入分析了不同类型的算法，并指出了当前方法的主要局限性及未来研究的方向，强调了领域特异性架构和robust评估协议的重要性。"}
{"llm_update_time": "20251023", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2505.20755", "html_url": "https://arxiv.org/abs/2505.20755", "title": "Uni-Instruct: 通过统一扩散散度指令的一步扩散模型", "title_en": "Uni-Instruct: One-step Diffusion Model through Unified Diffusion Divergence Instruction", "authors": "Yifei Wang,Weimin Bai,Colin Zhang,Debing Zhang,Weijian Luo,He Sun", "background": "本文统合了超过10种现有的一步扩散蒸馏方法，如Diff-Instruct、DMD、SIM、SiD、$f$-distill等，形成了一个理论驱动的框架，我们称之为Uni-Instruct。这些方法基于我们提出的$f$-散度家族的扩散扩展理论，并引入了克服原始扩展$f$-散度不可解性的关键理论，形成了一个等效且可处理的损失，从而有效训练一步扩散模型。", "innovation": "Uni-Instruct的创新之处在于通过对一一步扩散蒸馏方法进行了新的理论统合，不仅提供了理解现有方法的新视角，而且还实现了最先进的一步扩散生成性能。在CIFAR10生成基准中，Uni-Instruct达到了无条件生成的Frechet Inception Distance (FID)值为1.46，有条件生成的FID值为1.38。在ImageNet-$64 \times 64$生成基准中，Uni-Instruct达到了新的最先进的SOTA生成FID值为1.02，这比其79步教师扩散模型有显著的改进，差距为1.33（1.02 vs 2.35）。", "conclusion": "Uni-Instruct的强健理论和实验贡献可能会对一步扩散蒸馏和扩散模型知识转移的研究产生潜在帮助，提升了现有方法在文本到3D生成任务中的表现。"}
{"llm_update_time": "20251023", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2506.13579", "html_url": "https://arxiv.org/abs/2506.13579", "title": "离散扩散模型中的可变长度文本填充", "title_en": "Flexible-length Text Infilling for Discrete Diffusion Models", "authors": "Andrew Zhang,Anushka Sivakumar,Chiawei Tang,Chris Thomas", "background": "离散扩散模型是一种新型的文本生成器，相比自回归模型，它们具备双向上下文使用、并行生成和灵活提示的优点。然而，离散扩散模型的一个关键限制是缺乏在不使用真实位置数据的情况下进行灵活长度或灵活位置的文本填充的能力。", "innovation": "本文提出了DDOT（离散扩散与最优传输位置耦合），这是一种新的离散扩散模型，首次解决了这一限制问题。DDOT通过联合去噪标记值和标记位置，采用了一种新颖的样本层面最优传输（OT）耦合，从而保留了标记的相对顺序，并动态调整填充片段的位置和长度，这是之前文本扩散中缺少的能力。该方法与现有的离散文本扩散方法独立，并且兼容各种预训练文本去噪器。", "conclusion": "广泛的实验结果显示，DDOT在文本填充基准测试（如One-Billion-Word和Yelp）上优于简单的扩散基线。此外，DDOT的性能与最先进的非自回归模型相当，并能显著提高训练效率和灵活性。"}
{"llm_update_time": "20251023", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2506.00711", "html_url": "https://arxiv.org/abs/2506.00711", "title": "QoQ-Med: 使用领域意识相对策略优化训练构建多模态临床基础模型", "title_en": "QoQ-Med: Building Multimodal Clinical Foundation Models with Domain-Aware GRPO Training", "authors": "Wei Dai,Peilin Chen,Chanakya Ekbote,Paul Pu Liang", "background": "临床决策需要处理异质性数据，现有的多模态语言模型（MLLMs）主要集中在视觉数据上，并不能很好地跨临床专科领域泛化。现有的模型在处理不同临床域和模态难度的数据时表现不平衡，这限制了其在医疗决策支持中的应用。因此，急需一种能够综合医疗影像、时间序列信号和文本报告等信息的通用型临床基础模型，以提高多模态医疗数据处理能力，促进临床决策的智能化。", "innovation": "QoQ-Med 是首个能够在医疗图像、时间序列信号和文本报告之间共同推理的开放通用型临床基础模型。该模型通过领域意识相对策略优化（Domain-aware Relative Policy Optimization, DRPO）训练，该方法根据领域稀有性和模态难度逐级放大归一化奖励，解决了临床数据分布不均导致的性能失衡问题。DRPO测试结果显示，与无评价者的训练方法（如GRPO）相比，QoQ-Med 在视觉领域的宏观 F1 得分平均提高了 43%。此外，QoQ-Med 还能够高亮显示与诊断相关的显著区域，展示了其在专业性和性能上的优势，同时不超过类似模型。", "conclusion": "QoQ-Med 为构建多模态临床基础模型提供了一个新的框架，通过领域意识相对策略优化（DRPO）训练提高了模型在不同临床领域中的表现，并利用其开放性、可模块化训练管线和中间推理轨迹为后续研究提供支持。"}
{"llm_update_time": "20251023", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2506.22304", "html_url": "https://arxiv.org/abs/2506.22304", "title": "使用科伊曼算子展开生成流：快速且可解释的采样", "title_en": "Unfolding Generative Flows with Koopman Operators: Fast and Interpretable Sampling", "authors": "Erkan Turan,Aristotelis Siozopoulos,Louis Martinez,Julien Gaubil,Emery Pierson,Maks Ovsjanikov", "background": "连续正则化流（CNFs）能够提供优雅的生成建模，但其采样速度较慢，生成单个样本需要解开数百次函数评估的非线性常微分方程。尽管最近的方法如Rectified Flow和OT-CFM通过直线化轨迹来加速采样，但这些模型的动态仍然保持为非线性黑盒模型，限制了效率和可解释性。", "innovation": "通过使用科伊曼理论，全局线性化解流动力，将条件流匹配（CFM）提升到更高的科伊曼空间，表示其演化为单一的线性算子。这带来了两个关键好处：第一，采样成为一步并行计算，通过矩阵指数函数以闭式形式实现；第二，科伊曼算子提供了生成的光谱蓝图，通过其特征值和模态提供新颖的可解释性。我们为科伊曼算子训练了一种实用的、无需模拟的目标，确保与教师动力特征的无穷小一致性，并证明该对齐能够沿整个生成路径保持保真度。", "conclusion": "我们的方法在保持可生成性质量的同时实现了显著加速，并唯一地支持生成流的光谱分析。"}
{"llm_update_time": "20251023", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.09024", "html_url": "https://arxiv.org/abs/2507.09024", "title": "CNeuroMod-THINGS, 一个用于视觉神经科学的密集采样fMRI数据集", "title_en": "CNeuroMod-THINGS, a densely-sampled fMRI dataset for visual neuroscience", "authors": "Marie St-Laurent,Basile Pinsard,Oliver Contier,Elizabeth DuPre,Katja Seeliger,Valentina Borghesani,Julie A. Boyle,Lune Bellec,Martin N. Hebart", "background": "数据驱动的神经AI建模需要越来越大的神经成像数据集。CNeuroMod-THINGS通过使用详细描述的图像集采集新的密集采样、大规模fMRI数据集，来捕捉广泛语义概念的神经表示，以满足这一需求。该项目结合了THINGS倡议和Courtois神经建模项目的资源。", "innovation": "CNeuroMod-THINGS项目通过整合两个现有的项目（THINGS和Courtois神经建模项目），创建了一个新的密集采样大规模fMRI数据集，该数据集中包含用于视觉神经科学研究的详细描述的图像集，从而扩展了对人类视觉经验建模的能力。", "conclusion": "该研究通过利用现有资源的协同作用，证明了CNeuroMod-THINGS数据集的质量，并强调了其在建模人类视觉经验方面的价值。"}
{"llm_update_time": "20251023", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.16814", "html_url": "https://arxiv.org/abs/2507.16814", "title": "半离策强化学习在视觉语言慢思考推理中的应用", "title_en": "Semi-off-Policy Reinforcement Learning for Vision-Language Slow-Thinking Reasoning", "authors": "Junhao Shen,Haiteng Zhao,Yuzhe Gu,Songyang Gao,Kuikun Liu,Haian Huang,Jianfei Gao,Dahua Lin,Wenwei Zhang,Kai Chen", "background": "大型视觉语言模型（LVLMs）在解决复杂的多模态任务中需要增强视觉慢思考推理能力。但由于LVLMs主要通过视觉语言对齐进行训练，使用在策略强化学习（RL）开发慢思考能力受到初始能力限制，而脱离策略RL可以提供超越当前策略的方法，但直接从外部模型提取轨迹可能导致视觉错觉。", "innovation": "提出了SOPHIA，一种半脱离策略RL方法，结合可训练的LVLM的在策略视觉理解与语言模型的脱离策略推理，通过基于结果的奖励进行推理，并将视觉奖励反向传播，使LVLM能够通过脱离策略RL算法从获得的推理轨迹中学习慢思考推理能力。实验表明，SOPHIA在多个多模态推理基准测试中提升了开源LVLMs的性能，特别是在MathVision和OlympiadBench中，SOPHIA超越了某些封闭源代码模型（如GPT-4.1），分别达到49.08%和49.95%的pass@1准确率。", "conclusion": "SOPHIA在多个模态推理基准测试中表现出优越性，相较于监督微调和直接在策略RL方法提供了更好的策略初始化，为后续的在策略训练提供了更好的起点。"}
{"llm_update_time": "20251023", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.02600", "html_url": "https://arxiv.org/abs/2509.02600", "title": "Team Westwood Solution for MIDOG 2025 Challenge: An Ensemble-CNN-Based Approach For Mitosis Detection And Classification", "title_en": "Team Westwood Solution for MIDOG 2025 Challenge: An Ensemble-CNN-Based Approach For Mitosis Detection And Classification", "authors": "Tengyou Xu,Haochen Yang,Xiang 'Anthony' Chen,Hongyan Gu,Mohammad Haeri", "background": "本研究背景是对MItosis Domain Generalization (MIDOG) 2025挑战中的细胞分裂检测和异常细胞分裂分类问题的解决。研究背景涉及在大量医疗图像上检测和分类异常细胞分裂的重要性，这对于医学诊断和治疗具有重要价值。", "innovation": "研究创新点包括使用nnUNetV2进行细胞分裂候选筛查，并采用随机森林分类器结合三种卷积神经网络（EfficientNet-b3、EfficientNet-b5、EfficientNetV2-s）的预测结果进行细胞分裂检测。对于异常细胞分裂分类，采用了随机森林分类器结合EfficientNet-b3、EfficientNet-b5和InceptionV3三种卷积神经网络的预测结果。这表明了多模型集成在医疗图像处理中的有效性。", "conclusion": "根据初步和最终测试集的结果，研究提出的方案在细胞分裂检测和异常细胞分裂分类方面表现良好。具体来说，在初步测试集上的结果是：细胞分裂检测的F1分数为0.7450，异常细胞分裂分类的平衡准确率为0.8722；在最终测试集上的结果是：细胞分裂检测的F1分数为0.6972，异常细胞分裂分类的平衡准确率为0.8242。"}
{"llm_update_time": "20251023", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.25271", "html_url": "https://arxiv.org/abs/2509.25271", "title": "RADAR: 一种基于角色专业化合作的风险感知动态多代理框架，用于大规模语言模型安全性评估", "title_en": "RADAR: A Risk-Aware Dynamic Multi-Agent Framework for LLM Safety Evaluation via Role-Specialized Collaboration", "authors": "Xiuyuan Chen,Jian Zhao,Yuchen Yuan,Tianle Zhang,Huilin Zhou,Zheng Zhu,Ping Hu,Linghe Kong,Chi Zhang,Weiran Huang,Xuelong Li", "background": "现有的大规模语言模型（LLMs）的安全性评估方法存在固有限制，包括评估者偏见和由于模型同质性导致的检测失败，这共同削弱了风险评估过程的稳健性。", "innovation": "引入了一种理论框架，重构了潜在的风险概念空间，并将该空间分解为三个互斥子空间：显式风险子空间（涵盖直接违反安全准则的部分）、隐含风险子空间（捕捉需要上下文推理才能识别的潜在恶意内容）和非风险子空间。此外，提出了一种名为RADAR的多代理协作评估框架，该框架通过四种专门的互补角色利用多轮辩论机制，并采用动态更新机制以实现风险概念分布的自我进化，从而实现对显式和隐含风险的全面覆盖，并减轻评估者偏见。", "conclusion": "全面实验表明，RADAR在多个维度上显著优于基线评估方法，包括准确性、稳定性和自我评估风险敏感性。特别地，与最强的基线评估方法相比，RADAR在风险识别准确性方面的改进达到了28.87%。"}
{"llm_update_time": "20251023", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.18404", "html_url": "https://arxiv.org/abs/2508.18404", "title": "视运动交叉避免作为视觉搜索策略", "title_en": "Saccade crossing avoidance as a visual search strategy", "authors": "Alex Szorkovszky,Rujeena Mathema,Pedro Lencastre,Pedro Lind,Anis Yazidi", "background": "视觉搜索似乎随机进行，但存在一些眼动偏倚，这些偏倚使得注视方向和距离的概率依赖于之前的扫描路径。长路径历史的影响较难量化。研究使用生态学中的步长选择框架分析45秒内的“在哪里，沃尔多？”观看数据，发现了一种新的依赖记忆的效果，称为自我交叉避免。这个效应在个体间也有显著差异，并且主要是当两个点的幅度都较小时，眼动倾向于避免这些早期的扫描路径。", "innovation": "研究发现了一种新的适用于扫描路径的记忆依赖效应，即自我交叉避免。这种效应通过将实际数据与记忆无约化的合成数据（马尔可夫非参数模型）进行比较得到验证。同时，研究还通过最大似然法表明，这种效应最强存在时是在扫描路径的最后大约7秒内。此外，引入了一个包含自我交叉惩罚项的参数概率模型，可以重建眼动长度和自我交叉的联合统计数据。研究还使用混合效应回归量化了个体的战略差异及其在每个参与者六幅图像中的一致性。", "conclusion": "整体而言，避免交叉是一个局部定向策略，它与返回抑制一起促进了对视觉场景的探索。并且，倾向于避免交叉的参与者的眼动长度更短，持续时间更短，但没有显示出更多水平、垂直、前方或反向眼动。"}
{"llm_update_time": "20251023", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.11354", "html_url": "https://arxiv.org/abs/2509.11354", "title": "低成本明场显微镜图像分割智能软件系统：基于算法的细胞自动分析实现", "title_en": "Intelligent Software System for Low-Cost, Brightfield Segmentation: Algorithmic Implementation for Cytometric Auto-Analysis", "authors": "Surajit Das,Pavel Zun", "background": "对于预算有限的实验室，传统光学显微镜（明场显微镜）和标准CPU通常是唯一可用的资源。然而，明场图像的噪声、对比度低以及动态形态特征使得通过传统计算方法进行图像分析变得困难。这些问题，再加上缺乏GPU资源和复杂的软件界面，限制了研究产出。", "innovation": "本文提出了一种专为标准CPU桌面计算机配备的低预算实验室设计的显微镜图像分析框架。该框架基于Python，能够通过高级计算机视觉和机器学习流水线对活的未染色细胞进行细胞学分析，无需手动标注的训练数据或训练阶段。此外，它提供了用户友好的跨平台图形用户界面和脚本接口，方便开发人员进行程序控制和集成。该框架在端到端的工作流程中实现了语义和实例分割、特征提取、分析、评估和自动报告生成等功能。其模块化架构支持易于维护和灵活的集成，支持单张图像和批量处理。", "conclusion": "该框架在公共数据集livecells中对几种未染色的细胞类型进行验证，结果展示了在与当代工具Cellpose和StarDist相当的准确性与可重复性方面具有优势。基于CPU的平台下其竞争性的分割速度表明其在基础研究和临床应用中的巨大潜力，特别是在个性化医疗和肌肉再生疗法中的细胞移植研究中。该应用已开放以便于重复研究结果。"}
{"llm_update_time": "20251023", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.00058", "html_url": "https://arxiv.org/abs/2510.00058", "title": "基于N-gram上下文的Swin变换器变率图像压缩", "title_en": "Variable Rate Image Compression via N-Gram Context based Swin-transformer", "authors": "Priyanka Mudgal", "background": "该论文提出了一种基于N-gram上下文的Swin Transformer用于学习图像压缩。背景在于传统Swin Transformer在高分辨率图像重建时忽视了较大的区域，在高分辨率重建中的质量不高。该方法通过引入N-gram上下文克服了这一限制，从而在保持单个模型的情况下实现了变率压缩，改进了高分辨率重建的质量，特别是在图像关注区域（ROI）的优化方面取得了显著进步，特别适用于制造和工业视觉系统等面向对象的应用场景。", "innovation": "论文的创新点在于提出了一种结合N-gram上下文的Swin Transformer，能够克服原有Swin Transformer在高分辨率图像重建中对大区域忽视的问题。通过这种方式，扩大了参与像素恢复的区域范围，提升了高分辨率重建的质量，相比于现有的变率学习图像压缩技术，BD-Rate提高了-5.86%，并且特别提升了图像中的关注区域的质量，这对于物体导向的应用尤其有利，如制造和工业视觉系统等场景。", "conclusion": "该研究提出的方法通过引入N-gram上下文显著提高了Swin Transformer在图像压缩中的性能，特别是在高分辨率图像重建和关注区域质量提升方面，该方法展示了与现有技术相比的优越性能。"}
{"llm_update_time": "20251023", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.21789", "html_url": "https://arxiv.org/abs/2509.21789", "title": "视觉多智能体系统: 通过视觉流减轻幻觉雪崩", "title_en": "Visual Multi-Agent System: Mitigating Hallucination Snowballing via Visual Flow", "authors": "Xinlei Yu,Chengming Xu,Guibin Zhang,Yongbo He,Zhangquan Chen,Zhucun Xue,Jiangning Zhang,Yue Liao,Xiaobin Hu,Yu-Gang Jiang,Shuicheng Yan", "background": "多智能体系统（MAS）借助视觉语言模型（VLMs）能够完成复杂的任务，但同时也面临着一种新型的失败现象——多智能体视觉幻觉雪崩。这种现象中，幻觉由单一智能体传播至后续智能体，并由于过度依赖文本信息来传递视觉信息而被放大。通过对轮次、层和令牌级别的注意力分析，作者揭示了幻觉雪崩的本质在于视觉注意力分配的减少，并识别出一类在中间层具有单模态注意力峰值的视觉令牌，这在深度智能体轮次中逐渐减弱，从而导致MAS中的视觉幻觉雪崩。针对这一问题，提出了一种轻量级的ViF缓解方案，该方案使用选中的视觉传输令牌并通过视觉流传递跨智能体的消息，并重新分配注意力以放大这一模式。实验结果显示，该方法显著减少了幻觉雪崩，提高了八大基准（基于四种常见MAS结构和十种基础模型）的性能表现。", "innovation": "提出了一种轻量级的缓解幻觉雪崩的方法——ViF（Visual Flow）。该方法通过使用选中的视觉传递令牌和视觉流来跨智能体传递消息，并重新分配注意力以放大该模式。利用ViF，能够显著减少幻觉雪崩现象，且在多个基准测试中取得了稳定提升。该方法简单易行且可快速部署，适用于多种多智能体系统构造和基础模型。此外，该研究还通过详细的注意力分析揭示了幻觉雪崩的本质原因。", "conclusion": "通过动态调整注意力分配并利用视觉流，提出的方法显著改善了多智能体系统的性能，减少了由文本传递视觉信息导致的多智能体视觉幻觉雪崩现象。该研究为多智能体系统的改进提供了新的视角和方案。"}
{"llm_update_time": "20251023", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.09660", "html_url": "https://arxiv.org/abs/2510.09660", "title": "学习重点：通过谱各向异性前向噪声引导扩散", "title_en": "Learning What Matters: Steering Diffusion via Spectrally Anisotropic Forward Noise", "authors": "Luca Scimeca,Thomas Jiralerspong,Berton Earnshaw,Jason Hartford,Yoshua Bengio", "background": "扩散概率模型（DPMs）在生成性能方面表现强大，但其归纳偏置仍主要是隐性的。本文作者的目标是将归纳偏置嵌入扩散模型的训练和采样过程中，以便更好地适应数据的目标分布。", "innovation": "作者引入了一个异向性噪声操作符，通过替换等向性前向协方差为一个结构化的、频率对角线协方差来引导这些偏置，这统一了带通掩模和幂律权重，允许强调或抑制特定频率带，同时保持前向过程的高斯性。这被称作谱各向异性高斯扩散（SAGD）。作者推导了异向性协方差的关系，并证明在完全支持的情况下，学习到的评分在时间趋近于0时收敛于真实数据评分，同时异向性重塑了从噪声到数据的概率流路径。", "conclusion": "实验结果表明，诱导的异向性在多个视觉数据集上优于标准扩散，使学习能够选择性地忽略特定带内的已知损坏。总体而言，这些结果表明，精心设计的异向性前向噪声提供了一个简单而合理的工具来在DPM中定制归纳偏置。"}
{"llm_update_time": "20251023", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.18905", "html_url": "https://arxiv.org/abs/2510.18905", "title": "3D优化用于AI推理扩展：平衡准确度、成本和延迟", "title_en": "3D Optimization for AI Inference Scaling: Balancing Accuracy, Cost, and Latency", "authors": "Minseok Jung,Abhas Ricky,Muhammad Rameez Chatni", "background": "AI推理扩展通常通过一维启发式方法（固定推理轮次）或二维双变量权衡（例如，性能与计算资源之间的权衡）来调整，这些方法忽视了成本和延迟限制。这些限制往往影响了AI模型的运行效率。", "innovation": "引入了一个三维优化框架，该框架在统一的决策空间中同时校准准确度、成本和延迟，从而在考虑约束条件下实现推理扩展。通过蒙特卡洛模拟三个典型场景以及九个模拟的大语言模型，评估了四种优化方法来解决三维多目标优化问题。", "conclusion": "膝盖点优化在平衡准确度、成本和延迟方面达到了最佳效果，而在以精度为优先考虑时，最大化准确度仍然是最有利的。该框架为在不同运行环境中进行部署意识下的推理扩展提供了理论基础。"}
{"llm_update_time": "20251023", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.15530", "html_url": "https://arxiv.org/abs/2510.15530", "title": "VO-DP: 仅视觉语义-几何自适应扩散策略在仅视觉机器人操作中的应用", "title_en": "VO-DP: Semantic-Geometric Adaptive Diffusion Policy for Vision-Only Robotic Manipulation", "authors": "Zehao Ni,Yonghao He,Lingfeng Qian,Jilei Mao,Fa Fu,Wei Sui,Hu Su,Junran Peng,Zhipeng Wang,Bin He", "background": "在模仿学习的背景下，基于视觉运动的扩散策略学习是机器人操作的主要方向之一。多数现有方法依赖于点云的观察输入并通过点云特征学习构建场景表示，这使得它们能够实现显著的准确性。然而，现有的文献对仅视觉解决方案的深入探索不足，这些解决方案具有很大的潜力。本文旨在填补这一空白。", "innovation": "本文提出了一种基于预训练视觉基础模型的仅视觉单视角扩散策略学习方法（VO-DP），通过融合语义和几何特征实现有效的融合。该方法利用VGGT的中间特征，结合DINOv2的语义特征和交替注意模块的几何特征，通过交叉注意力和卷积神经网络压缩空间，作为策略头部的输入。实验结果表明，VO-DP不仅在视觉基线DP上表现显著优于，而且表现出与基于点云的DP3方法不同的性能趋势。在仿真任务中，VO-DP的平均成功率达到了64.6%，与DP3的64.0%相当，并远远超过了DP的34.8%；在现实任务中，它达到了87.9%的成功率，明显优于DP3的67.5%和DP的11.2%。进一步的稳健性评估证实，VO-DP在条件变化（包括颜色、尺寸、背景和照明）下仍保持着高度的稳定性。此外，还开源了一个基于加速器的机器人操作训练库，支持多节点和多GPU并行训练以及混合精度训练，兼容视觉运动策略DP、DP3和VO-DP，并支持RoboTwin模拟器。", "conclusion": "本文提出了一种新的仅视觉单视角扩散策略学习方法VO-DP，通过有效融合语义和几何特征，显著提高了机器人操作的成功率和在不同条件下的稳定性。该方法还开源了一个训练库，支持并在多种场景下展示了其优越性。"}
{"llm_update_time": "20251023", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.18193", "html_url": "https://arxiv.org/abs/2510.18193", "title": "FST.ai 2.0: An Explainable AI Ecosystem for Fair, Fast, and Inclusive Decision-Making in Olympic and Paralympic Taekwondo", "title_en": "FST.ai 2.0: An Explainable AI Ecosystem for Fair, Fast, and Inclusive Decision-Making in Olympic and Paralympic Taekwondo", "authors": "Keivan Shariatmadar,Ahmad Osman,Ramin Ray,Kisam Kim", "background": "在奥林匹克和残奥会搏击项目中，公平、透明和可解释的决策仍然面临重大挑战。该论文旨在解决这一问题，介绍了FST.ai 2.0，一个可解释的人工智能生态系统，旨在支持跆拳道比赛和训练期间的裁判、教练和运动员的实时决策支持。该系统在世界跆拳道生态系统中整合了基于姿态的动作识别、认识论不确定性的建模以及可视化的可解释性覆盖，以增强决策支持。此外，还提供了一系列交互式仪表板，支持人工智能与人类的协作决策。系统除了自动评分外，还提供了裁判培训、公平性监控和政策级分析的模块。实验验证证明，该系统在决策审核时间和裁判对AI辅助决策的信任度方面均有显著改进，为可信的、数据驱动的执裁和运动员评估提供了透明和可扩展的管道。", "innovation": "该系统创新性地结合了基于姿态的动作识别、认识论不确定性的建模和可视化的可解释性覆盖，通过交互式仪表板实现了人工智能与人类的协作决策。同时，系统还提供了一个模块化的框架，可支持裁判培训、公平性监控和政策级分析，进一步增强了系统的实用性和扩展性。通过在实际比赛数据上的实验验证，FST.ai 2.0 显著降低了决策时间并提高了裁判对AI决策的信任度。", "conclusion": "FST.ai 2.0 通过整合实时感知、可解释推理和治理意识设计，代表了体育中公平、问责和人类导向的人工智能的一步进展，建立了透明且可扩展的数据驱动执裁和运动员评估管道。"}
{"llm_update_time": "20251023", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.18925", "html_url": "https://arxiv.org/abs/2510.18925", "title": "在预测动力系统中的时空多尺度表示中应用降阶模型", "title_en": "Application of Reduced-Order Models for Temporal Multiscale Representations in the Prediction of Dynamical Systems", "authors": "Elias Al Ghazal,Jad Mounayer,Beatriz Moya,Sebastian Rodriguez,Chady Ghnatios,Francisco Chinesta", "background": "复杂多尺度系统的非线性和对初始条件的高度敏感性，以及传统机器学习方法对高频行为捕捉不足，导致了其动力学建模和预测的挑战性。这些问题限制了现有方法在处理真实世界复杂多尺度现象时的有效性。", "innovation": "本文提出了一种多尺度学习的三种方法：利用统一划分方法结合神经网络来分解动力学并直接预测宏观和微观行为；使用奇异值分解提取主导模式以明确分离宏观和微观动力学；在样本有限的情况下，采用稀疏高阶奇异值分解从有限测量中重建多尺度动力学。这些方法确保了粗略和精细动态的有效捕获，使得框架适用于复杂的多尺度现象以及具有不完整观测的数据维度更高的系统，提供了现象在所有时间尺度上的近似和解释。", "conclusion": "综合这三种提出的方法，框架能准确捕捉多尺度现象的粗略和精细动态，适用于复杂的多尺度现象，并能适应更高维度的系统，具备在所有时间尺度上提供近似和解释的能力。"}
{"llm_update_time": "20251023", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.18924", "html_url": "https://arxiv.org/abs/2510.18924", "title": " Noise-corrected GRPO: 从噪声奖励到无偏梯度", "title_en": "Noise-corrected GRPO: From Noisy Rewards to Unbiased Gradients", "authors": "Omar El mansouri,Mohamed El Amine Seddik,Salem Lahlou", "background": "目前的强化学习模型（如LLMs）和现代SOTA推理模型通常采用强化学习从人类反馈（RLHF）或验证奖励（RLVR）的标准方法进行对齐。但此类方法对来自不一致或错误奖励的噪声非常敏感，而且这类噪声与广泛应用的基于群体的政策优化方法之间的交互尚未得到充分探索。", "innovation": "本文提出了一种 Noise-robust Group Relative Policy Optimization (GRPO) 和 Done Right GRPO 的噪声鲁棒框架，该框架显式地将奖励篡改建模为伯努利噪声。方法在估计奖励反转概率后进行噪声修正，以校正学习信号，从而获得证明上无偏的梯度估计。实验结果显示，在应用噪声修正到标准奖励模型时，本方法在数学和代码任务中均表现出一致改进，准确度分别提高了6.7个和1.5个百分点。这一工作将监督学习中的标签噪声修正方法与现代RLHF相结合，提供了理论上和实践上的洞见与算法，适用于实际部署中的噪声环境。", "conclusion": "本工作通过Noise-robust GRPO 和 Done Right GRPO 框架，将监督学习中的标签噪声修正方法应用于现代RLHF中，获得了有理论依据和实际意义的改进效果，使得奖励模型在面临噪声条件时仍能提供无偏的梯度估计，适用于更现实的部署场景。"}
{"llm_update_time": "20251023", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.18921", "html_url": "https://arxiv.org/abs/2510.18921", "title": "在Apple Silicon上使用MLX进行设备上机器学习基准测试", "title_en": "Benchmarking On-Device Machine Learning on Apple Silicon with MLX", "authors": "Oluwaseun A. Ajayi,Ogundepo Odunayo", "background": "近年来，大型语言模型（LLMs）和机器学习的广泛应用激发了研究人员探索将这些模型部署到诸如笔记本电脑和移动电话等较小设备上的可能性。这需要能够利用设备硬件的框架和方法，为此，MLX框架应运而生。MLX是一个针对Apple硅设备优化的机器学习计算框架，简化了在这些设备上的研究、实验和原型设计过程。本文对MLX进行了性能评估，重点在于变换器模型的推理延迟。我们比较了MLX中不同变换器架构实现与它们的Pytorch实现之间的性能差异，创建了一个名为MLX-transformers的框架，其中包含不同变换器在MLX中的实现，并下载了Pytorch模型的检查点并转换为MLX格式，从而能无缝执行直接来自Hugging Face的变换器模型，省去了不同框架之间转换模型时通常需要的检查点转换步骤。研究中对比了两个Apple Silicon Macbook设备和NVIDIA CUDA GPU上不同模型的推理延迟性能，评估了BERT、RoBERTa和XLM-RoBERTa模型的性能，旨在未来的工作中扩展到包括不同模态的模型，从而提供更全面的MLX能力评估。", "innovation": "MLX框架是针对Apple硅设备优化的机器学习计算框架，简化了在这些设备上的研究、实验和原型设计过程。通过利用Apple硅的高级架构和功能，MLX-Transformers能够无缝执行直接来自Hugging Face的变换器模型，省去了不同框架之间转换模型时通常需要的检查点转换步骤。", "conclusion": "研究结果展示了MLX在Apple生态系统中实现高效且更具访问性的设备上机器学习应用方面具有潜力。"}
{"llm_update_time": "20251023", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.18927", "html_url": "https://arxiv.org/abs/2510.18927", "title": "BAPO: 利用平衡策略优化与自适应剪裁稳定大规模语言模型的离策 reinforcement学习", "title_en": "BAPO: Stabilizing Off-Policy Reinforcement Learning for LLMs via Balanced Policy Optimization with Adaptive Clipping", "authors": "Zhiheng Xi,Xin Guo,Yang Nan,Enyu Zhou,Junrui Shen,Wenxiang Chen,Jiaqi Liu,Jixuan Huang,Zhihao Zhang,Honglin Guo,Xun Deng,Zhikai Lei,Miao Zheng,Guoteng Wang,Shuo Zhang,Peng Sun,Rui Zheng,Hang Yan,Tao Gui,Qi Zhang,Xuanjing Huang", "background": "近年来，强化学习（RL）已成为使大规模语言模型（LLMs）对齐和增强的核心范式。然而，在off-policy场景下应用RL（使用过去策略的过时数据进行训练）可以提高样本效率，但仍然面临挑战：政策熵迅速下降，优化往往是不稳定的，甚至会崩溃。", "innovation": "通过理论和实证分析，本文识别出了两个关键洞察：（i）优化不平衡，其中负优势样本主导策略梯度，抑制有用行为并可能导致梯度爆炸；（ii）所提出的Entropy-Clip规则揭示了PPN-like目标中的固定剪裁机制系统地阻止了熵增加的更新，从而促使策略过度开发而牺牲探索。基于这些洞察，本文提出了一种平衡策略优化与自适应剪裁（BAPO）方法，该方法动态调整剪裁界限以适应性地重新平衡正负贡献，保留熵，并稳定RL优化。BAPO在不同off-policy场景中实现快速、稳定且数据高效的训练。", "conclusion": "在AIME 2024和AIME 2025基准测试中，7B规模的BAPO模型优于开源对手，如SkyWork-OR1-7B；而32B规模的BAPO模型不仅在同规模模型中达到最先进的水平，还优于先进的专有系统如o3-mini和Gemini-2.5-Flash-Thinking。"}
{"llm_update_time": "20251023", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.18913", "html_url": "https://arxiv.org/abs/2510.18913", "title": "ADPO：锚定直接偏好优化", "title_en": "ADPO: Anchored Direct Preference Optimization", "authors": "Wang Zixian", "background": "ADPO 是一个统一框架，扩展了具有软偏好、参考策略锚定和群体扩展的直接偏好优化 (DPO)。DPO 通常假设硬的二元标签和成对比较，而 ADPO 引入了软偏好概率、任意参考策略锚定和单份偏好建模，从而增强了训练的稳定性和效果。ADPO 通过软偏好概率缓解梯度漂移，通过参考策略锚定实现组内平移不变性和隐式 KL 正则化，以及通过 Plackett-Luce 分布进行单份偏好建模。该研究证明了 DPO、Bradley-Terry 目标函数和 Top-1-vs-Rest 形式可以作为 ADPO 的特殊情况。研究表明，在上下文臂竞猜中，ADPO 在 WinMass 上有38-63%的提高；在顺序强化学习中，如 CartPole 和 LunarLander，ADPO 对于噪声偏好的改进达到了15-29%；并在重度噪声污染环境下，KDE 基于的单份偏好平滑方法取得了显著提升。这些实验结果为参数模型设计提供了明确的指导：在清洁或中度噪声环境下使用成对锚定的 Soft-DPO，在重度噪声环境下使用 KDE 基于的单份偏好 ADPO。", "innovation": "ADPO 引入了软偏好概率、任意参考策略锚定和单份偏好建模。这些特性有助于减少梯度漂移，稳定训练过程，并通过 Plackett-Luce 分布进行单份偏好建模，从而提高了在噪声数据下的性能。ADPO 还提供了三个实用变种：成对锚定的 Soft-DPO、单份偏好模型（带有原始奖励）以及基于 KDE 的单份偏好平滑，分别适应不同噪声场景。ADPO 在不同环境下的应用和性能改进表明了其在实际问题中的有效性与灵活性。", "conclusion": "ADPO 提供了一个增强的框架，通过软偏好概率、参考策略锚定和单份偏好模型提高了直接偏好优化的训练稳定性和泛化能力。实验结果证明 ADPO 在处理不同类型的噪声数据时具有更好的表现，并为设计适用于各种挑战性问题的策略提供了指导。"}
{"llm_update_time": "20251023", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.18940", "html_url": "https://arxiv.org/abs/2510.18940", "title": "NeuroAda：激活每个神经元的潜力以实现参数高效微调", "title_en": "NeuroAda: Activating Each Neuron's Potential for Parameter-Efficient Fine-Tuning", "authors": "Zhi Zhang,Yixian Shen,Congfeng Cao,Ekaterina Shutova", "background": "现有的参数高效微调（PEFT）方法主要分为两类：加法型和选择性就地适应。加法型方法，如LoRA，通过引入额外模块来使模型适应下游任务，具有很强的记忆效率。然而，它们的表示能力通常有限，不太适合进行精细的适应。相比之下，选择性适应方法直接精细调整原始模型参数的一部分，允许更精确和有效的调整，但代价是显着增加内存消耗。为了平衡这一权衡，本文提出了一种名为NeuroAda的新PEFT方法，能够在保持高记忆效率的同时实现精细的模型微调。", "innovation": "NeuroAda通过首先识别重要参数（即网络内的连接）并在这些选定参数上引入绕路连接，同时在微调期间只更新绕路连接，从而保留原始模型参数不变，实现了精细的模型微调，并保持了高内存效率。", "conclusion": "实验结果表明，NeuroAda在23多个涉及自然语言生成和理解的任务上实现了最先进的性能，只需可训练参数的极小比例（≤0.02%），同时减少了高达60%的CUDA内存使用量。作者已将代码发布在指定的GitHub链接中。"}
{"llm_update_time": "20251023", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.18934", "html_url": "https://arxiv.org/abs/2510.18934", "title": "许多深度学习的泛化度量都是脆弱的", "title_en": "Position: Many generalization measures for deep learning are fragile", "authors": "Shuofeng Zhang,Ard Louis", "background": "已经应用了多种泛化度量到深神经网络（DNNs）上，尽管获得精确的边界仍然具有挑战性，但这些度量通常被认为能够重现泛化趋势。然而，这种度量在经过训练的网络上进行计算，并且许多后验泛化度量对小的训练修改非常敏感，即使这些修改对基础DNN的影响微乎其微，也可能会显著改变度量的价值、趋势或比例行为。", "innovation": "该论文创新地指出了许多后验检验泛化度量的脆弱性。这些度量在已经训练过的网络上计算，并可能因为微小的超参数更改（例如学习率调整或SGD变体之间的切换）而导致泛化度量中使用的常用指标如路径范数的学习曲线斜率反转。论文还发现在这一点上更为微妙的脆弱形式，比如作为最可靠度量之一的PAC-Bayes本原度量对超参数调整的敏感性较低，但它无法捕捉到不同学习曲线间的数据复杂度差异。尽管基于函数的边缘似然度量可能存在数据复杂性差异，包括比例行为，但它并非是后验度量。", "conclusion": "本文不仅展示了许多边界——例如路径、谱范数、Frobenius范数、扁平度代理和确定性PAC-Bayes近似——都是脆弱的，还论证了新度量的开发者应该显式地为其脆弱性进行审计。"}
{"llm_update_time": "20251023", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.18998", "html_url": "https://arxiv.org/abs/2510.18998", "title": "对受污染训练数据的无监督时间序列异常检测的编码-然后-分解方法——扩展版本", "title_en": "An Encode-then-Decompose Approach to Unsupervised Time Series Anomaly Detection on Contaminated Training Data--Extended Version", "authors": "Buang Zhang,Tung Kieu,Xiangfei Qiu,Chenjuan Guo,Jilin Hu,Aoying Zhou,Christian S. Jensen,Bin Yang", "background": "时间序列异常检测对于现代大规模系统非常重要，并应用于多种领域来分析和监控多样化的系统。无监督方法因其在训练过程中无需异常标签，能够避免潜在的高昂成本并且具有更广泛的应用范围而受到广泛关注。其中，自编码器由于其通过压缩表示的重建误差来定义异常得分而受到了广泛关注。但是，自编码器在训练时间序列期间对异常的敏感性导致了较低的准确性。", "innovation": "本文提出了一种新颖的编码-然后-分解范式。通过将编码表示分解为稳定表示和辅助表示，从而增强在受污染时间序列训练时的鲁棒性。此外，提出了一种基于互信息的新的度量标准以代替重建误差来识别异常。", "conclusion": "我们的方法在多个常用的时间序列基准（多变量和单变量）上展示了竞争力或最先进的性能，并且对于不同污染比率的时间序列表现出鲁棒性。"}
{"llm_update_time": "20251023", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.18989", "html_url": "https://arxiv.org/abs/2510.18989", "title": "使用PGD攻击在主动学习中提高神经算子泛化能力的方法：从数值偏微分方程求解器知识蒸馏的角度", "title_en": "Towards Universal Solvers: Using PGD Attack in Active Learning to Increase Generalizability of Neural Operators as Knowledge Distillation from Numerical PDE Solvers", "authors": "Yifei Sun", "background": "非线性偏微分方程(PDE)求解器需要精细的空间-时间离散化和局部线性化，导致高内存成本和慢运行时间。神经算子如FNOs和DeepONets通过学习函数到函数的映射并截断高频分量，提供了快速的一次性推断，但它们在离分布外(OOD)泛化方面表现不佳，对训练分布之外的输入常常失效。", "innovation": "本文提出了一种对抗性的教师-学生蒸馏框架，其中可微分的数值求解器监督一个紧凑的神经算子，同时一个PGD风格的主动采样循环在平滑性和能量约束下搜索最坏情况的输入以扩展训练集。这种方法利用了可微分的光谱求解器，使基于梯度的对抗搜索成为可能并稳定了样本挖掘。实验结果表明，这种对抗蒸馏显着提高了神经算子的OOD鲁棒性，同时保持了神经运算符的低成本和快速推断特性。", "conclusion": "本研究提出的对抗蒸馏方法在保持神经算子的优点的同时，有效提高了其在离分布外输入情况下的稳健性。"}
{"llm_update_time": "20251023", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.19014", "html_url": "https://arxiv.org/abs/2510.19014", "title": "通过大型语言模型处理历史记录训练的多臂老虎机算法实现知识告知的治疗推荐优化", "title_en": "Prior-informed optimization of treatment recommendation via bandit algorithms trained on large language model-processed historical records", "authors": "Saman Nessari,Ali Bozorgi-Amiri", "background": "当前的医疗实践中依赖于标准化的治疗框架和经验方法，这些方法忽视了个体患者的变化，导致次优的健康结果。", "innovation": "该系统综合了大型语言模型（LLMs）、条件表生成对抗网络（CTGAN）、T-learner反事实模型以及上下文豪猪技术，提供个性化、数据驱动的临床建议。该方法使用LLMs将非结构化的医学叙述转换为结构化数据，利用CTGAN生成符合实际数据的合成患者数据，运用T-learner预测特定患者的治疗反应，并通过结合先验知识的上下文豪猪来改进在线治疗选择，实现对新可能性的探索和现有知识的利用之间的有效平衡。在结直肠癌阶段III的数据集上测试，该系统的KernelUCB方法在5000次迭代中获得了0.60-0.61的平均奖励分数，超过其他参考方法。", "conclusion": "该全面系统解决了在线学习环境中的冷启动问题，提高了计算效率，并在特定患者特征的个性化医疗方面取得了显著进展。"}
{"llm_update_time": "20251023", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.18910", "html_url": "https://arxiv.org/abs/2510.18910", "title": "大型连接组模型：借助多任务学习景观中的脑-环境交互增强的fMRI大脑连接组基础模型", "title_en": "Large Connectome Model: An fMRI Foundation Model of Brain Connectomes Empowered by Brain-Environment Interaction in Multitask Learning Landscape", "authors": "Ziquan Wei,Tingting Dan,Guorong Wu", "background": "功能性神经影像（fMRI）在临床应用中的表现受限于样本量有限。为克服这一挑战，研究人员致力于利用大规模未标记fMRI数据进行自监督预训练，但自监督可能与大脑结果相关性不完全一致，导致基础模型在下游任务（如疾病预测）上表现不佳。因此，本文利用丰富的环境变量、人口统计信息和空前数量的功能神经影像数据，提出了多任务学习框架和扩展模型架构，以提高临床应用中的性能。", "innovation": "本文提出了大型连接组模型，通过自监督预训练结合多任务学习框架，在最大化利用贝叶斯环境中大脑-环境交互（BEI）的基础上，进行了半监督微调，生成了伪标签。该模型通过多任务预训练和半监督微调，显著提升了多种临床应用，包括性别预测、人类行为识别以及自闭症、帕金森病、阿尔茨海默病和精神分裂症等疾病的早期诊断，展示了在临床神经影像应用中的巨大潜力。", "conclusion": "提出的基于大规模fMRI数据的多任务学习框架和扩展模型架构成功地提高了临床神经影像任务的应用性能，尤其是在性别预测、人类行为识别和多种疾病的早期诊断中表现突出，展示了其在临床神经影像应用中的强大潜力。"}
{"llm_update_time": "20251023", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.19056", "html_url": "https://arxiv.org/abs/2510.19056", "title": "POLAR: 基于策略的层级强化学习方法在联邦学习中实现隐蔽后门攻击", "title_en": "POLAR: Policy-based Layerwise Reinforcement Learning Method for Stealthy Backdoor Attacks in Federated Learning", "authors": "Kuai Yu,Xiaoyu Wu,Peishen Yan,Qingqian Yang,Linshan Jiang,Hao Wang,Yang Hua,Tao Song,Haibing Guan", "background": "联邦学习（FL）允许多个客户端在不暴露本地数据的情况下分散进行模型训练，但其分布式特性使得它易遭受后门攻击。早期的FL后门攻击修改了整个模型，而近期的研究则专注于所谓的后门关键层（BC层），这种策略通过毒化选定的影响层来维持隐蔽性同时实现高效性。然而，现有的BC层方法依赖于基于规则的选择，而不考虑层之间的关系，使得它们效果不佳且容易被高级防御检测。", "innovation": "提出了POLAR（基于策略的层级强化学习方法），这是首个利用强化学习（RL）解决层级后门攻击中BC层选择问题的框架。POLAR不同于其他常用的RL范式，采用轻量的贝尔努利抽样。它动态地学习攻击策略，通过基于后门成功率（BSR）改进的策略梯度更新来优化层选择。为了确保隐蔽性，引入了一个正则化约束来限制修改的层数量，通过对大型攻击足迹进行惩罚。", "conclusion": "大量的实验表明，POLAR方法在对抗六种最先进的（SOTA）防御措施时，与最新攻击方法相比，性能提高了多达40%。"}
{"llm_update_time": "20251023", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.19093", "html_url": "https://arxiv.org/abs/2510.19093", "title": "Weight Decay may matter more than muP for Learning Rate Transfer in Practice", "title_en": "Weight Decay may matter more than muP for Learning Rate Transfer in Practice", "authors": "Atli Kosson,Jeremy Welborn,Yang Liu,Martin Jaggi,Xi Chen", "background": "在大型神经网络训练中，寻找最佳学习率通常是一项昂贵的超参数调优任务。MuP（Maximal Update Parameterization）提出了一种学率缩放规则，旨在使不同模型宽度内部表示的更新动力学保持稳定。但是，MuP的缩放规则依赖于强烈的假设，特别是在层的输入与权重及梯度更新的几何对齐方面。研究人员通过大规模的实证研究发现，这些假设仅在训练初期部分成立，而在训练后期，权重衰减比MuP更有效地稳定内部表示的更新动力学，这有助于学习率的转移。", "innovation": "本研究通过大规模实证研究揭示了在大型神经网络训练中，权重衰减比MuP在保持内部表示的更新动力学稳定方面更为有效，这在很大程度上挑战了关于学习率转移的传统观点。研究还提出，MuP的主要作用可能是一种隐式的学习率预热，可以通过修改热身计划来替代。", "conclusion": "本研究的结论是，权重衰减比MuP在实际中的学习率转移中更为重要。这一发现对未来研究和实践具有重要意义，可以解释例如为何MuP需要独立的权重衰减变体才能成功转移的现象。"}
{"llm_update_time": "20251023", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.19021", "html_url": "https://arxiv.org/abs/2510.19021", "title": "深度人工神经网络中的类别学习：内部表示的信息内容和几何结构", "title_en": "Category learning in deep neural networks: Information content and geometry of internal representations", "authors": "Laurent Bonnasse-Gahot,Jean-Pierre Nadal", "background": "研究表明，在动物和人工神经网络中，类别学习都会导致对于接近类别边界的刺激的辨别能力增强，即所谓的类别感知现象。以前基于神经科学研究的数据建模研究表明，这种扩张/压缩是高效学习的必然结果。本文研究的是如何将理论框架扩展到人工网络中，通过最小化贝叶斯成本（交叉熵损失的均值），最大化类别集和决策层前的神经活动之间的互信息，从而优化神经网络的学习效率和性能。", "innovation": "本文创新点在于，能够通过对人工网络学习过程的研究，揭示类别学习导致神经空间在决策边界附近的扩张，并通过最大化互信息找到合适的投影空间和构建具有适当度量的神经表示，使得神经信息散度遵循类别特定信息散度。这一发现为理解人工网络中的类别学习提供了一种新的理论框架，同时也提出了计算两个信息散度矩阵一致性以及与类别边界对齐的方法。此外，该研究还将其方法与信息瓶颈方法进行了比较，并对贝叶斯成本提供了偏差-方差分解，进一步探讨了这些概念对优化学习的重要性。", "conclusion": "研究发现，类别学习会导致神经空间在决策边界附近的扩张，使得神经空间在关键点的方向具有最优辨别能力。在学习后，两种信息散度矩阵会基本匹配并接近类别边界。研究将这一发现与信息瓶颈理论进行了比较，并提出了对贝叶斯成本的偏差-方差分解。这一研究为理解人工网络的学习机制提供了新的视角，并为进一步优化人工神经网络的学习效果提供了理论指导。"}
{"llm_update_time": "20251023", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.19040", "html_url": "https://arxiv.org/abs/2510.19040", "title": "通过形状函数分支增强决策树", "title_en": "Empowering Decision Trees via Shape Function Branching", "authors": "Nakul Upadhya,Eldan Cohen", "background": "决策树因其可解释性和在表格数据上的强大性能而受到青睐。然而，它们依赖于简单的轴向线性分割，导致需要复杂的结构来捕捉非线性特征效应，这反而削弱了人类对这些树的结构的理解。为解决这一局限，我们提出了决策树的一种新的泛化形式——形状泛化树（SGT），它在每个内节点应用一个可学习的轴向形状函数来对单一特征进行操作，允许一次分割中实现丰富且非线性的划分。由于用户可以直接可视化每个节点的形状函数，SGT自然具有可解释性，并提供了直观的模型决策机制的视觉解释。实验表明，SGT相比传统的轴向线性树在性能上更胜一筹，且模型大小更小。", "innovation": "我们提出了形状泛化树（SGT）及其学习算法ShapeCART，这是对传统轴向线性树的一个改进。SGT在每个内节点应用一个可学习的轴向形状函数，以进行非线性划分。我们进一步将SGT框架扩展到双变量形状函数（S2GT）和多路决策树（SGTK），并提出了Shape2CART和ShapeCARTK作为ShapeCART的扩展算法，用于学习S2GT和SGTK。", "conclusion": "实验结果显示，SGT在多个数据集上的性能优于传统的轴向线性树，同时模型大小更小。"}
{"llm_update_time": "20251023", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.19099", "html_url": "https://arxiv.org/abs/2510.19099", "title": "构成良好教学大纲的因素是什么？分离数据排序对LLM数学推理效果的影响", "title_en": "What Makes a Good Curriculum? Disentangling the Effects of Data Ordering on LLM Mathematical Reasoning", "authors": "Yaning Jia,Chunhui Zhang,Xingjian Diao,Xiangchi Yuan,Zhongyu Ouyang,soroush vosoughi", "background": "已有研究表明，课程学习（CL）通过将训练数据从简单到复杂排序，已经成为提升大型语言模型（LLMs）推理能力的一种流行策略。然而，先前的工作使用了不同的难度度量标准和训练设置，导致关于何时、何种方向（正向或反向）的CL策略更为有效的关键问题尚未明确解答。", "innovation": "本文通过一个统一的离线评估框架，将课程难度拆分为五个互补维度：问题难度、模型惊讶度、置信度差距、预测不确定性以及决策变量。基于对数学推理基准实验（使用Llama3.1-8B、Mistral-7B和Gemma3-4B模型），研究发现：（1）没有一种课程策略能普适占优——正向和反向课程学习的相对有效性取决于模型能力和任务复杂性；（2）即使在同一度量标准内，在不同难度级别的样本也会根据任务需求产生不同的效益；（3）任务对齐的教学大纲侧重于塑造模型的最终表示和泛化能力，而内部状态教学大纲则调节内部状态如信心和不确定性。", "conclusion": "研究结果挑战了一种普遍存在的课程策略观念，并为不同模型和任务环境下的实践提供可操作的指导。部分度量标准表明，优先处理决策不确定性较高的样本可能进一步提高学习效果。"}
{"llm_update_time": "20251023", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.19105", "html_url": "https://arxiv.org/abs/2510.19105", "title": "MetaCluster: 使Kolmogorov-Arnold网络实现深度压缩的框架", "title_en": "MetaCluster: Enabling Deep Compression of Kolmogorov-Arnold Network", "authors": "Matthew Raffel,Adwaith Renjith,Lizhong Chen", "background": "Kolmogorov-Arnold网络（KANs）用每条边的基系数向量替换标量权重，这提高了表达能力和精度，但也导致了参数和内存的成倍增加。因此，如何在保持精度的同时减少KANs的存储需求成为一个重要的研究课题。MetaCluster框架的目标就是在不牺牲精度的前提下，使KANs实现高度的压缩。", "innovation": "MetaCluster提出了一种轻量级的元学习器，与KAN共同训练，用于将低维嵌入映射到系数向量，让其位于易于聚类的低维流形上。随后在系数空间运行K均值聚类，并用共享质心替换每条边的向量。元学习器随后可以被丢弃，通过短暂的调优恢复任何剩余的精度损失。该方法显著降低了模型存储需求，且未损失精度。", "conclusion": "在MNIST、CIFAR-10和CIFAR-100数据集上，MetaCluster实现了多达80倍的参数存储减少，同时保持了相同的精度。这种压缩方法利用了KAN参数的向量性质，实现了巨大的存储节省。"}
{"llm_update_time": "20251023", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.19127", "html_url": "https://arxiv.org/abs/2510.19127", "title": "使用递归特征机调节自回归音乐生成", "title_en": "Steering Autoregressive Music Generation with Recursive Feature Machines", "authors": "Daniel Zhao,Daniel Beaglehole,Taylor Berg-Kirkpatrick,Julian McAuley,Zachary Novack", "background": "当前可控音乐生成仍然是一个重大挑战，现有的方法往往需要重新训练模型或引入可听见的缺陷。这使得在保持生成音乐质量的同时，实现细粒度且可解释的控制变得更加困难。", "innovation": "本文提出了MusicRFM框架，利用递归特征机（RFMs）使预训练的音乐模型具备细粒度的、可解释的控制能力，通过直接引导模型的内部激活来实现这种控制，而不需要逐步优化。此外，还提供了一系列先进的控制机制，包括动态、时间相关的调度，以及同时强制执行多个音乐属性的方法。", "conclusion": "通过MusicRFM，本文成功地在控制和生成质量之间找到了平衡：生成目标音符的准确性从0.23提高到0.82，同时文本提示的遵守度保持在未引导基准的约0.02范围内。这种方法在减少提示保真度影响的同时实现了有效控制，且提供了用于音乐领域的递归特征机代码，鼓励进一步探索。"}
{"llm_update_time": "20251023", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.19119", "html_url": "https://arxiv.org/abs/2510.19119", "title": "使用线性上下文多臂赌徒学习同伴影响力概率", "title_en": "Learning Peer Influence Probabilities with Linear Contextual Bandits", "authors": "Ahmed Sayeed Faruk,Mohammad Shahverdikondori,Elena Zheleva", "background": "在网络环境中，用户经常与其他用户分享关于内容、产品、服务和行动计划的推荐。这些推荐的成功和被采纳的程度高度依赖于发送者、接收者、两者的关系、推荐对象以及所使用的媒介。这就使得同伴影响力的概率变得高度异质。准确估计这些概率对于理解信息扩散过程和提高病毒式营销策略的有效性至关重要。然而，从数据中学习这些概率是具有挑战性的。静态数据能够捕捉同伴推荐与同伴行动之间的相关性，但无法揭示影响力关系。在线学习算法可以从干预中学习这些概率，但由于资源浪费或优化奖励等原因，它们倾向于探索具有较高影响力的领域。", "innovation": "本文在上下文线性多臂赌徒框架下研究了学习同伴影响力的概率问题。文章揭示了一个基本的权衡关系，即减少遗憾与减少估计误差之间的权衡，并描述了所有可实现的比率对。提出了一个基于不确定性指导探索的算法，通过调节参数，可以达到该权衡关系内的任一对。实验结果表明，该方法在半合成网络数据集上优于静态方法和忽略此权衡关系的上下文多臂赌徒算法。", "conclusion": "通过上下文线性多臂赌徒的框架和不确定性导向探索算法，可以有效学习同伴影响力的概率，并在减少遗憾与减少估计误差之间取得平衡。"}
{"llm_update_time": "20251023", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.19138", "html_url": "https://arxiv.org/abs/2510.19138", "title": "InvarGC: 在潜在混杂因素下异质干预时间序列的不变Granger因果性", "title_en": "InvarGC: Invariant Granger Causality for Heterogeneous Interventional Time Series under Latent Confounding", "authors": "Ziyi Zhang,Shaogang Ren,Xiaoning Qian,Nick Duffield", "background": "Granger因果性广泛用于复杂系统中从多变量时间序列数据中发现因果结构。传统的基于线性模型的Granger因果性测试往往无法检测到轻微的非线性因果关系。因此，近年来的研究探索了非线性Granger因果性方法，提高了性能。然而，这些方法通常依赖于因果完备性和已知的干预目标两个关键假设。因果完备性假设不存在潜在混杂因素，而它们的存在可能会引入伪相关。另外，实际时间序列数据通常来自异质环境，缺乏干预的先验知识。在实践中很难区分干预环境与非干预环境，更难识别受影响的变量或时间点。", "innovation": "提出了一种名为InvarGC的新方法，该方法利用跨环境异质性来减轻潜在混杂因素的影响，能够在边缘粒度上区分干预环境与非干预环境，从而恢复不变的因果关系，并证明在这些条件下具有可识别性。实验结果表明，在合成和真实世界数据集上，与最先进的方法相比，该方法具有竞争力的性能。", "conclusion": "InvarGC方法能够在存在潜在混杂因素的情况下处理异质性的干预性时间序列数据，恢复不变的因果关系，并证明了在这些条件下方法的可识别性。该方法在合成和真实世界数据集上的实验结果表明，与最先进的方法相比，该方法具有竞争力的性能。"}
{"llm_update_time": "20251023", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.19152", "html_url": "https://arxiv.org/abs/2510.19152", "title": "潜隐篡改：机理、阈值和可解释性", "title_en": "Subliminal Corruption: Mechanisms, Thresholds, and Interpretability", "authors": "Reya Vir,Sarvesh Bhatnagar", "background": "随着机器学习模型越来越多地在合成数据上进行微调，数据中的隐秘错误有可能通过相互关联的人工智能系统传播，造成潜在风险。尽管存在这一现象，但对其动态的量化理解仍然不足。", "innovation": "本文通过使用GPT-2进行教师-学生设定下的系统研究，揭示了潜隐篡改的规模法则、临界阈值和传播机制。研究发现：（1）潜隐篡改导致行为反转，不仅影响特定目标属性，还降低了模型的整体对齐性；（2）对污染数据的临界阈值达到时，对齐性会经历一个突变的相变，而不是逐渐退化；（3）解释性分析表明，篡改机制模仿了模型自然微调的过程，增加了检测难度。这些结果揭示了依赖合成数据的人工智能系统的关键脆弱性，并突显了需要制定新的安全协议来应对隐形威胁的必要性。", "conclusion": "这些结果强调了需要关注和防止潜隐篡改的风险，并提出了应对防范措施的新需求，以保护AI系统的安全和可靠性。"}
{"llm_update_time": "20251023", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.19155", "html_url": "https://arxiv.org/abs/2510.19155", "title": "特征空间适应性调整：鲁棒模型微调的新方法", "title_en": "Feature Space Adaptation for Robust Model Fine-Tuning", "authors": "Peng Wang,Minghao Gu,Qiang Huang", "background": "微调模型时普遍面临的灾难性遗忘问题，在下游领域数据有限或与预训练分布差异较大时尤为突出。现有的参数高效微调方法通过修改或扩展预训练模型的参数在权重空间进行操作，可能导致模型过度专门化于待下流数据。为缓解重写预训练知识的风险并增强鲁棒性，本文提出在特征空间进行微调的新方法。受下游潜变量效应等价模型(EEM)的启发，本文提出了两种新的微调方法：LoRFA（低秩特征适应）和VeFA（向量基特征适应）", "innovation": "基于特征空间适应的新方法，分别提出LoRFA（低秩特征适应）和VeFA（向量基特征适应）两种方法。通过轻量级的特征层面转换补偿下游潜变量的影响，保留预训练表示，进而优化模型在分布转移时的泛化能力", "conclusion": "特征空间适应方法在图像分类、NLU和NLG等任务上的微调结果与低秩适应性（LoRA）相当，且具有更一致的鲁棒性"}
{"llm_update_time": "20251023", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.19163", "html_url": "https://arxiv.org/abs/2510.19163", "title": "自然梯度VI：非共轭模型的保证", "title_en": "Natural Gradient VI: Guarantees for Non-Conjugate Models", "authors": "Fangyuan Sun,Ilyas Fatkhullin,Niao He", "background": "自然梯度变异分布近似（NGVI）是概率模型中近似后验分布的一种广泛应用的方法。尽管它具有实际成功和在变异分布推理中的基础性作用，但在非共轭似然的情况下，它的理论基础仍然有限。现有的研究表明NGVI是随机镜下降的一种特殊实例，并且有关联模型中的收敛保证已经通过相对平滑性和强凸性提供，但这些结果不适用于非共轭设定，因为在这些情况下，变异损失变得非凸且更难以分析。", "innovation": "本文主要针对均场参数化，并在三个关键方面推进了NGVI的理论理解。首先，推导了满足相对平滑性的充分条件。其次，通过这种结构提出了一种改进的NGVI算法，并具有非欧几里得投影，证明了该算法全局非渐近收敛到驻点。最后，对于似然函数的附加结构假设下，揭示了变异损失隐藏的凸性特征，并证明了NGVI快速全局收敛到全局最优。", "conclusion": "这些结果为NGVI在具有挑战性的推理环境中的几何结构和收敛行为提供了新的见解。"}
{"llm_update_time": "20251023", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.19158", "html_url": "https://arxiv.org/abs/2510.19158", "title": "非随机线性部分监测的实例相关遗憾界", "title_en": "Instance-Dependent Regret Bounds for Nonstochastic Linear Partial Monitoring", "authors": "Federico Di Gennaro,Khaled Eldowa,Nicolò Cesa-Bianchi", "background": "与经典的部分监测形式不同，线性部分监测能够处理无限的结果空间，并对损失和观测都施加线性结构。这种设置可以被视为线性贝叶斯的一种扩展，在线性贝叶斯中，损失和反馈以灵活的方式解耦。现有的理论保证主要依赖于不确定性的结构，而在这种模型中，遗憾界依赖于游戏的具体结构，并且更加透明，能够更好地反映观察与损失之间对齐的程度。在简单的探索-优化实例中，这种保证为实际应用提供了高效的实现方法。", "innovation": "该研究通过提出基于预见性优化的方法，提供了一种非随机（对抗性）有限动作版本的线性部分监测问题的解决方案。与之前的理论保证相比，所得到的遗憾界更加贴近实例的具体结构，能够在简单（局部可观测）和困难（全局可观测）游戏中分别实现标准的 √T 和 T²/₃ 遗憾率。研究者还对老的和新的部分信息设定进行了实例化，展示了对游戏结构依赖的可能紧的结果。", "conclusion": "研究结果表明，遗憾界对游戏结构的依赖性可以在某些有趣的情况下达到最佳。这种新的遗憾界提供了一种更加具体的分析手段，有助于在实际应用中更好地解决线性部分监测问题。"}
{"llm_update_time": "20251023", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.19178", "html_url": "https://arxiv.org/abs/2510.19178", "title": "多任务大语言模型RL后训练中梯度不平衡现象", "title_en": "Imbalanced Gradients in RL Post-Training of Multi-Task LLMs", "authors": "Runzhe Wu,Ankur Samanta,Ayush Jain,Scott Fujimoto,Jeongyeol Kwon,Ben Kretzu,Youliang Yu,Kaveh Hassani,Boris Vidolov,Yonathan Efroni", "background": "多任务大语言模型的后训练通常通过混合来自不同任务的数据集并联合优化来进行。这种方法假设所有任务产生的梯度幅度相似，但在实际中，当某些任务产生远大于其他任务的梯度时，优化过程会偏向于梯度幅度较大的任务。这种梯度不平衡的原因需要进一步探讨。", "innovation": "本文揭示了在使用强化学习（RL）进行多任务大语言模型后训练时，某些任务产生的梯度显著大于其他任务，从而使更新偏向于这些任务。这意味着，即使某些任务的梯度较大，它们的进步也不一定会比梯度较小的任务更大或更好。这一发现揭示了简单的数据集组合方法的局限性，为未来针对大语言模型的梯度级修正提出了研究方向。", "conclusion": "梯度不平衡不能仅通过常见的训练统计量（如奖励或优势）来解释，而与任务本身的内在差异相关。因此，应该谨慎避免简单的数据集混合，并建议未来的研究应关注于原理性的梯度级修正措施，以确保优化过程中梯度的公正性。"}
{"llm_update_time": "20251023", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.19202", "html_url": "https://arxiv.org/abs/2510.19202", "title": "Active Diffusion Neural Network for Graphs", "title_en": "An Active Diffusion Neural Network for Graphs", "authors": "Mengying Jiang", "background": "热扩散类类图神经网络（GNN）已增强我们对图中信息流动的理解，并促进了图神经网络的发展。然而，大多数扩散机制的 GNN 仍依赖于被动的热扩散方式，这种方法在捕捉全局图信息方面存在过拟合并导致同质化的问题。因此，节点表示在扩散过程中逐渐趋同到相同的特征向量，这限制了其性能。", "innovation": "该论文提出了一种名为 Active Diffusion-based Graph Neural Network (ADGNN) 的模型。ADGNN 通过整合动态影响扩散过程的多种外部信息来源实现了活性扩散，从而克服了过拟合问题。该模型还能直接计算活性扩散迭代公式的封闭解，确保节点特征保持独特性同时高效获取全局图结构的信息。", "conclusion": "在各种图任务上，ADGNN 相对于最新一代 GNN 模型表现出显著的准确性和效率提升，表明 ADGNN 在捕获全局图信息和保持节点差异性方面的有效性。"}
{"llm_update_time": "20251023", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.19199", "html_url": "https://arxiv.org/abs/2510.19199", "title": "一种高效的分布式演员-评论家算法", "title_en": "A Communication-Efficient Decentralized Actor-Critic Algorithm", "authors": "Xiaoxing Ren,Nicola Bastianello,Thomas Parisini,Andreas A. Malikopoulos", "background": "本文研究了多智能体系统中受限通信条件下的强化学习问题。在这样的系统中，智能体之间的通信受到限制，因此需要开发一种能够在减少通信开销的同时维持网络协调的分布式学习框架。传统的集中式学习方法通常需要智能体间频繁交换信息，这在通信受限的环境中会带来显著的挑战。因此，需要研究并提出一种新的算法来解决这一问题。", "innovation": "本文提出了一种分散的演员-评论家学习框架，其中每个智能体在进行几次局部策略和价值函数更新后，再与其他邻居智能体交换信息。这种方法显著减少了通信负担，同时保持了网络内的协调性。此外，该算法在马尔可夫采样的情况下建立了有限时间收敛分析，证明了所需的样本复杂度为$\text{O}(\text{ε}^{-3})$，通信复杂度为$\text{O}(\text{ε}^{-1}\tau^{-1})$。实验结果表明，该方法在合作控制场景中是有效且可靠的。", "conclusion": "本文提出了一种高效的分布式演员-评论家算法，解决了多智能体系统中受限通信条件下的学习问题。通过有限时间收敛分析，证明了该算法的理论效率。实验结果验证了该方法的有效性，未来可以进一步研究该算法在更复杂任务上的应用。"}
{"llm_update_time": "20251023", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.19160", "html_url": "https://arxiv.org/abs/2510.19160", "title": "初步使用视觉语言模型驱动提取小鼠行为以理解恐惧表达", "title_en": "Preliminary Use of Vision Language Model Driven Extraction of Mouse Behavior Towards Understanding Fear Expression", "authors": "Paimon Goulart,Jordan Steinhauser,Kylene Shuler,Edward Korzus,Jia Chen,Evangelos E. Papalexakis", "background": "多样的数据整合在许多学科中的科学探索中将起到关键作用。本文构建了一个视频-语言模型（VLM），用于通过文本输入来编码视频，以对小鼠在环境中的各种行为进行分类。这项模型能为每个个体和每个实验过程提供时间行为向量，生成高质量的数据集，通常不需要很多的人工输入，这将促进多种学科的研究者研究小鼠行为，使他们能够整合多个时间点和环境中的多种行为特征，形成一个全面的数据集，以此来解决复杂的研究问题。", "innovation": "本研究使用开源的Qwen2.5-VL模型，并通过提示、上下文学习（ICL）以及逐帧预处理方法提升其性能，发现这些方法均有助于提高分类效果，且结合使用后，针对所有行为（包括罕见行为如静止和逃逸）均产生了较高的F1分数，无需对模型进行微调。这项研究为小鼠行为的研究提供了新的工具。", "conclusion": "该模型将支持跨学科研究者研究小鼠行为，使他们能够整合跨时间点和环境中的多种行为特征，纳入到全面的数据集中，从而解决复杂的研究问题。"}
{"llm_update_time": "20251023", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.19223", "html_url": "https://arxiv.org/abs/2510.19223", "title": "增强图神经网络：一种协作学习方法", "title_en": "Enhancing Graph Neural Networks: A Mutual Learning Approach", "authors": "Paul Agbaje,Akajyoti Mitra,Afia Anjum,Pranali Khose,Ebelechukwu Nwafor,Habeeb Olufowobi", "background": "知识蒸馏（KD）技术已经成为一种强大的工具，用于从复杂的教师模型向轻量级学生模型转移专业知识，特别适用于在资源受限的设备上部署高性能模型。这种方法已经成功应用于图神经网络（GNNs），利用其表达能力生成捕获结构和特征相关信息的节点嵌入。然而，这项研究采用了一种不同于传统的知识蒸馏方法，探索了GNNs之间的协同学习潜力。缺少预训练的教师模型，研究发现较简单且浅层的GNN架构可以在训练过程中相互高效学习，特别是在处理多个任务时表现出更好的推理能力。", "innovation": "研究提出了一种协作学习框架，其中学生GNNs的集合可以在训练过程中相互教对方。为了促进模型间的高效知识交换，引入了一种自适应逻辑加权单元，并使用熵增强技术来提高互相学习的效果。这些组件动态赋予模型在训练期间调整其学习策略的能力，从而优化其下游任务的表现。", "conclusion": "在三个数据集（每个数据集用于节点和图分类）进行的广泛实验表明，本研究方法的有效性。"}
{"llm_update_time": "20251023", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.19241", "html_url": "https://arxiv.org/abs/2510.19241", "title": "SPOT: 标准化决策树优化方法以处理马尔可夫决策过程", "title_en": "SPOT: Scalable Policy Optimization with Trees for Markov Decision Processes", "authors": "Xuyuan Xiong,Pedro Chumpitaz-Flores,Kaixun Hua,Cheng Hua", "background": "在高风险的决策场景中，可解释的强化学习策略至关重要。然而，在马尔可夫决策过程（MDPs）中优化决策树策略仍具有挑战性。", "innovation": "我们提出了SPOT，一种新颖的方法用于计算决策树策略，将其优化问题形式化为混合整数线性规划（MILP）。为了提高效率，我们采用了一种减少空间分支定界的方法，解耦MDP动力学与树结构约束，从而可以高效并行搜索。与以前的方法相比，这种方法显著提高了运行时间和可扩展性。我们的方法确保每个迭代都得到最优决策树。在标准基准上的实验结果表明，SPOT实现了显著的速度加快，并且能够处理更大规模的MDP，具有更多状态。因此，生成的决策树策略是可解释且紧凑的，保持透明度而不牺牲性能。", "conclusion": "我们的方法同时实现了可解释性和可扩展性，比现有方法快一个数量级，提供了高质量的策略。"}
{"llm_update_time": "20251023", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.19229", "html_url": "https://arxiv.org/abs/2510.19229", "title": "启发式的配置视角：无监督相似性和早期认知", "title_en": "Brain-Inspired Perspective on Configurations: Unsupervised Similarity and Early Cognition", "authors": "Juntang Wang,Yihan Wang,Hao Wu,Dongmian Zou,Shixin Xu", "background": "婴儿在没有监督的情况下能够发现类别、检测新颖性和适应新环境，这给当前的机器学习带来了挑战。本文从神经启发的角度研究配置（一种有限分辨率的聚类框架），探讨其如何形成分层次的组织结构、敏感于新颖性特征以及具备适应动态变化的能力。为了评估这些特性，作者提出了mheatmap，一个提供比例热图和重新分配算法的工具，以公平地检测多层次和动态行为。", "innovation": "作者提出了配置这一新的无监督学习模型，通过单一分辨率参数和吸引-排斥动力学机制实现分层次组织、新颖性敏感性和灵活适应性。该模型通过mheatmap工具进行评估，展示了在标准聚类指标、新颖性检测和动态分类稳定性的优势。", "conclusion": "配置模型作为一种有原则的早期认知分类的计算模型，展示了在无监督学习中的优势，朝向启发式的人工智能迈出了重要一步。"}
{"llm_update_time": "20251023", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.19266", "html_url": "https://arxiv.org/abs/2510.19266", "title": "通过注意桥实现的任何变压器到Mamba的高效数据蒸馏", "title_en": "Data Efficient Any Transformer-to-Mamba Distillation via Attention Bridge", "authors": "Penghao Wang,Yuhao Zhou,Mengxuan Wu,Panpan Zhang,Zhangyang Wang,Kai Wang", "background": "自回归模型如Transformer已经成为了序列建模的主要工具，然而其训练成本高昂，生态系统尚不成熟。相比之下，状态空间模型（SSMs）提供了更高效的递归结构，但在知识提取方面仍存在挑战，尤其是在从预训练的Transformer模型向基于递归的SSMs模型进行知识转移时。", "innovation": "本文提出了Attention Bridge（注意桥）作为一项新型的数据高效蒸馏框架，通过轻量级桥梁在Transformer教师模型和状态空间学生模型之间实现细粒度的知识转移。CAB突破了传统知识蒸馏仅在输出层面的局限，能够在token级别提供监督，同时通过灵活的逐层对齐策略提高了效率和可转移性。", "conclusion": "我们的方法在多个视觉和语言领域的实验中都展现了对状态空间模型性能的一致性提升，即使在数据较少的情况下也优于标准和跨架构蒸馏方法。研究展示了基于注意力的知识可以高效地转移到递归模型中，为基于Transformer的知识快速应用于状态空间模型提供了新途径，有助于构建更强的SSM社区。"}
{"llm_update_time": "20251023", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.19248", "html_url": "https://arxiv.org/abs/2510.19248", "title": "配置混合用于下游预测", "title_en": "Mixing Configurations for Downstream Prediction", "authors": "Juntang Wang,Hao Wu,Runkun Guo,Yihan Wang,Dongmian Zou,Shixin Xu", "background": "人类具有将对象按相似性分组的自然能力，这一认知机制是聚类算法模仿的目标。最近在社区检测方面的进展使得在无需标签数据的情况下发现了有效层次聚类的配置，这些配置可以在多个分辨率尺度上识别。本文正式描述了这些配置，并在视觉变换器中的寄存器令牌中识别出类似的现象。寄存器令牌与配置相比体现出较低的冗余性和无需人工挑选的特点。这些配置可以通过无监督或自监督方法学习，但它们的选择或组成仍然具体依赖于下游任务和输入。", "innovation": "本文引入了一种名为GraMixC的插件模块，该模块可以提取配置、使用Reverse Merge/Split（RMS）技术对其对齐并使用注意力头进行融合，然后将其传递给任意的下游预测器。在DSN1 16S rRNA培养基预测任务中，GraMixC将R2分数提高了从0.6到0.9，创造了新的最先进的表现。同时，GraMixC还在标准的表格基准测试中展现出对单一分辨率和静态特征基线的优越性。", "conclusion": "该研究通过引入GraMixC模块，有效提升了基于配置的聚合能力在下游任务中的表现，展示了配置混合在提升模型性能上的巨大潜力。"}
{"llm_update_time": "20251023", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.19236", "html_url": "https://arxiv.org/abs/2510.19236", "title": "理解时间序列基础模型设计选择中的隐性偏见", "title_en": "Understanding the Implicit Biases of Design Choices for Time Series Foundation Models", "authors": "Annan Yu,Danielle C. Maddix,Boran Han,Xiyuan Zhang,Abdul Fatir Ansari,Oleksandr Shchur,Christos Faloutsos,Andrew Gordon Wilson,Michael W. Mahoney,Yuyang Wang", "background": "时间序列基础模型（TSFMs）是用于时间序列预测及相关时间任务的一类潜在强大、通用的工具，但它们的行为会受到设计中微妙归纳偏差的影响。现有的研究更多是开发新的模型并声称其优于现有TSFMs，而不是专注于优化模型训练过程中的各种参数，理解设计决策如何影响模型性能的方法少之又少。本文通过理论分析和实证研究关注不同设计选择（如窗口大小、嵌入方式、训练目标等）对模型内在属性的影响，揭示了这些选择导致的隐性偏见，并探讨了这些偏见对模型行为的影响特点，研究范围涉及异常处理等内容。这项研究为改进时间序列预测模型提供了新的视角和指导意义，也是未来学习和构建TSFMs的重要参考依据。", "innovation": "本文创新之处在于通过理论和实验相结合的方法，系统研究了时间序列基础模型训练过程中各种设计选择对其潜在属性的影响，揭示了设计决策如何引发隐性偏见，以及这些偏见在不同模型和数据情况下可能的表现形式，尤其在异常处理案例研究中展示了不同偏见的复杂交互方式，为改进TSFMs提供新视角和指导。", "conclusion": "本文研究结果表明，TSFMs的设计选择会引发不同类型的隐性偏见，这些偏见可能直观或非常反直觉地作用于模型行为。通过理解这些设计选择和它们导致的偏见，我们不仅可以更好地优化现有的TSFMs，还可以在未来构建更高效、更鲁棒的TSFMs。此外，本研究还为更好地理解TSFMs提供了新的理论框架，有助于研究人员在面对不同任务和应用场景时更有效地选择和应用适当的TSFM。"}
{"llm_update_time": "20251023", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.19257", "html_url": "https://arxiv.org/abs/2510.19257", "title": "FnRGNN：图神经网络中的分布感知公平性", "title_en": "FnRGNN: Distribution-aware Fairness in Graph Neural Network", "authors": "Soyoung Park,Sungsu Lim", "background": "图神经网络(GNNs)在处理结构化数据时表现出色，但在回归任务中的公平性研究仍然不足。现有的方法主要针对分类任务和表示级去偏见化，这种方法无法完全解决节点级回归任务中持续变量的性质问题。本文提出了FnRGNN，一种针对基于GNN的节点回归的公平性感知的内在处理框架，该框架从三个层面进行干预：（i）结构层面的边重权重，（ii）通过MMD表示层对齐，（iii）预测层面通过Sinkhorn基于分布匹配的正则化。这种多层策略确保了在复杂图拓扑结构下的鲁棒公平性。实验证明，FnRGNN可以在不牺牲性能的情况下减少群体间的差异性。", "innovation": "提出了一种名为FnRGNN的多层公平性干预框架，针对基于GNN的节点回归任务，在结构层面、表示层面和预测层面分别进行了边重权重调整、MMD分布对齐和Sinkhorn分布匹配正则化。这种多层面策略能够在复杂图结构中确保公平性，并在四个真实数据集上证明了其有效性，证明了可以在不影响性能的情况下减少群体间差距。", "conclusion": "通过多层面的方法，FnRGNN在基于GNN的节点回归任务中实现了公平性，实验结果表明其在保持性能的同时能够减少群体间差距。"}
{"llm_update_time": "20251023", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.19290", "html_url": "https://arxiv.org/abs/2510.19290", "title": "使用深度潜在因子模型的知识蒸馏不确定度", "title_en": "Knowledge Distillation of Uncertainty using Deep Latent Factor Model", "authors": "Sehyun Park,Jongjin Lee,Yunseop Shin,Ilsang Ohn,Yongdai Kim", "background": "深度集成能够提供最先进的、可靠的不确定性量化，但其沉重的计算和内存需求阻碍了它们在实际应用中的部署，例如设备上的AI。现有知识蒸馏方法压缩集成模型达到了小型学生模型，但这些方法难以保留不确定性，因为减少深度神经网络大小通常会导致方差减少。", "innovation": "提出了通过称为深度潜在因子模型（DLF）的新方法进行分布蒸馏（即，将教师集成压缩到学生分布而不是学生集成），其中通过将教师集成的每个成员视为某种随机过程的一个实现来估计教师集成的分布。利用EM算法稳定估计DLF模型的均值和协方差函数。通过多个基准数据集，证明了提出的高斯蒸馏方法优于现有基线。此外，展示了高斯蒸馏在语言模型微调和分布转移问题上的有效性", "conclusion": "提出的高斯蒸馏方法在多个基准数据集上优于现有基线，并有效解决了语言模型微调和分布转移问题。"}
{"llm_update_time": "20251023", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.19226", "html_url": "https://arxiv.org/abs/2510.19226", "title": "通过梯度摆动实现可控机器退学", "title_en": "Controllable Machine Unlearning via Gradient Pivoting", "authors": "Youngsik Hwang,Dong-Young Lim", "background": "机器退学（MU）的目标是从已训练的模型中移除特定数据的影响。但是，近似退学方法通常被表述为单一目标优化（SOO）问题，导致了退学效果和模型精度之间的关键权衡。这引发了一系列主要挑战：过度遗忘的风险、退学过程中的缺乏细微控制以及缺乏全面评估权衡的度量标准。", "innovation": "为了解决这些问题，作者将MU重新表述为多目标优化（MOO）问题。提出了一种名为Controllable Unlearning by Pivoting Gradient（CUP）的新算法，该算法具有一种独特的摆动机制。不同于传统的MOO方法只收敛于一个解，CUP的设计目的是能够在帕累托前沿上可控地导航。这种导航由一个直观的超参数‘退学强度’控制，允许精确选择所需的权衡。为了评价这种能力，采用了hypervolume指标，该指标可以捕获算法生成的整个解集的质量和多样性。实验结果显示，CUP生成的帕累托最优解更优，一致地优于现有方法在各种视觉任务中的表现。", "conclusion": "作者通过将机器退学问题从单一目标优化重新表述为多目标优化，并提出了一种新的算法CUP，实现了在不确定性退学过程中的控制。CUP算法通过一个直观的超参数来确保对权衡的精确控制，并证明了其在多种视觉任务中优于现有的方法。"}
{"llm_update_time": "20251023", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.19244", "html_url": "https://arxiv.org/abs/2510.19244", "title": "利用RL引导标签的SILVER在高维和多动作环境中的深度强化学习策略解释：一种基于模型的方法", "title_en": "Interpret Policies in Deep Reinforcement Learning using SILVER with RL-Guided Labeling: A Model-level Approach to High-dimensional and Multi-action Environments", "authors": "Yiyu Qian,Su Nguyen,Chao Chen,Qinyue Zhou,Liyuan Zhao", "background": "深度强化学习（RL）取得了显著的性能，但在可解释性方面存在不足，这限制了对政策行为的信任。现有的SILVER框架（Li, Siddique, and Cao 2025）使用基于Shapley的回归来解释RL政策，但仍然局限于低维度、二元动作的领域。", "innovation": "本文创新地提出了“SILVER结合RL指导标记”的增强版本，该版本通过将RL自身动作输出整合到边界点识别中，将SILVER扩展到多动作和高维度环境。该方法首先从图像观察中提取紧凑的特征表示，然后执行SHAP基于的特征归因，并利用RL指导标记生成行为一致的边界数据集。随后训练代理模型，以解释RL策略的决策结构。该研究在两个Atari环境中使用三种深度强化学习算法进行了评估，并通过人类受试者研究评估了解释性策略的清晰度和可信度。结果表明，该方法在保持任务性能的同时显著提高了透明度和人类对代理行为的理解。这为在高维和多动作环境中解释深度强化学习代理提供了一个可扩展和行为感知的框架，推进了可解释RL的发展。", "conclusion": "本文提出的方法保持了强大的任务性能的同时极大地提高了对RL政策行为的解释性和透明度，从而促进了深度强化学习的可解释性，并为在复杂环境中的解释提供了可扩展的框架。"}
{"llm_update_time": "20251023", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.19296", "html_url": "https://arxiv.org/abs/2510.19296", "title": "QiMeng-SALV: 基于信号感知学习的Verilog代码生成", "title_en": "QiMeng-SALV: Signal-Aware Learning for Verilog Code Generation", "authors": "Yang Zhang,Rui Zhang,Jiaming Guo,Lei Huang,Di Huang,Yunpu Zhao,Shuyao Cheng,Pengwei Jin,Chongxiao Li,Zidong Du,Xing Hu,Qi Guo,Yunji Chen", "background": "大型语言模型（LLMs）的显著进展为Verilog代码生成提供了潜在的机会，这对于自动电路设计至关重要。然而，由于缺乏有意义的功能奖励，基于强化学习（RL）的优先级优化在生成功能正确的Verilog代码方面受到限制。Verilog代码描述了硬件门的结构互联，使得不同的输出信号相互独立。该论文的任务是在这种环境下，通过利用功能正确输出信号的代码片段来优化RL训练，增强提取到的有意义的功能奖励。", "innovation": "本文提出了一种名为QiMeng-SALV的方法，它通过使用部分不正确的模块中验证过信号的实现，以及通过错误模块中的抽象语法树（AST）提取信号感知的代码片段，来增强功能性的奖励提取。另外，它采用了信号感知的DPO（Dependency Parsing Optimization），以优化在正确的信号级代码片段上，防止错误信号带来的干扰。这个方法从传统的模块级优化转向了细粒度的信号级优化，这是对功能奖励不足问题的一个重要改进。实验表明，该方法在VerilogEval和RTLLM上达到了最先进的性能，在具有7B参数的模型上与DeepSeek v3 671B模型的性能相当，并且在相同数据集上显著优于领先的开源模型CodeV。", "conclusion": "QiMeng-SALV成功地解决了功能性奖励不足的问题，通过信号感知学习实现了Verilog代码生成的细粒度优化，提高代码生成质量和性能，并对外开放了实现代码的链接。"}
{"llm_update_time": "20251023", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.19328", "html_url": "https://arxiv.org/abs/2510.19328", "title": "使用学习表示的聚类进行校准与区分优化", "title_en": "Calibration and Discrimination Optimization Using Clusters of Learned Representation", "authors": "Tomer Lavi,Bracha Shapira,Nadav Rappoport", "background": "机器学习模型对于决策制定和风险管理至关重要，需要在区分和校准方面提供高度可靠的预测。尽管校准常常被忽视，但在临床预测等关键决策中却非常重要。因此，提高模型的校准度是当前研究的重要方向。", "innovation": "本文引入了一种新的校准管道，通过聚类输入样本的学习表示，并利用训练在该聚类上的校准函数的集合来提高整体校准效果。这种方法不仅能将多种方法的校准得分提高到100%，还引入了一个独特的匹配度量，可以确保模型选择同时优化区分和校准。此外，该通用方案能够适应任何背景表示、聚类方法和校准方法，具有灵活性和优越的性能。", "conclusion": "该方案适用于常用的多种校准方法，并且可以优化模型在区分和校准两方面的表现，具有广泛的适用性和优越性。"}
{"llm_update_time": "20251023", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.19304", "html_url": "https://arxiv.org/abs/2510.19304", "title": "Loopholing 离道行走: 决定性穿越采样墙", "title_en": "Loopholing Discrete Diffusion: Deterministic Bypass of the Sampling Wall", "authors": "Mingyu Jo,Jaesik Yoon,Justin Deschenaux,Caglar Gulcehre,Sungjin Ahn", "background": "离散扩散模型提供了与自回归生成替代的有希望的选择，通过并行解码工作，但它们遭受采样墙的困扰：一旦发生类别采样，丰富的分布信息就会坍缩为独热向量，无法在步骤间传递，使得后续步骤只能在有限的信息下运行。", "innovation": "引入了Loopholing，这是一种新颖且简单的机制，通过确定性的潜在路径保留这些信息，从而提出了Loopholing离散扩散模型（LDDMs）。LDDMs通过自条件策略高效训练，实现了显著的提升，在生成困惑度上最高减少了61%，缩小甚至超越了自回归模型的差距，生成更具连贯性的文本。在推理任务中，LDDMs在 Countdown 和 24点游戏等算术基准上也表现出更好的性能。这些结果表明，Loopholing减轻了闲置步骤和振荡，提供了一条可扩展的通向高质量非自回归文本生成的途径。", "conclusion": "LDDMs通过Loopholing机制显著提升了非自回归文本生成的质量，缩小与自回归模型的差距，并在算术任务上实现了更好的性能。"}
{"llm_update_time": "20251023", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.19345", "html_url": "https://arxiv.org/abs/2510.19345", "title": "基础模型预测：形式与功能", "title_en": "Foundation Model Forecasts: Form and Function", "authors": "Alvaro Perez-Diaz,James C. Loach,Danielle E. Toutoungi,Lee Middleton", "background": "时间序列基础模型（TSFMs）在预测准确性方面表现出色，但预测的准确性并不完全决定其实际价值。预测的形式，如点预测、分位数预测、参数预测或轨迹集合，从根本上限制了它可以支持的操作任务类型。我们对最近的TSFMs进行调研，发现三分之二的模型只产生点或参数预测，而许多操作任务需要保留时间依赖性的轨迹集合预测。", "innovation": "我们建立了当预测类型可以转换且在什么条件下不能转换：轨迹集合可以经由边缘化转换为更简单的形式，而复杂的预测类型变回更简单的形式则需要通过假设时间依赖性来实现。我们证明单一的边缘分布无法决定路径依赖事件的概率——具有相同边缘分布的无限多个联合分布可以给出不同的操作性答案。我们为六个基本预测任务与最小预测类型建立了对应关系，并提供了任务对齐的评估框架。我们的分析阐明了为何预测类型而非准确性是区分实际应用价值的关键。", "conclusion": "我们的分析表明，在决定预测的实际用处时，预测类型而不是预测准确性更为关键，这为模型选择和应用提供了指导。"}
{"llm_update_time": "20251023", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.19338", "html_url": "https://arxiv.org/abs/2510.19338", "title": "每个注意力都重要：一种高效的长上下文推理混合架构", "title_en": "Every Attention Matters: An Efficient Hybrid Architecture for Long-Context Reasoning", "authors": "Ling Team,Bin Han,Caizhi Tang,Chen Liang,Donghao Zhang,Fan Yuan,Feng Zhu,Jie Gao,Jingyu Hu,Longfei Li,Meng Li,Mingyang Zhang,Peijie Jiang,Peng Jiao,Qian Zhao,Qingyuan Yang,Wenbo Shen,Xinxing Yang,Yalin Zhang,Yankun Ren,Yao Zhao,Yibo Cao,Yixuan Sun,Yue Zhang,Yuchen Fang,Zibin Lin,Zixuan Cheng,Jun Zhou", "background": "本文的技术报告介绍了Ring-linear模型系列，包括Ring-mini-linear-2.0和Ring-flash-linear-2.0。这些模型在长上下文推理场景中通过有效结合线性注意力和softmax注意力，显著降低了I/O和计算开销。相比320亿参数的密集模型，该系列模型将推理成本降低至原来的1/10，相比原始的Ring系列，成本也降低了超过50%。同时，通过系统地探索混合架构中不同注意力机制的比例，确定了目前最优的模型结构。", "innovation": "该系列模型采用了一种高效的混合架构，结合了线性注意力和softmax注意力，显著减少了长上下文推理的I/O和计算开销。通过使用自研高性能FP8操作符库linghe，整体训练效率提升了50%。模型在训练和推理阶段能够进行长期、稳定的高效优化，保持了在多个复杂推理基准上的最佳性能。", "conclusion": "基于训练和推理引擎操作的高度协同，该模型系列可以在强化学习阶段持续优化，保持SOTA性能。"}
{"llm_update_time": "20251023", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.19348", "html_url": "https://arxiv.org/abs/2510.19348", "title": "一种用于分支定界中变量选择的马尔可夫决策过程", "title_en": "A Markov Decision Process for Variable Selection in Branch & Bound", "authors": "Paul Strang,Zacharie Alès,Côme Bissuel,Olivier Juan,Safia Kedad-Sidhoum,Emmanuel Rachelson", "background": "混合整数线性规划（MILP）是一种强大的框架，用于解决广泛的NP难组合优化问题，通常通过分支定界法（B&B）求解。B&B求解器的表现关键因素是分支决策中的变量选择启发式。最近的研究试图将强化学习（RL）算法应用于B&B环境，以学习最优分支策略，通过灵感来自马尔可夫决策过程（MDP）的模型和专门的收敛定理和算法。", "innovation": "本文介绍了BBMDP，这是一种原则性的基本MPD框架，用于B&B中的变量选择，从而使可以利用广泛范围的RL算法来学习最优的B&B启发式。实证计算实验表明，我们提出的分支代理在四个通用的MILP基准测试中优于之前的最先进的RL代理。", "conclusion": "通过引入BBMDP模型，本文提供了一种有效的框架，该框架可以利用大量RL算法来学习最优的B&B启发策略。实验证明了模型的有效性。"}
{"llm_update_time": "20251023", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.19347", "html_url": "https://arxiv.org/abs/2510.19347", "title": "一种新的对抗样本类型", "title_en": "A New Type of Adversarial Examples", "authors": "Xingyang Nie,Guojie Xiao,Su Pan,Biao Wang,Huilin Ge,Tao Fang", "background": "多数机器学习模型会对对抗样本（adversarial examples）存在脆弱性，这使得这些模型的安全性面临威胁。对抗样本是通过在数据集样例上应用细微但故意最坏的修改来构造的，从而导致模型给出不同于原始样例的答案。现有研究主要关注构造使得模型输出非预期答案的对抗样本，但本文则构造了与原有样例差异显著但仍产生相同答案的对抗样本。这些构造的对抗样本可以在某些情况下作为攻击机器学习系统的工具。现有的对抗样本大多集中在数据集样例附近的分布，而本文的对抗样本则在样本空间中的分布更为广泛和分散。", "innovation": "本文提出了新颖的方法来构造对抗样本，包括NI-FGSM, NI-FGM这两种方法及其带有动量版本NMI-FGSM, NMI-FGM。这种方法能够构造出与原有样例差异显著但仍产生相同答案的对抗样本，这与现有方法构造使得模型输出非预期答案的方法形成了对比。这些构造的对抗样本并不局限于数据集样例附近，而是广泛分散在整个样本空间中，这使得对抗样本的分布更为复杂和难以预测。", "conclusion": "这种新的对抗样本类型可以被用于攻击某些机器学习系统，且现有的基于数据集样例附近分布的对抗样本方法难以识别和防御。"}
{"llm_update_time": "20251023", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.19349", "html_url": "https://arxiv.org/abs/2510.19349", "title": "Scalable LinUCB: 低秩设计矩阵更新算法在大规模动作空间推荐系统中的应用", "title_en": "Scalable LinUCB: Low-Rank Design Matrix Updates for Recommenders with Large Action Spaces", "authors": "Evgenia Shustova,Marina Sheshukova,Sergey Samsonov,Evgeny Frolov", "background": "线性上下文臂（LinUCB）算法在推荐系统中广泛使用，但由于特征维度和动作空间大小的增加，其训练、推理和内存成本也随之增加。主要瓶颈在于需要频繁更新、逆向和存储一个能吸收交互历史信息的设计矩阵。因此，提出了Scalable LinUCB算法，通过动态低秩参数化设计矩阵的逆Cholesky风格因子，使其能在更新逆矩阵时保持记忆效率和计算效率。通过使用投影分裂积分器进行动态低秩近似，其每步平均更新成本为O(dr)，存储成本也为O(dr)，其中r是近似秩。", "innovation": "Scalable LinUCB算法通过动态低秩参数化逆Cholesky因子来更新设计矩阵的逆，实现了快速且低内存的操作。提出了一系列数值稳定的秩-1和批次更新方法，这些方法可以维持逆矩阵而不直接构建整个矩阵。为了控制内存增长，采用了投影分裂积分器进行动态低秩近似，实验表明该算法在处理大规模动作空间的推荐系统中的效果显著。", "conclusion": "实验结果表明，我们的算法在大规模动作空间推荐系统中是有效的。Scalable LinUCB算法的推理复杂度为每动作评估O(dr)。"}
{"llm_update_time": "20251023", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.19376", "html_url": "https://arxiv.org/abs/2510.19376", "title": "扩散模型在动力系统优化基准测试", "title_en": "Optimization Benchmark for Diffusion Models on Dynamical Systems", "authors": "Fabian Schaipp", "background": "传统的优化技术评估常常忽视对扩散模型训练的考量。本文旨在通过几种最新的优化算法对训练扩散模型进行基准测试，特别是在去噪流动轨迹的训练中。研究还发现了Muon和SOAP在效率上的显著优势，它们相比AdamW可以降低18%的最终损失。此外，文章还回顾了近期关于模型训练过程中学习率调度和Adam与随机梯度下降（SGD）性能差异的现象，将这些现象放在扩散模型训练的背景下进行探讨和分析。", "innovation": "本文提出了一种新的基准测试方法，用于评估最新的优化算法在扩散模型训练中的表现。特别是，Muon和SOAP被证明是AdamW的有效替代方案，能够显著降低最终损失。此外，文章还重新审视了模型训练过程中的一些现象，包括学习率调度对训练动态的影响，以及Adam与SGD之间的性能差距。", "conclusion": "研究结果表明，Muon和SOAP在训练扩散模型时表现出色，提供了低于18%的最终损失。此外，研究还表明，优化算法的选择对扩散模型的重要性和学习率调度的影响对模型收敛时间和效果至关重要。"}
{"llm_update_time": "20251023", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.19305", "html_url": "https://arxiv.org/abs/2510.19305", "title": "FrogDeepSDM：使用多模态数据和伪缺损补充改进青蛙计数和分布预测", "title_en": "FrogDeepSDM: Improving Frog Counting and Occurrence Prediction Using Multimodal Data and Pseudo-Absence Imputation", "authors": "Chirag Padubidri,Pranesh Velmurugan,Andreas Lanitis,Andreas Kamilaris", "background": "监测物种分布对于保护工作至关重要，可以评估环境影响并制定有效的保护策略。传统的数据收集方法，如公民科学，虽然提供了有价值的见解，但在覆盖范围和完整性方面仍然有限。物种分布建模（SDM）通过使用出现数据和环境变量来预测大型地区内物种的存在，有助于弥补这些不足。在本研究中，我们通过应用深度学习和数据插补技术，结合“EY - 2022生物多样性挑战”数据集，增强了青蛙（Anura）的SDM准确性。实验结果表明，数据平衡显著提高了模型性能，将青蛙计数任务的平均绝对误差（MAE）从189降低到29。特征选择确定了影响出现的关键环境因素，优化了输入以保持预测准确性。多模态集成模型，整合了土地覆盖、NDVI和其他环境输入，在不同数据稀疏或不完整的情况下表现出稳健的一般化。结合图像和表格数据提高了青蛙计数和栖息地分类的准确性，分别达到了84.9%的准确性和0.90的AUC值。研究强调了多模态学习和数据预处理技术（如平衡和插补）在数据稀疏或不完整时提高预测生态建模的潜力，从而实现更精确和可扩展的生物多样性监测。", "innovation": "1. 通过应用深度学习和数据插补技术提升了青蛙的SDM准确性。\n2. 通过数据平衡显著提高了模型性能，将MAE从189降低到29。\n3. 通过特征选择确定了关键环境因素，优化了输入以保持预测准确性。\n4. 多模态集成模型整合了土地覆盖、NDVI和其他环境输入，优于单一模型，并在不同地区显示出稳健的一般化。\n5. 结合图像和表格数据提高了青蛙计数和栖息地分类的准确性，分别达到了84.9%的准确性和0.90的AUC值。", "conclusion": "该研究表明，通过多模态学习和数据预处理技术，如数据平衡和插补，即使在数据稀疏或不完整的情况下，也可以提高预测生态建模的准确性，从而促进更精确和可扩展的生物多样性监测，有助于更好地制定保护措施。"}
{"llm_update_time": "20251023", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.19385", "html_url": "https://arxiv.org/abs/2510.19385", "title": "CPSVD: 通过保留列的奇异值分解提高大型语言模型压缩", "title_en": "CPSVD: Enhancing Large Language Model Compression via Column-Preserving Singular Value Decomposition", "authors": "Lin Xv,Jingsheng Gao,Xian Gao,Ting Li,Yuzhuo Fu", "background": "大型语言模型（LLMs）由于其庞大的规模面临重要瓶颈，需要高效的压缩技术。现有的基于奇异值分解（SVD）的方法将整个参数矩阵均一处理，忽略了不同矩阵部分的SVD逼近误差差异性，导致压缩效果不佳。因此，需要一种新的方法来改进SVD在LLM压缩中的应用，更好地处理不同矩阵部分的差异性误差。", "innovation": "提出了一种新的方法——列保持奇异值分解（CPSVD），通过智能分割参数矩阵来改进基于SVD的LLM压缩。CPSVD识别并直接保留高分解误差的矩阵列，仅对低误差的列应用SVD，同时确定两种策略之间的最优平衡点以最小化误差。此外，CPSVD根据不同矩阵在LLM中的固有异质性误差分配非均匀压缩率给不同模块，并遵守目标层压缩比，从而进一步提高压缩性能。", "conclusion": "大量的实验表明，CPSVD在压缩性能上持续优于现有的基于SVD的LLM压缩方法，在零样本任务上实现了更低的困惑度和更高准确性。"}
{"llm_update_time": "20251023", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.19384", "html_url": "https://arxiv.org/abs/2510.19384", "title": "基于动态质量评估的学习鲁棒性和可转移性的图-文本对齐", "title_en": "Learning Noise-Resilient and Transferable Graph-Text Alignment via Dynamic Quality Assessment", "authors": "Yuhang Liu,Minglai Shao,Zengyi Wo,Yunlong Chu,Bing Hao,Shengzhong Liu,Ruijie Wang,Jianxin Li", "background": "在大规模网络应用中，如搜索引擎、推荐系统和知识发现，预训练图基础模型（GFMs）在文本标记图（TAGs）上的训练是至关重要的。然而，现有的CLIP风格的图-文本对齐模型存在两个主要问题：它们假定节点和文本之间有一对一的对应关系，忽视了真实世界图中存在的多对多关系；同时依赖于固定对齐目标，这些目标在面对数据质量波动时变得不稳定。", "innovation": "提出ADAligner，一种动态的质量感知图-文本对齐框架，它可以根据监督质量实时调整表征之间的多对多或一对一关系，从而促进软的子图水平多对多对齐，并在噪声条件下突出可靠的一对一对齐。此外，该框架理论上证明了动态机制构成了稳定的负反馈过程，具有收敛性和鲁棒性。", "conclusion": "通过对九个不同TAG数据集的全面实验，ADAligner在零样本/少量样本节点分类、链接预测和跨模态检索任务中，比先前的图-文本对齐模型表现更好。ADAligner能够在噪声监督环境下保持较强的鲁棒性，并将预训练速度提高约2至3倍，这对于网络环境中的图-文本表示学习具有广泛的实际应用前景。"}
{"llm_update_time": "20251023", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.19399", "html_url": "https://arxiv.org/abs/2510.19399", "title": "具备傅里叶增强特征的物理知情神经网络的迭代训练", "title_en": "Iterative Training of Physics-Informed Neural Networks with Fourier-enhanced Features", "authors": "Yulun Wu,Miguel Aguiar,Karl H.Johansson,Matthieu Barreau", "background": "物理知情神经网络（PINNs）在训练过程中存在频谱偏置的问题，即神经网络倾向于首先学习低频特征。这个问题在许多训练算法中普遍存在，并对_PINNs_的性能产生负面影响。为了解决这个问题，本文探讨了一种名为IFeF-PINN的新算法，旨在解决频谱偏置问题。该算法通过随机傅里叶特征来丰富潜在空间，从而引入高频分量，使得网络在训练过程中能够更好地捕捉高频特征。", "innovation": "本文提出的IFeF-PINN算法通过分两阶段训练来克服频谱偏置问题：首先是估计特征空间的基，然后进行回归以确定增强基函数的系数。该算法证明了对于线性模型，收敛问题是凸的，并证明了该迭代训练方案的收敛性。特别地，随机傅里叶特征增强了网络的表达能力，使得网络可以更准确地逼近高频偏微分方程。广泛的数值评估显示，该方法在经典基准问题上的性能优于最先进的算法，且在频域上的逼近效果更好。", "conclusion": "本文通过引入具备傅里叶增强特征的物理知情神经网络(IFeF-PINN)算法，有效解决了PINNs在高频特征表达上的难题。执行一系列数值实验后，IFeF-PINN展示出优于现有算法的性能，并且在不同频段上均表现出优于其它方法的逼近能力。"}
{"llm_update_time": "20251023", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.19421", "html_url": "https://arxiv.org/abs/2510.19421", "title": "FairNet：通过对比条件LoRA动态确保公平性而不损失性能", "title_en": "FairNet: Dynamic Fairness Correction without Performance Loss via Contrastive Conditional LoRA", "authors": "Songqi Zhou,Zeyuan Liu,Benben Jiang", "background": "确保机器学习模型的公平性是一个关键挑战。现有的去偏方法通常会牺牲性能，依赖于静态的纠正策略，并且难以应对数据稀疏的问题，尤其是在少数群体中更为明显。此外，它们对敏感属性的利用往往不尽如人意，要么过度依赖完整的标签标注，要么完全忽略这些属性。", "innovation": "我们提出了一种名为FairNet的新框架，用于动态、实例级别的公平性纠正。FairNet将偏见检测器与条件低秩适应（LoRA）集成，仅对被识别为偏见的实例进行公平性纠正机制的激活，从而在无偏实例上保持性能。一个重要贡献是设计了一种新的对比损失函数来训练LoRA模块，旨在减少不同敏感群体内部表示的差异，并有效解决少数群体的欠拟合问题。FairNet框架能够灵活处理完整、不完整或完全缺乏敏感属性标签的情况。理论上，当偏差检测器的TPR/FPR在适度范围内时，FairNet能够在不损害整体模型性能的情况下增强最差群体的性能，并有可能带来轻微的性能提升。", "conclusion": "全面的实证评估表明，FairNet在视觉和语言基准测试中都有效。理论分析表明，FairNet可以在不降低整体模型性能的情况下改善最坏群体的性能，并可能稍有性能提升。"}
{"llm_update_time": "20251023", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.19389", "html_url": "https://arxiv.org/abs/2510.19389", "title": "ARA: 自适应秩分配以实现高效的大规模语言模型SVD压缩", "title_en": "ARA: Adaptive Rank Allocation for Efficient Large Language Model SVD Compression", "authors": "Lin Xv,Jingsheng Gao,Xian Gao,Ting Liu,Yuzhuo Fu", "background": "在大规模语言模型(LLL)压缩领域，奇异值分解(SVD)是一种广泛研究和采用的低秩分解技术。SVD主要应用于线性模块上，而大语言模型中的线性模块与其他非线性组件相隔，因此SVD只能独立应用于每个线性模块。在全局压缩比约束下，确定不同线性模块的合适秩选择成为一个关键问题。现有的方法，如启发式算法和基于掩码的训练，在解决这一挑战方面取得了进展。然而，这些方法仍存在一些局限性：启发式算法在受限区域内探索解空间，而基于掩码的训练难以有效地捕捉奇异值谱和可训练参数之间的关系。更重要的是，当前方法忽视了关键特性，即在压缩比为1时增益函数是非光滑的，这往往导致训练过程陷入次优的局部极值。", "innovation": "本文提出了一种自适应秩分配（ARA）方法。具体地说，（1）ARA引入了一种专门的掩码设计，以实现保留秩与可训练参数之间的高效映射和更新；（2）它采用额外的损失函数来指导参数选择，以达到全局最优解。实验结果表明，ARA在80%压缩比下，于LLaMA2-7B模型实现了最佳性能。ARA将WikiText2的困惑度从8.38降至6.42，并在零样本任务中提高了平均准确率9.72个百分点，相比均匀压缩具有明显优势。", "conclusion": "实验结果表明，ARA方法在基于SVD的大规模语言模型压缩中通过秩分配实现了最先进的性能。具体应用在LLaMA2-7B模型上，80%压缩比下，ARA在WikiText2上的困惑度显著降低，并在零样本任务中明显提高了平均准确率。"}
{"llm_update_time": "20251023", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.19425", "html_url": "https://arxiv.org/abs/2510.19425", "title": "神经变分dropout过程", "title_en": "Neural Variational Dropout Processes", "authors": "Insu Jeon,Youngjin Park,Gunhee Kim", "background": "学习推断条件后验模型是实现鲁棒元学习的关键步骤。现有的元学习方法需要全局且共享的神经网络能够快速重新配置为新任务，尤其是在多任务少量样本学习的场景中。", "innovation": "本文提出了一种新的贝叶斯元学习方法——神经变异dropout过程(NVDPs)。NVDPs通过特定任务的dropout模型条件后验分布，并利用低秩伯努利专家元模型，高效地从少量观察上下文中映射dropout率。此外，NVDPs还利用了基于整个任务数据的新型先验，以优化在归一化可变推理中的条件dropout后验。", "conclusion": "实验表明，所提出的方法在少量样本学习任务如1D随机回归、图像补全和分类中表现出色。NVDPs能够在广泛的功能不确定性情况下鲁棒地近似任务特定的dropout率。"}
{"llm_update_time": "20251023", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.19383", "html_url": "https://arxiv.org/abs/2510.19383", "title": "LMFD:潜在单调特征发现", "title_en": "LMFD: Latent Monotonic Feature Discovery", "authors": "Guus Toussaint,Arno Knobbe", "background": "许多系统随着时间推移而老化、退化或以某种方式缓慢进行。监测这些系统时，传感器数据中可能存在某种形式的“年龄”信息，但可用的传感器可能无法直接提供这些信息。因此，本文研究的任务是从多变量时间序列中提取潜在的“年龄”代理特征，即使没有明确的“年龄”数据。研究认为，找到一个足够单调的传感器或传感器组合函数，可以作为所需代理特征。利用精心定义的语法和优化单调性（即时间与候选公式之间绝对斯皮尔曼等级相关性），提出的系统生成候选特征，并通过单调性进行拟合和评估。该方法在人工生成的数据集和两个实际世界数据集中的实验中得到了验证，结果表明系统能够将单调性较低的传感器组合成单调性较高的潜在特征。对于InfraWatch的实际世界数据集，两个单独绝对斯皮尔曼秩相关性分别为0.13和0.09的特征可以被合并成一个绝对斯皮尔曼秩相关性为0.95的代理特征，这表明该方法能够找到可解释的方程，可以作为系统“年龄”的代理特征。", "innovation": "本文提出了一种新的方法LMFD（Latent Monotonic Feature Discovery，潜在单调特征发现），该方法通过以下创新实现特征的提取和组合：1.使用精心定义的语法来优化求解单变量函数，确保时间序列中增加的单调性；2.采用绝对斯皮尔曼等级相关性来衡量单调性，并利用单调性高的特征作为潜在的“年龄”代理特征；3.能够将单独单独单调性较低的传感器组合成单调性较高的潜在特征，并证明该方法在实际数据集中的有效性，展示了其提取可解释的特征以作为“年龄”代理的潜力.", "conclusion": "本文通过系统验证，在人工生成的数据集和实际世界数据集中的实验表明，提出的LMFD方法能够在单调性较低的传感器特征中生成单调性较高的潜在特征，这些特征可以作为系统的“年龄”代理。特别是在InfraWatch的结构健康监测项目中，该方法展示了其独特能力，能够从单调性仅为0.13和0.09的特征中生成一个新的单调性为0.95的代理特征，这表明该方法具有很高的可解释性和实际应用价值。"}
{"llm_update_time": "20251023", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.19427", "html_url": "https://arxiv.org/abs/2510.19427", "title": "重访鲁棒性与普遍性的关系", "title_en": "Revisiting the Relation Between Robustness and Universality", "authors": "M. Klabunde,L. Caspari,F. Lemmerich", "background": "本文旨在重新审视Jones等人（2022年）提出的修改后的普遍性假设，该假设认为针对特定任务训练的对抗鲁棒模型在表现上非常相似。研究者们希望通过实验验证这一假设，特别是检查其在不同数据集上的普遍性。", "innovation": "研究者们提出了一个新颖的视角，即鲁棒性与普遍性之间的关系并非绝对，而是在特定情况下部分适用。通过简单的重训练分类器，可以获得更普遍的行为表现。", "conclusion": "研究结果表明，神经网络在特定情况下表现出部分普遍性，而对于严格的普遍性概念则持有怀疑态度。此外，研究者还发现预测行为的不一致性源自分类层，但通过简单地重新训练分类器，可以实现更普遍的预测行为。"}
{"llm_update_time": "20251023", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.19476", "html_url": "https://arxiv.org/abs/2510.19476", "title": "基于链式思维监控的安全案例实施之路", "title_en": "A Concrete Roadmap towards Safety Cases based on Chain-of-Thought Monitoring", "authors": "Julian Schulz", "background": "随着AI系统接近危险的能力水平，传统的安全性论证变得不够充分，因此需要新的方法来确保安全性。本文提出了一种基于推理模型的链式思维（CoT）监测的安全案例构建路线图，并概述了我们的研究计划。", "innovation": "本文提出了两种基于CoT监测的安全观点：一是模型在不使用CoT时没有危险的能力；二是对于由CoT启用的任何危险能力，CoT监测能够检测到它们。此外，作者系统地分析了对监控能力的两种威胁，并提出了维护CoT忠诚度的技术，以及可能从不可监控的CoT中提取可监控的CoT的方法。", "conclusion": "最后，作者通过建立预测市场来评估基于CoT监控的安全案例的可行性，以综合评估关键技术里程碑对其可行性的影响。"}
{"llm_update_time": "20251023", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.19422", "html_url": "https://arxiv.org/abs/2510.19422", "title": "利用大语言模型信念进行大语言模型去学习", "title_en": "LLM Unlearning with LLM Beliefs", "authors": "Kemou Li,Qizhou Wang,Yue Wang,Fengpeng Li,Jun Liu,Bo Han,Jiantao Zhou", "background": "大型语言模型在训练过程中，存在内置化敏感或有害内容的风险，这可能在模型输出中重新出现。现有的去学习方法通常依赖于梯度上升及其变体来降低特定目标响应的出现概率。然而，这种方法会引发一个关键的副作用：概率质量被重新分配到高可能性区域，这些区域通常与目标的语义相关重新表达相对应。这被称为挤压效应，解释了为什么许多方法仅导致虚假的去学习，且这个问题进一步被自动化评价指标（如ROUGE、真实比）所掩盖，这些指标错误地报告了实际的成功率。", "innovation": "本文提出了一个名为Bootstrapping (BS)的框架，该框架明确了挤压效应与模型自身高置信度生成之间的联系，即模型信念。因为模型信念本身捕捉了挤压效应中的非常高可能性区域，将它们直接纳入去学习的目标中可以有效地对抗挤压效应。通过同时抑制目标响应和模型信念，BS-T（令牌）能够衰减高概率的令牌，而BS-S（序列）则完全移除高置信度的生成。这种方法实现了更彻底的遗忘，同时保留了必要功能。跨多个基准评估和不同模型家族的广泛实验证明了该方法的有效性。", "conclusion": "本文提出了一种名为Bootstrapping的框架，通过考虑模型信念来有效对抗挤压效应，从而实现更彻底的遗忘，同时保持必要的功能。通过多种基准测试和不同模型家族的实验，验证了该方法的有效性。"}
{"llm_update_time": "20251023", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.19474", "html_url": "https://arxiv.org/abs/2510.19474", "title": "g-DPO: 可扩展的蛋白质语言模型偏好优化框架", "title_en": "g-DPO: Scalable Preference Optimization for Protein Language Models", "authors": "Constance Ferragu,Jonathan D. Ziegler,Nicolas Deutschmann,Arthur Lindoulsi,Eli Bixby,Cradle ML Team", "background": "直接偏好优化（Direct Preference Optimization, DPO）是一种能够使蛋白质语言模型与实验设计目标保持一致的有效方法。然而，DPO面临一个可扩展性瓶颈：带标签序列的数量越多，训练对的数量就会呈平方增长，即使是中等规模的数据集也会导致训练时间变得难以承受。", "innovation": "提出了一种新的框架g-DPO，它(i) 使用序列空间聚类来剪枝冗余训练对并保持训练信号，(ii) 通过基于组的近似方法来分摊似然计算，从而提高了训练效率。", "conclusion": "g-DPO在三个蛋白质工程任务上保持了与标准DPO在计算内和实验内表现上的统计上无法区分的结果，但收敛速度提高了1.8到3.7倍，当数据集规模增大时，预期会有更大的收益。"}
{"llm_update_time": "20251023", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.19479", "html_url": "https://arxiv.org/abs/2510.19479", "title": "图去学习遇见基于影响力的负偏好优化", "title_en": "Graph Unlearning Meets Influence-aware Negative Preference Optimization", "authors": "Qiang Chen,Zhongze Wu,Ang He,Xi Lin,Shuo Jiang,Shan You,Chang Xu,Yi Chen,Xiu Su", "background": "最近图去学习模型的进步通过从根本上保持节点表示不变来增强模型的效用，同时使用梯度上升法在遗忘集中实现去学习。然而，这种方法在去学习过程中由于梯度上升的快速发散速度而导致模型效用急剧下降。", "innovation": "本文引入了INPO（基于影响力的负偏好优化）框架，该框架关注减缓发散速度并提高模型效用对去学习过程的鲁棒性。首先分析了NPO（负偏好优化）具有较慢的发散速度，并从理论上提出了去学习高影响力的边可以减少去学习的影响。设计了基于影响力的信息函数以放大未学习边的影响，缓解遗忘集与保留集之间的紧密拓扑耦合，并通过去除法快速估算每条边的影响。此外，从拓扑学的角度提出了拓扑熵损失，以避免在去学习过程中过度丢失局部结构的信息。", "conclusion": "在五个真实数据集上进行的大量实验表明，基于INPO的方法在所有遗忘质量度量上都达到了最佳性能，同时保持了模型的效用。代码可以在[此处](this https URL)获取。"}
{"llm_update_time": "20251023", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.19507", "html_url": "https://arxiv.org/abs/2510.19507", "title": "通过团队合作检测和缓解LLM幻觉", "title_en": "Teaming LLMs to Detect and Mitigate Hallucinations", "authors": "Demian Till,John Smeaton,Peter Haubrick,Gouse Saheb,Florian Graef,David Berman", "background": "近期的研究显示，通过一致性方法在大型语言模型（LLM）中进行幻觉检测和缓解，这些方法通常涉及从单个LLM对给定提示进行采样的多个响应。这类方法有助于抵消由于训练数据的不完美性所导致的限制，例如偏见和在部署时信息的不足代表等，这些问题可能导致LLM产生幻觉。", "innovation": "本文展示了将来自不同训练数据、训练策略和模型架构的多个LLM的响应结合在一起的方法，即跨多个LLM模型团队的‘联盟一致性’方法，这种方法能够进一步提高幻觉检测和缓解的能力，超出单模型一致性方法的范围。此外，这种方法还常伴随着推理成本的降低，部分抵消了单模型一致性方法的一大缺点。", "conclusion": "本文通过评估来自15个LLM模型池的多个模型团队，研究了在这种联盟一致性方法中将不同LLM组合在一起的条件，并展示了这种方法通常带来的性能提升与减少的推理成本。"}
{"llm_update_time": "20251023", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.19482", "html_url": "https://arxiv.org/abs/2510.19482", "title": "ELUTQ：边缘设备上部署大型语言模型的高效LUT感知量化", "title_en": "ELUTQ: Efficient LUT-Aware Quantization for Deploying Large Language Models on Edge Devices", "authors": "Xin Nie,Liang Dong,HaiCheng Zhang,JiaWang Xiao,G. Sun", "background": "在基于CPU的边缘设备上部署大型语言模型（LLMs）对于实现设备端智能和扩大人工智能的可及性至关重要。然而，由于边缘设备计算和内存资源有限，这一部署仍然极具挑战性。特别是在边缘推理中，内存使用量和延迟是主要瓶颈。虽然权重量化可以有效减少内存消耗，但现有的硬件友好型方法往往依赖于均匀量化，这并不适合权重分布并且在低位宽下会导致较高的去量化开销。", "innovation": "本文提出了一种高效的量化框架ELUTQ，引入了一种新的量化格式——分层线性量化（HLQ）。HLQ能够更好地捕捉权重的统计特性，而不会增加位级线性查找表（LUT）为基础的矩阵乘法操作（GEMM）的计算成本，从而消除了去量化开销。HLQ是现有量化算法的补充，可以无缝集成到各种量化流程中。针对设备端高效部署，ELUTQ还提供了端到端推理优化的CPU内核。", "conclusion": "实验表明，对于LLaMA3-8B模型，在3比特精度下HLQ可以将困惑度降低约8%，2比特精度下降低约85%（采用后训练量化），并且在不到一小时内完成了量化过程。通过有效的微调，HLQ在2比特精度下进一步改善了性能，仅需两小时内即可完成。具体到推理效率，我们的2比特LLaMA2-7B模型在4线程和批量大小为1的情况下，可以在苹果M2芯片上达到每秒超过25个令牌。"}
{"llm_update_time": "20251023", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.19531", "html_url": "https://arxiv.org/abs/2510.19531", "title": "基于混淆实例原则的在线线性二次控制", "title_en": "The Confusing Instance Principle for Online Linear Quadratic Control", "authors": "Waris Radji(Scool, CRIStAL),Odalric-Ambrym Maillard(Scool, CRIStAL)", "background": "该研究重新审视了在未知动力学条件下利用模型为基础的强化学习控制线性系统具有二次成本的问题。传统的解决方法，如不确定性的乐观原则和汤普森采样，这些方法起源于多臂赌机问题（MABs），但存在实际应用中的局限性。", "innovation": "该研究提出了基于混淆实例（CI）原则的控制策略，这一原则在MABs和离散MDP中建立了后悔下界，并是MED家族算法的核心。这些算法在各种设置中以其渐近最优性而闻名。研究通过利用LQR策略的结构和敏感性与稳定性的分析，开发了MED-LQ。这项新策略将CI和MED的原则扩展到了大规模MDP的应用。", "conclusion": "在全面的控制测试套件中，MED-LQ展示了不同的场景中的竞争力，同时也突显了其在大规模MDP中的广泛应用潜力。"}
{"llm_update_time": "20251023", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.19517", "html_url": "https://arxiv.org/abs/2510.19517", "title": "大规模营销优化中观测数据和实验数据的层级决策导向因果学习", "title_en": "Bi-Level Decision-Focused Causal Learning for Large-Scale Marketing Optimization: Bridging Observational and Experimental Data", "authors": "Shuli Zhang,Hao Zhou,Jiaqi Zheng,Guibin Jiang,Bing Cheng,Wei Lin,Guihai Chen", "background": "在线互联网平台需要采用复杂营销策略以优化用户留存和平台收益——这是一个经典资源分配问题。传统方法采用两阶段流程：机器学习（ML）预测个人治疗效果，随后通过运筹学（OR）优化进行决策。这种方法面临两个基本的技术挑战：首先，预测与决策的不对齐：传统ML方法专注于提高预测准确性，而忽视了下游优化目标，导致改进的预测指标无法转化为更好的决策。其次，偏差与方差的困境：观测数据存在多重偏差（如选择偏差、位置偏差）；尽管实验数据（如随机控制试验）是无偏的，但它通常稀缺且成本高昂，因此导致高方差估计。", "innovation": "我们提出了一种层级决策导向的因果学习方法（Bi-DFCL），系统地解决了这些挑战。首先，我们利用实验数据开发了一个无偏的OR决策质量估计器，通过代理损失函数指引ML模型训练。其次，我们建立了一个双层优化框架，联合利用观测和实验数据，通过隐式梯度解决。这种新颖的表述允许我们的无偏OR估计器纠正从有偏差的观测数据中获得的学习方向，从而实现最优的偏差-方差权衡。", "conclusion": "广泛地在公开基准、工业营销数据集和大规模在线A/B测试中进行的评估显示了Bi-DFCL的有效性，显示出与现有最佳方法相比的统计显著性改进。目前，Bi-DFCL已经部署在海外市场最大的在线餐饮配送平台之一的美团上。"}
{"llm_update_time": "20251023", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.19498", "html_url": "https://arxiv.org/abs/2510.19498", "title": "节能且无需去量化：一种基于SPiking神经网络的显著值缓解量化大语言模型", "title_en": "Energy-Efficient and Dequantization-Free Q-LLMs: A Spiking Neural Network Approach to Salient Value Mitigation", "authors": "Chenyu Wang,Zhanglu Yan,Zhi Zhou,Xu Chen,Weng-Fai Wong", "background": "在大语言模型（LLMs）的时代，权重-激活量化有助于将模型安装在边缘设备上，通过减少内存和计算位宽。然而，对于能量受限的硬件，三个挑战仍然存在：（1）即使经过量化，乘加操作（MAC）仍然不可避免，并且继续主导能源消耗；（2）去量化（或每张量/通道重新缩放）引入了额外的算术和数据移动，增加了延迟和能源消耗；（3）均匀的参数位宽修剪了重要值，而当前的矩阵硬件和内存中跨通道混合精度通常不切实际。与这些挑战相对，基于大脑的突触神经网络（SNNs），由于它们基于二元脉冲的信息表示和积分放电（IF）范式，自然支持混合精度存储和节能计算，通过将复杂的MAC替换为时间累加（ACC）从而实现混合精度计算。因此，激发了我们提出SpikeQuant的设计思想，即选择性地将混合精度量化应用于具有明显值的激活，并将其重新编码为二元脉冲计数，从而实现不同位宽的动态混合存储。", "innovation": "提出了SpikeQuant，这是一种基于SNNs的方法，通过将具有明显值的激活选择性地应用混合精度量化，并将其重新编码为二元脉冲计数，实现动态不同位宽的混合存储。通过在积分放电机制的阈值中嵌入量化标度，我们的方法可以在不进行显式去量化的情况下进行节能线性变换。实验结果显示，SpikeQuant在W4A4量化下始终保持接近FP16困惑度的同时将能源成本降低至现有方法的4.6倍，突显了其在准确节能的大语言模型部署方面的有效性。", "conclusion": "SpikeQuant在W4A4量化下实现了接近FP16困惑度的同时显著降低了能源消耗，是准确且节能的大语言模型部署的有效方法。"}
{"llm_update_time": "20251023", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.19514", "html_url": "https://arxiv.org/abs/2510.19514", "title": "从原型到稀疏心电图解释：基于SHAP的多变量时间序列多类分类反事实解释", "title_en": "From Prototypes to Sparse ECG Explanations: SHAP-Driven Counterfactuals for Multivariate Time-Series Multi-class Classification", "authors": "Maciej Mozolewski,Betül Bayrak,Kerstin Bach,Grzegorz J. Nalepa", "background": "在可解释人工智能（XAI）中，由于其在医疗保健等领域中可操作和可解释的洞察潜力，时间序列的实例基础解释受到了越来越多的关注。现有的先进模型的可解释性面临着挑战，因此本文提出了一种以原型驱动的框架，用于针对12导联心电图分类模型生成稀疏的反事实解释，以应对这些挑战。该框架通过SHAP基准则对关键信号段进行识别并转换为区间规则，利用动态时间规整（DTW）和质心聚类提取代表性原型，并将这些原型与查询R-尖峰对齐以与被解释样本保持一致性，同时修改了78%的原始信号，但仍保持了81.3%的整体有效性和43%的时序稳定性。该方法评估了三种算法变体：原始、稀疏和对齐稀疏。针对不同类别的性能从心肌梗塞（MI）的98.9%有效性到心肌肥厚（HYP）检测的13.2%挑战。该方法支持近实时生成（<1秒）临床有效的反事实解释，并为交互式解释平台提供了基础。本文的研究结果制定了生理感知的反事实解释设计原则，并指出了用户控制的解释接口在临床部署中的可能性路径。", "innovation": "提出了一种新型的框架，用于生成稀疏、基于原型的反事实解释，特别应用于12导联心电图分类模型。该框架结合了SHAP解释和动态时间规整、质心聚类等技术，能够有效提高解释的精准度与效率，为医疗领域的AI诊断系统提供了新的解释机制。", "conclusion": "研究为AI在医疗诊断领域的应用提供了新的解释机制，通过生理感知的反事实解释，支持了在近实时场景中生成有效的临床解释。同时，该研究还提出了设计生理感知反事实解释的原则，并设想了未来向用户可控的解释界面过渡的可能性。"}
{"llm_update_time": "20251023", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.19530", "html_url": "https://arxiv.org/abs/2510.19530", "title": "未知求优：基于能量模型和强化学习的黑盒贝叶斯优化", "title_en": "Optimizing the Unknown: Black Box Bayesian Optimization with Energy-Based Model and Reinforcement Learning", "authors": "Ruiyao Miao,Junren Xiao,Shiya Tsang,Hui Xiong,Yingnian Wu", "background": "现有的Bayesian Optimization (BO) 方法通常通过平衡探索和利用来优化昂贵的目标函数。然而，这些方法往往受到显著的一步偏差的影响，可能导致朝着局部最优收敛，并在复杂或高维任务中表现不佳。最近，Black-Box Optimization (BBO) 在多种科学和工程领域取得了成功，尤其是在函数评估昂贵且无法获取梯度的情况下。", "innovation": "提出了一种结合Gaussian Processes (GP) 作为局部指导与Energy-Based Model (EBM) 来捕捉全局结构信息的方法，将每次Bayesian Optimization 迭代视为Markov Decision Process (MDP)，并使用Proximal Policy Optimization (PPO) 进行自适应多步前瞻，动态调整探索的深度和方向，以有效克服传统BO 方法的局限性。", "conclusion": "通过在合成和实际基准上进行广泛的实验证明了REBMBO 的优越性能，并进一步分析不同GP 配置跨越各种情况下其适应性和鲁棒性进一步得到突出。"}
{"llm_update_time": "20251023", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.19623", "html_url": "https://arxiv.org/abs/2510.19623", "title": "使用生成模型学习和模拟建筑疏散模式以提高安全设计", "title_en": "Learning and Simulating Building Evacuation Patterns for Enhanced Safety Design Using Generative Models", "authors": "Jin Han,Zhe Zheng,Yi Gu,Jia-Rui Lin,Xin-Zheng Lu", "background": "疏散模拟对于建筑物安全设计至关重要，确保了合理的疏散路线规划。然而，传统的疏散模拟依赖于精细的建模和大量参数，这使得它们在早期设计阶段的快速迭代过程中难以应用。因此，本文旨在提出DiffEvac，这是一种基于生成模型（GMs）的学习方法，用于高效疏散模拟和增强安全设计。", "innovation": "该研究提出了一种名为DiffEvac的新方法，通过生成模型学习建筑物的疏散模式，实现了与现有使用条件GANs和RGB表示的研究相比，SSIM提升37.6%，PSNR提升142%，并提高了16倍的模拟速度，使模拟时间减少到2分钟。此外，提出的解耦特征表示方法将布局、人群密度等物理特征嵌入到生成模型中，进一步提升了模拟效果。", "conclusion": "通过提出的方法，可以在早期设计阶段更加高效地进行疏散模拟，加速疏散路线的快速设计迭代和调整，并为智能建筑设计中的未来安全优化提供了新的见解和技术途径。此外，该方法降低了建模负担，支持大规模的‘什么如果’探索，并能够与多目标设计工具进行集成。"}
{"llm_update_time": "20251023", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.19611", "html_url": "https://arxiv.org/abs/2510.19611", "title": "气候意识深度学习框架用于通用可推广的疫情预报", "title_en": "A Climate-Aware Deep Learning Framework for Generalizable Epidemic Forecasting", "authors": "Jinpyo Hong,Rachel E. Baker", "background": "疫情爆发的精确预测对于有效的公共卫生应对和疫情控制至关重要。尽管机器学习（ML）方法的时间序列预测增加为改进疫情预报提供了令人振奋的途径，特别是在COVID-19疫情期间，ML模型已用于预测疫情趋势。然而，将ML模型应用于预测地方性疾病的预报却仍然未被充分探索。", "innovation": "本文提出了一种基于XGBoost+CNN+BiLSTM的深度学习混合框架ForecastNet-XCL，该框架针对地方性疾病的预测存在空白。ForecastNet-XCL通过结合高分辨率特征学习和捕捉长时间序列依赖机制，可基于气候和时间数据，在无需实时RSV监控的情况下，准确预测RSV感染病例数，预测周期可达100周。此外，该框架还带有利用气候控制滞后关系训练的自回归模块，并通过随机推断提供概率区间预报，以辅助决策。在34个美国州份的评估中，ForecastNet-XCL在多种场景下的性能优于统计基线、单一神经网络和传统集成方法，并保持了长时间预测的准确性。通过在气候多样数据集上训练，该模型在具有不规则或年度RSV模式的地区表现出更强的泛化能力。", "conclusion": "ForecastNet-XCL在效率、性能和不确定性感知设计方面表现出色，成为一个可部署的早期预警工具，适用于日益加剧的气候压力和有限的监控资源环境。"}
{"llm_update_time": "20251023", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.19634", "html_url": "https://arxiv.org/abs/2510.19634", "title": "无需预设矩阵的最小二乘求解器：其值、梯度及用途", "title_en": "Matrix-Free Least Squares Solvers: Values, Gradients, and What to Do With Them", "authors": "Hrittik Roy,Søren Hauberg,Nicholas Krämer", "background": "该论文指出，最小二乘法在现代机器学习中具有未被充分利用的巨大潜力，不仅仅是用来拟合线性模型。需要通过引入自定义梯度来将求解器转变成可微分的操作符，使其能够广泛应用于各种场景。", "innovation": "论文通过对最小二乘法进行改写，使其实现可微分操作，类似于神经网络层，从而开启了广泛的应用。具体实现了在大型模型中保持权重稀疏性、在评分生成模型中应用保守性约束以及基于预测性能调整高斯过程的超参数等。", "conclusion": "这项工作代表了开发可微分线性代数工具的下一步，并使这些工具能够被更广泛的机器学习实践者所使用。"}
{"llm_update_time": "20251023", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.19535", "html_url": "https://arxiv.org/abs/2510.19535", "title": "未知领域的洞察：分子数据的联邦多样性分析", "title_en": "Insights into the Unknown: Federated Data Diversity Analysis on Molecular Data", "authors": "Markus Bujotzek,Evelyn Trautmann,Calum Hand,Ian Hales", "background": "在制药领域，人工智能方法正在逐渐改变药物发现过程，但这些方法在工业应用中的转化受到了限制，主要原因是它们依赖于公开数据集，而这些数据集在规模和多样性方面未能充分涵盖制药公司的专有数据。联邦学习（FL）为其提供了一个有潜力的途径，可以将私有数据整合到隐私保护及协作模型训练中，跨越了数据孤岛。然而，这种联邦数据接入使完成依赖数据的特定任务，如估算数据集的多样性、执行有信息的分数据集操作和理解组合化学空间结构变得复杂。本文试图解决这一问题，通过研究联邦聚类方法在解开和表示分布分子数据方面的有效性，来填补这一空白。研究使用八种不同的分子数据集来评估三种方法：联邦k-均值（Fed-kMeans）、联邦主成分分析结合联邦k-均值（Fed-PCA+Fed-kMeans），以及联邦局部敏感哈希（Fed-LSH）与其集中式对应物的对比。评估使用标准的数学指标和一种新的基于化学的评估指标SF-ICF进行。大范围的评估和深入的可解释性分析表明了化学领域知识的重要性及在联邦多样性分析中的在客户端进行解释性分析的价值。", "innovation": "本文开创性地展示了如何使用联邦学习方法来分析和评价分布在不同数据孤岛上的分子数据的多样性。通过引入化学领域知识评价指标（SF-ICF）以及在不同联邦聚类方法（Fed-kMeans、Fed-PCA+Fed-kMeans 和 Fed-LSH）和其集中版本之间的比较，具体解决了联邦学习背后的隐私问题和跨数据孤岛的协作挑战。此外，文中通过大规模的基准测试和深入的可解释性分析，强调了化学领域知识和在客户端进行的解释性分析在联邦多样性分析中的重要性。", "conclusion": "本文的研究结果表明，采取联邦学习的方法能够有效改善制药领域中对分布分子数据多样性的理解和评价，通过化学领域知识和客户端解释性分析来增强联邦多样性分析的能力。这种方法既可以提高数据安全性，又能更好地理解混合化学空间，是未来药物发现中值得探索的方向。"}
{"llm_update_time": "20251023", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.19640", "html_url": "https://arxiv.org/abs/2510.19640", "title": "LoRA隐空间因子化", "title_en": "Latent Space Factorization in LoRA", "authors": "Shashi Kumar,Yacouba Kaloga,John Mitros,Petr Motlicek,Ina Kodrasi", "background": "低秩适应（LoRA）是一种广泛用于参数高效微调的方法。然而，现有的LoRA变体缺乏机制来显式地澄清学习低秩子空间内的任务相关信息，这可能限制了下游性能。传统的LoRA在将任务相关信息与剩余信息分开表示时存在局限性，引入FVAE-LoRA旨在改进这一问题，使编码器能够更有效地学习和分离关键特征和干扰特征。", "innovation": "FVAE-LoRA结合了变分自编码器（VAE）来学习两个不同的潜在空间，采用证据下界（Evidence Lower Bound）公式显式地促进潜在空间之间的因子化，专门分配一个潜在空间来处理任务相关特征，另一个来处理残差信息。这一创新实现了更有效的特征分离和干扰信号的减少，从而提高了模型在分布变化下的鲁棒性。", "conclusion": "对文本、音频和图像任务进行的广泛实验表明，FVAE-LoRA在标准LoRA的基础上实现了更优的性能。同时，错误关联评估也证实了FVAE-LoRA能够更有效地隔离与任务相关的信息，增强了模型在数据分布变化情况下的稳健性。该研究的代码已经在指定的网址上公开。"}
{"llm_update_time": "20251023", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.19643", "html_url": "https://arxiv.org/abs/2510.19643", "title": "时间序列中的重叠加权正交元学习器用于治疗效应估计", "title_en": "Overlap-weighted orthogonal meta-learner for treatment effect estimation over time", "authors": "Konstantin Hess,Dennis Frauen,Mihaela van der Schaar,Stefan Feuerriegel", "background": "在时间变化的环境中估计异质治疗效果（HTEs）极具挑战性，因为随预测时间窗的增加，观察到某些治疗序列的概率呈指数级下降。因此，观测数据中很少有支持许多可能治疗序列的支持，这导致了严重的重叠问题。现有的时间变化环境下元学习器通常假设足够的治疗重叠，因此在重叠低时会遭受估计方差膨胀的问题。", "innovation": "本文提出了一个新颖的重叠加权正交（WO）元学习器，用于估计时间变化环境中的异质治疗效果。该方法针对观察数据中干预治疗序列高概率获取的区域进行建模，提供了一种完全数据驱动的解决方案。通过开发一种新的Neyman-正交总体风险函数，我们可以最小化重叠加权的最优风险。WO-学习器具有Neyman正交的特性，使其对辅助函数的误指称具有鲁棒性。此外，WO-学习器完全是模型无感知的，可以应用于任何机器学习模型。通过广泛的实验，验证了新提出WO-学习器的优势。", "conclusion": "我们的新WO-学习器能够克服现有元学习器的问题，通过完全数据驱动的方法提供更可靠的异质治疗效果估算。"}
{"llm_update_time": "20251023", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.19705", "html_url": "https://arxiv.org/abs/2510.19705", "title": "通过分层推测编码实现快速推理", "title_en": "Fast Inference via Hierarchical Speculative Decoding", "authors": "Amir Globerson,Haim Kaplan,Yishay Mansour,Clara Mohri,Tal Schuster", "background": "Transformer语言模型通过自回归方式生成文本，导致推理延迟与生成的令牌数量成正比。推测性解码通过一个小模型快速提议令牌，而大目标模型并行验证，从而减少延迟而不牺牲输出质量。然而，存在一系列不同速度和准确性的候选小模型。", "innovation": "引入了一种分层推测解码（HSD）算法，该算法将这些小模型分层排列，每个模型提出令牌，随后更大的模型进行并行验证，直至大目标模型最终验证。我们推导了此类层级的预期延迟表达式，并表明可以通过多项式时间选择最优层级。", "conclusion": "实验结果显示，HSD相比单一小模型的最佳基准可以提供高达1.2倍的速度提升，证明了我们算法在减少生成延迟方面比以往技术更实用。"}
{"llm_update_time": "20251023", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.19675", "html_url": "https://arxiv.org/abs/2510.19675", "title": "受限内存条件下的微调训练动力学研究", "title_en": "Study of Training Dynamics for Memory-Constrained Fine-Tuning", "authors": "Aël Quélennec,Nour Hezbri,Pavlo Mozharovskyi,Van-Tam Nguyen,Enzo Tartaglione", "background": "随着深度神经网络模型的规模越来越大，而实际的部署环境又对资源有严格限制，高效的深度神经网络训练变得越来越重要。现有研究主要关注如何利用转移学习来提高训练效率和模型性能。本文则在这一背景下，基于模型的不同层对更新的重要性在架构上有所不同且可以先验确定，以及动态随机通道选择相比静态方法能提供更优的梯度逼近两个关键洞察，提出了TraDy这一新型的转移学习方案。", "innovation": "TraDy方案通过提出一种在预选层之间动态采样通道的方法，实现了在维持严格内存约束的同时，达到最佳的下游任务性能。该方法还通过最高可达到99%的激活稀疏度、95%的权重导数稀疏度以及97%的权重导数计算FLOPs减少，保证了高性能与低资源消耗之间的平衡。", "conclusion": "通过广泛的实验对比，TraDy在多种下游任务和架构中都达到了最先进的性能表现，同时严格遵守记忆限制。"}
{"llm_update_time": "20251023", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.19672", "html_url": "https://arxiv.org/abs/2510.19672", "title": "政策学习中的弃权", "title_en": "Policy Learning with Abstention", "authors": "Ayush Sawarni,Jikai Jin,Justin Whitehouse,Vasilis Syrgkanis", "background": "政策学习算法在个性化医疗和广告等领域被广泛应用于制定个性化的治疗方案。然而，大多数方法在预测不明确时仍然会强制执行决定，这在高风险场景中是很有风险的。因此，研究在不确定时政策学习中的弃权策略变得十分重要，即政策可以将决策推迟到默认安全选项或专家意见。弃权实现了一小部分奖励，在随机猜测的基础上增加，当政策弃权时。", "innovation": "提出了一个两阶段的学习器，首先识别一组接近最优的政策，然后从它们的不同意见中构建弃权规则。当已知倾向时，我们为作弊提供快速O(1/n)类型的后悔保证，并通过双重稳健(DR)目标将这些保证扩展到未知倾向的情况。还表明弃权是一个多功能的工具，直接应用于政策学习的核心问题：在不使用常见可实现性假设的情况下，在边际条件下提高了保证，通过规避小数据转移将其与分布稳健的政策学习联系起来，并支持安全政策改进，以确保与基准政策比有很大的概率改进。", "conclusion": "政策学习中的弃权提供了一种避免高风险预测错误的方法，通过容许一定的不确定性和委托决策给更加可靠的标准或专家，从而提供了更加稳健的决策策略。"}
{"llm_update_time": "20251023", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.19749", "html_url": "https://arxiv.org/abs/2510.19749", "title": "BATIS: 基于贝叶斯方法改进物种分布模型的方法", "title_en": "BATIS: Bayesian Approaches for Targeted Improvement of Species Distribution Models", "authors": "Catherine Villeneuve,Benjamin Akera,Mélisande Teng,David Rolnick", "background": "物种分布模型（SDMs）旨在基于环境变量预测物种分布，广泛用于监控和应对生物多样性的变化。尽管深度学习技术在SDMs中的应用在复杂和异质数据集上表现出色，但它们的有效性受到数据空间偏见的限制。", "innovation": "本文从贝叶斯视角重访深度SDMs，并引入了具有迭代更新先验预测功能的BATIS框架，以便在有限的观测数据下改进模型。同时，研究强调模型需要适当地捕捉即风险性和成因性不确定性，以有效结合细粒度的局部见解和更广生态模式。", "conclusion": "实证研究表明，贝叶斯深度学习方法能显著提高数据稀缺区域SDMs的可靠性，从而有助于生态理解和保护工作。"}
{"llm_update_time": "20251023", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.19753", "html_url": "https://arxiv.org/abs/2510.19753", "title": "当 Transformer 学到图连通性中的启发式算法时？", "title_en": "When Do Transformers Learn Heuristics for Graph Connectivity?", "authors": "Qilin Ye,Deqing Fu,Robin Jia,Vatsal Sharan", "background": "Transformer 模型经常难以学习通用化的算法，而是依赖于脆弱的经验策略。本文利用图连通性作为实验平台，对此现象进行了理论和实证的解释。", "innovation": "本文研究了一个简化的 Transformer 架构——去耦合 Transformer（disentangled Transformer），并证明了$L$层的模型有能力解决直径恰好为$3^L$的图问题，实现了等同于计算邻接矩阵幂的算法。文章分析了训练动力学，发现大多数训练实例在模型容量内会驱动正确的算法学习，而超出容量的实例则会驱动简单基于节点度数的启发式算法学习。", "conclusion": "限制训练数据在模型容量内可以促使标准和去耦合的 Transformer 学习精确的算法而非基于度数的启发式算法。"}
{"llm_update_time": "20251023", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.19773", "html_url": "https://arxiv.org/abs/2510.19773", "title": "The Tail Tells All: Estimating Model-Level Membership Inference Vulnerability Without Reference Models", "title_en": "The Tail Tells All: Estimating Model-Level Membership Inference Vulnerability Without Reference Models", "authors": "Euodia Dodd,Nataša Krčo,Igor Shilov,Yves-Alexandre de Montjoye", "background": "目前，成员推断攻击（MIAs）已经成为评估AI模型隐私风险的标运算。然而，最先进的攻击方法需要训练大量，往往是计算密集型的参考模型，这限制了它们的实用性。", "innovation": "本文提出了一种新型方法，可以在不使用参考模型的情况下评估模型级别的漏洞，即利用训练和测试分布来估计TPR在低FPR下的值。此外，还使用高损失区域内缺乏异常值来预测风险，并表明该方法能准确估计最先进的MIA攻击（LiRA）的模型级别漏洞，同时性能优于低成本攻击和其他分布差异度量。", "conclusion": "我们证明了使用非线性函数评估风险的方法具有潜力，在大型语言模型中也有应用前景。"}
{"llm_update_time": "20251023", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.19778", "html_url": "https://arxiv.org/abs/2510.19778", "title": "GaLLoP：基于梯度的低幅度参数稀疏学习", "title_en": "GaLLoP: Gradient-based Sparse Learning on Low-Magnitude Parameters", "authors": "Anand Choudhary,Yasser Sulaıman,Lukas Mauch,Ghouthi Boukli Hacene,Fabien Cardinaux,Antoine Bosselut", "background": "稀疏微调技术通过仅调整模型参数的稀疏子集来适应下游任务，但稀疏适应的效果依赖于选择最佳需要微调的模型参数。现有方法如LoRA、DoRA和SAFT在提升微调效果上有一定优势，但没有很好地平衡任务相关性和预训练知识的连贯性。", "innovation": "提出了一种新颖的基于梯度的稀疏微调技术GaLLoP，它仅微调在下游任务中有最大梯度幅度但预训练时幅度最小的模型参数。该方法优先选择高度任务相关但对预训练知识干扰最少的参数。", "conclusion": "实验表明，GaLLoP在LLaMA3 8B和Gemma 2B两个基模型上，能够稳健地提高或达到其他主流参数高效微调技术的同分布和异分布性能指标，还能有效缓解灾难性遗忘并稳定性能，增强泛化能力。"}
{"llm_update_time": "20251023", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.19755", "html_url": "https://arxiv.org/abs/2510.19755", "title": "扩散模型中的缓存方法概览：迈向高效的多模态生成", "title_en": "A Survey on Cache Methods in Diffusion Models: Toward Efficient Multi-Modal Generation", "authors": "Jiacheng Liu,Xinyu Wang,Yuqi Lin,Zhikai Wang,Peiru Wang,Peiliang Cai,Qinming Zhou,Zhengan Yan,Zexuan Yan,Zhengyi Shi,Chang Zou,Yue Ma,Linfeng Zhang", "background": "扩散模型因其卓越的生成质量和可控性已成为现代生成AI的基石。然而，它们固有的多步迭代和复杂的骨干网络导致了显著的计算开销和生成延迟，成为实时应用的瓶颈。尽管现有加速技术取得了一定进展，但仍面临适用范围有限、训练成本高或质量下降等问题。", "innovation": "扩散缓存（Diffusion Caching）提供了一种无需训练、架构无关且高效的推理范式。其核心机制在于识别和重用扩散过程中固有的计算冗余，通过在特征级别实现跨步骤重用和跨层调度，减少计算而不修改模型参数。该研究系统地回顾了扩散缓存的理论基础及其演变，并提出了一种统一的分类和分析框架。", "conclusion": "通过代表性方法的对比分析，我们展示了扩散缓存从静态重用发展到动态预测的趋势，增强了缓存的灵活性，并使其能够与采样优化和模型蒸馏等其他加速技术集成，为未来的多模态和交互应用提供了一个统一且高效的推理框架。我们认为这一范式将成为实现实时和高效生成AI的关键推动力，为‘高效生成智能’的理论和实践注入新的活力。"}
{"llm_update_time": "20251023", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.19754", "html_url": "https://arxiv.org/abs/2510.19754", "title": "CONFEX: 基于置信度保证的不确定性感知反事实解释", "title_en": "CONFEX: Uncertainty-Aware Counterfactual Explanations with Conformal Guarantees", "authors": "Aman Bilkhoo(1),Milad Kazemi(1),Nicola Paoletti(1),Mehran Hosseini(1 and 2) ((1) Department of Informatics, King's College London, (2) Department of Computer Science, University of Manchester)", "background": "反事实解释（CFXs）提供了模型预测的人类可理解的解释，有助于采取行动并增强模型的可解释性。然而，现有的方法经常忽视模型预测中的不确定性问题，或者缺少有效机制来融入不确定性并提供形式上的保证。这可能导致生成的解释在高不确定性区域中可能是误导性的或不适用的。因此，需要一种新的方法来生成感知不确定性的反事实解释，从而提高解释的可靠性和有效性。", "innovation": "本文提出了一种新颖的方法 CONFEX，它使用 Conformal Prediction (CP) 和 Mixed-Integer Linear Programming (MILP) 来生成感知不确定性的反事实解释。CONFEX 不仅考虑了预测不确定性保证，还通过局部化 CP 程序和利用基于树的输入空间离线分区，将 MILP 编码高效化，从而解决了反事实生成不遵守可交换性的问题。这种新的方法能够提供严谨的关于预测不确定性和最优性的保障，使得生成的解释更加可靠和合理。", "conclusion": "本文通过将 CONFEX 应用于多个基准和评估指标，证明了我们的不确定性感知方法能够提供稳健且合情合理的解释。这一方法为反事实解释领域提供了一种新的、有保证的方法，提高了解释的质量和可靠性。"}
{"llm_update_time": "20251023", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.19784", "html_url": "https://arxiv.org/abs/2510.19784", "title": "环境学习中的可泛化动力系统环境推断", "title_en": "Environment Inference for Learning Generalizable Dynamical System", "authors": "Shixuan Liu,Yue He,Haotian Wang,Wenjing Yang,Yunfei Wang,Peng Cui,Zhong Liu", "background": "数据驱动的方法为分析复杂动力系统提供了高效的解决方案，但依赖于独立同分布的数据假设，从而促进了处理环境差异的泛化技术的发展。然而，这些技术受限于其对环境标签的依赖性，而在训练过程中由于数据获取挑战、隐私问题和环境变化，环境标签往往不可用，尤其是在大规模公共数据集和涉及敏感信息的领域中。", "innovation": "提出了一种新颖的方法DynaInfer，该方法通过分析每次训练轮次中固定神经网络的预测错误来推断环境规范，从而直接从数据中进行环境分配。证明了该算法在无标签场景下有效解决交替优化问题，并通过广泛实验在多种动力系统中进行了验证。结果表明，DynaInfer超越了现有的环境标注技术，能够快速收敛到真实标签，并且在环境标签可用时甚至还能获得更好的性能。", "conclusion": "DynaInfer通过直接从数据中推断环境规范，解决了无标签场景下的环境分配问题，提供了高效的解决方案，并且在各种动力系统中表现优异。"}
{"llm_update_time": "20251023", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.19734", "html_url": "https://arxiv.org/abs/2510.19734", "title": "在线最小二乘SGD线性泛函的统计推理当$t \thicksim d^{1+\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{δ}}}}}}}}}}}}}}}}$时", "title_en": "Statistical Inference for Linear Functionals of Online Least-squares SGD when $t \\gtrsim d^{1+δ}$", "authors": "Bhavya Agrawalla,Krishnakumar Balasubramanian,Promit Ghosal", "background": "随机梯度下降(SGD)已成为现代数据科学的核心方法。然而，在高风险应用中部署SGD需要对其实有的不确定性进行严格的量化。现有高维投影参数的推理方法依赖于求解经验协方差矩阵，这在有限样本下需要至少$t \thicksim d^{\frac{3}{2}}$次迭代才能获得保证，这使得它们在计算上非常昂贵且对允许的维度扩展具有限制性。", "innovation": "本研究建立了线性函数的在线最小二乘SGD的非渐近Berry--Esseen界，从而在增长维度条件下提供了高斯中心极限定理(CLT)。提出的方法在计算效率上优于现有方法，其在线SGD过程的时间复杂度为$\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{O}}}}}}}}}}}}}}}(td)$，内存复杂度为$\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{O}}}}}}}}}}}}}}}(d)$，而现有的协方差求逆方法的时间复杂度为$\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{O}}}}}}}}}}}}}}}(td^2 + d^3)$。此外，还开发了一种在线方差估计器，并建立了其高概率偏差界，最终提供了首个在渐近最优维度扩展$t \thicksim d^{1+\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{δ}}}}}}}}}}}}}}}$下，能够构建在线SGD迭代置信区间的全在线和数据驱动框架。", "conclusion": "本论文首次提出了在接近最优维度扩展$t \thicksim d^{1+\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{δ}}}}}}}}}}}}}}}$下，用于在线SGD迭代置信区间构建的全在线和数据驱动的框架。该方法显著扩展了允许的维度扩展范围，同时提高了计算效率。"}
{"llm_update_time": "20251023", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.19796", "html_url": "https://arxiv.org/abs/2510.19796", "title": "通过隐迹成员推理验证黑盒模型来源", "title_en": "Blackbox Model Provenance via Palimpsestic Membership Inference", "authors": "Rohith Kuditipudi,Jing Huang,Sally Zhu,Diyi Yang,Christopher Potts,Percy Liang", "background": "本文探讨了如何通过训练后的语言模型来证明该模型是否被未经授权的使用者使用。当爱丽丝训练了一个公开权重的自然语言模型，而鲍勃使用了一个基于爱丽丝模型的黑盒变体生成文本时，爱丽丝能否证明这一点？本文将这一问题归结为独立性测试问题，并基于语言模型的隐迹式记忆特性进行研究。", "innovation": "本文提出了一种通过估计鲍勃模型对爱丽丝训练示例和顺序的可能性来直接估计的方法，并设计了两种基于不同方法测试鲍勃文本与爱丽丝模型版本之间关联性的实验，能够可靠地区分鲍勃生成的少量文本，从而验证鲍勃是否使用了爱丽丝的模型。", "conclusion": "无论是通过查询鲍勃模型的方式还是仅根据生成的文本内容，都可以测试鲍勃的模型或文本与爱丽丝的训练过程之间的相关性。本文通过实验展示了新方法的有效性，尤其是在查询设置中的表现更为突出，能直接估计模型对训练示例的可能性，并可靠地区分少量的孟加拉文本。"}
{"llm_update_time": "20251023", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.19801", "html_url": "https://arxiv.org/abs/2510.19801", "title": "全球南方国家训练主权语言模型的可行性：以巴西和墨西哥为例", "title_en": "The Feasibility of Training Sovereign Language Models in the Global South: A Study of Brazil and Mexico", "authors": "Sandra Malagon(1 and 2),Monica A. Ulloa Ruiz(1 and 2),Tatiana Elizabeth Sandoval Plaza(1),Gabriel Rafael Rosario Bolívar(1),Valentina García Mesa(1),Ivanna Alvarado Morales(1) ((1) Carreras con Impacto, (2) AIxo)", "background": "本文探讨了由于大规模语言模型训练对计算资源的要求快速增长，使得有能力的国家和全球南方国家之间在结构上出现了不对等的现象。研究聚焦于在硬件、能源和财政资源有限的情况下，在巴西和墨西哥训练主权规模语言模型的技术和财政可行性。", "innovation": "文章采用了一种双轴设计，分别对比了NVIDIA H100与A100两种加速器，并在不同的训练时间（90天和150天）下，评估计算需求、能源消耗、资本支出和监管兼容性。结果显示，所有配置均在出口控制和电力基础设施阈值以下，但财政可行性取决于硬件效率。", "conclusion": "我们建议将训练时间作为政策手段，以缓解硬件限制，从而能够在不与全球前沿竞争的情况下生产出可用、可审计并符合当地需求的语言模型。该研究通过强调上下文相关策略，为AI计算治理和科技主权的讨论做出了贡献，支持中等收入国家建立可持续的战略AI能力。"}
{"llm_update_time": "20251023", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.19710", "html_url": "https://arxiv.org/abs/2510.19710", "title": "SEMPO: 轻量级时间序列预报基础模型", "title_en": "SEMPO: Lightweight Foundation Models for Time Series Forecasting", "authors": "Hui He,Kun Yi,Yuanchi Ma,Qi Zhang,Zhendong Niu,Guansong Pang", "background": "近年来，大规模预训练模型在时间序列预测的基础模型开发方面取得了显著成功。尽管这些模型在各种下游预测任务中表现出色，但它们的网络架构庞大且需要在大规模数据集上进行大量预训练，这在资源受限的环境中严重限制了它们的部署。", "innovation": "我们提出了SEMPO，一种新型轻量级基础模型，仅需要在相对较小的数据集上进行预训练即可展现强大的时间序列预测能力。SEMPO包括两种关键模块：1) 能量感知频谱分解模块，通过建模不仅高能频率信号，还包括被现有方法忽略的低能但有信息性的频率信号，以提高预训练数据的利用效率；2) 混合提示Enabled Transformer，通过小型数据集特定提示学习异构的时间模式，并自适应地将时间序列标记路由到提示专家，以便在不同数据集和领域中实现参数高效的模型适应。", "conclusion": "实验结果显示，SEMPO在零样本和少量样本预测场景中均优于当前最先进的方法，显著减少了预训练数据量和模型规模，同时保持了强大的泛化能力。"}
{"llm_update_time": "20251023", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.19818", "html_url": "https://arxiv.org/abs/2510.19818", "title": "语义世界模型", "title_en": "Semantic World Models", "authors": "Jacob Berg,Chuning Zhu,Yanda Bao,Ishan Durugkar,Abhishek Gupta", "background": "世界模型为机器人控制提供了强大的范式，传统方法训练模型以预测未来的帧，基于当前帧和动作。然而，预测未来像素的目标往往与实际规划目标相矛盾；强大的像素重建不一定与良好的规划决策相关。本文提出，不仅仅要重建未来的帧，而是只需预测与任务相关的重要语义信息即可。本文将世界建模视为一个关于未来帧中语义信息的视觉问答问题。这种视角使得世界建模可以使用基于视觉语言模型的工具。视觉语言模型可以通过图像-动作-文本数据的监督微调过程训练为“语义”世界模型，从而继承训练好的视觉语言模型的各种泛化和鲁棒性特性，支持决策规划。", "innovation": "本文将世界模型视为一个关于未来帧中语义信息的视觉问答问题，从而将视觉语言模型训练为“语义”世界模型，通过图像-动作-文本数据的监督微调过程，实现决策规划，同时传承视觉语言模型的泛化和鲁棒性特性。此方法在开放性机器人任务中提升了策略改进的效果，相较于传统的基于重建的世界模型，在泛化能力上取得了显著提升。", "conclusion": "通过使用视觉语言模型训练语义世界模型，本文的方法在开放性机器人任务中显著提高了规划的决策效果，提升了泛化能力。"}
{"llm_update_time": "20251023", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.19797", "html_url": "https://arxiv.org/abs/2510.19797", "title": "Transformers都是几乎最优的线性分类元学习器", "title_en": "Transformers are almost optimal metalearners for linear classification", "authors": "Roey Magen,Gal Vardi", "background": "该研究基于Transformer展示出令人印象深刻的在上下文学习（ICL）能力，提出了Transformer是否可以作为元学习器，在少量上下文示例的情况下适应新任务，而无需进行进一步的训练。虽然近期理论研究已经探讨了Transformer在ICL方面的能力，但大多数分析并未涉及正式的元学习框架，即通过以多任务并行高效地解决相关任务，而不需要单独解决每个任务。前提是在共享的k维度子空间中，每个任务对应一个类条件的高斯混合模型。", "innovation": "本文首次提供了理论分析，表明简化后的Transformer架构可以通过梯度下降训练，作为线性分类设置中的近似最优元学习器。特别是在测试信号强度R的情况下，经过足够数量的任务训练后，Transformer可以在仅使用O(k / R^4)个上下文示例的情况下泛化到新任务。这种表现几乎与已知共享子空间的最优学习器相同，同时显著优于只有访问上下文数据的任何学习器，后者需要Omega(d / R^4)个示例才能泛化。此外，研究还提供了实现这一结果所需的学习任务数量和每任务示例数量的上限，这些上界不依赖于周围维度d。", "conclusion": "研究结果表明，简化后的Transformer架构能够在线性分类框架中作为几乎最优的元学习器使用，特别是在共享低维度子空间的线性分类任务中。这一发现进一步验证了Transformer在元学习场景中的实用性，尤其是在信号强度R和周围维度d较小的情况下。"}
{"llm_update_time": "20251023", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.18892", "html_url": "https://arxiv.org/abs/2510.18892", "title": "当模型无法遵循指令：256个大型语言模型的指令遵守测试", "title_en": "When Models Can't Follow: Testing Instruction Adherence Across 256 LLMs", "authors": "Richard J. Young,Brandon Gillins,Alice M. Matthews", "background": "尽管大型语言模型已被广泛应用，但对其指令遵循能力的系统性评估仍然具有挑战性。虽然存在着全面的基准测试，但专注于快速诊断特定指令遵循模式的测试仍有价值。鉴于新模型可能基于现有基准进行训练，因此需要新的评估方法来评估其真正的能力而不仅仅是记忆表现。为了评估语言模型在不同任务类别中的指令遵循能力，本文提出了一套包含20个精心设计提示的简化评估框架，并通过10月14日2025年大规模实证研究，对331个可通过OpenRouter获取的256个验证模型进行了测试。", "innovation": "本文介绍了一种简化评估框架，包含20个精心设计的提示，用于跨多个任务类别评估LLM的指令遵循能力。这一方法不仅使用了可验证的指令，还提供了一个兼具全面性与高效性的紧凑测试套件，每个提示都针对指令遵循的不同方面，如格式合规性、内容约束、逻辑顺序和多步骤任务执行。这种方法提供了一个实用的诊断工具，可供研究人员和实践者直接应用，且不需要耗费大量计算资源。此外，它填补了现有评估方法的空白，为区分模型的真实能力和记忆能力提供了新途径。", "conclusion": "本文的研究结果揭示了一致的失败模式，并识别出特定类型的指令特别具有挑战性。这项工作不仅贡献了一个实用的评估工具，还提供了有史以来最全面的当下语言模型指令跟随能力的实证分析。"}
{"llm_update_time": "20251023", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.18931", "html_url": "https://arxiv.org/abs/2510.18931", "title": "计算教育中的公平与伦理视角：大型语言模型辅助的多视角和主题性评估", "title_en": "A Justice Lens on Fairness and Ethics Courses in Computing Education: LLM-Assisted Multi-Perspective and Thematic Evaluation", "authors": "Kenya S. Andrews,Deborah Dormah Kanubala,Kehinde Aruleba,Francisco Enrique Vicente Castro,Renata A Revelo", "background": "课程大纲为课程定下了基调和期望，影响着学生和教师的学习体验。在涉及人工智能（AI）、机器学习（ML）和算法设计公平性和伦理性的计算课程中，理解如何克服公平结果障碍的方法至关重要。课程大纲分析为评估课程内容、深度、实践和期望提供了一种方法。然而，手动评估课程大纲耗时且易产生不一致。", "innovation": "该研究开发了一种基于正义的评分指标，并使用大型语言模型（LLM）进行了多视角的角色模拟评估课程大纲。研究采用多视角评估了24门涉及公平和伦理的AI/ML及相关计算课程的课程大纲，同时让LLM识别出课程中的主题趋势。这种多视角评估有助于捕捉角色特异性的重要优先事项，填补课程设计中的隐性漏洞。", "conclusion": "多视角评估揭示了课程设计中的细微差异和角色特定优先事项，帮助明确了改善公平、伦理和正义相关内容设计和交付的具体方向。"}
{"llm_update_time": "20251023", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.19728", "html_url": "https://arxiv.org/abs/2510.19728", "title": "生成合成医疗时间序列以实现细分亚组水平模型评估", "title_en": "Enabling Granular Subgroup Level Model Evaluations by Generating Synthetic Medical Time Series", "authors": "Mahmoud Ibrahim,Bart Elen,Chang Sun,Gökhan Ertaylan,Michel Dumontier", "background": "本文提出了一个新颖的框架，利用合成ICU时间序列数据不仅用于训练模型，还用于严格和可信地评估预测模型，包括在整体水平和细粒度的人口统计子组中。该研究在TimeDiff、HealthGen和TimeAutoDiff的先驱扩散和基于VAE的生成器基础上，引入了Enhanced TimeAutoDiff模型，该模型增加了分布对齐惩罚项，以增强潜在扩散目标。研究采用MIMIC-III和eICU数据集上的广泛基准测试，结果显示Enhanced TimeAutoDiff减少了现实数据和合成数据之间，以及现实数据之间的评估差距（TRTS差距），达到了Δ_{TRTS} ≤ 0.014 AUROC，并保持了训练效用（Δ_{TSTR} ≈ 0.01）。对于32个交叉细分亚组，大型合成群体将亚组水平的AUROC估计误差降低了最多50%，并在72%到84%的亚组中表现优于小型实际测试集。", "innovation": "引入了Enhanced TimeAutoDiff模型，该模型结合了分布对齐惩罚项来增强潜在扩散目标。研究结果显示，增强了的TimeAutoDiff模型有效地减小了现实数据和合成数据之间的评估差距，并保持了训练数据的效用。更重要的是，大型合成群体在32个细分亚组中表现优异，比小型实际测试集有更好的性能。", "conclusion": "本文提供了一个实用且保护隐私的路线图，可以在危重症监护中实现细化模型评估和分析，避免暴露敏感的电子病历数据，为医疗AI的整体可信度做出了贡献。"}
{"llm_update_time": "20251023", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.18878", "html_url": "https://arxiv.org/abs/2510.18878", "title": "CityAQVis: 城市多源数据驱动的集成机器学习-可视化工具用于城市区域污染物估计", "title_en": "CityAQVis: Integrated ML-Visualization Sandbox Tool for Pollutant Estimation in Urban Regions Using Multi-Source Data (Software Article)", "authors": "Brij Bridhin Desai,Yukta Arvind,Aswathi Mundayatt,Jaya Sreevalsan-Nair", "background": "城市空气污染对公众健康、环境可持续性和政策规划构成了重大威胁。有效的空气质量管理需要能够整合各种数据集并解释空间和时间污染物模式的预测工具。当前缺乏能够无缝集成预测和展示地面污染物浓度空间分布的交互式工具。", "innovation": "CityAQVis 是一种集成的机器学习-可视化工具，通过多源数据预测并展示地面污染物浓度，包括卫星观测、气象参数、人口密度、海拔和夜间灯光等。相较于其他传统空气污染可视化工具，CityAQVis 具备预测功能，用户可以构建和比较预测模型，可视化模型输出，以了解地面污染物动态。", "conclusion": "通过直观的图形用户界面，用户可以比较不同城市场景下地表污染物浓度的空间分布。研究表明，ML驱动的可视化分析能够提高环境感知，并支持基于数据的空气质量管理决策。"}
{"llm_update_time": "20251023", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.18904", "html_url": "https://arxiv.org/abs/2510.18904", "title": "DuoLens：一种用于检测机器生成的多语言文本和代码的稳健框架", "title_en": "DuoLens: A Framework for Robust Detection of Machine-Generated Multilingual Text and Code", "authors": "Shriyansh Agrawal,Aidan Lau,Sanyam Shah,Ahan M R,Kevin Zhu,Sunishchal Dev,Vasu Sharma", "background": "大语言模型（LLMs）生成多语言文本和源代码的能力日益增强，这使得对机器生成内容的检测工具的准确性与效率成为了迫切需求。现有的检测工具大多依赖于零样本方法（如Fast DetectGPT或GPTZero），但这些工具要么计算成本高，要么精确度不足，往往在这两者之间有所权衡，仍有改进空间。因此，需要一种能够兼顾准确性和效率的新型方法来填补这些缺口。现有的检测技术主要依赖于零样本方法，无法在保证准确性的前提下达到高效率。", "innovation": "论文提出将已预训练的RoBERTA和CodeBERTa等编码器仅有的小型语言模型（SLMs）进行微调，使用特定的数据集对源代码和其他自然语言进行训练，以证明在二分类任务中，SLMs的表现远远优于LLMs，同时大大减少了计算资源的占用。在输入512个令牌的数据集上，该模型实现了AUROC值在0.97到0.99之间，宏观F1值在0.89到0.94之间，将延迟降低了8到12倍，峰值VRAM占用降低了3到5倍。并且，即使在跨生成器转移和对抗变换下，模型的表现也能保持在92%以上的清洁的AUROC。此外，作者还提供了训练和评估脚本及种子配置文件，并附带有可再现性检查列表。", "conclusion": "综上所述，论文提出的方法在准确性和计算效率之间取得了平衡，并且表现出更优的性能，证明了小型语言模型在该领域的应用潜力。这项研究为今后开发更高效的机器生成内容检测工具提供了有力支持。"}
{"llm_update_time": "20251023", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.18932", "html_url": "https://arxiv.org/abs/2510.18932", "title": "通过大规模社交结构网络分析评价大语言模型的故事生成", "title_en": "Evaluating LLM Story Generation through Large-scale Network Analysis of Social Structures", "authors": "Hiroshi Nonaka,K. E. Perry", "background": "对大语言模型（LLMs）在复杂任务中的创造性能力进行评估通常需要进行难以放大规模的人类评估。因此，需要开发一种新的、可扩展的方法来评估LLMs在叙事生成方面的表现。", "innovation": "提出了一种新颖的、可扩展的方法，通过分析叙事中潜在的社会结构（即带有符号的字符网络）来进行LLMs故事生成评估。这种方法通过大规模比较分析超过1,200个由四款领先LLMs（GPT-4o, GPT-4o mini, Gemini 1.5 Pro, Gemini 1.5 Flash）和人类撰写的叙事结构进行展示和验证。", "conclusion": "基于网络属性如密度、聚类和带有符号的边权重，研究发现LLMs生成的故事显示出强烈倾向的紧密团队和正面关系，这与之前使用人类评估的研究一致。提出的方法为评估当前及未来LLMs的创造性叙事能力提供了一个有价值的工具。"}
{"llm_update_time": "20251023", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.18941", "html_url": "https://arxiv.org/abs/2510.18941", "title": "ProfBench: 多领域需要专业知识来回答和评判的标准", "title_en": "ProfBench: Multi-Domain Rubrics requiring Professional Knowledge to Answer and Judge", "authors": "Zhilin Wang,Jaehun Jung,Ximing Lu,Shizhe Diao,Ellie Evans,Jiaqi Zeng,Pavlo Molchanov,Yejin Choi,Jan Kautz,Yi Dong", "background": "评估大语言模型（LLMs）的进步通常受到验证响应的挑战限制，这使得评估主要集中在数学、编程和简短的问答任务上。然而，许多实际应用需要在处理专业文档、综合信息和生成详尽报告方面的专业领域内对LLMs进行评估。现有的评估标准未涵盖真实世界的专业应用需求，导致大多数LLM评估局限于简单任务。因此，开发一个全面且专业的评估标准成为迫切需要。", "innovation": "本文引入了ProfBench：一个由7000多对响应标准组成的评估集，这些标准是在物理博士学位、化学博士学位、金融MBA和咨询MBA的专家评估下建立的。通过减少自我提升偏见并大幅降低评估成本，建立了一个强大的、经济的LLM评估体系，使得评估更加公平和普及。此外，发现即使是最先进的LLM也面临重大挑战，顶级模型如GPT-5-high的整体性能也仅达到65.9%；分析还指出，专有模型与开源模型之间的性能差异显著，也探讨了扩展思考在处理复杂专业任务中的作用。", "conclusion": "ProfBench 提供了一个评估L`LMs专业能力的新基准，该基准突出了AI在处理复杂专业任务时的局限性，尤其是在生成综合报告和处理用户查询方面。这强调了专业知识在评判LLM性能上的重要性，并通过减少成本和提高公平性开拓了L`LMs评估的新方法。"}
{"llm_update_time": "20251023", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.19002", "html_url": "https://arxiv.org/abs/2510.19002", "title": "基于预测的公平选拔", "title_en": "Impartial Selection with Predictions", "authors": "Javier Cembrano,Felix Fischer,Max Klimm", "background": "这篇文章研究基于相互提名的代理选择问题，这在委员会选拔和AI对齐等领域有许多应用。由于代理既提名又被提名，他们可能会有激励去谎报他们对其他委托人资格的看法，以提高自己被选中的可能性。公平的机制通过确保代理的选拔与自己的提名无关来规避这一问题。先前的研究已经对这类机制的有效性进行了广泛研究。", "innovation": "本文提出了一个新的机制，该机制在预测正确时的一致性为 $1-O\big(\frac{1}{k}\big)$，在预测错误时的鲁棒性为 $1-\frac{1}{e}-O\big(\frac{1}{k}\big)$。特别地，当选择单个代理且每个代理只提名一个其他代理时，证明了一致性可以达到1，同时保证鲁棒性为$\frac{1}{2}$。与先前的研究结果对比，表明在几乎没有鲁棒性损失的情况下可以实现最佳一致性。", "conclusion": "在一般情况下，该机制在预测准确时达到最佳一致性，而在预测错误时也具有相当高的鲁棒性。对于单代理选举的特殊情况，可以实现完全一致性并保证至少一半的鲁棒性。"}
{"llm_update_time": "20251023", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.19008", "html_url": "https://arxiv.org/abs/2510.19008", "title": "Plural Voices, Single Agent: 向多元包容的家庭多用户空间迈进", "title_en": "Plural Voices, Single Agent: Towards Inclusive AI in Multi-User Domestic Spaces", "authors": "Joydeep Chandra,Satyam Kumar Navneet", "background": "国内的人工智能代理在伦理、自主性和包容性方面面临着挑战，尤其是对于被忽视的群体如儿童、老年人和神经多样性用户。", "innovation": "该论文提出了一种名为Plural Voices Model (PVM)的创新单一代理框架，该框架通过实时价值对齐动态协商多用户需求，利用心理健康、老年护理、教育和道德推理等多个领域的公共数据集。通过公平意识的教学设计和伦理增强，PVM确定核心价值、冲突和无障碍需求，以启发包容性原则。PVM 的隐私保护原型包括适应性安全支撑、个性化的互动（例如，神经多样性用户的操作步骤指导，简单用语供儿童使用）以及公平的冲突解决机制。初步评估结果显示，PVM 在合规性、公平性和安全违规率方面优于多代理基线，并且在延迟方面表现优秀。设计创新包括视频指导、自主性滑块、家庭枢纽和适应性安全仪表板，展示了在家庭多用户环境中，新的伦理和包容性方向，以及用户中心的自主系统的设计可能性。", "conclusion": "PVM在家庭多用户空间中展示了新的方向，提供了一种实际且有效的解决方案，以建立用户中心的多样化代理系统。"}
{"llm_update_time": "20251023", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.19020", "html_url": "https://arxiv.org/abs/2510.19020", "title": "Calibrated Principal Component Regression", "title_en": "Calibrated Principal Component Regression", "authors": "Yixuan Florence Wu,Yilun Zhu,Lei Cao and,Naichen Shi", "background": "在高维数据环境下，逐步提高参数化（overparameterized regime）下的主成分回归（Principal Component Regression, PCR）方法通过将高维数据投影到低维主成分子空间中再进行拟合，可以减少方差。但是，这种方法会在真实回归向量有质量分布在保留的主成分之外时导致截断偏差（truncation bias）。", "innovation": "提出了一种新的克服截断偏差的方法——校准主成分回归（Calibrated Principal Component Regression, CPCR）。该方法首先在主成分子空间中学习一个低方差先验，然后通过居中Tikhonov步骤在原始特征空间中校准模型，从而利用交叉拟合（cross-fitting）并控制截断偏差，使之软化PCR的硬截断。", "conclusion": "理论分析和实际实验结果表明，CPCR 在随机矩阵条件下比标准 PCA 在回归信号具有低方差方向非忽略成分时表现更优。而且，CPCR 在多个过参数化问题中一致提高了预测效果，展示了其在现代过参数化情境下的稳定性和灵活性。"}
{"llm_update_time": "20251023", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.19050", "html_url": "https://arxiv.org/abs/2510.19050", "title": "基于偏好奖励学习中的捷径行为矫正", "title_en": "Rectifying Shortcut Behaviors in Preference-based Reward Learning", "authors": "Wenqian Ye,Guangtao Zheng,Aidong Zhang", "background": "在通过人类反馈进行强化学习的过程中，基于偏好的奖励模型在调整大型语言模型至人类导向的行为方面发挥着核心作用。然而，近期的研究表明，这些模型容易出现奖励作弊现象，并且由于过度优化往往难以很好地泛化。模型通过利用捷径行为（例如，利用与训练数据中人类偏好评分相关但不反映实际目标的虚假特征，如冗长、讨好性语气等）来获得高奖励分数，而不仅仅是实际反映预定目标。", "innovation": "本文从一个更宽广的角度看待奖励作弊问题，将其视为捷径行为。我们提出了一种原则性但灵活的方法——基于偏好的奖励不变性以减轻捷径行为（PRISM），该方法在封闭形式的学习目标中学习具有特征映射的群不变内核。实验证明，我们的方法在多种基准测试中的奖励模型准确度上均有提升，并减少了下游策略模型对捷径行为的依赖，从而建立了一个稳健的基于偏好的调整框架。", "conclusion": "实验结果表明，我们的方法可以改进奖励模型在不同分布任务上的准确性，并减少下游策略模型对外部捷径行为的依赖，从而确保了基于偏好的模型调整框架的稳健性。"}
{"llm_update_time": "20251023", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.19090", "html_url": "https://arxiv.org/abs/2510.19090", "title": "跨越时间尺度学习嘈杂的组织动力学", "title_en": "Learning noisy tissue dynamics across time scales", "authors": "Ming Han,John Devany,Michel Fruchart,Margaret L. Gardel,Vincenzo Vitelli", "background": "组织动力学在伤口愈合到形态发生等多个生物过程中起着至关重要的作用。但这些有噪声的多细胞动力学系统因其高噪音水平和复杂性而难以预测。", "innovation": "本文介绍了一种生物仿生机器学习框架，能够直接从实验视频中推断出有噪声的多细胞动力学。该生成模型通过结合图神经网络、流化变换和WaveNet算法，将组织表示为由演化的图的边组成的神经随机微分方程。这种机器学习架构体现了生物组织的架构，相比卷积或全连接神经网络，它减少了所需的训练数据量。", "conclusion": "通过以表皮组织实验为例，我们证明该模型不仅能捕捉细胞的随机运动，还能预测细胞在分裂周期中的状态演变。此外，该方法能够准确生成发育系统（如苍蝇翅膀）和由随机ERK波介导的细胞信号传导过程的动力学，为生物工程和临床领域的数字孪生使用铺平了道路。"}
{"llm_update_time": "20251023", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.18900", "html_url": "https://arxiv.org/abs/2510.18900", "title": "化学空间中发现和探索的科学基础模型", "title_en": "Foundation Models for Discovery and Exploration in Chemical Space", "authors": "Alexius Wadell,Anoushka Bhutani,Victor Azumah,Austin R. Ellis-Mohr,Celia Kelly,Hancheng Zhao,Anuj K. Nayak,Kareem Hegazy,Alexander Brace,Hongyi Lin,Murali Emani,Venkatram Vishwanath,Kevin Gering,Melisa Alkan,Tom Gibbs,Jack Wells,Lav R. Varshney,Bharath Ramsundar,Karthik Duraisamy,Michael W. Mahoney,Arvind Ramanathan,Venkatasubramanian Viswanathan", "background": "原子级、热力学和动力学性质的准确预测对材料创新至关重要。当前的计算和实验方法在导航化学空间方面缺乏足够的可扩展性。基于大量未标记数据训练的科学基础模型有望在不同应用领域探索化学空间。已有研究通常规模较小，本文开发了一种名为MIST的分子基础模型，参数和数据量是先前工作的10倍以上。使用新的标记化方案，MIST模型能够从多样化的分子中学习核、电子和几何信息，以预测超过400种结构-性质关系，并在生理学、电化学和量子化学等多个领域的基准测试中达到或超过了最先进的性能。", "innovation": "开发了一种名为MIST的大型分子基础模型，参数和数据量比现有技术高出一个数量级。采用新颖的标记化方案，MIST能够全面捕获核、电子和几何信息，从而从多种不同的分子中学习。MIST模型对多种实际问题具有解决能力，包括多目标电解质溶剂筛选、嗅觉感知图谱绘制、同位素半衰期预测、手性金属有机化合物的立体化学推理以及二元和多元组分混合物性质预测。通过机械可解释性方法探究MIST模型揭示了训练数据中未明确呈现的可识别模式和趋势，表明模型能够学习可泛化的科学概念。提出了带超参数惩罚的贝叶斯神经网络比例法则，将模型开发的计算成本降低了约一个数量级，为加速材料发现、设计和优化奠定了基础并提供了有价值的指导，用于训练计算最优的科学基础模型。", "conclusion": "所提出的方法和发现代表了使用基础模型加速材料发现、设计和优化的一个重要进展，并为训练计算最优的科学基础模型提供了宝贵的指导。"}
{"llm_update_time": "20251023", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.19110", "html_url": "https://arxiv.org/abs/2510.19110", "title": "基于路径理论的签名核评分规则作为时空诊断的概率预报工具", "title_en": "Signature Kernel Scoring Rule as Spatio-Temporal Diagnostic for Probabilistic Forecasting", "authors": "Archer Dodson,Ritabrata Dutta", "background": "现代天气预报已经从数值天气预测（NWP）转向了数据驱动的机器学习预报技术。虽然这些新的模型能够生成概率预报来量化不确定性，但在训练和评估时，它们可能仍然受限于传统的评分规则（主要是均方误差MSE），这些规则忽略了天气和大气系统中存在的高相关数据结构。因此，本研究引入了一种基于粗糙路径理论的签名核评分规则，它将气象变量视为连续路径，并通过迭代积分来编码时空依赖性。", "innovation": "签名核评分规则基于粗糙路径理论，将气象变量重新定义为连续路径，通过迭代积分来编码时空依赖性，严格证明了该评分规则的有效性和鲁棒性。通过在WeatherBench 2模型上的实证评估，研究展示了签名核评分规则具有高度的区分能力，并能捕捉路径依赖的交互。研究采用预测顺序评分规则训练滑动窗口生成神经网络，证明了基于签名核训练的方法在长时序预报上优于气候统计方法。", "conclusion": "研究利用滑动窗口生成神经网络在ERA5再分析数据上进行训练，使用基于签名核的方法成功实现了无需对抗训练的概率预报模型。验证结果显示，签名核评分规则方法能有效提高仅有十五个时间步长的预报路径准确性。"}
{"llm_update_time": "20251023", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.19117", "html_url": "https://arxiv.org/abs/2510.19117", "title": "大型语言模型中幻觉检测的图信号处理框架", "title_en": "A Graph Signal Processing Framework for Hallucination Detection in Large Language Models", "authors": "Valentin Noël", "background": "大型语言模型在各种任务中取得了显著的效果，但辨别事实推理和幻觉依然具有挑战性。本文探讨了使用谱分析方法来区分这两种情况，通过对注意力机制和token嵌入建模动态图，运用图信号处理方法定义了诊断指标，如狄利克雷能量、频谱熵和高频能量比率，理论联系到计算稳定性的角度进行分析。实验结果表明，不同类型的幻觉具有不同的谱图特征，逻辑矛盾会大幅降低稳定性，而语义错误保持稳定但出现连接性漂移，替换幻觉则表现出中间的扰动程度。实验表明，基于谱图特征的简单检测器在准确性上优于基于困惑度的基线方法，显示出实际应用价值。", "innovation": "本文提出了一种谱分析框架，将Transformer层建模为由注意力机制诱导的动态图，通过图信号处理定义了一系列诊断指标，有效地区分了事实推理和幻觉，不仅揭示了幻觉的特征，还提出了使用谱图特征进行幻觉检测的方法，显著提升了检测准确性。", "conclusion": "研究结果表明，谱几何可能捕捉到推理模式和错误行为，为大规模语言模型中幻觉检测提供了一个有潜力的框架。"}
{"llm_update_time": "20251023", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.19131", "html_url": "https://arxiv.org/abs/2510.19131", "title": "训练无依赖的变压器中语音处理的频谱印记", "title_en": "Training-Free Spectral Fingerprints of Voice Processing in Transformers", "authors": "Valentin Noël", "background": "研究表明，不同的变压器架构可以通过不同的连接模式实现相同的语言计算，产生特定的‘计算印记’，可以通过频谱分析检测到。本研究利用图信号处理技术，在注意力诱导的令牌图上追踪20种语言和三个模型家族在语音交替下的代数连接性（费lder值，Δλ2）变化，特别是前期窗口（2-5层）。这些结果揭示了架构特有的印记，为揭示模型偏见并支持模型可靠性分析提供了简单、独立于训练的方法。", "innovation": "本研究创新之处在于，通过图信号处理技术在注意力诱导的令牌图上标定了20种语言和三个模型家族在语音交替下的代数连接性变化，特别是前期窗口（2-5层）的变化。这一分析方法揭示了不同架构特有的印记，通过这些印记可以关联行为差异，并受目标注意力头消融的调节，从而链接效果到早期注意力结构，证实了训练重点可以留有可检测的计算印记：特定的处理策略，潜在地在句法规则转换期间通过可测量的连接模式表现出来。此外，该框架还被用于区分推理模式，标志着其作为简单、无需训练诊断来揭示架构偏见和评估模型可靠性的潜力。", "conclusion": "总体而言，研究结果与观点一致，即训练重点可以留下可检测的计算印记：特定的处理策略，在句法规则转换期间以可测量的连接模式表现出来。除了语音交替外，该框架还用于区分推理模式，表明其作为简单且无需训练诊断来揭示架构偏见和支持模型可信度分析的工具的潜力。"}
{"llm_update_time": "20251023", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.19145", "html_url": "https://arxiv.org/abs/2510.19145", "title": "HAMLOCK: HArdware-Model LOgically Combined attacK", "title_en": "HAMLOCK: HArdware-Model LOgically Combined attacK", "authors": "Sanskar Amgain,Daniel Lobo,Atri Chatterjee,Swarup Bhunia,Fnu Suya", "background": "随着第三方硬件加速器（例如FPGA和ASIC）在深度神经网络（DNNs）中的使用增多，新的安全漏洞也随之产生。传统的基于模型的后门攻击通过修改模型权重来影响特定触发条件下的输入分类，但由于整个攻击逻辑嵌入在模型中（即软件），因此通常是可以被检测到的，因为它会形成一个可追踪的逐层激活路径。", "innovation": "本文提出了一种名为HAMLOCK的新颖的硬件-模型逻辑组合攻击。这种攻击将攻击逻辑分布在硬件-软件边界上，仅通过调整个别神经元的激活值来生成在特定触发条件下具有独特高激活值的响应。恶意硬件特洛伊木马会监测这些独特激活值，并触发另一个硬件特洛伊木马来直接操控输出逻辑，从而实现错误分类。这种分离的设计非常隐蔽，因为模型自身没有任何完整的后门激活路径，看起来完全没有恶意。", "conclusion": "实验表明，在MNIST、CIFAR10、GTSRB和ImageNet等基准测试中，HAMLOCK几乎可以实现完美的攻击成功率，几乎没有清洁准确率的损耗。更重要的是，HAMLOCK能够绕过现有的最先进的基于模型的防御，无需任何适应性优化。硬件特洛伊木马也不可检测，造成的面积和功率开销仅为0.01%，容易被工艺和环境噪声掩盖。这些发现揭示了硬件-软件接口处的一个关键漏洞，需要新的跨层防御措施来应对这种新兴威胁。"}
{"llm_update_time": "20251023", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.19173", "html_url": "https://arxiv.org/abs/2510.19173", "title": "金融市场的意识到新闻直接强化交易", "title_en": "News-Aware Direct Reinforcement Trading for Financial Markets", "authors": "Qing-Yu Lan,Zhan-He Wang,Jun-Qian Jiang,Yu-Tong Wang,Yun-Song Piao", "background": "金融市场上，新闻被认为是高度敏感的。因此，如何有效地将新闻数据纳入量化交易仍然是一个重要的挑战。现有方法通常依赖于手工设计的规则和/或手工构建的特征。", "innovation": "本文直接使用来自大型语言模型的新闻情绪分数，连同原始的价格和成交量数据，作为强化学习的直接输入。这些输入通过递归神经网络或变压器等序列模型进行加工，以进行端到端的交易决策。实验使用加密货币市场作为示例，并评估了两种代表性的强化学习算法：双层增强的Q网络（DDQN）和组相对策略优化（GRPO）。结果表明，不依赖于手工构建的特征或手工设计的规则的新闻意识方法可以在市场基准上实现更好的性能。", "conclusion": "这个过程中的时间序列信息的发挥了关键作用。"}
{"llm_update_time": "20251023", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.19168", "html_url": "https://arxiv.org/abs/2510.19168", "title": "超越标准模型的迁移学习", "title_en": "Transfer Learning Beyond the Standard Model", "authors": "Veena Krishnaraj,Adrian E. Bayer,Christian Kragh Jespersen,Peter Melchior", "background": "机器学习在进行宇宙学推理时非常强大，但通常需要许多高保真度的模拟覆盖广泛的宇宙学模型。迁移学习提供了一种通过在不同模型之间重用知识来降低模拟成本的方法。研究表明，对标准宇宙学模型 ΛCDM 进行预训练，并调整针对多种超出 ΛCDM 的场景（包括中微子质量、修改引力和原始非高斯性）可以显著减少超出 ΛCDM 的模拟次数。然而，当 ΛCDM 和超出 ΛCDM 参数之间存在强烈的物理退化时，也会出现负面影响。", "innovation": "提出了在标准宇宙学模型 ΛCDM 上进行预训练，然后对超出 ΛCDM 场景进行微调的方法。研究发现，包含瓶颈结构的迁移架构可以获得最佳性能。这种方法展示了在物理学中基础模型方法的机会和挑战：预训练可以使推理加速，但也可能妨碍学习新物理。", "conclusion": "研究表明，预训练可以帮助减少超出标准模型的模拟次数，但当存在强烈的物理退化时，可能会产生负面效果。不同的迁移架构中，包含瓶颈结构的模型表现最佳，这突显了在物理学中基础模型方法的应用和潜在问题。"}
{"llm_update_time": "20251023", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.19181", "html_url": "https://arxiv.org/abs/2510.19181", "title": "知识图谱中的可解释性问答", "title_en": "Interpretable Question Answering with Knowledge Graphs", "authors": "Kartikeya Aneja,Manasvi Srivastava,Subhayan Das,Nagender Aneja", "background": "本文介绍了一种仅依赖于知识图谱检索的问答系统，不依赖于大规模语言模型（LLM）的检索增强生成（RAG）。该系统采用一个小型改写器模型来改写从知识图谱查询检索出的实体关系边。这一工作通过Llama-3.2和GPT-3.5-Turbo在CRAG基准上的LLM评审实验，展示了系统的准确性分别为71.9%和54.4%。", "innovation": "该论文的创新点在于开发了一种基于知识图谱的问答系统，完全依赖于知识图谱的检索，使用一个小改写器模型来改写从知识图谱查询中检索到的实体关系边，而不需要使用大规模语言模型的检索增强生成技术。在CRAG基准上进行了评估，展示了系统的有效性。", "conclusion": "本文提出了一种新的知识图谱检索问答系统，该系统通过生成和处理知识图谱来获得最终的答案，而不是依赖于大规模语言模型的检索增强生成技术。实验结果表明，该系统具有较低的资源需求和较高的准确性。"}
{"llm_update_time": "20251023", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.19116", "html_url": "https://arxiv.org/abs/2510.19116", "title": "That's Deprecated! 理解、检测和引导语言模型在代码生成中知识冲突", "title_en": "That's Deprecated! Understanding, Detecting, and Steering Knowledge Conflicts in Language Models for Code Generation", "authors": "Jaesung Bae,Cameron Churchwell,Mitchell Hermon,Tsun-An Hsieh,Jocelyn Xu,Yekaterina Yegorova,Mark Hasegawa-Johnson,Heng Ji", "background": "本文探讨了当大语言模型（LLMs）遇到参数知识与提示中冲突信息不一致时的反应。基于先前的问答（QA）研究，本文将知识冲突的研究扩展到了代码生成领域。通过构建和解释知识冲突的通用框架，以及为代码冲突场景定制了新的评估方法和数据集，本文揭示了大模型参数中包含知识冲突的倾向。", "innovation": "本文提出了一种通用框架来构建和解释知识冲突，并设计了专门针对代码冲突场景的评估方法和数据集。实验结果表明，足够大的模型能够检测到知识冲突，准确率可达80.65%。此外，通过激活级别的引导，可以实现最高12.6%的成功率提升，但成效取决于模型大小、任务领域和引导方向的平衡。", "conclusion": "本文通过实验表明，大型语言模型能够以80.65%的准确率检测知识冲突。此外，通过激活级别引导可以提高12.6%的成功率，但需要根据模型大小、任务领域和引导方向进行平衡。研究结果将在文章接受后发布实验代码和数据。"}
{"llm_update_time": "20251023", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.19150", "html_url": "https://arxiv.org/abs/2510.19150", "title": "X-Ego: 通过跨自身体轮廓对比视频表示学习获取团队级别的战术情况意识", "title_en": "X-Ego: Acquiring Team-Level Tactical Situational Awareness via Cross-Egocentric Contrastive Video Representation Learning", "authors": "Yunzhe Wang,Soham Hans,Volkan Ustun", "background": "人类团队战术是基于每位队员的个人视角和他们对队友意图的预测、理解和适应能力而形成的。尽管视频理解的进步提高了对体育比赛中团队互动的建模，但现有大部分工作依赖于第三人称广播视角，忽视了多智能体学习中同步的自身体验特性。", "innovation": "提出了X-Ego-CS，这是一个包含了45场专业级别的“反恐精英2”电子竞技游戏中124小时 gameplay 录像的基准数据集，用于促进复杂3D环境中多智能体决策的研究。引入了跨自身体轮廓对比学习(CECL)，这是一种算法，通过对齐队友的自身体视觉流，促进从个人视角出发的团队战术情况意识。", "conclusion": "X-Ego-CS和CECL为电子竞技中的跨自身体多智能体基准测试奠定了基础。更广泛地说，我们的工作将游戏理解定位为多智能体建模和战术学习的试验平台，对虚拟和现实世界的时空推理和人机团队合作具有重要意义。相关代码和数据集可在给出的链接中获取。"}
{"llm_update_time": "20251023", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.19268", "html_url": "https://arxiv.org/abs/2510.19268", "title": "强化学习和上下文视觉语言模型的分层次DLO导向", "title_en": "Hierarchical DLO Routing with Reinforcement Learning and In-Context Vision-language Models", "authors": "Mingen Li,Houjian Yu,Yixuan Huang,Youngjin Hong,Changhyun Choi", "background": "在工业装配线和日常生活中，长时距的柔体线性对象（DLO）导向任务非常普遍。这些任务的挑战体现在机器人需要在长时距规划和技能稳定执行方面进行操作，而这些都需要精准的高层次推理。", "innovation": "本文提出了一种完全自主的分层次框架，用于解决复杂的DLO导向任务。该框架利用视觉-语言模型进行上下文中的高层次推理，生成可行的计划，并通过强化学习训练的低层级技能来执行。此外，还引入了一种恢复机制，以确保在长时距中的鲁棒性。", "conclusion": "本文的方法能够适应具有不同属性的物体、空间描述以及隐含语言命令的多样化场景。相比次优基线方法，该方法性能提高了近50%，整体成功率达到92.5%。"}
{"llm_update_time": "20251023", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.19245", "html_url": "https://arxiv.org/abs/2510.19245", "title": "VLM 剂量模拟购物者行为：视觉理解、推理与行动", "title_en": "See, Think, Act: Online Shopper Behavior Simulation with VLM Agents", "authors": "Yimeng Zhang,Jiri Gesi,Ran Xue,Tian Wang,Ziyi Wang,Yuxuan Lu,Sinong Zhan,Huimin Zeng,Qingjun Cui,Yufan Guo,Jing Huang,Mubarak Shah,Dakuo Wang", "background": "大型语言模型(LLMs)近年来在模拟在线购物者行为方面展现了强大的潜力。先前的工作通过应用指令调优（SFT）和强化学习（RL）改进了行为预测，但当前方法依赖于基于文本的输入，忽视了视觉感知在网页 GUI 交互中对人类决策的决定性作用。", "innovation": "本文研究了将视觉信息，特别是网页截图，通过视觉语言模型（VLMs）集成到行为模拟中的方法，利用OPeRA数据集。通过同时结合文本和视觉模态，本文旨在缩小合成代理和真实用户之间的差距，从而实现更认知对齐的在线购物行为模拟。具体而言，本文采用指令调优（SFT）进行联合行为预测和理由生成，并基于完整的交互上下文，如动作历史、过去的 HTML 观察和当前的网页截图进行调整。此外，通过与具有难度感知因子的层次奖励结构的集成强化学习，进一步增强了推理能力。", "conclusion": "我们的研究表明，包含视觉地基可以带来显著增益：文本和图像输入的组合比仅文本输入提高了超出 6% 的精确匹配准确性。这些结果表明，多模态地基不仅提高了预测准确性，还增强了在视觉复杂环境中模拟的真实感，捕捉了人类注意和决策中的细微差别，这是文本仅代理往往忽视的。最后，本文重新探讨了行为模拟框架的设计空间，指出了关键方法论限制，并提出了未来研究方向，以构建高效的高效的人类行为模拟器。"}
{"llm_update_time": "20251023", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.19225", "html_url": "https://arxiv.org/abs/2510.19225", "title": "RLBoost：利用预取资源实现LLMs中低成本强化学习", "title_en": "RLBoost: Harvesting Preemptible Resources for Cost-Efficient Reinforcement Learning on LLMs", "authors": "Yongji Wu,Xueshen Liu,Haizhong Zheng,Juncheng Gu,Beidi Chen,Z. Morley Mao,Arvind Krishnamurthy,Ion Stoica", "background": "强化学习（RL）对于大型语言模型（LLMs）的高级推理能力至关重要。RL工作流包括交替进行的展开（rollout）和训练阶段，这两种阶段的资源需求完全不同。尽管展开通常主导整个执行时间且可以通过多个独立实例高效扩展，但训练则需要紧密耦合的GPU和全网格通信。现有的RL框架可分为两类：共存和解耦架构。共存架构无法应对资源紧张问题，因为它们要求两个阶段共享相同的GPU。而解耦架构如果不对现有的RL算法进行修改，则会导致资源使用不足。此时，可以通过高效利用预取GPU资源（如公共云上的按需实例或生产集群中的闲置容量），实现加速RL工作流。已有研究证明，通过利用这些资源可以显著降低成本。", "innovation": "RLBoost是一个系统解决方案，旨在以低成本高效执行RL训练，主要是通过利用预取GPU资源。其创新点在于，认识到展开具有无状态和直觉上并行的特性，与预取且通常碎片化的资源完全匹配。为充分利用这些资源，尽管其可用性经常变化且不可预测，RLBoost采用了混合架构，并引入了三项关键技术：(1)自适应展开卸载以动态调整预留（按需）集群的工作负载；(2)基于拉模式的权重传输以快速提供新可用实例；(3)令牌级响应收集和迁移以有效处理抢占和连续负载平衡。", "conclusion": "实验结果表明，与仅使用按需GPU资源相比，RLBoost能够将训练效率提高1.51至1.97倍，并将成本效率提高28％至49％。"}
{"llm_update_time": "20251023", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.19251", "html_url": "https://arxiv.org/abs/2510.19251", "title": "使用层次Transformer和不确定性量化预测晶体结构的合成性", "title_en": "Synthesizability Prediction of Crystalline Structures with a Hierarchical Transformer and Uncertainty Quantification", "authors": "Danial Ebrahimzadeh,Sarah Sharif,Yaser Mike Banad", "background": "加速材料发现的一个核心挑战是预测哪些假设的无机晶体可以在实验中实现。这项工作针对这个问题，提出了一个名为SyntheFormer的正未标记框架，直接从晶体结构中学习合成性，结合傅立叶变换晶体周期性（FTCP）表示、逐级特征提取、随机森林特征选择以及紧凑的深层MLP分类器来实现这一目标。模型利用2011年至2018年的历史数据训练，并在2019年至2025年的未来数据上进行前瞻性评估。", "innovation": "SytheneFormer采用层次Transformer结构结合不确定性量化，通过傅立叶变换晶体周期性表示、逐级特征提取、随机森林特征选择和紧凑的深层MLP分类器来直接从晶体结构中学习合成性。在这样的时空分离评估下，模型取得了0.735的测试ROC曲线面积，在双重阈值校准下获得了97.6%的召回率和94.2%的覆盖率，展示出在预测实验可实现性时在最小化错失机会的同时保持分辨能力的强大能力。关键的是，该模型能够恢复实验确认的亚稳态化合物，并对许多热力学稳定但未合成的候选物质进行低评分，表明仅稳定性不足以预测实验可实现性。", "conclusion": "通过将结构感知表示与不确定性感知决策规则对齐，SyntheFormer提供了一种将实验室努力集中在最有希望的新无机材料上的实用途径，从而优先选择合成目标。"}
{"llm_update_time": "20251023", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.19277", "html_url": "https://arxiv.org/abs/2510.19277", "title": "使用高斯过程回归进行互动无线电力系统设计中的磁场估算", "title_en": "Magnetic field estimation using Gaussian process regression for interactive wireless power system design", "authors": "Yuichi Honjo,Cedric Caremel,Ken Takaki,Yuta Noma,Yoshihiro Kawahara,Takuya Sasatani", "background": "文中讨论了耦合谐振器无线电力传输（WPT）在无缝供电电子设备方面的前景。传统的电磁场仿真方法，如矩量法（MoM），由于计算资源消耗大，限制了实时互动应用中的计算效率。此外，系统对位置和几何形状变化的高度敏感性需要大量模拟，而铁磁屏蔽等结构进一步增加了这些模拟的复杂性。因此，需要一种快速而准确的方法来估算这种近场耦合系统的磁场和电力传输效率，以提高设计的互动性并有效地捕捉复杂几何形状与磁场之间的非线性相互作用。", "innovation": "文章提出了一种基于高斯过程回归（GPR）的方法来快速估算近场耦合系统中的磁场及其电力传输效率。通过构建3D自适应网格系统和采用主动学习策略来捕捉复杂几何结构与磁场之间的非线性交互，该方法能够在几秒内完成磁场计算，且与独立电磁模拟结果的平均误差小于6%。这是首次利用GPR方法实时估算整个磁场和电力传输效率。", "conclusion": "通过训练回归模型，该方法在非场计算方面达到亚秒级延迟，并且在没有铁磁屏蔽的情况下，相对于独立电磁仿真结果的平均误差小于6%，显示出在互动无线电力系统设计中的显著优势。"}
{"llm_update_time": "20251023", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.19303", "html_url": "https://arxiv.org/abs/2510.19303", "title": "协作渗透测试套件用于新兴生成型AI算法", "title_en": "Collaborative penetration testing suite for emerging generative AI algorithms", "authors": "Petar Radanliev", "background": "介绍了生成型AI模型面临模型反转、数据污染和对抗性输入等安全隐患。同时，提到了量子威胁，特别是Shor算法可以破解RSA和ECC加密。面对这些挑战，需要确保生成型AI模型免受经典和量子网络安全攻击的影响。", "innovation": "提出了一个协作渗透测试套件，包括五个集成组件：DAST、SAST、OWASP ZAP、Burp Suite、SonarQube、Fortify，以及结合CI/CD管道的IAST。还集成了Blockchain日志（基于Hyperledger Fabric）和量子加密（基于Lattice的RLWE协议），并进行了AI红队模拟。这套工具还提供了一个统一的工作流程，让AI、网络安全和量子领域的专家们可以协同工作。通过这套工具，总共发现了300多个漏洞，并在两周内将高严重性问题减少了70%，破解了区块链记录的漏洞90%的解决效率，并且在测试中保持了100%的量子加密完整性。", "conclusion": "提出了一个综合的量子AI安全协议，集成了区块链、量子加密和AI红队模拟等技术，确保生成型AI模型的安全性，改善了高严重性安全问题的处理效率，保持了量子加密的完整性。"}
{"llm_update_time": "20251023", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.19315", "html_url": "https://arxiv.org/abs/2510.19315", "title": "变换器本质上具有简洁性", "title_en": "Transformers are Inherently Succinct", "authors": "Pascal Bergsträßer,Ryan Cotterell,Anthony W. Lin", "background": "该研究基于变换器模型在其描述概念方面可能表现出的表达能力更强的观点。先前的工作已经在探索变换器如何有效地表征复杂的模式和概念，但缺乏直接度量变换器表达能力的方法。因此，有必要提出一个能够量化变换器表达能力的指标，并且需要进一步研究变换器表达能力强所带来的理论和实际影响。", "innovation": "该研究提出了简洁性作为衡量变换器表征概念能力的新方法。通过证明变换器可以通过更简洁的方式来表示形式语言，并且这种能力超越了诸如有穷自动机和线性时序逻辑（LTL）等标准形式语言表示方法，间接反映了变换器表达能力的优越性。此外，由于这种强大的表达能力，变换器属性的验证被证明是不可证明的复杂性问题（即EXPSPACE完全问题）", "conclusion": "变换器不仅表现出与传统形式语言表示方法相比的更高表达能力，还因为这种表达能力使得变换器属性的验证变得极其复杂。这一发现对于理解变换器的功能和应用范围具有重要意义，并且可能引导进一步的研究来探索变换器模型的有效性边界和优化方法。"}
{"llm_update_time": "20251023", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.19306", "html_url": "https://arxiv.org/abs/2510.19306", "title": "货币拓扑：外汇共动性的持久同调：一种聚类比较研究", "title_en": "Topology of Currencies: Persistent Homology for FX Co-movements: A Comparative Clustering Study", "authors": "Pattravadee de Favereau de Jeneret,Ioannis Diamantis", "background": "论文背景在于探讨拓扑数据分析（TDA）是否能够提供比传统统计方法更多的见解，尤其是在聚类货币行为方面。研究集中于复杂的外汇（FX）市场，该市场经常表现出非线性和高维的动力学，这可能是古典技术无法完全捕捉到的。为此，研究对比了基于TDA特征和传统统计特征进行聚类的结果，并利用月度对数收益率对13种主要货币对欧元的交易数据进行了分析。文中运用了k-均值和层次聚类两种常用的聚类算法，并通过Silhouette分数和Calinski-Harabasz指数评估了聚类质量。研究发现在使用TDA特征进行聚类时，产生的聚类更加紧凑且分离更清晰，特别是在Calinski-Harabasz分数方面取得了显著提高。然而，所有聚类方法的Silhouette分数都很低，表明分组外汇时间序列固有的难度。", "innovation": "研究创新之处在于将TDA应用于货币市场分析，并与传统的统计方法进行了对比。研究使用了持久同调方法，这是一种拓扑数据分析技术，能够捕捉数据的结构性特征。通过将TDA应用于外汇市场分析，揭示了货币共动性的结构性模式，这些模式可能被传统方法忽略。这强调了TDA作为一种有价值补充工具的价值，特别是在风险管理中，理解结构性共动性至关重要。", "conclusion": "研究结果表明，TDA方法在聚类外汇共动性方面表现出优势，能够产生更紧致且分离更清晰的聚类。尽管如此，所有的聚类方法在Silhouette分数上得分较低，这表明在外汇时间序列的分组上有固有的挑战。TDA的方法捕捉了传统方法可能会忽略的结构性模式，展示了TDA作为一种有价值的补充工具在金融时间序列分析中的作用，特别是在风险管理和理解结构性共动性方面有重要应用价值。"}
{"llm_update_time": "20251023", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.19334", "html_url": "https://arxiv.org/abs/2510.19334", "title": "利用大型语言模型进行元数据提取", "title_en": "Metadata Extraction Leveraging Large Language Models", "authors": "Cuize Han,Sesh Jalagam", "background": "大型语言模型（LLM）的出现已经彻底改变了跨领域的任务，包括法律文件分析的自动化，这是现代合同管理系统中的关键组成部分。本研究提出了LLM增强元数据提取的全面实现，重点在于自动检测和注释关键法律条款。研究采用了公开可获取的Contract Understanding Atticus Dataset（CUAD）以及自有的合同数据集，展示了将先进的LLM方法与实际应用相结合的重要性。研究确定了优化元数据提取的三个关键元素：稳健的文字转换、战略性的块选择以及特定于LLM的先进技术，包括思维链（Chain of Thought, CoT）提示和结构化工具调用。", "innovation": "本研究提出了利用LLM进行元数据提取的创新方法，具体包括三点：1. 采用稳健的文字转换技术；2. 选择战略性块；3. 使用包括思维链提示和结构化工具调用在内的先进LLM技术。研究表明，这种优化可以显著提高条款识别的准确性和效率。另外，研究通过实验验证，其方法有助于减少合同审查的时间和成本，同时保持高识别准确性。研究结果表明，经过仔细优化的LLM系统可以成为法律专业人士的宝贵工具，可能提高各类组织获取高效合同审查服务的机会。", "conclusion": "研究强调，精心优化的LLM系统在合同审查中具有显著潜力，可以减少时间和成本，同时保持高准确率。这对所有规模的组织来说是宝贵的合同审查服务工具。"}
{"llm_update_time": "20251023", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.19341", "html_url": "https://arxiv.org/abs/2510.19341", "title": "基于局部下降引理的非单调次梯度方法", "title_en": "Nonmonotone subgradient methods based on a local descent lemma", "authors": "Francisco J. Aragón-Artacho,Rubén Campoy,Pedro Pérez-Aros,David Torregrosa-Belén", "background": "本文将非单调下降方法的上下文扩展到一类称为上-$\boldsymbol{C}^2$的非光滑非凸函数，这些函数满足平滑局部形式的下降引理。在此假设下，提出了一种非单调次梯度方法，通过非单调线搜索证明了目标优化问题的一个稳定点的次序列收敛性。这种方法涵盖了多种次梯度算法，包括牛顿和拟牛顿方法。特别注重最小平方和聚类问题，提供了SNSM的具体实现。最后，通过数值实验展示了SNSM相较于已知算法的优点。", "innovation": "提出了基于局部下降引理的一般次梯度方法，并开发了一种自适应非单调次梯度方法（SNSM），能够自动更新线搜索参数。特别地，解决了最小平方和聚类问题，展示了SNSM的优越性。", "conclusion": "通过数值实验展示了SNSM在与已知算法对比中的优势。"}
{"llm_update_time": "20251023", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.19161", "html_url": "https://arxiv.org/abs/2510.19161", "title": "Extreme Event Aware ($\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\bf\tau}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}$-) Learning", "title_en": "Extreme Event Aware ($η$-) Learning", "authors": "Kai Chang,Themistoklis P. Sapsis", "background": "量化和预测罕见和极端事件一直是理解复杂动力系统的关键但具有挑战性的任务。由于这些事件的稀有性和严重性所带来的实际挑战，简单的抽样方法的方差较大，高保真的数值模拟计算成本高昂。尽管已经开发了许多数据驱动的方法来应对这些问题，但这些方法通常假设存在多次极端事件，无论是训练数据集内还是抽样过程中，这导致在平静事件的区域具有准确模型，但在与极端事件相关的区域则有高已知不确定性。理论结果基于最优传输提供了一个严谨的证明，并突显了所提出方法的优劣性。大量数值实验还进一步证实了$\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\bf\boldsymbol{\tau}}}}}}}}}}}}}}}}}}}}}}}}}$-学习框架在多种原型问题和实际天气降尺度问题中的有利性质。", "innovation": "提出了Extreme Event Aware ($\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\bf\boldsymbol{\tau}}}}}}}}}}}}}}}}}}}}}}}}}$-（或$\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\bf\boldsymbol{\tau}}}}}}}}}}}}}}}}}}}}}}}}}$-）学习，这是一种无需假定数据集中存在极端事件的学习方法。通过在训练过程中强制满足一些指标的极端事件统计信息，$\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\bf\boldsymbol{\tau}}}}}}}}}}}}}}}}}}}}}}}}}$-学习在极端事件未知的区域降低了不确定性，从而生成前所未有的极端事件，即使训练数据中缺乏极端事件。", "conclusion": "基于最优传输的理论结果提供了新的方法的严格证明，并突显了其优化性。大量的数值实验亦证实了$\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\bf\boldsymbol{\tau}}}}}}}}}}}}}}}}}}}}}}}}}$-学习框架在若干原型问题及实际天气降尺度问题中的优点。"}
{"llm_update_time": "20251023", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.19368", "html_url": "https://arxiv.org/abs/2510.19368", "title": "AMAuT: 从头训练的灵活高效多视图音频变换器框架", "title_en": "AMAuT: A Flexible and Efficient Multiview Audio Transformer Framework Trained from Scratch", "authors": "Weichuang Shao,Iman Yi Liao,Tomas Henrique Bode Maul,Tissa Chandesa", "background": "最近的基础模型如SSAST、EAT、HuBERT、Qwen-Audio和Audio Flamingo在标准音频基准测试中获得了顶级结果，但它们受限于固定的输入速率和时长，这限制了它们的再利用性。", "innovation": "提出了一种从头训练的框架AMAuT（Augmentation-driven Multiview Audio Transformer），该框架消除了对预训练权重的依赖，并支持任意的采样率和音频长度。AMAuT 集成了四个关键组件：增强驱动的多视图学习以提高鲁棒性、一维CNN瓶颈、双向上下文表示的双CLS + TAL标记，以及测试时适应/增强以提高推理可靠性。", "conclusion": "实验表明，AMAuT在五个公共基准上的准确性可达到99.8%，消耗的GPU小时数仅为相当的预训练模型的3%。因此，AMAuT提供了一种在计算资源受限环境中可行的高效和灵活的替代方案，使最先进的音频分类技术变得可用。"}
{"llm_update_time": "20251023", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.19372", "html_url": "https://arxiv.org/abs/2510.19372", "title": "关于Predictive Information在强化学习中的复杂性问题", "title_en": "On the hardness of RL with Lookahead", "authors": "Corentin Pla,Hugo Richard,Marc Abeille,Nadav Merlis,Vianney Perchet", "background": "我们研究了一种强化学习（RL），其中代理在决定其行动之前可以观察到执行任何一系列$\boldsymbol{\beta}$个动作后将访问的状态。这种预测信息可以大幅提高可实现的性能，但使用这种信息可能会带来潜在的计算成本。本文特别关注了这种提前规划策略的复杂性边界问题，尤其是在执行多个步骤预测的情况下。", "innovation": "我们提出了一个新的线性规划公式来解决一步预测最优计划问题，这可以在多项式时间内解决。然而，对于$\beta \boldsymbol{\beta}\boldsymbol{\textgreater}=\boldsymbol{2}$的情况，问题变得NP难。这项研究表明，提前规划的可计算性边界非常清晰，对于简化和解决未来更多相关的RL任务具有重要意义。", "conclusion": "我们的工作明确了提前规划预测信息的情况下可处理和不可处理的情况之间的精确边界。这为解决具有预测信息的强化学习问题提供了理论依据，并为未来的相关研究奠定了基础。"}
{"llm_update_time": "20251023", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.19357", "html_url": "https://arxiv.org/abs/2510.19357", "title": "Autobidding Arena: 统一评估经典和基于强化学习的自动出价算法", "title_en": "Autobidding Arena: unified evaluation of the classical and RL-based autobidding algorithms", "authors": "Andrey Pudovikov,Alexandra Khirianova,Ekaterina Solodneva,Aleksandr Katrutsa,Egor Samosvat,Yuriy Dorn", "background": "广告拍卖在电子商务公司收入生成中起着重要作用。为了使竞价程序能够处理成千上万的拍卖，行业正在积极开发自动出价（autobidding）算法。因此，公平且可再现的自动出价算法评估成为一个重要的问题。本研究提出了一种标准化和透明的评估协议，用于比较经典和强化学习（RL）自动出价算法。我们考虑了不同类别的最有效的自动出价算法，如基于控制器的、RL的、优化公式等，评估了多种环境下的这些算法的表现。利用最新的开源环境，它可以精确模拟竞价过程。这项工作不仅展示了所考虑的自动出价算法的最佳应用场景，还揭示了其意想不到的缺陷，按照多种标准评估这些算法。我们选择了一些关键指标来展示自动出价算法的表现、相应成本和预算节奏。这种方法使结果适用于多种平台，在这些平台上自动出价非常有效。所呈现的结果帮助从业者从多个角度评估候选自动出价算法，并选择符合公司目标的高效算法。", "innovation": "本文介绍了一种标准化且透明的评估协议，用于评估经典和基于强化学习（RL）的自动出价算法。这种协议考虑了不同类别中的最有效的自动出价算法，并利用开源环境进行真实竞价过程的模拟。通过这种方式，研究者能够全面而公平地比较这些算法，揭示它们的潜在优缺点。同时，选取的评估指标能够用于不同平台，适用范围广。", "conclusion": "本文展示了一个用于自动出价算法评估的统一架构，涵盖了经典和基于强化学习的方法。通过对比分析，识别出了不同算法的适用场景和潜在问题。这种方法为实际应用中的算法选择提供了宝贵的信息，帮助制定更有效的竞价策略。"}
{"llm_update_time": "20251023", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.19374", "html_url": "https://arxiv.org/abs/2510.19374", "title": "通过最适应线性和神经网络模型的平方根Cox生存分析", "title_en": "Square root Cox's survival analysis by the fittest linear and neural networks model", "authors": "Maxime van Cutsem,Sylvain Sardy", "background": "该研究重新审视了Cox比例风险模型和LASSO在生存分析中的应用，旨在提高特征选择的准确性。传统的Cox模型通常是通过交叉验证或BIC选择特征，但这种方法存在一定的局限性，特别是在特征选择方面。因此，需要提出新的方法改善特征选择过程，特别是在概率检索所有且只有好的特征方面表现出色。", "innovation": "该研究提出了一种新的方法，通过直接调整惩罚参数 $\boldsymbol{\text{λ}}$ 来优化特征选择。这种方法利用Cox部分似然的平方根来改进LASSO和BIC子集选择，具有更出色的性能。在通过线性模型或人工智能神经网络应用时，该方法表现出类似于压缩感知中的相变特征，能够显著提高特征选择的概率。", "conclusion": "该研究提出的方法在特征选择的准确性和可靠性上有了显著改进，特别是在生存分析的应用中。这种方法可以应用于线性模型和人工神经网络，提高了模型在提取真正相关特征能力方面的表现。"}
{"llm_update_time": "20251023", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.19373", "html_url": "https://arxiv.org/abs/2510.19373", "title": "使用温度采样有效训练不平衡数据集中的机器人学习策略", "title_en": "Using Temperature Sampling to Effectively Train Robot Learning Policies on Imbalanced Datasets", "authors": "Basavasagar Patil,Sydney Belt,Jayjun Lee,Nima Fazeli,Bernadette Bucher", "background": "正越来越多地收集机器人的动作和感官观测的大规模数据集，用于训练越来越大的神经网络。尽管这些任务在描述上可能不同，但许多任务涉及非常相似的物理动作序列。因此，许多机器人的任务数据集在所代表的物理机器人动作方面存在显著的不平衡。本工作提出了一种简单的采样策略来缓解这种不平衡，该策略只需几行代码即可集成到现有代码库中并改善泛化能力。", "innovation": "本研究提出了一种简单的温度采样策略，用于缓解机器人任务数据集不平衡问题。这种策略可以在预训练小型模型和微调大型基础模型中使用。与之前的方法相比，该方法在低资源任务上显示出显著的改进效果，而不影响高资源任务的性能，从而有效地利用模型容量来实现多任务策略。", "conclusion": "该研究的方法不仅提高了低资源任务的性能，而且保证了高资源任务的性能不降级。此外，该方法还在真实世界中对Franka Panda机械臂进行了验证，涉及不同的任务集合。该方法使得可以更有效地利用模型能力来实现多任务策略。"}
{"llm_update_time": "20251023", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.19366", "html_url": "https://arxiv.org/abs/2510.19366", "title": "MoE-Prism: 细分单一专家以实现弹性MoE服务的模型-系统联合设计", "title_en": "MoE-Prism: Disentangling Monolithic Experts for Elastic MoE Services via Model-System Co-Designs", "authors": "Xinfeng Xia,Jiacheng Liu,Xiaofeng Hou,Peng Tang,Mingxuan Zhang,Wenfeng Wang,Chao Li", "background": "Mixture-of-Experts (MoE)模型是大规模AI领域的最新技术，通过稀疏激活参数来实现高质量。然而，这种模型依赖于通过top-k机制在少数大型专家之间进行路由，这导致了'质量悬崖'，只能提供少数粗粒度的操作点。这种缺乏灵活性的情况迫使在成本和质量之间做出艰难的权衡，无法适应多样化的服务水平目标（SLO），这导致了资源的过度配置。现有MoE模型难以适应不同的需求，导致了性能和资源利用效率的瓶颈问题。", "innovation": "本文提出了MoE-Prism模型-系统联合设计，将刚性的MoE模型转换为弹性服务。该方法分为两个阶段：首先，一个‘离线重构引擎’系统地将大型专家分解为细粒度的“子专家”。该引擎使用元启发式方法进行神经元分组的优化求解器，无需重新训练即可保持功能局部性。其次，一个‘在线调度引擎’利用这种新弹性通过QoS感知调度实现。它实施专门的策略来解决复杂系统问题，包括最大化云部署的吞吐量和管理限制内存设备的延迟优化卸载。我们的评估表明，与基线相比，MoE-Prism提供了超过4倍的稳定操作点，使得AI服务在严格的延迟预算下可提高高达19.9%的吞吐量，或在有限资源下降低高达10.36%的延迟。MoE-Prism为弥合模型-系统差距提供了一个关键的“控制旋钮”，促进了下一代适应、高效和QoS感知的AI服务的发展。", "conclusion": "MoE-Prism通过细化单一专家并实现弹性MoE服务，解决了现有MoE模型在成本和质量之间的权衡难题，提供了更多稳定的操作点。从而，AI服务能够在严格的性能预算和资源限制下实现更好的性能和资源使用效率。"}
{"llm_update_time": "20251023", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.19418", "html_url": "https://arxiv.org/abs/2510.19418", "title": "从看到保护：ML辅助细粒度访问控制", "title_en": "From See to Shield: ML-Assisted Fine-Grained Access Control for Visual Data", "authors": "Mete Harun Akcay,Buse Gul Atli,Siddharth Prakash Rao,Alexandros Bakas", "background": "随着存储数据量的不断增长，识别并保护大型数据库中的敏感信息变得越来越具有挑战性，尤其是在与拥有不同角色和权限的多个用户共享时。本文提出了一个基于策略驱动的访问控制的信任数据共享系统架构，该架构能够选择性地保护敏感区域的同时保持系统的可扩展性。", "innovation": "本文提出的系统架构整合了四个核心模块，包括自动检测敏感区域、后修正、密钥管理以及访问控制。使用混合加密方案，结合了对称加密和属性基加密来实现高效性和策略执行。该系统支持高效的密钥分发并隔离密钥存储以增强整体安全性。", "conclusion": "实验结果显示，该系统在图像数据集上对于隐私敏感对象能够提供有效的检测和选择性加密，增加了宏均F1分数（5%）和平均平均精度（10%），并且每张图像的策略执行解密时间平均不超过1秒。这些结果证明了本研究提出的细粒度访问控制解决方案的有效性、效率和可扩展性。"}
{"llm_update_time": "20251023", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.19420", "html_url": "https://arxiv.org/abs/2510.19420", "title": "通过节点评估监测基于大型语言模型的多Agent系统免受篡改", "title_en": "Monitoring LLM-based Multi-Agent Systems Against Corruptions via Node Evaluation", "authors": "Chengcan Wu,Zhixin Zhang,Mingqian Xu,Zeming Wei,Meng Sun", "background": "基于大型语言模型（LLM）的多Agent系统（MAS）已成为人工智能应用的一个热门范式。然而，MAS中的诚信问题仍然是一个关键关切。与单Agent系统面临的挑战不同，MAS涉及更复杂的通信过程，使其更易受到篡改攻击的影响。现有的防御机制大多基于MAS的图表示，其中代理节点和通信形成边，这些方法主要集中在静态图防御上，要么检测固定图结构中的攻击，要么优化具有特定防御能力的静态拓扑结构。因此，现有的方法存在局限性，无法很好地应对动态变化的攻击。因此，需要开发一种动态防御模式来满足不断变化的MAS动态环境下的需求。", "innovation": "提出了一种动态防御模式，旨在通过连续监测MAS图中的通信来调整图形拓扑结构，准确地中断恶意通信，有效地抵御不断发展的多样化动态攻击。这些创新手段明显优于现有的MAS防御机制，为MAS的可靠应用提供了有效保障。", "conclusion": "实验结果表明，在更为复杂和动态的MAS环境中，该方法显著优于现有MAS防御机制，为保证MAS应用的信任度提供了有效的保障。"}
{"llm_update_time": "20251023", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.19444", "html_url": "https://arxiv.org/abs/2510.19444", "title": "统一的概率系统定量抽象：范畴对偶与逻辑完备性", "title_en": "Universal Quantitative Abstraction: Categorical Duality and Logical Completeness for Probabilistic Systems", "authors": "Nivar Anwer(Institute of Artificial Intelligence, De Montfort University, Leicester, United Kingdom)", "background": "本文提出了一个统一的定量抽象理论，应用于概率系统，并将其与范畴论、最优传输理论以及定量模态逻辑联系起来。其核心是ε-商，具有可传递性：在所有ε-抽象中，它是信息量最大的一个，并且遵循给定的价值损失上界。此外，通过特殊伴随函子定理建立了抽象与实现操作符（$Q_{\\varepsilon} \bot R_{\\varepsilon}$）之间的伴随关系，揭示了距离结构与逻辑语义之间的范畴对偶。", "innovation": "引入了一种定量模态μ-逻辑，并证明其表达能力完备性，使行为距离与最大逻辑差异一致。分析了接口细化下的可组合性，清晰了跨系统边界时抽象如何相互作用。通过有限马尔可夫决策过程精确验证了收敛性质、价值损失界、扰动下的稳健性、对抗性辨识能力以及可扩展性，展示了其鲁棒性和计算可行性。", "conclusion": "所提出的框架为状态聚合和表示学习提供了有原则的目标，数学上确保了在随机领域的价值函数近似中具有精确的保证。"}
{"llm_update_time": "20251023", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.19463", "html_url": "https://arxiv.org/abs/2510.19463", "title": "探索长尾和高度不平衡IC缺陷分类中的‘多在少中’和‘少在多中’特性", "title_en": "Exploring \"Many in Few\" and \"Few in Many\" Properties in Long-Tailed, Highly-Imbalanced IC Defect Classification", "authors": "Hao-Chiang Shao,Chun-Hao Chang,Yu-Hsien Lin,Chia-Wen Lin,Shao-Yun Fang,Yan-Hsiu Liu", "background": "尽管已经取得了显著进展，特别是在深度分类技术以及针对长尾或高度不平衡数据的自动光学检查模型方面，将这些方法应用于实际的IC缺陷分类任务仍然面临挑战。这主要是由于两个因素：首先，工业环境中对高产出率的要求导致数据分布远比通用不平衡数据集更为倾斜，这使得针对开放不平衡数据集设计的分类器在现实场景中难以有效工作；其次，实际样本中包含类特异性特征和类无关、领域相关的特征，这种复杂性尤其在高度不平衡的数据集分类过程中增加了难度。", "innovation": "该论文提出了一种新的IC-Defect-14数据集，这是一个源自实际IC生产线部署的AOI系统的大型高度不平衡IC缺陷图像数据集，具有独特的‘内类簇’特性，表现为高度的内类多样性与高外类相似性。这是很少同时存在于现有公共数据集中的特征，极大地降低了当前最先进的分类器对高度不平衡数据的性能。为此，该文提出了ReCAME-Net，这是一种遵循多专家分类框架的模型，并集成了区域通道注意力模块、度量学习损失、硬类别挖掘策略及知识蒸馏程序。", "conclusion": "广泛的实验评估表明，ReCAME-Net在IC-Defect-14数据集上优于先前的最先进的模型，同时在通用公共数据集上保持了相当的竞争性表现。"}
{"llm_update_time": "20251023", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.19471", "html_url": "https://arxiv.org/abs/2510.19471", "title": "重新评估最小贝叶斯风险解码在自动语音识别中的应用", "title_en": "Re-evaluating Minimum Bayes Risk Decoding for Automatic Speech Recognition", "authors": "Yuu Jinnai", "background": "最近的研究表明，在文本到文本生成任务中，基于样本的最小贝叶斯风险（MBR）解码在机器翻译、文本摘要和图像字幕等任务中超越了贝叶斯搜索。相比之下，贝叶斯搜索仍然是自动语音识别（ASR）和语音翻译（ST）任务中的常用方法。鉴于MBR解码在文本到文本生成任务中的有效性，可以预期它在语音到文本任务中也会有效。", "innovation": "本文通过对Whisper及其衍生模型在英语和日语的ASR和ST任务中的评估，发现MBR解码在大部分实验设置中均优于贝叶斯搜索。结果表明，MBR解码是一种适用于需要高精度的离线ASR和ST任务的有前途的方法。", "conclusion": "MBR解码方法在离线ASR和ST任务中表现出了较高的准确性，是一个有前景的方法，相关的代码已公开可用。"}
{"llm_update_time": "20251023", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.19465", "html_url": "https://arxiv.org/abs/2510.19465", "title": "基于条件生成对抗网络的属性约束孔隙尺度图像重建：PCP-GAN", "title_en": "PCP-GAN: Property-Constrained Pore-scale image reconstruction via conditional Generative Adversarial Networks", "authors": "Ali Sadeghkhani,Brandon Bennett,Masoud Babaei,Arash Rabbani", "background": "在地下水文地质学、碳存储和地热能等应用中，准确表征孔隙空间的形态非常重要，但由于自然空间异质性导致提取的子图像与核心测量值显著偏差，数据稀缺性限制了可用物理样本的数量，使得获得真正代表性且与宏观性质一致的孔隙尺度图像成为地层表征的基本挑战。", "innovation": "该研究提出了一种多条件生成对抗网络（cGAN）框架，该框架通过单个统一模型同时控制孔隙度值和深度参数生成具有精确属性控制的代表孔隙尺度图像，克服了代表性和数据可用性的双重挑战。该框架通过训练薄层样品解决了碳酸盐岩形成中不同深度的孔隙网络普遍原则和地质特性，实现了广泛的孔隙度控制，生成的图像在形态验证中保持了关键的孔隙网络特征，且生成图表现出优良的代表性，相比随机提取的真实子图像，其双约束误差显著降低。", "conclusion": "该模型为地层物理表征提供了变革性工具，尤其适用于碳存储、地热能和地下水管理应用，因为它能够理解并模拟孔隙空间的代表性形态，这对于这些应用的成功至关重要。"}
{"llm_update_time": "20251023", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.19470", "html_url": "https://arxiv.org/abs/2510.19470", "title": "HybridEP: Scaling Expert Parallelism to Cross-Datacenter Scenario via Hybrid Expert/Data Transmission", "title_en": "HybridEP: Scaling Expert Parallelism to Cross-Datacenter Scenario via Hybrid Expert/Data Transmission", "authors": "Weihao Yang,Hao Huang,Donglei Wu,Ningke Li,Yanqi Pan,Qiyang Zheng,Wen Xia,Shiyi Li,Qiang Wang", "background": "Mixture-of-Experts (MoE) 架构因能够扩展大规模模型而变得流行。然而，数据的快速增长超出了单个数据中心（DC）的训练能力，推动了跨数据中心分布式训练的新趋势。在专家并行化（EP）中，现有的优化方法试图重叠数据通信和计算过程，但在低带宽环境下效果不佳。由于跨数据中心的数据通信时间远超过计算时间，因此，随着数据中心的增多，跨数据中心的EP导致了重要瓶颈。", "innovation": "提出了一种名为 HybridEP 的混合机制，通过动态调整专家的空间位置来减少数据通信量和频率，从而最小化通信开销。HybridEP 根据一种基于流的模型确定最优的数据传输比例，并引入基于领域划分的分区技术和参数优化的迁移策略，以进一步细化通信拓扑。实验结果显示，在带宽受限场景下，HybridEP 相比现有的最佳 MoE 训练系统性能提升了 5.6 倍。在不同带宽环境下，使用 1000 个数据中心（DC）的大规模仿真实验表明，HybridEP 甚至可实现 1.45 倍的加速。", "conclusion": "HybridEP 作为一种更通用的专家并行化机制，在带宽受限的跨数据中心场景中具有更好的扩展性。实验表明，该机制能有效提高 MoE 模型的训练效率和性能。"}
{"llm_update_time": "20251023", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.19382", "html_url": "https://arxiv.org/abs/2510.19382", "title": "一种结构发现的去随机化框架及其在神经网络及其他领域中的应用", "title_en": "A Derandomization Framework for Structure Discovery: Applications in Neural Networks and Beyond", "authors": "Nikos Tsikouras,Yorgos Pantis,Ioannis Mitliagkas,Christos Tzamos", "background": "理解神经网络中特征学习的动力学仍然是一个重大挑战。Mousavi-Hosseini等人（2023年）的工作分析了多个索引的教师-学生设置，并表明在使用随机梯度下降（SGD）和强正则化器训练时，两层的学生网络的第一层权重会形成低秩结构。这种结构特性已被证明能降低泛化的样本复杂度。在此基础上，作者进一步在额外假设下建立了特定算法的学习保证。本文聚焦于结构的发现，研究在较弱假设下这一问题，具体包括任意大小和深度的神经网络、所有参数可训练、任意光滑损失函数、较小的正则化和通过达到二阶停滞点（SOSP）的任何训练方法（例如，扰动梯度下降）来训练的神经网络的研究。其中，核心在于一个关键的‘去随机化’引理，该引理说明在温和条件下，优化期望函数$\text{E}_{\textbf{x}}\text{[}g_{\theta}\text{(}\textbf{W}\text{x}+\textbf{b}\text{)}\text{]}$将收敛到$\textbf{W}=\textbf{0}$的点，这一基本性质直接解释了结构发现的本质，并在MAXCUT的端到端近似及约翰逊-林德施特兰斯嵌入计算等领域中具有直接应用价值", "innovation": "本文提出了一个去随机化框架，用于研究在较弱假设下神经网络结构发现的问题。该框架允许任意大小和深度的神经网络、所有参数可训练、任意光滑损失函数、较小的正则化和通过达到二阶停滞点（SOSP）的任何训练方法（例如，扰动梯度下降）来训练的神经网络进行研究。核心的‘去随机化’引理直接解释了结构发现的本质，并具有广泛的应用价值。这些应用包括MAXCUT的端到端近似及约翰逊-林德施特兰斯嵌入计算等领域。", "conclusion": "该研究在较弱假设下对结构发现的本质提供了新的见解，通过构建一个去随机化引理，直接解释了神经网络中低秩结构的形成过程，简化了结构发现的分析方法，并在多个领域展示了其广泛的应用前景。"}
{"llm_update_time": "20251023", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.19484", "html_url": "https://arxiv.org/abs/2510.19484", "title": "KnowMol: 采用多层化学知识推动分子大型语言模型的发展", "title_en": "KnowMol: Advancing Molecular Large Language Models with Multi-Level Chemical Knowledge", "authors": "Zaifei Yang,Hong Chang,Ruibing Hou,Shiguang Shan,Xilin Chen", "background": "分子大型语言模型由于在分子应用方面有令人期待的潜力而备受关注。然而，现有的分子大型语言模型在理解分子方面存在局限，这主要源于不充分的文本描述和预训练阶段化学结构表示的不足。这些问题阻碍了模型在分子理解及生成任务中的表现。", "innovation": "该研究引入了包含10万条细粒度化学分子标注的KnowMol-100K大规模数据集，并利用这种化学知识为分子提供了有效的表示方法，解决了现有表示策略的不足。在此基础上，开发了KnowMol，这是一种最新的多模态分子大型语言模型。实验结果表明， KnowMol 在分子理解和生成任务中表现出优越性能。", "conclusion": "KnowMol 通过利用多层化学知识，显著提高了分子大型语言模型在理解化学分子方面的性能。该模型为分子科学和相关应用提供了更强有力的支持。"}
{"llm_update_time": "20251023", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.19480", "html_url": "https://arxiv.org/abs/2510.19480", "title": "在线两阶段亚模式最大化", "title_en": "Online Two-Stage Submodular Maximization", "authors": "Iasonas Nikolaou,Miltiadis Stouras,Stratis Ioannidis,Evimaria Terzi", "background": "研究了给定一组单调亚模函数，Two-Stage Submodular Maximization (2SSM)的目标是在约束基集中选择一个目标函数使该函数在平均值上最大化。然而，当这些亚模函数是在线展现时，提出了Online Two-Stage Submodular Maximization (O2SSM)问题，并以加权阈值潜力函数为亚模函数类别中的一个大且重要的子类进行研究。该类别包括影响最大化、数据汇总和设施位置等。", "innovation": "设计了一种算法，该算法在一般线性基约束下实现了次线性$(1 - 1/e)^2$-遗憾，在均匀线性基秩为$k$的情况下，达到了$(1 - 1/e)(1-e^{-k}k^k/k!)$-遗憾，后者还为（离线）2SSM问题提供了最先进的界。", "conclusion": "通过实证实验验证了在线算法的性能。\n"}
{"llm_update_time": "20251023", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.19495", "html_url": "https://arxiv.org/abs/2510.19495", "title": "通过离线强化学习增强使用非专业人士数据的模仿学习", "title_en": "Using Non-Expert Data to Robustify Imitation Learning via Offline Reinforcement Learning", "authors": "Kevin Huang,Rosario Scalise,Cleah Winston,Ayush Agrawal,Yunchu Zhang,Rohan Baijal,Markus Grotz,Byron Boots,Benjamin Burchfiel,Hongkai Dai,Masha Itkina,Paarth Shah,Abhishek Gupta", "background": "模仿学习已经被证明能有效训练机器人执行复杂的任务，这是基于专家的人类演示。然而，这种方法受限于需要高质量、任务特定的数据，这限制了机器人在现实世界中各种物体配置和场景下的适应性。相比之下，非专家数据（如玩游戏的数据、次优演示、任务的部分完成或政策的部分流程）可以提供更多覆盖范围且收集成本更低。然而，传统的模仿学习方法无法有效地利用这些数据。", "innovation": "研究提出了通过合理的设汁，利用离线强化学习作为一种工具来运用非专家数据提高模仿学习策略的性能。研究表明，标准的离线强化学习方法在现实世界中数据稀疏覆盖的情况下难以有效利用非专家数据。但是，可以通过简单的算法修改来利用这些数据，而不需要过多的假设。通过这种方法，策略分布的支持可以拓宽，从而使结合离线强化学习的模仿算法在多种初始状态下都能成功地解决问题，展示出显著增强的恢复和泛化行为。此外，这些方法可以利用所有收集的数据，包括部分或不完整的演示，来增强任务导向的策略表现", "conclusion": "这种创新在操作任务中显著扩大了原始条件下成功学习策略的范围。此外，研究表明，这些方法能够利用所有收集的数据，包括不完整或次优的演示，来增强策略表现。这强调了在机器人学习中使用算法技术以可靠的方式利用非专家数据的重要性。"}
{"llm_update_time": "20251023", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.19488", "html_url": "https://arxiv.org/abs/2510.19488", "title": "VideoAgentTrek：从未标注视频进行计算机使用预训练", "title_en": "VideoAgentTrek: Computer Use Pretraining from Unlabeled Videos", "authors": "Dunjie Lu,Yiheng Xu,Junli Wang,Haoyuan Wu,Xinyuan Wang,Zekun Wang,Junlin Yang,Hongjin Su,Jixuan Chen,Junda Chen,Yuchen Mao,Jingren Zhou,Junyang Lin,Binyuan Hui,Tao Yu", "background": "训练计算机使用代理需要大量的GUI互动数据，但大规模手动标注行动轨迹极其昂贵。因此，需要一种自动从公开屏幕录制视频中提取训练数据的可扩展管道，以消除手动标注的需要。原始视频包含隐性演示但缺乏明确的动作标签，这是一项关键挑战。本次研究旨在解决这一问题，开发了Video2Action模块，包括视频定位模型和动作内容识别器，准确检测和定位GUI动作，提取高保真的结构化参数。应用于39000个YouTube教程视频，生成了152万个自动化的互动步骤，提升了任务成功率和步骤准确性，证明了互联网视频可以转换为高质量的监督信息，为计算机使用代理提供了一种可扩展的替代昂贵的手动标注方法。", "innovation": "开发了VideoAgentTrek管道，实现自动从大规模未标注视频中提取训练数据。具体创新点在于提出Video2Action模块，它包括视频定位模型和动作内容识别器，能够准确地检测和定位GUI动作，并提取精确的结构化参数。此外，通过使用生成的数据持续预训练并进行监督微调，实现了显著的任务成功率和步骤准确性的提升。", "conclusion": "互联网中的视频可以转化为高质量的计算机使用代理监督数据，提供了一种替代传统昂贵手动标注的可扩展方法。通过使用大量未标注的屏幕录像，可以有效生成训练数据，改善代理性能，表明被动收集的数据也可以被有效利用。"}
{"llm_update_time": "20251023", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.19528", "html_url": "https://arxiv.org/abs/2510.19528", "title": "学习上界下界价值包络来塑造在线强化学习：一种基本原则的方法", "title_en": "Learning Upper Lower Value Envelopes to Shape Online RL: A Principled Approach", "authors": "Sebastian Reboul,Hélène Halconruy,Randal Douc", "background": "研究的重点是利用离线数据加速在线强化学习，这是一个具有巨大潜力但在理论支持方面有限的方向。研究集中在如何在这一背景下学习和应用价值包络。现有方法存在固定形态函数依赖，而论文提出的方法通过脱耦合上下界，使上限与下限能灵活且精确地建模。", "innovation": "提出了一个原则性的两阶段框架：第一阶段使用离线数据推断价值函数的上限和下限，第二阶段将这些学习到的边界整合到在线算法中。这使方法能够提供更灵活和紧密的近似。相比依赖固定形态函数的方法，本研究的包络是数据驱动的，并明确建模为随机变量，且通过滤波论证确保各阶段的独立性。", "conclusion": "分析建立了由两个可解释要素决定的高概率后悔边界，从而正式地建立了离线预训练和在线微调之间的联系。实验结果表明，与UCBVI和其他先前的方法相比，该方法在表格MDP上的后悔减少显著。"}
{"llm_update_time": "20251023", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.19496", "html_url": "https://arxiv.org/abs/2510.19496", "title": "CARES: Context-Aware Resolution Selector for VLMs", "title_en": "CARES: Context-Aware Resolution Selector for VLMs", "authors": "Moshe Kimhi,Nimrod Shabtay,Raja Giryes,Chaim Baskin,Eli Schwartz", "background": "大型视觉语言模型通常以原生或高分辨率处理图像，以保持其在多种任务中的有效性。然而，这导致视觉标记占总标记的97-99%，从而增加了计算量和延迟，即使低分辨率的图像也足够使用。这对于图像处理是一个显著的资源浪费问题。尤其是在处理大批量图像数据时，高分辨率处理的高成本成为一个问题点。", "innovation": "提出了一个轻量级的预处理模块——CARES（一个上下文感知的分辨率选择器），它给定一个图像-查询对，能够预测最小的必要输入分辨率，从而减少模型的计算需求。CARES利用一个紧凑型视觉语言模型（350M）提取特征，并预测目标预训练视觉语言模型响应趋于其最佳性能时的分辨率。虽然CARES在训练时是一个离散分类器，但在推理时能够进行连续分辨率的插值，提供细粒度的控制。", "conclusion": "在跨不同分辨率和目标视觉语言模型的五个跨模态基准测试中，CARES能够保持任务性能的同时，计算量减少高达80%，显示出在单图像和自然图像处理中的潜力，大大减少了计算资源的需求。"}
{"llm_update_time": "20251023", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.19544", "html_url": "https://arxiv.org/abs/2510.19544", "title": "机器学习增强蒙特卡罗方法在组合优化中的实际优势演示", "title_en": "Demonstrating Real Advantage of Machine-Learning-Enhanced Monte Carlo for Combinatorial Optimization", "authors": "Luca Maria Del Bono,Federico Ricci-Tersenghi,Francesco Zamponi", "background": "组合优化问题既在实际应用中至关重要，也在优化方法的发展中起到核心作用。传统和量子计算方法经过多年的发展已经较为成熟，而利用机器学习辅助的方法才刚刚起步，并没有一致地超越最先进的经典方法。本文重点关注无约束二元优化问题中的Quadratic Unconstrained Binary Optimization (QUBO)类型问题，具体探讨在三维伊辛自旋玻璃体中寻找最低能量配置的挑战。我们使用一种整合了标准局部移动和通过机器学习建议的全局移动的全局退火蒙特卡罗算法。", "innovation": "本文采用了基于机器学习的全局退火蒙特卡罗算法，并证明了局部移动在获得最佳性能中起到了关键作用。该算法在基准测试中不仅超过了标准退火算法，而且在问题难度和系统大小变化时，比群体退火算法更具稳健性且无需超参数调整。", "conclusion": "研究表明，机器学习辅助的优化方法在组合优化设置中可能超越经典最先进的技术，这在我们所知的情况下是首次提供的清晰且稳健的证据。"}
{"llm_update_time": "20251023", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.19687", "html_url": "https://arxiv.org/abs/2510.19687", "title": "大型语言模型对沟通动机的敏感性如何？", "title_en": "Are Large Language Models Sensitive to the Motives Behind Communication?", "authors": "Addison J. Wu,Ryan Liu,Kerem Oktar,Theodore R. Sumers,Thomas L. Griffiths", "background": "人类交流具有目的性，处理信息时受到人类意图的影响。现有的大语言模型和AI代理也需要理解和评估信息来源的动机。", "innovation": "本文通过对照认知科学中的控制实验，验证了大语言模型对动机性证言的学习符合理性模型。此外，研究还扩展到赞助的在线广告等更加自然的情境，发现模型的推理与理性模型的预测并不完全一致，但通过一个简单的干预手段可以显著提高模型对动机和激励因素的重视度。", "conclusion": "大语言模型对他人动机有一定的敏感性，但在不同情境下需要改进以更好地反映理性模型。"}
{"llm_update_time": "20251023", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.19586", "html_url": "https://arxiv.org/abs/2510.19586", "title": "地球观测中分割模型的不确定性评估", "title_en": "Uncertainty evaluation of segmentation models for Earth observation", "authors": "Melanie Rey,Andriy Mnih,Maxim Neumann,Matt Overlan,Drew Purves", "background": "本文研究了基于卫星图像的语义分割预测中的不确定性估计方法。与标准图像分类相比，分割的不确定性估计面临独特挑战，需要能够产生逐像素估计的可扩展方法。大多数相关研究集中在场景理解和医学成像上，而本文则专注于遥感和地球观测应用中的现有方法的基准测试。实验重点评估不确定性度量的实际效用，测试它们在识别预测错误和噪声 corrupted 输入图像区域方面的能力。研究选择 PASTIS 和 ForTy 两个遥感数据集进行实验，这两个数据集在规模、地理覆盖范围和标签置信度上有所不同。", "innovation": "本文在遥感和地球观测应用程序中评估现有方法的基准测试，并且选择合适的模型和不确定性度量进行组合，以测试不确定性度量在识别预测错误和噪声 corrupted 输入图像区域方面的能力。基于研究结果提出了若干实用建议，进一步推动了该领域的研究和发展。", "conclusion": "本文广泛评估了部分模型在不同遥感数据集上的不确定性估计，强调了在地球观测中的应用。研究提出了具体的实用建议，包括选择合适的模型和不确定性度量组合，以提高不确定性估计的实际效用。"}
{"llm_update_time": "20251023", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.19665", "html_url": "https://arxiv.org/abs/2510.19665", "title": "关于Chernikov和Towsner最近预印本的注记", "title_en": "Remarks on a recent preprint of Chernikov and Towsner", "authors": "Maryanthe Malliaris", "background": "在Chernikov和Towsner的arXiv:2510.02420(1)中，提到了一个定理，但是在arXiv:2510.02420(2)中，虽然这个定理被修正了，但证明过程中存在错误。由于定理的相关性，原本将他们的工作与Coregliano-Malliaris的高arity PAC学习相关联的结论不再成立，而这种关联的消失是由于底层定义的变化对论文的结论产生了影响。因此，该论文指出了原定理和证明过程中的问题，并解释了为何原定义未能涵盖某些关键方面，这正是他们后续工作设计时需要考虑的", "innovation": "指出Chernikov和Towsner关于定理证明过程中的错误，重新分析了相关结论，并强调了原定义未涵盖的关键问题，这对理解高arity PAC学习领域的相关工作具有重要作用", "conclusion": "原定理和证明过程中的问题使得他们之前关于高arity PAC学习领域的相关结论不再成立，阐明了原定义的局限性，强调在高arity PAC学习领域中，原工作的某些方面需要进一步改进。"}
{"llm_update_time": "20251023", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.19579", "html_url": "https://arxiv.org/abs/2510.19579", "title": "地球观测中的多模态协作学习：通过模态协作提升单模态模型", "title_en": "Multi-modal Co-learning for Earth Observation: Enhancing single-modality models via modality collaboration", "authors": "Francisco Mena,Dino Ienco,Cassio F. Dantas,Roberto Interdonato,Andreas Dengel", "background": "多模态共学习正成为机器学习中一种有效的方法，使模型能够从不同模态中协作学习以增强单模态预测。地球观测（EO）是多模态数据分析的典范领域，其中各种遥感传感器收集数据来感知我们的地球。前所未有的大数据量带来了新的挑战。具体来说，由于实际操作限制，获取相同的传感器模态在训练和推理阶段变得越来越复杂。因此，多模态共学习提供了一种利用大量训练阶段的传感器数据来提高单模态模型性能以适应推理时间部署的有前景的策略。当前研究大多集中在为特定下游任务或推理阶段可用的特定模态设计定制解决方案。为应对这一挑战，本文提出了一种新的多模态共学习框架，该框架能够在各种任务中进行泛化，而不针对推理阶段的特定模态。该方法结合了对比学习和模态区分学习，引导单模态模型将内部模型结构化为模态共享和模态特定信息。本研究在覆盖不同传感器模态的分类和回归的四个EO基准数据集上进行评估，其中仅在训练时可用的模态在推理时可用。实验结果表明，在广泛的研究和计算机视觉文献以及特定于EO的方法中，我们的框架在单模态推理场景下的预测性能均有提高。这证实了我们框架在EO应用中的有效性。", "innovation": "提出了一种新的多模态共学习框架，能够泛化应用于不同的任务，结合对比学习和模态区分学习来引导单模态模型，使其内部模型结构化为模态共享和模态特定信息。该方法在四个不同的EO基准数据集上进行了评估，并在单模态推理场景中展示了优于现有方法的预测性能。", "conclusion": "本研究提出的多模态共学习框架在不同的EO应用中展示了更好的预测性能，验证了该方法在单模态推理场景中的有效性。"}
{"llm_update_time": "20251023", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.19731", "html_url": "https://arxiv.org/abs/2510.19731", "title": "地球与太空之间：关于非地面网络中HAPS的综述", "title_en": "Bridging Earth and Space: A Survey on HAPS for Non-Terrestrial Networks", "authors": "G. Svistunov(1),A. Akhtarshenas(1),D. López-Pérez(1),M. Giordani(2),G. Geraci(3),H. Yanikomeroglu(4) ((1) Universitat Politècnica de València, (2) University of Padova, (3) Universitat Pompeu Fabra, (4) Carleton University)", "background": "HAPS正在成为6G无线网络演进的关键使能器，连接地面和非地面基础设施。在平流层操作的HAPS能够提供广域覆盖、低延迟、高效宽带通信，并且具有灵活的部署选项，适用于多种应用程序。", "innovation": "本文综述了HAPS在6G生态系统中的应用场景、技术和整合策略，涵盖了HAPS在扩展未连接区域、支持动态回传、促进大规模物联网以及为自主和沉浸式服务提供可靠低延迟通信方面的角色。论文还回顾了地球和非地面网络集成的先进架构，概述了近期的现场试验，并详细讨论了关键使能技术，如信道建模、AI驱动的资源分配、干扰控制、移动管理和高效通信。", "conclusion": "通过填补现有文献中的空白，本文将HAPS定位为全球集成、可靠且可持续的6G网络的基础组件。"}
{"llm_update_time": "20251023", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.19733", "html_url": "https://arxiv.org/abs/2510.19733", "title": "Zhyper: 因子超网络模型用于条件化大语言模型微调", "title_en": "Zhyper: Factorized Hypernetworks for Conditioned LLM Fine-Tuning", "authors": "M. H. I. Abdalla,Zhipin Wang,Christian Frey,Steffen Eger,Josif Grabocka", "background": "大型语言模型（LLM）的条件化是指通过特定的文化规范、政治信仰或其他指定语义条件来指导LLM生成内容。然而，提示工程技术无法确保LLM按预期条件行为，因为预训练和校准数据集具有归纳偏差。之前的研究集中于通过直接条件化LoRA权重来微调LLM，但这种方法需要大量的参数。", "innovation": "本文提出了一种参数高效的因素超网络框架Zhyper，可以从文本描述生成上下文感知的LoRA适配器。实验表明，Zhyper在多项基准测试中表现竞争力，参数量比最先进的基线少26倍。此外，Zhyper还扩展到了文化对齐，提高了跨领域的泛化能力和细微情境价值的捕捉。", "conclusion": "Zhyper通过因素超网络框架有效解决微调LLM时的参数效率问题，实现了更好的上下文感知和情境价值捕捉，特别是在跨领域的应用中表现出色，与最先进的基线相比，参数少至26倍。"}
{"llm_update_time": "20251023", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.19767", "html_url": "https://arxiv.org/abs/2510.19767", "title": "SmartSwitch: 通过促进更深层次思考来克服LLM推理中的浅层思考，推进其推理能力", "title_en": "SmartSwitch: Advancing LLM Reasoning by Overcoming Underthinking via Promoting Deeper Thought Exploration", "authors": "Xichen Zhang,Sitong Wu,Haoru Tan,Shaozuo Yu,Yinghao Zhu,Ziyi He,Jiaya Jia", "background": "长链推理（LongCoT）能力是大型语言模型在复杂推理任务中取得突破的关键。然而，模型经常出现浅层思考的问题，即在未经充分探索的情况下频繁切换思想，这限制了模型的性能和标记效率。", "innovation": "提出了一个简单有效的推理策略——SmartSwitch推理框架。该框架可以无缝集成到任何大型语言模型中，持续监控模型的推理过程，发现浅层思考并引导模型进行更深入的探索。具体来说，感知模块识别思想切换的点并使用现成的过程奖励模型（PRM）评估前一个思想的潜力。如果发现潜在有价值的思想被过早放弃，干预模块会中断正在进行的推理，回溯到切换点之前，插入“深入提示”以鼓励沿着那条有希望的路径进一步探索。", "conclusion": "在具有挑战性的数学推理基准测试中，我们的方法显著提高了不同规模大型语言模型的性能。"}
{"llm_update_time": "20251023", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.19689", "html_url": "https://arxiv.org/abs/2510.19689", "title": "企业人力资源分析中的无服务器GPU架构：一项生产规模的BDaaS实现", "title_en": "Serverless GPU Architecture for Enterprise HR Analytics: A Production-Scale BDaaS Implementation", "authors": "Guilin Zhang,Wulan Guo,Ziqi Tan,Srinivas Vippagunta,Suchitra Raman,Shreeshankar Chatterjee,Ju Lin,Shang Liu,Mary Schladenhauffen,Jeffrey Luo,Hailong Jiang", "background": "随着工业和政府组织越来越多地依赖数据驱动的分析来处理劳动力、财务以及受监管的决策过程，及时性、成本效率和合规性成为了关键因素。分布式框架如Spark和Flink虽有效应对大规模批处理或流处理分析，但也引入了协调复杂性和审计开销等问题，这些问题与中等规模、延迟敏感的推理不匹配。同时，云供应商现在提供了无服务器GPU，并且像TabNet这样的模型使表型机器学习更具可解释性，这激励了在受监管环境中新的部署蓝图。", "innovation": "本文介绍了一种面向生产的大数据即服务（BDaaS）蓝图，该蓝图将单节点无服务器GPU运行时与TabNet集成。设计利用GPU加速以提高吞吐量、无服务器弹性以减少成本、以及特征掩码可解释性以满足IL4/FIPS合规性。通过HR、Adult和BLS数据集基准测试，与Spark和CPU基线进行比较，结果显示GPU管道在每千次推理的成本、延迟和吞吐量方面分别比Spark基准提高了90%、98倍和4.5倍，同时合规机制仅增加约5.7毫秒的延迟，且p99<22毫秒。在高峰负载下，可解释性保持稳定，确保了可靠的审计能力。", "conclusion": "研究结果提供了合规意识的基准、可重复的Helm打包蓝图以及展示安全、可解释且成本效益高的无服务器GPU分析在受监管的企业和政府环境中的实用性的决策框架。"}
{"llm_update_time": "20251023", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.19761", "html_url": "https://arxiv.org/abs/2510.19761", "title": "探索深度神经网络层数对网络入侵检测系统中对抗攻击的影响", "title_en": "Exploring the Effect of DNN Depth on Adversarial Attacks in Network Intrusion Detection Systems", "authors": "Mohamed ElShehaby,Ashraf Matrawy", "background": "对抗攻击对机器学习系统，尤其是深度神经网络（DNNs），构成了重大挑战。这些攻击通过微小地改变输入数据使得模型产生错误预测。本文主要探讨在网络安全检测系统（NIDS）领域中，增加深度神经网络的层数是否可以提高其对抗对抗攻击的鲁棒性，以及不同领域的实验结果对比。", "innovation": "本文通过对比网络入侵检测系统与计算机视觉领域中各种DNN的对抗鲁棒性，揭示了在NIDS领域增加层深不一定改善鲁棒性，甚至可能显著降低其对抗攻击的能力。而在计算机视觉领域，增加深度的影响更为温和。", "conclusion": "结果显示，对于NIDS应用，增加更多的层数并不一定能够提升其鲁棒性，而可能反而降低其对抗攻击的能力。相比之下，计算机视觉领域中，增加更多层的DNN稳健性影响较小。这些发现可以为开发稳健性更好的神经网络在NIDS应用中提供指导，同时也凸显了网络安全领域的独特特征。"}
{"llm_update_time": "20251023", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.19779", "html_url": "https://arxiv.org/abs/2510.19779", "title": "AdaSPEC：高效推测解码器的选择性知识蒸馏", "title_en": "AdaSPEC: Selective Knowledge Distillation for Efficient Speculative Decoders", "authors": "Yuezhou Hu,Jiaxin Guo,Xinyu Feng,Tuo Zhao", "background": "Speculative Decoding（推测解码，SD）通过使用一个小规模模型生成预测，然后由大规模目标模型验证，来加速大型语言模型的推理。然而，传统的知识蒸馏（KD）方法试图在所有标记上最小化这些模型之间的KL散度，这与SD的实际目标——最大化标记接受率——不一致。这导致小规模模型在吸收大型模型知识时受到容量限制，从而导致性能不佳。", "innovation": "本文提出了一种新颖的方法AdaSPEC，它在KD过程中引入了选择性标记过滤。AdaSPEC利用参考模型识别并过滤难以适应的标记，从而使小规模模型更好地与大规模目标模型对齐于简单的标记，从而在不牺牲生成质量的情况下提高整体标记接受率。实验结果表明，AdaSPEC在不同任务（算术推理、指令遵循、编程和总结）上均优于最先进的DistillSpec方法，实现更高的接受率（最高达15%）.", "conclusion": "研究通过AdaSPEC方法改进了传统的知识蒸馏方法，提高了模型的性能。实验展示了在多种任务上的有效性，并且该研究的方法公开可用。"}
{"llm_update_time": "20251023", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.19799", "html_url": "https://arxiv.org/abs/2510.19799", "title": "集成透明模型、大语言模型和从业者参与循环：一项公益项目评估案例", "title_en": "Integrating Transparent Models, LLMs, and Practitioner-in-the-Loop: A Case of Nonprofit Program Evaluation", "authors": "Ji Ma,Albert Casella", "background": "公共和非营利组织往往对采用人工智能工具持谨慎态度，因为许多模型缺乏透明性，尽管标准方法通常是分析总体趋势而非提供具体案例指导。这项研究测试了一种从业者参与的流程，该流程结合了透明决策树模型和大型语言模型（LLMs），以提高预测准确性、可解释性和生成实用洞察的能力。", "innovation": "研究提出了一种新的工作流程，该流程通过将透明决策树模型与大型语言模型结合，让从业者在整个过程中参与特征工程、模型设计、解释审查和使用性评估，以确保领域专业知识在整个分析阶段的指导下发挥作用。这种流程的创新之处在于它不仅提高了模型的准确性和可解释性，还考虑了使用者的实际需求。", "conclusion": "研究结果表明，结合透明模型、大型语言模型和从业者输入，能够实现精确、可信且可操作的案例级评估，为公共和非营利部门负责任地采用人工智能提供了可行路径。"}
{"llm_update_time": "20251023", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.19788", "html_url": "https://arxiv.org/abs/2510.19788", "title": "Benchmarking World-Model Learning", "title_en": "Benchmarking World-Model Learning", "authors": "Archana Warrier,Dat Nyugen,Michelangelo Naim,Moksh Jain,Yichao Liang,Karen Schroeder,Cambridge Yang,Joshua B. Tenenbaum,Sebastian Vollmer,Kevin Ellis,Zenna Tavares", "background": "当前用于学习和评估世界模型的方法与上述目标相背离：训练和评估主要聚焦于下一帧的预测，成功则通过环境中的奖励最大化来衡量。作者提出了一种新的评估协议WorldTest，旨在更好地检验模型学习代理的能力和灵活性，使其能独立于奖励任务，并在不同的相关环境中进行无奖励探索和目标检验。", "innovation": "WorldTest提出了一个开放式的评估协议，要求模型能够在未知的任务环境中进行广泛的探索，并且该协议对模型的表现不局限于特定的表现形式，从而可以进行跨方法比较。通过实例化WorldTest的框架，使用AutumnBench，一套43个互动网格环境和129种任务，作者比较了人类参与者和三种前沿模型的表现，发现虽然人类的表现优于模型，但在某些环境中增加计算性能仅对某些环境有效。", "conclusion": "WorldTest为评价模型学习环境动力学提供了新的框架，包括无奖励探索、基于行为的评分等，而AutumnBench揭示了世界模型学习中广泛存在的改进空间。"}
{"llm_update_time": "20251023", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.19807", "html_url": "https://arxiv.org/abs/2510.19807", "title": "Scaf-GRPO: 梯级分层组相对策略优化以增强LLM推理能力", "title_en": "Scaf-GRPO: Scaffolded Group Relative Policy Optimization for Enhancing LLM Reasoning", "authors": "Xichen Zhang,Sitong Wu,Yinghao Zhu,Haoru Tan,Shaozuo Yu,Ziyi He,Jiaya Jia", "background": " reinforcement learning from verifiable rewards for LLMs has enhanced their complex reasoning abilities, but they are constrained by the 'learning cliff' phenomenon, which causes models to fail when faced with problems beyond their current capability, leading to a persistent zero-reward signal and stalling progress in policy optimization algorithms like GRPO.", "innovation": "Scaf-GRPO是一种逐步训练框架，它仅在模型独立学习停滞时提供最小指导。该框架首先诊断学习停滞，然后通过注入分等级的提示来干预，这些提示从抽象概念到具体步骤不等，使模型能够自行构建有效解决方案。实验表明，Scaf-GRPO在挑战性数学基准测试中提高了Qwen2.5-Math-7B模型的pass@1得分，比GRPO基准提高了44.3%。", "conclusion": "我们的框架提供了一种稳健而有效的解决方法，用于解锁模型解决之前超出其能力范围的问题的能力，这对于扩展自主推理的边界至关重要。"}
{"llm_update_time": "20251023", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.19808", "html_url": "https://arxiv.org/abs/2510.19808", "title": "Pico-Banana-400K：面向文本指导图像编辑的大规模数据集", "title_en": "Pico-Banana-400K: A Large-Scale Dataset for Text-Guided Image Editing", "authors": "Yusu Qian,Eli Bocek-Rivele,Liangchen Song,Jialing Tong,Yinfei Yang,Jiasen Lu,Wenze Hu,Zhe Gan", "background": "近年来的多模态模型已经展示了出色的文本引导图像编辑能力，如GPT-4o和Nano-Banana等系统设立了新的基准。然而，研究社区的进展仍然受到缺乏大量高质量和公开可用的真实图像数据集的限制。", "innovation": "Pico-Banana-400K是一个全面的400K图像数据集，用于基于指令的图像编辑。该数据集通过利用Nano-Banana从OpenImages集合中的真实照片生成多样化的编辑对，以系统的方法确保了高质量和多样性的全面覆盖。此外，该数据集包含三个专门的子集：多轮编辑集合、偏好子集和长短期编辑指令对，以支持复杂编辑场景的研究。", "conclusion": "通过提供这个大规模、高质量和任务丰富的资源，Pico-Banana-400K为训练和基准测试下一代文本引导图像编辑模型奠定了坚实的基石。"}
{"llm_update_time": "20251023", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2303.04201", "html_url": "https://arxiv.org/abs/2303.04201", "title": "DR-VIDAL -- Doubly Robust Variational Information-theoretic Deep Adversarial Learning for Counterfactual Prediction and Treatment Effect Estimation on Real World Data", "title_en": "DR-VIDAL -- Doubly Robust Variational Information-theoretic Deep Adversarial Learning for Counterfactual Prediction and Treatment Effect Estimation on Real World Data", "authors": "Shantanu Ghosh,Zheng Feng,Jiang Bian,Kevin Butler,Mattia Prosperi", "background": "从真实世界的观察性（非随机化）数据中确定干预措施对结果的因果效应，如使用电子健康记录进行治疗重定位，具有挑战性，主要由于潜在的偏见。虽然因果深度学习在估计个体治疗效果方面已有提升，但现有的技术仍存在局限性。", "innovation": "提出了一种新颖的生成框架——双重稳健变分信息论深度对抗学习（DR-VIDAL），将两个治疗和结果的联合模型结合起来，即使其中一个模型存在误指定也能确保未被偏差影响的个体化治疗效果估计。该框架整合了变分自动编码器（VAE）、基于信息论的生成对抗网络（Info-GAN）和双重稳健模块。", "conclusion": "DR-VIDAL 将因果假设、VAE、Info-GAN 和双重稳健性融为一体，形成了一个全面且高效的框架。在合成和真实世界数据集（Infant Health and Development Program、Twin Birth Registry、National Supported Work Program）上，DR-VIDAL 的性能优于其他生成和非生成方法。相关代码可在<这个> https URL 下获取，使用 MIT 许可证。"}
{"llm_update_time": "20251023", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2306.10407", "html_url": "https://arxiv.org/abs/2306.10407", "title": "FP-IRL: Fokker-Planck 反向强化学习 -- 一种对马尔可夫决策过程的物理约束方法", "title_en": "FP-IRL: Fokker-Planck Inverse Reinforcement Learning -- A Physics-Constrained Approach to Markov Decision Processes", "authors": "Chengyang Huang,Siddhartha Srivastava,Kenneth K. Y. Ho,Kathy E. Luker,Gary D. Luker,Xun Huan,Krishna Garikipati", "background": "逆向强化学习（IRL）是一种强大的范式，用于揭示驱动智能体行为的激励结构，通过从马尔可夫决策过程（MDP）中的观测轨迹推断未知的奖励函数。然而，目前大多数现有的IRL方法都依赖于过渡函数，要么规定，要么预先估计，这在底层动力学未知、不可观察或难以采样的情况下构成了重大挑战。本文探讨了一种新型的Fokker-Planck约束增强学习（FP-IRL），该方法专为受Fokker-Planck（FP）动力学驱动的系统设计，可以从轨迹数据直接推断出奖励和过渡函数，而不需要访问采样过渡。本文通过建立马尔可夫决策过程（MDP）和Fokker-Planck方程之间的猜想等价性，建立了奖励最大化和自由能最小化之间的联系，从而通过变分系统识别方法实现对势能函数的推断。", "innovation": "提出了一种新型的Fokker-Planck约束反向强化学习（FP-IRL），解决了现有IRL方法中对过渡函数依赖的问题，可以直接从轨迹数据推断出奖励和过渡函数，避免了采样过渡函数的需求。通过建立MDP和Fokker-Planck方程之间的等价关系，引入变分系统识别方法，实现了潜在函数的推断，并复原了所有MDP的组成部分。", "conclusion": "通过合成基准和修改后的山车问题实验，证明FP-IRL能够准确恢复智能体的激励，同时保持计算效率和物理可解释性。"}
{"llm_update_time": "20251023", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2402.05960", "html_url": "https://arxiv.org/abs/2402.05960", "title": "基于相位的非平稳时间序列泛化学习", "title_en": "Phase-driven Domain Generalizable Learning for Nonstationary Time Series", "authors": "Payal Mohapatra,Lixu Wang,Qi Zhu", "background": "时间序列分析是连续传感应用中的基本任务，但在实际应用场景中，数据的分布往往会发生变化，这要求学习到具有泛化能力的表征。对于非平稳时间序列，其统计和谱特性会随时间变化，这使得学习任务更加复杂。", "innovation": "本文提出了一种基于相位驱动的泛化时间序列分类框架，PhASER。该框架包括三部分创新点：1）基于希尔伯特变换的增强，保持任务相关性的同时多样化非平稳性；2）分频-相位编码，视时变幅度和相位为独立模态；3）相位残差特征广播，通过残差连接整合二维相位特征与一维信号表征，提高泛化学习能力。", "conclusion": "通过五个数据集的广泛评估，PhASER 框架在睡眠阶段分类、人类活动识别和手势识别等任务上表现出优越性，与13种最先进的基线方法相比，平均提高了5%的性能，某些情况下提高了11%。此外，PhASER 的原理可以广泛应用于增强现有时间序列表示学习模型的泛化能力。"}
{"llm_update_time": "20251023", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.19811", "html_url": "https://arxiv.org/abs/2510.19811", "title": "Hubble: 一个促进大语言模型记忆研究的模型套件", "title_en": "Hubble: a Model Suite to Advance the Study of LLM Memorization", "authors": "Johnny Tian-Zheng Wei,Ameya Godbole,Mohammad Aflah Khan,Ryan Wang,Xiaoyuan Zhu,James Flemings,Nitya Kashyap,Krishna P. Gummadi,Willie Neiswanger,Robin Jia", "background": "本文介绍了Hubble，一个用于大语言模型（LLM）记忆研究的完全开源的模型套件。Hubble模型包括标准和扰动版本，标准模型基于大型英文语料库进行预训练，而扰动模型则在相同的方式下进行训练，并配有受控插入的文本，以模拟关键的记忆风险。该论文的核心发布包括8个模型，以及6个不同预训练阶段插入文本的模型，这表明记忆风险由敏感数据的频率与训练语料库的大小之间的关系决定。这些研究成果为解决记忆风险提供了一般性的最佳实践，并为大语言模型的记忆研究提供了广泛的研究工具。", "innovation": "Hubble模型的创新在于它是一个开源的模型套件，用于研究大语言模型的记忆问题，其中包含了标准和扰动两种类型的模型。通过这项研究，研究人员能够更深入地理解敏感数据在大语言模型中的记忆行为，并提出相应的减少风险的方法。此外，Hubble模型的随机插入特性使其成为会员推理和机器遗忘的理想测试平台。", "conclusion": "Hubble模型的研究揭示了敏感数据的频率与记忆风险之间的关系，并提出通过增加训练语料库的大小来稀释敏感数据，以及安排敏感数据在训练的早期出现的应对策略。此外，Hubble模型还为各种记忆研究提供了广泛的可能性，并邀请社区进一步探索、基准测试和构建相关工作。"}
{"llm_update_time": "20251023", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2312.10107", "html_url": "https://arxiv.org/abs/2312.10107", "title": "面向上下文的领域泛化：理解边际迁移学习的好处和限制", "title_en": "Towards Context-Aware Domain Generalization: Understanding the Benefits and Limits of Marginal Transfer Learning", "authors": "Jens Müller,Lars Kühmichel,Martin Rohbeck,Stefan T. Radev,Ullrich Köthe", "background": "本文探讨了在新领域中输入$X$的上下文信息如何能够改善深度学习模型预测的问题。在领域泛化的边际迁移学习研究基础上，将上下文定义为一组与输入相同领域关联的数据点的不变表示。通过对该方法在理论上可能获得益处的条件进行分析，并提出了两个易于实践验证的关键条件。此外，还探讨了这种方法所保证的鲁棒性的分布转移情景。实验结果表明，提出的条件在区分有利和不利场景方面有效。最后，通过检测模型在不同领域的不可证外推情况，识别潜在的故障案例，并展示了如何在预测性能和鲁棒性之间权衡选择最可靠的模型的方法。", "innovation": "本文创新地将上下文定义为数据点的不变表示，并提出了两个易于实践验证的关键条件。此外，作者展示了如何在预测性能和鲁棒性之间选择最可靠的模型的方法，解决了传统权衡问题。", "conclusion": "本文分析了上下文感知领域泛化的条件，提出了一个用于选择最可靠的模型的方法。实验结果显示，提出的条件能够有效地识别有利和不利的场景，展示了边际迁移学习在鲁棒性方面的潜力，并可以帮助识别模型在不可证外推中的潜在故障案例。"}
{"llm_update_time": "20251023", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2309.16519", "html_url": "https://arxiv.org/abs/2309.16519", "title": "AtomSurf : 表面表示在蛋白质结构学习中的应用", "title_en": "AtomSurf : Surface Representation for Learning on Protein Structures", "authors": "Vincent Mallet,Souhaib Attaiki,Yangyang Miao,Bruno Correia,Maks Ovsjanikov", "background": "尽管在评估和比较蛋白质数据的学习表示方面取得了显著进展，但是表面前端学习方法的作用仍然不太清楚。尤其是，尚未直接和公平地比较最好的表面前端学习方法和基于图的其他表示方法。现有的少数基于表面的方法要么单独使用表面信息，要么在全局池化上表现最佳。因此，本文通过改进最先进的表面编码器并将其应用于蛋白质学习任务来填补这一空白。然后，在Atom3D基准测试中直接和公平地比较所得到的方法与其他方法，突出表面学习的局限性。最后，提出一种集成方法，允许图和表面表示之间的特征学习共享，在所有层的节点和顶点级别实现这一目标。", "innovation": "改进最先进的表面编码器以应用于蛋白质学习任务；在Atom3D基准测试中直接和公平地比较表面表示方法和基于图的方法；提出一种集成方法，使得图和表面表示间的特征在节点和顶点级别进行学习共享；通过使用简化的表面和优化效率使该方法竞争性地在训练和推理时间上运行。", "conclusion": "所提出的方法在Atom3D基准测试的所有任务上达到了最先进的性能，同时严格遵循基准测试协议，对于结合识别绑定位点和分类结合口袋的任务也表现优异。此外，通过优化效率，使我们的工具在训练和推理时间上具有竞争力，当前实现了最好的性能。"}
{"llm_update_time": "20251023", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2405.17309", "html_url": "https://arxiv.org/abs/2405.17309", "title": "物联网和下一代网络中的图神经网络综述", "title_en": "Survey of Graph Neural Network for Internet of Things and NextG Networks", "authors": "Sabarish Krishna Moorthy,Jithin Jagannath", "background": "物联网（IoT）设备的指数增长以及6G技术推动更高的数据传输率和连接设备导致了数据量的急剧增加。这使得高效利用数据进行驱动的机器学习变得尤为重要。同时，图神经网络（GNNs）因其高性能、准确性、可扩展性和资源效率而成为适合复杂网络结构建模和信息提取的有前景的方法，但缺乏围绕物联网和下一代网络中GNN应用和进展的全面综述研究。", "innovation": "本研究通过详细描述GNN的术语、架构以及不同类型的GNN，提供了物联网和下一代网络中应用GNN的全面综述。重点关注了GNN在数据融合和入侵检测、提高频谱意识、在联网和战术系统中的应用，并将GNN与其他机器学习方法进行了对比。此外，还讨论了GNN的挑战和未来研究方向，激励在物联网和下一代网络中使用GNN的研究。", "conclusion": "本综述旨在为研究人员提供关于GNN在无线网络中的应用和最新用例的全面资源，同时对比其他机器学习方法。未来的研究方向包括解决当前挑战和探索更多应用场景。"}
{"llm_update_time": "20251023", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2305.17403", "html_url": "https://arxiv.org/abs/2305.17403", "title": "无需源数据的领域适应适用于SSVEP的脑机接口", "title_en": "Source-Free Domain Adaptation for SSVEP-based Brain-Computer Interfaces", "authors": "Osman Berke Guney,Deniz Kucukahmetler,Huseyin Ozkan", "background": "基于SSVEP的BCI拼写器能够帮助经历语言困难的人以较快的速度进行交流。然而，大多数主流方法在使用系统前需要进行一个漫长的校准期才能达到较高的信息传输率（ITR），这会给新用户带来不适。现有的方法主要通过使用标记的目标数据或直接校准用户来提高ITR，但这种方法可能给新用户带来不便或效率低下。因此，为了解决这一问题，本文提出了一种新方法，该方法利用预训练的深度神经网络（DNN）从源域数据（来自前用户的或之前实验的参与者的数据）适应新的用户（目标域），并且仅使用未标记的目标数据。这种方法通过最小化自适应和局部规则性的新自定义损失函数来适应预训练的DNN。实验证明，这种方法能够达到出色的ITR，即在基准数据集和BETA数据集上分别取得了201.15 bit/min和145.02 bit/min的I TR，且优于现有最先进的方法。同时，该方法减少了用户的校准负担，保持了较高的字符识别准确性和ITR，因而加速了BCI系统的日常生活应用。", "innovation": "本文提出了无需源数据的领域适应方法，利用预训练的深度神经网络从源域数据适应新的用户，仅使用未标记的目标数据进行自适应。该方法通过最小化自适应和局部规则性的新自定义损失函数来实现此目标。该方法不仅能够保持较高的字符识别准确性和ITR，而且大大减轻了用户的校准负担。", "conclusion": "本文的方法能够在无需用户校准的情况下，通过预训练的深度神经网络的自适应，显著提高基于SSVEP的BCI系统的信息传输率，同时保持较高的字符识别准确度。这将极大加速BCI系统的实际应用，为经历语言困难的用户提供高效、舒适的交流方式。"}
{"llm_update_time": "20251023", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2406.19195", "html_url": "https://arxiv.org/abs/2406.19195", "title": "利用最优传输权重的泛化误差界估计长期异质剂量反应曲线", "title_en": "Estimating Long-term Heterogeneous Dose-response Curve: Generalization Bound Leveraging Optimal Transport Weights", "authors": "Zeqin Yang,Weilin Chen,Ruichu Cai,Yuguang Yan,Zhifeng Hao,Zhipeng Yu,Zhichao Zou,Jixing Xu,Zhen Peng,Jiecheng Guo", "background": "长期治疗效果估计在许多应用中是一个重要但具有挑战性的问题。现有的方法依赖于理想假设，比如不存在未观察到的混杂因素或治疗为二元的来估计长期平均治疗效果。但在许多实际应用中，这些假设可能被违反，平均治疗效果无法满足个性化决策的需求。", "innovation": "本文提出了一个更为普遍的问题，即估计考虑到未观察到的混杂因素和连续治疗的长期异质剂量反应曲线（HDRC）。首先，通过引入最优传输权重框架，将长期观察数据与辅助的短期实验数据对齐以消除未观察到的混杂因素。其次，通过利用最优传输权重诱导的重分布，建立了条件反事实预测误差的泛化界。最后，基于上述理论基础开发了一种长期HDRC估计方法。", "conclusion": "在合成和半合成数据集上的大量实验展示了该方法的有效性。"}
{"llm_update_time": "20251023", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2406.18851", "html_url": "https://arxiv.org/abs/2406.18851", "title": "LICO: 大型语言模型在分子优化中的上下文内推理", "title_en": "LICO: Large Language Models for In-Context Molecular Optimization", "authors": "Tung Nguyen,Aditya Grover", "background": "黑盒函数优化是科学和工程中的基本问题，许多方法通过有限的历史评估来学习代理函数，以估算潜在目标。大型语言模型凭借大量数据预训练的强大模式匹配能力展现出作为代理建模候选者的潜力。然而，由于预训练语料中的领域数据稀缺以及用自然语言表述复杂问题的挑战，直接在预训练语言模型上进行预测并不总是可行的。本文讨论了LICO模型，这是一种针对分子域的通用模型，可扩展任意基础语言模型进行黑盒优化，尤其是在分子优化方面表现出色，特别是在PMO-1K基准测试中取得了最佳性能。", "innovation": "LICO通过在语言模型中增加嵌入层和预测层，并进行上下文内预测训练，使得模型能够针对特定领域的问题进行预测。LICO能够在未见过分子属性的情况下，仅通过上下文提示进行泛化，并且在PMO基准测试中表现出色，特别是在低预算版本PMO-1K中获得最佳性能。", "conclusion": "LICO模型实现了在大型语言模型上进行分子优化的突破，展示了其在特定科学领域中的潜力，并且在分子优化基准测试中取得了与传统方法竞争的性能，特别是在成本受限的版本中表现出色。"}
{"llm_update_time": "20251023", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2410.05975", "html_url": "https://arxiv.org/abs/2410.05975", "title": "通过对比元目标学习学习", "title_en": "Learning to Learn with Contrastive Meta-Objective", "authors": "Shiguang Wu,Yaqing Wang,Yatao Bian,Quanming Yao", "background": "元学习使学习系统能够快速适应新任务，类似于人类的学习过程。现有的元学习方法都使用小批量事件训练框架，这一框架会自然地提供任务标识信息，这种信息可以作为元训练的辅助监督，从而提高泛化能力。", "innovation": "提出了利用任务标识作为辅助监督的元训练方法，通过对比元学习者学习的内容，即模型表示，实现这一点。ConML作为一种问题和学习者无关的元训练框架，评估和优化对比元目标，并与现有的元学习模型以及其他基于上下文的学习模型无缝集成，带来了显著的性能提升，而实施成本较低。", "conclusion": "ConML方法能够无缝集成到现有的元学习框架和基于上下文的学习模型中，显著提升了性能，且实施成本较小。"}
{"llm_update_time": "20251023", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2410.04297", "html_url": "https://arxiv.org/abs/2410.04297", "title": "Bootstrap Sampling Rate Greater than 1.0 May Improve Random Forest Performance", "title_en": "Bootstrap Sampling Rate Greater than 1.0 May Improve Random Forest Performance", "authors": "Stanisław Kaźmierczak,Jacek Mańdziuk", "background": "随机森林（RFs）通常使用自助采样从原始训练集（大小为N）中抽取样本，生成每棵树的独立训练集。过去的研究所指出，抽取少于N个观察值也可能会取得令人满意的结果。自助采样率（BR）定义为每次自助抽样中样本数量与总训练实例数量的比例。以往的研究仅探索了BR大于1.0的情况，但普遍认为这种做法无效。本文利用36个不同的数据集，重新评估了BR值从1.2到5.0的范围，发现与标准设置（BR ≤ 1.0）相比，较高的BR值可以带来显著的分类精度提升。此外，本文还分析了BR对RF中决策树的叶结构的影响，并考察了影响最优BR的因素。研究结果表明，最优的BR主要由数据集的特征决定，而不仅仅是RF的超参数决定。", "innovation": "本研究通过使用36个不同数据集，重新评估了自助采样率从1.2到5.0的范围，发现了更高的自助采样率可以显著提高分类精度，并分析了自助采样率对随机森林中决策树叶结构的影响以及影响最优自助采样率的因素。", "conclusion": "研究结果表明，最优的自助采样率主要由数据集特征决定，而不是随机森林的超参数决定。"}
{"llm_update_time": "20251023", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2410.07711", "html_url": "https://arxiv.org/abs/2410.07711", "title": "AdaptGrad: 自适应采样降低噪声", "title_en": "AdaptGrad: Adaptive Sampling to Reduce Noise", "authors": "Linjiang Zhou,Chao Ma,Zepeng Wang,Libing Wu,Xiaochuan Shi", "background": "Gradient Smoothing 是一种有效的方法，用于减少基于梯度的模型解释方法中的噪声。SmoothGrad 通过添加高斯噪声来缓解大部分噪声，但其关键超参数高斯噪声的方差 $\boldsymbol{\text{σ}}$ 通常是手工设定或通过启发式方法设定，这使得平滑后的梯度仍然包含一定的噪声。", "innovation": "本文将 SmoothGrad 视为卷积的推论，并从置信水平的角度重新理解梯度噪声及其作用。基于这些洞察，本文提出了基于自适应采样的梯度平滑方法 AdaptGrad。通过全面的实验证明，AdaptGrad 能够有效减少 vanilla 梯度中的几乎全部噪声，并且该方法简单且通用，适用于提高基于梯度的可解释方法的效果。", "conclusion": "AdaptGrad 有效降低了 vanilla 梯度中的几乎全部噪声，并且是一种简单且通用的方法，适用于增强基于梯度的解释方法的可视化效果。"}
{"llm_update_time": "20251023", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2410.06019", "html_url": "https://arxiv.org/abs/2410.06019", "title": "探索输入流形揭示Transformer感知", "title_en": "Unveiling Transformer Perception by Exploring Input Manifolds", "authors": "Alessandro Benfenati,Alfio Ferrara,Alessio Marta,Davide Riva,Elisabetta Rocchetti", "background": "本文介绍了一种用于Transformer模型输入空间中等价类探索的一般方法。现有的模型通常被视为输入流形上的连续变形过程，作者基于坚实的数学理论提出了这一方法。通过使用模型雅可比矩阵定义的输出空间距离度量的拉普拉斯的特征值分解，可以重建输入空间中的等价类，并在它们之间导航。这种方法使研究人员能够根据输入实例的概率分布进行两种互补的探索程序：一种用于检索与原始实例产生相同概率分布的输入实例，从而识别相同的等价类；另一种则发现产生不同概率分布的实例，通过这种方式导航到不同的等价类。最后，文章展示了如何通过将检索到的实例的嵌入重新投影到人类可读的格式中来对这些实例进行有意义的解释。", "innovation": "提出的探索方法基于坚实的数学理论，利用特征值分解技术在模型的输入空间中重建等价类。该方法能够进行两种互补的探索程序，一种是检索与原始实例具有相同概率分布的输入实例，另一种则发现不同概率分布的实例，从而实现从一个等价类向另一个等价类的导航。实例的嵌入还可以被重新投影到人类可读的格式中进行解释，具有很强的创新性。", "conclusion": "本文证明了通过探索输入流形来揭示Transformer感知的有效性。提出的探索方法能够重建输入空间中的等价类并实现输入实例之间的导航，不同等价类的实例可以通过特征值分解重新投影到人类可读的格式中，从而更好地理解模型的输入感知机制。"}
{"llm_update_time": "20251023", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2410.10811", "html_url": "https://arxiv.org/abs/2410.10811", "title": "深度线性探针生成器在权重空间学习中的应用", "title_en": "Deep Linear Probe Generators for Weight Space Learning", "authors": "Jonathan Kahana,Eliahu Horwitz,Imri Shuval,Yedid Hoshen", "background": "权重空间学习致力于提取神经网络的信息，例如其训练数据集或泛化误差。现有的研究方法直接从模型权重中学习，但面临高维权重和神经元间的置换对称性的挑战。虽然探针方法通常不单独使用，但最初的实验显示其基础版本表现意外地好。然而，当前的探针学习策略效果不佳，因此引入了Deep Linear Probe Generators（探针生成器），这是一种简单但有效的探针方法改进。", "innovation": "提出了Deep Linear Probe Generators（探针生成器），通过添加一个共享的具有深度线性架构的生成模块，提供了一种倾向于结构化的探针生成机制，从而降低了过拟合的风险，该方法在简单的结构下表现出色，性能显著优于最新的最佳方法，并且效率极高，所需FLOPs数量比其他顶级方法少2到1000倍。", "conclusion": "探针生成器（ProbeGen）作为一种简单有效的修改探针方法，通过引入深度线性生成模块提供了一种结构化的探针生成机制，降低了过拟合，并取得了显著的性能提升，同时具有很高的效率。"}
{"llm_update_time": "20251023", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2411.01074", "html_url": "https://arxiv.org/abs/2411.01074", "title": "通过激活驱动训练实现DNN模块化", "title_en": "DNN Modularization via Activation-Driven Training", "authors": "Tuan Ngo,Abid Hassan,Saad Shafiq,Nenad Medvidovic", "background": "深度神经网络（DNNs）在适应不断变化的需求时会累积技术债务，并且需要大量的重新训练成本。以前的工作提出了在训练期间和之后分解DNN模型为模块的方法。然而，这些方法存在显著的权重重叠和准确率损失、仅关注卷积层、增加复杂性和训练时间等缺点。", "innovation": "本文提出了一种基于激活驱动的模块化训练方法——MODA。MODA通过直接调节各层的激活输出来促进模型内在模块化，基于三个模块目标：同类别亲和力、跨类别分散性和紧凑性。MODA在三种知名DNN模型和五个不同大小的数据集上进行了评估，结果显示，与现有最佳实践相比，使用MODA具有以下优势：（1）MODA实现模块化所需的时间缩短了22%；（2）生成的模块具有多达24倍少的权重和37倍少的权重重叠；（3）保持原始模型的准确性，无需额外的微调；在模块替换场景中，（4）MODA将目标类别的准确性平均提高12%，同时对其他类别的影响极小。", "conclusion": "MODA提供了一种有效且高效的模块化训练方法，显著减少了训练时间和模块间的权重重叠，同时保持了原始DNN模型的准确性。这种方法为DNN模块化训练提供了新的研究方向。"}
{"llm_update_time": "20251023", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2411.04372", "html_url": "https://arxiv.org/abs/2411.04372", "title": "使用整数序列生成任务对大规模语言模型进行基准测试", "title_en": "Benchmarking Large Language Models with Integer Sequence Generation Tasks", "authors": "Daniel O'Malley,Manish Bhattarai,Javier Santos,Nishath Rajiv Ranasinghe,Erick Draayer", "background": "本文介绍了一个新型基准测试，旨在严格评估大型语言模型（LLMs）在数学推理和算法代码合成任务中的能力。该基准包括来自OEIS（Online Encyclopedia of Integer Sequences）的整数序列生成任务，并测试模型生成准确且高效的Python代码来计算这些序列的能力，而不需要使用查找表。实验涵盖了来自OpenAI、Anthropic、Meta和Google的领先模型，并通过人工专家评估引入了一种自动作弊检测机制，以防止模型利用已记忆的序列值。结果显示，专为推理设计的模型在更复杂任务中显著提高了准确性，但整体而言，硬序列上的表现不佳，表明现有的算法推理仍面临重大挑战。该基准测试提供了对最先进的LLMs的理解，特别是突显了在可靠解决复杂数学推理任务方面仍需要进一步的发展。", "innovation": "本文介绍的基准测试具有以下几个创新点：1）使用来自OEIS的整数序列生成任务作为评估工具；2）利用自动作弊检测机制确保模型不依赖于查找表；3）包含了一系列分类为“容易”或“困难”的1000个OEIS序列；4）对比了专注于推理的模型与其他非推理模型在准确性和复杂任务上的表现差异，强调了在算法推理方面仍有挑战需要解决。", "conclusion": "该基准测试表明，推理模型在复杂任务上的准确性有了显著提高，但整体性能在困难序列上仍存在较大不足，强调了需要进一步发展以解决复杂数学推理任务的算法问题。该基准测试对于理解当前最先进的LLMs在推理能力上的优势和局限性具有重要意义，尤其突显出算法推理能力的提升非常重要。"}
{"llm_update_time": "20251023", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2410.21228", "html_url": "https://arxiv.org/abs/2410.21228", "title": "LoRA vs Full Fine-tuning: An Illusion of Equivalence", "title_en": "LoRA vs Full Fine-tuning: An Illusion of Equivalence", "authors": "Reece Shuttleworth,Jacob Andreas,Antonio Torralba,Pratyusha Sharma", "background": "细调是一种将预训练的大规模语言模型适应下游任务的关键范式。近年来，低秩适应（LoRA）等方法已被证明能够以极低的可训练参数数量有效地进行大规模语言模型（LLM）的细调。然而，LoRA 和全细调所学到的解决方案是否真正等价？文章通过分析模型的权重矩阵的谱性质，研究了 LoRA 和全细调如何改变预训练模型。研究发现，LoRA 和全细调的权重矩阵在奇异值分解方面表现出很大的不同结构：使用 LoRA 训练的权重矩阵具有新的高阶奇异向量，我们称之为“入侵维度”，而使用全细调训练的权重矩阵则没有这些入侵维度。进一步研究表明，LoRA 相比全细调忘记的知识要少，且主要局限于这些“入侵维度”中。通过改变细调后与“入侵维度”相关的奇异值，因果干预表明这些维度会造成记忆损失，将其规模减小可以改善预训练分布建模，同时保持下游任务性能的轻微下降。这对于持续学习也会产生负面效应，LoRA 模型在这些环境中表现更差，这强调了我们研究的实际意义。", "innovation": "文章通过分析模型的谱性质，揭示了 LoRA 和全细调之间的重要区别。具体而言，LoRA 和全细调的权重矩阵在奇异值分解上表现出完全不同的结构：使用 LoRA 训练的权重矩阵具有新的高阶奇异向量，而使用全细调训练的权重矩阵则没有这些入侵维度。研究还发现，“入侵维度”是 LoRA 忘记的知识主要集中在这些维度上，并且通过对这些“入侵维度”的因果干预可以减少这一效应。此外，还发现缩放“入侵维度”的规模可以显著提高建模预训练分布的效果，而影响下游任务性能的下降可以忽略不计。文章强调，积累“入侵维度”可能会对模型起到负面作用，并提出这一现象在持续学习中会进一步放大。", "conclusion": "研究表明，LoRA 和全细调的解决方案并不真正等价，并且 LoRA 的“入侵维度”会导致模型遗忘。此外，积聚“入侵维度”将对模型产生不利影响，这在持续学习中会进一步放大。通过积累和干预“入侵维度”的规模，可以改善预训练分布的建模能力，这强调了我们的发现具有实际意义。"}
{"llm_update_time": "20251023", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2410.10481", "html_url": "https://arxiv.org/abs/2410.10481", "title": "基于模型的大型语言模型定制作为服务", "title_en": "Model-based Large Language Model Customization as Service", "authors": "Zhaomin Wu,Jizhou Guo,Junyi Hou,Bingsheng He,Lixin Fan,Qiang Yang", "background": "大型语言模型（LLM）服务（如OpenAI和Google提供的）在通用任务上表现出色，但在特定领域的应用中经常表现不佳。当前用于这些LLM的定制服务通常需要用户上传数据进行微调，这会带来显著的隐私风险。不同的差分隐私（DP）数据合成方法虽然提供了一种替代方案，但由于在数据中引入了过多的噪声，其有效性通常是低的。", "innovation": "我们提出了一种名为Llamdex的新框架，它使LLM的定制能够以服务的形式进行，客户上传的是预训练的领域特定模型而非数据。该客户端上传的模型，可以选择性地使用较少噪声的差分隐私进行保护，并通过连接模块插入到基础LLM中。这些连接模块的训练不需要敏感的领域数据，从而使客户能够在保持数据隐私的同时定制LLM服务。实验表明，与在相同隐私约束下的最新隐私数据合成方法相比，Llamdex在特定领域的准确度提高了最高26%，并且通过消除了用户在查询中提供领域上下文的需要，维护了与原始LLM服务相当的推理效率。", "conclusion": "Llamdex 提出了一个创新框架，通过上传预训练的领域特定模型而非原始数据进行LLM的定制服务，同时通过连接模块实现插件式定制，保护了客户的隐私同时提高了特定领域的精度和推理效率。"}
{"llm_update_time": "20251023", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2501.03627", "html_url": "https://arxiv.org/abs/2501.03627", "title": "通过有信息树- Wasserstein 距离实现样本和特征的联合层次表示学习", "title_en": "Joint Hierarchical Representation Learning of Samples and Features via Informed Tree-Wasserstein Distance", "authors": "Ya-Wei Eileen Lin,Ronald R. Coifman,Gal Mishne,Ronen Talmon", "background": "高维数据在样本和特征上常表现出层次结构。然而，现有的层次表示学习方法大多只考虑其中一个模式。本文提出了一种基于树-Wasserstein距离(TWD)的无监督方法，用于同时学习样本和特征的层次表示。该方法交替处理两种数据模式，交替构建树和计算TWD，从而逐步改善两个模式的层次表示，揭示数据的有意义模式。", "innovation": "本文创新提出了一种联合学习样本和特征层次表示的无监督方法，通过树-Wasserstein距离交替优化两个数据模式，这种方法不同于现有方法只考虑单一模式。同时，该方法还可以与超球图卷积网络结合，提升链接预测和节点分类任务的性能，并在稀疏近似和无监督Wasserstein距离学习任务上表现出色。", "conclusion": "本文提供的方法理论上收敛，通过实验证明该方法不仅提高了复杂数据结构的表示能力，还在多个任务中优于基准方法。"}
{"llm_update_time": "20251023", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2412.02289", "html_url": "https://arxiv.org/abs/2412.02289", "title": "通过使用更少的能量实现更高效的分布式学习：能量受限设备上的分布式学习", "title_en": "Learn More by Using Less: Distributed Learning with Energy-Constrained Devices", "authors": "Roberto Pereira,Cristian J. Vaca-Rubio,Luis Blanco", "background": "联邦学习（FL）作为一种在分散的、隐私保护设备上进行模型分布式训练的解决方案已崭露头角，但参与设备的能效差异导致的系统异质性限制了其实际应用。这些能源限制不仅降低了模型的准确性，还会增加客户端退出率，影响实际FL部署中的收敛性。", "innovation": "提出了一种名为LeanFed的能量感知联邦学习框架，旨在优化电池受限设备上的客户端选择和训练工作负荷。LeanFed通过动态调整每个设备在训练过程中使用的本地数据比例，实现最大限度地提高设备参与并确保其不会在通信回合过程中耗尽电池。", "conclusion": "LeanFed在CIFAR-10和CIFAR-100数据集上的严格评估表明，它能够持续提升模型的准确性和稳定性，特别是在高数据异质性和有限电池寿命的设置中，通过减少客户端退出并延长设备可用性。这种方法展示了高效、保护隐私的联邦学习在真实世界大规模应用中的潜力，为资源受限网络上的稳健和可持续的普及AI奠定了基础。"}
{"llm_update_time": "20251023", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2412.01322", "html_url": "https://arxiv.org/abs/2412.01322", "title": "使用柯尔莫哥洛夫-阿诺德网络进行滚珠轴承可解释的故障和严重程度分类", "title_en": "Explainable fault and severity classification for rolling element bearings using Kolmogorov-Arnold networks", "authors": "Spyros Rigas,Michalis Papachristou,Ioannis Sotiropoulos,Georgios Alexandridis", "background": "滚珠轴承是旋转机械的关键组件，其性能直接影响工业系统的效率和可靠性。同时，轴承故障是导致机械故障的主要原因之一，常常导致昂贵的停机时间、生产率下降，甚至在极端情况下导致严重的破坏。因此，研究提出了一种利用柯尔莫哥洛夫-阿诺德网络解决这些挑战的方法，该方法通过自动特征选择、超参数调优和统一体系结构中的可解释故障分析，实现了故障检测和严重程度分类。", "innovation": "该研究提出的框架使用浅层网络架构，选择少量特征进行训练，生成轻量级模型，通过特征属性和激活函数的符号表示提供可解释的结果。该框架已在两个广泛认可的轴承故障诊断数据集上进行了验证，实现了完美的F1分数进行故障检测，以及在故障和严重程度分类任务中取得优异的表现，涵盖了不平衡和对中不良等不同类型的故障。符号表示增强了模型的可解释性，而特征属性提供了每个研究任务的最佳特征类型或信号的见解。这些结果表明，该框架具有在实际应用中（如实时设备监控）和科学研究中（需要高效且可解释的模型）的潜在应用价值。", "conclusion": "该研究框架突出了在实际应用中（如实时设备监控）和科学研究中（需要高效且可解释的模型）的应用潜力，并为该领域的进一步研究提供了工具和方法。"}
{"llm_update_time": "20251023", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2501.07652", "html_url": "https://arxiv.org/abs/2501.07652", "title": "部分观测非线性动态系统的有限样本识别", "title_en": "Finite Sample Identification of Partially Observed Bilinear Dynamical Systems", "authors": "Yahya Sattar,Yassir Jedra,Maryam Fazel,Sarah Dean", "background": "本文考虑了从噪声输入输出数据中学习部分观测的双线性动态系统的实现问题。给定单次输入输出样本轨迹，本文提供了一个有限时间分析，以从数据中学习系统的马尔可夫型参数，从而获得双线性系统的平衡实现。该双线性系统的识别算法通过回归输出到高度相关、非线性和厚尾的协变量，学习系统的马尔可夫型参数。此外，部分观测的双线性动态系统的稳定性依赖于用于激励系统的输入序列。这些特性对算法的学习原理分析构成了重大挑战。本文解决了这些挑战，并在统一稳定性假设下提供了识别算法的高概率误差界。分析还提供了影响学习准确性和样本复杂度的系统理论量的洞察。最后，本文使用合成数据进行了数值实验以加强这些洞察。", "innovation": "本文提出了一种双线性动态系统识别算法，通过回归输出到高度相关、非线性和厚尾的协变量来学习系统的马尔可夫型参数，并在统一稳定性假设下提供了高概率误差界。此外，分析结果提供了影响学习准确性和样本复杂度的系统理论量的洞察。", "conclusion": "本文解决了部分观测的双线性动态系统的有限样本识别问题，提供了误差界，并通过合成数据的实验验证了分析结果。"}
{"llm_update_time": "20251023", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2410.10101", "html_url": "https://arxiv.org/abs/2410.10101", "title": "在多项式时间内学习线性注意", "title_en": "Learning Linear Attention in Polynomial Time", "authors": "Morris Yau,Ekin Akyürek,Jiayuan Mao,Joshua B. Tenenbaum,Stefanie Jegelka,Jacob Andreas", "background": "之前的研究探讨了Transformer模型在模拟布尔电路或图灵机方面的计算可表达性。然而，这些模拟器从观察数据中学习的可行性仍然是一个公开问题。本研究填补了这一空白，首次提供了单层Transformer（特别是带有线性注意力的）在多项式时间内学习的理论结果，具体为强健的、无假设的PAC学习。研究者证明，线性注意力可以视为在适当定义的RKHS中的一类线性预测器。因此，学习任何线性Transformer的问题可以被转换为学习扩展特征空间中的普通线性预测器，反之亦然。研究者还展示了如何高效地确定训练数据集，使得每个经验风险最小化器在轻微对称转换下等同于生成数据的线性变压器，从而保证学习到的模型将在所有输入上正确泛化。另外，研究者还展示了通过线性注意力可以执行的计算任务，包括关联记忆、有限自动机以及具有多项式运行历史的通用图灵机（UTM）的一个类别，并在三个任务上验证了这些理论发现：随机线性注意力网络的学习、键值关联学习以及执行有限自动机的学习。这些发现将Transformer的理论可表达性和可学习性之间的差距联系起来，展示了灵活且通用的计算模型在多项式时间内可高效学习。", "innovation": "本研究表明，单层带有线性注意力的Transformer在多项式时间内具有强健的、无假设的PAC学习能力。这证明了虽然详细的Transformer模型可能非常复杂，但其线性部分可以通过合适的变换转化为更加简单的形式进行学习。此外，研究者还展示了线性注意力可以实现的计算任务，包括有限自动机、 Associative Memories 和具有多项式约束的通用图灵机（UTMs），并且这些任务在实验中得到了验证。研究结果表明，理论上复杂的模型可以通过适当的理论框架转化为可学习的形式，从而有助于提高Transformer的可学习性。", "conclusion": "研究结果填补了Transformer计算可表达性和可学习性之间的理论空白。研究者证明了带有线性注意力的简单单层Transformer可以通过有限的训练数据集学习，从而实现有效的泛化。并且可以学习的模型不仅限于那些可以轻松用线性模型表示的任务，也包括更多复杂的计算任务如有限自动机，从而展示了灵活和通用的计算模型在多项式时间内是高效的。"}
{"llm_update_time": "20251023", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2501.13133", "html_url": "https://arxiv.org/abs/2501.13133", "title": "使用扩散生成模型进行图表示学习", "title_en": "Graph Representation Learning with Diffusion Generative Models", "authors": "Daniel Wesego", "background": "扩散模型因其能够准确逼近复杂数据分布而成为图像和视频等各种数据模式下的前沿生成模型。扩散模型不同于传统的生成方法（如VAEs和GANs），它们使用逐步去噪过程，在多个迭代步骤中将噪声转化成有意义的数据，这一渐进的方法增强了它们的表达能力和生成质量。此外，扩散模型还能够从数据中抽取有意义的特征表示，同时学习生成样本。尽管扩散模型在这些方面表现优异，但将其应用于图结构数据仍然相对未被探索，主要原因是由于图的离散性质，需要与其它领域所使用的连续方法不同的离散扩散过程。", "innovation": "本文利用扩散模型的表征能力来学习图数据的有意义嵌入。通过在自编码器框架中训练一个离散扩散模型，使得模型能够有效地进行自编码和针对图数据特性的表示学习。我们从编码器的输出和解码器的第一个时间步隐藏嵌入的组合中提取表示。该方法展示了离散扩散模型在图表示学习中的潜力。", "conclusion": "通过训练离散扩散模型，本文方法能够有效实现图数据的自编码和表示学习。展示了扩散模型在图表示学习上的应用潜力。相关代码可以从提供的链接中找到。"}
{"llm_update_time": "20251023", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2502.02197", "html_url": "https://arxiv.org/abs/2502.02197", "title": "一种高效局部搜索方法在有符号网络中发现极化社区", "title_en": "An Efficient Local Search Approach for Polarized Community Discovery in Signed Networks", "authors": "Linus Aronsson,Morteza Haghir Chehreghani", "background": "有符号网络是一种社交系统中的自然框架，用于分析极化、信任和冲突。在这种网络中，边被标记为正或负，代表友好或敌对互动。识别有意义的群体结构对于理解在线讨论、政治分歧和信任动态至关重要。关键挑战是如何识别内部凝聚力强且对外敌对的社区，同时允许中立或未对齐的节点。当前方法的一个主要限制是倾向于产生规模严重不平衡的解决方案。已经证明，当不允许中立节点时，基于局部搜索的近似算法对于聚类有符号网络非常有效。在本文中，作者提出了一种方法，用于识别$k$个极化社区，解决了规模不平衡问题。并通过结合块坐标Frank-Wolfe优化，证明了这种方法具有线性收敛速度。实验结果表明，该方法在解决方案质量上优于最先进的基线方法，同时在计算效率上保持竞争力。", "innovation": "1. 引入了新的优化目标，避免了解决方案的不平衡性。2. 提出了第一个适用于有符号网络的局部搜索算法，允许中立节点，可扩展到大型网络。3. 通过结合块坐标Frank-Wolfe优化，证明了线性收敛率。", "conclusion": "该方法在真实数据集和合成数据集上的一致表现出色，揭示了一种有效识别有符号网络中极化社区的方法，具有线性收敛速度，并且在计算效率方面具有竞争力。"}
{"llm_update_time": "20251023", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2501.10088", "html_url": "https://arxiv.org/abs/2501.10088", "title": "一种在单调和循环加载下细砂本构建模的递归贝叶斯神经网络", "title_en": "A recursive Bayesian neural network for constitutive modeling of sands under monotonic and cyclic loading", "authors": "Toiba Noor,Soban Nasir Lone,G. V. Ramana,Rajdip Nayek", "background": "在土木工程中，本构模型对于捕捉不同排水条件、应力路径和加载历史下的土壤行为至关重要。尽管数据驱动的深度学习方法（例如，DL）作为传统本构表示的替代方案显示出潜力，但它们的部署需要模型不仅准确，而且能够量化预测不确定性。为了克服这一点，本文提出了一种递归贝叶斯神经网络（rBNN）框架，该框架将时间序列学习与广义贝叶斯推断统一起来，以实现预测准确性与严格的不确定性量化。该框架成功地捕捉了单调与循环加载下路径依赖的土壤响应。并通过人工模拟和实验数据验证了该方法的有效性，证明了该方法在不同数据精度和复杂性水平上的适应性。实验数据从单调加载到循环加载，再到从模拟数据到实验数据，展示了该方法的适应性。", "innovation": "递归贝叶斯神经网络框架结合了广义贝叶斯推断和时间序列学习，能够同时保证预测准确性并提供严谨的不确定性量化。该模型通过滑动窗口的递归结构，有效捕捉了单调与循环加载下的路径依赖土壤响应，利用理论上将网络参数作为随机变量，并通过广义变分推断估计它们的后验分布，从而为预测结果提供了校准的置信区间。这种方法与LSTM、编码器解码器和GRU架构相比，不仅在预测准确性上表现竞争力，还能提供可靠的信心区间。", "conclusion": "递归贝叶斯神经网络框架在单调和循环加载下对细砂进行了本构建模，通过四个数据集的实验和理论模拟验证了其有效性和适应性。该方法展示了在不同数据质量和复杂性上的优势，并且通过与其他机器学习模型的比较，证明了其在预测准确性与不确定性量化方面的优越性。"}
{"llm_update_time": "20251023", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2502.05625", "html_url": "https://arxiv.org/abs/2502.05625", "title": "无需训练的约束生成与稳定扩散模型", "title_en": "Training-Free Constrained Generation With Stable Diffusion Models", "authors": "Stefano Zampini,Jacob K. Christopher,Luca Oneto,Davide Anguita,Ferdinando Fioretto", "background": "稳定扩散模型在不同领域数据合成方面取得了最先进的成果，并在科学和工程应用中具有革命性的潜力，例如通过发现新颖解决方案和模拟计算上不可直接建模的系统。尽管越来越多的努力将基于物理的约束整合到生成模型中，但现有技术要么限制在潜扩散框架的应用上，要么缺乏严格强制特定领域约束的能力。", "innovation": "本文提出了一种将稳定扩散模型与受约束的最优化框架相结合的新方法，这使得生成满足严格物理和功能要求的输出成为可能。这种方法的有效性通过材料设计实验、要求精确形态学属性的复杂逆向设计任务以及版权约束的内容生成任务得到了验证。", "conclusion": "所提出的方法通过严格满足物理和功能要求，显著改进了生成模型的效果。相关代码已在该网址发布：[this https URL](this https URL)。"}
{"llm_update_time": "20251023", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2502.03762", "html_url": "https://arxiv.org/abs/2502.03762", "title": "从部分观察到的策略学习奖励机器", "title_en": "Learning Reward Machines from Partially Observed Policies", "authors": "Mohamad Louai Shehab,Antoine Aspeel,Necmiye Ozay", "background": "逆强化学习问题是通过从专家的最优策略或演示中推断出奖励函数来解决的问题。本文假设奖励可以表示为奖励机器，其转移依赖于与马尔可夫决策过程（MDP）状态相关的原子命题。文章的目标是使用有限信息识别真正的奖励机器。", "innovation": "文章引入了前缀树策略的概念，该策略将行为分布与MDP的每个状态和可实现的每个原子命题序列关联起来。进而定义了一种等价类的奖励机器，可以基于前缀树策略进行识别。提出了一种基于SAT（可满足性）的算法，该算法利用从前缀树策略中提取的信息来求解奖励机器。通过前缀树策略的适当深度，可以恢复等价类中的真实奖励机器。", "conclusion": "研究结果表明，如果前缀树策略达到足够的（但有限的）深度，基于SAT的方法可以恢复到等价类中的真实奖励机器。这些结果进一步推广到只能访问最优策略演示的情况。应用了多个示例，包括离散网格世界、块世界、连续状态空间的机器人手臂以及老鼠实验中的真实数据，以证明方法的有效性和普适性。"}
{"llm_update_time": "20251023", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2502.08206", "html_url": "https://arxiv.org/abs/2502.08206", "title": "优化异步联邦学习：模型参数陈旧性与更新频率之间的微妙权衡", "title_en": "Optimizing Asynchronous Federated Learning: A Delicate Trade-Off Between Model-Parameter Staleness and Update Frequency", "authors": "Abdelkrim Alahyane(LAAS-SARA, LAAS),Céline Comte(CNRS, LAAS-SARA, LAAS),Matthieu Jonckheere(CNRS, LAAS-SARA, LAAS),Éric Moulines(X)", "background": "同步联邦学习（FL）在客户端数量增加时表现不佳，受到从属效应的影响。算法如FedAsync和GeneralizedFedAsync通过使客户端与中央服务器之间的通信异步化来解决这一限制。本研究依赖于随机建模和分析，以更好地理解异步FL算法设计选择的影响，例如并发水平和路由概率，并利用这些知识优化损失。与大多数现有研究不同，本研究考虑了异构和可变服务速度以及客户端异构数据集的联合影响。", "innovation": "本研究的两大贡献是：首先，证明了一个离散的小男孩定律，以推导出相对延迟的闭式表达，这一量化陈旧性的重要指标使得可以通过Leconte等人的上界代理来有效地最小化每次模型更新的平均损失。其次，本文观察到，单纯优化这一指标会因过度强调陈旧性而严重降低系统速度。因此，提出了一个同时考虑速度的替代指标，并推导出可数化的上界，可以通过数值方式最小化。", "conclusion": "广泛的数值结果表明，这些优化可以提高10%到30%的准确性。"}
{"llm_update_time": "20251023", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2502.16763", "html_url": "https://arxiv.org/abs/2502.16763", "title": "使用神经网络精确执行加法、乘法和算法指令", "title_en": "Learning to Add, Multiply, and Execute Algorithmic Instructions Exactly with Neural Networks", "authors": "Artur Back de Luca,George Giapitzakis,Kimon Fountoulakis", "background": "神经网络因能够逼近光滑函数而闻名，但在训练中基于离散操作时，它们无法完美地将所学应用于未见输入。离散操作是二进制编码算法指令的核心，特别是在进行如算术测试时，神经网络经常被用作算法实现的测试。因此，研究神经网络能否精确学习执行二进制编码的算法指令变得尤为重要。", "innovation": "本文作者利用Neural Tangent Kernel (NTK)框架研究两层全连接网络在无限宽度极限下的训练动态，并展示了通过足够大的模型集合，在概率意义上，能精确执行四个基本任务：二进制排列、二进制加法、二进制乘法和Subtract and Branch if Negative (SBN)指令。由于SBN是图灵完全的，此框架也可扩展至可计算函数。该研究通过仅使用对数数量级的训练数据来高效实现精确学习。", "conclusion": "通过结构化训练数据来隔离位级规则，并在NTK范式下控制相关性以使模型预测与目标算法执行对齐，本文提出的方法有效地使神经网络能够精确执行二进制编码的算法指令。"}
{"llm_update_time": "20251023", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2502.18994", "html_url": "https://arxiv.org/abs/2502.18994", "title": "长期内因推断通过建模序列潜在混杂", "title_en": "Long-term Causal Inference via Modeling Sequential Latent Confounding", "authors": "Weilin Chen,Ruichu Cai,Yuguang Yan,Zhifeng Hao,José Miguel Hernández-Lobato", "background": "长期内因推断是各科学领域的重要但具有挑战性的问题。现有方法通过利用短期实验数据来解决长期观察研究中的潜在混杂问题，而Ghassami等人提出了基于条件加性等混杂偏倚（CAECB）假设的方法。这一假设认为短期结果和长期结果的混杂偏倚相等，从而识别长期的混杂偏倚和因果效应。尽管在某些情况下有效，但该假设仅适用于短期结果与长期结果相同尺度且只有单一短期结果的场景。", "innovation": "本论文提出了一种新的假设，扩展了CAECB假设，以处理时间序列的短期结果。这一假设在时间序列短期结果之间的顺序混杂偏倚之间建立了函数关系，并在此基础上理论上证明了长期因果效应的识别。根据识别结果，我们开发了一个估计器，并对其渐近性质进行了理论分析。广泛的实验验证了理论结果，并表明提出的方法的有效性。", "conclusion": "基于识别结果，我们提出的方法能够有效地解决时间序列短期结果中的潜在混杂问题，并通过理论分析和实验验证了其有效性和渐近性质。"}
{"llm_update_time": "20251023", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2503.01675", "html_url": "https://arxiv.org/abs/2503.01675", "title": "使用（不太）大的语言模型生成正式领域特定语言中的仿真模型：反应网络研究", "title_en": "Using (Not-so) Large Language Models to Generate Simulation Models in a Formal DSL: A Study on Reaction Networks", "authors": "Justin N. Kreikemeyer,Miłosz Jankowski,Pia Wilsdorf,Adelinde M. Uhrmacher", "background": "形式语言在建模和仿真中是不可或缺的一部分，能够将知识浓缩为易于自动执行、解释和分析的简洁模型。尽管自然语言是最直观的表达模型的方式，但计算机难以理解。本文探讨了如何利用大型语言模型（LLM）将自然语言转化为仿真模型，并通过合成数据生成器进行微调和评估，展示了其在合成数据生成器中的应用，评估结果表明微调后的Mistral模型可以在84.5%的情况下恢复真实仿真模型，小型用户研究也验证了其在各个领域的实用潜力。尽管有潜力，但在当前状态下，微调的小LLM仍无法与大LLM相比。", "innovation": "本研究使用了一个未经过大幅度微调的开源、7B参数的Mistral模型，并通过合成数据生成器微调了模型以将自然语言描述转化为反应网络模型中的形式特定语言。研究结果显示，这种开源、计算和内存效率高的方法在生成仿真模型方面具有潜力，为小型且开放源代码的LLM提供了新的机会，提高了系统生成的仿真模型的准确性，展示了在不同领域的实用价值。", "conclusion": "微调后的LLM在现有模型性能方面仍有待提升，未来需要高质量的训练数据来增强模型效果。与此同时，预计未来的小型开源LLM将带来新的机会和进步。为了实际应用，还需进一步改进训练数据和优化模型性能。"}
{"llm_update_time": "20251023", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2503.01872", "html_url": "https://arxiv.org/abs/2503.01872", "title": "FairGen: 通过适应性隐层引导控制扩散模型中敏感属性的公平生成", "title_en": "FairGen: Controlling Sensitive Attributes for Fair Generations in Diffusion Models via Adaptive Latent Guidance", "authors": "Mintong Kang,Vinayshekhar Bannihatti Kumar,Shamik Roy,Abhishek Kumar,Sopan Khosla,Balakrishnan Murali Narayanaswamy,Rashmi Gangadharaiah", "background": "文本到图像的扩散模型往往表现出对特定人口统计学群体的偏差倾向，例如在生成工程师图像时生成更多的男性而非女性，这引发了伦理关切并限制了其应用。因此，本研究旨在解决在扩散模型中减轻特定属性值（如“male”对应“gender”）生成偏向的同时，保持生成质量的挑战。", "innovation": "本文提出了FairGen，这是一种适应性隐层引导机制，可以在推理过程中控制生成分布。FairGen包含一个隐层引导模块，它动态调整扩散过程以强制执行特定属性，并且一个记忆模块追踪生成统计数据并引导隐层指导与目标公平分布对齐。此外，为进一步评估现有方法的不足之处，本文引入了一个全面的综合偏差评估基准（HBE），该基准涵盖了多个领域且包含复杂的提示，以更全面地评估偏差。", "conclusion": "广泛的评估表明，FairGen超越了现有的偏差缓解方法，在Stable Diffusion 2上的性别偏差降低方面取得了显著效果（例如降低了68.5%的性别偏差）。消融研究表明，FairGen能够在用户指定的任意粒度级别灵活控制输出分布，确保生成过程的适应性和高效性，实现了精准的偏差缓解。"}
{"llm_update_time": "20251023", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2503.07663", "html_url": "https://arxiv.org/abs/2503.07663", "title": "Merge then Realign: Simple and Effective Modality-Incremental Continual Learning for Multimodal LLMs", "title_en": "Merge then Realign: Simple and Effective Modality-Incremental Continual Learning for Multimodal LLMs", "authors": "Dingkun Zhang,Shuhan Qi,Xinyu Xiao,Kehai Chen,Xuan Wang", "background": "近年来，多模态大型语言模型（MLLMs）的发展增强了它们的多功能性，因为它们整合了越来越多的模态。考虑到训练MLLMs的成本高昂，通过模态增量连续学习（MCL）重新使用现有的模型并将其扩展到更多模态是有效的。尽管MCL的研究尚处于早期阶段，但这项工作探讨了导致MCL性能下降的原因，发现MCL不仅会遇到传统连续学习中的遗忘问题，还会遇到模态无感知和模态特定组件之间的不匹配问题。", "innovation": "本文提出了一个简洁有效的MCL范式，称为“合并然后对齐”（MERA）。MERA通过处理遗忘和不匹配问题，避免增加模型预算或修改模型架构，从而在MLLM社区中易于部署和高度重用。广泛实验证明了MERA的显著性能，当扩展到四个模态时，其平均后向相对增益为99.84%，达到几乎无损的MCL性能。本研究强调了MCL中的不匹配问题，并展示了在连续学习过程中如何调整MLLM的不同组件。", "conclusion": "本研究揭示了MCL中的不匹配问题，并展示了如何在连续学习过程中调整MLLM的不同组件。MERA作为一种简洁有效的MCL方法，证明了其对MLLM社区的高价值，为今后研究提供了新思路。"}
{"llm_update_time": "20251023", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2503.12730", "html_url": "https://arxiv.org/abs/2503.12730", "title": "TinySQL：逐步进阶的文本到SQL数据集，用于因果可解释性研究", "title_en": "TinySQL: A Progressive Text-to-SQL Dataset for Mechanistic Interpretability Research", "authors": "Abir Harrasse,Philip Quirke,Clement Neo,Dhruv Nathawani,Luke Marks,Amir Abdullah", "background": "当前，机制可解释性研究之间存在差距，即在玩具任务中分析简单电路与在大型模型中发现特征之间。为了缩小这一差距，论文提出了文本到SQL生成任务作为理想的测试，因为它结合了玩具任务的形式结构和现实世界的复杂性。", "innovation": "论文引入了一个名为TinySQL的合成数据集，由基本到高级的SQL操作逐步发展，以及训练不同参数范围（33M到1B）的模型，建立了全面的可解释性测试平台。通过多种互补的可解释性技术，如边缘归因补丁和稀疏自编码器，识别支持SQL生成的最小电路和组件。对不同SQL子技能的电路进行比较，评估其最小性、可靠性和可识别性。", "conclusion": "本文提供了一个稳健框架，用于逐步复杂环境中的探究和比较可解释性方法：从意图识别到模式解析再到结构化生成，揭示模型如何跨层组合SQL查询。"}
{"llm_update_time": "20251023", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2503.13414", "html_url": "https://arxiv.org/abs/2503.13414", "title": "在离散马尔可夫决策过程中的严格高效奖赏转移在强化学习中的证明", "title_en": "Provably Efficient Reward Transfer in Reinforcement Learning with Discrete Markov Decision Processes", "authors": "Kevin Vora,Yu Zhang", "background": "在强化学习中，代理需要适应新的目标奖赏函数，这一过程通常通过重新学习从先前学习的已知行为中获得的奖赏函数来实现。虽然这种方法理论上是可能的，但在已经存在源行为的情况下，这种方法可能效率低下。", "innovation": "本文提出了一种新的方法Q-Manipulation（Q-M），通过操纵Q函数来优化目标行为的学习过程。Q-M假设目标奖赏函数是源奖赏函数的已知函数，并通过迭代计算来收紧Q函数的界限，从而在学习开始之前对目标域中的动作进行修剪。此外，Q-M假设可以轻松提供或学习一个lite模型。", "conclusion": "本文形式上证明了在离散领域中，Q-M不会影响返回策略的最优性，并且证明了其在概率意义上的样本复杂性是有效的。Q-M在合成和模拟环境中被评估，展示了其有效性和实用性。"}
{"llm_update_time": "20251023", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2503.09483", "html_url": "https://arxiv.org/abs/2503.09483", "title": "学习基于卷积合成正则化的空间自适应 $\\ell_1$ 权重", "title_en": "Learning Spatially Adaptive $\\ell_1$-Norms Weights for Convolutional Synthesis Regularization", "authors": "Andreas Kofler,Luca Calatroni,Christoph Kolbitsch,Kostas Papafitsoros", "background": "在低场 MRI 图像重建中，传统的空间自适应和非自适应分析型方法依赖于 Total Variation 正则化。虽然模型驱动的深度学习方法表现良好，但它们缺乏可解释性。本文在卷积合成基于 $\\ell_1$ 正则化的框架下，提出了一种卷积滤波器的预训练和参数化方法，利用变形的 FISTA 算法对稀疏特征图中的时空变化参数进行估计，从而实现空间自适应参数图的学习。这种方法被用于评估低场 MRI 图像重建，并与现有的方法进行比较，以展示其视觉和定量上的可比性，同时保持高可解释性。", "innovation": "提出了一种新的卷积滤波器和参数化方法，利用变形的 FISTA 算法对低场 MRI 图像重建中稀疏特征图上的时空变化参数进行估计。该方法在保持良好重建结果的同时，还提供了对算法机制的有价值的见解，并且具有高可解释性。", "conclusion": "所提出的方法在低场 MRI 图像重建中产生了与现有方法相当的结果，并且其参数图可以量化每个滤波器在重建中的局部贡献，提供关于算法机制的见解，并有可能用于排除不适合的滤波器。"}
{"llm_update_time": "20251023", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2504.08437", "html_url": "https://arxiv.org/abs/2504.08437", "title": "自定义蜘蛛丝：机械属性调节的生成模型在蛋白质工程中的应用", "title_en": "Customizing Spider Silk: Generative Models with Mechanical Property Conditioning for Protein Engineering", "authors": "Neeru Dubey,Elin Karlsson,Miguel Angel Redondo,Johan Reimegård,Anna Rising,Hedvig Kjellström", "background": "蜘蛛丝的机械性能，包括其拉伸强度和延展性，主要由构成纤维的蛋白质重复区域决定。但是，建立机械特性和重复序列之间的联系具有挑战性，因为MaSps的序列-结构-功能关系复杂且高质量的注释数据集有限。", "innovation": "本研究提出了一种新的计算框架，用于设计具有可定制机械特性的MaSp重复序列。开发了一个基于GPT的轻量级生成模型，该模型通过从预训练的ProtGPT2蛋白语言模型中精简，并使用Spider Silkome数据集的精选部分进行多层次微调，特别针对MaSp重复序列生成进行了适应，并进一步用与实验证明的纤维级机械性能相关的572个重复序列进行细化。该模型可以生成针对特定机械性能定制的生物可行的MaSp重复区域，并预测给定序列的机械性能。", "conclusion": "该框架促进了基于蜘蛛丝的生物材料的理性设计，提供了工程具有定制机械特性的蛋白质序列的多功能工具。通过BLAST在Spider Silkome数据集和已知机械性能的MaSp重复序列测试集上的相关性研究进一步证实了模型的预测准确性。"}
{"llm_update_time": "20251023", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2504.07711", "html_url": "https://arxiv.org/abs/2504.07711", "title": "使用最优传输将嵌入主题合并进行数据流上的在线主题建模", "title_en": "Merging Embedded Topics with Optimal Transport for Online Topic Modeling on Data Streams", "authors": "Federica Granese,Benjamin Navet,Serena Villata,Charles Bouveyron", "background": "主题建模是无监督学习中的一个关键组成部分，用于识别文本语料库中的主题。随着社交媒体的迅速增长，每天生成的文本数据越来越多，因此在线主题模型方法对于处理不断连续到来的数据流至关重要。", "innovation": "本文介绍了一种新的在线主题建模方法，名为StreamETM。该方法基于嵌入主题模型(ETM)，通过使用不平衡最优传输来处理连续的部分文档批次模型。此外，采用了一种在线变化点检测算法，以识别随着时间变化的主题转移，从而实现文本流动态显著变化的识别。实验证明，StreamETM在模拟和真实数据上均优于竞争对手。", "conclusion": "数值实验表明StreamETM在模拟和实际数据上都优于竞争对手，并提供了代码供公众使用。"}
{"llm_update_time": "20251023", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2503.10632", "html_url": "https://arxiv.org/abs/2503.10632", "title": "Kolmogorov-Arnold Attention: Is Learnable Attention Better For Vision Transformers？", "title_en": "Kolmogorov-Arnold Attention: Is Learnable Attention Better For Vision Transformers?", "authors": "Subhajit Maity,Killian Hitsman,Xin Li,Aritra Dutta", "background": "Kolmogorov-Arnold networks (KANs) 是一种创新的结构，由可学习的激活函数组成，能够捕捉更复杂的数据关系。当前，KANs 主要被用于替代深度网络中的多层感知机（MLPs），包括先进的架构如视觉变换器（ViTs）。这项工作探讨了 KAN 是否能够学习 token 间的交互作用。通过设计基于 Fourier 基的 Kolmogorov-Arnold 注意机制（KArAt），研究指出，尽管学习注意力机制带来内存问题，但其低秩逼近版本可以有效改进性能，并在某些情况下超越传统的 softmax 注意机制。这项工作还包括将 KArAt 应用于 ConViT 和 Swin-Transformer，以及在 ViT-Det 中使用。通过分析损失景观、权重分布、优化路径和注意力可视化等，研究人员发现了 KArAt 的学习激活机制因其更好的注意力评分而提升表现，但仍需进一步在大规模模型上下文中测试其通用性。", "innovation": "提出了一种基于 Fourier 基的可学习注意力机制 (KArAt)，并设计了一种低秩逼近模块来解决内存膨胀问题。在一些场景中，KArAt 及其变种优于传统的 softmax 注意机制，或者与 CIFAR-10, CIFAR-100, 和 ImageNet-1K 等数据集表现持平。KArAt 还在 ConViT 和 Swin-Transformer 中表现良好，并应用于 ViT-Det 中的检测和分割任务。通过分析不同架构的表现，这项工作展示了 KArAt 在更复杂模型中的潜力，但也发现了其通用性受限于因素包括当前计算接口和参数、内存密集型机制的相对性能。", "conclusion": "尽管 KArAt 的学习激活机制在所有 ViTs 中表现更好，但其通用性在大规模模型中并未扩展。作者指出，设计 KArAt 的目的是为了显示学习注意力机制的可能性，并鼓励研究者探索 KArAt 在与更先进的架构结合时的效果。"}
{"llm_update_time": "20251023", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2505.00933", "html_url": "https://arxiv.org/abs/2505.00933", "title": "TunnElQNN: 一种用于高效学习的量子-经典混合神经网络", "title_en": "TunnElQNN: A Hybrid Quantum-classical Neural Network for Efficient Learning", "authors": "A. H. Abbas", "background": "混合量子-经典神经网络（HQCNNs）代表了机器学习领域的潜在前沿，它们结合了量子模型和经典模型的优势。已有研究表明，通过结合两者的特点可以提升模型性能和表达能力，尤其是在不饱和和多分类问题上。本研究在这一背景下提出了一种新的非顺序架构TunnElQNN，并对比了一个基于传统ReLU激活函数的基准模型ReLUQNN。测试数据集是具有不同遮盖程度的交错半圆数据集，用于多功能分类任务。", "innovation": "提出了一种新的非顺序架构TunnElQNN，其中在经典部分采用了由量子隧道效应启发的隧道二极管激活函数（TDAF）。TunnElQNN在具有不同类重叠程度的多功能分类任务上表现出色，并且其生成的决策边界表现优于仅包含TDAF的经典神经网络模型。这表明，将物理启发的激活函数与量子组件结合可以增强混合量子-经典机器学习模型的表达能力和鲁棒性。", "conclusion": "TunnElQNN模型在具有不同类重叠程度的多功能分类任务上表现出了持续优于ReLUQNN的性能。分析表明，TunnElQNN生成的决策边界在不同的类重叠水平下更具有优势。该研究不仅证明了在混合量子-经典架构中使用物理启发的激活函数的有效性，还突显了将其应用于改善模型的表达能力和鲁棒性的潜力。"}
{"llm_update_time": "20251023", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2505.11576", "html_url": "https://arxiv.org/abs/2505.11576", "title": "基于神经块的结构化可解释性", "title_en": "Concept-Guided Interpretability via Neural Chunking", "authors": "Shuchen Wu,Stephan Alaniz,Shyamgopal Karthik,Peter Dayan,Eric Schulz,Zeynep Akata", "background": "神经网络因其复杂的内部结构和难以理解的特性常被比喻为黑箱。这项研究提出了一个新视角，认为神经网络在底层表现出的模式与训练数据中的规律性相呼应。文章通过实验证明了此现象在简单循环神经网络和大型语言模型中的存在，并提出了利用认知中的“分块”策略来解读高维神经群体动态的方法。", "innovation": "论文提出了一种基于神经块的方法来实现可解释性，并借鉴认知科学中的“分块”原理，将高维神经群体动态分解为可解释的单元，这些方法包括离散序列分块（DSC）、群体平均（PA）和无监督分块发现（UCD），并在模型结构无关性方面提取了编码概念的实体。这些提取的块对网络行为具有因果影响。", "conclusion": "这项工作揭示了复杂学习系统的隐藏计算过程，通过结合认知原则和自然数据结构，将其从黑箱转化为可理解的系统。"}
{"llm_update_time": "20251023", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2505.01386", "html_url": "https://arxiv.org/abs/2505.01386", "title": "CATransformers: 通过联合模型-硬件优化实现碳意识Transformer", "title_en": "CATransformers: Carbon Aware Transformers Through Joint Model-Hardware Optimization", "authors": "Irene Wang,Newsha Ardalani,Mostafa Elhoushi,Daniel Jiang,Samuel Hsia,Ekin Sumbul,Divya Mahajan,Carole-Jean Wu,Bilge Acun", "background": "机器学习解决方案在各种关键应用场景中迅速普及，包括对话式AI助手和科学发现等。随着这些解决方案的采用增加，其生命周期中的碳足迹预计也会增加，这包括训练和推断过程中的运行碳足迹以及AI硬件制造过程中的嵌入碳足迹。目前缺乏一种将运行碳和嵌入碳纳入早期设计空间探索的联合优化框架，这导致了与延迟或能耗为中心的方法不同的基础权衡。为此，研究者们提出了一种新的框架——CATransformers，旨在通过联合优化Transformer模型及其硬件加速器，来实现可持续发展的模型架构和硬件设计，从而减少总的碳排放，并在保持准确性和延迟的情况下显著降低碳排放，且具有扩展性，通过多模态模型的案例研究进一步展现了其潜力。研究结果强调了全面优化方法的需求，这些方法在不牺牲模型能力和执行时间性能的情况下优先考虑碳效率。", "innovation": "CATransformers是首个集成了运行碳和嵌入碳的联合优化框架，解决了传统优化方法的局限性。该框架通过早期设计阶段的探索，实现可持续发展的模型架构和硬件设计，展现了与延迟和能耗优化不同的根本性贸易关系，降低了30%的总碳排放，且不影响模型的准确性和延迟，同时展示了其在多模态模型优化方面的扩展性。此外，CATransformers源代码公开提供，方便进一步研究和应用。", "conclusion": "CATransformers表明，采用综合优化方法并优先考虑碳效率，而不牺牲模型能力和执行时间性能，是实现AI技术可持续发展的有效途径。该框架为解决AI技术的碳足迹问题提供了新的思路，具有广泛的应用前景。"}
{"llm_update_time": "20251023", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2505.08727", "html_url": "https://arxiv.org/abs/2505.08727", "title": "记忆-压缩循环提高泛化", "title_en": "Memorization-Compression Cycles Improve Generalization", "authors": "Fangyuan Yu", "background": "当前普遍认为，模型泛化性能的提高仅通过增加数据量或优化模型架构。该研究通过理论证明，泛化还可以通过压缩内部表示实现。作者引入了信息瓶颈语言建模（IBLM）目标，该目标将语言建模问题重新构想为一个约束优化问题，即在保持预测准确性的情况下，最小化表示的熵。", "innovation": "提出了信息瓶颈语言建模（IBLM）目标，该目标将语言模型问题重新定义为一个优化问题，在保持预测性能的同时最小化表示的熵。提出了一种名为Gated Phase Transition（GAPT）的训练算法，该算法能够在记忆和压缩阶段之间自动切换，以改善模型的泛化能力。实验结果表明，GAPT在GPT-2预训练任务中，使得MDE减少了50%，交叉熵降低了4.8%，并在处理新型数据（OOD）泛化方面改进了35%。", "conclusion": "研究表明记忆-压缩循环可以在预训练过程中促进模型的泛化性能，并且GAPT算法能够改善模型在面临灾难性遗忘的情况下的泛化效果，该效果类似于睡眠巩固过程中觉醒学习和睡眠巩固之间的交替。"}
{"llm_update_time": "20251023", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2505.09160", "html_url": "https://arxiv.org/abs/2505.09160", "title": "利用对比和掩蔽自编码器学习的多任务无线信道表示基础模型", "title_en": "A Multi-Task Foundation Model for Wireless Channel Representation Using Contrastive and Masked Autoencoder Learning", "authors": "Berkay Guler,Giovanni Geraci,Hamid Jafarkhani", "background": "当前使用自监督学习对无线信道进行表示时，通常借鉴文本和图像处理领域的方法，但未能充分考虑无线通信的独特特性和限制。这些方法在处理无线环境特有的噪声、衰落和部分可观测性方面缺乏有效手段，因此需要一种能够更好地契合无线通信特点的模型。", "innovation": "提出了ContraWiMAE（无线对比掩蔽自编码器）这一变压器基础模型，通过结合掩蔽重构和掩蔽对比学习统一了无线信道的表示。其创新之处在于一种新型的无线启发式的对比目标，能够利用无线环境固有的噪声、衰落和部分可观测性作为自然增强方法，通过在未见过的场景和条件下进行广泛评估，展示了在多下游任务中的有效性，包括频率间波束选择、视距检测和信道估计等，突显了比有监督基线在挑战条件下更强的线性可分性和适应性以及更好的数据效率和竞争力。", "conclusion": "ContraWiMAE展示了在多变无线环境下优于现有无线信道基础模型的优越性能和数据效率，表明其在自监督无线信道表示学习方面的潜在优势，可作为未来研究的有力标准。为此，我们公开了ContraWiMAE的模型权重和训练管道，以促进进一步的研究工作。"}
{"llm_update_time": "20251023", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2505.16705", "html_url": "https://arxiv.org/abs/2505.16705", "title": "概念瓶颈模型的分析：测量、理解与减轻嘈杂标注的影响", "title_en": "An Analysis of Concept Bottleneck Models: Measuring, Understanding, and Mitigating the Impact of Noisy Annotations", "authors": "Seonghwan Park,Jueun Mun,Donghyun Oh,Namhoon Lee", "background": "概念瓶颈模型(CBMs)通过将预测分解为人类可解释的概念来确保可解释性。然而，用于训练CBMs的指导语句通常是嘈杂的，其影响尚未完全理解。", "innovation": "研究首次系统地分析了CBMs中的噪声问题，并展示了即使中度噪声也会同时损害预测性能、可解释性和干预效果。提出了一种两阶段框架：在训练阶段使用对噪声敏感的概念进行感知锐度最小化；在推理阶段使用预测熵对概念进行排序，并仅纠正最不确定的概念，用不确定性作为易感性的代理。", "conclusion": "理论分析和广泛的消融实验阐明了为什么锐度感知训练能提供鲁棒性，以及为什么不确定性可靠地识别了易感概念，从而提供了理论基础来同时保持可解释性和鲁棒性。"}
{"llm_update_time": "20251023", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2505.11883", "html_url": "https://arxiv.org/abs/2505.11883", "title": "MINGLE: Mixture of Null-Space Gated Low-Rank Experts for Test-Time Continual Model Merging", "title_en": "MINGLE: Mixture of Null-Space Gated Low-Rank Experts for Test-Time Continual Model Merging", "authors": "Zihuan Qiu,Yi Xu,Chiyuan He,Fanman Meng,Linfeng Xu,Qingbo Wu,Hongliang Li", "background": "现有的持续学习方法在独立微调模型时面临两个关键挑战：参数之间存在相互干扰，导致灾难性遗忘；以及对变化中的测试分布缺乏适应性。连续模型合并旨在无原训练数据的情况下，顺序合并独立微调模型，提供可扩展且高效的解决方案。然而，现有方法仍然存在上述挑战。因此，迫切需要新的方法来解决这些问题并提供更好的持续学习效果。", "innovation": "本文提出了Test-Time Continual Model Merging (TTCMM) 任务，通过在推断过程中利用少量未标记的测试样本来缓解参数冲突和处理分布偏移。为此，我们提出了MINGLE框架，这是一种新颖的方法，利用了参数高效、低秩的专家混合架构，并通过动态合并模型来缓解冲突。此外，我们还提出了Null-Space Constrained Gating和可调放松策略，以进一步减少遗忘并确保模型在不同任务之间的稳定性与适应性之间的平衡。这些方法在标准的持续模型合并基准上的实验中表现出优异的结果，显著减少了遗忘现象，并在多个不同任务顺序中平均超过先前的最佳方法7-9%。", "conclusion": "MINGLE框架在多个持续模型合并基准上的实验结果表明，该方法能够实现稳健的一般化，并显著减少遗忘。与先前最优方法相比，其在多个不同任务顺序中平均提高了7-9%的表现，成功解决了参数冲突和分布偏移问题。"}
{"llm_update_time": "20251023", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2505.17741", "html_url": "https://arxiv.org/abs/2505.17741", "title": "具有局部保持变换的离散神经流采样器", "title_en": "Discrete Neural Flow Samplers with Locally Equivariant Transformer", "authors": "Zijing Ou,Ruixiang Zhang,Yingzhen Li", "background": "离散分布的无偏采样是跨多个领域中的基本问题。尽管马尔可夫链蒙特卡洛方法提供了一个原理上的解决方案，但其常面临混合速度慢和收敛性差的问题。", "innovation": "本文提出了离散神经流采样器（DNFS），这是一种可训练且高效的离散采样框架。DNFS通过学习连续时间马尔可夫链的速率矩阵来确保其动力学满足柯尔莫哥洛夫方程。为减少无处不在的分区函数的蒙特卡洛估计的方差，文章采用了控制变量的方法，并引入了一种坐标下降学习算法。为了进一步提高计算效率，文章还提出了一种新型的速率矩阵参数化方法——局部保持变换，它在保持网络表示能力的同时显著提高了训练效率。", "conclusion": "实验证明，DNFS在多种应用中展示了其有效性，包括采样自无偏分布、训练离散能量模型以及解决组合优化问题。"}
{"llm_update_time": "20251023", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2505.13878", "html_url": "https://arxiv.org/abs/2505.13878", "title": "InfiFPO：大型语言模型中的偏好优化隐式模型融合", "title_en": "InfiFPO: Implicit Model Fusion via Preference Optimization in Large Language Models", "authors": "Yanggan Gu,Yuanyi Wang,Zhaoyi Yan,Yiming Zhang,Qi Zhou,Fei Wu,Hongxia Yang", "background": "现有模型融合工作主要集中在监督微调（SFT）上，而偏好对齐（PA）——对提高LLM性能至关重要的阶段——则被忽视了。现有的少数针对PA阶段的融合方法，如WRPO，简化了过程，只利用了源模型的响应输出而丢弃了概率信息，这限制了进一步提升LLM性能的可能性。", "innovation": "提出了一种偏好优化方法InfiFPO，用于隐式模型融合。InfiFPO将直接偏好优化（DPO）中的引用模型替换为融合的源模型，该融合模型在序列级别合成多重来源的概率信息，从而克服了先前工作中的词汇对齐复杂性挑战，同时保留了概率信息。通过引入概率剪裁和最大差距融合策略，InfiFPO使先前模型能够与人类偏好对齐，同时有效提取源模型的知识。", "conclusion": "全面实验表明，InfiFPO在11个广泛使用的基准测试中普遍优于现有模型融合和偏好优化方法。使用Phi-4作为旋转模型时，InfiFPO在11个基准上的平均性能从79.95提高到83.33，显著提高了其在数学、编码和推理任务上的能力。"}
{"llm_update_time": "20251023", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2505.15754", "html_url": "https://arxiv.org/abs/2505.15754", "title": "使用时间延展动作改进规划和模型基于强化学习", "title_en": "Improving planning and MBRL with temporally-extended actions", "authors": "Palash Chatterjee,Roni Khardon", "background": "连续时间系统通常通过离散时间动力学进行建模，这要求使用较小的仿真步长以保持准确性，从而导致需要较长的规划时间窗口，增加了计算需求并降低了性能。先前的无模型强化学习研究部分解决了这个问题，通过采用动作重复，即学习一个确定离散动作持续时间的策略。然而，这种方法并未直接解决连续决策时间尺度的问题。", "innovation": "本文提出了一种新的时间延展动作控制方法，直接控制连续决策时间尺度。通过将动作的持续时间为额外优化变量机制，不仅加速了轨迹的仿真时间，更重要的是，它允许在规划器的浅层搜索深度下进行深层的基本操作的搜索。此外，在模型基于强化学习（MBRL）框架下，该方法减少了模型学习引起的累积误差，并提高了模型的训练时间。主动臂赌博机形式下的范围自动选择表明了这一想法的有效性，其可以与MBRL框架整合。", "conclusion": "广泛实验证明，该方法在规划和MBRL中都能带来更快的规划速度、更好的解决方案，并且允许解决标准设定无法解决的问题。"}
{"llm_update_time": "20251023", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2505.18983", "html_url": "https://arxiv.org/abs/2505.18983", "title": "AmorLIP: 通过近似预训练实现高效语言-图像预训练", "title_en": "AmorLIP: Efficient Language-Image Pretraining via Amortization", "authors": "Haotian Sun,Yitong Li,Yuchen Zhuang,Niao He,Hanjun Dai,Bo Dai", "background": "CLIP 在多种文本-图像下游任务中展现出强大的零样本性能。现有的 CLIP 方法通常通过从每个批次中抽取负样本来优化对比学习目标，这要求非常大的批次大小和大量的计算资源，因此需使用大量甚至数千个 GPU。现有的缓解方法常常牺牲下游性能、增加训练时间和面临大数据集的扩展困难。", "innovation": "AmorLIP 提出了一个高效的 CLIP 预训练框架，通过轻量级神经网络近似复杂的对比学习中的昂贵计算，从而大幅提高训练效率和性能。同时，引入了基于能量模型频谱分解的新近似目标以及训练稳定性的改进技术。", "conclusion": "AmorLIP 在38个下游任务上展示了优越的零样本分类和检索能力，性能显著优于标准的 CLIP 基准，相对改进幅度最高达12.24%。"}
{"llm_update_time": "20251023", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2505.15788", "html_url": "https://arxiv.org/abs/2505.15788", "title": "通过光滑非凸不公性能度量近似值的严格约束实现监督学习公平性", "title_en": "Fair Supervised Learning Through Constraints on Smooth Nonconvex Unfairness-Measure Surrogates", "authors": "Zahra Khatti,Daniel P. Robinson,Frank E. Curtis", "background": "论文提出了一种新的策略，用于公平的监督机器学习。与文献中的其他策略相比，该策略的主要优势在于引入了一种新的光滑非凸替代函数来逼近不连续不公度量中涉及的阶跃函数。这种替代函数基于优化文献中的平滑方法，这是在公平的监督学习文献中新的方法。这个替代函数是一种紧缩近似，可以确保训练预测模型的公平性，而这对于其他替代函数（例如凸函数）来说在实践中可能会失败。此外，该策略通过使用严格的约束条件来替代正则化器，从而避免了难以解决的优化问题和昂贵的超参数调整成本。因此，这种方法能够同时处理多个可能冲突的不公度量约束，并且可以通过严格的约束而非正则化方法实现更具成效的学习过程。", "innovation": "1. 提出了一种新的光滑非凸替代函数来逼近不连续不公度量中的阶跃函数，该方法在公平的监督学习文献中是新颖的，并且给出了一种紧缩近似，确保训练的预测模型是公平的，避免了其他替代函数可能出现的不公平预测模型问题。2. 通过使用严格的约束条件而非正则化器，使得可以强制执行特定的不公容忍度，而无需承担与正则化相关的复杂问题和超参数调整成本。3. 该策略允许同时处理多种（可能冲突的）不公度量的约束条件，而不需要进一步复杂化优化问题和增加超参数调整的成本。相反，通过严格的约束，该方法可以实现可解性优化模型，同时减少调整成本。", "conclusion": "通过这种方法，研究者提出了一种新的监督学习公平性策略，该策略能够更有效地处理文献中提到的问题，同时避免了需要解决复杂优化问题和超参数调整的不方便之处。这种策略能够实现更实际、高效和可靠的公平监督机器学习。"}
{"llm_update_time": "20251023", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2505.20755", "html_url": "https://arxiv.org/abs/2505.20755", "title": "Uni-Instruct: 一种通过统一扩散偏差指令的一步扩散模型", "title_en": "Uni-Instruct: One-step Diffusion Model through Unified Diffusion Divergence Instruction", "authors": "Yifei Wang,Weimin Bai,Colin Zhang,Debing Zhang,Weijian Luo,He Sun", "background": "本文合并了超过10种现有的一步扩散蒸馏方法，如Diff-Instruct、DMD、SIM、SiD、$f$-distill等，将其纳入一个由我们提出的$f$-散度族的扩散扩展理论驱动的框架中，称之为Uni-Instruct。Uni-Instruct旨在克服原始扩展$f$-散度的不可处理性问题，通过最小化扩展的$f$-散度族构造了等效且可处理的损失函数，从而有效地训练一步扩散模型。", "innovation": "提出了Uni-Instruct，通过统一扩散偏差指令对多种现有一步扩散蒸馏方法进行整合，不仅提供了新的理论贡献，有助于从高层次理解现有方法，还显著提升了一步扩散生成性能。在CIFAR10生成基准测试中，Uni-Instruct实现了无条件生成的创纪录Frechet Inception Distance (FID)值1.46和有条件生成的FID值1.38。在ImageNet-$64 \times 64$生成基准测试中，Uni-Instruct达到一项新的最优一步生成FID值1.02，远优于其79步教师扩散模型，性能提升了1.33。", "conclusion": "Uni-Instruct在一步扩散蒸馏和扩散模型的知识转移方面的坚固理论和经验贡献可能会在未来的研究中有所帮助，主要用于文本到3D生成，Uni-Instruct在生成质量和多样性方面略优于先前的方法，如SDS和VSD。"}
{"llm_update_time": "20251023", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.06045", "html_url": "https://arxiv.org/abs/2506.06045", "title": "基于扩散的分层图神经网络在模拟非线性固体力学中的应用", "title_en": "Diffusion-Based Hierarchical Graph Neural Networks for Simulating Nonlinear Solid Mechanics", "authors": "Tobias Würth,Niklas Freymuth,Gerhard Neumann,Luise Kärger", "background": "基于图的机器学习模拟器已经展现出在不规则网格上模拟物理系统的优势，提高了速度并能够适应各种几何形状。然而，这些方法在捕捉全局现象，例如弯曲或固体力学中常见的长程相关性方面的能力有限。此外，这些模型在长时间序列上进行推断时会积累误差，这主要是由于它们依赖于局部信息传递和直接下一时刻的预测。", "innovation": "提出了Rolling Diffusion-Batched Inference Network (ROBIN)，这是一种新颖的基于图的机器学习模拟器，结合了两项创新：(i) Rolling Diffusion-Batched Inference (ROBI)，这是一种并行化推理方案，通过在时间窗口内跨步骤重叠去噪步骤来降低扩散基础细化过程的成本。(ii) 建立在代数多重网格细化上的分级图神经网络，能够进行跨不同网格分辨率的多尺度消息传递。该架构通过代数-分级消息传递网络实现，可捕捉对梁弯曲或多体接触至关重要的细尺度局部动态和全局结构效应。", "conclusion": "ROBIN 在涉及几何、材料和接触非线性的复杂 2D 和 3D 固体力学基准测试中表现出卓越的精度，显著优于现有的基于下一时刻学习的模拟器，同时将推理时间相比标准扩散模拟器减少了近一个数量级。"}
{"llm_update_time": "20251023", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2505.19955", "html_url": "https://arxiv.org/abs/2505.19955", "title": "MLR-Bench：评估开放型机器学习研究中的AI代理", "title_en": "MLR-Bench: Evaluating AI Agents on Open-Ended Machine Learning Research", "authors": "Hui Chen,Miao Xiong,Yujie Lu,Wei Han,Ailin Deng,Yufei He,Jiaying Wu,Yibo Li,Yue Liu,Bryan Hooi", "background": "近年来，人工智能（AI）代理在科学研究中的潜力不断增长，并展示了其在推动和辅助科学发现方面的强大能力。为应对这类挑战，提出了MLR-Bench这一全面基准，专注于评估AI代理在开放型机器学习研究中的表现。MLR-Bench包括201个任务，这些任务广泛覆盖来自NeurIPS、ICLR和ICML研讨会的多个机器学习主题，以及一种结合LLM（大型语言模型）审查员和精心设计的审查标准的自动化评估框架（MLR-Judge），和一个模块化的研究代理框架（MLR-Agent），该框架可以完成从创意生成到论文写作的四个阶段的研究任务。", "innovation": "MLR-Bench创新地结合了三个关键组件：一是全面涵盖多个机器学习主题的201个开源研究任务；二是集成了大型语言模型审查员和详细审查标准的自动化评估框架（MLR-Judge）；三是能够通过四个阶段生成和撰写研究报告的模块化研究代理框架（MLR-Agent）。该框架支持在不同研究阶段逐步进行评估，并对最终研究报告进行全面评估。研究人员使用MLR-Bench评估了六种前沿大型语言模型和一个先进的编码代理，发现虽然大型语言模型能够有效生成连贯的创意和结构化的论文，但当前的编码代理常在实验结果方面产生虚假或无效的结果，这对科学研究的可靠性构成重大障碍。同时，通过人类评估验证了MLR-Judge的有效性，展示了其作为可扩展的研究评估工具的潜力。", "conclusion": "研究人员通过MLR-Bench证明了大型语言模型在生成创意和结构化论文方面的有效性，同时也揭示了当前编码代理在实验结果方面的问题，并通过MLR-Judge验证证明了其评估框架的有效性。该研究旨在帮助社区通过MLR-Bench进行基准测试、诊断和改进AI研究代理，以实现可信赖且透明的科学研究发现。"}
{"llm_update_time": "20251023", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.10946", "html_url": "https://arxiv.org/abs/2506.10946", "title": "GUARD: 数据归因指导下的大型语言模型的有选择遗忘与保留", "title_en": "GUARD: Guided Unlearning and Retention via Data Attribution for Large Language Models", "authors": "Peizhi Niu,Evelyn Ma,Huiting Zhou,Duo Zhou,Huan Zhang,S. Rasoul Etesami,Olgica Milenkovic", "background": "大型语言模型（LLM）的有选择遗忘（unlearning）变得越来越重要，以应对监管合规、版权保护和隐私问题。然而，数据去除特定信息后意外破坏模型的有效性的问题（即无意中的遗忘）是现有LLM有选择遗忘的一大挑战。先前的研究主要集中在架构创新上，但在数据层面因素对有选择遗忘性能的影响方面研究不足。因此，现有方法在遗忘高影响数据时，往往会遭受保留信息质量减弱的问题。", "innovation": "我们提出了一种名为GUARD（Guided Unlearning And Retention via Data attribution）的新型框架，通过引入一种轻量级的数据归因度量，设计了一个新颖的有选择遗忘目标，该目标针对LLM有选择遗忘并产生了计算效率更高的分配策略，从而避免无意中的保留损失。同时，GUARD还提供了严格的理论保证，即在牺牲保留能力方面比现有方法有显著改进的同时，保持遗忘度量与先前方法相似。", "conclusion": "实验结果表明，GUARD在TOFU基准测试中的保留集上的真相比（truth ratio）损失减少了高达194.92%，当遗忘训练数据的10%时；在MUSE基准测试的保留集上的知识保留提高了16.20%，并且与最先进的方法相比，隐私损失的变化是适度的或适中的。"}
{"llm_update_time": "20251023", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2505.24379", "html_url": "https://arxiv.org/abs/2505.24379", "title": "遗忘但未被遗忘：LLM中精确卸载后的数据提取", "title_en": "Unlearned but Not Forgotten: Data Extraction after Exact Unlearning in LLM", "authors": "Xiaoyu Wu,Yifei Pang,Terrance Liu,Zhiwei Steven Wu", "background": "大型语言模型通常在包含网络收集的文档的数据集中进行训练，可能无意中包含有害或敏感个人隐私信息。为了应对不断增长的隐私担忧，提出了卸载方法来移除特定数据对训练模型的影响。在这类方法中，重新训练——即从零开始重新训练模式而不包含目标数据——被认为是减轻部署中隐私风险的最佳方法。然而，该研究在实际部署场景中重新审视了这一点，其中预卸载和卸载后的API信号都暴露出来了，如在开放权重的情况下。在这种情景下，提出了一种新颖的数据提取攻击，利用预卸载模型的信号指导后卸载模型，揭示了反映出删除数据分布的模式。通过结合模型指导与标记过滤策略，该攻击在MUSE、TOFU和WMDP等常见基准测试中显著提高了提取成功率，在某些情况下将性能翻倍。此外，该研究还展示了数据提取攻击在模拟的医疗诊断数据集中的有效性，突显了精确卸载可能带来的实际隐私泄露风险。研究表明，卸载在现实部署中可能以矛盾的方式增加隐私泄露风险，因此建议评估卸载方法考虑到更广泛的威胁模型，不仅要考虑卸载后的模型，还要考虑对手对先前检查点的访问。研究人员提供了相关代码供公众使用。", "innovation": "研究提出了一种新颖的数据提取攻击，该攻击在后卸载模型中利用预卸载模型的信号，提升了数据提取的成功率，特别是在常见的基准测试中表现显著提升。此外，该研究利用模拟的医疗诊断数据集进一步展示了精确卸载可能带来的隐私风险。", "conclusion": "该研究指出，尽管精确卸载被认为可以有效缓解隐私风险，但在实际部署环境中，这种方法可能反而增加了隐私泄露的风险。因此，需要评估卸载方法时考虑更广泛的威胁模型，不仅包括卸载后的模型，还包括潜在的预卸载信息对手的访问。"}
{"llm_update_time": "20251023", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.04168", "html_url": "https://arxiv.org/abs/2506.04168", "title": "Horizon Reduction Makes RL Scalable", "title_en": "Horizon Reduction Makes RL Scalable", "authors": "Seohong Park,Kevin Frans,Deepinder Mann,Benjamin Eysenbach,Aviral Kumar,Sergey Levine", "background": "本文研究了离线强化学习（RL）算法的可扩展性。理想的离线RL算法应该能够解决任何问题，无论复杂度如何，只要给定足够多的数据、计算能力和模型容量。研究团队使用比常规离线RL数据集大1000倍的数据集，在多种具有挑战性的未解决任务上检验当前离线RL算法是否能达到这一目标。但研究发现，尽管增加数据量，许多现有的离线RL算法的扩展行为较差，表现出性能饱和现象，远低于最大性能。研究认为，导致离线RL扩展不良的主要原因是时间跨度（horizon）较大，通过几项分析实验验证了这一假设，长时间跨度是扩展离线RL的基本障碍。因此，通过对时间跨度的减少来提高可扩展性，已经证明是有效的。", "innovation": "研究团队通过实验证明，降低时间跨度可以显著提高离线RL算法的可扩展性，这一发现对于提高离线RL算法的性能和扩展性具有重要意义。基于这些见解，提出了一个名为SHARSA的简单且可扩展的方法，以有效降低时间跨度。SHARSA在评估方法中表现出最佳的渐进性能和扩展行为，明确地降低时间跨度解锁了离线RL的可扩展性。此外，研究团队还提供了代码实现，使得研究结果可以被其他研究者复现。", "conclusion": "研究表明，时间跨度的长度是限制离线RL扩展的关键因素，而通过降低时间跨度可以显著提升其可扩展性。SHARSA算法在这种背景下提出，它在多个评估方法中表现出最佳的性能和扩展行为，验证了降低时间跨度对提高离线RL算法的性能和扩展性有显著作用。"}
{"llm_update_time": "20251023", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.00711", "html_url": "https://arxiv.org/abs/2506.00711", "title": "QoQ-Med：使用领域意识型GRPO训练构建多模态临床基础模型", "title_en": "QoQ-Med: Building Multimodal Clinical Foundation Models with Domain-Aware GRPO Training", "authors": "Wei Dai,Peilin Chen,Chanakya Ekbote,Paul Pu Liang", "background": "在临床决策中，常规需要处理异质性数据，但现有的多模态语言模型主要集中在视觉信息上，难以在不同临床专业之间泛化。本文介绍了QoQ-Med-7B/32B，这是一种能够联合推理医学图像、时间序列信号和文本报告的首个开源通用临床基础模型。模型通过领域意识相对策略优化（DRPO）训练，缓解了由临床数据分布偏差引起的表现不平衡问题。模型训练数据涵盖9个临床领域，共计261万对指令调整对，突出了DRPO训练方法相比其他无批评家训练方法的优越性，提升了宏F1值43%。此外，经过强化分割数据训练的QoQ-Med能够显著提高诊断性能，其IoU值较开源模型高10倍，同时达到OpenAI o4-mini的性能水平。为了促进可重复研究和下游研究，作者开源了模型权重、模块化训练管道和所有中间推理记录。", "innovation": "本文创新地引入了QoQ-Med-7B/32B模型，这是一种能够在医学图像、时间序列信号和文本报告上共同推理的多模态临床语言模型。该模型使用了领域意识相对策略优化（DRPO）训练方法，优化了不同数据域和模态之间的表现不平衡。此外，QoQ-Med模型在增强分割数据上的训练表现也非常出色，显著提高了诊断性能，同时在开源模型中达到了更高的精度水平。", "conclusion": "本文介绍的QoQ-Med模型在多模态临床语境下表现出色，尤其是在领域意识相对策略优化（DRPO）的训练方法下，模型能更有效处理复杂的数据特征。通过模型训练和性能评估，证明了QoQ-Med在视觉领域中的诊断性能有了显著提升，并且通过开源模型结构和训练流程，促进了该领域的进一步研究和发展。"}
{"llm_update_time": "20251023", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.11791", "html_url": "https://arxiv.org/abs/2506.11791", "title": "SEC-bench: 自动化评估大型语言模型代理在真实软件安全任务中的表现", "title_en": "SEC-bench: Automated Benchmarking of LLM Agents on Real-World Software Security Tasks", "authors": "Hwiwon Lee,Ziqi Zhang,Hanxiao Lu,Lingming Zhang", "background": "对大型语言模型（LLM）代理进行严格的安全评估对于确保其在整个软件开发生命周期中的安全部署至关重要。然而，现有的基准测试主要依赖于合成挑战或简化漏洞数据集，这些并未准确反映安全工程师在实践中遇到的复杂性和模糊性。", "innovation": "我们引入了SEC-bench，这是第一个用于评估LLM代理在真实安全工程任务上的全自动基准测试框架。SEC-bench利用了新颖的多代理支架，它可以自动构建带有挂钩的代码仓库，孤立环境中复制漏洞，并生成金标准修补程序以提供可靠的评估。我们的框架能够在每次实例上仅花费0.87美元，自动生成高质量的软件漏洞数据集并保持可重复性产物。利用SEC-bench，我们实现两个关键的软件安全任务，以严格评估LLM代理的能力：概念验证构建和漏洞修补。我们的综合评估表明，当前最先进的LLM代码代理在概念验证生成和漏洞修补方面存在显著的性能差距，成功率最多为18.0%和34.0%，在完整数据集上。", "conclusion": "这些结果强调了开发更实用、更智能、更自主的LLM代理对于安全工程中的关键步骤。"}
{"llm_update_time": "20251023", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.14806", "html_url": "https://arxiv.org/abs/2506.14806", "title": "连续时间中的重球动量方法及其离散化误差分析", "title_en": "Heavy-Ball Momentum Method in Continuous Time and Discretization Error Analysis", "authors": "Bochen Lyu,Xiaojing Zhang,Fangyi Zheng,He Wang,Zheng Wang,Zhanxing Zhu", "background": "探究连续时间下的微分方程已经被证明是研究离散优化方法的有效途径。尽管动量在基于梯度的优化方法中扮演着关键角色，但离散动力学与连续时间近似之间的差距仍未被全面解决，特别是在动量方法中的离散化误差问题。因此，本文旨在深入研究重球动量方法在连续时间中的表现，同时特别关注离散化误差，以提供新的理论工具来解决这一问题。", "innovation": "本文设计了一种一阶分区连续微分方程，明确地引入了多个抵消项来应对离散化误差，从而提供了一个能够控制任意步长阶次离散化误差的重球动量方法的连续时间模型。利用该模型，可以发现方向光滑性的新隐式正则化，并研究重球方法在对角线线性网络中的隐式偏见，展示了理论发现的实际应用价值。", "conclusion": "本文通过构建重球动量方法的连续时间模型，提供了一种处理任意步长阶次离散化误差的理论工具，并将其应用于探讨方向光滑性的隐式正则化以及重球方法在对角线线性网络中的隐式偏见，同时也通过数值实验进一步验证了其理论成果的有效性。"}
{"llm_update_time": "20251023", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.16313", "html_url": "https://arxiv.org/abs/2506.16313", "title": "通过增强的Epistemic神经网络提高GFlownets中的探索", "title_en": "Improved Exploration in GFlownets via Enhanced Epistemic Neural Networks", "authors": "Sajan Muhammad,Salem Lahlou", "background": "在GFlowNets中，高效地识别用于训练的正确轨迹仍然是一个待解决的问题。解决这个问题的关键在于在奖励分布尚未充分学习的区域优先进行探索，即通过不确定性驱动的探索来提高探索效率，使得代理了解自己未知的部分。", "innovation": "本文提出将Epistemic神经网络（ENN）与GFlowNets的常规结构相结合，实现更高效的联合预测和更好的不确定性量化，从而改善探索和最优轨迹识别。提出的算法名为ENN-GFN-Enhanced，并在不同环境中与基准方法进行比较和评估，证明了其在效率和效果上的优越性。", "conclusion": "研究证明，通过集成Epistemic神经网络（ENN），可以在GFlowNets中有效地提高探索效率和准确性，从而识别出更好的轨迹。具体地，ENN-GFN-Enhanced算法在网格环境和结构化序列生成任务中表现出了优越性，展现了其实际应用潜力。"}
{"llm_update_time": "20251023", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2505.18495", "html_url": "https://arxiv.org/abs/2505.18495", "title": "通过部分掩码超越掩码和不掩码：基于部分掩码的离散扩散模型", "title_en": "Beyond Masked and Unmasked: Discrete Diffusion Models via Partial Masking", "authors": "Chen-Hao Chao,Wei-Fang Sun,Hanwen Liang,Chun-Yi Lee,Rahul G. Krishnan", "background": "Masked diffusion models (MDM)是一种生成离散数据的强大模型，通过逐步揭露序列中的标记生成样本。每个标记可以处于两个状态之一：掩码或未掩码。研究表明，标记序列在连续采样步骤之间往往保持不变，导致模型重复处理相同的输入，产生冗余计算。为解决这一效率问题，本研究提出了一种部分掩码方案（Prime），该方案通过允许标记处于掩码和未掩码状态之间的混合状态，扩展了MDM。这一设计使模型能够在部分观察到标记信息的基础上做出预测，并促进细致的去噪过程。研究者推导了变分训练目标，并介绍了适合混合状态输入的简单架构设计。该方法在多种生成建模任务中表现出优越的性能。在文本数据上，它在OpenWebText数据集上的困惑度为15.36，优于之前的MDM（21.52）、自回归模型（17.54）及其混合变体（17.58），不依赖于自回归建模。在图像数据上，它在CIFAR-10和ImageNet-32上的FID分数分别为3.26和6.98，与最新的连续生成模型相媲美。", "innovation": "提出了部分掩码方案（Prime），通过允许标记处于掩码和未掩码状态之间的混合状态，扩展了MDM，提高了模型的预测精度和去噪能力。引入了适合混合状态输入的简单架构设计，并推导了变分训练目标，优化了模型性能。该方法在多种生成建模任务中表现出色，在OpenWebText、CIFAR-10和ImageNet-32上的性能优于现有模型。", "conclusion": "该研究提出了基于部分掩码的离散扩散模型（Prime），通过减少冗余计算和允许部分观察，显著提高了生成建模任务中的性能。该方法在OpenWebText和图像数据集上的表现优于之前的方法，展示了该技术在多种数据类型上的普适性和有效性。"}
{"llm_update_time": "20251023", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.21374", "html_url": "https://arxiv.org/abs/2506.21374", "title": "关注小权重", "title_en": "Pay Attention to Small Weights", "authors": "Chao Zhou,Tom Jacobs,Advait Gadhikar,Rebekka Burkholz", "background": "微调大规模预训练神经网络既耗资源也耗内存，这需要大量的计算成本。为减轻此问题，一个常用的方法是对模型参数的子集进行训练。通过分析微调过程中梯度和权重的关系，观察到一个明显的模式：大梯度通常与小权重相关联。这种关联在微调设置中比从头开始训练更为显著。", "innovation": "基于此观察，我们提出了NANOADAM，这个方法仅在微调过程中动态更新小权重，并提供几个实用的优势：首先，这种方法是梯度自由的 —— 参数子集可以在不需要梯度计算的情况下确定；其次，它保留了大权重，这些权重很可能包含了预训练期间学习到的关键特征，从而减少了灾难性遗忘的风险；最后，它允许使用更大的学习率，并且在实验中始终会提升通用化表现。我们对此方法在自然语言处理和视觉任务中的效果进行了验证。", "conclusion": "通过这种方法，我们显示它在自然语言处理和视觉任务中都表现良好，动态更新小权重在微调过程中提供了一种有效且高效的策略。"}
{"llm_update_time": "20251023", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.13579", "html_url": "https://arxiv.org/abs/2506.13579", "title": "离散扩散模型的灵活长度文本填充", "title_en": "Flexible-length Text Infilling for Discrete Diffusion Models", "authors": "Andrew Zhang,Anushka Sivakumar,Chiawei Tang,Chris Thomas", "background": "离散扩散模型是一种新型的文字生成器，相较于自动回归模型，它们拥有双向上下文使用、并行生成和灵活提示等优势。然而，它们的一个重要局限性在于无法在无需地面真实位置数据的情况下进行长度可变或位置可变的文本填充。", "innovation": "引入了DDOT（离散扩散与最优运输位置耦合），这是第一个能够克服上述挑战的离散扩散模型。DDOT通过一个新颖的样本层面最优运输（OT）耦合，共同去噪词值和词位置，使得相对词序得以保留，同时动态调节填充片段的位置和长度，这是文本扩散中先前所缺失的能力。", "conclusion": "在One-Billion-Word和Yelp等文本填充基准测试中，DDOT不仅超过了简单的扩散基线，还能达到当前最先进的非自动回归模型的性能，并显著提高了训练效率和灵活性。"}
{"llm_update_time": "20251023", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.16404", "html_url": "https://arxiv.org/abs/2506.16404", "title": "使用双注意力机制和非对称编码生成有向图", "title_en": "Generating Directed Graphs with Dual Attention and Asymmetric Encoding", "authors": "Alba Carballo-Castro,Manuel Madeira,Yiming Qin,Dorina Thanou,Pascal Frossard", "background": "有向图自然用于建模生物学、交通、社交网络和视觉理解等领域中具有不对称、有序关系的系统。生成此类图可以完成仿真、数据增强和新型实例发现等任务；然而，有向图生成仍未得到充分探索。有两个因素限制了该领域的进展：一是建模边的方向性引入了一个大幅增加的依赖空间，使得潜在分布更难学习；二是缺少标准化基线数据集妨碍了严格的评估。为了应对这些问题，需要更具表达能力的模型，能够敏感地捕捉方向性拓扑。本研究提出了Directo，首个基于离散流匹配框架的生成模型，该方法结合了：（i）针对非对称二元关系的原理性位置编码，（ii）双重注意力机制，能够同时捕捉入度和出度依赖关系，以及（iii）一个稳健且离散的生成框架。", "innovation": "Directo是首个基于离散流匹配框架的生成有向图的模型。创新点包括：1）采用针对非对称关系的原理性位置编码；2）采用双重注意力机制捕捉入度和出度依赖；3）提供了一个强大的离散生成框架。该方法针对合成和真实数据集建立了基准测试集，结果显示其在各种场景下表现良好，并且在特定类别（如有向无环图）上与专门模型竞争。", "conclusion": "该研究展示了方法的有效性和通用性，为未来有向图生成的研究奠定了坚实的基础。"}
{"llm_update_time": "20251023", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.22304", "html_url": "https://arxiv.org/abs/2506.22304", "title": "使用科分算子展开生成流：快速和可解释的采样", "title_en": "Unfolding Generative Flows with Koopman Operators: Fast and Interpretable Sampling", "authors": "Erkan Turan,Aristotelis Siozopoulos,Louis Martinez,Julien Gaubil,Emery Pierson,Maks Ovsjanikov", "background": "连续正则化流(CNFs)能够提供优雅的生成建模，但其采样速度较慢，生成单个样本需要求解非线性常微分方程，涉及数百次函数评估。近期方法如Rectified Flow和OT-CFM通过直线化轨迹加速了采样过程，但依然无法使学习的动力学线性化，限制了效率和可解释性。", "innovation": "本文提出了一种全新的视角，利用科分理论全局线性化流动力学。通过将条件流动匹配(CFM)提升到更高维度的科分空间，表示其演化过程为单一的线性算子。这种做法带来了两个关键优势：首先，采样过程变得单步且并行化，在封闭形式下通过矩阵指数计算。其次，科分算子提供了一种生成的光谱蓝图，通过其特征值和模式使生成过程具有新型的可解释性。此外，我们推导出一种实际的、无需仿真训练目标，确保无穷小的一致性，并展示了该共识保持了从教师动力学到生成路径的保真度，与边界唯一蒸馏区分开来。实验结果显示，本文方法在保持竞争力的同时，实现了显著的速度提升，还能够进行生成流的光谱分析.", "conclusion": "实验结果显示，本文方法在保持竞争力的同时，实现了显著的速度提升，还能够进行生成流的光谱分析。"}
{"llm_update_time": "20251023", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.01271", "html_url": "https://arxiv.org/abs/2507.01271", "title": "PULSE: 实践中的大型多模态模型遗忘评估场景", "title_en": "PULSE: Practical Evaluation Scenarios for Large Multimodal Model Unlearning", "authors": "Tatsuki Kawakami,Kazuki Egashira,Atsuyuki Miyai,Go Irie,Kiyoharu Aizawa", "background": "近年来，遗忘技术（用于让模型“忘记”之前学习的信息的方法）引起了人们对大型语言模型（LLMs）和大型多模态模型（LMMs）中的隐私和版权问题的兴趣。尽管已经建立了一些针对LLMs的遗忘基准，但对于LMMs的遗忘实践评估框架探索较少。现有的LMM遗忘基准通常只考虑模型通过单一遗忘操作卸载细调知识的场景，而没有考虑到不同知识获取阶段以及顺序请求下的情况。", "innovation": "本文引入了PULSE协议，用于评估LMMs在实际遗忘场景中的表现。该协议引入了两个关键视角：(i) 预训练知识遗忘，分析在不同知识获取阶段的效果；(ii) 长期可持续性评估，应对顺序请求。通过这些维度评估现有遗忘方法。结果发现，虽然一些技术能够成功卸载通过微调获得的知识，但在卸载预训练过程中获取的信息方面表现不佳。同时，能够在单一操作中有效卸载目标数据集的方法，在顺序卸载时会表现出显著性能下降。", "conclusion": "研究结果表明，现有的遗忘技术和方法在处理预训练知识和顺序数据请求方面存在局限性。因此，需要进一步开发既能卸载预训练知识，又能在顺序请求中保持稳定性能的遗忘方法。"}
{"llm_update_time": "20251023", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.02496", "html_url": "https://arxiv.org/abs/2507.02496", "title": "在线确保预测效率的公形预测", "title_en": "Online Conformal Prediction with Efficiency Guarantees", "authors": "Vaidehi Srinivas", "background": "该研究探讨了一种新颖的在线框架下的公形预测问题，直接优化效率。给定目标误覆盖率α > 0和时间跨度T。每天t ≤ T，算法必须输出区间I_t ⊆ [0,1]，然后点y_t ∈ [0,1]被揭示。算法的目标是在接近(1 - α)的天数内实现覆盖，同时还需最小化所输出区间（长度）的平均体积。", "innovation": "1. 对可交换序列，展示了可以构建区间以实现(1 - α) - o(1)的覆盖，其长度上限受回溯中最好固定区间影响。\n2. 对任意序列，展示了任何被认为是在平均长度上μ-近似相比回溯中最好固定区间的算法必须要比αT犯更多的错误，错误的数量与μ和问题的方面比有关。\n3. 主要算法结果是一个可恢复所有帕特奥-最优设置μ和错误数量的匹配算法，且算法确定性，对适应性强。", "conclusion": "我们的结果表明，可交换与任意序列之间的差距不同于经典的在线学习问题。事实上，我们展示了没有单个算法能在任意序列和可交换序列中同时为帕特奥最优。在算法方面，我们提供了一个算法以实现这两个情况下的近最优权衡。"}
{"llm_update_time": "20251023", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.05101", "html_url": "https://arxiv.org/abs/2507.05101", "title": "PRING: 从对 pair 到 graph 重新思考蛋白质-蛋白质相互作用预测", "title_en": "PRING: Rethinking Protein-Protein Interaction Prediction from Pairs to Graphs", "authors": "Xinzhe Zheng,Hao Du,Fanding Xu,Jinzhe Li,Zhiyuan Liu,Wenkang Wang,Tao Chen,Wanli Ouyang,Stan Z. Li,Yan Lu,Nanqing Dong,Yang Zhang", "background": "现有的基于深度学习的计算方法在预测蛋白质-蛋白质相互作用（PPIs）方面取得了显著成果。然而，现有的基准测试主要集中在孤立的成对评估上，忽视了模型重建具有生物学意义的PPI网络的能力，这对于生物学研究至关重要。", "innovation": "该研究引入了PRING，这是第一个从图层面评估蛋白质-蛋白质相互作用预测基准。PRING构建了一个高质量的多物种PPI网络数据集，包括21,484个蛋白质和186,818个相互作用，并通过精心设计的策略解决了数据冗余和泄漏问题。此外，PRING建立了两个互补的评估范式：图拓扑任务和功能任务，使得模型不仅可以评估网络拓扑，还可以支持蛋白质功能注释、生物模块检测甚至疾病机制分析。", "conclusion": "广泛的实验表明，当前的PPI模型在恢复PPI网络的结构和功能属性方面存在局限性，揭示了对实际生物学应用的支持不足。我们认为PRING为社区提供了可靠平台，以指导更有效的PPI预测模型的发展。PRING的数据库和源代码可从指定链接获取。"}
{"llm_update_time": "20251023", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.16814", "html_url": "https://arxiv.org/abs/2507.16814", "title": "视知觉缓慢思考推理的半离策增强学习", "title_en": "Semi-off-Policy Reinforcement Learning for Vision-Language Slow-Thinking Reasoning", "authors": "Junhao Shen,Haiteng Zhao,Yuzhe Gu,Songyang Gao,Kuikun Liu,Haian Huang,Jianfei Gao,Dahua Lin,Wenwei Zhang,Kai Chen", "background": "大规模视觉-语言模型（LVLMs）在解决复杂多模态任务时的关键在于增强其视觉缓慢思考推理能力。然而，由于LVLMs主要通过视觉-语言对齐进行训练，直接采用基于策略的强化学习（RL）来开发缓慢思考能力非常困难，因为其初始能力限制了轨迹空间。尽管离策RL可以超越当前策略，但直接从外部模型提取轨迹会导致视觉幻觉，是因为这些模型之间的视觉感知能力不匹配。", "innovation": "本文提出了SOPHIA，一种结合可训练的LVLM的基于策略视觉理解与语言模型的离策缓慢思考推理的半离策RL方法。SOPHIA通过将基于结果的奖励赋予推理，并反向传播视觉奖励，构建了一种半离策行为模型。LVLM利用离策RL算法中的传播奖励来学习缓慢思考推理能力。", "conclusion": "通过多个多模态推理基准测试，证明了SOPHIA的有效性。SOPHIA不仅大幅提升了InternVL3.0-38B的表现，使其成为开源LVLM中的最优，甚至在MathVision和OlympiadBench等具有挑战性的任务上也超越了一些封闭源模型（如GPT-4.1），分别取得了49.08%和49.95%的通过率。分析表明，SOPHIA在策略初始化方面优于监督微调和直接基于策略的RL方法。"}
{"llm_update_time": "20251023", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.02844", "html_url": "https://arxiv.org/abs/2509.02844", "title": "时间序列预测中的变化点校准预测", "title_en": "Conformal Prediction for Time-series Forecasting with Change Points", "authors": "Sophia Sun,Rose Yu", "background": "已有关于时间序列的校准预测方法虽然提供了一种通用且高效的不确定性量化手段，但目前的方法难以处理带有变化点（数据生成过程中的突然变化）的时间序列数据。", "innovation": "本文提出了一种新的时间序列变化点校准预测(CPTC)算法，该算法通过结合预测潜在状态的模型和在线校准预测来建模非平稳时间序列中的不确定性。此外，论文证明了CPTC在非平稳时间序列情况下的有效性和适应性，并通过6组合成和真实数据集展示了其优越性。", "conclusion": "研究证明CPTC算法在时间和假设最少的情况下保持有效性，并且在与最新基准方法的比较中显示出更好的有效性与适应性。"}
{"llm_update_time": "20251023", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.01254", "html_url": "https://arxiv.org/abs/2509.01254", "title": "消息表达理论所忽略的内容：用于GNN的消息传递复杂性", "title_en": "What Expressivity Theory Misses: Message Passing Complexity for GNNs", "authors": "Niklas Kemper,Tom Wollschläger,Stephan Günnemann", "background": "消息表达理论已经成为了分析GNN的主要框架，但由于这些理论无法准确反映GNN的实际能力，新模型试图通过提高表达能力来争取更高的性能。然而，本文认为，这种过度强调表达能力的要求是不合理的，因为大部分实际应用场景并不需要超过基本WL测试的表达能力。此外，消息表达理论的存在性判定和理想化的假设使得这一理论难以反映GNN的实际能力。", "innovation": "提出了消息传递复杂性（MPC），这是一种连续度量，量化了GNN架构解决给定任务时通过消息传递的难度。MPC不仅能捕捉到过度压缩等实际限制，还能保持从消息表达理论得出的不可判定结果，从而弥合理论与实践之间的差距。", "conclusion": "通过广泛的实验验证，MPC的理论预测与实际表现密切相关，成功解释了架构上的成功和失败。因此，MPC超越了消息表达理论，提供了一个更为强大和细致的框架来理解和改进GNN架构。"}
{"llm_update_time": "20251023", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.18167", "html_url": "https://arxiv.org/abs/2506.18167", "title": "通过引导向量理解思考语言模型的推理", "title_en": "Understanding Reasoning in Thinking Language Models via Steering Vectors", "authors": "Constantin Venhoff,Iván Arcuschin,Philip Torr,Arthur Conmy,Neel Nanda", "background": "近期大型语言模型的进展导致生成了具有广泛内部推理链的思考语言模型，在生成回应之前。虽然这些模型表现出改进的性能，但控制其推理过程仍具有挑战性。", "innovation": "本研究提出了一种通过分析和操纵DeepSeek-R1-Distill模型中特定推理行为来进行推理控制的方法。通过系统地在10个不同类别的500个任务中进行实验，识别出了思考模型展现的几种推理行为，如表达不确定性、为假设验证生成示例以及推理链中的回溯。研究表明，这些行为由模型激活空间中的线性方向介导，并可以通过引导向量进行控制。通过提取并应用这些向量，可以调节模型推理过程的特定方面，例如回溯或表达不确定性的倾向。", "conclusion": "该方法为以可控和可解释的方式引导思考模型的推理过程提供了实用工具。使用三个DeepSeek-R1-Distill模型验证了引导方法的有效性，展示了不同的模型架构之间的一致控制效果。"}
{"llm_update_time": "20251023", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.01687", "html_url": "https://arxiv.org/abs/2508.01687", "title": "使用PHAR解释时间序列分类器：从后验归因中提取和融合规则", "title_en": "Explaining Time Series Classifiers with PHAR: Rule Extraction and Fusion from Post-hoc Attributions", "authors": "Maciej Mozolewski,Szymon Bobek,Grzegorz J. Nalepa", "background": "解释机器学习模型在时间序列分类中的鲁棒性仍然是一个挑战，因为直接解释原始时间序列和输入空间的高维度非常困难。PHAR框架通过将后验、实例级别的特征归因转换为结构化的、易于理解的规则，来解决这一问题。这些规则定义了包含决策相关段落的人类可读间隔，并通过精细化原始系列上来界定的阈值条件，来增强模型的透明度。", "innovation": "PHAR框架提供了一种统一的方法，通过后验规则表征将数值特征归因转换为结构化的、易于理解的规则。它在长时间序列和广覆盖实例方面更有效地扩展了内置的基于规则的方法，如 Anchor。通过特定的规则融合步骤，使用加权选择和lasso基线调整策略，来平衡覆盖率、置信度和简洁性等关键质量指标。此外，还引入了可视化工具以展示规则的具体性和泛化性的权衡。PHAR能够将不一致和重叠的解释总结为连贯的、基于特定领域的见解。", "conclusion": "在UCR/UEA时间序列分类存档中的全面实验表明，PHAR能够通过提供易于理解且与模型预测一致的简洁规则来提高解释的准确性和一致性，从而改善时间序列分类任务中决策和解释的透明度和实际应用性。"}
{"llm_update_time": "20251023", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.25473", "html_url": "https://arxiv.org/abs/2509.25473", "title": "信号时间逻辑推理中的校准预测", "title_en": "Conformal Prediction for Signal Temporal Logic Inference", "authors": "Danyang Li,Yixuan Wang,Matthew Cleaveland,Mingyu Cai,Roberto Tron", "background": "现有的信号时间逻辑（STL）推理方法缺乏对推断规则形式化的置信度保证。虽然校准预测（CP）能够提供统计正确性保证，但通常作为训练后的包装器应用，未能提升模型学习效果。本文旨在通过引入端到端可微分的CP框架来增强STL推理的可靠性和可解释性。该框架采用基于稳健性的异常分值、直接嵌入平滑的CP层以及联合优化推断准确性和CP预测集的新损失函数，从而同时提高预测准确性和置信度保证。", "innovation": "引入一种基于稳健性的非正则性分数，并直接将光滑的CP层嵌入到训练中，同时优化推断准确性和CP预测集，并采用新的损失函数，实现了端到端的可微分框架。该方法在一系列基准时间序列任务中显示出降低预测不确定性（即，提高覆盖率并减少预测集大小）和提高准确性的优势，优于最先进的基线方法。", "conclusion": "通过直接将校准预测集成到STL推理的训练过程中，本文提出的方法能够同时提高推理的准确性和可靠性，并提供形式化的统计置信度保证。实验结果表明，在多个基准时间序列任务中，该方法能够显著减少预测的不确定性并提高准确性。"}
{"llm_update_time": "20251023", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.26433", "html_url": "https://arxiv.org/abs/2509.26433", "title": "ACT：赋权分类树", "title_en": "ACT: Agentic Classification Tree", "authors": "Vincent Grari,Tim Arni,Thibault Laugel,Sylvain Lamprier,James Zou,Marcin Detyniecki", "background": "在高风险应用场景中，AI系统需要生成透明、可解释和可追溯的决策，这一要求由监管法规逐渐提出。决策树如CART可以提供明确且可验证的规则，但只适用于结构化表格数据，无法直接处理如文本这样的非结构化输入。尽管在实际应用中，大型语言模型（LLMs）被广泛用于处理非结构化数据，但现有的提示策略如链式思维或提示优化仍然依赖于自由形式的推理，这限制了这些策略确保可靠行为的能力。", "innovation": "我们提出了赋权分类树（Agentic Classification Tree，ACT），这是一种将决策树方法扩展到非结构化输入的技术。ACT将每个分割表达为自然语言问题，并通过基于杂质评估和大型语言模型反馈（通过TextGrad）进行改进。实验表明，ACT在文本基准测试中能够匹配或超越基于提示的基准模型，同时产生透明和可解释的决策路径。", "conclusion": "ACT通过将决策树方法应用于非结构化输入，提供了一种新的透明和可解释的决策路径生成方法。"}
{"llm_update_time": "20251023", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.16949", "html_url": "https://arxiv.org/abs/2508.16949", "title": "打破探索瓶颈：面向通用LLM推理的Rubric-Scaffolded强化学习", "title_en": "Breaking the Exploration Bottleneck: Rubric-Scaffolded Reinforcement Learning for General LLM Reasoning", "authors": "Yang Zhou,Sunzhu Li,Shunyu Liu,Wenkai Fang,Kongcheng Zhang,Jiale Zhao,Jingwen Yang,Yihe Zhou,Jianwei Lv,Tongya Zheng,Hengtong Lu,Wei Chen,Yan Xie,Mingli Song", "background": "近年来，大型语言模型(Large Language Models, LLMs)的进步凸显了强化学习(Reinforcement Learning, RL)在促进推理能力发展方面的潜在价值。尽管结果令人鼓舞，但在提高RL效果时仍面临一个根本性难题，即RL的进步依赖于高质量样本的学习，但探索这些高质量样本的能力受到LLM固有限制的限制。这种限制导致了一个负面循环：无法探索的领域无法学习。", "innovation": "本文提出了一种新型的鲁棒指导框架(Rubric-Scaffolded Reinforcement Learning, RuscaRL)，解决了LLM推理中的探索瓶颈。RuscaRL通过检查表风格的评判标准来引导探索与学习过程：在生成展开时作为明确的探索指导，提供不同的检查表作为任务说明中的外部指导，引导生成多样的高质量响应，并逐渐减少该指导，促使模型内化背后的推理模式；在模型训练期间作为可验证的奖励，利用检查表作为参考获得稳健的LLM-as-a-Judge评分，从而有效促进通用推理任务的强化学习效果。", "conclusion": "大量的实验证明了提出的RuscaRL在各种基准测试中具有优越性，有效扩大了推理边界，在最佳的N次评估下表现最好。RuscaRL极大地提高了Qwen2.5-7B-Instruct在HealthBench-500上的表现，从23.6提高到50.3，超过了GPT-4.1。我们对Qwen3-30B-A3B-Instruct的微调版本在HealthBench-500上实现了61.1的得分，超过了包括OpenAI-o3在内的领先LLM。代码已公开。"}
{"llm_update_time": "20251023", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.20214", "html_url": "https://arxiv.org/abs/2509.20214", "title": "Q-Palette: 向最优比特分配高效部署大语言模型的分数比特量化器", "title_en": "Q-Palette: Fractional-Bit Quantizers Toward Optimal Bit Allocation for Efficient LLM Deployment", "authors": "Deokjae Lee,Hyun Oh Song", "background": "我们研究了对大型语言模型（LLM）的权重进行后训练量化（PTQ），在不需要重新训练的情况下量化权重，并且使用少量或无校准数据。在内存受限和小批归一化推理场景（如边缘设备上的个性化推理）中，这对于减少LLM推理的记忆占用和延迟至关重要。但LLM中具有重尾异常值的权重分布使得量化变得复杂，最近一些旋转方法通过将权重转换为近似高斯分布来解决这个问题，这样可以减少异常值并降低量化误差。尽管重要，但仍需要理论见解与实际实现相结合来指导量化过程。因此，提出了一种基于Q-Palette的混合量化方案，并在定量预算内优化量化器选择和层融合策略，以满足资源限制条件。", "innovation": "我们首次推导出在给定位预算下高斯权重的最优位分配，表明接近高斯失真-速率限制的细粒度分数位量化器对于实现最优量化性能至关重要。为了使这一理论见解能够应用于实际部署，引入了一个通用的量化器集合Q-Palette，提供了从高斯最优化的陶磁量化器到简单向量和标量化器的丰富选择，这些量化器均经过优化以适应各种位宽。此外，基于Q-Palette的基础组件，提出了新的混合量化框架，在资源约束下联合优化量化器选择和层融合策略。", "conclusion": "我们开发了Q-Palette，这是一个通用的分数位量化器集合，并开发了一个新的混合量化框架，这两种工具可以在资源约束条件下优化量化器选择和层融合，从而实现大语言模型的高效部署。相关代码可以在<该URL>获取。"}
{"llm_update_time": "20251023", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.05874", "html_url": "https://arxiv.org/abs/2510.05874", "title": "MaNGO - 通过元学习实现可适应的图网络模拟器", "title_en": "MaNGO - Adaptable Graph Network Simulators via Meta-Learning", "authors": "Philipp Dahlinger,Tai Hoang,Denis Blessing,Niklas Freymuth,Gerhard Neumann", "background": "准确地模拟物理现象在科学研究的各个领域都非常重要，应用范围从机器人学到材料科学等。传统的网格基模拟方法虽然精度高，但计算成本高且需要了解物理参数，如材料属性。相比之下，基于数据的方法，如图网络模拟器（GNSs），能够提供更快的推断，但存在两个关键局限性：首先，它们需要从头开始重新训练以适应微小的物理参数变化；其次，它们还需要为每个新的参数设置进行劳动密集型的数据收集。这很不高效，因为具有不同参数的模拟通常共享共同的潜在结构。本文通过元学习学习这种共享结构，使模拟器能够快速适应新的物理参数而无需重新训练来解决问题。", "innovation": "本文提出了一个新颖的架构MaNGO，通过元学习生成潜在表示来实现基于图的轨迹编码，还结合神经算子架构以减少时间累积的误差。该方法在多种具有不同材料属性的动力学预测任务中得到了验证，其性能显著优于现有的GNS方法。MaNGO在未见过的材料属性上的准确性接近于理想模型的准确性。", "conclusion": "本文通过元学习和神经算子架构解决了传统GNS的两个主要局限性，能实现更高效的物理模拟，为新材料属性的快速适应提供了可能。"}
{"llm_update_time": "20251023", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.08450", "html_url": "https://arxiv.org/abs/2510.08450", "title": "gLSTM: 通过增加存储容量缓解过压缩", "title_en": "gLSTM: Mitigating Over-Squashing by Increasing Storage Capacity", "authors": "Hugh Blayney,Álvaro Arroyo,Xiaowen Dong,Michael M. Bronstein", "background": "图神经网络（GNNs）利用图结构在节点之间传递信息，通常通过消息传递机制实现。尽管这些模型在广泛的应用中显示出潜力，但它们面临过压缩的问题。过压缩现象会导致节点表示的广域接收场中的信息被压缩到一个固定的大小向量中，从而形成信息瓶颈。本文重新审视了过压缩现象，从模型存储和检索能力的角度分析，定义为存储在节点表示中的可用于Later用途的信息量。研究了现有衡量过压缩的一些任务的局限性，并引入了一个新的合成任务来展示信息瓶颈可以饱和存储能力。", "innovation": "本文将序列建模文献中的关联记忆、快速权重编程者和xLSTM模型的思想适应到GNN中，开发了一种新的具有更好存储能力的GNN架构。该架构在作者的容量合成任务和一系列真实世界的图基准测试中都表现出强大的性能。", "conclusion": "通过开发的新GNN架构，作者证明了可以通过增加存储容量来缓解过压缩问题，从而提高模型的表现力和泛化能力。"}
{"llm_update_time": "20251023", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.09048", "html_url": "https://arxiv.org/abs/2510.09048", "title": "使用实际多模态数据集成的时空图卷积网络用于电动汽车充电需求预测", "title_en": "Spatio-Temporal Graph Convolutional Networks for EV Charging Demand Forecasting Using Real-World Multi-Modal Data Integration", "authors": "Jose Tupayachi,Mustafa C. Camur,Kevin Heaslip,Xueping Li", "background": "交通运输仍然是温室气体排放的主要来源，强调了向可持续替代方案过渡的紧迫性，如电动汽车（EVs）。然而，充电基础设施在空间分布上的不均匀分布和不规则使用给电网稳定性和投资规划带来了挑战。因此，有必要进行充电需求预测以优化充电基础设施和电网管理，特别是在电力需求波动较大的地区，如美国田纳西州的不同区域。", "innovation": "提出了TW-GCN框架，结合了图卷积网络和时间架构，以预测美国田纳西州的电动汽车充电需求。该框架利用实际交通流量、天气条件以及某家美国最大的电动汽车基础设施公司的专有数据，捕捉空间依赖性和时间动态性。实验表明，中时域（3小时）预测在响应性和稳定性之间取得了最佳平衡，并且1DCNN模型在所有实验中表现出色。此外，区域分析揭示了东、中、西田纳西州在预测准确性上的差异，反映了站点密度、人口和地方需求变化对模型性能的影响。", "conclusion": "TW-GCN框架推进了电动汽车基础设施规划的数据驱动智能整合，支持可持续交通系统的过渡和具有弹性的电网管理。不同区域的预测准确性表明，站点密度、人口和地方需求变化对模型性能有重要影响。"}
{"llm_update_time": "20251023", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.06293", "html_url": "https://arxiv.org/abs/2510.06293", "title": "BlockGPT：通过帧级自回归建模降雨的空间-时间模式", "title_en": "BlockGPT: Spatio-Temporal Modelling of Rainfall via Frame-Level Autoregression", "authors": "Cristian Meo,Varun Sarathchandran,Avijit Majhi,Shao Hung,Carlo Saccardi,Ruben Imhoff,Roberto Deidda,Remko Uijlenhoet,Justin Dauwels", "background": "预测降水量地图是一个高度复杂的时空建模任务，对于缓解极端天气事件的影响至关重要。短时降水预报，即现在气象预报，需要既准确又在实时应用中高效计算的模型。现有的方法，如基于令牌的自回归模型，常常因为有缺陷的归纳偏见和慢的推理而导致问题，而扩散模型则相对计算密集。为了应对这些局限性，我们引入了BlockGPT，这是一种使用批量令牌化（Block方法）的生成型自回归变压器，能够在每个时间步骤预测整个二维领域（帧）。", "innovation": "BlockGPT的因素空间-时间方法使用了每帧内的自我关注和跨帧的因果关注，构想为一种针对视频预测的模型无关范式。我们通过两种降水数据集KNMI（荷兰）和SEVIR（美国），将BlockGPT实例化于现在气象预报中，并将其与最先进的基准模型（包括基于令牌的NowcastingGPT和基于扩散模型的DiffCast+Phydnet）进行比较。结果表明，BlockGPT在分类指标上的事件定位、准确性和比同类基准快31倍的推理速度方面取得了显著优势。", "conclusion": "BlockGPT在降水量预测中展示了优越的性能和效率，尤其是在准确性、事件定位和推理速度方面超越了最先进的基准模型，为现在气象预报提供了新的解决方案。"}
{"llm_update_time": "20251023", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.09240", "html_url": "https://arxiv.org/abs/2510.09240", "title": "时间意识公平性在数据共享中的激励机制", "title_en": "Incentivizing Time-Aware Fairness in Data Sharing", "authors": "Jiangwei Chen,Kieu Thao Nguyen Pham,Rachael Hwee Ling Sim,Arun Verma,Zhaoxuan Wu,Chuan-Sheng Foo,Bryan Kian Hsiang Low", "background": "在协同数据共享和机器学习中，多个实体聚集它们的数据资源以训练具有更好性能的机器学习模型。然而，由于数据收集成本会导致各实体仅在被保证了公平性和个体理性等激励条件下才愿意共享数据。现有框架假定了所有实体会同时加入合作，但在现实场景中这并不总成立。实体由于数据清理时间长、难以克服的法律障碍或不了解情况等原因未能同时加入合作。因此，较早加入的实体承担了更高的风险，并鼓励后续实体加入贡献数据，应因其更早参与而获得更高的奖励。", "innovation": "本文提出了一个公平且考虑时间的data sharing框架，涵盖了新的时间相关激励机制。作者开发了新的方法来决定奖励值以满足这些激励，并进一步描述了如何生成符合奖励值的模型奖励，并对合成和真实世界的数据集进行了实证研究，展示了方法的特性。", "conclusion": "本文提供了一种公平且考虑时间的data sharing框架，通过考虑实体加入合作的时间先后给予相应奖励，以鼓励更多的数据共享和促进更好的模型训练结果。"}
{"llm_update_time": "20251023", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.09660", "html_url": "https://arxiv.org/abs/2510.09660", "title": "学习重要性：通过谱各向异性前向噪声引导扩散", "title_en": "Learning What Matters: Steering Diffusion via Spectrally Anisotropic Forward Noise", "authors": "Luca Scimeca,Thomas Jiralerspong,Berton Earnshaw,Jason Hartford,Yoshua Bengio", "background": "扩散概率模型（DPMs）在生成性能方面表现出色，但它们的归纳偏见仍然大部分是隐含的。本文旨在在训练和采样扩散模型时构建归纳偏见，以更好地适应数据的目标分布。", "innovation": "提出了一种各向异性噪声操作符，通过替换等向性的前向协方差为结构化的、频谱对角线的协方差来塑造这些偏见。该操作符统一了带通掩码和幂律权重，允许我们强调或抑制指定的频率带，同时保持前向过程的高斯性。这被称为谱各向异性的高斯扩散 (SAGD)。证明了带通的谱各向异性导出了对应不同的谱各向异性的分数关系，并在全支持下，学习到的分数趋近于真实数据分数，同时各向异性重塑了从噪声到数据的概率流路径。", "conclusion": "实验结果表明，诱导的各向异性在多个视觉数据集上优于标准扩散，并使模型可以选择性地学习，忽略特定频率带内的已知损坏。这些结果证明，精心设计的各向异性前向噪声提供了一个简单而又原理明确的方式来调整 DPMs 中的归纳偏见。"}
{"llm_update_time": "20251023", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.10777", "html_url": "https://arxiv.org/abs/2510.10777", "title": "预条件范数：统一框架下的最速下降、拟牛顿和自适应方法", "title_en": "Preconditioned Norms: A Unified Framework for Steepest Descent, Quasi-Newton and Adaptive Methods", "authors": "Andrey Veprikov,Arman Bolatov,Samuel Horváth,Aleksandr Beznosikov,Martin Takáč,Slavomir Hanzely", "background": "最优化理论是现代深度学习的核心，现有优化方法存在一个基本的权衡：几何适应性和利用曲率信息。最速下降算法可以通过选择范数来适应不同的几何结构，但始终保持一阶；拟牛顿方法和自适应优化器结合了曲率信息，但也局限于Frobenius几何，限制了它们在不同架构中的适用性。本文通过对预条件矩阵范数的新颖理解，提出了一种统一框架，旨在解决上述问题。", "innovation": "本文提出了一种新的统一优化框架，通过预条件矩阵范数的概念，将最速下降、拟牛顿方法和自适应方法统一起来。此框架揭示了许多广泛使用的优化器（如SGD、Adam以及更先进的方法Muon、KL-Shampoo、SOAP和SPlus）都是这一原则的特例。此外，引入了两种新的方法MuAdam和MuAdam-SANIA，结合了Muon的谱几何和Adam的预条件特征。实验结果显示这些优化器在性能上与现有最先进的方法相匹敌，甚至在某些情况下更胜一筹。", "conclusion": "该框架为理解优化器的几何不变性和在矩阵参数化设置下的尺度不变性提供了新的基础。通过这种方法，MuAdam和MuAdam-SANIA表现出很强的竞争力，在某些情况下超越了现有的顶级方法。"}
{"llm_update_time": "20251023", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.12140", "html_url": "https://arxiv.org/abs/2510.12140", "title": "采用自适应频谱专家和跨集分布校准的图少样本学习", "title_en": "Graph Few-Shot Learning via Adaptive Spectrum Experts and Cross-Set Distribution Calibration", "authors": "Yonghao Liu,Yajun Wang,Chunli Guo,Wei Pang,Ximing Li,Fausto Giunchiglia,Xiaoyue Feng,Renchu Guan", "background": "Graph few-shot learning因其能够仅通过有限标记节点快速适应新任务而受到了越来越多的关注。尽管当前的图少样本学习方法取得了显著进步，但仍存在一些关键局限性。首先，现有的大多数方法依赖于预定义和统一的图滤波器（例如低通或高通滤波器）来全局增强或抑制节点频率信号。固定谱操作未能考虑到真实世界图中固有的局部拓扑结构异质性。此外，这些方法通常假设支持集和支持集来自相同的分布。但在少样本条件下，支持集中有限的标记数据可能无法充分捕捉查询集的复杂分布，从而导致泛化性能不佳。", "innovation": "本文提出了一种新的图少样本学习框架GRACE，该框架结合了自适应频谱专家和跨集分布校准技术。理论上看，该方法通过适应局部结构变化和跨集分布校准来增强模型的泛化能力。实证上，GRACE在广泛实验设置中均优于最新的基线方法。", "conclusion": "GEAC（GRACE）在各种实验设置中始终优于最先进的基准方法。我们的代码可以在[链接]中找到。"}
{"llm_update_time": "20251023", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.14623", "html_url": "https://arxiv.org/abs/2510.14623", "title": "LeapFactual：基于条件流匹配的可靠视觉反事实解释", "title_en": "LeapFactual: Reliable Visual Counterfactual Explanation Using Conditional Flow Matching", "authors": "Zhuo Cao,Xuan Zhao,Lena Krieger,Hanno Scharr,Ira Assent", "background": "随着机器学习（ML）和人工智能（AI）模型在高风险领域，如医疗和科学研究中的集成度不断提高，对这些模型的要求不仅是准确，也要具备解释性。现有的可解释方法中，反事实解释能够通过识别输入中极小的变化，从而改变模型预测，提供更深层次的理解。然而，当前的反事实生成方法存在一些关键问题，包括梯度消失、不连续的潜在空间以及对所学决策边界和真实决策边界之间对齐的过度依赖。这些问题限制了反事实解释的应用范围。", "innovation": "本文提出了LeapFactual，一种基于条件流匹配的新颖反事实解释算法，以克服现有方法的局限性。LeapFactual能够生成可靠和有信息量的反事实样本，即使在真实和学习到的决策边界存在分歧的情况下也能生成。该方法具有模型无偏性，不仅限于具有可微损失函数的模型，还能处理人类参与的系统，将反事实解释的范围扩展到需要人类注释者的领域，例如公民科学。", "conclusion": "在基准数据集和实际数据集上的充分实验证明，LeapFactual能够生成准确、符合分布的反事实解释，提供行动参考信息。此外，可靠标签的反事实样本能够作为新训练数据用于模型增强。该方法广泛适用，提高了科学知识发现以及非专家的可解释性。"}
{"llm_update_time": "20251023", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.15242", "html_url": "https://arxiv.org/abs/2510.15242", "title": "Dual-Weighted Reinforcement Learning for Generative Preference Modeling", "title_en": "Dual-Weighted Reinforcement Learning for Generative Preference Modeling", "authors": "Shengyu Feng,Yun He,Shuang Ma,Beibin Li,Yuanhao Xiong,Songlin Li,Karishma Mandyam,Julian Katz-Samuels,Shengjie Bi,Licheng Yu,Hejia Zhang,Karthik Abinav Sankararaman,Han Fang,Riham Mansour,Yiming Yang,Manaal Faruqui", "background": "研究表明，增强学习（RL）在大型语言模型上有效扩展链式思考（CoT）推理，特别是在有验证答案的任务中。然而，将RL扩展到更一般的不可验证任务，通常以人类偏好对的形式呈现，仍然具有挑战性且研究不足。", "innovation": "本文提出了一种新的双重加权强化学习（DWRL）框架，该框架通过双重加权的RL目标将CoT推理与布雷德利-特里（BT）模型集成起来，从而保留了偏好建模的归纳偏置。DWRL利用两个互补的权重来近似BT模型的最大似然目标：一个实例级别的不匹配权重，强调与人类偏好不符的训练不足的偏好对；另一个是群体级别的条件偏好评分，促进有前景的想法。", "conclusion": "总体而言，本文的结果将DWRL定位为一种推理增强的偏好学习框架，适用于超出验证任务的更广泛的应用场景。"}
{"llm_update_time": "20251023", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.16021", "html_url": "https://arxiv.org/abs/2510.16021", "title": "基于特征的强化学习在连续日内光伏交易中的应用", "title_en": "Feature-driven reinforcement learning for photovoltaic in continuous intraday trading", "authors": "Arega Getaneh Abate,Xiufeng Liu,Ruyu Liu,Xiaobing Zhang", "background": "光伏运营商面临着发电量和短期电力价格的显著不确定性。连续日内市场使生产商能够实时调整其交易策略，从而有可能改善收益并减少不平衡成本。本文探讨了一种基于特征的强化学习方法，该方法通过数据驱动的特征将数据整合进入状态，并在顺序决策框架中学习投标策略。", "innovation": "提出了一种基于特征的强化学习（RL）方法，用于光伏日内交易。该方法将数据驱动的特征结合到状态中，并采用序贯决策框架学习投标策略，使用了Proximal Policy Optimization (PPO) 算法通过主要线性、可解释的策略解决。”该方法在历史市场数据上的训练和离样本评估表明，该策略在多种情境下持续优于基准模型。广泛的验证展示了快速收敛性、实时推理和透明的决策规则。所学权重突出市场微观结构和历史特征的重要作用。", "conclusion": "基于特征的RL方法为PV生产商在日内市场中积极参与提供了一条实用、数据高效且操作可行的途径。"}
{"llm_update_time": "20251023", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.16916", "html_url": "https://arxiv.org/abs/2510.16916", "title": "SolverLLM：通过LLM引导搜索利用测试时缩放解决优化问题", "title_en": "SolverLLM: Leveraging Test-Time Scaling for Optimization Problem via LLM-Guided Search", "authors": "Dong Li,Xujiang Zhao,Linlin Yu,Yanchi Liu,Wei Cheng,Zhengzhang Chen,Zhong Chen,Feng Chen,Chen Zhao,Haifeng Chen", "background": "大型语言模型（LLMs）在解决复杂推理任务（包括优化问题）方面具有潜在的能力。然而，现有的方法要么依赖于提示工程，这会导致在不同类型的问题上泛化能力差，要么需要昂贵的监督训练。", "innovation": "我们引入了SolverLLM，这是一种无监督训练框架，利用测试时缩放来解决多样的优化问题。SolverLLM 生成数学公式并将其转化为求解器准备的代码，通过新的蒙特卡洛树搜索（MCTS）策略进行引导。我们对经典MCTS进行了改进，包括动态扩展以实现自适应公式生成、通过结果驱动的反馈引导探索的提示反向传播，以及将奖励可靠性纳入决策过程的不确定性反向传播。", "conclusion": "实验结果显示，SolverLLM 在六个标准基准数据集上表现优于基于提示和基于学习的方法，能够在没有额外训练的情况下实现强大的泛化能力。"}
{"llm_update_time": "20251023", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.14810", "html_url": "https://arxiv.org/abs/2510.14810", "title": "重思海scriber原则：低维结构投影的无监督学习", "title_en": "Rethinking Hebbian Principle: Low-Dimensional Structural Projection for Unsupervised Learning", "authors": "Shikuang Deng,Jiayuan Zhang,Yuhang Wu,Ting Chen,Shi Gu", "background": "海伯学习是一种生物原则，直观地描述了神经元如何通过重复刺激适应其连接。然而，当应用于机器学习时，由于连接更新的不受约束和反馈调节的忽略，它面临严重问题。这限制了其在复杂网络架构和任务中的有效扩展。因此，本文介绍了一种新颖的无监督学习方法——结构投影海伯表示（SPHeRe），它通过局部辅助非线性块结合了正交性和结构信息保持。正交性约束旨在限制更新幅度，而结构信息保持的损失可以通过辅助的轻量投影反向传播到输入，这在概念上充当反馈调节作用。", "innovation": "本文提出了一种新颖的无监督学习方法——结构投影海伯表示（SPHeRe），该方法通过结合正交性和结构信息保持解决了海伯学习在机器学习中的问题。具体体现在通过局部辅助非线性块进行结构信息保持，并通过轻量投影反向传播来实现反馈调节功能。此外，这种方法在连续学习和迁移学习场景中表现出强大的有效性，并且在图像重建任务中展示了提取特征的稳定性和泛化能力。", "conclusion": "本文展示了海伯启发式的无监督学习规则在现代深度学习框架中的竞争力和潜力，证明了没有严格反向传播的高效和生物启发式学习算法的可能性。此外，SPHeRe在标准图像分类基准（CIFAR-10, CIFAR-100, Tiny-ImageNet）中达到了无监督突触可塑性方法的最佳性能，进一步验证了其卓越效果。"}
{"llm_update_time": "20251023", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.16780", "html_url": "https://arxiv.org/abs/2510.16780", "title": "3D-GSRD: 3D分子图自编码器与选择性重新遮掩解码", "title_en": "3D-GSRD: 3D Molecular Graph Auto-Encoder with Selective Re-mask Decoding", "authors": "Chang Wu,Zhiyuan Liu,Wen Shu,Liang Wang,Yanchen Luo,Wenqiang Lei,Yatao Bian,Junfeng Fang,Xiang Wang", "background": "分子表示学习（MRL）中的掩码图建模（MGM）是很有前途的方法，但将2D重新掩码解码的成功扩展到3D MGM并不容易，主要由于两个相互冲突的挑战：避免2D结构信息泄漏到解码器，同时仍能为重建重新掩码原子提供足够的2D上下文。", "innovation": "提出了3D-GSRD：一种3D分子图自编码器，结合了选择性重新遮掩解码（SRD）。SRD仅从编码器表示中重新遮掩3D相关的信息，同时保留2D图结构。SRD与3D关系变换编码器（3D-ReTrans）相结合，使用结构独立的解码器。实验证明3D-GSRD在MD17分子性质预测基准测试中的7个目标上达到了新的最佳性能。", "conclusion": "3D-GSRD通过SRD增强了编码器在MRL中的作用，并在广泛使用的MD17分子性质预测基准测试中取得了优异的下游性能，达到了新的最先进水平。"}
{"llm_update_time": "20251023", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.15061", "html_url": "https://arxiv.org/abs/2510.15061", "title": "Antislop：识别和消除语言模型中重复模式的全面框架", "title_en": "Antislop: A Comprehensive Framework for Identifying and Eliminating Repetitive Patterns in Language Models", "authors": "Samuel Paech,Allen Roush,Judah Goldfeder,Ravid Shwartz-Ziv", "background": "广泛采用的预训练语言模型（LLM）出现了特征性的重复表达方式，称为‘slop’，这降低了生成文本的质量，并使AI生成的文本容易辨认。", "innovation": "本文提出了Antislop，这是一种全面的框架，提供了检测和消除过度使用模式的工具。创新点包括：1. Antislop Sampler 使用回溯技术在推理时抑制不需要的字符串；2. 自动化的工作流程，通过与人类基准对比分析模型特有的slop，并生成训练数据；3. 最终词元优先级优化（FTPO），一种新颖的调优方法，在推理跟踪中出现禁止模式的地方精细调整logits。", "conclusion": "实验表明，某些slop模式在LLM输出中比人类文本出现频率高1,000倍以上。Antislop Sampler 成功抑制了8,000多个模式，同时保持了高质量，而词元禁用在仅2,000的情况下就不可用了。最重要的是，FTPO在跨领域的评估任务中，如GSM8K、MMLU和创意写作任务中，实现了90%的slop减少，同时保持或提高了性能，而DPO在获得更弱的抑制效果时，写作质量和词汇多样性显著下降。所有代码和结果在MIT许可下提供：this https URL"}
{"llm_update_time": "20251023", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.18037", "html_url": "https://arxiv.org/abs/2510.18037", "title": "评估概率时间序列预测模型在神经活动中的表现", "title_en": "Benchmarking Probabilistic Time Series Forecasting Models on Neural Activity", "authors": "Ziyu Lu,Anna J. Li,Alexander E. Ladd,Pascha Matveev,Aditya Deole,Eric Shea-Brown,J. Nathan Kutz,Nicholas A. Steinmetz", "background": "神经活动预测对于理解神经系统和实现闭环控制至关重要。尽管深度学习在时间序列预测领域取得了显著进展，但其在神经活动预测中的应用仍然有限。为了弥合这一差距，研究人员系统地评估了八种概率深度学习模型，包括两种基础模型。这些模型在通用预测基准上表现出色，并将其与四种经典统计模型和两种基线方法进行了比较。", "innovation": "这项研究通过系统地评估八种不同的概率深度学习模型，旨在填补神经活动预测领域的空白，并且发现某些深度学习模型在预测未来1.5秒内的自发神经活动方面优于经典方法。", "conclusion": "研究结果表明未来可以将这些模型应用于控制应用领域，并且这些模型为探索神经活动的固有时间结构提供了新的途径。"}
{"llm_update_time": "20251023", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.17313", "html_url": "https://arxiv.org/abs/2510.17313", "title": "超越静态与动态的解耦：多因素序列表示的基准与评估框架", "title_en": "Disentanglement Beyond Static vs. Dynamic: A Benchmark and Evaluation Framework for Multi-Factor Sequential Representations", "authors": "Tal Barami,Nimrod Berman,Ilan Naiman,Amos H. Hason,Rotem Ezra,Omri Azencot", "background": "在深度学习中，学习序贯数据的解耦表示是一个关键目标，在视觉、音频和时间序列领域有着广泛应用。尽管现实世界的数据涉及多个相互影响的语义因素，但之前的大部分研究主要集中在简单的静态和动态双因素设置上，因为这样的设置更容易收集数据，忽略了现实世界数据中固有的多因素特性。", "innovation": "本文引入了一个标准化基准，用于评估跨六个不同数据集（涵盖视频、音频和时间序列）的多因素序贯解耦。基准包括模块化的数据集集成工具、模型开发工具以及适用于多因素分析的评估指标。此外，还提出了事后潜空间探索阶段，用于自动对齐潜在维度与语义因素，并引入了一个基于Koopman的模型，实现了最先进的结果。此外，表明视觉语言模型可以自动进行数据集注解，并作为零样本解耦评估工具，无需手动标签和人工干预。", "conclusion": "这些建设性的工作为跨多个因素的序贯解耦提供了坚实和可扩展的基础。"}
{"llm_update_time": "20251023", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2405.11647", "html_url": "https://arxiv.org/abs/2405.11647", "title": "Hummer: 向有限竞争的偏好数据集迈进", "title_en": "Hummer: Towards Limited Competitive Preference Dataset", "authors": "Li Jiang,Yusen Wu,Junwu Xiong,Jingqing Ruan,Yichuan Ding,Qingpei Guo,Zujie Wen,Jun Zhou,Xiaotie Deng", "background": "偏好数据集对于在预训练语言模型中融入人类偏好至关重要，在强化学习从人类反馈中学习中发挥着关键作用。然而，这些数据集往往表现出相互冲突的对齐目标，这增加了对抗攻击的脆弱性，并且在调整下游任务以优先考虑特定的对齐目标时，可能会对其他目标产生负面影响。", "innovation": "本文介绍了一种新的统计度量——对齐维度冲突，用于量化偏好数据集中冲突的程度。此外，提出了Hummer和细粒度的变体Hummer-F，作为减少竞争的创新双向偏好数据集。Hummer基于UltraFeedback，并通过GPT-4的人工智能反馈进行增强，首次旨在减少对齐目标之间的竞争。同时，开发了奖励模型HummerRM和HummerRM-F，采用了混合采样方法有效平衡各种对齐目标。", "conclusion": "HummerRM作为理想模型，适用于领域特定的进一步微调和减少攻击的脆弱性。"}
{"llm_update_time": "20251023", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2409.08303", "html_url": "https://arxiv.org/abs/2409.08303", "title": "通过手写分析评估神经退行性疾病的可解释特征", "title_en": "Interpretable Features for the Assessment of Neurodegenerative Diseases through Handwriting Analysis", "authors": "Thomas Thebaud,Anna Favaro,Casey Chen,Gabrielle Chavez,Laureano Moro-Velazquez,Ankur Butala,Najim Dehak", "background": "神经退行性疾病（NDs）如帕金森病（PD）和阿尔茨海默病（AD）常常伴有运动功能障碍，但在早期阶段可能难以检测。这项研究使用来自113名参与多个在数字平板上执行任务的主体的手写信号的广泛可解释特征分析，试图评估这些特征在表征NDs的效用。", "innovation": "该研究从14种不同的任务中提取了任务通用和任务特定特征，并通过统计分析和一系列分类实验，探讨了哪些特征提供了对NDs与健康对照组以及不同NDs之间区分能力更强的信息。研究结果表明，通过测量参与者手写的手工艺品自定义的可解释特征（如稳定性的变化、书写速度、无书写时间以及不同小组间的压力变化）可以在多种任务之间显示出统计学上的显著差异，从而有效地区分NDs和健康对照组。", "conclusion": "研究表明，通过使用各种二元分类算法处理计算出的特征，可以在AD与健康对照组之间获得高达87%的准确率，在PD与健康对照组之间获得高达69%的准确率。这表明手写信号中的运动功能障碍可能具有潜在的价值，用于早期检测和诊断神经退行性疾病。"}
{"llm_update_time": "20251023", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2410.01735", "html_url": "https://arxiv.org/abs/2410.01735", "title": "LASeR: 使用多臂老虎机学习自适应选择奖励模型", "title_en": "LASeR: Learning to Adaptively Select Reward Models with Multi-Armed Bandits", "authors": "Duy Nguyen,Archiki Prasad,Elias Stengel-Eskin,Mohit Bansal", "background": "奖励模型（RMs）对于大型语言模型（LLMs）的校准至关重要，然而，一个针对特定任务（如写作）专门优化的RM是否能很好地适用于未见过的新任务（如数学计算）在事先是未知的。这使得仅使用一个固定的RM去训练LLMs可能不太理想。然而，同时优化多个RM会带来巨大的计算成本，并可能导致来自不同RM的矛盾信号，从而影响性能。因此，亟需一种方法来有效选择和利用多个RM，以提升LLMs的表现和效率。", "innovation": "我们提出了LASeR（Learning to Adaptively Select Rewards），将其奖励模型选择问题建模为一个多臂老虎机问题。LASeR能够高效地、迭代地选取最适合当前情况的RM来训练LLMs，不仅在常识推理和数学推理任务上提高了LLM训练的效果，还在开放指令执行任务上取得了更好的结果（如AlpacaEval测试中以72.69%的胜率超越RM分数集成基准），并且在生成长文本上下文中也展示了更好的性能（如单文档问答任务和少量学习下的F1分数分别提升2.96点和2.97点），从而提高了LLM的效率（如在某些任务上加速两倍）。", "conclusion": "通过LASeR，研究人员能够更有效地利用多个奖励模型，不仅提高了LLM在各种任务中的准确性，还展示了其在计算效率上的优势。LASeR方法展示了在多任务和长文本生成场景中的广泛应用潜力。"}
{"llm_update_time": "20251023", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2410.05530", "html_url": "https://arxiv.org/abs/2410.05530", "title": "VisDiff: SDF-Guided Polygon Generation for Visibility Reconstruction and Recognition", "title_en": "VisDiff: SDF-Guided Polygon Generation for Visibility Reconstruction and Recognition", "authors": "Rahul Moorthy,Jun-Jee Chao,Volkan Isler", "background": "机器学习能够捕捉组合结构的丰富表示，应用于诸如建筑平面图、地形、图像和动画的分析与生成任务。现有研究主要集中在具备明确特征、邻域或距离度量的结构上，而缺乏此类特征的结构尚未得到充分研究。例如，在多边形中，顶点位置的小变化会导致组合结构显著重组，这是通过可视性或三角剖分图来表达的。当前的表示学习方法无法捕捉到没有明确特征和距离度量的结构。研究缺口在于组合结构的可视重建问题，即给定一个可视性图，构建一个多边形，该多边形的可视性图即为原始的可视性图。", "innovation": "本文提出了一种新颖的基于扩散的方法VisDiff，用于从输入的可视性图生成多边形。该方法的独特之处在于，不直接生成多边形的顶点集，而是首先估计与多边形相关的符号距离函数（SDF），然后使用该SDF提取代表最终多边形的顶点位置。与直接生成顶点位置相比，这种方法能够更有效地学习可视关系。为了训练VisDiff，作者创建了一个精心策划的数据集，并用它来评估该方法，结果显示VisDiff的F1-Score相比标准方法和最先进的方法提高了26%。", "conclusion": "通过使用符号距离函数，VisDiff能够有效学习可视关系，从而实现可视重建和识别。实验表明，这种方法在F1-Score指标上取得了明显提升。"}
{"llm_update_time": "20251023", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2501.12407", "html_url": "https://arxiv.org/abs/2501.12407", "title": "高效且容错的流批混合模型", "title_en": "The Streaming Batch Model for Efficient and Fault-Tolerant Heterogeneous Execution", "authors": "Frank Sifei Luan,Ron Yifeng Wang,Yile Gu,Ziming Mao,Charlotte Lin,Amog Kamsetty,Hao Chen,Cheng Su,Balaji Veeramani,Scott Lee,SangBin Cho,Clark Zinzow,Eric Liang,Ion Stoica,Stephanie Wang", "background": "尽管机器学习模型的训练和推理都依赖于GPU，但基于CPU的数据处理往往成为瓶颈。现有的批处理或流处理的分布式数据处理系统假设了资源需求的一致性，它们在CPU计算上表现出色，但在处理异构资源时容易出现资源利用率低下或故障恢复时间长的问题。", "innovation": "本文提出了一种流批混合模型，该模型将批处理和流处理相结合，能实现高效且容错的异构执行。核心理念是使用分区作为执行单位以实现弹性适应，并允许跨异构操作符动态创建并流式传输以实现内存友好的流水线。", "conclusion": "通过采用异构集群，Ray Data 对异构批推理流水线的吞吐量提升了2.5-12倍，相较于传统的批处理和流处理系统。对于多模态模型，如Stable Diffusion，Ray Data 的训练吞吐量提高了31%，优于单一节点的机器学习数据加载器。"}
{"llm_update_time": "20251023", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2411.03270", "html_url": "https://arxiv.org/abs/2411.03270", "title": "稳定匹配中的排序：近似比率与学习", "title_en": "Stable Matching with Ties: Approximation Ratios and Learning", "authors": "Shiyun Lin,Simon Mauras,Nadav Merlis,Vianney Perchet", "background": "研究双面市场中的匹配问题，其中一侧的工人可能对工作有偏好排序，根据匹配效用形成偏好。不同于带有严格偏好排序的古典双面市场，不存在一个能够最大化所有工人效用的稳定匹配。本文分析了只通过稳定匹配时可能产生的线性效用损失，并探讨了如何在不知确切效用的情况下确保工人的效用至少达到最优效用的对数级近似。", "innovation": "文章提出了‘最优稳定份额’(OSS)比率来度量工人在任何稳定匹配中的最大可实现效用与给定匹配效用之间的比率。设计了算法来构建一个可能不稳定的匹配分布，从而实现一个渐近紧的O(logN) OSS比率。在效用未完全可知时，提供了一个保证工人们获取最优效用对数级近似的新算法。并且将这些离线近似结果扩展到了带有限制不稳定性仅观测配对效用的bandit学习环境中。", "conclusion": "研究了稳定匹配中由于工人具有排序偏好所带来的问题，并通过算法设计解决了这一难题。在不知道完全效用的情况下，这些算法能够为工人提供近似最优的效用。此外，提出了一个适用于受限制观测的bandit学习环境中的算法，并揭示了严格偏好和排序偏好市场之间的基本权衡。"}
{"llm_update_time": "20251023", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.13656", "html_url": "https://arxiv.org/abs/2510.13656", "title": "基于统计融合的Rebalancing with Calibrated Sub-classes (RCS)框架：跨模态稳健不平衡分类", "title_en": "Rebalancing with Calibrated Sub-classes (RCS): A Statistical Fusion-based Framework for Robust Imbalanced Classification across Modalities", "authors": "Priyobrata Mondal,Faizanuddin Ansari,Swagatam Das", "background": "类别不平衡问题严重挑战了模型的稳健性，模型往往倾向于多数类。分布校准提供了一种有效的方法来解决这一问题，通过估计更准确的类别分布。现有的方法往往依赖于多数类信息，无法有效处理少数类的过拟合问题。因此，需要一种能够融合多数类和中间类信息的方法，以更准确地估计少数类参数的校准框架。现有的大多数方法都在不同的数据模态上存在一定的局限性，缺乏一个普遍适用的解决方案。为此，本文通过训练一个编码器-解码器网络来保留不平衡数据集中的结构关系，并防止特征解纠缠，提出了一种新的统计融合校准框架——Rebalancing with Calibrated Sub-classes (RCS)。", "innovation": "该框架通过加权混合高斯组件融合了多数类和中间类的统计信息，以更准确地估计少数类参数。编码器-解码器网络被训练来保留不平衡数据集中的结构关系，并防止特征解纠缠。训练结束后，通过编码器提取的特征向量生成由校准分布引导的合成样本。这种基于融合的校准方法通过包含邻域分布信息来有效缓解了过拟合问题，而不仅仅依赖于多数类的统计信息。实验结果表明，该方法在图像、文本和表格数据集上均显著优于现有的多种基线和最先进的方法，显示了其在跨模态不平衡分类中的有效性和普遍适用性。", "conclusion": "提出的RCS框架在多种数据模态上展示了其优越性和广泛适用性，通过统计融合方法提高了分类的鲁棒性和准确性，有效应对实际中的不平衡分类挑战。"}
{"llm_update_time": "20251023", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2501.04961", "html_url": "https://arxiv.org/abs/2501.04961", "title": "揭开金融大型语言模型后训练之谜", "title_en": "Demystifying Domain-adaptive Post-training for Financial LLMs", "authors": "Zixuan Ke,Yifei Ming,Xuan-Phi Nguyen,Caiming Xiong,Shafiq Joty", "background": "大型语言模型（LLMs）在医学和金融等专业领域的适应性后训练已经显示出前景，但如何确定最佳适应标准和训练策略仍面临挑战，特别是在数据和模型配置方面存在差异时。本研究通过系统地考察金融领域的LLM适应性后训练，提出了解决这一问题的方法和策略。研究构建了一个名为FINDAP的方法体系，包括FinCap、FinRec、FinTrain和FinEval，分别对应核心能力定义、高效训练配方、训练数据集和支持的评估套件，最终模型Llama-Fin在多种金融任务中达到了最先进的性能。", "innovation": "提出了一种系统性和细粒度的方法（FINDAP），包括FinCap、FinRec、FinTrain和FinEval四个关键组件，用于细化大型语言模型（LLMs）在金融领域的适应性后训练。具体创新点包括：定义了目标领域所需的核心能力（FinCap）；提出了一种有效的训练食谱（FinRec），结合了持续预训练和指令跟随的优化，同时引入了一种利用生成奖励模型过程信号的新型偏好数据蒸馏方法；构建了一套支持FinRec的训练数据集（FinTrain）；设计了一套与FinCap对齐的全面评估套件（FinEval）。这些组件共同作用，实现了在各种金融任务上的优异性能。", "conclusion": "研究揭示了每个适应性后训练阶段如何为特定领域带来不同的能力，并发现了相应的挑战和有效的解决办法，为大型语言模型在特定领域的适应提供了宝贵的见解和指导。最终提出的模型Llama-Fin，在金融任务上达到了最先进的性能。"}
{"llm_update_time": "20251023", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2411.13022", "html_url": "https://arxiv.org/abs/2411.13022", "title": "全方位快速MRI：无需原始数据进行训练以弥补访问差距", "title_en": "Fast MRI for All: Bridging Access Gaps by Training without Raw Data", "authors": "Yaşar Utku Alçalar,Merve Gülle,Mehmet Akçakaya", "background": "物理驱动的深度学习(PD-DL)方法由于能够提高快速磁共振成像(MRI)扫描的重建效果而逐渐流行起来。尽管PD-DL方法可以提供比现有临床快速MRI技术更高的加速率，但它们的应用范围仍然受限于专门的MRI中心。一个关键挑战在于它们难以泛化到罕见的病理状况或不同的人群，这一点在多项研究中都有提到，同时也建议对目标人群进行微调以改进该问题。然而，当前的PD-DL训练方法需要访问原始k空间测量数据，而这些数据通常只能在签署了此类数据访问协议的专门MRI中心获得。这一问题尤其对于农村和缺乏资源的地区尤为关键，因为在这些地区，商业MRI扫描器只能提供最终重建后的图像，而无法访问原始k空间数据。为了应对这些挑战，我们提出了一种名为CUPID（基于压缩性的无监督学习通过并行成像保真度）的方法，以利用仅从MRI扫描器导出的常规临床重建图像进行高质量的PD-DL训练。", "innovation": "CUPID提出了一种创新的方法，通过仅利用从MRI扫描器导出的常规临床重建图像进行高度质量的PD-DL训练，而不需要访问原始k空间测量数据。该方法通过设计扰动来评估输出的质量，并确保输出与临床并行成像重建保持一致。此外，实验结果表明，CUPID在零样本训练设置中优于压缩感知(CS)和基于扩散的生成模型，且表现出较低的训练负担，这证明了其在回顾性和前瞻性欠采样获取中的有效性。", "conclusion": "CUPID方法为快速MRI的广泛应用提供了可能，特别是对偏远和农村地区。这种方法展示了为该昂贵的成像模态减少障碍的机会。"}
{"llm_update_time": "20251023", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2410.11857", "html_url": "https://arxiv.org/abs/2410.11857", "title": "LLMBridge：在以提示为中心的互联网中降低访问LLMs的成本", "title_en": "LLMBridge: Reducing Costs to Access LLMs in a Prompt-Centric Internet", "authors": "Noah Martin,Abdullah Bin Faisal,Hiba Eltigani,Rukhshan Haroon,Swaminathan Lamelas,Fahad Dogar", "background": "当前的互联网基础设施主要是基于HTTP的内容检索，其中中间盒（例如HTTP代理）在性能、安全性和成本效益方面发挥着关键作用。展望未来，互联网通信将由发送给生成型AI模型的“提示”主导。为此，我们需要提供类似于HTTP代理（例如缓存、路由、压缩）功能的代理，以便应对基于提示通信的独特挑战和机遇。为了支持基于提示的通信，我们介绍了LLMBridge，这是一个针对经济意识用户的LLM代理，特别适用于发展中地区和教育领域（例如学生和教师）。LLMBridge支持三项关键优化：模型选择（将提示路由到最合适的模型）、上下文管理（智能减少上下文量）以及语义缓存（使用本地模型和向量数据库提供提示）。这些优化为成本和质量之间引入了权衡，在高层次双向接口中，应用程序通过这些权衡进行导航。作为案例研究，我们在两种成本敏感环境中部署了LLMBridge：基于WhatsApp的问答服务和大学教室环境。WhatsApp服务已上线超过十二个月，为100多名用户服务，并处理了超过14700个请求。同时，我们还让LLMBridge在三个计算机科学课程的数月里接触到学生，它支持各种基于LLM的应用，如推理代理和聊天机器人，并每天处理平均500个请求。我们报告了两种环境中的部署经验，并使用收集的工作负载来评估各种成本优化策略的效用，分析其在成本、延迟和响应质量方面的权衡。", "innovation": "LLMBridge 是一种专门为经济意识用户（例如发展中地区和教育领域的用户）设计的 LLM 代理。它支持三项关键优化：模型选择、上下文管理以及语义缓存。这些优化为成本和质量之间引入了权衡，应用程序通过高层次、双向的接口进行导航。在两个成本敏感的环境中部署了 LLMBridge，并分析了各种成本优化策略在成本、延迟和响应质量方面的权衡。", "conclusion": "LLMBridge 在支持基于提示的通信方面提供了一种有效的解决方案，尤其是在低资源环境下。通过模型选择、上下文管理和语义缓存这三个优化，它平衡了成本和质量的权衡。未来的研究可进一步探讨如何优化性能和成本之间的关系，以更好地满足用户需求。"}
{"llm_update_time": "20251023", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2502.09282", "html_url": "https://arxiv.org/abs/2502.09282", "title": "MsEdF: 一种用于遥感图像描述的多流编码-解码框架", "title_en": "MsEdF: A Multi-stream Encoder-decoder Framework for Remote Sensing Image Captioning", "authors": "Swadhin Das,Raksha Sharma", "background": "遥感图像包含复杂的时空模式和语义结构，这使得模型难以准确描述。传统的编码-解码架构常用于遥感图像描述（RSIC），通过将视觉内容转化为描述性文本。然而，许多现有方法依赖于单流架构，这削弱了模型准确描述图像的能力。单流架构通常难以提取多样化的空间特征或捕捉复杂的语义关系，尤其在高类别相似度或上下文模糊的场景中效果有限。", "innovation": "本文提出了一个多流编码-解码框架（MsEdF），通过优化编码-解码体系的时空表示和语言生成，提高RSIC的性能。该框架通过融合两个互补图像编码器的信息，增强了多尺度和结构上不同的提示特征的集成，从而促进特征多样性。同时，通过采用堆叠的GRU架构和元素级聚合方案，改进了解码侧对情境感知描述的捕捉。", "conclusion": "在三个基准遥感图像描述数据集上的实验显示，MsEdF优于几种基线模型。"}
{"llm_update_time": "20251023", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2503.00273", "html_url": "https://arxiv.org/abs/2503.00273", "title": "交互决策中信息的演变：多臂 bandit 问题的案例研究", "title_en": "Evolution of Information in Interactive Decision Making: A Case Study for Multi-Armed Bandits", "authors": "Yuzhou Gu,Yanjun Han,Jian Qian", "background": "本文通过随机多臂老虎机问题的研究，探讨了交互决策中的信息演变过程。它聚焦于一个基本的例子，说明一个最优臂总是比其他臂高出固定幅度时，最优成功率和互信息如何随时间变化。", "innovation": "研究发现互信息的增长经历了线性、二次和再次线性三个阶段，并揭示了交互与非交互环境在信息量行为上的微妙差异。同时，文章指出最优成功率和互信息之间可以解耦，这意味着在交互决策中达到最优学习不一定需要最大化信息增益。", "conclusion": "本文的研究成果为我们提供了交互决策中信息与学习的复杂互动的新视角。多个最优成功率和互信息之间的非直接相关性为我们提供理解如何高效地进行交互决策的设计提供了新的思路。"}
{"llm_update_time": "20251023", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2503.09271", "html_url": "https://arxiv.org/abs/2503.09271", "title": "DitHub: 增量开放词汇对象检测的模块化框架", "title_en": "DitHub: A Modular Framework for Incremental Open-Vocabulary Object Detection", "authors": "Chiara Cappellino,Gianluca Mancusi,Matteo Mosconi,Angelo Porrello,Simone Calderara,Rita Cucchiara", "background": "开放词汇的目标检测器可以通过简单的文本提示推广到一组不受限制的类别。然而，适应这些模型到稀有类别或增强它们在多个专门领域的能力仍然是关键。最近的方法依赖于单一权重集的全局适应策略。", "innovation": "我们提出了一种模块化深度学习方法，名为DitHub。DitHub是一个框架，用于构建和维护高效的适应模块库，受版本控制系统启发，DitHub将专家模块作为分支管理，可以在需要时获取和合并。这种方法首次对适应模块的组合特性进行了深入研究，在对象检测领域。我们的方法在ODinW-13基准测试和新引入的评估类别再现的ODinW-O基准测试中均达到最新性能。", "conclusion": "我们通过DitHub框架实现了在ODinW-13基准测试和ODinW-O新基准测试中的最新性能。DitHub框架扩展了增量开放词汇对象检测的能力，为未来的这项研究开辟了道路。"}
{"llm_update_time": "20251023", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2504.10483", "html_url": "https://arxiv.org/abs/2504.10483", "title": "REPA-E: 通过潜扩散变换器实现VAE端到端调优", "title_en": "REPA-E: Unlocking VAE for End-to-End Tuning with Latent Diffusion Transformers", "authors": "Xingjian Leng,Jaskirat Singh,Yunzhong Hou,Zhenchang Xing,Saining Xie,Liang Zheng", "background": "传统的深度学习方法倾向于端到端训练，但在对潜扩散模型进行实验时发现，端到端训练VAE和扩散模型会导致性能下降。因此，研究团队探索了一种新的损失函数——表示对齐（REPA）损失，使得VAE和扩散模型能够通过端到端的方式共同调优。", "innovation": "提出了一种新的训练方法（REPA-E），通过使用REPA损失，即使在扩散损失不有效的情况下，也能够实现VAE和扩散模型的有效端到端训练。相对于标准方法和原始训练方法，该方法在加速扩散模型训练方面表现出了显著的效果，并且端到端调优还提高了VAE本身的性能。", "conclusion": "该方法在ImageNet 256x256上实现了FID分数的新最优值，分别是1.12（无分类自由引导）和1.69（有分类自由引导），并且公开了相关的代码。"}
{"llm_update_time": "20251023", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2503.20541", "html_url": "https://arxiv.org/abs/2503.20541", "title": "快速、模块化且可微的机器学习增强分子模拟框架", "title_en": "Fast, Modular, and Differentiable Framework for Machine Learning-Enhanced Molecular Simulations", "authors": "Henrik Christiansen,Takashi Maruyama,Federico Errica,Viktor Zaverkin,Makoto Takamoto,Francesco Alesiani", "background": "现有的分子动力学和蒙特卡洛模拟软件虽然功能强大，但在较复杂系统中的计算效率和灵活性仍然有限。传统的手优化模拟引擎难以同时提供高效和灵活性，而使用Python实现的框架虽然灵活，但在性能上可能不如手优化的版本，尤其是在大规模系统中。本文提出的DIMOS框架旨在通过集成机器学习增强的相互作用势和经典力场（包括高效网格-堆网络算法）来提高这些模拟的效率和灵活性，从而缩小手优化模拟引擎和Python实施之间的差距。", "innovation": "DIMOS框架提供了一种端到端的可微分子模拟方法，能够轻松整合机器学习增强的相互作用势，并实现经典力场，例如高效的网格-堆网络算法。框架的模块化设计使得经典和机器学习方法可以无缝组合，形成混合描述模型（ML/MM）。DIMOS还支持关键的动力学特征，如高效的邻居列表和用于较大时间步长的约束算法，进一步提高了模拟的效率。此外，该研究还展示了可微性在优化蒙特卡洛模拟（基于哈密顿蒙特卡洛）中的点分布方面的优势，从而观察到参数优化后的三倍速度提升。", "conclusion": "DIMOS框架通过减少系统大小的二次而非线性标度，实现了经典力场模拟相对于其他完全可微模拟框架的最高170倍提速。该研究的结果展示了可微框架在提高模拟速度和灵活性方面的潜在优势。"}
{"llm_update_time": "20251023", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2503.21681", "html_url": "https://arxiv.org/abs/2503.21681", "title": "RNA三维结构-功能建模的全面基准", "title_en": "A Comprehensive Benchmark for RNA 3D Structure-Function Modeling", "authors": "Luis Wyss,Vincent Mallet,Wissam Karroucha,Karsten Borgwardt,Carlos Oliver", "background": "近年来，RNA结构与功能之间的关系引起了深度学习研究领域的关注。随着核苷酸结构模型的不断进步，这种趋势预计会更加显著。然而，缺乏标准且易于访问的基准数据集，限制了使用深度学习技术分析RNA三维结构的研究进展。迄今为止，尚无专门为RNA三维结构功能预测设计的标准化基准数据集，阻碍了该领域的进一步发展和创新。", "innovation": "本文介绍了一套专门设计用于RNA结构功能预测的七个基准数据集。该数据集基于成熟的Python软件包rnaglib构建，简化了数据分发和编码，提供了数据集分割和评估的工具，并提供了一个用户友好、功能全面的模型比较环境。模块化和可重现的设计促进了社区贡献，允许快速定制。为了验证基准数据集的实用性，作者使用关系图神经网络报告了所有任务的基础结果。", "conclusion": "通过引入这一系列数据集，本文为RNA三维结构-功能建模研究提供了一种标准化的途径，促进了该领域的进一步研究发展。这些数据集为不同模型的有效评估提供了基础，对于推进RNA相关领域的应用具有重要意义。"}
{"llm_update_time": "20251023", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2504.07820", "html_url": "https://arxiv.org/abs/2504.07820", "title": "光滑距离核函数及其在MMD和Wasserstein梯度流中的应用", "title_en": "Smoothed Distance Kernels for MMDs and Applications in Wasserstein Gradient Flows", "authors": "Nicolaj Rux,Michael Quellmalz,Gabriele Steidl", "background": "在统计学中，定义最大均差（MMDs）时使用了负距离核函数$K(x,y) := - \\|x-y\\|$，这种核函数在各类应用中取得了良好的数值结果。特别是，所谓的切片技术由于负距离核函数的无参数结构，特别适用于处理高维核求和。但由于其在$x=y$处不具备光滑性，大部分经典的理论结果，例如对应MMD泛函的Wasserstein梯度流的结果不再成立。", "innovation": "本文提出了一种新型核函数，这种核函数保留了负距离核函数的优点（调和次数为1、几乎线性增长和简单的切片结构），同时解决了非光滑性问题，现具有Lipschitz可微性。通过简单的1D平滑处理绝对值函数，再经过Riemann-Liouville分数积分变换获得这种新型核函数。数值结果显示，该新型核函数在梯度下降方法中的表现与负距离核函数相当，但具备理论上的保证。", "conclusion": "新的核函数在保持负距离核函数优点的同时，解决了其非光滑性问题，使得理论结果得以成立，在梯度下降方法中具有良好的表现。"}
{"llm_update_time": "20251023", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2505.01828", "html_url": "https://arxiv.org/abs/2505.01828", "title": "秩一修正值迭代", "title_en": "Rank-One Modified Value Iteration", "authors": "Arman Sharifi Kolarijani,Tolga Ok,Peyman Mohajerin Esfahani,Mohamad Amin Sharif Kolarijani", "background": "本文提出了一种用于马尔可夫决策过程的规划和学习问题的新算法。该算法通过在策略评估步骤中使用转换概率矩阵的秩一近似来遵循一种策略迭代类型的更新方法。这种秩一近似与对应的转换概率矩阵的平稳分布密切相关，并通过幂方法进行近似。", "innovation": "提出了一种基于秩一近似的策略迭代算法，在策略评估步骤中使用转换概率矩阵的秩一近似。这种算法在规划问题中的计算复杂性和最优值迭代算法相同，在学习问题中的计算复杂性和Q学习算法相同，同时通过大量的数值模拟，该算法在规划和学习问题上都优于一阶算法及其加速版本。", "conclusion": "本文提供的算法可以在相同的时间复杂度下解决规划和学习问题，并且通过数值模拟表明，该算法在性能上优于其他一阶算法及其加速版本。"}
{"llm_update_time": "20251023", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2504.11555", "html_url": "https://arxiv.org/abs/2504.11555", "title": "Bilinear 观测下的二次控制分离原理的次优性", "title_en": "Sub-optimality of the Separation Principle for Quadratic Control from Bilinear Observations", "authors": "Yahya Sattar,Sunmook Choi,Yassir Jedra,Maryam Fazel,Sarah Dean", "background": "本文考虑了从双线性观测控制线性动力系统的最小二乘问题。尽管这个问题与标准的线性二次高斯（LQG）控制相似，但研究表明，在观测模型为双线性的情况下，分离原则并不成立，最优控制器也不再是估计状态的affine形式。此外，成本函数关于控制输入是非凸的。因此，通常难以找到最优反馈控制器的解析表达式。同时，标准LQG控制器在某些情况下仅局部最大化成本而非最小化。其次，最优控制器（解析导出）不唯一且是非线性的。本文还引入了输入依赖的可观测性概念，并推导出了卡尔曼滤波协方差保持有界的条件。作者通过多个合成设置中的数值实验来说明理论结果。", "innovation": "引入了输入依赖的可观测性概念，并研究了在双线性观测下的最优控制器性质。证明了标准LQG控制原理在此情况下的次优性，并推导了卡尔曼滤波协方差保持有界的条件。这些都是对传统LQG控制理论的重要扩展和补充。", "conclusion": "文章证明了双线性观测情况下的LQG控制原理的次优性。不同场景下最优控制器的性质并不等同于线性系统的分离设计，且最优控制器形式复杂。引入的输入依赖的可观测性和关于卡尔曼滤波协方差有界的条件，对实际系统的设计和分析提供了理论指导。"}
{"llm_update_time": "20251023", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2505.18871", "html_url": "https://arxiv.org/abs/2505.18871", "title": "非平稳Lipschitz多臂老虎机", "title_en": "Non-Stationary Lipschitz Bandits", "authors": "Nicolas Nguyen,Solenne Gaucher,Claire Vernade", "background": "研究了无限动作集上的非平稳Lipschitz多臂老虎机问题，其中的奖励函数满足Lipschitz条件，可以在任意时间点发生变化。现有研究通常需要预知非平稳性的先验信息，但在实际应用中这往往是不可行的。已有研究中，关于如何在无先验信息的情况下检测奖励函数的变化，缺乏有效的最小最大动态懊悔界保证的方法。因此，本文致力于解决这一问题，提出了一个新的适应性的跟踪算法，能够识别显著变化，并利用层次化动作空间离散化技术检测奖励函数变化，取得了最优的动态懊悔界。", "innovation": "设计了一种新的适应性跟踪算法，无需任何关于非平稳性的先验信息，利用层次化动作空间离散化技术检测奖励函数的变化，并取得了最小最大动态懊悔界最优保证，具体为$\tilde{O}(\tilde{L}^{1/3}T^{2/3})$，其中$\tilde{L}$表示显著变化的数量，$T$表示时间范围。这一方法填补了在没有先验信息的情况下，关于非平稳Lipschitz多臂老虎机研究中的空白。", "conclusion": "该研究提出了一种新的算法，在无需任何关于非平稳性的先验信息的情况下，能够检测奖励函数的变化，并且实现了最优的动态懊悔界。这一结果是首次给出这种设置下的最优保证。"}
{"llm_update_time": "20251023", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2501.13373", "html_url": "https://arxiv.org/abs/2501.13373", "title": "使用AI推动碳捕集：基于膜方程和线性回归估算渗透膜参数", "title_en": "Advancing Carbon Capture using AI: Design of permeable membrane and estimation of parameters for Carbon Capture using linear regression and membrane-based equations", "authors": "Bishwash Panerua,Biplov Paneru", "background": "本研究关注膜基系统在二氧化碳分离中的应用，以应对高效的碳捕集解决方案的迫切需求，以减轻气候变化的影响。研究采用了基于膜方程的线性回归模型来估算孔隙率 ε=0.4805、Kozene 常数 K=2.9084、比表面积 σ=105.3272 m²/m³ 等关键参数。这些参数通过合成数据集的线性回归分析得出。同时，研究还分析了膜的性能，包括流量 Q=9.8778×10⁻⁴ m³/s、进气压力 P₁=2.8219 MPa 和出气压力 P₂=2.5762 MPa。二氧化碳的渗透率值为 0.045，显示了高效的分离潜力。优化膜的性质以选择性地阻止二氧化碳，同时允许其他气体通过，对于提高碳捕集效率至关重要。", "innovation": "研究结合了合成数据集的线性回归分析技术来估算关键参数，这种技术为二氧化碳分离研究提供了新的方法。同时，研究探索了如何利用人工智能（AI）来设计适用于碳捕集的渗透膜，这对于应对全球气候变化挑战和支持联合国可持续发展目标（SDGs）具有重要意义。", "conclusion": "通过将这些技术整合到工业过程中，可以显著减少温室气体排放，促进循环经济，从而为达成全球气候变化目标做出贡献。"}
{"llm_update_time": "20251023", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2505.13732", "html_url": "https://arxiv.org/abs/2505.13732", "title": "Backward Conformal Prediction", "title_en": "Backward Conformal Prediction", "authors": "Etienne Gauthier,Francis Bach,Michael I. Jordan", "background": "传统的容效能保证预测覆盖水平，但容积大小会根据数据变化而变化。本文介绍了Backward Conformal Prediction方法，该方法可以在保证容效能的同时，灵活控制预测集的大小。这种方法基于Gauthier等人[2025]关于e值的后验有效性结果，可以确保边际覆盖水平为$\text{P}(Y_{\text{test}} \text{ in } \tilde{\text{α}}_{\text{n}}^{\tilde{\text{α}}}(X_{\text{test}})) \text{ at least } 1 - \text{E}[\tilde{\text{α}}]$，并结合了一个基于识别集的新颖的剔除一项估计$\bar{\text{α}}^{\text{LOO}}$，使理论保证在实践中可计算。这种方法特别适用于那些预测集过大在实践中不可行的应用场景，如医学诊断。", "innovation": "该方法核心创新在于定义了一个基于观察数据的规则，该规则限制预测集大小如何随数据变化行为，并根据实际应用调整容覆盖水平。这种方法提供了新的leave-one-out估计$\bar{\text{α}}^{\text{LOO}}$，结合了边际覆盖水平的估计，确保即使在数据依赖性的误覆盖情况下，理论保证仍然适用和实用。", "conclusion": "本文通过理论结果和实证证据支持该方法的有效性，展示了该方法能够在保持可计算的覆盖保证的同时，提供可解释且控制良好的预测集大小。特别适用于医学诊断等领域，其中大的预测集可能是不切实际的。"}
{"llm_update_time": "20251023", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.01162", "html_url": "https://arxiv.org/abs/2506.01162", "title": "近乎线性时间的私密假设选择，具有最优近似因子", "title_en": "Nearly-Linear Time Private Hypothesis Selection with the Optimal Approximation Factor", "authors": "Maryam Aliakbarpour,Zhan Shi,Ria Stevens,Vincent X. Wang", "background": "从分布的样本中估计分布密度是统计中的基本问题。假设选择解决了除了样本集之外，还给出n个候选分布（称为假设）的场景，并旨在确定哪个假设最能描述底层数据分布。已知该问题可以非常高效地解决，只需大致需要 $O(\text{log } n)$ 个样本并在 $\tilde{O}(n)$ 时间内运行。算法输出的质量通过与未知分布的总变差距离来衡量，该距离受到最优距离的限制，该最优距离是在最佳候选假设上实现的。已知 $\text{α} = 3$ 是该问题的最佳近似因子。", "innovation": "本文提出了一种中心模型下的差分隐私算法，该算法在假设数量的近线性时间内运行，实现了最优近似因子，并且样本复杂度增加仅为多项式对数级别。这解决了 [Bun, Kamath, Steinke, Wu, NeurIPS 2019] 提出的开放问题，之前的上界需要 quadratic 时间。", "conclusion": "本文展示了如何在保持算法效率的基础上，通过增加适度的样本量复杂度，使算法满足差分隐私要求，从而实现了在假设选择问题上具有最优近似因子的近乎线性时间的算法。"}
{"llm_update_time": "20251023", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.05735", "html_url": "https://arxiv.org/abs/2506.05735", "title": "LLMs真的会忘记吗？基于知识关联和置信度意识的卸载评估", "title_en": "Do LLMs Really Forget? Evaluating Unlearning with Knowledge Correlation and Confidence Awareness", "authors": "Rongzhe Wei,Peizhi Niu,Hans Hao-Hsun Hsu,Ruihan Wu,Haoteng Yin,Mohsen Ghassemi,Yifan Li,Vamsi K. Potluru,Eli Chien,Kamalika Chaudhuri,Olgica Milenkovic,Pan Li", "background": "现有的机器卸载技术主要侧重于显式删除孤立事实，而忽视了潜在的推断依赖性和大型语言模型中知识的非确定性，导致被认为遗忘的事实可能因相关信息而隐秘存在。因此，需要一种更准确捕捉现实世界知识隐式结构的方法，以评估模型的卸载效果，并揭示当前评估策略往往高估了卸载效果的问题。", "innovation": "提出了一个知识卸载评估框架，通过构建知识图谱并关联置信度得分来代表相关的事实背景，并利用强大的大型语言模型作为评估者，通过推理提取的知识子图来确定卸载效果。此外，框架中的语言模型评估者经过精心设计的任务提示，并通过人类评估校准以确保其可靠性和稳定性。实验结果表明，该框架能提供更真实和严谨的卸载性能评估，揭示当前评估策略夸大卸载效果的问题。", "conclusion": "最新构建的基准实验展示了该框架对卸载性能评估的更现实和严谨性。同时，结果显示，当前的卸载评估策略往往高估了卸载效果。该研究的代码已公开。"}
{"llm_update_time": "20251023", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.08616", "html_url": "https://arxiv.org/abs/2506.08616", "title": "在比较偏好学习模型中保持单调性的同时进行泛化", "title_en": "Generalizing while preserving monotonicity in comparison-based preference learning models", "authors": "Julien Fageot,Peva Blanchard,Gilles Bareilles,Lê-Nguyên Hoang", "background": "在将学习模型表达你对某一选项的偏好时，通常期望该模型按单调性增加你对首选选项的评价，并减少对另一选项的评价。然而，许多广泛使用的基于比较偏好的偏好学习模型，包括大型语言模型，在这种保证上往往有所欠缺。目前为止，唯一被证明具有单调性的基于比较的偏学习算法是广义Bradley-Terry模型，但这类模型不能泛化到未比较的数据。", "innovation": "本研究旨在探索能够泛化的单调性偏好学习模型。提出了一个新的线性广义Bradley-Terry模型，带有扩散先验，并确定了保证单调性的替代物嵌入的充分条件。实验证明这种单调性并非普遍保证，且新的泛化模型能显著提高准确性，尤其是在数据集有限时。", "conclusion": "实验结果显示，单调性并非泛化模型的普遍特性，而新提出的泛化单调性模型在数据有限的情况下能够显著提高准确率。"}
{"llm_update_time": "20251023", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.15753", "html_url": "https://arxiv.org/abs/2506.15753", "title": "QPPG: 基于量子预条件的策略梯度在瑞利衰落信道中的链路自适应", "title_en": "QPPG: Quantum-Preconditioned Policy Gradient for Link Adaptation in Rayleigh Fading Channels", "authors": "Oluwaseyi Giwa,Muhammad Ahmed Mohsin,Folarin Jubril Adesola,Muhammad Ali Jamshed", "background": "可靠的链路自适应在动态衰落环境下的高效无线通信中至关重要。然而，基于强化学习的解决方案往往会因策略梯度过差条件而导致收敛不稳定，阻碍其实用应用。", "innovation": "提出了一种基于费舍尔信息预条件的量子预条件策略梯度（QPPG）算法，该算法通过费舍尔信息基的预条件处理，稳定并加速了策略更新。在瑞利衰落环境中评估显示，QPPG 达到了更快的收敛速度、平均吞吐量提高了28.6%、平均传输功率降低了43.8%，相较于经典方法有显著优势。这项工作引入了量子几何条件，推动了链路自适应的发展，标志着未来6G网络中发展稳健的量子启发式强化学习的显著进步，从而增强通信可靠性和能效。", "conclusion": "QPPG 算法在瑞利衰落信道中的链路自适应中表现出显著优势，通过量子几何条件处理，为6G网络中的通信可靠性与能量效率带来了潜在的提升。"}
{"llm_update_time": "20251023", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.06407", "html_url": "https://arxiv.org/abs/2506.06407", "title": "TimeWak：时间序列数据中的时间链式哈希水印", "title_en": "TimeWak: Temporal Chained-Hashing Watermark for Time Series Data", "authors": "Zhi Wen Soi,Chaoyi Zhu,Fouad Abiad,Aditya Shankar,Jeroen M. Galjaard,Huijuan Wang,Lydia Y. Chen", "background": "合成的时间序列数据可以通过扩散模型生成，用于共享隐私敏感的数据集，如患者的功能性MRI记录。合成数据的关键标准包括高数据效用和可追溯性，以验证数据来源。然而，最新的水印方法仅在同质的潜在空间中嵌入，而最先进的时序生成器则在数据空间进行操作，这使得基于潜在空间的水印不兼容。这导致了直接在数据空间中处理时序依赖性和特征异质性的水印挑战。", "innovation": "我们提出了TimeWak，这是第一个专用于多变量时间序列扩散模型的水印算法。TimeWak通过直接在时间和特征数据空间中嵌入时间链式哈希水印来处理时序依赖性和空间异质性。此外，它还引入了ε-精确反向操作来解决差分过程反向时特征重建误差分布不均匀的问题。我们推导出了反向多变量时序数据时的误差边界，以保持抗攻击的水印可检测性。", "conclusion": "我们在五个具有不同时序长度的数据集和基线上对TimeWak的影响进行了广泛评估，包括合成数据质量、水印检测能力和在各种后编辑攻击下的鲁棒性。实验结果表明，TimeWak在对抗最强的最先进的基线时，在上下文FID得分和相关评分上分别提高了61.96%和8.44%，并且始终保持可检测性。"}
{"llm_update_time": "20251023", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.16895", "html_url": "https://arxiv.org/abs/2506.16895", "title": "在少量数据下进行多模态对齐，请让STRUCTURE引领你", "title_en": "With Limited Data for Multimodal Alignment, Let the STRUCTURE Guide You", "authors": "Fabian Gröger,Shuo Wen,Huyen Le,Maria Brbić", "background": "多模态模型在需要多模态对齐的复杂任务中表现出强大的能力，包括零样本分类和跨模态检索。然而，现有模型通常依赖于数百万对的多模态样本，这些样本在很多领域获取起来是极其昂贵或不现实的。本文探索在有限配对数据下构建多模态模型的可能性，通过将预训练的单模态基础模型进行对齐。研究显示，高质对齐在几千到数万对的配对样本中是可以实现的，这是通常领域中数据量的不到1%。这些样本可用于提高零样本图像分类和检索基准测试中的性能。", "innovation": "介绍了名为STRUCTURE的有效正则化技术，该技术可以保留单模态编码器潜在空间的邻域几何结构，并展示出在最后一层对齐往往不是最优选择，建议对各模态具最高代表性相似性的层进行对齐。这些技术可以在现有对齐方法中直接应用，并在24项零样本图像分类和检索基准测试中表现出了显著收益，分类任务的相对改进平均为51.6%，检索任务为91.8%。", "conclusion": "本研究强调了我们框架在有限样本多模态学习中的有效性和广泛适用性，并为资源受限领域提供了有希望的发展路径。"}
{"llm_update_time": "20251023", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.11153", "html_url": "https://arxiv.org/abs/2506.11153", "title": "QiMeng-MuPa: Mutual-Supervised Learning for Sequential-to-Parallel Code Translation", "title_en": "QiMeng-MuPa: Mutual-Supervised Learning for Sequential-to-Parallel Code Translation", "authors": "Changxin Ke,Rui Zhang,Shuo Wang,Li Ding,Guangli Li,Yuanbo Wen,Shuoming Zhang,Ruiyuan Xu,Jin Qin,Jiaming Guo,Chenxi Wang,Ling Li,Qi Guo,Yunji Chen", "background": "GPU-based高性能计算的兴起推动了并行编程模型，如CUDA的广泛应用。然而，传统的并行编程复杂性导致了对自序列到并行编程自动转换方法的需求。尽管如此，由于数据稀缺，基于机器学习的自序列到并行代码转换仍然面临挑战，尤其是在确保转换代码的功能等效性方面。最近的反向翻译方法虽然显示出潜力，但仍无法保证转换代码的功能等效性。", "innovation": "提出了一种名为QiMeng-MuPa的新颖的Mutual-Supervised Learning框架，用于解决自序列到并行代码转换中的功能等效性问题。该框架包含两个模型，翻译器和测试器，通过迭代的Co-verify和Co-evolve步骤，两者相互生成数据以共同改进。测试器生成单元测试以验证和过滤功能等效的转换代码，从而促进翻译器的进化，而翻译器生成作为增强输入的转换代码，以进化测试器。实验表明，QiMeng-MuPa显著提高了基模型的性能，特别是在Qwen2.5-Coder上，提高了Pass@1的比例高达28.91%，并提高了测试器性能68.90%。同时，QiMeng-MuPa在BLEU和CodeBLEU评分上的表现超过了之前的最先进方法CodeRosetta，分别提高了1.56和6.92，其性能与DeepSeek-R1和GPT-4.1相当。", "conclusion": "QiMeng-MuPa在自序列到并行代码转换中显著提高了性能，特别是在Qwen2.5-Coder上表现突出，并在BLEU和CodeBLEU评分上超越了CodeRosetta，显示出该框架的有效性和潜在价值。"}
{"llm_update_time": "20251023", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.08514", "html_url": "https://arxiv.org/abs/2508.08514", "title": "DeCAL 令牌级压缩", "title_en": "DeCAL Tokenwise Compression", "authors": "Sameer Panwar", "background": "该研究介绍了一种名为DeCAL的新方法，用于进行令牌级压缩。背景信息显示，现有的压缩方法可能在计算资源上有所限制，而DeCAL通过调整预训练的语言模型的编码器部分，专注于最大化压缩质量，即使会增加计算负担。", "innovation": "DeCAL采用了编码器-解码器语言模型，并通过去噪预训练学习生成高质量的一般性压缩表示。主要的创新在于通过最小修改编码器，特别是在2倍压缩下能达到与未压缩数据相当的性能水平，且在8倍压缩下，大多数元任务（如问答、摘要和多向检索）的度量标准也仅小幅下降。", "conclusion": "DeCAL在预计算密集表示可以利用的情况下提供了显著的成本节约，而且研究者认为该方法可以进一步完善以更具广泛适用性。"}
{"llm_update_time": "20251023", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.00890", "html_url": "https://arxiv.org/abs/2508.00890", "title": "AgentTTS：复杂任务中大型语言模型代理的测试时计算优化缩放策略", "title_en": "AgentTTS: Large Language Model Agent for Test-time Compute-optimal Scaling Strategy in Complex Tasks", "authors": "Fali Wang,Hui Liu,Zhenwei Dai,Jingying Zeng,Zhiwei Zhang,Zongyu Wu,Chen Luo,Zhen Li,Xianfeng Tang,Qi He,Suhang Wang", "background": "Test-time scaling (TTS)可以增强大型语言模型(LLMs)的性能，但这主要是在单阶段任务中研究，而许多实际问题则是多阶段的复杂任务，包括一系列异构子任务，每个子任务都需要特定能力的LLM。因此，本文研究多阶段复杂任务中的计算最优TTS问题，旨在为每个子任务选择合适的模型并分配预算以最大化整体性能。", "innovation": "提出了基于LLM代理的AgentTTS框架，该框架自动通过与执行环境的迭代反馈驱动交互来搜索计算最优分配。该方法不仅在搜索效率上优于传统和基于LLM的竞争基准，而且在训练集规模变化时表现更稳健，并且具有更好的可解释性。", "conclusion": "AgentTTS通过代理与执行环境的交互发现计算最优分配，在多阶段复杂任务的TTS方面表现出更高的效率和鲁棒性，并且具有更好的可解释性。"}
{"llm_update_time": "20251023", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.00596", "html_url": "https://arxiv.org/abs/2508.00596", "title": "具有抗合谋性的信息论分布式安全聚合", "title_en": "Information-Theoretic Decentralized Secure Aggregation with Collusion Resilience", "authors": "Xiang Zhang,Zhou Li,Shuangyang Li,Kai Wan,Derrick Wing Kwan Ng,Giuseppe Caire", "background": "在分散式联邦学习中，多个客户端通过交互式交换中间模型更新来共同学习共享的机器学习模型，利用网络中分布的私有数据集进行训练，同时采用加密技术保护聚合过程中的模型更新数据安全。虽然对安全聚合的研究兴趣不断增加，但现有工作主要集中在协议设计和计算保证上，较少从信息论角度理解其基本的安全边界，特别是在缺乏中央聚合器的情况下，通信量和密钥使用量的最优界限仍不清楚。因此，本文从信息论的角度研究了分散式安全聚合问题，提出了具有抗合谋性的分散安全聚合问题，分析了其最优率区域，探讨了安全聚合所需的最小通信量和密钥量。", "innovation": "本文的研究基于分散式联邦学习的背景，创新点在于提出了具抗合谋性的网络中从信息论角度研究分布式安全聚合问题的方法，确定了安全聚合的最优率区域，揭示了在分散式安全聚合过程中实现最小通信量和密钥量所需的条件，为设计安全且通信效率高的协议提供了理论基础。", "conclusion": "本文通过研究分散式安全聚合问题，建立了其在分散式环境中的信息论性能极限，为未来设计证明安全且通信效率高的学习系统协议提供了理论指导。"}
{"llm_update_time": "20251023", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.20779", "html_url": "https://arxiv.org/abs/2506.20779", "title": "ReLU神经网络的稳定极小值遭受维度灾难：神经破碎现象", "title_en": "Stable Minima of ReLU Neural Networks Suffer from the Curse of Dimensionality: The Neural Shattering Phenomenon", "authors": "Tongtong Liang,Dan Qiao,Yu-Xiang Wang,Rahul Parhi", "background": "该研究探讨了多变量输入的两层过参数化ReLU网络中隐偏好的平滑度/低曲率与泛化之间的关系。现有研究要么需要完全拟合，要么只关注一维输入。这项研究提出了在多变量输入情况下的一些新的理论结果，聚焦在由梯度下降训练中的极小值稳定性和边缘稳定性现象所推动的问题上。", "innovation": "该研究证明了在两个自然设置中（1）平滑解的泛化差距和（2）由稳定极小值进行的非参数函数估计中的均方误差（MSE），平坦解能确实促进泛化，但其收敛率会随输入维度增长而指数级恶化。此外，基于新颖的边界局部化ReLU神经元的包装论证构造了最小对数下界，揭示了平坦解如何利用“神经破碎”现象，导致在高维度下的性能较差。这是首次系统性解释平滑极小值在高维度下可能无法泛化的分析。", "conclusion": "研究表明，平坦解与低范解（即权重衰减）在高维情况下的性能表现存在指数级分离，尽管平坦解能促进泛化，但其收敛率在高维情况下会显著下降。此外，该研究通过详细的数值模拟验证了这些理论发现，并提供了全新的神经破碎现象来解释这一现象。"}
{"llm_update_time": "20251023", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.21087", "html_url": "https://arxiv.org/abs/2509.21087", "title": "现代语音增强系统是否易受对抗攻击的影响？", "title_en": "Are Modern Speech Enhancement Systems Vulnerable to Adversarial Attacks?", "authors": "Rostislav Makarov,Lea Schönherr,Timo Gerkmann", "background": "机器学习方法在语音增强方面的应用日益成熟，能够对输入信号进行越来越强大的修改。研究发现，这种强大的表达能力可能带来一个漏洞：先进的语音增强模型容易受到对抗攻击的影响。对抗噪声可以在保持原始输入掩蔽的情况下被精心设计并注入，使得增强后的语音输出具有完全不同的语义含义。", "innovation": "通过实验验证了目前的预测性语音增强模型确实可以被这种方式操控。进一步展示了设计上具有随机采样扩散模型对这种对抗攻击具有固有的鲁棒性。", "conclusion": "现代语音增强系统受到对抗攻击的影响，特别是扩散模型由于其设计原因天然具有抵抗此类攻击的特性。"}
{"llm_update_time": "20251023", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.15568", "html_url": "https://arxiv.org/abs/2508.15568", "title": "无梯度传播的基于概率高斯对齐的测时适配", "title_en": "Backpropagation-Free Test-Time Adaptation via Probabilistic Gaussian Alignment", "authors": "Youjia Zhang,Youngeun Kim,Young-Geun Choi,Hongyeob Kim,Huiling Liu,Sungeun Hong", "background": "测试时适配(TTA)可以通过在推理过程中利用未标记的测试数据来增强零样本鲁棒性，以应对分布偏移。尽管取得了显著进展，但现有方法仍然面临一些挑战，限制了其更广泛的适用性。主要挑战包括方法依赖于反向传播或迭代优化，这影响了可扩展性和实时部署；缺乏显式的类条件特征分布建模，这可能导致不可靠的决策边界和不校准的预测。", "innovation": "该论文提出了一种名为ADAPT的方法，这是一种无梯度传播的测试时适配方法。ADAPT重新定义了TTA为高斯概率推断任务，通过使用逐步更新的类别均值和共享协方差矩阵来建模类条件似然。引入了轻量级的正则化以纠正潜在的似然偏差，并使用CLIP先验和历史知识库进行引导。ADAPT方法不需要源数据、梯度更新或对目标数据的完全访问，支持在线和转化设置。", "conclusion": "广泛的实验证明，ADAPT方法在多种分布偏移基准上实现了最先进的性能，并且具有优越的可扩展性和鲁棒性。"}
{"llm_update_time": "20251023", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.08967", "html_url": "https://arxiv.org/abs/2509.08967", "title": "使用预训练波场神经运算符的物理知情波形反演", "title_en": "Physics-informed waveform inversion using pretrained wavefield neural operators", "authors": "Xinquan Huang,Fu Wang,Tariq Alkhalifah", "background": "全波形反演（FWI）对于构建高分辨率地下模型至关重要，但由于数据有限、结果低分辨率以及计算成本高，特别是对于实时应用时，往往会受到限制。虽然学习的波场神经操作符在提高效率和可微性方面已有了一些成效，但大多存在反演性能多噪且不稳定的问题。", "innovation": "提出了一种新的物理知情FWI框架，旨在提升在保持神经操作符基础FWI效率的同时，提高反演的准确性。该方法通过在损失函数中引入物理约束项，改进了反演后的速度模型的质量。具体而言，该方法从初始模型模拟波场，并评估生成波场的物理一致性（符合波动方程）和与记录数据的匹配程度，这种方法有助于降低噪声和伪影。", "conclusion": "使用该方法在OpenFWI和Overthrust模型的数值实验中，显示该方法在提供更清洁、更准确地下速度方面显著优于传统方法。与传统的FWI方法相比，该方法在效率上是一个重要的进展，在实际应用中为实时地下监测增强了全波形反演的应用前景。"}
{"llm_update_time": "20251023", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.17918", "html_url": "https://arxiv.org/abs/2509.17918", "title": "通过生成侧特征感知的虚假用户资料来欺骗推荐系统", "title_en": "Shilling Recommender Systems by Generating Side-feature-aware Fake User Profiles", "authors": "Yuanrong Wang,Yingpeng Du", "background": "推荐系统（RS）对用户的消费决策有很大影响，使得它们成为恶意刷评攻击的潜在目标，攻击者通过注入假用户资料来操控推荐结果。现有的刷评方法在仅使用评分矩阵作为训练数据的情况下能够生成有效的、不易察觉的假用户资料，但在侧特征也被推荐系统利用的情况下，他们缺乏全面的解决方案。因此，需要一种能够结合侧特征来生成具有侧特征感知能力的虚假用户资料的方法来解决上述问题，从而提高攻击的性能和隐秘性。", "innovation": "本文扩展了Leg-UP框架，增强生成器架构以引入侧特征，实现生成具有侧特征感知能力的虚假用户资料。这种方法在基准测试中的实验结果表明，该方法在保持隐秘性的前提下，能够实现强大的攻击性能。", "conclusion": "通过增强生成器以利用侧特征，提出的生成侧特征感知的虚假用户资料的方法能够有效提高针对推荐系统的刷评攻击的效果与隐秘性。"}
{"llm_update_time": "20251023", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.21664", "html_url": "https://arxiv.org/abs/2508.21664", "title": "通过连续排名概率评分进行集合预报的轨迹学习：Lorenz '96 案例研究", "title_en": "Trajectory learning for ensemble forecasts via the continuous ranked probability score: a Lorenz '96 case study", "authors": "Sagy Ephrati,James Woodfield", "background": "本文通过使用连续排名概率评分（CRPS）作为损失函数，展示了采用轨迹学习方法进行集合预报的可行性。利用两尺度Lorenz '96系统作为案例研究，开发并训练了加性与乘性随机参数化方法，以生成集合预测。研究结果表明，基于CRPS的轨迹学习产生的参数化方法在准确性与锐利度方面表现出色。这些参数化方法易于校准，在短期预报中优于基于梯度拟合的参数化方法。该方法在数据同化应用中特别有前景，因为它在短预测时间段内的准确性很高。", "innovation": "引入了使用连续排名概率评分（CRPS）作为损失函数的方法，来学习轨迹并生成集合预测。该方法开发了加性和乘性随机参数化方法，并验证了这些参数化方法在准确性、锐利度和校准简便性方面优于传统的基于梯度拟合的参数化方法。特别适用于数据同化的应用，因为其在短预测时间段内的准确性很高。", "conclusion": "文章通过两尺度Lorenz '96系统案例研究证明，基于CRPS的轨迹学习可以生成既准确又锐利的参数化方法，这些参数化方法易于校准并且在短期预报中优于基于梯度拟合的方法。这种方法对于数据同化有很高的应用前景。"}
{"llm_update_time": "20251023", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.25271", "html_url": "https://arxiv.org/abs/2509.25271", "title": "RADAR：一种基于角色专业化合作的风险感知动态多代理框架用于大语言模型安全性评估", "title_en": "RADAR: A Risk-Aware Dynamic Multi-Agent Framework for LLM Safety Evaluation via Role-Specialized Collaboration", "authors": "Xiuyuan Chen,Jian Zhao,Yuchen Yuan,Tianle Zhang,Huilin Zhou,Zheng Zhu,Ping Hu,Linghe Kong,Chi Zhang,Weiran Huang,Xuelong Li", "background": "现有的大语言模型（LLMs）的安全性评估方法存在固有的限制，如评估者偏差和由于模型同质性引发的检测失败，这些都削弱了风险评估过程的稳健性。", "innovation": "本文提出了一种名为RADAR的风险感知动态多代理框架，通过角色专业化合作，将其潜在的风险概念空间分解为三个互斥子空间（显式风险子空间、隐式风险子空间和无风险子空间），并利用多轮辩论机制和动态更新机制，实现风险概念分布的自我进化。RADAR在准确性、稳定性和自我评估风险敏感性等多个维度上显著优于基线评估方法。", "conclusion": "RADAR在挑战性测试集和公开基准上的实验表明，它能够全面覆盖显式和隐式风险，同时降低评估者偏差。与最强基线评估方法相比，RADAR在风险识别准确性上提高了28.87%。"}
{"llm_update_time": "20251023", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.21567", "html_url": "https://arxiv.org/abs/2509.21567", "title": "基于EEG的消费者行为预测：从经典机器学习到图神经网络的探索", "title_en": "EEG-Based Consumer Behaviour Prediction: An Exploration from Classical Machine Learning to Graph Neural Networks", "authors": "Mohammad Parsa Afshar,Aryan Azimi", "background": "消费者行为预测对市场营销、认知神经科学和人机交互具有重要意义。脑电图（EEG）数据能够通过提供关于大脑神经活动的详细信息帮助分析决策过程。", "innovation": "研究采用了比较方法来预测消费者行为，通过从NeuMa数据集中提取和清洗EEG数据特征，为图神经网络（GNN）模型创建脑连接性特征。研究对比了不同的机器学习模型，包括经典模型和GNN模型的不同架构，并应用了广泛的经典模型如集成模型。尽管总体结果没有显著差异，但GNN模型在某些基本标准上表现更好，尤其是在经典模型不理想的情况下。该研究不仅展示了结合EEG信号分析和机器学习模型可以提供更深入理解消费者行为的方法，还包括了广泛对比曾广泛用于基于EEG的神经市场营销的经典模型（如支持向量机SVM）和较少使用的模型（如图神经网络）。", "conclusion": "该研究通过对比不同类型的机器学习模型，尤其是在经典模型表现不佳的情况下，展示了图神经网络模型的优势，为基于EEG的消费者行为预测提供了新的思路。"}
{"llm_update_time": "20251023", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.23426", "html_url": "https://arxiv.org/abs/2509.23426", "title": "使用ToolUniverse民主化AI科学家", "title_en": "Democratizing AI scientists using ToolUniverse", "authors": "Shanghua Gao,Richard Zhu,Pengwei Sui,Zhenglun Kong,Sufian Aldogom,Yepeng Huang,Ayush Noori,Reza Shamji,Krishna Parvataneni,Theodoros Tsiligkaridis,Marinka Zitnik", "background": "当前，AI科学家是作为发现合作伙伴的新兴计算系统，然而要实现它们非常困难，因为它们是定制的，通常局限于固定的流程，缺少能够将工具、数据和分析统一到共享环境中的基础设施。在基因组学领域，统一的生态系统极大地转变了研究方式，通过提高平台的一致性、可再利用性以及社区驱动的开发。然而，AI科学家需要类似的基础架构来支持它们的发展。", "innovation": "本文介绍了一个名为ToolUniverse的生态系统，旨在克服限制AI科学家发展的问题。ToolUniverse允许从任何语言或推理模型构建AI科学家，无论是开源还是封闭权重。它标准化了AI科学家与工具的交互方式，提供了超过600种机器学习模型、数据集、API和科学包，支持从数据处理、知识检索到实验设计的数据分析任务。ToolUniverse能够自动生成新工具、优化工具规格，并将它们组合成具有主动性的工作流。", "conclusion": "ToolUniverse在一个高胆固醇症病例研究中被用来开发出一个AI科学家，能够识别出具有有利预测特性的药物同系物。该工具为公众提供了开源接入，展示了其在民主化AI科学家领域的潜力。"}
{"llm_update_time": "20251023", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.25486", "html_url": "https://arxiv.org/abs/2509.25486", "title": "大规模材料平衡采样的可扩展玻尔兹曼生成器", "title_en": "Scalable Boltzmann Generators for equilibrium sampling of large-scale materials", "authors": "Maximilian Schebek,Frank Noé,Jutta Rogal", "background": "使用生成模型来采样多体系统的平衡分布，如博尔兹曼生成器首次展示的那样，由于其能够在‘一次采样’中生成无偏且无相关样本的能力，吸引了大量关注。尽管这些模型在自然科学领域展现出了巨大潜力并取得了令人印象深刻的成果，但将其扩展到大型系统仍是主要挑战。", "innovation": "本文提出了一种博尔兹曼生成器架构，专注于材料科学应用。利用增强连接流与图神经网络结合，使生成过程基于局部环境信息，同时支持能量训练和快速推理。相比之前架构，本模型训练速度快得多，所需的计算资源少得多，并具有更优的采样效率。架构还可以应用于更大系统的尺寸，这使得高效模拟具有前所未有的大仿真单元的材料成为可能。", "conclusion": "通过将我们的方法应用于多个材料系统（包括Lennard-Jones晶体、mW水的各种冰相状态和硅的相图），对数以千计原子的大系统规模，我们展示了训练的博尔兹曼生成器能产生各种晶体结构的高精度平衡分布，以及在不同系统规模下的赫尔姆霍兹和吉布斯自由能，这些扩大了系统的规模，使得有限尺寸效应变得不那么重要。"}
{"llm_update_time": "20251023", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.02738", "html_url": "https://arxiv.org/abs/2510.02738", "title": "随力场流动：从力和演示引导的模拟数据学习3D可变形流动匹配策略", "title_en": "Flow with the Force Field: Learning 3D Compliant Flow Matching Policies from Force and Demonstration-Guided Simulation Data", "authors": "Tianyu Li,Yihan Li,Zizhe Zhang,Nadia Figueroa", "background": "尽管近年来视觉运动策略取得了一些进步，但具有高接触需求的任务仍具挑战性。需要连续接触的机器人操作任务需要明确处理顺应性和力。然而，大多数视觉运动策略忽略了顺应性，忽视了与现实世界物理交互的重要性，通常会导致在不确定性下产生过高的接触力或脆弱的行为。将力信息引入基于视觉的模仿学习可以帮助提高对接触的意识，但也可能需要大量的数据才能表现良好。数据稀缺的一个解决方案是通过模拟生成数据，但生成足够质量的数据需要耗费大量计算资源，以免遭受仿真实现差距的影响。", "innovation": "本文提出了一种生成力告知的模拟数据框架，通过单一的人类演示实例化，并展示了如何结合弹性策略提高仅从合成数据学习的视觉运动策略的性能。该方法已在现实机器人任务中得到验证，包括非工具块翻转和双臂物体移动，所学策略显示了可靠接触维持和对新条件的适应能力。", "conclusion": "我们的方法通过证明人工演示和力控制可以改善模拟数据生成的有效性，为从合成数据学习视觉运动策略的现实任务性能做出了贡献。所提出的框架在复杂的机器人操作任务中取得了稳健的结果，展示了可变形流动匹配策略的重要性。"}
{"llm_update_time": "20251023", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.11474", "html_url": "https://arxiv.org/abs/2510.11474", "title": "通过层次多智能体强化学习实现现实空中格斗中的协调策略", "title_en": "Coordinated Strategies in Realistic Air Combat by Hierarchical Multi-Agent Reinforcement Learning", "authors": "Ardian Selmonaj,Giacomo Del Rio,Adrian Schneider,Alessandro Antonucci", "background": "在现实的空中格斗模拟中，完善的态势感知和非线性飞行动力学使达成任务目标极具挑战性。", "innovation": "文章提出了一种新颖的3D多智能体空中格斗环境和层次多智能体强化学习框架，结合了异质智能体动力学、课程学习、联赛玩法和一种新的训练算法，实现了决策层次化，低层策略负责精确的控制动作，高层策略根据任务目标发布战术命令。", "conclusion": "实证结果表明，层次化的方法在复杂的空中格斗场景中提高了学习效率和战斗性能。"}
{"llm_update_time": "20251023", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.12829", "html_url": "https://arxiv.org/abs/2510.12829", "title": "使用大型语言模型作为证明者和验证者的数学", "title_en": "Mathematics with large language models as provers and verifiers", "authors": "Hieu Le Duc,Leo Liberti", "background": "自2024年和2025年开始，有关大规模语言模型的定理证明能力的讨论引起了人们的兴趣。这些讨论主要集中在语言模型解决国际数学奥林匹克竞赛难题以及其他为验证人工智能是否能够证明的猜想上的成功案例。这些结果显示了语言模型在复杂数学问题上的潜力。", "innovation": "本文报道了一项通过gpt-5模型的不同证明者和验证者实例协作来实现的定理证明壮举。为了确保产生的证明不会出现幻觉，最终的证明经过了Lean证明助手的正式验证，并且验证者的前提和结论与Lean代码的一致性也是由人类手动验证。尽管该方法尚不完善，但还是能够解决2025年国际数学奥林匹克竞赛的五道题中的六题，并接近解决六十六个数论猜想中的三分之一。", "conclusion": "本研究方法并非完美且绝对准确，但已经对语言模型在解决复杂数学问题中的潜力进行了初步的探索，并且展示了人工验证在增强模型证明的可靠性和准确性方面的重要性。"}
{"llm_update_time": "20251023", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.03502", "html_url": "https://arxiv.org/abs/2510.03502", "title": "ALHD：阿拉伯语LLM生成文本检测的大规模多体裁基准数据集", "title_en": "ALHD: A Large-Scale and Multigenre Benchmark Dataset for Arabic LLM-Generated Text Detection", "authors": "Ali Khairallah,Arkaitz Zubiaga", "background": "近年来，大规模语言模型（LLM）在生成文本方面的能力得到了显著提高，这引发了对这些模型生成的文本与真实人类生成的文本区别的关注。ALHD作为一个全新的大规模阿拉伯语数据集，旨在解决这一问题，它涵盖了新闻、社交媒体和评论三种体裁，并且包含了超过40万样本，这些样本由三种主要的LLM和多种人类来源生成，为研究阿拉伯语LLM生成文本检测的一般性提供了可能。", "innovation": "ALHD是首个专为区分人类生成和LLM生成文本设计的大规模综合阿拉伯语数据集。它包含了多样的体裁和语言变体，如正规阿拉伯语（MSA）和方言阿拉伯语，以及从多个来源生成的大量样本。此外，该数据集提供了详细的预处理、丰富的注释和标准化的平衡划分，确保研究的可重复性。通过标准化的数据集，研究者可以进行基准测试，评估不同模型在阿拉伯语LLM生成文本检测任务中的性能。", "conclusion": "ALHD在传统分类器、BERT模型和LLM模型（零样本和少量样本）的基准测试中展示了与微调BERT模型的竞争性表现，尤其是在特定体裁如新闻文章中的挑战性检测上。模型在多体裁跨场景应用中面临着不一致的表现挑战，尤其是在新闻文章中，LLM生成的文本在风格上难以区分，这为未来研究提供了新的方向。ALHD为此领域提供了坚实的基础，促进了对阿拉伯语LLM检测、信息误导、学术不诚实和网络威胁风险减轻的研究。"}
{"llm_update_time": "20251023", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.14176", "html_url": "https://arxiv.org/abs/2510.14176", "title": "ARM-FM: 通过基础模型自动化的组合强化学习奖励机器", "title_en": "ARM-FM: Automated Reward Machines via Foundation Models for Compositional Reinforcement Learning", "authors": "Roger Creus Castanyer,Faisal Mohamed,Pablo Samuel Castro,Cyrus Neary,Glen Berseth", "background": "强化学习（RL）算法对奖励函数的定义非常敏感，这一直是限制其广泛应用的核心挑战。奖励机器（RMs）作为一种基于自动机的奖励规范形式主义，在RL目标定义中发挥着机制作用。虽然RMs提供了有效的任务分解，但传统的奖励设计仍然依赖于手动指定，这需要大量的专业知识和精确性。现有的方法主要有两种不足：一是需要高度专业的知识进行手工设计；二是缺乏自动化的工具来直接从自然语言规范中生成RL奖励函数。因此，构建一种自动化的、基于基础模型的奖励设计框架成为了一个重要问题。", "innovation": "本研究提出了ARM-FM（Automated Reward Machines via Foundation Models）框架，利用基础模型（FMs）的高阶推理能力实现RL中奖励设计的自动化和组合方式。具体来说，ARM-FM（i）利用基础模型自动从自然语言规范中生成RMs；（ii）将语言嵌入与每个RM自动机状态关联，以实现跨任务的泛化；（iii）提供了在一系列具有挑战性的环境中ARM-FM的有效性证据，包括零样本泛化的证据。这项工作通过结合基础模型的文本理解和自动生成能力，为解决RL领域面临的关键挑战提供了一个创新的解决方案。", "conclusion": "本研究提出了ARM-FM框架，将基础模型的高阶推理能力应用于RL中的奖励设计。通过从自然语言规范中自动生成RMs，并实现跨任务的泛化能力，ARM-FM不仅提高了奖励定义的便捷性和准确性，还展示了在多种复杂环境中的良好性能，特别是零样本泛化的能力。这标志着在自动化和组合基于奖励的RL设计方向上取得了重要进展。"}
{"llm_update_time": "20251023", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.17111", "html_url": "https://arxiv.org/abs/2510.17111", "title": "高效视觉-语言-行动模型在实体操控中的系统性综述", "title_en": "Efficient Vision-Language-Action Models for Embodied Manipulation: A Systematic Survey", "authors": "Weifan Guan,Qinghao Hu,Aosheng Li,Jian Cheng", "background": "VLA模型通过将自然语言指令和视觉观察映射到机器人动作，将视觉-语言模型扩展到体内控制。尽管具有强大的能力，但VLA系统面临着巨大的计算和内存需求挑战，这与边缘平台如车载移动机械臂所需的实时性能相冲突。近年来，研究重点集中在解决这一矛盾上，提高VLA系统的效率，减少延迟、内存占用以及训练和推理成本。", "innovation": "本文对提高VLA效率的方法进行了系统性回顾，主要集中在减少延迟、内存占用和训练、推理成本。分类方法包括模型架构、感知特征、动作生成和训练/推理策略，总结了每类代表性技术，并展望了未来趋势和开放挑战，为推进高效体态智能提供了方向。", "conclusion": "文章最后讨论了未来趋势和开放挑战，强调了推进高效体态智能的方向。"}
{"llm_update_time": "20251023", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.15020", "html_url": "https://arxiv.org/abs/2510.15020", "title": "覆盖原理：预训练如何使后训练受益", "title_en": "The Coverage Principle: How Pre-Training Enables Post-Training", "authors": "Fan Chen,Audrey Huang,Noah Golowich,Sadhika Malladi,Adam Block,Jordan T. Ash,Akshay Krishnamurthy,Dylan J. Foster", "background": "语言模型在通过大规模文本语料库预训练并在特定任务上微调后，展示了惊人的能力，但这些模型最终成功的原因和机制仍然知之甚少。通常，预训练的成功通过交叉熵损失来衡量，但交叉熵不是预测下游性能的良好指标。因此，本文提供了在“覆盖”视角下的理论解释，覆盖度衡量预训练模型在高质量响应上的概率质量，对于后训练和测试时通过Best-of-N等方法优化具有必要的和充分的条件。", "innovation": "本文发展的理解“覆盖原理”，该原理揭示了下一个词预测（更普遍地说，最大似然）如何显式地优化具有良好覆盖度的模型。具体而言，研究表明覆盖度比交叉熵更好地泛化，避免了对问题特定参数（如序列长度）的虚假依赖。此外，本文还提出了可以证明能提高覆盖度的实用算法干预措施，包括模型/检查点选择过程、梯度规范化方案和测试时解码策略。", "conclusion": "本文通过分析覆盖度在预训练模型中的重要性，揭示了预训练和后训练之间的原理，提出了一种能够更有效提高模型性能的机制，并为提高预训练和后训练的模型性能提供了新的思路和方法。"}
{"llm_update_time": "20251023", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.15530", "html_url": "https://arxiv.org/abs/2510.15530", "title": "VO-DP: 单视图语义-几何自适应扩散策略", "title_en": "VO-DP: Semantic-Geometric Adaptive Diffusion Policy for Vision-Only Robotic Manipulation", "authors": "Zehao Ni,Yonghao He,Lingfeng Qian,Jilei Mao,Fa Fu,Wei Sui,Hu Su,Junran Peng,Zhipeng Wang,Bin He", "background": "在模仿学习领域中，基于视知觉的动作扩散策略学习是机器人操作的主要方向之一。现有的大多数方法依赖于点云作为观测输入，并通过点云特征学习构建场景表示，从而实现了显著的准确率。然而，现有的文献鲜少深挖仅基于视觉的解决方案，而后者具有巨大的潜力。", "innovation": "本文提出了一种名为VO-DP的方法，该方法利用预训练的视觉基础模型实现语义和几何特征的有效融合。通过结合VGGT的中间特征、DINOv2的语义特征和Alternating Attention块的几何特征，并通过交叉注意力和CNN进行空间压缩，形成策略头部的输入。实验表明，VO-DP不仅在视觉基准的DP上表现显著优越，而且在基于点云的方法DP3上还表现出独特的性能趋势，在仿真任务中平均成功率达到64.6%，高于DP的34.8%且接近DP3的64.0%。在真实世界任务中，该方法的成功率达到87.9%，远远超过了DP3的67.5%和DP的11.2%。此外，进一步的鲁棒性测试表明该方法在颜色、大小、背景和照明变化下仍能保持高稳定性。", "conclusion": "最后，该论文开放了一个用于机器人操作的训练库，该库基于Accelerate构建，支持多机器和多GPU并行训练以及混合精度训练，兼容诸如DP、DP3和VO-DP等视知觉策略，并支持RoboTwin模拟器。"}
{"llm_update_time": "20251023", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.17734", "html_url": "https://arxiv.org/abs/2510.17734", "title": "高效振荡算子的张量填充算法", "title_en": "Efficient Tensor Completion Algorithms for Highly Oscillatory Operators", "authors": "Navjot Singh,Edgar Solomonik,Xiaoye Sherry Li,Yang Liu", "background": "本文提出了低复杂度的张量填充算法及其高效的实现方法，用于重构以$n\times n$矩阵离散化的强烈振荡运算符。张量分解的基础是将输入矩阵重新整形，并将其蝴蝶分解表示为顺序为$O (\text{log } n)$的张量。将输入矩阵重新整形为张量，使蝴蝶分解可以表示为张量分解，其中采用密集张量。这种表示使得能够高效利用现有的密集和稀疏张量计算软件基础设施。\n", "innovation": "提出了一种蝴蝶格式下的两种张量填充算法，分别使用交替最小二乘法和基于梯度的最优化方法。同时提出了一种新颖策略，利用低秩矩阵完成来高效生成所提议算法的初始猜测。\n", "conclusion": "通过应用三个数值实验验证提议算法的效率和适用性，实验使用输入矩阵中的$O (n \text{log } n)$观察条目，并展示了所提议算法的$O(n \text{log}^3 n)$计算成本，对比低秩矩阵和量子张量火车完成，大型矩阵每迭代次数速度提高若干个数量级。使用新的初始猜测生成策略的提议的蝴蝶完成算法，重建误差相比最先进算法小一个数量级，实现了更准确的结构恢复。"}
{"llm_update_time": "20251023", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.16551", "html_url": "https://arxiv.org/abs/2510.16551", "title": "基于LLM的方法从评论中提取属性和特征以获得可行动见解", "title_en": "From Reviews to Actionable Insights: An LLM-Based Approach for Attribute and Feature Extraction", "authors": "Khaled Boughanmi,Kamel Jedidi,Nour Jedidi", "background": "该研究基于营销理论，提出了一种系统的方法来从客户评论中提取产品和服务的属性、功能及相关的情感。该方法使用大规模语言模型（LLM），可以区分感知属性和可操作特性，从而产生可解释和管理者可采取行动的洞见。研究团队应用了这种方法论对20,000条来自Starbucks门店的Yelp评论进行分析，并通过与人类标注者的协议和预测消费者评分的能力对该方法进行评估。", "innovation": "该创新之处在于采用大规模语言模型（LLM）方法系统地从客户评论中提取产品和服务的属性、功能以及相关的情感。这种方法能够区分感知属性和可操作特性，产生易于管理者理解并能采取行动的洞察。通过大规模数据样本的应用展示了比人工编码快得多的处理速度，同时保持了与人类编码的高一致性和良好的预测有效性。", "conclusion": "研究结果显示，大规模语言模型与人类编码者在一致性上有很高的相似度，且在预测消费者评分方面表现出很强的预测有效性，这证实了这种方法的可靠性。此外，这种方法能够识别出对客户满意度影响最大的属性和功能及其相关的情感，帮助企业找到“愉悦点”、解决“痛点”并设计针对性的干预措施。该方法还可用于监控服务功能的情感变化，为管理层提供洞察能力并指出改进的关键特征。通过提高关键服务功能的情感评分，模拟结果显示能够在每个门店获得1-2%的平均收入增长。"}
{"llm_update_time": "20251023", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.17947", "html_url": "https://arxiv.org/abs/2510.17947", "title": "PLAGUE：长期自适应生成多轮攻击的插件式框架", "title_en": "PLAGUE: Plug-and-play framework for Lifelong Adaptive Generation of Multi-turn Exploits", "authors": "Neeladri Bhuiya,Madhav Aggarwal,Diptanshu Purwar", "background": "随着大型语言模型（LLMs）的快速发展，多轮对话模式已经成为了与LLMs交互的主要方式，尤其是在执行长时间和复杂任务时。然而，随着LLM能力的提升，它们在多轮对话场景中越来越容易受到劫持，这使得有害意图可以在对话中被隐秘注入，导致不道德的结果。尽管单轮攻击已经得到了广泛研究，但适应性、效率和有效性仍然是其多轮版本的关键挑战。", "innovation": "本文提出了PLAGUE，这是一种受到终身学习代理启发的多轮攻击设计的插件式框架。PLAGUE将多轮攻击的生命期分解为三个精心设计的阶段（准备阶段、规划阶段和完成阶段），以实现系统且信息丰富的多轮攻击探索。实验表明，使用PLAGUE设计的红队代理在主要模型上取得了最先进的劫持结果，攻击成功率提高了30%以上，特别是在较少或相等的查询预算下。尤其值得一提的是，基于StrongReject，PLAGUE分别实现81.4%和67.3%的成功率（针对OpenAI的o3和Claude的Opus 4.1），这两个模型被认为是安全文献中抗劫持性能较好的。", "conclusion": "我们的工作提供了工具和见解，以理解在制作多轮攻击以全面评估模型漏洞时计划初始化、上下文优化和终身学习的重要性。"}
{"llm_update_time": "20251023", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2510.18895", "html_url": "https://arxiv.org/abs/2510.18895", "title": "CosmoCore 感情回放增强学习及其在代码生成中的应用", "title_en": "CosmoCore Affective Dream-Replay Reinforcement Learning for Code Generation", "authors": "Santhosh Kumar Ravindran", "background": "当前的大语言模型（LLMs）在代码生成方面面临挑战，包括生成虚构代码（如语法错误或逻辑错误）和自我纠正能力不足的问题。在此背景下，该论文提出了CosmoCore，一种受到神经科学启发的强化学习（RL）架构，旨在通过整合情感信号来增强代码生成能力。灵感来源于人类和动物学习中的情感反应机制，例如在训狗时，一次责备就能促使狗不再重复错误，该架构使用轻量级的多层感知器（MLP）对代码生成轨迹进行注释，标记其情感价值和惊奇度以提高模型的自我纠正能力，并减少虚构代码的生成。", "innovation": "该研究的创新点在于提出了CosmoCore，一种结合情感信号的神经科学启发的强化学习架构。该架构通过在代码生成过程中标记情感价值和惊奇度，优先处理高负面价值（如代码错误）的事件，并通过对低惊奇度的成功案例进行修剪来防止过自信和内存膨胀。这种方法在代码生成基准测试（如HumanEval和BigCodeBench）和自定义数据流水线环境中得到了验证，显示了显著的改善效果。此外，研究还通过消融实验证明了情感标记提高了探索中的好奇心，修剪处理减少了低效性。该框架扩展了从人类反馈的强化学习（RLHF），为更具有情感意识的代码助手提供潜在的应用场景，如IDE和数据管道中。", "conclusion": "通过CosmoCore增强学习框架，研究成功地降低了大语言模型在代码生成时错误代码的比例，加速了模型的自我纠正速度，验证了该架构的有效性。研究还通过开源代码和自定义的小型世界模拟，为其他研究者提供了重复实验的机会，并指出未来的研究方向可能包括在更广泛的场景中应用该框架，以及探索更多的情感信号类型。"}
{"llm_update_time": "20251023", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2510.19089", "html_url": "https://arxiv.org/abs/2510.19089", "title": "基于 Docker 的 CI/CD 方案以支持 Rocq/OCaml 项目", "title_en": "Docker-based CI/CD for Rocq/OCaml projects", "authors": "Érik Martin-Dorel", "background": "本文档介绍了三个紧密相关的软件项目：docker-coq, docker-coq-action, 和 docker-keeper。其目标是为了提高使用 Docker 基础的持续集成/持续部署（CI/CD）方案在 Rocq（原 Coq）或 OCaml 项目中的利用情况，并记录这些 DevOps 工具的基础需求以及主要设计选择，为它们未来的维护者提供帮助。", "innovation": "提供了一种基于 Docker 的 CI/CD 方案，可以支持 Rocq 和 OCaml 项目。同时，还详细描述了这些工具的基础需求和核心设计选择，有助于未来的维护工作。", "conclusion": "本文档不仅提供了 Rocq 和 OCaml 项目的 CI/CD 方案的高级描述，还详细记录了实现这些方案所必需考虑的基础需求和关键设计决定，为未来的维护者提供了有用的信息。"}
{"llm_update_time": "20251023", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.18193", "html_url": "https://arxiv.org/abs/2510.18193", "title": "FST.ai 2.0: 一个用于奥林匹克和残疾人跆拳道公平、快速和包容性决策的可解释AI生态系统", "title_en": "FST.ai 2.0: An Explainable AI Ecosystem for Fair, Fast, and Inclusive Decision-Making in Olympic and Paralympic Taekwondo", "authors": "Keivan Shariatmadar,Ahmad Osman,Ramin Ray,Kisam Kim", "background": "在竞技和残奥跆拳道比赛中，公平、透明和可解释的决策制定仍然是一个关键挑战。现有的自动化评分系统虽然提高了效率，但在增强透明度、理解和接受方面仍有不足。FST.ai 2.0旨在通过集成基于姿态的动作识别、先验不确定性的建模和可解释叠加图，为裁判、教练和运动员提供实时决策支持，从而解决这一问题。", "innovation": "FST.ai 2.0是一个可解释的AI生态系统，通过以下创新实现公平、快速和包容性的决策：1) 使用图卷积网络（GCNs）进行基于姿态的动作识别；2) 通过信念集建模先验不确定性；3) 为视觉决策提供可解释的叠加图；4) 提供交互式仪表板促进人类与AI的合作；5) 拓展到包括裁判培训、公平监控和政策级分析的模块，以此嵌入到世界跆拳道的生态系统中。实验验证显示，该系统在决审时间上减少了85%，裁判在AI辅助决策中的信任度达到了93%。", "conclusion": "FST.ai 2.0通过实时感知、可解释推理和治理感知设计，建立了透明且可扩展的决策管道，从而确保公平、负责任且与人一致的AI在体育赛事中的应用。"}
{"llm_update_time": "20251023", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2510.19035", "html_url": "https://arxiv.org/abs/2510.19035", "title": "使用基于系统工程和异功能图理论扩展资源约束项目调度以适用于大型项目", "title_en": "Extending Resource Constrained Project Scheduling to Mega-Projects with Model-Based Systems Engineering & Hetero-functional Graph Theory", "authors": "Amirreza Hosseini,Amro M. Farid", "background": "在项目管理的背景下，项目计划是不可或缺的组成部分，作为规划、监控、控制和管理项目的手段。尽管资源约束项目调度问题（RCPSP）是项目管理活动的核心之一，但在更广泛的基于模型系统工程（MBSE）文献中却鲜有讨论，这限制了其在复杂系统的设计和管理中的应用。", "innovation": "本文的主要创新有两个方面。首先，作者将RCPSP与更广泛的MBSE文献和异功能图理论（HFGT）进行整合。构建了一个从活动节点网络到SysML活动图，再到算子网的具体转换体系，将异功能网络最小成本流（HFNMCF）模型在RCPSP背景下进行具体化，证明RCPSP是该更大模型的特殊情况之一。其次，在示例中，通过利用特定的HFNMCF，能够在提供相似的项目计划的同时，提供明确的项目状态解析，有助于更丰富地进行监控和控制，同时保留经典RCPSP的优点并适应现实世界的约束和企业级决策过程。", "conclusion": "框架在保持经典RCPSP优势的同时，集成了真实世界中的约束和大型复杂项目的组织决策过程，能够为项目的状态提供明确解释，有助于进行更高效的监控和控制。"}
{"llm_update_time": "20251023", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2510.19254", "html_url": "https://arxiv.org/abs/2510.19254", "title": "TRACE: 针对访问控制漏洞保护智能合约存储库", "title_en": "Trace: Securing Smart Contract Repository Against Access Control Vulnerability", "authors": "Chong Chen,Jiachi Chen,Lingfeng Bao,David Lo,Yanlin Wang,Zhenyu Shan,Ting Chen,Guangqiang Yin,Jianxing Yu,Zibin Zheng", "background": "智能合约中的不当访问控制漏洞导致了数十亿美元的损失。GitHub托管了大量的智能合约存储库，包含源代码、文档和配置文件等开发中间件。第三方开发者频繁参考、重用或重构这些代码，但若引用的代码存在漏洞，则会引入重大安全风险。现有的智能合约漏洞检测工具在处理复杂存储库时能力有限，通常需要目标合约可编译以便生成抽象表示进行进一步分析。", "innovation": "本文提出了一款名为TRACE的工具，旨在保护非可编译的智能合约存储库免受访问控制漏洞的威胁。TRACE使用LLMs定位合约中的敏感函数（包含关键操作的函数），并通过补充函数片段构建一个可编译的合约。通过抽象语法树（AST）重构合约函数调用图，并利用每个函数的控制流图（CFG）节点信息进行敏感函数分析，检测访问控制漏洞。实验结果表明，TRACE在开源CVE数据集上优于现有最佳工具，且在5000个最近的链上合约中实现了89.2%的精确度，远超现有最佳工具76.9%的精确度，在83个实际项目仓库中达到了87.0%的精确度，远超DeepSeek-R1的14.3%。", "conclusion": "本文提出的TRACE工具在检测智能合约的访问控制漏洞方面表现优异，特别是在非可编译合约存储库中，其检测准确度显著优于现有工具。"}
{"llm_update_time": "20251023", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2510.19274", "html_url": "https://arxiv.org/abs/2510.19274", "title": "从规范到服务：使用多代理系统加速API优先开发", "title_en": "From Specification to Service: Accelerating API-First Development Using Multi-Agent Systems", "authors": "Saurabh Chauhan,Zeeshan Rasheed,Malik Abdul Sami,Kai-Kristian Kemell,Muhammad Waseem,Zheying Zhang,Jussi Rasku,Mika Saari,Pekka Abrahamsson", "background": "该论文描述了一个系统，该系统基于大型语言模型（LLMs）代理来自动化RESTful微服务的API优先开发。传统的API开发流程往往较为复杂且耗时，需要开发者反复迭代，通过调用API来测试和修正。本研究旨在通过自动化的手段提高API优先开发的效率，并检验基于LLM的多代理系统在支持API优先开发方法中的能力。为此，研究者使用了PRAB基准测试进行了评估。研究结果表明，在保持OpenAPI规范简单且专注的情况下，LLMs能够生成符合规范的、包含业务逻辑的完整功能代码。", "innovation": "该系统的创新点在于利用LLMs基于智能代理的自动开发系统能够从OpenAPI规范生成完整功能的代码，并通过执行日志分析持续改进代码质量。这显著减少了开发过程中的迭代次数，提高了开发效率和代码的健壮性，为API优先开发提供了一种新的自动化工具。", "conclusion": "该研究证明了通过LLM多代理系统可以在API优先开发过程中实现高效和自动化的服务生成。结果表明，在规范保持简洁的同时，LLMs能够生成具有适当业务逻辑的完整功能代码。研究者还公开了系统的代码，为进一步研究和实际应用提供了支持。"}
{"llm_update_time": "20251023", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2510.19237", "html_url": "https://arxiv.org/abs/2510.19237", "title": "从文本需求中自动化提取赛博物理系统的关注点：多解决方案研究", "title_en": "Automated Concern Extraction from Textual Requirements of Cyber-Physical Systems: A Multi-solution Study", "authors": "Dongming Jin,Zhi Jin,Xiaohong Chen,Zheng Fang,Linyu Li,Shengxin Zhao,Chuihui Wang,Hongbin Xiao", "background": "赛博物理系统（CPSs）将信息空间与物理世界深度融合，这使得需求提取要求更为复杂。虽然已经提出了一些自动化解决方案来减轻需求工程师的负担，但这些解决方案的有效性评价仍然依赖于公平和全面的基准测试。为了应对这一差距，本文提出了一种新的CPSs需求提取基准——ReqEBench，包含来自12个实际CPS项目的2,721个需求。ReqEBench在多个维度上与实际CPS需求保持一致，涵盖了CPS需求的全面关注点，并经过了严格的注释过程。此外，它还覆盖了多个CPS应用场景，如航空航天和医疗保健。利用我们的ReqEBench，进行了三种自动化需求提取方案的比较研究，揭示了它们在实际CPS中的表现，发现在实体需求提取方面GPT-4的F1分数仅为0.24。进一步分析了流行的大规模语言模型（LLM）基线解决方案的失败案例，总结了它们的不足，并提出了改进其能力的想法。", "innovation": "提出了一种新的CPSs需求提取基准——ReqEBench，涵盖了2,721个来自实际CPS项目的高质量数据，同时该基准具有多个重要优点：多维度与实际需求保持一致、全面涵盖CPS需求关注点、经过严格注释过程、覆盖多个CPS应用领域。此外，通过基准使用了三种自动化需求提取方案进行了比较研究，揭示了它们在真实CPS环境中的性能表现，特别是对于实体提取方面的不足进行了深入分析并提出了改进建议。", "conclusion": "相信通过引入ReqEBench，可以促进自动化需求提取的评估与开发，提高该领域的研究水平和实际应用效果。"}
{"llm_update_time": "20251023", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.07364", "html_url": "https://arxiv.org/abs/2510.07364", "title": "基模型知道如何推理，思考模型学习何时推理", "title_en": "Base Models Know How to Reason, Thinking Models Learn When", "authors": "Constantin Venhoff,Iván Arcuschin,Philip Torr,Arthur Conmy,Neel Nanda", "background": "尽管思考型语言模型在性能上不断取得进步，但仍不清楚它们是学习全新的推理能力还是重新利用基模型已经存在的能力。本文通过提出一种混合模型，在恰当时机激活基模型中的推理机制，以引发思考型模型级别的推理链，从而探明思考型模型利用了基模型中已有的能力。此外，本文介绍了一种基于未监督、自底向上的方法，用于揭示思考型模型中的可解读推理行为，这种方法可以客观地发现推理行为而不需要预先的假设。在三种基模型和四种思考型模型上，使用GSM8K和MATH500数据集，通过仅改变12%的词汇量而恢复了高达91%的性能差距，证明了基模型本身就具备推理能力，而思考型模型则学习如何在特定情况下应用这些能力。先前认为的训练方式是模型主要在预训练阶段学习推理机制，在此之后则是教会模型在恰当的时间高效运用这些机制，从而有效地利用推理时的计算资源。", "innovation": "本文提出了一种混合模型，该模型在适当的时间激活基模型的推理能力来模仿思考型模型的推理链，证实了思考型模型与基模型具备类似的有效推理能力，但思考型模型能够学会高效运用这些机制。此外，研究引入了一种无需预先假设的、自底向上的方法，用于在思考型模型中揭示可理解的推理行为。这为研究思考型模型如何取得更好性能提供了新视角，相较于过去的假设，明确了思考型模型学习推理的时间点而非起始点这一新机制。", "conclusion": "本文的研究结果重新定义了思考型模型的训练方式：模型的主要推理机制是在预训练阶段获得的，而后的训练阶段则负责教会模型如何在合适的时机高效利用这些机制，从而可以更有效地利用推理阶段的计算资源。通过这种方式，思考型模型能够克服基模型的一部分性能差距，仅需微小的额外词汇量投入。"}
{"llm_update_time": "20251023", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2510.19240", "html_url": "https://arxiv.org/abs/2510.19240", "title": "在嵌入式Linux开发中实施CI/CD的一般解决方案", "title_en": "A General Solution for the Implementation of CI/CD in Embedded Linux Development", "authors": "Behnam Agahi,Hamed Farbeh", "background": "随着嵌入式系统在各个行业的广泛应用，自动化开发和部署定制化Linux操作系统平台的需求日益重要。研究旨在设计并实现一个集成且可重复的基础设施，用于开发、构建和测试基于Yocto项目的Linux操作系统。该基础设施采用了三层架构，保证了版本同步、扩展性和可重复性。三个示例项目libhelloworld、helloworld和kernel module hello mod被开发并集成到构建流程中，持续集成与持续部署（CI/CD）管道采用GitLab CI实现，并结合独立的Docker环境自动化和简化构建与测试流程。本地缓存服务器集合了hashserv，下载和sstate缓存显著缩短了构建时间。通过在QEMU模拟器执行的六项启动测试场景验证了系统的功能性和稳定性。研究表明，该设计不仅保障了可重复性，而且可以扩展到实时Linux版本的持续部署等高级应用。未来建议包括扩大自动化测试、使用系统监控（Prometheus和Grafana）、采用分布式构建、优化Docker多阶段构建，并实现实时Linux变化的持续部署。这将为嵌入式系统的工业和研究项目提供一种稳定的可扩展模型，具备快速可靠的开发周期。", "innovation": "研究设计并实现了一个基于Yocto项目的集成且可重复的开发、构建和测试基础设施，通过层次化的三层架构来确保版本同步、扩展性和可重复性；运用了持续集成与持续部署（CI/CD）管道和独立的Docker环境来自动化工作流程；通过本地缓存服务器显著降低了构建时间；使用QEMU进行了六项启动测试场景验证了系统的功能性和稳定性。未来研究建议包括扩大自动化测试，使用系统监控（Prometheus和Grafana），采用分布式构建，优化Docker多阶段构建，以及实现实时Linux变化的持续部署，以提供一种稳定、可扩展的嵌入式Linux开发模型。", "conclusion": "研究展示了一种适用于嵌入式Linux开发的CI/CD解决方案，不仅确保了系统的可重复性，还扩展到了实现实时Linux版本的持续部署。未来建议还包括进一步优化自动化测试、监控、构建技术和部署机制，以提高系统的稳定性和扩展性。"}
{"llm_update_time": "20251023", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2510.19281", "html_url": "https://arxiv.org/abs/2510.19281", "title": "通过性能指标研究位运算符的直观性", "title_en": "An Empirical Study of Bitwise Operators Intuitiveness through Performance Metrics", "authors": "Shubham Joshi", "background": "本研究旨在探讨编程中位运算符的可读性和理解性，重点关注不同的位运算符在响应时间和错误率方面的表现差异。参与者包括无编程背景的人、初学者程序员以及不同编程经验的大学生（从大一开始至博士生）。研究使用全被试实验设计，评估不同编程背景的人理解并使用位运算符的情况。研究发现，某些位运算符（如OR、NOT、左移）在任务完成时间上显示出统计学上的显著性差异。虽然位运算符的复杂性通常不会导致更长的任务完成时间，但某些运算符的直观性较差，需要进一步研究，并可能需要重新设计以提高理解性。", "innovation": "本研究采用了全被试实验设计，并重点关注了不同背景的参与者对位运算符的理解，利用任务完成时间和准确率的变化，通过性能指标来评估位运算符的直观性。发现某些位运算符在任务完成时间上显示出了显著差异，这为编程教育和工具设计提供了新的视角。", "conclusion": "虽然位运算符的复杂性通常不会导致更长的任务完成时间，但在任务完成时间上仍然可以观察到一些位运算符（如OR、NOT、左移）的差异性。这表明某些位运算符的直观性较差，可能需要进一步研究和潜在的设计改进，以提高其理解性。"}
{"llm_update_time": "20251023", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2510.18923", "html_url": "https://arxiv.org/abs/2510.18923", "title": "自动编程评估系统中反馈类型的一项调查", "title_en": "A Survey on Feedback Types in Automated Programming Assessment Systems", "authors": "Eduard Frankford,Tobias Antensteiner,Michael Vierhauser,Clemens Sauerwein,Vivien Wallner,Iris Groher,Reinhold Plösch,Ruth Breu", "background": "随着各行各业数字化进程的加快，学习编程技能的需求增加，导致大学在各种课程中，包括技术、商业和管理领域，普遍引入了编程课程。因此，教学、评分和辅导学生所需的资源也增多，特别是面对具有不同教育背景和技能的学生。为了应对这一挑战，自动编程评估系统（APASs）发展起来，提供可扩展的高质评估系统，能够高效评价并即时反馈。然而，这些系统主要依赖预定义的单元测试生成反馈，反馈的范围和细节有限。近年来，大型语言模型（LLMs）的兴起为提高反馈质量和个人化提供了新的机遇。因此，研究了不同反馈机制在APASs中的感知效果及其对学生解决问题能力的影响，进行了涵盖200多名来自两所大学学生的大型研究，对比了编译器反馈、标准单元测试反馈和基于AI的高级反馈在质量感知和学生表现影响方面的效果。", "innovation": "本研究利用大型语言模型增强了反馈的质量和个性化，探讨了不同反馈机制对学生学习体验和编程能力的影响。研究结果表明，虽然学生认为单元测试反馈最有效，但基于AI的反馈能够显著提升学生的表现。这表明将单元测试与AI驱动的指导相结合，可以优化自动反馈机制，提高编程教育中的学习成果。", "conclusion": "研究结果指出，尽管普遍认为标准单元测试反馈更有帮助，但利用AI生成的反馈有助于显著提高学生的学习表现。建议将单元测试与AI驱动的指导相结合，以优化自动反馈机制，改善编程教育中的学习成效。"}
{"llm_update_time": "20251023", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2510.19438", "html_url": "https://arxiv.org/abs/2510.19438", "title": "AutoMT: 一种基于多智能体大语言模型的自动 metamorphic 测试框架，用于自主驾驶系统的测试", "title_en": "AutoMT: A Multi-Agent LLM Framework for Automated Metamorphic Testing of Autonomous Driving Systems", "authors": "Linfeng Liang,Chenkai Tan,Yao Deng,Yingfeng Cai,T.Y Chen,Xi Zheng", "background": "自主驾驶系统（ADS）是安全关键系统，其中的故障可能会非常严重。现有的元形测试（MT）方法主要依赖于手工工作，缺乏自动化。现有MT方法在检测ADS中的故障时需要大量的人工努力，但AutoMT框架能够自动从本地交通规则中提取元形关系（MRs），并生成有效的后续测试用例，大大提高了自动化程度。", "innovation": "AutoMT 是一个基于大语言模型（LLMs）的多智能体元形测试框架，通过自动从 Gherkin 语法的交通规则中提取元形关系，以及利用视觉-语言代理和搜索代理生成有效的后续测试用例，实现了从手动到自动化的转变。实验结果表明，与手工定义的元形关系相比，AutoMT 在后续测试用例的生成中具有更高的测试多样性，并且能够检测到高达 20.55% 的更多行为违规。", "conclusion": "AutoMT 的模块化结构使得 MR 提取、过滤和测试生成的模块能够独立工作，这支持了其集成到工业流程中，并可能使基于模拟的测试能够系统地覆盖未被充分代表或关键的安全场景。与传统的依靠固定预定义规则的手动 MT 方法不同，AutoMT 可以自动提取多样化的元形关系，增强现实数据集，并帮助发现常在实地测试和数据收集期间被忽视的边缘案例。"}
{"llm_update_time": "20251023", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2510.19393", "html_url": "https://arxiv.org/abs/2510.19393", "title": "基于字节码的Java项目中已知漏洞依赖项检测", "title_en": "Bytecode-centric Detection of Known-to-be-vulnerable Dependencies in Java Projects", "authors": "Stefan Schott,Serena Elisa Ponta,Wolfram Fischer,Jonas Klauke,Eric Bodden", "background": "典型的Java项目中有71%的代码来自开源软件（OSS）依赖，使OSS依赖成为现代软件代码库中的主要组成部分。尽管依赖项扫描器可以识别已知漏洞的依赖项，但在依赖项修改（如重新编译、重捆绑或重新打包）的情况下，现代依赖项扫描器仍然存在挑战，尤其是在Java生态系统中这些修改较为常见。因此，研究者和公司开发了多种依赖扫描工具来应对这些安全风险。然而，现有的代码中心扫描工具，如Eclipse Steady，在面对这些常见修改类型的依赖项时依然存在不足。", "innovation": "Jaralyzer是基于字节码的Java依赖扫描器，无需依赖于包含的OSS依赖项的元数据或源代码，而是直接分析依赖项的字节码。与其他流行的依赖扫描器相比，Jaralyzer在检测被修改依赖项中的漏洞方面表现出色，并能识别所有上述类型的修改。即使在未修改的依赖项上应用，Jaralyzer也优于Eclipse Steady，能检测到更多的真实漏洞并产生更少的假警告。", "conclusion": "Jaralyzer能有效地识别Java项目中存在的修改依赖项中的已知漏洞，特别是在常见的修改类型（重新编译、重捆绑或重新打包）中表现尤为出色，解决了现有代码中心扫描工具的不足。"}
{"llm_update_time": "20251023", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2510.19600", "html_url": "https://arxiv.org/abs/2510.19600", "title": "Human-Agent Collaborative Paper-to-Page Crafting for Under $0.1", "title_en": "Human-Agent Collaborative Paper-to-Page Crafting for Under $0.1", "authors": "Qianli Ma,Siyu Wang,Yilin Chen,Yinhao Tang,Yixiang Yang,Chang Guo,Bingjie Gao,Zhening Xing,Yanan Sun,Zhipeng Zhang", "background": "科学研究的进步离不开研究成果的交流与传播，而研究人员常常因构建项目网页这个繁琐的手动过程而分心。现有的自动化工具已经可以处理静态幻灯片和海报，但网页的动态、互动性质仍然是一个未解决的难题。", "innovation": "我们重新定义了问题，提出不在于单一命令，而在于一种协作式的分层次过程。我们引入了AutoPage，一种新的多智能体系统，它将论文转化为网页的过程细分为从叙事规划到多模态内容生成再到互动渲染的粗细管道。为了对抗AI幻觉，我们引入了专用的“检查员”智能体来验证每一步是否符合原始论文，同时可选的人类检查点确保最终产品完全符合作者的愿景，将系统转变为一个强大的协作助手。为了验证我们的方法，我们还构建了全球首个此类任务的基准——PageBench。", "conclusion": "实验表明，AutoPage不仅可以生成高质量、视觉上令人愉悦的网页，而且效率惊人，小于15分钟内的成本小于0.1美元。源代码和数据集将会发布在网页中。"}
{"llm_update_time": "20251023", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2510.19593", "html_url": "https://arxiv.org/abs/2510.19593", "title": "根因分析的一种目标导向综述", "title_en": "A Goal-Driven Survey on Root Cause Analysis", "authors": "Aoyang Fang,Haowen Yang,Haoze Dong,Qisheng Lu,Junjielong Xu,Pinjia He", "background": "根因分析（RCA）在大规模云服务中的事件管理中是至关重要的。尽管“根因分析”这个词被广泛应用，不同的研究对此任务的定义却不尽相同。这是因为“根因分析”一词隐含涵盖了具有不同基础目标的任务。例如，快速定位故障服务和识别特定功能错误分别有着不同的目标，但之前的综述往往忽略了这些基于目标的区分，通常是根据输入数据类型（例如：基于指标的方法和基于跟踪的方法）来分类文献，导致汇集了不同目标的研究工作，从而掩盖了该领域的真正进展和空白。", "innovation": "本文提出了一种目标导向的框架，能够基于其多样化的目标有效分类和整合自2014年至2025年间共135篇关于云事件管理中根因分析的论文。除了目标导向的分类，还讨论了所有根因分析论文的最终目标作为其不同的根因分析形式的伞式覆盖。此外，还探讨了根因分析中的开放挑战和未来研究方向。", "conclusion": "本文为根因分析领域提供了一种新的分类视角，突出了不同类型目标的研究进展，并提出了未来研究的方向。该综述有助于理解根因分析的实际进展，填补了之前综述的空白。"}
{"llm_update_time": "20251023", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2510.19460", "html_url": "https://arxiv.org/abs/2510.19460", "title": "欧洲能源系统中的互联互通测试映射与演变：int:net视角", "title_en": "Mapping and Evolving Interoperability Testing in European Energy Systems: The int:net Perspective", "authors": "Thomas I. Strasser,Edmund Widl,Carlos Ayon Mac Gregor,Mirko Ginocchi,Rene Kuchenbuch", "background": "欧洲能源景观正在经历由可再生能源、数字技术和分布式系统一体化驱动的持续转变。确保这些组件和系统之间能够可靠地交换信息并协同工作对于实现安全、灵活和高效的能源供应基础设施至关重要。尽管已有多种倡议推动智能电网测试基础设施的发展，但这些尚未专注于互联互通测试。因此，缺乏一个概括性且协调的互联互通测试能力视图。", "innovation": "本工作通过对30个互联互通测试设施进行结构化调查，提供了一个新颖的贡献，即分析欧洲的互联互通测试设施景观。该研究提供了测试基础设施的分类目录、应用方法论和参考测试案例，并提出了开发未来测试环境的蓝图。这些发现有助于建立一个协调的欧洲互联互通测试生态系统，以支持合作、创新并与能源转型的目标保持一致。", "conclusion": "研究结果为建立协调的欧洲互联互通测试生态系统提供了支持，该生态系统能够促进合作、创新并确保与能源转型目标的一致性。"}
{"llm_update_time": "20251023", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2510.19615", "html_url": "https://arxiv.org/abs/2510.19615", "title": "FidelityGPT：使用检索增强生成纠正反编译失真的方法", "title_en": "FidelityGPT: Correcting Decompilation Distortions with Retrieval Augmented Generation", "authors": "Zhiping Zhou,Xiaohong Li,Ruitao Feng,Yao Zhang,Yuekang Li,Wenbu Feng,Yunqian Wang,Yuqing Li", "background": "反编译将机器代码转换为人类可读的形式，便于在没有源代码的情况下进行分析和调试。然而，现有的反编译技术常常导致输出可读性和语义准确性下降。现有方法，例如变量重命名或结构简化，可以提供部分改善，但在处理复杂闭源二进制文件时，却缺乏有效的检测和纠正手段。因此，提出了FidelityGPT框架，旨在通过系统地检测和纠正语义失真来提高反编译代码的准确性和可读性。", "innovation": "FidelityGPT引入了针对闭源设置定制的失真感知提示模板，结合了检索增强生成（RAG）和动态语义强度算法，以识别失真行并从数据库检索到语义相似的代码。此外，变量依赖算法通过分析冗余变量及其依赖关系，进一步解决了长上下文限制的问题，将其整合到提示上下文中。在一项基于二进制相似度基准的数据集中，FidelityGPT的平均检测准确率为89%，精确度为83%。与最新的DeGPT（修复率83%，修复后修复率37%）相比，FidelityGPT的修复率达到了94%，修复后修复率为64%，表明其在准确性和可读性方面取得了显著的改进。", "conclusion": "这些结果突显了FidelityGPT在基于LLM的反编译和逆向工程中潜在的进步。"}
{"llm_update_time": "20251023", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2510.19692", "html_url": "https://arxiv.org/abs/2510.19692", "title": "超越代码的主动软件工程：框架视野、价值观和词汇", "title_en": "Toward Agentic Software Engineering Beyond Code: Framing Vision, Values, and Vocabulary", "authors": "Rashina Hoda", "background": "主动AI即将在软件工程领域引发一场巨大的范式转变。随着科技工作者急于将主动AI变为现实，软件工程研究人员正被驱使建立主动软件工程作为一个研究领域。早期关于主动软件工程的愿景主要集中在代码相关的活动上，但早期的经验研究表明，需要考虑各种社会-技术方面的关注点才能在实践中实现它。", "innovation": "本文通过：（a）建议其范围从代码扩展到一个“全过程”的愿景，并将主动软件工程与软件工程基础、演变以及新兴的主动软件工程框架相结合；（b）提出初步的价值观和原则来引导努力的方向；（c）分享关于设计/使用明确词汇的指导，为活跃的软件工程社区提供指导思想，以促进社区合作，引导软件工程领域奠定坚实的基础，使主动软件工程在长期内不可避免地成为既刻意又可取的目标。", "conclusion": "希望通过上述思想鼓励社区合作，并引导软件工程领域朝着主动软件工程的强固基础的方向迈进，使它在长期内不仅不可避免，而且刻意和可取。"}
{"llm_update_time": "20251023", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2509.23130", "html_url": "https://arxiv.org/abs/2509.23130", "title": "SysMoBench：评估生成式AI在形式化建模复杂真实系统方面的能力", "title_en": "SysMoBench: Evaluating AI on Formally Modeling Complex Real-World Systems", "authors": "Qian Cheng,Ruize Tang,Emilie Ma,Finn Hackett,Peiyang He,Yiming Su,Ivan Beschastnikh,Yu Huang,Xiaoxing Ma,Tianyin Xu", "background": "形式化模型对于定义大型、复杂计算机系统及其正确性的验证至关重要，但编写和维护这些模型非常昂贵。尽管生成式AI技术在生成某些类型的规范方面显示出前景，现有研究大多仅针对小型代码，而不是完整的系统。因此，尚不清楚AI是否能够处理现实系统的复杂特性，并将其抽象为形式化的模型。", "innovation": "SysMoBench为评估AI生成模型的能力提供了一个基准。它特别关注并发和分布式系统，这些系统是当今关键计算基础设施的核心，包括操作系统和云基础设施。SysMoBench采用了TLA+作为形式化规格语言，但基准测试可以扩展到其他规格语言。SysMoBench通过自动化评估标准、语法和运行时正确性、系统代码符合性和不变正确性来解决评估AI生成模型的主要挑战。", "conclusion": "SysMoBench目前包含了九种不同的系统元素，并且正在积极添加更多元素，它有助于我们理解当今LLM和代理的能力和局限性，为该领域提供了坚实的基础，并开启了新的研究方向。"}
{"llm_update_time": "20251023", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2510.19747", "html_url": "https://arxiv.org/abs/2510.19747", "title": "基于零代码大语言模型应用开发工具的综述", "title_en": "Review of Tools for Zero-Code LLM Based Application Development", "authors": "Priyaranjan Pattnayak,Hussain Bohra", "background": "大语言模型（LLMs）正在改变软件开发的方式，通过启用零代码平台。这些平台允许用户通过利用LLMs作为开发过程的核心组件来构建应用程序，而无需编写代码。本文综述了这一领域的最新平台，采用广泛的研究方法，按照界面风格、后端集成、输出类型和可扩展性等关键维度对平台进行分类。文章不仅涵盖了专门基于LLM的应用构建器，还涵盖了集成LLM功能的通用零代码平台。", "innovation": "通过创建分类学，按界面类型（对话式、可视化等）、支持的LLM后端、输出类型（聊天机器人、完整应用程序、工作流）和扩展性程度对这些平台进行分类，文章还涵盖了核心功能，如自主代理、内存管理、工作流编排和API集成，并提供了详细的比较。此外，文章讨论了与传统和低代码开发方法相比的权衡（如可定制性、可扩展性和供应商锁定），并概述了未来发展方向，包括多模态界面、设备上的LLM和改进的编排，以利用AI民主化应用创建。", "conclusion": "尽管基于零代码LLM的平台极大地降低了创建AI驱动应用的门槛，但仍面临灵活性和可靠性的挑战。总体而言，该领域的景观正在迅速演变，为非程序员的复杂软件创建提供了激动人心的机会。"}
{"llm_update_time": "20251023", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2510.18893", "html_url": "https://arxiv.org/abs/2510.18893", "title": "CodeCRDT：多智能体LLM代码生成的观察驱动协调", "title_en": "CodeCRDT: Observation-Driven Coordination for Multi-Agent LLM Code Generation", "authors": "Sergey Pugachev", "background": "多智能体大型语言模型（LLM）系统由于昂贵的协调成本无法实现并行加速。", "innovation": "提出了CodeCRDT，这是一种观察驱动的协调模式，智能体通过监控共享状态并使用可观察更新和确定性收敛来协调，而不是通过显式的消息传递。", "conclusion": "在600次试验中（6个任务，每种模式50次运行）的评估显示，CodeCRDT既带来了好处也存在权衡：在某些任务中最多可提高21.1%的速度，而在其他任务中最多可降低39.4%的速度，但实现了100%的收敛且没有合并失败。研究形式化了随机LLM智能体的观察驱动协调，揭示了语义冲突率（5-10%）以及质量-性能权衡，并基于任务结构为并行协调的成败提供了实证描述。"}
{"llm_update_time": "20251023", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2510.19777", "html_url": "https://arxiv.org/abs/2510.19777", "title": "BOSQTGEN：突破测试生成的声障", "title_en": "BOSQTGEN: Breaking the Sound Barrier in Test Generation", "authors": "S M Sadrul Islam Asif,James Chen,Earl T. Barr,Mark Marron", "background": "现代软件越来越多地通过组成API构建，使API合同变得至关重要的角色。然而，不充分的合同会导致期望的不匹配和失败，从而迫切需要进行稳健的合规性测试。目前的测试生成技术受到主要挑战的阻碍：多语言系统、源代码不可访问性、成本与可靠性的权衡，以及最关键的是生成结构化输入的困难。因此，对一种新的黑盒方法和工具——BOSQTGEN的需求变得迫切，用于API测试生成。", "innovation": "BOSQTGEN通过一种新颖的方法将API规范分解成基本元素，使用LLMs提出协调的层级，并利用组合测试来高效地进行采样，从而确保关键交互的覆盖率，同时避免随机采样的冗余。系统在RESTful基准测试中实现了平均82%的代码覆盖率，比前最先进的系统高出20%或更多，并接近手工编写测试套件的水平。通过提供一种完全以API为驱动的测试生成方法，使开发人员能够自动创建高质量的测试案例进行验证或测试驱动开发。", "conclusion": "BOSQTGEN系统显著提高了API测试生成的效率和覆盖率，为开发人员提供了一种自动化的解决方案来创建高质量的测试案例，这对于现代软件的验证和测试驱动开发非常重要。"}
{"llm_update_time": "20251023", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2510.19012", "html_url": "https://arxiv.org/abs/2510.19012", "title": "在Apache Spark中使用Java、Python和Scala处理大型数据的比较分析", "title_en": "Comparative analysis of large data processing in Apache Spark using Java, Python and Scala", "authors": "Ivan Borodii,Illia Fedorovych,Halyna Osukhivska,Diana Velychko,Roman Butsii", "background": "尽管已有研究专注于单个处理阶段，但在使用Apache Iceberg对端到端的ETL工作流进行全面比较方面，不同编程语言的研究仍然有限。本文通过Java、Python和Scala的三种编程语言对Apache Spark平台处理大型数据集的过程进行了比较分析。", "innovation": "研究表明，编程语言显著影响Apache Spark算法的数据处理效率。Scala和Java更适合处理大规模数据和复杂操作，而Python更适合小规模数据处理。这对于根据特定性能需求和信息处理量来优化数据处理过程具有重要意义。", "conclusion": "本文的结果表明，Python在处理少量数据时表现出色，而Scala和Java在处理大量数据和复杂操作时更有效。研究结果可以用于根据特定性能要求和处理的信息量来优化数据处理流程。"}
{"llm_update_time": "20251023", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2510.18897", "html_url": "https://arxiv.org/abs/2510.18897", "title": "AI驱动的分布式系统设计：通过重复的LLMs抽样和仿真器实现可扩展的云优化", "title_en": "AI for Distributed Systems Design: Scalable Cloud Optimization Through Repeated LLMs Sampling And Simulators", "authors": "Jacopo Tagliabue", "background": "本文探讨了通过将大规模语言模型（LLMs）的随机代码生成与特定领域的仿真器中的确定性验证结合起来，设计AI驱动的分布式系统策略的方法。使用一个函数作为服务的运行时（Bauplan）及其开源仿真器（Eudoxia）作为案例研究，框架将调度器设计视为迭代生成-验证循环：LLMs提出一个Python策略，仿真器在标准化跟踪上对其进行评估，结构化反馈引导后续的生成。这种设置保持了可解释性，同时能够在大的设计空间中进行有针对性的搜索。报告了跨多个模型的初步结果关于吞吐量改进。然而，讨论了当前设置的限制点，并概述了下一步的工作；特别是，假设人工智能将在通过帮助启动新的仿真器来扩大此方法的应用广度方面发挥关键作用。", "innovation": "结合了大规模语言模型的随机代码生成和特定领域的仿真器中的确定性验证，形成了AI驱动的分布式系统策略设计方法。将调度器设计视为迭代生成-验证循环，通过结构化反馈引导后续的生成。保持了可解释性的同时，能够在大的设计空间中进行有针对性的搜索。提出了一种新的系统架构，并报告了跨多个模型的初步结果。假设人工智能将在通过帮助启动新的仿真器来扩大此方法的应用广度方面发挥关键作用。", "conclusion": "文章讨论了当前方法的局限性，并提出下一步计划的关键点在于通过人工智能来扩展这种方法的应用范围，通过帮助启动新的仿真器来实现规模效应。"}
{"llm_update_time": "20251023", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2510.18936", "html_url": "https://arxiv.org/abs/2510.18936", "title": "SBAN: 一种用于大规模语言模型预训练和软件代码挖掘的框架与多维数据集", "title_en": "SBAN: A Framework \\& Multi-Dimensional Dataset for Large Language Model Pre-Training and Software Code Mining", "authors": "Hamed Jelodar,Mohammad Meymani,Samita Bai,Roozbeh Razavi-Far,Ali A. Ghorbani", "background": "该研究旨在促进大型语言模型（LLMs）的软件代码分析的预训练和评估，因此开发了一个大型且多维度的数据集SBAN（Source code, Binary, Assembly, and Natural Language Description）。该数据集包括超过300万个样本，分为290万个良性样本和67.2万个恶意软件样本，每个样本通过二进制代码、汇编指令、自然语言描述和源代码四个互补层面进行表示。", "innovation": "SBAN具有独特的多模态结构，能够促进跨表示学习、软件语义理解以及自动检测恶意软件的研究。除了安全应用，SBAN还支持代码翻译、代码解释和其他涉及异构数据的软件挖掘任务。由于其适用于大规模训练深度模型（包括变压器和其他LLM架构），SBAN为企业建设能够理解和分析代码的智能系统提供了坚实的基础。", "conclusion": "SBAN为软件行为挖掘、安全分析和改进LLM在软件代码挖掘任务中的前训练和适应性提供了新的机会。通过将低级机器表示与高级人类语义相结合，SBAN为构建能够理解和分析代码的智能系统提供了一个强大而灵活的基础平台。"}
{"llm_update_time": "20251023", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2510.19303", "html_url": "https://arxiv.org/abs/2510.19303", "title": "协作渗透测试套件以应对新兴生成式AI算法", "title_en": "Collaborative penetration testing suite for emerging generative AI algorithms", "authors": "Petar Radanliev", "background": "该论文背景在于生成式AI模型面临的安全漏洞问题，包括模型逆向工程、数据污染和对抗性输入等，以及量子计算带来的威胁，如Shor算法破解RSA和ECC加密。在此背景下，该研究旨在确保生成式AI模型能够抵御来自经典和量子的网络安全攻击。", "innovation": "提出的创新解决方案是构建一个协作渗透测试套件，它整合了五个组件：DAST、SAST、OWASP ZAP、Burp Suite、SonarQube、Fortify以及通过CI/CD管道集成的IAST。该套件还融合了区块链日志记录（使用Hyperledger Fabric）和量子加密（使用基于环的RLWE协议），以及通过模拟红队对对抗性机器学习和量子辅助攻击进行模拟。这一整合的工作流适合AI、网络安全和量子专家共同使用。实验结果显示，该套件能够在2周内发现300多个漏洞，其中70%的高严重性问题得到了解决，并且量子模型也保持了100%的完整性。", "conclusion": "研究得出了量子AI安全协议的结论，该协议结合了区块链、量子加密和AI红队演练，并成功地维护了量子算法的完整性和在各种测试环境中的安全性。"}
{"llm_update_time": "20251023", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2510.19691", "html_url": "https://arxiv.org/abs/2510.19691", "title": "LifeSync-Games：促进负责任游戏和人类发展的视频游戏范式", "title_en": "LifeSync-Games: Toward a Video Game Paradigm for Promoting Responsible Gaming and Human Development", "authors": "R. González-Ibáñez,J. Macías-Cáceres,M. Villalta-Paucar", "background": "随着技术进步，大约30亿人将视频游戏视为其数字生活的核心部分。尽管游戏能够满足多种社交、身体和心理需求，但其对人类发展和福祉的支持潜力尚未得到充分利用。尽管有研究表明游戏会带来积极的结果，如认知改善和问题解决能力提升，公众讨论和监管更多地关注其风险而非益处。因此，需要一种平衡的方法来改进游戏对人类发展的贡献，以促进负责任的游戏行为和人类发展。", "innovation": "LifeSync-Games框架通过利用简化版的数字孪生技术，将虚拟游戏与现实生活活动连接起来。这创造了一种双向关系，旨在通过促进自控和在身体、心理健康以及社交领域促进个人成长来增强游戏的开发价值。该框架包括理论基础、技术组件、设计指南和评估方法，并演示了其在新游戏和畅销游戏中应用的早期实例，展示了其多样性和实际相关性。", "conclusion": "LifeSync-Games框架提供了一种新的视频游戏范式，通过增强游戏的教育和心理支持功能，促进负责任的游戏行为和人类发展。该框架通过创建虚拟与现实之间的联系，为游戏设计师和用户提供了一个激励自我调节和成长的新途径。"}
{"llm_update_time": "20251023", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2510.19799", "html_url": "https://arxiv.org/abs/2510.19799", "title": "将透明模型、LLM与实践者参与结合：非营利项目评估案例", "title_en": "Integrating Transparent Models, LLMs, and Practitioner-in-the-Loop: A Case of Nonprofit Program Evaluation", "authors": "Ji Ma,Albert Casella", "background": "公共和非营利组织通常不愿意采用AI工具，因为大多数模型缺乏透明度，即使标准方法通常分析聚合模式而非提供具体案例的指导。这项研究测试了一种实践者参与的工作流，该工作流结合了透明的决策树模型和大型语言模型（LLM），以提高预测准确性、可解释性和生成实用见解的能力。研究使用正在进行的大学成功项目的数据构建可解释的决策树，以揭示关键预测因素。然后将每个树的结构提供给LLM，使它可以基于透明模型生成具体案例的预测。在整个特征工程、模型设计、解释审查和易用性评估的过程中，实践者参与进来，确保现场专长指导分析的每个阶段。", "innovation": "该研究提出了一种结合透明决策树模型、大型语言模型（LLM）与实践者参与工作流的方法，旨在提高预测准确性、可解释性以及生成实用见解。这种方法确保在特征工程、模型设计、解释审查和易用性评估等各个环节中，领域专业知识能够指导分析过程。", "conclusion": "研究结果表明，将透明模型、LLM和实践者输入相结合可以产生准确、可信和实用的具体案例评估结果，为公共和非营利领域负责任的AI采用提供了可行途径。"}
{"llm_update_time": "20251023", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2503.14000", "html_url": "https://arxiv.org/abs/2503.14000", "title": "面向Python程序的类型感知LLM基础回归测试生成", "title_en": "Type-aware LLM-based Regression Test Generation for Python Programs", "authors": "Runlin Liu,Zhe Zhang,Yunge Hu,Yuhang Lin,Xiang Gao,Hailong Sun", "background": "自动化回归测试生成已经被广泛研究，然而为Python程序生成高质量的测试仍然是一个挑战性的任务。Python的动态类型特性使得现有方法，从基于搜索的软件测试（SBST）到最近的基于大语言模型（LLM）的技术，往往会遇到类型错误的问题。现有的方法经常生成无效的输入和语义上不一致的测试用例，这些最终削弱了它们的实际效果。", "innovation": "我们提出了Test4Py，这是一种新的框架，旨在增强Python中自动化测试生成的类型正确性。Test4Py利用程序的调用图来捕获参数的更丰富的上下文信息，并引入了一种基于行为的类型推理机制，以准确地推理参数类型并构造有效的测试输入。Test4Py还集成了一种迭代修复程序，逐步精化生成的测试用例以提高覆盖率。", "conclusion": "在对183个真实Python模块进行评估后，Test4Py达到了平均语句覆盖率83.0%和分支覆盖率70.8%，分别比最先进的工具高出7.2%和8.4%。"}
{"llm_update_time": "20251023", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2411.04372", "html_url": "https://arxiv.org/abs/2411.04372", "title": "基于整数序列生成任务评估大型语言模型", "title_en": "Benchmarking Large Language Models with Integer Sequence Generation Tasks", "authors": "Daniel O'Malley,Manish Bhattarai,Javier Santos,Nishath Rajiv Ranasinghe,Erick Draayer", "background": "当前的大型语言模型（LLMs）在数学推理和算法代码合成方面的表现值得进一步评估。本文通过收集来源于OEIS的挑战性整数序列生成任务，设计了一套严格的基准测试，用以对LLMs进行评估。", "innovation": "本文提出了一个新颖的基准测试，该基准测试集包括生成整数序列的任务，要求模型直接生成Python代码而非依靠查找表。测试集中包含OEIS中正式分类为“易”或“难”的1000个序列，并引入了自动检测作弊机制以防止模型使用记忆的序列值。实验结果表明，专注于推理的模型在复杂任务上取得了明显的优势，但整体性能有待提高。", "conclusion": "当前的LLMs在算法推理方面仍存在不足，需要进一步发展以可靠地解决复杂数学推理任务。基准测试为研究提供了重要的参考，强调了对更先进模型的迫切需求。"}
{"llm_update_time": "20251023", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2510.19667", "html_url": "https://arxiv.org/abs/2510.19667", "title": "Dara: 从粉末X射线衍射数据自动进行多重假设的相识别与精修", "title_en": "Dara: Automated multiple-hypothesis phase identification and refinement from powder X-ray diffraction", "authors": "Yuxing Fei,Matthew J. McDermott,Christopher L. Rom,Shilong Wang,Gerbrand Ceder", "background": "粉末X射线衍射（XRD）是表征晶体材料的基础技术。然而，在多相体系中，可靠地解释XRD模式，尤其是析出相识别，仍然是一个需要专业知识的手工任务。由于XRD方法只提供结构信息，一种参考相常常可以被应用在同一个模式中，这导致了当忽视替代方案时会产生潜在的误判。因此，需要一种方法来减轻人类的工作量并与处理这一挑战，Dara（Data-driven Automated Rietveld Analysis）被引入，旨在通过自动化识别和改进多变相从粉末XRD数据来进行多次试验。Dara在给定的化学空间进行全面的相组合树搜索，并利用强大的Rietveld精修程序（BGMN）验证每种假设。", "innovation": "Dara引入了一种自动化的框架，用于从粉末XRD数据中识别和精修多变相。其创新点包括通过结构数据库筛选，自动扩展树过程中的同构物簇自动聚类，基于峰值匹配的评分识别表现性相进行精修。当存在不确定性时，Dara生成多个假设供人类专家或进一步表征工具倾向于选择。通过提高相识别的可靠性和准确性，Dara能够进行大规模的复杂XRD模式分析，并为多模式表征流程的集成打下基础，朝着完全自动驾驶的材料发现前进。", "conclusion": "Dara通过增强相识别的可靠性和准确性，适用于实际复杂的XRD模式分析，为多模式表征流程的集成提供基础，推动了材料发现的自我驱动进程。"}
{"llm_update_time": "20251023", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2506.10043", "html_url": "https://arxiv.org/abs/2506.10043", "title": "TrioXpert: 微服务系统自动故障管理框架", "title_en": "TrioXpert: An Automated Incident Management Framework for Microservice System", "authors": "Yongqian Sun,Yu Luo,Xidao Wen,Yuan Yuan,Xiaohui Nie,Shenglin Zhang,Tong Liu,Xi Luo", "background": "自动化故障管理在大规模微服务系统中扮演着关键角色。然而，现有方法通常仅依赖单模态数据（如度量、日志和跟踪），难以同时处理多个下游任务，包括异常检测（AD）、故障分类（FT）和根本原因定位（RCL）。此外，目前的技术缺乏清晰的推理证据，导致解释性不足。为了克服这些限制，本文提出了一种名为 TrioXpert 的端到端故障管理框架，能够充分利用多模态数据。TrioXpert 设计了针对不同模态固有特点的三个独立数据处理管道，从数值和文本两个维度全面表征微服务系统的运行状态。它使用大型语言模型（LLMs）协作机制同时处理多个任务，并提供清晰的推理证据以确保强大的解释性。", "innovation": "提出了 TrioXpert，一种端到端的自动化故障管理框架，该框架利用多模态数据进行全面的数据处理，并使用大型语言模型（LLMs）进行协作推理，以同时处理多个任务并提供清晰的推理证据，增强解释性。该框架在两个微服务系统数据集上的广泛评估展示了其在AD、FT和RCL任务中卓越的表现，同时已在联想的生产环境中部署，展示了诊断效率和准确性的重要提升。", "conclusion": "实验结果表明，TrioXpert 在 AD、FT 和 RCL 任务中分别提高了 4.7% 至 57.7%、2.1% 至 40.6% 和 1.6% 至 163.1% 的性能。并且 TrioXpert 已实际部署于联想的生产环境，证明了其在诊断效率和准确性方面的显著提升。"}
{"llm_update_time": "20251023", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2506.11153", "html_url": "https://arxiv.org/abs/2506.11153", "title": "QiMeng-MuPa: Mutual-Supervised Learning for Sequential-to-Parallel Code Translation", "title_en": "QiMeng-MuPa: Mutual-Supervised Learning for Sequential-to-Parallel Code Translation", "authors": "Changxin Ke,Rui Zhang,Shuo Wang,Li Ding,Guangli Li,Yuanbo Wen,Shuoming Zhang,Ruiyuan Xu,Jin Qin,Jiaming Guo,Chenxi Wang,Ling Li,Qi Guo,Yunji Chen", "background": "GPU为基础的高性能计算（HPC）推动了并行编程模型如CUDA的广泛应用。然而，由于并行编程固有的复杂性，需要自动化的串行到并行的转换方法。当前基于机器学习的方法虽然具有潜力，但无法确保转换后的代码具有功能等效性。现有方法仍无法解决这一问题，尤其是在数据稀缺的情况下。", "innovation": "本文提出了QiMeng-MuPa，这是一种新颖的互监督学习框架，用于序列到并行代码转换。QiMeng-MuPa框架由两个模型组成：译码器和测试器。通过共验证和共进化步骤的迭代循环，译码器和测试器互相生成数据并共同提高。测试器生成单元测试来验证和筛选功能等效的译码器输出，从而优化译码器；而译码器则生成翻译代码，作为测试器的增强输入。实验结果显示，QiMeng-MuPa在多个基准模型上显著提升了性能，特别是对比CodeRosetta在BLEU和CodeBLEU上的得分分别提升了1.56和6.92，并且与DeepSeek-R1和GPT-4.1的性能相当。", "conclusion": "QiMeng-MuPa框架在序列到并行代码转换中实现了显著提升，不仅增强了实验模型的性能，还超越了之前最先进的方法。此外，QiMeng-MuPa的代码已公开。"}
{"llm_update_time": "20251023", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2505.20749", "html_url": "https://arxiv.org/abs/2505.20749", "title": "Can Agents Fix Agent Issues？", "title_en": "Can Agents Fix Agent Issues?", "authors": "Alfin Wijaya Rahardja,Junwei Liu,Weitong Chen,Zhenpeng Chen,Yiling Lou", "background": "LLM-based.agent.systems.正在成为一种新的软件范式，并广泛应用于医学、机器人和编程等领域。然而，维护这些系统需要大量努力，因为它们不可避免地会出现错误，不断进化以适应不断变化的外部需求。因此，自动解决代理问题（即错误报告或功能请求）是一个关键且具有挑战性的任务。最近的软件工程（SE）代理（例如SWE-agent）在处理传统软件系统中的问题方面显示出潜力，但它们能否有效地解决代理系统中的实际问题仍不清楚，因为两者存在显著差异。为了填补这一差距，研究者首先手动分析了201个实际的代理问题，确定了代理问题的常见类别。然后花费500人时构建了一个名为AGENTISSUE-BENCH的可再现基准，它包括50个代理问题解决任务（每个任务都有可执行环境和触发失败的测试）。最后，评估最先进的SE代理在AGENTISSUE-BENCH上的性能，结果显示它们的有效性有限（即解决率为3.33%至12.67%）。这些结果强调了与传统软件相比，维护代理系统的独特挑战，突显了需要进一步研究开发更先进的SE代理以解决代理问题的需求。", "innovation": "研究者构建了一个名为AGENTISSUE-BENCH的可再现基准，它包括50个代理问题解决任务（每个任务都有可执行环境和触发失败的测试）。这项研究通过提供一个可重复的平台来评估当前最先进的SE代理人处理代理问题的有效性，这是该研究的一项创新。", "conclusion": "当前最先进的SE代理在解决代理问题方面表现有限，解决率仅为3.33%至12.67%。这强调了与传统软件相比，维护代理系统的独特挑战，并指出了需要进一步研究以开发更先进的SE代理解决代理问题的重要性。"}
