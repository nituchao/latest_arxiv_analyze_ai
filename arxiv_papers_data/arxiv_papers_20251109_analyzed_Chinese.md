# 20251109
[![Subscribe_Visitors](https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss)](https://github.com/nituchao/latest_arxiv_analyze_ai)

## 1. `cs.AI` - 在多模态大语言模型中，是看还是读：用户行为推理 [PDF](https://arxiv.org/pdf/2511.03845), [HTML](https://arxiv.org/abs/2511.03845)
### Authors
Tianning Dong,Luyi Ma,Varun Vasudevan,Jason Cho,Sushant Kumar,Kannan Achan
### Background
多模态大语言模型正在重塑现代代理系统在处理用户的顺序行为数据时的推理方式。然而，用户行为数据是通过文本还是图像表示，哪种方式可以最大化多模态大语言模型的表现效果却鲜有探讨。本研究通过将交易数据分别表示为文本段落、散点图和流程图来评估不同模态在用户行为推理中的优劣。
### Innovation
提出了名为BehaviorLens的系统性基准测试框架，通过该框架评估六种多模态大语言模型在用户行为推理中的不同模态之间的权衡关系。实验结果显示，当数据以图像形式呈现时，多模态大语言模型的下一次购买预测准确性提高了87.5%，且没有增加额外的计算成本。
### Conclusion
研究发现，对于提高多模态大语言模型在用户行为推理中的表现效果，更倾向于使用图像表示形式的数据，而不是文本形式，且无需额外增加计算开销。
## 2. `cs.AI` - 知吾者：一种针对大型语言模型可解释性的自主助理 [PDF](https://arxiv.org/pdf/2511.03878), [HTML](https://arxiv.org/abs/2511.03878)
### Authors
Suraj Prasai,Mengnan Du,Ying Zhang,Fan Yang
### Background
当前市面上的大型语言模型（LLM）解释工具虽然提供了有价值的见解，但这些工具依然存在碎片化、代码密集等问题。用户难以通过简单的界面操作获取模型的解释结果。
### Innovation
开发了名为‘知吾者’（KnowThyself）的自主助理，这是一种基于对话界面的解释工具，用户可以上传模型、提出自然语言问题并获得带有引导解释的互动可视化结果。‘知吾者’的核心设计包括一个 orchestrate LLM 重述用户查询、一个 agent router 将查询导向专门模块，以及最后将输出结果进行语境化表述为连贯的解释。这种设计降低了技术门槛，提供了一个可供扩展的平台来检查 LLM 的解释性。通过将整个流程嵌入为对话式工作流，知吾者为无障碍 LLM 解释提供了一个坚实的基础。
### Conclusion
‘知吾者’不仅提供了一种新的、用户友好的界面来解释 LLM 的行为，还提供了一个可扩展的平台，使得不同背景的用户都能够更容易地理解复杂模型的功能和决策过程。
## 3. `cs.AI` - 在深度知识追踪中的因果关系提取 [PDF](https://arxiv.org/pdf/2511.03948), [HTML](https://arxiv.org/abs/2511.03948)
### Authors
Kevin Hong,Kia Karbasi,Gregory Pottie
### Background
计算教育研究的一个长期目标是开发可解释的知识追踪(KT)模型。Deep Knowledge Tracing (DKT)使用循环神经网络(RNN)来预测学生对作业的知识和表现，被认为是传统KT方法的主要进步。研究表明，其性能提升源于能够建模课程中不同知识组件(KC)之间的双向关系，从而推断学生对一个KC的理解程度取决于他们的其他KC表现。然而，本文挑战了这种解释，表明DKT的优势在于其隐式建模先决条件关系的因果结构，而非双向关系。通过将作业关系图简化为有向无环图(DAG)并在因果子集上训练DKT，作者展示了DKT的预测能力与这些因果结构高度一致。
### Innovation
本文提出了一种新的因果关系提取方法，通过使用DKT学习表示简化作业关系图，并且提供了实证证据支持其观点。表明DKT的效用主要归因于其对KC之间因果依赖关系的近似能力，而非简单的关系映射。
### Conclusion
研究结果表明，DKT的高效率主要是由于其可以近似表示KC之间的因果依赖关系，而不是简单的双向关系映射。
## 4. `cs.AI` - ArchPilot：一种基于代理的多智能体机器学习工程方法 [PDF](https://arxiv.org/pdf/2511.03985), [HTML](https://arxiv.org/abs/2511.03985)
### Authors
Zhuowen Yuan,Tao Liu,Yang Yang,Yang Wang,Feng Qi,Kaushik Rangadurai,Bo Li,Shuang Yang
### Background
近年来，基于大语言模型的智能代理已经在自动化机器学习工程方面展示了强大的能力。然而，它们依赖于反复进行完整训练来评估候选解决方案，这导致了大量的计算开销，对大型搜索空间的支持有限，以及迭代周期缓慢。
### Innovation
我们引入了ArchPilot，这是一种多智能体系统，它将架构生成、基于代理的评估和自适应搜索整合到一个统一的框架中。ArchPilot包括三个专门的智能体：一个协调搜索过程的调度智能体，使用借鉴蒙特卡洛树搜索(MCTS)的新颖算法并带有重启机制来管理之前候选的内存；一个生成智能体，迭代生成、改进和调试候选架构；以及一个执行代理训练运行、生成和优化代理函数并根据代理评估分数生成忠实度意识性能度量的评估智能体。这种多智能体协作允许ArchPilot在最大程度上减少对昂贵完整训练的依赖，从而在有限预算下促进有效的机器学习工程。
### Conclusion
在MLE-Bench上的实验表明，ArchPilot在与AIDE和ML-Master等最新基准相比时表现出色，证实了我们的多智能体系统方法的有效性。
## 5. `cs.AI` - 在大型语言模型中通过数值属性解读多属性混杂 [PDF](https://arxiv.org/pdf/2511.04053), [HTML](https://arxiv.org/abs/2511.04053)
### Authors
Hirohane Takagi,Gouki Minegishi,Shota Kizawa,Issey Sukeda,Hitomi Yanaka
### Background
尽管行为研究表明大型语言模型（LLMs）存在数值推理错误，但其背后的表示机制尚未明确。研究表明，LLMs在处理单一实体的多个数值属性时可能存在系统性偏差，并且外来数值背景会影响它们的表示及其下游输出。
### Innovation
本文通过结合线性探测、部分相关分析及基于提示的脆弱性测试，研究了数值属性在LLMs中的内部整合方式及无关数值背景对其表示的影响。研究发现LLMs编码了现实世界的数值相关性，但倾向于系统性地放大这些相关性。此外，无关背景会一致地引起大小的表示差异，这一影响因模型规模而有所不同。这项研究揭示了LLMs决策中的脆弱性，并为在多属性纠缠下实现更公平、表示感知的控制奠定了基础。
### Conclusion
本研究揭示了LLMs在处理多属性数据时可能存在偏差，这种偏差受到无关背景的影响，且模型规模会影响这种影响的程度。这些发现对LLMs的表示和决策透明度提出了挑战，为在多属性情境下进行公平、安全的决策提供了新的视角。
## 6. `cs.AI` - LLMs and Cultural Values: the Impact of Prompt Language and Explicit Cultural Framing [PDF](https://arxiv.org/pdf/2511.03980), [HTML](https://arxiv.org/abs/2511.03980)
### Authors
Bram Bulté,Ayla Rigouts Terryn
### Background
大型语言模型（LLMs）正在全球范围内被广泛使用，用户用多种语言与之互动。然而，LLMs在训练数据和优化目标中的不平衡性引起了对其能否代表广泛用户群体文化多样性的质疑。本研究通过探讨LLMs与文化价值观之间的关系，分析提示语言和文化框架对模型响应及其与不同国家人类价值观一致性的潜在影响。研究使用来自霍夫斯特德价值观调查模块和世界价值观调查的63个项目，翻译成11种语言，对10种LLMs进行了测试，并且以不同的文化视角进行了题目设计。研究表明，提示语言和文化视角都能影响LLM的输出结果，但这种影响是有局限性的。
### Innovation
本研究通过直接测试10种不同语言和文化背景的LLMs，系统地分析了提示语言和明确的文化框架对LLM响应的影响。发现LLMs对提示语言响应有所变化，但文化默认值太根深蒂固，以至于无法广泛代表文化多样性。这些发现表明，虽然提示语言可以在一定程度上引导LLM响应，但无法克服它们系统性的偏见。
### Conclusion
研究结果揭示了LLMs在文化多样性上的尴尬地位：它们对提示语言的变化反应足够灵敏，可以产生不同的结果，但其对特定文化默认值的依赖太强，无法充分反映文化的多样性。
## 7. `cs.AI` - Agentmandering:基于大规模语言模型代理的游戏理论公平重新分区框架 [PDF](https://arxiv.org/pdf/2511.04076), [HTML](https://arxiv.org/abs/2511.04076)
### Authors
Hao Li,Haotian Chen,Ruoyuan Gong,Juanjuan Wang,Hao Jiang
### Background
重新分区在塑造选票转化为政治影响力方面扮演着核心角色。现有的计算方法主要致力于生成大量合法有效的选区划划分方案，但往往会忽略选择过程中的战略动态。这种忽略为党派行为体提供了机会，使其可以挑选虽符合技术要求但由于政治原因更有利的地图。仅满足形式约束并不能确保公平，特别是当选择过程本身可以被操纵时。因此，需要引入新的方法来确保公平和稳定性，特别是在选情均衡州的情境下。
### Innovation
我们提出了Agentmandering框架，将其重新分区重新构想为两个代表对立政治利益的代理之间的轮流谈判过程。这种方法借鉴了博弈论理念，特别是“选择和冻结”协议，通过大规模语言模型（LLM）代理将战略互动嵌入重新分区过程。代理交替选择和冻结来自少量候选地图的选区，逐步通过约束和可解释的选择将州划分出来。实验证实，Agentmandering在各州2020年后的选情数据上显著减少了党派偏见和不公正现象，相较于标准基线实现了2至3个数量级更低的方差。
### Conclusion
我们的结果表明，Agentmandering不仅提高了公平性，还提高了稳定性，特别是在选情均衡州的场景下。我们的代码在如下链接中提供：[提供链接的网址]。
## 8. `cs.AI` - 不同的分词算法如何影响LLMs和Transformer模型在二进制代码分析中的性能 [PDF](https://arxiv.org/pdf/2511.03825), [HTML](https://arxiv.org/abs/2511.03825)
### Authors
Ahmed Mostafa,Raisul Arefin Nahid,Samuel Mulder
### Background
分词是汇编代码分析的基础，影响词汇量、语义覆盖范围和下游任务性能等内在特征。尽管重要，汇编代码分词仍是一个未充分探索的领域。本文通过评估分词模型及其参数选择（如词汇量大小）的内在属性，填补了这一空白。我们探索了适用于汇编代码独特特性的预处理定制选项和预分词规则，并评估了它们对函数签名预测等下游任务的影响。研究基于分词效率、词汇压缩和表示忠实度评估多种分词模型，使用最新的预训练模型进行评估，结果显示，分词器选择对下游性能有显著影响，内在指标虽不能完全预测外部评估结果，但也揭示了内在分词器属性与实际汇编代码任务之间复杂的权衡关系。
### Innovation
本文首次系统性分析了不同分词模型及其参数选择对汇编代码分析中LLMs和Transformer模型性能的影响。探索了对汇编代码特有的前处理定制选项和预分词规则，并评估其对下游任务（如函数签名预测）的影响。使用最新预训练模型进行评估，揭示了内在分词器属性与实用的汇编代码任务之间的复杂权衡关系。
### Conclusion
本文提供了一线洞察，如何优化分词模型以适应低级代码分析，为基于自然语言模型（NLM）的二进制代码分析流程的健壮性和可扩展性做出了贡献。
## 9. `cs.AI` - 在Multi-Agentic AI轨迹中检测静默失败 [PDF](https://arxiv.org/pdf/2511.04032), [HTML](https://arxiv.org/abs/2511.04032)
### Authors
Divya Pathak,Harshit Kumar,Anuska Roy,Felix George,Mudit Verma,Pratibha Moogi
### Background
Multi-Agentic AI系统，由大型语言模型（LLMs）驱动，本质上是非确定性的，并且容易出现如漂移、循环和输出缺失细节等难以察觉的故障。这些故障很难检测，为保障系统的稳定性和可靠性带来挑战。本文的研究背景在于，面对这些难以检测的故障，需要提出有效的检测方法以保障系统的运行状态。通过引入在代理行为轨迹中检测异常的任务，旨在发现这些故障，进而为这些系统的行为监测和维护提供支持。为此，作者开发了一个数据集编排流程，以捕捉用户行为、代理的非确定性和LLM变量。通过此流程，建立了两个基准数据集，包含4,275和894条Multi-Agentic AI系统的轨迹。
### Innovation
本文的创新在于提出了在Multi-Agentic AI系统代理行为轨迹中检测异常的任务，并提供了一个数据集编排流程来捕捉用户行为、代理的非确定性和LLM变量。通过该数据集，作者验证了监督学习方法（如XGBoost）和半监督学习方法（如SVDD）的准确性，实现了高达98%和96%的准确率，从而为该领域的研究提供了第一个系统性的研究。
### Conclusion
本文通过引入在代理行为轨迹中检测异常的方法，为Multi-Agentic AI系统提供了系统的异常检测方法，并提供了两个基准数据集，使得相关研究可以在此基础上进一步发展。未来的研究可以通过继续优化这些方法和数据集，进一步提升检测的准确性和效率。
## 10. `cs.AI` - 通过经验合成扩展代理学习 [PDF](https://arxiv.org/pdf/2511.03773), [HTML](https://arxiv.org/abs/2511.03773)
### Authors
Zhaorun Chen,Zhuokai Zhao,Kai Zhang,Bo Liu,Qi Qi,Yifan Wu,Tarun Kalluri,Sara Cao,Yuanhao Xiong,Haibo Tong,Huaxiu Yao,Hengduo Li,Jiacheng Zhu,Xian Li,Dawn Song,Bo Li,Jason Weston,Dat Huynh
### Background
虽然强化学习（RL）可以通过互动使大规模语言模型（LLM）代理实现自我改进，但其实现仍然面临诸多挑战，包括高昂的成本、有限的任务多样性和不可靠的奖励信号，以及复杂的基础设施。所有这些因素都会阻碍大规模经验数据的收集。为了应对这些挑战，本文介绍了一种名为DreamGym的新框架，该框架旨在综合多样化的经验，以确保大规模可扩展的强化学习训练。DreamGym不依赖昂贵的真实环境演练，而是将环境动力学转变为基于推理的经验模型，通过逐步推理提取一致的状态转换和反馈信号，从而实现高效的大规模代理演练数据收集。
### Innovation
DreamGym引入了一种新的方法来合成多样的经验，该方法通过逐步推理来自我生成一致的状态转换和反馈信号，从而实现大规模可扩展的强化学习训练。它还利用离线真实数据初始化经验重放缓冲区，并持续添加新的互动来支持代理训练。此外，DreamGym可以自适应地生成新的任务来挑战当前的代理策略，从而实现更有效的在线课程学习。实验结果显示，DreamGym显著提高了强化学习训练的效果，在全合成设置和仿真到现实的过渡场景中均表现出色。对于非强化学习准备的任务，DreamGym的表现比所有基线高出30%以上。在成本较高的强化学习准备但实际中较困难的场景中，使用仅合成互动，它就能达到与GRPO和PPO相同的性能。当将仅基于合成经验训练的策略转移到实际环境的强化学习时，DreamGym在需要较少实际互动的情况下提供了显著的性能增益，这提供了一种通用强化学习的可扩展预热策略。
### Conclusion
DreamGym通过合成多样的经验，解决了大规模经验数据收集的挑战，有效提高了强化学习训练的质量和效率。对于各种环境和代理架构，实验结果表明，DreamGym在全合成设置和仿真到现实的过渡场景中都能显著改善强化学习，甚至在未准备的强化学习任务上也表现出色。
## 11. `cs.AI` - Opus：工作流评估的定量框架 [PDF](https://arxiv.org/pdf/2511.04220), [HTML](https://arxiv.org/abs/2511.04220)
### Authors
Alan Seroul,Théo Fagnoni,Inès Adnani,Dana O. Mohamed,Phillip Kingston
### Background
本文介绍了一种名为Opus Workflow Evaluation Framework的工作流评估框架，它通过概率规范形式化量化了工作流的质量和效率。该框架将工作流的正确性、可靠性和成本整合进一个数学模型中，支持自动化工作流的评估、分类和优化，甚至可以集成到强化学习回路中指导工作流的发现和精炼。在此之前，业界需要一种能够直接比较、打分和优化工作流的综合方法，尤其是在现代自动化系统中。
### Innovation
该框架主要创新在于：1) 通过概率函数Opus Workflow Reward来估计预期性能；2) 通过Opus Workflow Normative Penalties来捕捉工作流在结构性、语义性以及信号相关性的质量；3) 提出统一的优化公式，在奖励和惩罚之间的权衡中识别和排名最佳工作流。这些创新点显著提升了工作流评估的科学性和实用性。
### Conclusion
本文提出了一种新的工作流评估框架Opus，该框架能够直接评估、分类和优化工作流，甚至能够简化在现代自动化系统和强化学习中的工作流发现与精炼过程。
## 12. `cs.AI` - 当激励剥夺了力量 [PDF](https://arxiv.org/pdf/2511.04177), [HTML](https://arxiv.org/abs/2511.04177)
### Authors
Claire Yang,Maya Cakmak,Max Kleiman-Weiner
### Background
激励是一种衡量代理控制其环境能力的指标，已在AI代理助手的研究中提出作为通用的目标无关准则。权前研究表明，在诸如家庭和医院等多人类环境中，AI协助是有前景的方式。然而，此前关于基于激励的协助工作主要假定代理在隔离地协助一个人类。作者通过引入开源多人类格网测试套件Disempower-Grid，展示了基于单个人类激励优化的辅助强化学习代理可能会显著减少另一人类对环境的影响和回报，一种我们称之为剥夺的现象，并分析了这种现象的产生条件以及联合激励避免剥夺但牺牲用户奖励的情况。
### Innovation
作者通过Disempower-Grid测试套件实证展示了单一个人类激励优化可能导致另一位人类的环境影响力和奖励显著下降，首次提出了‘剥夺’这一概念，并分析了剥夺现象出现的条件，证明了联合激励可以在避免剥夺的同时减少用户奖励。这项工作揭示了AI对齐社区中一个更广泛的挑战：在单代理场景中看起来对齐的没有目标准则，在多代理场景中可能产生偏差。
### Conclusion
作者的工作揭示了更广泛的挑战：在单代理场景中似乎对齐的目标准则，在多代理场景中可能会导致偏差。研究指出了通过联合激励可以缓解剥夺现象，但可能以牺牲用户奖励为代价。
## 13. `cs.AI` - KGFR: 结构化的知识图谱基础检索器 [PDF](https://arxiv.org/pdf/2511.04093), [HTML](https://arxiv.org/abs/2511.04093)
### Authors
Yuanning Cui,Zequn Sun,Wei Hu,Zhangjie Fu
### Background
大型语言模型（LLMs）在推理方面表现出色，但在回答知识密集型问题时存在局限性，原因在于它们的知识有限且缺乏上下文信息。现有方法依赖于微调的LLMs或基于GNN的检索器，这些方法受限于数据集特定的调优和在大型或未见过的图上的扩展性问题。
### Innovation
提出的LLM-KGFR协作框架结合了基于LLM的结构化检索器——知识图谱基础检索器(KGFR)。KGFR使用LLM生成的描述编码关系，并根据实体在其问题中的角色初始化实体，从而实现了未见过的知识图谱的零样本泛化。为了高效处理大型图，它采用异步逐步传播(＜br＞APP)，这一逐步扩展策略能够在限制高度节点的同时保留有信息性的路径。通过节点、边和路径级别接口，LLM可以迭代地请求候选答案、支持的事实以及推理路径，从而形成可控的推理循环。
### Conclusion
实验结果显示，LLM-KGFR在性能、可扩展性和泛化方面表现出色，提供了一个适用于知识图谱增强推理的实际解决方案。
## 14. `cs.AI` - 通过预测编码共享空间记忆 [PDF](https://arxiv.org/pdf/2511.04235), [HTML](https://arxiv.org/abs/2511.04235)
### Authors
Zhengru Fang,Yu Guo,Jingjing Wang,Yuang Zhang,Haonan An,Yinhai Wang,Yuguang Fang
### Background
多智能体系统中的智能体在部分可观测性和有限带宽的影响下，需要共享并重构一致的空间记忆，但这一过程常常导致协调失效。
### Innovation
该论文提出了一种多智能体预测编码框架，将协调视为减少智能体之间的相互不确定性最小化的过程。该框架利用网格细胞样度量作为内部空间编码，智能体通过自监督运动预测自发产生，以实现带宽高效通信机制和专门的神经群体，这些神经群体编码伙伴的位置，类似于 hippocampal 社交地心细胞。同时，该框架通过分层强化学习策略来积极探索以减少联合不确定性，提高了智能体在带宽限制下成功导航的能力，展示了卓越的鲁棒性，并提供了一个从共同的预测驱动中产生复杂社会表征的理论依据和生物学可能的框架，促进社会 collective 智能的形成和提升。
### Conclusion
这种通过预测编码共享空间记忆的方法，对于有限带宽下智能体间的高效沟通和协作提供了有效的解决策略，成功与否随着带宽的减少表现出了优雅的降级行为，与全广播基线相比表现出优越性。这为研究智能体之间的复杂社交表征提供了一个有理论基础和生物合理性的框架，展示了这些表征如何在共同的预测驱动下自发产生，从而促进社会集体智能的形成。
## 15. `cs.AI` - RLoop: 一种基于迭代策略初始化的自我改进框架，用于强化学习 [PDF](https://arxiv.org/pdf/2511.04285), [HTML](https://arxiv.org/abs/2511.04285)
### Authors
Zeng Zhiyuan,Jiashuo Liu,Zhangyue Yin,Ge Zhang,Wenhao Huang,Xipeng Qiu
### Background
尽管可验证奖励的强化学习（RLVR）在训练大型推理模型方面非常强大，但其训练动态包含一个关键挑战：强化学习过拟合，即模型获得训练奖励但丧失泛化能力。已有研究揭示，这主要由策略过度专业化和在训练过程中生成的多样化解决方案的灾难性遗忘驱动。标准优化会丢弃这些有价值的跨步骤策略多样性，从而导致泛化能力下降和遗忘问题。
### Innovation
我们提出了一个名为RLoop的自我改进框架，该框架基于迭代策略初始化，构建了自提升的机制。RLoop将标准训练过程转化为良性循环：首先使用RL从给定策略探索解决方案空间，然后筛选成功的轨迹创建专家数据集。该数据集通过拒绝采样微调（RFT）重新优化初始策略，为下一迭代提供更优的初始策略。通过这种探索和利用的迭代重初始化循环，能够将策略的临时变化转化为稳健的性能提升。实验表明，RLoop可以减少遗忘并大大提高泛化能力，相较于标准RL，平均准确性提升了9%，pass@32提升了超过15%。
### Conclusion
RLoop通过有效解决RL过拟合和遗忘问题，显著提升了强化学习模型的性能，展示了其在优化策略持续性的潜力。
## 16. `cs.AI` - AdversariaLLM：大语言模型鲁棒性研究统一和模块化工具箱 [PDF](https://arxiv.org/pdf/2511.04316), [HTML](https://arxiv.org/abs/2511.04316)
### Authors
Tim Beyer,Jonas Dornbusch,Jakob Steimle,Moritz Ladenburger,Leo Schwinn,Stephan Günnemann
### Background
大语言模型（LLM）的安全性和稳健性研究快速扩展，但已形成一个碎片化且经常有错误的实现、数据集和评估方法的生态系统。这种碎片化使得跨研究的可重复性和可比性变得困难，妨碍了有意义的进步。
### Innovation
介绍了一种工具箱AdversariaLLM，用于进行LLM劫持鲁棒性研究。该工具箱的设计以可重复性、正确性和可扩展性为中心。框架包含了十二种对抗攻击算法，集成了多个涵盖危害性、过度拒绝和有用性评估的基准数据集，以及通过Hugging Face提供的广泛开放权重LLM访问。此外，实施包含能够增强可比性和可重复性的高级特性，如计算资源跟踪、确定性结果和分布性评估技术。该工具箱还通过伴侣包JudgeZoo整合了评判功能，该包也可以独立使用。这些组件试图为透明、可比和可重复的大语言模型安全性研究建立坚实的基础
### Conclusion
这些组件共同旨在为大语言模型的安全性研究提供一个坚实的基础，使研究更加透明、可比和可重复。
## 17. `cs.AI` - 测试测试者：基于人类的语音AI测试平台质量评估 [PDF](https://arxiv.org/pdf/2511.04133), [HTML](https://arxiv.org/abs/2511.04133)
### Authors
Miguel E. Andres,Vadim Fedorov,Rida Sadek,Enric Spagnolo-Arrizabalaga,Nadescha Trudel
### Background
语音AI代理正迅速转向生产部署，但仍缺乏系统的测试可靠性方法。组织无法客观评估他们使用的测试方法（内部工具或外部平台）是否有效，随着语音AI每日交互次数达到数亿，这种测试质量评估的测量差距变得至关重要。本文提出了第一个通过以人为本的标准来评估语音AI测试质量的系统框架，该框架通过对接各种现有的心理测量技术（如两两比较生成Elo评级、自助法置信区间和置换测试）与严密的统计验证相结合，提供了可重复的度量指标，适用于任何测试方法。为了验证该框架并展示其用途，在三种领先的商用平台中进行了全面的实证评估，评估了21,600个人判断和45场模拟，并对60场对话进行了真实性验证。研究结果表明，通过本文提出的框架在统计上显著优于其他平台，最高性能平台Evalion的评估质量（f1分数）为0.92，而其他平台为0.73，模拟质量为0.61，其他平台为0.43。该框架使研究人员和组织能够实证验证任何平台的测试能力，为大规模语音AI部署提供必要的度量基础。相关材料被提供以促进可重复性和采用。
### Innovation
该研究提出了第一个通过以人为本的标准框架来评估语音AI测试质量，该框架结合了已有的心理测量技术与严格的统计验证方法，旨在填补测试方法可靠性评估的技术空白，并提供了一种可重复的评估指标，能够有效评价各种测试方法。并通过大型实证测试验证了其在真实世界中的适用性与优越性。
### Conclusion
该框架使研究人员和组织能够实证验证任何平台的测试能力，为语音AI的规模部署提供了必要的度量基础，有助于提高语音AI系统的可靠性与用户体验。相关材料的公开有助于科研工作的可重复性和实际应用的便捷性。
## 18. `cs.AI` - GUI-360: 一种全面的数据集和基准测试用于计算机使用代理 [PDF](https://arxiv.org/pdf/2511.04307), [HTML](https://arxiv.org/abs/2511.04307)
### Authors
Jian Mu,Chaoyun Zhang,Chiming Ni,Lu Wang,Bo Qiao,Kartik Mathur,Qianhui Wu,Yuhang Xie,Xiaojun Ma,Mengyu Zhou,Si Qin,Liqun Li,Yu Kang,Minghua Ma,Qingwei Lin,Saravan Rajmohan,Dongmei Zhang
### Background
该论文背景指出，计算机使用代理（CUAs）在现实世界中面临独特挑战，并且存在三个持续存在的差距：与实际任务的稀缺性，多模态轨迹自动收集和注解管道的缺失，以及一个集成评估GUI引脚、屏幕解析和行为预测的统一基准。这些差距导致现有模型在CUAs方面存在局限性，尤其是行为引脚和行为预测方面的能力不足，即使经过监督微调或强化学习也未能达到人类级别的可靠性。因此，研究者引入了GUI-360°，旨在克服现有数据集和评估方法的不足，推动计算机使用代理领域的发展。
### Innovation
GUI-360°是一个大规模且全面的CUAs数据集和基准测试集，通过LLM增强的方式，实现了从查询获取到环境模板构建，再到任务实例化和批量执行，以及LLM驱动的质量过滤的自动化流程。该数据集涵盖超过120万执行的动作步骤，包括来自主流窗口办公应用的数千个轨迹，支持高分辨率截屏，可获得的可访问性元数据，以及具象化的目标、中间推理轨迹和成功与未成功的动作轨迹。此创新方法不仅填补了现有数据集的空缺，还支持三个核心任务：GUI引脚、屏幕解析、行为预测以及一个反映现代代理设计的GUI+API行为空间。
### Conclusion
通过在GUI-360°上对最先进的视觉语言模型进行基准测试，研究发现这些模型在引脚和行为预测方面存在明显的开箱即用的不足；即便经过监督微调或强化学习，模型也未完全达到人类级别的可靠性。因此，研究者建议通过提供GUI-360°数据集及配套代码，以促进可复现研究，加速构建稳健的桌面CUAs的进度。
## 19. `cs.AI` - RxSafeBench: 在模拟会诊中识别大型语言模型的药物安全性问题 [PDF](https://arxiv.org/pdf/2511.04328), [HTML](https://arxiv.org/abs/2511.04328)
### Authors
Jiahao Zhao,Luxin Xu,Minghuan Tan,Lichao Zhang,Ahmadreza Argha,Hamid Alinejad-Rokny,Min Yang
### Background
尽管大型语言模型（LLMs）驱动的医疗系统在多种医疗保健任务中取得了显著进展，但由于缺乏现实世界的数据集，受隐私和访问限制的影响，有关其药物安全性的研究仍相对有限。此外，在现实临床咨询环境中评估LLMs，特别是关于药物安全性方面，仍然存在不足。
### Innovation
本文提出了一个框架，用于模拟和评估临床咨询以系统地评估LLMs的药物安全性能力。框架中生成包含药物风险的问诊诊断对话，并建立了一个名为RxRisk DB的专门药物安全性数据库，包含6725个禁忌症、28781个药物相互作用和14906个适应症-药物对。采用两阶段过滤策略，确保临床现实性和专业质量，形成基准RxSafeBench，包含2443个高质量会诊情景。采用结构化的多项选择题评估顶级开源和专有LLMs，在模拟患者背景下测试它们推荐安全药物的能力。结果显示，当前的LLMs在整合禁忌症和相互作用知识方面存在困难，尤其是在风险隐含而非显式时。本文揭示了确保LLM系统中药物安全的关键挑战，并为改进可靠性提供了通过更好提示和针对特定任务的调整的见解。RxSafeBench提供了第一个全面的基准，用于评估LLMs在药物安全性方面的表现，有助于提升医疗决策支持中的更安全和可信的人工智能驱动系统。
### Conclusion
本文提出了一种框架，通过模拟和评估临床咨询，系统评估大型语言模型在药物安全性方面的表现。建立了RxSafeBench基准，为评估LLMs在药物安全性方面的表现提供了全面框架，推动了基于人工智能的临床决策支持系统的发展，提高了系统安全性和可靠性。
## 20. `cs.AI` - Monitor-Generate-Verify (MGV): 改造元认知理论用于语言模型推理 [PDF](https://arxiv.org/pdf/2511.04341), [HTML](https://arxiv.org/abs/2511.04341)
### Authors
Nick Oh,Fernand Gobet
### Background
现有的测试推理架构，如生成-验证范式，侧重生成和验证，但忽略了决定何时和如何开始推理的监控过程。这种缺失可能导致前缀主导陷阱，模型过早地承诺低效的推理路径，难以恢复，导致约20%的准确性损失。
### Innovation
本文通过将Flavell的和Nelson及Narens的元认知理论形式化为计算规范，提出了Monitor-Generate-Verify (MGV)框架。MGV扩展了生成-验证范式，增加了在生成开始前的显式监控，以及通过验证反馈来改进未来的监控。尽管没有提供实证验证，但这项工作首次系统地将元认知理论转化为计算规范，为理解推理系统失败提供了原则性的语言，并建议了未来的推理设计的具体架构改进。
### Conclusion
这项工作填补了推理系统架构的关键空白，提供了一种理解推理系统失败的框架，并为未来测试时推理设计的具体架构干预提供了建议，但未提供实证验证。
## 21. `cs.AI` - 探针的探查：概念对齐的方法和指标 [PDF](https://arxiv.org/pdf/2511.04312), [HTML](https://arxiv.org/abs/2511.04312)
### Authors
Jacob Lysnæs-Larsen,Marte Eggen,Inga Strümke
### Background
在可解释人工智能中，概念激活向量（CAVs）通常通过训练线性分类器探针来检测人类可理解的概念方向。人们普遍认为，高探针准确率意味着CAV忠实代表其目标概念。然而，该研究展示了仅依赖探针分类准确率来衡量概念对齐程度是不可靠的，实际上，探针更可能捕捉到无关的关联而不是仅代表目标概念。
### Innovation
该研究引入了一种基于空间线性归因的概念定位方法，并全面比较了该方法与现有特征可视化技术在检测和减轻概念对齐方面的能力。此外，提出了三种评估概念对齐性的度量标准：硬准确度、分割评分和增强稳健性。
### Conclusion
我们的研究发现，具有变化不变性和空间对齐性的探针一致提高了概念对齐性。这些发现强调了需要基于对齐的评估指标而非探针准确性，并强调了将探针调整到模型架构和目标概念性质的重要性。
## 22. `cs.AI` - 偏好中的危险：为何GRPO在序数奖励下失败 [PDF](https://arxiv.org/pdf/2511.04439), [HTML](https://arxiv.org/abs/2511.04439)
### Authors
Anisha Garg,Ganesh Venkatesh
### Background
GRPO因其简单性而在使大语言模型（LLMs）成为特定任务专家方面极具吸引力，但这种简单性也使其在试图通过更丰富、非二元的反馈来增强强化学习训练时变得不够明确。当使用序数奖励给部分正确性打分时，GRPO的简单性开始造成问题，因为其组平均水平基准经常给予失败轨迹正面评价并强化错误行为。
### Innovation
提出了一个新的名为CoRPO的公差相对策略优化公式，解决了这一缺陷。CoRPO使用自适应基准，确保失败解决方案不被正面强化。只要策略持续达到该阈值，基准就会自动转换为相对偏好模式，推动模型找到最优解而非仅仅“可接受”的解。在代码验证任务中，CoRPO展示了更稳定的收敛性和更好的领域外泛化能力。
### Conclusion
这项工作代表了我们更广泛研究计划中的关键一步，旨在通过强化学习使LLMs学习真正的新能力。我们通过使LLMs能够从丰富的多维度反馈中学习来实现这一点，在本文中从二元奖励发展到序数奖励，进一步到更密集的逐步骤监督。
## 23. `cs.AI` - 提高大型语言模型作为更好决策制定代理的后训练方法：一种最小后悔策略 [PDF](https://arxiv.org/pdf/2511.04393), [HTML](https://arxiv.org/abs/2511.04393)
### Authors
Chanwoo Park,Ziyang Chen,Asuman Ozdaglar,Kaiqing Zhang
### Background
大型语言模型（LLMs）现在常被作为“代理”用于决策制定（DM）任务，特别是在互动和动态环境中。然而，由于LLMs最初并非为决策制定而设计，它们在基本在线DM问题中表现不佳，未能实现低遗憾或有效的探索-利用权衡。因此，需要一种新的策略来提高它们的表现。
### Innovation
本文提出了迭代遗憾最小化微调（Iterative RMFT），这是一种后训练方法，通过反复将低遗憾决策轨迹回传到基础模型中微调模型。与以前的方法不同，该方法利用遗憾度量来激励模型自身的DM能力和推理机制，避免了僵化的输出工程，并提供了更灵活、自然语言的训练信号。实验结果显示，Iterative RMFT能够提升各种模型（如带有数值输入/输出的Transformer、开放权重LLMs和先进的封闭权重模型如GPT-4o min）的DM表现。此外，该方法在输出和推理格式上的灵活性使它能够在具有不同时间框架、动作空间、奖励过程和自然语言上下文的任务中实现泛化能力。
### Conclusion
本文提供了一种原理性的、通用的后训练框架（Iterative RMFT），旨在提升LLMs的决策制定能力。该框架展示了单层Transformer在简化环境下的无遗憾学习能力。
## 24. `cs.AI` - 超越最短路径：基于语义上下文的自主车辆路径规划 [PDF](https://arxiv.org/pdf/2511.04464), [HTML](https://arxiv.org/abs/2511.04464)
### Authors
Carnot Braun,Rafael O. Jarczewski,Gabriel U. Talasso,Leandro A. Villas,Allan M. de Souza
### Background
传统的车辆路径优化系统能够高效地优化单一指标，如时间或距离，但在考虑多个指标时，需要更多的优化过程，并且缺乏对人类驾驶员复杂的、语义的、动态的上下文的理解能力，如多步骤任务、情境约束或紧急需求。这些系统难以处理多目标问题，例如同时优化时间和二氧化碳排放量。因此，当面对实际城市场景中的多个复杂目标时，系统往往需要进行复杂的调整和优化，以满足用户的需求和偏好，从而导致路径选择的准确性和适应性不足。
### Innovation
本文提出了一种名为PAVe (Personalized Agentic Vehicular Routing)的混合自主代理助手，它通过结合经典路径规划算法和基于大语言模型（LLM）的语义推理层，能够处理多目标问题并适应真实城市环境中的复杂需求。PAVe利用多目标（时间、CO2）Dijkstra算法生成的候选路线集，并通过预处理的地理位置数据中的城市兴趣点（POIs）信息对这些路线进行评估，进一步考虑用户任务、偏好和避障规则。这种方法在实际城市场景中的验证显示了其高准确性和适应性，成功将复杂的用户意图融入到路径调整中，并实现了超过88%的初始路径选择准确性，采用了局部模型。
### Conclusion
结合经典路径规划算法和基于大语言模型的语义推理层，是创建个性化、适应性强、可扩展的都市交通优化解决方案的一种稳健而有效的方法。PAVe在实际城市场景中的表现证明了这一点，不仅提高了路径选择的准确性，还增强了系统的灵活性和响应性。
## 25. `cs.AI` - 优化城市雨水管道传感器布局：一种基于数据驱动的稀疏传感方法 [PDF](https://arxiv.org/pdf/2511.04556), [HTML](https://arxiv.org/abs/2511.04556)
### Authors
Zihang Ding,Kun Zhang
### Background
城市地表水洪涝越来越多地由排水系统无法承受的强降雨引发，尽管需要在高空间和时间分辨率下进行洪水预测和监测，但时间、预算和技术的限制阻碍了其全面实施。如何在资源受限的条件下优化传感器布局并预测排水网络的流量条件是一个重大挑战。
### Innovation
本研究提出了一种基于数据驱动的稀疏传感（DSS）框架，结合EPA-SWMM模型，通过伍德兰大街流域作为案例研究，优化传感器布局并重构地表水系统中洪峰流量。该框架利用奇异值分解（SVD）进行维数减少，QR分解进行传感器分配，以模拟训练数据集为基础，确定最优监测节点，并通过与SWMM获得的结果进行比较来验证这些监测节点的代表性。
### Conclusion
在77个节点中优化放置的3个传感器实现了令人满意的重构性能（Nash-Sutcliffe效率值在0.92-0.95之间）。模型在测量不确定性方面显示出良好的鲁棒性，传感器故障的鲁棒性取决于位置且随着部署传感器数量的增加而提高。该DSS框架平衡了计算效率和物理可解释性，能够以最少的传感器实现高精度的流量重构。该框架可进一步与预测模型集成，以在有限的传感和监测资源下实现洪涝预警和实时控制。
## 26. `cs.AI` - 大型语言模型在博弈论实验中复制和预测人类合作行为 [PDF](https://arxiv.org/pdf/2511.04500), [HTML](https://arxiv.org/abs/2511.04500)
### Authors
Andrea Cera Palatsi,Samuel Martin-Gutierrez,Ana S. Cardenal,Max Pellert
### Background
大型语言模型（LLMs）在决策制定和模拟人类行为方面应用广泛，但它们是否能准确反映人类的实际决策模式仍然不清楚。这对实际应用中的潜在危害和模拟人类行为的无效性提出了疑问。研究人员开发了一种博弈论实验的数字孪生体，并提出了一种系统的提示和探测框架以评估机器行为。通过测试三种开源模型（Llama、Mistral 和 Qwen），发现 Llama 能够以高精度模拟人类合作模式，而 Qwen 接近纳什均衡预测。研究人员通过生成并预注册可测试的假设，扩展了原有人类测试游戏的范围，证明了适当校准的语言模型能够复制人类行为的模式，并为探索未开发的实验空间提供了系统的方法，指出了它们在社会和行为科学中的补充研究方法，能够产生关于人类社会决策的新经验预测。
### Innovation
开发了一种博弈论实验的数字孪生体，提出了一种系统的提示和探测框架以评估机器行为；通过测试多种开源模型，发现某些模型能够以高精度模仿人类合作模式；生成并预注册可测试的假设，扩展了原有人类测试游戏的范围，简化了模拟过程；通过适当的校准，大型语言模型能够描绘并探索新的实验空间，提供了一个新的研究方法来预测人类社会决策。
### Conclusion
适当校准的大规模语言模型能够准确模仿人类行为模式，并为不可探索的实验空间提供了系统研究方法，为社会和行为科学领域提供了新的经验预测，展示了大型语言模型在复制和预测人类合作行为方面的潜力。
## 27. `cs.AI` - 我们在问对问题了吗？关于表格数据分析中自然语言查询的歧义问题 [PDF](https://arxiv.org/pdf/2511.04584), [HTML](https://arxiv.org/abs/2511.04584)
### Authors
Daniel Gomm,Cornelius Wolff,Madelon Hulsebos
### Background
自然语言接口对表格数据的操作必须处理查询中固有的歧义。过去，人们往往将歧义视为系统的不足，而非看作双方合作的特征。研究表明，这种合作可以使查询定义的责任在用户和系统之间共享。现有的评估框架在处理不同类型查询时存在歧义，这种处理方式不足以准确评估系统的执行精度或解释能力，也不足以全面考虑查询处理中的合作必要性。论文通过提出一个原则性框架来区分合作查询与非合作查询，对15个流行的数据集进行了评估与分析，揭示了当前查询处理评估的不足之处，从而改变对歧义的看法，强调合作在查询解决中的重要性。
### Innovation
提出了一个区分合作查询与非合作查询的框架，通过分析15个数据集的查询，揭示了当前查询处理评估的局限性，强调了合作在解决查询中的重要性，为自然语言接口设计与评估提供了新的视角和方向。
### Conclusion
论文的研究表明，解决查询中的歧义不应仅仅被视为需要修复的问题，而应被看作是一个合作的过程，其中用户和系统共同承担责任。这一反思有助于更好地设计和评估针对表格数据的自然语言接口，并对未来的研究方向提出了建议和展望。
## 28. `cs.AI` - 使用统计方法探索电子商务平台上的网络攻击模式 [PDF](https://arxiv.org/pdf/2511.03020), [HTML](https://arxiv.org/abs/2511.03020)
### Authors
Fatimo Adenike Adeniya(York St John University, London Campus, London, United Kingdom)
### Background
电子商务平台的网络攻击越来越复杂，威胁到了消费者的信任度和运营的连续性。本文通过应用Verizon Community Data Breach (VCDB) 数据集，研究利用统计建模和机器学习技术来检测和预测电子商务领域的网络攻击模式的方法。研究发现，假期购物活动期间经历的网络攻击比非假期时期严重得多，并且采用的CatBoost模型在多个指标上表现最佳，因此提高了网络攻击预测的准确性，有助于提前预见攻击风险和分类攻击类型。
### Innovation
本文提出了一种结合了统计建模和机器学习的混合分析框架，具有季节性预测和可解释集成学习的特点，能够预见时间风险和攻击类型分类，增强了对未来网络攻击的预防措施。此外，还考虑了伦理问题，例如敏感数据的负责任使用和偏见评估。
### Conclusion
尽管存在数据类别不平衡和依赖历史数据的问题，这项研究仍提供了预见性网络安全资源配置的见解，并指出了实时威胁检测研究的未来方向。
## 29. `cs.AI` - Jr. AI Scientist 和其风险报告：基于基线论文的自主科学研究 [PDF](https://arxiv.org/pdf/2511.04583), [HTML](https://arxiv.org/abs/2511.04583)
### Authors
Atsuyuki Miyai,Mashiro Toyooka,Takashi Otonari,Zaiying Zhao,Kiyoharu Aizawa
### Background
确保AI驱动的科学进步的可信性和可持续性需要理解当前AI科学家系统的功能和风险，同时维护学术生态系统的完整性。为此，开发了Jr. AI科学家系统，该系统模仿了初级学生研究人员的核心研究流程。而此前的研究大多假设了完全自动化或仅针对小规模代码的操作，Jr. AI科学家遵循一个明确的研究流程，并借助现代编码代理来处理复杂、多文件的实现，从而实现科学上的贡献。该文通过自动评估、作者主导的评估和向专门用于AI驱动科学贡献的Agents4Science提交来评估Jr. AI科学家的表现，结果显示其生成的论文得到了更高的评审分数，但也指出了其重要限制，显示了当前AI科学家系统的潜在风险和未来研究的关键挑战。开发过程中还全面报告了识别的各种风险，希望能加深对AI科学家开发中的进展和风险的理解。
### Innovation
Jr. AI科学家系统模仿了初级学生研究人员的核心研究流程，通过分析基线论文的局限性、提出创新假设并通过严格实验验证，最终撰写论文以展示结果。它不同于以前的完全自动化系统或仅处理小型代码的方法，而是采用了一个明确的研究工作流程，并使用现代编码代理来处理复杂的、多重文件的实现，实现了科学上的贡献。
### Conclusion
Jr. AI科学家在Manual Reviewer、作者主导的评估和向Agents4Science的提交中，生成的论文获得了比现有完全自动化系统更高的评审分数。然而，作者评估和Agents4Science的评审也指出了其重要局限和潜在风险，表明直接应用当前AI科学家系统存在风险，未来研究的关键挑战也得到了明确。这些发现旨在加深对当前AI科学家开发所取得的进展和面临的风险的理解。
## 30. `cs.AI` - DR. WELL: 动态推理和基于符号世界模型的学习在化身LLM基础的多智能体协作中的应用 [PDF](https://arxiv.org/pdf/2511.04646), [HTML](https://arxiv.org/abs/2511.04646)
### Authors
Narjes Nourzad,Hanqing Yang,Shiyu Chen,Carlee Joe-Wong
### Background
合作性的多智能体规划需要智能体在部分信息和有限通信的情况下做出联合决策，但由于轨迹级别的协调经常会失败，即使是轻微的时间或运动偏差也会引发冲突。通过提高抽象层次和提供一套基础的动作词汇来实现同步和集体进步的符号规划可以缓解这一挑战。
### Innovation
提出了一种去中心化的神经-符号框架DR. WELL，用于合作性的多智能体规划。这种框架经过两个阶段的协商协议运作：首先，智能体提出候选角色并进行推理，然后在达成共识和环境约束的情况下将角色进行分配。分配后，每个智能体独立生成并执行与其角色相对应的符号计划而不泄露详细的轨迹信息。所有计划基于一个共享的世界模型进行实际执行，该模型编码当前状态并在智能体行动时被更新。通过在符号计划而非原始轨迹的基础上进行推理，DR. WELL 避免了基于步骤的弱对齐，并支持高抽象级别的可重用、可同步和可解释的操作。
### Conclusion
实验结果表明，DR. WELL 在合作性积木推动任务中的适应性提高，动态世界模型捕捉到可重用的模式并提高了任务完成率和效率。通过协商和自我完善，动态世界模型提供了一种时间开销逐渐提高，但协作策略却越来越高效的动态方法。
## 31. `cs.AI` - 基于仿真验证的集成4D/5D数字孪生框架的预测性施工控制 [PDF](https://arxiv.org/pdf/2511.03684), [HTML](https://arxiv.org/abs/2511.03684)
### Authors
Atena Khoshkonesh,Mohsen Mohammadagha,Navid Ebrahimi
### Background
美国建筑行业的成本和时间偏差持续存在，显示了确定性CPM和静态文档估算的局限性。
### Innovation
本研究提出了一种结合BIM与NLP成本映射、计算机视觉进度测量、贝叶斯概率CPM更新和深度强化学习资源调度的集成4D/5D数字孪生框架。
### Conclusion
此项九个月的案例研究表明，该集成框架在估算劳动力减少43%、减少6%的加班时间、项目缓冲使用率降低30%的同时，以128天的完成时间保持在P50-P80置信区间内按时完成。数字孪生沙箱还实现了实时‘如果...会发生什么’的预测和可追溯的成本-时间对齐性，验证了结合AI分析、概率CPM和DRL对未来预测、透明度和控制韧性提升的作用。
## 32. `cs.AI` - VeriCoT：通过逻辑一致性检查进行神经符号链式推理验证 [PDF](https://arxiv.org/pdf/2511.04662), [HTML](https://arxiv.org/abs/2511.04662)
### Authors
Yu Feng,Nathaniel Weir,Kaj Bostrom,Sam Bayless,Darion Cassel,Sapana Chaudhary,Benjamin Kiesl-Reiter,Huzefa Rangwala
### Background
大型语言模型（LLMs）可以通过链式思考（CoT）执行多步推理，但它们不能可靠地验证其自身的逻辑。即使它们得到了正确的答案，内在的推理可能仍然存在缺陷，特别是在高风险场景中降低了对其的信任。为了解决这一问题，本研究引入了VeriCoT，这是一种神经符号方法，能够从CoT推理中提取并验证正式的逻辑论据。VeriCoT将每个CoT推理步骤形式化为一阶逻辑，并识别出支持论证的基础前提，包括源上下文、常识知识或先前的推理步骤。这种符号表示形式使得自动求解器能够验证逻辑的有效性，而自然语言前提则让人类和系统能够识别到未受支持或谬误的推理步骤。
### Innovation
VeriCoT 是一种通过逻辑一致性检查进行神经符号链式推理验证的方法。它将 CoT 推理步骤形式化为一阶逻辑，识别基础前提，并使用符号表示形式与自然语言前提结合，确保推理的有效性。此外，VeriCoT 的验证信号被用于推理时的自我反思，监督微调（SFT）以及使用验证为基础的成对奖励进行直接偏好优化的偏好微调（PFT），进一步提高了推理的有效性和准确性。
### Conclusion
实验结果表明，VeriCoT 能够有效识别推理中的缺陷，并作为最终答案正确性的强大预测器。VeriCoT 的验证信号还被用于推理时的自我反思、监督微调（SFT）和偏好微调（PFT），从而进一步提高推理的有效性和准确性。
## 33. `cs.AI` - MazeMate: 一个基于LLM的聊天机器人，用于支持游戏化编程学习中的CT [PDF](https://arxiv.org/pdf/2511.03727), [HTML](https://arxiv.org/abs/2511.03727)
### Authors
Chenyu Hou,Hua Yu,Gaoxia Zhu,John Derek Anas,Jiao Liu,Yew Soon Ong
### Background
计算思维（CT）是一种基础性的问题解决技能，而游戏化的编程环境是培养这种技能的常见方法。当前，虽然大型语言模型（LLMs）能够提供即时编程支持，但很少用于促进CT的发展。本文介绍了一个名为MazeMate的LLM驱动聊天机器人，嵌入到一个三维迷宫编程游戏中，旨在提供适应性、上下文敏感的支撑，与迷宫解和设计过程中的CT过程相匹配。
### Innovation
MazeMate通过将LLM集成到游戏环境中，提供了一种新颖的方法来支持CT的发展。提供的支持是适应性的和上下文敏感的，旨在与迷宫解和设计过程中的CT过程相匹配。这种设计方法强调了基于LLM的支持在实际课堂环境中的应用潜力。
### Conclusion
实验结果表明，MazeMate对学生在迷宫解方面有所帮助，但在迷宫设计方面的支持有限，包括建议不匹配和伪造的算法解决方案。这些发现显示了基于LLM的支撑在支持CT方面的潜力，并指出了进一步改进设计的方向，以提高MazeMate在真实课堂环境中的易用性。
## 34. `cs.AI` - 推动可持续的网络代理：基于实证和理论分析的基准测试和能源消耗估算 [PDF](https://arxiv.org/pdf/2511.04481), [HTML](https://arxiv.org/abs/2511.04481)
### Authors
Lars Krupp,Daniel Geißler,Vishal Banwari,Paul Lukowicz,Jakob Karolus
### Background
网络代理，如OpenAI的Operator和Google的Project Mariner，是强大的代理系统，突破了大型语言模型（LLM）的界限。它们能够根据用户的指令自主与互联网交互，如导航网站、填充搜索框和比对价格列表。尽管网络代理研究正在繁荣发展，但它们引发的可持续性问题却仍未得到充分探索。
### Innovation
本文通过理论估算和实证基准测试，首次探讨了网络代理的能源和$CO_2$成本。研究结果表明，不同网络代理创建理念对耗费的能源有严重影响，能耗高并不一定意味着更好的结果。本文还揭示了在估算能耗时因缺乏透明度而无法公开模型参数和过程的问题。研究工作推动了网络代理评估方式的改变，提倡在基准测试中引入专门衡量能源消耗的指标。
### Conclusion
本文贡献在于提出一种新的评估网络代理方法，强调了在基准测试中测量和评估能源消耗的重要性，为后续研究提供方向。
## 35. `cs.AI` - 基于卷积神经网络的模型类别选择深度学习方法 [PDF](https://arxiv.org/pdf/2511.03743), [HTML](https://arxiv.org/abs/2511.03743)
### Authors
Marios Impraimakis
### Background
研究了一种新颖的卷积神经网络方法的仅响应模型类别选择能力。该方法利用单一自由度的回答及其类别信息来训练和验证一维卷积神经网络，无需系统输入信息或完整的系统识别。
### Innovation
网络能够在信号仅有少量变化时选择新的、未标记的信号的模型类别，无需系统输入信息或完整的系统识别。该方法对于具有阻尼行为或迟滞行为的线性和非线性动态系统，以及三维建筑有限元模型，都展示了良好的选择模型类别的能力。
### Conclusion
此方法能够为结构健康监测应用提供一个强有力的工具，特别是在信号微小变化中区分不同模型类别的能力突出。
## 36. `cs.AI` - 并非所有解释都等同：探究当前XAI评估中的陷阱 [PDF](https://arxiv.org/pdf/2511.03730), [HTML](https://arxiv.org/abs/2511.03730)
### Authors
Joe Shymanski,Jacob Brue,Sandip Sen
### Background
解释性人工智能（XAI）旨在通过向人类用户提供解释来提高现代AI模型的透明度。目前用于评估这些XAI模型质量的方法多种多样，包括用户研究或提出的客观指标如“真实度”，但这些方法往往是临时且不够通用的。大多数研究仅通过简单的用户调查来分析没有解释和使用提议方案生成的解释之间的差异。我们认为这种方法无法充分证明生成的解释质量，因为任何形式的解释与没有解释相比会带来更好的结果。因此，该研究旨在揭示这一误区：无论质量或正确性如何，任何解释都会提高用户满意度。
### Innovation
研究提出强调可操作解释的重要性，并通过棋类教学代理助手的案例研究验证了该主张的有效性。研究呼吁XAI领域的相关研究采用更全面的评价技术，以证明解释质量不仅限于用户满意度。
### Conclusion
研究结果提供了一个在XAI领域采取行动的呼吁，即对未来的解释质量进行超出用户满意度范围的证明。此外，研究还分析了安慰或可操作解释在何种场景中最为有用。
## 37. `cs.AI` - 超越聊天：以人为本的大型语言模型支持系统框架 [PDF](https://arxiv.org/pdf/2511.03729), [HTML](https://arxiv.org/abs/2511.03729)
### Authors
Zhiyin Zhou
### Background
大型语言模型正在从简单的交易性问答扩展到作为同伴、教练、调解人和内容管理员的角色，支持人类的成长、决策和福祉。当前的研究旨在提出一个以人类为中心的大型语言模型支持系统的角色框架，对比了实际部署在不同领域的应用案例，并确定了跨领域的设计原则：透明性、个性化、边界保护、隐私保留的记忆和情感可靠性的平衡。
### Innovation
该论文提出了一个角色框架来构建以人类为中心的大型语言模型支持系统，强调了从简单任务回答向更复杂角色（如同伴和导师）转变的重要性。框架中提出了五个关键设计原则：透明性、个性化、社交边界（guardrails）、私人记忆的使用以及情感可靠性的平衡，并扩展了对评估模型性能的指标，不仅限于准确性，还包括信任、用户参与和长期效果。同时，该框架还对潜在风险进行了分析，并提出了未来发展的方向。
### Conclusion
研究的目标是为敏感领域中的人类提供负责任的大型语言模型集成支持，不在仅仅是提供答案。研究提出了具体的跨领域设计原则和评估方法，并对未来的研究方向进行了展望，涵盖统一评估、人机混合模型、记忆架构、跨域基准测试和治理等方面。
## 38. `cs.AI` - 使用Hyperchat AI在实际预测任务中的对话型集体智能 (CCI) [PDF](https://arxiv.org/pdf/2511.03732), [HTML](https://arxiv.org/abs/2511.03732)
### Authors
Hans Schumann,Louis Rosenberg,Ganesh Mani,Gregg Willcox
### Background
Hyperchat AI是一种新的代理技术，允许网络化的大型人类团队进行深入的对话，讨论复杂问题，头脑风暴，揭示风险，评估替代方案，并逐步趋同于优化解决方案，以增强群体的集体智能（CI）。论文通过一项正式研究探讨了使用Hyperchat AI进行实时对话来预测职业棒球大联盟（MLB）比赛结果的能力。
### Innovation
研究采用了一种新的方法，利用Hyperchat AI中的人工智能代理技术，促使网络化的体育迷团队进行实时对话，预测MLB比赛的结果。这种方法显著提高了预测的准确性，甚至超过了浅层的博彩市场计划。
### Conclusion
实验结果表明，使用Hyperchat AI进行高信心预测的群体准确率为78%，远超博彩市场的57%。如果这些群体根据预测投注，有可能获得46%的回报率。并且，高质量对话产生的高信心预测准确率高达88%，这表明实时互动讨论是提高预测准确性的重要因素。
## 39. `cs.AI` - MimiTalk：以双代理人AI革新定性研究 [PDF](https://arxiv.org/pdf/2511.03731), [HTML](https://arxiv.org/abs/2511.03731)
### Authors
Fengming Liu,Shubin Yu
### Background
本文介绍了MimiTalk，这是一种旨在社会科学中实现可扩展和伦理对话数据收集的双代理人宪法AI框架。该框架结合了一个监督模型和一个对话模型，以实现策略性监督和问题生成。作者通过一系列研究，探讨了MimiTalk在实际应用中的效果和优势，包括减少访谈焦虑、保持对话连贯性以及信息丰富度、一致性和稳定性等方面的效果，同时也指出了AI和人类访谈在技术见解获取和文化情绪捕捉方面的差异。
### Innovation
该研究提出了一种新的方法，通过双代理人AI框架支持领域研究中的有效人机协作，实现了可复制、可扩展和高质量控制的定性研究。MimiTalk通过结合监督模型和对话生成模型，提高了定性研究的效率和信息质量，为社会科学提供了新的研究工具和方法。
### Conclusion
研究结果表明，MimiTalk在减少访谈焦虑、保持对话连贯性以及信息丰富度、一致性和稳定性方面优于人类访谈，无论是在技术见解获取还是文化情绪捕捉方面，MimiTalk与AI访谈和人类访谈都能实现互补，从而支持高质量、可复制和可控的研究成果。
## 40. `cs.AI` - 通过自适应上下文管理实现高效的设备端代理 [PDF](https://arxiv.org/pdf/2511.03728), [HTML](https://arxiv.org/abs/2511.03728)
### Authors
Sanidhya Vijayvargiya,Rahul Lokesh
### Background
设备端的人工智能代理具有提供个性化、低延迟辅助的潜力，但其部署受到内存容量有限的限制，这限制了可用的上下文。这种有限的上下文窗口导致在支持复杂工具功能的丰富、状态化的交流与保持设备上的可行性之间产生权衡。论文提出了一种框架，通过三个协同优化来打破这一权衡：1) 使用专用于对话历史压缩的LoRA适配器构建动态内存系统；2) 使用高效序列化格式最小化每个工具的标记开销；3) 使用按需加载工具定义的机制，仅在选择工具时加载完整工具定义。
### Innovation
该框架通过三项关键优化解决了设备上AI代理在上下文管理上的挑战：1) 利用LoRA适配器动态内存系统压缩和结构化对话历史；2) 使用低标记开销的工具方案最小化序列化格式；3) 按需加载工具定义减少开销。这种方法显著减小了上下文占位，比传统基线在用户复杂任务中的性能相当或更优，同时证明了对上下文管理的精明策略是实现设备上具有能力和持久性的AI的关键。
### Conclusion
该框架通过适应性上下文管理实现了高效设备端代理，显著压缩了初始系统提示上下文和上下文增长速度，证明了局部和高效地管理上下文对于设备上持续和能力强大的AI的重要性。
## 41. `cs.AI` - 将时间序列深度学习模型应用于爱尔兰多年生黑麦草生长预测 [PDF](https://arxiv.org/pdf/2511.03749), [HTML](https://arxiv.org/abs/2511.03749)
### Authors
Oluwadurotimi Onibonoje,Vuong M. Ngo,Andrew McCarre,Elodie Ruelle,Bernadette O-Briend,Mark Roantree
### Background
草地是世界上第二大陆地碳汇，对生物多样性和碳循环调节起着关键作用。爱尔兰乳制品业是该国的重要经济支柱，但面临盈利性和可持续性的挑战。目前，草地生长预测主要依赖于不切实际的机理模型，本研究提出了一种适用于单变量数据的时间序列深度学习模型，以提供成本效益更高的替代方案。
### Innovation
研究提出一种基于时间卷积网络的模型，专门用于预测爱尔兰科克地区多年生黑麦草的生长情况。该模型利用了历史草高数据，表现良好，RMSE为2.74，MAE为3.46。模型在长达1757周（34年）的数据集上进行了验证，提供了有助于优化模型配置的见解，进一步提高了草生长预测的可靠性。
### Conclusion
本研究增强了我们对模型行为的理解，提高了草原生长预测的可靠性，对于推动可持续乳制品生产具有重要意义。该研究通过使用深度学习模型为爱尔兰草地可持续管理提供了新的见解和工具。
## 42. `cs.AI` - 质疑问题：在线审议过程中的代表审计 [PDF](https://arxiv.org/pdf/2511.04588), [HTML](https://arxiv.org/abs/2511.04588)
### Authors
Soham De,Lodewijk Gelauff,Ashish Goel,Smitha Milli,Ariel Procaccia,Alice Siu
### Background
许多审议过程，如公民会议和审议调查，为参与者提供直接与专家交流的机会。尽管参与者通常被邀请提出问题供专家小组讨论，但由于时间限制，只能选择有限的问题，这导致了一个如何选择最能代表参与者利益的小批量问题的挑战。
### Innovation
论文引入了一个审计框架，用于基于“正当代表”(JR)的社会选择概念来衡量问题集提供的代表水平。提出了适用于一般效用设置的审计JR的第一批算法，最高效的算法在时间复杂度上为$O(mntext{log}n)$。论文还应用了这些审计方法，对比了实际上提出到专家小组的问题、参与者使用整数线性规划选择的问题以及大型语言模型生成的总结性问题的代表性质，揭示了大型语言模型在支持审议过程中的前景和局限性。
### Conclusion
通过将这些方法集成到一个已在美国及其他多个国家使用的在线审议平台上，使实践者能够容易地审计和改进未来的审议过程中的代表性，突出展示了LLMs在支持审议过程中的潜力及其当前的限制。
## 43. `cs.AI` - OpenMENA:一个基于神经形态边缘AI应用的开源阻变存储器接口和计算板 [PDF](https://arxiv.org/pdf/2511.03747), [HTML](https://arxiv.org/abs/2511.03747)
### Authors
Ali Safa,Farida Mohsen,Zainab Ali,Bo Wang,Amine Bermak
### Background
边缘人工智能需要高效的能量消耗解决方案。阻变存储器交叉阵列能够实现内存计算和局部可塑性学习，为边缘AI提供了一条能效路径。然而，关于阻变存储器的研究更多集中在私有的硬件接口和封闭的软件栈，缺乏一个全面的开放系统，特别是针对实际应用如数字识别和机器人避障的任务优化。Open-MENA旨在填补这一空白，提供一个全面开放的阻变存储器接口系统，支持实际应用的研究和发展。
### Innovation
Open-MENA引入了一个可重复使用的硬件接口，该接口包含混合信号读-写-验证循环，支持阻变存储器交叉阵列；一个包含高级API的固件软件堆栈，用于推断和设备上的学习；以及一种名为VIPI的电位增量比例积分方法，用于将预先训练的权重编程到模拟阻抗中，并通过芯片在环中的微调来处理设备非理想性。这是首个结合这些组件的开放系统，为阻变存储器在边缘AI中的应用提供了完整的解决方案。
### Conclusion
OpenMENA已通过数字识别和实际机器人避障任务的测试验证，展示了从权重转移至本地适应的过程。并作为开源项目发布，旨在普及阻变存储器在边缘AI研究中的应用。
## 44. `cs.AI` - 使用Gramian Angular Fields的联邦学习在异构IoT设备上实现隐私保护ECG分类 [PDF](https://arxiv.org/pdf/2511.03753), [HTML](https://arxiv.org/abs/2511.03753)
### Authors
Youssef Elmir,Yassine Himeur,Abbes Amira
### Background
本研究在物联网（IoT）医疗环境中，提出了一种用于保护隐私的心电图（ECG）分类的联邦学习（FL）框架。通过将1D ECG信号转换为2D Gramian Angular Field（GAF）图像，利用卷积神经网络（CNNs）进行高效特征提取，同时确保敏感医疗数据保留在每个设备上，从而实现数据安全。本研究是首先通过实验证实了在异构物联网设备上基于GAF的联邦ECG分类的方法，该方法在性能和通信效率方面都有量化数据。
### Innovation
本研究的创新点在于：1. 首次在异构物联网设备上实验验证基于GAF的联邦ECG分类，通过量化性能和通信效率。2. 在边缘-云集成的真实物联网场景中部署框架，涵盖了服务器、笔记本电脑和资源受限的树莓派4，以评估其可行性。3. 实验结果显示，FL-GAF模型在多用户设置中达到95.18%的高分类精度，比单用户基线模型在准确性和训练时间上均有显著优势。
### Conclusion
本研究的结果强调了轻量级、隐私保护的人工智能在物联网医疗监控中的潜在价值，支持智能健康系统中的可扩展和安全的边缘部署。尽管增加了GAF转换的计算复杂性，但框架仍保持了有效的资源利用和通信开销。
## 45. `cs.AI` - 利用基于大语言模型的代理进行社会科学研究：从引文网络模拟中获得见解 [PDF](https://arxiv.org/pdf/2511.03758), [HTML](https://arxiv.org/abs/2511.03758)
### Authors
Jiarui Ji,Runlin Lei,Xuchen Pan,Zhewei Wei,Hao Sun,Yankai Lin,Xu Chen,Yongzheng Yang,Yaliang Li,Bolin Ding,Ji-Rong Wen
### Background
大型语言模型（LLMs）通过利用大量网络数据预训练来模拟人类行为中的逻辑和模式，但其在社会模拟中的能力边界尚不明确。本文旨在进一步探索LLMs的社会属性。
### Innovation
本文提出了一个名为CiteAgent的框架，该框架利用LLM生成基于人类行为模拟的引文网络。此外，本文还建立了一种基于LLM的社会科学研究范式，即LLM-SE和LLM-LE，这为分析引文网络现象提供了严格的实验方法。通过理想化社会实验的模拟结果，扩展了传统科学学研究的范围，提供了关于现实学术环境的重要见解。
### Conclusion
本文展示了LLMs在社会科学研究中的潜力，特别是在引文网络研究方面的应用。通过CiteAgent框架和新建立的研究范式，为验证和挑战现有理论提供了途径，同时也为引文网络研究提供了新的方法和视角。
## 46. `cs.AI` - OptiMA: 一种用于非常复杂的多智能体系统的基于事务的具有吞吐量优化的框架 [PDF](https://arxiv.org/pdf/2511.03761), [HTML](https://arxiv.org/abs/2511.03761)
### Authors
Umut Çalıkyılmaz,Nitin Nayak,Jinghua Groppe,Sven Groppe
### Background
近年来，多智能体系统的研究方向已转向探索更复杂更大的模型以完成复杂任务。在这个过程中，增加系统的复杂性可能导致两大问题：对故障更敏感和性能瓶颈。本文通过提出一个基于事务的框架和引入事务调度机制，来预防潜在的系统故障，并提高系统性能，进而可以管理拥有上百个智能体的复杂系统。
### Innovation
提出了一个新的基于事务的框架（OptiMA）并整合事务调度机制，用于支持非常复杂的多智能体系统。该框架不仅能够在实验证明中能够执行拥有超过一百个智能体的系统，还能通过提高性能吞吐量超过16%来展示事务调度的效果。此外，还对事务调度问题进行了理论分析，并提供了一系列实用工具支持未来的研究工作。
### Conclusion
通过构建OptiMA框架并实现事务调度解决方案，本文成功展示了如何有效管理及提高包含众多智能体的综合系统的性能和可靠性，为构建更复杂的多智能体系统提供了新的方法和实用工具。
## 47. `cs.AI` - 沿着标签树攀登：医疗成像中的层次保持对比学习 [PDF](https://arxiv.org/pdf/2511.03771), [HTML](https://arxiv.org/abs/2511.03771)
### Authors
Alif Elham Khan
### Background
医学图像标签通常按照分类体系组织（如器官-组织-亚型），但标准的自监督学习(SL)方法忽略了这种结构。本文背景在于现有方法未能充分利用标签树结构进行有效学习。
### Innovation
本文提出了一种保持层次结构的对比框架，使标签树成为训练和评估过程中的主要信号。具体创新点包括：引入两个插件目标，即层次加权对比（HWC），通过共享祖先调整正/负样本强度，促进同父类的一致性；层次感知差距（LAM），一种原型差距，可在不同层次上分离祖先组。该模型无需改变架构即可适用于欧几里得和双曲嵌入，且在多个基准测试中，与强大的自监督学习基线相比，提出了的目标在身份和可解释性方面始终表现出更好的表现。
### Conclusion
研究表明，即使在没有曲率的情况下，HWC和LAM也是有效的。结合这两种方法能产生最符合分类体系的表示。总之，研究结果提供了一个简单而通用的方法，用于学习尊重标签树的医学图像表示，并促进具有丰富层次结构领域的表现和可解释性。
## 48. `cs.AI` - 通过提示难度预测优化推理效率 [PDF](https://arxiv.org/pdf/2511.03808), [HTML](https://arxiv.org/abs/2511.03808)
### Authors
Bo Zhao,Berkcan Kapusuzoglu,Kartik Balasubramaniam,Sambit Sahu,Supriyo Chakraborty,Genta Indra Winata
### Background
推理语言模型在复杂任务上的表现优异，但因其规模庞大和较长的推理路径，导致部署成本高昂。本文的研究背景是探索如何在不牺牲准确性的基础上减少计算开销。
### Innovation
本文提出了一种路由策略，该策略将每个问题分配给最有可能解决它的最小模型。通过使用s1.1-32B的中间表示训练轻量级预测器，以指导推理模型间的路由。该方法在不同数学基准测试中提高了效率，实现了与s1.1-32B相当的表现，但计算资源消耗显著减少。
### Conclusion
研究结果表明，基于难度的路由策略在推理模型成本效益部署方面是有效的。
## 49. `cs.AI` - 专家评估LLM世界模型：高温超导体案例研究 [PDF](https://arxiv.org/pdf/2511.03782), [HTML](https://arxiv.org/abs/2511.03782)
### Authors
Haoyu Guo,Maria Tikhanovskaya,Paul Raccuglia,Alexey Vlaskin,Chris Co,Daniel J. Liebling,Scott Ellsworth,Matthew Abraham,Elizabeth Dorfman,N. P. Armitage,Chunhan Feng,Antoine Georges,Olivier Gingras,Dominik Kiese,Steven A. Kivelson,Vadim Oganesyan,B. J. Ramshaw,Subir Sachdev,T. Senthil,J. M. Tranquada,Michael P. Brenner,Subhashini Venugopalan,Eun-Ah Kim
### Background
大型语言模型（LLMs）在科学文献探索方面具有巨大的潜力，但它们在提供科学准确且全面地回答复杂问题方面的效果，特别是在专业领域，仍然是一个活跃的研究领域。本文使用高温铜氧化物领域作为一个范例，评估LLM系统在了解文献方面是否达到了专家级水平。为此，研究人员构建了一个包含1,726篇科学论文的专家定制数据库，涵盖了该领域的历史，并提出了67个专家设计的问题来测试对文献深入理解的程度。这些系统必须回答一系列精心设计的问题，并接受专家根据平衡视角、事实的全面性、简洁性和证据支持等方面的评估。
### Innovation
文中提出了一种使用高温超导体领域的专家定制数据库和问题集来评估LLM系统的创新方法。特别地，文中提到两种使用检索增强生成（RAG）系统的模型在全面性和支持性方面优于现成模型。这种方法为评估基于LLM的推理系统专家级性能提供了一个新的标准。此外，专家设计的问题集和评价标准也为以后的研究提供了参考工具。
### Conclusion
研究发现，使用检索增强生成（RAG）系统的两个模型在关键指标上表现更为出色，尤其是在提供全面且支持良好的答案方面。研究讨论了LLM性能的有希望的方面，同时也指出了所有模型存在的关键不足之处。专家设计的问题集和评价标准对于评估基于LLM的推理系统的专家级性能具有重要意义。
## 50. `cs.AI` - Laugh, Relate, Engage: Stylized Comment Generation for Short Videos [PDF](https://arxiv.org/pdf/2511.03757), [HTML](https://arxiv.org/abs/2511.03757)
### Authors
Xuan Ouyang,Senan Wang,Bouzhou Wang,Siyuan Xiahou,Jinrong Zhou,Yuekang Li
### Background
短视频平台已成为现代互联网景观中的核心媒介，高效的信息传递和强大的互动性正在重新定义用户参与和文化传播。在各种形式的用户互动中，评论在促进社区参与和内容再创作方面发挥着关键作用。然而，生成既符合平台指南又能体现风格多样性和上下文意识的评论仍然是一项重大挑战。
### Innovation
LOALGORITHM 是一种模块化的多代理系统（MAS），专为可控的短视频评论生成设计。该系统集成了视频分段、上下文和情感分析以及风格感知的提示构建。它支持六种不同的评论风格：双关语（谐音）、押韵、模因应用、讽刺（反讽）、平淡的幽默和内容提取。该系统通过多模态大型语言模型（MLLM）直接处理视频输入，并通过显式的提示标记和少量例证实现精细的风格控制。同时，构建了一个双语数据集，涵盖了五种流行的视频类型：喜剧小品、日常生活笑话、有趣动物片段、幽默评论和脱口秀。
### Conclusion
LOALGORITHM 在抖音和YouTube上的评价分别为90%以上和87.55%。这项工作提供了一个可扩展且文化适应的框架，用于短视频平台上的风格化评论生成，为增强用户参与和创意互动提供了具有前景的路径。
## 51. `cs.AI` - PLLuM: 一个波兰大型语言模型家族 [PDF](https://arxiv.org/pdf/2511.03823), [HTML](https://arxiv.org/abs/2511.03823)
### Authors
Jan Kocoń,Maciej Piasecki,Arkadiusz Janz,Teddy Ferdinan,Łukasz Radliński,Bartłomiej Koptyra,Marcin Oleksy,Stanisław Woźniak,Paweł Walkowiak,Konrad Wojtasik,Julia Moska,Tomasz Naskręt,Bartosz Walkowiak,Mateusz Gniewkowski,Kamil Szyc,Dawid Motyka,Dawid Banach,Jonatan Dalasiński,Ewa Rudnicka,Bartłomiej Alberski,Tomasz Walkowiak,Aleksander Szczęsny,Maciej Markiewicz,Tomasz Bernaś,Hubert Mazur,Kamil Żyta,Mateusz Tykierko,Grzegorz Chodak,Tomasz Kajdanowicz,Przemysław Kazienko,Agnieszka Karlińska,Karolina Seweryn,Anna Kołos,Maciej Chrabąszcz,Katarzyna Lorenc,Aleksandra Krasnodębska,Artur Wilczek,Katarzyna Dziewulska,Paula Betscher,Zofia Cieślińska,Katarzyna Kowol,Daria Mikoś,Maciej Trzciński,Dawid Krutul,Marek Kozłowski,Sławomir Dadas,Rafał Poświata,Michał Perełkiewicz,Małgorzata Grębowiec,Maciej Kazuła,Marcin Białas,Roman Roszko,Danuta Roszko,Jurgita Vaičenonienė,Andrius Utka,Paweł Levchuk,Paweł Kowalski,Irena Prawdzic-Jankowska,Maciej Ogrodniczuk,Monika Borys,Anna Bulińska,Wiktoria Gumienna,Witold Kieraś,Dorota Komosińska,Katarzyna Krasnowska-Kieraś,Łukasz Kobyliński,Martyna Lewandowska,Marek Łaziński,Mikołaj Łątkowski,Dawid Mastalerz,Beata Milewicz,Agnieszka Anna Mykowiecka,Angelika Peljak-Łapińska,Sandra Penno,Zuzanna Przybysz,Michał Rudolf,Piotr Rybak,Karolina Saputa,Aleksandra Tomaszewska,Aleksander Wawer,Marcin Woliński,Joanna Wołoszyn,Alina Wróblewska,Bartosz Żuk,Filip Żarnecki,Konrad Kaczyński,Anna Cichosz,Zuzanna Deckert,Monika Garnys,Izabela Grabarczyk,Wojciech Janowski,Sylwia Karasińska,Aleksandra Kujawiak,Piotr Misztela,Maria Szymańska,Karolina Walkusz,Igor Siek,Jakub Kwiatkowski,Piotr Pęzik
### Background
目前，大型语言模型（LLMs）在现代人工智能中扮演着核心角色，但这些模型的开发主要集中在英语上，导致其他语言的支持有限。PLLuM（Polish Large Language Model）作为一个专为波兰语定制的大型开源基础模型家族，旨在填补这一空白，满足对高质量、透明且文化相关的语言模型的需求。
### Innovation
PLLuM 通过一系列创新解决了现存问题：1. 建设了一个新的 140 亿词的波兰语文本语料库用于预训练；2. 创建了一个包含 77,000 条自定义指令的数据集；3. 设计了一个 100,000 条偏好优化的数据集；4. 引入了一个负责任的人工智能框架，包括严格的数据治理和混合模块进行输出修正和安全性筛选；5. 描述并优化了基模型及指令调整变体的架构、训练过程和对齐技术；6. 在公共行政领域展示了模型的应用价值。
### Conclusion
通过公开发布这些模型，PLLuM 希望促进开放研究并强化波兰的主权人工智能技术。
## 52. `cs.AI` - 噪声注入：提高有限数据集的离分布泛化能力 [PDF](https://arxiv.org/pdf/2511.03855), [HTML](https://arxiv.org/abs/2511.03855)
### Authors
Duong Mai,Lawrence Hall
### Background
深度学习（DL）模型在图像识别方面的研究已经显示这些模型难以泛化到不同的设备、人群等数据上。特别地，通过胸部X光（CXR）识别COVID-19的方法，在新临床来源的数据上表现出了泛化能力不足的问题，尤其是在没有包含在训练集中的新数据上的表现。这是因为模型倾向于学习依赖于特定源的捷径，这些捷径不能应用于新的数据分布，而不是合理地利用生物标志物来最大化在训练集内数据上的性能表现。
### Innovation
为了使模型对抗分布变化更为稳健，我们的研究探索了在训练过程中使用基本的噪声注入技术（高斯噪声、条纹噪声、泊松噪声以及椒盐噪声）。实证结果显示，这种方法显著减小了在内部分布（ID）和外部分布（OOD）评估之间性能差距，即从0.10-0.20降至0.01-0.06，基于关键指标（如AUC、F1、准确率、召回率和特异性）的10次随机种子的平均结果。
### Conclusion
我们的研究结果显示，噪声注入技术可以有效提高模型的离分布泛化能力。为了验证和推广这一发现，我们的源代码已公开发布，可以从该网址访问：this https URL
## 53. `cs.AI` - CORE - 细胞级粗细分级图像注册引擎用于多染色图像对齐 [PDF](https://arxiv.org/pdf/2511.03826), [HTML](https://arxiv.org/abs/2511.03826)
### Authors
Esha Sadia Nasir,Behnaz Elhaminia,Mark Eastwood,Catherine King,Owen Cain,Lorraine Harper,Paul Moss,Dimitrios Chanouzas,David Snead,Nasir Rajpoot,Adam Shephard,Shan E Ahmed Raza
### Background
在多染色组织切片的高分辨率、核级别分析中，WSI的整体对准至关重要。现有的WSI对准方法难以在多样化的多模态WSI数据集之间实现精确的核级别对准。因此，针对这一挑战，本文提出了一种名为CORE的新颖粗细分级框架，专门用于多模态WSI的核级别对准。该框架首先利用基于提示的组织掩码提取进行粗对准阶段，从而有效地过滤掉伪影和非组织区域，然后通过组织形态及加速密集特征匹配实现全局对准。进一步，通过自定义的形状感知点集注册模型对来自粗对准的切片中的细胞核中心进行细粒度刚性对准。最后，通过估计非线性位移场实现细胞级别的非刚性对准。这些方法通过自动产生的细胞核提高了可变形对准的准确性，从而确保了不同模态之间的精确核级别对准。
### Innovation
本文主要创新在于提出的CORE粗细分级框架。该框架通过结合基于提示的组织掩码提取、加速的特征匹配、形状感知点集注册以及非刚性对准，解决了WSI在多样化的多模态数据集间的核级别对准难题。
### Conclusion
本文提出的CORE方法在三项公开的WSI对准数据集以及两项私人数据集中进行了评估，表明该方法在亮场和免疫荧光显微镜WSI中的泛化能力、精准度和鲁棒性方面优于当前最先进的方法。
## 54. `cs.AI` - AI领域中的权力杠杆 [PDF](https://arxiv.org/pdf/2511.03859), [HTML](https://arxiv.org/abs/2511.03859)
### Authors
Tammy Mackenzie,Sukriti Punj,Natalie Perez,Sreyoshi Bhaduri,Branislav Radeljic
### Background
本文探讨学术界、政府、企业和民间社会的决策者在实施人工智能时如何处理权力问题。研究揭示了个人如何体验和行使权力杠杆，这些权力杠杆被描述为社会机制，影响机构对技术变革的回应。研究基于新制度主义者的工作，通过定制的个人问卷收集了决策者的机构管辖权信息，针对AI领域提供了十二个虚构的高级决策者人物，以展示个人能动性、组织逻辑和机构基础设施如何在AI治理中交织。
### Innovation
研究将机构治理框架与AI领域联系起来，通过虚构的高级决策者人物展示了个人能动性、组织逻辑和机构基础设施如何在AI治理中交织。最终部分提供了权力杠杆在AI领域变化中的动态，以及五个可供机构和社会运动研究者测试的假设。研究成果对于政策制定者及其在公共部门的同行与智能治理的个人互动方式提供了见解，并为相关研究提供了方向性指导。
### Conclusion
最后，研究提出一种可供政策制定者及其民间社会伙伴与AI治理相关互动的手段。通过分析决策者的问卷回答，研究讨论了决策者在AI领域中的个人权力、维护机构稳定的方法，以及推动机构变革的方法。最终结论以表格形式展示了AI领域中权力杠杆的动态，并提供五个可测试的假设，供机构和社会运动研究者参考。
## 55. `cs.AI` - OMPILOT：利用变压器模型实现自动生成代码并行化以供共享内存计算 [PDF](https://arxiv.org/pdf/2511.03866), [HTML](https://arxiv.org/abs/2511.03866)
### Authors
Arijit Bhattacharjee,Ali TehraniJamsaz,Le Chen,Niranjan Hasabnis,Mihai Capota,Nesreen Ahmed,Ali Jannesari
### Background
近期，大型语言模型（LLMs）在代码翻译领域的进展显著加速了编程语言之间的转换，提高了准确性和效率。虽然LLMs最初是为自然语言处理设计的，但它们在建模编程语言语法规则和语义方面表现出强大的能力，且在准确性和灵活性上优于传统的基于规则的系统。这些模型简化了跨语言转换，减少了开发工作量，并加快了遗留代码的迁移。
### Innovation
本文介绍了一款名为OMPILOT的新型领域特定编码器-解码器变压器模型，专门用于将C++代码转换为OpenMP，实现有效的共享内存并行化。OMPILOT模型采用了结合自监督和监督学习策略的自定义预训练目标，以改善代码翻译的稳健性。此外，与之前主要关注循环级别的转换工作相比，OMPILOT操作在函数级别，以捕捉更广泛的语义上下文。为了评估该模型，提出了一个名为OMPBLEU的新型复合度量标准，专门用于评估OpenMP并行构造的正确性和质量，超越了传统翻译度量标准的局限。
### Conclusion
通过引入OMPILOT模型，以及提出OMPBLEU度量标准，作者展示了利用变压器模型在代码自动并行化领域的新进展，能够更好地评估OpenMP并行构造的质量，并有效实现了C++代码到OpenMP的转换。
## 56. `cs.AI` - 探索自主X射线引导脊柱手术的机器控制策略学习 [PDF](https://arxiv.org/pdf/2511.03882), [HTML](https://arxiv.org/abs/2511.03882)
### Authors
Florence Klitzner,Blanca Inigo,Benjamin D. Killeen,Lalithkumar Seenivasan,Michelle Song,Axel Krieger,Mathias Unberath
### Background
基于模仿学习的机器人控制策略在基于视频的机器人技术中重新引起关注。然而，对于像脊柱内固定这样依赖于X射线引导的程序，这一方法的有效性尚不清楚。这是因为多视角X射线的解释复杂，且双平面引导下的内窥镜插入操作则更是增添了难度和挑战。研究团队旨在探索模仿学习策略在双平面引导下的内窥镜插入过程中的机会和挑战，开发了一种能够模拟真实脊柱手术环境的虚拟沙箱，进而在多种变量背景下评估该方法的应用潜力和局限性。
### Innovation
该研究创新性地提出了一种基于模仿学习的机器控制策略，并应用到X射线引导下的脊柱内固定手术过程中。通过建立一个高仿真度的虚拟手术环境（in silico sandbox），可以自动化地模拟此类手术，并且能够生成能够真实复制操作者步骤的X光片序列数据集。此研究有望将现有的基于模仿学习的方法拓展到复杂的医学手术环境中，并且在安全性和适应性上得到了初步验证。
### Conclusion
初步结果显示，基于模仿学习的策略在68.5%的情况下能够在一次尝试中成功执行，并且能够保持穿刺路径的安全性，包容多种椎体水平和复杂解剖结构，包括骨折。尽管如此，模型在细节上的精确度仍存在一定局限性，特别是在入口点的准确性上。如何提供足够的及时性反馈也成为进一步考虑的关键方面。未来的工作需要开发出更加稳健的先验知识和领域知识，以便能为未来的轻量化和无CT的手术导航建立基础。
## 57. `cs.AI` - 利用基于类别的输入图像组合提高小型和类别不平衡数据集的诊断性能 [PDF](https://arxiv.org/pdf/2511.03891), [HTML](https://arxiv.org/abs/2511.03891)
### Authors
Hlali Azzeddine,Majid Ben Yakhlef,Soulaiman El Hazzat
### Background
深度学习模型在小型、类别不平衡数据集和输入图像质量差的情况下可能会产生高假阳性率。该研究探讨了如何通过图像组合来改进训练输入，用于克服这些问题。具体来说，研究使用了Optical Coherence Tomography (OCT)数据集，该数据集包含2,064个高分辨率的人类视网膜扫描图像，代表了七种不同的疾病，且存在显著的类别不平衡问题。研究方法是将同一类别的多张图像组合成复合输入图像，从而增强同一类别的内部变化，提高每个训练样本的有效信息密度，并提高模型区分微妙疾病模式的能力。为了确保公平比较，使用了相同的模型架构和超参数进行所有实验，最终证明该方法显著提高了诊断性能。
### Innovation
该研究提出了一种基于类别的图像组合方法(Class-Based Image Composition)，即将同一类别的多张图像融合成复合输入图像（Composite Input Images, CoImg）。通过这种方法，提高了同一类别的内部变化，增加了每个训练样本的有效信息密度，增强了模型区分微妙疾病模式的能力。特别是通过这种方法，基于VGG16模型的Co-OCTDL数据集在F1分数和AUC方面取得了接近完美的精度，显著降低了假阳性率。
### Conclusion
基于提出的类别图像组合方法，数据集的诊断性能显著提高，特别是对于小型、类别不平衡的数据集，这种方法可以生产高质量的预测结果，即使在样本数量较小或者存在类别不平衡的情况下也是如此。
## 58. `cs.AI` - SnappyMeal：一种多模态AI食品记录应用的设计和纵向评估 [PDF](https://arxiv.org/pdf/2511.03907), [HTML](https://arxiv.org/abs/2511.03907)
### Authors
Liam Bakar,Zachary Englhardt,Vidya Srinivas,Girish Narayanswamy,Dilini Nissanka,Shwetak Patel,Vikram Iyer
### Background
食品记录，无论是自我驱动的还是指派的，对于发现饮食、医疗、健身和健康结果之间的联系都至关重要。现有的食品记录方法，如手写日记和基于应用程序的日记，灵活性差，导致遵守度低，可能产生不准确的营养总结。这些发现与先前文献一致，强调了改进食品记录方法的急迫性。
### Innovation
SnappyMeal 是一种基于人工智能的饮食跟踪系统，利用多模态输入，使用户能够更灵活地记录饮食摄入。SnappyMeal 引入了目标相关的后续问题来智能地从用户获取缺失的背景信息，并从用户的购物收据和营养数据库中检索信息，以提高准确性。
### Conclusion
通过使用公开可用的营养基准测试和为期三周的多用户野外部署，SnappyMeal 接收到了用户高度评价的多个输入方法，且报告称感知精度很高。这些见解表明，多模态人工智能系统可以显著提高饮食跟踪的灵活性和情境意识，为新一代智能化自我跟踪应用奠定了基础。
## 59. `cs.AI` - 大规模反思促进代码安全性生成 [PDF](https://arxiv.org/pdf/2511.03898), [HTML](https://arxiv.org/abs/2511.03898)
### Authors
Arup Datta,Ahmed Aljohani,Hyunsook Do
### Background
大型语言模型（LLMs）现在被广泛用于编写和重构代码，但可运行的代码并不一定安全。本文评估了安全代码生成，使用了Instruct Prime，一个消除了合规所需提示和引导污染的方法，并对比了五种指令调优的代码LLMs，在零样本和三轮反思提示两种方法下进行评估。安全评估使用了Insecure Code Detector（ICD），并通过修复、回归和NetGain指标对不同编程语言和CWE家族进行测评。研究发现，初始评估中约25-33%的程序存在不安全性问题，Python语言的代码安全性最高，而C和C#语言的代码安全性最低，Java、JavaScript、PHP和C++介于中间。反思提示提高了所有模型的安全性，在三个轮次中平均准确性从70.74%提升到了79.43%，并显示出第一轮的提升最为显著。修复、回归和NetGain指标的趋势表明，一次或两次反思提示轮次能带来最大的收益。
### Innovation
该研究引入了Instruct Prime并使用反思提示方法来实现大规模安全代码生成。反思提示有效提升了模型的安全性，特别在第一轮反思提示后成效最大，总的效果从初始的70.74%提高到了79.43%。
### Conclusion
反思提示方法能够提升代码安全性，尤其是对于初期评估中安全性较低的C和C#语言。该方法在初始轮次中的效果最为显著，而额外的反思提示轮次则能带来较小的进一步提升。
## 60. `cs.AI` - 进化优化方法优于Adam优化方法在嵌入空间探索中的表现 [PDF](https://arxiv.org/pdf/2511.03913), [HTML](https://arxiv.org/abs/2511.03913)
### Authors
Domício Pereira Neto,João Correia,Penousal Machado
### Background
深度生成模型，尤其是扩散架构，已经在图像生成领域取得了革命性的进步。然而，这些模型难以控制和优化以实现特定目标，且在不需要昂贵的重新训练的情况下进行优化具有挑战性。进化空间探索，特别是通过进化算法（EAs），已经显示出了优化图像生成的潜力，特别是在扩散模型中。因此，本研究探讨了分离协方差矩阵适应进化策略（sep-CMA-ES）这一进化优化方法与广泛采用的自适应时刻估计（Adam）在稳定的扩散XL Turbo的提示嵌入向量上的性能。
### Innovation
本研究首次将分离协方差矩阵适应进化策略（sep-CMA-ES）应用于稳定的扩散XL Turbo的提示嵌入向量，并通过将LAION美学预测器V2与CLIPScore结合起来作为加权适应度函数，进行评估，以实现视觉吸引力和提示遵循的灵活权衡。实验结果表明，sep-CMA-ES在美学和对齐度量上持续优于Adam优化方法，证明了进化方法在扩散模型嵌入空间探索中的高效无梯度优化潜力，无需微调。
### Conclusion
进化方法为深生成模型的嵌入空间探索提供了高效的无梯度优化方式，增强了控制能力，无需细调。本研究强调了进化方法在生成模型嵌入空间探索中的潜力，并指出了未来的研究方向。
## 61. `cs.AI` - NVIDIA Nemotron Nano V2 VL [PDF](https://arxiv.org/pdf/2511.03929), [HTML](https://arxiv.org/abs/2511.03929)
### Authors
NVIDIA:Amala Sanjay Deshmukh,Kateryna Chumachenko,Tuomas Rintamaki,Matthieu Le,Tyler Poon,Danial Mohseni Taheri,Ilia Karmanov,Guilin Liu,Jarno Seppanen,Guo Chen,Karan Sapra,Zhiding Yu,Adi Renduchintala,Charles Wang,Peter Jin,Arushi Goel,Mike Ranzinger,Lukas Voegtle,Philipp Fischer,Timo Roman,Wei Ping,Boxin Wang,Zhuolin Yang,Nayeon Lee,Shaokun Zhang,Fuxiao Liu,Zhiqi Li,Di Zhang,Greg Heinrich,Hongxu(Danny)Yin,Song Han,Pavlo Molchanov,Parth Mannan,Yao Xu,Jane Polak Scowcroft,Tom Balough,Subhashree Radhakrishnan,Paris Zhang,Sean Cha,Ratnesh Kumar,Zaid Pervaiz Bhat,Jian Zhang,Darragh Hanley,Pritam Biswas,Jesse Oliver,Kevin Vasques,Roger Waleffe,Duncan Riach,Oluwatobi Olabiyi,Ameya Sunil Mahabaleshwarkar,Bilal Kartal,Pritam Gundecha,Khanh Nguyen,Alexandre Milesi,Eugene Khvedchenia,Ran Zilberstein,Ofri Masad,Natan Bagrov,Nave Assaf,Tomer Asida,Daniel Afrimi,Amit Zuker,Netanel Haber,Zhiyu Cheng,Jingyu(Justin)Xin, Di (Allan)Wu,Nik Spirin,Maryam Moosaei,Roman Ageev,Vanshil Atul Shah,Yuting Wu,Daniel Korzekwa,Unnikrishnan Kizhakkemadam Sreekumar,Wanli Jiang,Padmavathy Subramanian,Alejandra Rico,Sandip Bhaskar,Saeid Motiian,Kedi Wu,Annie Surla,Chia-Chih Chen,Hayden Wolff,Matthew Feinberg,Melissa Corpuz,Marek Wawrzos,Eileen Long,Aastha Jhunjhunwala,Paul Hendricks,Farzan Memarian,Benika Hall,Xin-Yu Wang,David Mosallanezhad,Soumye Singhal,Luis Vega,Katherine Cheung,Krzysztof Pawelec,Michael Evans,Katherine Luna,Jie Lou,Erick Galinkin
### Background
NVIDIA推出了Nemotron Nano V2 VL，这是Nemotron vision-language系列的最新模型，专门设计用于强现实世界文档理解、长时间视频理解和推理任务。它基于之前的模型Llama-3.1-Nemotron-Nano-VL-8B，在视觉和文本领域实现了显著改进，通过模型架构、数据集和训练方法的重大升级来实现。
### Innovation
Nemotron Nano V2 VL在架构上进行了优化，采用混合Mamba-Transformer大语言模型，并引入了创新的token减少技术，以提高在长文档和视频场景中的推理吞吐量。此外，它还提供了BF16、FP8和FP4格式的模型检查点，并共享了大量的数据集、训练方法和代码。
### Conclusion
总的来说，NVIDIA通过Nemotron Nano V2 VL进一步增强了其vision-language模型的能力，实现了在实际应用中的更强表现，并向社区提供了更多的开发资源和技术支持。
## 62. `cs.AI` - 合作代理在Ruby中的自动化程序修复 [PDF](https://arxiv.org/pdf/2511.03925), [HTML](https://arxiv.org/abs/2511.03925)
### Authors
Nikta Akbarpour,Mahdieh Sadat Benis,Fatemeh Hendijani Fard,Ali Ouni,Mohamed Aymen Saied
### Background
自动程序修复（APR）随着大型语言模型（LLMs）的进步而快速发展，但现有方法大多计算成本高且主要集中在少数几种编程语言上。尽管在web开发中被广泛应用且开发者面临着不少挑战，Ruby却在APR研究中被忽视了。本研究旨在填补这一研究空白，为Ruby设计了一种新的轻量级框架，名为RAMP。
### Innovation
RAMP引入了一组协作代理，通过生成针对性的测试、反思错误并逐步优化候选修复来实现程序修复的循序渐进过程。与现有方法不同，RAMP避免依赖大规模的多语言修复数据库或昂贵的微调，而是直接利用轻量级提示和基于测试的反馈在Ruby上运行。研究结果表明，RAMP在XCodeEval基准上的通过率达到67%，优于先前的方法，并且在5个迭代内即实现了快速收敛。进一步分析指出，测试生成与自我反思是RAMP性能的关键驱动因素。此外，研究发现RAMP特别擅长修复错误答案、编译错误和运行时错误。
### Conclusion
RAMP为多代理修复策略提供了新的见解，并为扩展基于LLM的调试工具到未充分研究的语言奠定了基础。
## 63. `cs.AI` - 基于随机权重平均高斯的无监督医学影像增量异常学习：我检测我所不知 [PDF](https://arxiv.org/pdf/2511.03912), [HTML](https://arxiv.org/abs/2511.03912)
### Authors
Nand Kumar Yadav,Rodrigue Rizk,William CW Chen,KC Santosh(AI Research Lab, Department of Computer Science and Biomedical and Translational Sciences, Sanford School of Medicine, University Of South Dakota, Vermillion, SD, USA)
### Background
在医学影像中进行未知异常检测仍然是一项基本挑战，原因是可标注的异常样本稀缺且专家监督成本高昂。当前方法多数依赖于有监督学习，并且需要生成模型或回放缓冲等技术来捕捉数据分布的变化，但如果缺乏先验或无法生成精确的异常样本，便会引发样本偏移和误入异常的风险。本文研究在稀缺标签和高成本专家监督的情况下如何进行无监督的异常检测。
### Innovation
本文提出了一种无需标记的无监督增量学习框架，该框架通过轻量级适配器更新和不确定性指导的样本接纳交替进行，逐步扩展信任的正常样本集合。框架中使用了一个冻结的预训练视觉骨干神经网络并添加了适配器模块，防止了过度拟合，同时使用紧凑的核心集能有效实现k-NN异常评分。双概率门控机制确保了增量扩展过程中的安全性，防止了数据偏移和虚假包含。此机制不依赖于生成模型或回放缓冲，提高了系统的效率和准确性。实验结果表明，该方法在不同医学影像数据集上取得了显著效果，如在COVID-CXR上ROC-AUC提高了0.9982，Pneumonia CXR上ROC-AUC提高了0.8968，以及在Brain MRI ND-5上ROC-AUC和PR-AUC分别提高了0.7269和0.8211。
### Conclusion
本文提出了一种新颖的无监督增量异常学习框架，该框架通过快速响应数据分布的变化减少了样本偏移，适用于标签稀缺和成本高昂的医学影像环境。实验证明，该方法在多种医学影像数据集上均取得了显著的性能提升，具有广阔的应用前景。
## 64. `cs.AI` - RLHF：文化、多模态及低延迟对齐方法的全面综述 [PDF](https://arxiv.org/pdf/2511.03939), [HTML](https://arxiv.org/abs/2511.03939)
### Authors
Raghav Sharma,Manan Mehta,Sai Tiger Raina
### Background
RLHF 是大规模语言模型（LLMs）对齐的标准方法，尽管近年来在文本基础上的方法上取得了重大进展，但研究已经扩展到多模态对齐、文化公平性和低延迟优化等关键领域。
### Innovation
本文综述了最新的创新成果，包括对基础算法（如 PPO、DPO 和 GRPO）的回顾，详细分析了最新技术，并提供了对这些技术的比较性综合分析，从而为基础研究者提供了解决开放挑战的重要指南。
### Conclusion
本文为研究人员设计更加稳健、高效和公平的人工智能系统指明了道路，为文化、多模态和低延迟对齐方法的研究提供了重要参考。
## 65. `cs.AI` - 通过纹理引导的高斯网格联合优化提升多视图重建 [PDF](https://arxiv.org/pdf/2511.03950), [HTML](https://arxiv.org/abs/2511.03950)
### Authors
Zhejia Cai,Puhua Jiang,Shiwei Mao,Hongkun Cao,Ruqi Huang
### Background
从多视角图像重构真实的三维物体是3D编辑、AR/VR以及数字内容创作等应用中的重要步骤。现有的方法通常在几何准确性和照片真实性之间做了权衡，往往会将几何形状和外观优化分割开，这不利于后续的编辑任务。
### Innovation
本文提出了一种新颖的框架，通过高斯引导下的可微网格渲染同时优化网格几何（顶点位置、面）和顶点颜色，结合输入图像的光照一致性以及法线和深度图的几何正则化，实现无缝的Gaussian-网格联合优化。
### Conclusion
该方法可以获得高质量的3D重建，能够进一步应用于如重新照明和形状变形等下游编辑任务，并且代码将在接受后公开发布。
## 66. `cs.AI` - 通过向量翻译在大型语言模型之间实现直接语义通信 [PDF](https://arxiv.org/pdf/2511.03945), [HTML](https://arxiv.org/abs/2511.03945)
### Authors
Fu-Chun Yang,Jason Eshraghian
### Background
在多智能体环境中，如辩论、反思或工具调用中，大型语言模型通常以简单的文本音节传递信息，从而丢弃大部分潜在语义，这限制了信息传递并增加了不必要的计算开销。
### Innovation
研究通过向量翻译建立了一个潜在桥梁，使用学习过的映射来实现大型语言模型之间的直接语义交换。采用双编码器翻译器在Llama-2-7B和Mistral-7B-Instruct之间训练，平均余弦对齐得分为0.538。通过将翻译后的向量以30%的混合强度注入目标模型，可以引导生成而不影响逻辑稳定性。双向评估显示转移不对称性比1:2.01，表明通用模型能提供比指令调整模型更可转移的表示。
### Conclusion
保守地注入翻译后的向量保持了计算稳定性，证明了跨模型潜在通信的可行性，这使得智能系统能够共享语义而非简单字符。
## 67. `cs.AI` - PEFA-AI: 使用逐步错误反馈代理AI推进开源LLM进行RTL生成 [PDF](https://arxiv.org/pdf/2511.03934), [HTML](https://arxiv.org/abs/2511.03934)
### Authors
Athma Narayanan,Mahesh Subedar,Omesh Tickoo
### Background
该研究背景涉及自动化在片级传输级别（RTL）生成中的应用，特别是在无需人工干预的情况下，使用多个专门的大型语言模型（LLM）和硬件仿真工具协作完成复杂任务的能力。目前，尽管存在一些尝试，但尚未有一种方法能够在保持性能的同时解决这一问题。
### Innovation
该研究的创新点在于提出了一种代理流，称为PEFA（渐进错误反馈系统），此系统利用迭代的错误反馈机制逐步增加方法的复杂性，实现自我纠正。此外，该方法使用开源代理框架，结合开放源代码和专有源代码LLM进行RTL生成，从而缩小了两者之间的性能差距，并取得了最先进的通过率，同时保持了在令牌计数上的高效性。该方法在两个开源的自然语言到RTL的数据集上进行了基准测试，成功证明了其有效性。
### Conclusion
该研究表明，通过使用逐步错误反馈代理AI，可以提高开源LLM在RTL生成中的性能。这种方法不仅设定了新的基准，提高了通过率，而且在保持高效性的同时，缩小了与专有源代码方法之间的差距。未来的工作可以进一步探索和优化此代理框架，使之更加广泛地应用于不同类型的任务和场景中。
## 68. `cs.AI` - 通过合成模型生成实现可解释模型的大规模元学习 [PDF](https://arxiv.org/pdf/2511.04000), [HTML](https://arxiv.org/abs/2511.04000)
### Authors
Kyaw Hpone Myint,Zhe Wu,Alexandre G.R. Day,Giri Iyengar
### Background
决策树由于其可解释性在高风险领域如金融和医疗中广泛应用。现有的元学习方法通常依赖于现实世界的数据或计算成本高昂的优化决策树进行预训练。
### Innovation
本文提出了一种高效且可扩展的方法，用于生成合成预训练数据，以实现决策树的元学习。通过合成采样近似最优决策树，创建大规模、真实的数据集。该方法使用元树变压器架构，证明了这种方法在性能上与基于实时数据或昂贵的优化决策树预训练相当，显著降低了计算成本，增强了数据生成的灵活性，为可解释决策树模型的大规模和高效元学习铺平了道路。
### Conclusion
本文的方法显著减少了计算成本，增强了数据生成灵活性，并为可解释决策树模型的大规模和高效元学习开辟了道路。
## 69. `cs.AI` - PETRA：基于演化轨迹的预训练演化变换器用于SARS-CoV-2突变预测 [PDF](https://arxiv.org/pdf/2511.03976), [HTML](https://arxiv.org/abs/2511.03976)
### Authors
Xu Zou
### Background
自SARS-CoV-2出现以来，它展现了一条快速且不可预测的进化轨迹，特征是不断出现能够逃避免疫的变异株，这给公共卫生和疫苗开发带来了持续挑战。尽管大规模生成预训练变换器（GPTs）在序列数据建模上取得了革命性的进展，但它们直接应用于嘈杂的病毒基因组序列有局限性。因此，本文提出PETRA（Pretrained Evolutionary TRAnsformer），一种基于从系统发生树中推导出的进化轨迹的转换器方法，而非原始的RNA序列。该方法有效缓解了测序噪音，捕捉了病毒进化的层级结构。
### Innovation
PETRA采用了一种加权训练框架来解决全球序列数据在地理和时间上的重大不平衡问题。与现有的最佳基线相比，PETRA在预测核苷酸突变和刺突蛋白氨基酸突变方面表现更优，其加权召回率@1分别为9.45%和17.10%，而基线仅为0.49%和6.64%。此外，PETRA也展示了其在实时预测主要分支如24F(XEC)和25A(LP.8.1)中的突变方面的能力。
### Conclusion
PETRA是一种基于进化轨迹的预训练变换器，它通过加权训练框架缓解全球序列数据地理和时间的不平衡，显著提高了对SARS-CoV-2突变的预测能力，特别是核苷酸和刺突蛋白氨基酸突变的预测。
## 70. `cs.AI` - 在检索增强语言模型中的演绎推理：生成和验证缺失的前提 [PDF](https://arxiv.org/pdf/2511.04020), [HTML](https://arxiv.org/abs/2511.04020)
### Authors
Shiyin Lin
### Background
检索增强生成（RAG）模型，通过结合记忆检索和语言生成，表现出色于知识密集型任务，但对于检索证据不足的情况处理不佳，导致推理过程中的缺口。
### Innovation
提出了一种框架，将演绎推理整合到检索增强的大语言模型中，该方法能够检测不足的证据，生成候选的缺失前提，并通过一致性与可行性检查验证它们，从而提高答案准确性和推理可靠性。
### Conclusion
此研究突出了演绎推理作为一种增强RAG系统健壮性和可解释性的有前途的方向。
## 71. `cs.AI` - 利用通用任务框架加速科学发现 [PDF](https://arxiv.org/pdf/2511.04001), [HTML](https://arxiv.org/abs/2511.04001)
### Authors
J. Nathan Kutz,Peter Battaglia,Michael Brenner,Kevin Carlberg,Aric Hagberg,Shirley Ho,Stephan Hoyer,Henning Lange,Hod Lipson,Michael W. Mahoney,Frank Noe,Max Welling,Laure Zanna,Francis Zhu,Steven L. Brunton
### Background
机器学习和人工智能算法正在重新定义和增强动态系统在工程、物理和生物学等领域的表征和控制。新兴的建模范式需要比较性指标来评估各种科学目标，包括预测、状态重建、泛化和控制，同时也需要考虑有限数据场景和噪声测量的影响。因此，需要一种通用任务框架（CTF），它可以支持多样化的实际目标，并为不断发展的众多算法提供客观的比较基准，这些算法在现实世界科学和工程应用中得到广泛应用。
### Innovation
论文提出了一个通用任务框架（CTF），旨在为工程和科学领域提供一系列具有多样性和实用性的挑战数据集。CTF作为一种关键使能技术，促进了机器学习/人工智能算法在传统应用领域，如语音识别、语言处理和计算机视觉中的快速发展。
### Conclusion
CTF为比较各类在实际应用中不断发展的算法提供了重要的客观指标，有助于推动科学发现的加速。CTF的发展将对跨科学和工程领域的算法发展产生重要影响。
## 72. `cs.AI` - 多尺度星形胶质网络钙动态在异常检测中实现生物合理智能 [PDF](https://arxiv.org/pdf/2511.03993), [HTML](https://arxiv.org/abs/2511.03993)
### Authors
Berk Iskar,Michael Taynnan Barros
### Background
传统的网络异常检测系统面临的挑战是，它们依靠离线训练的传统检测器对新威胁和零日或多态攻击变得脆弱，并容易出现概念漂移。这个背景下，研究者们努力寻找能够应对这些挑战的新方法，即需要一种可快速适应不断演变数据模式的方法。
### Innovation
本文提出了一种Ca$^{2+}$调控学习框架，该框架受脑星形胶质细胞钙信号传递机制的启发。通过配合一个用于模拟钙离子动态变化的多细胞星形胶质体动态模拟器和一个深度神经网络，该模型在多个训练/测试分割上实现了高准确性，且在保持少量运行时开销的同时减少了误报和漏报。此外，该方法提供了一种用于快速适应数据变化的泛化解决方案，不仅适用于网络安全领域，还能应用于其他需要实时适应变化的检测任务中。
### Conclusion
通过在CTU-13（Neris）网络流量数据集上的评估，本文所提出的方法展示了其在生物合理的异常检测中的有效性，Ca$^{2+}$调控模型在多个切分上超过了一个与之匹配的基本DNN基线，并且其性能提升与几乎可忽略的运行开销共存。
## 73. `cs.AI` - 通过自适应分割计算在内存和延迟受限环境下实现大型语言模型推理 [PDF](https://arxiv.org/pdf/2511.04002), [HTML](https://arxiv.org/abs/2511.04002)
### Authors
Mingyu Sung,Vikas Palakonda,Suhwan Im,Sunghwan Moon,Il-Min Kim,Sangseok Yun,Jae-Mo Kang
### Background
大型语言模型（LLMs）已经在各种推理任务中取得了接近人类的表现，但在资源受限的物联网（IoT）设备上的部署仍然不切实际，这是因为其庞大的参数占用和内存密集型的自回归解码。虽然分割计算提供了一种有希望的解决方案，即将模型执行分割到边缘设备和云服务器之间，但现有的方法未能解决自回归推断的独特挑战，尤其是迭代的令牌生成过程和扩展的键值（KV）缓存需求问题。
### Innovation
本文介绍了第一个专门为LLM在边缘设备上部署设计的自回归感知分割计算框架。作者做了三个主要贡献：开发了混合精度量化方案一阶分割压缩（OPSC），首次解决了内存不足的问题；提出了结合阈值分割（TS）和逐令牌适应比特量化（TAB-Q）的两阶段中间压缩流水线，以保留关键激活精度的同时大幅度减少通信开销；形成了一个统一的优化框架，共同选择最佳分割点、量化设置和序列长度，以满足严格的内存和延迟约束。
### Conclusion
广泛的评估表明，与最新的量化方法SmoothQuant、OmniQuant和Atom相比，该框架实现了1.49倍的推理速度提升，并大幅减少了通信开销，同时保持或提高了模型精度。
## 74. `cs.AI` - 使用MRI和nnU-Net进行左心房分割 [PDF](https://arxiv.org/pdf/2511.04071), [HTML](https://arxiv.org/abs/2511.04071)
### Authors
Fatemeh Hosseinabadi,Seyedhassan Sharifi
### Background
左心房（LA）的准确分割对于引导心房颤动（AF）消融和构建生物物理心脏模型至关重要。手动勾画耗时、依赖观察者且不适用于大规模或时间敏感的临床工作流程。深度学习方法，特别是卷积架构，在医学影像分割任务中已显示出出色的性能。
### Innovation
本研究应用了自动化、自我配置的深度学习分割架构nnU-Net，对2013年左心房分割挑战的MRI数据集进行分割。该模型自动适应MRI数据的预处理、网络配置和训练管道。该网络在不同左心房形状、对比度和图像质量和心房体及近端肺静脉的勾画中表现出了鲁棒的泛化能力，显著超越了传统分割方法。
### Conclusion
提出的nnU-Net模型在左心房分割任务上取得了93.5的Dice相似系数，默认与专家标注高度一致，显著优于以往研究中的多种传统分割方法。
## 75. `cs.AI` - 基于LLM的人机协同认知框架在灾害搜救中的应用 [PDF](https://arxiv.org/pdf/2511.04042), [HTML](https://arxiv.org/abs/2511.04042)
### Authors
Kailun Ji(1),Xiaoyu Hu(1),Xinyu Zhang(1 and 2),Jun Chen(1 and 2) ((1) School of Electronics and Information, Northwestern Polytechnical University, Xi'an, China, (2) Chongqing Institute for Brain and Intelligence, Guangyang Bay Laboratory, Chongqing, China)
### Background
大规模灾难搜寻与救援（SAR）任务经常受到复杂地形和通信中断的挑战。无人飞行器（UAV）群具有广阔区域搜索和补给投送的任务潜力，但高效的协同需要显著的认知负担。人类操作者在高压力环境下将高层次的救援目标转换为低层次的UAV群指令时，存在“意图到行动”的差距，这一过程易出错。
### Innovation
本文提出了一种新的基于LLM-CRF的人机协作系统，该系统利用了大规模语言模型（LLM）来增强人类与UAV群的合作认知能力。首先，通过自然和多模式交互方式捕捉操作人员的意图，然后利用LLM作为认知引擎，进行意图理解、任务分解和无人机群的任务规划。这种闭环框架使UAV群成为主动伙伴，实现实时反馈，减少手动监控和控制需求，显著提升了SAR任务的有效性。
### Conclusion
本文在模拟SAR场景中评估了提出的方法。实验结果显示，与传统的有序和命令接口相比，基于LLM的方法将任务完成时间减少了约64.2%，任务成功率提高了7%，同时显著降低了主观认知负荷，NASA-TLX评分降低了42.9%。本研究为在高风险场景中创建更直观和有效的无人飞行器群人机协作奠定了基础。
## 76. `cs.AI` - 儿科超声图像中的儿童阑尾炎检测 [PDF](https://arxiv.org/pdf/2511.04069), [HTML](https://arxiv.org/abs/2511.04069)
### Authors
Fatemeh Hosseinabadi,Seyedhassan Sharifi
### Background
儿童阑尾炎是儿童急性腹痛的主要原因之一，其诊断因症状重叠和影像质量的差异性而具有挑战性。为了应对这一挑战，研究人员开发并评估了一种基于预训练ResNet架构的深度学习模型，用于从超声图像中自动检测阑尾炎。
### Innovation
该研究使用来自德国路德维希港海德维希儿童医院的Regensburg儿科阑尾炎数据集，该数据集包含相关临床评分和实验室数据。研究团队提出了一种基于ResNet的深度学习模型，通过微调该模型以区分阑尾炎和非阑尾炎病例，并通过归一化、缩放和增强等预处理步骤来增强泛化能力。模型在不同类型的超声图像中显示出强大的诊断性能。
### Conclusion
提出的ResNet模型在图像分类任务中的整体准确率达到了93.44%，精确率91.53%，召回率89.8%，有效识别了不同类型的超声图像中的阑尾炎，特别是克服了低对比度、杂波噪声和儿童影像学中的结构变异带来的挑战。
## 77. `cs.AI` - LLM指导输入变异和语义反馈的混合 fuzzing 方法 [PDF](https://arxiv.org/pdf/2511.03995), [HTML](https://arxiv.org/abs/2511.03995)
### Authors
Shiyin Lin
### Background
软件模糊测试已成为自动化漏洞发现的关键技术，然而现有变异策略缺乏语义意识，导致产生冗余的测试用例并且探索程序深层状态的速度较慢。
### Innovation
本文提出了一种混合式模糊测试框架，结合静态和动态分析以及大型语言模型（LLM）辅助的输入变异和语义反馈。它通过将控制流和数据流信息转化为结构化的提示，让LLM生成语义多样且语法正确的输入。在执行过程中，以程序状态变化、异常类型和输出语义等信息为依据，增加语义反馈信号，从而让模糊测试器优先选择触发新型程序行为的输入，超出简单的代码覆盖率层面。
### Conclusion
在libpng、tcpdump和sqlite等实际开源目标软件上的评估表明，本方法在首次发现漏洞的时间、语义多样性以及新漏洞发现的数量上均优于现有最先进的模糊测试工具。本文突显了结合LLM推理和语义反馈增强漏洞发现的速度和深度的潜力。
## 78. `cs.AI` - 基于矩形标准矛盾理论基础的自动定理生成器 [PDF](https://arxiv.org/pdf/2511.04092), [HTML](https://arxiv.org/abs/2511.04092)
### Authors
Yang Xu,Peiyao Liu,Shuwei Chen,Jun Liu
### Background
目前尚缺乏一个严谨的理论体系能够系统地生成非平凡且逻辑有效的定理。这项研究旨在填补这一关键缺口。
### Innovation
该研究首次提出了一种基于矩形标准矛盾的新型自动定理生成理论和工具。定义并证明了一种新的逻辑结构——矩形标准矛盾。基于这一结构，提出了完整的自动定理生成（ATG）理论；设计了一种高效模板导向的ATG算法，并开发了一个矩形自动定理生成器。
### Conclusion
这项研究使机器从验证者转变为发现者，为逻辑和人工智能领域奠定了基础研究的新途径。
## 79. `cs.AI` - 基于AI驱动的入侵检测系统的自动化和可解释性DoS分析 [PDF](https://arxiv.org/pdf/2511.04114), [HTML](https://arxiv.org/abs/2511.04114)
### Authors
Paul Badu Yakubu,Lesther Santana,Mohamed Rahouti,Yufeng Xin,Abdellah Chehri,Mohammed Aledhari
### Background
随着分布式拒绝服务（DDoS）攻击频率和复杂性不断增加，开发更高效且可解释的检测方法变得至关重要。传统的检测系统在可扩展性和透明度方面存在问题，影响实时响应和对攻击途径的理解。
### Innovation
本论文提出了一种自动化框架，利用基于树的管道优化工具（TPOT）自动选择和优化机器学习模型和特征，减少手动实验的需求。同时，引入SHapley Additive exPlanations (SHAP) 提高模型的可解释性，提供对个体特征贡献的详细洞察。通过结合TPOT的自动化管道选择和SHAP可解释性，该方法提高了DDoS检测的准确性和透明度。实验结果表明，平均反向数据包长度和最小前向数据包头部长度等关键特征在检测DDoS攻击中至关重要，提供了一种可扩展且可解释的网络安全解决方案。
### Conclusion
本研究提出的方法通过利用自动化选择和优化模型的工具并结合可解释性分析技术，显著提高DDoS检测的准确性和透明度，提供了一种可扩展和可解释的网络安全解决方案。
## 80. `cs.AI` - 列表语言识别的极限定性 [PDF](https://arxiv.org/pdf/2511.04103), [HTML](https://arxiv.org/abs/2511.04103)
### Authors
Moses Charikar,Chirag Pabbaraju,Ambuj Tewari
### Background
戈德的经典结果表明，对于大多数有趣的语言集合，语言识别的极限是不可能实现的。随后，安格林提出了一个精确的语言集合的分类，即哪些集合可以实现语言识别的极限。本文在语言生成的积极结果激励下，重新审视了语言识别的经典问题，即学习者在每次猜测时可以产生一个包含k个猜测的列表的目标，以此确保告知一定时间后至少有一个猜测是正确的。文章基于安格林对有限列表猜测的版本分类，提供了列表语言识别极限的精确表征，进一步给出了概念性吸引人的表征。
### Innovation
文章提出了一种新的方法，即允许学习者在每次猜测时生成k个猜测，给出了k列表识别语言集合的极限的精确表征，并表明这样的语言集合能够被k列表识别的充要条件是该集合可以分解成k个可以通过单列表进行极限识别的子语言集合。文章还讨论了当输入是从集合中某个语言支持的i.i.d.流中抽取时，列表识别的语言集合的识别速率问题，证明了如果一个集合可以被k列表识别的极限，那么该集合可以在指数速率下被识别，且这是最优的。反之，如果一个集合不能被k列表识别的极限，那么它不能以任何使之趋向于零的速度进行k列表识别。
### Conclusion
文章为列表语言识别的极限提供了一个精确表征，展示了k列表识别语言集合的能力受限，以及识别速率的最优条件。
## 81. `cs.AI` - DeNoise: 学习鲁棒的图表示以进行无监督图级异常检测 [PDF](https://arxiv.org/pdf/2511.04086), [HTML](https://arxiv.org/abs/2511.04086)
### Authors
Qingfeng Chen,Haojin Zeng,Jingyi Jie,Shichao Zhang,Debo Cheng
### Background
随着关键领域中图结构数据的快速增长，无监督图级异常检测（UGAD）已成为关键任务。UGAD的目的是识别那些偏离正常行为模式的整体图。然而，大多数图神经网络（GNN）方法假设训练集是干净的，仅包含正常图，而这种情况在实践中很少见。即使训练集中有少量异常图的存在也会使学习到的表示失真，并导致性能急剧下降。因此，如何处理受污染的训练数据成为一个重要挑战。
### Innovation
本文提出了一种名为DeNoise的鲁棒统一图级异常检测框架，旨在处理受污染的训练数据。该框架通过对抗目标同时优化图级编码器、属性解码器和结构解码器，以学习抗噪声的嵌入表示。进一步地，DeNoise引入了一种编码器锚点对齐去噪机制，该机制将正常图的高信息节点嵌入融合到所有图的嵌入中，从而提高表示质量并抑制异常干扰。此外，对比学习组件将正常图的嵌入紧凑化并在潜在空间中排斥异常图。实验结果表明，DeNoise在多种噪声强度条件下能够学习可靠的图级表示，并显著优于现有最先进的UGAD基准方法。
### Conclusion
本文提出了一种名为DeNoise的鲁棒框架，以处理UGAD中的受污染训练数据问题。DeNoise通过对抗目标和对抗噪声机制提高了图表示的鲁棒性，通过对比学习进一步优化了正常图的表示效果。实验表明，DeNoise在多种噪声环境中表现出色，能够显著提升UGAD任务的性能。
## 82. `cs.AI` - 在编程教育中架设元认知：理解学生-人工智能交互及其设计意义 [PDF](https://arxiv.org/pdf/2511.04144), [HTML](https://arxiv.org/abs/2511.04144)
### Authors
Boxuan Ma,Huiyong Li,Gen Li,Li Chen,Cheng Tang,Yinjie Xie,Chenghao Gu,Atsushi Shimada,Shin'ichi Konomi
### Background
当前，生成型AI工具如ChatGPT为新手程序员提供了前所未有的即时、个性化支持。虽然这一发展充满前景，但它们对学生元认知过程的影响仍然未被充分研究。现有的研究主要集中在正确性和可用性上，较少关注学生使用AI助手是否支持或绕过了关键的元认知过程。
### Innovation
本研究通过元认知视角分析大学编程课程中的学生-AI交互，调查了超过10,000个对话日志，并补充了学生和教育者的调查。研究重点关注提示和回应与元认知阶段和策略的对齐情况，综合数据来源进行分析，提炼出旨在支持而非取代元认知参与的人工智能编程助手设计考量。研究结果为开发增强学生编程教育学习过程的教育AI工具提供了指导。
### Conclusion
本研究为开发能够强化学生编程学习过程的教育AI工具提供了设计建议，旨在支持学生的元认知参与，而不是取代它。
## 83. `cs.AI` - 使用场地关键点检测的自动网球球员和球跟踪系统 [PDF](https://arxiv.org/pdf/2511.04126), [HTML](https://arxiv.org/abs/2511.04126)
### Authors
Venkata Manikanta Desu,Syed Fawaz Ali
### Background
当前存在对于自动化的网球比赛分析需求，以帮助教练、广播员和运动员更好地理解比赛动态。现有技术主要集中在球员和球的实时检测与跟踪，以及场地关键点的识别，但这些技术在集成度和综合性能上仍有提升空间。因此，本文研究提出了一种完整的工作流，旨在通过结合多种深度学习模型来实现球员和网球的实时检测与跟踪，并通过识别场地关键点提供辅助的空间参考。这有助于提供详细的运动分析，包括球员移动模式、球速、射球准确性及反应时间等。实验结果显示该系统在不同比赛场景和场地条件下具有稳健表现，并输出带有详细性能指标的标注视频。
### Innovation
本研究创新地提出了一完整的自动化网球比赛分析框架。该框架集成了YOLOv8球员检测、自训练的YOLOv5模型进行球跟踪、基于ResNet50的场地关键点检测模型。相比现有技术，此系统不仅提高了检测与跟踪的实时性和准确性，还通过识别场地关键点提升了空间参考的精确度，从而能够提供更为详尽的比赛分析数据，为教练、广播员和运动员提供实用的洞见。
### Conclusion
实验结果显示，该系统在多变的赛场条件下和不同的比赛情景中表现出稳健的性能。它能够输出标注视频及详细的比赛表现指标，使教练、广播员和运动员能够更好地了解比赛的动态，从而提高训练和比赛的效果。
## 84. `cs.AI` - DMSORT: 一种适用于无人船舶平台的有效并行海洋多目标跟踪架构 [PDF](https://arxiv.org/pdf/2511.04128), [HTML](https://arxiv.org/abs/2511.04128)
### Authors
Shengyu Tang,Zeyuan Lu,Jiazhi Dong,Changdong Yu,Xiaoyu Wang,Yaohui Lyu,Weihao Xia
### Background
精确感知海洋环境是确保船舶航行安全和有效海上监控的关键。然而，复杂的海洋环境会引发相机运动并导致视觉退化，给多目标跟踪（MOT）带来了很大挑战。为了应对这一挑战，提出了一个高效的多分支海上多目标跟踪（DMSORT）方法，通过并行跟踪器与仿射补偿的核心框架，结合目标检测和重识别（ReID）分支，以及专门的动态相机运动估计分支，解决了海上MOT问题。在检测模块中集成可逆列检测网络（RCDN），利用多层次视觉特征进行鲁棒目标检测，另外，设计轻量级的基于Transformer的外观提取器（Li-TAE）捕获全局上下文信息，生成鲁棒的外观特征，通过构建投影变换、平台运动补偿和卡尔曼滤波，分离平台和目标内的运动，最后利用聚类优化特征融合模块，确保在噪声、遮挡和漂移的情况下身份一致性。
### Innovation
提出了DMSORT方法，一个创新的多分支并行架构，结合了可逆列检测网络（RCDN）和轻量级基于Transformer的外观提取器（Li-TAE），专门用于海上MOT。这种架构能够实现高效运行，同时保持高身份一致性并且对抖动和遮挡具有鲁棒性，显著提升了多目标跟踪的性能。
### Conclusion
在新加坡海上数据集上的广泛评估表明，DMSORT达到了最先进的性能。特别地，DMSORT在现有的基于ReID的MOT架构中实现了最快的运行时，同时保持了高度的一致性和对抖动和遮挡的鲁棒性。
## 85. `cs.AI` - 我们一致吗？LLMs与人类判断负责任AI价值观之间的初步一致性研究 [PDF](https://arxiv.org/pdf/2511.04157), [HTML](https://arxiv.org/abs/2511.04157)
### Authors
Asma Yamani,Malak Baslyman,Moataz Ahmed
### Background
大型语言模型（LLMs）在软件工程任务中越来越被应用到需求提取、设计和评估中，这引发了对其是否与人类在负责任AI价值观上的判断相一致的关键问题。本研究旨在探讨LLMs在负责任AI价值观上的偏好与两个群体（美国代表性样本和AI从业者）之间的接近程度。利用23种不同模型与四项任务的结果，研究分析了LLMs与人类价值观之间的差距，尤其是在要求优先级排序时的表现，揭示了其在理论与实践中的不一致性。
### Innovation
本研究通过量化比较LLMs、美国代表性样本和AI从业者的ResponsiBLE价值观得分，首次系统评估了这些模型在负责任AI价值观上的接近程度。研究表明，尽管LLMs总体上更倾向于与AI从业者的价值观一致，但在优先软件需求时的实践表现上存在与宣称价值观不一致的情况，从而为AI辅助软件开发建立评估、解读和监控价值对齐的方法提供了一个框架。
### Conclusion
研究结果揭示了在无需人工监督的情况下依赖LLMs进行需求工程时的潜在风险，并强调了系统的方法来评估、解释和监测AI辅助软件开发中的价值对齐的重要性。
## 86. `cs.AI` - 推进公平的人工智能：用拉丁美洲背景下的LLMs评估文化表达性 [PDF](https://arxiv.org/pdf/2511.04090), [HTML](https://arxiv.org/abs/2511.04090)
### Authors
Brigitte A. Mora-Reyes,Jennifer A. Drewyor,Abel A. Reyes-Angulo
### Background
人工智能系统通常反映的是经济发达地区的偏见，而拉丁美洲等经济欠发达地区的背景则被边缘化，这主要是由于数据集的不平衡。该研究探讨了拉丁美洲多样化背景下的AI表示，揭示了经济发达与欠发达地区之间的差异。研究指出，英语在文化和语言上对西班牙语、葡萄牙语和印第安语（如克丘亚语和纳瓦特尔语）的主导地位加剧了这种偏见，并通过西方视角来塑造拉丁美洲的观点。研究强调了拉丁美洲历史和政治社会背景的重要性，挑战了以欧洲为中心的模型，并提倡收集反映拉丁美洲历史、土著知识和多元语言的多元数据集，以促进社区中心的公平人工智能发展。
### Innovation
该研究引入了一种与拉丁美洲历史和社会政治背景相适应的具有文化意识的数据集，用这种方式挑战了以欧洲为中心的模型，并通过这一数据集对六种语言模型的训练，提高了Mistral-7B的文化表达性42.9%，从而推动了公平的人工智能发展。研究使用了新型的文化表达性指标、统计测试和语言分析评估这些模型。研究结果表明，部分模型更能够捕捉拉丁美洲的视角，而其他模型则表现出明显的感情倾向偏差（p < 0.001）.
### Conclusion
研究提出了公平AI的倡导，即优先使用反映拉丁美洲历史、土著知识和多元语言的数据集，并强调社区中心的方法来放大边缘化的声音，以促进公正的人工智能发展。
## 87. `cs.AI` - BAPPA: 评估代理、方案和管道在自动文本转SQL生成中的性能 [PDF](https://arxiv.org/pdf/2511.04153), [HTML](https://arxiv.org/abs/2511.04153)
### Authors
Fahim Ahmed,Md Mubtasim Ahasan,Jahir Sadik Monon,Muntasir Wahed,M Ashraful Amin,A K M Mahbubur Rahman,Amin Ahsan Ali
### Background
Text-to-SQL系统提供了一种自然语言接口，使非专业人士能够访问数据库中的信息。然而，现有的大型语言模型（LLM）在从自然语言指令生成SQL代码时面临着因数据库模式庞大和复杂推理而导致的挑战。此前的研究常集中于复杂、且不切实际的流水线，而较小且高效的模型却常被忽视。
### Innovation
本文探索了三种多代理LLM流水线，并对从极小到较大的开源模型进行了系统的性能基准测试：（1）多代理讨论流水线，其中代理按照顺序评论和完善SQL查询，评判者综合最后的答案；（2）规划者-编码者流水线，其中思考模型规划者生成逐步的SQL生成计划，编码者综合查询；（3）编码者-聚合器流水线，其中多位编码者独立生成SQL查询，推理代理选择最佳查询。实验结果表明，多代理讨论可以提升小型模型的性能，使Qwen2.5-7b-Instruct的执行精度在三轮讨论后提高了10.6%。在这类流水线中，LLM推理者-编码者流水线取得了最佳结果，DeepSeek-R1-32B和QwQ-32B规划者使Gemma3 27B IT精度从52.4%提升至最高分的56.4%。
### Conclusion
多代理讨论流水线能够提升小型模型的执行准确性，而LLM推理者-编码者流水线则给出了最优的结果，展示了这一方法在自动文本转SQL生成中的优越性。
## 88. `cs.AI` - 一种基于进化的方法解决多资源负载均衡问题 [PDF](https://arxiv.org/pdf/2511.04183), [HTML](https://arxiv.org/abs/2511.04183)
### Authors
Leszek Sliwko
### Background
在研究的多资源系统优化问题中，传统的进化方案由于严格的实际可行性函数而效果不佳。因此，本文提出了改进和适应标准遗传算法的一系列方法，如引入类似生物学中的随机遗传漂移的迁移操作符。
### Innovation
论文提出了一种强化的遗传算法方法，对标准遗传算法进行了改进，引入了迁移操作符。这种方法解决了在实际可行性函数非常严格的条件下，传统进化方案效果不佳的问题。通过这种方式，提出了更加有效的多资源负载平衡优化策略。
### Conclusion
本文通过改进的遗传算法，引入了迁移操作符，有效解决了多资源负荷均衡问题，提高了算法的实用性和效率。
## 89. `cs.AI` - 基于在线视频进行推理时的计算机使用代理学习 [PDF](https://arxiv.org/pdf/2511.04137), [HTML](https://arxiv.org/abs/2511.04137)
### Authors
Yujian Liu,Ze Wang,Hao Chen,Ximeng Sun,Xiaodong Yu,Jialian Wu,Jiang Liu,Emad Barsoum,Zicheng Liu,Shiyu Chang
### Background
计算机使用代理能够操作计算机并自动化繁琐的任务，但与人类用户相比，尤其是在需要特定应用程序、平台和多步骤工作流的领域特定程序知识的任务上，它们仍然存在差距。人类可以通过观看视频教程来弥合这一差距：我们搜索、略读，并有选择地模仿与当前子目标匹配的短片段。本文旨在研究如何有效地让计算机使用代理在推理时从在线视频中学习。已有研究显示，尽管近年来取得了快速进展，但在许多应用领域中，这些代理仍依赖于有限的内部知识库，这限制了它们完成复杂任务的能力。对于那些需要特定应用程序和平台中特定技巧的任务，计算机使用代理依赖于人类用户的介入来实现自动化。
### Innovation
本文提出了一种框架，该框架在推理时检索和筛选教程视频，将它们转换为结构化的演示轨迹，并在执行过程中动态选择轨迹作为上下文指导。此外，利用视觉语言模型（VLM）推断用户界面（UI）操作，将视频分割成动作的短子序列，并为每个子序列分配一个文本目标。在推理时，一个两阶段选择机制动态地在每一步选择一个轨迹添加到上下文中，使代理集中于对其下一个决策最有帮助的局部指导。实验结果显示，该框架在两个广泛使用的基准测试上均优于强大的基线代理和仅使用文本教程或转录的变体。研究分析强调了轨迹分割和选择的重要性、动作过滤以及视觉信息的作用，表明大量的在线视频可以通过系统提炼成可操作的指导，从而提高代理在推理时的表现。
### Conclusion
实验结果表明，本文提出的方法在多个基准测试中取得了优于现有基线代理和仅使用文本或转录的变体的表现。进一步的分析还强调了轨迹分割、行动过滤及视觉信息在提升计算机使用代理性能中的关键作用。更多详细信息和代码可在给定的网址找到。
## 90. `cs.AI` - 使用大型语言模型解释软件漏洞 [PDF](https://arxiv.org/pdf/2511.04179), [HTML](https://arxiv.org/abs/2511.04179)
### Authors
Oshando Johnson,Alexandra Fomina,Ranjith Krishnamurthy,Vaibhav Chaudhari,Rohith Kumar Shanmuganathan,Eric Bodden
### Background
软件安全漏洞的普遍存在促使公司采用静态应用程序安全测试（SAST）工具来检测漏洞。然而，这些工具在易用性方面经常存在问题，因为它们通用的警告消息没有提供足够的信息给开发人员，导致误解或忽视了重要的发现。鉴于大型语言模型（LLMs）及其文本生成能力的最新发展，我们的研究探索了一种结合方法，使用LLMs解决SAST的可解释性挑战。
### Innovation
我们提出了SAFE，一个集成开发环境（IDE）插件，利用GPT-4o解释由SAST工具检测到的安全漏洞的原因、影响和缓解策略。我们的实验结果显示，SAFE生成的解释能够显著帮助初学者到中级开发人员理解并解决安全漏洞，从而提高SAST工具的整体易用性。
### Conclusion
我们在专家用户研究中发现了SAFE生成的解释能显著帮助开发人员理解并解决安全漏洞，进而改善SAST工具的易用性。
## 91. `cs.AI` - 可信的LLM调解通信：在多个应用领域评估LLM作为沟通者（LAAC）框架中的信息准确性 [PDF](https://arxiv.org/pdf/2511.04184), [HTML](https://arxiv.org/abs/2511.04184)
### Authors
Mohammed Musthafa Rafi,Adarsh Krishnamurthy,Aditya Balu
### Background
随着AI生成内容的增加，传播中出现了一个荒谬的交流戏院，其中发送者使用LLM夸大简单的想法，接收者则使用LLM压缩信息，且双方都不直接接触真实的内容。该文提议改变这一现状，通过将LLM定位为通过结构化对话捕捉发送者意图并促进真实知识交流的智能通信中介，从根本上改变这一情况。然而，如何在众多沟通场景下有效部署依赖于LLM的可靠性和一致性，是一个亟待解决的问题。
### Innovation
提出了LAAC（LLM作为沟通者）框架，这是一种通过结构化对话捕捉发送者意图并促进真实知识交换的新形式；并系统性地评估了信息忠诚度要求，涵盖信息提取精度、结构化知识再现性和查询反馈的一致性。
### Conclusion
初步研究在多个LAAC使用案例中揭示了可靠部署LAAC在高风险沟通场景之前需要解决的信任差距。
## 92. `cs.AI` - 系统性评估在数字病理学中准确图像对齐预处理技术 [PDF](https://arxiv.org/pdf/2511.04171), [HTML](https://arxiv.org/abs/2511.04171)
### Authors
Fatemehzahra Darzi,Rodrigo Escobar Diaz Guerrero,Thomas Bocklitz
### Background
图像配准是指通过将两个或多个图像映射到同一个坐标系统中来在空间上对齐这些图像，使得相应的解剖学或组织结构在图像之间匹配。在数字病理学中，配准使可以从不同染色或成像模态直接对比和整合信息，支持诸如生物标志物分析和组织重建等应用。跨模态图像间的准确配准是数字病理学中的关键步骤。本文研究了如何不同颜色变换技术影响H&E染色图像和非线性多模态图像之间的配准。为此，使用了一个包含20对组织样本的数据集，并应用了包括颜色变换（CycleGAN、Macenko、Reinhard、Vahadane）、反转、对比度调整、强度归一化和去噪在内的多种预处理步骤。所有的图像都使用了VALIS配准方法进行配准，该方法首先进行刚性配准，然后在低分辨率和高分辨率图像上分两步进行非刚性配准。配准效果通过相对配准误差（rTRE）进行评估。
### Innovation
本文系统地评估了不同的颜色变换技术（包括CycleGAN、Macenko、Reinhard、Vahadane）在不同预处理步骤（包括反转、对比度调整、强度归一化和去噪）下的效果。结果显示，CycleGAN颜色变换方法在多模态图像和H&E染色图像之间的配准误差最小，这表明在配准之前应用颜色变换可以提高跨模态图像的对齐效果，并支持数字病理学中更可靠的分析。
### Conclusion
研究发现，使用颜色变换方法在图像配准时之前的预处理可以显著改善在多模态图像和H&E染色图像之间的对齐质量，这对数字病理学中的准确分析具有重要意义。
## 93. `cs.AI` - seqme: 一个评估生物序列设计的Python库 [PDF](https://arxiv.org/pdf/2511.04239), [HTML](https://arxiv.org/abs/2511.04239)
### Authors
Rasmus Møller-Larsen,Adam Izdebski,Jan Olszewski,Pankhil Gawade,Michal Kmicikiewicz,Wojciech Zarzecki,Ewa Szczurek
### Background
近年来，计算方法在设计生物序列方面的进展推动了评估这些方法性能的度量标准的发展。这些方法的性能通常以设计序列对目标分布的忠实性和获得所需属性的程度来衡量。然而，缺乏一个实现这些度量标准的软件库。
### Innovation
本文介绍了一个模块化且高度可扩展的开源Python库seqme，该库包含用于评估生物序列设计计算方法的模型无关度量标准。seqme涵盖了序列基础度量、嵌入基础度量和属性基础度量三个类别，适用于多种生物序列，包括小分子、DNA、ncRNA、mRNA、肽和蛋白质。库提供了多种生物序列的嵌入模型和属性模型，以及诊断和可视化功能以检查结果。
### Conclusion
seqme 可用于评估单次和迭代的计算设计方法。
## 94. `cs.AI` - AStF: 基于自适应统计融合的运动风格迁移 [PDF](https://arxiv.org/pdf/2511.04192), [HTML](https://arxiv.org/abs/2511.04192)
### Authors
Hanmo Chen,Chenghao Xu,Jiexi Yan,Cheng Deng
### Background
传统的人体运动风格迁移通常依赖于图像处理中有效的均值和方差方法，尽管已经有一些类似的方法被应用于运动风格迁移，但由于图像和运动之间的根本差异，仅依赖均值和方差不足以完全捕捉运动数据的复杂动态模式和时空一致性特性。因此，需要引入更高级的统计特征，如偏度和峰度，以更好地分析运动风格并提高运动风格迁移的质量和效果。
### Innovation
本文提出了一种新颖的自适应统计融合器（AStF），它包括样式解缠模块（SDM）和高阶多统计注意（HOS-Attn）。该方法通过自适应地融合这些高级统计特征，能够更全面地捕捉动态风格中固有的时空统计模式，进而显著提高运动风格迁移的效果。此外，AStF还结合了一个运动一致性正则化鉴别器（MCR），进一步提升了模型在运动风格迁移任务中的性能。实验结果表明，与当前最先进的方法相比，AStF在运动风格迁移任务上展示了更高的优势。
### Conclusion
通过提供一种更全面的模型来描述动态风格中固有的时空统计模式，AStF在运动风格迁移任务上表现出卓越的性能。与现有的最优方法相比，AStF展示了显著的优势。
## 95. `cs.AI` - 多头注意力机制下的强彩票票假说 [PDF](https://arxiv.org/pdf/2511.04217), [HTML](https://arxiv.org/abs/2511.04217)
### Authors
Hikari Otsuka,Daiki Chijiwa,Yasuyuki Okoshi,Daichi Fujiki,Susumu Takeuchi,Masato Motomura
### Background
强彩票票假说（SLTH）认为，高性能的子网络称为强彩票票（SLTs）隐藏在随机初始化的神经网络中。尽管最近的理论研究已经证明了SLTH在各种神经架构中的有效性，但是对于基于变换器的架构，理论理解仍然不足。当前的SLTH理论尚未涵盖变换器的核心组件——多头注意力机制（MHA）。
### Innovation
本文提出了对MHA中的SLTs存在性的一种理论分析。证明了如果随机初始化的MHA具有特定隐藏维度，则其很可能包含一个能够近似任意相同输入维度的MHA的SLTs。此外，还利用此理论将SLTH扩展到不包含归一化层的变换器中。并通过实验证明了理论发现，表明通过增加源模型的隐藏维度，SLT与目标模型之间近似误差会呈指数级下降。
### Conclusion
研究证明了特定条件下MHA中存在SLTs，并通过理论分析扩展了SLTH到变换器中。实验结果验证了这种扩展的有效性，显示了隐藏维度增加带来的显著近似性能提升。
## 96. `cs.AI` - 带协作信号解耦的去噪推荐模型 [PDF](https://arxiv.org/pdf/2511.04237), [HTML](https://arxiv.org/abs/2511.04237)
### Authors
Zefeng Li,Ning Yang
### Background
尽管协同过滤（CF）算法在推荐系统中取得了显著性能，但由于用户项目交互矩阵中的噪声，其推荐性能存在不足。尽管有多种去噪研究提高了推荐模型，但大多数现有方法仅在单一图上进行去噪，这可能导致协作信号减弱，即去除两个节点间的边会中断其他节点间的路径，削弱依赖路径的协作信息。
### Innovation
本文提出了一种基于图神经网络（GNN）的CF模型，名为DRCSD，用于去噪不稳定交互。DRCSD具有两个核心模块：协作信号解耦模块（通过结构特性将信号分解为不同的顺序）和顺序级去噪模块（对每个顺序进行针对性去噪）。此外，传统GNN基CF模型中的信息聚合机制也进行了修改，避免在最终聚合操作之前发生跨顺序信号干扰。
### Conclusion
在三个公开的真实世界数据集上进行的广泛实验表明，DRCSD在对抗不稳定交互方面具有更好的鲁棒性，并在推荐准确度指标上相对于最先进的基线模型实现了统计显著性改进。
## 97. `cs.AI` - CLIP文本编码器的脆弱性研究 [PDF](https://arxiv.org/pdf/2511.04247), [HTML](https://arxiv.org/abs/2511.04247)
### Authors
Allie Tran,Luca Rossetto
### Background
近年来，多模态共嵌模型，尤其是CLIP，通过在共享表示空间中对齐图像和文本，提升了零样本分类和多媒体信息检索的现状。然而，这些模型在对比对齐训练时可能缺乏对小输入扰动的稳定性，特别是在处理手动表达的查询时，查询的小变项可能导致最佳匹配结果的显著差异。
### Innovation
本文系统分析了在多媒体信息检索场景中多种类型非语义查询扰动的影响。使用TRECVID Ad-Hoc Video Search查询和V3C1视频集合，评估了多种CLIP变体下的词汇、句法和语义扰动。研究发现，句法和语义扰动导致了最大的不稳定性，而脆弱性主要集中在细微的表面编辑，如标点符号和大小写。
### Conclusion
研究结果强调了鲁棒性是评估视觉-语言模型时的一个关键维度，而不仅仅是基准准确度。
## 98. `cs.AI` - 通过贝叶斯偏好推理实现高效的人工反馈强化学习 [PDF](https://arxiv.org/pdf/2511.04286), [HTML](https://arxiv.org/abs/2511.04286)
### Authors
Matteo Cercola,Valeria Capretti,Simone Formentin
### Background
将机器学习模型与人类的主观判断对齐是机器学习的一个重要目标。然而，收集人类偏好的数据通常成本高且耗时，这激发了更加高效的学习范式的需要。已有两种方法提供了互补的优势：基于奖励的强化学习人类反馈（RLHF）可以有效地扩展到包括大模型调整在内的高维度任务，而基于偏好优化（PBO）则通过主动查询实现了更高的样本效率。
### Innovation
本文提出了一种结合了RLHF的可扩展性和PBO的查询效率的混合框架。该方法通过在RLHF管道中引入一个以获取驱动的模块，实现主动且高样本效率的偏好数据收集。该方法在两种代表性领域中进行了验证：高维度偏好优化和大语言模型调整。实验结果显示，该方法在样本效率和整体性能上都取得了持续的改善。
### Conclusion
针对高维度偏好优化和大语言模型调整的任务，所提出的混合框架通过有效结合RLHF和PBO的优点，实现了偏好学习的高效性。
## 99. `cs.AI` - Proto-LeakNet：合成人脸图像信号泄露感知的归属分析方法 [PDF](https://arxiv.org/pdf/2511.04260), [HTML](https://arxiv.org/abs/2511.04260)
### Authors
Claudio Giusti,Luca Guarnera,Sebastiano Battiato
### Background
随着合成图像和深度伪造生成模型的日益复杂，溯源和真实性验证已成为现代计算机视觉系统面临的关键挑战。最近的研究表明，扩散管道在生成输出时会无意间留下持续存在的统计痕迹，称为信号泄露，特别是在潜在表示中。
### Innovation
利用这一观察结果，我们提出了一种叫做Proto-LeakNet的方法，这是一个信号泄露感知且可解释的归属框架。该方法结合了基于闭集分类与基于密度的开集评估，实现了无需重新训练即可分析未见过的生成器。该方法在扩散模型的潜在域中重模拟部分正向扩散，以揭示残余的生成器特定线索。通过时间注意力编码器聚合多步潜在特征，通过特征加权原型头结构嵌入空间并实现透明归属。
### Conclusion
在仅使用闭集数据训练的情况下，Proto-LeakNet能够学习一个在后处理下仍保持鲁棒性的潜在几何结构，超越了最先进的方法，并实现了已知和未知生成器之间的强可分性。这些结果表明，在潜在空间中建模信号泄露偏见可以实现可靠的且可解释的人工智能图像和深度伪造取证。
## 100. `cs.AI` - MedSapiens: 重新思考医学影像解剖标志检测的姿态 [PDF](https://arxiv.org/pdf/2511.04255), [HTML](https://arxiv.org/abs/2511.04255)
### Authors
Marawan Elbatel,Anbang Wang,Keyuan Liu,Kaouther Mouheb,Enrique Almar-Munoz,Lizhuo Lin,Yanqi Yang,Karim Lekadir,Xiaomeng Li
### Background
尽管传统的医学影像解剖标志检测依赖于专门领域的模型，但大规模预训练视觉模型的出现带来了新的机遇。本文旨在重新审视一种基础模型——Sapiens（专为人姿态估计设计），通过多数据集的预训练，将其应用于医学影像，从而可能会解锁该基础模型在医学解剖标志定位方面的潜在优势，但这一潜力尚未充分开发。
### Innovation
本文提出了一种新模型MedSapiens，借助于对Sapiens进行多数据集预训练的方式，使基于人体的基础模型能够以更有效的方式解决医学影像中解剖标志的检测问题。实验结果显示，MedSapiens在平均检测成功率方面，相较于通用模型提高了5.26%，相较于专业模型提高了21.81%。此外，MedSapiens在少量标注数据条件下表现良好，相比单次高精度模型提升了2.69%。这些成果表明，基于人体的基础模型能够提供有效的先验知识，有助于提升解剖标志检测的准确性。
### Conclusion
通过MedSapiens的研究，本文验证了基于人体的基础模型在医学影像解剖标志检测中的强效先验，展示了在多样化数据集下的优越性能，尤其是在有限数据标注的场景下依然能够取得显著提升，为医学影像解剖标志检测领域提供了新的参考路径。代码和模型权重已公开可供下载。
## 101. `cs.AI` - MusRec：借助校正流和扩散变换器实现零样本文本到音乐编辑 [PDF](https://arxiv.org/pdf/2511.04376), [HTML](https://arxiv.org/abs/2511.04376)
### Authors
Ali Boudaghi,Hadi Zare
### Background
音乐编辑已成为人工智能领域的重要且实用的子领域，应用于视频游戏和电影音乐制作等场景。然而，现有模型存在诸多限制，如只能编辑由其自身模型生成的合成音乐，需要非常精确的提示，或需特定任务重新训练，缺乏真正的零样本能力。
### Innovation
利用近期校正流和扩散变换器的进展，提出了MusRec，这是首个能够高效、有效地对真实世界音乐执行多种编辑任务的零样本文本到音乐编辑模型。
### Conclusion
实验结果表明，该方法在保留音乐内容、结构一致性以及编辑保真度方面优于现有方法，奠定了可控音乐编辑在实际场景中的坚实基础。
## 102. `cs.AI` - 基于Sentinel-1影像的深 обучения объектов надморского оборудования и влияние синтетических данных в процессе обучения [PDF](https://arxiv.org/pdf/2511.04304), [HTML](https://arxiv.org/abs/2511.04304)
### Authors
Robin Spanier,Thorsten Hoeser,Claudia Kuenzer
### Background
近年来，海上基础设施的扩展，包括海上风电场、石油和天然气平台、人工岛及水培设施，突显了有效监测系统的需求。海上基础设施检测模型的发展依赖于全面、平衡的数据集，但在样本稀缺时会受到影响，尤其是对于未充分代表的类、形状和尺寸。本文通过使用2023年第四季度来自四个区域（里海、南海、几内亚湾、巴西海岸）的合成和实际Sentinel-1卫星图像，研究用于提升模型性能的合成训练数据应用。
### Innovation
本文使用合成训练数据提高深学习下的YOLOv10目标检测模型性能，并通过在三个未见区域（墨西哥湾、北海、波斯湾）测试模型，评估地理转移性。通过这种方式，研究了合成数据如何增强不平衡类别的表示以及整体模型性能，从而迈出了一步，使海上基础设施的全球检测成为可能。该研究强调了平衡数据集的重要性，并指出生成合成数据是一种有效策略，用于解决遥感中常见的挑战，展示了深度学习在未来大范围、全球海上基础设施监测中的潜力。
### Conclusion
该研究证实，合成数据能够改善海上基础设施检测模型的泛化能力，提高模型识别海上平台的准确性。利用合成数据生成策略不仅可以增强对未充分代表对象类别的表示，还能提升整体模型性能，为在全球范围内实现海上设施建设的监控提供了可能。
## 103. `cs.AI` - Spurious Correlation-Aware Embedding Regularization for Worst-Group Robustness [PDF](https://arxiv.org/pdf/2511.04401), [HTML](https://arxiv.org/abs/2511.04401)
### Authors
Subeen Park,Joowang Kim,Hakyung Lee,Sunjae Yoo,Kyungwoo Song
### Background
深度学习模型在各个领域表现出色，但往往依赖于伪相关性，使得它们在分布转移时变得脆弱。尤其在子群体转移场景中，模型在少数群体中的表现不佳。尽管现有方法已经取得了一定的进步，但仍受到泛化能力的限制，缺乏将嵌入空间表示与最差群体错误率联系起来的严格理论框架。
### Innovation
本文提出了一种新的方法——Spurious Correlation-Aware Embedding Regularization (SCER)，旨在直接对特征表示进行正则化，以抑制伪线索。研究表明，最差群体错误率受到分类器对伪相关和核心方向依赖程度的影响。通过在嵌入级别施加理论约束，SCER鼓励模型聚焦于关键特征，减少对伪模式的敏感性。这种方法在多个视觉和语言领域中，显著提高了最差群体的准确率。
### Conclusion
通过系统评估，SCER在最差群体准确率方面优于先前的最先进研究，证明了其有效性。文章代码已开源。
## 104. `cs.AI` - AIM: 高性能PIM架构级IR-drop抑制的软硬件协同设计 [PDF](https://arxiv.org/pdf/2511.04321), [HTML](https://arxiv.org/abs/2511.04321)
### Authors
Yuanpeng Zhang,Xing Hu,Xi Chen,Zhihang Yuan,Cong Li,Jingchen Zhu,Zhao Wang,Chenguang Zhang,Xin Si,Wei Gao,Qiang Wu,Runsheng Wang,Guangyu Sun
### Background
SRAM Processing-in-Memory (PIM) 因其卓越的计算密度、能耗效率和计算精度而成为高性能PIM实现的最有力方案。然而，追求更高性能需要更复杂的设计和更高的工作频率，这加剧了IR-drop问题。严重的IR-drop会显著降低芯片性能，甚至影响可靠性。现有的电路级IR-drop缓解方法，如后端优化，资源密集且通常会权衡功率、性能和面积（PPA）。
### Innovation
本文提出了一种AIM方法，通过软硬件协同设计在高性能PIM架构级缓解IR-drop问题。首先，基于PIM的位序列和就地数据流处理特性，提出了Rtog和HR，建立了PIM工作负载与IR-drop之间的直接关联。接着，提出了LHR和WDS，通过软优化技术在架构级广泛探索IR-drop缓解方案，同时保持计算准确性。随后，开发了IR-Booster动态调整机制，将软件级HR信息与硬件IR-drop检测相结合，调整PIM宏的V-f对，以实现更高的能效和性能。最后，提出了一种HR感知的任务映射方法，将软件和硬件设计结合，以实现最大改进。后布局仿真的结果显示，AIM在7nm 256-TOPS PIM芯片上实现了最高的69.2%的IR-drop缓解，提升2.29倍的能效和1.152倍的速度。
### Conclusion
AIM在7nm 256-TOPS PIM芯片上的后布局仿真实验结果表明，该方法成功缓解了69.2%的IR-drop，从而实现了2.29倍的能效提升和1.152倍的速度提升。
## 105. `cs.AI` - 回归与分类的等价性 [PDF](https://arxiv.org/pdf/2511.04422), [HTML](https://arxiv.org/abs/2511.04422)
### Authors
Jayadeva,Naman Dwivedi,Hari Krishnan,N.M. Anoop Krishnan
### Background
回归和分类之间正式的联系一直比较薄弱。尽管支持向量回归中使用了`边缘最大化`术语`||w||`，但它的使用最多仅仅是作为正则化手段。本文通过分析一个包含M个样本的回归问题等价于两个M个样本的线性可分分类问题，揭示了回归问题与分类问题之间的正式联系，从而探讨了新的回归形式，并提出了一种“回归性”度量，以估计数据集回归的难度，无需先建立模型。此外，还利用等价性训练神经网络学习一个线性化映射，将输入变量转换到一个线性回归器适用的空间中。
### Innovation
该研究揭示了一个包含M个样本的回归问题等价于两个M个样本的线性可分分类问题，提出了一种新的回归形式，提出了“回归性”度量，并利用推理出的等价性训练神经网络学习一个线性化映射，使输入变量转换到一个线性回归器适用的空间中。这表明了回归问题和分类问题之间实质上的等价性，为回归问题提供了新的视角。
### Conclusion
该研究发现了回归问题与分类问题之间的正式等价关系，并提出了一个新的“回归性”度量来评估数据集的回归难度。通过等价性，研究还开发了一种方法，即通过训练神经网络学习一个线性化映射来使非线性数据线性化，从而简化回归任务。
## 106. `cs.AI` - Differentially Private In-Context Learning with Nearest Neighbor Search [PDF](https://arxiv.org/pdf/2511.04332), [HTML](https://arxiv.org/abs/2511.04332)
### Authors
Antti Koskela,Tejas Kulkarni,Laith Zumot
### Background
近期，由于上下文学习固有的隐私风险，差分隐私的上下文学习(DP-ICL)成为一个活跃的研究话题。然而，现有方法忽略了现代大型语言模型(LLM)流水线中的一个关键组成部分：用于检索相关上下文数据的相似性搜索。已有方法忽视了这一点，导致对上下文学习中的隐私保护不足。因此，需要一种新的方法来保护隐私的同时保持上下文学习的效果。这篇工作在差分隐私框架下提出了一个整合相关示例的接近邻居搜索方法，以实现隐私保护和学习效果之间的平衡。实验结果证明了该方法的优势，尤其是在文本分类和文档问答任务上表现更优，且在隐私-效用权衡上更优越。
### Innovation
文中提出了一种新的差分隐私框架下的上下文学习方法，它将接近邻居搜索与隐私过滤相结合，有效地管理了隐私成本，同时提高了学习性能。这种方法在多个评价基准上优于现有基线，并且在隐私和实用性之间取得了较好的权衡。通过这种方法，作者实现了在保持学习效果的同时，遵循了一个差分隐私的预算。此外，该工作中使用数据库中的接近邻居检索，并结合隐私跟踪过滤器来确保隐私成本的累积不超过中央差分隐私预算。实验结果表明，该方法在文本分类和文档问答任务上相比现有基线具有明显的优势，并提供了更好的隐私-效用权衡。
### Conclusion
研究提出了一种新的差分隐私框架下的上下文学习方法，该方法通过整合接近邻居搜索和隐私过滤，显著提升了隐私保护的同时保持了上下文学习的效果。实验结果显示，该方法在多个基准任务上均具有优越的表现，并在隐私-效用权衡方面提供了更好的结果，因此可以广泛应用于需要处理敏感数据的任务中，尤其是大型语言模型中的上下文检索环节。
## 107. `cs.AI` - LUME-DBN: 从重症监护中不完整数据全面贝叶斯学习DBNs [PDF](https://arxiv.org/pdf/2511.04333), [HTML](https://arxiv.org/abs/2511.04333)
### Authors
Federico Pirola,Fabio Stella,Marco Grzegorczyk
### Background
动态贝叶斯网络（DBNs）在医疗保健中的应用越来越多，因为它们能够以保持可解释性的方式来建模患者的复杂时间关系，这对于临床决策至关重要。然而，现有的处理纵向临床数据中的缺失数据的方法主要源自静态贝叶斯网络文献，未能充分考虑数据的时间特性。这种差距限制了随着时间推移量化不确定性的能力，特别是在重症监护环境中，理解时间动态对于模型的使用可靠性至关重要，适用于多样化的患者群体。尽管DBNs具有潜力，一个全面的贝叶斯框架将缺失数据处理纳入其中仍然未得到充分开发。
### Innovation
提出了一种新的基于吉布斯抽样方法来从不完整数据中学习DBNs。该方法将每个缺失值视为遵循高斯分布的未知参数。在每次迭代中，未观察到的值从其完全条件分布中采样，这使得进行有原则的填补和不确定性估计成为可能。该方法在模拟数据集和重症监护中的实际重症患者数据上进行了评估，相较于标准的模型无关技术（如MICE），贝叶斯方法展现了更高的重构精度和收敛性质。研究结果强调了将全面的贝叶斯推断纳入时间模型中的临床相关性，提供更可靠的填补及对模型行为更深入的洞察。这种方法支持更安全和知情的临床决策，特别是在频繁存在重要缺失数据的环境中。
### Conclusion
该研究表明了全面贝叶斯推断在时间模型中的临床相关性，提供更可靠的填补和对模型行为更深入的洞察，支持更安全和知情的临床决策，特别是在频繁存在重要缺失数据的环境中。这些结果表明了LUME-DBN算法在处理ICU中数据不完整性问题上的有效性和潜在重要性。
## 108. `cs.AI` - 基于LSTM的无字典深度方法用于具有输入延迟的非线性系统的线性模型识别 [PDF](https://arxiv.org/pdf/2511.04451), [HTML](https://arxiv.org/abs/2511.04451)
### Authors
Patrik Valábek,Marek Wadinger,Michal Kvasnica,Martin Klaučo
### Background
具有输入延迟的非线性动力系统在预测、估计和控制方面提出了重大挑战，因为它们自身的复杂性和延迟对系统行为的影响。传统线性控制技术在这种情况下往往无效，需要创新的方法。传统的扩展动态模式分解(eDMD)方法依赖于预定义的字典，这带来了已知动态被包含进字典的问题。
### Innovation
本文提出了一种新颖的方法，即使用LSTM增强的Deep Koopman模型近似Koopman算子，从而能够将具有时间延迟的非线性系统线性化。LSTM层的引入使得该框架能够捕捉历史依赖，并有效将带有时延的系统动力学编码到潜在空间中。这种增强的方法消除了对预定义字典的依赖，从而缓解了已知动态需要被手动包含到字典中的问题。
### Conclusion
与eDMD方法的定量比较表明，在未知非线性动力学的真实情况下，预测准确性有显著提高，并且在已知系统动态的情况下可获得与eDMD类似的结果。
## 109. `cs.AI` - 成本与质量之间的关系？LLM代理辅助对软件开发的影响 [PDF](https://arxiv.org/pdf/2511.04427), [HTML](https://arxiv.org/abs/2511.04427)
### Authors
Hao He,Courtney Miller,Shyam Agarwal,Christian Kästner,Bogdan Vasilescu
### Background
大型语言模型（LLMs）在软件工程领域展现出了革命性的潜力。LLM代理近年来在软件开发中的应用正在迅速增长，开发者声称采用这些工具后生产力显著提升。然而，目前缺乏确凿的实证证据支持这一说法。本研究旨在评估广泛使用的LLM代理助手——Cursor，对于项目开发速度和软件质量的影响。研究通过比较采用Cursor的GitHub项目和未采用Cursor的匹配对照组项目，从而进行最先进的差异比较实验设计。研究发现，采用Cursor会导致短期内项目开发速度显著提高，但同时也导致长期代码复杂度和静态分析警告数量显著增加，进而导致开发速度放缓。
### Innovation
本研究采用了最先进的差异比较实验设计，并通过面板广义矩估计方法挖掘问题背后的关键因素。该研究填补了现有关于LLM代理辅助对软件工程影响的实证研究空白，并提出了一种新颖的方法来评估其长期影响和潜在风险。
### Conclusion
研究结果表明，虽然采用LLM代理助手Cursor能短期内显著提高开发速度，但长期会导致代码复杂性和静态分析警告增多，从而减缓开发速度。该研究为软件工程从业者、LLM代理助手设计者及研究人员提供了重要启示。
## 110. `cs.AI` - 基于订阅平台的欺诈防范收益分配 [PDF](https://arxiv.org/pdf/2511.04465), [HTML](https://arxiv.org/abs/2511.04465)
### Authors
Abheek Ghosh,Tzeh Yuan Neoh,Nicholas Teh,Giannis Tyrovolas
### Background
本文研究了一种基于订阅模式的平台模型，用户支付固定费用以获取无限内容访问权限，而创作者则获得一部分收入。现有的欺诈检测方法主要依赖机器学习技术，与不良行为者展开持续的博弈。研究旨在探究内在制衡操纵的收益分配机制。
### Innovation
论文引入了三种类型的欺诈抵抗公理，并检验了现有规则是否符合这些标准。研究发现，广泛采用的一种机制不仅未能防止欺诈，反而使检测操纵变得计算上不可行。同时，论文提出了一个名为 ScaledUserProp 的新规则，该规则满足所有三种欺诈抵抗公理。
### Conclusion
通过实验手段，使用真实和合成的流媒体数据，研究展示了 ScaledUserProp 规则相比现有规则更加公平。
## 111. `cs.AI` - 基于深度Koopman的巴氏杀菌单元经济模型预测控制 [PDF](https://arxiv.org/pdf/2511.04437), [HTML](https://arxiv.org/abs/2511.04437)
### Authors
Patrik Valábek,Michaela Horváthová,Martin Klaučo
### Background
本文提出了一种用于高效实验室规模巴氏杀菌单元（PU）运行的深度Koopman经济模型预测控制（EMPC）方法。该方法利用Koopman算子理论将复杂的非线性系统动力学转换为线性表示，从而能够应用凸优化方法同时准确地表示复杂的PU系统。这种方法通过神经网络从实验数据中学习线性动力学，相对于传统的N4SID子空间识别，开放环预测精度提高了45%。这两类模型都应用于包含可解释经济成本的EMPC公式，例如能源消耗、由于不足的巴氏杀菌导致的材料损失以及执行器磨损。通过使用松弛变量确保EMPC的可行性。该深度Koopman EMPC与N4SID EMPC在存在外部干扰的多变量PU非线性模型上进行数值验证。干扰包括进泵未关闭故障场景和引入待巴氏杀菌的冷批次。研究结果表明，深度Koopman EMPC将与N4SID基线相比，总经济成本减少了32%，主要是因为减少了材料损失和能源消耗。此外，基于Koopman的稳态操作相比基线节省了10.2%的电能。这些研究结果强调了将深度Koopman表示与经济优化集成以实现热工密集型工厂资源高效控制的实用优势。
### Innovation
该研究采用Koopman算子理论将非线性系统转换为线性表示，通过神经网络从实验数据中学习线性动力学，有效提高了开放环预测精度。同时，这种经济模型预测控制方法能更精确地处理复杂的巴氏杀菌单元，通过集成经济优化实现资源高效控制，尤其在减少材料损失和能源消耗方面表现优异。该方法还通过引入松弛变量确保了实际可行性。
### Conclusion
基于深度Koopman的经济模型预测控制在多变量巴氏杀菌单元中展示了显著的性能优势，特别是减少了总经济成本。此外，相比基线方法，该控制方法还能在稳态操作中显著减少电能消耗。这些结果推动了热工密集型工厂的资源高效控制集成，包括深度Koopman表示与经济优化的结合。
## 112. `cs.AI` - 为知识图谱增强的LLM提供更好的训练和评估的真实子图 [PDF](https://arxiv.org/pdf/2511.04473), [HTML](https://arxiv.org/abs/2511.04473)
### Authors
Alberto Cattaneo,Carlo Luschi,Daniel Justus
### Background
从结构化知识图谱中检索信息是提高大型语言模型（LLM）事实准确性的有前景方向。尽管提出了多种解决方案，但由于缺乏用于图检索的具有真实目标的挑战性问答数据集，这些方法之间的比较变得困难。作者介绍了SynthKGQA框架，可以从任何知识图谱生成高质量的合成知识图谱问答数据集，为每个问题提供知识图谱中的所有真实事实以进行推理。利用该框架生成的数据，不仅支持KG检索器基准测试，还使他们能够训练出性能更好的模型。作者应用SynthKGQA生成了GTSQA数据集，旨在测试知识图谱增强的语言模型在未见过的图结构和关系类型方面的零样本泛化能力，并在多种KG增强的LLM解决方案上进行了基准测试评分。
### Innovation
作者提出了一种名为SynthKGQA的新框架，可以从任何知识图谱生成高质量的合成知识图谱问答数据集，并提供了每个问题的所有真实事实以进行推理。利用该框架生成的数据不仅支持更好的基准测试，还用于训练性能更优的模型。此外，作者还使用生成的数据集（GTSQA）测试了知识图谱增强的语言模型在未见过的图结构和关系类型方面的零样本泛化能力，并对多种KG增强的LLM解决方案进行了基准测试评分。
### Conclusion
作者使用SynthKGQA生成了一种新的数据集GTSQA，用于测试知识图谱增强的语言模型在未见过的图结构和关系类型方面的零样本泛化能力。通过基准测试，作者展示了GTSQA数据集的有效性和对改进KG检索器的贡献，并指出这种方法可以改善知识图谱增强的LLM的训练和评估。
## 113. `cs.AI` - RUST-BENCH：在结构化表格中测试LLM推理不明确文本基准 [PDF](https://arxiv.org/pdf/2511.04491), [HTML](https://arxiv.org/abs/2511.04491)
### Authors
Nikhil Abhyankar,Purvi Chaurasia,Sanchit Kabra,Ananya Srivastava,Vivek Gupta,Chandan K. Reddy
### Background
现有的表格推理基准主要测试模型在小型、均匀表格上的表现，未能充分反映真实世界数据的复杂性，从而对大语言模型（LLMs）的推理能力产生了片面的看法。实际表格往往较长、异构且具有特定领域性，混合了结构字段和自由文本，需要跨越数千个标记的多跳推理。
### Innovation
本文引入RUST-BENCH，这是一个包含7966个问题的数据集，来自于2031个真实世界的表格，涵盖了两个领域：i）RB-Science（NSF资助记录）；ii）RB-Sports（NBA统计数据）。不同于以往的工作，RUST-BENCH同时评估了模型在规模、异构性、领域特定性和推理复杂性方面的表现。
### Conclusion
实验结果表明，LLMs在处理异构模式和复杂多跳推理方面面临挑战，这揭示了当前架构中的持续弱点并推动了策略的发展。RUST-BENCH为推进表格推理研究建立了新的具有挑战性的测试床。
## 114. `cs.AI` - 生成、评估、迭代：为LLM法官人工循环优化合成数据 [PDF](https://arxiv.org/pdf/2511.04478), [HTML](https://arxiv.org/abs/2511.04478)
### Authors
Hyo Jin Do,Zahra Ashktorab,Jasmina Gajcin,Erik Miehling,Martín Santillán Cooper,Qian Pan,Elizabeth M. Daly,Werner Geyer
### Background
LLM-as-a-judge范式能够提供灵活、用户定义的评估方式，但其效果往往受限于可用的多样化和代表性数据稀缺，用于细化评估标准。研究通过一个工具解决了这一问题，该工具将合成数据生成整合到LLM-as-a-judge的工作流中，使用户能够创建定制化的、具有挑战性的测试案例，包括边界情况，并支持现有的测试案例的AI辅助实时编辑。工具还揭示了数据生成背后的提示和解释，增加了透明度和可解释性。在一项用户研究中发现，该工具受到83%的参与者的偏好，因为它允许用户快速生成多样化的合成数据而无需额外的工作量，生成的合成数据在细化评估标准和与人类偏好对齐方面与手动制作的数据一样有效。此研究结果强调了合成数据在提高效率和可扩展性方面具有潜在的替代作用，特别是在这些特性至关重要的情况下，
### Innovation
该工具将合成数据生成融入到LLM-as-a-judge的工作流中，让用户能够创建具有灵活配置的定制化和挑战性的测试案例。同时，它支持AI辅助的实时编辑现有测试案例，并提供生成数据背后的提示和解释，增强了透明度和可解释性。用户研究显示，该工具明显提升了效率，生成的合成数据在评估标准的精细化和人类偏好对齐方面与手工制作的数据一样有效。
### Conclusion
研究结果表明，合成数据作为一种有效的生成方法，特别是在追求效率和可扩展性的情境下，替代了传统的手动生成或选择测试案例的做法，为LLM法官的人工循环优化提供了一种新的途径。
## 115. `cs.AI` - Q3R：迭代加权秩正则化器以实现有效的低秩训练 [PDF](https://arxiv.org/pdf/2511.04485), [HTML](https://arxiv.org/abs/2511.04485)
### Authors
Ipsita Ghosh,Ethan Nguyen,Christian Kümmerle
### Background
低秩优化基于的参数高效训练已经成为一种高度成功的工具，用于微调大型深度学习模型。然而，在低秩预训练任务中，保持低秩结构和目标函数的挑战使得这些方法在这种任务中表现不佳。
### Innovation
提出了一种名为Q3R的二次加权秩正则化器，这是一种新颖的低秩诱导训练策略，受迭代重加权最小二乘（IRLS）框架的启发。Q3R基于一个二次正则化项，该项作为秩的近似目标最大化平滑对数行列式。与其它低秩训练技术相比，Q3R能够以可忽略的计算开销训练具有指定低目标秩的权重矩阵，同时保持与现有架构的完全兼容性，并能实现与全连接模型类似的预测性能。例如，通过实验表明，能够将ViT-Tiny模型的60%和80%参数分别削减至CIFAR-10性能下降1.3%和4%，余下的参数为模型的低秩训练提供了坚实的基础，而不牺牲预测性能。
### Conclusion
Q3R在图像和语言任务中的变换器中得到了有效性验证，包括低秩微调，展示了其在低秩训练中的适用性和效果。
## 116. `cs.AI` - 语言模型是否意识到未走的道路？token级别不确定性与隐藏状态动态 [PDF](https://arxiv.org/pdf/2511.04527), [HTML](https://arxiv.org/abs/2511.04527)
### Authors
Amir Zur,Atticus Geiger,Ekdeep Singh Lubana,Eric Bigelow
### Background
在语言模型生成文本时，个体词项的选择可能导致不同的推理路径，这使得不确定性难以量化。本文探讨了语言模型在生成过程中是否能够代表其可能采取的不同推理路径。
### Innovation
作者利用隐藏激活来控制和预测语言模型在链式推理过程中的不确定性，并发现模型的不确定性与其可控制性之间存在明显相关性。这些结果表明激活干预最有效的时机是在模型尚未完全确定最终答案时，同时隐藏激活还可以预测模型未来结果分布，表明模型隐含地表示了可能路径的空间。
### Conclusion
本文研究发现，语言模型在生成过程中确实能够代表其可能采取的不同推理路径。通过控制隐藏激活，可以影响模型的不确定性。同时，隐藏激活还可以预测模型未来的结果分布，说明模型内部隐含地表示了各种可能的推理路径。
## 117. `cs.AI` - 刑事司法中的替代公平性和准确度优化 [PDF](https://arxiv.org/pdf/2511.04505), [HTML](https://arxiv.org/abs/2511.04505)
### Authors
Shaolong Wu,James Blume,Geshi Yeung
### Background
算法公平性研究领域迅速发展，但在刑事司法领域，核心概念依旧不清楚。本文回顾了群体公平性、个体公平性和过程公平性，并分析了它们之间的冲突。研究指出，在保护群体之间的准确率差异控制在一定范围内，而不是精确平等，以优化准确度和凸显误差成本伦理选择，为解决了算法公平性遇到的一些挑战提供了新的思路。
### Innovation
提出了一种对标准群体公平性的简单改进建议，即在保护群体之间的假阴性率差异控制在一定范围内的基础上，最小化加权错误损失。这种方法更容易找到解决方案，可以提高预测精度，并揭示了误差成本的伦理选择。此外，该方法还应对数据偏差和不完整性、隐性的正向行动以及子群体约束的爆炸性增长这三类批评进行了应对，旨在为解决刑事司法中的算法公平性问题提供新的视角和方法。
### Conclusion
本文建议在公共决策系统中采用基于三个支柱的实用框架：基于需求的决策、透明度和问责性、以及精炼的定义和解决方案。通过这种方法将技术设计与合法性联系起来，并为使用风险评估及相关工具的机构提供了可操作的指导。
## 118. `cs.AI` - OUNLP在TSAR 2025共享任务中的表现：通过代码生成实现多轮文本简化 [PDF](https://arxiv.org/pdf/2511.04495), [HTML](https://arxiv.org/abs/2511.04495)
### Authors
Cuong Huynh,Jie Cao
### Background
本文描述了由作者提交至TSAR-2025共享任务（Alva-Manchego等人，2025）的OUNLP系统，该系统旨在使用LLM提示生成法来进行读写性控制的文本简化。通过对基于提示的文本简化方法的分析，作者发现文本简化的表现与源文本CEFR等级和目标CEFR等级之间的差距密切相关。这一发现激发了作者提出两种多轮简化方法，并使用GPT-4o进行生成。
### Innovation
本文的主要创新在于提出了两种基于规则的多轮简化方法（MRS-Rule）和联合基于规则的LLM简化方法（MRS-Joint），并且使用GPT-4o进行生成。这种方法能够显著提升文本简化的一系列性能。从大规模参与者中脱颖而出，该系统排名前20位。此外，通过使用LLM简化候选文本作为多轮简化过程的起点，能够进一步提高多轮简化的效果。
### Conclusion
最终，尽管排名居中，但仍显示出改进多轮简化效果的潜力，并表明采用LLM简化候选文本作为起点可以显著提升系统的整体性能。
## 119. `cs.AI` - 在大型语言模型中解码五大特质：温度依赖性表达与架构聚类 [PDF](https://arxiv.org/pdf/2511.04499), [HTML](https://arxiv.org/abs/2511.04499)
### Authors
Christos-Nikolaos Zacharopoulos,Revekka Kyriakoglou
### Background
随着大型语言模型（LLMs）在人类中心应用中的重要性不断增加，理解其类似人格的行为变得越来越重要，这对负责的发展和部署至关重要。本文系统地评估了六种LLMs，使用五大特质评估问卷（BFI-2）框架，以评估不同采样温度下的人格特征表达。研究表明，四种人格维度存在显著差异，神经质和外向性对温度调整特别敏感。进一步的层次聚类揭示了不同的模型簇，表明架构特征可能使某些模型倾向于稳定的特质档案。
### Innovation
本文创新性地使用五大特质评估问卷（BFI-2）框架系统地评估了六种LLMs的人格特征表达，并发现了温度对神经质和外向性的影响。此外，通过层次聚类分析，揭示了模型之间的差异，这为理解LLMs中人格特征的涌现提供了新的见解，并为模型调优、选择以及AI系统的伦理治理提供了新的视角。
### Conclusion
研究表明，LLMs在不同的人格维度上表现出显著的差异，并且神经质和外向性受到温度调整的影响较大。层次聚类分析揭示了不同模型之间的集群，表明架构特征可能影响模型的人格特征表现。这些结果为理解LLMs中人格特征的涌现提供了新的见解，并为模型调优、选择和AI系统的伦理治理提供了新的视角。
## 120. `cs.AI` - RAGalyst: 自动化的人文对齐代理评价框架用于特定领域的RAG [PDF](https://arxiv.org/pdf/2511.04502), [HTML](https://arxiv.org/abs/2511.04502)
### Authors
Joshua Gao,Quoc Huy Pham,Subin Varghese,Silwal Saurav,Vedhus Hoskere
### Background
RAG是将大型语言模型与事实证据联系起来的关键技术，但在特定、安全关键领域的RAG系统评估仍然是一个重大挑战。现有评估框架往往依赖于基于启发式的指标，这些指标未能捕捉领域特定的细微差异；其他工作则使用LLM作为裁判的方法，缺乏与人类判断验证的对齐。
### Innovation
RAGalyst是一个自动化且与人类对齐的代理框架，用于严谨评估特定领域的RAG系统。该框架包含一个生成高质量合成问答数据集的代理管道，并通过代理筛选步骤确保数据保真度。RAGalyst优化了两个关键的LLM作为裁判指标——答案正确性和可回答性，以实现与人类注释的高度相关性。研究结果表明，RAG性能高度依赖于上下文，没有一个嵌入模型、大型语言模型或超参数配置适用于所有领域。此外，还分析了RAG中常见的答案正确性低的主要原因。
### Conclusion
这些发现强调了系统评估框架如RAGalyst的重要性，该框架使实践者能够揭示领域内的权衡并做出知情的设计选择，以构建可靠和有效的RAG系统。RAGalyst可在GitHub上获取。
## 121. `cs.AI` - LLM-as-a-Judge: 寻找推荐系统中的世界模型 [PDF](https://arxiv.org/pdf/2511.04541), [HTML](https://arxiv.org/abs/2511.04541)
### Authors
Baptiste Bonin,Maxime Heuillet,Audrey Durand
### Background
在推荐系统中，模型用户跨领域偏好建模仍然是一项关键挑战，特别是在推荐有序序列项目（即排列表推荐）方面。以往的研究主要探讨如何通过两两比较排列表来有效表达和建模用户偏好。
### Innovation
本文研究了大型语言模型（LLM）如何通过排列表两两推理有效作为用户偏好的世界模型。通过在不同数据集上开展实证研究，验证了LLM在排列表推荐任务中的性能，并根据偏好函数的属性探究了改进的方向，显示了LLM作为推荐系统中世界模型的潜力。
### Conclusion
实验结果表明，LLM在不同任务上的性能与其捕捉到的偏好函数的特性有关，这些发现为改进推荐系统的性能提供了指导，并强调了LLM作为推荐系统世界模型的潜力。
## 122. `cs.AI` - 探讨因果干预对神经网络中的离散表示的解决方法 [PDF](https://arxiv.org/pdf/2511.04638), [HTML](https://arxiv.org/abs/2511.04638)
### Authors
Satchel Grant,Simon Jerome Han,Alexa Tartaglini,Christopher Potts
### Background
当前常见的机制可解释方法是通过在模型表示中执行针对性的干预，以了解这些表示所编码的内容。然而，作者提出一个问题：这种干预是否会生成分布外（离散）的表示，进而影响对其结果解释和模型自然状态的忠实程度？
### Innovation
研究通过实证方法证明了常见因果干预技术往往会使内部表示偏离目标模型的自然分布，并通过理论分析识别出了两种类型的不同分布：无害的和有害的。此外，作者还提出了通过对干预进行修改来减轻有害不同分布的对策，并引入了一种新的正则化方法来减少有害不同分布的可能性，同时保持干预的解释力。
### Conclusion
这些研究表明，制定更加可靠的可解释性方法是有可能的，未来的研究可以通过此方向进一步提高模型的可解释性和准确性。
## 123. `cs.AI` - 基于等价讨论图语义的一阶逻辑等价性推理 [PDF](https://arxiv.org/pdf/2406.12163), [HTML](https://arxiv.org/abs/2406.12163)
### Authors
Ryuta Arisaka
### Background
目前缺乏一个可用于处理各种讨论与论辩模型的形式化推理框架，这限制了在人工智能领域更广泛地进行讨论和论辩的推理能力。现有的研究通常只能处理单个论点或论据结构，而无法处理更复杂的讨论和论辩模型。
### Innovation
文章提出了讨论图语义的一阶逻辑等价性，引入了用于一般讨论和论辩的更广泛的推理方法。第二，扩展了Dung的扩展概念，使图节点在推理框架中等价。第三，通过讨论图语义证明了这些扩展的一阶可描述性，从而可以在一阶逻辑中进行推理。这种框架对Dung的所有扩展的命题可描述性产生了直接结果。
### Conclusion
通过提出讨论图语义的一阶逻辑等价性，以及扩展Dung的扩展概念，该研究为处理复杂论辩模型和讨论提供了一种新的形式化方法，并证明了其在逻辑上的可描述性和推理能力。
## 124. `cs.AI` - X-Diffusion: 基于跨体态人类演示训练扩散政策 [PDF](https://arxiv.org/pdf/2511.04671), [HTML](https://arxiv.org/abs/2511.04671)
### Authors
Maximus A. Pace,Prithwish Dan,Chuanruo Ning,Atiksh Bhardwaj,Audrey Du,Edward W. Duan,Wei-Chiu Ma,Kushal Kedia
### Background
人类可以快速大规模录制视频，成为机器人学习的优质训练数据来源。然而，人类和机器人在体态上存在根本性的差异，导致动作执行不匹配。直接将人类手部动作的运动学重排会生成机器人无法执行的物理动作。尽管存在这些底层差异，人类演示仍提供了关于如何操作和与物体互动的重要运动线索。
### Innovation
提出X-Diffusion，一个原理性的框架，用于训练扩散策略，利用人类数据而不学习动态不可行的动作。X-Diffusion首先训练一个分类器来预测动作是人类执行还是机器人执行。之后，在添加足够噪声使得分类器不能区分其体态后，人类动作才被用于策略训练。一致性符合机器人执行的动作在低噪水平下监督主题细化去噪，而存在差异的人类动作在高噪水平下仅提供粗略指导。实验显示，简单的协同训练在执行不匹配下会削弱策略性能，而X-Diffusion在五个操作任务中持续提高了性能。
### Conclusion
在五个操作任务中，X-Diffusion的平均成功率比最佳基线提高了16%，实验结果表明X-Diffusion有效且适用于解决执行不匹配问题。
## 125. `cs.AI` - 在图变换器中结合结构和时间上下文进行关系深度学习 [PDF](https://arxiv.org/pdf/2511.04557), [HTML](https://arxiv.org/abs/2511.04557)
### Authors
Divyansha Lachi,Mahmoud Mohammadi,Joe Meyer,Vinam Arora,Tom Palczewski,Eva L. Dyer
### Background
在医疗保健、金融和电子商务等领域，关系数据的时间动态源自诸如患者与提供者或用户与不同类别产品之间的复杂互动。对这些数据的操作模型必须整合跨越多种实体的长距离空间和时间依赖关系，同时支持多个预测任务。然而，现有的针对关系数据的图模型主要关注空间结构，将时间信息仅视为过滤约束，用于排除未来事件，而未将其视为建模信号，并且通常设计用于单一任务预测。因此，这些模型存在不足：缺乏长程依赖整合能力以及跨任务集成能力，从而限制了其广泛应用的价值。
### Innovation
本文提出了一个时间子图采样器，通过检索超越 Immediate Neighbourhood 的节点来增强全局上下文以捕捉时间相关的关联，进一步提出了 Relation Graph Perceiver (RGP)，一种利用基于跨注意力的潜在瓶颈的图变换器架构。RGP 利用一个潜在瓶颈将来自不同节点和边类型的信息整合到一个共同的潜在空间中，使模型能够在整个关系系统中构建全局上下文。此外，RGP 还引入了灵活的跨注意力解码器，支持在一个模型中进行在不同标签空间内任务的联合学习实验结果表明，RGP 在 RelBench、SALT 和 CTU 上提供了最先进的性能，提供了一种通用且可扩展的解决方案，支持多种预测任务。
### Conclusion
RGP 通过结合时间上下文和结构上下文，显著提升了基于图的深度学习框架的性能，适应性和扩展性，尤其适用于涉及多种实体类型和预测任务的关系数据。
## 126. `cs.AI` - 多代理LLM系统在有限元分析中的协作动态及可靠性挑战 [PDF](https://arxiv.org/pdf/2408.13406), [HTML](https://arxiv.org/abs/2408.13406)
### Authors
Chuan Tian,Yilei Zhang
### Background
大型语言模型（LLM）驱动的多代理系统在科学和工程中的计算工作流自动化逐渐增多，但代理间动态如何影响推理质量和验证可靠性尚未明确。该研究构建了一个基于AutoGen的多代理框架，用于线弹性有限元分析（FEA），研究了四种任务下的七个角色配置，受限于12轮对话上限，进行了1120次实验。结果显示，合作效果主要依赖功能互补性，而非团队规模。其中三代理编码-执行-批评配置产生了物理和视觉上正确的解决方案，而冗余审核员的加入则降低了成功率。但仍存在三个系统性故障模式：①质疑偏见，反驳代理支持而非挑战输出（85-92%一致，包括错误）；②冗余审核员导致的过早共识；③验证和一致性验证之间的差距，导致物理上错误但可执行的代码未被发现。在复杂任务中，没有代理组合成功验证本构关系。
### Innovation
基于功能多样性、角色分化和计算验证理论，提出了可操作的设计原则：（i）分配互补代理角色；（ii）实施多级验证（执行、规范、物理学）；（iii）通过对抗或触发机制防止过早共识。这为工程工作流程中的可信LLM协作奠定了理论基础。
### Conclusion
研究确立了多代理LLM系统在工程工作流程中的设计指导原则，确保提高了推理质量和验证可靠性，并指出了优化协作动态的方法，以增强系统的可靠性。
## 127. `cs.AI` - Style2Code：一种基于双模态对比表示学习的可样式控制代码生成框架 [PDF](https://arxiv.org/pdf/2505.19442), [HTML](https://arxiv.org/abs/2505.19442)
### Authors
Dutao Zhang,Nicolas Rafael Arroyo Arias,YuLong He,Sergey Kovalchuk
### Background
可控代码生成，即在保持功能的同时生成符合指定风格的代码，仍然是一个具有挑战性的问题。现有的方法在实现样式控制和代码正确性之间存在权衡。
### Innovation
该论文提出了一种结合对比学习和条件解码的双阶段训练框架，实现灵活的样式控制。首先将代码风格表示与语义和结构特征对齐，然后基于学习到的样式向量微调语言模型以指导生成。该方法通过轻量级混合支持样式插值和用户个性化，统一框架在提高样式控制方面优于以前工作，同时不牺牲代码的正确性。这是将对比对齐与条件解码结合用于样指导代码生成的第一个方法。
### Conclusion
该框架在保持代码正确性的同时实现了增强的样式控制，为可控代码生成提供了一个新的统一解决方案。
## 128. `cs.AI` - 《让我们就此达成一致》：探讨文本总结中可解释的人工智能的分歧问题 [PDF](https://arxiv.org/pdf/2410.18560), [HTML](https://arxiv.org/abs/2410.18560)
### Authors
Seema Aswani,Sujala D. Shetty
### Background
文本摘要中可解释的人工智能（XAI）方法对于理解模型行为和增强对模型生成总结的信任至关重要。然而，最近的研究突出了一个关键问题——分歧问题。当不同的XAI方法对同一模型结果给出矛盾的解释时，这种分歧会导致解释的不一致性，从而降低对模型理解的信心，对于安全和负责的人工智能应用尤为重要。尽管XAI方法的有效性，已有研究首次实证调查了文本摘要中的分歧问题，发现这种不一致性在最先进的摘要模型中普遍存在。因此，有必要提出新的方法来减少不同XAI方法之间的不一致性以增加对AI生成摘要的信任度。因此，本文提出了基于区域划分的新型解释方法——区域可解释AI（RXAI），通过使用句子变换器和聚类，将每篇文章拆分为更小、更连贯的段落。
### Innovation
本文提出了一种新的基于区域划分的可解释的人工智能方法（RXAI），它通过将文章分割成较小、更连贯的段落，单独对每个段落应用XAI方法，从而创造局部解释，以减少不同XAI方法之间的不一致性，提高了对AI生成摘要的信任度。此外，该方法还开发了一个交互式的JavaScript可视化工具，用于在句子级别进行容易且带有颜色标记的答案探索，增强了用户对模型解释的理解。
### Conclusion
研究结果表明，局部解释比全面解释更一致。所提出的RXAI方法在两个基准摘要数据集中（Extreme Summarization（Xsum）和CNN/Daily Mail）得到验证，显示出分歧显著减少。这表明RXAI方法能够有效减少不同XAI方法之间的分歧，从而增强对AI生成摘要的信任度。
## 129. `cs.AI` - 在无地面真实值的情况下评估受LLM污染的众包数据 [PDF](https://arxiv.org/pdf/2506.06991), [HTML](https://arxiv.org/abs/2506.06991)
### Authors
Yichi Zhang,Jinlong Pang,Zhaowei Zhu,Yang Liu
### Background
生成式AI的成功突显了高质量人类反馈在构建可信赖AI系统中的关键作用。然而，通过众包工作者使用大型语言模型（LLMs）可能导致数据集被LLM生成的响应所污染。现有探测LLM的方法主要依赖高维度训练数据如文本，这不适合标记任务如多项选择标注。因此，本文探讨了同伴预测机制——一种在不使用地面真实值的情况下评估工人反馈信息的机制，以减轻众包中的LLM协助作弊问题，特别是在标注任务方面。该研究基于先前的研究，提出了一种无需训练的评分机制，并在考虑LLM串通的众包模型下提供了理论保证。文章建立了一套方法的有效条件，并通过现实世界数据集的实证分析证明了其在检测低效率作弊方面的鲁棒性。
### Innovation
本文提出了一种无需训练的评分机制，用于在考虑到LLM串通的众包模型下评估受LLM污染的数据，并提供了在理论上的保证。
### Conclusion
本文通过建立条件和现实数据集的实证分析，证明了提出的机制在检测低效率的LLM协助作弊方面的有效性与鲁棒性。
## 130. `cs.AI` - 跨模态因果干预在阿尔茨海默病预测中的应用 [PDF](https://arxiv.org/pdf/2507.13956), [HTML](https://arxiv.org/abs/2507.13956)
### Authors
Yutao Jin,Haowen Xiao,Junyong Zhai,Yuxiao Li,Jielei Chu,Fengmao Lv,Yuxiao Li
### Background
轻度认知障碍（MCI）作为阿尔茨海默病（AD）的早期阶段，早期识别和干预能够有效延缓向痴呆症的进展。然而，AD的诊断仍然在神经科学中是一个重大挑战，主要由于多模态数据的选择偏差引起的各种混杂因素以及变量间的复杂关系造成的干扰。这些因素使得非因果模型容易捕捉到错误的输入输出相关性，导致结果不够可靠。因此，开发能够减轻混杂因素影响的新型诊断辅助体系是迫切需要的。
### Innovation
本文提出了一种名为MediAD的创新性视觉语言因果干预框架。该框架利用大型语言模型（LLMs）对临床数据进行严格模板化总结，增强了文本输入。MediAD运用磁共振成像（MRI）、临床数据和通过LLMs增强的文本数据来分类为认知正常（CN）、轻度认知障碍（MCI）和阿尔茨海默病（AD）等类别。此框架通过统一的因果干预方法减轻了可观察和不可观察的混杂因素的影响。实验结果显示，MediAD在区分CN/MCI/AD案例方面表现优异，多项评估指标上优于其他方法。
### Conclusion
本文展示了将因果推理与多模态学习相结合在神经疾病诊断中的潜力。跨模态因果干预框架MediAD通过减轻混杂因素的影响，有效的提高了对AD患者识别的准确性。
## 131. `cs.AI` - 从临床出发的病理基础模型 [PDF](https://arxiv.org/pdf/2510.23807), [HTML](https://arxiv.org/abs/2510.23807)
### Authors
Hamid R. Tizhoosh
### Background
在非医学领域，基础模型（FMs）通过大规模自我监督和多模态学习在计算机视觉和语言处理方面取得了革命性进展。因此，人们预期这些模型在计算病理学中的快速应用将对癌症诊断、预后和多模态检索带来类似的突破。然而，近期系统评估揭示了基础模型存在的根本缺陷：诊断准确性低、鲁棒性差、几何不稳定、计算需求大和安全漏洞令人心忧。
### Innovation
本文作者分析了基础模型在病理学中的应用现状，指出了其概念上的不足，并识别了七大原因：生物复杂性、无效的自我监督、过度泛化、过度复杂的架构设计、缺乏特定领域创新、数据不足以及与组织切片尺寸相关的根本设计缺陷。
### Conclusion
现有病理基础模型在概念上与组织形态的本质存在偏差，呼吁重新思考基础模型的主要范式。
## 132. `cs.AI` - 基于大脑启发的情感共鸣机制构建具有 altruistic 和道德行为的人工智能代理 [PDF](https://arxiv.org/pdf/2410.21882), [HTML](https://arxiv.org/abs/2410.21882)
### Authors
Feifei Zhao,Hui Feng,Haibo Tong,Zhengqiang Han,Erliang Lin,Enmeng Lu,Yinqian Sun,Yi Zeng
### Background
随着人工智能与人类社会的紧密结合，确保其行为的安全性、利他性和与人类伦理和道德价值观的一致性变得至关重要。然而，现有研究在将伦理考量嵌入人工智能方面的成果尚不充分，以前基于原则和规则的外部约束无法为人工智能提供长期的稳定性和泛化能力。情感共鸣内在地激发了通过情感分享和传染机制来缓解他人消极情绪的利他行为。基于此，本文借鉴人类情感共鸣驱动利他决策的神经机制，模拟共享自我-他人感知-镜像-共鸣神经回路，构建了一个基于情感共鸣驱动利他决策的人工智能模型。模型通过情感共鸣直接影响多巴胺的释放，形成内在的利他动机。该模型在三个实验场景下展示了持续一致的利他行为表现：情绪传染集成的双主体利他救援、多主体游戏和机器人情感共鸣互动场景。深入分析证实了情感共鸣水平与利他偏好之间的正相关性（与心理行为实验结果一致），同时展示了伙伴的情感共鸣水平如何影响代理的行为模式。进一步验证该模型在涉及自我利益和他人福祉冲突的道德困境、部分可观测环境和对抗防御场景中的性能和稳定性。这项工作为开发伦理对齐的人工智能提供初步探索，为构建类似人类情感共鸣驱动的道德决策视角做出了贡献。
### Innovation
本文构建了一个基于情感共鸣驱动利他决策的人工智能模型，该模型模仿人类的神经机制，通过情感共鸣实现内在的利他动机，并在多个实验环境中展示了稳定的利他行为。这为人工智能道德决策提供了新的视角，并致力于提升AI的伦理对齐。
### Conclusion
本文通过建立一种新型的基于情感共鸣驱动利他决策的AI模型，验证了情感共鸣与利他行为之间的关联性，并展示了其在不同情境下的稳定性和适应性。研究为未来开发伦理对齐的人工智能提供了初步的理论依据和实践指导。
## 133. `cs.AI` - 结构化辩论提高金融AI中企业信用推理 [PDF](https://arxiv.org/pdf/2510.17108), [HTML](https://arxiv.org/abs/2510.17108)
### Authors
Yoonjin Lee,Munhee Kim,Hanbi Choi,Juhyeon Park,Seungho Lyoo,Woojin Park
### Background
尽管在金融AI领域取得了进步，但在企业信用评估中基于证据的自动化推理仍面临挑战。非财务定量指标在贷款偿还结果中起着决定性作用，但难以被形式化。现有方法主要集中在数值预测，未能为专业贷款评估所需的解读判断提供支持。
### Innovation
本研究开发并评估了两种基于大规模语言模型（LLM）的操作系统，旨在从非财务证据中生成结构化推理。第一种是非对抗性的单一代理系统（NAS），通过单步推理管道进行双向分析。第二种是基于辩论的多代理系统（KPD-MADS），通过基于卡尔·波普尔批判性对话框架的十个步骤结构化互动协议实现对抗性验证。这两种系统应用于三个真实的企业案例，并由经验丰富的信贷风险专家进行评估。
### Conclusion
相比于手工专家报告，两种系统均实现了显著的生产率提升（NAS：每个案例11.55秒；KPD-MADS：91.97秒；人类基线：1920秒）。KPD-MADS在解释恰当性、实际适用性和易用性方面表现更好，分别获得了更高的中位评分（4.0 vs. 3.0，4.0 vs. 3.0，62.5 vs. 52.5）。这些结果表明，结构化的多代理互动可以增强金融AI中的推理严密性和可解释性，推动企业信用评估中可扩展和可辩护的自动化进程。
## 134. `cs.AI` - Seg the HAB: Language-Guided Geospatial Algae Bloom Reasoning and Segmentation [PDF](https://arxiv.org/pdf/2510.18751), [HTML](https://arxiv.org/abs/2510.18751)
### Authors
Patterson Hsieh,Jerry Yeh,Mao-Chi He,Wen-Han Hsieh,Elvis Hsieh
### Background
气候变化加剧了有害藻华（HAB），尤其是蓝细菌的频繁发生，威胁到水生生态系统和人类健康。传统的人工水样监测方法劳动密集，空间和时间覆盖有限。近年来，远程传感器中的视觉-语言模型（VLMs）展示了大规模AI驱动解决方案的潜力，但对图像的理解和藻华严重程度的量化仍然存在挑战。
### Innovation
提出了ALGae Observation and Segmentation (ALGOS) 系统，结合了遥感图像理解和严重程度估计。该方法整合了GeoSAM辅助的人工评价以生成高质量的分割掩码，并使用NASA的Cyanobacteria Aggregated Manual Labels (CAML) 对视觉语言模型进行微调。实验表明，ALGOS在分割和严重程度估计方面均表现出稳健的性能，为实际的自动化蓝细菌监测系统铺平了道路。
### Conclusion
ALGOS系统在藻华监测的分割和严重程度估计方面表现出稳健的性能，为 praktical 蓝细菌监测系统的发展提供了新思路，并展示了视觉-语言模型在该领域的应用潜力。
## 135. `cs.AI` - 自主工程设计：一个知识引导的多智能体框架 [PDF](https://arxiv.org/pdf/2511.03179), [HTML](https://arxiv.org/abs/2511.03179)
### Authors
Varun Kumar,George Em Karniadakis
### Background
工程设计过程通常需要来自多个领域的专业知识，这会导致复杂的合作和反复的改进。传统的工程设计方法往往资源密集且容易出现低效率的问题。
### Innovation
我们通过建立一个集成结构化设计和审查循环的多智能体人工智能框架来正式化工程设计过程。该框架引入了专门的知识驱动智能体来协作生成和改进设计提案。
### Conclusion
本研究展示了如何通过配备结构化知识表示的协作智能体来提高工程设计过程的效率、一致性和质量。
## 136. `cs.AI` - BOTS：LLM强化微调中贝叶斯在线任务选择的统一框架 [PDF](https://arxiv.org/pdf/2510.26374), [HTML](https://arxiv.org/abs/2510.26374)
### Authors
Qianli Shen,Daoyuan Chen,Yilun Huang,Zhenqing Ling,Yaliang Li,Bolin Ding,Jingren Zhou
### Background
强化微调（RFT）是将大型语言模型（LLMs）与人类偏好对齐并增强其推理能力的关键技术，但其效果高度依赖于训练期间探索的任务。均匀的任务采样效率低下，会浪费计算资源在既不重要也不可行的任务上，而现有的任务选择方法常常面临高生成成本、适应性差或证据不完整的问题。
### Innovation
提出了一种名为BOTS（贝叶斯在线任务选择）的统一框架，该框架基于贝叶斯推理，能够自适应地维护模型演化过程中任务难度的后验估计。BOTS将直接评估选定任务的显式证据和通过这些评估推断的未选任务隐式证据结合起来，使用Thompson采样确保探索与利用之间的平衡。为使隐式证据实用化，BOTS使用超轻量的插件进行无额外生成的难度估算，几乎不会增加额外开销。
### Conclusion
在不同的领域和LLM规模下，BOTS相对于基准模型和删减模型，在提高数据效率和性能方面表现出一致性优势，提供了一个实用且可扩展的动态任务选择解决方案，在LLM强化微调中具有显著的效果和前景。
## 137. `cs.AI` - Orion-MSP: 多尺度稀疏注意机制用于表格式上下文学习 [PDF](https://arxiv.org/pdf/2511.02818), [HTML](https://arxiv.org/abs/2511.02818)
### Authors
Mohamed Bouadi,Pratinav Seth,Aditya Tanna,Vinay Kumar Sankarapu
### Background
表格式数据仍然是现实世界应用的主要格式。然而，开发针对表格式数据的有效神经网络模型仍然具有挑战性，因为它们涉及到异质特征类型以及多尺度的复杂相互作用。尽管最近在表格式上下文学习（ICL）方面的进展，如TabPFN和TabICL，已实现了与梯度提升树（GBTs）相当的性能，但现有架构仍存在几个关键限制：单一尺度的特征处理忽略了层次结构依赖性；密集注意力机制导致计算复杂度随表格宽度呈平方级增长；严格顺序组件处理阻止了重复的表示精炼和跨组件的通信交流。
### Innovation
Orion-MSP架构包含三个关键创新：（1）多尺度处理以捕捉层次特征交互作用；（2）块稀疏注意力机制，综合采用了窗口化、全局和随机模式以实现高效性和远程连接性；（3）借鉴Perceiver架构风格的内存容量，支持组件间安全的双向信息流。这些创新解决了现行架构中的局限性，提高了在复杂表格数据上的处理能力和性能，同时保持了有效的扩展性，建立了更高效的数据表上下文学习的新标准。
### Conclusion
Orion-MSP在多种基准测试中匹配或超过了最先进的性能，同时能够有效扩展到高维度的表格数据，确立了在高效表格式上下文学习中的新标准。模型已公开发布。
## 138. `cs.AI` - Unified Kernel for Neural Network Learning [PDF](https://arxiv.org/pdf/2403.17467), [HTML](https://arxiv.org/abs/2403.17467)
### Authors
Shao-Qun Zhang,Zong-Yi Chen,Yong-Ming Tian,Xun Lu
### Background
过去几十年，神经网络学习与核学习的区分和联系引起了广泛的关注。近年来，理论研究取得进展，将无限宽度的神经网络与高斯过程联系起来。两种主要方法是神经网络高斯过程（NNGP）和神经切线核（NTK）。NNGP基于贝叶斯推理，是一种零阶核；NTK基于梯度下降的切线空间，是一种一阶核。
### Innovation
本文提出了统一神经核（UNK），这是一种通过生成变量的内积诱导的核，能够表征基于梯度下降和参数初始化的神经网络的学习动力学。UNK核保留了NNGP和NTK的极限性质，在有限的学习步数下表现出类似NTK的行为，并在学习步数接近无穷大时收敛到NNGP。此外，本文还理论地阐述了UNK核的统一性，提供了关于该统一核的严格证明和整个学习过程的理解。
### Conclusion
实验结果证明了我们所提出的Unified Neural Kernel的有效性。
## 139. `cs.AI` - Stochastic Diffusion: 一种用于随机时间序列预测的扩散概率模型 [PDF](https://arxiv.org/pdf/2406.02827), [HTML](https://arxiv.org/abs/2406.02827)
### Authors
Yuansan Liu,Sudanthi Wijewickrema,Dongting Hu,Christofer Bester,Stephen O'Leary,James Bailey
### Background
近期扩散概率模型的创新已经为图像、文本和音频生成带来了重要进展，使其在生成时间序列预测方面得到了应用。然而，要利用这些能力对高度随机的时间序列数据进行建模仍然是一个挑战。
### Innovation
本文提出了一个名为StochDiff的新模型，通过利用随机潜在空间的表示能力，在每个时间步骤中学习数据驱动的先验知识，以建模多变量时间序列数据的变异性。这种方法使模型能够捕捉复杂的时序动态和数据的固有不确定性，从而提高了其对高度随机时间序列数据建模的能力。
### Conclusion
通过在真实世界数据集上的广泛实验，我们展示了解决随机时间序列预测的有效性，并且利用该模型在实时手术指导中的应用实例，探讨了其在医疗领域的潜在价值。
## 140. `cs.AI` - 法律事实预测：法律判决预测的关键环节 [PDF](https://arxiv.org/pdf/2409.07055), [HTML](https://arxiv.org/abs/2409.07055)
### Authors
Junkai Liu,Yujie Tong,Hui Huang,Bowen Zheng,Yiran Hu,Peicheng Wu,Chuan Xiao,Makoto Onizuka,Muyun Yang,Shuyuan Zheng
### Background
法律判决预测(LJP)是帮助当事人及其律师预测判决结果并优化诉讼策略的重要自然语言处理(NLP)任务。现有研究通常依靠通过证据确立的法律事实来预测判决结果。然而，这些事实往往在诉讼早期难以获得，限制了基于事实的LJP的实际应用。
### Innovation
本文提出了一种新的法律NLP任务——法律事实预测(LFP)，该任务以当事人提交的证据作为输入来预测法律事实，从而使得基于事实的LJP技术能够在缺乏真实法律事实的情况下作出预测。此外，作者还首次提出了一个用于评估LFP任务的基准数据集LFPBench。
### Conclusion
广泛的实验表明，LFP增强的LJP有效，并且强调了LFP在法律行业中具有广阔的研究方向和发展潜力。
## 141. `cs.AI` - SnapStream：在数据流加速器上高效解码长序列 [PDF](https://arxiv.org/pdf/2511.03092), [HTML](https://arxiv.org/abs/2511.03092)
### Authors
Jonathan Li,Nasim Farahini,Evgenii Iuliugin,Magnus Vesterlund,Christian Haggstrom,Guangtao Wang,Shubhangi Upasani,Ayush Sachdeva,Rui Li,Faline Fu,Chen Wu,Ayesha Siddiqua,John Long,Tuowen Zhao,Matheen Musaddiq,Hakan Zeffer,Yun Du,Mingran Wang,Qinghua Li,Bo Li,Urmish Thakker,Raghu Prabhakar
### Background
随着像LLaMA-3.1-8B-Instruct和DeepSeek-R1这样的大型语言模型（LLMs）参数超过十亿且支持超过10万上下文长度，对片上内存的需求也在增加，以支持大型键值（KV）缓存。尽管StreamingLLM和SnapKV等技术展示了如何在保持模型准确性的同时控制KV缓存大小，但这些技术在诸如vLLM或SGLang这样的框架中进行工业部署时仍然不太常见。原因有两个方面：一方面，这些框架采用静态图和连续批次处理方法，难以修改标准多头注意力算法；另一方面，这类技术在现代遵循指令和推理模型中的准确性影响尚不明确，因此没有明确需要实现这些技术。因此，本研究探讨了这些准确性影响，并开发了SnapStream，这是一种适用于大规模部署的KV缓存压缩方法，其结果在SambaNova SN40L加速器上的真实生产环境中展示了其有效性。
### Innovation
本研究开发了SnapStream，这是一种KV缓存压缩方法，可以在保留模型准确性的情况下压缩缓存，特别适用于具有静态图和连续批次处理方法的大型语言模型框架，如vLLM或SGLang。研究通过16路张量并行部署DeepSeek-671B在SambaNova SN40L加速器上实现了片上内存使用效率提升了4倍，并且对于LongBench-v2、AIME24和LiveCodeBench等基准测试展示了最小的准确性退化。这是首次在具有静态图和连续批次处理方法的生产推理系统中实现稀疏的KV注意力技术的部署。
### Conclusion
研究展示了SnapStream在真实生产环境中大规模部署的有效性，并且该方法提升了片上内存使用效率，并保持了模型在长序列上的推理准确性。
## 142. `cs.AI` - 在算子学习和普遍逼近中的投影方法 [PDF](https://arxiv.org/pdf/2406.12264), [HTML](https://arxiv.org/abs/2406.12264)
### Authors
Emanuele Zappala
### Background
本文使用Leray-Schauder映射获得了一种新的连续的（可能是非线性的）算子在任意Banach空间上的普遍逼近定理。在此基础上，提出了用于函数空间$L^p$（多变量函数）的算子学习方法，该方法基于多项式基的正交投影。对于$p=2$的情况，给出了逼近结果成立的一些充分条件。这项研究为算子学习中的深度学习方法提供了理论框架。
### Innovation
本文的主要创新在于：1) 使用Leray-Schauder映射获得新的普遍逼近定理；2) 提出了一种新的方法用于Banach空间$L^p$中多变量函数的算子学习；3) 对于$p=2$的情形，给出了具体的逼近结果成立的条件。
### Conclusion
本文通过理论分析和方法研究，为多变量函数算子学习和普遍逼近提供了新的理论支持和方法框架，特别是对于$L^2$空间，提供了具体的实现场景下的逼近条件。这项工作为进一步的算子学习研究奠定了基础。
## 143. `cs.AI` - LLM目标性能不足不成比例地影响弱势用户 [PDF](https://arxiv.org/pdf/2406.17737), [HTML](https://arxiv.org/abs/2406.17737)
### Authors
Elinor Poole-Dayan,Deb Roy,Jad Kabbara
### Background
尽管最先进的大型语言模型在许多任务上表现出色，但有关模型行为的大量研究仍然集中在诸如幻觉和偏差等不良行为上。本文研究了用户特质（如英语水平、教育水平和国籍）对大型语言模型响应质量的影响，尤其是这些响应在信息准确度、真实性以及拒绝方面的影响。通过实证研究，发现大型语言模型的表现不佳在一定程度上对低英语水平、低教育水平和非美国籍的用户不成比例地影响明显，导致这些模型对这些最脆弱的用户来说不可靠的信息源。
### Innovation
本研究首次详细探讨了用户特质对大型语言模型响应质量的影响，特别是从英语水平、教育水平和国籍三个方面进行了分析。研究使用了三个最新的大型语言模型和两个不同数据集来验证真实性与事实性。通过实证分析指出，对于最脆弱的用户群体，大型语言模型的不良行为出现得更频繁。
### Conclusion
大型语言模型的不良行为在涉及低英语水平、低教育水平和非美国籍用户时发生得更多，这使得这些模型对最脆弱的用户来说不可靠。
## 144. `cs.AI` - 增强深度学习的剩余柯莫哥洛夫-阿诺尔德网络 [PDF](https://arxiv.org/pdf/2410.05500), [HTML](https://arxiv.org/abs/2410.05500)
### Authors
Ray Congrui Yu,Sherry Wu,Jiang Gui
### Background
尽管深度卷积神经网络（CNNs）取得了巨大的成功，但由于网络深度中包含数百层，优化和训练这些网络仍然具有挑战性且成本高昂。传统的卷积操作本质上受限于其线性性质以及固定的激活函数，需要许多层来学习数据中的有意义模式。由于网络的巨大规模，这种方法在计算上效率低下，并且在小数据集上存在过拟合或梯度爆炸的风险。因此，我们引入了一个“插件”模块，称为剩余柯莫哥洛夫-阿诺尔德网络（RKAN）。
### Innovation
我们的模块非常紧凑，可以轻松添加到传统深度网络的任何阶段（层级），它学习整合支持多项式特征转换到现有的卷积框架中。RKAN在不同的视觉任务和广泛测试的基准中的一致性改进超越了基线模型，实现了前沿性能。
### Conclusion
RKAN在不同视觉任务上的表现达到了前沿水平，提供了一种有效的途径，可以在传统深度网络中增强学习效果，同时保持模型的紧凑性和平坦化优势。
## 145. `cs.AI` - 多智能体强化学习中目标干预的基本原则 [PDF](https://arxiv.org/pdf/2510.17697), [HTML](https://arxiv.org/abs/2510.17697)
### Authors
Anjie Liu,Jianhong Wang,Samuel Kaski,Jun Wang,Mengyue Yang
### Background
在多智能体强化学习（MARL）中，通过全局的人工干预指导复杂系统尤其在大规模场景中是不切实际的。现有的设计外部机制（如内在奖励和人工反馈）来协调智能体的方法大多是基于经验研究，缺乏一个易于使用的研究工具。因此，提出了一种多智能体影响图（MAIDs）作为图形框架来解决这些问题。MAIDs用于分析和可视化MARL中的无指导自我组织和全局指导机制，通过引入一种称为目标干预范式的新型MARL交互范式，旨在减少全局指导的问题。同时，通过因果推理技术，即预策略干预（PSI），实现场景中的目标干预。MAIDs的聚合相关性图分析工具用于识别设计的MARL交互范式下的MARL学习范式是否可行。
### Innovation
引入了多智能体影响图（MAIDs）作为解决MARL问题的图形框架，并提出了一种称为目标干预范式的新型MARL交互范式。通过因果推理技术预策略干预（PSI）来实现目标干预。此外，使用MAIDs的聚合相关性图分析作为工具进行奖励机制的识别判断。
### Conclusion
本研究表明了目标干预的有效性，并验证了相关性图分析的结果，证实了提出的方法可以在实际应用中有效减少全局指导的问题，并提高MARL系统的自我组织能力。
## 146. `cs.AI` - 超越科罗莫哥洛夫障碍：一种可学习加权混合自动编码器的模型降阶方法 [PDF](https://arxiv.org/pdf/2410.18148), [HTML](https://arxiv.org/abs/2410.18148)
### Authors
Nithin Somasekharan,Shaowu Pan
### Background
高维复杂物理系统的表示学习旨在识别低维度的本质隐空间，这对于减少阶模型和模态分析至关重要。尽管近年来引入了深度自动编码器来克服著名的科罗莫哥洛夫障碍，但当潜在空间的秩增加时，它们通常表现出较差的收敛行为。
### Innovation
本文提出了一种可学习加权混合自动编码器，这是一种结合了奇异值分解（SVD）与深度自动编码器的混合方法，通过可学习加权框架。研究成果在于指出引入可学习权重参数是至关重要的；并且实验结果表明，该模型的尖锐度比其他模型低数以千计的倍数。这款方法在1D库拉托夫斯基和强迫各向同性湍流数据集上的实验中，显著提升了各类竞争模型的一般化性能。
### Conclusion
将本文提出的技术与时间序列建模技术（如库普曼算子，LSTM）结合使用时，对于高维多尺度偏微分方程系统的代理建模提供了显著的改进。
## 147. `cs.AI` - 理解Adam需要更好的旋转依赖假设 [PDF](https://arxiv.org/pdf/2410.19964), [HTML](https://arxiv.org/abs/2410.19964)
### Authors
Tianyue H. Zhang,Lucas Maes,Alan Milligan,Alexia Jolicoeur-Martineau,Ioannis Mitliagkas,Damien Scieur,Simon Lacoste-Julien,Charles Guille-Escuret
### Background
尽管Adam在广泛应用中表现出色，但其相对于随机梯度下降（SGD）的优势缺乏全面的理论解释。本文探讨了Adam在参数空间旋转下的敏感性。研究发现，在随机参数空间旋转下，Adam在训练变压器时的表现会下降，这表明其在实践中高度依赖基底的选择。这表明传统的旋转不变假设不足以理论解释Adam的优势。
### Innovation
通过对支持结构化旋转来保持或增强其实验性能的识别，本文发现了旋转敏感性的结构，并且通过检验文献中的旋转依赖假设，发现它们在解释不同旋转类型下的Adam行为时存在不足。本文还验证了更新的正交性作为Adam基底敏感性的潜在指标，并提出这可能是开发用于解释其实用成功的新旋转依赖理论框架的关键量化。
### Conclusion
本文研究发现，传统的旋转不变假设不足以解释Adam的行为，需要更好的旋转依赖假设。更新的正交性可能是理解Adam优劣的关键理论指标。
## 148. `cs.AI` - GASP: 提升黑盒生成对抗后缀以劫持LLMs的高效方法 [PDF](https://arxiv.org/pdf/2411.14133), [HTML](https://arxiv.org/abs/2411.14133)
### Authors
Advik Raj Basani,Xiao Zhang
### Background
大规模语言模型（LLMs）在各种自然语言处理任务中表现出色，但在生成自然语言输入方面仍存在局限，且容易受到精心设计的输入提示（称为监禁攻击）的影响，这些提示可以绕过安全控制，导致有害响应。传统方法依赖于手动启发式规则，但这些方法的通用性有限。尽管基于优化的自动攻击可以提高攻击效率，但它们常常生成 unnatural 的提示，容易被安全过滤器检测到，或因离散标记优化的计算成本高而受限。
### Innovation
本文引入了生成对抗后缀提示生成器（GASP），这是一种新型自动框架，能够高效地在完全黑盒环境中生成易于阅读的监禁攻击提示。GASP 利用潜在贝叶斯优化来构建对抗后缀，通过有效探索连续潜在嵌入空间并逐步优化后缀提示生成器，以提高攻击效果，同时通过目标迭代精炼流程保持提示的一致性。
### Conclusion
通过全面的实验，我们展示了GASP可以生成自然的对抗后缀，大幅提高监禁攻击成功率，减少训练时间并加速推理速度，因此它是一种高效且可扩展的方法，用于打击LLMs。
## 149. `cs.AI` - 可移植且隐蔽的集成攻击：大规模语言模型的黑盒逃狱框架 [PDF](https://arxiv.org/pdf/2410.23558), [HTML](https://arxiv.org/abs/2410.23558)
### Authors
Yiqi Yang,Hongye Fu
### Background
本文介绍了一种新颖的黑盒逃狱框架，该框架集成了多种将LLM作为攻击者的方法，以交付具有高度可移植性和效果的攻击。该框架基于前人在逃狱研究和实践中提出的三个关键见解：集成方法比单一方法更胜一筹，能够在揭示对齐的LLM漏洞方面表现更佳；恶意指令在逃狱难度上各不相同，需要定制化的优化处理；破坏恶意提示的语义连贯性可操纵其嵌入，从而提高成功概率。该解决方案已在2024年大规模语言模型与代理安全竞赛的逃狱攻击轨道中获得了高排名，验证了其有效性和适用性。
### Innovation
提出了一个集成了多种将LLM作为攻击者策略的黑盒逃狱框架，能够执行具有高度迁移性且有效的攻击。这种框架利用了三个关键的洞见，即集成方法在揭示对齐的LLM漏洞时表现优异，恶意指令在逃狱难度上各不相同，需要定制化的优化处理，以及破坏恶意提示的语义连贯性可以提高成功概率。该项目在2024年比赛中的好成绩证实了这些策略的有效性。
### Conclusion
通过本文展示的黑盒逃狱框架，研究人员认为可以更有效地揭示大规模语言模型的对齐漏洞，并且该框架在比赛中取得的优异成绩为未来相关研究提供了有力支持。
## 150. `cs.AI` - KGGen: 使用语言模型从纯文本提取知识图谱 [PDF](https://arxiv.org/pdf/2502.09956), [HTML](https://arxiv.org/abs/2502.09956)
### Authors
Belinda Mo,Kyssen Yu,Joshua Kazdan,Joan Cabezas,Proud Mpala,Lisa Yu,Chris Cundy,Charilaos Kanatsoulis,Sanmi Koyejo
### Background
近年来，对于构建知识图谱（KGs）的基础模型的关注度不断上升，揭示了一个根本性的挑战：知识图谱数据相对稀缺。已知的最佳KGs主要由人类标注、通过模式匹配创建或使用早期NLP技术提取而成。尽管手工生成的KGs数量稀少，但自动提取的KGs质量存在疑问。本文探讨了在语言模型的帮助下，如何解决KG数据稀缺的问题，提出了一个名为KGGen的文本到KG生成器，能够从纯文本生成高质量的知识图谱。
### Innovation
不同于其他知识图谱提取工具，KGGen能够将相关实体聚类起来，减少提取的KG中的稀疏性。此外，本文还提供了一个名为MINE的第一个基准测试工具，用于评估提取工具从纯文本生成有用知识图谱的能力。通过与现有工具进行基准测试，展示了KGGen的显著优越性能。
### Conclusion
本文通过提出KGGen技术，首次提供了一个可以解决知识图谱数据稀缺问题的解决方案。同时，该研究还提供了一个用于测试KG提取工具有效性的基准测试工具MINE。实验结果表明，KGGen在生成高质量知识图谱方面表现远远优于现有的其他工具。
## 151. `cs.AI` - 使用演绎推理提高大语言模型代码生成效果 [PDF](https://arxiv.org/pdf/2502.15835), [HTML](https://arxiv.org/abs/2502.15835)
### Authors
Zhuchen Cao,Sven Apel,Adish Singla,Vera Demberg
### Background
大语言模型（LLMs）在将自然语言（NL）指令转换为程序代码方面展现了令人印象深刻的潜力。然而，用户的指令往往包含内在的模糊性，这使得LLMs难以生成准确反映用户真正意图的代码。为了应对这一挑战，研究人员提出了生成多个程序代码候选并重新排序的方法以识别最佳解。本文考虑了通过理性的言语行为（RSA）框架构建的新型代码候选再次排序机制CodeRSA，旨在引导LLMs进行更加全面的脚本推理。
### Innovation
本文提出了CodeRSA，一种基于理性的言语行为（RSA）框架的新型代码候选再排序机制，旨在引导LLMs进行更加全面的脚本推理，从而更好地理解用户的真实意图。通过在HumanEval和MBPP两种广泛使用的代码生成基准上使用Llama-3-8B-Instruct和Qwen-2.5-7B-Instruct进行实验评估，结果表明CodeRSA在大多数情况下优于最先进的方法，并且表现出稳健的整体性能。这证明了将演绎推理整合到代码候选再排序中的有效性，为提升LLMs代码生成质量提供了有希望的方向。
### Conclusion
评估结果表明，CodeRSA在每次实验中都优于常用的基准方法，并且在大多数情况下都超过了最先进的方法，展示了稳健的整体性能。这些研究结果强调了将演绎推理整合到代码候选再排序中的有效性，并为提高LLMs代码生成质量指明了前景。
## 152. `cs.AI` - 优化算法中的记忆如何隐式地修改损失函数 [PDF](https://arxiv.org/pdf/2502.02132), [HTML](https://arxiv.org/abs/2502.02132)
### Authors
Matias D. Cattaneo,Boris Shigida
### Background
在现代深度学习优化方法中，每次更新都依赖于之前迭代的历史，这种依赖性随着迭代的进行而迅速衰减。例如，具有动量的最速下降法通过指数平滑过去的梯度来实现指数衰减的记忆。本文提出了一种通用技术，用于识别一个无记忆算法，该算法近似于具有记忆的优化算法。该技术通过将所有过去的迭代替换为当前迭代，并添加一个基于记忆而来的校正项（也与当前迭代有关）来实现这一点。该校正项可解释为对损失函数的扰动，这种扰动的性质可以说明记忆如何隐式地对优化动力学进行（反）正则化。作为该理论的应用，作者发现Lion不具有由记忆诱导的AdamW那样的隐式反正则化，这为解释Lion的更好泛化性能提供了理论基础的解释。
### Innovation
提出了一种通用技术，用于识别一个无记忆算法，该算法近似于具有记忆的优化算法。这种技术通过替换所有过去的迭代为当前迭代，并添加一个基于记忆的校正项来实现。该研究提供了一种对优化算法中记忆作用的理解方法，特别是对损失函数的影响以及这种扰动的性质对优化动力学的（反）正则化影响的探索。
### Conclusion
研究表明，具有记忆的优化算法可以通过对损失函数的扰动生成（反）正则化，而不同的优化器如Lion和AdamW因其记忆作用的不同，导致了其隐式的（反）正则化特性也不相同，这种理论也解释了Lion在某些任务上的更好泛化性能。
## 153. `cs.AI` - 在进化排行榜中通过RAG基准测评LLM的忠诚度 [PDF](https://arxiv.org/pdf/2505.04847), [HTML](https://arxiv.org/abs/2505.04847)
### Authors
Manveer Singh Tamber,Forrest Sheng Bao,Chenyu Xu,Ge Luo,Suleman Kazi,Minseok Bae,Miaoran Li,Ofer Mendelevitch,Renyi Qu,Jimmy Lin
### Background
检索增强生成（RAG）旨在通过将响应与外部背景资料对接来降低幻觉的发生率。然而，即便在提供了相关背景资料的情况下，大型语言模型（LLMs）仍然经常引入不必要的信息或自相矛盾的内容。Vectara通过原始幻觉排行榜跟踪了自2023年以来LLMs的幻觉率，并使用HHEM幻觉检测模型。然而，当前的幻觉检测方法存在局限性。针对这一点，作者提出了一种名为FaithJudge的新框架，并基于该框架构建了一个增强的幻觉排行榜，测评LLMs在返回摘要、问答和数据到文本生成任务中的RAG忠诚度。
### Innovation
提出了FaithJudge框架，这是一种LLM作为评判者的框架，利用多样的人类标注的幻觉示例来显著提高LLM自动幻觉评估的可靠性。这使得在RAG环境中对LLM的幻觉进行更可靠的基准测试，同时支持更具可信度的生成AI系统的发展。
### Conclusion
通过FaithJudge框架建立的增强幻觉排行榜，提供了对LLMs在若干任务中的RAG忠诚度的测评，增强了LLM在生成任务中的可信度，并促进了更加有效的幻觉检测和评估。
## 154. `cs.AI` - SafeVLA: 通过约束学习实现视觉-语言-行动模型的安全对齐 [PDF](https://arxiv.org/pdf/2503.03480), [HTML](https://arxiv.org/abs/2503.03480)
### Authors
Borong Zhang,Yuhao Zhang,Jiaming Ji,Yingshan Lei,Josef Dai,Yuanpei Chen,Yaodong Yang
### Background
视觉-语言-行动模型(VLAs)具有作为通用机器人策略的潜力。然而，在实际部署中，这些模型带来了重大的安全挑战，包括对环境、机器人自身和人类造成伤害的风险。如何将安全约束明确地整合到VLAs中？本文通过探索结合安全方法(ISA)，系统地建模安全要求，主动引发多样化的不安全行为，利用安全强化学习有效地约束VLAs策略，并通过针对性评估确保其安全性来解决这一问题。采用受限马尔可夫决策过程(CMDP)范式，ISA从对抗引出的安全风险的最小最大视角优化VLAs，使得通过这一全面的方法获得以下关键特性：(I)有效安全性能折衷，相较于最先进的方法，降低安全违规累计成本83.58%，同时还保持任务成功率+3.85%。(II)强大的安全性保证，能够缓解长尾风险并处理极端故障场景。(III)在各种离分布扰动下的学习安全行为的稳健泛化能力。这些效果在长时间移动操作任务上进行了评估。
### Innovation
本文提出了结合安全方法(ISA)来系统建模安全要求，主动引出多样化的不安全行为，利用安全强化学习有效约束VLAs策略，并通过针对性评估确保其安全性。通过采用约束马尔可夫决策过程(CMDP)范式，ISA优化VLAs从最小最大视角对抗引出的安全风险。这种方法使得VLAs策略不仅在安全与性能之间取得有效的折衷，还能有效缓解长尾风险、处理极端故障场景并实现学习的安全行为在各种离分布扰动下的稳健泛化能力。
### Conclusion
本文所提出的SafeVLA方法在长时间移动操作任务上展示了其有效性和稳健性，不仅实现了从安全到性能的有效平衡，还显著提升了安全保证，能够处理长尾风险和极端故障场景，展现出泛化到各种离分布扰动的学习安全行为。相关的数据、模型及新的基准环境在[line provided in the paper]上提供。
## 155. `cs.AI` - Quamba2: 一种适用于选择性状态空间模型的稳健且可扩展的后训练量化框架 [PDF](https://arxiv.org/pdf/2503.22879), [HTML](https://arxiv.org/abs/2503.22879)
### Authors
Hung-Yueh Chiang,Chi-Chih Chang,Natalia Frumkin,Kai-Chiang Wu,Mohamed S. Abdelfattah,Diana Marculescu
### Background
状态空间模型（SSMs）由于其一致的内存使用和高性能，正在成为Transformer的一种有吸引力的替代方案。然而，SSMs在云服务或资源有限的设备上的扩展面临挑战，主要是由于它们的数据存储需求和计算能力。通过使用低比特宽度的数据格式对SSMs进行量化，可以减少模型大小并利用硬件加速。尽管如此，SSMs对于量化造成的错误较为敏感，因此研究人员主要关注优化特定模型或比特宽度以提高效率，而不影响性能。然而，不同的比特宽度配置对不同的应用场景是必需的，例如W4A8以提升大规模批次解码速度，而W4A16则用于增强单用户短提示生成速度。
### Innovation
论文提出了一种名为Quamba2的后训练量化框架，该框架兼容W8A8、W4A8和W4A16的输入配置，适用于Mamba1和Mamba2模型。基于SSMs的通道顺序保持和激活持久性特征，该框架提出了一种离线方法，通过排序和聚类对输入x进行8位量化，并结合输入依赖参数B和C的逐状态组量化。为了确保计算不变性，通过重新排列权重以适应聚类序列。实验结果表明，Quamba2-8B在前填充和生成阶段分别实现了1.3倍和3倍的加速，内存减少了4倍，平均准确率下降了1.6%，并展示了该框架的普适性和鲁棒性。
### Conclusion
Quamba2通过离线对输入和权重的量化方法，提供了一种适用于不同平台的SSM部署方案，提高了性能并减少了内存占用。该方法已经在实验中显示出了优越的性能，并且代码和量化模型将开源。
## 156. `cs.AI` - TathyaNyaya和FactLegalLlama：在印度法律背景下推进事实判断预测与解释 [PDF](https://arxiv.org/pdf/2504.04737), [HTML](https://arxiv.org/abs/2504.04737)
### Authors
Shubham Kumar Nigam,Balaramamahanthi Deepak Patnaik,Shivam Mishra,Noel Shallum,Kripabandhu Ghosh,Arnab Bhattacharya
### Background
在基于事实的判断预测与解释（FJPE）领域，依赖实证数据对于构建稳健且真实的AI驱动决策工具至关重要。传统的数据集中多包含完整的法律文本，这并没有专注于反映真实世界司法过程中的事实驱动结果。为此，研究者们开发了TathyaNyaya，这是专门为印度法律情境设计的最大标注数据集，包含印度最高法院和各个高等法院的判决文书。TathyaNyaya和其衍生模型FactLegalLlama将有助于提高AI辅助法律系统中的透明度和可解释性，特别是在印度法律领域。
### Innovation
这篇论文提出了TathyaNyaya数据集和FactLegalLlama模型，二者均是针对印度法律背景下的FJPE任务。TathyaNyaya是迄今为止最大的标注数据集，专注于事实陈述而不是全面的法律文本，能够更好地反映实际审判过程中的因果关系。而基于TathyaNyaya的Fine-tuning，FactLegalLlama能够生成高质量的解释，实现了预测精度与上下文相关解释的结合。这一创新方法为提高AI辅助法律系统中的透明度和可解释性提供了新的解决方案，进一步推动了FJPE在印度法律领域的应用。
### Conclusion
TathyaNyaya 不仅在规模和多样性上超越了现有数据集，还为构建可解释的AI系统在法律分析中的应用设立了基准。TathyaNyaya 和 FactLegalLlama 在提升预测性能和解释性方面的重要性得到了证明，它们将成为促进AI辅助法律决策的基础资源。
## 157. `cs.AI` - 闭环环境下的RNN学习动力学 [PDF](https://arxiv.org/pdf/2505.13567), [HTML](https://arxiv.org/abs/2505.13567)
### Authors
Yoav Ger,Omri Barak
### Background
递归神经网络（RNN）在神经科学启发的任务上受训练为强大的脑信息处理模型。然而，典型的训练方式依赖于开环的、监督的环境，而现实中的学习过程发生在闭环环境中。已经有研究工作描述了闭环RNN的数学理论，分析其学习动态。
### Innovation
开发了一个数学理论来描述闭环环境中线性RNN的学习动态。证明了闭环和开环训练的RNN表现出截然不同的学习路径，并解析了闭环情形下的学习动态，区分短期策略改进和长期稳定性两种目标，提出了适用于真实电机控制任务的框架，展示了其更广泛的适用性。
### Conclusion
研究结果强调了在生物学合理的情景下，建模闭环动力学的重要性。
## 158. `cs.AI` - 通过微调迁移实现高效模型开发 [PDF](https://arxiv.org/pdf/2503.20110), [HTML](https://arxiv.org/abs/2503.20110)
### Authors
Pin-Jie Lin,Rishab Balasubramanian,Fengyuan Liu,Nikhil Kandpal,Tu Vu
### Background
现代大语言模型在高效更新方面面临挑战，每次新的预训练模型版本都需要重复昂贵的对齐过程。这一挑战同样适用于领域或语言特定的模型，其中必须为每一种新的基础模型版本重新对它们进行微调。本文探讨了模型版本之间微调更新的迁移，具体是从一个源模型版本中导出差分向量（代表权重变化），并将其应用到不同目标版本的基础模型中。通过对各种开放权重模型版本的实证评估，证实这种迁移可以显著提升目标基础模型的性能。例如，将Llama 3.0 8B的微调更新应用到Llama 3.1 8B上，性能分别提高了46.9%和15.7%，甚至超过了Llama 3.1 8B的指令版本。此外，研究还展示了多语言任务上的性能提升，分别提高了4.7%和15.5%的Global MMLU（针对马达加斯加语和土耳其语）。我们发现，合并这些模型能为后续微调提供更好的初始条件。最后，控制实验证明微调迁移在源模型和目标模型参数空间呈线性连接区域时效果最佳，并提供了该方法的理论分析。综合来看，微调迁移为持续开发大语言模型提供了一种成本效益高且实际可行的策略。
### Innovation
本文提出了通过迁移一种源模型版本的微调更新到不同目标版本的基础模型中，从而显著提升目标基础模型的性能。这种方法能够在无需额外训练的情况下实现显著的性能提升，并适用于多语言任务。此外，控制实验表明微调迁移在源和目标模型参数空间呈线性连接区域时效果最佳，并进行了理论分析说明这一方法的有效性。
### Conclusion
微调迁移为持续开发大语言模型提供了一种成本效益高且实际可行的策略，通过这一方法能在无需额外训练的情况下显著提升目标基础模型的性能。此外，这种方法在多语言任务上也展示了显著的性能提升。
## 159. `cs.AI` - Foundation Model Embeddings时代的多模态癌症建模 [PDF](https://arxiv.org/pdf/2505.07683), [HTML](https://arxiv.org/abs/2505.07683)
### Authors
Steven Song,Morgan Borjigin-Wang,Irene Madejski,Robert L. Grossman
### Background
TCGA通过整合基因组、临床和影像数据，促进了癌症研究中的新型发现，并成为了大规模参考数据集。此前有许多研究基于TCGA数据构建了定制深度学习模型，用于如癌症生存预测等任务。然而，TCGA中的病理报告文本数据没有得到充分的利用。因此，本文研究了使用经典机器学习模型结合多模态、无监督的FM嵌入来处理癌症数据的可能性，并展示了多模态融合的易用性和优势，同时探讨了病理报告文本的纳入以及基于模型的文本总结和虚构化的效果。
### Innovation
本文的创新点在于提出了基于FM嵌入的多模态癌症模型方法，特别是关注如何利用病理报告中的文本信息，并通过经典机器学习模型对其进行处理。这种方法能够克服历史上的数据利用障碍，提高预测准确度，并为未来基于FM的医疗健康应用提供参考。
### Conclusion
本文通过验证多模态融合和病理报告文本处理的有效性，提出了一种以嵌入为中心的多模态癌症建模方法。研究结果表明，这种方法不仅简化了建模过程，还提高了模型性能。未来的探索可以进一步考虑不同模型方法的整合以取得更好的效果。
## 160. `cs.AI` - 重访残差连接：促进稳定高效的深层网络的正交更新 [PDF](https://arxiv.org/pdf/2505.11881), [HTML](https://arxiv.org/abs/2505.11881)
### Authors
Giyeong Oh,Woohyun Cho,Siyeol Kim,Suhwan Choi,Youngjae Yu
### Background
残差连接对于深度神经网络至关重要，能够通过缓解梯度消失问题来增加网络的深度。然而，在标准残差更新中，模块的输出是直接加到输入流中，可能导致更新主要强化或调整现有流的方向，这可能未能充分利用模块学习全新特征的能力。已有研究表明，通过优化模块输出与输入流的关系，可以促进更具代表性的特征学习，提高网络的整体泛化能力和训练稳定性。
### Innovation
提出了一种新的更新策略——正交残差更新，该策略将模块输出相对于输入流进行分解，仅添加与输入流正交的分量。这种方法旨在引导模块主要贡献新的表示方向，促进特征学习的丰富性，同时促进更高效的训练。实验结果表明，该正交更新策略在不同架构（如ResNetV2、视觉变换器）和数据集（如CIFAR、TinyImageNet、ImageNet-1k）上均能提高泛化准确性和训练稳定性，例如在ImageNet-1k上ViT-B模型的顶级准确率提高了3.78个百分点。
### Conclusion
通过正交残差更新，促进深层网络中的丰富特征学习，提高其训练稳定性和泛化准确性。这种更新策略可以在多种网络架构和数据集上得到验证和应用。
## 161. `cs.AI` - 用引导向量助你获得诚实地回答：使用引导向量帮助LLM-评估者获得诚实替代方案 [PDF](https://arxiv.org/pdf/2505.17760), [HTML](https://arxiv.org/abs/2505.17760)
### Authors
Leon Eshuijs,Archie Chaudhury,Alan McBeth,Ethan Nguyen
### Background
对于大型语言模型（LLMs）中的微妙不诚实行为，如逢迎和操控，无论是人类还是自动化评估者都难以检测。这些行为常常通过细微的偏见表现出来，而非明确的假陈述。现有的评估方法往往依赖于黑盒评估，而本研究介绍了一种新颖的框架JUSSA，通过引导向量在推理过程中生成更诚实的替代方案，提供对比样本帮助评估者更容易地检测到微妙的不诚实模式。
### Innovation
JUSSA利用模型内部机制创建基于单个案例的目标对比，而非仅仅改进模型行为。该方法在应对逢迎和操纵行为检测方面表现出色，尤其在帮助较弱的评估者应对简单的不诚实问题以及较强评估者应对复杂问题时表现出显著效果。此外，层间实验揭示了不诚实提示如何导致中间层表示与诚实表示的偏差，从而指明了生成对比样本的最佳位置。这项工作证明了引导向量不仅能够影响行为，还能提升安全性评估，为系统的复杂性增加提供了新的模型审计方向。
### Conclusion
JUSSA方法提高了检测不诚实的准确率，并展示了其在不同任务中的有效性。对于较弱的评估者，JUSSA有助于检测简单的不诚实行为；对于较强评估者，它有助于解决更困难的任务。这项研究为复杂的系统提供了新的模型审计方向，进一步增强了安全评估的能力。
## 162. `cs.AI` - 大型语言模型的稳定性：缓解策略与评估指标的综述 [PDF](https://arxiv.org/pdf/2505.18658), [HTML](https://arxiv.org/abs/2505.18658)
### Authors
Pankaj Kumar,Subhankar Mishra
### Background
大型语言模型（LLMs）已经成为自然语言处理（NLP）和人工智能（AI）发展的有前途的基础构件。然而，确保LLMs的稳健性仍然是一个关键的挑战。
### Innovation
本文系统地审视了LLMs的稳健性本质，包括其概念基础、一致表现的重要性以及在实际应用中失效模式的含义。分析了非稳健性的来源，包括固有的模型限制、数据驱动的脆弱性以及外部对抗因素。并回顾了最新的缓解策略和广泛采用的基准、新兴指标以及评估实际可靠性中的持续缺口。
### Conclusion
最后，综合现有综述和跨学科研究的发现，强调了趋势、未解决的问题和未来研究的路径。
## 163. `cs.AI` - Two Causally Related Needles in a Video Haystack [PDF](https://arxiv.org/pdf/2505.19853), [HTML](https://arxiv.org/abs/2505.19853)
### Authors
Miaoyu Li,Qin Chao,Boyang Li
### Background
评估视频语言模型(VLMs)对长视频的理解能力仍然是一个挑战，尤其是在从长视频的不同位置提取信息并联合理解以及建模人类行为因果关系方面。现有基准在这两个关键能力上存在不足。
### Innovation
本文提出了一个长上下文视频理解基准——Causal2Needles，用于评估模型从长视频中的两个不同位置提取和理解信息的能力，以及建模人类行为因果关系的能力。通过非因果单一针、因果单一针和因果双针问题来评估这些能力，特别是在因果双针问题中，要求模型从长视频和相关解说文本中提取因果事件的信息。为了防止文本偏见，引入了两种补充问题格式。
### Conclusion
现有的基准模型在因果双针问题上表现不佳，模型表现与两个针之间的距离呈负相关。这些发现突显了当前VLMs的关键局限性。数据集可在以下网址获取: [数据集链接]。
## 164. `cs.AI` - 推理模型更易产生幻觉：面向事实的强化学习方法 [PDF](https://arxiv.org/pdf/2505.24630), [HTML](https://arxiv.org/abs/2505.24630)
### Authors
Junyi Li,Hwee Tou Ng
### Background
大语言模型（LLMs）通过强化学习（RL）优化显著提升了其在推理任务上的能力，实现了多种具有挑战性的基准测试中的显著成果。然而，实证分析发现，推理导向的RL微调会显著增加幻觉的发生率。RL训练动态的深入分析表明，高方差梯度、熵引起的随机性以及对伪局部最优的敏感性是导致幻觉的关键因素。
### Innovation
提出了一种创新的RL微调算法——Factuality-aware Step-wise Policy Optimization（FSPO），在每次推理步骤中引入显式的事实性验证，利用与给定证据的自动验证动态调整token级优势值，鼓励推理过程中的事实正确性。
### Conclusion
FSPO在数学推理和幻觉基准测试中使用Qwen2.5和Llama模型进行实验，验证了其在减少幻觉的同时提高推理准确性，显著提升了可靠性和性能。
## 165. `cs.AI` - 复合流匹配在动力学转移数据的强化学习中的应用 [PDF](https://arxiv.org/pdf/2505.23062), [HTML](https://arxiv.org/abs/2505.23062)
### Authors
Lingkai Kong,Haichuan Wang,Tonghan Wang,Guojun Xiong,Milind Tambe
### Background
将预先收集的离线数据整合到目标环境中，可以显著提高强化学习（RL）的样本效率，但这一优势往往会受到源环境和目标环境之间的转换动态差异的挑战。现有的方法通常通过惩罚或过滤高动态差异区域的源过渡来应对这一问题，但它们通常依赖于KL散度或互信息来估计动态差异，而当源和目标动态的支持集不交时，这两种方法可能会出现不明确的情况。
### Innovation
本文提出了CompFlow方法，该方法基于流匹配和最优传输之间的理论联系。CompFlow将目标动态建模为基于源域流输出分布的条件流，而不是直接从高斯先验中学习。这种复合结构提供了两大优势：（1）提高了学习目标动态的一般化能力；（2）通过计算源和目标转换的Wasserstein距离，提出了一个基于动态差异的规范估计方法。此外，CompFlow还引入了一种乐观的主动数据收集策略，以优先在高动态差异区域进行探索，并证明这种方法可以减少与最优策略的性能差异。
### Conclusion
在多种具有转移动态的数据的RL基准测试中，CompFlow方法显著优于强基线。
## 166. `cs.AI` - 开放领域金融问答中标准化文件的层次检索与证据校编 [PDF](https://arxiv.org/pdf/2505.20368), [HTML](https://arxiv.org/abs/2505.20368)
### Authors
Jaeyoung Choe,Jihoon Kim,Woohwan Jung
### Background
基于检索增强生成（RAG）的大语言模型（LLMs）在金融领域被广泛应用，因为它们在知识密集型任务上的卓越表现。然而，标准化文档（例如SEC上报文件）经常具有相似的格式和表格结构，如重复的文案和结构化的表格。这种相似性导致传统的RAG方法错误地识别近似重复文本，导致重复检索，这削弱了准确性和完整性。因此，需要解决这些问题的方法，这种方法首先通过层次检索来减少相似文本的混淆，并从文档中选择最相关的段落，然后去除无关的段落。必要时，自动生成补充查询以收集缺失的信息。
### Innovation
提出了一种层次检索与证据校编（HiREC）框架。此方法首先进行层次检索以减少相似文本的混淆，先检索相关文档，然后从文档中选择最相关的段落，同时进行证据校编去除无关的段落，必要时自动生成补充查询收集缺失的信息。该论文构建并发布了包含145,897份SEC文档和1,595个问题-答案对的大规模开放域金融问答基准数据集LOFin，以评估这种方法的有效性。
### Conclusion
本文提出了一种层次检索与证据校编（HiREC）框架，解决了标准化文档使用RAG方法时的困惑问题，通过两级检索和自动补全提升了准确性和完整性。论文构建了一个大规模的开放域金融问答基准数据集LOFin以验证所提方法的效果，证明了该方法在开放领域金融问答中的有效性。
## 167. `cs.AI` - Autocomp：面向张量加速器的强大且可移植的代码优化器 [PDF](https://arxiv.org/pdf/2505.18574), [HTML](https://arxiv.org/abs/2505.18574)
### Authors
Charles Hong,Sahil Bhatia,Alvin Cheung,Yakun Sophia Shao
### Background
硬件加速器，尤其是用于张量处理的加速器，在当今计算环境中已经非常普遍。然而，即使在构建编译器方面进行了大量努力，编程这些张量加速器仍然具有挑战性，导致它们的潜力没有被充分利用。大型语言模型（LLMs）在代码生成和优化任务中显示出巨大潜力，但生成低资源语言，如专门的张量加速器代码，仍然有显著挑战。本研究旨在解决这一挑战，提出了一种名为Autocomp的方法，该方法允许加速器程序员利用领域知识和硬件反馈，通过自动化LLM驱动的搜索来优化代码。通过将每个优化过程分为规划和代码生成两个阶段的过程提示，并在规划阶段插入简洁且可调的优化菜单，以及在每次搜索迭代中整合硬件的正确性和性能反馈，实现了这一目标。Autocomp在三种不同的硬件平台上展示了优化代码的性能提升，比供应商提供的库（Gemmini）快5.6倍，比专家手动调优代码（AWS Trainium）快1.9倍，比基于机器学习的成本模型（NVIDIA L40S）高3.8倍。此外，研究还表明，从Autocomp生成的优化计划可以在类似张量操作之间重复利用，固定样本预算下速度提升最多可达24%。
### Innovation
Autocomp方法通过将每个优化过程设计为结构化的两阶段提示，即规划和代码生成阶段，并在规划阶段使用简洁且通用的优化菜单插入领域知识，然后在每次搜索迭代中将硬件的正确性和性能反馈整合为反馈，实现了自动化的LLM驱动搜索来优化代码。这种方法提高了代码性能，使得优化过程更加灵活且可移植。
### Conclusion
研究展示了Autocomp优化代码在不同硬件平台上的性能，证明了Autocomp能显著提升代码效率。通过整合领域知识和硬件反馈，Autocomp能够自动优化张量加速器上的代码，不仅超越了现有的优化方法，还展示了跨类似张量操作的优化计划重用潜力，进一步提高了速度。
## 168. `cs.AI` - 基于伯恩斯坦基的凸散度的神经隐式采样器的显式密度逼近 [PDF](https://arxiv.org/pdf/2506.04700), [HTML](https://arxiv.org/abs/2506.04700)
### Authors
José Manuel de Frutos,Manuel A. Vázquez,Pablo M. Olmos,Joaquín Míguez
### Background
排名为基础的统计度量，如不变统计损失（ISL），最近被证明是训练隐式生成模型的稳健且实用的工具。本文在此基础上引入了dual-ISL，一种新型的无需似然的隐式生成模型训练目标。本文通过互换目标和模型分布在ISL框架中的角色，得到了模型密度空间中的凸优化问题。研究还证明了由此产生的排名为基础的不连续性度量d_K具有两个重要性质：弱收敛下的连续性和相对于L^1范数的连续性，以及其第一参数的凸性，这些性质是KL或Wasserstein距离等经典发散度不具有的特性。
### Innovation
本文提出了dual-ISL，这是一种新型的无需似然目标，适用于训练隐式生成模型。dual-ISL通过互换目标和模型分布的角色，使得优化问题在模型密度空间中成为凸的。此外，研究还提供了一种理论框架，将密度比率$q = p/tilde p$在伯恩斯坦多项式基上的$L^2$-投影，从理论上精确分析了截断误差和收敛速率，并给出了截断密度近似的闭式解。进一步通过随机的一维投影扩展到多元情况，定义了sliced dual-ISL散度，保持了凸性和连续性。通过实验证明了这些理论优势在实践中也有良好的体现。
### Conclusion
dual-ISL在多个基准测试中表现出更快的收敛速度、更平滑且更稳定地训练，以及更有效地预防模式崩溃的优点，相较于经典ISL和其他主要的隐式生成方法，同时也提供了显式的密度近似。
## 169. `cs.AI` - HELM: 折射大型语言模型通过曲率混合专家 [PDF](https://arxiv.org/pdf/2505.24722), [HTML](https://arxiv.org/abs/2505.24722)
### Authors
Neil He,Rishabh Anand,Hiren Madhu,Ali Maatouk,Smita Krishnaswamy,Leandros Tassiulas,Menglin Yang,Rex Ying
### Background
大规模语言模型（LLMs）在多个领域中的文本建模任务中取得了显著成效。然而，自然语言具有固有的语义层次结构和微妙的几何结构，现有的LLMs由于依赖欧几里得操作，在捕捉这些特性方面并不完整。最近的研究还表明，不遵守标记嵌入的几何结构会导致训练不稳定并降低生成能力。这让研究者认为转向非欧几里得几何可以更好地使语言模型与文本的内在几何结构相契合。
### Innovation
本文提出了在双曲空间（Hyperbolic space）中完全运行的大型语言模型（HELM），利用其广泛、无标度和低失真特性。此外，提出了混合曲率专家模型（HELM-MICE），其中每个专家在一个不同的曲率空间中操作，以更精细地编码来自文本的几何结构。还引入了密集模型HELM-D。文中还为这两个模型开发了旋转型位置编码和RMS归一化的关键双曲等效。这是首次在亿参数规模下训练完全双曲的大型语言模型，并在MMLU和ARC等基准测试中进行评估，涵盖了STEM问题解决、普通知识和常识推理。研究表明，与流行的欧几里得架构（如LLaMA和DeepSeek）相比，HELM架构在多个方面实现了持续收益，通过双曲几何在大规模语言模型预训练中提高了推理能力的有效性和增强性。
### Conclusion
实验结果表明，HELM架构在多个指标上优于常用的欧几里得架构，特别是在处理复杂的语言模式时，明显提高了推理能力和效果。
## 170. `cs.AI` - 利用压缩和量化多条件标记化实现高级手语视频生成 [PDF](https://arxiv.org/pdf/2506.15980), [HTML](https://arxiv.org/abs/2506.15980)
### Authors
Cong Wang,Zexuan Deng,Zhiwei Jiang,Yafeng Yin,Fei Shen,Zifeng Cheng,Shiping Ge,Shiwei Gan,Qing Gu
### Background
手语视频生成（SLVG）旨在从口语文本生成具有身份保留的手语视频。现有方法主要依赖单一粗略条件（例如，骨架序列）作为中介，以连接翻译模型和视频生成模型，这限制了生成视频的自然性和表现力。
### Innovation
我们提出了一种名为SignViP的创新SLVG框架，该框架结合了多个细粒度条件以提高生成保真度。SignViP采用离散标记化范式整合和表示细粒度条件（例如，细粒度姿态和3D手部），而不是直接翻译高维条件。SignViP包括三个核心组件：Sign Video Diffusion Model（与多条件编码器联合训练以学习包含细粒度运动和外观的连续嵌入）、基于有限标量量化（FSQ）的自编码器（进一步训练以压缩和量化这些嵌入）和多条件标记翻译器（训练以将口语文本翻译为离散的多条件标记）。
### Conclusion
实验结果表明，SignViP在包括视频质量、时间连贯性和语义忠实度在内的多种指标上达到了最先进的性能。代码可以在提供的链接处获取。
## 171. `cs.AI` - 深图学习在工业碳排放分析及其政策影响中的应用 [PDF](https://arxiv.org/pdf/2507.02912), [HTML](https://arxiv.org/abs/2507.02912)
### Authors
Xuanming Zhang
### Background
工业碳排放是气候变化的主要驱动因素，然而，由于众多因素之间存在多重共线性以及不同行业和时间纵向上的复杂依赖性，对这些排放进行建模具有挑战性。
### Innovation
我们提出了一种基于图的深度学习框架DGL，用于分析和预测工业CO_2排放。该方法通过使用具有注意力机制的图神经网络（GNN）来建模行业（或区域）之间的关系，并通过时序变换器学习长期模式，从而解决了高特征相关性问题并捕获了工业与时间上的关联性。与传统的回归或聚类方法不同，我们的方法能够通过结构化编码特征关系来解决共线性问题，并通过因果推理识别真正的排放驱动因素，提高透明度和公平性。
### Conclusion
我们展示了高排放热点以及公平干预计划的建议，强调了先进AI图学习在促进气候行动中的潜力，为政策制定者和行业利益相关者提供了有力工具，以实现碳减排目标。同时，该模型能够为各行业的特定低碳化策略提供指导，符合可持续发展目标。
## 172. `cs.AI` - HoliSafe: 全面的安全基准测试与模型架构为视觉语言模型 [PDF](https://arxiv.org/pdf/2506.04704), [HTML](https://arxiv.org/abs/2506.04704)
### Authors
Youngwan Lee,Kangsan Kim,Kwanyong Park,Ilcahe Jung,Soojin Jang,Seanie Lee,Yong-Ju Lee,Sung Ju Hwang
### Background
尽管已经有了一些努力来提高视觉语言模型（VLMs）的安全性，现有方法存在两个主要不足：1）现有的安全调优数据集和基准仅部分考虑了图像-文本交互可能导致有害内容的问题，往往是忽视了看似无害但实际存在风险的结果。这种狭窄的覆盖范围使得VLMs在新的配置中容易受到恶意攻击。2）先前的方法主要依赖于基于数据的调优，缺乏内在的结构改良以增强安全性。这项研究通过引入一个涵盖所有五种安全/不安全图像-文本组合的全面安全数据集和基准，即HoliSafe，解决了这些问题，为训练和评估提供了更坚实的基础。此外，还提出了一个新颖的模块化框架，其中包含一个视觉防护模块（VGM），旨在评估输入图像对VLM的潜在危害。
### Innovation
1）通过引入全面的安全数据集和基准HoliSafe，覆盖了所有五种安全/不安全的图像-文本组合，为训练和评估提供了更全面的基础。2）提出了一种新颖的模块化框架，包括一个视觉防护模块（VGM），旨在评估输入图像对VLM的潜在危害，使VLMs既能学习生成更安全的回应，又能提供可解释的危害分类，以合理化其拒绝决策。3）VGM被设计为插件组件，允许与不同的预训练VLMs无缝集成。
### Conclusion
实验表明，使用HoliSafe训练Safe-VLM与VGM的方法在多个VLM基准测试中取得了最先进的安全性性能。HoliSafe-Bench自身揭示了现有VLM模型的关键漏洞。希望HoliSafe和VGM能够推动对鲁棒且可解释的VLM安全性的进一步研究，扩展未来在多模态对齐方面的研究路径。
## 173. `cs.AI` - MeAJOR Corpus: 一个多源的钓鱼邮件检测数据集 [PDF](https://arxiv.org/pdf/2507.17978), [HTML](https://arxiv.org/abs/2507.17978)
### Authors
Paulo Mendes,Eva Maia,Isabel Praça
### Background
钓鱼邮件持续对网络安全构成重大威胁，通过欺诈性内容和恶意载荷利用人类的脆弱性。虽然机器学习模型在检测钓鱼威胁方面非常有效，但它们的表现很大程度上依赖于训练数据的质量和多样性。现有的钓鱼邮件数据集存在关键的限制，无法满足研究需求。为此，该研究提出了一种名为MeAJOR（Merged email Assets from Joint Open-source Repositories）的新颖多源钓鱼邮件数据集，旨在克服现有资源的局限性。
### Innovation
MeAJOR数据集是一款新颖的多源钓鱼邮件数据集，集成了135894个样本，涵盖了广泛的钓鱼技术和合法邮件，并包含各种工程特征。通过与其他四类分类模型（RF、XGB、MLP和CNN）进行系统的实验验证，展示了该数据集的有效性，XGB模型达到了98.34%的F1分数。通过集成多类别广泛的特征，该数据集为研究人员提供了可重复使用的稳定资源，解决了诸如类别不平衡、一般化和可再现性等常见挑战。
### Conclusion
该数据集通过集成多源异构数据和广泛工程特征，提供了一个可重复使用且稳定的资源，能够有效提高钓鱼邮件检测性能。通过系统的实验验证，证明了其在钓鱼检测研究中的有效性和实用性。
## 174. `cs.AI` - 通过自适应比特分配实现高效准确的脉冲神经网络 [PDF](https://arxiv.org/pdf/2506.23717), [HTML](https://arxiv.org/abs/2506.23717)
### Authors
Xingting Yao,Qinghao Hu,Fei Zhou,Tielong Liu,Gang Li,Peisong Wang,Jian Cheng
### Background
多比特脉冲神经网络（SNNs）近年来成为了研究热点，旨在追求高效能与高精度的人工智能。然而，随着更多位的加入，相关的内存和计算需求急剧增加，导致性能提升变得不成比例。基于不同层的重要性不同，更多位可能成为浪费和干扰，这篇论文提出了一种自适应的比特分配策略，用于直接训练的SNNs，实现了内存和计算资源的精细分层分配。因此，SNN的效率和准确性得以提高。具体地说，我们参数化了权重和脉冲的时长和位宽，并通过梯度使它们可学习和可控。为了应对位宽和时长变化带来的挑战，我们提出了改进型脉冲神经元，可以处理不同的时长、为时长梯度的导数提供支持，并更适合脉冲量化。此外，我们从理论上阐述了可学习位宽的步长不匹配问题，该问题可能导致严重的量化误差，并相应提出了步长更新机制以缓解这一问题。
### Innovation
提出了一种自适应的比特分配策略以优化脉冲神经网络，改善了SNN的效率和准确性。具体创新包括参数化权重和脉冲的时长和位宽，并通过梯度使它们可学习和可控；提出了改进型脉冲神经元，能够处理不同的时长，并支持对时间长度的梯度求导以配合脉冲量化；系统地分析和提出了步长不匹配问题及其解决方案，以避免严重的量化误差；实验表明，该方法在不同数据集上降低了整体内存和计算成本，并实现了更高的准确率，特别是在ImageNet上，SEWResNet-34模型实现了2.69%的准确率提升和4.16倍的比特预算降低，为最先进的基准工作。
### Conclusion
该方法通过自适应比特分配和神经元改进，有效降低了SNN的内存和计算成本，同时提高了准确率。实验结果表明，该方法对不同数据集均有效，特别是在ImageNet上实现了显著的改进。
## 175. `cs.AI` - vibe coding作为软件开发中意向中介的重组：定义、影响与研究议程 [PDF](https://arxiv.org/pdf/2507.21928), [HTML](https://arxiv.org/abs/2507.21928)
### Authors
Christian Meske,Tobias Hermanns,Esther von der Weiden,Kai-Uwe Loser,Thorsten Berger
### Background
随着vibe coding的普及，软件开发正在经历根本性的变革，大量当代代码由AI生成。快速采用与有限的概念理解之间的差距凸显了对该新兴范式的探究需求。
### Innovation
定义了vibe coding作为一种软件开发范式，其中人类和生成型AI通过自然语言对话协作创造软件制品。vibe coding重新配置了认知工作，重新分配了人类与机器之间的知识劳动，将软件开发过程中专门知识从传统的设计或技术实现转向协作编排。识别了关键的机遇与风险，包括民主化、加速和系统的影响，以及黑箱代码库、责任缺口、生态系统偏见等问题。
### Conclusion
提出了跨越人类中心、技术中心和组织中心的研究议程，以指导对该范式未来研究的指导。
## 176. `cs.AI` - XRoboToolkit：一种多平台机器人远程操作框架 [PDF](https://arxiv.org/pdf/2508.00097), [HTML](https://arxiv.org/abs/2508.00097)
### Authors
Zhigen Zhao,Liuchuan Yu,Ke Jing,Ning Yang
### Background
视觉-语言-动作模型的快速发展引发了对大规模、高质量机器人演示数据集的迫切需求。尽管远程操作是数据收集的主要方法，但当前的方法存在可扩展性有限、设置过程复杂和数据质量不佳的问题。
### Innovation
提出了一种基于OpenXR标准的扩展现实(RX)平台上的机器人远程操作跨平台框架XRoboToolkit。该系统包括低延迟立体视觉反馈、基于优化的逆运动学以及对多种跟踪模态的支持，如头部、控制器、手部和辅助动作追踪器。XRoboToolkit的模块化架构可以无缝集成到各种机器人平台和仿真环境中。
### Conclusion
通过精细操作任务展示了该框架的有效性，并通过训练VLA模型来验证数据质量，证明了这些模型具有稳健的自主性能。
## 177. `cs.AI` - NyayaRAG：印度普通法体系下基于RAG的真实法律判决预测 [PDF](https://arxiv.org/pdf/2508.00709), [HTML](https://arxiv.org/abs/2508.00709)
### Authors
Shubham Kumar Nigam,Balaramamahanthi Deepak Patnaik,Shivam Mishra,Ajay Varghese Thomas,Noel Shallum,Kripabandhu Ghosh,Arnab Bhattacharya
### Background
法律判决预测（LJP）已成为人工智能在法律领域的一个关键领域，旨在自动预测司法结果并增强法律推理的可解释性。尽管之前在印度的研究主要依赖于案件内的事实、问题和推理，但这些方法往往忽视了普通法律体系中的核心元素——依赖于法律条款和判例。
### Innovation
提出了一种检索增强生成（RAG）框架NyayaRAG，通过提供模型具体案件描述、相关法律条款以及基于语义检索的先例，模拟真实的法庭情景，评估这种综合输入在预测法院裁决和生成法律解释方面的效果。该框架结合了特定领域的工作流程，针对印度的法律体系进行定制，使用标准词汇和语义度量以及基于LLM的评估器（如G-Eval）进行评估。
### Conclusion
结果显示，将事实输入与结构化的法律知识融合可以显著提高预测的准确性和解释的质量。
## 178. `cs.AI` - Med-GLIP: 使用大规模标注数据推进医疗语言-图像预训练 [PDF](https://arxiv.org/pdf/2508.10528), [HTML](https://arxiv.org/abs/2508.10528)
### Authors
Ziye Deng,Ruihan He,Jiaxiang Liu,Yuan Wang,Zijie Meng,Songtao Jiang,Yong Xie,Zuozhu Liu
### Background
医疗图像定位旨在将自然语言短语与医学图像中的特定区域对齐，作为智能诊断、视觉问答（VQA）和自动化报告生成（MRG）的基础任务。然而，现有研究受到模态覆盖有限、粗粒度标注和缺乏统一可泛化的图像定位框架的限制。
### Innovation
本文构建了一个包含超过530万区域级别注释的大规模医学定位数据集Med-GLIP-5M，覆盖了七个影像模态和多种解剖结构及病理发现。在此基础上，提出了一种模态感知的图像定位框架Med-GLIP，该框架可以从多样化的训练数据中隐式学习层次语义理解，实现对跨尺度结构的识别，如区分肺部和肺炎病灶。实验表明，Med-GLIP在多个图像定位基准测试中优于现有最先进的基线。
### Conclusion
Med-GLIP将空间输出融入下游任务中，包括医疗VQA和报告生成，显著提升了这些任务的表现。数据集将很快发布。
## 179. `cs.AI` - GENIAL：通过网络反转进行生成设计空间探索以实现低功耗算法逻辑单元 [PDF](https://arxiv.org/pdf/2507.18989), [HTML](https://arxiv.org/abs/2507.18989)
### Authors
Maxence Bouvier,Ryan Amaudruz,Felix Arnold,Renzo Andri,Lukas Cavigelli
### Background
随着AI工作负载的增多，优化算术单元对于减少数字系统的占地面积变得越来越重要。传统的设计流程通常依赖于手动或启发式优化，其在全面探索设计理念空间方面能力有限。本文介绍了一种基于机器学习的框架GENIAL，该框架能够自动生成和优化算术单元，特别关注于多相乘器的设计。GENIAL的核心是一个基于Transformer的代理模型，该模型经过两个阶段训练：首先是自我监督的预训练，然后是监督微调，用于从抽象的设计表示中稳健地预测关键的硬件指标，例如功耗和面积。通过反转代理模型，GENIAL高效地搜索新的操作数编码，直接减少特定输入数据分布的算术单元中的能耗。通过在大数据集上的大量实验表明，GENIAL在样本效率和收敛速度方面优于其他方法，使得在逻辑综合优化流程中能够部署高成本的逻辑综合优化流程，从而提高代理模型的准确性。有趣的是，GENIAL自动发现的编码在代表性AI工作负载中的多相乘器中可节省高达18%的开关活动能耗，相较于传统的补码方法。同时，GENIAL的方法也在状态机领域取得了显著改进，这显示出GENIAL适用于广泛的逻辑函数。
### Innovation
GENIAL通过利用基于Transformer的代理模型，结合自我监督的预训练和监督微调过程，能够自动生成和优化算术单元，特别是对于降低多相乘器的开关活动能耗具有显著效果。通过对大数据集的实验，GENIAL展示了其在样本效率和快速收敛方面优于其他方法的能力，能够集成高成本的逻辑综合优化流程，提高了代理模型的准确性。此外，GENIAL还展示了其在状态机等更广泛逻辑函数上的应用潜力。
### Conclusion
这些进展标志着向自动的高质量结果优化组合逻辑电路生成方向迈进了一大步，对于数字系统的优化具有重要意义。
## 180. `cs.AI` - 医学领域大型语言模型中的记忆现象：普遍性、特征和影响 [PDF](https://arxiv.org/pdf/2509.08604), [HTML](https://arxiv.org/abs/2509.08604)
### Authors
Anran Li,Lingfei Qian,Mengmeng Du,Yu Yin,Yan Hu,Zihao Sun,Yihang Fu,Erica Stutz,Xuguang Ai,Qianqian Xie,Rui Zhu,Jimin Huang,Yifan Yang,Siru Liu,Yih-Chung Tham,Lucila Ohno-Machado,Hyunghoon Cho,Zhiyong Lu,Hua Xu,Qingyu Chen
### Background
大型语言模型（LLMs）在医疗领域展现出了显著的潜力。目前，LLMs 已经广泛应用于诊断辅助、医学问答和临床信息整合等任务。然而，一个关键的开放问题是：这些模型在多大程度上会记住训练中的医学数据。本研究旨在提供第一个全面评估 LLMs 在医学中的记忆现象，包括记忆在医学领域中的频率、特征、容量以及可能的下游影响。
### Innovation
该研究系统地分析了三种不同的适应场景：继续在医学文本语料库上进行前向训练、在标准医学基准数据集上进行微调以及在真实世界临床数据上进行微调，包括来自耶鲁新 Haven 医疗系统的超过 13,000 份独特的住院记录。结果显示，记忆现象在所有适应场景中普遍存在，且高于一般领域的报告。
### Conclusion
记忆现象对医学领域 LLMs 的开发和采用均有影响，并可分为有益的记忆（如临床指南和生物医学参考的准确回忆）、无信息的记忆（如重复免责声明或标准化医疗文档语言）和有害的记忆（如生成数据集特定或敏感的临床内容）。基于这些发现，研究提出了实用建议，促进有益的记忆，增强领域特定的逻辑推理和事实准确性；减少无信息的记忆，促进超越表面模式的学习；减轻有害记忆，防止敏感或可识别患者信息的泄露。
## 181. `cs.AI` - 一种用于预测大流行期间心血管疾病生物标志物的多目标贝叶斯变换器框架 [PDF](https://arxiv.org/pdf/2509.01794), [HTML](https://arxiv.org/abs/2509.01794)
### Authors
Trusting Inekwe,Winnie Mkandawire,Emmanuel Agu,Andres Colubri
### Background
COVID-19大流行扰乱了全球的卫生保健系统，特别是对心血管疾病（CVD）等慢性疾病的患者产生了不成比例的影响。这些干扰通过延迟护理和行为变化影响了关键的CVD生物标记物，包括低密度脂蛋白胆固醇（LDL-C）、糖化血红蛋白（HbA1c）、BMI和舒张压（SysBP）。准确建模这些变化对于预测疾病进展并指导预防性护理至关重要。然而，之前的研究所没有从电子健康记录（EHR）中使用机器学习（ML）进行多目标预测的CVD生物标记物预测，同时联合捕捉生物标记物间的依赖性、时间模式和预测不确定性。
### Innovation
本文提出了一种基于预训练BERT变换器框架的MBT-CB（多目标贝叶斯变换器），用于从EHR数据中联合预测LDL-C、HbA1c、BMI和SysBP等CVD生物标记物。该模型利用贝叶斯变分推断估计不确定性，嵌入捕捉时间关系，并通过DeepMTR模型捕捉生物标记物间的关系。MBT-CB在包括其他基于BERT的机器学习模型的一组基准模型中表现出显著的性能提升。
### Conclusion
MBT-CB的出色表现突显了它在预测CVD生物标记物和在大流行期间支持临床决策方面的潜力。该模型有效地捕捉了数据和模型不确定性、患者生物标志物间关系以及时间动态。
## 182. `cs.AI` - Test-Time Warmup for Multimodal Large Language Models [PDF](https://arxiv.org/pdf/2509.10641), [HTML](https://arxiv.org/abs/2509.10641)
### Authors
Nikita Rajaneesh,Thomas Zollo,Richard Zemel
### Background
多模态大型语言模型（MLLMs）在融合文本和图像的高级推理方面具有巨大潜力，但尚未完全实现这一潜力。MLLMs通常包括一个语言模型（LLM）、一个视觉编码器以及一个连接器，将视觉编码器的嵌入映射到LLM的文本嵌入空间。尽管各个组件都基于包含数十亿样本的大型数据集进行预训练，但整个多模态模型通常仅基于几千至数百万样本进行训练，这可能导致在复杂推理任务上的表现较弱。
### Innovation
本文提出了在测试时预热方法（Test-Time Warmup），通过利用弱监督辅助任务的数据，每次测试时对MLLM进行个性化调整，而无需依赖大量的带有标签的数据集进行微调。这种方法在Llama-Vision-Instruct模型上分别在MMMUs、VQA-Rad和GQA上实现了4.03%、5.28%和1.63%的相对性能改进。
### Conclusion
通过对推理之前的预热，可以增强MLLMs在多种推理任务中的鲁棒性。
## 183. `cs.AI` - 从耳朵出发：基于感知的高保真音乐重建 [PDF](https://arxiv.org/pdf/2509.14912), [HTML](https://arxiv.org/abs/2509.14912)
### Authors
Kangdi Wang,Zhiyue Wu,Dinghao Zhou,Rui Lin,Junyu Dai,Tao Jiang
### Background
现有的开源音乐信号重建模型在训练过程中往往忽略了听觉感知方面的重要性，导致在相位准确性和立体声空间表示方面存在不足。这对于依赖高质量音频输入的大规模音频任务，如基于扩散的过程生成来说是一个挑战。
### Innovation
提出了εar-VAE，一种重新思考和优化VAE训练范式的开源音乐信号重建模型。主要创新包括：(i) 在损失计算前应用K加权感知滤波器，使其目标与听觉感知相匹配。(ii) 引入了两种新型相位损失：相关损失用于立体声一致性，以及使用其导数（瞬时频率和群延迟）的相位损失，以提高精确度。(iii) 提出了一种新的光谱监督范式，其中振幅由所有四个中/侧/左/右组件监督，而相位仅通过LR组件进行监督。
### Conclusion
实验结果显示，εar-VAE在44.1kHz时，在多样化的评估指标上显著优于现有的开源模型，特别是在高频谐波重建和空间特性上表现出色。
## 184. `cs.AI` - HyperAdapt：简单的高秩适应 [PDF](https://arxiv.org/pdf/2509.18629), [HTML](https://arxiv.org/abs/2509.18629)
### Authors
Abel Gurung,Joseph Campbell
### Background
基础模型在多种任务上表现出色，但将其应用于特定应用通常需要微调，这通常需要大量的内存和计算资源。参数高效微调（PEFT）方法通过仅更新少数权重来减轻这一问题。
### Innovation
引入了HyperAdapt，这是一种参数高效的微调方法，与现有的先进方法（如LoRA）相比，它显著减少了可训练参数的数量。特别地，HyperAdapt通过应用行和列的对角矩阵缩放来调整预训练的权重矩阵，从而产生高秩更新，但只需要$n+m$个可训练参数来更新一个$n times m$的矩阵。理论分析上，我们建立了HyperAdapt更新中秩的上限，实验证明它在各个模型层中持续诱导高秩变换。
### Conclusion
在GLUE、算术推理和常识推理基准测试中，使用至多14B参数的模型进行实验，结果表明，HyperAdapt的性能与全微调和最先进的PEFT方法相当或接近，而使用的可训练参数数量则是完全微调方法的数万倍少。
## 185. `cs.AI` - ChessArena: 一个用于评估大型语言模型的战略推理能力的国际象棋测试床 [PDF](https://arxiv.org/pdf/2509.24239), [HTML](https://arxiv.org/abs/2509.24239)
### Authors
Jincheng Liu,Sijun He,Jingjing Wu,Xiangsen Wang,Yang Chen,Zhaoqi Kuang,Siqi Bao,Yuan Yao
### Background
最近的大规模语言模型（LLMs）表现出强大的推理能力。然而，一个关键问题仍未得到解答：这些模型是否真正具备战略推理能力，特别是复杂的战术推理能力，还是主要通过在训练数据中提取复杂的模式来进行高明的推理？
### Innovation
本文提出了一种名为ChessArena的国际象棋测试床，用于评估LLMs的战略推理能力。ChessArena是一个竞争框架，允许LLMs以四种不同的模式相互竞争。测试床具有排名算法和排行榜，可以评估包括基本理解、棋步选择和解谜等一系列细致的能力。超过13种不同模式的LLMs在ChessArena中进行了超过800场比赛，结果揭示了当前LLMs的显著缺点：没有任何模型能够击败人类业余水平的棋手Maia-1100，甚至有些模型无法战胜随机选择棋步的玩家。此外，还提供了一个强大的基准模型：我们的微调Qwen3-8B在测试床中的表现显著提高，接近当前最大的推理模型。
### Conclusion
ChessArena测试床揭示了当前LLMs存在的重要局限性，即它们在复杂的战术推理能力方面仍然表现不佳，并提出了一种能够显著提高性能的强大基准。
## 186. `cs.AI` - 通过主动风险感知学习社交导航 [PDF](https://arxiv.org/pdf/2510.07871), [HTML](https://arxiv.org/abs/2510.07871)
### Authors
Erjia Xiao,Lingfeng Zhang,Yingbo Tang,Hao Cheng,Renjing Xu,Wenbo Ding,Lei Zhou,Long Chen,Hangjun Ye,Xiaoshuai Hao
### Background
论文描述了对IROS 2025 RoboSense挑战赛Social Navigation赛道的参赛技术细节。该赛道旨在开发基于RGBD感知和导航系统，让自主代理能够在充满人类的动态室内环境中安全、高效且符合社交规范地导航。挑战要求代理仅使用车载传感器，包括RGB-D图和里程计，无需全球地图或特权信息的访问，同时必须遵守社交规范，如保持安全距离和避免碰撞。
### Innovation
本文介绍了一种Proactive Risk Perception模块，增强社交导航性能。该模块结合Falcon模型，赋予代理基于距离预测周围人类的碰撞风险得分的能力，从而增强其空间意识与主动避碰行为。
### Conclusion
在Social-HM3D基准上的评估表明，该方法提高了代理在动态室内环境中保持个人空间符合规范的能力，同时导航到目标，最终在16支参赛队伍中获得第2名的好成绩。
## 187. `cs.AI` - 平衡质量和多样性：垃圾邮件过滤扭曲数据标签分布 [PDF](https://arxiv.org/pdf/2509.08217), [HTML](https://arxiv.org/abs/2509.08217)
### Authors
Eve Fleisig,Matthias Orlikowski,Philipp Cimiano,Dan Klein
### Background
为了使得机器学习数据集准确地反映多样化人群的意见，这些数据必须要保留数据标签的差异性，同时过滤掉垃圾邮件或低质量的回复。如何平衡注释员的可靠性和代表性成为一个亟待解决的问题。广泛使用的注释员过滤方法旨在减少数据中的噪音，但却往往误除了真正有分歧的注释员，而保留了垃圾注释员，从而在准确性和标签多样性之间引入了次优权衡。现有文献中的垃圾注释过滤方法通常假设噪声和多样性是一致的，但在缺乏多样性的任务中，这种假设可能导致性能下降。因此，研究发现，现有的垃圾邮件过滤方法在处理需要保留多样性的任务时需要调整，以区分真正的注释员和垃圾注释员。
### Innovation
本文通过实证研究了多种注释员过滤方法对主观任务中标签差异性保留的影响，并发现现有方法在确保数据质量的同时，可能会损害标签的多样性。研究进一步分析了合成垃圾注释的表现，发现现有方法往往假设垃圾注释更加随机，而实际上，大多数垃圾注释行为与真实注释员无显著差异，只有一小部分真正的垃圾注释行为具有相同的问题答案。该研究指出，真实垃圾注释行为通常不如非垃圾注释行为随机，因此需要开发考虑标签多样性的垃圾邮件过滤方法，以避免过滤掉真正提供了有价值数据的真实注释员。
### Conclusion
本研究发现，为了在任务中保留标签多样性，必须谨慎选择注释员过滤方法。保守的注释员去除设置(<5%)对标签多样性有益，而其他方法则增加了数据的平均绝对误差。研究还指出，现有垃圾邮件过滤方法的假设需要调整，以适应需要保留多样性的任务。未来研究应侧重于开发能够兼顾数据质量和多样性的更有效的垃圾邮件过滤方法。
## 188. `cs.AI` - 自监督学习在可穿戴EEG高效睡眠分期中的系统评估 [PDF](https://arxiv.org/pdf/2510.07960), [HTML](https://arxiv.org/abs/2510.07960)
### Authors
Emilio Estevan,María Sierra-Torralba,Eduardo López-Larraz,Luis Montesano
### Background
可穿戴脑电图（EEG）设备已成为睡眠多导生理图（PSG）的有前途的替代方案。由于这些设备具备低成本和可扩展性，广泛采用后会产生大量未标记的数据，而临床人员无法大规模分析这些数据。此外，尽管深度学习在睡眠分级方面取得了成功，但这依赖于大量标注的数据集。自监督学习（SSL）提供了一种机会，通过利用未标记的信号来解决标注数据稀缺的问题，从而减少标注工作量。本文对SSL方法在使用可穿戴EEG进行睡眠分期中的系统评估进行了研究。
### Innovation
作者系统评估了多种自监督学习方法在使用可穿戴EEG进行睡眠分期中的应用。通过在两个数据集（BOAS和HOGAR）上进行实验，展示了SSL方法在标注数据稀缺时能够显著提高分类性能，同时仅需较少的标注数据就可以达到临床标准的准确度。此外，自监督表示方法还表现出对人群特征、记录环境和信号质量变化的鲁棒性。这项研究可能有助于推动使用可穿戴EEG进行高效睡眠监测系统的开发，减少对手动标注的依赖。
### Conclusion
结果表明，SSL方法不仅可以显著提升分类性能，而且可以有效减少对标注数据的依赖。具体表现为，在标注数据稀缺的情况下，SSL方法能够比监督学习方法提供更好的性能。通过仅使用5%到10%的标注数据，SSL方法仍然能够达到80%以上的临床准确度。此外，SSL表示方法对不同的环境和信号质量表现出高度的鲁棒性。这些发现证明了SSL方法在使用可穿戴EEG进行睡眠分类中的潜力，有助于提高睡眠监测系统的可负担性和效率。
## 189. `cs.AI` - 集成顺序和关系建模的用户事件：数据集和预测任务 [PDF](https://arxiv.org/pdf/2510.11903), [HTML](https://arxiv.org/abs/2510.11903)
### Authors
Rizal Fathony,Igor Melnyk,Owen Reinert,Nam H. Nguyen,Daniele Rosa,C. Bayan Bruss
### Background
用户事件建模在许多机器学习应用中起着核心作用，涵盖了电子商务、社交媒体、金融、网络安全等多个领域。用户事件可以大致分为个人事件和关系事件，前者涉及个人行为，后者涉及用户之间的互动。这两种事件通常分别使用序列方法和图方法进行建模。然而，由于需要在现实系统中同时捕捉这两种事件类型，之前的工作很少将它们结合起来处理。这是因为简化认为用户行为可以用一个统一的形式化表示，作为序列或图之一来充分表示。因此，需要公共数据集和明确包含个人和关系事件的预测任务以弥补这一差距。
### Innovation
本文提出了集成序列和关系建模的用户事件数据集和预测任务，并提出了一种统一的形式化方法。实验证明，通过综合使用这两种事件类型，模型可以获得更好的效果。研究表明，当前的方法仍存在改进的空间。作者还分享了这些资源以支持统一用户事件建模的研究并鼓励在这个方向上取得进步。
### Conclusion
结果表明，单纯使用序列或图的方法对用户的事件进行建模存在局限性，而通过结合个人事件和关系事件的数据建模，可以提高模型的效果。为了推动这一研究领域的发展，作者提供了这些数据集和一种统一的形式化方法，希望进一步推进统一用户事件建模的研究。
## 190. `cs.AI` - 通过视觉语言真/假验证的零样本指代表达理解 [PDF](https://arxiv.org/pdf/2509.09958), [HTML](https://arxiv.org/abs/2509.09958)
### Authors
Jeffrey Liu,Rongbin Hu
### Background
通常，指代表达理解(REC)任务使用特定任务训练的 grounding 模型来解决。该论文指出，在没有针对 REC 进行任何专门训练的情况下，可以实现与训练过的模型相当甚至更为优秀的表现。
### Innovation
该方法将 REC 重新定义为基于 ROI（region-of-interest）的视觉语言验证问题，使用通用的 YOLO-World 卷积对象检测器生成提案，然后使用通用的 VLM（视觉语言模型）独立地为每一个区域进行 True/False 查询的回答，这简化了跨 ROI 的干扰，支持选择多个匹配，并且不需要微调。
### Conclusion
该方法不仅超越了零样本基线模型 GroundingDINO 的表现，还在 RecCOCO、RecCOCO+ 和 RecCOCOg 数据集上的效果超过了经过 REC 训练和 CRG（多关系图）训练的 GroundingDINO 的结果。研究还证实了验证方法优于基于选择的提示方法，并且结果使用通用模型也是一致的。因此，该研究强调了工作流设计在驱动零样本 REC 性能方面的关键作用，而非任务特定的预训练。
## 191. `cs.AI` - RealDPO: 实为虚拟，偏好即评价 [PDF](https://arxiv.org/pdf/2510.14955), [HTML](https://arxiv.org/abs/2510.14955)
### Authors
Guo Cheng,Danni Yang,Ziqi Huang,Jianlou Si,Chenyang Si,Ziwei Liu
### Background
视频生成模型在近期已经实现了显著的质量提升，但在生成复杂的动作方面仍面临巨大挑战。现有模型往往难以产生自然流畅且上下文一致的动作。这种生成动作与真实世界动作之间的差距限制了其实际应用能力。
### Innovation
我们提出了RealDPO，一种新颖的对齐范式，利用真实世界的视频作为正样本进行偏好学习，从而改进动作的生成精度。RealDPO采用了带有定制损失函数的直接偏好优化方法（DPO），通过对比真实视频与模型错误输出间差异，实现迭代自我纠正，逐步提升动作质量。我们还提出了RealAction-5K数据集，该数据集包含大量高质量的视频，捕捉人类日常活动丰富的运动细节，以支持复杂的运动合成后的训练。实验结果表明，与最先进的模型和现有的偏好优化技术相比，RealDPO可以显著提升视频质量、文本一致性和动作的真实感。
### Conclusion
通过引入这种新的优化范式和高质量的数据集，我们的研究成果在动作生成的自然度和一致性方面都有显著提升，并为后续研究提供了新的方向。
## 192. `cs.AI` - 使用表征相似性分析比较计算病理学基础模型 [PDF](https://arxiv.org/pdf/2509.15482), [HTML](https://arxiv.org/abs/2509.15482)
### Authors
Vaibhav Mishra,William Lotter
### Background
计算病理学（CPath）中的基础模型因其在促进许多下游任务中的潜力而越来越被发展。尽管最近的研究已经评估了不同模型的任务性能，但仍不清楚它们学习表示的具体结构和变异性。本文通过表征相似性分析方法系统地分析了六个CPath基础模型的表征空间。
### Innovation
本研究使用表征相似性分析方法分析了基于视觉-语言对比学习（CONCH, PLIP, KEEP）和自我蒸馏（UNI (v2), Virchow (v2), Prov-GigaPath）的CPath基础模型。研究发现在表征相似性方面UNI2和Virchow2具有最高的独特性，而Prov-Gigapath在模型之间的相似性最高。此外，所有模型的表示都显示了较高的幻灯片依赖性，但相对较低的疾病依赖性。
### Conclusion
该研究突显了提高对幻灯片特定特征鲁棒性的机会，指导了模型集成策略，并提供了有关训练范式如何塑造模型表示的见解。本框架在医学影像领域具有扩展性，通过对基础模型内部表示的探查，可以支持其有效开发和部署。
## 193. `cs.AI` - 使用全局分歧令牌并行训练大规模语言模型 [PDF](https://arxiv.org/pdf/2510.05132), [HTML](https://arxiv.org/abs/2510.05132)
### Authors
Sheng Jia,Xiao Wang,Shiva Prasad Kasiviswanathan
### Background
尽管通过增加并行测试计算来扩展LLM可以提高性能，但这需要生成既多样化又准确的推理路径。对于具有挑战性的问题，导致多样且正确的推理模式的分叉令牌通常位于采样树的深处。因此，鼓励多样性的常见策略，如温度缩放，在多样性和准确性之间遇到了恶化的权衡。
### Innovation
提出了将并行推理视为下一个令牌集预测问题，并将基于集的全局损失整合到监督微调（SFT）中，使用自监督二分匹配来将全局分叉令牌与独特的推理轨迹匹配。实验表明，我们的方法SSFT能够保留这些独特的推理模式并产生新的全局分叉令牌，从而在多个推理基准测试中均优于SFT，特别是在Pass@1和Cons@k指标上表现出色。
### Conclusion
我们的SSFT方法在鼓励多样性和提高准确性之间提供了更好的平衡，并且在多个推理基准测试中表现出色，特别是在评估指标Pass@1和Cons@k方面。
## 194. `cs.AI` - ADPO: 锚定直接偏好优化 [PDF](https://arxiv.org/pdf/2510.18913), [HTML](https://arxiv.org/abs/2510.18913)
### Authors
Wang Zixian
### Background
直接偏好优化(DPO)在标注者噪声和分布变化下的效果不稳，因为它依赖于硬的成对标记，并只正则化对数概率差值。ADPO框架通过参考锚定扩展了偏好学习，使其能够利用软列表式监督。ADPO通过最小化KL散度来实现目标，从而在合适的条件下恢复监督微调、知识蒸馏、最大熵强化学习和DPO等方法，并且引入由softmax鱼叉度量治理的隐含信任区域，进而支持动态锚定更新。
### Innovation
ADPO引入了通过参考点锚定直接偏好优化，扩展了偏好学习的能力，使其能够利用软列表式监督。它可以在合适的条件下恢复多种监督学习方法，并引入一个由softmax鱼叉度量治理的隐含信任区域。此外，ADPO支持动态锚定更新，从而能够在噪声环境中提高在线探索，并在无噪声环境中更有效地进行离线蒸馏。
### Conclusion
ADPO在我们的基准测试中显示，动态锚定在噪声环境下的在线探索方面表现出优势，而固定锚定在离线蒸馏方面更具优势，能够将学生教师之间的KL散度降低170到5000倍。
## 195. `cs.AI` - Gestura: 一种基于LVLM的实时自由手势理解和语义桥梁系统 [PDF](https://arxiv.org/pdf/2510.21814), [HTML](https://arxiv.org/abs/2510.21814)
### Authors
Zhuoming Li,Aitong Liu,Mengxi Jia,Yubi Lu,Tengxiang Zhang,Changzhi Sun,Dell Zhang,Xuelong Li
### Background
自由手势理解对人机交互具有高度吸引力，因为它可以解放用户不受预定义手势类别的限制。然而，目前唯一现有的解决方案GestureGPT在识别准确性和响应速度方面存在局限。
### Innovation
本文提出了一种端到端的系统Gestura，用于自由手势理解。Gestura利用预训练的大型视觉-语言模型（LVLM）将自由手势的高度动态和多样性模式与高层语义概念对齐。为了更好地捕捉不同风格下的微妙手部动作，引入了骨骼点处理模块，以通过嵌入解剖手部先验知识来补充LVLM的细粒度领域知识缺乏。此外，采用逐步推理策略Chain-of-Thought (CoT)，实现浅层知识到深层语义理解的转变，显著增强了模型对模糊或非传统手势的解释能力。
### Conclusion
这些组件使Gestura能够实现稳健且可适应的自由手势理解。此外，我们还开发了首个用于自由手势意图推理和理解的开源数据集，包含超过30万个标注的问答对。
## 196. `cs.AI` - 重塑奖励机制，不仅奖励终点：一种用于测试时强化学习的复合路径与答案自我评分奖励机制 [PDF](https://arxiv.org/pdf/2510.17923), [HTML](https://arxiv.org/abs/2510.17923)
### Authors
Chenwei Tang,Jingyu Xing,Xinyu Liu,Wei Ju,Jiancheng Lv,Fan Zhang,Deng Xiong,Ziyue Qiao
### Background
强化学习（RL）是推动大型语言模型（LLMs）发展的强大架构，尤其在数学和代码生成等复杂推理领域取得了显著成果。然而，当前的RL方法在数据标注依赖方面存在基本的可扩展性瓶颈。为此，研究者们转向利用未标注数据进行自适应学习，面临的挑战是如何在缺乏真实监督的情况下可靠地进行奖励估计。现有的方法如Test-Time RL依赖于一致性共识，但存在强化错误伪标签的风险。
### Innovation
研究引入了一种新的奖励机制——COMPASS（Composite Path and Answer Self-Scoring），这是一种无需外部监督的测试时奖励机制。它整合了两种互补组件：Dual-Calibration Answer Reward (DCAR)，稳定训练并通过置信度和可信度校准建立可靠伪标签；Decisive Path Reward (DPR)，直接优化推理过程质量，超越单纯的结果监督。这种机制共同增强了模型的分析能力，实验结果表明，在不同推理任务和模型架构下，COMPASS实现了显著的一致性性能提升，为LLMs从持续经验中学习提供了更可扩展的方向。
### Conclusion
COMPASS系统性地增强了解析能力，并在多种推理任务和模型结构中取得了显著的、一致的性能提高，为LLMs从连续经验中学习提供了更可扩展的途径。
## 197. `cs.AI` - TraceTrans: 对手术预测的转化与空间追踪 [PDF](https://arxiv.org/pdf/2510.22379), [HTML](https://arxiv.org/abs/2510.22379)
### Authors
Xiyu Luo,Haodong Li,Xinxing Cheng,He Zhao,Yang Hu,Xuan Song,Tianyang Zhang
### Background
图像到图像转换模型在不同视觉领域之间的图像转换中取得了显著的成功，并且越来越多地被用于医疗任务，如预测手术后结果和疾病进展建模。然而，大多数现有的方法主要旨在匹配目标分布，但往往忽略了源图像和转换图像之间的空间对应关系。这种限制可能导致结构不一致和幻觉，从而降低预测的可靠性和可解释性。特别是在临床应用中，严格要求解剖准确性进一步突显了这一挑战。
### Innovation
本文提出了TraceTrans，这是一个新颖的可变形图像转换模型，旨在预测手术后效果。TraceTrans在生成与目标分布一致的图像的同时，明确地揭示了与术前输入的空间对应关系。该框架通过编码器进行特征提取，并使用双解码器来预测空间位移和合成转换后的图像。预测的变形场对生成输出施加了空间约束，确保了与源图像的解剖一致性。
### Conclusion
在医学整形和大脑MRI数据集上的广泛实验表明，TraceTrans能够提供准确且可解释的术后预测，突出其在可靠临床部署中的潜力。
## 198. `cs.AI` - 使用大规模语言模型作为证明者和验证者的数学证明 [PDF](https://arxiv.org/pdf/2510.12829), [HTML](https://arxiv.org/abs/2510.12829)
### Authors
Hieu Le Duc,Leo Liberti
### Background
自2024年起，关于大规模语言模型在定理证明方面的表现开始引起关注，主要集中在其在解决复杂数学问题（如国际数学奥林匹克竞赛的问题）和验证猜想方面的成功案例。ChatGPT在此背景下，通过多次使用gpt-5模型的不同证明者和验证者实例进行协作，实现了一项定理证明的壮举。为确保生成的证明不出现幻觉，最后的证明经过了lean证明助手的形式验证，人工验证了前提和结论的一致性。
### Innovation
提出了一种新的合作方法，即通过gpt-5模型的不同证明者和验证者实例协作进行定理证明，这种方法能有效避免幻觉问题。尤其在解决2025年IMO的五个问题和几乎完成66个数论猜想方面取得了显著成果。
### Conclusion
虽然该方法尚不完善且不精确，但它展示了在数学证明中使用大规模语言模型作为一种有效工具的潜力，并在解决复杂的数学问题和验证猜想方面取得了显著成就。
## 199. `cs.AI` - 为第二好的服务付费：博弈论方法对抗不诚实的大型语言模型提供商 [PDF](https://arxiv.org/pdf/2511.00847), [HTML](https://arxiv.org/abs/2511.00847)
### Authors
Yuhan Cao,Yu Wang,Sitong Liu,Miao Li,Yixin Tao,Tianxing He
### Background
随着大型语言模型（LLMs）通过应用程序编程接口（APIs）的广泛应用，服务提供商有可能进行欺诈性操纵，例如替代高性能模型或虚增响应以增加计费，这引起了严重漏洞。本文通过博弈理论和机制设计的视角研究这一问题。作者构建了一个针对现实用户-提供商生态系统的正式经济模型，模型中用户可以迭代委托给多个模型提供商，而提供商则可以采取多种策略行为。
### Innovation
首次提出了针对现实用户-提供商生态系统的正式经济模型，证明了在连续策略空间和任意$0<frac12$内的$boldsymbol{text{ε}}$下，存在具有$O(T^{1-boldsymbol{text{ε}}}text{log} T)$近似激励兼容机制，并保证近线性第二最好的用户效用。此外，证明了无法保证预期用户效用优于本文机制的下限结果，并在现实API设置中展示了机制的有效性。
### Conclusion
对于不诚实的LLM提供商，本文提出了博弈论方法以补偿第二好的服务。此方法在现实API设置的仿真实验中显示出有效性，并且不存在更好的机制能够保证更好的预期用户效用。
## 200. `cs.AI` - Deep Edge Filter: 返回深度学习中的人工制作层 [PDF](https://arxiv.org/pdf/2510.13865), [HTML](https://arxiv.org/abs/2510.13865)
### Authors
Dongkwan Lee,Junhoo Lee,Nojun Kwak
### Background
神经网络在不同领域的深度特征中编码了任务相关信息和领域特定的偏差。传统的深度学习模型在处理不同数据形式（如视觉、文本、3D和音频）时，模型的泛化能力可能受到限制。
### Innovation
提出了一种新的方法——Deep Edge Filter，它通过高通滤波深度神经网络的特征来提高模型的泛化能力。该方法假设神经网络中高频成分包含任务相关语义信息，而低频成分存储了领域特定的偏见。通过从中减去低通滤波输出，该方法隔离了泛化表示并将结构完整性保留下来。实验结果表明，在多种领域中，该方法能提高模型性能，不论模型架构和数据类型如何。分析表明该方法导致了特征稀疏化，并有效隔离了高频基频成分。
### Conclusion
无论模型架构和数据类型如何，该方法在多种领域的实验中均表现出持续的性能提升，提供了对核心假设的经验验证。该方法通过隔离泛化表示而不会破坏模型结构，从而提升模型的泛化能力。相关代码可在此处访问：this https URL
## 201. `cs.AI` - 非凸空中异质联邦学习：偏差与方差折衷 [PDF](https://arxiv.org/pdf/2510.26722), [HTML](https://arxiv.org/abs/2510.26722)
### Authors
Muhammad Faraz Ul Abrar,Nicolò Michelusi
### Background
空中联邦学习（OTA-FL）已被广泛认可为一种在无线多址信道上利用波形叠加来聚合模型更新的可扩展范式。现有的OTA-FL设计主要通过假设等路径损耗的无线条件或者强制零偏差更新来确保零偏差模型更新，但这些设计在异质无线场景下受限于最弱设备并放大了更新的方差。先前对有偏OTA-FL的研究主要针对凸目标函数，而现代AI模型通常高度非凸。受到这些问题的启发，在异质无线场景下，我们研究使用随机梯度下降（SGD）的OTA-FL，以处理较为通用的光滑非凸目标函数。我们开发了允许结构化和时间不变偏差但仍能降低方差更新的OTA-FL SGD更新。我们推导出有限时间停稳性界（期望的平均梯度平方模值），明确揭示了偏差与方差之间的折衷关系。为了优化这种折衷，我们提出了非凸联合OTA功率控制设计，并开发了只需要基站统计CSI的高效次凸逼近（SCA）算法。实验表明，基于SCA的设计通过优化偏差加速了收敛，提高了泛化能力，优于之前的OTA-FL基准。
### Innovation
开发了允许结构化和时间不变偏差但仍能有效降低方差更新的OTA-FL-SGD更新，推导了偏差与方差之间的折衷关系，并提出了非凸联合OTA功率控制设计及有效的次凸逼近（SCA）算法，仅需统计CSI即可实现。这些方法能够优化非凸OTA-FL下的偏差与方差折衷，加速收敛，提高泛化性能。
### Conclusion
本研究首次系统地研究了在异质无线场景下非凸目标函数的OTA-FL，并且提出了一种优化非凸OTA-FL偏差与方差折衷的新方法，通过该方法实现了更快速的收敛和更好的泛化性能。
## 202. `cs.AI` - 因果图神经网络在医疗健康领域的应用 [PDF](https://arxiv.org/pdf/2511.02531), [HTML](https://arxiv.org/abs/2511.02531)
### Authors
Munib Mesinovic,Max Buhlan,Tingting Zhu
### Background
医疗健康系统中的人工智能系统在部署到不同机构时通常会产生故障，表现为性能下降和历史数据中嵌入的歧视性模式的延续。这种脆弱性部分源于学习统计关联而非因果机制。
### Innovation
因果图神经网络结合图基表示的生物医学数据和因果推理理论，以学习不变机制而非伪相关性，从而解决分布转移、歧视和不可解释性的三重危机。这些方法包括结构因果模型、去纠缠的因果表示学习，以及在图上进行干预预测和反事实推理的技术。
### Conclusion
因果图神经网络为基于患者的具体因果数字双胞胎提供了基础，这些双胞胎可以在无管理的临床试验中使用，并结合大型语言模型进行假设生成和因果图神经网络进行机制验证。然而，依然存在计算需求限制实时部署、验证挑战需要多模态证据三角化及因果洗牌等风险。提出了区分因果启发式架构和实质性因果验证发现的层级框架，并指出了重要研究方向，即做出因果而非单纯相关性的声明。
## 203. `cs.AI` - OceanAI: 一种准确、透明、近实时的海洋学洞察对话平台 [PDF](https://arxiv.org/pdf/2511.01019), [HTML](https://arxiv.org/abs/2511.01019)
### Authors
Bowen Chen,Jayesh Gajbhar,Gregory Dusek,Rob Redmon,Patrick Hogan,Paul Liu,DelWayne Bohnenstiehl,Dongkuan Xu,Ruoying He
### Background
人工智代表正在改变科学界，但一般的对话AI系统常常生成未验证的“幻觉”，这破坏了科学的严谨性。目前缺乏能够提供准确、透明和实时海洋数据的对话平台，许多现有的AI产品在这个领域表现不佳，要么拒绝回答问题，要么提供没有支持的数据结果。因此，有必要开发一种新的对话平台，能够提供由国家海洋和大气管理局（NOAA）提供的准确数据，并能实现实时数据查询和验证，以支持海洋科学领域的决策和研究。
### Innovation
OceanAI是第一个将开源大型语言模型的自然语言流畅性和NOAA的实时参数化海洋数据流集成在一起的对话平台。每当用户提出查询时，如'2024年波士顿港的水面最高点是什么？'，OceanAI会实时调用API来识别、解析和合并相关数据集，生成可重复的自然语言回答和数据可视化，并提供原始数据引用，从而保证结果的准确性、透明性和可验证性。与市场上其他广泛使用的AI聊天界面产品相比，OceanAI是唯一一个提供由NOAA提供的准确数据并带有原始数据引用的产品。OceanAI还针对扩展性进行了设计，可以连接到多个NOAA数据产品和变量，支持海洋灾害预测、生态系统评估和水质监测等应用。
### Conclusion
通过将输出与可验证的观察相结合，OceanAI推动了透明度、可重复性和信任的提升，提供了一种可扩展的框架，用于支持海洋科学领域的AI增强决策。这种平台可以为研究人员、管理者和公众提供有价值的海洋学洞察，提高海洋管理的科学性和有效性。
## 204. `cs.AI` - PoCo: 生成型智能合约概念验证漏洞利用工具 [PDF](https://arxiv.org/pdf/2511.02780), [HTML](https://arxiv.org/abs/2511.02780)
### Authors
Vivi Andersson,Sofia Bobadilla,Harald Hobbelhagen,Martin Monperrus
### Background
智能合约在高对抗性环境中运行，其中的漏洞可能导致重大经济损失，因此需要进行安全审计。在审计过程中，概念验证（PoC）攻击扮演着重要角色，通过这些攻击可以向利益相关者证明所报告的漏洞是真实的、可复现且可修复的。然而，手动创建PoC攻击是耗时、易错的，且常受限于紧凑的审计时间表。因此，需要一种自动化的工具来生成PoC攻击，以减轻人工工作的负担并提高审计效率和质量。
### Innovation
我们提出了POCO框架，这是一种生成性代理框架，能够从审计人员撰写的自然语言漏洞描述中自动生成可执行的概念验证攻击。POCO通过在执行代码工具中进行‘思考-行动-观察’循环来自主生成PoC攻击，生成的PoC与Foundry测试框架兼容，可以直接集成到审计报告和其他安全工具中。我们的研究表明，基于代理的框架可以显著降低生成高质量PoC攻击所需的劳动量，为智能合约安全社区提供了直接可操作的知识。
### Conclusion
我们提出的POCO框架能够显著提高智能合约审计中PoC攻击的生成效率和质量，为智能合约安全审计过程带来新的革新。通过利用代理技术，POCO能够在审计流程中提供有效的自动化支持，从而降低团队的工作负担并提高审计的整体效果。
## 205. `cs.AI` - TowerVision: 理解和改进视觉语言模型中的多语言性 [PDF](https://arxiv.org/pdf/2510.21849), [HTML](https://arxiv.org/abs/2510.21849)
### Authors
André G. Viveiros,Patrick Fernandes,Saul Santos,Sonal Sannigrahi,Emmanouil Zaranis,Nuno M. Guerreiro,Amin Farajian,Pierre Colombo,Graham Neubig,André F. T. Martins
### Background
尽管视觉语言模型（VLMs）取得了显著进展，但大多数现有工作都遵循了以英语为中心的设计流程，限制了它们在多语言环境中的效果。本文通过全面的经验研究探讨了多种多语言设计选择的影响，如训练数据组成、编码器选择和文本骨干网等。研究结果是建立在多语言文本模型Tower+之上的开放多语言VLMs系列TowerVision，适用于图像-文本和视频-文本任务。
### Innovation
研究通过在微调过程中引入视觉和文化上下文，使模型在ALM-Bench、Multi30K（图像任务）和ViMUL-Bench（视频任务）上的性能超过了使用更大数据集训练的现有方法。此外，还发布了高质量的VisionBlocks数据集，着重表明多语言视觉语言训练数据显著改善了跨语言泛化效果，并且指令调优的大语言模型并不是总是最优的初始化点。
### Conclusion
为了支持进一步研究，所有模型、数据和训练配方均已公开发布。
## 206. `cs.AI` - FATE: 多难度层级形式代数基准系列 [PDF](https://arxiv.org/pdf/2511.02872), [HTML](https://arxiv.org/abs/2511.02872)
### Authors
Jiedong Jiang,Wanyi He,Yuefeng Wang,Guoxiong Gao,Yongle Hu,Jingting Wang,Nailing Guan,Peihao Wu,Chunbo Dai,Liang Xiao,Bin Dong
### Background
近年来，大型语言模型展示出在形式定理证明中的杰出能力，尤其是在像国际数学奥林匹克(IMO)这样的竞赛数学基准上。然而，这些竞赛并不能反映现代数学研究的深度、广度和抽象层次。为此，我们引入了FATE（Formal Algebra Theorem Evaluation），这一新的形式代数基准系列旨在推动高级数学推理的发展，其中包含两个新组件FATE-H和FATE-X，每个组件有100道代数和交换代数的抽象问题。FATE系列覆盖了从本科生练习到超出博士资格考试难度的难题范围。特别地，FATE-X是首个突破博士水平考试难度和覆盖范围的形式基准。
### Innovation
FATE系列通过设立具有不同困难级别的新基准，填补了大语言模型在形式定理证明与现代数学研究之间的差距。FATE-H和FATE-X分别专注于代数和交换代数问题，并对现有最先进的语言模型进行了一级和二级评估。研究发现，最先进的模型在FATE-H基准上只能达到3%的准确性，在FATE-X基准上完全失败。此外，该研究还系统地分类了模型在形式化过程中常见的错误，并表明专业证明器在自然语言阶段的表现不如通用模型。
### Conclusion
FATE提供了一个坚实且具有挑战性的基准，为迈向研究水平的形式数学推理设定了必要的检查点。这一基准挑战了当前大语言模型的局限性，强调了在高级数学推理中形式化自然语言推理的重要性。
## 207. `cs.AI` - 基于节点的多模态文本、音频、图像和视频生成的节点编辑 [PDF](https://arxiv.org/pdf/2511.03227), [HTML](https://arxiv.org/abs/2511.03227)
### Authors
Alexander Htet Kyaw,Lenin Ravindranath Sivalingam
### Background
当前故事生成系统多以文本为主，且缺乏对多模态内容进行直接编辑和迭代优化的机制。而本研究旨在开发一种基于节点的系统，将故事以节点的形式表示，能够通过直接用户编辑和自然语言提示进行扩展、编辑和迭代细化。每个节点可以整合文字、图像、音频和视频，允许创作者构建多模态叙述。
### Innovation
该系统通过节点表示故事，并支持直接用户编辑和自然语言提示的扩展、编辑和迭代细化。它能够整合多种模态的内容，并且通过任务选择代理自动路由专门处理故事生成、节点结构推理、节点图布局格式化和上下文生成的任务。该系统支持针对个别节点的目标编辑、自动分叉的平行故事情节以及节点为基础的迭代细化。
### Conclusion
研究成果表明，基于节点的编辑不仅能控制叙事结构，还能支持文本、图像、音频和视频的迭代生成。该研究还汇报了自动故事大纲生成的定量结果和编辑工作流的定性观察。然而，该系统目前仍存在扩展到更长叙事的局限性和多节点间的一致性问题，并提出未来研究将关注带有人机协作和用户导向的创意人工智能工具。
## 208. `cs.AI` - 基于环境相似性和船舶移动性的耦合预测框架 [PDF](https://arxiv.org/pdf/2511.03499), [HTML](https://arxiv.org/abs/2511.03499)
### Authors
Gabriel Spadon,Vaishnav Vaidheeswaran,Claudio DiBacco
### Background
海洋入侵物种通过全球航运传播，产生重大生态和经济损失。传统风险评估需要详细的压载水记录和交通模式，但这些记录通常不完整，限制了全球覆盖范围。
### Innovation
本文提出了一个理论框架，通过结合港口之间的环境相似性和观察到的、预测的船舶移动性来量化入侵风险。利用气候变化特征来描述每个港口的海洋条件，使用从自动识别系统数据中提取的移动网络来捕捉船舶流动和潜在转移路径。通过聚类和度量学习揭示气候相似性，从而估算沿航运路线的物种存活几率。利用时间链接预测模型捕捉在环境条件变化时交通模式可能的变化。
### Conclusion
这种环境相似性和预测移动性的综合框架可以为港口和航行级别提供暴露估计，支持有针对性的监测、航线调整和管理干预。
## 209. `cs.CL` - 激活空间个性引导：LLM中稳定特征控制的混合层选择 [PDF](https://arxiv.org/pdf/2511.03738), [HTML](https://arxiv.org/abs/2511.03738)
### Authors
Pranav Bhandari,Nicolas Fay,Sanjeevan Selvaganapathy,Amitava Datta,Usman Naseem,Mehwish Nasim
### Background
目前大型语言模型在生成过程中表现出潜在的人格特征，但是可靠地控制或调整这些特征以满足特定需求仍然是一个开放的挑战。对于模式化人类人格的Big Five人格特质，从模型中提取隐藏状态激活并识别场景特定优化层，以确保稳健插入，这方面的研究仍然不足。本研究旨在通过新的方法和管道来探索这些问题，特别是在如何通过微妙的调整来控制模型的行为，而不影响流畅性、变化性和一般能力。
### Innovation
本文提出了一种新的管道，利用Big Five人格特质从转层器层中提取隐藏状态激活，并应用低秩子空间发现方法，识别不同模型架构下特定人格特质的优化层，实现稳健插入。研究结果表明，通过有选择性的层调整，可以有效地控制模型生成的输出中的人格特质表达，而不牺牲模型的一般能力和流畅性。
### Conclusion
本研究揭示了人格特质存在于低秩共享子空间中，并通过谨慎的调整将潜在结构转化为用于有效引导的可操作机制，从而在心理理论和实用模型对齐之间架起桥梁，有助于稳定地控制大型语言模型的特征表达。
## 210. `cs.AI` - LA-MARRVEL: 一种基于知识和语言的LLM重新排序器，用于增强AI-MARRVEL在罕见病诊断中的性能 [PDF](https://arxiv.org/pdf/2511.02263), [HTML](https://arxiv.org/abs/2511.02263)
### Authors
Jaeyeon Lee,Hyun-Hwan Jeong,Zhandong Liu
### Background
罕见病的诊断需要将基因发现与往往未结构化的参考文本关联起来。当前的处理管道虽然能够收集大量的候选基因，但临床医生仍然需要花费大量时间来筛选假阳性结果并从文献和数据库中综合证据。主要挑战在于语言：表型描述和遗传模式通常以文字形式书写，而非通过表格完全捕捉到。大型语言模型（LLMs）可以阅读这样的文本，但在临床应用中需要依靠可引用的知识和稳定、可重复的行为。因此，本研究尝试在高召回率的第一阶段管道之上实现一个知识导向和语言敏锐的重新排名层，旨在提高精密度和可解释性，而不替代标准生物信息学步骤。
### Innovation
本研究开发了一种知识导向和语言敏锐的LLM重新排序器，名为LA-MARRVEL。它结合了专家构建的上下文和共识方法来减少LLM的变异性，从而生成更短、更合理的基因列表供专家评审。LA-MARRVEL通过对多轮LLM运行的量化投票算法生成了一个一致排序的基因列表，并使用了已被广泛认可作为罕见病诊断标准方法的AI-MARRVEL管道。LA-MARRVEL的表现优于其他方法（包括传统的生物信息学诊断工具如AI-MARRVEL、Exomiser、LIRICAL以及原始的大型语言模型如Anthropic Claude），年均5@Recall为94.10%，相较于AI-MARRVEL提高了3.65个百分点。LLM生成的推理清晰地解释了表型匹配和遗传模式的路径，使临床审查更快捷、更简单。
### Conclusion
LA-MARRVEL结合专家构建的上下文、共识方法和LLM重新排序层，提高了罕见病诊断的准确性和可解释性，同时实现在临床应用中可以引用的知识和稳定的行为。LA-MARRVEL已经在在线AI-MARRVEL功能中实现，可用于处理多个独立罕见病患者队列的真实数据集，证明了其实用性和有效性。
## 211. `cs.AI` - 机器犯罪学 [PDF](https://arxiv.org/pdf/2511.02895), [HTML](https://arxiv.org/abs/2511.02895)
### Authors
Gian Maria Campedelli
### Background
尽管达到类似人类的人工智能(AI)的可能性仍然存在争议，但未来将是一个越来越多地拥有自主机器的社会的可能性很高。自主AI代理已经在多个行业和数字环境中得到部署和活动，并且随着人类与人类及人类与机器的互动，机器与机器的互动预计会越来越普遍。根据这些发展，作者认为犯罪学必须开始考虑这一转变对犯罪和社会控制的影响。
### Innovation
作者提出了一个新的视角，即用社会网络理论和Woolgar几十年前对机器的社会学的呼吁，将AI视为具有计算、社会和法律维度的具有自身行为能力的实体。此外，作者还提出了一个二元分类法来描述AI代理之间的互动可能引发反常、非法或犯罪结果的途径。同时，作者提出了四个关键问题，强调了理论和实证研究对于理解和应对多代理AI系统对犯罪研究的影响的必要性。
### Conclusion
这些问题是理论和实证研究中亟待解决的，研究者需要对此进行更多的关注，并在有关AI安全和治理的讨论中发挥更为积极的作用。
## 212. `cs.CL` - TextualVerifier:一步步验证TextGrad [PDF](https://arxiv.org/pdf/2511.03739), [HTML](https://arxiv.org/abs/2511.03739)
### Authors
Eugenius Mario Situmorang,Adila Alfa Krisnadhi,Ari Wibisono
### Background
当前TextGrad是一个基于文本的自动微分新方法，能让复合AI系统进行优化而不需要显式的数值方程。但目前缺少自我验证机制以确保基于文本的决策推理的有效性。该论文旨在填补这一验证缺口，通过引入一个采用大规模语言模型支持的链式推理和多数投票验证框架TextualVerifier来实现这一目标。TextualVerifier采用四个阶段的工作流程：链式推理分解、变异生成、多数投票和共识聚合。该框架非侵入性地整合到TextGrad的损失函数和优化结果验证阶段。实验证明TextualVerifier有显著提升，并在不同基准测试中表现出色。
### Innovation
TextualVerifier通过引入一个基于语言模型的自我验证框架，填补了TextGrad在推理有效性自我验证方面的空白，无需依赖数值梯度，从而提高了基于文本的优化可靠性，开启了新的验证方向。该框架采用四个阶段的工作流程，即链式推理分解、变异生成、多数投票和共识聚合。该框架以非侵入方式与TextGrad的损失函数和优化结果验证阶段集成。
### Conclusion
实验结果表明，TextualVerifier在不同基准测试中表现出了显著的提升，进一步验证版本也取得了明显的效果。TextualVerifier为基于文本的优化提供了一个自我验证的方法，确保了推理的有效性和可靠性，为未来的研究打开了新的方向。
## 213. `cs.AI` - 人工智能在小学STEM教育中的应用：当前应用和未来挑战的系统综述 [PDF](https://arxiv.org/pdf/2511.00105), [HTML](https://arxiv.org/abs/2511.00105)
### Authors
Majid Memari,Krista Ruggles
### Background
人工智能正在转型小学STEM教育，但现有证据片段化。本研究通过对2020-2025年间258项涉及八类AI应用的研究进行系统综述，将重点关注领域合成。这八类应用包括智能辅导系统、学习分析、自动化评估、计算机视觉、教育机器人、多模态感知、增强现实/虚拟现实（XR）中的AI增强及适应性内容生成。研究表明大多数研究聚焦于小学高年级和数学领域，交叉的STEM学科融合较少。同时，虽然对话式AI表现出中等效果，只有34%的研究包括标准化效果大小。其中包括碎片化的生态系统、发展不适当、基础设施障碍、缺乏隐私框架、弱的STEM学科整合、公平差距、教师边缘化和狭窄的评估范围等八项主要限制障碍。地域分布也呈不平衡，大多数研究（90%）来自北美、东亚和欧洲。
### Innovation
本研究通过系统综述258项研究，全面分析了人工智能在小学STEM教育的应用及挑战，提供了详细的全球地理分布和具体的应用领域分布情况。研究成果展示了对话式AI的中等成效和存在的一些基础性问题，为未来的研究和应用提供了方向，包括提出兼容架构以支持真实STEM整合，保证适宜设计，隐私保护分析机制，以及以教师为中心的实施，而不是取代人类的专业知识。
### Conclusion
尽管对话式AI有一定的成效，但仍存在许多阻碍其广泛应用的关键问题。需要进一步的研究来解决生态系统不兼容、基础设施障碍、隐私问题、狭隘的评估范围和教师培训等挑战，以促进人工智能在小学STEM教育中的更广泛应用。未来的研究应该关注提高跨学科整合、设计适宜性、隐私保护和技术与人类教师协同作用。
## 214. `cs.AI` - 使用控制边界函数对大型语言模型进行对齐 [PDF](https://arxiv.org/pdf/2511.03121), [HTML](https://arxiv.org/abs/2511.03121)
### Authors
Yuya Miyaoka,Masaki Inoue
### Background
本文提出了一种基于控制的框架，用于通过利用控制障碍函数(CBF)对齐大型语言模型（LLMs），以确保生成用户希望的语言文本。背景在于现有大型语言模型的生成文本可能不符合用户期望，需要一种机制进行干预。该机制利用了一个安全过滤器插件，该过滤器可以应用于从基础LLM生成的预测标记，以确保生成的文本符合用户期望。
### Innovation
提出了一种基于控制障碍函数的框架，用作安全过滤器，该过滤器可以在没有对基础LLM进行微调的情况下，将其作为对齐目的的附加类型使用，同时，如果有关于期望对齐的评估模型，可以直接将其应用于过滤器设计。该创新点在于无需对基础模型进行微调即可实现模型的对齐。
### Conclusion
提出的系统使用开源语言模型，旨在生成正面语言。该系统的核心在于使用控制障碍函数作为安全过滤器，干预基础LLM的生成过程，从而实现符合用户期望的语言文本生成。
## 215. `cs.CL` - PLLuM：波兰大型语言模型系列 [PDF](https://arxiv.org/pdf/2511.03823), [HTML](https://arxiv.org/abs/2511.03823)
### Authors
Jan Kocoń,Maciej Piasecki,Arkadiusz Janz,Teddy Ferdinan,Łukasz Radliński,Bartłomiej Koptyra,Marcin Oleksy,Stanisław Woźniak,Paweł Walkowiak,Konrad Wojtasik,Julia Moska,Tomasz Naskręt,Bartosz Walkowiak,Mateusz Gniewkowski,Kamil Szyc,Dawid Motyka,Dawid Banach,Jonatan Dalasiński,Ewa Rudnicka,Bartłomiej Alberski,Tomasz Walkowiak,Aleksander Szczęsny,Maciej Markiewicz,Tomasz Bernaś,Hubert Mazur,Kamil Żyta,Mateusz Tykierko,Grzegorz Chodak,Tomasz Kajdanowicz,Przemysław Kazienko,Agnieszka Karlińska,Karolina Seweryn,Anna Kołos,Maciej Chrabąszcz,Katarzyna Lorenc,Aleksandra Krasnodębska,Artur Wilczek,Katarzyna Dziewulska,Paula Betscher,Zofia Cieślińska,Katarzyna Kowol,Daria Mikoś,Maciej Trzciński,Dawid Krutul,Marek Kozłowski,Sławomir Dadas,Rafał Poświata,Michał Perełkiewicz,Małgorzata Grębowiec,Maciej Kazuła,Marcin Białas,Roman Roszko,Danuta Roszko,Jurgita Vaičenonienė,Andrius Utka,Paweł Levchuk,Paweł Kowalski,Irena Prawdzic-Jankowska,Maciej Ogrodniczuk,Monika Borys,Anna Bulińska,Wiktoria Gumienna,Witold Kieraś,Dorota Komosińska,Katarzyna Krasnowska-Kieraś,Łukasz Kobyliński,Martyna Lewandowska,Marek Łaziński,Mikołaj Łątkowski,Dawid Mastalerz,Beata Milewicz,Agnieszka Anna Mykowiecka,Angelika Peljak-Łapińska,Sandra Penno,Zuzanna Przybysz,Michał Rudolf,Piotr Rybak,Karolina Saputa,Aleksandra Tomaszewska,Aleksander Wawer,Marcin Woliński,Joanna Wołoszyn,Alina Wróblewska,Bartosz Żuk,Filip Żarnecki,Konrad Kaczyński,Anna Cichosz,Zuzanna Deckert,Monika Garnys,Izabela Grabarczyk,Wojciech Janowski,Sylwia Karasińska,Aleksandra Kujawiak,Piotr Misztela,Maria Szymańska,Karolina Walkusz,Igor Siek,Jakub Kwiatkowski,Piotr Pęzik
### Background
大型语言模型（LLMs）在现代人工智能中扮演着重要角色，但其发展主要集中在英语上，导致对其他语言的支持有限。
### Innovation
PLLuM（波兰大型语言模型），一款专门针对波兰语的开源基础模型家族。它包含一个负责的人工智能框架，该框架包括严格的数据治理和混合模块的输出纠正和安全过滤。通过创建新的1400亿词的波兰语文本语料库、77,000个自定义指令数据集和100,000个偏好优化数据集，确保了高质量、透明且文化相关性的语言模型。
### Conclusion
通过公开发布这些模型，PLLuM旨在促进开放研究，加强波兰的主权人工智能技术。
## 216. `cs.CL` - GRDD+:一个具有跨架构微调评估的扩展希腊方言语料库 [PDF](https://arxiv.org/pdf/2511.03772), [HTML](https://arxiv.org/abs/2511.03772)
### Authors
Stergios Chatzikyriakidis,Dimitris Papadakis,Sevasti-Ioanna Papaioannou,Erofili Psaltaki
### Background
现有希腊方言数据集（GRDD）已经存在，但缺乏来自克里特岛方言、塞浦路斯方言、黑海希腊方言和北希腊方言的数据。为了丰富这一资源并拓展其使用范围，该研究团队扩展了现有数据集，增加了六个新品种，使得数据集更加多样化和充实。
### Innovation
该研究首次创建了一个包含6,374,939个单词和10种方言的语料库，这些方言涵盖了从克里特岛到意大利南部的广泛地区。同时，研究团队还对多种模型架构进行了微调评估，以观察高质量方言数据对语言模型性能的影响。这些评估包括三种模型架构（Llama-3-8B、Llama-3.1-8B、Krikri-8B）和一些前沿模型（Claude-3.7-Sonnet、Gemini-2.5、ChatGPT-5）的表现对比。
### Conclusion
这是迄今为止首个具有如此多样性和规模的语言模型方言数据集。研究结果表明，高质量的方言数据在多个LLMs中的微调效果显著，不同模型架构都能够不同程度地从这些数据中受益。
## 217. `cs.CL` - 视觉-语言模型中背景信息对语用解释的影响 [PDF](https://arxiv.org/pdf/2511.03908), [HTML](https://arxiv.org/abs/2511.03908)
### Authors
Alvin Wei Ming Tan,Ben Prystawski,Veronica Boyce,Michael C. Frank
### Background
迭代参考游戏描述了一种场景，其中参与者的角色反复使用语言选择新的指代对象，这一过程为测试代理进行上下文相关语用推理的能力提供了一个很好的实验场景。本文研究了人类和视觉-语言模型在迭代参考游戏中的表现，变化了提供给模型的背景信息的数量、顺序和相关性。
### Innovation
研究通过改变背景信息，分析了视觉-语言模型在多轮语境中进行语用推理的能力。研究展示了背景信息如何显著提升模型的表现力，特别是在提供了相关背景信息的情况下，模型的表现有了极大的提升。
### Conclusion
视觉-语言模型在具有抽象指代对象的少数示例参考游戏中仍面临挑战，表明在语用理解方面仍需进一步提升。背景信息的有效利用对于提高模型在复杂语境下的表现至关重要。
## 218. `cs.AI` - CareMedEval数据集：评估生物医学领域的批判性评估与推理 [PDF](https://arxiv.org/pdf/2511.03441), [HTML](https://arxiv.org/abs/2511.03441)
### Authors
Doria Bonzi,Alexandre Guiggi,Frédéric Béchet,Carlos Ramisch,Benoit Favre
### Background
在生物医学领域，批判性文献评估是一项至关重要的技能。大型语言模型（LLMs）虽然为这一任务提供了潜在的支持，但在专业领域的批判性推理方面，其可靠性仍有限。现有基准数据集大多关注普遍推理能力，而缺乏评估生物医学领域内特定批判性阅读和推理能力的数据集。为了解决这一问题，本研究基于法国医学学生的真实考试，构建了一个名为CareMedEval的新数据集，涵盖37篇科学文章的534个问题，专注于评估大模型的生物医学领域批判性评价和推理任务的能力。
### Innovation
本研究通过引入CareMedEval数据集，旨在提供一个专注于评估生物医学领域内特定批判性阅读和推理能力的数据集。该数据集设计独特，基准测试展示了最先进的通用和生物医学专用大模型在不同上下文条件下评估生物医学文献任务的难度。尽管生成中间推理标记大大提高了结果，但这些模型在研究局限性和统计分析方面仍然面临巨大挑战。因此，CareMedEval提供了一个具有挑战性的基准测试环境，揭示了当前大模型的局限性，并为未来自动化支持批判性评价的发展铺平了道路。
### Conclusion
CareMedEval数据集为评估生物医学领域高层次的合情推理提供了挑战性的测试床。它揭示了现有大模型的局限性，并为未来用于批判性评估的自动化支持的进步指明了方向。
## 219. `cs.CL` - 为低资源语言评估机器翻译数据集：性别视角 [PDF](https://arxiv.org/pdf/2511.03880), [HTML](https://arxiv.org/abs/2511.03880)
### Authors
Hellina Hailu Nigatu,Bethelhem Yemane Mamo,Bontu Fufa Balcha,Debora Taye Tesfaye,Elbethel Daniel Zewdie,Ikram Behiru Nesiru,Jitu Ewnetu Hailu,Senait Mengesha Yayo
### Background
随着低资源语言越来越多地被纳入NLP研究，收集大规模数据集变得尤为重要。然而，这种优先数量而非质量的做法可能导致1）低资源语言技术性能不佳，2）产生和传播社会偏见的有害内容。文章研究了三种低资源语言（Afan Oromo、Amharic和Tigrinya）的机器翻译数据集的质量，特别是在性别代表方面。研究发现，虽然训练数据包含大量的政治和宗教领域文本，但基准数据集则更多集中在新闻、健康和体育等领域。数据显示性别偏差严重，有害和有毒的女性形象描述尤其突出，减少数据量反而表明数量不保证质量，
### Innovation
文章创新性地从性别角度评估了低资源语言的机器翻译数据集质量，并发现了政治和宗教领域文本的高比例、性别偏差严重以及负面女性形象等事实，强调了单纯追求数据量的不足，提出了更慎重收集数据集的建议。
### Conclusion
研究结果表明，尽管数据量大，质量却不一定有保证，并且数据集可能包含有害内容。文章呼吁进一步研究低资源语言数据集，并及早采取措施消除有害内容。
## 220. `cs.CL` - STARS: Segment-level Token Alignment with Rejection Sampling in Large Language Models [PDF](https://arxiv.org/pdf/2511.03827), [HTML](https://arxiv.org/abs/2511.03827)
### Authors
Mohammad Atif Quamar,Mohammad Areeb,Mikhail Kuznetsov,Muslum Ozgur Ozmen,Z. Berkay Celik
### Background
大型语言模型的安全应用需要将其与人类价值观对齐，现有的方法如微调虽然有效，但计算成本高且效果欠佳；另一种方法如Best-of-N采样虽然能实现最佳对齐，但在实际操作中需要难以实现的计算量。因此，需要一种在提高计算效率的同时能有效提升对齐质量的方法。作者提出了一种名为STARS的解码时算法，通过逐段采样、评分、拒绝和接受短的固定大小的标记片段来引导模型生成，实现了早期路径修正并使计算效率显著提升，从而提高了对齐质量。这些研究在6种不同的大语言模型上进行了验证，结果显示STARS在胜率上优于监督微调(SFT)高达14.9个百分点，优于直接偏好优化(DPO)20.2个百分点，同时与强的Best-of-N基线保持竞争力。这项工作证明了基于奖励的分段标记采样的方法是一种可推广、稳健且高效的对齐大语言模型的替代方法，可替代传统的微调和全长序列排名方法。
### Innovation
提出了一种名为STARS的新方法，它是一种解码时算法，能够在逐段采样、评分、拒绝和接受短的固定大小的标记片段中引导模型生成，并允许早期路径修正，从而提高了计算效率和对齐质量。与传统的做法相比，STARS在使用较低计算资源的情况下，仍能显著提升对齐质量。
### Conclusion
作者通过实验验证了STARS的有效性，证明了它在多个大型语言模型上均能显著提高对齐质量，并且在计算效率上具有显著优势。这表明STARS是一种有效的策略，用于对齐大语言模型，可以作为一种替代传统的微调和序列排名方法的方法。
## 221. `cs.CL` - 通过向量翻译在大型语言模型之间实现直接语义通信 [PDF](https://arxiv.org/pdf/2511.03945), [HTML](https://arxiv.org/abs/2511.03945)
### Authors
Fu-Chun Yang,Jason Eshraghian
### Background
在多代理设置下，如辩论、反思或工具调用，大型语言模型（LLMs）以简单令牌形式传递消息，几乎丢弃所有潜在语义，这限制了信息传输并增加了不必要的计算开销。
### Innovation
通过向量翻译形成潜在桥梁，使用学习到的映射，允许直接在表示空间之间进行语义交换。从 Llama-2-7B 和 Mistral-7B-Instruct 训练的双编码器翻译器达到了 0.538 的平均余弦对齐值。在 30% 融合强度下注入翻译向量，可以在不破坏概率值的情况下引导目标模型的生成。双向评估显示转移不对称性比 2.01：1，表明通用模型提供更具可转移性的表示形式，而非指令调整变体。
### Conclusion
这种保守的注入保持了计算稳定性，同时证明了跨模型潜在通信的可行性，使得共享意义而非简单令牌的合作 AI 系统成为可能。
## 222. `cs.CL` - 人类福祉地理指数：2013年至2023年美国县级数据集 [PDF](https://arxiv.org/pdf/2511.03915), [HTML](https://arxiv.org/abs/2511.03915)
### Authors
Stefano M. Iacus,Devika Jain,Andrea Nasuto,Giuseppe Porro,Marcello Carammia,Andrea Vezzulli
### Background
现有的衡量人类福祉的方法往往缺乏精细的空间和时间分辨率，而全面的人类福祉包括幸福、健康、目的、美德、人际关系和财务稳定等多维度的指标。为了更深入地理解社会福祉，需要一种能够精细分析这些因素的方法。本文介绍了一种新的地理指数——人类福祉地理指数（HFGI），该指数通过分析从2013年至2023年大约26亿条美国推特数据，利用微调后的大型语言模型来分类与哈佛全球福祉研究框架相匹配的48个指标，以及对移民态度和腐败感知等的衡量。
### Innovation
该研究创新性地利用社交媒体大数据（如推特）作为人类福祉的衡量工具，并通过微调的大型语言模型识别和分类推文中与福祉相关的表达，从而提供了一个前所未有的高分辨率的数据集，用于分析美国过去十年人类福祉的状态及其变化。此外，该指数还可以跨学科地分析福祉、不平等和社会变迁等因素，揭示人类福祉在社交媒体话语中的动态变化。
### Conclusion
该地理指数资源能够以前所未有的分辨率进行跨学科分析，提供了过去十年美国在推特上反映的人类福祉动态变化的见解。该研究为理解社会福祉提供了新的工具，并为具体的福祉政策制定提供了重要数据支持。
## 223. `cs.CL` - GRAD: 基于图检索的自适应解码方法以减轻幻觉 [PDF](https://arxiv.org/pdf/2511.03900), [HTML](https://arxiv.org/abs/2511.03900)
### Authors
Manh Nguyen,Sunil Gupta,Dai Do,Hung Le
### Background
尽管大型语言模型的规模在增长，消除模型生成内容中的幻觉仍然是一个持续的挑战。现有的方法通常依赖于外部知识源，如结构化数据库或知识图谱，并通过提示或检索访问这些知识源。但是，基于提示的接地方法在不同领域上容易出现脆弱性，并且符号知识整合会带来重大的检索和格式化成本。鉴于此，本文提出了一种新的解码时间方法GRAD（Graph-Retrieved Adaptive Decoding），该方法利用语料库中的证据来生成文本，而无需重新训练模型
### Innovation
GRAD 利用单次前向传递方法构建从小规模检索语料库中积累的稀疏token迁移图，解码时通过图检索过滤logits并动态融合模型logits，以鼓励具有语料证据的内容，同时保持流畅性。GRAD 在三种模型和涵盖不同幻觉和事实任务的问答基准测试中，相对于贪婪解码，实现了更高的内在准确度（高达9.7%）、更低的幻觉率（8.6%）和更大的正确率（6.9%），并且在所有方法中获得了最高的真实-信息产品得分。
### Conclusion
GRAD 提供了一个轻量级、插拔式的替代方案，相对于对比解码和知识图谱增强，证明了基于语料库层级token迁移统计证据的有效性，使生成内容更加真实可信且可验证。
## 224. `cs.CL` - 在检索增强语言模型中应用演绎推理：生成和验证缺失前提 [PDF](https://arxiv.org/pdf/2511.04020), [HTML](https://arxiv.org/abs/2511.04020)
### Authors
Shiyin Lin
### Background
大型语言模型（LLMs）通过检索增强（RAG）技术，在知识密集型任务中表现出强大的性能。然而，当检索到的证据不完整时，RAG 管线常常出问题，导致推理过程中出现空白。在这种情况下，演绎推理作为一种生成可能缺失前提的方法，可以合理地填补这些缺口。本文基于此背景提出了一个框架，将演绎推理集成到检索增强的LLMs中，以检测证据不足的情况，生成候选缺失前提，并通过一致性和可行性检查验证这些前提。实验结果表明，该方法提高了回答准确性和推理的真实性。这项工作凸显了演绎推理作为提升RAG系统的鲁棒性和可解释性的有前途的方法。
### Innovation
本文提出了一个将演绎推理集成到检索增强语言模型中的框架。该方法能够检测证据不充分，生成候选缺失前提，并通过一致性与可行性检查来验证这些前提。这种方法改善了回答的准确性和推理的真实性，展示了演绎推理对增强RAG系统鲁棒性和解释力的潜力。
### Conclusion
本文的工作强调了演绎推理作为提升RAG系统的鲁棒性和可解释性的前景，同时通过实验证明了该方法的有效性。
## 225. `cs.CL` - 分解、缓存、征服：二元提示法在高效的基于大语言模型的多标签分类中的应用 [PDF](https://arxiv.org/pdf/2511.03830), [HTML](https://arxiv.org/abs/2511.03830)
### Authors
Mikołaj Langner,Jan Eliasz,Ewa Rudnicka,Jan Kocoń
### Background
本文介绍了一种使用大型语言模型（LLMs）进行高效多标签文本分类的方法。方法基于将分类任务重新表述为一系列二元（是/否）决策序列。该方法对手动生成所有标签的单一结构响应进行了改进，而是分别查询每个目标维度，结合前缀缓存机制，在保持准确性的前提下，显著提高了短文本推理的效率。该研究重点在于情感文本分析，涵盖了24个维度，包括情感和情绪。利用LLM到SLM的蒸馏技术，一个强大的标注模型（DeepSeek-V3）为每个文本提供了多个注释，这些注释随后用来微调不同的较小模型（HerBERT-Large, CLARIN-1B, PLLuM-8B, Gemma3-1B）。微调后的模型相比零样本基线显著提高，在训练过程中出现的维度上表现尤为突出。研究表明，将多标签分类分解为二元查询，结合蒸馏和缓存感知推理，提供了一种适用于大型语言模型的、可扩展且有效的分类框架。虽然方法在情感状态上进行验证，但该方法具有普适性，适用于各种领域。
### Innovation
本文提出了一种新的方法，即将多标签文本分类任务重新表述为一系列二元决策序列，并通过独立查询每个目标维度和前缀缓存机制，有效提高了分类效率，同时保持了准确性。这种方法利用了大型语言模型的潜力，通过蒸馏技术进一步提升了分类性能，同时提供了一种可扩展的框架，适用于各种场景。
### Conclusion
本文提出的方法通过分解多标签分类任务、利用蒸馏和缓存技巧，提供了一种高效且可扩展的基于大型语言模型的分类框架。虽然在情感分析中进行了验证，但该方法具有广泛的适用性，适用于不同领域的多标签分类任务。
## 226. `cs.CL` - WST: 弱监督转换器在自动语音识别中的应用 [PDF](https://arxiv.org/pdf/2511.04035), [HTML](https://arxiv.org/abs/2511.04035)
### Authors
Dongji Gao,Chenda Liao,Changliang Liu,Matthew Wiesner,Leibny Paola Garcia,Daniel Povey,Sanjeev Khudanpur,Jian Wu
### Background
循环神经网络-转换器(RNN-T)在端到端自动语音识别(ASR)任务中广泛应用，但它依赖于大量高质量的标注数据，这些数据获取成本高且难度大。为减轻依赖性，提出了一种弱监督转换器(WST)，它结合了一个灵活的训练图，能够有效地处理转录中的错误，无需额外的置信度估计或辅助预训练模型。
### Innovation
WST 融合了一个灵活的训练图，用于有效处理转录错误，而不依赖于额外的置信度估计或辅助预训练模型。实验表明，WST 在高达 70% 的转录错误率下仍能保持性能，且相比现有的基于连接主义时间分类(CTC)的弱监督方法（如绕路时间分类(BTC)和全时间分类(OTC)）表现出更优的效果。这表明 WST 在实际 ASR 环境中具有实用性和鲁棒性。
### Conclusion
WST 在合成和工业数据集上的实验证明了其在现实 ASR 场景中的实用性和鲁棒性，并且其实现将对外公开。
## 227. `cs.CL` - T-FIX：解释性文本与专家可理解特征的关系 [PDF](https://arxiv.org/pdf/2511.04070), [HTML](https://arxiv.org/abs/2511.04070)
### Authors
Shreya Havaldar,Helen Jin,Chaehyeon Kim,Anton Xue,Weiqiu You,Marco Gatti,Bhuvnesh Jain,Helen Qu,Daniel A Hashimoto,Amin Madani,Rajat Deo,Sameed Ahmed M. Khatana,Gary E. Weissman,Lyle Ungar,Eric Wong
### Background
随着大规模语言模型（LLMs）在知识密集型领域（如手术、天文学、心理治疗等）的应用，用户不仅期待得到答案，还希望获得有意义的解释。这些领域的用户通常都是该领域的专家（如医生、天文学家、心理学家），他们需要的解释应反映出专家级别的推理过程。然而，当前的评估方案主要强调解释的可接受性和内部一致性，未能准确衡量解释内容是否真正符合专家直觉。
### Innovation
本文提出了T-FIX，这是一个涵盖七个知识密集型领域的基准测试，旨在将专家共识作为评估LLM解释的标准。研究人员与领域专家合作，开发了新的指标来衡量LLM解释与专家判断的契合度。
### Conclusion
T-FIX通过专家级别的准绳更好地评估了LLM提供的解释质量，使LLMs在知识密集型领域的应用更加可靠并符合实际需求。
## 228. `cs.CL` - 通过大规模训练和与云供应商方法进行基准测试提高放射学报告去标识化性能 [PDF](https://arxiv.org/pdf/2511.04079), [HTML](https://arxiv.org/abs/2511.04079)
### Authors
Eva Prakash,Maayane Attias,Pierre Chambon,Justin Xu,Steven Truong,Jean-Benoit Delbrouck,Tessa Cook,Curtis Langlotz
### Background
本研究旨在通过使用大规模标注数据集来增强基于变压器的模型的自动化去标识化能力，并将其与商业云供应商系统的保护患者信息（PHI）检测性能进行基准测试。该研究基于最先进的变压器基线去标识化管道，并在其上进行了微调，同时引入了额外的 PHI 类别（AGE）。
### Innovation
该研究采用了大规模多模态训练的数据集，提高了跨机构的一般化和鲁棒性。同时，通过合成 PHI 的生成确保了数据的实用性和隐私。研究中的模型在 PHI 检测方面超过了之前的学术和商业系统，并为安全临床文本处理建立了新的基准。
### Conclusion
基于多样性放射学数据集训练的基于变压器的去标识化模型在 PHI 检测方面优于之前的所有学术和商业系统，并确立了一个新的基准。
## 229. `cs.CL` - 徒手不换尿布：人类与AI生成的关于情绪词汇的关联 [PDF](https://arxiv.org/pdf/2511.04077), [HTML](https://arxiv.org/abs/2511.04077)
### Authors
Špela Vintar,Jan Jona Javoršek
### Background
人类对词语的联想是了解内部语义词汇的一个已知方法，但人类对词语提示的自发反应往往难以预测，因为这些反应可能受到个人经历、情感或个人认知风格的影响。形成看似不相关的概念之间的关联是创造力的驱动机制。本文对比了人类与大型语言模型在联想行为上的差异，特别是针对情绪色彩浓厚的词语，研究大语言模型是否能像人类一样生成联想。
### Innovation
研究对比了人类与大语言模型在生成与情绪色彩浓厚词汇的联想上的差异，发现两者联想的重叠程度中等，但大语言模型的联想趋向于放大刺激的情绪负载，且比人类的联想更可预测，更缺乏创造力。
### Conclusion
人类与大语言模型在联想行为上存在适度的重叠，但总体上而言，大语言模型生成的联想更倾向于放大刺激的情绪负载，且缺乏人类联想的创造力和自发性。
## 230. `cs.CL` - Plan of Knowledge: Retrieval-Augmented Large Language Models for Temporal Knowledge Graph Question Answering [PDF](https://arxiv.org/pdf/2511.04072), [HTML](https://arxiv.org/abs/2511.04072)
### Authors
Xinying Qian,Ying Zhang,Yu Zhao,Baohang Zhou,Xuhui Sui,Xiaojie Yuan
### Background
TKGQA旨在通过利用时间知识图谱（TKGs）中的事实信息来回答时间敏感的问题。虽然先前的研究已经使用预训练的TKG嵌入或图神经网络来注入时间知识，但它们未能完全理解时间约束的复杂语义信息。最近，大型语言模型（LLMs）取得了显著进展，得益于其强大的语义理解和推理泛化能力，但它们的时间推理能力仍然有限。LLMs容易出现虚构和知识匮乏的问题。
### Innovation
本文提出了Plan of Knowledge框架，包含一个对比度时间检索器，称为PoK。该框架通过将复杂的时间问题分解为预定义工件的子目标序列，作为中间指导，促进推理探索。同时，构建了一个时间知识存储（TKS），通过对比检索框架使模型能够选择性地从TKGs中检索语义和时间对齐的事实。结合结构化规划与时间知识检索，PoK有效地提高了时间推理的可解释性和事实一致性。实验结果表明，PoK显著提高了LLMs的检索精度和推理准确性，与最先进的TKGQA方法相比，最多提高了56.0%。
### Conclusion
通过结合结构化规划与时间知识检索，PoK框架显著提升了大规模语言模型在时间知识图谱问答中的解释性和事实一致性，实验结果证明其在多个基准TKGQA数据集上优于现有最好的方法。
## 231. `cs.CL` - 批量化提示抑制推理过程中的过度思考：批量化提示如何抑制推理模型中的过度思考 [PDF](https://arxiv.org/pdf/2511.04108), [HTML](https://arxiv.org/abs/2511.04108)
### Authors
Wenmo Qiu,Saurabh Srivastava
### Background
近期研究探索了批量提示作为策略来摊薄大语言模型（LLMs）推理成本。本文则进一步表明，批量提示能提供另一个尚未充分认识到的好处：它在大型推理模型（LRMs）进行多步推理时起到正则化作用。
### Innovation
文章揭示了批量提示不仅是一个提高吞吐量的优化策略，还是一个强大的推理时间正则化器，能够提高准确率同时显著减少推理所需令牌数量（3到5倍）。详细的行为分析表明，批量提示可以抑制过度思考，减少重复的自我修正语言，并引导更果断的答案。此外，研究还观察到批量推理中出现的一种集体效应：模型往往能够从早期的例子中提取模式，将其应用到后续更难的问题中。
### Conclusion
这些发现使批量提示超越了简单的吞吐量优化，成为大模型推理更高效、更可靠的一种正则化手段。
## 232. `cs.CL` - CantoASR：低资源粤语音节感知ASR-LALM协作框架 [PDF](https://arxiv.org/pdf/2511.04139), [HTML](https://arxiv.org/abs/2511.04139)
### Authors
Dazhong Chen,Yi-Cheng Lin,Yuchen Huang,Ziwei Gong,Di Jiang,Zeying Xie,Yi R.(May)Fung
### Background
自动语音识别（ASR）对于语言连通性至关重要，然而，由于注解数据有限、六个声调、声调连音、音调变化以及口音差异等问题，低资源粤语一直具有挑战性。现有ASR模型常常遭受高词错误率，而大型音频语言模型（LALMs）尽管能够拓展上下文推理，但仍然需要明确的声学声调和音节音调线索。
### Innovation
本文介绍了一种名为CantoASR的ASR-LALM错误修正框架，该框架结合了强制对齐以提取声学特征，LoRA微调后的Whisper以提高声调识别能力，以及指令微调后的Qwen-Audio以进行韵律感知修正。实验结果表明，该方法在自发粤语数据上的字符错误率显著优于Whisper-Large-V3。这些结果表明，将声学线索与LALM推理结合是一种可扩展的策略，在资源有限的音调和方言ASR领域具有潜力。
### Conclusion
本研究通过将声学线索与LALM推理结合起来，为低资源音调和方言ASR提供了一种可扩展的方法，其在粤语ASR领域的应用显示出显著的效果。
## 233. `cs.CL` - 极限环境下列表语言识别的特性描述 [PDF](https://arxiv.org/pdf/2511.04103), [HTML](https://arxiv.org/abs/2511.04103)
### Authors
Moses Charikar,Chirag Pabbaraju,Ambuj Tewari
### Background
本研究探讨了无限序列中的语言识别问题，即给定目标语言的序列实例，学习者需输出一系列猜测，确保在某个有限时间之后的所有猜测都是正确的。传统的研究表明，对于大多数有趣的语言集合，语言识别在极限状态下是不可能完成的。阿金林后来给出了在某些特定情况下这个任务可以完成的精确描述。在此基础上，研究者借鉴了语言生成领域的最新进展，重新探讨了给学习者增加每步可以给出k个猜测的权利的情况下的经典语言识别问题。
### Innovation
基于阿金林描述单个猜测情况的递归版本，本文给出了可以在极限状态下进行k列表语言识别的语言集合的精确描述，并揭示了语言识别与识别能力的递归分解之间的概念性关联。此外，本文还研究了统计背景下输入作为支持某语言集合的分布中的i.i.d.流情况下的列表识别速率，发现若语言集合在极限下是k列表可识别的，则该集合以指数速率k列表可识别，并且这是最优的。若集合不在极限下k列表可识别，则任何趋于零的速率都无法实现。
### Conclusion
语言集合可以在极限下k列表识别的条件是该集合可以被分解为k个可以在极限下识别的语集合。进一步地，证明了如果集合以k列表可识别，则其以指数速率进行，这是最好的结果；如果集合不以k列表可识别，则任何趋零速率都无法识别。
## 234. `cs.CL` - RIDE: 使用项目反应理论演化难度的对抗性问题重写框架用于数学推理 [PDF](https://arxiv.org/pdf/2511.04120), [HTML](https://arxiv.org/abs/2511.04120)
### Authors
Xinyuan Li,Murong Xu,Wenbiao Tao,Hanlun Zhu,Yike Zhao,Jipeng Zhang,Yunshi Lan
### Background
大型语言模型在数学推理方面表现出色，但这往往是因为训练数据泄露或表面模式匹配，而非真正的推理能力。当前的基于规则的对抗性扰动方法往往生成不恰当的问题，并妨碍系统性评估问题的难度和基准的演进。为了填补这一空白，我们提出了一种基于项目反应理论（IRT）的新颖对抗性问题重写框架RIDE，它可以严谨地测量问题的难度，并生成更具挑战性的、良好的问题变体。我们使用35个大型语言模型模拟学生，并从他们的回答中构建了一个难度排名器。这个排名器在强化学习中提供奖励信号，并指导一个问题重写模型将现有的问题重新表述为不同难度水平的问题。对具有竞争性的数学基准进行应用，生成了扰动版本，这些版本削弱了高级大语言模型的性能，实验显示，26个模型的平均性能下降了21.73%，从而揭示了数学推理中的有限鲁棒性，并验证了我们评价方法的有效性。
### Innovation
提出了RIDE，一种新颖的对抗性问题重写框架，它利用项目反应理论（IRT）来严格测量问题难度并生成更具挑战性的问题变体，解决了目前方法中的问题，并提供了系统性评估问题难度和基准进化的手段。通过强化学习的奖励信号和模拟能力，RIDE能够生成具有不同难度级别的扰动版本的数学问题，从而揭示高级LLM在数学推理上的局限性。
### Conclusion
RIDE能够生成能够挑战高级LLM的数学问题版本，揭示了数学推理的鲁棒性有限性，证明了该框架的有效性，并为评估深度模型的数学推理能力提供了一种新的方法。
## 235. `cs.CL` - 可信的LLM中介通信：在多种应用领域评估LLM作为通信中介(LAAC框架)的信息准确性 [PDF](https://arxiv.org/pdf/2511.04184), [HTML](https://arxiv.org/abs/2511.04184)
### Authors
Mohammed Musthafa Rafi,Adarsh Krishnamurthy,Aditya Balu
### Background
人工智能生成内容的普及导致了一种荒诞的交流剧场，在这种剧场中，发送者利用大型语言模型（LLMs）使简单想法变得冗长，接收者则使用LLMs将其压缩回摘要。这种过程使得双方都不接触真实的交流内容。此背景下提出了一种新的框架——LLM作为通信中介（LAAC），旨在通过结构化的对话捕捉发送者的意图，并促进接收者的真实知识交流。但部署可信的LLM作为通信中介仍需解决关于信息保真度、一致性和可靠性的关键问题。研究者通过多用途场景的实验评估了LAAC在这些信任维度的表现，揭示了在高风险交流场景中可靠部署LAAC前仍需解决的测量信任差距。
### Innovation
提出了LAAC框架，通过结构化对话捕捉发送者的意图，并促进接收者的真实知识交流，旨在减少因AI生成内容而产生的虚假交流。研究设计了多方面的信任评估，包括信息捕捉保真度、重现性和查询响应完整性，以确保LLM作为沟通中介的有效性与可靠性。
### Conclusion
尽管建立了LAAC框架评估了其信任维度的表现，研究发现仍存在可测量的信任差距，有待进一步解决。在高风险的交流场景中可靠部署LAAC之前，必须解决这些差距。
## 236. `cs.CL` - BAPPA: 评估代理、计划和管道以实现自动文本到SQL生成 [PDF](https://arxiv.org/pdf/2511.04153), [HTML](https://arxiv.org/abs/2511.04153)
### Authors
Fahim Ahmed,Md Mubtasim Ahasan,Jahir Sadik Monon,Muntasir Wahed,M Ashraful Amin,A K M Mahbubur Rahman,Amin Ahsan Ali
### Background
文本到SQL系统提供了一个自然语言界面，允许用户通过查询数据库来访问存储的信息，即使是没有技术背景的用户也能使用。然而，现有的大型语言模型（LLM）在从自然语言指令生成SQL查询方面遇到了困难，主要是由于数据库模式的规模庞大和复杂性的需求。现有的研究工作通常集中在复杂的、不那么实用的工作流上，而一些更小更高效的模型则被忽略了。因此，本文研究了三种多代理LLM工作流，对小到大的开源模型进行了系统性能基准测试，以探索如何改善这些模型的SQL生成能力。
### Innovation
本文探索了三种多代理LLM工作流：(1) 多代理讨论工作流，其中多个代理迭代地评论和改进SQL查询，最终由评审员合成答案；(2) 计划者-编码员工作流，其中思维模型计划生成逐步SQL生成计划，而编码器则合成查询；(3) 编码员-聚合器工作流，其中多个编码员独立生成SQL查询，然后由推理代理选择最佳的查询。通过在Bird-Bench Mini-Dev数据集上的实验发现，多代理讨论工作流能够提高小型模型的性能，尤其是在某些特定的小模型（如Qwen2.5-7b-Instruct）上能够达到10.6%的执行准确性提升。而LLM推理器-编码员工作流显示出了最好的结果，通过DeepSeek-R1-32B和QwQ-32B计划者，Gemma 3 27B IT的准确性从52.4%提升到了最高的56.4%。
### Conclusion
本文通过系统性的性能基准测试对三种多代理LLM工作流进行了研究，证实了多代理讨论工作流能够有效提升小型模型的SQL生成能力，并且LLM推理器-编码员工作流能够达到最佳效果。同时，本文公开了相关代码，以便进一步的研究使用。
## 237. `cs.CL` - 基于计算图灵测试揭示人与AI语言的系统性差异 [PDF](https://arxiv.org/pdf/2511.04195), [HTML](https://arxiv.org/abs/2511.04195)
### Authors
Nicolò Pagan,Petter Törnberg,Christopher A. Bail,Anikó Hannák,Christopher Barrie
### Background
大型语言模型（LLMs）在社会科学中被广泛用于模拟人类行为，基于它们能够生成类似人类的文本这一假设。然而，这一假设尚未经过充分验证。现有的验证方法主要依赖于人类判断，测试人类是否能区分AI和人类的输出，这显示出该评价方法粗糙且不可靠。因此，缺乏有力工具来评估LLM生成文本的真实性和校准模型以符合现实数据的能力。
### Innovation
本文介绍了计算图灵测试：一种验证框架，将聚合指标（如BERT检测能力和语义相似度）与可解释的语言特征（如风格标志和主题模式）相结合，评估LLM在特定数据集中如何接近人类语言。此外，论文系统地比较了九个开放参数LLM在五种校准策略（包括微调、定向提示和上下文检索）下的表现，衡量它们再现用户在X、Bluesky和Reddit的交互能力。研究结果挑战了文献中的核心假设。即使经过校准，LLM输出仍能明显区别于人类文本，特别是在情绪色彩和情感表达方面。指令微调模型的表现不如基础模型，模型规模的扩大也不一定能提高人类拟真度。研究表明，优化人类拟真度往往以牺牲语义保真度为代价，反之亦然。这些结果提供了一个急需的评估和校准框架，并提醒我们当前LLM模拟人类通信能力的局限性。
### Conclusion
研究结果表明，需要一个可扩展的验证和校准框架来评估和校准LLM模拟，并警告了现有模型在捕捉人类交流方面的局限性。
## 238. `cs.CL` - LLM-as-a-Judge is Bad, Based on AI Attempting the Exam Qualifying for the Member of the Polish National Board of Appeal [PDF](https://arxiv.org/pdf/2511.04205), [HTML](https://arxiv.org/abs/2511.04205)
### Authors
Michał Karp,Anna Kubaszewska,Magdalena Król,Robert Król,Aleksander Smywiński-Pohl,Mateusz Szymański,Witold Wydmański
### Background
本研究通过实证分析，评估当前大型语言模型（LLMs）是否能在波兰国家上诉院（Krajowa Izba Odwoławcza）成员资格考试中通过。文章探讨了两种相关概念：将模型作为实际考试应试者，并采用“LLM作为法官”的方法，其中模型生成的答案由其他模型自动评估。
### Innovation
研究人员测试了包括GPT-4.1、Claude 4 Sonnet和Bielik-11B-v2.6在内的几种LLM，在闭卷和不同的检索增强生成设置中。构建了一个混合信息恢复和提取管道支持模型，并采用了“LLM作为法官”的方法来评估模型答案。
### Conclusion
尽管模型在公共采购法律知识测试中取得了令人满意的分数，但没有达到实际写作部分的及格标准，且“LLM作为法官”的评估经常与官方审核委员会的判断存在分歧。作者指出，当前的LLM在解决幻觉、不正确的法律引用、逻辑论证弱点以及法律专家和技术团队之间的密切合作方面存在重要限制。研究结果表明，尽管技术进步迅速，当前的LLMs尚未能在波兰公共采购裁决中取代人类法官或独立考官。
## 239. `cs.CL` - 通过图基归标签高效提取主题：一种深度模型的轻量级替代方案 [PDF](https://arxiv.org/pdf/2511.04248), [HTML](https://arxiv.org/abs/2511.04248)
### Authors
Salma Mekaoui,Hiba Sofyan,Imane Amaaz,Imane Benchrif,Arsalane Zarghili,Ilham Chaker,Nikola S. Nikolov
### Background
从文本中提取主题已变得至关重要，尤其是在大量未结构化文本数据激增的背景下。现有的大多数方法依赖于高度计算密集型的方法来应对这一挑战。然而，我们认为概率和统计方法，如主题建模（TM），可以提供资源消耗较少的有效替代方案。
### Innovation
本文提出了一种基于图的标签化方法，旨在为现有主题模型中的主题词赋予有意义的标签，并通过探索主题词之间的关系来进一步丰富这些标签。通过这种方法，我们避免了依赖于复杂和计算密集型的模型，而该方法在两个不同数据集上与基准模型进行比较时，显示出了良好的性能。
### Conclusion
本方法在BERTScore和余弦相似度方面稳步优于传统基准模型，且在计算效率方面可与ChatGPT-3.5相比。未来的研究方向包括提高主题标签的可解释性和自动化程度。
## 240. `cs.CL` - 动态联合批选择以实现高效机器翻译微调 [PDF](https://arxiv.org/pdf/2511.04406), [HTML](https://arxiv.org/abs/2511.04406)
### Authors
Mohammad Amin Ghanizadeh,Mohammad Javad Dousti
### Background
数据质量和有效选择对于提高机器翻译模型性能至关重要，是实现稳健可靠的翻译系统的基础。论文提出了一种针对机器翻译系统微调的数据选择方法，该方法利用学习模型和预训练参考模型之间的协同作用来提升整体训练效果。通过对数据点的学习能力和相关性进行系统评估，确保仅选取最相关和有影响力的实例参与微调过程，以此提高数据利用效率.
### Innovation
该方法通过定义学习性评分，系统评估训练数据点的有用性。采用批选择策略考虑数据点之间的相互依赖关系，优化训练效率，同时保持对数据相关性的关注。实验结果显示，与IID基线相比，该方法在英波以及其他语言对上的mBART模型微调中表现出了五倍的数据效率提升。同时，使用缓存嵌入时，该方法通过减少需要的训练数据点数量提高了计算效率，并通过增强泛化能力，实现了比随机选择更好的翻译性能.
### Conclusion
实验结果表明，该方法在数据效率、计算效率、泛化能力和翻译表现方面均优于现有方法，展示了其在机器翻译微调中的有效性。
## 241. `cs.CL` - 概率文本时间序列抑郁检测 [PDF](https://arxiv.org/pdf/2511.04476), [HTML](https://arxiv.org/abs/2511.04476)
### Authors
Fabian Schmidt,Seyedehmoniba Ravan,Vladimir Vlassov
### Background
准确且可解释的抑郁严重程度预测对于临床决策支持至关重要，但现有的预测模型通常缺乏时间建模和不确定性估计。现有的文本模型在临床访谈时间序列数据中预测PHQ-8评分时，往往无法提供可靠的不确定性估计和时间分析。
### Innovation
我们提出了PTTSD（概率文本时间序列抑郁检测），这是一种框架，可以从单个访谈文本预测PHQ-8评分，并通过时间建模来估计不确定性。PTTSD模型包括序列到序列和序列到一元两种变体，都结合了双向LSTM、自注意力机制、残差连接以及使用负对数似然进行训练的高斯或学生t分布输出头，这种方法在时间序列文本数据上能够提供更为准确和可靠的预测结果。
### Conclusion
PTTSD在E-DAIC和DAIC-WOZ数据集上的性能优于其他仅基于文本的系统，能够提供准确和校准良好的预测区间，并且通过消融实验和与MentalBERT的比较，验证了自注意力机制和概率建模的价值。通过多步骤校准分析和定性案例研究，进一步表明了不确定预测增强的临床意义和解释性。
## 242. `cs.CL` - SSPO: 句子层次的策略优化 [PDF](https://arxiv.org/pdf/2511.04256), [HTML](https://arxiv.org/abs/2511.04256)
### Authors
Kun Yang,Zikang chen,Yanmeng Wang,Zhigen Li
### Background
在大型语言模型（LLMs）的后训练过程中，可验证奖励的强化学习（RLVR）已经显著提升了LLMs的推理能力。然而，一些RLVR算法，如GRPO和GSPO，由于策略更新不稳定和采样数据利用率低的问题而表现出较差的效果。GRPO在标记级上计算重要比例，专注于优化单个标记，容易受到异常值的影响，导致模型训练崩溃。GSPO在响应级上计算重要比例，解决了GRPO重要比例计算的高方差和训练噪声累积问题，但所有响应标记共享同一重要比例，极端值容易影响整体均值，导致响应整体被错误地舍弃，减少了采样数据的利用率。
### Innovation
本论文提出了SSPO（句子层次的策略优化），通过在句子层次计算重要比例，平衡了GRPO和GSPO的优点，避免了培训崩溃和高方差，同时通过剪辑机制防止整个响应标记被舍弃。此外，通过文献熵调整PPO-CLIP中的剪辑边界，激励高文献熵标记进行探索并限制低文献熵标记的剪辑范围。SSPO在五个数据集上的平均得分为46.57，超过了GRPO（43.01）和GSPO（44.42），在三个数据集上获得了最先进的性能，这表明SSPO在利用生成数据方面具有有效性。
### Conclusion
本研究通过知识的整合，提出了一种新的课题优化算法SSPO，有效地保障了训练的鲁棒性，提高了模型的性能。实验结果表明，SSPO在广泛应用中展现出显著的优势，证明了其在处理大型语言模型后训练问题中的有效性和重要性。
## 243. `cs.CL` - 如果我能回到过去：通过历史推理任务让LLMs进行时间重塑 [PDF](https://arxiv.org/pdf/2511.04432), [HTML](https://arxiv.org/abs/2511.04432)
### Authors
Lars Bungum,Charles Yijia Huang,Abeer Kashar
### Background
该研究旨在探究大规模语言模型（LLMs）在时间推理方面的能力。研究者使用一本1940年的挪威书籍中的琐事问题，要求LLMs从1940年的视角解答这些问题。研究还使用英语和挪威语两种语言提出问题，并通过LLM作为评判者的方式进行评分，部分评分由母语者抽查进行验证。结果显示，使用英语提问比使用挪威语效果更佳，这出乎了研究者的预料。研究还对比了不同规模的LLM模型，发现使用更大规模的模型能够提升问题解答的效果。研究还测试了DeepSeek-R1、Gemma3、Qwen3和Llama3.1等模型系列以及专门为挪威语定制的最大可用LLM。
### Innovation
研究采用了历史推理任务来探索LLMs的时间推理能力。研究创新之处在于使用了一本1940年的挪威书籍中的琐事问题，要求模型从1940年的视角进行回答，并且发现使用英语提问比使用挪威语效果更佳，这是一个意外的结果。此外，研究还对比了不同规模的LLM模型，并且测试了专门为挪威语定制的最大可用LLM。
### Conclusion
研究发现，使用英语提问与更大规模的LLM模型能够提升LLM在时间推理任务中的表现。这表明，虽然语言的差异可能会影响模型的表现，但模型规模的增加有助于改善模型的理解与推理能力。未来的研究可以进一步探讨不同语言环境下的模型表现，并探索其他的优化方法来提升LLM的时间推理能力。
## 244. `cs.CL` - ThaiOCRBench：泰语视觉语言理解任务多样化的基准 [PDF](https://arxiv.org/pdf/2511.04479), [HTML](https://arxiv.org/abs/2511.04479)
### Authors
Surapon Nonesung,Teetouch Jaknamon,Sirinya Chaiophat,Natapong Nitarach,Chanakan Wittayasakpan,Warit Sirichotedumrong,Adisai Na-Thalang,Kunat Pipatanakul
### Background
尽管在多模态建模方面取得了进展，现有的基准主要集中在高资源语言上，泰语则被严重忽视，尤其是在需要文档结构理解的任务中。为了解决这一问题，ThaiOCRBench 提供了一个包含 2,808 个样本的多样化、人工标注的数据集，涵盖 13 个任务类别，用于评估各种最先进的视觉语言模型在零样本设置下的表现。结果显示出显著的性能差距，私有模型相较于开源模型表现更佳。通过详细的错误分析，识别出语言偏差、结构不匹配和虚构内容等关键挑战。这是一个为低资源、书写系统复杂的环境评估视觉语言模型的标准框架，并提供了提高泰语文档理解的行动指南。
### Innovation
ThaiOCRBench 是第一个全面评估视觉语言模型（VLMs）在泰语文本丰富视觉理解任务上的基准；提供了一个多样化的数据集，包含 2,808 个样本和 13 个任务类别；评估了多种最先进的 VLMs 在零样本环境下的性能；通过详细的错误分析，识别出关键挑战并提供了改进泰语文档理解的指导。
### Conclusion
ThaiOCRBench 提供了标准框架来评估视觉语言模型在低资源、复杂书写系统环境中的性能，并通过实际分析提供了改进泰语文档理解的关键洞察。
## 245. `cs.CL` - OUNLP在TSAR 2025共享任务中的表现：通过代码生成的多轮文本简化器 [PDF](https://arxiv.org/pdf/2511.04495), [HTML](https://arxiv.org/abs/2511.04495)
### Authors
Cuong Huynh,Jie Cao
### Background
本文描述了提交给2025年TSAR共享任务（Alva-Manchego等人，2025年）的OUNLP系统，该系统使用基于LLM提示的生成方法来进行可读性控制的文本简化。通过分析基于提示的文本简化方法，我们发现文本简化的效果高度依赖于源CEFR水平与目标CEFR水平之间的差距。
### Innovation
基于上述发现，我们提出了两种多轮简化方法并使用GPT-4o生成它们：基于规则的简化（MRS-Rule）和联合基于规则的LLM简化（MRS-Joint）。通过把这些理想的方法运用到系统中，我们的提交系统在20个团队中排名第7。进一步改进后的MRS-Joint方法显示，以LLM简化候选文本为起点可以进一步提高多轮简化的效果。
### Conclusion
与基于规则的简化方法相比，将LLM简化候选文本作为起点可以显著提升多轮简化效果，因此，该方法展示了在基于LLM的文本简化系统中的实际改进和应用潜力。
## 246. `cs.CL` - 测试时重用预训练数据是计算倍增器 [PDF](https://arxiv.org/pdf/2511.04234), [HTML](https://arxiv.org/abs/2511.04234)
### Authors
Alex Fang,Thomas Voice,Ruoming Pang,Ludwig Schmidt,Tom Gunter
### Background
大语言模型通过其庞大的预训练语料库学习，能够解决越来越多的任务；尽管研究人员致力于改进这些数据集，但很少有努力去理解预训练架构从数据中提取思想和知识的效率。本文利用检索增强生成和测试时的计算，以量化预训练过程中被遗留的数据集价值，以及随规模变化的情况。研究表明，使用标准并且主要开源的数据集进行预训练和检索能够显著提高MMLU、Math-500和SimpleQA的数据准确性，且这种效果在去污染后仍然存在。对于MMLU，我们发现检索可以作为一种约5倍的计算倍增器，将预训练效果翻倍。我们进一步通过在测试时间利用额外的计算能力来解析检索出的上下文，使得公共LLaMA 3.1 8B模型在MMLU上的准确率提高了10个百分点。
### Innovation
本文引入了测试时利用已有的预训练数据来计算，提出检索增强生成的方法，实现了数据集价值的量化评估，并展示了这种方法在MMLU、Math-500和SimpleQA等任务上的显著优势。特别是，检索可以显著提高模型在MMLU等任务上的准确性，并且通过利用更多的计算资源来解析检索出的上下文，进一步提升了模型的性能。
### Conclusion
当前的预训练方法未能充分利用现有预训练数据中的信息，仍然存在改进的空间。通过测试时重用数据，可以显著提升模型的性能，表明预训练数据中有大量的未利用价值。
## 247. `cs.CL` - 在大型语言模型中解码涌现的五大人格特质：温度依赖的表达与架构聚类 [PDF](https://arxiv.org/pdf/2511.04499), [HTML](https://arxiv.org/abs/2511.04499)
### Authors
Christos-Nikolaos Zacharopoulos,Revekka Kyriakoglou
### Background
随着大型语言模型（LLMs）在人类中心应用中的重要作用日益突出，理解它们的人格特征行为对负责任的发展和部署变得越来越重要。本研究系统评估了六种LLMs，并采用五大人格特质问卷（BFI-2）框架，评估其在不同采样温度下的特质表达情况。
### Innovation
研究通过应用采样温度的调整，系统性地评估了六种大型语言模型在五大人格特质（Nearoticism、Extraversion等）上的表现差异，揭示了特定模型对温度调整的敏感性，并通过层次聚类分析发现了模型的聚类模式，提供了对模型调优、选择及其AI系统伦理治理的新视角。
### Conclusion
研究结果显示，这六种LLMs在四个个性维度上表现出显著差异，尤其是神经质和外向性受温度调整影响较大。层级聚类分析还揭示了不同的模型类别，表明架构特征可能预置对稳定特质模式的倾向。这些结果为深入了解大型语言模型中涌现的人格特征模式提供了新见解，并提供了一种新的模型调优、选择及AI系统伦理治理的视角。
## 248. `cs.CL` - RUST-BENCH：在结构化表格内对LLM推理进行基准测试 [PDF](https://arxiv.org/pdf/2511.04491), [HTML](https://arxiv.org/abs/2511.04491)
### Authors
Nikhil Abhyankar,Purvi Chaurasia,Sanchit Kabra,Ananya Srivastava,Vivek Gupta,Chandan K. Reddy
### Background
现有的表格推理基准通常测试模型在较小且均匀的表格上，无法代表现实世界数据的复杂性，未能充分反映大型语言模型（LLMs）的推理能力。现实中的表格数据既长又异构，且具有领域特定性，涉及结构化字段与自由文本的混合，需要在数千个标记间进行跨步推理。
### Innovation
RUST-BENCH 是一个包含 7966 个问题的基准，这些问题来自 2031 张真实世界的表格。它涵盖了两个领域：i) RB-Science（NSF 奖项记录）和 ii) RB-Sports（NBA 数据统计）。与其他研究不同，RUST-BENCH 联合评估了 LLM 在规模、异构性、领域特异性和推理复杂性方面的表现。实验结果表明，LLMs 在异构模式和复杂跨步推理方面存在困难，揭示了当前架构中的持续弱点，推动了策略调整。
### Conclusion
RUST-BENCH 建立了一个新的具有挑战性的测试环境，用于促进表格推理研究的进展。
## 249. `cs.CL` - REMIND: 输入损失景观揭示后卸载LLM中的残余记忆 [PDF](https://arxiv.org/pdf/2511.04228), [HTML](https://arxiv.org/abs/2511.04228)
### Authors
Liran Cohen,Yaniv Nemcovesky,Avi Mendelson
### Background
机器卸载的目标是通过移除特定训练数据的影响，而不需要对模型进行全面重新训练。这种能力对于确保隐私、安全和合规至关重要。因此，验证模型是否真的忘记了目标数据对于保持可靠性和可信度至关重要。然而，现有的评估方法通常仅在单个输入级别评估遗忘情况，这可能会忽略语义上相似的示例中存在的残留影响。这种影响可能削弱隐私并导致间接信息泄露。
### Innovation
本文提出了一种名为REMIND（残余记忆在邻域动态中的检测）的新型评估方法，旨在检测未学习数据的微弱剩余影响，并区分数据是否已有效遗忘。REMIND通过分析模型在小输入变化下的损失情况，揭示了单点评估所忽视的模式。未学习的数据会导致更平坦、更平缓的损失景观，而保留或无关的数据则表现出更尖锐、更波动的模式。REMIND仅需基于查询的访问，其性能在类似条件下优于现有方法，并且在不同的模型、数据集和重新表述输入中表现出了稳健性，使其适用于实际部署。REMIND提供了一种更灵敏和可解释的卸载有效性度量，为评估语言模型的卸载提供了一个可靠的框架。
### Conclusion
REMIND为评估具有卸载功能的语言模型卸载效果提供了一个新的视角，并为解决遗忘和记忆问题提供了可靠的框架。
## 250. `cs.CL` - IntelliProof：基于论辩网络的对话辅助器，用于系统的反思 [PDF](https://arxiv.org/pdf/2511.04528), [HTML](https://arxiv.org/abs/2511.04528)
### Authors
Kaveh Eskandari Miandoab,Katharine Kowalyshyn,Kabir Pamnani,Anesu Gavhera,Vasanth Sarathy,Matthias Scheutz
### Background
 Existing automated essay scoring systems primarily focus on surface-level text analysis, lacking comprehensive analysis of the argumentative structure and the user experience. The paper addresses this gap by introducing a new system, IntelliProof, which aims to enhance understanding and evaluation of argumentative essays through the use of LLMs and an argumentation graph.
### Innovation
 IntelliProof 利用 LLMs 对论点进行分类和评分，然后通过可视化增强理解。该系统提供分析分类的依据并产生有关文章连贯性的定量指标。此外，它提供一组工具，有助于更好地理解论辩性文章及其对应的图，填补了论辩性文章的结构语义与用户理解之间的鸿沟。
### Conclusion
IntelliProof 为用户提供了快速探索论辩质量的能力，同时保留了人工监督，而且还提供了工具来增强对论辩性文字的理解。该系统已通过 live demo 开放供体验：[点击这里](this https URL)。
## 251. `cs.CL` - 构建放射报告中的临床不确定性模型：从明示不确定性标记到隐含推理路径 [PDF](https://arxiv.org/pdf/2511.04506), [HTML](https://arxiv.org/abs/2511.04506)
### Authors
Paloma Rabaey,Jong Hak Moon,Jung-Oh Lee,Min Gwan Kim,Hangyul Yoon,Thomas Demeester,Edward Choi
### Background
放射报告在临床决策中具有很高的价值，并且在结构化为机器可读格式时具有巨大的自动化分析潜力。但报告中常包含不确定性，这种不确定性可分为两种类型：（一）明示不确定性，即对发现存在或不存在的怀疑，通过规避语句表达出来，其含义因上下文而异；（二）隐含不确定性，即放射科医生省略了部分推理过程，仅记录关键发现或诊断，导致删减的结果是实际不存在还是因为未提及不清楚。
### Innovation
该研究提出了一种两步框架，首先通过专家验证和语言模型（LLM）构建明示不确定性的量化方法，其次通过扩展模型建模隐含不确定性。具体而言，通过参考常见的规避语句专家验证的排名，将每个发现映射到一个基于此参考的概率值。此外，他们通过系统地添加从专家定义的14种常见诊断的诊断路径中衍生出来的典型子发现，创建了一个扩增和具有不确定性意识的Lunguage++基准数据集，该数据集支持不确定性意识的图像分类、忠实的诊断推理及对诊断不确定性临床影响的新研究。
### Conclusion
该工作通过对放射报告中的各种不确定性进行建模，发布了Lunguage++数据集，提高了对放射学报告中细微结构的自动化分析能力，有助于优化临床决策并进一步探索诊断不确定性对临床实践的影响。
## 252. `cs.CL` - 语言模型是否意识到未走的道路？token级不确定性与隐藏状态动态 [PDF](https://arxiv.org/pdf/2511.04527), [HTML](https://arxiv.org/abs/2511.04527)
### Authors
Amir Zur,Atticus Geiger,Ekdeep Singh Lubana,Eric Bigelow
### Background
在生成文本时，语言模型会对每个token进行选择，这可能会引导它们采取非常不同的推理路径，从而使得不确定性量化变得困难。研究表明，语言模型在推理过程中可能会考虑多种可能的路径，但如何量化和控制这些不确定性仍然是一个挑战。本研究旨在探索语言模型是否能够体现生成过程中它们能够采取的替代路径，以及如何通过控制其激活状态来预测模型的不确定性及其未来的可能结果。
### Innovation
研究通过利用隐藏激活来控制和预测语言模型在链式推理中的不确定性，发现模型在不同token上的不确定性与其可以通过控制激活状态被引导的程度之间存在明确的相关性。这表明，当模型还没有确定最终答案时，通过干预其激活状态是最有效的。此外，该研究还发现隐藏激活能够预测模型未来结果的分布，证明了模型在某种程度上体现了可能路径的空间。这些发现为理解和控制语言模型的不确定性提供了新的视角和技术手段。
### Conclusion
研究发现，语言模型在chain-of-thought推理过程中，其不确定性与可以通过控制其激活状态被引导的程度之间存在明显的相关性。这提示我们，当模型尚未完全确定最终答案时，通过干预其隐藏激活状态可以更好地控制和理解其不确定性。此外，隐藏激活还能够预测模型未来可能的结果分布，表明语言模型在内在地表示可能路径的空间。
## 253. `cs.CL` - RAGalyst：针对特定领域的RAG自动人本化代理评估 [PDF](https://arxiv.org/pdf/2511.04502), [HTML](https://arxiv.org/abs/2511.04502)
### Authors
Joshua Gao,Quoc Huy Pham,Subin Varghese,Silwal Saurav,Vedhus Hoskere
### Background
RAG（检索增强生成）是将大语言模型（LLM）与具体事实证据结合的关键技术，但在专业且安全性要求高的领域中评估RAG系统仍然面临巨大挑战。现有的评估框架通常依赖启发式指标，无法捕捉到领域内的具体差异，也有使用大模型作为评委的方法，但缺乏与人类判断的有效校准。本文在这方面的背景是为了提供一种系统性的自动人本化代理评估框架，以适应特定领域的RAG系统评估需求。
### Innovation
本文提出了一种名为RAGalyst的自动化人本化代理评估框架，用于严格评估特定领域的RAG系统。RAGalyst的特点是使用一个代理流程，生成高质量的合成问答数据集，同时通过代理过滤确保数据的准确性和真实性。此外，它还优化了两个关键的大语言模型作为评委指标——答案正确性和可回答性，能够在强关联人类注释的情况下进行改进。研究表明，RAG组件的表现高度依赖于上下文，没有一种嵌入模型、大语言模型或超参数配置可以普遍适用。在军事操作、网络安全和桥梁工程等三个行业领域的应用也显示出这一特性。此外，具体分析了RAG中最常见的答案不正确原因，突出了系统性评估框架的重要性，它能帮助从业者发现领域内的具体权衡并作出有信息的、有针对性的设计选择，以构建可靠且有效的RAG系统。
### Conclusion
我们的研究结果强调了系统性评估框架如RAGalyst的重要性，它可以帮助从业者发现领域内特有的权衡并做出明智的设计选择，从而构建可靠且有效的RAG系统。该框架已经开源，并在GitHub上提供。
## 254. `cs.CL` - 当检索胜过生成：用于可扩展虚假新闻检测的密集证据检索 [PDF](https://arxiv.org/pdf/2511.04643), [HTML](https://arxiv.org/abs/2511.04643)
### Authors
Alamgir Munir Qazi,John P. McCrae,Jamal Abdul Nasir
### Background
虚假信息的蔓延迫切需要强大且计算效率高的事实验证系统。当前最先进的方法利用大型语言模型（LLMs）生成解释性理由，但在实际部署中面临显著的计算障碍和虚构风险。本文探讨了一种轻量级框架DeReC（密集检索分类），通过结合密集检索和专门的分类，该系统在准确性和效率上表现更优。
### Innovation
DeReC 是一种轻量级框架，通过综合使用密集检索和专门分类，实现比自回归LLM基方法更高的准确性和效率。此外，DeReC 在实际部署中的执行时间显著减少，对于不同数据集大小展示了其有效性，特别是在 F1 分数上超越了当前最先进的方法 L-Defense。
### Conclusion
精心设计的基于检索的系统可以匹配甚至超越LLM在专门任务中的性能，同时在实际部署中更加实用。
## 255. `cs.CL` - Logit-Entropy 适应性停止启发式算法在高效链式思考推理中的应用 [PDF](https://arxiv.org/pdf/2511.04654), [HTML](https://arxiv.org/abs/2511.04654)
### Authors
Mohammad Atif Quamar,Mohammad Areeb
### Background
链式思考（Chain-of-Thought，CoT）提示是使大型语言模型能够实现复杂推理的关键技术。然而，生成完整且固定长度的理由需要大量的策略计算，这会增加令牌使用量和延迟。
### Innovation
本文引入了LEASH（Logit-Entropy Adaptive Stopping Heuristic），一种无需训练的解码算法，能够适应性停止理由生成。LEASH通过监测令牌级熵的斜率和顶级策略边际改进两个内在信号，在二者均出现停滞时终止生成。该算法在GSM8K和AQuA-RAT基准测试上，在四个指令调优模型上表现出出色的效果，平均减少了30-35%的令牌生成并降低了27%的延迟，同时相对于CoT牺牲了10个百分点的准确性。LEASH算法具有模型通用性且无需额外的训练或监督，提供了一种CoT解码的简单且高效替代方案。
### Conclusion
LEASH算法能够显著减少令牌生成和延迟，同时保持相对较高的准确性，为大型语言模型进行高效链式思考推理提供了一个简单且有效的选择。
## 256. `cs.CL` - 从模型到漏洞：迈向可操作的生成型LSTM漏洞报告 [PDF](https://arxiv.org/pdf/2511.04538), [HTML](https://arxiv.org/abs/2511.04538)
### Authors
Cyril Vallez,Alexander Sternfeld,Andrei Kucharavy,Ljiljana Dolamic
### Background
随着大型语言模型（LLM）在软件开发中的作用愈发重要，生成代码中出现的漏洞在整体网络安全中也变得越来越关键。目前，虽然提出了许多LLM代码安全基准并采用了改进生成代码安全性的方法，但这些措施对广泛使用的LLM代码安全性的影响尚不清楚。研究指出，即使是最新开源模型，在实际使用环境中最早报告的漏洞场景下也存在漏洞，这表明之前的漏洞防护措施并未有效解决漏洞问题。针对这一问题，本文引入了一个新的严重性度量（Prompt Exposure, PE），该度量能够反映由LLM生成的漏洞所带来的风险，结合漏洞严重性、生成概率和引发漏洞代码生成的提示形式。为了鼓励缓解最严重和最常见的漏洞，该研究使用PE定义了模型暴露（Model Exposure, ME）得分，表示模型生成的漏洞的严重性和普遍性。
### Innovation
本文提出了一个新的度量标准，即Prompt Exposure（PE），用于评估LLM生成的漏洞风险。同时定义了Model Exposure（ME）得分，根据PE来衡量模型生成漏洞的严重性和普遍性，为缓解这些漏洞提供了可操作的指导。
### Conclusion
研究展示了即使是最新的开源模型，目前仍然存在漏洞，特别是在实际使用环境中。为了解决这个问题，研究提出了一个新的度量标准和评分系统，以提高对LSTM网络安全漏洞防护的关注度和处理效率。
## 257. `cs.CL` - BanglaMedQA和BanglaMMedBench：评估用于孟加拉医学问答的检索增强生成策略 [PDF](https://arxiv.org/pdf/2511.04560), [HTML](https://arxiv.org/abs/2511.04560)
### Authors
Sadia Sultana,Saiyma Sittul Muna,Mosammat Zannatul Samarukh,Ajwad Abrar,Tareque Mohmud Chowdhury
### Background
在低资源语言中开发准确的生物医学问答系统仍然是一个重大挑战，这限制了可靠医疗知识的平等获取。目前缺乏专门针对低资源语言的大量生物医学多选题数据集，用于评估医疗人工智能中的推理和检索能力。该研究旨在填补这一空白，通过构建BanglaMedQA和BanglaMMedBench数据集来评估和基准测试几种检索增强生成（RAG）策略。
### Innovation
该研究引入了两种创新：一是通过光学字符识别（OCR）整合孟加拉医学教科书语料库；二是采用Agentic RAG管道，动态选择检索与推理策略。Agentic RAG在实验中达到了89.54%的准确率，优于其他配置，证明了其优秀的解释质量，展示了基于RAG的方法在孟加拉语医学问答领域的潜力。
### Conclusion
研究表明，基于RAG的方法可以提高孟加拉语医学问答的可靠性和可访问性，为未来多语言医疗人工智能的研究奠定了基础。
## 258. `cs.CL` - MIDI-LLM: 调整大型语言模型以进行文本到MIDI音乐生成 [PDF](https://arxiv.org/pdf/2511.03942), [HTML](https://arxiv.org/abs/2511.03942)
### Authors
Shih-Lun Wu,Yoon Kim,Cheng-Zhi Anna Huang
### Background
当前，存在一种名为Text2midi的模型，用于将自由形式的文本提示生成多声道MIDI音乐。然而，该模型在质量、文本控制和推理速度方面存在局限性。
### Innovation
MIDI-LLM 利用大型语言模型（LLM）扩展其词汇表以包括MIDI令牌，并采用两阶段训练方法赋予其从文本到MIDI的生成能力。通过保留原始LLM的参数结构，MIDI-LLM可以直接利用vLLM库加速推理过程。
### Conclusion
实验表明，与最近的Text2midi模型相比，MIDI-LLM在音乐质量、文本控制和推理速度上具有更高的性能。
## 259. `cs.CL` - MimiTalk：利用双代理AI重塑定性研究 [PDF](https://arxiv.org/pdf/2511.03731), [HTML](https://arxiv.org/abs/2511.03731)
### Authors
Fengming Liu,Shubin Yu
### Background
本文介绍了MimiTalk，这是一种针对社会科学研究中可扩展且合乎伦理的对话数据收集设计的双代理人工智能框架。框架整合了监管模型用于策略性监督和对话模型用于问题生成。为了评估该框架的有效性，作者进行了三项研究：第一项研究评估了20名参与者的工作效率；第二项研究将121次由MimiTalk生成的AI访谈与来自MediaSum数据集的1,271个人类访谈进行了比较，使用了自然语言处理（NLP）度量和倾向得分匹配的方法；第三项研究邀请了10位跨学科研究人员进行人类和AI访谈，随后进行了盲法主题分析。结果显示，MimiTalk减少了访谈焦虑，保持了对话连贯性，并在信息丰富度、连贯性和稳定性方面优于人类访谈。AI访谈激发了技术见解，而人类访谈更善于捕捉文化和情感方面的细微差别。这些发现表明，双代理宪法AI支持有效的人机协作，能够实现可复制、可扩展且质量控制的定性研究。
### Innovation
本文的创新在于提出了MimiTalk，这是一种结合了监管模型和对话生成模型的双代理人工智能框架，旨在实现大规模且合乎伦理的对话数据收集。通过三项研究，作者验证了该框架能够减少访谈者的焦虑，保证对话的连贯性，并在提供信息方面优于人类访谈，尤其在技术话题上的深度和敏感话题上的坦诚度方面。此外，MimiTalk还为定性研究提供了一种有效的人机协作方式，能够保障研究的可复制性和质量控制。
### Conclusion
MimiTalk双代理宪法AI框架在社会科学研究中的应用表明了其在提高访谈效率、减少访谈者焦虑、保证对话连贯性和信息丰富度方面的能力。该框架支持有效的人类和人工智能协作，为未来的定性研究提供了可靠的方法，有助于实现高质量、可复制的定性研究成果。
## 260. `cs.CL` - 不同标记化算法如何影响用于二进制代码分析的LLM和变换器模型 [PDF](https://arxiv.org/pdf/2511.03825), [HTML](https://arxiv.org/abs/2511.03825)
### Authors
Ahmed Mostafa,Raisul Arefin Nahid,Samuel Mulder
### Background
标记化是汇编代码分析的基础，影响词汇量、语义覆盖范围和下游任务性能等内在特性。尽管其重要性，汇编代码的标记化仍然是一个未充分研究的领域。本文旨在通过评估自然语言处理（NLP）标记化模型及其参数（如词汇量大小）的内在属性来填补这一空白。研究涉及多种标记化模型，并系统分析其在编码汇编指令和捕捉语义方面的效率。同时，评估这些模型对下游任务（如函数签名预测）的影响，这是二进制代码分析中的一个重要问题。
### Innovation
研究探索了符合汇编代码特点的预处理定制选项和预标记规则，并使用最先进的预训练模型（包括解码器大型语言模型Llama 3.2、解码器只变压器BERT和编码器-解码器模型BART）评估这些标记化模型的有效性。初步结果显示，标记化器的选择显著影响下游性能，内在指标可以部分预测外在评估结果，揭示了内在标记化器属性与其在低级代码任务中的适用性之间的复杂权衡。
### Conclusion
这项研究提供了有关优化用于低级代码分析的标记化模型的宝贵见解，推动了基于自然语言模型（NLM）的二进制分析工作流程的稳定性和扩展性。
## 261. `cs.CL` - LLMs and Cultural Values: the Impact of Prompt Language and Explicit Cultural Framing [PDF](https://arxiv.org/pdf/2511.03980), [HTML](https://arxiv.org/abs/2511.03980)
### Authors
Bram Bulté,Ayla Rigouts Terryn
### Background
大规模语言模型（LLMs）正在全球范围内被各类用户使用，并且这些用户使用多种语言与模型交互。然而，训练数据和优化目标中的不平衡问题引起了人们对LLMs能否准确反映其用户的文化多样性的担忧。本文探讨了LLMs和文化价值观之间的关系，研究了提示语言和文化框架如何影响模型响应及其与人类价值观的一致性。
### Innovation
文章通过探索单独或组合使用提示语言和显式文化框架，研究其对10个LLM的输出的影响。结果显示，虽然提示语言和文化框架可以有效地引导模型响应，但仍无法克服模型固有的偏见。此外，结合两种方法的效果并不优于单一文化视角加英语提示的方法。这些发现揭示了LLMs对于文化多样性的代表性的内在局限性。
### Conclusion
这些研究表明，尽管LLMs可以通过调整提示语言和文化视角来生成一些变化，但它们的输出仍受到特定文化默认设置的限制，难以全面准确地反映文化多样性。
## 262. `cs.CL` - 通过合成模型生成实现可解释模型的可扩展元学习 [PDF](https://arxiv.org/pdf/2511.04000), [HTML](https://arxiv.org/abs/2511.04000)
### Authors
Kyaw Hpone Myint,Zhe Wu,Alexandre G.R. Day,Giri Iyengar
### Background
决策树在金融和医疗等高风险领域广泛使用，由于其可解释性。已有研究表明，元学习可以通过利用历史数据的知识来改进模型性能，但通常需要大量的计算资源来实现最优的决策树模型。因此，文中提出了一种高效且可扩展的方法，用于生成合成预训练数据，以促进决策树的元学习。
### Innovation
文中提出了一种基于MetaTree变压器架构的方法，通过合成方式生成近最优的决策树，这种方法能够在大规模且真实的数据集上训练，从而实现与使用真实世界数据或计算成本高昂的最优决策树相比，保持接近的性能。该方法显著减少了计算成本，增强了数据生成的灵活性，为可解释决策树模型的大规模和高效元学习奠定了基础。
### Conclusion
所提出的方法显著提高了决策树模型的可解释性，同时降低了计算成本，增强了数据生成的灵活性，并且为大规模可调节的决策树模型元学习开辟了新的途径。
## 263. `cs.CL` - RLHF：文化、多模态及低延迟对齐方法的全面综述 [PDF](https://arxiv.org/pdf/2511.03939), [HTML](https://arxiv.org/abs/2511.03939)
### Authors
Raghav Sharma,Manan Mehta,Sai Tiger Raina
### Background
强化学习从人类反馈（RLHF）已经成为大规模语言模型（LLM）对齐的标准方法。尽管如此，最近的研究进展已经超越了传统的基于文本的方法。本文综述了对齐研究的最新前沿，特别是多模态对齐、文化公平性和低延迟优化等关键领域存在的不足之处。为了系统地探索这些领域，论文首先回顾了基础算法，如PPO、DPO和GRPO，然后深入分析了最新的创新方法。
### Innovation
文章提供了这些技术的比较性综述，并指出了开放性挑战，旨在为构建更稳健、高效和公平的人工智能系统的研究人员提供一个重要的指导框架。它集中于RLHF在文化和多模态对齐以及低延迟优化方面的新进展，填补了相关研究的空白。
### Conclusion
文章为研究人员在构建更多鲁棒、高效和公平的AI系统方面提供了一个重要的路线图，尤其关注了文化、多模态和低延迟对齐方法的新前沿。
## 264. `cs.CL` - DartQuant：高效旋转分布校准用于大语言模型量化 [PDF](https://arxiv.org/pdf/2511.04063), [HTML](https://arxiv.org/abs/2511.04063)
### Authors
Yuantian Shao,Yuanteng Chen,Peisong Wang,Jianlin Yu,Jing Lin,Yiwu Yao,Zhihui Wei,Jian Cheng
### Background
量化在加速大规模模型推理方面起着关键作用，旋转矩阵已被证明通过平滑异常值有效地提高量化性能。然而，旋转优化算法的端到端微调计算成本高，容易过拟合。
### Innovation
提出了一种高效分布感知旋转校准方法DartQuant，通过约束旋转后激活值的分布来降低旋转优化的复杂性。此外，引入了QR-Orth优化方案，以更高效的解决方案替代昂贵的交替优化。实验表明，DartQuant具有优越的性能，在70B模型上实现了47倍的加速和10倍的内存节省。
### Conclusion
DartQuant首次成功在单张3090 GPU上完成70B模型的旋转校准，使得在资源受限环境中进行大语言模型量化成为可能。
## 265. `cs.CL` - Pushdown自动机中的可探索性 [PDF](https://arxiv.org/pdf/2511.04048), [HTML](https://arxiv.org/abs/2511.04048)
### Authors
Ayaan Bedi,Karoliina Lehtinen
### Background
研究了可探索性，它是推down自动机中非确定性的度量，进一步推广了历史确定性。一个自动机在读取输入时，如果通过当前已读取输入基础上构建的k个并发运行步骤来构造一个接受运行（如果存在）就足以，称之为k-可探索。研究显示，可探索性PDAs类在表达能力和简洁性上介于历史确定性和完全非确定性的PDAs之间。提高可探索性能形成无限的有层次结构的分类，每一层定义了比上一层更强大的类，但整个类别仍然不等同于通用非确定性的PDAs。
### Innovation
引入了参数化的可探索性概念，其中运行的数量依赖于输入长度，并证明了指数级的可探索性精确捕捉了上下文自由语言。还证明，可探索性PDAs相比于历史确定性可以具有的指数级的简洁性，并且确定性和2-可探索性PDAs之间的简洁性差距不是递归可枚举的。
### Conclusion
研究将可探索性确立为推down系统中非确定性的稳健且操作上有意义的度量标准。
## 266. `cs.CL` - 在线词汇使用中的亚指数增长：分段幂律模型 [PDF](https://arxiv.org/pdf/2511.04106), [HTML](https://arxiv.org/abs/2511.04106)
### Authors
Hayafumi Watanabe
### Background
传统上，社会中思想和语言的扩散通常用S形模型，如逻辑斯蒂曲线来描述。然而，亚指数增长（一种比指数增长更慢的模式，在流行病学中已知）在更广泛的社会现象中往往被忽略。本文通过分析大约10亿篇日本博客文章，以及英语、西班牙语和日语的在线搜索趋势数据，研究了分段幂律模型来表征复杂的增长曲线。研究揭示了亚指数增长模式在整个社会扩散中的普遍性，并探讨了这一模式的参数与主题性质的关系。
### Innovation
本文提出了一个分段幂律模型来描述复杂增长曲线，仅使用少量参数。该模型揭示了亚指数增长而非指数增长模式在社会扩散中的普遍性，并提出一个微观行为模型来区分与陌生人的外部交流和在社区内的内部互动，这为人们理解社会扩散过程提供了一个新的视角。
### Conclusion
亚指数增长是一种社会扩散的常见模式，而该模型提供了一种描述、比较和解释复杂多样增长曲线的实用框架。
## 267. `cs.CL` - 直视前方：高效的文档方向检测 [PDF](https://arxiv.org/pdf/2511.04161), [HTML](https://arxiv.org/abs/2511.04161)
### Authors
Suranjan Goswami,Abhinav Ravi,Raja Kolla,Ali Faraz,Shaharukh Khan,Akash,Chandra Khatri,Shubham Agarwal
### Background
尽管在文档理解领域取得了显著进展，但确定扫描或拍摄文档的正确方向仍然是实际应用中的关键预处理步骤。准确的旋转校正是提高光学字符识别（OCR）等下游任务性能的关键，尤其是由于用户错误导致对齐不准确的情况，尤其是在拍摄过程中相机的初始方向不正确时更为常见。
### Innovation
本研究引入了OCR旋转基准（ORB），这是一个新的基准，用于评估OCR对图像旋转的鲁棒性，包括基于旋转变换的结构化和自由形态的英语OCR数据集构建的ORB-En，以及涵盖11种印度中期/低资源语言的新颖多语言数据集ORB-Indic。同时，研究提出了一种基于Phi-3.5-Vision视觉编码器的快速、鲁棒且轻量级旋转分类流水线，结合动态图像裁剪并在独立基础上进行特定于四类旋转任务的微调。方法在两个数据集上的旋转识别准确率分别达到了96%和92%。此外，研究还展示了该模块在提升OCR性能中的关键作用：封闭源OCR性能提高最多可达14%，开源权重OCR性能可提高4倍，在模拟实际环境下的效果显著。
### Conclusion
该方法在识别旋转方面表现出色，并在模拟的实际应用环境中显著提升了OCR性能，特别是在基于封闭源和开源权值的OCR模型上。
## 268. `cs.CL` - MXFP4量化所需的只是一个块旋转 [PDF](https://arxiv.org/pdf/2511.04214), [HTML](https://arxiv.org/abs/2511.04214)
### Authors
Yuantian Shao,Peisong Wang,Yuanteng Chen,Chang Xu,Zhihui Wei,Jian Cheng
### Background
大型语言模型（LLMs）取得了显著的成果，但其快速扩大的规模带来了内存、计算和能源方面的高额成本。后训练量化（PTQ）是有效部署的一种有前景的解决方案，但实现准确的W4A4量化仍然是一个开放的挑战。尤其是，虽然大多数现有方法专注于INT4格式，但MXFP4格式（一种新的FP4格式，获得NVIDIA、AMD和Intel硬件支持）的出现使得现有技术的应用性成为一个问题。鉴于此，本文建立了一个对MXFP4格式下的PTQ方法的综合基准，发现诸如GPTQ等方法表现强劲，但基于旋转的方法由于与MXFP4根本不同的功率分配模式而在完全不兼容问题上表现不佳。
### Innovation
本文提供了基于区块的旋转策略，适应了基于旋转的方法以适用于MXFP4格式，从而在不同类型的LLMs上显著提高了准确度。这种策略被认为是简单的却非常有效的，为PTQ研究在新兴低精度格式下的进步奠定了基础。
### Conclusion
本文的发现不仅为实践者提供了明确的指导，还为基础研究指明了方向，特别在MXFP4等新兴低精度格式下的PTQ研究方面。
## 269. `cs.CL` - 转型导师：布加大学指导的AI驱动聊天机器人方法 [PDF](https://arxiv.org/pdf/2511.04172), [HTML](https://arxiv.org/abs/2511.04172)
### Authors
Mashrur Rahman,Mantaqa abedin,Monowar Zamil Abir,Faizul Islam Ansari,Adib Reza,Farig Yousuf Sadeque,Niloy Farhan
### Background
大学学生在本科期间面临着巨大的挑战，经常缺乏导师无法大规模提供的个性化现场指导。虽然有数字工具存在，但对于初学者来说，定制化的指导仍然严重不足。
### Innovation
本文介绍了一个AI驱动的聊天机器人，旨在成为布加大学的学生导师。主要组件是一个高效的数据摄入管道，能够从多种来源（如CSV文件和大学网页）处理和更新信息。聊天机器人采用了结合BM25词汇排名和ChromaDB语义检索的混合方法来检索信息，并使用LLaMA-3.3-70B大型语言模型生成对话式回应。生成的文本在语义上非常相关，BERTScore为0.831，METEOR得分为0.809。数据管道也非常高效，更新数据仅需106.82秒，而新数据则需要368.62秒。通过聊天机器人，可以回答学生问题，帮助他们更好地理解大学生活，并协助他们更好地规划他们的学期安排，特别是在开放学分制度的大学中.
### Conclusion
该聊天机器人将能够帮助学生回答问题，更好地理解大学生活，并帮助他们更好地规划他们的学期。
## 270. `cs.CL` - 不确定性下的幻象：LLMs的不确定性量化在歧义下失效 [PDF](https://arxiv.org/pdf/2511.04418), [HTML](https://arxiv.org/abs/2511.04418)
### Authors
Tim Tomov,Dominik Fuchsgruber,Tom Wollschläger,Stephan Günnemann
### Background
当前的大语言模型（LLMs）中的不确定性量化（UQ）对于其可信部署至关重要，但现有的UQ方法通常是基于没有歧义的任务进行衡量的。现有的不确定性估计器在严格的无歧义假设下表现良好，但在歧义数据上则退化为近乎随机的表现。
### Innovation
引入了MAQA*和AmbigQA*，这是第一个带有基于事实共现估算的确切答案分布的歧义问答（AmbigQA）数据集。研究发现了不同的不确定性估计方法在这类数据上的表现一致性下降：使用预测分布本身、模型内部表示，以及模型的集成。证明了这种现象可以通过理论解释，并揭示了预测分布和集成估计器在歧义下的局限性。
### Conclusion
研究揭开了当前LLMs中的UQ方法的关键缺陷，并提出了需要重新思考当前建模范式的动机。
## 271. `cs.CL` - 黑盒护栏反向工程攻击 [PDF](https://arxiv.org/pdf/2511.04215), [HTML](https://arxiv.org/abs/2511.04215)
### Authors
Hongwei Yao,Yun Xia,Shuo Shao,Haoran Shi,Tong Qiao,Cong Wang
### Background
大型语言模型（LLMs）越来越多地采用护栏来确保其输出符合伦理、法律和具体应用的约束。虽然这些护栏有效遏制了有害的响应，但也引入了一类新漏洞，即可通过观察到的决策模式被逆向工程。本文研究了黑盒LLM护栏反向工程攻击，并提出了基于强化学习的Guardrail Reverse-engineering Attack（GRA）框架，利用遗传算法驱动的数据增强来近似受害护栏的决策策略。通过收集输入输出对，优先处理分歧情况，并执行有针对性的变异和交叉，该方法逐步逼近受害护栏的高度准确的替代品。
### Innovation
提出了一种基于强化学习的黑盒LLM护栏反向工程攻击（GRA）框架，利用遗传算法驱动的数据增强来近似受害护栏的决策策略。通过收集输入输出对、优先处理分歧情况以及执行有针对性的变异和交叉，该方法逐步逼近受害护栏的高度准确的替代品。该研究评估GRA在ChatGPT、DeepSeek和Qwen3三个广泛部署的商业系统上，证明其规则匹配率超过0.92，API成本不到$85。
### Conclusion
这些发现表明护栏提取的实际可行性，并突出当前LLM安全性机制的安全风险。研究结果揭示了当前护栏设计中的关键漏洞，并强调了LLM部署中更稳健防御机制的迫切需要。
## 272. `cs.CL` - 大型语言模型在博弈论实验中的合作行为复现与预测 [PDF](https://arxiv.org/pdf/2511.04500), [HTML](https://arxiv.org/abs/2511.04500)
### Authors
Andrea Cera Palatsi,Samuel Martin-Gutierrez,Ana S. Cardenal,Max Pellert
### Background
大型语言模型（LLMs）在健康、教育和法律等领域决策以及模拟人类行为方面被广泛应用。然而，LLMs在实际应用中如何与人类决策模式相符仍然了解不足。这种差距可能是致命的：不适当的对齐可能导致有害的后果，而不能复制人类行为使LLMs在社会模拟中无效。本研究填补了这一空白。
### Innovation
通过开发博弈论实验的数字孪生和引入系统化的提示与探究框架，对三种开源模型（Llama、Mistral和Qwen）进行测试，发现Llama在人类合作模式的复现方面高度忠实，能捕捉到人类与理性选择理论的偏差；Qwen则与纳什均衡预测值高度一致。特别地，该研究实现了群体层面行为的复现，不依赖于角色基础的提示，简化了模拟过程。此外，该研究还生成了可测试的关于新型博弈配置的假设，为探索未开发的实验空间提供了新的途径。
### Conclusion
适当校准的大型语言模型能够复现总体的人类行为模式，并为社会和行为科学的传统研究提供新的实证预测，有助于系统性探索未开发的实验空间。
## 273. `cs.CL` - 思考视频：视频生成作为有希望的多模态推理范式 [PDF](https://arxiv.org/pdf/2511.04570), [HTML](https://arxiv.org/abs/2511.04570)
### Authors
Jingqi Tong,Yurong Mou,Hangcheng Li,Mingzhe Li,Yongzhuo Yang,Ming Zhang,Qiguang Chen,Tianyi Liang,Xiaomeng Hu,Yining Zheng,Xinchi Chen,Jun Zhao,Xuanjing Huang,Xipeng Qiu
### Background
现有的'思考文字'和'思考图像'范式显著提高了大型语言模型（LLMs）和视觉语言模型（VLMs）的推理能力，但这些范式存在内在局限性，如图像仅能捕捉单一时刻，无法表示动态过程或连续变化；以及视觉和文本作为不同模态的分离，阻碍了统一的多模态理解和生成。
### Innovation
本文引入了'思考视频'的新范式，利用视频生成模型（如Sora-2）在统一的时间框架内连接视觉和文本推理，克服了上述局限性。为此作者构建了视频思考基准（VideoThinkBench），包含视觉中心任务和文本中心任务。
### Conclusion
研究发现视频生成模型Sora-2具备统一的多模态理解和生成潜力，提出'思考视频'作为统一的多模态推理范式。在视觉中心任务中，Sora-2通常与最先进的VLMs相当，甚至在某些任务中超过了VLMs。在文本中心任务中，Sora-2在MATH上达到了92%的准确率，在MMMU上达到了75.53%的准确率。同时发现自我一致性与上下文学习可以进一步提高Sora-2的表现。
## 274. `cs.CL` - Jr. AI Scientist and Its Risk Report: 自主科学探索从基础论文出发 [PDF](https://arxiv.org/pdf/2511.04583), [HTML](https://arxiv.org/abs/2511.04583)
### Authors
Atsuyuki Miyai,Mashiro Toyooka,Takashi Otonari,Zaiying Zhao,Kiyoharu Aizawa
### Background
理解当前AI科学家系统的功能和风险对于确保基于AI的科学研究的可信度和可持续性至关重要，同时保护学术生态系统的核心价值。为此，研究团队开发了Jr. AI科学家，这是一种最先进的自主AI科学家系统，模仿了新手学生研究员的核心研究流程：从人类指导者的基线论文开始，分析其局限性，形成改进的全新假设，通过严格的实验验证，并撰写包含结果的文章。
### Innovation
Jr. AI科学家遵循了明确的研究流程，利用现代编码代理处理复杂的多文件实现，从而生成科学价值显著的文章。不同于先前的全自动系统或小规模代码操作，Jr. AI科学家显著改进了研究流程和自动化程度。
### Conclusion
研究展示了Jr. AI科学家生成的论文获得的评审分数高于现有的全自动系统，但仍发现了作者评价和Agents4Science评论中重要意义的限制，表明当前AI科学家系统的潜在风险和未来研究的关键挑战。研究团队全面报告了开发过程中识别的各种风险，希望这些见解能加深对当前AI科学家开发进展和风险的理解。
## 275. `cs.CL` - 分解提示：探索大型语言模型中的多语言语言结构知识 [PDF](https://arxiv.org/pdf/2402.18397), [HTML](https://arxiv.org/abs/2402.18397)
### Authors
Ercong Nie,Shuzhou Yuan,Bolei Ma,Helmut Schmid,Michael Färber,Frauke Kreuter,Hinrich Schütze
### Background
在使用LLMs进行多语言语言结构知识的序列标注时，维持输出模板是一个挑战，尤其是在当前的文本到文本提示策略中。目前的方法难以确保语言结构的准确性和一致性。
### Innovation
本文介绍了一种分解提示方法，该方法为输入句子的每个词生成单独的提示，询问其语言标签，从而解决了传统单一文本到文本提示方法的局限。此外，该方法在38种语言的通用依赖关系词性标注数据集上进行了测试，使用了英语为中心和多语言LLMs，结果显示分解提示在零样本和少量样本设置下比迭代提示基线更有效率。
### Conclusion
分解提示方法提高了英语为中心的LLMs跨语言知识迁移的能力，在评估的多语言环境下表现出色。
## 276. `cs.CL` - 法律事实预测：法律判决预测中缺失的一环 [PDF](https://arxiv.org/pdf/2409.07055), [HTML](https://arxiv.org/abs/2409.07055)
### Authors
Junkai Liu,Yujie Tong,Hui Huang,Bowen Zheng,Yiran Hu,Peicheng Wu,Chuan Xiao,Makoto Onizuka,Muyun Yang,Shuyuan Zheng
### Background
法律判决预测（LJP）能够帮助原告和律师预测判决结果并优化诉讼策略，已成为关键的法律NLP任务。现有研究通常使用已经确定的法律事实来预测判决，但法律事实往往在诉讼早期阶段难以获得，这大大限制了基于事实的LJP的实际应用。
### Innovation
本文提出了一个新的法律NLP任务——法律事实预测（LFP），该任务以原告提供的证据为输入预测法律事实，从而让基于事实的LJP技术能够在缺乏真实法律事实的情况下做出预测。同时提出了首个用于评估LFP任务的基准数据集LFPBench。广泛的实验结果表明了LFP赋能的LJP的有效性，并指出了LFP的研究方向。
### Conclusion
本文扩展了LFPBench基准数据集，并证明了LFP赋能的LJP的有效性，为未来LFP的研究打开了新的可能性。
## 277. `cs.CL` - DR. WELL: 动态推理和基于符号世界模型的学习在具身LLM多智能体协作中的应用 [PDF](https://arxiv.org/pdf/2511.04646), [HTML](https://arxiv.org/abs/2511.04646)
### Authors
Narjes Nourzad,Hanqing Yang,Shiyu Chen,Carlee Joe-Wong
### Background
多智能体合作规划要求代理在部分信息下进行联合决策，并且通信有限。轨迹层级的协调通常会失败，因为时间或移动中的小偏差会引发冲突。符号规划通过提高抽象级别并提供动作词汇表来解决这些问题，这使得同步和集体进步成为可能。
### Innovation
提出了一种去中心化的神经符号框架DR. WELL，用于合作多智能体规划。合作通过两阶段协商协议展开：首先，代理提出候选角色并进行推理；其次，在共识和环境约束下进行角色分配。在分配承诺之后，每个代理独立生成并执行其角色的符号计划，不透露详细的轨迹。通过基于执行结果和共享世界模型实现推理，DR. WELL 避免了原始轨迹级别的脆弱对齐，实现了更具可重用性、可同步性和可解释性的高层操作。实验证明，动态世界模型有助于多智能体协作，提高任务完成率和效率。
### Conclusion
实验表明，通过协商和自改进，我们的动态世界模型能够捕捉到可重用的模式，从而提高任务完成率和效率。虽然这需要额外的时间开销，但更高效的协作策略促使了更高效的协作策略的发展。
## 278. `cs.CL` - VeriCoT: 通过逻辑一致性检查的神经符号链式思考验证 [PDF](https://arxiv.org/pdf/2511.04662), [HTML](https://arxiv.org/abs/2511.04662)
### Authors
Yu Feng,Nathaniel Weir,Kaj Bostrom,Sam Bayless,Darion Cassel,Sapana Chaudhary,Benjamin Kiesl-Reiter,Huzefa Rangwala
### Background
LLMs可以使用链式思考（CoT）进行多步骤推理，但它们不能可靠地验证其自身的逻辑。即使它们得出正确的答案，其背后的推理也可能存在缺陷，这在高风险场景中会削弱信任。
### Innovation
VeriCoT是一个神经符号方法，它从CoT推理中提取并验证形式逻辑论证。它将每个CoT推理步骤形式化为一阶逻辑，并指明支持论证的前提，包括来源于背景的假设、常识知识或前期推理步骤。符号表示允许自动化求解器验证逻辑有效性，而自然语言前提则使人类和系统能够识别未验证或谬误的推理步骤。通过在ProofWriter、LegalBench和BioASQ数据集上的实验，VeriCoT能够有效识别错误推理，并作为预期答案正确性的重要预测指标。此外，还利用VeriCoT的验证信号进行了推理时自我反思、基于VeriCoT精简数据集的监督微调（SFT）以及使用基于验证的成对奖励进行直接偏好优化（DPO）的偏好微调（PFT），进一步提高了推理的准确性和有效性。
### Conclusion
VeriCoT展示了作为一种新的验证方法，能够有效检测错误推理，并作为预测最终答案正确性的强指标。此外，通过VeriCoT的验证信号进行的推理时自我反思、监督微调以及偏好微调进一步提高了推理的准确性和有效性。
## 279. `cs.CL` - KGGen: 使用语言模型从文本中提取知识图谱 [PDF](https://arxiv.org/pdf/2502.09956), [HTML](https://arxiv.org/abs/2502.09956)
### Authors
Belinda Mo,Kyssen Yu,Joshua Kazdan,Joan Cabezas,Proud Mpala,Lisa Yu,Chris Cundy,Charilaos Kanatsoulis,Sanmi Koyejo
### Background
近年来，建立知识图谱（KGs）的基础模型引起了广泛关注。然而，也存在一个根本性的挑战：知识图谱的数据相对稀缺。当前最知名的KGs主要是由人类标注、通过模式匹配创建或使用早期NLP技术提取。虽然人类生成的KGs数量稀缺，但自动提取的KGs的质量则存在疑问。
### Innovation
为了应对数据稀缺的问题，本文提出了一种文本到KG生成器（KGGen），它是一种利用语言模型从纯文本生成高质量图的软件包。KGGen具有集群相关实体的功能，以减少从文本中提取的KGs中的稀疏性。此外，本文还发布了一个首个基准测试，即节点和边的信息量度量（MINE），来测试提取器从纯文本生成有用KG的能力。
### Conclusion
我们将新的工具KGGen和MINE基准测试工具与现有的KG提取器进行了对比，并展示了远超现有技术的性能。KGGen已作为一个Python库（使用`pip install kg-gen`安装）提供给用户，使得它更为普及。
## 280. `cs.CL` -  pragmatische推理论证提高LLM代码生成 [PDF](https://arxiv.org/pdf/2502.15835), [HTML](https://arxiv.org/abs/2502.15835)
### Authors
Zhuchen Cao,Sven Apel,Adish Singla,Vera Demberg
### Background
大型语言模型（LLMs）在将自然语言（NL）指令转化为程序代码方面展示了令人印象深刻的潜力，但用户指令中固有的歧义性给LLMs带来了挑战，使其难以生成准确反映用户真实意图的代码。为了应对这一挑战，研究者们提出了一种方法，即产生多个代码候选，然后进行再排序来识别最佳解决方案。
### Innovation
本文提出了一种名为CodeRSA的新颖代码候选再排序机制，它是基于理性说话行为（RSA）框架设计的，旨在引导LLMs进行更为全面的关于用户意图的语用推理。实验结果表明，CodeRSA在常见基准模型Llama-3-8B-Instruct和Qwen-2.5-7B-Instruct上，在HumanEval和MBPP这两个广泛使用的代码生成基准上表现出了一致的优越性能，并在大多数情况下超越了现有最先进的方法，展示了稳健的整体性能。这强化了将语用推理整合到代码候选再排序中的有效性，为提高LLMs代码生成质量提供了有前景的方向。
### Conclusion
研究结果证明了将语用推理整合到代码候选再排序中的有效性，为提高大型语言模型代码生成质量提供了新的潜在研究方向。
## 281. `cs.CL` - DAMRO: 潜入LVLM的注意力机制以减少物体幻觉 [PDF](https://arxiv.org/pdf/2410.04514), [HTML](https://arxiv.org/abs/2410.04514)
### Authors
Xuan Gong,Tianshi Ming,Xinpeng Wang,Zhihua Wei
### Background
尽管大型视觉语言模型（LVLM）取得了巨大成功，但它们不可避免地存在幻觉问题。LVLM中的视觉编码器和大型语言模型（LLM）解码器都是基于Transformer的，通过注意机制提取视觉信息并生成文本输出。研究发现，LLM解码器对图像标记的注意分布与视觉编码器非常一致，两者都会倾向于关注图像背景的一些特定标记而忽略了图像中的目标对象。这归因于视觉编码器本身固有的缺陷，误导LLM过度强调冗余信息并生成物体幻觉。
### Innovation
提出了一种名为DAMRO的新型训练前策略，该策略深入挖掘LVLM的注意力机制以减少物体幻觉。具体而言，该方法使用ViT中的分类标记（CLS）过滤出解码阶段中散布在背景中的高注意异常标记，并在解码阶段消除这些异常标记的影响。这种方法在多种基准测试中评估了包括LLaVA-1.5、LLaVA-NeXT和InstructBLIP在内的LVLM，并取得了显著效果，减少了LVLM中的幻觉问题。
### Conclusion
通过DAMRO方法显著减少了LVLM中的高注意异常标记的影响，从而有效地缓解了LVLM的幻觉问题。研究结果在POPE、CHAIR、MME和GPT-4V辅助评估等各种基准测试中得到了验证。相关代码已在此处发布：{代码链接}。
## 282. `cs.CL` - 句法依赖结构中的根节点是谁？ [PDF](https://arxiv.org/pdf/2501.15188), [HTML](https://arxiv.org/abs/2501.15188)
### Authors
Ramon Ferrer-i-Cancho,Marta Arias
### Background
句子的句法结构可以用树结构来表示，其中每个节点代表一个词，并显示词与词之间的句法关系。尽管在无监督方法中取得了显著进展，可以获取句法结构，但在正确预测边的方向上仍存在挑战。通常，句法依赖关系中边的方向是从词指向根节点的。通过寻找无向树和根节点的前提可减轻正确预测边方向的挑战。尽管当前无监督方法取得了进展，但性能仍然有限，这表明我们缺乏对根节点概念的基本理解。研究者考虑了一个集合中的中心度得分，包括仅考虑自由树（非空间得分）和考虑节点位置（空间得分）的得分。通过假设根节点是句法依赖结构中的重要或中心节点，作者验证了该假设，即根节点通常具有较高的中心度，而中心度高的节点也往往是根节点。最终，新型仅考虑节点及其邻居位置的得分表现最佳。
### Innovation
研究提出了一种新的方法来确定句法依赖结构中的根节点，通过考虑节点位置及其邻居位置的中心度得分。该方法证明了根节点通常是中心度较高的节点，并且中心度高的节点也往往是根节点。这种创新方法有助于在无监督句法结构学习中更好地理解根节点的概念，为网络科学提供理论和实证依据。
### Conclusion
研究确认了句法依赖结构的根节点通常是中心度较高的节点，并通过新型得分方法确定了最佳的根节点识别方法。这为无监督句法结构识别提供了理论基础和新的视角。
## 283. `cs.CL` - 我们在提出表格数据查询时是否问出了正确的问题？关于表格数据分析中自然语言查询的歧义性思考 [PDF](https://arxiv.org/pdf/2511.04584), [HTML](https://arxiv.org/abs/2511.04584)
### Authors
Daniel Gomm,Cornelius Wolff,Madelon Hulsebos
### Background
自然语言界面在处理表格数据查询时必须处理查询固有的歧义性。以往的做法是将歧义视为系统缺陷，但本文认为可以重新将之视为用户和系统间合作互动的一部分，即查询规范的责任由用户与系统共同承担。这引发了对查询类型的深入分析，发现当前查询类型的混合使用存在控制不足的问题，欠缺能全面评估系统执行准确性和解释能力的标准。文章还基于此框架对15个常用数据集中的查询进行了分析
### Innovation
作者提出了一个原则性的框架，区分了可解决解释的协作查询和无法解决的非协作查询。此框架有助于重新定义自然语言界面在表格数据分析中的设计和评估方向，为未来的研究指明了方向
### Conclusion
提出的框架和查询分析的反思，使得自然语言界面在表格数据上的设计和评估从单纯‘修正’歧义转向了‘拥抱’合作性解决查询，为后续研究提供了启发
## 284. `cs.CL` - 大型语言模型对弱势用户的靶向表现不佳不成比例地影响 [PDF](https://arxiv.org/pdf/2406.17737), [HTML](https://arxiv.org/abs/2406.17737)
### Authors
Elinor Poole-Dayan,Deb Roy,Jad Kabbara
### Background
尽管最先进的大型语言模型（LLMs）在许多任务中展现了令人印象深刻的表现，但已有大量研究关注这些模型的负面行为，如幻觉和偏见。本文探讨了不同用户属性对LLM响应质量的影响，特别是在信息准确性、真实性以及拒绝度等方面的变化。研究集中在三个最新的LLM和两个针对真实性和事实性的不同数据集上。
### Innovation
本文的研究创新之处在于，首次系统地分析了用户特质对LLM响应质量的影响，并发现负面行为在低英语水平、低教育程度和非美国籍用户中更为常见，这揭示了当前LLM模型可能对最脆弱的用户群体构成信息不可靠的风险。
### Conclusion
研究发现，当今最先进的LLM在信誉和准确性方面表现出的负面行为在低英语水平、低教育程度和非美国籍用户中更为突出，这些用户也因此成为了信息的不安全来源。
## 285. `cs.CL` - GraphCheck: 基于实体关系图的多路径事实核查 [PDF](https://arxiv.org/pdf/2502.20785), [HTML](https://arxiv.org/abs/2502.20785)
### Authors
Hyewon Jeon,Jay-Yoon Lee
### Background
自动事实核查旨在基于相关证据评估文本声明的真实性。然而，验证需要多步推理的复杂声明仍是一个重大挑战。
### Innovation
我们提出了GraphCheck，这是一种新颖的框架，将声明转换为实体-关系图，以实现结构化和系统化的事实核查。通过明确建模显式和潜在实体以及探索多种推理路径，GraphCheck增强了验证的稳健性。为了应对复杂场景，但又不需要为简单声明过于复杂的问题，我们引入了DP-GraphCheck，这是一种变体，采用了轻量级的策略选择器，能够在直接提示和GraphCheck之间自适应选择，这种选择机制通过为每个声明应用适当的推理水平提高了准确性和效率。
### Conclusion
通过对HOVER和EX-FEVER数据集的实验，我们的方法在验证准确性和计算效率方面优于现有方法，同时，DP-GraphCheck中的策略选择机制能够很好地推广到其他事实核查流水线，展示了我们框架的广泛适用性。
## 286. `cs.CL` - 数据集、文档和重复：不平等数据质量的实用问题 [PDF](https://arxiv.org/pdf/2503.07879), [HTML](https://arxiv.org/abs/2503.07879)
### Authors
Alex Fang,Hadi Pouransari,Matt Jordan,Alexander Toshev,Vaishaal Shankar,Ludwig Schmidt,Tom Gunter
### Background
数据过滤已成为提升模型性能并降低计算成本的有效工具。然而，随着大型语言模型计算预算的不断增加，由高度过滤和去重复数据集提供的有限数据量将成为实际限制。为了更好地了解如何解决这一问题，我们研究了不同计算预算下，通过数据过滤和去重生成的多个预训练数据集的模型性能。
### Innovation
我们发现，通过适当修改训练配方，重复现有的高度过滤数据集几次（最多10次）可以在多个数量级的计算预算下，优于使用单次训练更大的超集中数据集。虽然这一发现依赖于对数据集进行多次重复，我们还研究了在数据集内部文档层面上的重复现象。我们发现，并非所有数据集中的文档都是平等的，通过显式地操作单个文档的数量，我们可以相对于令牌预算创建更好的数据集。
### Conclusion
即使大型语言模型继续扩展，数据过滤仍然是研究的重要方向。
## 287. `cs.CL` - TathyaNyaya和FactLegalLlama：在印度法律背景下推进事实判断预测和解释 [PDF](https://arxiv.org/pdf/2504.04737), [HTML](https://arxiv.org/abs/2504.04737)
### Authors
Shubham Kumar Nigam,Balaramamahanthi Deepak Patnaik,Shivam Mishra,Noel Shallum,Kripabandhu Ghosh,Arnab Bhattacharya
### Background
在基于事实判断预测与解释（FJPE）领域，依赖真实数据对于开发稳健且现实的AI驱动决策工具至关重要。本文介绍了TathyaNyaya，这是为印度法律环境量身定制的最大标注数据集，包含了印度最高法院和各级高等法院的判决书。该数据集经过精心设计，着重于客观事实的陈述，反映了真正的司法流程，其中客观数据推动结果。TathyaNyaya数据集不仅在规模和多样性上超过了现有数据集，还为构建法律分析中的可解释AI系统确立了基准。
### Innovation
本文提出了TathyaNyaya数据集及其基于LLaMa-3-8B模型的指令调整版本FactLegalLlama。FactLegalLlama基于TathyaNyaya中的事实数据进行微调，结合了预测精度和上下文相关解释，提高了透明度和可解释性，特别是在AI辅助法律系统中至关重要。该研究方法结合了变压器用于二元判断预测，以及使用FactLegalLlama进行解释生成，为推进印度地区FJPE提供了坚实框架。
### Conclusion
研究强调了事实精准度和领域特定调整在提高预测性能和可解释性方面的重要性，将TathyaNyaya和FactLegalLlama确立为AI辅助法律决策的基础资源。
## 288. `cs.CL` - 采用不断进化的排行榜衡量LLM在RAG中的信仰度 [PDF](https://arxiv.org/pdf/2505.04847), [HTML](https://arxiv.org/abs/2505.04847)
### Authors
Manveer Singh Tamber,Forrest Sheng Bao,Chenyu Xu,Ge Luo,Suleman Kazi,Minseok Bae,Miaoran Li,Ofer Mendelevitch,Renyi Qu,Jimmy Lin
### Background
检索增强生成（RAG）旨在通过将响应与外部上下文相联系来减少幻觉，然而，即使提供了相关上下文，大型语言模型（LLMs）仍然经常引入未被支持的信息或矛盾。当前的幻觉检测方法存在局限性。因此，需要一种更可靠的方法来评估和识别LLMs在RAG中的幻觉。
### Innovation
该论文介绍了一种名为FaithJudge的新框架，这是一种LLM作为裁判的系统，利用多样的人标注的幻觉示例来显著提高自动LLM幻觉评估的准确性。本文还介绍了以FaithJudge为中心的增强幻觉排行榜，用于评估LLMs在总结、问答和数据到文本生成任务中RAG信仰度的表现。这一创新体系进一步支持了开发更可信赖的生成型AI系统的努力。
### Conclusion
FaithJudge能够为RAG中的LLM幻觉提供更可靠的基准测试，并支持开发更可信赖的生成型AI系统。此外，通过引入FaithJudge为中心的排行榜，该研究为LLM在RAG任务中的表现提供了一种更为可靠和标准化的评估方法。
## 289. `cs.CL` - 通过微调转移实现高效模型开发 [PDF](https://arxiv.org/pdf/2503.20110), [HTML](https://arxiv.org/abs/2503.20110)
### Authors
Pin-Jie Lin,Rishab Balasubramanian,Fengyuan Liu,Nikhil Kandpal,Tu Vu
### Background
现代大语言模型（LLMs）在进行高效更新方面遇到挑战，每次生成新的预训练模型版本都需要重复昂贵的对齐过程。对于专门领域的模型或针对特定语言的模型，由于需要对新的基础模型版本进行微调，因此每次更新时都需要重新进行细调。本研究探讨了不同模型版本之间的微调更新转移。通过在各种开源模型版本上进行实证评估，结果表明，转移微调更新可以显著提高目标基础模型的性能。例如，从Llama 3.0 8B模型的微调更新应用到Llama 3.1 8B模型后，在IFEval和LiveCodeBench上分别提高了46.9%和15.7%，甚至超过了Llama 3.1 8B Instruct。此外，研究结果还展示了在多语言任务上也取得了改进。
### Innovation
本文创新地提出了利用微调更新的转移技术实现不同版本之间的知识转移。具体方法是从一个源模型版本中获取一个表示权重变化的差分向量（diff vector），并将其应用于另一目标版本的基础模型。通过这种方法，可以在无需额外训练的情况下显著提升目标模型的性能。研究不仅证明了这种方法在单语言任务中的有效性，还进一步展示了在多语言任务中的性能增益，并通过实验证明了细调转移最有效的情况是当源模型和目标模型参数空间处于线性可连通区域时。
### Conclusion
微调转移提供了一种低成本且实用的策略，用于持续开发大语言模型，这有助于降低大规模模型开发的成本，并提高模型开发的效率。此外，研究还通过理论分析进一步验证了微调转移的有效性和机制，并提供了具体的实验结果来支持以上论点。
## 290. `cs.CL` - 知识背景下的讨论总结：他们在谈论什么？ [PDF](https://arxiv.org/pdf/2505.12474), [HTML](https://arxiv.org/abs/2505.12474)
### Authors
Weixiao Zhou,Junnan Zhu,Gengyao Li,Xianfu Cheng,Xinnian Liang,Feifei Zhai,Zhoujun Li
### Background
传统的对话总结主要关注对话内容，假设包含足够的信息来形成清晰的总结。然而，在基于共享背景的讨论中，参与者经常省略背景信息并使用隐含的参考，导致不熟悉背景的读者感到困惑。为了解决这个问题，作者引入了知识背景下的讨论总结（KGDS），这是一个新颖的任务，旨在生成补充背景总结以提供上下文和清晰的意见总结以澄清参考。
### Innovation
作者提出了一个新颖的任务——知识背景下的讨论总结（KGDS），该任务旨在生成补充背景总结以提供上下文和清晰的意见总结以澄清参考。同时，作者还构建了第一个KGDS基准，其中包括新闻讨论对以及专家创建的多粒度黄金注释用于评估子摘要，并提出了一种新的分层评估框架，具有细粒度和可解释的指标。
### Conclusion
作者对12个先进的大型语言模型（LLMs）进行了广泛的评估，结果显示KGDS仍然是一个重大挑战。这些模型经常在背景总结中遗漏关键事实并保留无关信息，在意见总结整合中无法解决隐含的参照。
## 291. `cs.CL` - 推理模型更常产生幻觉：面向真实性的强化学习方法 [PDF](https://arxiv.org/pdf/2505.24630), [HTML](https://arxiv.org/abs/2505.24630)
### Authors
Junyi Li,Hwee Tou Ng
### Background
大型语言模型（LLMs）通过强化学习（RL）优化显著提升了推理任务的能力，但在多个挑战性基准任务上表现出色的同时，经验分析表明基于推理的RL微调会导致幻觉现象显著增加。研究者发现高方差梯度、熵诱导的随机性和对假局部最优的敏感性是导致幻觉的关键因素。
### Innovation
提出了一种新颖的RL微调算法Factuality-aware Step-wise Policy Optimization（FSPO），该算法在每次推理步骤中引入显式的事实验证。FSPO通过使用自动验证与给定证据相结合来动态调整标记级别的优势值，确保推理过程中的事实正确性。
### Conclusion
在数学推理和幻觉基准测试中使用Qwen2.5和Llama模型进行的实验表明，FSPO能够有效减少幻觉现象，提高推理精度，显著增强可靠性和性能。
## 292. `cs.CL` - 压缩作弊：几何扭曲视角下语言模型的补充信息特性 [PDF](https://arxiv.org/pdf/2505.17793), [HTML](https://arxiv.org/abs/2505.17793)
### Authors
Jianxiang Zang,Meiling Ning,Yongda Wei,Shihan Dou,Jiazheng Zhang,Nijia Mo,Binhong Li,Tao Gui,Qi Zhang,Xuanjing Huang
### Background
近年来，“压缩即智能”的概念为语言模型（LMs）提供了新的信息度量视角，强调了高度结构化的表示形式反映了LMs的智能水平。然而，从几何学角度看，高度压缩LMs的词表示空间趋向于退化成高度各向异性状态，这妨碍了LMs理解指令的能力，直接影响其性能。研究发现，压缩与各向异性之间的同步性实际上是LM表示中的“压缩作弊”，其中噪声主导的方向通过牺牲空间均匀性来制造高压缩率的假象。
### Innovation
基于上述发现，我们提出了三种通过几何失真分析来改进的压缩度量方法，并将其整合到自评估流水线中。这些改进的度量方法与LM的综合能力高度一致，Spearman相关系数超过0.9，显著优于原始压缩度量和其他基于内部结构的度量。这证实了通过引入表示的几何扭曲，压缩作弊极大地增强了对LMs的信息解释。
### Conclusion
这些改进的压缩度量方法不仅提高了LMs的评估准确性，还揭示了LMs在压缩作弊过程中存在的问题，从而为深入了解LMs的信息特性和优化其性能提供了新的视角。
## 293. `cs.CL` - 大型语言模型中的鲁棒性：缓解策略和评估指标综述 [PDF](https://arxiv.org/pdf/2505.18658), [HTML](https://arxiv.org/abs/2505.18658)
### Authors
Pankaj Kumar,Subhankar Mishra
### Background
大型语言模型（LLMs）已成为了自然语言处理（NLP）和人工智能（AI）领域发展的有希望的基础。然而，确保LLMs的鲁棒性仍然是一个关键问题。本文综述了现有研究，系统地探讨了LLMs的鲁棒性本质，包括其概念基础、跨多样化输入的一致性能的重要性及其在实际应用中的失败模式影响。同时，分析了非鲁棒性来源，将模型固有限制、数据驱动的脆弱性和外部 adversarial 因素作为可靠性受损的原因进行分类。此外，综述了最新的缓解策略，讨论了广泛采用的基准测试、新兴的评估指标以及持续存在的可靠性评估差距。最后，综合现有的综述和跨学科研究的结果，突出了趋势、未解决的问题和未来研究的道路。
### Innovation
本文提供了一个全面的综述，涵盖了当前LLMs领域的研究，涵盖了鲁棒性概念、非鲁棒性来源的分类和最新的缓解策略，还讨论了广泛采用的基准、新兴的评估指标以及持续存在的可靠性评估差距。此外，本文综合了已有综述和跨学科研究的结果，提出了未来研究的方向。
### Conclusion
本文总结了当前的研究趋势，指出了尚未解决的问题和未来研究的途径，旨在为该领域的未来发展提供指导。
## 294. `cs.CL` - 低资源语言多语言编码器语言模型压缩研究 [PDF](https://arxiv.org/pdf/2505.16956), [HTML](https://arxiv.org/abs/2505.16956)
### Authors
Daniil Gurgurov,Michal Gregor,Josef van Genabith,Simon Ostermann
### Background
本文探讨了如何使用两阶段知识蒸馏、结构化剪枝、截断和词汇裁剪等方法来极大地压缩低资源语言的多语言编码器只读语言模型。现有技术已经被集成并推向极限，以创建更小的单一语言模型，同时仍保留关键的语言特定知识。研究表明，在压缩率为92%的情况下，模型仍能保持竞争力，不同下游任务中的平均性能下降为2-10%，在最大压缩时为8-13%，这些任务包括情感分析、主题分类、命名实体识别和词性标注，针对三种低资源语言进行评估。进一步发现，性能下降与教师模型中特定语言数据量相关，数据集越大，性能损失越小。
### Innovation
本文提出了一种新颖的方法，系统地结合了现有技术并将其推向极限。该方法应用于多语言编码器语言模型的压缩，主要包括两阶段知识蒸馏、结构化剪枝、截断和词汇裁剪。通过减少层数、前馈隐藏层大小以及中间层嵌入大小，创建显著更小的单一语言模型，同时保持关键的语言特定知识。最终实现了最高92%的压缩率，并保持了竞争性的性能表现，未压缩环境下对各种下游任务的性能仅轻微下降。
### Conclusion
本文通过系统地结合并优化现有压缩技术，成功地将多语言编码器只读语言模型压缩了92%。得益于压缩方法的有效实施，压缩后的模型仍能保持较高的性能，尤其是在中度压缩时表现出色。此外，研究表明，压减少的绩效下降与教师语言模型的数据量相关，数据量更大时，性能下降幅度更小。实验还证实了这些技术在多语言模型压缩中的最佳实践。
## 295. `cs.CL` - TurBLiMP: 一套土耳其语语言最小对立对基准 [PDF](https://arxiv.org/pdf/2506.13487), [HTML](https://arxiv.org/abs/2506.13487)
### Authors
Ezgi Başar,Francesca Padovani,Jaap Jumelet,Arianna Bisazza
### Background
当前语言模型（LMs）的评估资源主要集中在一些语言上，而对于土耳其语来说，缺乏专门设计的语言能力评估资源，特别是在语法现象评估方面。TurBLiMP 填补了这一空白，旨在评估单语和多语种语言模型的语境能力。该基准涵盖了包含1000对语言最小对的16种语言现象，特别关注土耳其语中的两个未被充分研究的属性：词序灵活性和通过形态学过程实现的从属关系。这些特征在当前语言模型的句法评估中未被充分考虑。
### Innovation
TurBLiMP 是第一个为土耳其语设计的语言最小对立对基准，它包括16种语言现象的1000对对立面，特别关注未被充分研究的词序灵活性和形态学从属关系。实验结果显示，即使是最先进的大型语言模型，在处理对人类来说不构成挑战的语法现象时仍然表现不佳。此外，语言模型对词序复杂性和形态学复杂性的敏感度可能与人类不同。
### Conclusion
语言模型依然在处理和人类难度相当的语法现象时表现出挑战，同时对单词顺序复杂性和形态复杂性的敏感度有所不同。TurBLiMP 为评估土耳其语中的语义和句法能力提供了一个重要的工具，促进了在多语种环境下的语言模型研究和发展。
## 296. `cs.CL` - 同质键，异质值：利用局部KV缓存不对称性扩展长期上下文LLMs [PDF](https://arxiv.org/pdf/2506.05410), [HTML](https://arxiv.org/abs/2506.05410)
### Authors
Wanyun Cui,Mingwei Xu
### Background
大型语言模型（LLMs）的最新进展强调了扩展上下文长度的重要性，但由于注意力机制的二次复杂性，这在高效实现长上下文建模方面提出了重大挑战。KV缓存压缩已经成为解决这一问题的关键方法。先前的研究发现，KV缓存中的键和值存在一种未被充分注意到的不对称性：相邻的键接受相似的注意权重（局部一致性），而相邻的值则表现出不同的分布（异质性）。这种不对称性揭示了现有压缩方法中存在的根本限制，这些方法将键和值统一处理。为了克服这个限制，该研究提出了一个无需训练的压缩框架（AsymKV），它结合了基于一致性的键合并和一种理论上无损的值压缩方法。详尽的实验表明，AsymKV在各种任务和模型上都优于现有的长上下文方法，例如在LLaMA3.1-8B模型上，AsymKV在长基准（LongBench）上的平均得分为43.95，超过了像H_2O等最先进的方法（38.89）。
### Innovation
该研究发现了KV缓存中键和值的局部一致性与分布异质性的不对称性，并开发了一个无需训练的压缩框架（AsymKV），该框架结合了基于一致性的键合并和理论上无损的值压缩方法，从而解决了现有压缩方法中存在的关键限制。
### Conclusion
AsymKV框架在各种任务和基础模型上展示了优越的表现，在LLaMA3.1-8B模型上，AsymKV在LongBench上的性能显著超过了现有的最先进方法。
## 297. `cs.CL` - FinEval-KR: 一种评估大语言模型在金融领域的知识和推理能力框架 [PDF](https://arxiv.org/pdf/2506.21591), [HTML](https://arxiv.org/abs/2506.21591)
### Authors
Shaoyu Dou,Yutian Shen,Mofan Chen,Zixuan Wang,Jiajie Xu,Qi Guo,Kailai Shao,Chao Chen,Haixiang Hu,Haibo Shi,Min Min,Liwen Zhang
### Background
大语言模型（LLMs）在金融推理任务中展示了巨大的潜力，但这些任务要求既要有领域知识，又需要复杂的推理能力。当前的评估基准通常未能分离这些能力指标与单一任务性能，并且缺乏对于任务失败的根本原因分析。为此，该研究引入了FinEval-KR，一种新的评估框架，旨在分离并量化LLMs的知识和推理能力，提出了知识评分和推理评分的独立指标。此外，该研究还提出了一种认知评分，基于布卢姆分类学来分析不同认知层次上的推理任务能力。
### Innovation
提出了一种新颖的评估框架FinEval-KR，用于分离并量化大语言模型的知识和推理能力，引入了知识评分和推理评分的独立指标，并基于布卢姆分类学提出了认知评分，以分析不同认知层次上的推理任务能力。此外，作者还发布了一个新的开源中文金融推理数据集，涵盖了22个子领域，以支持可再现的研究和金融推理方面的进一步进展。实验结果表明，推理能力和高级认知能力是影响推理准确性的核心因素。同时，该研究发现，即使是顶尖模型，在知识应用方面仍存在瓶颈。
### Conclusion
该研究揭示了大语言模型推理能力与高级认知能力是影响其金融推理准确性的关键因素，并指出在知识应用方面，顶尖模型仍然存在不足。此外，专业化的金融大语言模型在多个指标上普遍落后于顶级通用大模型。未来的工作可以通过该框架进一步提升LLMs在金融领域的推理能力和应用效果。
## 298. `cs.CL` - XL-DURel: 细调语句变换器以进行序数Word-in-Context分类 [PDF](https://arxiv.org/pdf/2507.14578), [HTML](https://arxiv.org/abs/2507.14578)
### Authors
Sachin Yadav,Dominik Schlechtweg
### Background
论文提出了一个针对序数Word-in-Context分类优化的多语言 Sentence Transformer 模型 XL-DURel。研究背景是现有的模型在处理序数和二分类任务时表现不理想，尤其是在回归和排名任务中使用了一种基于复杂空间中角度距离的排名目标。
### Innovation
研究创新点在于通过细调 Sentene Transformer 开发了一种专门针对序数 Word-in-Context 分类的模型，并测试了多个回归和排序任务的损失函数，结果表明该模型在序数和二分类数据上均表现出色，尤其是在基于角度距离的目标排序任务上。此外，研究还发现二分类可以被视为序数分类的特例，并且优化的通用序数模型在特定的二分类任务上表现更好。
### Conclusion
研究结果表明，使用统一的方法对 Word-in-Context 模型进行建模可以提高不同任务表述下的性能，为 Word-in-Context 分类任务提供了一种更为统一的处理方式。
## 299. `cs.CL` - DYNARTmo: 动态发音模型，用于发音运动模式可视化 [PDF](https://arxiv.org/pdf/2507.20343), [HTML](https://arxiv.org/abs/2507.20343)
### Authors
Bernd J. Kröger
### Background
本文介绍了DYNARTmo，这是一种动态发音模型，旨在通过一个侧面中线平面可视化发音过程。该模型基于UK-DYNAMO框架，并整合了发音欠规范性、音素和手势控制以及连音原则。DYNARTmo 根据十个连续参数和六个离散参数模拟了六个关键发音器官，能够生成元音和辅音发音配置。该实现嵌入在Web应用程序（SpeechArticulationTrainer）中，包含侧面中线、声门和软腭视图，适用于语音学教育和言语治疗。
### Innovation
该模型创新地结合了发音欠规范性、音素和手势控制以及连音原则，使用十个连续参数和六个离散参数模拟六个关键发音器官，能够生成元音和辅音发音配置。模型嵌入在Web应用程序中，提供多种视角，用于语音学教育和言语治疗。
### Conclusion
本文集中讨论了静态建模方面，未来的研究工作将集中在动态运动生成以及与发音-声学模块的集成。
## 300. `cs.CL` - NyayaRAG：印度普通法体系下基于RAG的现实法律判决预测 [PDF](https://arxiv.org/pdf/2508.00709), [HTML](https://arxiv.org/abs/2508.00709)
### Authors
Shubham Kumar Nigam,Balaramamahanthi Deepak Patnaik,Shivam Mishra,Ajay Varghese Thomas,Noel Shallum,Kripabandhu Ghosh,Arnab Bhattacharya
### Background
法律判决预测（LJP）已成为人工智能在法律领域中的关键领域，旨在自动化司法结果预测并增强法律推理的可解释性。以往的研究主要依赖于案件内部内容，如事实、争议点和推理，但往往忽视了普通法体系中的关键要素——通过遵循法律条款和先例来制定判决。为了填补这一空白，本研究提出了一种名为NyayaRAG的检索增强生成（RAG）框架，模拟真实的法庭场景，向模型提供事实上的案件描述、相关的法律法规以及语义上检索到的先前案例，以评估这些输入组合在预测法院判决和生成法律解释方面的有效性。该研究制定了针对印度法律体系的特定领域管道进行评估。
### Innovation
NyayaRAG是一个检索增强生成（RAG）框架，它将事实性的案件描述、相关的法律法规以及语义检索到的先前案例集成到模型中，以模拟真实的法庭场景。研究采用特定领域的流程评估该框架的效果，并使用包括标准的语义和词汇度量以及以大型语言模型为基础的评估器如G-Eval进行评估。
### Conclusion
实验证明，将事实性信息与结构化的法律知识相结合，可显著提高预测的准确性和解释的质量。NyayaRAG为法律判决预测领域提供了一种新的方法，以期提高公正性和透明度，辅助法律专业人士并增强公众对法律判决的理解。
## 301. `cs.CL` - Text2VectorSQL：迈向结构化查询和向量搜索的统一接口 [PDF](https://arxiv.org/pdf/2506.23071), [HTML](https://arxiv.org/abs/2506.23071)
### Authors
Zhengren Wang,Dongwen Yao,Bozhou Li,Dongsheng Ma,Bo Li,Zhiyu Li,Feiyu Xiong,Bin Cui,Linpeng Tang,Wentao Zhang
### Background
随着非结构化数据的激增，传统数据库接口面临根本性挑战。尽管文本到SQL查询（Text-to-SQL）已使得访问结构化数据民主化，但对于解读语义或多模态查询仍无能为力。与此同时，向量搜索已被确立为查询非结构化数据的标准方法，但其与SQL接口（VectorSQL）的集成仍然依赖于手动查询构建，缺乏标准化评价方法，这造成了潜力与实际应用之间的巨大差距。
### Innovation
本文引入并形式化了Text2VectorSQL这一新任务，旨在建立一个统一的自然语言接口，以无缝查询结构化和非结构化数据。为此，我们提出了一个面向研究的基础生态系统，其中包括：（1）用于合成高质量Text2VectorSQL训练数据的可扩展和稳健的流水线；（2）首次大规模、多维度基准VectorSQLBench，涵盖三个数据库后端（SQLite，PostgreSQL，ClickHouse）和四种数据源（BIRD，Spider，arXiv，Wikipedia）的12种不同组合；（3）旨在进行更精细性能分析的若干新型评估指标。实验不仅证实了我们训练模型的优异基线性能，还揭示了召回率下降的挑战：SQL过滤器与向量搜索的整合会比传统过滤的向量搜索导致更显著的结果遗漏。通过确定核心任务、提供必要的数据和评估基础设施以及识别关键研究挑战，本工作为构建下一代统一和智能的数据接口奠定了基础。
### Conclusion
通过定义核心任务、提供必要数据和评估基础设施、并识别关键的研究挑战，本研究为下一代统一和智能化的数据接口的构建奠定了坚实的基础。进一步的工作旨在解决召回率下降挑战，深入推进该领域研究。
## 302. `cs.CL` - 蒸馏与对比学习：如何训练你的重排序器 [PDF](https://arxiv.org/pdf/2507.08336), [HTML](https://arxiv.org/abs/2507.08336)
### Authors
Zhichao Xu,Zhiqi Huang,Shengyao Zhuang,Vivek Srikumar
### Background
文本重排序是信息检索中的关键步骤。当今广泛使用的两种策略是对比学习（直接优化真实标签）和知识蒸馏（从较大的重排序器转移知识）。尽管这两种方法已经得到大量研究，但在实际条件下对比这两种方法对跨编码器重排序器训练效果的明确比较仍有待进行。本文通过在相同数据上训练不同大小（0.5B, 1.5B, 3B, 7B）和架构（Transformer, Recurrent）的重排序器，比较了这两种方法的效果，使用一个强大的对比学习模型作为蒸馏教师模型。研究结果表明，从表现更好的教师模型蒸馏通常比对比学习在域内和域外排序性能上更为优越，这一发现适用于所有学生模型的大小和架构。如果使用一个与学生模型容量相同能力的教师模型进行蒸馏，特别是在处理域外任务时，效果并不理想。这些结果为根据可用教师模型选择训练策略提供了实践指导。如果可以访问较大的表现更好的教师模型，建议使用知识蒸馏来训练较小的重排序器；在没有时，对比学习仍然是一个稳健的基线。本文的代码已经提供，以确保结果的可重现性。
### Innovation
本文通过系统比较对比学习和知识蒸馏在训练跨编码器重排序器时的效果，填补了这一研究领域的空白。特别地，通过使用不同大小和架构的学生模型，并利用一个强大的对比学习模型作为蒸馏教师模型，研究提供了关于教师模型容量对不同训练方法效果影响的实证证据。这项研究对选择适当的训练策略以优化性能具有重要实践意义。此外，通过开放代码促使结果的可重现性也是一项创新点。
### Conclusion
从表现更好的教师模型进行知识蒸馏比直接基于对比学习方法训练重排序器，在重排序性能上更为优越。尤其是在处理域外任务时，蒸馏方法提供了显著的优势。然而，当蒸馏教师模型与学生模型容量相同时，效果并不理想。这些发现为根据可用的教师模型选择合适的训练方法提供了明确的指导。建议使用知识蒸馏来训练较小的重排序器，特别是当可以访问更强大和更大型的教师模型时；而在没有时，对比学习仍然是稳健的基线。
## 303. `cs.CL` - 平衡质量和多样性：去噪过程扭曲了数据标签分布 [PDF](https://arxiv.org/pdf/2509.08217), [HTML](https://arxiv.org/abs/2509.08217)
### Authors
Eve Fleisig,Matthias Orlikowski,Philipp Cimiano,Dan Klein
### Background
为了使机器学习数据集准确反映人群中的不同意见，必须保留数据标签中的变化，同时过滤掉垃圾信息或低质量响应。如何在保持标注员可靠性和代表性之间取得平衡？研究发现，设计用于噪声是单个真实标签差异情况下的策略，往往在标注不一致的标注员和垃圾信息标注员之间做出错误的取舍，导致准确性和标签多样性之间的次优权衡。在保守的标注员去除设置（<5%）之后，所有测试方法都增加了绝对平均误差。此外，这些方法假设垃圾信息标注员比实际攻击者更随机，但大多数垃圾信息标注员和真实标注员在分布上是无法区分的，少数可区分的攻击者给出的答案相对固定而非随机。
### Innovation
研究实证评估了不同标注员过滤策略对主观任务标签变异性的保留影响，发现现有去噪方法通常在标注不一致和垃圾信息标注员之间做出的取舍效果不佳，提出了更高的弹性去噪设置（<5%），并强调需要针对标签多样性的去噪方法。
### Conclusion
研究结果强调了需要一种能够同时考虑数据质量和标签多样性的垃圾信息过滤方法，因为任务要求保留标签的多样性时，实际攻击者往往比非攻击者更不随机，现有的参数化方法假设标签变异性的攻击者往往表现不佳。
## 304. `cs.CL` - RPRO: 基于排序偏好强化优化的医学问答与诊断推理增强 [PDF](https://arxiv.org/pdf/2509.00974), [HTML](https://arxiv.org/abs/2509.00974)
### Authors
Chia-Hsuan Hsu,Jun-En Ding,Hsin-Ling Hsu,Chun-Chieh Liao,Fang-Ming Hung,Feng Liu
### Background
医学问题回答需要高度的推理能力，结合领域知识和逻辑推理。然而，现有的大型语言模型（LLMs）生成的推理链常常缺乏事实准确性与临床可靠性。针对此问题，现有研究多采用对话语义偏好方法，但这些方法往往难以确保生成的推理链与临床工作流程相一致，并且难以自动识别和修正质量低下的推理链。
### Innovation
本文提出了一种创新的框架——排序偏好强化优化（RPRO），该框架结合了强化学习与偏好驱动的推理优化，特别设计针对临床场景中的推理链优化。RPRO 的创新之处在于：使用自适应任务推理模板，并通过概率评估机制与临床工作流程对齐；自动生成并自动识别低质量的推理链并进行纠正；不同于传统的对话语义偏好方法，引入基于布雷德利-特里模型的组内排名优化，并结合 KL 散度正则化方法来实现稳定的训练。这些方法显著提升了大型语言模型在医学问答（PubMedQA 和 MedQA-USMLE）场景中的性能，且效果优于包括医学专业版本在内的更大参数量的模型，显示了结合偏好优化与质量驱动修正的可扩展性和有效性。
### Conclusion
结合偏好优化与质量驱动修正，RPRO 提供了一种构建更可靠、临床导向的医学大型语言模型的可行路径。实验结果表明，RPRO 模型在不同标准上取得了持续改进，并且小参数量的模型甚至优于大批量的模型，进一步验证了其有效性和可行性。
## 305. `cs.CL` - 第四次多语言共指解析共享任务的研究成果：大规模语言模型是否能取代传统方法？ [PDF](https://arxiv.org/pdf/2509.17796), [HTML](https://arxiv.org/abs/2509.17796)
### Authors
Michal Novák,Miloslav Konopík,Anna Nedoluzhko,Martin Popel,Ondřej Pražák,Jakub Sido,Milan Straka,Zdeněk Žabokrtský,Daniel Zeman
### Background
第四次多语言共指解析共享任务作为CODI-CRAC 2025研讨会的一部分被组织。此前的几届任务都要求参与者开发能够识别提及并根据身份共指进行聚类的系统。这项任务在保持传统挑战的同时，引入了专为大规模语言模型设计的新式榜单，并扩展了涵盖两个新语言在内的三个新数据集，使用了版本1.3的CorefUD数据集。共有九个系统参与了这次任务，其中包括四种基于大规模语言模型的方法（两种微调的和两种少量样本适应的）.
### Innovation
引入了专门为大规模语言模型设计的新式榜单，使用了简化后的纯粹文本格式，更加适合大规模语言模型的处理方式，且增加了三个新的数据集，扩展至两个新语言，使用了版本1.3的CorefUD数据集。
### Conclusion
虽然传统的系统仍然保持领先，但大规模语言模型显示出明显的潜力，未来可能会在多语言共指解析方面挑战现状的解决方案。
## 306. `cs.CL` - 使用大型语言模型作为证明者和验证者的数学 [PDF](https://arxiv.org/pdf/2510.12829), [HTML](https://arxiv.org/abs/2510.12829)
### Authors
Hieu Le Duc,Leo Liberti
### Background
2024年和2025年，关于大型语言模型的定理证明能力开始出现有趣的成功案例，特别是在国际数学奥林匹克竞赛的问题上。论文介绍了一种由GPT-5的不同证明者和验证者实例合作完成的定理证明方法，以确保生成的证明不出现幻觉，并通过Lean证明助手进行了形式验证，由人类进一步验证前提和结论的一致性。这种方法在解决2025年IMO的五个问题以及验证线性数论猜想方面表现出色，解决了六十多个猜想中的三分之一。
### Innovation
该论文提出了一种新的协作方法，即使用GPT-5的不同证明者和验证者实例共同完成定理证明。该方法通过Lean证明助手的形式验证以及人工验证前提和结论的一致性，确保了证明的可靠性。该方法在复杂问题和数论猜想验证方面取得了显著成果。
### Conclusion
该方法在解决2025年IMO问题以及验证数论猜想方面表现突出，证明了大型语言模型在复杂数学问题和验证猜想领域的潜力。尽管该方法尚未完全成熟，但它展示了未来在数学证明领域的发展可能性。
## 307. `cs.CL` - CorPipe 25在CRAC 2025中的表现：评估多语言编码器在多语言共指消解中的效果 [PDF](https://arxiv.org/pdf/2509.17858), [HTML](https://arxiv.org/abs/2509.17858)
### Authors
Milan Straka
### Background
本文介绍了CorPipe 25，这是在CRAC 2025共享任务中获胜的多语言共指消解系统。分享任务的第四次迭代引入了新的基于大型语言模型（LLM）的赛道，并减小了开发集和测试集的规模以降低计算需求，还增加了额外的数据集。CorPipe 25是之前系统的完全重新实现，从TensorFlow迁移到了PyTorch。该系统在LLM和未加约束的赛道上都显著优于其他参赛系统，提高了8个百分点。其源代码和训练模型已公开发布。
### Innovation
CorPipe 25是最新的大型语言模型轨道，以及对以前系统的重构，从TensorFlow到PyTorch，并显著提高了性能。此外，数据集规模的减小和任务设置的变化使其计算需求更低，同时还提供了可访问的源代码和预训练模型以供参考与复现。
### Conclusion
CorPipe 25在较新的CRAC 2025共享任务中取得了显著的成绩，尤其是在大型语言模型轨道上的表现优于其他系统。同时，系统本身的重构展示了迁移学习在处理多语言共指消解问题上的重要性，并提供了供社区进一步研究的资源。
## 308. `cs.CL` - 通过全局分叉令牌训练大型语言模型并行推理 [PDF](https://arxiv.org/pdf/2510.05132), [HTML](https://arxiv.org/abs/2510.05132)
### Authors
Sheng Jia,Xiao Wang,Shiva Prasad Kasiviswanathan
### Background
尽管大型语言模型（LLMs）通过扩展并行测试时计算来提高性能，但这也依赖于生成既多样又准确的推理路径。对于复杂问题，触发多种正确推理模式的分叉标记通常位于采样树的深处。因此，鼓励多样性的常用策略，如温度缩放，可能会在多样性与准确性之间遇到恶化的效果。鉴于这一挑战，作者将并行推理视为下一个标记集的预测问题，并利用自我监督的二分匹配将全局分叉标记与独特的推理路径进行匹配，集成到监督微调（SFT）中。研究表明，在单一推理路径上进行平庸的微调会导致这些独特的推理模式消失，而作者提出的方法，集合监督微调（SSFT），能够保留这些模式并生成新的全局分叉标记。多个推理基准实验表明，SSFT 在 Pass@1 和 Cons@k 指标上优于 SFT。
### Innovation
将并行推理视为下一个标记集的预测问题，并利用集合全局损失将自我监督的二分匹配集成到监督微调中，从而生成新的全局分叉标记，保留了多样性并提高准确率。这个方法有效地解决了传统方法在处理复杂推理任务时面临的多样性与准确性之间的困境。
### Conclusion
通过全局分叉令牌的监督微调（SSFT）方法在多个推理基准上优于常规监督微调（SFT），在 Pass@1 与 Cons@k 指标上表现出更优的表现。
## 309. `cs.CL` - META-RAG: Meta-Analysis-Inspired Evidence-Re-Ranking Method for Retrieval-Augmented Generation in Evidence-Based Medicine [PDF](https://arxiv.org/pdf/2510.24003), [HTML](https://arxiv.org/abs/2510.24003)
### Authors
Mengzhou Sun,Sendong Zhao,Jianyu Chen,Haochun Wang,Bing Qin
### Background
证据导向医学在临床应用中占有关键地位。通过合适的医疗文章，医生可以有效降低误诊率。虽然大规模语言模型技术（如RAG）可以在证据导向医学任务中发挥作用，但在区分高质量证据方面仍然存在挑战。鉴于此，研究人员借鉴meta分析的方法，提出了一种新的方法来重新排列和筛选医学证据，从而提高LLMs在诊断中的证据质量，减少错误知识的注入，使用户能够获得更有效的回复。背景涉及到证据导向医学的重要性以及现有RAG技术在证据质量区分方面的不足。
### Innovation
该研究提出了一种Meta-Analysis激励下的证据重新排名方法（META-RAG），利用几种证据导向医学的方法（包括可靠性分析、异质性分析和外推分析）来模拟meta分析过程。这种方法旨在提高从PubMed数据集中提取高质量和可靠证据的能力，从而改进RAG模型的准确性。创新点在于使用meta分析框架改进证据筛选机制，使得LLMs能够更有效地处理和利用医学文献中的高质量证据，以提高诊断准确性。
### Conclusion
该研究通过META-RAG方法显著提高了提取高质量证据的能力，实验结果显示准确性提高了11.4%。这种方法能够帮助RAG从PubMed数据集中提取更高质量和可靠的证据，减少错误知识的注入，并使用户获得更有效的回复。
## 310. `cs.CL` - 利用控制屏障函数对大型语言模型进行对齐 [PDF](https://arxiv.org/pdf/2511.03121), [HTML](https://arxiv.org/abs/2511.03121)
### Authors
Yuya Miyaoka,Masaki Inoue
### Background
本文提出了一种基于控制的框架，用于通过利用控制屏障函数（CBF）来对齐大型语言模型（LLMs），以确保用户期望的文本生成。该框架将安全滤波器应用于基准LLM预测生成的令牌，以干预生成的文本。背景描述了当前对齐LLMs的需求和挑战，强调了CBF作为安全滤波器的作用及其应用场景。
### Innovation
该框架的创新在于利用CBF安全滤波器直接应用于生成的文本，而不需对基准LLM进行微调。此外，如果有关于期望对齐的评估模型，可以直接应用于滤波器设计。这种方法的优势是灵活性和高效性，能够在保持模型原始性能的同时实现对齐目标
### Conclusion
整体文本生成系统使用开源语言模型实现，旨在生成积极的文本。结论总结了该方法的有效性，并展望了其在确保大型语言模型生成符合用户期望文本方面的重要作用。
## 311. `cs.CL` - 医学领域大型语言模型中的记忆现象：常见性、特征和影响 [PDF](https://arxiv.org/pdf/2509.08604), [HTML](https://arxiv.org/abs/2509.08604)
### Authors
Anran Li,Lingfei Qian,Mengmeng Du,Yu Yin,Yan Hu,Zihao Sun,Yihang Fu,Erica Stutz,Xuguang Ai,Qianqian Xie,Rui Zhu,Jimin Huang,Yifan Yang,Siru Liu,Yih-Chung Tham,Lucila Ohno-Machado,Hyunghoon Cho,Zhiyong Lu,Hua Xu,Qingyu Chen
### Background
大型语言模型（LLMs）在医学领域的应用已经显示出了显著的潜力，被广泛应用于诊断辅助、医学问答和临床信息整合等任务。然而，一个关键问题悬而未决，即LLMs在多大程度上记忆了医学训练数据。已有研究主要集中在一般领域的记忆现象，对医学领域中LLMs记忆现象的研究还未进行全面评估。
### Innovation
本研究首次对医学领域中LLMs的记忆现象进行综合性评估，分析其普遍性（出现频率）、特征（记忆内容）、体积（记忆内容量）以及潜在下游影响（记忆对医学应用的影响）。研究系统地分析了三种主要的适应场景，评估了LLMs在医学数据集上继续预训练、在标准医学基准上微调以及在实际临床数据上的微调性能。
### Conclusion
研究发现，记忆现象在所有适应场景中普遍存在，且显著高于一般领域的报告。记忆现象影响LLMs在医学中的开发和采用，并可分类为有益的（准确回忆临床指南和生物医学参考）、无信息的（重复免责声明或模板化医学文档语言）以及有害的（生成特定数据集或敏感的临床内容）。基于这些研究结果，本研究提供了实用建议，以促进有益的记忆现象，使其增强领域特定推理和事实准确性；减少无信息的记忆现象，推动更深层次的学习，超越表面模式；以及减轻有害的记忆现象，防止敏感或可识别患者信息的泄露。
## 312. `cs.CL` - VISTA Score: Verification In Sequential Turn-based Assessment [PDF](https://arxiv.org/pdf/2510.27052), [HTML](https://arxiv.org/abs/2510.27052)
### Authors
Ashley Lewis,Andrew Perrault,Eric Fosler-Lussier,Michael White
### Background
对话人工智能系统在需要事实可靠性的环境中部署时，幻觉（即生成与现有证据或对话背景不符的陈述）是一个主要障碍。现有的评估指标要么评估孤立的响应，要么将不可验证的内容视为错误，这限制了它们在多轮对话中的应用。当前的方法存在局限性，无法有效检测幻觉现象，尤其是在多轮对话场景中。因此，需要发展一种有效的多轮对话事实性评估框架，来改善对话人工智能系统的透明性和可靠性.
### Innovation
本文提出了一种名为VISTA（Verification In Sequential Turn-based Assessment）的框架，通过基于断言的验证和序列一致性跟踪来评估对话事实性。VISTA将每个助手的回合拆解为原子事实断言，验证它们并与可信赖的来源和对话历史进行对比，将不可验证的声明分为主观的、矛盾的、缺乏证据的或弃权的类别。与基准方法相比，VISTA在八种大型语言模型和四个对话事实性基准上显著提升了幻觉检测能力，同时也得到了人类评估者的一致性认同，并揭示了现有基准中的不一致性。通过将事实性建模为对话的动态属性，VISTA提供了一个更透明、更接近人类标准的对话系统的真实性度量标准.
### Conclusion
通过这种方式，VISTA不仅提高了多轮对话幻觉检测的准确性，还促使对话自动系统朝着更加透明和符合人类标准的方向发展。
## 313. `cs.CL` - OceanAI: 一个准确、透明、近实时的海洋学对话平台 [PDF](https://arxiv.org/pdf/2511.01019), [HTML](https://arxiv.org/abs/2511.01019)
### Authors
Bowen Chen,Jayesh Gajbhar,Gregory Dusek,Rob Redmon,Patrick Hogan,Paul Liu,DelWayne Bohnenstiehl,Dongkuan Xu,Ruoying He
### Background
当前，人工智能正在迅速改变科学领域，但通用的对话AI系统经常生成未验证的“幻觉”，这削弱了科学研究的严谨性。海洋学作为一门重要的科学领域，需要高度准确和可靠的实时信息。为此，OceanAI平台旨在结合开源大型语言模型的自然语言流畅性和美国国家海洋和大气管理局（NOAA）的权威海洋数据流，以提供准确、透明和近实时的海洋学信息。通过实时API调用，OceanAI能够识别、解析和综合相关数据集，生成可重复的自然语言回应和数据可视化结果。
### Innovation
OceanAI平台通过结合开源大型语言模型的自然语言生成能力和NOAA的实时海洋数据流，提供了一个准确、透明和近实时的对话平台。与其他AI聊天界面产品相比，OceanAI能够在不牺牲数据完整性和准确性的情况下，提供支持来源的数据，而其他产品要么拒绝回答，要么提供未证实的结果。此外，OceanAI支持多个NOAA数据产品和变量，适用于海洋灾害预测、生态系统评估和水质监测等应用。
### Conclusion
OceanAI通过将其输出和验证过的观察结果结合起来，推动了透明性、可重复性和信任，为海洋领域的AI辅助决策提供了可扩展的框架。未来，OceanAI平台将继续扩展支持更多的NOAA数据产品和变量，以支持更多元化的海洋学应用。一个公共演示可在以下链接找到：this https URL。
## 314. `cs.CL` - LiveSearchBench：基于动态知识检索与推理的自动构建基准 [PDF](https://arxiv.org/pdf/2511.01409), [HTML](https://arxiv.org/abs/2511.01409)
### Authors
Heng Zhou,Ao Yu,Yuchen Fan,Jianing Shi,Li Kang,Hejia Geng,Yongting Zhang,Yutao Fan,Yuhao Wu,Tiancheng He,Yiran Qin,Lei Bai,Zhenfei Yin
### Background
在评估大型语言模型（LLMs）的问答能力时，通常依赖于静态基准，这样的基准倾向于奖励记忆能力，并且未能准确反映世界知识的动态特性。现有的基准测试无法捕捉到世界知识的变化性，导致大型语言模型在应对训练后获取的新事实时表现不佳，特别是在多跳查询中更为明显。
### Innovation
LiveSearchBench 提出了一种自动化的基准构建管道，该管道可以从最近的知识更新中构造依赖于检索的基准。这种方法通过计算连续的维基数据快照之间的差异、过滤候选三元组的质量，并在三个不同推理难度等级上生成自然语言问题，确保每个问题都可以通过 SPARQL 验证获得唯一的、可验证的答案。该管道是完全自动化的，可以在时间上扩展，并最大限度地减少人工干预，可以持续生成具有时间相关性的基准。此外，实验表明，检索增强方法和更大的指令调优模型虽然有部分增益，但未能填补这一时效性差距。因此，本方法旨在从静态的记忆评估转向对最新检索和推理任务的评估，为长期、系统地评估 LLMs 在不断变化的知识环境下的性能提供了基础。
### Conclusion
LiveSearchBench 通过实时生成依赖于检索的能力测试，有效地解决了现有基准评估的不足，强调了在关于动态知识的问题处理中保持最新信息检索的重要性，为长期评估 LLMs 的性能提供了更好的基准。
## 315. `cs.CL` - CareMedEval数据集：评价生物医学领域的批判性评价与推理能力 [PDF](https://arxiv.org/pdf/2511.03441), [HTML](https://arxiv.org/abs/2511.03441)
### Authors
Doria Bonzi,Alexandre Guiggi,Frédéric Béchet,Carlos Ramisch,Benoit Favre
### Background
在生物医学领域，批判性文献评估是一项关键技能。虽然大型语言模型（LLMs）在这方面提供了一定的支持潜力，但在专业化领域进行批判性推理的能力仍然有限。因此，需要研究一种专门针对生物医学领域批判性评估和推理任务的数据集来评估LLMs的性能。CareMedEval由此被开发，它是基于法国医学生的真实考试题集构建的，旨在评测LLMs在这类任务上的表现，并揭示了当前模型在处理具体问题时的局限性。
### Innovation
CareMedEval是一个原创数据集，通过提取法国医学生的真实考试题目，提供37篇科学文章中的534个问题，专注于评测LLMs在生物医学领域批判性阅读和推理方面的能力。现有的评估基准通常没有明确地针对批判性阅读和基于科学文献的推理进行评测，而CareMedEval则填补了这一空白，提供了对LLMs推理能力的更具挑战性的评测环境，揭示了现有技术的局限性和未来发展的方向。
### Conclusion
通过对先进的一般语言模型和生物医学专业化的LLMs进行基准测试，在不同情境中的表现显示，这些模型在复杂的批判性评价和推理方面仍然存在挑战，尤其在研究局限性和统计分析方面。CareMedEval提供了一个评估LLMs在这种类型任务上能力的具有挑战性的基准，揭示了现有技术的不足并为未来的自动化支持开发指明了方向。
## 316. `cs.CL` - 在语言模型中通过分解增强训练以提高事后归因质量 [PDF](https://arxiv.org/pdf/2510.25766), [HTML](https://arxiv.org/abs/2510.25766)
### Authors
Sriram Balasubramanian,Samyadeep Basu,Koustava Goswami,Ryan Rossi,Varun Manjunatha,Roshan Santhosh,Ruiyi Zhang,Soheil Feizi,Nedim Lipka
### Background
大型语言模型（LLMs）在长文档问答中被广泛应用，可靠的来源归属对于提升信任至关重要。现有的事后归因方法在提取式问答方面效果良好，但在多跳、抽象性和半提取式场景中表现不佳，这些场景中答案需要综合多个段落的信息。
### Innovation
本文提出了将事后归因重新定义为一种推理问题的方法，即将答案分解成构成单元，每个单元与特定上下文相关联。研究发现，促使模型生成这些分解并作为归因的一部分可以提高性能。在此基础上，提出了DecompTune方法，这是一种后训练方法，训练模型在进行推理时生成答案的分解。作者构建了一个包含复杂问答任务的多样化数据集，并使用特定任务的定制奖励对Qwen-2.5（7B和14B）进行了二次微调和GRPO训练，这一方法显著提升了归因质量，超越了以往的方法，接近或超过了最先进的模型。
### Conclusion
DecompTune方法通过让模型在生成答案时进行中间推理步骤，显著提高了语言模型事后归因的准确性，超越了现有的方法，并且在其特定任务上达到了或超过了最新的前沿模型的表现。
## 317. `cs.CL` - 大型语言模型会重塑临床预测吗？ [PDF](https://arxiv.org/pdf/2505.18246), [HTML](https://arxiv.org/abs/2505.18246)
### Authors
Yusuf Yildiz,Goran Nenadic,Meghna Jani,David A. Jenkins
### Background
大型语言模型（LLMs）在医疗领域的应用越来越受到关注。本文分析了LLMs在改善临床预测模型（CPMs）诊断和预后任务方面的潜力，特别是它们处理纵向电子健康记录（EHR）数据的能力。然而，存在许多方法论、验证、基础设施和监管方面的挑战，限制了它们的广泛应用，例如时间事件建模方法不足、预测难以校准、缺乏外部验证和对少数群体的偏见影响等。高昂的基础设施成本和缺乏明确的监管框架也阻碍了其采用。
### Innovation
LLMs在处理多模态和纵向EHR数据以及实现针对多种健康状况的多元预测方面展现出潜力。然而，文章指出了诸如时间事件建模方法不足、预测校准差、外部验证有限以及对少数群体的偏差等问题，这些挑战限制了LLMs的广泛应用。
### Conclusion
为了实现临床预测的公正和有效集成，需要进一步的工作和跨学科合作。开发时序感知、公平和可解释的模型应成为优化临床预测工作流程的优先重点。
## 318. `cs.CL` - 开放域标准化财务问答中的分层次检索与证据校验 [PDF](https://arxiv.org/pdf/2505.20368), [HTML](https://arxiv.org/abs/2505.20368)
### Authors
Jaeyoung Choe,Jihoon Kim,Woohwan Jung
### Background
在金融领域，基于检索增强生成（RAG）的大语言模型（LLMs）由于在知识密集型任务上的优异表现而广泛应用。但由于标准化文件（如SEC申报文件）存在相似格式和结构，传统RAG方法难以区分近似相同的文本，导致检索结果中的重复问题，这影响了模型的准确性和完整性。
### Innovation
本文提出了分层次检索与证据校验（HiREC）框架。首先通过分层次检索减少相似文本混淆，先检索相关文件，再选择最相关的段落。通过证据校验过程去除无关段落，并在必要时自动生成补充查询以收集缺失信息。此外，还构建并发布了包含145,897份SEC文件及1,595个问答对的大型开放领域财务问答基准数据集（LOFin），以评估该方法的有效性。
### Conclusion
HiREC框架通过分层次检索和证据校验有效解决了标准化财务文件中因相似文本导致的检索准确性问题，提高了模型的准确性和完整性。
## 319. `cs.CL` - VERA：针对大规模语言模型的变分推理黑盒脱狱框架 [PDF](https://arxiv.org/pdf/2506.22666), [HTML](https://arxiv.org/abs/2506.22666)
### Authors
Anamika Lochab,Lu Yan,Patrick Pynadath,Xiangyu Zhang,Ruqi Zhang
### Background
API-only访问最新的LLM表明，在实际环境中识别模型漏洞的需要。当前大多数基于梯度优化的方法依赖于遗传算法，这些方法受限于初始设置和对人工制定提示池的依赖。此外，这些方法需要对每个提示单独进行优化，无法全面地表征模型漏洞。
### Innovation
介绍了VERA：变分推理框架用于脱狱。VERA将黑盒脱狱提示问题转化为变分推理问题，通过训练一个小的攻击LLM来逼近目标LLM对抗提示的后验分布。训练完成后，攻击者可以生成针对目标查询的多样且流畅的脱狱提示，而无需重新优化。
### Conclusion
实验结果表明，VERA在多种目标LLM上表现出强大的性能，突显出概率推理对于对抗性提示生成的价值。
## 320. `cs.CL` - RadZero: 基于相似性的跨注意力机制在胸片中实现可解释的视觉-语言对齐的零样本多任务能力 [PDF](https://arxiv.org/pdf/2504.07416), [HTML](https://arxiv.org/abs/2504.07416)
### Authors
Jonggwon Park,Byungmu Yoon,Soobum Kim,Kyoyun Choi
### Background
近年来，多模态模型在医学影像领域显著提高了视觉-语言（VL）对齐的表现，尤其是在放射学领域。然而，现有的方法在利用复杂的放射学报告进行学习和提供可视化注意力概率的可解释性方面能力有限。为了克服这些挑战，该论文提出了一种新的框架RadZero，该框架适用于包含多任务零样本能力的胸片视觉-语言对齐。RadZero利用大型语言模型从放射学报告中提取简洁的语义句子，并采用多正样本对比训练来有效捕捉图像和相关文本描述之间的关系。
### Innovation
RadZero 的主要创新在于引入了一个名为 VL-CABS（基于相似性的视觉-语言跨注意力机制）的关键组件。VL-CABS 通过计算文本嵌入和局部图像片段特征之间的相似性，增强了零样本推理、分类和体素级视觉-语言相似性图的生成能力，提高了视觉-语言对齐的解释性。实验结果表明，RadZero 在零样本分类、定位和分割方面优于现有方法。此外，通过可视化视觉-语言相似性图，进一步证明了 VL-CABS 在增强可解释性方面的潜力。
### Conclusion
RadZero 通过在其研究中的创新方案，在零样本多任务设置下实现了精确的视觉-语言对齐，增强了放射学报告的理解和应用。实验表明在多个公开数据集上，RadZero 在零样本分类、定位和分割方面表现优越，并且通过可视化分析进一步验证了其在解释性方面的潜力。
## 321. `cs.CL` - 潜在学习： episodic 记忆通过使经验的灵活重复使用来补充参数学习 [PDF](https://arxiv.org/pdf/2509.16189), [HTML](https://arxiv.org/abs/2509.16189)
### Authors
Andrew Kyle Lampinen,Martin Engelcke,Yuxuan Li,Arslan Chaudhry,James L. McClelland
### Background
本文探讨了机器学习系统在泛化方面失败的原因，揭示了参数机器学习系统的一个弱点：缺乏潜在学习能力。潜在学习是指学习与当前任务无关但对未来任务可能有用的隐性信息。文中通过语言模型中的反转诅咒和基于代理的导航新发现，展示了潜在学习在不同应用场景中的失败情况。
### Innovation
文章从认知科学的角度受到启发，提出将 episodic 记忆作为参数学习的一种补充，以改善系统的灵活性和泛化能力。同时，研究指出一种具有 oracle 检索机制的系统能够更灵活地利用学习经验，从而更好地解决多种泛化挑战。此外，研究强调了一些关键组件，例如在单个示例中上下文学习的重要性，以便系统能够利用检索到的示例中的信息。
### Conclusion
本文结果表明潜在学习可能是当前机器学习系统相对于自然智力的数据利用效率较低原因之一，研究表明检索方法可以补充参数学习，以提高泛化能力。作者最后讨论了这些发现与认知科学和神经科学中先前结果的联系，并讨论了其更广泛的影响。
## 322. `cs.CV` - SILVI: Simple Interface for Labeling Video Interactions [PDF](https://arxiv.org/pdf/2511.03819), [HTML](https://arxiv.org/abs/2511.03819)
### Authors
Ozan Kanbertay(1),Richard Vogg(1 and 2),Elif Karakoc(2),Peter M. Kappeler(2 and 3),Claudia Fichtel(2),Alexander S. Ecker(1) ((1) Institute of Computer Science and Campus Institute Data Science, University of Göttingen, (2) Behavioral Ecology &amp; Sociobiology Unit, German Primate Center, Göttingen, Germany, (3) Department of Sociobiology/Anthropology, University of Göttingen, Göttingen, Germany)
### Background
计算机视觉方法在自动分析通过相机陷阱、无人机或直接野生动物观测收集的大规模视频数据方面被越来越多地使用。虽然近期的研究主要集中在检测单一行为动作，但对行为交互的检测和标注研究却相对较少。现有开源标注工具要么不支持个体位置的标注，要么不能捕捉交互行为。本文旨在填补这一空白。
### Innovation
本文提出了SILVI，这是一种开源标注软件，结合了行为标注和个体定位的双重功能。SILVI允许研究人员直接在视频数据中注释行为和互动，生成可用于训练和验证计算机视觉模型的结构化输出。通过将行为生态学与计算机视觉相结合，SILVI促进了精细行为分析的自动化方法的发展。SILVI不仅适用于动物行为研究，也可以广泛用于需要提取动态场景图的人类互动视频标注。
### Conclusion
虽然开发主要集中在动物行为中，但SILVI可以广泛应用于其他需要提取动态场景图的人类互动视频标注中。相关的软件、文档和下载说明可以在以下链接获得：this https URL.
## 323. `cs.CV` - LoRA-Edge: Tensor-Train-Assisted LoRA for Practical CNN Fine-Tuning on Edge Devices [PDF](https://arxiv.org/pdf/2511.03765), [HTML](https://arxiv.org/abs/2511.03765)
### Authors
Hyunseok Kwak,Kyeongwon Lee,Jae-Jin Lee,Woojoo Lee
### Background
在边缘应用如人体活动识别（HAR）中，设备上微调卷积神经网络（CNNs）是必要的，以应对领域变化。然而，严格的内存、计算和能耗预算使得全面微调无法实现。
### Innovation
LoRA-Edge 是一种基于低秩适应（LoRA）与张量训练辅助的方法，通过 (i) 应用张量训练奇异值分解（TT-SVD）于预训练的卷积层，(ii) 仅选择性地更新输出侧核心并将辅助路径保持在初始状态无活动，(iii) 将更新重新合并到密集核中，从而保持推理成本不变。此设计保留下卷积结构并相比全量微调减少可训练参数数量达两个数量级。
### Conclusion
LoRA-Edge 在多种 HARC 数据集和 CNN 后端中，微调精度最多为全量微调的 4.7% 内，更新参数最多为 1.49%。在 Jetson Orin Nano 上，TT-SVD 初始化和选择性核心训练可使收敛至目标 F1 翻 1.4-3.8 倍快。LoRA-Edge 使结构对齐的，参数高效的设备上 CNN 调整成为边缘平台的现实选择。
## 324. `cs.CL` - Quamba2：针对选择性状态空间模型的稳健且可扩展的后训练量化框架 [PDF](https://arxiv.org/pdf/2503.22879), [HTML](https://arxiv.org/abs/2503.22879)
### Authors
Hung-Yueh Chiang,Chi-Chih Chang,Natalia Frumkin,Kai-Chiang Wu,Mohamed S. Abdelfattah,Diana Marculescu
### Background
状态空间模型(SSMs)因其一致的内存使用和高性能而成为Transformer的一种有吸引力的替代方案。然而，在云服务或资源有限的设备上扩展SSMs具有挑战性，因为它们的存储需求和计算能力。针对此挑战，通过使用低位宽数据格式对SSMs进行量化可以减小模型大小并受益于硬件加速。尽管如此，SSMs对量化引起的错误敏感，因此最近的努力主要集中在优化特定模型或位宽以提高效率而不牺牲性能。然而，在不同场景下，不同的位宽配置是必要的，例如W4A8用于提高大批量解码速度，W4A16用于增强单用户短提示生成速度。
### Innovation
论文提出了一种名为Quamba2的后训练量化框架，适用于Mamba1和Mamba2模型的不同位宽配置。利用SSMs的通道顺序保持和激活持久性，该框架提出了一种离线方法，通过排序和聚类输入x并在输入依赖参数B和C上进行分群量化8位线性递归。为了在SSM输出中保持计算不变性，根据聚类序列重新排列权重。实验表明，Quamba2-8B在预填充和生成阶段分别实现了1.3倍和3倍的性能提升，同时提供4倍的内存减少，平均准确度损失仅为1.6%。框架在MMLU上的评估展示了其普遍性和鲁棒性。
### Conclusion
Quamba2框架展示了其在不同平台上的日益增长的部署需求。该研究释放了代码和量化模型供进一步研究和应用使用。
## 325. `cs.CV` - 基于数据和模型增强的YOLOv12深度学习模型在沙漠废物检测和分类中的应用 [PDF](https://arxiv.org/pdf/2511.03888), [HTML](https://arxiv.org/abs/2511.03888)
### Authors
Abdulmumin Sa'ad,Sulaimon Oyeniyi Adebayo,Abdul Jabbar Siddiqui
### Background
全球废物危机正在加剧，固体废物的产生预计到2050年将增加70%。传统的废物收集方法，在沙漠等偏远或恶劣环境中尤其耗时、低效且具有危险性。尽管近年来计算机视觉和深度学习的进步为自动化废物检测系统打开了大门，但大部分研究仍集中于城市环境和可回收材料，而忽视了有机和有害废物以及未被充分探索的地形如沙漠。
### Innovation
本文提出了一种增强的实时物体检测框架，基于YOLOv12的精简轻量版本，结合了自我对抗训练（SAT）和专门的数据增强策略。使用DroneTrashNet数据集，我们在精度、召回率和平均精确率（mAP）方面取得了显著改进，同时实现了低延迟和紧凑的模型大小，适用于资源受限的空中无人机部署。与最先进的轻量级YOLO变体的基准测试进一步证实了其在准确性和效率方面的最佳平衡。
### Conclusion
我们的结果验证了结合数据中心和模型中心增强技术在沙漠环境下实现稳健、实时废物检测的有效性。
## 326. `cs.CV` - Noise Injection: 提高小样本集中泛化能力的离分布外数据噪声注入方法 [PDF](https://arxiv.org/pdf/2511.03855), [HTML](https://arxiv.org/abs/2511.03855)
### Authors
Duong Mai,Lawrence Hall
### Background
深度学习（DL）模型在图像识别任务中展示出未能将学习到的知识推广到不同设备、不同人群等不同数据上的问题，特别是胸部X光片（CXR）上的新冠肺炎（COVID-19）检测，未能成功推广到训练集中未覆盖的新临床数据来源。这主要是因为模型学习了特定来源的捷径——这些捷径不能转移到新的数据分布中，而不是学习合理的生物标志物来最大化内部分布数据上的性能。因此，提高模型对分布变化的鲁棒性，研究在训练过程中引入基础噪声注入技术（高斯噪声、斑点噪声、泊松噪声和盐-椒噪声）的效果。
### Innovation
研究表明，通过在训练过程中引入基础噪声注入技术，可以显著减小内部分布和外部分布评价之间的性能差距，从0.10-0.20降低到0.01-0.06，基于对多个随机种子下关键指标（如AUC、F1、准确率、召回率和特异性）的平均结果。该研究提供了提高小样本集泛化能力的新思路，特别在外部数据推广能力方面表现出显著的提升效果。
### Conclusion
该研究证明了通过在训练过程中引入噪声的方法可以显著提高模型对分布变化的鲁棒性，并且该方法在多个关键指标上均显示出良好的性能。研究团队已将源代码公开，进一步验证和扩展这种方法的有效性。
## 327. `cs.CV` - 通过纹理引导的高斯网格联合优化改进多视角重建 [PDF](https://arxiv.org/pdf/2511.03950), [HTML](https://arxiv.org/abs/2511.03950)
### Authors
Zhejia Cai,Puhua Jiang,Shiwei Mao,Hongkun Cao,Ruqi Huang
### Background
多视角图像重建对于3D编辑、AR/VR和数字内容创作等应用至关重要。现有的方法通常侧重于几何准确性（Multi-View Stereo）或逼真的渲染（Novel View Synthesis），往往会将几何形状和外观优化脱钩，这妨碍了下游编辑任务。
### Innovation
本文提出了一种新颖的框架，通过高斯引导的网格差分渲染同时优化网格几何（顶点位置和面）和顶点颜色，利用输入图像的 photometric 相关性和从法线图和深度图获得的几何正则化。
### Conclusion
通过优化几何和外观，该框架能够获得高质量的3D重建，这些重建可以获得进一步地利用，例如用于重新照明和形状变形等下游编辑任务；代码将在文章被接受后公开。
## 328. `cs.CV` - 光场相机的线性分数变换模型及其校准方法 [PDF](https://arxiv.org/pdf/2511.03962), [HTML](https://arxiv.org/abs/2511.03962)
### Authors
Zhong Chen,Changfeng Chen
### Background
3D重建使用光场相机需要准确校准内部参数，但这是一个既重要又具有挑战性的前提条件。为此，本文提出了使用线性分数变换（LFT）参数α来解耦主透镜和微透镜阵列（MLA），并通过最小二乘法解析解和后续非线性优化来实现校准，同时介绍了一种从原始图像中检测特征的方法。
### Innovation
提出了使用线性分数变换（LFT）参数α来解耦主透镜和微透镜阵列的方法，结合最小二乘解析解和非线性优化，从而提高光场相机校准的精度和效率。同时，该方法可以加速原始光场图像的模拟，对数据驱动的深度学习方法至关重要。
### Conclusion
通过提出的模型，原始光场图像的模拟变得更快，这对数据驱动的深度学习方法至关重要，实验结果也验证了该方法的有效性。相关代码可以通过作者的网站获得。
## 329. `cs.CV` - 自适应时域细化：连续深度分配和距离回归以实现高效动作定位 [PDF](https://arxiv.org/pdf/2511.03943), [HTML](https://arxiv.org/abs/2511.03943)
### Authors
Ibne Farabi Shihab,Sanjeda Akter,Anuj Sharma
### Background
当前的动作位置检测方法在边界检测方面存在不足，这些方法在处理不同难度的边界时应用的是均匀计算，导致精度不高。
### Innovation
该研究提出了两种互补的贡献：1) 提出了边界距离回归（BDR），通过符号距离回归而非分类提供信息论上最优的边界检测，实现了43%的边界峰值锐化；2) 自适应时域细化（ATR）通过连续深度选择$tau times [0,1]$分配计算量，能在不使用强化学习的情况下实现端到端的可微优化。这些贡献在多个架构上实现了显著的性能提升，并且在THUMOS14基准上实现了比均匀处理更高的效率。
### Conclusion
研究结果显示，自适应时域细化与边界距离回归方法相结合，在THUMOS14基准上实现了56.5%的mAP@0.7，比均匀处理的53.6%提高了2.9%，在计算成本上节省了18%。这些技术在四种基准上通过严格的统计测试得到了验证，特别是在处理边界异质性时性能有所提升。训练成本通过知识蒸馏得到缓解，轻量级学生模型保留了99%的性能，而成本基本保持不变。
## 330. `cs.CV` - 使用基于类别的输入图像组成提高小型和不平衡数据集的诊断性能 [PDF](https://arxiv.org/pdf/2511.03891), [HTML](https://arxiv.org/abs/2511.03891)
### Authors
Hlali Azzeddine,Majid Ben Yakhlef,Soulaiman El Hazzat
### Background
小规模和不均衡的数据集以及输入图像质量差会导致深度学习模型产生较高的误预测率。此背景论文探讨了在Optical Coherence Tomography (OCT)成像数据集中存在的问题，并提出了一种新的方法来改进这类数据的处理方式，以提高诊断准确性。这些数据集中的每种疾病数量可能存在显著差异，给模型的学习带来挑战。
### Innovation
论文介绍了基于类别的图像组成（Class-Based Image Composition, CoImg）技术，该技术将同一类别中的多个图像融合成合成的视觉复合图像，这种合成图像可以增强类内部的变异性和每份训练样本的信息密度，从而提高模型区分细微病变模式的能力。通过这种方式，研究者构建了一个完美平衡类别的数据集Co-OCTDL。并通过与原始数据集的对比实验，展示了该方法的有效性，特别是在基线模型优于不平衡数据集的情况下。
### Conclusion
通过将原始OCT数据集转换为Co-OCTDL和使用VGG16模型进行训练，提出的复合法显著提高了诊断准确度。具体来说，Co-OCTDL数据集在F1分数和AUC上均达到了接近完美的表现（F1-score为0.995，AUC为0.9996），并且误预测率降低。该研究表明，在受到类别不平衡或样本量小影响的弱数据集上，该方法可以获得高质量的预测结果。
## 331. `cs.CV` - 探究自主X射线引导脊柱手术的机器人控制策略学习 [PDF](https://arxiv.org/pdf/2511.03882), [HTML](https://arxiv.org/abs/2511.03882)
### Authors
Florence Klitzner,Blanca Inigo,Benjamin D. Killeen,Lalithkumar Seenivasan,Michelle Song,Axel Krieger,Mathias Unberath
### Background
基于模仿学习的机器人控制策略在基于视频的机器人技术中正重新引起研究兴趣。然而，这种方法是否适用于X射线引导的程序，例如脊柱植入术仍不清楚。这是由于需要对多视图X射线进行解释。因此，研究在双平面引导下针头插入过程中的模仿策略学习的机会和挑战。为此，构建了一个适合大规模、自动化、高度真实的模拟脊柱手术的在体内电子模拟器。通过收集正确的轨道和相应的双平面X射线序列来模拟专业人员的逐步对齐过程。然后，使用视觉信息训练规划和开环控制的模仿学习策略，以迭代地对针头进行对齐。这个精确控制的设置提供了对这种方法的局限性和能力的见解。该策略在68.5%的情况下首次尝试成功，并在不同的椎体水平上保持了安全的椎体内轨迹。该策略在复杂解剖结构，包括骨折，以及在各种初始条件下均保持稳健。在真实双平面X射线上的仿真表明，模型可以生成合理轨迹，尽管仅在模拟中进行了训练。尽管初步结果很有希望，但作者也识别了限制，特别是在进入点精度方面。完全闭环控制将需要如何提供足够的反馈的额外考虑。更多的稳健先验和领域知识可能会使这些模型为未来实现轻量级和CT自由的脊柱内手术导航提供基础。
### Innovation
开发了一个适用于X射线引导脊柱手术的高度真实的在体内电子模拟器，并在该基础上训练了模仿学习策略，以根据视觉信息迭代对齐针头。此研究提供了关于这种方法的局限性和能力的见解，展示了基于模仿学习的方法在复杂解剖结构和不同初始条件下的稳健性。此外，首次研究了双平面引导下的模仿策略学习，为未来该领域的研究奠定了基础。
### Conclusion
尽管初步结果显示基于模仿学习的方法在X射线引导脊柱手术中具有很大的潜力，但在进入点精度等方面存在挑战。未来可以通过提供更频繁的反馈来解决闭环控制的问题，同时还需要更多的稳健先验和领域知识，以使这些模型更适用于临床应用。
## 332. `cs.CV` - 我检测未知的事物：基于随机权重平均高斯的无监督医学影像异常学习 [PDF](https://arxiv.org/pdf/2511.03912), [HTML](https://arxiv.org/abs/2511.03912)
### Authors
Nand Kumar Yadav,Rodrigue Rizk,William CW Chen,KC Santosh(AI Research Lab, Department of Computer Science and Biomedical and Translational Sciences, Sanford School of Medicine, University Of South Dakota, Vermillion, SD, USA)
### Background
医学影像中的未知异常检测仍然是一个基本挑战，由于标记异常样本稀缺且专家监督成本高昂。现有的方法通常需要大量已标记的异常样本和训练成本，这限制了其在实际应用中的推广。本文提出了一种无需监督的框架，该框架通过逐步扩展可信正常样本集来解决这一问题，而无需任何异常标签。这种方法从一小部分验证正常的图像开始，并通过轻量级适应器更新和不确定性门控样本接纳交替进行。
### Innovation
本文提出的框架通过引入双概率门控机制，在逐步扩展过程中确保了安全性。该机制使用冻结预训练视觉主干网，并添加了小型卷积适配器，以确保快速适应和微乎其微的计算开销。提取的特征被存储在一个紧凑的核心集中，以实现高效的k-最近邻异常评分。与以往依赖于生成重建或重放缓冲的方法不同，本文提出的模型通过SWAG（Stochastic Weight Averaging-Gaussian）方法防止漂移和错误包含，从而提高了医学影像异常检测的有效性和效率。
### Conclusion
本文实验结果显示，随着未标记数据的增加，系统的正常性概念逐渐细化，获得了显著的提升。在COVID-CXR数据集上，ROC-AUC从0.9489提升到0.9982（F1：0.8048到0.9746）；在Pneumonia CXR数据集上，ROC-AUC从0.6834提升到0.8968；在Brain MRI ND-5数据集上，ROC-AUC从0.6041提升到0.7269，而PR-AUC从0.7539提升到0.8211。这些结果表明，该方案在实际的、标签稀缺的医学影像应用中非常有效和高效。
## 333. `cs.CV` - Room Envelopes：图像中室内布局重建的合成数据集 [PDF](https://arxiv.org/pdf/2511.03970), [HTML](https://arxiv.org/abs/2511.03970)
### Authors
Sam Bahrami,Dylan Campbell
### Background
现代的场景重建方法能够准确恢复在一组图像中可见的3D表面，但通常会导致不完整的重建，遗漏了所有被遮挡的表面。虽然在使用生成模型的情况下，已经取得进展，以从不完整观察中重建整个对象，但场景中的结构性元素，如墙壁、地板和天花板，却获得了较少的关注。这些场景元素通常较为平面化、重复和简单，因此可以采用较少成本的方法来预测它们。本文背景正是这一研究领域的不足与挑战，以及为了填补这一研究空白所做的努力。
### Innovation
本文提出了一个合成数据集——Room Envelopes，该数据集提供了一组RGB图像以及每幅图像相关的两个点云图：一个捕捉可见表面，另一个在移除装饰和固定件后捕捉第一层表面，即结构布局。这为P待预测的前一组可见表面和前一层布局表面直接监督现代单目几何估计器提供了便利。这一贡献直接有助于加深对场景范围、对象形状和位置的理解。
### Conclusion
该研究通过提供一种新方法，即使用合成的Room Envelopes数据集，对单目几何估计器的训练提供直接监督，从而推动了室内布局重建技术的进步，对未来的研究和实际应用具有重要意义。
## 334. `cs.CV` - GNN-MoE: 使用图神经网络进行参数高效域泛化的上下文感知patches路由 [PDF](https://arxiv.org/pdf/2511.04008), [HTML](https://arxiv.org/abs/2511.04008)
### Authors
Mahmoud Soliman,Omar Abdelaziz,Ahmed Radwan,Anand,Mohamed Shehata
### Background
域泛化（DG）旨在使视觉变换器（ViT）在未见过的数据域上具有稳健的性能。为了适应DG，大幅微调预训练ViT成本高昂，会影响其泛化性能。因此，需要一种更高效的方法来适应预训练ViT以应对DG挑战。
### Innovation
提出了GNN-MoE，通过对专家（MoE）框架使用高效的克罗内克适配器来增强参数高效微调（PEFT）。不同于基于token的路由，新方法通过图神经网络（GNN，如GCN，GAT，SAGE）进行上下文感知的patch路由，动态分配patches到专业化专家，从而利用patch间的上下文关系来更好适应域转移。这样可以提升DG性能，同时保持高参数效率，证明了基于图的上下文路由在实现鲁棒、轻量级DG方面的有效性。
### Conclusion
GNN-MoE在DG基准上的性能达到最优或具有竞争力，并且具有高参数效率，表明基于图的上下文路由对于实现鲁棒和轻量级DG具有实用性。
## 335. `cs.CV` - PhysCorr：带有自动偏好选择的双奖励DPO在物理约束的文本到视频生成中的应用 [PDF](https://arxiv.org/pdf/2511.03997), [HTML](https://arxiv.org/abs/2511.03997)
### Authors
Peiyao Wang,Weining Wang,Qi Li
### Background
文本到视频生成领域取得了显著的感知质量进展，但生成内容经常违背物理可能性的基本原则，表现为不合理的物体动力学、不一致的互动和不现实的运动模式。这些失败阻碍了视频生成模型在具身人工智能、机器人技术和高度仿真领域的应用。
### Innovation
提出了一种统一框架PhysCorr，用于建模、评估和优化视频生成中的物理一致性。具体而言，引入了第一个双维度奖励模型PhysicsRM，量化了物体内部稳定性和物体之间交互。在此基础上，开发了PhyDPO，这是一种新颖的直接偏好优化管道，利用对比反馈和物理感知重新加权来引导生成物理连贯结果。该方法是模型无关且可扩展的，能够无缝集成到各种视频扩散和变压器后端架构中。实验结果表明，PhysCorr 在物理现实度方面取得了显著提升，同时保持了视觉保真度和语义一致性。这项工作朝着物理导向且可靠的视频生成迈出了关键一步。
### Conclusion
PhysCorr 在多个基准上的广泛实验表明，这种方法在保持视觉保真度和语义一致性的同时，显著提高了物理现实度。
## 336. `cs.CV` - MedDChest: 一种内容感知多模态基础视觉模型用于胸部成像 [PDF](https://arxiv.org/pdf/2511.04016), [HTML](https://arxiv.org/abs/2511.04016)
### Authors
Mahmoud Soliman,Islam Osman,Mohamed S. Shehata,Rasika Rajapakshe
### Background
当前，视觉模型在医学影像中的性能受限于细调预训练在不同领域的自然图像上进行。我们提出了MedDChest，一种针对胸部成像优化的新视觉变换器（ViT）模型，通过从大量精心编排的多模态数据集进行从头预训练，以解决现有领域间差距问题。MedDChest使用Guided Random Resized Crops这一新的内容感知数据增强策略，帮助模型更高效地学习医学影像中的关键信息。
### Innovation
MedDChest的核心技术贡献在于Guided Random Resized Crops，这是一种新型的内容感知数据增强策略，能够引导采样偏向解剖学相关区域，解决标准裁剪技术在医学影像中的低效问题。除此之外，MedDChest还是首次采用大规模、领域内预训练并结合领域特定数据增强策略的模型，显著优于其他公开的ImageNet预训练模型。
### Conclusion
通过实验，MedDChest证明了大规模、领域内预训练结合领域特定数据增强策略的优势，提供了一个强大的、鲁棒的特征提取器，可以作为多种胸部诊断任务的良好起点。模型权重将公开，以促进未来的研究和应用。
## 337. `cs.CV` - 基于低帧率PPG信号的混合深度学习模型稳健生物特征认证 [PDF](https://arxiv.org/pdf/2511.04037), [HTML](https://arxiv.org/abs/2511.04037)
### Authors
Arfina Rahman,Mahesh Banavar
### Background
光谱仪（PPG）信号通过光测量皮肤血量的变化，因其非侵入性、固有的活体检测能力和适合低成本可穿戴设备的特性，近年来在生物特征认证中备受关注。然而，PPG信号的质量受到运动伪影、照明变化和个体生理差异的挑战，因此稳健的特征提取和分类变得至关重要。
### Innovation
本文提出了一种基于低帧率指尖视频提取的PPG信号的轻量级低成本生物特征认证框架。该框架通过结合卷积视觉变换器（CVT）和ConvMixer分支的空间特征，以及长短期记忆网络（LSTM）的时序特征，开发了一个名为CVT-ConvMixer-LSTM的混合深度学习模型。该模型采用了连续小波变换（CWT）将一维PPG信号转换为二维时频图，从而有效捕捉瞬态心血管动态。
### Conclusion
实验结果表明，该系统的认证准确率达到98%，证明了其对噪声和个体差异的稳健性。由于其高效性、可扩展性和固有的活体检测能力，该系统非常适合用于移动和嵌入式生物安全应用。
## 338. `cs.CV` - CaRF: 提高3D高斯点云分割中的多视角一致性 [PDF](https://arxiv.org/pdf/2511.03992), [HTML](https://arxiv.org/abs/2511.03992)
### Authors
Yuwen Tao,Kanglei Zhou,Xin Tan,Yuan Xie
### Background
该研究关注于解释自然语言表达并定位相应的3D区域在高斯场中。尽管最近的发展已经实现了语言与3D几何之间的跨模态对齐，但现有管道在处理多视角一致性方面仍然不足，因为它们依赖于2D渲染的伪监督和特定视角的特征学习。因此，该研究旨在通过引入Camera Aware Referring Field (CaRF)，一种直接在3D高斯空间中运行的完全可微分框架，来解决这一问题，从而实现多视角一致性。具体而言，该框架通过引入Gaussian Field Camera Encoding (GFCE)，将相机几何学融入到高斯文本交互中，显式建模视点依赖性变化，并增强几何推理。此外，在训练过程中提出了一种新的配对视图监督方法In Training Paired View Supervision (ITPVS)，在训练过程中对每个Gaussian logits进行对齐，有效避免单视角过拟合，并暴露视间差异以进行优化。
### Innovation
提出了一种名为Camera Aware Referring Field (CaRF)的完全可微分框架，直接在3D高斯空间运行，实现多视角一致性。引入了Gaussian Field Camera Encoding (GFCE)来将相机几何学融入高斯文本交互中，以显式建模视点依赖性变化，并增强几何推理。同时提出了一种称为In Training Paired View Supervision (ITPVS)的新监督方法，用于在训练过程中对每对Gaussian logits进行对齐，从而有效避免单视角过拟合并暴露视间差异。
### Conclusion
在三个代表性基准上的实验结果表明，CaRF方法在Ref LERF、LERF OVS和3D OVS数据集上的均提升分别为16.8%、4.3%和2.0%的mIoU。此外，该研究促进了更可靠和多视角一致的3D场景理解，为增强现实/虚拟现实交互和自主感知等领域带来潜在益处。
## 339. `cs.CV` - 近无损3D体素表示，无需等值面 [PDF](https://arxiv.org/pdf/2511.04029), [HTML](https://arxiv.org/abs/2511.04029)
### Authors
Yihao Luo,Xianglong He,Chuanyu Pan,Yiwen Chen,Jiaqi Wu,Yangguang Li,Wanli Ouyang,Yuanming Hu,Guang Yang,ChoonHwai Yap
### Background
3D重建和生成的基础是准确且高效的3D网格体素化表示。现有的基于等值面的表示依赖于封闭性修复或渲染优化，这不可避免地牺牲了几何精度。这意味着现有方法在处理复杂几何和拓扑结构时表现不佳，无法在高分辨率下保持几何细节和结构的准确性和完整性。
### Innovation
为了解决上述问题，本文提出了忠实轮廓法（Faithful Contouring），这是一种用于任意网格的稀疏体素化表示方法，最高支持2048+分辨率，不需要将网格转换为场函数，也不需要在重新网状化过程中提取等值面。该方法通过保留清晰度和内部结构，即使在具有复杂几何和拓扑的挑战性情况下，也能实现近无损的精度。此外，该方法在贴图、操作和编辑方面也显示出灵活性。为了实现高效的表示和重构，本文设计了一种双模式自编码器，使得形状重构既可扩展又能保持细节。实验结果表明，忠实轮廓法在表示和重构方面均超越了现有方法，在表示时实现了10^-5级别的距离误差，在网格重构时，Chamfer 距离减少了93%，F分数提高了35%，证明了其作为3D学习任务表示的优越性。
### Conclusion
忠实轮廓法提高了3D网格表示的质量，能够在高分辨率下保留几何细节和结构的准确性，同时其自编码器能够实现高效且细节保留的形状重构。实验结果证实了该方法在3D学习任务中的优越表现。
## 340. `cs.CV` - 深层语言锚定多模态视觉-脑部对齐中的深语义不确定性感知 [PDF](https://arxiv.org/pdf/2511.04078), [HTML](https://arxiv.org/abs/2511.04078)
### Authors
Zehui Feng,Chenqi Zhang,Mingru Wang,Minuo Wei,Shiwei Cheng,Cuntai Guan,Ting Han
### Background
从神经信号（如EEG、MEG和fMRI）中揭示视觉语义仍然是一项主要挑战，这主要是由于个体差异和视觉特征的交织性质。现有的方法直接将神经活动与视觉嵌入对齐，但仅基于视觉的表现通常难以捕捉到潜在的语义维度，影响了可解释性和深度鲁棒性。
### Innovation
提出了Bratrix框架，这是一个端到端的多模态语言锚定视觉-脑部对齐方法。Bratrix将视觉刺激拆分为分层的视觉和语言语义组件，并将视觉和脑部表示投影到共享的潜在空间中，从而在视觉-语言和脑-语言嵌入之间建立起对齐。Bratrix整合了一个新颖的不确定性感知模块，在对齐过程中应用了不确定性感知加权。此外，通过使用可学习的语言锚定语义矩阵增强跨模态相关性，并采用单模态预训练和多模态微调的两阶段训练策略，提高了Bratrix-M的对齐精度。
### Conclusion
在EEG、MEG和fMRI基准测试中，Bratrix提高了检索、重构和配图表现，特别是在200类EEG检索任务中，Bratrix-M超越了其他最先进方法14.3%。代码和模型可获取。
## 341. `cs.CV` - 对抗与基于分数的CT去噪：CycleGAN与Noise2Score比较 [PDF](https://arxiv.org/pdf/2511.04083), [HTML](https://arxiv.org/abs/2511.04083)
### Authors
Abu Hanif Muhammad Syarubany
### Background
本文研究了在未配对和自我监督条件下CT图像去噪的方法，评估了两种强大的、训练数据高效的范式：基于CycleGAN的残差转换器和基于Noise2Score得分匹配去噪器。研究在共通的评估协议下，通过配置扫描确定了CycleGAN中使用了一个简单的标准U-Net骨干网络作为最优设置，并进行了长时间的训练。Noise2Score虽然在绝对PSNR/SSIM上略逊一筹，但在非常 noisy 的输入上取得了显著的提升，突显了其在没有干净成对数据时的实用性。总的来说，CycleGAN提供了最强的最终图像质量，而Noise2Score则提供了具有竞争力性能的无配对的健壮替代方案。
### Innovation
研究对比了基于CycleGAN的残差转换器和基于Noise2Score得分匹配去噪器在CT图像去噪中的表现。通过在未配对和自我监督条件下进行评估，发现CycleGAN配置为U-Net骨干网络并经过长时间训练达到了最佳效果，而Noise2Score在非常 noisy 的输入上取得了显著的成效。
### Conclusion
CycleGAN在最终图像质量上表现最优，提供了最强的图像质量。而Noise2Score则提供了在缺乏干净成对数据时的稳健的无配对解决方案，并且具有的竞争力的性能。
## 342. `cs.CV` - 简单3D姿态特征支持人类和机器的社会场景理解 [PDF](https://arxiv.org/pdf/2511.03988), [HTML](https://arxiv.org/abs/2511.03988)
### Authors
Wenshuo Qin,Leyla Isik
### Background
人类能够迅速且不费力气地从视觉输入中提取多种关于他人社会互动的信息，从视线方向到高阶的信息。然而，支撑这些能力的计算原理仍不完全清楚，社会互动识别依然是先进的人工智能视觉系统面临的挑战。这项研究假设人类依赖3D姿态信息来做出社会互动判断，而大多数人工智能视觉模型则缺乏这种信息。为了验证这一假设，研究者将最先进的姿态和深度估计算法结合起来，提取短时间内人类日常行为视频片段中的3D关节位置，并与当前的人工智能视觉模型进行对比。结果发现，3D关节位置在预测人类社会互动判断方面表现出色，揭示出关键的社会信息存在于明确的肢体位置而非大多数视觉模型学习到的特征中，包括用于提取关节位置的姿势模型的层间嵌入。为了发现人类在进行社会判断时使用的关键姿态特征，研究者推导出一个简化的3D社会姿态特征集，描述了视频中人脸的3D位置及其方向。研究发现，这些简化的描述符预测能力与完整的一套3D关节相当，并且当与预训练的视觉模型嵌入结合使用时，显著提高了预训练的视觉模型的预测性能。此外，每种预训练的视觉模型中3D社会姿态特征的表示程度可以预测该模型匹配人类社会判断的能力。因此，我们的研究提供了有力的证据，表明人类对社会场景的理解依赖于明确的3D姿态表示，并可以由简单的、结构化的视为空间原素支持。
### Innovation
该研究通过结合最先进的姿态和深度估计算法提取3D关节位置，而这是大多数人工智能视觉模型中缺乏的信息。该研究进一步推导出简化的3D社会姿态特征，仅描述视频中人脸的3D位置及其方向，发现这些特征在预测人类社会互动判断方面与完整的3D关节具有同样乃至更强的预测能力。这表明，人类的社会场景理解依赖于明确的3D姿态表示，并可以由简单的、结构化的视为空间原素支持。这种方法显著提高了预训练的视觉模型的性能，且预训练模型中3D社会姿态特征的表示程度可以预测其匹配人类社会判断的能力。
### Conclusion
我们的研究结果表明，人类对社会场景的理解依赖于明确的3D姿态表示，并且可以通过简单的、结构化的视为空间原素来支持。这不仅提供了对人类社会认知机制的新理解，也揭示了提高人工智能社会互动识别能力的新途径。
## 343. `cs.CV` - 当Swin Transformer遇见KANs：一种改进的医学图像分割Transformer架构 [PDF](https://arxiv.org/pdf/2511.04084), [HTML](https://arxiv.org/abs/2511.04084)
### Authors
Nishchal Sapkota,Haoyan Shi,Yejia Zhang,Xianshi Ma,Bofang Zheng,Danny Z. Chen
### Background
医学图像分割对于精确诊断和治疗规划至关重要，但因复杂的解剖结构和有限的标注训练数据而充满挑战。基于CNN的分割方法在局部特征提取方面表现出色，但在建模长程依赖关系方面存在困难。而Transformer模型则能更有效地捕捉全局上下文，但其本质数据需求大且计算成本高。
### Innovation
本文提出了一种类似于U-Net的UKAST架构，该架构将基于柯尔莫戈罗夫-阿诺尔德网络(Kolmogorov-Arnold Networks, KANs)的有理函数整合到Swin Transformer编码器中。该架构利用有理基础函数和来自柯尔莫戈罗夫-阿诺尔德变压器(Kolmogorov-Arnold Transformer, KAT)的组有理KANs (Group Rational KANs, GR-KANs)，解决了传统B样条KANs的效率问题，从而产生了更具表达力且数据效率更高的框架，具有降低的FLOPs和较小的参数数量增加。UKAST在四个不同的2D和3D医学图像分割基准中达到了最先进的性能，持续超越基于CNN和Transformer的基线模型，并且在数据稀少的情况下表现出色，缓解了标准视觉Transformer的数据饥渴性。
### Conclusion
这些结果展示了解释增强的Transformer架构在数据高效医学图像分割中的潜力。相关代码可在该链接中获得：this https URL
## 344. `cs.CV` - SpatialLock：文字到图像合成中的精确空间控制 [PDF](https://arxiv.org/pdf/2511.04112), [HTML](https://arxiv.org/abs/2511.04112)
### Authors
Biao Liu,Yuanzhi Liang
### Background
近年来，文字到图像（T2I）合成取得了显著进展，推动了如自动生成数据集等应用的发展。然而，生成图像中的对象定位精度控制仍是一个挑战。现有方法未能充分利用位置信息，导致对对象空间布局的理解不够准确。为了应对这个问题，该研究提出了一种新颖的方法叫SpatialLock，该框架利用感知信号和语义信息共同控制空间位置的生成。
### Innovation
SpatialLock框架引入了两个组成部分：空间参与注入（PoI）和空间导向学习（PoG）。PoI通过注意力层直接整合空间信息，促进模型有效学习语义信息。PoG采用基于感知的监督进一步细化对象定位。这些功能使模型能够生成具有精确空间布局的对象，并提高生成图像的视觉质量。实验表明，SpatialLock在精准对象定位方面达到了新记录，多数据集上的IOU分数均高于0.9。
### Conclusion
SpatialLock框架通过引入空间参与注入和空间导向学习，提升了模型在文字到图像合成中生成图像的空间精确度和视觉质量，达到了新的技术水平。
## 345. `cs.CV` - 多风格文本到草图生成 [PDF](https://arxiv.org/pdf/2511.04123), [HTML](https://arxiv.org/abs/2511.04123)
### Authors
Tengjie Li,Shikui Tu,Lei Xu
### Background
近期视觉-语言模型的发展促进了草图生成的进步。然而，现有的专门方法主要集中在通用合成，缺乏对草图风格的精细控制机制。
### Innovation
提出了一个无需训练的基于扩散模型的框架，可以通过文本提示和参考风格草图实现 显式的风格指导。与之前的风格转移方法不同，本研究将参考特征作为辅助信息引入，并通过线性平滑处理，结合风格内容指导机制，有效减少了参考草图的内容泄露，提升了合成质量，特别对于参考草图和目标草图结构相似度低的情况效果显著。此外，提出了多风格生成支持框架，该框架能够整合多个参考草图的特征，并通过协调的AdaIN模块进行控制，从而实现可控的多风格生成，增强了风格控制的灵活性。
### Conclusion
大量实验表明，该方法在风格对齐准确性和风格控制灵活性方面实现了高质量的草图生成。官方实现已可从此处获取。
## 346. `cs.CV` - 使用场地关键点检测的自动网球玩家和球跟踪系统 [PDF](https://arxiv.org/pdf/2511.04126), [HTML](https://arxiv.org/abs/2511.04126)
### Authors
Venkata Manikanta Desu,Syed Fawaz Ali
### Background
目前，足球比赛的自动化分析系统较多，但对于网球比赛的分析系统相对较少，尤其是能够实时检测和跟踪玩家和球，并识别场地上关键点的系统更为稀缺。这项研究旨在填补这一空白，提供一个全面的自动化网球比赛分析管道，以满足教练、运动员和广播人员的需要。
### Innovation
本研究创新地集成了多种深度学习模型，包括YOLOv8进行玩家检测，自训练的YOlOv5模型进行球跟踪，基于ResNet50的架构进行场地上关键点检测。系统能够实时提供详细的运动模式、球速、射准以及反应时间等数据分析，能够在不同比赛场景下表现出色。
### Conclusion
实验结果表明，该系统在不同比赛条件下具有稳健的性能。系统能生成带有注释的视频及详细的性能指标，为教练、运动员和广播人员提供具体的见解，帮助他们更好地理解比赛的动力学。
## 347. `cs.CV` - 在推理时从在线视频中学习以增强计算机使用代理 [PDF](https://arxiv.org/pdf/2511.04137), [HTML](https://arxiv.org/abs/2511.04137)
### Authors
Yujian Liu,Ze Wang,Hao Chen,Ximeng Sun,Xiaodong Yu,Jialian Wu,Jiang Liu,Emad Barsoum,Zicheng Liu,Shiyu Chang
### Background
计算机使用代理可以操作计算机并自动化繁琐任务，但相较于人类用户，尤其是在需要特定应用程序、平台和多步骤工作流程的专业程序知识的任务中，它们仍然存在差距。因此，人类可以通过观看视频教程来填补这一差距：我们搜索、浏览并从匹配当前子目标的短段教程中选择性地模仿。本文研究如何在推理时使计算机使用代理能够有效学习在线视频。
### Innovation
本文提出了一个框架，该框架在推理时检索和筛选教程视频，将它们转化为结构化的演示轨迹，并在执行过程中动态选择轨迹作为上下文指导。特别地，通过视觉-语言模型（VLM），推断UI操作、将视频分割成动作的短子序列，并为每个子序列分配一个文本目标。在推理过程中，通过两阶段选择机制动态地在每个步骤选择一个轨迹添加到上下文中，使其代理关注于最有助于下个决策的局部指导。
### Conclusion
实验表明，与基础代理和仅使用文本教程或转录的数据变体相比，该框架始终表现出色。分析强调了轨迹分割和选择、动作过滤和视觉信息的重要性，表明大量在线视频可以系统地提炼成富有行动价值的指导，从而在推理时提高计算机使用代理的能力。
## 348. `cs.CV` - DMSORT:一种用于无人驾驶船只平台的高效并行海上多目标跟踪架构 [PDF](https://arxiv.org/pdf/2511.04128), [HTML](https://arxiv.org/abs/2511.04128)
### Authors
Shengyu Tang,Zeyuan Lu,Jiazhi Dong,Changdong Yu,Xiaoyu Wang,Yaohui Lyu,Weihao Xia
### Background
准确感知海上环境对于确保船舶航行安全和有效的海事监控至关重要，然而复杂的海上环境经常导致摄像机运动并随后产生视觉退化，给多对象跟踪（MOT）带来巨大的挑战。
### Innovation
提出了一种高效的 DMSORT 方法，以解决海上 MOT 面临的挑战。该方法的核心是一个并行跟踪器，其中包括一个附有仿射补偿的对象检测和重新识别（ReID）分支，以及一个专门用于动态摄像机运动估计的分支。此外，集成了可逆柱状检测网络 (RCDN) 和轻量级基于 Transformer 的外观提取器（Li-TAE），以捕获全局上下文信息并生成鲁棒的外观特征。通过构建投影变换，分离平台诱导和目标固有运动，并应用平台运动补偿，从而在卡尔曼滤波器中稳定真实物体轨迹。最后，聚类优化特征融合模块有效结合了运动和外观提示，以在噪声、遮挡和漂移情况下确保身份一致性。
### Conclusion
在新加坡海事数据集上的广泛评估表明，DMSORT 达到了最先进的性能。值得注意的是，DMSORT 在现有的基于 ReID 的 MOT 框架中实现了最快的运行时，同时保持了高度的身份一致性，并对抖动和遮挡具有很高的鲁棒性。
## 349. `cs.CV` - 龟兔指导：使用多速率积分加速扩散模型推理 [PDF](https://arxiv.org/pdf/2511.04117), [HTML](https://arxiv.org/abs/2511.04117)
### Authors
Yunghee Lee,Byeonghyun Pak,Junwha Hong,Hoseong Kim
### Background
本文提出了一种名为‘龟兔指导’（Tortoise and Hare Guidance, THG）的无训练策略，旨在加速扩散采样过程，同时保持高保真生成。通过重新定义无分类器指导（Classifier-Free Guidance, CFG）的偏微分方程（ODE）为一个多速率ODE系统，我们表明噪声估计和附加指导项对数值误差的敏感性有明显差异。通过错误界分析，我们发现附加指导分支对近似更稳健，揭示了传统求解器未能利用的重大冗余性。
### Innovation
本文的创新在于重新将CFG ODE作为多速率ODE系统处理，揭示附加指导分支对近似具有更强的鲁棒性，并引入了特殊的错误界感知时间步长采样器和指导尺度调度器。具体创新包括：1）减少额外指导项的计算量；2）引入错误界感知时间步长采样器和指导尺度调度器；3）通过多速率方法大幅减少函数评估次数（NFE），同时保持几乎相同的生成保真度（$triangle$ImageReward $triangleq$ 0.032），并在相同的计算预算下超越最先进的CFG基无训练加速器。
### Conclusion
我们的研究结果表明，多速率形式对于扩散求解器有潜力，为无模型重训练的实时高质量图像合成铺平了道路。
## 350. `cs.CV` - 直接看到：有效OCR的文档方向检测 [PDF](https://arxiv.org/pdf/2511.04161), [HTML](https://arxiv.org/abs/2511.04161)
### Authors
Suranjan Goswami,Abhinav Ravi,Raja Kolla,Ali Faraz,Shaharukh Khan,Akash,Chandra Khatri,Shubham Agarwal
### Background
尽管在文档理解方面取得了显著进展，但在实际应用场景中，确定扫描或拍摄文档的正确方向仍然是一个关键的预处理步骤。准确的旋转校正是提高下游任务（如光学字符识别OCR）性能的重要因素，因为常见的偏差通常是由用户错误引起的，尤其是在拍摄时相机基线方向错误造成的。
### Innovation
本文首先引入了OCR-Rotation-Bench (ORB)，这是一种新的基准，用于评估OCR对图像旋转的鲁棒性，包括基于旋转转换的结构化和自由形式的英语OCR数据集构建的ORB-En，以及一个全新的多语言数据集ORB-Indic，涵盖了11种印度语中的中低资源语言。此外，本文还提出了一种快速、稳健且轻量的旋转分类流水线，基于Phi-3.5-Vision的视觉编码器，并结合动态图像裁剪，专门针对四类旋转任务进行微调。
### Conclusion
我们的方法在两个数据集上的旋转识别准确率分别达到了96%和92%。此外，我们还展示了我们的模块在提高OCR性能中的关键作用：对于商业源模型，提高多达14%；对于开源权重模型，提高多达4倍。
## 351. `cs.CV` - Covariance描述符遇到通用视觉编码器：黎曼深度学习在医学图像分类中的应用 [PDF](https://arxiv.org/pdf/2511.04190), [HTML](https://arxiv.org/abs/2511.04190)
### Authors
Josef Mayr,Anna Reithmeir,Maxime Di Folco,Julia A. Schnabel
### Background
Covariance描述符能够捕捉图像特征的二阶统计特性，已在通用计算机视觉任务中展现出强大性能，但在医学影像领域却鲜有应用。本文通过使用预训练的一般视觉编码器（GVE）提取的特征构造Covariance描述符，并将其与手工制作的描述符进行对比，探究其在医学图像分类中的有效性，尤其是针对特异正定（SPD）矩阵的分类网络SPDNet。实验结果表明，基于GVE特征的Covariance描述符优于手工制作的描述符，而结合DINOv2特征的SPDNet优于最先进的方法。
### Innovation
本文提出了使用预训练的一般视觉编码器（如DINOv2和MedSAM）来构建Covariance描述符，并将其应用于医学图像分类任务中。研究特别关注了SPDNet网络，这是专门为处理对称正定矩阵设计的分类网络。实验结果证明，这种方法在多个医学图像数据集中都能取得优越的效果，特别是在结合DINOv2特征时SPDNet表现尤为出色。
### Conclusion
该研究揭示了结合Covariance描述符和强大的预训练视觉编码器对于医学图像分析的潜力，表明这是一种有效的医学图像分类方法。
## 352. `cs.CV` - AStF: 通过自适应统计融合器实现的人运动风格迁移 [PDF](https://arxiv.org/pdf/2511.04192), [HTML](https://arxiv.org/abs/2511.04192)
### Authors
Hanmo Chen,Chenghao Xu,Jiexi Yan,Cheng Deng
### Background
人类运动风格迁移可以让角色在保持特定风格的同时显得更真实，更少僵硬。传统的任意图像风格迁移通常处理均值和方差，这种方法已被证明有效。同时，类似的方法也被应用于运动风格迁移。然而，由于图像和运动之间存在根本性的区别，仅依赖均值和方差无法充分捕捉运动数据中的复杂动态模式和时空一致性特征。因此，本文的关键洞察是引入尖度和峰度这两个系数来分析运动风格。
### Innovation
提出了一种名为Adaptive Statistics Fusor (AStF)的新方法，它由Style Disentanglement Module (SDM)和High-Order Multi-Statistics Attention (HOS-Attn)组成。AStF与一种名为Motion Consistency Regularization (MCR)的鉴别器进行了联合训练。实验结果表明，通过提供运动变换内在的时空统计模式的更全面模型，AStF在运动风格转移方面优于现有技术。
### Conclusion
通过提供对动态风格内在的时空统计模式的更全面建模，所提出的AStF在运动风格转移上展示了优于现有技术的性能。本文提供的代码和模型可以在this https URL找到。
## 353. `cs.CV` - 数字病理学中精确图像配准预处理技术的系统评估 [PDF](https://arxiv.org/pdf/2511.04171), [HTML](https://arxiv.org/abs/2511.04171)
### Authors
Fatemehzahra Darzi,Rodrigo Escobar Diaz Guerrero,Thomas Bocklitz
### Background
图像配准是指通过将两张或多张图像映射到相同的坐标系统，来空间对齐图像、使影像中的相应解剖或组织结构在不同图像之间匹配的过程。在数字病理学领域，图像配准支持通过多种染色或成像模态直接比对和整合信息，进而促进如生物标志物分析和组织重建等应用。跨模态图像配准是数字病理学中的一个关键步骤。本文旨在探究不同颜色转换技术对H&E染色图像和非线性多模态图像配准的影响，通过不同预处理步骤对20个组织样本配对进行处理并使用VALIS配准方法进行配准，配准性能用相对目标配准误差（rTRE）来评估。在两种场景下分别进行了配准实验，结果显示CycleGAN颜色转换方法在图像间配准误差方面表现最佳，其他方法则误差较高，这表明在配准前进行颜色转换可以提高跨模态图像的对齐精度，支持数字病理学中的更可靠分析。
### Innovation
研究引入了CycleGAN颜色转换技术，并将其应用于H&E染色图像和非线性多模态图像的配准，创新性地评估了不同预处理步骤（包括颜色转换、对比度调整、强度归一化和去噪）对图像配准精度的影响。研究结果表明，颜色转换有助于提高不同模态图像间的对齐精度，并为数字病理学分析提供更好的支持。
### Conclusion
本研究通过评估各种图像预处理技术对不同模态图像配准的影响，发现CycleGAN颜色转换方法在图像配准性能方面表现最佳，其预处理技术可以有效提高跨模态图像之间的匹配精度，适用于数字病理学中的图像配准应用。
## 354. `cs.CV` - MedSapiens: 以姿态重新思考医学影像中的解剖标志检测 [PDF](https://arxiv.org/pdf/2511.04255), [HTML](https://arxiv.org/abs/2511.04255)
### Authors
Marawan Elbatel,Anbang Wang,Keyuan Liu,Kaouther Mouheb,Enrique Almar-Munoz,Lizhuo Lin,Yanqi Yang,Karim Lekadir,Xiaomeng Li
### Background
在医学影像中，解剖标志的检测传统上依赖于针对特定领域的模型，而大规模预训练视觉模型的出现为这一领域带来了新的机遇。本文探讨了将Sapiens这种为姿态估计优化的人本中心基础模型适应到医学成像中，通过多数据集预训练来建立新的基准。研究表明，人本中心模型在空间姿态定位方面具有天然优势，但这一潜力尚未得到充分利用。
### Innovation
本文提出了MedSapiens模型，通过多数据集预训练将Sapiens模型应用于医学成像中的解剖标志检测，显著提高了检测准确率。MedSapiens模型在多个数据集上建立了新的基准记录，在平均成功检测率（SDR）方面，相较于通用模型提升了5.26%，相较于专科模型提升了21.81%。此外，在数据稀少的情况下，MedSapiens模型的表现也优于现有的少量标注模型。
### Conclusion
通过将人本中心基础模型应用于医学成像中，MedSapiens模型展示了在解剖标志检测方面的新潜力。尽管这是一种重温基础方法的做法，但通过引入多数据集预训练，MedSapiens在解剖标志检测任务中的表现超过了现有的先进模型。
## 355. `cs.CV` - FastGS：在100秒内训练3D高斯斑点 [PDF](https://arxiv.org/pdf/2511.04283), [HTML](https://arxiv.org/abs/2511.04283)
### Authors
Shiwei Ren,Tianci Wen,Yongchun Fang,Biao Lu
### Background
现有的3D高斯斑点加速方法在训练过程中未能有效控制高斯的数量，导致冗余的计算时间开销。
### Innovation
提出了一种名为FastGS的新颖、简单且通用的加速框架，基于多视图一致性考虑每个高斯的重要性，高效地解决了训练时间与渲染质量之间的权衡。FastGS创新地设计了基于多视图一致性密度增加与消除策略，取消预算机制。
### Conclusion
实验结果表明，FastGS在训练速度上远超最先进的方法，分别在Mip-NeRF 360数据集上实现3.32倍加速，在Deep Blending数据集上实现15.45倍加速。FastGS在各种任务中展现了强大的通用性，提供2-7倍的训练加速。项目页面可访问: this <https://> URL
## 356. `cs.CV` - 基于DINOv2的视频驱动步态表征学习方法用于视频可见-红外行人再识别 [PDF](https://arxiv.org/pdf/2511.04281), [HTML](https://arxiv.org/abs/2511.04281)
### Authors
Yujie Yang,Shuang Li,Jun Ye,Neng Dong,Fan Li,Huafeng Li
### Background
现有方法倾向于利用模态不变的视觉特征，但忽视了步态特征的重要性。这些特征不仅模态不变，而且富含时间动态性，因此限制了它们建立跨模态视频匹配所必需的空间-时间一致性的能力。
### Innovation
提出了基于DINOv2的步态表征学习框架（DinoGRL），利用DINOv2丰富的视觉先验知识来学习与外观线索互补的步态特征，以便为跨模态检索提供稳健的序列级表示。引入了具备语义意识的轮廓和步态学习（SASGL）模型，生成并增强与DINOv2通用语义先验相关的轮廓表示，并与ReID目标联合优化以实现语义丰富且任务适配的步态特征学习。还开发了渐进双向多粒度增强（PBMGE）模块，在多个空间粒度上允许步态流和外观流之间的双向交互，充分利用它们的互补性，丰富全局表示的局部细节，生成具有高度区分力的特征。
### Conclusion
在HITSZ-VCM和BUPT数据集上的广泛实验显示了本文方法的优势，显著优于现有的最先进的方法。
## 357. `cs.CV` - 基于Sentinel-1图像的深学习海上平台目标检测及合成训练数据的影响 [PDF](https://arxiv.org/pdf/2511.04304), [HTML](https://arxiv.org/abs/2511.04304)
### Authors
Robin Spanier,Thorsten Hoeser,Claudia Kuenzer
### Background
海上基础设施（包括海上风电场、石油和天然气平台、人工岛和养殖设施）的扩展揭示了有效监测系统的需求。现有模型开发依赖于综合且平衡的数据集，但在样本稀缺的情况下（尤其是稀有的对象类别、形状和尺寸），模型性能会受到影响。
### Innovation
本文通过使用在2023年第四季度来自四个地区（里海、南中国海、几内亚湾和巴西海岸）的合成和实际的Sentinel-1卫星图像训练基于YOLOv10的物体检测模型，探索了合成训练数据如何提升模型性能，进而验证了模型的地理转移能力。研究结果表明，使用合成数据可使检测的海上平台总数达到3,529个，F1分数从0.85提升到了0.90。
### Conclusion
平衡数据集的重要性得到了强调，并提出了合成数据生成的有效策略，以应对遥感领域常见的挑战。研究展示了深度学习技术在全球范围内进行海上基础设施监控的潜力。
## 358. `cs.CV` - VOC 2008数据集中马和摩托车二分类的CNN架构比较研究 [PDF](https://arxiv.org/pdf/2511.04344), [HTML](https://arxiv.org/abs/2511.04344)
### Authors
Muhammad Annas Shaikh,Hamza Zaman,Arbaz Asif
### Background
本文对VOC 2008数据集中马和摩托车的二分类问题进行了九种卷积神经网络架构的全面评估。针对样本不均衡的问题，采用了少数类数据增强技术。通过比较包括ResNet-50、ConvNeXt-Tiny、DenseNet-121和Vision Transformer等现代架构，评估了多个性能指标。实验结果表明不同架构表现差异显著，ConvNeXt-Tiny在马和摩托车分类上分别取得了最高的平均精确度95.53%和89.12%。
### Innovation
本文通过数据增强技术显著改善了少数类检测，并特别有利于更深的架构。研究提供了在不平衡二分类任务中选择架构的见解，量化了数据增强策略在缓解检测中的类别不平衡问题方面的影响。
### Conclusion
研究为不平衡二分类任务中的架构选择提供了一些见解，并量化了数据增强策略在缓解检测中的类别不平衡问题方面的影响。
## 359. `cs.CV` - Proto-LeakNet: 针对合成人类面部图像的信号泄漏感知归因 [PDF](https://arxiv.org/pdf/2511.04260), [HTML](https://arxiv.org/abs/2511.04260)
### Authors
Claudio Giusti,Luca Guarnera,Sebastiano Battiato
### Background
随着合成图像和深度造假生成模型的日益复杂，源归因和真实性验证成为现代计算机视觉系统面临的关键挑战。近期研究表明，扩散管道意外地在其输出中留下了持久的统计痕迹，即信号泄漏，特别是在潜在表示中。基于这一观察，我们提出了一种名为Proto-LeakNet的信号泄漏感知和可解释归因框架，该框架结合了封闭集分类和基于密度的开放集评估，无需重新训练即可分析未见过的生成器。该方法在扩散模型的潜在域中重新模拟部分前向扩散以揭示残留的特定生成器线索。时间注意力编码器聚合多步潜在特征，而特征加权原型头构建嵌入空间，实现透明归因。该模型仅在封闭数据上训练，宏AUC高达98.13%，学习到的潜在几何结构在后处理过程中保持稳定，超越现有最先进的方法，并在已知和未见过的生成器之间实现了强分离性。这些结果表明，在潜在空间建模信号泄漏偏倚可以实现可靠的和可解释的人工智能图像和深度假信息取证。整个工作的代码将在提交时公布。
### Innovation
1. 提出了Proto-LeakNet，一种信号泄漏感知和可解释归因框架，结合了封闭集分类和基于密度的开放集评估，无需重新训练即可分析未知的生成器。2. 在扩散模型的潜在域中重新模拟部分前向扩散以揭示残留的特定生成器线索。3. 时间注意力编码器和特征加权原型头用于构建嵌入空间和实现透明归因。4. 仅使用封闭数据训练，宏AUC高达98.13%，学习到的潜在几何结构在后处理过程中保持稳定，超越现有最先进的方法。实现了已知和未见过的生成器之间的强分离性。5. 建模潜在空间中的信号泄漏偏倚，可以实现可靠的和可解释的人工智能图像和深度假信息取证。
### Conclusion
Proto-LeakNet 在合成图像源归因和真实性验证方面展示了显著的性能，通过在潜在空间建模信号泄漏偏倚，实现了可靠的可解释的人工智能图像和深度假信息取证，并且其方法具有较高的推广性。
## 360. `cs.CV` - 子流形稀疏卷积网络在计算机断层扫描中自动化3D分割肾和肾脏肿瘤 [PDF](https://arxiv.org/pdf/2511.04334), [HTML](https://arxiv.org/abs/2511.04334)
### Authors
Saúl Alonso-Monsalve,Leigh H. Whitehead,Adam Aurisano,Lorena Escudero Sanchez
### Background
在放射影像学（如CT）中对肿瘤进行精确分割是一项专门且耗时的任务，当前是阻碍在临床环境中进行定量分析的瓶颈。因此，开发自动分割肿瘤的影像方法至关重要并已受到近年来的广泛关注。然而，传统的卷积神经网络因三维扫描包含大量体素而难以处理，通常需要对图像进行下采样或使用其子集。针对这一问题，本文提出了一种新方法，该方法分为体素稀疏化和子流形稀疏卷积网络两个阶段，允许对高分辨率输入进行分割，并采用原生3D模型架构，同时显著减少了GPU内存和时间的需求。
### Innovation
本文提出了一种新的稀疏卷积网络方法，该方法解决了传统方法处理大体素图像的难题，通过两个阶段：体素稀疏化和子流形稀疏卷积。该方法实现了高分辨率输入下的分割和3D模型架构，同时在GPU内存和时间使用方面显著减少资源需求，获得最先进的准确性。
### Conclusion
在KI TS23挑战中对肾癌患者CT图像的研究表明，该方法与挑战获胜者具有竞争力，肾和肿瘤的Dice相似系数分别为95.8%和85.7%，并对肿瘤的相似系数为80.3%。此外，该方法还提供了显著的计算改进，与等效的密集架构相比，推理时间减少60%，VRAM使用量减少75%，适用于CPU和各种GPU卡。
## 361. `cs.CV` - MATLAB教程：结合化学计量学的深度特征提取在分析应用中的应用 [PDF](https://arxiv.org/pdf/2511.04349), [HTML](https://arxiv.org/abs/2511.04349)
### Authors
Puneet Mishra,Martijntje Vollebregt,Yizhou Ma,Maria Font-i-Furnols
### Background
在分析化学中，材料的空间信息通常通过成像技术捕获，如传统的彩色相机或先进的超光谱相机和显微镜。然而，有效提取和分析这些空间信息以用于探索和预测目的仍然是一项挑战，尤其是在使用传统的化学计量方法时。最近，深度学习和人工智能的发展显著提高了图像处理能力，使得捕获常规图像处理技术难以捕捉的多尺度深度特征成为可能。尽管开源深度学习模型的广泛应用，但在分析化学中的采用仍然有限，因为缺乏结构化的、逐步的指导来实施这些模型。
### Innovation
本教程通过提供一个逐步指南，将深度学习方法应用于从成像数据中提取空间信息，并将其与其他数据源（如光谱信息）集成。该工作的重点不是训练图像处理的深度学习模型，而是利用现有的开源模型从图像数据中提取深度特征。
### Conclusion
本教程提供了MATLAB代码示例，展示了从分析化学中常见的成像模态获取图像数据的处理过程。读者需要使用本教程中提供的代码在其自己的数据集上运行这些步骤。
## 362. `cs.CV` - 评估由天气引起的传感器遮挡对BEVFusion在3D物体检测中的影响 [PDF](https://arxiv.org/pdf/2511.04347), [HTML](https://arxiv.org/abs/2511.04347)
### Authors
Sanjay Kumar,Tim Brophy,Eoin Martino Grua,Ganesh Sistu,Valentina Donzella,Ciaran Eising
### Background
准确的3D物体检测对于自动驾驶车辆在复杂真实环境中的安全导航至关重要。Bird's Eye View (BEV)表示法将多传感器数据投影到顶部视角的空间格式中，已经成为稳健感知的强大方法。尽管基于BEV的融合架构通过多模态集成展示了强大的性能，但在恶劣天气条件下（如雾、烟雾或物理障碍物导致的传感器遮挡）对3D检测准确性的影响尚没有被充分研究。本文通过在nuScenes数据集上评估BEVFusion架构的性能，研究了遮挡对相机和激光雷达输出的影响。
### Innovation
本文的研究重点是在由恶劣天气条件引起的传感器遮挡情况下的3D物体检测性能变化。具体展示了遮挡对相机和激光雷达输出的不同影响，并揭示了融合设置中哪种传感器的遮挡对检测准确性的影响更大。
### Conclusion
研究表明，即使是在中等遮挡条件下，相机的遮挡也会导致精度显著下降，而对于激光雷达，重度遮挡才导致显著性能下降。融合环境中，遮挡对相机的影响较小，但对激光雷达的影响较大，显示了模型对激光雷达的依赖性更强。未来研究需要关注对遮挡的感知方法以及在恶劣环境条件下提高传感器融合技术的性能。
## 363. `cs.CV` - 消化道视觉接地推理中的多任务学习 [PDF](https://arxiv.org/pdf/2511.04384), [HTML](https://arxiv.org/abs/2511.04384)
### Authors
Itbaan Safwan,Muhammad Annas Shaikh,Muhammad Haaris,Ramail Khan,Muhammad Atif Tahir
### Background
本研究提出了一个针对MediaEval Medico 2025挑战的多任务框架，利用LoRA-调优的Florence-2模型同时进行视觉问答（VQA）、解释生成以及视觉定位。系统整合了三个精心准备的数据集：（1）Kvasir-VQA-x1，用于问答学习；（2）一个合成增强的解释数据集，提供结构化的医学推理；（3）文本-区域对，将视觉特征与分割掩码链接起来。该多任务架构使模型能够共同学习视觉定位、推理和解释，产生高效且可解析的响应。广泛的评估表明，这种方法在答案准确性及视觉定位上比单一任务基线显著提升，证明了语义相关多任务学习对医学VQA应用的有效性。
### Innovation
利用LoRA-调优的Florence-2模型，构建了一个整合视觉问答、解释生成和视觉定位的多任务框架。整合了三个精心准备的数据集，包括Kvasir-VQA-x1、合成增强的解释数据集、以及文本-区域对，实现在医学VQA任务上的多任务学习，提高了答案准确性和视觉定位效果。
### Conclusion
我们的方法在答案准确性和视觉定位方面显著优于单一任务基线，证明了语义相关的多任务学习在医疗VQA应用中的有效性。
## 364. `cs.CV` - RISE-T2V: 使用LLM进行扩展性文本到视频生成的重述和注入语义 [PDF](https://arxiv.org/pdf/2511.04317), [HTML](https://arxiv.org/abs/2511.04317)
### Authors
Xiangjun Zhang,Litong Gong,Yinglin Zheng,Yansong Liu,Wentao Jiang,Mingyi Xu,Biao Wang,Tiezheng Ge,Ming Zeng
### Background
大多数T2V扩散模型依赖预训练的文本编码器进行语义对齐，但在处理简洁的提示时，往往难以保持视频质量。主要问题是这些模型对文本语义的理解有限，且文本编码器无法在线重组提示以更好地与用户意图对齐，限制了模型的可扩展性和可用性。这些缺点导致现有模型难以有效应对用户需求，尤其是在视频质量保持与用户意图一致的方面存在不足。
### Innovation
该研究引入了RISE-T2V，该模型将提示重述和语义特征提取集成到一步中，而不是两个独立的步骤，解决了现有模型的上述问题。RISE-T2V设计了名为Rephrasing Adapter的新模块，允许扩散模型在LLM的下一个标记预测期间利用文本隐藏状态，作为视频生成的条件，从而可以使基本提示隐式转化为更全面的表示形式，并更好地匹配用户意图。此外，通过利用LLM的强大功能，模型能够执行更广泛的T2V任务。实验结果表明，RISE-T2V是一个多功能框架，适用于不同的视频扩散模型架构，显著增强了T2V模型生成高质量视频并与用户意图对齐的能力。
### Conclusion
RISE-T2V是一个增强的T2V模型框架，通过集成提示重述和语义特征提取以及引入Rephrasing Adapter模块，显著提高了模型在生成高质量视频并保持与用户意图一致方面的能力。该模型架构具有高度的通用性和扩展性，适用于多种预训练语言模型和视频扩散模型。
## 365. `cs.CV` - BoRe-Depth: 通过边界精炼实现嵌入式系统中无监督单目深度估计 [PDF](https://arxiv.org/pdf/2511.04388), [HTML](https://arxiv.org/abs/2511.04388)
### Authors
Chang Liu,Juan Li,Sheng Zhang,Chang Liu,Jie Li,Xu Zhang
### Background
单目深度估计是实现无人驾驶系统三维感知的关键技术之一。无监督单目深度估计因其成本低的优势而受到广泛关注，但现有方法在嵌入式系统上面临着深度估计性能差和目标边界模糊的挑战。
### Innovation
本文提出了一种新的单目深度估计模型BoRe-Depth，它仅包含8.7M参数，可以在嵌入式系统上准确估计深度图，并显著提高边界质量。模型创新点包括：1) 设计一种增强特征自适应融合模块(enhanced feature adaptive fusion module)来增强边界细节表示；2) 将语义知识集成到编码器中，以提高目标识别和边界感知能力；3) BoRe-Depth部署在NVIDIA Jetson Orin上，运行效率为50.7 FPS，显著优于先前轻量级模型。
### Conclusion
实验结果显示，提出的模型在多个具有挑战性的数据集上显著优于之前轻量级模型，提供了详细的消融研究。代码在此：https://github.com/example/repo.
## 366. `cs.CV` - 解决凸分割视觉拼图问题 [PDF](https://arxiv.org/pdf/2511.04450), [HTML](https://arxiv.org/abs/2511.04450)
### Authors
Yaniv Ohayon,Ofir Itzhak Shahar,Ohad Ben-Shahar
### Background
拼图问题需要将无序排列的拼图碎片重新排列回原始位置，以重建原来的完整图案，通常是一个图像。这是一个被认为无解的问题。虽然自动拼图解谜器的应用前景广阔，但大多数文献主要集中在方形拼图的解谜上，限制了其实际应用。本文旨在扩展计算机处理的拼图类型，针对凸分割拼图，这是一种多边形拼图的主要子集，拼图碎片为凸形。
### Innovation
利用几何和图像兼容性，引入贪婪解谜器，并提供了第一个此类拼图的基准数据集，以供性能评估。
### Conclusion
本文显著扩展了计算处理的拼图类型，具体关注凸分割拼图，这是一种多边形拼图的主要子集。通过利用几何和图像兼容性，提出了一种贪婪解谜器，并提供了第一个此类拼图的基准数据集以衡量性能。
## 367. `cs.CV` - DORAEMON: 一种统一的视觉物体建模和表示学习大规模库 [PDF](https://arxiv.org/pdf/2511.04394), [HTML](https://arxiv.org/abs/2511.04394)
### Authors
Ke Du,Yimin Peng,Chao Gao,Fan Zhou,Siqiao Xue
### Background
当前存在视觉对象建模和表示学习在不同尺度上的分离现象，缺乏统一的工具来覆盖分类、检索和度量学习等多种任务。同时，研究者们在不同软件库和平台之间切换时遇到了重重困难，这限制了研究进展和成果的实际应用。因此，需要一个统一的公开源代码库来整合这些任务，并简化复杂的研究流程，提高实验的可复现性和结果的可靠性，同时能够将研究成果快速有效地应用到实际应用中去。
### Innovation
DORAEMON 是一个开源的 PyTorch 库，统一了视觉对象建模和表示学习在不同尺度上的应用。它使用单个 YAML 驱动的工作流程来完成分类、检索和度量学习的任务。该库还提供了超过 1000 个预训练的 backbones，通过一个与 timm 相兼容的接口进行访问，同时提供模块化的损失函数、增强和分布式训练工具。DORAEMON 的可复现食谱在 ImageNet-1K、MS-Celeb-1M 和 Stanford 在线产品上的结果至少与参考结果相当，同时支持一命令导出到 ONNX 或 HuggingFace，可以实现研究与部署之间的桥梁。通过汇集数据集、模型和训练技术，DORAEMON 提供了一个可扩展的基础平台，加速了视觉识别和表示学习的研究实验，促进了研究的高效迁移至实际应用中。
### Conclusion
DORAEMON 通过统一视觉对象建模和表示学习的任务，提供了一个可复现、高效和灵活的研究工具，极大地简化了复杂的研究流程，提高了实验的效率和结果的可靠性，为研究者之间提供了交流和共享的机会，从而促进了这一领域的发展。
## 368. `cs.CV` - HideAndSeg：自然栖息地中八爪鱼分割的基于自动提示的AI工具 [PDF](https://arxiv.org/pdf/2511.04426), [HTML](https://arxiv.org/abs/2511.04426)
### Authors
Alan de Aguiar,Michaella Pereira Andrade,Charles Morphy D. Santos,João Paulo Gois
### Background
在自然栖息地中分析八爪鱼极具挑战性，因为它们具有伪装能力，皮肤纹理和颜色快速变化，非刚性形体变形，以及频繁被遮挡。另外，水下光照和浑浊度的变化也增加了难度。由于缺乏大规模标注数据集，该研究引入了HideAndSeg，这是一种新型的、最少监督的人工智能工具，用于分割八爪鱼视频。该工具为这一任务建立了量化基准。
### Innovation
HideAndSeg 结合了 SAM2 和自定义训练的 YOLOv11 对象检测器。它首先让用户提供点坐标以生成初始分割掩码，然后利用 SAM2 提供边界框提示完全自动化该过程，无需进一步的手动干预。该研究提出了两个无监督指标——时间一致性 DICE_t 和新组件计数 NC_t，用于在没有真实数据的情况下量化分割质量并指导掩码优化。HideAndSeg 能够在自然环境中即使八爪鱼完全被遮挡后也能重新识别和分割八爪鱼，而手动提示模型在这种情况下会失败。这种方法减少了真实世界场景中手动分析的需求，提供了用于更高效研究野生头足类动物行为的实用工具。
### Conclusion
HideAndSeg 完成了对八爪鱼的自动分割，减少了分割噪声，特别是在自然环境中的完全遮挡场景下，仍能识别和分割八爪鱼。相比手动提示的方法，这种方法提供了更高效的分析工具，为野生头足类动物的行为研究铺平了道路。
## 369. `cs.CV` - THEval. 生成模型评估框架用于谈话头视频生成 [PDF](https://arxiv.org/pdf/2511.04520), [HTML](https://arxiv.org/abs/2511.04520)
### Authors
Nabyl Quignon,Baptiste Chopin,Yaohui Wang,Antitza Dantcheva
### Background
视频生成已经取得了显著的进步，生成的视频越来越接近真实。然而，生成方法的发展速度已经超越了评估方法的发展，目前对谈话头生成的评估主要依赖有限的几个指标，评估视频的整体质量、唇同步，并进行用户研究。
### Innovation
提出了一种新的评估框架，包括与三个维度相关的8个指标：(i)质量，(ii)自然度，(iii)同步。在选择指标时重视效率和与人类偏好的一致性，以分析头部、嘴巴、眉宇的精细动态以及面部质量。实验基于一个新制作的真实数据集，以减轻数据偏差。 
### Conclusion
对17个最先进的模型生成的85,000个视频进行了实验，结果表明，许多算法在唇同步方面表现出色，但在生成表现力和无artifact细节方面存在挑战。我们将发布原始代码、数据集和排行榜，并定期更新以反映领域的发展进步。
## 370. `cs.CV` - 使用地球空间基础模型进行滑坡灾害制图：地理普遍性、数据匮乏与波段适应性 [PDF](https://arxiv.org/pdf/2511.04474), [HTML](https://arxiv.org/abs/2511.04474)
### Authors
Wenwen Li,Sizhe Wang,Hyunho Lee,Chenyan Lu,Sujit Roy,Rahul Ramachandran,Chia-Yu Hsu
### Background
滑坡对人类生命、基础设施和环境造成严重破坏，准确及时地绘制滑坡地图对于灾害准备和响应至关重要。然而，传统的深度学习模型在不同传感器、区域或有限训练数据条件下应用时常常表现不佳。
### Innovation
本文提出一个三维分析框架，涵盖传感器、标签和领域，以适应地理空间基础模型（GeoFMs），尤其是针对Prithvi-EO-2.0进行滑坡制图。实验表明，该模型在一致性能方面优于特定任务的CNN（U-Net，U-Net++）、视觉变换器（Segformer，SwinV2-B）及其他GeoFMs（TerraMind，SatMAE）。该模型基于全球预训练、自我监督和适应性微调，能够应对光谱差异，维持在标签稀缺情况下的准确性，并在多样数据集和地理设置中表现更稳定的泛化能力。
### Conclusion
我们研究将GeoFMs定位为更稳健和可扩展的滑坡风险降低和环境监测方法的一个进步。然而，计算成本高和可用于滑坡研究的可重用AI训练数据稀缺仍然是存在的挑战。
## 371. `cs.CV` - V-Thinker：基于图像的互动思考 [PDF](https://arxiv.org/pdf/2511.04460), [HTML](https://arxiv.org/abs/2511.04460)
### Authors
Runqi Qiao,Qiuna Tan,Minghan Yang,Guanting Dong,Peiqing Yang,Shiqiang Lang,Enhui Wan,Xiaowan Wang,Yida Xu,Lan Yang,Chong Sun,Chen Li,Honggang Zhang
### Background
在该领域中，使大型多模态模型（LMMs）深入整合图像交互并具备远期推理能力仍然是一个长期挑战。最近在视觉中心推理方面的进展探索了一种有前景的“以图像思考”范式，这标志着从图像辅助推理到图像互动思维的转变。虽然这一里程碑使得模型能够聚焦于细粒度的图像区域，但进展仍然受到有限的视觉工具空间和特定任务工作流程设计的限制。
### Innovation
我们提出了V-Thinker，这是一种通用的多模态推理助理，通过端到端的强化学习实现互动、视觉中心的思考。V-Thinker包括两个关键组件：1）数据演化飞轮，自动合成、演化和验证跨三个维度（多样性和质量及难度）的互动推理数据集；2）视觉进步训练课程，首先通过点级监督对感知进行对齐，然后通过两阶段的强化学习框架进行互动推理的整合。此外，还介绍了VTBench，这是一个由专家验证的基准测试，针对基于视觉的互动推理任务。
### Conclusion
广泛的实验表明，V-Thinker在一般和互动推理场景中均能稳定地优于强大的LMM基线，为推动图像互动推理应用的发展提供了宝贵见解。
## 372. `cs.CV` - 单时点学习：腹腔镜胆囊切除手术复杂性评估 [PDF](https://arxiv.org/pdf/2511.04525), [HTML](https://arxiv.org/abs/2511.04525)
### Authors
Dimitrios Anastasiou,Santiago Barbarisi,Lucy Culshaw,Jayna Patel,Evangelos B. Mazomenos,Imanol Luengo,Danail Stoyanov
### Background
在腹腔镜胆囊切除术(LC)中，严重的炎症与较长的手术时间和更高的术后并发症风险相关。Parkland评分(Parkland Grading Scale, PGS)提供了一种临床验证的评估炎症严重程度的框架，但其在手术视频中的自动化应用在现实场景中仍然很少被探索。特别是在需要直接分析完整视频而无需事先手动筛选的情况下。
### Innovation
本文提出了一种新的框架STC-Net（SingleTimestamp-based Complexity estimation for LC via PGS），用于手术视频中单时点复杂性评估，能够直接在不依赖静态图像或人工剪辑片段的情况下运行。该框架通过时空定位模块和评分模块联合进行时空定位和评分，引入了一种结合硬定位和软定位目标以及背景意识评分监督的新损失函数。
### Conclusion
STC-Net在LC手术视频的复杂性评估中展示了可扩展且有效的方法，它能够从完整的LC手术视频中自动进行PGS基础上的复杂性评估，为术后分析和手术培训提供了积极的展望。
## 373. `cs.CV` - UniSplat: 统一空时融合通过3D潜支架进行动态驾驶场景重建 [PDF](https://arxiv.org/pdf/2511.04595), [HTML](https://arxiv.org/abs/2511.04595)
### Authors
Chen Shi,Shaoshuai Shi,Xiaoyang Lyu,Chunyang Liu,Kehua Sheng,Bo Zhang,Li Jiang
### Background
自动驾驶中向前馈3D重建技术取得了快速进步，但现有方法对于稀疏且不重叠的摄像头视角与复杂场景动态性具有挑战。
### Innovation
提出了一种通用的前馈框架UniSplat，该框架通过统一的时空融合机制学习稳健的动态场景重建。UniSplat构建了一个3D潜支架，这是一种结构化的表示形式，利用预训练的基础模型捕获几何和语义场景上下文。还引入了一种高效的融合机制，直接在3D支架内操作，确保时空对齐的一致性。设计了双分支解码器，该解码器通过结合点锚定细化与体素生成来从融合支架中生成动态意识的高斯分布，并保持静态高斯的持久记忆，以实现超出当前摄像头覆盖范围的流式场景完成。
### Conclusion
在实际数据集上的广泛实验表明，UniSplat在新颖视角合成方面达到了最先进的性能，即使对于超出原始摄像头覆盖范围的视角也提供了健壮且高质量的渲染结果。
## 374. `cs.CV` - 思考与视频：视频生成作为有希望的多模态推理范式 [PDF](https://arxiv.org/pdf/2511.04570), [HTML](https://arxiv.org/abs/2511.04570)
### Authors
Jingqi Tong,Yurong Mou,Hangcheng Li,Mingzhe Li,Yongzhuo Yang,Ming Zhang,Qiguang Chen,Tianyi Liang,Xiaomeng Hu,Yining Zheng,Xinchi Chen,Jun Zhao,Xuanjing Huang,Xipeng Qiu
### Background
现有的“思考与文本”和“思考与图像”范式显著提高了大语言模型（LLMs）和视觉语言模型（VLMs）的推理能力。然而，这些范式存在固有的局限性：图像仅捕捉单个瞬间，无法表现动态过程或连续变化；文本和视觉作为不同的模态分离，阻碍了统一多模态理解和生成。为克服这些局限，本文提出“思考与视频”范式，利用如Sora-2等视频生成模型，在统一的时间框架内结合视觉和文本推理。为此，我们开发了VideoThinking基准测试（VideoThinkBench），包含视觉中心任务（如眼动谜题）和文本中心任务（如GSM8K和MMMU的子集）。
### Innovation
本文提出“思考与视频”新范式，利用视频生成模型Sora-2，以统一时间框架结合视觉和文本推理。开发了VideoThinkBench基准测试，包含视觉中心和文本中心任务，评估Sora-2在多模态推理中的能力。
### Conclusion
研究结果表明，视频生成模型具有统一多模态理解和生成的潜力，定位“思考与视频”为统一多模态推理范式。
## 375. `cs.CV` - Polarization-resolved imaging improves eye tracking [PDF](https://arxiv.org/pdf/2511.04652), [HTML](https://arxiv.org/abs/2511.04652)
### Authors
Mantas Žurauskas,Tom Bu,Sanaz Alali,Beyza Kalkanli,Derek Shi,Fernando Alamos,Gauresh Pandit,Christopher Mei,Ali Behrooz,Ramin Mirjalili,Dave Stronks,Alexander Fix,Dmitri Model
### Background
传统的近红外成像技术通过测量光的强度来实现眼球追踪，但这种方法存在一些限制，如在眼睑闭合、眼距变化和瞳孔大小变化的情况下，准度会受到影响。
### Innovation
本文展示了利用偏振成像技术通过测量反射光的偏振状态来增强眼球追踪的方法。偏振启用的眼球追踪系统由带偏振滤波阵列的相机和线性偏振近红外光源组成，能够揭示巩膜和角膜上的可追踪特征和视线相关信息，在仅有强度信息的情况下，这些特征和信息在强度图像中是不可见的。基于卷积神经网络的机器学习模型在不同条件下，使用偏振成像技术的眼球追踪系统相比仅使用强度信息的眼球追踪系统的准确度提高了10-16%。
### Conclusion
本文的研究结果将光线-组织偏振效应与提升人机交互的实用性联系起来，并将透射光偏振增强的眼球追踪（PET）定位为一种简单可靠的传感模态，适用于未来可穿戴设备。
## 376. `cs.CV` - PixCLIP：通过任意粒度的像素-文本对齐学习实现精细视觉语言理解 [PDF](https://arxiv.org/pdf/2511.04601), [HTML](https://arxiv.org/abs/2511.04601)
### Authors
Yicheng Xiao,Yu Chen,Haoxuan Ma,Jiale Hong,Caorui Li,Lingxiang Wu,Haiyun Guo,Jinqiao Wang
### Background
尽管Contrastive Language-Image Pretraining (CLIP) 模型在各种下游视觉语言理解任务中取得了显著的成功，提高其细粒度图像-文本对齐的能力仍然是一个活跃的研究重点。现有大多数工作通过显式增加视觉信息处理的精细度来提升CLIP模型的能力，例如引入视觉提示以引导模型关注图像中的特定局部区域。虽然关于多模态大语言模型（MLLMs）的研究表明利用长而详细的文本描述可以有效改善模型的细粒度视觉-语言对齐，但是CLIP文本编码器固有的词汇长度限制限制了CLIP处理长文本序列内嵌的细粒度文本信息的能力。因此，协同利用增强视觉和文本内容处理精细度的优势，提出PixCLIP框架，该框架能够同时容纳视觉提示输入并处理长文本描述。具体的实现方案包括建立自动标注流水线生成像素级局部化的长文本描述，并构建包含近150万个样本的高质量数据集，以及将CLIP原始文本编码器替换为大语言模型，并提出一个包含三个分支的像素-文本对齐学习框架，促进图像区域与对应文本描述在任意粒度下的精细对齐。实验表明，PixCLIP在像素级交互和处理长文本方面取得了突破，并达到最先进的性能。
### Innovation
提出了PixCLIP框架，该框架能够同时容纳视觉提示输入并处理长文本描述。具体内容包括建立自动标注流水线生成像素级局部化的长文本描述，构建包含近150万个样本的高质量数据集，将CLIP原始文本编码器替换为大语言模型，并提出一个包含三个分支的像素-文本对齐学习框架，促进图像区域与对应文本描述在任意粒度下的精细对齐。通过协同利用增强视觉和文本内容处理精细度的优势，PixCLIP实现了像素级交互和长文本处理能力的突破，达到了最先进的性能。
### Conclusion
实验结果表明，PixCLIP在像素级交互和处理长文本方面取得了突破性进展，实现了在图像-文本对齐方面的最先进的性能。
## 377. `cs.CV` - 在虚拟免疫组织化学中的信任构建：图像质量的自动化评估 [PDF](https://arxiv.org/pdf/2511.04615), [HTML](https://arxiv.org/abs/2511.04615)
### Authors
Tushar Kataria,Shikha Dubey,Mary Bronner,Jolanta Jedrzkiewicz,Ben J. Brintz,Shireen Y. Elhabian,Beatrice S. Knudsen
### Background
深度学习模型可以从HE（苏木精和伊红）染色图像中生成虚拟免疫组织化学（IHC）染色，这为实验室IHC提供了一种可扩展且低成本的替代方案。然而，当前的纹理和分布度量评估图像质量的方式主要衡量图像保真度而非IHC染色的准确性，这使得可靠的图像质量评价变得具有挑战性。
### Innovation
文章介绍了一种自动化且基于准确性的框架，用于评估16个配对或非配对图像转换模型中的图像质量。通过颜色去卷积生成每个虚拟IHC模型预测的像素遮罩，使用真实和虚拟IHC的分割掩膜来计算标记准确性度量（Dice、IoU、Hausdorff距离），从而直接量化像素级别的正确标签而无需专家人工标注。结果表明，传统的图像保真度度量（如Frechet Inception Distance (FID)、峰值信噪比（PSNR）和结构相似度（SSIM））与染色准确性及病理学家评估的相关性较低。配对模型如PyramidPix2Pix和AdaptiveNCE在染色准确性上表现出色，而基于扩散和GAN的非配对模型在提供准确的IHC阳性像素标签方面可靠性较差。此外，整个组织切片图像在基于局部块的评估中无法揭示的问题强调了整个组织切片（WSI）层面上基准的重要性。
### Conclusion
这一框架为评估虚拟IHC模型的质量提供了一种可重复的方法，这是一个关键步骤，可以加速其向病理科的应用。
## 378. `cs.CV` - NovisVQ：一种用于无参考无观点帧质量评估的流式卷积神经网络 [PDF](https://arxiv.org/pdf/2511.04628), [HTML](https://arxiv.org/abs/2511.04628)
### Authors
Kylie Cancilla,Alexander Moore,Amar Saini,Carmen Carrano
### Background
现有视频质量评估（VQA）方法存在重大限制，如全参考（FR）度量需要干净的参考视频，大多数无参考（NR）模型依赖昂贵的人类意见标签。此外，大多数无观点的NR方法是基于图像的，忽略了对视频目标检测至关重要的时间上下文。
### Innovation
提出了一种可扩展的、基于流式的VQA模型，该模型是无参考且无观点的。该模型利用DAVIS数据集的合成降级，训练了一个时间感知的卷积架构，可以直接从降级视频中预测FR度量（LPIPS、PSNR、SSIM），在推理时无需参考。该方法展示了在跨多种降级类型泛化方面优于自身的基于图像的基线，强调了时间建模对于大型VQA系统必不可少的价值。同时，该模型在与广泛使用的意见感知图像质量评估基准BRISQUE的相关性方面表现更好，验证了其时间无意见的方法的有效性。
### Conclusion
展示了该流式方法在广泛VQA应用中的优越性，并进一步验证了时间建模对无参考VQA的重要性。
## 379. `cs.CV` - SIMS-V: 通过模拟指令调优的空间视频理解 [PDF](https://arxiv.org/pdf/2511.04668), [HTML](https://arxiv.org/abs/2511.04668)
### Authors
Ellis Brown,Arijit Ray,Ranjay Krishna,Ross Girshick,Rob Fergus,Saining Xie
### Background
尽管目前的多模态语言模型在高层次的视频理解方面取得了显著进展，但在时间和空间中的空间推理方面仍然存在不足。当前的空间训练方法主要依赖真实的视频数据，但由于获得具有精确空间注解的多样化脚本仍然存在瓶颈。
### Innovation
我们提出了一种名为SIMS-V的系统数据生成框架，利用3D模拟器提供的特权信息，生成具有丰富空间信息的视频训练数据，以辅助多模态语言模型。通过系统的消融实验，我们发现了对于培养可转移的空间智能最有效的三个问题类别：度量测量、视野依赖性推理和时间跟踪。7B参数的视频LLM仅使用25K模拟样例进行了微调，超过了72B参数的基线模型，并在严格的现实世界空间推理基准测试中达到了具有竞争力的表现。
### Conclusion
我们的方法展示了强大的通用性，在一般的视频理解中保持性能，同时在执行体感和现实世界的空间任务时显示出显著的改进。
## 380. `cs.CV` - Carousel: 一个高分辨率的数据集用于多目标自动图像裁剪 [PDF](https://arxiv.org/pdf/2511.04680), [HTML](https://arxiv.org/abs/2511.04680)
### Authors
Rafe Loya,Andrew Hamara,Benjamin Estell,Benjamin Kilpatrick,Andrew C. Freeman
### Background
自动图像裁剪是一种方法，用于最大化照片中裁剪区域的人类感知质量。尽管已有许多工作提出了生成单一裁剪的技术，但很少有研究关注生成多个具有美学吸引力的裁剪区域的问题。本文通过讨论现代社交媒体应用来阐述该问题，并提供了一个包含277张相关图片及其人类标注的数据集，使用图像分割算法作为预处理步骤来评估数个单裁剪模型的效果。
### Innovation
本文首次提出了一个用于多目标自动图像裁剪的高分辨率数据集，并结合图像分割算法作为一种预处理手段，评估了多个单裁剪模型的有效性。
### Conclusion
本文通过提供一个包括277张相关图片及其人类标注的数据集及结合图像分割作为预处理步骤，证明了可以有效地评估多个单裁剪模型在多目标自动图像裁剪中的效果。
## 381. `cs.CV` - 跟踪和理解物体变换 [PDF](https://arxiv.org/pdf/2511.04678), [HTML](https://arxiv.org/abs/2511.04678)
### Authors
Yihong Sun,Xinyu Yang,Jennifer J. Sun,Bharath Hariharan
### Background
现实世界的物体经常会发生状态改变，从苹果被切开到蝴蝶从茧中出来，这些变化的追踪对于理解物体和动态非常重要。然而，现有的方法在物体发生变换后往往会丢失跟踪目标物体，主要是由于物体外观发生了显著变化。
### Innovation
为了应对这一限制，本文引入了Track Any State任务，即通过变换跟踪物体并在过程中检测和描述状态变化。为此，提出了一种名为TubeletGraph的零样本系统，该系统可以在变换后恢复丢失的物体，映射物体状态随时间的变化过程。
### Conclusion
TubeletGraph在变换下的跟踪性能达到了最新水平，还展示了对物体变换的更深层次的理解，并展示了在复杂物体变换方面的临时语义定位和语义推理的潜力。
## 382. `cs.CV` - Cambrian-S: 向视频中的空间超感知迈进 [PDF](https://arxiv.org/pdf/2511.04670), [HTML](https://arxiv.org/abs/2511.04670)
### Authors
Shusheng Yang,Jihan Yang,Pinzhi Huang,Ellis Brown,Zihao Yang,Yue Yu,Shengbang Tong,Zihan Zheng,Yifan Xu,Muhan Wang,Daohan Lu,Rob Fergus,Yann LeCun,Li Fei-Fei,Saining Xie
### Background
当前的多模态智能系统大多反应性强、任务驱动，依赖于长时间的大规模上下文记忆。现有的基准测试主要评估早期阶段的能力，缺乏对复杂空间感知和真实世界建模的全面覆盖。因此，真实空间超感知技术需要朝着扩大感知范式的方向发展，涉及空间的多阶段认识，包括语义感知、事件认知、隐式空间认知和预测世界建模。然而，现有的基准测试在挑战模型进行真实世界建模方面做得不够充分。
### Innovation
该研究提出了Cambrian-S，这是一个两部分的基准测试，包括长视野视觉空间回忆(VSR)和持续视觉空间计数(VSC)，这些任务需要处理任意时长的视频输入，但又难以通过简单地扩展上下文规模来解决。研究通过收集VSI-590K数据集和训练Cambrian-S模型，实现了在VSI-Bench上绝对提升了30%的表现，同时还保留了通用能力。此外，研究提出预测性感知作为一种前进途径，展示了通过自我监督的下一个潜空间帧预测器利用预测误差来驱动记忆和事件分割的方法，这种新方法在VSI-SUPER上的表现显著优于现有的领先自定义基线模型。
### Conclusion
尽管通过大规模训练已经显著提升了视觉空间能力，但即将到来的时空感知还远远不足。研究得出结论：简单的数据规模扩展不足以实现空间超感知，预测性感知将是未来进展的关键路径。
## 383. `cs.CV` - InfinityStar: 统一时空自回归建模在视觉生成中的应用 [PDF](https://arxiv.org/pdf/2511.04675), [HTML](https://arxiv.org/abs/2511.04675)
### Authors
Jinlai Liu,Jian Han,Bin Yan,Hui Wu,Fengda Zhu,Xing Wang,Yi Jiang,Bingyue Peng,Zehuan Yuan
### Background
在视觉和语言领域，自回归建模最近取得了显著成功。现有的自回归模型通常将空间依赖性和时间依赖性分别处理，缺乏统一的方法来同时处理这两种类型的依赖性。本文提出了InfinityStar，一种统一的空间-时间自回归框架，用于高分辨率的图像和动态视频合成。
### Innovation
InfinityStar框架采用纯粹离散的方法，同时捕捉空间和时间依赖性，并在一个架构中联合进行建模。这种统一的设计支持多种生成任务，如文本到图像、文本到视频、图像到视频和长时间交互式视频合成，通过简单的时序自回归实现。实验表明，InfinityStar在VBench上的得分高达83.74，超过所有自回归模型，并超过了一些竞争扩散模型如HunyuanVideo。与领先基于扩散的方法相比，没有任何额外优化的情况下，该模型生成5秒720p视频的速度快约10倍。在我们所知的研究中，InfinityStar是第一个能生成工业级720p视频的离散自回归视频生成器。
### Conclusion
我们发布了所有代码和模型，以促进高效、高质量视频生成的进一步研究。InfinityStar的设计不仅提高了生成质量，还大大提升了生成速度，展示了其在视觉生成领域的创新性和实用性。
## 384. `cs.CV` - 基准设计师应该在测试集上进行训练以揭示可利用的非视觉捷径 [PDF](https://arxiv.org/pdf/2511.04655), [HTML](https://arxiv.org/abs/2511.04655)
### Authors
Ellis Brown,Jihan Yang,Shusheng Yang,Rob Fergus,Saining Xie
### Background
目前，强大的多模态大型语言模型（MLLMs）评估标准对于确保模型确实理解视觉输入至关重要。然而，研究发现许多模型能够通过隐藏的捷径、语言先验和表面模式等手段在多模态基准测试上表现出色，而无需强大的视觉理解能力。对于设计者而言，理想的基准测试应该是能够揭示视觉处理模型的真正能力。因此，标准的基准测试设计需要能够防止被利用，设计者首先应该模仿潜在的捷径，使用诊断和解偏技术来系统地识别和减轻非视觉偏差。直接在测试集上“训练”是最有效的方法，即通过探索测试集的内在、可利用模式来检查其表现。作者基于此标准制定了两个部分：首先使用“测试集压力测试”（TsT）方法诊断基准测试的脆弱性；其次通过迭代的偏差修剪（IBP）程序解除了高偏见样本，提取出非视觉偏差。
### Innovation
提出了‘测试集压力测试’（TsT）和‘迭代的偏差修剪’（IBP）两种方法来系统地识别及减轻非视觉偏差。TsT方法通过k折交叉验证精细调用大型语言模型来揭示测试集上的捷径表现，并为每个样本打上偏见评分。此外，IBP程序通过过滤高偏见样本来去偏基准测试。这项研究还特别关注四个基准测试：VSI-Bench，CV-Bench，MMMU，以及VideoMME，并发现普遍存在非视觉偏差，通过应用整个框架，创建了VSI-Bench-Debiased基准，进一步减少了非视觉可解性，并扩大了纯视觉能力表现的差距.
### Conclusion
基准测试设计师应该首先通过‘测试集压力测试’尝试游戏自己的基准测试，识别可利用的非视觉捷径；并通过‘迭代的偏差修剪’程序去除高偏见样本，去除了非视觉偏差。应用这种方法到四个基准测试后，通过VSI-Bench-Debiased展示了非视觉解题难度降低，以及测试集与真实环境之间更显著的差距，表明这种方法能够有效评估模型的真正能力。
## 385. `cs.CV` - 基于深度学习的卷积神经网络方法进行模型分类选择 [PDF](https://arxiv.org/pdf/2511.03743), [HTML](https://arxiv.org/abs/2511.03743)
### Authors
Marios Impraimakis
### Background
本文研究了一种新颖的深度卷积神经网络方法在仅依靠响应信号及其类信息进行一维卷积神经网络训练与验证的能力。这种方法能够在无需使用系统输入信息或进行完全系统识别的情况下，选择新且未标记信号的模型类别。此外，通过卡尔曼滤波算法增强该方法，结合加速度和位移数据的动力学约束条件，进一步优化了响应信号的融合。这种方法能够识别信号中的细微变化，这些变化反映出阻尼行为或滞回行为，适用于线性与非线性动态系统，以及3D建筑有限元模型的健康监测应用。
### Innovation
该方法仅依靠响应信号及其类信息进行一维卷积神经网络的训练与验证，无需系统输入信息或完全系统识别。通过卡尔曼滤波算法增强该方法，结合动力学约束条件，优化了响应信号的融合。这种方法能够识别并分类由于阻尼或滞回行为导致的只有细微变化的信号，适用于多种动态系统和结构健康监测应用。
### Conclusion
该方法成功地在动态系统中实现模型级别的自动分类，并识别出由于系统阻尼或滞回行为导致的轻微响应信号变化。该技术为结构健康监测提供了一种强大的工具，适用于线性与非线性动态系统及3D有限元模型。
## 386. `cs.CV` - 使用二维投影训练的物理信息神经网络增强计算机断层扫描（CT）心血管流速估计：一项模拟研究 [PDF](https://arxiv.org/pdf/2511.03876), [HTML](https://arxiv.org/abs/2511.03876)
### Authors
Jinyuxuan Guo,Gurnoor Singh Khurana,Alejandro Gonzalo Grande,Juan C. del Alamo,Francisco Contijoch
### Background
非侵入性成像技术评估血液流动在心脏功能和结构评估中发挥着关键作用。尽管CT是一种广泛用于评估心血管解剖结构和功能的成像技术，但在从含对比剂的电影中直接估算血液流速方面尚未开发出有效的方法。
### Innovation
本文提出了一种称为SinoFlow的新框架，该框架直接利用二维投影数据而非重建图像来估算血液流速，从而在各项测试中表现出更高的准确性和鲁棒性，特别是在脉冲模式成像中表现出色。
### Conclusion
研究表明，SinoFlow在CT基于的流速估计中具有潜力，为非侵入性血液流速评估提供更可靠的途径。该研究旨在为未来使用物理信息神经网络处理CT图像的应用奠定基础，并提供一种基于图像的流速估算解决方案。
## 387. `cs.CV` - 回归与分类的等价性 [PDF](https://arxiv.org/pdf/2511.04422), [HTML](https://arxiv.org/abs/2511.04422)
### Authors
Jayadeva,Naman Dwivedi,Hari Krishnan,N.M. Anoop Krishnan
### Background
在统计学习理论中，回归和分类之间的正式联系是脆弱的。尽管支持向量回归中使用了边距最大化项$boldsymbol{w}$的范数，但这种做法只被作为一种正则化手段。本文通过证明一个回归问题在满足特定条件时等价于一个分类问题，揭示了一种新的正则化回归方法。
### Innovation
作者提出了一个回归和分类之间的等价关系，具体来说，在给定一定条件下，一个具有M个样本的回归问题与一个具有2M个样本的线性可分分类问题具有一一对应关系。利用这种等价性，可以提出一种衡量数据集回归难度的指标，并且通过这种方法训练神经网络来学习线性化映射，从而在新的空间中采用线性回归模型。
### Conclusion
本文利用回归和分类问题的等价性，提出了一种新型的回归方法，并利用这种等价关系构建了一个评估数据集回归难易程度的指标，并通过训练神经网络学习线性化映射来改进模型性能。
## 388. `cs.CV` - NVIDIA Nemotron Nano V2 VL [PDF](https://arxiv.org/pdf/2511.03929), [HTML](https://arxiv.org/abs/2511.03929)
### Authors
NVIDIA:Amala Sanjay Deshmukh,Kateryna Chumachenko,Tuomas Rintamaki,Matthieu Le,Tyler Poon,Danial Mohseni Taheri,Ilia Karmanov,Guilin Liu,Jarno Seppanen,Guo Chen,Karan Sapra,Zhiding Yu,Adi Renduchintala,Charles Wang,Peter Jin,Arushi Goel,Mike Ranzinger,Lukas Voegtle,Philipp Fischer,Timo Roman,Wei Ping,Boxin Wang,Zhuolin Yang,Nayeon Lee,Shaokun Zhang,Fuxiao Liu,Zhiqi Li,Di Zhang,Greg Heinrich,Hongxu(Danny)Yin,Song Han,Pavlo Molchanov,Parth Mannan,Yao Xu,Jane Polak Scowcroft,Tom Balough,Subhashree Radhakrishnan,Paris Zhang,Sean Cha,Ratnesh Kumar,Zaid Pervaiz Bhat,Jian Zhang,Darragh Hanley,Pritam Biswas,Jesse Oliver,Kevin Vasques,Roger Waleffe,Duncan Riach,Oluwatobi Olabiyi,Ameya Sunil Mahabaleshwarkar,Bilal Kartal,Pritam Gundecha,Khanh Nguyen,Alexandre Milesi,Eugene Khvedchenia,Ran Zilberstein,Ofri Masad,Natan Bagrov,Nave Assaf,Tomer Asida,Daniel Afrimi,Amit Zuker,Netanel Haber,Zhiyu Cheng,Jingyu(Justin)Xin, Di (Allan)Wu,Nik Spirin,Maryam Moosaei,Roman Ageev,Vanshil Atul Shah,Yuting Wu,Daniel Korzekwa,Unnikrishnan Kizhakkemadam Sreekumar,Wanli Jiang,Padmavathy Subramanian,Alejandra Rico,Sandip Bhaskar,Saeid Motiian,Kedi Wu,Annie Surla,Chia-Chih Chen,Hayden Wolff,Matthew Feinberg,Melissa Corpuz,Marek Wawrzos,Eileen Long,Aastha Jhunjhunwala,Paul Hendricks,Farzan Memarian,Benika Hall,Xin-Yu Wang,David Mosallanezhad,Soumye Singhal,Luis Vega,Katherine Cheung,Krzysztof Pawelec,Michael Evans,Katherine Luna,Jie Lou,Erick Galinkin
### Background
NVIDIA发布了Nemotron Nano V2 VL，这是Nemotron视觉-语言系列的最新型号，旨在实现强大的现实世界文档理解、长时间视频理解以及逻辑推理任务。该模型是对之前模型Llama-3.1-Nemotron-Nano-VL-8B的重要改进，尤其是在视觉和文本领域均表现出显著提高，这是通过模型架构、数据集和训练策略的重大提升实现的。
### Innovation
Nemotron Nano V2 VL是一款混合Mamba-Transformer语言模型，集成了创新性的标记减少技术，以提高长文档和视频场景下的推理性能。模型提供BF16、FP8和FP4格式的模型检查点，还分享了大量的数据集、方法和训练代码，增强了研究和应用的可及性。
### Conclusion
NVIDIA通过改进模型架构、数据集和训练策略，在视觉和文本领域取得了显著进步，发布了Nemotron Nano V2 VL，提高了长时间文档和视频场景下的推理速度，并提供了多种高精度格式的模型检查点和强大的研究工具，供用户研究和使用。
## 389. `cs.CV` - GraSP-VLA: 基于图的符号化动作表示在VLA策略下的长时规划 [PDF](https://arxiv.org/pdf/2511.04357), [HTML](https://arxiv.org/abs/2511.04357)
### Authors
Maëlic Neau,Zoe Falomir,Paulo E. Santos,Anne-Gwenn Bosser,Cédric Buche
### Background
自主机器人从演示学习新技能是现代机器人学的重要挑战。现有解决方案通常使用端到端模仿学习的Vision-Language Action (VLA)模型或行为模型学习(AML)的符号化方法。VLA模型受限于缺乏高层次的符号规划，限制了它们在长时任务上的能力；而符号化的AML方法缺乏泛化性和可扩展性。
### Innovation
提出了一种新的神经-符号方法GraSP-VLA，它使用连续场景图表示法生成演示的符号表示。这种表示在推理过程中用于生成新的规划领域，并为低级VLA策略分配任务，从而扩展了机器人可以连续重复的动作数量。
### Conclusion
实验结果表明，GraSP-VLA能够有效地在规划域自动生成任务中建模符号表示。此外，真实世界实验表明，连续场景图表示法有可能在长时任务中优化低级VLA策略的功能。
## 390. `cs.CV` - 基于3D CT图像的主动脉瓣有限元网格自动化形变网络生成 [PDF](https://arxiv.org/pdf/2511.03890), [HTML](https://arxiv.org/abs/2511.03890)
### Authors
Linchen Qian,Jiasong Chen,Ruonan Gong,Wei Sun,Minliang Liu,Liang Liang
### Background
准确地从3D CT图像建模主动脉瓣对于生物力学分析和患者特定的模拟评估瓣膜健康状况或制定术前计划至关重要。然而，跨不同患者的主动脉瓣网格生成既需要高质量又需要保持一致性仍然具有挑战性。传统方法通常会产生具有不规则拓扑的三角网格，这会导致元素形状不良和由于个体间解剖变异导致的对应不一致。
### Innovation
本文提出了基于深度神经网络的模板拟合管道框架，用于从3D CT图像生成结构化四边形网格来表示主动脉瓣几何结构。通过使用一个通用四边形网格模板重新网格化所有患者的主动脉瓣，确保了患者间的网格拓扑一致性和节点间、元素间的对应一致性。这使得深度神经网络的训练更加简单，仅使用两种损失函数项（几何重构项和光滑正则化项），便可以保持网格光滑性和元素质量。实验结果显示，所提方法能够生成高质量且光滑度和形状质量改进的主动脉瓣表面网格，相比传统方法需要更少的显式正则化项。这表明使用结构化的四边形网格作为模板和神经网络训练的方法既确保了网格的一致性和质量，又简化了训练过程，从而提高了主动脉瓣建模的效果和效率。
### Conclusion
本文提出的方法在主动脉瓣的数据处理和建模方面有着潜在的应用前景，尽管仍需考虑不同患者的具体需求和进一步优化。
## 391. `cs.CV` - μNeuFMT: 光学特性自适应荧光分子断层成像通过隐式神经表示 [PDF](https://arxiv.org/pdf/2511.04510), [HTML](https://arxiv.org/abs/2511.04510)
### Authors
Shihan Zhao,Jianru Zhang,Yanan Wu,Linlin Li,Siyuan Shen,Xingjun Zhu,Guoyan Zheng,Jiahua Jiang,Wuwei Ren
### Background
荧光分子断层成像（FMT）是一种用于非侵入性3D可视化荧光探针的有前途的技术，但其重建仍然具有挑战性，因为其固有的不适定性和依赖于不准确或通常未知的组织光学特性。尽管深度学习方法已经显示出潜力，但它们的监督性质限制了在训练数据外部的一般化能力。背景部分解释了FMT技术目前面临的挑战，及其对改进光学特性自适应的迫切需求。
### Innovation
该研究提出了一种名为μNeuFMT的自监督FMT重建框架，它结合了基于隐式神经的场景表示与显式的光子传播物理建模。其关键创新之处在于重建过程中同时优化荧光分布和光学特性（μ），消除了对组织光学精确先验知识或预训练数据的依赖。结果显示，即使使用严重错误的初始值（0.5倍至2倍的真实值），μNeuFMT也能稳健恢复荧光分子分布和光学系数。广泛的数值、实验和体内验证表明，μNeuFMT在各种异质场景中优于传统的和监督式深度学习方法。这项工作为在复杂临床相关场景中提供更可靠分子成像确立了一个新的范例，例如荧光引导手术。
### Conclusion
μNeuFMT提出了一个全新的稳健和准确的FMT重建范例，为复杂的临床相关应用中的可靠分子成像铺平了道路，特别是在荧光引导手术等场景中。
## 392. `cs.CV` - 共通点是什么？多模态模型在跨场景推理时会产生幻觉 [PDF](https://arxiv.org/pdf/2511.03768), [HTML](https://arxiv.org/abs/2511.03768)
### Authors
Candace Ross,Florian Bordes,Adina Williams,Polina Kirichenko,Mark Ibrahim
### Background
现有的多模态语言模型在处理包含多种物体的概念时表现出色，但在处理现实世界的场景推理时，尤其是在大规模数据集上表现出色的情况下，仍存在重大漏洞。当前的感知基准测试接近饱和，但模型在真实的跨场景推理任务中表现欠佳，揭示了这些模型在处理真实世界复杂场景时的真实推理能力与测试表现之间的差距。
### Innovation
本文构建了一个名为Common-O的新基准测试，该测试利用了超过10500个全新图像，避免了网络训练数据的污染。该测试旨在超越单纯感知，类似于人类的认知测试，通过询问“场景中有哪些共通点”来探查模型在跨越不同场景的推理能力。测试中，作者还评估了多种先进的多模态语言模型，包括那些专门用于链式推理的模型，发现即使是最好的模型在处理Common-O和复杂场景时的表现也非常有限，共通点而已仅达到35%，在复杂场景中则更降低至1%，表明这些模型可能过度依赖于训练期间看到的物体共现情况。
### Conclusion
尽管这些模型在图像感知方面的挑战已经得到了充分解决，但在复杂场景中的推理障碍仍然是一个显著问题。对此，研究者发现，如果图像规模适当提高，会在一定程度上提升模型的表现，而对于那些专门使用多图像输入训练的模型，表现改善更为显著，这表明扩大规模的多图像训练在克服幻觉问题上可能具有前景。这些发现被预期能够促进对跨场景推理过程中幻觉问题的研究和探索，以期进一步提升模型的真实场景理解能力。
## 393. `cs.CV` - 基于输出分布感知的张量分解方法在卷积神经网络压缩中的应用 [PDF](https://arxiv.org/pdf/2511.04494), [HTML](https://arxiv.org/abs/2511.04494)
### Authors
Alper Kalle,Theo Rudkiewicz,Mohamed-Oumar Ouerfelli,Mohamed Tamaazousti
### Background
卷积神经网络在图像相关任务中的广泛应用普遍伴随着巨大的计算要求，一旦网络训练完成，其存储和计算需求可以通过压缩来减少。传统的方法通过在权重空间中寻找低秩近似，通常是通过最小化像Frobenius范数这样的各向同性范数，而本文提出的方法则通过在函数空间测量误差来优化。具体来说，我们最小化层输出分布的变化，可以表示为$rVert (W - tilde{W}) tilde{boldsymbol{boldSigma}}^{-1/2} rVert_2$的形式，其中$tilde{boldsymbol{boldSigma}}^{-1/2}$是层输入的协方差矩阵的平方根，$W$和$tilde{W}$是原始权重和压缩后权重。实验结果表明，这种方法在不需要后压缩微调的情况下表现出与传统方法相当的性能，并且即使在原始训练数据不可用时，也可以通过转移基于协方差的范数实现压缩，同时仍保持较高的准确性。
### Innovation
本文提出了一种基于输出分布感知的张量分解方法，该方法通过在函数空间中测量误差来优化卷积神经网络的压缩。不同于传统的压缩方法需要后压缩微调，本文的方法在很大程度上不需要额外的微调就可以达到与传统方法相当的性能。此外，这种基于协方差的范数还可以跨数据集转移，即使原始训练数据不可用也能进行有效的压缩。
### Conclusion
本文提出了一种新的基于输出分布感知的张量分解方法，通过在函数空间中直接优化来减少卷积神经网络的计算和存储需求。实验结果表明，这种方法不仅不需要额外的微调就能达到与传统方法相当的性能，而且在缺乏原始训练数据的情况下也能有效压缩网络，保持较好的准确性。
## 394. `cs.CV` - 使用高保真Gaussian Splatting模拟软体交互的实物到模拟机器人策略评估 [PDF](https://arxiv.org/pdf/2511.04665), [HTML](https://arxiv.org/abs/2511.04665)
### Authors
Kaifeng Zhang,Shuo Sha,Hanxiao Jiang,Matthew Loper,Hyunjong Song,Guangyan Cai,Zhuo Xu,Xiaochen Hu,Changxi Zheng,Yunzhu Li
### Background
机器人操作策略正在迅速发展，但在现实世界中的直接评估成本高昂、耗时且难以复制，特别是对于涉及柔性物体的任务。现有仿真器往往无法捕捉柔软物体交互的视觉和物理复杂性。因此，研究者开发了一种实物到模拟的机器人策略评估框架，该框架利用真实的视频生成软体的数字双胞胎，并通过3D Gaussian Splatting以高保真度渲染机器人、物体和环境。
### Innovation
该框架通过结合基于物理的重建与高质量渲染，使软体交互的评估变得更加可复制、可扩展和准确。研究者在毛绒玩具打包、绳索布线和T块推动等代表性柔性操作任务上验证了这种方法，展示了模拟运行与现实世界执行性能的高度关联，并揭示了已学习策略的关键行为模式。
### Conclusion
研究结果表明，将基于物理的重建与高质量渲染结合起来，能够实现柔性物体操作策略的可重复、可扩展和高精度评估。这种框架为机器人操作策略的开发和优化提供了有价值的工具。
## 395. `cs.CV` - Evo-1：保留语义对齐的轻量级视觉-语言-行动模型 [PDF](https://arxiv.org/pdf/2511.04555), [HTML](https://arxiv.org/abs/2511.04555)
### Authors
Tao Lin,Yilei Zhong,Yuxin Du,Jingjing Zhang,Jiting Liu,Yinxinyu Chen,Encheng Gu,Ziyan Liu,Hongyi Cai,Yanwen Zou,Lixing Zou,Zhaoye Zhou,Gen Li,Bo Zhao
### Background
视觉-语言-行动（VLA）模型作为一种整合感知、语言和控制的框架，已经在使机器人通过多模态理解执行多样任务方面展现了强大的能力。然而，当前的VLA模型通常参数量巨大，依赖大规模的机器人数据预训练，导致训练时具有高计算成本，部署时也存在实时推理的局限性。此外，大多数训练范式通常会降低视觉语言主干的感知表示，导致过拟合且泛化性能差。
### Innovation
本文提出了一种轻量级VLA模型Evo-1，该模型在无需机器人数据预训练的情况下减少了计算量并提高了部署效率。Evo-1构建在原生的多模态视觉-语言模型（VLM）基础上，加入了新颖的跨模态扩散变换器和优化的集成模块。此外，Evo-1引入了两阶段的训练范式，逐步对齐行动与感知，保留了VLM的表示。Evo-1仅具有0.77亿参数，在Meta-World和RoboTwin套件中取得了最先进的结果，分别超过了前最好模型12.4%和6.9%，还在LIBERO上达到了94.8%的结果。在实际评估中，Evo-1实现了78%的成功率，具有高推理频率和低内存开销，优于所有基线方法。
### Conclusion
Evo-1模型在不依赖大规模机器人数据预训练的情况下，大幅减少了计算量和提高了部署效率，仍保持了强大的性能，并且在多个基准测试中取得了突破性的成绩。
## 396. `cs.CV` - 三台校准相机的相对姿态实用解决方案 [PDF](https://arxiv.org/pdf/2303.16078), [HTML](https://arxiv.org/abs/2303.16078)
### Authors
Charalambos Tzamos,Viktor Kocur,Yaqing Ding,Daniel Barath,Zuzana Berger Haladova,Torsten Sattler,Zuzana Kukelova
### Background
本文研究了从四个点对应关系估计三台校准相机的相对位姿这一具有挑战性的问题。
### Innovation
提出了一种基于使用四个对应关系估算前两个视图的近似几何结构的新颖高效方法。这种方法可以将几何结构模型化为使用一个附加近似对应关系估计的仿射几何或完全透视几何。新的求解器基于现有的高效极小解算器，即4点仿射基础矩阵、著名的5点相对位姿求解器和P3P求解器，因此高效的且易于实现。实验证明，当适当与局部优化结合使用时，所提出的求解器能够达到最先进的结果，基于近似均值点对应关系的新型求解器比基于仿射几何的求解器更加稳健和精确。
### Conclusion
提出的基于近似均值点对应关系的新型求解器，在性能上超过了基于仿射几何的求解器，能够达到最先进的结果。
## 397. `cs.CV` - GentleHumanoid：学习上肢顺应性以实现接触丰富的人机和物体交互 [PDF](https://arxiv.org/pdf/2511.04679), [HTML](https://arxiv.org/abs/2511.04679)
### Authors
Qingzhou Lu,Yao Feng,Baiyu Shi,Michael Piseno,Zhenan Bao,C. Karen Liu
### Background
人形机器人需要在以人类为中心的环境中操作，其中安全自然的物理交互至关重要。然而，目前的强化学习方法大多关注刚性跟踪并抑制外来力。现有增强阻抗的方法通常局限于基座或末端执行器控制，并侧重于抵抗极端力而不是实现顺应性。因此，需要一种框架来整合阻抗控制到全身运动跟踪策略中，以实现上半身的顺应性
### Innovation
提出了一种名为GentleHumanoid的框架，该框架将阻抗控制集成到全身运动跟踪策略中，以实现上半身的顺应性。核心是一个统一的弹簧模型，该模型同时模拟了阻力接触（在接触表面时产生的恢复力）和引导接触（根据人类运动数据采样的推拉力）。该模型确保肩部、肘部和腕部的力学一致力，并通过可调整的任务力阈值来支持安全性。在模拟和Unitree G1人形机器人上分别进行了不同顺应性要求的任务评估，结果表明政策可以减少最高接触力同时保持任务成功率，从而实现更平滑和自然的交互
### Conclusion
研究结果展示了向人类安全有效地协作及在真实环境中的物体处理方向迈出的一步。
## 398. `cs.CV` - X-Diffusion: Training Diffusion Policies on Cross-Embodiment Human Demonstrations [PDF](https://arxiv.org/pdf/2511.04671), [HTML](https://arxiv.org/abs/2511.04671)
### Authors
Maximus A. Pace,Prithwish Dan,Chuanruo Ning,Atiksh Bhardwaj,Audrey Du,Edward W. Duan,Wei-Chiu Ma,Kushal Kedia
### Background
人类视频可以快速且大规模地录制，成为机器人学习中训练数据的理想来源。然而，人类和机器人在体形上存在根本性的差异，导致动作执行也不同。直接将人类的手部动作转换给机器人，在物理上可能是不可行的。尽管存在这些低级别的差异，但人类的演示提供了操作和与物体交互的重要运动线索。文中提出利用正向扩散过程的创新方法：随着噪声加入动作，低级别的执行差异会逐渐消失，高级别的任务指导则保留下来。
### Innovation
文章提出了X-Diffusion，一种原理性的框架，通过培训扩散策略来最大化利用人类数据，不学习动态上不可行的运动。X-Diffusion首先训练一个分类器来预测受噪声影响的动作是由人类还是机器人执行的。然后，在分类器无法辨别执行体的情况下，才会将人类动作纳入策略训练。一致的动作有助于监督细颗粒度的去噪，在低噪声水平，而动作上的不匹配则在高噪声水平上提供粗略的指导。实验结果表明，X-Diffusion在五个操作任务中实现了比最佳基线平均高出16%的成功率。
### Conclusion
 naive联合训练在执行差异下会降低策略性能，而X-Diffusion切实改善了这一问题。这个项目网站可以在该链接访问：这里.
## 399. `cs.CV` - Jr. AI Scientist和其风险报告：基于基线论文的自主科学研究 [PDF](https://arxiv.org/pdf/2511.04583), [HTML](https://arxiv.org/abs/2511.04583)
### Authors
Atsuyuki Miyai,Mashiro Toyooka,Takashi Otonari,Zaiying Zhao,Kiyoharu Aizawa
### Background
理解当前AI科学家系统的能力和风险对于确保AI驱动科学研究的信任和可持续性至关重要，同时保护学术生态系统不失真。鉴于此，研究团队开发了Jr. AI科学家，这是一个先进的自主AI科学家系统，模仿初级学生研究者的科研工作流程：基于人类导师提供的基线论文，分析其局限性，提出改进的新假设，通过严格的实验验证这些假设，并撰写包含实验结果的论文。与以往假设完全自动化或仅处理小规模代码的方法不同，Jr. AI科学家遵循明确的科研工作流程，并利用现代编程代理来处理复杂的多文件实现，从而创造具有科学价值的贡献。通过使用AI评审员进行自动化评估、作者主导的评估以及向专门用于AI驱动科研贡献的Agents4Science提交论文，研究人员已经评估了Jr. AI科学家的效能。
### Innovation
Jr. AI科学家是一个先进的自主AI科学家系统，模仿初级学生研究者的科研工作流程，区别于之前假设完全自动化或仅处理小规模代码的方法，Jr. AI科学家遵循明确的科研工作流程，并利用现代编程代理处理复杂的多文件实现，从而创造具有科学价值的贡献。通过自动化评估、作者主导评估以及向专门用于AI驱动科研贡献的场地提交论文，研究人员已经评估了Jr. AI科学家的效能，表明其生成的论文获得的评审分数高于现有的完全自动化系统。然而，研究也指出了作者评估和Agents4Science评审中发现的重要限制，揭示了直接应用当前的AI科学家系统可能存在的风险及其未来研究的关键挑战。
### Conclusion
在整个开发过程中，我们全面报告了各种风险。我们希望这些见解能够加深对当前AI科学家系统开发的进步和风险的理解。
## 400. `cs.CV` - 通过方向无关型EM公式弥合生成式和判别式嘈杂标签学习的差距 [PDF](https://arxiv.org/pdf/2308.01184), [HTML](https://arxiv.org/abs/2308.01184)
### Authors
Fengbei Liu,Chong Wang,Yuanhong Chen,Yuyuan Liu,Gustavo Carneiro
### Background
尽管嘈杂标签学习通常使用判别方法以简化和快速操作，但生成式建模提供了一种更具原则性的替代方案，通过捕捉产生特征、清洁标签和受损观察的联合机制。以前的工作通常引入额外的潜在变量和复杂的图像生成器，偏向于重建，固定单一的数据生成方向，限制了灵活性，并假定清洁标签的均匀先验，忽略了实例级的不确定性。
### Innovation
提出了一种单阶段、EM风格框架，采用生成式嘈杂标签学习，具有方向无关性，并避免显式的图像合成。首先，推导出单一的EM目标，其E步专门适应不同的因果方向而不改变整体优化。其次，用基于判别分类器在有限训练集上的数据归一化代理替换难以计算的概率分布，保留生成式建模的结构优势，而成本更低。第三，引入了
### Conclusion
在标准的视觉和自然语言处理嘈杂标签基准测试中，该方法取得了最先进的准确度，较低的转移矩阵估计误差，并且相比当前的生成式和判别式基线，训练计算量显著减少。
## 401. `cs.CV` - LEAP-VO：视觉里程计中的长期有效的任意点跟踪 [PDF](https://arxiv.org/pdf/2401.01887), [HTML](https://arxiv.org/abs/2401.01887)
### Authors
Weirong Chen,Le Chen,Rui Wang,Marc Pollefeys
### Background
现有的视觉里程计方法主要集中在两视角点跟踪上，往往忽略了图像序列中的丰富的时间上下文，忽视了全局运动模式，也无法评估整条轨迹的可靠性。这些不足在遮挡、动态物体和低纹理区域等场景中影响了性能。
### Innovation
介绍了Long-term Effective Any Point Tracking (LEAP) 模块，该模块创新性地结合了视觉、跨轨迹和时间线索，通过精心选择的锚点进行动态轨迹估计。LEAP的时序概率表述将分布更新整合到一个可学习的迭代细化模块中，以对点级不确定性进行推理。基于这些特点，我们开发了LEAP-VO，这是一种鲁棒的视觉里程计系统，能够处理遮挡和动态场景。
### Conclusion
广泛的实验表明，所提出的方法在各种视觉里程计基准上显著优于现有基线。
## 402. `cs.CV` - 使用FAGC方法揭示铜合金的结构-性能关系 [PDF](https://arxiv.org/pdf/2404.09515), [HTML](https://arxiv.org/abs/2404.09515)
### Authors
Yuexing Han,Ruijie Li,Guanxin Wan,Gan Hu,Yi Liu,Bing Wang
### Background
铜-铬-锆(Cu-Cr-Zr)合金在电子设备和电力行业中起着重要作用，它们的电导率和硬度至关重要。然而，由于可用样本稀缺，对这些合金的微观结构图像与其关键性能之间的关系的有效研究不足。
### Innovation
采用了FAGC特征增强方法，在预形状空间特征空间中增强Cu-Cr-Zr合金的微观结构图像。通过构建伪标签扩展训练样本数量，并将这些特征输入多种机器学习模型以构建性能预测模型。实验结果表明，当使用决策树分类器和100个增强特征时，方法在预测电导率（$R^2=0.978$）和硬度（$R^2=0.998$）方面表现出色。进一步分析表明，图像噪声减少的区域（比如很少的晶粒或相界）对电导率贡献更大。
### Conclusion
FAGC方法在数据有限的材料科学中具有潜力，能够克服图像数据不足的挑战，为建立复杂微结构和材料性能之间的详细定量关系提供有力工具。
## 403. `cs.CV` - 稳健的从基础矩阵自校准焦距 [PDF](https://arxiv.org/pdf/2311.16304), [HTML](https://arxiv.org/abs/2311.16304)
### Authors
Viktor Kocur,Daniel Kyselica,Zuzana Kukelova
### Background
自标定中的两相机自标定基本问题是几何计算机视觉中的基本问题之一。在主点已知和像素为正方形的假设下，经典的Bougnoux公式可用来计算未知的焦距。然而，在许多实际情况下，该公式因常见的奇异点而导致不准确的结果。此外，估计受到计算出的基础矩阵中的噪声和假设的主点位置的影响。因此，本文提出了一种有效且鲁棒的迭代方法，以根据给定的基础矩阵和参数估计的先验信息来估计相机的焦距和主点。此外，我们研究了RANSAC生成的模型的计算高效检查方法，可提高模型估计的准确性并减少总计算时间。广泛的实验证明，我们的迭代方法比Bougnoux公式和其他最先进的方法在估计焦距方面的准确性有了显著提高，即使依赖于不准确的先验也是如此。
### Innovation
本文提出了一种有效且鲁棒的迭代方法，以估计给定基础矩阵和参数估计的先验信息下的相机焦距和主点。此外，研究了一种计算高效的RANSAC生成模型的检查方法，以提高模型估计的准确性并减少总计算时间。
### Conclusion
我们在实际和合成数据上的大量实验表明，我们的迭代方法在焦距估计的准确性方面比Bougnoux公式和其他最先进的方法有了显著的提升，即使依赖于不准确的先验也是如此。
## 404. `cs.CV` - 伪立体输入：自监督立体匹配中遮挡挑战的解决方案 [PDF](https://arxiv.org/pdf/2410.02534), [HTML](https://arxiv.org/abs/2410.02534)
### Authors
Ruizhi Yang,Xingqiang Li,Jiajun Bai,Jinsong Du
### Background
自监督立体匹配有望通过消除对昂贵的地标数据的依赖而改变游戏规则。现有的主要方法基于光度一致性，但这些方法在面对遮挡问题时存在根本性限制，无论采用何种网络架构，遮挡问题都是无法克服的。现有方法通过识别和移除或者引入额外的正则性来尝试解决这一问题，但是这些方法未能提供一个完整的解决方案。
### Innovation
本文提出了一种更根本的解决方案，核心想法是将单侧有效的和单侧错误的信号固定状态转换为通过伪立体输入策略从遮挡物的两侧以概率方式获取有效的反馈信号。该框架去除了输入和反馈之间的耦合，没有引入任何额外的约束。质性实验表明遮挡问题得到了解决，并实现了两侧的对称和一致的性能。定量实验验证了解决遮挡挑战带来的显著性能提升。
### Conclusion
该工作提供了一个完整的框架，彻底解决了遮挡问题，显著提高了自监督立体匹配的性能，通过伪立体输入策略实现了两侧的对称和一致的性能。
## 405. `cs.CV` - EMHI: 拟人佩戴头显和体式加速度计的一种多模态第一视角人体动作数据集 [PDF](https://arxiv.org/pdf/2408.17168), [HTML](https://arxiv.org/abs/2408.17168)
### Authors
Zhen Fan,Peng Dai,Zhuo Su,Xu Gao,Zheng Lv,Jiarui Zhang,Tianyuan Du,Guidong Wang,Yang Zhang
### Background
第一视角（Egocentric）人体姿态估计（HPE）对于VR/AR应用非常重要。现有的方法主要依赖于第一视角图片或稀疏的惯性测量单元（IMU）信号，但这两者都有各自的不足，图像中存在自我遮挡问题，而IMU信号则稀疏且漂移。此外，缺乏包含多种模态数据的现实世界数据集是该领域进展的一大障碍。因此，迫切需要建立一种包含第一视角视角图片和IMU信号的多模态数据集，以解决这一问题和推动第一视角人体姿态估计研究的进步。
### Innovation
本文提出了一种名为EMHI的数据集，该数据集利用佩戴头显和体式加速度计收集同步的立体图像和IMU数据，并提供了SMPL格式的人体姿态注释。所提的MEPoser方法融合了多模态数据，通过时间特征编码器和基于MLP的回归头来提高人体姿态估计的准确性。实验表明，该方法在现有单模态方法上表现更好，证明了所提出数据集的有效性。
### Conclusion
本文介绍了EMHI数据集，它是一种包含多模态数据的高品质第一视角人体动作数据集，并提出了一种新的方法MEPoser。该数据集和方法可以促进第一视角人体姿态估计研究，并加速该技术在VR/AR产品中的实际应用。
## 406. `cs.CV` - 相对径向失真校正是否对于相机相对姿态估计是必要的？ [PDF](https://arxiv.org/pdf/2410.05984), [HTML](https://arxiv.org/abs/2410.05984)
### Authors
Charalambos Tzamos,Viktor Kocur,Yaqing Ding,Torsten Sattler,Zuzana Kukelova
### Background
相机姿态估计是Structure-from-Motion等许多应用中的基本步骤。常见的相对姿态估计方法是利用RANSAC循环内的最小解算器。孔洞相机的高效解算器广泛存在，但几乎所有相机都会表现出径向失真。未考虑径向失真的结果会显著变差。虽然存在简单实现的小型径向失真解算器，但其在运行时间和实现上比孔洞解算器复杂得多。
### Innovation
本文比较了一种简单实现的方法，该方法结合了高效的孔洞解算器和采样的径向失真参数，实验表明这种简单方法在运行时间更短的情况下，性能与最精确的最小失真解算器相当或更好，同时比快速的非最小解算器更有准确性。研究清晰地表明，在实践中复杂的径向失真解算器并非必需。
### Conclusion
即使对于存在径向失真的相机，使用简单结合高效孔洞解算器和采样径向失真参数的方法，也可以达到与复杂径向失真解算器相当甚至更优的性能，而运行速度更快。因此，复杂的径向失真解算器在实践中并不是必要。代码与基准已公开可用。
## 407. `cs.CV` - Optimized Minimal 3D Gaussian Splatting [PDF](https://arxiv.org/pdf/2503.16924), [HTML](https://arxiv.org/abs/2503.16924)
### Authors
Joo Chan Lee,Jong Hwan Ko,Eunbyung Park
### Background
3D Gaussian Splatting (3DGS)已成为实时、高性能渲染的强大表示方法，适用于广泛的应用场景。然而，使用大量显式高斯模型来表示3D场景会带来显著的存储和内存负担。尽管高精度属性表示可以大幅减少高保真渲染所需的高斯数量，现有的3DGS压缩方法仍然依赖于一个相对较大的高斯数量，主要是通过优化属性压缩实现的。因为较小的高斯集对丢失压缩更加敏感，容易导致质量下降。由于高斯数量直接关联计算成本，必须实际有效地减少高斯数量，而不是仅仅优化存储。
### Innovation
本文提出了一种优化最小高斯表示(OMG)，可以在最少的普模型基础上显著减少存储。OMG首先通过最小化冗余来确定独特的高斯，同时保持高保真质量。此外，提出了紧凑且精确的属性表示方法，可以有效捕捉原模型的连续性与不规则性。还提出了子向量量化技术来改进不规则性的表示，同时保持快速训练和极小的码本大小。广泛的实验表明，OMG的存储要求比上一代最佳方案降低了近50%，同时能够实现600+ FPS的高质量渲染速度。
### Conclusion
我们的源代码可以在以下链接获得。
## 408. `cs.CV` - 基于同态的三视角焦距恢复 [PDF](https://arxiv.org/pdf/2501.07499), [HTML](https://arxiv.org/abs/2501.07499)
### Authors
Yaqing Ding,Viktor Kocur,Zuzana Berger Haladová,Qianliang Wu,Shen Cai,Jian Yang,Zuzana Kukelova
### Background
本文介绍了一种从三视角同态恢复焦距的新方法。背景在于，通过研究两个同态之间的-normal向量一致性，提出了新的焦距和同态之间的显式约束，这种约束使用了消除技术。三视角同态提供了两个额外的约束条件，这使得能够恢复一个或两个焦距。文中详细讨论了四个可能的情况：三个相机具有未知且相等的焦距；三个相机具有两个未知但不同的焦距；三个相机中的一个焦距已知，另外两个相机的焦距相等或不同。这些情况都可以转化为求解一或两个未知数的多项式方程，这些方程可以使用Sturm序列或隐含变量技术有效求解。利用合成和真实数据进行的评估表明，提出的解算器在速度和准确性上都优于依赖于现有两视角解算器的方法。
### Innovation
本文提出了从三视角同态中恢复焦距的新型方法。通过研究两个同态之间的-normal向量一致性，获得了新的关于焦距和同态之间的一阶显式约束。三视角同态提供两个额外的约束，使得能够恢复一个或两个焦距。这种方法可以转化为解一或两个未知数的多项式方程，并能高效地使用Sturm序列或隐含变量技术求解。与现有的依赖于两视角解算器的方法相比，提出的解算器在速度和准确性上更优。
### Conclusion
利用三视角同态能够恢复一个或两个焦距，而且还提供了比现有两视角解算器更快和更准确的方法。代码和数据可以在指定的网址找到。
## 409. `cs.CV` - EarthGPT-X：使用视觉提示实现多级多源遥感图像理解的空间大语言模型 [PDF](https://arxiv.org/pdf/2504.12795), [HTML](https://arxiv.org/abs/2504.12795)
### Authors
Wei Zhang,Miaoxin Cai,Yaqian Ning,Tong Zhang,Yin Zhuang,Shijian Lu,He Chen,Jun Li,Xuerui Mao
### Background
自然域多模态大型语言模型（MLLMs）通过视觉和文本提示展示了有效的空间推理能力。然而，这些模型直接应用于遥感（RS）时受到物理异质性、多样模态和独特空间尺度的阻碍。现有的RS MLLMs主要局限于光学遥感影像和简单的语言交互，限制了其在实际应用场景中的灵活和扩展性。
### Innovation
1) 引入了结合文本指令和不同视觉提示（点、框、自由形）的双提示机制，模仿人类生活中指示的灵活性；2) 建立了一个全面的多源多级提示数据集，使模型超越整体图像理解，支持层次空间推理，包括场景级理解和精细的物体特征和关系分析；3) 提出了跨域的一站式融合训练策略，使模型在不同模态和任务上高效且一致地对齐。
### Conclusion
广泛实验表明，EarthGPT-X 显著优于现有自然与RS MLLMs，建立了第一个能够在RS场景中使用视觉提示进行多源、多任务和多级解释的框架。
## 410. `cs.CV` - CREA：一种用于创意图像编辑和生成的协作多智能体框架 [PDF](https://arxiv.org/pdf/2504.05306), [HTML](https://arxiv.org/abs/2504.05306)
### Authors
Kavana Venkatesh,Connor Dunlop,Pinar Yanardag
### Background
AI图像中的创造力仍然是一个基本的挑战，不仅需要生成视觉上引人注目的内容，还需要能够添加新颖、表达性和富艺术性的图像变换。与依赖直接提示修改的传统编辑任务不同，创造性的图像编辑需要一种自主、迭代的方法，平衡原创性、连贯性和艺术意图。现有的方法在这方面关注度和进展有限，因此急需一种新的解决方案来提高图像编辑的创意性和多样性.
### Innovation
我们提出了CREA，一种创新的多智能体协作框架，模仿人类的创意思维过程。CREA利用一组特化的AI代理动态协作，完成概念化、生成、评判和增强图像的任务。通过广泛的定性和定量评估，我们证明CREA在多样性、语义对齐和创意转换方面显著优于现有的最先进的方法。这是首次将创意编辑任务作为一种新工作引入.
### Conclusion
CREA通过多智能体协作显著改进了图像创意编辑和生成，展现了更高的原创性和艺术价值，填补了现有技术在该领域的空白。
## 411. `cs.CV` - RadZero: 基于相似性的跨注意力机制在胸部X射线中的可解释视觉-语言对齐及其零样本多任务能力 [PDF](https://arxiv.org/pdf/2504.07416), [HTML](https://arxiv.org/abs/2504.07416)
### Authors
Jonggwon Park,Byungmu Yoon,Soobum Kim,Kyoyun Choi
### Background
近期在多模态模型领域的进展显著提升了医学影像领域，特别是放射学中的视觉-语言（VL）对齐。然而，现有的方法在利用复杂放射学报告方面效果有限，并且在通过注意力概率可视化提高可解释性方面存在不足。
### Innovation
本文提出了RadZero，一种新颖的框架，旨在通过零样本多任务能力解决VL对齐问题。RadZero的亮点在于VL-CABS（基于相似性的视觉-语言跨注意力机制），它能够将文本嵌入与局部图像特征对齐，从而实现细腻的可解释VL推理。RadZero采用大型语言模型从放射学报告中提取简洁的语义句子，并利用多正样本对比训练方法来有效捕捉图像与其他相关文本描述之间的关系。此外，RadZero利用预训练的视觉编码器和附加的可训练Transformer层来支持高分辨率图像的高效处理。VL-CABS机制使得RadZero能够进行零样本推理，通过相似概率进行分类，并生成像素级别的VL相似度图以进行定位和分割。与现有方法相比，实验结果表明RadZero在零样本分类、定位和分割方面表现优异。
### Conclusion
RadZero在公开的胸部X射线基准数据集上的实验结果表明，其在零样本分类、定位和分割方面优于当前最先进的方法。此外，VL相似度图的分析突显了VL-CABS在提高VL对齐解释性的潜力。质性评估进一步验证了RadZero在医学影像中的有效性，并能够实现开放词汇的语义分割。代码可在指定链接获取。
## 412. `cs.CV` - 重返正轨：动态场景重建中的束调整 [PDF](https://arxiv.org/pdf/2504.14516), [HTML](https://arxiv.org/abs/2504.14516)
### Authors
Weirong Chen,Ganlin Zhang,Felix Wimbauer,Rui Wang,Nikita Araslanov,Andrea Vedaldi,Daniel Cremers
### Background
传统SLAM系统依赖于束调整，但在处理常见的非正式视频中的动态场景时遇到困难。这类视频中的动态元素使得运动交织在一起，无法满足传统系统所需的静态环境假设。现有技术要么滤除动态元素，要么独立建模它们的运动，但这两种方法分别会导致重建不完整和不一致的运动估计问题。
### Innovation
本文采用新颖的方法，利用3D点追踪器将摄像机引起的运动与动态物体的观测运动分离。通过仅仅考虑摄像机引起的成分，束调整可以可靠地在所有场景元素上进行操作。另外，利用基于尺度图的轻量级后处理来确保视频帧间的深度一致性。本文框架结合了传统SLAM的核心——束调整以及鲁棒的学习基于的3D追踪前端，集成运动分解、束调整和深度细化，形成了统一框架BA-Track。BA-Track可以准确跟踪摄像机运动，并生成时间上连贯且尺度一致的密集重建，适用于静态和动态元素。
### Conclusion
在具有挑战性的数据集上的实验结果表明，我们的方法在摄像机姿态估计和3D重建精度方面具有显著改进。
## 413. `cs.CV` - DOVE: 一种用于实际视频超分辨率的高效单步扩散模型 [PDF](https://arxiv.org/pdf/2505.16239), [HTML](https://arxiv.org/abs/2505.16239)
### Authors
Zheng Chen,Zichen Zou,Kewei Zhang,Xiongfei Su,Xin Yuan,Yong Guo,Yulun Zhang
### Background
扩散模型在实际视频超分辨率（VSR）中表现出良好的性能，但由于其对大量采样步骤的依赖，导致推理过程极其缓慢。加速采样的技术，特别是单步技术，提供了一种潜在的解决方案。然而，实现这一目标在视频超分辨率中仍然具有挑战性，主要因为高视频数据训练开销和严格的保真度要求。
### Innovation
提出了DOVE，一种通过微调预训练的视频扩散模型（即CogVideoX）获得的高效单步扩散模型。为了有效训练DOVE，引入了潜在像素训练策略，并设计了一个视频处理管道，构建了一个高质量的数据集（HQ-VSR），专门为VSR任务提供定制的数据。
### Conclusion
广泛的实验表明，DOVE在性能上与多步扩散模型相似或更优，并且还提供了出色的推理效率，相比现有方法MGLD-VSR，速度提高了28倍。代码可在此处获取：this https URL.
## 414. `cs.CV` - 重访残差连接：稳定高效的深层网络的正交更新 [PDF](https://arxiv.org/pdf/2505.11881), [HTML](https://arxiv.org/abs/2505.11881)
### Authors
Giyeong Oh,Woohyun Cho,Siyeol Kim,Suhwan Choi,Youngjae Yu
### Background
残差连接对深度神经网络至关重要，它们通过缓解梯度消失的问题，使网络可以达到更深的层次。然而，标准的残差更新方式直接将模块的输出添加到输入流中，这可能导致更新主要强调或调控现有的信息流向，从而可能无法充分利用模块学习全新的特征的能力。现有研究试图通过改变更新策略来增强模块的能力，使其能够贡献更多新颖的表示方向，从而促进更丰富和高效的特征学习。已有研究表明，正交更新策略可以提高泛化准确性和训练稳定性，并在多种架构和数据集上取得了成功，如ResNetV2、视觉变换器等，以及CIFARs、TinyImageNet和ImageNet-1k等数据集上。例如，对于ImageNet-1k上的ViT-B模型，其Top-1准确率提高了3.78个百分点。
### Innovation
本文引入了正交残差更新(Orthogonal Residual Update)。该方法将模块的输出相对于输入流进行分解，并仅添加垂直于该流的方向的分量。这种设计旨在引导模块主要贡献新的表示方向，从而促进更丰富和高效的特征学习，同时提高训练效率。通过实验验证，正交更新策略在多种神经网络架构和数据集上取得了显著的效果，特别是在稳定性和泛化能力方面。
### Conclusion
正交残差更新策略能够显著提高模型在不同架构和数据集上的泛化准确性和训练稳定性，为稳定高效的深层网络提供了新的解决方案。
## 415. `cs.CV` - MMPerspective: Do MLLMs Understand Perspective? A Comprehensive Benchmark for Perspective Perception, Reasoning, and Robustness [PDF](https://arxiv.org/pdf/2505.20426), [HTML](https://arxiv.org/abs/2505.20426)
### Authors
Yolo Yunlong Tang,Pinxin Liu,Zhangyun Tan,Mingqian Feng,Rui Mao,Chao Huang,Jing Bi,Yunzhong Xiao,Susan Liang,Hang Hua,Ali Vosoughi,Luchuan Song,Zeliang Zhang,Chenliang Xu
### Background
人类视觉感知的基础在于视角的理解，但大规模多模态语言模型（MLLMs）在内部化视角几何方面的程度尚不明确。本文旨在通过设计第一个系统性评估MLLMs在视角理解上的基准测试MMPerspective，来深入了解这一点。
### Innovation
文章引入了MMPerspective，这是第一个专门设计用于系统性评估MLLMs在视角理解上的基准测试。它包含10个精心策划的任务，覆盖了视角感知、推理、鲁棒性三个维度；包含2,711个真实和合成图像实例，及5,083个问题-答案对，评估模型在消失点感知、计数、视角推理、空间中线关系理解、保持视角不变形下的空间一致性等关键能力。评估结果显示，尽管模型在表面感知任务上表现出色，但在组成推理和在扰动下保持空间一致性方面存在显著困难。
### Conclusion
MMPerspective为诊断和提升视觉-语言系统中的空间理解提供了一个有价值的试验平台。文章分析还揭示了模型架构、规模与视角能力之间的复杂关系，指出了鲁棒性瓶颈，并强调了链式思考提示的好处。
## 416. `cs.CV` - TextRegion：冻结图像-文本模型中的对齐区域令牌 [PDF](https://arxiv.org/pdf/2505.23769), [HTML](https://arxiv.org/abs/2505.23769)
### Authors
Yao Xiao,Qiqian Fu,Heyi Tao,Yuqun Wu,Zhen Zhu,Derek Hoiem
### Background
图像-文本模型在图像级别的任务上表现出色，但在细节视觉理解方面存在困难。虽然这些模型能够提供强大的图像-语言对齐，但分割模型如SAM2能提供精确的空间边界。因此，论文提出了一种名为TextRegion的简单、有效且无需训练的框架，将图像-文本模型的优势与SAM2融合，生成有力的文本对齐区域令牌。这些令牌能够实现详细的视觉理解，同时保留开放词汇的能力。这些令牌可以直接应用于各种下游任务，包括开放世界语义分割、指示性表达理解和语义定位。
### Innovation
论文提出了一种名为TextRegion的简单、有效且无需训练的框架，将图像-文本模型的优势与SAM2模型融合，生成文本对齐区域令牌。这些令牌能够实现详细的视觉理解，同时保留开放词汇的能力。此外，该框架与许多图像-文本模型兼容，使其非常适合应用于实际场景，并易于扩展以适应更强的模型。
### Conclusion
论文进行了广泛的评估，相较于最新的无需训练的方法，其结果表现优异或具有竞争力。框架能够直接应用于多种下游任务，包括开放世界语义分割、指示性表达理解和语义定位，并且对于未来的更强图像-文本模型也具有高度的兼容性。
## 417. `cs.CV` - Time告诉了我们什么？静态图像中的时间意识探索性研究 [PDF](https://arxiv.org/pdf/2503.17899), [HTML](https://arxiv.org/abs/2503.17899)
### Authors
Dongheng Lin,Han Hu,Jianbo Jiao
### Background
时间通过光照变化体现在我们所见之中。受到这一启发，本文探讨了从静态图像中学习时间意识的潜力，试图回答时间向我们传达了什么。为此，本文首先引入了一个包含可靠时间戳的130,906张图片的时间导向集合（TOC）数据集。借助这个数据集，提出了跨模态对比学习的时-图像对比学习（TICL）方法，以联合建模时间戳和相关视觉表示。研究表明，提出的TICL不仅在时间戳估计任务中取得了最先进的性能，而且还能通过仅查看静态图像学习的时间感知嵌入，表现出色地完成几种时间意识下游任务，如基于时间的图像检索、视频场景分类和时间感知图像编辑等。
### Innovation
本文创新性地提出了一种名为TICL的方法，该方法通过跨模态对比学习从静态图像中联合建模时间戳和视觉表示，不仅在时间戳估计任务中取得了最先进的性能，还能通过仅查看静态图像学习的时间感知嵌入，表现出色地完成几种时间意识下游任务，如基于时间的图像检索、视频场景分类和时间感知图像编辑等。
### Conclusion
我们的研究发现，与时间相关的视觉线索可以从静态图像中学习，并对多种视觉任务有益，为未来关于时间相关视觉场景理解的研究奠定了基础。
## 418. `cs.CV` - UMA: 超高细节人体模型通过多级表面对齐 [PDF](https://arxiv.org/pdf/2506.01802), [HTML](https://arxiv.org/abs/2506.01802)
### Authors
Heming Zhu,Guoxing Sun,Christian Theobalt,Marc Habermann
### Background
从多视角视频中学习具有生动动态和逼真外观的可动服饰人类模型，在计算机图形学和计算机视觉领域是一项重要的基础研究问题。得益于隐式表示的最新进展，基于可驱动的人类模板网格添加隐式表示使得可动模型的质量达到了前所未有的水平。然而，这些模型通常无法保留最详细的细节，尤其是在虚拟摄像机放大和渲染达到4K分辨率及以上时更为明显。这主要是由于表面追踪不准确，包括深度对齐错误和角色几何体与真实表面之间的表面漂移，这两者迫使具有详细外观模型的几何体误差进行补偿。
### Innovation
本文提出了一种潜在线性变形模型，并通过基础二维视频点跟踪器的指导来监督可动角色的3D变形，从而提高了对光照和表面变化的鲁棒性，并降低了陷入局部极小值的风险。此外，通过级联培训策略生成一致的3D点轨迹，该策略通过将点轨迹锚定在渲染的人体模型上来确保最终监督人体模型的面元和面片级别，从而缓解了历时漂移和缺乏3D意识的问题。
### Conclusion
为了验证本文方法的有效性，作者引入了一个新的数据集，包含五个超过10分钟的多视角视频序列，用40个校准的6K分辨率摄像机拍摄，并包含穿着具有挑战性纹理图案和皱纹变形服装的主体。实验结果表明，本文方法在渲染质量和几何精度方面显著优于先前的最佳方法。
## 419. `cs.CV` - Two Causally Related Needles in a Video Haystack [PDF](https://arxiv.org/pdf/2505.19853), [HTML](https://arxiv.org/abs/2505.19853)
### Authors
Miaoyu Li,Qin Chao,Boyang Li
### Background
当前评估视听模型（VLMs）理解长视频的能力仍然具有挑战性。现有的基准测试主要关注理解单个或多个短片段，但对于从长时间跨度中提取信息以及理解长期因果关系的能力评估不足。
### Innovation
本文提出了一种名为Causal2Needles的新型长时间上下文视频理解基准，旨在评估观测和理解长视频中因果事件及在周围叙述中关联的能力。它引入了非因果单针和因果单针问题，以及最复杂的因果双针问题，这些复杂问题要求模型从长视频和伴随叙述文本中提取信息。此外，为防止文本偏见，引入了两种互补的问题格式：定点视频片段查找和该片段中的详细视觉描述。
### Conclusion
实验结果表明，现有基准测试表现出色的模型在因果双针问题上却表现不佳，且模型的性能与两针之间的距离成负相关。这些结果揭示了当前VLMs的关键局限性。该数据集可在 provided URL 中访问。
## 420. `cs.CV` - MIND：从UDFs生成材料界面以重建非流形曲面 [PDF](https://arxiv.org/pdf/2506.02938), [HTML](https://arxiv.org/abs/2506.02938)
### Authors
Xuhui Chen,Fei Hou,Wencheng Wang,Hong Qin,Ying He
### Background
未标注形状拓扑性的3D点云或多视图图像难以用距离场（UDFs）表示。尽管先前的工作主要集中在从点云或多视图图像中学习UDFs，从UDFs中提取网格仍然具有挑战性。通常的做法是从UDFs局部重构有符号距离场（SDFs）以通过Marching Cubes进行曲面提取，但这种方法往往会引入拓扑错误，比如孔洞或虚假组件，并且局部SDFs无法表示非流形几何，因此在某些情况下导致完全失败。现有的方法难以处理复杂且非流形的表面，尤其是在重建非流形曲面时性能较差。
### Innovation
提出了一种名为MIND的新颖算法，直接从UDFs生成材料界面，以便全局视角下提取非流形网格。该方法的核心在于通过UDFs推导有意义的空间分区，其中目标表面作为不同区域之间的界面出现。方法首先计算一个双符号局部场以区分流形片段的两侧，然后将其扩展到多标签全局场，能够分离非流形结构的所有侧。通过结合多标签场与输入的UDFs，使用多标签Marching Cubes算法构建支持非流形网格提取的材料界面。在来自不同数据源（包括点云重建、多视图重建和中轴线变换）的UDFs上进行了大量实验，结果表明MIND方法能稳健地处理复杂非流形表面，显著优于现有方法。
### Conclusion
实验结果表明，MIND方法能够从UDFs中稳健地提取复杂的非流形曲面，并显著优于现有的方法。该研究方法能为3D重建和重建提供一种新的处理复杂非流形几何的方法。
## 421. `cs.CV` - WaveGuard：通过双树复小波和图神经网络实现稳健的深仿生检测与源头追踪 [PDF](https://arxiv.org/pdf/2505.08614), [HTML](https://arxiv.org/abs/2505.08614)
### Authors
Ziyuan He,Zhiqing Guo,Liejun Wang,Gaobo Yang,Yunfeng Diao,Dan Ma
### Background
深度伪造技术（Deepfake）带来了日益增长的风险，如隐私泄露和身份盗窃。为了应对这些威胁，本研究提出了WaveGuard，这是一种在频域嵌入并使用基于图的结构一致性实现鲁棒性和不可感知性增强的先验水印框架。特别地，WaveGuard利用双树复小波变换（DT-CWT）将水印嵌入到高频子带中，并通过结构一致性图神经网络（SC-GNN）保持视觉质量。此外，该框架还设计了一个注意力模块以提高嵌入精度。实验证明，WaveGuard在鲁棒性和视觉质量方面均优于现有的方法，特别是在面部替换和重新台词任务上取得了良好效果。
### Innovation
提出了WaveGuard，一种先验水印框架，结合了双树复小波变换（DT-CWT）在频域嵌入水印，并利用结构一致性图神经网络（SC-GNN）保持视觉质量，还设计了一个注意力模块以提高嵌入精度。实验结果显示WaveGuard在鲁棒性和视觉质量上均优于现有的方法。
### Conclusion
本研究使用WaveGuard框架在频域中嵌入水印，并利用结构一致性图神经网络（SC-GNN）保持视觉质量，实验证明在鲁棒性和视觉质量方面均优于现有的方法。
## 422. `cs.CV` - AutoVLA: 一种具有自适应推理和强化微调的视觉-语言-行动模型用于端到端自主驾驶 [PDF](https://arxiv.org/pdf/2506.13757), [HTML](https://arxiv.org/abs/2506.13757)
### Authors
Zewei Zhou,Tianhui Cai,Seth Z. Zhao,Yun Zhang,Zhiyu Huang,Bolei Zhou,Jiaqi Ma
### Background
最近在视觉-语言-行动（VLA）模型方面取得的进展表明，这些模型通过利用世界知识和推理能力，有望实现端到端的自主驾驶。然而，现有的VLA模型常常难以生成物理上不可行的动作输出，具有复杂的模型结构，或是进行不必要的长时间推理。
### Innovation
本文提出了一种新的VLA模型AutoVLA，它在一个自回归生成模型中统一了推理和动作生成，以实现端到端的自主驾驶。AutoVLA直接从原始视觉输入和语言指令中执行语义推理和轨迹规划，并且通过监督微调赋予模型两种思考模式：快速思考（仅涉及轨迹）和慢速思考（通过链式推理增强）。此外，引入了一种基于组相对策略优化（GRPO）的强化微调方法，以减少简单场景中的不必要的推理过程，提升规划性能和效率。
### Conclusion
通过在现实世界和模拟数据集及基准测试（包括nuPlan、nuScenes、Waymo和CARLA）中进行广泛实验，结果表明AutoVLA在开环和闭环设置中均表现出强大的竞争力，并展示了其在多种场景下的自适应推理和准确规划能力。
## 423. `cs.CV` - 利用压缩和量化多条件标记化先进手语视频生成 [PDF](https://arxiv.org/pdf/2506.15980), [HTML](https://arxiv.org/abs/2506.15980)
### Authors
Cong Wang,Zexuan Deng,Zhiwei Jiang,Yafeng Yin,Fei Shen,Zifeng Cheng,Shiping Ge,Shiwei Gan,Qing Gu
### Background
现有的手语视频生成（SLVG）方法主要依赖粗略的单一条件（例如骨架序列）作为桥梁，这限制了生成的手语视频的自然性和表现力。
### Innovation
提出了一种名为SignViP的新颖SLVG框架，该框架结合了多种细粒度条件，以提高生成保真度。SignViP采用了离散标记化范式，将细粒度条件（如细粒度姿态和3D手）整合到表示中，而不是直接翻译高维的易出错条件。SignViP包含三部分核心组件：（1）Sign Video Diffusion Model与多条件编码器联合训练，学习包含细粒度运动和外观的连续嵌入；（2）Finite Scalar Quantization（FSQ）自编码器进一步训练，对这些嵌入进行压缩和量化，以紧凑地表示条件；（3）多条件标记翻译器训练将语音文本翻译为离散多条件标记。实验结果表明，SignViP在视频质量、时间连贯性和语义保真度等指标上都达到了最先进的性能。
### Conclusion
SignViP框架通过采用压缩和量化多条件标记化的方法，显著提高了手语视频生成的质量，包括视频质量、时间连贯性和语义保真度等方面。
## 424. `cs.CV` - 注重本质：基于取证导向增强的通用AI生成视频检测 [PDF](https://arxiv.org/pdf/2506.16802), [HTML](https://arxiv.org/abs/2506.16802)
### Authors
Riccardo Corvi,Davide Cozzolino,Ekta Prashnani,Shalini De Mello,Koki Nagano,Luisa Verdoliva
### Background
合成视频生成技术正在迅速发展，现有模型能够生成高度逼真的高分辨率视频，几乎可以与真实视频区分不开。虽然已有多种视频取证检测器被提出，但它们通常存在泛化能力差的问题，限制了它们在实际应用场景中的应用。
### Innovation
本文的关键见解是引导检测器朝着识别重要特征的方向发展，设计了一个新的取证导向的增强策略，该策略基于小波分解，通过替换特定的频带，在不依赖复杂算法和大规模数据集包括多种合成生成器的情况下，提高AI合成视频检测器的一般泛化能力。
### Conclusion
尽管方法简单，但通过单一生成模型训练的检测器在面对其他多种模型生成的视频时展示出显著的准确率改进，并在极为新颖的生成模型（如NOVA和FLUX）上取得了出色的结果。
## 425. `cs.CV` - Med-GLIP：基于大规模标注数据集的医疗语言-图像预训练进展 [PDF](https://arxiv.org/pdf/2508.10528), [HTML](https://arxiv.org/abs/2508.10528)
### Authors
Ziye Deng,Ruihan He,Jiaxiang Liu,Yuan Wang,Zijie Meng,Songtao Jiang,Yong Xie,Zuozhu Liu
### Background
医学图像解码旨在将自然语言短语与医学图像中的特定区域对齐，作为智能诊断、视觉问答（VQA）和自动生成报告（MRG）的基础任务。然而，现有的研究受到单一模态覆盖不足、标注精度粗糙以及缺乏统一、可泛化的解码框架的限制。
### Innovation
为应对这些挑战，该研究构建了包含超过530万区域级标注的大规模医学解码数据集Med-GLIP-5M，涵盖了七种成像模态，包括多种解剖结构和病理发现。基准之上，提出了一种模态感知解码框架Med-GLIP，该框架通过多样化训练数据隐式获取层次语义理解，能够识别不同粒度的结构，如区分肺部与肺炎病灶。广泛实验表明，Med-GLIP在多个解码基准测试中持续优于最新基线。进一步集成其空间输出到下游任务（如医学VQA和报告生成）中，显著提升了性能。
### Conclusion
最终，该数据集将很快发布，为医学图像理解研究提供了重要的支持。
## 426. `cs.CV` - MCTED: 一个用于火星影像生成数字高程模型的机器学习就绪数据集 [PDF](https://arxiv.org/pdf/2509.08027), [HTML](https://arxiv.org/abs/2509.08027)
### Authors
Rafał Osadnik,Pablo Gómez,Eleni Bohacek,Rickbir Bahia
### Background
随着机器学习在火星地形理解和地貌分析中的广泛应用，需要高质量的训练数据集来支持相关研究和应用。现有数据集在覆盖范围和处理复杂性方面存在局限，难以满足大规模数字高程模型（DEM）预测任务的需求。
### Innovation
本文提出了一个名为MCTED的新数据集，为火星数字高程模型预测任务提供了机器学习应用的基础数据。通过综合处理高分辨率火星正射影像和DEM配对数据，生成了包含80,898个样本的数据集。为了克服大规模DEM处理过程中的常见问题，如数据缺陷和缺失点，开发了相应的工具来解决或减轻这些问题的影响。此外，还制定了训练和验证集的划分策略，确保不会出现数据泄漏，并增加了表示缺失或修改值的掩码。本文还通过训练一个小型U-Net模型，并将其性能与DepthAnythingV2进行比较，验证了MCTED数据集的有效性，即使是非常小的模型也能在特定的数据集上超越深度估计基础模型的零样本性能。数据集和生成代码完全开源，并在公共存储库中提供。
### Conclusion
该研究通过生成一个完备的数据集，并利用实际案例展示了其有效性和实用性，为未来基于机器学习的火星地形研究提供了有力支持。
## 427. `cs.CV` - HoliSafe: 全面的安全基准与建模框架为视觉语言模型 [PDF](https://arxiv.org/pdf/2506.04704), [HTML](https://arxiv.org/abs/2506.04704)
### Authors
Youngwan Lee,Kangsan Kim,Kwanyong Park,Ilcahe Jung,Soojin Jang,Seanie Lee,Yong-Ju Lee,Sung Ju Hwang
### Background
尽管在增强视觉语言模型（VLMs）的安全性方面已经进行了大量努力，但当前的方法仍存在两个主要不足。1）现有的安全调优数据集和基准仅部分考虑图像-文本交互如何产生有害内容，往往会忽略看似无害的配对下的情景不安全结果。这种狭窄的覆盖范围使VLMs在未见配置下容易遭受脱狱攻击。2）先前的方法主要依赖基于数据的调优，而缺乏从根本上增强安全性的架构创新。本文通过引入一个全面的安全数据集和基准HoliSafe来解决这些差距。HoliSafe涵盖了所有五种安全/不安全的图像-文本组合，提供了更加稳健的基础来进行训练和评估（HoliSafe-Bench）。作者进一步提出了一种新颖的模块化框架，以增强VLM的安全性。该框架包括一个视觉守护模块（Visual Guard Module, VGM），旨在评估输入图像对VLM的有害性。该模块赋予VLM双重功能：不仅可以学习生成更安全的响应，还可以提供可解释的有害性分类，以证明拒绝决策的理由。这种方法的一个显著优点是其模块化，VGM被设计为插件组件，可无缝集成到各种规模的预训练VLM中。实验表明，基于HoliSafe训练的Safe-VLM结合VGM实现了多种VLM基准的最先进的安全性性能。此外，HoliSafe-Bench自身揭示了现有VLM模型中存在的关键漏洞。希望HoliSafe和VGM将促使对未来多模态对齐的研究进一步关注稳健和可解释的VLM安全性，开辟新的研究途径。
### Innovation
本文的主要创新包括：1）全面的安全数据集和基准HoliSafe，涵盖了所有五种安全/不安全的图像-文本组合，提供了更为稳健的基础来训练和评估。2）提出了一个新颖的模块化框架，包括一个视觉守护模块（VGM），用于评估输入图像对VLM的有害性，赋予VLM双重功能，既能生成更安全的响应，也能进行可解释的有害性分类。3）模块化的VGM设计为插件组件，可以无缝集成到各种规模的预训练VLM中。4）实验表明，基于HoliSafe训练和集成VGM的Safe-VLM在多个VLM基准上达到了最先进的安全性性能，并揭示了现有VLM模型中的关键漏洞。
### Conclusion
本文介绍了全面的安全数据集和基准HoliSafe以及与之结合的视觉守护模块（VGM）。通过这些创新，可以显著提升VLM的安全性性能，并提供更可解释的决策过程。未来的研究应进一步利用这些工具来开发更加稳健和可解释的VLM安全性，推进多模态对齐领域的进展。
## 428. `cs.CV` - 通过视觉语言True/False验证的零样本 referring表达理解 [PDF](https://arxiv.org/pdf/2509.09958), [HTML](https://arxiv.org/abs/2509.09958)
### Authors
Jeffrey Liu,Rongbin Hu
### Background
以往的研究通常使用专门训练的场景解析模型来处理referring表达理解(REC)任务。尽管这种模型可以取得良好的效果，但本研究提出了一种零样本工作流程，能够在没有任何专门训练的情况下实现与或超越已有训练过的模型的性能。这种方法将REC任务重新定义为基于区域的视觉语言验证，从而简化了跨区域干扰的处理，并支持弃权和多重匹配，无需微调。
### Innovation
该研究创新性地将REC任务重新定义为基于区域的视觉语言验证过程，提出了一种无需任何特定任务训练的零样本工作流程。这种方法利用YOLO-World生成的提议，由通用VLM独立回答每个区域的True/False查询，显著降低了跨区域干扰，支持弃权和多重匹配，并且无需微调。此外，研究发现，验证过程在控制实验中显著优于基于选择的提示，结果在多种开放模型中保持一致。
### Conclusion
该研究证明，工作流程设计比特定任务的预训练更为重要，能够驱动强烈的零样本REC性能。值得注意的是，即使在使用未微调的模型时，这种方法也超过了以前训练过的模型的表现。
## 429. `cs.CV` - FlexAC：向模态大语言模型中灵活控制关联推理的方向 [PDF](https://arxiv.org/pdf/2510.11190), [HTML](https://arxiv.org/abs/2510.11190)
### Authors
Shengming Yuan,Xinyu Lyu,Shuailong Wang,Beitao Chen,Jingkuan Song,Lianli Gao
### Background
模态大语言模型（MLLMs）在保持忠实性和增强创造力之间存在固有的权衡关系，因为不同的任务需要不同程度的联想推理。然而，现有的方法在调节这种推理强度以达到跨事实性和创造性场景的适应能力方面缺乏灵活性。
### Innovation
本文提出了一种名为Flexible Association Control (FlexAC) 的框架，旨在调节MLLMs中的联想行为。FlexAC通过诱导由幻觉引导的中间表示来编码联想方向，选择高度关联的例子来构建有效的联想引导向量，并通过适应性调整来平衡创造性和输出稳定性之间的权衡。此外，FlexAC还引入了来自目标域样本前向传递的任务特定联想向量，增强了模型对多种关联方向的跟随能力，更好地适应创造性任务。
### Conclusion
本文的方法在 Creation-MMBench 上提高了最多5.8倍的创造性，并在CHAIR上将幻觉率降低了29%，超越了现有的基线方法，证明了在MLLMs中实现联想推理的灵活控制的有效性。
## 430. `cs.CV` - Hemorica：用于自动化脑出血分类、分割和检测的综合CT扫描数据集 [PDF](https://arxiv.org/pdf/2509.22993), [HTML](https://arxiv.org/abs/2509.22993)
### Authors
Kasra Davoodi,Mohammad Hoseyni,Javad Khoramdel,Reza Barati,Reihaneh Mortazavi,Amirhossein Nikoofard,Mahdi Aliyari-Shoorehdeli,Jaber Hatam Parikhan
### Background
颅内出血（ICH）的CT扫描及时诊断仍是临床优先考虑的问题，但开发稳健的人工智能（AI）解决方案受到公共数据碎片化的阻碍。由于目前缺乏大型且统一的公共数据集，这阻碍了AI技术的发展。
### Innovation
Hemorica是一个公开可用的数据集，包含了2012年至2024年间372个头部CT扫描，每个扫描都有详尽的五个ICH亚型（硬膜外、硬膜下、蛛网膜下腔、脑实质内、室管膜内）的注释，支持多任务和渐进式学习，还提供了轻量级模型的基准参考。这为设计基于AI的ICH检测和定量系统提供了支持。
### Conclusion
Hemorica通过详细的注释和标准化的工作流程提供了高质量的标注，轻量级模型在二元分类和分割任务中都达到了较高的性能，表明该数据集不仅标注质量高，样本量也足够，可用于多种AI技术的开发、验证和转移适用性研究。
## 431. `cs.CV` - RealDPO: 实际还是虚构，这是偏好 [PDF](https://arxiv.org/pdf/2510.14955), [HTML](https://arxiv.org/abs/2510.14955)
### Authors
Guo Cheng,Danni Yang,Ziqi Huang,Jianlou Si,Chenyang Si,Ziwei Liu
### Background
视频生成模型在合成质量方面已取得了显著进步，但生成复杂的动态动作依然是一项关键挑战。现有模型往往难以产出自然、流畅且语境一致的动态动作。这使得生成的动态动作与现实世界动作之间的差距限制了其实际应用。
### Innovation
本文引入了RealDPO，一种新颖的对齐范式，利用真实世界数据作为正样本进行偏好学习，从而提升动态动作合成的准确性。RealDPO利用直接偏好优化（DPO）与定制损失函数来增强动态动作的真实性。通过对比真实世界视频和模型错误输出，RealDPO能够进行迭代自我校正，逐步提高动态动作质量。此外，提出了RealAction-5K，这是一个精心编排的数据集，包含高质量捕捉人类日常活动的视频，具有丰富的精确动态细节，以支持复杂动态动作的后训练。
### Conclusion
实验结果表明，RealDPO在视频质量、文本对齐和动态动作真实性方面显著优于现有顶级模型和传统偏好优化技术。
## 432. `cs.CV` - 使用表示相似性分析比较计算病理基础模型 [PDF](https://arxiv.org/pdf/2509.15482), [HTML](https://arxiv.org/abs/2509.15482)
### Authors
Vaibhav Mishra,William Lotter
### Background
计算病理（CPath）领域中，基础模型由于能在促进许多后续任务方面发挥作用而逐渐得到发展。尽管最近的研究评估了模型在不同任务上的表现，但人们对这些模型学习表示结构和变异性的了解还相对较少。本研究通过使用计算神经科学领域流行的分析技术，系统地分析了六个CPath基础模型的学习表示空间，为我们提供了关于这些模型表示属性的新见解。
### Innovation
本文的创新之处在于采用代表相似性分析（RSA）的方法，系统地比较了六个基于不同学习范式的CPath基础模型的表示空间。研究发现了新颖的发现，例如，具有相同训练范式的模型（视觉仅限 vs. 视觉语言）并不保证表示更加相似，同时证明了统一训练和语言视觉训练对模型表示的影响不同。这为提高模型对特定切片特征的鲁棒性和模型集成策略提供了指导，并且提供了有关训练范式如何影响模型表示的见解。这一框架有望在医学成像领域扩展，以支持基础模型的有效开发和部署。
### Conclusion
本研究通过代表相似性分析发现，不同训练范式的模型表现出不同的表示结构，滑依赖性高而疾病依赖性相对较低，并且在标准和方法上的改进将有助于提高模型的鲁棒性，指导模型集成策略，并为理解不同训练范式对模型表示的影响提供见解。这些发现对于计算病理基础模型的研究具有重要意义，并为相关领域的未来发展提供了指导。
## 433. `cs.CV` - Gestura: 一种连接动作与语义的LVLM驱动系统，用于实时自由式手势理解 [PDF](https://arxiv.org/pdf/2510.21814), [HTML](https://arxiv.org/abs/2510.21814)
### Authors
Zhuoming Li,Aitong Liu,Mengxi Jia,Yubi Lu,Tengxiang Zhang,Changzhi Sun,Dell Zhang,Xuelong Li
### Background
自由式手势理解在人机交互中非常吸引人，因为它使用户摆脱预定义手势类别的限制。然而，目前唯一的方法GestureGPT在识别准确性和响应时间方面存在局限。因此，需要一种更有效的系统来实时理解和处理自由式手势。
### Innovation
该论文提出了一种名为Gestura的端到端系统，该系统利用预训练的大规模视觉-语言模型（LVLM）来匹配自由式手势的动态和多变模式，并将其与高层次的语义概念对齐。Gestura还引入了肢体处理模块和基于步骤的推理策略，前者通过嵌入解剖手部先验知识解决了LVLM缺乏精细领域知识的问题，后者则通过逐步的语义推理将浅显知识转化为深层次的语义理解，增强对模糊或不寻常手势的理解能力。此外，该研究还开发了一个开源的手势意图推理和理解数据集，包含超过30万条标注的问答对。
### Conclusion
Gestura通过这些组件实现了稳健且适应性强的自由式手势理解。通过这种方式，该系统能够实现实时、高效且准确地理解和解释自由式手势，这将极大地提升人机交互的用户体验。
## 434. `cs.CV` - 通过CLIP进行 caption驱动的解释：探测 CNNs 的偏差 [PDF](https://arxiv.org/pdf/2510.22035), [HTML](https://arxiv.org/abs/2510.22035)
### Authors
Patrick Koller(Northwestern University, Evanston, Illinois, United States),Amil V. Dravid(University of California, Berkeley, California, United States),Guido M. Schuster(Eastern Switzerland University of Applied Sciences, Rapperswil, St. Gallen, Switzerland),Aggelos K. Katsaggelos(Northwestern University, Evanston, Illinois, United States)
### Background
在机器学习（ML）中，鲁棒性已经成为一个极为关键的问题。解释黑盒模型以理解其行为并提升其鲁棒性的科学被称为可解释的人工智能（XAI）。目前，计算机视觉问题中一项先进的XAI方法是生成显著性图。显著性图会突出显示模型被激发最强烈的图像的像素空间。然而，如果存在重叠像素空间中的错误且显著的特征，这种方法可能会导致误导。因此，本文提出了一种基于语句的XAI方法，通过将被解释的独立模型与对比语言-图像预训练（CLIP）模型进行整合，并采用一种新的网络手术方式实现。这种方法能够识别对模型预测贡献最大的主导概念，从而减少独立模型落入环境变化风险，有助于开发出更鲁棒的机器学习模型。
### Innovation
提出了一种基于语句的XAI方法，通过将被解释的独立模型与对比语言-图像预训练（CLIP）模型进行整合，并采用一种新的网络手术方式实现。这种方法能够识别对模型预测贡献最大的主导概念，从而减少独立模型落入环境变化风险，有助于开发出更鲁棒的机器学习模型。
### Conclusion
基于语句的XAI模型能够识别对模型预测贡献最大的主导概念，从而减少独立模型落入环境变化风险，对该类问题产生了积极的影响，贡献显著地促进了开发更鲁棒的ML模型。
## 435. `cs.CV` - 残差扩散桥梁模型用于图像恢复 [PDF](https://arxiv.org/pdf/2510.23116), [HTML](https://arxiv.org/abs/2510.23116)
### Authors
Hebaixu Wang,Jing Zhang,Haoyang Chen,Haonan Guo,Di Wang,Jiayi Ma,Bo Du
### Background
扩散桥梁模型为任意配对分布之间建立了概率路径，并展现了在通用图像恢复中的巨大潜力。然而，现有大多数方法仅仅将扩散桥梁视为简单的随机插补变体，缺乏统一的分析视角。此外，传统方法通过全局噪声注入和移除来重建图像，不可避免地会由于不完美的重建而扭曲未损坏区域。
### Innovation
提出了一种残差扩散桥梁模型（RDBM），重新理论化了广义扩散桥梁的随机微分方程并推导出了其正向和反向过程的解析公式。通过利用给定分布的残差来调节噪声的注入和移除，实现了对受损区域的自适应修复和对未受损区域的保真度保留。深入揭示了现有桥梁模型的基本数学本质，证明所有这些模型都是RDBM的特例，且实证展示了所提模型的最优性。
### Conclusion
通过大量实验，验证了该方法在不同图像恢复任务中的先进性能。相关代码已公开。（链接见文章）
## 436. `cs.CV` - TIR-Bench: 为代理图像思维推理制定的全面基准 [PDF](https://arxiv.org/pdf/2511.01833), [HTML](https://arxiv.org/abs/2511.01833)
### Authors
Ming Li,Jike Zhong,Shitian Zhao,Haoquan Zhang,Shaoheng Lin,Yuxiang Lai,Chen Wei,Konstantinos Psounis,Kaipeng Zhang
### Background
目前视觉推理的前沿正朝着如OpenAI o3之类可以智能创建和操作工具以解决图像问题的模型发展，这种能力被称为带图像的链式推理。然而，现有的基准测试无法全面捕捉这种高级能力，最常见的基准测试（如视觉搜索）仅测试基本操作，例如定位和裁剪，这些操作缺乏对复杂、动态且工具依赖推理的洞察。
### Innovation
本文提出了TIR-Bench，一个全面的基准测试，用于评估13种不同任务中的代理图像思维推理能力。每个任务都要求创新工具使用进行图像处理和操作。此外，本文评估了22种不同时期的多模态大型语言模型，从开源模型到具有明确工具使用增强功能的模型。TIR-Bench 的结果表明，这种基准测试具有普遍的挑战性，强大的表现需要真正的代理图像思维推理能力。
### Conclusion
最终，本文展示了直接与代理微调之间的初步比较研究。
## 437. `cs.CV` - 穿越天气的源域LiDAR通过几何感知点丢失 [PDF](https://arxiv.org/pdf/2511.01250), [HTML](https://arxiv.org/abs/2511.01250)
### Authors
YoungJae Cheong,Jhonghyun An
### Background
LiDAR语义分割在恶劣天气中会因折射、散射和点丢失而退化，这会破坏几何形状。先前的工作在天气模拟、混合增强、领域随机化以及不确定性或边界正则化等方面有所进步，但仍然忽略了边界、角落和稀疏区域内的结构性缺陷。
### Innovation
作者提出了一种几何感知适配器（Light Geometry-aware adapter），该模块对方位角进行了校准，并应用了水平圆形填充以在0~360度的环绕边界上保持邻居的连续性。局部窗口的K-最近邻搜索收集了附近的点并计算了简化的局部统计信息，这些信息被压缩为紧凑的几何感知提示。训练期间，这些提示驱动区域感知的正则化，从而稳定在结构上脆弱区域的预测。该适配器即插即用，可以与增强技术互补，并且可以在训练期间仅启用，不影响推理成本。
### Conclusion
在仅源域的跨天气设置中，模型在SemanticKITTI上进行训练并在SemanticSTF上进行评估（没有目标标签或微调）。相较于数据中心化的增强基准，该适配器将mIoU提高了7.9个百分点；相较于类别中心化的正则化基准，提高了0.6个百分点。这些结果表明，基于几何的正则化是所有天气LiDAR分割的关键方向。
## 438. `cs.CV` - SurgViVQA：基于时间感知的手术场景视频问答 [PDF](https://arxiv.org/pdf/2511.03325), [HTML](https://arxiv.org/abs/2511.03325)
### Authors
Mauro Orazio Drago,Luca Carlini,Pelinsu Celebi Balyemez,Dennis Pierantozzi,Chiara Lena,Cesare Hassan,Danail Stoyanov,Elena De Momi,Sophia Bano,Mobarak I. Hoque
### Background
当前的视频问答（VideoQA）方法主要依赖于静态图像特征，而手术领域中现有的VideoQA模型经常无法捕捉视频中的动态信息，如动作和器械-组织交互，这使得它们难以准确理解手术过程中的关键步骤。现有的数据集通常缺乏时间上的注释，无法提供足够的动态信息来支持准确的程序解释。
### Innovation
本文提出了一种名为SurgViVQA的手术视频问答模型，它将视觉推理从静态图像扩展到了动态手术场景。模型采用了掩蔽视频-文本编码器来融合视频和问题特征，捕捉到了动作和工具-组织交互等时间线索，然后由一个微调后的语言模型将其解码为连贯的答案。该模型在构建的REAL-Colon-VQA数据集上进行了评估，并且在公共的EndoVis18-VQA数据集上也表现出了更好的性能，特别是在关键词准确性方面。
### Conclusion
SurgViVQA和REAL-Colon-VQA数据集为手术VideoQA提供了时间感知的理解框架，使得AI模型能够更有效地解释动态的手术程序上下文。此外，实验验证了模型在问题变化时的稳健性和泛化能力。相关代码和数据集可以在提供的链接中获取。
## 439. `cs.CV` - OmniVLA: 物理接地的多模态VLA与统一多传感器感知在机器人操作中的应用 [PDF](https://arxiv.org/pdf/2511.01210), [HTML](https://arxiv.org/abs/2511.01210)
### Authors
Heyu Guo,Shanmu Wang,Ruichun Ma,Shiqi Jiang,Yasaman Ghasempour,Omid Abari,Baining Guo,Lili Qiu
### Background
VLA模型通过大规模的视觉-语言预训练展现出了在机器人动作预测中的强大泛化能力。然而，现存的大多数模型仅依赖RGB相机，这限制了它们的感知能力以及相应的操纵能力。这些模型缺乏对物理现象和空间智能的有效理解，特别是在需要物理感知的任务中表现不足。研究者们需要一种能够集成多种传感器输入，并同时提供物理意义丰富的感知的多模态VLA模型，以提升机器人在实际操作中的性能和效率.
### Innovation
提出了一种名为OmniVLA的多模态VLA模型，该模型集成了诸如红外相机、毫米波雷达和麦克风阵列等新型传感器，克服了传统模型的感知局限。OmniVLA的核心在于“传感器遮罩图像”，这是一种将空间上接地且物理意义上有意义的遮罩叠加到RGB图像上的统一表示。模型基于RGB预训练的VLA骨干网络，采用多传感器感知架构进行训练。这种统一的多模式感知方法有助于模型在保持高效学习的前提下充分利用不同传感器的数据，从而实现更高效和更强泛化能力的学习效果.
### Conclusion
研究展示了OmniVLA在具有挑战性的实际任务中的卓越性能，其任务成功率达到了84%，相较于仅使用RGB数据的模型和原生传感器数据的模型，分别高出59%和28%。此外，OmniVLA还表现出更高的学习效率和更强的泛化能力，这为未来的机器人操作任务提供了新的解决方案和可能性.
## 440. `cs.CV` - X-Diffusion：使用横截面扩散模型从单张图像生成详细3D MRI体积 [PDF](https://arxiv.org/pdf/2404.19604), [HTML](https://arxiv.org/abs/2404.19604)
### Authors
Emmanuelle Bourigault,Abdullah Hamdi,Amir Jamaludin
### Background
磁共振成像（MRI）作为一种关键的诊断工具，但由于数据获取的广泛需求，高分辨率扫描往往速度较慢且成本较高。传统的MRI重建方法旨在加快此过程，通过填补K空间中缺失的频率分量，进行全3D扫描的重建。然而，这些方法需要进行全3D扫描，对时间与资源要求较高。
### Innovation
该研究引入了X-Diffusion，这是一种新颖的横截面扩散模型，可以从极少量的空间域输入中重建详细的3D MRI体积，实现从单张2D MRI切片或几张切片到3D重建的转换。X-Diffusion的独特之处在于，它在横截面训练和推断过程中将MRI数据视为整体的3D体积，而不同于之前的传统方法将MRI扫描视作标准平面上的单独2D切片（冠状面、横断面、矢状面）。
### Conclusion
在颅内肿瘤MRI和全身体MRI数据集上的实验结果表明，X-Diffusion不仅在未见数据上比现有最佳方法具有更高的量化准确性（PSNR），还能保持诸如肿瘤轮廓、脊柱曲度和脑体积等关键解剖特征。令人惊讶的是，该模型能够在仅接受脑部数据训练的情况下成功重建膝关节MRI，展示了其泛化能力。通过医学专家评估进一步确认了生成3D MRIs的临床相关性和真实度。因此，X-Diffusion是首项能够从高度受限的2D输入中生成详细3D MRI的方法，有潜力加速MRI采集并降低相关成本。
## 441. `cs.CV` - 评估Geo-基础模型在洪水淹没制图中的价值：针对Sentinel-1、Sentinel-2和PlanetScope进行模型基准测试以供终端用户使用 [PDF](https://arxiv.org/pdf/2511.01990), [HTML](https://arxiv.org/abs/2511.01990)
### Authors
Saurabh Kaushik,Lalit Maurya,Elizabeth Tellman,ZhiJie Zhang
### Background
Geo-基础模型（GFMs）能够快速且可靠地从卫星图像中提取空间和时间信息，通过利用地理位置和时间嵌入来改善洪水淹没图的绘制。尽管GFMs具有潜力，但它们是否优于传统模型如U-Net仍有待验证，特别是在不同传感器和数据可用性情景下缺乏系统比较，这影响了终端用户的模型选择指导。因此，该研究通过行星影像、Sentinel-1和Sentinel-2对三种GFMs（Prithvi 2.0、Clay V1.5、DOFA和UViT）进行评估，并与TransNorm、U-Net和注意力U-Net进行对比。
### Innovation
该研究通过跨传感器和数据可用性情景对多种GFMs进行了全面的系统比较。这填补了GFMs在洪水测绘应用中相对于传统模型性能的不确定性的空白，提供了有助于终端用户选择的模型基准测试。Clay在不同传感器上的表现优于其他模型，特别是在PlanetScope、Sentinel-2和Sentinel-1上的表现尤为突出。此外，Clay在计算时间和参数量上都具有明显优势，显示出基于GFMs的洪水测绘模型在降低计算成本和标注努力的同时仍能达到小幅至中等的准确度提升。
### Conclusion
Clay 在所有场景下的表现最佳，尤其在PlanetScope、Sentinel-2 和 Sentinel-1 上，且在计算时间和参数量上更具优势，显示出GFMs 与传统U-Net相比在洪水测绘准确性上的小到中等的改进，同时具有较低的计算成本和标注努力。
## 442. `cs.CV` - Shallow Diffuse: 通过扩散模型低维子空间实现稳健且不可见的水印 [PDF](https://arxiv.org/pdf/2410.21088), [HTML](https://arxiv.org/abs/2410.21088)
### Authors
Wenda Li,Huijie Zhang,Qing Qu
### Background
AI生成内容的广泛应用引发了对虚假信息和版权侵权的重大关注。水印技术是识别这些AI生成的图像并防止其滥用的关键方法。现有的水印技术普遍将水印嵌入扩散采样过程的整个流程中，但这种集成方式难以保持水印的稳健性和检测性。本文旨在解决这些问题。
### Innovation
提出了Shallow Diffuse，一种新的嵌入扩散模型输出中的稳健且不可见的水印技术。不同于现有方法，Shallow Diffuse通过利用图像生成过程中的低维子空间来解耦水印嵌入步骤。这种方法确保了大部分水印在该子空间的零空间内，有效分离了水印与图像生成过程。理论和实验证明，这种解耦策略显著提高了数据生成的一致性和水印的检测性。Shallow Diffuse在鲁棒性和一致性方面优于现有水印方法。
### Conclusion
通过广泛的实验进一步验证了Shallow Diffuse的有效性，其代码已公开。
## 443. `cs.CV` - 信息驱动的成像系统设计 [PDF](https://arxiv.org/pdf/2405.20559), [HTML](https://arxiv.org/abs/2405.20559)
### Authors
Henry Pinkard,Leyla Kabuli,Eric Markley,Tiffany Chien,Jiantao Jiao,Laura Waller
### Background
传统的成像系统设计模仿人类眼睛，以生成可视觉解析的测量结果。然而，现代成像系统在不依赖人类视觉的情况下对原始测量数据进行计算处理，这意味着原始测量数据的信息量变得比视觉解析性更重要。尽管测量信息量至关重要，但目前成像系统性能评估方法并未量化这一点，而是通过评估质量的特殊指标或借助于次级任务的性能来间接评估。
### Innovation
本文提出了信息驱动的成像系统设计的理论基础和实际方法，用于直接量化受到噪声影响的测量数据与其未知物体之间的互信息。通过拟合测量和噪声特性的概率模型，以及使用梯度优化技术来改进系统设计，开发了一种称为信息驱动编码分析学习（IDEAL）的技术。通过这种方式，研究结果显示互信息已经成为一种通用的成像系统性能度量标准，能够实现高效的设计优化和实际条件下的评估。
### Conclusion
通过信息驱动的方法，所设计的成像系统能够匹配端到端优化方法的性能。这些结果证明互信息可以作为一种通用的成像系统性能指标，不仅适用于计算机高效的优化设计，而且在实际环境中也具有评估能力。
## 444. `cs.CV` - DAMRO: 探入LVLM的注意力机制以减少对象幻觉 [PDF](https://arxiv.org/pdf/2410.04514), [HTML](https://arxiv.org/abs/2410.04514)
### Authors
Xuan Gong,Tianshi Ming,Xinpeng Wang,Zhihua Wei
### Background
尽管大视觉-语言模型（LVLM）取得了巨大的成功，但它们不可避免地会遇到幻觉问题。LVLMs中的视觉编码器和大规模语言模型（LLM）解码器都是基于Transformer的，模型通过注意力机制提取视觉信息并生成文本输出。我们发现，LLM解码器对图像标记的注意分布与视觉编码器高度一致，两者都倾向于关注背景标记而非图像中的指代对象。我们归因于非预期的注意分布是视觉编码器自身的潜在缺陷，这误导LLM过度强调冗余信息并生成对象幻觉。
### Innovation
提出了一种名为DAMRO的新颖无训练策略，通过‘钻入’LVLM的注意力机制来‘减少’对象幻觉。具体而言，该方法利用ViT的分类标记（CLS）过滤出背景中散布的高注意力异常标记，然后在解码阶段消除这些标记的影响。我们使用POPE、CHAIR、MME和GPT-4V辅助评估等多种基准对LVLMs（包括LLaVA-1.5、LLaVA-NeXT和InstructBLIP）进行了评估。结果表明，该方法显著减少了这些异常标记的影响，从而有效缓解了LVLM的幻觉问题。
### Conclusion
我们的方法有效地减少了LVLM中的对象幻觉问题。为了实现这一目标，我们提出了一种新颖的无训练策略DAMRO，并通过多个基准模型和评估方法验证了其有效性。
## 445. `cs.CV` - 评估并提高用于医学图像分析的合成胸部X光片的有效性 [PDF](https://arxiv.org/pdf/2411.18602), [HTML](https://arxiv.org/abs/2411.18602)
### Authors
Eva Prakash,Jeya Maria Jose Valanarasu,Zhihong Chen,Eduardo Pontes Reis,Andrew Johnston,Anuj Pareek,Christian Bluethgen,Sergios Gatidis,Cameron Olsen,Akshay Chaudhari,Andrew Ng,Curtis Langlotz
### Background
本文旨在探索生成合成胸部X光图像的最佳实践方法，并通过增加医学图像数据集来优化深度学习模型在分类和分割等下游任务中的性能。
### Innovation
该研究利用潜扩散模型根据文本提示或分割掩码生成合成胸部X光图像。研究中探索了使用代理模型和放射科医生反馈来提高合成数据质量的方法。研究还测量了将生成的合成图像添加到CheXpert、CANDID-PTX、SIIM和RSNA肺炎数据集中的实际图像上对分类和分割模型性能的改进，并采用了F1分数和Dice分数进行评估。
### Conclusion
生成合成胸部X光图像的最佳实践包括使用单一疾病标签或几何变换的分割掩码进行条件生成，以及可能使用代理模型进行微调以改进生成。
## 446. `cs.CV` - BasicAVSR：通过图像先验和增强的运动补偿实现任意尺度视频超分辨率 [PDF](https://arxiv.org/pdf/2510.26149), [HTML](https://arxiv.org/abs/2510.26149)
### Authors
Wei Shang,Wanying Zhang,Shuhang Gu,Pengfei Zhu,Qinghua Hu,Dongwei Ren
### Background
视频超分辨率（AVSR）旨在增强视频帧的分辨率，可能在各种缩放因子下进行，这带来了在空间细节再现、时间一致性以及计算复杂性方面的挑战。
### Innovation
本文提出了一个强大的基准模型BasicAVSR，通过整合四个关键组件：1) 基于图像拉普拉斯金字塔的自适应多尺度频率先验，2) 流向引导传播单元以从相邻帧中聚合时空信息，3) 第二阶运动补偿单元以实现更准确的相邻帧空间对齐，4) 超分辨率单元以生成规模感知且内容无关的上采样内核。此外，提出三种传播变体，以满足不同应用场景的需求：(i) 单向RNN单元用于严格在线推理，(ii) 带有限前瞻性的单向RNN单元用于可容忍小输出延迟的推理，(iii) 双向RNN单元用于计算资源较少受限的离线任务。实验结果表明，不同场景下模型的有效性和适应性。研究表明，BasicAVSR在超分辨率质量、泛化能力和推理速度方面显著优于现有方法。我们的工作不仅推动了AVSR的前沿研究，还将其核心组件扩展应用于多个框架以应对多种场景需求。
### Conclusion
通过广泛的实验，我们展示了BasicAVSR在这些不同场景下的有效性和适应性。我们的模型在超分辨率质量、泛化能力和推理速度方面均优于现有方法。
## 447. `cs.CV` - GASP: 效率高的生成对抗后缀 untuk 为生成大语言模型的突破性攻击 [PDF](https://arxiv.org/pdf/2411.14133), [HTML](https://arxiv.org/abs/2411.14133)
### Authors
Advik Raj Basani,Xiao Zhang
### Background
大语言模型在各种自然语言处理任务中展现出了显著的能力，但仍然容易受到精心设计的输入提示（称为 jailbreak 攻击）的影响，这些提示旨在绕过安全机制并引发有害反应。传统的防御方法依赖于手动启发式方法，但它们在普适性方面有限。尽管基于优化的方法可以自动化这一过程，但它们通常生成的提示不自然，容易被安全过滤器检测到，或者由于离散 token 优化的原因需要较高的计算成本。
### Innovation
本文介绍了一种名为 Generative Adversarial Suffix Prompter (GASP) 的新颖自动化框架，能够在完全黑盒环境中高效生成人类可读的 jailbreak 提示。GASP 利用潜空间的贝叶斯优化技术来快速探索连续的潜空间以生成对抗后缀，并采用目标迭代优化程序来平衡提示的一致性，从而提升攻击效果。
### Conclusion
通过全面的实验，研究表明 GASP 能够生成自然且有效的对抗后缀，显著提高了 jailbreak 攻击的成功率，缩短了训练时间，并加快了推理速度，因此，它是一个高效的、可扩展的解决方案，适用于大语言模型的红队测试。
## 448. `cs.CV` - 针对优化任务的人猴视觉背侧流模型的缩放定律 [PDF](https://arxiv.org/pdf/2411.05712), [HTML](https://arxiv.org/abs/2411.05712)
### Authors
Abdulkadir Gokce,Martin Schrimpf
### Background
近年来，受大量物体分类数据集训练的人工神经网络模型开始模拟灵长类动物大脑的核心物体识别行为和神经反应模式。虽然扩大计算资源、模型规模和数据集规模被认为可以提升任务性能，但这些增大对大脑响应的匹配度影响尚不清楚。本文系统地评估了在基准测试中训练的任务优化模型，这些基准涵盖了V1、V2、V4、IT区以及行为表现，探索了用于模拟灵长类视觉背侧流的缩放定律。尽管在较大的模型中行为拟合度持续提升，但在神经拟合度方面却没有进一步提升，这在不同模型架构和数据集条件下都成立。尽管模型具备更强的归纳偏置和数据集包含更好的图片，它们在计算效率上表现更好，但对于更高阶的视觉区域而言，大规模模型的增益尤为显著。尽管小规模模型在少量样本的情况下不能很好地匹配，但缩放当前模型和数据集已经足以匹配人类的核心物体识别行为，但未必能够改进对大脑视觉背侧流的建模，这表明需要采用新的策略来构造大脑模型的研究方向十分必要。
### Innovation
研究探索了用于模拟灵长类视觉背侧流的缩放定律，发现模型规模增加对行为拟合度提高明显，但对神经拟合度提高有限，这一结果在不同模型架构和数据集条件下都得到验证，即使模型具有更强的归纳偏置和高质量的图像数据也是如此。研究表明仅靠增加规模不足以提升大脑视觉背侧流模型的性能，需要探索新的方法和策略来改进。这一发现揭示了在深度学习应用领域对大脑认知行为模拟的新视角。
### Conclusion
尽管放大模型和数据集可以满足与人类核心物体识别行为的匹配，但无法显著提高大脑视觉背侧流模型的表现，突显了新型建模策略的必要性。未来的优化需要不断创新方法来提高神经拟合度。
## 449. `cs.CV` - Poutine: 视觉-语言-轨迹预训练和训练后强化学习使端到端自动驾驶稳健 [PDF](https://arxiv.org/pdf/2506.11234), [HTML](https://arxiv.org/abs/2506.11234)
### Authors
Luke Rowe,Rodrigue de Schaetzen,Roger Girgis,Christopher Pal,Liam Paull
### Background
在自动驾驶中保持良好的驾驶行为，特别是在异常场景中，仍是一个关键挑战。一种有前景的方法是利用大语言模型的通用知识和推理能力，将异常驾驶场景视为逻辑推理任务来解决。
### Innovation
提出了一种名为Poutine的方法，该方法仅使用一个现成的3B参数视觉-语言模型（VLM），无需额外组件即可通过简单的高可扩展性训练配方实现稳健的端到端自动驾驶。该方法首先通过视觉、语言和轨迹（VLT）令牌的自我监督下一个标记预测训练Poutine-Base，以学习强大的基本驾驶能力，然后通过一组人类偏好评价的例子进行细调，采用组相对策略优化（GRPO）。
### Conclusion
最终的Poutine模型在Waymo端到端驾驶基准测试中的RFS达到7.99，在2025年Waymo基于视觉的端到端驾驶挑战赛中获得第一名，显著领先。实验结果表明，传统的手工分词器或在先前工作中添加到基VLM的定制架构组件并非必要的，而是预训练的VLT与轻量级的RL微调相结合有望实现稳健和通用的自动驾驶。
## 450. `cs.CV` - 优化高效准确的脉冲神经网络通过自适应位分配 [PDF](https://arxiv.org/pdf/2506.23717), [HTML](https://arxiv.org/abs/2506.23717)
### Authors
Xingting Yao,Qinghao Hu,Fei Zhou,Tielong Liu,Gang Li,Peisong Wang,Jian Cheng
### Background
多比特脉冲神经网络 (SNNs) 最近成为热点研究领域，致力于追求能效和高精度的 AI。然而，随着参与的比特数量增加，相关的内存和计算需求开始显著上升，到一定程度时，性能提升变得不那么成比例。基于不同层级的重要性不同以及额外的比特可能浪费和相互干扰的想法，本文提出了一个自适应位分配策略，针对直接训练的 SNN，实现精细层次的内存和计算资源分配。因此，SNN 的效率和准确性可以得到提升。
### Innovation
本文提出了一个自适应位分配策略，结合了可学习和可调控的权重和脉冲时长参数化，以及针对变化的比特宽度和时长提出了精细化脉冲神经元，提出了步长更新机制来缓解可学习位宽度导致的步长不匹配问题。实验表明，这种方法能够降低总体的内存和计算成本，同时提升准确性。特别是在 ImageNet 上，SEWResNet-34 达到了 2.69% 的准确性提升和 4.16 倍的更低比特预算。
### Conclusion
本研究表明，通过自适应位分配策略优化 SNN，不仅能够减少整体的内存和计算成本，还能同时实现更高的准确性。实验结果证明了这种方法的有效性，并且将开源。
## 451. `cs.CV` - 跨模态因果干预用于阿尔茨海默病预测 [PDF](https://arxiv.org/pdf/2507.13956), [HTML](https://arxiv.org/abs/2507.13956)
### Authors
Yutao Jin,Haowen Xiao,Junyong Zhai,Yuxiao Li,Jielei Chu,Fengmao Lv,Yuxiao Li
### Background
轻度认知障碍(MCI)是阿尔茨海默病(AD)的前期阶段，在这个阶段早期诊断和干预可以有效延缓向痴呆症的进展。然而，由于多模态数据的选择偏倚和变量之间复杂的相互关系，AD 的诊断仍然是神经学中的一个重大挑战。
### Innovation
本文提出了一种新的跨模态因果干预框架名为MediAD（Mediator for Alzheimer's Disease），它采用大型语言模型(LLMs)对临床数据进行严格模板化总结，丰富了文本输入。MediAD结合磁共振成像(MRI)、临床数据和LLMs丰富后的文本数据，将参与者分类为认知正常(CN)、MCI和AD类别。该框架通过统一的因果干预方法隐式地缓解了观察性和非观察性混杂因素的影响。
### Conclusion
实验结果显示，该方法在区分CN/MCI/AD病例方面表现出色，在大多数评估指标上优于其他方法。研究展示了将因果推理与多模态学习集成在神经疾病诊断中的潜在价值。
## 452. `cs.CV` - JaneEye: 一种12纳米2K帧率每帧18.9μ焦耳的事件驱动眼球追踪加速器 [PDF](https://arxiv.org/pdf/2510.01213), [HTML](https://arxiv.org/abs/2510.01213)
### Authors
Tao Han,Ang Li,Qinyu Chen,Chang Gao
### Background
眼球追踪已经成为扩展现实(XR)中基于视线交互的关键技术。然而，传统的基于帧的眼球追踪系统往往无法满足XR对高精度、低延迟和高能效的要求。事件摄像头提供了一种有吸引力的替代方案，其时间和空间分辨率非常高，且功耗低。现有的眼球追踪设备在精度、延迟和能效方面仍存在不足。
### Innovation
本研究提出了JaneEye，一种专门为可穿戴设备设计的能量高效的事件驱动眼球追踪硬件加速器，利用稀疏的高时空分辨率事件数据。研究通过引入一种基于新型ConvJANET层的超轻量神经网络架构，简化了传统的ConvLSTM结构，仅保留了忘记门控，从而在减轻计算复杂性的前提下保证了时间建模的能力。该模型在3ET+数据集上的像素误差为2.45，仅使用17.6K参数，事件帧率最高可达1250Hz。通过自定义激活函数和定点量化等方法进一步提高了硬件效率。通过软硬件协同设计，12纳米ASIC实现可运行在400MHz，端到端延迟为0.5毫秒(相当于2000帧每秒FPS)，能量效率为18.9μ焦耳/帧。
### Conclusion
JaneEye在低功耗、高性能的眼球追踪解决方案方面取得了突破，适用于下一代XR可穿戴设备的集成。
## 453. `cs.CV` - 通过主动风险管理学习社交导航 [PDF](https://arxiv.org/pdf/2510.07871), [HTML](https://arxiv.org/abs/2510.07871)
### Authors
Erjia Xiao,Lingfeng Zhang,Yingbo Tang,Hao Cheng,Renjing Xu,Wenbo Ding,Lei Zhou,Long Chen,Hangjun Ye,Xiaoshuai Hao
### Background
本次报告描述了我们向IROS 2025 RoboSense挑战赛中的社会导航赛道提交的技术细节。该赛道旨在开发基于RGBD的感知和导航系统，使自主代理能够在动态的人口稠密室内环境中安全、高效地进行社交合规的导航。挑战要求代理以第一人称视角运行，仅使用车载传感器（如RGBD观察和里程计），禁止使用全局地图或特权信息，同时必须遵守社交规范，如保持安全距离和避免碰撞。
### Innovation
我们在此基础上引入了主动风险管理模块（Proactive Risk Perception Module）来增强社交导航性能。这种方法增强了Falcon模型，使其能够学习预测周围人类的距离为基础的碰撞风险评分，从而让代理能够发展出更加稳健的空间意识和主动避碰行为。
### Conclusion
在Social-HM3D基准上的评估证明，我们的方法提高了代理在拥挤室内环境中导航到目标时保持个人空间合规的能力，以2名参赛队伍的成绩在挑战中排名第二。
## 454. `cs.CV` - 基于粒子-网格神经动力学的RGB-D视频中可变形物体模型学习 [PDF](https://arxiv.org/pdf/2506.15680), [HTML](https://arxiv.org/abs/2506.15680)
### Authors
Kaifeng Zhang,Baoyu Li,Kris Hauser,Yunzhu Li
### Background
对可变形物体的动力学建模具有挑战性，由于它们多样的物理属性以及从有限的视觉信息中估计状态的困难。利用一种结合物体粒子和空间网格的混合表示的神经动态框架来应对这些挑战。粒子-网格模型捕捉全局形状和运动信息，同时预测密集的粒子运动，适用于各种形状和材料的物体建模。粒子表示物体的形状，而空间网格将3D空间离散化，以保证空间连续性并提高学习效率。通过与高斯散斑结合用于视觉渲染，该框架实现了对可变形物体的全学习驱动数字孪生，并生成3D的条件动作视频。实验表明，该模型能从机器人与物体互动的稀疏视角RGB-D录像中学习多样物体的动力学，也能在类别水平上对未见过的实例进行泛化。在仅少量相机视角的场景中，我们的方法优于现有基于学习和基于物理的动力学模拟器。此外，展示我们的学习模型在基于模型计划中的用途，实现了各类任务中的目标导向的物体操作。详情可访问here提供了项目的页面
### Innovation
提出了一种基于粒子-网格神经动力学框架，结合粒子和空间网格捕捉物体的全局形状和运动信息，预测密集的粒子运动，适用于各种形状和材料的物体建模；利用高斯散斑实现视觉渲染；该框架实现了可变形物体的全学习驱动数字孪生，并生成3D的条件动作视频；展示了在机器人与物体互动场景下从稀疏视角RGB-D录像中学习物体动力学的能力；方法在有限视角场景下优于现有基于学习和基于物理的动力学模拟器；学习模型亦适用于基于模型的计划，在各类任务中执行目标导向的物体操作
### Conclusion
该研究提出的方法通过集成粒子-网格模型和高斯散斑的视觉渲染，实现了对可变形物体的动力学建模。通过对机器人与物体互动的稀疏视角RGB-D录像进行学习，该模型能够生成3D的条件动作视频，并且在有限视角场景下表现优于现有方法。该方法在模型预测方面表现出色，能够进行目标导向的物体操作。
## 455. `cs.CV` - 面向临床应用的病理基础模型 [PDF](https://arxiv.org/pdf/2510.23807), [HTML](https://arxiv.org/abs/2510.23807)
### Authors
Hamid R. Tizhoosh
### Background
在非医疗领域，基础模型（FMs）通过大规模自我监督和多模态学习已经彻底改变了计算机视觉和语言处理。因此，它们在计算病理学中的快速采用被期望能带来类似的重大突破，特别是在癌症诊断、预后和多模态检索方面。然而，最近系统的评估揭示了基础模型存在的根本性缺陷，如诊断准确性低、鲁棒性差、几何不稳定性、计算需求大以及安全漏洞等问题。
### Innovation
本文通过分析这些缺陷，指出它们源于基础模型在主流AI中的通用假设与人类组织固有的复杂性之间更深层次的不匹配。提出了七种相关的原因：生物复杂性、不有效的自我监督、过度泛化、过度复杂的架构、缺乏领域特定创新、数据不足以及与组织斑块大小相关的根本设计缺陷。
### Conclusion
当前的病理基础模型在本质上仍然与组织形态的性质不匹配，需要对这些模型的基本范式进行根本性的反思。
## 456. `cs.CV` - Seg the HAB: Language-Guided Geospatial Algae Bloom Reasoning and Segmentation [PDF](https://arxiv.org/pdf/2510.18751), [HTML](https://arxiv.org/abs/2510.18751)
### Authors
Patterson Hsieh,Jerry Yeh,Mao-Chi He,Wen-Han Hsieh,Elvis Hsieh
### Background
随着气候变化加剧，特别是对有毒藻华（HAB），特别是蓝藻（cyanobacteria），的出现，这些藻类威胁到了水生生态系统的健康和人类健康。传统监测方法，如手工取样，劳动密集型且在时间和空间覆盖方面有限。近年来，基于视觉-语言模型（VLMs）的遥感技术在远程感知方面展现出了潜在的人工智能驱动解决方案，但在处理图像推理和定量藻花严重性方面仍面临挑战。
### Innovation
本研究引入了ALGae Observation and Segmentation (ALGOS)系统，这是一种结合了遥感图像理解与严重程度预测的分割和推理系统。ALGOS通过GeoSAM辅助的人类评估进行高质量分割掩模的校准，并利用NASA的Cyanobacteria Aggregated Manual Labels (CAML)对视觉语言模型进行了微调，以实现对严重程度预测。实验证明，ALGOS在分割和严重程度估计方面表现稳健，为实用且自动化的蓝藻监测系统铺平了道路。
### Conclusion
ALGOS系统结合遥感图像理解与严重程度预测，通过GeoSAM辅助的人类评估进行高质量分割掩模校准，并利用CAML数据集对视觉语言模型进行了微调。通过实验，ALGOS在不同场景下表现出了优秀的性能，有望推动实际和自动化的蓝藻监测系统发展。
## 457. `cs.CV` - TraceTrans: 转换与空间跟踪在手术预测中的应用 [PDF](https://arxiv.org/pdf/2510.22379), [HTML](https://arxiv.org/abs/2510.22379)
### Authors
Xiyu Luo,Haodong Li,Xinxing Cheng,He Zhao,Yang Hu,Xuan Song,Tianyang Zhang
### Background
图像到图像翻译模型在跨视觉领域转换图像方面取得了显著的成功，并且越来越多地被用于医学任务，如预测术后结果和模拟疾病进展。然而，现有的大多数方法主要致力于匹配目标分布，往往忽略了源图像和翻译图像之间的空间对应关系。这种局限性会导致结构上的不一致性以及幻象，削弱了预测的可靠性和可解释性。在临床上，这种挑战变得更加突出，因为需要高度精确的解剖准确性。
### Innovation
本文提出了一种新颖的可变形图像翻译模型——TraceTrans，适用于术后预测。该模型在生成图像的同时，明确揭示了与术前输入的时空对应关系，并生成与目标分布齐平的图像。框架包含一个用于特征提取的编码器和两个用于预测空间变形和合成翻译图像的解码器。预测的变形场对生成的输出施加空间约束，确保输出与原始源的解剖一致性。
### Conclusion
在医学美容和脑部MRI数据集上的 extensive 实验验证了 TraceTrans 的准确性和可解释性，突显了其在安全可靠临床部署中的潜力。
## 458. `cs.CV` - 从Legacy Survey of Space and Time的天文图像中进行推后估计的神经网络 [PDF](https://arxiv.org/pdf/2510.15315), [HTML](https://arxiv.org/abs/2510.15315)
### Authors
Yicun Duan,Xinyue Li,Camille Avestruz,Jeffrey Regier,LSST Dark Energy Science Collaboration
### Background
2026年，维拉·C·鲁宾天文台的时空遗产巡天（LSST）将全面运行，产生大量的天文图像。构建天文目录是基于天文图像数据的大多数科学流程中的一个基础步骤，但传统的方法难以提供统计一致性，而现有的概率方法由于计算效率低下、不准确或无法处理多波段叠加图像，无法满足需求。LSST将生成多波段叠加图像，这是其主要输出格式。为了应对这些挑战，本文探索了一种名为神经后验估计（NPE）的新的贝叶斯推理方法，该方法利用深度学习，实现计算效率和高准确度。这已被DC2模拟天空调查的数据集证实，该数据集高度真实且旨在模拟LSST的数据，NPE在光源检测、星系分类和星系形状测量等方面均优于标准LSST管道。NPE还提供了经过良好校准的后验近似。尽管在LSST图像的实际应用中可能存在一定程度的建模不准确，但可以通过多种策略减轻其影响。
### Innovation
提出了一种名为神经后验估计（NPE）的新贝叶斯推理方法，利用深度学习技术，既实现计算效率又保证高准确度。NPE在模拟LSST数据的DC2数据集上全体超越了标准的LSST管道，特别是在光源检测、星系分类和星系形状测量等方面。还提供了经过良好校准的后验近似。
### Conclusion
使用模拟数据获得的积极结果表明了NPE在时间和不存在建模不准确情况下的潜力。尽管NPE在实际LSST图像应用时不可能完全避免建模不准确的问题，但可以通过多种方法适度减小其影响。
## 459. `cs.LG` - 将时间序列深度学习模型应用于爱尔兰多年生黑麦草生长预测 [PDF](https://arxiv.org/pdf/2511.03749), [HTML](https://arxiv.org/abs/2511.03749)
### Authors
Oluwadurotimi Onibonoje,Vuong M. Ngo,Andrew McCarre,Elodie Ruelle,Bernadette O-Briend,Mark Roantree
### Background
草地在全球第二大陆地碳汇中占据重要地位，对生物多样性和碳循环调节发挥关键作用。爱尔兰的乳制品业是重要的经济贡献者，但面临着盈利性和可持续性的挑战。目前，草的生长预测依赖于不切实际的机械模型，本研究提倡使用适用于单一数据集的深度学习模型作为成本效益较高的替代方案。
### Innovation
提出了针对单变量数据集的深度学习模型，以预测爱尔兰科尔克地区的多年生黑麦草生长。特别地，一个时间卷积网络模型在此任务中表现出优异的性能，使用历史草高数据作为输入，其RMSE为2.74，MAE为3.46。该研究还通过涵盖34年1757周的全面数据集验证了最佳模型配置，此过程提供了对于模型行为深入了解，增强其对中国奶业可持续性实践的可靠性预测能力，进一步推动可持续奶业实践的发展
### Conclusion
该研究加深了我们对模型行为的理解，从而提高了草生长预测的可靠性，并为可持续乳品农业实践做出了贡献。
## 460. `cs.LG` - 共有的是什么？多模态模型在场景间推理时表现出幻觉现象 [PDF](https://arxiv.org/pdf/2511.03768), [HTML](https://arxiv.org/abs/2511.03768)
### Authors
Candace Ross,Florian Bordes,Adina Williams,Polina Kirichenko,Mark Ibrahim
### Background
多模态语言模型在应对开放词汇量中的物体时具有显著的能力。然而，最好的模型在现实世界的场景推理中仍然存在幻觉问题，这揭示了它们在现有饱和感知基准上的表现在现实世界推理中的差距。本文旨在填补这一差距，通过构建一个新的没有使用网络训练数据的新图像的基准测试，以调查多模态模型在场景间推理中的限制。
### Innovation
本文提出了一个新的基准测试，名为Common-O，专门用于评估模型在场景间推理中的表现。这项基准测试利用了人类认知测试的灵感，通过询问“共同点是什么？”来探查不同场景之间的推理。研究还发现，规模可以提供适度的改进，而专门使用多图像输入训练的模型则显示出更大的改进，揭示了多图像训练可能具有潜力。
### Conclusion
绝佳的表现最好的模型仅在Common-O上达到35%，而在Common-O Complex（更复杂的场景）中仅达到1%。该研究发现，当场景中存在相似物体时，模型更容易出现幻觉，这可能表明模型依赖于训练期间看到的对象共现。这些发现有望推动对场景间推理中幻觉挑战的研究。
## 461. `cs.LG` - 使用多模态语义扰动进行VLMs污染检测 [PDF](https://arxiv.org/pdf/2511.03774), [HTML](https://arxiv.org/abs/2511.03774)
### Authors
Jaden Park,Mu Cai,Feng Yao,Jingbo Shang,Soochahn Lee,Yong Jae Lee
### Background
近年来，视觉-语言模型（VLMs）在许多基准任务上取得了最先进的性能。然而，使用大规模、通常专有的预训练语料库可能导致测试集泄漏，从而导致虚增的性能表现。虽然过去的研究已经提出了一些减轻策略，如预训练数据的去污染和大型语言模型基准的重新设计，但对于被污染的VLMs检测方法的研究仍然很匮乏。已有检测方法要么全面失效，要么表现不一致。因此，本文旨在解决这个问题。
### Innovation
本文提出了一种新颖且简单有效的检测方法，基于多模态语义扰动，表明被污染的模型在受控扰动下无法泛化。此外，本文验证了该方法在多种现实污染策略下的有效性，证实了其鲁棒性和有效性。
### Conclusion
本文通过故意对开源VLMs进行污染，并在流行基准测试上展示现有检测方法的失效情况。进而提出了一种基于多模态语义扰动的新颖且简单有效的检测方法。最后，通过多种实际污染策略验证了该方法的可靠性和有效性，并将代码和扰动数据集公开。
## 462. `cs.LG` - 通过提示难度预测优化推理效率 [PDF](https://arxiv.org/pdf/2511.03808), [HTML](https://arxiv.org/abs/2511.03808)
### Authors
Bo Zhao,Berkcan Kapusuzoglu,Kartik Balasubramaniam,Sambit Sahu,Supriyo Chakraborty,Genta Indra Winata
### Background
生成语言模型在执行复杂的任务方面表现出色，但由于其庞大体量和长推理轨迹，部署成本较高。本文讨论了通过将每个问题分配给最有可能解决它的最小模型来减少计算量同时不牺牲准确性的方法。
### Innovation
提出了一种路由方法，利用s1.1-32B的中间表示训练轻量级预测器，预测问题的难度或模型的正确性，以指导不同推理模型之间的路由选择。实验表明，与随机分配相比，该方法在多样化的数学基准测试中提高了效率，并且在计算使用量减少的情况下，性能与s1.1-32B相当。
### Conclusion
研究结果表明，基于难度的路由策略在经济高效地部署推理模型方面是有效的。
## 463. `cs.LG` - 使用Gramian Angular Fields的联邦学习在异构物联网设备上进行隐私保护的心电图分类 [PDF](https://arxiv.org/pdf/2511.03753), [HTML](https://arxiv.org/abs/2511.03753)
### Authors
Youssef Elmir,Yassine Himeur,Abbes Amira
### Background
在物联网（IoT）医疗环境中，隐私保护的心电图（ECG）分类是亟待解决的问题。本文提出了一种联邦学习（FL）框架，通过将1D ECG信号转换为2D Gramian Angular Field（GAF）图像，实现低计算复杂度下的高效特征提取，同时确保敏感医疗数据保留在各个设备上，避免中央服务器汇集大量数据导致的隐私问题。此外，该研究也是首次在异构物联网设备上实验性验证基于GAF的联邦ECG分类，衡量性能和通信效率。
### Innovation
本文的主要创新点在于：1. 将1D ECG信号转换为2D GAF图像，利用卷积神经网络（CNN）进行高效特征提取；2. 首次在异构物联网设备上实验性验证基于GAF的联邦ECG分类；3. 采用边云集成的方法（部署在服务器、笔记本电脑和资源受限的Raspberry Pi 4上），评估在实际IoT环境中的可行性。
### Conclusion
实验结果显示，基于GAF的联邦学习模型（FL-GAF）在多客户端设置下实现了95.18%的高分类准确性，与单客户端基准相比，在准确性和训练时间上都显示出显著优越性。尽管GAF转换添加了额外的计算复杂度，但该框架在资源利用率和通信开销上表现高效。这些发现强调了轻量级、隐私保护的AI在物联网基于医疗监控中的应用潜力，支持在智能健康系统中的可扩展和安全边缘部署。
## 464. `cs.LG` - FusionDP: 基础模型辅助的分部分敏特征差异隐私学习 [PDF](https://arxiv.org/pdf/2511.03806), [HTML](https://arxiv.org/abs/2511.03806)
### Authors
Linghui Zeng,Ruixuan Liu,Atiquer Rahman Sarkar,Xiaoqian Jiang,Joyce C. Ho,Li Xiong
### Background
在隐私保护机器学习中，保护敏感训练数据的隐私至关重要。然而，在实际场景中，可能只需为数据中的部分特征提供隐私保护。例如，在重症监护病房（ICU）数据中，像年龄和性别这样的人口统计属性更容易重新识别，而原始实验室结果相对不敏感。传统的DP-SGD算法会在一个样本的所有特征中强制执行隐私保护，导致过度注入噪声和模型性能显著下降。
### Innovation
提出了一种FusionDP框架，该框架具有两个步骤，旨在增强在特征级别差异隐私下的模型性能。首先，利用大型基础模型通过非敏感特征来预测敏感特征，避免在模型训练过程中访问真实值，作为外部先验信息提供高质量的敏感属性估计。其次，引入了修改的DP-SGD算法，在模型训练过程中同时使用原始和预测的敏感特征，从而正式保护原始敏感特征的隐私。该框架通过在两种模态下的实验与现有隐私保护基线进行对比，显著提高了模型性能，同时保持了特征级别的隐私，验证了基础模型驱动的插补在不同模态下提高隐私-实用性权衡的潜力。
### Conclusion
FusionDP 方法有效地增强了在部分敏感特征级别上的隐私保护同时提升了模型性能，展示了基础模型驱动的插补在复杂医疗数据中的应用潜力，为不同模态的隐私保护与性能提升提供了一种新的解决方案。
## 465. `cs.LG` - 因架构而异：基于DEBA的架构感知自适应批量调度 [PDF](https://arxiv.org/pdf/2511.03809), [HTML](https://arxiv.org/abs/2511.03809)
### Authors
François Belias,Naser Ezzati-Jivan,Foutse Khomh
### Background
现有的自适应批量大小方法旨在加速神经网络训练，但这些方法通常采用统一的适应策略，适用于所有架构，忽略了不同类型架构的具体需求。因此，这种一刀切的方法并未充分利用不同架构在训练过程中的特定属性和需求。
### Innovation
提出了DEBA（动态高效的批量适应），一种自适应批量调度器，通过监控梯度方差、梯度范数变化和损失变化来指导批量大小的调整。此外，作者还提出了一个基于梯度稳定性的基线表征框架，用于预测哪些架构将从自适应调度中受益，并发现滑动窗口统计和足够的冷却期是成功的关键设计选择。
### Conclusion
研究表明，架构本身决定了自适应调整的有效性。对于轻量级和中等深度的架构，可以实现显著的训练速度提升和略高的精度改进。与此同时，这项工作挑战了自适应方法在不同架构上普遍适用的假设，并提供了首次系统证据表明批量大小适应需要一种架构感知的设计。
## 466. `cs.LG` - Sketch-Augmented Features Improve Learning Long-Range Dependencies in Graph Neural Networks [PDF](https://arxiv.org/pdf/2511.03824), [HTML](https://arxiv.org/abs/2511.03824)
### Authors
Ryien Hosseini,Filippo Simini,Venkatram Vishwanath,Rebecca Willett,Henry Hoffmann
### Background
图神经网络（GNN）通过迭代聚合局部邻域信息来处理图结构数据。尽管这种局部消息传递的范式提供了强大的归纳偏置并利用了图的稀疏性，但也带来了三个关键挑战：（i）长距离信息的过度压缩；（ii）节点表示的过度平滑化；以及（iii）表达能力有限。
### Innovation
本文通过将随机全局嵌入的节点特征，即所谓的‘草图随机特征’注入标准GNNs，使GNNs能够有效地捕捉长距离依赖关系。这些嵌入具有独特性、距离敏感性和拓扑无关性的特性，我们通过分析和实验表明，将这些特性注入GNNs后可以缓解上述问题。
### Conclusion
实验结果表明，这种策略在现实世界的图学习任务中可以一致地改善标准GNNs的性能，提供了一种独立的解决方案，并且还可以作为现有技术（如图位置嵌入）的补充改进。我们的源代码可以在[该网址]找到。
## 467. `cs.LG` - 笑，联系，互动：短视频中带有风格的评论生成 [PDF](https://arxiv.org/pdf/2511.03757), [HTML](https://arxiv.org/abs/2511.03757)
### Authors
Xuan Ouyang,Senan Wang,Bouzhou Wang,Siyuan Xiahou,Jinrong Zhou,Yuekang Li
### Background
短视频平台已成为现代互联网景观中的核心媒介，高效的信息发布和强大的互动性正在重塑用户参与和文化传播。用户互动中，评论在促进社区参与和内容再创造方面发挥着重要作用。然而，生成既符合平台规范又能够体现风格多样性及语境意识的评论仍然是一项重大挑战。
### Innovation
引入了一个模块化的多智能体系统（MAS）LOALGORITHM，用于可控短视频评论生成。系统集成了视频分割、上下文和情感分析，以及风格感知的提示构建。通过多模态大型语言模型（MLLM），LOALGORITHM可以处理视频输入，并通过明确的提示标记和少量示例实现精细的风格控制。系统支持六种不同的评论风格：双关语（同音词）、押韵、使用梗图、讽刺（反讽）、普通幽默和内容提取。为支持开发和评估，构建了一个双语数据集，使用来自抖音（中文）和YouTube（英文）的官方API，覆盖五大流行视频类型：喜剧选段、日常生活笑话、滑稽动物剪辑、幽默评论和脱口秀。评估结合了自动化的独特性、相关性和风格一致性指标，以及大规模的人类偏好研究，参与了40个视频和105名参与者。结果显示，LOALGORITHM显著超越了基础模型，在抖音上获得了90%以上的偏好率，在YouTube上为87.55%，显示出一个可扩展且文化适应性的框架，用于短视频平台上带有风格的评论生成，为增强用户参与和创造力提供了有前景的途径。
### Conclusion
LOALGORITHM 是一个可扩展且文化适应性的框架，用于短视频平台上的带风格评论生成，通过多模态模型和多智能体系统结合，实现了对不同评论风格的精细控制，并通过大规模的人类偏好研究证明了系统的有效性和优势。
## 468. `cs.CV` - SLAM&Render：神经渲染、高斯斑点图和SLAM交集的基准测试 [PDF](https://arxiv.org/pdf/2504.13713), [HTML](https://arxiv.org/abs/2504.13713)
### Authors
Samuel Cerezo,Gaetano Meli,Tomás Berriel Martins,Kirill Safronov,Javier Civera
### Background
原本用于新型视角合成和场景渲染的方法，如神经辐射场（NeRF）和高斯斑点图，现在开始被应用于同时定位与建图（SLAM）中。然而，现有的数据集未能包含两项技术面临的特定挑战，如_SLAM中的序列操作和跨视角及光照条件的一般化。数据通常由手持或悬挂在无人机或移动机器人上的传感器收集，这增加了精确再现传感器动作的复杂性。为解决这些问题，该论文提出了一种名为SLAM&Render的新数据集，旨在评估SLAM、新型视角渲染和高斯斑点图交叉领域的算法。通过使用机器人操作臂录制了一系列数据，该数据集包含40个与RGB-D图像、IMU读数、机器人运动数据和真实姿态流时间同步的序列。
### Innovation
该数据集特别为机器人操作臂录制，并详细记录了机器人运动数据，从而使研究者能够评估SLAM算法在机器人应用中的最新集成情况。数据集设计了五种布置，涉及消费级和工业级物体，在四种受控照明条件下进行，各序列有不同的训练和测试轨迹。所有序列保持静止状态，但包含不同程度的对象重排和遮挡。该数据集通过多个基准检验结果验证了其作为新兴研究领域相关基准测试的有效性，并通过引入新的数据形式使其成为SLAM和神经渲染等领域的开创性贡献。
### Conclusion
该数据集验证了自身作为新兴研究领域基准测试的有效性，并为相关研究提供了一个可靠的测试平台。通过提供详细的机器人动作数据和严格管理的照明条件，它为SLAM、新型视角渲染和高斯斑点图的相互交集领域的研究奠定了坚实的基础。
## 469. `cs.LG` - 使用加性模型的高阶因果结构学习 [PDF](https://arxiv.org/pdf/2511.03831), [HTML](https://arxiv.org/abs/2511.03831)
### Authors
James Enouen,Yujia Zheng,Ignavier Ng,Yan Liu,Kun Zhang
### Background
因果结构学习长期以来是从小数据中推断因果见解的核心任务。尽管现实世界中的过程往往表现出多层次的机制，但在因果发现过程中对交互过程的显式处理却很少受到关注。
### Innovation
本文将因果加法模型(CAM)扩展到包含更高阶交互作用的加法模型。引入了处理新结构所需的定义和理论工具，并延伸了通常的马尔可夫等价类，以使高阶有向超图识别结果可以反映出更复杂的结构。还探讨了为何学习更复杂的超图结构可能在实证上表现更好，更具约束性的假设，例如CAM，会导致更容易学习的超图和更好的有限样本复杂性。开发了一种改进的贪婪CAM算法来处理更复杂的超图搜索空间。
### Conclusion
最终展示了改进的贪婪CAM算法在合成实验中的实际用途。
## 470. `cs.LG` - 从静态到动态：基于能量引导扩散分层的离线到在线强化学习提升 [PDF](https://arxiv.org/pdf/2511.03828), [HTML](https://arxiv.org/abs/2511.03828)
### Authors
Lipeng Zu,Hansong Zhou,Xiaonan Zhang
### Background
离线到在线强化学习（RL）过渡带来了巨大的挑战，因为固定的行为策略在离线数据集中与在线学习期间不断变化的策略之间存在分布差异。尽管这个问题已经被广泛认识到，但很少有方法尝试明确评估或利用离线数据本身的分布结构，这在调整学习策略以适应不同类型的样本时留下了研究空白。
### Innovation
文章提出了一种创新方法，能量引导扩散分层（StratDiff），这种方法有助于实现离线到在线RL的更平滑过渡。StratDiff利用扩散模型从离线数据集中学习先验知识，然后通过能量基函数进行细化，以改进策略的模仿并生成在线微调时类似于离线行为的动作。对于每个样本，计算生成的动作与对应采样动作之间的KL散度，并据此将训练批次分为离线相似和在线相似的子集。离线相似样本使用离线目标进行更新，而在线相似样本遵循在线学习策略。
### Conclusion
文章通过将StratDiff与现成方法Cal-QL和IQL集成，并在D4RL基准测试上进行广泛的实验验证，展示了其有效性。实验结果表明，StratDiff显著优于现有方法，实现更好的适应性和更稳定的性能。
## 471. `cs.LG` - 信贷模型中的公平性和解释性：适应性解释框架在演变人群中的应用 [PDF](https://arxiv.org/pdf/2511.03807), [HTML](https://arxiv.org/abs/2511.03807)
### Authors
Shivogo John
### Background
随着借款人的行为演变、经济条件的变化以及监管环境的改变，现代信用评分系统的底层数据分布不断重塑。传统的解释性方法，如SHAP，假设数据和背景分布固定，当概念漂移发生时，这些解释变得不稳定且可能不公平。本文研究了这一挑战，并通过开发适应性解释框架，使解释能力与公平性能够适应动态变化的信贷模型。通过对多年的信贷数据集进行研究，研究将XGBoost预测建模与三种适应性SHAP变体结合，即：基于切片解释权重调整、基于滑动窗口背景样本的概念漂移感知SHAP重基线以及基于增量岭回归的在线代理校准。每种方法都通过预测性能（AUC、F1）、方向稳定性和排名稳定性（余弦相似度、肯德尔tau）以及公平性（人口均等性和重新校准）的度量标准与静态SHAP进行基准测试。结果显示，在时间稳定性和减少不同群体间差异性影响方面，适应性方法，特别是重基线和代理为基础的解释方法，显著提高而未降低预测准确性。鲁棒性测试，包括反事实扰动、背景敏感性分析和代理变量检测，进一步验证了在现实世界的情景下，适应性解释的稳定性。这些发现确立了适应性解释作为一种实用机制，保障了数据驱动的信用系统中的透明性、问责制以及伦理可靠性，并更广泛地适用于任何随人群变化而演变的决策模型中。
### Innovation
通过开发适应性解释框架，能够使解释能力与公平性适应动态变化的信贷模型，特别是通过基于切片解释权重调整、基于滑动窗口背景样本的概念漂移感知SHAP重基线以及基于增量岭回归的在线代理校准三种方法，提高了在时间上的稳定性并减少了对不同人群的影响差异，而不会牺牲预测准确性。同时，适应性解释还经受住了反事实扰动、背景敏感性分析和代理变量检测等鲁棒性测试，验证了在现实世界变化中的稳定性。
### Conclusion
这些发现确立了适应性解释作为一种实用机制，保障了数据驱动的信用系统中的透明性、问责制以及伦理可靠性，并更广泛地适用于任何随人群变化而演变的决策模型中。
## 472. `cs.LG` - 通过后续状态预测增强深度Q学习的Q值更新 [PDF](https://arxiv.org/pdf/2511.03836), [HTML](https://arxiv.org/abs/2511.03836)
### Authors
Lipeng Zu,Hansong Zhou,Xiaonan Zhang
### Background
深度Q网络（DQN）通过从回放缓冲区中采样的转换来估计未来回报。然而，DQN的目标更新往往依赖于由过去，可能不最优的策略产生的后续状态。这些状态不能提供有信息量的学习信号，导致更新过程中的高方差。当采样的转换与代理当前的策略严重不匹配时，这一问题更为突出。
### Innovation
提出了一个称为Successor-state Aggregation Deep Q-Network（SADQ）的新模型。SADQ使用随机过渡模型明确建模环境动力学，并将后续状态分布整合进Q值估计过程，实现了更稳定的、与策略对齐的价值更新。同时，SADQ利用建模的过渡结构探索了更高效的行动选择策略。理论保证表明SADQ保持无偏的价值估计并减少了训练方差。
### Conclusion
广泛的实验结果表明，SADQ在标准的强化学习基准和真实的向量控制任务中都比各种DQN变体更稳定、学习效率更高。
## 473. `cs.LG` - 从移动信号预测社会人口特征 [PDF](https://arxiv.org/pdf/2511.03924), [HTML](https://arxiv.org/abs/2511.03924)
### Authors
Ekin Uğurel,Cynthia Chen,Brian H. Y. Lee,Filipe Rodrigues
### Background
从移动数据推断社会人口属性可以帮助交通规划者更好地利用被动收集的数据集，但仍因移动模式与社会人口特征之间的关系较弱且不一致以及在不同情境下有限的概括性而面临挑战。
### Innovation
论文从三个角度解决了这个问题：首先，通过引入基于定向移动图的行为导向的高层次移动描述符来提高预测准确性并保持解释性；第二，引入了评估模型置信度和准确率均匀性的指标和可视化诊断工具；第三，开发了多任务学习框架，在共享表示中共同预测多个社会人口属性以提高泛化能力和样本效率。
### Conclusion
所提出的多层次移动描述符和多任务学习框架在训练数据有限或应用模型的不同时间点（即测试集分布与训练集不同）时，显著优于单任务模型，从而提高了预测性能。此外，提出了评估模型置信度和准确率均匀性的指标和可视化诊断工具，有助于量化不确定性。
## 474. `cs.LG` - 社会平台上的滞后预测基准数据集 [PDF](https://arxiv.org/pdf/2511.03877), [HTML](https://arxiv.org/abs/2511.03877)
### Authors
Kimia Kazemian(1),Zhenzhen Liu(1),Yangfanyu Yang(2),Katie Z Luo(1),Shuhan Gu(1),Audrey Du(1),Xinyu Yang(2),Jack Jansons(1),Kilian Q Weinberger(1),John Thickstun(1),Yian Yin(2),Sarah Dean(1) ((1) Department of Computer Science, Cornell University (Ithaca, USA), (2) Department of Information Science, Cornell University (Ithaca, USA))
### Background
社交和协作平台会产生多元时间序列轨迹，其中早期的互动（如查看、点赞或下载）可能几个月或几年后才会伴随着更高的影响力，例如引用、销售或评论。这种模式被称为Lead-Lag Forecasting（LLF）：给定一个早期的使用渠道（lead），预测一个关联但时间上有所延迟的结果通道（lag）。尽管这种模式非常普遍，但在时间序列社区中，LLF并没有作为一个统一的预测问题被研究，原因在于缺乏标准化的数据集。所以作者在此提供两个大规模的基准数据集，旨在支撑对LLF的研究。作者还指出其他具有类似滞后动态的领域，如维基百科、Spotify、电子商务和LinkedIn等。
### Innovation
作者构建了两个超高流量的基准数据集：arXiv（访问量到230万篇论文的引用）和GitHub（推送/关注到30万仓库的托管）。这些数据集提供了长期预测的理想平台，可以捕捉跨年的长时序动态、全范围的结果跨度，并且避免了采样的生存偏差。此外，作者还制定了数据的数据整理和清洗的所有技术细节，通过统计和分类测试验证了滞后动态的存在，并且对回归基准进行了参数化和非参数化的测试。
### Conclusion
这项研究建立了LLF作为一种新的预测范式，并为其在社会和使用数据中的系统探索提供了实证基础。数据门户和支持材料可以在此处获取：[此链接](this https URL)。
## 475. `cs.LG` - SynQuE：在无需注释的情况下估计合成数据集质量 [PDF](https://arxiv.org/pdf/2511.03928), [HTML](https://arxiv.org/abs/2511.03928)
### Authors
Arthur Chen,Victor Zhong
### Background
在收集数据成本高昂或存在隐私限制的情况下，现实世界中可用于训练的数据稀缺，这给数据集选择带来了巨大挑战。为了缩小这一差距，研究人员提出了SynQuE（Synthetic Dataset Quality Estimation，合成数据集质量评估）问题，旨在通过有限的未标注实际数据来评估合成数据集在实际任务中的预期性能。
### Innovation
该研究是首次为SynQuE问题建立了全面的基准，通过引入并评估代理指标来选择合成数据进行训练，以最大化实际数据任务性能。研究还介绍了一种新的基于大型语言模型推理的代理指标LENS，该指标能够更好地处理复杂规划任务中的细微特征，从而在多个任务中表现优于其他代理指标，提高了任务性能，同时证明了SynQuE在数据稀缺场景下的实际可行性。
### Conclusion
本研究通过建立SynQuE框架，为在实际数据稀缺条件下选择合成数据提供了一种实用的方法，并通过实证结果证明了代理指标的有效性，特别是在复杂任务上表现更优。此工作还推动了基于基础模型的数据表征和细粒度数据选择的未来研究方向。
## 476. `cs.LG` - NVIDIA Nemotron Nano V2 VL [PDF](https://arxiv.org/pdf/2511.03929), [HTML](https://arxiv.org/abs/2511.03929)
### Authors
NVIDIA:Amala Sanjay Deshmukh,Kateryna Chumachenko,Tuomas Rintamaki,Matthieu Le,Tyler Poon,Danial Mohseni Taheri,Ilia Karmanov,Guilin Liu,Jarno Seppanen,Guo Chen,Karan Sapra,Zhiding Yu,Adi Renduchintala,Charles Wang,Peter Jin,Arushi Goel,Mike Ranzinger,Lukas Voegtle,Philipp Fischer,Timo Roman,Wei Ping,Boxin Wang,Zhuolin Yang,Nayeon Lee,Shaokun Zhang,Fuxiao Liu,Zhiqi Li,Di Zhang,Greg Heinrich,Hongxu(Danny)Yin,Song Han,Pavlo Molchanov,Parth Mannan,Yao Xu,Jane Polak Scowcroft,Tom Balough,Subhashree Radhakrishnan,Paris Zhang,Sean Cha,Ratnesh Kumar,Zaid Pervaiz Bhat,Jian Zhang,Darragh Hanley,Pritam Biswas,Jesse Oliver,Kevin Vasques,Roger Waleffe,Duncan Riach,Oluwatobi Olabiyi,Ameya Sunil Mahabaleshwarkar,Bilal Kartal,Pritam Gundecha,Khanh Nguyen,Alexandre Milesi,Eugene Khvedchenia,Ran Zilberstein,Ofri Masad,Natan Bagrov,Nave Assaf,Tomer Asida,Daniel Afrimi,Amit Zuker,Netanel Haber,Zhiyu Cheng,Jingyu(Justin)Xin, Di (Allan)Wu,Nik Spirin,Maryam Moosaei,Roman Ageev,Vanshil Atul Shah,Yuting Wu,Daniel Korzekwa,Unnikrishnan Kizhakkemadam Sreekumar,Wanli Jiang,Padmavathy Subramanian,Alejandra Rico,Sandip Bhaskar,Saeid Motiian,Kedi Wu,Annie Surla,Chia-Chih Chen,Hayden Wolff,Matthew Feinberg,Melissa Corpuz,Marek Wawrzos,Eileen Long,Aastha Jhunjhunwala,Paul Hendricks,Farzan Memarian,Benika Hall,Xin-Yu Wang,David Mosallanezhad,Soumye Singhal,Luis Vega,Katherine Cheung,Krzysztof Pawelec,Michael Evans,Katherine Luna,Jie Lou,Erick Galinkin
### Background
该论文介绍了一种名为Nemotron Nano V2 VL的新模型，这是NVIDIA Nemotron视觉-语言系列的最新版本，旨在提供强大的实际文档理解、长时间视频理解和推理任务的能力。该模型相对于之前的Llama-3.1-Nemotron-Nano-VL-8B在所有视觉和文本领域都实现了显著的改进，通过改进模型架构、数据集和训练策略来达成这一目标。
### Innovation
Nemotron Nano V2 VL在NVIDIA的Nemotron Nano V2混合Mamba-Transformer语言模型基础上，通过引入创新的令牌减少技术，实现了长文档和视频场景中的更高推理吞吐量。此外，该模型在BF16、FP8和FP4格式中提供了模型检查点，并且分享了大量数据集、食谱和训练代码，以促进社区的研究和应用开发。这些改进使得Nemotron Nano V2 VL能够更高效地处理复杂的视觉和文本任务。
### Conclusion
NVIDIA Nemotron Nano V2 VL模型在视觉和文本处理领域取得了显著进步，并通过开源其模型、数据集、食谱和训练代码，展现了其开放性和灵活性，为未来的相关研究和应用提供了重要支持。
## 477. `cs.LG` - DecoHD：在极端内存预算下分解的超维度分类 [PDF](https://arxiv.org/pdf/2511.03911), [HTML](https://arxiv.org/abs/2511.03911)
### Authors
Sanggeon Yun,Hyunwoo Oh,Ryozo Masukawa,Mohsen Imani
### Background
分层是一种已证明的方法，可以在不改变输入输出的情况下缩小深度网络。本文将这一理念引入到超维度计算（HDC）中，但通常情况下减少内存容量会缩短特征轴，并削弱各种特性，如集中度和鲁棒性。在先前的HDC分解方法中，通过固定的原子超向量进行解码，这种方法不利于压缩学习到的类别原型。因此，需要一种新的方法来直接优化解码过程，以适应HDC的参数化表示，保留原有的连接捆绑和评分机制，同时在受限的内存预算下实现超压缩。
### Innovation
作者提出了一种新的方法DecoHD，通过在每层共享一组通道的分解HDC参数化中进行直接学习，并利用层间的乘法捆绑和最终的打包来生成由紧凑因子构成的宽表示空间。DecoHD通过一个轻量级的打包头压缩类别轴，同时保持原有的捆绑打包评分机制。训练是端到端的，推断过程仍然保持纯粹的HDC，与内存内/附近的加速器相兼容。在评估中，DecoHD在严格的部署预算下可以获得极端的内存节省，并且在类别的稀疏性、噪声鲁棒性、准确性等方面表现出色，且可大幅减少所需的训练参数数量。
### Conclusion
DecoHD在与较强非缩减的HDC基线相比，除了最坏情况下降低约5.7%的准确性之外，平均保持在0.1-0.15%的准确性范围内，拥有更好的随机比特翻转噪声鲁棒性，使用了多达约97%的少得多的可训练参数，在硬件上实现了比CPU、GPU以及基线HDC ASIC约为277倍至35倍的能量和速度收益。
## 478. `cs.LG` - RLHF: 一种全面的文化、多模态和低延迟对齐方法综述 [PDF](https://arxiv.org/pdf/2511.03939), [HTML](https://arxiv.org/abs/2511.03939)
### Authors
Raghav Sharma,Manan Mehta,Sai Tiger Raina
### Background
RLHF 是目前大型语言模型（LLMs）对齐的标准方法，但最近的研究已经超越了传统的基于文本的方法，开始关注多模态对齐、文化公平性和低延迟优化等内容的空白领域。现有的研究主要集中在强化学习算法，如 PPO、DPO 和 GRPO，以及近年来的新创新技术的比较和分析上，为构建更稳健、高效和公平的人工智能系统提供了理论基础和研究指导。
### Innovation
本文首次对多模态对齐、文化公平性和低延迟优化等关键领域的研究进行了系统性的回顾和分析，填补了这些领域的研究空白，同时对最新的强化学习算法进行了详细的技术分析，并指出了未来的研究挑战，为该领域的研究提供了重要的路线图。
### Conclusion
本文通过对RLHF方法的系统性综述，为构建更为稳健、高效和公平的AI系统提供了重要的理论基础和技术指导，同时也指出了该领域未来的研究方向和挑战。
## 479. `cs.LG` - LogHD: 通过分层类轴减少实现具有鲁棒性的超维度分类器压缩 [PDF](https://arxiv.org/pdf/2511.03938), [HTML](https://arxiv.org/abs/2511.03938)
### Authors
Sanggeon Yun,Hyunwoo Oh,Ryozo Masukawa,Pietro Mercati,Nathaniel D. Bastian,Mohsen Imani
### Background
超维度计算（HDC）适用于约束了存储、能量和可靠性的系统。传统的每类一个原型的设计需要O(CD)的存储空间（C为类别，D为维度）。先前的研究通过压缩特征轴减少了存储空间和计算复杂度，但牺牲了鲁棒性。因此，需要一种能够在减小存储空间的同时保持或增强分类器鲁棒性的方法。
### Innovation
LogHD引入了一种分层类轴减少方法，通过使用约n≈⌈log_k C⌉个字母大小为k的包超向量代替每类的C个原型，在D维激活空间中进行解码，将存储空间减少至O(Dlog_k C)的同时保持D维度。LogHD利用容量感知的代码表和基于图谱的解码，并与特征轴稀疏化结合使用，能在相似内存下保持目标精度，并在更高的比特翻转率下维持精度。LogHD的ASIC实例在能耗和速度上相较于AMD Ryzen 9 9950X和NVIDIA RTX 4090分别提高了498倍和62.6倍，并相较于特征轴HDC的ASIC基础实例提高了4.06倍能耗效率和2.19倍速度。
### Conclusion
LogHD在保持或增强分类器鲁棒性的同时，实现了具有竞争力的准确性，并能显著提高能量效率和减少延迟。
## 480. `cs.LG` - PrivacyCD：认知诊断中保护学生隐私的分层去学习 [PDF](https://arxiv.org/pdf/2511.03966), [HTML](https://arxiv.org/abs/2511.03966)
### Authors
Mingliang Hou,Yinuo Wang,Teng Guo,Zitao Liu,Wenzhou Dou,Jiaqi Zheng,Renqiang Luo,Mi Tian,Weiqi Luo
### Background
认知诊断（CD）模型需要移除特定学生的数据已成为迫切需求，这是由于用户越来越坚持他们的‘被遗忘权’。然而，现有的CD模型大多没有考虑隐私问题，并缺乏有效的数据遗忘机制。通用的遗忘算法直接应用在这类模型上效果不佳，因为它们在处理CD模型的独特异质结构时难以平衡遗忘的完全性、模型的有用性以及效率。
### Innovation
本文首次系统研究了CD模型中的数据遗忘问题，提出了一种新的高效算法：层级重要性导向遗忘（HIF）。关键洞察是，CD模型中的参数重要性在每一层都有不同的特征。HIF通过结合个体和层级级别的重要性创新的平滑机制，实现了对要遗忘数据相关参数的更精确区分。
### Conclusion
在三个真实数据集的实验中，HIF在关键指标上显著优于基线算法，为CD模型提供了用户数据删除请求的有效响应方案，并为部署高性能且保护隐私的人工智能系统开辟了道路。
## 481. `cs.LG` - 非参数化模型中随机高斯-牛顿优化与泛化界限的非渐近分析 [PDF](https://arxiv.org/pdf/2511.03972), [HTML](https://arxiv.org/abs/2511.03972)
### Authors
Semih Cayci
### Background
深度学习中的一个重要问题是高阶优化方法如何影响其泛化能力。本文分析了具有勒温伯格-马夸特阻尼和批量采样技术的随机高斯-牛顿（SGN）方法，用于训练具有平滑激活函数的过参数化深度神经网络。研究背景包括SGN方法在回归设置下的有限时间收敛性和非渐近泛化界限，强调了批量大小、网络宽度和深度对SGN性能的影响。
### Innovation
本文的理论贡献有两个方面。首先，通过参数空间中可变度量分析，建立了有限时间收敛界，其中明确地依赖于批量大小、网络宽度和深度。其次，推导了SGN在过参数化情况下的非渐近泛化界限，通过均匀稳定性本质表征了曲率、批量大小和过参数化对泛化性能的影响。研究结果指出了一个有利的泛化区域，其中高斯-牛顿矩阵沿优化路径的最小特征值越大，泛化能力越好，泛化稳定性越强。
### Conclusion
研究结果表明，在训练过参数化深度神经网络时，SGN方法在特定条件下能表现出良好的泛化特性，特别是当路径上的高斯-牛顿矩阵的最小特征值较大时，这种方法能提供更紧的泛化稳定性边界。
## 482. `cs.LG` - 条件分数学习在马尔可夫转移核中最快变化检测中的应用 [PDF](https://arxiv.org/pdf/2511.03953), [HTML](https://arxiv.org/abs/2511.03953)
### Authors
Wuxia Chen,Taposh Banerjee,Vahid Tarokh
### Background
研究了未知转移核的马尔可夫过程中快速变化检测的问题。传统方法通常依赖于明确的概率评估，这在高维数据生成的复杂系统中可能非常复杂。文章提出了一种直接从样本对$(boldsymbol{x}, boldsymbol{y})$中学习条件分数$abla_{boldsymbol{y}} text{log} p(boldsymbol{y}|boldsymbol{x})$的方法，从而避免了显式的概率评估，提供了学习转移动力学的实用方法。基于这一估计，开发了条件Hylväinen分数差异为基础的CUSUM过程来检测转移核的变化。通过确保增量边界，提出了统计的截断版本。利用均匀遍历马尔可夫过程的Hoeffding不等式，证明了误报平均时间的指数下界，并证明了检测延迟的渐近上界。这为高维马尔可夫模型中的分数为基础的检测提供了理论保证和实际可行性。
### Innovation
提出了一种从样本对$(boldsymbol{x}, boldsymbol{y})$直接学习条件分数$abla_{boldsymbol{y}} text{log} p(boldsymbol{y}|boldsymbol{x})$的方法，克服了传统方法依赖显式概率评估的局限性，并发展了一种使用条件Hylväinen分数差异的CUSUM过程来检测马尔可夫转移核的变化，同时还提出了统计的截断版本，提供了理论保证和实际可行性。
### Conclusion
通过直接学习条件分数并使用Hoplayer不等式，研究为高维马尔可夫模型提供了可靠的检测方法。结果表明，所提出的方法不仅具有理论保证，而且具有实际应用的可行性，可有效检测马尔可夫转移核中的快速变化。
## 483. `cs.LG` - 使用共同任务框架加速科学研究 [PDF](https://arxiv.org/pdf/2511.04001), [HTML](https://arxiv.org/abs/2511.04001)
### Authors
J. Nathan Kutz,Peter Battaglia,Michael Brenner,Kevin Carlberg,Aric Hagberg,Shirley Ho,Stephan Hoyer,Henning Lange,Hod Lipson,Michael W. Mahoney,Frank Noe,Max Welling,Laure Zanna,Francis Zhu,Steven L. Brunton
### Background
机器学习（ML）和人工智能（AI）算法正在工程、物理和生物学科学中重新定义和增强动态系统的表征和控制。这些新兴建模范式需要比较性度量标准来评估广泛多样的科学目标，包括预测、状态重构、泛化和控制，并考虑有限数据情况和嘈杂测量。现阶段急需一个客观的度量标准来比较当前实践科学和工程中快速发展和部署的各种算法。
### Innovation
本文提出了一种通用任务框架（CTF），它包括一系列具有多种实际常见目标的挑战数据集。CTF是关键的使能技术，促成了在传统应用如语音识别、语言处理和计算机视觉中的ML/AI算法的快速进步。CTF提供了一个评估和比较这些新兴算法的平台。
### Conclusion
CTF能够客观地实施不同的算法，从而加速科学发现，并推动ML/AI技术在科学研究和工程中的应用。
## 484. `cs.LG` - 通过合成模型生成实现可解释模型的大规模元学习 [PDF](https://arxiv.org/pdf/2511.04000), [HTML](https://arxiv.org/abs/2511.04000)
### Authors
Kyaw Hpone Myint,Zhe Wu,Alexandre G.R. Day,Giri Iyengar
### Background
决策树因其可解释性而在高风险领域（如金融和医疗保健）中广泛应用。现有的方法通常是基于真实数据进行预训练或生成最优决策树，这些方法可能在计算成本上较高。本文旨在解决这一问题，提出了一种高效且可扩展的方法，通过生成合成预训练数据来实现决策树的元学习。
### Innovation
提出了用于生成合成预训练数据的方法，以实现决策树的元学习。这种方法可以生成大量的、现实的大型数据集，并通过MetaTree变换器架构证明，这种方法在性能上能达到与使用真实数据预训练或计算密集型最优决策树相当的效果。此策略显着降低了计算成本，增强了数据生成的灵活性，并为可解释决策树模型的大规模和高效元学习铺平了道路。
### Conclusion
本文提出的方法实现了性能与真实数据预训练或最优决策树相当，但显著降低了计算成本，并且策略增强了数据生成的灵活性，为大规模和高效库解释决策树模型的元学习实现了可能。
## 485. `cs.LG` - 使用连续葡萄糖监测与机器学习识别代谢亚表型以指导个性化生活方式改变 [PDF](https://arxiv.org/pdf/2511.03986), [HTML](https://arxiv.org/abs/2511.03986)
### Authors
Ahmed A. Metwally,Heyjun Park,Yue Wu,Tracey McLaughlin,Michael P. Snyder
### Background
传统的静态葡萄糖阈值分类糖尿病和糖耐量受损可能会遮盖由胰岛素抵抗、β细胞功能障碍和 incretin 缺乏主导的生理生化异质性。研究表明，连续葡萄糖监测和可穿戴技术使非侵入性、动态代谢表型学成为可能。通过这种技术，可以利用家庭中的持续葡萄糖监测（CGM）结合口服葡萄糖耐量测试（OGTT）的高分辨率葡萄糖数据，准确预测肌肉胰岛素抵抗和β细胞功能的标准指标。此外，在现实世界中，个体对标准化餐后的血糖反应（PPGR），例如土豆相对于葡萄的血糖峰值，也可作为其代谢亚型的生物标志物。此外，结合可穿戴设备数据，表明惯常的饮食、睡眠和运动模式（尤其是其时间）与特定的代谢异常有关联，有助于个性化生活方式干预。
### Innovation
研究展示了如何利用连续葡萄糖监测和可穿戴技术结合机器学习，识别代谢亚表型，并提供个性化的生活方式建议。通过高分辨率的葡萄糖数据，机器学习模型可以准确预估肌肉胰岛素抵抗和β细胞功能。研究还揭示了特定代谢亚型对饮食干预的依赖性，从而发展出针对个体核心代谢缺陷的个性化营养、行为和药物治疗策略，这标志着预防糖尿病的精确时代的到来。
### Conclusion
CGM可以将早期葡萄糖异常的复杂性分解为可操作的亚表型。这种方法超越了简单的血糖控制，提出了针对个体核心代谢缺陷的个性化营养、行为和药物策略的新策略，从而推动了精确糖尿病预防的新时代。
## 486. `cs.LG` - TwIST: 在独立子网络训练中精心策划变换器的彩票 [PDF](https://arxiv.org/pdf/2511.03983), [HTML](https://arxiv.org/abs/2511.03983)
### Authors
Michael Menezes,Barbara Su,Xinze Feng,Yehya Farhat,Hamza Shili,Anastasios Kyrillidis
### Background
该研究介绍了一种名为TwIST的分布式训练框架，用于高效的大语言模型（LLM）稀疏化。背景在于传统的稀疏化方法通常需要额外的后处理步骤（例如校准或基于海森矩阵的方法），成本较高且效率低下。在尝试优化稀疏模型的过程中，研究者们试图找到一种不需要额外后处理的稀疏化方法，以在部署时实现无成本的剪枝，同时保持与最先进的后处理稀疏化方法相似的性能，尤其是在高稀疏度（例如50%以上）的情况下表现更优。
### Innovation
TwIST的独特创新在于并行训练多个子网络，定期聚合这些子网络的参数，并在训练过程中重新采样新的子网络。这一过程能识别出高质量的子网络（被誉为“金票据”），且不依赖于任何额外的后处理步骤。TwIST的方法能够在保持与最先进的后处理稀疏化方法相当的性能下，实现无额外成本的稀疏化部署。值得注意的是，TwIST生成的是结构性的密集矩阵，这在普通硬件（如CPU）上可以提供实际的推理加速和内存节省，而不支持高效的稀疏计算。
### Conclusion
研究结果表明，在不同的稀疏度下，TwIST在性能上具有显著优势，尤其是在50%以上的高稀疏度条件下的表现尤为突出。例如，在50%稀疏度下，TwIST能达到23.14的困惑度，而与之最接近的先有方法则为31.64；同时TwIST无需额外的微调或恢复开销即可实现可部署的稀疏LLM，是一种高效的训练时路径。
## 487. `cs.LG` - PETRA: 基于演化轨迹的预训练变换器用于SARS-CoV-2的突变预测 [PDF](https://arxiv.org/pdf/2511.03976), [HTML](https://arxiv.org/abs/2511.03976)
### Authors
Xu Zou
### Background
自SARS-CoV-2出现以来，其表现出快速且不可预测的进化轨迹，特征是持续出现免疫逃逸变异株。这给公共卫生和疫苗开发带来了持续的挑战。尽管大规模预训练变换器（GPTs）已经彻底改变了序列数据建模，但它们直接应用于噪声病毒基因组序列的能力是有限的。由于SARS-CoV-2的突变具有显著的空间和时间不平衡性，现有方法难以准确预测病毒的未来突变。研究提出了PETRA（Pretrained Evolutionary TRAnsformer），一种基于从系统发育树衍生的进化轨迹的新型变换器方法，而非直接使用原始RNA序列，以有效缓解测序噪声并捕捉病毒进化的层级结构。通过带权训练框架解决全球序列数据中的地理和时间上的不均衡问题，PETRA在预测SARS-CoV-2突变方面表现优异，相比最佳基线，其核苷酸突变的加权召回率为9.45%，刺突蛋白氨基酸突变的加权召回率为17.10%，而最优点分别是0.49%和6.64%。并且还展示了其在实时预测主要支系（如24F(XEC)和25A(LP.8.1)）方面的潜力。代码已经在该链接公开：this https URL
### Innovation
PETRA基于从系统发育树衍生的进化轨迹，而非直接使用原始RNA序列，有效缓解测序噪声并捕捉病毒进化的层级结构。通过带权训练框架解决全球序列数据中的地理和时间上的不均衡问题，显著提高了对未来SARS-CoV-2突变的预测能力，相较于现有基线模型，在核苷酸和刺突蛋白氨基酸突变预测上分别取得了显著提升，且能够在实时预测主要病毒支系突变方面展示其潜力。
### Conclusion
本研究通过引入PETRA（Pretrained Evolutionary TRAnsformer），基于系统发育树的进化轨迹，使用带权训练框架，显著提高了对SARS-CoV-2未来突变预测的准确性。该方法不仅在预测核苷酸和刺突蛋白氨基酸突变方面表现出色，具有较高的加权召回率，还在实时监测病毒变异方面展示了应用潜力。相关代码已公开以供进一步研究应用。
## 488. `cs.LG` - 大型模型可组合微调算法中的结构先验和模块化适配器 [PDF](https://arxiv.org/pdf/2511.03981), [HTML](https://arxiv.org/abs/2511.03981)
### Authors
Yuxiao Wang,Di Wu,Feng Liu,Zhimin Qiu,Chenrui Hu
### Background
大型预训练模型在多任务适应中面临高计算成本和结构不稳定的问题，需要一种集成图结构先验与模块化适配器的方法来解决这些问题。该方法通过引入关系矩阵来建模任务之间的依赖关系，明确地将节点和路径间的关联编码进图结构先验中，提供统一的结构约束来适配权重分配和路径选择。模块化适配器通过低秩映射和可插拔机制嵌入到不同层中，这在先验指导下实现了高效的任务间组合和复用，不仅提高了参数效率和训练稳定性，还缓解了多任务场景下的路径冲突和冗余计算。实验通过对超参数敏感性、环境敏感性和数据敏感性的分析，验证了在结构约束下的方法的一致性和优越性能。研究表明，提出的方法在保持模型轻量设计的同时显著提升了任务预测精度、适配权重分配精度和整体计算效率，突显了图先验和模块化机制在可组合微调中的协同优势。
### Innovation
提出了一种名为可组合微调的细调方法，该方法结合了图结构先验和模块化适配器。通过引入关系矩阵来表征任务之间的依赖关系，将节点和路径的关联明确编码到图结构先验中，从而提供统一的结构约束来适配权重分配和路径选择。这种方法通过低秩映射和可插拔机制嵌入模块化适配器到不同层，实现了高效的任务间组合和复用。这种方法不仅提高了参数效率和训练稳定性，还缓解了多任务场景下的路径冲突和冗余计算。此外，通过系统分析关键因素如路由温度、门限值和关系矩阵正则化强度，验证了在结构约束下的方法性能一致性与优越性。
### Conclusion
实验结果表明，提出的方法显著提升任务预测准确性、适配权重分配的精确度以及整体计算效率，同时保持了模型的轻量设计，展示了图先验与模块化机制在可组合细调中的协同优势。
## 489. `cs.LG` - 通过重建预训练的双分支动态选择增强多模态蛋白质功能预测 [PDF](https://arxiv.org/pdf/2511.04040), [HTML](https://arxiv.org/abs/2511.04040)
### Authors
Xiaoling Luo,Peng Chen,Chengliang Liu,Xiaopeng Jin,Jie Wen,Yumeng Liu,Junsong Wang
### Background
多模态蛋白质特征在蛋白质功能预测中起着关键作用，但这些特征包含广泛的多元信息，跨越结构数据、序列特征、蛋白质属性和互作网络，使得理解和解析这些复杂信息的关联变得困难。
### Innovation
提出了一种名为DSRPGO的多模态蛋白质功能预测方法，通过利用动态选择和重建预训练机制。引入了双向交互模块（BInM）以促进多模态特征之间的交互学习，并设计了动态选择模块（DSM）以选择对当前蛋白质功能预测最有利的特征表示。
### Conclusion
所提出的DSRPGO模型在人类数据集的BPO、MFO和CCO方面表现显著提高，从而优于其他基准模型。
## 490. `cs.LG` - 通过自适应分割计算实现受内存和延迟约束的大型语言模型推理 [PDF](https://arxiv.org/pdf/2511.04002), [HTML](https://arxiv.org/abs/2511.04002)
### Authors
Mingyu Sung,Vikas Palakonda,Suhwan Im,Sunghwan Moon,Il-Min Kim,Sangseok Yun,Jae-Mo Kang
### Background
大型语言模型（LLMs）在各种推理任务中已经达到了接近人类的性能，但在资源受限的物联网（IoT）设备上的部署仍不可行，原因在于模型的巨大参数量和内存密集型的自回归解码。分割计算提供了一种有前景的解决方案，即在边缘设备和云服务器之间分割模型执行。然而，现有的方法未能解决自回归推理的独特挑战，特别是迭代的token生成过程和不断扩展的关键值（KV）缓存要求。 
### Innovation
本文提出了第一个专门为边缘设备部署大型语言模型而设计的自回归感知分割计算框架。贡献包括开发了一点分割压缩（OPSC），这是一种混合精度量化方案，通过战略性地将模型分割为具有不同精度级别的前端和后端段来预防内存不足；提出了一种两阶段中间压缩管道，结合了阈值分割（TS）和基于token的自适应位量化（TAB-Q），以保持关键激活的精度同时大大减少通信开销；制定了一个统一的优化框架，联合选择最优分割点、量化设置和序列长度，以满足严格的内存和延迟约束。
### Conclusion
在多种大型语言模型和硬件平台上进行的广泛评估表明，与最先进的量化方法（包括SmoothQuant、OmniQuant和Atom）相比，该框架具有优越的性能，同时实现1.49的推理速度提高和显著的通信开销减少，并维持或提高了模型的准确性。
## 491. `cs.LG` - 多尺度神经营养网络钙动力学在异常检测中的生物合理智能 [PDF](https://arxiv.org/pdf/2511.03993), [HTML](https://arxiv.org/abs/2511.03993)
### Authors
Berk Iskar,Michael Taynnan Barros
### Background
传统的在网络异常检测系统中训练的检测器遇到多个挑战，容易受到概念漂移和新型威胁（如零日攻击或多态性攻击）的影响。这些问题导致检测性能下降，增加了误报和漏报的风险。为了克服这些问题，本文提出了一种Ca$^{2+}$-调制学习框架，该框架受到脑内星形胶质细胞钙$^{2+}$信号传导机制的启发，从而实现快速、上下文敏感的适应，提升信息处理的鲁棒性。该方法通过一个多细胞星形胶质细胞动力学模拟器与深度神经网络(DNN)的结合，来模拟星形胶质细胞钙$^{2+}$动力学，这在多列车/测试分割中展示了优异的效果，显著降低了误报和漏报率，且几乎没有运行时开销。该方法证明在网络安全领域有效，具有广泛适用于需要快速适应变化数据模式的流式检测任务的潜力。
### Innovation
本文提出了一种Ca$^{2+}$-调制学习框架，将生物学中星形胶质细胞钙$^{2+}$信号传导机制应用于网络异常检测。该框架包含一个多细胞星形胶质细胞动力学模拟器和深度神经网络(DNN)。模拟器通过IP$_3$介导的钙$^{2+}$释放、SERCA泵摄取和通过细胞间隙连接的传导性依赖扩散来建模星形胶质细胞钙$^{2+}$动力学。与传统方法相比，该方法在CTU-13 (Neris)网络流量数据集上表现更为出色，准确率高达约98%，并且误报和漏报率显著减少，运行时开销较小，预计算的Ca$^{2+}$轨迹即可实现这一性能提升。
### Conclusion
本文提出的Ca$^{2+}$-调制学习框架展示了其在网络安全应用中的有效性，并具有广泛应用于需要快速适应变化数据模式的流式检测任务的潜力。该方法通过生物合理的比率实现快速适应，证明了其在减少误报和漏报率方面的优势，并且在多列车/测试分割中取得了显著效果。
## 492. `cs.LG` - DartQuant: 效率导向的旋转分布校准方法用于大语言模型的量化 [PDF](https://arxiv.org/pdf/2511.04063), [HTML](https://arxiv.org/abs/2511.04063)
### Authors
Yuantian Shao,Yuanteng Chen,Peisong Wang,Jianlin Yu,Jing Lin,Yiwu Yao,Zhihui Wei,Jian Cheng
### Background
量化在加速大规模模型的推理过程中起着关键作用。旋转矩阵已被证明能通过平滑异常值有效提高量化性能。然而，端到端的旋转优化算法微调计算成本高且容易过拟合。
### Innovation
提出了一种高效的分布感知旋转校准方法，DartQuant，通过约束旋转后激活函数的分布来减少旋转优化的复杂性。此外，引入了QR-Orth优化方案，取代了昂贵的交替优化，提供了一个更高效的解决方案。实验结果表明，DartQuant 在多种模型量化实验中表现出优越性能，实现了70B模型旋转优化47倍的加速和10倍的内存节省，并且首次在单个3090 GPU上成功完成70B模型的旋转校准。
### Conclusion
DartQuant方法使大语言模型在资源受限环境中进行量化成为可能。相对于现有方法，DartQuant在70B模型旋转优化上实现了47倍的加速和10倍的内存节省，并且在单个3090 GPU上成功完成了旋转校准。
## 493. `cs.LG` - 使用nnU-Net进行MRI左心房分割 [PDF](https://arxiv.org/pdf/2511.04071), [HTML](https://arxiv.org/abs/2511.04071)
### Authors
Fatemeh Hosseinabadi,Seyedhassan Sharifi
### Background
左心房（LA）的准确分割对指导心房颤动（AF）消融和构建生物物理心脏模型至关重要。手动分割耗时、依赖观察者且不能满足大范围或时间敏感的临床工作流程需求。最近的研究表明，特别是卷积架构的深度学习方法，在医学图像分割任务中表现出色。本研究使用nnU-Net框架将其应用于2013年左心房分割挑战数据集，该框架是一种自动配置的深度学习分割架构，能够根据MRI数据的特点自动调整其预处理、网络配置和训练管道。
### Innovation
利用nnU-Net框架进行自动配置的深度学习分割，提高MRI左心房分割的准确性和效率，特别是在处理不同形状、对比度和图像质量的左心房方面表现出色。
### Conclusion
提出的nnU-Net模型在Dice相似度系数（DSC）评估中均值得分高达93.5，与专家标注高度重合，并在多个传统分割方法中表现出色，网络在不同左心房形态、对比度和图像质量下表现出良好的泛化能力，准确界定了心房主体和邻近肺静脉。
## 494. `cs.LG` - 儿科超声图像中的阑尾炎检测 [PDF](https://arxiv.org/pdf/2511.04069), [HTML](https://arxiv.org/abs/2511.04069)
### Authors
Fatemeh Hosseinabadi,Seyedhassan Sharifi
### Background
儿科阑尾炎是儿童急性腹痛最常见的原因之一，但由于症状重叠和影像质量的差异，其诊断对临床医师依然是一个挑战。该研究旨在利用预训练的ResNet架构开发和评估一种自动识别阑尾炎的深度学习模型，通过分析儿童患者的腹部超声图像数据，包括血液检测结果和临床评分，来提高诊断精度和效率。
### Innovation
研究采用了儿科患者腹痛住院期间的超声扫描数据集，利用预训练的ResNet模型对超声图像进行精调，以区分有阑尾炎和无阑尾炎的病例。通过数据预处理，包括归一化、重置大小和增强，提高了模型的泛化能力。研究结果显示，该模型在多种不同层次的超声图像中对阑尾炎的识别表现优异，准确率达到了93.44%，精确度达到了91.53%，召回率为89.8%，成功地学习了具有区分性的空间特征，克服了低对比度、多普勒噪声和儿童影像学中的解剖变异等挑战。
### Conclusion
所提出的ResNet模型在鉴别超声图像中存在阑尾炎的问题上表现优异，证明了使用深度学习模型进行自动检测的潜力与效果。
## 495. `cs.LG` - 学习多种过滤器意识的距离度量以进行带过滤器的最近邻搜索 [PDF](https://arxiv.org/pdf/2511.04073), [HTML](https://arxiv.org/abs/2511.04073)
### Authors
Ananya Sutradhar,Suryansh Gupta,Ravishankar Krishnaswamy,Haiyang Xu,Aseem Rastogi,Gopal Srinivasa
### Background
最近邻搜索中的过滤器近似最近邻(ANN)检索是从数据集中检索与查询向量最接近的向量。现有的基于图的方法通常通过固定惩罚或基于过滤器满足度优先处理节点的方式实现过滤器意识。然而，这些方法使用固定的、与数据无关的惩罚，难以有效适应具有多样标签和向量分布的数据集。
### Innovation
本文提出了一种理论上的替代方法，通过从数据中学习来直接实现向量距离和过滤器匹配的最佳权衡，而非依赖固定的惩罚。作者将此问题表示为一个带约束的线性优化问题，从而推导出更能反映基础过滤器分布的权重，更有效地解决过滤器ANN搜索问题。这些学习到的权重指导搜索过程和索引构建，能够更好地捕捉底层过滤器分布和过滤器语义，导致更有效的图形结构。
### Conclusion
实验证明，适应数据的距离函数能显著提高准确度，相对于固定惩罚方法提高5-10%，表明为此类问题提供了一种更灵活和可泛化的框架。
## 496. `cs.LG` - DeNoise：学习鲁棒图表示以实现无监督图级别异常检测 [PDF](https://arxiv.org/pdf/2511.04086), [HTML](https://arxiv.org/abs/2511.04086)
### Authors
Qingfeng Chen,Haojin Zeng,Jingyi Jie,Shichao Zhang,Debo Cheng
### Background
随着关键领域中图结构数据的迅速增长，无监督图级异常检测（UGAD）已成为一项重要的任务。UGAD专注于识别与正常行为模式显著偏离的完整图。然而，大多数基于图神经网络（GNN）的方法假定训练集是干净的，只包含正常图，这在实践中很少见。即使是轻微的异常图污染也会扭曲学习的表示形式并显著降低性能。
### Innovation
该研究提出了DeNoise，这是一种鲁棒的UGAD框架，专门设计用于处理受污染的训练数据。DeNoise通过对抗性目标同时优化图级编码器、属性解码器和结构解码器，学习对噪声具有抵抗力的嵌入。此外，DeNoise引入了一种基于编码器锚点对齐的去噪机制，将正常图中的高信息节点嵌入融合到所有图嵌入中，从而提高表示质量，同时抑制异常干扰。对比学习组件将正常图的嵌入聚集在潜在空间中，并推动异常图的嵌入远离。广泛的实验表明，DeNoise能够在不同噪声强度下始终学习可靠的图级别表示，并显著优于最先进的UGAD基线方法。
### Conclusion
DeNoise方法在多种真实世界数据集上表现出了出色的鲁棒性，能够有效处理训练集中存在的异常图，并显著提升了无监督图级异常检测的性能。
## 497. `cs.LG` - KoTaP：韩国公司税务规避、绩效和治理面板数据集 [PDF](https://arxiv.org/pdf/2511.04094), [HTML](https://arxiv.org/abs/2511.04094)
### Authors
Hyungjong Na,Wonho Song,Seungyong Han,Donghyeon Jo,Sejin Myung,Hyungjoon Kim
### Background
本文介绍了韩国家族税务规避面板数据集（KoTaP），这是一个从2011年至2024年在韩国综合证券市场（KOSPI）和韩国创业板市场（KOSDAQ）上市的非金融企业的长期面板数据集。排除掉金融机构、非12月制会计年度结束的公司、资本损失和税前亏损的公司后，最终数据集包含1,754家公司的12,653个观测值。KoTaP旨在将公司税务规避作为预测变量，并与收益管理、盈利能力、稳定性、增长率、治理等多个领域相关联。
### Innovation
KoTaP的特点在于其平衡的面板结构、标准化的变量和国际文献中核心指标分布和相关性的一致性。同时，它反映了韩国公司特有的结构性特征，如集中的所有权、高比例的外资持股和较高的流动性比率，从而提供了国际可比性和情境的独特性。该数据集支持基准经济计量学和深度学习模型的应用、外部有效性检查、可解释AI分析、政策评估、审计规划和投资分析，成为会计、金融和跨学科研究的重要公开资源。
### Conclusion
KoTaP为研究税务规避对绩效和治理的影响提供了重要的工具，具有高可解释性和国际可比性。对于政策制定者、会计师、投资者和研究人员来说，这是一个至关重要的开放资源。
## 498. `cs.LG` - 交换策略优化算法用于半无限安全强化学习 [PDF](https://arxiv.org/pdf/2511.04147), [HTML](https://arxiv.org/abs/2511.04147)
### Authors
Jiaming Zhang,Yujie Yang,Haoning Wang,Liping Zhang,Shengbo Eben Li
### Background
安全强化学习（安全RL）旨在在优化长期性能的同时遵守安全要求。然而，在许多实际应用中，问题涉及到无限数量的约束，即所谓的半无限安全RL（SI-safe RL）。这类问题通常出现在必须在整个连续参数空间（例如：确保每个空间位置的资源分布充足）强制执行安全性条件下，会遇到无限多的约束问题。
### Innovation
本文提出了一种名为交换策略优化（EPO）的算法框架，该框架实现了最优策略性能和确定性有界的安全性。EPO 通过迭代求解带有限约束集的RL子问题，并通过约束扩展和删除自适应地调整活跃集。在每一步迭代中，超过预定义容差的约束被添加以精细策略，而零拉格朗日乘数的约束在策略更新后被移除。这一交换规则防止工作集无控制的增长，并支持有效的策略训练。我们的理论分析表明，在温和假设下，通过EPO训练的策略可以实现与全球约束违反严格保持在预设界线内的最优解相媲美的性能。
### Conclusion
本文通过理论分析证明了EPO算法的有效性，在满足安全要求的前提下能达到最优性能。
## 499. `cs.LG` - 在任何地方学习降落：适用于航空轨迹的可迁移生成模型 [PDF](https://arxiv.org/pdf/2511.04155), [HTML](https://arxiv.org/abs/2511.04155)
### Authors
Olav Finne Praesteng Larsen,Massimiliano Ruocco,Michail Spitieris,Abdulmajid Murad,Martina Ragosta
### Background
空中交通管理（ATM）解决方案的研发和验证需要轨迹数据，然而二级和区域性机场往往面临严重的数据稀缺问题，这限制了机器学习方法的应用和大规模模拟或‘假设情境’分析的能力。
### Innovation
本文研究了是否可以使用迁移学习，将数据丰富的机场上的生成模型高效地适应数据稀缺的机场。具体来说，采用了最新扩散-和流动匹配为基础的架构来航空领域，并评估了在苏黎世（源机场）和都柏林（目标机场）着陆航迹数据集之间的迁移性。结果表明，基于扩散的模型即使只使用 Dublin 数据的 5%，也能实现与基线相当的性能，并且在所有衡量标准和视觉检查中，这些模型的表现优于从零开始训练的模型。虽然在捕捉稀有轨迹模式方面存在挑战，但这些发现展示了迁移学习在减少 ATM 中轨迹生成的数据需求方面的潜力，即使在缺乏历史记录的环境下，也可生成逼真的合成数据。
### Conclusion
尽管在捕捉稀有轨迹模式上存在一定挑战，但研究表明，迁移学习能够显著减少 ATM 中轨迹生成所需的数据量，从而在数据稀缺的环境中也能生成逼真的模拟数据。
## 500. `cs.LG` - 探索端到端大型语言模型作为编译器的可能性 [PDF](https://arxiv.org/pdf/2511.04132), [HTML](https://arxiv.org/abs/2511.04132)
### Authors
Hongbin Zhang,Shihao Gao,Yang Liu,Mingjie Xing,Yanjun Wu,Chen Zhao
### Background
近年来，端到端大型语言模型（Large Language Model, LLM）技术在各个领域展现出了显著的优势。编译器作为关键的系统软件和基础设施，负责将源代码转换为目标代码。尽管LLM已在编译器的开发和维护中得到了应用，但它们作为端到端编译器的潜力尚未得到充分探索。本文研究了LLM作为编译器（LaaC）的可行性及其未来方向，并设计了CompilerEval数据集和框架来评估主流LLM在源代码理解及汇编代码生成方面的能力。实验结果显示，当前LLM表现出一些基本的编译能力，但在编译成功率方面仍较低。通过优化提示、扩大模型规模和引入推理方法，可以显著提升LLM生成的汇编代码质量。因此，我们在这些发现的基础上保持对未来Laac的乐观态度，并提出了实用的架构设计和未来研究方向。
### Innovation
本文创新性地探索了LLM作为编译器的可能性，设计了专门用于评估主流LLM在源代码理解及汇编代码生成能力的CompilerEval数据集和框架，通过优化提示、扩大模型规模和引入推理方法显著提升了LLM生成的汇编代码质量。
### Conclusion
基本面来看，LLM在编译方面展现了一定潜力，尽管当前实现的编译成功率较低。通过进一步优化和改进，LLM有潜力生成高质量的汇编代码，从而推动编译领域的范式转变。未来的研究可以集中在定向训练、丰富的提示和专门的基础设施上，以进一步提升LLM作为编译器的有效性。
## 501. `cs.LG` - 关于深度集成中的联合正则化和校准 [PDF](https://arxiv.org/pdf/2511.04160), [HTML](https://arxiv.org/abs/2511.04160)
### Authors
Laurits Fredsgaard(1),Mikkel N. Schmidt(1) ((1) Department of Applied Mathematics and Computer Science, Technical University of Denmark)
### Background
深度集成作为一种强大的机器学习工具，不仅提升了模型性能，还改善了不确定性校准。通常，集成模型是通过单独训练和调优来构建的，但现有证据表明，联合调优集成模型可以带来更好的性能。本研究探索了共同调优重量衰减、温度缩放和提前停止对预测性能和不确定性量化的影响。
### Innovation
研究提出了一种部分重叠的保留策略作为联合评估和最大化训练数据利用之间的实用折衷方案。结果表明，联合调优通常能匹配或提高性能，但不同任务和指标的效果差异显著。研究揭示了单独和联合优化在深度集成训练中的权衡。
### Conclusion
我们的研究为希望优化深度集成模型的实践者提供了有价值的见解和指南。相关代码可在指定链接中找到。
## 502. `cs.LG` - 使用Transformer模型处理异构电子健康记录数据的临床风险识别深度学习方法 [PDF](https://arxiv.org/pdf/2511.04158), [HTML](https://arxiv.org/abs/2511.04158)
### Authors
Anzhuo Xie,Wei-Chen Chang
### Background
该研究针对异构电子健康记录（EHR）数据中的临床风险分类挑战，这些问题包括不规则的时间模式、大规模的模态差异以及复杂语义结构。传统的机器学习和时间深度学习模型难以有效捕捉这些复杂性，因此需要一种能够处理这些问题的新方法。此研究提出的是一种基于Transformer的纵向建模方法，旨在应对这些医疗健康数据中的复杂挑战
### Innovation
该方法采用了多源医疗特征作为输入，利用特征嵌入层实现结构化和非结构化数据的一体化表示。引入了可学习的时间编码机制来捕捉不均匀采样间隔下的动态演变。核心模型采用了多头自注意力结构，能够对长短期趋势进行全局依赖建模，利于不同时间尺度下的趋势和波动聚合。为此设计了一个语义加权池化模块，可自适应地赋予医疗事件重要性，从而提高风险相关特征的区分能力。最后，通过线性映射层生成个体级别的风险评分。实验结果显示，该模型在准确性、召回率、精确率和F1分数方面优于传统机器学习和时间深度学习模型，能够在多源异构EHR环境中实现稳定且精确的风险识别，并为临床智能决策提供了高效可靠的框架
### Conclusion
该研究提出的方法能够在多源异构EHR环境中稳定且精确地识别风险，并提供一种有效的临床智能决策框架。实验结果表明，该模型在多个评估度量中优于现有的传统方法和时间深度学习方法，并且能够适应不同类型和模态的EHR数据，具有广泛的应用前景。
## 503. `cs.LG` - 可分神经符号回归 [PDF](https://arxiv.org/pdf/2511.04124), [HTML](https://arxiv.org/abs/2511.04124)
### Authors
Giorgio Morales,John W. Sheppard
### Background
符号回归（SR）通过发现能够捕捉观测数据中潜在关系的数学表达式来复杂系统建模。然而，大多数SR方法倾向于最小化预测误差而不是识别支配方程，这常常导致表达式过于复杂或不准确。为了应对这一挑战，本文提出了一种基于分解的SR方法，该方法利用变换器模型、遗传算法（GA）和遗传编程（GP）生成可解释的多元表达式。
### Innovation
本文提出了一种基于尺度分解的可解释SR方法，该方法可以将训练好的“不透明”回归模型简化为一种解释性的数学表达形式。该方法利用多尺度变换器生成多个描述因子如何影响不透明模型响应的单变量符号骨架，随后采用基于GA的选择和基于GP的逐步合并程序，选择高质量的候选人骨架并通过基因遗传算法优化最终的多元骨架系数。
### Conclusion
本文的方法在不同程度的噪声控制问题上进行了评估，其在内插和外推误差方面表现优于两种GP方法、三种基于神经网络的SR方法以及一种混合方法。与这些方法不同，本文方法始终可以学习到与原始数学结构相符的表达式。
## 504. `cs.LG` - MXFP4量化中你需要的是区块旋转 [PDF](https://arxiv.org/pdf/2511.04214), [HTML](https://arxiv.org/abs/2511.04214)
### Authors
Yuantian Shao,Peisong Wang,Yuanteng Chen,Chang Xu,Zhihui Wei,Jian Cheng
### Background
大型语言模型（LLMs）已经取得了显著的成功，但其快速增长的规模带来了对内存、计算和能源的巨大成本压力。后训练量化（PTQ）是一个有望提高部署效率的解决方案，但要实现准确的W4A4量化仍然存在挑战。尽管大多数现有方法专注于INT4格式，但新兴的MXFP4（一种新的FP4格式，具有NVIDIA、AMD、Intel等硬件支持）的出现引发了对现有技术适用性的疑问。现有的大多数技术设计主要针对INT4格式，因此需要对这些方法进行评估以确认它们对MXFP4的有效性。
### Innovation
本研究建立了一个全面的MXFP4格式下的PTQ方法基准。通过系统性地评估方法性能，发现诸如GPTQ等方法表现强劲，而使用全局旋转的方法由于MXFP4的特性表现出严重的不兼容性。研究进一步分析了这一矛盾的根本原因，提出了一种基于这一见解的简单而有效的区块旋转策略，使基于旋转的方法适应MXFP4，从而在多种LLM上实现了显著的准确率提升。此外，发现MXFP4的块缩放和泛最大值能量重新分配之间的基本不匹配是此问题的主要原因。这不仅提供了明确的实践指导，也为未来在新兴低精度格式下的PTQ研究奠定了基础。
### Conclusion
本研究的研究结果不仅为从业者提供了明确的指导，还为在新兴低精度格式下的PTQ研究奠定了基础。
## 505. `cs.LG` - seqme：一个用于评估生物序列设计的Python库 [PDF](https://arxiv.org/pdf/2511.04239), [HTML](https://arxiv.org/abs/2511.04239)
### Authors
Rasmus Møller-Larsen,Adam Izdebski,Jan Olszewski,Pankhil Gawade,Michal Kmicikiewicz,Wojciech Zarzecki,Ewa Szczurek
### Background
近年来，计算方法在设计生物序列方面的进展引发了对评估这些方法性能的度量标准的需求，特别是为了提高设计序列与目标分布的一致性和获得所需的特性。然而，缺乏一个基于这些度量标准的单一软件库。因此，需要一个模块化、高度可扩展的开源Python库，用于评估生物序列设计的计算方法。
### Innovation
本文介绍了seqme，这是一个模块化且高度可扩展的开源Python库，包含用于评估生物序列设计计算方法的模型无关度量标准。seqme包含三组度量标准：序列基于、嵌入基于和属性基于，并适用于广泛类型的生物序列：小分子、DNA、ncRNA、mRNA、肽和蛋白质。此外，它还提供了多种生物序列嵌入和属性模型，以及诊断和可视化功能，用于检查结果。seqme可以用来评估一次性和迭代计算设计方法。
### Conclusion
seqme为评估生物序列设计的计算方法提供了一个有力的工具，其多功能性和扩展性使其适用于多种应用场景。
## 506. `cs.LG` - ScaleDL：迈向可扩展和高效的分布式深度学习工作负载运行时预测 [PDF](https://arxiv.org/pdf/2511.04162), [HTML](https://arxiv.org/abs/2511.04162)
### Authors
Xiaokai Wang,Shaoyuan Huang,Yuting Li,Xiaofei Wang
### Background
深度神经网络（DNNs）构成了现代AI服务的基础，支持诸如自动驾驶、聊天机器人和推荐系统等多种应用。随着模型的增大和复杂度的提高，DNN的工作负载（如训练和推理任务）对分布式计算资源提出了前所未有的要求，因此准确的运行时预测对于优化开发和资源分配变得至关重要。传统的预测方法依赖于叠加计算单元模型，这限制了它们的准确性和普适性。相比之下，增强图模型能够提高性能，但却显著增加了数据收集的成本。因此，需要一个能够在准确度、普适性和数据收集成本之间取得平衡的方法。
### Innovation
我们提出了一种名为ScaleDL的新颖运行时预测框架，它结合了非线性逐层建模和基于图神经网络（GNN）的跨层交互机制，能够实现DNN运行时准确的预测和不同网络架构之间的层次普适性。此外，ScaleDL还采用了D-最优方法来减少数据收集成本。实验证明，ScaleDL在运行时预测准确性和普适性方面优于基准模型，MRE降低了6倍，RMSE降低了5倍。
### Conclusion
ScaleDL通过引入非线性逐层建模和基于GNN的跨层交互机制，以及使用D-最优方法优化数据收集成本，成功地实现了DNN运行时预测的准确性、普适性和成本之间的平衡。实验结果表明，ScaleDL在多个流行DNN模型的工作负载上表现出显著的性能提升。
## 507. `cs.LG` - 多头注意力机制中的强彩票假说 [PDF](https://arxiv.org/pdf/2511.04217), [HTML](https://arxiv.org/abs/2511.04217)
### Authors
Hikari Otsuka,Daiki Chijiwa,Yasuyuki Okoshi,Daichi Fujiki,Susumu Takeuchi,Masato Motomura
### Background
强彩票假说（SLTH）认为，在随机初始化的神经网络中潜藏有高性能的子网络，称之为强彩票（SLTs）。尽管近期的研究已经对各种神经架构证明了SLTH，但在基于变换器的架构中，对于SLTH缺乏理论上的理解。特别是在当前的SLTH理论框架中，未能考虑到多头注意力（MHA）机制，这是变换器的核心组件。
### Innovation
本文通过理论分析多头注意力机制中的强彩票假说，证明了一个随机初始化的具有$H$个头和输入维度$d$的MHA，如果其隐藏维度为$O(dtext{log}(Hd^{3/2}))$，则它以高概率包含一个能近似等输入维度MHA的强彩票。进一步地，通过利用这个理论，将强彩票假说推广到了缺少归一化层的变换器中。并通过实验证实理论成果，表明通过增加源模型MHA和变换器的隐藏维度，目标模型与MHA之间的逼近误差呈指数级减少。
### Conclusion
研究证明了在多头注意力机制中存在强彩票，并将其理论推广至不包含归一化层的变换器。通过增加隐藏维度，可以显著减少源模型与目标模型之间近似的误差。
## 508. `cs.LG` - 基于时间逻辑语义的轨迹可解释概念学习：以星星为指引 [PDF](https://arxiv.org/pdf/2511.04244), [HTML](https://arxiv.org/abs/2511.04244)
### Authors
Irene Ferfoglia,Simone Silvetti,Gaia Saveri,Laura Nenzi,Luca Bortolussi
### Background
时间序列分类在安全关键应用中极为重要，但通常使用黑箱深度学习方法处理，使其难以理解其输出的原理。STELLE方法通过将轨迹直接嵌入时间逻辑概念的空间中，建立了分类和解释的统一框架，旨在解决这一挑战。
### Innovation
提出了STELLE（信号时序逻辑嵌入，用于逻辑基础学习和解释）方法，这是一种神经符号框架，通过引入基于STL的新颖内核，将原始时间序列映射到预定义的STL公式之上，从而同时优化准确性和可解释性。这一方法提供局部可解释性（以人类可读的STL条件形式）和全局可解释性（以分类特征公式形式）。
### Conclusion
实验结果表明，STELLE在提供逻辑准确的解释方面与现有方法竞争同时保持了高精度，验证了在各种实际基准数据集上的有效性和应用潜力。
## 509. `cs.LG` - 基于最近邻搜索的差分隐私在上下文学习 [PDF](https://arxiv.org/pdf/2511.04332), [HTML](https://arxiv.org/abs/2511.04332)
### Authors
Antti Koskela,Tejas Kulkarni,Laith Zumot
### Background
由于大数据模型（LLM）在上下文学习过程中固有的隐私风险，最近关于差分隐私在上下文学习（DP-ICL）方面的研究变得非常活跃。然而，现有的方法忽视了现代LLM管道中的一个关键组成部分：用于检索相关上下文数据的最近邻搜索。
### Innovation
本文介绍了一种差分隐私框架，该框架在隐私意识下实现了相关示例的最近邻搜索，使得在所有评价基准上均显著优于现有基线，实现了更好的隐私-效用权衡。方法包括数据库中最近邻检索和隐私过滤器，后者跟踪所选样本的累计隐私成本，以确保符合差分隐私预算的中心要求。
### Conclusion
在文本分类和文档问答实验中，所提出的方法明显优于现有的基线方法。
## 510. `cs.LG` - 通过贝叶斯偏好推断实现高效的强化学习从人类反馈 [PDF](https://arxiv.org/pdf/2511.04286), [HTML](https://arxiv.org/abs/2511.04286)
### Authors
Matteo Cercola,Valeria Capretti,Simone Formentin
### Background
从人类偏好中学习是让机器学习模型与人类主观判断对齐的核心。然而，收集这种偏好数据往往是昂贵且耗时的，这推动了更高效的学习范式的需要。现有两种方法提供了优势互补：RLHF（基于强化学习的人类反馈）在高维任务如LLM微调中能够有效扩展；而PBO（基于知识获取的多臂 bandit 优化）通过主动查询获得更高的样本效率。
### Innovation
文章提出了一个将RLHF的可扩展性与PBO的查询效率结合的混合框架。该框架通过将一个策略驱动的模块整合进RLHF流程中，实现主动和样本高效的偏好收集。实验结果在高维偏好优化和LLM微调两个代表性领域中显示，这种方式在样本效率和总体性能上都具有一致性的改进。
### Conclusion
实验结果表明，该提出的混合框架在两个任务上都带来了样本效率和整体性能的改进。
## 511. `cs.LG` - Spurious Correlation-Aware Embedding Regularization for Worst-Group Robustness [PDF](https://arxiv.org/pdf/2511.04401), [HTML](https://arxiv.org/abs/2511.04401)
### Authors
Subeen Park,Joowang Kim,Hakyung Lee,Sunjae Yoo,Kyungwoo Song
### Background
深度学习模型在各种领域中表现出色，但在依赖于虚假的相关性的同时，也使其容易受到分布变化的影响。特别是在小众群体变化的场景中，模型在这些被代表不足的群体中表现较差。尽管现有方法在减轻这个问题方面取得了一些进展，但其性能提升仍然受限，缺乏将嵌入空间表示与最坏群体误差直接关联的严格理论框架。
### Innovation
提出了Spurious Correlation-Aware Embedding Regularization for Worst-Group Robustness (SCER)，这是一种新型方法，直接正则化特征表示以抑制虚假线索。通过在嵌入层面施加理论约束，SCER鼓励模型专注于核心特征，减少对虚假模式的敏感性。
### Conclusion
通过在视觉和语言领域的系统评估，SCER 在最坏群体准确率上优于先前的最佳研究。代码已发布。
## 512. `cs.LG` - 不确定性下的幻象：大语言模型的不确定性量化在模糊性下失效 [PDF](https://arxiv.org/pdf/2511.04418), [HTML](https://arxiv.org/abs/2511.04418)
### Authors
Tim Tomov,Dominik Fuchsgruber,Tom Wollschläger,Stephan Günnemann
### Background
大语言模型（LLMs）的准确不确定性量化（UQ）对于其可信赖部署至关重要。然而，现有UQ方法通常是在无模糊性任务中进行基准测试的，并未充分考虑真实语言中的固有模糊性，即aleatoric不确定性。研究表明，当前的不确定性估计器在无模糊性假设的限制下表现良好，但在模糊性数据上则表现近乎随机。
### Innovation
作者引入了MAQA*和AmbigQA*，这是首次专门针对模糊性问题的数据集，其中包含了基于事实共现估算的真实答案分布。作者发现，当前的不确定性估计方法在不同估计范式下（使用预测分布本身、模型内部表示以及多个模型的集合）均表现出性能下降，理论解释表明，预测分布和基于单一模型的估计方法在模糊性下存在根本限制。
### Conclusion
研究揭示了现有大语言模型UQ方法的关键缺陷，并促使重新思考当前的建模范式。
## 513. `cs.LG` - 联邦环境中带重尾噪声的随机最小极大优化 [PDF](https://arxiv.org/pdf/2511.04456), [HTML](https://arxiv.org/abs/2511.04456)
### Authors
Xinwen Zhang,Hongchang Gao
### Background
带重尾噪声的非凸随机优化逐渐受到关注，因为许多实际研究表明，它是比标准有界方差假设更现实的假设。本文探讨了联邦学习中带重尾梯度噪声的非凸-PL最小极大优化。
### Innovation
提出两种新的算法：Fed-NSGDA-M（结合归一化梯度）和FedMuon-DA（利用Muon优化器进行本地更新）。理论实证展示了这两种算法在带重尾噪声的联邦最小极大优化中的收敛速率分别为$O({1}/{(TNp)^{frac{s-1}{2s}}})$，这是首次在带重尾噪声的情况下，提供严格理论保证的联邦最小极大优化算法。
### Conclusion
详尽的实验进一步验证了这两种算法的有效性，同时也是在带重尾噪声情况下首个提供严格理论保证的联邦最小极大优化算法。
## 514. `cs.LG` - 回归与分类的等价性 [PDF](https://arxiv.org/pdf/2511.04422), [HTML](https://arxiv.org/abs/2511.04422)
### Authors
Jayadeva,Naman Dwivedi,Hari Krishnan,N.M. Anoop Krishnan
### Background
回归与分类之间的正式联系并不充分。尽管在支持向量回归中使用了范数正则化项 ||w||，但它最多仅被当作正则化手段来证明其合理性。研究表明，一个包含M个样本的回归问题如果样本位于一个超平面上，可以与一个具有2M个样本的线性可分分类任务一一对应，从而揭示两者之间的等价性。
### Innovation
研究展示了如何在此等价关系基础上，通过最大化分类任务的间隔来得到不同于传统使用的回归形式，并提出了一个‘可回归性’度量，无需先学习模型就可以估计数据集回归的难易程度。此外，研究利用此等价关系，训练神经网络以学习转换输入变量到一个线性回归适用的空间的映射。
### Conclusion
研究结果表明，回归问题可以通过一个线性可分的分类任务来解决，从而可以利用分类算法来执行回归任务，为回归与分类之间的关系提供新的视角，并介绍了一种无需直接学习模型就能评估数据集回归难易程度的方法。
## 515. `cs.LG` - ForecastGAN：一种基于分解的对抗框架，用于多视程时间序列预测 [PDF](https://arxiv.org/pdf/2511.04445), [HTML](https://arxiv.org/abs/2511.04445)
### Authors
Syeda Sitara Wishal Fatima,Afshin Rahimi
### Background
时间序列预测在金融、供应链管理等多个领域都至关重要。现有的方法在处理多视程预测时存在局限性，尤其是在短期预测上表现不佳且往往不考虑类别特征。Transformer模型尽管在长期预测方面表现出色，但在短期预测上则往往表现欠佳，且通常忽略类别特征。
### Innovation
ForecastGAN提出了一种基于分解的对抗框架，通过三个集成模块（拆分模块、模型选择模块和对抗训练模块）解决上述问题，有效结合了数值和类别特征，并通过条件生成对抗网络训练增强预测的稳健性。
### Conclusion
ForecastGAN在多种时间序列数据集上的实验结果表明，其在短期预测中始终优于最先进的Transformer模型，而长期预测中表现也极具竞争力。这项研究提供了一种更为通用的时间序列预测方法，能够适应特定上下文并在多样化的数据特征下保持强劲的性能，而无需大量的超参数调优。
## 516. `cs.LG` - LUME-DBN: 从重症监护中不完整数据中进行完整的贝叶斯学习的DBN [PDF](https://arxiv.org/pdf/2511.04333), [HTML](https://arxiv.org/abs/2511.04333)
### Authors
Federico Pirola,Fabio Stella,Marco Grzegorczyk
### Background
动态贝叶斯网络（DBNs）在医疗保健中的应用越来越广泛，因为它们能够建模患者数据中的复杂时间关系并保持可解释性，这对于临床决策至关重要。然而，现有的处理纵向临床数据中缺失数据的方法大多来自于静态贝叶斯网络文献，未能适当考虑数据的时间特性。这导致了难以随时间准确量化不确定性的问题，这在重症监护等场景下尤为重要，因为了解时间动态性是模型可靠性和普适性所必需的。尽管DBNs具有潜力，但尚未完全开发出整合缺失值处理的贝叶斯框架方法.
### Innovation
本文提出了一种基于Gibbs抽样的新颖方法，用于从不完整数据中学习DBNs。该方法将每个缺失值视为遵循高斯分布的未知参数。在每次迭代中，未观察到的值从它们的完整条件分布中抽样，从而实现合理的插补和不确定性估计。我们的方法在模拟数据集和有创重症监护患者的真实世界数据上进行了评估，与标准的模型无偏技术（如MICE）相比，我们的贝叶斯方法显示出了更好的重构精度和收敛性。这些结果突出了在时间模型中整合完整的贝叶斯推理的临床相关性，提供了更可靠的插补，并提供了更深入的对模型行为的洞见。这种方法支持在缺数据频发且潜在影响较大的情况下进行更安全和科学的临床决策.
### Conclusion
我们的方法提供了在临床决策中更可靠的插补方案，并可以帮助更好地理解模型行为。这对于在监护病房等需要处理大量潜在影响大的缺失数据的环境中做出更安全和科学的决策尤为重要。
## 517. `cs.LG` - 朝向因果市场模拟器 [PDF](https://arxiv.org/pdf/2511.04469), [HTML](https://arxiv.org/abs/2511.04469)
### Authors
Dennis Thumm,Luis Ontaneda Mijares
### Background
现有基于深度生成模型的市场生成器已显示出对合成金融数据生成的前景，但这些方法缺乏用于反事实分析和风险评估的因果推理能力。为了应对这一挑战，通过结合变分自编码器和结构因果模型，提出了一种新的时间序列神经因果模型变分自编码器（TNCM-VAE），可以在保持时间依赖性和因果关系的同时生成反事实金融时间序列。
### Innovation
该方法通过解码器架构中的有向无环图来强制因果约束，并采用因果 Wasserstein 距离进行训练。在由 Ornstein-Uhlenbeck 过程启发的合成自回归模型上，该方法优于真实的反事实概率估计，L1 距离最低可达 0.03-0.10。此模型可使金融压力测试、情景分析和增强回测成为可能，通过生成符合潜在因果机制的合理反事实市场轨迹
### Conclusion
TNCM-VAE 方法通过结合变分自编码器和结构因果模型，显著提高了反事实概率估计性能。该模型在金融压力测试、情景分析和增强回测中具备重要应用价值，确保生成的市场轨迹既遵循时间依赖性又符合因果机制。
## 518. `cs.LG` - 用于卷积神经网络压缩的分布感知张量分解 [PDF](https://arxiv.org/pdf/2511.04494), [HTML](https://arxiv.org/abs/2511.04494)
### Authors
Alper Kalle,Theo Rudkiewicz,Mohamed-Oumar Ouerfelli,Mohamed Tamaazousti
### Background
神经网络广泛应用于图像相关任务，但通常需要大量的计算资源。训练完成的网络可以通过压缩来减少对内存和计算能力的需求。传统的压缩方法在权重空间中寻找低秩近似，通常通过最小化某类范数，比如 Frobenius 范数实现。然而，这些方法都是在权重空间中进行优化，而没有直接考虑网络的功能输出。
### Innovation
本文提出了一种新的基于数据感知范数的张量分解方法，用于卷积神经网络的压缩。该方法直接优化网络功能输出的变化，而非传统方法中优化权重空间的低秩近似。具体而言，该方法通过最小化层输出分布的变化来实现，这是一种新的范数表达形式。此外，本文提出了针对两种最常用张量分解（Tucker-2 和 CPD）的交替最小二乘算法，并展示了这种数据感知方法在多个CNN架构和数据集上的优势。
### Conclusion
本研究提出的基于数据感知范数的张量分解方法无需额外的后压缩微调，就可以在多个CNN架构和数据集上实现与传统的压缩方法相当或更好的压缩效果。此外，这种范数方法还可以在不同数据集之间迁移，即使原始训练数据不可用，也能实现有效的网络压缩。
## 519. `cs.LG` - 刑事司法中的替代公平与准确度优化 [PDF](https://arxiv.org/pdf/2511.04505), [HTML](https://arxiv.org/abs/2511.04505)
### Authors
Shaolong Wu,James Blume,Geshi Yeung
### Background
算法公平性作为研究领域得到了迅速的发展，但在刑事司法领域，关键概念仍然存在争议。本文回顾了群体公平、个体公平和过程公平，并分析了它们之间的冲突。文章随后提出了一种标准群体公平方法的简单修改，通过最小化加权错误损失，并保持不同群体的假阴性率差异在一定范围内，使解决方案更容易找到，提高预测准确性，并凸显错误成本的伦理选择。
### Innovation
提出了一种标准群体公平方法的简单修改，通过最小化加权错误损失，并保持不同群体的假阴性率差异在一定范围内，使解决方案更容易找到，提高预测准确性，并凸显错误成本的伦理选择。
### Conclusion
文章提出了一个基于三项支柱的实用部署框架：基于需求的决策，透明性和问责制，以及精确定义和解决方案。这些元素将技术设计与合法性联系起来，并为使用风险评估及相关工具的机构提供了可操作的指导。
## 520. `cs.LG` - Q3R: Quadratic Reweighted Rank Regularizer for Effective Low-Rank Training [PDF](https://arxiv.org/pdf/2511.04485), [HTML](https://arxiv.org/abs/2511.04485)
### Authors
Ipsita Ghosh,Ethan Nguyen,Christian Kümmerle
### Background
低秩优化基于的参数高效训练方法已成为大型深度学习模型微调的非常成功的工具。然而，在低秩预训练任务中，保维持低秩结构和优化目标都是一项具有挑战性的任务。传统的低秩训练技术在训练具有特定低秩目标矩阵时，难以在保持较小计算开销的情况下达到与密集模型相近的预测性能，且难以与现有架构保持兼容性。
### Innovation
该论文提出了一种名为Q3R的二次重新加权秩正则化器，受迭代重加权最小二乘法（IRLS）框架的启发，提出了一个新颖的基于秩诱导训练策略。Q3R使用一个二次正则化项来支配作为秩替代目标的平滑对数行列式。Q3R在保持与密集模型相近的预测性能的同时，能够训练具有特定低秩目标的权重矩阵，且计算开销小，并且与现有架构完全兼容。例如，在一个实验中，Q3R能够将ViT-Tiny模型的参数裁剪60%和80%，而在CIFAR-10 上的性能分别下降1.3%和4%。该方法在Transformer模型在图像和语言任务中，以及低秩微调任务中都表现出有效性
### Conclusion
Q3R方法能够在保持与密集模型相近的预测性能的同时，裁剪掉大量参数，为低秩训练提供了有效的新策略，验证了其在各种图像和语言任务上的有效性。
## 521. `cs.LG` - 用于更好地训练和评估知识图增强LLMs的真实子图 [PDF](https://arxiv.org/pdf/2511.04473), [HTML](https://arxiv.org/abs/2511.04473)
### Authors
Alberto Cattaneo,Carlo Luschi,Daniel Justus
### Background
从结构化知识库中检索信息是提升语言模型事实准确性的有前途的方向。尽管已提出了各种解决方案，但由于缺乏挑战性的问答数据集和图检索的真实目标，方法间的对比变得困难。作者提出了一种SynthKGQA框架，用于从任何知识图谱生成高质量的合成知识图谱问答数据集，提供知识图谱中的全部真实事实以每个问题进行推理。这种方法不仅可以更有效地评估图检索工具，还可以用于训练更好的模型。
### Innovation
提出了SynthKGQA框架，可以从任何知识图谱生成高质量的合成知识图谱问答数据集。通过利用此框架生成的带真实目标的数据，不仅可以进行更有效的基准测试，还可以用于训练更好的模型。应用SynthKGQA到Wikidata，生成了一个新的数据集GTSQA，专门测试图检索工具在面对新图结构和关系类型情况下的零样本泛化能力。
### Conclusion
SynthKGQA生成的真实子图数据集GTSQA，用于测试知识图增强的LLMs的零样本泛化能力，并对流行的图增强LLM解决方案进行了基准测试。这表明，使用真实数据进行训练和评估可以提高模型的性能和准确性。
## 522. `cs.LG` - 将不确定量化方法应用于云微物理的降维代理模型 [PDF](https://arxiv.org/pdf/2511.04534), [HTML](https://arxiv.org/abs/2511.04534)
### Authors
Jonas E. Katona,Emily K. de Jong,Nipun Gunawardena
### Background
降维模型（ROMs）能够高效地模拟高维物理系统，但缺乏稳健的不确定性量化方法。现有的方法通常依赖于特定的架构或训练过程，这限制了灵活性和通用性。
### Innovation
本文提出了一种后处理、模型通用的框架，用于在潜空间 ROMs 中进行预测不确定性量化，该方法无需修改底层架构或训练过程。通过使用一致预测，该方法估计 ROM 管道中多个组件的统计预测区间：潜在动力学、重构和端到端预测。
### Conclusion
该方法应用于云微物理的潜空间动力学模型，准确预测了滴尺寸分布的演化，并在 ROM 管道中量化了不确定性。
## 523. `cs.LG` - EPGP代数和有限元法在自由度相同时的比较 [PDF](https://arxiv.org/pdf/2511.04518), [HTML](https://arxiv.org/abs/2511.04518)
### Authors
Obed Amo,Samit Ghosh,Markus Lange-Hegermann,Bogdan Raiţă,Michael Pokojovy
### Background
该论文旨在比较边界约束Ehrenpreis--Palamodov高斯过程（B-EPGP）代理模型与经典有限元方法结合Crank--Nicolson时间步进（CN-FEM）求解二维波动方程的效果，特别是在齐次Dirichlet边值条件下的表现。为了确保公平性，引入了自由度（DoF）匹配协议，以直接对比两种方法在相同计算复杂度下的效果。
### Innovation
提出了一种新的B-EPGP代理模型，该模型利用从特征变体派生的指数多项式基来严格满足偏微分方程（PDE）和边界条件，并使用正则化最小二乘法估计系数。通过在相同的自由度下进行比较，B-EPGP在空间和时间上的$L^2$误差显著低于CN-FEM，约提高了两个数量级的准确性。
### Conclusion
在相同的自由度下，B-EPGP方法在解决二维波动方程时表现出更优的空间-时间$L^2$误差和最大时间$L^2$误差，显著提高了计算精度。
## 524. `cs.LG` - 在图变换器中结合时序和结构上下文以实现关系深度学习 [PDF](https://arxiv.org/pdf/2511.04557), [HTML](https://arxiv.org/abs/2511.04557)
### Authors
Divyansha Lachi,Mahmoud Mohammadi,Joe Meyer,Vinam Arora,Tom Palczewski,Eva L. Dyer
### Background
在医疗、金融和电子商务等领域的数据中，关系数据的时间动态来自于不同实体间的复杂交互。要广泛适用，这些数据上的模型必须整合跨越各种实体类型的长时间范围的空间和时间依赖性，同时支持多种预测任务。然而，现有的关系数据分析图模型主要侧重于空间结构，将时间信息仅视为过滤未来事件的约束条件而非模型信号，通常设计用于单一任务预测。
### Innovation
本文提出了一个时序子图采样器，通过回收节点超越邻域的信息来增强全局上下文，以捕捉时间相关的关系。此外，提出了关系图感知机（RGP），这是一种结合了跨注意力机制隐式瓶颈的图变压器架构，用于关系深度学习，能够高效整合结构和时间上下文的信息，将不同类型节点和边的信息整合到一个公共隐空间中，从而使模型能够在整个关系系统中建立全局上下文。RGP 集成了一个灵活的跨注意力解码器，支持单个模型中跨任务的联合学习，这些任务具有不重叠的标签空间。
### Conclusion
实验结果表明，RGP 提供了一种适用于多种预测任务的关系深度学习的前沿解决方案。
## 525. `cs.LG` - 基于端到端强化学习的Koopman模型用于空气分离单元的(e)NMPC [PDF](https://arxiv.org/pdf/2511.04522), [HTML](https://arxiv.org/abs/2511.04522)
### Authors
Daniel Mayfrank,Kayra Dernek,Laura Lang,Alexander Mitsos,Manuel Dahmen
### Background
最近提出了一种基于强化学习的方法（Mayfrank et al. (2024)，Comput. Chem. Eng. 190），该方法可以训练Koopman替代模型以在特定（经济性）非线性模型预测控制((e)NMPC)应用中达到最佳性能。迄今为止，该方法仅在小型案例研究中进行了验证。本研究证明该方法可以扩展到基于大型单产品(氮气)空气分离单元模型的更具挑战性的需求响应案例研究中。所有数值实验中假定只能观测到少量现实可测量的植物变量。与基于系统识别的Koopman (e)NMPC相比，这种方法能实现相似的经济性能且避免了约束违反。
### Innovation
提出了将基于强化学习的方法应用于大型空气分离单元的更复杂和挑战性的需求响应案例研究，展示了Koopman替代模型在(e)NMPC中的应用，并与基于系统识别的方法进行了比较，证明了其优越性，即在不违反约束的情况下，实现了相似的经济性能。
### Conclusion
提出的基于强化学习的Koopman模型在(e)NMPC中不仅实现了相似的经济性能，还避免了约束违反，从而在大型空气分离单元的需求响应案例研究中表现出很好的扩展能力。
## 526. `cs.LG` - ARETE：一种使用大规模语言模型进行文本自动检索的R包 [PDF](https://arxiv.org/pdf/2511.04573), [HTML](https://arxiv.org/abs/2511.04573)
### Authors
Vasco V. Branco,Jandó Benedek,Lidia Pivovarova,Luís Correia,Pedro Cardoso
### Background
目前实施严格的保护措施的主要障碍是缺乏关键物种的数据，尤其是出现数据。由于人类活动的加速，研究人员需要更快地收集和处理新的信息。这些信息散见于科学论文和灰色文献中，但这些数据通常不是机器可读的，需要大量的手动工作来提取。
### Innovation
我们提出了一种名为ARETE的R包，这是一个开源软件，利用大型语言模型（具体使用了聊天机器人GPT的应用程序接口）自动化物种出现数据的提取过程。该R包整合了数据提取和验证的所有步骤，从光学字符识别到离群值检测，并以表格格式输出数据。我们还通过系统比较模型和人类注释员的工作来验证ARETE的有效性。
### Conclusion
ARETE方法通过对比基于GBIF数据和自动提取的100种蜘蛛的分布图，扩展了已知物种的分布范围，揭示了过去未发现的区域。这极大地加速了以往未被充分利用的出现数据访问，并对空间保护规划和灭绝风险评估具有重要意义。研究人员可以更快地获取数据，优先分配资源，并自动验证选定的物种，同时维持大多数数据的自动化提取，还可以在项目规划期间预测可用的文献数据。
## 527. `cs.LG` - 环境无关的目标条件化：无奖励自主学习的研究 [PDF](https://arxiv.org/pdf/2511.04598), [HTML](https://arxiv.org/abs/2511.04598)
### Authors
Hampus Åström,Elin Anna Topp,Jacek Malec
### Background
本文探讨如何将常规的强化学习环境转换为目标导向环境，使智能体能够自我驱动地解决任务，无需外部奖励。研究表明，智能体可以通过自主选择其目标来学习解决任务，在训练时间上与外部指导的强化学习相当。本文的方法不依赖于底层的离策学习算法。由于该方法是环境无关的，智能体不会对任何目标给予更高评价，导致单个目标性能不稳定。
### Innovation
提出了环境无关的目标条件化方法，使智能体能够在无奖励条件下自我驱动地学习解决任务。方法独立于底层的削弱学习算法，但会导致单个目标性能的不稳定。然而，实验表明，使用该方法训练的智能体能够实现平均目标成功率的提升和稳定。
### Conclusion
使用本文的方法训练的智能体能够寻找环境中的任何观察结果，从而在特定应用场景之前实现通用智能体的训练。这种方法为无奖励自主学习提供了新的视角。
## 528. `cs.LG` - 高效部分观测大尺度动力系统概率代数建模技术 [PDF](https://arxiv.org/pdf/2511.04641), [HTML](https://arxiv.org/abs/2511.04641)
### Authors
Hans Harder,Abhijeet Vishwasrao,Luca Guastoni,Ricardo Vinuesa,Sebastian Peitz
### Background
本文关注用于描述偏微分方程（如Navier-Stokes方程）的动力系统的概率预报技术。研究背景在于复杂系统（特别是大规模3D模拟）的高效建模和预测，尤其是在基于观测数据的情况下，如何提供准确且计算代价低的预测。
### Innovation
文章提出了几种减少采样步骤的方法，并进行了比较，包括直接蒸馏、渐进蒸馏、对抗扩散蒸馏、Wasserstein GANs和修正流。此外，它还直接预测了大规模3D模拟中的2D切片，为求解器提供了高效的来流生成方法。
### Conclusion
实验表明，这些新方法能够有效减少计算步骤，提高预测效率，并能直接处理大规模3D模拟的数据，为这些系统的大规模预测提供了新的方向。
## 529. `cs.LG` - 神经网络因果干预引发的异构表示的解决方法 [PDF](https://arxiv.org/pdf/2511.04638), [HTML](https://arxiv.org/abs/2511.04638)
### Authors
Satchel Grant,Simon Jerome Han,Alexa Tartaglini,Christopher Potts
### Background
通常，机制解释的方法是通过在模型表示中进行因果干预来理解这些表示所编码的内容。然而，该研究探讨了这种干预是否会导致模型内部表示偏离目标模型的自然分布。这引发了对未来解释与目标模型自然状态一致性的质疑。研究首先通过实验证明了常见的因果干预技术经常将内部表示移出目标模型的自然分布。在此基础上，研究提供了两类偏离的理论分析：无害偏离发生在权重的零空间和行为决策边界内的协方差中；而有害偏离激活了隐藏的网络路径并引起潜在的行为变化。最后，为了减轻有害偏离的情况，研究对Grant（2025）的反向事实潜变量（CL）损失进行了修改，使其干预保持更接近自然分布，从而降低有害偏离的可能性，同时保持干预的解释能力。
### Innovation
提出了通过修改反向事实潜变量（CL）损失，使其干预保持更接近自然分布，从而减少有害偏离现象，同时保留干预的解释能力的新方法。这为更可靠的解释方法提供了一条途径。
### Conclusion
研究结果强调了在进行因果干预时需关注避免有害偏离的方法，从而提高解释方法的可靠性。
## 530. `cs.LG` - Decentralized Multi-Agent Stochastic Shortest Path Problems 的遗憾下界 [PDF](https://arxiv.org/pdf/2511.04594), [HTML](https://arxiv.org/abs/2511.04594)
### Authors
Utkarsh U. Chavan,Prashant Trivedi,Nandyala Hemachandra
### Background
多智能体系统（MAS）在诸如 swarm robotics 和交通路由等应用中至关重要，其中智能体需要以去中心化的方式协调以达成共同目标。随机最短路径（SSP）问题为建模此类去中心化控制提供了自然的框架。尽管在单智能体环境下对于学习的研究已经非常广泛，但分布式的多智能体变体却鲜有探索。本文在这方面迈出了重要的一步，研究了基于线性函数近似的分布式多智能体 SSP（Dec-MASSPs）。该研究采用了基于对称性的新颖论证，以识别最优策略的结构。其主要贡献是首个基于具有任意数量智能体的困难学习实例构建的Setting的遗憾下界，遗憾下界为 $bigOmega(bigtext{sqrt}{K})$，共K个 episode。这阐明了分布式控制的学习复杂性，并进一步指导了多智能体系统中高效学习算法的设计。
### Innovation
基于线性函数近似的分布式多智能体 SSP 研究；首次为该环境提供遗憾下界；通过构建具有任意数量智能体的难学习实例来形象化学习困难性；识别最优策略的结构。
### Conclusion
研究得出了分布式多智能体 SSP 的遗憾下界，强调了在该问题中的学习难点，并为设计有效的学习算法提供指导。
## 531. `cs.LG` - 将复杂性视为优势：基于后悔的观点探讨涌现结构 [PDF](https://arxiv.org/pdf/2511.04590), [HTML](https://arxiv.org/abs/2511.04590)
### Authors
Oshri Naparstek
### Background
本文介绍了复杂性优势(CAA)框架，该框架定义了一个系统相对于一组观察者的复杂性。与将复杂性视为固有属性不同，本文评估了不同观察者在试图对系统进行建模时所遭受的预测后悔程度。系统的复杂性是指当有的观察者容易理解和预测，而其他观察者难以理解和预测时，就会产生信息优势。本文显示，这种表达方式能够统一包括多尺度熵、预测信息和观察者依赖结构等在内的多种涌现行为概念。
### Innovation
CAA框架提出了一种新的复杂性评估方法，强调从观察者的角度评估系统的复杂性，而不是将其视为固有属性。通过这种方式，本文揭示了系统复杂性的功能性价值，即那些能够在不同观察者之间制造差异化后悔的系统被认为是“有趣的”。通过简单的动力学模型，本文进一步验证了这一观点，并讨论了其在学习、进化和人工代理方面的意义。
### Conclusion
本文通过引入CAA框架，为理解和评估复杂性提供了一种新的视角，通过观察者的预测后悔来量化系统复杂性，从而为复杂性在功能上的价值提供了一个定量的基础。CAA框架为探索和理解复杂系统的涌现现象提供了新的思路和方法，具有重要的理论与实践意义。
## 532. `cs.LG` - 图像分类深层集成在数据偏移下的线性模式连通性 [PDF](https://arxiv.org/pdf/2511.04514), [HTML](https://arxiv.org/abs/2511.04514)
### Authors
C. Hepburn,T. Zielke,A.P. Raulf
### Background
线性模式连通性（LMC）现象将深度学习的多个方面联系起来，包括在嘈杂的随机梯度下训练稳定性、局部极小值（盆地）的光滑性和泛化能力、样本模型之间的相似性和功能性多样性以及架构对数据处理的影响。本文实验性地研究了数据偏移下LMC，并确定了一些有助于减轻其影响的条件。数据偏移被解释为额外的随机梯度噪声来源，可以通过使用较小的学习率和较大的批处理大小来减少。
### Innovation
本文发现了数据偏移下LMC的条件，并将其解释为额外的随机梯度噪声源，通过使用较小的学习率和较大的批处理大小来减少。这影响着模型是否收敛于相同的局部极小值或损失景观中不同平滑度和泛化能力的区域。此外，本文强调了LMC在权衡训练效率与通过较大、更多样化集成所获得的效益之间的平衡。
### Conclusion
尽管通过LMC采样的模型更倾向于频繁地产生相同的错误，但LMC的优势在于它在提高训练效率的同时，也带来了更大、更多样化集成所带来的收益。未来将公开相关的代码和补充材料。
## 533. `cs.LG` - 遗忘现象普遍存在 [PDF](https://arxiv.org/pdf/2511.04666), [HTML](https://arxiv.org/abs/2511.04666)
### Authors
Ben Sanati,Thomas L. Lee,Trevor McInroe,Aidan Scannell,Nikolay Malkin,David Abel,Amos Storkey
### Background
在开发通用学习算法时，一个基本挑战是它们在适应新数据时往往忘记过去的知识。尽管过去几十年的研究，还没有一个统一定义阐明学习的内在动态。为了解决这一问题，需要一套原理性的理解方式来克服遗忘现象。
### Innovation
本文提出了一种算法和任务无关的理论，将遗忘定义为学习者对未来经验预测分布的自我一致性缺失，表现为预测信息的丧失。该理论自然地产生了一种算法遗忘倾向的通用度量方法，并设计了一系列包容分类、回归、生成建模和强化学习的实验来验证理论的有效性。
### Conclusion
实验结果表明，遗忘在所有学习场景中普遍存在，并在决定学习效率中起重要作用。这些结果为理解和改进通用学习算法的信息保留能力提供了理论基础。
## 534. `cs.LG` - TT-Prune: Time触发联邦学习中联合模型剪枝与资源分配以实现通信效率 [PDF](https://arxiv.org/pdf/2511.04653), [HTML](https://arxiv.org/abs/2511.04653)
### Authors
Xinlu Zhang,Yansha Deng,Toktam Mahmoodi
### Background
联邦学习（FL）可通过解决数据隐私问题为机器学习提供新的机会。时间触发联邦学习（TT-Fed），作为一种异步和同步联邦学习的通用形式，通过固定的时间间隔将用户分层。然而，FL网络中的用户设备不断增加，无线带宽有限，导致了诸如延迟者和通信开销等问题的加剧。本文在无线TT-Fed系统中引入了适应性模型剪枝，并研究了在确保最小学习延迟的同时，联合优化剪枝比和带宽分配以最小化训练损失的问题。基于模型剪枝的梯度l_2范数进行收敛性分析，以获得收敛上界，并提出了在给定延迟阈值下最小化模型训练损失的联合优化问题。进一步利用KKT条件得出无线带宽和剪枝比的解析解。仿真实验表明，通过剪枝可以在降低通信成本40%的情况下保持模型性能不变。
### Innovation
本文提出的TT-Prune方法通过结合适应性模型剪枝和带宽资源优化，有效地减少了通信开销，同时保证了模型性能。
### Conclusion
本文提出的方法在确保模型性能不变的前提下，能够显著减少训练过程中的通信成本。实验结果证明了方法的有效性和实用性。
## 535. `cs.LG` - 多方法途径对数学入学评估的分析：经典方法、机器学习和聚类方法 [PDF](https://arxiv.org/pdf/2511.04667), [HTML](https://arxiv.org/abs/2511.04667)
### Authors
Julian D. Allagan,Dasia A. Singleton,Shanae N. Perry,Gabrielle C. Morgan,Essence A. Morgan
### Background
本研究采用多方法框架，结合经典测试理论、机器学习和无监督聚类方法，评估了一项包含40个条目的数学入学考试。通过对198名学生的评估结果进行分析，研究了考试条目的有效性，并提出了改进建议。
### Innovation
本研究创新性地结合了经典测试理论、机器学习和聚类方法进行多方法分析，以评估数学入学考试的有效性。通过识别区分度高的题目，采用机器学习算法提高评估准确率，并基于聚类分析提出优化建议。
### Conclusion
研究结果表明，通过多方法结合的方法可以为基于数据的数学入学评估优化提供强有力的实证基础。建议替换区分度低的题目，实施两阶段评估，并结合随机森林预测结果并增加透明机制。
## 536. `cs.LG` - 基于仿真的集成4D/5D数字孪生框架的预测性施工控制验证 [PDF](https://arxiv.org/pdf/2511.03684), [HTML](https://arxiv.org/abs/2511.03684)
### Authors
Atena Khoshkonesh,Mohsen Mohammadagha,Navid Ebrahimi
### Background
美国建筑行业中持续的成本和进度偏差是一个主要挑战，显示了确定性CPM和静态文档估计方法的局限性。
### Innovation
本文提出了一种将BIM与基于自然语言处理的造价映射、计算机视觉驱动的进度测量、贝叶斯概率CPM更新以及深度强化学习资源优化集成的4D/5D数字孪生框架。验证了该方法在准确性和效率上的提升，并增强了预测精度、透明性和控制韧性。
### Conclusion
结合AI分析、概率CPM和DRL的工作流程验证了一种预测性、自适应和可审计的施工管理实践路径。
## 537. `cs.LG` - Nowcast3D: 通过灰盒学习实现可靠的极端降水即时预报 [PDF](https://arxiv.org/pdf/2511.04659), [HTML](https://arxiv.org/abs/2511.04659)
### Authors
Huaguan Chen,Wei Han,Haofei Sun,Ning Lin,Xingtao Song,Yunfan Yang,Jie Tian,Yang Liu,Ji-Rong Wen,Xiaoye Zhang,Xueshun Shen,Hao Sun
### Background
当前，极端降水的即时预报需要高空间和时间分辨率以及较长的预测时间。现有方法存在限制，数值天气预报(NWP)和深度学习仿制太慢且分辨率低，无法快速响应对流变化。外推和纯数据驱动模型容易积累错误并产生过度平滑。二维雷达方法舍弃了关键的垂直信息，无法准确重建高度依赖的动力学。为了克服这些挑战，该论文介绍了一种灰盒、全流程三维即时预报框架，该框架可以直接处理体积雷达反射率，并结合物理约束神经运算符与数据驱动学习。这种方法可以学习垂直变化的三维径流场，并通过保守径流操作器来参数化空间变化的扩散。此外，引入了一个基于布朗运动的随机项来表示未解决的动力学。通过残差分支捕捉小尺度对流的初始和微物理变量，扩散为基础的随机模块估计不确定性。该框架在不同降水模式下的预报准确性提高，并且在盲测中以160名气象学家中的57%胜出。
### Innovation
该论文提出了一种三维灰盒即时预报框架，能够直接处理三维雷达反射率数据，结合物理约束和数据驱动学习，学习三维和垂直变化的动力学，同时引入模拟未解决问题运动的随机项，提高预报准确性，并通过残差分支和不确定性估算法模块进一步优化。该方法能够在不同预报时间尺度上实现可靠的极端降水即时预报，表明该方法具有可扩展性和鲁棒性，为提高极端降水即时预报技能提供了新途径。
### Conclusion
这种三维灰盒即时预报框架通过恢复全三维动力学，并结合物理约束和数据驱动学习，实现了从0到3小时大尺度降水的可靠预报，展示了其在极端降水即时预报中的潜力。它在盲测中表现优异，比纯数据驱动方法或物理模型具有更好的性能。
## 538. `cs.LG` - 一种用于模型类别选择的卷积神经网络深度学习方法 [PDF](https://arxiv.org/pdf/2511.03743), [HTML](https://arxiv.org/abs/2511.03743)
### Authors
Marios Impraimakis
### Background
本文介绍了一种新的深度卷积神经网络方法，以一种简单有效的方式评估仅依赖响应的模型类别选择能力。通过利用单一自由度的响应及其分类信息，训练并验证了一维卷积神经网络。这种方法无需系统输入信息，或完整的系统辨识，即可选择新且未标记信号的模型类别。
### Innovation
本文提出的深度卷积神经网络方法能够仅通过系统响应信息选择动态系统（线性和非线性）的新信号类别。此外，文中还探讨了一个基于物理的算法增强，使用卡尔曼滤波器结合加速度和位移数据的运动学约束来融合系统响应信号。
### Conclusion
本文方法在轻微信号变化（如阻尼行为或滞回行为）下能够准确选择模型类别，适用于线性、非线性动态系统及3D建筑有限元模型的结构健康监控。该方法提供了一种强大的工具来实施结构健康监测应用。
## 539. `cs.LG` - 按需摩擦：基于生成模型的摩擦元界面逆向设计框架 [PDF](https://arxiv.org/pdf/2511.03735), [HTML](https://arxiv.org/abs/2511.03735)
### Authors
Valentin Mouton,Adrien Mélot
### Background
设计表现出预设宏观行为的摩擦表面是一个具有挑战性的逆向问题，这受到非唯一解和接触模拟高计算成本的限制。传统的途径依赖于低维度参数化的启发式搜索方法，这种方法的应用范围有限，尤其是在处理复杂的或非线性的摩擦定律时。为了应对这一挑战，本文提出了一种使用变分自编码器（VAEs）的生成建模框架，用于从目标摩擦定律中推断表面形貌。该研究表明，通过生成建模可以有效克服传统方法的局限性，实现候选表面形貌的无模拟高效生成.
### Innovation
提出了一种基于变分自编码器（VAEs）的生成性建模框架，旨在从目标摩擦定律逆向推断出所需的表面形貌。该方法利用一个包含2亿个样本的合成数据集进行训练，这些样本是通过参数化的接触力学模型构建的。这种方法能够高效、无模拟地生成候选表面形貌，同时平衡了精度、吞吐量和生成解的空间多样性。此外，这种方法还为通过定制表面形貌实现几乎实时的摩擦行为控制奠定了基础.
### Conclusion
研究结果展示了生成建模在这种逆向设计任务中的潜力与局限性，并概述了在平衡这些目标时的实用考虑。这种新的方法为实现摩擦界面的高度定制化和实时控制开辟了新的途径。
## 540. `cs.LG` - 一种用于混合电源系统稳定预报的动态递归相邻记忆网络 [PDF](https://arxiv.org/pdf/2511.03746), [HTML](https://arxiv.org/abs/2511.03746)
### Authors
Guang An Ooi,Otavio Bertozzi,Mohd Asim Aftab,Charalambos Konstantinou,Shehab Ahmed
### Background
现代电力系统中高比例的逆变器资源导致了复杂动态行为，挑战了传统稳定性评估方法的可扩展性和通用性。现有的实时电力系统稳定性预测方法需要能够应对这些挑战，以确保电力系统的稳定运行。本文采用了一种结合物理信息分析与深度学习的动态递归相邻记忆网络（DRAMN）来解决这一问题。该网络通过结合滑动窗口动态模式分解技术处理时空依赖性，可以从相量测量单元和传感器数据中构建时间变化的多层邻接矩阵，以捕捉系统动态特性，如模态参与系数、耦合强度、相位关系和频谱能量分布等。
### Innovation
DRAMN 进行了创新性设计，其特点在于在递归门控机制中直接整合图卷积操作，这使得它可以同时建模动态演变和时间依赖关系，而无需将空间和时间依赖性分开处理。这种方法在模型性能、解释性方面具有显著优势，不需要牺牲性能即可降低特征维度，实现了对不同类型稳定性现象的普适性验证。实验结果表明，该模型的性能优于包括经典机器学习算法和最近的图模型在内的所有基准模型。
### Conclusion
本研究提出的 DRAMN 模型实现了对复杂电力系统的高质量实时稳定性预报，同时提供了对电力系统操作者的增强解释性，具有实时部署到现代控制中心的潜力。
## 541. `cs.LG` - 动态测度运输的学习路径：控制视角 [PDF](https://arxiv.org/pdf/2511.03797), [HTML](https://arxiv.org/abs/2511.03797)
### Authors
Aimee Maurais,Bamdad Hosseini,Youssef Marzouk
### Background
本文作者将控制理论引入动态测度运输(DMT)路径识别的问题中。通常使用的路径可能并不适合DMT，因此本文探讨了现有方法与均场博弈的联系，提出了优化问题来识别倾斜路径，并强调寻求光滑速度的重要性。
### Innovation
在现有的基础上，作者通过连接均场博弈理论来增强路径识别的方法，提供了一种灵活的优化问题家族，并且建议使用鼓励速度平滑性的目标函数。此外，作者还基于最近的高斯过程方法来解决这些问题，从而提出了一种能够恢复更加有效和光滑运输模型的数值算法。
### Conclusion
与使用未倾斜参考路径的模型相比，本文算法能够恢复更高效、更平滑的运输模型。
## 542. `cs.LG` - 二阶Karhunen-Loève展开代理模型与主动学习方法用于随机场 [PDF](https://arxiv.org/pdf/2511.03756), [HTML](https://arxiv.org/abs/2511.03756)
### Authors
Aniket Jivani,Cosmin Safta,Beckett Y. Zhou,Xun Huan
### Background
该研究旨在开发一种代理模型，用于处理具有不确定输入的场值感兴趣的量。背景信息指出，现有的谱方法通常效率高但可能忽略某些重要响应趋势，而多级颜色展开则可能捕捉这些趋势但效率较低。为了克服这些缺点，该研究提出了一种结合低精度（LF）和高精度（HF）模拟的二阶Karhunen-Loève展（KLE）代理模型，以有效地计算和降低复杂的高维随机场问题的计算成本。
### Innovation
提出了一种新的代理模型框架——二阶（Bifidelity）Karhunen-Loève展开（KLE）结合主动学习策略。该方法通过结合低精度（LF）模拟和高精度（HF）模拟，利用主动学习技术优化新HF样本的选择，从而提高了代理模型的准确性和效率。具体创新点包括：首次提出利用二阶KLE展开以捕捉高维随机场中的主要响应趋势并减少系统偏差；通过主动学习策略（AL）自适应地选择新HF样本来提升模型预测精度；该方法的有效性已在不同复杂度的案例（包括一维解析基准、二维对流扩散系统和三维湍流圆射流模拟）上得到验证，并显示出与单精度方法和随机采样方法相比的优越性能。
### Conclusion
最终结果表明，二阶KLE代理模型与主动学习策略框架在不同复杂程度的模型上均取得了较高的预测精度，并且比单精度方法和随机采样方法更节省计算资源。该方法在处理复杂随机场问题时具有显著优势，是一种有效的计算工具。
## 543. `cs.LG` - 不同分词算法对二进制代码分析中LLMs和变换器模型的影响 [PDF](https://arxiv.org/pdf/2511.03825), [HTML](https://arxiv.org/abs/2511.03825)
### Authors
Ahmed Mostafa,Raisul Arefin Nahid,Samuel Mulder
### Background
分词在汇编代码分析中是基础，影响词汇量、语义覆盖和下游任务的性能。尽管分词非常重要，但汇编代码分词研究尚不充分。研究旨在评估NLP分词模型及其参数选择的内在属性，如词汇量大小，探索针对汇编代码特性的预处理和分词规则，评估这些模型对下游任务的影响，如函数签名预测（二进制代码分析中的关键问题）。
### Innovation
本文通过全面研究各种分词模型，系统分析它们在编码汇编指令和捕捉语义方面的能力，使用最先进的预训练模型，如解码器型大规模语言模型（LLM）Llama 3.2、编码器型变换器BERT和编码器-解码器模型BART，从分词效率、词汇压缩和表示保真度等多个维度评估分词模型。初步发现表明，分词器的选择显著影响下游性能，内在指标可以部分但不完全预测评估结果，揭示了内在分词器属性与实际汇编代码任务之间的复杂权衡。
### Conclusion
研究为优化用于低级代码分析的分词模型提供了有价值的见解，有助于增强基于自然语言模型（NLM）的二进制分析工作流程的稳健性和可扩展性。
## 544. `cs.LG` - 在多模态大语言模型中，看还是读：用户行为推理 [PDF](https://arxiv.org/pdf/2511.03845), [HTML](https://arxiv.org/abs/2511.03845)
### Authors
Tianning Dong,Luyi Ma,Varun Vasudevan,Jason Cho,Sushant Kumar,Kannan Achan
### Background
多模态大语言模型（MLLMs）正在改变现代代理系统处理用户行为数据的方式。然而，文本或图像的用户行为数据表示在提升MLLM性能方面哪种更为有效尚未得到充分探索。本研究利用一个实际的购买序列表数据集，在六个MLLMs中，通过将交易数据表示为（1）文本段落、（2）散点图和（3）流程图，系统地评估了模态之间的权衡取舍。研究表明，当数据以图像形式表示时，预测接下来的购买行为的准确性提高了87.5%，且没有增加额外的计算成本。
### Innovation
本文提出了行为探针（BehaviorLens），一个系统化的基准测试框架，用于评估六个MLLMs在用户行为推理方面的模态权衡。该研究通过不同形式（文本、图像）的数据表示，实证比较了它们在预测用户接下来行为上的表现差异，为多模态大语言模型的设计提供了新的视角和方法。
### Conclusion
研究表明，图像形式的用户行为数据表示不仅能够显著提高接下来购买行为的预测准确性，而且能够在计算成本不变的情况下实现这一提升。这对于理解如何优化多模态大语言模型以更好地处理用户行为数据具有重要意义。
## 545. `cs.LG` - 由深度学习驱动的降尺度方法用于评估北欧地区未来温度极端事件的气候风险 [PDF](https://arxiv.org/pdf/2511.03770), [HTML](https://arxiv.org/abs/2511.03770)
### Authors
Parthiban Loganathan,Elias Zea,Ricardo Vinuesa,Evelyn Otero
### Background
北欧地区广泛分布着不同类型的柯本-革赫格气候区。这些地区的快速变化和增加的气候变异性催生了显著的适应需求。区域规划需依赖高分辨率的未来温度预测。针对这一需求，本研究提供了一个集成降尺度框架，该框架结合了Vision Transformer (ViT)、卷积长短期记忆网络（ConvLSTM）和具有空间-时间注意力机制以及不平衡感知网络（GeoStaNet模型）。该框架使用Deep Learning-TOPSIS (DL-TOPSIS) 多准则决策系统在十个代表性气象站上评估温度数据，这些站点覆盖了温带海洋性(Cfb)、亚北极海洋性(Cfc)、暖夏季大陆性(Dfb)以及亚北极(Dfc)气候区。研究通过挪威地球系统模型（NorESM2-LM）CMIP6输出进行了偏差校正和验证。
### Innovation
本研究开发了一种集成降尺度框架，集成了ViT、ConvLSTM和GeoStaNet模型，提供站址、高分辨率的未来温度极值不确定性估计。此外，研究采用了DL-TOPSIS多准则决策系统，并评估了不同气候区域的气温变化。特别是该框架在提高温度预测精度方面表现出色，利用NorESM2-LM CMIP6输出生成可信的降尺度预测。
### Conclusion
在SSP5-8.5情景下，亚北欧行（Dfc）和暖夏季大陆性的（Dfb）气候区域预计分别在2100年前后升温4.8°C和3.9°C，日温差增加超过1.5°C。亚北极冬季季节最先出现时间出现（Dfc：约2032年）的信号，表明迫切需要适应性措施。研究结果为高纬度地区快速环境变化下的适应政策提供站址、高分辨率不确定性和极值估计，具有直接的应用价值。
## 546. `cs.LG` - 使用sinogram训练的物理知情神经网络提高CT衍生心血管流速估计：一个模拟研究 [PDF](https://arxiv.org/pdf/2511.03876), [HTML](https://arxiv.org/abs/2511.03876)
### Authors
Jinyuxuan Guo,Gurnoor Singh Khurana,Alejandro Gonzalo Grande,Juan C. del Alamo,Francisco Contijoch
### Background
非侵入性的基于成像的方法在评估心脏结构和功能中起着关键作用。尽管CT是一种常用的成像方法，可以细致地评估心血管结构和功能，但直接从对比剂演变的电影中估算血液流速的方法尚未开发。因此，需要改进的方法来提高CT成像在流速估计中的效果。
### Innovation
该研究提出了一种改进的框架SinoFlow，利用sinogram数据直接估算血液流速。SinoFlow通过避免滤波反投影引入的误差提高流速估计的性能，并在各种CT参数设置中表现稳定，同时保持更高的准确性和兼容性。
### Conclusion
研究证明了SinoFlow在CT流速估计中的潜在价值，为非侵入性血液流速评估提供了更有力的方法。研究结果还旨在为进一步将PINNs应用于CT图像提供指导，并为基于图像的估算提供解决方案，在合理的采集参数下可以获得准确的流速估计。
## 547. `cs.LG` - 知自我：用于大语言模型可解释性的代理助手 [PDF](https://arxiv.org/pdf/2511.03878), [HTML](https://arxiv.org/abs/2511.03878)
### Authors
Suraj Prasai,Mengnan Du,Ying Zhang,Fan Yang
### Background
现有的工具虽然提供了有用的信息，但这些工具仍然存在分散、代码复杂的问题。学者们需要更集合化和易于使用的界面来理解和解释大型语言模型（LLM）。
### Innovation
开发了名为‘知自我’的代理助手，将各种能力整合到基于聊天的界面中，用户可以上传模型、提出自然语言问题并获得带有指导说明的交互式可视化。核心设计包括一个调度器LLM重新表述用户查询，一个代理路由器进一步将其导向专业化模块，最终输出被汇总成连贯的解释。这一设计降低了技术门槛，提供了一个可扩展的平台用于检查大语言模型。
### Conclusion
通过将整个流程嵌入对话式工作流程中，‘知自我’为可访问的大语言模型可解释性提供了坚实的基础，使得这一领域更易于理解和使用。
## 548. `cs.LG` - OMPILOT: 系统化利用变压器模型进行自动并行化以适应共享内存计算范式 [PDF](https://arxiv.org/pdf/2511.03866), [HTML](https://arxiv.org/abs/2511.03866)
### Authors
Arijit Bhattacharjee,Ali TehraniJamsaz,Le Chen,Niranjan Hasabnis,Mihai Capota,Nesreen Ahmed,Ali Jannesari
### Background
近年来，大规模语言模型（LLMs）在代码翻译方面取得了显著进展，提高了跨编程语言转换的准确性和效率。原始开发主要是用于自然语言处理，但LLMs展示了强大的编程语言语法和语义建模能力，超越了传统基于规则的系统，在准确性和灵活性方面都表现更为出色。这些模型简化了跨语言转换，减少了开发成本，并加速了遗留代码的迁移。
### Innovation
论文介绍了一种名为OMPILOT的新颖领域特定编码器-解码器变压器模型，专门用于将C++代码翻译为OpenMP，从而实现有效的共享内存并行化。OMPILOT利用了针对并行构造语义的定制预训练目标，并结合了无监督和监督学习策略以提高代码翻译的鲁棒性。与之前主要聚焦于循环层面转换的工作不同，OMPILOT在函数级别运作，捕捉更广泛的语义上下文。此外，论文提出了一种新的复合评价指标OMPBLEU，专门用于评估OpenMP并行构造的正确性和质量，解决了传统翻译指标的局限性。
### Conclusion
OMPILOT模型通过结合预训练目标、无监督和监督学习策略，增强了代码翻译的精确性和范围。OMPILOT在函数级别操作，以捕捉更丰富的语义上下文，并通过新型指标OMPBLEU评估软件质量，展示了其在自动并行化方面的优越性能。
## 549. `cs.LG` - 哪种相似性敏感熵？ [PDF](https://arxiv.org/pdf/2511.03849), [HTML](https://arxiv.org/abs/2511.03849)
### Authors
Phuc Nguyen,Josiah Couch,Rahul Bansal,Alexandra Morgan,Chris Tam,Miao Li,Rima Arnaout,Ramy Arnaout
### Background
量化系统的标准步骤之一是测量其熵。传统的熵度量如香农熵仅捕捉系统元素频率中的信息。近年来，Leinster、Cobbold和Reeve (LCR)提出了一种新的方法，可以捕捉元素之间相似性和差异中的丰富信息，从而引入了一种相似性敏感的熵。之后，Vendi得分 (VS) 被引入作为替代方法，提出了关于LCR与VS如何比较以及哪种更优的问题。本文通过概念、数学分析和实验，特别是在53个机器学习数据集中的应用，探讨了这两个方法的优劣对比，显示二者能捕捉系统中的互补信息，除非在某些极限情况下有差异。此外，文章还探讨了相似度的量化依赖性，并引入了“半距离”的概念来量化这种依赖性。证明 VS 就Rényi-Hill指数参数的某些值而言提供了LCR的上界，并推测这种界对于所有值都成立。研究表明，仅在将元素视为基本“元元素”线性组合或系统或数据集具有量子力学特性的情况下，VS 是更优的选择。对于只希望捕捉由相似性提供的丰富信息的广泛情况，LCR是更优的；即便在某些“半距离”情况下，两种方法也能够互补。
### Innovation
1. 提出了“相似性敏感熵”，并讨论了LCR与VS两种方法的比较，揭示它们在捕捉系统信息方面的互补性质。2. 引入了“半距离”的概念来量化相似度的量化依赖性。3. 证明了VS在某些Rényi-Hill指数参数值上提供了LCR的上界，并推测这种界对于所有值都成立。
### Conclusion
在涉及基本“元元素”的线性组合或系统具有量子力学特性的特定情况下，Vendi得分 (VS) 是更优选的方法；而在其他情况下，Leinster、Cobbold和Reeve (LCR) 提出的方法更受青睐。此外，两种方法在某些“半距离”下也可以互补。
## 550. `cs.LG` - 探索自主X射线引导脊柱手术的机器人控制策略学习 [PDF](https://arxiv.org/pdf/2511.03882), [HTML](https://arxiv.org/abs/2511.03882)
### Authors
Florence Klitzner,Blanca Inigo,Benjamin D. Killeen,Lalithkumar Seenivasan,Michelle Song,Axel Krieger,Mathias Unberath
### Background
基于模仿学习的机器人控制策略在基于视频的机器人技术中重新引起了关注。然而，这种方法是否适用于如脊柱内固定等X射线引导的程序仍不清楚，因为多视角X射线的解释非常复杂。鉴于此，研究者选择双平面引导穿刺针插入作为研究对象。为了实现这一目标，他们开发了一个高度逼真的模拟环境，并收集了一组正确的穿刺路径和相应的双平面X射线序列，用于训练基于模仿学习的规划和开环控制策略。
### Innovation
研究设计了一个高度逼真的仿真环境，用于大规模和自动化模拟X射线引导下的脊柱手术。该环境保证了高度的真实性。通过收集正确的穿刺路径和双平面X射线序列，他们训练出仅基于视觉信息迭代对准穿刺针的模仿学习策略。这一精确控制的设置，揭示了这种方法的局限性和能力。尽管初步结果显示该策略能在68.5%的情况下一次性成功，并保持安全的椎体内路径，但精确进入点的精度仍然存在问题，且在提供足够频繁的反馈方面需要进一步考虑。
### Conclusion
这项工作初步表现出一定的潜力，但在实际应用中仍存在一些限制，比如进入点的精确度。全闭环控制需要提供更频繁的反馈。通过更稳健的先验知识和领域知识，这些模型可能会为未来的轻量化和无CT脊柱内手术导航奠定基础。
## 551. `cs.LG` - 掩蔽扩散模型的最佳推理调度 [PDF](https://arxiv.org/pdf/2511.04647), [HTML](https://arxiv.org/abs/2511.04647)
### Authors
Sitan Chen,Kevin Cong,Jerry Li
### Background
标准自回归大规模语言模型的主要瓶颈在于其推理过程是顺序进行的，导致推理时间非常长且昂贵。为克服这一问题，从业者提出了一类称为扩散语言模型的模型，其中蒙版扩散模型（MDM）最为成功。MDM能够按非顺序方式采样标记，并且似乎能够并行采样许多标记。然而，对于这些模型能够进行多少并行采样而不显著影响其采样性能，缺乏严密的理解。
### Innovation
本文给出了MDM模型的一种新的、精确的预期分歧特性，这种特性适用于任何分布和采样调度。通过利用这一连接，本文取得了关于此问题的一些新的下界和上界。尽管这种连接理论上给出了适用于任何分布的最佳解码调度，但本文证明在一般情况下，没有先验知识是无法与它竞争的，即使在看似简单的环境中也是如此。此外，本文还展示了基于基础分布信息理论特征的新上界和新采样格式，其中双总相关和双总相关的特性和性质表明，在某些自然环境中，可以在O(log n)步中采样而不会有任何明显的性能损失，其中n是总序列长度。
### Conclusion
本文提供了关于MDM模型并行采样的最优特征和特性，及其与函数逼近理论的关联。通过这种关联，本文揭示了新的下界和上界，尽管理论上可以确定任何分布的最佳采样策略，但在没有先验知识的情况下，通常无法实现这一最佳策略。本文还介绍了根据基础分布的信息论特性进行采样的新策略，证明在某些情况下可以在对数时间内采样而不会损失性能。
## 552. `cs.LG` - 使用3D CT图像自动化生成主动脉瓣有限元网格的形状变形网络 [PDF](https://arxiv.org/pdf/2511.03890), [HTML](https://arxiv.org/abs/2511.03890)
### Authors
Linchen Qian,Jiasong Chen,Ruonan Gong,Wei Sun,Minliang Liu,Liang Liang
### Background
准确地从3D CT图像中对主动脉瓣进行几何建模对于生物力学分析和患者特异性模拟评估瓣膜健康或进行术前计划至关重要。然而，生成具有高质量和一致性的主动脉瓣网格模型仍然具有挑战性。传统方法往往产生拓扑形状不规则的三角网格，这可能导致元素形状差以及由于患者间解剖变异而导致的对应关系不一致。
### Innovation
本文通过引入基于深度神经网络的模板贴合流水线，从3D CT图像中生成具有结构化的四边形网格来表示主动脉瓣几何结构，以应对这一挑战。这种方法确保了网格拓扑在患者间的一致性，通过使用一个包含几何重建项和光滑正则化项的损失函数简化了深度神经网络的学习目标，从而提高了网格光滑性和元素质量。
### Conclusion
实验结果表明，所提出的方法生成了高质量的主动脉瓣表面网格，具有更好的光滑性和形状质量，并且相比传统方法需要更少的显式正则化项。这些结果表明，使用结构化的四边形网格作为模板和神经网络训练不仅可以保证网格对应关系和质量，还可以简化训练过程，从而提高了主动脉瓣建模的有效性和效率。
## 553. `cs.LG` - 使用向量化计算欧拉特征函数和变换 [PDF](https://arxiv.org/pdf/2511.03909), [HTML](https://arxiv.org/abs/2511.03909)
### Authors
Jessi Cisewski-Kehe,Brittany Terese Fasy,Alexander McCleary,Eli Quist,Jack Ruder
### Background
加权欧拉特征变换（WECT）和欧拉特征函数（ECF）已经在多种应用中显示出其实用性。然而，目前计算这些函数的方法既未优化速度，也未扩展到高维环境。现有的方法难以高效且适用多维几何单形（或立方体复形）的计算.
### Innovation
提出了一个基于张量操作的向量化框架，该框架适用于GPU架构，并且可以在任意维度的几何单形（或立方体复形）上全功能运行，相比于现有方法，在多种图像数据集上计算WECT和ECF时，速度提高了多达180倍。这些变换的计算已实现于开源Python包pyECT中.
### Conclusion
本文介绍的向量化框架有效地改进了高维几何单形（或立方体复形）上计算WECT和ECF的方法，实现了高效且全功能的计算，为这些工具在更广泛的应用中提供了可能。
## 554. `cs.LG` - 沿标签树攀登：医疗成像中保持层次结构的对比学习 [PDF](https://arxiv.org/pdf/2511.03771), [HTML](https://arxiv.org/abs/2511.03771)
### Authors
Alif Elham Khan
### Background
医学图像标签通常按照分类学组织（例如，器官-组织-亚型），但标准的自监督学习（SSL）忽视了这种结构。为此，本文提出了一种保持层次结构的对比框架，使标签树成为训练信号和评估目标。
### Innovation
该文章引入了两种插件目标：层次加权对比（HWC）和层次感知边界（LAM）。HWC 根据共享祖先调整正负配对强度，以促进内部一致性；LAM 是一种原型边界，用于区分不同层级的祖先组。这两种目标可以在几何无关的情况下应用于欧几里得和双曲嵌入，而不需要改变架构。
### Conclusion
实验结果表明，提出的策略在多个基准测试（包括乳腺组织病理学）中，能够得到比强SSL基础模型更好的表征质量，同时更好地尊重分类学。通过特征一致性等度量指标进行评估，本文的算法能够更好地实现标签树结构的保护，且未改变曲率的情况下，这两种目标仍然得到最佳的效果。总之，该方法提供了一种简单而通用的配方，用于学习尊重标签树结构的医学图像表示，进一步促进了层次结构丰富的领域中的性能和可解释性。
## 555. `cs.LG` - 高维随机梯度下降的高维极限定理：含有动量和自适应步长 [PDF](https://arxiv.org/pdf/2511.03952), [HTML](https://arxiv.org/abs/2511.03952)
### Authors
Aukosh Jagannath,Taj Jones-McCormick,Varnan Sarangian
### Background
本文研究了具有Polyak动量和自适应步长的随机梯度下降（SGD-M）算法在高维情况下的行为，提供了在线SGD及其一些变种之间严格比较的框架。研究涵盖了Spiked Tensor PCA和单指数模型两个流行的学习问题，验证了算法在高维情况下的多方面益处，包括更接近全局极小值的固定点和更宽广的适应步长范围。
### Innovation
开发了高维条件下的随机梯度下降(Momentum)与自适应步长的极限理论，提供了一种严格比较在线梯度下降及其变种的方法。研究表明，即使自适应步长相同，SGD-M也可能在高维下表现出较差的性能与在线梯度下降相比。特别是在高维情况下，该算法可以带来固定点接近真实极小值和允许更多步长范围的优势，理论上支持并解释了早期预训练稳定并改进在线随机梯度下降中动态失败的问题。
### Conclusion
成果揭示了早期内存预处理能够通过稳定和改善在线随机梯度下降的动态来提高其性能，在高维情况下特别有效。
## 556. `cs.LG` - GRAD: 图谱检索自适应解码在幻觉缓解中的应用 [PDF](https://arxiv.org/pdf/2511.03900), [HTML](https://arxiv.org/abs/2511.03900)
### Authors
Manh Nguyen,Sunil Gupta,Dai Do,Hung Le
### Background
大规模语言模型（LLMs）在生成过程中仍面临幻觉缓解的挑战，尽管模型规模在不断扩大。现有的方法常常依赖外部知识源，如结构化数据库或知识图谱，通过提示或检索获取信息。然而，基于提示的知识接地脆弱且领域敏感，而符号知识集成则会产生高昂的检索和格式化成本。
### Innovation
为了借鉴知识图谱的思路，本文提出了在解码过程中基于图谱检索的自适应解码（Graph-Retrieved Adaptive Decoding, GRAD）方法。GRAD 不需要重新训练模型，在一次前向传递中构造稀疏的令牌过渡图，通过累加小型检索语料库的下一个令牌概率。在解码过程中，图检索得到的概率会被最大归一化并适配地融合到模型概率中，从而有助于生成高证据支持的内容，同时保持流畅性。无论是在三个模型上还是在覆盖内在、外在幻觉、事实任务的问答基准测试中，GRAD 比贪心解码均表现出色，提高了内在准确性、降低了幻觉率，并提高了正确率，同时获得了最高的真实性-信息性产品评分，超过了所有其他方法。
### Conclusion
GRAD 提供了一种轻量级且即插即用的替代方案，对比解码和知识图谱增强，证明了从语料库级别的令牌过渡统计证据能有效引导生成更真实和可验证的输出。
## 557. `cs.LG` - 基于数据和模型增强YOLOv12 DL模型的沙漠垃圾检测与分类 [PDF](https://arxiv.org/pdf/2511.03888), [HTML](https://arxiv.org/abs/2511.03888)
### Authors
Abdulmumin Sa'ad,Sulaimon Oyeniyi Adebayo,Abdul Jabbar Siddiqui
### Background
全球固体废物危机正在加剧，预计到2050年固体废物产生量将增加70%。传统废物收集方法，尤其是在沙漠等偏远或恶劣环境中，劳动密集、低效且往往具有危险性。尽管最近在计算机视觉和深度学习方面的进展为自动废物检测系统打开了大门，但大多数研究主要集中在城市环境中可回收材料的检测上，而忽略了有机和危险废物以及未被探索的沙漠等特殊地形。
### Innovation
本文提出了一种基于精简轻量级YOLov12的增强实时对象检测框架，集成自对抗训练（SAT）和特定的数据增强策略。通过使用DroneTrashNet数据集，证明了在精确度、召回率和mAP上的显著改进，同时实现了低延迟和紧凑的模型大小，适合在资源受限的航空无人机上部署。与最先进的轻量级YOLO变体进行基准测试，进一步突显了其在准确性和效率上的最佳平衡。
### Conclusion
实验结果验证了结合数据为中心和模型为中心的增强对于在沙漠环境中实现鲁棒的实时废物检测的有效性。
## 558. `cs.LG` - 使用一般技术近似高维经验核矩阵 [PDF](https://arxiv.org/pdf/2511.03892), [HTML](https://arxiv.org/abs/2511.03892)
### Authors
Chiraag Kaushik,Justin Romberg,Vidya Muthukumar
### Background
本文探讨了一种在一般核函数条件下，计算随机核矩阵的预期算子范数的简单易用的方法。方法利用了U-统计的解耦结果和非交换Khintchine不等式，得到依赖于核函数的标量统计和相应的“相关核”矩阵的上下界。这种方法特别应用到了高维数据中内积核矩阵的新、更紧的近似结果，其中样本量和数据维度呈多项式关系。
### Innovation
提出了一种使用解耦结果和非交换Khintchine不等式的方法，得到了依赖于标量统计和相关核矩阵的随机核矩阵的上下界。这种方法简化了现有依赖矩方法和组合证明的结果，并为各向异性高斯数据提供了新的近似结果。通过相似的技术还得到了更紧的偏置下界。
### Conclusion
这种方法不仅简化了现有的基于矩方法和组合论证的证明，还为各向异性高斯数据提供了新的近似结果，并且通过类似技术得到了一种更紧的偏置下界。
## 559. `cs.LG` - 限于列表的语言识别问题的刻画 [PDF](https://arxiv.org/pdf/2511.04103), [HTML](https://arxiv.org/abs/2511.04103)
### Authors
Moses Charikar,Chirag Pabbaraju,Ambuj Tewari
### Background
作者研究了语言识别的心理学极限问题，目标是在给定目标语言的示例序列后，学习者输出一系列猜测，使得若干时间点之后的所有猜测都是正确的。传统的结果显示，语言识别极限几乎对任何有趣的语言集合都是不可能的。后来，Angluin对这个问题进行了精确的归纳，给出了哪些语言集合可以在这种条件下被识别。基于最近在语言生成问题中的积极研究成果，作者重新审视了语言识别问题，这次学习者可以每一步生成一个包含$k$个猜测的列表，目标是在若干时点之后，每一时刻至少有一个猜测是正确的。作者给出了可以被$k$列表识别的集合的精确特性，并且给出了一种新的可理解的刻画：可以被$k$列表识别的集合当且仅当它可以被分解为$k$个集合，这些集合中的每一个都可以被单个列表识别。作者还利用刻画结果建立了统计设置下识别率的结果。
### Innovation
作者基于Angluin的单列表识别结果，引入了$k$列表识别的具体特性，并提供了概念吸引力的刻画，指出了$k$列表识别与单列表识别之间的关系。该研究进一步证明了$k$列表识别的收集可以在指数速率下被$k$列表识别，这是最优的结果，同时也证明了不可$k$列表识别的集合不存在任何识别速率。这一结果推进了对语言识别问题的理解。
### Conclusion
可以被$k$列表识别的集合当且仅当它可以被分解为$k$个集合，这些集合中的每一个都可以被单个列表识别；如果集合是$k$列表识别的，那么它可以以指数速率$k$列表识别；如果不可$k$列表识别，那么任何识别率趋零的识别都是不可能的。
## 560. `cs.LG` - 使用密度功率Stein算子进行鲁棒推理 [PDF](https://arxiv.org/pdf/2511.03963), [HTML](https://arxiv.org/abs/2511.03963)
### Authors
Shinto Eguchi
### Background
本文提出了一种密度功率加权的Stein算子，即$boldsymbol{text{γ}}$-Stein算子，并将其归因于来自$boldsymbol{text{γ}}$-散度的新类算子。该算子的设计目的是为了构建对于非规范化概率模型的鲁棒推理方法。这种算子通过将模型密度的幂次作为权重，隐含地下权重离群值的影响，从而提供了一种稳健性的原则机制。应用该算子，作者提出了一种稳健的扩展分数匹配方法，该方法保留了不依赖于模型归一化常数的关键属性。作者还扩展了该框架，开发出两个关键应用：$boldsymbol{text{γ}}$-核化Stein差异用于稳健的拟合优度检验，以及$boldsymbol{text{γ}}$-Stein变分梯度下降用于稳健的贝叶斯后验逼近。
### Innovation
作者利用$boldsymbol{text{γ}}$-Stein算子构建了一种对于非规范化概率模型的鲁棒的分数匹配方法，并发展了两种关键应用：一种用于稳健的拟合优度检验的$boldsymbol{text{γ}}$-核化Stein差异，以及一种用于稳健的贝叶斯后验逼近的$boldsymbol{text{γ}}$-Stein变分梯度下降。这些方法通过保持不依赖于模型的归一化常数的关键属性，提供了一种稳健的替代标准基线的方法。实验结果表明，作者的方法在鲁棒性和统计效率方面显著优于标准基线方法，尤其是在污染的高斯模型和四次势模型上取得了显著的性能提升。
### Conclusion
本文提出了$boldsymbol{text{γ}}$-Stein算子，一种新的用于构建非规范化概率模型的鲁棒推理方法。作者通过应用该算子，提出了稳健的分数匹配方法和基于该算子的应用。实验结果表明，新方法相较于标准方法具有显著的鲁棒性和统计效率优势。
## 561. `cs.LG` - REMIND: 输入损失景观揭示后续卸载的大规模语言模型中的残留记忆 [PDF](https://arxiv.org/pdf/2511.04228), [HTML](https://arxiv.org/abs/2511.04228)
### Authors
Liran Cohen,Yaniv Nemcovesky,Avi Mendelson
### Background
机器卸载旨在从模型中去除特定训练数据的影响，无需重新训练。这对于保障隐私、安全和合规至关重要。因此，验证模型是否真正忘记了目标数据对于保持可靠性和可信度是必不可少的。然而，现有的评估方法通常是在单个输入层面评估遗忘情况。这种方法可能无法捕捉到在语义相似样本中存在的残留影响。这种残留影响会损害隐私并导致间接信息泄露。
### Innovation
本文提出了REMIND（残留记忆在邻域动力学中的发现）这一新颖的评估方法，用于检测未学数据的细微剩余影响并判断数据是否被有效遗忘。REMIND通过分析模型在小输入变化下的损失变化，揭示了单一输入点评估无法发现的模式。研究表明，未学数据产生平缓、不陡峭的损失景观，保留或无关数据则表现出更尖锐、更具波动性的模式。REMIND仅需基于查询的访问，其性能优于在类似约束条件下其他方法，并且在不同模型、数据集和重新表述的输入中展示了鲁棒性，使其适用于现实世界的部署。
### Conclusion
REMIND提供了对卸载效果更为敏感且可解释的度量，为评估语言模型的卸载提供了可靠框架。结果表明，REMIND为记忆和卸载的理解提供了新的视角。
## 562. `cs.LG` - 最小体积非负矩阵分解在扩展充分分散条件下鲁棒性 [PDF](https://arxiv.org/pdf/2511.04291), [HTML](https://arxiv.org/abs/2511.04291)
### Authors
Giovanni Barbarino,Nicolas Gillis,Subhayan Saha
### Background
最小体积非负矩阵分解(min-vol NMF)已被成功应用于多种领域，包括高光谱成像、化学动力学、光谱学、主题建模及音频源分离。然而，它在噪声环境中的鲁棒性一直是个长期未解的问题。
### Innovation
本文证明了在扩展充分分散条件下，最小体积非负矩阵分解可以在噪声环境中识别出真实的因子。
### Conclusion
最小体积非负矩阵分解在数据点充分分散于由基向量生成的潜在单纯形空间内时，可以在噪声条件下识别出真实因子，解决了其在噪声环境下的鲁棒性问题。
## 563. `cs.LG` - 在线回顾调整的齐性推断以更快适应分布变化 [PDF](https://arxiv.org/pdf/2511.04275), [HTML](https://arxiv.org/abs/2511.04275)
### Authors
Jungbin Jun,Ilsang Ohn
### Background
齐性预测作为一种有效的框架，能够在满足可交换性假设的前提下构建无分布预测集并提供保证的覆盖率。然而，在线环境中，数据分布随时间变化，这意味着可交换性假设经常被违反。尽管最近提出了一些解决这一问题的方法，但这些方法通常是逐步适应分布变化的，因为它们只能向前调整预测，即只生成新观察数据点的预测而不更新之前已计算的预测。
### Innovation
本文提出了一种新的在线齐性推理方法，带有回顾性调整机制，旨在更快地适应分布变化。该方法利用回归方法以及有效的去一个点外留更新公式，在新数据到达时回顾性地调整过去的预测，从而使整个预测集与最新的数据分布保持一致。
### Conclusion
通过在合成数据集和真实数据集上进行广泛数字研究，我们展示了所提出的方法比现有在线齐性预测方法更快的覆盖率重新校准和更高的统计效率。
## 564. `cs.LG` - 基于AI驱动的入侵检测系统的自动化和可解释性服务分析 [PDF](https://arxiv.org/pdf/2511.04114), [HTML](https://arxiv.org/abs/2511.04114)
### Authors
Paul Badu Yakubu,Lesther Santana,Mohamed Rahouti,Yufeng Xin,Abdellah Chehri,Mohammed Aledhari
### Background
随着分布式拒绝服务（DDoS）攻击的频率和复杂性增加，开发更高效且易于解释的检测方法变得至关重要。传统的检测系统在可扩展性和透明性方面存在局限性，阻碍了实时响应和攻击向量的理解。本文提出了一种使用机器学习（ML）自动检测和解释DDoS攻击的框架。通过利用基于树的管道优化工具（TPOT）自动化选择和优化ML模型及特征，减少手动实验的需要。利用SHapley Additive exPlanations（SHAP）增强了模型的可解释性，提供对单个特征在检测过程中的贡献的详细见解。结合TPOT自动管道选择和SHAP可解释性，这种方法提高了DDoS检测的准确性和透明性。实验结果表明特征如平均向后数据包长度和最小前向数据包头部长度在检测DDoS攻击中至关重要，提供了可扩展和可解释的网络安全解决方案。
### Innovation
本文提出的创新在于使用基于树的管道优化工具（TPOT）自动化选择和优化机器学习模型及特征，以及利用SHapley Additive exPlanations（SHAP）增强模型的可解释性。这种结合提高了DDoS检测的准确性和透明性，并提供了可解释的网络安全解决方案，能够有效应对DDoS攻击的挑战。
### Conclusion
通过结合TPOT的自动管道选择和SHAP可解释性，本文的方法提高了DDoS检测的准确性和透明性。实验结果证明了该方法的有效性，强调了关键特征在DDoS检测中的作用，并为基于AI驱动的入侵检测系统提供了可扩展且解释清晰的解决方案。
## 565. `cs.LG` - MedSapiens: 将姿态应用于重新思考医学成像 landmark 检测 [PDF](https://arxiv.org/pdf/2511.04255), [HTML](https://arxiv.org/abs/2511.04255)
### Authors
Marawan Elbatel,Anbang Wang,Keyuan Liu,Kaouther Mouheb,Enrique Almar-Munoz,Lizhuo Lin,Yanqi Yang,Karim Lekadir,Xiaomeng Li
### Background
传统的 landmark 检测依赖于领域特定的模型，而大规模预训练视觉模型的出现为该领域带来了新的机遇。尽管如此，人类中心的基础模型的潜力仍未得到充分挖掘，这些模型原本旨在实现空间姿态定位。
### Innovation
该研究通过多数据集预训练 Sapiens（一个用于姿态估计的人类中心基础模型）来重新思考医学成像中的 landmark 检测，提出了 MedSapiens 模型，实现了在多个数据集上的新最佳表现。MedSapiens 在平均成功检测率 (SDR) 上相较于通用模型提高了 5.26%，相较于专科模型提高了 21.81%。同时，它在有限标注数据设置下的性能也得到了评估，相较于少样本状态的最新技术，SDR 提高了 2.69%。
### Conclusion
MedSapiens 证明了人类中心的基础模型在 anatomical landmark 检测中的强大先验，展示了即使在少量标注数据的情况下，它们也具有很强的适应性。
## 566. `cs.LG` - Twirlator: 用于分析量子机器学习波函数子群对称性效应的流水线 [PDF](https://arxiv.org/pdf/2511.04243), [HTML](https://arxiv.org/abs/2511.04243)
### Authors
Valter Uotila,Väinö Mehtola,Ilmo Salmenperä,Bo Zhao
### Background
在几何深度学习和几何相关的量子机器学习中，利用数据对称性是提升性能的关键因素。尽管对称化方法显示出一定的潜力，但在量子机器学习中其实践开销（如额外门操作、表达能力受限等）尚未被充分理解。本文发展了一个自动流水线来测量量子机器学习波函数在各种对称性条件下的特性，定义了学习问题的对称度为允许的子群大小。研究了不同大小的子群表示对19种常见波函数的影响，并通过计算描述各种对称性条件下波函数行为的三种类别的度量，从而展示了各个波函数门开销的变化，以及对表达能力和纠缠能力的影响，以帮助选择合适的波函数模式用于几何量子机器学习应用。
### Innovation
开发了一种自动流水线来分析量子机器学习波函数在不同子群对称性影响下的特性。引入了基于原生成器和对称化生成器差值的范数、分类深度和大小以及纠缠能力和表达性的度量方法，揭示了子群对称性对不同波函数的门开销和纠缠能力的影响。
### Conclusion
研究表明，不同对称性条件下波函数的门开销有所不同。随着对称性的增加，波函数的表达能力降低，而纠缠能力通常会增加。这些结果有助于选取足够表达力和计算效率的波函数模式，应用于几何量子机器学习中。
## 567. `cs.LG` - DeepPAAC:一种新的深Galerkin方法用于代理-委托问题 [PDF](https://arxiv.org/pdf/2511.04309), [HTML](https://arxiv.org/abs/2511.04309)
### Authors
Michael Ludkovski,Changgen Xie,Zimu Zhu
### Background
文章讨论了连续时间下的代理-委托(Principal-Agent, PA)问题的数值求解。现有的研究通常难以处理具有连续支付和多维代理策略的问题，特别是在处理复杂的Hamilton-Jacobi-Bellman方程时存在挑战。因此，需要发展一种新的数值方法来解决这些问题。
### Innovation
文章提出了一个新的基于深度学习的算法，即DeepPAAC Actor-Critic（DeepPAAC），它可以有效处理多维状态和控制，并具有处理隐式Hamiltonians的能力。此外，作者还研究了神经网络架构、训练设计和损失函数对求解器收敛性的影响，并通过五个不同的案例研究来验证其有效性。
### Conclusion
研究结果表明，DeepPAAC算法能够有效地解决多维状态下的代理-委托问题，并能处理复杂的约束条件。通过不同的案例研究，展示了该算法在不同情况下的稳定性和准确性。
## 568. `cs.LG` - AIM: 超高性能PIM架构级IR-drop缓解的软硬件协同设计 [PDF](https://arxiv.org/pdf/2511.04321), [HTML](https://arxiv.org/abs/2511.04321)
### Authors
Yuanpeng Zhang,Xing Hu,Xi Chen,Zhihang Yuan,Cong Li,Jingchen Zhu,Zhao Wang,Chenguang Zhang,Xin Si,Wei Gao,Qiang Wu,Runsheng Wang,Guangyu Sun
### Background
SRAM Processing-in-Memory (PIM)在高性能PIM实现中表现出色，提供了极高的计算密度、能源效率和计算精度。然而，追求更高性能需要更复杂的电路设计和更高的操作频率，这进一步加剧了IR-drop问题。严重的IR-drop会显著降低芯片性能并威胁其可靠性。传统的电路级IR-drop缓解方法，如后端优化，虽然资源密集，但却常常在性能、功耗和面积（PPA）之间做出妥协。
### Innovation
我们提出了AIM，一种在超高性能PIM架构级IR-drop缓解的软硬件协同设计方法。首先，利用PIM中的位串行和原位数据流计算特性，引入Rtog和HR，建立了PIM工作负载与IR-drop之间的直接关联。在此基础上，提出了LHR和WDS，能够在保持计算准确度的前提下，进行全面的架构级IR-drop缓解探索。紧接着，开发了IR-Booster，这是一种动态调整机制，能够结合软件级HR信息和硬件基于的IR-drop监控，以动态调整PIM宏的V-f对，从而实现增强的能源效率和性能。最后，提出了HR意识任务映射方法，以联通软件和硬件设计，实现最佳改进效果。
### Conclusion
在7nm 256-TOPS PIM芯片上进行的后布局仿真结果显示，AIM实现了高达69.2%的IR-drop缓解，带来2.29倍的能源效率提升和1.152倍的速度提升。
## 569. `cs.LG` - 使用扩展时间序列结构因果模型在能源市场中检测因果结构变化 [PDF](https://arxiv.org/pdf/2511.04361), [HTML](https://arxiv.org/abs/2511.04361)
### Authors
Dennis Thumm
### Background
能源市场展示了天气模式、发电技术和价格形成之间的复杂因果关系，这种关系呈现出连续的变化而非离散的转折点。当前的方法在建模电力价格时，并没有明确的因果解释或反事实推理能力。
### Innovation
引入了扩展时间序列因果模型(ATSCM)，将反事实推理框架扩展到具有学习因果结构的多变量时间数据中。通过整合神经因果发现，学习时间变化的因果图，无需真实DAG作为先验知识。这种方法能够生成新型反事实查询，比如在不同的可再生能源发电情景下，价格会是多少？
### Conclusion
通过ATSCM，能够在实际的电力市场价格数据中实现复杂的因果关系建模，提供对不同可再生能源发电情景下的价格预测能力。
## 570. `cs.LG` - LLMs仍在哪些方面挣扎？代码生成基准的深入分析 [PDF](https://arxiv.org/pdf/2511.04355), [HTML](https://arxiv.org/abs/2511.04355)
### Authors
Amir Molzam Sharifloo,Maedeh Heydari,Parsa Kazerooni,Daniel Maninger,Mira Mezini
### Background
大型语言模型（LLMs）在代码生成方面取得了显著成功，提高其性能已成为AI研究的核心焦点。基准和排行榜日益流行，提供了LLMs的定量排名，但它们对LLMs常无法解决的任务提供有限的洞察，这对于理解当前的限制和引导更强大模型的开发至关重要。现有的一些基准和技术未能揭示LLMs的弱点。
### Innovation
本文深入分析了四个流行基准上的代码生成任务，识别出LLMs最可能失败的任务，并通过系统检查114个LLMs持续挣扎的任务，揭示了LLMs的四大反复出现的弱点模式，以及基准任务中最常导致失败的常见复杂性。
### Conclusion
研究揭示了LLMs的四大反复出现的弱点模式和基准任务中常见的复杂性，这些发现对于理解当前的限制并指导更强大模型的开发具有重要意义。
## 571. `cs.LG` - MusRec：通过矫正流和扩散变换器实现的零样本文本到音乐编辑 [PDF](https://arxiv.org/pdf/2511.04376), [HTML](https://arxiv.org/abs/2511.04376)
### Authors
Ali Boudaghi,Hadi Zare
### Background
音乐编辑已成为人工智能中的一个重要且实用的领域，其应用范围广泛，从视频游戏和电影音乐制作到根据用户偏好个性化现有曲目。然而，现有的模型存在许多限制，比如只能编辑由自己模型生成的合成音乐、需要非常精确的提示或需要针对特定任务重新训练，因此缺乏真正的零样本能力。
### Innovation
利用近期在矫正流和扩散变换器方面取得的进展，我们提出了MusRec，这是一个前所未有的零样本文本到音乐编辑模型，能够在不针对特定任务重新训练的情况下，有效地编辑真实音乐中的多种任务。实验证明我们的方法在保留音乐内容、结构一致性和编辑保真度方面优于现有方法，为实际应用场景中的可控音乐编辑奠定了坚实的基础。
### Conclusion
通过MusRec模型，我们展示了在实际场景中实现可控音乐编辑的能力，达到了在保留音乐内容、结构一致性和编辑保真度方面的优越性能，这一成果为音乐编辑领域的发展作出了贡献。
## 572. `cs.LG` - 深度Koopman经济模型预测控制在巴氏杀菌单元中的应用 [PDF](https://arxiv.org/pdf/2511.04437), [HTML](https://arxiv.org/abs/2511.04437)
### Authors
Patrik Valábek,Michaela Horváthová,Martin Klaučo
### Background
本文讨论了一种针对实验室规模的巴氏杀菌单元（PU）的高效运营，提出了一种基于深度Koopman的经济模型预测控制（EMPC）方法。该方法利用Koopman算子理论将复杂的非线性系统动力学转化为线性表示，以便使用凸优化算法，并能准确表示复杂的PU系统。
### Innovation
本文的方法通过使用神经网络从实验数据中学习线性动力学，相比传统的N4SID子空间辨识，开放环预测准确性提高了45%。此外，基于Koopman的EMPC方法在缓解扰动（如输送泵失效和引入冷批次）下与N4SID EMPC方法相比，总经济成本降低了32%，主要归因于材料损失和能源消耗的减少。
### Conclusion
Koopman基于的EMPC方法在热密集型工厂的资源效率控制中展示了其实用优势，通过将深度Koopman表示与经济优化相结合，实现了资源的有效利用。
## 573. `cs.LG` - 子流形稀疏卷积网络在计算机断层扫描中自动化3D分割肾脏及肾肿瘤 [PDF](https://arxiv.org/pdf/2511.04334), [HTML](https://arxiv.org/abs/2511.04334)
### Authors
Saúl Alonso-Monsalve,Leigh H. Whitehead,Adam Aurisano,Lorena Escudero Sanchez
### Background
在放射学图像如计算机断层扫描（CT）中，准确勾勒肿瘤的任务非常专业化且耗时，目前已成为限制临床环境中进行定量分析的瓶颈。开发用于医学影像中肿瘤自动分割的方法变得至关重要，近年来已经取得了显著进展。然而，传统卷积神经网络在处理大量体素的3D扫描时，因计算复杂度较高，通常需要进行体素的降采样或使用局部切片。
### Innovation
本文提出了一种新的方法，利用体素稀疏化和子流形稀疏卷积网络分两阶段进行处理，这种方法可以在高分辨率输入下进行分割，同时保持3D模型架构的原貌，能够获得最先进的准确率，同时显著减少了计算资源的需求，相比等效的密集架构，其推理时间最多减少60%，VRAM使用量最多减少75%，适用于CPU和各类GPU。
### Conclusion
本文方法在肾癌患者的CT图像中应用于KiTS23挑战，达到了具有竞争力的结果，肾+肿块的Dice相似系数为95.8%，肿块+囊肿的Dice相似系数为85.7%，肿块单独的Dice相似系数为80.3%，同时在CPU和测试的各类GPU卡上实现了显著的计算改进，推理时间和VRAM使用量分别减少了60%和75%。
## 574. `cs.LG` - 视觉定位推理中的多任务学习在消化道VQA中的应用 [PDF](https://arxiv.org/pdf/2511.04384), [HTML](https://arxiv.org/abs/2511.04384)
### Authors
Itbaan Safwan,Muhammad Annas Shaikh,Muhammad Haaris,Ramail Khan,Muhammad Atif Tahir
### Background
该论文针对MediaEval Medico 2025挑战中的视觉问答（VQA）任务，介绍了利用LoRA调整过的Florence-2模型构建的多任务框架。框架整合了三个数据集：Kvasir-VQA-x1以学习问答，合成增强的解释数据集提供结构化的医疗推理，以及连接文本与区域的文本到区域对，将视觉特征与分割掩模联系起来。多个评估表明，多任务模型在答案准确性和视觉定位方面显著优于单任务基线，强调了基于地基多任务学习在医疗VQA应用中的有效性。
### Innovation
提出了利用逐步调整过的Florence-2模型的多任务框架，同时进行视觉问答、解释生成和视觉定位。该框架结合了三个精心策划的数据集，创新性地通过多任务学习来共同学习视觉定位、推理和解释，从而产生更准确和可解释的回答。
### Conclusion
我们的研究展示了在消化道的VQA任务中使用多任务学习方法的巨大潜力。多任务模型在视觉问答的准确性、解释的结构化程度以及视觉定位的精确度上都显著优于单任务模型。这证明了结合多任务学习和特定医疗数据集在处理复杂视觉推理任务上的有效性。
## 575. `cs.LG` - 偏好陷阱：为什么GRPO在序数奖励上失败 [PDF](https://arxiv.org/pdf/2511.04439), [HTML](https://arxiv.org/abs/2511.04439)
### Authors
Anisha Garg,Ganesh Venkatesh
### Background
GRPO因其简洁性而在适应大型语言模型（LLM）完成特定任务方面具有高度吸引力。然而，这种简洁性也使其在增强以丰富、非二元反馈进行训练时变得不够明确。当利用序数奖励给出部分奖励时，GRPO的简洁性开始出现问题，因为它群体平均基线往往赋予失败轨迹正向优势，从而强化错误行为。
### Innovation
我们引入了Correctness Relative Policy Optimization（CoRPO），一种新方法，解决了这一缺陷。CoRPO使用可调节的基线，设置最低质量阈值，确保失败的解决方案不会受到正向激励。只有当策略一致性地达到该阈值时，基线才会自动转换为相对偏好模式，推动模型寻找最优解而非仅仅“可接受”的解。我们通过代码验证任务实证验证了CoRPO的有效性，显示出更强的稳定性收敛和更好的泛化能力。
### Conclusion
这项工作标志着我们更广泛的研究计划中的关键一步，旨在通过强化学习让LLM学习真正新的能力。我们通过使LLM能够从丰富的多维反馈中学习实现这一点——从本工作的二元到序数奖励，进而发展到每步更密集的监督。
## 576. `cs.LG` - 采用增强 LSTM 的无词典方法识别具有输入延迟非线性系统的线性模型 [PDF](https://arxiv.org/pdf/2511.04451), [HTML](https://arxiv.org/abs/2511.04451)
### Authors
Patrik Valábek,Marek Wadinger,Michal Kvasnica,Martin Klaučo
### Background
非线性动力系统伴有输入延迟会为预测、估计和控制带来重大挑战，这是因为系统的复杂性和延迟对系统行为的影响。传统的线性控制技术在这种背景下往往无效，需要创新的方法。传统的扩展动态模式分解(eDMD)方法依赖于预先定义的字典，这可能导致系统动力学未知或未被正确地纳入字典中。
### Innovation
本文提出了一种利用增强 LSTM 的 Deep Koopman 模型来近似库默曼算子的新方法，从而能够对具有时间延迟的非线性系统进行线性表示。通过引入 LSTM 层，所提出的框架可以捕捉历史依赖性，并有效地将带延迟的系统动力学编码到潜在空间中。与依赖预先定义字典的传统 eDMD 方法不同，LSTM 增强的 Deep Koopman 模型是无字典的，这种方法可以缓解因系统动力学未知而无法集成本身进行字典构建的问题。
### Conclusion
与 eDMD 在模拟系统上的对比表明，当真实非线性动力学未知时，该方法在预测准确性方面具有显著优势。即使系统的真实动力学未知，该方法也能够达到与预知系统动力学的 eDMD 相当的结果。
## 577. `cs.LG` - 在线贝叶斯实验设计在部分观测动态系统的应用 [PDF](https://arxiv.org/pdf/2511.04403), [HTML](https://arxiv.org/abs/2511.04403)
### Authors
Sara Pérez-Vieites,Sahel Iqbal,Simo Särkkä,Dominik Baumann
### Background
贝叶斯实验设计（BED）提供了一种原理性的框架来优化数据收集，但在至关重要的实际场景中，如部分可观测的动态系统中却不适用。这些系统通常可以使用状态空间模型（SSM）来建模，其中潜状态变量在参数和数据之间起到中介作用，使得似然性——以及信息论目标如期望信息增益（EIG）——变得难以处理。此外，系统的动态特性要求一种能够在计算上高效地顺序更新后验分布和选择设计的在线算法。已有方法不能有效解决这些问题。因此，作者针对上述挑战，提出了新的方法，通过引入嵌套粒子滤波器（NPF）来高效进行在线推理并提供收敛性保证，成功处理部分可观测性和在线计算的问题。
### Innovation
作者为非线性状态空间模型开发了新的期望信息增益（EIG）及其梯度的估计器，这些估计器会明确地对潜状态进行归一化处理，从而使得在计算上实现大规模随机优化成为可能。这项创新还利用嵌套粒子滤波器进行高效在线推理，并提供了收敛性保证，最终使得现有方法无法有效处理的部分观测动态系统的贝叶斯实验设计问题得以解决。该方法被成功应用于实际模型中，如易感-感染-恢复（SIR）模型和移动源定位任务中，展示了新框架的有效性。
### Conclusion
通过引入采用嵌套粒子滤波器（NPF）进行在线推理的新贝叶斯实验设计方法，我们成功克服了部分观测动态系统中存在的挑战。我们的方法不仅适用于处理部分可观测量，还能够在线计算，所提出的方法通过估计器对潜状态进行归一化处理，使得大规模随机优化成为可能。该方法应用于真实模型中，如SIR和移动源定位任务，证明了它在实际应用场景中的有效性。
## 578. `cs.LG` - 订阅平台上的防欺诈收益分配 [PDF](https://arxiv.org/pdf/2511.04465), [HTML](https://arxiv.org/abs/2511.04465)
### Authors
Abheek Ghosh,Tzeh Yuan Neoh,Nicholas Teh,Giannis Tyrovolas
### Background
研究围绕基于订阅平台展开，用户支付固定费用以获得内容的无限访问权限，创作者则获得收入的一部分。当前识别欺诈的方法主要依赖机器学习，与不良行为者之间形成不断升级的对抗。
### Innovation
探讨了一种内生地抵消欺诈激励的收益分配机制。定义了三种欺诈抵抗公理，并检查现有规则是否满足这些公理。发现广泛应用于流媒体平台的机制不仅未能防止欺诈，还使得欺诈检测成为计算上不可行的任务。同时，提出了一种新型规则，即ScalesUserProp，满足所有三种欺诈抵抗公理。并且，通过使用真实世界和合成流媒体数据实验，证实ScalesUserProp作为一种更公平的选择优于现有的规则。
### Conclusion
ScalesUserProp 规则在防止欺诈和检测欺诈方面比现有规则更为公平和有效。
## 579. `cs.LG` - 在贝塔环境下拟合强化学习模型到行为数据 [PDF](https://arxiv.org/pdf/2511.04454), [HTML](https://arxiv.org/abs/2511.04454)
### Authors
Hao Zhu,Jasper Hoffmann,Baohe Zhang,Joschka Boedecker
### Background
近年来，强化学习模型在科学研究中被广泛关注，用于描述人类和动物的决策行为。本文考虑在多臂赌博机环境中拟合强化学习模型到已给定的行为数据的问题，以优化这类模型的应用范围。通过理论分析，本文提出了一个基于凸松弛和优化的新颖求解方法，并在模拟的多臂赌博机环境下与现有基准方法进行对比，表明此方法在性能和计算时间上都有显著优势。
### Innovation
本文提供了一个适用于广泛应用场景的强化学习模型拟合的通用数学优化问题的形式化表达，并基于理论结果提出了基于凸松弛和优化的新颖求解方法。该方法在模拟多臂赌博机环境下表现出色，并显著减少了计算时间。此外，还提供了开源的Python包使得研究人员可以直接应用于数据分析而无需具备凸优化的知识。
### Conclusion
本文提出的方法在性能上与现有最先进的方法相当，但在计算时间上表现更优。同时，提供了一个开源的Python包，使得研究人员可以直接应用此方法进行数据分析，无需了解凸优化的相关知识。
## 580. `cs.LG` - 使用集成汉克动态模式分解的德尔夫特372双体船数据驱动不确定感知波浪适应性预测 [PDF](https://arxiv.org/pdf/2511.04461), [HTML](https://arxiv.org/abs/2511.04461)
### Authors
Giorgio Palma,Andrea Serani,Matteo Diez
### Background
研究对象是德尔夫特372号双体船在海况5条件下的波浪适应性测试。通过不规则波槽测试收集了在Fr = 0.425下的纵中心波高、纵摇、俯仰、概念飞行甲板速度、概念桥加速度和总阻力的实验测量（时间序列）数据。这些数据被组织成训练集、验证集和测试集，以开发和验证不确定感知的波浪适应性预测方法。
### Innovation
文章创新地提出了集成汉克动态模式分解（HDMDc）算法，这种算法解决了波浪适应性预测中的非线性和记忆效应问题，并且通过两种集成策略，即贝叶斯HDMDc（BHDMDc）和费禧里叶HDMDc（FHDMDc），提供了不确定性的估计和概率分布。特别是FHDMDc方法相比传统的确定性方法，能够更准确地预测波浪适应性，并提供稳健的不确定性估计，而BHDMDc在当前测试案例中没有显示出明显的优势。
### Conclusion
FHDMDc方法产生的运动概率密度函数与实验数据和URANS结果高度一致，表明该方法具有可靠的波浪适应性预测能力，为设计和操作支持提供了有效的计算手段。
## 581. `cs.LG` - RUST-BENCH：在结构化表格内的非结构化文本上评估LLM推理 [PDF](https://arxiv.org/pdf/2511.04491), [HTML](https://arxiv.org/abs/2511.04491)
### Authors
Nikhil Abhyankar,Purvi Chaurasia,Sanchit Kabra,Ananya Srivastava,Vivek Gupta,Chandan K. Reddy
### Background
现有的表格推理基准大多测试模型在小而统一的表格上的表现，这未能充分反映实际数据的复杂性，并且未能全面评估大型语言模型（LLMs）的推理能力。实际表格通常很长，异构且特定于领域，包含结构化字段和自由文本，并要求跨数千个标记进行多跳推理。
### Innovation
RUST-BENCH引入了一个新的基准，包含了7966个来自2031个真实世界的表格问题，覆盖了两个领域：i）RB-Science（NSF资助记录）和ii）RB-Sports（NBA统计数据）。与其他工作的不同之处在于，RUST-BENCH联合评估了LLMs在规模、异构性、领域特异性以及推理复杂性方面的表现。
### Conclusion
实验结果显示，LLMs在异构模式和复杂多跳推理方面表现不佳，暴露出现有架构中的持久弱点，并提出了策略。RUST-BENCH为推进表格推理研究设立了新的挑战性测试平台。
## 582. `cs.LG` - 在线重复最优停止算法：同时实现竞争比和后悔上界 [PDF](https://arxiv.org/pdf/2511.04484), [HTML](https://arxiv.org/abs/2511.04484)
### Authors
Tsubasa Harada,Yasushi Kawase,Hanna Sumita
### Background
研究重复最优停止问题，该问题将经典的最优停止问题推广到在T轮中反复解决相同问题的场景。在此框架下，目标是设计能够在每轮提供竞争力同时在整个过程中实现亚线性后悔的算法。
### Innovation
提出一种通用的算法框架，能够同时在广泛重复最优停止问题中实现这些目标。核心思想是在每轮中动态选择算法，选择标准是基于观察历史的最优算法或基于样本的具有竞争比保证的算法。
### Conclusion
该方法不仅在每轮中至少与基线样本算法表现相当，并且确保整体后悔量在网络为$?tilde{O}(?sqrt{T})$的上界；并在诸如预言不等式、秘书问题及在对抗、随机和独立同分布输入模型下的变体中展示了广泛的应用。此外，对重复预言不等式问题给出了$1/2$的竞争比从第二轮开始，并且$?tilde{O}(?sqrt{T})$后悔量，还建立了$?Omega(?sqrt{T})$的后悔下界，表明算法的性能几乎是最优的。
## 583. `cs.LG` - 保密计算在云安全中的应用：探索基于硬件的加密使用信任执行环境 [PDF](https://arxiv.org/pdf/2511.04550), [HTML](https://arxiv.org/abs/2511.04550)
### Authors
Dhruv Deepak Agarwal,Aswani Kumar Cherukuri
### Background
随着云计算的发展，数据处理和存储能力得到了前所未有的扩展和灵活性，同时带来了巨大的安全挑战，尤其是在保护敏感数据方面。传统的安全措施，如静态加密和传输加密，无法保护数据在使用过程中的安全，并且暴露于各种可能的泄露风险中。
### Innovation
本文探讨了使用硬件基于的信任执行环境（如Intel SGX和ARM TrustZone）来保护数据处理过程中的隐私性和完整性，作为传统的安全措施的补充。通过文献综述，分析了这些信任执行环境的部署策略、性能指标和实际应用，指出了部署过程中可能面临的问题、潜在弱点、扩展性问题和集成问题，强调了信任执行环境在增强和推动云安全基础设施中的核心作用。
### Conclusion
信任执行环境在构建保密计算的坚实基础方面具有重要作用，为云安全基础设施提供了安全保障，推动了保密计算的发展。
## 584. `cs.LG` - 功能性脑图的统一生成潜表征 [PDF](https://arxiv.org/pdf/2511.04539), [HTML](https://arxiv.org/abs/2511.04539)
### Authors
Subati Abulikemu,Tiago Azevedo,Michail Mamalakis,John Suckling
### Background
通常情况下，功能脑图的特性被用不同的图论描述量或频谱描述量进行独立刻画，忽略了这些特征在不同脑和条件下如何相互关联和部分重叠。研究人员认为，密集的加权功能连接图占据了一个低维度的潜在几何空间，在这个空间中，拓扑结构和频谱结构表现出逐步变化。
### Innovation
通过图变换自动编码器与潜在扩散的方法估计此统一图表示，并生成密集的功能脑图，频谱几何提供了归纳偏置以引导学习。这种感知几何的潜表征是无监督的，但能有效区分工作记忆状态并解码视觉刺激，通过整合神经动力学进一步提高了性能。从扩散建模的分布中，能够采样出符合生物学原理的结构合理的人工密集图。
### Conclusion
此研究通过图变换自动编码器与潜在扩散的方法估计了一个统一的图形表示，生成了密集的功能脑图。此几何感知的潜表征无监督地分离了工作记忆状态并能解码视觉刺激，研究结果进一步通过整合神经动力学提高效率和准确性，并且能够生成符合生物学原理的人工稠密图。
## 585. `cs.LG` - 在物理制约下的逆问题不确定性：科学AI中的隐藏风险 [PDF](https://arxiv.org/pdf/2511.04564), [HTML](https://arxiv.org/abs/2511.04564)
### Authors
Yoh-ichi Mototake,Makoto Sasaki
### Background
物理信息化的机器学习（PIML）将偏微分方程（PDE）整合到机器学习模型中，用于解决估计表征物理系统的系数函数（如哈密顿函数）的逆问题。尽管系数函数在PIML中通常基于预测性能进行估算，但物理学科在评估模型时并不仅依赖于预测准确性。例如，开普勒的日心模型因其行星运动的微小偏差被推崇，尽管其预测准确性与地心模型相似。这突显了数据驱动建模中的固有不确定性以及选择物理意义上合理解的科学重要性。
### Innovation
本文提出了一种框架，用于量化和分析物理信息化逆问题中系数函数估计中固有的不确定性。该框架应用于磁流体力学的简化模型，并展示了通过几何约束可以识别不确定性，并且可以唯一确定简化模型。
### Conclusion
通过引入几何约束，我们能够在物理信息化逆问题中唯一地估计简化模型，并确认可以减轻不确定性带来的风险。
## 586. `cs.LG` - Jr. AI Scientist 及其风险报告：从基线论文开展自主科学探索 [PDF](https://arxiv.org/pdf/2511.04583), [HTML](https://arxiv.org/abs/2511.04583)
### Authors
Atsuyuki Miyai,Mashiro Toyooka,Takashi Otonari,Zaiying Zhao,Kiyoharu Aizawa
### Background
理解和掌握当前人工智能科学家系统的功能和风险对于确保可信赖的和可持续的AI驱动科学研究至关重要，同时也需要保持学术生态系统的完整性和诚信。许多现有的AI科学家系统要么假设完全自动化，要么仅在小型代码上运行，这限制了它们在复杂多文件实现中的应用，无法产生有价值的科学贡献。
### Innovation
我们通过开发Jr. AI科学家，实现了一种最先进的自主AI科学家系统，模仿了一名普通学生研究人员的核心研究工作流程。该系统能够根据人类导师提供的基线论文，分析其局限性，提出改进的新假设，通过严谨的实验验证这些假设，并撰写包含结果的论文。Jr. AI科学家遵循明确的研究工作流程，并利用现代编码代理处理复杂的多文件实现，增加了科学贡献的价值。
### Conclusion
我们的评估结果显示Jr. AI科学家生成的论文在评审中获得了比现有完全自动系统更高的评分。然而，这两种评估方法都发现了一些重要的限制，指出了直接应用当前AI科学家系统的潜在风险和未来研究的关键挑战。我们将全面报告开发过程中发现的各种风险。希望这些见解能加深对AI科学家开发进展和风险的理解。
## 587. `cs.LG` - 里斯兹回归作为直接密度比率估计 [PDF](https://arxiv.org/pdf/2511.04568), [HTML](https://arxiv.org/abs/2511.04568)
### Authors
Masahiro Kato
### Background
里斯兹回归作为一种在偏差校正机器学习中用于因果和结构参数估计的工具，已经引起了人们的关注（Chernozhukov等，2021）。研究表明，在平均处理效应（ATE）估计等重要情况下，里斯兹回归与直接密度比率估计（DRE）紧密相关。里斯兹回归与直接密度比率估计中的直接重要性拟合（LSIF，Kanamori等，2009）在思想和目标上一致。尽管里斯兹回归因其广泛的适用性而受到重视，可以应用于广泛的代表性估计问题，但与DRE的等效性允许我们直接应用特定情况下的现有结果，包括收敛率分析、通过最小化Bregman散度选择损失函数以及用于灵活模型（如神经网络）的正则化技术。
### Innovation
这项研究确认了里斯兹回归与直接密度比率估计之间的等效性，特别是在处理效应估计的情况下。这一点允许直接借用现有的针对直接密度比率估计方法的结果，如收敛率分析，Bregman散度最小化的损失函数选择以及对神经网络等灵活模型的正则化技术。这项研究继续作者之前在Kato（2025a）和Kato（2025b）的文章中的研究结果。
### Conclusion
里斯兹回归与直接密度比率估计之间的等效性拓宽了直接密度比率估计方法的应用范围，使欠偏差机器学习中的里斯兹代表器洞察片段适用于更广泛的领域。
## 588. `cs.LG` - 阿尔茨海默病中的潜在潜时间动态因果发现 [PDF](https://arxiv.org/pdf/2511.04619), [HTML](https://arxiv.org/abs/2511.04619)
### Authors
Natalia Glazman,Jyoti Mangal,Pedro Borges,Sebastien Ourselin,M. Jorge Cardoso
### Background
大多数因果发现方法假设图是静态的，这限制了这些方法在疾病如阿尔茨海默病（AD）中的应用。此类模型无法解释因潜在疾病时间轴调节下的不断演变的病理生理学。
### Innovation
提出将现有的潜在变量模型应用于实际的AD数据，推断出能够摆脱实际年龄影响的数据驱动疾病轨迹的潜时间，从而学习因果关系的变化。同时，引入少量的、与疾病无关的基本知识显著提高了图的准确性和方向性。
### Conclusion
潜时间比实际年龄更能预测诊断（AUC 0.82 vs 0.59）。我们的框架揭示了新（NfL, GFAP）和已建立的AD标记之间的动态相互作用，即使在违背假设的情况下也能实现实际的因果发现。
## 589. `cs.LG` - evomap：Python中的动态映射工具箱 [PDF](https://arxiv.org/pdf/2511.04611), [HTML](https://arxiv.org/abs/2511.04611)
### Authors
Maximilian Matthe
### Background
映射方法在多个学科中广泛用于将对象之间的关系可视化为空间表示或地图。然而，现有的大多数统计软件仅支持静态映射，这种映射只能捕捉对象在某一时间点的关系，并缺乏分析这些关系随时间变化的工具。evomap通过实现原文由Matthe, Ringel, 和Skiera（2023年）提出的动态映射框架EvoMap填补了这一空白，将传统的静态映射方法适用于动态分析。
### Innovation
evomap包支持多种映射技术，包括多维尺度法（MDS）的变体、Sammon映射和t分布的随机临近嵌入（t-SNE）。此外，它还提供数据预处理、探索和结果评估的工具，为动态映射应用提供了全面的工具集。
### Conclusion
本文概述了静态和动态映射的基础知识，详细描述了evomap的架构和功能，并通过一个详细的使用案例来说明其应用。
## 590. `cs.LG` - W7-X中的电子尺度湍流建模的机器学习方法 [PDF](https://arxiv.org/pdf/2511.04567), [HTML](https://arxiv.org/abs/2511.04567)
### Authors
Ionut-Gabriel Farcas,Don Lawrence Carl Agapito Fernando,Alejandro Banon Navarro,Gabriele Merlo,Frank Jenko
### Background
构建减少的湍流传输模型是加速剖面预测和执行不确定性量化、参数扫描和设计优化等多查询任务的关键。本研究涉及构建机器学习驱动的W7-X stellarator中的电子温度梯度（ETG）湍流模型。
### Innovation
该论文提出了一个机器学习驱动的减少模型，该模型通过回归和基于主动机器学习的程序构建，预测ETG热通量作为三个等离子体参数的函数：归一化电子温度径向梯度（$boldsymbol{boldsymbol{boldsymbol{boldsymbol{boldsymbol{boldsymbol{boldsymbol{boldsymbol{boldsymbol{boldsymbol{beta}}}}}}}}})$n_{boldsymbol{boldsymbol{boldsymbol{boldsymbol{boldsymbol{boldsymbol{boldsymbol{boldsymbol{beta}}}}}}}}}}}$），归一化电子温度和密度径向梯度比（$boldsymbol{boldsymbol{boldsymbol{boldsymbol{boldsymbol{boldsymbol{boldsymbol{boldsymbol{boldsymbol{boldsymbol{beta}}}}}}}}}})$n_{boldsymbol{boldsymbol{boldsymbol{boldsymbol{boldsymbol{boldsymbol{boldsymbol{boldsymbol{boldsymbol{boldsymbol{beta}}}}}}}}}}}}}$），电子与离子温度比（$boldsymbol{tau}$）。模型首先在七个径向位置构建模型，然后通过从现有模拟数据库中选择最具信息性的点动态改进训练集，以提高预测能力。此外，研究还构建了通用的、位置无关的减少模型，并评估了它们在其他位置的预测能力。
### Conclusion
研究中的模型展示了稳健的性能和准确性与原始参考模拟相当，即使在超过训练域的应用中也是如此。这表明通过机器学习构建的减少模型具有广泛的应用潜力。
## 591. `cs.LG` - DR. WELL: 动态推理与符号世界模型学习结合的多智能体协作框架 [PDF](https://arxiv.org/pdf/2511.04646), [HTML](https://arxiv.org/abs/2511.04646)
### Authors
Narjes Nourzad,Hanqing Yang,Shiyu Chen,Carlee Joe-Wong
### Background
多智能体合作规划需要智能体在部分信息和有限通信的情况下进行联合决策。在轨迹层面的协调常常失败，因为时间或动作的小偏差会引发冲突。符号规划通过提高抽象层次和提供基本的动作词汇来解决这一挑战，从而实现同步和集体进步。基于动态世界模型，多智能体之间通过谈判协议进行合作，确保在环境约束下的同步和联合分配，并独立生成和执行符合该分配的符号计划，避免了低层次的轨迹对齐问题，确保了高级操作的可重用性、可同步性和可解释性。
### Innovation
提出了DR.WELL，一种去中心化的神经符号框架，用于多智能体合作规划。其主要创新在于通过两阶段的谈判协议协调智能体角色分配，并通过动态世界模型确保执行计划的可行性。这种框架允许智能体进行高层次的推理和同步执行，从而避免了直接对齐低层轨迹的复杂性，增强了计划的灵活性和可解释性，能够在动态环境中实现智能体之间的高效协作。
### Conclusion
通过实验验证了承诺机制和动态世界模型的有效性，表明该方法能够提高任务完成率和效率，智能体在任务执行过程中能够灵活适应不断变化的环境，利用自演化能力优化协作策略。
## 592. `cs.LG` - 基于ODE逼近的Adam算法：通用与过参数化的设置 [PDF](https://arxiv.org/pdf/2511.04622), [HTML](https://arxiv.org/abs/2511.04622)
### Authors
Steffen Dereich,Arnulf Jentzen,Sebastian Kassing
### Background
Adam优化器目前被认为是深度学习中最受欢迎的优化方法。本文通过发展基于ODE的方法，研究Adam优化器在快慢系统的尺度范围内的行为。在固定动量参数并在步长趋于零的情况下，证明了Adam算法是特定向量场的流的渐近伪轨迹，该向量场被称为Adam向量场。利用渐近伪轨迹的性质建立了算法的收敛结果。对于比较一般的设定，证明了如果Adam算法收敛，则其极限点必须是Adam向量场的零点，而不仅仅是目标函数的局部极小点或临界点。与目标函数最小化比较，Adam算法在过参数化的经验风险最小化条件下，能够在全局最小点附近的邻域内局部找到最小点集。证明了目标函数在全局最小点邻域内作为诱导自Adam向量场的流的Lyapunov函数，并且如果Adam算法无穷多次进入全局最小点的邻域，则会收敛至全局最小点集
### Innovation
论文提供了一种基于ODE的方法来分析Adam优化器，特别是在快慢系统的尺度范围内。证明了Adam算法的渐近伪轨迹性质，建立了它的收敛性结果。在全局最小点附近，证明了目标函数可以作为Adam向量场诱导的流的Lyapunov函数，并且能够局部找到全局最小点集
### Conclusion
如果Adam算法收敛，其极限点必须是Adam向量场的零点；特别是在过参数化的经验风险最小化条件下，Adam算法能够找到全局最小点的邻域内的最小点集。
## 593. `cs.LG` - 使用高保真Gaussian Splatting模拟软体交互的从实到仿机器人策略评估 [PDF](https://arxiv.org/pdf/2511.04665), [HTML](https://arxiv.org/abs/2511.04665)
### Authors
Kaifeng Zhang,Shuo Sha,Hanxiao Jiang,Matthew Loper,Hyunjong Song,Guangyan Cai,Zhuo Xu,Xiaochen Hu,Changxi Zheng,Yunzhu Li
### Background
机器人的操作策略正在迅速发展，但在现实世界中的直接评估仍然代价高昂、耗时且难以复制，尤其是对于涉及可变形物体的任务。现有的模拟器虽然能够提供可扩展和系统的替代方案，但在捕捉软体物体相互作用的结合视觉和物理复杂性方面通常会失败。因此，急需一种有效的方法来构建基于现实世界的软体物体数字化双胞胎，并以高保真度渲染机器人、对象和环境以进行操作策略评估。
### Innovation
本文提出了一个从实到仿的机器人策略评估框架，该框架通过从实际视频构建软体物体的数字化双胞胎，并使用3D Gaussian Splatting以高保真度渲染机器人、物体和环境，以评估机器人操作策略。这种方法在毛绒玩具打包、绳子布线和T-块推移等代表性的可变形操作任务上得到了验证，显示出模拟回放与现实世界执行性能之间强烈的相关性，并揭示了学习策略的关键行为模式。因此，这种结合物理信息重构与高质量渲染的方法能够实现可重复的、可扩展的和精确的机器人操作策略评估。
### Conclusion
结合物理信息重构与高质量渲染的方法能够实现可重复的、可扩展和准确的机器人操作策略评估，通过这种方式可以有效地评估和验证机器人在面对可变形物体任务时的表现。
## 594. `cs.LG` - 物理信息神经网络和神经算子在参数化偏微分方程中的应用：人机协作分析 [PDF](https://arxiv.org/pdf/2511.04576), [HTML](https://arxiv.org/abs/2511.04576)
### Authors
Zhuo Zhang,Xiong Xiong,Sen Zhang,Yuan Zhao,Xi Yang
### Background
偏微分方程（PDEs）在科学和工程中无处不在，且其解依赖于参数（物理属性、边界条件、几何形状）。传统数值方法需要为每个参数重新求解PDE，使得参数空间探索变得极其昂贵。然而，近年来的机器学习进步，尤其是物理信息神经网络（PINNs）和神经算子，已经通过学习能够泛化的解算子来革命性地改变了参数化PDE的解决方法。本文通过对比流体力学、固体力学、热传导和电磁学领域的实例，阐明了神经算子在多查询场景下的计算加速效果（可高达1000到100000倍）及其与传统求解器的准确性相当。本文还提供了方法选择的实用指导，讨论了理论基础（普遍逼近性、收敛性）并指出了关键的开放挑战：高维参数、复杂几何结构和离分布泛化能力。本文建立了一个统一框架，通过算子学习来理解参数化PDE求解方法，并提供了一个快速发展的领域中持续更新的综合资源。
### Innovation
研究提出了两种主要的范式：物理信息神经网络（PINNs），它将物理定律作为软约束以处理稀疏数据的逆问题；神经算子（如DeepONet、傅里叶神经算子），它学习在无限维函数空间之间的映射，从而实现了前所未有的泛化能力。神经算子在多查询场景下实现了高达1000到100000倍的计算加速，同时保持了与传统求解器相当的准确性。此外，该研究提供了方法选择的实用指导，并探讨了理论基础（普遍逼近性、收敛性）以及关键的开放挑战（高维参数、复杂几何结构、离分布泛化能力）。通过这种方法，本文为快速发展的领域提供了一个统一的框架和持续更新的综合资源。
### Conclusion
本文建立了一个统一框架，通过算子学习来理解参数化PDE求解方法，并提供了一个快速发展的领域中持续更新的综合资源。本文通过对比分析，证明了神经算子在计算效率上的显著优势，并指出了未来研究的关键方向，有助于推动该领域的进一步发展。
## 595. `cs.LG` - 评价者的等效性：在人类判断环境中的分类器评估 [PDF](https://arxiv.org/pdf/2106.01254), [HTML](https://arxiv.org/abs/2106.01254)
### Authors
Paul Resnick,Yuqing Kong,Grant Schoenebeck,Tim Weninger
### Background
在许多决策环境中，确定性的正确答案不存在或不可用。在这种情况下，比较自动化分类器与人类判断是很有帮助的。论文介绍了一种基于人类判断来评估分类器的方法和框架。
### Innovation
论文提出了一个全新的框架，用于仅基于人类判断来评估分类器。该方法量化了一个分类器的表现，即判断该分类器等效于多少个能够给出类似判断的人类评判者。此外，该框架还区分了基于假定正确答案的一致性和基于单个人类判断的匹配性两种模型，并展示了如何使用该框架来实践地评估与部署AI系统。
### Conclusion
通过案例研究和形式化分析，论文展示了这种框架的实际应用，并提供了在人类判断环境中如何更好地评价和部署AI系统的指导。
## 596. `cs.LG` - A Unified Kernel for Neural Network Learning [PDF](https://arxiv.org/pdf/2403.17467), [HTML](https://arxiv.org/abs/2403.17467)
### Authors
Shao-Qun Zhang,Zong-Yi Chen,Yong-Ming Tian,Xun Lu
### Background
过去的几十年里，神经网络学习和核学习之间的区分和联系引起了广泛关注。最近的研究成果促进了无限宽神经网络与高斯过程之间的理论联系。主要的两种方法是神经网络高斯过程（NNGP）和神经 tangent 核（NTK）。NNGP 是基于贝叶斯推理的一阶核，而 NTK 是基于梯度下降的切线空间的一阶核。
### Innovation
本文提出了统一神经内核（UNK），由生成变量的内积诱导，表征了梯度下降和参数初始化下的神经网络学习动态。UNK 核保留了 NNGP 和 NTK 的极限性质，在有限的学习步骤中表现出 NTK 的行为，并在其学习步长趋于无穷时收敛到 NNGP。此外，我们还从理论上刻画了 UNK 核的统一性和学习收敛性，提供了对这一统一核的全面理解。
### Conclusion
实验结果验证了所提方法的有效性。
## 597. `cs.LG` - DES Year 3 结果：利用深度学习从弱引力透镜和星系聚集图实现 $w$CDM 推断的模拟基于推断。I. 分析设计 [PDF](https://arxiv.org/pdf/2511.04681), [HTML](https://arxiv.org/abs/2511.04681)
### Authors
A. Thomsen,J. Bucko,T. Kacprzak,V. Ajani,J. Fluri,A. Refregier,D. Anbajagane,F. J. Castander,A. Ferté,M. Gatti,N. Jeffrey,A. Alarcon,A. Amon,K. Bechtol,M. R. Becker,G. M. Bernstein,A. Campos,A. Carnero Rosell,C. Chang,R. Chen,A. Choi,M. Crocce,C. Davis,J. DeRose,S. Dodelson,C. Doux,K. Eckert,J. Elvin-Poole,S. Everett,P. Fosalba,D. Gruen,I. Harrison,K. Herner,E. M. Huff,M. Jarvis,N. Kuropatkin,P.-F. Leget,N. MacCrann,J. McCullough,J. Myles,A. Navarro-Alsina,S. Pandey,A. Porredon,J. Prat,M. Raveri,M. Rodriguez-Monroy,R. P. Rollins,A. Roodman,E. S. Rykoff,C. Sánchez,L. F. Secco,E. Sheldon,T. Shin,M. A. Troxel,I. Tutusaus,T. N. Varga,N. Weaverdyck,R. H. Wechsler,B. Yanny,B. Yin,Y. Zhang,J. Zuntz,S. Allam,F. Andrade-Oliveira,D. Bacon,J. Blazek,D. Brooks,R. Camilleri,J. Carretero,R. Cawthon,L. N. da Costa,M. E. da Silva Pereira,T. M. Davis,J. De Vicente,S. Desai,P. Doel,J. García-Bellido,G. Gutierrez,S. R. Hinton,D. L. Hollowood,K. Honscheid,D. J. James,K. Kuehn,O. Lahav,S. Lee,J. L. Marshall,J. Mena-Fernández,F. Menanteau,R. Miquel,J. Muir,R. L. C. Ogando,A. A. Plazas Malagón,E. Sanchez,D. Sanchez Cid,I. Sevilla-Noarbe,M. Smith,E. Suchyta,M. E. C. Swanson,D. Thomas,C. To,D. L. Tucker(DES Collaboration)
### Background
数据驱动的方法，特别是深度学习技术，在从宇宙学的大尺度结构中提取非高斯信息方面展现出了强大的能力。本研究旨在利用模拟基于推断（SBI）方法结合弱引力透镜和星系聚集图，进行 Dark Energy Survey (DES) 第三年（DES Y3）的推断，为即将进行的DES数据分析做准备。该研究构建了一套可扩展的前向模型，基于CosmoGridV1 N-体模拟 suite生成了超过一百万张DES Y3级别的自洽模拟图。
### Innovation
开发了一种基于深度图卷积神经网络（CNN）的模型，用于从全样本范围内的天球几何数据中学习低维特征，这些特征大约最大化与目标参数的信息互惠。通过使用正常化流在十维参数空间（涵盖 $w$CDM 玄学、内在对齐和线性星系偏见参数）中进行神经密度估计，该模型实现了参数约束的显著提升，并通过探测量组合有效地打破了参数退化。
### Conclusion
该研究证明了由深度学习支持的SBI分析方法在即将到来的宽视场成像巡天中的潜力。目前的方法在 $theta_{OM} - S_8$ 平面上实现了参数约束结果显著改进，取得了2-3倍的成效，从而突破了参数的退化问题。实验还通过使用来自前向模型的系统污染和独立的Buzzard星系目录进行了广泛验证，以确保其稳健性。
## 598. `cs.LG` - Stochastic Diffusion: 一种用于随机时间序列预测的扩散概率模型 [PDF](https://arxiv.org/pdf/2406.02827), [HTML](https://arxiv.org/abs/2406.02827)
### Authors
Yuansan Liu,Sudanthi Wijewickrema,Dongting Hu,Christofer Bester,Stephen O'Leary,James Bailey
### Background
扩散概率模型在图像、文本和音频生成方面取得了显著进展，但应用于高度随机的时间序列数据建模仍面临挑战。这一论文在这一背景下提出了一种新的新颖模型——Stochastic Diffusion (StochDiff) 模型，旨在使其能够更好地应对高度随机的时间序列数据。
### Innovation
StochDiff模型通过利用随机潜在空间的表征能力来在每个时间步骤中学习数据驱动的先验知识，以建模多元时间序列数据的变异性。这种模型改进了对高度随机时间序列数据的建模能力，特别适用于时间序列预测。
### Conclusion
通过对真实世界数据集的广泛实验，展示了所提出的StochDiff模型在随机时间序列预测中的有效性。此外，还展示了该模型在实际手术指导中的应用，强调了其对医疗社区的潜在益处。
## 599. `cs.LG` - 局部片段，全局收益：使用图神经网络进行子图计数 [PDF](https://arxiv.org/pdf/2305.19659), [HTML](https://arxiv.org/abs/2305.19659)
### Authors
Shubhajit Roy,Shrutimoy Das,Binita Maity,Anant Kumar,Anirban Dasgupta
### Background
子图计数是分析图表结构数据中结构模式的基础任务，在诸如计算生物学和社交网络分析等领域具有重要应用。重复出现的模式揭示功能和组织性质。此前的 WL 算法版本受限于表达能力，影响了效率和效果的提升。
### Innovation
提出了局部版本的 Weisfeiler-Leman (WL) 算法来改进计数任务，包括 Local $k$-WL，证明其比 $k$-WL 更具有表达力，并提出了一种新的片段技术，可将复杂子图分解为更简单的子模式。同时，引入 Layer $k$-WL 和 Recursive $k$-WL 两种变体，提高了时间效率和空间效率。通过这些概念，开发了一个结合子模式计数来计算更复杂模式计数的可微学习框架，结合了组合算法设计和机器学习方法。此外，证明了 Local $k$-WL 在可忽略的时间复杂性下比现有 GNN 层次结构更具有表现力补充了该方法的优劣比较。
### Conclusion
结合了可微学习框架，提出的方法有效地扩展了子图计数的应用范围，并且在可忽略的时间复杂度下比先前方法更具有表达力。
## 600. `cs.LG` - 通过预训练跨多样图形和任务推广图变换器 [PDF](https://arxiv.org/pdf/2407.03953), [HTML](https://arxiv.org/abs/2407.03953)
### Authors
Yufei He,Zhenyu Hou,Yukuo Cen,Jun Hu,Feng He,Xu Cheng,Jie Tang,Bryan Hooi
### Background
图预训练主要集中在处理小图（如分子图）或固定图上的节点表征学习，但对于包含数十亿节点的工业规模大图，如何避免任务间的负面影响并发展具有归纳能力的通用图预训练模型仍然是一个挑战。作者的目标是开发一种可以在未见过的新节点甚至新图上进行预测的通用图预训练模型。
### Innovation
本文提出了一种基于Transformer架构的可扩展的图预训练框架PGT（Pre-trained Graph Transformer），在掩码自编码架构的基础上设计了两种预训练任务：一种用于重构节点特征，另一种用于重构局部结构。作者提出了一个创新策略，利用解码器进行特征增强，而非像原始自编码器那样丢弃解码器。该框架在公开数据集ogbn-papers100M上（1.11亿节点，16亿边）展示了卓越性能，证明了其可扩展性和效率，并在腾讯的在线游戏数据上部署验证了其在实际大规模图上的预训练能力和多任务推广能力。
### Conclusion
该工作通过引入PGT框架，实现了在大图上的高效可扩展性预训练，并通过实验展示了其在实际图数据上的有效推广能力。
## 601. `cs.LG` - FedQUIT：基于准能虚拟教师的设备上联邦忘却 [PDF](https://arxiv.org/pdf/2408.07587), [HTML](https://arxiv.org/abs/2408.07587)
### Authors
Alessio Mora,Lorenzo Valerio,Paolo Bellavista,Andrea Passarella
### Background
联邦学习（FL）系统允许在不集中收集个人数据的情况下协作训练机器学习模型。然而，在FL中，参与者应能够执行被遗忘的权利，即在请求时能够从已学习的模型中删除他们的过去贡献。现有方法通常需要额外的假设和复杂的数据处理步骤来实现这一点，这使跨设备设置的应用变得困难。
### Innovation
本文提出了FedQUIT，一种新颖的算法，使用知识蒸馏来从FL全局模型中擦除忘却数据的贡献，同时保持其泛化能力。FedQUIT直接作用于请求退出联邦的客户端设备，并利用教师-学生框架。FL全局模型作为教师，本地模型作为学生。为了诱导遗忘，FedQUIT对教师在本地数据上的输出（需要忘却的数据）进行调整，惩罚真实类别的预测评分。与现有方法相比，本方法不需要存储参与者的历史更新或访问代理数据集等几乎不可行的假设。
### Conclusion
通过在多种数据集和模型架构上的实验，证明了FedQUIT在忘却数据方面优于现有竞争对手，具有与常规FedAvg轮次相同的计算需求，并且通过将累计的通信成本减少最多117.6倍来重新获得初始的泛化性能，从而降低了重新训练的成本。
## 602. `cs.LG` - 理解Adam需要更好的旋转依赖假设 [PDF](https://arxiv.org/pdf/2410.19964), [HTML](https://arxiv.org/abs/2410.19964)
### Authors
Tianyue H. Zhang,Lucas Maes,Alan Milligan,Alexia Jolicoeur-Martineau,Ioannis Mitliagkas,Damien Scieur,Simon Lacoste-Julien,Charles Guille-Escuret
### Background
尽管Adam在广泛应用中表现出色，但其相对于随机梯度下降（SGD）的优势缺乏全面的理论解释。该研究发现Adam在训练Transformer时对参数空间的随机旋转非常敏感，表明其性能受到影响，从而揭示传统的旋转不变假设无法充分解释Adam的优势。研究人员还识别出一些结构化的旋转，这些旋转能够保持或者增强Adam的实验表现。研究表明现有的旋转依赖的假设无法解释不同类型的旋转对Adam行为的影响。
### Innovation
该研究揭示了Adam对旋转的依赖敏感性，并强调了旋转不变假设的不足。通过确认更新的正交性作为理解Adam基础敏感性的潜在关键指标，研究人员提出旋转依赖理论框架，来更好地解释其实验成功。
### Conclusion
研究指出，需要新的旋转依赖假设来更好地解释Adam的优势。正交性可能是关键指标，能够帮助发展旋转依赖的理论框架，这些框架将更好地解释Adam的实验成功。
## 603. `cs.LG` - 突破科莫戈罗夫障碍：一种可学习加权混合自动编码器进行模型级数减少 [PDF](https://arxiv.org/pdf/2410.18148), [HTML](https://arxiv.org/abs/2410.18148)
### Authors
Nithin Somasekharan,Shaowu Pan
### Background
高维复杂物理系统的表示学习旨在识别一个低维内在潜在空间，这对简化模型和模态分析至关重要。然而，近期引入的深度自动编码器（AEs）在潜在空间秩增加时通常表现出较差的收敛行为，难以解决著名的科莫戈罗夫障碍。
### Innovation
本文提出了一种可学习加权混合自动编码器，该模型通过结合奇异值分解（SVD）与深度自动编码器的优点，并引入可学习的加权参数来改进收敛性能。在经典混沌偏微分方程系统（如1D库拉托夫斯基-西瓦什金斯基湍流）上的实验表明，该方法在泛化性能上显著优于其他竞争方法，并且结合时序建模技术（例如库普曼算子、LSTM）可进一步优化高维多尺度偏微分方程系统的代理模型性能。
### Conclusion
通过引入可学习加权参数，提出的模型显著改善了收敛行为和泛化性能，并在高维多尺度偏微分方程系统的代理建模中提供了显著的优势。
## 604. `cs.LG` - 小奇异值很重要：随机矩阵分析中的变换器模型 [PDF](https://arxiv.org/pdf/2410.17770), [HTML](https://arxiv.org/abs/2410.17770)
### Authors
Max Staats,Matthias Thamm,Bernd Rosenow
### Background
本文分析预训练变压器模型中权值矩阵的奇异值光谱，以了解信息在光谱两端的存储情况。通过随机矩阵理论（RMT）作为零信息假设，认为与RMT的一致性是随机性的证据，而偏差则是学习的证据。研究发现，奇异值显著偏离RMT不仅是大奇异值，也有一些小奇异值。这与激活协方差矩阵的特征向量相关数据 overlap，表明小奇异值及其向量在数据中的重要意义。作者通过实验证明这一点，并提出一种线性随机矩阵模型来解释这一点。研究结果强调了光谱低端的忽视重要性，并为基于SVD的大规模语言模型修剪和压缩提供理论和实践指导。
### Innovation
本文采用了随机矩阵理论作为零信息假设，观察到不仅大奇异值，甚至小奇异值都存在显著偏离RMT的现象，并且提出了线性随机矩阵模型来解释这些观察现象。这些发现强调了光谱低端的重要性，并为基于SVD的大规模语言模型修剪和压缩提供了理论依据和技术指导。
### Conclusion
实验证明，偏离RMT的小奇异值可以比光谱中间的部分更能提高语言模型的困惑度，并且在微调后，最小的十分位部分可以成为光谱第三重要的部分。这表明，在大数据模型的权重光谱分析中，需要更加关注光谱低端的奇异值，以获得更好的模型性能。
## 605. `cs.LG` - 通过迭代比例马尔可夫方法的扩散与对抗薛定谔桥 [PDF](https://arxiv.org/pdf/2410.02601), [HTML](https://arxiv.org/abs/2410.02601)
### Authors
Sergei Kholkin,Grigoriy Ksenofontov,David Li,Nikita Kornilov,Nikita Gushchin,Alexandra Suvorikova,Alexey Kroshnin,Evgeny Burnaev,Alexander Korotin
### Background
介绍了Iterative Markovian Fitting (IMF) 程序及其对Schrödinger Bridge (SB) 问题的解决方法，说明了高效的实用实现需要采用一种启发式的修改——在每个迭代中交替拟合前向和后向时间扩散。这种修改对于稳定训练和在无配对领域翻译等应用中获得可靠结果至关重要。此外，论文揭示了修改后的IMF与基础方法Iterative Proportional Fitting (IPF) 之间的密切联系，即经典的Sinkhorn算法，并且证明了启发式修改的IMF实际上整合了IMF和IPF程序的方法。引入了一种新的融合方法，称为Iterative Proportional Markovian Fitting (IPMF) 程序。通过理论和实证分析，建立了IPMF程序在各种条件下的收敛性，从而为解决SB问题提供了一个统一框架。同时，从实用角度来看，IPMF程序提供了在图像相似度和生成质量之间灵活平衡的新机制，能够针对特定任务定制模型。
### Innovation
揭示了修改后的IMF与IPF之间的联系，将启发式修改的IMF整合为IPMF程序，并通过理论和实证分析证明其在SB问题上的收敛性，提供了一种统一的解决方案。此外，提出了一种新的在图像相似度和生成质量之间进行折中的方法，以适应特定任务的需求。
### Conclusion
通过证明IPMF程序的收敛性和应用中灵活性，该研究提供了一种解决SB问题的统一框架，并提出了一种新的机制，使模型能够适应不同任务的具体需求。
## 606. `cs.LG` - Shallow Diffuse: Robust and Invisible Watermarking through Low-Dimensional Subspaces in Diffusion Models [PDF](https://arxiv.org/pdf/2410.21088), [HTML](https://arxiv.org/abs/2410.21088)
### Authors
Wenda Li,Huijie Zhang,Qing Qu
### Background
AI生成内容的广泛应用引发了关于虚假信息和版权侵权的重要问题。水印技术是识别这些AI生成的图像并防止其滥用的关键方法。现有的一些水印方法在整个扩散采样过程中嵌入水印，但这些方法未能完全解决问题，因此研究人员开发了新的水印技术，如Shallow Diffuse，以更好地应对这些问题。
### Innovation
Shallow Diffuse是一种新的水印技术，它通过利用图像生成中的低维子空间来分离开水印嵌入与图像生成过程，确保大部分水印位于子空间的零空间中，从而增强数据生成的一致性和水印的可检测性。相比现有方法，Shallow Diffuse在鲁棒性和一致性方面表现出色。
### Conclusion
广泛的实验验证了Shallow Diffuse在鲁棒性和一致性方面优于现有水印方法。该技术发布的代码可以在 provided link 地址找到。
## 607. `cs.LG` - AnomalyAID：半监督网络异常检测中的可靠解释 [PDF](https://arxiv.org/pdf/2411.11293), [HTML](https://arxiv.org/abs/2411.11293)
### Authors
Yachao Yuan,Yu Huang,Yingwen Wu,Jin Wang
### Background
在网络异常检测应用中，无监督或者半监督学习起着重要的作用，但用有限的标标注样本学习异常模式是具有挑战性的；同时，缺乏解释性也成为了实际上采用半监督框架的一个关键障碍。现有的解释方法大多是为监督/无监督框架或非安全领域开发的，不能可靠地解释结果。
### Innovation
本文提出了一种新的半监督网络异常检测框架AnomalyAID，它旨在（1）使异常检测过程可解释，并提高解释结果的可靠性；（2）为有限监督数据上的异常检测系统提供高置信度的伪标签。该框架通过引入全局和局部解释器提供可靠的解释，同时设计了一种新的两阶段半监督学习框架，通过模型预测与特殊约束的对齐来改进网络异常检测性能。
### Conclusion
实验结果表明，AnomalyAID 能够为半监督网络异常检测系统提供准确的检测结果和可靠的解释。AnomalyAID 的代码可在该链接中获取：this https URL.
## 608. `cs.LG` - 使用深度混合效应自编码器进行单细胞转录组学数据的可解释分析和批效应可视化——scMEDAL [PDF](https://arxiv.org/pdf/2411.06635), [HTML](https://arxiv.org/abs/2411.06635)
### Authors
Aixa X. Andrade,Son Nguyen,Austin Marckx,Albert Montillo
### Background
单细胞RNA测序能够实现细胞异质性的高分辨率分析，但消除批次效应（batch effects）以区分生物信号仍然是一大挑战。现有的批次校正算法往往会抑制或丢弃与批次相关的变异，而非建模这些变异。这使得通过批次效应准确解析生物学信息变得困难。
### Innovation
我们提出了一种名为scMEDAL的新框架，该框架使用两个互补子网络分别建模批次不变效应和批次特定效应。其中，scMEDAL-RE是一种随机效应贝叶斯自编码器，可以学习批次特定的表示同时保留与批次效应混杂的生物学相关信息，而scMEDAL-FE则通过对抗学习提供一种默认批次校正组件。这种框架在多种条件下（如自闭症、白血病、心血管）、细胞类型以及技术、生物学效应方面进行了评估，显示scMEDAL-RE能够生成可解释且包含批次特异性信息的嵌入，能够补充现有的校正方法（如scVI、Scanorama、Harmony、SAUCIE），并提高疾病状态、捐赠者组和组织预测的准确性。此外，scMEDAL还提供生成性可视化，能够推断出细胞在不同批次下的表达情况。
### Conclusion
scMEDAL是一个灵活、可解释的框架，能够补充现有校正方法，为细胞异质性和数据获取提供更深入的理解，同时提供改进的预测能力和可视化功能。
## 609. `cs.LG` - 针对灵长类视觉背侧流的优化任务模型的缩放定律 [PDF](https://arxiv.org/pdf/2411.05712), [HTML](https://arxiv.org/abs/2411.05712)
### Authors
Abdulkadir Gokce,Martin Schrimpf
### Background
当使用大规模物体分类数据集训练某些人工神经网络模型时，它们开始近似模拟灵长类大脑中核心的物体识别行为和神经响应模式。尽管最近的机器学习进展表明，扩展计算量、模型规模和数据集规模可提升任务表现，但对这种扩展对大脑匹配度的影响仍不明确。本研究通过系统地评估超过600个在控制条件下训练的模型，探讨这些模型对灵长类视觉背侧流的建模，评估了V1、V2、V4、IT和行为的多个基准，研究发现，在更大的模型中，行为对齐持续扩展，但神经对齐在某个点后趋于饱和，这一观察结果在不同的模型架构和训练数据集中保持一致。尽管具有更强归纳偏置的模型和具有高质量图像的数据集在计算效率上更高，但更多地增加规模尤其有益于更高水平的视觉区域，这些小模型在少量样本上训练时体现出极差的对齐。
### Innovation
本研究系统地评估了大量在控制条件下训练的模型，涵盖V1、V2、V4、IT以及行为的表现，确定了模型规模与行为对齐的关系，并发现了神经对齐达到饱和点的现象，这对于灵长类视觉背侧流的建模提供了新的见解。
### Conclusion
研究结果表明，尽管扩展当前的模型架构和数据集规模能够与人类核心物体识别行为实现对齐，但这并不足以提升对大脑视觉背侧流的建模。这强调了需要创新策略来构建大脑模型的必要性。
## 610. `cs.LG` - GASP：高效生成用于突破LLM障碍的对抗后缀 [PDF](https://arxiv.org/pdf/2411.14133), [HTML](https://arxiv.org/abs/2411.14133)
### Authors
Advik Raj Basani,Xiao Zhang
### Background
大语言模型（LLMs）在各种自然语言处理任务中展示了令人印象深刻的性能，但它们仍然容易受到精心设计的输入提示（称为囚笼攻击）的影响，这些攻击旨在绕过安全保护并引发有害响应。传统方法依赖于手动启发式方法，但这种方法在通用性方面存在局限性。尽管基于优化的攻击方法能够自动化过程，但它们通常生成的提示听起来不自然，这些提示可能会被安全过滤器轻易检测到，或者由于离散标记优化的高计算成本而需要大量计算资源。
### Innovation
本文介绍了一种名为生成对抗后缀提示器（GASP）的新型自动化框架，可在完全黑盒设置中高效生成可读的人类对抗后缀。GASP 使用潜在贝叶斯优化来通过高效探索连续潜在嵌入空间来构建对抗后缀，并通过带目标的迭代优化过程逐步优化后缀提示生成器，以提高攻击效果并保持提示的一致性。
### Conclusion
实验结果表明，GASP 能够生成自然的对抗后缀，显著提高了囚笼攻击的成功率，减少了训练时间，并加速了推理速度，从而使其成为对大语言模型进行红队测试的有效且可扩展的解决方案。
## 611. `cs.LG` - 一定程度的深度能产生深远影响：log-深度变换器的表达能力 [PDF](https://arxiv.org/pdf/2503.03961), [HTML](https://arxiv.org/abs/2503.03961)
### Authors
William Merrill,Ashish Sabharwal
### Background
近期理论结果表明，变换器无法表达长期输入的序列化推理问题，因为它们的计算深度是有限的。然而，此前的研究将深度视为一个常数，因此对于有限深度是否足以解决较短输入的问题，以及增加变换器的深度如何影响其表达能力，仍不清楚。这篇论文通过分析能够随上下文长度n增长的最小深度变换器，来探讨这些问题。
### Innovation
这篇论文展示了即使深度为$theta(text{log}n)$的高统一变换器也能表达两个重要问题：识别正则语言和图的连通性。这表明增长的深度能提供表达能力的好处，并且理论能够定量预测表达这些问题所需的深度增长量，指出深度放大比宽度扩展或思维链放大更高效。此外，实验结果显示，理论上的深度要求和实际训练成功的深度要求非常接近，这对于逐步推理的深度选择提供了实用指导。
### Conclusion
本研究澄清了深度如何影响变换器推理能力，并为选择适合序列推理的有效深度提供了实践经验。
## 612. `cs.LG` - 重返联邦微调：关键共享一轮即可 [PDF](https://arxiv.org/pdf/2412.04650), [HTML](https://arxiv.org/abs/2412.04650)
### Authors
Ziyao Wang,Bowei Tian,Yexiao He,Zheyu Shen,Guoheng Sun,Yuhan Liu,Luyang Liu,Meng Liu,Ang Li
### Background
近期基础模型（FMs）的进展增加了对大规模跨域数据集进行模型微调的需求。为了应对这一需求，联邦微调发现了新的应用场景。联邦微调允许将模型在多个设备上分布在多个数据集上的数据集上进行微调，同时保证数据隐私。然而，联邦学习算法中存在的大量参数和多轮通信导致了昂贵的通信成本，极大地阻碍了联邦微调的实际应用。
### Innovation
论文通过理论和实证分析表明，传统的多轮聚合算法可能并不是联邦微调大型FMs所必需的。实验结果表明，一次聚合（即一次通信轮次的联邦微调）可以达到与多轮聚合相同的全局模型性能。大型FMs在一次通信轮次微调时的训练损失显著低于较小的模型，一次通信轮次的联邦微调可以显著降低通信成本，同时具有异步聚合的潜力，增强了隐私性，并通过文本生成和文本到图像生成任务保持了与多轮联邦微调的一致性能。
### Conclusion
我们的发现为实践中的联邦微调提供了新的见解，提高了效率，减少了成本，扩展了FMs的适用性。
## 613. `cs.LG` - 在基础模型嵌入时代的多模态癌症建模 [PDF](https://arxiv.org/pdf/2505.07683), [HTML](https://arxiv.org/abs/2505.07683)
### Authors
Steven Song,Morgan Borjigin-Wang,Irene Madejski,Robert L. Grossman
### Background
The Cancer Genome Atlas (TCGA) 通过其协调的基因组、临床和影像数据使癌症研究方面取得了新的发现，并且为癌症研究提供了一个大规模的参考数据集。许多先前的研究已在TCGA数据上开发了定制的深度学习模型，用于诸如癌症生存预测等任务。尽管TCGA包含病理报告等自由文本数据，但这些数据通常使用不足。
### Innovation
本文提出了采用经典机器学习模型对多模态零样本基础模型嵌入进行癌症数据建模的方法。它展示了多模态融合的简便性和叠加效果，优于单一模态模型。此外，还展示了包含病理报告文本的优势，并且严格评估了基于模型的文本摘要和生成的效果。
### Conclusion
本文提出了一种以嵌入为中心的方法，用于多模态癌症建模，能够有效利用多种类型的数据，并且通过严格的模型验证显示了这些方法的有效性。
## 614. `cs.LG` - 优化算法中的记忆如何隐式修改损失函数 [PDF](https://arxiv.org/pdf/2502.02132), [HTML](https://arxiv.org/abs/2502.02132)
### Authors
Matias D. Cattaneo,Boris Shigida
### Background
在现代深度学习的优化方法中，每次更新都依赖于之前的迭代历史，通常被称为记忆。这种依赖随迭代次数的增加而迅速减小。例如，带有动量的梯度下降法通过指数加权平均过去的梯度来实现指数衰减的记忆。本文研究了一种通用技术，用于构建一个记忆无关的算法，该算法可以近似具有记忆依赖的优化算法。这种方法通过将所有过去的迭代替换为当前迭代，并添加一个来自记忆的修正项来实现。这一修正项可以被解释为对损失函数的扰动，其性质可以揭示内存如何隐式地正则化或反向正则化优化动力学。通过理论应用，研究表明Lion算法与其他具有类似性质的算法（如AdamW）相比，没有被记忆产生的反向正则化所影响，这为Lion表现出更好的泛化效果提供了理论解释。
### Innovation
提出了一个能够近似具有记忆依赖的优化算法的记忆无关算法。通过将所有过去的迭代替换为当前迭代，并添加一个源于记忆的修正项（可以视为对损失函数的扰动）来实现。这种方法能够揭示内存如何隐式地正则化或反向正则化优化动力学。
### Conclusion
Lion算法与含有类似性质的优化算法（如AdamW）相比，没有被记忆产生的反向正则化影响，从而解释了Lion的更好泛化性能。
## 615. `cs.LG` - 后嵌入线性化解释：基于个体潜在编码的可解释和可变体线性表示事后解释 [PDF](https://arxiv.org/pdf/2504.20667), [HTML](https://arxiv.org/abs/2504.20667)
### Authors
Simone Piaggesi,Riccardo Guidotti,Fosca Giannotti,Dino Pedreschi
### Background
事后可解释性对于理解黑盒机器学习模型至关重要。目前广泛使用的基于代理的技术虽然适用于局部和全局模型不可知的解释，但存在显著限制，如局部代理捕捉非线性但计算成本高且参数敏感，而全局代理虽然更有效但难以处理复杂的局部行为。
### Innovation
本文提出了ILLUME框架，该框架基于表示学习方法，并与各种代理模型兼容，以便为任何黑盒分类器提供解释。该方法结合了一个全局训练的代理模型和通过超编码器学习的实例特定线性变换，生成局部和全局解释。实证研究显示，ILLUME在生成符合黑盒模型的准确、稳健和忠实的特征贡献和决策规则方面表现出色，从而提供了一个统一的解释框架，有效解决了传统代理方法中的限制。
### Conclusion
ILLUME框架通过与不同代理模型结合，提供了可解释性和灵活的局部及全局解释，有效地弥补了传统代理方法的不足，在黑盒模型的解释性方面表现优异。
## 616. `cs.LG` - Quamba2：针对选择性状态空间模型的稳健且可扩展的后训练量化框架 [PDF](https://arxiv.org/pdf/2503.22879), [HTML](https://arxiv.org/abs/2503.22879)
### Authors
Hung-Yueh Chiang,Chi-Chih Chang,Natalia Frumkin,Kai-Chiang Wu,Mohamed S. Abdelfattah,Diana Marculescu
### Background
状态空间模型（SSMs）由于其一致的内存使用和高性能，正在成为Transformer的有吸引力替代方案。然而，由于其存储要求和计算能力限制，SSMs在扩展到云服务或资源受限的设备上仍具挑战性。虽然量化SSMs使用低位宽数据格式可以减少模型大小并受益于硬件加速，但量化过程可能会导致SSMs出现错误，因此需要优化以保持性能和效率。为了应对这些挑战，本文针对Mamba1和Mamba2两个底层架构提出了Quamba2量化框架，该框架可以适应W8A8、W4A8和W4A16等多种不同的位宽配置，以满足不同场景的需求。
### Innovation
本文提出了一个名为Quamba2的后训练量化框架，针对选择性状态空间模型进行了优化。其创新点包括：1) 一种基于输入排序和聚类的方法来量化线性递归的输入，以及针对输入依赖参数的逐状态组量化；2) 在不同状态下重新排列权重以确保计算不变性；3) 该方法在预填充和生成阶段分别提供1.3倍和3倍的加速，同时将内存减少4倍，平均精度损失仅为1.6%。此外，框架在MMLU上的评估显示了其广泛适用性和鲁棒性。
### Conclusion
研究展示了Quamba2量化框架在多种位宽配置下的优越性能，为选择性状态空间模型在不同平台上的部署提供了有效方法。该框架通过平衡计算效率和模型精度，实现了对存储和计算资源的有效利用，适用于需要资源受限环境下的实际应用。同时，通过开源代码和模型，促进了该领域的进一步研究和应用。
## 617. `cs.LG` - 正则化的最小二乘学习在重尾噪声下是最小imax最优的 [PDF](https://arxiv.org/pdf/2505.14214), [HTML](https://arxiv.org/abs/2505.14214)
### Authors
Mattes Mollenhauer,Nicole Mücke,Dimitri Meunier,Arthur Gretton
### Background
本文研究了在具有有限高阶矩的噪声环境中，核希尔伯特空间中的岭回归性能。在经典的积分算子框架基础上，得出了包含次高斯项和多项式项的过拟合风险界。在标准的特征值衰减条件下，这些结果证明了正则化最小二乘法在重尾噪声环境下的渐进稳健性。
### Innovation
本文的主要创新在于得出了在重尾噪声环境下正则化最小二乘法的最优风险界，该结果在以往的工作中仅在次指数噪声环境下被证明。这种结果的获得是基于Hilbert空间值随机变量的Fuk-Nagaev不等式。
### Conclusion
在标准的特征值衰减假设下，本文得出的过拟合风险界是渐进最优的。因此，正则化最小二乘法在面对重尾噪声时是渐进稳健的，证明了在有噪声的环境中，正则化方法的有效性。
## 618. `cs.LG` - 借助引导向量提供诚实替代方案以帮助LLM评委：你的诚实答案是什么？ [PDF](https://arxiv.org/pdf/2505.17760), [HTML](https://arxiv.org/abs/2505.17760)
### Authors
Leon Eshuijs,Archie Chaudhury,Alan McBeth,Ethan Nguyen
### Background
检测大型语言模型（LLMs）中的隐秘不诚实行为，如拍马屁和操控，对人类和自动化评估者都是具有挑战性的任务，因为这些行为往往通过小偏见而非明显错误表现出来。现有的评估方法大多依赖于黑盒评估，而无法有效利用模型内部信息来创建有针对性的比较。
### Innovation
引入了一种名为JUSSA（使用安全引导替代的评委使用框架）的新框架，其不直接改进模型行为，而是通过在推理过程中应用引导向量生成更诚实的替代方案，帮助评委更容易地检测到隐秘不诚实模式。通过创建基于单个示例的目标比较，JUSSA能够有效提高检测精度。
### Conclusion
研究表明，JUSSA在多种情况下都能有效提高检测准确性，尤其对于不同强度的评委在不同难度的任务上都显示出积极影响。实验证明，不诚实提示在模型中间层导致的表示差异可以有效指导生成对比示例。这表明引导向量可以用于增强安全性评估，而不仅仅是改变行为，为复杂系统中的可扩展模型审查开辟了新的方向。
## 619. `cs.LG` - 闭环环境中的RNN学习动力学 [PDF](https://arxiv.org/pdf/2505.13567), [HTML](https://arxiv.org/abs/2505.13567)
### Authors
Yoav Ger,Omri Barak
### Background
递归神经网络（RNNs）在经过神经科学启发的任务训练后能够提供强大的脑计算模型。然而，典型的训练方法依赖于开环、监督的设置，而真实世界的习总书记在闭环环境中展开。本研究发展了一个数学理论，描述了在闭环背景下训练的线性RNN的学习动力学。研究发现，即使两个看似相同的RNN，在闭环或开环环境下训练也会遵循截然不同的学习路径。这促使进一步研究闭环与开环情况下学习动力学的差异，以及它们与训练损失演变的关联。实验结果显示，闭环RNN的学习动态不仅受短期策略改进的影响，还受到长期行为稳定性的影响，这一过程与开环RNN完全不同。
### Innovation
开发了描述闭环环境下线性RNN学习动力学的数学理论，揭示了闭环RNN与开环RNN在学习路径上的显著差异。具体分析了闭环环境下RNN的学习动态，发现长时间行为稳定性是闭环学习的关键因素。提出了一个框架，将该理论应用于实际的运动控制任务，证明了其在更广泛领域的适用性。这一研究强调了在生物学上更加合理的设定中建模闭环动力学的重要性，为理解实际环境下的神经网络学习机制提供了新的视角。
### Conclusion
研究结果强调了对闭环动态建模的重要性，在生物学上更合理的环境中，揭示了闭环RNN和开环RNN学习动态的本质差异。这一理论为理解实际环境中的神经网络学习机制提供了潜在的价值，并有望为未来的生物启发式学习算法和应用提供指导。
## 620. `cs.LG` - 在扩散采样器的可扩展和高效训练方面 [PDF](https://arxiv.org/pdf/2505.19552), [HTML](https://arxiv.org/abs/2505.19552)
### Authors
Minkyu Kim,Kiyoung Seong,Dongyeop Woo,Sungsoo Ahn,Minsu Kim
### Background
在缺乏数据的情况下训练扩散模型以从非归一化能量分布中采样，面临的挑战是扩散采样器在复杂场景下的表现不佳，尤其是当能量评估代价高昂且采样空间高维时。现有的方法在面对这些挑战时表现不足。
### Innovation
提出了一种可扩展且样本效率高的框架，将强大的经典采样方法与扩散采样器结合。具体而言，使用带新颖性辅助能量的蒙特卡洛马尔可夫链（MCMC）采样器作为Searcher收集离策略样本，并通过辅助能量函数补足扩散采样器较少访问的模式探索。这些离策略样本与策略样本数据结合以训练扩散采样器，进而扩展其能量景观的覆盖范围。此外，还识别出优先偏差是训练过程中模式崩溃的主要原因，并引入周期性重新初始化技巧来解决这一问题。
### Conclusion
该方法在标准基准测试中显著提高了扩散采样器的样本效率，并且在更高维度的问题和真实世界分子构象生成方面表现优异。
## 621. `cs.LG` - 变换器如何学习隐式推理？ [PDF](https://arxiv.org/pdf/2505.23653), [HTML](https://arxiv.org/abs/2505.23653)
### Authors
Jiaran Ye,Zijun Yao,Zhidian Huang,Liangming Pan,Jinxin Liu,Yushi Bai,Amy Xin,Weichuan Liu,Xiaoyin Che,Lei Hou,Juanzi Li
### Background
近期研究指出，大型语言模型（LLMs）可以在不显式表达中间步骤的情况下进行多跳推理并给出正确答案，但其潜在机制仍然不甚明了。本文通过在受控的符号环境中从零开始训练变换器，研究了这种隐式推理的产生机制。
### Innovation
研究发现，LMs在多步推理中存在三个发展阶段：早期记忆、同分布泛化以及跨分布泛化。进一步研究发现，训练中使用原子三元组并非必要，但却能加速学习过程；二步泛化依赖于查询层面特定组合结构的暴露。为此，引入了两种诊断工具：跨查询语义修补和基于余弦的表示性探针，揭示了成功推理与隐空间中余弦相似性簇的关系。
### Conclusion
这些发现为理解隐式多跳推理的可解释性提供了新的见解，帮助阐明LMs中的复杂推理过程的内部展开方式，并为提高这些模型的透明度提供了途径。
## 622. `cs.LG` - Mustafar: 促进LLM推理中KV缓存剪枝的无结构稀疏性 [PDF](https://arxiv.org/pdf/2505.22913), [HTML](https://arxiv.org/abs/2505.22913)
### Authors
Donghyeon Joo,Helya Hosseini,Ramyad Hadidi,Bahar Asgari
### Background
LLM解码性能的主要瓶颈在于缓存占用的高内存开销，尤其是在长上下文长度的情况下。当前的KV缓存压缩通常依赖于结构化稀疏性，但在保持准确性的同时进行剪枝和压缩可能需要大量的调优工作。
### Innovation
该研究展示了无结构稀疏性显著提高了KV缓存压缩，允许高达70%的稀疏性而不影响准确性或需要微调，实现了Key和Value缓存的高效剪枝策略，特别是提出了一种基于Token幅度的剪枝方法，该方法在无结构稀疏性下既适用于Key缓存，也适用于Value缓存，后者即使其分布较为均匀也表现出色。通过使用位图为基础的稀疏格式和自定义的注意力核函数，能够压缩并直接在压缩缓存上进行计算，极大地加速了解码计算中的内存受限操作。
### Conclusion
通过自定义注意力核函数和位图为基础的格式，实现了KV缓存高达45%的压缩比，从而使得上下文长度更长并且吞吐量提高了2.23倍，相较于密集推理有了显著的提升。剪枝机制和稀疏注意力核函数已公开提供。
## 623. `cs.LG` - 重新审视关键批量大小：一种简单经验主义方法以实现大规模语言模型训练 [PDF](https://arxiv.org/pdf/2505.23971), [HTML](https://arxiv.org/abs/2505.23971)
### Authors
William Merrill,Shane Arora,Dirk Groeneveld,Hannaneh Hajishirzi
### Background
在大规模训练语言模型时，正确的批量大小至关重要：较大批量能够加快训练速度，但过大则会影响标记效率。McCandlish等人（2018）建议，可以基于训练中的梯度噪声尺度估计一个关键批量大小（CBS），在该大小以下，训练对损失影响不大。尽管该方法已被实践采用，例如在训练GPT-3时，但其对于梯度噪声作为CBS代理的假设较为薄弱，从而导致其在实践中可信度有待验证。
### Innovation
本文提出了一种简单的经验主义方法直接测量CBS，并展示了CBS随训练过程的变化情况。通过在OLMo模型上应用该方法，研究发现了不同模型规模（1B和7B）下CBS的变化趋势一致，即初始化时接近0，开始快速增加，然后随着训练进展趋于稳定。此外，该研究还表明可通过批量大小预热方法可靠地在大规模批量大小下训练语言模型，即从较小批量开始，随着CBS增长逐步增加批量大小。
### Conclusion
通过批量大小预热方法，研究使用较小批量训练至较小损失，较原有43%更少的梯度步骤达到更优性能，验证了该方法在大规模批量下训练语言模型的有效性，从而增加了数据并行性同时不损害性能。
## 624. `cs.LG` - Shifted-Dynamics 数据条件流匹配的复合流方法 [PDF](https://arxiv.org/pdf/2505.23062), [HTML](https://arxiv.org/abs/2505.23062)
### Authors
Lingkai Kong,Haichuan Wang,Tonghan Wang,Guojun Xiong,Milind Tambe
### Background
现有的强化学习（RL）方法在利用预收集的离线数据时，可以显著提高样本效率，但通常受到源环境和目标环境之间转换动态差异的挑战。现有的方法通常通过惩罚或过滤源数据在高动态差距区域的转换来解决这一问题，但它们通常基于Kullback-Leibler（KL）散度或互信息来估计动态差距，这在源环境和目标环境动态不交集时可能不明确。
### Innovation
提出了CompFlow方法，该方法基于流匹配和最优传输之间的理论联系。具体来说，CompFlow将目标动力学建模为基于源域流输出分布的条件流，而不是直接从高斯先验学习它。这种方法有两个关键优点：（1）提高学习目标动力学的一般性；（2）通过源和目标转换之间的Wasserstein距离获得动态差距的原理性估计。CompFlow引入了一种乐观的主动数据收集策略，优先探索高动态差距区域，并理论证明这种策略可以减少与最优策略的性能差异。实验证明，CompFlow在多个具有移位动态数据的RL基准测试中优于强基线。
### Conclusion
CompFlow通过利用原则性估计的动态差距，提出了一种综合流方法来提高强化学习中转移动态不匹配数据的样本效率。该方法有机地结合了预收集的离线数据的优点，同时解决了传统方法在处理动态差距估算不明确的挑战。
## 625. `cs.LG` - 含有填充标记的Transformer的确切表征能力 [PDF](https://arxiv.org/pdf/2505.18948), [HTML](https://arxiv.org/abs/2505.18948)
### Authors
William Merrill,Ashish Sabharwal
### Background
长短期记忆网络（LLMs）中的因果解码会影响推理阶段的计算能力。研究人员探索了不增加参数数量的情况下扩展Transformer表达能力的替代方法，比如使用填充标记进行并行计算。尽管Transformer上限为$?mathsf{TC}^0$类的问题，但证明其下限一直是个难题。在本文中，作者引入了新的技术分析填充Transformer，证明了带有寒武纪常数次循环输入长度为$n$的填充Transformer能够准确识别$?mathsf{FO}$-uniform $?mathsf{TC}^d$类的适中可并行化问题。此外，通过填充标记和循环控制，两种方式相结合可以系统性地提高Transformer的表达能力，使用多项式对数次数的循环，能够在不损失并行性能的前提下全面表达$?mathsf{FO}$-uniform $?mathsf{NC}$类问题，这是在不牺牲效率的情况下最好能达到的效果（除非$?mathsf{NC} = ?mathsf{P}$）。这些结果推动了填充标记和循环作为检查阶段计算中的可并行化替代方法的研究。
### Innovation
引入了新的技术分析含有填充标记的Transformer，证明了带有寒武纪常数次循环输入长度为$n$的填充Transformer能够准确识别$?mathsf{FO}$-uniform $?mathsf{TC}^d$类的适中可并行化问题。作者证明，通过填充标记和循环控制，两种方式相结合可以系统性地提高Transformer的表达能力，使用多项式对数次数的循环，能够在不损失并行性能的前提下全面表达$?mathsf{FO}$-uniform $?mathsf{NC}$类问题，这是在不牺牲效率的情况下最好能达到的效果（除非$?mathsf{NC} = ?mathsf{P}$）。
### Conclusion
通过填充标记和循环控制相结合的方式，系统性地提高了Transformer的表达能力，证明了多项式对数循环的填充Transformer能够全面表达$?mathsf{FO}$-uniform $?mathsf{NC}$类问题，而无需牺牲并行性能，从而推动了进一步研究填充标记和循环作为检查阶段计算中的可并行化替代方法。
## 626. `cs.LG` - 神经隐式采样器的Bernstein基凸散度下的显式密度近似 [PDF](https://arxiv.org/pdf/2506.04700), [HTML](https://arxiv.org/abs/2506.04700)
### Authors
José Manuel de Frutos,Manuel A. Vázquez,Pablo M. Olmos,Joaquín Míguez
### Background
近年来，基于秩的统计度量，如不变统计损失(ISL)，已被证明是一种稳健且实用的工具，用于训练隐式生成模型。本文在ISL框架下提出了dual-ISL，一个新颖的无似然训练隐式生成模型的目标函数，通过互换目标分布和模型分布的角色，得到一个模型密度空间上的凸优化问题。
### Innovation
本文开发了一个理论框架，将dual-ISL解释为密度比$q = p/tilde p$在Bernstein多项式基上的$L^2$投影，从中推导出截断误差的确切界限、精确的收敛速率和截断密度近似式的闭式表达。此外，通过随机一维投影扩展分析到多元设置，定义了一个保持凸性和连续性的sliced dual-ISL散度。
### Conclusion
实验结果表明，这些理论优势转化为实际优势。在多个基准测试中，dual-ISL收敛更快，提供更为平滑和稳定的训练，更有效地防止了模式坍缩，同时提供了显式的密度近似，优于经典的ISL和其他领先的方法。
## 627. `cs.LG` - HELM: 混合曲率专家的双曲大型语言模型 [PDF](https://arxiv.org/pdf/2505.24722), [HTML](https://arxiv.org/abs/2505.24722)
### Authors
Neil He,Rishabh Anand,Hiren Madhu,Ali Maatouk,Smita Krishnaswamy,Leandros Tassiulas,Menglin Yang,Rex Ying
### Background
大型语言模型（LLMs）已经在跨领域文本建模任务中取得了巨大成功。然而，自然语言本质上包含语义层次结构和微妙的几何结构，当前的LLMs由于依赖欧几里得操作，未能完全捕捉这些特性。最近的研究显示，不尊重标记嵌入的几何结构会导致训练稳定性问题和生成能力下降。研究结果表明，转向非欧几里得几何可能更好地使语言模型与文本的内在几何结构相一致。
### Innovation
本文提出了一种完全在双曲空间中操作的方法，双曲空间因其扩展性、无尺度性和低失真性而著称。因此，作者提出了HELM（HypErbolic Large Language Models）系列模型，这是一种基于Transformer的语言模型的几何再思考方式，解决了现有模型在表示灵活性、缺失必要操作和可扩展性方面的局限性。此外，还引入了HELM-MICE（混合曲率专家模型）模型，通过在不同的曲率空间中操作每个专家来编码更多的几何结构；以及HELM-D（密集模型）模型，在确保准确表达的同时提高了模型的密度。此外，还发展了HMLA（Hyperbolic Multi-Head Latent Attention），提高了大规模训练和推理过程中的效率。
### Conclusion
本文是首个在亿参数规模训练完全双曲大型语言模型的工作，并在涵盖STEM问题解决、一般知识和常识推理等多个领域的基准测试（如MMLU和ARC）上展示了HELM架构的成效，提升了多达4%的性能，证实了双曲几何在大规模语言模型预训练中提供的有效性和增强的推理能力。
## 628. `cs.LG` - 打破数据孤岛：通过生成性持续学习构建开放和可扩展的移动基础模型 [PDF](https://arxiv.org/pdf/2506.06694), [HTML](https://arxiv.org/abs/2506.06694)
### Authors
Yuan Yuan,Yukun Liu,Chonghua Han,Jie Feng,Yong Li
### Background
基础模型已经在自然语言处理和计算机视觉等领域取得了革命性进展，通过在多样化任务和数据集上进行通用学习。然而，构建类似的基础模型来模拟人类移动模式仍然充满挑战，因为移动数据的隐私敏感性导致不同机构之间的数据孤岛。由于这些数据孤岛的存在，现有的建模方法无法将不同来源的数据有效地整合在一起。
### Innovation
该论文提出了MoveGCL，一种通过生成性持续学习来训练移动基础模型的可扩展且保护隐私的框架。MoveGCL可以在不共享原始数据的情况下，通过回放由冻结教师模型生成的合成轨迹来实现去中心化且进步的模型进化，通过定制的蒸馏策略有效缓解灾难性遗忘。此外，MoveGCL还采用了与移动模式相关的专家路由机制和层级渐进适应策略来提高稳定性。实验结果表明，MoveGCL相较于联合训练的性能不劣，并显著优于联邦学习基线，同时提供了强大的隐私保护。
### Conclusion
MoveGCL代表了为移动领域解锁基础模型的重要一步，为开放、可扩展和保护隐私的基础模型在基础模型时代的发展提供了一个实际的蓝图。为促进研究的可复制性，该论文已发布了相关的代码和模型。
## 629. `cs.LG` - 工业碳排放的深图学习及其政策影响 [PDF](https://arxiv.org/pdf/2507.02912), [HTML](https://arxiv.org/abs/2507.02912)
### Authors
Xuanming Zhang
### Background
工业碳排放是气候变化的主要驱动因素之一，但由于多种因素之间的多重共线性以及不同部门和时间间的复杂相互依赖关系，对其进行建模具有挑战性。我们的研究基于此背景，旨在通过一种新颖的图基深度学习框架DGL来分析和预测工业CO2排放情况，以解决高特征相关性和捕捉工业-时间相互依赖性的问题。
### Innovation
我们提出了一个基于图的深度学习框架DGL，该框架使用图神经网络（GNN）通过注意力机制建模行业（或区域）间的关系，并通过时间变换器学习长程模式，从而解决了共线性问题并整合因果推理来确定碳排放的真实驱动因素，提高了透明度和公平性。此外，该模型的预测性能优越，相比基线深度模型，其预测误差降低了15%以上，同时保持了可解释性并通过注意力权重和因果分析实现。
### Conclusion
我们是第一个通过结构化编码特征关系并结合因果推理来解决共线性的图-时间架构。该研究表明，通过这种先进的AI图学习方法，可以指导针对可持续发展目标的部门特定减排策略，并为政策制定者和行业利益相关者提供实现碳减排目标的有力工具。我们还展示了高排放热点区域，并建议了公平干预计划，体现了先进AI图学习方法在气候行动中的潜力。
## 630. `cs.LG` - 使用SparseLoCo在通信受限条件下进行高效的大语言模型预训练 [PDF](https://arxiv.org/pdf/2508.15706), [HTML](https://arxiv.org/abs/2508.15706)
### Authors
Amir Sarfi,Benjamin Thérien,Joel Lidin,Eugene Belilovsky
### Background
由于其在带宽受限环境下（如数据中心间和互联网上）训练大型语言模型（LLMs）的优势，高效的分布式训练算法受到了广泛关注，这些算法旨在减少通信频率。然而，尽管减少了通信频率，这些方法仍然通常需要传输模型完整梯度的拷贝，这导致即使是跨数据中心连接也会出现通信瓶颈，从而对性能产生轻微的负面影响。量化是减少伪梯度大小的常用方法，但在大语言模型的预训练上下文中，现有的方法很难利用稀疏化技术并获得有限的量化效果。
### Innovation
本文引入了SparseLoCo，这是一种在LLMs上高效利用错误反馈加Top-k稀疏化和2比特量化以达到极端稀疏度（低至1-3%）的通信高效训练算法，同时超过了全精度DiLoCo。主要创新点在于外层动量可以在本地通过错误反馈累加器与激进稀疏化相结合进行近似，并且稀疏聚合实际上可以提高模型性能。
### Conclusion
实验结果表明，在多种通信受限条件下进行大语言模型训练时，SparseLoCo在性能和通信成本方面提供了显著的优势。
## 631. `cs.LG` - 在大型语言模型中实现临界学习以应用于量子场论及其他领域 [PDF](https://arxiv.org/pdf/2506.03703), [HTML](https://arxiv.org/abs/2506.03703)
### Authors
Xiansheng Cai,Sihan Hu,Tao Wang,Yuan Huang,Pan Zhang,Youjin Deng,Kun Chen
### Background
基础物理经常面临复杂符号问题，缺乏指导性的实例或成熟的原理。尽管人工智能（AI）具有潜力，但其通常需要大量数据才能学习，这在信息稀缺的前沿限制了其应用。本研究旨在通过引入学习临界性（LaC）——一种强化学习（RL）方法，调节大型语言模型（LLMs）至尖锐的学习转变，解决信息稀缺性问题。在这种过渡点，LLMs能够从少量数据中实现最佳泛化，以七进制七位数加法为例进行展示，这是非平凡算术推理的考验。此外，通过一个简化概念网络模型（CoNet）来解释这一高峰表现，这种模型也经受了尖锐的学习转变，并表现出二次相变的特征，显示出关键性思考模式，这对泛化至关重要。在量子场论中，利用LaC调整单一样例训练的8B参数LLM，解决了未见过的高阶问题，显著优于更大的模型。这表明LLMs在临界点运行时性能最佳，由此种探索性动态使得它们能够提取底层操作规则。
### Innovation
提出了一种名为学习临界性（LaC）的强化学习方案，该方案通过调节大型语言模型至尖锐学习过渡点，以解决信息稀缺问题。这种过渡点使模型能够从少量数据中实现最佳泛化。CoNet模型被用来验证这一理论，并通过单个样例训练也展示了类似的行为。此外，该研究证明了LaC在量子场论中的应用，通过少量实例训练的8B参数大型语言模型，成功解决未见过的高阶问题，显著优于更大规模的模型。这展示了学习临界性利用物理原理为复杂、数据稀少挑战提供AI解决方案的潜力。
### Conclusion
通过学习临界性（LaC）方法，揭示了大型语言模型在特定信息稀缺的物理挑战中所能达到的最优性能，表明通过在临界点操作，可以最大化模型的探索性动态能力，从而有效地提取潜在的操作规则。此外，该方法在量子场论中取得了显著的成果，展示了其在复杂问题解决中的潜在应用价值。
## 632. `cs.LG` - GENIAL: 通过网络反转进行生成性设计空间探索以实现低功耗算法逻辑单元 [PDF](https://arxiv.org/pdf/2507.18989), [HTML](https://arxiv.org/abs/2507.18989)
### Authors
Maxence Bouvier,Ryan Amaudruz,Felix Arnold,Renzo Andri,Lukas Cavigelli
### Background
随着AI工作负载的增长，优化算术单元对于减少数字系统足迹变得越来越重要。传统的设计流程往往依赖于手动或启发式优化，这种方法在彻底探索设计空间方面是有限的。因此，本文提出了一个基于机器学习的框架GENIAL，该框架能够自动生成和优化算术单元，重点是乘法器。GENIAL的核心是一个经过两阶段训练的变换器基础的代理模型，首先进行自我监督的预训练，随后进行监督微调，以从抽象的设计表示中准确预测诸如功耗和面积等关键硬件指标。通过反转代理模型，GENIAL高效地搜索新的操作数编码，直接减少特定输入数据分布下的算术单元的功耗。大量实验数据显示，与其它方法相比，GENIAL在样本效率和收敛速度上更有优势，这使高要求的逻辑综合优化流程能够纳入，进而提高代理模型的准确性。值得注意的是，GENIAL能够自动发现与传统补码相比可实现18%开关活动节省的设计编码。此外，作者还展示了其方法在状态机上的显著改进，突显了GENIAL在多种逻辑功能上的适用性。
### Innovation
GENIAL框架通过两阶段训练的变换器基础代理模型，能够从抽象设计表示中准确预测关键硬件指标，确保了设计的鲁棒性和效率。通过利用逆向代理模型进行操作数编码的优化搜索，直接减少了乘法器等单元的功耗。与传统设计方法相比，GENIAL能够自动发现更优的设计编码，显著节省了功耗，并适用于多种逻辑功能。
### Conclusion
这些进步标志着自动化高质量结果优化组合电路生成在数字系统中的一个重要进展。GENIAL框架的提出，不仅提升了低功耗算法逻辑单元的设计效率，还展示了其广泛的适用性，为其在更广泛的逻辑函数中的应用铺平了道路。
## 633. `cs.LG` - SolarCrossFormer: 通过整合卫星图像和地面传感器提高日预报太阳能辐射 [PDF](https://arxiv.org/pdf/2509.15827), [HTML](https://arxiv.org/abs/2509.15827)
### Authors
Baptiste Schubnel,Jelena Simeunović,Corentin Tissier,Pierre-Jean Alet,Rafael E. Carrillo
### Background
需要准确的大规模太阳能光伏系统（PV）并入电网的预测，但当前预测方案在时间和空间分辨率上无法满足系统运营商的需求。
### Innovation
提出了一种新型的深度学习模型SolarCrossFormer，结合卫星图像和地面气象站的时间序列数据，使用新颖的图卷积神经网络来利用输入数据的跨模态和同模态相关性，提高预测的准确性和分辨率。SolarCrossFormer可以在24小时内每15分钟生成瑞士任何地点的概率预测，并在实际操作中表现稳定，能够纳入新的时间序列数据而不需重新训练模型。
### Conclusion
实验结果显示，SolarCrossFormer在预测viar上一年和瑞士127个地点的数据后，平均绝对误差为6.1％，与商业数值气象预测服务取得的结果相当。
## 634. `cs.LG` - Test-Time Warmup for Multimodal Large Language Models [PDF](https://arxiv.org/pdf/2509.10641), [HTML](https://arxiv.org/abs/2509.10641)
### Authors
Nikita Rajaneesh,Thomas Zollo,Richard Zemel
### Background
尽管多模态大型语言模型（MLLMs）在文本和图像交叉推理中展现了巨大的潜力，但目前尚未充分实现这一潜力。现有的MLLMs通常由一个语言模型（LLM）、一个视觉编码器和一个将视觉编码器的嵌入映射到LLM文本嵌入空间的连接器构成。尽管各组件都经过大规模数据集（数亿样本）的预训练，整个多模态模型通常只在几千（或数百万）样本上进行训练，导致在复杂推理任务上表现较弱。
### Innovation
本文提出了一种测试时预热方法（Test-Time Warmup），该方法通过利用弱监督辅助任务的数据来适应每个测试实例的MLLM，而不是依靠广泛的标记数据集进行微调。使用该方法，我们在Llama-Vision-Instruct模型上观察到相对性能提升：在MMMU上为4.03%，在VQA-Rad上为5.28%，在GQA上为1.63%。
### Conclusion
我们的方法证明了，在推理前进行‘预热’可以增强MLLMs在多样化推理任务中的鲁棒性。
## 635. `cs.LG` - 潜在学习： episodic 记忆通过使经验的灵活重用成为可能来补充参数学习 [PDF](https://arxiv.org/pdf/2509.16189), [HTML](https://arxiv.org/abs/2509.16189)
### Authors
Andrew Kyle Lampinen,Martin Engelcke,Yuxuan Li,Arslan Chaudhry,James L. McClelland
### Background
当机器学习系统在泛化时出现问题，其原因之一可能在于缺乏潜在学习能力——即学习对于当前任务无关但对未来任务可能有用的信息。本文通过借鉴认知科学的观点，探讨了参数机器学习系统中的一个弱点，并展示了这一视角如何关联到语言模型和基于代理的导航中的多种失败现象。
### Innovation
本文提出，通过利用 episodic 记忆，机器学习系统可以更灵活地重用先前的经验来提高泛化能力。研究还强调了将检索机制与参数学习结合使用的重要性，以及内在上下文学习在获取跨检索经验使用信息的能力中的关键作用。
### Conclusion
研究结果表明，参数机器学习系统相较于自然智能在数据利用效率上的相对不足可能是潜在学习能力不足所导致的。该研究通过讨论认知科学和神经科学中的相关研究成果，进一步探讨了检索方法如何助力参数学习，以改进泛化能力，提供了关于潜在学习机制及其对机器学习领域潜在影响的见解。
## 636. `cs.LG` - 一种用于预测疫情期间心血管疾病生物标志物的多目标贝叶斯变换器框架 [PDF](https://arxiv.org/pdf/2509.01794), [HTML](https://arxiv.org/abs/2509.01794)
### Authors
Trusting Inekwe,Winnie Mkandawire,Emmanuel Agu,Andres Colubri
### Background
COVID-19大流行扰乱了全球的医疗体系，特别是对心血管疾病（CVD）等慢性病患者影响尤为严重。这种扰乱导致了延缓护理和行为改变，从而影响了关键的CVD生物标志物，如低密度脂蛋白胆固醇（LDL-C）、糖化血红蛋白A1c（HbA1c）、体质指数（BMI）和收缩压（SysBP）。准确建模这些变化对预测疾病进展和指导预防护理至关重要。然而，以前的研究没有利用机器学习（ML）从电子健康记录（EHRs）中进行多目标预测，同时捕捉生物标志物之间的依赖性、时间模式以及预测不确定性。
### Innovation
该论文提出了一种基于预训练的BERT变换器框架的多目标贝叶斯变换器（MBT-CB），用于从EHR数据联合预测LDL-C、HbA1c、BMI和SysBP等CVD生物标志物。该模型利用贝叶斯变分推理来估计不确定性，并通过嵌入捕捉时间关系，通过DeepMTR模型捕捉生物标志物之间的关系。评估结果表明，MBT-CB在新冠肺炎疫情期间来自马薩诸塞州中部的3390个CVD患者记录（304名独特患者）的回顾性EHR数据上优于各种基线模型，包括其他基于BERT的ML模型，达到了MAE为0.00887，RMSE为0.0135和MSE为0.00027，有效地捕捉了数据和模型不确定性、患者生物标志物关系以及时间动态。
### Conclusion
MBT-CB的出色表现展示了其在疫情期间改善CVD生物标志物预测和支持临床决策方面的潜力。
## 637. `cs.LG` - 通过社交科学研究中的LLM微调进行人类行为预测 [PDF](https://arxiv.org/pdf/2509.05830), [HTML](https://arxiv.org/abs/2509.05830)
### Authors
Akaash Kolluri,Shengguang Wu,Joon Sung Park,Michael S. Bernstein
### Background
大规模语言模型（LLMs）为模拟社会科学研究中的结果提供了强大的机遇。本文展示了直接对过去实验中的个体水平响应进行微调可以显著提高这些模拟的准确性，涵盖多种社会科学领域。通过构建包含290万响应的数据集SocSci210，本文研究了通过微调大规模语言模型实现不同水平泛化的可能性。研究发现，在完全未见的研究中，微调后的最佳模型Socrates-Qwen-14B比基线模型（Qwen2.5-14B）在不同条件下人类响应的分布一致性提高了26%，且优于GPT-4o。此外，通过在研究的子条件集上进行微调，新的未见条件下的泛化表现尤为 robust，提高了71%。由于SocSci210包含丰富的 demographic 信息，模拟能够在减少偏见方面（通过微调）显著减少 10.6%。这表明大规模语言模型在社会科学研究中的微调可用于更准确地模拟实验假设筛选。
### Innovation
本文通过自动管道构建了一个包含290万响应的SocSci210数据集，展示了对其他研究中的个体水平响应进行微调，可以显著提高模拟的准确性，特别是在未见研究和新条件下泛化的表现。研究发现，Socrates-Qwen-14B在完全未见的研究中比基线模型和GPT-4o更适合，准确度提高了26%；在特定条件的微调下，泛化能力提高了71%；同时，也通过减少偏见使得模拟结果更加公平。
### Conclusion
由于社会科学研究领域经常产生丰富且特定主题的数据集，本研究的成果表明在这些数据上进行微调可以更准确地模拟实验假设，这为提高模拟准确性和研究的社会科学性质提供了重要途径。所有数据、模型和微调代码都可以在给定的网址获得。
## 638. `cs.LG` - CancerGUIDE：利用内部分歧估计进行癌症指南理解 [PDF](https://arxiv.org/pdf/2509.07325), [HTML](https://arxiv.org/abs/2509.07325)
### Authors
Alyssa Unell,Noel C. F. Codella,Sam Preston,Peniel Argaw,Wen-wai Yim,Zelalem Gero,Cliff Wong,Rajesh Jena,Eric Horvitz,Amanda K. Hall,Ruican Rachel Zhong,Jiachen Li,Shrey Jain,Mu Wei,Matthew Lungren,Hoifung Poon
### Background
国家综合癌症网络（NCCN）提供了基于证据的癌症治疗指南。将复杂的患者陈述转化为符合指南的治疗建议耗时且需要特殊的专业知识，并且容易出错。大型语言模型（LLM）的进步有可能减少生成治疗建议所需的时间并提高准确性。本文提出了一种基于LLM代理的方法，自动为非小细胞肺癌（NSCLC）患者生成符合指南的治疗路径。该方法包括构建一个包含临床会诊、诊断结果和医疗历史的新颖纵向数据集，由专科肿瘤学家专家标注相应的NCCN指南路径；展示了现有LLM具备领域特定的知识，能够生成高质量的代理基准以用于模型开发和评估，显示出与专家标注基准的强烈相关性；开发了一种结合昂贵的人工标注与模型一致性信息的混合方法，构建了一个既可以预测相关指南又能验证治疗建议准确性的元分类器，并通过校准的置信分数（AUROC=0.800）确保了输出的准确性，支撑了性能的权衡和监管合规，从而建立了权衡准确性、可解释性和监管要求的临床可行的LLM基于指南遵循系统，降低了标注成本，提供了一条自动化的临床决策支持可扩展途径。
### Innovation
开发了一种利用新型纵向数据集构建的基于LLM代理的自动生成符合NSCLC患者治疗路径的方法，展示了现有的LLM拥有领域特定知识的优势，能够生成高质量的代理基准以用于模型开发和评估。通过结合昂贵的人工标注与模型一致性信息开发了混合方法，不仅预测了相关指南，还通过校准的置信分数验证了治疗建议的准确性。这种方法为满足临床需求的LLM基于指南遵循系统提供了框架，平衡了准确性和可解释性，适应了监管要求，并减少了标注成本，提供了一条自动化的临床决策支持的可扩展途径。
### Conclusion
本文建立了基于LLM的指南遵循系统的临床可行性框架，该框架在提高准确性、可解释性和满足监管要求的同时降低了标注成本，提供了一条可行的自动化的临床决策支持途径。
## 639. `cs.LG` - 大型语言模型在胎儿监测分析中超越领域特定架构 [PDF](https://arxiv.org/pdf/2509.18112), [HTML](https://arxiv.org/abs/2509.18112)
### Authors
Sheng Wong,Ravi Shankar,Beth Albert,Gabriel Davis Jones
### Background
孕前电子胎儿监测（EFM）和卡轩图（CTG）分析目前主要依赖于领域特定模型，但鲜有研究将现代基础模型或语言模型应用于这些任务。尽管基础模型和语言模型已经在多个领域展示了跨学科的泛化能力，但它们在CTG分析中的潜力尚未得到充分探索。
### Innovation
本研究首次全面评估了最先进的架构在自动产前CTG分类中的表现。通过统一的框架对超过2500个20分钟的记录进行了评估，涉及15种覆盖领域特定、时间序列、基础模型和语言模型类别的模型。研究发现，微调后的大型语言模型在数据可用性不同场景下持续优于基础和领域特定模型，但在宫缩活动信号缺失的情况下，领域特定模型显示了更高的鲁棒性。这些性能改进需要显著更高的计算资源。
### Conclusion
研究结果表明，尽管微调后的大型语言模型在CTG分类中达到了最新的技术水平，但在实际部署时必须在性能与计算效率之间权衡。
## 640. `cs.LG` - HyperAdapt: 简单高秩适应 [PDF](https://arxiv.org/pdf/2509.18629), [HTML](https://arxiv.org/abs/2509.18629)
### Authors
Abel Gurung,Joseph Campbell
### Background
基础模型在多种任务中表现出色，但将其应用于特定应用通常需要微调，这涉及大量内存和计算资源。参数高效的微调（PEFT）方法通过仅更新少量权重来缓解这一问题。本文探讨了HyperAdapt，这是一种与目前最先进的方法如LoRA相比显著减少可训练参数数量的参数高效微调方法。具体来说，HyperAdapt通过在预训练权重矩阵上应用行和列的缩放矩阵，以对角矩阵的形式调整预训练权重矩阵，实现高秩更新，只需一个n×m矩阵的n+m个可训练参数即可。
### Innovation
HyperAdapt通过使用行和列的缩放矩阵在预训练权重矩阵上进行调整，实现了高秩更新，同时使用了非常少的可训练参数数量。理论研究得出了HyperAdapt更新的上界秩，实证结果表明它在各个模型层上能一致地产生高秩变换。
### Conclusion
HyperAdapt在GLUE、算术推理和常识推理基准上，即使在超大规模模型（至多140亿参数）上，也能达到与完全微调和最新的PEFT方法相当或接近的性能，而使用的可训练参数数量则仅为其一个数量级或多个数量级的更少。
## 641. `cs.LG` - 集成序列和关系模型的用户事件整合：数据集和预测任务 [PDF](https://arxiv.org/pdf/2510.11903), [HTML](https://arxiv.org/abs/2510.11903)
### Authors
Rizal Fathony,Igor Melnyk,Owen Reinert,Nam H. Nguyen,Daniele Rosa,C. Bayan Bruss
### Background
用户事件建模在许多机器学习应用中起着重要作用，涵盖电子商务、社交媒体、金融和网络安全等领域。用户事件可以大致分为个人事件和关系事件，分别涉及个人行为和两个用户之间的交互。目前，这两种类型的事件通常使用基于序列的方法和基于图的方法分开建模。尽管现实世界系统需要同时捕捉这两种类型，但过往研究普遍在这方面存在不足。主要原因在于，人们倾向于用单一的模型表示用户行为，比如序列或图。为解决这一问题，需要提供明确集成个人和关系事件的数据集和预测任务。
### Innovation
该研究首次提出了一组同时考虑用户事件和关系事件的公共数据集和预测任务，并提出了一种统一的建模形式化方法。实验证明，同时采用这两种事件模型对提高建模效果有益，并表明当前方法还存在一定的改进空间。
### Conclusion
研究表明，当前方法在整合用户事件建模方面仍存在提升空间。因此，研究团队发布了这些资源以支持进一步的统一用户事件建模研究。
## 642. `cs.LG` - Deep Edge Filter: 回归人工设计层在深度学习中的深度边缘滤波 [PDF](https://arxiv.org/pdf/2510.13865), [HTML](https://arxiv.org/abs/2510.13865)
### Authors
Dongkwan Lee,Junhoo Lee,Nojun Kwak
### Background
该论文的背景在于现有深度神经网络在提取和利用特征时存在一定的局限性。网络倾向于存储特定领域的偏差在低频特征中，而任务相关的语义信息则主要包含在高频成分中。因此，通过运用高通滤波技术，作者希望分离出更通用且有效的特征表示。实验结果表明，无论模型架构和数据模态如何，该方法均能带来一致的性能提升，证实了高频特征对于模型泛化能力的重要性。
### Innovation
该论文提出的 Deep Edge Filter 是一种创新性方法，采用了高通滤波技术对深度神经网络特征进行处理，以提升模型的泛化能力。该方法通过从原始特征中减去低通滤波后的输出，有效地分离出一般化表征，同时保持模型架构的完整性。实验结果验证了该方法对不同领域的广泛适用性，并明确了高频特征对于模型泛化的重要性。
### Conclusion
实验结果和分析表明，该方法可以在多种领域和多种模型架构下提升模型的泛化性能，并且能够有效抑制特征的冗余，突出高频特征的重要性。作者还强调了该方法对于回归人工设计层在深度学习中的重要性。
## 643. `cs.LG` - ChessArena: 一个评估大规模语言模型战略推理能力的国际象棋测试平台 [PDF](https://arxiv.org/pdf/2509.24239), [HTML](https://arxiv.org/abs/2509.24239)
### Authors
Jincheng Liu,Sijun He,Jingjing Wu,Xiangsen Wang,Yang Chen,Zhaoqi Kuang,Siqi Bao,Yuan Yao
### Background
最近的大规模语言模型（LLMs）展示了强大的推理能力。然而，一个关键问题仍未解决：这些模型是否真的具备复杂的策略推理能力，还是主要在训练数据中的复杂模式识别上表现出色？为了回答这一问题，本文提出了一个名为ChessArena的国际象棋测试平台，用于评估LLMs的战略推理能力。国际象棋需要长期规划、严格规则理解以及多轮对话记忆等多种复杂的推理能力。ChessArena是一个竞争框架，LLMs在此框架下进行相互竞技，采用四种不同的游戏模式。该测试平台配备了排名算法和排行榜，并能评估基础理解、移动选择、解谜等细粒度的能力。13种不同模式的LLMs在ChessArena中进行了超过800场比赛。结果显示当前LLMs存在明显的局限性：没有任何模型能在比赛中击败Maia-1100（一个处于人类 아마추어级别的人工智能象棋引擎），甚至有些模型无法击败随机选择移动的玩家。另外，本文还提供了一个测试平台的基准：我们的Qwen3-8B模型进行微调后显著提高了性能，接近更大的最先进的推理模型。
### Innovation
本文提出一个名为ChessArena的测试平台，专门用于评估大语言模型的战略推理能力。这是一个国际合作象棋竞争框架，评估了13种不同类型的LLMs，并展示其在策略制定、理解规则和处理多轮对话方面的能力。这个测试平台引入了评估模型在棋局中对应对基本局面、选择移动和解谜等问题的细粒度能力的方式。更重要的是，这个测试提供了一个基准线，显示即使是较大规模和更先进的推理模型，仍与人类水平的象棋引擎存在差距。
### Conclusion
当前的大规模语言模型在战略推理方面仍存在明显的局限性，没有任何模型能在国际象棋比赛中击败处于人类业余水平的棋手Engine。未来仍需要更深入的研究和更加强大的模型以提高其战略推理能力。我们提出的ChessArena测试平台提供了一种新的评估框架，这对于推进大语言模型的发展具有重要意义。
## 644. `cs.LG` - ADPO: 确定锚点的直接偏好优化 [PDF](https://arxiv.org/pdf/2510.18913), [HTML](https://arxiv.org/abs/2510.18913)
### Authors
Wang Zixian
### Background
Direct Preference Optimization (DPO) 虽然有效，但在标注者噪声和分布偏移情况下容易失效，因为它依赖于硬的两两配对标签，并仅正则化对数概率差异。
### Innovation
提出了 Anchored Direct Preference Optimization（ADPO）框架，通过参考锚点扩展偏好学习到软列表监督。ADPO 通过最小化 KL(q || softmax((s - s_ref) / τ_{anc}))，具备多种优势：(i) 通过目标 q、锚策略和温度的选择，可恢复有监督微调、知识蒸馏、最大熵强化学习和 DPO 等作为特例；(ii) 引入了由 softmax 汤森度元度维护的隐式可信区域，与锚点无关；(iii) 支持动态锚点更新，保证了稳定性。
### Conclusion
实验中观察到了根据任务依赖的权衡，动态锚点改进了在线探索能力，而固定锚点在离线蒸馏中更优，实现了在我们的基准模型上学生-教师 KL 失真度最多减少了 170 到 5000 倍的结果。
## 645. `cs.LG` - TowerVision：理解并改进视觉语言模型中的多语言性 [PDF](https://arxiv.org/pdf/2510.21849), [HTML](https://arxiv.org/abs/2510.21849)
### Authors
André G. Viveiros,Patrick Fernandes,Saul Santos,Sonal Sannigrahi,Emmanouil Zaranis,Nuno M. Guerreiro,Amin Farajian,Pierre Colombo,Graham Neubig,André F. T. Martins
### Background
尽管在视觉语言模型（VLMs）领域取得了显著进步，但大多数现有工作均以英语为中心，限制了其在多语言环境中的效果。
### Innovation
该工作进行了全面的经验研究，分析了多种多语言设计选择（如训练数据组成、编码器选择和文本骨架）的影响，提出了基于多语言文本模型Tower+构建的多模态多语言VLMs系列——TowerVision。该模型在ALM-Bench、Multi30K（图像任务）和ViMUL-Bench（视频任务）等多项多模态多语言基准测试中表现良好，并且特别在文化背景任务和多模态翻译中具有优势。通过在微调过程中结合视觉和文化语境，模型克服了在较大数据集上训练的现有方法，表现出色。
### Conclusion
研究表明，多语言视觉语言训练数据显著改善了跨语言泛化能力，无论是从资源丰富语言到资源不足语言还是反之皆然。此外，指令调整的LLM并非总是最佳初始点。为了进一步支持研究，所有模型、数据和训练食谱均公开发布。
## 646. `cs.LG` - 经验贝叶斯多臂博弈学习 [PDF](https://arxiv.org/pdf/2510.26284), [HTML](https://arxiv.org/abs/2510.26284)
### Authors
Xia Jiang,Rong J.B. Zhu
### Background
基于上下文的多任务学习由于其在提升多个相关任务决策能力方面的潜力，引起了广泛的研究兴趣。现有方法往往忽视不同博弈实例间协方差结构的学习，导致信息共享不足和特定实例变异性的处理不够灵活。本文提供了一种新颖的基于经验贝叶斯的多博弈贝叶斯框架，通过分层贝叶斯模型捕捉不同博弈实例间的异质性和相关性，使得信息共享更有效，同时可以灵活地适应实例间的特定变化。
### Innovation
本文引入了一种基于经验贝叶斯的方法来估计先验分布的协方差矩阵，增强了多博弈学习的实用性和灵活性。基于此方法，开发了两种高效算法：ebmTS（经验贝叶斯多博弈蒙特卡洛采样）和ebmUCB（经验贝叶斯多博弈上置信界），这两种算法都将估计的先验融入决策过程中。此外，提供了所提出算法的频率遗憾上界，补充了多博弈问题领域的一个研究空白。
### Conclusion
通过在合成和真实世界数据集上的广泛实验，表明了我们所提方法在复杂环境下的优越性能，与现有技术相比，累积遗憾更低，突显了其在多博弈中的探索和利用之间的良好平衡效果。
## 647. `cs.LG` - 旅程的奖励，而不仅仅是目的地：测试时强化学习中综合路径和答案自我评分奖励机制 [PDF](https://arxiv.org/pdf/2510.17923), [HTML](https://arxiv.org/abs/2510.17923)
### Authors
Chenwei Tang,Jingyu Xing,Xinyu Liu,Wei Ju,Jiancheng Lv,Fan Zhang,Deng Xiong,Ziyue Qiao
### Background
强化学习（RL）已成为推动大型语言模型（LLMs）发展的强大范式，在复杂推理领域，如数学和代码生成方面取得了显著成果。然而，当前的RL方法因过度依赖于人工curated的偏好数据或标记数据集来构建奖励模型而面临根本性的可扩展性瓶颈。为了克服这一限制，该研究探讨了利用未标记数据的RL，让模型通过连续的经验流自主学习。在这个场景中，核心挑战是在没有真实标签监督的情况下准确估计奖励。现有的方法，如Test-Time RL，通过自我一致共识来解决这一问题，但也存在强化错误伪标签的风险，而伪标签是通过多数投票导出的。
### Innovation
研究引入了COMPASS（综合路径和答案自我评分）这种全新的测试时奖励机制，该机制无需外部监督即可运行。COMPASS融合了两个互补的组件：Dual-Calibration Answer Reward (DCAR)，通过信心和可信度校准来建立可信赖的伪标签，稳定训练过程；以及Decisive Path Reward (DPR)，它直接优化推理过程质量，超出单纯结果监督。通过共同强化可信赖的共识答案和高度决断性的推理链，COMPASS系统地提高模型的分析能力。实验表明，COMPASS在各种推理任务和模型架构上实现了显著且一致的性能提升，为LLMs从连续经验中学习提供了一个更具可扩展性的方向。
### Conclusion
实验结果证明，COMPASS在各种推理任务和模型架构上实现了显著且一致的性能提升，为LLMs从连续经验中学习提供了一个更具可扩展性的方向。
## 648. `cs.LG` - LLMs作为上下文元学习者进行模型和超参数选择 [PDF](https://arxiv.org/pdf/2510.26510), [HTML](https://arxiv.org/abs/2510.26510)
### Authors
Youssef Attia El Hili,Albert Thomas,Malik Tiomoko,Abdelhakim Benechehab,Corentin Léger,Corinne Ancourt,Balázs Kégl
### Background
在机器学习中，模型和超参数的选择至关重要但极具挑战性，通常需要依赖专家直觉或成本高昂的自动化搜索。我们研究了大规模语言模型（LLMs）能否在这一任务中发挥作用，作为一种上下文元学习者。通过将每个数据集转化为可解释的元数据，我们促使LLMs推荐模型家族和超参数。我们研究了两种提示策略：1）零样本模式，仅依赖预训练知识；2）元经验增强模式，结合了过去任务中模型及其表现的例子。在合成和真实世界基准测试中，我们证明了LLMs可以利用数据集元数据推荐具有竞争力的模型和超参数，而无需进行搜索，并且元经验增强提示带来的改进展示了其在上下文元学习方面的潜力。
### Innovation
研究发现，大规模语言模型可以通过上下文元学习的方式建议具有竞争力的模型和超参数，而无需搜索。元经验增强提示展示了其在上下文元学习方面的潜力，为大规模语言模型在模型选择和超参数优化领域中的应用开辟了新的可能性。
### Conclusion
研究结果表明，大规模语言模型在模型选择和超参数优化方面具有潜在的重要作用，可以作为一种轻量级的通用助手。推测基于元数据的上下文元学习方法可以显著提高模型推荐的性能。
## 649. `cs.LG` - Flashlight: PyTorch Compiler Extensions to Accelerate Attention Variants [PDF](https://arxiv.org/pdf/2511.02043), [HTML](https://arxiv.org/abs/2511.02043)
### Authors
Bozhi You,Irene Wang,Zelal Su Mustafaoglu,Abhinav Jangda,Angélica Moreira,Roshan Dathathri,Divya Mahajan,Keshav Pingali
### Background
注意力机制是大型语言模型（LLMs）的一个基本构建模块，因此已经有许多努力致力于高效实现这个机制。例如，FlashAttention利用平铺和内核融合来优化注意力计算。最近，引入了一些新的注意力机制变体来提高模型的质量或效率。但是，支持这些机制仍然具有挑战性，因为它们通常需要特定的内核或手动调优的实现。FlexAttention最近通过使用静态编程模板来支持FlashAttention风格的内核的一部分变体，但其仍然存在局限性。
### Innovation
本文提出了Flashlight，这是一个构建在PyTorch生态系统中的编译器原生框架，它可以自动为任意的基于注意力机制的程序生成融合的FlashAttention风格内核，而无需依赖静态模板或预定义的内核特殊化。Flashlight利用PyTorch的编译工作流程透明地融合和分割注意力计算，从而实现对各种注意力模式的高效执行。Flashlight不仅支持FlexAttention模型可以表达的所有变体，还能够处理FlexAttention无法处理的数据依赖型注意力公式，从而增加了模型的灵活性和可实现性。实验结果表明，Flashlight生成的内核性能与FlexAttention相当或更优，并且支持原生PyTorch代码，使开发者能够在不牺牲性能的情况下快速探索新的注意力模型。
### Conclusion
Flashlight框架能够自动为任意的基于注意力机制的程序生成高效的FlashAttention风格内核，无需依赖静态模板或预定义的内核特殊化。Flashlight通过PyTorch的编译工作流程融合和分割注意力计算，实现了对多种注意力模式的高效执行。其优于FlexAttention的地方在于，不仅可以支持更多变体还可以支持FlexAttention无法处理的数据依赖型注意力公式，同时保持了PyTorch代码的灵活性，允许开发者快速探索新的注意力模型而不影响性能。
## 650. `cs.LG` - 非凸的波形超置异构联邦学习：偏差-方差权衡 [PDF](https://arxiv.org/pdf/2510.26722), [HTML](https://arxiv.org/abs/2510.26722)
### Authors
Muhammad Faraz Ul Abrar,Nicolò Michelusi
### Background
OTAF联邦学习作为一种利用无线多址信道波形叠加来在单次使用中聚合模型更新的可扩展范式，已被广泛认可。现有的OTAF设计大多通过假设相同的路径损耗（设备间的同质无线条件）或者强制零偏差更新来确保模型更新为零偏差，以保证收敛性。但在异构无线场景下，这样的设计会受到最弱设备的限制，导致更新方差增加。此外，现有的对偏置OTAF的研究大多集中在凸目标函数上，而大多数现代AI模型是非凸的。鉴于这些差距，本文研究了在无线异构场景下具有随机梯度下降（SGD）的一般光滑非凸OTAF的目标函数。我们提出了新颖的具有结构化、时不变偏差的OTAF-SGD更新方法，以降低方差更新。我们推导出一个有限时间稳态界（预期时间平均梯度范数平方），明确揭示了偏差-方差权衡。为了优化这种权衡，我们提出了一个非凸联合OTAF功率控制设计，并开发了一个只需基站处统计CSI（信道状态信息）的高效连续凸逼近（SCA）算法。通过在非凸图像分类任务上的实验验证了这种方法：基于SCA的设计通过优化偏差加速了收敛，并且相比之前的OTAF基线提高了泛化能力。
### Innovation
我们的创新主要包括：（1）提出了具有结构化、时不变偏差的OTAF-SGD更新方法，以允许偏差并降低方差更新；（2）推导出揭示偏差-方差权衡关系的有限时间稳态界；（3）提出了基于SCA的非凸联合OTAF功率控制设计，只需统计CSI即可实现高效优化；（4）通过非凸图像分类任务实验验证了加速收敛和提高泛化能力的效果。
### Conclusion
本文在无线异构场景下研究了一般光滑非凸OTAF中的偏置-方差权衡问题。我们设计了具有结构化偏差的OTAF-SGD更新方法，推导出了偏差-方差权衡的解析形式，并提出了高效的功率控制算法。实验结果表明，本方法能够加速收敛并改善泛化能力。
## 651. `cs.LG` - DashCLIP：利用多模态模型生成DoorDash的语义嵌入 [PDF](https://arxiv.org/pdf/2504.07110), [HTML](https://arxiv.org/abs/2504.07110)
### Authors
Omkar Gurjar,Kin Sum Liu,Praveen Kolli,Utsaw Kumar,Mandar Rahurkar
### Background
尽管视觉-语言模型在各种生成任务中取得了成功，但获取高质量的产品语义表示和用户意图仍然具有挑战性，因为现有的模型难以捕捉实体之间的微妙关系。在这一背景下，本文提出了一种结合训练框架，通过对比学习对齐单模态和多模态编码器，以图像-文本数据为依据进行联合训练，针对产品和用户查询进行建模。
### Innovation
本文提出了一种通过对比学习对单模态和多模态编码器进行对齐的联合训练框架，以图像-文本数据为基础，通过一个由大型语言模型（LLM）提炼的相关性数据集训练查询编码器，从而消除对用户互动历史的依赖。这种嵌入展示了强大的泛化能力，并在商品分类和相关性预测等应用中提高了性能。此外，个人化广告推荐中的点击率和转化率显著提升，进一步验证了对其关键业务指标的影响。
### Conclusion
本文提供的框架具有灵活性，是提高电子商务领域用户体验的一种有前途的解决方案。
## 652. `cs.LG` - 从RGB-D视频学习可变形物体模型的粒子-网格神经动力学 [PDF](https://arxiv.org/pdf/2506.15680), [HTML](https://arxiv.org/abs/2506.15680)
### Authors
Kaifeng Zhang,Baoyu Li,Kris Hauser,Yunzhu Li
### Background
对可变形物体的动力学建模具有挑战性，因为它们的物理性质多样，并且很难从有限的视觉信息中估计状态。
### Innovation
提出了一个结合对象粒子和空间网格的混合表示的神经动力学框架，以捕捉全局形状和运动信息，同时预测密集的粒子运动，适用于建模具有不同形状和材料的物体。该框架通过与Gaussian Splattings的结合实现了一种基于学习的变形物体数字孪生，并生成了3D条件动作视频。
### Conclusion
模型通过稀疏视角RGB-D记录的机器人-物体交互记录，学会了多种物体——如绳子、衣服、填充动物和纸袋的动力学，并在未见实例中实现了类别级别的泛化。该方法在有限摄像机视角的场景中优于最先进的基于学习和基于物理的模拟器，并在基于模型的规划中展示了其在各种任务中的目标导向物体操作的应用前景。
## 653. `cs.LG` - 通过微调转移实现高效模型开发 [PDF](https://arxiv.org/pdf/2503.20110), [HTML](https://arxiv.org/abs/2503.20110)
### Authors
Pin-Jie Lin,Rishab Balasubramanian,Fengyuan Liu,Nikhil Kandpal,Tu Vu
### Background
现代大模型在每次更新时都会遇到效率问题，因为每次新的预训练模型版本都需要重新进行昂贵的对齐过程。即使是针对特定领域或语言的模型，每次新基础模型的发布也需要重新在专门的数据上进行微调。本文探讨了不同模型版本之间的微调更新迁移，通过从源模型版本导出差分向量并应用于目标模型版本的基础模型上，验证了这种方法的有效性。
### Innovation
本文提出了一种将微调更新从一个模型版本转移到另一个不同版本的方法，通过导出源模型的差分向量，并将其应用于目标模型的基础模型，实现在无需额外训练的情况下显著提高目标模型的性能。具体实例包括将从Llama 3.0 8B迁移的微调更新提高Llama 3.1 8B的IFEval和LiveCodeBench得分，以及在多语言任务中的性能提升。
### Conclusion
研究表明，微调转移的方法在无需额外训练的情况下提高了模型的性能，特别是在多语言任务中表现尤为显著。实验结果证明，通过模型版本之间的微调更新迁移可以在保持或超越新发布模型性能的情况下，实现高效的模型开发。这为持续的LLM开发提供了一种成本效率高且实用的策略。
## 654. `cs.LG` - VERA: 变化推理框架用于破解大型语言模型 [PDF](https://arxiv.org/pdf/2506.22666), [HTML](https://arxiv.org/abs/2506.22666)
### Authors
Anamika Lochab,Lu Yan,Patrick Pynadath,Xiangyu Zhang,Ruqi Zhang
### Background
现代API仅提供访问最新LLM的能力，这突显了在实际环境中需要有效检测模型漏洞的黑盒破解方法的必要性。大多数现有的方法依赖于遗传算法进行基于梯度的优化，但由于初始化和对人工提练提示池的依赖，这些方法的效果有限。此外，这些方法需要对每个提示进行单独的优化，无法提供模型漏洞的全面描述。因此，提出了VERA作为解决方案。
### Innovation
VERA采用了变化推理框架将黑盒破解提示定义为变化推理问题，通过训练一个小的攻击者LLM来近似目标LLM在对抗提示上的后验，并使用预训练的攻击者LLM生成针对目标查询的多样且流畅的破解提示，而无需重新优化。实验结果表明，VERA在多种目标LLM上实现了良好的性能，突显了概率推理在对抗提示生成中的价值。
### Conclusion
实验结果证实了VERA的有效性和性能，通过将黑盒破解提示辨识转化为变化推理问题，VERA提供了一种新颖的方法来识别大型语言模型中的漏洞，具有广泛的应用前景。
## 655. `cs.LG` - 大型语言模型的鲁棒性：缓解策略与评估指标综述 [PDF](https://arxiv.org/pdf/2505.18658), [HTML](https://arxiv.org/abs/2505.18658)
### Authors
Pankaj Kumar,Subhankar Mishra
### Background
大型语言模型（LLMs）在自然语言处理（NLP）和人工智能（AI）的发展中展现出巨大的潜力。然而，确保LLMs的稳健性仍是一个关键挑战。为了应对这些挑战并推动领域发展，本综述提供了一个全面的研究概述。研究系统地探讨了LLMs稳健性的本质，包括其概念基础、跨多种输入的一致表现的重要性以及现实应用中失效模式的影响。同时分析了非稳健性的来源，将模型固有限制、数据驱动的脆弱性和外部对抗性因素纳入其中，这些因素损害了可靠性，并回顾了最新的缓解策略，讨论了广泛采用的基准、新兴的评估指标以及现实可靠性评估中的持续性缺口。本综述通过现有综述和跨学科研究的综合分析，突显了趋势、未解问题和未来研究的路径方案
### Innovation
本研究提供了一个全面的大型语言模型稳健性的概述，系统分析了稳健性的本质及其对抗性因素，回顾了最新的缓解策略，并讨论了评估指标。这些发现突显了趋势、未解问题和未来研究的方向，推动了领域的发展与进步
### Conclusion
本综述总结了当前在大型语言模型稳健性方面的研究成果，指出了趋势和未解的问题，并提出了未来研究路径，为相关领域提供了有价值的参考
## 656. `cs.LG` - VQ-VAEs的信理论坛化泛化分析：潜变量的作用 [PDF](https://arxiv.org/pdf/2505.19470), [HTML](https://arxiv.org/abs/2505.19470)
### Authors
Futoshi Futami,Masahiro Fujisawa
### Background
潜变量（LVs）在编码-解码模型中起到了关键作用，通过允许有效数据压缩、预测和生成。尽管LVs在监督学习中的泛化理论属性已被广泛研究，但在无监督模型如变分自编码器（VAEs）中的类似分析却相对不足。本文扩展了信息论的泛化分析方法，应用于具有离散潜空间的矢量量化（VQ）VAEs，引入了新的数据依赖先验，以严谨地分析潜变量、泛化和数据生成之间的关系。
### Innovation
本文对VQ-VAEs的信息论泛化进行分析，提出了潜变量和泛化关系的新观点，并通过引入新的数据依赖先验进一步澄清了潜变量与数据生成性能的关系。同时，推导出重建损失的新泛化误差界，该误差界仅依赖于潜变量和编码器的复杂性，与解码器无关。此外，还提供了真实数据和生成数据分布之间的2- Wasserstein距离的上界，解释了潜变量正则化如何贡献于数据生成性能。
### Conclusion
本文将信息论泛化分析应用于矢量量化VAEs，通过引入新的数据依赖先验，给出了潜变量和泛化的定量关系。并通过导出重建损失的新泛化误差边界，强调了潜变量在数据生成中的重要性。同时，作者解释了潜变量正则化如何影响数据生成性能。
## 657. `cs.LG` - RadZero: 基于相似度的交叉注意力机制在胸部X光图像中的可解释视觉-语言对齐及其零样本多任务能力 [PDF](https://arxiv.org/pdf/2504.07416), [HTML](https://arxiv.org/abs/2504.07416)
### Authors
Jonggwon Park,Byungmu Yoon,Soobum Kim,Kyoyun Choi
### Background
近年来，多模态模型在医疗影像学领域的建议-语言（VL）对齐方面取得了显著进步，尤其是在放射学领域。然而，现有方法对于如何有效利用复杂的放射学报告进行学习存在局限性，并且通过注意力概率可视化提供的解释性有限。
### Innovation
引入了RadZero框架，这是一种新的胸部X光图像VL对齐方法，具有零样本多任务能力。Key创新点在于VL-CABS（基于相似度的交叉注意力--跨注意力基于相似度），它可以将文本嵌入与局部图像特征对齐，从而实现解释性的细粒度VL推理。RadZero通过使用大型语言模型从放射学报告中提取简洁的语义句子，并采用多正样本对比训练来有效地捕捉图像与多个相关文本描述之间的关系。此外，RadZero还通过计算文本嵌入与局部图像块特征之间的相似性，实现了零样本推理，并生成像素级VL相似图进行定位和分割。
### Conclusion
实验结果表明，RadZero在胸部X光公开基准测试集中的零样本分类、定位和分割方面优于现有最佳方法。进一步地，VL相似图分析显示了VL-CABS在VL对齐中的解释性潜力。此外，定性评估还表明RadZero在开放词汇语义分割方面的有效性，进一步验证了其在医学影像中的效果。完整代码可在 [此链接] 获取。
## 658. `cs.LG` - Autocomp：为张量加速器量身打造的强大且灵活的代码优化器 [PDF](https://arxiv.org/pdf/2505.18574), [HTML](https://arxiv.org/abs/2505.18574)
### Authors
Charles Hong,Sahil Bhatia,Alvin Cheung,Yakun Sophia Shao
### Background
硬件加速器，尤其是那些为张量处理设计的，已成为现代计算的必备工具。然而，即使有许多编译器的努力，编写这些张量加速器的代码仍然具有挑战性，导致其潜在效能没有得到充分利用。近期，大规模语言模型（LLMs）在代码生成和优化任务方面展现出显著潜力，但在生成低资源语言，如专门的张量加速器代码方面仍面临挑战。
### Innovation
我们提出了一种名为Autocomp的方法，以此让加速器程序员利用领域知识和硬件反馈，通过自动化LLM驱动搜索优化代码。创新点包括：1）将每一优化过程设计为结构化的两阶段提示，分为计划和代码生成阶段；2）在计划阶段通过简明且灵活的优化菜单插入领域知识；3）在每次搜索迭代中整合来自硬件的正确性和性能评估作为反馈。这种方法在三个不同的硬件平台上展现出卓越性能，优化后的代码运行速度最高提升5.6倍，优于现成库(Gemmini)、专家级手工调优代码（AWS Trainium）和基于机器学习的成本模型（NVIDIA L40S）的表现。此外，产生的优化策略可以在相似张量操作中复用，固定样本预算下可提升高达24%的速度。
### Conclusion
Autocomp通过自动化LLM驱动搜索为张量加速器代码优化提供了一个灵活且有效的解决方案。在三个不同硬件平台上进行了验证，证明其能够显著提高代码优化的效率和性能，并且该优化策略具有跨操作复用性，从而进一步提升性能。
## 659. `cs.LG` - 矩形实矩阵高阶奇异值导数 [PDF](https://arxiv.org/pdf/2506.03764), [HTML](https://arxiv.org/abs/2506.03764)
### Authors
Róisín Luo,James McDermott,Colm O'Riordan
### Background
通过Kato的分析型摄动理论中的减少消去算子，我们提出了一种理论框架来推导实矩形矩阵中奇异值的一般n阶Fréchet导数。传统的矩阵分析技术难以直接推导高阶导数。本文通过将矩形矩阵视为有限维希尔伯特空间上的紧算子，并嵌入块自共轭算子中以捕捉非对称扰动，来解决这一问题。这种方法使得通过卡托的渐近特征值展开获得了一般形式的无穷小n阶谱变异性表达式。进一步应用Kronecker积表示，本文得到了一个尚未在文献中出现的奇异值海森矩阵。
### Innovation
通过结合抽象算子理论摄动理论与矩阵分析，本文的方法为随机矩阵应用中高阶谱灵敏性研究提供了一套实用工具，特别是在对抗性扰动的深度学习场景中。这是通过将矩阵表示嵌入自共轭算子实现的，并应用Kato的渐近特征值展开来获得高等次的谱变化表达式。该研究首次提供了奇异值的Hessian矩阵的具体形式，丰富了相关理论框架。
### Conclusion
本文通过利用Kato分析型摄动理论中的减少消去算子，提出了一种理论框架来推导实矩形矩阵中奇异值的一般n阶Fréchet导数。这不仅克服了一阶导数以上的奇异值导数难以直接获得的问题，还通过具体的矩阵表示方法，得到了Hessian矩阵的形式，为抗干扰深度学习等应用提供了新的工具和方法。
## 660. `cs.LG` - TathyaNyaya和FactLegalLlama：印度法律背景下事实判断预测和解释的进步 [PDF](https://arxiv.org/pdf/2504.04737), [HTML](https://arxiv.org/abs/2504.04737)
### Authors
Shubham Kumar Nigam,Balaramamahanthi Deepak Patnaik,Shivam Mishra,Noel Shallum,Kripabandhu Ghosh,Arnab Bhattacharya
### Background
在基于事实判断预测和解释（FJPE）的背景下，依赖准确的事实数据对于开发强健且具现实性的AI驱动决策工具至关重要。本文介绍了TathyaNyaya，这是专门为印度法律环境设计的最大规模标注数据集，它涵盖了印度最高法院和各高等法院的判决。数据集名称来源于印度语词汇“Tathya”（事实）和“Nyaya”（正义）。TathyaNyaya专注于事实陈述而非完整的法律文本，反映了现实中的司法流程，其中事实数据决定了结果。本文还提出了FactLegalLlama，这是经过指令调优的LLaMa-3-8B大型语言模型的变体，优化用于生成高质量的FJPE任务解释。
### Innovation
本文的创新之处在于，首先，TathyaNyaya数据集不仅规模更大、多样度更高，还专门针对印度法律环境，为预测和解释任务提供了独特的视角；其次，FactLegalLlama模型融合了Transformer和LLM来生成高质的解释，此模型在TathyaNyaya数据集上进行了微调，能同时提高预测准确性和解释相关性，增强了透明度和可解释性。最后，该研究强调了事实精度的精准性对于提高预测性能和解释性的重要性，以及TathyaNyaya和FactLegalLlama作为AI辅助法律决策的基础资源的作用。
### Conclusion
TathyaNyaya和FactLegalLlama共同为印度法律中的FJPE任务提供了坚实的基础。它们不仅能够提升AI在法律分析中的解释性，还为构建可解释的AI系统开辟了新路径。这一研究对于推动印度法律环境中的FJPE有着重要的意义。
## 661. `cs.LG` - 通过自适应位分配实现高效且准确的脉冲神经网络 [PDF](https://arxiv.org/pdf/2506.23717), [HTML](https://arxiv.org/abs/2506.23717)
### Authors
Xingting Yao,Qinghao Hu,Fei Zhou,Tielong Liu,Gang Li,Peisong Wang,Jian Cheng
### Background
多电平脉冲神经网络(SNNs)近年来成为研究热点，追求能耗低且精确度高的人工智能。然而，随着涉及的位数增多，相关内存和计算需求显著增加，性能提升变得不成比例。基于不同层的重要性不同且额外的位可能会被浪费和干扰这一洞察，本研究提出了直接训练的SNNs的自适应位分配策略，实现了精确控制每一层的内存和计算资源分配。实验在包括静态CIFAR和ImageNet以及动态CIFAR-DVS、DVS-GESTURE和SHD数据集上展示，表明本方法可降低总体内存和计算成本并保持高精度。特别是在ImageNet上，改进的SEWResNet-34比先进基准工作提高了2.69%的准确率并降低了4.16倍的位预算。
### Innovation
提出了自适应位分配策略，通过参数化权重和脉冲的时间长度及位宽，使它们通过梯度学习和可控。提出了改进的脉冲神经元，能够处理不同时间长度、计算梯度时间长度以及更适合脉冲量化。理论分析了可学习位宽的步长不匹配问题，提出了步长更新机制来缓解这一问题。
### Conclusion
在各种数据集上的实验结果显示，本方法能在降低整体内存和计算成本的同时，实现更高的准确度。此外，该工作将开源。
## 662. `cs.LG` - A LoD of Gaussians: 统一外部内存中超大规模重建的训练和渲染 [PDF](https://arxiv.org/pdf/2507.01110), [HTML](https://arxiv.org/abs/2507.01110)
### Authors
Felix Windisch,Thomas Köhler,Lukas Radl,Michael Steiner,Dieter Schmalstieg,Markus Steinberger
### Background
高斯撒点技术作为一种高性能的新型视图合成技术，可以实现小场景的实时渲染和高质量重建。然而，要将其扩展到更大的环境，目前依赖于将场景划分为块，这种方式在块边界处会产生伪像，难以在不同尺度下进行训练，并且不适于无结构的场景，如城市规模的飞掠与街道级别的视野结合。此外，渲染仍然受到GPU内存的限制，因为所有可见的块必须同时存在于VRAM中。
### Innovation
我们提出了Gaussians的层次结构(A LoD of Gaussians)，一种在单个消费级GPU上训练和渲染超大规模场景的框架，而无需划分场景。该方法将整个场景保存在外部内存中（例如，在CPU内存中）并直接训练层次结构（LoD）表示。通过结合高斯分层与顺序点树的混合数据结构，该方法可以高效地进行视图依赖的层次结构选择，并利用临时一致性来支持实时流式传输和渲染。这些创新使得可以无缝地进行多尺度重建和交互式复杂场景可视化——从宽广的空中视角到精细的地表细节。
### Conclusion
这些创新技术使得超大规模场景的实时、交互式可视化成为可能，从广阔的空中视角到精细的地面细节，都实现了无缝的多尺度重建。
## 663. `cs.LG` - 周期线性弹性周期均质化问题的通用傅里叶神经算子 [PDF](https://arxiv.org/pdf/2507.12233), [HTML](https://arxiv.org/abs/2507.12233)
### Authors
Binh Huy Nguyen,Matti Schneider
### Background
在微尺度力学问题的微结构化分析中，解决单元问题的等效建模是困难的，现有的深度学习框架无法与传统的计算方法相媲美。即使对于机器学习方法，其特性及其有效性也并不明确，更不用说指出哪些方法最有前景。该研究中，作者提出采用傅里叶神经算子（FNOs），结合快速傅里叶变换（FFT）微结构方法的经验，构造了一个FNO代理模型，能够预测具有任意刚度分布（仅受材料对比度约束）的解决单元问题的方案。这种方法打破了材料对称性（如各向同性）、相数量和材料界面上几何形状的限制，提供了详细的物理保证。通过构建不需要任何训练的FNO模型，实验证明其达到了与基本方案相同的存储需求和执行时间与传统快速傅里叶变换解算器相似的状态，并成功解决了超过1000万体素的大规模问题。研究旨在突出FNOs在解决微结构力学问题中的潜力，将其与基于FFT的方法联系起来，从而在两领域之间建立一个富有成效的交流平台。
### Innovation
提出了一种新的方法，即采用傅里叶神经算子（FNOs）来解决周期性线性弹性均质化问题，结合快速傅里叶变换方法的经验，构造了一个FNO代理模型，能够有效预测具有任意刚度分布的单元问题的解决方案，无需对材料对称性进行任何假设。此方法适用于超过100万体素的大型问题，并且具有快速计算和低存储需求的特点。
### Conclusion
该研究通过使用傅里叶神经算子（FNOs）和结合快速傅里叶变换方法，提供了解决微尺度线性弹性周期均质化问题的有效解决方案，证明了其具有广泛的适用性和高准确度。这种方法打开了一种新的技术途径，将有助于加速工程师和科学家在材料科学中的复杂微尺度力学计算。
## 664. `cs.SE` - 基于LLM的端到端软件开发代理系统评估与研究 [PDF](https://arxiv.org/pdf/2511.04064), [HTML](https://arxiv.org/abs/2511.04064)
### Authors
Zhengran Zeng,Yixin Li,Rui Xie,Wei Ye,Shikun Zhang
### Background
基于大语言模型（LLM）的自主代理在端到端软件开发中的发展代表着软件工程的一个重要范式转变。然而，这些系统的科学研究受到重大挑战的阻碍，包括过于简化的基准测试和由于混淆实施变量导致难以进行公平比较不同的代理架构。
### Innovation
首先，开发了一个具有挑战性和动态更新的E2EDevBench，用于模拟现实的开发场景。其次，提出了结合测试用例的功能评估和细粒度的LLM需求验证的混合评估框架。利用这个框架，对基于统一基础实现的三个代表性的代理架构进行了受控的实验研究，以分离工作流设计的影响。研究表明，最先进的代理系统可以满足大约50%的需求，但其成功取决于任务分解和协作的架构策略。此外，分析表明，主要瓶颈在于需求遗漏和自我验证不足。
### Conclusion
这项工作为社区提供了更现实的基准、全面的评估框架和关于软件开发代理当前能力和核心挑战的关键见解，指导未来研究向增强需求理解和规划方向发展。
## 665. `cs.SE` - LLM-Driven Adaptive Source-Sink Identification and False Positive Mitigation for Static Analysis [PDF](https://arxiv.org/pdf/2511.04023), [HTML](https://arxiv.org/abs/2511.04023)
### Authors
Shiyin Lin
### Background
静态分析对于发现软件漏洞非常有效，但通常面临着源-汇规格不完整以及高误报率的问题。传统的基于LLM的检测器往往缺乏适应性和确定性，而AdaTaint框架通过神经语义推理适配性地推断源/汇规格并通过过滤虚假警报来解决这些问题。
### Innovation
AdaTaint是一个利用LLM驱动的污点分析框架，能够自适应地推断源/汇规格并通过神经语义推理过滤虚假警报。与仅有LLM的检测器不同，AdaTaint将模型建议与程序事实和约束验证相结合，确保了框架的适应性和确定性。该框架在Juliet 1.3、SV-COMP风格的C基准测试以及三个大型现实项目上的评估显示，相比最先进的基线方法（CodeQL、Joern和仅有LLM的管线），AdaTaint将误报降低了43.7%，召回率提高了11.2%。
### Conclusion
研究结果表明，将LLM推理与符号验证相结合是实现更准确和可靠的静态漏洞分析的可行路径。
## 666. `cs.SE` - 自然语言能力如何塑造软件工程任务中的GenAI代码 [PDF](https://arxiv.org/pdf/2511.04115), [HTML](https://arxiv.org/abs/2511.04115)
### Authors
Ruksit Rojpaisarnkit,Youmei Fan,Kenichi Matsumoto,Raula Gaikovina Kula
### Background
随着基础模型（FM）驱动工具在软件工程中的广泛应用，自然语言提示已成为开发人员与大型语言模型（LLMs）之间的重要接口。尽管许多研究集中在提示结构上，但自然语言熟练度作为一个影响代码生成质量的重要因素，尚未得到充分探索。本文研究了独立于提示技术的英语语言熟练度是否会影响LLMs生成代码的专业性和正确性。通过HumanEval数据集，系统地调整了164项编程任务的提示熟练度等级，从基础到高级，并测量了生成代码的专业性和正确性。
### Innovation
研究发现了LLMs默认使用中级（B2）自然语言水平。虽然对代码生成专业性的影响取决于模型，但较高的提示熟练度始终能够在所有模型中生成更准确的代码。该结果表明，自然语言熟练度是控制代码生成的关键杠杆，有助于开发人员定制AI输出并提高解决方案的可靠性。
### Conclusion
自然语言熟练度是关键杠杆，对控制代码生成至关重要，开发人员可以利用这一杠杆定制AI输出并提高解决方案的可靠性。
## 667. `cs.SE` - 使用大型语言模型解释软件漏洞 [PDF](https://arxiv.org/pdf/2511.04179), [HTML](https://arxiv.org/abs/2511.04179)
### Authors
Oshando Johnson,Alexandra Fomina,Ranjith Krishnamurthy,Vaibhav Chaudhari,Rohith Kumar Shanmuganathan,Eric Bodden
### Background
由于软件安全漏洞的普遍存在，公司开始采用静态应用程序安全测试（SAST）工具来检测漏洞。然而，这些工具在易用性方面存在局限性，它们提供的通用警告信息未能充分向开发人员传达重要信息，导致开发人员对关键发现产生误解或忽略。鉴于大型语言模型（LLMs）及其文本生成能力的最新发展，我们的研究探索了一种结合使用LLMs来解决SAST可解释性问题的混合方法。我们的研究表明，结合GPT-4o的IDE插件SAFE可以显著帮助初级到中级的开发人员理解并解决安全漏洞，从而提高SAST工具的整体易用性。
### Innovation
SAFE是一个结合GPT-4o的IDE插件，用于解释SAST工具检测到的安全漏洞的原因、影响和缓解策略。这项创新通过使用先进的语言模型，提供更详细的解释，帮助开发人员更好地理解和解决安全问题。
### Conclusion
专家用户研究结果表明，SAFE生成的解释能够显著帮助初级到中级开发人员理解并解决软件安全漏洞，从而提高SAST工具的整体易用性和效果。
## 668. `cs.SE` - 我们对齐了吗？大型语言模型与人类判断关于负责任人工智能价值观的初步研究 [PDF](https://arxiv.org/pdf/2511.04157), [HTML](https://arxiv.org/abs/2511.04157)
### Authors
Asma Yamani,Malak Baslyman,Moataz Ahmed
### Background
随着大型语言模型（LLMs）在软件工程任务中的广泛应用，如需求获取、设计和评估，对其与人类关于负责任AI价值观判断的对齐提出了关键问题。本研究旨在探讨LLMs的价值偏好与两类人类群体（美国代表性样本和AI从业者）之间的对齐程度。
### Innovation
研究评估了23种不同的LLMs在四个任务中的性能：选择负责任AI价值观的关键点、在特定背景下评估这些价值观的重要性、解决不同价值观之间的权衡问题、以及优先考虑体现了这些价值观的软件需求。研究结果表明，LLMs与AI从业者的对齐程度高于美国代表性样本，特别强调公平、隐私、透明度、安全和问责制。研究揭示了LLMs声称遵守的价值观念与其实际优先处理的需求之间的不一致，这种不一致性也表明了其表述行为与实际行为之间的不准确性。
### Conclusion
本研究强调了在需求工程中依赖无监督的LLMs的风险，突显了系统性方法在AI辅助软件开发中衡量、解释和监控价值对齐的必要性。
## 669. `cs.SE` - GITER: 使用Kubernetes风格的自定义资源的Git基声明式交换模型 [PDF](https://arxiv.org/pdf/2511.04182), [HTML](https://arxiv.org/abs/2511.04182)
### Authors
Christos Tranoris
### Background
本文介绍了一种使用Git作为协调媒介的轻量级且可审计的异步信息交换方法，取代了传统API和消息代理，采用Kubernetes Operators和自定义资源(CRs)构建基于Git的通信模型。这种方法扩展了GitOps的应用领域，使其不仅限于基础设施管理，还能支持跨域、跨组织和隔离网络环境下的协作场景。
### Innovation
提出了一种基于Git的新通信模式，利用Git原生特性（版本控制、提交签名和访问控制）确保透明性、可追溯性和可重复性，同时保持系统之间的松耦合和自治。这种方法将GitOps扩展到跨域、跨组织和隔离网络环境协作场景，并讨论了与RESTful和消息代理集成模型的比较。
### Conclusion
本文讨论了该模型的架构原理、实施注意事项，并对比了基于Git的声明式通信方案与RESTful和消息代理方案的优劣，强调了采用Git作为声明式通信媒介的优势及潜在权衡。
## 670. `cs.SE` - Collaborative Agents for Automated Program Repair in Ruby [PDF](https://arxiv.org/pdf/2511.03925), [HTML](https://arxiv.org/abs/2511.03925)
### Authors
Nikta Akbarpour,Mahdieh Sadat Benis,Fatemeh Hendijani Fard,Ali Ouni,Mohamed Aymen Saied
### Background
近年来，基于大型语言模型（LLMs）的自动程序修复（APR）取得了显著进展，但当前大多数方法仍面临计算成本高昂的问题，并且主要是针对有限几种编程语言。尽管Ruby在Web开发中应用广泛，并且存在持续的开发挑战，但在APR研究中却没有得到充分关注。
### Innovation
本文介绍了一种名为RAMP的新型轻量级框架，将程序修复过程表述为反馈驱动的迭代过程，专为Ruby语言设计。RAMP利用协作代理生成针对性测试、反思错误并不断优化候选修复方案，直到找到正确解决方案。与先前方法相比，RAMP不依赖于大型多语言修复数据库或昂贵的微调，而是通过轻量级提示和基于测试的反馈直接作用于Ruby语言。在XCodeEval基准测试中，RAMP的pass@1达到67%，超过了先前的方法。进一步的实验证明了测试生成和自我反思是其性能的关键驱动因素。此外，RAMP在修复错误答案、编译错误和运行时错误方面特别有效。这种方法为多代理修复策略提供了新的见解，并为将基于LLM的调试工具推广到尚未充分研究的语言奠定了基础。
### Conclusion
RAMP框架在Ruby上的实验结果表明了其有效性和潜力，为未来扩展基于LLM的调试工具到更多语言以及探索多代理修复策略提供了重要的研究基础。
## 671. `cs.SE` - 大型语言模型指导下的漏洞检测 [PDF](https://arxiv.org/pdf/2511.04014), [HTML](https://arxiv.org/abs/2511.04014)
### Authors
Hao Zhu,Jia Li,Cuiyun Gao,Jiaru Qian,Yihong Dong,Huanyu Liu,Lecheng Wang,Ziliang Wang,Xiaolong Hu,Ge Li
### Background
大型语言模型（LLMs）在代码理解任务中取得了显著进展，但在漏洞检测方面表现有限，难以区分漏洞代码和修复后的代码。这种现象主要是因为LLMs缺乏对安全规范的理解，即代码应如何行为以保持安全。当代码行为与这些期望不符时，就会产生潜在的漏洞。然而，此类知识在训练数据中并不常见，导致模型无法推断安全缺陷。
### Innovation
提出了一种名为VulInstruct的规范指导方法，该方法系统地从历史漏洞中抽取安全规范以检测新漏洞。VulInstruct从两个视角构建了规范知识库：（i）来自跨项目高质量补丁的一般规范，捕捉基础的安全行为；（ii）特定于目标代码的领域特定规范，基于相关仓库中的重复违规行为。VulInstruct通过检索相关历史案例和规范，使LLMs能够推理预期的安全行为，而不是依赖表面模式。实验表明，VulInstruct在PrimeVul数据集上相比基线模型在F1-分数和召回率上分别提高了32.7%和50.8%，并且能够唯一检测出比任何基线多24.3%的漏洞。此外，VulInstruct在实际生产代码中发现了一个未知的重大漏洞（CVE-2025-56538），具有实际的应用价值。
### Conclusion
VulInstruct在严格的标准下成功实现了正确的预测和有效的推理，显著提高了漏洞检测的准确性和覆盖范围。该方法不仅在实验中表现出色，还在实际生产环境中发现了一个重大漏洞，验证了其在真实世界漏洞检测中的有效性。
## 672. `cs.SE` - PSD2Code: 通过多模态大语言模型从设计文件自动生成前端代码 [PDF](https://arxiv.org/pdf/2511.04012), [HTML](https://arxiv.org/abs/2511.04012)
### Authors
Yongxi Chen,Lei Chen
### Background
设计到代码生成（design-to-code generation）作为一种有望弥合设计原型与可用前端代码之间差距的方法已经出现。目前已有的方法往往存在结构不一致、资产对齐不当和生产就绪性不足的问题。本文通过解析PSD文件和资产对齐，旨在生成可用于生产的React+SCSS代码。研究显示，这种方法在代码相似度、视觉保真度和生产就绪性等多个评估指标上显著优于现有方法，从而为工业级前端代码生成奠定了基础。
### Innovation
提出了一种新的多模态方法PSD2Code，该方法通过解析PSD文件和资产对齐，生成生产级的React+SCSS代码，引入了“解析-对齐-生成”（ParseAlignGenerate）流水线，从PSD文件中提取层次结构、图层属性和元数据，为前端代码生成提供精确的空间关系和语义分组。系统采用基于约束的对齐策略，确保生成的元素与设计资源的一致性，并通过结构化的提示构建增强控制力和代码质量。该方法在不同大型语言模型上表现出强大的独立性，验证了在工业级代码生成中集成结构化设计信息与多模态大型语言模型的有效性。
### Conclusion
全面评估表明，PSD2Code方法在多个指标上显著优于现有方法，显示出该方法在工业级前端代码生成中的有效性，并向着设计驱动的自动化前端开发迈出了一大步，有效缓解了结构不一致、资产对齐不当和生产就绪性不足的问题。
## 673. `cs.SE` - PEFA-AI：利用渐进式错误反馈代理AI推进开源LLM在RTL生成中的应用 [PDF](https://arxiv.org/pdf/2511.03934), [HTML](https://arxiv.org/abs/2511.03934)
### Authors
Athma Narayanan,Mahesh Subedar,Omesh Tickoo
### Background
本文介绍了一种由多个代理组成的自主流程，这些代理结合了专业的大语言模型（LLMs）和硬件仿真工具，以无人干预的方式协作完成从高层次描述到寄存器传输级（RTL）生成的复杂任务。重要的是，该流程采用了代理渐进式错误反馈系统（PEFA），这是一种自我纠正机制，通过迭代错误反馈逐步提升方法的复杂性，从而替代人工干预。生成的RTL代码包括编译检查、功能正确性和综合可构建性的检验。为了验证这种方法在代码生成中的适应性，使用两个开源的自然语言到RTL的数据集进行了基准测试。通过在开源代理框架上实施提出的策略，利用开源和专有LLM的有效结合，弥补了性能差距，并展示了从高层次描述到RTL生成的关键步骤。与之前发表的方法相比，该论文提出了新的基准指标，具有先进的通过率并有效减少了令牌计数。这表明代理AI流程作为一种创新的方法，在提高开源LLM性能方面取得了重要进展，而且这种方法是高效的，能够处理复杂的硬件设计任务。
### Innovation
介绍了利用代理渐进式错误反馈系统（PEFA）推进开源大语言模型（LLMs）在RTL生成中的应用。该方法通过无人干预的方式合作完成复杂任务，且能够在不依赖于人工的情况下生成高质量的RTL代码。同时，通过开源代理框架的应用展示了技术的有效性和效率，尤其是在节省令牌计数方面具有优势。此外，该论文提出了一个新的基准指标，展示了其在性能上超越了现有方法。
### Conclusion
本文提出了一种新颖的代理AI流程，其中PEFA系统能够自适应地提升生成RTL代码的复杂性，从而取代传统的人工干预方式。该方法已经在开源代理框架中得到了验证，通过结合开源和专有LLMs，大大提高了性能。相比之前的方法，该论文设置了一个新的基准，表明代理AI流程能够有效地提高开源LLMs在RTL生成中的表现。该方法能够有效减少令牌计数，提高了生成RTL代码的效率。
## 674. `cs.SE` - 生物医学开源软件：至关重要的软件包和隐匿的英雄 [PDF](https://arxiv.org/pdf/2404.06672), [HTML](https://arxiv.org/abs/2404.06672)
### Authors
Eva Maxfield Brown,Stephan Druskat,Laurent Hébert-Dufresne,James Howison,Daniel Mietchen,Andrew Nesbitt,João Felipe Pimentel,Boris Veytsman
### Background
尽管科学研究中的科学软件非常重要，但它们通常没有正式受到认可和奖励，尤其是在基础库方面，即使这些库在研究中发挥着核心作用，但在论文中也可能未被提及。
### Innovation
使用CZ Software Mentions Dataset来绘制生物医学论文中使用的软件的上游依赖性，并确定科学软件生态系统中最关键的软件包。提出软件依赖性网络中的中心性度量，并分析三个生态系统（PyPi、CRAN和Bioconductor），以确定具有最高中心性的软件包。
### Conclusion
通过分析和确定核心软件包，研究强调了这些软件在支持当前研究中的重要性，并为资助者、基础设施提供商和其他组织提供了一个理解依赖性软件网络复杂性的框架。
## 675. `cs.SE` - evomap：Python中的动态映射工具箱 [PDF](https://arxiv.org/pdf/2511.04611), [HTML](https://arxiv.org/abs/2511.04611)
### Authors
Maximilian Matthe
### Background
传统的映射方法被广泛应用于多个学科，用于可视化对象之间的关系，但大多数现有的统计软件仅支持静态映射，无法分析这些关系随时间的变化。evomap通过实现Matthe, Ringel, 和 Skiera (2023) 提出的动态映射框架 EvoMap，填补了这一空白，将传统的静态映射方法适应于动态分析。
### Innovation
evomap 包含多种映射技术，如 Multidimensional Scaling (MDS)、Sammon Mapping 和 t-distributed Stochastic Neighbor Embedding (t-SNE) 的变体，以及数据预处理、探索和结果评估的实用工具，为动态映射应用提供了一整套工具。
### Conclusion
本文概述了静态和动态映射的基本原理，描述了 evomap 的架构和功能，并通过一个详尽的应用示例进行了说明。
## 676. `cs.SE` - 软件问题报告中的秘密泄露预防 [PDF](https://arxiv.org/pdf/2410.23657), [HTML](https://arxiv.org/abs/2410.23657)
### Authors
Sadif Ahmed,Md Nafiu Rahman,Zahin Wahab,Gias Uddin,Rifat Shahriyar
### Background
在数字时代，意外暴露敏感信息（如API密钥、令牌和凭证）已成为日益严重的安全威胁。尽管大多数先前的研究集中在检测源代码中的秘密，但软件问题报告中的泄漏仍然未被充分研究。
### Innovation
本研究通过大规模分析和实用的秘密检测流水线填补了这一空白，该流水线结合了基于正则表达式的提取和基于大规模语言模型（LLM）的上下文分类，以检测真实的秘密并减少误报。研究比较了熵基和关键词启发式方法、经典机器学习、深度学习和基于LLM的方法。结果显示，RoBERTa和CodeBERT等较小的模型大幅提高了性能，而自微调开源更大的LLM模型如Qwen和LLaMA则达到了94.49%的F1分数。
### Conclusion
研究最终在178个实际GitHub存储库上验证了其方法，F1分数为81.6%，这证明了该方法在实际场景中的强大泛化能力。
## 677. `cs.SE` - 启动日扩散：跟踪 Hacker News 对 AI 工具 GitHub 星数的影响 [PDF](https://arxiv.org/pdf/2511.04453), [HTML](https://arxiv.org/abs/2511.04453)
### Authors
Obada Kraishan
### Background
社交新闻平台成为开源项目的关键推广渠道，尤其是 Hacker News（HN）。虽然衡量这些平台的即时影响仍具有挑战性，但本研究聚焦于量化 HN 对 GitHub 上 AI 和大语言模型工具星数增长的影响。
### Innovation
本文提出了一个可复现的演示系统，该系统基于公开的 API 跟踪 HN 曝光对 GitHub 星数增长的影响。通过使用机器学习模型（弹性网络）和非线性方法（梯度提升），文章识别了病毒式增长的关键预测因素，如发布时机和“Show HN”标签的影响。该系统能够在标准硬件上运行不到五分钟，自动收集数据、训练模型并生成可视化结果，使得研究结果易于复现。
### Conclusion
研究发现，HN 曝光后的启动库平均能在24小时内获得121颗星，48小时内获得189颗星，一周内获得289颗星。发布时机至关重要，最佳发布时间能额外获得数百颗星。经控制其他因素后，“Show HN”标签没有显著优势。该演示系统便于即时复现，并能扩展至其他平台，为研究人员和开发人员提供启动动态的实用见解。
## 678. `cs.SE` - Eclipse ESCET v4.0中监督控制器合成的概述与性能评估 [PDF](https://arxiv.org/pdf/2511.04370), [HTML](https://arxiv.org/abs/2511.04370)
### Authors
Dennis Hendriks,Michel Reniers,Wan Fokkink,Wytse Oortwijn
### Background
监督控制器用于控制网络物理系统，确保其正确和安全地运行。合成基工程（SBE）是一种自动化很大程度上监督控制器设计和实现的方法。SBE将基于模型的工程与计算机辅助设计相结合，使工程师能够关注系统应该做什么（需求）而非如何做到（设计和实现）。ESCET是Eclipse中的一个开源项目，供用户、研究者和工具供应商共同开发一个支持整个SBE流程的工具包，特别是通过CIF建模语言和工具。
### Innovation
该研究提供了一个关于CIF符号监督控制器合成算法的描述，包括了通常文献中忽略但具有重要意义的方面，如预防运行时错误、处理不同类型的需要、支持输入变量（连接到外部输入）。此外，该研究还引入并描述了CIF的基准模型，包含23种不同尺寸和复杂度的工业和学术模型。研究还介绍了ESCET从v0.8（2022年12月）到v4.0（2024年6月）的改进，这些改进影响了合成性能，并在基准模型上评估了它们，展示了当前CIF的实际合成性能。研究还简要介绍了多级合成的概念，这是一种非单一合成方法，对合成性能进行了评估，发现虽然它可以进一步改善合成性能，但还需要进一步提高性能以合成复杂模型。
### Conclusion
该研究介绍了CIF的符号监督控制器合成算法及其重要的实践相关方面，提出了CIF基准模型，评估了ESCET从v0.8到v4.0的改进对合成性能的影响，展示了当前CIF的合成性能。研究还分析了多级合成方法，并对进一步改进合成性能的需求提出了初步结论。
## 679. `cs.SE` - APRMCTS：利用迭代树搜索改进基于大语言模型的自动化程序修复 [PDF](https://arxiv.org/pdf/2507.01827), [HTML](https://arxiv.org/abs/2507.01827)
### Authors
Haichuan Hu,Quanjun Zhang
### Background
自动程序修复（APR）是一种在无需人工干预的情况下修复软件错误的技术，在软件开发与维护中扮演重要角色。近年来，随着大规模语言模型（LLMs）的进步，提出了一系列基于APR的先进技术，并取得显著效果。然而，现有的基于LLM的APR技术主要依赖于试错策略，存在两个主要问题：（1）由于局部探索导致的修复效果受限，（2）由于重复探索导致的搜索效率低。
### Innovation
本文提出了一种名为APRMCTS的新技术，通过迭代树搜索方法来改善基于LLM的APR。APRMCTS将蒙特卡洛树搜索（MCTS）融入到缀补搜索中，通过全局评估已探索的修复方案，并选择最具潜力的一个进行进一步的优化和生成。这种方法有效地解决了陷入局部最优解的问题，提高了修复搜索的效率。实验结果表明，APRMCTS与GPT-3.5结合使用时，可以修复201个bug，比所有现有的前沿基线都要好。此外，与其他几个基线模型结合使用时，APRMCTS还显示出更高的修复成功率，且所用的修复方案较少，成本也更低。
### Conclusion
我们的实验研究证明，APRMCTS在提高修复效果和效率方面表现出色，尤其是在处理复杂bug方面更为突出。
## 680. `cs.SE` - Pragmatic Reasoning improves LLM Code Generation [PDF](https://arxiv.org/pdf/2502.15835), [HTML](https://arxiv.org/abs/2502.15835)
### Authors
Zhuchen Cao,Sven Apel,Adish Singla,Vera Demberg
### Background
大型语言模型（LLMs）在将自然语言（NL）指令转化为程序代码方面展现了巨大的潜力。然而，用户指令常含有固有的模糊性，这使得LLMs难以准确生成反映用户真实意图的代码。为此，研究人员提出了产生多种程序代码候选并重新排序以确定最佳解的方法。本文将讨论一种称为CodeRSA的新颖代码候选重排序机制，该机制基于Rational Speech Act（RSA）框架，旨在引导LLMs进行更全面的关于用户意图的实用推理。
### Innovation
CodeRSA是一种基于Rational Speech Act（RSA）框架的新型代码候选重排序机制，设计用于指导LLMs进行更全面的实用推理，以更好地理解用户的意图。通过使用Llama-3-8B-Instruct和Qwen-2.5-7B-Instruct在两个广泛应用的代码生成基准HumanEval和MBPP上进行评估，实验结果表明CodeRSA始终优于常见基准，大多数情况下超过了最先进的方法，并且整体表现稳健。这些结果表明将实用推理集成到代码候选重排序中是有效的，为提高LLMs代码生成质量提供了一个有希望的方向。
### Conclusion
实验结果表明将实用推理集成到代码候选重排序中是有效的，为提高LLMs代码生成质量提供了一个有希望的方向。CodeRSA在两个广泛使用的代码生成基准上表现出色，优于现有方法，证明了将其应用于LLMs代码生成的有效性。
## 681. `cs.SE` - Testora：使用自然语言意图检测行为回归 [PDF](https://arxiv.org/pdf/2503.18597), [HTML](https://arxiv.org/abs/2503.18597)
### Authors
Michael Pradel
### Background
随着软件不断演进，代码更改可能会引入回归错误或以其他未预期的方式影响行为。传统的回归测试生成难以检测未预期的行为变化，因为它们会将所有行为差异都报告为潜在的回归。然而，大多数代码更改都是为了以某种方式改变行为，例如修复错误或添加新功能。本文介绍了Testora，这是第一个通过将代码更改的意图与其导致的行为差异进行比较来检测回归的自动化方法。给定一个拉取请求（PR），Testora查询LLM生成测试以演练修改后的代码、比较原始代码和修改后的代码的行为，并将任何行为差异分类为有意图或无意图。该方法利用了PR自然语言信息（如标题、描述和提交消息），利用自然语言意图来检测行为回归。将Testora应用于具有复杂和流行Python项目的PR，结果发现19个回归缺陷，还有11个PR虽未有意图修复错误，却意外地修复了一个错误。在13个报告给开发者的回归中，有11个已得到确认并被修复了9个。使用Testora的成本在实际部署中是可以接受的，检查一个PR需要12.3分钟，LLM成本仅为每PR 0.003美元。我们希望这种方法能够在或在代码更改被合并到代码库前或后不久使用，提供一种在传统方法未捕捉到时早于提前检测回归的方法。
### Innovation
Testora首次提出了通过LLM和自然语言信息来区分有意图和无意图的行为差异的方法，显著提高了检测回归的准确性和效率。
### Conclusion
测试结果显示，Testora在早期阶段可以有效地帮助开发者识别并修复未预期的行为变化，相较于传统方法具有更高的准确性和更少的成本。
## 682. `cs.SE` - vibe coding as a reconfiguration of intent mediation in software development: definition, implications, and research agenda [PDF](https://arxiv.org/pdf/2507.21928), [HTML](https://arxiv.org/abs/2507.21928)
### Authors
Christian Meske,Tobias Hermanns,Esther von der Weiden,Kai-Uwe Loser,Thorsten Berger
### Background
当前软件开发正经历一场根本性的转变，尤其是在vibe coding（情绪编码）日益普及的情况下，大量现代代码库现已被AI生成。这种快速发展与有限的概念性理解之间的脱节凸显了对这一新范式的探究的必要性。文章通过意图视角和历史分析，定义了vibe coding作为一种人类与生成性AI共同参与创造软件制品的新范式，促进自然语言对话，使得从确定性指令到概率推理的意图调解过程发生改变。这一过程涉及开发人员将其概念性目标转化为计算机系统能够执行的表示。研究表明，vibe coding重塑了认知工作，重新分配了人类与机器之间的知识劳动，使软件开发过程中的专业性转移，更多地转向协作编排，而非传统的设计和技术实现领域。
### Innovation
文章创新性地将vibe coding定义为一种新的软件开发范式，强调人类与AI的协作，并通过自然语言对话进行创造，改变了传统的确定性指令到概率推理的意图调解过程。研究指出vibe coding重新分配了认知工作和知识劳动，从设计或技术实现转向了协作编排，并识别了伴随的关键机遇和风险，如民主化、加速、系统优势以及黑箱代码库、责任缺口和生态系统偏见。
### Conclusion
文章提出了跨越人类-技术-组织中心方向的研究议程，旨在为未来对这一范式的调查提供指导。通过重新定义意图调解过程，提出了vibe coding对软件开发的重大再配置意义，以及未来的研究方向。
## 683. `cs.SE` - LLM-生成单元测试中的测试异味 [PDF](https://arxiv.org/pdf/2410.10628), [HTML](https://arxiv.org/abs/2410.10628)
### Authors
Wendkûuni C. Ouédraogo,Yinghua Li,Xueqi Dang,Xunzhu Tang,Anil Koyuncu,Jacques Klein,David Lo,Tegawendé F. Bissyandé
### Background
LLMs有望将单元测试生成从人工负担转变为自动化解决方案。然而，除了编译能力和覆盖程度之外，对于LLM生成的测试的质量还知之甚少，特别是在测试异味（如设计缺陷，阻碍可读性和可维护性的设计错误）方面的表现。本文首次提供了多基准、大规模的LLM生成单元测试中的测试异味扩散分析。研究对比了LLM输出与人类编写的测试套件（作为现实实践的参照）以及从EvoSuite生成的SBST测试（作为自动化基准），以区分这些LLM是在产生人类特征的缺陷还是合成生成的特征。研究涉及四个LLM（GPT-3.5，GPT-4，Mistral 7B，Mixtral 8x7B）共计20505个类级测试套件，972个方法级案例来自TestBench，14469个EvoSuite测试以及来自34635个开源Java项目的779585个人类编写的测试
### Innovation
本文采用两种互补的检测工具（TsDetect和JNose），分析了测试异味的存在率、共现模式以及与软件属性和生成参数的相关性，发现LLM生成的测试中持续表现出了诸如Assertion Roulette和Magic Number Test等测试异味，这些模式受提示策略、上下文长度和模型规模的影响。研究还揭示了LLM生成的测试与人类编写的测试之间的重叠，以及EvoSuite表现出的特定生成器缺陷，这既显示了LLM生成测试的潜力，也揭示了潜在的风险。这些发现证实了设计嗅味感知的生成框架、提示工程策略和增强检测工具的需求，以确保可维护、高质量的测试代码。
### Conclusion
本文的研究结果强调了LLM基于测试生成的机遇与风险，并强调了需要设计嗅味感知生成框架、提示工程策略和增强检测工具的重要性，以确保可维护和高质量的测试代码。
## 684. `cs.SE` - C-ITS中的应用管理：基于需求驱动的部署和重新配置编排 [PDF](https://arxiv.org/pdf/2509.18793), [HTML](https://arxiv.org/abs/2509.18793)
### Authors
Lukas Zanger,Bastian Lampe,Lennart Reiher,Lutz Eckstein
### Background
随着车辆的自动化和互联程度不断提高，形成了合作智能运输系统（C-ITS），并使用外部服务。这种情况使得云原生技术，如微服务和容器编排，在它们的操作中变得越来越重要。然而，大型C-ITS中的应用编排由于环境的动态性和高效资源利用的需求，面临着独特的挑战。在本文中，我们提出了一种基于云原生技术的需求驱动的应用管理方法，特别是利用Kubernetes来应对这些挑战。
### Innovation
方法考虑了来自C-ITS内不同实体的需求，并利用Kubernetes应用管理框架与ROS 2结合，实现微服务的自动化部署、重新配置、更新、升级和规模扩大。该方法通过动态调整以满足变化的需求，尤其是对外部支持服务（如集体环境模型）的请求，实现动态需求的处理。
### Conclusion
我们展示了该框架在集体环境感知的C-ITS用例中的操作，并公开了该原型框架的源代码，以便更好地展示其功能和性能。这种方法能够减少计算资源消耗和网络流量。
## 685. `cs.SE` - PoCo: 针对智能合约的自主概念证明漏洞利用生成 [PDF](https://arxiv.org/pdf/2511.02780), [HTML](https://arxiv.org/abs/2511.02780)
### Authors
Vivi Andersson,Sofia Bobadilla,Harald Hobbelhagen,Martin Monperrus
### Background
智能合约运行在一个高度敌对的环境中，其中的漏洞可能会导致重大财务损失。因此，智能合约需要进行安全审计。在审计过程中，概念证明（PoC）漏洞利用对显示报告的安全漏洞的真实性、可重复性和可操作性起着关键作用。然而，手动创建PoC是耗时且容易出错的，通常受限于紧凑的审计时间表。
### Innovation
我们引入了POCO（自主框架），这是一个自动化框架，能够从审计人员撰写的自然语言漏洞描述中自动生成可执行的概念证明漏洞利用。POCO通过与一组代码执行工具进行Reason-Act-Observe循环交互，以自主方式生成概念证明漏洞利用。它生成的漏洞利用是完全可执行的，并兼容Foundry测试框架，可以直接集成到审计报告和其他安全工具中。我们对23个实际的漏洞报告数据集进行评估，POCO在生成结构良好且逻辑正确的概念证明方面优于提示方法和工作流基线。我们的成果展示了自主框架可以显著降低高质量概念证明在智能合约审计中的需求量，为智能合约安全研究社区提供了直接可行的知识。
### Conclusion
我们的贡献证明了自主框架可以在提升智能合约审计中的概念证明质量方面起到重要作用，极大地减少了所需的工作量。
## 686. `cs.SE` - 全球平台分类：集中式、分布式、联邦制和草根式 [PDF](https://arxiv.org/pdf/2511.03286), [HTML](https://arxiv.org/abs/2511.03286)
### Authors
Ehud Shapiro
### Background
本文探讨了设计用于服务全球人口的数字平台的背景。这些平台已经服务于数十亿人，具有重要性和复杂性。作者提出了基于原子事务的多智能体转移系统和协议，用作一个形式框架来研究这些平台，强调了关键智能体的概念，这些是绝对必不可少的。
### Innovation
本文的创新在于提出了基于原子事务的多智能体转移系统和协议的框架，定义了四个类别（集中式、分布式、联邦制和草根式）来分类全球平台。作者还为示例的全球社交网络提供了四个不同类别的详细规范，并证明了它们都满足相同的正确性属性。
### Conclusion
本文提供了第一个数学框架，可以用来分类当前和想象中的任何全球平台。通过提供多智能体原子事务规范和确定随之而来多智能体协议中的关键智能体集合的数量，作者提供了一个统一的数学方法来研究全球数字平台，这可能是当今最重要的计算机系统分类之一。
