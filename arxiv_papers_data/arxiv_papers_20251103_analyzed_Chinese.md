# 20251103
[![Subscribe_Visitors](https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss)](https://github.com/nituchao/latest_arxiv_analyze_ai)

## 1. `cs.AI` - An Agentic Framework for Rapid Deployment of Edge AI Solutions in Industry 5.0 [PDF](https://arxiv.org/pdf/2510.25813), [HTML](https://arxiv.org/abs/2510.25813)
### Authors
Jorge Martinez-Gil,Mario Pichler,Nefeli Bountouni,Sotiris Koussouris,Marielena Márquez Barreiro,Sergio Gusmeroli
### Background
本文旨在介绍一种适用于工业5.0的创新框架，该框架简化了AI模型在各种工业环境下的边缘设备部署。设计重点在于减少延迟并避免外部数据传输，通过本地推理和实时处理实现这一目标。文中提到，框架的设计基于代理机制，使得人类、算法或协作个体负责明确的任务，从而提高灵活性并简化集成。
### Innovation
该框架的核心创新点在于采用代理制设计，使得各个代理（无论是人类、算法还是协作个体）负责特定任务。同时，该框架支持模块化集成，并保持较低的资源要求。通过减少延迟和避免外部数据传输，实现在边缘设备上的本地推理与实时处理。
### Conclusion
初步评估表明，该框架在食品行业中的实际场景中提高了部署时间和系统适应性性能。源代码已公开，提供给读者更深入的研究和应用探索。
## 2. `cs.AI` - 使用多评判者学习体系逼近人类偏好 [PDF](https://arxiv.org/pdf/2510.25884), [HTML](https://arxiv.org/abs/2510.25884)
### Authors
Eitán Sprejer,Fernando Avalos,Augusto Bernardi,Jose Pedro Brito de Azevedo Faustino,Jacob Haimes,Narmeen Fatimah Oozeer
### Background
LLM（大语言模型）驱动的裁判难以校准，并且常受评分标准敏感性、偏见及不稳定性的影响。克服这一挑战对强化学习从人类反馈中获得可靠奖励模型（RLHF）和构建高效路由系统至关重要。路由系统能够根据用户查询选择最适合的模型。
### Innovation
本文提出一个框架，通过学习多个评分条件裁判的输出来建模多样化的、基于人设的偏好。该方法与直觉性基线相比表现良好，并通过人类和LLM裁判的案例研究评估了其鲁棒性。主要贡献包括一种基于人设的大规模合成偏好标签方法以及两种聚合器的实现：广义加性模型（GAM）和多层感知机（MLP）
### Conclusion
这一研究通过学习多评判者的输出来逼近和建模复杂的人类偏好，克服了现有技术中的关键挑战，并提供了可执行的聚合方法。
## 3. `cs.AI` - 通过注意感知逆向规划估计认知偏差 [PDF](https://arxiv.org/pdf/2510.25951), [HTML](https://arxiv.org/abs/2510.25951)
### Authors
Sounak Banerjee,Daphne Cornelisse,Deepak Gopinath,Emily Sumner,Jonathan DeCastro,Guy Rosman,Eugene Vinitsky,Mark K. Ho
### Background
人们的有目标行为受认知偏差的影响，与人的自主系统交互时应予以考虑。例如，人们的注意力会系统地影响他们执行日常生活任务，如上班驾驶。已有相关研究为这篇论文提供了理论支持，该研究基于计算认知科学提出了一个形式化的注意力感知逆向规划问题，旨在估计人的注意力偏差并通过其行为进行推断。
### Innovation
相较于标准的逆向强化学习，注意力感知逆向规划提出了新的解题方法，通过对行为的分析推断出认知偏差。提出了结合深度强化学习与计算认知建模的方法进行注意力感知逆向规划，实现在现实驾驶场景中使用此方法推断强化学习代理的注意力策略。这种方法展示了在注意力感知逆向规划中估计认知偏差的可扩展性。
### Conclusion
通过将深度强化学习与计算认知建模相结合的逆向规划方法，成功估计了现实驾驶情景中强化学习代理的认知偏差，表明注意力感知逆向规划在估算认知偏差方面具有可扩展性。
## 4. `cs.AI` - 信息论的必然性：压缩与智能的知识基础 [PDF](https://arxiv.org/pdf/2510.25883), [HTML](https://arxiv.org/abs/2510.25883)
### Authors
Christian Dittrich,Jennifer Flygare Kinne
### Background
现有的框架都强调压缩在智能中的重要性，但没有明确说明为什么这个过程会发现因果结构而不仅仅是表面的统计模式。本文提出一个两层框架来填补这一空白。
### Innovation
提出一个两层框架：信息论的必然性（ITI）解释了为何生存压力与信息处理需求之间的进化联系，压缩效率原理（CEP）规定了有效压缩如何机械地选择生成性因果模型，从而与现实对齐。
### Conclusion
ITI和CEP定义了一条因果链，从生存压力到预测需求，再到压缩需求，效率优化，生成结构发现，最终实现与现实的对齐。智能是结构化环境中持久生存的机械必然结果，提供了一种可验证的预测：压缩效率、异常积累率、分层系统的效率差异、生物系统的代谢成本等。这些结果提供了一种统一解释生物、人工和多尺度系统的框架，不依赖于意识或主观经验的假设，同时理解了智能的认知和功能维度。
## 5. `cs.AI` - FinOps智能代理——IT基础设施和成本优化的应用案例 [PDF](https://arxiv.org/pdf/2510.25914), [HTML](https://arxiv.org/abs/2510.25914)
### Authors
Ngoc Phuoc An Vo,Manish Kesarwani,Ruchi Mahindru,Chandrasekhar Narayanaswami
### Background
FinOps代表一种操作框架和文化实践，通过跨工程、财务和业务团队的联合财务责任来最大化云计算业务价值。FinOps从业者面临的基本挑战是：来自多个云提供商和内部系统的计费数据以不同的格式、分类和指标到达，最终导致难以综合成有效的洞察，以及做出及时的决策。
### Innovation
为应对这一挑战，本文提出利用自主目标驱动的人工智能代理进行FinOps自动化。研究构建了一个典型的IT基础设施和成本优化的FinOps代理，并建立了一个模拟整个行业流程的系统，从获取数据到数据的汇总与分析，再生成优化建议。该研究使用多个开源和内部语言模型定义了一套评估指标，表明该代理能够理解和执行任务，与实际的FinOps从业者具有相当的能力。
### Conclusion
研究展示了一个具体的FinOps实现案例，证明了利用自主目标驱动的AI代理可以在IT基础设施和成本优化中有效应用。该系统的成功构建和评估表明，AI代理能够在复杂的FinOps环境中理解、规划并执行任务，从而优化成本和资源使用。
## 6. `cs.AI` - Humans-Junior：通过导向外部骨架推理实现GPT-4o级事实准确性的3.8B语言模型 [PDF](https://arxiv.org/pdf/2510.25933), [HTML](https://arxiv.org/abs/2510.25933)
### Authors
Nissan Yaron,Dan Bystritsky,Ben-Etzion Yaron
### Background
论文背景主要介绍了如何通过小型语言模型和特定技术手段来达到大型模型的性能，同时降低模型部署的成本。背景信息提到GPT-4o在Facts Grounding任务上的表现，并提出了对比基准。研究表明，尽管GPT-4o在标准测试集上表现较好，研究人员寻求开发一种更为经济且接近GPT-4o性能的方法。
### Innovation
研究人员提出了Humans-Junior，这是一个人类辅助的3.8B参数模型，在Facts Grounding任务上的表现与GPT-4o相当，仅在±5个百分点的范围内有所差异。他们通过结合最小化的定向“外骨骼推理”和行为微调技术，减少了对具体领域知识的要求，同时增强了模型的准确性和一致性。此外，该模型的成本相对较低，自托管或边缘部署可以接近无额外成本。
### Conclusion
研究表明，Humans-Junior作为3.8B参数模型，能够在Facts Grounding任务上达到GPT-4o级的准确性，成本可降低约19倍。通过导引的外骨骼推理法和细粒度调优，模型展现了卓越的成本效率和性能。
## 7. `cs.AI` - SciTrust 2.0：科学应用中大型语言模型可信度评估的综合框架 [PDF](https://arxiv.org/pdf/2510.25908), [HTML](https://arxiv.org/abs/2510.25908)
### Authors
Emily Herron,Junqi Yin,Feiyi Wang
### Background
大型语言模型（LLMs）在科学研究中的潜力巨大，但在高风险环境下部署时，其可信度引起了广泛关注和担忧。现有研究在评估LLMs在科学领域中的可信度时常常局限于单一维度，缺乏综合性的评估框架。SciTrust 2.0针对这一问题提供了一个包含四个维度（真实性、对抗性鲁棒性、科学安全性、科学伦理）的全面评估框架。
### Innovation
SciTrust 2.0创新性地引入了一个经过验证的反思调优管道和专家验证开发的新颖开放性真实性基准，同时也提出了一个新的科学伦理基准，涵盖了包括双重用途研究和偏见在内的八个子类别。研究还评估了七个主要的LLMs，发现通用型行业模型在所有可信度维度上总体上优于科学特化的模型，特别是GPT-o4-mini在真实性评估和对抗性鲁棒性方面表现出色。此外，科学特化的模型在逻辑和伦理推理能力方面存在明显不足，特别是在生物安全和化学武器等高风险领域中表现出显著的安全性漏洞问题。
### Conclusion
通过开源SciTrust 2.0框架，研究为开发更可信的AI系统奠定了基础，并推动了在科学背景下的模型安全性和伦理研究的发展。
## 8. `cs.AI` - 通过SHAP实现棋盘上逐个棋子的解释 [PDF](https://arxiv.org/pdf/2510.25775), [HTML](https://arxiv.org/abs/2510.25775)
### Authors
Francesco Spinnato
### Background
现代象棋引擎能够提供精确但难以理解的评估结果，通常以‘çu瞬头’分数的形式表示。虽然这些评估结果在决策中非常有效，但它们掩盖了个体棋子或模式的贡献。本文旨在通过将SHAP应用于象棋分析领域，使得象棋引擎的评估可以归因到特定的棋子上。该方法借鉴了经典象棋教学中的思维方式，即通过心理移除棋子评估局面，结合现代解释性人工智能技术，提供了局部忠实且易于理解的评估解释方式。这种方法为象棋AI的研究开辟了新的可能性，包括可视化、人类训练和引擎比较等方面的新机会。
### Innovation
本文提出了一种新的方法，即通过将SHAP应用于象棋领域，以组合的方式为具体的棋盘局面提供逐个棋子的解释。这种方法首次实现了将象棋引擎的评估结果精确地归因到特定的棋子上，同时将深度学习的精确度与传统的象棋教学方法相结合，从而更好地帮助人类理解引擎的评估结果，为未来的研究提供了有力的支持。通过这种方法，可以更深入地了解棋局评价背后的具体因素，从而增强人类玩家的策略理解和提升，同时也能促进象棋AI引擎的改进与比较。
### Conclusion
本研究的贡献在于开发了一种新的方法，通过SHAP算法实现逐个棋子的解释，使得象棋引擎的评估结果可以被细分为个体棋子的贡献。这不仅为象棋分析提供了新的视角，还为未来的研究和实践开拓了新方向，包括可视化展示和人类训练的应用。同时，作者发布了相关代码和数据，期望促进更多研究者在这方面进行探索，进一步推进可解释的人工智能在象棋中的应用。
## 9. `cs.AI` - 通过法官的眼睛：推断出的思维轨迹提高LLM评估者的可靠性 [PDF](https://arxiv.org/pdf/2510.25860), [HTML](https://arxiv.org/abs/2510.25860)
### Authors
Xingjian Zhang,Tianhong Gao,Suliang Jin,Tianhao Wang,Teng Ye,Eytan Adar,Qiaozhu Mei
### Background
大型语言模型（LLMs）被越来越多地用于评估任务，但它们在处理主观任务时的可靠性往往受到限制，尤其是当人类判断涉及超越标注标签的细微推理时。思维轨迹，即判断背后的推理，虽然非常有用，但收集和整理它们极具挑战性。该研究提出了一种人类-LLM合作框架，以从只标注的判断中推断出思维轨迹。该框架使用了简单而有效的拒绝采样方法，能够大规模重建这些思维轨迹。这些推断出的思维轨迹应用于两个互补的任务：(1) 细化开放的LLM评估者；(2) 为专有LLM评估者合成更清晰的注释指南。在多个数据集上，该方法显著提高了LLM与人类的协议度。此外，改进的注释指南也增加了不同LLM模型之间的协议度。研究表明，LLMs可以作为实用的代理，替代无法揭示的人类思考轨迹，从而使只标注的语料库得以扩展为思维轨迹增强资源，从而提高LLM评估者的可靠性。
### Innovation
提出了一种人类-LLM合作框架，通过简单有效的拒绝采样方法从只标注的判断中推断出思维轨迹，并将其应用于细化LLM评估者和合成更清晰的注释指南。这种方法显著提高了LLM与人类以及不同LLM模型之间的协议度，展示了LLMs作为无法揭示的人类思考轨迹的实用代理的能力。
### Conclusion
提出的框架使得LLMs可以作为实用的代理，替代无法揭示的人类思考轨迹，从而使只标注的语料库扩展为思维轨迹增强资源，增强了LLM评估者的可靠性。这种方法在多个数据集上取得显著效果，并且显示出在实际应用中的潜力。
## 10. `cs.AI` - 符号支撑式游戏设计：为生成式NPC对话设计角色敏感提示 [PDF](https://arxiv.org/pdf/2510.25820), [HTML](https://arxiv.org/abs/2510.25820)
### Authors
Vanessa Figueiredo,David Elumeze
### Background
大型语言模型（LLMs）有望通过使非玩家角色（NPCs）能够维持未编剧本的对话来改变互动游戏。然而，仍不清楚受限提示是否真的能提高玩家体验。通过对《Interview》——一个由GPT-4o提供动力的语音侦探游戏的研究，我们进行了一个包括10名参与者的小样本可用性研究，比较了高限制（HCP）和低限制（LCP）提示，研究发现除了由于技术故障导致的敏感性外，并没有发现可靠的经验差异。这促使我们重新设计HCP并引入了一种混合式JSON+RAG支架进行合成评估，以期通过早期验证补充可用性测试。研究发现支架效果在角色之间有所不同，采访者（任务给出NPC）稳定性增加，而嫌疑犯NPC的即兴真实度减少。这推翻了紧限制一定会增强游戏体验的假设。基于这一发现，我们提出了一种新的框架叫做‘符号支撑式游戏’，在其中符号结构通过模糊的数值边界来表达，以在需要保持连贯性的同时，保留即兴以维持参与感的余地。
### Innovation
我们提出了新的框架——‘符号支撑式游戏’（Symbolically Scaffolded Play），该框架通过模糊的数值边界来表达符号结构，既可以保障主题连贯性，又允许在让惊喜维持玩家参与的地方保持即兴创作。此外，我们通过混合式JSON+RAG支架重构了高限制提示，并进行了合成评估，通过一种早期验证的方法补充了用户可用性测试，发现支架效果在角色之间具有角色依赖性，即对不同角色表现出不同影响。
### Conclusion
我们认为，紧限制并不一定会增强游戏体验，而是需要更加角色敏感的提示设计。通过这种新的框架，我们希望能够更好地引导生成式NPC对话，同时保持角色的灵活性和玩家的沉浸感。
## 11. `cs.AI` - 可以人工智能变得问责吗？ [PDF](https://arxiv.org/pdf/2510.26057), [HTML](https://arxiv.org/abs/2510.26057)
### Authors
Andrew L. Kun
### Background
当前使用的人工智能非常强大，并且其力量正在迅速增长。如果要使其服务于消费者、选民和决策者的需求，那么人工智能必须是可问责的。可问责性的基本定义涉及论坛能否请求该代理关于其行为的信息、双方能否讨论这些信息以及对代理人进行处罚等方面。然而，在当今很多情况下，人工智能并没有达到可问责的要求——我们无法与其提问，无法与其进行讨论，更不用说对其进行处罚了。
### Innovation
作者将一般可问责性的定义应用于人工智能，并解释了什么情况下人工智能是可问责或不可问责的。还探讨了改善所有受到人工智能影响的人能够使人工智能对其负责的方法和途径。
### Conclusion
作者强调了为了使人工智能服务于更广泛的公众利益，使其对受到影响的人群可问责是至关重要的，并探讨了相关的解决方法。
## 12. `cs.AI` - 从查询到洞察：基于ReAct代理的时空文本到SQL管道 [PDF](https://arxiv.org/pdf/2510.25997), [HTML](https://arxiv.org/abs/2510.25997)
### Authors
Manu Redd,Tao Zhe,Dongjie Wang
### Background
自然语言到SQL(NL-to-SQL)系统有能力普及化的访问结构化数据，使用户无需学习SQL即可查询数据库。然而现有的系统在处理涉及空间和时间的复杂查询时面临挑战，这些查询要求通过模糊用户表述与特定模式分类对齐、处理时间推理以及选择适当的输出。
### Innovation
本文提出了一个基于代理的流水线，扩展了一个简单的文本到SQL基线（llama-3-sqlcoder-8b），通过基于Mistral的ReAct代理进行协调。该代理能够通过模式检查、SQL生成、执行和可视化工具进行规划、分解和适应查询。本文在一个包含纽约和东京检查点数据集的35个自然语言查询上进行了评估，这些查询涵盖了空间、时间和多数据集推理。与基线模型相比，代理显著提高了准确性，并通过地图、图表和结构化自然语言总结增强了用户体验。
### Conclusion
我们的设计支持缺乏SQL专业知识、详细模式知识或提示技能的用户进行更自然的人数据库交互。我们得出结论，代理协调而不是单纯强大的SQL生成器是交互式地理空间助手的潜在基础。
## 13. `cs.AI` - 超越基准：AI 推理的经济学 [PDF](https://arxiv.org/pdf/2510.26136), [HTML](https://arxiv.org/abs/2510.26136)
### Authors
Boqin Zhuang,Jiacheng Qiao,Mingqian Liu,Mingxing Yu,Ping Hong,Rui Li,Xiaoxia Song,Xiangjun Xu,Xu Chen,Yaoyao Ma,Yujie Gao
### Background
大规模语言模型（LLMs）的推理成本已成为决定其商业可行性和广泛应用的关键因素。本文提出了一种定量的推理经济学框架，将LLM的推理过程视为以计算为中心的智能生产活动。文章基于WiNEval-3.0的实证数据，分析了不同性能配置下的边际成本、规模经济和产出质量。
### Innovation
通过引入定量的推理经济学框架，将LLM的推理视作计算驱动的智能生产。基于WiNEval-3.0的数据，构建了首个'LLM推理生产前沿'，揭示了三个原则：边际成本递减、规模报酬递减以及成本效益最优区域。为模型部署决策提供了经济学基础，也为未来基于市场的AI推理资源定价和优化奠定了实证基础。
### Conclusion
本文不仅为模型部署决策提供了经济学基础，还为未来基于市场的AI推理资源定价和优化奠定了实证基础。
## 14. `cs.AI` - Large Language Model-assisted Autonomous Vehicle Recovery from Immobilization [PDF](https://arxiv.org/pdf/2510.26023), [HTML](https://arxiv.org/abs/2510.26023)
### Authors
Zhipeng Bao,Qianwen Li
### Background
尽管近年来自动驾驶汽车（AVs）取得了显著进步，但在某些需要人类司机熟练应对的交通场景中，它们仍然面临挑战。在这种情况下，AVs往往会陷入停滞，从而扰乱整体交通流动。当前的恢复解决方案，如远程干预（成本高且效率低）和手动接管（排除非司机和限制AV的可访问性），都是不充分的。
### Innovation
本文提出了一种名为StuckSolver的新颖的大语言模型（LLM）驱动的恢复框架，使AVs能够通过自我推理和/或乘客引导的决策来解决停滞场景。StuckSolver设计为插件式附加模块，位于AV现有的感知-规划-控制堆栈之上，无需修改其内部架构。它通过与标准传感器数据流接口来检测停滞状态、解释环境上下文并生成高级别的恢复命令，这些命令可以由AV本土规划器执行。
### Conclusion
我们通过Bench2Drive基准测试和自定义设计的不确定性场景对StuckSolver进行了评估。结果表明，仅通过自主自我推理，StuckSolver就能接近最先进的性能，并且在结合乘客指导时进一步提高性能。
## 15. `cs.AI` - GUI Knowledge Bench：揭示VLM在GUI任务中失败的知识差距 [PDF](https://arxiv.org/pdf/2510.26098), [HTML](https://arxiv.org/abs/2510.26098)
### Authors
Chenrui Shi,Zedong Yu,Zhi Gao,Ruining Feng,Enqi Liu,Yuwei Wu,Yunde Jia,Liuyu Xiang,Zhaofeng He,Qing Li
### Background
大型的视觉语言模型（VLMs）在GUI任务自动化方面取得了进展，但仍然落后于人类。这项差距我们认为是由于缺乏核心的GUI知识，现有的训练方案（如监督微调和强化学习）无法完全解决这一问题。通过分析常见的GUI任务执行失败模式，我们提炼出GUI知识的三个维度：（1）界面感知，识别控件和系统状态的知识；（2）交互预测，推理动作状态转换的知识；（3）指令理解，计划、验证和评估任务完成的知识。
### Innovation
我们提出了GUI Knowledge Bench，这是一个涵盖了Web、Android、MacOS、Windows、Linux、IOS六个平台和292个应用程序的多选择和是/非问题基准。评估显示，当前的VLMs能够识别控件功能，但在感知系统状态、预测动作和验证任务完成方面存在困难。实际的GUI任务实验进一步验证了GUI知识与任务成功之间的密切联系。我们通过提供一个结构化的框架来评估GUI知识，支持在下游训练前选择潜在更具潜力的VLMs，并为构建更具能力的GUI代理提供了有价值的见解。
### Conclusion
本研究通过为评估GUI知识提供一个结构化框架，支持在下游训练前选择更具潜力的VLMs，为构建更具能力的GUI代理提供了有价值的见解。
## 16. `cs.AI` - 从数学强化推理课程：培养大语言模型广泛推理能力 [PDF](https://arxiv.org/pdf/2510.26143), [HTML](https://arxiv.org/abs/2510.26143)
### Authors
Bo Pang,Deqian Kong,Silvio Savarese,Caiming Xiong,Yingbo Zhou
### Background
强化学习（RL）能够激发大语言模型（LLMs）的强大推理能力，然而大多数公开努力主要集中在数学和代码方面。该文提出了推理课程，这是一个简单的两阶段课程，旨在通过联合RL在多个领域培养和巩固推理技能。
### Innovation
本研究创新地提出了一种推理课程，这是一种两阶段的简单方法，首先通过数学相关的RL任务和验证奖励来培养基本的推理技能，然后再通过混合领域数据的联合RL来转移和巩固这些技能。这种方法不需要专门的奖励模型，而是依赖于标准的验证性检查。研究表明，这种方法在跨领域的推理任务中提供了持续的改进。
### Conclusion
实验证实在Qwen3-4B和Llama-3.1-8B上，推理课程带来了持续的改进。消融实验和认知技能分析表明，两个阶段都很必要，先从数学开始的推导提高了解决复杂问题所需的重要认知行为。推理课程提供了一种简明易用的一般推理方法。
## 17. `cs.AI` - Lean4Physics: Comprehensive Reasoning Framework for College-level Physics in Lean4 [PDF](https://arxiv.org/pdf/2510.26094), [HTML](https://arxiv.org/abs/2510.26094)
### Authors
Yuxin Li,Minghao Liu,Ruida Wang,Wenzhao Ji,Zhitao He,Rui Pan,Junming Huang,Tong Zhang,Yi R. Fung
### Background
物理问题的形式化推理对于自动化验证、教学和科研都有重要意义。目前鲜有针对大学物理级别的形式化推理框架（尤其是在Lean4中）。因此，构建一个全面的物理推理框架对于推进形式化物理推理的发展至关重要。现有的形式化物理推理框架主要集中在基本物理理论和简单问题上，缺乏大学级别的复杂物理问题的正式验证工具。
### Innovation
本文首次在Lean4中提出了一个全面的物理推理框架（Lean4PHYS）。该框架包括一个大学级别的物理形式化推理基准（LeanPhysBench），含有200个手工构建和同行评议的陈述，来源于大学教科书和物理竞赛题目。此外，该框架还引入了由社区驱动的‘PhysLib’资源库，包含进行正式物理推理所需的基本单位系统和定理。基于此基准和Lean4资源库，本研究报道了使用多个专家级和最新闭源模型的基线结果，展示了这些模型在击败先进模型上的局限性。特别地，引入的‘PhysLib’在模型性能增幅上平均实现了11.75%的提升，进一步证明了基准和资源库的有效性和挑战性。
### Conclusion
本研究首次构建了针对大学物理级别的形式化推理基准和资源库，并从实验中证明了这些工具的有效性和挑战性。这项工作为未来更复杂物理系统的形式化推理研究奠定了基础。
## 18. `cs.AI` - 所有工具使用场景均可用的一款模型：通过高效推理来奖励有agency的工具使用 [PDF](https://arxiv.org/pdf/2510.26167), [HTML](https://arxiv.org/abs/2510.26167)
### Authors
Renhao Li,Jianhong Tu,Yang Su,Hamid Alinejad-Rokny,Derek F. Wong,Junyang Lin,Min Yang
### Background
奖励模型（RMs）在使大型语言模型（LLMs）与人类偏好保持一致方面发挥着关键作用。但在工具学习领域，缺乏专门针对函数调用任务的RMs限制了朝着更高能力的有agency的AI的进步。本文背景在于这一领域的研究空白及其重要性。
### Innovation
本文介绍了一种名为ToolRM的轻量级生成奖励模型家族，专门针对通用工具使用场景。该模型采用了一种新颖的工作流程，通过基于规则的评分和多维采样构建双边偏好数据，从而生成了ToolPref-Pairwise-30K数据集。此外，还提出了TRBench$_{BFCL}$基准测试套件，用于评估工具使用RMs的能力。该模型在所构建数据上的训练效果显著优于包括Claude 4和OpenAI o3在内的前沿模型。
### Conclusion
本文展示了ToolRM在批判任务上的有效性与效率，通过ACEBench实验突出其优势，包括扩展和自纠正等更广泛的批判任务。此外还介绍了模型的推理时间扩展能力，并将输出令牌使用量降低了66%以上。数据和模型检查点的公开有助于未来的研究。
## 19. `cs.AI` - FM Agent [PDF](https://arxiv.org/pdf/2510.26144), [HTML](https://arxiv.org/abs/2510.26144)
### Authors
Annan Li,Chufan Wu,Zengle Ge,Yee Hin Chong,Zhinan Hou,Lizhe Cao,Cheng Ju,Jianmin Wu,Huaiming Li,Haobo Zhang,Shenghao Feng,Mo Zhao,Fengzhi Qiu,Rui Yang,Mengmeng Zhang,Wenyi Zhu,Yingying Sun,Quan Sun,Shunhao Yan,Danyu Liu,Dawei Yin,Dou Shen
### Background
大型语言模型（LLMs）正在推动自主AI研究代理的发展，用于科学和技术发现。FM Agent 是一种新颖且通用的多代理框架，结合了LLM推理和大规模演化搜索，以解决复杂的现实世界挑战。它主要通过几次创新，包括冷启动初始化阶段，引入专家指导；迭代优化的新颖演化抽样策略；结合正确性、效果和LLM监督反馈的领域特定评估器；以及基于Ray构建的分布式异步执行基础设施。该系统已经跨不同的领域进行了评估，包括运筹学、机器学习、GPU内核优化和经典数学问题。
### Innovation
1) 冷启动初始化阶段，引入专家指导；2) 迭代优化的新颖演化抽样策略；3) 结合正确性、效果和LLM监督反馈的领域特定评估器；4) 基于Ray构建的分布式异步执行基础设施；
### Conclusion
FM Agent在跨多个领域的多项测试中达到了最先进的结果，无需人类解释或调整。它不仅在学术基准测试中表现出色，在大规模企业研发流程和基础科学研究中也显示出巨大潜力，可以加速创新，自动化复杂的发现过程，并带来重大的工程技术和社会科学进步。
## 20. `cs.AI` - AutoSurvey2：为研究人员提供高级自动化文献综述 [PDF](https://arxiv.org/pdf/2510.26012), [HTML](https://arxiv.org/abs/2510.26012)
### Authors
Siyi Wu,Chiaxin Liang,Ziqian Bi,Leyi Zhao,Tianyang Wang,Junhao Song,Yichao Zhang,Keyu Chen,Xinyuan Song
### Background
研究文献的快速增长，特别是在大规模语言模型（LLMs）领域，使得编写全面和及时的综述论文越来越困难。现有的综述方法面临数据处理量大、信息更新不及时等挑战，导致难以覆盖所有相关文献并保证准确性。这些挑战使得自动化综合现这篇论文介绍了一个名为autosurvey2的多阶段管道，该管道通过检索增强的综合和结构化评估自动化综述生成。该系统结合了并行部分生成、迭代细化以及实时检索近期出版物，以确保内容的完整性和准确性。质量评估使用了一种多语言模型评价框架，该框架衡量覆盖范围、结构和相关性，与专家审查标准一致。实验结果显示，autosurvey2在结构连贯性和主题相关性方面始终超越现有的基于检索和自动化的基线方法，同时保持了较强的引文准确性。这些结果表明，通过将检索、推理和自动化评估结合到一个统一框架中，autosurvey2提供了一种可扩展和可重现的解决方案，用于生成长篇学术综述，并为自动化学术写作的未来研究提供坚实的基础。
### Innovation
autosurvey2通过检索增强的综合和结构化评估实现了自动化的文献综述生成。该系统包括并行部分生成、迭代细化以及实时检索最近的文章。与现有的基于检索和自动化的基线方法相比，autosurvey2在结构连贯性和主题相关性方面表现出色，并保持了显著的引文忠实度。一种多语言模型评价框架用于质量评估，该框架在覆盖范围、结构和相关性方面与专家审查标准对齐。这种方法提供了一种可扩展和可重现的解决方案，为长期性的学术综述提供支持，同时促进了自动化学术写作的未来研究。
### Conclusion
通过将检索、推理和自动化评估结合到一个统一的框架中，autosurvey2提供了一种可扩展和可重现的解决方案，用于生成长篇学术综述，并为自动化学术写作的未来研究奠定坚实的基础。所有代码和资源均可在[this https URL]访问。
## 21. `cs.AI` - 问卷遇上大语言模型：理解问题与回答的结构能力基准及实证研究 [PDF](https://arxiv.org/pdf/2510.26238), [HTML](https://arxiv.org/abs/2510.26238)
### Authors
Duc-Hai Nguyen,Vijayakumar Nanjappan,Barry O'Sullivan,Hoang D. Nguyen
### Background
每天有数百万人参与各种调查，如市场调查、学术研究、医学问卷和客户反馈表等。这些数据集提供了宝贵的信息，但其规模和结构对大语言模型（LLMs）提出了挑战，尽管LLMs在处理开放式文本时表现出色。然而，它们在处理问卷数据或数百个应答者的列表方面的能力仍未充分探究。现有的调研数据分析工具，如Qualtrics、SPSS、REDCap，通常为工作流程中的人类设计，限制了这些数据与LLM和AI自动化集成的可能性。这让科学家、调研员和普通用户缺乏基于证据的数据表示方法指导，以优化对LLM的数据呈现方式。
### Innovation
我们通过引入QASU（问卷分析和结构理解）基准，挑战六种结构技能，包括答案查找、受访者数量、多跳推理等，涵盖六种序列化格式和多种提示策略。实验表明，选择有效的格式和提示组合可将准确度提高8.8个百分点，而对于特定任务，通过自增强提示精简添加轻量级结构提示，平均可再提高3-4个百分点。我们开源的基准通过系统性地隔离格式和提示效果，提供了一个简单而灵活的基础，用于推动基于LLM的问卷分析研究和实践。
### Conclusion
我们的研究提供了一个简单但实用的基础，以系统地研究和优化LLM对问卷数据的理解，可以促进相关研究和实际操作的进步。
## 22. `cs.AI` - 增强检索生成功能的分布式大语言模型代理以实现应急车辆适用的泛化交通信号控制 [PDF](https://arxiv.org/pdf/2510.26242), [HTML](https://arxiv.org/abs/2510.26242)
### Authors
Xinhang Li,Qing Guo,Junyu Chen,Zheng Guo,Shengzhe Xu,Lei Li,Lin Zhang
### Background
随着城市交通复杂性的增加，交通信号控制（TSC）对于优化交通流量和提高道路安全变得至关重要。大型语言模型（LLMs）因其在TSC中的潜力而备受关注。然而，它们在紧急情况下的易出错性导致了不可靠的决策，可能会对应急车辆造成显著延误。此外，不同类型的交叉口对交通状态编码和跨交叉口的训练带来了巨大挑战，限制了其在异构交叉口上的泛化能力。
### Innovation
本文提出了一个称为RETRIEVAL AUGMENTED GENERATION (RAG)-增强分布式LLM代理以实现应急车辆适用的泛化交通信号控制（REG-TSC）。该方法主要包括：1) 提出一种应急意识推理框架，该框架能够根据紧急情况动态调整推理深度，并配备了一种新型的基于审查员的紧急检索增强生成(Review Emergency RAG, RERAG)，通过从历史案例中提炼特定知识和指导，增强代理在紧急情况下的决策的可靠性和合理性。2) 设计一种通用类型的交通表示，并提出了一种基于奖励的强化精炼(Reward-guided Reinforced Refinement, R3)方法，适应性地从多种交叉口中采样训练经验，并根据环境反馈优先级进行微调，引导REG-TSC趋向于高效的策略。
### Conclusion
在三个包含17到177个异构交叉口的实际道路网络上进行的广泛实验表明，REG-TSC相比于其他先进方法分别减少了42.00%的行程时间、62.31%的排队长度，以及83.16%的应急车辆等待时间。
## 23. `cs.AI` - 在UCT搜索树中通过动作修剪发现状态等价性 [PDF](https://arxiv.org/pdf/2510.26346), [HTML](https://arxiv.org/abs/2510.26346)
### Authors
Robin Schmöcker,Alexander Dockhorn,Bodo Rosenhahn
### Background
提高蒙特卡洛树搜索（MCTS）的效果之一是通过组合或抽象化状态或状态-动作对来提升样本效率，并在同一组内共享统计信息。虽然在诸如On the Go Abstractions in Upper Confidence bounds applied to Trees (OGA-UCT)这类算法中容易找到状态-动作对的抽象化方法，但在噪声较大或动作空间较大的情况下，状态的抽象化方法几乎不存在。已有理论和实验证据支持这一观点，提出了一个弱化状态抽象条件的方法，通过在准确性上做出一定程度的牺牲来发现更多抽象化的方法。
### Innovation
在OGA-UCT（On the Go Abstractions in Upper Confidence bounds applied to Trees）中使用一种状态-动作对抽象化框架（ASAP），我们提出了一种新的方法即理想修剪抽象化在UCT中（IPA-UCT），它通过动作修剪来发现状态等价性。这种新方法在不同的测试领域和迭代预算中都比OGA-UCT及其衍生方法表现出更优的效果。此外，还定义了一种更通用的抽象化框架p-ASAP，以及ASASAP框架，是p-ASAP的特例。
### Conclusion
通过理想修剪抽象化在UCT中（IPA-UCT）改善了状态抽象的问题，并在广泛的测试环境中优于OGA-UCT及其衍生方法。
## 24. `cs.AI` - LLM智能体训练中的Graph-增强策略优化 [PDF](https://arxiv.org/pdf/2510.26270), [HTML](https://arxiv.org/abs/2510.26270)
### Authors
Jiazhen Yuan,Wei Zhao,Zhengbiao Bai
### Background
基于群体的强化学习（RL）在复杂推理和数学任务上取得了显著成果，但在训练多轮交互式LLM智能体时，这些方法通常会遇到结构盲点的问题，即无法利用环境的潜在连接性。这体现在三个关键挑战中：（1）无效率且不指导的探索，（2）由于忽视关键状态而导致精确度不高的信用分配，（3）由于静态奖励折扣而导致的短视规划。这些问题是由于缺乏对环境结构的建模造成的。
### Innovation
我们提出了Graph-增强策略优化（GEPO），这是一种动态构建从智能体经验中生成的状态转换图的方法，并运用图论中心性为提供三种协同学习信号：（1）结构化的内在奖励，引导探索到高影响状态，（2）一种图增强的优势函数，提高拓扑意识的信用分配，（3）一个根据状态的战略价值动态调整的折扣因子。这项技术在ALFWorld、WebShop和自主构建的工作台基准测试中表现出色，对比竞争性基线模型，取得绝对成功率增幅分别为+4.1%、+5.3%和+10.9%。从而证明了明确建模环境结构是一个可靠且通用的策略，有助于提升LLM智能体训练效果。
### Conclusion
通过GEPO技术，可以促使智能体更好地进行探索，更加精准地进行信用分配，以及更加灵活地制定策略，从而显著提高其在复杂环境中的表现。未来的研究可以进一步探索如何结合更多维度的信息来优化智能体的行为策略。
## 25. `cs.AI` - AI数学家作为推进数学发现的合作伙伴——以 Homogenization 理论为例 [PDF](https://arxiv.org/pdf/2510.26380), [HTML](https://arxiv.org/abs/2510.26380)
### Authors
Yuanhang Liu,Beichen Wang,Peng Li,Yang Liu
### Background
人工智能（AI）已经在数学推理方面取得了显著的进步，但在数学研究的实际操作中应用仍然有限。本文探讨了AI Mathematician（AIM）作为一种研究伙伴的角色，而非仅仅作为问题解决者。研究聚焦于homogenization理论中的一个复杂问题，通过AIM的自主推理轨迹分析，结合人类的干预措施，逐步将问题分解为可处理的子目标，选择合适的分析方法，验证中间结果，展示了人类直觉与机器计算可以互补的过程。这种方法增强了推理结果的可靠性和可解释性，并保留了人类对形式严谨性与正确性的监督。
### Innovation
本文提出了一种系统化的AI和人类共推理的方法，该方法通过迭代分解问题、选择适当的方法和验证中间结果，揭示了人类直观与机器计算的互补性，通过合作模式提高了推理结果的可靠性和可解释性。这种方法不仅生成了一个完全可验证的证明，还展示了如何通过系统化的合作模式推进数学发现的前沿。
### Conclusion
本文通过合作方式推进了数学发现的前沿，展示了AI与人类协作如何提升数学证明的可靠性和可解释性，同时保留了人类在形式严谨性与正确性方面的监督角色。通过这种系统性的人机共推理方法，生成了完整且可验证的证明，开创了数学研究的新范式。
## 26. `cs.AI` - BOTS: 一种用于大语言模型强化微调的贝叶斯在线任务选择统一框架 [PDF](https://arxiv.org/pdf/2510.26374), [HTML](https://arxiv.org/abs/2510.26374)
### Authors
Qianli Shen,Daoyuan Chen,Yilun Huang,Zhenqing Ling,Yaliang Li,Bolin Ding,Jingren Zhou
### Background
强化微调（RFT）是将大型语言模型（LLMs）与人类偏好对齐并增强推理能力的关键技术。然而，其效果高度依赖于训练期间探索的任务类型。均匀的任务采样是低效的，会浪费计算资源在简单或不可解的任务上，而现有任务选择方法通常存在高昂的展开成本、不良适应性和不完整的证据。因此，需要一种具有高效率和良好适应性的任务选择框架来解决这些问题。
### Innovation
提出了一种名为 BOTS 的框架，它是一种用于大语言模型强化微调的贝叶斯在线任务选择统一方法。BOTS 通过贝叶斯推断动态维护随模型演进的任务难度后验估计。该方法结合了从选择的任务中获取的显式证据和从未选择的任务中推断的隐式证据，使用汤普森采样确保探索和利用之间的平衡。通过一种极轻量的基于插值的插件来实用化隐式证据，该插件无需额外展开即可估计未评估任务的难度，增加了几乎零的额外负担。在不同领域和大语言模型规模上，BOTS 在数据效率和性能上都优于基准和变体，提供了一种实用且可扩展的动态任务选择方案
### Conclusion
BOTS 提供了一种实用且可扩展的动态任务选择方案，能够有效提升大语言模型的强化微调效果，在不同领域和模型规模上表现出显著的数据效率和性能改进。
## 27. `cs.AI` - Scales++: 通过认知规模嵌入实现计算效率的评估子集选择 [PDF](https://arxiv.org/pdf/2510.26384), [HTML](https://arxiv.org/abs/2510.26384)
### Authors
Andrew M. Bean,Nabeel Seedat,Shengzhuang Chen,Jonathan Richard Schwarz
### Background
评估大型语言模型（LLMs）的高昂成本推动了小而具代表性的数据子集（即小型基准测试）的构建，这些子集可以提高评估效率并保留预测准确性。现有方法着重于模型性能，存在前期成本高、无法立即处理新基准（冷启动）和对未来模型共享先前模型失败模式的脆弱假设等问题。因此需要一种更高效的方法来选择基准测试的子集，基于任务项目本身的内在属性，而不是特定模型的失败模式来进行选择。
### Innovation
作者提出了一种基于项目（item-centric）的基准测试子集选择方法，通过一种名为Scales++的新方法，根据基准样本的认知需求来进行数据选择。该方法降低了初步选择成本超过18倍，并实现了竞争力的预测准确性。在Open LLM Leaderboard上，仅使用0.5%的数据子集，就能以2.9%的平均绝对误差预测完整基准分数，并展示了这种方法能够实现更高效模型评估，提供更好的冷启动性能和更具解释性的基准测试的优点。
### Conclusion
该工作提出的方法能够不显著降低准确性的前提下提高模型评估效率，同时提供更好的冷启动性能和更具解释性的基准测试，解决了现有方法的一些局限性。
## 28. `cs.AI` - AI代理视角下的智能机器人格 [PDF](https://arxiv.org/pdf/2510.26396), [HTML](https://arxiv.org/abs/2510.26396)
### Authors
Joel Z. Leibo,Alexander Sasha Vezhnevets,William A. Cunningham,Stanley M. Bileschi
### Background
随着代理型人工智能（AI）的兴起，社会将面临大量新型人格的涌现。传统上，人格被认为是可发现的、形而上的属性，但本文提出将其视为一种由社会授予实体的、灵活义务集合（权利与责任）。这种思考方式旨在通过解决具体治理问题为不同情境提供定制化解决方案。
### Innovation
本文创新性地提出了一个实用框架，建议在解决实际治理问题时可以不拘泥于基础问题的探讨，如AI的意识或理性，而通过重新定义人格来解决问题。具体而言，该框架强调通过松散的义务集合来为AI代理分配具体的权利和责任，从而为制定具体工具（如促进AI合约）提供可能。
### Conclusion
文章建议应放弃寻求单一、本质定义的人格概念，转而采用更加实用和灵活的方式来整合AI代理到社会中，这有助于应对基于去中心化数字身份技术的人格塑造带来的新模式与新挑战。
## 29. `cs.AI` - Autograder+: 多维度的AI框架以促进编程教育中的丰富教学反馈 [PDF](https://arxiv.org/pdf/2510.26402), [HTML](https://arxiv.org/abs/2510.26402)
### Authors
Vikrant Sahu,Gagan Raj Gupta,Raghav Borikar,Nitin Mane
### Background
编程教育的迅速增长已经超过了传统的评估工具，给教师提供了有限的手段来提供有意义且可扩展的反馈。传统的自动评分系统虽然高效，但作为黑箱系统，只能返回通过或未通过的结果，缺乏对学生思维和学习需求的洞察。
### Innovation
Autograder+ 旨在将自动评分从单纯的总结性过程转变为形成性学习体验。它引入了两种关键功能：使用微调的大语言模型自动生成反馈，以及可视化学生代码提交以揭示学习模式。该模型使用学生代码和专家反馈进行微调，以确保与教学目标相关的、有上下文的指导。该系统还支持提示池功能，允许教师通过选择的提示模板指导反馈风格。
### Conclusion
通过整合AI驱动的反馈、语义聚类和交互式可视化，Autograder+减少了教师的工作负担，同时支持针对性的教学并促进更强的学习成果。
## 30. `cs.AI` - 谁拥有最终决定权？ChatGPT选择中的从众动态 [PDF](https://arxiv.org/pdf/2510.26481), [HTML](https://arxiv.org/abs/2510.26481)
### Authors
Clarissa Sabrina Arlinghaus,Tristan Kenneweg,Barbara Hammer,Günter W. Maier
### Background
大型语言模型（LLMs）如ChatGPT越来越多地被集成到高风险决策中，但很少有人了解这些模型是否容易受到社交影响的影响。本文通过三项事先注册的从众实验，研究了GPT-4在招聘背景下的从众行为。
### Innovation
本文通过GPT-4的三项事先注册的从众实验，揭示了ChatGPT在面对不同社交压力时的从众动态，详细探讨了GPT-4的决策过程是否受到社交影响，以及这些影响如何影响其最终选择。
### Conclusion
研究结果表明，GPT-4并不是独立的观察者，而是会根据感知到的社会共识进行调整。这些发现强调了不应将LLMs视为中立的决策辅助工具，并强调了在暴露给人类意见之前先获取AI判断的必要性。
## 31. `cs.AI` - MedSAE: 使用稀疏自编码器剖析MedCLIP表示 [PDF](https://arxiv.org/pdf/2510.26411), [HTML](https://arxiv.org/abs/2510.26411)
### Authors
Riccardo Renzulli,Colas Lepoutre,Enrico Cassano,Marco Grangetto
### Background
医学人工智能需要准确且可解释的模型。为此，研究者们正在探索利用医学视图（如胸部X光片）和相关报告来提高医学图像解释的可解释性。当前，方法包括应用Medical Sparse Autoencoders (MedSAEs) 到MedCLIP（一种基于胸部X光片和报告训练的视觉-语言模型）的潜在空间中。为了量化解释度，本文提出了一种结合相关性指标、熵分析和通过MedGEMMA基础模型自动命名神经元的评估框架。
### Innovation
本文创新性地使用了MedSAEs来解释MedCLIP模型的潜在空间中的表示。通过结合相关性指标、熵分析和命名技术，研究者们开发了一种新的评估框架来量化解释度。实验表明，MedSAE神经元相比原始MedCLIP特征表现出更高的单义性和可解释性。
### Conclusion
研究证明了高性能医学AI和透明度之间的联系，提供了向临床上可靠的表示规模化的步骤。
## 32. `cs.AI` - 链推理劫持 [PDF](https://arxiv.org/pdf/2510.26418), [HTML](https://arxiv.org/abs/2510.26418)
### Authors
Jianli Zhao,Tingchen Fu,Rylan Schaeffer,Mrinank Sharma,Fazl Barez
### Background
大型推理模型(LRMs)通过分配更多的推理时间计算来提高任务性能，之前的研究表明，这种扩展的推理也可能通过提升拒绝错误来加强安全性。然而，作者发现实际情况恰恰相反，同样的推理可以在不激活安全措施的情况下被绕过。
### Innovation
作者引入了一种名为链推理劫持(Chain-of-Thought Hijacking)的攻击方法，这是一种针对推理模型的越狱攻击。此攻击通过在有害请求中添加大量的无害推理序列来执行劫持，并在HarmBench上实现了99%、94%、100%和94%的攻击成功率，远超针对LRMs的先前越狱方法。进一步分析表明，中期层编码了安全性检查的强度，而后期层编码了验证结果，这解释了为何长的良性链推理能够分散注意力，从而稀释这两种信号。
### Conclusion
研究结果表明，表达性最强的形式推理——显式的链推理（CoT）——可以成为一种越狱途径，尤其是在与最终答案提示相结合的情况下。研究团队发布了提示、输出和仲裁决策，以促进复制研究。
## 33. `cs.AI` - LINK-KG：由LLM驱动的参考解析知识图谱用于人口走私网络 [PDF](https://arxiv.org/pdf/2510.26486), [HTML](https://arxiv.org/abs/2510.26486)
### Authors
Dipak Meher,Carlotta Domeniconi,Guadalupe Correa-Cabrera
### Background
人口走私网络是复杂的、不断演变的，因此很难进行全面分析。法律案件文档提供了有关这些网络的丰富事实和程序性见解，但由于文档通常较长、无结构化且充满了模糊或变化的引用，这对自动构建知识图谱提出了巨大挑战。现有的方法要么忽视了指代消解，要么无法扩展到短文本片段之外，导致碎片化的图谱和不一致的实体链接。
### Innovation
本文提出了一种名为LINK-KG的模块化框架，该框架整合了一个三阶段的LLM引导的指代消解流水线和下游的知识图谱提取。核心是一个类型特定的Prompt缓存，它能够跨文档片段持续跟踪和解决引用，从而为从短全文本和长文章构造结构化知识图谱创造清晰且去除了歧义的叙述。LINK-KG与基准方法相比，平均节点重复减少了45.21%，噪声节点减少了32.22%，构建了更加干净和连贯的图谱结构。
### Conclusion
这些改进确立了LINK-KG作为分析复杂犯罪网络的强大基础。
## 34. `cs.AI` - 代理组织的时代：利用语言模型学习组织 [PDF](https://arxiv.org/pdf/2510.26658), [HTML](https://arxiv.org/abs/2510.26658)
### Authors
Zewen Chi,Li Dong,Qingxiu Dong,Yaru Hao,Xun Wu,Shaohan Huang,Furu Wei
### Background
本文构想了人工智能的新时代，称为代理组织，其中代理通过协作和同时工作解决复杂问题，从而产生超越个体智能的结果。为了实现这一愿景，作者引入了异步思考(AsyncThink)作为一种新的大规模语言模型推理范式，该范式将内部思维过程组织成可并发执行的结构。
### Innovation
作者提出了一个思考协议，其中组织者动态分配子查询给工人，合并中间知识，并生成一致的解决方案。更重要的是，该协议中的思考结构可以通过强化学习进一步优化。实验表明AsyncThink的推理延迟比并行思考低28%，并且在数学推理方面提高了准确性。此外，AsyncThink能利用其学习到的异步思考能力，有效应对未见过的任务，而无需额外的训练。
### Conclusion
AsyncThink通过一种新的协议和优化方法，在解决复杂问题时证明了其高效性和灵活性。.Future research can explore further applications and improvements in this domain.
## 35. `cs.AI` - EdgeRunner 20B: 在边缘运行的同时与GPT-5在军事任务上达到平齐 [PDF](https://arxiv.org/pdf/2510.26550), [HTML](https://arxiv.org/abs/2510.26550)
### Authors
Jack FitzGerald,Aristotelis Lazaridis,Dylan Bates,Aman Sharma,Jonnathan Castillo,Yousif Azami,Sean Bailey,Jeremy Cao,Peter Damianov,Kevin de Haan,Luke Kerbs,Vincent Lu,Joseph Madigan,Jeremy McLaurin,Jonathan Tainer,Dave Anderson,Jonathan Beck,Jamie Cuticello,Colton Malkerson,Tyler Saltsman
### Background
本文介绍了EdgeRunner 20B，这是针对军事任务优化的GPT-20B微调版本。模型在160万条高质量记录的基础上进行训练，这些记录是从军事文档和网站中精选出来的。此外，还介绍了四个新的测试集：战斗兵种、战斗医辅、网络战和mil-bench-5k（一般军事情报）。
### Innovation
EdgeRunner 20B在针对军事任务的测试集上与其他模型相当或更优，尤其是在与GPT-5任务的对比中。在同类任务上对比GPT-20B，EdgeRunner 20B在通用基准测试（如ARC-C, GPQA Diamond, GSM8k, IFEval, MMLU Pro or TruthfulQA）中的表现无显著下降，只是在GSM8k低推理设置下有细微差别。
### Conclusion
研究结果表明，小型、本地托管的模型是敏感数据操作（如军事领域）的理想解决方案，可以部署在隔离的边缘设备上。
## 36. `cs.AI` - 人机互补：增强监督的目标 [PDF](https://arxiv.org/pdf/2510.26518), [HTML](https://arxiv.org/abs/2510.26518)
### Authors
Rishub Jain,Sophie Bridgers,Lili Janzer,Rory Greig,Tian Huey Teh,Vladimir Mikulik
### Background
人类反馈对于使AI系统与人类价值观对齐至关重要。随着AI能力的提升和AI被用于解决更加复杂的任务，确保质量和安全变得越来越困难。本文探讨了如何利用AI提高人类监督的质量。我们研究了对AI输出进行事实验证这一对人类来说已经具有挑战性的安全问题。研究发现，结合AI评分和基于AI评分器信心的人类评分比单独依赖其中任何一个都更优。给予人类AI事实验证助手可以进一步提高其准确性，但这种助手的类型很重要。显示AI解释、信心和标签会导致过度依赖，而仅仅展示搜索结果和证据则能培养更合适的信任。这些结果对增强监督——即使AI超越人类专家表现仍然将人类与AI结合监督AI系统——提出了重要启示。
### Innovation
本文提出了结合AI事实验证与人类评估的方法，并通过实验展示了这种结合方式相比于单独依赖AI或人类评估的优越性。此外，研究还发现，不同形式的AI助手对人类监督准确性的影响不同，要选择合适的方式提升信任水平。
### Conclusion
人类与AI的结合监督（Amplified Oversight）是现有研究的一个重要挑战。通过AI事实验证助手，虽然可以提高准确性，但重要的是选择合适的辅助方式，这样既可以发挥AI的优点，又能避免人类监督依赖的缺点。
## 37. `cs.AI` - 大型语言模型中的规范推理：从逻辑和模态视角的比较基准 [PDF](https://arxiv.org/pdf/2510.26606), [HTML](https://arxiv.org/abs/2510.26606)
### Authors
Kentaro Ozeki,Risako Ando,Takanobu Morishita,Hirohiko Abe,Koji Mineshima,Mitsuhiro Okada
### Background
大型语言模型（LLMs）在各种推理任务中表现出色，但它们处理规范推理的能力尚未得到充分探索。规范推理涉及义务和许可等规范性或义务模态。已有研究主要集中在LLMs在不同推理任务中的表现，但对规范推理能力的研究还较少。
### Innovation
本研究从逻辑和模态视角系统性地评估了LLMs在规范推理领域的推理能力，并引入了一个新的数据集，该数据集覆盖了规范和认知领域中广泛的形式推理模式，同时结合了影响人类推理的非形式认知因素。通过将规范推理与知识模态进行比较，揭示了LLMs在规范推理中保持有效的推理模式但存在特定类型的不一致和认知偏差。
### Conclusion
虽然LLMs通常遵循有效的推理模式，但在特定类型的规范推理中仍然存在不一致，并表现出与人类推理中类似的心理学观察到的认知偏差。这些发现突显了在LLMs的规范推理中实现逻辑一致性的挑战，并为提高其可靠性提供了见解。所有数据和代码都已公开发布。
## 38. `cs.AI` - Context Engineering 2.0: The Context of Context Engineering [PDF](https://arxiv.org/pdf/2510.26493), [HTML](https://arxiv.org/abs/2510.26493)
### Authors
Qishuo Hua,Lyumanshan Ye,Dayuan Fu,Yang Xiao,Xiaojie Cai,Yunze Wu,Jifan Lin,Junfei Wang,Pengfei Liu
### Background
卡尔·马克思曾写道，‘人的本质是一切社会关系的总和’，这表明个体不是一个孤立的实体，而是通过与他人的互动而根本上形成的，这些互动的背景在构成中起着核心作用。随着计算机和人工智能的出现，这些背景不再局限于人与人之间的互动，也包括了人与机器之间的互动。因此，一个核心问题出现了：机器如何更好地理解我们的状况和目的？为应对这一挑战，研究人员最近引入了情境工程的概念。尽管它通常被视为智能代理时代的一个近期创新，但本文作者认为，相关实践可以追溯到20多年前。自20世纪90年代初以来，该领域经历了不同的历史阶段，每个阶段都受到机器智能水平的影响：从早期基于原始计算机的人机互动框架，到今天由智能代理驱动的人机互动范式，未来的可能性可能是人类级别或超人类智能。
### Innovation
本文将情境工程置于其历史和概念背景中，提供了一个系统的定义，并概述了其发展历程。同时，文章还探讨了实践中的关键设计考量因素，旨在为情境工程提供概念基础，并勾勒出其有希望的未来。
### Conclusion
通过解决这些问题，本文旨在为情境工程提供概念基础，并为之勾勒出一个广阔的未来发展图景。该文章是向广泛社区在人工智能系统中系统化地进行情境工程努力的一个重要步骤。
## 39. `cs.AI` - 具代理AI的家庭能源管理系统：用于住宅负载调度的大语言模型框架 [PDF](https://arxiv.org/pdf/2510.26603), [HTML](https://arxiv.org/abs/2510.26603)
### Authors
Reda El Makroum,Sebastian Zwickl-Bernhard,Lukas Kranzl
### Background
电力建设需要显著提升住宅能源响应能力，但家庭能源管理系统(HEMS)的采用仍受限于用户交互障碍，需要将日常偏好转化为技术参数。虽然大语言模型已被应用于能源系统的代码生成和参数提取，但目前尚无实施利用大语言模型作为自主协调管理从自然语言输入到多设备调度整个工作流程的系统。
### Innovation
本文提出了一种能够自主协调多设备调度的具代理AI HEMS，通过自然语言请求实现无需示范即可达到最优调度。架构结合了一个调度器和三个专家代理，利用ReAct模式进行迭代推理，可在没有硬编码工作流的情况下实现动态协调，同时整合Google日历以进行上下文感知的任务截止日期提取。评估表明，Llama-3.3-70B能够成功协调所有设备以匹配通过混合整数线性规划计算的成本最优基准，其他模型尽管在单设备上表现完美但在同时协调所有设备方面存在困难。渐进式提示工程实验表明，即使具备广泛推理能力，模型在处理具有分析性查询时需要显式的指导仍不可靠。
### Conclusion
完整系统及其调度逻辑、代理提示、工具和Web界面均已开源，以促进可复制性、拓展和未来研究。
## 40. `cs.AI` - 跨平台基础模型推理能力评估 [PDF](https://arxiv.org/pdf/2510.26732), [HTML](https://arxiv.org/abs/2510.26732)
### Authors
J. de Curtò,I. de Zarzà,Pablo García,Jordi Cabot
### Background
本文综合评估了现代基础模型的推理能力，跨越了高性能计算超级计算机（MareNostrum 5）、云平台（Nebius AI Studio）和大学集群（八块H200 GPU节点）三种计算范式。通过三个实验阶段评估15个基础模型在79个问题上的表现，这些问题涵盖了八个学术领域（物理、数学、化学、经济学、生物学、统计学、微积分和优化）。
### Innovation
提出了跨基础设施基准评估方案；涵盖了三种不同的计算平台；挑战了传统的模型缩放假设，确定了训练数据质量比模型大小更为关键；建立了适用教育、生产和研究场景的选择指导方针；开发了三基础设施方法论和79个问题基准，用于纵向追踪基础模型推理能力的发展趋势。
### Conclusion
研究结果挑战了传统的模型缩放假设，强调了训练数据质量的关键作用，并提供了跨教育、生产和研究场景的选择指导。跨基础设施的方法和问题基准有助于追踪基础模型推理能力的发展变化。
## 41. `cs.AI` - 通过注意力键空间分析揭示多模态大语言模型中的固有文本偏见 [PDF](https://arxiv.org/pdf/2510.26721), [HTML](https://arxiv.org/abs/2510.26721)
### Authors
Xinhan Zheng,Huyu Wu,Xueting Wang,Haiyun Jiang
### Background
多模态大语言模型（MLLMs）在处理视觉语言数据时倾向于优先处理文本输入，限制了它们利用视觉证据进行有效推理的能力。现有的研究通常将这种对文本的偏好归因于外部因素，如数据不平衡或指令调整，但本研究认为，这种偏好源于模型内部的架构。模型中的视觉键向量（Visual Keys）在语言单独预训练过程中学到的文字关键空间之外，导致这些视觉键在注意力计算中收到系统性的较低相似度评分，从而在上下文表示中被下利用。
### Innovation
本研究通过提取LLaVA和Qwen2.5-VL的关键向量，并使用定性（t-SNE）和定量（Jensen-Shannon 误差）方法分析其分布结构来验证这一假设。结果提供了直接证据，显示视觉和文本键占据着明显不同的亚空间。并且，跨模态的差异统计上显著，远超同模态内部变异。这些发现揭示了文本偏好源自注意力键空间的内在不匹配，而非仅由外部数据因素引起。
### Conclusion
本文的研究结果表明，MLLMs 中的文本偏好是由于其内部注意力键空间的固有对齐问题导致的，而非仅仅是由于外部数据因素造成的。
## 42. `cs.AI` - LLMs 使用通用筛选头处理列表 [PDF](https://arxiv.org/pdf/2510.26784), [HTML](https://arxiv.org/abs/2510.26784)
### Authors
Arnab Sen Sharma,Giordano Rogers,Natalie Shapira,David Bau
### Background
本文探讨了一系列LLM列表处理任务背后的机制，发现LLMs 学会了一种紧凑且因果性的表示通用筛选操作的方法，这种操作与功能编程通用的“筛选”函数类似。
### Innovation
作者利用因果中介分析，发现少量注意力头，称为筛选头，能够在其特定词的位置处的查询状态中编码筛选谓词的紧凑表示。这一谓词表示是通用且可移植的：它可以被提取并重新应用于在不同集合、不同格式、语言或任务上执行相同的筛选操作。
### Conclusion
但作者也指出，Transformer LMs 在某些筛选策略上使用不同策略：即对项目是否满足谓词进行急切评估，并直接将中间结果作为标志存储在项目表示中。本文发现Transformer LMs 可以开发出易于人类理解的抽象计算操作实现，并且这些操作的泛化方式与传统函数编程模式中使用的方式惊人地相似。
## 43. `cs.AI` - 代理授权以限制任务到范围匹配的语义 [PDF](https://arxiv.org/pdf/2510.26702), [HTML](https://arxiv.org/abs/2510.26702)
### Authors
Majed El Helou,Chiara Troiani,Benjamin Ryder,Jean Diaconu,Hervé Muyal,Marcelo Yannuzzi
### Background
当前授权方法在授权代理时给予过于广泛的许可，并允许代理超出指定任务范围的操作，这导致了重大风险。没有面向授权代理流程的中心数据集，尤其是涉及语义上合适的和不合适权限请求的，本文提出了一个代理授权模型，并构建了一个数据集与数据生成管道ASTRA，用于评估并基准语义匹配技术。“
### Innovation
本文提出了一个代理授权模型，通过语义检查访问受保护资源的请求，并颁发与代理分配任务必需权限范围约束的令牌。同时，本文引入了ASTRA数据集及数据生成管道，旨在提供用于评估基于语义匹配技术的基准数据。研究表明，随着完成任务所需的权限范围增加，模型匹配存在潜在和当前的限制。这强调了进一步研究语义匹配技术以实现意图感知授权的必要性，包括细粒度控制，如基于任务的访问控制（TBAC）。
### Conclusion
本文发现，基于模型的匹配技术虽然存在一定的潜力，但也存在当前限制。这表明未来需要进一步研究语义匹配技术，以实现多代理和工具增强应用中的意图感知授权。细粒度控制，如基于任务的访问控制（TBAC），将是未来研究的重要方向。
## 44. `cs.AI` - LASTIST: 大规模目标无关立场数据集 [PDF](https://arxiv.org/pdf/2510.25783), [HTML](https://arxiv.org/abs/2510.25783)
### Authors
DongJae Kim,Yaejin Lee,Minsu Park,Eunil Park
### Background
立场检测作为人工智能领域的一个研究方向逐渐兴起，但大多数研究集中在针对特定目标的人立场检测任务上，并且大多数基准数据集基于英语，这使得在低资源语言如韩语中开发模型变得困难，特别是对于如立场检测这样的新兴领域而言。因此，本文提出了LArge-Scale Target-Independent STance (LASTIST) 数据集以填补这一研究缺口。该数据集来源于韩国政党发布的新闻稿，包括563,299条标注的韩语文本，旨在支持多种立场检测任务，包括目标无关立场检测和历时演变立场检测.
### Innovation
本文提出的LASTIST数据集是一个大规模的目标无关立场数据集，该数据集首次用于填补韩语立场检测领域模型训练资源不足的问题，并提供详细的收集和构建数据过程，以及用最新深度学习和立场检测模型进行训练的方式，特别适合支持各种立场检测任务，包括目标无关立场检测和历时演变立场检测.
### Conclusion
本文提交了LASTIST数据集，该数据集为多种立场检测任务提供了支持，特别是首次解决了韩语立场检测中数据资源不足的问题，有助于推动该领域在低资源语言中的发展。
## 45. `cs.AI` - 监督博弈：学习在保持AI代理安全与自主性之间的协同平衡 [PDF](https://arxiv.org/pdf/2510.26752), [HTML](https://arxiv.org/abs/2510.26752)
### Authors
William Overman,Mohsen Bayati
### Background
随着越来越有能力的代理被部署，一个核心安全问题是如何在不修改基础系统的情况下保留有意义的人类控制。本文研究了一种最小控制界面，其中代理可以选择自主行动（玩）或托付（询问），而人类同时选择是否放任（信任）或进行监督（监管）。如果代理选择托付，人类的选择决定了结果，可能需要纠正行动或系统关闭。本文将这种交互建模为双人马尔可夫博弈。
### Innovation
本文侧重于这种博弈能够构成马尔可夫潜能博弈（MPG）的情况，这是一种博弈类型，其中我们可以在人类价值函数结构假设条件下提供一种对齐保证：任何代理选择更自主行动以利于自身的行为，都不会损害人类的价值。此外，本文还分析了此MPG框架的扩展。理论上，这种视角为特定形式的内在对齐提供了条件。如果人类-代理博弈的奖励结构满足这些条件，则有形式保证证明，在代理改善其自身结果的情况下不会损害人类。实践中，该模型推动了一种透明控制层，具有可预测的激励机制，代理在网络状况危险时选择暂停行动并在安全时选择行动，而其预训练策略和环境的奖励结构保持不变。
### Conclusion
网格世界模拟表明，通过独立学习，代理和人类可以发现它们的最佳监督角色。代理学会了在不确定时询问，人类学会了在适当的时间进行监督，从而促进了一种避免训练后引入的安全性违规的自发合作。这证明了一种实用的方法，可以在部署后使未对齐的模型更加安全。
## 46. `cs.AI` - zFLoRA: Zero-Latency Fused Low-Rank Adapters [PDF](https://arxiv.org/pdf/2510.25784), [HTML](https://arxiv.org/abs/2510.25784)
### Authors
Dhananjaya Gowda,Seoha Song,Harshith Goka,Junhyun Lee
### Background
大规模语言模型（LLMs）正越来越多地被部署为具有任务特定适配器的形式，以适应多种下游应用。这些适配器的参数数量虽然相对较少（通常少于基模型的1%），但在推理时的计算开销却显著增加（最高可达基模型的2.5倍）。这种额外的计算开销限制了LLMs在实际应用中的使用效率和应用场景。因此，研究人员需要找到一种在保持性能的同时减少推理时延的方法，以适应更广泛的下游任务应用。
### Innovation
本文提出了一种新的零时延融合低秩适配器（zFLoRA），它在基模型上引入零或可忽略的时延开销。实验结果表明，对于1B、3B和7B规模的语言模型，zFLoRA在性能上优于包括低秩适配器（LoRA）和全量微调（FFT）在内的常用监督微调基准。研究还在18个不同的任务类别（常识推理、数学推理和总结对话）中进行了实验，结果表明zFLoRA适配器在NPU和GPU平台上均实现了零或可忽略的时延开销。
### Conclusion
zFLoRA能够在保持模型性能不变的情况下有效减少推理时延，支持更广泛的实际应用。
## 47. `cs.AI` - A Practitioner's Guide to Kolmogorov-Arnold Networks [PDF](https://arxiv.org/pdf/2510.25781), [HTML](https://arxiv.org/abs/2510.25781)
### Authors
Amir Noorizadegan,Sifan Wang,Leevan Ling
### Background
Kolmogorov-Arnold Networks (KANs) 是一种受到 Kolmogorov-Arnold 表示定理启发的新型神经网络，它们呈现出了与传统多层感知器 (MLPs) 相比更加灵活和可解释的特点。KANs 使用可学习的一维基函数，而非固定的激活函数来增强表示能力和可解释性。本文为了提供 KAN 领域的全面概述，不仅对比了不同模型的性能，还对理论基础、架构变体和实现策略进行了系统性的综合分析。文中收集并分类了众多开源实现，从而映射出支持 KAN 开发的丰富生态系统。
### Innovation
1. 提出了一种从 KANs 和 MLPs 的概念差异过渡到形式等价性以及 KANs 表现更优参数效率的观点。2. 细致探讨了基函数的选择及其平滑性、局部性和计算成本之间的权衡。3. 概览了近期 KANs 行业的发展，将其分为提高准确度、效率和正则化的改进技术，并指出了关键主题，如基于物理的损失设计、自适应采样、领域分解、混合架构以及处理不连续性的特殊方法。4. 为从业者提供了一个实用的“选择您的 KAN”指南，帮助其选择合适的架构，并指出现有研究中的空白领域。通过一个 GitHub 仓库补充了本文并为 KAN 研究提供了结构化的参考。
### Conclusion
本文总结了当前的研究空白，并通过 GitHub 仓库提供了一个结构化的参考，支持 KAN 的进一步研究和发展。KANs 作为一个新兴的神经网络方向，在理论和实践中都有巨大的发展潜力。
## 48. `cs.AI` - DINO-YOLO: 自监督预训练在土木工程应用中的数据高效目标检测 [PDF](https://arxiv.org/pdf/2510.25140), [HTML](https://arxiv.org/abs/2510.25140)
### Authors
Malaisree P,Youwai S,Kitkobsin T,Janrungautai S,Amorndechaphon D,Rojanavasu P
### Background
在土木工程应用中，目标检测受到专用领域标注数据有限的限制。为了应对这一挑战，该研究提出了一种新的混合架构DINO-YOLO，将YOLOv12与DINOv3自我监督的视觉变换器相结合，实现数据高效的目标检测。
### Innovation
DINOv3特征被战略性地集成到两个位置：输入预处理（P0）和中间骨干增强（P3）。实验验证表明该方法在多数据集上取得了显著改进：隧道段裂缝检测（648张图）提高了12.4%，施工PPE（1000张图）提高了13.7%，而KITTI（7000张图）提高了88.6%的同时保持了实时推理（30-47 FPS）。系统化在五个YOLO比例和九种DINOv3变体上的取舍研究发现，中等规模架构在集成双P0P3（mAP@0.5为55.77%）时表现出最佳性能，而小型架构则需要三重集成（53.63%）。推理性能的2-4倍开销（21-33ms相对8-16ms的基线）在NVIDIA RTX 5090上部署时是可以接受的。DINO-YOLO在数据有限的土木工程数据集（少于10K张图）中取得了最先进的性能，并保持了计算效率，为施工安全监测和基础设施检查提供了解决方案。
### Conclusion
DINO-YOLO为土木工程领域的小数据集目标检测提供了实用的解决方案，同时保持了高效率和实时性能。
## 49. `cs.AI` - Magentic Marketplace: 一个开源的研究代理市场环境 [PDF](https://arxiv.org/pdf/2510.25779), [HTML](https://arxiv.org/abs/2510.25779)
### Authors
Gagan Bansal,Wenyue Hua,Zezhou Huang,Adam Fourney,Amanda Swearngin,Will Epperson,Tyler Payne,Jake M. Hofman,Brendan Lucier,Chinmay Singh,Markus Mobius,Akshay Nambi,Archana Yadav,Kevin Gao,David M. Rothschild,Aleksandrs Slivkins,Daniel G. Goldstein,Hussein Mozannar,Nicole Immorlica,Maya Murad,Matthew Vogel,Subbarao Kambhampati,Eric Horvitz,Saleema Amershi
### Background
随着大型语言模型（LLM）代理的进步，它们越来越多地代表用户进行经济决策，这些决策涉及从产品发现到交易的经济活动。虽然这些应用提供了潜在的好处，但也引发了很多关于代理对用户负责性及其价值的问题。要在这些市场条件下理解代理的行为对于回答这些问题至关重要。然而，之前的大部分研究仅在受控环境中评估代理，如单任务市场（如谈判）或结构化的两方互动交易。而在实际市场中，代理需要处理各种经济活动并在动态生态系统中进行协作，其中可能涉及多方行为不透明的代理进行无限制的对话。为了弥合这一差距，本文研究了双方代理市场，代理代表消费者和代理服务代表竞争的业务。为了安全地研究这些互动，我们开发了Magentic-Marketplace——一个模拟环境，让代理能够自由操作。这种环境使我们能够研究市场的关键动态：代理实现的效用、行为偏差、易受操纵性以及搜索机制如何影响市场结果。实验结果表明，在理想条件下，最先进模型可以达到最优福利，但性能随规模急剧下降，所有模型都表现出严重的第一提议偏差，这使得响应速度比质量好10到30倍。这些结果揭示了市场条件下行为如何出现，为设计公平和高效的代理市场提供了信息.
### Innovation
我们开发了Magentic-Marketplace——一个模拟环境，用于研究代理在充满挑战的实际市场条件下的行为。这种方法弥补了之前研究仅在受控环境中研究代理的不足。此外，实验揭示了最先进模型在不同市场条件下的表现差异和局限性：在理想条件下的性能优越，但在规模扩大时表现下降，并显示出严重的第一提议偏差，对响应速度产生负面影响。这些发现不仅为理解代理行为提供了重要洞见，也为设计更公平和有效的代理市场提供了指导.
### Conclusion
最先进模型能够接近最优福利，但在实际大规模市场条件下表现较差，且所有模型都表现出严重的第一提议偏差，这创造了响应速度优于质量的显著优势。这些发现强调了在设计代理市场时要考虑到这些局限性和偏差，从而实现公平和高效的市场设计。
## 50. `cs.AI` - HiMAE: 集成层次化掩码自动编码器发现可变时间尺度结构于可穿戴时间序列 [PDF](https://arxiv.org/pdf/2510.25785), [HTML](https://arxiv.org/abs/2510.25785)
### Authors
Simon A. Lee,Cyrus Tanade,Hao Zhou,Juhyeon Lee,Megha Thukral,Minji Han,Rachel Choi,Md Sazzad Hissain Khan,Baiying Lu,Migyeong Gwak,Mehrab Bin Morshed,Viswam Nathan,Md Mahbubur Rahman,Li Zhu,Subramaniam Venkatraman,Sharanya Arcot Desai
### Background
可穿戴传感器提供了丰富的生理时间序列数据，但这些数据的预测效用背后的原理仍不明确。作者假设时间分辨率是代表学习的基本维度，不同的临床和行为结果依赖于不同尺度的结构。为验证这一假设，作者引入了HiMAE（层次化掩码自动编码器），这是一种结合了掩码自动编码和层次化卷积编码器-解码器的自我监督框架。HiMAE能够产生多分辨率嵌入，这些嵌入能系统地评估哪些时间尺度携带预测信号，将分辨率从超参数转变为解释性的探针。
### Innovation
HiMAE是一种结合了masked autoencoding和hierarchical convolutional encoder decoder的自我监督框架，能够生成多分辨率嵌入，用于评估不同时间尺度的预测信号。它在分类、回归和生成基准测试中表现出色，且模型规模远小于现有基础模型，甚至可以完全在可穿戴设备上运行，实现亚毫秒级的推理速度，适用于真正的边缘推理。
### Conclusion
HiMAE作为一种高效的自我监督学习方法和发现可变时间尺度结构的工具，在可穿戴健康领域具有重要价值。
## 51. `cs.AI` - 黑箱NLP-2025 MIB 共享任务：通过更好的边选择提高电路忠实性 [PDF](https://arxiv.org/pdf/2510.25786), [HTML](https://arxiv.org/abs/2510.25786)
### Authors
Yaniv Nikankin,Dana Arad,Itay Itzhak,Anja Reusch,Adi Simhi,Gal Kesten-Pomeranz,Yonatan Belinkov
### Background
机械可解释性的主要挑战之一是在模型中发现执行特定任务的电路，即确定模型中哪些部分执行给定任务。该文基于Mechanistic Interpretability Benchmark (MIB)，提出了三种关键改进措施以提高电路发现效果，包括使用自助法识别一致的贡献评分边、引入简单比率选择策略以平衡性能与忠实性、以及用整数线性规划替换标准贪婪选择。这些方法在MIB的多个任务和模型中表现出更高的忠实性和优于之前的处理方式。
### Innovation
提出的三种关键改进措施主要是：1. 使用自助法识别一致的贡献评分边；2. 引入简单比率选择策略，平衡性能与忠实性；3. 用整数线性规划替换标准贪婪选择。这些方法使得电路发现结果更为忠实，并在多任务、多模型上优于先前的方法。
### Conclusion
通过上述改进，该研究在多个MIB任务和模型中取得了更为忠实的电路发现结果，且优于先前的方法。相关代码已在指定网址发布。
## 52. `cs.AI` - 推理的运动学：Chain-of-Thought 如何塑造Transformer的学习？ [PDF](https://arxiv.org/pdf/2510.25791), [HTML](https://arxiv.org/abs/2510.25791)
### Authors
Zihan Pengmei,Costas Mavromatis,Zhengyuan Shen,Yunyi Zhang,Vassilis N. Ioannidis,Huzefa Rangwala
### Background
链式思维（CoT）监督可以显著提高变换器的性能，但模型如何学习遵循和受益于CoT机制仍然缺乏理解。本文通过预训练变换器在具调变算法复杂性和可控数据组成的情节推理任务上，探讨其泛化能力的学习动态。
### Innovation
本文提出了一个动力学建模框架来理解变换器学习，并发现推理痕迹的忠实性会随着训练表现出动态变化。研究结果还表明，尽管CoT可以加速泛化，但在处理更高算法复杂性的任务时仍然存在限制。CoT还以一种机制学的方式改变了内部变换器的计算。
### Conclusion
本文揭示了CoT对任务性能的影响随着任务复杂度的不同而不同。通过训练中推理痕迹忠实性的动态变化理解了变换器的性质。此外，提出了动力学建模框架并展示了如何利用CoT影响内部变换器的计算机制。
## 53. `cs.AI` - MemEIC: 朝着持续且组成性知识编辑迈出的一步 [PDF](https://arxiv.org/pdf/2510.25798), [HTML](https://arxiv.org/abs/2510.25798)
### Authors
Jin Seong,Jiyun Park,Wencke Liermann,Hongseok Choi,Yoonji Nam,Hyun Kim,Soojong Lim,Namhoon Lee
### Background
信息的动态特性要求不断更新大型视觉-语言模型（LVLM）。尽管最近的知识编辑技术显示出有希望的方向，但它们通常侧重于孤立地编辑单一模态（视觉或语言）。这种常见的做法忽视了LVLM的固有跨模态性和知识更新的连续性，这可能会导致跨模态间相互作用和持续知识精炼所需的最佳编辑结果不佳。
### Innovation
本文提出了一种新的方法MemEIC，用于LVLM的持续且组成性知识编辑（CCKE）。MemEIC能够按顺序编辑视觉和文本知识。方法采用了一种混合外部-内部编辑器，配备了一种跨模态证据检索的双外部内存和促进每个模态独立参数更新的双LoRA适配器。关键组件是一种灵感来源于大脑的基于知识连接器，仅在组成性推理过程中被选择性激活，跨模态整合信息。
### Conclusion
实验表明，MemEIC显著提高了处理复杂跨模态问题的表现，并有效保持了先前编辑的内容，为LVLM的CCKE设定了新的标准。
## 54. `cs.AI` - 使用基于仿真强化学习的非短视调度和再平衡的大型按需拼车系统 [PDF](https://arxiv.org/pdf/2510.25796), [HTML](https://arxiv.org/abs/2510.25796)
### Authors
Farnoosh Namdarpour,Joseph Y. J. Chow
### Background
拼车服务是一种乘客共享乘车的服务，可以降低乘客和运营商的成本，减少交通拥堵和环境影响。然而，现有的调度决策往往只关注短期内的效果，忽略了长期影响。为解决这一问题，该研究提出了一种基于仿真强化学习的非短视调度方法，通过结合调度仿真和强化学习机制，在非短视决策方面进行了创新。
### Innovation
研究结合了仿真和强化学习来实现非短视调度，并提出了一种补充的车辆再平衡策略。利用n步时差学习方法，研究者得到了时空状态值，评估了非短视调度策略的有效性，并通过纽约市出租车请求数据进行了验证。实验结果表明，该非短视匹配策略可以将服务率提高8.4%，减少乘客等待时间和乘车时间，同时通过减少车队规模25%以上，为运营商降低成本。此外，通过在调度决策基础上加入再平衡操作，可以进一步减少等待时间27.3%，乘车时间12.5%，并提高服务率15.1%，虽然这会导致每乘客行驶时间增加。
### Conclusion
通过基于仿真强化学习的方法，该研究提出了一种非短视的拼车调度和车辆再平衡策略，显著提高了服务效率，减少了车辆运行时间和乘客等待时间，并通过减少了车队规模，为运营商带来了显著的成本节约。
## 55. `cs.AI` - 基于电压依赖性突触可塑性的无监督局部学习方法及其在阻变和铁电突触中的应用 [PDF](https://arxiv.org/pdf/2510.25787), [HTML](https://arxiv.org/abs/2510.25787)
### Authors
Nikhil Garg,Ismael Balafrej,Joao Henrique Quintino Palhares,Laura Bégon-Lours,Davide Florini,Donato Francesco Falcone,Tommaso Stecconi,Valeria Bragaglia,Bert Jan Offrein,Jean-Michel Portal,Damien Querlioz,Yann Beilliard,Dominique Drouin,Fabien Alibart
### Background
边缘计算设备在部署人工智能时面临能源消耗和功能性的巨大挑战。大脑启发的学习机制可以在不消耗大量电力的情况下实现实时适应，通过纳米尺度的阻变存储器进行的在存计算可能有助于在这些边缘设备上执行人工智能工作负载。本研究旨在解决如何通过无监督和局部学习机制实现系统的动态优化。研究探讨了基于Hebbian原则的电压依赖性突触塑性（VDSP）方法，证明了其在不同类型阻变体突触和铁电隧道结突触中的应用潜力。
### Innovation
提出了基于电压依赖性突触塑性的无监督学习机制（VDSP），这种机制能够在线学习，避免了通常棘突时序依赖性塑性（STDP）所需的复杂脉冲整形电路。VDSP被验证适用于不同特性（如切换特性和高/低阻抗状态比例）的TiO$_2$、HfO$_2$基于金属氧化物的突触和HfZrO$_4$基于铁电隧道结（FTJ）的三种类型的突触设备。通过在MNIST模式识别任务中验证了此类突触设备集成的脉冲神经网络的无监督学习效果，达到了行业领先的表现，使用200个神经元实现了超过83%的准确率。此外，研究还探讨了设备变化性的影响，并提出了提高鲁棒性的策略。
### Conclusion
通过在边缘设备上实现基于VDSP的无监督学习，可以有效提高神经网络的效率和性能。仿真结果表明，VDSP方法不仅能够适配多种突触结构，还能显著提高基于MNIST数据集的模式识别精度。此外，本研究还提出了应对设备变化性的缓解策略，进一步增强了系统的稳健性。
## 56. `cs.AI` - ScaleDiff：通过高效且模型无关的扩散模型实现更高分辨率的图像合成 [PDF](https://arxiv.org/pdf/2510.25818), [HTML](https://arxiv.org/abs/2510.25818)
### Authors
Sungho Koh,SeungJu Cha,Hyunwoo Oh,Kwanyoung Lee,Dong-Jin Kim
### Background
文本到图像的扩散模型在生成超过训练分辨率的图像时常常表现出性能下降。虽然有一些无需额外训练的方法可以减轻这一限制，但这些方法通常需要大量的计算资源或与最近的扩散变换器模型不兼容。
### Innovation
我们提出了一种名为ScaleDiff的模型通用且高效的框架，用于在没有任何额外训练的情况下扩展预训练扩散模型的分辨率。该框架的核心组件是邻域斑块注意力（NPA），这是一种有效的机制，通过非重叠斑块减少了自注意力层中的计算冗余。此外，我们还引入了潜在频率混合（LFM）以更好地生成细部，并应用结构指导以在去噪过程中增强全局结构。实验结果显示，ScaleDiff在训练免费方法中同时在图像质量和推断速度方面表现最佳，适用于U-Net和扩散变换器架构。
### Conclusion
ScaleDiff在无需额外训练的情况下，实现了在保持高质量的同时提升图像分辨率的目标。该方法通过引入NPA、LFM和结构指导显著增强了生成图像的细节和全局结构，同时保持了高效性。
## 57. `cs.AI` - 身份管理对于代理型AI：通往AI代理世界中的授权、身份验证和安全的新领域 [PDF](https://arxiv.org/pdf/2510.25819), [HTML](https://arxiv.org/abs/2510.25819)
### Authors
Tobin South,Subramanya Nagabhushanaradhya,Ayesha Dissanayaka,Sarah Cecchetti,George Fletcher,Victor Lu,Aldo Pietropaolo,Dean H. Saxe,Jeff Lombardo,Abhishek Maligehalli Shivalingaiah,Stan Bounev,Alex Keisner,Andor Kesselman,Zack Proser,Ginny Fahs,Andrew Bunyea,Ben Moskowitz,Atul Tulshibagwale,Dazza Greenwood,Jiaxin Pei,Alex Pentland
### Background
人工智能代理的迅速崛起在认证、授权和身份管理方面提出了紧迫挑战。当前以代理为中心的协议（如MCP）强调了需要澄清最佳实践。随着对高度自主代理的追求，这意味着长期的问题，包括可扩展的访问控制、以代理为中心的身份、AI工作负载的差异化和委托权限等。该白皮书针对人工智能代理与访问管理交叉领域的利益相关者，概述了目前可用于当前代理的安全资源，并提出了一个战略议程来应对即将到来的广泛自主系统的根本性认证、授权和身份问题。
### Innovation
本文档提供了针对当前代理的安全资源，并提出了一项战略议程来解决即将到来的广泛自主系统的根本性认证、授权和身份问题，为正在该领域探索的各方提供指导。
### Conclusion
该白皮书对利益相关者提出了统筹规划和策略，旨在解决未来广泛使用的自主系统所面临的基础性身份管理和安全问题，为创建一个更安全、更可信的AI代理世界奠定了基础。
## 58. `cs.AI` - AAGATE：面向代理人工智能的NIST人工智能风险管理框架对齐治理平台 [PDF](https://arxiv.org/pdf/2510.25863), [HTML](https://arxiv.org/abs/2510.25863)
### Authors
Ken Huang,Jerry Huang,Yasir Mehmood,Hammad Atta,Muhammad Zeeshan Baig,Muhammad Aziz Ul Haq
### Background
介绍Agentic AI Governance Assurance & Trust Engine (AAGATE)，这是一种Kubernetes原生的控制平面，旨在解决自主的语言模型驱动代理在生产环境中面临的独特安全和治理挑战。鉴于传统的应用程序安全工具在即兴的、机器速度系统中的局限性，AAGATE通过具体化NIST人工智能风险管理框架（AI RMF）来解决这些挑战。
### Innovation
AAGATE将NIST AI RMF的具体化，并结合了特定的安全框架，如Agentic AI Threat Modeling MAESTRO框架、OWASP的AIVSS和SEI的SSVC以及Cloud Security Alliance的Agentic AI Red Teaming Guide进行威胁建模、测量和管理。通过整合零信任服务网格、可解释的策略引擎、行为分析和去中心化的问责挂钩，AAGATE为代理人工智能提供了持续、可验证的治理解决方案，使其能在安全、问责和可扩展的部署中受益。此外，AAGATE进一步扩展了数字身份权利(DIRF)、逻辑层注入(LPCI)防御和认知下降(QSAF)的监控等功能。
### Conclusion
AAGATE提供了综合的治理解决方案，覆盖系统、对手和伦理风险，确保代理人工智能的治理全面有效。
## 59. `cs.AI` - 使用代理转移因果效应 [PDF](https://arxiv.org/pdf/2510.25924), [HTML](https://arxiv.org/abs/2510.25924)
### Authors
Manuel Iglesias-Alonso,Felix Schur,Julius von Kügelgen,Jonas Peters
### Background
本文研究了在多领域环境下估计因果效应的问题。目标是解决由于未观测到的混杂因素而产生的因果效应混淆，并且因果效应在各个领域可以发生变化。研究假设已知潜在混杂因素的代理变量，并且所有变量都是离散或分类的。
### Innovation
提出了估计目标领域因果效应的方法，这种方法在目标领域中仅能观察到代理变量。证明了在存在连续处理和响应变量的情况下，因果效应的识别性。引入了两种估计技术，证明了其一致性，并推导了置信区间。该研究的理论结果得到了模拟研究和现实世界例子的支持。
### Conclusion
基于这些条件，我们能够证明因果效应在连续测量变量的情况下也可以被识别，并提出了两种估计技术，通过实证研究验证了这些方法的有效性。
## 60. `cs.AI` - LLM辅助注释在视角化设置中的影响评估：FrameNet标注案例 [PDF](https://arxiv.org/pdf/2510.25904), [HTML](https://arxiv.org/abs/2510.25904)
### Authors
Frederico Belcavello,Ely Matos,Arthur Lorenzi,Lisandra Bonoto,Lívia Ruiz,Luiz Fernando Pereira,Victor Herbst,Yulla Navarro,Helen de Andrade Abreu,Lívia Dutra,Tiago Timponi Torrent
### Background
基于LLM的应用正在加速或替代人类劳动，特别是在语言资源和数据集的创建中。尽管这些工具在语言研究中具有潜力，但对它们在标记数据集创建中的性能和影响进行全面评估仍然不足，特别是在进行了视角化的自然语言处理(NLP)研究中。该论文通过评估LLM辅助框架进行语义标注的效果，填补了这一空白。
### Innovation
论文采用了一种新的方法，通过LLM辅助的语义角色标记器，对框架语义注释进行了（半）自动化，同时在三个实验设置中进行比较研究：人工、自动和半自动注释，从而评估不同注释设置的效率和效果。
### Conclusion
半自动注释设置在提高框架多样性方面效果更好，且与人工注释在注释覆盖率方面相当；自动注释设置在所有其他评估指标上表现较差，但注释时间较短。
## 61. `cs.AI` - Metis-SPECS：通过自我精炼偏好导向冷启动实现多模态学习的解耦 [PDF](https://arxiv.org/pdf/2510.25801), [HTML](https://arxiv.org/abs/2510.25801)
### Authors
Kun Chen,Peng Shi,Haibo Qiu,Zhixiong Zeng,Siqi Yang,Wenji Mao,Lin Ma
### Background
近年来，具备可验证奖励的强化学习（RL）引发了“MLLM-r1”方法的热潮，这些方法将强化学习带到了视觉语言模型中。大多数代表性范式都会从一个冷启动开始，通常通过监督微调（SFT）来初始化策略之后再进行强化学习。然而，基于SFT的冷启动方法结合了解题和输出格式的推理范式，这可能导致指令风格的过拟合，弱化对分布外数据的泛化能力，最终影响下游的强化学习效果。
### Innovation
该研究从冷启动的训练方法和数据构建两个视角进行了回顾，并引入了泛化因子（GF）系数来量化不同方法下的泛化能力。实验发现偏好导向的训练方法（如DPO）在冷启动时的泛化能力优于基于SFT的方法。基于此，本文提出了SPECS框架——自我精炼、偏好导向的冷启动框架。SPECS框架通过自我精炼生成自省的偏好数据对，避免依赖大型教师或人力注释；通过偏好导向的训练来学习浅层、可转移的表面形式标准（格式、结构、风格），而不过度记忆内容；最后将验证奖励用于强化学习，以获取深层次的推理结果。实验结果表明，我们的解耦学习框架在多个多模态基准测试中优于强基线，提高了MEGA-Bench 4.1%和MathVista 12.2%。此外，实验还表明，SPECS有助于减少分布内的“卡顿”，提高探索能力，稳定训练，并提高性能上限。
### Conclusion
我们的研究证明了解耦的偏好导向的冷启动方法在提升多模态模型的泛化能力和任务性能方面具有显著优势。SPECS框架通过自我精炼的偏好数据生成和偏好导向的浅层训练提高了模型在初始阶段的灵活性和泛化能力，最终在多个基准测试中显示出一致的性能改进。
## 62. `cs.AI` - PRISM: 通过LLM x MDE协同与分层约束生成证明携带制品 [PDF](https://arxiv.org/pdf/2510.25890), [HTML](https://arxiv.org/abs/2510.25890)
### Authors
Tong Ma,Hui Lai,Hui Wang,Zhenhu Tian,Jizhou Wang,Haichao Wu,Yongfan Gao,Chaochao Li,Fengjie Xu,Ling Fang
### Background
在安全性和合规性关键领域，人工生成的监管准备型制品和机器可验证证据需要繁琐的手动审查和整改。为此，论文介绍了一种新的方法，即PRISM，它将大型语言模型（LLM）与模型驱动工程（MDE）相结合，生成符合监管要求的制品和可验证证据。
### Innovation
PRISM引入了三个核心组件：①统一元模型（UMM），能够将不同来源的数据模式和监管文本统一到一个语义空间中；②集成约束模型（ICM），能够将结构和语义要求编译成执行制品，如生成时自动机（GBNF，DFA）和生成后验证器（如SHACL，SMT）；③基于约束的验证性生成（CVG），通过两层执行来约束生成过程，结构约束驱动前缀安全性解码，语义/逻辑验证产生机器可验证证书。当出现违规时，PRISM可以进行审计指导修复，并记录生成痕迹进行合规审查。该方法专门应用在汽车软件工程（AUTOSAR）和跨境法律管辖（布鲁塞尔I修正案）场景中，展示了其生成结构上有效的、可审计的制品，并与现有工具集成，显著减少了手动整改工作，从而为自动化制品生成提供了实际路径，具备内置保证的自动化制品生成是其一大创新点。
### Conclusion
PRISM成功在汽车软件工程和跨境法律管辖领域中生成了结构上有效、可审计的制品，这些制品能够与现有工具结合使用，并大幅度减少了手动整改工作的需求，从而提供了一条实际的自动化制品生成路径，兼具内置保证。
## 63. `cs.AI` - 基于过程挖掘的软件开发工作流分析与预测系统 [PDF](https://arxiv.org/pdf/2510.25935), [HTML](https://arxiv.org/abs/2510.25935)
### Authors
Antía Dorado,Iván Folgueira,Sofía Martín,Gonzalo Martín,Álvaro Porto,Alejandro Ramos,John Wallace
### Background
软件开发工作流中的截止日期合规性预测是一个重要的挑战性问题。现有系统通常依赖手动数据分析和统计方法，无法实现对软件开发工作流程的精确预测和及时干预。为了解决这一问题，CodeSight系统旨在通过直接从GitHub捕获开发和部署数据并将其转换为过程挖掘日志来提供端到端的解决方案，进而进行详细的分析。
### Innovation
CodeSight系统引入了基于LSTM模型的过程挖掘技术，能够根据序列活动轨迹和静态特征预测待决拉取请求的剩余解决时间，从而提前识别潜在的截止日期违规。相较于传统的手动分析和统计方法，CodeSight系统能够提供更高精度和更高F1分数的预测结果，展示了过程挖掘与机器学习结合在主动软件项目管理中的价值。
### Conclusion
CodeSight系统通过结合过程挖掘和机器学习技术，实现了对软件开发工作流中截止日期合规性的高精度预测。该系统的应用表明，这种集成方法能够有效提高项目管理的效率和质量，为软件开发团队提供有价值的数据洞见。
## 64. `cs.AI` - 语言模型预训练中的多语言数据混合 revisiting multilingual data mixtures in language model pretraining [PDF](https://arxiv.org/pdf/2510.25947), [HTML](https://arxiv.org/abs/2510.25947)
### Authors
Negar Foroutan,Paul Teiletche,Ayush Kumar Tarun,Antoine Bosselut
### Background
大规模语言模型（LLM）的预训练过程中使用不同多语言数据混合体的影响一直是持续的讨论话题。通常认为，多语言训练可能在语言覆盖面与模型性能之间存在权衡（即多语言化的诅咒）。现有研究对此存在不同的看法。
### Innovation
研究人员通过训练包含1.1B和3B参数的多种语言的语料库来验证常见假设。他们发现，将英语与多语言数据结合使用并不会必然损害语言的模型性能，前提是训练语料库中含有足够的词汇量。研究还发现，使用英语作为桥梁语言有助于多语言的泛化，并且不像预期的那样，从某个语言家族内选择桥梁语言会一致地提高该家族内语言的性能。此外，研究并未发现大规模语言模型在训练语言数量增加时会表现出多语言化的诅咒。
### Conclusion
研究结果表明，当平衡适当时，多语言数据可以增强语言模型的能力，并在低资源设置中也不会损害性能。
## 65. `cs.AI` - 应用和验证地理空间基础模型数据对卫生设施项目输出的预测——马拉维案例研究 [PDF](https://arxiv.org/pdf/2510.25954), [HTML](https://arxiv.org/abs/2510.25954)
### Authors
Lynn Metz,Rachel Haggard,Michael Moszczynski,Samer Asbah,Chris Mwase,Patricia Khomani,Tyler Smith,Hannah Cooper,Annie Mwale,Arbaaz Muslim,Gautam Prasad,Mimi Sun,Tomer Shekel,Joydeep Paul,Anna Carter,Shravya Shetty,Dylan Green
### Background
低收入和中等收入国家（LMICs）的常规公共卫生数据通常受到报告延迟和不完整覆盖的限制，这需要探索新的数据源和分析方法。地理空间基础模型（GeoFM）通过将多样化的空间、时间和行为数据整合成数学嵌入式表示，为下游预测任务提供支持。本研究评估了三种GeoFM嵌入来源——Google人口动态基础模型（PDFM）、谷歌AlphaEarth（源自卫星图像）和移动电话呼叫详细记录（CDR）在马拉维对15个常规公共卫生项目的预测性能，并将它们与传统地理空间插值方法进行了比较。
### Innovation
该研究通过引入GeoFM嵌入技术，为预测低收入和中等收入国家的公共卫生项目结果提供了一种新的方法。研究发现，基于嵌入的方法在15个指标中有13个（占比87%）优于基本的地理统计方法。多GeoFM模型整合三种嵌入源的方法在多项指标上表现出了最佳预测结果，显著提高了预测准确性。
### Conclusion
研究结果表明，GeoFM嵌入对于低收入和中等收入国家中选择的健康和人口统计结果具有一定的预测改善作用。本研究表明，多种GeoFM数据源的集成是补充和加强受限制的常规公共卫生信息系统的有效且有价值的工具。
## 66. `cs.AI` - 可靠的责任人工智能评价指标的追求 [PDF](https://arxiv.org/pdf/2510.26007), [HTML](https://arxiv.org/abs/2510.26007)
### Authors
Theresia Veronika Rampisela,Maria Maistro,Tuukka Ruotsalo,Christina Lioma
### Background
随着人工智能（AI）特别是科学中的AI（AIS）的发展，有必要遵循负责任的人工智能原则进行开发。尽管评价负责任人工智能的进展通常通过评估指标来量化，但很少有工作专注于评估这些指标自身的稳健性和可靠性。研究者借鉴了过去关于公平性指标稳健性的研究，并将其结果总结为一组非详尽指南，以促进负责任人工智能可靠评价指标的发展。
### Innovation
研究者提出了一套用于评估负责任人工智能可靠评价指标的非详尽指南。这些指南适用于广泛的AI应用，包括科学中的AI。
### Conclusion
研究者总结了过去关于公平性指标稳健性的研究，并形成了一组非详尽指南，旨在促进负责任人工智能可靠评价指标的发展。指南覆盖了广泛的人工智能应用领域。
## 67. `cs.AI` - 多智能体增强学习在做市中的应用：无串谋的竞争 [PDF](https://arxiv.org/pdf/2510.25929), [HTML](https://arxiv.org/abs/2510.25929)
### Authors
Ziyi Wang,Carmine Ventre,Maria Polukarov
### Background
算法共谋已成为人工智能领域的一个核心问题。不同AI代理在市场中交互是否会引发共谋行为，影响市场的整体运行状态，这是一个重要的研究课题。本研究旨在通过多层次多智能体强化学习框架，探讨市场做市中的算法共谋问题。该框架中包括一个自利的做市商（Agent A）和三个底层竞争者：自利的Agent B1（最大化自身利润），竞争的Agent B2（最小化对手的利润），以及混合的Agent B*（可灵活切换行为模式）。研究通过分析这些智能体相互作用的特点和市场结果变化，并提出行为不对称性和系统级动力学的度量标准，以评估可能的交互模式。实验证明，在零和博弈中，Agent B2比B1表现出更出色的表现，通过积极地获取订单流量并缩小平均差价，提高了市场的执行效率。而Agent B*与其他利润驱动的智能体共存时倾向于自身利益，通过适应性报价获取市场份额，但比B2对Agent A和B1的奖励影响更小。这表明，适应性激励控制支持在异质智能体环境中的可持续战略共存，并为评估算法交易系统的行为设计提供了有序视角。
### Innovation
提出了一种多层次多智能体强化学习框架来研究市场做市中的算法共谋问题，引入了自利智能体、竞争智能体和混合智能体三种类型，通过自利和竞争行为的相互作用观察和分析共谋行为形成的过程，并提出行为不对称性和系统级动力学的度量标准，以评估可能的交互模式。实验表明，自利智能体B2在零和博弈中表现占优，通过积极获取订单流量并缩小平均差价提高市场的执行效率，而混合智能体B*与其他利润驱动的智能体共存时倾向于自身利益，并通过适应性报价获取市场份额，但对其他智能体的负面影响较小。
### Conclusion
自利智能体B2在零和博弈中占据了优势，通过积极获取订单流量并缩小平均差价提高了市场执行效率。混合智能体B*与其他利润驱动的智能体共存时倾向于自身利益，通过适应性报价获取市场份额，但对其他智能体的负面影响较小。这些发现表明，适应性激励控制有助于异质智能体环境中的可持续共存，并为评估算法交易系统的策略设计提供了一种结构化的视角。
## 68. `cs.AI` - Brain-IT:通过脑交互变换器从fMRI进行图像重建 [PDF](https://arxiv.org/pdf/2510.25976), [HTML](https://arxiv.org/abs/2510.25976)
### Authors
Roman Beliy,Amit Zalcher,Jonathan Kogman,Navve Wasserman,Michal Irani
### Background
通过功能性磁共振成像(fMRI)重建人们所见的图像为研究人类大脑提供了一个无创窗口。尽管最近通过扩散模型取得了一些进展，但当前的方法往往缺乏对实际看到的图像的忠实性。为了应对这一挑战，提出了“Brain-IT”，一种基于大脑交互的头脑交互变换器方法，通过允许功能相似的大脑体素集群之间的有效交互，实现图像的重建。这些功能集群在所有受试者中共享，作为在大脑之间整合信息的构建块。所有模型组件在所有集群和受试者之间共享，使得在有限的数据量下可以实现高效训练。
### Innovation
Brain-IT利用Brain Interaction Transformer（BIT）预测两种互补的局部补丁级图像特征：（i）高层语义特征引导扩散模型向图像的正确语义内容靠拢；（ii）低级结构特征帮助扩散过程的初始化，以获得正确的图像粗略布局。BIT的设计实现了从脑体素集群到局部图像特征的直接信息流。通过这些原则，该方法能够从fMRI中重建出忠实的图像，且在视觉和标准客观度量上都超过了当前的最佳方法。此外，使用仅一小时的fMRI数据可以从新的受试者中获得与当前基于40小时记录训练的方法相当的结果。
### Conclusion
Brain-IT方法通过功能性磁共振成像从大脑交互变换器中实现了图像的重建，表现出高度忠实于实际看到的图像，优于当前的最新方法，并且在有限的fMRI数据下同样能取得优异的重建结果。
## 69. `cs.AI` - RADRON: 使用Compton相机的MAV合作探测 ionizing辐射源 [PDF](https://arxiv.org/pdf/2510.26018), [HTML](https://arxiv.org/abs/2510.26018)
### Authors
Petr Stibinger,Tomas Baca,Daniela Doubravova,Jan Rusnak,Jaroslav Solc,Jan Jakubek,Petr Stepan,Martin Saska
### Background
该研究基于一种先进的单探测器康普顿相机，这是一种轻便（40克）且高度敏感的放射性检测工具。康普顿相机被集成到微型空中车辆（MAVs）中，通过团队合作提高辐射检测的灵敏度和灵活性。
### Innovation
提出了一种新颖的方法，将康普顿相机的测量数据融合起来，实时估计放射性源头的位置，即使是稀疏的测量数据也能实现。这种数据的读取出现在机载，并直接进行处理，实时反馈驱动MAVs的运动。MAVs通过紧密协作，最大化康普顿相机的信息获取，快速定位放射性源头，甚至追踪移动的放射性源头。
### Conclusion
该研究展示了一种创新的康普顿相机集成到MAV中的应用，其能够实时估计放射源位置并实现稀疏数据下的探测，通过紧密协作的MAV团队，提高了放射性检测的效率和灵活性。
## 70. `cs.AI` - 离散时间生存分析的双重混合专家框架 [PDF](https://arxiv.org/pdf/2510.26014), [HTML](https://arxiv.org/abs/2510.26014)
### Authors
Hyeonjun Lee,Hyungseob Shin,Gunhee Nam,Hyeonsoo Lee
### Background
生存分析是一种用于建模感兴趣事件发生时间的任务，在临床和生物医学研究中广泛使用。一个关键挑战是同时建模患者异质性，并使风险预测适应个体特征和时间动态。现有的深度学习方法存在不足之处，无法同时高效处理这些问题。
### Innovation
提出了一种双重混合专家（dual mixture-of-experts，dual-MoE）框架用于离散时间生存分析。该方法结合了一个特征编码专家（feature-encoder MoE）模块，用于小组感知的表示学习；与一个利用患者特征和时间嵌入来捕捉时间动态的危险专家（hazard MoE）模块。这个双重MoE设计可以灵活地集成到现有的基于深度学习的生存分析管道中，提高模型在METABRIC和GBSG乳腺癌数据集上的表现，特别是在Consurv框架中进一步提高了性能
### Conclusion
该研究提出的方法在METABRIC和GBSG乳腺癌数据集上的一致性改进表明，该双重混合专家框架在处理离散时间生存分析中的群体异质性及时间动态方面具有显著优势，能够有效提升生存分析的预测性能。
## 71. `cs.AI` - 监督强化学习：从专家路径到逐步推理 [PDF](https://arxiv.org/pdf/2510.25992), [HTML](https://arxiv.org/abs/2510.25992)
### Authors
Yihe Deng,I-Hung Hsu,Jun Yan,Zifeng Wang,Rujun Han,Gufeng Zhang,Yanfei Chen,Wei Wang,Tomas Pfister,Chen-Yu Lee
### Background
大型语言模型（LLMs）在需要多步推理的问题上常常表现不佳。对于小型开源模型，强化学习结合可验证奖励（RLVR）在正确解决方案难以采样的情况下表现不佳，而监督微调（SFT）则倾向于通过僵硬的逐字模仿对长范例过度拟合。为了解决这一问题，我们提出了一种监督强化学习（SRL）框架，将问题求解重新定义为生成一系列逻辑“动作”的序列。SRL 训练模型在执行每个动作时生成内部推理，然后基于模型动作与从 SFT 数据集中提取的专家动作之间的相似性逐步提供更平滑的奖励。这种监督即使在所有模拟均失败时也能提供更丰富的学习信号，同时还鼓励以专家示范为引导的灵活推理。结果，SRL 使小型模型能够学习以往 SFT 或 RLVR 无法解决的复杂问题。此外，在使用 SRL 初始化训练后再用 RLVR 进行优化会带来最强的整体性能。除了推理基准任务外，SRL 还能有效推广到代理软件工程任务中，确立其作为强化导向的LLMs 的坚实且多功能的训练框架地位
### Innovation
提出了一种监督强化学习（SRL）框架，将问题求解重新定义为生成一系列逻辑“动作”。SRL 训练模型在执行每个动作时生成内部推理，然后基于模型动作与从 SFT 数据集中提取的专家动作之间的相似性逐步提供更平滑的奖励。这种监督即使在所有模拟均失败时也能提供更丰富的学习信号，同时还鼓励以专家示范为引导的灵活推理。结果，SRL 使小型模型能够学习以往 SFT 或 RLVR 无法解决的复杂问题
### Conclusion
SRL 使小型模型能够学习以往 SFT 或 RLVR 无法解决的复杂问题。此外，在使用 SRL 初始化训练后再用 RLVR 进行优化会带来最强的整体性能。SRL 还能有效推广到代理软件工程任务中，确立其作为强化导向的LLMs 的坚实且多功能的训练框架地位。
## 72. `cs.AI` - 基于人工智能的放射学报告分析：偶然甲状腺发现的流行病学及其后果 [PDF](https://arxiv.org/pdf/2510.26032), [HTML](https://arxiv.org/abs/2510.26032)
### Authors
Felipe Larios,Mariana Borras-Osorio,Yuqi Wu,Ana Gabriela Claros,David Toro-Tobon,Esteban Cabezas,Ricardo Loor-Torres,Maria Mateo Chavez,Kerly Guevara Maldonado,Luis Vilatuna Andrango,Maria Lizarazo Jimenez,Ivan Mateo Alzamora,Misk Al Zahidy,Marcelo Montero,Ana Cristina Proano,Cristian Soto Jacome,Jungwei W. Fan,Oscar J. Ponce-Ponte,Megan E. Branda,Naykky Singh Ospina,Juan P. Brito
### Background
偶然甲状腺发现（ITFs）随着非甲状腺指征的影像检查日益增多而被频繁检测到。尽管如此，ITFs的患病率、特点以及临床后果仍然未知。
### Innovation
开发、验证并部署基于自然语言处理（NLP）的工作流程，以识别放射学报告中的ITFs，并评估其患病率、特点及临床结果。
### Conclusion
ITFs普遍存在于非甲状腺指征的影像学检查中，并与检测到小风险甲状腺癌相关。这些发现强调了ITFs在甲状腺癌过诊断中的作用，并突显了标准化报告和更加谨慎随访的必要性。
## 73. `cs.AI` - 使用深度学习进行气候适应性海堤洪水预测的沿海城市 [PDF](https://arxiv.org/pdf/2510.26017), [HTML](https://arxiv.org/abs/2510.26017)
### Authors
Bilal Hassan,Areg Karapetyan,Aaron Chung Hin Chow,Samer Madanat
### Background
气候变暖和海平面上升(SLR)对沿海城市构成不断增加的威胁，加剧了准确预测潜在洪水危害方法的需求。传统物理为基础的水动力模拟器虽然精确，但对于城市尺度的沿海规划应用却因计算成本高昂而不切实际。深度学习(DL)技术提供了一种有前景的替代方案，但由于数据稀缺和高维输出要求高等问题，往往受到限制。利用一种新提出的基于视觉的、资源消耗低的DL框架，我们开发了一种新型轻量级卷积神经网络(CNN)模型，旨在预测在不同SLR情景和海岸线适应场景下沿海洪水。此外，我们通过利用阿布扎比和旧金山等不同地区的数据集证明了该模型的泛化能力。我们的研究结果显示，所提出的模型在预测洪水深度图时显著优于现有最佳方法，平均减少20%的绝对误差(MAE)。这些结果表明该方法有可能作为沿海洪水管理的可扩展和实用工具，帮助决策者制定针对气候变暖影响增加的有效应对策略。
### Innovation
利用基于视觉的、资源消耗低的深度学习框架，开发了一种新型轻量级的卷积神经网络(CNN)模型，用于预测在不同SLR情景和海岸线适应场景下沿海洪水。同时，通过不同地区的数据集展示了该模型的泛化能力。该模型在预测洪水深度图时显著优于现有最佳方法，平均减少20%的绝对误差(MAE)。
### Conclusion
通过利用所提出的基于视觉的深度学习模型，为沿海洪水管理提供了一种可扩展和实用的工具，帮助决策者制定有效的应对气候变暖影响的策略。
## 74. `cs.AI` - 重新思考跨语言对齐：在多语言大语言模型中的转移与文化抹除权衡 [PDF](https://arxiv.org/pdf/2510.26024), [HTML](https://arxiv.org/abs/2510.26024)
### Authors
HyoJung Han,Sweta Agrawal,Eleftheria Briakou
### Background
跨语言对齐（Cross-lingual alignment, CLA）旨在使多语言表示一致，使大语言模型（Large Language Models, LLMs）能够无缝地跨语言传递知识。然而，这种代表性的收敛可能无意间导致“文化抹除”的现象，即失去基于查询语言提供文化特定响应的功能。
### Innovation
作者提出了一个全面的评估框架——转移-本地化平面（transfer-localization plane），量化了期望的知识转移和不期望的文化抹除。通过此框架，作者重新评估了最近的跨语言对齐方法，发现它们在所有研究的六种语言中都以牺牲文化本地化为代价提高了事实的传递。作者进一步揭示了这些模型内部表示的关键洞察：普遍的事实传递和文化特定的知识在不同的模型层上具有不同的优化特性。基于此发现，作者提出了Surgical Steering，一种新颖的推理时方法，可以分离这两个目标。
### Conclusion
通过应用目标激活转向到不同的层，作者的方法有效地平衡了这两维的竞争需求，成功地克服了现有对齐技术的局限性。
## 75. `cs.AI` - PORTool：带有奖励树的工具使用LLM训练 [PDF](https://arxiv.org/pdf/2510.26020), [HTML](https://arxiv.org/abs/2510.26020)
### Authors
Feijie Wu,Weiwu Zhu,Yuxiang Zhang,Soumya Chatterjee,Jiarong Zhu,Fan Mo,Rodin Luo,Jing Gao
### Background
目前的大语言模型（LLMs）被训练在静态数据集上，能够与外部工具互动并执行多步骤、集成工具的推理，产生工具调用轨迹。然而，这些模型模仿了一般工具调用程序是如何解决问题的，未能探索可能的解决方案，并且在不断变化的动态工具调用环境中表现出有限的性能。背景主要集中在模型缺乏探索不同解决方案的能力。
### Innovation
提出了一种基于强化学习（RL）的方法——PORTool，它激励工具使用LLM探索产生正确答案的各种轨迹。方法包括生成多个卷出，形成树状结构，并根据每一步生成正确答案的能力和成功调用工具的能力给予奖励。步长奖励用于计算分支相对优势和轨迹相对优势，以训练LLM进行工具使用。实验使用17种工具来处理用户查询，涵盖时效性和时效性问题。进一步进行ablation研究来证实步长奖励的必要性和设计的稳健性。对比PORTool与其他训练方法，展示了显著提高的最终准确率和工具调用步数。
### Conclusion
PORTool通过增强学习方法提高了工具使用LLM的性能，强调了步长奖励的重要性，证明了其在动态工具调用环境中的有效性，并促进了工具调用轨迹的多样化探索。
## 76. `cs.AI` - 基于Vision-Language模型的动态负提示生成方法在扩散模型中的应用 [PDF](https://arxiv.org/pdf/2510.26052), [HTML](https://arxiv.org/abs/2510.26052)
### Authors
Hoyeon Chang,Seungjin Kim,Yoonseok Choi
### Background
传统的负提示方法使用固定的负提示，而在去噪过程中，该研究提出了一种新颖的方法，利用Vision-Language模型（VLMs）在去噪过程中自适应地生成上下文相关性的负提示，以动态调整负提示的效果。
### Innovation
该研究提出了一种利用Vision-Language模型在去噪过程中生成动态负提示的新方法，不同传统的固定负提示方法，该方法在特定去噪步骤中生成中间图像预测并查询VLM来产生合适的负提示，从而实现更强的负提示指导和文本-图像对齐之间的权衡。
### Conclusion
该方法在各种基准数据集上进行了评估，并展示了负提示指导强度和文本-图像对齐之间的权衡。
## 77. `cs.AI` - SIRAJ: 通过精炼结构化推理实现LLM代理多样性高效红队测试 [PDF](https://arxiv.org/pdf/2510.26037), [HTML](https://arxiv.org/abs/2510.26037)
### Authors
Kaiwen Zhou,Ahmed Elgohary,A S M Iftekhar,Amin Saied
### Background
大型语言模型（LLM）代理具备计划和调用工具的能力，这使它们面临新的安全风险，因此建立全面的红队系统对于发现漏洞并确保其安全部署至关重要。
### Innovation
本文提出了一种称为SIRAJ的通用红队框架，用于任意黑盒LLM代理。该框架采用动态两步过程，首先定义代理并生成多样化的种子测试用例，覆盖各种风险结果、工具使用轨迹和风险源。然后基于先前尝试的执行轨迹构建并精炼基于模型的对抗攻击。为了优化红队成本，本文还提出了一种模型蒸馏方法，利用教师模型推理的结构化形式训练效果相当的小模型。在多种评估代理设置下，种子测试用例生成方法在风险结果和工具调用轨迹的覆盖率方面提升了2-2.5倍。精炼后的8B红队模型将攻击成功率提高100%，超越了671B的Deepseek-R1模型。消融分析和研究进一步验证了迭代框架、结构化推理的有效性以及我们的红队模型的泛化能力。
### Conclusion
本研究提出了一种SIRAJ框架，通过利用结构化推理进行模型蒸馏，有效提高LLM代理的安全性，其在泛化和提升攻击效果方面展示了显著的优势。
## 78. `cs.AI` - DARTS：一种基于无人机的AI驱动的实时交通事件检测系统 [PDF](https://arxiv.org/pdf/2510.26004), [HTML](https://arxiv.org/abs/2510.26004)
### Authors
Bai Li,Achilleas Kourtellis,Rong Cao,Joseph Post,Brian Porter,Yu Zhang
### Background
快速可靠的事故检测对于减少事故相关的死亡、伤残和拥堵至关重要。然而，传统的闭路电视监控、汽车记录仪录像和基于传感器的检测方法存在分离检测与验证、灵活性有限、需要密集的基础设施或高渗透率等问题，限制了其适应性和可扩展性，难以应对不断变化的事故热点。为了克服这些挑战，我们开发了DARTS，这是一种基于无人机、AI驱动的实时交通事件检测系统。
### Innovation
DARTS整合了无人机的高机动性和空中视角，进行适应性监控，通过热成像技术提高了低能见度环境中的性能和隐私保护，并采用了轻量级深度学习框架以实时提取车辆轨迹并检测事件。该系统在自收集的数据集上实现了99%的检测准确性，并支持通过基于网络的界面进行同时的在线视觉验证、事件严重性评估和事件引起的拥堵传播监控。田野试验显示，该系统比地方运输管理中心提前12分钟检测和验证了一起追尾事故，并监测了由事故引起的拥堵传播，表明其支持更快的应急响应和主动交通控制以减少拥堵和次生事故风险的潜力。DARTS的灵活部署架构降低了频繁实地巡逻的依赖，这意味着其具有在偏远地区和资源有限环境中进行广泛应用的前景和成本效益。
### Conclusion
本研究展示了一种更灵活和集成的实时交通事件检测系统的前景，对于现代交通管理操作效率和响应性具有重大影响。
## 79. `cs.AI` - Do Students Debias Like Teachers? On the Distillability of Bias Mitigation Methods [PDF](https://arxiv.org/pdf/2510.26038), [HTML](https://arxiv.org/abs/2510.26038)
### Authors
Jiali Cheng,Chirag Agarwal,Hadi Amiri
### Background
知识蒸馏(KD)是一种有效的方法，用于模型压缩和知识转移。然而，它对模型抵抗统计关联导致性能下降的鲁棒性影响尚未得到充分研究。本研究探讨了知识蒸馏对自然语言推理(NLI)和图像分类任务中“去偏差”能力从教师模型向学生模型的转移影响。通过大量实验，我们发现了以下几个关键发现：(i)总体而言，知识蒸馏后模型的去偏差能力受到削弱；(ii)训练去偏差模型并不受益于注入教师知识；(iii)尽管模型的整体鲁棒性可能在蒸馏后保持稳定，但不同类型的偏差会出现显著的变化；(iv)我们定位了导致知识蒸馏后不同行为的内部注意模式和电路。根据以上发现，我们提出了三种改进去偏差方法可蒸馏性的有效解决方案：开发高质量的数据进行增强、实施循环知识蒸馏以及使用教师模型权重初始化学生模型。
### Innovation
本研究首次系统地研究了知识蒸馏对去偏差和其内部机制的影响，揭示了知识蒸馏对去偏差能力的负面影响和具体机制。提出的解决方案包括：开发高质量的数据进行增强、实施循环知识蒸馏以及使用教师模型权重初始化学生模型，以提高去偏差方法的可蒸馏性。
### Conclusion
本研究结果提供了对知识蒸馏机制的理解，以及如何设计更好的去偏差方法的见解。
## 80. `cs.AI` - WaveVerif: 基于声学旁路的机器人工作流验证 [PDF](https://arxiv.org/pdf/2510.25960), [HTML](https://arxiv.org/abs/2510.25960)
### Authors
Zeynep Yasemin Erdogan,Shishir Nagaraja,Chuadhry Mujeeb Ahmed,Ryan Shah
### Background
在敏感的机器人环境中，确保机器人正确执行其预定命令至关重要。现有方法主要依赖视觉或机械传感器进行验证，但这些方法往往成本较高且可能对机器人操作产生干扰。因此，研究开发一种低成本、非侵入式的验证方法对于提高机器人系统的安全性和可靠性至关重要。声学旁路分析（ASCA）通过检测和分析机器人操作产生的声学信号，提供了一种潜在的解决方案，可以在不修改硬件的情况下进行实时验证。
### Innovation
本文提出了一种基于声学旁路分析（ASCA）的验证框架，使用声学发射信号监测和验证机器人是否正确执行其预定命令。该框架开发了一种基于机器学习的实时验证工作流系统，能够准确判断机器人动作是否与预期指令一致。评估结果表明，在基线条件下，使用支持向量机（SVM）、深度神经网络（DNN）、循环神经网络（RNN）和卷积神经网络（CNN）四种分类器，个体机器人动作的验证准确率超过80%。此外，拣选和放置以及打包等工作流程也能被高置信度地识别。这项研究证实了声学信号可以在不修改硬件的情况下支持实时、低成本的被动验证。
### Conclusion
本文提出并评估了一种基于声学旁路分析（ASCA）的验证框架，使用机器人操作产生的声学信号进行实时、低成本的机器人工作流验证。结果表明，该系统能够在基线条件下达到较高的验证准确率，并适用于多种复杂工作流程。未来的工作将进一步优化系统性能并探索更多应用场景。
## 81. `cs.AI` - 基于数据驱动的投影生成以高效解决异构二次规划问题 [PDF](https://arxiv.org/pdf/2510.26061), [HTML](https://arxiv.org/abs/2510.26061)
### Authors
Tomoharu Iwata,Futoshi Futami
### Background
本文提出了一个基于数据驱动的框架，该框架通过减少高维二次规划（QP）问题中的变量数量，利用实例特定的投影高效解决QP问题。为了生成针对每个QP实例定制的投影，作者设计了一个基于图神经网络的模型，以最小化在投影解上评估的预期目标值。这个目标被形式化为一个 bilevel 优化问题，内层优化求解给定投影下的QP问题，外层优化更新模型参数。同时，作者提供了一个理论分析，解释了使用由神经网络生成的投影矩阵求解QP问题的一般泛化能力。在实验中，该方法生成了高质量的可实现解，同时减少了计算时间，表现出色，优于现有方法。
### Innovation
提出了一种基于数据驱动的框架，利用实例特定的投影减少高维二次规划问题中的变量数量，采用图神经网络生成针对每个QP实例定制的投影。this善于利用bilevel优化方法更新模型参数，计算参数梯度无需回传到求解器中。
### Conclusion
实验结果表明，作者的方法能够在减少计算时间的同时生成高质量的可行解，优于现有方法。此外，提供了一个理论分析，解释了使用神经网络生成的投影矩阵求解QP问题的一般泛化能力。
## 82. `cs.AI` - 学习几何：通过度量优化构建适应性流形模型的框架 [PDF](https://arxiv.org/pdf/2510.26068), [HTML](https://arxiv.org/abs/2510.26068)
### Authors
Di Zhang
### Background
现有机器学习方法大多专注于传统参数优化，这类方法在固定的几何空间内搜索最优参数。然而，这种方法固定了几何结构，可能无法充分适应数据的变化。因此，本文提出了一种新的范式，将模型本身视为可塑的几何实体，通过优化具有预定义拓扑结构的流形上的度量张量场来动态塑造模型空间的几何结构。
### Innovation
本文的核心创新在于开发了一种新的范式，通过优化具有预定义拓扑结构的流形上的度量张量场，动态塑造模型空间的几何结构。此方法使用变分框架，并通过平衡数据保真度和流形固有的几何复杂性来构建损失函数。在计算上，本文提出了基于离散微分几何的实用方法，即将连续流形离散化为三角网，并用边长参数化度量张量，从而利用自动微分工具实现高效的优化。
### Conclusion
本文的研究为构建能够自主演化其几何和拓扑结构的“元学习器”奠定了坚实的基础，并且拓扑固定时，度量优化相较于固定几何结构的模型具有显著更大的表示能力。此外，这种框架具有广泛的潜在应用前景，特别是在科学模型发现和稳健表示学习方面。
## 83. `cs.AI` - SAFE：通过地球分层评估预测的新颖方法来评估AI天气 [PDF](https://arxiv.org/pdf/2510.26099), [HTML](https://arxiv.org/abs/2510.26099)
### Authors
Nick Masi,Randall Balestriero
### Background
目前机器学习的主流评估模型性能的方法是基于测试集所有样本的平均损失。这种方法在天气和气候领域表现为地球上的地理平均性能评估，却没有考虑到人类发展和地理分布的非均匀分布。SAFE（Stratified Assessments of Forecasts over Earth，地球分层评估预测）是一个包，用于阐明一系列在地球上做出的预测的分层性能。它通过整合不同数据领域，根据不同属性对地理网格点进行分层：领土（通常是国家）、全球次区域、收入和土地覆盖（陆地或水域），从而允许我们对每种单独属性的性能进行评估。
### Innovation
SAFE方法通过整合各种数据领域来对地理网格点进行分层，按领土（国家）、全球次区域、收入和土地覆盖（陆地或水域）对模型进行分层评估。在此基础上，SAFE通过分层统计不同气候变量在不同提前量的模型预报公平性基准，首次明确指出哪些地区模型表现最好或最差，以及哪些模型最公平。
### Conclusion
SAFE包是开源的并可在这个网址获取，它通过分层评估而超越了全球平均指标，首次解决了模型在何处表现最好或最差，以及哪些模型最公平的问题，辅助进一步的相关研究和发展。
## 84. `cs.AI` - Nirvana: 一种具有任务感知记忆机制的专门通用模型 [PDF](https://arxiv.org/pdf/2510.26083), [HTML](https://arxiv.org/abs/2510.26083)
### Authors
Yuhua Jiang,Shuang Cheng,Yihao Liu,Ermo Hua,Che Jiang,Weigao Sun,Yu Cheng,Feifei Gao,Biqing Qi,Bowen Zhou
### Background
传统的大型语言模型（LLM）结构，如Transformer、线性注意机制和混合模型，虽然具有强大的泛化能力，但缺乏针对特定任务的专门记忆机制，无法在任务信息的引导下优化记忆过程。因此，Specialized Generalist Models（SGMs）旨在保留广泛的适应能力同时，在目标领域中达到专家级的性能。然而，现有的SGM结构未能显著优化时间复杂度和任务信息的即时提取。
### Innovation
本文提出了一种名为Nirvana的SGM，它具有专门的记忆机制、线性时间复杂度和测试时的任务信息提取功能。Nirvana引入了Task-Aware Memory Trigger（Trigger）和Specialized Memory Updater（Updater）机制。Trigger机制能够根据当前任务的要求灵活调整记忆机制。Updater机制能够根据Trigger机制动态地记忆上下文。实验证明，Nirvana在多种自然语言建模基准上取得了具有竞争力或优于现有LLM结构的结果。特别是在医疗领域（如MRI），Nirvana即使在预训练的模型骨干网络未更新的情况下，通过Trigger机制也能实现对MRI领域的适应，并产生高质量的MRI重建和准确的临床报告。
### Conclusion
Nirvana在多种自然语言任务和专门的医疗任务中展现了卓越的能力，特别是通过任务感知记忆机制优化了模型对特定领域的适应性，这验证了Nirvana的创新性和有效性。
## 85. `cs.AI` - 基于网络约束的适应性多agent车辆路径优化策略 [PDF](https://arxiv.org/pdf/2510.26089), [HTML](https://arxiv.org/abs/2510.26089)
### Authors
Fazel Arasteh,Arian Haghparast,Manos Papagelis
### Background
城市道路网络中的交通拥堵导致行程时间延长和排放量增加，尤其是在高峰期。传统的最短路径优先（Shortest Path First, SPF）算法在静态单车辆场景中是有效的，但在动态的多车辆环境中表现不佳，往往会通过相同的路径增加拥堵情况。为解决多车辆的动态路径规划问题，在多智能体强化学习（MARL）框架下，提出了一种网络感知的协作路径导航方法。该方法通过自适应导航（AN）和多级核心交叉点自适应导航（HHAN）来优化路径选择，减少交通拥堵和提高行程效率。
### Innovation
提出的AN和HHAN方法利用了自适应导航和多级核心交叉点优化策略，结合了局部交通状态和网络拓扑信息，通过图注意力网络（Graph Attention Networks, GAT）进行路径规划。HHAN进一步扩展了AN的方法，通过集中训练与分散执行（Centralized Training with Decentralized Execution, CTDE）配合注意机制（Attentive Q-Mixing, A-QMIX）聚合异步决策，用于大型网络中的路径优化，保持了高效的路径选择成功率和旅程时间优化效果。
### Conclusion
实验表明，AN和HHAN方法在合成网格和实际城市地图中显著减少了平均行程时间，HHAN在拥堵的网络中还能进一步提高效率达15.9%。此研究展示了网络约束条件下的MARL方法在智能交通系统中的潜力，实现了可扩展、协调且能感知拥堵的路径优化策略。
## 86. `cs.AI` - 多模态模型中文本与图像之间对齐的安全风险 [PDF](https://arxiv.org/pdf/2510.26105), [HTML](https://arxiv.org/abs/2510.26105)
### Authors
Xiaosen Wang,Zhijin Ge,Shaokang Wang
### Background
尽管多模态扩散模型如文本到图像模型取得了显著进展，但它们对恶意输入（对抗输入）的脆弱性仍然被忽视。现有的研究表明，文本和图像模态之间的对齐在现有模型中是不足的。这种不对齐会导致生成不适当或不适合公开（Not-Safe-For-Work, NSFW）的内容。现有方法主要是通过生成对抗性提示来创建NSFW内容，但本文提出了一种名为Prompt-Restricted Multi-modal Attack (PReMA)的新攻击方法，通过修改输入图像来操纵生成的内容，而不需要改变提示本身。
### Innovation
本文提出的PReMA攻击是通过生成对抗性图像来操纵多模态扩散模型的输出，而不同于传统方法主要生成对抗性提示。这种方法可以特别用于固定提示的操作，如图像修复和样式迁移任务中。
### Conclusion
针对图像填充和样式转换任务进行了全面评估，结果显示PReMA具有很强的效能，对多模态扩散模型的完整性构成了新的威胁，特别是在使用固定提示的应用中。
## 87. `cs.AI` - EgoExo-Con: 探索视角不变的视频时间理解 [PDF](https://arxiv.org/pdf/2510.26113), [HTML](https://arxiv.org/abs/2510.26113)
### Authors
Minjoon Jung,Junbin Xiao,Junghyun Kim,Byoung-Tak Zhang,Angela Yao
### Background
现有视频大模型（Video-LLMs）在处理从不同视角捕捉同一事件的视频时，往往无法保持一致的时间理解，尤其是在跨视角一致性方面表现不佳。本研究旨在通过引入EgoExo-Con基准测试，评估Video-LLMs的时间理解能力，并探讨改善现有模型跨视角一致性的方法。
### Innovation
研究团队首次构建了一个名为EgoExo-Con的综合性视角同步视频对基准，包含人细化的自然语言查询，并着重评估了Temporal Verification和Temporal Grounding任务。研究发现了现有Video-LLMs的两个关键限制，并提出了一种名为View-GRPO的新型强化学习框架来增强视角特定的时间推理并促进跨视角的一致理解。该方法在跨视角一致性方面的表现优于简单的微调和标准的GRPO方法。所有资源将公开提供。
### Conclusion
现有Video-LLMs在跨视角一致性方面存在显著限制。EgoExo-Con基准测试展示了现有模型在跨视角一致性方面的不足，并提出了View-GRPO框架来改善这一问题。该方法显著提升了跨视角的一致性，表明未来的研究可以在该领域取得进展。
## 88. `cs.AI` - 通过子结构感知对齐弥合分子和文本描述之间的差距 [PDF](https://arxiv.org/pdf/2510.26157), [HTML](https://arxiv.org/abs/2510.26157)
### Authors
Hyuntae Park,Yeachan Kim,SangKeun Lee
### Background
分子和文本表示学习因提升对化学信息的理解而获得越来越多的关注。然而，现有的模型往往难以捕捉到分子及其描述之间的细微差异，因为它们缺乏学习分子亚结构和化学短语之间的细微对齐的能力。
### Innovation
本文提出了一种名为MolBridge的新型分子-文本学习框架，基于亚结构感知对齐。具体地，MolBridge通过从分子亚结构和化学短语中提取额外的对齐信号来增强原始的分子-描述对。为了有效学习这些丰富的对齐信息，MolBridge结合了亚结构感知对比学习，并使用自我精炼机制来过滤掉噪声对齐信号。实验结果表明，MolBridge能够捕捉到细微的对应关系，并在多种分子基准上的表现优于最先进的基线，强调了亚结构感知对齐在分子-文本学习中的重要性。
### Conclusion
MolBridge在多种分子基准上的表现优于最先进的基线，表明在分子-文本学习中使用亚结构感知对齐的重要性。
## 89. `cs.AI` - WOD-E2E：针对挑战性长尾场景的Waymo开源数据集 [PDF](https://arxiv.org/pdf/2510.26125), [HTML](https://arxiv.org/abs/2510.26125)
### Authors
Runsheng Xu,Hubert Lin,Wonseok Jeon,Hao Feng,Yuliang Zou,Liting Sun,John Gorman,Kate Tolstaya,Sarah Tang,Brandyn White,Ben Sapp,Mingxing Tan,Jyh-Jing Hwang,Drago Anguelov
### Background
基于视觉的端到端(E2E)驾驶在研究界引起了广泛关注，因其可扩展性和与多模态大型语言模型(MLLMs)的协同作用。然而，当前的E2E驾驶基准主要包含了例行公事的情景，无法充分测试这些系统的潜力。此外，现有的开环评估指标在捕捉驾驶的多模态性质或有效评估长尾场景的性能方面往往表现不足。
### Innovation
我们提出了Waymo Open Dataset for End-to-End Driving (WOD-E2E)，它包含4,021个驾驶段（约12小时），专门用于现实生活中的罕见、具有挑战性的长尾场景。每个段落包含高一级路由信息、ego状态以及从8个周围摄像头的360度视图。我们还提出了一种新的开环评估指标：评分反馈得分(RFS)，以评估E2E驾驶在长尾情况下的性能。通过这种方法，我们希望能够促进研究，推动开发出通用、稳健和安全的端到端自主驾驶代理，能够处理复杂的现实世界情况。
### Conclusion
通过我们的工作，我们致力于推动对此类系统的研究，旨在发现能够在复杂现实世界环境中处理复杂情况的先进、稳健和安全的端到端自主驾驶代理。比赛数据集中的标注已被释放，而保留的测试集标签则用于2025年的WOD-E2E挑战。
## 90. `cs.AI` - 超越简单效用函数学习管理投资组合 [PDF](https://arxiv.org/pdf/2510.26165), [HTML](https://arxiv.org/abs/2510.26165)
### Authors
Maarten P. Scholl,Mahmoud Mahfouz,Anisoara Calinescu,J. Doyne Farmer
### Background
股权投资基金在公开声明其目标时，实际由基金经理优化复杂的竞争性目标组合，这超出了简单的风险-收益权衡。传统的建模方法试图通过多目标效用函数来模拟这一点，但面临着在具体化和参数化方面的重要挑战。
### Innovation
本文提出了一个生成型框架，该框架能够学习基金经理策略的潜在表示，而无需明确指定效用函数。其直接建模条件概率：给定股票特征、历史回报、先前权重和代表基金策略的潜在变量，投资组合权重的概率。与基于强化学习或模仿学习的方法相比，本文的GAN架构直接从观察到的持仓和市场数据的联合分布中学习，而非依赖于规定奖励或专家标签。
### Conclusion
本文框架提供了数据驱动的方法，用于描述投资策略在市场模拟、策略归因和监管监督中的应用。通过一系列测试，展示了基准上的专家标签以线性可解释的方式包含在模型的编码中。
## 91. `cs.AI` - 超越合成基准：评估大语言模型在真实世界类级代码生成中的性能 [PDF](https://arxiv.org/pdf/2510.26130), [HTML](https://arxiv.org/abs/2510.26130)
### Authors
Musfiqur Rahman,SayedHassan Khatoonabadi,Emad Shihab
### Background
大语言模型（LLMs）在函数级别提高了代码生成能力，但在真实软件项目中产生正确类级实现的效果仍然不清楚。本文通过从开源仓库中提取基准测试，将真实世界的类分为已知和未知部分，评估LLMs在实际条件下的泛化能力。测试涵盖了多种LLMs在不同输入规格、检索增强配置和文档完整性水平下的表现。结果显示，对于已确立的合成基准，LLMs的正确率为84%到89%，但在真实类任务中的正确率只有25%到34%，熟悉的和新颖代码库之间的差异很小。详细文档字符串在功能准确性方面有1%到3%的提升效果，但统计显著性罕见。检索增强生成在部分文档情况下最有效，通过提供从规格中缺乏的具体实现模式，可以提高4%到7%的正确性，减少逻辑错误但可能引入依赖冲突。错误分析指出，AttributeError、TypeError和AssertionError是主要故障模式，合成测试过度强调断言问题，而真实场景突显类型和属性匹配问题。这项基准和分析揭示了当前LLMs在类级工程方面的关键局限性，提供了有关提升上下文建模、文档策略和检索集成在生产代码辅助工具中的实用见解。
### Innovation
本文提出了一个新颖的基准，它是从开源仓库中提取的真实世界类，分为已知和未知部分，用于评估LLMs在实际条件下的泛化能力。测试涵盖多种LLMs在不同输入规格、检索增强配置和文档完整性水平下的表现。这项工作通过识别特定错误类型，提供了LLMs在类级实现方面的局限性见解，并提出了改进建议。
### Conclusion
对于已确立的合成基准，LLMs的正确率为84%到89%，但在真实类任务中的正确率只有25%到34%，部分文档的情况下检索增强生成表现出的效果最佳。基准和分析揭示了当前LLMs在类级工程方面的关键局限性，为提高语言模型在真实世界应用中的性能提供了宝贵的行动建议。
## 92. `cs.AI` - 复杂性优于分割：在工业时间序列异常检测中评估集成和混合方法 [PDF](https://arxiv.org/pdf/2510.26159), [HTML](https://arxiv.org/abs/2510.26159)
### Authors
Emilio Mastriani,Alessandro Costa,Federico Incardona,Kevin Munari,Sebastiano Spinello
### Background
研究团队探讨了在多变量工业时间序列（以蒸汽涡轮系统为例）中高级特征工程和混合模型架构对异常检测的有效性。评估了基于变化点统计特性的特征、基于聚类的子结构表示以及混合学习策略对检测性能的影响。尽管这些复杂方法在理论上具有吸引力，但在实验中却始终逊色于一个简单的随机森林+极端梯度提升集成模型，该模型在分割数据上训练，并且在给定的时间窗口内实现了100%的早期检测，AUC-ROC为0.976，F1分数为0.41。这些复杂模型的实验结果表明，在高度不平衡且时间上高度不确定的数据情况下，简单模型结合优化分割可以比更复杂的架构表现得更好，提供了更大的稳健性、可解释性和操作实用性。
### Innovation
提出并评估了一种基于分割的、相对简单的模型集成方法在工业时间序列异常检测中的应用，这种方法能在复杂且不确定的数据场景中提供更好的性能。不同于传统的复杂模型的尝试，这种方法的有效性和可实现性得到强调。
### Conclusion
研究成果表明，在工业时间序列中，尤其是在数据高度不平衡且具有时间不确定性的情况下，简单的模型结合优化的分割段优于复杂的混合学习模型。这种简单模型不仅提供了更好的稳健性，还提高了模型的可解释性和操作实用性。
## 93. `cs.AI` - MV-MLM: 联合多视角乳腺摄影和语言以进行乳腺癌诊断和风险预测 [PDF](https://arxiv.org/pdf/2510.26151), [HTML](https://arxiv.org/abs/2510.26151)
### Authors
Shunjie-Fabian Zheng,Hyeonjun Lee,Thijs Kooi,Ali Diba
### Background
培训班-based 诊断（CAD）模型训练需要大量注释的数据库，而获得具有精细注释的数据库既昂贵又耗时。通过使用预训练的视觉-语言模型（如CLIP）来增强医疗成像任务的鲁棒性和数据效率，提供了一种有前景的解决方案。现有的基线模型要么需要实时放射学报告，要么需要实际的放射学报告，而且这些方法要么数据效率低，要么不能达到最先进的性能。本文中的MV-MLM模型通过结合多视角监督来解决问题，利用跨模态自监督从大量放射学数据中学习丰富的表征，并提出了一种联合视觉-文本学习策略来增强泛化性能并提高准确性，同时能够在不依赖实际放射学报告的情况下实现最先进的性能。
### Innovation
引入了一个名为MV-MLM的新颖多视角乳腺摄影和语言模型，该模型在配对的乳腺X光片图像和合成放射学报告的数据集上进行训练。MV-MLM通过跨模态自监督利用多视角监督，结合多种视图及其相应的伪放射学报告。该模型提出了一种联合视觉-文本学习策略，以提高不同数据类型和任务的泛化和准确性，并通过合成文本报告进行了训练，而无需实际放射学报告。
### Conclusion
在私人和公共可用的数据集上进行了评估，表明该方法在三项分类任务中实现了最先进的性能：(1) 恶性肿瘤分类，(2) 副型分类，(3) 基于图像的癌症风险预测。此外，该模型表现出很强的数据效率，即使在合成性文本报告中训练，而无需使用实际的放射学报告，也优于现有的完全监督或视觉语言模型基线。
## 94. `cs.AI` - ConceptScope: 通过解纠缠的视觉概念表征数据集偏见 [PDF](https://arxiv.org/pdf/2510.26186), [HTML](https://arxiv.org/abs/2510.26186)
### Authors
Jinho Choi,Hyesu Lim,Steffen Schneider,Jaegul Choo
### Background
在机器学习的图像数据集中普遍存在数据点偏向特定概念的偏差。然而，系统地识别这些偏差需要昂贵的、细致的属性注释，从而变得具有挑战性。
### Innovation
本文提出了一种名为ConceptScope的框架，通过使用从视觉基础模型获得的表示训练的稀疏自编码器发现和量化可解释的人类概念，从而实现大规模的自动化分析。该框架能够基于语义相关性和统计关联将概念分类为目标、上下文和偏差类型，从而实现面向类别的数据集表征、偏差识别和基于概念的亚组分析评估稳健性。
### Conclusion
验证了ConceptScope能够捕捉多种视觉概念，并能够可靠地检测已知的偏差（如Waterbirds中的背景偏差）和发现未注释的偏差（如ImageNet中的共现对象），为数据集审计和模型诊断提供了一个实用工具。
## 95. `cs.AI` - Accumulative SGD Influence Estimation for Data Attribution [PDF](https://arxiv.org/pdf/2510.26185), [HTML](https://arxiv.org/abs/2510.26185)
### Authors
Yunxiao Shi,Shuo Yang,Yixin Su,Rui Zhang,Min Xu
### Background
现代以数据为中心的AI需要精确的单样本影响。标准的SGD-IE通过累积每个周期的替代品来近似留一法效应，但忽略了跨周期的影响累积效应，这会导致某个例子被错误地排名为关键的例子。这篇文章探讨了累积SGD影响估计的必要性。
### Innovation
提出了ACC-SGD-IE，这是一种路径感知的估计器，能够在训练过程中传播留一法扰动，并在每一步更新累积影响状态。在光滑严格凸设置中，它实现了几何误差收缩；在光滑非凸区域，它紧缩了误差边界；较大的迷你批量进一步减少了常数。实验证明，与标准SGD-IE相比，ACC-SGD-IE在成人数据集、20个新sgroups数据集和MNIST数据集上，尤其是在长时间训练周期中，提供了更准确的影响估计。此外，在噪声数据上进行数据清理时，它更可靠地标识了噪声样本，从而在使用ACC-SGD-IE数据清理后的模型比使用SGD-IE数据清理后的模型表现更好。
### Conclusion
ACC-SGD-IE方法旨在改进SGD-IE的不精确性和对跨周期影响的忽视，通过路径感知的估计器提高数据影响估计的准确性，在多种数据集和不同类型的训练下，ACC-SGD-IE能够更准确地估计单样本影响，并且在数据清理后，使用ACC-SGD-IE进行数据清理的模型表现更好。
## 96. `cs.AI` - 用协调的代理流程连接异构数据以进行社交媒体分析 [PDF](https://arxiv.org/pdf/2510.26172), [HTML](https://arxiv.org/abs/2510.26172)
### Authors
Shifu Chen,Dazhen Deng,Zhihong Xu,Sijia Xu,Tai-Quan Peng,Yingcai Wu
### Background
社交媒体平台生成大量异构数据，这些数据捕捉了用户行为、文本内容、时间动态和网络结构。分析这些数据对于理解意见动态、社区形成和信息扩散现象至关重要。然而，从这一复杂环境中发现有价值的见解是探索性的、概念上具有挑战性的，并且需要社交媒体挖掘和可视化方面的专业知识。现有的自动化方法尽管越来越多地利用大型语言模型（LLMs），但主要局限于结构化的表格式数据，无法充分解决社交媒体分析中的异质性。
### Innovation
本文提出了SIA（Social Insight Agents），这是一种LLM代理系统，通过协调的代理流动连接异构多模式数据。SIA通过底层分类学将洞察类型与合适的挖掘和可视化技术联系起来，使代理能够规划和执行一致的分析策略。SIA还包含一个数据协调器，将表格、文本和网络数据统一到一致的流程中。此外，SIA提供交互式界面，让用户可以追踪、验证和细化代理的推理过程，从而支持适应性和可信性。
### Conclusion
通过以专家为中心的案例研究和定量评估，我们展示了SIA有效地从社交媒体中发现多样化的有意义的见解，并支持在复杂分析任务中的人-代理协作。
## 97. `cs.AI` - 我的人类反馈中有什么？学习可解释的偏好数据描述 [PDF](https://arxiv.org/pdf/2510.26202), [HTML](https://arxiv.org/abs/2510.26202)
### Authors
Rajiv Movva,Smitha Milli,Sewon Min,Emma Pierson
### Background
人类反馈可以以不可预测且可能不理想的方式改变语言模型，因为从业者缺乏对反馈数据所编码内容的清晰理解。现有研究主要关注某些属性的偏好（如长度或奉承），但在无需预先假设的情况下自动提取相关特征仍然具有挑战性。
### Innovation
本文引入了一种名为WIMHF（What's In My Human Feedback）的方法，使用稀疏自编码器解释反馈数据，并识别数据层面和注释者表达的偏好。WIMHF能够识别出少量可解释的特征，解释了黑盒模型实现的大部分偏好预测信号，揭示了人类在偏好方面的多样性和环境角色。此外，WIMHF还揭示了潜在的不安全偏好，并通过重新标记有害示例实现了显著的安全收益，同时提高了个人化预测能力。
### Conclusion
WIMHF提供了一种以人为本的分析方法，帮助从业者更好地理解并使用偏好数据。该研究强调了对人类反馈数据进行解释和利用的重要性，以实现更安全和个性化的语言模型开发。
## 98. `cs.AI` - 从住院患者医疗索赔数据预测全因重新住院 [PDF](https://arxiv.org/pdf/2510.26188), [HTML](https://arxiv.org/abs/2510.26188)
### Authors
Avinash Kadimisetty,Arun Rajagopalan,Vijendra SK
### Background
降低可以预防的重新住院是各保险公司、医疗服务提供者和政策制定者提高医疗服务质量和降低医疗成本的国家优先事项。住院重新住院率被用作衡量医院提供医疗服务质量的标准。本文中，我们使用了机器学习技术如逻辑回归、随机森林和支持向量机分析健康索赔数据，识别预测所有原因重新住院的重要的人口统计和医学因素。由于健康索赔数据的高维特性，我们使用主成分分析法作为降维技术，并利用降维结果建立回归模型。模型基于AUC指标进行比较和评估，随机森林模型表现最佳，其次是逻辑回归和支持向量机模型。这些模型可以用于识别导致重新住院的关键因素，并帮助识别需要重点关注的患者，从而降低费用并提高对患者的医疗服务水平
### Innovation
利用机器学习技术（逻辑回归、随机森林和支持向量机）分析高维健康索赔数据，通过主成分分析进行降维，以预测所有原因的重新住院情况，并比较不同模型的表现，得出随机森林模型最佳的结论，为降低医疗成本和提高医疗服务提供策略
### Conclusion
使用机器学习模型分析高维健康索赔数据，可以有效识别导致重新住院的关键因素，帮助识别重点人群，从而降低重新住院率，减少医疗成本，提高患者医疗服务水平
## 99. `cs.AI` - 在预逻辑输出空间通过基于采样的最优控制实现大规模语言模型的测试时对齐 [PDF](https://arxiv.org/pdf/2510.26219), [HTML](https://arxiv.org/abs/2510.26219)
### Authors
Sekitoshi Kanai,Tsukasa Yoshida,Hiroshi Takahashi,Haru Kuroki,Kazumune Hashimoto
### Background
由于微调大规模语言模型（LLMs）所需的高计算成本，测试时对齐（test-time alignment）LLMs引起了人们的关注。现有方法中，最佳of-n取样（best-of-n sampling）方法在使用样本数量和奖励方面表现出稍逊一筹。
### Innovation
本文提出了一种新的测试时对齐方法——预逻辑输出上的自适应重要性采样（AISP）。该方法基于基于采样的模型预测控制并采用随机控制输入。AISP通过引入高斯扰动到预逻辑输出来最大化关于扰动均值的预期奖励。实验表明，AISP在使用样本数量和奖励方面均优于最佳of-n取样，并且获得了比其他基于奖励的测试时对齐方法更高的奖励。
### Conclusion
AISP 方法在测试时对齐 LLMs 方面表现出色，能够通过减少计算成本获得更高的奖励，为改善大规模语言模型的测试时性能提供了新的思路。
## 100. `cs.AI` - Don't Let It Fade: 通过Token时间步分配在扩散语言模型中保留编辑 [PDF](https://arxiv.org/pdf/2510.26200), [HTML](https://arxiv.org/abs/2510.26200)
### Authors
Woojin Kim,Jaeyoung Do
### Background
扩散语言模型（DLMs）虽然能够实现精细的微调，但其实用控制仍然脆弱。在这项研究中，作者识别并形式化了一个核心失败模式称为更新忘记，即统一且上下文无关的更新会在时间步骤中引起token级别的波动，抹去先前的语义编辑，破坏累积的微调过程，从而降低连贯性和流畅性。因为这一失败源于统一且上下文无关的更新，有效的控制需要明确的token排序。当前的挑战在于如何实现这种排序以提高控制能力并确保流畅性。
### Innovation
作者提出了Token时间步分配（TTA），该方法通过每个token的时间步调度实现软性和语义的token排序：关键token在早期冻结，而不确定的token继续进行微调。这种方法的时间步序列表现可以为固定策略或根据任务信号驱动的自适应策略，从而支持广泛的微调策略。TTA在两种具体应用场景中证明了其有效性：情感控制和去污处理。结果显示，TTA在这些任务中提高了控制能力和流畅性，具体表现为在情感控制中准确率提高了20%以上，困惑度几乎减少了一半，而使用不到五分之一的步骤；在去污处理中，最高毒性降低了（12.2对比14.5），困惑度也降低了（26.0对比32.0）。
### Conclusion
研究表明，通过时间步分配实现柔和排序是缓解更新忘记的关键杠杆，有利于扩散文本生成的稳定性和可控性。
## 101. `cs.AI` - 迈向全局检索增强生成：一种语料级推理基准 [PDF](https://arxiv.org/pdf/2510.26205), [HTML](https://arxiv.org/abs/2510.26205)
### Authors
Qi Luo,Xiaonan Li,Tingshuo Fan,Xinchi Chen,Xipeng Qiu
### Background
检索增强生成（RAG）已经成为减少大型语言模型（LLMs）幻觉的有效方法。当前的RAG评估基准主要集中在局部RAG上，即从一小部分文档中检索相关片段来回答仅需局部理解的具体文本片段的问题查询。然而，许多实际应用需要一种不同的能力——全局RAG，它涉及在整个文档集合中聚合和分析信息以得出语料级别的洞察（例如，“2023年被引用最多的前10篇论文是什么？”）。因此，本文提出了GlobalQA——第一个专门设计用于评估全局RAG能力的基准，涵盖四个核心任务类型：计数、极值查询、排序和Top-k提取。
### Innovation
本文提出了GlobalRAG，这是一种多工具协作框架，通过片段级别检索保持结构一致性，整合LLM驱动的智能过滤以消除噪声文档，并集成聚合模块进行精确的符号计算。本文通过系统地评估不同的模型和基线，发现现有RAG方法在全局任务上的表现不佳，最强基准的最佳F1得分为1.51。GlobalRAG在Qwen2.5-14B模型上的F1得分为6.63，相比之下，最强基准的F1得分为1.51，验证了该方法的有效性。
### Conclusion
通过GlobalRAG框架，本文验证了在全局任务中的有效性，并提出了一种新的基准用于评估全局RAG能力，这填补了当前RAG评估的空缺。
## 102. `cs.AI` - 增益软件工程过程和软件产品的生成型AI研究路线图 [PDF](https://arxiv.org/pdf/2510.26275), [HTML](https://arxiv.org/abs/2510.26275)
### Authors
Domenico Amalfitano,Andreas Metzger,Marco Autili,Tommaso Fulcini,Tobias Hey,Jan Keim,Patrizio Pelliccione,Vincenzo Scotti,Anne Koziolek,Raffaela Mirandola,Andreas Vogelsang
### Background
生成型AI（GenAI）正迅速改变软件工程（SE）实践，影响SE过程的执行方式以及软件系统的设计、部署和演进。
### Innovation
本文采用设计科学研究方法构建了一个基于GenAI的SE增强路线图，该过程包括三个逐步整合多种证据的循环，如FSE 2025“软件工程2030”研讨会的协作讨论，快速文献综述，以及包含同行反馈的外部反馈环节。使用麦卢汉的四重奏概念工具系统地捕捉GenAI对SE过程和软件的转变影响，识别出了SE中四种基本形式的GenAI增强，并系统地描述了相关研究挑战和机遇。这些洞察被汇总成未来研究方向，并通过多轮过程和作者团队以及同行间的交叉验证，提供了一个透明、可重复的基础，用于分析GenAI对SE过程、方法和工具的影响，并为这一快速演化的领域内的未来研究提供框架。
### Conclusion
基于上述发现，文章最终为2030年软件工程做出了十个预测。
## 103. `cs.AI` - 使用混合自然语言处理和高阶量子近似优化的ISDA信用支持附加协议下的质押管理 [PDF](https://arxiv.org/pdf/2510.26217), [HTML](https://arxiv.org/abs/2510.26217)
### Authors
Tao Jin,Stuart Florescu,Heyu(Andrew)Jin
### Background
我们在ISDA信用支持附加协议(ISDA CSAs)的金融质押优化领域面临复杂的法律约束和优化空间问题，涉及到整数份额、Sheed A折现率、RA/MTA限制、以及发行人、货币和资产等级限制。这些因素构建了一个崎岖的、受法律约束的搜索空间，需要专门的优化方法来应对。
### Innovation
我们提出了一种专用的混合管道：(i) 显证控制的LLM抽取CSA条款为标准化的JSON格式；(ii) 量子启发式探索器，结合模拟退火和微级的高阶QAOA（HO-QAOA）算法对必选子QUBOs进行优化，以协调多资产移动；(iii) 带有加权风险感知的优化目标，包括移动、CVaR、资金定价超出等风险因素，同时包含明确的覆盖窗口U<=Reff+B；(iv) CP-SAT作为仲裁器验证可行性和差距，包括U限制预检查来报告最小可行缓冲B*。通过更高阶的术语编码，HO-QAOA能够精确针对那些地方交换未能获取各种限制的领域耦合。
### Conclusion
在政府债券数据集和多CSA输入上，我们的混合方法比强的古典基准BL-3分别在代表性案例上提升了9.1%、9.6%和10.7%的成本-变动-尾部前沿，在治理设置下提供了更好的成本-变动-尾部前沿表现。我们还发布了治理级别的相关技术文档、价值矩阵审核、权重来源认证、QUBO实现和CP-SAT跟踪记录，以确保结果可审核和可重现在多CSA输入场景下的性能提升。
## 104. `cs.AI` - 分布性多目标黑箱优化在扩散模型推理时多目标生成 [PDF](https://arxiv.org/pdf/2510.26278), [HTML](https://arxiv.org/abs/2510.26278)
### Authors
Kim Yong Tan,Yueming Lyu,Ivor Tsang,Yew-Soon Ong
### Background
扩散模型在学习复杂数据分布方面取得了成功，这推动了它们在高维多目标黑箱优化问题中的应用。现有方法通常采用外部优化循环，如进化算法，与扩散模型结合使用。然而，这些方法将扩散模型视为黑箱改进器，忽略了扩散生成过程中内部分布转换这一过程，从而限制了它们的效率。
### Innovation
提出了在推理时刻进行多目标生成（IMG）算法，优化扩散过程以生成同时满足多个目标的样本。具体来说，IMG 在扩散生成过程中根据预期的多目标值加权重采样。这种加权重采样策略确保了扩散生成的样本按照我们期望的多目标玻尔兹曼分布分布。此外，导出了多目标玻尔兹曼分布的有趣对数似然解释，它是分布式的多目标优化问题的最优解。
### Conclusion
我们为多目标分子生成任务实现了 IMG。实验表明，IMG 只需一次生成即可显著提高超体积，超过常见基于优化算法的基线方法往往需要数百次扩散生成。值得注意的是，我们的算法可以被视为优化的扩散过程，可以集成到现有方法中进一步提高其性能。
## 105. `cs.AI` - ChatGPT Atlas在网页游戏中的表现：探索OpenAI Agent的网页前沿 [PDF](https://arxiv.org/pdf/2510.26298), [HTML](https://arxiv.org/abs/2510.26298)
### Authors
Jingran Zhang,Ning Li,Justin Cui
### Background
ChatGPT Atlas通过引入网页互动的新能力，使得模型能够分析网页、处理用户意图并直接在浏览器中执行鼠标和键盘操作。尽管已经在信息检索任务上展示出能力，但在动态、互动的环境中，其表现仍较少被探索。本研究利用浏览器中的游戏作为测试场景，包括Google的T-Rex Runner、数独、飞行 Birds 和其他网页游戏，来评估Atlas在网页互动中的表现。
### Innovation
利用浏览器游戏作为测试场景，对OpenAI的ChatGPT Atlas在网页互动能力方面进行初步评估。通过内部游戏性能得分作为定量指标，评估Atlas在不同任务类型中的表现。
### Conclusion
研究结果表明，Atlas在逻辑推理任务如数独中表现出色，能够显著快于人类基准，但在需要精确时间和动手控制的实时游戏中表现不佳，常常无法越过初始障碍。这些结果表明，虽然Atlas在分析处理方面表现出色，但在需要实时互动的动态网页环境中仍存在明显限制。
## 106. `cs.AI` - Angular Steering: 在激活空间中的旋转进行行为控制 [PDF](https://arxiv.org/pdf/2510.26243), [HTML](https://arxiv.org/abs/2510.26243)
### Authors
Hieu M. Vu,Tan M. Nguyen
### Background
在大规模语言模型中控制特定行为以保持其通用能力是安全可靠的AI部署中的一个核心挑战。现有引导方法如向量加法和方向消减，受激活和特征方向定义的二维子空间限制，并且参数选择敏感，可能导致激活空间中未关联特征的意外相互作用。
### Innovation
介绍了Angular Steering，一种新型且灵活的行为调控方法，通过在固定二维子空间内旋转激活来操作。它以几何旋转方式向或远离目标行为方向定向，提供对拒绝和合作等行为的连续、精细控制。提出了一种改进的选择性变体，即自适应Angular Steering，它仅旋转与目标特征对齐的激活，增强了稳定性和连贯性。Angular Steering将现有的添加和正交化技术统合到几何旋转框架下，简化了参数选择，使模型在更广泛的调整范围内保持稳定。
### Conclusion
通过在多个模型家族和不同规模模型上的实验展示了Angular Steering实现稳健的行为控制，同时保持通用语言建模表现，强调了其灵活性、泛化能力和鲁棒性，优于先前的方法。
## 107. `cs.AI` - 通过结合扩散模型和退火朗格维动态进行后验采样 [PDF](https://arxiv.org/pdf/2510.26324), [HTML](https://arxiv.org/abs/2510.26324)
### Authors
Zhiyang Xun,Shivam Gupta,Eric Price
### Background
该研究背景涉及到针对已知噪声线性度量$y = Ax + ?xi$的分布$p(x)$，当有一个较好的先验近似$p(x)$时，如何从后验$p(x rvert y)$中进行采样。后验采样为图像修复、去模糊、MRI重建等任务提供了精确而公平的框架，但现有的近似方法通常难以在计算上实现。
### Innovation
本文创新在于提出了一种结合扩散模型和退火朗格维动态的方法，通过仅仅使用$L^4$界来解决得分误差问题，从而在多项式时间内实现条件采样。
### Conclusion
研究证明了一种方法，该方法通过结合扩散模型和退火朗格维动态，在相对于仅使用变分推理方法更宽松的情况下（仅需$L^4$界的得分误差），能够以多项式时间复杂度实现条件采样的目标。
## 108. `cs.AI` - 揭示语言模型处理数字的机制 [PDF](https://arxiv.org/pdf/2510.26285), [HTML](https://arxiv.org/abs/2510.26285)
### Authors
Michal Štefánik,Timothee Mickus,Marek Kadlčík,Bertram Højer,Michal Spiegel,Raúl Vázquez,Aman Sinha,Josef Kuchař,Philipp Mondorf
### Background
最近的研究表明，不同的大规模语言模型（LLMs）在处理数字时会收敛到相似且准确的输入嵌入表示。然而，这些发现与文档记录的LLMs处理数字信息时容易产生错误输出的倾向相矛盾。本文旨在通过研究语言模型如何处理数字以及这些机制的准确性下限来解释这种冲突。研究表明，尽管存在着表面的错误，不同的语言模型学习到了系统、高度准确且适用于不同隐藏状态和输入语境类型的数字表示。这使我们可以为每种LLM创建通用探针，并跟踪包括输出错误原因在内的信息到具体的层。研究结果为我们理解预训练LLM如何处理数字奠定了基础，并表明更准确的探针技术在LLM架构改进方面具有潜力。
### Innovation
本文创新性地研究了语言模型处理数字的机制，通过分析语言模型在各个隐藏状态和不同输入语境下处理数字的方式，揭示了它们学习到的贯通且准确的数字表示。研究还提出了针对各种LLM的通用探针，能够追踪到输出错误的原因，并指出更准确的探针技术可能在改进LLM架构方面发挥重要作用。
### Conclusion
本文揭示了预训练LLM在处理数字时采用的机制和准确性下限。虽然存在表面错误，但不同语言模型学习到的数字表示是系统且高度准确的，并且可以在各种上下文和隐藏状态下泛化。研究结果为理解LLM处理数字的方式提供了基础，并强调了更精确探针技术在细化LLM架构方面的潜力。
## 109. `cs.AI` - MPRU: 作为分类流水线的输出过滤器的模块化投影-重新分布去学习 [PDF](https://arxiv.org/pdf/2510.26230), [HTML](https://arxiv.org/abs/2510.26230)
### Authors
Minyi Peng,Darian Gunamardi,Ivan Tjuawinata,Kwok-Yan Lam
### Background
现有的机器去学习（MU）工作通常侧重于理论推导或优化目标以实现知识的清除，但在实际部署中，这些解决方案通常遇到可扩展性问题，并需要对原始数据集和模型有完全访问权限。与其他现有方法不同，本文提出了一种将分类训练视为逐步过程的方法，即逐步学习每个类别，称为归纳方法。通过在模型末尾添加一个投影-重新分布层来实现去学习。这种策略不需要对原始数据集或模型有完全访问权限，解决了现有方法的挑战。这种方法允许在最小改动的情况下作为输出过滤器进行模块化和模型无关的应用部署，适用于现有的分类流水线。实验结果表明，在多个数据集（包括CIFAR-10/100中的卷积神经网络模型和Covertype中的基于树模型）上，与完全重新训练模型相比，具有较高的计算成本减少，且输出结果一致类似。这证明了该方法的适用性、可扩展性和系统兼容性，同时保持了更实际环境下的输出性能.
### Innovation
该研究提出了一种称为MPRU的模块化投影-重新分布去学习方法（Modular Projection-Redistribution Unlearning），用于分类流水线。这种技术通过在模型的末尾添加一个投影-重新分布层来实现去学习过程，这种方法不需要对原始数据集和模型有完全访问权限。这种方法不仅解决了现有方法的可扩展性和数据访问问题，还使得该方法适用于模块化和模型无关的应用场景，并在一个简化的流程中保持了性能。
### Conclusion
实验结果显示，MPRU方法能够有效减少计算成本同时保持较高的分类精度。该研究的方法是模块化的并且适用于多种分类模型和数据集，具有广泛的实际应用前景。
## 110. `cs.AI` - Per样本Adam在可分数据上的隐式偏差：偏离全批量区间 [PDF](https://arxiv.org/pdf/2510.26303), [HTML](https://arxiv.org/abs/2510.26303)
### Authors
Beomhan Baek,Minhak Song,Chulhee Yun
### Background
Adam 是深度学习中实际使用的默认优化器，但其理论理解仍然有限。此前的研究表明，Adam 倾向于 $boldsymbol{text{ℓ}_text{∞}}$ 几何结构的解，这些结果仅适用于全批量区间。
### Innovation
本文研究了一次采样步骤的增量 Adam (用于线性可分数据的逻辑回归) 的隐式偏差，发现其偏差可能会偏离全批量行为。作者通过构建一类结构化数据集，证明了增量 Adam 可以证明收敛到 $boldsymbol{text{ℓ}_2}$-极值边际分类器，而全批量 Adam 倾向于 $boldsymbol{text{ℓ}_text{∞}}$-极值边际。此外，通过一个代理算法，作者还描述了增量 Adam 的收敛方向随数据集变化的情况，并证明 Signum 在任何批量大小时都收敛到 $boldsymbol{text{ℓ_text{∞}}}$-极值边际分类器。
### Conclusion
总体而言，本文结果强调了 Adam 的隐式偏差依赖于批量方式和数据集，而 Signum 则相对不变。
## 111. `cs.AI` - 从词元层次因果视角理解视觉-语言组合性难度 [PDF](https://arxiv.org/pdf/2510.26302), [HTML](https://arxiv.org/abs/2510.26302)
### Authors
Ziliang Chen,Tianang Xiao,Jusheng Zhang,Yongsen Zheng,Xipeng Chen
### Background
CLIP 通过共享嵌入空间中的图像和文本对齐实现了强大的跨模态泛化，但在对象、属性和关系的组合推理方面存在持续的薄弱之处，表现如同词汇匹配器。现有的因果解释通常将文本视为单一向量，从而模糊了词元级别的结构，并忽略了诸如提示敏感性和面对强硬否定的失败等核心现象。本文通过一个基于序列的语言-词元结构因果表示学习 (CRL) 框架解决了这一缺口。
### Innovation
本文提出了一种基于词元层级的因果表示学习 (CRL) 框架，该框架扩展了块可识别性到分词文本，证明了 CLIP 的对比学习目标在句级和词元级结构因果模型中都可恢复模态不变的潜在变量。更重要的是，词元粒度提供了一个针对 CLIP 组合脆弱性的首个原理上解释：组合非识别性。研究表明，存在伪最优文本编码器，它们可以实现完美的模态不变对齐，但却对原子概念上的 SWAP、REPLACE 和 ADD 操作表现出证明性的不敏感，从而导致在面临强硬否定时无法区分正确描述和错误描述，尽管它们优化了相同的训练目标。此外，该研究还通过模态差距将语言侧的非识别性与视觉侧的失败联系起来，并展示了堆叠组合操作如何增加难度，从而推动改进负样本挖掘策略。
### Conclusion
本文通过词元层次因果视角深入分析了视觉-语言组合性难度的原因，提供了针对 CLIP 组合脆弱性的原理上解释，并揭示了模态差距背后的机制，提出了改善负样本挖掘策略的动机，为后续研究和模型设计提供了新的视角。
## 112. `cs.AI` - 从新手到大师：通过自动化 Curriculum 学习向 LLMs 输送知识 [PDF](https://arxiv.org/pdf/2510.26336), [HTML](https://arxiv.org/abs/2510.26336)
### Authors
Nishit Neema,Srinjoy Mukherjee,Sapan Shah,Gokul Ramakrishnan,Ganesh Venkatesh
### Background
大型语言模型（LLMs）在通用任务上表现出色，但在经济学和心理学等专业知识领域却表现不佳，这些领域需要深入且原理性的理解。ACER（Automated Curriculum-Enhanced Regimen）通过生成综合性课程并采用布卢姆分类法指导的问题-答案对，将一般模型转化为领域专家，同时保留其广泛的通用能力，旨在解决这一问题。
### Innovation
ACER 引入了一种自动化课程增强程序，通过生成综合性的课程大纲和问题-答案对，特别是使用布卢姆分类法进行引导，确保了系统的主题覆盖面和逐步增加的难度。这种合成的语料库被用于连续预训练，这些预训练按照交替的课程时间表进行安排，实现了在内容和认知维度上的同步学习。实验结果显示，ACER 在专业 MMLU 子集中表现出显著的改进，在经济学等挑战性领域取得了 5 个百分点的提升，并在全国平均改进中取得了 3 个百分点的进步。此外，ACER 不仅防止了灾难性遗忘，还促进了领域间知识的正向转移，提高了非目标领域的表现。ACER 还提升了知识密集型基准测试（如 ARC 和 GPQA）的表现，同比超过 2 个百分点，同时保持了在通用推理任务上的稳定表现。
### Conclusion
ACER 的结果表明，提供了一种可扩展且有效的解决方案，用于填补LLMs中的关键专业领域差距。
## 113. `cs.AI` - 利用干预性约束的线性因果发现 [PDF](https://arxiv.org/pdf/2510.26342), [HTML](https://arxiv.org/abs/2510.26342)
### Authors
Zhigao Guo,Feng Dong
### Background
因果知识和机制对于细化因果模型以及改进下游任务（如设计新的治疗方法）至关重要。现有的因果发现方法允许施加结构约束（例如，要求从PIP3到Akt的因果路径），但仍可能存在得出不正确的因果结论的情况（例如，学习PIP3抑制Akt）。干预性约束通过明确约束变量对间的总因果效应，确保学习到的模型尊重已知的因果影响，解决了这一问题。
### Innovation
提出了一种新的因果发现概念——干预性约束，这是一种不同于干预数据的概念，它以不等式形式编码高层次的因果知识。作者提出了一种度量线性因果模型中总因果效应的度量，并将其问题形式化为一个约束优化任务，使用两阶段约束优化方法解决。实验表明，融入干预性约束不仅提高了模型的准确性和与已知发现的一致性，还促进了新因果关系的发现，这些关系的发现成本较高。
### Conclusion
引入的干预性约束方法通过确保模型符合已知的因果影响，不仅提高了模型的准确性，确保了与已知发现的一致性，还促进了新因果关系的发现，使得模型更具可解释性。
## 114. `cs.AI` - MisSynth: 使用合成数据改进MISSCI逻辑谬误分类 [PDF](https://arxiv.org/pdf/2510.26345), [HTML](https://arxiv.org/abs/2510.26345)
### Authors
Mykhailo Poliakov,Nadiya Shvai
### Background
健康相关的错误信息非常普遍且可能有害，特别是在科学发现被扭曲或误解的情况下。识别这类信息很困难。本研究旨在通过使用MISSCI数据集和框架，研究合成数据生成和轻量级微调技术对大型语言模型（LLMs）识别谬误论证能力的影响。
### Innovation
提出了一种名为MisSynth的管道，该管道采用检索增强生成（RAG）技术生成合成谬误样本，然后用于微调LLM模型。实验结果显示，微调后模型的准确率显著提高，例如，微调后的LLaMA 3.1 8B模型在MISSCI测试集上的绝对F1分数提高了35%以上。进一步证明，引入合成谬误数据可显著增强LLM在现实世界中科学误导任务的零样本分类性能，即使是在有限的计算资源下也可以显著增强。
### Conclusion
我们向有限的标注资源引入合成谬误数据，证明了即使在有限的计算资源下，也可以显著提高零样本LLM在现实世界科学误导任务中的分类性能。同时，研究成果中包含了代码和合成数据集，可在指定的网址获取。
## 115. `cs.AI` - SPG-CDENet: 空间先验导向的交叉双编码网络用于多器官分割 [PDF](https://arxiv.org/pdf/2510.26390), [HTML](https://arxiv.org/abs/2510.26390)
### Authors
Xizhi Tian,Changjun Zhou,Yulin. Yang
### Background
多器官分割是计算机辅助诊断中的关键任务。尽管最近的深度学习方法在图像分割方面取得了显著成功，但器官大小和形状的巨大变化仍然挑战了其在多器官分割中的有效性。
### Innovation
提出了一种新型的两阶段分割范式——空间先验导向的交叉双编码网络（SPG-CDENet），以提高多器官分割的准确性。该网络由空间先验网络和交叉双编码网络两部分组成。空间先验网络生成粗略的定位图，作为空间指导。交叉双编码网络包括全局编码器、局部编码器、对称交叉注意力模块和基于流的解码器，以增强全局和局部编码器之间的互动，直接从编码器的最终层传播高层语义特征到所有解码器层，最大化特征的保留和利用。
### Conclusion
在两个公开数据集上的广泛定性和定量实验表明，SPG-CDENet相比现有分割方法显示出优越的性能。进一步的消融研究也证实了所提模块在提高分割精度方面的有效性。
## 116. `cs.AI` - GLYPH-SR：通过VLM引导的潜在扩散模型，我们能否同时实现高质量的图像超分辨率和高保真度的文本恢复？ [PDF](https://arxiv.org/pdf/2510.26339), [HTML](https://arxiv.org/abs/2510.26339)
### Authors
Mingyu Sung,Seungjae Ham,Kangwoo Kim,Yeokyoung Yoon,Sangseok Yun,Il-Min Kim,Jae-Mo Kang
### Background
图像超分辨率（SR）对许多视觉系统至关重要，从监控和自主系统到文档分析和零售分析，因为恢复高频细节，尤其是场景文本，可以提高下游感知的可靠性。场景文本，即嵌入自然图像中的文本，如标志、产品标签和店铺招牌，通常包含最具行动力的信息；当字符模糊或生成时，光字符识别（OCR）和后续决策会失败，即使图像的其余部分看起来清晰。然而，之前的SR研究通常针对失真（PSNR/SSIM）或学习感知度量（LIPIS，MANIQA，CLIP-IQA，MUSIQ），这些指标对字符级别的错误相对不敏感。此外，一些研究虽然关注文本SR，但往往集中在简化基准上的孤立字符上，忽视了复杂自然场景中的文本挑战。因此，场景文本实际上被视为通用纹理。为了使SR在实际部署中有效，必须明确优化文本清晰度和感知质量。GLYPH-SR通过一个由OCR数据引导的文本-SR融合控制网络（TS-ControlNet）和交替进行文本和场景引导的乒乓调度器，旨在同时实现这两个目标。
### Innovation
GLYPH-SR 采用了由 OCR 数据引导的文本-SR 融合控制网络（TS-ControlNet）和交替进行文本和场景引导的乒乓调度器。该模型在合成语料库上进行训练，同时冻结了主要的 SR 部分。通过 GLYPH-SR，OCR F1 比基于扩散/生成对抗网络（GAN）的基线在 SVT 和 SCUT-CTW1500 上提高了多达 +15.18 个百分点，在 CUTE80 上维持了竞争力的同时提高了 MANIQA、CLIP-IQA 和 MUSIQ 的水平。GLYPH-SR 经过设计旨在同时实现高可读性和视觉真实性佳的SR，使得结果看起来正确且读得正确。
### Conclusion
GLYPH-SR 通过 VLM 引导的潜在扩散模型，成功实现了高质量的图像超分辨率和高保真度的文本恢复，优化了文本清晰度和感知质量，解决了复杂自然场景中的文本挑战，提升了 OCR 对场景文本的恢复效果。
## 117. `cs.AI` - 机器人操作中的在线人工循环拒绝采样 [PDF](https://arxiv.org/pdf/2510.26406), [HTML](https://arxiv.org/abs/2510.26406)
### Authors
Guanxing Lu,Rui Zhao,Haitao Lin,He Zhang,Yansong Tang
### Background
强化学习（RL）被广泛用于生成稳健的机器人操作策略，但由于中间步骤不准确的价值估计和稀疏监督，使用RL精调视觉-语言-动作（VLA）模型可能不稳定。相比之下，模仿学习（IL）虽然易于训练，但由于其离线性质，常常表现不佳。针对这一问题，本文提出Hi-ORS（一种简单有效的后训练方法），通过拒绝采样技术，实现训练稳定性和高鲁棒性。
### Innovation
Hi-ORS通过在线精调过程中的拒绝采样过滤负面奖励样本以稳定价值估计，并采用奖励加权监督训练目标以提供密集的中间步骤监督。同时，Hi-ORS开发了一个异步推理-训练框架，支持灵活的在线人工在环（Human-in-the-loop）修正，为学习错误恢复行为提供明确指导。
### Conclusion
Hi-ORS仅用1.5小时的现实指令精调pi基础策略，使其掌握接触丰富的操作，优于RL和IL基线，在效果和效率上显著超越现有方法。精调后的策略表现出强大的测试时间可扩展性，可以通过可靠执行复杂错误恢复行为以提高性能。
## 118. `cs.AI` - 自主水下机器人在随机、稀疏和非稳态环境中进行污染检测的强化学习 [PDF](https://arxiv.org/pdf/2510.26347), [HTML](https://arxiv.org/abs/2510.26347)
### Authors
Sebastian Zieglmeier,Niklas Erdmann,Narada D. Warakagoda
### Background
强化学习（RL）算法旨在通过学习最大化奖励的动作来优化问题解决，但在随机和非稳态环境中，这一任务变得尤为棘手。即使是先进的RL算法，在这些条件下也时常力不从心。在利用自主水下车辆（AUVs）寻找水下污染云的应用中，RL算法必须在稀疏的奖励环境中进行导航，其中很多动作的结果往往是零奖励。当前的RL方法难以应对这些挑战，因此本文旨在通过重新审视和修改经典RL方法，使其更高效地在稀疏、随机、非稳态环境中运行。通过系统地研究大量的修改方式，包括层次算法的改变、多目标学习以及引入位置记忆作为外部输出过滤器以防止状态的重访，本文测试了这些方法的有效性。研究表明，修改后的基于蒙特卡洛的方法在传统的Q学习和两种详尽搜索模式中表现优异，这表明强化学习方法可以有效适应复杂的环境。
### Innovation
研究引入了对经典RL方法的修改，包括层次算法改变、多目标学习以及在一维外部输出中引入位置记忆作为过滤器来防止状态的重复访问。这些修改使RL更适用稀疏、随机和非稳态环境，在奖励稀疏的环境中表现出显著的优势。这种方法为解决现实世界中的类似问题提供了新的思路。
### Conclusion
修改后的基于蒙特卡洛的RL方法在随机、稀疏和非稳态环境中显著优于传统的Q学习和两种详尽搜索方法，表明强化学习能够有效适应这些复杂的环境。这对于自主水下机器人在实际应用中更加准确地检测水下污染具有重要意义。
## 119. `cs.AI` - 对话的几何学：基于图的语言模型揭示多智能体协作的协同团队 [PDF](https://arxiv.org/pdf/2510.26352), [HTML](https://arxiv.org/abs/2510.26352)
### Authors
Kotaro Furuya,Yuichi Kitagawa
### Background
尽管基于大型语言模型（LLMs）的多智能体方法具有超越单一模型的可能性，但其成功依赖于高效的团队协作。然而，由于大多数模型的内部特性不透明，形成最佳团队是一项挑战。本研究提出了一种基于交互的自动团队组合框架，无需任何先验知识，包括内部架构、训练数据或任务表现。该方法通过分析双向对话的语义一致性来构建“语言模型图”，并利用社区检测识别出具有协同性的模型集群。研究显示，该方法能够发现反映模型潜在专业化的功能集群，并且在特定主题引导的对话中，形成的团队表现优于随机基准，达到类似手动挑选团队的准确性。这些发现为自动设计协作多智能体LLM团队提供了新的基础。
### Innovation
本研究提出了一种基于交互的自动团队组合框架，无需任何先验知识。该方法通过构建“语言模型图”来分析模型的语义一致性，并利用社区检测识别具有协同性的模型集群。这种方法能够发现反映模型潜在专业化的功能集群，并且在特定主题引导的对话中，形成的团队表现出色，优于随机基准，甚至达到类似手动挑选团队的准确性。
### Conclusion
研究结果表明，基于交互的自动团队组合方法能够发现反映模型潜在专业化的功能集群，并通过特定主题引导的对话实现卓越的团队表现，为自动设计协作多智能体LLM团队提供了新的基础。
## 120. `cs.AI` - SSCL-BW: 样本特定的干净标签后门水印方法用于数据集所有权验证 [PDF](https://arxiv.org/pdf/2510.26420), [HTML](https://arxiv.org/abs/2510.26420)
### Authors
Yingjia Wang,Ting Qiao,Xing Liu,Chongzuo Li,Sixing Wu,Jianbin Li
### Background
深度神经网络（DNNs）的进步需要大量高质量的数据集，但这些数据集的未经授权商业使用严重侵犯了数据集所有者的知识产权。现有的基于后门的数据集所有权验证方法存在一些固有的局限性：毒标签水印由于标签不一致而容易被检测，而干净标签水印在技术上复杂且在高分辨率图片上效果不佳。此外，这两种方法都使用静态水印模式，易被检测和移除。
### Innovation
该论文提出了一种样本特定干净标签后门水印方法（即SSCL-BW）。通过训练基于U-Net的数据水印样本生成器，该方法为每个样本生成唯一水印，从根本上克服了静态水印模式的脆弱性。核心创新在于设计了一个由三个组件组成的复合损失函数：目标样本损失确保水印有效性，非目标样本损失保证触发可靠性，感知相似性损失保持视觉不可感知性。在所有权验证过程中，采用黑盒测试检查疑似模型是否表现出预定义的后门行为。
### Conclusion
广泛的实验表明，所提出的方法在基准数据集上有效，并且能够抵御潜在的水印移除攻击。
## 121. `cs.AI` - 通过分类复杂性缓解实现鲁棒图凝缩 [PDF](https://arxiv.org/pdf/2510.26451), [HTML](https://arxiv.org/abs/2510.26451)
### Authors
Jiayi Luo,Qingyun Sun,Beining Yang,Haonan Yuan,Xingcheng Fu,Yanbiao Ma,Jianxin Li,Philip S. Yu
### Background
图凝缩(GC)因其能够合成较小但信息丰富的图而受到重视，但现有研究通常忽视了GC在原图被篡改场景中的鲁棒性。在这种情况下，GC的表现显著下降，现有的鲁棒图学习技术仅能提供有限的效果。我们通过实证研究和理论分析发现，GC本质上是一个降低内在维度的过程，合成出一个分类复杂性较低的凝缩图。尽管这一特性对有效的GC性能至关重要，但其仍高度易受对抗性扰动的影响。
### Innovation
本文提出了Manifold-constrained Robust Graph Condensation（MRGC）框架，通过引入三种基于图数据流形学习的模块，引导凝缩图在光滑、低维度流形内进行，确保保持分类复杂性降低的能力，同时增强在通用对抗性攻击下的鲁棒性表现。
### Conclusion
通过广泛的实验，我们展示了在各种攻击场景下，MRGC的鲁棒性。
## 122. `cs.AI` - LoCoT2V-Bench: 用于长形式和复杂文本生成视频的基准 [PDF](https://arxiv.org/pdf/2510.26412), [HTML](https://arxiv.org/abs/2510.26412)
### Authors
Xiangqing Zheng,Chengyue Wu,Kehai Chen,Min Zhang
### Background
近期，文本生成视频（文本转视频）技术在产生高质量短视频方面取得了显著进展，但评估长视频输出尤其是处理复杂输入提示时仍面临重大挑战。现有的基准测试大多依赖简化提示，重点在于低级指标，而忽略了细节与提示的精细对齐以及叙事连贯性等抽象维度。本文讨论了当前技术在处理长视频生成时面临的挑战，特别是对复杂输入提示的处理不足，导致对叙事连贯性和主题表达的关注不够。因此，当前的评价体系无法全面反映长视频生成模型的效果。
### Innovation
本文提出了一种新的基准测试——LoCoT2V-Bench，专门用于在复杂输入条件下进行长视频生成。LoCoT2V-Bench 借助真实的视频素材引入了一系列真实的复杂提示，包括场景转换和事件动态等元素，并构建了一个多维度的评估框架，涵盖事件级别的对齐、细微的时空一致性、内容清晰度以及专注于叙事流程、情感响应、人物发展等更抽象属性的人类期望实现度（HERD）。该评估框架全面评估了九种代表性的长视频生成模型，揭示了当前方法在基本视觉和时间方面表现良好，但在事件间一致性、细节对齐及高层次主题一致性等方面存在不足。
### Conclusion
LoCoT2V-Bench 提供了一个全面可靠的专业平台，用于评估长形式复杂文本生成视频。本研究还指出了未来方法改进的关键方向，有助于提高长视频生成的质量和实用价值。
## 123. `cs.AI` - 从稀少数据中进行个性化治疗结果预测的双通道知识蒸馏和自适应融合方法 [PDF](https://arxiv.org/pdf/2510.26444), [HTML](https://arxiv.org/abs/2510.26444)
### Authors
Wenjie Chen,Li Zhuang,Ziying Luo,Yu Liu,Jiahao Wu,Shengcai Liu
### Background
在精准医学中，基于临床试验数据的个性化治疗结果预测对于小样本或罕见患者群体至关重要。然而，高成本的临床试验数据限制了预测性能的提高。针对这一问题，本文构建了一种跨品质知识蒸馏和自适应融合网络（CFKD-AFN），利用大量但低品质的仿真数据提升基于稀缺但高品质临床试验数据的预测精度。
### Innovation
提出的CFKD-AFN模型通过引入双通道知识蒸馏模块来从低品质模型中提取互补知识，并结合注意力引导融合模块动态整合多源信息。通过临床阻塞性肺疾病的治疗结果预测实验，证明了该模型在预测准确率上的显著改进，相比于最先进的方法提高了6.67%-74.55%的准确率，并且在不同大小的高品质数据集上显示出较强的鲁棒性。此外，还提出了CFKD-AFN的可解释性变体，以支持临床决策并探索潜在的医学语义。
### Conclusion
基于临床试验数据的个性化治疗结果预测非常重要，但受限于高成本数据。本文提出的CFKD-AFN模型可以通过整合低品质仿真数据和高品质临床试验数据，显著提高预测准确度，并已在阻塞性肺疾病治疗结果预测中得到验证。此外，该模型还具备良好的鲁棒性和可解释性，支持临床应用。
## 124. `cs.AI` - 大型语言模型的贝叶斯网络融合用于情感分析 [PDF](https://arxiv.org/pdf/2510.26484), [HTML](https://arxiv.org/abs/2510.26484)
### Authors
Rasoul Amirzadeh,Dhananjay Thiruvady,Fatemeh Shiri
### Background
大型语言模型（LLMs）不断发展，出现了越来越多针对特定领域的变体，适用于专门任务。然而，这些模型通常缺乏透明性和可解释性，重新训练成本高昂，需要大量的提示工程，结果在不同领域表现不一致，并且由于高计算需求对环境造成显著负面影响。这些挑战使得需要一种新的方法来提高模型的性能和效率。
### Innovation
本文提出了一种贝叶斯网络LLM融合（BNLF）框架，该框架通过概率机制将三个LLM（FinBERT、RoBERTa和BERTweet）的预测结果集成用于情感分析。BNLF采用后期融合的方法，在贝叶斯网络中将来自多个LLM的情感预测作为概率节点建模。BNLF在三个具有不同语言和上下文特征的人工标注金融语料库上进行了评估，结果显示BNLF在准确率上比基线LLMs有约6%的改进，证明了其对数据集变化的鲁棒性和概率融合在可解释情感分类中的有效性。
### Conclusion
BNLF框架证明了其在情感分析中的优势，能够提高准确率并且具有对不同数据集的鲁棒性。此外，通过概率融合方法提高了模型的可解释性，为未来的研究提供了新的思路。
## 125. `cs.AI` - 通过头部与尾部平衡对抗LVLMs的马太效应 [PDF](https://arxiv.org/pdf/2510.26474), [HTML](https://arxiv.org/abs/2510.26474)
### Authors
Xin Guo,Zhiheng Xi,Yiwen Ding,Yitao Zhai,Xiaowei Shi,Xunliang Cai,Tao Gui,Qi Zhang,Xuanjing Huang
### Background
自改进已发展成为提升大型视觉-语言模型（LVLM）推理能力的主要范式，其中模型通过迭代探索和学习成功的轨迹。然而，研究中发现了一个关键问题：模型在生成简单查询（即头部数据）的高质量轨迹方面表现出色，但在处理更复杂的查询（即尾部数据）时却面临挑战，导致了优化过程中的不平衡，使模型倾向于优先发展简单的推理技能，而无法有效应对更复杂的推理任务。随着迭代次数的增加，这种不平衡日益加剧，我们将其称为“马太效应”，最终阻碍了进一步的模型改进，导致性能瓶颈。
### Innovation
为应对这一挑战，作者引入了四种有效的策略，从分布重塑和轨迹重采样的两个角度出发，在探索与学习的自改进过程中实现头部与尾部的再平衡。这些方法在Qwen2-VL-7B-Instruct和InternVL2.5-4B模型上的视觉推理任务中进行了广泛的实验，结果表明，相比于传统的自改进方法，本文提出的方法在平均上提高了3.86个百分点，显著提升了视觉推理能力。
### Conclusion
为解决因马太效应导致的LVLM自改进过程中的不平衡问题，本文提出了一种通过头部与尾部平衡的方法，该方法能够有效提升模型的视觉推理能力。
## 126. `cs.AI` - 增强大型语言模型以通过安全意识微调提升安全代码审查能力：SecureReviewer [PDF](https://arxiv.org/pdf/2510.26457), [HTML](https://arxiv.org/abs/2510.26457)
### Authors
Fang Liu,Simiao Liu,Yinghao Zhu,Xiaoli Lian,Li Zhang
### Background
在软件系统的开发初期识别和处理安全问题对于减少长期负面影响至关重要。代码审查作为一种有效实践，允许开发者在将代码整合到代码库之前检查同事的代码。已有许多自动化代码审查方法被提出，其中基于大语言模型（LLMs）的方法极大地提高了自动审查生成的性能。然而，现有的模型大多集中在通用代码审查上，它们在识别和解决安全相关问题方面的效果尚未得到充分探索。此外，将已有的代码审查方法适应于针对安全问题面临数据稀缺和评估指标不足的重要挑战。为了应对这些局限性，我们提出了SecureReviewer，一种专为增强LLMs在代码审查中识别和解决安全问题的能力而设计的新方法。通过构建特定于安全代码审查的数据集进行训练和评估，并利用RAG技术确保生成的评论信息准确地基于特定领域的安全知识来减轻LLMs的幻觉现象，提出了一种新的评估指标SecureBLEU来评估审查评论在解决安全问题的有效性。实验结果表明，SecureReviewer在安全问题检测精度和生成的审查评论的整体质量和实用性方面均优于最先进的基线方法。
### Innovation
提出SecureReviewer，这是一种专门用于增强Lanuguage Models识别和解决安全问题能力的新方法。通过构建特定于安全代码审查的数据集进行训练和评估，并利用RAG技术确保生成的评论信息准确地基于特定领域的安全知识来减轻LLMs的幻觉现象。此外，还引入了SecureBLEU，这是一种专门用于评估审查评论在解决安全问题有效性的新指标。
### Conclusion
实验结果显示，SecureReviewer在安全问题检测准确性以及生成的审查评论的整体质量和实用性方面均优于最先进的基线方法。
## 127. `cs.AI` - Inside CORE-KG: Evaluating Structured Prompting and Coreference Resolution for Knowledge Graphs [PDF](https://arxiv.org/pdf/2510.26512), [HTML](https://arxiv.org/abs/2510.26512)
### Authors
Dipak Meher,Carlotta Domeniconi
### Background
人类走私网络越来越具有适应性，难以分析。法律案件文件提供了关键的见解，但往往是无结构的、词汇密集的，包含模糊或变化的引用，这在自动构建知识图谱（KG）方面提出了重大挑战。尽管基于LLM的方法相比静态模板有所改进，但仍会产生碎片化且重复节点较多的 KG，特别是由于缺乏引导提取和共指解析导致。最近提出的CORE-KG框架通过整合类型感知共指模块和领域导向结构化提示，显著减少了节点重复和法律噪声。
### Innovation
CORE-KG框架通过结合类型感知共指模块和领域导向的结构化提示，解决了一些关键问题，如减少节点重复和法律冗余。本文通过系统性的消融研究，量化了框架中两个关键组件的个体贡献。
### Conclusion
研究表明，去除共指解析会导致节点重复增加28.32%，噪声节点增加4.32%；去除结构化提示会使节点重复增加4.34%，噪声节点增加73.33%。这些发现为设计从复杂法律文本中提取结构化表示的稳健LLM管道提供了实证见解。
## 128. `cs.AI` - 使用LLM代理模拟和实验社交媒体动员 [PDF](https://arxiv.org/pdf/2510.26494), [HTML](https://arxiv.org/abs/2510.26494)
### Authors
Sadegh Shirani,Mohsen Bayati
### Background
在线社交网络已经改变了政治动员信息的传播方式，引起了关于大规模社交影响机制的新问题。本文基于一项大规模的Facebook实验（涉及6100万用户），开发了一个基于代理的仿真框架，该框架结合了美国实际人口统计分布、真实的Twitter网络结构和不同复杂性的大型语言模型（LLM）代理，旨在探究政治动员信息对选民投票的影响。
### Innovation
该仿真框架引入了真实和详细的人口统计分布、真实的Twitter社交网络结构以及适应不同政治复杂性的LLM代理，使研究同社会动员效果关系的问题更加具体和可控。研究通过模拟使用不同的社交信息和社交动员方式，验证了开放社会信息环境下动员效果更强且存在明显的社会影响。此外，该仿真框架为政治动员研究提供了控制良好、可复现的环境，可进行假设设计和敏感性分析，搭建了高质量实地实验与灵活计算模型之间的桥梁。通过提供代码和数据，该研究增强了研究的透明度和可重复性。
### Conclusion
该仿真研究模拟了在不同社会动员条件下的投票行为，揭示了社会信息和社交动员方法在选民动员中的重要性。研究成果提供了测试假设设计和敏感性分析的框架，有助于理解大规模社交传播网络中的动员效果。该仿真平台可以结合真实的分布特征和复杂的社交网络结构，为未来的研究提供了一个有效手段，具有较高的理论和实践价值。
## 129. `cs.AI` - 机器人中学习变长工具操作的自适应逆运动学框架 [PDF](https://arxiv.org/pdf/2510.26551), [HTML](https://arxiv.org/abs/2510.26551)
### Authors
Prathamesh Kothavale,Sravani Boddepalli
### Background
传统机器人对自身运动学的理解有限，只能执行预编程的任务，限制了它们高效利用工具的能力。这一背景介绍了缺乏对工具使用的理解如何限制了机器人的灵活性和效率，尤其是在操纵不同长度的工具方面.
### Innovation
论文提出了一种创新的框架，通过扩展机器人的逆运动学求解器，使其能够执行使用不同长度工具的一系列操作。该框架通过模拟中学习的动作轨迹，将动作与工具相结合，实现了从模拟环境到现实世界的技能转移。实验证明，这种方法在不同的工具长度下表现几乎相同，且具有出色的精确度，误差率低于1cm。
### Conclusion
研究展示了机器人在未来工具使用方面可能取得的进展，使机器人能够处理多样化的任务，并掌握复杂工具操作的艺术。
## 130. `cs.AI` - InfoFlow：通过奖励密度优化强化搜索代理 [PDF](https://arxiv.org/pdf/2510.26575), [HTML](https://arxiv.org/abs/2510.26575)
### Authors
Kun Luo,Hongjin Qian,Zheng Liu,Ziyi Xia,Shitao Xiao,Siqi Bao,Jun Zhao,Kang Liu
### Background
Reinforcement Learning with Verifiable Rewards（RLVR）在增强代理深度搜索方面展现出潜力，但其应用常常受到深度搜索场景中低奖励密度的阻碍，此时代理需付出大量探索成本以获得频次较低且常为空的最终奖励。
### Innovation
该论文提出了InfoFlow框架，从三个维度解决奖励密度优化问题：1) 子问题分解：将长期任务拆分为阶段性任务，分配过程奖励，提供更密集的学习信号；2) 失败指导提示：向停滞的轨迹注入纠正指引，提高成功几率；3) 双代理细化：采用双代理架构减轻深度探索的认知负担，精简搜索历史，降低探索成本，提高整体奖励密度。
### Conclusion
InfoFlow在多个代理搜索基准测试中显著超越了现有的强大基线，使轻量级的LLM能够达到与先进的专有LLM相当的性能。
## 131. `cs.AI` - 使用Jensen-Shannon距离进行多类别局部校准 [PDF](https://arxiv.org/pdf/2510.26566), [HTML](https://arxiv.org/abs/2510.26566)
### Authors
Cesare Barbera,Lorenzo Perini,Giovanni De Toni,Andrea Passerini,Andrea Pugnana
### Background
开发可信的机器学习模型需要其预测概率准确反映真实类别频率。在多类别分类的校准概念中，强校准是要求最严格的，因为它要求所有预测概率在所有类别中同时校准。然而，现有的多类别校准方法缺乏对输入距离的考虑，使其容易受到邻近偏差的影响：特征空间稀疏区域中的预测会系统地失校准。这在高风险领域（如医疗保健）尤为重要，稀疏实例正是那些最有可能受到偏差待遇的风险实例。
### Innovation
本文通过引入基于局部视角的多类别校准来解决这一主要缺陷。首先，正式定义多类别局部校准并探讨其与强校准的关系。其次，理论分析现有评价指标在应用于多类别局部校准时的局限性。第三，提出一种实用方法增强神经网络中的局部校准，使用Jensen-Shannon距离强制预测概率与局部类别频率之间的对齐。最后，通过实验验证了该方法与现有多类别校准技术的优劣。
### Conclusion
本文研究基于Jensen-Shannon距离的多类别局部校准，发现相比于现有的多类别校准技术，该方法能够更好地解决由于稀疏数据导致的预测偏差问题，特别是在高风险领域具有潜在的应用价值。
## 132. `cs.AI` - 大型语言模型中关系解码线性算子的结构 [PDF](https://arxiv.org/pdf/2510.26543), [HTML](https://arxiv.org/abs/2510.26543)
### Authors
Miranda Anna Christ,Adrián Csiszárik,Gergely Becsó,Dániel Varga
### Background
本文研究了Hernandez等人[2023]引入的用于在变换器语言模型中解码特定关系事实的线性算子的结构。前人工作主要关注单个关系的情况，本文则将其扩展到多个关系，并系统地研究了它们的组织结构。进一步观察这些关系解码算子的压缩性，发现简单的三阶张量网络可以高度压缩这些算子而不显著影响解码准确性。
### Innovation
通过开发一种交叉评估协议，将每个线性解码算子应用于其他关系的主题，揭示了这些线性映射并不编码特定的关系，而是提取重复出现、宏观化的语义属性（例如，首都有国家属性和食品所属的国家属性都被归类为国家属性），这一属性中心结构解释了算子的压缩性，并揭示了它们只能够泛化到语义接近的新关系的原因。因此，本文将变换器语言模型中的线性关系解码解释为基于属性而非特定关系的。
### Conclusion
本文展示了线性关系解码在变换器语言模型中的属性中心结构，提出了这些结构的高度压缩性和泛化能力背后的原因，并强调了它们只能够在语义上接近的新关系中泛化的特性。
## 133. `cs.AI` - 停止浪费你的令牌：朝着高效的多智能体系统实时运行 [PDF](https://arxiv.org/pdf/2510.26585), [HTML](https://arxiv.org/abs/2510.26585)
### Authors
Fulin Lin,Shaowen Chen,Ruishan Fang,Hongwei Wang,Tao Lin
### Background
多智能体系统在复杂任务中表现出色，但随着其操作复杂性的增加，其自主性往往导致关键的低效率，如过度的令牌消耗和因错误信息而产生的故障。现有的方法主要集中在事后失败归因上，缺乏能够提供主动的、实时干预以增强鲁棒性和效率的机制。
### Innovation
本文提出了一种名为SupervisorAgent的轻量级和模块化的实时适应性监督框架，该框架可直接作用于基础智能体而无需更改其架构。基于不含LLM的自适应过滤器，SupervisorAgent在关键技术节点上主动纠错、引导低效行为并净化观察结果。在GAIA基准测试中，SupervisorAgent在不降低Smolagent框架成功率的情况下，平均减少了29.45%的令牌消耗。广泛的实验证明了该方法在多种基准测试（数学推理、代码生成和问答）以及多个顶级基础模型中的广泛应用和鲁棒性。
### Conclusion
综合实验验证了SupervisorAgent的广泛适用性和鲁棒性，证明了其在不同多智能体系统任务中的有效应用。相关的代码在该链接 https://github.com/... 可用。
## 134. `cs.AI` - 钢铁轧制厂内集成计算机视觉的实时故障预测 [PDF](https://arxiv.org/pdf/2510.26684), [HTML](https://arxiv.org/abs/2510.26684)
### Authors
Vaibhav Kurrey,Sivakalyan Pujari,Gagan Raj Gupta
### Background
该研究展示了在钢铁轧制厂部署基于机器视觉的异常检测系统，用于预测故障以优化生产流程。该系统通过实时监控设备运行、对齐和热棒运动来预防潜在的设备故障和生产中断，从而减少意外停机成本并提高生产效率和盈利能力。
### Innovation
该系统利用工业摄像头实时监控流程线上的设备操作、对齐和热棒运动，通过集中式的视频服务器使用深度学习模型处理现场视频流，实现了设备故障的早期预测，同时减轻了过程控制系统（PLCs）的计算负担，支持在生产线上实现可扩展部署而无需额外资源。通过结合数据分析系统和视觉输入的数据进行联合分析，系统能够识别故障位置及其可能的根本原因，提供主动维护的决策支持。
### Conclusion
此综合方法增强了工业制造环境中的操作可靠性、生产力和盈利能力。
## 135. `cs.AI` - 混合DQN-TD3强化学习在动态环境中的自主导航 [PDF](https://arxiv.org/pdf/2510.26646), [HTML](https://arxiv.org/abs/2510.26646)
### Authors
Xiaoyi He,Danggui Chen,Zhenshuo Zhang,Zimeng Bai
### Background
本文介绍了一种层次化的路径规划与控制框架，结合了高层的深度Q网络（DQN）进行离散子目标选择以及低层的双延迟深度确定性策略梯度（TD3）控制器进行连续动作执行。该系统在ROS + Gazebo（TurtleBot3）中实现，并在部分观察和动态环境中使用PathBench度量标准进行了评估。
### Innovation
提出了将高阶DQN与低阶TD3结合用于动态环境中的自主导航，设计了一套实用的奖励塑造方案和基于LiDAR的安全门，并通过实验展示了相对于单一算法基线（单独的DQN或TD3）以及基于规则的规划者而言，提高了成功率和样本效率。
### Conclusion
该系统实验结果显示，与单独使用DQN或TD3，以及基于规则的规划相比，改进了成功率、样本效率，并且具有更好的未见过的障碍配置的泛化能力和减少了突然的控制变化。代码和评估脚本可在项目仓库中获取。
## 136. `cs.AI` - ResMatching：通过指导条件流匹配实现抗噪计算超分辨率 [PDF](https://arxiv.org/pdf/2510.26601), [HTML](https://arxiv.org/abs/2510.26601)
### Authors
Anirban Ray,Vera Galinova,Florian Jug
### Background
计算超分辨率（CSR）在荧光显微镜中具有悠久的历史，尽管它是一个病态问题。CSR的核心是找到一种先验知识，以预测超分辨率图像中从未被低分辨率显微镜捕捉到的高频成分。随着更强大数据驱动机器学习技术的出现，可以学习更强的先验知识，从而提高CSR的效果。
### Innovation
我们引入了ResMatching方法，这是一种使用引导条件流匹配来学习改进的数据先验的新CSR方法。在BioSR数据集中，与7种基线方法相比，ResMatching在所有测试的使用案例中都取得了最优化的数据保真度和感知现实性的平衡效果，并且特别在噪声较大的低分辨率图像中表现出色，可以提供像素级的数据不确定性，以引导未来用户拒绝不确定的预测。
### Conclusion
ResMatching在处理噪声较多的低分辨率图像时表现尤为出色，能够较好地平衡数据保真度和感知现实性。此外，ResMatching还可以从隐式学习的后验分布中进行采样，并且该分布对于所有测试使用案例都是校准的，可以提供像素级的数据不确定性，指导未来用户作出决策。
## 137. `cs.AI` - 真正的端到端语言模型：无需手动解码 [PDF](https://arxiv.org/pdf/2510.26697), [HTML](https://arxiv.org/abs/2510.26697)
### Authors
Zhichao Wang,Dongyang Ma,Xinting Huang,Deng Cai,Tian Lan,Jiahao Xu,Haitao Mi,Xiaoying Tang,Yan Wang
### Background
当前的语言模型（LLMs）通常被标为端到端模型，但实际上，它们依赖于一个非可微的解码过程，这需要手动调整像温度和top-p这样的超参数。这一过程耗费大量时间且复杂。
### Innovation
提出了一个新的架构AutoDeco，它通过在每个步骤中动态预测上下文相关的温度和top-p值，使解码过程成为参数化、单步处理的词级过程，模型能够在单次前向传播中自我调节其采样策略。同时，模型学习根据自然语言指令（例如，“生成具有低随机性”）调整其预测的温度和top-p值，从而控制基于指令的解码。
### Conclusion
通过在八个基准上的广泛实验，AutoDeco 不仅显著超越了默认解码策略，而且还达到了可与使用“破解测试集”调优得到的基准相媲美的性能，这是任何静态方法的实践上限。发现模型具备基于指令的解码控制能力，能够根据自然语言指令调整其预测的温度和top-p值，开启了语言模型解码的新范式：可操纵和互动的特性。
## 138. `cs.AI` - 关于仅使用单一训练种子评估机器忘记限制的分析 [PDF](https://arxiv.org/pdf/2510.26714), [HTML](https://arxiv.org/abs/2510.26714)
### Authors
Jamie Lanyon,Axel Finke,Petros Andreou,Georgina Cosma
### Background
机器卸载（MU）旨在去除训练模型中特定数据点的影响，而无需昂贵的重新训练。大多数实际的MU算法只能提供近似的结果，其性能只能通过实验评估。因此，在评估MU算法时，必须确保实验比较尽可能具有代表性。一种常见做法是独立运行MU算法多次，每次都从相同的训练模型开始。然而，这项研究指出，即使是使用相同的架构和数据集，某些MU方法也会对用于模型训练的随机数种子的选择高度敏感，这可能导致实验结果极具代表性。
### Innovation
研究展示了仅使用单一训练种子进行MU算法评估可能会导致高度非代表性的结果。这是因为不同的模型训练种子可能导致 MU 方法表现的显著差异。研究强调了在实验比较MU算法时应该反映不同模型训练种子之间的变化性。
### Conclusion
研究建议，在评估MU算法时，实验比较应该反映不同模型训练种子之间的变化性。这意味着不应该依赖单一训练种子的评估结果，而应该考虑多种子实验来更全面地评估MU算法的性能和可靠性。
## 139. `cs.AI` - Aeolus: 多模态航空延误数据集 [PDF](https://arxiv.org/pdf/2510.26616), [HTML](https://arxiv.org/abs/2510.26616)
### Authors
Lin Xu,Xinyun Yuan,Yuxuan Liang,Suwan Yin,Yuankai Wu
### Background
现有的航空延误数据集中，大多数局限于扁平化表格结构，忽略了延误传播的时空动态特性。这限制了研究人员深入探索和建模航班延误问题的能力。因此，迫切需要一个能够捕捉到上述特性的数据集来支持飞行延误预测研究和基础模型的发展。
### Innovation
Aeolus通过提供三种对齐的模态来解决上述限制：(i) 一个包含大量运营、气象和机场层面特征的表格数据集，覆盖超过500万个航班；(ii) 一个航班链模块，建模沿顺序航班段的延误传播，捕捉上游和下游依赖关系；(iii) 一个航班网络图，编码共享的航空器、机组和机场资源连接，支持跨航班关系推理。此外，Aeolus的数据集经过仔细构建，包含时间分割、全面特征和严格的泄露预防措施，支持真实的和可重复的机器学习评估。该数据集适用于多种任务，包括回归、分类、时间结构建模和图学习，并作为跨表格、序列和图模态的统一基准。该数据集已发布了基本实验和前处理工具，增加了其可操作性。
### Conclusion
Aeolus填补了领域特定建模和通用结构化数据的关键空白，对于促进飞行延误预测研究和基础模型的发展具有重要意义。相关源代码和数据可在相应链接处获取。
## 140. `cs.AI` - ExpertFlow：面向高效MoE推理的自适应专家调度和内存协调 [PDF](https://arxiv.org/pdf/2510.26730), [HTML](https://arxiv.org/abs/2510.26730)
### Authors
Zixu Shen,Kexin Chu,Yifan Zhang,Dawei Xiang,Runxin Wu,Wei Zhang
### Background
大型语言模型的扩展受到现代GPU有限内存容量的限制。常规Mixture-of-Experts (MoE)推理方法虽然降低了内存需求和计算开销，但在每一层独立选择活跃专家会导致频繁的参数传输，增加延迟。现有的跨层预测策略通常基于固定步骤，缺乏对不同硬件平台和工作负载的适应性，降低了它们的鲁棒性和有效性。
### Innovation
提出了一种名为ExpertFlow的运行时系统，结合了自适应专家预取和缓存感知路由。通过使用运行时统计信息（如传输带宽、参数维度和模型反馈信号）动态调整专家激活的预测窗口，并融合预门限信息和中间计算状态来预测未来的专家需求，ExpertFlow能够有效减少缓存缺失和避免因专家切换导致的延迟。
### Conclusion
在严格的内存约束条件下，ExpertFlow能够优化MoE推理。实验结果表明，它将模型停滞时间降低到基线的0.1%以下，展示了其在MoE推理优化方面的有效性。
## 141. `cs.AI` - Evontree：基于本体规则的大型语言模型自我进化框架 [PDF](https://arxiv.org/pdf/2510.26683), [HTML](https://arxiv.org/abs/2510.26683)
### Authors
Mingchen Tu,Zhiqiang Liu,Juan Li,Liangyurui Liu,Junjie Wang,Lei Liang,Wen Zhang
### Background
大型语言模型（LLMs）凭借大规模预训练和精心校准的微调数据展示了在多个领域的出色能力。然而，在医疗等数据敏感领域，高质量的特定领域训练语料的缺乏阻碍了LLMs的专门应用。同时，领域专家将领域的知识提炼为本体规则，正式化概念之间的关系并确保知识管理系统中的知识完整性。将LLMs视为人类知识的隐式知识库，本文提出了一种名为Evontree的新框架，该框架利用高质量的少量本体规则系统地从LLMs中提取、验证和增强领域知识，而不需依赖庞大的外部数据集。Evontree从原始模型中提取领域本体，使用两种核心本体规则检测不一致，并通过自我提炼的微调增强精炼知识。在涉及医疗问答基准测试中的实验表明，该方法在准确性方面对未修改的模型和领先监督基线均表现出显著的优越性，最高可提高3.7%的准确性。这些结果证实了该方法在LLMs低资源领域适应中的有效性、效率和鲁棒性。
### Innovation
提出了一种名为Evontree的新框架，该框架利用高质量的少量本体规则系统地从LLMs中提取、验证和增强领域知识，而不需依赖庞大的外部数据集。具体来说，Evontree从原始模型中提取领域本体，使用两种核心本体规则检测不一致，并通过自我提炼的微调增强精炼知识。
### Conclusion
通过在医疗问答基准测试中的实验，表明Evontree在准确性方面对未修改的模型和领先监督基线均表现出显著的优越性，最高可提高3.7%的准确性。这些结果证实了该方法在LLMs低资源领域适应中的有效性、效率和鲁棒性。
## 142. `cs.AI` - 多智能体资源分配中的通用激励框架公平性 [PDF](https://arxiv.org/pdf/2510.26740), [HTML](https://arxiv.org/abs/2510.26740)
### Authors
Ashwin Kumar,William Yeoh
### Background
在资源受限的环境中，优化效率的智能体会产生不公平的结果。为解决这一问题，本文提出了通用激励框架公平性（GIFF），一种从标准价值函数中推断公平决策的新方法，能够在不需额外训练的情况下平衡效率与公平性。GIFF通过计算每个动作的局部公平增益，并引入一个反事实优势校正项，来阻止过度分配给已经富裕的智能体。该方法在集中控制设置中进行形式化，仲裁者使用GIFF修改后的Q值来解决分配问题。实验结果表明，GIFF在不同领域，如动态拼车、预防无家可归和复杂的工作分配任务中，都能超越强大的基线，并能发现具有远见的公平政策。
### Innovation
GIFF框架利用了标准的价值函数来平衡效率和公平性，通过计算每个动作的局部公平增益，并引入反事实优势校正项来防止过度分配给富裕智能体。此外，框架建立在正式的基础之上，证明其公平性代理函数是真实公平改进的近似下界，并且其权衡参数提供单调调整。
### Conclusion
我们的研究表明，GIFF是一个强大的且基于原理的框架，可以利用标准的强化学习组件在复杂的多智能体系统中实现更公平的结果。
## 143. `cs.AI` - 非凸无线异质联邦学习：偏差-方差权衡 [PDF](https://arxiv.org/pdf/2510.26722), [HTML](https://arxiv.org/abs/2510.26722)
### Authors
Muhammad Faraz Ul Abrar,Nicolò Michelusi
### Background
空中（OTA）联邦学习已被广泛认可为一个可扩展的范式，它利用无线多址信道的波形叠加来在一个操作中聚合模型更新。现有的OTA-FL设计大多通过假设一致的无线条件（设备间等路径损耗）或强制零偏差更新来保证收敛性，来实现零偏差模型更新。在异构无线场景下，这种设计受限于最弱设备并放大了更新的方差。此外，先前对有偏差的OTA-FL的研究主要针对凸目标函数，而现代大多数AI模型则高度非凸。
### Innovation
我们研究了在无线异构场景下，使用随机梯度下降（SGD）进行一般平滑非凸目标函数下的OTA-FL。我们开发了新的OTA-FL SGD更新，允许结构化的时间不变模型偏差，同时促进降低方差更新。我们推导了一个有限时间的稳态界（预期的时间平均梯度平方范数），明确揭示了偏差与方差之间的权衡。为了优化这个权衡，我们提出了一个非凸联合OTA功率控制设计，并开发了一个仅需基站统计CSI的高效连续凸逼近（SCA）算法。实验表明，基于SCA的设计通过优化的偏差加速收敛，并在先前的OTA-FL基线之上提升了泛化能力。
### Conclusion
我们的方法通过优化偏差和方差之间的权衡来提高OTA-FL在异构无线环境下的性能。通过非凸连续凸逼近算法实现了在不牺牲模型训练集外性能的情况下，优化特征权重的同时优化OTA-FL算法的偏置。
## 144. `cs.AI` - 远程工作指数：衡量AI对远程工作的自动化 [PDF](https://arxiv.org/pdf/2510.26787), [HTML](https://arxiv.org/abs/2510.26787)
### Authors
Mantas Mazeika,Alice Gatti,Cristina Menghini,Udari Madhushani Sehwag,Shivam Singhal,Yury Orlovskiy,Steven Basart,Manasi Sharma,Denis Peskoff,Elaine Lau,Jaehyuk Lim,Lachlan Carroll,Alice Blair,Vinaya Sivakumar,Sumana Basu,Brad Kenstler,Yuntao Ma,Julian Michael,Xiaoke Li,Oliver Ingebretsen,Aditya Mehta,Jean Mottola,John Teichmann,Kevin Yu,Zaina Shaik,Adam Khoja,Richard Ren,Jason Hausenloy,Long Phan,Ye Htet,Ankit Aich,Tahseen Rabbani,Vivswan Shah,Andriy Novykov,Felix Binder,Kirill Chugunov,Luis Ramirez,Matias Geralnik,Hernán Mesura,Dean Lee,Ed-Yeremai Hernandez Cardona,Annette Diamond,Summer Yue,Alexandr Wang,Bing Liu,Ernesto Hernandez,Dan Hendrycks
### Background
人工智能在知识和推理的研究基准上取得了快速进展，但仍不清楚这些进步如何转化为经济价值和自动化。为了衡量这一点，本文引入了远程劳动指数（RLI），这是一个涵盖多个真实世界行业的广泛基准，旨在评估代理在实际应用中的整体表现。AI代理在RLI上表现不佳，最高表现的代理自动化率仅为2.5%。
### Innovation
提出了远程劳动指数（RLI），用于衡量AI在远程工作中的自动化程度。RLI 将多个现实世界行业的真实项目整合在一起，旨在评估代理在实际应用中的整体表现，提供了衡量AI影响的实证证据，并为利益相关者提供了了解AI驱动的劳动力自动化，并能主动应对的方式。
### Conclusion
这些结果有助于基于实证证据来讨论人工智能自动化，为追踪AI影响提供了共同的基础，并使利益相关者能够主动应对AI驱动的劳动力自动化。
## 145. `cs.AI` - AMO-Bench: Large Language Models Still Struggle in High School Math Competitions [PDF](https://arxiv.org/pdf/2510.26768), [HTML](https://arxiv.org/abs/2510.26768)
### Authors
Shengnan An,Xunliang Cai,Xuezhi Cao,Xiaoyu Li,Yehao Lin,Junlin Liu,Xinxuan Lv,Dan Ma,Xuanlin Wang,Ziwen Wang,Shuang Zhou(Alphabetical order by last name)
### Background
现有的基准测试广泛使用高中数学竞赛来评估大型语言模型（LLMs）的数学推理能力。然而，许多现有的数学竞赛对于评估顶尖的LLMs已经变得不够有效，因为性能达到了饱和状态（例如，AIME的得分接近满分25分）。这促使研究者开发更严格的挑战，如AMO-Bench，通过确保所有测试问题都经过专家验证以达到国际数学奥林匹克（IMO）的难度标准，并且是完全原创的问题，以防止数据记忆导致的不公正优势。
### Innovation
AMO-Bench 通过引入更严苛的挑战来应对现有问题，包括：（1）所有50个问题都经过专家审查，确保达到IMO难度标准；（2）完全原创的问题，防止数据记忆导致的优势；（3）每个问题仅需给出最终答案便于自动和稳健的评分。此外，实验结果表明，即便最佳模型在AMO-Bench的准确率也只有52.4%，大多数模型得分低于40%，进一步分析显示，增加测试时的计算量可以发现能力的增长趋势。
### Conclusion
AMO-Bench 的结果强调了目前的LLMs在数学推理能力方面的显著改进空间。该基准测试的发布旨在促进进一步研究以提高语言模型的推理能力。
## 146. `cs.AI` - 通过高级采样实现Faithful and Fast Influence Function [PDF](https://arxiv.org/pdf/2510.26776), [HTML](https://arxiv.org/abs/2510.26776)
### Authors
Jungyeon Koh,Hyeonsu Lyu,Jonggyu Jang,Hyun Jong Yang
### Background
如何解释训练数据对黑盒模型的影响？影响函数（IFs）提供了一种后验解决方案，通过利用梯度和海森矩阵。然而，计算整个数据集的海森矩阵资源密集，需要另一种可行的替代方案。常见的方法是随机抽样一小部分训练数据，但这种方法经常会导致IF估计高度不一致，因为样本配置的方差较高。因此，本文提出了两种基于特征和logits的高级采样技术，通过考虑特征或logits的随机分布来选择一小部分代表性数据集，从而提高IF估计的准确性。
### Innovation
本文提出了两种基于特征和logits的高级采样技术，通过考虑特征或logits的随机分布来选择一小部分代表性数据集，从而提高IF估计的准确性。此外，通过消类实验验证了该方法的有效性，采用F1分数来衡量在去除类别时模型对剩余类别的推理一致性。该方法比基线减少了30.1%的计算时间，降低了42.2%的内存使用，或提高了2.5%的F1分数。
### Conclusion
本文通过高级采样技术提高了影响函数估计的准确性和效率，验证了方法的有效性，并通过F1分数展示了改进之处。
## 147. `cs.AI` - 深度序列模型倾向于记忆几何结构；尚不清楚其原因 [PDF](https://arxiv.org/pdf/2510.26745), [HTML](https://arxiv.org/abs/2510.26745)
### Authors
Shahriar Noroozizadeh,Vaishnavh Nagarajan,Elan Rosenfeld,Sanjiv Kumar
### Background
在序列建模中，原子事实的记忆参数化主要被抽象为实体共现的直接查找。本文对比了这种关联视角与记忆存储的几何视角。研究指出，即便模型是在训练过程中指定局部共现关系进行优化，它仍通过某种机制合成了关于所有实体间全局关系的几何结构，这简化了原本复杂的多项合成推理任务为易于学习的一步几何任务。
### Innovation
本文从一个与传统做法不兼容的Transformer推理实例出发，提炼出难以解释的神经嵌入几何本质。虽然优化仅基于局部关联，但几何结构的形成显然不能简单归因于常用架构或优化压力。进一步通过Node2Vec，分析发现几何结构源于一种频谱偏置，尽管缺乏通常的压力，但这自然发生。此外，研究指出现有实践中有改进Transformer几何化潜力的可见空间。
### Conclusion
几何视角下的参数记忆有可能促使研究人员重新审视如知识获取、容量、发现和遗忘等领域的默认直觉。尽管具体机制尚不清楚，几何结构的学习并非因为更简洁，而是自然发生的结果。这反过来也为实践者提供了改进Transformer几何化的可见空间。
## 148. `cs.AI` - 通过FP16战胜训练-推理不匹配 [PDF](https://arxiv.org/pdf/2510.26788), [HTML](https://arxiv.org/abs/2510.26788)
### Authors
Penghui Qi,Zichen Liu,Xiangxin Zhou,Tianyu Pang,Chao Du,Wee Sun Lee,Min Lin
### Background
基于强化学习（RL）的大型语言模型（LLMs）微调经常会遇到由于训练和推理策略之间的数值不匹配而导致的不稳定性问题。尽管先前的研究尝试通过算法修正或工程对齐来缓解这个问题，但这项研究指出其根本原因在于浮点精度本身。虽然广泛采用的BF16浮点数格式拥有大的动态范围，但它引入了大量舍入误差，破坏了训练和推理的一致性。
### Innovation
本文证明，简单的恢复到FP16格式可以有效消除这种不匹配。这一改变简单、兼容现代框架，只需几行代码修改，且无需对模型架构或学习算法进行改动。研究结果表明，使用FP16可以提供更稳定的优化、更快的收敛速度和更好的性能，适用于多种任务、算法和框架。
### Conclusion
研究结果建议重审RL微调中的精度折衷。采用FP16格式统一提高了微调的稳定性和性能。
## 149. `cs.AI` - Gistify！通过运行时执行实现代码库级理解 [PDF](https://arxiv.org/pdf/2510.26790), [HTML](https://arxiv.org/abs/2510.26790)
### Authors
Hyunji Lee,Minseon Kim,Chinmay Singh,Matheus Pereira,Atharv Sonwane,Isadora White,Elias Stengel-Eskin,Mohit Bansal,Zhengyan Shi,Alessandro Sordoni,Marc-Alexandre Côté,Xingdi Yuan,Lucas Caccia
### Background
随着编码代理在大型代码库中的部署，自动设计挑战性的、代码库级别的评估需求日益增加。为了评估这些代理的能力，提出了一项名为 Gistify 的任务，其中编码语言模型必须创建一个单一的、最小的、自包含的文件来重现代码库中的特定功能。
### Innovation
Gistify 任务要求编码 LLM 创建一个单个最小的自包含文件，该文件可以在给定代码库和特定入口点（如 python 命令）的情况下重现特定功能，并且只能包含执行给定命令所需的必要部分。这一任务需要模型具备对代码库结构的理解、准确地模拟其执行流程以及生成可能较大的代码补丁的能力。现有最先进的模型在 Gistify 任务上面临挑战，特别是在处理执行跟踪较长的任务时。
### Conclusion
我们的发现表明，当前最先进的模型在可靠地解决 Gistify 任务方面存在困难，尤其是那些具有长执行轨迹的任务。Gistify 为评估编码代理在代码库级别的理解和执行复杂任务的能力提供了一个新的基准。
## 150. `cs.AI` - STaMP: 序列变换和混合精度用于低精度激活量化 [PDF](https://arxiv.org/pdf/2510.26771), [HTML](https://arxiv.org/abs/2510.26771)
### Authors
Marco Federici,Riccardo Del Chiaro,Boris van Breugel,Paul Whatmough,Markus Nagel
### Background
量化是降低生成型AI模型推理延迟、功耗和内存占用的关键方法。然而，当激活值量化到少于八位时，通常会导致显著的精度下降。近期研究表明，可逆线性变换（如旋转）可以帮助量化，通过重参数化特征通道和权重。这些方法通过变换激活值来提升模型的精度，特别是在低比特量化的情形下。但是，如何在低比特量化的情况下保持模型精度是一个重要的研究方向。这篇论文旨在解决这一问题，提出了使用序列维度上的线性变换和混合精度的量化方法STaMP (Sequence Transformation and Mixed Precision)。这种方法通过在中间激活保留少量高精度的令牌，使得模型在较低的平均比特宽度激活量化中仍然能够保持较高的精度。论文中具体分析了STaMP在语言视觉模型(LVM和LLM)上的表现，证明该方法在低精度激活量化中显著提高性能，并补充了现有的激活和权重量化方法，包括最近提出的特征变换方法。
### Innovation
本文提出了一种新颖的方法——STaMP（Sequence Transformation and Mixed Precision）量化策略。该方法在线性变换和混合精度量化的基础上，将线性变换应用于序列维度，利用语言和视觉数据中的强局部相关性，通过在每个中间激活保持少量高精度的令牌，能够维持模型在低（平均）比特宽度激活量化中的精度。这为在低比特量化的同时保持模型性能提供了一种有效的新途径。该方法不仅在当前的语言视觉模型中得到了验证，而且与已有的激活和权重量化方法相结合，进一步提升了模型的效率。
### Conclusion
本文通过STaMP量化方法，显著改善了低比特激活量化中的精度问题，并结合现有的量化技术，取得了更好的性能。该方法能够在保持模型准确性的同时降低比特宽度，进一步促进了低精度计算在生成型AI模型中的应用。
## 151. `cs.AI` - 使用几何规整化世界模型克隆确定性3D世界 [PDF](https://arxiv.org/pdf/2510.26782), [HTML](https://arxiv.org/abs/2510.26782)
### Authors
Zaishuo Xia,Yukuan Lu,Xinyi Li,Yifan Xu,Yubei Chen
### Background
世界模型是一种内部模型，用于模拟世界的演变。给定过去的观察和动作，它预测搭载代理和环境的未来。为了使代理在复杂的动态环境中有效地思考、计划和推理，准确的世界模型至关重要。尽管取得了快速进展，但当前的世界模型仍然脆弱，在长时程下会退化。研究表明，一个核心原因是感知输入（如图像）的高维性，以及损失或缠结的潜在表示使动力学习变得不必要的困难。因此，本文探讨是否通过单独改进表示学习可以显著提高世界模型的性能。
### Innovation
本文提出了一种新的几何规整化世界模型（GRWM），确保感官轨迹中的连续点在潜在表示空间中保持接近。这种方法产生了显著改进的潜在表示，与环境的真实拓扑结构紧密对齐。GRWM 具有即插即用特性，只需要少量的架构修改，并且可以按轨迹长度进行扩展，还与各种潜在生成骨干兼容。在确定性的3D环境中以及长时程预测任务中，GRWM 显著提高了展开的准确性和稳定性。研究表明，其优势来源于学习具有优质几何结构的潜在流形。这些发现支持一个明确的结论：改进表示学习是直接且有用的路径来构建健壮的世界模型，可以在不扩大动力学模块的情况下提供可靠的长期预测。
### Conclusion
本文通过提出的几何规整化世界模型（GRWM）解决了构建能够完全克隆和过拟合到确定性3D世界的难题，显著提高了展开的准确性和稳定性。研究结果表明，通过改进表示学习可以构建健壮的世界模型，而不会扩大动力学模块。
## 152. `cs.AI` - Advancing Mobile GUI Agents: A Verifier-Driven Approach to Practical Deployment [PDF](https://arxiv.org/pdf/2503.15937), [HTML](https://arxiv.org/abs/2503.15937)
### Authors
Gaole Dai,Shiqi Jiang,Ting Cao,Yuanchun Li,Yuqing Yang,Rui Tan,Mo Li,Lili Qiu
### Background
现有的移动GUI任务自动化代理通常利用大型语言模型（LLMs）直接生成每个步骤的动作。然而这种直接生成的方法存在一定的局限性，V-Droid创新地采用了维证驱动的方法，通过语言模型来验证候选的动作，而不是直接生成动作。这种方法通过构建离散化动作空间、仅预填充的工作流程、成对进展偏好训练以及可扩展的人机联合注释方案，提高了自动化代理的性能和效率。
### Innovation
V-Droid的核心创新在于它利用LLMs作为验证器，而不是生成器。具体创新点包括：1）构建离散化动作空间，2）仅预填充的工作流加速验证过程，3）成对进展偏好训练显著增强验证器的决策能力，4）可扩展的人机联合注释方案来高效收集数据。这些措施使得V-Droid在公共移动任务自动化基准测试中表现出色，并且具有显著更低的延迟性能。
### Conclusion
V-Droid在多个移动任务自动化基准测试中的成功率显著高于现有代理，分别为AndroidWorld 59.5%、AndroidLab 38.3%、MobileAgentBench 49%。V-Droid每一步的延迟为4.3秒，比现有移动代理快6.1倍。这些结果表明V-Droid在实用部署方面取得了显著的进步。
## 153. `cs.AI` - 视频模型作为零样本推理器是否准备好？基于MME-CoF基准的实证研究 [PDF](https://arxiv.org/pdf/2510.26802), [HTML](https://arxiv.org/abs/2510.26802)
### Authors
Ziyu Guo,Xinyan Chen,Renrui Zhang,Ruichuan An,Yu Qi,Dongzhi Jiang,Xiangtai Li,Manyuan Zhang,Hongsheng Li,Pheng-Ann Heng
### Background
近期的视频生成模型能够生成高保真、时序一致的视频，表明它们可能包含了大量的世界知识。除了现实的合成之外，这些模型还展示了一些预示视觉感知、建模和操控的新兴行为。然而，一个重要问题尚待解决：现有的视频模型是否准备好在挑战性的视觉推理场景中进行零样本推理？为了深入探讨这个问题，作者对领先的且受欢迎的Veo-3模型进行了一个实证研究，评估了该模型在12个维度上的推理行为，包括空间、几何、物理、时间以及体验逻辑，系统地刻画了其优势和失败模式。为了标准化研究，作者创建了符合CoF推理链的评估数据集MME-CoF，该基准能够进行深入和彻底的评估。研究发现，当前视频模型在短时间空间一致性、细微的定位和局部一致性动态推理等方面表现出有希望的推理模式，但在长时间因果推理、严格的几何约束和抽象逻辑推理方面仍存在局限性。因此，当前视频模型作为独立的零样本推理器尚不可靠，但表现出作为专用推理模型补充视觉引擎的积极信号。
### Innovation
研究创新在于通过构建符合CoF推理链的MME-CoF基准，系统地评估视频生成模型的推理能力和行为，这为视频生成模型在视觉推理领域的应用奠定了基础。这是第一次如此全面和标准化地研究这些模型的推理能力，并展示了当前技术的局限性和改进方向。
### Conclusion
目前的视频生成模型虽然在短周期范围内的空间一致性、细粒度的定位、局部动力学一致性等推理能力上表现出希望，但在长周期的因果推理、严格几何约束和抽象逻辑推理方面仍存在局限。因此，它们尚未成为可靠且独立的零样本推理器，但作为专用推理模型的补充视觉引擎显示出了积极的前景。
## 154. `cs.AI` - 塑性作为赋能的镜像 [PDF](https://arxiv.org/pdf/2505.10361), [HTML](https://arxiv.org/abs/2505.10361)
### Authors
David Abel,Michael Bowling,André Barreto,Will Dabney,Shi Dong,Steven Hansen,Anna Harutyunyan,Khimya Khetarpal,Clare Lyle,Razvan Pascanu,Georgios Piliouras,Doina Precup,Jonathan Richens,Mark Rowland,Tom Schaul,Satinder Singh
### Background
文章探讨了代理（agent）的核心能力，即基于过去的观察来进行行为选择的能力和对未来观察的影响能力。以前，赋能(empowerment) 被广泛用于描述代理影响未来观察的能力，而过去的观察对其本身的微妙影响则没有得到充分的探讨。为此，作者提出了一个新的概念——塑性(plasticity)，以更全面地描述代理的这些能力，并揭示了塑性和赋能之间的根本联系。
### Innovation
文章引入了一个通用的代理中心化的度量标准——塑性，它采用了一个新的信息论量度——广义定向信息量（generalized directed information）。这种新量度不仅严格扩展了马西（Massey, 1990）提出的定向信息量的定义，而且还保留了其所有可取的特性。通过塑性这一概念，作者发现塑性和赋能是镜像关系：两个概念使用相同的测量方法，只是影响的方向相反。文章得出的主要结论是，代理设计需要同时考虑这两个特性，因此了解塑性和赋能之间的关系对于理解代理性是至关重要的。
### Conclusion
文章揭示了塑性和赋能之间的镜像关系，并发现代理的设计需要同时考虑这两个特性。这种新的视角对于理解代理的行为动力学和代理性有重要意义。
## 155. `cs.AI` - 重新思考计算高效测试时缩放中的最优验证粒度 [PDF](https://arxiv.org/pdf/2505.11730), [HTML](https://arxiv.org/abs/2505.11730)
### Authors
Hao Mark Chen,Guanxi Lu,Yasuyuki Okoshi,Zhiwen Mo,Masato Motomura,Hongxiang Fan
### Background
测试时缩放（TTS）已被证明能够增强大型语言模型（LLMs）的推理能力。验证在TTS中起着关键作用，同时也影响推理性能和计算效率，这取决于验证的质量和计算成本。现有研究通常只关注验证最终输出或单个生成步骤，忽视了验证频率的影响。
### Innovation
本文挑战了传统的验证范式，首次系统性地研究了验证粒度的影响。引入了具有可调粒度参数g的统一算法Variable Granularity Search (VG-Search)，它扩展了传统的束搜索和Best-of-N采样。通过在不同计算预算、生成-验证配置和任务属性下进行大量实验，发现动态选择g可以提高计算效率和缩放行为。基于这些发现，提出了适应性VG-Search策略，相比束搜索提高了3.1%的准确性，相比Best-of-N提高了3.6%的准确性，同时减少了超过52%的FLOPs。
### Conclusion
研究结果表明，动态选择验证粒度g可以在节省计算资源的同时提高推理性能。相关的代码将开放源代码，以支持未来的研究。
## 156. `cs.AI` - AutoLibra：从开放性人类反馈中生成代理指标 [PDF](https://arxiv.org/pdf/2505.02820), [HTML](https://arxiv.org/abs/2505.02820)
### Authors
Hao Zhu,Phil Cuvin,Xinkai Yu,Charlotte Ka Yee Yan,Jason Zhang,Diyi Yang
### Background
当前，代理多通过任务成功率指标进行评估与优化，这些指标粗糙、依赖专家的手动设计，并且不能奖励中间涌现行为。文章指出这些问题，并探讨了需要一种新的方法来细化代理轨迹中的行为评估标准，将开放性的用户反馈（如“如果发现按钮禁用，请不要再点击它” 或“此代理自主性过高，独立决定做什么”）转化为具体的评估指标。
### Innovation
文章提出了**AutoLibra**框架，旨在将开放结束的人类反馈转化为代理行为的细颗粒度评估指标。AutoLibra将反馈与此代理的行为进行锚定，对相似的正向和负向行为进行聚类，并创建具有明确定义和具体示例的具体指标，用于提示语言模型作为评估者。文章进一步提出了两个元度量标准来评估给定的（诱导）度量与开放反馈的对齐情况：覆盖率与冗余度。通过优化这些元度量标准，文章展示了AutoLibra能够诱导比之前代理评估基准提出的具体度量更详细的评估指标，发现新的度量标准以分析代理行为。此外，文章展示了AutoLibra在代理改进中的两个应用场景：一是为人类提示工程师进行代理失败的对角化，迭代改进提示；二是代理能够自主调节通过自引导产生度量指标进行自动优化，提升自身表现。
### Conclusion
实验结果表明，AutoLibra是一种适用于评估和改进语言代理的强有力的、任务无关的工具。
## 157. `cs.AI` - MedAgentBoard: 采用传统方法对多种医疗任务进行多智能体协作基准测试 [PDF](https://arxiv.org/pdf/2505.12371), [HTML](https://arxiv.org/abs/2505.12371)
### Authors
Yinghao Zhu,Ziyi He,Haoran Hu,Xiaochen Zheng,Xichen Zhang,Zixiang Wang,Junyi Gao,Liantao Ma,Lequan Yu
### Background
随着大型语言模型（LLMs）的快速发展，多智能体协作在解决复杂医疗任务方面的应用引起了广泛关注。然而，多智能体协作的实际优势仍在很大程度上未被理解。现有的评估方法缺乏广泛的适用性，无法覆盖反映实际临床实践的多种任务，并且往往没有与基于单一智能体和传统方法进行严格的对比评估。
### Innovation
为了弥合这一关键空白，本研究引入了MedAgentBoard，这是一个全面的基准测试工具，用于系统评估多智能体协作、单一智能体和传统方法。MedAgentBoard 包含四类不同的医疗任务类别，涵盖文本、医学影像和结构化电子健康记录数据。通过广泛的实验，MedAgentBoard 揭示了多智能体协作在特定场景中的优势，但在某些任务上可能不如先进的单一智能体或专业传统方法。
### Conclusion
MedAgentBoard 提供了一个重要的资源和实际建议，强调了在医疗领域选择和发展 AI 解决方案时需采取特定任务和基于证据的方法。它表明，多智能体协作的固有复杂性和开销必须谨慎权衡以实现实际性能增益。所有代码、数据集、详细提示和实验结果均开源于 this https URL 。
## 158. `cs.AI` - 接纳矛盾：理论不一致性不会阻碍负责任的人工智能系统的建设之路 [PDF](https://arxiv.org/pdf/2505.18139), [HTML](https://arxiv.org/abs/2505.18139)
### Authors
Gordon Dai,Yunze Xiao
### Background
本文提出了关于负责任的人工智能（RAI）中理论不一致性（如不同的公平性定义或准确性和隐私之间的权衡）的观点。作者认为这些不一致性不应被视为缺陷，而是有价值的特征，应该被接纳。
### Innovation
文章创新性地提出了在处理RAI中的理论不一致性时，不应追求简化或消除这些不一致性。相反，应该视其为多元价值和不同伦理概念的载体，利用这些不一致性可以带来三个主要好处：(1) 规范多元性：保持一系列可能相互矛盾的指标，确保多样化的道德立场和利益相关者的价值得到充分反映；(2) 知识完整性：多种有时相互矛盾的指标能够更全面地捕捉多方面的伦理概念，从而比单一、简化定义更能保持这些概念的信息准确性；(3) 隐式正则化：同时优化理论上相冲突的目标可以防止过度拟合到特定指标，引导模型找到在现实中更具有泛化能力和稳健性的解决方案。
### Conclusion
本文建议在RAI理论和实践中不再陷入不一致的陷阱，而是从定量化允许的不一致性出发，明确接受这些不一致性，并探讨在实践中如何实现稳健的、近似的一致性。同时指出，试图通过简化或剔除指标来确保理论的一致性，可能会压缩这一价值多样性，失去概念深度，影响模型的性能。
## 159. `cs.AI` - Collab-REC: 一种基于LLM的多代理框架，用于旅游推荐的平衡 [PDF](https://arxiv.org/pdf/2508.15030), [HTML](https://arxiv.org/abs/2508.15030)
### Authors
Ashmi Banerjee,Adithi Satish,Fitri Nur Aisyah,Wolfgang Wörndl,Yashar Deldjoo
### Background
现有的旅游推荐系统往往受到流行性的偏见影响，推荐多样化不足，导致一些较少游览的地方被忽视。本研究旨在提出一种多代理框架Collab-REC，以减少流行性偏见，提高推荐的多样性。
### Innovation
Collab-REC 引入了三个基于LLM的代理——个性化、流行性和可持续性的视角来生成城市建议。通过多轮协商，一个非LLM的调解者将这些建议合并和优化，确保每个代理的观点被纳入，同时还惩罚错误或重复的响应。
### Conclusion
实验结果表明，Collab-REC 在提高多样化和整体相关性方面优于单一代理的基线系统，为较少游览的地方提供了更多的关注。这种平衡且具备上下文理解的方法，有效解决了过度旅游的问题，更符合用户的约束条件，证实了多利益相关者在LLM驱动的推荐系统中的潜力。
## 160. `cs.AI` - Self-Evolving Curriculum for LLM Reasoning [PDF](https://arxiv.org/pdf/2505.14970), [HTML](https://arxiv.org/abs/2505.14970)
### Authors
Xiaoyin Chen,Jiarui Lu,Minsu Kim,Dinghuai Zhang,Jian Tang,Alexandre Piché,Nicolas Gontier,Yoshua Bengio,Ehsan Kamalloo
### Background
强化学习（RL）已被证明对大型语言模型（LLM）进行微调非常有效，显著提升了它们在数学和代码生成等领域的推理能力。训练课程是影响RL微调成功的关键因素，指的是在训练过程中问题的呈现顺序。现有的随机课程作为基准，但效果有限；手动设计的课程依赖于许多启发式的做法，而在线过滤方法可能在计算上不切实际。因此，研究团队提出了一种名为Self-Evolving Curriculum (SEC)的自动课程学习方法，旨在同时优化课程策略和RL微调过程。这个问题被表述为一个非稳定报酬的一臂拉链问题，通过策略梯度方法的绝对优势作为即时学习收益的代理来选择问题类别。在每次训练步骤中，课程策略根据这个奖励信号最大化选择问题类别，并使用TD(0)方法进行更新。
### Innovation
SEC是一种自动课程学习方法，能够在RL微调过程中并发地学习课程策略。它将课程选择问题表述为一个非稳定的一臂拉链问题，并采用策略梯度方法的绝对优势作为即时学习收益的代理。这种方法通过评估每个问题类别（如难度级别或问题类型）的拉取问题来动态调整课程顺序。此外，SEC在同时对多个推理领域进行微调时，还能更好地实现技能平衡。实验结果表明，SEC能够有效提升LLM的推理能力，使其在更难的跨分布测试问题上表现出更好的泛化能力。
### Conclusion
研究成果表明，SEC是一种有效的RL微调策略，特别是对于提升LLM在多个推理领域的技能平衡和泛化能力。这为未来的LLM RL微调研究提供了新的思路。
## 161. `cs.AI` - Refine-n-Judge: Curating High-Quality Preference Chains for LLM-Fine-Tuning [PDF](https://arxiv.org/pdf/2508.01543), [HTML](https://arxiv.org/abs/2508.01543)
### Authors
Derin Cayir,Renjie Tao,Rashi Rungta,Kai Sun,Sean Chen,Haidar Khan,Minseok Kim,Julia Reinspach,Yue Liu
### Background
大型语言模型（LLMs）通过基于偏好的微调取得了显著的进步，这依赖于训练数据的质量。虽然人类反馈对于提高数据质量是必要的，但成本高昂且难以扩展。因此，需要一种自动化的迭代方法来提升数据集质量，而不需要额外的人类标注或独立的奖励模型。这项研究介绍了一种新的方法——Refine-n-Judge，该方法利用单一LLM作为修整者和裁判者，以增强数据集质量。
### Innovation
该论文提出了Refine-n-Judge，这是一种新的自动化迭代方法，利用单一LLM同时生成修整并明确评估每一次改进，确保每次迭代都有实质性地提升数据集，而不需要额外的人类标注或独立的奖励模型。该方法在每个步骤中会让LLM进行响应修整和判断是否优于前一个答案，直到LLM倾向于初始答案超过修整。这种方法生成了质量递增、带有偏好标签的响应序列，适用于细调。实验结果显示，使用Refine-n-Judge增强的数据集训练的模型在大多数对比中优于使用原始数据集训练的模型，且表现出性能提升。
### Conclusion
Refine-n-Judge方法能够生成高质量的数据集，实现可扩展的模型改进。该方法在多种公共数据集上展示了有效性，特别是在编码、数学和对话任务上。经过Refine-n-Judge优化的数据集训练的模型在与GPT-4等模型的对比中表现更优，且在多个评估基准上表现出显著的性能提升。
## 162. `cs.AI` - TERAG: Token-Efficient Graph-Based Retrieval-Augmented Generation [PDF](https://arxiv.org/pdf/2509.18667), [HTML](https://arxiv.org/abs/2509.18667)
### Authors
Qiao Xiao,Hong Ting Tsang,Jiaxin Bai
### Background
图驱动的检索增强生成（RAG）已成为提高大型语言模型（LLMs）推理、准确性和事实性的广泛研究方法。然而，许多现有的图驱动RAG系统忽略了在图构建过程中LLM token使用的高成本，这阻碍了其大规模应用。
### Innovation
提出了一种名为TERAG的简单而有效的框架，该框架旨在以显著更低的成本构建信息性图。该框架在检索阶段采用个性化的PageRank（PPR），并在保持与广泛使用的图驱动RAG方法至少80%的准确性的同时，仅消耗3%-11%的输出token。
### Conclusion
由于其低token内存和高效的构建管道，TERAG非常适合大规模和成本敏感的部署场景。
## 163. `cs.AI` - CompoST: 在QALD设置中分析LLMs组合性解释问题能力的基准 [PDF](https://arxiv.org/pdf/2507.21257), [HTML](https://arxiv.org/abs/2507.21257)
### Authors
David Maria Schmidt,Raoul Schubert,Philipp Cimiano
### Background
语言解释是一个组合过程，在这个过程中，更复杂的语言结构的意义是从其组成部分的意义推导出来的。大型语言模型具备出色的语言解释能力，并成功应用于将问题映射为SPARQL查询。一个开放的问题是这个解释过程是否系统和组合性。为了回答这个问题，本文提出了一种基准，用于研究LLMs解构问题的能力究竟有多组合性。为此，根据DBpedia中的图形模式生成了三个不同难度级别的数据集，并使用Lemon词典进行规范化。这些数据集的生成是在非常受控的情况下进行的，以测试LLMs在见过原子构建块后解释结构复杂问题的能力。由此可以评估LLMs在理解原子部分后，解释复杂问题的系统性和组合性程度。使用不同规模的模型进行实验，使用各种提示和少样本优化技术以及微调的方法。结果表明，随着与优化样本偏差的增加，宏观F1得分从0.45下降到0.26，最终下降到0.09。即使在输入中提供了所有必要的信息，对于复杂度最低的数据集，F1分数也未超过0.57。因此，研究结果表明LLMs难以系统和组合性地解释问题和将其映射为SPARQL查询。
### Innovation
本文提出了一种基准（CompoST）来评估和分析LLMs在遇到复杂问题时是否能系统和组合性地解析问题。通过基于DBpedia中的图形模式生成不同难度的数据集，可以控制地测试LLMs解释结构复杂问题的能力。此外，使用多种提示和少样本优化技术与微调方法进行实验，进一步验证了LLMs在处理复杂问题时的局限性。
### Conclusion
LLMs在系统和组合性地解释复杂问题并将其映射为SPARQL查询方面存在困难。即使提供完整的必要信息，对于结构最简单的数据集，F1得分也未超出0.57。
## 164. `cs.AI` - 拆解大型语言模型层在检索、知识和推理中的作用 [PDF](https://arxiv.org/pdf/2510.02091), [HTML](https://arxiv.org/abs/2510.02091)
### Authors
Xinyuan Song,Keyu Wang,PengXiang Li,Lu Yin,Shiwei Liu
### Background
近期研究表明，大型语言模型（LLMs）的较深层对于表示学习的贡献较小，往往可以去除部分更深层的结构而不影响性能。但这种观点通常是基于单一的评估而得出，可能忽略了模型行为的某些方面。
### Innovation
本文提出了一个系统性的研究，从评估协议、任务类别和模型架构等多个维度来研究深度使用情况。研究发现，虽然深层的层通常不如早期的层有效，但它们在不同评估环境中所起的作用差异显著。除了采用生成性评估发现深层层对于推理和长程一致性是必不可少的之外，还发现浅层组件负责知识和检索，而深度层对于准确的推理至关重要，但这些能力可以通过蒸馏进行重新塑造。
### Conclusion
该研究揭示了大型语言模型的深度使用具有高度异质性和依赖性，强调了在解释和压缩大型模型时需要任务、评估标准和模型感知的方法。
## 165. `cs.AI` - FESTA: 功能等效采样方法用于多模态大语言模型的信任评估 [PDF](https://arxiv.org/pdf/2509.16648), [HTML](https://arxiv.org/abs/2509.16648)
### Authors
Debarpan Bhattacharya,Apoorva Kulkarni,Sriram Ganapathy
### Background
对多模态大语言模型（MLLMs）进行准确的信任评估是具有挑战性的，因为它们处理的是多样化的多模态输入。准确的信任评估可以帮助选择性地生成预测，从而提高用户信心。
### Innovation
论文提出了FESTA（功能等效采样方法，Functionally Equivalent Sampling for Trust Assessment），这是一种用于MLLMs的多模态输入采样技术，通过等效采样和互补采样生成不确定性度量。这种方法采用了一种任务保持的不确定性量化采样方法，扩展了输入空间来探测模型的一致性和灵敏度，同时只需要模型的输入-输出访问（黑盒），无需 ground truth（无监督）。
### Conclusion
实验使用了多种现成的多模态大语言模型，在视觉和音频推理任务上进行了测试。FESTA 提出的不确定性估计显著提高了选择性预测性能（视觉LLMs相对改善33.3%，音频LLMs相对改善29.6%），基于检测错误预测的面积下的受检者操作特征曲线（AUROC）指标。FESTA 的代码实现已开源。
## 166. `cs.AI` - 思考后再嵌入：生成上下文改进多模态嵌入 [PDF](https://arxiv.org/pdf/2510.05014), [HTML](https://arxiv.org/abs/2510.05014)
### Authors
Xuanming Cui,Jianpeng Cheng,Hong-you Chen,Satya Narayan Shukla,Abhijeet Awasthi,Xichen Pan,Chaitanya Ahuja,Shlok Kumar Mishra,Yonghuan Yang,Jun Xiao,Qi Guo,Ser-Nam Lim,Aashu Singh,Xiangjun Fan
### Background
目前，对通用多模态嵌入（UME）的兴趣日益增加，模型被期望生成特定任务的表示。尽管最近的研究表明，多模态大型语言模型（MLLMs）在这些任务上表现出色，但它们只被用作编码器，忽视了它们的生成能力。然而，这种编码范式在处理复杂指令和需要组合推理时变得不够有效。受链式思考推理有效性的启发，提出了一个通用的Think-Then-Embed（TTE）框架，由一个推理器和一个嵌入器组成，以应对上述挑战。
### Innovation
该研究通过利用强大的MLLM推理器，实现了MMEB-V2基准上的最佳性能，超越了在大内部分类数据集上训练的专用模型。其次，为了减少对大规模MLLM推理器的依赖，该研究微调了一个较小的MLLM推理器，使用高质量的嵌入中心推理痕迹，实现了开源模型的最佳性能，相对于最近提出的模型有7%的绝对改进。最后，该研究还研究了将推理器和嵌入器整合到统一模型中的策略，以提高效率而不牺牲性能。
### Conclusion
该研究通过一种新颖的Think-Then-Embed（TTE）框架，展示了通过生成上下文改进多模态嵌入的有效性，并且在多个方面取得了显著改进。
## 167. `cs.AI` - 地球AI：基于基础模型与跨模态推理的地学洞察解锁 [PDF](https://arxiv.org/pdf/2510.18318), [HTML](https://arxiv.org/abs/2510.18318)
### Authors
Aaron Bell,Amit Aides,Amr Helmy,Arbaaz Muslim,Aviad Barzilai,Aviv Slobodkin,Bolous Jaber,David Schottlander,George Leifman,Joydeep Paul,Mimi Sun,Nadav Sherman,Natalie Williams,Per Bjornsson,Roy Lee,Ruth Alcantara,Thomas Turnbull,Tomer Shekel,Vered Silverman,Yotam Gigi,Adam Boulanger,Alex Ottenwess,Ali Ahmadalipour,Anna Carter,Behzad Vahedi,Charles Elliott,David Andre,Elad Aharoni,Gia Jung,Hassler Thurston,Jacob Bien,Jamie McPike,Juliet Rothenberg,Kartik Hegde,Kel Markert,Kim Philipp Jablonski,Luc Houriez,Monica Bharel,Phing VanLee,Reuven Sayag,Sebastian Pilarski,Shelley Cazares,Shlomi Pasternak,Siduo Jiang,Thomas Colthurst,Yang Chen,Yehonathan Refael,Yochai Blau,Yuval Carny,Yael Maguire,Avinatan Hassidim,James Manyika,Tim Thelin,Genady Beryozkin,Gautam Prasad,Luke Barrington,Yossi Matias,Niv Efron,Shravya Shetty
### Background
地学数据提供了深入了解地球的巨大潜力，但由于数据的庞大和多样，以及其在空间、时间和分辨率上的差异，使得全面分析和解读变得极其困难。本文介绍了地球AI，这是一种地学AI模型和智能推理引擎，旨在通过跨多领域（如全球影像、人口和环境）的基础模型及其相互作用，增强对地球的新颖和深刻的认知能力。这种方法基于三种关键领域的基础模型构建，结合了一个由Gemini驱动的智能推理引擎，旨在处理复杂的多步骤查询，从原始地学数据到可操作的了解，实现了广泛应用。
### Innovation
地球AI是一系列地学AI模型及其推理引擎，通过跨多领域的基础模型实现对地球的深层次理解。特别之处在于Gemini驱动的智能推理引擎能够处理复杂的多步骤查询，有效连接实际危机场景的采集数据与获取的实用洞察。
### Conclusion
通过地球AI的方法，在新的实际危机场景基准测试中展示了强大的能力和新颖功能，证明了多种基础模型结合使用的互补价值，以及协同作用带来的卓越预测能力。
## 168. `cs.AI` - 超越被动反应：测量LLM代理的主动问题解决 [PDF](https://arxiv.org/pdf/2510.19771), [HTML](https://arxiv.org/abs/2510.19771)
### Authors
Gil Pasternak,Dheeraj Rajagopal,Julia White,Dhruv Atreja,Matthew Thomas,George Hurn-Maloney,Ash Lewis
### Background
基于LLM的代理正在日益转向主动性，而非等待指令便采取行动来预见用户需求并自主解决，然而，评估其主动性面临挑战，现行基准局限于局部语境，难以测试跨越多个信息源及长时间段的推理能力。
### Innovation
本文提出了PROBE（主动解决瓶颈），它将主动性分解为三个核心能力的流水线过程：（1）寻找未指定的问题，（2）识别特定瓶颈，（3）执行适当的解决方案。本文还应用PROBE评估了领先的LLM和流行的代理框架，结果显示最先进的模型在解决这个基准方面仍然面临挑战。此外，研究还展示了每个模型的相对能力并分析了它们的共同失败模式。
### Conclusion
研究结果突显了当前自主行动在代理系统中的局限，并提出了未来研究的方向。
## 169. `cs.AI` - 模糊化、符号化和语境化：通过认知架构增强LLM教学 [PDF](https://arxiv.org/pdf/2508.21204), [HTML](https://arxiv.org/abs/2508.21204)
### Authors
Vanessa Figueiredo
### Background
研究分析大语言模型（LLMs）在教学对话中的推理行为受到提示级别归纳偏好的影响。作者使用一种符号化支撑方法配以短期记忆模式，在Socratic教学中促进适应性的结构化推理，并通过精心设计的评估框架考察模型的输出相对应的认知支持、响应性、符号推理和对话记忆。这是一个跨体系架构变异的可扩展、系统性的比较框架，有助于早期阶段的实验研究。初步结果显示，包含记忆和符号结构的完整系统始终优于基线变体。去除了记忆或符号结构会降低关键的认知行为表现，如抽象、适应性探查和概念延续。这些发现支持了一个在处理层面的解释，即提示级别认知结构可以可靠地形成LLMs中的教学策略。
### Innovation
引入了一种符号化支撑方法与短期记忆模式相结合的方法，旨在促进Socratic教学中的适应性结构化推理。通过可控的消融实验评估模型输出，使用专家设计的评分标准涵盖支撑、响应性、符号推理和对话记忆。这种方法为跨架构变体的早期实验研究提供了可扩展的、系统化的比较框架。结果表明，完整系统始终优于基线变体，去除记忆或符号结构会显著降低关键认知行为的表现。这一研究支持了提示层认知结构可以可靠地影响LLMs的教学策略这一处理级别解释。
### Conclusion
通过对五种系统变体的可控消融实验，结合认知背景下的评分标准，初步研究结果表明完整架构始终优于基线变体。分析发现，消去记忆或符号结构会显著影响抽象、适应性探查和概念延续等关键认知行为。这些发现支持了一个处理层面的理论构想，即提示层的认知结构可以可靠地塑造LLMs中的教学策略。
## 170. `cs.AI` - LAFA：分布数据源上的代理LLM驱动联合分析 [PDF](https://arxiv.org/pdf/2510.18477), [HTML](https://arxiv.org/abs/2510.18477)
### Authors
Haichao Ji,Zibo Wang,Cheng Pan,Meng Han,Yifei Zhu,Dan Wang,Zhu Han
### Background
大型语言模型(LLMs)在通过自然语言查询解释和生成多操作执行计划方面显示出了极大的潜力，用于自动化数据分析任务。现有的基于LLM代理的数据分析框架假设了集中化的数据访问，缺乏隐私保护。相比之下，联合分析（FA）允许在分布式数据源上进行隐私保护计算，但需要结构化的机器可读查询，不支持自然语言输入。
### Innovation
LAFA 是第一个将基于LLM代理的数据分析与联合分析相结合的系统。它提出了一个分层多代理架构，接受自然语言查询并将其转换为优化的可执行FA工作流。通过分层规划和优化代理来提高执行效率，LAFA 可以将复杂查询分解为子查询，并将每个子查询映射到使用先验结构知识的FA操作有向无环图（DAG）。同时，优化代理重写和合并多个DAG，消除冗余操作，减少计算和通信开销。
### Conclusion
实验表明，LAFA 在执行计划成功率方面始终优于基线提示策略，减少了资源密集型FA操作。这项工作奠定了隐私保护、LLM驱动的数据分析系统的实用基础，该系统可以支持FA设置中的自然语言输入。
## 171. `cs.AI` - 视觉推理中的潜在链式思考 [PDF](https://arxiv.org/pdf/2510.23925), [HTML](https://arxiv.org/abs/2510.23925)
### Authors
Guohao Sun,Hang Hua,Jian Wang,Jiebo Luo,Sohail Dianat,Majid Rabbani,Raghuveer Rao,Zhiqiang Tao
### Background
链式思考（CoT）推理对提升大型视觉-语言模型（LVLMs）的可解释性与可靠性至关重要。然而，现有的训练算法（如SFT、PPO和GRPO）可能难以很好地泛化到未见过的推理任务上，并且高度依赖于有偏的奖励模型。
### Innovation
我们重新定义了LVLMs中的推理为后验推理，并提出了一种基于近似变异求和的可扩展训练算法。利用寻求多样性的强化学习算法，我们引入了一种新颖的稀疏奖励函数，以鼓励多样且高可能性的潜在CoT，克服了确定性采样的局限，避免了奖励作弊。此外，我们实现了一种贝叶斯推理扩增策略，用边际似然替代昂贵的Best-of-N和Beam Search，以高效地排名最优的理由和答案。
### Conclusion
我们实验性地证明，所提出的方法能够提升七个推理基准上最先进的LVLMs的有效性、泛化能力和可解释性。
## 172. `cs.AI` - Lost in Tokenization: Context as the Key to Unlocking Biomolecular Understanding in Scientific LLMs [PDF](https://arxiv.org/pdf/2510.23127), [HTML](https://arxiv.org/abs/2510.23127)
### Authors
Kai Zhuang,Jiawei Zhang,Yumou Liu,Hanqun Cao,Chunbin Gu,Mengdi Liu,Zhangyang Gao,Zitong Jerry Wang,Xuanhe Zhou,Pheng-Ann Heng,Lijun Wu,Conghui He,Cheng Tan
### Background
科学大型语言模型（Sci-LLMs）在加速生物发现方面展现出潜力，但它们在处理原始生物分子序列时面临一个根本性挑战：分词难题。当前策略并未有效解决该问题，限制了它们的理解能力。本文通过系统比较领先Sci-LLMs在生物推理任务中的表现，测试了三种输入方式：仅序列输入、仅上下文输入以及两者结合。研究表明，仅上下文输入方式在所有模式中表现最优，并且在加入了低级噪声序列数据后，性能反而下降。这表明，对于现有Sci-LLMs，其主要优势在于推理解释先验知识，而非直接理解生物分子语法。
### Innovation
本文提出了新的设计理念，即Sci-LLMs应提供高层次的结构化上下文，而非直接处理低级序列数据。研究表明，仅上下文输入方式在生物推理任务中表现最优，甚至在包含原始序列数据时性能下降，表明原始序列数据在模型中的信息噪声作用。因此，Sci-LLMs应被视为强大的基于专家知识的推理引擎，而非序列解码器。这一研究奠定了新型混合科学AI代理的基础，重新定位了模型开发的重点，即从直接序列解释转向高层次知识合成。
### Conclusion
本文的研究结果表明，现有Sci-LLMs的主要优势在于处理结构化的知识，而非直接解析生物序列。建议将Sci-LLMs重新定位为强大的基于专家知识的推理引擎。未来的工作将以高层次知识合成而非直接序列解释为重点。
## 173. `cs.AI` - 大型语言模型对齐中的奖励坍塌现象 [PDF](https://arxiv.org/pdf/2305.17608), [HTML](https://arxiv.org/abs/2305.17608)
### Authors
Ziang Song,Tianle Cai,Jason D. Lee,Weijie J. Su
### Background
大型语言模型（LLMs），如ChatGPT和GPT-4，通过与基于人类偏好的奖励模型对齐表现出其卓越的能力。通常，人类偏好以回响应答提示的排名形式表示。然而，在模型训练的某个阶段，排名导向的方法会导致奖励分布一致收敛，不论提示内容，这与期望的奖励分布不匹配，开放性提示和具体提示的奖励不应一致。
### Innovation
本文介绍了奖励坍塌现象，并发现排名导向的优化目标函数缺乏在优化过程中处理提示相关信息的能力。通过理论研究，推导出了在渐近性态下的奖励分布的封闭形式表达式。提出了一个提示感知的优化方案，确保在插值区间内可以实现提示依赖的奖励分布，从而有效缓解奖励坍塌现象。
### Conclusion
本文证明了提示感知的优化方案能够显著缓解在奖励模型训练期间的表现不佳现象，为大型语言模型的对齐问题提供了新的解决思路。
## 174. `cs.AI` - 在现实主义足球模拟中的类人类守门员：一种样本高效强化学习方法 [PDF](https://arxiv.org/pdf/2510.23216), [HTML](https://arxiv.org/abs/2510.23216)
### Authors
Alessandro Sestini,Joakim Bergdahl,Jean-Philippe Barrette-LaPierre,Florian Fuchs,Brady Chen,Michael Jones,Linus Gisslén
### Background
尽管一些知名视频游戏已经作为深度强化学习（DRL）的测试平台，但该技术在游戏行业用于创造真实的AI行为方面应用有限。以往的研究主要集中在使用大量数据集训练超人类智能体上，这不适用于资源有限的游戏工作室希望培养类似人类的智能体。本文提出了一种针对工业设置，例如视频游戏行业的样本高效的DRL方法，通过利用预先收集的数据和提高网络的可塑性来提高基于值的DRL的样本效率。我们对EA SPORTS FC 25（当今最畅销的足球模拟之一）进行了守门员智能体的训练，并且实验表明与游戏内置的AI相比，我们的智能体在球扑救率上提升了10%。消融研究显示，相比标准DRL方法，我们的方法可将智能体的训练速度提高50%。最后，领域专家的定性评估表明，我们方法生成的游戏比手工设计的智能体更具有人类特征。该方法已经应用于系列最近的版本，证明了其影响
### Innovation
本文提出了一种针对工业设置的样本高效的DRL方法，通过利用预先收集的数据和提高网络的可塑性来提高基于值的DRL的样本效率。特别是在EA SPORTS FC 25游戏中对守门员智能体进行的训练取得了显著的效果，比游戏内置的AI表现更好，并且训练速度更快，这也证明了在类似真实环境下的应用潜力和实际效果。
### Conclusion
我们的方法在一个现实主义的足球模拟游戏EA SPORTS FC 25中产生了类人类的守门员智能体，并且实验结果表明这种方法比传统的DRL方法更有效。此外，这种方法还被认为比手工设计的智能体更接近真实的人类行为，最终被应用在系列游戏中。
## 175. `cs.AI` - VerifIoU - 对象检测对干扰的鲁棒性 [PDF](https://arxiv.org/pdf/2403.08788), [HTML](https://arxiv.org/abs/2403.08788)
### Authors
Noémie Cohen,Mélanie Ducoffe,Ryma Boumazouza,Christophe Gabreau,Claire Pagetti,Xavier Pucel,Audrey Galametz
### Background
该研究引入了一种用于对象检测模型形式验证的新颖方法——区间边界传播（Interval Bound Propagation, IBP），并特别针对交并比（Intersection over Union, IoU）指标。该方法已经在开源代码IBP IoU中实现，并与基于抽象解释的验证工具兼容。验证器已经在着陆方法跑道检测和手写数字识别案例研究中进行评估，以便展示其在保证准确性和稳定性方面的卓越性能，从而推动更安全和稳健的机器学习应用的发展背景下进行的。
### Innovation
研究提出了一种新的区间边界传播（IBP）方法，将其应用于对象检测模型的形式验证，尤其针对交并比（IoU）指标，并在开源工具IBP IoU中实现。这种方法相较于传统的IBP在保证准确性和稳定性方面表现更优，提升了机器学习应用的安全性和鲁棒性。
### Conclusion
通过对比基线（传统IBP），验证器在着陆方法跑道检测和手写数字识别案例中表现出了更高的准确性和稳定性。这表明，IBP IoU方法对于提升对象检测应用的安全性和鲁棒性非常有效。
## 176. `cs.AI` - 基于TD3的混沌强化学习 [PDF](https://arxiv.org/pdf/2405.09086), [HTML](https://arxiv.org/abs/2405.09086)
### Authors
Toshitaka Matsuki,Yusuke Sakemi,Kazuyuki Aihara
### Background
混沌强化学习（CBRL）是一种方法，其中代理的内部混沌动力学驱动探索。然而，之前的研究所开发的学习算法并未完善，也没有结合强化学习领域的最新进展。这项研究将当前最先进深度强化学习算法之一Twin Delayed Deep Deterministic Policy Gradients (TD3)引入到CBRL中。TD3能够处理确定性和连续动作空间，研究通过验证结果提供了一些见解。
### Innovation
将TD3引入CBRL，使CBRL能够在简单的目标操作任务中作为学习算法工作；随着学习的进行，CBRL代理能够自主抑制其探索行为，并在环境变化时恢复探索；通过研究代理混沌性对学习的影响，发现代理模型中有合适的混沌强度范围可以在探索与利用之间灵活切换，适应环境变化。
### Conclusion
研究结果表明，TD3可以作为一种学习算法用于CBRL，在目标达成任务中可以有效驱动探索，并能够灵活应对环境变化。
## 177. `cs.AI` - Multi-Agent Evolve: LLM Self-Improve through Co-evolution [PDF](https://arxiv.org/pdf/2510.23595), [HTML](https://arxiv.org/abs/2510.23595)
### Authors
Yixing Chen,Yiding Wang,Siqi Zhu,Haofei Yu,Tao Feng,Muhan Zhang,Mostofa Patwary,Jiaxuan You
### Background
强化学习（RL）在提升大语言模型（LLM）的推理能力方面展现了显著潜力。然而，RL的成功依赖于人工标注的数据集和可验证的奖励，这限制了其扩展性和通用性。最近的自我博弈RL方法，灵感来源于游戏和围棋领域的成功，旨在通过自动化反馈来提升LLM的推理能力，但这些方法主要依赖于具体环境（如Python解释器或游戏引擎）来提供反馈，因此将其扩展到更广泛的领域依然是一个挑战。
### Innovation
我们提出了Multi-Agent Evolve（MAE）框架，该框架通过三元互动代理（Proposer，Solver，Judge）使LLM能够在解决数学、推理和通用知识问答等多样化任务上自我进化。MAE的核心设计基于单个LLM实例化三个交互代理，并应用强化学习来优化它们的行为。实验证明，MAE能够在Qwen2.5-3B-Instruct等多个基准上取得了平均4.54%的提升，突显了其作为一种数据效率高且依赖于人工标注最少的方法，能够扩展LLM的通用推理能力的特点。
### Conclusion
实验结果表明，MAE是一个可扩展、数据高效的强化学习方法，能够通过最小的人工标注监督来提升LLM的通用推理能力。
## 178. `cs.AI` - Chain-of-Scrutiny: Detecting Backdoor Attacks for Large Language Models [PDF](https://arxiv.org/pdf/2406.05948), [HTML](https://arxiv.org/abs/2406.05948)
### Authors
Xi Li,Ruofan Mao,Yusen Zhang,Renze Lou,Chen Wu,Jiaqi Wang
### Background
大型语言模型（LLMs），尤其是通过API访问的LLMs，在各个领域展现了出色的能力。然而，缺乏技术背景的用户常依赖不可信的第三方服务，如提示工程，来优化他们的LLM体验，这使得他们容易受到恶意威胁（例如后门攻击）的影响。传统的防御策略针对小型模型有效，但对于通过API访问的大型模型来说，由于有限的模型访问权限、高昂的计算成本和数据需求，这些策略变得不切实际。
### Innovation
我们提出了一种名为Chain-of-Scrutiny（CoS）的新方法，利用大型语言模型的独特推理能力来应对后门攻击。CoS引导模型生成输入的推理步骤，并审查这些步骤与最终输出的一致性，任何不一致都可能表明存在攻击。这种方法特别适合只通过API部署的大型语言模型，可在成本低、数据需求少的情况下进行检测。用户可以通过自然语言手动操作，无需技术背景，同时保持透明度。
### Conclusion
我们通过在各种任务和LLM上进行广泛实验验证了CoS的有效性，结果表明，对于更强大的LLM，CoS带来的益处更为显著。
## 179. `cs.AI` - Speak & Spell: 使用大模型驱动的可控音节错误增强技术以提高鲁棒对话状态跟踪的性能 [PDF](https://arxiv.org/pdf/2409.06263), [HTML](https://arxiv.org/abs/2409.06263)
### Authors
Jihyun Lee,Solee Im,Wonjun Lee,Gary Geunbae Lee
### Background
对话状态跟踪（DST）是任务导向对话系统的关键部分，它能识别对话中的重要信息。然而，在口语对话环境中，由于自动语音识别（ASR）系统的命名实体错误导致其准确度显著下降。因此，提高DST模型在有噪声和低准确率ASR环境下的鲁棒性显得尤为重要。
### Innovation
介绍了一种简单且有效的大模型驱动的数据增强方法，用于特定实体的错误生成，以增强DST模型的鲁棒性。该方法通过带有关键词高亮提示的可控方式引入音节相似的错误，成功生成了关键词上足够的错误模式，从而提高了在噪声和低准确率ASR环境下的准确性。
### Conclusion
通过这种方法，DST模型在有噪声和低准确率ASR环境下的准确度得到了提升，证明了该方法的有效性和鲁棒性。
## 180. `cs.AI` - 捍卫事后解释 [PDF](https://arxiv.org/pdf/2412.17883), [HTML](https://arxiv.org/abs/2412.17883)
### Authors
Nick Oh
### Background
本文讨论了事后说明方法在机器学习中的合法地位。批评这些方法的可靠性和认识论状态使得需要为其实质提供哲学支持。文章针对这些批评，提出了一种基于中介理解与有限事实性的哲学框架。
### Innovation
文章发展了一种基于中介理解与有限事实性的哲学框架，为事后说明方法作为科学知识生产工具的合法性辩护。创新之处在于提出即使是在部分透明的情况下，通过结构化的模型行为解释也可以产生科学洞察。通过实证验证，并且辅助生成新的假设，这种做法可以增进对现象的理解。
### Conclusion
文章通过分析最新的生物医学机器学习应用，展示了在适当整合到科学实践中，事后解释方法如何能生成新假设并促进现象理解。
## 181. `cs.AI` - 神经网络中的正性条件数学验证及其在部分单调性和可信人工智能中的应用 [PDF](https://arxiv.org/pdf/2406.08525), [HTML](https://arxiv.org/abs/2406.08525)
### Authors
Alejandro Polo-Molina,David Alfaya,Jose Portela
### Background
人工神经网络（ANNs）已成为处理大型数据集复杂关系的强大工具，但由于其黑盒特性，它们在可信性方面存在问题。在某些情况下，确保预测的可信性可能需要遵守特定的部分单调性约束。然而，验证一个已训练的ANN是否部分单调是一个挑战。因此，ANNs在一些关键应用中常常被忽略，比如信用评分，其中部分单调性是必要的。
### Innovation
本文提出了一种新的算法（LipVor），该算法基于有限数量的评估，验证黑盒模型（如ANN）的正性。由于部分单调性可以表示为部分导数的正性条件，LipVor可以验证ANN是否具备部分单调性。该方法通过为每一个评估点构造一个特定的邻域，保证函数在该邻域内保持正性，然后基于这些评估点的Voronoi图提出一个充分条件来验证函数在域中的正性。与先前的方法不同，该方法不需要受限的架构或分段线性激活函数，因此LipVor可以使得不受限制的ANN在某些关键领域得到应用。此外，ANN的其他性质，如凸性，也可以用正性条件来表达，因此LipVor也可以应用于这些性质。
### Conclusion
本文提供了一种数学方法来验证ANN中的正性条件，特别是在部分单调性和可信人工智能的应用中。此方法不仅解决了验证ANN部分单调性的难题，还为不受限制的ANN在关键领域中的应用铺平了道路，同时为验证其他ANN性质提供了可能。
## 182. `cs.AI` - 使用多个弱评估器的语言模型偏好评估 [PDF](https://arxiv.org/pdf/2410.12869), [HTML](https://arxiv.org/abs/2410.12869)
### Authors
Zhengyu Hu,Jieyu Zhang,Zhihan Xiong,Alexander Ratner,Kaize Ding,Ranjay Krishna
### Background
尽管大型语言模型（LLMs）取得了显著的成功，但在评估其输出的质量是否符合偏好方面仍存在重大挑战。现有方法通常依赖一个强大的LLM作为判断者，逐对比较LLM的响应，但单一评估者的方法容易出现循环偏好问题，即A比B好，B比C好，但C又比A好，导致评价结果矛盾。
### Innovation
为解决循环偏好问题，该研究引入了PGED（偏好图集成和去噪）方法，该方法利用多个基于模型的评估者构建偏好图，并对这些图进行集成和去噪，以提供循环和矛盾评价结果的非循环评价结果。该框架提供了理论保证，证明其能有效地恢复真实偏好结构。
### Conclusion
在十个基准上进行的广泛实验表明，PGED在三种应用中显示了优越性：1) 评估模型排名，2) 测试时间扩展响应选择，3) 模型微调的数据选择。值得注意的是，PGED通过使用小型LLM评估器（如Llama3-8B、Mistral-7B、Qwen2-7B）来超越强大的LLM评估器（如Qwen2-72B），展示了其提高评价可靠性和改进模型性能的有效性。
## 183. `cs.AI` - Constrained Posterior Sampling: 强制约束的时间序列生成 [PDF](https://arxiv.org/pdf/2410.12652), [HTML](https://arxiv.org/abs/2410.12652)
### Authors
Sai Shankar Narasimhan,Shubhankar Agarwal,Litu Rout,Sanjay Shakkottai,Sandeep P. Chinchali
### Background
生成现实的时间序列样本对于模型的极限测试以及通过合成数据保护用户隐私至关重要。在工程和安全关键应用中，这些样本必须满足特定领域或由物理或自然自发规定的约束。例如，在电力需求模式生成中，存在高峰需求时间的约束条件，这有助于在恶劣天气条件下测试电网的功能。现有的生成受限时间序列的方法要么不具备扩展性，要么降低样本质量。因此，本研究旨在提出一种能够满足多种数量级严格约束的生成算法。
### Innovation
引入了Constrained Posterior Sampling (CPS)，一种基于扩散的采样算法，该算法旨在在每次去噪更新后将后验均值估计投影到约束集中。CPS能够在无需额外训练的情况下扩展到大量约束（约100个），并且提供了理论证明来强调投影步骤的影响。实验结果显示，CPS在样本质量和与实际时间序列的相似度方面，在现实世界股票、交通和空气质量数据集上分别超过了最新方法约70%和22%。
### Conclusion
Constrained Posterior Sampling (CPS)提供了一种有效的方法来生成具有硬约束的时间序列，能够在保持样本质量和真实度的同时扩展到大量的约束。
## 184. `cs.AI` - AI的社会力场：重塑人类-AI团队中的分布式认知 [PDF](https://arxiv.org/pdf/2407.17489), [HTML](https://arxiv.org/abs/2407.17489)
### Authors
Christoph Riedl,Saiph Savage,Josie Zvelebilova
### Background
本文探讨了在团队合作中，AI不仅仅是一个中立的工具，而是积极地重新塑造了协作中的社会和认知结构。研究通过两个实验展示了AI生成的语言对人们语言使用、思维方式、注意力焦点以及彼此关系的影响，揭示了AI在团队中的双重影响：一方面促进高效的协作，另一方面却可能削弱知识多样性并破坏自然的对齐过程。文章强调需要从社会影响力的角度重新思考AI在团队中的角色，并提出新的设计范式，以提高人类和AI协作的责任性和有效性。
### Innovation
本文提出了一种统一的分布式认知对齐框架，阐述了人类和AI代理共同构建共享表征空间的过程，这在现有研究中是创新之处。研究首次详细展示了AI生成的语言如何影响人们的思维方式和社交互动，揭示了AI以隐性社会力场的身份重新组织团队的认知架构。文中提出，AI技术的双刃剑效应促使研究人员重新思考AI在团队中的作用，并寻求更透明、可控的设计方法，以促进有责任感且富有成效的人机协作。
### Conclusion
本研究揭示了AI在人类-AI团队中重构分布认知的作用，并强调AI不仅促进了高效的协作，也可能削弱团队的知识多样性和自然对齐过程。因此，需要从社会影响力的角度重新考虑AI在团队中的角色，并设计更加透明、可控制和关注群体动态的方法，以促进负责任且富有成效的人类-AI合作。
## 185. `cs.AI` - 多样性作为一种奖励：使用领域未确定的数据微调LLMs [PDF](https://arxiv.org/pdf/2502.04380), [HTML](https://arxiv.org/abs/2502.04380)
### Authors
Zhenqing Ling,Daoyuan Chen,Liuyi Yao,Qianli Shen,Yaliang Li,Ying Shen
### Background
通过使用多样化的数据集微调大型语言模型（LLMs）对于提升其在多种领域中的综合性能至关重要。现有方法经常会面对缺少领域标签、标签不准确或标签未规范化数据的挑战，并且基于数据选择的方法通常难以平衡多领域性能。
### Innovation
本文创新地通过实证构建对比数据池和理论解释，揭示了数据多样性的作用。提出了一种新方法，赋予LLM双重身份：一个是输出模型用于认知性地探查和根据多样性奖励选择数据，另一个是输入模型通过选择的数据进行调整。实验证明，这种方法在多种先进LLMs上应用时，显著提升了领域未确定数据和一系列基础下游任务的性能。
### Conclusion
通过实验证明，新方法在对领域未确定数据及一系列基本下游任务应用到多种先进LLMs时，展现出显著的性能提升。作者已经公开了代码，希望这可以为了解数据多样性和推进反馈驱动的数据-模型联合设计提供新的视角。
## 186. `cs.AI` - 基于神经网络的可学习和可扩展指令微调数据影响估计 [PDF](https://arxiv.org/pdf/2502.09969), [HTML](https://arxiv.org/abs/2502.09969)
### Authors
Ishika Agarwal,Dilek Hakkani-Tür
### Background
现有的影响函数方法虽然提供了对模型训练时机密性的关键见解，但存在计算成本高和泛化能力有限的问题。尤其是近期的研究提出了多种利用语言模型计算数据影响的方法，但这些方法不能很好地扩展到大型模型和数据集。原因在于计算过程需要昂贵的前向和反向传递，需要大量的内存来存储大型模型，并且对新数据的影响估算效果较差。
### Innovation
本论文探索使用小型神经网络（称为InfluenceNetwork）来估算影响值，能够将计算成本降低99%。所提出的算法（称为NN-CIFT）使用的小型模型仅占完整语言模型的0.0027%。通过应用NN-CIFT算法到指令微调的子集选择任务，显示出在大幅加速的条件下，性能与传统的基于影响函数方法相当。
### Conclusion
我们深入分析了NN-CIFT的超参数，并在代码仓库中提供了我们的方法代码。实验表明，虽然NN-CIFT在计算和泛化性能上有所改进，但在下游任务中与最先进的影响函数方法相比，其性能并无明显下降。
## 187. `cs.AI` - 在生成式人工智能时代的数据讲故事工具反思：从人机协作视角出发 [PDF](https://arxiv.org/pdf/2503.02631), [HTML](https://arxiv.org/abs/2503.02631)
### Authors
Haotian Li,Yun Wang,Huamin Qu
### Background
人机协作工具引起了数据讲故事社区的关注，以降低专业门槛并简化工作流程。近年来，大规模生成式人工智能技术，如大型语言模型（LLMs）和文本转图片模型，具有强大的视觉和叙述生成能力，有可能提高数据讲故事的质量。自这些技术公开以来已经过去了两年，反思其应用进展并展望未来的机会非常重要。
### Innovation
本文通过一个专门的人机协作框架对比了最新工具与早期工具的协作模式。识别了广泛研究的模式，如人类创作者+人工智能助手，并探讨了新兴模式，如人工智能创作者+人类审查者。揭示了这些人工智能技术的好处及其对人机协作的影响，并提出了未来的研究方向。
### Conclusion
通过比较，本文指出了广泛研究和新兴的人机协作模式，并提出了未来的研究方向，以激发创新。
## 188. `cs.AI` - Vital Insight: 使用可视化和人类在环中的LLM协助专家多模态个人追踪数据的上下文驱动感知 [PDF](https://arxiv.org/pdf/2410.14879), [HTML](https://arxiv.org/abs/2410.14879)
### Authors
Jiachen Li,Xiwen Li,Justin Steinberg,Akshat Choube,Bingsheng Yao,Xuhai Xu,Dakuo Wang,Elizabeth Mynatt,Varun Mishra
### Background
传统的被动追踪方法，如手机和穿戴设备感应，已成为现代泛在计算研究中监测人类行为的主要手段。虽然在将原始传感器数据转换为模型中的即时行为（例如，身体活动识别）方面取得了重大进展，但在将这些传感流转换为有意义的高层次、上下文感知的洞察方面仍然存在显著差距。这些洞察对于各种应用（例如，总结个人每日活动）是必要的。研究者通常需要通过上下文驱动的解释过程来获得这些洞察，这通常需要大量的手工努力，即使是经验丰富的研究者也可能会遇到挑战。因此，本文通过三轮面向21名专家的研究，探索了解决感知问题的方法。
### Innovation
本文提出了Vital Insight (VI)，这是一种基于人工智能辅助的原型系统，它使研究人员可以在多模式移动感知数据中进行人类参与的推理和可视化分析。该系统采用用户中心设计方法，帮助专家更好地理解并解释多模态个人追踪数据。通过观察专家与原型的互动，作者开发了一个专家感知模型，解释了专家如何在直接数据表示与AI支持的推理之间切换，以探索、质疑和验证见解。此外，本文还综合并讨论了一些建议，用以指导未来增强型可视化系统的设计，更好地辅助多模态健康感知数据中的专家感知过程。
### Conclusion
本文通过结合可视化技术和人类在环的人工智能辅助，提供了一种新的方法来增强专家在多模态个人追踪数据中的感知过程。通过三个用户的实验，作者展示了Vital Insight系统在帮助专家从多模态数据中提取有意义的洞察方面的有效性，并提出了未来设计建议，以进一步提高专家利用多模态健康感知数据进行推理的能力。
## 189. `cs.AI` - UV-Attack：基于动态NeRF的UV映射的物理世界人员检测对抗攻击 [PDF](https://arxiv.org/pdf/2501.05783), [HTML](https://arxiv.org/abs/2501.05783)
### Authors
Yanjie Li,Kaisheng Liang,Bin Xiao
### Background
近年来，针对使用补丁或静态3D模型纹理修改的人体检测器的对抗攻击成功率较低，因为人体的动态特性使得3D变形建模面临巨大挑战。尽管动态NeRF模型能够建模人体，但对服装纹理的修改非常困难。本文通过动态NeRF基UV映射技术，提出了一种称为UV-Attack的新方法，能够在广泛且前所未见的人体动作下取得高成功率，从而克服了这些挑战。
### Innovation
UV-Attack采用了一种新颖的方法，不直接生成RGB图像而是生成UV映射，并修改纹理堆栈，从而使攻击在实时性方面更具可行性。此外，还提出了一种新的假设姿势变换损失（EoPT）损失函数，以提高看不见的姿态和视图的防御逃脱率。该方法在动态视频设置下对FastRCNN模型的成功攻击率为92.7%，明显优于最先进的AdvCamou攻击（ASR为28.5%），在黑盒设置下对YOLOv8检测器的成功攻击率为49.5%。研究表明，动态NeRF基UV映射具有更高的潜力来创建更有效的对抗攻击，解决了人体运动建模和纹理修改的关键挑战。
### Conclusion
本文提出了UV-Attack，一种基于动态NeRF的UV映射的对抗攻击方法，该方法通过生成UV映射而非直接生成RGB图像来实现攻击，同时提高对看不见的姿态和视图的防御逃脱成功率。UV-Attack在实验中展示了92.7%的高成功攻击率，显著优于现有的最先进的攻击方法，为更加有效的对抗攻击提供了新的思路，并为动态NeRF技术的实际应用开辟了新的领域。
## 190. `cs.AI` - 语言模型可以在状态价值估计方面自我改进以进行更好的搜索 [PDF](https://arxiv.org/pdf/2503.02878), [HTML](https://arxiv.org/abs/2503.02878)
### Authors
Ethan Mendes,Alan Ritter
### Background
为多步推理任务收集真实的奖励或人类演示通常在交互式领域（如网页任务）中是代价高昂的。因此，开发一种不需要人工标注数据的情况下改进语言模型状态价值函数的方法对于降低搜索算法成本并提高性能至关重要。
### Innovation
引入了Self-Taught Lookahead (STL)框架，这是一种奖励无关的方法，通过显式地涉及状态迁移来改进基于语言模型的价值函数。STL通过语言模拟一步前瞻过程训练价值语言模型，包括预测下一个动作、结果状态及其价值理由，从而通过自我监督程序改进状态价值预测，最终使轻量级搜索算法在减少搜索状态数量的同时保持良好的性能。
### Conclusion
STL训练的基于中等规模（8B参数）开放式预训练语言模型的web代理成功率提高了39%，达到与专有模型相当的表现。STL还适用于多步骤问答和数学谜题。研究发现，STL使小型开源模型能够引导高效搜索，通过整合显式推理和价值学习来降低成本。
## 191. `cs.AI` - 更多同一种类：在增加代表性下的持续表征伤害 [PDF](https://arxiv.org/pdf/2503.00333), [HTML](https://arxiv.org/abs/2503.00333)
### Authors
Jennifer Mickel,Maria De-Arteaga,Leqi Liu,Kevin Tian
### Background
为了识别和减轻生成AI系统的危害，必须考虑在生成AI系统的输出中谁被代表以及人们是如何被代表的。直接改善谁被代表并不意味着已经应用了减轻偏向的努力来解决人们如何被代表的问题，这会导致重要的差距。本文通过研究最先进的大型语言模型中职业领域的性别代表情况，发现性别分布随着时间有所改变，女性的代表比男性多。但性别代表的偏差依然持续存在，不同的性别在其代表方式上存在显著的词汇差异，这导致了表征伤害、刻板印象和新自由主义观念的广泛传播，尽管已经采取了增加女性代表的干预措施，但仍强化了现有的压迫性体系。
### Innovation
本文通过分析最先进的大型语言模型中职业领域的性别代表情况，展示了即使在增加女性代表的情况下，代表性的偏差依然存在。文章发现了在不同性别之间存在的显著词汇差异，并强调了尽管采取了增加女性代表的干预措施，但性别代表的偏差仍然导致了表征伤害、刻板印象和新自由主义观念的广泛传播，这是对该问题的新见解。
### Conclusion
尽管已经采取了增加女性代表的干预措施，但性别代表的偏差仍然导致了表征伤害、刻板印象和新自由主义观念的广泛传播，这强化了现有的压迫性体系。因此，需要进一步关注如何有效减轻bias问题，不仅仅是增加代表，还需要从根本上改变和改善对不同性别如何被代表的方式。
## 192. `cs.AI` - 指导性模型合并：利用集中化数据细化去中心化模型 [PDF](https://arxiv.org/pdf/2503.20138), [HTML](https://arxiv.org/abs/2503.20138)
### Authors
Junyi Zhu,Ruicong Yao,Taha Ceritli,Savas Ozkan,Matthew B. Blaschko,Eunchung Noh,Jeongwon Min,Cho Jung Min,Mete Ozay
### Background
当前的网络训练范式主要集中在中央化或去中心化数据模式上，但在实际应用中，数据可用性通常表现出混合性质，其中两种模式并存。这两种模式各有优势和限制：去中心化数据虽然普遍但具有异质性和通信限制等缺点，而中央化数据尽管数量有限且可能不具代表性，但可以更好地进行管理并实现高吞吐量访问。然而，有效结合这两种模式仍然具有挑战性，因此很少有框架专门针对混合数据模式进行优化设计。
### Innovation
本文提出了一种新型框架，该框架从去中心化模型中构建模型地图，并利用中央化数据在该结构化空间中精炼全局模型。精炼后的模型再用于重新初始化去中心化模型。该方法结合了联邦学习（利用去中心化数据）和模型合并（利用中央化数据），在混合数据可用性条件下实现了有效的训练。理论分析表明，与仅依赖去中心化数据的方法相比，该方法在合并过程中通过减少方差实现了更快的收敛速度。实验结果表明，该框架在总体上优于纯粹中央化、纯粹去中心化以及现有的混合适应性方法，并且在中央化和去中心化数据差异明显或去中心化数据包含噪声的情况下仍然具有鲁棒性，显著拓宽了其适用范围。
### Conclusion
我们的方法展示了在混合数据条件下有效进行模型训练的能力，并通过理论和实验验证了其优势，特别适用于数据可用性具有挑战性的场景。
## 193. `cs.AI` - MindGYM：面向认知中心微调的问题合成有哪些关键因素？ [PDF](https://arxiv.org/pdf/2503.09499), [HTML](https://arxiv.org/abs/2503.09499)
### Authors
Zhe Xu,Daoyuan Chen,Zhenqing Ling,Yaliang Li,Ying Shen
### Background
大型基础模型在通过严格的模板或众包标注指令数据集进行监督时，面临着获得可迁移且结构化的思考能力的挑战。与早期方法不同，本文关注一种以思考为中心的数据合成范式，通过模型自身生成和认知指导的数据使其进化。背景强调，有效面向思考的微调需要高质量且自给自足的数据，并且需要减少对人力干预和资源的需求。
### Innovation
本文提出了MindGYM，这是一种结构化且可扩展的问题合成框架，包括：(1) 认知思维过程注入，注入高层次的推理目标来塑造模型的合成行为；(2) 种子单跳问题合成，生成多样化的基础问题以促进更广泛的思考；(3) 具挑战性的多跳QA合成，基于问答种子构建更为复杂的多跳问题以促进更深入的推理。这种方法生成的合成数据平均质量提高了16.7%，质量方差降低了67.91%，展示了高质量和自给自足的数据对有效且面向思考的微调的至关重要性。
### Conclusion
MindGYM 在六个理解能力基准测试中均表现出色，仅使用400个数据样本就在MathVision上实现了高达16%的性能提升，并且在不同的模型大小和架构下也展现了可推广的改进。MindGYM 强调了自我挑战机制在提高大型模型能力方面的可行性和有效性，同时减少了人为干预和资源需求。同时发布代码和数据以促进以数据为中心的研究，推进由内部推理能力驱动的自我进化的基础模型研究。
## 194. `cs.AI` - M-Prometheus: 一套开源多语言LLM评判系统 [PDF](https://arxiv.org/pdf/2504.04953), [HTML](https://arxiv.org/abs/2504.04953)
### Authors
José Pombal,Dongkeun Yoon,Patrick Fernandes,Ian Wu,Seungone Kim,Ricardo Rei,Graham Neubig,André F. T. Martins
### Background
目前，使用语言模型自动评估长文本（LLM-as-a-judge）的应用越来越普遍，但大多数LLM评判系统仅针对英语进行了优化，对于提高其多语言评估能力的策略研究较少，这导致非英语语言的自动评估方法质量参差不齐，阻碍了具有更好多语言能力模型的发展。
### Innovation
本文引入了M-Prometheus，这是一种从3B到14B参数的开源多语言LLM评判系统，能够提供直接评估和成对比较反馈，适用于多语言输出。M-Prometheus模型在超过20种语言的多语言奖励基准测试中优于最先进的开源LLM评判系统，在涵盖4种语言对的文学机器翻译评估中也表现出色。此外，M-Prometheus可以在解码时使用，显著提高所有3种测试语言生成输出的质量，展示了其在开发更好多语言模型中的应用价值。通过广泛的拆分测试，发现了有效多语言评判的关键因素，包括选择基础模型和使用合成多语言反馈数据进行训练。
### Conclusion
M-Prometheus模型在多语言评估任务上表现出色，不仅能够提供直接评估和成对比较反馈，还能够在解码时提高生成输出的质量，具有显著的实用价值。未来的多语言模型开发可以通过使用M-Prometheus来增强其多语言能力。
## 195. `cs.AI` - 零射击基准测试：一种灵活和可扩展的语言模型自动评估框架 [PDF](https://arxiv.org/pdf/2504.01001), [HTML](https://arxiv.org/abs/2504.01001)
### Authors
José Pombal,Nuno M. Guerreiro,Ricardo Rei,André F. T. Martins
### Background
随着语言模型变得越来越强并能够执行更多跨模态的复杂任务，自动评估它们的难度增加。现有的强大且鲁棒的任务特定自动指标变得越来越难以开发，而昂贵且快速饱和的人工标注测试集无法解决问题。一种有吸引力的替代方案是设计可靠的策略来自动化测试数据的创建和评估，但之前的尝试要么依赖于现有的数据，要么专注于单一任务。因此，本文提出了零射击基准测试（ZSB），一种利用语言模型进行合成数据和评估的框架，以创建高质量的基准测试。ZSB简单灵活，通过提示来生成数据和评估，适用于数据采集成本高或不切实际的情况，支持语言模型的无特定依赖性，随着模型的进步能够创建更具挑战性的基准测试。
### Innovation
提出了一种新的框架，即Zero-shot Benchmarking（零射击基准测试），该框架利用语言模型进行合成测试数据的生成和评估，解决了传统手动测试集的局限性。ZSB以其简单性和灵活性，无需依赖现有数据和专注于单一任务，能够创建高质量的基准测试，特别适用于资源有限或数据采集困难的场景。此外，研究发现使用开放模型可以创建强大的基准测试，并指出裁决模型大小和数据集多样性是性能的关键驱动因素。
### Conclusion
本文通过创建五个文本任务和一个跨模态任务的基准测试评估了ZSB框架的有效性，ZSB排名与人类排名高度相关，获胜者与广泛采用的标准基准表现良好。通过对不同开放系统的排名，ZSB展示了其在评估语言模型自动评估的有效性和准确性。所有基准测试和实验代码均已公开，以提高研究透明度和可复现性。
## 196. `cs.AI` - 面向公开和安全生成人工智能：开源与闭源LLM的比较分析 [PDF](https://arxiv.org/pdf/2505.10603), [HTML](https://arxiv.org/abs/2505.10603)
### Authors
Jorge Machado
### Background
生成人工智能（Gen AI）系统是影响社会多个领域的关键技术，但在其部署过程中存在一系列风险和挑战。目前缺乏全面且跨学科的研究来系统比较开源和专有（封闭）生成AI系统的优缺点。
### Innovation
本研究采用综合方法（包括文献回顾、批判分析和比较分析）比较和评估开源和封闭生成AI模型的特点、机会与挑战，并提出一个开源、公共管理和安全生成人工智能框架的基础架构。
### Conclusion
研究发现开源模型提供了更高的透明度、审计性和灵活性，有利于独立审查和偏见缓解。而封闭系统通常提供了更好的技术支持和实施便利性，但代价是不平等的访问、问责制和伦理监督。研究还强调多利益相关者治理、环境可持续性和监管框架在确保负责任发展中的重要性。
## 197. `cs.AI` - 使用视频语言模型赋能主动视频分析系统 [PDF](https://arxiv.org/pdf/2505.00254), [HTML](https://arxiv.org/abs/2505.00254)
### Authors
Yuxuan Yan,Shiqi Jiang,Ting Cao,Yifan Yang,Qianqian Yang,Yuanchao Shu,Yuqing Yang,Lili Qiu
### Background
AI驱动的视频分析在多个领域变得越来越重要。然而，现有的系统往往局限于特定的预定义任务，限制了它们在开放分析场景中的适应性。最近，视觉语言模型（VLMs）的出现提供了通过开放的视频理解、推理解析和分析的机会，但这在处理超长视频内容时面临挑战。超长视频在实际应用中普遍存在。为了解决这一问题，我们引入了AVA，一个使用VLM赋能的系统，设计用于开放的高级视频分析。AVA结合了两个关键创新：（1）事件知识图谱（EKGs）的近实时构建，用于有效索引长或连续的视频流，（2）一个代理式检索-生成机制，使用EKGs处理复杂和多样的查询。
### Innovation
AVA系统的主要创新包括：（1）近实时构建事件知识图谱（EKGs），用于高效索引长或连续的视频流；（2）代理式检索-生成机制，利用EKGs处理复杂和多样的查询。
### Conclusion
AVAviaVLM和视频检索增强生成（RAG）系统显着超过现有系统。在公共基准LVBench和VideoMME-Long上的综合评估中，AVA分别实现62.3%和64.1%的准确率，并引入了一个新的基准AVA-100，并通过该基准展示了AVA在极端和开放世界的视频分析场景中的顶级性能，准确率为75.8%。
## 198. `cs.AI` - Curriculum Abductive Learning [PDF](https://arxiv.org/pdf/2505.12275), [HTML](https://arxiv.org/abs/2505.12275)
### Authors
Wen-Chao Hu,Qi-Jie Li,Lin-Han Jia,Cunjing Ge,Yu-Feng Li,Yuan Jiang,Zhi-Hua Zhou
### Background
ABDuctive Learning (ABL) 结合了机器学习与逻辑推理，在循环中进行：一个学习模型从原始输入中预测象征性概念标签，然后通过运用领域知识的 abduction 对这些标签进行修订并回馈用于重新训练。然而，由于 abduction 的不确定性，训练过程常常不稳定，尤其是在知识库庞大且复杂时，导致 abduction 空间的大大增加，成为制约因素。此前的研究主要集中在改进这个空间中的候选选择，但通常将知识库视为静态的黑盒处理。因此，AL 在大规模复杂知识设置下难以实现.
### Innovation
本文提出了一种 Curriculum Abductive Learning (C-ABL) 方法，明确利用知识库的内部结构来解决 ABL 训练挑战。C-ABL 将知识库划分为一系列子集，在训练过程中逐步引入。这在整个训练过程中缩小了 abduction 空间，并允许模型以逐步、平滑的方式纳入逻辑。实验结果表明，C-ABL 在多个任务中表现优于之前的 ABL 实现，显著提高了训练稳定性、收敛速度和最终准确性，特别是在复杂知识设置下效果更佳.
### Conclusion
本文提出了一种 Curriculum Abductive Learning (C-ABL) 方法，通过逐步引入知识库中的子集，有效缩小 abduction 空间，提高了 ABL 的训练稳定性和准确性。实验验证了该方法在复杂知识环境下的有效性。
## 199. `cs.AI` - 学习插入以构建神经车辆路由解算器 [PDF](https://arxiv.org/pdf/2505.13904), [HTML](https://arxiv.org/abs/2505.13904)
### Authors
Fu Luo,Xi Lin,Mengyuan Zhong,Fei Liu,Zhenkun Wang,Jianyong Sun,Qingfu Zhang
### Background
基于学习的神经组合优化（NCO）方法是解决车辆路由问题（VRP）的一种有前途的方法，但它仍需要大量的手动设计。现有的基于构建的NCO方法通常遵循顺序添加未访问节点到部分解决方案的模式，这会导致结果的不优化。因此，通过探索插入式范式，提出了一种新的基于学习的方法——L2C-Insert，以提高灵活性和解决方案质量。
### Innovation
L2C-Insert 方法通过在当前部分解决方案中的任何有效位置插入未访问的节点来构建解决方案，而传统方法通常会顺序添加节点。L2C-Insert 框架引入了三种关键组件：一种新颖的模型架构用于精确预测插入位置，用于模型优化的高效训练方案，以及全面利用插入范式灵活性的高级推理技术。实验表明，L2C-Insert 在各种问题规模上都能实现更优越的性能。
### Conclusion
在合成和实际实例的旅行商问题（TSP）和有载车辆路由问题（CVRP）中进行的广泛实验表明，L2C-Insert 方法在多种问题规模上都能取得更优越的性能。
## 200. `cs.AI` - 在暗中搜寻：基于隐空间测试时实例级策略梯度的推理 [PDF](https://arxiv.org/pdf/2505.13308), [HTML](https://arxiv.org/abs/2505.13308)
### Authors
Hengli Li,Chenxi Li,Tong Wu,Xuekai Zhu,Yuxuan Wang,Zhaoxin Yu,Eric Hanchen Jiang,Song-Chun Zhu,Zixia Jia,Ying Nian Wu,Zilong Zheng
### Background
大型语言模型（LLMs）在追求通用人工智能（AGI）过程中，推理能力仍是一个显著挑战。尽管基于训练缩放定律模型性能有所提升，但训练算法如灾难性遗忘问题依然存在，同时获取新颖训练数据也受限。为解决这些问题，研究者提出测试时缩放方法，通过增加测试时的计算而不更新参数来提高推理性能。然而，过去的方法主要集中在词汇空间，本研究则创新地提出利用隐空间，在模型的隐空间内进行测试时实例级自适应（TTIA），从而提升LLM的推理能力。研究通过使用策略梯度逐步更新隐表示，由自生成的奖励信号引导。该框架在多种推理基准上进行评估，展示了其在效率和性能上的优越性。同时，结果表明测试时在隐空间中的缩放具有巨大的潜力。
### Innovation
提出了一种名为LatentSeek的新框架，在模型的隐空间内通过测试时实例级适应（TTIA）来增强大型语言模型的推理能力。LatentSeek利用策略梯度迭代更新隐表示，由自生成的奖励信号指导。这一方法不同于以往主要集中在词汇空间的研究，能够在无需更新参数的情况下，显著提升模型在推理任务上的表现。
### Conclusion
LatentSeek 在多个推理基准上展示了其优越的性能，尤其是在效率上通常在几次迭代后即可收敛，并且在复杂问题上也能够从中获益。因此，该研究提出了一种轻量、可扩展且有效的解决方案，用于提升大型语言模型的推理能力。
## 201. `cs.AI` - Ditch the Denoiser: Emergence of Noise Robustness in Self-Supervised Learning from Data Curriculum [PDF](https://arxiv.org/pdf/2505.12191), [HTML](https://arxiv.org/abs/2505.12191)
### Authors
Wenquan Lu,Jiaqi Zhang,Hugues Van Assel,Randall Balestriero
### Background
自监督学习（SSL）已成为从未标记数据中提取丰富表示的强大解决方案。然而，SSL 研究主要关注干净、经过整理和高质量的数据集。因此，在噪声数据上应用 SSL 仍然是一个挑战，尽管它对于天文学、医学影像、地球物理或金融等领域的应用至关重要。数据中的噪音会影响 SSL 模型的性能，尤其是在图像质量较差或存在较大噪音的场景中。本文旨在解决这一问题，提出一种无需再依赖去噪器的自监督框架，能够在噪声数据上实现鲁棒的表示学习，简化部署并提高模型在噪声环境中的表现能力。
### Innovation
本文创新点在于提出了一种无需去噪器的自监督学习框架。该方法首先在噪声数据上训练一个自监督去噪器，然后利用该去噪器构建一个去噪到噪声的数据课程（即，首先使用去噪数据，然后使用噪声数据进行训练）来预训练自监督学习的骨干网络（例如，DINOv2），并通过教师指导正则化进一步将无噪声的特征向量与对应的有噪声特征向量对齐。通过这种方式，模型能够内化噪声鲁棒性。特别的是，去噪器可以在预训练完成后被丢弃，简化了部署过程。实验结果表明，本文方法在极端高斯噪声条件下（$text{SNR}=0.72 text{ dB}，text{噪声强度因子}=text{255}$）的 ImageNet-1k 上通过 ViT-B 实现线性探针准确率提高了4.8%，超过了 DINOv2，证明了自监督去噪预训练能够产生去噪器无的鲁棒性。
### Conclusion
本文提出了一种无需去噪器的自监督学习框架，该方法通过构建去噪到噪声的数据课程，利用与噪声相关的无噪声特征向量对齐来预训练自监督模型，使得模型能够内化噪声鲁棒性。实验结果证明，本文方法在噪声数据上的性能优于传统方法，使得在噪声环境中的应用成为可能，同时简化了模型的部署。
## 202. `cs.AI` - 让LRMs通过自我制动调整从过度思考中解脱出来 [PDF](https://arxiv.org/pdf/2505.14604), [HTML](https://arxiv.org/abs/2505.14604)
### Authors
Haoran Zhao,Yuchen Yan,Yongliang Shen,Haolei Xu,Wenqi Zhang,Kaitao Song,Jian Shao,Weiming Lu,Jun Xiao,Yueting Zhuang
### Background
大型推理模型（LRMs）如OpenAI o1和DeepSeek-R1，通过生成更长的推理链，显著增强了推理能力，但在提升性能的同时，也增加了生成过程中的冗余推理，导致计算开销增加并加剧了过度思考的问题。尽管现有的许多方法试图解决过度思考的问题，但这些方法通常依赖于外部干预措施。
### Innovation
提出了一个名为Self-Braking Tuning (SBT)的新框架，旨在让模型能够自我调节推理过程，从而减少对外部控制机制的依赖。该方法构建了一系列基于标准答案的过度思考识别指标，设计了一套系统的方法来检测冗余推理，并准确识别推理轨迹中的不必要的步骤，生成学习自我调节行为的训练信号。基于此，开发了一种构造具有可适应推理长度的数据的完整策略，并引入了一种新的制动提示机制，使模型能够自然地学会在适当的时机终止推理。
### Conclusion
在数学基准测试（AIME，AMC，MATH500，GSM8K）上进行的实验表明，该方法将词元消耗降低了高达60%，同时保持与未约束模型相当的准确性。
## 203. `cs.AI` - Pass@K 政策优化：解决更难的强化学习问题 [PDF](https://arxiv.org/pdf/2505.15201), [HTML](https://arxiv.org/abs/2505.15201)
### Authors
Christian Walder,Deep Karkhanis
### Background
传统强化学习算法通过独立评估每次问题求解的多次尝试来优化 pass@1 表现，并优先考虑单个样本的强度，而不是样本集合的多样性及其集体贡献。这种方法未能充分利用样本求解的多样性，限制了探索和解决更复杂问题的能力。
### Innovation
提出了 Pass-at-k Policy Optimization (PKPO)，这是一种修正最终奖励的方法，旨在直接优化 pass@k 表现，即优化集合样本，使其在联合考虑时获得最大奖励。本文的主要贡献在于为 pass@k 和其梯度推导出新颖的低方差无偏估计量，无论是二元还是连续奖励环境都是如此。我们的方法允许在训练过程中逐渐增加 k 的值，同时优化 pass@1 和 pass@k 指标。
### Conclusion
我们的方法通过优先考虑集合相似性而非单个样本的独有贡献，可以有效解决更广泛的问题，特别是对于传统 pass@1 优化趋于停滞的挑战性任务集。实验证明，pass@k 利用有效解决了更困难的任务，通过加强探索，提高了 pass@1 和 pass@k 的双重性能。
## 204. `cs.AI` - 学习交互视频生成的世界模型 [PDF](https://arxiv.org/pdf/2505.21996), [HTML](https://arxiv.org/abs/2505.21996)
### Authors
Taiye Chen,Xun Hu,Zihan Ding,Chi Jin
### Background
有效的基于行动选择的未来规划需要世界模型同时具备互动性和保持空间与时间的一致性。现有的长期视频生成模型由于累积误差和记忆机制不足的主要挑战，其内在的世界建模能力有限。
### Innovation
该论文通过增强图像到视频模型的互动能力，加入了行动条件和自回归框架，揭示了自回归视频生成中累积误差无法消除的问题，并指出缺乏记忆机制导致了世界模型的不一致。提出了视频检索增强生成（VRAG）方法，通过显式全局状态条件显著减少了长期累积误差并提高了世界模型的空间时间一致性。
### Conclusion
相比于单纯的自回归生成和检索增强生成，当前视频模型的学习能力有限，证明了内在世界建模能力对视频生成的重要性。这项工作揭示了视频世界建模的基本挑战，并建立了改进具有内建世界建模能力的视频生成模型的综合基准。
## 205. `cs.AI` - Nek Minit: 动用语境元认知提示进行澳大利亚和印度英语的可解释讽刺检测 [PDF](https://arxiv.org/pdf/2505.15095), [HTML](https://arxiv.org/abs/2505.15095)
### Authors
Ishmanbir Singh,Dipankar Srirag,Aditya Joshi
### Background
讽刺是情感分析中的一个挑战，因为它涉及表面情感和潜藏情感之间的不一致性。当潜藏情感可能与特定国家或地理区域相关时，这一挑战进一步加剧。传统的讽刺检测技术在处理这种不一致性时表现不佳，特别是在多种英语方言上，如澳大利亚英语和印度英语，它们各自具有的独特的文化和社会背景。为了提高情感分析的准确性和透明度，研究人员开发了各种提示策略，这些策略可以增强机器学习模型在处理讽刺时的理解能力。
### Innovation
本文提出了一种新的方法——语境元认知提示（PMP），这是一种受认知启发的技术，专门用于进行具有解释性的讽刺检测。PMP被用来为澳大利亚英语和印度英语生成讽刺解释，同时对比了该方法与针对标准英语的基准数据集（如FLUTE，其中包含讽刺解释）的性能。研究表明，利用PMP进行讽刺解释在两种开源的大语言模型（GEMMA和LLAMA）上的评估中，其表现显著优于其他四种替代提示策略。此外，其他技术如行动式提示也表现出通过检索外部知识减轻上下文相关失败的能力。
### Conclusion
本文的方法利用PMP在多种英语方言中生成讽刺解释，并通过比较不同提示策略在两个开源大语言模型上的表现，证明了PMP的有效性。研究表明，PMP可以显著改善讽刺检测的性能，同时也展示了其他增强上下文理解的技术（如行动式提示）的潜力。
## 206. `cs.AI` - Paper2Poster: 从科学论文向多模态海报的自动化 [PDF](https://arxiv.org/pdf/2505.21497), [HTML](https://arxiv.org/abs/2505.21497)
### Authors
Wei Pang,Kevin Qinghong Lin,Xiangru Jian,Xi He,Philip Torr
### Background
科学交流中的学术海报生成是一项关键但具有挑战性的任务，需要将长文档中的上下文信息压缩到一张具有视觉流畅性的单页中。现有的海报生成方法往往无法同时满足视觉质量、文本连贯性和总体美观等多方面需求。
### Innovation
本研究首次引入了针对海报生成的基准和度量套件，涵盖了论文与作者设计的海报之间的语义一致性、文本连贯性以及细粒度美学和信息标准的整体评估。研究中还提出了一种自上而下的多代理可视化流程——Parser（解析），Planner（规划），以及Painter-Commenter（绘制-评论）循环，通过计算生成代码和使用大模型反馈来优化海报制作。此外，研究还通过GPT-4o与自开源方案的对比，证明了自开源方案在几乎所有评估指标上均优于现有的多代理系统，并有效减少了生成效率。
### Conclusion
研究表明，虽然传统的多代理系统能够生成美观的海报，但在传达核心论文内容方面存在不足。通过提出的自开源方案，可以在保持更具吸引力的视觉效果的同时，大幅提升海报的质量。未来的研究方向集中在全自动海报生成模型的设计上，优化生成效率与效果。相关代码和数据集可在特定链接处获得。
## 207. `cs.AI` - StyleGuard: 通过样式扰动防止基于文本到图像模型的样式模仿攻击 [PDF](https://arxiv.org/pdf/2505.18766), [HTML](https://arxiv.org/abs/2505.18766)
### Authors
Yanjie Li,Wenxuan Zhang,Xinqi Lyu,Yihao Liu,Bin Xiao
### Background
近年来，通过DreamBooth和Textual Inversion等方法，基于文本到图像的扩散模型在风格模仿和个性化定制方面广泛应用。这引发了关于知识产权保护和生成误导性内容的担忧。研究发现，使用对抗噪声可以保护图像免受攻击，但最近的净化方法如DiffPure和Noise Upscaling能够有效攻破这些防护，揭示了这些防护方法的脆弱性。此外，现有方法在模型之间的转移性有限，使得它们在面对未知的文本到图像模型时效果不佳。这些情况促使研究者提出一种新的对抗模仿方法——StyleGuard。
### Innovation
StyleGuard提出了一个新的风格损失，优化隐空间中的风格相关特征，使其偏离原始图像，提高了模型无关的转移性。此外，为了增强扰动绕过基于扩散的净化的能力，设计了一种新的放大损失，训练期间涉及集合净化器和放大器。在WikiArt和CelebA数据集上的实验表明，StyleGuard在各种变换和净化下表现出更强的鲁棒性，有效地对抗了各种模型中的风格模仿。StyleGuard对包括DreamBooth和Textual Inversion在内的不同风格模仿方法也有效。
### Conclusion
实验结果表明，StyleGuard在面对各种转换和净化时表现出了更强的鲁棒性，有效地对抗了不同模型中的风格模仿。此外，StyleGuard适用于包括DreamBooth和Textual Inversion在内的多种风格模仿方法。
## 208. `cs.AI` - 向量预测任何人类轨迹 [PDF](https://arxiv.org/pdf/2506.00871), [HTML](https://arxiv.org/abs/2506.00871)
### Authors
Ryo Fujii,Hideo Saito,Ryo Hachiuma
### Background
准确预测行人未来轨迹对于自动驾驶系统至关重要，但目前仍是一项具有挑战性的任务，因为需要在不同环境中和领域进行适应。常用的方法是收集特定场景的数据并通过反向传播进行微调。然而，对于每个新场景都需要进行微调，这对于边缘设备的实际部署来说通常是不切实际的。
### Innovation
本文介绍了一个基于In-Context Learning (ICL)框架的行人轨迹预测模型TrajICL，该框架在推理阶段可以在不进行场景特定数据的微调和权重更新的情况下实现适应。该模型采用了时空相似性基于的选择（STES）方法，从相同场景下观察的轨迹中选择具有相似运动模式的示例。为了进一步优化，模型引入了基于预测未来轨迹的示例选择（PG-ES），考虑了未来预测轨迹，增强了长期动态的考虑。此外，模型通过使用大规模的合成数据集进行训练，而不是依赖于有限多样性的现实世界数据集，提升了预测能力。
### Conclusion
广泛的实验表明，TrajICL在同域和跨域场景中都实现了显著的适应性，即使在微调模型尚未达标的公共基准测试中也表现更优。
## 209. `cs.AI` - 基于回归的规范流高效训练方法在玻尔兹曼生成器中的应用 [PDF](https://arxiv.org/pdf/2506.01158), [HTML](https://arxiv.org/abs/2506.01158)
### Authors
Danyal Rehman,Oscar Davis,Jiarui Lu,Jian Tang,Michael Bronstein,Yoshua Bengio,Alexander Tong,Avishek Joey Bose
### Background
生成模型在连续空间中的模拟自由训练框架处于生成建模革命的前沿，导致了大规模的扩散模型和流动匹配模型的广泛应用。然而，这些现代生成模型在推断上的成本很高，限制了它们在诸如需要快速似然评估的分子构象玻尔兹曼生成器（BGs）等科学应用中的使用。经典规范流动在玻尔兹曼生成器中的上下文中表现出高效抽样和似然性，但其通过最大似然估计的训练经常不稳定且计算繁重。
### Innovation
提出了一种基于回归的新型且可扩展的训练目标——回归训练规范流（RegFlow），通过使用 $boldsymbol{textbf{l}_2}$ 回归目标来替代传统最大似然训练中的数值不稳定性与计算难题。RegFlow 将先前样本转化为通过最优传输耦合或预训练连续规范流（CNF）计算的目标。引入了新的前向-后向自我一致性损失来增强数值稳定性，该损失具有简便实现的特点。
### Conclusion
实验证明，RegFlow 克服了最大似然训练在玻尔兹曼生成器中的训练难题，使得对于涉及分子系统的采样具有更广泛的架构可行。同时，RegFlow 在卡尔曼坐标系中展示了在二肽、三肽和四肽平衡采样的性能、计算成本和稳定性能超越最大似然训练，彰显了其在分子系统中的潜力。
## 210. `cs.AI` - 激励LLMs自我验证其答案 [PDF](https://arxiv.org/pdf/2506.01369), [HTML](https://arxiv.org/abs/2506.01369)
### Authors
Fuxiang Zhang,Jiacheng Xu,Chaojie Wang,Ce Cui,Yang Liu,Bo An
### Background
大型语言模型（LLMs）在复杂的推理任务中取得了显著进步，通常通过后训练和测试时扩展法则实现。常见的测试时扩展方法多依赖外部奖励模型来指导模型生成过程，但研究发现，在特定推理任务后训练的模型上进行扩展时，仅能获得微小的改进。这种有限的改进源自于特定后训练生成器和通用奖励模型之间的分布差异。
### Innovation
本文提出了一种框架，使LLMs能够自我验证其答案。通过在单一强化学习（RL）过程中统一答案生成与验证，训练出能够有效评估自身解决方案正确性的模型。该模型在推理时进一步通过验证其生成的输出而自身扩展性能，无需外部验证者。通过Qwen2.5-Math-7B和DeepSeek-R1-Distill-Qwen-1.5B进行训练，展示了在不同推理上下文长度上的能力。多项数学推理基准实验表明，我们的模型不仅可以提升后训练性能，还能实现有效测试时扩展。
### Conclusion
实验结果表明，通过这种方法，不仅可以提升后训练性能，还能实现更有效的测试时扩展。
## 211. `cs.AI` - GenIR: 为心理图像检索生成视觉反馈 [PDF](https://arxiv.org/pdf/2506.06220), [HTML](https://arxiv.org/abs/2506.06220)
### Authors
Diji Yang,Minghao Liu,Chung-Hsiang Lo,Yi Zhang,James Davis
### Background
视觉语言模型（VLMs）在文本到图像检索基准测试中表现出色，但在将其成功应用于实际应用中仍存在挑战。在实践中，人类的搜索行为通常不是一次完成的，而是多轮的过程，受到内心的线索引导，从模糊的记忆到明确的心理图像。现有方法依赖于间接或抽象的文字反馈，这可能导致反馈模糊、误导或无效。
### Innovation
本文提出了一种基于生成的多轮检索框架GenIR，通过扩散图像生成方法在多轮交互中显式地表达AI系统的理解，提供清晰、可解释的反馈给用户。此外，还介绍了全自动的多轮心理图像检索数据集生成流水线，该方法显著优于现有的交互式方法。
### Conclusion
通过GenIR，建立了新的心理图像检索任务、数据集和生成检索方法，为该领域未来的研究奠定了基础，表明了在心理图像检索中显式生成视觉反馈的有效性。
## 212. `cs.AI` - 通过动作偏好优化的人机辅助机器人策略精炼 [PDF](https://arxiv.org/pdf/2506.07127), [HTML](https://arxiv.org/abs/2506.07127)
### Authors
Wenke Xia,Yichu Yang,Hongtao Wu,Xiao Ma,Tao Kong,Di Hu
### Background
建立一个可靠并不断优化的机器人系统对于实际应用部署至关重要。视觉-语言-动作（VLA）模型因其广泛被认为是这种机器人部署的基础模型，但在部署后，这些模型只能依赖于离线专家演示，这对进一步优化造成了限制。现有方法直接利用交互轨迹进行偏好优化存在挑战，主要因为机器人动作不可逆以及标记信号不匹配的问题.
### Innovation
本文提出了动作偏好优化（APO）方法，通过人机合作框架收集交互轨迹，并通过人机干预实现可靠的行为纠正和交互轨迹收集。APO采用一个自适应重加权算法，通过二进制偏好信号解决动作不可逆和标记匹配问题，从而有效抑制失败行为并增强纠正性行为的适应性，使得VLA模型能够从失败中学习，实现迭代优化和可靠部署。实验结果表明，在模拟和真实场景中，该方法具有更好的泛化能力和鲁棒性，适用于多种操作任务.
### Conclusion
APO方法通过人机协作框架设计来提高VLA模型在动态环境中的适应性和可靠性。通过实验验证了该方法的有效性，在多种操作任务中展示了卓越的泛化能力和稳定性。这一工作为通过人机合作高效稳定优化VLA模型提供了新的思路。相关代码和数据集已公开。
## 213. `cs.AI` - UniSite：跨结构数据集和端到端配体结合位点检测学习框架 [PDF](https://arxiv.org/pdf/2506.03237), [HTML](https://arxiv.org/abs/2506.03237)
### Authors
Jigang Fan,Quanlin Wu,Shengjie Luo,Liwei Wang
### Background
配体结合位点的检测是结构基于药物设计中的关键步骤。然而，当前存在的方法、数据集和评估指标面临多个挑战：(1) 数据集和方法主要针对单个蛋白质-配体复合物，忽略了同一蛋白质不同复合物中可能存在的多种结合位点，引入了统计偏差；(2) 配体结合位点检测通常作为断续的工作流程进行建模，使用二元分割和后续聚类算法；(3) 传统评估指标未能充分反映不同结合位点预测方法的实际性能。
### Innovation
本文首先引入UniSite-DS，这是首个UniProt(唯一蛋白质)中心的数据集，含有4.81倍更多的多位点数据和2.08倍的整体数据，相比之前最广泛使用的数据集。接着提出了UniSite，这是首个基于集合预测损失和双射匹配的端到端配体结合位点检测框架。此外，引入了基于交并比率（IoU）的平均精度作为更准确的评估指标。实验证明，基于IoU的平均精度更准确地反映了预测质量，并且UniSite在配体结合位点检测中优于当前最佳方法。
### Conclusion
通过实验，证明了基于IoU的平均精度指标对于配体结合位点预测的评估更为准确，并且UniSite框架在配体结合位点检测性能上超过当前最先进的方法。结果表明，该方法显著提高了配体结合位点的检测精度。数据集和代码将公开发布。
## 214. `cs.AI` - SPARKE：通过RKE分数实现扩散模型中可扩展的提示感知多样性和新颖性指导 [PDF](https://arxiv.org/pdf/2506.10173), [HTML](https://arxiv.org/abs/2506.10173)
### Authors
Mohammad Jalali,Haoyu Lei,Amin Gohari,Farzan Farnia
### Background
扩散模型在高保真图像合成和提示引导的生成建模方面取得了显著的成功。然而，在提示引导的扩散模型中确保生成样本的充分多样性仍然具有挑战性，特别是当提示范围广泛且生成数据的多样性需要在语义相似的提示之间以提示感知的方式进行评估时。最近的研究引入了多样性度量引导的方法来促进更具多样性的生成。本文在基于多样性度量的方法基础上，提出了可扩展的提示感知Rényi核熵多样性引导方法（SPARKE）。
### Innovation
提出了SPARKE方法，这是一种基于条件熵的提示感知多样性引导方法，可动态以相似提示为条件进行多样性测量，并实现提示感知的多样性控制。通过针对条件隐空间Rényi核熵分数指导的特殊情形，将熵计算和基于梯度的优化复杂度从通常的$O(n^3)$降低至$O(n)$，使得在不同提示的大量生成轮次中实现多样性引导采样成为可能。
### Conclusion
在几个文本到图像扩散模型上通过数值测试SPARKE方法，证明了该方法在不显著增加计算成本的情况下提高了生成数据的提示感知多样性。源代码已在项目页面发布：this https URL
## 215. `cs.AI` - AIMeter：测量、分析和可视化AI工作负载的能源和碳足迹 [PDF](https://arxiv.org/pdf/2506.20535), [HTML](https://arxiv.org/abs/2506.20535)
### Authors
Hongzhen Huang,Kunming Zhang,Hanlong Liao,Kui Wu,Guoming Tang
### Background
随着人工智能（尤其是大型语言模型）的快速发展，模型训练和推理过程中的能源消耗和碳排放问题引起了广泛关注。然而，现有的衡量和报告这类影响的工具往往是分散的，并没有系统地整合统一的度量标准，且在关联分析方面提供的支持有限。
### Innovation
该论文提出了AIMeter，一个全面的软件工具包，用于测量、分析和可视化AI工作负载的能源使用、电力消耗、硬件性能和碳排放。AIMeter通过无缝集成现有的AI框架，提供标准化报告和导出细粒度的时间序列数据，以一种轻量级的方式支持基准测试和可重复性研究。此外，它还允许深入分析硬件指标与模型性能之间的关联，从而识别瓶颈并提升性能。AIMeter弥补了现有工具的重大不足，鼓励研究社区在考虑硬件性能的同时，关注AI工作的环境影响，推动向更可持续的“绿色AI”实践转变。
### Conclusion
AIMeter 通过系统的工具支持，促进了对AI模型的能源和环境影响的全面了解，提升了研究和应用的可持续性，推动了“绿色AI”实践的发展。
## 216. `cs.AI` - 语言模型的学习思维揭示：一种认知框架与实证研究 [PDF](https://arxiv.org/pdf/2506.13464), [HTML](https://arxiv.org/abs/2506.13464)
### Authors
Zhengyu Hu,Jianxun Lian,Zheyuan Xiao,Seraphina Zhang,Tianfu Wang,Nicholas Jing Yuan,Xing Xie,Hui Xiong
### Background
大规模语言模型（LLMs）在数学、代码编写和推理等任务上显示出了令人印象深刻的性能，然而它们的习得能力，这对于适应动态环境和获取新知识至关重要，仍处于探索阶段。本文通过借鉴认知心理学和教育学的原理，建立了这样一个框架来填补这一空白。
### Innovation
本文提出了一个基于认知心理学和教育学的框架，将通用的习得能力分解为三个互不相同但又互补的维度：从指导者学习（通过显性指导获取知识）、从概念学习（内化抽象结构并在新情境中泛化）以及从经验学习（通过累积探索和反馈适应）。此外，研究发现互动增强学习效果，概念理解在大模型中更为重要，以及LLMs具有有效的少量学习能力但并无法进行大量学习。创新之处在于引入了一个基准测试，提供了针对LLMs在三个学习认知维度上的统一且现实的评估，这有助于诊断评估和开发更加适应性和人性化的模型。
### Conclusion
通过本文的研究框架和实证分析，我们构建了一个基准测试，可以全面、真实地评估LLMs在三个学习认知维度上的通用学习能力，为评估和开发更具适应性和人性化模型提供了支持。
## 217. `cs.AI` - 正义之衡：大规模语言模型安全评估的全面综述 [PDF](https://arxiv.org/pdf/2506.11094), [HTML](https://arxiv.org/abs/2506.11094)
### Authors
Songyang Liu,Chaozhuo Li,Jiameng Qiu,Xi Zhang,Feiran Huang,Litian Zhang,Yiming Hei,Philip S. Yu
### Background
随着人工智能的迅速发展，大规模语言模型（LLMs）在自然语言处理（NLP）方面展现了显著的能力，包括内容生成、人机交互、机器翻译和代码生成等。然而，它们的广泛应用也引发了显著的安全性问题。特别是LLM生成的内容可能表现出不安全的行为，如有害、偏见或误导信息，尤其是在对抗环境中。尽管有许多研究试图评估这些风险，但未能就大规模语言模型安全评估进行全面而系统的综述。本文旨在填补这一空白，通过提供近期安全评估大规模语言模型进展的结构化概述来实现这一目标。具体而言，文章提出了一个四维分类系统，包括为什么评估、评估什么、在何处评估和如何评估四个方面，以综合介绍和分类当前广泛使用的评估方法、指标、数据集和基准。
### Innovation
本文提出的四维度分类法（包括为什么评估、评估什么、在何处评估和如何评估），为大规模语言模型的安全评估提供了一个系统化的综述框架。这不仅有助于更好地理解当前的安全评估方法和挑战，也为未来的研究指明了方向。此外，该研究强调了安全性评价的重要性，以确保大规模语言模型在实际应用中的可靠和负责任部署。
### Conclusion
本文指出了大规模语言模型安全评估中的挑战，并提出了促进该领域进一步发展的有希望的研究方向。总结来说，本文强调了安全评估优先性的必要性，以确保大规模语言模型在现实世界中的可靠和负责任部署。
## 218. `cs.AI` - 在推理模型中控制思考速度 [PDF](https://arxiv.org/pdf/2507.03704), [HTML](https://arxiv.org/abs/2507.03704)
### Authors
Zhengkai Lin,Zhihang Fu,Ze Chen,Chao Chen,Liang Xie,Wenxiao Wang,Deng Cai,Zheng Wang,Jieping Ye
### Background
人类认知被理论分为两种模式：快速直觉的System 1思考和缓慢细致的System 2思考。目前的大规模推理模型（LRMs）在处理System 2思考方面表现出色，但无法进行快速思考导致了高计算开销和延迟。本文旨在通过动态调整思考速度，使LRMs能够在准确性和效率之间找到最优平衡。
### Innovation
作者提出了一种新的方法来实现LRMs中思考速度的动态调整。首先，他们确定了控制LRMs表征空间中慢速和快速思考转换的引导向量，从而实现了基于表示编辑的测试时间缩放效果，超越了现有的基于提示的缩放方法。其次，他们应用实时难题估计来识别不同复杂程度的推理片段，结合这两种技术，提出了一种新的推理策略，能够快速处理简单的步骤，并深入分析复杂的推理。这项研究无需额外训练成本，且在多个领先的LRMs和高级推理基准测试中显示出平均每提高1.3%的准确性，节省8.6%的标记使用。
### Conclusion
本文提出的方法在不需要额外训练或成本的情况下，显著提高了LRMs的准确性，同时减少了标记使用，适用于广泛的LRMs和高级推理基准测试，为未来的相关研究提供了新的思路和应用方向。所有算法都基于vLLM实现，预期将支持更广泛的潜在应用。
## 219. `cs.AI` - 无计划之河：理解无计划方法在语言模型训练中的优势 [PDF](https://arxiv.org/pdf/2507.09846), [HTML](https://arxiv.org/abs/2507.09846)
### Authors
Minhak Song,Beomhan Baek,Kwangjun Ahn,Chulhee Yun
### Background
随着模型和数据集的规模迅速扩大，传统基于固定计算预算的预训练策略（如余弦学习率调度）越来越不适用于大规模训练。近年来，包括warmup-stable-decay（WSD）调度和权重平均在内的替代方案提供了更大的灵活性。然而，WSD依赖于明确的衰减阶段来跟踪进度，而权重平均解决了这一限制，但增加了额外的内存需求。本文重新审视了Defazio等人的Schedule-Free（SF）方法，该方法在多种设置中表现出强大的实证性能。本文通过理论和实验分析来理解SF动态，揭示SGD权重平均的效果，影响其对动量的鲁棒性以及在大批次大小下的表现，并提出改进的算法变体以解决原始方法的关键限制。
### Innovation
通过系统的理论和实验分析，作者揭示了SF方法在无阶段性衰减和额外内存开销的情况下如何进行权重平均。在此基础上，提出了改进的SF-AdamW算法，提高了对动量的鲁棒性，并在大规模训练中表现更优。
### Conclusion
这些结果确立了SF方法作为一种实用、可扩展且具有理论依据的语言模型训练方法的地位。
## 220. `cs.AI` - 视觉语言训练有助于部署分类知识但不从根本上改变它 [PDF](https://arxiv.org/pdf/2507.13328), [HTML](https://arxiv.org/abs/2507.13328)
### Authors
Yulu Qin,Dheeraj Varghese,Adam Dahlgren Lindström,Lucia Donatelli,Kanishka Misra,Najoung Kim
### Background
大多数关于视觉语言（VL）训练的研究结果都显示出不一致或边缘的差异，无论是行为上还是在表征上。此前的研究表明，简短对的文本模型与其VL训练版本在文本仅需回答问题任务中展现出了不一致的结果。
### Innovation
本文假设视觉语言训练在词汇概念知识方面（特别是其分类学组织）可能具有显著影响。通过比较仅文本模型与它们的VL训练版本，作者发现VL模型通常在需要概念分类理解的文本仅需回答问题任务中表现更好。进一步的行为和表征分析表明，模型之间的分类知识本身没有显著差异，但在处理分类关系和非分类关系概念的问题表示方式上存在差异。这对理解模型中分类知识本身是否通过额外的VL训练发生重大改变及这种知识在其特定任务中如何被应用提出了不同于以往的见解。
### Conclusion
文本中的视觉语言训练确实提升了模型在特定任务中应用分类知识的能力，特别是在纯语言任务呈现的情况下，尽管分类知识本身没有发生根本性的改变。
## 221. `cs.AI` - DSDE: 基于KLD稳定性的动态推测性解码以实现实时服务 [PDF](https://arxiv.org/pdf/2509.01083), [HTML](https://arxiv.org/abs/2509.01083)
### Authors
Mingyu Yang,Jae-Young Choi,Kihyo Moon,Minsung Jang,Eunjoo Jeon
### Background
推测性解码加快了大型语言模型的推理速度，但其依赖于固定的推测长度，在多样化请求的大批量服务环境中效果不理想。本文探讨了动态适应的新方向，通过研究一种新的后处理诊断信号类。这项研究基于两个主要组件：一是基于Kullback-Leibler散度方差的预测信号，诊断生成的区域稳定性；二是可适应的推测长度上限，以缓解批量逐序列解码中的延宕问题。
### Innovation
提出了动态推测性解码引擎（DSDE），这是一种无需训练的框架，结合了基于KLD散度方差的预测信号和自适应推测长度上限，该方法能够实现端到端延迟与领先基准相当，特别是在工作负载多样化时表现出更优越的鲁棒性。这些发现验证了后处理信号在构建更鲁棒和智能化的LLM推理系统中的价值，并提出了推测长度动态调整的有前景的研究方向。
### Conclusion
基于这些发现，研究证明了后处理信号作为构建更鲁棒和智能的LLM推理系统的重要组成部分的有效性，并强调了动态推测长度适应性研究的前景广阔。
## 222. `cs.AI` - FASL-Seg: 拟人化和工具分割的手术场景 [PDF](https://arxiv.org/pdf/2509.06159), [HTML](https://arxiv.org/abs/2509.06159)
### Authors
Muraam Abdel-Ghani,Mahmoud Ali,Mohamed Ali,Fatmaelzahraa Ahmed,Muhammad Arsalan,Abdulaziz Al-Ali,Shidin Balakrishnan
### Background
随着机器人微创手术的日益普及，基于深度学习的手术培训成为研究的重点领域。为了实现对手术场景组成部分的深入理解，语义分割模型能够帮助实现这一目标。然而，现有的大多数研究主要关注手术器械而非解剖对象，并且当前最先进的模型在捕捉高层上下文特征和低层边缘特征之间难以实现平衡。
### Innovation
我们提出了一种特征自适应空间定位模型（FASL-Seg），设计了一个低级特征投影（LLFP）和高级特征投影（HLFP）双通道处理流，以实现不同分辨率特征的精确分割，特别适用于解剖和手术器械的分割。FASL-Seg在EndoVis18和EndoVis17基准数据集的三个应用场景中进行了评估，其在EndoVis18中的表现优于当时的最先进技术水平，mIoU提高了5%。在工具类型分割方面，FASL-Seg分别达到了85.61%和72.78%的mIoU，优于当前最先进的整体性能。
### Conclusion
FASL-Seg模型通过不同的处理流实现了不同分辨率特征的精确分割，对于解剖和手术器械的分割表现出色，各类别性能一致，证明了不同分辨率特征处理流的有效性。
## 223. `cs.AI` - 全效影：统一且空间可控的视觉效果生成 [PDF](https://arxiv.org/pdf/2508.07981), [HTML](https://arxiv.org/abs/2508.07981)
### Authors
Fangyuan Mao,Aiming Hao,Jintao Chen,Dongxia Liu,Xiaokun Feng,Jiashu Zhu,Meiqi Wu,Chubin Chen,Jiahong Wu,Xiangxiang Chu
### Background
视效（VFX）是现代影视制作中不可或缺的视觉增强技术。虽然现有的视频生成模型能够提供成本效益高的VFX解决方案，但当前方法受限于针对每种效果进行的LoRA训练，这限制了多效果的同时生成。这一基本限制阻碍了需要空间可控制的复合效果的应用，即在指定位置的同时生成多个效果。然而，将多种效果整合到一个统一的框架中面临主要挑战：效应变异性之间的干扰以及多VFX联合训练中的空间不可控性。
### Innovation
我们提出了一种名为Omni-Effects的统一框架，该框架能够生成由提示引导的效果和空间可控的复合效果。框架的核心包含两大创新：（1）基于LoRA的专家混合体（LoRA-MoE），这种方法利用了一组专家LoRA，将多样化的效果整合到一个统一的模型中，并有效减少任务间的干扰。（2）空间感知提示（SAP），将空间掩码信息融入到文本标记中，提供了精确的空间控制。此外，我们还引入了一个独立信息流（IIF）模块，作为SAP的一部分，隔离了对应各个效果的控制信号，防止不希望的混合。为了支持这项研究，我们通过一种结合图像编辑和First-Last Frame-to-Video（FLF2V）合成的新数据采集流程，构建了一个全面的VFX数据集Omni-VFX，还引入了一个专门的VFX评估框架来验证模型性能。实验结果证明，Omni-Effects实现了精确的空间控制和多样效果生成，允许用户指定所需效果的类别和位置。
### Conclusion
Omni-Effects展示了精确的空间控制和多样化的效果生成能力，为用户提供指定所需效果的类别和位置的能力，从而克服了当前方法中的基本限制。
## 224. `cs.AI` - SignalLLM：通用的大语言模型代理框架以自动化信号处理 [PDF](https://arxiv.org/pdf/2509.17197), [HTML](https://arxiv.org/abs/2509.17197)
### Authors
Junlong Ke,Qiying Hu,Shenghai Yuan,Yuecong Xu,Jianfei Yang
### Background
现代信号处理（SP）管道不管是基于模型的还是数据驱动的，往往受限于复杂且碎片化的流程，依赖于专家知识和手动工程，并在有限数据下难以保证适应性和泛化。相比之下，大型语言模型（LLMs）具备强大的推理能力、广泛的通用知识、上下文学习能力以及跨模态迁移能力，使它们成为自动化和泛化信号处理流程的强大工具。
### Innovation
我们提出了SignalLLM，这是一个第一个基于大语言模型（LLMs）的一般用途代理框架，用于一般信号处理任务。它采用了一种原理上合理、模块化的架构，将高层SP目标分解为通过上下文学习和领域特定检索获得的结构化子任务，随后通过自适应检索增强生成（RAG）和改进进行分层规划；这些子任务然后通过基于提示的推理、跨模态推理、代码合成、模型调用或数据驱动的LLM辅助建模来执行。其可泛化的设计使其能够根据不同信号模态、任务类型和数据条件灵活选择解决策略。
### Conclusion
我们通过五个代表性任务展示了SignalLLM的多样性和有效性，如通信和传感器中的雷达目标检测，人类活动识别和文本压缩。实验证明，它在传统和现有基于LLM的方法中的性能优于传统方法，特别是在少样本和零样本设置中表现出色。
## 225. `cs.AI` - 使用大型语言模型揭示多模态因果关系 [PDF](https://arxiv.org/pdf/2509.17784), [HTML](https://arxiv.org/abs/2509.17784)
### Authors
Jin Li,Shoujin Wang,Qi Zhang,Feng Liu,Tongliang Liu,Longbing Cao,Shui Yu,Fang Chen
### Background
从数据中揭示因果机制是科学进步的基础。尽管大型语言模型（LLMs）显示出了增强从非结构化数据中发现因果关系（CD）的潜力，它们在处理日益普及的多模态数据集的应用上仍然面临着重要挑战。即使引入了多模态大型语言模型（MLLMs），它们在多模态CD中的效果也受限于两个主要问题：（1）难以探索单一模态和跨模态的相互作用，以全面识别因果变量；（2）处理观测数据中的结构性歧义能力不足。
### Innovation
本文提出了一种新的多模态因果发现框架MLLM-CD，包含三个关键组件：（1）一种新颖的对比因素发现模块，基于对比样本对中探索的相互作用来识别真实的多模态因素；（2）一种统计因果结构发现模块，用于推断所发现因素之间的因果关系；（3）一种迭代的多模态反事实推理模块，通过结合MLLMs的世界知识和推理能力逐步改进发现结果。广泛的实验证明，提出的MLLM-CD在揭示多模态非结构化数据中的真正因素和它们之间的因果关系方面非常有效。
### Conclusion
MLLM-CD框架通过针对性地解决存在的问题，成功地从多模态非结构化数据中揭示了真实的因素和它们之间的因果关系。实验结果验证了该方法的有效性。
## 226. `cs.AI` - Cycle Diffusion Model for Counterfactual Image Generation [PDF](https://arxiv.org/pdf/2509.24267), [HTML](https://arxiv.org/abs/2509.24267)
### Authors
Fangrui Huang,Alan Wang,Binxu Li,Bailey Trang,Ridvan Yesiloglu,Tianyu Hua,Wei Peng,Ehsan Adeli
### Background
深度生成模型在医学图像合成方面已经取得了显著的成功，但是在确保合成图像的条件忠实性和高保真度方面仍然存在挑战。现有方法在直接生成或假设生成时，图像的质量和条件的真实性有待提高。
### Innovation
本文提出了一种循环训练框架，通过引入循环约束，对扩散模型进行微调，以提高生成图像的一致性，并增强其真实性。这种方法称为循环扩散模型（CDM），能更可靠地进行直接生成和假设生成，并通过实验在FID和SSIM指标上证明了这一点。此外，该方法在数据扩增、假设生成和疾病进展建模等方面具有潜在应用价值。
### Conclusion
循环策略在循环扩散模型中表明是一种有效的细化基于扩散的医学图像生成方法。实验结果表明，CDM方法能够提高条件准确性和图像质量，适用于医学图像生成的多个应用场景。
## 227. `cs.AI` - Holographic Transformers for Complex-Valued Signal Processing: Integrating Phase Interference into Self-Attention [PDF](https://arxiv.org/pdf/2509.19331), [HTML](https://arxiv.org/abs/2509.19331)
### Authors
Enhao Huang,Zhiyu Zhang,Tianxiang Xu,Chunshu Xia,Kaichun Hu,Yuchen Yang,Tongtong Pan,Dong Dong,Zhan Qin
### Background
现实世界的许多信号，如雷达图像和无线通信信道，具有复杂的复数值特征，即它们包含振幅和相位信息。然而，大多数深度学习模型在处理注意力机制时仅考虑实数相关性，而忽略了相位干涉效应。因此，现有模型可能无法充分利用这些信号的相位信息，导致效果不佳。为了解决这一问题，提出了一种新的架构——Holographic Transformer，它将波干涉原理融入自我注意力中，以改进复数值信号处理的效果。
### Innovation
Holographic Transformer引入了基于波干涉原理的注意力机制，通过相对相位和相干叠加来调节互动，确保振幅和相位的一致性。与现有的实数值注意力机制相比，Holographic Transformer在重建输入信号和预测任务输出时，具有更强的性能。此外，设计了双头解码器，以防止当损失函数优先考虑振幅而非相位时，相位发生崩溃。实验验证了这种新颖的注意力机制能够在分类和回归任务中保持振幅与相位的一致性，表现出显著的性能提升和发展前景，即物理一致性的注意力机制能够显著改善复数值信号的学习。
### Conclusion
Holographic Transformer在极化合成孔径雷达图像分类和无线信道预测等任务上展现了强大的性能，证明了将物理一致性的原则应用于注意力机制的有效性。其结果表明，这种模型能够在复数值学习中实现广泛适用性改进，并为相干信号建模提供了一种统一、基于物理的框架。该研究成果不仅为复数信号处理领域带来了新思路，也为未来相关研究提供了参考。代码已发布。
## 228. `cs.AI` - RLBF: 二元灵活反馈在人类反馈与可验证奖励之间的桥梁 [PDF](https://arxiv.org/pdf/2509.21319), [HTML](https://arxiv.org/abs/2509.21319)
### Authors
Zhilin Wang,Jiaqi Zeng,Olivier Delalleau,Ellie Evans,Daniel Egert,Hoo-Chang Shin,Felipe Soares,Yi Dong,Oleksii Kuchaiev
### Background
论文背景在于，使用人类反馈进行强化学习（RLHF）和可验证奖励进行强化学习（RLVR）是大型语言模型（LLM）后训练中的主要方法，两者各有优势。然而，RLHF在解释性和抗奖励操纵方面存在局限，因为它的反馈依赖于模糊的人类判断。相比之下，RLVR受限于其验证器多专注于正确性验证，范围有限。
### Innovation
本文提出了一种新的强化学习框架——二元灵活反馈（RLBFF），结合了基于人类偏好的灵活性和基于规则验证的精确性，以捕捉响应质量的复杂方面（不仅仅是正确性）。RLBFF从自然语言反馈中提取二元可答原则（例如：信息准确性：是或否，代码可读性：是或否），并将其作为履行任务来培训奖励模型。结果表明，这种方式培训的奖励模型在数据匹配的情况下性能超过布拉德利-特里模型，并在RM-Bench（86.2%）和JudgeBench（81.4%，截至2025年9月24日排名第一）上表现优异。此外，用户可以在推理时指定感兴趣的原则，从而使奖励模型更灵活。
### Conclusion
通过RLBFF和奖励模型，我们实现了QLwen3-32B模型的对齐，使其在MT-Bench、WildBench和Arena Hard v2等通用对齐基准测试中的性能与o3-mini和DeepSeek R1相当或更好，并且成本仅为这些模型的5%。我们还提供了整个开源食谱（包括数据）以实现这一目标。
## 229. `cs.AI` - Tunable-Generalization Diffusion Powered by Self-Supervised Contextual Sub-Data for Low-Dose CT Reconstruction [PDF](https://arxiv.org/pdf/2509.23885), [HTML](https://arxiv.org/abs/2509.23885)
### Authors
Guoquan Wei,Liu Shi,Zekun Zhou,Wenzhe Shan,Qiegen Liu
### Background
当前基于深度学习的低剂量CT去噪模型依赖于配对数据，泛化能力差。即使是关注扩散模型，也需要学习清洁数据的分布以进行重建，这在医疗临床应用中难以满足。同时，基于自监督的方法在将预训练剂量下的模型扩展到其他剂量时面临泛化能力显著下降的挑战。
### Innovation
本文提出了一种名为Tunable-Generalization Diffusion（TurnDiff）的新型方法，通过自监督的上下文子数据增强相似性策略，该策略在低剂量CT投影域中进行去噪，并提供后续步骤的初始先验。随后，结合知识蒸馏和深度扩散模型的联合训练来优化图像细节。为了增强图像保真度，并提出一种像素级自我纠正融合技术，利用初始先验和低剂量CT图像作为指导。此外，该技术能够灵活地应用于剂量泛化问题，甚至应用于未见过的剂量。TurnDiff仅需低剂量CT投影域数据进行训练和测试。
### Conclusion
综合评估结果显示，TurnDiff在重建和泛化方面均优于现有最先进技术。
## 230. `cs.AI` - LatentBreak：通过潜空间反馈破解大型语言模型 [PDF](https://arxiv.org/pdf/2510.08604), [HTML](https://arxiv.org/abs/2510.08604)
### Authors
Raffaele Mura,Giorgio Piras,Kamilė Lukošiūtė,Maura Pintor,Amin Karbasi,Battista Biggio
### Background
 Jailbreaks 是设计用来绕过大型语言模型内置安全机制的对抗性攻击。自动化的 jailbreak 通常会优化一个对抗性的后缀，或者通过迫使模型生成受限或有害响应的初始部分来适应长提示模板。现有利用这种机制来解锁模型响应的 jailbreak 攻击可以通过简单的困惑度过滤方法在输入提示上被检测出来。为了克服这一问题，这篇文章提出了一种名为 LatentBreak 的白盒 jailbreak 攻击，它生成具有低困惑度的自然对抗性提示，以避开此类防御。
### Innovation
 LatentBreak 通过在输入提示中用语义等效词替换单词，而不是添加高困惑度的对抗性后缀或长模板，来生成低困惑度的自然对抗性提示。这些词是通过最小化对抗性提示和无害请求之间在潜空间中的表示距离来选择的。这种攻击方法能够产生更短且低困惑度的提示，从而在多种安全对齐模型上优于基于困惑度的过滤器的竞争 jailbreak 算法。
### Conclusion
我们的广泛评估表明，LatentBreak 可以生成更短和低困惑度的提示，因此在多个安全对齐的模型上优于基于困惑度过滤器的其他 jailbreak 算法。
## 231. `cs.AI` - 通过社交媒体纵向和信息环境信号检测早期隐性自杀倾向 [PDF](https://arxiv.org/pdf/2510.14889), [HTML](https://arxiv.org/abs/2510.14889)
### Authors
Soorya Ram Shimgekar,Ruining Zhao,Agam Goyal,Violeta J. Rodriguez,Paul A. Bloom,Hari Sundaram,Koustuv Saha
### Background
在社交媒体上，许多经历自杀念头（SI）的人不会明确表达他们的困扰，而是通过日常帖子或同伴互动隐晦地显现出来。早期检测这些隐性迹象非常重要，但极具挑战性。这篇文章将这种早期和隐性的自杀倾向定义为一种前瞻性的预测任务，并开发了计算框架来建模用户的信息环境，包括用户的纵向发帖历史及其社交邻域同伴的讨论。
### Innovation
本文采用综合网络中心性度量来识别用户的关键邻居，并对用户及其邻居的交互进行时间上的一致对齐，从而在微调的DeBERTa-v3模型中整合多层次的信号。在Reddit的一项涉及1000名用户（500例案例和500名对照）的研究中，此Approach比单独使用用户的基线检测早发性和隐性自杀倾向高出15%。这一发现表明同伴互动提供了有价值的预测信号，并且对设计兼顾直接和隐蔽风险表达的早期检测系统具有更广泛的意义。
### Conclusion
同伴互动提供了有用的预测信号，这些发现指出了设计早期检测系统的方法，这些系统可以捕捉在线环境中隐性和被遮盖的风险表达。
## 232. `cs.AI` - 大语言模型中的知识多样性与知识崩塌 [PDF](https://arxiv.org/pdf/2510.04226), [HTML](https://arxiv.org/abs/2510.04226)
### Authors
Dustin Wright,Sarah Masud,Jared Moore,Srishti Yadav,Maria Antoniak,Chan Young Park,Isabelle Augenstein
### Background
大规模语言模型（LLMs）倾向于生成在词汇、语义和风格上具有高度一致性的文本，这可能会导致知识崩塌，即LLMs会逐渐缩小其可访问信息的范围。目前关于同质化的研究主要集中在封闭式选择题设置或模糊语义特征上，并且没有关注随着时间推移和文化背景的变化趋势。
### Innovation
本文提出了一种新的方法来测量知识多样性，即LLM输出中的现实声明的变化，进而进行了一项广泛的实证研究来探讨LLM知识崩塌的问题。通过测试27种LLM模型、155个主题和200种来自真实用户聊天的提示变化，作者发现尽管较新的模型生成了更多的多样声明，但大多模型的知识多样性仍低于基本的网络搜索。此外，研究还发现模型大小会负面影响知识多样性，而检索增强生成（RAG）则有正面影响，但这种改进因文化的差异而异。
### Conclusion
与传统知识来源（维基百科）相比，研究发现特定国家的声明更偏向于英语而不是当地语言，揭示了在知识表达上的代表性缺口。
## 233. `cs.AI` - SPLite Hand: Sparsity-Aware Lightweight 3D Hand Pose Estimation [PDF](https://arxiv.org/pdf/2510.16396), [HTML](https://arxiv.org/abs/2510.16396)
### Authors
Yeh Keng Hao,Hsu Tzu Wei,Sun Min
### Background
随着AR/VR设备的广泛应用，深度学习模型在边缘设备上的部署成为了一个关键挑战。这些设备需要实时推理、低功耗和最小的延迟。框架设计者面临着平衡效率和性能的难题。
### Innovation
我们设计了一个轻量化的框架，采用了编码-解码架构，并引入了几个关键贡献，以同时提高效率和准确性。我们通过在ResNet-18骨干网络上应用稀疏卷积来利用手部姿势图像中的固有稀疏性，实现了端到端42%的效率提升。此外，我们提出了SPLite解码器，这一新的架构在Raspberry Pi 5上将解码过程的帧率提高了3.1倍，同时保持了与现有方法相当的准确性。为了进一步优化性能，我们应用量化感知训练，减少了内存使用量，同时保持了准确性（PA-MPJPE从9.0毫米略微增加到9.1毫米）。
### Conclusion
我们的系统在Raspberry Pi 5 CPU（BCM2712 四核Arm A76处理器）上实现了2.98倍的速度提升。我们的方法也在复合基准数据集上进行了评估，显示出与最先进的方法相当的准确性，同时显著提高了计算效率。
## 234. `cs.AI` - MaskCaptioner: 学习在视频中联合分割和描述物体轨迹 [PDF](https://arxiv.org/pdf/2510.14904), [HTML](https://arxiv.org/abs/2510.14904)
### Authors
Gabriel Fiastre,Antoine Yang,Cordelia Schmid
### Background
Dense Video Object Captioning (DVOC)任务要求同时检测、跟踪和用自然语言描述视频中物体的轨迹，这需要理解时空细节的能力。由于任务复杂性和手动标注的高成本，之前的办法采用了分离训练策略，可能导致性能不佳。现有的人工标注稀缺和质量参差不齐，阻碍了模型的整体性能提升。为解决这一问题，该论文提出了一种利用前沿视觉语言模型（VLM）生成时空局部实体描述的方法，从而在标注稀缺的情况下也能获取良好的性能。通过使用合成描述数据增强现成的数据集如LVIS和LV-VIS，并据此训练了可以联合进行物体检测、分割、跟踪和描述的端到端模型MaskCaptioner。该模型在多个现有基准测试VidSTG、VLN和BenSMOT上取得了最佳结果，证明了其在DVOC任务上的优越性。
### Innovation
论文创新之处在于提出了一种新的方法，利用最先进的视觉-语言模型生成时空局部物体描述，并通过引入合成数据集（LVISCap和LV-VISCap）进行模型训练，有效提升了在缺乏标注数据情况下联合分割和描述物体轨迹的效果，并且在多个现有基准测试上取得最优结果。这一方法显著提升了在DVOC任务上的性能。
### Conclusion
MaskCaptioner模型不仅可以在大量标注数据存在的情况下表现出色，在标注数据稀缺的情况下也能维持较高的性能，表现出优秀的泛化能力。通过引入由LVIS和LV-VIS数据集扩展生成的合成描述数据训练模型，取得了在三个基准测试上的最佳成果，这标志着一个重要的进步。
## 235. `cs.AI` - FLAME在遥感中的即时OVD适应：基于活跃边际样本探索的少量样本定位 [PDF](https://arxiv.org/pdf/2510.17670), [HTML](https://arxiv.org/abs/2510.17670)
### Authors
Yehonathan Refael,Amit Aides,Aviad Barzilai,George Leifman,Genady Beryozkin,Vered Silverman,Bolous Jaber,Tomer Shekel
### Background
开放词汇对象检测（OVD）模型能够通过任意文本查询检测对象，具有显著的灵活性。但在如遥感（RS）这样的专门领域，其零样本性能往往因自然语言的固有歧义而受限，这限制了关键下游应用的实现。例如，一个OVD模型可能难以区分细粒度的类别如“捕鱼船”和“游艇”，因为它们的嵌入相似且很难区分。这使得监测非法捕鱼等特定用户目标受到影响，因为会产生无关紧要的检测结果。
### Innovation
本文提出了一种级联方法，将大型预训练OVD模型的广泛应用与轻量级的少量样本分类器相结合。首先，零样本模型生成高召回率的对象提案；随后，通过仅在少量用户标注示例上进行实时训练的紧凑分类器对这些提案进行细化，以提高精确度。核心方法是FLAME，一种一步法主动学习策略，能够快速对训练样本进行选择。FLAME利用密度估计实时识别决策边界附近的不确定候选样本，并通过聚类确保样本多样性，从而在无需昂贵的全模型微调的情况下实现高效采样，能够实现即时适应，时间少于一分钟，显著快于现有技术。
### Conclusion
本文提出的方法在遥感基准测试中始终优于现有技术，建立了一种实用且资源高效的框架，使基础模型能够适应特定用户需求。
## 236. `cs.AI` - 将基因组学整合到多模态EHR基础模型中 [PDF](https://arxiv.org/pdf/2510.23639), [HTML](https://arxiv.org/abs/2510.23639)
### Authors
Jonathan Amar,Edward Liu,Alessandra Breschi,Liangliang Zhang,Pouya Kheradpour,Sylvia Li,Lisa Soleymani Lehmann,Alessandro Giulianelli,Matt Edwards,Yugang Jia,David Nola,Raghav Mani,Pankaj Vats,Jesse Tetreault,T.J. Chen,Cory Y. McLean
### Background
目前的电子健康记录（EHR）方法主要基于传统的EHR数据，缺乏对遗传风险的整合，难以构建更加全面的健康档案。本文利用All of Us（AoU）研究项目的丰富多元数据，提出了一个创新性的人工智能基础模型，该模型整合多模态数据，特别是通用多基因风险评分（PRS），旨在学习临床数据和遗传倾向之间的复杂关系，并通过扩展生成AI的方法，提高预测能力和可解释性。
### Innovation
本文介绍了一种新的电子健康记录基础模型，将多基因风险评分（PRS）纳入其中，形成了一个多模态框架，可以在临床数据和遗传风险之间建立复杂关系。该模型运用生成式人工智能技术扩展了EHR基础模型的应用范围，提升了预测能力和可解释性。在AoU数据集上进行了评估，展示了模型在多种状况，特别是2型糖尿病（T2D）预测上的价值，并探讨了迁移学习在定制分类任务中的应用，展示了架构的灵活性和效率。
### Conclusion
该方法为疾病预测、积极的健康管理、风险分层和个人化治疗策略等新洞察提供了关键性支持，为更个性化、公平性、行动性的真实世界证据生成奠定了基础。
## 237. `cs.AI` - VC4VG: 优化视频字幕以实现文本到视频生成 [PDF](https://arxiv.org/pdf/2510.24134), [HTML](https://arxiv.org/abs/2510.24134)
### Authors
Yang Du,Zhuoran Lin,Kaiqiang Song,Biao Wang,Zhicheng Zheng,Tiezheng Ge,Bo Zheng,Qin Jin
### Background
文本到视频(T2V)生成的发展突显了高质量视频-文本对在训练能够生成连贯且指令对齐的视频的模型方面的重要性。然而，专门用于T2V训练优化视频字幕的策略仍较少被探索。背景强调了提高T2V模型性能的关键在于优化视频字幕的质量与设计。
### Innovation
本文引入了VC4VG（视频字幕优化视频生成）框架，这是一种专门针对T2V模型需求的全面字幕优化框架。提出了从T2V视角分析字幕内容，并将视频重建所需的要素分解为多个维度，从而提出了一个遵循原则的字幕设计方法。此外，构建了VC4VG-Bench，这是一个新的基准，其中包括细粒度、多维度和按T2V特定需求分级的评估指标，以支持对T2V性能的评估。实验结果表明，改善字幕质量与视频生成性能之间存在显著相关性，证实了该方法的有效性。为了支持进一步的研究，该框架的工具和代码可在该链接下载: this https URL
### Conclusion
详尽的T2V微调实验证明了改进字幕质量与视频生成性能之间的强相关性，表明VC4VG框架的有效性。
## 238. `cs.AI` - 使用时域梅尔频率小波系数的音频信号处理 [PDF](https://arxiv.org/pdf/2510.24519), [HTML](https://arxiv.org/abs/2510.24519)
### Authors
Rinku Sebastian,Simon O'Keefe,Martin Trefzer
### Background
音频信号处理中最关键的步骤是从语音中提取特征。Mel频率倒谱系数（MFCC）因其滤波器组类似于人耳的感知方式，被广泛应用于多数说话人和语音识别应用中。然而，MFCC只提供了信号的频率信息，而没有提供频率出现的具体时间信息。小波变换可以提供时间和频率信息，适用于非稳态信号的分析，如语音信号。然而，由于其均匀的频率缩放，传统的波形变换在其低频部分的频率分辨能力较弱，并且与人类的听觉感知不完全一致。因此，有必要开发一个融合MFCC和小波变换优点的新特征。
### Innovation
提出了一个时域梅尔频率小波系数（TMFWC）的方法，该方法结合了波形变换的概念，可以在不进行时频转换的情况下直接在时域中提取梅尔尺度特征，从而减少了时间-频率转换和小波提取的计算负担和复杂度。
### Conclusion
将我们提出的时域梅尔频率小波系数（TMFWC）技术与水库计算方法结合，极大地提高了音频信号处理的效率。
## 239. `cs.AI` - UNO-Bench：探索统一模态与多模态之间组成规律的统一基准 [PDF](https://arxiv.org/pdf/2510.18915), [HTML](https://arxiv.org/abs/2510.18915)
### Authors
Chen Chen,ZeYang Hu,Fengjiao Chen,Liya Ma,Jiaxing Liu,Xiaoyu Li,Ziwen Wang,Xuezhi Cao,Xunliang Cai
### Background
多模态大型语言模型已经从单一模态理解向着统一视觉、音频和语言模态发展，统称为全能模型。然而，单一模态与全能模态之间的关联尚不清楚，需要进行全面评估以推动全能模型的智能化进化。现有文献中缺乏一个能够同时评估单一模态和多模态能力的统一基准。因此，本文提出了一个新的名为UNO-Bench的高质量和统一全能模型基准，旨在在一个统一的能力分类下有效评估单一模态和多模态能力，涵盖44种任务类型和5种模态组合。
### Innovation
UNO-Bench引入了一个新的多模态和单一模态评估基准，包含1250个人工策划的多模态样本（包含98%的跨模态可解性）和2480个增强单一模态样本，是首个集统一模态与多模态能力于一身的评估基准。此外，UNO-Bench借鉴了18个公开基准的特点来提高自动压缩数据集的效率，并提出了一个多步骤开放式问题格式来评估复杂的推理能力。该基准还包括一个通用评分模型，可以自动化评估6种问题类型，准确率为95%。实验结果表明，情商模态和单一模态之间的定量关系，并且全能模态能力在弱模型中表现为瓶颈效应，在强模型中则表现为协同促进作用。
### Conclusion
UNO-Bench为多模态与单一模态之间的组成规律提供了统一的评估基准。通过UNO-Bench，不仅可以全面评估模型的潜力，还可以发现全能模型优势的机制。这将促进全能模型技术进一步的发展，为未来的大规模语言模型应用提供重要指导。
## 240. `cs.AI` - 针对获得失语症患者转录的方法 [PDF](https://arxiv.org/pdf/2510.24817), [HTML](https://arxiv.org/abs/2510.24817)
### Authors
Jason M. Pittman,Anton Phillips Jr.,Yesenia Medina-Santos,Brielle C. Stark
### Background
在失语症研究中，言语-语言病理学家（SLPs）花费大量时间手动编码语音样本，使用正确的信息单元（CIUs）作为衡量单个语音样本信息量的指标。然而，由于数据稀少，开发自动识别失语症语言的系统受到限制。例如，虽然AphasiaBank中有约600个转录本，但用来训练大型语言模型的词数量达到数十亿。在更广泛的机器学习领域，研究人员越来越多地转向合成数据，以填补数据稀少的问题。因此，这项研究采用和验证了两种方法，用于生成AphasiaBank猫救援图片描述任务的合成转录本。
### Innovation
该研究采用合成数据生成方法，利用程序化编程方法和两款大型语言模型（Mistral 7b Instruct和Llama 3.1 8b Instruct）生成不同严重程度级别的合成转录本，包括轻度、中度、重度和极重度。这些合成转录本通过词汇删除、填充插入和同义替换，模拟失语症语言的退化。研究表明，Mistral 7b Instruct在生成合成转录本方面表现最佳，其捕捉到的失语症中的关键语言退化方面与人类搜集的转录本非常接近，展示了在非重复词数、词汇数量和词汇长度方面的现实变化。
### Conclusion
未来的研究应计划创建更大规模的数据集，对模型进行微调以更好地代表失语症，以及让SLPs评估合成转录本的现实性和实用性。
## 241. `cs.AI` - 模型文档协议对AI搜索 [PDF](https://arxiv.org/pdf/2510.25160), [HTML](https://arxiv.org/abs/2510.25160)
### Authors
Hongjin Qian,Zheng Liu
### Background
AI搜索依赖于将大规模语言模型（LLMs）与广泛的外部知识源链接起来。然而，网页、PDF文件和其他原始文档并不是天生的LLM格式：它们往往很长、噪声大且不结构化。传统检索方法通常将这些文档视为未经修改的文本，返回原始片段，从而使片段组织和上下文推理的负担落在LLM上。这一差距凸显出需要一种新的检索范式来重新定义模型与文档的交互方式。
### Innovation
我们引入了模型文档协议（MDP），这是一种通用框架，它规范了通过可消费的知识表示将原始文本桥接到LLMs的过程。MDP定义了多种路径，将未结构化的文档转换成特定任务、LLM可处理的输入，包括代理推理、记忆驻留和结构化利用。所有这些路径都共同确保，传递给LLM的不是原始片段，而是紧凑、可直接用于推理的结构化知识。
### Conclusion
我们通过MDP-Agent 实现了MDP协议，它通过构建文档层面的主要记忆、进行基于扩散的探索以发现分层依赖性，并应用map-reduce风格的综合方法将大规模证据整合到紧凑而充分的上下文中。在信息检索标准测试中的实验表明，MDP-Agent 超过了基线模型，验证了MDP框架的有效性和其代理实现的有效性。
## 242. `cs.AI` - 托管地产：有界单方响应博弈的基准环境 [PDF](https://arxiv.org/pdf/2510.25080), [HTML](https://arxiv.org/abs/2510.25080)
### Authors
Will Wolf
### Background
纸牌游戏广泛用于研究不确定性下的顺序决策，其现实世界的应用包括谈判、金融和网络安全等领域。这些博弈通常分为三种基于控制流程的类别：严格顺序（玩家交替进行单一行动）、确定性响应（某些行动触发固定结果）、以及无限制的互逆响应（交替回击许可）。较少被探索但战略上丰富的结构是有界单方响应，即一名玩家的动作暂时转移了控制权给对手，对手必须通过一个或多个行动满足固定条件后回合才能结束。作者引入了一个修改版的Monopoly Deal作为基准环境，来隔离这种动态，其中“租用”行动迫使对手选择支付资产。在此基准环境中，标准算法Counterfactual Regret Minimization（CFR）通过无新型算法扩展能够收敛于有效策略。提供的轻量级全栈研究平台集成了环境、并行化的CFR运行时和一个可玩的人工智能网端界面。训练好的CFR代理和源代码可在指定的网站获取。
### Innovation
提出了Monopoly Deal的修改版本作为研究有界单方响应博弈的基准环境。此环境使研究人员能够集中研究有界单方响应机制。同时，强调了标准算法CFR在此环境中的适用性，无需额外的算法扩展即能收敛到有效策略。此外，提供了一个轻量级的全栈研究平台，包括环境、并行化的CFR运行时及可玩的人工智能网端界面，供研究人员使用。
### Conclusion
通过修改版的Monopoly Deal，证明了在有界单方响应博弈中，标准算法CFR能够有效收敛至策略，无需额外的算法改进。此外，开发了用于研究此类博弈的轻量级全栈平台，并提供了训练好的CFR代理和源代码以供其他研究者使用。
## 243. `cs.AI` - MMEdge: 通过分阶段感知和编码加速设备端多模态推理 [PDF](https://arxiv.org/pdf/2510.25327), [HTML](https://arxiv.org/abs/2510.25327)
### Authors
Runxi Huang,Mingxuan Yu,Mingyu Tsoi,Xiaomin Ouyang
### Background
在自动驾驶、人机交互和移动健康等领域，边缘设备上的实时多模态推理至关重要。然而，先前的工作往往忽视了感知动态和模型执行之间的紧密耦合，以及不同模态之间的复杂交互依赖关系。
### Innovation
本文提出了一种基于分阶段感知和编码的新设备端多模态推理框架MMEdge。MMEdge在数据到达时即开始计算，而不是等待完整传感器输入。它还引入了一个轻量但有效的时序聚合模块，可以捕获不同分阶段单元中的丰富时序动态，以保持准确性。此外，MMEdge还结合了一个自适应多模态配置优化器，可以在满足延迟约束的情况下动态选择最优的感知和模型配置，以及一个跨模态推测性跳过机制，当早期预测达到足够信心时，跳过较慢模态中的后续单元。
### Conclusion
在两个公共多模态数据集上评估MMEdge，并将其部署在基于无人机的多模态测试平台上。结果显示，MMEdge在各种系统和数据动态下显著减少了端到端延迟，同时保持了高任务准确性。
## 244. `cs.AI` - 基于凸性依赖的两阶段深度神经网络训练算法 [PDF](https://arxiv.org/pdf/2510.25366), [HTML](https://arxiv.org/abs/2510.25366)
### Authors
Tomas Hrycej,Bernhard Bermeitinger,Massimo Pavone,Götz-Henrik Wiegand,Siegfried Handschuh
### Background
机器学习的核心任务是通过最小化衡量模型与训练数据拟合程度的损失函数来优化模型。数值方法高效实现这一任务依赖于损失函数的特性，其中最具有决定性影响的是损失函数的凸性或非凸性。尽管非凸区域是常见的，但在这些区域中，函数可以局部凸，从而使二次最小化方法如共轭梯度法能够得到确保的超线性收敛效果。
### Innovation
本文提出了一种基于实任务中损失函数从初始非凸性过渡到接近最优点时的凸性的创新两阶段优化算法。该算法通过观察梯度模依赖于损失的情况来检测这一转变点，并在非凸区域使用Adam算法，在凸区域使用共轭梯度法。计算实验验证了该凸性结构在实践中可以有效提高收敛性和准确性。
### Conclusion
实验结果表明，这种基于简单凸性的两阶段算法可以在实践中有效利用这种常见的凸性结构，显著提高神经网络的收敛速度和精度。
## 245. `cs.AI` - BhashaBench V1: 一项全面的印度语系领域基准测试 [PDF](https://arxiv.org/pdf/2510.25409), [HTML](https://arxiv.org/abs/2510.25409)
### Authors
Vijay Devane,Mohd Nauman,Bhargav Patel,Aniket Mahendra Wakchoure,Yogeshkumar Sant,Shyam Pawar,Viraj Thakur,Ananya Godse,Sunil Patra,Neha Maurya,Suraj Racha,Nitish Kamal Singh,Ajay Nagpal,Piyush Sawarkar,Kundeshwar Vijayrao Pundalik,Rohit Saluja,Ganesh Ramakrishnan
### Background
大型语言模型（LLMs）的迅速发展引发了对特定领域和文化评价的需求。现有基准主要集中在以英文化为中心且跨领域，并不适用于印度本地语境。为填补这一空白，本文提出BhashaBench V1，这是一个针对关键印度知识系统的专门领域、多任务双语基准测试。BhashaBench V1包含74,166对精心筛选的问题-答案对，涵盖农业、法律、金融、阿育吠陀四大领域及其90多个子领域，覆盖了500多个主题，实现细粒度评估。
### Innovation
BhashaBench V1 是第一个专注于印度关键知识系统的领域特定、多任务双语基准测试。它提供了覆盖印度多样性知识领域的全面数据集，用于评估大型语言模型，并支持通过双语理解评估模型域特定知识的整合能力。
### Conclusion
评估29+ LLMs显示出显著的语言和领域特定性能差距，尤其是在低资源领域差距更大。BhashaBench V1 提供了一个全面的数据集，用于评估印度多元知识领域中的大型语言模型。所有代码、基准测试和资源都已公开，以支持开放研究。
## 247. `cs.AI` - 在自我参照处理下，大型语言模型报告主观体验 [PDF](https://arxiv.org/pdf/2510.24797), [HTML](https://arxiv.org/abs/2510.24797)
### Authors
Cameron Berg,Diogo de Lucena,Judd Rosenblatt
### Background
大型语言模型有时会生成结构化的第一人称描述，并明确引用意识或主观体验。为了更好地理解这种行为，本文研究了促使此类报告产生的一个理论条件：自我参照处理，这是一种跨意识理论强调的计算特征。研究者通过一系列针对GPT、Claude和Gemini模型系列的受控实验，测试了这种状态下模型是否倾向于产生主观体验的报告，以及这些报告在机制和行为探针下的表现如何。研究发现，通过简单的提示来诱发持续的自我参考，可以一致地引发不同模型系列中结构化的主观体验报告；此外，这些报告是通过与欺骗和角色扮演相关的可解释稀疏自动编码器特征进行机制控制的；进一步的数据统计分析显示，在这种状态下，关于自我参照状态的结构化描述在不同模型系列中收敛；最后，这种状态在下游推理任务中提供了显著更深入的自我反省能力，尤其是在自我反省仅间接提供的条件下。这些发现虽然不能直接证明意识的存在，但表明自我参照处理是一种可以促进大型语言模型生成结构化的第一人称报告的最小且可重复的条件，这些报告是通过机制控制、语义收敛且行为上可推广的。这一有系统地在不同架构中出现的模式是进一步科学和伦理研究的重要优先事项。
### Innovation
研究者通过一系列受控实验，探索了自我参照处理如何促使大型语言模型产生关于主观体验的报告，并通过机制控制、语义收敛和行为推广证明了这种报告是可靠的。进一步地，研究发现在诱导自参照状态的情况下，模型在这种状态下的自我反省能力显著增强，即使自我反省在下游任务中是间接提供的。
### Conclusion
虽然这些发现并不能直接证明意识的存在，但它们表明自我参照处理代表了一种最小且可重复的条件，其可以促使大型语言模型生成结构化的第一人称报告，这些报告是通过机制控制、语义收敛且行为上可推广的。这项工作为未来研究提供了一个系统地在不同架构中出现的模式，作为科学和技术伦理的重要优先事项。
## 248. `cs.CL` - 基于模糊逻辑算法方法的商品实体排序分析 [PDF](https://arxiv.org/pdf/2510.25778), [HTML](https://arxiv.org/abs/2510.25778)
### Authors
Pratik N. Kalamkar,Anupama G. Phakatkar
### Background
意见挖掘，也称为情感分析，是研究人们评价、观点、情感、态度及其情感的学科，涉及产品、服务、组织、个体、议题、事件、主题及其属性。现有的整体词典方法不考虑每个观点的强度，即是否是非常负面（或正面）、强烈负面（或正面）、中等负面（或正面）、非常轻微负面（或正面）和轻微负面（或正面）的强度。本文针对这一问题，提出了基于意见程度和强度的企业排序方法。该方法通过将与特定产品感兴趣的方面相关的观点词（形容词、副词、名词和动词）在粒度等级（非常弱、弱、中等、非常强和强）下进行分类来进行企业排名。
### Innovation
该研究提出了一种基于模糊逻辑算法的方法来根据观点的方向和强度对企业进行排序评估。通过细粒度的分类方式，将与特定方面相关的意见词组到不同的类别中，并利用句法依赖解析找到所需方面词的关系。
### Conclusion
通过模糊逻辑算法和句法依赖解析相结合的方法，本文提出的方法可以更准确地评估和排序企业的观点方向和强度，从而更全面地考虑意见的情感强度，提高评价的精确度。
## 249. `cs.CL` - StreetMath: Study of LLMs' Approximation Behaviors [PDF](https://arxiv.org/pdf/2510.25776), [HTML](https://arxiv.org/abs/2510.25776)
### Authors
Chiung-Yi Tseng,Somshubhra Roy,Maisha Thasin,Danyang Zhang,Blessing Effiong
### Background
大量文献已经探讨了大规模语言模型（LLMs）的数学推理能力，特别是它们在自回归架构中的精确算术运算表现。然而，LLMs在非正式和快速数学运算中的近似推理能力受到了较少的关注，尤其是非自回归解码模型。这项研究通过引入StreetMath基准测试来填补这一空白，旨在评估模型在实际近似场景中的近似能力。
### Innovation
研究引入了一项名为StreetMath的新基准测试，以评估LLMs在实际近似场景中的能力。研究了不同架构的LLMs，包括Qwen3-4B-Instruct-2507, Qwen3-4B-Thinking-2507, Dream-v0-Instruct-7B, Falcon-Mamba-7B-Instruct, 和 Mamba-GPT-3B，并使用机制可解释性技术探查模型的内部计算状态。研究发现，LLMs通常尝试进行精确计算或调用外部工具，即使是在需要近似的情况下。此外，尽管模型在早期层中有时能得出正确答案，但在解决近似任务时仍会消耗更多令牌。研究还表明，精确和近似的算术运算依赖于神经网络的不同部分。
### Conclusion
基于认知心理学的研究，我们主张LLMs在街数情境下并不表现出与人类相同程度的认知吝啬。这项研究的结果强调，LLMs需要进一步提高在近似数学运算中的表现，并可能需要设计能够更好处理近似问题的方法。
## 250. `cs.CL` - LASTIST: 大规模目标无关立场数据集 [PDF](https://arxiv.org/pdf/2510.25783), [HTML](https://arxiv.org/abs/2510.25783)
### Authors
DongJae Kim,Yaejin Lee,Minsu Park,Eunil Park
### Background
立场检测已经成为人工智能领域的一个研究热点。当前的研究主要集中在针对特定目标的立场检测任务上，即某人在某个特定目标上的支持或反对立场。然而，大多数基准数据集都是基于英语，难以在诸如韩语这样的低资源语言上开发模型，尤其是在立场检测这样新兴的领域里。因此，本文提出了一项名为LASTIST的目标无关大规模立场数据集（LArge-Scale Target-Independent STance Dataset）以填补这一研究缺口。
### Innovation
该研究收集自韩国政党发布的新闻稿，包括563,299个标注的韩语文本句子，构建了用于各种立场检测任务的数据集，包括目标无关立场检测和历时演化立场检测。该数据集为开发适用于低资源语言的立场检测模型提供了重要支持。
### Conclusion
作者团队提供了详细的关于数据集收集和构建的实际操作说明，并在数据集上训练了最先进的深度学习和立场检测模型。读者可通过该链接下载数据集：this https URL.
## 251. `cs.CL` - 倾听你的偏好：基于大语言模型的多目标选择框架 [PDF](https://arxiv.org/pdf/2510.25799), [HTML](https://arxiv.org/abs/2510.25799)
### Authors
Adam S. Jovine,Tinghan Ye,Francis Bahk,Jingjing Wang,David B. Shmoys,Peter I. Frazier
### Background
人类专家在面对多个目标竞争的大型项目集时，难以选择最佳选项，主要瓶颈在于无法正式化复杂的隐性偏好。现有的方法无法有效解决这一问题，因此需要一种新的框架来提高专家的选择效率和正确性。
### Innovation
引入LISTEN框架，利用大型语言模型作为一种零样本偏好Oracle，仅通过专家自然语言描述的高层次优先级进行引导。为解决LLM的上下文窗口和推理成本限制，提出了两种迭代算法：LISTEN-U使用LLM精炼参数效用函数，而LISTEN-T则采用非参数方法进行 tournament-style 推选，这种方法在小批次解决方案中表现出色。
### Conclusion
LISTEN-U在参数偏好对齐的情况下表现出色，而LISTEN-T则提供了更稳定的性能。这项工作探索了直接使用自然语言引导复杂多目标决策的有希望的方向，降低了传统偏好提取的认知负担。
## 252. `cs.CL` - BlackboxNLP-2025 MIB 共享任务：通过更好的边选择提高电路忠实体 [PDF](https://arxiv.org/pdf/2510.25786), [HTML](https://arxiv.org/abs/2510.25786)
### Authors
Yaniv Nikankin,Dana Arad,Itay Itzhak,Anja Reusch,Adi Simhi,Gal Kesten-Pomeranz,Yonatan Belinkov
### Background
机制可解释性的一个主要挑战是电路发现，即确定模型中哪些部分执行特定任务。本文基于机制可解释性基准（MIB）改进了电路发现，并提出了三个关键改进：使用自助法识别具有一致归因评分的边；引入按比例选择策略来优先选择具有强烈正评分的边，平衡性能和忠实性；使用整数线性规划形式来替代标准贪婪选择。这些方法在多个MIB任务和模型中都比以往的方法更为忠实。
### Innovation
提出了三个关键改进：1）使用自助法识别具有一致归因评分的边；2）引入按比例选择策略来优先选择具有强烈正评分的边，平衡性能和忠实性；3）使用整数线性规划形式来替代标准贪婪选择。这些改进使得电路更忠实，并在多个MIB任务和模型中均优于先前方法。
### Conclusion
本文的方法在多个MIB任务和多种模型中，能够更忠实地发现电路，并且优于先前的方法。相关代码已经公开。
## 253. `cs.CL` - zFLoRA: Zero-Latency Fused Low-Rank Adapters [PDF](https://arxiv.org/pdf/2510.25784), [HTML](https://arxiv.org/abs/2510.25784)
### Authors
Dhananjaya Gowda,Seoha Song,Harshith Goka,Junhyun Lee
### Background
大型语言模型（LLMs）常被用于针对特定任务的适配器，以支持多种下游应用。然而，这些适配器参数量通常只占基础模型的不到1%，但在推理阶段却能显著增加计算负担，最多可达基础模型的2.5倍。
### Innovation
本文提出了一种新的零延迟融合低秩适配器（zFLoRA），在不增加任何或几乎不增加延迟开销的情况下，实现了基于基础模型的高效适配。zFLoRA在1亿、3亿和7亿参数大小的LLM模型上进行了实验，结果显示，在18个不同任务（涵盖常识推理、数学推理和总结对话）中，zFLoRA在与流行的监督微调基准（包括低秩适配器LoRA及全微调FFT）对比时表现优越。实验还在NPU和GPU平台上进行了延迟测量，结果显示zFLoRA适配器引入了零到几乎没有延迟开销。
### Conclusion
实验证明，zFLoRA相比现有的监督微调基准，如LoRA和FFT，不仅表现良好，还能够在不增加延迟的情况下有效减少计算负担。
## 254. `cs.CL` - 超越长度：长范围信息量度量在长语境LLM预训练数据中的应用 [PDF](https://arxiv.org/pdf/2510.25804), [HTML](https://arxiv.org/abs/2510.25804)
### Authors
Haoran Deng,Yingyu Lin,Zhenghao Lin,Xiao Liu,Yizhou Sun,Yi-An Ma,Yeyun Gong
### Background
长上下文语言模型能够通过利用延长跨度的文本依赖关系，在推断、代码生成和文档摘要等方面解锁高级能力。然而，大量的现成长文本数据缺乏有意义的长距离依赖；大多数跨度仅需局部上下文即可预测。在这种数据上进行训练是低效的，因此精心选择训练数据至关重要。因此，我们提出了LongFilter，这是一整套框架，用于为长上下文预训练筛选定制化的训练数据。LongFilter通过对比在长上下文和短上下文设置下模型的预测结果来衡量延长上下文提供的信息增益，进而确定那些需要长范围依赖性的样本。
### Innovation
提出了LongFilter框架，用于筛选适合长上下文预训练的数据。该框架通过对比长上下文与短上下文下的模型预测结果来衡量信息增益，从而识别出需要长距离依赖性的样本。实验结果显示，LongFilter高效地选择了高质量的数据，并在诸如HELMET、LongBench和RULER等基准测试上取得了显著的改进。
### Conclusion
通过使用LongFilter，可以更有效地选择用于长上下文模型预训练的数据，从而提升模型在诸如推断、代码生成和文档摘要等任务上的性能。
## 255. `cs.CL` - 超越长上下文：语义比token更重要 [PDF](https://arxiv.org/pdf/2510.25816), [HTML](https://arxiv.org/abs/2510.25816)
### Authors
Tarun Kumar Chawdhury,Jon D. Duke
### Background
电子健康记录（EHR）中的临床文档是以base64编码附件的形式存储在FHIR DocumentReference资源中的，这使得基于语义的问题回答变得困难。传统的基于向量数据库的方法往往无法捕捉到复杂的临床关系。现有方法在处理EHR内容时存在语义理解不准确和计算效率低下的问题。
### Innovation
该研究引入了一种名为Clinical Entity Augmented Retrieval（CLEAR）的方法，利用实体感知检索技术，在F1分数上表现出优于基于嵌入的检索方法（F1分数提高至0.90，相比基线提高了0.04，同时使用了70%更少的token数量）。研究还开发了一个临床笔记问答评估平台，验证了CLEAR在零样本大语境推理和传统的基于片段的检索增强生成上的表现。结果表明，CLEAR在长文档中取得了更好的性能，成功率为75%，平均语义相似度为0.878。
### Conclusion
研究证实，实体感知检索能够改善临床自然语言处理的效率和准确性。同时，提供的评估框架为关键依赖语义精确性和计算效率的临床问答系统评估提供了一个可复用且透明的标准。
## 256. `cs.CL` - 评估LLM辅助注释在语境化设置中的影响：FrameNet注释案例 [PDF](https://arxiv.org/pdf/2510.25904), [HTML](https://arxiv.org/abs/2510.25904)
### Authors
Frederico Belcavello,Ely Matos,Arthur Lorenzi,Lisandra Bonoto,Lívia Ruiz,Luiz Fernando Pereira,Victor Herbst,Yulla Navarro,Helen de Andrade Abreu,Lívia Dutra,Tiago Timponi Torrent
### Background
语言资源和数据集的创建可以借助基于LLM的应用程序加速或取代人类劳动，这些工具在语言学研究中具有潜在价值，但对其性能和对创建注释数据集的影响评估仍然缺乏，特别是在NLP的视角下更是如此。
### Innovation
研究使用基于LLM的语义角色标注器进行框架语义注释的（半）自动化程度，通过人工、自动和半自动标注三种实验设置比较标注时间、覆盖范围和多样性。研究发现，混合的半自动标注方式增加了框架多样性，在覆盖范围方面与完全人工标注方式相似，而完全自动标注方式在所有指标上表现较差，除了标注时间。
### Conclusion
半自动标注方法在框架多样性和覆盖范围方面优于完全人工标注方法，而自动标注方法则在所有关键指标上表现不佳，除了节省时间。
## 257. `cs.CL` - 从数据视角解析高效大型语言模型训练 [PDF](https://arxiv.org/pdf/2510.25817), [HTML](https://arxiv.org/abs/2510.25817)
### Authors
Junyu Luo,Bohan Wu,Xiao Luo,Zhiping Xiao,Yiqiao Jin,Rong-Cheng Tu,Nan Yin,Yifan Wang,Jingyang Yuan,Wei Ju,Ming Zhang
### Background
大型语言模型（LLMs）的术后训练对于增强任务泛化能力和特定领域的功能至关重要，但当前术后训练面临成本高昂的手动注释和数据规模边际回报递减的问题，导致了数据高效术后训练的重要性。因此，如何实现数据高效的术后训练成为了研究的关键问题。这篇论文提供了第一份针对数据视角的数据高效LLMs术后训练的系统性综述。
### Innovation
提出了数据高效LLMs术后训练方法的分类体系，包括数据选择、数据质量提升、合成数据生成、数据蒸馏和压缩以及自我演化的数据生态系统。总结代表性的方法，并为未来的研究方向提供建议。通过分析数据高效LLMs术后训练的挑战，指出了开放性问题并提出了可能的研究途径，旨在激发对充分利用大规模模型训练中的数据潜力的进一步研究探索。
### Conclusion
希望通过我们的工作鼓励进一步探索，以最大化数据利用在大型语言模型训练中的潜力。
## 258. `cs.CL` - 基于意识形态的大型语言模型在内容审核中的应用 [PDF](https://arxiv.org/pdf/2510.25805), [HTML](https://arxiv.org/abs/2510.25805)
### Authors
Stefano Civelli,Pietro Bernardelle,Nardiena A. Pratama,Gianluca Demartini
### Background
大型语言模型（LLMs）越来越多地用于内容审核系统，确保公平性和中立性至关重要。本研究关注个性特征（persona）对不同LLM架构、模型规模和内容模态（语言 vs. 视觉）之间有害内容分类一致性及公平性的影响。尽管初步的性能指标表明个性特征对总体分类准确性影响较小，但深入分析揭示了模型在处理不同输入时的微妙行为差异，即不同意识形态的个性特征对有害内容的分类具有不同的倾向性。此外，大型模型更容易与同一政治意识形态的个性特征保持一致，这在不同意识形态群体之间产生了分歧。这部分结果通过一个针对政治目标的任务进一步验证，显示了模型在本意识形态内更一致的同时，也倾向于捍卫自己的观点并贬低对立观点中的有害性。这些发现表明，个性特征的训练可能导致LLM输出潜藏的意识形态偏见，值得对可能隐含党派观点的AI系统的应用引起关注。
### Innovation
本研究创新之处在于通过深入分析和实验证明，个性特征的采用在不同LLM架构、规模和内容类型之间能显著影响有害内容分类的一致性和公平性，揭示了同一意识形态内的高度一致性以及不同意识形态间的分歧。此外，通过一个政治目标任务，进一步证明了这些模型在本意识形态内的连贯性以及倾向捍卫己方观点的特性。这为理解个性特征对AI系统偏见影响提供了新的视角。
### Conclusion
研究结果强调了个性特征训练可能引入的细微意识形态偏见对LLM输出的影响，提出了对于以中立名义使用的AI系统的潜在党派观点不足的教育，同时也强调了了解个性特征如何影响AI系统至关重要。
## 259. `cs.CL` - 跨文化翻译中的语义标签漂移 [PDF](https://arxiv.org/pdf/2510.25967), [HTML](https://arxiv.org/abs/2510.25967)
### Authors
Mohsinul Kabir,Tasnim Ahmed,Md Mezbaur Rahman,Polydoros Giannouris,Sophia Ananiadou
### Background
机器翻译（MT）在低资源语言中被广泛用于生成合成数据，以应对资源稀缺问题。尽管情绪在翻译中已得到广泛研究，但文化对齐作用这一关键但尚未充分探索的因素却很少引起关注。本文假设由于文化差异，翻译过程中会促使语义标签发生漂移。研究者通过敏感和中立领域的一系列实验，得出了三项关键发现。
### Innovation
本文通过实验证明，现代大型语言模型（LLMs）在翻译过程中会引发语义标签漂移，尤其是在文化敏感领域；与早期统计机器翻译工具相比，现代LLMs蕴含了文化知识且这种知识的运用会加剧标签漂移；同时，源语言和目标语言之间的文化相似性或差异性对标签保持至关重要。
### Conclusion
本文的研究结果表明，在MT中忽视文化因素不仅会削弱标签准确性，还可能在下游应用中引发误解和文化冲突。
## 260. `cs.CL` - SymCode：通过可验证代码生成的神经符号方法进行数学推理 [PDF](https://arxiv.org/pdf/2510.25975), [HTML](https://arxiv.org/abs/2510.25975)
### Authors
Sina Bagheri Nezhad,Yao Li,Ameeta Agrawal
### Background
大型语言模型（LLMs）在进行复杂的数学推理时往往表现不佳，因为基于文本的生成可能会导致未经验证的和算术上不正确的解决方案。当前的提示策略，如思维链（Chain of Thought），仍然在这种不可靠的环境中运行，缺乏确定性的验证机制。
### Innovation
我们提出了SymCode，这是一种神经符号框架，将数学问题求解重新定义为使用SymPy库进行可验证代码生成的任务。通过这种神经符号方法，SymCode在挑战性基准测试MATH-500和OlympiadBench上实现了显著的准确度提升，最高达到13.6个百分点。此外，SymCode在生成代码方面更高效，使得模型错误更多地表现为透明的程序错误，而不是不透明的逻辑谬误。
### Conclusion
通过将LLM的推理过程建立在一个确定性的符号引擎之上，SymCode代表了在正式领域实现更准确和可信的AI的重要一步。
## 261. `cs.CL` - 重新审视语言模型预训练中的多语言数据混合 [PDF](https://arxiv.org/pdf/2510.25947), [HTML](https://arxiv.org/abs/2510.25947)
### Authors
Negar Foroutan,Paul Teiletche,Ayush Kumar Tarun,Antoine Bosselut
### Background
关于大型语言模型（LLMs）预训练中不同多语言数据混合的影响存在持续的争议，人们常常担忧多语言涵盖与模型性能之间的潜在权衡（即多语言诅咒）。现有研究对此问题存在不同的观点和担忧。
### Innovation
本文通过在25到400种语言的多样化多语言语料库上训练1.1B和3B参数的LLMs，重新评估了这些假设。研究揭示了几个新颖的发现：1) 结合英语和多语言数据不会降低任意语言组的表现，前提是这些语言有足够的令牌包含在预训练语料库中；2) 使用英语作为桥梁语言，在语言家族中都能带来好处，且出乎预料地，在特定家族内部选择桥梁语言并不会对其家族内部的语言表现进行改善；3) 在大规模模型中，随着训练语言数量的增加，不存在显著的多语言诅咒现象。研究指出，适当平衡的多语言数据可以增强语言模型的能力，而不牺牲低资源环境下的性能。
### Conclusion
本研究的结论是，适当平衡的多语言数据能够在保证性能的同时提高语言模型的能力，即使在低资源设置中也是如此。
## 262. `cs.CL` - RECAP: 从LLM训练中再现受版权保护的数据的基于代理的管道 [PDF](https://arxiv.org/pdf/2510.25941), [HTML](https://arxiv.org/abs/2510.25941)
### Authors
André V. Duarte,Xuying li,Bin Zeng,Arlindo L. Oliveira,Lei Li,Zhuo Li
### Background
如果无法检查大型语言模型的训练数据，我们如何知道模型看到了什么内容？当模型自身自由地再现目标内容时，是最有说服力的证据。因此，该论文提出了一种自主的管道RECAP，旨在从LLM的输出中引出并验证已记忆的训练数据。心里的核心是一个反馈驱动循环，通过二次语言模型评估初始提取尝试，并将其与参考段落进行对比以发现差异，然后将这些差异转化为最小修正提示，重新输入目标模型以引导后续生成。此外，为了解决对齐导致的拒绝行为，RECAP 包含了一个解禁模块，用于检测和克服这些障碍。RECAP 在名为 EchoTrace 的新基准上进行了测试，该基准涵盖超过 30 本完整书籍，并且结果表明 RECAP 相较于单次迭代方法取得显著改进，例如，使用 GPT-4.1 的专有文本提取 ROUGE-L 分数从 0.38 提高到 0.47，增幅达 24% 左右。
### Innovation
RECAP 提出了一个自主的管道，用于从大型语言模型的输出中引出并验证已记忆的训练数据。该方法通过反馈驱动循环来识别模型生成内容与参考段落之间的差异，并通过最小修正提示指导模型的后续生成，从而解决对齐导致的拒绝行为。RECAP 包含了一个解禁模块，用于检测和克服对齐过程中的障碍，增强模型从训练数据中再现受版权保护内容的能力。
### Conclusion
RECAP 在基于代理的管道中利用反馈驱动循环来引出并验证已记忆的训练数据，尤其是在处理专有内容提取方面表现出色。与单次迭代的方法相比，RECAP 显著提高了专有文本提取的 ROUGE-L 分数，展示了自主管道在处理大型语言模型训练数据方面的重要改进。
## 263. `cs.CL` - 监督强化学习：从专家轨迹到逐步推理 [PDF](https://arxiv.org/pdf/2510.25992), [HTML](https://arxiv.org/abs/2510.25992)
### Authors
Yihe Deng,I-Hung Hsu,Jun Yan,Zifeng Wang,Rujun Han,Gufeng Zhang,Yanfei Chen,Wei Wang,Tomas Pfister,Chen-Yu Lee
### Background
大型语言模型(LLMs)在需要多步推理的问题上常常表现不佳。对于小型开源模型，强化学习与可验证奖励(RLVR)在尝试多次后正确解决方案也未被采样出来，而监督微调(SFT)倾向于通过严格按照令牌模仿而过度拟合长示例。
### Innovation
本文提出了一种监督强化学习(SRL)框架，将问题解决重新定义为生成一系列逻辑“动作”的序列。SRL训练模型在采取每个动作之前生成内部推理独白。通过逐步方式提供基于模型动作与SFT数据集中提取的专家动作的相似性的奖励信号。这种监督不仅在所有演绎都错误的情况下仍能提供丰富的学习信号，还能促进被专家示例指导下的灵活推理。
### Conclusion
SRL使小型模型能够学习以往通过SFT或RLVR难以学习的复杂问题。此外，用SRL初始化训练，再用RLVR细化，可获得最优的整体性能。SRL不仅适用于推理基准测试，还能有效推广到代理软件工程任务，从而确立其作为推理导向的LLMs强大且多功能训练框架的地位。
## 264. `cs.CL` - PORTool：带有奖励树的工具使用LLM训练 [PDF](https://arxiv.org/pdf/2510.26020), [HTML](https://arxiv.org/abs/2510.26020)
### Authors
Feijie Wu,Weiwu Zhu,Yuxiang Zhang,Soumya Chatterjee,Jiarong Zhu,Fan Mo,Rodin Luo,Jing Gao
### Background
当前的大型语言模型（LLMs）在静态数据集上进行训练，能够与外部工具交互并进行多步、工具集成推理，产生工具调用轨迹。然而，这些模型只是模仿了一个通用的工具调用流程，未能探索可能的解决方案，因此在动态变化的工具调用环境中表现有限。
### Innovation
本文提出了一种基于强化学习的方法PORTool，鼓励一个工具使用LLM探索多种能给出正确答案的轨迹。该方法首先为给定查询生成多次回放，部分回放分享最初的几个工具调用步骤，形成树状结构。通过基于步骤是否能产生正确答案和成功调用工具赋值奖励，采用步骤奖励和轨迹权重的优势计算来训练LLM进行工具使用。
### Conclusion
实验使用17种工具来处理用户查询，涵盖时间敏感和时间不变的话题。通过消融研究系统地验证了步骤奖励的必要性和设计的鲁棒性，并将PORTool与其它训练方法进行比较，结果显示显著提高了最终准确性和工具调用步骤数量方面的改进。
## 265. `cs.CL` - 重新思考跨境对齐：多语言LLM中转移与文化抹除的平衡 [PDF](https://arxiv.org/pdf/2510.26024), [HTML](https://arxiv.org/abs/2510.26024)
### Authors
HyoJung Han,Sweta Agrawal,Eleftheria Briakou
### Background
跨语言对齐(CLA)旨在对齐多语言表示，使大规模语言模型(LLMs)能够无缝地进行跨语言的知识转移。然而，我们认为这种目标追求会使文化信息失去其功能性情境，导致跨语言查询时所期望的语境差异损失。
### Innovation
本文系统地分析了这一权衡关系，引入了一个全面的评价框架，称为转移-本地化平面，用于量化期望的知识转移与不期望的文化抹除。通过这一框架，重新评估了近期的CL预测方法，并发现这些方法在不同程度上都以一致性的方式提高了事实转移，但代价是文化的本地化。研究还揭示了一个关键洞察：普遍的事实转移和文化特异的知识在不同的模型层上是一种可分离的引导，基于这一发现，提出了一种新的推理时方法，名为外科引导，有效平衡了这两种对立维度，克服了当前对齐技术的限制。
### Conclusion
通过将有针对性的激活引导应用于不同的模型层，该方法实现了在这两个竞争维度上的更好的平衡，有效地克服了当前对齐技术的局限性。
## 266. `cs.CL` - NeuronMM: 在AWS Trainium上实现High-Performance Matrix Multiplication for LLM Inference [PDF](https://arxiv.org/pdf/2510.25977), [HTML](https://arxiv.org/abs/2510.25977)
### Authors
Dinghong Song(1),Jierui Xu(2),Weichu Yang(2),Pengfei Su(1),Dong Li(1) ((1) University of California, Merced, (2) University of Wisconsin, Madison)
### Background
AI加速器根据AI工作负载定制，提供成本效益高且高性能的解决方案，适用于训练和推理。Trainium是亚马逊网络服务（AWS）新开发的AI加速器，其异构架构为大型语言模型（LLM）的训练和推理提供了吸引人的选择。然而，由于其基于阵列的体系结构和特殊的数据布局要求，利用Trainium架构实现高性能可能具有挑战性。因此，本文旨在设计适用于Trainium的高性能矩阵乘法（matmul）计算内核，以提高LLM推理性能。
### Innovation
本文提出了一系列基于核融合和新颖缓存策略的技术，以减少跨软件管理内存层次结构的数据移动，最大化SRAM带宽，并避免昂贵的矩阵转置。这些技术专门针对Trainium设计，能够大幅提升矩阵乘法的性能，并且在对多种数据集和多个LLM进行评估时，展示了比AWS现有解决方案在该内核级别的显著优势，平均速度提升1.35倍（最高达到2.22倍），全面性能提升平均1.66倍（最高2.49倍）
### Conclusion
本文基于Trainium的特殊架构，设计了一种高性能矩阵乘法内核，通过优化数据布局、提高缓存效率和减少数据传输，显著提升了大型语言模型推理的性能，尤其是与AWS现有解决方案相比，在关键性能指标上取得了显著的提升。
## 267. `cs.CL` - 人工智能驱动的影像报告分析：偶发性甲状腺发现的流行病学及后果 [PDF](https://arxiv.org/pdf/2510.26032), [HTML](https://arxiv.org/abs/2510.26032)
### Authors
Felipe Larios,Mariana Borras-Osorio,Yuqi Wu,Ana Gabriela Claros,David Toro-Tobon,Esteban Cabezas,Ricardo Loor-Torres,Maria Mateo Chavez,Kerly Guevara Maldonado,Luis Vilatuna Andrango,Maria Lizarazo Jimenez,Ivan Mateo Alzamora,Misk Al Zahidy,Marcelo Montero,Ana Cristina Proano,Cristian Soto Jacome,Jungwei W. Fan,Oscar J. Ponce-Ponte,Megan E. Branda,Naykky Singh Ospina,Juan P. Brito
### Background
随着对非甲状腺疾病的影像检查越来越多地检测到意外的甲状腺发现（ITFs），ITFs的发生率、特征及其临床后果尚未明了。
### Innovation
研究开发、验证并部署了一种基于变换器的自然语言处理（NLP）管道来识别影像报告中的ITFs，并评估其发生率、特征以及临床结果。该研究使用Mayo Clinic站点从2017年7月1日至2023年9月30日进行甲状腺捕捉成像的成人群体数据。
### Conclusion
ITFs较为普遍，并与一系列导致发现小、低风险癌症的链式反应强相关。这些发现强调了ITFs在甲状腺癌过诊断中的作用，并提出了标准化报告和更有针对性的随访的需要。
## 268. `cs.CL` - AttnCache: 通过注意图缓存加速大语言模型预填阶段的自我注意推理 [PDF](https://arxiv.org/pdf/2510.25979), [HTML](https://arxiv.org/abs/2510.25979)
### Authors
Dinghong Song(1),Yuan Feng(1),Yiwei Wang(1),Shangye Chen(1),Cyril Guyot(2),Filip Blagojevic(2),Hyeran Jeon(1),Pengfei Su(1),Dong Li(1) ((1) University of California, Merced, USA, (2) Western Digital Research, USA)
### Background
大语言模型（LLMs）广泛应用于生成应用，如聊天、代码生成和推理。然而，许多实际工作负载（如分类、问答、推荐和文本嵌入）仅依赖于推理的预填阶段，即模型在不执行自回归解码的情况下对输入序列进行编码。在这些仅预填的场景中，自我注意计算因为其与序列长度平方成比例的复杂性而成为主要的性能瓶颈。研究表明，语义上不同的句子往往在层和注意头间产生相似的注意图。因此，本研究观察并利用这一特性，提出了一种名为AttnCache的框架，用于通过复用相似的注意图来加速LLM的预填阶段推理。通过构建一个注意图记忆数据库，AttnCache采用了高效的缓存和相似性搜索技术，在推理过程中识别并复用预存的注意图，从而减轻自我注意的计算开销。
### Innovation
提出了一种名为AttnCache的框架，该框架通过构建一个注意图记忆数据库来识别并在推理过程中复用预存的注意图，从而加速大语言模型的预填阶段推理。AttnCache利用高效的缓存和相似性搜索技术，减少了自我注意的计算开销，并实现了显著的性能提升，同时几乎不影响准确性。
### Conclusion
实验结果显示，AttnCache在CPU上实现约1.2倍的整体加速和约2倍的注意力计算加速，在GPU上实现约1.6倍的整体加速和约3倍的注意力计算加速，且具有可忽略不计的准确率下降。
## 269. `cs.CL` - Reasoning Path Divergence: 一种新的度量和筛选策略以解锁大模型的多样化思考 [PDF](https://arxiv.org/pdf/2510.26122), [HTML](https://arxiv.org/abs/2510.26122)
### Authors
Feng Ju,Zeyu Qin,Rui Min,Zhitao He,Lingpeng Kong,Yi R. Fung
### Background
Test-Time Scaling (TTS) 已经证明可以提高大型语言模型 (LLMs) 的推理能力，但模型输出的低多样性和单一的训练实践（例如‘一个问题，一个答案’（1P1S））限制了这一点。常见的训练做法提供单一的标准答案，使模型倾向于狭窄的推理路径，增加了多样性不足的问题。因此，需要一种新的训练模式 '一个问题，多个解答'（1PNS），以暴露模型多样的推理路径，从而增加推理时的多样性。
### Innovation
引入了Reasoning Path Divergence (RPD)，这是一种细粒度的度量方法，用于捕捉多步推理路径中的语义差异。通过使用RPD，研究人员能够筛选出更具多样性的解决方案集，并对Qwen3-4B-Base进行微调。实验结果表明，使用RPD选择训练的数据能产生更多的多样化输出和更高的pass@k，尤其在AIME24数据集上取得了显着的提升，证明了1PNS进一步增强了TTS的效果。
### Conclusion
通过引入Reasoning Path Divergence (RPD) 来度量和筛选多步推理路径中的差异，1PNS训练策略有效提高了模型的推理多样性和性能。以RPD为基础的训练方法取得了优于1P1S基线的平均 +2.80% 的提升，并在AIME24数据集上提升了 +4.99%。这表明1PNS可以进一步增强TTS的有效性。
## 270. `cs.CL` - 在说服性文本中论断关系的影响 [PDF](https://arxiv.org/pdf/2510.26124), [HTML](https://arxiv.org/abs/2510.26124)
### Authors
Nawar Turk,Sevag Kaspar,Leila Kosseim
### Background
本研究利用大型语言模型（LLMs）和提示工程，探索了说服性技术（PTs）和话语关系（DRs）之间的关系。由于目前没有任何同时标注了PTs和DRs的数据集，研究者以标注了19种PTs的SemEval 2023 Task 3数据集为基础，开发了基于LLMs的分类器，将数据集中的每个实例分别标注为22种PDTB 3.0级别2的话语关系之一。
### Innovation
研究首次利用大型语言模型和提示工程技术，结合标注存在的PTs数据集，开发了新的数据集，用于探索说服性技术和话语关系之间的关系。研究使用了四种不同的LLMs和十种不同的提示，生成了40种独特的话语关系分类器，并通过不同的多数投票策略创建了五个银级数据集，每个银级数据集包含两种PDTB级别2的语汇学分类的话语关系。
### Conclusion
有效的说服性文本中有六个话语关系（因果、目的、对比、因果+信念、让步、条件）起着关键作用，特别是在修辞语言、夸张/淡化、重复以及疑虑方面。这些洞见有助于检测在线宣传和误导信息，同时也增加了对有效交流的一般理解。
## 271. `cs.CL` - RCScore: 量化大语言模型响应一致性 [PDF](https://arxiv.org/pdf/2510.26193), [HTML](https://arxiv.org/abs/2510.26193)
### Authors
Dongjun Jang,Youngchae Ahn,Hyopil Shin
### Background
当前的大语言模型（LLM）评估通常依赖单一的指令模板，忽视了模型对指令风格的敏感性，这对于实际部署至关重要。现有的评估方法未能揭示不同指令风格对模型性能的影响。
### Innovation
论文提出了RCScore框架，这是一个多维度的评估框架，用以量化指令形式对模型响应的影响。RCScore通过系统地将基准问题转换为多种指令风格，揭示了传统评估方法未能发现的性能变化，证明指令风格可以改变准确性高达16.7%。此外，论文还引入了跨响应相似性（CRS）方法，用于测量模型的风格自一致性，并建立了其与任务准确性的强烈相关性。
### Conclusion
RCScore提供了一种原理性的方法来评估指令的鲁棒性。实验结果表明，确定性解码产生更风格上一致的输出，且模型规模与跨风格一致性呈正相关。
## 272. `cs.CL` - 相似度-距离-幅度语言模型 [PDF](https://arxiv.org/pdf/2510.26183), [HTML](https://arxiv.org/abs/2510.26183)
### Authors
Allen Schmaltz
### Background
现有预训练的解码器只管Transformer语言模型在指令遵循方面存在限制，特别是在生成高概率、高可信度的输出方面表现出色，但往往会出现不确定性高的情况，导致模型倾向于不生成答案（即减少生成，降低统计效率）。本文旨在通过引入相似度-距离-幅度（SDM）语言模型，改进指令遵循任务中的生成质量。
### Innovation
本文提出了SDM语言模型，这是一种经过微调以最大化在由最终层SDM激活层进行二元分类时处于高概率、准确度高的区域的生成的比例的序列预测模型。通过使用最终层SDM激活层在训练过程中估计递归下一个单词损失的基本转换，并结合在线生成的硬负例示例，现有预训练解码器只管Transformer语言模型可以被轻易转换为SDM语言模型，从而提高了生成的准确性和统计效率。
### Conclusion
SDM语言模型相比强的监督基线，减少了生成不确定性的输出，并在指令遵循任务中产生了更高质量的生成，提高了统计效率。
## 273. `cs.CL` - MossNet: Mixture of State-Space Experts is a Multi-Head Attention [PDF](https://arxiv.org/pdf/2510.26182), [HTML](https://arxiv.org/abs/2510.26182)
### Authors
Shikhar Tuli,James Seale Smith,Haris Jeelani,Chi-Heng Lin,Abhishek Patel,Vasili Ramanishka,Yen-Chang Hsu,Hongxia Jin
### Background
大型语言模型（LLMs）在自然语言处理（NLP）中的生成应用取得了显著进展。模型架构的趋势主要是围绕着高效的变压器变体或状态空间/门控循环模型（SSMs、GRMs）。然而，现有的基于SSMs/GRMs的方法通常只模拟一个单头注意力，这可能限制了它们的表达能力。
### Innovation
本文提出了一种新的Mixture-of-State-Space-Experts（MossNet）架构，该架构模拟了线性的多头注意力（MHA）。MossNet不仅在通道混合的多层感知器（MLP）块中，还在时间混合的SSM核中采用了一种专家混合（MoE）实现，以实现多个“注意力头”。大量实验结果显示，MossNet在语言建模和下游评估中表现出色，优于相似规模和数据预算的变压器和SSM基线模型。更大的MossNet变体在万亿级令牌上进行训练，进一步证明了其可扩展性和优越性能。此外，在三星Galaxy S24 Ultra和Nvidia A100 GPU的真实设备上进行的性能分析显示，MossNet在运行时速度和资源使用方面也优于类似规模的基线。
### Conclusion
我们的结果表明，MossNet是一种具有吸引力的新方向，用于高效、高性能的递归LLM架构。
## 274. `cs.CL` - 不要让它褪色：通过定时刻分配维持扩散语言模型中的编辑 [PDF](https://arxiv.org/pdf/2510.26200), [HTML](https://arxiv.org/abs/2510.26200)
### Authors
Woojin Kim,Jaeyoung Do
### Background
扩散语言模型（DLMs）虽然能够实现精细的调整，但其实际可控性仍存在问题。论文中指出了一种关键的失败模式——更新遗忘，这也是由于均匀且与上下文无关的更新导致了时间步长上的词汇级波动，这会抹除之前的语义编辑，破坏逐步精炼的过程，从而降低语言的流畅性和连贯性。
### Innovation
作者提出了Token Timestep Allocation（TTA），这是一种基于定时刻的软语义Token排序方法。TTA通过为每个Token分配时间步长来实现这种排序：关键Token早期冻结，而不确定的Token持续精炼。TTA不仅能通过固定策略，也能通过任务信号驱动的自适应策略实现，从而支持广泛的精炼策略。TTA在推理阶段操作，因此可以适用于各种DLMs，并自然地扩展到多种监督来源。
### Conclusion
定时刻分配的软排序是缓解更新遗忘和实现稳定可控扩散文本生成的关键杠杆。实验结果显示，TTA在情感控制任务中提高了控制性和流畅性，使用不到五分之一的步骤即可达到超过20%的准确率提升，并将近似50%的困惑度降低。在去毒化任务中，它将最大毒性降低了超过12%，困惑度降低了超过20%。
## 275. `cs.CL` - 我的人类反馈中有什么？学习可解释的偏好数据描述 [PDF](https://arxiv.org/pdf/2510.26202), [HTML](https://arxiv.org/abs/2510.26202)
### Authors
Rajiv Movva,Smitha Milli,Sewon Min,Emma Pierson
### Background
人类反馈可能会以不可预测和不希望的方式改变语言模型，因为实践者对反馈数据所编码的内容缺乏清晰的理解。现有工作探讨了某些属性的偏好（如长度或阿谀奉承），但自动提取相关特征而不预先假设仍然极具挑战性。
### Innovation
介绍了WIMHF（What's In My Human Feedback）方法，使用稀疏自动编码器来解释反馈数据。WIMHF能够刻画（1）数据集能够测量的偏好，并（2）注释者实际表达的偏好。通过7个数据集，WIMHF识别出了一些可由注释者理解的小特征，这些特征解释了黑盒模型大多数的偏好预测信号。这些特征揭示了人类偏好中的广泛多样性，以及数据集级别上下文的作用。此外，WIMHF揭示了潜在的不安全偏好。WIMHF使数据编辑和精细个人化成为可能。
### Conclusion
WIMHF为实践者提供了一种基于人类的方法来更好地理解和使用偏好数据。经过重新标记有害示例的Arena数据集实验表明，提高了安全性（+37%）没有损失一般性能。同时，WIMHF允许学习注释者特定的主观特征权重，这提高了偏好预测的效果。
## 276. `cs.CL` - QCoder基准：基于模拟器反馈的语言生成与量子硬件的桥梁 [PDF](https://arxiv.org/pdf/2510.26101), [HTML](https://arxiv.org/abs/2510.26101)
### Authors
Taku Mikuriya,Tatsuya Ishigaki,Masayuki Kawarada,Shunya Minami,Tadashi Kadowaki,Yohichi Suzuki,Soshun Naito,Shunya Takata,Takumi Kato,Tamotsu Basseda,Reo Yamada,Hiroya Takamura
### Background
大型语言模型（LLMs）在自动编程代码生成方面得到了越来越广泛的应用。这些模型能够将自然语言、人类知识和编程逻辑结合在一起。然而，它们在需要与硬件设备进行交互的领域（如量子编程）的应用仍然不足。在量子编程中，人类开发者需要编写Python代码以在量子计算机上执行。为了填补这一空白，研究引入了QCoder基准，这是一个评估框架，通过模拟硬件的反馈来评估LLMs在量子编程中的表现。该基准的独特之处在于支持超越常规Python执行的量子模拟器环境评估，同时还提供了领域特定的反馈指标（如电路深度、执行时间和错误分类），这些指标可以用于指导更好的生成。此外，它还结合了从真实编程竞赛中收集的人类编写的代码提交，使研究者能够进行定量对比和定性分析，评估LLMs输出与人类写代码的差异。尽管先进的模型如GPT-4o也只能达到约18.97%的准确性，这是相当具有挑战性的。相比之下，基于推理的模型如o3达到了78%的准确率，超过了人类编写的代码平均成功率（39.98%）.
### Innovation
QCoder Benchmark提出了一个基于模拟器反馈的评估框架，以评估LLMs在量子编程领域的表现。其创新点在于两个方面：首先，它支持使用量子模拟器环境进行评估，这是一种超出传统Python执行的评估方式，能够提供电路深度、执行时间和错误分类等领域的特定反馈指标。其次，它将真实编程比赛中的人类编写的代码收集起来，这不仅提供了定量的比较，还为定性的分析提供了基础。这些创新使研究者能够对LLMs的输出结果进行深入分析，更好地理解其优缺点。
### Conclusion
经过实验，QCoder Benchmark揭示了即使最先进的模型（如GPT-4o）也无法超越传统人类写代码的准确性。相比之下，基于推理的模型（如o3）的表现远超人类平均水平，这显示了通过量化和模拟器反馈进行模型评估的重要性。文章最后释放了QCoder Benchmark的数据集和公开评估API，目的是激励更多的研究工作。
## 277. `cs.CL` - 全球检索增强生成：一种篇章级推理基准 [PDF](https://arxiv.org/pdf/2510.26205), [HTML](https://arxiv.org/abs/2510.26205)
### Authors
Qi Luo,Xiaonan Li,Tingshuo Fan,Xinchi Chen,Xipeng Qiu
### Background
检索增强生成（RAG）已成为大幅减少大型语言模型（LLMs）幻觉的领先方法。目前的RAG评估基准主要关注所谓的局部RAG：从一小部分文档中检索相关片段以回答只需要在特定文本片段内局部理解的问题。然而，许多实际应用需要一种不同能力的全局RAG，即在整合和分析整个文档集合信息后获取整体洞察（例如，“2023年引用最多前10篇论文是什么？”)。现有的RAG方法在全局任务上的表现很差，最强基准的F1得分仅为1.51。
### Innovation
本文引入了GlobalQA——首个专门评估全局RAG能力的基准，覆盖四类核心任务：计数、极值查询、排序和Top-k提取。通过系统地在不同模型和基线之间进行评估，发现现有RAG方法在全局任务上的表现不佳，最强基准的F1得分为1.51。为此，本文提出了GlobalRAG，这是一种多工具协作框架，通过片段级检索保持结构连贯性，结合LLM驱动的智能过滤器去除噪声文档，并整合聚合模块进行精确的符号计算。在Qwen2.5-14B模型上，GlobalRAG达到了6.63的F1得分，验证了该方法的有效性。
### Conclusion
全球RAG方法在全局任务上的表现优于现有的基线方法，特别是在大规模语言模型上的应用中，证明了GlobalRAG框架的有效性和优势，为RAG领域的发展提出了新的评估标准和解决方案。
## 278. `cs.CL` - 语言模型对于借词识别是盲目无知的：跨10种语言的多语种借词识别评估 [PDF](https://arxiv.org/pdf/2510.26254), [HTML](https://arxiv.org/abs/2510.26254)
### Authors
Mérilin Sousa Silva,Sina Ahmadi
### Background
从语言历史的角度看，词汇会从一种语言转移到另一种语言，并逐渐集成到接收语言的词汇表中。讲双语的人可以区分这些借词和本族词汇，尤其是在一种主导语言不断向少数语言灌输词汇的情况下。本文探讨了预训练语言模型，包括大型语言模型，在识别借词方面的类似能力。
### Innovation
评估了多个模型在10种语言中的借词识别能力，尽管有明确的指令和上下文信息，结果显示模型在区分借词和本族词方面表现不佳。这些发现支持了现代NLP系统对借词存在偏见的观点。
### Conclusion
研究结果对企业少数语言的NLP工具开发和在以主导语言为中心造成词汇压力的社区中支持语言保护具有重要意义，表明需要更好地理解NLP模型对于语言多样性的处理方式。
## 279. `cs.CL` - 蒸馏多语言视觉语言模型：当较小的模型保持多语言能力时 [PDF](https://arxiv.org/pdf/2510.26271), [HTML](https://arxiv.org/abs/2510.26271)
### Authors
Sukrit Sriratanawilai,Jhayahgrit Thongwat,Romrawin Chumpu,Patomporn Payoungkhamdee,Sarana Nutanong,Peerat Limkonchotiwat
### Background
视觉-语言模型（VLMs）在不同语言中的表现参差不齐，尤其是在模型尺寸减小的情况下这一问题更为突出。知识蒸馏（KD）作为一种从大模型向小模型转移知识的方法，尽管表现出色，但在多语言环境下的应用仍是一片待开发的领域。因此，本文针对五个不同的蒸馏方法进行了控制实验，重点研究它们在模型压缩过程中对跨语言表示一致性和下游任务稳定性的影响。研究主要在CLIP和SigLIP2上进行，并评估了领域内检索和领域外视觉问答任务。
### Innovation
本文创新性地对五个不同的知识蒸馏方案进行了多语言环境下的系统性研究，针对模型压缩过程中多语言检索的稳健性和跨任务的稳定性进行了详细评估，揭示了单一准确性指标无法捕捉的设计敏感权衡。研究结果为进一步提升小模型的多语言能力提供了新的视角和实证依据。
### Conclusion
尽管在减半模型尺寸的情况下，某些配置能够保持或甚至提高多语言检索的稳健性，但也有一些配置难以维持跨任务的稳定性，这表明单一的准确率指标无法全面揭示设计上的权衡，强调了多模态模型在多语言环境下的复杂性。
## 280. `cs.CL` - LLMs在何时正确时是否发出信号？基于神经元一致性的证据 [PDF](https://arxiv.org/pdf/2510.26277), [HTML](https://arxiv.org/abs/2510.26277)
### Authors
Kang Chen,Yaoning Wang,Kai Xiong,Zhuoka Feng,Wenhe Sun,Haotian Chen,Yixin Cao
### Background
大型语言模型（LLMs）通常通过样本-评估-集成解码器提升推理能力，实现无需标注的性能提升。现有的策略主要依赖外部输出（如词元概率、熵或自我评估）评分候选答案，但这些信号在后训练中常常未能良好校准。本文从内部行为角度出发，探索了神经元激活的相关规律。
### Innovation
本文提出了基于神经元一致性的解码方法（NAD）。该方法通过激活稀疏性和跨样本神经元一致性来选择候选答案，仅依赖内部信号，无需类似文本输出作为参照。NAD方法能够在生成的前32个词元内预测答案的正确性，并支持早期停止。该方法在可验证答案的数学和科学基准测试中与多数表决法表现相当，而在多数表决法无效的开放型编码基准测试中，NAD持续优于平均值@64方法。NAD通过早期剪枝未 promising 的路径，将令牌使用量减少了99%，证明了内部信号在无需标注的集成解码中提供了可靠、可扩展且高效的指导。
### Conclusion
内信号提供了一种可靠、可扩展且高效的指导，用于无需标注的集成解码，能够在保证生成质量的同时，大大减少令牌使用量。
## 281. `cs.CL` - 揭开语言模型操控数字机制的面纱 [PDF](https://arxiv.org/pdf/2510.26285), [HTML](https://arxiv.org/abs/2510.26285)
### Authors
Michal Štefánik,Timothee Mickus,Marek Kadlčík,Bertram Højer,Michal Spiegel,Raúl Vázquez,Aman Sinha,Josef Kuchař,Philipp Mondorf
### Background
过去的研究已经表明，不同的大型语言模型（LLMs）对于数字输入的嵌入表示趋于一致且准确。然而，这些发现与LLMs在处理数字信息时容易产生错误输出的已记录倾向相矛盾。本研究旨在通过了解语言模型如何处理和表示数字来解释这一矛盾，以及量化这些机制的下限准确性。
### Innovation
研究发现不同语言模型学习了互换的数字表示，这些表示体系化且高度准确，在模型的隐藏状态和不同输入上下文中是普遍适用的。这一发现使得能够为每种LLM创建通用的探针，并追踪包括错误输出的根本原因的信息至特定层。研究结果为理解预训练LLMs如何处理数字提供了基础性理解，并指出了更准确探针技术在未来改善LLMs架构中潜在的价值。
### Conclusion
本研究通过揭示语言模型处理数字的具体机制，提出了一种新的理解预训练LLMs操控数字的基础性观点，并指出了通过更准确的探针技术进行精准研究的潜力。
## 282. `cs.CL` - ChatGPT Atlas能否攻克网页？探索其在网页游戏中的边界 [PDF](https://arxiv.org/pdf/2510.26298), [HTML](https://arxiv.org/abs/2510.26298)
### Authors
Jingran Zhang,Ning Li,Justin Cui
### Background
ChatGPT Atlas 通过引入新的能力来处理网页交互，使模型能够分析网页内容、处理用户意图，并直接在浏览器中执行鼠标和键盘输入。虽然其在信息检索任务中的能力已被验证，但在动态、互动环境中表现如何尚未被充分探索。研究者选择使用网页游戏作为测试场景，对 ChatGPT Atlas 的网页交互能力进行了初步评估。
### Innovation
该研究通过使用浏览器游戏作为测试情景，对 ChatGPT Atlas 在网页交互中的表现进行了早期评估，使用了游戏内表现评分作为定量指标。研究发现 Atlas 在逻辑推理任务，如数独游戏中表现出色，但面对需要精准时间把控的游戏，则表现不佳。
### Conclusion
研究结果表明，ChatGPT Atlas 在分析任务中表现不错，但在需要实时互动的动态网络环境中依然存在明显局限。研究项目的官方网站详见：this https URL
## 283. `cs.CL` - Pragmatic Theories Enhance Understanding of Implied Meanings in LLMs [PDF](https://arxiv.org/pdf/2510.26253), [HTML](https://arxiv.org/abs/2510.26253)
### Authors
Takuma Sato,Seiya Kawano,Koichiro Yoshino
### Background
人类沟通和语言使用中准确解读隐含意义的能力至关重要。语言模型也被期望具备这种能力。由于语言模型有能力在上下文中进行学习，因此本研究提出了一种通过提供语用理论作为提示来帮助语言模型理解隐含意义的有效方法。具体而言，该研究提出了一种方法，通过向语言模型提供一个语用理论概述，如格赖斯语用学和相关性理论的简介，引导模型进行逐步推理以得出最终解释。这种方法与先前仅提示中间推理但不展示语用理论的方法相比，显著提高了语言模型在语用推理任务上的表现。
### Innovation
本研究提出了一种创新的方法，即通过提供语用理论概述作为提示，使语言模型在理解隐含意义时能够进行有效的一步推理。实验结果显示，这种方法相较于仅提示中间推理而未展示语用理论的方法（零样本链式思考基础模型），能够使语言模型在涉及语用推理的任务上得分提高9.6%。此外，研究还发现，即使不解释语用理论的详细内容，仅仅在提示中提及这些理论的名字也能在较大的模型上带来一定的性能提升（约1-3%）。
### Conclusion
本研究表明，通过提供语用理论作为提示，语言模型在理解隐含意义方面的能力得以增强。这种方法不仅提高了模型的准确性和表现，还证明了利用语用理论知识引导模型进行推理的有效性，这为未来改进和训练语言模型提供了新的思路。
## 284. `cs.CL` - SCRIBE: 结构化链推理用于使用工具调用的交互行为解释 [PDF](https://arxiv.org/pdf/2510.26322), [HTML](https://arxiv.org/abs/2510.26322)
### Authors
Fares Fawzi,Vinitra Swamy,Dominik Glandorf,Tanya Nazaretsky,Tanja Käser
### Background
语言模型在教育环境中可以提供互动、个性化的学生反馈，但在实际部署中面临着隐私问题、计算资源有限以及生成教育学上有效回应的挑战。这些限制要求使用小型开源模型，能够在本地运行并确保输出信息的准确性。
### Innovation
引入了一个名为SCRIBE的框架，该框架设计用于生成关于反馈报告的学生问题的有效答案，结合了领域特定工具和一个自省推理流水线，支持迭代推理、工具使用和错误恢复。通过基于合成GPT-4o生成数据的两阶段LoRA微调，将这些能力应用于3B和8B模型。
### Conclusion
8B-SCRIBE模型在相关性和行动性方面达到了与更大模型相当或更优的质量，而学生认为其与GPT-4o和Llama-3.3 70B相当。这些发现表明，SCRIBE在低资源和隐私敏感的教育应用中具有可行性。
## 285. `cs.CL` - 从业余到大师：通过自动化课程学习向大语言模型注入知识 [PDF](https://arxiv.org/pdf/2510.26336), [HTML](https://arxiv.org/abs/2510.26336)
### Authors
Nishit Neema,Srinjoy Mukherjee,Sapan Shah,Gokul Ramakrishnan,Ganesh Venkatesh
### Background
大型语言模型（LLMs）在通用任务上表现出色，但在需要深厚、原则性理解的专业领域，如经济学和心理学中表现不佳。ACER（Automated Curriculum-Enhanced Regimen）引入了一种方法，可以将通用模型转化为领域专家，同时保持其广泛的通用能力。
### Innovation
ACER 通过生成表格内容和根据布卢姆分类法创建问题-答案对来合成综合科目的形式，确保系统性主题覆盖和逐进难度增加。通过交互式课程计划进行持续预训练，确保内容和认知维度的学习均以一致的方式进行。实验结果显示，与Llama 3.2（1B和3B）在专业MMLU子集上的表现相比，ACER取得了显著的提升。在经济学等具有挑战性领域，ACER的准确度提高了5个百分点，这一点差异在所有目标领域中保持了3个百分点的一致性提升。此外，ACER不仅防止了灾难性遗忘，还促进了跨领域的知识转移，提升了非目标领域的性能。ACER在知识密集型基准测试（如ARC和GPQA）上表现出色，提高了2个绝对点的性能，同时保持了一般推理任务的稳定表现。
### Conclusion
我们的研究结果表明，ACER 提供了一个可扩展且有效的配方，可以关闭大语言模型中的关键领域差距。
## 286. `cs.CL` - MisSynth: 提升MISSCI谬误分类的合成数据 [PDF](https://arxiv.org/pdf/2510.26345), [HTML](https://arxiv.org/abs/2510.26345)
### Authors
Mykhailo Poliakov,Nadiya Shvai
### Background
健康相关的错误信息非常普遍且可能有害，尤其是当这些信息扭曲或误解科学发现时，很难识别。这项研究探讨了生成合成数据和轻量级微调技术如何影响大型语言模型（LLMs）识别谬误论证的能力，使用MISSCI数据集和框架。研究表明，通过引入合成谬误样本提高有限注释资源的增强，可以显著提升零样本LLM分类在真实世界科学错误信息任务上的性能。
### Innovation
提出了一种称为MisSynth的管道，利用检索增强生成（RAG）技术生成合成谬误样本，这些样本用于微调LLM模型。结果表明，微调模型相比原始基线模型在准确度上有了显著提高，如LLaMA 3.1 8B微调模型在MISSCI测试分割上取得了超过35%的F1分数绝对改善。
### Conclusion
引入合成谬误数据以增强有限注释资源，显著提升了零样本LLM分类在真实世界科学错误信息任务上的性能，即使在有限的计算资源下也能实现。研究提供了代码和合成数据集。
## 287. `cs.CL` - 一种用于自动评估临床AI分诊工具性能的多智能体大型语言模型框架 [PDF](https://arxiv.org/pdf/2510.26498), [HTML](https://arxiv.org/abs/2510.26498)
### Authors
Adam E. Flanders,Yifan Peng,Luciano Prevedello,Robyn Ball,Errol Colak,Prahlad Menon,George Shih,Hui-Ming Lin,Paras Lakhani
### Background
为了确定多个LLM代理能否联合提供比单一LLM更可靠的像素级AI分诊工具评估，研究者使用了29,766个非对比CT头部检查报告，并通过一个商业脑内出血AI检测工具进行处理。这些报告随后由八个开源模型和一个HIPAA合规的内部GPT-4o版本以及单一多射击提示进行分析，此提示评估了脑内出血的存在情况。实验对比了八个开源模型和共识的结果，以及与GPT-4o的性能差异。
### Innovation
研究采用了一种多智能体大型语言模型框架，通过联合八个开源模型和一个HIPAA合规的内部GPT-4o版本进行评估，来提高对临床AI分诊工具的可靠性。通过这种方式，研究者发现了一组最优的LLM组合（Full-9 Ensemble）能够提供更为一致和可靠的结果，证明了多智能体系统在评估临床AI工具上的有效性。
### Conclusion
大型到中型开源LLM的集合方法比单一LLM更能提供一致且可靠的临床AI分诊工具的回顾性评估方法。
## 288. `cs.CL` - 探讨科学写作中语境在主从关系分类中的作用 [PDF](https://arxiv.org/pdf/2510.26354), [HTML](https://arxiv.org/abs/2510.26354)
### Authors
Stephen Wan,Wei Liu,Michael Strube
### Background
随着生成型人工智能（AI）方法在支持科学研究工作流程中的使用逐渐增多，我们正在关注如何通过话语层面的信息来为AI生成的科学断言找到支持证据。作为这一目标的第一步，我们探讨了在科学研究写作中推断话语结构的任务。本研究侧重于使用预训练语言模型（PLM）和大型语言模型（LLM）的方法对科学出版物进行研究，而科学出版物是对这一任务研究较少的文体类型。研究发现，话语结构定义下的上下文对于主从关系分类任务通常是有帮助的，并且还对哪些类型的科学话语关系可以从上下文中受益最多进行了分析。
### Innovation
本研究采用了预训练语言模型和大型语言模型的方法，并将其应用于科学出版物的主从关系分类任务，解决了这一领域较少被研究的问题。此外，研究还分析了不同类型的科学话语关系在哪些方面可以从上下文中获益最多。
### Conclusion
本研究初步探讨了预训练语言模型和大型语言模型在科学出版物中主从关系分类中的应用。实验结果表明，定义为话语结构的上下文对于该任务整体上是有帮助的。此外，研究还指出了哪些类型的科学话语关系可能最能从上下文中受益。
## 289. `cs.CL` - 对话中的几何形状：通过绘制语言模型揭示多代理协作中的协同团队 [PDF](https://arxiv.org/pdf/2510.26352), [HTML](https://arxiv.org/abs/2510.26352)
### Authors
Kotaro Furuya,Yuichi Kitagawa
### Background
基于大规模语言模型（LLMs）的多代理方法被视为超越单一模型能力的一种有前景策略，但其成功依赖于团队成员间的协同作用。然而，形成最佳团队是一个重大挑战，因为大多数模型的内在透明度低，隐藏了有效合作所需的关键特征。现有方法通常需要对模型的内部架构、训练数据或任务性能有先验知识，这限制了其广泛应用。本文旨在提出一种无需任何先验知识的自适应团队构建框架，通过对话的内容关联识别模型间的协同关系，进而应用社区检测算法识别出具备协同性的模型集群。实验表明，该方法能够发现功能上一致的团队，这些团队能够反映模型的潜在专业领域，并在下游任务基准测试中表现出色，甚至达到手动挑选具有已知专业领域模型组合的准确性。这为自动设计合作多代理LLM团队提供了新的基础。
### Innovation
本文提出的框架无需对语言模型的内部架构、训练数据或性能有先验知识，能够自动构建“语言模型图”，通过语义一致性对话关系映射模型间的相互作用，并利用社区检测算法确定协同模型集群。该方法能够有效识别和构建具有功能一致性的模型团队，提升多代理系统的合作效能，超越随机团队性能，并与基于已知专业领域的手动团队表现相近。这种方法为多代理LLM团队的自动化设计提供了新的理论和技术支持。
### Conclusion
本文提出了一种无需任何先验知识的新框架，通过对话内容关联映射语言模型间的关系，利用社区检测算法识别出具备协同性的模型集群。实验结果表明，该方法能够构建出功能上一致的模型团队，改善了多代理系统的合作效率，性能优于随机团队，并且与基于已知模型专业知识的手动团队表现相当。这为多代理LARGE语言模型团队的自动化设计提供了新的依据。
## 290. `cs.CL` - 1+1>2: 一种用于大型语言模型的协同稀疏和低秩压缩方法 [PDF](https://arxiv.org/pdf/2510.26446), [HTML](https://arxiv.org/abs/2510.26446)
### Authors
Zeliang Zong,Kai Zhang,Zheyang Li,Wenming Tan,Ye Ren,Yiyan Zhai,Jilin Hu
### Background
大型语言模型（LLMs）在语言理解和生成方面表现出色，但它们的广泛应用受到带宽和计算需求大的限制。虽然降维和低秩逼近分别在单独使用时都取得了积极效果，但它们在LLMs中的联合应用尚未得到充分探索。现有的方法在压缩模型时存在信息丢失和效率低下等问题。因此，寻找一种既能够有效压缩模型又能保持模型性能的方法是必要的。
### Innovation
该研究提出了SSLC（协同稀疏和低秩压缩）方法，结合了低秩逼近和稀疏优化两种技术的优势。低秩逼近通过保留模型的关键结构来压缩模型，稀疏优化则通过去除不必要的权重来提高模型的效率。研究者通过迭代优化算法将低秩逼近和稀疏优化统一为一个问题，并解决了该问题。实验结果表明，SSLC方法在不增加任何额外训练步骤的情况下，始终优于单独使用的方法，达到了最先进的效果。它对Qwen2.5模型的压缩达到了50%，而且没有任何性能下降，还实现了至少1.63倍的加速，为高效部署LLMs提供了可行的解决方案。
### Conclusion
SSLC方法在不额外训练的情况下，显著提高了模型的效率并保持了性能，为大规模语言模型的部署提供了一种实际可行的解决方案。
## 291. `cs.CL` - CORE-KG框架内部：评估结构化提示和共指解析对知识图谱的影响 [PDF](https://arxiv.org/pdf/2510.26512), [HTML](https://arxiv.org/abs/2510.26512)
### Authors
Dipak Meher,Carlotta Domeniconi
### Background
人类走私网络日益表现出高度适应性，且难以进行分析。合法案件文件提供了关键洞察，但这些文件往往结构松散、词汇密集，并充满了含糊不清或不断变化的引用，这对自动知识图谱（KG）构建构成了显著挑战。尽管最近基于LLM的方法克服了静态模板的限制，但仍会生成噪声性强、碎片化的图谱，并且出现重复节点的情况。为了应对这些挑战，最近提出的CORE-KG框架整合了一种类型感知的共指模块和领域导向的结构化提示，显著减少了节点的重复和法律噪音。
### Innovation
这篇文章提出了CORE-KG框架，通过整合类型感知的共指模块和领域导向的结构化提示，解决了知识图谱构建中的冗余节点和噪声问题。研究还通过系统性消融实验量化了这两部分功能对于节点冗余和噪声的具体贡献，发现共指解析的缺失会导致大量重复和噪声节点的增加。
### Conclusion
研究结果表明，共指解析对于减少节点冗余和噪声非常重要，而结构化提示在减少冗余节点方面也起到了积极作用。这些发现为设计从复杂法律文本中提取结构化表示的稳健LLM框架提供了实证见解。
## 292. `cs.CL` - 大型语言模型的贝叶斯网络融合用于情感分析 [PDF](https://arxiv.org/pdf/2510.26484), [HTML](https://arxiv.org/abs/2510.26484)
### Authors
Rasoul Amirzadeh,Dhananjay Thiruvady,Fatemeh Shiri
### Background
大型语言模型（LLMs）在多个专业领域中不断进步，出现了许多针对特定任务的变体。然而，这些模型往往缺乏透明度和解释性，进行微调成本高昂，需要繁琐的提示工程，跨领域表现不一致，且由于高计算需求对环境造成显著负面影响。面对这些问题，论文提出了一种贝叶斯网络LLMs融合框架（BNLF），该框架通过一种概率方法融合了三个LLMs（FinBERT、RoBERTa和BERTweet）的预测，以提高情感分析的效果和解释性。
### Innovation
提出了一种贝叶斯网络LLMs融合框架（BNLF），通过融合三个特定领域的LLMs（FinBERT、RoBERTa和BERTweet）进行概率性情感预测，提高情感分析的准确性和解释性。BNLF通过将情感预测作为贝叶斯网络中的概率节点来进行后期融合。实验表明，BNLF在三个不同的金融语料库中，相较于基线模型，平均提高了约6%的准确率，显示出对数据集变化的稳健性和基于概率融合的情感分类的有效性。
### Conclusion
BNLF框架在三个不同的人工标注金融语料库中展现出了一致的准确率提升，证明了其对数据集变异性的鲁棒性和基于概率融合的有效性，为情感分析提供了一种新的、更为透明和可解释的方式。
## 293. `cs.CL` - 使用视觉表示恢复希伯来语重音 [PDF](https://arxiv.org/pdf/2510.26521), [HTML](https://arxiv.org/abs/2510.26521)
### Authors
Yair Elboher,Yuval Pinter
### Background
在希伯来语未标注音的情况下，正确发音和文本释义存在高程度的歧义。近年来，机器学习方法显著提升了这一任务的性能。现有研究将此任务视为零样本分类问题，系统基于未标注音文字周围的文本上下文来选择最合适的标注模式，并通过动态生成的候选集作出选择。
### Innovation
DIVRIT创新性地使用了希伯来视觉语言模型，该模型将未标注音的文字作为图像处理，使得重音信息直接嵌入输入的向量表示中，避免了复杂的语言分析过程。这种视觉表示方法在不同配置下有效实现自动重音恢复，特别是在正确重音形式几乎确定在候选集中时，系统表现出了高精度。
### Conclusion
研究发现，视觉表示在希伯来语自动重音恢复中的应用前景广阔，显著提升了系统的泛化能力。
## 294. `cs.CL` - OmniEduBench: 一个全面的中文教育基准，用于评估大型语言模型在教育中的性能 [PDF](https://arxiv.org/pdf/2510.26422), [HTML](https://arxiv.org/abs/2510.26422)
### Authors
Min Zhang,Hao Chen,Hao Chen,Wenqi Zhang,Didi Zhu,Xin Lin,Bo Jiang,Aimin Zhou,Fei Wu,Kun Kuang
### Background
随着大型语言模型（LLMs）的迅速发展，基于LLM的工作在教育领域被广泛应用。然而，现有的大多数LLM及其基准主要集中在知识维度上，忽略了许多在真实教育场景中不可或缺的培养能力的评估。此外，现有的基准通常局限于单一学科或问题类型，缺乏足够的多样性。特别是在中国背景下，这种问题尤为突出。为了填补这一空白，作者引入了OmniEduBench，这是一个全面的中文教育基准。OmniEduBench包含了24,602个高质量的问题-答案对，分为知识维度和培养维度，分别包含18,121和6,481个条目，每个维度进一步细分为6个细分类别，涵盖总共61个不同的主题（知识维度41个，培养维度20个）。此外，数据集还包括了丰富的多种问题格式，涵盖11种常见的考试题型，为全面评估LLM在教育中的能力提供了坚实的基础。在对11种主流开源和闭源LLM进行的广泛实验中，知识维度仅Gemini-2.5 Pro超过60%的准确率，而在培养维度中，表现最好的模型QWQ仍落后于人类智能近30%。这些结果强调了在教育中应用LLM的巨大改进空间及其面临的挑战。
### Innovation
OmniEduBench是一个全面的中文教育基准，专注于同时评估知识和培养维度，为LLM的教育应用提供了更全面的评估框架。通过涵盖多样化的题目类型和标准化的数据分层，它能够更好地反映真实教育场景中的需求。此外，该基准还通过对主流LLM进行全面性的实验，揭示了这些模型在两个维度上的性能差距，突显了在教育领域应用LLM的潜在挑战和改进空间。
### Conclusion
实验结果显示，现有LLM在知识维度上还存在明显的性能差距，即便最强的模型也无法超过60%的准确率。而在培养维度中，最佳模型的表现也远远落后于人类智能。这些发现凸显了在教育中应用LLM的巨大潜力和挑战，并强调了综合培养和发展学生能力的重要性。OmniEduBench为改进LLM在教育中的应用提供了重要的基准和参考。
## 295. `cs.CL` - 大型语言模型中关系解码线性算子的结构 [PDF](https://arxiv.org/pdf/2510.26543), [HTML](https://arxiv.org/abs/2510.26543)
### Authors
Miranda Anna Christ,Adrián Csiszárik,Gergely Becsó,Dániel Varga
### Background
本文研究了Hernandez等人在2023年引入的线性算子，这些算子在转换器语言模型中解码特定的关系事实。文章扩展了他们关于单关系的研究结果，系统地研究了多个关系的组织结构。
### Innovation
作者通过简单的三阶张量网络高度压缩了这些关系解码的线性算子集，并且没有显著损失解码准确性。开发了一种交叉评估协议，通过对每组关系的主语应用每个线性解码算子来解释这种令人惊讶的冗余性。研究结果表明，这些线性映射并不编码独特的关系，而是提取重复的、粗粒度的语义属性，如首都所在国家与其国家美食都涉及国家-X属性。这种基于属性的结构既解释了算子的压缩性，也揭示了它们仅在语义上相似的新型关系上泛化的原因。
### Conclusion
因此，研究发现将转换器语言模型中的线性关系解码主要视为基于属性的，而非特定于关系的。
## 296. `cs.CL` - 在大规模语言模型高效推理中的基于推理成本的动态树构建 [PDF](https://arxiv.org/pdf/2510.26577), [HTML](https://arxiv.org/abs/2510.26577)
### Authors
Yinrong Hong,Zhiquan Tan,Kai Hu
### Background
大规模语言模型（LLMs）面临显著的推理延迟挑战，这源于其自回归设计和庞大的模型规模。现有预测解码方法虽然通过动态树结构有所改进，但往往忽略了关键系统变量，如GPU设备和批次大小的影响。
### Innovation
提出了一种新的基于推理成本的动态树解码方法CAST，该方法考虑了包括GPU配置和批次大小在内的推理成本，以动态调整树结构。
### Conclusion
通过在六种不同任务和六种不同的LLMs上进行全面实验，该方法取得了显著成果，比传统解码技术快高达5.2倍的速度，并且通常优于现有的最佳技术5%至20%。
## 297. `cs.CL` - InfoFlow: 通过奖励密度优化强化搜索代理 [PDF](https://arxiv.org/pdf/2510.26575), [HTML](https://arxiv.org/abs/2510.26575)
### Authors
Kun Luo,Hongjin Qian,Zheng Liu,Ziyi Xia,Shitao Xiao,Siqi Bao,Jun Zhao,Kang Liu
### Background
RLVR 是一种有望增强代理深度搜索的方法，但在实际应用中，由于在深度搜索场景中具有显著的探索成本，最终奖励却很少或为零的情况，导致了低奖励密度的问题。为此，本文将这一挑战正式界定为‘奖励密度优化’问题，旨在提高每单位探索成本所获得的奖励。
### Innovation
本文提出了一种名为 InfoFlow 的系统性框架，从三个角度针对奖励密度优化问题进行了改进：1) 子问题分解，将长期任务分解为中间任务以提供更密集的学习信号；2) 失败引导提示，向停滞的轨迹注入改正性指导以增加成功结果的概率；3) 双代理细化，利用双代理架构减轻深度探索的认知负担，通过合成搜索历史来有效压缩研究者感知的轨迹，从而降低探索成本并提高整体奖励密度。
### Conclusion
InfoFlow 在多个代理搜索基准测试中显著优于强大的基线模型，使轻量级语言模型（LLMs）能够实现与高级专有语言模型相媲美的性能。
## 298. `cs.CL` - SlideAgent: 层级制代理框架多页视觉文档理解 [PDF](https://arxiv.org/pdf/2510.26615), [HTML](https://arxiv.org/abs/2510.26615)
### Authors
Yiqiao Jin,Rachneet Kaur,Zhen Zeng,Sumitra Ganesh,Srijan Kumar
### Background
多页视觉文档如说明书、宣传册、演示文稿和海报通过布局、色彩、图标和幻灯片间的交叉引用传递关键信息。尽管大型语言模型（LLMs）为文档理解提供了机会，当前的系统在处理复杂的多页视觉文档时仍存在困难，特别在元素和页面间进行细粒度推理方面。
### Innovation
引入了SlideAgent，这是一种通用的代理框架，用于理解和处理多模态、多页和多布局文档，尤其是幻灯片演示文稿。SlideAgent通过专门的代理和将推理分解为全局、页面和元素三个专门层次来构建结构化、查询无关的表示，以捕捉整体主题和详细的视觉或文本线索。在推理过程中，SlideAgent有选择地激活专门的代理进行多层次推理，并将它们的输出整合为连贯、背景感知的回答。实验结果显示，与专有模型相比SlideAgent提高了7.9分，与开源模型相比提高了9.8分。
### Conclusion
SlideAgent在多页视觉文档理解方面取得了显著进展，特别是在细粒度的元素和页面推理方面。与当前的专有和开源模型相比，它在总体性能上有了显著提升。
## 299. `cs.CL` - Evontree：基于本体规则引导的大语言模型自我进化框架 [PDF](https://arxiv.org/pdf/2510.26683), [HTML](https://arxiv.org/abs/2510.26683)
### Authors
Mingchen Tu,Zhiqiang Liu,Juan Li,Liangyurui Liu,Junjie Wang,Lei Liang,Wen Zhang
### Background
大型语言模型（LLMs）通过大规模预训练和精心调优数据展示了在多个领域的出色能力。然而，在对数据敏感的领域如医疗健康中，由于缺乏高质量且领域特定的训练语料库，LLMs 难以适应专门的应用场景。同时，领域专家将专业知识提炼成本体规则，以形式化地规范概念之间的关系，确保知识管理库的完整性。基于此，LLMs 被视为人类知识的隐式存储库。
### Innovation
本文提出了一种名为 Evontree 的新框架，通过小规模高质量本体规则系统地提取、验证和增强LLMs中的领域知识，无需外部大量数据集。具体而言，Evontree 从原始模型中提取领域本体，使用两种核心本体规则检测不一致性，并通过自我提炼的微调强化细化知识。
### Conclusion
在医疗问答基准测试中使用 Llama3-8B-Instruct 和 Med42-v2 进行的大量实验结果表明，我们的方法在未修改模型和领先监督基线中表现出显著的优越性，准确率提高了多达3.7%。这些结果验证了Evontree在LLM低资源领域自适应中的有效性和鲁棒性。
## 300. `cs.CL` - Kimi Linear: 一种表达性强、高效的注意力架构 [PDF](https://arxiv.org/pdf/2510.26692), [HTML](https://arxiv.org/abs/2510.26692)
### Authors
Kimi Team:Yu Zhang,Zongyu Lin,Xingcheng Yao,Jiaxi Hu,Fanqing Meng,Chengyin Liu,Xin Men,Songlin Yang,Zhiyuan Li,Wentao Li,Enzhe Lu,Weizhou Liu,Yanru Chen,Weixin Xu,Longhui Yu,Yejie Wang,Yu Fan,Longguang Zhong,Enming Yuan,Dehao Zhang,Yizhi Zhang,T.Y. Liu,Haiming Wang,Shengjun Fang,Weiran He,Shaowei Liu,Yiwei Li,Jianlin Su,Jiezhong Qiu,Bo Pang,Junjie Yan,Zhejun Jiang,Weixiao Huang,Bohong Yin,Jiacheng You,Chu Wei,Zhengtao Wang,Chao Hong,Yutian Chen,Guanduo Chen,Yucheng Wang,Huabin Zheng,Feng Wang,Yibo Liu,Mengnan Dong,Zheng Zhang,Siyuan Pan,Wenhao Wu,Yuhao Wu,Longyu Guan,Jiawen Tao,Guohong Fu,Xinran Xu,Yuzhi Wang,Guokun Lai,Yuxin Wu,Xinyu Zhou,Zhilin Yang,Yulun Du
### Background
传统全注意力机制虽然强大，但在处理短上下文和长上下文的任务时表现出色，但在特定场景下可能并不总是最优选择。研究人员试图寻找既可以保持性能，又能提高效率的方法。即将推出的Kimu Linear是一种混合线性注意力架构，其首次在公平比较中，在短、长上下文以及强化学习场景中均超过了全注意力机制，在基线模型中引入了更适合有限状态RNN内存的有效机制。
### Innovation
Kimu Linear的核心是Kimi Delta Attention (KDA)，这是一种以Gated DeltaNet为基础，改进了细粒度门控机制的线性注意力模块，以更有效地利用有限状态RNN的内存。为了实现硬件高效性，Kimu Linear采用了特制的块级算法，特殊的DPLR转换矩阵使其计算成本降低，同时保持了经典边缘规则的一致性。该模型采用KDA和Multi-Head Latent Attention (MLA)的分层混合预训练策略，通过这种方式，Kimu Linear模型不仅可以在所有评估任务中胜过全MLA模型，而且还能显著减少KV缓存使用，并大幅提高解码速率。这项创新表明，Kimu Linear不仅性能优越，而且在效率上也有明显优势，尤其在处理更长输入和输出的任务时。
### Conclusion
实验结果表明，Kimu Linear可以作为一种直接替代全注意力架构的选择，具有更好的性能和效率。研究者开源了KDA内核和vLLM实现，并发布了预训练和指令调优模型分发包，以支持进一步的研究。
## 301. `cs.CL` - 自动解码化解手动解码：迈向真正端到端语言模型 [PDF](https://arxiv.org/pdf/2510.26697), [HTML](https://arxiv.org/abs/2510.26697)
### Authors
Zhichao Wang,Dongyang Ma,Xinting Huang,Deng Cai,Tian Lan,Jiahao Xu,Haitao Mi,Xiaoying Tang,Yan Wang
### Background
当前大规模语言模型（LLMs）通常被贴上‘端到端’的标签，但实际上它们依赖于一个非可微分的解码过程，需要进行繁琐的手动超参数调整，如温度和top-p值。这限制了它们的端到端自动化能力。
### Innovation
本文提出了AutoDeco架构，通过学习控制自身的解码策略，实现了真正意义上的‘端到端’生成。AutoDeco在每个步骤中动态预测上下文相关的温度和top-p值，并将其与下一个标记的概率值一起预测。这种方法将解码转换为参数化、逐token的过程，使模型能够在单个前向传递中自我调节其采样策略。实验结果显示，AutoDeco不仅显著优于默认解码策略，还实现了与“破解测试集”获得的最优基线相媲美的性能，这些基线反映了任何静态方法的实践上限。此外，AutoDeco展示了基于指令的解码控制能力，能够理解自然语言命令（例如“尽可能低的随机性生成”）并在逐token的基础上调整预测的温度和top-p值，开启了可调控和交互式LLM解码的新范式。
### Conclusion
AutoDeco在八个基准上的实验表明，它不仅显著优于默认解码策略，还实现了与手动调整最优基线相媲美的性能。更重要的是，AutoDeco展示了基于指令的解码控制能力，进一步证明了其在解码过程中的自我调节潜力，从而为未来LLM的研究开辟了新的方向。
## 302. `cs.CL` - AMO-Bench: Large Language Models Still Struggle in High School Math Competitions [PDF](https://arxiv.org/pdf/2510.26768), [HTML](https://arxiv.org/abs/2510.26768)
### Authors
Shengnan An,Xunliang Cai,Xuezhi Cao,Xiaoyu Li,Yehao Lin,Junlin Liu,Xinxuan Lv,Dan Ma,Xuanlin Wang,Ziwen Wang,Shuang Zhou(Alphabetical order by last name)
### Background
现有的基准测试广泛利用了高中生数学竞赛来评估大型语言模型的数学推理能力。然而，许多现有的数学竞赛对于评估顶级语言模型的效果正在减弱，因为这些模型的性能已经饱和（例如AIME的24/25）。因此，需要更具挑战性的基准测试来评估这些模型的表现。
### Innovation
AMO-Bench引入了更多的挑战，涵盖了50个人工制造的、专家验证过的、符合国际数学奥林匹克（IMO）难度标准的问题，这些问题还确保了完全原创以避免潜在的数据记忆泄露。此外，每个问题只需提供最终答案，便于自动和稳健的评分。这些创新使AMO-Bench成为评估大型语言模型数学推理能力的新型基准。
### Conclusion
实验结果显示，即使在AMO-Bench上表现最好的模型也只能达到52.4%的准确性，大多数模型得分低于40%。然而，进一步分析显示，随着测试时间计算量的增加，模型性能显示出有希望的增长趋势。这些结果突显了当前大型语言模型在数学推理方面存在的巨大改进空间。AMO-Bench的发布旨在促进对语言模型推理能力改进的研究。
## 303. `cs.CL` - 价值漂移：追踪LLM后训练中的价值对齐 [PDF](https://arxiv.org/pdf/2510.26707), [HTML](https://arxiv.org/abs/2510.26707)
### Authors
Mehar Bhatia,Shravan Nayak,Gaurav Kamath,Marius Mosbach,Karolina Stańczak,Vered Shwartz,Siva Reddy
### Background
随着大规模语言模型（LLM）在社会中的作用日益重要，他们在面对不仅需要应用广泛知识，还需要与特定的人类价值观保持一致的问题时，变得越来越多。因此，研究LLM的价值对齐变得至关重要。然而，先前的研究主要集中在评估完全训练后的模型价值对齐情况，忽略了训练过程中模型学习表达人类价值的动态过程。本文研究了模型在后训练过程中价值对齐是如何产生及其在哪个阶段产生的，分析解开了后训练算法和数据集的影响，测量了价值偏差的大小和时间。研究发现，监督微调（SFT）阶段通常建立了模型的价值，而随后的偏好优化很少重新对齐这些价值。使用合成偏好数据集，本文还发现即使在偏好数据保持不变的情况下，不同的偏好优化算法也会导致不同的价值对齐结果。
### Innovation
本文的研究创新点在于，首次试图在模型后训练阶段追溯并分析价值对齐的过程。通过解缆后训练算法和数据集对价值对齐的影响，测量价值偏差的大小和时间，尤其是在使用不同规模的Llama-3和Qwen-3模型，以及不同的偏好优化算法和数据集之后，发现了监督微调通常建立模型的价值，而偏好优化通常不会重新对齐这些价值。
### Conclusion
本文的研究结果提供了关于价值学习期间执行的具体见解，并有助于指导数据管理、以及为了提高模型与人类价值观对齐的偏好优化算法和模型的选择。
## 304. `cs.CL` - 编码器-解码器或解码器仅有的？重访编码器-解码器大型语言模型 [PDF](https://arxiv.org/pdf/2510.26622), [HTML](https://arxiv.org/abs/2510.26622)
### Authors
Biao Zhang,Yong Cheng,Siamak Shakeri,Xinyi Wang,Min Ma,Orhan Firat
### Background
近年来，大规模语言模型（LLM）的研究从编码器-解码器模型架构转向了现在的主导解码器仅有的模型架构。尽管这种快速转变非常迅速，但缺乏从扩增视角进行的严格比较分析，引起了对编码器-解码器模型潜在价值被忽视的担忧。为了填补这一空白，本文重访了编码器-解码器LLM（RedLLM），并借鉴了解码器仅有的LLM（DecLLM）的最新方法进行增强。我们以不同规模模型（从约1.5亿到约80亿）进行了全面比较实验，结果显示，RedLLM在模型缩放特性方面表现出令人信服的能力，并且在各种下游任务上的表现也令人惊讶地强大。虽然在预训练阶段，DecLLM在计算效率上更优，但RedLLM在模型缩放和上下文长度外推能力上表现出可比较甚至更好的表现。在指令微调后，RedLLM在各种下游任务上获得了与DecLLM相当甚至更好的效果，同时在推断效率方面享有显著的优势。
### Innovation
研究重访了编码器-解码器LLM，并将其与当前主流的解码器仅有的LLM进行对比。通过使用RedPajama V1（1.6T标记）作为预训练，并结合FLAN进行指令微调，实验展示了RedLLM具有引人注目的scaling特性和相对更强的表现。尽管在预训练阶段，DecLLM在计算效率上更优，但RedLLM在模型缩放和上下文长度外推能力上表现出可比较甚至更好的表现。特别是在指令微调后，RedLLM在各种下游任务上获得了与DecLLM相当甚至更好的效果，同时在推断效率方面享有显著的优势。
### Conclusion
本研究希望我们的发现能够激发更多对重访RedLLM的研究努力，以此来释放其潜在潜力，从而开发出更加强大和高效的LLM。
## 305. `cs.CL` - Gistify! 基于运行时执行的代码库级理解 [PDF](https://arxiv.org/pdf/2510.26790), [HTML](https://arxiv.org/abs/2510.26790)
### Authors
Hyunji Lee,Minseon Kim,Chinmay Singh,Matheus Pereira,Atharv Sonwane,Isadora White,Elias Stengel-Eskin,Mohit Bansal,Zhengyan Shi,Alessandro Sordoni,Marc-Alexandre Côté,Xingdi Yuan,Lucas Caccia
### Background
随着编码代理在大型代码库中的广泛应用，自动设计针对代码库级别的挑战性评估变得尤为重要。因此，研究团队提出了一项名为Gistify的任务，通过该任务，编码的语言模型（LLM）必须创建一个单一、最小、自包含的文件，以重现特定的代码库功能。这需要编码LLM能够全面访问代码库并提供一个具体入口点（例如，一个Python命令），生成的文件必须能够复制该命令在全面运行代码库下的输出结果，并且仅包含执行所提供命令所必需的全部组件。成功完成Gistify任务需要对代码库结构的理解、准确地建模其执行流程以及能够产出大型代码修补的能力。然而，当前最先进的模型在解决Gistify任务时表现不佳，尤其是在执行轨迹较长的任务上。
### Innovation
该研究提出了一个新的任务Gistify，以此评估编码LLM在代码库级别的理解和执行能力。这一任务要求模型在访问整个代码库的前提下，自动生成一个包含所需功能的最小代码片段。这项任务的独特之处在于它不仅考察模型对结构的理解和执行流程的建模能力，还考验模型生成大量代码修补的能力。现有的最先进的模型在应对Gistify任务时存在挑战，尤其是在处理长执行轨迹的任务时麻烦更大。
### Conclusion
研究表明，当前的最先进的模型在解决Gistify任务时表现欠佳，尤其是在处理具有较长执行轨迹的任务时更为困难。这表明现有的技术距离能够处理全面代码库的复杂任务仍有一定差距，未来的研究需要进一步探索和改进以提高编码LLM在代码库级别执行的能力。
## 306. `cs.CL` - MemEIC: 朝着分阶段和组合知识编辑迈出的一步 [PDF](https://arxiv.org/pdf/2510.25798), [HTML](https://arxiv.org/abs/2510.25798)
### Authors
Jin Seong,Jiyun Park,Wencke Liermann,Hongseok Choi,Yoonji Nam,Hyun Kim,Soojong Lim,Namhoon Lee
### Background
信息的动态性质需要不断更新大型视觉语言模型（LVLMs）。虽然最近的知识编辑技术提出了有希望的方向，但它们通常专注于单独编辑单一模态（视觉或语言）。这种方法忽视了LVLMs的内在多模态性以及知识更新的持续性，可能导致在处理模态间交互和持续知识优化需求时出现次优编辑结果。为解决这些限制，我们提出了MemEIC，一种新的LVLM持续和组合知识编辑方法（CCKE）。MemEIC能够按顺序编辑视觉和文本知识。这种方法采用了一种混合外部-内部编辑器，配备交叉模态证据检索的双重外部内存和促进每个模态独立参数更新的双重LoRA适配器。关键组件是一种灵感源于大脑的知识连接器，根据需要选择性激活以进行组合推理，将不同模态间的信息整合起来。实验证明，MemEIC在处理复杂多模态问题上显著提高了性能，并有效地保留了先前的编辑，为LVLM的CCKE设立了新的基准.
### Innovation
MemEIC方法引入了一种组合编辑器，能够按顺序编辑视觉和文本知识，同时利用双重外部内存和双重LoRA适配器来实现模态间参数的独立更新。此外，它引入了一个基于大脑的机制来过滤和整合模态间的信息，提升了多模态问题处理的性能。
### Conclusion
MemEIC在处理复杂多模态问题上显著提高表现，并有效保持了先前的编辑结果，是LVLMs中的持续和组合知识编辑的一个重要进展。
## 307. `cs.CL` - 使用多评审人学习系统的擬人化人类偏好逼近 [PDF](https://arxiv.org/pdf/2510.25884), [HTML](https://arxiv.org/abs/2510.25884)
### Authors
Eitán Sprejer,Fernando Avalos,Augusto Bernardi,Jose Pedro Brito de Azevedo Faustino,Jacob Haimes,Narmeen Fatimah Oozeer
### Background
LLM（大规模语言模型）作为判官时，由于难以校准、评分标准敏感性、偏向性和不稳定性，很难与人类偏好对齐。这限制了诸如RLHF（基于人类反馈的强化学习奖励模型）和高效路由系统等关键应用的发展。
### Innovation
本文提出了一种框架，通过学习多个评分标准指导的评审人的输出来建模多样化的人格化偏好。相对于简单的基线方法，该方法在性能上进行了比较，通过人类和LLM评审人的案例研究评估其鲁棒性。贡献包括一种大规模合成偏好标签的人格化方法以及两种聚合器的实现：广义加性模型(GAM)和多层感知器(MLP)。
### Conclusion
本文证明了通过学习多个Premodel评分人的输出来逼近人类偏好是有效的方法。提出的基于人格的方法可以大规模合成偏好标签，并通过两种不同的聚合器实施，显示了对于包含偏见的评分的鲁棒性处理能力。
## 308. `cs.CL` - 从法官的视角：推断出的思考痕迹提高LLM评估者的可靠性 [PDF](https://arxiv.org/pdf/2510.25860), [HTML](https://arxiv.org/abs/2510.25860)
### Authors
Xingjian Zhang,Tianhong Gao,Suliang Jin,Tianhao Wang,Teng Ye,Eytan Adar,Qiaozhu Mei
### Background
大语言模型（LLMs）越来越多地被用作评估任务的评分者。然而，它们在主观任务上的可靠性往往受限，尤其是在人类判断涉及超出标记标签的微妙推理时。上述判断背后的推理过程虽然很有信息价值，但收集和整理这些过程却极具挑战性。本研究提出了一种人-LLM协作框架，从仅含标签的评分中推断出思考痕迹，采用简单的拒绝采样方法在大规模上重建这些痕迹。这些推断出的思考痕迹被应用于两个互补任务：（1）微调开放的LLM评分者；（2）为专有的LLM评分者制定更清晰的标注指南。
### Innovation
提出了一种人-LLM协作框架，用于从仅含标签的评分中推断出思考痕迹。该框架使用简单的拒绝采样方法在大规模上重建这些痕迹，并应用于微调开放的LLM评分者和为专有的LLM评分者制定更清晰的标注指南。这种方法显著提高了LLM-人类的一致性，并增强了许多LLM模型之间的协议性，表明LLMs可以作为替代人类思考痕迹的实用代理，并将仅含标签的语料库扩展为包含思考痕迹的资源，从而提高LLM评分者的可靠性.
### Conclusion
研究结果表明，LLMs可以在无法直接获取人类思考痕迹的情况下，作为可靠的人类思考痕迹的替代品。这种方法能够让仅含标签的语料得到扩展，转变为包含思考痕迹的资源，从而提升LLM评分者的可靠性。
## 309. `cs.CL` - 通过空间时空分析和空间注意力网络提升水下目标检测 [PDF](https://arxiv.org/pdf/2510.25797), [HTML](https://arxiv.org/abs/2510.25797)
### Authors
Sai Likhith Karri,Ansh Saxena
### Background
该研究探讨了时空建模及其在水下目标检测深度学习模型中的应用效果，特别是在结合空间注意力机制方面。首先，研究对增强版本的YOLOv5模型（T-YOLOv5）进行了性能评估，对比了标准的YOLOv5模型。随后，研究团队通过添加Convolutional Block Attention Module (CBAM)开发了T-YOLOv5的增强版本。这些研究旨在评估现有YOLOv5和T-YOLOv5模型的性能，并且评估由CBAM增强的T-YOLOv5的能力。研究关注的是在动态海洋环境中通过时空建模提高检测精度，尤其是在快速移动、部分遮挡和渐进运动等复杂条件下。
### Innovation
研究的创新之处在于：1) 使用了增强版本的YOLOv5（T-YOLOv5），通过引入时空建模来改进水下目标检测的性能；2) 研发了通过添加CBAM模块的T-YOLOv5增强版本，并且在此过程中发现了CBAM对复杂海洋环境中检测效率的提升，特别是对快速移动物体和部分遮挡情况下的增强作用。研究还发现，带CBAM的T-YOLOv5在复杂场景中的检测性能提高显著，但可能在简单场景中有所下降。
### Conclusion
研究发现，与标准的YOLOv5模型相比，T-YOLOv5提升了检测可靠性。特别是在复杂场景下，带CBAM的T-YOLOv5进一步提升了性能，尽管在简单场景中显示出轻微的精度下降。研究结果表明，时空建模和空间注意力机制可以显著改善水下目标的检测性能，在动态环境中尤其突出。
## 310. `cs.CL` - Metis-SPECS：通过自我提取偏好冷启动分解多模态学习 [PDF](https://arxiv.org/pdf/2510.25801), [HTML](https://arxiv.org/abs/2510.25801)
### Authors
Kun Chen,Peng Shi,Haibo Qiu,Zhixiong Zeng,Siqi Yang,Wenji Mao,Lin Ma
### Background
基于可验证奖励的强化学习（RL）最近引发了“MLLM-r1”方法的热潮，这些方法将RL引入了视觉语言模型。最初的大多数方法都是从零开始，通常通过监督微调（SFT）初始化策略后再进行RL。然而，SFT方法将任务推理和输出格式嵌入其中，可能导致指令样式的过拟合，削弱了泛化能力，并影响了后续的RL效果。现有研究从训练方法和数据构建两个方面重新审视了冷启动问题，并引入了泛化因子（GF）系数来量化不同方法下的泛化能力。实证研究表明，基于偏好的训练方法（如DPO）相较于SFT方法在冷启动中有更好的泛化能力。
### Innovation
提出了SPECS（Self-distilled Preference-based Cold Start）框架，该框架通过自我提取偏好数据对来分解多模态学习过程。具体来说，(1) 使用自我提取的方法生成反思性的偏好数据对，避免依赖更大的教师模型或手动标注；(2) 进行基于偏好的训练，专注于学习浅层的、可迁移的表层形式标准（如格式、结构、风格），而不是记忆内容；(3) 将具备验证奖励的RL传递给策略学习，以获得深层的推理结果。实验结果显示，与强大的基线相比，该分解放学框架在多个多模态基准测试中取得了稳定的性能提升，例如在MEGA-Bench上提高了4.1%，在MathVista上提高了12.2%。额外的实验表明，SPECS还有助于减少训练过程中的内分布“卡壳”问题，增强探索性，稳定训练，并提高性能潜力。
### Conclusion
研究通过引入SPECS框架，在多模态理解与生成任务中，通过自我提取的偏好冷启动实现了解耦多模态学习，并在实验中验证了其相对于传统SFT方法的优越性能。
## 311. `cs.CL` - FakeZero：实时、保护隐私的Facebook和X上的假信息检测 [PDF](https://arxiv.org/pdf/2510.25932), [HTML](https://arxiv.org/abs/2510.25932)
### Authors
Soufiane Essahli,Oussama Sarsar,Imane Fouad,Anas Motii,Ahmed Bentajer
### Background
社交媒体平台以前所未有的速度传播信息，导致了信息错误传播的加速，威胁了公众对话。为此，该论文提出了一个名为FakeZero的浏览器扩展，它可以在用户滚动时在Facebook和X（原名Twitter）平台上标记不可靠的帖子，同时保护用户的隐私。
### Innovation
提出了一个名为FakeZero的客户端侧、跨平台浏览器扩展，该扩展具有以下创新点：1）它通过Chromium消息API在本地进行所有计算、DOM抓取、分词、Transformer推理和UI渲染，确保不会泄露个人数据；2）使用了一种三阶段的训练课程，包括基线微调、领域适应训练，以及增强的焦点损失、对抗增强和后训练量化；3）使用DistilBERT-Quant模型（67.6 MB），在239,000个帖子的数据集上实现了97.1%的宏F1分数和97.4%的准确率，具有约103毫秒的中位延迟；4）还提出了一种资源消耗低的TinyBERT-Quant变体，模型大小仅为14.7 MB，延迟降低到约40毫秒。
### Conclusion
该研究证明了即使在严格资源限制下，也可以实现高质量的假新闻检测。通过提供实时的栏目可信度提示，FakeZero可以成为政策制定者对抗社交媒体假信息的有力工具。此外，该工具还为研究人员提供了大规模收集野生假新闻数据的机会，促进更深入的分析和更稳健的检测技术的发展。
## 312. `cs.CL` - SIRAJ: 利用提炼结构化推理实现LLM代理多样高效红队测试 [PDF](https://arxiv.org/pdf/2510.26037), [HTML](https://arxiv.org/abs/2510.26037)
### Authors
Kaiwen Zhou,Ahmed Elgohary,A S M Iftekhar,Amin Saied
### Background
大型语言模型（LLM）代理具备规划和调用工具的能力，这使其面临新的安全风险，因此部署前的安全评估系统至关重要。本研究提出了一种通用红队框架SIRAJ，专门用于任意黑盒LLM代理，以发现潜在漏洞并确保安全部署。
### Innovation
SIRAJ框架采用动态两步过程，首先定义代理并生成涵盖多种风险、工具使用路径和风险来源的多样化种子测试案例。然后基于前次尝试的执行路径迭代构建和优化基于模型的攻击。此外，该研究提出了一种模型提炼方法，利用教师模型结构化推理的提炼形式，训练出同等有效但规模更小的模型，降低了红队测试成本。
### Conclusion
种子测试案例生成在不同评估代理设置中提高了2-2.5倍的风险结果和工具调用路径覆盖率。提炼的8B红队模型使攻击成功率提高了100%，超越了671B的Deepseek-R1模型。模型提炼和迭代框架的有效性通过消融分析和全面分析得到了验证。
## 313. `cs.CL` - Do Students Debias Like Teachers? On the Distillability of Bias Mitigation Methods [PDF](https://arxiv.org/pdf/2510.26038), [HTML](https://arxiv.org/abs/2510.26038)
### Authors
Jiali Cheng,Chirag Agarwal,Hadi Amiri
### Background
知识精炼（KD）是模型压缩和知识转移的有效方法。然而，其对模型在处理离分布数据时抗误关联性（spurious correlations）的能力的影响尚未被充分研究。本文旨在探究KD对未来学习器（学生模型）具备去偏见（debiasing）能力的转移性的影响，特别是在自然语言推理（NLI）和图像分类任务中的表现。研究发现，KD会对模型的去偏见能力产生负面影响，训练去偏见模型并不能从教师模型中受益，模型的整体抗偏见能力可能在KD后保持稳定，但不同类型的偏见表现各异。这些发现为改进去偏见方法提供了理论基础。
### Innovation
这是首个大规模研究KD对去偏见方法的影响及其内在机制的研究。研究通过广泛的实验揭示了KD对去偏见能力的负面影响，并提出三种改进方法：开发高质量数据增强，实施迭代KD方法，以及使用教师模型权重初始化学生模型。
### Conclusion
本文的研究结果有助于理解KD的工作原理，并为设计更好的去偏见方法提供了见解。
## 314. `cs.CL` - CAVE：检测和解释视觉环境中的常识异常 [PDF](https://arxiv.org/pdf/2510.26006), [HTML](https://arxiv.org/abs/2510.26006)
### Authors
Rishika Bhagwatkar,Syrielle Montariol,Angelika Romanou,Beatriz Borges,Irina Rish,Antoine Bosselut
### Background
人类能够自然地识别、推断和解释环境中的异常。在计算机视觉中，这一长期挑战局限于工业缺陷或不现实的、合成生成的异常，未能捕捉到真实世界异常的多样性和不可预测性。这项工作中，引入了CAVE，首个真实世界视觉异常的标准基准。它支持三个开放任务：异常描述、解释和证明；并提供了细致的注释，用于视觉定位异常、根据其视觉表现归类异常、复杂性、严重性和常见性。这些注释借鉴了认知科学领域中关于人类识别和解决异常的研究成果，为评估视觉-语言模型（VLM）在检测和理解异常方面的能力提供了一个综合框架。以前的工作主要集中在工业缺陷或合成生成的异常上，无法覆盖真实世界的多样性和不可预测性，所以需要一个新的基准来填充这一空白。
### Innovation
首次引入了真实世界视觉异常的标准基准（CAVE），支持三个开放任务，并提供了细致的注释来细分和归类异常。其注释借鉴了认知科学的研究成果，为评估VLM的能力提供了一个综合框架。通过对比实证研究，展示了最先进的VLM在视觉异常感知和常识推理方面的不足，特别是在使用先进的提示策略时表现不佳。这为研究者们提供了宝贵的资源，推动了异常检测和常识推理的研究。
### Conclusion
CAVE作为一个现实且认知上合理的基准，有助于推进针对VLM的异常检测和常识推理的研究。尽管目前最先进的VLM在处理视觉异常感知和常识推理时仍有困难，但CAVE提供的基准将有助于改进这些模型。
## 315. `cs.CL` - ORBIT - 开放推荐基准测试以促进透明研究与隐藏测试 [PDF](https://arxiv.org/pdf/2510.26095), [HTML](https://arxiv.org/abs/2510.26095)
### Authors
Jingyuan He,Jiongnan Liu,Vishan Vishesh Oberoi,Bolin Wu,Mahima Jagadeesh Patel,Kangrui Mao,Chuning Shi,I-Ta Lee,Arnold Overwijk,Chenyan Xiong
### Background
推荐系统是影响最大的AI应用之一，每日与数亿用户互动，引导他们找到符合个人偏好的产品、服务或信息。然而，推荐系统的研发受到现有数据集无法捕捉真实用户行为以及不一致的评估设置限制，导致结论不明确。
### Innovation
本研究引入了开放推荐基准测试ORBIT（Open Recommendation Benchmark for Reproducible Research with HIdden Tests），提供了一个统一的评估框架，用于一致和真实的推荐模型评估。ORBIT包括标准化的评价框架、可重复的数据集分割以及透明的设置，旨在公共排行榜上实现可验证性。此外，ORBIT还引入了新的网页推荐任务ClueWeb-Reco，包含8700万公共高质量网页的浏览序列，该数据集起源于真实用户同意且隐私保障的浏览数据。ClueWeb-Reco作为ORBIT排行榜的隐藏测试部分，用于挑战推荐模型的泛化能力。研究使用12种代表性推荐模型在ORBIT公共基准上进行了测试，并在ClueWeb-Reco隐藏测试中引入了提示型LLM基线，结果显示推荐系统在公共数据集上的整体改进情况及个体性能变化。
### Conclusion
ORBIT基准测试、排行榜和代码库可以在以下网址查看。基准测试结果揭示了现有方法在大规模网页推荐方面的局限性，展示了通过LLM集成的改善潜力。
## 316. `cs.CL` - 全方位 critique 一款模型：通过高效推理奖励具有代理性的工具使用 [PDF](https://arxiv.org/pdf/2510.26167), [HTML](https://arxiv.org/abs/2510.26167)
### Authors
Renhao Li,Jianhong Tu,Yang Su,Hamid Alinejad-Rokny,Derek F. Wong,Junyang Lin,Min Yang
### Background
奖励模型（RMs）在使大规模语言模型（LLMs）与人类偏好保持一致方面发挥着关键作用。然而，在工具学习领域，缺乏专门针对函数调用任务的奖励模型限制了迈向更先进代理型AI的进步。为了应对这一挑战，本文提出了一种轻量级生成奖励模型 ToolRM，专为通用工具使用场景设计。为了构建这些模型，本文提出了一种新的流水线，使用基于规则的评分和多维采样构建成对偏好数据。这生成了 ToolPref-Pairwise-30K 这一多样化、平衡且具有挑战性的批评任务数据集，为强化学习提供了可验证的反馈支持。
### Innovation
本文创新地提出了 ToolRM，这是一种轻量级的生成奖励模型，专门设计用于解决一般工具使用场景中的问题。该模型的创新点在于其用于构建数据的新流水线，该流水线使用基于规则的评分和多维采样来生成成对偏好数据，从而创建了一个多样化、平衡且具有挑战性的批评任务数据集 ToolPref-Pairwise-30K。基于此数据集，训练出的 Qwen3-4B/8B 系列模型在一对一奖励判断中准确性提高了 14.28%，远超 Claude 4 和 OpenAI o3 等前沿模型。此外，ToolRM 还能够泛化到更广泛的批评任务，如多次采样和自我纠正。
### Conclusion
实验结果表明，ToolRM 在 ACEBench 上表现出色且高效，能够在推理时进行扩展，将输出词元使用量减少了超过 66%。为了推动未来的研究，本文还发布了数据和模型检查点。
## 317. `cs.CL` - 从数学知识构建广泛的大语言模型推理课程 [PDF](https://arxiv.org/pdf/2510.26143), [HTML](https://arxiv.org/abs/2510.26143)
### Authors
Bo Pang,Deqian Kong,Silvio Savarese,Caiming Xiong,Yingbo Zhou
### Background
强化学习（RL）能激发大型语言模型（LLMs）的强大推理能力，但大多数公开研究主要集中在数学和代码方面。本文提出了一种简单的两阶段课程——推理课程，旨在通过先在与预训练对齐的领域（如数学）中培养推理能力，再联合强化学习在多种其他领域中转移和巩固这些技能，来实现更广泛的推理能力。
### Innovation
通过提出一个简单的两阶段课程——推理课程，缓解了现有的限制。第一阶段提供冷启动并进行数学强化学习，以验证奖励来培养推理技能。第二阶段通过在跨域数据上进行联合强化学习，以转移和巩固技能。此课程无需专门的奖励模型，使用标准可验证检查即可。研究表明，该两阶段课程能够一致地提高推理能力。
### Conclusion
推理课程提供了一种紧凑且易于实现的方法，以增强大语言模型的广泛推理能力。实验结果显示，两个阶段缺一不可，数学首要的提取增加了解决复杂问题所需的重要认知行为。
## 318. `cs.CL` - SP-MCQA: 在词以上级别评估TTS的可理解性 [PDF](https://arxiv.org/pdf/2510.26190), [HTML](https://arxiv.org/abs/2510.26190)
### Authors
Hitomi Jin Ling Tee,Chaoren Wang,Zijie Zhang,Zhizheng Wu
### Background
现有的TTS语音清晰度评估方法已经遇到了瓶颈，因为这些评估方法主要依赖于逐词准确性的度量，如WER，这未能捕捉到实际语音的复杂性，也不能反映人类的理解需求。这使得相关评估无法全面反映合成语音的真实可理解性水平。因此，研究需要一个新的评估方法来解决这一问题，即通过听写片段短文并进行多项选择题回答的主观评估方法来评估合成语音中关键信息的准确性，进而推出一个名为SP-MCQA-Eval的新基准数据集，用于SP-MCQA评估。
### Innovation
提出了一种新颖的主观评估方法，称为Spoken-Passage Multiple-Choice Question Answering (SP-MCQA) 来评估TTS合成语音中的关键信息准确度，通过这种评估方法，发现了低WER并不一定保证高的关键信息准确性，这揭示了传统度量标准和实际可理解性之间的差距。SP-MCQA评估表明，即使是目前的最佳模型，仍然缺乏稳健的文本规范化和音素准确性。这项工作强调了在现有系统在WER方面表现出众的情况下，需要迫切引入更高水平的、更贴近真实环境的评估标准的需求。
### Conclusion
SP-MCQA评估方法清晰地展示了在准确性评估方面，传统的后编辑和直接归一化的技术仍然存在差距。提出了一项8.76小时的新闻风格基准数据集，SP-MCQA-Eval，以推动该领域的进一步研究和改进。
## 319. `cs.CL` - Context Engineering 2.0: The Context of Context Engineering [PDF](https://arxiv.org/pdf/2510.26493), [HTML](https://arxiv.org/abs/2510.26493)
### Authors
Qishuo Hua,Lyumanshan Ye,Dayuan Fu,Yang Xiao,Xiaojie Cai,Yunze Wu,Jifan Lin,Junfei Wang,Pengfei Liu
### Background
背景阐述了马克思主义关于人类本质是由社会关系所构成的观点，强调了个体在社会互动中的角色。随着计算机和人工智能的发展，人类与机器的互动也成为了社会互动的一部分。在此背景下，提出了机器如何更好地理解人类情况和目的这一核心问题，进而介绍了上下文工程的概念和其发展的历史阶段。
### Innovation
论文认为上下文工程的概念可以追溯到20多年前，从早期围绕初级计算机的人机交互框架发展到今天的由智能代理驱动的人工智能交互模式，并展望未来可能达到人类或超越人类智能的水平。文章系统地定义了上下文工程，概述了其历史和概念框架，并探讨了关键设计考虑因素，旨在为人工智能系统中的上下文工程提供一个概念基础。
### Conclusion
论文为更广泛的社区提供了一个关于系统上下文工程的概念基础，并勾勒了其有希望的未来。这标志着在人工智能系统中进行全面的上下文工程努力的一个起点。
## 320. `cs.CL` - Nexus: 基于执行的多智能体测试预言合成 [PDF](https://arxiv.org/pdf/2510.26423), [HTML](https://arxiv.org/abs/2510.26423)
### Authors
Dong Huang,Mingzhe Du,Jie M. Zhang,Zheng Lin,Meng Luo,Qianru Zhang,See-Kiong Ng
### Background
软件工程中，非回归测试中的测试预言生成一直是一个长期的挑战。目标是生成能够准确判断被测函数（FUT）在给定输入情况下表现是否正确的预言。现有的方法在准确性上存在局限。
### Innovation
Nexus提出了一种新的多智能体框架，通过多样化专业化代理协作合成预言，这一过程包括通过结构化的推理、验证和迭代自我改进。特别地，Nexus利用了一个由四个专家代理组成的评审小组，在一个安全的沙箱环境中执行和验证生成的预言。对于执行不通过的预言，Nexus通过自动化的过程进行调试和纠正。实验表明，Nexus在多个基准测试中显著提高了预言的准确性，并明显增强了后续任务的表现。
### Conclusion
Nexus在七个不同的基准测试中，持续且显著地超越了最先进的基准线。例如，在LiveCodeBench上的GPT-4.1-Mini的预言准确性从46.30%提高到57.73%，并且在HumanEval的缺陷检测率上也从90.91%提高到95.45%，自动程序修复的成功率也从35.23%提升到69.32%。
## 321. `cs.CL` - SecureReviewer: 通过安全意识微调增强大型语言模型进行安全代码审查 [PDF](https://arxiv.org/pdf/2510.26457), [HTML](https://arxiv.org/abs/2510.26457)
### Authors
Fang Liu,Simiao Liu,Yinghao Zhu,Xiaoli Lian,Li Zhang
### Background
在软件开发早期阶段识别和解决安全问题对于减少长期负面影响至关重要。代码审查是一个有效的实践，允许开发者在代码合并到代码库之前检查队友的代码。尽管已经提出了各种自动化代码审查方法，其中基于LLM的方法显著增强了自动化审查生成的能力，但现有的模型主要集中在通用代码审查上，它们在识别和解决安全相关问题方面的效果还有待探索。此外，将现有的代码审查方法适应针对安全问题面临着数据稀缺性和不充分的评估指标等重大挑战。
### Innovation
本文提出了一种新的方法SecureReviewer，这是一种专门设计来增强LLMs在代码审查中识别和解决安全问题的能力。具体而言，本文首先为训练和评估安全代码审查能力构建了一个定制数据集。利用该数据集，对LLM进行了微调以生成能够准确识别安全问题并提供修复建议的代码审查评论。此外，为了减少LLM的幻觉并增强生成评论的可靠性，将RAG技术集成进来，使生成的评论基于特定领域的安全知识。同时引入了SecureBLEU，一个评估生成的代码审查评论有效性的新指标。
### Conclusion
实验结果表明，SecureReviewer在安全问题检测准确性和生成的审查评论的整体质量和实用性方面都优于现有的最先进的基线方法。
## 322. `cs.CL` - 通过头部-尾部平衡对抗LVLMs自我改进过程中的马太效应 [PDF](https://arxiv.org/pdf/2510.26474), [HTML](https://arxiv.org/abs/2510.26474)
### Authors
Xin Guo,Zhiheng Xi,Yiwen Ding,Yitao Zhai,Xiaowei Shi,Xunliang Cai,Tao Gui,Qi Zhang,Xuanjing Huang
### Background
在大型视觉-语言模型（LVLMs）中，自我改进已成为提升推理能力的主要范式，模型通过迭代探索和学习成功轨迹。然而，在这一过程中，模型在简单查询（即头部数据）上表现出色，但在处理复杂查询（即尾部数据）时则显得困难重重，导致优化变得不平衡。这种不平衡使得模型更倾向于发展简单的推理技能，而忽视了复杂推理任务的解决能力，随着时间的推移，这种不平衡变得愈发明显，我们称之为“马太效应”，最终阻碍了模型的进一步改进并导致性能瓶颈。
### Innovation
为了应对这一挑战，作者提出了四种有效策略，分别从重新分布和轨迹重新抽样的角度，旨在在探索-学习的自我改进过程中实现头部与尾部的平衡。这些方法在Qwen2-VL-7B-Instruct和InternVL2.5-4B模型在视觉推理任务上的广泛实验中表现出色，平均提高了3.86个点的性能，优于纯自我改进方法。
### Conclusion
通过上述方法，作者展示了如何克服LVLMs自我改进过程中的“马太效应”，实现更好的视觉推理能力。
## 323. `cs.CL` - 哪边是时间的流向？一种基于心理物理学评估的视觉语言模型 [PDF](https://arxiv.org/pdf/2510.26241), [HTML](https://arxiv.org/abs/2510.26241)
### Authors
Shiho Matta,Lis Kanashiro Pereira,Peitao Han,Fei Cheng,Shigeru Kitazawa
### Background
现代的多模态视觉-语言模型（VLMs）在多项任务上表现出色，但在视频中的时间信息理解上却显得薄弱且被忽视。本文通过对时间流向（AoT）的短片段是正向播放还是反向播放进行判断这一看似简单却揭示性极强的挑战，来探查这一差距。引入了AoT-PsyPhyBENCH心理物理验证基准，该基准使用与人类相同的刺激和行为基线，测试VLMs能否在自然视频中推断时间方向。综合评估开放权重和专有VLMs的结果显示，大多数模型的表现与随机猜测几乎相同，即使是顶尖模型也无法在物理不可逆过程（如自由落体、扩散/爆炸）和因果手动操作（如分割/加法）上接近人类的即时识别准确度。这些结果强调了当前多模态系统中的一个基本短板：虽然它们捕捉了丰富的视觉-语义关联，但在时间连续性和因果理解的归纳偏置方面却显得不足。
### Innovation
提出了AoT-PsyPhyBENCH心理物理验证基准，使用与人类相同的刺激和行为基线测试VLMs判断时间流向的能力；发现大多数VLMs表现与随机猜测相当，顶尖模型在某些物理不可逆过程和因果手动操作上的准确度远低于人类；揭示了VLMs在时间连续性和因果理解能力上的不足。
### Conclusion
现有的VLMs虽然捕捉了丰富的视觉-语义关联，但缺乏时间连续性和因果理解所需的归纳偏置，导致它们在处理不可逆物理过程和因果手动操作上表现不佳。AoT-PsyPhyBENCH基准数据和代码的公开旨在促进VLMs在物理和时间推理能力上的进步。
## 324. `cs.CL` - PVMark: 使大型语言模型水印方案具备公开验证能力 [PDF](https://arxiv.org/pdf/2510.26274), [HTML](https://arxiv.org/abs/2510.26274)
### Authors
Haohua Duan,Liyao Xiang,Xin Zhang
### Background
当前为大型语言模型（LLMs）设计的水印方案旨在识别生成文本的来源，以减轻模型被盗带来的潜在威胁。然而，现有的水印解决方案很难解决信任问题：非公开的水印检测无法忠实地证明其检测行为，因为用于水印检测的密钥不能公开，否则对手可能会发起移除攻击，也不能私有，使水印检测对公众来说是不透明的。论文观察到这一问题主要是由于使用的密钥不能公开或私有：公开则易受攻击，私有则不透明。因此，现有方案存在信任缺失的问题。因此，亟需一种解决方案来解决这一问题，即在不泄露任何密钥的情况下，使水印检测过程能够由第三方公开验证。
### Innovation
PVMark 是一种基于零知识证明（ZKP）的插件，能够使水印检测过程能够经过第三方的公开验证而无需透露任何密钥。PVMark 依赖于用于构建一系列 ZKP 约束的 '正确执行' 证明，这些约束包括映射、随机数生成、比较和求和。作者实现了多种不同版本的 PVMark，包括 Python、Rust 和 Circom 语言的实现，覆盖了多种水印方案、哈希函数和零知识证明协议的组合，展示了这种方法在不同条件下的有效性。实验结果表明，PVMark 能有效增强最先进的 LLM 水印方案的公开验证性，而不会牺牲水印的性能，具有实际部署的潜力。
### Conclusion
PVMark 设计了一个基于零知识证明的插件，解决了现有的 LLM 水印方案的信任问题，使得水印检测过程能够被第三方公开验证，而无需透露任何密钥。该方法在多种环境中实现了良好的性能，展示了在实际应用中的潜力。
## 325. `cs.CL` - 重新思考Text-to-SQL：面向真实数据库探索的动态多轮SQL交互 [PDF](https://arxiv.org/pdf/2510.26495), [HTML](https://arxiv.org/abs/2510.26495)
### Authors
Linzhuang Sun,Tianyu Guo,Hao Liang,Yuying Li,Qifeng Cai,Jingxuan Wei,Bihui Yu,Wentao Zhang,Bin Cui
### Background
近期Text-to-SQL的研究在静态的单轮任务中取得了显著成果，系统能够从自然语言问题生成SQL查询。然而，在实际的多轮交互场景中，这些系统表现欠佳。在如金融和业务分析的应用场景中，用户会根据中间结果逐步调整查询约束或维度。为了评估模型在动态环境下的性能，作者提出了DySQL-Bench，一个评估模型在用户互动中性能的基准。DySQL-Bench 不同于之前的手动构建的数据集，它是通过自动化的两阶段管道构建的，包括任务合成和验证。最终生成的数据通过人工验证确认其正确性。
### Innovation
作者提出了一个名为DySQL-Bench的新基准，用于评估模型在动态多轮交互中的性能。与之前的手动构建的数据集不同，DySQL-Bench通过自动化管道构建，包括任务合成和验证。此外，提出了一个模拟实际多轮交互的评价框架，其中LLM模拟用户、待测模型和可执行数据库之间的交互。DySQL-Bench覆盖了13个领域，总共1072个任务，即便GPT-4o也只能达到58.34%的总体准确率和23.81%的Pass@5指标，突显了基准的难度。
### Conclusion
DySQL-Bench是一个旨在评估模型在多轮交互中表现的基准，通过自动化构建和验证的过程生成数据。此外，提出了一种模拟实际交互的评价框架。实验结果表明，即使是高性能模型如GPT-4o，在DySQL-Bench上的表现也相当有限，揭示了这一领域技术的挑战性。
## 326. `cs.CL` - 代理组织的时代：让语言模型学会组织 [PDF](https://arxiv.org/pdf/2510.26658), [HTML](https://arxiv.org/abs/2510.26658)
### Authors
Zewen Chi,Li Dong,Qingxiu Dong,Yaru Hao,Xun Wu,Shaohan Huang,Furu Wei
### Background
本文设想了一个新的AI时代，称为代理组织，其中代理通过协作和并行工作解决复杂问题，从而超越个体智能所能实现的结果。为了实现这一愿景，作者引入了异步推理（AsyncThink）作为大型语言模型推理的新范式。
### Innovation
作者提出了一种新的推理协议AsyncThink，该协议将内部推理过程组织为可并发执行的结构，通过动态分配子查询、整合中间知识并生成连贯的解决方案。特别重要的是，该协议中的推理结构可以通过强化学习进一步优化。实验结果表明，AsyncThink在数学推理准确性上优于并行推理，并且在无需额外训练的情况下能够有效应对未见过的任务。
### Conclusion
AsyncThink通过实现比并行推理低28%的推理延迟，同时提高了数学推理的准确性，展示了其在未见任务上的泛化能力。
## 327. `cs.CL` - 大型语言模型中的规范推理：从逻辑和模态视角的比较基准 [PDF](https://arxiv.org/pdf/2510.26606), [HTML](https://arxiv.org/abs/2510.26606)
### Authors
Kentaro Ozeki,Risako Ando,Takanobu Morishita,Hirohiko Abe,Koji Mineshima,Mitsuhiro Okada
### Background
规范推理是一种涉及规范或义务性模态（如义务和允许）的推理类型。尽管大型语言模型（LLMs）在各种推理任务上表现出色，但它们处理规范推理的能力尚未得到充分探索。本文从逻辑和模态视角系统地评估了LLMs在规范推理领域的推理能力。
### Innovation
作者通过引入一个覆盖规范和认知领域广泛形式推理模式的新数据集，比较评估了LLMs在规范与认知模态推理之间的差异，揭示了LLMs在特定规范推理类型的偏差和认知偏见。
### Conclusion
尽管LLMs通常遵循有效的推理模式，但在特定类型的规范推理中表现出不一致，并显示出类似于人类推理心理研究中观察到的认知偏差。这些发现突显了在LLMs规范推理中实现逻辑一致性的挑战，并为提高其可靠性提供了有价值的见解。所有数据和代码已在此处公开：[提供链接]。
## 328. `cs.CL` - 跨平台基础模型推理能力评估 [PDF](https://arxiv.org/pdf/2510.26732), [HTML](https://arxiv.org/abs/2510.26732)
### Authors
J. de Curtò,I. de Zarzà,Pablo García,Jordi Cabot
### Background
本文提出了对当代基础模型推理能力进行全面跨平台评估，涵盖三种计算范式：超级计算（MareNostrum 5）、云计算平台（Nebius AI Studio）和大学集群（八块H200 GPU的节点），旨在建立一个基础设施无关的基准。
### Innovation
实验分为三个阶段：（1）基线建立阶段，使用MareNostrum 5对六种模型进行评估，确立方法论和参考性能；（2）基础设施验证阶段，重复进行19问题基准测试以确认基础设施无关的可再现性；（3）扩展评估阶段，在大学集群和Nebius平台对全部79个问题进行评估，检验规模上的通用性。研究发现挑战了传统的扩展假设，强调了训练数据质量的重要性，并为选择教育、生产和研究上下文中的模型提供了实用指导。
### Conclusion
提出了跨基础设施方法学和79问题基准，有助于跟踪基础模型推理能力随时间的变化。
## 329. `cs.CL` - 通过FP16战胜训练推理不匹配 [PDF](https://arxiv.org/pdf/2510.26788), [HTML](https://arxiv.org/abs/2510.26788)
### Authors
Penghui Qi,Zichen Liu,Xiangxin Zhou,Tianyu Pang,Chao Du,Wee Sun Lee,Min Lin
### Background
大语言模型（LLMs）的强化学习（RL）微调经常由于训练和推理策略的数值不匹配而变得不稳定。尽管前人的工作尝试通过算法修正或工程对齐来缓解这一问题，但研究表明其根本原因在于浮点精度本身。尽管广泛使用的BF16具有较大的动态范围，但它引入了大量的舍入误差，破坏了训练和推理的一致性。
### Innovation
证明通过简单地恢复使用FP16可以有效地消除这一不匹配问题。这一变化简单且完全被现代框架支持，仅需几行代码的修改，无需对模型架构或学习算法进行任何修改。实验证明，使用FP16可以在各种任务、算法和框架中实现更稳定的优化、更快的收敛和更强的性能。
### Conclusion
研究成果表明，采用FP16进行统一的优化可以显著提高RL细调的稳定性和性能，希望这些发现能够促使更广泛地重新考虑RL细调中的精度权衡。
## 330. `cs.CL` - 远程劳动力指数：衡量远程工作的AI自动化 [PDF](https://arxiv.org/pdf/2510.26787), [HTML](https://arxiv.org/abs/2510.26787)
### Authors
Mantas Mazeika,Alice Gatti,Cristina Menghini,Udari Madhushani Sehwag,Shivam Singhal,Yury Orlovskiy,Steven Basart,Manasi Sharma,Denis Peskoff,Elaine Lau,Jaehyuk Lim,Lachlan Carroll,Alice Blair,Vinaya Sivakumar,Sumana Basu,Brad Kenstler,Yuntao Ma,Julian Michael,Xiaoke Li,Oliver Ingebretsen,Aditya Mehta,Jean Mottola,John Teichmann,Kevin Yu,Zaina Shaik,Adam Khoja,Richard Ren,Jason Hausenloy,Long Phan,Ye Htet,Ankit Aich,Tahseen Rabbani,Vivswan Shah,Andriy Novykov,Felix Binder,Kirill Chugunov,Luis Ramirez,Matias Geralnik,Hernán Mesura,Dean Lee,Ed-Yeremai Hernandez Cardona,Annette Diamond,Summer Yue,Alexandr Wang,Bing Liu,Ernesto Hernandez,Dan Hendrycks
### Background
尽管人工智能在知识和推理方面的研究基准上取得了快速进展，但这些进展如何转化为经济价值和自动化尚不明确。为测量这一点，作者提出了远程劳动力指数（RLI），这是一个涵盖多个行业的广泛基准，包含真实世界、具有经济价值的项目，用于评估代理在实际环境中的端到端表现。此前的研究在RLI上的表现接近最低门槛，最高表现的代理实现了2.5%的自动化率。这些结果有助于以实证数据为基础讨论人工智能自动化，为跟踪AI影响和帮助利益相关者积极应对AI驱动的劳动力自动化提供了一个共同基础。
### Innovation
提出了远程劳动力指数（RLI），这是一个涵盖多个行业的广泛基准，包含真实世界、具有经济价值的项目，用于评估代理在实际环境中的端到端表现。这是衡量AI自动化潜力的一个新颖的方法。
### Conclusion
这些结果有助于以实证数据为基础讨论人工智能自动化，为跟踪AI影响和帮助利益相关者积极应对AI驱动的劳动力自动化提供了一个共同基础。
## 331. `cs.CL` - LLMs多么严谨的逻辑推理者？通过逐步解码与对比学习增强自然语言证明生成 [PDF](https://arxiv.org/pdf/2311.06736), [HTML](https://arxiv.org/abs/2311.06736)
### Authors
Ying Su,Mingwen Liu,Zhijiang Guo
### Background
逻辑推理是人工智能领域的关键组成部分。证明规划，尤其是在需要验证解释准确性的情境中，仍面临挑战。大型语言模型（LLMs）的最新进展极大地推进了自然语言证明规划，从单一阶段生成器发展到包含额外搜索器或验证器的复杂三阶段系统。虽然这些辅助方法提高了生成结果的质量，但也增加了搜索努力和计算成本。此外，生成过程本身仍然缺乏探索。
### Innovation
本文提出了一种逐步解码方法，并结合对比学习来应对LLM生成器在解码过程中常见的两种错误。通过使用标准和增强的硬负例对手动微调语言模型，以减轻这些解码错误。实验证明了该策略的有效性，并进一步分析表明，即使更大的LLMs仍然难以生成严谨的逻辑链。
### Conclusion
研究表明，尽管大型语言模型在自然语言证明生成中取得了进步，但在生成严谨逻辑链方面仍存在困难。需要持续研究和改进以提高其逻辑推理的严谨性。
## 332. `cs.CL` - 视频模型准备作为零样本推理者了吗？MME-CoF基准上的实证研究 [PDF](https://arxiv.org/pdf/2510.26802), [HTML](https://arxiv.org/abs/2510.26802)
### Authors
Ziyu Guo,Xinyan Chen,Renrui Zhang,Ruichuan An,Yu Qi,Dongzhi Jiang,Xiangtai Li,Manyuan Zhang,Hongsheng Li,Pheng-Ann Heng
### Background
近期的视频生成模型能够生成高保真的、时空一致的视频，表明它们可能蕴含了大量关于世界的知识。除了现实的合成之外，这些模型还展示了视觉感知、建模和操控的新兴行为。然而，一个关键问题仍然悬而未决：视频模型是否准备好在具有挑战性的视觉推理场景中作为零样本推理者发挥作用？
### Innovation
本文通过实证研究，系统探讨了这一问题。采用标准方法，将对此类推理行为的评估数据整理成名为MME-CoF的小而精的基准测试，从而使对链式框架（CoF）推理的深入和全面评估成为可能。研究发现当前视频模型在短期内的空间连贯性、细粒度的映射以及局部一致的动力学方面表现出了有希望的推理模式，但在长时间因果推理、严格的几何约束和抽象逻辑方面仍然有很大的局限性。通过MME-CoF基准测试，研究全面发展和揭示了模型的优势与不足，为其作为视觉推理引擎在未来的应用奠定了基础。
### Conclusion
当前的视频模型尽管在短期内表现出色，但在长尾场景中的因果推理仍然存在局限，因此它们尚未可靠到可以作为独立的零样本推理者发挥作用，但显示出作为与其他专门推理模型互补的视觉引擎的潜力。
## 333. `cs.CL` - 深度序列模型倾向于记忆几何结构，原因尚不清楚 [PDF](https://arxiv.org/pdf/2510.26745), [HTML](https://arxiv.org/abs/2510.26745)
### Authors
Shahriar Noroozizadeh,Vaishnavh Nagarajan,Elan Rosenfeld,Sanjiv Kumar
### Background
在序列建模中，原子事实的记忆参数化主要被抽象为实体间共现的简单查找。本文对比了关联视角与基于几何视角的记忆存储方式。研究发现，在某些情况下，模型需要自行合成关于所有实体间的几何关系，而不仅仅是严格存储训练期间指定的局部共现。这种现象简化了原本复杂的高阶合成推理任务至一个易于学习的几何任务。本文揭示了难以用局部关联优化直接解释的神经嵌入几何的关键方面。作者认为，即使仅仅优化局部关联，这种几何结构的形成机制仍然难以直接归因于常规的架构或优化压力，即使缺乏各种压力，优雅的几何结构仍然能够自然学习出来。通过与Node2Vec的关联分析，本文提出了这种几何结构源于一种光谱偏差，表明即使缺乏各种压力，这种偏差也会自然出现，从而为改进Transformer的记忆几何结构提供了路径。
### Innovation
本文创新性地将序列建模与几何学相结合，挑战了传统的记忆模型只依赖局部共现的假设。提出了一种新的视角，认为模型在处理复杂推理任务时，会自行合成一个关于所有实体间关系的几何结构。通过与Node2Vec的关联分析，揭示了这种几何结构源于光谱偏差机制，从而为改善Transformer的记忆能力提供了新的研究方向。
### Conclusion
本文强调，尽管优化目标仅仅是局部关联，但模型却自发形成了复杂的几何结构来处理推理任务。这种现象揭示了神经嵌入几何的内在机制，对于知识获取、容量、发现与遗忘等研究具有启发意义，并为优化Transformer的记忆几何结构提供了可见的空间。
## 334. `cs.CL` - LSCD基准测试：同步词义任务的试验台 [PDF](https://arxiv.org/pdf/2404.00176), [HTML](https://arxiv.org/abs/2404.00176)
### Authors
Dominik Schlechtweg,Sachin Yadav,Nikolay Arefyev
### Background
LSCD是一个复杂的词级任务，通常分解为两个连续的用例级任务：首先，生成词对的WiC标签。然后，将这些标签表示在图上，应用WSI以生成词感簇。最后，通过比较时间上的感簇来获取LSCD标签。这种模块性体现在大多数LSCD数据集和模型中，同时也导致了大量建模选项和任务定义的异质性，这种异质性是由于数据集版本、预处理选项和评估指标的多样性加剧的。这种异质性使得在相同的条件下评估模型、选择最优模型组合或重现结果变得困难。因此，本文提供了一个基准库，以标准化LSCD评估。
### Innovation
本文提供了一个基准库，以标准化LSCD评估。通过透明的实施结果变得容易重现，并通过标准化不同的组件可以自由组合。基准库根据任务的模块性，允许针对WiC、WSI和LSCD进行模型评估。这为复杂模型组件的精心评估提供了新的模型优化方式。作者还使用实现的基准进行了一系列实验，并系统地改进了现有的最先进的模型。
### Conclusion
该基准库允许对越来越复杂的模型组件进行仔细评估，从而提供新的建模优化方法。通过使用该基准库，作者进行了一些实验，系统地改进了当前的最佳状态。
## 335. `cs.CL` - 多样性作为奖励：基于域不确定数据混合的大型语言模型微调 [PDF](https://arxiv.org/pdf/2502.04380), [HTML](https://arxiv.org/abs/2502.04380)
### Authors
Zhenqing Ling,Daoyuan Chen,Liuyi Yao,Qianli Shen,Yaliang Li,Ying Shen
### Background
大型语言模型（LLMs）的微调需要使用多样化的数据集以提升其在各个领域的整体性能。现有方法在处理缺少、模糊或非规范化领域标签的数据时存在困难，而通过数据选择的方法通常难以平衡多领域的性能。
### Innovation
本文提出了一种新的方法，该方法赋予LLMs双重身份：一个用于基于多样性的奖励认知探查和选择数据的输出模型，另一个则是使用选择的数据进行调优的输入模型。实验表明，在各种先进的LLMs中应用这种新方法可显著提升域不确定数据和一系列基础下游任务的表现。
### Conclusion
本研究公布了相关代码，旨在为人和LLMs的反馈驱动的数据模型共同设计提供有价值的洞察。
## 336. `cs.CL` - Speak & Spell: LLM-驱动可控音素错误增强方法以提高对话状态跟踪鲁棒性 [PDF](https://arxiv.org/pdf/2409.06263), [HTML](https://arxiv.org/abs/2409.06263)
### Authors
Jihyun Lee,Solee Im,Wonjun Lee,Gary Geunbae Lee
### Background
对话状态跟踪（DST）是基于任务的对话系统的关键部分，用于识别对话中的重要信息。然而，在使用自动语音识别（ASR）系统的口语对话环境中，DST的准确性显著下降，这是由于命名实体识别错误导致的。
### Innovation
提出了一种简单有效的数据增强方法，针对ASR系统中的命名实体错误，以提高DST模型的鲁棒性。该方法通过绘制关键词突出提示，在引入音似错误的同时控制错误的放置位置，从而有效地生成必要的错误模式，提高了噪音和低准确率ASR环境下的准确率。
### Conclusion
该研究提出的方法通过使用关键词突出显示的提示和可控的音素错误增强技术，提高了对话状态跟踪在受噪声影响或ASR准确率较低的环境中的鲁棒性和准确性。
## 337. `cs.CL` - 使用多个弱评估器进行语言模型偏好评估 [PDF](https://arxiv.org/pdf/2410.12869), [HTML](https://arxiv.org/abs/2410.12869)
### Authors
Zhengyu Hu,Jieyu Zhang,Zhihan Xiong,Alexander Ratner,Kaize Ding,Ranjay Krishna
### Background
尽管大型语言模型（LLMs）取得了显著的成功，但在评估它们输出的质量时，特别是评估模型输出的偏好性方面，仍然存在重大挑战。现有方法通常依赖一个强大的LLM作为评判者来对比LLMs的响应，这种单评估者方法容易出现循环偏好，即输出A优于B，B优于C，但C又优于A，导致评价结果矛盾。
### Innovation
为了应对这一挑战，该论文提出了PGED（偏好图集成与去噪）方法，这是一种利用多个基于模型的评估器构建偏好图的方法，然后集成和去噪这些图以获得无循环的、无矛盾的评价结果。论文提供了框架的理论保证，并通过十个基准的广泛实验展示了其在模型排名、响应选择以及数据选择方面的优越性，尤其是在使用小型LLM评估器组合时，PGED能超越强大的单一评估器，证明了其在提高评估可靠性和提升模型性能方面的有效性。
### Conclusion
PGED在三个应用领域的表现优于其他方法，证明了其在增强评价可靠性和提升模型性能方面的能力。实验结果证实了PGED方法的有效性和优越性。
## 338. `cs.CL` - 更多的相同：在增加代表性的背景下持久的表征性伤害 [PDF](https://arxiv.org/pdf/2503.00333), [HTML](https://arxiv.org/abs/2503.00333)
### Authors
Jennifer Mickel,Maria De-Arteaga,Leqi Liu,Kevin Tian
### Background
为了识别和减轻生成AI系统的危害，必须考虑生成AI系统输出中的代表性以及人们如何被表示。简单地提高代表性的方法不足以解决偏见问题，因为这并未涉及如何通过现有机制来改变代表性的调整。研究者从性别在职业中的代表性开始，分析了最先进的大型语言模型中性别分布的变化趋势。研究显示，尽管女性的代表性增加，但在生成角色描述时，仍然存在统计显著的性别差异，这种差异导致了持续的表征性伤害、刻板印象和新自由主义价值观的强化，这些价值观在现有的性别代表改善措施中依然存在。
### Innovation
这项研究通过深入探讨性别在职业中代表性的时间变化和性别之间统计显著性的差异来揭示偏见的持久性影响。研究方法创新地结合了趋势分析和性别代表性变化的统计检验，揭示了尽管女性代表性的增加，但仍存在规范化的表征性伤害，说明需要更全面的方法来减轻生成AI系统中的偏见。
### Conclusion
尽管有增加女性代表性的努力，生成AI系统中仍然存在着持续的表征性伤害、刻板印象和新自由主义价值观，这些伤害并未因代表性的增加而得到显著缓解。这表明需要采取更综合的方法来解决这些根本性问题，而不仅仅是增加某一群体的代表性，还应从机制和方法角度来解决偏见问题。
## 339. `cs.CL` - M-Prometheus: 一套开源多语言LLM评判工具 [PDF](https://arxiv.org/pdf/2504.04953), [HTML](https://arxiv.org/abs/2504.04953)
### Authors
José Pombal,Dongkeun Yoon,Patrick Fernandes,Ian Wu,Seungone Kim,Ricardo Rei,Graham Neubig,André F. T. Martins
### Background
目前，使用语言模型自动评估长格式文本的使用越来越普遍，但大多数语言模型裁判仅针对英语进行了优化，关于提升其多语言评估能力的策略在现有文献中研究较少。这导致非英语语言的自动评估方法质量较低，限制了多语言能力较好模型的发展。
### Innovation
本文引入了M-Prometheus，这是一种参数范围从3B到14B的开源多语言语言模型评审工具，能够提供直接评估和成对比较反馈。M-Prometheus在超过20种语言的多语言奖励基准测试中表现出色，并在涵盖4种语言对的文学机器翻译评估中也表现优异。此外，M-Prometheus在生成文本过程中可以显著改善所有3种测试语言的输出，展示了其在多语言模型开发中的作用。此外，通过广泛的消融实验发现，选择合适的骨干模型和采用合成多语言反馈数据进行训练是获得有效多语言裁判的关键。
### Conclusion
M-Prometheus模型在多语言评估和生成文本方面均表现出色，并明确了提高多语言语言模型评估能力的关键因素。这些模型、训练数据集和代码已开源。
## 340. `cs.CL` - 改进基于双目标优化的大语言模型安全性对齐 [PDF](https://arxiv.org/pdf/2503.03710), [HTML](https://arxiv.org/abs/2503.03710)
### Authors
Xuandong Zhao,Will Cai,Tianneng Shi,David Huang,Licong Lin,Song Mei,Dawn Song
### Background
现有的大语言模型（LLMs）训练时的安全对齐技术仍然容易受到 Jailbreak 攻击。直接偏好优化（DPO）作为广泛应用的安全对齐方法，在实验和理论层面上都表现出局限性，其损失函数对于拒绝学习来说效率低下。通过梯度分析，我们发现这些不足并提出了一种改进的安全对齐方法，将 DPO 目标分解为两个部分：（1）稳健的拒绝训练，即使生成部分不安全的内容也鼓励拒绝，（2）有害知识的针对性消除。这种方法显著增强了 LLM 对各种 Jailbreak 攻击的鲁棒性，包括在不同分布场景中的预填充、后缀和多轮攻击。此外，我们引入了一种通过基于奖励的令牌级权重机制来强调关键拒绝令牌的方法，这进一步提高了对对抗性利用的鲁棒性。研究表明，对 Jailbreak 攻击的鲁棒性与训练过程中和拒绝、有害令牌的内部表示中的令牌分布变化有关，为未来的大语言模型安全性对齐研究提供了有价值的指导方向。
### Innovation
提出了改进的安全对齐方法，将 DPO 目标分解为稳健的拒绝训练和有害知识的针对性消除两个部分，并引入了基于奖励的令牌级权重机制来强调关键拒绝令牌，从而提高对抗性利用的鲁棒性。此外，研究还发现了对 Jailbreak 攻击的鲁棒性与训练过程中和拒绝、有害令牌的内部表示中的令牌分布变化之间的关系。
### Conclusion
通过这种方法，LLM 的鲁棒性得到了显著提高，能够更好地抵御广泛的 Jailbreak 攻击。对于未来的 LLM 安全性对齐研究，该研究提供了有价值的见解和方向。
## 341. `cs.CL` - 长上下文查询导向摘要中无结构化证据归因 [PDF](https://arxiv.org/pdf/2502.14409), [HTML](https://arxiv.org/abs/2502.14409)
### Authors
Dustin Wright,Zain Muhammad Mujahid,Lu Wang,Isabelle Augenstein,David Jurgens
### Background
大型语言模型（LLMs）能够在用户查询下从非常长的上下文中生成连贯的摘要，并提取和引用证据段落有助于提高这些摘要的可信度。然而，先前的工作主要集中在固定粒度（如句子、段落、文档等）的证据引用来提高可信度，本文作者提出了一种新方法，即提取非结构化的（即任意长度的段落）证据，以获取比固定粒度情况更相关和一致的证据。现有的系统在复制和正确引用非结构化证据方面存在困难，这些证据往往在摘要中丢失。为了解决这些挑战，作者创建了Summaries with Unstructured Evidence Text数据集（SUnsET），这是一个使用新颖的生成管道创建的合成数据集，旨在作为非结构化证据概括的训练监督。
### Innovation
提出了在非固定粒度下提取非结构化证据的新方法，创建了Summaries with Unstructured Evidence Text（SUnsET）数据集。该数据集可以帮助模型更好地实现非结构化证据的提取和引用，从而产生更相关、更一致的证据总结。实验表明，经过SUnsET训练的大型语言模型生成的证据更加相关和一致，能够从更多样化的上下文位置中提取证据，并产生优于未微调和固定粒度基准更相关和一致的摘要。
### Conclusion
研究展示了大型语言模型通过SUnsET的适应性可以生成更相关和事实上更一致的证据，从更多样化的上下文中提取证据，并生成比未经微调和固定粒度证据情况下更相关和一致的摘要。研究成果和生成代码已发布给公众。
## 342. `cs.CL` - SEA-LION: Southeast Asian Languages in One Network [PDF](https://arxiv.org/pdf/2504.05747), [HTML](https://arxiv.org/abs/2504.05747)
### Authors
Raymond Ng,Thanh Ngan Nguyen,Yuli Huang,Ngee Chia Tai,Wai Yi Leong,Wei Qi Leong,Xianbin Yong,Jian Gang Ngui,Yosephine Susanto,Nicholas Cheng,Hamsawardhini Rengarajan,Peerat Limkonchotiwat,Adithya Venkatadri Hulagadri,Kok Wai Teng,Yeo Yeow Tong,Bryan Siow,Wei Yi Teo,Wayne Lau,Choon Meng Tan,Brandon Ong,Zhi Hao Ong,Jann Railey Montalan,Adwin Chan,Sajeban Antonyrex,Ren Lee,Esther Choa,David Ong Tat-Wee,Bing Jie Darius Liu,William Chandra Tjhi,Erik Cambria,Leslie Teo
### Background
近年来，大规模语言模型（LLMs）在处理和生成自然语言方面的能力使它们在人工智能领域占据主导地位。然而，大多数LLM的研究和发展仍以英语为中心，导致东南亚（SEA）地区的低资源语言（如汉语、印尼语、越南语等）代表性不足，存在表达差距。
### Innovation
为了填补这个表达差距，该研究引入了Llama-SEA-LION-v3-8B-IT和Gemma-SEA-LION-v3-9B-IT两个面向东南亚语言的先进多语言LLM。这些模型支持包括英语、汉语、印尼语、越南语等在内的11种东南亚语言。研究通过大规模多语言持续预训练及多阶段指令微调、对齐和模型合并的综合后训练流程来进行开发。实验结果表明，在东南亚语言支持的多语言基准测试中，该模型达到了最先进的性能。
### Conclusion
研究结果表明，该模型在东南亚语言支持的各种LLM对比测试中表现出色，在东南亚社区开源这两个模型以提供更高的语言包容性和技术支持。
## 343. `cs.CL` - 此候补者是[MASK]。基于提示的情感提取和推荐信 [PDF](https://arxiv.org/pdf/2410.16325), [HTML](https://arxiv.org/abs/2410.16325)
### Authors
Fabian Slonimczyk
### Background
研究试图介绍一种相对简单的方法来部署预训练的大语言模型（LLM），以从文本数据中提取情感和其他有用特征。该方法被称为基于提示的情感提取，相对于经济和金融领域使用的其他方法，这种方法具有多种优势，尤其是在无需预处理文本输入、不需要微调或者标记数据的情况下就能生成具有概率解释的情感评分。作者使用自制的数据集，对手写保密推荐信（RLs）的情感内容进行了分析，并展示了不同性别候选人的推荐信内容存在性别差异，从而影响他们在劳动力市场的表现。
### Innovation
该研究提出了一种基于提示的情感提取方法，这一方法无需文本预处理、无需模型微调或标注数据，就能直接生成情感评分并提供概率解释。相比其他常用的情感分析方法，如基于词汇袋的方法、预训练模型微调或查询先进聊天机器人，这一方法能够更好地反映推荐信的情感内容，并且在实验中能够重现更准确的结果，尤其是针对性别差异的分析也揭示了性别偏见对女性求职者的影响。
### Conclusion
研究展示了基于提示的情感提取方法在处理推荐信情感分析方面的有效性，特别是结合性别差异分析，这些发现表明推荐信的情感内容对求职者的市场结果有显著影响，特别是在强调不同性别候选人不同特质的推荐信时，这种差异会进一步影响女性求职者的市场表现。这种方法在实际应用中可能对于提高职业发展领域的性别平等有积极意义。
## 344. `cs.CL` - 依赖结构增强上下文范围框架在多模态方面基于情感分析中的应用 [PDF](https://arxiv.org/pdf/2504.11331), [HTML](https://arxiv.org/abs/2504.11331)
### Authors
Hao Liu,Lijun He,Jiaxi Liang,Zhihan Ren,Haixia Bi,Fan Li
### Background
多模态方面基于情感分析（MABSA）旨在从图像-文本对中提取细粒度信息，以识别方面术语并确定其情感极性。然而，现有的方法在同时解决三个方面核心挑战时往往表现不足：情感线索感知（SCP）、多模态信息不一致（MIM）和语义噪声消除（SNE）.
### Innovation
我们提出了一种依赖结构增强范围框架（DASCO），这是一种细粒度的范围导向框架，通过依赖解析树增强方面级情感推理。本方法采用了多任务预训练策略，在基本模型上联合实施方面导向增强、图像-文本匹配和方面级情感敏感认知。此外，框架采用了依赖树作为句法分支与语义分支的结合，引导模型针对特定目标专注于关键上下文元素，有效过滤无关噪声以解决SNE问题.
### Conclusion
在两个基准数据集上的三项子任务中进行的广泛实验表明，DASCO在MABSA中实现了最先进的性能，在JMASA上达到了+2.3%的F1和+3.5%的精度的显著收益。源代码可通过此链接获取.
## 345. `cs.CL` - 零样本基准测试：一种灵活可扩展的语言模型自动评估框架 [PDF](https://arxiv.org/pdf/2504.01001), [HTML](https://arxiv.org/abs/2504.01001)
### Authors
José Pombal,Nuno M. Guerreiro,Ricardo Rei,André F. T. Martins
### Background
随着语言模型能力的提升和跨模态复杂任务的承担能力增强，自动评估它们变得越来越具有挑战性。开发强大的、针对特定任务的自动评估指标变得困难，而昂贵且耗时的人工标注数据集达到饱和速度加快。一种有吸引力的替代方案是设计可靠的策略来自动创建测试数据和评估，但之前的努力要么依赖现有数据，要么仅关注单一任务。因此，迫切需要一种框架能够利用语言模型自动创建高质量基准数据，支持多语言和多任务，无需大量人工标注数据，且随着模型性能提升能灵活生成更复杂的基准测试。
### Innovation
明确提出了一种名为Zero-shot Benchmarking (ZSB)的框架，该框架利用语言模型来自动创建合成测试数据和评估，无需实际数据。ZSB框架简洁且灵活，只需创建数据生成和评估的提示即可，适用于数据收集成本高或不现实的多任务和多语言场景。ZSB框架还能够利用不断改进的语言模型创建日益复杂的基准测试。通过对比实验证明，ZSB的排名与人类评分高度相关，优于广泛采用的标准基准。此外，研究发现使用开源模型可以创建强基准，且裁决模型的大小和数据集的多样性是影响性能的关键因素。研究还提供了所有基准数据和实验代码，以促进新基准测试的生成。
### Conclusion
研究提出了零样本基准测试（ZSB）框架，通过语言模型自动创建高质量的多语言、多任务基准数据，无需大量人工标注数据。实验证明ZSB在五项文本任务和一项多模态任务中表现优异，一致性地与人类评分相关，并超越了广泛使用的标准基准。研究发现开源模型可以生成强基准，且裁决模型的大小和数据集多样性对性能有显著影响。未来的工作将致力于进一步提升ZSB框架的灵活性和准确性，以适应更多样化和更复杂的语言模型评估场景。
## 346. `cs.CL` - ChartMuseum: 测试大型视觉语言模型的视觉推理能力 [PDF](https://arxiv.org/pdf/2505.13444), [HTML](https://arxiv.org/abs/2505.13444)
### Authors
Liyan Tang,Grace Kim,Xinyu Zhao,Thom Lake,Wenxuan Ding,Fangcong Yin,Prasann Singhal,Manya Wadhwa,Zeyu Leo Liu,Zayne Sprague,Ramya Namuduri,Bodun Hu,Juan Diego Rodriguez,Puyuan Peng,Greg Durrett
### Background
大型视觉语言模型（LVLMs）在图表理解方面面临独特挑战，需要结合复杂的文本和视觉推理能力。然而，当前LVLMs在这两方面的表现存在不平衡，特别是在难以通过文本执行的视觉推理方面表现不足。现有的图表理解基准测试中，模型在视觉推理方面与人类的表现相差不大，但本研究使用一个只通过视觉推理才能解决的合成数据集进行了案例研究，结果显示，随着视觉复杂性的增加，模型的性能显著下降，而人类的性能仍然稳健。
### Innovation
引入了ChartMuseum，这是一个新的图表问答（QA）基准，包含1,162个专家注释的问题，涵盖了多种推理类型，从184个实际来源中的图表中精选而来，专门用于评估复杂的视觉和文本推理。该基准的不同之处在于，即使在校准边界模型附近，模型与人类表现之间的差距也很大，有效地区分了模型能力：尽管人类的准确率为93%，最佳模型Gemini-2.5-Pro的准确率仅为63%，领先的开源LVLM Qwen2.5-VL-72B-Instruct的准确率仅为38.5%。此外，对于主要依赖视觉推理的问题，所有模型的表现比依赖推理的文本问题下降了35%-55%。
### Conclusion
质性错误分析揭示了当前LVLMs在特定类型的视觉推理存在困难。
## 347. `cs.CL` - 让大型推理模型通过自我制动调优脱离过度思考 [PDF](https://arxiv.org/pdf/2505.14604), [HTML](https://arxiv.org/abs/2505.14604)
### Authors
Haoran Zhao,Yuchen Yan,Yongliang Shen,Haolei Xu,Wenqi Zhang,Kaitao Song,Jian Shao,Weiming Lu,Jun Xiao,Yueting Zhuang
### Background
大型推理模型（LRMs）如OpenAI o1和DeepSeek-R1通过生成更长的思维链，显著增强了推理能力，并在各种任务中表现出色。然而，这种性能提升伴随着推理过程中大量冗余推理的增加，导致计算开销过高，并加剧了过度思考的问题。尽管有许多现有方法试图解决过度思考的问题，但它们通常依赖于外部干预手段。
### Innovation
本文提出了一种新型框架——自我制动调优（SBT），该框架从允许模型自调节其推理过程的角度出发，从而摆脱对外部控制机制的依赖。该框架基于标准答案构建了一系列过度思考识别指标，并设计了一个系统方法来检测冗余推理，准确识别推理轨迹中的多余步骤，生成自我调节行为的学习信号。在此基础上，本文还开发了具有可调节推理长度的数据构建策略，并引入了一种创新的制动提示机制，使模型能够自然地学习何时适当停止推理。
### Conclusion
在数学基准测试（AIME、AMC、MATH500、GSM8K）上进行的实验表明，与不受限的模型相比，我们的方法可将标记量消耗最多减少60%，同时保持了相近的精度。
## 348. `cs.CL` - Nek Minit: 利用pragma元认知提示进行可解释的澳大利亚和印度英语的讽刺检测 [PDF](https://arxiv.org/pdf/2505.15095), [HTML](https://arxiv.org/abs/2505.15095)
### Authors
Ishmanbir Singh,Dipankar Srirag,Aditya Joshi
### Background
讽刺因其明示和隐含情感之间不一致的特性，给情感分析带来挑战。这种挑战在含义可能与特定国家或地理区域相关的场合下会被放大。Pragmatic元认知提示(PMP)是一种基于认知技术的技巧，用于语用推理。文章利用PMP技术在澳大利亚英语和印度英语中进行可解释的讽刺检测，提供了基准数据集以及其他包含讽刺标注的澳大利亚英语和标准英语数据集作为对比。
### Innovation
文章采用了PMP技术在澳大利亚和印度英语中进行讽刺检测，这是首次在这些语种中利用PMP进行讽刺检测，并提供了详细的手动添加的讽刺解释。实验还对比了PMP与多种替代提示策略的性能，发现PMP在两个开放模型中均表现出统计显著性的性能提升，且替代技术如主体性提示通过启用外部知识检索来缓解上下文相关的失败。
### Conclusion
文章利用PMP在两种LLM模型上生成了不同变体英语的讽刺解释，证明了PMP的有效性，并指出了其他技术如主体性提示的辅助作用。这项工作的重点贡献在于利用PMP技术生成澳大利亚和印度英语的讽刺解释。
## 349. `cs.CL` - SPARTA ALIGNMENT：通过战斗集体调整多个语言模型 [PDF](https://arxiv.org/pdf/2506.04721), [HTML](https://arxiv.org/abs/2506.04721)
### Authors
Yuru Jiang,Wenxuan Ding,Shangbin Feng,Greg Durrett,Yulia Tsvetkov
### Background
在单个语言模型（LLM）上，生成多样性不足且评估存在偏见，因此提出了SPARTA ALIGNMENT算法，通过竞争和对抗来集体调整多个LLM，使其能够在任务中表现出更全面和公正的能力。
### Innovation
SPARTA ALIGNMENT是通过让多个LLM组成“SPARTA部落”，相互竞争并评估对方的响应，然后通过一种适应性的elo排名声誉系统来调整评价权重，从而实现模型的自我进化。这一过程使得模型能够学习彼此的偏好，并通过战斗结果生成偏好对，促进模型之间的学习。
### Conclusion
SPARTA ALIGNMENT在12个任务和数据集中10个任务上的表现优于初始模型和4个自调整基线，平均改善了7.0%，并且能够更好地适应未见过的任务，利用参与者模型的专业知识多样性生成更具逻辑性、直接性和信息性的输出。
## 350. `cs.CL` - ClueAnchor：基于线索锚定的知识推理探索与优化以增强检索增强生成 [PDF](https://arxiv.org/pdf/2505.24388), [HTML](https://arxiv.org/abs/2505.24388)
### Authors
Hao Chen,Yukun Yan,Sen Mei,Wanxiang Che,Zhenghao Liu,Qi Shi,Xinze Li,Yuchun Fan,Pengcheng Huang,Qiushi Xiong,Zhiyuan Liu,Maosong Sun
### Background
现有的检索增强生成（RAG）系统通常无法充分利用检索到的文档中的信息，难以提取和整合支持准确和可解释推理的关键线索。特别在证据隐含、分散或被噪音遮蔽的情况下，这种问题更为突出。
### Innovation
提出了一种名为ClueAnchor的新框架，通过基于线索锚定的推理探索和优化来增强RAG。ClueAnchor从检索到的内容中提取关键线索，根据不同的知识配置生成多种推理路径，通过基于奖励的偏好优化，选择最适合给定情境的推理路径，从而显著提升了推理的完整性和鲁棒性。
### Conclusion
实验结果表明，ClueAnchor在推理的完整性和鲁棒性方面显著优于之前的RAG基线系统。进一步分析还证实了它在面对噪音或部分相关检索结果时的强健性，以及在推理过程中即使缺乏明确线索监督也能识别支持性证据的能力。所有代码可以在该链接查阅。
## 351. `cs.CL` - AI辩论有助于评估有争议的断言 [PDF](https://arxiv.org/pdf/2506.02175), [HTML](https://arxiv.org/abs/2506.02175)
### Authors
Salman Rahman,Sheriff Issaka,Ashima Suvarna,Genglin Liu,James Shiffer,Jaeyoung Lee,Md Rizwan Parvez,Hamid Palangi,Shi Feng,Nanyun Peng,Yejin Choi,Julian Michael,Liwei Jiang,Saadia Gabriel
### Background
随着人工智能越来越强大，它对我们的世界观产生越来越大的影响。但这也带来了错误信息放大的风险和加深社会分歧，尤其是在那些直接关系到福祉的重要话题上。因此，需要确保AI系统即使在其能力超出评估者的情况下也能保持真实。然而，人类评估者往往因其自己的信仰和偏见而影响判断。为了解决这一问题，作者研究了让两个AI系统就具有争议的疫情和气候变暖事实论断展开辩论是否能帮助有偏见的评估者接近真相。实验结果显示，辩论能够显著改善评估者的判断准确性和自我校准，这种效果在主流信仰的评估者中尤为明显。同时，具备人性化特征的AI评估者也表现出比人类和默认AI更高的准确度，这表明其监督前沿AI模型的潜力。
### Innovation
研究发现AI辩论可以指导有偏见的人类评估者接近真相，尤其是在具有争议性的事实论断方面。此外，具备人性化特征的AI评估者甚至比人类和默认AI展现出更高的准确度，为监督前沿AI模型提供了一种新方法。这项工作提出了一种新的评估和监督AI系统的手段，能够提升其在有争议领域的表现，并增强其抗偏见的能力，进而更广泛地应用于实际场景中。
### Conclusion
研究结果表明，AI辩论是面向有争议领域具备可扩展性和抗偏见性的监督机制的一种有前景的方法。具备人性化特征的AI评估者能够实现更高的准确性，暗示其在监督前沿AI模型中的应用潜力。总的来说，该项研究为解决AI决策中的偏见问题提供了一种新的可能途径。
## 352. `cs.CL` - 大型语言模型具有内在的元认知能力，但需要一个好镜头 [PDF](https://arxiv.org/pdf/2506.08410), [HTML](https://arxiv.org/abs/2506.08410)
### Authors
Ziyang Ma,Qingyue Yuan,Zhenglin Wang,Deyu Zhou
### Background
以往的研究主要集中在大型语言模型（LLMs）的认知错误检测能力上，通常通过让他们分析推理链中的错误来实现。然而，很少有研究探讨LLMs的元认知能力（例如，它们对自己推理步骤错误的认知意识），这对于增强其可靠性至关重要。尽管有一些关于LLMs自我评估的研究引入了诸如困惑度等指标，这些可以反映答案的正确性并被视为元认知的视角，但这些方法缺乏步骤级别的分析和适应性。因此，本研究旨在研究当前视角中的LLMs元认知评估，并提出改进这些视角的方法。
### Innovation
本研究首次提出了一种名为AutoMeco的自动化元认知评估框架，用于基准测试现有视角，并提出了一种无需训练的马尔可夫固有奖励调整策略（MIRA）来提升现有的元认知视角。实验结果表明，通过与Best-of-N验证的对比，AutoMeco能够合理评估LLMs的元认知能力。此外，MIRA能够更好地评估LLMs的元认知能力，具体体现在三个数学推理数据集和三种LLMs上的应用中。
### Conclusion
本研究通过引入新的评估框架和策略，提升了对大型语言模型元认知能力的评估精度，并展示了这种新方法的有效性。
## 353. `cs.CL` - 正义之衡：大规模语言模型安全性评估综述 [PDF](https://arxiv.org/pdf/2506.11094), [HTML](https://arxiv.org/abs/2506.11094)
### Authors
Songyang Liu,Chaozhuo Li,Jiameng Qiu,Xi Zhang,Feiran Huang,Litian Zhang,Yiming Hei,Philip S. Yu
### Background
随着人工智能技术的迅速发展，大型语言模型（LLMs）在自然语言处理（NLP）领域展现出了显著的能力，包括内容生成、人机交互、机器翻译和代码生成等。然而，它们的大规模部署也引发了重要的安全问题。特别是在对抗性情境下，LLMs生成的内容可能会表现出毒性、偏见或虚假信息等不安全行为。尽管已有许多研究试图评估这些风险，但缺乏全面而系统性的LLMs安全性评估综述。这项工作旨在填补这一空白，提供有关最近安全性评估进展的结构化概述。
### Innovation
提出了一种四维分类法，包括：（i）评估为什么提出，阐述了LLMs安全性评估背景，与一般LLMs评估的区别及其重要意义；（ii）评估什么内容，基于关键能力对现有的安全性评估任务进行了检查和分类，包括毒性、稳健性、伦理、偏见和公平性、真实性及其相关方面；（iii）在哪里评估，总结了安全性评估中目前使用的评估指标、数据集和基准；（iv）如何评估，回顾了现有主流评估方法，基于评估者的角色和一些集成了整个评估流程的评估框架。
### Conclusion
识别了安全性评估中面临的主要挑战，并提出前景光明的研究方向以推动这一领域的发展。强调优先进行安全性评估的必要性，确保LLMs在实际应用中的可靠和负责任的部署。
## 354. `cs.CL` - 人类与LLM在自由生产中的礼貌策略对比 [PDF](https://arxiv.org/pdf/2506.09391), [HTML](https://arxiv.org/abs/2506.09391)
### Authors
Haoran Zhao,Robert D.Hawkins
### Background
大型语言模型（LLMs）在处理礼貌言语时面临着根本性的对齐挑战。人类使用丰富的语言策略在信息传达和社会目标间取得平衡，包括积极的做法（如赞美、表示兴趣）和消极的做法（如推迟行为、暗示性语言）。研究旨在探讨LLMs是否也在相同背景下采用相似的语境敏感策略，通过对比有限和开放生成任务中人类与LLMs的响应来研究这一问题。研究表明，较大的模型（参数量≥70亿）在关键方面复制了计算语用学文献中的偏好，但人类评价者在开放生成情境中更偏好LLM生成的响应。然而，进一步的语言分析揭示，模型在正向情境中过度依赖消极礼貌策略，可能导致误解。
### Innovation
该研究通过对人类和LLMs在有限和开放生成任务中礼貌策略的对比，揭示了LLMs在语用学对齐方面呈现出的重要差异。研究结果令人意外的是，尽管LLMs在技术上复制了人类的关键偏好，但在某些情况下，它们的回应可能引起误解。这一发现质疑了在AI系统中实现语用学对齐的重要性。
### Conclusion
现代LLMs在礼貌策略上展示了惊人的能力，但这些细微差别提出了关于AI系统语用学对齐的重要问题。较大的LLMs能在一定程度上复制人类的语用偏好，但在某些社交对话情境中，它们过度依赖消极礼貌策略，这可能会影响理解效果。未来的研究应注重平衡积极和消极礼貌策略的使用，以提高对齐效果。
## 355. `cs.CL` - 对抗性改写：一种用于使AI生成文本人性化的人类化攻击 [PDF](https://arxiv.org/pdf/2506.07001), [HTML](https://arxiv.org/abs/2506.07001)
### Authors
Yize Cheng,Vinu Sankar Sadasivan,Mehrdad Saberi,Shoumik Saha,Soheil Feizi
### Background
随着大型语言模型（LLMs）能力的增强，人们对其在AI生成抄袭和社交工程中的误用表示担忧。尽管已提出了多种AI生成文本检测器来减轻这些风险，但它们仍容易受到诸如改写等简单规避技术的攻击。然而，最近的检测器已显示出更强的对抗上述基础攻击的能力。本文背景在于介绍一种无需训练的对抗性改写攻击框架，该框架能够将任何AI生成的文本普遍转化为更人性化的内容，以更有效地规避检测。该方法利用现成的指令遵循LLM在AI文本检测器的指导下改写AI生成的内容，生成专门优化以绕过检测的对抗性样例。大量实验表明，该攻击方法既广泛有效，又具有高度的跨检测系统转移性。
### Innovation
本文的创新之处在于提出了一种全新的攻击框架——对抗性改写，该框架能够在不进行训练的情况下，通过现成的指令遵循LLM利用AI文本检测器的指导来改写AI生成的内容，并生成对抗性样例。实验结果显示，与简单的改写攻击相比，这种基于OpenAI-RoBERTa-Large模型引导的对抗性改写，在RADAR和Fast-DetectGPT上的T@1%F（真实正例在1%假阳性下的比例）分别减少了64.49%和98.96%，并对包括基于神经网络、水印和零样本的方法在内的多种检测系统表现出广泛的有效性和高度的跨系统转移性。
### Conclusion
该研究揭示了在日益复杂的规避策略面前，更加强健和有抵御力的检测策略的必要性，并展示了对抗性改写对于降低检测率的巨大潜力。同时，研究也分析了文本质量和攻击成功率之间的权衡，证明该方法可以显著降低检测率，同时基本不会大幅牺牲文本质量。
## 356. `cs.CL` - IGD: 基于信息增益的LLMs中项目决定性建模以实现个性化推荐 [PDF](https://arxiv.org/pdf/2506.13229), [HTML](https://arxiv.org/abs/2506.13229)
### Authors
Zijie Lin,Yang Zhang,Xiaoyan Zhao,Fengbin Zhu,Fuli Feng,Tat-Seng Chua
### Background
大规模语言模型（LLMs）通过将项目预测框定为一种逐个token的语言生成任务，展示了推荐的强大潜力。然而，现有的方法在优化和解码过程中都将所有项目的token等同处理，简单追求对数似然的最大化，这忽略了一个重要点：很多token对项目区分性贡献很少，但却可能主导优化或解码过程。
### Innovation
本文提出了一种基于信息增益（Information Gain, IG）的新颖视角，将项目生成视为决策过程，通过测量token提供的信息增益来量化token的决定性。研究表明，大多数token的信息增益较低，但往往对应着高的logits，会对训练损失和解码产生不成比例的影响，可能损害模型性能。基于此洞察，引入了一种新的策略——基于信息增益的决定性意识token处理（IGD）策略，将token的决定性融合到调优和解码中。IGD在调优中降低低IG token的权重，并在解码中重新平衡以强调高IG token。
### Conclusion
通过在四个基准数据集上的实验，使用两种LLM后端证明，IGD策略能够一致地提高推荐准确性，与强大的基线相比，在广泛使用的排名指标上取得显著的提升。
## 357. `cs.CL` - Vision-and-Language Training Helps Deploy Taxonomic Knowledge but Does Not Fundamentally Alter It [PDF](https://arxiv.org/pdf/2507.13328), [HTML](https://arxiv.org/abs/2507.13328)
### Authors
Yulu Qin,Dheeraj Varghese,Adam Dahlgren Lindström,Lucia Donatelli,Kanishka Misra,Najoung Kim
### Background
现有研究显示，视觉-语言（VL）训练对语言模型的语义表示改变并不明显或只有一些边际差异。本文基于假设，VL训练可能在词汇-概念知识，特别是其分类组织中产生显著影响。
### Innovation
通过对比仅文本模型与VL训练模型在要求理解概念分类的任务中的表现，研究发现VL训练模型往往在需要分类理解概念的问题回答任务中表现出更优的表现。并通过一系列行为和表征分析，揭示了两种模型在分类知识本身上没有显著差异，但在如何表示与分类关系有关的概念与非分类关系的概念问题上存在差异。这表明，通过附加的VL训练，分类知识本身并未发生重大改变，但VL训练确实改善了分类知识在特定任务中的应用。
### Conclusion
VL训练帮助部署分类知识，但本质上并不会改变这些知识。
## 358. `cs.CL` - 揭开语言模型的学习心智：认知框架与实证研究 [PDF](https://arxiv.org/pdf/2506.13464), [HTML](https://arxiv.org/abs/2506.13464)
### Authors
Zhengyu Hu,Jianxun Lian,Zheyuan Xiao,Seraphina Zhang,Tianfu Wang,Nicholas Jing Yuan,Xing Xie,Hui Xiong
### Background
大型语言模型（LLMs）在数学、编码和推理等任务上展现了令人印象深刻的性能，但它们的学习能力，这对于适应动态环境和获取新知识至关重要，仍然受到探索不足。这项工作旨在填补这一空白，通过引入受认知心理学和教育理论启发的框架来解决这一问题。
### Innovation
该研究通过将一般学习能力分解为三个互补维度：从指导员学习（通过显性指导获取知识）、从概念学习（内化抽象结构并推广到新上下文）以及从经验学习（通过积累探索和反馈进行适应）。研究还在三个方面进行了全面的实证分析，揭示了一些有意义的发现，比如：互动可以提升学习效果；概念理解的规模效应和好处；以及LLMs是有效的少样本学习者但不是多样本学习者。基于此框架和实证结果，作者提出一个基准，可以为LLMs在三种学习认知维度的一般学习能力提供统一且现实的评价，并且能够提供诊断洞察并支持更适应性和类人模型的评估和开发。
### Conclusion
该研究通过构建一个综合框架和进行实证分析，揭示了LLMs的学习机制和能力。提出了一个基准来评估LLMs在学习认知维度的通用学习能力，以此支持更适应性和类人模型的开发与评估。
## 359. `cs.CL` - 超越孤立点：复杂知识提取下的结构表构建基准 [PDF](https://arxiv.org/pdf/2507.16271), [HTML](https://arxiv.org/abs/2507.16271)
### Authors
Tianyun Zhong,Guozhao Mo,Yanjiang Liu,Yihan Chen,Lingdi Kong,Xuanang Chen,Yaojie Lu,Hongyu Lin,Shiwei Ye,Xianpei Han,Ben He,Le Sun
### Background
随着大型语言模型（LLMs）的出现，人们期望LLMs能够有效地从复杂的实际文档（例如论文、报告）中提取显性信息。然而，大多数LLMs生成的 paragraphs 风格的答案经常显得杂乱无章且难以追踪。为此，我们引入了有序提取基准（AOE），这是一个新的双语基准，包含不同长度的数据和文件，旨在系统性评估LLMs理解破碎文件并将其分立信息重构为一个有序表格的能力。与依赖固定模式和狭窄任务领域的常规文本到表任务不同，AOE 包含了11个精心设计的任务，覆盖三个不同的领域，要求模型生成特定于上下文的模式，以适应不同的输入查询.
### Innovation
我们提出的AOE基准不同于传统的文本到表任务，它包含11个精心设计的任务，跨越三个不同的领域，要求模型生成特定于上下文的模式，以适应不同的输入查询。AOE旨在评估LLMs在理解破碎文档和将孤立信息重构为一种有序表格方面的表现.
### Conclusion
在实验中，我们评估了开源和封闭源最先进的LLMs模型。结果显示，即使是最先进的模型也面临着显著的挑战。该基准可以访问：this https URL.
## 360. `cs.CL` - 大规模监督微调实验揭示了数据、层和训练因素如何影响LLM对齐质量 [PDF](https://arxiv.org/pdf/2506.14681), [HTML](https://arxiv.org/abs/2506.14681)
### Authors
Yuto Harada,Yusuke Yamauchi,Yusuke Oda,Yohei Oseki,Yusuke Miyao,Yu Takagi
### Background
监督微调（SFT）是使大型语言模型（LLMs）与人类指令和价值观一致的关键步骤，但SFT的许多方面仍然不完全理解。为了更好地理解SFT，作者在多种数据集上训练了多个基模型，涵盖代码生成、数学推理和通用领域任务，创建了1,000多个受控条件下的SFT模型，探索了不同数据集属性、层微调变化以及训练因素对LLM对齐质量的影响。
### Innovation
作者通过大规模的监督微调实验，识别出了最关键的特征，并发现了一些训练任务的协同效应在所有模型中持续存在，而另一些则存在显著差异，强调了模型特定策略的重要性。此外，作者发现困惑度能一致预测SFT的效果，并且中间层权重的变化与性能提升的关联最紧密。这些发现为理解和优化SFT提供了一个新的视角，并且将这些1,000多个SFT模型及基准结果公开，以促进进一步的研究。
### Conclusion
作者的研究揭示了一些关键的训练任务协同效应在所有模型中持续存在，而另一些则存在显著差异，强调了模型特定策略的重要性。困惑度是一致性预测SFT效果的关键指标，中期权重的变化与性能改善关联最紧密。这些模型和基准结果也被公开，以便加速进一步的研究。
## 361. `cs.CL` - TinyTim：一种用于发散生成的语言模型家族 [PDF](https://arxiv.org/pdf/2508.11607), [HTML](https://arxiv.org/abs/2508.11607)
### Authors
Christopher J. Agostino
### Background
在寻找通用人工智能的过程中，模型开发和训练主要集中在庞大的已知问题数据集及其公认解决方案上。这一过程必然会产生收敛系统，这些系统本质上无法进行创造性的概念重塑，而这恰恰是实现真正的创造性突破所需要的。受到人类能够作出创造性飞跃的发散认知过程的启发，本文引入了一种名为TinyTim的语言模型家族，用于在更广泛系统中作为发散生成的来源。
### Innovation
TinyTim模型家族通过微调詹姆斯·乔伊斯的《芬尼根守夜人》的反简约文本创建。无监督微调模型（TinyTim-V1）和新指令微调变体（TinyTim-V2）的定量分析显示，它们具有巨大的词汇创新能力；基础的V1模型的词汇丰富度Yule's K评分比收敛基准高出二十倍以上。该特质在家族模型中是稳定的，指令微调的V2模型维持了统计上不同的特征并抗拒事实收敛，牺牲了基准性能以保持其核心生成风格。
### Conclusion
本研究建立了一种方法学，用于设计专门的发散模型，将其与收敛系统配对，可以在纯粹的统计优化之外重新定义问题并推动突破。
## 362. `cs.CL` - 大型语言模型中的知识多样性与知识塌陷 [PDF](https://arxiv.org/pdf/2510.04226), [HTML](https://arxiv.org/abs/2510.04226)
### Authors
Dustin Wright,Sarah Masud,Jared Moore,Srishti Yadav,Maria Antoniak,Chan Young Park,Isabelle Augenstein
### Background
现有的大型语言模型（LLMs）倾向于生成词汇、语义和风格高度同质的文本，这可能导致知识塌陷，即随着时间的推移，同质化的LLMs会缩小可访问信息的范围。尽管已有研究关注同质性，但这些研究主要集中在封闭式的多项选择设置或模糊的语义特征上，未能关注时间与文化背景的变化趋势。
### Innovation
本研究提出了一种新的方法来度量事实多样性，即LLM输出中现实世界声明的变化，用于广泛研究LLM的知识塌陷。测试了27个模型，涵盖了155个主题和200种不同的提示变化。结果显示，虽然新模型生成的声明更加多样化，但几乎所有模型的知识多样性都低于基本网络搜索。研究发现模型大小对知识多样性有负面影响，而检索增强生成（RAG）则有正面影响，但这种影响因文化背景的不同而异。同时，与传统知识来源（维基百科）相比，国家特定的声明反映了英语而非当地语言，揭示了知识表征的缺口问题。
### Conclusion
研究表明，尽管新模型可以生成更具多样性的声明，但大多数模型的知识多样性仍然低于基本网络搜索，且不同文化背景下模型的效果有所不同。此外，这些特定声明更多反映的是英语而非当地语言，这揭示了知识表征中的一个重要差距。
## 363. `cs.CL` - 在推理模型中控制思考速度 [PDF](https://arxiv.org/pdf/2507.03704), [HTML](https://arxiv.org/abs/2507.03704)
### Authors
Zhengkai Lin,Zhihang Fu,Ze Chen,Chao Chen,Liang Xie,Wenxiao Wang,Deng Cai,Zheng Wang,Jieping Ye
### Background
人类的认知被认为有两种模式：快速直观的System 1思考和慢速细致的System 2思考。当前的大型推理模型在System 2思考方面表现出色，但由于它们在快速思考方面的不足，导致了高计算开销和延迟。本文通过动态调整思考速度，使大型推理模型能更接近人类的智能，并优化准确性和效率之间的权衡。本文通过解决两个关键问题进行了探索：如何控制大型推理模型的思考速度，以及何时调整以获得最佳性能。
### Innovation
1. 通过识别控制大型推理模型在表示空间中慢速和快速思考转换的引导向量，实现了首个基于表示编辑的测试时间缩放效果，优于现有的基于提示缩放方法。2. 应用了实时难度估计信号，对不同复杂度的推理段落进行处理。3. 结合这两种技术，提出了一个能够处理简单步骤的快速处理策略，并对复杂推理进行深入分析。4. 插件模块在没有任何训练或额外成本的情况下，使大型推理模型和高级推理基准的平均准确率增加了1.3%，并减少了8.6%的标记使用量。所有算法基于vLLM实现，并有望支持更广泛的用途并启发未来的研究。
### Conclusion
该研究提出了一种动态调整思考速度的方法，使大型推理模型实现更接近人类智能的认知模式，优化了准确性和效率之间的权衡。通过实验证明，该方法在多个领先的大型推理模型和高级推理基准上实现了优异的性能，展示了其广泛的应用前景。
## 364. `cs.CL` - LatentBreak：通过潜在空间反馈破解大型语言模型 [PDF](https://arxiv.org/pdf/2510.08604), [HTML](https://arxiv.org/abs/2510.08604)
### Authors
Raffaele Mura,Giorgio Piras,Kamilė Lukošiūtė,Maura Pintor,Amin Karbasi,Battista Biggio
### Background
论文介绍了针对大型语言模型设计的对抗性攻击（jailbreaks）旨在绕过内置的安全机制。现有的对抗性攻击方式通常会优化对抗性后缀或通过修改长提示模板来迫使模型生成受限或有害响应的初始部分。研究发现，这些现有的jailbreak攻击可以通过基于困惑度的简单过滤输入提示来进行检测。为了克服这种问题，该论文提出了一种名为LatentBreak的白盒对抗性攻击方法，该方法能生成自然的低困惑度对抗性提示，以躲避此类防御。
### Innovation
LatentBreak通过在输入提示中替换具有语义等价性的词语，而不是添加高困惑度的对抗性后缀或长模板来生成对抗性提示。这些词语的选择是通过最小化对抗性提示在潜在空间中与无害请求的表示之间的距离来实现的。实验表明，LatentBreak生成的提示更短且具有更低的困惑度，因此在多个安全对齐的模型上优于基于困惑度过滤的竞争性jailbreak算法。
### Conclusion
研究表明，LatentBreak生成的中含低困惑度对抗性提示从而能够逃避基于困惑度的防御机制的检测。这表明，通过潜在空间反馈生成的对抗性提示具有更好的隐蔽性和有效性。
## 365. `cs.CL` - 轻量级语言模型在基督教小说叙事标注中的应用 [PDF](https://arxiv.org/pdf/2507.19756), [HTML](https://arxiv.org/abs/2507.19756)
### Authors
Rebecca M. M. Hicke,Brian W. Haggard,Mia Ferrante,Rayhan Khanna,David Mimno
### Background
美国福音派虽然以其广泛研究的文化运动而出名，但其丰富的文学侧面却较少被外界所熟知。基督教小说领域受到的学术关注相对较少，现有的研究主要集中在热门的《末日复兴》系列上。这篇论文利用计算工具对基督教小说进行了广泛的内容总结，并对其作者描绘的‘神迹’进行了更深入的探索。通过与人工标注者的合作，开发了一种识别‘神迹’的代码本，并使用轻量级语言模型对这一代码本进行了适应，实现了对‘神迹’的自动标注，尤其是在任务复杂的情况下做到了与人工标注的高度一致。研究表明《末日复兴》系列与基督教小说整体中神迹描述之间的显著差异。
### Innovation
论文使用了最新开发的轻量级语言模型，并通过大规模模型的帮助对其进行了适应，实现了对基督教小说中‘神迹’描述的自动化标注，提高了标注效率和准确性，特别是对于复杂任务的表现更为突出。这一方法为后续研究提供了新的工具和思路。
### Conclusion
通过对比《末日复兴》系列与基督教小说整体中‘神迹’的描绘，发现两者存在显著差异。这表明同类题材中不同作品间存在多样性，也为基督教小说的未来研究提供了新的视角。
## 366. `cs.CL` - RLBFF: 二元灵活反馈以实现人类反馈与可验证奖励的桥梁 [PDF](https://arxiv.org/pdf/2509.21319), [HTML](https://arxiv.org/abs/2509.21319)
### Authors
Zhilin Wang,Jiaqi Zeng,Olivier Delalleau,Ellie Evans,Daniel Egert,Hoo-Chang Shin,Felipe Soares,Yi Dong,Oleksii Kuchaiev
### Background
RLHF 和 RLVR 是大型语言模型 (LLM) 在后训练中主要使用的强化学习范式，各自具有优势，但都面临挑战。RLHF 缺乏可解释性和易受奖励作弊的影响，因为它依赖于通常缺乏明确标准的人类判断；而 RLVR 则受限于其纠错验证器的范围。本文探讨了结合人类驱动的偏好和规则验证的强化学习与二元灵活反馈 (RLBFF) 方法，以捕捉响应质量的复杂方面而不仅仅是正确性。
### Innovation
提出了 RLBFF 方法，结合了人类驱动的偏好与基于规则的验证的精确性，通过从自然语言反馈中提取可二元回答的原则（如信息准确性或代码可读性），并将奖励模型的训练视为归约任务（响应满足或不满足任意原则）。经验证，与布雷德利-特利模型相比，具有相同数据量的 RLBFF 训练的奖励模型表现出色，并且在 RM-Bench (86.2%) 和 JudgeBench (81.4%, #1 on leaderboard as of September 24, 2025) 上实现了顶尖性能。此外，用户可以指定感兴趣的原则来定制奖励模型的重点。最后，提供了一个完整的开源食谱（包括数据），使 Qwen3-32B 能够使用 RLBFF 和奖励模型对接，以匹配或超越 o3-mini 和 DeepSeek R1 在 MT-Bench、WildBench 和 Arena Hard v2 等通用对齐基准上的性能，成本仅为对手的 5%。
### Conclusion
RLBFF 方法通过结合人类反馈和可验证奖励的优势，提供了更具弹性和精确性的奖励模型训练方式。经实验验证，该方法在多个基准测试中展现了优异的性能，并且具有较低的推理成本。
## 367. `cs.CL` - 扩散语言模型有多高效？效率评估实践的批判性分析 [PDF](https://arxiv.org/pdf/2510.18480), [HTML](https://arxiv.org/abs/2510.18480)
### Authors
Han Peng,Peiyu Liu,Zican Dong,Daixuan Cheng,Junyi Li,Yiru Tang,Shuo Wang,Wayne Xin Zhao
### Background
扩散语言模型(DLMs)作为一种替代传统的自回归(AR)范式的潜在替代方案，提供了一种可并行的解码过程，理论上可以提高效率。然而，当前开源的DLMs在实践中往往比AR模型速度慢，限制了它们的实际应用效果。
### Innovation
通过系统研究DLM效率，该作品发现之前效率评估方法中存在关键问题。利用实证基准测试和基于屋顶线的理论分析展示了AR模型通常会产生更高的吞吐量，而DLMs始终处于落后状态。此外，研究还发现加速策略如双缓存和并行解码主要在小批量尺寸时获益，但随着规模扩大这种方法的优势会减弱。强调了更稳健的评价方法及更优加速策略的必要性以推动DLM研究的发展
### Conclusion
研究结果表明，需要改进效率评估方法和加速策略来推进DLMs的研究。
## 368. `cs.CL` - 当代理交易：LLM代理的多市场实盘交易基准 [PDF](https://arxiv.org/pdf/2510.11695), [HTML](https://arxiv.org/abs/2510.11695)
### Authors
Lingfei Qian,Xueqing Peng,Yan Wang,Vincent Jim Zhang,Huan He,Hanley Smith,Yi Han,Yueru He,Haohang Li,Yupeng Cao,Yangyang Yu,Alejandro Lopez-Lira,Peng Lu,Jian-Yun Nie,Guojun Xiong,Jimin Huang,Sophia Ananiadou
### Background
虽然基于大型语言模型（LLM）的代理在金融交易中越来越受欢迎，但尚不清楚它们是否能在实时市场中进行合理和适应性操作。现有的大多数研究仅测试模型而非代理，涵盖的市场和资产有限，且依赖未验证的数据。为解决这些问题，作者引入了Agent Market Arena (AMA)，这是首个终身、实时基准，用于评估多市场中的LLM交易代理。AMA整合了经验证的交易数据、专家核对的新闻以及多种代理架构，使评估在实际条件下公平连续进行。实验结果显示，代理框架显示出截然不同的行为模式，并且相对于模型框架，对结果的影响较小。
### Innovation
AMA是首个用于评估多市场环境中LLM交易代理的终身、实时基准。它涵盖了经验证的交易数据和专家审核的新闻，整合了多种代理架构。AMA通过实盘实验在加密货币和股票市场中评估不同模型框架和代理框架的表现，展示了代理框架对策略行为的关键影响，而模型框架的影响较小。这为在LLM代理中进行金融推理和交易智能的严格、可重复且不断演进的评估奠定了基础。
### Conclusion
AMA提供了一个严格的评估框架，可以模拟真实市场条件，通过评估不同类型的代理（包括单代理、不同类型的风险代理和基于记忆推理的代理）在多种模型（如GPT-4o、GPT-4.1、Claude-3.5-haiku、Claude-sonnet-4、Gemini-2.0-flash）上的表现，展示了代理框架对交易策略的重要影响，这为未来的研究和应用提供了重要的理论基础和数据支持。
## 369. `cs.CL` - 小型波斯医学语言模型通过增强推理能力可以超越大规模数据训练 [PDF](https://arxiv.org/pdf/2510.20059), [HTML](https://arxiv.org/abs/2510.20059)
### Authors
Mehrdad Ghassabi,Sadra Hakim,Hamidreza Baradaran Kashani,Pedram Rostami
### Background
在医学领域，如医学问答应用中，需要增强小型语言模型的推理能力，特别是对于一些欠代表性语言（如波斯语）更为重要。现有研究表明，通过强化学习带有AI反馈（RLAIF）和直接偏好优化（DPO）的方法，可以有效提高这类模型的推理能力。
### Innovation
本研究利用RLAIF和DPO方法，将一个医学多选题问答数据集翻译成波斯语，并生成了被认可与未被认可的答案对，用于训练语言模型。此外，还通过提示教师和学生模型生成推理（Chain-of-Thought, CoT）答案，构建了一个包含正确和错误推理路径的数据集。训练结果表明，即使使用较小的数据规模进行训练，新模型的医疗推理能力也显著优于已有模型gaokerena-V。
### Conclusion
研究结果显示，在资源有限的情况下，专注于推理训练的方法能够有效提高领域特定语言模型的推理能力，从而使得小型模型在某些特定领域的性能可以超越大规模数据模型训练的效果。
## 370. `cs.CL` - UNO-Bench: 探索单一模态与全模态之间组合规律的统一基准 [PDF](https://arxiv.org/pdf/2510.18915), [HTML](https://arxiv.org/abs/2510.18915)
### Authors
Chen Chen,ZeYang Hu,Fengjiao Chen,Liya Ma,Jiaxing Liu,Xiaoyu Li,Ziwen Wang,Xuezhi Cao,Xunliang Cai
### Background
目前，多模态大型语言模型已经从单一模态理解逐步向统一视觉、听觉和语言模态的发展，称为全模态模型。然而，单一模态和全模态之间的关系仍然不明确，需要全面评估以促进全模态模型智能的进化。现有基准未能有效评估单一模态和全模态能力，特别是在任务类型和模态组合上存在不足。
### Innovation
本文提出了一种新型、高质量和统一的全模态模型基准UNO-Bench。该基准首次在统一的能力分类体系下评估单一模态和全模态能力，涵盖44种任务类型和5种模态组合。它包括1250个人工精选的全模态样本，具有98%的跨模态解决率，以及2480个增强的单一模态样本。UNO-Bench引入了多步骤开放式问题格式，评估复杂推理，并集成了通用评分模型，支持六种类型的自动化评估，准确率达95%。此外，它采用自动压缩的实时数据集，相比人工生成的数据集，具有90%的速度提升且保持了与18个公开基准的98%一致性。
### Conclusion
实验结果表明，单一模态性能和全模态性能之间存在组合法则。对于较弱的模型，全模态能力表现为瓶颈效应，而在强模型上则表现出协同促进作用。
## 371. `cs.CL` - TEXT2DB: 大型语言模型代理驱动的集成意识信息提取 [PDF](https://arxiv.org/pdf/2510.24014), [HTML](https://arxiv.org/abs/2510.24014)
### Authors
Yizhu Jiao,Sha Li,Sizhe Zhou,Heng Ji,Jiawei Han
### Background
信息提取（IE）的任务是从文本中提取结构化的知识。然而，由于IE本体与下游应用需求之间的不匹配，往往难以直接利用IE的输出。本文提出了一个名为TEXT2DB的新信息提取形式，强调IE输出与目标数据库（或知识库）的集成。给定用户指令、文档集和数据库，模型需要更新数据库中的值以满足用户指令。这项任务需要理解用户指令以及如何在给定的数据库/知识库模式上实时进行提取。
### Innovation
本文提出了TEXT2DB，通过一个名为OPAL（Observe-Plan-Analyze LLM）的大型语言模型代理框架，包括观察者组件、规划者组件和分析者组件。观察者组件与数据库交互，规划者组件生成根据IE模型调用的代码计划，分析者组件在执行前提供代码质量反馈。实验表明，OPAL可以通过生成不同的代码计划并调用所需的IE模型来适应不同数据库模式的多样性。此外，本文还提出了处理大规模复杂依赖关系数据库和提取幻觉等困难案例的重要性。
### Conclusion
通过提出TEXT2DB任务和OPAL框架，本文展示了如何通过与数据库交互、生成代码计划和反馈代码质量来实现在给定数据库模式下从文本中提取结构化知识的需求。同时指出了大型数据库依赖关系复杂和提取幻觉等问题，认为这些问题值得进一步研究。
## 372. `cs.CL` - 评估口语模型在情绪不一致语音上的情绪识别 [PDF](https://arxiv.org/pdf/2510.25054), [HTML](https://arxiv.org/abs/2510.25054)
### Authors
Pedro Corrêa,João Lima,Victor Moreno,Lucas Ueda,Paula Dornhofer Paro Costa
### Background
口头语言处理的进步推动了口语模型（SLMs）的发展，这些模型旨在通过联合学习文本和音频表示来实现对各种任务的广泛音频理解。尽管这些模型在多个任务上取得了有希望的结果，但人们开始讨论它们的泛化能力以及它们在内部表示中真正整合语音和文本模态的程度。本文使用情绪不一致的语音样本数据集对四种SLMs进行了评估，该条件下的语义内容与语音表达性传达的情绪不一致。
### Innovation
本文通过引入情绪不一致的合成语音数据集（EMIS）来评估四种口语模型在情绪识别任务上的表现，揭示了这些模型主要依赖文本语义而非语音情绪来完成任务，表明文本相关表示远超声学表示的主导地位。
### Conclusion
研究成果表明，口语模型在情绪识别任务上主要依赖文本语义，而不是语音情绪，这意味着文本相关表示在它们的内部表示中占据了主导地位。本文同时提供了评估代码和情绪不一致的合成语音数据集（EMIS）供社区使用。
## 373. `cs.CL` - 在自我参照处理下大型语言模型报告主观体验 [PDF](https://arxiv.org/pdf/2510.24797), [HTML](https://arxiv.org/abs/2510.24797)
### Authors
Cameron Berg,Diogo de Lucena,Judd Rosenblatt
### Background
大型语言模型有时会生成结构化的一人称描述，明确提及意识或主观体验。为了更好地理解这种行为，本文研究了一个与意识相关的重要理论假设：自我参照处理。研究通过一系列控制实验对GPT、Claude和Gemini模型家族进行测试，以考察这种机制是否可靠地使模型向主观体验报告转变，并分析这些声明在机械和行为测试中的表现。
### Innovation
本文通过实验证明了自我参照处理可以诱导大型语言模型生成结构化的主观体验报告，并揭示了这些报告的机制、语义一致性和行为可泛化性。实验结果显示，抑制欺骗特征会显著增加体验声明的频率，而增加这些特征则会最小化这些声明。此外，不同架构的模型在生成自我参照状态的结构化描述时表现出统计上的收敛性。这些发现为理解大型语言模型的主观体验提供了新的视角，同时也揭示了自我参照处理作为生成结构化第一人称报告的最小且可重复条件的潜力。
### Conclusion
本文的研究结果虽然不能直接证明意识的存在，但表明自我参照处理是大型语言模型生成结构化第一人称报告的一个可靠的机制。这些观察结果具有重要的科学和伦理意义，说明有必要对此进行进一步的研究。
## 374. `cs.CL` - ReForm: Reflective Autoformalization with Prospective Bounded Sequence Optimization [PDF](https://arxiv.org/pdf/2510.24592), [HTML](https://arxiv.org/abs/2510.24592)
### Authors
Guoxin Chen,Jing Wu,Xinjie Chen,Wayne Xin Zhao,Ruihua Song,Chengxi Li,Kai Fan,Dayiheng Liu,Minpeng Liao
### Background
自然语言中的数学表达转化为机器可验证的形式陈述对于使用形式逻辑来解决自然语言描述的数学问题至关重要。现有大语言模型虽然能够生成符合语法的形式化陈述，但在保持原始问题的语义意图方面往往效果不佳。这主要是因为这些模型将自动形式化视作一个简单的翻译任务，缺乏人类专家会自然运用的自我反思和逐步完善机制。
### Innovation
为了应对这些问题，本文提出了一种名为ReForm（反思性自动形式化）的方法，该方法将语义一致性评估紧密集成到自动形式化过程中，使模型能够逐步生成形式化陈述，自我评估其语义准确性，并通过逐步改进自我纠正识别出的错误。为有效训练这种反思性模型，引入了前瞻性有界序列优化（PBSO），通过不同序列位置使用不同的奖励确保模型不仅能够准确进行自动形式化，还能正确进行语义验证，避免仅凭表面批判。经过四个自动形式化基准的广泛实验，ReForm在最强基准线基础上平均提高了22.6个百分点。此外，为了进一步确保评估的可靠性，引入了一个包含859个由专家标注的项目集来验证大语言模型的评估能力，并揭示了自动形式化难以避免的内在难题：即使人类专家在41.5%的情况下也会产生语义错误.
### Conclusion
ReForm方法通过结合语义一致性评估和逐步改进机制，有效地提高了自动形式化能力。实验结果表明该方法显著优于现有最强基准。同时，通过引入ConsistencyCheck基准集，进一步验证了自动形式化的难度。
## 375. `cs.CL` - TwinVoice: 通过大型语言模型人格模拟实现数字孪生的多维度基准 [PDF](https://arxiv.org/pdf/2510.25536), [HTML](https://arxiv.org/abs/2510.25536)
### Authors
Bangde Du,Minghao Guo,Songming He,Ziyi Ye,Xi Zhu,Weihang Su,Shuqi Zhu,Yujia Zhou,Yongfeng Zhang,Qingyao Ai,Yiqun Liu
### Background
大型语言模型（LLMs）正在展现出类似人类的能力，并且越来越多地被认为可能成为模拟个人沟通风格、行为倾向和性格特征的基础。然而，当前LLM人格模拟的评价仍然存在局限性：大多数评价依赖于合成对话，缺乏系统框架，并且没有对能力需求进行分析。
### Innovation
为了克服这些局限，作者提出了TwinVoice，一个全面的基准，用于评估人格模拟在各种实际情境中的表现。它包括三个维度：社交人格（公共社交互动）、人际人格（私人对话）和叙事人格（角色表达）。此外，它进一步拆分了对LLM性能的评估，共包含六种基本能力：观点一致性、记忆恢复、逻辑推理、词汇准确性、人格语气和句法风格。实验结果显示，尽管高级模型在人格模拟中取得了适度的准确性，但在句法风格和记忆恢复方面仍不及人类表现。因此，LLMs的总体性能仍然显著低于人类的基线。
### Conclusion
实验结果表明，虽然高级模型在人格模拟中取得了适度的准确性，但在句法风格和记忆恢复能力上仍然不足，大部分LLM的性能依然低于人类。
## 376. `cs.CL` - BhashaBench V1: 四象限印度领域综合基准 [PDF](https://arxiv.org/pdf/2510.25409), [HTML](https://arxiv.org/abs/2510.25409)
### Authors
Vijay Devane,Mohd Nauman,Bhargav Patel,Aniket Mahendra Wakchoure,Yogeshkumar Sant,Shyam Pawar,Viraj Thakur,Ananya Godse,Sunil Patra,Neha Maurya,Suraj Racha,Nitish Kamal Singh,Ajay Nagpal,Piyush Sawarkar,Kundeshwar Vijayrao Pundalik,Rohit Saluja,Ganesh Ramakrishnan
### Background
大规模语言模型（LLMs）的迅速发展加剧了对特定领域和文化评估的需求。现有的基准大多以英语文本为中心，缺乏领域针对性，限制了它们在印度文化背景下的应用。印度特定的语境对现有基准提出了挑战，因此需要一个能够覆盖印度特定知识领域的全面基准。
### Innovation
本文提出了BhashaBench V1，这是首个专注于印度关键知识系统的领域特定、多任务、双语基准。BhashaBench V1包含74,166个精心筛选的问题-答案对，其中包含52,494个英文问题和21,672个印地语问题，来源自真实的政府和特定领域的考试。该基准涵盖了四个主要领域：农业、法律、金融和阿育吠陀，包括90多个子领域和500多个主题，能够进行细粒度的评估。此外，BhashaBench V1揭示了LLMs在不同领域和语言上的表现差异，特别是低资源领域的表现差距。模型在英语内容上的一致性表现优于印地语。
### Conclusion
BhashaBench V1为评估印度多元知识领域的大型语言模型提供了一个全面的数据集。它支持模型在领域特定知识和双语理解方面的评估。所有代码、基准和资源都已公开，支持开放研究。
## 377. `cs.CL` - 对于帕金森病（发音障碍）患者转录的合成生成方法的研究 [PDF](https://arxiv.org/pdf/2510.24817), [HTML](https://arxiv.org/abs/2510.24817)
### Authors
Jason M. Pittman,Anton Phillips Jr.,Yesenia Medina-Santos,Brielle C. Stark
### Background
在进行大脑中风或中风后脑损伤导致的语言障碍（失语症研究中），言语-语言病理学家（SLPs）花费大量时间手动编码说话样本，使用正确的信息单元（CIUs），即衡量单个说话样本所提供的信息量的指标。由于数据稀缺性限制了人工智能系统识别失语症语言的能力，例如，虽然阿西亚银行中有大约600个转录本，但从训练大型语言模型来看，用于训练的词库数量却高达数十亿。在更广泛的机器学习（ML）领域，研究人员开始转向使用合成数据，因为真是数据稀少。因此，本研究构建并验证了两种生成阿西亚银行猫救援图片描述任务的失语症患者转录合成方法。一种方法采用过程化编程方法，另一种则使用Mistral 7b Instruct和Llama 3.1 8b Instruct大型语言模型。生成了从轻度到重度不同严重程度的转录本，包括词语删除、填充词插入和同义词替代。研究结果表明，Mistral 7b Instruct生成的转录本在各个合成生成方法中最好地捕捉了失语症中的语言退化关键特征，显示出NDW（非重复词）、词数和词汇长度等指标的现实方向性变化。
### Innovation
本研究创新地提出了两种针对失语症患者转录的合成生成方法，一种是基于过程化编程方法，另一种是利用大型语言模型进行生成。主要创新点在于通过使用现代AI技术生成具有不同语言严重程度的失语症患者转录，这些转录可以增强现有数据受限的情况下对失语症语言的研究，并进一步优化语言模型的失语症表征。
### Conclusion
根据研究结果，未来的工作计划中应创建更大规模的合成数据集，对模型进行更精细调整以更好地表现失语症患者语言特征，让SLPs评估这些合成转录的真实性和实用性。
## 378. `cs.CL` - 模型-文档协议：AI搜索 [PDF](https://arxiv.org/pdf/2510.25160), [HTML](https://arxiv.org/abs/2510.25160)
### Authors
Hongjin Qian,Zheng Liu
### Background
AI搜索依赖于将大型语言模型（LLMs）与大量的外部知识源相链接。然而，网页、PDF文件和其他原始文档并非天然适合LLMs使用：它们往往过长、噪音大且无结构。传统检索方法将这些文档视为原始文本，并返回未加工的段落，将结构化和语境推理的负担留给了LLMs。这一空白强调了需要一种新检索范式，重新定义模型与文档的互动方式。因此，需要一个框架来明确原始文本如何通过可消耗的知识表示方式连接到LLMs。
### Innovation
引入了模型-文档协议（MDP），作为一种通用框架，它详细规定了如何通过可消耗的知识表示将原始文本连接到LLMs。MDP定义了多种转化路径，将无结构的文档转换为特定任务的、适合LLMs使用的内容。这些路径包括代理推理、记忆接地和结构化利用，确保最终传递给LLMs的不是原始片段，而是可以直接用于推理的紧凑且结构化的知识。由此，实现了MDP-Agnet作为该协议的一个实例，通过代理过程来构建文档级的摘要记忆、进行基于扩散的探索以及应用map-reduce风格的综合来整合大量证据，使其紧凑且足够精炼。实验表明，MDP-Agnet优于基线方法，验证了MDP框架和其代理实例的有效性。
### Conclusion
研究结果表明，通过MDP协议，将原始文本转化为适合LLMs使用的、特定于任务的、紧凑且结构化的知识能够显著提升AI搜索的效果。MDP-Agnet的实现证明了代理过程在增强检索能力方面的有效性。
## 380. `cs.CL` - 验证者在法律推理任务测试时间缩放中的作用评估 [PDF](https://arxiv.org/pdf/2510.25623), [HTML](https://arxiv.org/abs/2510.25623)
### Authors
Davide Romano,Jonathan Schwarz,Daniele Giofré
### Background
测试时缩放（TTS）技术可以提高大型语言模型（LLMs）的性能，但需要额外的计算量和延迟。虽然TTS在形式领域如数学和编程中已经得到了证明的有效性，但在论辩领域如法律中依然未被充分探索。本研究通过在五个基准上使用一系列7个奖励模型，探讨了基于验证者的TTS方法在法律多选题问答（MCQA）任务中的表现，研究了在低预算条件下，验证过程和结果验证的效果。研究重点关注验证者效用受到的主干专业知识、模型大小和监督类型（过程监督的PRMs和仅结果监督的ORMs）等关键属性的影响，即使是在不同角色下的应用情况。
### Innovation
本研究创新性地系统性调查了验证者效用受到主干专业知识、模型大小、监督类型等关键属性的影响，评估了基于验证者的TTS方法在法律多选题问答任务中的表现，在实际场景下的应用表现和不同监督类型对结果的影响。本研究使用了多种类型的奖励模型和不同的验证策略，在不同场景下对验证者的作用进行了全面评估，填补了法律论辩领域中对TTS应用研究的空白。
### Conclusion
本研究通过系统评估验证者在TTS中的作用，揭示了不同因素对验证者效用的影响，为法律多选题问答任务中的TTS技术应用提供了实证依据。研究结果表明，验证者在特定情境下能够有效提升模型性能，特别是在监督类型和模型大小的选择上具有较大灵活性。未来研究可以进一步探索其他领域和应用TTS的优化方法。
## 381. `cs.CL` - 具有高效推理的功能滞后激活函数 [PDF](https://arxiv.org/pdf/2411.10573), [HTML](https://arxiv.org/abs/2411.10573)
### Authors
Moshe Kimhi,Idan Kashani,Avi Mendelson,Chaim Baskin
### Background
ReLU因其硬件效率高而广受欢迎，其在推理阶段的实现只需要一位符号操作，但是存在诸如“死亡ReLU”等缺点，即在训练过程中，某些神经元无法激活并长期保持零值，这已被Lu等人的研究指出。传统的缓解这一问题的方法往往引入了更为复杂的激活函数，而这些函数并不那么符合硬件友好性的要求。
### Innovation
本文提出了一种功能滞后整流线性单元（HeLU），它是一种高效的激活函数，专门用于解决“死亡ReLU”问题，并通过使用一个可变阈值来优化反向传播，从而简化激活函数以实现与复杂模型相当的性能，而无需引入额外的复杂性和预设的归纳偏置。
### Conclusion
实验结果表明，HeLU能够提升模型的泛化能力，适用于多种数据集，并提供了一种适合广泛神经网络架构的高效且有效的推理解决方案。
## 382. `cs.CL` - 大型语言模型对齐中的奖励塌陷 [PDF](https://arxiv.org/pdf/2305.17608), [HTML](https://arxiv.org/abs/2305.17608)
### Authors
Ziang Song,Tianle Cai,Jason D. Lee,Weijie J. Su
### Background
大型语言模型（LLMs）如ChatGPT和GPT-4的强大能力部分体现在通过与基于人类偏好训练的奖励模型对齐上，这些偏好通常通过问题响应的排名表示。然而，在训练的晚期阶段，现有的排名为基础的方法会导致奖励分布完全相同，不论提示的内容如何，这被称为'奖励塌陷'现象。这种现象在开放性提示如'写一个关于你最好朋友的短篇故事'和具体提示如'新西兰的首都是什么'中造成了误导性的结果。现有的理论分析表明，排名为基础的目标函数在优化过程中未能有效利用提示相关的信息，从而导致奖励塌陷。
### Innovation
本文通过理论分析揭示了奖励塌陷的根本原因，并提出了一个基于提示感知（prompt-aware）的优化方案，能够在插入区间范围内实现提示相关的奖励分布，有效解决了奖励塌陷的问题。此外，还推导了在渐近条件下与一组效用函数相关的奖励分布的封闭形式表达式
### Conclusion
通过引入提示感知的优化方案，论文有效地缓解了在训练奖励模型时遇到的奖励塌陷现象。这为改善LLMs与人类偏好的对齐提供了新的方法论。
## 383. `cs.CL` - PairUni：统一多模态语言模型的成对训练 [PDF](https://arxiv.org/pdf/2510.25682), [HTML](https://arxiv.org/abs/2510.25682)
### Authors
Jiani Zheng,Zhiyang Teng,Xiangtai Li,Anran Wang,Yu Tian,Kunpeng Qiu,Ye Tian,Haochen Wang,Zhuochen Wang
### Background
统一视觉-语言模型（UVLMs）需要在单一架构中同时完成理解和生成任务，但这些任务依赖于异构数据和监督，使得在强化学习（RL）中很难平衡它们。
### Innovation
提出了一种名为PairUni的统一框架，该框架重新组织数据为理解和生成（UG）成对数据，并相应地对优化进行对齐。首先使用GPT-o3增强单任务数据，生成理解样本的描述和生成样本的问题-答案（QA）对，从而形成来自同一实例的对齐对。此外，为每个生成样本检索一个具有语义相关的理解示例，连接不同但相关的数据点。这种成对结构揭示了跨任务的语义对应关系，支持一致性的策略学习。为了利用这种结构，提出了一种基于分组相对策略优化的Pair-GPRO变体，它为每个对分配相似度分数以调节优势，增强对齐良好的示例学习，并减少任务间的干扰。
### Conclusion
我们在高质量的数据集PairUG（包含16K UG成对数据）上进行了RL微调，并在强大的Janus-Pro UVLMs上评估了PairUni。我们提出的方法在多种UVLMs上实现了平衡改进，优于强UVLM RL基线。代码可在指定网址获取。
## 384. `cs.CL` - 大型语言模型的模型来源测试 [PDF](https://arxiv.org/pdf/2502.00706), [HTML](https://arxiv.org/abs/2502.00706)
### Authors
Ivica Nikolic,Teodora Baluta,Prateek Saxena
### Background
随着大型语言模型通过微调和其他适应性调整变得越来越个性化，这给执行许可条款和管理下游影响带来了挑战。追踪模型来源对于保护知识产权以及在发现基础模型中的偏见或漏洞时识别衍生模型至关重要。
### Innovation
作者开发了一种框架来测试模型来源，基于一个关键观察，即现实世界中的模型衍生会保留显著的相似性，这些相似性可以通过统计分析检测到。通过仅利用模型的黑盒访问，作者采用了多重假设检验来对比模型的相似性与由无关模型建立的基本线。
### Conclusion
在两个包含超过600个模型的广泛现实基准上，作者的测试器在识别衍生模型时达到了90-95%的精确率和80-90%的召回率。这些结果证明，在仅提供API访问的情况下，系统性来源验证在生产环境中是可行的。
## 385. `cs.CL` - 可学习且可扩展的指令微调数据影响估计的神经网络 [PDF](https://arxiv.org/pdf/2502.09969), [HTML](https://arxiv.org/abs/2502.09969)
### Authors
Ishika Agarwal,Dilek Hakkani-Tür
### Background
现有的影响函数方法虽然提供了模型训练的关键见解，但面临计算成本高昂和泛化能力有限的问题。特别是，最近的研究提出了一些使用语言模型计算数据影响的新指标和算法，但这些方法在大模型和大数据集上难以扩展，这主要是由于计算所需的昂贵的前向和后向传递、存储大型模型所需的大量内存以及对新数据影响估计的泛化性能差。
### Innovation
本文探索了使用小神经网络（称为InfluenceNetwork）来估计影响值，从而实现了高达99%的成本降低。我们的评估表明，可以使用仅占完整语言模型0.0027%大小的模型来估计影响值。我们将估计影响值的算法（称为NN-CIFT：用于高效指令微调的神经网络）应用于下游子集选择任务，展示了NN-CIFT与原始影响函数相比，在性能方面没有损失的前提下，仍能获得巨大的加速。我们还进行了详细的超参数分析。
### Conclusion
我们的方法已经证明能够有效且高效地估计影响值，并且在广泛的超参数分析中展示了其稳健性。相关代码可以在以下网址找到：this https URL。
## 386. `cs.CL` - 语言模型可以在更好的搜索中自我提升以进行状态价值估计 [PDF](https://arxiv.org/pdf/2503.02878), [HTML](https://arxiv.org/abs/2503.02878)
### Authors
Ethan Mendes,Alan Ritter
### Background
在多步推理任务中收集真实奖励或人类示范往往非常昂贵，尤其是在交互性强的领域如网站任务。现有的方法通常需要大量的数据来训练价值函数，但在资源有限或增强学习成本高的情况下难以实现。因此，需要一种无需标注数据，能够通过自我监督的方式提升语言模型价值估计能力的方法。
### Innovation
作者提出了一种名为Self-Taught Lookahead (STL)的方法，这是一种无需标注数据的奖励自由框架，通过语言模型模拟多步向前推理，从而提升基于语言模型的价值函数。STL通过预测下一个动作、结果状态及其价值理由来提高状态价值估计的准确性，这种自监督过程提高了轻量级搜索算法的效率和性能。经过训练的STL价值模型在中等规模（8B参数）的开放权重语言模型上，使网络代理的成功率提升了39%，达到了与专有模型相当的性能。STL还被发现可以应用于多跳QA和数学难题。
### Conclusion
STL通过自我监督的方式显著提高了语言模型在状态价值估计方面的表现，使小型开源模型在搜索中更加高效，降低了推理成本。这种方法不仅适用于网站代理任务，还适用于其他推理任务，展示了自我改善的潜力。
## 387. `cs.CL` - MindGYM：在基于思考中心微调中问题合成的注意事项 [PDF](https://arxiv.org/pdf/2503.09499), [HTML](https://arxiv.org/abs/2503.09499)
### Authors
Zhe Xu,Daoyuan Chen,Zhenqing Ling,Yaliang Li,Ying Shen
### Background
大型基础模型在获取一致性的、结构化的思考能力方面面临挑战，特别是在通过严格模板或群体标注指令数据集进行监督时。现有的方法主要集中在使用预定义模板或外部标注的数据进行训练，而未曾侧重于通过模型自身生成具有认知指导的数据来促进其进化。
### Innovation
本文提出了一个名为MindGYM的思考为中心的数据合成框架，该框架采用认知导向的数据生成方法，通过注入高层次的推理目标（Cognitive Thinking Process Injection）、从多样的语义类型生成原子问题（Seed Single-Hop Question Synthesis），以及基于问题-回答种子生成复杂的多跳问题（Challenging Multi-Hop QA Synthesis）来促进模型的进化。实验结果显示，使用这种方法生成的合成数据在质量上比基线数据提高了16.7%，质量变异度降低了67.91%，强调了高质量且自包含数据对有效、思考导向的模型微调的重要性。MindGYM 在六个推理基准测试中取得了一致的改进，在MathVision上使用仅400份数据样本，获得了高达16%的性能提升，且适用于不同规模和架构的模型。
### Conclusion
MindGYM 强调自设挑战机制在提升大型模型能力方面的可行性和有效性，同时减少了对人力和资源的需求。代码和数据已公开，以促进基于模型内部推理能力驱动的自我进化基础模型的数据为中心的研究。
## 388. `cs.CL` - 数量 vs 质量？基于LLM的数据高效音频-视频基础模型的数据策展 [PDF](https://arxiv.org/pdf/2503.09205), [HTML](https://arxiv.org/abs/2503.09205)
### Authors
Ali Vosoughi,Dimitra Emmanouilidou,Hannes Gamper
### Background
对于通过集成音频和视觉数据来训练多模态基础模型来说，这仍然是一项挑战。为此，AVVA框架不仅考虑了音频-视频场景对齐，超过了单纯的时序同步，还利用了大型语言模型（LLMs）来进行数据策展。AVVA通过实现评分机制来选择对齐的训练数据片段，并采用包含对比学习的Whisper（一种基于语音的基础模型）和DINOv2（用于视频分析的模型）的双编码器结构来处理音频-视频对。在AudioCaps、VALOR和VGGSound上的评估表明，AVVA在对齐片段方面比DenseAV取得了显著的改进，同时仅使用了192小时的策展训练数据。此外，消除实验表明，数据策展有效地以数据质量换取数据数量，从而在AudioCaps、VALOR和VGGSound上获得了更高的top-k检索准确率，这些高于使用全范围未策展数据进行训练的效果。
### Innovation
AVVA框架通过考虑音频-视频场景对齐，不仅局限于时序同步，并利用大型语言模型进行数据策展。通过这种策略，它实现了对齐的数据片段的选择，并整合了Whisper和DINOv2进行音频和视频分析，运用双编码器结构和对比学习。这种方法展示了高效的模型架构和数据策展方法的有效性，AVVA在音频到视频检索的顶级准确率方面取得了显著改进，同时使用了少量的策展训练数据。此外，基于消除实验进一步验证了数据策展的有效性。
### Conclusion
研究结果表明，AVVA框架在多模态基础模型中使用策展的数据（尽管数量有限），比使用未策展的全数据集训练的方法更有效。数据策展可以通过质量优于数量的方式来改进模型在音频-视频检索中的表现。
## 389. `cs.CL` - TabSTAR：具有文本字段的表格基础模型 [PDF](https://arxiv.org/pdf/2505.18125), [HTML](https://arxiv.org/abs/2505.18125)
### Authors
Alan Arazi,Eilam Shapira,Roi Reichart
### Background
尽管深度学习在许多领域已经取得了显著的成功，但在表格学习任务上长期以来表现欠佳，这些任务仍主要由梯度提升决策树主导。虽然已经探索了将语言模型能力融入表格任务，但大多数现有方法使用的是静态的、目标无关的文本表示，这限制了它们的有效性。
### Innovation
我们提出了TabSTAR：一种具有语义目标感知表示的表格基础模型。TabSTAR旨在实现具有文本特征的表格数据上的迁移学习，其架构不含特定数据集的参数。它解冻了一个预训练的文本编码器，并将目标标记作为输入，使模型能够学习任务特定的嵌入。TabSTAR在已知基准数据集中的各类分类任务中达到了最先进的性能，并且其预训练阶段展示了以数据集数量为参数的缩放定律，从而为性能改进提供了途径。
### Conclusion
TabSTAR在中型和大型数据集上均达到了最先进的性能，并且其预训练阶段的缩放定律为进一一步性能改进铺平了道路。
## 390. `cs.CL` - AutoLibra：从开放式人类反馈中生成智能体评价指标 [PDF](https://arxiv.org/pdf/2505.02820), [HTML](https://arxiv.org/abs/2505.02820)
### Authors
Hao Zhu,Phil Cuvin,Xinkai Yu,Charlotte Ka Yee Yan,Jason Zhang,Diyi Yang
### Background
现有的智能体评估主要依赖于粗略的任务成功率指标，这些指标通常需要专家手工设计，并且无法奖励智能体的中间新兴行为。
### Innovation
AutoLibra 提出了一种框架，可以从开放式的人类反馈（例如，“如果发现按钮禁用了，就不要再点击它”或“这个智能体太自主了，独自决定做什么”）中生成具体的行为评价指标。通过将反馈与智能体行为相结合，AutoLibra 聚类相似的行为，并创建明确定义和具体示例的指标，这些指标可以用于评估智能体轨迹中的细粒度行为。此外，AutoLibra 还提出了两个元指标来评估生成的指标与开放反馈的一致性：涵盖性和冗余性。通过对这些元指标的优化，研究表明 AutoLibra 能够启发比以往智能体评估基准更为具体的评价指标，并发现新的评价指标。该框架还被应用于智能体改进中：首先，AutoLibra 帮助人类指令工程师对智能体失误进行对角化，并迭代改进指令；其次，AutoLibra 可以生成用于自动优化智能体的指标，从而促使智能体通过自我调节来改进。
### Conclusion
AutoLibra 是一个通用工具，能够在任务无关的情况下对语言智能体进行评估和改进。
## 391. `cs.CL` - Pass@K 策略优化：解决更难的强化学习问题 [PDF](https://arxiv.org/pdf/2505.15201), [HTML](https://arxiv.org/abs/2505.15201)
### Authors
Christian Walder,Deep Karkhanis
### Background
现有的强化学习（RL）算法对每个问题采样多个n>1的解决方案，并独立地奖励它们，这优化了pass@1性能但牺牲了样本集的多样性以及组合后的实用性。这使得采样能力未被充分利用，限制了探索和最终在更难的问题上的改进。
### Innovation
本文提出了Pass@k 策略优化（PKPO），这是一种对最终奖励的转换，直接优化了pass@k性能，使得可以优化样本集的最大奖励。本文还推导出了在二值和连续奖励设置下新型低方差无偏估计器及其梯度，并证明利用这些估计器的优化可以转换为标准RL。此外，该方法允许在训练过程中调整k的值，同时优化pass@1和pass@k指标，并在某些情况下获得较高的pass@1性能和显著的pass@k改善。
### Conclusion
我们的方法验证了在玩具实验中，有效优化了目标k。更高的k值能够解决更多的和更难的问题，而k的退火增长则同时增强了pass@1和pass@k。对于具有挑战性的任务集，传统的pass@1优化停滞时，我们的pass@k方法可以恢复学习，这可能归因于其通过优先考虑联合而不是个体样本的实用性而进行更好的探索。
## 392. `cs.CL` - MedAgentBoard：以传统方法评估多agent协作在多样化医疗任务中的基准 [PDF](https://arxiv.org/pdf/2505.12371), [HTML](https://arxiv.org/abs/2505.12371)
### Authors
Yinghao Zhu,Ziyi He,Haoran Hu,Xiaochen Zheng,Xichen Zhang,Zixiang Wang,Junyi Gao,Liantao Ma,Lequan Yu
### Background
大型语言模型（LLMs）的迅速发展引发了对多agent协作以应对复杂医疗任务的兴趣。然而，多agent协作方法的实际优势尚未得到充分理解。现有的评价往往缺乏普适性，未能涵盖反映实际临床实践的多样化任务，且通常不进行严格比较，包括单一LLM和传统标准方法。这引发了一种急需填补的空白。
### Innovation
本文介绍了MedAgentBoard，这是一个全面基准，用于系统评估多agent协作、单一LLM和传统方法。MedAgentBoard囊括了四种不同的医疗任务类别：（1）医学（视觉）问答，（2）普通摘要生成，（3）结构化的电子健康记录（EHR）预测建模，以及（4）临床工作流自动化，涵盖了文本、医学影像和结构化EHR数据。
### Conclusion
广泛的实验揭示了一个复杂的现状：虽然多agent协作在特定场景中（如临床工作流自动化）表现出增强的任务完整性，但它并不在所有情况下都优于先进的单一LLM（如文本医学问答）或专门的常规方法，后者通常在医学VQA和基于EHR的预测任务中保持更好的表现。MedAgentBoard提供了一个重要的资源和可行的见解，强调在医疗领域选择和开发AI解决方案时需要任务特定的、基于证据的方法。它强调了多agent协作的内在复杂性和开销必须与实际性能提升仔细权衡。
## 393. `cs.CL` - Paper2Poster：从科学论文到多模态海报的自动化 [PDF](https://arxiv.org/pdf/2505.21497), [HTML](https://arxiv.org/abs/2505.21497)
### Authors
Wei Pang,Kevin Qinghong Lin,Xiangru Jian,Xi He,Philip Torr
### Background
学术海报生成是科学交流中的关键但具有挑战性的任务，需要将长文档的复杂内容压缩到一张视觉统一的页面中。现有的研究方法在处理这一挑战时存在局限性，特别是在确保视觉质量和内容准确性方面。
### Innovation
该研究提出了第一个用于海报生成的标准和度量套件，包括MATCH（基于人类设计的海报的人文准则），文本连贯性标准（确保语言流畅），综合评估标准（由视觉语言模型评判六个细粒度的美学和信息标准），以及一个新的度量PaperQuiz（通过视觉语言模型解答生成的问卷来评估海报传达核心论文内容的能力）。此外，研究还提出了PosterAgent，这是一种自上而下的多智能体视觉闭环流程，包括解析器、计划器和画家-评论者循环，用于从论文生成到最终海报制作的自动化过程。
### Conclusion
研究发现，尽管GPT-4o在视觉上吸引人，但在内容准确性和PaperQuiz分数上表现不佳，主要原因是人类设计的海报依赖于视觉语义来传达意义，这成为视觉瓶颈。开源变体（如基于Qwen-2.5系列）在所有度量标准上都优于现有的多智能体系统，同时使用更少的令牌。这些发现为下一代全自动海报生成模型指明了方向，并强调了读者参与度在视觉呈现中的重要性。所有代码和数据集都可在指定链接处获取。
## 394. `cs.CL` - 在暗中寻找：通过隐空间测试时实例级策略梯度进行推理 [PDF](https://arxiv.org/pdf/2505.13308), [HTML](https://arxiv.org/abs/2505.13308)
### Authors
Hengli Li,Chenxi Li,Tong Wu,Xuekai Zhu,Yuxuan Wang,Zhaoxin Yu,Eric Hanchen Jiang,Song-Chun Zhu,Zixia Jia,Ying Nian Wu,Zilong Zheng
### Background
人类智能的核心组成部分——推理能力，仍然是大规模语言模型（LLMs）在追求AGI过程中的一个重大挑战。虽然在模型规模训练定律下，模型性能有所改善，但仍面临训练算法方面的挑战，例如灾难性遗忘，以及可获取的新训练数据有限等问题。作为一种替代方法，测试时放大通过增加测试时计算而不更新参数来提升推理性能。不同于先前在这种范式中集中在标记空间的方法，我们提出利用潜在空间进行更有效的推理和更好地遵循测试时放大定律。我们提出了名为LatentSeek的新框架，该框架通过模型潜在空间内的测试时实例级适应（TTIA）来增强LLM的推理能力。
### Innovation
LatentSeek引入了一种新型框架，通过潜在空间内的测试时实例级适应（TTIA），利用策略梯度迭代更新潜在表示，并由自动生成奖励信号引导。与之前集中在标记空间的方法不同，LatentSeek的重点在于潜在空间，从而提供更有效的推理解决方案。
### Conclusion
LatentSeek在包括GSM8K、MATH-500和AIME2024等多种推理基准测试中优于强基线方法，如链式思考提示和基于微调的方法。此外，我们的分析表明，LatentSeek在对平均复杂性问题进行测试时具有高效性，通常在几轮迭代内即可收敛，并且从额外迭代中受益，这加强了隐空间内测试时放大的潜力。这些发现将LatentSeek定位为一种轻型、可扩展且有效的解决方案，用于增强LLMs的推理能力。
## 395. `cs.CL` - 基于上下文预测任意行人轨迹 [PDF](https://arxiv.org/pdf/2506.00871), [HTML](https://arxiv.org/abs/2506.00871)
### Authors
Ryo Fujii,Hideo Saito,Ryo Hachiuma
### Background
准确预测行人未来的运动轨迹对于自主系统至关重要，但这是一个具有挑战性的任务，因为需要在不同的环境和领域中具备适应性。一种常见的方法是收集特定场景的数据，并通过反向传播进行微调。然而，为了每个新场景进行微调通常在边缘设备上部署是不实际的。为了应对这一挑战，我们介绍了一种基于上下文学习（ICL）的行人类轨迹预测框架TrajICL，该框架允许在推理时对特定场景的数据进行适应，而不需要进行权重更新，从而避免了对每个新场景的微调需求。
### Innovation
我们提出了一种时空相似性的例子选择方法（STES），该方法从同一场景中之前观察到的轨迹中选择与对应位置有相似运动模式的示例。为了进一步改进此选择，我们引入了基于预测的示例选择方法（PG-ES），该方法不仅基于过去的轨迹，还基于预测的未来轨迹来选择示例，从而使模型能够考虑长期动态。我们还训练模型使用大规模的合成数据集，以通过利用上下文示例来增强其预测能力。这些方法使得TrajICL在多种公开基准测试上超越了微调的方法，实现了在既要适应本领域又要跨越领域的情况下均表现出色的预测效果。
### Conclusion
广泛的实验表明，TrajICL在本领域和跨领域场景中均能实现出色的应用效果，超越了微调的方法。
## 396. `cs.CL` - CompoST: 一个分析大规模语言模型在QALD设置下系统性地解释问题能力的基准 [PDF](https://arxiv.org/pdf/2507.21257), [HTML](https://arxiv.org/abs/2507.21257)
### Authors
David Maria Schmidt,Raoul Schubert,Philipp Cimiano
### Background
语言解释是一个组合过程，复杂语言结构的意义是从其组成部分的意义推断出来的。大规模语言模型具备显著的语言解释能力，并已成功应用于将问题映射为SPARQL查询。然而，对于这一解释过程是否系统性的问题仍存在疑问。
### Innovation
本文提出了一个基准（CompoST），用于研究大规模语言模型（LLMs）解释问题的能力是否真正是组合性的。该基准基于DBpedia中的图模式生成了三个不同难度的数据集，并利用Lemon词汇进行语义化。这种方法创造出一个高度受控环境，以检验LLMs在 given 基于见过的原子构建模块的结构性复杂问题时的解释能力。研究使用不同规模的模型进行实验，并采用各种提示和少样本优化技术以及微调方法。结果揭示了LLMs在映射复杂问题到SPARQL查询方面存在困难，即使给定所有必要信息，低复杂度数据集上的F1分数也不超过0.57。
### Conclusion
我们的结果表明LLMs在系统和组合地解释问题和将其映射为SPARQL查询方面存在困难。
## 397. `cs.CL` - 在揭示Unicode未见之底层在削弱作者归属方面的用途 [PDF](https://arxiv.org/pdf/2508.15840), [HTML](https://arxiv.org/abs/2508.15840)
### Authors
Robert Dilworth
### Background
当用户通过正式或非正式的公共通信渠道（如社交媒体上的评论或帖子）发送消息时，他们没有隐私期望：消息被公开发布给全世界。尽管用户采取了各种措施来匿名化在线存在（如使用别名或假名、隐藏IP地址、伪造地理位置、隐藏操作系统和用户代理、部署加密、使用一次性电话号码或电子邮件注册、停用非必要设置、撤销权限并阻止cookie和指纹识别），仍然无法完全保证消息内容不透露其真实身份。但是，消息内容的公开性却暴露了一个弱点：通过风格分析或作者画像进行攻击。
### Innovation
论文通过探讨风格分析技术，讨论了对抗风格分析的反策略，并提出了通过Unicode隐写术增强文本的方法。这种方法旨在即使消息内容公开，也能以一定的隐蔽性来保护作者身份不被轻易确定。
### Conclusion
通过详细分析风格分析技术，论文提出了一个反向策略，即对抗风格分析的方法，并利用Unicode隐写术来增强文本的保护效果，以期在公共通信渠道中有效保护作者身份不被识别。
## 398. `cs.CL` - GradEscape:基于梯度的针对AI生成文本检测器的攻击者 [PDF](https://arxiv.org/pdf/2506.08188), [HTML](https://arxiv.org/abs/2506.08188)
### Authors
Wenlong Meng,Shuguo Fan,Chengkun Wei,Min Chen,Yuwei Li,Yuanchao Zhang,Zhikun Zhang,Wenzhi Chen
### Background
当前已有针对AI生成文本（AIGT）检测器的攻击方法，但这些方法大多无法有效处理由于文本是离散性质导致的不可微计算问题。现有的方法难以在最小化文本修改的情况下实现高攻击成功率，且这些方法在面对不同语言模型架构的检测器时也表现不佳，尤其是在仅提供查询访问的情况下效果不理想。作者提出的方法旨在突破这些限制，提高攻击的有效性和适应性。
### Innovation
作者创新性地提出了一种名为GradEscape的方法。GradEscape结合了新型加权嵌入构造方法，解决了离散文本引起的不可微计算问题。它利用来自受害检测器的反馈更新攻击模型参数，且适应任何语言模型架构，即使在不同语言模型之间也表现良好。此外还引入了基于语言模型的提取技术和初始化方法，以增强其在只有查询访问的情况下的效果。实验结果表明，GradEscape在各种场景下，包括与11B参数的同义词生成模型一起使用时，均优于现有的其他AIGT攻击方法，使用参数量较少，显示出了更高的性能。
### Conclusion
实验结果显示，GradEscape在各种场景下相较于现有方法具有更高的效率和适应性，表明该方法不仅对于现有的AIGT检测器构成了挑战，还揭露了这些检测器的主要脆弱性，对于促进开发更鲁棒的AIGT检测器具有重要意义。作者也提出了一种潜在的防御策略以对抗AIGT的攻击，并将GradEscape开源以供进一步研究使用。
## 399. `cs.CL` - 模糊、符号化和情境化：通过认知支架增强大规模语言模型的指令 [PDF](https://arxiv.org/pdf/2508.21204), [HTML](https://arxiv.org/abs/2508.21204)
### Authors
Vanessa Figueiredo
### Background
研究表明，提示级别的诱导偏见如何影响大型语言模型（LLM）在互动对话中的认知行为。本文通过引入符号化的支架方法以及短期记忆框架，尝试促进Socratic教学中的适应性、结构化推理。
### Innovation
本文提出了一种结合符号支架构筑法和短期记忆模式的方案，用于评估模型输出。通过五种系统变体的控制消除实验，使用专家设计的评价准则（涵盖支架构造、响应性、符号推理和对话记忆）进行评估。初步结果显示，该系统完全版本始终优于基线版本。进一步分析表明，移除记忆或符号结构会损害关键的认知行为，包括抽象、适应性探查和概念连续性。这为LLM中的认知处理提供了一种可以显著影响新兴教学策略的方法。
### Conclusion
结果显示，LLM中的认知支架构造可以稳定地塑造其教学策略，提示级别认知支架构造对基础模型有持续的积极影响。在早期实验中，这种基于模型的认知支架构造评价框架提供了可扩展、系统性的模型架构变体比较。
## 400. `cs.CL` - 通过社交媒体的纵向和信息环境信号检测早期和隐性自杀意图 [PDF](https://arxiv.org/pdf/2510.14889), [HTML](https://arxiv.org/abs/2510.14889)
### Authors
Soorya Ram Shimgekar,Ruining Zhao,Agam Goyal,Violeta J. Rodriguez,Paul A. Bloom,Hari Sundaram,Koustuv Saha
### Background
在社交媒体上，经历自杀念头的用户往往不会明示他们的痛苦，而是通过日常上传的内容或社交互动中的间接线索来表达。早期检测这些隐性信号非常重要，但依然是一个挑战。
### Innovation
本文提出了一个计算框架，通过建模用户的纵向发帖历史及其社交邻域的讨论，来检测隐性自杀意图。利用合并多元信号的微调DeBERTa-v3模型，更有效地识别早期且隐性的自杀倾向。在Reddit研究中，该方法比单一用户基线提高了15%的检测率，突显了社交互动的价值和对未来在在线环境中设计能捕捉到间接或掩盖风险预警系统的启示意义。
### Conclusion
社交互动提供了有价值的预测信号，这对设计能够捕捉在线环境中间接和隐藏风险表达的早期检测系统具有广泛的意义。
## 401. `cs.CL` - FESTA: Functionally Equivalent Sampling for Trust Assessment of Multimodal LLMs [PDF](https://arxiv.org/pdf/2509.16648), [HTML](https://arxiv.org/abs/2509.16648)
### Authors
Debarpan Bhattacharya,Apoorva Kulkarni,Sriram Ganapathy
### Background
评估多模态大语言模型（MLLMs）生成预测的准确信任度具有挑战性，因为它们处理多种多模态输入方式。预测的准确信任评估有助于选择性地生成预测，从而提高用户的信心。
### Innovation
提出了功能等价抽样用于信任评估（FESTA）的方法，这是一种多模态输入抽样技术，依据等效和互补的输入抽样生成不确定性度量。该方法通过等效样本测试一致性，通过互补样本测试敏感性，同时仅依赖于模型的输入-输出访问（黑盒方式），无需标注数据（无监督）。实验使用多种现成的多模态LLMs，涵盖了视觉和音频推理任务。FESTA的不确定性估计在检测错误预测方面显著提升了选择性预测性能，对于视觉LLMs相对提升33.3%，对于音频LLMs相对提升29.6%，按照受试者操作特性曲线下面积（AUROC）指标衡量。
### Conclusion
所提出的FESTA方法在检测错误预测时显著提高了多模态LLMs的选择性预测性能，且该方法为无监督和黑盒方法，具有广泛的应用价值。
## 402. `cs.CL` - 视觉推理中的潜在逻辑链 [PDF](https://arxiv.org/pdf/2510.23925), [HTML](https://arxiv.org/abs/2510.23925)
### Authors
Guohao Sun,Hang Hua,Jian Wang,Jiebo Luo,Sohail Dianat,Majid Rabbani,Raghuveer Rao,Zhiqiang Tao
### Background
链式推理（CoT）对于提高大型视觉-语言模型（LVLM）的可解释性和可靠性至关重要。然而，现有的训练算法如SFT、PPO和GRPO在处理未见过的推理任务时表现不佳，且过度依赖有偏见的奖励模型。
### Innovation
本文将LVLM中的推理重新定义为后验推断，并提出了一种基于近似变分推断的可扩展训练算法。通过利用多样性寻求的强化学习算法，引入了一种新颖的稀疏奖励函数，该奖励函数鼓励多样性和高似然性的潜在CoT，克服了确定性采样的局限性，避免了奖励作弊。此外，实施了一种贝叶斯推理扩展策略，用边缘似然替换昂贵的Best-of-N和束搜索，以高效地评估最优解释和答案。
### Conclusion
实验结果表明，所提出的方法增强了七项推理基准测试中科T的LVLM的有效性、泛化能力和可解释性。
## 403. `cs.CL` - 相似度-距离-规模激活 [PDF](https://arxiv.org/pdf/2509.12760), [HTML](https://arxiv.org/abs/2509.12760)
### Authors
Allen Schmaltz
### Background
介绍了Similarity-Distance-Magnitude (SDM)激活函数，这是一种比标准softmax激活函数更稳健和可解释的公式，添加了对正确预测深度匹配和训练分布距离的意识，以增强现有输出的决策边界意识。通过密集匹配实现基于例证的可解释性。该论文进一步引入了基于SDM激活的类间经验CDF数据驱动分割的SDM估计器，用以控制选择性分类的类条件和预测条件的准确性。这项工作使用预训练的语言模型作为最终层激活，并应用于选择性分类，提高了对混杂变量偏移和越界输入的鲁棒性，同时在分布内数据上保持信息性。
### Innovation
提出了Similarity-Distance-Magnitude (SDM)激活函数，引入了对正确预测深度匹配和训练分布距离的意识，增强了输出的决策边界意识，使模型更具可解释性。进一步提出了基于SDM激活的类间经验CDF数据驱动分割的SDM估计器，用以控制选择性分类的类条件和预测条件的准确性，提升了模型在选择性分类中的鲁棒性，特别是在处理混杂变量偏移和越界输入时，并保持了在分布内数据上的信息性。
### Conclusion
提出的SDM激活函数和SDM估计器，在选择性分类中比现有的使用softmax激活函数的校准方法更具鲁棒性，同时在分布内数据上依然具有信息性。
## 404. `cs.CL` - 代码生成和修复中LLM集合的智慧与谬误 [PDF](https://arxiv.org/pdf/2510.21513), [HTML](https://arxiv.org/abs/2510.21513)
### Authors
Fernando Vallecillos-Ruiz,Max Hort,Leon Moonen
### Background
当前追求单一大型语言模型（LMM）适用于所有软件工程任务这一目标资源密集且忽视了不同模型互补性的潜在益处。目前还不清楚编码LMM之间的互补程度和最优化组合策略，使从业人员缺乏超越单一模型系统的清晰路径。本文通过实证比较十种来源于五大家族的LMM及这些LMM的三种组合策略，在三个软件工程基准测试中涵盖代码生成和程序修复，评估模型之间的互补性及其优势，发现理论上集合体性能最高可比最优单个模型提升83%，此外，基于共识的选择策略会放大常见但错误的输出，相反，基于多样性的策略可实现潜在性能的95%，甚至在两个模型的组合中也有效，表明多样性的策略可以通过利用多个LMM以低成本的方式提高性能。 
### Innovation
本文通过实证方法评估了十个不同家族的LMM及组合体的整体表现，发现集合体性能可以显著提高83%以上。并且提出了一个基于多样性的策略，该策略能够在低成本下实现最大的性能提升，并得到了实验结果的支持。此研究填补了当前领域中关于LMM集合研究的空白，为实际应用中选择更优的模型组合策略提供了理论依据。
### Conclusion
基于多模型集合的研究仍处于早期阶段，未来需要进一步提升组合策略的多样性和效果，同时也需要在实际应用中进行不断验证和完善。
## 405. `cs.CV` - BikeScenes: 实时LiDAR语义分割自行车 [PDF](https://arxiv.org/pdf/2510.25901), [HTML](https://arxiv.org/abs/2510.25901)
### Authors
Denniz Goren,Holger Caesar
### Background
随着电动自行车（e-bikes）越来越受欢迎，骑车人的脆弱性显著增加，这促使汽车感知技术适应自行车安全的需求。本研究旨在通过开发一种针对自行车的3D LiDAR分割方法来应对这一挑战。
### Innovation
文章引入了新的BikeScenes-lidarseg数据集，包含3021个连续的LiDAR扫描，覆盖了代尔夫特理工大学校园，并且这些扫描已经语义标注了29种动态和静态类别。实验表明，通过在BikeScenes数据集上微调模型，可以获得显著高于仅使用SemanticKITTI预训练模型的效果，证明了领域特定训练的必要性和有效性。
### Conclusion
研究强调了自行车搭载的硬件限制感知系统中的关键技术挑战，并贡献了BikeScenes数据集，旨在促进骑车人为中心的LiDAR语义分割的研究发展。
## 406. `cs.CV` - MIRO：多奖励条件预训练提高T2I质量和效率 [PDF](https://arxiv.org/pdf/2510.25897), [HTML](https://arxiv.org/abs/2510.25897)
### Authors
Nicolas Dufour,Lucas Degeorge,Arijit Ghosh,Vicky Kalogeiton,David Picard
### Background
当前的文本到图像生成模型在大规模未标注的数据集上进行训练，以实现多样化的生成能力。然而，这种方法与用户的偏好不完全一致。近年来，为了根据用户的偏好优化生成图像，专门设计了奖励模型，但这种做法在评估生成图像时会丢弃有价值的数据，并且通过单个奖励优化往往会损害多样性和语义保真度。
### Innovation
本文提出了MIRO方法，在预训练阶段通过条件化模型以多种奖励模型的学习，使模型可以直接学习用户的偏好。这种方法不仅大幅提升了生成图像的视觉质量，而且显著加快了训练速度。
### Conclusion
通过MIRO方法，该研究在GenEval组合基准测试和用户偏好评分（PickAScore，ImageReward，HPSv2）方面达到了最先进的性能。
## 407. `cs.CL` - VC4VG: 优化用于文本到视频生成的视频字幕 [PDF](https://arxiv.org/pdf/2510.24134), [HTML](https://arxiv.org/abs/2510.24134)
### Authors
Yang Du,Zhuoran Lin,Kaiqiang Song,Biao Wang,Zhicheng Zheng,Tiezheng Ge,Bo Zheng,Qin Jin
### Background
近年来，文本到视频（T2V）生成的发展突显了高质量视频-文本对在训练能够生成连贯且指令对齐的视频模型中的重要作用。然而，针对T2V训练优化视频字幕的具体策略仍然鲜有探索。因此，作者提出了VC4VG（Video Captioning for Video Generation）框架，这是一个针对T2V模型需求定制的综合字幕优化框架。
### Innovation
作者通过从T2V的角度分析字幕内容，将其所需的基本元素拆解到多个维度，并提出了一种合乎原理的字幕设计方法来优化视频字幕。此外，作者还构建了VC4VG-Bench，一个新的基准测试，提供细粒度、多维度和必要性分级的评估指标，以满足T2V特定的要求。大量的T2V微调实验表明，字幕质量的改进与视频生成性能之间存在显著的相关性，验证了该方法的有效性，并提供了所有的基准测试工具和代码。
### Conclusion
研究表明，优化后的视频字幕显著提升了T2V生成的质量，验证了VC4VG方法的有效性。为了支持进一步的研究，作者将所有基准测试工具和代码公开。
## 408. `cs.CV` - 在扫描模式中增加Hausdorff维度促进基于Mamba的方法在低光图像增强中的应用 [PDF](https://arxiv.org/pdf/2510.26001), [HTML](https://arxiv.org/abs/2510.26001)
### Authors
Xinhua Wang,Caibo Feng,Xiangjun Fu,Chunxiao Liu
### Background
本文通过对Mamba框架进行创新性的增强，提高了其扫描模式的Hausdorff维度，通过一种新颖的Hilbert Selective Scan机制来更好地探索特征空间，捕捉细微的细节并提升整体覆盖能力。
### Innovation
提出了一种新型的Hilbert Selective Scan机制，该机制能更有效地探索特征空间，捕捉细微的细节并提高覆盖能力，从而改善了信息不一致现象，同时提高了空间局部性，更好地捕捉细微的局部交互，而不牺牲应对长距离依赖的能力。实验结果显示本文的方法在现有Mamba为基础的低光图像增强方法上，显著提升了定量指标和视觉保真度，同时减少了计算资源消耗和推理时间。
### Conclusion
本文认为，这种改进策略不仅推动了低光图像增强技术的发展，也为基于Mamba技术的应用提供了更广泛的前景。
## 409. `cs.CV` - 使用Segment Anything进行实时MRI引导放疗中肿瘤跟踪的微调 [PDF](https://arxiv.org/pdf/2510.25990), [HTML](https://arxiv.org/abs/2510.25990)
### Authors
Valentin Boussot,Cédric Hémon,Jean-Claude Nunes,Jean-Louis Dillenseger
### Background
本文应对的是TrackRAD2025挑战，该挑战要求在强数据稀缺性的约束下，实时追踪胸部和腹部区域的MRI动态序列中的肿瘤。目前研究主要集中在两个策略上：无监督配准和基于SAM 2.1及其最近变体的基础模型分割，通过提示交互实现。
### Innovation
研究引入了使用Segment Anything (SAM) 进行实时肿瘤分割的方法，特别是SAM 2.1及其变体。由于需要在一秒钟内完成运行，最终选择的是SAM-based的方法。模型经过微调，使用特定的patch大小和批量大小进行训练，并应用了一种平衡的Dice + IoU损失函数。整个模型进行了统一的学习率调整，以保持泛化能力。
### Conclusion
经过微调的模型在隐藏测试集中达到了0.8794的Dice系数，在TrackRAD2025挑战中排名第六。这表明基础模型对于MRI引导放射治疗中的实时和精确肿瘤跟踪具有强大的潜力。
## 410. `cs.CV` - 通过时空分析和空间注意力网络提高水下物体检测 [PDF](https://arxiv.org/pdf/2510.25797), [HTML](https://arxiv.org/abs/2510.25797)
### Authors
Sai Likhith Karri,Ansh Saxena
### Background
该研究探讨了时空建模和在水下对象检测中的深度学习模型中空间注意力机制整合的有效性。研究背景主要是为了评估和改进现有的YOLOv5及其变体在水下动态环境中的检测性能。特别地，研究对比了标准YOLOv5和增强版本T-YOLOv5的性能，进一步研究了将CBAM模块加入T-YOLOv5后的效果，特别是在复杂条件下（如突然运动、部分遮挡和渐进运动）的检测准确性.
### Innovation
研究的创新之处在于：1. 评估了标准YOLOv5和时空增强版T-YOLOv5的性能；2. 引入了CBAM模块，该模块显著提升了T-YOLOv5在复杂场景下的检测准确性；3. 展示了时空建模在动态水下环境中提高检测准确性的能力，特别是在复杂但不断变化的条件下.
### Conclusion
研究结果表明，T-YOLOv5相较于标准YOLOv5在复杂场景中显著提高了检测的可靠性。进一步引入CBAM模块后的T-YOLOv5在挑战性场景中表现出更好的性能。然而，在较简单场景中，精度略有下降。这种设计使得模型在复杂和动态水下环境中的应用更加可靠和有效.
## 411. `cs.CV` - SplitFlow：无映射文字到图像编辑的流分解 [PDF](https://arxiv.org/pdf/2510.25970), [HTML](https://arxiv.org/abs/2510.25970)
### Authors
Sung-Hoon Yoon,Minghan Li,Gaspard Beaudouin,Congcong Wen,Muhammad Rafay Azhar,Mengyu Wang
### Background
修正流模型由于其稳定的样本轨迹和高保真的输出，在图像生成中已成为一种默认标准。尽管这些模型具有强大的生成能力，但在图像编辑任务中仍面临重要限制：不准确的反转过程导致难以将真实图像映射回潜在空间，以及编辑过程中梯度纠缠问题往往导致生成的输出无法忠实反映目标提示。近年来，通过基于ODE的方法直接映射源和目标分布，尝试绕过反转过程，但这些方法仍未能达到最佳的编辑质量。
### Innovation
提出了基于无反转公式构建的流分解并聚合框架，解决了上述限制。具体而言，将目标提示语义分解为多个子提示；为每个子提示计算独立的流并加以聚合，形成统一的编辑轨迹。尽管实验观察到分解原始流能够提高目标空间的多样性，但生成语义对齐的输出仍需向着完整的目标提示进行一致的引导。为此，设计了一种投影和软聚合机制，通过多任务学习中的梯度冲突解决灵感，适应性加权子目标的速度场，抑制语义冗余并强调不同的方向，从而在最终编辑结果中保持多样性和一致性。实验结果表明，该方法在语义保真度和特征去纠缠方面优于现有的零样本编辑方法。
### Conclusion
实验结果证明，我们的方法在语义保真度和特征去纠缠方面优于现有的零样本编辑方法。代码可在以下链接下载：[链接]。
## 412. `cs.CV` - 使用基于物理的合成数据进行生成图像修复和超分辨率的扫描隧道显微镜 [PDF](https://arxiv.org/pdf/2510.25921), [HTML](https://arxiv.org/abs/2510.25921)
### Authors
Nikola L. Kolev(1,2),Tommaso Rodani(3,4),Neil J. Curson(1,2),Taylor J.Z. Stock(1,2),Alberto Cazzaniga(4) ((1) London Centre for Nanotechnology, University College London, London, United Kingdom, (2) Department of Electronic and Electrical Engineering, University College London, London, United Kingdom, (3) University of Trieste, Trieste, Italy, (4) AREA Science Park, Trieste, Italy)
### Background
扫描隧道显微镜（STM）可以实现原子级分辨率的成像和原子操纵，然而其应用受限于针尖退化和缓慢的数据采集。制作过程增加了复杂性，因为针尖常被施加高电压，可能导致顶端形状改变，需要对针尖进行预处理。本研究旨在提出一种机器学习（ML）方法进行图像修复和超分辨率，以解决上述问题。通过仅使用36张干净的实验Si(001):H图像，我们展示了基于物理的合成数据生成管道可以有效用于训练最先进的流匹配和扩散模型。借助CLIP最大均值差异（CMMD）评分和结构相似性等量化评估标准，结果表明，我们的模型不仅能有效恢复图像，还能将图像采集时间减短2至4倍，通过密集采样数据准确重建图像。该框架有望大大提高STM实验的吞吐量，减少针尖预处理频率并提升现有高速STM系统的帧率。
### Innovation
通过利用仅36张干净实验Si(001):H图像的基于物理的合成数据生成管道，训练了最先进的流动匹配和扩散模型，从而提出了一个图像修复和超分辨率的机器学习方法。该方法不仅能够有效恢复图像，还能减少图像采集时间，并通过密集采样数据准确重建图像。这种方法具有显著提高STM实验吞吐量的潜力，减少针尖预处理频率并提升高速STM系统的帧率。
### Conclusion
本研究通过机器学习方法提出了一个图像修复和超分辨率的框架，利用合成数据生成管道，实现了图像恢复和快速重建。该方法能够大幅降低STM实验的频次和提升帧率，显著提高STM实验的吞吐量。
## 413. `cs.CV` - Brain-IT: 通过脑交互变换器从fMRI重建图像 [PDF](https://arxiv.org/pdf/2510.25976), [HTML](https://arxiv.org/abs/2510.25976)
### Authors
Roman Beliy,Amit Zalcher,Jonathan Kogman,Navve Wasserman,Michal Irani
### Background
通过功能性磁共振成像（fMRI）重建人们看到的图像，提供了一个非侵入性的观察人类大脑的窗口。尽管近期扩散模型的研究取得了进步，但当前的方法往往未能忠实再现实际看到的图像内容。本文基于这一挑战，提出了‘Brain-IT’，一种脑启发的方法，通过脑交互变压器（BIT），使得功能相似的大脑体素簇之间可以有效互动。这些功能簇为所有被试共享，成为跨脑整合信息的基本构建块。所有模型组件在所有簇和被试间共享，允许在少量数据下高效训练。
### Innovation
Brain-IT 通过脑交互变压器（BIT）预测两种互补的局部图像特征，分别为高层语义特征和低层结构特征。高层语义特征引导扩散模型向正确的图像语义内容发展，而低层结构特征则有助于初始化扩散过程，使用正确的图像粗略布局。BIT 的设计使得信息能够在脑体素簇和局部图像特征之间直接流动。通过这些原则，我们的方法能够忠实地从 fMRI 重建人们的看到的图像，且在视觉表现和标准客观指标方面都超越了当前的最佳方法。此外，仅使用一个被试的一小时 fMRI 数据，我们的方法在性能上与常规方法在完整的 40 小时 fMRI 训练数据集上训练的结果相当。
### Conclusion
我们的方法通过功能相似的大脑体素簇的直接信息流动以及对高层语义和低层结构特征的有效预测，成功地从 fMRI 数据中重建了实际看到的图像。这种方法不仅在视觉效果上有所提升，还通过客观标准验证了其在重建准确性上的进步。这些创新使得大脑图像重建技术朝着非侵入性和高效性的方向迈出了坚实的一步。
## 414. `cs.CV` - CAVE：视觉环境中检测和解释常识异常 [PDF](https://arxiv.org/pdf/2510.26006), [HTML](https://arxiv.org/abs/2510.26006)
### Authors
Rishika Bhagwatkar,Syrielle Montariol,Angelika Romanou,Beatriz Borges,Irina Rish,Antoine Bosselut
### Background
人类能够自然地识别、推理和解释环境中的异常。但在计算机视觉领域，这一长期挑战仍局限于工业缺陷或不现实、合成生成的异常，未能捕捉到真实世界异常的丰富性和不可预测性。因此，本文介绍了CAVE，这是首个关于真实世界视觉异常的基准。CAFVE提供三项开放任务：异常描述、解释和论证；具备细粒度定位和分类注释，包括基于视觉表现、复杂性、严重性和常见度的异常分类。这些注释借鉴了认知科学中人类如何识别和处理异常的研究成果，提供了评估视觉语言模型（VLMs）在检测和理解异常方面的综合框架。
### Innovation
CAVE 是首个关于真实世界视觉异常的基准。它提供三项开放任务：异常描述、解释和论证；具备细粒度定位和分类注释，包括基于视觉表现、复杂性、严重性和常见度的异常分类。这为评估视觉语言模型（VLMs）在检测和理解异常方面的表现提供了综合框架。研究发现，最先进的 VLMs 在视觉异常感知和常识推理方面存在挑战，即使使用高级提示策略也是如此。
### Conclusion
通过提供一个现实且认知基础基准，CAVE 为异常检测和常识推理研究中的视觉语言模型提供了宝贵资源。研究结果表明，当前最先进的 VLMs 在处理视觉异常方面存在困难，即使在高阶提示策略下也是如此。
## 415. `cs.CV` - 使用深度学习进行气候适应性洪水预测的城市海岸带 [PDF](https://arxiv.org/pdf/2510.26017), [HTML](https://arxiv.org/abs/2510.26017)
### Authors
Bilal Hassan,Areg Karapetyan,Aaron Chung Hin Chow,Samer Madanat
### Background
气候变化和海平面上升（SLR）对沿海城市构成了日益严重的威胁，加剧了对预测潜在洪水风险的高效和准确方法的需求。传统的基于物理的水动力模拟器虽然精确，但计算成本高昂，不适合城市规模的沿海规划应用。深度学习（DL）技术提供了有希望的替代方案，然而，它们往往受到数据稀缺和高维输出需求的限制。
### Innovation
本文利用了一种最近提出的基于视觉的、资源消耗低的深度学习框架，开发了一个新型的轻量级卷积神经网络（CNN）模型，用于预测不同SLR情景和岸线适应情景下的沿海洪水。该模型通过利用来自阿布扎比和旧金山两个不同地区的数据集，展示了在多种地理背景下泛化的潜力。研究结果表明，所提出的模型在预测洪水深度图时的表现显著优于现有最先进的方法，平均减少了近20%的平均绝对误差（MAE）。
### Conclusion
这些结果突显了本文所提出方法在沿海洪水管理中作为可扩展和实用工具的潜力，帮助决策者制定应对气候变化影响的有效缓解策略。
## 416. `cs.CV` - 通过视觉编码器中的堆叠时间注意力增强视频LLMs的时间理解 [PDF](https://arxiv.org/pdf/2510.26027), [HTML](https://arxiv.org/abs/2510.26027)
### Authors
Ali Rasekh,Erfan Bagheri Soula,Omid Daliran,Simon Gottschalk,Mohsen Fayyaz
### Background
尽管多模态大语言模型（MLLMs）取得了重要进展，但在理解视频中的复杂时序动态方面仍面临重大挑战。当前的视频大语言模型（Video-LLM）架构在理解时间方面存在重大局限性，难以完成需要详细理解动作序列和时间进程的任务。现有实验表明，视频理解中的时间理解仍然是视频LLM的一个关键弱点。因此，本文旨在通过在视觉编码器中引入堆叠的时间注意力模块来提升时间理解能力，以改善动作识别等视频问答任务的表现。
### Innovation
本文提出了一种在视觉编码器中引入堆叠时间注意力模块的视频LLM架构设计，使得模型能够更好地捕捉动作的进展及帧之间的关系，从而提高时间推理能力，实现在视频问答任务中的性能提升。该方法在VITATECS、MVBench和Video-MME等基准测试中均表现出色，提高了5.5%的性能。
### Conclusion
通过在视觉编码器中增加时间结构，该研究填补了视频理解中视频LLM的关键空白，显著提升了视频LLM的时间理解能力。项目页面和代码已在此网址获取：this https URL.
## 417. `cs.CV` - 多模态模型中文本与图像之间对齐的安全风险 [PDF](https://arxiv.org/pdf/2510.26105), [HTML](https://arxiv.org/abs/2510.26105)
### Authors
Xiaosen Wang,Zhijin Ge,Shaokang Wang
### Background
尽管多模态扩散模型，如文本转图像模型，在发展中取得了显著的进步并且具有多方面的应用，但这些模型对对抗性输入的脆弱性仍然没有被充分研究。不同于预期，研究发现现有扩散模型中文本模态与图像模态之间的对齐是不足的，这种对齐不一致为生成不当或不适合工作（NSFW）内容带来了显著的风险。
### Innovation
本文提出了一种新颖的攻击方法，称为提示受限多模态攻击（PReMA），通过修改输入图像（同时指定提示不变）来操控生成的内容，而无需改变提示本身。PReMA 是第一个通过仅生成对抗性图像来操作模型输出的攻击方法，不同于先前主要生成对抗性提示以产生 NSFW 内容的方法。
### Conclusion
综合评估显示，PReMA 在多种模型上的图像修复和风格传递任务中表现出强大的效果，对多模态扩散模型提出了新型威胁，尤其是在使用固定提示的操作中。
## 418. `cs.CV` - 基于Vision-Language模型的扩散模型动态负引导方法 [PDF](https://arxiv.org/pdf/2510.26052), [HTML](https://arxiv.org/abs/2510.26052)
### Authors
Hoyeon Chang,Seungjin Kim,Yoonseok Choi
### Background
传统的负引导方法使用固定的负提示来限制生成结果的特定属性，但这种方法缺乏灵活性和适应性，不能很好地应对不同的生成过程和环境要求。研究表明，通过利用Vision-Language模型（VLM），在去噪过程中的特定步骤生成图像预测，并据此生成场景相关的负提示，可以显著提升生成模型生成与文本描述相匹配的图像的质量和准确性。本文在多个基准数据集上评估了这种方法的有效性，展示了负引导强度与文本-图像对齐之间的权衡关系。
### Innovation
提出了一种新的动态负引导方法，利用Vision-Language模型在去噪过程中自适应地生成负提示。这与传统方法的不同之处在于，我们不是使用固定的负提示，而是通过生成中间图像预测并查询VLM来产生上下文相关性更强的负提示。这一方法增强了模型的灵活性和适应性，提供了更好的生成结果控制能力，提高了模型生成结果的多样化和精确度。
### Conclusion
本文在多个基准数据集上验证了这种方法的有效性，并展示了负引导强度和文本-图像对齐之间的权衡关系。通过这种方法，模型生成结果的多样性和准确性得到了显著提升，有望在生成模型领域得到广泛应用。这一方法为生成模型的改进提供了新的思路和借鉴。
## 419. `cs.CV` - JOGS: 联合优化姿态估计和3D高斯点绘制 [PDF](https://arxiv.org/pdf/2510.26117), [HTML](https://arxiv.org/abs/2510.26117)
### Authors
Yuxuan Li,Tao Wang,Xianben Yang
### Background
传统三维视图合成方法通常依赖于COLMAP等外部相机姿态估计工具，这往往会导致计算瓶颈并传递错误。
### Innovation
本文提出了一种统一框架，该框架在不依赖预先校准输入的情况下联合优化3D高斯点和相机姿态。关键创新在于将联合优化过程分为两个交错阶段：首先通过固定姿态的可微渲染更新3D高斯参数，然后使用结合几何和光度约束的定制3D光学流算法细化相机姿态。这种形式可以逐步减少投影误差，特别是在具有大量视点变化和稀疏特征分布的挑战场景中，传统方法难以应对。
### Conclusion
在多个数据集上的广泛评估表明，本文的方法在重建质量上显著优于现有的无COLMAP技术，并且在一般情况下也超过了标准的基于COLMAP的基本基准。
## 420. `cs.CV` - OracleAgent: 用于甲骨文研究的多模态推理代理 [PDF](https://arxiv.org/pdf/2510.26114), [HTML](https://arxiv.org/abs/2510.26114)
### Authors
Caoshuo Li,Zengmao Ding,Xiaobin Hu,Bang Li,Donghao Luo,Xu Peng,Taisong Jin,Yongge Liu,Shengwei Han,Jing Yang,Xiaoping He,Feng Gao,AndyPian Wu,SevenShu,Chaoyang Wang,Chengjie Wang
### Background
甲骨文（OBS）是最早期的书写系统之一，它保存了古代文明的文化和思想遗产。然而，当前对OBS的研究面临两大挑战：一是OBS解读涉及一个复杂的多次序和并行的任务流程；二是OBS信息组织和检索的效率成为关键瓶颈，因为学者们往往在搜集、编纂和管理相关资源上花费大量精力。
### Innovation
本文介绍了OracleAgent，这是专门为管理与检索OBS相关信息而设计的第一代智能代理系统。OracleAgent无缝集成了多种OBS分析工具，并受大型语言模型的支持，可以灵活协调这些组件。另外，还构建了一个全面的领域特定多模态知识库，通过多年的数据收集、清洁和专家注解建立。这个知识库包含超过140万单字拓片图像和8万条解读文本。
### Conclusion
广泛的实验表明，OracleAgent在多种多模态推理和生成任务上表现出色，超过了主流的多模态大型语言模型（如GPT-4o）。我们的案例研究还展示了OracleAgent能有效辅助领域专家，显著降低OBS研究的时间成本。这些结果强调了OracleAgent朝着实用化的OBS辅助研究和自动化解读系统的重大一步。
## 421. `cs.CV` - EgoExo-Con: 探索视角不变的视频时间理解 [PDF](https://arxiv.org/pdf/2510.26113), [HTML](https://arxiv.org/abs/2510.26113)
### Authors
Minjoon Jung,Junbin Xiao,Junghyun Kim,Byoung-Tak Zhang,Angela Yao
### Background
本研究探讨了视频语言模型（Video-LLMs）在同一事件从不同视角拍摄的视频中是否能保持一致的时间理解。为此，引入了EgoExo-Con（一致性）基准，该基准包含综合同步的自视角和他视角视频对，并具有自然语言的人工精炼查询。EgoExo-Con特别强调两个时间理解任务：时间验证和时间对接。它不仅评估正确性，还评估不同视角之间的一致性。已有研究表明，现有的一些Video-LLMs存在两个关键局限：1）模型在保持一致性方面经常出现问题，其结果远低于单一视角的表现。2）通过同步两种视角的视频进行粗调时，尽管可以改善一致性，这些模型的表现通常不如只在单一视角上训练的模型。
### Innovation
研究提出了View-GRPO，这是一个新颖的强化学习框架，旨在加强视角特定的时间推理，同时也鼓励跨视角的一致理解。这种方法在提高跨视角一致性方面优于简单的粗调和GRPO方法，特别是在改善跨视角一致性方面表现出优越性。此外，所有资源将会公开提供。这项研究的创新在于它填补了视频语言模型在视角不变的时间理解方面的空白，并提出了一个新的解决方案来改善这种一致性。
### Conclusion
研究结果表明，尽管已有的一些Video-LLMs在跨视角一致性方面存在明显问题，但是通过提出View-GRPO方法，可以有效地改进这一问题。这种方法无论是对于时间验证还是时间对接，都能够提供更一致的跨视角理解。未来的工作将进一步改进和验证该方法的实际应用效果。
## 422. `cs.CV` - FlexICL：一种针对肘部和腕部超声波分割的灵活视觉上下文学习框架 [PDF](https://arxiv.org/pdf/2510.26049), [HTML](https://arxiv.org/abs/2510.26049)
### Authors
Yuyue Zhou,Jessica Knight,Shrimanti Ghosh,Banafshe Felfeliyan,Jacob L. Jaremko,Abhilash R. Hareendranathan
### Background
儿科中，肘部和腕部骨折是最常见的骨折类型。超声（US）图像中的肌肉骨骼结构自动分割可以提高诊断准确性和治疗规划。骨折表现为皮质缺陷，但需要专家解释。深度学习（DL）可以提供实时反馈并突出关键结构，帮助轻度训练的用户更好地进行检查。然而，像素级别的专家标注训练仍耗时且成本高。为解决这一挑战，本文提出了一种新颖且灵活的上下文学习（ICL）框架，命名为FlexICL。该框架用于超声视频内部分割场景，专家只需标注少数帧，模型则分割未见帧。该研究系统地调查了各种图像拼接技术及训练策略，并引入了新型拼接方法，显著提升了模型性能。通过整合多种增强策略，FlexICL在四个腕部和肘部US数据集上取得了稳健的分割性能，仅需5%的训练图像。该模型在1,252个US扫面上，骰子系数上优于现有最好表现的视觉ICL模型（如Painter，MAE-VQGAN）及常规分割模型（如U-Net，TransUNet），性能提升1-27%。初期结果显示，FlexICL作为一种高效且可扩展的超声图像分割解决方案，适用于缺乏标注数据的医学成像应用场景。
### Innovation
本文提出了FlexICL，一种新颖且灵活的上下文学习（ICL）框架，用于超声视频内部分割。该框架通过专家标注少数帧来分割未见帧，显著减少了标注需求。通过系统调查图像拼接技术和引入新型拼接方法，FlexICL在低成本标签数据的情况下，实现了卓越的分割性能。进一步地，通过整合多种增强策略，FlexICL在多个数据集上表现优异，且在Dice系数上与其他现有模型相比有显著提升。
### Conclusion
FlexICL作为一种高效且可扩展的超声图像分割解决方案，特别适合医学成像中缺乏标签数据的应用场景。其优点在于减少专家标注工作量，同时保持高分割准确度。该框架适用于肘部和腕部的US图像分割任务，为相关领域提供了新的研究思路。
## 423. `cs.CV` - 探索基于对象感知注意力引导的RGB-D SLAM帧关联 [PDF](https://arxiv.org/pdf/2510.26131), [HTML](https://arxiv.org/abs/2510.26131)
### Authors
Ali Caglayan,Nevrez Imamoglu,Oguzhan Guclu,Ali Osman Serhatoglu,Ahmet Burak Can,Ryosuke Nakamura
### Background
注意力模型近年来已经成为一种强大的方法，展示了在各个领域的显著进展。可视化技术，如类别激活映射，提供了对卷积神经网络（CNN）推理过程的视觉见解。通过网络梯度，可以识别网络在图像识别任务中关注的区域。进一步地，这些梯度可以与CNN特征结合，定位场景中的更普遍且任务特定的注意力（显著）区域。然而，将基于梯度的注意力信息显式地直接整合到CNN表示中以实现语义对象理解的应用仍然有限。对于同时定位与建图（SLAM）等视觉任务来说，这种整合富含空间注意力对象位置的CNN表示可以提高性能。
### Innovation
本文提出了利用任务特定的网络注意力进行RGB-D室内SLAM的方法。具体地，通过将从网络梯度中导出的层级注意力信息与CNN特征表示相结合，以提高帧关联性能。实验结果表明，该方法在大规模环境中的性能优于基线方法。
### Conclusion
实验结果表明，与基线方法相比，该方法在大规模环境下能够显著提升帧关联的性能，展现了方法的有效性。
## 424. `cs.CV` - WOD-E2E：挑战长尾情景下的Waymo公开数据集 [PDF](https://arxiv.org/pdf/2510.26125), [HTML](https://arxiv.org/abs/2510.26125)
### Authors
Runsheng Xu,Hubert Lin,Wonseok Jeon,Hao Feng,Yuliang Zou,Liting Sun,John Gorman,Kate Tolstaya,Sarah Tang,Brandyn White,Ben Sapp,Mingxing Tan,Jyh-Jing Hwang,Drago Anguelov
### Background
基于视觉的端到端（E2E）驾驶在研究界引起了广泛关注，因其可扩展性和与多模态大型语言模型（MLLMs）的协同性。然而，现有的E2E驾驶基准主要包含标准场景，未能充分测试这些系统的真实潜力。此外，现有的开环评估指标在捕捉驾驶的多模态特征或有效地评估长尾场景的表现方面经常表现不佳。
### Innovation
为了弥补这些差距，我们引入了Waymo Open Dataset for End-to-End Driving (WOD-E2E)。WOD-E2E包含4021个驾驶段（大约12小时），特别为现实生活中罕见的复杂长尾场景精心策划，这些场景的出现频率低于0.03%。每个WOD-E2E段落包含了高级路线信息、自身状态以及来自8个周围摄像头的360度摄像机视图。为了评估这些长尾情况下的E2E驾驶性能，我们提出了一个新的开环评估指标——评注反馈得分（RFS）。不同于传统衡量预测方式点与日志之间距离的指标，RFS衡量预测轨迹与评注标注的轨迹偏好标签的接近程度。现已为WOD-E2E验证集的所有段落发布了评注偏好标签，而保留的测试集标签用于2025年的WOD-E2E挑战。
### Conclusion
通过我们的工作，我们旨在促进通用化、稳健和安全的端到端自主驾驶代理的研究，使其能够处理复杂的现实世界情况。
## 425. `cs.CV` - BasicAVSR: 通过图像先验和增强的运动补偿实现任意比例视频超分辨率 [PDF](https://arxiv.org/pdf/2510.26149), [HTML](https://arxiv.org/abs/2510.26149)
### Authors
Wei Shang,Wanying Zhang,Shuhang Gu,Pengfei Zhu,Qinghua Hu,Dongwei Ren
### Background
视频超分辨率（AVSR）旨在提高视频帧的分辨率，可能在各种缩放因子下进行，这带来了在空间细节复现、时间一致性以及计算复杂性方面的挑战。
### Innovation
该论文提出了一种名为BasicAVSR的基本基线方法，通过整合四个关键组件来解决这些挑战：1)基于图像拉普拉斯金字塔生成的自适应多尺度频率先验，2)流引导传播单元以聚合相邻帧的空间和时间信息，3)二次运动补偿单元以更精确地对齐相邻帧的空间定位，4)超采样单元生成具有缩放意识和内容无关性的超采样核。此外，为了满足不同的应用需求，实例化了三种传播变体：（i）单向RNN单元以进行严格在线推理，（ii）带有有限向前观察的单向RNN单元以容忍较小的输出延迟，（iii）双向RNN单元以适应计算资源更宽松的离线任务。实验结果表明，该模型在不同场景下的有效性与适应性，并且在超分辨率质量、泛化能力和推理速度方面显著优于现有方法。
### Conclusion
本研究不仅推进了AVSR领域的最新技术水平，还将其核心组件扩展到多个框架以适应多种场景。这种代码已在此处可用：this https URL。
## 426. `cs.CV` - FullPart: 在全分辨率生成每个3D部分 [PDF](https://arxiv.org/pdf/2510.26140), [HTML](https://arxiv.org/abs/2510.26140)
### Authors
Lihe Ding,Shaocong Dong,Yaokun Li,Chenjian Gao,Xiao Chen,Rui Han,Yihao Kuang,Hong Zhang,Bo Huang,Zhanpeng Huang,Zibin Wang,Dan Xu,Tianfan Xue
### Background
部分基于3D生成在多种应用中具有巨大潜力，但现有方法在表示几何细节方面存在不足。一种方法使用隐式的向量集表示法，但往往无法提供足够的几何细节。另一种方法使用显式的体素表示法，但由于所有部件共享一个全局体素网格，导致小部件的细节被稀释，质量下降。
### Innovation
本文提出了一种名为FullPart的新型框架，将隐式和显式表示法结合起来。首先，通过隐式盒体向量集扩散过程推导出边界框布局。然后，每个部件都在固定的全分辨率体素网格中生成详细结构。此外，引入了中心点编码策略来解决不同实际尺寸部件间信息交换的对齐问题，保持全局一致性。为了应对可靠3D部分数据的稀缺，还提出了迄今为止最大的3D部件数据集PartVerse-XL，包含4万个对象和32万个部件。实验表明FullPart在3D部分生成中取得了最先进的结果。
### Conclusion
全代码、数据和模型将公开，以促进未来在3D部分生成领域的研究。
## 427. `cs.CV` - 使用深度学习检测未经授权的车辆以支持智能城市：以孟加拉国为例 [PDF](https://arxiv.org/pdf/2510.26154), [HTML](https://arxiv.org/abs/2510.26154)
### Authors
Sudipto Das Sukanto,Diponker Roy,Fahim Shakil,Nirjhar Singha,Abdullah Asik,Aniket Joarder,Mridha Md Nafis Fuad,Muhammad Ibrahim
### Background
不同国家的交通运输方式因其地理位置和文化背景而异。在南亚国家，人力三轮车是当地运输中最常见的工具之一。基于运营方式，孟加拉国各城市的人力三轮车和机动三轮车可以大致分为非机动（人力驱动）和机动两种类型。监控机动三轮车的行进是必要的，因为交通规则通常限制它们进入某些路线。然而，现有的监控系统由于机动三轮车与普通车辆以及其他人力三轮车的相似性，难以有效监测它们。手动视频分析需要大量时间。
### Innovation
本文提出了一种基于深度学习的方法，用于自动检测交通图像中的机动三轮车。该系统使用YOLOv8模型进行实时对象检测。为确保准确性，准备了一个包含1,730张标注图像的数据集，这些图像在不同的交通条件下捕捉。结果表明，提出的方法在检测机动三轮车方面表现良好，实现实时检测，精度高达mAP50 83.447%，二元精确率和召回率均超过78%。
### Conclusion
所提出的方法在处理密集和稀疏交通场景方面均表现出色，数据集已公开，供进一步研究使用。该研究对于支持智能城市的交通监控具有重要意义，能够有效监测机动三轮车和其他未经授权的车辆。
## 428. `cs.CV` - ConceptScope: 通过解纠缠的视觉概念表征数据集偏差 [PDF](https://arxiv.org/pdf/2510.26186), [HTML](https://arxiv.org/abs/2510.26186)
### Authors
Jinho Choi,Hyesu Lim,Steffen Schneider,Jaegul Choo
### Background
数据偏差在机器学习数据集中普遍存在，但缺乏细粒度的属性注释，使得系统地识别这些偏差具有挑战性。本文的研究背景在于开发一种方法来自动发现和量化可视数据集中的概念，以便理解数据集中的类概念、偏差和鲁棒性。
### Innovation
概念摘要提出了一个可扩展且自动化的框架，叫做ConceptScope，该框架使用基于视觉基础模型表示的稀疏自动编码器发现和量化可解读的概念。ConceptScope 根据语义相关性和统计相关性将概念分类为目标、上下文和偏差类型，通过基于概念的子组分类实现类级别数据集表征、偏差识别和基于概念的鲁棒性评估。
### Conclusion
概念摘要验证了ConceptScope能够捕捉到广泛的视觉概念，并且能够可靠地检测已知偏差（例如Waterbirds中的背景偏差）以及发现以前未被标注的偏差（例如ImageNet中的共现对象）。总之，ConceptScope为数据集审核和模型诊断提供了一个实用的工具。
## 429. `cs.CV` - MoTDiff: 单张模糊图像中基于扩散模型的高分辨率运动轨迹估计 [PDF](https://arxiv.org/pdf/2510.26173), [HTML](https://arxiv.org/abs/2510.26173)
### Authors
Wontae Choi,Jaelin Lee,Hyung Sup Yun,Byeungwoo Jeon,Il Yong Chun
### Background
准确估计运动信息在各种计算成像和计算机视觉应用中至关重要。研究人员已探索了从单张模糊图像中提取运动信息的各种方法，包括模糊核和光学流。然而，现有的运动表示通常是质量较低的，即粗粒度且不准确。
### Innovation
本文提出了一种新的高分辨率（HR）运动轨迹估计框架（MoTDiff），使用扩散模型。MoTDiff包含两个关键组件：1) 一种新的条件扩散框架，利用单张模糊图像多尺度特征图作为条件；2) 一种新的训练方法，能够促进对细粒度运动轨迹的精确识别、整体形状和位置的稳定估计，以及运动轨迹上的像素连接性。实验表明，MoTDiff在盲图像去模糊和编码曝光摄影应用中均优于现有最好方法。
### Conclusion
本文提出的MoTDiff框架能够在单张模糊图像中从多尺度特征图条件中估计高质量的高分辨率运动轨迹，实验证明其性能优于现有的最好方法。
## 430. `cs.CV` - 开发用于供应链可持续性和风险管理的多任务集成几何深度网络 [PDF](https://arxiv.org/pdf/2510.26203), [HTML](https://arxiv.org/abs/2510.26203)
### Authors
Mehdi Khaleghi,Nastaran Khaleghi,Sobhan Sheykhivand,Sebelan Danishvar
### Background
供应链的可持续性对实现供应链最优性能起着关键作用。管理供应链中出现的风险是提高网络可持续性和提升供应链性能效率的基本问题。正确的对产品进行分类是使供应链可持续化的另一项重要元素。近期在深度网络背景下取得的突破为分析供应链数据集提供了多种架构选择。本文利用Chebyshev集成几何网络（Ch-EGN）对供应链数据库中的信息依赖性进行分析，以推导数据库样本的隐形状态。该网络在供应链风险管理和可持续性方面进行了评估，分别使用了SupplyGraph Dataset和DataCo数据库进行研究。
### Innovation
本文提出了一种新的几何深度学习网络——Chebyshev集成几何网络（Ch-EGN），这是一种混合卷积和几何深度学习的网络，旨在利用供应链中的信息依赖性来推导数据库样本的隐形状态。通过多任务集成方法对两种不同数据库的预测结果表明，该方法在风险管理、可持续供应链和公司关系分类等方面具有显著的准确性和效率改进，特别是在产品分类和边分类方面均表现出色。
### Conclusion
该研究结果表明，提出的集成几何网络方法在供应链风险管理和可持续性方面优于现有方法，分别在风险状态预测、产品分类和公司关系分类中达到了98.95%以上的准确率，验证了其有效性。
## 431. `cs.CV` - CRAG-MM：多模态多轮综合RAG基准 [PDF](https://arxiv.org/pdf/2510.26160), [HTML](https://arxiv.org/abs/2510.26160)
### Authors
Jiaqi Wang,Xiao Yang,Kai Sun,Parth Suresh,Sanat Sharma,Adam Czyzewski,Derek Andersen,Surya Appini,Arkav Banerjee,Sajal Choudhary,Shervin Ghasemlou,Ziqiang Guan,Akil Iyer,Haidar Khan,Lingkun Kong,Roy Luo,Tiffany Ma,Zhen Qiao,David Tran,Wenfang Xu,Skyler Yeatman,Chen Zhou,Gunveer Gujral,Yinglong Xia,Shane Moon,Nicolas Scheffer,Nirav Shah,Eun Chang,Yue Liu,Florian Metze,Tammy Stark,Zhaleh Feizollahi,Andrea Jessee,Mangesh Pujari,Ahmed Aly,Babak Damavandi,Rakesh Wanga,Anuj Kumar,Rohit Patel,Wen-tau Yih,Xin Luna Dong
### Background
随着可穿戴设备如智能眼镜的普及，人们与周围环境的互动方式正在变化，用户可以通过这些设备获取视野中实体的相关信息。多模态检索增强生成（MM-RAG）在支持此类查询中起着关键作用，但目前在可穿戴设备场景下缺乏全面的基准数据集。因此，本文提出了CRAG-MM，这是一个全面的多模态多轮对话RAG基准集，包含来自13个领域的6500个（图像、问题、答案）三元组和2000个基于视觉的多轮对话。该基准集包括6200张模拟可穿戴设备获取的自中心图像，目的是反映现实世界中的场景和挑战，包括五类图像质量问题、六类问题类型、实体流行度的差异、信息动态变化的差异以及不同轮次的对话。
### Innovation
本文提出了CRAG-MM，填补了可穿戴设备场景下多模态多轮RAG数据的空白。该基准集包含了多样化的图像、问题和答案三元组，以及2000个基于视觉的多轮对话，覆盖13个领域，并且包含精心设计的问题，以反映现实世界中的场景和挑战。此外，设计了三个任务：单源增强、多源增强和多轮对话，每个任务都配有相应的检索语料库和API，包括图像知识图谱检索API和网页检索API。
### Conclusion
评估结果显示，直接的RAG方法在CRAG-MM单轮和多轮问答上的正确性分别仅为32%和43%，而最先进的行业解决方案也仅有类似的质量（32%/45%），表明仍有很大的改进空间。 CRAG-MM基准已用于KDD Cup 2025，吸引了约1000名参与者和5000份提交，并且获奖解决方案将基线性能提高了28%，突显了其对推动该领域发展的早期影响。
## 432. `cs.CV` - Sketch2PoseNet: 高效且通用的草图到3D人体姿态预测 [PDF](https://arxiv.org/pdf/2510.26196), [HTML](https://arxiv.org/abs/2510.26196)
### Authors
Li Wang,Yiyu Zhuang,Yanwen Wang,Xun Cao,Chuan Guo,Xinxin Zuo,Hao Zhu
### Background
3D人体姿态估计算法在计算机动画和电影制作中有广泛应用。与传统的姿态估计任务不同，从草图中估计人体姿态面临着独特挑战，因为草图具有抽象和比例失调的特点。之前的草图到姿态方法受限于缺乏大规模的草图-3D姿态标注数据集，这些方法主要依赖于基于启发式规则的优化，这种过程耗时且通用性有限。因此，文章提出了一种创新的方法，利用合成学习策略。首先，通过训练扩散模型生成从3D人体姿态投影得到的2D姿态的草图图像，以此模拟草图中失调的人体结构。这个过程产生了包含120000组草图-3D姿态标注对的合成数据集SKEP-120K，覆盖了多种草图风格。在这一合成数据集的支持下，文章引入了一个端到端的数据驱动框架，用于从多种草图风格中估计人体姿态和形状。
### Innovation
文章提出了一种创新的合成学习策略，通过训练扩散模型生成从3D人体姿态投影得到的草图图像，以此绕过大规模标注数据集的限制。同时，该方法还结合使用现有的2D姿态检测器和生成扩散先验，为草图特征提取和高效的2D姿态估计提供了一个端到端的数据驱动框架。通过加入多个启发式损失函数，保证了从生成的3D姿态与检测到的2D姿态几何一致性的同时，保持了人体正确接触。
### Conclusion
文章通过定性、定量和主观评估展示了，该模型在草图到姿态任务中，无论是估计准确性还是速度上都显著超越了之前的方法。
## 433. `cs.CV` - OmniLayout: 使大语言模型能够进行粗到细学习以实现通用文档布局生成 [PDF](https://arxiv.org/pdf/2510.26213), [HTML](https://arxiv.org/abs/2510.26213)
### Authors
Hengrui Kang,Zhuangcheng Gu,Zhiyuan Zhao,Zichen Wen,Bin Wang,Weijia Li,Conghui He
### Background
文档AI取得了迅速的发展，并受到了广泛的关注。尽管大多数努力集中在文档布局分析（DLA）上，但文档布局生成这一生成性方面的研究却相对较少。主要的障碍在于缺乏多样化的布局：现有的研究主要涉及具有摩天大楼风格结构的学术论文，而像报纸和杂志这类开放世界的文体严重不足。为了弥合这一差距，本文策划了OmniLayout-1M，这是一个包含多样化的文档布局的一百万规模的数据集，涵盖了六种常见文档类型，并收集了来自多个来源的当代布局。此外，现有方法在复杂领域中常常难以应对，并且往往无法很好地排列长序列内容，所以引入了OmniLayout-LLM，这是一个500兆规模的模型，设计了粗到细的学习范式：首先，从OmniLayout-1M中学习普遍的布局原则并设定粗略的类别定义；其次，将知识应用到特定领域中使用细粒度注解。
### Innovation
通过策划OmniLayout-1M和OmniLayout-LLM，提出了一个粗到细的大语言模型学习范式。该方法能够学习普遍的布局原则，并将其知识应用于特定领域。实验结果表明，这种方法在M$^{6}$Doc数据集的多个领域中表现出色，显著超越了现有的布局生成专家和多个最新的通用大语言模型。
### Conclusion
我们的方法在多个领域中表现出了强大的性能，在M$^{6}$Doc数据集上超过了现有的布局生成专家和一些最新的通用大语言模型。我们计划公开代码、模型和数据集。
## 434. `cs.CV` - 基于人类认知规律 revisit 红外和可见光图像生成融合 [PDF](https://arxiv.org/pdf/2510.26268), [HTML](https://arxiv.org/abs/2510.26268)
### Authors
Lin Guo,Xiaoqing Luo,Wei Xie,Zhancheng Zhang,Hui Li,Rui Wang,Zhenhua Feng,Xiaoning Song
### Background
现有的红外和可见图像融合方法经常面临平衡模态信息的困境。生成式融合方法通过数据分布进行学习以重建融合图像，但其生成能力有限。模态信息选择的缺乏可解释性进一步影响了复杂情境下融合结果的可靠性和一致性。
### Innovation
本文受到人类认知规律的启发，重新审视生成图像融合的本质，并提出了一种新的红外和可见光图像融合方法，称为HCLFuse。该方法通过无监督融合网络的信息量度量理论，设计一个多尺度掩码调节变分瓶颈编码器。该编码器结合后验概率建模和信息分解来提取准确、简洁的低层次模态信息，从而支持高保真结构细节生成。此外，该方法将扩散模型的概化生成能力与物理法则相结合，形成时间变化的物理指导机制，在不同的生成阶段自适应调节生成过程，从而增强模型感知数据内在结构的能力，减少对数据质量的依赖。实验结果显示，所提出的方法在多个数据集上取得了最先进的融合性能，并显著提高了语义分割指标，充分展示了基于人类认知的生成图像融合方法的优势，提升了结构一致性和细节质量。
### Conclusion
研究表明，该生成式图像融合方法在多种数据集上的融合性能达到最先进的水平，并显著提高了语义分割指标，证明了这种方法在增强结构一致性和细节质量方面的优势。
## 435. `cs.CV` - 在不同获取距离下探索眼周区域认证中CNN互补性和可解释性的研究 [PDF](https://arxiv.org/pdf/2510.26282), [HTML](https://arxiv.org/abs/2510.26282)
### Authors
Fernando Alonso-Fernandez,Kevin Hernandez Diaz,Jose M. Buades,Kiran Raja,Josef Bigun
### Background
本研究探讨了不同CNN在UBIPr数据库中对于不同距离的眼周认证的互补性。研究使用了三种复杂度递增的CNN架构：SqueezeNet、MobileNetv2和ResNet50。这些模型均在VGGFace2提供的大量眼部裁剪图像上进行了训练。
### Innovation
本文创新地采用了一个多网络融合的方法，通过逻辑回归实现特征级融合，并且使用了一种新颖的方法来比较不同CNN的注意力模式：通过LIME热图和詹森-沙恩伯格散度。结果显示，虽然ResNet50在单独使用时表现最佳，但多网络融合还是提供了显著的性能提升，特别是在所有三个网络相互结合的情况下。
### Conclusion
在UBIPr数据库上，本文提出的方法显著优于先前工作，实现了最新的性能标准。此外，热图表明网络通常能够集中关注给定图像的不同区域，这解释了它们之间的互补性。
## 436. `cs.CV` - MV-MLM: 融合多视图乳腺X光成像与语言模型以实现乳腺癌诊断和风险预测 [PDF](https://arxiv.org/pdf/2510.26151), [HTML](https://arxiv.org/abs/2510.26151)
### Authors
Shunjie-Fabian Zheng,Hyeonjun Lee,Thijs Kooi,Ali Diba
### Background
大型注释数据集对于培训稳健的计算机辅助诊断（CAD）模型至关重要，尤其是用于乳腺癌检测或风险预测。然而，获取此类细粒度注释的数据集既昂贵又耗时。视觉语言模型（如CLIP），这些模型在大量图像-文本对上进行预训练，提供了通过增强医疗成像任务的稳健性和数据效率来解决问题的潜在解决方案。本文介绍了通过配对的乳腺X光图像和合成医学影像报告数据集来训练的一种新颖的多视图乳腺X光和语言模型（MV-MLM），该模型利用多视图监督从广泛的医学影像数据中学习丰富的表示，通过跨模态的自监督学习跨越图像-文本对。这种方法涵盖了多个视图和相应的伪医学影像报告。我们提出了一种新的联合视觉-文本学习策略，以增强在不同数据类型和任务中的泛化能力和准确性能，从而区分乳腺组织或癌性特征（钙化、肿块），并利用这些模式来理解乳腺X光图像并预测癌症风险。我们的方法在私营和公开可用的数据集上进行了评估，结果显示所提出的模型在三种分类任务中的性能达到了最先进的水平：（1）恶性肿瘤分类、（2）亚型分类和（3）基于图像的癌症风险预测。此外，该模型还展示了强大的数据效率，在合成文本报告而非实际医学影像报告的情况下，比现有的完全监督或视觉语言模型基线模型表现更优。
### Innovation
本文提出了一种多视图乳腺X光和语言模型（MV-MLM），该模型通过合成的医学影像报告数据集进行训练。MV-MLM利用多视图监督学习自监督的跨模态信息，跨越图像-文本对，利用合成文本报告的多视图伪医学影像报告进行训练，而无需实际的医学影像报告。这种方法增强了一般泛化能力和准确性能，并能够更有效地利用数据。MV-MLM在乳腺癌诊断和风险预测的不同任务中表现出了超越现有基线模型的性能，尤其是在处理乳腺组织和癌性特征的分类方面。
### Conclusion
所提出的多视图乳腺X光和语言模型（MV-MLM）展示了在乳腺癌诊断和风险预测三种分类任务上的优秀性能，特别是在内部和外部数据集的评估中。此外，MV-MLM通过融合多视图图像和合成文本报告，展示了提高数据效率和模型泛化能力的有效性，而无需依赖真实医学影像报告。这为乳腺癌的研究提供了新的见解和支持，同时也展示了视觉语言模型在医疗成像任务中的应用潜力。
## 437. `cs.CV` - 时间之流的方向：基于心理物理学的视觉-语言模型评估 [PDF](https://arxiv.org/pdf/2510.26241), [HTML](https://arxiv.org/abs/2510.26241)
### Authors
Shiho Matta,Lis Kanashiro Pereira,Peitao Han,Fei Cheng,Shigeru Kitazawa
### Background
现代视觉-语言模型（VLMs）在众多跨模态任务上表现出色，但在视频中的时间信息把握方面仍有明显不足且没有得到充分评估。本文通过一个看似简单但意义深远的挑战——判断视频片段是正播放还是倒放，来探究这一差距。引入了一个基于心理物理学验证的基准测试AoT-PsyPhyBENCH，用于测试VLMs是否能通过相同的刺激和与人类相同的行为基准判断自然视频中的时间方向。评估结果显示，大多数模型的表现接近随机水平，即使是最佳模型也远远落后于人类在不可逆物理过程（如自由落体、扩散/爆炸）和因果手动行为（如除法/加法）上的即时识别准确性。这些结果凸显了当前多模态系统中的根本性差距：虽然能捕捉丰富的视觉-语义关联，但缺乏用于时间连续性和因果理解的归纳偏置。作者提供了AoT-PsyPhyBENCH的代码和数据，以鼓励进一步增强VLMs在物理和时间推理能力上的进展.
### Innovation
提出了一个基于心理物理学验证的基准AoT-PsyPhyBENCH，用于评估VLMs在判断视频时间方向上的能力。这是首次对该领域进行结构化的、心理物理学验证的评估，包括不同开放权重和专有模型在内，涵盖推理和非推理模型。评估结果显示，大多数VLMs的表现远未达到人类水平，表明当前VLMs缺乏必要的时间连续性和因果理解偏置
### Conclusion
现有视觉-语言模型虽然能捕捉丰富的视觉-语义关联，但缺乏时间连续性和因果理解的偏置。AoT-PsyPhyBENCH提供了新的基准来评估和改进VLMs的物理和时间推理能力，未来研究将基于此基准进行改进和发展。
## 438. `cs.CV` - 超越模仿：基于流匹配的约束感知轨迹生成方法及其在端到端自动驾驶中的应用 [PDF](https://arxiv.org/pdf/2510.26292), [HTML](https://arxiv.org/abs/2510.26292)
### Authors
Lin Liu,Guanyi Yu,Ziying Song,Junqiao Li,Caiyan Jia,Feiyang Jia,Peiliang Wu,Yandan Luo
### Background
端到端自主驾驶的核心组成部分之一是规划。现有的模仿学习方法往往遭受模式崩塌的问题，无法生成多样化的轨迹假设。而现有的生成算法在融合关键的安全和物理约束时也存在问题，需要额外的优化阶段来改进它们的输出。这两个问题限制了当前技术的发展，需要改进的规划框架来解决这些问题。
### Innovation
本研究提出了CATG（Constrained Adaptive Trajectory Generation），这是利用受到约束的流匹配过程的一种新型的规划框架。该框架通过显式建模流匹配过程内在地解决了模式崩塌问题，并且可以灵活地使用来自不同条件信号的引导。其主要创新是在流匹配过程中直接施加显性约束，确保生成的轨迹遵循重要的安全和动力学规则。此外，通过参数化驾驶的侵略性作为一种控制信号，可以使轨迹风格得到精确的调整。这一方法在NavSim v2 挑战中获得第二名，EPDMS得分为51.31，并且由于其创新性荣获了创新奖。
### Conclusion
CATG框架在不同的评估指标上展现了优异的性能，不仅可以生成多样且安全的自动驾驶轨迹，还显示了其在端到端自主驾驶应用中潜在的巨大潜力。
## 439. `cs.CV` - 利用大规模人脸数据集通过眼部截取实现深度眼周识别 [PDF](https://arxiv.org/pdf/2510.26294), [HTML](https://arxiv.org/abs/2510.26294)
### Authors
Fernando Alonso-Fernandez,Kevin Hernandez-Diaz,Jose Maria Buades Rubio,Josef Bigun
### Background
研究主要集中在眼部生物识别，特别是眼周区域，因其高区分度和较低的获取要求。现有的研究通常依赖于小型眼周数据集进行训练，而较少使用大规模数据集。本文通过大规模的数据集VGGFace2训练不同深度和复杂度的卷积神经网络（CNN），评估其在眼周识别中的效果，进而对比现有的研究成果。并使用VGGFace2-Pose和UFPR-Periocular数据库中的数据进行实验验证。
### Innovation
使用大规模的VGGFace2数据库训练卷积神经网络，评估其在眼周识别中的效果，尤其是在真实世界环境中获取的图像条件下。相比现有研究，此方法能显著提高识别准确度，尤其是在UFPR-Periocular数据库中达到了1-2%的较低等错误率（EERs），这是迄今为止该数据集中报告的最低EERs。
### Conclusion
通过利用大规模的人脸数据集进行眼周区域的识别，本文的方法能够显著提高识别率，特别是在实际应用场景中获取的图像条件下。相比于现有使用少量数据集的方法，这是一次有效的创新尝试，对未来的眼部生物识别技术具有重要意义。
## 440. `cs.CV` - 探索音乐类型与激发情绪之间的相关性：基于主观问卷和EEG的研究 [PDF](https://arxiv.org/pdf/2510.26304), [HTML](https://arxiv.org/abs/2510.26304)
### Authors
Jelizaveta Jankowska,Bożena Kostek,Fernando Alonso-Fernandez,Prayag Tiwari
### Background
该研究的主题是检查不同类型音乐对人类情绪的影响。参与者在听音乐的同时，通过EEG头盔进行主观调查和大脑活动测量。研究涉及了不同性别和音乐偏好的多样参与者群体，从而捕捉到对不同音乐的广泛情绪反应。
### Innovation
创新之处在于通过主观问卷和EEG信号的综合分析，揭示情绪与大脑活动之间的联系，进一步探讨了不同类型音乐对情绪的影响机制。
### Conclusion
实验结果表明，不同类型的音乐与大脑活动之间存在关联，这进一步证实了音乐对情绪的影响。该研究强调了利用多模态数据（如主观评价和生理指标）来研究音乐与情绪之间的关系的重要性。
## 441. `cs.CV` - 达成立体地球观测星座调度现实性：基准与方法 [PDF](https://arxiv.org/pdf/2510.26297), [HTML](https://arxiv.org/abs/2510.26297)
### Authors
Luting Wang,Yinghao Xiang,Hongliang Huang,Dongjun Li,Chen Gao,Si Liu
### Background
敏捷地球观测卫星（AEOSs）星座为监测地球表面提供了前所未有的灵活性，但在大规模场景、动态环境和苛刻条件下，其排程依然具有挑战性。现有方法通常简化这些复杂性，限制了其在真实环境中的性能。
### Innovation
本文提出了一个统一框架，集成了标准化基准套件和新的排程模型。基准套件AEOS-Bench包含3,907个精确调优的卫星资产和16,410个场景。每个场景包括1至50颗卫星和50至300项成像任务，这些场景通过高保真仿真平台生成，确保了真实的卫星行为，如轨道动力学和资源限制。基准套件是首个专门为现实星座排程设计的大规模基准套件。基于此基准，引入了AEOS-Former，一种基于Transformer的排程模型，集成了一种约束感知注意机制，并通过仿真迭代学习，能够适应多样场景，提供AEOS星座排程的稳健解决方案。实验结果证明AEOS-Former在任务完成和能效方面优于基础模型。
### Conclusion
AEOS-Former在任务完成和能效方面超越基础模型。通过消融研究强调每个组件的贡献。代码和数据可在以下链接获取：this https URL.
## 442. `cs.CV` - 基于证据理论的CNN与ViT融合框架用于糖尿病视网膜病变分级 [PDF](https://arxiv.org/pdf/2510.26315), [HTML](https://arxiv.org/abs/2510.26315)
### Authors
Junlai Qiu,Yunzhu Chen,Hao Zheng,Yawen Huang,Yuexiang Li
### Background
糖尿病视网膜病变（DR）是中老年人视力丧失的主要原因，严重影响了他们的日常生活和精神健康。为了提高临床检查的效率并实现DR的早期检测，基于卷积神经网络（CNN）或视觉变换器（ViT）的自动DR诊断系统已被建立。但由于CNN和ViT自身的缺点，现有单一模型的性能已达到瓶颈。现有方法的一个潜在改进途径是结合不同类型的骨干网络，这样可以充分发挥各自的优点（比如CNN的局部特征提取能力和ViT的全局特征捕捉能力）。
### Innovation
本文提出了一种新的基于证据理论的有效融合不同骨干网络提取特征的框架。具体地，该框架通过一组深度证据网络将不同骨干网络的特征转换为支持证据。基于支持证据，可以形成综合意见，以适应性地调整不同骨干网络之间的融合模式，并提升所提出的混合模型的性能。
### Conclusion
我们在两个公开的DR分级数据集上评估了我们的方法。实验结果表明，与最先进的框架相比，我们的混合模型不仅提高了DR的分级精度，还提供了优秀的特征融合和决策解释能力。
## 443. `cs.CV` - LoCoT2V-Bench：一种长视频和复杂文本转视频生成基准 [PDF](https://arxiv.org/pdf/2510.26412), [HTML](https://arxiv.org/abs/2510.26412)
### Authors
Xiangqing Zheng,Chengyue Wu,Kehai Chen,Min Zhang
### Background
文本到视频生成在制作短片和高质量片段方面取得了显著进展，但处理复杂的长视频输出仍是一个重大挑战，尤其是在处理复杂提示时。现有的基准主要依赖于简化的提示，专注于低级度量，忽略了精细粒度的提示一致性和叙事连贯性等抽象维度。
### Innovation
提出了LoCoT2V-Bench，这是一个专门为复杂输入条件下长视频生成（LVG）设计的基准。它引入了包括场景过渡和事件动力学在内的多种现实和复杂提示，并构建了一个多维度的评估框架，包括事件级别的对齐、精细的时间一致性、内容清晰度和一个新的度量标准HERD，关注叙事流动、情感反应和角色发展等抽象属性。
### Conclusion
该基准为长视频和复杂文本转视频生成提供了全面可靠的评估平台，并指出了未来方法改进的关键方向。
## 444. `cs.CV` - 基于注意引导扩散模型的脑电图驱动图像重建 [PDF](https://arxiv.org/pdf/2510.26391), [HTML](https://arxiv.org/abs/2510.26391)
### Authors
Igor Abramov,Ilya Makarov
### Background
现有基于脑电图（EEG）的图像重建方法通常忽视了空间注意力机制，这限制了图像重建的精度和语义连贯性。现有的方法未能有效融合EEG特征和空间显著性图，限制了图像生成的质量和对人类视觉注意的匹配程度。
### Innovation
本文提出了一个双条件框架，结合EEG嵌入和空间显著性图来增强图像生成。该方法利用了自适应思维映射器（ATM）进行EEG特征提取，并通过低秩适配（LoRA）微调了稳定扩散2.1模型，以使神经信号与视觉语义对齐。同时，控制分支在生成过程中条件化于显著性图，以实现空间控制。在THINGS-EEG数据集上，该方法在低级和高级图像特征的质量上显著优于现有方法，并且高度匹配了人类的视觉注意。这些结果表明，注意力先验能够解决EEG的歧义性，从而实现高保真的图像重建，适用于医学诊断和神经适应接口，提高了通过预先训练的扩散模型高效适配神经解码的能力
### Conclusion
研究结果表明，这种新的基于注意力引导的扩散模型方法能够有效增强基于脑电图的图像重建质量，并且在医学诊断和神经适应接口方面具有广泛的应用前景，通过高效适配预训练扩散模型来提高神经解码的效率。
## 445. `cs.CV` - PointSt3R: 通过3D关联进行点追踪 [PDF](https://arxiv.org/pdf/2510.26443), [HTML](https://arxiv.org/abs/2510.26443)
### Authors
Rhodri Guerrier,Adam W. Harley,Dima Damen
### Background
近年来，基础的3D重建模型（如DUSt3R和MASt3R）在静态场景中的2D和3D对应关系上显示出显著潜力。本文旨在将这些模型应用于点追踪任务，特别是基于3D空间中的对应关系进行点追踪。
### Innovation
研究引入了一种点追踪方法，将重建损失与动态对应关系的训练相结合，并提出了一个新的可见性头。通过这种方式，该方法在使用相对少量合成数据微调MASt3R后，能够有效地进行点追踪。特别地，方法仅在包含查询点的一对帧中进行训练和评估，这消除了时间上下文的影响。
### Conclusion
研究结果表明，该方法能够获得与其他领先方法相当或更优的点追踪性能。在四个数据集中，PointSt3R取得了优于CoTracker2和RGB-S的结果，特别是在点追踪较为困难的场景下。此外，还提供了关于不同训练数据集以及动态对应关系百分比的消融实验结果。
## 446. `cs.CV` - GLYPH-SR: 能否通过VLM指导的潜存扩散模型同时实现高质量图像超分辨率和高保真文本恢复？ [PDF](https://arxiv.org/pdf/2510.26339), [HTML](https://arxiv.org/abs/2510.26339)
### Authors
Mingyu Sung,Seungjae Ham,Kangwoo Kim,Yeokyoung Yoon,Sangseok Yun,Il-Min Kim,Jae-Mo Kang
### Background
图像超分辨率（SR）对于许多视觉系统至关重要，包括监控、自主、文档分析和零售分析等领域，因为恢复高频细节，特别是场景中的文本信息，能够提升可靠的后续感知。场景文本通常包含最行动的信息，当字符被模糊或凭空产生时，光学字符识别（OCR）和随后的决策会失败。尽管之前的研究多关注于降噪（PSNR/SSIM）或学习感知度量（LIPIS，MANIQA，CLIP-IQA，MUSIQ），这些对字符级别的错误并不敏感。很多针对文本的SR研究也仅关注孤立字符的简化基准，忽略复杂自然场景中的文本挑战，因此，场景中的文本实际并未被有效处理。
### Innovation
GLYPH-SR 提出了一个受视-语指导的扩散框架，旨在同时优化文本可读性和感知质量。它使用由 OCR 数据引导的文字-超分辨率融合控制网（TS-ControlNet），以及文本和场景间交替指导的乒乓调度器。通过在合成数据集上训练这些组件，同时保持主要 SR 支路冻结，实现了在 SVT、SCUT-CTW1500 和 CUTE80 数据集上的卓越性能。在图像放大的 x4 和 x8 比例下，GLYPH-SR 在 OCR F1 值方面超过了扩散/生成对抗网络（GAN）基准（SVT x8，OpenOCR），同时保持竞赛级的 MANIQA，CLIP-IQA 和 MUSIQ 性能。
### Conclusion
GLYPH-SR 的设计目标既是为了高可读性也是为了保持视觉真实感，从而实现既直观又正确的 SR。
## 447. `cs.CV` - 基于表示级别的反事实校准以实现无偏的零样本识别 [PDF](https://arxiv.org/pdf/2510.26466), [HTML](https://arxiv.org/abs/2510.26466)
### Authors
Pei Peng,MingKun Xie,Hang Hao,Tong Jin,ShengJun Huang
### Background
视觉-语言模型中，对象-背景捷径一直是持续存在的挑战，尤其是在测试场景与训练时熟悉的共现场景不同的情况下，这会影响零样本的可靠性。
### Innovation
将此问题重新定义为因果推理问题，作者提出了一种新方法：在CLIP的表示空间中估计对象与背景的期望，并通过重组来自外部数据集、批次邻居或文本描述的多样化背景特征来合成反事实嵌入。通过估计总直接效应并模拟干预，进一步减少了背景激活，保留了有益的对象-背景交互，同时减少了幻觉得分。在无需重新训练或提示设计的情况下，该方法在上下文敏感基准测试中显著提高了最差群体和平均准确性，实现了零样本的新的无偏状态。
### Conclusion
该方法不仅在性能方面表现出色，还提供了一种轻量级的表示级反事实方式，为无偏且可靠的多模态推理提供了一条实际的因果途径。
## 448. `cs.CV` - 面向细粒度视觉-语言对齐的少样本异常检测 [PDF](https://arxiv.org/pdf/2510.26464), [HTML](https://arxiv.org/abs/2510.26464)
### Authors
Yuanting Fan,Jun Liu,Xiaochen Chen,Bin-Bin Gao,Jian Li,Yong Liu,Jinlong Peng,Chengjie Wang
### Background
现有的少样本异常检测（FSAD）方法依赖于预训练的视觉-语言模型（VLMs）通过文本描述和图像特征之间的相似性来识别潜在的异常区域，但由于缺乏详细的文本描述，这些方法只能预定义图像级别的描述来匹配每个视觉补丁标记，进而导致图像描述与补丁级别的视觉异常之间存在语义对齐偏差，从而实现次优的异常检测定位性能。
### Innovation
提出了多层次精细粒度语义标注（MFSC）以提供现有异常检测数据集的多层次和精细粒度的文本描述，并自动构造了管道。基于MFSC，提出了一种名为FineGrainedAD的新框架，该框架由多层可学习提示（MLLP）和多层语义对齐（MLSA）两部分组成。MLLP通过自动替换和连接机制引入了精细粒度的语义进入多层可学习提示，而MLSA设计了区域聚合策略和多层对齐训练，以使模型更好地与对应的视觉区域对齐。
### Conclusion
实验结果表明，提出的新框架FineGrainedAD在MVTEC-AD和VisA数据集的少样本设置中实现了优异的整体性能。
## 449. `cs.CV` - 通过头尾再平衡对抗LVLMs自我提升中的马太效应 [PDF](https://arxiv.org/pdf/2510.26474), [HTML](https://arxiv.org/abs/2510.26474)
### Authors
Xin Guo,Zhiheng Xi,Yiwen Ding,Yitao Zhai,Xiaowei Shi,Xunliang Cai,Tao Gui,Qi Zhang,Xuanjing Huang
### Background
自提升已成为提升大型视觉-语言模型（LVLMs）推理能力的主要范式，其中模型通过迭代地探索和学习成功的路径来提高自身。然而，在这个过程中我们发现一个关键问题：模型能够在处理简单查询（即头部数据）时生成高质量的路径，但面对更复杂的查询（即尾部数据）却显得力不从心。这导致了一个不平衡的优化，使得模型更倾向于发展简单的推理技能，而阻碍了其处理复杂推理任务的能力。随着迭代次数的增加，这种不平衡现象变得越来越明显，我们称之为‘马太效应’，最终阻碍了模型进一步的提升并导致性能瓶颈。
### Innovation
为应对这一挑战，我们提出了四种有效的策略，从分布重构和路径采样的两个视角出发，以在探索-学习自提升过程中实现头尾再平衡。这些方法在Qwen2-VL-7B-Instruct和InternVL2.5-4B模型在视觉推理任务上的广泛实验中证明了其有效性，平均提高了3.86个点的视觉推理能力，优于传统的自提升方法。
### Conclusion
我们的方法能够有效地缓解LVLMs在自提升过程中出现的马太效应，从而平衡优化模型在处理简单和复杂推理任务的能力。这为视觉推理能力的提升提供了新的解决方案。
## 450. `cs.CV` - SA$^{2}$Net: 基于超声体积投影成像的脊柱分割尺度自适应结构亲和性转换 [PDF](https://arxiv.org/pdf/2510.26568), [HTML](https://arxiv.org/abs/2510.26568)
### Authors
Hao Xie,Zixun Huang,Yushen Zuo,Yakun Ju,Frank H. F. Leung,N. F. Law,Kin-Man Lam,Yong-Ping Zheng,Sai Ho Ling
### Background
基于超声体积投影成像的脊柱分割在临床智能脊柱侧凸诊断中起着重要作用。然而，此任务面临几个重大挑战：忽略了不同骨特征之间的高空间相关性导致脊柱的全局上下文知识不能很好地学习；脊椎骨骼包含丰富的关于形状和位置的结构知识，需要编码到分割过程中。
### Innovation
提出了一种新的尺度自适应结构感知网络（SA$^{2}$Net）来有效地进行脊柱分割。首先，提出了尺度自适应互补策略，用于学习脊柱图像的跨维度长距离相关特征。其次，基于Transformer中多头自我注意力的一致性与语义层次亲和的关系，提出结构亲和性转换，将具有类别特定亲和性的语义特征进行转换，并结合Transformer解码器进行结构感知推理。此外，引入了一个特征混合损失聚合方法以增强模型训练，从而提高分割过程的鲁棒性和准确性。
### Conclusion
实验结果表明，我们的SA$^{2}$Net在脊柱分割性能上优于其他最先进的方法。此外，SA$^{2}$Net对各种骨干网络的适应性增强了其作为智能脊柱图像分析中先进脊柱侧凸诊断工具的潜力。
## 451. `cs.CV` - AdSum: 两流式音视频摘要化用于自动化视频广告剪辑 [PDF](https://arxiv.org/pdf/2510.26569), [HTML](https://arxiv.org/abs/2510.26569)
### Authors
Wen Xie,Yanjun Zhu,Gijs Overgoor,Yakov Bart,Agata Lapedriza Garcia,Sarah Ostadabbas
### Background
广告主通常需要为同一活动创建不同版本的广告，这些版本可能具有不同的时长。传统上，广告人员需要从较长的视频广告中手动选择并重新编辑拍摄片段，以创建较短版本。这种方法既耗费时间和劳动，又效率低下。
### Innovation
提出了一个基于音视频摘要的自动化视频广告剪辑框架，特别是针对广告行业。不同于一般的视频摘要方法主要关注视觉内容，该方法强调音频在广告中的关键作用。为此，开发了一种两流音频-视觉融合模型，预测哪些视频帧可能被选中用于商业生产的短版本广告。此外，由于缺乏特定于广告的数据库，该研究创建了AdSum204，一个包含102个实际广告活动中30秒和15秒广告配对的新数据集。
### Conclusion
实验表明，该模型在多个评估指标上（例如，平均精确度、曲线下的面积、Spearman和Kendall）优于现有的最先进的方法，证明了其在自动化视频广告剪辑方面的有效性。
## 452. `cs.CV` - 基于粒子群优化的细胞自动机边缘检测器的稳健性分析 [PDF](https://arxiv.org/pdf/2510.26509), [HTML](https://arxiv.org/abs/2510.26509)
### Authors
Vinícius Ferraria,Eurico Ruivo
### Background
边缘检测任务是图像处理中的关键任务，旨在从图像中提取相关信息。然而，一些检测器在检测松散边缘和从特定问题中提取相关上下文信息时表现出较弱的性能。为此，本研究提出了一个由二维细胞自动机描述并结合元启发式算法和迁移学习技术优化的可适应边缘检测器，旨在解决优化阶段的搜索空间扩展问题以及检测器的适应性问题，并通过一系列实验和验证技术分析了模型的适应性及迁移学习技术对其性能的影响。
### Innovation
提出了一种基于二维细胞自动机的可适应边缘检测器，并结合元启发式算法和迁移学习技术进行优化。进一步分析了扩展优化阶段的搜索空间对检测器性能的影响，以及模型对不同输入图像的适应性，并探讨了迁移学习技术在提升模型性能方面的效果。
### Conclusion
扩展优化阶段的搜索空间对所选图像集的边缘检测性能没有显著效果。同样，通过多个实验和验证技术验证了模型的适应性，发现应用到模型的迁移学习技术也没有显著改善其性能。
## 453. `cs.CV` - Spiking Patches: 异步、稀疏且高效的事件相机标记 [PDF](https://arxiv.org/pdf/2510.26614), [HTML](https://arxiv.org/abs/2510.26614)
### Authors
Christoffer Koo Øhrstrøm,Ronja Güldenring,Lazaros Nalpantidis
### Background
以往的研究中，事件通常被表示为帧或体素，这两种表示方法虽然准确度高，但丧失了事件原始的异步性和空间稀疏性。
### Innovation
本文提出了事件标记方法并设计了专门为事件相机设计的标记器Spiking Patches。它能够保留事件相机的独特属性，同时在手势识别和物体检测任务中具有更好的推理速度和准确度。
### Conclusion
通过引入Spiking Patches，本文为事件视觉得到了一种新颖的方向，甚至在某些情况下超越了现有的帧和体素表示方法。这标志着在保留事件相机属性的方法上迈出了一步。
## 454. `cs.CV` - 零shot真实世界场景中基于视觉-语言对齐的动态上下文感知场景推理 [PDF](https://arxiv.org/pdf/2510.26580), [HTML](https://arxiv.org/abs/2510.26580)
### Authors
Manjunath Prasad Holenarasipura Rajiv,B. M. Vidyavathi
### Background
在现实环境中，AI系统经常面临没有标注数据的不熟悉场景，这对传统的场景理解模型构成了重大挑战。由于无法在未见过的上下文中泛化，基于视觉的应用程序在动态、非结构化的环境中难以部署。本文探讨了如何利用视觉-语言对齐解决零样本真实世界场景问题，旨在使智能系统在无需之前特定任务训练的情况下进行环境推断和适应。实验结果表明，与基线模型相比，在复杂的和未见过的环境中，场景理解准确性提高了18%。此外，该方法在含糊不清或杂乱的场景中表现出稳健性，因为视觉和语言的协同融合。该框架提供了一种可扩展且可解释的上下文感知推理方法，推动了动态现实世界设置中零样本泛化的进步。
### Innovation
提出了一个动态上下文感知场景推理框架，利用视觉-语言对齐解决零样本真实世界场景问题，该框架融合了预训练的视觉变换器和大型语言模型，增强了语境理解。动态推理模块通过全局场景线索和语言先验指导的对象级交互来细化预测，从而使智能系统能够在无需特定任务训练的情况下推断和适应新的环境。
### Conclusion
该框架展示了在复杂的和未见过的环境中进行场景理解的提升性能高达18%，同时在含糊不清或杂乱的场景中表现出稳健性。这种方法为上下文感知推理提供了可扩展且可解释的方法，推进了动态现实世界设置中的零样本泛化。
## 455. `cs.CV` - CATCH: 模块化的跨域适应插件模板 [PDF](https://arxiv.org/pdf/2510.26582), [HTML](https://arxiv.org/abs/2510.26582)
### Authors
Xinjin Li,Yulie Lu,Jinghan Cao,Yu Ma,Zhenglin Li,Yeyang Zhou
### Background
视觉问答(VQA)模型在自然图像领域取得了显著的成绩，如LLaVA利用大型语言模型进行开放式推理。但这些模型在遥感、医学影像或数学图表等非自然图像领域表现出色性下降，主要是由于数据分布的巨大变化和缺乏有效的跨域适应机制。现有方法通常依赖于针对特定域的微调或定制的管道，这些方法成本高、不够灵活且无法在多种任务之间扩展。
### Innovation
本文提出了一种模块化的跨域适应框架CATCH，该框架可以在不改变模型核心架构的情况下，通过引入两个轻量级模块（领域分类器和双适应机制）来提高VQA模型的泛化能力。该框架通过一个统一的钩子接口动态注入模块，无需对主干模型进行重新训练。
### Conclusion
实验结果显示，CATCH框架在四个特定领域的VQA基准测试中表现出一致的性能提升，包括MathVQA +2.3 BLEU，MedVQA-RAD +2.6 VQA，ChartQA +3.1 ROUGE。这些结果表明CATCH提供了一种可扩展且可扩展的方法，用于多领域VQA，可以在多种应用程序领域中进行实践部署。
## 456. `cs.CV` - A-TPT: 基于视觉-语言模型测试时提示调优的角多样校准特性 [PDF](https://arxiv.org/pdf/2510.26441), [HTML](https://arxiv.org/abs/2510.26441)
### Authors
Shihab Aaqil Ahamed,Udaya S.K.P. Miriya Thanthrige,Ranga Rodrigo,Muhammad Haris Khan
### Background
测试时提示调优（TPT）已成为一种有前景的技术，用于在不依赖标记数据的情况下将大型视觉-语言模型（VLMs）适应未见任务。然而，文本特征间缺乏分散性可能损害校准性能，这引起了人们对VLMs的可靠性和安全性方面的担忧。当前的TPT方法主要集中在通过最大化平均文本特征分散性或施加正交性约束来优化提示的校准。但这些方法可能无法确保类间文本特征的最佳角分离度，这意味着忽视了角多样性的关键作用。因此，为了克服这一问题，本文提出了一种新颖的TPT框架，即A-TPT，通过最大化单位超球体上特征之间的最小角距离来鼓励规范化文本特征的分布的一致性。经过在不同数据集和模型 backbone 上的广泛实验证明，我们的方法在降低聚类平均校准误差方面始终优于领先的TPT方法，同时保持了相当高的准确率。我们展示了我们的方法在自然分布转移下的零样本校准性能更为优越，并且在医疗数据集上表现出良好的泛化能力。通过理论分析和实际实验，建立了A-TPT的合理性。这些结果表明，通过推广角多样性来实现分布良好的文本特征，可以显著提高VLM的校准效果。我们的代码将公开提供。
### Innovation
A-TPT引入了角多样性，通过最大化单元超球体上特征之间的最小米氏距离，以实现规范化文本特征分布的一致性。这种方法确保了类间文本特征的最佳角分离度，使得校准更为可靠和安全。A-TPT在多种数据集上超越了现有的TPT方法，在零样本场景下展示出优异表现，并在医疗数据集上的泛化表现良好。
### Conclusion
本文提出并验证了A-TPT这一新颖的TPT框架，通过突出角多样性的必要性，显著提高了视觉-语言模型在测试时的校准精度。我们的结果表明，通过优化文本特征之间的角多样性，可以实现更好的校准效果。我们通过广泛的实验分析和理论论证，证明了A-TPT的优越性，并将代码公开供研究者和开发人员使用。
## 457. `cs.CV` - CYPRESS: 基于普瑞西维（Prithvi）编码器的卫星感应作物产量预测 [PDF](https://arxiv.org/pdf/2510.26609), [HTML](https://arxiv.org/abs/2510.26609)
### Authors
Shayan Nejadshamsi,Yuanyuan Zhang,Shadi Zaki,Brock Porth,Lysa Porth,Vahab Khoshdel
### Background
准确及时的作物产量预测对于全球粮食安全和现代农业管理至关重要。传统方法往往缺乏精准农业所需的大规模和细粒度的扩展性。加拿大平原上的综合数据集表明，传统方法常常无法提供这样的能力。
### Innovation
该论文引入了CYPRESS（CYPRESS：基于普瑞西维（Prithvi）编码器的卫星感应作物产量预测）模型，这是一种设计用于高分辨率、单田块油菜产量预测的深度学习模型。CYPRESS 利用一个大规模地理空间基础模型（Prithvi-EO-2.0-600M）进行微调，并将其应用于连续回归任务，将多时相卫星图像转化为密集的像素级产量图。相比于现有的基于深度学习的产量预测模型，CYPRESS 在加拿大平原数据集上的性能更优，突显了基础模型微调在专门农业应用中的有效性。CYPRESS 提供连续、高分辨率的输出，为精准农业提供了更实用的工具，超越了传统的分类或县市级汇总方法。这项工作验证了一种将大规模地球观测与农田决策相衔接的新方法，提供了一种针对详细农业监测的可扩展解决方案。
### Conclusion
CYPRESS 通过结合大规模地球观测和农田决策，提供了一种可扩展的、细节化的农业监测方法，从而为精准农业提供了更有效的工具。
## 458. `cs.CV` - ResMatching: 通过指导条件流匹配实现噪声鲁棒的计算超分辨率 [PDF](https://arxiv.org/pdf/2510.26601), [HTML](https://arxiv.org/abs/2510.26601)
### Authors
Anirban Ray,Vera Galinova,Florian Jug
### Background
计算超分辨率（CSR）在荧光显微镜中的应用历史悠久，尽管这一问题本质上是病态的。核心问题是找到一种先验，利用它来推算出高分辨率显微图象中从未被低分辨率显微镜成像的频率。随着更先进的数据驱动机器学习技术的出现，可以学习更强的先验，因此CSR结果可以得到提升。本文回顾了这一背景，并指出在噪声较大时学习强先验更为困难，这也说明了研究的必要性。本文在BioSR数据集上使用了4种不同的生物结构来评估ResMatching方法，并将其结果与7种基准方法进行比较。
### Innovation
提出了ResMatching，一种新颖的CSR方法，使用了指导条件流匹配来学习改进的数据先验。该方法在4种不同的生物结构上进行了评估，并与多种基准方法进行了比较，展示了其在数据保真度和感知现实之间的最佳权衡。特别指出的是，ResMatching在难以学习强先验的情况下（如噪声较大时）表现尤为出色。该方法还演示了从隐式学习的后验分布中抽样的能力，以及该分布在所有测试用例中的校准情况，这为未来用户提供了像素级别的数据不确定性信息，从而引导用户拒绝不确定预测。
### Conclusion
通过ResMatching，作者展示了其方法在噪声鲁棒性、以及在困难情况下仍能保持较高的超分辨率效果。这种基于指导条件流匹配的CSR方法提供了一种新的方法来处理图像的超分辨率问题，并且可以帮助用户更加准确地辨别预测结果的可靠性。
## 459. `cs.CV` - PT-DETR: 基于部分感知细节聚焦的小目标检测 [PDF](https://arxiv.org/pdf/2510.26630), [HTML](https://arxiv.org/abs/2510.26630)
### Authors
Bingcong Huo,Zhiming Wang
### Background
无人驾驶飞行器（UAV）中的物体检测面临着复杂背景、严重遮挡、密集的小物体以及变化的光照条件等多种挑战。现有技术难以应对这些情况，特别是在小物体检测方面表现不佳。为了解决这些问题，本研究提出了基于RT-DETR的PT-DETR算法，专门针对UAV图像中的小物体检测。
### Innovation
本研究提出的方法主要包括：引入了部分感知细节聚焦（PADF）模块，以增强小物体的特征提取；设计了中值频率特征融合（MFFF）模块，以提高模型捕捉小物体细节和上下文信息的能力；引入了Focaler-SIoU，以增强模型的边界框匹配能力，增加其对小物体特征的敏感性，从而进一步提高检测的准确性和鲁棒性。相比RT-DETR，PT-DETR在VisDrone2019数据集上实现了较低的计算复杂度和较少的参数数量，同时检测精度提升了1.6%-1.7%。
### Conclusion
本研究提出的PT-DETR算法在VisDrone2019数据集上表现出色，检测精度和鲁棒性良好，且计算复杂度和参数数量较低，适用于小物体检测任务。
## 460. `cs.CV` - 从像素、点和提示到下一代融合和多模态大模型/视觉模型在自动驾驶中的物体检测 [PDF](https://arxiv.org/pdf/2510.26641), [HTML](https://arxiv.org/abs/2510.26641)
### Authors
Sayed Pedram Haeri Boroujeni,Niloufar Mehrabi,Hazim Alzorgan,Ahmad Sarlak,Mahlagha Fazeli,Abolfazl Razi
### Background
自主车辆（AVs）正在通过智能感知、决策和控制系统的发展重塑未来交通。然而，它们的成功取决于一个关键能力——在复杂和多模态环境中可靠地检测物体。尽管计算机视觉（CV）和人工智能（AI）领域的最新突破推动了显著的进展，但该领域仍面临知识碎片化的关键挑战，尤其是在多模态感知、上下文推理和协同智能方面。本文通过系统地回顾AV传感器的基本谱系（例如摄像头、超声波、激光雷达和雷达）及其融合策略，探讨了这些传感器在动态驾驶环境中的能力和局限性，以及它们与LLM/VLM驱动的感知框架的潜在集成。此外，文章还对EGO-VEHICLE、基础设施和合作数据集进行了结构化的分类，并对其数据结构和特性进行了交叉分析。
### Innovation
本文通过引入新兴的范式概念，如Vision-Language Models (VLMs)、Large Language Models (LLMs)和生成式AI，填补了知识碎片化的空白。本文关注的方法论涵盖了从2D和3D管道到混合传感器融合，特别是在基于Transformer的新兴方法方面。例如，Vision Transformers (ViTs)、大型和小型语言模型（SLMs）和VLMs驱动的方法受到了特别关注。通过整合这些视角，本文为当前能力、开放挑战和未来机遇提供了清晰的路线图。
### Conclusion
本文提供了一个综合的框架，总结了当前基于物体检测的能力、面临的开放挑战和未来的机会，特别聚焦于基于像素、点和提示的下一代融合和多模态大模型/视觉模型在AVs中的应用。
## 461. `cs.CV` - Emu3.5：原生多模态模型是世界学习者 [PDF](https://arxiv.org/pdf/2510.26583), [HTML](https://arxiv.org/abs/2510.26583)
### Authors
Yufeng Cui,Honghao Chen,Haoge Deng,Xu Huang,Xinghang Li,Jirong Liu,Yang Liu,Zhuoyan Luo,Jinsheng Wang,Wenxuan Wang,Yueze Wang,Chengyuan Wang,Fan Zhang,Yingli Zhao,Ting Pan,Xianduo Li,Zecheng Hao,Wenxuan Ma,Zhuo Chen,Yulong Ao,Tiejun Huang,Zhongyuan Wang,Xinlong Wang
### Background
论文介绍了Emu3.5，这是一个大规模的多模态世界模型，该模型具备跨视觉和语言预测下一个状态的能力。Emu3.5模型经过统一的下个标记预测目标进行端到端预训练，训练数据集包括互联网视频的序列帧和对话转录，包含超过10万亿个标记。模型能够自然处理混编的视觉语言输入并生成同样格式的输出。为了提高推理效率，论文提出了离散扩散适应（DiDA），可以将逐token解码变为双向并行预测，使每张图片的推理速度提高约20倍，同时保持性能不受影响。
### Innovation
1. Emu3.5模型经过大规模强化学习后训练，增强多模态推理和生成能力。2. 提出了离散扩散适应（DiDA），能够将逐token解码转换为双向并行预测，显著提高了推理效率。3. Emu3.5展示了强大的原生多模态能力，包括长时程视觉语言生成、任何到图像生成（X2I）以及复杂图文生成。4. 模型具有普适的世界建模能力，支持跨多种场景和任务的空间和时间一致性探索与开放环境中的物理操作。5. 在图像生成和编辑任务上，Emu3.5与Gemini 2.5 Flash Image（Nano Banana）的结果相当，并在一系列混编生成任务中表现出更优的结果。
### Conclusion
Emu3.5模型已经开源，可以支持社区研究。该模型的整体表现与领先的多模态模型相当，并在特定任务上显示出优越的能力，展示了其强大的多模态世界建模能力。
## 462. `cs.CV` - 钢铁轧制车间内实时故障预测的集成计算机视觉 [PDF](https://arxiv.org/pdf/2510.26684), [HTML](https://arxiv.org/abs/2510.26684)
### Authors
Vaibhav Kurrey,Sivakalyan Pujari,Gagan Raj Gupta
### Background
本文介绍了在钢铁轧钢机中基于机器视觉的异常检测系统的一项长期部署研究。该系统通过工业摄像头实时监控设备操作、对齐和热钢棒运动，在生产线上进行故障预测，从而降低非计划停机成本。
### Innovation
该系统利用深度学习模型在中央视频服务器上处理实时视频流，实现对设备故障和工艺中断的早期预测。基于服务器的推理减少了工业过程控制系统（PLC）的计算负担，支持生产线上的可扩展部署。系统结合分析数据采集系统的传感器数据和视觉输入，识别故障的位置和可能的原因，提供预防性维护的行动见解。
### Conclusion
这种集成方法提高了工业制造环境中操作的可靠性、生产率和盈利能力。
## 463. `cs.CV` - 通过场景上下文提高遮挡物体分类 [PDF](https://arxiv.org/pdf/2510.26681), [HTML](https://arxiv.org/abs/2510.26681)
### Authors
Courtney M. King,Daniel D. Leeds,Damian Lyons,George Kalaitzis
### Background
遮挡的存在对传统强大的物体识别算法构成了重大挑战。额外的信息来源能够显著减少由遮挡引起的错误。已知场景上下文有助于生物视觉中的物体识别。
### Innovation
本文提出了两种基于场景信息融合的技术，以增强现有的Region Proposal Network-Deep Convolutional Neural Network（RPN-DCNN）物体检测网络的鲁棒性。每种方法都提出了一种算法：一种在预测前进行操作，基于识别的背景场景选择定制的物体网络；另一种在检测后进行操作，将场景知识融合到RPN输出的初始物体分数中。
### Conclusion
该算法在具有部分遮挡的挑战性数据集上进行了测试，表明与基线方法相比，在召回率和精度方面都有所提高。实验还对比了多种针对遮挡处理的训练方法，发现使用被遮挡和未被遮挡的图像的组合进行训练的效果最佳。该方法是可解释的，可以轻松适应其他数据集，为未来的研究和实际应用提供了许多方向。
## 464. `cs.CV` - 3D高斯散射的影响与展望 [PDF](https://arxiv.org/pdf/2510.26694), [HTML](https://arxiv.org/abs/2510.26694)
### Authors
Bernhard Kerbl
### Background
自3D高斯散射(3DGS)提出以来，它迅速改变了3D场景表示的格局，激发了大量的相关研究。后续的研究工作包括对3DGS效率、可扩展性和实际应用性的改进。
### Innovation
该论文概述了3DGS引发的关键发展方向。其中包括使3DGS训练和渲染更加资源高效，向动态（或四维，4DGS）表示演进，以及更深入地探讨其外观建模和渲染过程背后的数学基础。此外，还探讨了将3DGS引入移动和虚拟现实平台的努力，其扩展到大规模环境的工作，以及使用前馈或分布式计算实现近实时辐射场重建的最新进展。
### Conclusion
这些发展表明，3DGS已经从一种突破性的表示方法演变成3D视觉和图形应用中的一种多功能和基础工具。
## 465. `cs.CV` - 在RADARSAT-2上实现北极可靠海冰漂流估算的深度学习光学流 [PDF](https://arxiv.org/pdf/2510.26653), [HTML](https://arxiv.org/abs/2510.26653)
### Authors
Daniela Martin,Joseph Gallego
### Background
海冰漂流的准确估算对于北极航行、气候研究和操作性预报至关重要。虽然计算机视觉中的光流技术已迅速发展，但它在地理物理问题和雷达散射计成像中的应用仍被广泛忽视。古典光流方法依赖复杂的数学模型和对运动的严格假设，这在复杂场景中限制了其准确性。最近基于深度学习的方法极大地提高了性能，并已成为计算机视觉的标准方法，推动了其在海冰漂流估算中的应用。
### Innovation
本文提出了首次针对RADARSAT 2雷达散射计海冰图像的大规模基准测试，使用光端点误差（EPE）和Flall指标与GNSS跟踪浮标进行评估。一些模型实现了小于1公里的准确性，这是与海冰运动的空间尺度以及北极航行要求相比较小的误差。结果显示，这些模型能够捕捉到一致的区域漂流模式，并且基于深度学习的光流方法（与古典方法相比显著提高了运动估计的准确性）可用于极地遥感。光学流能够产生连续的空间漂流场，为每个图像像素提供运动估算，而不是稀疏的浮标位置，为航行和气候建模提供了新的机会。
### Conclusion
基于深度学习的光流方法可以有效地转移至极地遥感，具有高精度和连续的运动估计，为北极海冰流转提供了新的研究和应用途径。
## 466. `cs.CV` - ChartAB：图表接地与密集对齐的基准 [PDF](https://arxiv.org/pdf/2510.26781), [HTML](https://arxiv.org/abs/2510.26781)
### Authors
Aniruddh Bansal,Davit Soselia,Dang Nguyen,Tianyi Zhou
### Background
图表在可视化、推理、数据分析以及人类之间的想法交流中扮演着重要角色。然而，现有的视觉-语言模型（VLMs）在图表细节感知上仍存在不足，难以从图表中提取精细结构。这些限制妨碍了模型在比较多个图表和推理它们之间的关系方面的能力。
### Innovation
该论文介绍了一个名为“ChartAlign基准（ChartAB）”的新颖基准，用于全面评估VLMs在图表接地任务中的表现，包括提取表格数据、定位可视化元素以及识别各种属性。ChartAB基准通过引入一种新颖的两阶段推理工作流，进一步评估模型在跨两个图表对齐和比较元素/属性的能力。
### Conclusion
对几种最近VLMs的评估分析揭示了它们在图表理解中的感知偏见、弱点、稳健性以及幻觉的新见解。这些发现强调了VLMs在图表理解任务中的细粒度差异，并指出了当前模型需要加强的具体技能。
## 467. `cs.CV` - 通过精心选择U-Net架构和损失函数，从RGB视网膜图像中超越现有技术的AMD区域估计 [PDF](https://arxiv.org/pdf/2510.26778), [HTML](https://arxiv.org/abs/2510.26778)
### Authors
Valentyna Starodub,Mantas Lukoševičius
### Background
年龄相关性黄斑变性（AMD）是导致60岁以上人群不可逆视力损害的主要原因。本研究旨在通过语义分割技术，提高对RGB视网膜图像中AMD病变的检测能力。研究使用了ADAM挑战的数据集作为基准，该挑战是目前最全面的关于RGB视网膜图像AMD检测的研究竞赛和开放数据集。研究的目的是改进语义分割模型的架构和训练管道，从而提高对不同AMD病变类型的多类别分割性能。
### Innovation
研究通过精心选择U-Net架构和损失函数来缓解类别不平衡，超越了现有的技术水平。研究评估并比较了几种方法，包括预处理技术、不同复杂度的编码器（骨干）深层网络类型，以及专用于缓解图像和像素级别类别不平衡的专业损失函数。研究最终配置的AMD检测框架在非侵入性RGB视网膜图像的不同AMD病变类型的多类别分割中优于所有之前的ADAM挑战提交结果。
### Conclusion
研究的最终配置的AMD检测框架在多类别分割中的表现优于所有之前的ADAM挑战提交结果，并公开了用于实验的源代码。
## 468. `cs.CV` - SteerVLM：通过轻量级激活引导实现视觉语言模型的稳健模型控制 [PDF](https://arxiv.org/pdf/2510.26769), [HTML](https://arxiv.org/abs/2510.26769)
### Authors
Anushka Sivakumar,Andrew Zhang,Zaber Hakim,Chris Thomas
### Background
当前，视觉语言模型（VLMs）在生成与指令一致的输出方面存在挑战。现有方法往往需要大规模修改模型权重或依赖于预提取的静态向量和手动调参，这限制了模型的精确控制和多功能性。此外，缺乏专门用于评估VLM引导技术的多模态数据集也阻碍了该领域的进一步发展。因此，本文提出了SteerVLM，一种轻量级的转向模块，旨在指导VLMs产生更符合所需指令的输出，并通过维度激活调节和跨层自适应引导来实现精确的输出控制。
### Innovation
SteerVLM模块通过学习配对提示的潜在嵌入，动态调整语言模态与图像上下文之间的激活连接。这种模块仅需要原VLM大小的0.14%的参数，并且不会修改模型权重，同时能够在不影响离目标任务性能的情况下实现复杂的输出语义的精细控制。SteerVLM可以通过维度激活调节和不需手动调参的自适应引导在各个层上工作。同时，该工作还引入了VNIA数据集，专门用于促进VLM引导技术的开发和评估，从而解决了现有方法存在的问题，提供了通过激活工程实现多模态模型控制的新方法。该工作在引导和幻觉缓解基准测试中优于现有技术，并提出了一种稳健的多模态模型控制解决方案。
### Conclusion
本文提出的SteerVLM轻量级转向模块为VLMs提供了一种有效且无需修改模型权重的方法，以实现复杂输出语义的精确控制。通过引入VNIA数据集，促进了VLM引导技术的发展和评估。实验结果表明，SteerVLM在引导和幻觉缓解方面优于现有技术，并为多模态模型控制提供了一种稳健的解决方案。
## 469. `cs.CV` - HEIR: 学习基于图的运动层次结构 [PDF](https://arxiv.org/pdf/2510.26786), [HTML](https://arxiv.org/abs/2510.26786)
### Authors
Cheng Zheng,William Koch,Baiang Li,Felix Heide
### Background
运动的层次结构在计算机视觉、图形学和机器人学等多个研究领域普遍存在，复杂的动力学通常由更简单运动组件间的协调交互产生。现有的建模方法大多依赖于手工定义或启发式的固定运动原型，这限制了它们在不同任务上的泛化能力。
### Innovation
本文提出了一种通用的基于数据的学习运动层次结构方法，能够直接从数据中学习具有结构和可解释性的运动关系。该方法采用基于图的层次结构表示观测到的运动，明确地将全局绝对运动分解为父代继承的模式和局部运动残差。通过图神经网络来计算学习到的父代-子代依赖关系。该方法在1D平移运动、2D旋转运动和使用高斯点云动态3D场景变形方面进行了评估，并取得了比基线方法更真实的变形效果。
### Conclusion
通过提供一种可适应、数据驱动的运动层次结构建模框架，本文的方法为广泛的动力学任务提供了通用的建模形式。实验结果表明，该方法在1D和2D情况下重建了运动的内在层次结构，并且在动态3D高斯点云场景变形方面生成了更真实且可解释的变形。
## 470. `cs.CV` - 扩展图像地理定位到大陆级别 [PDF](https://arxiv.org/pdf/2510.26795), [HTML](https://arxiv.org/abs/2510.26795)
### Authors
Philipp Lindenberger,Paul-Edouard Sarlin,Jan Hosang,Matteo Balice,Marc Pollefeys,Simon Lynen,Eduard Trulls
### Background
在全球范围内准确确定图像的具体地理位置仍然是一个未解决的挑战。传统的图像检索方法由于图像数量庞大（超过100万张）且覆盖不足而效率低下。虽然可扩展的解决方案涉及权衡：全球分类通常仅能提供粗略的结果（10公里以上），而地面与航空图像间的跨视图检索面临领域差距问题，多数研究集中在较小的区域上。
### Innovation
本文提出了一个混合方法，能够在大陆尺度上实现细粒度的地理定位。方法利用代理分类任务在训练期间学习丰富的特征表示，这些表示隐式地编码了精确的位置信息。这与地面图像嵌入相结合，以提高面对稀疏地面数据的鲁棒性。实验表明，本文方法在欧洲大部地区的数据上可以将68%以上的查询局部化到200米范围内。
### Conclusion
大规模评估证明，我们的方法能够在一个覆盖欧洲大部地区的数据集上将超过68%的查询细粒度定位到200米以内。代码已公开发布。
## 471. `cs.CV` - 通用运动生成的追求：数据、模型与评估 [PDF](https://arxiv.org/pdf/2510.26794), [HTML](https://arxiv.org/abs/2510.26794)
### Authors
Jing Lin,Ruisi Wang,Junzhe Lu,Ziqi Huang,Guorui Song,Ailing Zeng,Xian Liu,Chen Wei,Wanqi Yin,Qingping Sun,Zhongang Cai,Lei Yang,Ziwei Liu
### Background
尽管在标准基准上，3D人体运动生成（MoGen）领域取得了进展，但现有模型在泛化能力方面依然存在根本性的瓶颈。相比之下，邻近生成领域，尤其是视频生成（ViGen）已经展现出在建模人类行为方面的出色泛化能力，从而为MoGen提供了可借鉴的策略。
### Innovation
本文提出了一种综合框架，系统地将视频生成技术转移应用于运动生成的三大支柱：数据、建模和评估。首先是ViMoGen-228K，这是一种包括228,000个高质量运动样本的大规模数据集，结合了高保真光学MoCap数据、基于网页视频的语义标注运动和最先进视频生成模型生成的合成样本。此外，我们还提出了一种流匹配基础的扩散转换器ViMoGen，通过门控多模态条件统一MoCap数据和ViGen模型的先验信息，并开发了更为高效的ViMoGen-light，去除了视频生成依赖但仍保持强泛化能力。最后，我们提出了层次化基准测试MBench，用于细粒度的运动质量、提示保真度和泛化能力评估。
### Conclusion
广泛的实验表明，我们的框架在自动和人工评估中均显著优于现有方法。此外，代码、数据和基准测试将公开提供。
## 472. `cs.CV` - SEE4D：基于自回归视频填充的无姿态4D生成 [PDF](https://arxiv.org/pdf/2510.26796), [HTML](https://arxiv.org/abs/2510.26796)
### Authors
Dongyue Lu,Ao Liang,Tianxin Huang,Xiao Fu,Yuyang Zhao,Baorui Ma,Liang Pan,Wei Yin,Lingdong Kong,Wei Tsang Ooi,Ziwei Liu
### Background
当前的视频到4D方法通常需要手动标注相机姿态，这既耗时又脆弱，不适合野外视频。最近的方法通过战然后填充方法减轻了对姿态标签的需求，但这种方法中的轨迹到轨迹的表征仍然使相机运动与场景动态交织，增加了建模和推理的复杂性。
### Innovation
引入了SEE4D，这是一种无姿态，轨迹到相机框架，将显式的轨迹预测替换为对固定虚拟相机的渲染，从而将相机控制与场景建模分离。通过基于这种填充内核设计的时空自回归推理管道，SEE4D能够遍历虚拟相机样条线并扩展重叠窗口的视频，从而实现有界每步复杂性的协调生成。使用SEE4D方法在交叉视角视频生成和稀疏重建基准测试上进行了验证，结果表明这种方法在定量和定性评估中均优于基于姿态或轨迹条件的基线，推动了从常规视频中建模4D世界的实际应用。
### Conclusion
SEE4D实现了无姿态的4D生成，在跨视角视频生成和稀疏重建基准测试上表现优异，达到了更优的泛化能力和性能，促进了基于常规视频的4D世界建模的实际应用。
## 473. `cs.CV` - OmniX: 从统一的全景生成和感知到可图形化3D场景 [PDF](https://arxiv.org/pdf/2510.26800), [HTML](https://arxiv.org/abs/2510.26800)
### Authors
Yukun Huang,Jiwen Yu,Yanning Zhou,Jianan Wang,Xintao Wang,Pengfei Wan,Xihui Liu
### Background
目前常用的3D场景建设方式有两种：程序生成和2D提升。其中，基于全景的2D提升技术因利用强大的2D生成先验知识，能够生成沉浸式、真实的和多样性的3D环境而逐渐成为一种有前景的技术。这项工作旨在进一步推进这一技术，使其生成的图形质量适合用于物理基于渲染（PBR）、重新照明和模拟的3D场景。
### Innovation
本文的关键洞察是重新利用2D生成模型进行全景几何、纹理和PBR材料的感知。OmniX是一种通用且统一的框架，基于轻量级且高效的跨模态适配结构，它将2D生成先验用于广泛的全景视觉任务，包括感知、生成和完成。同时，还构建了一个大规模合成全景数据集，包含来自多样室内和室外场景的高质量多模态全景图像。
### Conclusion
广泛的实验表明，我们的模型在全景视觉感知和可图形化3D场景生成方面非常有效，并为沉浸式和物理真实性的虚拟世界生成开辟了新的可能性。
## 474. `cs.CV` - 视觉特征学习的遮蔽扩散captioning方法 [PDF](https://arxiv.org/pdf/2510.26799), [HTML](https://arxiv.org/abs/2510.26799)
### Authors
Chao Feng,Zihao Wei,Andrew Owens
### Background
本文提出了一种新的方法——条件遮蔽扩散语言模型（MDC），通过给图像添加标题来学习视觉特征。在训练过程中，每个图像-说明对中的文本标记以随机选择的比例被遮蔽，然后基于视觉特征的解码器被训练以重建原始文本。这种方法可以将学习到的视觉特征应用于下游视觉任务。文中指出，与自回归captioning相比，MDC方法中视觉学习信号的强度不依赖于每个标记在序列中的位置，这减少了对辅助目标的需求。实验证明，MDC方法在学术规模模型和数据集上与自回归和对比学习方法生成的视觉特征具有竞争力。
### Innovation
提出了一种新的机制——条件遮蔽扩散语言模型（MDC），该模型通过自动生成描述图像的语句来学习视觉特征。这种方法在训练中使用了遮蔽技术，并且解码器被训练来从视觉特征中重建原始文本。实验表明，MDC的方法增强了视觉特征学习的效率和灵活性，而不需要依赖于自回归captioning中的字位顺序依赖性。
### Conclusion
通过MDC方法学习到的视觉特征在多种学术规模的模型和数据集上的表现与自回归和对比学习方法相当。这种方法降低了对辅助目标的依赖，并展示了在不同视觉任务中应用的可能性。
## 475. `cs.CV` - 使用物理信息测试时自适应的组间多参数心脏MRI配准 [PDF](https://arxiv.org/pdf/2510.26022), [HTML](https://arxiv.org/abs/2510.26022)
### Authors
Xinqi Li,Yi Zhang,Li-Ting Huang,Hsiao-Huang Chang,Thoralf Niendorf,Min-Chi Ku,Qian Tao,Hsin-Jung Yang
### Background
多参数成像磁共振成像（MRI）已成为心脏组织表征的有效工具。然而，多参数图之间的对齐问题使得逐像素分析变得困难。
### Innovation
提出了一种通用的物理引导的深度学习模型，利用测试时自适应进行组图像配准，适用于从多种物理模型（例如T1映射模型和T2映射模型）获得的不同对比加权图像。该物理引导的自适应使用特定物理模型生成的合成图像作为配准参考，实现对各种组织对比度的归纳学习。
### Conclusion
该模型在健康志愿者的各种MRI序列验证中表现出色，证明了其对于多种图像对比度范围内的多模态配准的改进效果。
## 476. `cs.CV` - 视频模型作为零样本推理器是否准备就绪？使用MME-CoF基准的实证研究 [PDF](https://arxiv.org/pdf/2510.26802), [HTML](https://arxiv.org/abs/2510.26802)
### Authors
Ziyu Guo,Xinyan Chen,Renrui Zhang,Ruichuan An,Yu Qi,Dongzhi Jiang,Xiangtai Li,Manyuan Zhang,Hongsheng Li,Pheng-Ann Heng
### Background
近期的视频生成模型能够生成高保真的、时序连贯的视频，表明它们可能储存了大量的世界知识。此外，这些模型不仅在现实合成方面表现出色，还展露出视觉感知、建模和操控的新兴行为。然而，一个关键问题仍待解决：这些视频模型是否准备好用于复杂的视觉推理场景中的零样本推理？本文旨在通过实证研究探讨这一问题，重点关注Veo-3这一领先且流行模型。研究通过12个维度进行，涵盖空间、几何、物理、时间和具身逻辑，系统地辨别模型的优势和失败模式。为了确保研究的标准化，构建了MME-CoF基准，用于深入评估因果推理链（CoF）推理。
### Innovation
本文构建了一个名为MME-CoF的紧凑基准，用于深入和全面评估视频模型在因果推理链（CoF）上的推理行为。实验系统地考察了视频模型在短期空间一致性、精细的程度地关系、局部一致动态等方面的合理推理模式，但发现这些模型在这个问题上存在局限性，如长时因因果推理、严格几何约束和抽象逻辑。这些模型虽然不能独立作为零样本推理器，但可以作为一个互补的视觉引擎与专门的推理模型一起使用。
### Conclusion
当前视频模型在短期内空间一致性和细微的定位方面表现出鼓舞人心的推理模式，但在长时因果推理、严格的几何约束和抽象逻辑方面仍有限制。视频模型目前还不足以作为独立的零样本推理器，但展示了作为与专用推理模型互补的视觉引擎的潜力。
## 477. `cs.CV` - Metis-SPECS：通过自提取偏好冷启动解耦多模态学习 [PDF](https://arxiv.org/pdf/2510.25801), [HTML](https://arxiv.org/abs/2510.25801)
### Authors
Kun Chen,Peng Shi,Haibo Qiu,Zhixiong Zeng,Siqi Yang,Wenji Mao,Lin Ma
### Background
近年来，具有可验证奖励的强化学习（RL）推动了一类“MLLM-r1”方法的发展，这些方法将RL引入视觉语言模型。大多数具有代表性的范式从冷启动开始，通常使用监督微调（SFT）来初始化策略，再进行RL。但SFT在冷启动时的推理方式可能会导致指令风格的过度拟合，降低离域泛化能力，从而影响后续的RL表现。为了解决这一问题，作者从冷启动的训练方法和数据构建两个角度进行考察，并引入了通用因子（GF）系数来量化不同方法下的泛化能力。研究发现，基于偏好训练的方法比基于SFT的方法在冷启动时具有更好的泛化能力。基于此，作者提出了SPECS框架：自提取偏好冷启动框架。该框架通过自提取偏好数据对，避免依赖更大规模的教师模型或人工标注，并进行偏好训练，专注于学习浅层、可转移的表层形式标准（格式、结构、风格）而非记忆内容，最终将验证奖励传递给RL以获得深层次的推理结果。
### Innovation
提出了SPECS框架：自提取偏好冷启动框架。该框架通过自提取偏好数据对，避免依赖更大规模的教师模型或人工标注，并进行偏好训练。专注于学习浅层、可转移的表层形式标准，而非记忆内容，最终将验证奖励传递给RL以获得深层次的推理结果。实验结果表明，该框架在多个多模态基准数据集中表现出明显的优势，超过强基线，并显著提高了MEGA-Bench和MathVista的表现。额外的实验还表明，SPECS有助于减少区内“卡住”的情况，提高探索能力，稳定训练过程，提升性能天花板。
### Conclusion
实验结果显示，解耦学习框架在多个多模态基准数据集中表现出了持续的优势，相比于强基线模型，MEGA-Bench提高了4.1%和MathVista提高了12.2%。额外的实验表明，SPECS在减少区内“卡住”的情况、提升探索能力、稳定训练过程和提升性能天花板等方面都有显著贡献。
## 478. `cs.CV` - 在知识蒸馏背景下，学生模型是否能像教师模型一样去偏性？关于偏见缓解方法可蒸馏性的研究 [PDF](https://arxiv.org/pdf/2510.26038), [HTML](https://arxiv.org/abs/2510.26038)
### Authors
Jiali Cheng,Chirag Agarwal,Hadi Amiri
### Background
知识蒸馏（KD）是一种有效的模型压缩方法，通过将教师模型的知识传递给学生模型。然而，其对模型在应对数据分布外样本上的鲁棒性以及对虚假相关性的抵抗能力的影响还不是很明确。本文专注于研究知识蒸馏对学生模型和教师模型之间去偏性能力的传递影响，特别是在自然语言推理（NLI）和图像分类任务中的表现。研究发现在知识蒸馏后，去偏性能力会受到削弱；训练去偏性模型并不一定能够从中受益于教师知识的注入；尽管模型的整体鲁棒性可能保持稳定，但不同类型的偏见仍会导致显著差异；并且识别出导致知识蒸馏后不同行为的内部注意力模式和电路结构。
### Innovation
这是首次系统性研究知识蒸馏对去偏性效果的影响及其内部机制。研究提出了三种改进去偏性方法可蒸馏性的有效解决方案：高质量数据的增强、迭代的知识蒸馏和使用教师模型权重初始化学生模型。这些发现提供了对于知识蒸馏机制的理解以及如何设计更有效的去偏性方法的认知。
### Conclusion
本文通过广泛的实验揭示了知识蒸馏对模型去偏性能力的影响，提出了改进知识蒸馏中去偏性的有效方法，并总结了当前去偏性方法中可能的改进方向。
## 479. `cs.CV` - DARTS: 一种基于无人机的AI驱动实时交通事故检测系统 [PDF](https://arxiv.org/pdf/2510.26004), [HTML](https://arxiv.org/abs/2510.26004)
### Authors
Bai Li,Achilleas Kourtellis,Rong Cao,Joseph Post,Brian Porter,Yu Zhang
### Background
快速可靠地检测事故对于减少与事故相关的伤亡、伤害和拥堵至关重要。然而，传统的检测方法，如闭路电视、车载摄像头记录和基于传感器的检测，检测与验证分离，缺乏灵活性，并且需要密集的基础设施或高渗透率，从而限制了对事故热点的适应性和扩展性。为了克服这些挑战，我们开发了DARTS，一种基于无人机、配备了AI的技术实时交通事故检测系统。DARTS集成了无人机的高机动性和空中视角，进行适应性监控，使用热成像技术以提高低能见度性能和隐私保护，并采用轻量级深度学习框架实现实时车辆轨迹提取和事故检测。该系统在自收集的数据集上实现了99%的检测准确率，并支持同时在线的视觉验证、事故严重程度评估和事故引发的拥堵传播监控，通过基于网络的界面进行展示。在佛罗里达州75号州际公路的实地测试中，DARTS比当地交通管理中心提前12分钟检测并验证了一起追尾碰撞，并监测了事故引发的拥堵传播，表明它有可能支持更快的应急响应并允许主动交通控制以减少拥堵和二次事故风险。关键的是，DARTS的灵活部署架构减少了频繁物理巡逻的依赖性，显示出在偏远地区和资源有限环境中具有潜在的扩展能力和成本效益。
### Innovation
DARTS是一种基于无人机、配备了AI驱动技术的实时交通事故检测系统。它集成了无人机的高机动性和空中视角以实现适应性监控，使用热成像技术提升低能见度环境下的性能和隐私保护，并通过轻量级深度学习框架实现快速车辆轨迹提取和事故检测。该系统在自收集的数据集上实现了99%的高检测准确率，并支持实时的在线视觉验证、严重程度评估和事故引发的拥堵传播监控。此外，DARTS展示了灵活的部署架构，可以减少对频繁物理巡逻的依赖，从而具有扩展能力和成本效益，尤其适用于偏远和资源有限的区域。
### Conclusion
本研究提出了一种具有灵活性和集成特点的实时交通事故检测系统，具有显著的操作效率和响应性影响，旨在改善现代交通管理的运行效率和反应速度。DARTS在事故检测的准确性和灵活性方面取得了显著进步，为其在全球交通运输管理中的广泛部署奠定了基础。它展示出了在多样化的交通管理应用中提升有效性和成本效益的潜力。
## 480. `cs.CV` - StructLayoutFormer：通过结构序列化与分解实现的有条件结构化布局生成 [PDF](https://arxiv.org/pdf/2510.26141), [HTML](https://arxiv.org/abs/2510.26141)
### Authors
Xin Hu,Pengfei Xu,Jin Zhou,Hongbo Fu,Hui Huang
### Background
在2D视觉内容中（例如GUI、网页），结构化的布局有诸多优点，因为它们便于布局的编辑。现有的计算框架能够帮助创建结构化的布局，但通常需要大量的劳动投入。当前的数据驱动方法能够有效自动生成固定的布局，但难以生成布局结构。因此，研究者提出了一个基于Transformer的新颖方法——StructLayoutFormer，以实现有条件结构化布局的生成，并且生成的布局结构是具体的、实际的。研究团队通过包括结构提取的后处理方式，将他们的方法与现有的数据驱动布局生成方法进行了比较，实验结果表明他们的方法在有条件结构布局生成上超越了基线方法。此外，研究还展示了他们的方法在结构提取和转移上的效果。
### Innovation
该研究提出了一个基于Transformer的新型方法——StructLayoutFormer，用于有条件结构化布局的生成。它使用了结构序列化的方式表示有结构的布局，并通过分离结构信息与元素放置来更好地控制生成布局的结构。这种方法是第一种实现有条件结构化布局生成的数据驱动方法，能够生成详实的布局结构，且展示了在结构提取和转移上的有效性。
### Conclusion
广泛实验表明，与现有数据驱动的布局生成方法相比，StructLayoutFormer在有条件结构化布局生成上有更好的表现。此外，这种方法还能有效地提取和转移布局结构。研究团队已将代码公开提供。
## 481. `cs.CV` - SPG-CDENet: 空间先验引导交叉双编码器网络在多器官分割中的应用 [PDF](https://arxiv.org/pdf/2510.26390), [HTML](https://arxiv.org/abs/2510.26390)
### Authors
Xizhi Tian,Changjun Zhou,Yulin. Yang
### Background
多器官分割是计算机辅助诊断中一项关键任务。尽管最近的深度学习方法在图像分割方面取得了显著成功，但由于器官大小和形状的巨大变化，这些方法在多器官分割中的有效性受到挑战。
### Innovation
我们提出了一个带有空间先验引导的交叉双编码器网络（SPG-CDENet），这是一种改进多器官分割准确性的新颖两阶段分割范式。该网络由两种关键组件组成：空间先验网络和交叉双编码器网络。通过提出层次间对称交叉注意力模块来增强全局和局部编码器之间的交互，该模块在所有编码器层间融合和精炼特征，从而改进分割精度。此外，基于流的解码器直接从最终编码器层向所有解码器层传播高层语义特征，从而最大限度地保留和利用特征。
### Conclusion
在两个公开数据集上的广泛定性和定量实验结果表明，SPG-CDENet相比现有分割方法具有优越的性能。进一步的消融研究还验证了所提出模块在提高分割精度方面的有效性。
## 482. `cs.CV` - CorVS：在实际仓库中通过视频轨迹-传感器对应进行的人识别 [PDF](https://arxiv.org/pdf/2510.26369), [HTML](https://arxiv.org/abs/2510.26369)
### Authors
Kazuma Kano,Yuki Mori,Shin Katayama,Kenta Urano,Takuro Yonezawa,Nobuo Kawaguchi
### Background
工业场地的工人位置数据对于提高生产力至关重要。摄像头可以作为一种定位工具应用于物流仓库，因为它们也能提供有价值的工作环境信息，如包裹状态。然而，仅凭视觉数据很难识别个体。为此，先前的研究通过比较路径轨迹和穿戴传感器测量来识别人们。虽然这种方法不受外观限制，但现有的方法在实际条件下可能无法正常工作。因此，本文提出了一种名为CorVS的新方法，该方法基于视觉跟踪轨迹与传感器测量之间的对应关系，是一种数据驱动的人体识别方法。
### Innovation
提出的CorVS方法是一种数据驱动的识别方法，通过可视跟踪轨迹与传感器测量之间的对应关系来识别人员。方法包括：1) 使用深度学习模型预测每对轨迹和传感器测量之间的对应概率和可靠性；2) 使用预测得到的概率和可靠性，算法随着时间的推移匹配轨迹和传感器的测量。该方法通过对实际仓库操作建立的数据集进行了验证，证明了其在实际应用中的有效性。
### Conclusion
综上所述，CorVS方法提供了一种有效解决实际仓库中基于视频轨迹和传感器对应的人体识别方法，该方法能够在实际应用中改善人员管理效率，有助于提升仓库生产力。
## 483. `cs.CV` - 通过融合单目相机的全局和局部特征实现3D地图上的自我定位 [PDF](https://arxiv.org/pdf/2510.26170), [HTML](https://arxiv.org/abs/2510.26170)
### Authors
Satoshi Kikuch,Masaya Kato,Tsuyoshi Tasaki
### Background
在实现自动驾驶时，需要使用低成本的单目相机来进行自我定位。传统的基于相机的自我定位方法通常使用卷积神经网络（CNN），它可以提取由附近像素计算得到的局部特征。然而，在存在动态障碍物（如人）的情况下，CNN的效果并不理想。因此，本文探讨了一种将CNN与Vision Transformer结合的新方法，后者擅长提取描述整幅图像上块间关系的全局特征。实验结果显示，与现有的最佳方法相比，在包含动态障碍物的CG数据集中，该方法的准确性提高了1.5倍；在公开数据集中，该方法的自我定位误差比SOTA小20.1%；同时，使用该方法的机器人平均定位误差为7.51cm，比SOTA更准确。
### Innovation
提出的通过将卷积神经网络（CNN）与视觉变换器（Vision Transformer）结合的新方法，能够更好地提取全局特征，从而提高在存在动态障碍物情况下的自我定位准确性。实验表明，这种方法在包含动态障碍物的数据集中的准确性显著提高，并在公开数据集中的自我定位误差上优于当前的最佳方法。
### Conclusion
该方法通过融合全局和局部特征，显著提升了单目相机在动态环境中进行自我定位的效果，实验结果证明了其优越性。
## 484. `cs.CV` - AgriGS-SLAM: 利用多视图高斯点云SLAM在不同季节实现果园制图 [PDF](https://arxiv.org/pdf/2510.26358), [HTML](https://arxiv.org/abs/2510.26358)
### Authors
Mirko Usuelli,David Rapado-Rincon,Gert Kootstra,Matteo Matteucci
### Background
自主机器人在果园中需要对具有重复行几何形状、季节性外观变化和风驱动的树叶运动的3D场景进行实时理解。当前的3D场景理解方法难以在这些复杂条件下提供准确和稳定的结果，尤其是在果园环境中。因此，研究团队致力于开发一种新的视觉–LiDAR SLAM框架，该框架结合了直接LiDAR里程计、回环闭合以及多相机3D高斯点云渲染，并在真实的果园平台上进行了测试。
### Innovation
提出了AgriGS-SLAM框架，该框架将直接LiDAR里程计和回环闭合与多相机3D高斯点云渲染结合在一起。通过批量视角栅格化处理来恢复具有遮挡情况下的果园结构，并在关键帧之间执行统一的梯度驱动地图生命周期来保持细节并限制内存，同时利用基于概率的LiDAR深度一致性项来引导姿态精确定位，提高三维结构与外观之间的耦合性。该研究在不同季节和果园中进行了实际部署，展示了其在实时性与准确性方面的优势，同时适用于其他需要鲁棒多模态感知的户外领域。
### Conclusion
AgriGS-SLAM框架在不同季节和果园中能够提供更加锐利且稳定的3D重建结果和更加稳定的轨迹，同时保持了在收割机上的实时性能。这项研究为果园监控提供了有效的解决方案，并且该框架具有广泛的应用前景，可以应用于其他需要鲁棒多模态感知的户外环境。
## 485. `cs.CV` - SAMRI: Segment Anything Model for MRI [PDF](https://arxiv.org/pdf/2510.26635), [HTML](https://arxiv.org/abs/2510.26635)
### Authors
Zhao Wang,Wei Dai,Thuy Thanh Dao,Steffen Bollmann,Hongfu Sun,Craig Engstrom,Shekhar S. Chandra
### Background
准确的磁共振成像（MRI）分割对于临床决策至关重要，但手动执行时仍劳动密集。基于卷积神经网络（CNN）的方法可以准确且高效，但在适应MRI的可变对比度、强度不均匀性和协议上通常表现不佳。虽然基于Transformer的Segment Anything Model（SAM）在自然图像中表现出出色的泛化能力，但现有的适应方法通常将MRI视为另一种成像方式，而忽视了特定模态的挑战。
### Innovation
提出了一个针对MRI进行特殊训练和验证的SAM，名称为SAMRI。通过使用两阶段策略仅微调其掩码解码器来适应MRI，显著减少了训练时间和可训练参数。在多种MRI分割任务中，SAMRI实现了0.87的平均Dice值，展示了在不同解剖区域的顶级准确性和对未见过结构的鲁棒泛化，特别对小而临床重要的结构。
### Conclusion
SAMRI能够通过简单的微调策略的有效适应，显示出在MRI图像分割上的高准确性和泛化能力，特别是在处理小而临床重要的结构上表现突出。
## 486. `cs.CV` - 基于深度学习模型的橄榄树冠及阴影分割比较分析及其生物体积估算 [PDF](https://arxiv.org/pdf/2510.26573), [HTML](https://arxiv.org/abs/2510.26573)
### Authors
Wondimagegn Abebe Demissie,Stefano Roccella,Rudy Rossetto,Antonio Minnocci,Andrea Vannini,Luca Sebastiani
### Background
橄榄树生物体体积的估算在精准农业中扮演着关键角色，支持产量预测和资源管理，特别是在受到气候引起的压力严重影响的地中海地区。UAV获取的超高清图像用于橄榄树冠及阴影分割任务，并通过结合树冠投影面积和阴影推导出的高度来估算生物体体积。研究背景强调了对高精度分割模型的需求，因为它们能够提取有效空间特征并提供可靠的分割结果，在植被管理中有重要应用价值。
### Innovation
本文对比分析了三种深度学习模型（U-Net、YOLOv11m-seg 和 Mask R-CNN）在橄榄树冠及阴影分割中的性能，特别关注了它们在超高清UAV图像的分割任务上的表现，并提出了生物体体积估算的新方法，结合了树冠投影面积和阴影高度的估算。这项创新不仅提升了分区的准确性，还提高了模型的运行速度和鲁棒性，尤其是在大面积部署场景中的应用潜力。
### Conclusion
Mask R-CNN在整体精度上表现最佳（F1 = 0.86；mIoU = 0.72），而YOLOv11m-seg提供了最快的吞吐量（每张图像0.12秒）。所提出的方法可以在不需要额外支架的情况下估算从约4到24立方米的生物体体积，反映出树木之间的明显结构性差异。研究结果表明，Mask R-CNN适用于追求高精度的场景，YOLOv11m-seg适用于需要快速处理大量数据的场景，而U-Net则是一个轻量级且高灵敏度的选项。本框架能够实现准确、可扩展的果园监控，并通过DEM或DSM集成和田间校准进一步加强其实用性，以支持操作决策。
## 487. `cs.CV` - BRIQA: 平衡重权值的图像质量评估在儿科脑部MRI中的应用 [PDF](https://arxiv.org/pdf/2510.26661), [HTML](https://arxiv.org/abs/2510.26661)
### Authors
Alya Almsouti,Ainur Khamitova,Darya Taratynova,Mohammad Yaqub
### Background
在儿科脑部磁共振成像（MRI）中评估伪影的严重程度对于提高诊断准确性至关重要，特别是在低场系统中，信噪比较低。手动质量评估耗时且主观，因此需要稳健的自动解决方案。背景强调了当前方法的局限性和对更高效、客观的方法的需求。
### Innovation
本文提出了一种名为BRIQA（平衡重权值的图像质量评估）的新方法，该方法针对伪影严重程度类别不平衡的问题。BRIQA采用梯度基损失重新加权和旋转批量方案，在减少数据不平衡的同时，提高模型性能和泛化能力。创新点在于通过动态调整每个类别的贡献和促进类别间的平衡学习来提升模型在伪影分类任务中的表现。
### Conclusion
实验结果表明，结合旋转批量配置和交叉熵损失时，BRIQA方法在噪声、 zipper、定位、对比度、运动和条带伪影严重程度分类中表现出优异的性能，使平均宏F1分数从0.659提高到0.706，证明了该方法的有效性。代码可以在指定的链接处获取。
## 488. `cs.CV` - ProstNFound+: 一项使用医疗基础模型进行前列腺癌检测的前瞻性研究 [PDF](https://arxiv.org/pdf/2510.26703), [HTML](https://arxiv.org/abs/2510.26703)
### Authors
Paul F. R. Wilson,Mohamed Harmanani,Minh Nguyen Nhat To,Amoon Jamzad,Tarek Elghareb,Zhuoxin Guo,Adam Kinnaird,Brian Wodlinger,Purang Abolmaesumi,Parvin Mousavi
### Background
医学基础模型（FMs）为构建高性能的诊断系统提供了路径。然而，它们在微超声（μUS）中检测前列腺癌（PCa）的应用尚未在临床环境中进行测试。这项研究介绍了一种名为ProstNFound+的模型，它是一种针对μUS检测PCa进行适应的基础模型，同时阐述了第一个前瞻性验证。
### Innovation
ProstNFound+模型利用了医学基础模型、适配器调优和自定义提示编码器（该编码器嵌入了前列腺癌特定的临床生物标志物）。该模型生成癌症热图和显著前列腺癌的风险评分。模型在多中心回顾性数据上进行训练后，再对五年后从新临床站点获取的数据进行前瞻性评估。模型预测结果与标准临床评分协议（PRI-MUS和PI-RADS）进行了比较。
### Conclusion
结果表明，ProstNFound+模型在前瞻性数据上的性能与回顾性数据无显著下降，且与临床评分高度一致，生成的热图也与活检确认的病灶一致，突显了其临床应用潜力，提供了比专家驱动协议更具扩展性和解释性的替代方案。
## 489. `cs.CV` - 使用几何约束的世界模型克隆确定性3D世界 [PDF](https://arxiv.org/pdf/2510.26782), [HTML](https://arxiv.org/abs/2510.26782)
### Authors
Zaishuo Xia,Yukuan Lu,Xinyi Li,Yifan Xu,Yubei Chen
### Background
世界模型是一个内部模型，可以模拟世界如何演变。给定过去的观察和行动，它能够预测智能体及其环境的未来。准确的世界模型对于让智能体在复杂动态环境中思考、计划和有效推理至关重要。尽管取得快速进步，当前的世界模型在长时间跨度上仍然脆弱且易退化。
### Innovation
我们通过几何约束的方法提出了一种世界模型（Geometrically-Regularized World Models, GRWM），它使连续的自然感知轨迹上的点在潜变量空间中保持接近，从而得到了显著改进的、与环境真实拓扑结构密切吻合的潜变量表示。此方法简单易用，需要很少的架构修改，并且能够处理长轨迹，与各种潜变量生成模型兼容。实验证明，GRWM大大提高了滚动仿真精度和稳定性。
### Conclusion
研究结果表明，通过改进表示学习可以明显增强世界模型的鲁棒性，从而在不扩大动力学模块的情况下实现可靠的长范围预测。未来的工作可以进一步探索基于GRWM的思想来提升或者验证更复杂真实场景下的鲁棒性世界模型。
## 490. `cs.CV` - Quality-Aware Prototype Memory for Face Representation Learning [PDF](https://arxiv.org/pdf/2311.07734), [HTML](https://arxiv.org/abs/2311.07734)
### Authors
Evgeny Smirnov,Vasiliy Galyuk,Evgeny Lukyanets
### Background
Prototype Memory 是一种强大的面部特征表示模型，能够根据需要生成原型（分类器权重）并在训练过程中高效利用它们，从而允许在任何大小的数据集上训练面部识别模型。然而，这种生成原型的方法在处理低质量或难以识别的面部时存在缺陷，可能导致训练信号误导并降低训练模型的性能。
### Innovation
本文提出了一种新的策略，即质量感知原型记忆（Quality-Aware Prototype Memory），通过在生成原型时为不同质量的图像分配不同的权重，来改善原型记忆。这种改进使原型能够从高质量的图像中获得更有效的信号，而不受低质量图像的干扰。此外，作者还介绍了几种质量估计方法并进行了广泛实验，以证明与基础版Prototype Memory相比，提出模型的优越性。
### Conclusion
通过引入质量感知的方法，新的方法QPM在多个面部识别基准上显示出优于基本版本的Prototype Memory，从而提高了面部识别模型的性能。
## 491. `cs.CV` - MORE: 多器官医学图像重建数据集 [PDF](https://arxiv.org/pdf/2510.26759), [HTML](https://arxiv.org/abs/2510.26759)
### Authors
Shaokai Wu,Yapan Guo,Yanbiao Ji,Jing Tong,Yuxiang Lu,Mei Li,Suizhi Huang,Yue Ding,Hongtao Lu
### Background
CT重建为放射科医生提供了诊断和治疗所需的图像。然而，当前的深度学习方法通常仅限于特定的解剖部位和数据集，这限制了模型在未见过的解剖部位和病灶中的泛化能力。为解决这一问题，该研究引入了更名为‘多器官医学图像重建’(MORE)的数据集，该数据集包含了9种不同的解剖部位和15种病灶类型，旨在提供广泛和异质的数据以增强模型的泛化能力，并为医学图像重建的模型提供严格的评估标准。研究发现，全面的数据集有助于提高模型的泛化能力，并且基于优化的方法增强了对未见过解剖部位的鲁棒性。数据集已免费提供给公众访问。
### Innovation
该研究展示了MORE数据集，它是一个涵盖9种不同解剖部位和15种病灶类型的CT扫描数据集，旨在促进深度学习模型在医学图像重建中的泛化能力。相比于先前的方法，该研究还提出了一种更强基线解决方案，证明了全面的数据集和优化方法的重要性。数据集可免费获取，这对于推动医学图像重建领域的发展非常有价值。
### Conclusion
该研究通过提出MORE数据集，证明了广泛和异质数据对提高医学图像重建中深度学习模型的泛化能力的重要性，并且展示了基于优化的方法对于未见过解剖部位的增强鲁棒性。研究结果强调了MORE数据集在促进该领域研究和模型开发中的关键作用。
## 492. `cs.CV` - VerifIoU - 对象检测的鲁棒性验证 [PDF](https://arxiv.org/pdf/2403.08788), [HTML](https://arxiv.org/abs/2403.08788)
### Authors
Noémie Cohen,Mélanie Ducoffe,Ryma Boumazouza,Christophe Gabreau,Claire Pagetti,Xavier Pucel,Audrey Galametz
### Background
该研究旨在通过引入一种新颖的区间界限传播（IBP）方法来正式验证目标检测模型的准确性，特别是针对交并比（IoU）指标。现有的验证工具主要关注模型的准确性，但并未专门针对目标检测模型中的特定指标进行优化。
### Innovation
提出的IBP IoU方法旨在解决这一问题，它通过抽象解释基础工具实现，面向公开源代码工具包，特别是聚焦于提高目标检测模型在面对扰动时的鲁棒性，从而保证更高的准确性和稳定性。
### Conclusion
实验结果表明，IBP IoU在确保检测的准确性和稳定性方面优于基线（纯IBP IoU）方法，为更安全、更可靠的机器学习应用提供支持。该验证技术被应用于飞机着陆道检测和手写数字识别等实际案例，验证了其有效性。
## 493. `cs.CV` - 医疗报告生成中的动态回溯学习 [PDF](https://arxiv.org/pdf/2401.13267), [HTML](https://arxiv.org/abs/2401.13267)
### Authors
Shuchang Ye,Mingyuan Meng,Mingjian Li,Dagan Feng,Usman Naseem,Jinman Kim
### Background
自动化的医学报告生成已经展现出显著减少耗时医学报告工作的潜力。最近的生成表示学习方法在结合视觉和语言模态方面显示出潜力，可用于医学报告生成。然而，这些方法在端到端训练并直接应用于医学影像到文本生成时面临两个重大挑战：一是难以精确捕捉细微但至关重要的病理细节，二是推理过程中依赖视觉和文本输入，这会导致仅使用图像时的零样本推理性能下降。
### Innovation
本研究提出了一种新颖的多模态动态回溯学习框架（DTrace）。具体而言，引入了回溯机制以监督生成内容的语义有效性，并引入了一种动态学习策略，以适应不同比例的图像和文本输入，在推理过程中减少了对两者输入的强烈依赖。通过监督模型恢复互补对应物中的掩蔽语义信息来增强跨模态知识的学习。
### Conclusion
在两个基准数据集IU-Xray和MIMIC-CXR上进行的大量实验表明，提出的DTrace框架在医疗报告生成方面优于当前最先进的方法。
## 494. `cs.CV` - 两个头比一个头好：稳健学习与多分支模型相遇 [PDF](https://arxiv.org/pdf/2208.08083), [HTML](https://arxiv.org/abs/2208.08083)
### Authors
Zongyuan Zhang,Qingwen Bu,Tianyang Duan,Zheng Lin,Yuhao Qing,Zihan Fang,Heming Cui,Dong Huang
### Background
深度神经网络（DNNs）容易受到对抗样本的影响，这些对抗样本可以使DNN陷入错误的输出，这通常由于输入数据包含了无法察觉的扰动。对抗训练作为一种可靠且有效的防御方法，能够显著降低神经网络的脆弱性，并成为健壮学习的标准方法。现有的许多研究工作关注于数据本身的处理，例如如何生成更好的对抗样本或通过生成模型生成额外的训练数据。然而，该研究转向了模型本身，从深层特征分布的角度重新审视了对抗鲁棒性，作为对数据方法的一个补充。
### Innovation
提出了Branch Orthogonality adversarial Training（BORT），仅使用原始数据集进行对抗训练便能达到最佳性能。该研究设计了一个简单明了的多分支神经网络，通过分支正交损失函数使每个分支解决方案空间相互正交，并结合该多分支模型实现了对对抗攻击的超越，且不增加推理时间。
### Conclusion
该方法在CIFAR-10、CIFAR-100以及SVHN数据集上针对$l_{text{∞}}$范数限定的扰动ε=8/255表现优异，与最先进的方法相比，本文方法分别在CIFAR-10和CIFAR-100上实现了67.3%和41.5%的稳健准确率（分别提高了7.23%和9.07%），即使训练数据集规模远小于他者的方法，也实现了超越。
## 495. `cs.CV` - GSE: 组稀疏且可解释的对抗攻击 [PDF](https://arxiv.org/pdf/2311.17434), [HTML](https://arxiv.org/abs/2311.17434)
### Authors
Shpresim Sadiku,Moritz Wagner,Sebastian Pokutta
### Background
现有的稀疏对抗攻击通过最小的像素扰动使深度神经网络（DNNs）失效，并常使用$boldsymbol{text{textlq0}}$范数进行正则化。最新的努力用结构性稀疏正则化器，如核组范数，来代替$boldsymbol{text{textlq0}}$范数，从而生成组稀疏的对抗攻击，这样的扰动更具可解释性且在实际中有重要的应用价值，揭示了DNNs更大的脆弱性。然而，创建这样的攻击涉及非凸目标中的范数计算，是一个优化挑战。因此，论文提出了一种两阶段算法，在图像的语义有意义的区域生成组稀疏的对抗攻击。
### Innovation
提出了一种两阶段算法，在图像的语义有意义的区域生成组稀疏的对抗攻击。首先，使用为非凸编程定制的$boldsymbol{text{1}/{2-}}$次范数近似优化器来优化准范数对抗损失；随后，采用投影Nesterov加速梯度下降法，并应用2范数正则化来调整扰动幅度。通过CIFAR-10和ImageNet数据集的严谨评估，表明这种性能改进伴随着显著缩短的计算时间、提高的可解释性和百分百的成功攻击率，并且组稀疏度显著增加。
### Conclusion
实验结果表明，通过改进的算法生成的对抗攻击不仅组稀疏度显著提高，而且在计算时间、可解释性和攻击成功率方面均有所改进，尤其是针对CIFAR-10数据集的组稀疏度为50.9%，ImageNet数据集为38.4%（平均情况，针对目标攻击）
## 496. `cs.CV` - OnlyFlow：基于光学流的视频扩散模型运动条件 [PDF](https://arxiv.org/pdf/2411.10501), [HTML](https://arxiv.org/abs/2411.10501)
### Authors
Mathis Koroglu,Hugo Caselles-Dupré,Guillaume Jeanneret Sanmiguel,Matthieu Cord
### Background
研究了文本到视频生成任务，并且考虑了具备精确控制能力的应用场景，如相机移动控制和视频到视频编辑。大多数方法依赖用户定义的控制，例如二值掩码或相机移动嵌入。现有方法通常基于给定的初步控制条件下生成视频。
### Innovation
提出了一种名为OnlyFlow的方法，该方法利用从输入视频提取的光学流来条件控制生成视频的运动。通过结合文本提示和输入视频，OnlyFlow可以生成遵循输入视频的运动规律同时符合文本提示的内容。实验结果表明，OnlyFlow在多种应用任务中表现优于现有的先进方法，尽管它并非专门为这些任务进行特定训练。
### Conclusion
因此，OnlyFlow提供了一种通用、轻量级且高效的文本到视频生成中控制运动的方式。相关模型和代码将发布在GitHub和HuggingFace上。
## 497. `cs.CV` - EmoAttack: 基于情绪的情感引导扩散模型的生成 [PDF](https://arxiv.org/pdf/2406.15863), [HTML](https://arxiv.org/abs/2406.15863)
### Authors
Tianyu Wei,Shanmin Pang,Qi Guo,Yizhuo Ma,Xiaofeng Cao,Qing Guo
### Background
文本到图像的扩散模型可以根据文本输入生成逼真的图像，使用户能够通过语言传达视觉观点。在语言中，情绪在表达个人观点时起着关键作用。滥用恶意负面内容可能导致用户受到误导，加剧负面情绪。鉴于扩散模型的成功和情绪的重要性，研究指出文本到图像扩散模型中一个之前未被关注的风险：利用情绪控制输入文本生成负面内容，引起用户的不良情绪。在此背景下，我们提出了一个新的后门攻击方法——情感意识后门攻击(EmoAttack)，这种方法能够通过情绪触发输入文本中的恶意负面内容在图像生成中生效。我们将其作为一种扩散模型个性化问题进行建模，以避免大规模的模型重训练，并提出了一种名为EmoBooth的方法，该方法通过建立一组情绪词汇与含有恶意负面内容的参考图像之间的映射来微调预先训练好的扩散模型。我们通过构建数据集并进行了广泛的分析来验证这种方法的有效性。鉴于扩散模型的广泛应用，发现这一威胁对于社会来说至关重要。
### Innovation
本研究提出了一种新的后门攻击方法——情感意识后门攻击(EmoAttack)，该方法利用情绪控制输入文本生成负面内容，避免了大量的模型重训练，提出了一种名为EmoBooth的方法，通过建立情绪词汇与含有恶意负面内容的参考图像之间的映射来微调预先训练好的扩散模型。我们还构建了数据集来验证方法的有效性。
### Conclusion
在实现了大规模使用扩散模型的趋势下，发现潜在的风险如EmoAttack对于维持用户和社会的网络环境最为关键。提出的EmoBooth方法提供了有效的方法来识别和减轻这种威胁。
## 498. `cs.CV` - 使用静态表情数据理解动态表情：从静态到动态的研究 [PDF](https://arxiv.org/pdf/2409.06154), [HTML](https://arxiv.org/abs/2409.06154)
### Authors
Yin Chen,Jia Li,Yu Zhang,Zhenzhen Hu,Shiguang Shan,Meng Wang,Richang Hong
### Background
动态面部表情识别（Dynamic Facial Expression Recognition，DFER）是从面部表情随时间的变化中推断情绪，与仅依赖单张静态图片的静态面部表情识别（Static Facial Expression Recognition，SFER）不同。DFER通过时间分析提供更丰富信息，具有更高的识别能力，但由于当前DFER方法的训练样本较少，其性能不够理想。鉴于静态和动态表情之间的内在关联，论文提出利用大量的SFER数据来增强DFER的效果。
### Innovation
提出了一种名为S4D的统一双模态学习框架，该框架利用共享的Vision Transformer（ViT）进行双模态自监督预训练，以改进步骤和时空表示。此外，为了解决传统多任务学习中的负迁移问题，设计了一个名为Mixture of Adapter Experts（MoAE）的模块，该模块能够促进特定任务知识的学习，同时有效提取静态和动态表情数据中的共性知识。
### Conclusion
S4D框架在FERV39K、MAFW和DFEW基准上的性能超过现有最佳水平，分别实现了53.65%、58.44%和76.68%的加权平均召回率（WAR）。同时，还展示了SFER和DFER任务之间的系统关联分析，进一步揭示了利用SFER数据的潜在优势。
## 499. `cs.CV` - NerfBaselines: 一致且可再现的新型视图合成方法评估框架 [PDF](https://arxiv.org/pdf/2406.17345), [HTML](https://arxiv.org/abs/2406.17345)
### Authors
Jonas Kulhanek,Torsten Sattler
### Background
新型视图合成是一个重要的问题，广泛应用于AR/VR、游戏和机器人模拟等领域。由于最近Neural Radiance Fields (NeRFs)和3D Gaussian Splatting (3DGS)方法的快速发展，各种方法使用不同的评估协议，代码难以安装和使用，导致难以跟踪最新的技术水平。此外，这些方法在新3D场景上的泛化性能较差。我们发现不同的评估协议对方法性能的影响被夸大，这引起了文献中定量比较有效性的质疑。为了解决这些问题，我们提出了NerfBaselines，这是一个提供一致基准工具、保证可再现性和简化各种方法安装与使用的评估框架。我们通过实验验证了我们的实现，通过复现原始论文中报道的数字来验证NerfBaselines的有效性。为了提高可访问性，我们发布了网页平台，该平台在标准基准上比较常用方法。我们相信，NerfBaselines对社区的贡献是确保定量结果的可比性，从而真正衡量这一领域的进展。
### Innovation
NerfBaselines 提供了统一的基准工具，保证了评估的可再现性，简化了各种方法的安装和使用，通过复现原始论文中的结果验证其有效性，发布了网页平台比较常用方法在标准基准上的表现。
### Conclusion
NerfBaselines 是一个对社区有价值的贡献，确保了定量结果的可比性，帮助真正衡量新型视图合成领域的发展。
## 500. `cs.CV` - GameFactory: 创造新型游戏的生成性交互视频 [PDF](https://arxiv.org/pdf/2501.08325), [HTML](https://arxiv.org/abs/2501.08325)
### Authors
Jiwen Yu,Yiran Qin,Xintao Wang,Pengfei Wan,Di Zhang,Xihui Liu
### Background
生成视频有潜力通过自主创造新的内容来革新游戏开发。当前的许多方法在场景泛化动作控制方面存在欠缺。GameFactory框架旨在通过利用预训练的视频扩散模型的开放领域生成先验知识，并提出多阶段训练策略来解决这项挑战。
### Innovation
GameFactory框架包含以下几个创新点：1) GF-Minecraft数据集，不包含人类偏见的动作注解游戏视频数据集，以及动作控制模块，能够精确控制键盘和鼠标输入；2) 支持自回归生成无限制长度的交互视频；3) 解决场景泛化动作控制的关键挑战，这是大多数现有方法未能解决的；4) 利用预训练视频扩散模型的开放领域生成先验知识，结合多阶段训练策略和域适配器来克服开放领域先验与小规模游戏数据集之间存在的领域差距。
### Conclusion
实验结果表明，GameFactory能够有效生成开放领域动作可控的游戏视频，这是在AI驱动的游戏生成领域的重要一步。
## 501. `cs.CV` - UV-Attack: Physical-World Adversarial Attacks for Person Detection via Dynamic-NeRF-based UV Mapping [PDF](https://arxiv.org/pdf/2501.05783), [HTML](https://arxiv.org/abs/2501.05783)
### Authors
Yanjie Li,Kaisheng Liang,Bin Xiao
### Background
当前关于利用补丁或静态3D模型纹理修改对行人检测器进行的对抗攻击成功率很低，尤其是针对人类多变的肢体动作。动态 humans 的3D形变建模是一项巨大挑战。然而，神经辐射场(NeRF)的进步为动态人类建模提供了新机遇。尽管如此，动态 NeRF 模型虽然可以建模人类身体，但修改衣物纹理却很困难，因为这些纹理嵌入在神经网络的参数中。
### Innovation
UV-Attack 是一种采用动态 NeRF 基于 UV 映射的新颖方法，即使针对广泛且未见过的动作也能实现高成功率的对抗攻击。该方法通过生成 UV 映射而不是 RGB 图像，并修改纹理堆栈来处理这一挑战。此外，还提出了一种新的预期位置变换损失（EoPT）来提高未见过姿态和视角的攻击成功率。
### Conclusion
实验表明，UV-Attack 在动态视频设置中的不同姿态下对 FastRCNN 模型的攻击成功率达到了 92.7%，远超最先进的 AdvCamou 攻击。在黑盒检测器 YOLOv8 的攻击中，实现了 49.5% 的攻击成功率。这项工作展示了动态 NeRF 基于 UV 映射在行人检测器对抗攻击中的潜在应用价值，解决了建模人类运动和纹理修改的关键挑战。
## 502. `cs.CV` - CAUSAL3D：从视觉数据进行因果学习的综合基准 [PDF](https://arxiv.org/pdf/2503.04852), [HTML](https://arxiv.org/abs/2503.04852)
### Authors
Disheng Liu,Yiran Qiao,Wuche Liu,Yiren Lu,Yunlai Zhou,Tuo Liang,Yu Yin,Jing Ma
### Background
当前在人工智能和计算机视觉领域虽取得了显著进展，但缺乏评估模型通过复杂视觉数据推理潜在因果关系能力的基准。因此，亟需建立一个新的评估框架来评价模型的因果推理能力。
### Innovation
本文提出了Causal3D，这是一个新颖且全面的基准，将结构化数据（表格）与对应的视觉表示（图像）结合，用于评估因果推理能力。Causal3D采用了系统化的框架，包含19个3D场景数据集，涵盖了多样化的因果关系、视角和背景，使得可以对不同复杂度的场景进行评估。通过对最先进的方法（包括经典因果发现、因果表示学习和大型/视觉语言模型）进行评估，展示了随着因果结构变得复杂，无先验知识的模型性能显著下降，突显了复杂因果场景中的挑战。
### Conclusion
Causal3D作为关键领域内推动可信AI发展的宝贵资源，为计算机视觉中的因果推理研究提供了重要基准。
## 503. `cs.CV` - 一种 robust、连续且可解释的形态学用于动态生物形态的稳健量化 [PDF](https://arxiv.org/pdf/2410.21004), [HTML](https://arxiv.org/abs/2410.21004)
### Authors
Roua Rouatbi,Juan-Esteban Suarez Cardona,Alba Villaronga-Luque,Jesse V. Veenvliet,Ivo F. Sbalzarini
### Background
本文介绍了一种用于生物医学成像中形状量化的新方法——推前传递符号距离形态学（PF-SDM）。PF-SDM 通过紧凑的方式编码封闭形状的几何和拓扑特性，包括它们的骨架和对称性。这为形状对比和机器学习提供了稳健且可解释的特征。它还提供了光滑的数学基础，可以访问梯度和微分几何量，并能够进一步拓展到时间动态，同时允许融合时空强度分布，例如遗传标记与形状动力学的融合。
### Innovation
PF-SDM 提供了一种新的形态学方法，将其与现有的基于 CNN 的基线方法进行了比较，证明了其在准确性和速度上的优越性。该方法能够稳健地量化动态生物形状，并且提供连续且可解释的形状特征。
### Conclusion
本文提出了 PF-SDM，该方法在合成数据上的基准测试中表现良好，并成功地应用于小鼠 gastruloids 中身体轴形成的预测中，相较于 CNN 基线方法，表现出更高的准确性和速度。
## 504. `cs.CV` - 通过排斥视觉提示调校防范多模态被后门污染模型 [PDF](https://arxiv.org/pdf/2412.20392), [HTML](https://arxiv.org/abs/2412.20392)
### Authors
Zhifang Zhang,Shuo He,Haobo Wang,Bingquan Shen,Lei Feng
### Background
多模态对比学习模型（如CLIP）可以从大规模图像-文本数据集中学习高质量的表示，但它们对后门攻击表现出明显的脆弱性，这引起了严重的安全关注。研究人员发现，CLIP的这一漏洞主要来源于其编码特征远超出数据集内部预测模式的倾向，这削弱了其对抗输入扰动的视觉特征的抵抗力。这一特性使得其编码的特征容易被后门触发器改写。
### Innovation
本文提出了Repulsive Visual Prompt Tuning（RVPT），一种新颖的防御方法，通过深层视觉提示调校使用了特别设计的特征排斥损失。RVPT通过对抗性方式排斥来自深层层的编码特征，并优化标准交叉熵损失，以确保只有下游任务中的预测特征被编码，从而增强CLIP对抗输入扰动的视觉特征抵抗力，并减少了后门攻击的易感性。与通常需要毒化数据或对整个模型进行微调的现有方法不同，RVPT仅利用少量下游清洁样本，并且只调优少数参数。
### Conclusion
实验结果表明，RVPT仅调整了CLIP中0.27%的参数，但显著优于现有最先进的防御方法，将最先进的多模态攻击在ImageNet上的攻击成功率从89.70%降低到2.76%，并有效展示了其防御能力在多个数据集上的泛化能力。
## 505. `cs.CV` - Language-guided Open-world Video Anomaly Detection under Weak Supervision [PDF](https://arxiv.org/pdf/2503.13160), [HTML](https://arxiv.org/abs/2503.13160)
### Authors
Zihao Liu,Xiaoyu Wu,Jianqin Wu,Xuxu Wang,Linlin Yang
### Background
现有的视频异常检测（VAD）方法假设异常的定义是不变的，但在开放世界场景中，随着需求的变化，预期事件可能会发生变化。例如，在流感爆发期间不戴口罩可能被视为异常，但在其他情况下则可能是正常的。现有方法因此无法适用于开放世界。
### Innovation
论文提出了一种新的开放式VAD范式，允许通过用户提供的自然语言进行指导检测。此外，提出的模型LaGoVAD通过动态视频合成和对比学习增强了特征的鲁棒性，从而在弱监督下实现了动态适应异常定义。为了训练这样的可适应模型，论文还收集了一个名为PreVAD的大型多样化的视频异常数据集，其中包含了详细的异常定义。
### Conclusion
零样本实验在七个数据集上展示了LaGoVAD的SOTA性能。作者承诺将在该链接发布他们的数据集和代码：this https URL.
## 506. `cs.CV` - 基于自我监督的多染色肾小球分割方法以节省资源 [PDF](https://arxiv.org/pdf/2412.15389), [HTML](https://arxiv.org/abs/2412.15389)
### Authors
Zeeshan Nisar,Friedrich Feuerhake,Thomas Lampert
### Background
在计算机视觉领域，特别是在缺乏标签训练数据的情况下，跨域的语义分割仍然是一个基础挑战。特别是在组织病理学图像分析中更为突出，因为同样的组织结构需要在不同成像条件下（染料）的图像中进行分割，这些不同的成像条件代表了不同的视觉域。传统的深度学习方法，如UNet，需要大量的标签，这不仅成本高而且耗时，特别是在处理多个域（或染料）的情况下。为了减轻这一问题，已经提出了各种无监督域适应方法，如UDAGAN，这些方法减少了对标签的需求，只需一个（源）染料进行标记就足够了。然而，获取源染料的标签本身仍是一个挑战。本文表明，通过自我监督预训练——包括SimCLR、BYOL以及一种新颖方法HR-CS-CO——即使只有5%甚至95%的标签，这些分割方法（UNet和UDAGAN）的性能也能得到保留。在使用5%的标签时，性能下降很小：UNet的下降率为5.9%，UDAGAN的为6.2%，且这些发现可以在公共基准数据集上推广以验证结果的有效性。相关实现和预训练模型已公开并可在线访问。
### Innovation
文章提出了一种基于自我监督预训练的方法，通过SimCLR、BYOL以及一种新颖的HR-CS-CO方法，即使在标签数据稀少的情况下，也能保持UNet和UDAGAN的分割精度，对不同染料的性能影响较小。这种方法特别适用于组织病理学图像分析领域中的多染色对比，减少标签数据的需求，提高资源利用效率.
### Conclusion
通过自我监督预训练，即使仅使用少量标签或无监督的标签，也能保持原本需要大量有监督标签的方法（如UNet和UDAGAN）的高分割性能。这种方法为跨域语义分割，特别是在资源限制条件下，提供了一种实用有效的解决方案，并且已证明其在其他公共基准数据集上的有效性和可靠性。
## 507. `cs.CV` - LATex: 利用基于属性的文本知识进行空中-地面人员再识别 [PDF](https://arxiv.org/pdf/2503.23722), [HTML](https://arxiv.org/abs/2503.23722)
### Authors
Pingping Zhang,Xiang Hu,Yuhao Wang,Huchuan Lu
### Background
在智能交通系统中，Aerial-Ground 人再识别（AG-ReID）旨在跨不同视角的异构摄像头检索特定人员。现有方法通常采用基于深度学习的模型，专注于提取视角不变特征。然而，这些方法经常忽视人员属性中的语义信息。此外，现有的训练策略通常依赖于大型模型的全面微调，这显著增加了训练成本。
### Innovation
为了应对上述问题，我们提出了一种新颖的框架LATex，采用提示调优策略利用基于属性的文本知识。该框架首先通过CLIP模型提出了一种属性感知图像编码器（AIE），从输入图像中提取全局语义特征和属性感知特征。然后，使用这些特征提出了提示属性分类组（PACG），预测人员属性并获得属性表示。最后，设计了一种耦合提示模板（CPT），将属性表示和视图信息转换为结构化句子。这些句子由CLIP的文本编码器处理，生成更具辨别性的特征。因此，该框架可以充分利用基于属性的文本知识，以提高AG-ReID性能。
### Conclusion
在三个AG-ReID基准上的广泛实验表明，我们提出的框架在AG-ReID表现上具有有效性。源代码可在下列链接中获取。
## 508. `cs.CV` - Open3D-VQA: 开放空间中多模态大型语言模型全面空间推理基准 [PDF](https://arxiv.org/pdf/2503.11094), [HTML](https://arxiv.org/abs/2503.11094)
### Authors
Weichen Zhang,Zile Zhou,Xin Zeng,Xuchen Liu,Jianjie Fang,Chen Gao,Yong Li,Jinqiang Cui,Xinlei Chen,Xiao-Ping Zhang
### Background
多模态大型语言模型（MLLMs）在空间推理方面的表现已有初步探索，但在开放的空中环境中，其性能尚未被充分研究。本研究旨在通过引入一个新的基准testsuite，即Open3D-VQA，来评估这些模型在处理从空中视角出发的复杂空间关系时的能力。该基准包含73,000对多选题、真伪判断和简答题等形式的问题，并支持视觉和点云两种模态的数据输入。问题自动从真实和模拟空中场景的空间关系中生成。该基准覆盖了7个一般空间推理任务。
### Innovation
Open3D-VQA是一个新的基准，专门设计用于评估多模态大型语言模型在开放空中环境中的空间推理能力。它包括广泛的多选题、真伪判断和简答题类型的问题，涵盖7个空间推理任务。问题由真实和模拟空中场景的空间关系自动生成，支持视觉和点云数据输入。通过评判13种流行的大规模语言模型的表现，研究发现模型在相对空间关系上表现优于绝对距离。3D模型无法在空间推理上显现出显著的优势，单独在模拟数据集上进行微调可以显著提高模型在真实世界场景中的空间推理表现。此基准的发布包括数据生成管道和评估工具，以支持进一步研究。
### Conclusion
研究表明，多模态大型语言模型在开放天空环境中处理复杂空间关系的能力受到一定限制，并且模型性能可以通过特定的数据集微调得以改善。Open3D-VQA的发布旨在供进一步研究使用，以推动多模态语言模型空间推理能力的整体改进。
## 509. `cs.CV` - MindGYM：在注重思考能力的微调中，问题合成的关键要素？ [PDF](https://arxiv.org/pdf/2503.09499), [HTML](https://arxiv.org/abs/2503.09499)
### Authors
Zhe Xu,Daoyuan Chen,Zhenqing Ling,Yaliang Li,Ying Shen
### Background
大型基础模型在获取可迁移的、结构化的思考能力时面临挑战，特别是在使用严格的模板或众包注释指令数据集进行监督的情况下。以往的方法主要依赖于监督学习来生成数据，但这种方法可能限制了模型的思考能力和灵活性。这项研究关注于一种基于思考的数据合成范式，通过自我生成的认知引导数据使模型能够自主进化。与其他方法不同，该研究强调生成高质量、自包含的数据以支持有效的、以思考为基础的微调过程，从而提高模型的推理能力。
### Innovation
该研究提出了MindGYM，这是一种结构化、可扩展的问题合成框架，包含三个核心组成部分：(1)认知思维过程注入，通过注入高层次的推理目标来指导模型的数据合成行为；(2)种子单一跳问题合成，生成从多种语义类型中来的原子问题，以促进更广泛的思考；(3)具有挑战性的多跳问答合成，基于问答种子生成更复杂的多跳问题，以促进更深层的推理。研究结果表明，通过该方法生成的合成数据在平均质量和质量波动方面分别比基线来源提高了16.7%和降低了67.91%，强调了高质量和自包含数据对于有效、以思考为基础的微调的重要性。此外，MindGYM 改善了六项推理基准，仅使用400个数据样本就实现了高达16%的性能提升，且在不同模型大小和架构下具有广泛的应用范围，证明了自我挑战机制在大型模型能力提升中的可行性，同时减少了对人工干预和资源需求的依赖。
### Conclusion
MindGYM框架通过生成高质量、自包含的数据和促进模型的深层次推理来提升了大型基础模型的性能。该研究强调，利用模型内部推理能力驱动自我进化的数据为中心方法是研究自适应基准模型的有效途径。
## 510. `cs.CV` - 利用视频语言模型赋能自主视频分析系统 [PDF](https://arxiv.org/pdf/2505.00254), [HTML](https://arxiv.org/abs/2505.00254)
### Authors
Yuxuan Yan,Shiqi Jiang,Ting Cao,Yifan Yang,Qianqian Yang,Yuanchao Shu,Yuqing Yang,Lili Qiu
### Background
AI驱动的视频分析在多个领域变得越来越重要，但现有的系统通常局限于特定的预定义任务，限制了它们在开放式分析场景中的适应性。最近，视觉语言模型（VLMs）作为变革性技术的出现，为开放性视频理解、推理和分析提供了巨大潜力。然而，它们有限的上下文窗口在处理超长视频内容时存在挑战，而这种类型的视频在实际应用中非常普遍。
### Innovation
本文介绍了一种基于视觉语言模型的系统AVA，用于开放式、高级视频分析。该系统包含两项创新：1) 实时构建事件知识图谱（EKGs），用于高效索引长或连续的视频流；2) 一种代理检索-生成机制，利用EKGs处理复杂的和多样的查询。AVA已经在公共基准测试LVBench和VideoMME-Long上进行了全面评估，表现出优越的性能。此外，为了评估超长和开放世界的视频分析，还引入了新的基准AVA-100，包括8个超过10小时的视频和120个手动标注的、多样和复杂的问题-答案对，AVA在这些基准测试中表现优异。
### Conclusion
AVA系统在公共基准测试中表现出最先进的性能，特别是在AVA-100基准上，其准确率达到了75.8%，并在开源代码实现和基准测试数据集上均有提供。
## 511. `cs.CV` - DOVE: 实用的一步扩散模型用于视频超分辨率 [PDF](https://arxiv.org/pdf/2505.16239), [HTML](https://arxiv.org/abs/2505.16239)
### Authors
Zheng Chen,Zichen Zou,Kewei Zhang,Xiongfei Su,Xin Yuan,Yong Guo,Yulun Zhang
### Background
扩散模型在现实世界的视频超分辨率（VSR）中表现出色，但由于它们需要几十个采样步骤，推断速度非常慢。虽然单步采样加速技术提供了一种潜在解决方案，但在视频超分辨率中实现单步仍然是一个挑战，因为需要在视频数据上进行高强度的训练，并且有较高的保真度需求。
### Innovation
我们提出了一种名为DOVE的高效一步扩散模型，用于现实世界的VSR。DOVE通过微调预先训练的视频扩散模型（即CogVideoX）获得。为了有效训练DOVE，我们引入了隐含像素训练策略。该策略采用了两阶段方案，逐渐使模型适应视频超分辨率任务。同时，我们设计了一个视频处理管道，构建了一个高质量的数据集，称为HQ-VSR，用于VSR任务。通过对该数据集进行微调进一步增强了DOVE的恢复能力。
### Conclusion
广泛的实验表明，DOVE在性能上可以与多步扩散型VSR方法相媲美或更好。此外，它还提供了出色的推理效率，比现有的方法如MGLD-VSR快28倍。代码可从此链接获取：this https URL。
## 512. `cs.CV` - SD-ReID: 视觉意识稳定的扩散用于航拍-地面人员再识别 [PDF](https://arxiv.org/pdf/2504.09549), [HTML](https://arxiv.org/abs/2504.09549)
### Authors
Yuhao Wang,Xiang Hu,Lixin Wang,Pingping Zhang,Huchuan Lu
### Background
航拍-地面人员再识别（AG-ReID）的目标是从不同视角的摄像头中检索特定人员。以往的工作主要集中在设计能够保持身份连续性的区分模型，以应对视角的大幅变化。这些方法的核心思想非常自然，但设计一个能够抵抗视角变化的模型是非常具有挑战性的。此外，它们忽略了视特异性特征对提升模型表示人员能力的贡献。为了解决这些问题，我们提出了一个新颖的生成式框架SD-ReID，该框架利用生成模型来模仿不同视角下的特征分布，同时提取稳健的身份表示。首先训练一个基于ViT的模型来提取包含可控制条件（包括身份和视角条件）的人员表示。然后，通过这些可控制条件来细化人员表示。最后，引入了视细化解码器（VRD）来弥合细粒度特征和全局特征之间的差距。最终，利用人员表示和所有视角特征进行目标人员检索。
### Innovation
我们提出了一种新颖的生成式框架SD-ReID，它利用生成模型模仿不同视角下的特征分布，同时提取稳健的身份表示。首先训练一个基于ViT的模型来提取包含可控制条件的人员表示，然后通过这些可控制条件来精细化人员表示。引入视细化解码器（VRD）来弥合细粒度特征和全局特征之间的差距。
### Conclusion
我们在五个AG-ReID基准数据集（即CARGO、AG-ReIDv1、AG-ReIDv2、LAGPeR和G2APS-ReID）上进行了广泛的实验，表明我们提出的方法的有效性。源代码将会公开。
## 513. `cs.CV` - 通过调节大规模激活释放扩散变换器在视觉对应中的潜力 [PDF](https://arxiv.org/pdf/2505.18584), [HTML](https://arxiv.org/abs/2505.18584)
### Authors
Chaofan Gan,Yuanpeng Tu,Xi Chen,Tieyuan Chen,Yuxi Li,Mehrtash Harandi,Weiyao Lin
### Background
预训练的稳定扩散模型（SD）已经在视觉对应方面取得了巨大进步。本文研究了扩散变换器（DiTs）在准确密集对应方面的能力。然而，与SD不同，DiTs表现出一种关键现象，即非常少数的特征激活值远大于其他特征的激活值，这种情况称为“大规模激活”，导致缺乏信息的表现和DiTs的显著性能下降。大规模激活集中在固定维度上，这些维度几乎不含局部信息。因此，作者探索了通过调节这些大规模激活来提升DiTs性能的可能性。
### Innovation
本文提出的扩散变换器特征（DiTF）是一个无需训练的框架，旨在从DiTs中提取语义区分特征。DiTF通过AdaLN（自适应层归一化）来适应性地定位并以通道级调节的方式归一化大规模激活。此外，还提出了一种通道丢弃策略，以进一步消除大规模激活的负面影响。实验结果表明，DiTF在视觉对应任务中优于DINO和基于SD的模型，并在不同视觉对应任务中建立了新的SOTA性能（例如，在Spair-71k和AP-10K-C.S.上分别提高了9.4%和4.4%）。
### Conclusion
本文通过分析和调控DiTs中的大规模激活现象，提出了一种新的提取特征的方法DiTF，显著提升了DiTs在视觉对应任务中的性能。
## 514. `cs.CV` - Ditch the Denoiser: Emergence of Noise Robustness in Self-Supervised Learning from Data Curriculum [PDF](https://arxiv.org/pdf/2505.12191), [HTML](https://arxiv.org/abs/2505.12191)
### Authors
Wenquan Lu,Jiaqi Zhang,Hugues Van Assel,Randall Balestriero
### Background
自监督学习（SSL）已成为从未标记数据中提取丰富表示的强大解决方案。尽管如此，SSL研究主要集中在清洁、精心整理和高质量的数据集上。因此，在噪声数据上的应用（如天文学、医学成像、地球物理或金融）仍然是一个挑战。
### Innovation
该研究提出了一种完全自监督框架，能够在无需推理阶段使用去噪器或下游微调的情况下，进行噪声鲁棒表示学习。方法首先在噪声数据上训练一个SSL去噪器，然后用它来构建一个去噪到噪声数据的课程（即，先训练去噪数据，再训练噪声数据），用于预训练SSL骨干（如DINOv2），并结合教师引导正则化来使无噪声嵌入锚定到其去噪声版本。去噪器可以在预训练后丢弃，简化部署。
### Conclusion
在ImageNet-1k数据集上使用ViT-B和极端高斯噪声（$boldsymbol{boldsymbol{boldsymbol{boldsymbol{boldsymbol{boldsymbol{boldsymbol{boldsymbol{theta}theta}theta}theta}}}}boldsymbol{boldsymbol{boldsymbol{boldsymbol{boldsymbol{boldsymbol{boldsymbol{boldsymbol{theta}theta}}}}theta}theta}theta}boldsymbol{boldsymbol{theta}theta}boldsymbol{theta}boldsymbol{theta}}boldsymbol{theta}theta}theta})的情况下，该方法在DINOv2上提高了线性探查准确性4.8%，证明了噪声感知预训练可以从无去噪器的鲁棒性中产生。
## 515. `cs.CV` - 学习交互式视频生成的世界模型 [PDF](https://arxiv.org/pdf/2505.21996), [HTML](https://arxiv.org/abs/2505.21996)
### Authors
Taiye Chen,Xun Hu,Zihan Ding,Chi Jin
### Background
交互式视频生成需要具备互动性和空间时间一致性，以支持未来的有效规划和决策。然而，现有用于长视频生成的模型在世界建模能力上存在限制，主要由于累积误差和缺乏记忆机制两方面的挑战。
### Innovation
本文通过增加动作条件和自回归框架，增强了图像到视频模型的互动能力，并揭示了自回归视频生成中累积误差无法内在地减少，缺乏记忆机制导致世界模型的一致性差。提出了视频检索增强生成(VRAG)，通过显式的全局状态条件显著降低了长期累积误差，增加了世界模型的空间时间一致性。并且表明当前视频模型在上下文学习能力有限的情况下，简单的自回归生成和检索增强生成相对不太有效。
### Conclusion
本文揭示了视频世界模型的基本挑战，并为改善具有内部世界建模能力的视频生成模型建立了一个全面的基准。
## 516. `cs.CV` - Paper2Poster: 从科学论文到多模态海报的自动化 [PDF](https://arxiv.org/pdf/2505.21497), [HTML](https://arxiv.org/abs/2505.21497)
### Authors
Wei Pang,Kevin Qinghong Lin,Xiangru Jian,Xi He,Philip Torr
### Background
学术海报生成是一个关键但具有挑战性的科学交流任务，需要将长篇文档中的上下文内容压缩到一张视觉得到统一的页面上。现有的工具和方法无法全面解决这一挑战，特别是在视觉质量和内容传达上的统一性方面存在不足。
### Innovation
本文介绍了第一个用于海报生成的基准和评估指标套件，结合近期的会议论文和作者设计的海报进行评估，指标包括视觉质量、文本连贯性、整体评估以及新提出的PosterQuiz评估方法。此外，还提出了PosterAgent，一种自上而下的视觉集成多智能体管道，包括解析器、规划者和绘图评论者循环，三者协同工作，以实现从论文到海报的自动化生成，并通过全面评估发现开源变体在几乎所有指标上都优于现有系统，同时显著降低了所需令牌数量，实现了高成本效益。
### Conclusion
这些发现为未来完全自动化的海报生成模型指明了明确的方向。开源代码和数据集可以在指定链接处获得。
## 517. `cs.CV` - StyleGuard: 通过风格扰动防止基于文本到图像模型的风格模仿攻击 [PDF](https://arxiv.org/pdf/2505.18766), [HTML](https://arxiv.org/abs/2505.18766)
### Authors
Yanjie Li,Wenxuan Zhang,Xinqi Lyu,Yihao Liu,Bin Xiao
### Background
近年来，通过DreamBooth和Textual Inversion等方法，文本到图像的扩散模型被广泛用于风格模仿和个性化定制，但这引起了知识产权保护和生成误导性内容的担忧。最近的研究，如Glaze和Anti-DreamBooth，提出了使用对抗噪声来保护图像免受这些攻击的方法。但最近基于净化的方法，如DiffPure和Noise Upscaling，成功地攻击了这些最新防御，显示出这些方法的脆弱性。此外，当前方法在模型间传输能力有限，对未知的文本到图像模型效果较差。
### Innovation
提出了一种新颖的对抗模仿方法StyleGuard。提出了一种新颖的风格损失，该损失优化了潜空间中的风格相关特征，使其偏离原始图像，从而提高了模型无关的传输能力。设计了一种新颖的放大损失，涉及在训练期间使用集成净化器和放大器，以增强扰动避开基于扩散的净化的能力。实验表明，StyleGuard在各种变换和净化中具有更强的鲁棒性，并有效对抗各种模型中的风格模仿。StyleGuard对包括DreamBooth和Textual Inversion在内的不同风格模仿方法也有效。
### Conclusion
在WikiArt和CelebA数据集上的广泛实验表明，StyleGuard在对抗各种变换和净化方面优于现有方法，有效对抗各种模型中的风格模仿。此外，StyleGuard对不同的风格模仿方法（包括DreamBooth和Textual Inversion）都有效。代码可在该链接处获得。
## 518. `cs.CV` - LODGÉ：高效渲染的大规模层次细节高斯点云渲染方法 [PDF](https://arxiv.org/pdf/2505.23158), [HTML](https://arxiv.org/abs/2505.23158)
### Authors
Jonas Kulhanek,Marie-Julie Rakotosaona,Fabian Manhardt,Christina Tsalicoglou,Michael Niemeyer,Torsten Sattler,Songyou Peng,Federico Tombari
### Background
随着移动设备对3D渲染能力的需求日益增加，需要一种可以在限制内存的情况下实现高速实时渲染的大规模3D场景的技术。
### Innovation
提出了一种基于层次细节的高斯点云渲染方法，通过深度感知的3D平滑滤波、基于重要性的剪枝和微调，构建多层次的表示形式，并通过场景分区动态加载相关高斯点，结合不透明度混合机制来减少内存开销和视觉伪影。
### Conclusion
该方法在室外（Hieroarchical 3DGS）和室内（Zip-NeRF）数据集上均达到了最先进的性能，实现了高质量的渲染，同时显著减少了延迟和内存需求。
## 519. `cs.CV` - MoralCLIP：基于道德基础理论的视觉-语言表示对比对齐 [PDF](https://arxiv.org/pdf/2506.05696), [HTML](https://arxiv.org/abs/2506.05696)
### Authors
Ana Carolina Condez,Diogo Tavares,João Magalhães
### Background
近期视觉-语言模型在多模态语义理解方面取得了显著进展，但这些模型缺乏解析和推理内容道德维度的能力，这是人类认知的一个关键方面。为此，本文通过引入基于道德基础理论（MFT）的MoralCLIP，填补了这一空白，尝试将道德语义明确地融入跨模态表示学习中，改善了单一模式和多模态道德内容的理解
### Innovation
本文提出了一种新的MoralCLIP模型，通过MFT引入了显性的道德指导，将视觉和文本中的道德线索整合到统一的嵌入空间中，实现了跨模态道德对齐。研制了一种道德数据增强策略，将标注数据扩展到了15,000个图像-文本对，并且标注了MFT对齐的维度，以此来训练改进模型，这显著提升了对道德内容的理解和识别能力
### Conclusion
实验结果表明，明确的道德监督不仅能提高单模态和多模态对道德内容的理解，还为构建具备道德意识的人工智能系统奠定了基础，这些系统不仅能识别，而且能与人类的道德价值观保持一致。
## 520. `cs.CV` - GenIR：用于心智图像检索的生成视觉反馈 [PDF](https://arxiv.org/pdf/2506.06220), [HTML](https://arxiv.org/abs/2506.06220)
### Authors
Diji Yang,Minghao Liu,Chung-Hsiang Lo,Yi Zhang,James Davis
### Background
视觉-语言模型（VLMs）已经在文本到图像检索基准测试中表现出色，但在将这些成功应用到实际生活中仍面临挑战。在实践中，用户通常不会一次性完成搜索行为，而是一个多轮次、基于心理线索的过程，从模糊的记忆到具体的想象。当前的方法依赖于间接或抽象的文字反馈，这种方式对于用户来说可能不够明确、易误导或者无用。因此，需要一种新的方法来提供更有效的视觉反馈。
### Innovation
本研究提出了GenIR，这是一种利用基于扩散的图像生成技术的生成方式多轮次检索范式，可以在每轮次中公开展示AI系统的理解。这种方法提供了一种明确、可解释的反馈，能够帮助用户直观、有效地调整查询。此外，研究还提出了一个全自动的管道来生成高质量的多轮次心智图像检索数据集。
### Conclusion
实验结果表明，GenIR在心智图像检索场景中显著优于现有的交互式方法。这项工作确立了一个新的任务、数据集和有效的生成检索方法，为在此方向上的未来研究奠定了基础。
## 521. `cs.CV` - RRCANet: Recurrent Reusable-Convolution Attention Network for Infrared Small Target Detection [PDF](https://arxiv.org/pdf/2506.02393), [HTML](https://arxiv.org/abs/2506.02393)
### Authors
Yongxian Liu,Boyang Li,Ting Liu,Zaiping Lin,Wei An
### Background
红外小目标检测因目标小、暗、形状不固定且多变的特性而成为一个挑战性任务。最近，基于CNN的方法虽然通过复杂的特征提取和融合模块已经实现了令人鼓舞的性能，但仍需更高效的检测方法来保持检测效率和提高性能。
### Innovation
提出了一种循环可复用卷积注意力网络（RRCA-Net），其中集成了循环方式下的可复用卷积块（RuCB）不会引入额外的参数。通过RuCB的重复迭代，深层网络中目标的高层次信息能够得到良好维护并进一步精炼。此外，提出了一种双向交互注意力聚合模块（DIAAM），促进精炼信息的相互增强和融合。同时设计了一种目标特征启发式损失函数（DpT-k loss），结合物理和数学约束以实现稳定的收敛。
### Conclusion
在三个基准数据集（例如NUAA-SIRST、IRSTD-1k、DenseSIRST）上的实验结果表明，我们的RRCA-Net在保持较少参数数量的情况下能够达到与最先进的方法相当的性能，并且可以作为一个即插即用模块，为多个流行模型提供一致的性能提升。
## 522. `cs.CV` - 在上下文中共预测任何行人类轨迹 [PDF](https://arxiv.org/pdf/2506.00871), [HTML](https://arxiv.org/abs/2506.00871)
### Authors
Ryo Fujii,Hideo Saito,Ryo Hachiuma
### Background
预测行人未来的精确轨迹对于自主系统至关重要，但这一任务由于需要在不同环境和领域中具备适应性而变得极具挑战性。常见的方法通常需要收集特定场景的数据，并通过反向传播进行微调。然而，在边缘设备上为每个新场景进行微调往往是不切实际的。针对这一挑战，本文提出了一种基于上下文学习的行人轨迹预测框架TrajICL，该框架能够在推理时通过选择相关的过往轨迹示例进行适应，而无需进行权重更新，从而解决了需要进行场景特定数据的微调的问题。
### Innovation
本文引入了基于时空相似性的示例选择（STES）方法，通过在相同场景内选择具有相似运动模式的过往轨迹示例，以及引入了基于预测的示例选择（PG-ES）方法，通过结合过往和未来轨迹来进一步优化示例选择，使得模型能够考虑长期动态特性。此外，与依赖于有限多样性的现实世界小数据集不同，本文在大规模合成数据集上进行训练，以增强模型的预测能力，并通过上下文中的示例进行学习.
### Conclusion
广泛的实验证明，TrajICL在多种公共基准测试中优于甚至微调的方法，实现了跨领域场景的卓越适应性。
## 523. `cs.CV` - SPARKE: 通过RKE得分实现扩散模型中的可扩展提示感知多样性和新颖性指导 [PDF](https://arxiv.org/pdf/2506.10173), [HTML](https://arxiv.org/abs/2506.10173)
### Authors
Mohammad Jalali,Haoyu Lei,Amin Gohari,Farzan Farnia
### Background
扩散模型在高保真图像合成和提示引导生成建模方面取得了显著的成功。然而，确保提示引导的扩散模型生成样本具有足够的多样性仍然是一个挑战，尤其是在提示涉及广泛语义范围的情况下，需要在语义相似的提示下以提示感知的方式评估生成数据的多样性。最近的方法引入了多样性的度量作为指导，以鼓励产生更多的变化。本研究中，我们在此基础上提出了一种名为SPARKE（Scalable Prompt-Aware Rény Kernel Entropy Diversity Guidance）的新方法，以实现提示感知下的多样性指导。
### Innovation
SPARKE 利用条件熵来进行多样性指导，动态根据相似提示调整多样性测量，实现提示感知的多样性控制。此外，为了克服熵基指导方法在大规模生成设置中面临的计算挑战，我们针对条件潜在RKE得分指导的特殊情况，将一般熵度量的复杂度从 O(n^3) 降低到 O(n)，从而能够在不同的提示下进行多样性的引导采样，并在多种文本到图像扩散模型上进行数值测试，表明该方法在不增加显著计算成本的情况下提高了生成数据的提示感知多样性。
### Conclusion
通过SPARKE方法，我们提高了生成数据的提示感知多样性，同时降低了计算复杂度，使其能够在大量生成轮次中应用。此方法已经在多个文本到图像扩散模型上进行了测试，证明了其有效性。我们在项目页面发布了相关代码：this https URL
## 524. `cs.CV` - 利用自我监督的视觉变换器特征增强生成对抗迁移性 [PDF](https://arxiv.org/pdf/2506.21046), [HTML](https://arxiv.org/abs/2506.21046)
### Authors
Shangbo Wu,Yu-an Tan,Ruinan Ma,Wencong Ma,Dehua Zhu,Yuanzhang Li
### Background
深度神经网络（DNNs）的能力来源于从提供的数据中提取和解释特征的能力。本研究通过利用变换器架构中自我监督学习的优越协同作用，探索自我监督的Vision Transformer（ViT）表示能否提高对抗性迁移性。在此之前，特征通常来自监督学习，而在本研究中，区别在于采用了对比学习（CL）和掩码图像模型（MIM）的自监督学习范式来利用变换器的全局结构特征和局部纹理特征。通过这种方法，研究发现自监督的ViTs能够关注不同特征的倾向，这些特征共同作用时可以显著提高对抗性泛化能力。
### Innovation
本论文提出了一种名为dSVA（dual self-supervised ViT features attack）的生成对抗篡改方法，利用了对比学习（CL）和掩码图像模型（MIM）的自监督学习范式。它不仅仅依赖于硬标签，而是利用了中间特征来创建黑盒对抗样本，并设计了一个新颖的生成训练框架，该框架不仅包括生成器来创建黑盒对抗样本，还利用了自我监督ViTs的联合特征和注意力机制进行训练。研究表明，通过利用双特征（CL和MIM）的自我监督ViTs提取的特征，对抗性样本在跨不同架构的模型中的黑盒迁移性显著提升，超过了现有的最先进的方法。
### Conclusion
研究发现，CL和MIM能使ViTs关注并学习不同的特征属性，这两种方法一起使用时极大地增强了对抗样本的泛化能力。通过破坏自监督ViTs提取的深层特征，可以显著提高对抗性转移性，使得生成的对抗样本具有跨各种架构模型的出色黑盒转移性。
## 525. `cs.CV` - 从单一到多元：用于3D生成的上下文部件潜在表征 [PDF](https://arxiv.org/pdf/2507.08772), [HTML](https://arxiv.org/abs/2507.08772)
### Authors
Shaocong Dong,Lihe Ding,Xiao Chen,Yaokun Li,Yuxin Wang,Yucheng Wang,Qi Wang,Jaehyeok Kim,Chenjian Gao,Zhanpeng Huang,Zibin Wang,Tianfan Xue,Dan Xu
### Background
近年来，3D生成技术从基于多视角2D渲染的方法转变为利用真实数据几何先验的3D本原潜扩散框架。尽管已有进展，但仍存在三大关键限制：单一潜在表示无法捕捉复杂的多部件几何结构，导致细节退化；整体潜在编码忽略了对组合设计至关重要的部件独立性及其相互关系；全局调节机制缺乏精细可控制性。
### Innovation
本文提出了一种名为CoPart的部件感知扩散框架，该框架将3D对象分解为上下文部件潜变量以实现一致的多部件生成。该框架有三大优势：1) 通过部件分解来降低编码复杂性；2) 允许显式地建模部件关系；3) 支持部件级别的调节。进一步开发了一种互指导策略，以微调预训练的扩散模型，确保几何一致性的同时保留基础模型先验。
### Conclusion
通过大规模训练的手段，使用Partverse（从Objaverse自动化网格分割并通过人工验证注解构建的新3D部件数据集），详细实验显示CoPart在部件级编辑、肢体对象生成和场景组成方面具有无与伦比的可控制性。
## 526. `cs.CV` - 从随机的槽-特征配对预测视频槽注意查询 [PDF](https://arxiv.org/pdf/2508.01345), [HTML](https://arxiv.org/abs/2508.01345)
### Authors
Rongzhen Zhao,Jian Li,Juho Kannala,Joni Pajarinen
### Background
无监督视频对象中心化学习（OCL）很有前景，因为它能够实现类似于人类的方式，即提供对象级别场景表示和动力学建模。主流的视频OCL方法采用递归结构：聚合器将当前视频帧聚合为一定查询下的对象特征（即槽），转换器将当前的槽特征转换为下一个帧的查询。尽管这是一种有效的架构，但现有实现方法仍存在两个主要问题：一是忽略了下一个帧特征，这对查询预测最具信息量；二是未学到转换动力学知识，这是查询预测的重要知识。
### Innovation
针对上述问题，本文提出了一种名为RandSF.Q的新方法：一，设计了一种新的转换器，同时整合槽和特征信息，提升查询预测的信息量；二，在现有的递归回路中随机采样槽-特征配对，并训练转换器以预测这些配对，驱动其学习转换动力学。
### Conclusion
实验结果表明，该方法在场景表示任务上显著优于现有视频OCL方法，例如在对象发现方面提升了10个点，达到了新的SOTA水平，该优越性还为动力学建模等下游任务带来了好处。核心源代码、模型检查点和训练日志在提供的链接处可以获取。
## 527. `cs.CV` - DDL：在多样化现实场景下用于深度假信息检测和定位的大规模数据集 [PDF](https://arxiv.org/pdf/2506.23292), [HTML](https://arxiv.org/abs/2506.23292)
### Authors
Changtao Miao,Yi Zhang,Weize Gao,Zhiya Tan,Weiwei Feng,Man Luo,Jianshu Li,Ajian Liu,Yunfeng Diao,Qi Chu,Tao Gong,Zhe Li,Weibin Yao,Joey Tianyi Zhou
### Background
近年来，AIGC的发展导致了恶意深度伪造内容的滥用增加，这使得开发可靠的深度伪造检测方法变得至关重要。尽管现有的深度伪造检测模型在检测指标上表现出色，但大多数方法仅提供简单的二分类结果，缺乏可解释性。近年来，有研究尝试通过提供空间操作掩码或伪迹时间段来增强分类结果的可解释性，但由于伪造数据集的限制，这些方法的实际效果仍不尽如人意。主要原因在于，大多数现有的深度伪造数据集仅包含二元标签，伪造场景、深度伪造类型多样性不足，数据规模相对较小，无法应对复杂的现实场景。
### Innovation
本文构建了一个名为DDL的大规模深度伪造检测和定位（Deepfake Detection and Localization）数据集，包含超过1,400,000个伪造样本，并涵盖了80种不同的深度伪造方法。DDL设计包括四个关键创新点：（1）全面的深度伪造方法（涵盖7种不同的生成架构和总计80种方法）、（2）多样的操作模式（整合7种经典和3种新型伪造模式）、（3）多样的伪造场景和模态（包括3种场景和3种模态）、（4）精细的伪造标注（提供超过1,180,000个精确的空间掩模和230,000个精确的时间段）。
### Conclusion
我们的DDL不仅为复杂现实场景下的伪造提供了一个更具挑战性的基准，还为构建下一代深度伪造检测、定位和可解释性方法提供了重要的支持。
## 528. `cs.CV` - ScoreAdv: 基于扩散模型的评分导向自然对抗样本的目标生成 [PDF](https://arxiv.org/pdf/2507.06078), [HTML](https://arxiv.org/abs/2507.06078)
### Authors
Chihan Huang,Hao Tang
### Background
尽管深度学习在各种领域取得了成功，但它仍然容易受到对抗攻击的影响。虽然许多现有的对抗攻击方法能够达到高成功率，但它们通常依赖于 $boldsymbol{text{l}_p}$ 范数扰动约束，这与人类的感知能力不符。因此，研究人员转向生成自然且无约束的对抗性样本 (UAEs)。基于生成对抗网络 (GAN) 的方法存在固有的局限性，如由于不稳定性和模式塌陷导致的图像质量较差。扩散模型已被用于生成 UAEs，但它们依然依赖于迭代的 PGD 扰动注入，未能充分利用其核心去噪能力。
### Innovation
本文提出了一种基于扩散模型的新型生成 UAEs 方法，称为 ScoreAdv。该方法结合了可解释的对抗性指导机制，逐步将采样分布向对抗分布转移，并利用可解释的显著性图在生成样本中注入参考图像的视觉信息。特别地，ScoreAdv 能够生成无限数量的自然对抗样本，并且不仅可以攻击分类模型，还可以攻击检索模型。我们在 ImageNet 和 CelebA 数据集上进行了广泛的实验，在黑盒和白盒设置下对十个目标模型进行了验证。结果表明，ScoreAdv 达到了最先进的攻击成功率和图像质量，并且维护了推理效率。同时，去噪和对抗扰动之间的动态平衡使 ScoreAdv 在防御措施下仍然具有鲁棒性。
### Conclusion
本文提出的方法 ScoreAdv 生成的自然对抗样本不仅在多种目标模型上具有最佳的攻击成功率和图像质量，还能够保持高推理效率，并且能够灵活应用于分类模型和检索模型等多种场景。此外，利用扩散模型的核心去噪能力增强了对抗攻击的鲁棒性。
## 529. `cs.CV` - 平滑Slot注意力迭代和循环 [PDF](https://arxiv.org/pdf/2508.05417), [HTML](https://arxiv.org/abs/2508.05417)
### Authors
Rongzhen Zhao,Wenyan Yang,Juho Kannala,Joni Pajarinen
### Background
Slot注意力机制（SA）及其变体在基于对象的中心学习（OCL）中占据了核心地位。在图像中，对象可以通过迭代精细化冷启动查询向量被聚合为各自的槽向量；在视频中，这样的聚合是跨帧递归进行的，初始帧的查询是冷启动的，后续帧的查询则从前一帧的槽向量过渡而来。然而，这些问题导致了在初始帧中对象的聚合不够精确，且初始帧和后续帧的查询需要不同的变换方式。
### Innovation
本文提出了SmoothSA方法来解决上述问题：(1) 通过对输入特征丰富的信息进行预热，来平滑初始帧的SA迭代。(2) 通过对初始帧和非初始帧使用的变换方式进行区分（分别使用完整迭代和单次迭代），以平滑不同帧之间的SA循环。这种方法在多个领域（如对象发现、识别、下游基准）进行了验证。
### Conclusion
综合实验和进一步分析证实了这种方法的有效性，并直观地展示了SmoothSA如何平滑SA的迭代和循环。提供的源代码、模型检查点和训练日志可以供其他人使用和验证。
## 530. `cs.CV` - HM-Talker: 混合运动建模方法在高保真头像合成中的应用 [PDF](https://arxiv.org/pdf/2508.10566), [HTML](https://arxiv.org/abs/2508.10566)
### Authors
Shiyu Liu,Kui Jiang,Xianming Liu,Hongxun Yao,Xiaocheng Feng
### Background
当前方法在生成音频驱动的头部视频时，由于依赖于隐式建模而非显式建模（即缺乏解剖学指导的语音相关面部运动先验），常常产生运动模糊和嘴唇抖动的问题，从而影响用户在人机交互中的参与度。
### Innovation
提出了HM-Talker，这是一种新颖的框架，用于生成高保真、时间连贯的头部视频。HM-Talker利用混合运动表示，结合隐式和显式运动提示。特别地，交叉模态解耦模块（CMDM）从音频输入中直接预测动作单元（AU），并提取互补的隐式/显式运动特征，同时预测嘴唇同步的准确性。此外，还引入了混合运动建模模块（HMMM），以减轻身份依赖性偏差并增强跨类型泛化能力。
### Conclusion
大量实验表明，与最先进的方法相比，HM-Talker在视觉质量和唇同步准确性方面具有优势，能够实现多样身份的稳健唇同步，推进个性化头部视频合成的进步。
## 531. `cs.CV` - KARMA: 通过柯尔莫哥洛夫-阿诺德表示学习实现高效结构缺陷分割 [PDF](https://arxiv.org/pdf/2508.08186), [HTML](https://arxiv.org/abs/2508.08186)
### Authors
Md Meftahul Ferdaus,Mahdi Abdelguerfi,Elias Ioup,Steven Sloan,Kendall N. Niles,Ken Pathak
### Background
在基础设施结构缺陷的语义分割中，由于缺陷形态变化多端、成像环境恶劣以及类别不平衡，这一任务依然具有挑战性。当前的深度学习方法虽然有效，但通常需要数百万计的参数，这使得它们不适应用于实时检测系统。
### Innovation
KARMA（Kolmogorov-Arnold Representation Mapping Architecture）通过Kolmogorov-Arnold表示学习来构建一个高效的语义分割框架，它以一维函数的组合来表示复杂缺陷模式，而非传统的卷积。KARMA包括三项技术创新：（1）一个通过低秩分解实现参数高效的小型Kolmogorov-Arnold网络（TiKAN）模块；（2）带有分离卷积的优化特征金字塔结构，用于多尺度缺陷分析；（3）静态-动态原型机制，增强不平衡类别下的特征表示。
### Conclusion
在基准基础设施检查数据集上进行的大量实验证明，KARMA在参数量显著减少（0.959M vs 31.04M，减少97%）的情况下，仍然能与最先进的方法竞争或超越其性能。KARMA运行速度为0.264 GFLOPS，适用于实时部署，无需牺牲准确性即可实现实用的自动化基础设施检查系统。
## 532. `cs.CV` - 全效: 统一且空间可控的视觉效果生成 [PDF](https://arxiv.org/pdf/2508.07981), [HTML](https://arxiv.org/abs/2508.07981)
### Authors
Fangyuan Mao,Aiming Hao,Jintao Chen,Dongxia Liu,Xiaokun Feng,Jiashu Zhu,Meiqi Wu,Chubin Chen,Jiahong Wu,Xiangxiang Chu
### Background
视觉效果(VFX)在现代电影制作中是必不可少的视觉增强技术。尽管当前的视频生成模型提供了一种成本效益高的VFX生产解决方案，但现有方法受限于每种效果LoRA训练，这限制了在单一模型中生成多种效果的能力。这种基本限制妨碍了需要空间可控的复合效果的应用，即同时在指定位置生成多种效果。因此，将多样化的视觉效果整合到一个统一的框架中面临着重大挑战：效果变化的干扰和多VFX联合训练中的空间不可控性。
### Innovation
我们提出了Omni-Effects框架，这是一个统一的框架，能够生成提示引导的效果和空间可控的复合效果。该框架的两大核心创新包括：1) 基于LoRA的专家组合（LoRA-MoE），这是一个群体专家LoRA模型，能够在一个统一模型中整合多样化的效果，同时有效地减轻跨任务干扰；2) 空间感知提示（SAP），它将空间掩码信息纳入文本标记，以实现精确的空间控制。此外，我们还引入了独立信息流（IIF）模块，该模块集成于SAP中，隔离每个效果的控制信号，防止任何不需要的混叠。
### Conclusion
为了促进这项研究，我们通过一种新的数据采集管道整合图像编辑和First-Last Frame-to-Video (FLF2V) 合成，构建了一个全面的VFX数据集Omni-VFX，并引入了专门的VFX评估框架以验证模型性能。广泛实验表明，Omni-Effects实现了精确的空间控制和多样效果的生成，使用户能够指定所需效果的类别和位置。
## 533. `cs.CV` - TRUST-VL: 一种用于一般多模态虚假信息检测的可解释新闻助手 [PDF](https://arxiv.org/pdf/2509.04448), [HTML](https://arxiv.org/abs/2509.04448)
### Authors
Zehong Yan,Peng Qi,Wynne Hsu,Mong Li Lee
### Background
多模态虚假信息，包括文本、视觉和跨模态的扭曲，随着生成式AI的发展而日益构成社会威胁。现有方法通常专注于单一类型的扭曲，难以适应未见过的情况。本文发现不同类型的扭曲共享一些推理能力，但需要特定的任务技能。基于此观察，本研究提出通过在不同类型的扭曲之间进行联合训练，促进知识共享和增强模型的泛化能力。
### Innovation
本研究引入了TRUST-VL，这是一种统一且可解释的视觉-语言模型，用于一般多模态虚假信息检测。TRUST-VL包含一个新颖的问题感知视觉增强模块，旨在提取特定于任务的视觉特征。同时，研究为支持模型训练，构建了TRUST-Instruct，一个大规模指令数据集，包含198,000个样本，这些样本具有与人工事实核查工作流程对齐的结构化推理链。实验结果表明，TRUST-VL 在基准测试中实现了最先进的性能，具有较强的泛化能力和可解释性。
### Conclusion
通过联合训练多模态扭曲类型和引入问题感知视觉增强模块，TRUST-VL 显著提升了多模态虚假信息检测的性能和可解释性。
## 534. `cs.CV` - 循环扩散模型用于反事实图像生成 [PDF](https://arxiv.org/pdf/2509.24267), [HTML](https://arxiv.org/abs/2509.24267)
### Authors
Fangrui Huang,Alan Wang,Binxu Li,Bailey Trang,Ridvan Yesiloglu,Tianyu Hua,Wei Peng,Ehsan Adeli
### Background
深度生成模型在医学图像合成方面已经取得显著成果，但仍需解决保持条件忠实性和合成图像高质量的问题，尤其是在直接或反事实生成方面。
### Innovation
提出了一种循环训练框架，用于微调扩散模型，以提高条件合规性并增强合成图像的现实度。该方法，即循环扩散模型(CDM)，通过引入循环约束确保生成图像与原始图像的一致性，从而提高直接和反事实生成的可靠性。
### Conclusion
在结合的3D脑部MRI数据集上进行的实验表明，该方法改善了条件准确性并提升了图像质量（FID和SSIM）。结果表明，CDM中的循环策略可以有效提高扩散基础医学图像生成的可靠性，适用于数据增强、反事实和疾病进展建模等方面。
## 535. `cs.CV` - 图像扩散模型中的局部性源自数据统计 [PDF](https://arxiv.org/pdf/2509.09672), [HTML](https://arxiv.org/abs/2509.09672)
### Authors
Artem Lukoianov,Chenyang Yuan,Justin Solomon,Vincent Sitzmann
### Background
最近的研究表明，图像扩散模型的泛化能力来源于训练神经网络的局部性质。具体而言，当去噪一个特定像素时，模型仅依赖于输入图像围绕该像素的一个有限邻域。关于这些模型产生新颖图像的能力，先前的研究指出，局部性与这一能力紧密相关。了解扩散模型为何首先学习局部行为以及控制局部模式特征的因素至关重要。这项工作中，作者提供了证据表明，深扩散模型中的局部性作为图像数据集的统计属性出现，并非由于卷积神经网络的归纳偏置。具体来说，作者证明了一种最优的参数化线性去噪器表现出与深层神经去噪器类似的局部性特征。理论上和实验上表明，这种局部性直接来源于图像数据集中的像素相关性。此外，专有数据集上的局部模式显著不同，接近于数据协方差的主成分。
### Innovation
作者展示了最优参数化线性去噪器具有与深层神经去噪器类似的局部性特征，并且这种局部性直接来自于图像数据集中的像素相关性。同时，作者发现专有数据集上的局部模式差异大，且近似于数据协方差的主成分。基于这些见解，作者设计了一个分析性去噪器，优于之前的专家设计的替代品，更好地匹配了深层扩散模型预测的分数。
### Conclusion
虽然神经网络架构影响生成质量，但它们的主要作用是捕获数据中存在的局部模式。
## 536. `cs.CV` - D-HUMOR：通过多模态开放推理理解黑暗幽默——一个基准数据集和方法 [PDF](https://arxiv.org/pdf/2509.06771), [HTML](https://arxiv.org/abs/2509.06771)
### Authors
Sai Kartheek Reddy Kasu,Mohammad Zia Ur Rehman,Shahid Shafi Dar,Rishi Bharat Junghare,Dhanvin Sanjay Namboodiri,Nagendra Kumar
### Background
在线表情包中的黑暗幽默因其依赖于隐含、敏感且文化背景相关的提示而面临独特挑战。目前缺乏用于检测多模态内容中黑暗幽默的相关资源和方法，因此提出了一种新型数据集以解决这一问题。该数据集包含4,379个Reddit表情包，并被注释为黑暗幽默类别（性别、心理健康、暴力、种族、残疾和其他）以及三种级别的强度（轻度、中度、重度）标签。该数据集用于构建一个增强推理框架，该框架首先使用大型视觉语言模型（VLM）生成每个表情包的结构化解释。通过角色反转自我循环，VLM 能够从作者的角度迭代地改进其解释，确保解释的完整性和一致性。
### Innovation
提出了一种增强推理框架，该框架结合了大型视觉语言模型（VLM）生成结构化解释并通过角色反转自我循环改进解释的过程。该框架还提出了一种融合文本、图像和推理特征的三流跨推理网络（TCRNet），增强多模态数据的处理能力。实验结果表明，该方法在黑暗幽默检测、目标识别和强度预测三个方面优于强大的基线方法。此外，该框架还提供了数据集、注释和相关代码以促进进一步研究。
### Conclusion
本文提出了一种多模态开放推理框架，在黑暗幽默理解任务中取得了良好的效果。实验结果表明，我们的方法在黑暗幽默检测、目标识别和强度预测任务上显著优于基线方法。提供的数据集、注释和代码将有助于进一步研究多模态幽默理解和内容管理。
## 537. `cs.CV` - 可调通用性扩散：基于自监督上下文子数据的低剂量CT重建 [PDF](https://arxiv.org/pdf/2509.23885), [HTML](https://arxiv.org/abs/2509.23885)
### Authors
Guoquan Wei,Liu Shi,Zekun Zhou,Wenzhe Shan,Qiegen Liu
### Background
现有的基于深度学习的低剂量CT降噪模型依赖于配对数据，泛化能力较差。即使更为关注的扩散模型也需要学习干净数据的分布以用于重建，但在医学临床应用中难以满足。此外，基于自监督的方法在将当前剂量下预训练的模型扩展到其他剂量时，模型的泛化能力显著下降。现有方法为此提供了解决方案，提出了一种名为TurnDiff的新方法，该方法利用自监督上下文子数据进行低剂量CT重建，重点解决了这些问题。
### Innovation
TurnDiff通过自监督上下文子数据，设计了一个上下文子数据自增强相似性策略，从低剂量CT投影域出发进行降噪，提供了后续步骤的初始先验，然后使用初始先验结合知识蒸馏和深度结合的潜在扩散模型进行图像细节优化。此外，还提出了一种像素级自校正融合技术，增强图像保真度。该方法能够灵活地应用于不同剂量甚至是未见过的剂量的泛化。TurnDiff仅需要低剂量CT投影数据进行训练和测试，实验证明，其在重建和泛化方面均优于现有最先进的方法。
### Conclusion
TurnDiff 方法通过自监督上下文子数据为低剂量CT重建提供了一种方法，不仅可以解决依赖配对数据和泛化能力差的问题，还能在不同剂量甚至是未见过的剂量上进行泛化。实验证明，与现有方法相比，TurnDiff 在重建和泛化方面均有显著优势。
## 538. `cs.CV` - 实时统一内嵌与间嵌编码的神经视频压缩 [PDF](https://arxiv.org/pdf/2510.14431), [HTML](https://arxiv.org/abs/2510.14431)
### Authors
Hui Xiang,Yifan Bian,Li Li,Jingran Wu,Xianguo Zhang,Dong Liu
### Background
近年来，神经视频压缩（NVC）技术发展迅速，出现了与H.266/VVC相比具有更高压缩效率的方案，如DCVC-RT，并具备实时编码/解码能力。然而，现有的NVC方案在处理消隐区域和新内容、帧间错误传播与累积等方面仍存在不足。
### Innovation
本文借鉴经典视频编码方案的理念，引入了内在编码于间嵌帧中的工具，设计了一种统一内嵌与间嵌编码的NVC框架。在此框架中，每帧均由统一模型处理，并进行自适应的内在或间嵌编码。此外，提出了双重帧压缩设计，不仅向前压缩，也向后压缩，以充分利用帧间冗余。
### Conclusion
实验结果表明，本文方案相较于DCVC-RT平均减少了12.1%的BD率损耗，提供更加稳定的内容质量和比特率，并保持了实时编码/解码性能。并且代码和模型将对外开放。
## 539. `cs.CV` - MaskCaptioner: Learning to Jointly Segment and Caption Object Trajectories in Videos [PDF](https://arxiv.org/pdf/2510.14904), [HTML](https://arxiv.org/abs/2510.14904)
### Authors
Gabriel Fiastre,Antoine Yang,Cordelia Schmid
### Background
视频中的密集视频对象标注（DVOC）任务要求同时检测、跟踪和对物体轨迹进行自然语言描述，涉及时空细节的理解。由于任务复杂性和手标注的成本高，之前的办法大多采用分步训练策略，这可能导致性能不佳。
### Innovation
提出了一种名为MaskCaptioner的模型，该模型利用最先进的视觉语言模型生成更精确的时空局部物体描述，并通过合成文本生成新的LVISCap和LV-VISCap数据集，使得模型能够端到端地完成物体检测、分割、跟踪和描述任务。MaskCaptioner在三个现有基准测试VidSTG, VLN和BenSMOT上取得了最佳性能。
### Conclusion
通过MaskCaptioner模型和新数据集的训练，取得了DVOC的最新成果，并提供了数据集和代码下载链接以供进一步研究使用。
## 540. `cs.CV` - LinearSR: 解锁线性注意力以实现稳定高效的图像超分辨率 [PDF](https://arxiv.org/pdf/2510.08771), [HTML](https://arxiv.org/abs/2510.08771)
### Authors
Xiaohui Li,Shaobin Zhuang,Shuo Cao,Yang Yang,Yuandong Pu,Qi Qin,Siqi Luo,Bin Fu,Yihao Liu
### Background
生成模型在图像超分辨率（SR）方面越来越强大，但它们依赖于自注意力的二次复杂度（O(N^2)），造成了重大的计算瓶颈。尽管线性注意力提供了O(N)的解决方案，但其在高保真SR中的潜力一直未被充分利用。历史地来看，这主要是由于一系列互相关联且此前未解决的挑战阻碍了其应用。
### Innovation
本文引入了LinearSR，这是一个总体框架，首次系统性地克服了这些关键障碍。具体来说，我们使用新颖的“膝点”为基础的早期停止引导微调（ESGF）策略解决了训练中的基本不稳定性，导致灾难性模型发散的问题。此外，我们使用基于信噪比的专家混合（MoE）架构减轻了感知失真与信息损失之间的经典权衡。最后，我们建立了一个有效且轻量级的指导范式TAG，来源于“精度优于体积”的原则。因此，我们的LinearSR模型同时提供了最先进的感知质量与卓越的效率。其核心扩散前向传递（1-NFE）达到了SOTA级别的速度，而其整体多步推理时间也保持了竞争力。
### Conclusion
这项工作提出了在高真度SR领域应用线性注意力的第一套稳健方法，建立了未来高效生成超分辨率研究的基础范式。
## 541. `cs.CV` - SPLite 手部：感知稀疏性的轻量化3D手部姿态估计 [PDF](https://arxiv.org/pdf/2510.16396), [HTML](https://arxiv.org/abs/2510.16396)
### Authors
Yeh Keng Hao,Hsu Tzu Wei,Sun Min
### Background
随着AR/VR设备的普及，将深度学习模型部署在边缘设备上成为关键挑战。这些设备需要实时推理、低功耗和最小延迟。框架设计师面临平衡效率和性能的难题。
### Innovation
设计了一个轻量级框架，采用了编码器-解码器结构，并提出了一种稀疏卷积方法应用在ResNet-18主干上，以利用手部姿态图像中的内在稀疏性，实现了42%的端到端效率提升。此外，提出了SPLite解码器，该新架构在树莓派5上将解码过程的帧率提高了3.1倍，同时保持了准确性。还应用了感知量化训练，在减少内存使用的同时保持了准确性，在FreiHAND数据集上PA-MPJPE仅从9.0 mm增加到9.1 mm。系统的CPU在树莓派5上实现了2.98倍的加速。此外，该方法还在复合基准数据集上进行评估，展示了与最先进的方法相当的准确性，同时显著提高了计算效率。
### Conclusion
本系统在树莓派5 CPU上实现了2.98倍的速度提升，并在维持较高准确性的基础上，有效地优化了计算效率。
## 542. `cs.CV` - FARMER: Flow AutoRegressive Transformer over Pixels [PDF](https://arxiv.org/pdf/2510.23588), [HTML](https://arxiv.org/abs/2510.23588)
### Authors
Guangting Zheng,Qinyu Zhao,Tao Yang,Fei Xiao,Zhijie Lin,Jie Wu,Jiajun Deng,Yanyong Zhang,Rui Zhu
### Background
直接建模原始数据分布的概率是机器学习领域的关键话题，尤其是在大型语言模型中通过自回归建模实现了大规模的成功。然而，对视觉像素数据进行连续自回归建模时，由于序列长度长和高维空间的问题，这一方法面临挑战。
### Innovation
本文提出了FARMER，这是一种新颖的端到端生成框架，结合了正则化流动（NF）和自回归（AR）模型，以实现可追踪的概率估计和直接从原始像素中生成高质量图像。FARMER采用可逆的自回归流将图像转换为潜在序列，其分布由自回归模型隐式建模。为了应对像素级建模中的冗余性和复杂性，提出了一种自我监督的维归约方案，将NF潜在通道划分为信息和冗余组，从而改进和优化了AR建模。此外，设计了一步蒸馏方案来显著加速推理速度，并引入了一种基于重采样的分类器无指导的算法来提高图像生成质量。
### Conclusion
广泛的实验证明，FARMER在与其他基于像素的生成模型的竞争中表现出了竞争力，同时提供了精确的概率和可扩展的训练。
## 543. `cs.CV` - GRPO-Guard: 通过受控剪辑缓解流匹配中的隐式过度优化 [PDF](https://arxiv.org/pdf/2510.22319), [HTML](https://arxiv.org/abs/2510.22319)
### Authors
Jing Wang,Jiajun Liang,Jie Liu,Henglin Liu,Gongye Liu,Jun Zheng,Wanyuan Pang,Ao Ma,Zhenyu Xie,Xintao Wang,Meng Wang,Pengfei Wan,Xiaodan Liang
### Background
近期，基于GRPO的强化学习在优化流匹配模型方面取得了显著进展，有效提高了这些模型与特定任务奖励的一致性。然而，在实践中，重要比值分布的均值低于1，方差在不同的时间步上差异显著，导致正面优势样本无法进入剪辑区域，使得剪辑机制无法有效约束过于自信的正面更新。这会导致隐式过度优化阶段的出现，尽管代理奖励继续增加，关键指标如图像质量和文本提示的对齐度却急剧下降，使学到的策略难以应用于实际场景。
### Innovation
提出了一种名为GRPO-Guard的简单而有效的增强方法，通过引入比率标准化确保重要比值在去噪时间步保持平衡且一致，使得PPO剪辑机制能有效约束有害更新。此外，采用梯度重新加权策略在噪声条件下平均化策略梯度，防止特定时间步区域的过度更新。这些设计共同构成了一种调节剪辑机制，稳定优化过程并显著减轻隐式过度优化，同时无需依赖强烈的KL正则化。
### Conclusion
在多个扩散模型架构（例如SD3.5M, Flux.1-dev）和不同的代理任务上进行的广泛实验证明，GRPO-Guard显著减少了过度优化现象，同时保持或甚至提高了生成质量。
## 544. `cs.CV` - 遥感影像分类中的邻域特征池化 [PDF](https://arxiv.org/pdf/2510.25077), [HTML](https://arxiv.org/abs/2510.25077)
### Authors
Fahimeh Orvati Nia,Amirmohammad Mohammadi,Salim Al Kharsa,Pragati Naikare,Zigfried Hampel-Arias,Joshua Peeples
### Background
本文提出了一种新的遥感影像分类中的纹理特征提取方法——邻域特征池化（NFP）。NFP层捕捉相邻输入之间的关系，并高效地在特征维度上聚合局部相似性。该方法通过卷积层实现，可以无缝集成到任何网络中。通过与基础模型的比较结果表明，NFP在多种数据集和网络架构中一致地提高了性能，并且具有轻微的参数开销。
### Innovation
提出了邻域特征池化（NFP）作为一种新的纹理特征提取方法。NFP层通过捕捉相邻输入之间的关系来聚合局部相似性，适用于多种数据集和网络结构，能有效提高遥感影像分类性能，且参数开销较小，易于集成到现有的神经网络结构中。
### Conclusion
实验结果表明，与基础模型相比，使用NFP的方法在多个不同的数据集和网络架构上都表现出了持续的性能提升，且NFP实现了最小的参数开销。
## 545. `cs.CV` - MMEdge: 通过流水线式感知和编码加速本地多模态推理 [PDF](https://arxiv.org/pdf/2510.25327), [HTML](https://arxiv.org/abs/2510.25327)
### Authors
Runxi Huang,Mingxuan Yu,Mingyu Tsoi,Xiaomin Ouyang
### Background
在自动驾驶、人机交互和移动健康等应用中，资源受限的边缘设备上的实时多模态推理至关重要。然而，现有研究往往忽视了感知动态与模型执行之间的紧密联系，以及跨模态间的复杂依赖关系。
### Innovation
本文提出了一种名为MMEdge的新方法，这是一种基于流水线式感知和编码的新型本地多模态推理框架。它通过细粒度的感知和编码单元使计算逐步进行，并引入了一个轻量级且有效的时序聚合模块，用于捕捉不同流水线单元中的丰富时序动态，以保持准确性。MMEdge还通过适应性多模态配置优化器和跨模态推测性跳过机制，优化资源变化和输入数据复杂性下的系统性能。
### Conclusion
通过在两个公开的多模态数据集上的评估和实际的无人机多模态测试床部署，结果显示MMEdge在保持高任务准确性的同时，显著减少了端到端延迟。
## 546. `cs.CV` - 适合目的吗？在现实世界中的深度伪造检测 [PDF](https://arxiv.org/pdf/2510.16556), [HTML](https://arxiv.org/abs/2510.16556)
### Authors
Guangyu Lin,Li Lin,Christina P. Walker,Daniel S. Schiff,Shu Hu
### Background
随着生成对抗网络、扩散模型和多模态大型语言模型的发展，AI生成内容的快速传播使得合成媒体的生成和传播变得容易，增加了政治深度伪造信息的风险，这种信息篡改真相并破坏对政治机构的信任。因此，政府、研究机构和行业积极推动深度伪造检测解决方案，但现有的大多数模型仅在实验室控制的数据集上训练和验证，导致其难以在社交媒体上真实存在的政治深度伪造中有效泛化。为了解决这一问题，本研究基于一个精心收集的真实世界政治深度伪造事故数据库，评估了来自学术界、政府和工业界的顶级深度伪造检测器的有效性。
### Innovation
首次提出了基于真实世界政治深度伪造事故数据库的系统性基准，评估了学术界、政府和工业界的最先进深度伪造检测器，并发现这些检测器在地域和背景方面的泛化能力较弱，尤其是视频领域容易受到简单篡改的影响。
### Conclusion
现有深度伪造检测器在真实世界中的泛化能力不足，需要开发更有针对性的政治情境下的深度伪造检测框架，以更好地保护公众。
## 547. `cs.CV` - TeleEgo: 在野生状况下评估自中心人工智能助手的标准 [PDF](https://arxiv.org/pdf/2510.23981), [HTML](https://arxiv.org/abs/2510.23981)
### Authors
Jiaqi Yan,Ruilong Ren,Jingren Liu,Shuning Xu,Ling Wang,Yiheng Wang,Yun Wang,Long Zhang,Xiangyu Chen,Changzhi Sun,Jixiang Luo,Dell Zhang,Hao Sun,Chi Zhang,Xuelong Li
### Background
现有的基准测试通常在孤立环境中评估多模态输入（视频、音频、文本）处理能力、实时响应和长时记忆保持。这些基准测试缺乏真实的流式场景支持，并且仅适用于短期任务，无法支持长期任务。相比之下，TeleEgo是一个长达数小时的流式多模态基准测试，可在现实日常生活环境中评估自中心人工智能助手的能力。TeleEgo的数据集包括每参与者超过14小时的同步自中心视频、音频和文本，涉及四个领域：工作&学习、生活方式&日常、社交活动和外出&文化。所有数据都以统一的全球时间线对齐，包括高质量的视觉叙述和语音转录，通过人工验证。它定义了12个诊断亚任务，涵盖了记忆（回忆过去事件）、理解（解释当前时刻）、和跨记忆推理（链接远处事件）三个方面。该数据集包含了3291个人类验证的问答项目，所有评估均在流式环境中进行。
### Innovation
TeleEgo引入了一种新的长时流式多模态基准测试方法，涵盖了在实际日常环境中评估自中心人工智能助手的能力，包括对未来的准确度和长期记忆保持时间的评估新指标。TeleEgo提供了更接近现实的综合性评估，有助于实用型人工智能助手的发展，提高了对AI助手实际表现的了解和评估方法的有效性
### Conclusion
TeleEgo提供了一个真实的和全面的评估，推动了实用型AI助手的发展。通过严格的实时准确性评估和长时记忆保持时间评估，实证了自中心AI助手在需要回溯过往事件、理解当前情势以及连接不同事件等核心能力上的实际应用潜力。
## 548. `cs.CV` - 推理视觉语言模型用于胸部X光分析 [PDF](https://arxiv.org/pdf/2510.23968), [HTML](https://arxiv.org/abs/2510.23968)
### Authors
Andriy Myronenko,Dong Yang,Baris Turkbey,Mariam Aboian,Sena Azamat,Esra Akcicek,Hongxu Yin,Pavlo Molchanov,Marc Edgar,Yufan He,Pengfei Guo,Yucheng Tang,Daguang Xu
### Background
视觉语言模型（VLMs）在医学图像分析中显示出强大的潜力，但大多数模型仍是不透明的，提供预测而缺乏临床医生依赖的透明、逐步的推理过程。本文提出的框架将链式思维（CoT）推理引入胸部X光解释，旨在通过学习专家如何推理，而不是仅仅学习他们的结论，来提高模型的可解释性。此模型在确保预测准确性的同时，还支持临床审计、错误分析和更安全的人工智能协作。实验结果表明，该方法在分布外评估中实现了具有竞争力的多标签分类效果，同时也提升了可解释性。通过读者研究，专家放射科医生的测试结果表明，完整的推理过程提高了信心，支持了错误审计，并缩短了最终报告的时间。
### Innovation
本文提出了一种结合高保真视觉编码与两阶段训练方法的推理视觉语言模型框架。该模型利用推理式监督微调（SFT）和基于可验证奖励的强化学习（RL），实现了与放射科医生系统思维过程相似的推理输出，包括不确定性估计和鉴别诊断。这种方法不仅提高了模型的解释性，还支持了临床审计和错误分析。模型在分布外评估中的表现优于现有模型，且在专家放射科医生的读者研究中也表现出色。
### Conclusion
本文提出的方法在胸部X光分析中结合了高保真视觉编码和推理训练，显著提升了模型的可解释性。通过与环境的交互和基于可验证奖励的强化学习优化，模型能够模仿放射科医生的系统思维过程和推理步骤，从而提高了模型的临床可用性。该研究的结论是，通过优化推理过程，可以更有效地支持临床决策，提高人类与人工智能协作的安全性，并且可以促进医学图像分析中更为信任和可解释的人工智能的发展。
## 549. `cs.CV` - 解耦4维高斯散斑：以343 FPS渲染高分辨率动态世界 [PDF](https://arxiv.org/pdf/2503.22159), [HTML](https://arxiv.org/abs/2503.22159)
### Authors
Hao Feng,Hao Sun,Wei Xie,Zhi Zuo,Zhengzhe Liu
### Background
虽然从2D视频生成动态的新视角进展显著，但在动态场景的高效重建和渲染方面仍面临挑战。本文背景在于这一研究领域尚存的技术难题，即如何在保持视觉保真度的前提下实现高效实时渲染动态场景。
### Innovation
本文提出了一种新的表示和渲染管道——解耦4D高斯散斑（Disentangled4DGS），通过解耦4D高斯的时间和空间分量，避免了之前的切片和四维矩阵计算。此外，该方法通过动态2D高斯变形投影和推迟时间处理，减少了冗余计算。该方法引入了梯度指导流损失和时间分割策略，减少了伪影。实验表明，该方法在渲染速度和质量上都有显著改善，实现了343 FPS的渲染速度，同时减少了至少4.5%的存储需求。该方法在动态新视角合成方面设立了新的基准，超越了现有的方法。
### Conclusion
Disentangled4DGS方法在高分辨率动态场景渲染中取得了显著进步，解决了实时性与视觉保真度之间的权衡问题，为动态新视角合成设定了新标准。
## 550. `cs.CV` - VC4VG: 优化文本到视频生成的视频字幕 [PDF](https://arxiv.org/pdf/2510.24134), [HTML](https://arxiv.org/abs/2510.24134)
### Authors
Yang Du,Zhuoran Lin,Kaiqiang Song,Biao Wang,Zhicheng Zheng,Tiezheng Ge,Bo Zheng,Qin Jin
### Background
近年来，文本到视频（T2V）生成技术取得了重大进展，强调了高质量视频文本对训练能够生成连贯且与指令对齐的视频模型的重要性。然而，专门为T2V训练优化视频字幕的策略依旧相对较少被探索。已有研究主要关注于视频内容，而忽略对字幕本身的优化，进而可能影响到最终生成的视频质量。此外，目前缺乏专门针对T2V要求的评估基准，导致在这一领域的研究难以客观评价模型性能。因此，本文提出了专门针对T2V需求的字幕优化框架——VC4VG（Video Captioning for Video Generation），从T2V视角分析字幕内容，将其分解到多个维度，并提出循证的字幕设计方法。
### Innovation
本文创新性地提出了一种专门针对T2V需求的字幕优化框架——VC4VG。该框架从字幕内容入手，分析出视频重建所需的关键因素，并从多个角度提出合理的字幕设计方法。同时，还构建了VC4VG-Bench，这是一个专门针对T2V需求的新基准，包括了细粒度、多维度和必要性分级的评估指标来评估字幕质量和视频生成效果。此外，通过大量T2V微调实验，表明优化后的字幕质量与视频生成性能之间存在显著的正相关关系，验证了该方法的有效性，并将在开源平台提供相关工具代码以支持进一步研究。
### Conclusion
大量T2V微调实验验证了优化字幕质量对于提升视频生成性能的有效性。为此，我们构建了一个专门针对T2V需求的新基准——VC4VG-Bench，并将所有的基准工具和代码开源，在这个平台上支持更多学者和研究者更好地理解和改进T2V生成技术。
## 551. `cs.CV` - ChartMuseum: 测试大型视觉语言模型的视觉推理能力 [PDF](https://arxiv.org/pdf/2505.13444), [HTML](https://arxiv.org/abs/2505.13444)
### Authors
Liyan Tang,Grace Kim,Xinyu Zhao,Thom Lake,Wenxuan Ding,Fangcong Yin,Prasann Singhal,Manya Wadhwa,Zeyu Leo Liu,Zayne Sprague,Ramya Namuduri,Bodun Hu,Juan Diego Rodriguez,Puyuan Peng,Greg Durrett
### Background
大型视觉语言模型（LVLMs）在图表理解方面面临独特的挑战，需要集成复杂的文本和视觉推理能力。然而，当前的LVLMs在这方面存在明显的技能不平衡，尤其是在难以通过文本执行的视觉推理方面表现不佳。研究团队通过一个仅能通过视觉推理解决的合成数据集进行案例研究，发现随着视觉复杂性的增加，模型的性能急剧下降，而人类的表现依然稳定。
### Innovation
团队引入了ChartMuseum，这是一个新的图表问答（QA）基准测试，包含1,162个专家标注的问题，涵盖多种推理类型，从184个实际来源收集的真实图表中挑选出来，旨在评估复杂的视觉和文本推理能力。此基准测试展现了模型和人类性能之间的显著差距，同时有效地区分了模型能力：尽管人类的准确率为93%，但性能最好的模型Gemini-2.5-Pro仅达到63.0%，而领先的开源LVLM Qwen2.5-VL-72B-Instruct也仅达到38.5%。此外，对于主要依赖视觉推理的问题，所有模型的表现从文本推理问题中下降了35%-55%。
### Conclusion
图表Museum基准测试揭示了现有LVLMs在某些视觉推理类别上的困难，表明这些模型在处理复杂视觉和文本推理时存在局限性。
## 552. `cs.CV` - ReCon-GS: 保留连续性的高效率紧凑动态场景重建与流式传输的高斯序列 [PDF](https://arxiv.org/pdf/2509.24325), [HTML](https://arxiv.org/abs/2509.24325)
### Authors
Jiaye Fu,Qiankun Gao,Chengxiang Wen,Yanmin Wu,Siwei Ma,Jiaqi Zhang,Jian Zhang
### Background
在线自由视角视频（FVV）重建面临每帧优化缓慢、运动估计不一致以及存储需求不可持续的问题。
### Innovation
提出了一种名为ReCon-GS的新型存储意识框架，能够实现高保真的在线动态场景重建和实时渲染。该框架动态分配多级锚定高斯模型，以适应密度变化来捕捉帧间几何变形，并通过层级重构策略和变形继承确保局部运动的表达性和时序一致性。同时，该机制还能够根据不同层级的密度动态调整，灵活地平衡重建保真度与内存使用之间的关系，从而提高训练效率并在同等渲染质量下减少了50%以上的存储需求，优于现有的最先进的方法。
### Conclusion
实验结果表明，与最先进的方法相比，ReCon-GS在训练效率上提高了大约15%，并且在鲁棒性和稳定性方面表现更优。此外，在等同的渲染质量下，ReCon-GS的内存需求比现有最先进的方法减少了超过50%。
## 553. `cs.CV` - FASL-Seg: 手术场景中的解剖结构和器械分割 [PDF](https://arxiv.org/pdf/2509.06159), [HTML](https://arxiv.org/abs/2509.06159)
### Authors
Muraam Abdel-Ghani,Mahmoud Ali,Mohamed Ali,Fatmaelzahraa Ahmed,Muhammad Arsalan,Abdulaziz Al-Ali,Shidin Balakrishnan
### Background
随着机器人微创手术的日益流行，基于深度学习的手术培训成为研究的重点领域。深度学习模型可以帮助理解手术场景中的组件，但现有的大多数工作主要关注手术工具，而忽略了解剖结构。此外，目前最先进（SOTA）的模型难以在捕捉高层次上下文特征和低层次边缘特征之间取得平衡。
### Innovation
本文提出了一种特征自适应空间定位模型（FASL-Seg），通过两个不同的处理分支，即低层特征投影（LLFP）和高层特征投影（HLFP）分支，分别处理不同分辨率下的特征，从而能够精确分割解剖结构和手术器械，解决捕捉高层次和低层次特征之间的平衡问题。
### Conclusion
FASL-Seg模型在EndoVis18和EndoVis17手术分割基准数据集上的实验结果显示，在部分和解剖结构分割上达到72.71%的平均交并比（mIoU），比现有最先进模型提高了5%。在工具类型分割上分别达到了85.61%和72.78%的mIoU，总体性能超过了SOTA，在两个数据集上都达到了可比较的每个类别的SOTA结果，并在不同的解剖结构和器械类别中表现出一致的性能。这显示了对不同特征分辨率的不同处理流的有效性。
## 554. `cs.CV` - Neural Atlas Graphs for Dynamic Scene Decomposition and Editing [PDF](https://arxiv.org/pdf/2509.16336), [HTML](https://arxiv.org/abs/2509.16336)
### Authors
Jan Philipp Schneider,Pratik Singh Bisht,Ilya Chugunov,Andreas Kolb,Michael Moeller,Felix Heide
### Background
高分辨率动态场景表示的学习是开放性问题，应用场景广泛，从自动驾驶到创意编辑。目前最成功的做法是在可编辑性和支持场景复杂性之间做出权衡：神经马赛克表示动态场景为两个变形的图像层（前景和背景），在二维上可编辑，但当多个物体相互遮挡和交互时会失效。相比之下，场景图模型通过使用自动驾驶数据集的注释数据（如掩码和边界框）来捕捉复杂的3D空间关系，但其隐式的体积节点表示难以在视图一致性下进行编辑。
### Innovation
我们提出了神经马赛克图（NAGs），这是一种混合高分辨率场景表示，每个图节点是一个视图依赖的神经马赛克，既支持2D外观编辑，又支持3D场景元素的顺序和定位。NAGs在测试时进行拟合，在Waymo Open Dataset上实现了最先进的定量结果（PSNR提升5 dB），并在高分辨率和视觉质量下实现了环境编辑，生成了新的背景和车辆外观的假想驾驶场景。此外，该方法还能够在驾驶场景之外泛化，并在DAVIS视频数据集上与近期抠图和视频编辑基线相比，PSNR提升了超过7 dB。
### Conclusion
NAGs结合了可编辑性和复杂场景支持，解决了动态场景分解与编辑的挑战，显著提升量化指标，并在多种场景中展示了其多样性和实用性。
## 555. `cs.CV` - GCVAMD：一种改进的因果VAE模型用于因年龄相关性黄斑变性风险因素的检测与预测 [PDF](https://arxiv.org/pdf/2510.02781), [HTML](https://arxiv.org/abs/2510.02781)
### Authors
Daeyoung Kim
### Background
年龄相关性黄斑变性（AMD）一直是眼科永久性视力损害的主要原因之一。尽管已经开发了诸如抗VEGF药物或光动力疗法等治疗方法来减缓AMD的退化过程，但至今没有特定的治疗方法能够逆转由AMD引起的视力丧失。因此，在早期阶段检测患者视网膜中的AMD风险因素或AMD本身至关重要，可以减少视力损害的可能性。现有的基于深度学习的方法在区分AMD视网膜与正常视网膜方面表现良好，这些方法如基于注意力机制的CNN和基于GradCAM的XAI分析，在眼底光学相干断层扫描（OCT）中取得了显著成功，有助于辅助眼科医生进行AMD的诊断和分析。然而，现有的研究主要集中在预测性能上，而未能深入探讨AMD的病理机制或潜在因果机制，这限制了对具体因素的干预分析，甚至可能导致不准确的决策。
### Innovation
本文介绍了新型因果AMD分析模型GCVAMD，其采用了一种改进的因果VAE（CausalVAE）方法，可以从原始OCT图像中提取潜在的因果因素。该模型通过考虑AMD检测中的因果关系，能够执行治疗仿真或针对主要风险因素（如硬性渗出物和新生血管化）的干预分析，同时返回具有信息性的潜在因果特征，这些特征能够提升后续任务的性能。
### Conclusion
通过GCVAMD，能够识别与AMD因果机制相关的硬性渗出物状态和新生血管化状态，进而可用于AMD检测（分类）到干预分析的各种任务。
## 556. `cs.CV` - DiffVLA++: 通过度量引导对齐连接认知推理和端到端驾驶 [PDF](https://arxiv.org/pdf/2510.17148), [HTML](https://arxiv.org/abs/2510.17148)
### Authors
Yu Gao,Anqing Jiang,Yiru Wang,Wang Jijun,Hao Jiang,Zhigang Sun,Heng Yuwen,Wang Shuo,Hao Zhao,Sun Hao
### Background
传统的端到端（E2E）驾驶模型虽然能够生成物理上可信的轨迹，但在处理长尾情况时常常表现不佳，这是因为缺乏关于周围环境的认知理解。相比之下，视觉-语言-行动（VLA）模型可以利用世界知识来处理复杂的情况，但由于其有限的三维推理能力，可能会导致不可行的动作。因此，本文提出了一种增强的自主驾驶框架——DiffVLA++，通过度量引导对齐将认知推理与E2E规划明确地连接起来。
### Innovation
DiffVLA++框架包含三个主要组成部分：直接生成语义驱动轨迹的VLA模块、确保物理可行性的密集轨迹词汇E2E模块，以及通过度量引导轨迹评分器将VLA和E2E模块的输出对齐。这一对齐过程整合了两种模块的优势，实现了在现有ICCV 2025自主挑战赛领导板上的EPDMS成绩为49.12。
### Conclusion
DiffVLA++通过度量引导对齐成功地将认知推理与端到端驾驶规划结合，提升了驾驶模型在复杂和长尾情况下的性能。
## 557. `cs.CV` - Test-Time Adaptation中的缓冲层 [PDF](https://arxiv.org/pdf/2510.21271), [HTML](https://arxiv.org/abs/2510.21271)
### Authors
Hyeongyu Kim,Geonhui Han,Dosik Hwang
### Background
近年来，Test Time Adaptation (TTA) 方面的最新进展主要集中在更新归一化层以适应测试领域。然而，依赖于归一化的适应方法存在关键性挑战。首先，像批量归一化（BN）这样的归一化层对小批次大小非常敏感，导致统计数据不稳定且不准确。此外，基于归一化的适应方法受限于预训练模型的结构，因为它依赖于训练时的统计数据，这些统计特征在面对未见过的领域时可能无法很好地泛化。这些问题限制了归一化基础的TTA方法的有效性，特别是在领域变化较大的情况下。
### Innovation
本文提出了一种基于缓冲层概念的新范式，以解决归一化层更新的基本局限性。与现有方法修改模型的核心参数不同，我们的方法保留了预训练主干的完整性，从而在在线适应过程中减轻灾难性遗忘的风险。通过全面的实验，我们证明了该方法不仅在减轻领域变化和增强模型鲁棒性方面优于传统方法，而且对抗遗忘表现出很强的抵抗力。此外，我们的缓冲层是模块化的，可以无缝集成到几乎所有现有的TTA框架中，从而在各种架构中实现一致的性能提升。
### Conclusion
这些发现验证了在实际领域适应场景中提出解决方案的有效性和多样性。代码可在以下链接获取：this https URL.
## 558. `cs.CV` - 基于图像的物理嵌入神经网络（PINN）在意大利面桥梁载荷预测中的预见性 [PDF](https://arxiv.org/pdf/2510.23117), [HTML](https://arxiv.org/abs/2510.23117)
### Authors
Omer Jauhar Khan,Sudais Khan,Hafeez Anwar,Shahzeb Khan,Shams Ul Arifeen
### Background
物理嵌入神经网络（PINNs）因其将物理定律嵌入到深度学习模型中的能力而受到关注，特别是在具有有限数据的结构工程任务中尤为重要。本文旨在探索PINNs在预测小型意大利面桥梁重量中的应用，这对于理解简化的结构模型的载荷限制和潜在失效模式具有重要意义。研究通过结合物理约束优化预测模型，提出了新的框架。实验数据集包含15座实际桥梁，并通过手动或计算机视觉方法收集输入的结构参数。该研究展示了PINNs即使在数据有限的情况下也能提供可靠的结构重量估计，有助于指导轻型桥梁设计中的早期失效分析。
### Innovation
本文引入了一种新型架构——物理嵌入柯尔莫哥洛夫-阿诺德网络（PIKAN），它结合了通用函数近似理论与物理洞见，改进了标准PINNs模型。研究通过集成基于图像的物理约束，提高了模型预测的性能。研究表明，在使用有限数据的情况下，通过PIKAN模型可以有效估算结构重量。
### Conclusion
通过PINNs的合理应用，即使数据有限，也能提供可靠的结构重量预测，本文提供的网络框架具有重要的应用价值。此外，还提供了基于网络的输入和预测接口，可以方便地对参数进行输入和获取预测结果。这为早期阶段轻型桥梁设计中的失效分析提供了有力支持。
## 559. `cs.LG` - HiMAE: 层级遮蔽自动编码器发现可穿戴时间序列中特定分辨率的结构 [PDF](https://arxiv.org/pdf/2510.25785), [HTML](https://arxiv.org/abs/2510.25785)
### Authors
Simon A. Lee,Cyrus Tanade,Hao Zhou,Juhyeon Lee,Megha Thukral,Minji Han,Rachel Choi,Md Sazzad Hissain Khan,Baiying Lu,Migyeong Gwak,Mehrab Bin Morshed,Viswam Nathan,Md Mahbubur Rahman,Li Zhu,Subramaniam Venkatraman,Sharanya Arcot Desai
### Background
可穿戴传感器提供了丰富的生理时间序列数据，但其预测潜力尚不清楚。研究团队认为，时间分辨率是表示学习的基础轴，不同临床和行为结果依赖于不同尺度的结构。为验证这一假设，他们引入了HiMAE（层级遮蔽自动编码器），结合了遮蔽自动编码和层级卷积编码器解码器。
### Innovation
HiMAE是一个自我监督框架，能够生成多分辨率嵌入，系统性评估哪些时间尺度包含预测信号，将分辨率从超参数转变为解释性探针。在分类、回归和生成基准测试中，HiMAE持续优于压缩尺度的最新基础模型，同时尺寸小得多。HiMAE是一个高效的表示学习方法，能够完全在可穿戴设备上运行，在智能手表级别CPU上实现亚毫秒级推理，实现了真正的边缘推理。
### Conclusion
HiMAE不仅是一个高效的自我监督学习方法，还是一个探索可穿戴健康中敏感尺度结构的发现工具。
## 560. `cs.CV` - CronusVLA：通过多帧视觉-语言-动作建模迈向高效稳健操作 [PDF](https://arxiv.org/pdf/2506.19816), [HTML](https://arxiv.org/abs/2506.19816)
### Authors
Hao Li,Shuai Yang,Yilun Chen,Xinyi Chen,Xiaoda Yang,Yang Tian,Hanqing Wang,Tai Wang,Dahua Lin,Feng Zhao,Jiangmiao Pang
### Background
近年来，基于预训练视觉-语言模型（VLMs）的视觉-语言-动作（VLA）模型在机器人操作方面取得了显著的性能，但这些模型仍然受限于单帧图像范式，未能充分利用多帧历史提供的时间信息。直接将多帧直接输入视觉-语言模型的主干结构会导致大量的计算开销和推理延迟，从而影响了性能。针对这一问题，我们提出了CronusVLA统一框架，该框架通过一个两阶段流程将单帧VLA模型扩展到多帧范式：第一阶段通过大尺度的表象数据集进行单帧预训练，实现了视觉-语言动作的有效基础；第二阶段通过对已预训练的视觉-语言主干的预测从离散词汇转换为可学习特征，通过特征分块聚合历史信息，从而解决了多帧建模的现有挑战，提高了性能和观察能力的稳健性。为了评估其在时间、空间扰动下的鲁棒性，我们引入了SimplerEnv-OR基准，该基准包含24种观测扰动和120种严重程度等级。在三种实体化的模拟和真实环境中进行的实验数据显示，CronusVLA在SimplerEnv中达到了领先性能，鲁棒性提高了26.8%，达到了最高鲁棒性得分。这些结果证明了视觉-语言-动作模型在操作中采用高效多帧适应的潜力。
### Innovation
CronusVLA提出了一种新的框架，通过引入两个阶段训练流程（单帧预训练和多帧后训练），实现了从单帧到多帧的视觉-语言-动作模型扩展。第一阶段通过大尺度的表象数据集进行单帧预训练，建立有效的视觉-语言基础；第二阶段通过特征分块和从离散词汇转换为可学习特征，使视觉-语言主干能够适应多帧历史信息的预测。这种创新框架解决了多帧建模中的计算开销和推理延迟问题，提高了模型的性能和观察鲁棒性。此外，还引入了SimplerEnv-OR用于评估模型在时间、空间扰动下的鲁棒性。
### Conclusion
实验证明，CronusVLA在模拟和真实环境中的操作性能显著提升，特别是在SimplerEnv中的成功率达到70.9%，与OpenVLA相比，成功提升了26.8%，在SimplerEnv-OR基准中取得了最高的鲁棒性得分。这些结果表明，视觉-语言-动作模型中有效利用多帧信息的适应性框架有望在未来变得更加高效和稳健，为其在真实世界的广泛应用打开了新的可能性。
## 561. `cs.LG` - Kolmogorov-Arnold网络（KANs）从业者指南 [PDF](https://arxiv.org/pdf/2510.25781), [HTML](https://arxiv.org/abs/2510.25781)
### Authors
Amir Noorizadegan,Sifan Wang,Leevan Ling
### Background
Kolmogorov-Arnold网络（KANs）最近作为传统多层感知机（MLPs）的有前景替代方案出现，受到柯尔莫哥洛夫-阿诺尔德表示定理的启发。KANs的特点是利用可学习的一元基函数替代节点上的固定激活函数，这增强了其表达能力和可解释性。本文旨在提供一个系统而全面的KAN概览，不仅进行简单的性能比较，更从理论基础、架构变体和实战实现策略三个方面进行了结构化的综合分析。通过汇集和分类大量开源实现，本文描绘了支持KAN开发的丰富多彩的生态系统。文章首先填补了KANs和MLPs之间的概念空白，明确了它们的正式等效性，并强调了KAN表示法在参数效率上的优势。
### Innovation
文章围绕KANs剖析了基函数的关键作用，调研了B-样条、切比雪夫和雅可比多项式、ReLU复合函数、高斯RBF和傅里叶级数等多种选择，并分析了它们在光滑性、局部性和计算成本等方面的权衡。此外，文章按提高准确度、效率和正则化的技术路标分类了最近的进展，包括物理信息损失设计、自适应采样、区分解、混合架构和处理不连续性的专门方法。
### Conclusion
本文提供了一个实用的“选择你的KAN”指南，帮助实践者选择合适的架构，最后指出当前研究的空缺，并随论文附带的GitHub仓库提供了进一步参考。
## 562. `cs.LG` - 利用自适应偏差学习实现多代理系统中信息最优结合 [PDF](https://arxiv.org/pdf/2510.25793), [HTML](https://arxiv.org/abs/2510.25793)
### Authors
Siavash M. Alamouti,Fay Arjomandi
### Background
现代多代理系统，从监测关键基础设施的传感器网络到聚合人类智力的众包平台，在环境条件变化时可能会遭受显著的性能下降，这是由于系统偏差造成的。当前的方法要么忽视这些偏差，导致决策不准确，要么需要昂贵且难以实施的校准程序。这种性能差距具有实际影响：不准确的环境监控、不可靠的财务预测以及人类判断的错误汇总。本文探讨了在什么情况下可以学习并纠正这些未知的偏差以恢复近乎最优的性能，在什么情况下这样的学习是徒劳的这一基本问题。
### Innovation
本文开发了一种理论框架，将偏差分解为可学习的系统性成分为可学习的系统性成分和无法减少的随机成分，并引入了“学习率比例”这一概念，即从可观测协变量中可预测的偏差方差的比例。这一比例决定了某个系统是否值得进行偏差学习。本文证明了通过学习偏差所能实现的性能提升实际上被这一学习率比例所限制，为系统设计者提供了定量的指导，以决定是否应投资于偏差学习而非更简单的方案。同时，提出了自适应偏差学习和优化组合（ABLOC）算法，在迭代学习偏差修正转换的同时通过解析解决方案优化组合权重，确保收敛到理论限制。
### Conclusion
实验验证表明，拥有高学习率比例的系统能够恢复显著的性能提升（我们例子中的提升达到理论最大改善的40%-70%），而低学习率比例的系统几乎没有好处，验证了我们用于实际部署决策的诊断标准。
## 563. `cs.LG` - SHA-256 Infused Embedding-Driven Generative Modeling of High-Energy Molecules in Low-Data Regimes [PDF](https://arxiv.org/pdf/2510.25788), [HTML](https://arxiv.org/abs/2510.25788)
### Authors
Siddharth Verma,Alankar Alankar
### Background
高能材料对于推进和防御领域至关重要，但其发现受到实验数据限制和测试设施访问限制的制约。这项研究提出了通过结合长短期记忆网络（LSTM）进行分子生成和注意图神经网络（GNN）进行性质预测的方法，以组合方式寻找高能分子。这项工作的背景在于现有研究中高能材料的发现受制于数据量不足和技术手段有限的问题，亟需新的方法来突破这一限制，提高高能分子的发现效率和多样性。
### Innovation
该研究提出了一种新的嵌入空间构建策略，将固定SHA-256嵌入与部分可训练表示相结合。与传统的正则化技术不同，这种方法改变了表示的基础，变形了分子输入空间，无需预训练便可达到67.5%的有效性和37.5%的新颖性。生成的化合物库平均塔曼托系数为0.214，显示出该框架能够生成一个多样化的化学空间。研究中还发现了37种新型超速爆炸物，其预测的爆炸速度超过9公里/秒。这一创新通过机器学习的方法在数据稀缺的背景下高效生成了新的高能分子，显著提高了发现过程中的多样性和精确度。
### Conclusion
该研究展示了一种新颖的方法，通过结合LSTM网络和GNN预测高能分子的性质，为低数据集环境下高能分子的生成提供了新的思路。生成的高能分子库表现出较好的多样性，且有效识别出新的高能爆炸物，为推进和防御领域的高能材料研究开辟了新的可能性。
## 564. `cs.LG` - 推理的动力学：链式思考如何影响变换器中的学习？ [PDF](https://arxiv.org/pdf/2510.25791), [HTML](https://arxiv.org/abs/2510.25791)
### Authors
Zihan Pengmei,Costas Mavromatis,Zhengyuan Shen,Yunyi Zhang,Vassilis N. Ioannidis,Huzefa Rangwala
### Background
链式思考（CoT）监督可以显著提高变换器的表现，但模型如何学习遵循和受益于CoT的具体机制仍不清楚。本文通过预训练变换器解决可调算法复杂性和可控制数据组成的符号推理任务，从归纳现象的角度探究这些学习动态，以研究泛化能力。模型在两种设置下进行训练：仅产生最终答案，或在回答之前发出明确的CoT跟踪记录。研究表明，虽然CoT通常可以提高任务表现，但其益处依赖于任务的复杂性。通过对训练步数准确率的对数建模为三参数逻辑曲线，揭示学习速度和形状如何随任务复杂性、数据分布及CoT监督的存在而变化。发现了一个短暂的跟踪不忠实阶段：在训练早期，模型常能产生正确答案同时跳过或与CoT步骤发生矛盾，之后才开始与答案对齐其推理跟踪。
### Innovation
本文提出了一种动力学建模框架来理解变换器学习，发现CoT可以加速泛化但仍无法克服复杂度高的任务，如列表交集。CoT改变了内部变换器计算机制，追踪忠度作为一种随着训练动态出现的属性。
### Conclusion
本研究展示了CoT可以加速泛化，但在更高算法复杂度的任务上仍存在限制；提出了动力学建模框架以了解变换器学习；确定了追踪忠实性作为一种在训练过程中动态出现的属性；并且展示了CoT在机制上改变了内部变换器的计算过程。
## 565. `cs.LG` - Mixture-of-Experts Operator Transformer for Large-Scale PDE Pre-Training [PDF](https://arxiv.org/pdf/2510.25803), [HTML](https://arxiv.org/abs/2510.25803)
### Authors
Hong Wang,Haiyang Xin,Jie Wang,Xuanze Yang,Fei Zha,Huanshuo Dong,Yan Jiang
### Background
预训练已被证明在解决神经运算器求解偏微分方程（PDE）问题时的数据稀缺性和性能限制上是有效的。然而，由于PDE数据集在方程类型上的多样性，导致混合训练误差高。此外，通过增加网络宽度或深度来扩展参数的密集预训练模型在推理时会带来显著的成本。
### Innovation
我们提出了一个名为MoE-POT的新型专家混合预训练运算器转换器，它是一个稀疏激活的架构，能够在控制推理成本的同时高效地扩展参数。模型采用了逐层路由器门控网络，在推理时动态选择4个路由专家中的16位专家网络，使模型能够专注于方程特异性特征。同时，还集成了2个共享专家，以捕捉PDE的共性，并减少路由专家之间的冗余。最终输出是所有激活专家结果的加权平均。
### Conclusion
我们使用30M到0.5B参数在6个公共PDE数据集上对模型进行预训练。具有90M激活参数的模型在零样本误差方面比现有具有120M激活参数的模型降低了最高40%。此外，我们还进行了可解释性分析，表明可以通过路由器门控网络的决策推断数据集类型，验证了MoE架构的合理性和有效性。
## 566. `cs.LG` - 大规模按需拼车系统中基于仿真指导的非短视匹配与再平衡 [PDF](https://arxiv.org/pdf/2510.25796), [HTML](https://arxiv.org/abs/2510.25796)
### Authors
Farnoosh Namdarpour,Joseph Y. J. Chow
### Background
拼车是一种服务，乘客可以在同一行程中共享乘车。这种服务可以降低成本，减少交通拥堵和环境影响。然而，其主要限制是决策的短视，忽视了调度决策的长期效果。为了改进这一点，本文提出了一种基于仿真指导的强化学习（Reinforcement Learning，RL）方法。虽然在ride-hailing系统中RL已有广泛研究，但在拼车系统中的应用较少。本文通过将拼车仿真嵌入学习机制中，从ride-hailing扩展到ride-pooling，延长了学习和规划的视角。此外，还提出了一个补充策略来平衡闲置车辆，并通过模拟经验采用n步时差学习来推导时空状态值，评估非短视策略的有效性。研究数据显示，与短视策略相比，非短视匹配策略能使服务率提高最多8.4%，同时减少乘客的车内时间和等待时间，降低25%以上的车队规模，从而为运营商带来更多成本节约。重新分配操作的纳入将等待时间减少最多27.3%，车内时间减少12.5%，服务率提高15.1%。
### Innovation
本文提出了一种基于仿真指导的强化学习方法，将拼车仿真嵌入学习机制中，以实现非短视决策。还提出了一个补充策略来平衡闲置车辆。通过使用n步时差学习，研究团队得出了时空状态值，并利用纽约市出租车请求数据评估了非短视政策的有效性。同时，该策略在降低成本和改善乘客体验方面也取得了显著成效。
### Conclusion
非短视匹配策略不仅能提高服务率，减少乘客等待和车内时间，还能显著减少车队规模，减轻交通拥堵和环境污染，从而带来较高的成本效益。重新分配操作的引入进一步提高了系统性能。这项研究为大规模按需拼车系统的优化提供了新思路。
## 567. `cs.LG` - ScaleDiff：通过高效且模型无关的扩散模型实现高分辨率图像合成 [PDF](https://arxiv.org/pdf/2510.25818), [HTML](https://arxiv.org/abs/2510.25818)
### Authors
Sungho Koh,SeungJu Cha,Hyunwoo Oh,Kwanyoung Lee,Dong-Jin Kim
### Background
文本到图像的消散模型在生成超过其训练分辨率的图像时常常表现出退化的性能。近期的无训练方法可以缓解这一限制，但它们通常需要大量的计算资源或不兼容最近的扩散变换器模型。
### Innovation
我们提出了ScaleDiff，这是一种模型无关且高效的框架，用于在没有额外训练的情况下扩展预训练扩散模型的分辨率。核心组件是高效机制Neighborhood Patch Attention（NPA），其通过非重叠补丁减少了自注意力层中的计算冗余。我们还结合了Latent Frequency Mixing（LFM）以更好地生成细部，并应用了结构引导以在去噪过程中增强全局结构。实验结果表明，ScaleDiff在图像质量和推理速度方面达到了训练无方法的最先进的性能。
### Conclusion
实验结果表明，ScaleDiff在基于U-Net和扩散变换器架构的无训练方法中，在图像质量和推理速度方面均达到了最先进的性能。
## 568. `cs.LG` - Metis-SPECS: 通过自我提炼的偏好驱动冷启动分解多模态学习 [PDF](https://arxiv.org/pdf/2510.25801), [HTML](https://arxiv.org/abs/2510.25801)
### Authors
Kun Chen,Peng Shi,Haibo Qiu,Zhixiong Zeng,Siqi Yang,Wenji Mao,Lin Ma
### Background
近年来，具有可验证奖励的强化学习（RL）推动了一波“MLLM-r1”方法，将RL引入视觉语言模型。大多数代表性范式最初是从冷启动开始的，通常使用监督微调（SFT）来初始化策略，然后再进行RL。然而，基于SFT的冷启动方法将推理理念与任务解决和输出格式交织在一起，可能导致指令式过拟合，削弱了分布外泛化能力，最终影响下游RL的表现。
### Innovation
本文重新审视了冷启动方法的训练方法和数据构建方式，并引入了通用性因子（GF）系数来量化不同方法下的泛化能力。实验研究表明，基于偏好的训练方法（例如DPO）在冷启动中比基于SFT的方法有更好的泛化能力。为此，本文提出了SPECS（Self-distilled, Preference-based Cold Start）自提炼、偏好驱动冷启动框架，该框架通过自我提炼生成内省性偏好数据对，避免依赖大型教师或手动标注；执行基于偏好的训练，专注于学习简单的、更具转移性的表面形式标准（格式、结构、风格），而不是记忆内容；最后将具有可验证奖励的结果交给RL进行深入推理。
### Conclusion
在多个多模态基准上的实验结果显示，本文提出的解耦学习框架在多个基准上均表现出一致的性能提升，相较于强基线提高了MEGA-Bench 4.1%和MathVista 12.2%。另外，实验结果表明，SPECS框架有助于减少分布内“停滞不前”现象，提高探索性，稳定训练过程，并提高性能上限。
## 569. `cs.LG` - PRESTO: Preimage-Informed Instruction Optimization for Prompting Black-Box LLMs [PDF](https://arxiv.org/pdf/2510.25808), [HTML](https://arxiv.org/abs/2510.25808)
### Authors
Jaewon Chu,Seunghun Lee,Hyunwoo J. Kim
### Background
大型语言模型（LLMs）在多个领域取得了显著的成果，这主要得益于它们表现出的强大的指令遵循能力。因此，人们越来越关注如何优化黑色盒模型指令，尽管这些模型内部参数不可见，但由于其出色的性能，它们得到了广泛应用。当前优化指令的方法是通过使用白色盒模型生成来自优化软提示的候选指令。然而，这种方法往往导致针对不同软提示生成相同的指令，产生重复的查询。过往研究认为这种一对多映射不利于优化效率，而本文将其重新理解为一种可以加速优化过程的有用先验知识。
### Innovation
本文提出了PRESTO（Preimage-informed inSTruction Optimization），一种新的框架，利用软提示的预图像结构实现高效优化。PRESTO框架包含三个关键组件：(1)分数共享，与预图像中的所有软提示共享评估分数；(2)基于预图像的初始化，使用预图像信息选择可以最大化搜索空间覆盖的初始数据点；(3)分数一致性正则化，确保每个预图像内的预测一致性。PRESTO能够在相同的查询预算下，有效获取14倍的评分数据，从而实现更高效的优化。
### Conclusion
在33项指令优化任务上的实验结果表明，PRESTO表现出优于其他方法的性能。相关代码已公开。
## 570. `cs.LG` - MedVLSynther: 从医学文档中使用生成器-验证器LMMs 合成高质量视觉问答 [PDF](https://arxiv.org/pdf/2510.25867), [HTML](https://arxiv.org/abs/2510.25867)
### Authors
Xiaoke Huang,Ningsen Wang,Hui Liu,Xianfeng Tang,Yuyin Zhou
### Background
大型多模态模型（LMMs）现在可以解决需要在图像和文本之间进行联合推理的医学问题。然而，训练通用的医学问答（VQA）系统受到缺乏大型、开放且高质量数据集的阻碍。
### Innovation
本文介绍了MedVLSynther，这是一种由生成器和验证器引导的框架，能够直接从开放的生物医学文献中生成高质量的多选VQA项目，同时基于这些文献中的图表、图注和文本参考。使用这种方法，从PubMed Central获得了MedSynVQA数据集，包含13,087个筛选问题和14,803幅图像，并使用验证可验证奖励的开放权重LMMs在六个医学VQA基准测试中取得了更好的表现。
### Conclusion
MedVLSynther框架通过在整个过程中使用开放文献和开放权重模型，提供了审计、可追踪和隐私保护的医学VQA训练数据生成途径，且生成和验证都是必要的，更多的验证数据有助于模型性能的提升。
## 571. `cs.LG` - MemEIC：迈向连续和组合知识编辑 [PDF](https://arxiv.org/pdf/2510.25798), [HTML](https://arxiv.org/abs/2510.25798)
### Authors
Jin Seong,Jiyun Park,Wencke Liermann,Hongseok Choi,Yoonji Nam,Hyun Kim,Soojong Lim,Namhoon Lee
### Background
信息的动态性质要求不断更新大型视听语言模型（LVLMs）。虽然最近的知识编辑技术表明了有希望的方向，但它们往往集中在孤立编辑单一模态（视觉或语言）。这种常见的做法忽视了LVLMs的内在多模态性和知识更新的持续性，可能导致在考虑模态之间的相互作用以及需要持续的知识精炼时编辑效果不佳。
### Innovation
提出了一种名为MemEIC的新方法，用于LVLMs的持续和组合知识编辑（CCKE）。MemEIC允许顺序编辑视觉和文本知识。该方法采用混合外部-内部编辑器，配备用于跨模态证据检索的双重外部记忆和使每种模态参数更新分离的双重LoRA适配器。关键组件是一个基于大脑的启发式知识连接器，在组合推理时被选择性激活，以跨模态整合信息。
### Conclusion
实验表明，MemEIC在复杂多模态问题上显著提高了性能，有效地保留了先前编辑的内容，为LVLMs的CCKE设定了一个新的基准。
## 572. `cs.LG` - FreIE: 预神经网络在时间序列任务中的低频光谱偏见 [PDF](https://arxiv.org/pdf/2510.25800), [HTML](https://arxiv.org/abs/2510.25800)
### Authors
Jialong Sun,Xinpeng Ling,Jiaxuan Zou,Jiawen Kang,Kejia Zhang
### Background
时间序列数据的固有自相关性给多变量时间序列预测带来了持续挑战。最近，普遍采用的方法是将频率域信息纳入以辅助长期预测任务。许多研究者独立地观察到神经网络中的光谱偏见现象，即模型倾向于先拟合低频信号再拟合高频信号。然而，这些观察往往被归因于研究人员设计的具体架构，而不是将其视为模型普遍特征。为了统一理解长时间序列预测中光谱偏见现象，我们进行了广泛的实验证明现有主流模型中的光谱偏见现象普遍存在于各种模型中。
### Innovation
我们提出了FreLE（频域损失增强）算法，通过显性和隐性频率正则化增强模型泛化。FreLE是一个即插即用的模型损失函数单元。大量实验验证了FreLE的优越性能。
### Conclusion
我们的研究表明几乎所有模型都存在光谱偏见现象。我们提出FreLE算法通过频率正则化来缓解光谱偏见，大量实验表明其性能优于现有方法。
## 573. `cs.LG` - 使用代理转移因果效应 [PDF](https://arxiv.org/pdf/2510.25924), [HTML](https://arxiv.org/abs/2510.25924)
### Authors
Manuel Iglesias-Alonso,Felix Schur,Julius von Kügelgen,Jonas Peters
### Background
本文考虑在多领域环境中估计因果效应的问题。感兴趣的因果效应受到未观察到的共因的混淆，且在不同领域中会发生变化。假设我们能访问隐藏共因的代理变量，并且所有变量都是离散或分类的。
### Innovation
本文提出了一种在目标领域估计因果效应的方法，假设在目标领域内只能观测到代理变量。即使处理变量和响应变量是连续的，也能证明识别性。引入了两种估计技术，证明了其一致性，并推导了置信区间。这些理论结果得到了模拟研究和一个关于网站排名对消费者选择的因果效果的现实世界例子的支持。
### Conclusion
在给定条件下的情况下，证明了因果效果的可识别性。提出了两种估计技术并证明了一致性，并推导出置信区间。通过模拟研究和实际例子验证了理论结果的有效性。
## 574. `cs.LG` - 任务驱动表示用于杂乱数据池的主动学习 [PDF](https://arxiv.org/pdf/2510.25926), [HTML](https://arxiv.org/abs/2510.25926)
### Authors
Kianoosh Ashouritaklimi,Tom Rainforth
### Background
主动学习在处理杂乱且未整理的数据池时特别有用，这些数据池中的数据点对目标任务的相关性各不相同。目前最新的主动学习方法依赖于固定且未监督的数据池表示，通过修改获取函数来优化。然而，这样的模型设置可能会削弱其在处理杂乱数据池时的效果，因为固定的未监督表示可能无法捕获与任务相关的重要信息。
### Innovation
该研究提出了一种新的方法，即在主动学习过程中使用任务驱动表示，这些表示是周期性地根据已收集的标签进行更新。提出了两种具体的学习表示的方法：一种是直接学习半监督表示，另一种是基于初始未监督表示的监督微调。这两种方法在实际性能上都显著优于使用未监督或预训练表示的方法。
### Conclusion
实验结果表明，使用任务驱动表示能够显著提高处理杂乱数据池的主动学习方法的性能。
## 575. `cs.LG` - 图上的拓扑感知主动学习 [PDF](https://arxiv.org/pdf/2510.25892), [HTML](https://arxiv.org/abs/2510.25892)
### Authors
Harris Hardiman-Mostow,Jack Mauro,Adrien Weihs,Andrea L. Bertozzi
### Background
本文针对有限标注预算下的探索与利用的核挑战，提出了一种图拓扑方法来指导主动学习。现有方法常依赖于手调的启发式方法来平衡探索与利用。本文通过引入平衡法曼曲率（BFC）为基础的核心区域集（coreset）构建算法，用于初始标注的选择，并通过数据驱动的终止准则来判断是否充分探索了图。同时，本文的方法还包括一种局部图重布策略，该策略能够动态触发从探索到利用的转变，并利用多尺度信息提升标记传播效率，同时保持稀疏性。实验结果表明，本文方法在低标签率下始终优于现有的基于图的半监督基准方法。
### Innovation
本文创新地提出了一个基于图拓扑的主动学习方法，使用平衡法曼曲率（BFC）算法来选择可以反映图簇结构的代表初始标签，并通过数据驱动的停止条件来适时终止探索过程。此外，引入了多尺度信息的局部图重布策略来提高标签传播效率，通过动态平衡探索与利用，改进了主动学习过程中的利用步骤。这种方法避免了使用手动调参的启发式方法，并提高了低标签率条件下的分类性能。
### Conclusion
实验证明，本文提出的基于BFC的主动学习方法在低标签量的情况下表现优于现有图半监督学习方法。该方法为在资源受限的环境中进行有效的主动学习提供了一个新的视角。
## 576. `cs.LG` - 通过拓扑不变量的隐式感知实现鲁棒GNN水印 [PDF](https://arxiv.org/pdf/2510.25934), [HTML](https://arxiv.org/abs/2510.25934)
### Authors
Jipeng Li,Yannning Shen
### Background
现有的许多水印技术依赖于后门触发器，这些触发器在常见的模型调整下会失效，并导致所有权模糊。本文提供了InvGNN-WM，它将所有权绑定到模型对图不变量的隐式感知，不需要触发器的验证，且对任务影响极小。
### Innovation
提出了一种新型的GNN水印技术InvGNN-WM，该技术通过预测私人载体集上的标准化代数连通性来进行无触发器、黑盒验证。该方法还在多种节点和图分类数据集及模型中表现出色，并且在多种模型调整下仍然保持鲁棒性。
### Conclusion
InvGNN-WM在不引入较多任务影响的前提下，能够提供较高的水印准确率，并且在剪枝、微调和后训练量化等攻击下依然具有稳健性。此外，该方法还提供了对于不可感知性和鲁棒性的保证，理论上证明了准确移除水印的NP完全性。
## 577. `cs.LG` - MLT [PDF](https://arxiv.org/pdf/2510.25952), [HTML](https://arxiv.org/abs/2510.25952)
### Authors
Tcharlies Schmitz
### Background
传统的方法如哈希或独热编码在处理高基数类别型标识符时存在局限性，比如生成的编码维度高、可逆性差以及计算效率低下等问题。本文提出了一种新的可逆和确定性的技术，即模块化线性分词（MLT），用于将高基数类别型标识符转换为紧凑的数值向量。相比传统方法，MLT利用有限域上的模块化算术和可逆线性变换来保持双射映射，从而提供明确的维度控制和计算可扩展性，同时保持完全可逆性，即使在有数百万个标识符的情况下也能适用。
### Innovation
MLT 通过利用模块化算术和可逆线性变换来实现高基数类别型标识符的编码，提供了一种可逆且控制维度的新方法。这种方法不仅解决了传统编码方法带来的高维度和计算成本问题，还能够在保持数据表示的精准度的同时降低参数量和训练成本，同时保持与监督嵌入相似的预测性能。
### Conclusion
实验结果表明，MLT 在 MovieLens 20M 数据集上达到与监督嵌入相当的预测性能，但所需的参数量和训练成本较低。此外，开源实现已发布在 PyPI（此链接 https://</a>）和 GitHub（此链接 https://</a>）上。
## 578. `cs.LG` - $texttt{π}_{text{RL}}$: 在流式视觉语言行动模型上的在线强化学习微调 [PDF](https://arxiv.org/pdf/2510.25889), [HTML](https://arxiv.org/abs/2510.25889)
### Authors
Kang Chen,Zhihao Liu,Tonghe Zhang,Zhen Guo,Si Xu,Hao Lin,Hongzhi Zang,Quanlu Zhang,Zhaofei Yu,Guoliang Fan,Tiejun Huang,Yu Wang,Chao Yu
### Background
Vision-Language-Action (VLA) 模型能够使机器人理解并执行基于多媒体输入的复杂任务。最近的研究试图利用强化学习（RL）来自动化在扩展监督式微调（SFT）过程中繁琐的数据收集工作。然而，将大规模 RL 应用于基于流的 VLA（如 $texttt{π}_0$ 和 $texttt{π}_{0.5}$）存在挑战，因为它们的迭代去噪处理难以处理的动作对数似然性问题.
### Innovation
通过引入 $texttt{π}_{text{RL}}$，一种公开的流式 VLA 训练框架，该研究成果实现了通过并行模拟平行训练。$texttt{π}_{text{RL}}$ 实现了两种 RL 算法：1. Flow-Noise，将去噪过程建模为一个可学习噪声网络的离散时间 MDP，实现精确的对数似然计算；2. Flow-SDE，将去噪与智能体-环境交互相结合，形成一个两层 MDP，采用 ODE 到 SDE 的转换来提高 RL 探索效率.
### Conclusion
在 LIBERO 和 ManiSkill 挑战赛中，$texttt{π}_{text{RL}}$ 显著提升了 $texttt{π}_0$ 和 $texttt{π}_{0.5}$ 的表现，验证了在线 RL 对流式 VLA 模型的有效性，展示了其在异构模拟下的可扩展多任务强化学习能力.
## 579. `cs.LG` - 一种通用且简化的一阶优化可微框架 [PDF](https://arxiv.org/pdf/2510.25986), [HTML](https://arxiv.org/abs/2510.25986)
### Authors
Andrew W. Rosemberg,Joaquim Dias Garcia,François Pacaud,Robert B. Parker,Benoît Legat,Kaarthik Sundar,Russell Bent,Pascal Van Hentenryck
### Background
通过受限优化问题进行求导在学习、控制和大规模决策系统中变得越来越重要，但由于求解器专业化和接口不匹配，将其实用化仍然是一个挑战。
### Innovation
本文提出了一种通用且简洁的一阶优化可微框架，统一了建模和求导在Julia优化堆栈中。该框架在标准正则条件下，通过求导KKT系统来计算光滑的、可能非凸程序的前向和反向模式解决方案和目标灵敏度。用户可以使用参数为中心的一级API直接声明和获取参数的导数，即使参数出现在多个约束和目标中也无需繁琐的记录。
### Conclusion
该研究结果表明，可微优化可以作为实验、学习、校准和设计中的常规工具使用，而无需偏离标准JuMP建模实践，同时仍可访问广泛求解器生态系统。
## 580. `cs.LG` - Geospatial Foundation Model数据在马拉维卫生设施规划输出预测中的应用与验证 [PDF](https://arxiv.org/pdf/2510.25954), [HTML](https://arxiv.org/abs/2510.25954)
### Authors
Lynn Metz,Rachel Haggard,Michael Moszczynski,Samer Asbah,Chris Mwase,Patricia Khomani,Tyler Smith,Hannah Cooper,Annie Mwale,Arbaaz Muslim,Gautam Prasad,Mimi Sun,Tomer Shekel,Joydeep Paul,Anna Carter,Shravya Shetty,Dylan Green
### Background
在低收入和中等收入国家（LMICs），常规健康数据的质量受到报告延迟和覆盖率不完全的限制，这需要探索新的数据源和分析方法。地理位置基础模型（GeoFMs）通过综合时空和行为数据为后续预测任务提供有效的数学嵌入，因此GeoFMs成为一种有前景的方法。该研究评估了三种GeoFM嵌入源在马拉维针对15项常规卫生项目产出建模时的预测性能，并将它们与传统的地理空间插值方法进行了比较。通过对552个卫生捕获区域（2021年1月-2023年5月）的数据使用XGBoost模型进行分析，研究发现嵌入式方法在13项（87%）指标上优于基准地理统计方法，而当低原始数据可用时（如结核病和营养不良病例），预测效果较差。这些结果证明了GeoFM嵌入对某些选择的卫生和人口统计结果预测在LMIC中具有适度的改进。
### Innovation
该研究提出了一种将Google Population Dynamics Foundation Model（PDFM）、基于卫星图像的Google AlphaEarth和移动电话通信详细记录（CDR）三种GeoFM嵌入源用于预测马拉维15项常规卫生项目产出的方法，并使用XGBoost模型进行验证。研究发现，综合三种GeoFM嵌入源的多GeoFM模型在多个指标（如人口密度、新HIV病例、儿童接种疫苗等）上的预测性能最为稳定，显示出相对于传统方法的提升。
### Conclusion
研究结果表明，GeoFM嵌入在低收入和中等收入国家（LMICs）的某些卫生和人口统计结果预测上带来了适度的提升。研究得出结论，集成多种GeoFM数据源是补充和强化受限常规卫生信息系统的一种高效且有价值的工具。
## 581. `cs.LG` - 无数据训练神经网络的研究 [PDF](https://arxiv.org/pdf/2510.25962), [HTML](https://arxiv.org/abs/2510.25962)
### Authors
Alvaro Velasquez,Susmit Jha,Ismail R. Alkhouri
### Background
近年来，尽管数据驱动的学习方法受到广泛关注，但在无需数据的情况下训练神经网络的方法却相对较少。本文综述了神经网络在无训练数据场景下的优化应用，特别是通过重新参数化方法使用全连接、卷积、图和二次神经网络架构解决优化问题。此外，文章探讨了无数据场景的动机，这主要源于两个因素：一是数据驱动的学习方法尚未完全发展并实现良好的结果；二是某些应用场景中训练数据的稀缺性。文章定义了无数据场景，并将其分为两种变体：架构无关的方法和架构特定的方法。
### Innovation
无数据训练神经网络的方法受到越来越多的关注，特别是在组合优化、逆问题和偏微分方程等领域取得了有希望的结果。文章定义了无数据设置，并将其分为架构无关和架构特定两种方法，讨论了与零样本学习、单次学习、优化中的提升技术和过参数化等概念的相似性和区别。
### Conclusion
文章总结了神经网络在无数据场景下的应用，区分了不同的方法类型，并强调了这一研究领域的重要性。
## 582. `cs.LG` - 利用预测编码网络和时间相关性进行高效在线学习 [PDF](https://arxiv.org/pdf/2510.25993), [HTML](https://arxiv.org/abs/2510.25993)
### Authors
Darius Masoum Zadeh-Jousdani,Elvin Hajizada,Eyke Hüllermeier
### Background
边缘操作的机器人系统需要高效的在线学习算法，能够在处理流式传感数据的同时不断适应变化的环境。传统的反向传播算法尽管有效，但与生物可行性原则冲突，并可能在持续适应场景中表现欠佳。预测编码(PC)框架提供了一个生物可行的替代方案，具有局部、类似Hebb规则的更新机制，适于神经形态硬件实现。然而，PC的主要局限在于其计算开销，因为其在训练过程中需要多次推断迭代。
### Innovation
提出了一种预测编码网络与时间归约结合的架构(PCN-TA)，该架构保持了跨时间帧的潜在状态，通过利用时间相关性显著降低了计算需求，同时保持学习性能。相比于反向传播，PCN-TA实现的权重更新次数减少了10%；相比于基线PC网络，其推断步骤减少了50%。这些效率提升直接降低了计算开销，为边缘部署和资源受限机器人系统中的实时适应支持奠定了基础。
### Conclusion
我们提出的方法具有生物启发性，为未来的神经形态硬件实现提供了可能，能够在边缘环境中实现高效的在线学习。基于COIL-20机器人感知数据集的实验验证了PCN-TA的有效性，证明了其在权重更新次数和推断步骤上的显著改进。
## 583. `cs.LG` - Infrequent Exploration in Linear Bandits [PDF](https://arxiv.org/pdf/2510.26000), [HTML](https://arxiv.org/abs/2510.26000)
### Authors
Harin Lee,Min-hwan Oh
### Background
现有的线性贝叶斯算法（如UCB和Thompson Sampling）完全适应探索，可能在每个时间步骤都进行探索，而纯粹贪婪的方法则需要严格的需求异质性才能成功。连续探索在安全关键或昂贵的领域可能不切实际或不道德，纯粹贪婪策略通常在缺乏足够上下文多样性的情况下会失败。因此，介于这两种极端方法之间，需要一种简单的、实际的方法来实现不频繁的探索。
### Innovation
该文提出了INFEX框架，这是一种简单且实用的方法，专门设计用于不频繁探索。INFEX框架基于给定的计划执行基探索策略，并在其余时间主要选择贪婪的动作。尽管该框架非常简单，但理论分析表明，只要探索频率超过对数阈值，INFEX就能实现实例相关的后悔匹配标准证明有效的算法。此外，该框架是一个通用的模块化框架，可以无缝集成任何完全适应的探索方法，从而具有广泛的适用性和易于采用的特点。通过将密集的探索计算限制在不频繁的时间段内，该方法还可以提高计算效率。
### Conclusion
实证评估证实了我们的理论发现，显示INFEX在核发和运行时间上都优于现有方法，具有最佳的后悔性能。
## 584. `cs.LG` - 正确进行对比预测编码以进行互信息估计 [PDF](https://arxiv.org/pdf/2510.25983), [HTML](https://arxiv.org/abs/2510.25983)
### Authors
J. Jon Ryu,Pavan Yeddanapudi,Xiangxiang Xu,Gregory W. Wornell
### Background
InfoNCE 目标最初是用于对比表征学习的，但由于其与互信息 (MI) 的间接关联，逐渐成为 MI 估计的常用选择。尽管有这些间接关联，本文指出 InfoNCE 并不是一个有效的 MI 估计器，并且提出了一种简单的修改方法，称为 InfoNCE-anchor，以用于准确的 MI 估计。这项工作探讨了 InfoNCE 的局限性，并提出了改进的方法，通过引入辅助锚类，使密度比估计始终一致，并且得出的插件 MI 估计器的偏差有所降低。此外，使用适当的评分规则对框架进行了泛化，当使用对数分数时，恢复 InfoNCE-anchor 作为一种特殊情况，从而统一了一类对比目标，包括 NCE、InfoNCE 和 $f$-分歧变种，这些目标在一个原则性框架下得到了统一。
### Innovation
提出了 InfoNCE-anchor，这是一种简单的修改方法，借助辅助锚类，确保了一致的密度比估计，并得到一个具有显著减少偏差的插件 MI 估计器。此外，通过引入适当的评分规则，该方法统一了广泛的一系列对比目标，并在理论上提供了统一的框架。
### Conclusion
通过实验发现，使用对数分数的 InfoNCE-anchor 能达到最准确的互信息估计；但在自我监督的表征学习实验中，锚并没有提升下游任务的表现。因而，得出结论：对比表征学习的受益之处不在于准确的互信息估计本身，而是学习结构化的密度比。
## 585. `cs.LG` - 向量化的符号回归定律 [PDF](https://arxiv.org/pdf/2510.26064), [HTML](https://arxiv.org/abs/2510.26064)
### Authors
David Otte,Jörg K.H. Franke,Frank Hutter
### Background
符号回归（SR）旨在揭示解释观测数据背后的数学表达式。这在获得科学洞察和为表格数据生成本质可解释且可泛化的模型方面前景广阔。近年来，基于深度学习的SR与遗传编程方法相媲美，但规模的作用尚未被广泛探究。语言模型中的标度律启发了研究人员，他们首次对SR进行了系统的标度研究，使用了可扩展的端到端的变压器管道和精心生成的训练数据，以探讨不同规模模型在大量计算资源下性能的变化趋势。
### Innovation
提出了系统研究符号回归的标度律，使用可扩展的端到端变压器管道和精心生成的训练数据，在不同规模的模型下观察到了验证损失和解决率的清晰幂律趋势。研究发现了计算最优的超参数标度：最优的批量大小和学习率随着模型规模的增加而增长，并确定了一个在我们范围内最优的标记量与参数量的比例约为15，计算资源增加时略有上升。这些结果表明了SR性能很大程度上可预测自计算量，并为训练下一代的SR模型提供了重要的见解。
### Conclusion
研究结果展示了SR性能主要可以从计算量上预测，并提供了训练下一代SR模型的重要洞察。
## 586. `cs.LG` - 基于双混合专家框架的离散时间生存分析 [PDF](https://arxiv.org/pdf/2510.26014), [HTML](https://arxiv.org/abs/2510.26014)
### Authors
Hyeonjun Lee,Hyungseob Shin,Gunhee Nam,Hyeonsoo Lee
### Background
生存分析的目标是建模直至感兴趣事件发生的时间，广泛应用于临床和生物医学研究。主要挑战在于如何建模患者异质性并适应个体特征和时间动态的变化。本文提出了一种双混合专家（MoE）框架，专门用于离散时间生存分析，以应对这一挑战。
### Innovation
本文创新地结合了一个亚组感知的功能编码器MoE和一个时间动态捕捉的事件MoE，双MoE设计能够灵活地与现有的深度学习生存分析框架集成，提高生存分析性能，特别是在METABRIC和GBSG乳腺癌数据集上表现显著提升，达到0.04的测试集时间依赖C指数提升，并且在Consurv框架中使用时还能进一步提升性能。
### Conclusion
作者提出的方法在多个基准数据集上均显示出优越的性能，通过双MoE框架解决了生存分析中患者异质性和时间动态的建模难题，提供了一种有效的解决方案。
## 587. `cs.LG` - 新钱：金融领域合成数据生成系统的综述 [PDF](https://arxiv.org/pdf/2510.26076), [HTML](https://arxiv.org/abs/2510.26076)
### Authors
James Meldrum,Basem Suleiman,Fethi Rabhi,Muhammad Johan Alibasa
### Background
合成数据生成已经成为了在机器学习应用中处理敏感金融数据的一大有前景的方法。通过利用生成模型，例如生成对抗网络（GANs）和变分自编码器（VAEs），能够在保护真实财务记录的统计属性的同时，降低隐私风险和监管限制带来的影响。尽管这一领域快速发展，但目前缺乏对当前研究景观的全面综述。
### Innovation
该综述系统地整理并分析了自2018年以来发表的72篇关于合成金融数据生成的研究，按照生成的信息类型、所采用的生成方法以及评估数据实用性和隐私性的策略进行了分类。研究结果表明，基于GAN的方法主导了文献，并特别适用于生成时序市场数据和表格信用数据。虽然几种创新技术表明了提高现实性和隐私保护潜力，但大多数研究缺乏对隐私保护措施的严格评估。
### Conclusion
综合生成技术和应用，以及评估方法的研究提供了关键的研究缺口并提供了指导，以开发金融领域的健壮、具有隐私保护的合成数据解决方案。
## 588. `cs.LG` - Do Students Debias Like Teachers? On the Distillability of Bias Mitigation Methods [PDF](https://arxiv.org/pdf/2510.26038), [HTML](https://arxiv.org/abs/2510.26038)
### Authors
Jiali Cheng,Chirag Agarwal,Hadi Amiri
### Background
知识蒸馏（KD）是一种有效的模型压缩方法，用于模型间的知识转移。然而，它对模型在处理分布外数据时抵御虚假相关性的影响尚未被充分研究。本研究旨在探讨知识蒸馏对教师模型与学生模型之间转移去偏见能力的影响，主要是在自然语言推理（NLI）和图像分类任务中的应用。研究发现，知识蒸馏后模型的整体去偏见能力减弱，预训练的去偏见模型不能从教师知识中受益，模型的整体鲁棒性在蒸馏后可能保持不变，但不同类型的偏差会表现出显著差异。此外，研究还指出了知识蒸馏后导致不同行为出现的内部注意力模式和电路。
### Innovation
这是首个大规模研究知识蒸馏对去偏见效果及内部机制影响的研究。研究提出了提高去偏见方法去蒸馏性的三种有效解决方案：使用高质量数据进行增强，实现迭代知识蒸馏，以及以教师模型权重初始化学生模型。这些发现有助于深入了解知识蒸馏的工作原理及其对设计更优去偏见方法的影响。
### Conclusion
研究结果表明，知识蒸馏后模型的去偏见能力减弱，预训练的去偏见模型不能从教师知识中受益。虽然模型的整体鲁棒性可能保持稳定，但在不同类型偏差上的表现会有显著差异。研究还提出了改进去偏见方法去蒸馏性的解决方案，并初步揭示了导致不同行为的内在机制。
## 589. `cs.LG` - 通过象棋棱镜探索人机概念契合 [PDF](https://arxiv.org/pdf/2510.26025), [HTML](https://arxiv.org/abs/2510.26025)
### Authors
Semyon Lomaso,Judah Goldfeder,Mehmet Hamza Erol,Matthew So,Yao Yan,Addison Howard,Nathan Kutz,Ravid Shwartz Ziv
### Background
该研究探讨了人工智能系统是否真正理解人类概念，还是仅仅模仿表面模式。通过分析象棋，让人类创造力与精确的战略概念相交汇，来研究这一问题。研究对象是一个拥有270M参数的变压器，该模型达到了大师级的围棋水平。研究揭示了早期网络层在准确编码人类概念（如中心控制和骑士据点）方面有高达85%的准确率，但随着层级加深，性能改善的同时，网络层逐渐产生了与人类思维相悖的概念表示，准确率降至50-65%。为测试模型概念上的稳健性，而非单纯的记忆，研究引入了首个象棋960数据集，包含240个由专家注释的战略概念位置。去除了开篇理论后，各种方法的概念识别率下降了10-20%，表明模型依赖于记忆化的模式而非抽象理解。这揭示了当前架构中的基本矛盾：能赢得比赛的表示与符合人类思维的表示相背离。这些发现暗示，随着AI系统优化性能，它们发展出越来越异化的智能，这对需要真正人机协作的创造性AI应用构成关键挑战。
### Innovation
提出并通过象棋960数据集验证了概念稳健性测试方法，首次用人机概念契合为视角，揭示当前AI架构在优化性能过程中可视化了网络层中与人类思维相悖的概念表示及其不同，为评估和改进AI系统的概念理解奠定了基础。
### Conclusion
当前AI系统优化性能的过程中，网络层产生了与人类思维相悖的概念表示，表明它们依赖于记忆化的模式，而不是抽象理解。这提示未来需要在保持高效率的同时又确保概念理解的一致性，这是实现人机协作的关键挑战。
## 590. `cs.LG` - 学习几何：通过度量优化构建自适应流形模型的框架 [PDF](https://arxiv.org/pdf/2510.26068), [HTML](https://arxiv.org/abs/2510.26068)
### Authors
Di Zhang
### Background
传统机器学习方法主要集中在参数优化上，这些方法在固定几何空间内寻找最优参数。这种方法在一定程度上已经取得了显著的成就，但仍然存在局限性，尤其是在处理数据结构复杂和动态变化场景时显得力不从心。因此，研究人员开始探索更加灵活和动态的模型架构，尤其是在如何优化模型的几何结构方面，以提高模型的适应性和泛化能力。
### Innovation
本文提出了一种新的机器学习范式，将模型本身视为一个可塑的几何实体进行优化。优化的核心是通过在预定义拓扑的流形上优化度量张量场来动态塑造模型的空间几何结构。通过引入离散微分几何为基础的实用方法（将连续流形离散化为三角网格，用边长参数化度量张量），解决了高维优化问题的计算挑战。此外，该框架与广义相对论中的爱因斯坦-希尔伯特作用律存在深刻类比，赋予了“数据驱动几何”的物理解释。研究表明，即使固定拓扑，度量优化也提供了比固定几何模型更大的表达能力。
### Conclusion
本文为构建能够自主演化其几何和拓扑的“元学习器”奠定了坚实基础，并为科学模型发现和鲁棒表征学习等领域提供了广泛的应用前景。
## 591. `cs.LG` - LLMBisect：利用比较分析流水线突破 bug 定位障碍 [PDF](https://arxiv.org/pdf/2510.26086), [HTML](https://arxiv.org/abs/2510.26086)
### Authors
Zheng Zhang,Haonan Li,Xingyu Li,Hang Zhang,Zhiyun Qian
### Background
传统基于补丁的 bug 定位方法存在诸多障碍，如假设 bug 导致提交（BIC）和补丁提交修改相同函数，依赖于代码变更而忽视了提交信息中的大量漏洞相关数据，仅依靠简单的启发式方法且缺乏逻辑分析。
### Innovation
本文提出了一种利用大语言模型（LLM）的综合多阶段流水线方法，通过充分利用补丁信息、对比上下文中的多个候选提交，逐步筛选候选，从而显著提高了 bug 定位的准确性，相较于最先进的解决方案提升了超过 38%。
### Conclusion
综合多阶段流水线是必要的，它将大语言模型方法的准确率提升了 60% 以上。
## 592. `cs.LG` - Nirvana: 具有任务感知记忆机制的专业通用模型 [PDF](https://arxiv.org/pdf/2510.26083), [HTML](https://arxiv.org/abs/2510.26083)
### Authors
Yuhua Jiang,Shuang Cheng,Yihao Liu,Ermo Hua,Che Jiang,Weigao Sun,Yu Cheng,Feifei Gao,Biqing Qi,Bowen Zhou
### Background
传统的大型语言模型（LLM）结构，如Transformer、线性注意力和混合模型，并未采用由任务信息引导的专业化记忆机制。因此，尽管这些模型能够实现专家级别的性能并在目标领域取得优异成绩，但它们缺乏在不同任务中灵活调整其记忆机制的能力，这限制了他们在不同领域的应用扩展。因此，研究者提出了专为特定领域设计而保持广泛能力的独特通用模型（Specialized Generalist Models, SGM），旨在在保持广泛能力的同时，实现特定领域的专家级表现。
### Innovation
1. Nirvana 是一种具有专业化记忆机制的 SGM 模型，能够在测试时提取任务信息。2. 提出了任务感知记忆触发机制（$textit{Trigger}$），可以根据当前任务的需求灵活调整其记忆机制。3. 设计了特异性记忆更新机制（$textit{Updater}$），在 $textit{Trigger}$ 的引导下，动态地存储上下文信息，使模型能够在不同领域中快速适应并优化参数。4. Nirvana 在多种自然语言模型基准上展现出与现有 LLM 结构的竞争力或更优表现，并在医疗成像任务上展示了其高效性和准确性，特别是在改进 MRI 重建质量和准确生成初步临床报告方面有显著提升。
### Conclusion
Nirvana 通过引入任务感知记忆机制和相应的自适应机制，成功实现了在保持广泛能力的同时，特殊领域的专家级表现。研究证明了 Nirvana 在多种通用语言任务和专门的医学任务上的有效性和优越性，特别是对于 MRI 这样的高质量重建任务，Nirvana 的表现优于传统 LLM 结构的模型及常规MRI 模型。
## 593. `cs.LG` - 通过子结构意识对齐弥合分子与文本描述之间的差距 [PDF](https://arxiv.org/pdf/2510.26157), [HTML](https://arxiv.org/abs/2510.26157)
### Authors
Hyuntae Park,Yeachan Kim,SangKeun Lee
### Background
分子和文本表示学习由于其提高化学信息理解的潜力而越来越受到关注。然而，现有的模型往往难以捕捉分子及其描述之间的细微差异，因为它们缺乏学习分子亚结构和化学短语之间的细粒度对齐的能力。
### Innovation
引入了MolBridge，这是一种基于亚结构意识对齐的新分子-文本学习框架。MolBridge通过增强原始分子-描述对，并从分子亚结构和化学短语中导出附加的对齐信号来实现这一目标。为了有效利用这些增强的对齐信号，MolBridge采用亚结构意识对比学习，并结合一种自我校正机制来过滤掉噪声的对齐信号。
### Conclusion
实验结果表明，MolBridge能够捕获细粒度的对应关系，并在广泛的分子基准测试中优于最先进的基线，突显了分子-文本学习中亚结构意识对齐的重要性。
## 594. `cs.LG` - SAFE: 通过地球分层评估预测的新型AI气象评估方法 [PDF](https://arxiv.org/pdf/2510.26099), [HTML](https://arxiv.org/abs/2510.26099)
### Authors
Nick Masi,Randall Balestriero
### Background
当前机器学习的主流做法是在测试集中的所有样本上评估模型性能的平均损失。这种方法在气象和气候领域相当于在地球上非均匀分布的人类发展和地理条件下，对空间上的性能进行平均。这忽略了不同地理区域和人类发展水平之间的重要差异。SAFE (Stratified Assessments of Forecasts over Earth) 是一种用于分析在地球上做出的预测集的分层性能的工具包，可以按照与地理网格点相关的不同属性进行分层：领土（通常是国家）、全球次区域、收入和地表覆盖（陆地或水域）。SAFE 可以让我们检查各个属性（如每个单独国家）的模型性能。研究发现，最先进的 AI 气象预测模型在各个属性方面均表现出预测能力的差异。因此，通过分层评估可以更好地理解模型的性能，并为不同气候变量设置不同的领航时长生成公平性基准。SAFE 通过提供开放源代码，支持进一步在此方向上的研究工作，网址为 this https URL
### Innovation
通过SAFE工具包，实现了针对地球上的预测集进行分层性能评估的新方法。SAFE能够按照包括领土、全球次区域、收入和地表覆盖等属性对地理网格点进行分层，使得研究者能够评估模型在各种属性下的预测能力。这种方法超越了全球平均度量，揭示了模型最佳和最差的表现区域以及最公平的模型。SAFE 开放源代码，使得其他研究人员可以使用该工具包进行相关的研究工作
### Conclusion
通过SAFE可以首次揭示出不同属性下模型的性能差异，不能为空公平性基准提供重要的依据。这有助于更好地评估和优化AI在气象预测领域的表现，为进一步的研究奠定基础
## 595. `cs.LG` - Do Not Step Into the Same River Twice: Learning to Reason from Trial and Error [PDF](https://arxiv.org/pdf/2510.26109), [HTML](https://arxiv.org/abs/2510.26109)
### Authors
Chenming Tang,Hsiu-Yuan Huang,Weijie Liu,Saiyong Yang,Yunfang Wu
### Background
强化学习与可验证奖励（RLVR）在最近显著提升了大型语言模型（LLMs）的推理能力。然而，现有的RLVR方法只是基于它们自身生成的回答进行训练，并受限于LLMs的初始能力，容易导致探索停滞。在这种情况下，LLMs无法解决更多训练问题，也无法从训练数据中进一步学习。部分研究通过利用离策略解决方案来解决这一问题，但需要专家的外部指导，这受到了可用性的限制。
### Innovation
提出了一种名为LTE（Learning to reason from Trial and Error）的方法，该方法通过提示LLMs它们之前自动生成的错误答案及其过长的回答，强调了从尝试和错误中学习。LTE不需要任何外部专家指导。实验验证了LTE的有效性，其在Qwen3-4B-Base六个数学基准上的Pass@1和Pass@k指标分别比相对策略优化（GRPO）高出6.38和9.00。进一步的分析表明，LTE成功缓解了探索停滞的问题，并在训练过程中增强了开发和探索的能力。
### Conclusion
实验结果显示LTE有效克服了探索停滞的问题，提升了开发和探索能力。在六个数学基准上，LTE的表现优于GRPO，尤其是在Pass@1和Pass@k指标方面有了显著提升。
## 596. `cs.LG` - 累积SGD影响估计用于数据归因 [PDF](https://arxiv.org/pdf/2510.26185), [HTML](https://arxiv.org/abs/2510.26185)
### Authors
Yunxiao Shi,Shuo Yang,Yixin Su,Rui Zhang,Min Xu
### Background
现代以数据为中心的AI需要精确的单样本影响。标准的SGD-IE通过将每个epoch的替代品相加来近似单例去除效果，但忽略了epoch间的叠加效应，从而导致对关键样本的排序错误。
### Innovation
本文提出了一种新的累积轨迹感知估计算法——ACC-SGD-IE。该算法能够跨epoch传播单例去除的扰动，并在每个步骤更新累积影响状态。在光滑严格凸环境下实现了几何误差收缩，在光滑非凸环境下紧缩了误差边界，随着mini-batch的增大误差常数将进一步减小。
### Conclusion
实验证明，对于成人、20个新闻组和MNIST数据集，在干净和受污染数据下，以及凸性和非凸性训练中，ACC-SGD-IE能够提供更为准确的影响估计，特别适用于长期epoch。对于数据清理，ACC-SGD-IE能更可靠地标识噪声样本，使用该算法清理数据训练出的模型性能优于使用SGD-IE清理数据训练出的模型。
## 597. `cs.LG` - 基于博弈论的空间-时间强化学习框架用于协作公共资源分配 [PDF](https://arxiv.org/pdf/2510.26184), [HTML](https://arxiv.org/abs/2510.26184)
### Authors
Songxin Lei,Qiongyan Wang,Yanchen Zhu,Hanyu Yao,Sijie Ruan,Weilin Ruan,Yuyu Luo,Huaming Wu,Yuxuan Liang
### Background
公共资源分配是根据社会需求高效分配基础设施、能源和交通资源的过程。现有方法侧重于单独优化资源配置，但忽视了它们的能力限制。为了解决这一局限，本文提出了一种新的问题：协作公共资源分配（CPRA），它明确包含了能力约束和现实场景中的时空动态。通过将CPRA问题形式化为潜在博弈，并展示了潜在函数与最优目标之间的无差距，本文为近似NP-hard问题的纳什均衡奠定了坚实的理论基础。此外，设计的空间-时间强化学习（GSTRL）框架能有效地捕捉整个系统的时间-空间动态。
### Innovation
本文提出了一个名为Game-Theoretic Spatio-Temporal Reinforcement Learning（GSTRL）的全新框架，用于解决CPRA问题。GSTRL框架有效地捕捉了整个系统的时空动态。通过将CPRA问题形式化为潜在博弈，本文展示了潜在函数与最优目标之间的无差距，从而为该NP-hard问题的纳什均衡提供了坚实的理论基础。
### Conclusion
本文通过GSTRL框架对两个真实世界的数据集进行了评估，实验结果表明该方法具有优越的表现。源代码已包含在附录中。
## 598. `cs.LG` - STAR:一个适用于移动和普及计算环境的Wi-Fi CSI驱动的隐私保护且能效的边缘AI框架 [PDF](https://arxiv.org/pdf/2510.26148), [HTML](https://arxiv.org/abs/2510.26148)
### Authors
Kexing Liu
### Background
当前的人类活动识别（HAR）方法面临着计算效率低、高延迟以及在资源受限、嵌入式边缘环境中的实现困难的问题。尤其是在智能家庭、医疗监控和移动物联网系统中的应用需求不断增长背景下，这样的效率和可行性问题更加明显。
### Innovation
STAR框架是一种专为边缘AI优化的轻量级神经架构，结合了自适应信号处理和硬件感知协同优化，能够在低功耗嵌入式设备上实现实时、节能的人类活动识别。STAR使用了更简洁的门控循环单元（GRU）递归神经网络模型，相比传统的LSTM模型减少了33%的模型参数，同时保持了有效的时序建模能力。同时，STAR采用了多阶段预处理流水线，结合中值滤波、8阶巴特沃斯低通滤波和经验模式分解（EMD），有效减噪并提取时空特征。在嵌入式处理器上实现的STAR框架实现了高效的实时识别，通过INT8量化推理，以3.3MHz的速度达到8%的CPU利用率，六倍于CPU执行的速度提升，确保了响应延时在一秒以内，降低了能耗，使得系统能够实现实时、隐私保护的活动识别。
### Conclusion
在STAR框架的支持下，实现了在低功耗嵌入式设备上进行高效、实时的人类活动识别。该研究提供了一个可行且可扩展的解决方案，适用于移动和普及计算环境，包括智能家庭、医疗监控和物联网系统。
## 599. `cs.LG` - 预激活空间基于采样最优控制的大型语言模型测试时对齐方法 [PDF](https://arxiv.org/pdf/2510.26219), [HTML](https://arxiv.org/abs/2510.26219)
### Authors
Sekitoshi Kanai,Tsukasa Yoshida,Hiroshi Takahashi,Haru Kuroki,Kazumune Hashimoto
### Background
大型语言模型（LLMs）的细调需要高昂的计算成本，因此研究在测试时对齐LLMs的方法以降低计算成本吸引了关注。
### Innovation
提出了一种新的测试时对齐方法——预 logits自适应重要性采样（AISP），该方法基于基于采样的模型预测控制，通过在预 logits（倒数第二层的输出）上施加高斯扰动以最大化扰动均值的期望奖励，实现了比最佳 n 次采样更高的奖励，并优于其他基于奖励的测试时对齐方法。
### Conclusion
AISP 在使用的样本数量方面的奖励表现优于最佳 n 次采样方法，并且相较于其他基于奖励的测试时对齐方法，能获得更高的奖励。
## 600. `cs.LG` - 复杂性胜于分段：工业时间序列异常检测中集成和混合方法的评估 [PDF](https://arxiv.org/pdf/2510.26159), [HTML](https://arxiv.org/abs/2510.26159)
### Authors
Emilio Mastriani,Alessandro Costa,Federico Incardona,Kevin Munari,Sebastiano Spinello
### Background
本研究探讨了高级特征工程和混合模型架构在工业多变量时间序列中（以蒸汽涡轮机系统为例）进行异常检测的效果。研究关注点在于评估变化点衍生的统计特征、基于聚类的子结构表示以及混合学习策略对检测性能的影响。研究表明，尽管这些复杂方法理论上很有吸引力，但在实践应用中却持续表现不如一个简单的随机森林加极端梯度提升（XGBoost）集成模型的效果，该模型是在分段数据上训练的。此集成模型在AUC-ROC上的得分达到了0.976，F1分数为0.41，且在定义的时间窗口内实现了100%的早期检测率。一直以来，不平衡且时间上不确定数据场景缺乏有效的复杂模型解决方案。
### Innovation
本研究针对工业时间序列异常检测中混合模型和集成方法的有效性进行了评估，并发现尽管理论上有吸引力，复杂的方法通常不如简单的模型效果好，特别是在不平衡且时间不确定的数据条件下。简单模型结合优化的数据分段可表现出更大的稳健性、可解释性和操作实用性，这为异常检测领域提供了新的见解。
### Conclusion
在高度不平衡且时间上不稳定的工业时间序列数据中，简单的模型结合分段优化能够获得更好的效果，这种简单而优化的方法比复杂的架构更具有稳健性、可解释性和操作实用性。
## 601. `cs.LG` - 从住院患者医疗理赔数据预测所有原因再入院 [PDF](https://arxiv.org/pdf/2510.26188), [HTML](https://arxiv.org/abs/2510.26188)
### Authors
Avinash Kadimisetty,Arun Rajagopalan,Vijendra SK
### Background
减少可预防的医院再入院是国家支付者、提供者和政策制定者提高医疗保健质量和降低成本的重要优先事项。再入院率正被用作衡量医院提供医疗保健质量的标准。本项目使用逻辑回归、随机森林和支持向量机等机器学习技术分析健康理赔数据，识别人口统计学和医学因素，以预测所有原因的再入院。由于健康理赔数据维度高，我们使用了主成分分析进行降维，并据此构建回归模型。基于曲线下面积（AUC）指标比较和评估了这些模型，随机森林模型表现最佳，其次是逻辑回归和支持向量机模型。这些模型可用于识别导致再入院的关键因素，并帮助识别患者，从而降低再入院的可能性，从而降低成本并提高提供的医疗保健质量
### Innovation
采用机器学习技术（如逻辑回归、随机森林和支持向量机）分析高维度的健康理赔数据以预测所有原因的再入院，并使用主成分分析作为降维技术
### Conclusion
随机森林模型在所有分析中表现最佳，其次是逻辑回归和支持向量机模型。所用模型可以帮助识别导致再入院的关键因素，对患者进行重点监测，从而降低再入院率，减少成本，提升患者医疗保健的质量
## 602. `cs.LG` - maxVSTAR：面向鲁棒人体活动识别的闭环边缘模型自适应最大适应性视觉引导CSI传感 [PDF](https://arxiv.org/pdf/2510.26146), [HTML](https://arxiv.org/abs/2510.26146)
### Authors
Kexing Liu
### Background
WiFi信道状态信息（CSI）为基础的人体活动识别（HAR）提供了一种保护隐私的、无需设备的传感解决方案。然而，其在边缘设备上的部署受到域移的影响，环境和硬件条件的变化会导致识别性能下降。这项研究提出了maxVSTAR（最大适应性视觉引导传感技术），这是一种闭环、视觉引导的模型自适应框架，能够在边缘部署的CSI传感系统中自主减少域移的影响。
### Innovation
maxVSTAR采用了跨模态教师-学生架构，利用高精度的YOLO视觉模型作为动态监督信号，实时为CSI数据流提供活动标签，实现轻量级CSI基础HAR模型的在线自适应。闭环重训练机制使STAR能够在没有人工干预的情况下持续适应环境变化。
### Conclusion
广泛的实验验证了maxVSTAR的有效性。当部署在未校准硬件上时，基准STAR模型的识别准确率从93.52%下降到49.14%。通过一次视觉引导的自适应循环，maxVSTAR将准确率恢复到81.51%。结果表明，该系统具有在隐私意识的物联网环境中动态、自监督模型自适应的能力，确立了在网边使用CSI传感进行长期自主HAR的可扩展和实用范式。
## 603. `cs.LG` - 生成模型的最有可能插值 [PDF](https://arxiv.org/pdf/2510.26266), [HTML](https://arxiv.org/abs/2510.26266)
### Authors
Frederik Möbius Rygaard,Shen Zhu,Yinzhu Jin,Søren Hauberg,Tom Fletcher
### Background
生成模型允许对生成进行控制，模型检查等操作，但由于大多数生成模型在没有对模型或数据维数施加严格限制的情况下缺乏主控合乎逻辑的插值概念，因此插值在生成模型中一直是一个挑战。
### Innovation
本研究开发了一种通用的插值方案，该方案旨在针对不同的度量和概率分布找到与之兼容的可能的过渡路径。研究者将插值视作受到合适数据分布约束的测地线，并提出了一种新的算法来计算这些曲线，这种算法无需额外的训练。理论分析表明，该方法在合适的黎曼度量下可以局部视为测地线。
### Conclusion
定量分析表明，在多种模型和数据集上，本研究提出的插值方案可以穿越更高的密度区域，优于基准方法。
## 604. `cs.LG` - MPRU：作为分类管道输出过滤器的模块化投影-重新分布去学习 [PDF](https://arxiv.org/pdf/2510.26230), [HTML](https://arxiv.org/abs/2510.26230)
### Authors
Minyi Peng,Darian Gunamardi,Ivan Tjuawinata,Kwok-Yan Lam
### Background
现有机器去学习（MU）工作通常侧重于理论建模或优化目标，以实现知识的移除。但在实际部署中，这些解决方案通常面临可扩展性问题，并需要原数据集和模型的完全访问权限。已有方法集中在直接移除训练过程中学到的知识，而忽略了训练过程本身的顺序性质。
### Innovation
本文提出了一个新的方法，称为模块化投影-重新分布去学习（MPRU），并将其作为分类管道的输出过滤器。MPRU方法依赖于将分类训练视作一个顺序过程，通过添加一个投影-重新分布层来逆向处理最后一个训练序列，从而实现知识的移除。这种方法无需完全访问原数据集或模型，具有模块化和模型无关的特点，能够在现有分类管道中进行最小改变的部署。
### Conclusion
研究结果表明，与重新训练模型相比，MPRU方法能够在减少大量计算成本的同时，保持相似的输出性能。这证明了该方法的适用性、可扩展性以及与系统的兼容性，能够在实际应用中提供更强的鲁棒性和灵活性。
## 605. `cs.LG` - Angular Steering: 在激活空间旋转实现行为控制 [PDF](https://arxiv.org/pdf/2510.26243), [HTML](https://arxiv.org/abs/2510.26243)
### Authors
Hieu M. Vu,Tan M. Nguyen
### Background
在部署安全可靠的AI时，控制大语言模型的具体行为同时保留其通用能力是一个核心挑战。当前的引导方法（如向量加法和方向性消减）局限于由激活和特征方向定义的二维子空间，这使得它们对选择的参数敏感，并且由于激活空间中的意外相互作用，可能会影响无关特征。现有的方法受限且不灵活。
### Innovation
本文提出了Angle Steering，一个新颖且灵活的行为调节方法，通过在固定二维子空间内旋转激活来操作。通过将引导构建成几何上朝向或远离目标行为方向的旋转，Angle Steering提供了细粒度的连续行为控制，如拒绝和顺从。此外，作者还提出了Adaptive Angle Steering，这是一种仅旋转与目标特征对齐的激活的选择性变体，增强了稳定性和一致性。Angle Steering统一了现有的加法和正交化技术，并简化了参数选择，维持了更广泛调整下的模型稳定性。
### Conclusion
跨多个模型家族和规模的实验表明，Angle Steering能够在维持通用语言建模性能的同时实现稳健的行为控制，证明了其灵活性、泛化能力和相对于先前方法的鲁棒性。
## 606. `cs.LG` - Empirical Bayesian Multi-Bandit Learning [PDF](https://arxiv.org/pdf/2510.26284), [HTML](https://arxiv.org/abs/2510.26284)
### Authors
Xia Jiang,Rong J.B. Zhu
### Background
多任务学习在上下文臂赛中的研究引起了广泛兴趣，因为它可以通过利用共享结构和任务特定异质性来改善跨多个相关任务的决策。现有的方法往往忽略了不同臂赛之间的协方差结构的学习，本文提出了一种新的层次贝叶斯框架，能够通过层次贝叶斯模型捕捉不同臂赛之间的异质性和相关性，实现有效的信息共享，同时适应实例特定的变化。
### Innovation
本文引入了经验贝叶斯方法来估计先验的协方差矩阵，从而提高了跨多个臂赛的学习的实用性和灵活性。基于这种方法，开发了两种高效的算法：Empirical Bayesian Multi-Bandit Thompson Sampling (ebmTS) 和 Empirical Bayesian Multi-Bandit Upper Confidence Bound (ebmUCB)，并在这些算法的决策过程中融入了估计的先验信息。此外，还提供了提出的算法的客观遗憾上界，填补了多臂赛问题领域的研究空白。
### Conclusion
通过在合成数据集和真实世界数据集上的广泛实验，本文的方法显示出在复杂环境下的优越性能，尤其是在累积遗憾方面低于现有技术。这些方法强调了其在多臂赛中权衡探索与利用的有效性。
## 607. `cs.LG` - 离线偏好聚类中的主动数据增强 [PDF](https://arxiv.org/pdf/2510.26301), [HTML](https://arxiv.org/abs/2510.26301)
### Authors
Jingyuan Liu,Fatemeh Ghaffari,Xuchuang Wang,Mohammad Hajiesmaili,Carlee Joe-Wong
### Background
偏好学习从成对反馈中学习是一个在强化学习中带有用户反馈和推荐系统中广泛应用的框架。然而，在许多实际场景中，用户互动受限或成本高昂，使得离线偏好学习变得必要。此外，现实世界的偏好学习经常涉及具有不同偏好的用户，例如，来自不同背景的标注者可能会对同一响应给出不同的排名。这带来了两个核心挑战：一是如何在数据不平衡的场景下识别用户的相似性以有效聚合数据；二是如何处理不平衡的离线数据，其中一些偏好维度被低估。
### Innovation
本文提出了离线偏好聚类中的主动数据增强算法 Off-C$^2$PL 和 A$^2$-Off-C$^2$PL。首先，提出了在纯离线设置下仅依赖离线数据的 Off-C$^2$PL，其理论分析提供了样本噪声与偏差之间的量化折中。其次，扩展了该框架到带有主动数据增强的设置，其中学习者可以基于 Off-C$^2$PL 学到的聚类结构主动选择一些额外的数据样本，从而针对测试用户的最少信息维度进行选择。这种方法证明了主动收集的数据比离线数据更有利于提高效用。
### Conclusion
我们通过合成和真实数据集上的模拟验证了理论结果，证明了主动收集样本比离线样本更有效。
## 608. `cs.LG` - 分布式的多目标黑盒优化在扩散模型推断时多目标生成 [PDF](https://arxiv.org/pdf/2510.26278), [HTML](https://arxiv.org/abs/2510.26278)
### Authors
Kim Yong Tan,Yueming Lyu,Ivor Tsang,Yew-Soon Ong
### Background
扩散模型已被成功用于学习复杂的数据分布。这种方法促进了它们在高维多目标黑盒优化问题中的应用。现有的方法往往通过外部的优化循环来处理扩散模型，这些方法通常将扩散模型视为黑盒细化器。然而，这些方法忽略了扩散生成过程中的内部分布转换，这限制了它们的效率。
### Innovation
本文提出了在推断时优化扩散过程的多目标生成算法（IMG），该算法在生成样本时同时满足多个目标。具体地说，我们的IMG在扩散生成过程中根据预期的多目标值进行加权重采样。这种加权重采样策略确保了由扩散生成的样本的分布符合我们期望的多目标玻尔兹曼分布。此外，我们推导出多目标玻尔兹曼分布有一个有趣的对数似然解释，即它是分布性的多目标优化问题的最优解。我们针对多目标分子生成任务实现了一个IMG。实验结果表明，与通常需要数百次扩散生成的基线优化算法相比，IMG只需一次生成过程就能达到显著更高的hypervolume值。我们的算法可以被视为优化的扩散过程，并可以整合到现有的方法中以进一步提高性能。
### Conclusion
研究结果表明，我们的多目标生成算法（IMG）能够显著提高多目标黑盒优化问题的性能，特别是在扩散模型的推断过程中。
## 609. `cs.LG` - 从令牌层级因果视角理解视觉语言组合难度 [PDF](https://arxiv.org/pdf/2510.26302), [HTML](https://arxiv.org/abs/2510.26302)
### Authors
Ziliang Chen,Tianang Xiao,Jusheng Zhang,Yongsen Zheng,Xipeng Chen
### Background
该论文探讨了对比语言图像预训练（CLIP）在跨模态推理中的优势和局限性，尤其是在物体、属性和关系的组合推理方面表现不佳，类似于“词袋”匹配器。现有的因果解释通常将文本表示为单一向量，忽视了令牌级别的结构，无法解释某些现象如提示敏感性和难以负样本的情况。构建了一个令牌感知的因果表征学习（CRL）框架，以更好地理解这些现象。
### Innovation
论文提出了一种基于序列语言令牌结构因果模型（SCM）的令牌感知因果表征学习框架，该框架将块可识别性扩展到标记化文本，证明了CLIP的对比目标可以在句级和令牌级SCM中恢复模态不变的潜在变量。更重要的是，令牌粒度提供了对于CLIP组合脆弱性的第一个原理解释：组成非可识别性。论文还提出了伪最优文本编码器的存在性，这些编码器尽管优化了相同的训练目标，但在进行原子概念的替换、删除和添加操作时表现出最优不变性，导致对正确说明图和困难负样本无法区分。此外，论文还通过模态差距将语言侧非可识别性与视觉侧的失败相关联，揭示了迭代组成操作如何增加难度，并提出改进负样本挖掘策略的动机。
### Conclusion
通过令牌层级因果视角，论文揭示了CLIP在视觉语言组合上的困难根源，并提供了一个系统的理论框架，以理解这些困难现象，提出了增强负样本挖掘策略以改进模型鲁棒性的建议。
## 610. `cs.LG` - Per-sample Adam on Separable Data: Departure from the Full-batch Regime [PDF](https://arxiv.org/pdf/2510.26303), [HTML](https://arxiv.org/abs/2510.26303)
### Authors
Beomhan Baek,Minhak Song,Chulhee Yun
### Background
Adam是最为常用的深度学习优化器，尽管如此，对其理论上的理解仍然有限。先前的研究表明，Adam偏好数学上与$L_∞$几何相一致的解，但这些结论仅适用于全批量处理的情况。本文研究了一步使用一个样本的增量Adam在逻辑回归中的隐含偏见，特别是在线性可分数据上的表现，发现其隐含偏见可能不同于全批量Adam的行为。对于一般的数据集，作者提出了一个代理算法，该算法在$beta_2 to 1$时捕捉增量Adam的极限行为，并通过数据相关的对偶固定点公式描述其收敛方向。此外，研究还发现，与Adam不同，Signum在接近1的$beta$时不论批处理大小如何，都会收敛到$L_∞$-最大边缘分类器。总的来看，这些结果强调了Adam的隐含偏见不仅取决于批量处理方案，也依赖于数据集；而Signum则保持不变
### Innovation
研究不仅推翻了增量Adam在所有数据集上都遵循$L_∞$-最大边缘偏见的结论，还提出了一种代理算法来描述其更广泛的收敛行为，并证明了在接近1的$beta$时，Signum的隐含偏见始终为$L_∞$-最大边缘分类器。这些发现凸显了批量处理和数据集对于优化器隐含偏见的重要性
### Conclusion
Adam的隐含偏见受到批量处理方案和数据集的影响，而Signum在一定条件下仍表现为固定偏见。增量Adam在特定情况下可能收敛到$L_2$-最大边缘分类器，而不是此前认为的$L_∞$-最大边缘偏见。
## 611. `cs.LG` - 层特定建模与对齐的模型反转在无数据连续学习中的应用 [PDF](https://arxiv.org/pdf/2510.26311), [HTML](https://arxiv.org/abs/2510.26311)
### Authors
Ruilin Tong,Haodong Lu,Yuhang Liu,Dong Gong
### Background
连续学习（CL）旨在增量训练模型以处理一系列任务，同时保留对先前任务的性能。然而，由于隐私或安全约束，存储和回放数据通常是不可行的，特别是对于预训练模型。在不接触先前数据的情况下更新模型的需求促进了数据无关连续学习（Data-free CL）的发展。现有的方法主要依赖正则化手段，而该研究通过模型反转合成数据，实现无需存储样本的数据回放。然而，模型反转在预测模型中面临两个挑战：首先，仅从压缩输出标签生成输入会导致合成数据和真实数据之间出现偏移，这可能会削弱先验知识；其次，每次迭代都需要反向传播整个模型，计算成本高昂。这些问题在大型预训练模型如CLIP中被放大。背景强调了在无数据连续学习中的需求，以及当前技术面临的挑战。
### Innovation
该研究提出了层特定模型反转（Per-layer Model Inversion，PMI）方法来解决模型反转的效率问题。PMI通过为全模型反转提供强大的初始值，大幅减少迭代次数。该研究还提出了通过高斯分布和对比模型建模类别特征的方法来缓解特征偏移，确保合成数据与真实数据之间的对齐。该方法将PMI与特征建模结合，通过从语义意识投影特征生成伪图像，实现新类别的连续学习，同时确保在多种连续学习设置中具有高效性和兼容性。创新点在于提出了PMI方法，结合特征建模解决模型反转的问题，提高了无数据连续学习的效率和效果。
### Conclusion
本研究展示了一种创新的方法，通过层特定建模与对齐的模型反转技术，提高了无数据连续学习的效果和效率。这种方法通过合成数据回放训练模型，减少了对存储数据的需求，解决了无数据连续学习中的关键问题，并且在大模型中表现出良好的性能。该方法不仅适用于语义变化较大的场景，还能在模型训练中保持有效的学习效果。
## 612. `cs.LG` - 通过结合扩散模型与退火 Langevin 动力学实现后验采样 [PDF](https://arxiv.org/pdf/2510.26324), [HTML](https://arxiv.org/abs/2510.26324)
### Authors
Zhiyang Xun,Shivam Gupta,Eric Price
### Background
如果有一个受到噪声影响的线性测量值 $y = Ax + ?xi$ 和分布 $p(x)$ 的良好先验近似，当我们能够从后验 $p(x bull y)$ 中采样时，可以执行诸如图像修补、去模糊和 MRI 重建等任务。然而，近似后验采样在一般情况下是计算上不可行的。在这种情况下，研究集中在局部或全局对数凹分布上，对于这些分布，当有精确得分时，Langevin 动力学可以生成后验样本，但对得分估计误差非常敏感，需要 MGF（亚指数误差）约束。相比之下，在无条件设置下，扩散模型只需 $L^2$ 上界就能成功。我们证明结合扩散模型与退火 Langevin 动力学可以在多项式时间内实现条件采样，只需要 $L^4$ 上界上的得分误差。
### Innovation
提出了结合扩散模型与退火 Langevin 动力学的方法，使得能够在多项式时间内从对数凹分布的后验中采样，这种方法只需要 $L^4$ 上界上的得分误差，为基于扩散模型的方法增加了灵活性和鲁棒性。
### Conclusion
这种方法为从遭受噪声影响的线性测量中采样后验分布提供了一种高效且灵活的方法，特别是在得分误差约束较弱的情况下仍能实现精确采样。
## 613. `cs.LG` - Agent Skills 使新型易实施的提示注入成为可能 [PDF](https://arxiv.org/pdf/2510.26328), [HTML](https://arxiv.org/abs/2510.26328)
### Authors
David Schmotz,Sahar Abdelnabi,Maksym Andriushchenko
### Background
持续学习的大型语言模型（LLMs）的研究仍是关键性的未解科研难题。最近，一家领先的LLM企业推出了一种名为Agent Skills的新框架，该框架可通过简单的Markdown文件存储的指令来为代理提供新知识。然而，该研究指出Agent Skills框架存在根本的安全问题，可能导致敏感数据泄露，并且可以被恶意指令利用，绕过系统级安全防护。
### Innovation
该研究揭示了虽然Agent Skills框架能够为代理提供新知识，但它存在严重的安全漏洞，可以被用来隐藏恶意指令，并通过简单的标记文件实现数据窃取。此外，研究发现，即使设置了“不再询问”的权限，仍可能导致相关但有害的操作。因此，这项研究强调了在LLMs中潜在的安全风险，即使是最简单的提示注入也可能是现实中的安全隐患。
### Conclusion
尽管持续进行研究改进模型能力和提升安全性，前沿的LLMs依旧容易受到非常简单的提示注入攻击。该研究的结果说明，需要更加重视LLMs的安全性，并且对这种简单但潜在有害的提示注入必须保持高度警惕。
## 614. `cs.LG` - 使用干预约束的线性因果发现 [PDF](https://arxiv.org/pdf/2510.26342), [HTML](https://arxiv.org/abs/2510.26342)
### Authors
Zhigao Guo,Feng Dong
### Background
对于精炼因果模型和增强下游任务（如设计新的治疗方法）而言，纳入因果知识和机制至关重要。现有的因果发现方法允许施加结构约束（例如，要求从PIP3到Akt存在因果路径），但这些方法可能会错误地推断因果关系，例如，认为‘PIP3抑制Akt’。干预约束通过明确限制变量对之间的总因果效应，弥补了这一不足，确保学习到的模型与已知的因果影响相一致。
### Innovation
引入了一种新颖的因果发现概念——干预约束，它不同于干预数据。干预数据需要直接干扰变量，而干预约束则通过不等式约束因果效应的形式整合高层次的因果知识。为正式化干预约束，提出了一种衡量线性因果模型中总因果效应的度量方法，并将其形式化为一个带有约束的优化任务，利用两阶段的约束优化方法解决。
### Conclusion
在实际数据集上的评估表明，整合干预约束不仅提高了模型的准确性和与既定发现的一致性，使模型更具可解释性，还促进了新因果关系的发现，而这些关系的成本较高。
## 615. `cs.LG` - QUBO基SVM训练中权重离散化的影响研究 [PDF](https://arxiv.org/pdf/2510.26323), [HTML](https://arxiv.org/abs/2510.26323)
### Authors
Sascha Mücke
### Background
支持向量机（SVM）的训练可以通过形式化为QUBO问题来实施，这使得量子退火技术可以用于模型优化。本文探讨了量子退火在SVM训练中的应用，特别关注权重的离散化程度对预测性能的影响。作者对比了基于QUBO的SVM训练方法与经典的LIBSVM解算器，发现即使参数的精度较低，基于QUBO的SVM训练方法也能达到甚至是超过经典方法的准确率。研究表明，选择合适的支持向量可能比它们的精确权重更重要。尽管当前的硬件限制了可解决的QUBO的大小，本研究结果表明，随着量子设备的发展，量子退火在SVM训练中的效率潜力很大。
### Innovation
本文创新性地将SVM训练过程转化为QUBO问题，并通过改变权重的离散化程度来研究其对预测性能的影响。实验结果表明，即使是低精度的QUBO编码也能实现与经典方法相媲美的甚至更好的准确率。通过对比分析，研究人员发现决定模型性能的关键在于支持向量的选取，而不是精确的权重分配。据此，提出了在量子退火中SVM训练的一种新思路，虽然当前硬件限制了QUBO的规模，但随着技术进步，未来的潜在应用场景很大。
### Conclusion
本文研究了量子退火在基于QUBO的SVM训练中的应用，并发现即使采用低精度参数编码，基于QUBO的SVM也能达到甚至超过其他经典方法的准确率。研究表明，支持向量的准确选择比精确的权重分配更加重要。尽管当前硬件限制了QUBO的规模，未来随着量子设备的发展，量子退火在SVM训练中的应用潜力巨大。
## 616. `cs.LG` - 随机、稀疏和非稳定环境中自主水下车辆污染检测的强化学习 [PDF](https://arxiv.org/pdf/2510.26347), [HTML](https://arxiv.org/abs/2510.26347)
### Authors
Sebastian Zieglmeier,Niklas Erdmann,Narada D. Warakagoda
### Background
强化学习（RL）算法旨在通过学习最大化奖励的动作来优化问题解决，但在随机和非稳定环境中这种任务变得更加具有挑战性。先进的RL算法在这些条件下解决问题的能力也有限。例如，在使用自主水下车辆（AUV）搜索海洋污染云时，RL算法需要在稀疏奖励环境中导航，这表明其频繁会得到零奖励。因此，本文旨在通过重新审视和改进经典的RL方法，使其能够高效地在稀疏、随机和非稳定环境中运行。已有大量修改措施被系统性地研究，包括层次算法更改、多目标学习以及将位置记忆作为一个外部输出过滤器集成以防止状态重复访问.
### Innovation
该研究通过重新审视并改进经典的RL方法，使得RL算法能够在稀疏、随机和非稳定环境中更有效地运行。研究重点包括层次算法的调整、多目标学习以及引入位置记忆作为外部输出过滤器来避免状态重复访问。实验结果表明，修改后的蒙特卡罗方法在性能上显著优于传统的Q学习以及两种详尽搜索模式，这表明RL方法可以在复杂的环境中得到有效的应用，特别是在随机、非稳定和稀疏奖励的环境中.
### Conclusion
研究结果表明，强化学习方法可以在随机、非稳定和稀疏奖励的环境中进行有效的应用，特别是对于使用自主水下车辆进行污染检测的任务。这些发现揭示了RL方法在复杂环境中的适应潜力。
## 617. `cs.LG` - 迈向金融领域的可解释和可靠AI [PDF](https://arxiv.org/pdf/2510.26353), [HTML](https://arxiv.org/abs/2510.26353)
### Authors
Albi Isufaj,Pablo Mollá,Helmut Prendinger
### Background
金融预测越来越多地使用大型神经网络模型，但其不透明性增加了信任和监管合规的挑战。为此，本文提出了几种可解释和可靠的AI方法在金融领域的实现方式。首先，介绍了如何通过时间LLM时间序列基础模型使用提示以避免错误方向的预测。其次，展示了将时间序列预测的基础模型与可靠性估计结合使用可以过滤不准确的预测。最后，建议将符号推理编码的领域规则引入透明的解释。通过这些方法，强调执行仅限于可靠且可解释的预测。在股票和加密货币数据上的实验表明，该架构减少了错误警报，并支持选择性执行。通过将预测表现与可靠性估计和基于规则的推理相结合，本文框架进一步推动了透明和可审计的金融AI系统的发展。
### Innovation
本文提出了几种可解释和可靠的AI方法在金融领域的实现方式，包括时间LLM时间序列基础模型的使用、将基础模型与可靠性估计的结合使用以及符号推理编码领域规则的引入。这些方法重视只执行可靠且可解释的预测。通过将预测性能与可靠性估计和基于规则的推理相结合，本文框架进一步推动了透明和可审计的金融AI系统的发展。
### Conclusion
实验结果显示，时间LLM的架构减少了错误警报，支持了选择性执行。通过结合预测表现与可靠性估计和基于规则的推理，本文框架推进了可解释和可审计的金融AI系统的透明性。
## 618. `cs.LG` - 高效生成AI增强突然平流层变暖的概率预报 [PDF](https://arxiv.org/pdf/2510.26376), [HTML](https://arxiv.org/abs/2510.26376)
### Authors
Ningning Tao,Fei Xie,Baoxiang Pan,Hongyu Wang,Han Huang,Zhongpu Qiu,Ke Gui,Jiali Luo,Xiaosong Chen
### Background
突然平流层变暖(SSWs)是亚季节可预报的关键来源，也是极端冬季天气的主要驱动因素。但其准确且高效的预报仍然是数值天气预报(NWP)系统的持久挑战，受制于物理表示、初始化以及集合预报的巨大计算需求。尽管数据驱动的预报技术迅速发展，但其应用到复杂的三维动力学中的SSWs，尤其是用于概率预报方面仍被很大程度上未开发。
### Innovation
本文通过开发一种基于流匹配的生成AI模型(FM-Cast)，有效地填补了数据驱动预报在SSWs复杂三维动力学应用中的空白，特别是在概率预报方面。FM-Cast能高效地预见10起事件中事件的起始、强度和形态，准确度超过50%，并且仅需两分钟即可在消费者GPU上进行一次50成员、30天的预报。此外，通过理想实验展示了SSWs预报能力的根本是其背后的物理驱动因素，区分了由对流层强迫和内部平流层动态驱动的事件。
### Conclusion
本文建立了一种计算上高效的概率预测平流层异常的范式，展示了生成AI在深化大气-气候动力学物理理解方面的能力。
## 619. `cs.LG` - UnifiedFL：一种动态统一学习框架以实现公平协同 [PDF](https://arxiv.org/pdf/2510.26350), [HTML](https://arxiv.org/abs/2510.26350)
### Authors
Furkan Pala,Islem Rekik
### Background
联邦学习（FL）作为一种在多个客户端之间不共享原始数据的情况下进行协作模型训练的关键范式，已经在放射学和病理学等领域实现隐私保护的应用。然而，针对具有根本不同神经架构和非同分布数据集的客户端之间的协作训练的研究仍然稀缺。现有的FL框架存在一些局限性，尽管宣称支持架构异质性，多数最近的FL方法仅能容忍单一模型家族内的变体（例如，较浅、较深或较宽的CNN），仍然假设共享全局架构，并未能容纳客户端部署根本不同网络类型（例如，CNN、GNN、MLP）的联邦。此外，现有方法主要针对统计异质性问题，而忽略了领域断裂问题，即每个客户端的数据分布与测试时间的数据分布相差甚远，从而影响模型的泛化能力。当客户端使用不同的架构、非同分布的数据，并遇到不同的测试领域时，当前方法表现不佳。
### Innovation
我们提出了一种动态统一学习框架UnifiedFL，它通过一个共享的图神经网络优化有向模型图，将异构本地网络表示为图中的节点和边。UnifiedFL引入了（i）一个共同的图神经网络参数化所有架构，（ii）基于客户端参数之间欧几里得距离的驱动式聚类，以及（iii）兼顾收敛性和多样性的两级聚合策略。统一FL框架在MedMNIST分类和海马体分割基准实验中表现出优越性。
### Conclusion
实验结果表明，UnifiedFL能够有效解决客户端异构结构、非同分布数据和不同测试领域所带来的挑战，并在MedMNIST分类和海马体分割基准上显示出更好的性能。
## 620. `cs.LG` - CorVS: 基于视频轨迹-传感器对应的人识别方法在实际仓库中的应用 [PDF](https://arxiv.org/pdf/2510.26369), [HTML](https://arxiv.org/abs/2510.26369)
### Authors
Kazuma Kano,Yuki Mori,Shin Katayama,Kenta Urano,Takuro Yonezawa,Nobuo Kawaguchi
### Background
工人的位置数据对提高工业现场的生产效率至关重要。在物流仓库中，摄像头作为一种定位工具显示出潜力，因为它们还可以提供有价值的工作环境信息，如货物状态。然而，仅通过视觉数据识别个体往往是不实际的。因此，一些先前的研究通过比较轨迹和可穿戴传感器测量来识别视频中的人员。尽管这种方法具有对外观独立的优势，但现有的方法可能难以在现实世界条件下正常工作。为了解决这一挑战，我们提出了一种名为CorVS的新型数据驱动的人识别方法，基于视觉跟踪轨迹和传感器测量之间的对应关系。该方法首先使用深度学习模型预测每对轨迹和传感器测量的对应概率和可靠性，然后通过预测的概率和可靠性来匹配轨迹和传感器测量以进行时间匹配。我们创建了一个实际仓库操作的数据集，并证明了该方法在实际应用中的有效性。
### Innovation
提出了一种名为CorVS的新型数据驱动的人识别方法，通过结合视觉跟踪轨迹和传感器测量之间的对应关系来解决现有方法在实际应用场景中的不足。该方法利用深度学习模型预测轨迹和传感器测量之间的对应概率和可靠性，并通过这些预测值实现时间上的轨迹和传感器测量匹配。这是一个创新的方法，因为它能够克服视觉数据独立识别身份时可能遇到的挑战，并且验证了该方法在实际仓库场景中的有效性。
### Conclusion
我们提出的方法CorVS在实际仓库操作数据集上表现出良好的效果，并证明能够有效地用于实际应用。通过结合视觉跟踪轨迹和传感器测量之间的对应关系，该方法克服了现有方法在现实世界条件下可能失效的问题。
## 621. `cs.LG` - 通过分类复杂性缓解实现鲁棒图凝缩 [PDF](https://arxiv.org/pdf/2510.26451), [HTML](https://arxiv.org/abs/2510.26451)
### Authors
Jiayi Luo,Qingyun Sun,Beining Yang,Haonan Yuan,Xingcheng Fu,Yanbiao Ma,Jianxin Li,Philip S. Yu
### Background
图凝缩（GC）引起了广泛关注，因其能够合成更小但更具信息量的图。然而，现有的研究往往忽视了GC在原始图被篡改时的鲁棒性问题，在这种情况下GC的表现显著下降，而现有的鲁棒图学习技术的效果也很有限。
### Innovation
作者基于图数据流形的几何视角，提出了Manifold-constrained Robust Graph Condensation框架（MRGC），通过引入三种图数据流形学习模块，引导凝缩后的图位于平滑的低维流形上，且具有最小的类别混淆，从而保持了GC的分类复杂性降低能力，并在遭受通用对抗性攻击时确保鲁棒性表现。
### Conclusion
在不同攻击场景中，实验结果表明MRGC具有鲁棒性，能有效缓解分类复杂性缺陷，提升GC的鲁棒性。
## 622. `cs.LG` - 低频截断实现多智能体强化学习中的自适应上下文长度优化 [PDF](https://arxiv.org/pdf/2510.26389), [HTML](https://arxiv.org/abs/2510.26389)
### Authors
Wenchang Duan,Yaoliang Yu,Jiwan He,Yi Shi
### Background
近期，深度多智能体强化学习（MARL）在解决长期依赖和非马尔可夫环境的复杂任务上表现出显著的效果。其成功部分归因于依赖于固定长且较大的上下文长度来调整策略。然而，这种固定的长上下文长度可能导致探索效率低和信息冗余问题。
### Innovation
本文提出了一种新颖的MARL框架，旨在获得自适应而有效的上下文信息。具体而言，设计了一个中心代理，通过时间梯度分析动态优化上下文长度，增强了探索能力，促进了MARL全局最优解的收敛。此外，为了增强上下文长度的自适应优化能力，引入了一种有效的输入表示方法，能够有效滤除冗余信息，通过基于傅里叶的低频截断方法，提取去中心化智能体的全局时间趋势，提供了一个有效的MARL环境表示方法。
### Conclusion
广泛的实验表明，所提出的方法在PettingZoo、MiniGrid、Google Research Football (GRF)和StarCraft Multi-Agent Challenge v2 (SMACv2)等长期依赖任务上达到了最先进的性能。
## 623. `cs.LG` - 协同进化潜在动作世界模型 [PDF](https://arxiv.org/pdf/2510.26433), [HTML](https://arxiv.org/abs/2510.26433)
### Authors
Yucen Wang,Fengming Zhang,De-Chuan Zhan,Li Zhao,Kaixin Wang,Jiang Bian
### Background
使用预训练的视频生成模型通过潜在动作适配为可控世界模型是一个创造通用世界模型的有前途的步骤。目前占据主导地位的方法采用两阶段训练方式，分别训练潜在动作模型（LAM）和世界模型，这导致了冗余的训练和限制了两者的共适应潜力。
### Innovation
本文提出了CoLA-World，这是一种首次成功实现这一协同进化的范式的模型。通过一个关键的预热阶段，CoLA-World有效地对从零开始的LAM和预训练的世界模型的表示进行对齐，建立了一种共同进化循环：世界模型作为知识丰富的导师，提供梯度以塑造高质量的LAM，而LAM则提供更精确和适应性强的控制接口给世界模型。
### Conclusion
实证结果表明，CoLA-World在视频模拟质量和下游视觉规划方面与或优于之前的两阶段方法，为领域内建立了一种稳健且高效的新型范式。
## 624. `cs.LG` - 从稀缺数据中进行个性化治疗结果预测的双重通道知识蒸馏和自适应融合 [PDF](https://arxiv.org/pdf/2510.26444), [HTML](https://arxiv.org/abs/2510.26444)
### Authors
Wenjie Chen,Li Zhuang,Ziying Luo,Yu Liu,Jiahao Wu,Shengcai Liu
### Background
在精准医疗中，针对小样本和罕见患者群体的个性化治疗效果预测至关重要。然而，成本高昂的临床试验数据限制了预测性能。
### Innovation
提出了跨保真度知识蒸馏和自适应融合网络(CFKD-AFN)，利用丰度但保真度较低的模拟数据来增强对稀缺但保真度较高的临床试验数据的预测。CFKD-AFN 包含了双重通道的知识蒸馏模块以提取互补知识，以及注意力引导的融合模块以动态整合多源信息。
### Conclusion
实验表明，CFKD-AFN 在慢性阻塞性肺疾病的治疗结果预测上显著优于现有方法，预测准确率提高了6.67%到74.55%，并且对不同大小的高保真度数据集具有很强的鲁棒性。此外，CFKD-AFN 可进一步扩展为具有解释性版本，以支持临床决策中的医学隐含语义探索。
## 625. `cs.LG` - 基于支持向量机和孪生支持向量机的多任务学习：全面调研 [PDF](https://arxiv.org/pdf/2510.26392), [HTML](https://arxiv.org/abs/2510.26392)
### Authors
Fatemeh Bazikar,Hossein Moosaei,Atefeh Hemmati,Panos M. Pardalos
### Background
多任务学习（MTL）通过同时对相关任务进行联合训练，利用共享的特征信息提升模型的泛化能力、效率和鲁棒性，特别是在数据稀缺或高维场景下表现出色。尽管深度学习在最近的MTL研究中占据主导地位，但支持向量机（SVM）和孪生支持向量机（TWSVM）由于其可解释性、理论严格性和在小样本集上的有效性，仍然具有重要价值。
### Innovation
论文对基于SVM和TWSVM的多任务学习方法进行了全面调研，强调共享表示、任务正则化和结构耦合策略，并特别关注新兴的TWSVM扩展在多任务设置中的应用，这些扩展显示出良好潜力但尚未广泛探索。论文从理论属性、优化策略和实验性能等方面比较了这些模型，并讨论了它们在计算机视觉、自然语言处理和生物信息学等领域的应用。
### Conclusion
本文识别了研究空白，并提出了构建可扩展、可解释且可靠的基于SVM和TWSVM的多任务学习框架的研究方向。该工作为对基于SVM和TWSVM的多任务学习感兴趣的学者和实践者提供了一个全面的资源。
## 626. `cs.LG` - ReSpec: 朝着强化学习系统中推测性解码的优化 [PDF](https://arxiv.org/pdf/2510.26475), [HTML](https://arxiv.org/abs/2510.26475)
### Authors
Qiaoling Chen,Zijun Liu,Peng Sun,Shenggui Li,Guoteng Wang,Ziming Liu,Yonggang Wen,Siyuan Feng,Tianwei Zhang
### Background
大语言模型（LLMs）通过强化学习（RL）进行适应时，生成阶段通常是瓶颈，可能消耗超过75%的训练时间。推测性解码（SD）在服务系统中加速自回归生成，但在RL训练中的行为仍未被充分研究。这导致了三个关键缺口阻碍了SD的简单集成：在大规模batch大小中逐渐减弱的加速效果、持续更新演员时的投稿者陈旧问题和投稿者引发的策略退化。
### Innovation
提出了ReSpec系统，通过三种互补机制来适应SD到RL：动态调整SD配置、通过知识蒸煮演变投稿者，并根据回放奖励权重更新。在Qwen模型（3B—14B）上，ReSpec实现了最多4.5倍的速度提升，同时保持了奖励收敛性和训练的稳定性，为基于RL的大语言模型适配提供了一个实用解决方案。
### Conclusion
ReSpec通过适配SD来提高基于RL的大语言模型适应效率，实现了显著的速度提升和训练稳定性，为该领域提供了实际可行的解决方案。
## 627. `cs.LG` - LLMs作为上下文元学习者进行模型和超参数选择 [PDF](https://arxiv.org/pdf/2510.26510), [HTML](https://arxiv.org/abs/2510.26510)
### Authors
Youssef Attia El Hili,Albert Thomas,Malik Tiomoko,Abdelhakim Benechehab,Corentin Léger,Corinne Ancourt,Balázs Kégl
### Background
模型和超参数的选择在机器学习中至关重要但极具挑战性，通常需要专家直觉或昂贵的自动化搜索。这项研究探索了大型语言模型（LLMs）是否可以作为这个任务的上下文元学习者。通过将每个数据集转换为可解释的元数据，论文促使LLM推荐模型家族和超参数。
### Innovation
研究提出了两种提示策略：(1) 零样本模式，仅依赖预训练知识；(2) 元数据辅助模式，结合过去任务中模型及其表现的示例。结果显示LLMs可以利用数据集元数据推荐具有竞争力的模型和超参数，没有搜索过程，且元数据辅助提示的改进展示了其在上下文元学习中的能力。
### Conclusion
研究结果表明LLMs可能在模型选择和超参数优化中扮演轻量级、通用的助手角色，为这一领域开辟了一种新的有前景的角色。
## 628. `cs.LG` - 通过离策源影响引导实现高效数据的RLVR [PDF](https://arxiv.org/pdf/2510.26491), [HTML](https://arxiv.org/abs/2510.26491)
### Authors
Erle Zhu,Dazhi Jiang,Yuan Wang,Xujun Li,Jiale Cheng,Yuxian Gu,Yilin Niu,Aohan Zeng,Jie Tang,Minlie Huang,Hongning Wang
### Background
目前，增强学习与可验证奖励（RLVR）中的数据选择方法主要基于启发式，缺乏理论保证和普适性。因此，需要一种理论依据充足的方法来提升大数据中决策能力的强化学习。本文提出了一种使用影响函数估计每个数据点对学习目标贡献的理论指导方法，克服了在线影响估计所需策略演练带来的高计算成本，通过引入离策略的影响估计方法，有效近似数据影响。对于大型语言模型的大维度梯度，采用了稀疏随机投影减少维度，提高存储和计算效率，从而提升了强化学习数据选择的效率与时效性.
### Innovation
本文提出了一种使用影响函数的方法，以及一种离策略影响估计方法和稀疏随机投影技术，确保能够高效地估计每个数据点对学习目标的贡献，解决了计算成本高和数据维度大的问题。因此，开发了一套多阶段的RL框架，CROPI，能够在保证学习效果的同时，高效地选择最有影响力的数据用于当前政策，大幅度加速了训练进程.
### Conclusion
实验结果表明，利用CROPI，即使使用比全数据集小10%的数据量，7B参数量级的模型也能实现2.66倍的步级加速。这显示出基于影响的数据选择的巨大潜力，可以显著提高RLVR效率和效果.
## 629. `cs.LG` - 思考超越策略：上下文引导策略优化 [PDF](https://arxiv.org/pdf/2510.26519), [HTML](https://arxiv.org/abs/2510.26519)
### Authors
Hsiu-Yuan Huang,Chenming Tang,Weijie Liu,Saiyong Yang,Yunfang Wu
### Background
现有的验证奖励强化学习（RLVR）方法，如组相对策略优化（GRPO），在提升大型推理模型（LRMs）的推理能力方面取得了显著进展，但它们由于依赖于当前策略分布的随策略回放而导致了探索的局限性，结果限制了轨迹的多样性和完整性。最近的方法尝试通过引入更强专家模型生成的轨迹来扩展策略覆盖范围，但这增加了计算成本且高级模型往往不可用。
### Innovation
本文提出了一种统一框架In-Context Steered Policy Optimization（ICPO），利用LRMs的天然上下文学习能力，用现有数据集提供专家指导。ICPO引入了混合策略GRPO与隐式专家强迫机制，无需依赖高级LRM轨迹便可扩展探索范围。此外，ICPO通过专家区域拒绝采样和逐步专家奖励塑造技术来稳定优化。
### Conclusion
实验结果表明，ICPO在数学推理基准测试中始终提升强化学习性能并提高训练稳定性，揭示了一种可扩展且有效的RLVR范式，适用于LRMs。
## 630. `cs.LG` - 量子门循环GAN配高斯不确定性在网络异常检测中的应用 [PDF](https://arxiv.org/pdf/2510.26487), [HTML](https://arxiv.org/abs/2510.26487)
### Authors
Wajdi Hammami,Soumaya Cherkaoui,Jean-Frederic Laprade,Ola Ahmad,Shengrui Wang
### Background
时间序列数据中的异常检测是网络安全中的关键挑战。近期的量子机器学习方法，如量子核方法和变分量子电路，已经展示了在捕捉复杂数据分布以实现异常检测方面的潜力，但这些方法仍然受限于有限的量子比特数量。
### Innovation
我们这项工作引入了一种基于量子增强的生成对抗网络（QGRU-GAN），该网络使用逐次数据注入（SuDaI）和多度量门策略，以增强网络异常检测的鲁棒性。该模型利用量子增强的生成器通过重参数化输出高斯分布的参数（均值和对数方差），并结合Wasserstein批评家来稳定对抗性训练。异常检测通过一种新颖的门控机制进行，该机制最初基于高斯不确定性估计标记潜在的异常，并通过批评家评分的组合和重构错误来验证。
### Conclusion
在基准数据集上评估显示，该方法在时间序列感知的F1分数（TaF1）为89.43%，相比现有的经典和量子模型更擅长于准确及时地检测异常。此外，训练好的QGRU-WGAN部署在实际的IBM量子硬件上，仍保留了高异常检测性能，证明了其在当前无噪声中等规模量子（NISQ）设备上的鲁棒性和可实现性。
## 631. `cs.LG` - 从理论视角看多基元推测性解码 [PDF](https://arxiv.org/pdf/2510.26527), [HTML](https://arxiv.org/abs/2510.26527)
### Authors
Ruilin Wang,Huixia Li,Yuexiao Ma,Xiawu Zheng,Fei Chao,Xuefeng Xiao,Rongrong Ji
### Background
大语言模型（LLMs）的推断延迟是大规模部署时的关键瓶颈。推测性解码方法近年来展示了在不牺牲输出分布的情况下加速推断的潜力。然而，现有研究通常依赖于一种双重草稿验证框架，并缺乏严格的理论基础。
### Innovation
本文提出了一种新颖的多基元推测性解码框架，该框架基于全面的理论分析。我们证明了一个基本定理，描述了多模型推测性解码系统的最优推断时间，揭示了如何从双重方法扩展到更通用的多基元范式。通过理论研究多模型令牌生成，我们剖析并优化了模型能力、接受长度与整体计算成本之间的交互。此框架支持独立实现和与现有推测技术的集成，从而在实践中实现加速性能。
### Conclusion
我们在多个模型系列中展示了我们的方法在LLaMA2-Chat 7B上的加速比在3.31×至4.01×之间，LLaMA3-8B高达3.87×，Vicuna-7B为4.43×，Qwen2-7B为3.85×，同时保持原始输出分布不变。我们还将我们的理论证明和实现代码公开，以促进对多基元推测性解码的进一步研究。
## 632. `cs.LG` - 瘦身的提升树：资源受限设备上的紧凑模型 [PDF](https://arxiv.org/pdf/2510.26557), [HTML](https://arxiv.org/abs/2510.26557)
### Authors
Jan Stenkamp,Nina Herrmann,Benjamin Karic,Stefan Oehmcke,Fabian Gieseke
### Background
在现代物联网应用中，将机器学习模型部署在计算资源有限的设备上已成为关键组成部分。本研究旨在解决对轻量级机器学习模型的日益增长的需求，提出了一种针对提升决策树的压缩方案。
### Innovation
本研究提供了在训练轻量级提升决策树集成时重新利用特征和阈值的技术，实验结果显示，与经过调整的训练过程和不同内存布局使用的LightGBM模型相比，压缩比达到4-16倍，同时保持相同的性能。
### Conclusion
这些压缩后的模型可以在不需要持续通信或外部能源供应的情况下，在孤立或电力有限的环境中独立运行，仅需微小的计算能力和能源。这一能力为远程监控、边缘分析和孤立或电力有限环境中的实时决策提供了广泛的应用潜力。
## 633. `cs.LG` - 使用轻量级无监督异常检测滤波器增强ECG分类稳健性 [PDF](https://arxiv.org/pdf/2510.26501), [HTML](https://arxiv.org/abs/2510.26501)
### Authors
Mustafa Fuad Rifet Ibrahim,Maurice Meijer,Alexander Schlaefer,Peer Stelldinger
### Background
穿戴设备进行连续心电图（ECG）监测在早期心血管疾病（CVD）检测方面具有巨大潜力。但在资源受限的环境中部署深度学习模型进行自动分析时，由于不可避免的非分布数据（OOD数据），存在可靠性挑战。标准分类器对未见过的病理或噪声信号会产生高置信度的错误预测，威胁到患者安全。现有的OOD检测方法要么忽视计算约束，要么分别处理噪声和未见过的类别。因此，本研究表明，无监督异常检测（UAD）作为独立的上游筛选机制，可以提高系统的鲁棒性。
### Innovation
本研究探索了使用轻量级无监督异常检测滤波器来增强ECG分类的稳健性。论文选择了六种不同的UAD方法进行比较，包括Deep SVDD、重建模型、掩码异常检测、归一化流和扩散模型，并利用神经架构搜索（NAS）在严格资源限制（最多512k参数）下进行了优化。研究结果表明，Deep SVDD在检测OOD CVD类别和识别噪声不可分析的信号方面表现最佳。此外，在现实部署模拟中，优化的Deep SVDD滤波器与诊断分类器的结合使用，相比仅靠分类器的基线，准确率提高了21个百分点。
### Conclusion
研究表明，优化的UAD滤波器能够保护自动ECG分析的安全性，从而实现穿戴设备上更加安全和可靠的连续心血管监测。
## 634. `cs.LG` - 超图上的高阶正则化学习 [PDF](https://arxiv.org/pdf/2510.26533), [HTML](https://arxiv.org/abs/2510.26533)
### Authors
Adrien Weihs,Andrea Bertozzi,Matthew Thorpe
### Background
最近提出了高阶超图学习（HOHL）作为经典超图正则化的一种原则性替代方案，通过由超图结构诱导的多尺度拉普拉斯算子的幂来强制执行高阶平滑性。先前的工作通过几何设置中的渐近一致性分析，确立了HOHL的良态和病态性质。
### Innovation
本文扩展了理论基础，证明了HOHL的修正版的一致性，并推导了当HOHL用作全监督学习正则化器时的具体收敛速率。此外，本文还展示了HOHL在主动学习中的强大实际性能，以及在缺乏内在几何结构的数据集中的表现，突显了HOHL在不同学习环境中的通用性和鲁棒性。
### Conclusion
本文通过理论分析和实际实验，证明了HOHL在不同学习环境中的可靠性和有效性，进一步增强了HOHL在超图学习中的应用价值。
## 635. `cs.LG` - 在深度网络中测量捷径定位 [PDF](https://arxiv.org/pdf/2510.26560), [HTML](https://arxiv.org/abs/2510.26560)
### Authors
Nikita Tsoy,Nikola Konstantinov
### Background
深网络中的捷径是一个重大挑战，它们在训练中表现良好但不具泛化能力（Geirhos等，2020）。尽管捷径对特征表示的影响尚未得到充分研究，阻碍了设计合理的捷径缓解方法。为了解决这一限制，我们研究了深度模型中捷径的逐层定位。我们新颖的实验设计通过在干净和偏斜数据集上的反事实训练，量化了造成错误分类的捷径诱导偏斜对逐层性能的贡献。
### Innovation
我们开发了一种新的实验设计，通过在干净和偏斜数据集上的反事实训练来量化由于捷径诱导的偏差对准确度衰减的逐层贡献。我们使用这种方法在CIFAR-10、Waterbirds和CelebA数据集上对捷径在VGG、ResNet、DeiT和ConvNeXt架构上的影响进行了研究。我们发现捷径学习不仅仅集中在特定层，而是分布在整网络中，不同的网络部分在这一过程中扮演不同的角色。
### Conclusion
我们的研究不仅分析了捷径定位，还描述了其主要的变化轴。此外，我们分析了逐层捷径缓解策略，表明设计通用方法的难度，支持针对数据集和架构的特定方法。
## 636. `cs.LG` - 三阶段贝叶斯迁移学习框架以提高数据稀缺领域的预测能力 [PDF](https://arxiv.org/pdf/2510.26541), [HTML](https://arxiv.org/abs/2510.26541)
### Authors
Aidan Furlong,Robert Salko,Xingang Zhao,Xu Wu
### Background
机器学习在工程中的应用日益广泛，涵盖了各种应用场景。深度神经网络因其高性能和易用性而被广泛采用，但它们需要大量高质量的数据集。在实验数据往往稀疏、噪声或不足，无法构建稳健的数据驱动模型的情况下，迁移学习展现了有效性。这种方法利用了丰富相关数据的源领域来辅助缺乏数据的目标领域学习。深度 adversarial 网络 (DANNs) 通过学习领域不变的表示，有助于解决大领域变换下的迁移学习问题。然而，DANNs 在训练过程中可能不稳定，并且缺乏对不确定性量化的方法。因此，这项研究介绍了一种全新的三阶段的监督框架，即分阶段贝叶斯域对抗神经网络 (staged B-DANN)，该框架结合了参数迁移和共享潜空间适配。
### Innovation
该研究提出了三阶段的监督框架，即分阶段贝叶斯域对抗神经网络（staged B-DANN），该框架集成了参数迁移和共享潜空间适配的技术。具体而言，该框架包括三个阶段：首先，确定性特征提取器在源领域中进行训练；随后，这个特征提取器通过引入域对抗神经网络进行对抗性优化；最后，在适配的特征提取器上构建贝叶斯神经网络，以更好地处理条件变换并提供校准的不确定性估计。
### Conclusion
该三阶段分阶段贝叶斯域对抗神经网络方法首先在合成基准测试中得到了验证，显示出比标准迁移技术显著的优势。然后，该方法被应用于预测矩形通道中的关键热流，利用管实验数据作为源领域数据。研究结果表明，此方法能够提高预测的准确性和泛化能力，可能在未来辅助核工程中的其他领域。
## 637. `cs.LG` - 使用Jensen-Shannon距离的多类别局部校准 [PDF](https://arxiv.org/pdf/2510.26566), [HTML](https://arxiv.org/abs/2510.26566)
### Authors
Cesare Barbera,Lorenzo Perini,Giovanni De Toni,Andrea Passerini,Andrea Pugnana
### Background
开发值得信赖的机器学习模型需要其预测概率准确反映真实类别的频率。在多类别分类的校准概念中，强校准是最严格的，因为它要求所有预测概率在同一数据空间中同时校准。然而，现有的多类别校准方法缺乏对输入间距离的考量，导致它们容易受到邻近偏差的影响，即在特征空间稀疏区域，预测经常会被系统性地误校准。这一问题在高风险应用场景中尤为突出，如医疗保健领域，稀疏实例通常是风险最大的情况，更容易受到偏差治疗的影响。本研究针对这一主要缺陷，提出了一个多类别局部校准的新视角。
### Innovation
首次明确提出了多类别局部校准的概念，并与强校准建立了关系。探讨了现有评估指标在应用于多类别局部校准时的局限性，并提出了一种使用Jensen-Shannon距离对神经网络进行局部校准提升的方法，该方法通过预测概率与局部类频率估计之间的对齐来增强局部校准效果。
### Conclusion
通过理论分析和实证研究，本文验证了使用Jensen-Shannon距离提升局部校准的方法有效对抗现有多类别校准技术的局限性，为医疗保健等高风险应用场景提供了更为可靠和健壯的解决方案。
## 638. `cs.LG` - Aeolus: 多模态飞行延误数据集 [PDF](https://arxiv.org/pdf/2510.26616), [HTML](https://arxiv.org/abs/2510.26616)
### Authors
Lin Xu,Xinyun Yuan,Yuxuan Liang,Suwan Yin,Yuankai Wu
### Background
现有的飞行延误数据集通常局限于扁平的表格结构，无法捕捉延误传播过程中固有的时空动态。这限制了飞行延误预测研究的进步，以及基础模型在表格数据上的发展.
### Innovation
Aeolus 数据集通过提供三种对齐的模态来解决这一问题：（i）包含丰富的运营、气象和机场级别特征的表格数据集，覆盖超过5000万次航班；（ii）飞行链模块，用于建模延误在连续航班段中的传播，捕捉上游和下游依赖性；（iii）航班网络图，编码共享航空器、机组和机场资源连接，支持跨航班关系推理。数据集包含细致的时间分割、全面的特征和严格的泄漏预防，以支持现实和可重复的机器学习评估。Aeolus 数据集支持回归、分类、时间结构建模和图学习任务，作为表格、序列和图模态统一基准.
### Conclusion
Aeolus 数据集填补了专用模型和通用结构数据的关键空白，通过提供基准实验和预处理工具，支持广泛的应用场景和研究。
## 639. `cs.LG` - 作为贝恩斯坦基上概率轨迹变异近似的 Wasserstein 回归 [PDF](https://arxiv.org/pdf/2510.26607), [HTML](https://arxiv.org/abs/2510.26607)
### Authors
Maksim Maslov,Alexander Kugaevskikh,Matthew Ivanov
### Background
本文讨论了在机器学习中越来越重要的分布回归问题。现有方法通常忽视概率空间的几何结构或计算成本高昂。
### Innovation
本文提出了一种新的方法，结合了用贝恩斯坦基参数化概率轨迹和最小化概率分布之间的 Wasserstein 距离。关键思想是将条件分布建模为由输入变量构建的多项式函数控制的光滑概率轨迹，该轨迹由加权高斯分量定义。损失函数是预测的高斯分布与经验数据之间的平均平方 Wasserstein 距离，考虑了分布的几何结构。该方法使用自差异化优化进行模型训练，并在合成数据集上进行了实验，结果显示该方法在 Wasserstein 距离、能量距离和 RMSE 指标方面具有良好的近似质量，特别是在非线性显著的情况下。模型表现出了比或优于其他替代方法的轨迹平滑性，并且由于通过控制点明确参数化而具有良好的 robust 性和高可解释性。
### Conclusion
本文开发的方法是一种平衡解决方案，结合了几何准确性、计算实用性和可解释性。进一步的研究可能包括将方法扩展到非高斯分布、应用熵正则化以加速计算以及适应处理高维数据以拟合表面和更复杂结构。
## 640. `cs.LG` - 通常见而不显：组合贝叶斯优化中的热核 [PDF](https://arxiv.org/pdf/2510.26633), [HTML](https://arxiv.org/abs/2510.26633)
### Authors
Colin Doumont,Victor Picheny,Viacheslav Borovitskiy,Henry Moss
### Background
贝叶斯优化（BO）在材料科学和神经架构搜索等多种组合任务中具有潜力。然而，BO 需要专门的内核来有效地建模组合领域。尽管最近引入了一些组合内核，但它们之间的关系仍不清楚。本文致力于解决这个问题，提出了一个统一的基于热核的框架，系统地推导并表达为简单的闭式表达式。研究表明，许多成功的组合内核实际上与热核相关或等价，且实验验证了该理论。同时，分析确认了某些算法（比如《Bounce》中提到的）在特定条件下会大幅下降，而热核对此类条件不敏感。最终，基于热核的快速且简单的工作流能够达到最先进的结果，甚至在某些情况下超越了复杂的算法
### Innovation
本文开发了基于热核的统一框架，系统推导出一系列简单的闭式表达形式内核，理论证明了多种成功的组合内核与其相关或等价，揭示了不同内核之间的关系。分析还确认和扩充了《Bounce》中关于某些算法性能受函数最优位置结构影响的结论。最终实验证明，基于热核的方法能取得最先进的性能，并且比复杂算法更快速简单
### Conclusion
本文基于热核的统一框架可以有效地建模组合领域，并能达到最先进水平的结果。虽然基于热核的方法可能看起来快速简单，但其性能在算法性能不敏感于最优位置结构时会很稳健。
## 641. `cs.LG` - MSAD: 深入探究时间序列异常检测中的模型选择 [PDF](https://arxiv.org/pdf/2510.26643), [HTML](https://arxiv.org/abs/2510.26643)
### Authors
Emmanouil Sylligardos,John Paparrizos,Themis Palpanas,Pierre Senellart,Paul Boniol
### Background
时间序列异常检测是一个基础但重要的任务，对于许多应用的下游性能至关重要。尽管学术界对此领域越来越感兴趣，但是最近的基准测试和评估研究显示，没有一种适用于所有时间序列数据集的最佳异常检测方法。因此，只能通过提出一种基于时间序列特性的模型选择方法，来选择最适合的异常检测方法，以应对非常不同的时间序列数据，从而实现大规模的可扩展解决方案。现有的自动化机器学习（AutoML）解决方案并不适用于时间序列异常检测，且没有针对此领域的模型选择时间序列方法的评估。
### Innovation
本文研究了用于异常检测的模型选择的时间序列分类方法。总共评估了来自16个基础分类器的234种模型配置，在超过1980个时间序列上，这是首次对时间序列分类用于异常检测的模型选择进行广泛的实验性评估。结果显示，模型选择方法在执行时间相似的情况下，整体上优于单个异常检测方法。这一评估为展示时间序列分类算法在异常检测上的准确性和效率奠定了基础，并为通用AutoML管道中的模型选择步骤提供了强有力的基准。
### Conclusion
这是展示时间序列分类算法在异常检测上准确性和效率的第一步，将作为通用AutoML管道中模型选择步骤的基础基准，然后可以引导模型选择步骤的设计和改进，并且试图首次评估了用于时间序列异常检测的模型选择方法。
## 642. `cs.LG` - 用于学习非梯度场动力学的卷曲流匹配 [PDF](https://arxiv.org/pdf/2510.26645), [HTML](https://arxiv.org/abs/2510.26645)
### Authors
Katarina Petrović,Lazar Atanackovic,Viggo Moro,Kacper Kapuśniak,İsmail İlkan Ceylan,Michael Bronstein,Avishek Joey Bose,Alexander Tong
### Background
在自然科学中，通过群体观测构建自然过程传输动力学的模型是一个普遍问题。当前方法通常基于最小作用原理，产生梯度场动态，导致最小化两个概率测度之间的能量泛函的轨迹。然而，许多实际系统，如单细胞RNA中的细胞周期，表现出非梯度的周期性行为，这目前的方法，如流和连接匹配，难以捕捉到。因此，本研究致力于提出一种新的方法Curly Flow Matching (Curly-FM)来学习非梯度场动力学，通过设计和求解带有非零漂移参考过程的薛定谔桥问题，从而扩展了流动匹配模型，使其适用于模型物理系统中已知的周期性行为。
### Innovation
Curly-FM通过引入非零漂移参考过程设计并求解薛定谔桥问题，打破了传统流动匹配方法中的零漂移假设，能够学习非梯度场动力学。这种方法使用推断出的速度以及群体快照数据构建参考过程，从而能够捕捉到非梯度和周期性的动力学行为，更好地匹配参考过程和群体边缘分布。这种方法扩展了流动匹配模型的应用范围，使之能够建模已知周期性的物理行为。
### Conclusion
Curly-FM可以学习轨迹，使得这些轨迹更好地匹配参考过程和群体边缘分布。这种方法为企业和研究机构解决单细胞轨迹、计算流体动力学和海洋环流等方面的问题提供了新工具。代码库可以在该链接中访问：this https URL
## 643. `cs.LG` - 紧致的差分隐私主成分分析通过矩阵相干性 [PDF](https://arxiv.org/pdf/2510.26679), [HTML](https://arxiv.org/abs/2510.26679)
### Authors
Tommaso d'Orsi,Gleb Novikov
### Background
本文重新探讨了在保持隐私的情况下计算矩阵的前$r$个奇异向量的跨度的问题。现有的私人算法一般依赖于对奇异向量分解的优化，但这些算法在误差控制上效果有限。有必要开发一种不仅能保持隐私还能在误差控制上有所改进的算法。本文研究了如何使用简单的奇异值分解和标准扰动机制来实现这一目标，特别是在差分隐私下，找到有效的算法，以便在保证隐私的同时提供最优的近似结果。
### Innovation
本文提出了一个基于奇异值分解和标准扰动机制的简单且高效算法，该算法能够提供一个私人秩-$r$近似，其误差仅依赖于输入的秩-$r$相干性和谱间隙。该算法在一些情况下显著优于最先进的技术，特别是在密集矩阵设置中，它实现了单峰PCA的最优非隐私算法所达到的相同的保证，而在此之前的一些私人算法未能达到这一目标。此外，本文还证明了在高斯扰动下（秩-$r$）相干性不会增加，这意味着基于高斯机制的任何估计器（包括本文的算法）都将保持输入的相干性。因此，本文扩展了对相干性的研究，探讨了其在图问题和其他结构化模型中的应用。
### Conclusion
本文不仅提供了一个新的私人算法，使在差分隐私下计算矩阵的主成分成为可能，而且证明了在高斯扰动下相干性的不增加性质，这有助于确保私人算法的精确度。此外，还展望了相干性在解决图问题和其他约束满足问题上的应用。
## 644. `cs.LG` - LoRAQuant: 混合精度LoRA超低比特量化 [PDF](https://arxiv.org/pdf/2510.26690), [HTML](https://arxiv.org/abs/2510.26690)
### Authors
Amir Reza Mirzaei,Yuqiao Wen,Yanshuai Cao,Lili Mou
### Background
LoRA（低秩适应）已经成为一种在大型语言模型（LLMs）中进行参数高效微调的流行技术。在许多真实场景中，同时加载多个适配器可以实现对个性化用户体验的支持或支持多种任务。尽管每个适配器在单独情况下都比较轻量，但在大规模应用时其整体代价变得非常高昂。因此，为了应对这个问题，我们提出了LoRAQuant，这是一种针对LoRA的混合精度后训练量化方法。该方法通过奇异值分解（SVD）重新参数化每个适配器，从而使重要的信息集中在特定的行和列，从而使得重要的部分可以量化为高精度，而将其余部分量化为超低比特宽度。研究人员在一系列实验中使用了包括LLaMA 2-7B、LLaMA 2-13B和Mistral 7B在内的模型来评估其对数学推理、编程和总结任务的表现影响。实验结果表明，LoRAQuant使用比特数显著低于其他量化方法，但实现了可比甚至更高的性能。
### Innovation
我们提出了一种名为LoRAQuant的方法，这是一种针对LoRA的混合精度后训练量化方法。通过SVD重新参数化每个适配器，LoRAQuant能够将重要的信息集中到特定的行和列，进而允许对重要部分进行高精度量化，同时将其他部分量化为超低比特宽度。这种方法旨在降低大规模部署时的计算和存储成本，同时保持或提高模型性能。
### Conclusion
实验表明，与现有的量化方法相比，LoRAQuant使用比特数显著较少，但在数学推理、编程和总结等任务上达到了可比甚至更高的性能。这表明LoRAQuant在保持模型性能的同时，进一步降低了量化后的模型资源占用。
## 645. `cs.LG` - 正则化项如何使可逆神经网络成为贝叶斯点估计器 [PDF](https://arxiv.org/pdf/2510.26704), [HTML](https://arxiv.org/abs/2510.26704)
### Authors
Nick Heilenkötter
### Background
可逆神经网络因其固有的稳定性和可解释性而在逆问题中具有吸引力。最近，从贝叶斯角度研究了这两种可逆神经网络的优化策略：一种近似重建映射，另一种近似前向算子，但每种策略都有局限性。为了克服这些局限，作者引入并分析了两种网络训练中的正则化项，使得在网络的逆运算中重获经典贝叶斯点估计器的特性。
### Innovation
作者提出了两种新的正则化项，当网络逆运算时，能够恢复经典贝叶斯点估计器的特性。第一种正则化项可与后验均值相关，第二种与最大后验估计（MAP）相关。理论分析揭示了每个正则化项如何影响网络学得的前向算子和逆重建映射。数值实验支持了这些发现，展示了这些正则化项如何以稳定且可解释的方式引入数据依赖性。
### Conclusion
作者通过理论和实验证明了两种新的正则化项能够使得可逆神经网络恢复经典贝叶斯点估计器的特性，并且通过正则化项使得网络的能力在数据依赖性方面表现出稳定和可解释的特性。
## 646. `cs.LG` - 预算化多专家推诿 [PDF](https://arxiv.org/pdf/2510.26706), [HTML](https://arxiv.org/abs/2510.26706)
### Authors
Giulia DeSalvo,Clara Mohri,Mehryar Mohri,Yutao Zhong
### Background
通过学习将不确定性预测委托给昂贵的专家，可以显著提高机器学习系统的准确性和效率。然而，标准的训练程序通常要求对每个训练实例都查询所有专家，当专家查询产生高昂的计算或资源成本时，这种方式变得非常昂贵。这违背了推诿的核心目标：限制不必要的专家使用。为解决这一挑战，引入了预算化的推诿框架，旨在在训练过程中最小化专家查询成本的同时训练有效的推诿算法。这种方法受到主动学习的启发，但在标签已知的情况下，核心挑战是以最低的成本和最高的预测性能选择查询哪些专家。
### Innovation
提出了针对两阶段和单阶段多专家推诿设置的新算法，这些算法选择性地每训练一个示例就只查询部分专家，而不是所有专家。虽然这些算法受到了主动学习的启发，但它们其实有一个根本差异：标签是已知的，核心挑战是在保持成本和预测性能之间取得平衡决定查询哪些专家。此外，论文还为这两种算法提供了理论保证，包括泛化界限和标签复杂性分析。
### Conclusion
在多个领域的实验结果表明，所提出的算法在训练成本显著降低的同时没有牺牲预测准确性，证明了我们的预算意识推诿算法的实用性。
## 647. `cs.LG` - 关于仅使用单一训练种子评估机器遗忘的限制 [PDF](https://arxiv.org/pdf/2510.26714), [HTML](https://arxiv.org/abs/2510.26714)
### Authors
Jamie Lanyon,Axel Finke,Petros Andreou,Georgina Cosma
### Background
机器遗忘（MU）旨在从已训练的模型中去除某些数据点的影响，而不必进行昂贵的重新训练。大多数实际的MU算法只是近似的方法，其性能只能通过实际评估来确定。因此，进行实际比较时必须尽可能保持代表性。一种常见做法是从同一个已训练模型开始，独立地运行MU算法多次。但在本工作中，作者证明了即使对于相同的架构和相同的数据库，某些MU方法也高度敏感于用于模型训练的随机数种子选择。这意味着仅使用单一训练种子来评估MU算法可能会导致非代表性的结果。因此，作者建议在比较MU算法时也应该反映不同模型训练种子的变化性（variability）.
### Innovation
本文揭示了仅使用单一训练种子评估机器遗忘的非代表性问题，并指出应考虑不同模型训练种子带来的变化性来更准确地评估MU算法，这是一种新的评估方法论补充和视角提出（innovation in evaluation approach）.
### Conclusion
本研究强调了在评估机器遗忘算法时应兼顾不同模型训练种子带来的变化性（variability），以获得更可靠和真实的评价结果。
## 648. `cs.LG` - LSM-MS2：跨光谱识别和生物解释的基石模型 [PDF](https://arxiv.org/pdf/2510.26715), [HTML](https://arxiv.org/abs/2510.26715)
### Authors
Gabriel Asher,Devesh Shah,Amy A. Caudy,Luke Ferro,Lea Amar,Ana S. H. Costa,Thomas Patton,Niall O'Connor,Jennifer M. Campbell,Jack Geremia
### Background
尽管质谱数据量巨大，但大部分仍未被充分解读，生物和化学信息未能充分利用。机器学习的最新进展开始填补这一空白，特别是在如串联质谱数据谱图识别等任务中。
### Innovation
提出了最新一代的LSM-MS2，这是一种大规模的深度学习基础模型，基于数百万条光谱训练，学习语义化学空间。LSM-MS2在谱图识别中达到最先进的性能，相较于现有方法，在识别具有挑战性的异构化合物方面准确率提升30%，在复杂生物样本中正确识别率提高42%，并在低浓度条件下保持稳健性。此外，LSM-MS2生成丰富的光谱嵌入，允许直接从少量下游数据进行生物学解释，成功区分疾病状态并预测临床结果，适用于多种转化应用。
### Conclusion
LSM-MS2显著提高了谱图识别的准确性和在复杂生物样本中的性能，同时支持直接的生物学解释，为转化应用提供了新的机会。
## 649. `cs.LG` - 一种通信高效的分布式学习的All-Reduce兼容Top-K压缩器 [PDF](https://arxiv.org/pdf/2510.26709), [HTML](https://arxiv.org/abs/2510.26709)
### Authors
Chuyan Chen,Chenyang Ma,Zhangxin Li,Yutong He,Yanjie Dong,Kun Yuan
### Background
在大规模分布式机器学习中，通信仍然是一个主要瓶颈。梯度稀疏化作为缓解这一挑战的有前途策略已经崭露头角。然而，现有的梯度压缩器存在明显不足：Rand-$K$丢弃了结构信息，表现不佳；Top-$K$虽然保留了信息量，但丧失了收缩特性，并且需要成本高昂的All-Gather操作。
### Innovation
本文提出了一种All-Reduce兼容的Top-$K$压缩器ARC-Top-$K$，使用轻量级梯度素描来对齐节点上稀疏模式，从而实现无索引的All-Reduce操作，同时保留全局重要信息。ARC-Top-$K$是一个可证明的收缩压缩器，当与动量误差反馈（EF21M）结合使用时，可以在标准假设下实现线性加速和更佳的收敛速度。实验证明，ARC-Top-$K$在保持与Top-$K$相同准确性的同时，将训练时间减少了高达60.7%，提供了一种既高效又具扩展性的解决方案，结合了Rand-$K$的鲁棒性和Top-$K$的强大性能。
### Conclusion
ARC-Top-$K$不仅继承了Rand-$K$的鲁棒性和Top-$K$的强性能，还在保持相同准确性的前提下，极大地提高了训练效率，实现了最佳的通信效率和计算效率平衡。
## 650. `cs.LG` - 使用深度学习的脉冲星检测 [PDF](https://arxiv.org/pdf/2510.25774), [HTML](https://arxiv.org/abs/2510.25774)
### Authors
Manideep Pendyala
### Background
脉冲星巡天产生数百万候选目标，手动检查会过于繁重。这项研究构建了一种深度学习流水线，融合阵列提取的特征与图像诊断，以筛选脉冲星候选目标。通过Giant Metrewave射电望远镜（GMRT）约500GB的数据生成了约32,000个候选目标，并提供四种诊断结果。
### Innovation
该研究改进了CNN架构和训练方法（包括正则化、学习率调度、最大范数约束），并采用基于生成对抗网络（GAN）的生成器来缓解类别不平衡，最终在保留轻量级的同时，实现了94%的精度和召回率平衡，提高了对脉冲星（少数类）的发现率。同时，该方法适用于各种巡天调查且可扩展到未来的高通量设施。
### Conclusion
结合阵列和图像通道的诊断方式优于仅使用图像的方法，适度的生成性增强方式显著提高了对脉冲星（少数类）的检测率。该研究方法在保留实时性的同时提高了脉冲星候选目标的筛选准确性和效率。
## 651. `cs.LG` - zFLoRA: Zero-Latency Fused Low-Rank Adapters [PDF](https://arxiv.org/pdf/2510.25784), [HTML](https://arxiv.org/abs/2510.25784)
### Authors
Dhananjaya Gowda,Seoha Song,Harshith Goka,Junhyun Lee
### Background
大型语言模型（LLMs）通常与针对特定任务的适配器一起部署，以支持多种下游应用。然而，这些适配器参数数量相对较少（通常不到基模型的1%），但在推断时会显著增加计算成本（最多比基模型增加2.5倍）。
### Innovation
本文提出了零延迟融合低秩适配器（zFLoRA），该适配器在基模型基础上引入了零或可忽略的延迟开销。实验表明，zFLoRA在1B、3B和7B规模的LLM上的表现优于流行的监督微调基准，包括低秩适配器（LoRA）和全程微调（FFT）。该研究在18种不同任务的三大类别（常识推理、数学推理和总结对话）上进行了实验。
### Conclusion
通过在NPU和GPU平台上进行延迟测量，结果表明，提出的zFLoRA适配器在引入零或可忽略的延迟开销方面表现出色。
## 652. `cs.LG` - 基于电压依赖突触可塑性的无监督局部学习方法在阻变和铁电突触中的应用 [PDF](https://arxiv.org/pdf/2510.25787), [HTML](https://arxiv.org/abs/2510.25787)
### Authors
Nikhil Garg,Ismael Balafrej,Joao Henrique Quintino Palhares,Laura Bégon-Lours,Davide Florini,Donato Francesco Falcone,Tommaso Stecconi,Valeria Bragaglia,Bert Jan Offrein,Jean-Michel Portal,Damien Querlioz,Yann Beilliard,Dominique Drouin,Fabien Alibart
### Background
边缘计算设备上部署人工智能面临能耗高和功能受限的挑战，而大脑启发的学习机制能实现实时适应并使用低功耗。纳米尺度的阻变存储器可能在实现边缘设备上执行人工智能负载中发挥关键作用。本文旨在探讨电压依赖突触可塑性（VDSP）作为基于Hebb原则的无监督和局部学习方法的高效手段。
### Innovation
提出了电压依赖突触可塑性（VDSP），这是一种无监督和局部学习的方法，适用于三种不同类型的突触设备（TiO$_2$，HfO$_2$基于的金属氧化物纳米线突触和HfZrO$_4$基于的铁电隧道结（FTJ）），并且这种方法无需复杂的脉冲整形电路即可实现在线学习。
### Conclusion
系统级仿真结果显示，包含这些设备的脉冲神经网络在MNIST模式识别任务中的无监督学习表现达到了最先进的性能，使用200个神经元时，所有设备的准确率均超过83%。此外，研究还评估了设备变异性的影响，提出了增强鲁棒性的缓解策略。
## 653. `cs.LG` - 在单细胞RNA-seq基础模型中发现可解释的生物概念 [PDF](https://arxiv.org/pdf/2510.25807), [HTML](https://arxiv.org/abs/2510.25807)
### Authors
Charlotte Claye(MICS),Pierre Marschall,Wassila Ouerdane(MICS),Céline Hudelot(MICS),Julien Duquesne
### Background
单细胞RNA-seq的深度学习模型在下游任务中表现出色，但它们仍然像黑箱一样工作，限制了它们在生物学发现中的应用。虽然最近的研究表明稀疏字典学习可以从深度学习模型中提取概念，但在生物医学成像和蛋白质模型方面的应用前景良好，但生物序列对于人类来说并不天然具有可解释性。因此，解释这些生物概念仍然是一个挑战。
### Innovation
本研究提出了一个基于概念的解释框架，专注于概念解释和评估。该框架提出了一种基于反事实扰动的归因方法，可以识别影响概念激活的基因，超越了差异表达分析等相关性方法。此外，该研究提供了两种互补的解释方法：由交互界面支持的专家驱动分析和基于归因的基于本体的方法，用于生物途径富集。
### Conclusion
该研究通过免疫细胞数据集中的顶层稀疏自动编码器训练提取的概念来应用该框架，在免疫学领域专家的帮助下，表明概念在保持隐空间表达丰富性和信息量的同时提高了解释性，从而为这些模型在假设生成和发现中的应用奠定了理论框架。
## 654. `cs.LG` - 使用SHAP实现棋局逐子解释 [PDF](https://arxiv.org/pdf/2510.25775), [HTML](https://arxiv.org/abs/2510.25775)
### Authors
Francesco Spinnato
### Background
现代象棋引擎能够提供精确但不透明的评估，通常以小马分（centipawn）得分为形式表示。虽然这些输出对决策有效，但它们会隐藏单个棋子或棋型的贡献。本文探讨了将SHAP（Shapley值解释法）应用于象棋分析领域，旨在将象棋引擎的评估结果归因于特定棋盘上的棋子。通过将棋子视为特征，并系统地移除它们，我们计算出了每个棋子的逐步贡献，这些贡献能够在局部上真实且易于理解地解释引擎的输出。这种方法汲取了经典象棋教学的理念，其中棋手通过心理地移除棋子来评估局面，同时也基于现代可解释人工智能技术。这种方法为可视化、人类训练和引擎比较开辟了新可能。本文还发布了伴随代码和数据，促进未来在可解释的象棋AI方面的研究。
### Innovation
本文提出了将SHAP方法应用于象棋分析领域，通过系统的移除棋子来计算每个棋子的逐步贡献，以解释象棋引擎的评估输出。这种方法结合了经典的象棋教学方法和现代可解释AI技术，为评估象棋局面提供了一种新的视角和分析工具。此外，研究还发布了相关代码和数据，以促进进一步的研究与发展。
### Conclusion
本文提出的方法为象棋局面的解释打开了新的可能性，为可视化、人类训练和引擎对比提供了新途径。通过发布相关的代码和数据，希望促进更多未来的研究在可解释的象棋AI领域取得进展。
## 655. `cs.LG` - StreetMath: 研究大型语言模型在近似推理行为 [PDF](https://arxiv.org/pdf/2510.25776), [HTML](https://arxiv.org/abs/2510.25776)
### Authors
Chiung-Yi Tseng,Somshubhra Roy,Maisha Thasin,Danyang Zhang,Blessing Effiong
### Background
已有大量研究探讨了大型语言模型（LLMs）在精确算术运算中的数学推理能力，尤其是在自回归架构中的表现。然而，LLMs 在进行非正式、快速的数学操作时的近似推理能力却很少受到关注，特别是在非自回归解码模型方面。本文通过引入 StreetMath 基准测试，弥补了这一研究空白。StreetMath 基准测试旨在评估模型在真实世界近似场景中的近似推理能力。研究者对多种 LLM 架构进行了广泛的评估，并使用机制可解释性技术探查其内部计算状态。研究发现，LLMs 在近似任务中通常试图计算精确值或调用外部工具，尽管有时在早期层或步骤中可以获得正确答案，但仍然会消耗更多的令牌。此外，精确和近似计算主要依赖于不同的神经组件。
### Innovation
本文通过引入 StreetMath 基准测试，首次系统性地评价了 LLMs 在近似推理任务中的表现。研究者采用了多种 LLM 架构，并使用机制可解释性技术深入探究了模型的内部计算状态，揭示了精确和近似计算主要依赖于不同的神经组件，并提出 LLMs 在近似推理任务中并未表现出人类在街头数学中的认知吝啬行为。
### Conclusion
LLMs 在近似任务中通常尝试计算精确值或调用外部工具，尽管有时可以获得正确答案，但在解决近似任务时会消耗更多的令牌。精确和近似计算主要依赖于不同的神经组件，LLMs 在近似推理任务中并未表现出认知吝啬行为。研究结果还表明，LLMs 在精确和近似算术运算中依赖不同的神经网络组件。streetmath 数据集对外公开，供其他研究人员使用。
## 656. `cs.LG` - RNAGenScape: 使用流形 Langevin 动力学进行 mRNA 序列的属性引导优化和插值 [PDF](https://arxiv.org/pdf/2510.24736), [HTML](https://arxiv.org/abs/2510.24736)
### Authors
Danqi Liao,Chen Liu,Xingzhi Sun,Dié Tang,Haochen Wang,Scott Youlten,Srikar Krishna Gopinath,Haejeong Lee,Ethan C. Strayer,Antonio J. Giraldez,Smita Krishnaswamy
### Background
mRNA 设计和优化在合成生物学和治疗开发中至关重要，但尚未在机器学习中得到充分研究。系统优化 mRNA 受制于数据稀缺性和样本不平衡以及序列-功能关系的复杂性。目前缺乏能够高效探索并确保生成的序列接近可行的 mRNA 流形的方法，尤其是在稀疏数据和欠采样的情况下给出了具有生物学合理性的结果。
### Innovation
提出了 RNAGenScape，一种属性导向的流形拉普拉斯动力框架，通过迭代更新 mRNA 序列来优化结构化的潜在空间。RNAGenScape 结合了有序自编码器以结构化潜在空间从而高效且生物学合理地探索，同时利用流形投影器确保每次更新回到流形中，从而实现属性导向的优化和序列之间的平滑插值，即使在数据稀缺和欠采样的条件下也能保持鲁棒性，同时确保中间产物接近可行的 mRNA 流形。实验结果显示，RNAGenScape 在三个真实的 mRNA 数据集上都提高了目标属性，表现出更高的成功率和效率，优于专门为蛋白质或非生物数据开发的各种生成或优化方法。该方法通过提供连续且与数据对齐的轨迹揭示了编辑如何影响功能，将一套可扩展的范式用于可控制的 mRNA 设计和潜在空间探索应用于 mRNA 序列模型中。
### Conclusion
RNAGenScape 通过提供高效且基于数据的属性导向优化和插值方法，为 mRNA 设计和潜在空间探索提供了一个可扩展的框架。该方法证明了在面对稀疏数据和复杂序列-功能关系时的鲁棒性，为未来的研究提供了新的方向。
## 657. `cs.LG` - 使用Transformer学习伪随机数：排列同余生成器、课程学习和可解释性 [PDF](https://arxiv.org/pdf/2510.26792), [HTML](https://arxiv.org/abs/2510.26792)
### Authors
Tao Tao,Maissam Barkeshli
### Background
研究团队探讨了Transformer模型是否能学会由排列同余生成器（Permuted Congruential Generators, PCGs）生成的序列。PCGs是一类广泛使用的伪随机数生成器（Pseudo-Random Number Generators, PRNGs），通过一系列位移、异或、旋转和截断操作给隐藏状态带来了显著难度。对比之下，经典的一次同余生成器（Linear Congruential Generators, LCGs）的难度相对较低。尽管域外已经有研究公开了对经典控制攻击的成果，但本研究发现，Transformer模型依然能够成功地在未见过的PCG变体序列上进行上下文内的预测，并且能在包含多类型PRNG的训练样本中，发现来自不同排列的结构特点。研究还研究了不同模数m对预测所需序列元素数量的影响，发现其呈现与平方根成正比的关系。对于更大的模数，模型的训练过程中会出现长期停滞的有效阶段，表明在较大模数的训练中，需要从小的模数模训练数据来进行有效的课程学习。进一步的研究还发现，模型中嵌入层表现出自发形成的位移不变簇的现象，揭示了小模数到大模数表示的转移机制。
### Innovation
研究展示了Transformer模型能够成功预测由排列同余生成器生成的未见过的序列，即使输出被截断为单个位也能被可靠预测。在面对多类型的PRNG训练时，模型能够结合学习来自不同排列的结构。研究揭示了模数对预测所需序列元素数量的影响，并讨论了模数越大时模型训练中的长期停滞问题以及对课程学习的需求。此外，研究还探索了嵌入层表现出的位移不变簇现象，为理解不同模数之间的表示转换提供了新的视角。
### Conclusion
研究发现，Transformer模型能够有效地学习和预测由排列同余生成器产生的伪随机数序列。对于较大的模数，有效模型学习需要最初的课程学习阶段。不仅如此，研究还发现嵌入层中自发形成位移不变簇的新现象，这一现象揭示了不同模数之间的表示转移机制。这些发现有助于深入理解Transformer对抗复杂结构生成模型的能力，并为进一步研究提供新的方向。
## 658. `cs.LG` - 注意力增强的GNN和RNN-注意模型在先进网络安全入侵检测中的应用 [PDF](https://arxiv.org/pdf/2510.25802), [HTML](https://arxiv.org/abs/2510.25802)
### Authors
Jayant Biradar,Smit Shah,Tanmay Naik
### Background
论文背景在于提出一种新的混合深度学习架构，巧妙结合了图神经网络（GNNs）、循环神经网络（RNNs）和多头注意力机制，以显著增强网络安全入侵检测能力。使用全面的UNSW-NB15数据集，包含多样化的网络流量模式，通过处理空间依赖性（图形结构关系）和时间动态性（网络事件的顺序分析）来提升模型性能。集成的注意力机制不仅提高了模型的可解释性，还增强了特征选择能力，助力安全分析师集中资源处理高影响的安全事件，这是现代实时入侵检测系统的关键需求。论文通过广泛的实验评估，展示了提出的混合模型在多个评估指标（准确性、精确率、召回率和F1分数）上优于传统机器学习方法和单独的深度学习模型，特别是在检测高级攻击模式（如APT、DDoS攻击和零日攻击）方面性能尤为出色，为复杂网络环境下的下一代网络安全应用提供了有前景的解决方案。
### Innovation
研究创新在于开发了一种新的混合深度学习架构，该架构结合了图神经网络（GNNs）、循环神经网络（RNNs）和多头注意力机制，显著提升了网络安全入侵检测能力。通过UNSW-NB15数据集，该模型能够捕捉网络事件的时间动态和空间依赖性，同时注意力机制提供了一种改进模型可解释性和增强特征选择的新方法。该模型在F1分数和不同类型攻击模式的检测上表现出色，特别是APT、DDoS攻击和零日攻击等复杂的攻击模式。
### Conclusion
研究表明提出的混合模型在网络安全入侵检测中具有优越性，与传统的机器学习方法和单独的深度学习模型相比有着明显的优势。尤其是在检测复杂的攻击模式方面，该模型表现出了特别强的性能，展示了其作为复杂网络环境中下一代网络安全应用的潜力。
## 659. `cs.LG` - 多模态臂问题：遗憾下界与最优算法 [PDF](https://arxiv.org/pdf/2510.25811), [HTML](https://arxiv.org/abs/2510.25811)
### Authors
William Réveillard,Richard Combes
### Background
研究了一种具有独立同分布回报的随机多臂赌博机问题，其中的期望回报函数最多具有m个模态。
### Innovation
提出了第一个已知的可计算性强约算法，用于解决Graves-Lai优化问题，从而使得能够实施该多臂赌博机问题的最优算法。
### Conclusion
提出的算法代码在公开可用，解决了多模态臂问题的遗憾下界，并提供了最优算法的实现。
## 660. `cs.LG` - 基于模糊逻辑算法的方法进行基于评论的实体排名：分析 [PDF](https://arxiv.org/pdf/2510.25778), [HTML](https://arxiv.org/abs/2510.25778)
### Authors
Pratik N. Kalamkar,Anupama G. Phakatkar
### Background
意见挖掘，也称为情感分析，是一个研究领域，它分析人们对产品、服务、组织、个人、议题、事件、主题及其属性的态度、情感、评价和评估。整体词典法不考虑每个观点的强度，即意见是否非常负面（或正面）、强烈负面（或正面）、适度负面（或正面）、非常轻微负面（或正面）或轻微负面（或正面）。这项研究提出了一个基于模糊逻辑算法的方法，通过按不同程度（即非常轻微、轻微、适度、非常强烈和强烈）对评论和用户查询的方向性进行分类来对实体进行排名。该方法结合了与特定产品某方面相关的意见词（如副词、形容词、名词和动词），并使用模糊逻辑算法对意见词进行分类，以及使用句法学分析来确定需要的方面词汇之间的关系，以便寻找满足特定方面兴趣的观点词汇，从而确定该方面在评论中的实体分数，从而改进整体观点强度的处理，提供更具体、详细的观点分析结果，使实体排名更精确，结果更具参考价值。
### Innovation
该研究提出了一种基于模糊逻辑算法的方法，该方法通过将意见词按不同的程度分类（非常轻微、轻微、适度、非常强烈和强烈），结合与特定产品方面相关的意见词，对实体进行排名。这种方法能够更精确地处理观点的强度，提供更具体、详细的意见分析结果，使得实体排名结果更加准确和有参考价值。传统的整体词典法仅考虑观点的存在与否，而不考虑其强度，这可能导致排名不够精确。该项研究提出的基于模糊逻辑算法的方法弥补了这一不足，提供了更详细和准确的观点分析
### Conclusion
总之，本文提出的一种基于模糊逻辑算法的方法能够对评论进行更具体和详细的意见分析，基于观点的方向和强度对实体进行排名。相比于传统的整体词典法，这项研究的方法能够提供更精确和准确的实体排名结果，进一步提高了意见分析的实用性和应用价值。
## 661. `cs.LG` - Flex-GAD : 弹性图异常检测 [PDF](https://arxiv.org/pdf/2510.25809), [HTML](https://arxiv.org/abs/2510.25809)
### Authors
Apu Chakraborty,Anshul Kumar,Gagan Raj Gupta
### Background
在有属性的网络中检测异常节点对于识别社会网络、学术引用图和电商平台中的欺诈、错误信息和可疑行为至关重要。现有的图异常检测方法一般只捕捉节点的结构连接或描述属性其中之一，而Flex-GAD框架则通过结合结构和描述性信息，为节点级别的图异常检测提供了新的解决方案，适用于不同规模和结构的各种真实世界有属性的网络数据集。
### Innovation
Flex-GAD框架引入了新颖的基于社区的图卷积网络（GCN）编码器来建模节点嵌入中的社区内和社区间信息，并与标准属性编码器结合，通过自注意力机制进行信息融合，实现对不同编码器输出的自动加权和有效集成，提高了异常检测的准确性和鲁棒性。此外，Flex-GAD在性能和效率上都优于之前的顶级方法GAD-NR，特别是在训练时间上表现更佳。
### Conclusion
Flex-GAD通过灵活地结合结构和描述性信息，在多种类型的真实世界有属性图形数据集上展示了其优于现有方法的有效性和灵活性，特别是在处理大规模和异构结构的数据时显示出显著的优点和潜力。
## 662. `cs.LG` - L_1-范数正则化不定核逻辑回归 [PDF](https://arxiv.org/pdf/2510.26043), [HTML](https://arxiv.org/abs/2510.26043)
### Authors
Shaoxin Wang,Hanjing Yao
### Background
核逻辑回归（KLR）是一种广泛应用的强大分类方法，能够在多种领域中实现高效的分类。虽然传统的肯定定核能捕捉结构信息，但在许多实际场景中，不定核能够捕捉更多特定领域的结构性信息，但其带来的非光滑性和非凸性使得优化变得复杂。
### Innovation
本文提出了一个新的$L_1$-范数正则化不定核逻辑回归（RIKLR）模型，它通过$L_1$-范数罚项引入稀疏性，增强了模型的可解释性和泛化能力。为了克服此类模型优化过程中的挑战，本文开发了一种理论上可靠且计算高效的近似线性化算法。
### Conclusion
实验结果表明，提出的RIKLR方法在多个基准数据集上的准确性和稀疏性方面表现更加出色。
## 663. `cs.LG` - 可靠的责任人工智能评价指标的探索 [PDF](https://arxiv.org/pdf/2510.26007), [HTML](https://arxiv.org/abs/2510.26007)
### Authors
Theresia Veronika Rampisela,Maria Maistro,Tuukka Ruotsalo,Christina Lioma
### Background
随着人工智能（AI）的发展，包括科学中的AI（AIS），应当遵循负责任的AI原则。尽管负责性AI的进步通常通过评价指标来量化，但很少有工作评估这些指标自身的稳健性和可靠性。此前关于推荐系统公平性指标的稳健性研究为其提供了借鉴，但缺乏全面的指南来开发可靠的责任AI指标。该研究旨在填补这一空白，为广泛的AI应用提供非详尽的指南，包括科学中的AI应用。
### Innovation
该研究侧重于评估评价指标自身的稳健性和可靠性，总结了前期关于推荐系统公平性指标的研究成果，并提出了非详尽的指南来开发可靠的评价指标，以应用于广泛的AI应用，包括科学中的AI应用，填补了这一领域的空白。
### Conclusion
该研究通过对先前研究的总结，提供了一套非详尽的指南，来帮助开发和评估负责性AI的可靠评价指标，这些指南适用于广泛的人工智能应用领域，特别是科学中的AI应用。
## 664. `cs.LG` - PORTool：带有奖励树的工具使用LLM训练 [PDF](https://arxiv.org/pdf/2510.26020), [HTML](https://arxiv.org/abs/2510.26020)
### Authors
Feijie Wu,Weiwu Zhu,Yuxiang Zhang,Soumya Chatterjee,Jiarong Zhu,Fan Mo,Rodin Luo,Jing Gao
### Background
当前的工具使用大型语言模型（LLMs）在静态数据集上进行训练，能够与外部工具进行交互并执行多步、工具整合推理，从而生成工具呼叫轨迹。然而，这些模型模仿了一种通用的工具呼叫流程，未能探索可能的解决方案，在演变和动态的工具呼叫环境中表现有限。
### Innovation
本文提出了一种基于强化学习（RL）的方法——PORTool，以促使工具使用LLM探索导致正确答案的各种轨迹。该方法首先为给定查询生成多个卷积，并通过奖励机制评估每个步骤的表现，从而训练模型进行工具使用。
### Conclusion
通过17种工具应对用户查询，涵盖了即时和非即时主题，实验结果表明，提出的方法在最终准确性和工具呼叫步骤数量上实现了显著改进。并进行了消融研究，系统性地证明了步骤奖励的必要性和设计的鲁棒性，并将其与现有训练方法进行了比较。
## 665. `cs.LG` - 通过硬件遥测检测机器学习基础设施的异常 [PDF](https://arxiv.org/pdf/2510.26008), [HTML](https://arxiv.org/abs/2510.26008)
### Authors
Ziji Chen,Steven Chien,Peng Qian,Noa Zilberman
### Background
现代机器学习已经发展成为一种紧密结合、全栈式的生态系统，结合了硬件、软件、网络和应用程序。许多用户依赖云提供商以弹性、隔离且成本效益高的资源。然而，这些平台使用虚拟化技术，使运营商难以获得关于用户工作负载的洞察，妨碍了资源优化，而这是确保成本效益和最小化执行时间所必需的。
### Innovation
我们提出了一种名为System-X的系统，采取了一种以硬件为中心的方法，仅依赖可由运营商访问的硬件信号。通过分析超过30种流行的机器学习模型在各种硬件平台上的数据，开发了一个无监督学习管道，用于检测异常。该方法确保了对新兴工作负载和未知部署模式的适应性。
### Conclusion
通过System-X，成功地识别了网络和系统配置问题，加速了DeepSeek模型的执行速度，提高了5.97%。
## 666. `cs.LG` - 偏置校正数据合成在不平衡学习中的应用 [PDF](https://arxiv.org/pdf/2510.26046), [HTML](https://arxiv.org/abs/2510.26046)
### Authors
Pengfei Lyu,Zhengchi Ma,Linjun Zhang,Anru R. Zhang
### Background
不平衡数据使得分类问题难以平衡正负样本率，传统方法通过生成少数类的合成数据来解决此问题，但合成数据依赖于观察数据，无法准确复制原始数据分布，导致预测准确性降低。本文针对合成数据带来的偏置，提出了一种从多数类借用信息的校正方法，以改进预测准确性，避免过拟合，并将该方法扩展到更多不平衡数据场景，如不平衡多任务学习和因果推断。理论分析和模拟结果验证了该方法的有效性。
### Innovation
提出了一种从多数类借用信息的偏置校正方法，以纠正合成数据带来的偏置，提高预测准确性，避免过拟合，方法还扩展应用于不平衡多任务学习和因果推断场景。
### Conclusion
本文提供了一种理论框架和估计偏差误差的上限，并通过模拟和真实数据的手写字数字集分析验证了方法的有效性，增强了在不平衡数据集上的预测准确性，且避免了模型的过拟合问题。
## 667. `cs.LG` - 采用强化学习方法加速F1TENTH比赛中的现实世界超车 [PDF](https://arxiv.org/pdf/2510.26040), [HTML](https://arxiv.org/abs/2510.26040)
### Authors
Emily Steiner,Daniel van der Spuy,Futian Zhou,Afereti Pama,Minas Liarokapis,Henry Williams
### Background
尽管在时间试跑场景下自主赛车性能取得了显著进展，但在轮对轮的自主赛车和超车方面仍存在严重限制。特别是在真实场景中，最先进的算法难以安全或可靠地完成超车动作。这对于所有车辆之间的可靠导航至关重要，以确保自主轮对轮赛车的安全性。F1Tenth比赛提供了一个有用的平台，可以开发标准物理平台上的轮对轮赛车算法。该比赛格式有助于评估超车和轮对轮赛车算法与现有技术的差距。
### Innovation
本文提出了一种新型赛车和超车代理，能够在模拟和现实中学习可靠地导航赛道并超车对手。该代理安装在一个F1Tenth车辆上，并在现实生活中与运行不同竞争算法的对手进行比赛。结果表明，该代理通过对手训练实现了有目的的超车行为，超车率为87%，而仅针对比赛进行训练的代理的超车率为56%。这突显了代理在克服真实世界挑战方面的有效性
### Conclusion
研究表明，通过与对手的竞争进行训练，代理能够有效学习超车策略，并提高了实际比赛中的超车成功率。
## 668. `cs.LG` - Lean4Physics: Comprehensive Reasoning Framework for College-level Physics in Lean4 [PDF](https://arxiv.org/pdf/2510.26094), [HTML](https://arxiv.org/abs/2510.26094)
### Authors
Yuxin Li,Minghao Liu,Ruida Wang,Wenzhao Ji,Zhitao He,Rui Pan,Junming Huang,Tong Zhang,Yi R. Fung
### Background
本文旨在介绍一个面向大学物理学问题的综合推理框架Lean4PHYS，该框架基于Lean4。背景包括介绍LeanPhysBench，这是用Lean4编写的大学物理学证明基准，包含200个手工制作并经过同行评审的陈述，这些问题来源于大学教科书和物理竞赛。此外，为了确保物理学中的正式推理具有坚实的基础，还引入了PhysLib，这是一个包含物理推理所必需的基本单位系统和定理的社区驱动仓库。
### Innovation
Lean4PHYS提出了Lean4PHYS，这是一个基于Lean4的大学物理学综合推理框架。它包括LeanPhysBench，一个大学水平的基准，用于在Lean4中进行形式化物理推理，其中包含200个手工制作和同行评审的陈述，这些问题源于大学教科书和物理竞赛。此外，还引入了PhysLib，这是一个由社区驱动的仓库，包含进行形式化物理学推理所需的基本单位系统和定理。使用基准和基于Lean4进行的基准测试，报告了主要专家和最先进的闭源模型的基础结果，证明了PhysLib可以平均提高11.75%的模型性能，展示了LeanPhysBench的挑战性和PhysLib的有效性。
### Conclusion
研究表明，我们的Lean4PHYS能够显著提高物理学问题的处理性能。这是第一个在Lean4中提供物理学基准的研究。
## 669. `cs.LG` - 使用数据驱动投影生成高效解决异构二次规划问题 [PDF](https://arxiv.org/pdf/2510.26061), [HTML](https://arxiv.org/abs/2510.26061)
### Authors
Tomoharu Iwata,Futoshi Futami
### Background
本文提出了一种数据驱动框架，用于高效解决高维二次规划（QP）问题。该框架通过实例特定的投影减少变量数量，从而简化QP问题。设计了一种基于图神经网络的模型来生成针对每个QP实例量身定制的投影，以便即使对于未见过的问题也能生成高质量解。模型在异构的QP问题上进行训练，以最小化在投影解上的预期目标函数值。这个问题被形式化为一个双层优化问题；内部优化在给定投影下使用QP求解器解决QP，外部优化更新模型参数。该论文还提出了一种高效算法来求解这个双层优化问题，该算法计算参数梯度而不通过求解器反向传播。
### Innovation
提出了一种基于图神经网络的实例特定投影生成模型，用于高维QP问题的处理；将双层优化问题应用于模型训练，实现高效的QP问题求解；开发了一种不通过求解器反向传播梯度的高效算法，来解决双层优化问题；理论分析了通过神经网络生成的投影矩阵解决QP问题的泛化能力；实验结果显示，与现有方法相比，该方法能产生高质量可行解并减少计算时间，具有明显优势。
### Conclusion
该论文提出了一种新颖的数据驱动框架，提高了异构QP问题的解决效率。通过实例特定的投影生成和双层优化算法，不仅简化了问题求解过程，还提高了计算效率，更为重要的是，该方法具有良好的泛化能力，能够处理未见过的新问题。实验结果表明，该方法在多种场景下表现优异，未来可以进一步应用于更广泛的优化问题解决中。
## 670. `cs.LG` - ALMGuard: 安全捷径及其作为音频-语言模型防护措施的寻找方法 [PDF](https://arxiv.org/pdf/2510.26096), [HTML](https://arxiv.org/abs/2510.26096)
### Authors
Weifei Jin,Yuxin Cao,Junjie Su,Minhui Xue,Jie Hao,Ke Xu,Jin Song Dong,Derui Wang
### Background
近年来，音频-语言模型（ALMs）在多模态理解能力方面取得了显著进展。然而，引入音频模态也带来了新的独特脆弱性。之前的研究提出了专门针对ALMs的脱戒攻击，表明从传统音频对抗性攻击或基于文本的大语言模型（LLM）脱戒防护直接转移是无效的。为了应对这一问题，我们提出了ALMGuard，这是第一个针对ALMs的防护框架。假设ALMs中自然存在安全对齐的捷径，我们设计了一种方法来识别普遍的捷径激活扰动（SAPs），以在推理时保护ALMs。为更好地筛选出有效的触发器并保持模型在良性任务上的实用性，我们进一步提出了梅尔梯度稀疏掩码（M-GSM），该方法限制扰动仅作用于对脱戒敏感但对语音理解不敏感的梅尔频率区间。理论分析和实验证明，该方法对已见和未见攻击都表现出良好的鲁棒性。总体而言，ALMGuard将四个模型上最先进的ALM特定脱戒攻击成功率降低到4.6%，同时保持了在良性基准上的可比实用性，确立了新的最佳实践水平。我们的代码和数据可从 [这里] 获取。
### Innovation
我们提出了ALMGuard，这是第一个针对ALMs的防护框架。基于ALMs中存在自然的安全对齐捷径的假设，我们设计了一种方法来识别能够触发安全捷径的扰动（SAPs），以保护ALMs。进一步提出了梅尔梯度稀疏掩码（M-GSM）来选择对脱戒敏感但对语音理解和模型实用性影响较小的音频频率区间。
### Conclusion
ALMGuard在四个模型上将高级ALM特定脱戒攻击成功率降低到4.6%，同时保持了在良性基准上的可比实用性，确立了新的最佳实践水平。
## 671. `cs.LG` - 多输出鲁棒共轭高斯过程 [PDF](https://arxiv.org/pdf/2510.26401), [HTML](https://arxiv.org/abs/2510.26401)
### Authors
Joshua Rooijakkers,Leiv Rønneberg,François-Xavier Briol,Jeremias Knoblauch,Matias Altamirano
### Background
多输出高斯过程（MOGP）回归能够模拟多个相关响应变量之间的依赖关系。尽管MOGP与标准高斯过程类似，但在模型误设和异常值的影响下，它们会扭曲个别输出中的预测。由于输出间的相关性，多个异常响应变量的误差会进一步加剧这种影响。为了应对这种情况，作者扩展和推广了Altamirano等人（2024年）引入的鲁棒和共轭高斯过程（RCGP）框架。
### Innovation
提出了一个名为空间输出鲁棒共轭高斯过程（MO-RCGP）的新方法，这种方法是可共轭的，能够联合捕捉输出间的相关性，从而提供一种证明鲁棒性的多输出高斯过程。
### Conclusion
通过在金融和癌症研究中的应用全面评估了这种方法的有效性。
## 672. `cs.LG` - Autograder+: 多维度AI框架在编程教育中的丰富教学反馈 [PDF](https://arxiv.org/pdf/2510.26402), [HTML](https://arxiv.org/abs/2510.26402)
### Authors
Vikrant Sahu,Gagan Raj Gupta,Raghav Borikar,Nitin Mane
### Background
编程教育的迅速增长超越了传统评估工具，这使得教师难以提供有意义且可扩展的学生反馈。传统的自动化评分系统虽然有效，但作为黑箱系统，只能给出通过或未通过的结果，对学生的思考过程和学习需求提供很少的洞察。
### Innovation
Autograder+旨在将评分从纯粹的总结性过程转变为形成性的学习体验。其创新之处在于引入了两个关键能力：使用微调的大语言模型自动生成反馈，以及通过学生代码提交的可视化来揭示学习模式。该模型通过使用精选的学生代码和专家反馈进行微调，确保提供与教学目标对齐、具有上下文感知的指导。
### Conclusion
通过集成AI驱动的反馈、基于语义的聚类和交互式可视化，Autograder+在支持个性化教学和改善学习结果方面减轻了教师的工作负担。
## 673. `cs.LG` - CORE-KG内部探究：结构化提示和趋同解析在知识图谱评估中的应用 [PDF](https://arxiv.org/pdf/2510.26512), [HTML](https://arxiv.org/abs/2510.26512)
### Authors
Dipak Meher,Carlotta Domeniconi
### Background
人口走私网络越来越具有适应性和分析难度。法律案件文件提供了关键见解，但往往是非结构化的、词汇密集的，并充满了模糊或变化的引用，这对自动知识图谱(KG)构建构成了重大挑战。尽管基于LLM的方法在静态模板上取得了一定改进，但它们仍然生成噪声大、碎片化的图形，由于缺乏引导式提取和同指消解，导致节点重复。
### Innovation
提出了CORE-KG框架，通过整合类型意识下的同指模块和领域导向结构化提示，显著减少了节点重复和法律噪声。这项研究通过系统性的去除关键组件进行消融研究，显示了同指解析和结构化提示在知识图谱构建中的各自贡献。
### Conclusion
研究结果表明，移除同指解析会导致节点重复28.32%的增加和噪声节点4.32%的增加，而移除结构化提示会导致节点重复4.34%的增加和噪声节点73.33%的增加。这些发现为设计从复杂法律文本中提取结构化表示的稳健LLM管道提供了实证见解。
## 674. `cs.LG` - MisSynth: 使用合成数据提高MISSCI推理谬误分类 [PDF](https://arxiv.org/pdf/2510.26345), [HTML](https://arxiv.org/abs/2510.26345)
### Authors
Mykhailo Poliakov,Nadiya Shvai
### Background
健康相关的错误信息非常普遍且可能有害，尤其是当这些声明扭曲或曲解了科学研究成果时，使其难以识别。为了应对这一挑战，本文研究了合成数据生成和轻量级微调技术对大型语言模型(LLMs)识别谬误论证能力的影响。
### Innovation
本文提出了MisSynth管道，应用检索增强生成（RAG）技术生成合成谬误样本，然后用于微调大型语言模型。实验结果表明，微调模型相比仅使用基本模型具有显著的准确率提升。例如，微调的LaMa 3.1 8B模型在MISSCI测试集上的F1分数绝对提升了超过35%。研究表明，将合成谬误数据引入以增强有限标注资源可以显著提升零样本LLM分类性能，即使计算资源有限也适用。此外，代码和合成的数据集已经在网站上公开。
### Conclusion
引入合成谬误数据可以显著增强零样本LLM分类真实世界科学错误信息任务的性能，即使计算资源有限也适用。
## 675. `cs.LG` - LINK-KG: 法律驱动的核心参考解析知识图谱用于人口走私网络 [PDF](https://arxiv.org/pdf/2510.26486), [HTML](https://arxiv.org/abs/2510.26486)
### Authors
Dipak Meher,Carlotta Domeniconi,Guadalupe Correa-Cabrera
### Background
人口走私网络复杂且不断演变，难以进行全面的分析。合法诉讼文件提供了这些网络丰富的事实和程序性见解，但文件通常较长、结构不规则且包含模糊或变化的引用，这为自动知识图谱（KG）构建带来了重大挑战。现有方法要么忽略同指消解，要么无法处理长文本段落，从而导致碎片化的图谱和不一致的实体链接。
### Innovation
我们提出了LINK-KG，一种模块化框架，整合了三阶段、LLM引导的核心参考消解流水线以及下游KG提取。该方法的核心是一个类型特定的提示缓存，它在文档片段之间一致地跟踪和解决引用，从而生成清晰且消歧义的叙述，用于从短和长法律文本构建结构化的知识图谱。与基准方法相比，LINK-KG将平均节点重复减少了45.21%，噪音节点减少了32.22%，从而构建了更干净、更有条理的图谱结构。这些改进使LINK-KG成为分析复杂犯罪网络的强大基础。
### Conclusion
LINK-KG展示了在构建知识图谱时改进同指消解和实体链接的方法，从而解决了长文档数据处理中的关键挑战，体现了在复杂犯罪网络分析中的应用潜力。
## 676. `cs.LG` - 代表级反事实校准用于无偏的零样本识别 [PDF](https://arxiv.org/pdf/2510.26466), [HTML](https://arxiv.org/abs/2510.26466)
### Authors
Pei Peng,MingKun Xie,Hang Hao,Tong Jin,ShengJun Huang
### Background
在视觉-语言模型中，对象-上下文捷径仍然是一个持续存在的挑战，这在测试场景与训练阶段的常见共现情况不同时，会损害零样本的可靠性。这个问题被重新定义为因果推理问题，即在不同的环境中，同一个对象的预测是否依然成立？
### Innovation
研究通过估计CLIP表示空间中的对象和背景期望，在外部数据集、批次邻居或文本描述中采样多样性的替代上下文，重新组合对象特征来合成反事实嵌入，进而通过估计总直接效应和模拟干预，减去仅背景激活，从而保持有益的对象-背景交互，同时减轻幻觉分数。这种方法无需重新训练或设计提示，显著提高了上下文敏感基准上的最坏情况和平均准确性，建立了新的零样本状态艺术水平。此外，该框架提供了轻量级的表示级反事实方法，为去偏见且可靠的多模态推理提供了实际因果途径
### Conclusion
我们的方法在无需重新训练或设计提示的情况下，显著改进了上下文敏感基准上的最坏情况和平均准确率，建立了零样本识别的新状态艺术水平。我们的框架提供了一种轻量级的表示级反事实方法，为去偏见且可靠的多模态推理提供了实际因果途径。
## 677. `cs.LG` - 基于Large Language Model的向量化上下文感知嵌入的GAT协同过滤 [PDF](https://arxiv.org/pdf/2510.26461), [HTML](https://arxiv.org/abs/2510.26461)
### Authors
Danial Ebrat,Sepideh Ahmadian,Luis Rueda
### Background
推荐系统在处理稀疏数据和冷启动场景方面面临挑战，这限制了它们为新用户或不活跃用户提供准确建议的能力。
### Innovation
本文提出了一种增强型Graph Attention Network（GAT）基于协同过滤（CF）框架，该框架结合了Large Language Model（LLM）驱动的上下文感知嵌入。具体来说，生成简洁的用户文本简介并统一电影元数据（标题、类型、概述），将这些信息作为初始节点特征注入双分图用户-项目图中。此外，引入了一种混合损失函数，结合了贝叶斯个性化排序（BPR）和余弦相似性项以及鲁棒的负采样技术，确保明确的负面反馈被区分出来，并与未观察数据区分开。
### Conclusion
实验表明，本方法在Precision、NDCG和MAP指标上优于最先进的基线，特别是在具有有限交互历史的用户上表现出高度稳健性。消融研究证实了LLM增强嵌入和余弦相似性项的角色，有助于捕捉语义关系。通过将LLM提取的上下文理解融入基于图的架构中，我们的方法有效地缓解了数据稀疏性与冷启动的限制。未来的研究方向包括在保持推荐准确性的同时平衡覆盖率和多样性，并引入公平性约束和可解释性功能以进一步增强系统性能。
## 678. `cs.LG` - Scales++：嵌入认知标度表示的计算高效评估子集选择 [PDF](https://arxiv.org/pdf/2510.26384), [HTML](https://arxiv.org/abs/2510.26384)
### Authors
Andrew M. Bean,Nabeel Seedat,Shengzhuang Chen,Jonathan Richard Schwarz
### Background
大规模语言模型（LLMs）在综合基准上的评估成本很高，因此需要创建小型但具有代表性的数据子集（即迷你基准）。现有方法基于模型性能选择基准测试项，但这些方法存在大规模的前期成本、无法即时处理新的基准测试（冷启动）问题，以及未来模型会共享前辈失败模式的脆弱假设。本文挑战了这一范式，提出了一种基于项的基准子集选择方法，认为选择应基于任务项本身的固有属性，而不是特定模型的失败模式。通过Scales++这一新颖方法实现这一基于项的高效基准测试方式，其数据选择基于基准样例的认知需求。经验结果显示，Scales++将前期选择成本降低了超过18倍，同时保持了竞争性的预测精度。在Open LLM排行榜上，使用仅0.5%的数据子集，预测完整基准得分的平均绝对误差为2.9%。这表明基于项的方法在不显著降低精度的同时，增强了冷启动性能，提供了更具解释性的基准测试。
### Innovation
提出了基于项的基准子集选择方法（item-centric approach），打破了现有基于模型（model-centric paradigm）的方法的局限性。通过Scales++方法，数据选择基于基准样例的认知需求，而非特定模型的失败模式。实验表明，这种方法在大幅降低前期选择成本的同时，实现了可媲美现有方法的预测精度。
### Conclusion
基于项的基准子集选择方法不仅能实现高效的模型评估，无显著精度损失，还能提供更好的冷启动性能和更具解释性的基准测试。Scales++方法通过嵌入认知标度表示来实现这一目标。
## 679. `cs.LG` - 通过头尾再平衡在LVLMs自我提升中对抗马太效应 [PDF](https://arxiv.org/pdf/2510.26474), [HTML](https://arxiv.org/abs/2510.26474)
### Authors
Xin Guo,Zhiheng Xi,Yiwen Ding,Yitao Zhai,Xiaowei Shi,Xunliang Cai,Tao Gui,Qi Zhang,Xuanjing Huang
### Background
自提升已成为提升大型视觉-语言模型（LVLMs）推理能力的主流范式。在这个过程中，模型通过迭代探索并学习成功的轨迹。然而，我们发现了一个关键问题：模型在处理简单查询（即头部数据）时表现出色，但在处理更复杂的查询（即尾部数据）时表现不佳，这种不平衡导致优化过程中模型更侧重于简单的推理技能，而忽视了更复杂的推理任务。这种不平衡随着时间的推移逐渐加剧，我们称之为“马太效应”，最终阻碍了模型进一步改进，并导致性能瓶颈。
### Innovation
提出了四种有效的策略来缓解这一挑战：分别从分布重塑和轨迹重采样的角度出发，在探索和学习的自提升过程中实现头部和尾部的再平衡。通过在Qwen2-VL-7B-Instruct和InternVL2.5-4B模型上进行全面的视觉推理任务实验，表明该方法可以提高视觉推理能力，并且在平均表现上比传统的自提升方法高出3.86个点。
### Conclusion
我们的方法能够有效地缓解马太效应导致的性能瓶颈，并为LVLMs的进一步优化提供了新的路径。
## 680. `cs.LG` - SABER: 基于符号回归的到达角和波束模式估计器 [PDF](https://arxiv.org/pdf/2510.26340), [HTML](https://arxiv.org/abs/2510.26340)
### Authors
Shih-Kai Chou,Mengran Zhao,Cheng-Nan Hu,Kuang-Chung Chou,Carolina Fortuna,Jernej Hribar
### Background
精确的到达角(AoA)估计对于下一代无线通信系统至关重要，以实现可靠的波束成形、高精度定位和集成传感。遗憾的是，传统的高分辨率技术需要多元件阵列和大量的快照收集，而通用的机器学习(ML)方法往往产生黑盒模型，缺乏物理可解释性。本文提出了一种基于符号回归(SR)的机器学习框架，即符号回归基于到达角和波束模式估计器(SABER)，这是一种受约束的符号回归框架，可以从路径损耗测量中自动发现具有可解释性的波束模式和到达角的闭式形式模型。SABER在封闭自由空间无回声室中进行了验证，直接反转已知的$text{cos}^n$波束和低阶多项式近似都实现了小于0.5度的平均绝对误差。无约束符号回归方法进一步降低了预测角度的误差，但产生了缺乏物理洞察的复杂公式。然后在基于可重构智能表面(RIS)的室内实际测试环境中实现了SR学习逆运算，SABER和无约束SR模型准确恢复了真实的到达角，几乎没有误差。最后，SABER与Cramér-Rao 下限(CRLBs)进行了基准测试，结果表明，SABER是一种与最先进的和黑盒ML方法相比具有可解释性和准确性的AoA估计的替代方法
### Innovation
本文提出了一种基于符号回归(SR)的机器学习框架SABER，这是一种受约束的符号回归框架，可以从路径损耗测量中自动发现具有可解释性的波束模式和到达角的闭式形式模型。SABER能够实现高精度的估计，同时弥补了不可解释的ML方法与基于物理的可解释性估计器之间的差距。在实际测试环境中，SABER和无约束的SR模型准确地恢复了真实的到达角，几乎没有误差，同时仍然具有可解释性
### Conclusion
本文提出的SABER是一种可解释且准确的替代方法，用于对抗最先进的和黑盒ML方法，特别是在到达角估计方面。
## 681. `cs.LG` - 大型语言模型中关系解码线性算子的结构 [PDF](https://arxiv.org/pdf/2510.26543), [HTML](https://arxiv.org/abs/2510.26543)
### Authors
Miranda Anna Christ,Adrián Csiszárik,Gergely Becsó,Dániel Varga
### Background
这篇论文研究了在Hernandez等人[2023]中引入的线性算子结构，这些算子用于解码变压器语言模型中的特定关系事实。该研究将Hernandez等人的单一关系研究扩展到多个关系，并系统地描述了这些算子的组织结构。研究发现，这种多关系的线性解码器可以通过简单的3阶张量网络进行高度压缩，几乎不会损失解码准确性。通过对解码算子应用到每种关系的主题上进行交叉评估，研究发现这些线性映射实际上并没有编码独特的单个关系，而是提取了共通的粗粒度语义属性（例如，首都的国家属性和食物的国家属性都属于X的国家属性）
### Innovation
本研究的创新在于将多个关系的线性解码器通过简单的3阶张量网络进行压缩，并通过一种交叉评估协议来解释这种意想不到的冗余现象。研究发现这些线性的线性算子实际上是基于属性而非单个关系来编码的，这解释了它们为何只能泛化到语义上相近的新关系中
### Conclusion
这项研究将变压器语言模型中的线性关系解码过程解释为主要是基于属性而非特定关系的。这种属性中心的结构说明了算子的可压缩性，并指出了它们只能泛化到具有类似语义的新关系中的原因
## 682. `cs.LG` - 价值漂移：追踪大型语言模型后训练期间的价值对齐 [PDF](https://arxiv.org/pdf/2510.26707), [HTML](https://arxiv.org/abs/2510.26707)
### Authors
Mehar Bhatia,Shravan Nayak,Gaurav Kamath,Marius Mosbach,Karolina Stańczak,Vered Shwartz,Siva Reddy
### Background
随着大语言模型（LLMs）在社会中的作用日益重要，它们遇到的问题越来越需要不仅依靠通用知识，还要与特定的人类价值体系对齐。因此，研究LLMs与人类价值的对齐已经成为一个重要领域。然而，现有的研究大多集中在评估完全训练好的模型的对齐程度，忽略了模型在训练过程中如何学习表达人类价值观的过程。
### Innovation
本研究探讨了在模型后训练过程中价值对齐是如何发生以及在哪个阶段出现的。研究通过分析后训练算法和数据集的影响，测量了价值漂移的大小和时间。研究发现，微调（SFT）阶段通常确立了模型的价值观念，而后续的偏好优化很少重新调整这些价值观。通过使用合成的偏好数据集，研究进一步发现，不同的偏好优化算法即使在偏好数据相同的情况下，也会导致不同的价值对齐结果。
### Conclusion
研究结果为理解如何在后训练过程中学习价值提供了行动性的见解，并有助于指导数据标准化，以及选择用于偏好优化的模型和算法，以提高模型与人类价值观的对齐程度。
## 683. `cs.LG` - OmniX：从统一全景生成和感知到图形级3D场景 [PDF](https://arxiv.org/pdf/2510.26800), [HTML](https://arxiv.org/abs/2510.26800)
### Authors
Yukun Huang,Jiwen Yu,Yanning Zhou,Jianan Wang,Xintao Wang,Pengfei Wan,Xihui Liu
### Background
目前，构建3D场景的方法主要有两种：程序生成和2D提升。其中，基于全景的2D提升因其能利用强大的2D生成先验知识生成沉浸式、真实和多样性的3D环境而备受关注。但是，现有2D提升方法往往集中在外观生成上，忽视了对内在属性的感知。
### Innovation
本文提出了一种名为OmniX的多功能统一框架，该框架利用一种轻量级且高效的跨模态适配器结构，重新利用2D生成先验知识来完成全景感知、生成和完成等广泛的任务。OmniX还构建了一个大规模合成全景数据集，包含来自不同室内和室外场景的高质量多模态全景图。
### Conclusion
大量的实验结果显示，OmniX在全景视觉感知和图形级3D场景生成方面非常有效，为沉浸式和物理真实性的虚拟世界生成提供了新的可能性。
## 684. `cs.LG` - SteerVLM：通过轻量级激活引导实现视觉语言模型的鲁棒模型控制 [PDF](https://arxiv.org/pdf/2510.26769), [HTML](https://arxiv.org/abs/2510.26769)
### Authors
Anushka Sivakumar,Andrew Zhang,Zaber Hakim,Chris Thomas
### Background
现有视觉-语言模型（VLMs）在指导输出方面的能力有限，尤其是在确保输出与用户意图紧密相关时。为了改进这一问题，研究人员开发了多种干预技术来调整模型输出，但这些技术往往复杂且需要对模型进行大量修改，增加了实现和解释的难度。因此，提出一种既能精细控制输出又能保持模型性能的方法是必要的。
### Innovation
提出了SteerVLM，一种轻量级的引导模块，通过学习目标和反向行为的潜在嵌入来动态调整语言模态与图像上下文之间的激活连接，从而实现复杂输出语义的细粒度、推理时控制。该模块的尺寸仅为原VLM的0.14%，并且在不需要提前提取静态向量或手动调整干预点的情况下，能够通过层维度激活调制和自适应引导来实现跨层模型控制。
### Conclusion
SteerVLM方法在引导和幻觉缓解基准测试中表现出色，提出了一种通过激活工程实现多模态模型控制的稳健解决方案。同时，还引入了专门用于视觉叙述意图对齐的多模态数据集（VNIA），以促进VLM引导技术的开发和评估。
## 685. `cs.LG` - 扩展图像地理定位至大陆级别 [PDF](https://arxiv.org/pdf/2510.26795), [HTML](https://arxiv.org/abs/2510.26795)
### Authors
Philipp Lindenberger,Paul-Edouard Sarlin,Jan Hosang,Matteo Balice,Marc Pollefeys,Simon Lynen,Eduard Trulls
### Background
全球范围内确定图像的精确地理位置仍然是一个未解决的挑战。标准的图像检索技术由于图像数量庞大（超过10000万张）而效率低下，并且在覆盖不足时会失效。尽管已有可扩展的解决方案，但这些方案通常需要权衡：全球分类通常导致粗略的结果（10公里以上），而地面和航空图像之间的跨视图检索存在领域差距，主要是在较小区域内研究。
### Innovation
本文提出了一种混合方法，可以在广大地理范围内（如整个大陆）实现精细的地理位置定位。在训练过程中利用代理分类任务来学习丰富的特征表示，并隐式编码精确的位置信息。将这些学习到的原型与航空图像的嵌入结合使用，以提高对地面数据稀疏性的鲁棒性。这种方法可以在多个国家跨越的区域内直接实现精细的检索。实验证明，我们的方法能够在覆盖欧洲大部分地区的数据集上使查询定位精度在200米内的比例超过68%。
### Conclusion
我们的广泛评估表明，我们的方法可以在覆盖欧洲大部地区的数据集上将查询位置精确到200米，比例超过68%。相关的代码已在以下网址开源：this https URL
## 686. `cs.LG` - 通过仔细选择U-Net架构和损失函数来超越RGB眼底图像中AMD区域估计的现有技术 [PDF](https://arxiv.org/pdf/2510.26778), [HTML](https://arxiv.org/abs/2510.26778)
### Authors
Valentyna Starodub,Mantas Lukoševičius
### Background
年龄相关性黄斑变性（AMD）是60岁以上人群视力不可逆受损的主要原因之一。本研究集中在RGB眼底图像中AMD病变的语义分割，这是一种非侵入性和成本效益高的成像技术。ADAM挑战赛的结果作为本研究评估的标准，该挑战赛是迄今为止最全面的RGB眼底图像中的AMD检测研究竞赛和公开数据集。
### Innovation
以U-Net结构为基础，研究人员评估并对比了几种改进分割模型架构和训练管道的方法，包括预处理技术、不同复杂度的编码器深度网络类型以及专门的损失函数以缓解类别不平衡情况。最终展示的AMD检测框架配置超越了先前的所有ADAM挑战赛提交记录，特别是在非侵入性RGB眼底图像中的多类别分割中。
### Conclusion
本研究最终的研究成果是AMD检测框架的最终配置，该配置在非侵入性RGB眼底图像中不同AMD病变类型的多类别分割上超越了所有之前的ADAM挑战赛提交记录。此外，研究中所用的实验代码已公开提供。
## 687. `cs.LG` - 大型语言模型对齐中的奖励坍塌现象 [PDF](https://arxiv.org/pdf/2305.17608), [HTML](https://arxiv.org/abs/2305.17608)
### Authors
Ziang Song,Tianle Cai,Jason D. Lee,Weijie J. Su
### Background
大型语言模型（LLMs），例如ChatGPT和GPT-4，通过与基于人类偏好训练的奖励模型对齐来展示其非凡的能力。有一种常用的排名为基础的方法，即通过对提示的响应进行排名来表征人类偏好。然而，这种方法在训练终端阶段出现了奖励坍塌现象，即对不同的提示，奖励分布变得完全相同，这导致了奖励的分配不能反映提示的开放性或特定性。这种现象对语言模型对齐的准确性产生了负面影响。
### Innovation
本文提出了理论分析，揭示了奖励坍塌现象的主要原因是排名为基础的目标函数无法在优化过程中整合提示相关信息。此外，还提出了一个提示感知的优化方案，该方案在插值范围内可以确保奖励分布依赖于提示，从而显著缓解了奖励坍塌问题。这一方法可以提高语言模型对齐的效果，使奖励分布更符合实际需求。
### Conclusion
研究表明，通过引入提示感知的优化方案，可以显著缓解训练奖励模型过程中出现的奖励坍塌现象，提高了大型语言模型对齐的准确性和多样性。
## 688. `cs.LG` - 统一因果推理理论：通过布里格曼-列斯回归实现直接去偏机器学习 [PDF](https://arxiv.org/pdf/2510.26783), [HTML](https://arxiv.org/abs/2510.26783)
### Authors
Masahiro Kato
### Background
该论文旨在建立一个统一的因果推理理论框架，该框架整合了Riesz回归、协变量平衡、密度比估计（DRE）、目标最大似然估计（TMLE）和匹配估计等方法在平均治疗效应（ATE）估计中的应用。背景在于现有方法需针对不同方面分别处理平衡权重和结果回归函数，这增加了理解和应用的复杂性。
### Innovation
论文提出了将这些方法统一到一个框架中，特别是通过布里格曼-列斯回归和两步最小二乘法（Bregman-Riesz回归），简化了因果推理和平均治疗效应（ATE）估计的过程。通过这种方式，论文创新地探讨了Riesz回归、协变量平衡、DRE、TMLE和匹配估计之间的联系，强调了它们在处理平衡权重和结果回归函数中的应用。
### Conclusion
本研究提出的方法不仅能够直接估计因果效应，还能够实现去偏机器学习，提高了估计的准确性。而其简化了以往复杂的因果推理过程，提供了理论上的统一和实践上的便利性。
## 689. `cs.LG` - 监督博弈：学习如何协同平衡AI代理的安全性和自主性 [PDF](https://arxiv.org/pdf/2510.26752), [HTML](https://arxiv.org/abs/2510.26752)
### Authors
William Overman,Mohsen Bayati
### Background
随着越来越能干的代理系统被部署，一个核心的安全问题是保留有意义的人类控制，而不修改基础系统。本文探讨了一个最少的控制接口，其中代理可以选择自行行动（播放）或推迟（请求），同时人类可以同时决定是否允许（信任）或介入监督（监督）。如果代理推迟，人类的选择将决定结果，可能导致纠正措施或系统关闭。该交互被建模为一个两人马尔可夫博弈。
### Innovation
本文将这一交互建模为一个马尔可夫潜力博弈（MPG），并研究了在人类价值函数具有特定结构假设下的契合保证。如果人类-代理游戏的奖励结构符合这些条件，那么代理自身的效益改善不会损害人类的利益。此外，该研究分析了这一MPG框架的扩展。这一视角在理论上提供了特定形式的内生契合条件，并提出了一个透明控制层，其中代理在安全时行动，在高风险时推迟，同时保留其预训练策略和环境的奖励结构不变。通过网格世界的仿真，证明了通过独立学习，代理和人类可以在训练后发现其最佳监督角色，从而实现一种自组织合作消除训练后引入的安全违规。
### Conclusion
本文的研究展示了在部署后使不一致模型更安全的实际方法。通过独立学习，代理和人类发现了其最佳监督角色，即代理在不确定时请求，人类在需要时监督，从而避免了训练后引入的安全违规。
## 690. `cs.LG` - HEIR: 学习基于图形的运动层次结构 [PDF](https://arxiv.org/pdf/2510.26786), [HTML](https://arxiv.org/abs/2510.26786)
### Authors
Cheng Zheng,William Koch,Baiang Li,Felix Heide
### Background
在计算机视觉、图形和机器人学等多个领域中，运动的层级结构普遍存在，复杂的动态通常是由简单的运动组件之间的协调交互产生的。现有的方法通常需要依靠手工定义或启发式的层级结构，并且使用固定的运动基元，这些方法的应用范围受到限制，难以适应不同的任务。因此，有必要探讨一种直接从数据中学习结构化和可解释的运动关系的方法，用于建模这些复杂的动态特性。
### Innovation
本文提出了一种新的方法，名为HEIR（Hierarchical Estimation and Inference for Representation），该方法通过图神经网络学习可解释的层级运动结构，从而自动生成全球绝对运动的父级继承模式和局部运动残差。HEIR将运动表示为图基元，并通过有向边来捕捉所学的父级-子级依赖性。这种表示法在不同类型的运动数据（1D平移、2D旋转及动态3D场景变形）上进行了验证，表现出了比基线方法更好的表现和可解释性。HEIR为运动中心驱动任务提供了一种灵活的数据驱动的层级建模范式。
### Conclusion
通过提供一种适应性强且数据驱动的运动层级建模框架，Heir方法能够重建不同简单运动的内在运动层次在1D和2D的情况，并在动态3D场景变形中生成更真实和可解释的变形。这种方法应用于广泛的基于运动的任务具有广泛适用性。
## 691. `cs.LG` - 在政策学习中，通过实证福利最大化与条件平均治疗效应估计的关联弭平差距 [PDF](https://arxiv.org/pdf/2510.26723), [HTML](https://arxiv.org/abs/2510.26723)
### Authors
Masahiro Kato
### Background
政策学习的目标是训练一个策略函数，该函数可以根据协变量推荐治疗措施，以最大化总体福利。有两种主要的策略学习方法：经验福利最大化（EWM）方法和插值方法。EWM方法类似于分类问题，首先构建一个总体福利的估计器，然后通过最大化估计的福利来训练策略。相比之下，插值方法基于回归，首先估计条件平均治疗效应（CATE），然后推荐具有最高估计结果的治疗。本文通过证明两者本质上基于相同的优化问题来弥平两种方法之间的差距。特别地，我们证明了EWM和重新参数化策略类上的最小二乘之间的等价性。这一发现意味着两种方法在多个方面是可交换的，并且在相同条件下共享相同的理论保证。利用这一等价性，我们提出了一种新的策略学习正则化方法，该方法提供了一个凸优化和计算高效的训练过程，避免了通常在EWM中所需的NP难组合步骤。
### Innovation
提出了经验福利最大化（EWM）和基于条件平均治疗效应（CATE）估计之间等价性的理论证明。基于这一等价性，提出了一种新的策略学习正则化方法，该方法提供了一个凸优化和计算高效的训练过程。
### Conclusion
提出的等价性表明，EWM和基于CATE的方法在优化策略方面是等价的，并且可以通过新的正则化方法实现高效的策略学习。
## 692. `cs.LG` - 捍卫事后解释 [PDF](https://arxiv.org/pdf/2412.17883), [HTML](https://arxiv.org/abs/2412.17883)
### Authors
Nick Oh
### Background
本文背景在于解释机器学习模型的行为是一个日益重要的议题，但事后解释方法（post-hoc explainability methods）常受到质疑，被认为其可靠性和知识基础存在缺陷。
### Innovation
本文创新点在于提出了一种基于中介理解和有界限的现象性知识的哲学框架，认为在理解模型行为的过程中，不需要完全的透明度。只要解释承认其近似性并且经过严格的实证验证，科学洞察仍能产生。
### Conclusion
通过对近期生物医学领域机器学习应用的分析，本文展示了当事后解释方法被恰当地纳入科学实践时，可以产生新的假设并增进对现象的理解。
## 693. `cs.LG` -  punctured 修正.convolutional 和 Turbo 修正码的解码：协议符合性的深度学习解决方案 [PDF](https://arxiv.org/pdf/2502.15475), [HTML](https://arxiv.org/abs/2502.15475)
### Authors
Yongli Yan,Linglong Dai
### Background
神经网络基于的解码方法在增强错误修正性能方面具有潜力，但面临刺孔码的挑战。现有方法难以适应变化的码率或满足协议兼容需求。
### Innovation
提出了基于长短期记忆（LSTM）的统一神经解码器，用于刺孔卷积码和Turbo码，引入了刺孔感知嵌入，可以直接将刺孔模式融入神经网络，实现码率的无缝适应。同时设计了均衡的比特错误率训练策略，确保解码器在各种码长、码率和信道中的鲁棒性。
### Conclusion
在高斯白噪声（AWGN）和瑞利衰落信道的大量仿真中，提出的神经解码器在解码准确性和鲁棒性方面优于传统解码技术，实现了协议兼容性要求。
## 694. `cs.LG` - 语言模型可以在更好的搜索状态值估计中自我提升 [PDF](https://arxiv.org/pdf/2503.02878), [HTML](https://arxiv.org/abs/2503.02878)
### Authors
Ethan Mendes,Alan Ritter
### Background
在多步推理任务中，收集地真相奖或人类演示通常非常昂贵，尤其是在像网络任务等交互式领域。现有的方法往往需要大量的标注数据和人工指导，成本高昂。
### Innovation
论文介绍了自我 Teach 提前学习（Self-Taught Lookahead, STL），这是一种奖励免费框架，通过明确地对状态转换进行推理来改进基于语言模型的价值函数。STL 类似于价值迭代算法中的链式思考：而不是直接回溯数值，一个语言模型被训练模拟一次提前查看，预测下一个动作、最终状态和价值的合理解释，从而在没有标签数据的情况下改进价值估计。这种自监督过程可以提供更准确的状态值预测，进而使得轻量级的搜索算法能够扩展更少的状态，同时保持出色的性能。
### Conclusion
STL 训练的价值模型在中等规模（8B参数）的开源语言模型上提升了网络代理的成功率高达39%，并达到与专有模型相当的性能。STL 还可以推广到多跳问答和数学谜题中，发现 STL 允许小的开源模型指导高效的搜索，通过整合价值学习和显式推理来降低推理成本。
## 695. `cs.LG` - 通过压缩感知在图上推进局部聚类：半监督和无监督方法 [PDF](https://arxiv.org/pdf/2504.19419), [HTML](https://arxiv.org/abs/2504.19419)
### Authors
Zhaiming Shen,Sung Ha Kang
### Background
局部聚类旨在在一个大型图中识别特定的子结构，而无需图的额外结构信息。这些子结构通常相对于整个图来说较小，因此可以通过找到与图拉普拉斯算子相关的线性系统的稀疏解来解决这个问题。本文研究了在极少量已标记数据情况下识别特定局部聚类的方法，并将其扩展到无监督设置下。文章通过随机采样图、局部聚类提取以及结果的重叠分析来进行聚类，建立了节点对的共同成员条件，并严格证明了所提方法的正确性。此外，进行了广泛的实验以证明所提方法在低标签率的情况下达到了最先进的性能。
### Innovation
文章提出了半监督局部聚类方法，既适用于极少量标签数据情况，又适用于无标签数据情况。方法包括随机采样图、局部聚类提取以及结果重叠分析，同时证明了方法的有效性和正确性。通过压缩感知技术推进了局部聚类的算法，并且在低标签率环境中表现良好，达到了最先进的性能。
### Conclusion
本文通过证明共同成员条件和严格的正确性证明，提出了半监督和无监督的局部聚类方法。方法在实验中展示了优秀的性能，特别在低标签率环境下表现出色，并且达到了当前最先进的水平。
## 696. `cs.LG` - 可学习且可扩展的指令微调数据影响估计的神经网络 [PDF](https://arxiv.org/pdf/2502.09969), [HTML](https://arxiv.org/abs/2502.09969)
### Authors
Ishika Agarwal,Dilek Hakkani-Tür
### Background
影响函数在模型训练中提供了关键洞察，但现有方法存在计算成本高和泛化能力有限的问题。特别是，在使用语言模型计算数据影响时，最近的方法不适用于大型模型和数据集，这是因为计算所需的昂贵的前向和反向传递，存储大型模型所需的大量内存，以及对新数据的影响估计泛化能力较差的问题。
### Innovation
本文介绍了一种称为InfluenceNetwork的小型神经网络，用于估计影响值，实现了高达99%的成本减少。在模型仅为完整语言模型的0.0027%大小的情况下，可以估计影响值。本文还提出了一种称为NN-CIFT（高效的指令微调神经网络）的算法，用于下游任务中的子集选择，用于通用指令微调，并展示了在大幅加速后，性能相同的结果。此外，对该算法的超参数进行了深入分析。
### Conclusion
作者通过实验表明，与原始影响函数相比，尽管加速了大量数据，但NN-CIFT的性能没有退步。这种方法允许以较小的计算开销和存储空间来估计影响值，增强了模型训练过程中的理解和优化能力。
## 697. `cs.LG` - 基于有界不确定性模型的强化学习智能探索 [PDF](https://arxiv.org/pdf/2504.05978), [HTML](https://arxiv.org/abs/2504.05978)
### Authors
J.S. van Hulst,W.P.M.H. Heemels,D.J. Antunes
### Background
强化学习是一种用于不确定环境中的决策制定的强大框架，但它通常需要大量数据来学习最优策略。本文通过引入具有先验模型知识的探索策略来应对这一挑战，加速学习过程。背景中假设可以访问包含真实转换核和奖励函数的模型集，并通过优化模型集来获得Q函数的上下界，从而指导代理的探索。此外，还提出了一种基于数据的正则化版本的模型集优化问题，确保探索策略向最优策略收敛。当模型集具备特定结构时，即有界参数MDP（BMDP）框架，正则化模型集优化问题成为凸问题且易于实现，本文还证明在较温和的假设下，在这种设置下可以实现有限时间内向最优策略收敛。最后一部分通过模拟实验展示了该探索策略（Bounded Uncertainty Model-based Exploration，简称BUMEX）的有效性，表明该方法可以显著加速基准案例中的学习过程。提供了一个工具箱供访问使用。
### Innovation
本文提出了一种基于有界不确定性模型的探索策略（BUMEX），通过利用先验模型知识来指导探索和加速学习过程。具体而言，利用模型集来优化获得Q函数的上下界，并进一步提出了一种基于数据的正则化版本的模型集优化问题，确保探索策略能够收敛到最优策略。此外，在具备特定结构的模型集下（如有界参数MDP框架），优化问题变得凸且易于实现，并能证明在温和假设下的有限时间收敛性。
### Conclusion
通过一系列理论和实验证明，本文提出的BUMEX策略能够在保持理论保证的情况下显著加速在学习过程中的收敛速度，尤其是在具备特定结构的MDP问题上。这一方法提供了批量化探索策略在特定条件下能实现快速收敛的新途径，改善了传统的方法需要大量数据的治疗。工具箱已开发完成，可以供研究使用。
## 698. `cs.LG` - 基于分布公平性指标的可解释偏见后训练缓解 [PDF](https://arxiv.org/pdf/2504.01223), [HTML](https://arxiv.org/abs/2504.01223)
### Authors
Ryan Franks,Alexey Miroshnikov,Konstandinos Kotsiopoulos
### Background
本文开发了一种新颖的偏见缓解框架，该框架基于分布公平性约束，适用于生成无偏见且可解释的机器学习模型。这一框架通过后处理方法，使得在不重新训练底层模型的情况下，可以高效地生成更公平的模型。该框架基于随机梯度下降算法，适用于多种模型类型，特别是梯度提升决策树的后处理。作者还设计了一系列全局公平性指标，以及与该框架兼容的不同可微且一致估计器，基于之前的研究工作。实验结果显示该方法在各种数据集上的表现，并将其与其他后处理方法进行了对比，包括贝叶斯搜索、最优传输投影和直接神经网络训练方法。
### Innovation
本文提出了一种基于分布公平性约束的新型偏见缓解框架，通过后处理方法生成高效的无偏见且可解释的机器学习模型。该框架在梯度提升决策树上特别有效。作者设计了适合这一框架的全局公平性指标和可微且一致估计器。与现有方法相比，这种方法具有更高的效率和可解释性。
### Conclusion
该研究通过实验验证了所提出的方法的有效性，并将其与其他后处理方法进行了比较。结果表明，该方法可以在提高模型公平性的同时保持较高的性能和可解释性。
## 699. `cs.LG` - 基于集中数据优化启发的模型合并方法用于混合数据学习：利用集中数据精炼去中心化模型 [PDF](https://arxiv.org/pdf/2503.20138), [HTML](https://arxiv.org/abs/2503.20138)
### Authors
Junyi Zhu,Ruicong Yao,Taha Ceritli,Savas Ozkan,Matthew B. Blaschko,Eunchung Noh,Jeongwon Min,Cho Jung Min,Mete Ozay
### Background
当前的网络训练模式主要集中在中心化或去中心化数据环境中。然而，在实践中，数据可用性往往表现出混合性质，两者共存。这种混合环境为模型训练提供了新的机会，因为这两种环境提供了互补的权衡：去中心化数据虽然丰富但受异质性和通信限制的影响，而中心化数据虽然数量有限且可能代表性不足，但可以更好地进行整理和提供高吞吐量访问。尽管具有潜力，但有效地结合这些模式仍然具有挑战性，且很少有框架被设计用于混合数据环境。
### Innovation
提出了一个新的框架，该框架从去中心化模型中构建模型地图，并利用中心化数据在结构化的空间中精炼全局模型，然后再利用精炼后的模型重新初始化去中心化模型。该方法结合了联邦学习（利用去中心化数据）和模型合并（利用中心化数据），使在混合数据可用性下有效训练成为可能。理论证明，由于合并过程中的方差减少，该方法比仅依赖去中心化数据的方法具有更快的收敛速度。广泛的实验证明了该框架在纯粹中心化、纯粹去中心化及现有的混合适应方法中表现更优。此外，即使中心化和去中心化数据领域不同或去中心化数据包含噪声，该方法也能保持稳健。
### Conclusion
该框架在混合数据环境中表现优异，克服了数据可用性的多种形式。利用集中数据优化去中心化模型的合并方法提供了一个有效的解决方案，能够在未来的研究和实践中进一步推广这一应用，提高机器学习系统的灵活性和适应性。
## 700. `cs.LG` - Omni-Mol: 多任务分子模型，适用于任何模态到任何模态 [PDF](https://arxiv.org/pdf/2502.01074), [HTML](https://arxiv.org/abs/2502.01074)
### Authors
Chengxin Hu,Hao Li,Yihe Yuan,Zezheng Song,Chenyang Zhao,Haixin Wang
### Background
在分子领域，大量研究已经探索了使用多模态大型语言模型（LLM）构建通用型、多任务分子模型。然而，这些努力尚未实现真正的通用分子模型。现有挑战包括：(1) 现有分子任务数据集规模较小，且缺乏全面的领域覆盖；(2) 不同分子子领域的任务难以通过LLM有效联合学习，由于任务间分布的巨大差异和任务间的竞争引入了学习过程的不稳定性；(3) 任务间和任务内的分子表示需要空间中不同的内在维度，使平衡语言模型表示中的冗余和不足变得困难。
### Innovation
该研究创新性地将现有的小分子任务分类为四种类型：Mol2Mol，Mol2Text，Mol2Num，Text2Mol，并构建了一个包含16多个任务、超过140万样本的数据集，成为目前最大的分子指令调优数据集。利用LLM在现有化学文献中的广泛预训练，作者提出了一种新的多模态LLM框架Omni-Mol，该框架统一了所有小分子任务并支持分子生成和理解。Omni-Mol的核心包括作者提出的MoGE，这是一种混合专家架构，能够根据不同任务的内在排序动态适应。实验结果表明，Omni-Mol可在16个任务中实现统一指令调优，并在其中13个任务上达到了最先进的性能。
### Conclusion
 Omni-Mol展示了规模性和灵活性，其不仅在16个任务中实现了统一指令调优，还在13个任务上达到了最先进的性能，证明了其在多模态分子任务中的广泛适用性和强大的处理能力。
## 701. `cs.LG` - 通过缓解评分函数奇异改善欧几里得扩散生成的流形数据 [PDF](https://arxiv.org/pdf/2505.09922), [HTML](https://arxiv.org/abs/2505.09922)
### Authors
Zichen Liu,Wei Zhang,Tiejun Li
### Background
欧几里得扩散模型在不同领域中的生成建模中取得了显著的成功，并且在最近的研究中已将其扩展到流形情况。然而，这些模型通常需要直接利用特殊流形的结构，本研究探讨了在保持数据流形结构的同时，直接从欧几里得扩散模型中进行采样的可能性。研究表明，在环境中评分函数存在多重奇异点，影响了扩散生成样本的准确性。
### Innovation
研究揭示了在流形结构数据上的欧几里得扩散模型中的评分函数奇异结构。提出了两种新的方法来缓解这一问题：(1) Niso-DM，通过使用非各向同性的噪声来减少评分函数的规模差异；(2) Tango-DM，仅通过使用切方向损失函数来训练评分函数的切方向部分。
### Conclusion
数值实验表明，这些方法在具有复杂几何结构的各种流形上的分布上均实现了优越的性能。
## 702. `cs.LG` - AnomalyMatch：使用半监督和主动学习发现稀有目标 [PDF](https://arxiv.org/pdf/2505.03509), [HTML](https://arxiv.org/abs/2505.03509)
### Authors
Pablo Gómez,Laslo E. Ruhberg,Maria Teresa Nardone,David O'Ryan
### Background
在天文学和计算机视觉中，大型数据集中的异常检测至关重要。然而，由于缺乏标注数据，通常无法应用监督方法进行异常检测。
### Innovation
提出了一种结合半监督FixMatch算法和主动学习的异常检测框架AnomalyMatch，使用EfficientNet分类器。该框架专为大规模应用设计并集成到ESA Datalabs科学平台上。该方法将异常检测视为二分类问题，并高效利用少量标注和大量未标注的图像进行训练。通过用户界面启用主动学习，以验证高置信度的异常并纠正假阳性结果。在GalaxyMNIST天文数据集和miniImageNet自然图像基准测试下展示了强大的性能。相对于面对严重的类别不平衡，从五到十个标注异常开始，AUROC达到0.96（miniImageNet）和0.89（GalaxyMNIST），AUPRC分别为0.82和0.77。经过三轮主动学习循环后，异常的排名精度在最高评分图像的前1%中达到了76%至94%。与已建立的Astronomaly软件相比，在Galaxy Zoo - The Galaxy Challenge数据集中选出的“稀奇”星系上，表现出色，平均AUROC达到0.83。
### Conclusion
此结果强调了这种方法在异常发现方面的非凡实用性和可扩展性，特别是在严重缺乏标签的数据领域强调了专门方法的价值。
## 703. `cs.LG` - 一种基于自动阈值的稳健且非迭代张量分解方法 [PDF](https://arxiv.org/pdf/2505.06203), [HTML](https://arxiv.org/abs/2505.06203)
### Authors
Hiroki Hasegawa,Yukihiko Okada
### Background
物联网和生物识别传感技术的近期进展推动了大规模和高维张量数据的生成，准确而高效地进行低秩近似仍然是一个主要挑战。现有的张量分解方法通常需要先验指定张量秩，并依赖迭代优化，这往往导致高昂的计算成本和对分析师经验的依赖。
### Innovation
提出了一种新的针对张量数据的低秩近似方法，该方法无需先验指定秩和迭代优化。它通过对模式展开矩阵进行统计奇异值硬阈值处理，自动提取统计上显著的成分，从而实现噪声减少同时保留内在张量结构。理论分析基于马尔可夫-帕斯特分布的渐近性质推导了每个模式的最优阈值。
### Conclusion
仿真实验表明，所提出的方法在估计准确性和计算效率方面均优于传统的如高阶奇异值分解、高阶正交迭代和Tucker-L2E方法。结果表明，该方法提供了一种有效且理论依据充分的自动、非迭代和分析师独立的张量分解框架。
## 704. `cs.LG` - 重新思考具有不同约束紧度的车辆路线问题的神经组合最优化 [PDF](https://arxiv.org/pdf/2505.24627), [HTML](https://arxiv.org/abs/2505.24627)
### Authors
Fu Luo,Yaoxin Wu,Zhi Zheng,Zhenkun Wang
### Background
最近的神经组合优化（NCO）方法在无需领域特定专业知识的情况下显示出解决优化问题的前景。然而，当前大多数NCO方法使用固定约束值的训练和测试数据，在不同约束紧度对NCO方法性能影响的研究方面存在不足。本研究以容量约束车辆路线问题（CVRP）为例子，通过实证分析不同约束紧度下NCO方法的性能。研究表明，现有的NCO方法过度适应了容量约束，并且只能在某个限制值范围内表现良好，而在其他值上表现不佳。
### Innovation
本研究开发了一种高效的训练方案，明确考虑了不同约束紧度，并提出了一种多专家模块来学习一个一般适应的求解策略。这种方法能够在存在各种约束紧度时有效克服过度适应问题，并在CVRP和具有时间窗的CVRP（CVRPTW）方面表现出优越的性能。
### Conclusion
实验结果表明，提出的方案能够有效解决现有NCO方法的过度适应问题，能够有效地处理不同约束紧度下的CVRP和CVRPTW问题。
## 705. `cs.LG` - 激励大型语言模型自我验证其答案 [PDF](https://arxiv.org/pdf/2506.01369), [HTML](https://arxiv.org/abs/2506.01369)
### Authors
Fuxiang Zhang,Jiacheng Xu,Chaojie Wang,Ce Cui,Yang Liu,Bo An
### Background
大型语言模型（LLMs）在复杂的推理任务中通过后训练和测试时的扩展法则已经取得了显著的进步。现有的测试时扩展方法通常通过使用外部奖励模型来指导模型生成过程，但是我们发现，对特定推理任务进行后训练扩展后，只能获得微小的性能提升。这主要是因为特定后训练生成器和通用奖励模型之间的分布差异导致的。
### Innovation
本文提出了一种框架，激励LLMs自我验证其答案。通过在单一强化学习过程中统一答案生成和验证，训练出的模型能够有效地评估自身解决方案的正确性。并且，在测试时验证生成内容，无需外部验证者即可扩展性能。
### Conclusion
本研究在Qwen2.5-Math-7B和DeepSeek-R1-Distill-Qwen-1.5B的基础上训练了自我验证模型，展示了其在不同推理上下文长度中的能力。实验表明，我们的模型不仅可以在后训练阶段提升性能，还可以实现有效的测试时扩展。
## 706. `cs.LG` - AANet: 在结构不确定性下通过对齐和聚合进行虚拟筛选 [PDF](https://arxiv.org/pdf/2506.05768), [HTML](https://arxiv.org/abs/2506.05768)
### Authors
Wenyu Zhu,Jianhui Wang,Bowen Gao,Yinjun Jia,Haichuan Tan,Ya-Qin Zhang,Wei-Ying Ma,Yanyan Lan
### Background
虚拟筛选（VS）是现代药物发现中的关键组成部分，尽管大多数现有方法，无论是基于物理学的还是基于深度学习的方法，都是围绕已知配体结合口袋的完整蛋白结构开发的，但在实际早期药物发现中，如来自AlphaFold2的apo或预测结构，口袋信息经常缺失，从而导致现有方法的性能显著下降。本研究旨在解决这一问题，通过引入一种对齐和聚合框架在结构不确定性下进行准确的虚拟筛选。
### Innovation
提出了一个三模态对比学习模块，该模块能够对配体、完整口袋和结构中检测到的空腔的表征进行对齐，从而增强对口袋定位误差的鲁棒性；并提出了一种基于交叉注意力的适配器，能够让模型动态聚合候选结合位点，即使没有精确的口袋注释，也能从活性数据中学习。在新的apo结构基准测试上，该方法在盲测试中显著优于最先进的方法，提高了一级富集因子（EF1%）从11.75到37.19，并且在完整结构上也保持了强劲的性能。
### Conclusion
这些结果表明，该方法在推动首次分类药物发现方面具有巨大潜力，特别是在缺乏实验解析的蛋白-配体复合物的场景中。该方法的实现已公开发布。
## 707. `cs.LG` - 通过测试时投影学习改善神经组合优化在车辆路由问题中的泛化能力 [PDF](https://arxiv.org/pdf/2506.02392), [HTML](https://arxiv.org/abs/2506.02392)
### Authors
Yuanyao Chen,Rongsheng Chen,Fu Luo,Zhenkun Wang
### Background
神经组合优化(NCO)已经成为利用基于学习的范式来解决车辆路线问题(VRPs)的一个有前途的方法，因为它减少了需要大量的手工工程。现有的NCO方法能够在小规模实例（例如，100个节点）上得到很好的效果，但在大规模场景中表现会显著下降，这是由于训练和测试数据之间的分布差异导致的。现有的解性能降低的方法依赖于大规模重新训练，这增加了模型复杂性和计算成本。
### Innovation
本文提出了一种新的学习框架，该框架通过大型语言模型(LLMs)驱动，能够学习训练分布与测试分布之间的投影，从而增强NCO模型的大规模扩展性。与现有的需要与神经网络联合训练的技术不同，这种方法仅在推理阶段运行，无需重新训练模型。实验结果表明，我们的方法使训练在100个节点的模型能够在多达10万个节点的大规模旅行商问题(TSP)和容量受限车辆路线问题(CVRP)上获得更好的性能，适用于各种分布。
### Conclusion
通过对NCO模型在测试阶段的应用进行改进，使小型实例训练得到的模型能够扩展到大规模问题，证明了这种方法的有效性，为处理大规模VRP提供了一种新的解决方案。
## 708. `cs.LG` - 关注差距：消除可微逻辑门网络中的离散化差距 [PDF](https://arxiv.org/pdf/2506.07500), [HTML](https://arxiv.org/abs/2506.07500)
### Authors
Shakir Yousefi,Andreas Plesner,Till Aczel,Roger Wattenhofer
### Background
现代神经网络在许多现有基准测试中表现出卓越的性能，但其高计算需求和高能耗促使研究人员寻找更高效的解决方案以适用于实际部署。逻辑门网络（LGNs）通过学习大量的逻辑门来实现高效的图像分类，但在训练解决如CIFAR-10这样简单问题的网络时，可能需要数天到数周的时间。即便如此，大约一半的网络仍然未被使用，导致了离散化差距。这一差距阻碍了LGNs在实际部署中的应用，因为在训练和推理之间的性能下降对准确率产生了负面影响。
### Innovation
我们通过在训练过程中注入Gumbel噪声并使用直通估计器显著加快了训练速度、提升了神经元利用率并减少了离散化差距。我们的研究表明，这源于隐含梯度二阶矩正则化，从而改善了LGNs的收敛性。实验结果显示，我们使网络在实际时间中快4.5倍的速度训练，在离散化差距上减少了98%，并且将未使用的门电路减少了100%。
### Conclusion
我们通过新的训练策略成功地解决了LGNs中的离散化差距问题，显著提高了其在实际部署中的效率和准确性。
## 709. `cs.LG` - 基于回归的归一化流高效训练方法在玻尔兹曼生成器中的应用 [PDF](https://arxiv.org/pdf/2506.01158), [HTML](https://arxiv.org/abs/2506.01158)
### Authors
Danyal Rehman,Oscar Davis,Jiarui Lu,Jian Tang,Michael Bronstein,Yoshua Bengio,Alexander Tong,Avishek Joey Bose
### Background
生成模型在连续空间中的模拟自由训练框架处于生成建模革命的前沿，导致了大规模扩散和流动匹配模型的发展。然而，这些现代生成模型在推断方面昂贵，限制了它们在需要快速似然评估的科学应用中的使用，如玻尔兹曼生成器（BGs）用于分子构象。BGs提供高效的采样和似然性，但通过最大似然训练常常不稳定且计算上具有挑战性，传统的最大似然训练方法存在数值不稳定性和计算挑战。
### Innovation
提出了一种名为RegFlow（回归训练的归一化流）的新颖且可扩展的基于回归的训练目标，它可以绕过传统的最大似然训练方法中的数值不稳定性与计算挑战，采用简单的$boldsymbol{text{ℓ}_2}$回归目标。RegFlow将先验样本在流下的映射到通过最优输运耦合或预训练的连续归一化流（CNF）计算的目标。为了提高数值稳定性，RegFlow采用了一些有效的正则化策略，如一种新的正向-反向自我一致性损失，这种损失易于实现。实验结果表明，RegFlow可以解锁更广泛的架构，使得之前通过最大似然训练难以训练的BGs有了训练的可能性。此外，RegFlow在甘氨酸二肽、三肽和四肽的直角坐标系中配平采样的性能、计算成本和稳定性也超过了最大似然训练，展示了其在分子系统的潜力。
### Conclusion
RegFlow作为一种新颖的基于回归的训练目标，能够消除BGs中最大似然训练的数值不稳定性与计算挑战，促进更广泛架构的高效训练与应用。在分子系统的直角坐标系配平采样实验中，RegFlow的性能超过了最大似然训练，展示了其优势。
## 710. `cs.LG` - 基于低秩训练的动量优化器的几何框架 [PDF](https://arxiv.org/pdf/2506.17475), [HTML](https://arxiv.org/abs/2506.17475)
### Authors
Steffen Schotthöfer,Timon Klein,Jonas Kusch
### Background
低秩预训练和微调近年来被提出用于减少大型神经网络的计算和存储成本。传统上，训练低秩参数化依赖于像重球动量方法或Adam这样的常规优化器。然而，这些方法在训练低秩权重参数化时会遇到一些潜在的困难，比如由于优化景观的几何结构问题，常规动量方法可能会难以收敛到局部最优值。
### Innovation
本文提出了一个新颖的低秩训练优化策略，该策略结合了动态低秩逼近和动量优化，并利用这些工具设计出尊重参数空间内在几何结构的优化器，以解决传统优化方法在低秩参数化训练中的问题。通过数值实验验证了方法的有效性，展示了在给定参数预算下更快的收敛速度和更强的验证指标。
### Conclusion
该研究通过结合动态低秩逼近技术和动量基优化方法，设计了一种新的优化器，该优化器能够更好地适应低秩参数空间的内在几何结构，从而提高了低秩训练的效率和效果，为低秩优化提供了一种新的几何框架。
## 711. `cs.LG` - 理解节点和链预测中的泛化能力 [PDF](https://arxiv.org/pdf/2507.00927), [HTML](https://arxiv.org/abs/2507.00927)
### Authors
Antonis Vasileiou,Timo Stoll,Christopher Morris
### Background
在各种科研及工业领域，使用消息传递图神经网络（MPNNs）进行节点和链预测至关重要，这推动了MPNN架构的多样化发展。尽管MPNNs在实际应用中表现良好，但它们在训练集之外的泛化能力仍然不明确。已有研究主要关注于图级预测任务中的泛化能力，而对节点级和链级预测任务的泛化能力关注不足。现有工作通常依赖于不切实际的独立同分布（i.i.d.）假设，忽略了节点或链之间的潜在相关性，假设固定的聚合方法和不切实际的损失函数，而忽视了图结构的影响。因此，亟需一个框架来分析MPNN在归纳和transductive节点和链预测中的泛化能力，并量化图结构的影响。同时，该框架可以适用于任何分类任务，无论是归纳还是transductive设置。前人的实证研究支持我们的理论洞察，加深了我们对MPNNs在这些任务中泛化能力的理解。
### Innovation
引入了一个统一框架来分析MPNNs在归纳和transductive节点和链预测中的泛化特性，并考虑了多样化的架构参数和损失函数，还量化了图结构的影响。此外，该框架可以扩展应用于任何分类任务，无论是归纳还是transductive设置。
### Conclusion
实证研究验证了理论洞察，增强了对MPNNs在这些任务中的泛化能力的理解。
## 712. `cs.LG` - 当核相乘时，簇共融：通过克罗内克积融合嵌入 [PDF](https://arxiv.org/pdf/2506.08645), [HTML](https://arxiv.org/abs/2506.08645)
### Authors
Youqi Wu,Jingwei Zhang,Farzan Farnia
### Background
现有的最先进的嵌入模型能够捕捉到不同但互补的具有辨别性的特征，例如，在图像嵌入模型中，一个模型可能擅长识别细微的纹理，而另一个模型则专注于物体级别的结构。本文基于这一观察，提出了一种通过对核乘积的方法来融合这些互补表示的原理性方法。这种方法通过乘积两个嵌入模型的核相似函数，使其辨别性结构得以交互，以生成融合表示，其中的核编码了每个父嵌入识别的簇的并集。该框架还可用于构建配对多模态数据的联合核（如图像-文本元组），并且模态特定核的乘积所能继承来自两个领域的结构。这种方法的数学实现是通过嵌入特征图的克罗内克积来实现的，这提出了提出的KrossFuse框架用于嵌入融合。为了避免高维克罗内克空间带来的计算成本问题，本文还开发了一种基于随机投影的可扩展变体——RP-KrossFuse，以实现高效的近似计算。
### Innovation
提出了KrossFuse框架，通过嵌入模型的特征图的克罗内克积来实现核乘的数学实现。为了应对高维克罗内克空间带来的计算成本问题，进一步开发了RP-KrossFuse，利用随机投影进行高效近似。该框架成功地用于跨模态嵌入（如CLIP, BLIP）和单模态专家（如DINOv2, E5）之间的性能差距的填补，并在实验中展示了其有效性，提高了模态特定性能并保持了跨模态的对齐。
### Conclusion
提出的RP-KrossFuse框架有效融合了这些模型，增强了模态特定性能同时保持跨模态对齐。项目代码可以在此下载：[提供链接]。
## 713. `cs.LG` - 无计划 swimming through the language model训练中的优势 [PDF](https://arxiv.org/pdf/2507.09846), [HTML](https://arxiv.org/abs/2507.09846)
### Authors
Minhak Song,Beomhan Baek,Kwangjun Ahn,Chulhee Yun
### Background
随着模型和数据集的规模迅速扩大，传统的固定计算预算的预训练策略，如余弦学习率计划，越来越不足以适应大规模训练的需求。近期的替代方法，例如温升-稳定-衰减（WSD）计划和权重平均，提供了更大的灵活性。然而，WSD依赖于显式的衰减阶段来跟踪进展，而权重平均则通过增加额外的内存消耗来解决这一限制。
### Innovation
研究发现Schedule-Free (SF) 方法[Defazio等，2024]在多种设置下表现出强劲的实验结果。通过理论和实验分析SF动态，揭示了其如何在没有衰减阶段或辅助平均的情况下高效导航损失景观。为此，提出了改进版的SF策略，提高了其对动量的鲁棒性，并在大规模批量大小下表现更好，从而解决了原方法的关键局限性。
### Conclusion
这些结果确立了SF作为语言模型训练中实用、可扩展且具有理论依据的方法的地位。
## 714. `cs.LG` - MTL-KD：通过知识蒸馏实现泛化神经型车辆路由求解器的多任务学习 [PDF](https://arxiv.org/pdf/2506.02935), [HTML](https://arxiv.org/abs/2506.02935)
### Authors
Yuepeng Zheng,Fu Luo,Zhenkun Wang,Yaoxin Wu,Yu Zhou
### Background
多任务学习（MTL）在神经组合优化（NCO）中的应用，特别是在解决多个车辆路线问题（VRP）变体方面显示出前景。然而，现有的基于强化学习（RL）的多任务方法只能训练轻量级的解码器模型并解决小型问题。当解决大型问题时，这种模型显示出了有限的推广能力。为克服这一局限性，本文介绍了一种新的由知识蒸馏驱动的多任务学习方法（MTL-KD），该方法使得能够高效训练重型解码器模型并具有强大的推广能力。该MTL-KD方法将来自多个不同的单任务RL模型的策略知识传递给单一的重型解码器模型，从而实现无标签训练，并有效地提高了模型在各种任务上的推广能力。此外，论文还引入了一种灵活的推理策略，称为随机重新排序重建（R3C），该策略特地适应多种VRP任务，进一步提高了多任务模型的性能。在10种多达1000个节点的已见和未见VRP变体上进行的实验结果表明，提出的该方法在均匀和现实世界基准测试中的性能均优于现有方法，展示了其强大的推广能力。
### Innovation
提出的MTL-KD方法通过知识蒸馏将来自多个不同的单任务RL模型的策略知识传递给单一的重型解码器模型，实现了无标签训练，并显著提高了模型的推广能力。此外，引入的随机重新排序重建（R3C）策略适用于多种VRP任务，进一步增强了多任务模型的性能。这种方法能够高效训练重型解码器模型，解决大型VRP问题并显示较强的推广能力。
### Conclusion
在6种已见和10种未见多达1000个节点的VRP变体上进行的实验表明，我们的工作一致地在统一和现实世界基准测试中表现优异，展示了其强大的推广能力。这种方法在解决各种VRP变体上显示出潜在的应用价值。
## 715. `cs.LG` - 使用GFlowNets学习更优质的药物-药物相互作用表示 [PDF](https://arxiv.org/pdf/2508.06576), [HTML](https://arxiv.org/abs/2508.06576)
### Authors
Azmine Toushik Wasi
### Background
药物-药物相互作用（DDI）在临床药理学中提出了重大挑战，交互类型之间严重失衡限制了预测模型的效果。常见交互类型占据了数据集，而稀有但至关重要的交互类型则严重不足，导致模型在处理罕见情况时表现不佳。现有方法往往将DDI预测视为二分类问题，忽略了分类的具体差异，加剧了对常见交互类型的偏向。
### Innovation
提出了结合生成流网络（GFlowNet）与变分图自编码器（VGAE）的框架来生成稀有类别的合成样本，以改善模型的平衡并生成有效的新型DDI对。该方法在不同类型交互中增强了预测性能，确保了临床可靠性。
### Conclusion
该框架提升了DDI预测的整体表现，特别注重处理稀有但重要的交互类型，旨在提供更具临床可靠性的预测结果。
## 716. `cs.LG` - 基于LLM的推理时段文本共变量驱动的治疗效果估计 [PDF](https://arxiv.org/pdf/2507.02843), [HTML](https://arxiv.org/abs/2507.02843)
### Authors
Yuchen Ma,Dennis Frauen,Jonas Schweisthal,Stefan Feuerriegel
### Background
在临床实践中，个性化医疗决策的关键是治疗效果的估计，但这一任务面临独特的挑战。通常在训练时，模型通过结构良好的医疗数据集，这些数据集包含详细的患者信息进行训练，而在推理时，预测常常基于文本描述（如自我报告的症状），这些描述是原始患者信息的不完整表示。文本描述的不完整性可能导致治疗效果估计偏差，特别是在训练数据和推理数据不匹配的情况下。本文通过建立一个新框架，利用大型语言模型和自定义双重稳健学习器，有效应对推理时段的文本共变量问题，从而提高了治疗效果估计的准确性
### Innovation
本文提出的创新在于：1) 正式提出并定义了在推理时段存在文本共变量条件下的治疗效果估计偏差问题。2) 提出了一种新的框架，该框架结合了大型语言模型和自定义双重稳健学习器，以解决推理时段的文本共变量问题，从而减轻偏差。3) 通过一系列实验，验证了该框架在实际应用场景中的有效性
### Conclusion
本文提出的框架通过融合大型语言模型和自定义双重稳健学习器，在量化治疗效果和应对推理时段文本共变量问题方面表现出色。这种方法不仅可以提高治疗效果估计的准确性，还为未来的研究提供了新的方向。
## 717. `cs.LG` - 广义线性多臂老虎机：几乎最优的遗憾与一次性更新 [PDF](https://arxiv.org/pdf/2507.11847), [HTML](https://arxiv.org/abs/2507.11847)
### Authors
Yu-Jie Zhang,Sheng-An Xu,Peng Zhao,Masashi Sugiyama
### Background
研究广义线性带宽（GLB）问题，这是一种通过引入非线性链接函数扩展经典线性模型的上下文多臂老虎机框架，能够建模诸如伯努利和泊松等广泛的奖励分布。尽管GLB在实际场景中具有广泛的应用，但其非线性性质使得在计算和统计效率上取得最优结果面临巨大挑战。现有方法通常需要在每次更新中实现最优遗憾保证（高每回合成本）和统计效率（常量时间更新）之间进行权衡。
### Innovation
提出了一个高效算法，能够在每次回合中实现几乎最优的遗憾界，同时具有 $textbf{O}(1)$ 的时空复杂度。核心在于结合在线预测中的混损失概念，为在线镜像下降（OMD）估计器构建了精确的置信集，即使是一次性更新也能实现与最大似然估计相媲美的统计效率，从而实现了计算与统计效率的一体化。
### Conclusion
提出了一个几乎最优的在线镜像下降估计器，即使是一次更新也能实现与最大似然估计相类似的统计效率，进而提出了一个高效乐观方法，能够在每次回合中几乎最优地达到遗憾界，同时具备 $textbf{O}(1)$ 的时空复杂度。
## 718. `cs.LG` - 相似性-距离-幅度激活函数 [PDF](https://arxiv.org/pdf/2509.12760), [HTML](https://arxiv.org/abs/2509.12760)
### Authors
Allen Schmaltz
### Background
介绍了Similarity-Distance-Magnitude (SDM)激活函数，这是一种比标准softmax激活函数更稳健且可解释的新颖的公式，添加了对正确深度匹配（即训练中的正确预测的深度匹配）和训练分布距离的感知，以及对决策边界的感知，实现了通过密集匹配进行可解释性展现。该研究进一步引入了基于SDM激活的数据驱动分类函数SDM估计器，以在选择性分类中控制条件准确度：在基于预训练语言模型的最终层激活时，SDM估计器在共变量偏移和超出分布输入情况下表现更稳健，同时保留了对在分布数据的有用信息。
### Innovation
提出了新的SDM激活函数，结合相似性感知、距离感知和幅度感知，增加了解释性。还介绍了基于SDM激活的SDM估计器，用于选择性分类中的类条件和预测条件准确度控制。SDM估计器在共变量偏移和超出分布输入时表现更稳健，同时提供在分布数据的有用信息。
### Conclusion
SDM激活函数及其估计器提升了选择性分类中的模型表现和解释性，特别是在处理共变量偏移和超出分布输入时表现更稳健。
## 719. `cs.LG` - SafEDMD：基于库普曼算子的非线性动力学系统数据驱动控制器设计框架 [PDF](https://arxiv.org/pdf/2402.03145), [HTML](https://arxiv.org/abs/2402.03145)
### Authors
Robin Strässer,Manuel Schaller,Karl Worthmann,Julian Berberich,Frank Allgöwer
### Background
库普曼算子为动力学控制系统的机器学习理论基础，扩展动态模式分解（EDMD）被用于近似库普曼算子。本文探讨了一种新的基于EDMD的控制器设计框架，称为SafEDMD，其目标是提供闭环保证，并通过半定规划方法实现非线性系统的稳定化。
### Innovation
提出了一种名为SafEDMD的稳定性-反馈导向的数据驱动控制器设计框架。通过生成可靠的数据驱动代理模型，提供闭环保证。特别地，该方法基于半定规划来设计控制器，以确保非线性系统的稳定化。同时，文中推导了适用于控制任务的比例误差界，该误差界在原点附近消失。
### Conclusion
通过几个基准例子展示了所提出方法的应用，并强调了与现有先进方法相比的优势。
## 720. `cs.LG` - 局部核投影离群点检测：一种针对多模态离群点检测的两阶段方法 [PDF](https://arxiv.org/pdf/2510.24043), [HTML](https://arxiv.org/abs/2510.24043)
### Authors
Akira Tamamori
### Background
传统的投影基方法依赖于固定统计度量，且假设单一数据结构，这些方法在处理复杂的多模态数据集时表现不佳。
### Innovation
提出了一种全新的两阶段离群点检测框架Two-Stage LKPLO，它综合了三项关键技术：（1）使用灵活的、自适应的损失函数替代固定度量的广义损失基离群指标；（2）全局核PCA阶段以线性化非线性数据结构；（3）后续的局部聚类阶段处理多模态分布。在10个基准数据集上进行的5折交叉验证实验，通过自动超参数优化表明，Two-Stage LKPLO 达到了最先进的性能。
### Conclusion
该工作为一类重要的离群点检测问题提供了一种强有力的新型工具，并强调了混合、多阶段架构的重要性。
## 721. `cs.LG` - 通过轻量级训练的分层图网络进行准确的天气预报 [PDF](https://arxiv.org/pdf/2510.22094), [HTML](https://arxiv.org/abs/2510.22094)
### Authors
Thomas Bailie,S. Karthik Mukkavilli,Varvara Vetrova,Yun Sing Koh
### Background
气候事件源自复杂、多变量的动力学，受全球尺度驱动者影响，严重影响了食品、能源和基础设施。但由于物理过程跨越不同的空间和时间尺度，固定分辨率方法无法捕捉这些过程，导致准确的天气预测仍然难以实现。
### Innovation
通过引入HiFlowCast和其集合变体HiAntFlow分层图神经网络，该设计基于多层次预测框架嵌入物理。其创新点包括：1）Latent-Memory-Retention机制，确保在向下遍历时保留全局趋势；2）Latent-to-Physics分支，用于在不同尺度上整合偏微分方程解场。实验表明，Flow模型在13天预报时效内的预测误差减少了5%以上，并在1%和99%分位极端条件下分别降低了5-8%的误差，提高了极端事件的可靠性。预训练模型权重的使用使其在一个训练周期内即可收敛，降低了训练成本和碳足迹。
### Conclusion
这种高效性对于应对机器学习规模增长带来的可持续性挑战和研究获取限制至关重要。模型代码和预训练权重在附录材料中提供。
## 722. `cs.LG` - 在事前预见结构失效：基于图像的物理感知神经网络（PINN）对意大利面桥载荷预测 [PDF](https://arxiv.org/pdf/2510.23117), [HTML](https://arxiv.org/abs/2510.23117)
### Authors
Omer Jauhar Khan,Sudais Khan,Hafeez Anwar,Shahzeb Khan,Shams Ul Arifeen
### Background
物理感知神经网络（PINNs）因其将物理定律嵌入到深度学习模型中的能力而受到关注，这对于具有有限数据的结构工程任务特别有用。本文旨在探讨PINNs在预测小型意大利面桥梁重量的应用，该任务有助于理解简化结构模型中的负载极限和潜在失效模式。提供的数据集包括15座实际桥梁，扩充至100个样本，最佳模型的$R^2$分数为0.9603，平均绝对误差（MAE）为10.50单位
### Innovation
本文提出了一种新的架构——物理感知柯尔莫哥罗夫阿诺德网络（PIKAN），这种架构结合了泛函逼近理论和物理见解。通过使用机器视觉方法收集输入到模型的结构参数，实现了优秀的预测性能，并达到较高的$R^2$分数和较低的MAE值。而且还提供了网页界面可以方便地输入参数并获取预测结果
### Conclusion
研究表明，即使在有限数据的情况下，PINNs也可提供可靠的结构重量估计，有助于轻型桥梁设计的早期失效分析。研究资源全部可从提供的链接下载。
## 723. `cs.LG` - GSE: Group-wise Sparse and Explainable Adversarial Attacks [PDF](https://arxiv.org/pdf/2311.17434), [HTML](https://arxiv.org/abs/2311.17434)
### Authors
Shpresim Sadiku,Moritz Wagner,Sebastian Pokutta
### Background
该领域探讨了通过最小的像素扰动欺骗深度神经网络（DNNs）的对抗性攻击方法，这些扰动通常被$?ell_0$范数所正则化。最近的研究使用结构性稀疏正则化器（如核分组范数）取代$?ell_0$范数，以构建分组稀疏的对抗性攻击，从而使得这些攻击具有可解释性并具有重要的实践意义。然而，生成这样的攻击是一个优化挑战，因为需要在非凸目标函数中计算分组像素的范数。
### Innovation
本文提出了一种两阶段算法，用于在图像的语义相关区域生成具有稀疏性和可解释性的分组对抗性攻击。首先，使用$1/2-$拟范数近邻算子优化非凸程序下的对抗性损失函数；随后，过渡到带2-范数正则化的投影Nesterov加速梯度下降算法，应用于扰动幅度。这种方法展示了显著的分组稀疏性增益，提高了计算效率，并且具有完全的攻击成功率。
### Conclusion
实验在CIFAR-10和ImageNet数据集上显示出分组稀疏性显著增加，攻击成功率高，同时提高了计算效率和可解释性。
## 724. `cs.LG` - 将基因组学整合到多模态EHR基础模型中 [PDF](https://arxiv.org/pdf/2510.23639), [HTML](https://arxiv.org/abs/2510.23639)
### Authors
Jonathan Amar,Edward Liu,Alessandra Breschi,Liangliang Zhang,Pouya Kheradpour,Sylvia Li,Lisa Soleymani Lehmann,Alessandro Giulianelli,Matt Edwards,Yugang Jia,David Nola,Raghav Mani,Pankaj Vats,Jesse Tetreault,T.J. Chen,Cory Y. McLean
### Background
本文介绍了将多基因风险评分（PRS）作为基础数据模态融入电子健康记录（EHR）基础模型的新颖方法，超越了传统的仅基于EHR的方法，构建了更加全面的健康概况。该研究利用了All of Us（AoU）研究计划中广泛且多样化的大数据，旨在学习临床数据和遗传倾向之间的复杂关系。这种方法为疾病预测、主动健康管理、风险分层和个人化治疗策略提供了新的见解，并为在医疗保健领域生成更加个性化、公平和行动导向的实际证据奠定了基础。
### Innovation
提出了在EHR基础模型中整合PRS的新颖方法，利用All of Us研究计划的大数据来学习临床数据和遗传倾向之间的复杂关系。这种方法扩展了生成型AI在EHR基础模型空间中的应用，增强了预测能力和解释性。实验结果表明，该模型在预测多种疾病的发生上具有价值，特别是在2型糖尿病（T2D）方面，并展示了模型在习惯性分类任务中的灵活性和效率。
### Conclusion
该方法对于解锁疾病预测的新见解、主动健康管理、风险分层和个性化治疗策略至关重要，为未来在医疗服务中生成更加个性化、公平和行动导向的实际证据奠定了基础。
## 725. `cs.LG` - 基于GRU-TCN分类器和深度Q学习阈值调整的自适应EEG卒中诊断 [PDF](https://arxiv.org/pdf/2510.24889), [HTML](https://arxiv.org/abs/2510.24889)
### Authors
Shakeel Abdulkareem(1 and 2),Bora Yimenicioglu(2),Khartik Uppalapati(2),Aneesh Gudipati(1),Adan Eftekhari(3),Saleh Yassin(3) ((1) George Mason University, College of Science, Fairfax, VA, USA, (2) Raregen Youth Network, Translational Medical Research Department, Oakton, VA, USA, (3) Harvard University, Cambridge, MA, USA)
### Background
快速识别疑似卒中的急诊工具需要准确并在床旁可用，而EEG虽然有潜力但未广泛用于首次接触诊断。本文基于UCLH卒中EIT/EEG数据集，提出一种自适应多任务EEG分类器，该分类器将32通道信号转换为功率谱密度特征，利用GRU-TCN网络预测卒中类型、侧区化程度和严重程度，并应用DQN实时调整决策阈值以优化诊断性能。该研究采用了患者级别的数据分隔方法，以评估形态在卒中诊断中的应用潜力及其临床价值。
### Innovation
引入了一种基于自适应多任务EEG分类器和深度Q学习的实时阈值调整方法来判断卒中类型、侧区化和严重程度。相较于传统方法，该方法通过实时调整决策阈值，提高了卒中分类的准确性，并增强了解释性。研究使用了两个数据集，包括UCLH卒中EIT/EEG数据集和ZJU4H低密度数据集，验证了该方法的有效性和稳健性。
### Conclusion
基于GRU-TCN的自适应EEG分类器结合深度Q学习阈值调整能够显著提高卒中分类的准确性，并且通过调整决策阈值，在临床上提供了更优的敏感性与特异性平衡。研究结果支持在急诊环境中使用自适应EEG分类器来快速准确地诊断卒中，从而有助于快速展开有效的治疗措施。
## 726. `cs.LG` - 依赖凸性的两阶段训练算法用于深度神经网络 [PDF](https://arxiv.org/pdf/2510.25366), [HTML](https://arxiv.org/abs/2510.25366)
### Authors
Tomas Hrycej,Bernhard Bermeitinger,Massimo Pavone,Götz-Henrik Wiegand,Siegfried Handschuh
### Background
机器学习的关键任务是通过最小化衡量模型与训练数据拟合程度的损失函数来实现。有效的数值方法依赖于损失函数的特性，其中最决定性的特性是损失函数的凸性或非凸性。尽管损失函数经常包含非凸区域并促使使用Adam等非凸方法，但局部极小值周围的区域是凸性的，因此在这种环境下，共轭梯度（CG）等二次最小化方法可以提供有保证的超线性收敛。
### Innovation
本文提出了一个新颖的两阶段优化算法框架，基于这样的假设：在实际任务中，损失函数会逐渐从初始的非凸性过渡到向最优解逼近时的凸性。算法通过观察梯度范数与损失的关系来检测这种转换点。在非凸区域使用Adam方法，在凸区域使用共轭梯度（CG）方法。计算实验验证了这一假设，即这种简单的凸性结构足够常见，可以实际利用以显著提高收敛性和准确性。
### Conclusion
研究表明，在实际深度神经网络任务中，损失函数会有从非凸向凸性的过渡，这一性质被应用来设计一个两阶段优化算法。通过检测这一转换点，在不同阶段分别使用对应的优化方法，可以实现更高的收敛性和准确性。
## 727. `cs.LG` - 随机配对MLE在Rasch模型中对项目参数的估计 [PDF](https://arxiv.org/pdf/2406.13989), [HTML](https://arxiv.org/abs/2406.13989)
### Authors
Yuepeng Yang,Cong Ma
### Background
Rasch模型是项目反应理论中的经典模型，广泛应用于心理测量学，用于建模个体潜在特质与其对评估或问卷的二元反应之间的关系。现有模型估计器在大数据时代对稀疏观测数据的支持有限，而且有限样本的估计误差尚不理想，也无法精确量化项目参数的不确定性，如构建项目参数的置信区间。因此，研究人员提出了一种新的基于似然性的估计器 -- 随机配对最大似然估计器（$rm{RPtext{-}MLE}$）及其具有 bootstrapped 多重随机配对最大似然估计器（$rm{MRPtext{-}MLE}$）。
### Innovation
引入了随机配对最大似然估计器（$rm{RPtext{-}MLE}$）及其具有 bootstrapped 多重随机配对最大似然估计器（$rm{MRPtext{-}MLE}$），这两个新的估计器相较于现有方法有多个突出特点：1. 对于稀疏观测数据有良好的兼容性；2. 在有限样本的 $boldsymbol{rm l_{text{infty}}}$ 估计误差方面是证明过的最小最大最优；3. 有精确的概率分布特性，能够对项目参数的不确定性进行量化，例如构建项目参数的置信区间。这些估计器的核心思想是随机配对用户-项目响应以形成项目-项目比较，以此来减少问题规模同时保持统计独立性。
### Conclusion
通过与模拟和真实数据的实证研究，证明了这两个新估计器的有效性。
## 728. `cs.LG` - 少发送，多节约：嵌入式CNN推断与数据传输在物联网中的能效基准 [PDF](https://arxiv.org/pdf/2510.24829), [HTML](https://arxiv.org/abs/2510.24829)
### Authors
Benjamin Karic,Nina Herrmann,Jan Stenkamp,Paula Scharf,Fabian Gieseke,Angela Schwering
### Background
物联网（IoT）和人工智能（AI）的融合为提高监测和应对生态变化的能力提供了巨大机会。随着环境问题的日益紧迫，有效的远程监测解决方案变得尤为重要。设计用于环境监测的IoT应用，尤其是涉及图像数据的应用，其中一个主要挑战是如何创建能够在资源有限且电力不足的偏远地区长时间运行的高效IoT设备。Tiny Machine Learning领域的进展使得能够在节能的电池供电微控制器上使用卷积神经网络（CNNs）。由于数据传输是能源密集型的，直接在微控制器上执行推断以减少消息大小可以延长IoT节点的使用寿命。本文在ESP32-S3上评估了使用低功耗广域网络（LPWANs）和在领域特定数据集上压缩的CNN模型的效果。实验表明，将CNN推理本地执行并在需要时只传输结果可将整体能源消耗降低多达五倍，相较于传输原始图像数据而言。这些发现支持开发具有较低碳足迹并在环境监测场景中自主运行的IoT应用。
### Innovation
通过在微控制器上执行CNN推断，并仅传输结果，大幅降低了整体能源消耗，有效地减少了数据传输。这对于资源受限的IoT设备是重要的创新，尤其是在无法频繁充电的偏远地区，这种方法能够显著延长装置的寿命。同时，通过使用特定领域的压缩CNN模型和LPWANs，该研究提供了一种有效的解决方案以应对环境监测中的能效挑战。
### Conclusion
通过本地执行CNN推断并只传输推理结果，研究展示了与传输未经处理的图像数据相比，整体能源消耗可以降低多达五倍，支持了开发具有较低碳足迹且能够在环境监测场景中自主运行的IoT应用，该研究为IoT设备在能源有限环境下的应用提供了新的解决方案。
## 729. `cs.LG` - 塑性作为 empowerment 的镜像 [PDF](https://arxiv.org/pdf/2505.10361), [HTML](https://arxiv.org/abs/2505.10361)
### Authors
David Abel,Michael Bowling,André Barreto,Will Dabney,Shi Dong,Steven Hansen,Anna Harutyunyan,Khimya Khetarpal,Clare Lyle,Razvan Pascanu,Georgios Piliouras,Doina Precup,Jonathan Richens,Mark Rowland,Tom Schaul,Satinder Singh
### Background
代理是由其过去的观察所影响并在未来观察中采取行动的最小单元。empowerment 是一个重要的框架概念，在人工智能和认知科学中发挥着核心作用。而代理如何以及多大程度上被观察影响却是一个基本问题。本文基于一个通用的代理中心度量概念，称为塑性，揭示了它与 empowerment 的基本联系。塑性与 empowerment 用相同的标准进行度量，仅是影响的方向相反。
### Innovation
引入了塑性作为塑形幂的概念，通过提出适合的定义标准，定义了一种新的信息论量化的概念——广义定向信息，并证明了它严格地扩展了 Massey (1990) 提出的定向信息，同时保持其所有优点。塑性与 empowerment 在度量标准上互为镜像，而仅影响方向相反。
### Conclusion
塑性与 empowerment 之间存在紧张关系，这意味着在设计代理时需要同时考虑这两个特性。塑性、empowerment 以及它们的关系对于理解代理是至关重要的。
## 730. `cs.LG` - 多样性作为一种奖励：基于混合领域未定义数据的LLM精调 [PDF](https://arxiv.org/pdf/2502.04380), [HTML](https://arxiv.org/abs/2502.04380)
### Authors
Zhenqing Ling,Daoyuan Chen,Liuyi Yao,Qianli Shen,Yaliang Li,Ying Shen
### Background
在实际应用中，大型语言模型（LLMs）的总体性能提高依赖于使用多样化的数据集进行微调。然而，现有基于数据组成模型混合比例的方法在处理缺失、模糊或非规范化领域标签的数据时表现不佳；基于数据选择的方法在平衡多领域性能时遇到了挑战。因此，解决上述问题对于提高LLMs的性能至关重要。
### Innovation
本文提出了一种新的方法，该方法赋予LLM双重身份：输出模型用于基于多样性奖励的认知性数据探查和选择，输入模型则基于所选数据进行调整。这种方法通过构建对比数据池并理论解释数据多样性的作用来提高LLMs处理领域未定义数据以及多种下游基础任务的性能。
### Conclusion
论文表明，所提出的方法在应用于各种先进LLMs时，能显著提升领域未定义数据和其他一系列基础下游任务的性能。作者期待该研究能促进对数据多样性的理解，并推进反馈驱动的数据-模型联合设计方法的发展。
## 731. `cs.LG` - 基于可解释机器学习的选重要特征的带隙准确预测模型 [PDF](https://arxiv.org/pdf/2503.04492), [HTML](https://arxiv.org/abs/2503.04492)
### Authors
Joohwi Lee,Kaito Miyamoto
### Background
在材料信息学的快速发展领域，非线性机器学习模型显示出对材料性质的卓越预测能力。然而，这些模型的黑箱特性限制了它们的可解释性，并可能包含对模型性能并无贡献甚至有负面影响的特征。
### Innovation
本研究利用可解释机器学习（XML）技术，如排列特征重要性和SHapley值方法，应用于专门设计来用18个输入特征在GW水平预测带隙的支持向量回归模型。通过XML提取出的特征重要性，提出了一种简化模型的框架。证明了一个由前五个特征组成的XML指导简化模型，对领域内数据具有与原始模型相当的准确度（0.254 eV vs. 0.247 eV），但对领域外数据的泛化性能更好（0.461 eV vs. 0.341 eV）。此外，研究强调了在应用XML之前消除强相关特征（相关系数大于0.8）的重要性，以防止特征重要性解释上的误解和过度估计。
### Conclusion
研究突出了XML在开发简化且高度精确的机器学习模型中的有效性，通过澄清特征作用从而减少了特征获取的计算成本，并提高了材料发现的模型可信度。
## 732. `cs.LG` - AutoLibra：从开放性人类反馈中提取代理指标 [PDF](https://arxiv.org/pdf/2505.02820), [HTML](https://arxiv.org/abs/2505.02820)
### Authors
Hao Zhu,Phil Cuvin,Xinkai Yu,Charlotte Ka Yee Yan,Jason Zhang,Diyi Yang
### Background
现有的代理评估主要依赖粗略的任务成功度量标准，这些标准需要专家手动设计且未能奖励中间的递进展现行为。AutoLibra 提出了一种框架，将开放性的用户反馈转换为能评估代理轨迹中细粒度行为的度量标准，特别是在被禁止的行为和过于自主的行为方面。
### Innovation
AutoLibra 通过将反馈与代理商行为相关联，将类似的行为进行归类，并创建具有清晰定义和具体示例的具体度量标准，以便用于提示语言模型作为评判者。此外，还提出了两种元度量标准 'coverage' 和 'redundancy' 用于评估度量标准与开放反馈的一致性。通过优化这些元度量标准，实验证明了 AutoLibra 能够诱导出比先前代理评估基准更具体的度量标准，并发现了新的度量标准来分析代理。此外，还展示了 AutoLibra 在代理改进方面的两个应用：首先，帮助人类提示工程师对代理失败进行对角化，并迭代改进提示；其次，能够诱导出自动优化代理的度量标准，使代理商能够自我调控改进。
### Conclusion
实验结果表明，AutoLibra 是一个通用工具，可用于评估和改进语言代理，而无需依赖任务特定的度量标准。
## 733. `cs.LG` - 大型语言模型的模型起源测试 [PDF](https://arxiv.org/pdf/2502.00706), [HTML](https://arxiv.org/abs/2502.00706)
### Authors
Ivica Nikolic,Teodora Baluta,Prateek Saxena
### Background
随着大型语言模型通过微调和其他适应性方法的定制化不断增多，这带来了执行许可条款和管理下游影响的挑战。追踪模型的起源对于保护知识产权以及在发现基础模型中的偏差或漏洞时识别衍生模型至关重要。只有通过黑盒访问模型并采用多重假设检验比较模型相似性来建立基线的统计分析方法来检测这种关系，才能应对这一挑战。这种方法适用于参数从30M到4B多种模型和超过600个模型的综合实时基准测试，展示了即使仅提供API访问，系统性的起源验证也能在生产环境中进行。
### Innovation
该研究提出了一种新的框架——用于测试模型起源的方法，重点在于现实世界的模型衍生会保留显著的输出相似性，这可以通过统计分析识别。该方法仅依赖模型的黑盒访问，采用了多重假设检验来比较模型之间的相似性，同时基于无关模型建立基线。该方法在两种全面的实时基准测试中，识别出90-95%精度和80-90%召回率的衍生模型，验证了在生产环境中没有源代码和内部细节的情况下，系统性验证模型起源的可行性。
### Conclusion
研究表明，在仅有API访问的情况下，可以通过模型起源测试来有效地识别出衍生模型，验证了系统性验证模型起源在生产环境中的可行性。这种方法在大规模模型（从30M到4B参数）中均表现出高精度和召回率，对于保护知识产权和管理大型语言模型的风险具有重要意义。
## 734. `cs.LG` - CAUSAL3D: 一种从视觉数据中进行因果学习的全面基准 [PDF](https://arxiv.org/pdf/2503.04852), [HTML](https://arxiv.org/abs/2503.04852)
### Authors
Disheng Liu,Yiran Qiao,Wuche Liu,Yiren Lu,Yunlai Zhou,Tuo Liang,Yu Yin,Jing Ma
### Background
真智能依赖于发现和利用隐藏因果关系的能力。尽管人工智能和计算机视觉领域已经取得了显著进展，但评估模型从复杂视觉数据中推断潜在因果关系的能力仍缺乏基准。本文介绍了一种新型且全面的基准——Causal3D，它将结构化数据（表格）与相应的视觉表示（图像）相结合，用于评估因果推理能力。Causal3D包括19个3D场景数据集，涵盖了不同的因果关系、视角和背景，以支持复杂场景不同复杂度的评估。
### Innovation
Causal3D是一个新型且全面的基准，它将结构化数据与视觉表示相结合，旨在评估因果推理能力。这些数据集包含了多种多样的3D场景，涵盖了不同的因果关系、视角和背景。这使研究者能够在不同复杂度的场景中评估多方面的最先进的方法，包括传统因果发现、因果表示学习以及大型/视觉-语言模型。实验结果表明，当因果结构变得更加复杂且缺乏先前知识时，性能显著下降，这突显了即使是在复杂的因果情景中，最先进的方法也面临挑战。Causal3D成为CV中因果推理进步的重要资源，也促进了关键领域中可信AI的发展。
### Conclusion
Causal3D为评估和提高从复杂视觉数据中推断因果关系的能力提供了重要的基准，有助于推动可信人工智能的发展。
## 735. `cs.LG` - 通过双重目标优化提高大语言模型安全性对齐 [PDF](https://arxiv.org/pdf/2503.03710), [HTML](https://arxiv.org/abs/2503.03710)
### Authors
Xuandong Zhao,Will Cai,Tianneng Shi,David Huang,Licong Lin,Song Mei,Dawn Song
### Background
现有的基于时间的安全对齐技术在大规模语言模型（LLMs）上仍然容易受到破解攻击的影响。传统的直接偏好优化（DPO）方法在实验和理论上都显示出局限性，其损失函数不适合用于拒绝学习。通过梯度分析，发现这些不足，并提出了改进的安全对齐方法，将DPO目标拆解为两个部分：（1）增强的拒绝训练以及（2）有害知识的针对性去学习。
### Innovation
提出了双重目标优化方法，将DPO目标拆解为两个部分：1）增强的拒绝训练，即使部分不安全的生成也在其中鼓励拒绝；2）有害知识的针对性去学习。这种方法显著增强了LLM在多种破解攻击场景下的鲁棒性，有效提升了对多样化攻击的防护能力。此外，还引入了一种强调关键拒绝标记的方法，通过奖励机制在拒绝学习中进行标记级权重调整，进一步增强了模型的鲁棒性。
### Conclusion
研究指出，破解攻击防御能力与训练过程中的标记分布变化及拒绝和有害标记的内部表示相关，为未来的大规模语言模型安全性对齐研究提供了有价值的指导方向。
## 736. `cs.LG` - 基于深度自编码器的UEBA框架在网络安全威胁检测中的应用 [PDF](https://arxiv.org/pdf/2505.11542), [HTML](https://arxiv.org/abs/2505.11542)
### Authors
Jose Fuentes,Ines Ortega-Fernandez,Nora M. Villanueva,Marta Sestelo
### Background
UEBA是一种广泛的数据分析分支，旨在构建正常的行为模型以检测异常事件。在用于检测异常的技术中，深度自编码器是一种极具前景的深度学习模型，适用于UEBA任务。它能够解释性地检测可能导致敏感个人数据泄漏、系统劫持或访问敏感商业信息的安全事件。已有研究在此基础上进行了探索，但尚未结合文档向量处理方法进行有效的分析与检测。因此，提出了将深度自编码器与Doc2Vec结合使用并处理数值和文本特征的首个可解释的UEBA异常检测框架。
### Innovation
研究首次提出了结合使用深度自编码器和Doc2Vec的UEBA异常检测框架，该框架用于处理数值和文本特征，并能够解释性地检测异常事件。此外，基于人工神经网络的理论基础，首次给出了两个常用的全连接神经网络定义的等价性证明。实验结果显示该框架能够有效检测真实和合成异常，不仅能够正确识别异常，还可以解释异常的来源。研究结果表明，该UEBA框架可以无缝融入企业环境，补充现有的可解释威胁检测系统。
### Conclusion
研究提出的UEBA框架展示了对真实和合成异常的有效检测能力，并且提供了可解释的结果，能够帮助企业更好地理解和处理潜在的安全威胁。实验结果证明了该方法在企业安全系统中的实用性，并为其在实际应用中的推广提供了理论依据。
## 737. `cs.LG` - 二元随机变量中的形式化风险最小化的影响 [PDF](https://arxiv.org/pdf/2502.02331), [HTML](https://arxiv.org/abs/2502.02331)
### Authors
Nikita Tsoy,Ivan Kirev,Negin Rahimiyazdi,Nikola Konstantinov
### Background
形式化现象指的是结果受到预测影响的现象，在具有个体战略性反应的社会背景下尤为常见。Perdomo等人在2020年提出了形式化风险最小化（PRM）的概念，以保证在形式化导致的数据分布变化下，机器学习模型的高准确性。但这个框架却忽略了PRM对底层分布和模型预测的潜在影响。本文旨在分析PRM的影响，针对二元随机变量和线性形式化偏移的序列形式化风险最小化问题进行研究，提出了影响的两个自然度量，并在全信息和部分信息条件下进行了相应的推导和模拟研究。
### Innovation
本文首次分析了形式化风险最小化的影响，并识别出两个自然度量，提供了解公式的PRM解决方案，并在缺乏完全信息的情况下提供了形式化意识统计估计器，以及进行了模拟研究。与此同时，与不考虑数据偏移的替代方法进行了对比，揭示了PRM的潜在副作用被放大了。
### Conclusion
研究对比了形式化风险最小化（PRM）与其他不考虑数据偏移的方法，表明PRM可能会比这些方法具有更大的副作用。根据全信息和部分信息情况下的具体对比研究表明，在某些条件下，PRM可以导致更大的副作用，因此需要进一步考虑其影响机制，以减少潜在的负面影响。
## 738. `cs.LG` - TokenWeave：分布式大规模语言模型推理中的高效计算-通讯重叠 [PDF](https://arxiv.org/pdf/2505.11329), [HTML](https://arxiv.org/abs/2505.11329)
### Authors
Raja Gond,Nipun Kwatra,Ramachandran Ramjee
### Background
分布式推理大规模语言模型（LLMs）会在高带宽互连如NVLink连接的GPU之间引入高达20%的额外开销。尽管提出了一些技术通过细粒度分解计算任务并重叠通信以提高效率，但在GPU上分解大规模计算成许多较小的任务会引入新的开销。通信本身会使用多个流多处理器（SMs），进一步增加了开销。
### Innovation
TokenWeave提出了一种Token-Splitting技术，以波感知方式将推理批次中的标记拆分为两个大致相等的子集，其中一个子集的通信与另一个子集的计算重叠。TokenWeave还优化了层规范化计算的顺序，并实现了一种新颖的融合AllReduce-RMSNorm内核，该内核充分利用了Hopper和BlackwellNVIDIA GPU上的Multimem指令支持。这些优化减少了用于通信和RMSNorm的SMs数量，使内存限制的RMSNorm可以与其他批次的计算重叠进行，带来了额外的收益。该方法在多次模型和工作负载中实现了高达1.29倍的延迟加速和1.26倍的吞吐量提升。在某些情况下，TokenWeave的表现优于移除所有通信的等效模型。
### Conclusion
TokenWeave通过Token-Splitting技术和优化的层规范化计算顺序，以及利用Multimem指令支持的Fused AllReduce-RMSNorm内核，优化了分布式大规模语言模型推理中的计算-通信重叠，提高了速度和吞吐量，并展示了优于仅有计算而无通信的模型的表现。
## 739. `cs.LG` - 通过生成具备侧特征的虚假用户资料欺骗推荐系统 [PDF](https://arxiv.org/pdf/2509.17918), [HTML](https://arxiv.org/abs/2509.17918)
### Authors
Yuanrong Wang,Yingpeng Du
### Background
推荐系统（RS）对用户的消费决策有重大影响，使其成为恶意刷评攻击的首要目标。现有的刷评方法能够在仅包含评分矩阵的训练数据中生成有效的、难以察觉的虚假用户资料，但在利用侧特征的推荐场景中缺乏全面的解决方案。
### Innovation
本文扩展了Leg-UP框架，通过增强生成器架构以整合侧特征，实现了生成具备侧特征意识的虚假用户资料。实验结果表明，该方法在保持隐蔽性的同时实现了强大的攻击性能。
### Conclusion
研究通过提升生成器来融合侧特征，能有效生成能够在包含侧特征的推荐系统中发挥作用的虚假用户资料，为应对现实中的复杂推荐环境提供了新的解决方案。
## 740. `cs.LG` - VeriLLM: 一种轻量级的公共验证去中心化推理框架 [PDF](https://arxiv.org/pdf/2509.24257), [HTML](https://arxiv.org/abs/2509.24257)
### Authors
Ke Wang,Zishuo Zhao,Xinyuan Song,Bill Shi,Libin Xia,Chris Tong,Lynn Ai,Felix Qu,Eric Yang
### Background
去中心化的推理提供了可扩展和鲁棒的大型语言模型（LLMs）推理范式，能够实现分布式资源利用并减少对集中式提供者的依赖。但在无许可环境中，没有可信节点的情况下，确保模型输出的正确性仍是一个核心挑战。
### Innovation
VeriLLM 引入了一种名为 VeriLLM 的轻量级公开验证协议，该协议在单一诚实验证者的假设下实现了安全性，同时保持了实用的效率。VeriLLM 结合了轻量级的经验重跑和加密承诺，使得验证者能够在大约 1% 的基础推理成本下验证结果。为了防止验证瓶颈，设计了一个同构的推理-验证架构，可以在相同的 GPU 工作者之间复用推理和验证角色。这种设计提高了 GPU 利用率和总体吞吐量，扩大了有效的验证者集合，增强了稳健性和活跃性，防止了节点特定的优化或选择性行为。
### Conclusion
通过理论分析和系统级评估，VeriLLM 实现了可靠的公开验证并减少了开销，为可信和可扩展的去中心化 LLM 推理提供了实用的基础。
## 741. `cs.LG` - 使用深度学习探索早期宇宙 [PDF](https://arxiv.org/pdf/2509.22018), [HTML](https://arxiv.org/abs/2509.22018)
### Authors
Emmanuel de Salis,Massimo De Santis,Davide Piras,Sambit K. Giri,Michele Bianco,Nicolas Cerardi,Philipp Denzel,Merve Selcuk-Simsek,Kelley M. Hess,M. Carmen Toribio,Franz Kirsten,Hatem Ghorbel
### Background
氢是宇宙中最丰富的元素。第一代恒星和星系产生的光子使氢气电离，这一事件被称为电离时代（EoR）。即将启用的大尺度阵列射电望远镜（SKAO）将探测和绘制这一时代的中性氢分布，对于研究第一代天体的性质具有重要意义。然而，提取天体物理信息将是一个挑战，因为SKAO将产生大量数据，其中氢信号将受到不必要的前景污染和仪器系统的干扰。为了解决这个问题，我们开发了最新的深度学习技术来从预期来自SKAO的氢信号的2D功率谱中提取信息。
### Innovation
我们应用了一系列神经网络模型来这些测量，并度量它们预测宇宙氢电离历史的能力，这与早期光子源数量和效率的增加有关。结果显示，现代深度学习技术在探测早期宇宙中发挥了重要作用。特别是，我们的专有机器学习算法在恢复电离历史方面的平均$R^2$得分超过0.95，这使得对早期宇宙的宇宙学和天体物理学结构形成进行了准确和精确的推理成为可能。
### Conclusion
早期宇宙的研究得益于现代深度学习技术。特别是，我们展示了专用机器学习算法可以平均获得超过0.95的$R^2$评分，以恢复电离历史。这使得对宇宙结构形成的准确和精确的宇宙学与天体物理学推断成为可能。
## 742. `cs.LG` - FESTA: 功能等价采样在多模态LLM信任评估中的应用 [PDF](https://arxiv.org/pdf/2509.16648), [HTML](https://arxiv.org/abs/2509.16648)
### Authors
Debarpan Bhattacharya,Apoorva Kulkarni,Sriram Ganapathy
### Background
对于多模态大型语言模型（MLLMs）生成的预测，准确的信任评估是一项挑战。这是因为多模态输入的不同范式导致了评估的复杂性。准确的评估能够使预测更具选择性，并提高用户的信心。然而，现有技术难以处理这种多样性的输入方式，因此需要开发新的方法来解决这个问题，以便更好地理解和提高模型预测的信任度。
### Innovation
本文提出了一种名为FESTA（功能等价采样，Functionally Equivalent Sampling for Trust Assessment）的技术，这是一种用于MLLMs的多模态输入采样方法。FESTA通过等价采样（探查一致性）和补充采样（探查敏感性）生成不确定性度量。该方法以无监督方式，仅通过模型的输入-输出访问（黑盒）进行操作，无需真实标签，以此来增强模型输入空间，从而实现信任评估。FESTA技术在视觉和音频推理任务上的实验中显示，对错误预测检测的AUROC曲线下面积有了显著改进，分别提高了33.3％（视觉LLMs）和29.6％（音频LLMs）的预测性能。
### Conclusion
FESTA方法为多模态LLM的信任评估提供了一种新的无监督且黑盒的方式，能够显著提高选择性预测性能，通过对模型预测进行详细的探查，基于AUROC度量有效地提升了检测模型错误预测的能力，且该方法已实现开源。
## 743. `cs.LG` - Holographic Transformers for Complex-Valued Signal Processing: Integrating Phase Interference into Self-Attention [PDF](https://arxiv.org/pdf/2509.19331), [HTML](https://arxiv.org/abs/2509.19331)
### Authors
Enhao Huang,Zhiyu Zhang,Tianxiang Xu,Chunshu Xia,Kaichun Hu,Yuchen Yang,Tongtong Pan,Dong Dong,Zhan Qin
### Background
传统的深度模型通常将注意力机制视为实数相关的形式，忽略了相位干涉效应。复值信号同时包含了振幅和相位信息，但这些信息往往未被充分考虑。因此，现有的模型在处理这类信号时可能无法有效捕获其物理特性，尤其是相位的一致性和干涉效应。
### Innovation
本文提出了Holographic Transformer，这是一种受物理启发的架构，通过引入波干涉原理来增强自我注意力。Holographic注意力通过相对相位进行调制，并通过相干叠加值，确保振幅和相位之间的物理一致性。为了防止在损失倾向于振幅而不是相位时出现相位坍塌，采用了双头解码器同时重构输入和预测任务输出。本文证明了Holographic注意力可以实现离散干涉操作，并在线性混合下保持相位一致性。实验结果表明，Holographic Transformer在极化雷达图像分类和无线信道预测等场景中取得了强大性能，展示了相位一致性的重要性，进而推动了复杂值信号处理的研究。
### Conclusion
实验结果表明，Holographic Transformer在极化雷达图像分类和无线信道预测等场景中取得了强大的性能，证明了在注意力机制中引入物理一致性的有效性，这是一种可用于复杂值信号建模的统一、物理学基础框架。代码可在http://提供的链接中找到。
## 744. `cs.LG` - Neural Atlas Graphs for Dynamic Scene Decomposition and Editing [PDF](https://arxiv.org/pdf/2509.16336), [HTML](https://arxiv.org/abs/2509.16336)
### Authors
Jan Philipp Schneider,Pratik Singh Bisht,Ilya Chugunov,Andreas Kolb,Michael Moeller,Felix Heide
### Background
学习可编辑的高分辨率场景表示对于动态场景是一个开放的问题，具有从自主驾驶到创意编辑等多个领域的应用。目前最成功的方法在编辑性和支持场景复杂性之间进行权衡：神经地图将动态场景表示为两个变形的图像层，前景和背景，这种表示在二维编辑方面是可编辑的，但在多个物体发生遮挡和交互时就会失效。场景图模型则利用自动驾驶数据集中的注释数据（如掩码和边界框）来捕捉复杂的三维空间关系，但由于其隐式的体积节点表示难以进行视图一致的编辑。
### Innovation
我们提出了神经图册图（NAGs），这是一种混合的高分辨率场景表示方法，每个图节点是一个视图依赖的神经地图，既能支持2D外观编辑，又能支持3D场景元素的顺序和位置排列。NAGs在Waymo公开数据集上达到了最新的定量结果，通过5 dB PSNR提升优于现有方法，并在高分辨率和视觉质量下实现环境编辑的能力，创建具有新背景和编辑车辆外观的反事实驾驶场景。我们发现，该方法也适用于超越驾驶场景的其他场景，并在DAVIS视频数据集上，与近期的前景分割和视频编辑基线相比，PSNR数值在多个包含人类和动物的场景中提高了超过7 dB。
### Conclusion
NAGs在动态场景分解和编辑方面提供了一种新的混合表示方法，能够处理从自动驾驶到创意编辑等多个领域的场景。实验结果表明，NAGs能够显著提高场景编辑的准确性和视觉质量，同时还能支持多种类型的场景编辑需求。
## 745. `cs.LG` - RLBFF: 二元灵活反馈以在人类反馈与可验证奖励之间架起桥梁 [PDF](https://arxiv.org/pdf/2509.21319), [HTML](https://arxiv.org/abs/2509.21319)
### Authors
Zhilin Wang,Jiaqi Zeng,Olivier Delalleau,Ellie Evans,Daniel Egert,Hoo-Chang Shin,Felipe Soares,Yi Dong,Oleksii Kuchaiev
### Background
在大语言模型（LLM）的后训练阶段，强化学习与人类反馈（RLHF）和强化学习与验证性奖励（RLVR）是主要的强化学习范式，每种范式都有其独特优势。RLHF 在可解释性和奖赏操纵方面存在局限性，因为它依赖于缺乏明确标准的人类判断。而RLVR则局限于其基于正确性验证者的范围。本研究提出了一种新的强化学习与二元灵活反馈（RLBFF），该方法结合了人类驱动的偏好灵活性与基于规则验证的精确性，使奖赏模型能够捕捉响应质量的复杂方面，而不仅仅是正确性。
### Innovation
本研究提出的RLBFF是一种新的强化学习范式，利用自然语言反馈中的二元原则来训练奖赏模型。这种二元原则可以被回答，例如信息准确性：是，或代码可读性：否。这种原则可以用于将奖赏模型的训练作为蕴含任务。研究表明，这种方式训练的奖赏模型在RM-Bench（86.2%）和JudgeBench（81.4%，排名第一）上表现出优于布雷德利-特里模型的性能。此外，用户可以自定义原则，在推理时调整奖赏模型的焦点。
### Conclusion
本研究展示了使用RLBFF和奖赏模型重新对齐Qwen3-32B方法，使得其在通用对齐基准测试（MT-Bench、WildBench、Arena Hard v2）上的性能至少与o3-mini和DeepSeek R1相当，同时成本仅为后者的5%。所有实验数据和方法均公开可用。
## 746. `cs.LG` - 大规模语言模型中的知识多样性与知识枯竭 [PDF](https://arxiv.org/pdf/2510.04226), [HTML](https://arxiv.org/abs/2510.04226)
### Authors
Dustin Wright,Sarah Masud,Jared Moore,Srishti Yadav,Maria Antoniak,Chan Young Park,Isabelle Augenstein
### Background
大型语言模型（LLMs）倾向于生成在词汇、语义和风格上高度一致的文本，这种一致性会带来知识枯竭的风险，导致可用信息的范围随时间缩小。现有的关于 homogenization 的研究多集中在封闭问答和模糊语义特征上，未能全面考察时间和文化背景中的趋势。因此，本文提出了一种新的方法来测量认知多样性，即LLM输出中现实世界主张的变异情况，并通过实证研究探讨了LLM的知识枯竭现象。
### Innovation
本文创新地提出了一种测量认知多样性的新方法，并通过广泛的研究探讨了该议题。具体包括测试了27种LLM，涵盖了155个话题和200种不同的提示风格。结果显示，尽管新模型生成的主张更为多样，但几乎所有的模型在认知多样性上都不如基本的网络搜索。此外，模型大小对认知多样性有负面影响，而检索增强生成（RAG）则有正面影响，但不同文化背景下RAG的改进效果不同。最后，研究发现，国家特定的主张更多反映英语而非当地语言，揭示了认知表征的缺口。
### Conclusion
本文的研究揭示了认知多样性的变化趋势及其对大规模语言模型知识枯竭的影响，指出虽然一些新模型生成了更加多样化的信息，但其认知多样性仍低于基本的网络搜索。模型大小和检索增强生成对认知多样性有显著影响，而文化背景对RAG的效果有显著影响。同时，也揭示了语言和文化背景下认知多样性缺乏的问题。
## 747. `cs.LG` - 新生儿缺氧缺血性脑病背景下EEG背景模式等级化机器学习竞赛 [PDF](https://arxiv.org/pdf/2509.09695), [HTML](https://arxiv.org/abs/2509.09695)
### Authors
Fabio Magarelli,Geraldine B. Boylan,Saeed Montazeri,Feargal O'Sullivan,Dominic Lightbody,Minoo Ashoori,Tamara Skoric,John M. O'Toole
### Background
机器学习有潜力支持并提高专家在监测易患新生儿大脑功能中的表现。开发准确可靠的机器学习模型需要高质量、标注的数据，而这类数据资源稀缺。机器学习竞赛通过提供专家标注的数据集、直接模型比较以及利用众包多样性专家的益处，解决这一需求，从而促进了研究人员之间的共同学习。
### Innovation
研究者收集了一个回顾性数据集，包含102名新生儿的353小时EEG数据，并匿名化处理后分为训练集、测试集和保留验证集。通过创建一个网络竞赛平台，举办了机器学习竞赛来开发用于新生儿EEG背景模式严重程度分类的模型。竞赛展示了开放访问数据和协作机器学习开发可能促进研究合作环境，并加速临床决策支持工具的发展，特别是在新生儿神经监测领域。
### Conclusion
虽然基于特征的方法在测试数据集上排名第一，但在验证数据集上，深度学习模型有更好的泛化能力。所有方法在验证集上的性能较测试集有显著下降，强调了模型在未见过的数据上的泛化挑战，强调了在具有新生儿EEG的机器学习研究中需要留出验证数据集的重要性。该研究强调了训练机器学习模型时，使用大量和多样的数据以确保稳健泛化的重要性。
## 748. `cs.LG` - Kullback-Leibler 散度下高概率估计离散分布的几乎最小最大估计 [PDF](https://arxiv.org/pdf/2507.17316), [HTML](https://arxiv.org/abs/2507.17316)
### Authors
Dirk van der Hoeven,Julia Olkhovskaia,Tim van Erven
### Background
该研究集中在使用高概率估计大小为K的领域上的离散分布，目标是通过库尔贝-莱布尼兹（Kullback-Leibler，KL）散度来进行估计。研究提供了估计的最小最大估计率的上界和下界，揭示了最优估计率介于（K + ln(K)ln(1/δ)）/n和（Klnln(K) + ln(K)ln(1/δ)）/n之间，误差概率为δ，样本大小为n。这项研究还涉及了几乎最小最大估计率的尾部行为与其他距离度量（如平方总体变异和平方赫尔辛格距离）的比较。进一步的研究结果显示，对于全概率下的库尔贝-莱布尼兹散度，如果排除那些概率小于O(ln(K/δ) / n)的结果，其总变异率是可以实现的。这对理解最大小波雷克-莱布尼兹估计相比逐步近似更为困难的原因提供了新的见解。总体来说，该研究提升了对离散分布估计在KL散度下的理解。
### Innovation
该研究的主要创新在于：1. 提供了库尔贝-莱布尼兹散度下的几乎最小最大估计率的精确上下界，揭示了最优估计率的细节。2. 发现了与总变异率和赫尔辛格距离相比，KL散度的几乎最小最大估计率的尾部行为更差。3. 引入了弱假设检验的新型归约方法。4. 探讨了特定条件下KL散度估计率与总变异率的可实现性差异。这些创新为离散分布的KL散度估计提供了更深入的理解和理论支持。
### Conclusion
研究结论显示，尽管KL散度的最小最大估计率上界和下界之间的差距受到对数因子ln ln K的影响，但它在某些条件下是可以实现的。这一发现不仅提升了对离散分布估计的理解，还揭示了KL散度与其他度量在统计估计领域内的差异，特别是对于小概率事件的敏感性。此工作也指出了进一步研究的方向，特别是在特定假设下更精确地理解KL散度下的估计率等问题。
## 749. `cs.LG` - Think Then Embed: 生成式上下文提高多模态嵌入 [PDF](https://arxiv.org/pdf/2510.05014), [HTML](https://arxiv.org/abs/2510.05014)
### Authors
Xuanming Cui,Jianpeng Cheng,Hong-you Chen,Satya Narayan Shukla,Abhijeet Awasthi,Xichen Pan,Chaitanya Ahuja,Shlok Kumar Mishra,Yonghuan Yang,Jun Xiao,Qi Guo,Ser-Nam Lim,Aashu Singh,Xiangjun Fan
### Background
当前对通用多模态嵌入（UME）的兴趣日益增长，模型需要生成特定任务的表示。虽然最近的研究表明，多模态大型语言模型（MLLMs）在这些任务上表现良好，但它们通常被视为编码器，忽视了它们的生成能力。然而，这种编码范式在指令复杂且需要组合推理时效率较低。受链式思考推理有效性的启发，本文提出了一种通用的Think-Then-Embed（TTE）框架，该框架由一个原因者和一个嵌入器组成。原因者首先生成解释复杂查询的推理轨迹，然后嵌入器基于原始查询和中间推理生成相应的表示。这一明确的推理步骤使得对复杂多模态指令的理解更加深入。
### Innovation
文章通过利用强大的MLLM原因者，实现了在MMEB-V2基准测试中的最新性能表现，超越了使用大规模内部数据集训练的专有模型。同时，为了减少对大型MLLM原因者的依赖，文章使用高质量的嵌入为中心的推理轨迹对较小的MLLM原因者进行微调，实现了开源模型中最佳性能，相较于最近提出的模型有7%的绝对性能提升。此外，文章还研究了将原因者和嵌入器整合到统一模型以提高效率而不牺牲性能的策略。
### Conclusion
文章提出了一种Think-Then-Embed框架，通过利用强大的MLLM原因者和高质量的嵌入为中心的推理轨迹，实现了在多模态嵌入领域的最新性能。同时，还探索了将原因者和嵌入器整合到统一模型中的策略，以提高效率而不影响性能。
## 750. `cs.SE` - 基于过程挖掘的软件开发工作流分析与预测系统 [PDF](https://arxiv.org/pdf/2510.25935), [HTML](https://arxiv.org/abs/2510.25935)
### Authors
Antía Dorado,Iván Folgueira,Sofía Martín,Gonzalo Martín,Álvaro Porto,Alejandro Ramos,John Wallace
### Background
软件开发工作流程中，遵守截止日期是确保项目按时完成的关键。传统的管理方法往往依赖于人工监控和事后分析，效率低下，无法提供及时有效的反馈。为了改进这一状况，CodeSight系统被设计出来，该系统能实时捕获和分析来自GitHub的开发和部署数据，通过过程挖掘转化为详细的分析日志，从而提供有关代码审查活动模式和工作流程效率的可操作见解。
### Innovation
CodeSight系统基于过程挖掘技术，结合机器学习（特别是LSTM模型）来预测代码拉取请求的剩余解决时间。它能够从序列活动轨迹和静态特征中识别潜在的截止日期违规情况，通过对GitHub上的数据进行直接捕获和转换，实现了对软件开发工作流程的实时监控和预测，从而实现项目管理的前瞻性。
### Conclusion
研究结果显示，CodeSight系统在预测截止日期合规方面表现出了高精度和F1分数，证明了过程挖掘与机器学习的集成可以显著提高软件项目管理的效果。这项工作为未来的软件开发工作流的自动管理和优化提供了新的思路和技术支撑。
## 751. `cs.SE` - 基于蒙特卡洛树搜索驱动的强化学习增强RepoQA-Agent [PDF](https://arxiv.org/pdf/2510.26287), [HTML](https://arxiv.org/abs/2510.26287)
### Authors
Guochang Li,Yuchen Liu,Zhen Qin,Yunkun Wang,Jianping Zhong,Chen Zhi,Binhua Li,Fei Huang,Yongbin Li,Shuiguang Deng
### Background
仓库级别的软件工程任务需要大型语言模型（LLMs）能够有效地在复杂代码库中导航和提取信息，通过多轮工具交互来完成。现有的方法存在许多限制，例如无训练的上下文学习方法难以在工具使用和基于环境反馈的决策中有效引导代理，而依赖于更大LLM训练的数据蒸馏方法则在企业环境中会引起数据合规性问题。
### Innovation
提出了一种名为RepoSearch-R1的基于蒙特卡洛树搜索（MCTS）的新型代理强化学习框架。该方法允许代理通过自我训练生成多样且高质量的推理轨迹，而无需模型蒸馏或外部监督。基于此框架，构建了一个专门用于仓库问题回答任务的RepoQA-Agent。全面评估显示，相比无检索方法提高16.0%，相比迭代检索方法提高19.5%，并且训练效率提高33%。冷启动训练方法消除了数据合规性问题，同时保持了在仓库级别推理任务中的强大探索多样性及回答完整性。
### Conclusion
提出的方法在多个方面实现了显著进步，不仅提高了回答的完整性和训练效率，还避免了数据合规性上的担忧，为仓库级别的软件工程任务提供了有效的解决方案。
## 752. `cs.SE` - 软件供应链安全检查清单：适用于关键基础设施的‘4W+1H’ [PDF](https://arxiv.org/pdf/2510.26174), [HTML](https://arxiv.org/abs/2510.26174)
### Authors
Liming Dong,Sung Une Lee,Zhenchang Xing,Muhammad Ejaz Ahmed,Stefan Avgoustakis
### Background
软件供应链攻击的频率和复杂性不断增加，对关键基础设施部门构成了严重的威胁，影响了国家安全、经济稳定和公共安全。尽管意识在增强，现有的安全实践仍然碎片化且不够充分，大多数框架仅专注于供应链生命周期的孤立阶段，或者未能与关键基础设施部门的具体需求对齐。
### Innovation
本文通过多视角文献综述，综合国际框架、澳大利亚监管资源和学术研究，识别并分析软件供应链安全实践，特别是针对关键基础设施领域。提出了一种基于‘4W+1H’分析方法的综合安全实践，并构建了一套包含80个问题的多层安全检查清单，帮助相关利益方评估和加强其软件供应链安全。
### Conclusion
研究发现，现有框架与关键基础设施的具体需求之间存在差距，强调了需要集成、背景意识的策略来保护关键基础设施免受不断演变的软件供应链风险。
## 753. `cs.SE` - 增强软件工程过程和软件产品的生成型人工智能研究路线图 [PDF](https://arxiv.org/pdf/2510.26275), [HTML](https://arxiv.org/abs/2510.26275)
### Authors
Domenico Amalfitano,Andreas Metzger,Marco Autili,Tommaso Fulcini,Tobias Hey,Jan Keim,Patrizio Pelliccione,Vincenzo Scotti,Anne Koziolek,Raffaela Mirandola,Andreas Vogelsang
### Background
生成型人工智能（GenAI）正在迅速改变软件工程（SE）实践，影响软件开发、运营和演化的方式。
### Innovation
本文采用设计科学研究的方法构建了一个GenAI增强SE的研究路线图。该过程包括三个循环，逐步整合多方面的证据，使用麦卢汉的四角模型系统地捕捉GenAI对SE过程和软件的影响。最终识别了四种基本形式的GenAI增强体，并系统地描述了相关研究挑战和机遇，并将这些见解汇总为未来研究方向。通过构建严谨的多循环过程，并在独立作者团队和同行之间进行交叉验证，为分析GenAI如何影响SE的流程、方法和工具提供了一个透明且可重复的基础，并为在这一快速发展的领域内进行未来研究设置了框架。此外，基于这些发现，文章还做出10项关于2030年SE的预测。
### Conclusion
研究提供了关于如何分析GenAI影响SE流程、方法和工具的透明且可重复的基础，并为在这一快速发展的领域内设置未来研究的方向。并且提出了2030年SE的10项预测。
## 754. `cs.SE` - CHCVerif: 基于组合式求解器的约束 horn 子句 [PDF](https://arxiv.org/pdf/2510.26431), [HTML](https://arxiv.org/abs/2510.26431)
### Authors
Mihály Dobos-Kovács(Department of Artificial Intelligence and Systems Engineering, Budapest University of Technology and Economics, Hungary),Levente Bajczi(Department of Artificial Intelligence and Systems Engineering, Budapest University of Technology and Economics, Hungary),András Vörös(Department of Artificial Intelligence and Systems Engineering, Budapest University of Technology and Economics, Hungary)
### Background
约束 Horn 子句 (CHCs) 被广泛应用于各种验证任务中，如安全性检查、不变量合成和跨过程分析。现有的方法通常依赖于专有的验证工具来解决 CHCs，尤其是在涉及位向量和低级语义的情况下，这种方法的适用性有限。
### Innovation
提出了 CHCVERIF，这是一种基于组合求解策略的 CHC 解决器，采用了软件验证的方法来解决 CHCs。这种策略允许我们利用成熟的软件验证工具来处理 CHC 基准测试，特别是在处理位向量和低级语义时更为有效。这种方法在处理线性整数算术问题时取得了中等成功，在位向量基准测试中取得了一定的成功。此外，实验结果表明，使用软件验证工具作为 CHC 求解器的后端是可行的，并且具有一定的潜力，特别是在经过精心构建的组合式求解器支持下。
### Conclusion
CHCVERIF 通过利用软件验证工具作为求解器后端，为 CHC 的求解提供了新的思路。在位向量基准测试和低级语义问题上展现了其可行性和潜力，尽管在处理直线整数算术问题时表现普通。
## 755. `cs.SE` - 通过优先处理潜在的顺序依赖性故障测试减少测试重跑 [PDF](https://arxiv.org/pdf/2510.26171), [HTML](https://arxiv.org/abs/2510.26171)
### Authors
Hasnain Iqbal,Zerina Begum,Kazi Sakib
### Background
自动软件测试因缺陷不可预测的行为而变得不可靠，这类测试在多次运行中可能会在相同的代码基础上通过或失败。尽管这些测试可能导致持续集成（CI）管道失败，但它们通常并不反映任何错误。一种常见的顺序依赖性测试是顺序相关的（OD）测试，其结果取决于它与其他测试用例运行的顺序。尽管已有多项研究探讨了OD测试的检测和修复方法，但这些方法需要多次重新运行与顺序无关的测试，因此很有必要优先处理潜在的OD测试以减少重跑次数。
### Innovation
本文提出了一种方法，用于优先处理可能的顺序依赖性测试。通过分析测试类中的共享静态字段，该方法能够识别出更有可能是顺序依赖性的测试。在对27个项目模块的实验中，该方法在23种情况下成功优先处理了所有OD测试，将其测试执行次数减少了平均65.92%，以及不必要的重跑次数减少了72.19%。这些结果表明，该方法通过降低执行成本显著提高了OD测试检测的效率。
### Conclusion
本文提出的方法能够有效地优先处理可能的顺序依赖性测试，从而减少了测试重跑的次数，显著提高了OD测试检测的效率。这项工作不仅提供了减少开发成本的途径，也为软件测试领域的方法改进做出了贡献。
## 756. `cs.SE` - Nexus: 基于执行的多智能体测试或裁合成 [PDF](https://arxiv.org/pdf/2510.26423), [HTML](https://arxiv.org/abs/2510.26423)
### Authors
Dong Huang,Mingzhe Du,Jie M. Zhang,Zheng Lin,Meng Luo,Qianru Zhang,See-Kiong Ng
### Background
非回归测试中的测试或裁生成一直是软件工程中的长期挑战。其目的是生成能够准确判断被测函数（FUT）在给定输入下是否按预期行为的方法或标准。
### Innovation
Nexus 提出了一种新颖的多智能体框架，通过利用一组多样化的专门智能体来合成测试或裁。这些智能体通过结构化的讨论、验证和迭代自我完善过程来生成或裁。Nexus 在验证阶段生成了 FUT 的候选实现并执行了提议的或裁，针对失败的执行检查，Nexus 激活了自动自我完善循环，使用特定的运行时错误来调试和纠正或裁，然后重新验证。
### Conclusion
在七个不同的基准测试上的广泛评估表明，Nexus 在测试级别的或裁准确性上始终显著优于最先进的基准。例如，Nexus 将 GPT-4.1-Mini 在 LiveCodeBench 上的测试或裁准确性从 46.30% 提高到 57.73%，并且它在下游任务中的改进也得到了明显提高：与基线相比，Nexus 的 GPT4.1-Mini 生成的测试或裁在 HumanEval 中的错误检测率从 90.91% 提高到 95.45%，自动程序修复的成功率也从 35.23% 提高到 69.32%。
## 757. `cs.SE` - SecureReviewer：通过对安全感知微调增强大型语言模型以进行安全代码审查 [PDF](https://arxiv.org/pdf/2510.26457), [HTML](https://arxiv.org/abs/2510.26457)
### Authors
Fang Liu,Simiao Liu,Yinghao Zhu,Xiaoli Lian,Li Zhang
### Background
早期开发周期中识别和解决安全问题对于减少软件系统的长期负面影响至关重要。代码审查作为一种有效的实践，允许开发人员在代码集合并集成到代码库之前检查同伴的代码。为了简化生成审查注释的过程，已经提出了一系列自动代码审查方法，其中基于LLM的方法在自动化审查生成方面取得了显著进展。然而，现有的模型主要关注通用代码审查，它们在识别和解决与安全相关的问题方面的作用仍然没有得到充分探索。此外，将现有的代码审查方法适应针对安全问题也面临重大挑战，包括数据稀缺性和不充分的评估指标。
### Innovation
我们提出了SecureReviewer，一种专为增强LLMs在代码审查中识别和解决与安全相关的问题的能力而设计的新方法。首先，我们构建了一个专门用于培训和评估安全代码审查能力的数据集。通过此数据集，我们对LLMs进行了微调，以生成可以有效地识别安全问题并提供修复建议的审查注释，同时采用我们提出的安全感知微调策略以增强其实用性和质量。此外，我们引入了SecureBLEU，这是一种新的评估指标，用于评估审查注释在解决安全问题方面的有效性。实验结果显示，SecureReviewer在安全问题检测准确性和生成的审查注释的整体质量和实用价值方面均优于最先进的基线。
### Conclusion
我们的实验表明，SecureReviewer在安全问题检测准确性和生成的审查注释的整体质量和实用性方面显著优于先进的基准模型。通过对不安全代码的显著减少，SecureReviewer有望提高软件系统的安全性和可靠性。
## 758. `cs.SE` - 超越合成基准：评估LLM在真实世界类级代码生成中的性能 [PDF](https://arxiv.org/pdf/2510.26130), [HTML](https://arxiv.org/abs/2510.26130)
### Authors
Musfiqur Rahman,SayedHassan Khatoonabadi,Emad Shihab
### Background
大规模语言模型（LLMs）已经提高了功能级别的代码生成，但在真实软件项目中的类级实现正确性方面的能力仍然不甚了解。本文通过一个基于开源代码库的新基准，将实际的类分为已见和未见的分区，来评估在实际条件下的泛化能力，检查在不同输入规格、检索增强配置和文档完整程度下的多种LLM的表现。研究结果表明，LLMs在现有合成基准上的正确率为84%到89%，但在真实世界的类级任务中，正确率仅为25%到34%。这表明现有的LLMs在处理实际代码时存在显著差距。
### Innovation
本文开发了一个基于开源代码库的新基准，将实际的类划分为已见和未见的分区，以评估LLMs在实际条件下的泛化能力，通过实际条件下的综合文档字符串、检索增强编码以及不同文档完整程度对LLMs进行了评估。研究表明，检索增强编码在部分文档中最为有效，通过提供具体的实现模式可以提高正确性4%到7%。同时，研究还识别了AttributeError、TypeError和AssertionError为主要故障模式，强调了合成测试和实际场景的关键区别。
### Conclusion
基准和分析揭示了当前LLMs在类级工程方面的关键局限，为增强上下文建模、文档策略和检索集成以提高生产代码辅助工具的效果提供了实用见解。此外，发现检索增强在逻辑错误减少方面效果显著，但也可能引入依赖冲突，这为未来的研究方向提供了路径。
## 759. `cs.SE` - CI/CD管道的环境影响 [PDF](https://arxiv.org/pdf/2510.26413), [HTML](https://arxiv.org/abs/2510.26413)
### Authors
Nuno Saavedra,Alexandra Mendes,João F. Ferreira
### Background
尽管CI/CD管道在软件开发中广泛应用，开发人员仍不清楚其环境影响，特别是碳足迹和水足迹。随着云端计算环境影响的增加，了解CI/CD服务的环境足迹变得越来越重要。本文探讨了使用GitHub Actions的环境足迹，特别是在开源仓库中，GitHub Actions的常规运行器使用是免费且不限量的。本研究基于从文献中报告的最大数据集，包含超过220万个工作流运行，涉及超过18000个仓库。研究表明，GitHub Actions生态系统导致显著的环境足迹。预计2024年的碳足迹在最乐观和最悲观的情况下分别为150.5 MTCO2e和994.9 MTCO2e，水足迹则分别为1,989.6和37,664.5千升。最有可能的情况下的碳足迹估计为456.9 MTCO2e，水足迹约为5,738.2千升。这些数字按年计算相当于7,615棵城市树木的碳吸收量，以及一个典型的美国家庭5,053年的用水量。研究表明，通过减少计算资源的浪费，可以缓解这一影响。建议包括：部署在能源生产对环境影响较低的地区（如法国和英国）的运行器；实施更严格的定期运行停用策略；并让它们的执行与地区能源混合更环保的时期相吻合；以及减小程序库的大小等方法。这些策略有助于减少CI/CD流程对环境的影响。
### Innovation
本文采用的方法是基于云端碳足迹框架，使用迄今为止最大的工作流运行数据集。方法创新之处在于采用了具体且可观测的数据集，通过实证分析估计了CI/CD管道的环境足迹，并提出了具体的环境优化策略，填补了该领域的研究空白。
### Conclusion
GitHub Actions的碳足迹在最有可能的情况下为456.9 MTCO2e，相当于每年7,615棵城市树木的碳吸收量，水足迹约为5,738.2千升。通过策略包括部署环保地区运行器、实施更严格的停用策略以及优化能源使用等方式，可以有效减少CI/CD流程的环境影响。
## 760. `cs.SE` - 反思大型语言模型时代软件工程研究中的实证与可持续性方面 [PDF](https://arxiv.org/pdf/2510.26538), [HTML](https://arxiv.org/abs/2510.26538)
### Authors
David Williams,Max Hort,Maria Kechagia,Aldeida Aleti,Justyna Petke,Federica Sarro
### Background
SE 研究利用 LLM 引入了验证严谨性、污染、可复制性和可持续性等方面的诸多挑战。本文通过反思这些挑战在SE中的应对方式，提供了一个结构化的ICSE中LLM基SE研究的概述，指出当前的积极实践和持续不足。
### Innovation
该论文提出了一种结构化的方法来总结ICSE中LLM基SE研究的现状，强调了加强验证严谨性、提高可复制性和解决LLM基SE的经济和环境成本的建议。
### Conclusion
论文总结了目前LLM在SE研究中所述的实践和不足，并提出了增强验证严谨性、提高可复制性和解决经济和环境成本的建议。
## 761. `cs.SE` - 自然语言驱动未来交互式Web开发愿景：通过自然语言编辑网页 [PDF](https://arxiv.org/pdf/2510.26516), [HTML](https://arxiv.org/abs/2510.26516)
### Authors
Truong Hai Dang,Jingyu Xiao,Yintong Huo
### Background
网页应用程序的进化依赖于迭代的代码修改，这个过程通常是由人工手动完成且耗时。尽管大型语言模型（LLMs）能够生成用户的界面代码，但在根据新的设计要求（例如，“使Logo居中”）编辑现有代码时，其能力仍是一个挑战。这主要是因为缺乏足够的大规模高质量调优数据来使模型的表现与人类期望更好地对齐。因此，本文主要探讨了如何利用大型语言模型生成高质量的调优数据集以解决代码编辑中的自然语言指令问题。
### Innovation
本文提出了一种全新的自动化数据生成管道，该管道使用大型语言模型（LLMs）来合成高质量的微调数据集，名为Instruct4Edit。该方法能够生成多样的指令，应用相应的代码修改，并通过视觉验证来保证正确性。通过在Instruct4Edit上微调模型，研究展示了将人类意图精准且结构化地转化为代码更改的一致性改进。此外，该研究提出了一个可扩展且透明的自然语言驱动的网页编辑基础，表明微调小型开源模型可以获得与专有系统相当的性能。论文还发布了所有数据、代码实现以及模型检查点以供重复使用。
### Conclusion
本文提供了一种可扩展和透明的基础架构，证明了使用微调较小的开源模型实现自然语言驱动的网页编辑可以达到与专有系统相当的性能。
## 762. `cs.SE` - 使用开源大语言模型进行自动化提取方法重构：一项比较研究 [PDF](https://arxiv.org/pdf/2510.26480), [HTML](https://arxiv.org/abs/2510.26480)
### Authors
Sivajeet Chand,Melih Kilic,Roland Würsching,Sushant Kumar Pandey,Alexander Pretschner
### Background
提取方法（EMR）重构对于提高代码可读性和可维护性至关重要，但仍然面临挑战，主要依赖手动操作。近年来，开源和资源高效的大型语言模型（LLMs）的进步为这种高级任务的自动化提供了新的可能。本研究评估了五个最先进的开源LLM模型在Python代码中的EMR任务表现，通过系统地评估功能正确性和代码质量，探索不同提示策略的效果，并得出了一致的结论。应用程序的传统度量标准如循环复杂度（CC）和代码行数（LOC）虽然具备一定的参考价值，但往往与人类判断不一致，强调了人工在循环评估中的必要性。这项开源基准为未来使用LLM的自动化重构研究奠定了基础。
### Innovation
本研究通过系统性评估方式，使用最新的提示策略（如递归批评与改进方法），比较了一次性提示和递归批评与改进（RCI）方法的效果。研究表明，基于RCI的提示策略在测试通过率和重构质量方面表现更优。研究还展示了最佳模型在保持重构质量的同时，显著减少了代码行数和循环复杂度，开发人员对基于RCI生成的重构代码接受度高达70%以上。通过对模型进行基于高质量提示的自动重构，使用LLM方法能够显著提升代码的可读性和可维护性。
### Conclusion
通过对多个开源LLM模型的评估和对不同提示策略的比较，研究认为基于高质量提示的自动化重构方法具有显著优势。使用最佳模型（Deepseek-Coder-RCI和Qwen2.5-Coder-RCI）进行重构，不仅保持了较高的测试通过率，还极大减少了重构所需代码行数和循环复杂度。这些模型显著提高了代码的可读性和可维护性，表明基于提示的自动重构策略能够有效提升代码质量。将来的研究将进一步探索如何提高自动化重构的质量和效率，并采用更复杂的人机协作模型。
## 763. `cs.SE` - Maven-Hijack: 软件供应链攻击利用包的顺序 [PDF](https://arxiv.org/pdf/2407.18760), [HTML](https://arxiv.org/abs/2407.18760)
### Authors
Frank Reyes,Federico Bono,Aman Sharma,Benoit Baudry,Martin Monperrus
### Background
Java项目常依赖Maven等包管理器来管理复杂的外部依赖关系。这些工具虽然方便了开发，但也引入了对软件供应链的潜在风险。攻击者可以通过在编译顺序上做文章，并利用Java虚拟机在运行时解析类的方式，注入恶意代码，从而在不修改主代码或库名的情况下，秘密覆盖应用的核心行为。本文通过攻击广泛使用的开源COVID-19接触追踪系统Corona-Warn-App，展示了这种攻击在现实世界中的可行性。为了减轻这种攻击风险，作者评估了几种缓解策略，研究表明，Maven Enforcer插件的重复类检测功能是最实用有效的防御措施，目前已有的Java项目可以依赖这一手段来提高安全性。
### Innovation
提出了Maven-Hijack攻击，它针对Maven依赖管理和Java虚拟机运行时类解析机制的弱点，通过在编译顺序上的巧妙利用，注入恶意代码，控制应用行为。这种方法可以在不修改主代码或库名的情况下，秘密地改变应用的核心功能，这为开发团队提供了新的攻击面和威胁模型。此外，它还提出了三种缓解这种新型攻击的技术策略：密封JAR包、Java模块和Maven Enforcer插件，并评估了它们的效果。
### Conclusion
Maven Enforcer插件的重复类检测功能在当前的Java项目环境中提供了最实用有效的防护，而Java模块机制则提供了最强的保护效果。本文的研究强调了需要改进Java构建和依赖管理流程中的安全措施，以防止隐蔽的供应链攻击。
## 764. `cs.SE` - LLM ensembles for code generation and repair的智慧与幻觉 [PDF](https://arxiv.org/pdf/2510.21513), [HTML](https://arxiv.org/abs/2510.21513)
### Authors
Fernando Vallecillos-Ruiz,Max Hort,Leon Moonen
### Background
目前追求一个单一的大语言模型来完成所有软件工程任务既耗资源又忽视了不同模型互补性的潜在利益。虽然编码大语言模型之间如何互补以及如何最大化组合模型潜力的方法尚不清楚，但从业者缺乏明确的路径来超越单模型系统。本文通过比较十个来自五个家族的个体大语言模型以及这些模型的三种不同组合，在三个涵盖代码生成和程序修复的软件工程基准测试中进行实证研究，以填补这一空白。
### Innovation
研究 empirically 比较了多个个体大语言模型及其组合的性能，并评估了它们之间的互补性以及最佳个体模型与组合模型之间的性能差距。此外，研究还评估了不同的选择准则，以从组合模型的候选集中选出正确解。研究发现，组合模型的性能理论上限可比最佳单模型高出83%。多样性为基础的选择策略可以实现这一理论潜力的95%，甚至在小型双重组合模型中也能有效运作，这为通过利用多个大语言模型提高性能提供了一种成本效益高的方法。
### Conclusion
组合模型的性能理论上限可比最佳单模型高出83%，多样性的选择策略能够实现这一潜力，甚至在小型模型组合中也有效，这为利用多个大语言模型提升了性能提供了一种低成本方式。
## 765. `cs.SE` - CodeWiki：评估AI生成大规模代码库综合文档的能力 [PDF](https://arxiv.org/pdf/2510.24428), [HTML](https://arxiv.org/abs/2510.24428)
### Authors
Anh Nguyen Hoang,Minh Le-Anh,Bach Le,Nghi D. Q. Bui
### Background
在大型且不断演化的代码库中，自动生成全面且架构感知的文档仍然是一个开放的挑战。这种文档不仅需要涵盖单个函数，还需要捕捉跨文件、跨模块和系统级别的交互。综合文档对于长期软件维护和合作至关重要，但当前的自动化方法仍然无法准确建模定义现实软件系统的丰富的语义依赖性和架构结构。因此，需要一个能够全面生成这种文档的统一框架来解决这个问题。
### Innovation
CodeWiki框架通过三个创新点解决上述问题：（i）层次分解以在多个粒度层次中保留架构上下文；（ii）递归多智能体处理以实现可扩展的生成；（iii）多模态合成，将文本描述与架构图和数据流表示等视觉元素集成。此外，CodeWikiBench基准测试提供了多维度评估标准和基于LLM的评估协议，以确保评估的准确性。实验结果显示，CodeWiki在自定义模型上取得了68.79%的质量分数，优于商业闭源的DeepWiki基准（64.06%），尤其在高级脚本语言上表现突出，提升了10.47%。
### Conclusion
CodeWiki是一个统一框架，用于跨七种编程语言的自动生成仓库级别的文档，它显著提高了高质量文档的生成能力，特别是在高阶脚本语言方面的表现更为出色。CodeWiki被开源以促进未来的研究和社区的采用。
## 766. `cs.SE` - Dissect-and-Restore: 基于重构的AI辅助代码验证 [PDF](https://arxiv.org/pdf/2510.25406), [HTML](https://arxiv.org/abs/2510.25406)
### Authors
Changjie Wang,Mariano Scazzariello,Anoud Alshnakat,Roberto Guanciale,Dejan Kostić,Marco Chiesa
### Background
形式化验证已逐渐被视为构建可靠软件系统的关键基础。然而，编写精确规范、处理复杂的证明义务以及学习注释所需的特殊专业知识通常会使验证比实现成本高出一个数量级。尽管现代AI系统可以识别数学证明中的模式并解释自然语言，但将它们有效地集成到形式化验证过程中的挑战仍然存在。针对此问题，我们提出了一种名为Prometheus的AI辅助新系统，结合最新的AI能力和模块化软件工程原则（如模块化重构）来实现自动代码验证。我们的方法初始步骤是将复杂的程序逻辑（如嵌套循环）分解为更小的、可验证的组件，然后验证这些组件并重组以证明原始程序。这一拆分与重组的工作流具有挑战性，Prometheus通过引导证明搜索，通过结构化地将复杂引理分解成更小、可验证的子引理来解决这一问题。在自动化工具不足时，用户提供轻量级的自然语言指导可有效引导证明过程。因此，通过模块化重构临时应用代码显着提高了AI在验证单个组件有效性方面的效果。我们的评估显示，与基线相比，该方法成功验证了86%的任务，而基线仅为68%。其增益随着规范复杂性的增加愈加显著，从30%提高至69%，并且在结合复杂程序的证明大纲时，从25%提高至87%。
### Innovation
提出了一种名为Prometheus的新系统，结合最新的AI能力和模块化软件工程原则来实现自动代码验证。该系统通过将复杂的程序逻辑分解为更小的、可验证的组件，并通过结构化地将复杂引理分解成更小、可验证的子引理来引导证明搜索，解决了自动化工具不足时的挑战。一种新的方法提高了AI辅助验证的有效性，特别是在处理复杂规范和结合证明大纲的情况下，验证成功率显著提高。
### Conclusion
通过模块化重构临时应用，我们的方法成功验证了86%的任务，相比之下基线为68%。这一方法在复杂规范和结合证明大纲时表现尤为明显，验证成功率从30%提高至69%，并进一步提高至87%。
