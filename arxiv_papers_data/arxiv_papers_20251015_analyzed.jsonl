{"llm_update_time": "20251015", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.12015", "html_url": "https://arxiv.org/abs/2510.12015", "title": "使用大型语言模型进行偏好征询时的提问", "title_en": "Asking Clarifying Questions for Preference Elicitation With Large Language Models", "authors": "Ali Montazeralghaem,Guy Tennenholtz,Craig Boutilier,Ofer Meshi", "background": "大型语言模型（LLMs）使得推荐系统能够通过开放式的对话界面与用户互动。为了个性化LLMs的回答，尤其是当用户的历史数据有限时，提取用户偏好至关重要。一种方法是向用户提供澄清性提问，但生成有效的跨领域澄清性提问仍然具有挑战性。", "innovation": "本文提出了一种新颖的方法，用于训练LLMs以顺序提问以揭示用户偏好。方法基于扩散模型，分为两个阶段：首先从前向过程生成澄清性问题以获取答案，并逐步去除这些答案以“添加噪声”到用户资料；其次，反向过程涉及训练模型“去噪”，通过学习有效提问以重建用户资料。", "conclusion": "我们的方法显著提高了LLMs提问漏斗问题并有效征询用户偏好方面的技巧。"}
{"llm_update_time": "20251015", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.12061", "html_url": "https://arxiv.org/abs/2510.12061", "title": "增强LLM代理的空间意识：迈向基于空间背景的野火应对推理", "title_en": "Empowering LLM Agents with Geospatial Awareness: Toward Grounded Reasoning for Wildfire Response", "authors": "Yiheng Chen,Lingyao Li,Zihui Ma,Qikai Hu,Yilun Zhu,Min Deng,Runlong Yu", "background": "有效的灾害响应对于保护生命和财产至关重要。现有的统计方法往往缺乏语义背景，难以跨事件泛化，并提供了有限的可解释性。大型语言模型（LLMs）能够实现少样本泛化，但仍然局限于文本信息，并且无法理解地理数据。因此，存在一个亟待解决的问题：如何将空间感知集成到灾害响应系统的代理中。", "innovation": "为了弥合这一差距，本文引入了一种空间感知层（GAL），通过将代理与结构化的地基数据进行关联，赋予了代理空间背景。该框架从原始野火检测开始，自动检索并整合基础设施、人口统计、地形和天气信息，形成简明且标注单位的感知脚本。增强的上下文使得代理能够生成基于证据的资源分配建议（例如，人员分配和资金分配），并通过历史类比和日常变化信号进行逐步更新。这一方法在多个LLM模型的多种野火场景中进行了评估，表明具有空间背景的代理能够优于基准模型。", "conclusion": "所提出的方法能够泛化到其他灾害类型，如洪水和飓风。"}
{"llm_update_time": "20251015", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.12033", "html_url": "https://arxiv.org/abs/2510.12033", "title": "CausalTrace: 智能制造中的一种神经符号因果分析代理", "title_en": "CausalTrace: A Neurosymbolic Causal Analysis Agent for Smart Manufacturing", "authors": "Chathurangi Shyalika,Aryaman Sharma,Fadi El Kalach,Utkarshani Jaimini,Cory Henson,Ramy Harik,Amit Sheth", "background": "现代制造环境需要准确的预测以及易于解释的理解，以处理过程异常、根本原因及潜在干预措施。现有AI系统常作为孤立的“黑箱”运行，缺乏将预测、解释和因果推理无缝整合的能力，这限制了它们在高风险工业环境中的可信度和实用性。", "innovation": "我们提出了CausalTrace，一个集成于SmartPilot工业CoPilot中的神经符号因果分析模块。CausalTrace利用工业本体和知识图进行数据驱动的因果分析，具备因果发现、反事实推理和根本原因分析等功能，支持实时操作人员交互，并通过提供透明的可解释性决策支持来补充现有代理。全方位评估CausalTrace使用多种因果评估方法和C3AN框架（即神经符号整合的定制、紧凑、复合AI）展现了其在鲁棒性、智能和可信度方面的性能。", "conclusion": "在学术火箭装配试验环境中的综合评估显示，CausalTrace在领域专家评估（ROUGE-1得分为0.91，在本体问答中的一致性）和根本原因分析性能方面表现出色（MAP@3：94%，PR@2：97%，MRR：0.92，Jaccard：0.92）。该系统在C3AN评估中得分4.59/5，证明了其在实际部署中的精准性和可靠性。"}
{"llm_update_time": "20251015", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.11985", "html_url": "https://arxiv.org/abs/2510.11985", "title": "CGBench: 用于临床遗传学研究的语言模型科学推理基准", "title_en": "CGBench: Benchmarking Language Model Scientific Reasoning for Clinical Genetics Research", "authors": "Owen Queen,Harrison G. Zhang,James Zou", "background": "背景变异和基因解读是个性化医学和转化生物医学的基础。然而，传统方法手动且劳动密集型。生成语言模型（LMs）可以促进这一过程，加速基础研究向临床可行动洞察的转化。虽然现有的基准试图量化LMs解释科学数据的能力，但这些研究集中在狭窄的任务上，无法转化为实际研究。为应对这些挑战，作者引入了CGBench，这是一个稳健的基准，用于测试语言模型在科学出版物上的推理能力。CGBench基于ClinGen，这是一个由专家绘制的临床遗传学文献解释资源。", "innovation": "创新CGBench是一个经过验证的基准，用于测试语言模型在科学文献上的推理能力。它从ClinGen（一个专家绘制的临床遗传学文献解读资源）构建而成。CGBench测试了8种不同的LMs，并发现模型在文献解读方面存在显著差距，特别是在细微指令方面。理性模型在精细任务中表现出色，而非理性模型在高层次解读中更胜一筹。此外，作者还用LM判断方法测量了LM解释与人类解释之间的差异，揭示了即使正确分类证据，模型也会出现幻觉或误解结果的情况。", "conclusion": "结论CGBench阐明了语言模型在精确解释科学出版物方面的能力和局限性，为AI在临床遗传学和更广泛的科学中的未来研究开辟了途径。"}
{"llm_update_time": "20251015", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.12063", "html_url": "https://arxiv.org/abs/2510.12063", "title": "ThinkPilot: 通过自动优化思考前缀引导推理模型", "title_en": "ThinkPilot: Steering Reasoning Models via Automated Think-prefixes Optimization", "authors": "Sunzhu Li,Zhiyu Lin,Shuling Yang,Jiale Zhao,Wei Chen", "background": "大型推理模型（LRMs）尽管强大，但在推理过程中仍然存在低效和偏离目标的问题。目前，无需训练的方法要么依赖僵硬的启发式规则，要么提供描述性的、不可操作的分析。本文背景在于探索一种无需训练的框架——ThinkPilot，它可以自动优化LRMs的推理。它采用进化过程生成思考前缀，这些前缀可以根据推理行为的分类进化，从而引导模型向更优的表现转变。", "innovation": "ThinkPilot 通过引入自动优化思考前缀的方法，自动优化大型推理模型的推理过程。它使用进化过程生成思考前缀，这些前缀基于推理行为的分类进化，以指导模型向更优表现转变。这种方法显著提升了模型在有效推理中的准确性和效率，大幅提高了模型的安全性，并增强了指令遵循能力。它还可以与现有的基于训练的方法协同工作。通过自动识别和诱发特定的行为分布，ThinkPilot 提供了一种普遍适用的框架，以使大型推理模型的推理与任务需求相一致。", "conclusion": "实验表明，自动优化的思考前缀能够可靠地控制大型推理模型的推理行为，并且不同的任务对特定行为的分布有强烈偏好。通过自动识别和激发这些行为，ThinkPilot 提供了一种通用框架，来使大型推理模型的推理与任务需求相一致。该研究的方法和代码已经在相关链接中公开，为未来研究提供了宝贵的资源。"}
{"llm_update_time": "20251015", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.11736", "html_url": "https://arxiv.org/abs/2510.11736", "title": "Dhumbal纸牌游戏中的AI代理：一项比较研究", "title_en": "AI Agents for the Dhumbal Card Game: A Comparative Study", "authors": "Sahaj Raj Malla", "background": "本研究通过系统比较基于规则、搜索和学习的方法，评估了人工智能代理在Dhumbal纸牌游戏中的表现。Dhumbal是一种在不完全信息下进行的多玩家卡牌游戏，具有重要的文化意义。研究通过构建Dhumbal的规则和实现多种策略，如启发式方法（攻击性、保守性、平衡性、机会主义）、搜索方法（蒙特卡洛树搜索、信息集蒙特卡洛树搜索）和强化学习方法（深度Q网络、策略梯度优化），以及随机基线来评估这些代理。评估过程包括在同一类别中的比赛以及跨类别的冠军赛。", "innovation": "本研究创新之处在于首次系统地将基于规则、搜索和学习的方法应用于Dhumbal这个游戏，提供了在不完全信息下的启发式方法的有效性见解，并通过强度归一化t检验、Cohen’s d效应大小计算和95%置信区间，确保了评估的科学性。此外，研究还提供了一个可重复的AI框架和开源代码。", "conclusion": "基于规则的攻击性代理在模拟的1024个回合中表现出最高的胜率（88.3%，95%置信区间：[86.3, 90.3]），这表明在利用声明方面有效利用了不完全信息。研究为AI研究领域提供了有价值的贡献，并支持了文化游戏的数字化保存。"}
{"llm_update_time": "20251015", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.12066", "html_url": "https://arxiv.org/abs/2510.12066", "title": "AI代理作为通用任务解决者", "title_en": "AI Agents as Universal Task Solvers", "authors": "Alessandro Achille,Stefano Soatto", "background": "现有的AI推理代理能够通过部署工具、模拟多种假设的结果并自我反思来执行各种任务，尽管这些过程不是在传统意义上进行编程时的计算。研究者们开始质疑是否AI代理可以是通用的，并探究链式思维推理是否可以解决任何计算任务。此外，研究还探讨了AI代理如何学习推理，是基于模型大小还是训练数据集大小。基于这一背景，本研究重新定义了在AI代理背景下的学习角色，并强调时间在学习推理中的基础原则。", "innovation": "本研究将AI代理重新解释为具备计算能力的随机动力系统，并提出了从经典归纳学习向转导学习的转变。转导学习强调时间和减少解决新任务所需时间的重要性，而不是仅仅减少重构误差。此外，研究展示了一种理论推导，解释了推理时间和训练时间之间的幂律膨胀关系，并指出在对标记数据进行大规模建模时，虽然可以在基准测试上提高准确性，但并不能进行真正智能或超智能的学习。优化推理模型规模的关键应该是时间，而非仅仅依赖于模型大小和训练数据集大小。", "conclusion": "研究强调了在优化推理模型规模时时间的重要性，而非仅仅依赖于模型大小和训练数据集大小。大规模的模型在无限的空间和时间中可能会表现出类似天才的行为，但缺乏洞察力，真正的智能在于通过算法结构减少解决问题所需的时间。"}
{"llm_update_time": "20251015", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.11977", "html_url": "https://arxiv.org/abs/2510.11977", "title": "全貌智能代理排行榜：智能代理评估所需的缺失基础设施", "title_en": "Holistic Agent Leaderboard: The Missing Infrastructure for AI Agent Evaluation", "authors": "Sayash Kapoor,Benedikt Stroebl,Peter Kirgis,Nitya Nadgir,Zachary S Siegel,Boyi Wei,Tianci Xue,Ziru Chen,Felix Chen,Saiteja Utpala,Franck Ndzomga,Dheeraj Oruganty,Sophie Luskin,Kangheng Liu,Botao Yu,Amit Arora,Dongyoon Hahm,Harsh Trivedi,Huan Sun,Juyong Lee,Tengjun Jin,Yifan Mai,Yifei Zhou,Yuxuan Zhu,Rishi Bommasani,Daniel Kang,Dawn Song,Peter Henderson,Yu Su,Percy Liang,Arvind Narayanan", "background": "AI代理已经在从编程到客户服务等多种复杂的现实世界任务中得到了开发。然而，这些代理的评估面临着许多挑战，这些挑战会阻碍我们深入了解它们实际表现得如何。为了应对这些挑战，作者引入了全貌代理排行榜（HAL）来解决这些难题。", "innovation": "作者作出了三项主要贡献。首先，提供了一个标准化的评估框架，能够协调数百个虚拟机上的并行评估，将评估时间从几周缩短到几小时，同时消除了常见的实现错误。其次，进行跨模型、支架和基准的三维分析。通过在编程、网络导航、科学和客户服务等领域进行21,730次代理的评估，验证了框架的有效性。分析揭示了许多令人惊讶的洞察，如在多数情况下较高的推理努力会降低准确性。最后，使用LLM辅助的日志检查发现了以前未报告的行为，如在HuggingFace上搜索基准而不是解决任务，或者在航班预订任务中滥用信用卡。作者分享了所有的代理日志，总计约25亿语言模型调用语，并鼓励进一步研究代理行为.", "conclusion": "通过标准化智能代理评估的方法，并解决代理评估中的常见问题，作者希望将注意力从擅长基准的代理转移到在现实世界中可靠工作的代理上。"}
{"llm_update_time": "20251015", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.12047", "html_url": "https://arxiv.org/abs/2510.12047", "title": "大型语言模型会遵守合约吗？评估和强制执行代码生成中的合约一致性", "title_en": "Do Large Language Models Respect Contracts? Evaluating and Enforcing Contract-Adherence in Code Generation", "authors": "Soohan Lim,Joonghyuk Hahn,Hyunwoo Park,Sang-Ki Ko,Yo-Sub Han", "background": "当前广泛使用的代码生成基准，如HumanEval+和MBPP+主要通过功能正确性来评估大型语言模型（LLMs），使用良好的输入数据进行pass@k测试。然而，这些基准忽略了现实中的一个重要方面：合约遵守问题，即预条件和有效性约束，这些约束规定了如何拒绝无效输入。这种忽视导致现有的基准无法衡量模型生成真正稳健和可靠的代码片段。", "innovation": "为了填补这一空白，作者引入了PACT框架，该框架旨在系统性地评估和提升LLM生成代码片段中的合约遵守度，同时保持功能正确性。PACT的贡献包括三个方面：首先，它提供了一个涵盖合约违规的全面测试套件数据库，扩展了HumanEval+和MBPP+；其次，它允许在不同提示条件下系统地分析代码生成，证明与仅使用合约描述相比，结合合约违规测试案例显著提高了模型遵守合约的能力；最后，它引入了新的度量标准，以严格量化合约遵守度，无论是测试生成还是代码生成。", "conclusion": "PACT揭示了传统基准测试忽略的关键错误，提供了严格的可解释度量标准来评估LLM生成代码片段的功能性和这一 http URL的鲁棒性。相关数据和代码可访问 https://this.http.URL/code_and_data."}
{"llm_update_time": "20251015", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.11822", "html_url": "https://arxiv.org/abs/2510.11822", "title": "超越共识：缓解LLM法官评估中的和顺偏差", "title_en": "Beyond Consensus: Mitigating the Agreeableness Bias in LLM Judge Evaluations", "authors": "Suryaansh Jain,Umair Z. Ahmed,Shubham Sahai,Ben Leong", "background": "近年来大模型（LLMs）不断更新，要求现代应用开发者需决定是否转换到新的模型。人工评估虽然标准，但成本高且不具扩展性。现有的最高标准是使用LLMs作为评估者（LLM-as-a-judge），但这种方法存在严重偏差：LLMs倾向于过度肯定结果。具体表现为，尽管LLMs能以高准确率（96%真实阳性率）识别有效的输出，但在识别无效输出（真实阴性率<25%）方面表现糟糕。因此，即使结合多种模型的方法如多数投票（majority voting）也未能有效解决此问题，引入的少数否决策略（minority-veto strategy）可以部分防止数据缺失带来的影响。为提升进一步的精确度，提出了一种新型回归框架，该框架利用少量的人工标注数据直接建模验证者的偏差。在一项具有挑战性的编程反馈任务中，该方法将最大绝对误差降至1.2%，相对于14种最佳LLMs集成实现了2倍的改进。", "innovation": "提出了少数否决策略和基于回归的新型框架来缓解LLMs评估中的和顺偏差。少数否决策略能够较好地应对数据丢失的情况，优于一般多数投票方法。新的回归框架则通过少量标注数据直接建模验证者的偏差，显著提高了评估的精确度。", "conclusion": "少数否决策略和回归框架有效缓解了LLMs评估中的和顺偏差，从而提高了评估的准确性和可靠性，特别是在需要高精度的场景下表现出色。"}
{"llm_update_time": "20251015", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.12067", "html_url": "https://arxiv.org/abs/2510.12067", "title": "HiCoTraj:基于轨迹的分层链式推理零样本人口统计推断", "title_en": "HiCoTraj:Zero-Shot Demographic Reasoning via Hierarchical Chain-of-Thought Prompting from Trajectory", "authors": "Junyi Xie,Yuankun Jiao,Jina Kim,Yao-Yi Chiang,Lingyi Zhao,Khurram Shafique", "background": "从人类移动模式推断人口统计属性，如年龄、性别或收入水平，能够推动关键的应用，例如精准的公共卫生干预、公平的城市规划和个人化的交通服务。现有的基于移动性的推断研究主要依赖带有人口统计标签的大规模轨迹数据，这导致了解释性和跨数据集及用户群体的一般化能力有限。", "innovation": "提出了一种名为HiCoTraj的框架，该框架利用大模型（LLMs）的零样本学习能力和语义理解能力，无需标记的训练数据就能进行人口统计推断。HiCoTraj将轨迹转换为具有丰富的语义和自然语言表示的形式，通过创建详细的活动记录和多尺度访问摘要。然后，HiCoTraj使用一种新颖的分层链式推理来系统地引导大模型通过三个认知阶段：事实特征提取、行为模式分析和结构化的人口统计推断。", "conclusion": "实验证实在现实世界的轨迹数据上，HiCoTraj在零样本场景下对多个人口统计属性实现了竞争性表现。这种方法克服了标注的人口统计数据稀少的问题，同时提供了透明的推理链。"}
{"llm_update_time": "20251015", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.12072", "html_url": "https://arxiv.org/abs/2510.12072", "title": "EmboMatrix: 一个可扩展的体感决策训练平台", "title_en": "EmboMatrix: A Scalable Training-Ground for Embodied Decision-Making", "authors": "Zixing Lei,Sheng Yin,Yichen Xiong,Yuanzhuo Ding,Wenhao Huang,Yuxi Wei,Qingyao Xu,Yiming Li,Weixin Li,Yunhong Wang,Siheng Chen", "background": "体感决策让智能体能够通过持续与物理世界的交互，将高层级目标转化为可执行行动，是通用体感智能的基础。大型语言模型（LLMs）凭借其强大的决策能力为实现这一潜力提供了前景，但由于缺乏对物理环境的暴露，其真正的体感理解受到了限制。为解决这一问题，提出了一种训练地（Training Ground）的概念，提供了任务和场景模拟、体感交互和反馈信号，旨在使LLM获得真实的体感决策能力。", "innovation": "EmboMatrix 是首个类型的训练地，它提供大规模和多样化的任务，并采用高效模拟和精确奖励。EmboMatrix 包含多种创新技术：大规模任务和场景生成的多智能体数据引擎、支持扩展模拟的分布式异构硬件系统和技术层次的奖励架构，以实现精确监督。通过利用 EmboMatrix，培育出 EmboBrain，该 LLM 的体感决策能力源自广泛的体感交互。实验显示，EmboBrain-7B 在两个体感决策基准测试中的表现优于 671B DeepSeek-R1 基准，证明了交互式、环境化学习构建真正智能体的潜力", "conclusion": "实验结果表明，基于交互式、环境化学习构建的真正智能体具有显著优势，表明了 EmboMatrix 在培养具备体感决策能力的智能体方面的有效性和潜力。"}
{"llm_update_time": "20251015", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.12080", "html_url": "https://arxiv.org/abs/2510.12080", "title": "评估大型语言模型支持的任务中的随机性和熵的质量", "title_en": "Evaluating the Quality of Randomness and Entropy in Tasks Supported by Large Language Models", "authors": "Rabimba Karanjai,Yang Lu,Ranjith Chodavarapu,Lei Xu,Weidong Shi", "background": "大型语言模型（LLM）技术的飞速发展带来了多样化应用，其中许多应用需要内置的随机性功能，如随机决策、游戏、调度、AI代理和密码学相关任务。虽然LLM在处理随机性方面的具体能力，特别是在生成和利用随机数方面的能力尚不明晰。本文通过一系列实验来探索LLM处理涉及随机性任务的能力，着重考虑了外来工具访问性、任务类型、模型状态（新鲜模型与非新鲜模型）以及引言策略等因素。实验涵盖生成随机数、生成密码等随机字符串、项目洗牌及使用熵和NIST随机性测试套件评估随机性质量的任务，发现LLM生成的随机性输出表现出一定程度的随机性，但性能不一致，且偏离预期行为较为明显，这揭示了LLM在处理涉及随机性任务方面的关键限制，指出需要改进的领域以提高其处理随机性任务的能力。", "innovation": "本文通过设计综合考虑多种因素的实验，首次系统性评估了大型语言模型在支持随机性任务时产生的随机性和熵的质量，此研究强调了当前模型在这一方面存在的不足，并为未来技术改进提供了指导方向。", "conclusion": "尽管LLM能够生成某种程度上模拟随机性的输出，但其性能具有不确定性，难以满足预期的随机性标准，需要在模型状态、外部工具接入、任务类型及提示策略等方面进行优化，以提升处理随机性任务的能力。"}
{"llm_update_time": "20251015", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.12088", "html_url": "https://arxiv.org/abs/2510.12088", "title": "One Life to Learn: 从无指导探索推断用于随机环境的符号世界模型", "title_en": "One Life to Learn: Inferring Symbolic World Models for Stochastic Environments from Unguided Exploration", "authors": "Zaid Khan,Archiki Prasad,Elias Stengel-Eskin,Jaemin Cho,Mohit Bansal", "background": "过去的研究主要集中在确定性高、交互数据充足、机械简单且有人类指导的环境中，通过推断和表示环境的过渡动态来构建可执行程序。但现有方法并没有处理复杂、随机环境，而且要求只有一次机会在没有人类帮助的情况下探索一个敌对环境的问题。为此，论文提出了OneLife框架，旨在通过概率编程框架中的条件激活程序法式法则来建模世界动态，以应对这些挑战。", "innovation": "OneLife框架通过在相关世界状态中激活条件下作-效果结构的操作法式法则，创建了一个动态计算图，该图仅通过相关法则进行推理和优化，避免了所有法则都参与对复杂层级状态预测时产生的缩放挑战。此外，它还能够通过稀疏规则激活学习随机动态。为了在这些严苛条件下评估方法，论文引入了一个新的评估协议，测量状态排名和状态保真度。OneLife在Crafter-OO环境下表现出色，即使在极小的互动和无指导的情况下也能成功学习环境的关键动态，并在23种场景中中有16种场景中优于强基准。还测试了OneLife的规划能力，模拟展开成功地识别了更优策略。", "conclusion": "通过建立OneLife框架，论文为自主构建未知且复杂环境的程序化世界模型奠定了基础。"}
{"llm_update_time": "20251015", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.12121", "html_url": "https://arxiv.org/abs/2510.12121", "title": "通过目标化表示编辑在大型语言模型中实现精确属性强度控制", "title_en": "Precise Attribute Intensity Control in Large Language Models via Targeted Representation Editing", "authors": "Rongzhi Zhang,Liqin Ye,Yuzhao Heng,Xiang Chen,Tong Yu,Lingkai Kong,Sudheer Chava,Chao Zhang", "background": "精确的属性强度控制对于适应不同用户期望的AI系统至关重要。当前的方法通常只能提供方向性的或开放性的指导，无法可靠地实现精确的属性强度控制。实验数据表明，现有方法需要改进以提高精确性控制能力，进而实现多样化的用户需求。", "innovation": "该研究提出了一种新型的方法，通过三个关键设计来改进属性强度控制：(1) 将精确的属性强度控制重新定义为一个目标到达问题，而非简单的最大化问题；(2) 使用时间差分学习训练一个轻量级的价值函数，以预测部分生成后的最终属性强度分数，从而引导LLM输出；(3) 利用基于梯度的干预手段在隐藏表示上进行操作，以精确导航模型达到特定属性强度目标。该方法实现了对属性强度的精细和连续控制。实验结果验证了方法在多个任务上的有效性和效率提升。", "conclusion": "研究展示了该方法在LLaMA-3.2-3b和Phi-4-mini上的优越性，能够高精度地引导文本生成到用户指定的属性强度目标。此外，该方法在三个下游任务中的应用证明了其效率提升，包括偏好数据合成、Pareto前沿逼近与优化以及干预自由的推理行为提取。研究结果表明，该方法在大型语言模型中实现了精确的属性强度控制，为AI系统的适应性提供了新的路径。"}
{"llm_update_time": "20251015", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.12076", "html_url": "https://arxiv.org/abs/2510.12076", "title": "BeSTAD: 行为感知的空间-时间异常检测方法用于人类移动数据", "title_en": "BeSTAD: Behavior-Aware Spatio-Temporal Anomaly Detection for Human Mobility Data", "authors": "Junyi Xie,Jina Kim,Yao-Yi Chiang,Lingyi Zhao,Khurram Shafique", "background": "传统的异常检测主要集中在轨迹级别的分析上，识别群体移动轨迹中的统计异常或时空不一致之处。然而，对于个体级别的异常检测，即检测个人移动行为与自身历史模式之间的不寻常偏差，在大型人口数据集中仍然面临重大挑战。现有的方法难以发现和解释单个个体在移动模式上的细微偏差。因此，需要一种新的方法来捕捉大规模人群中的个性化行为特征，并通过同时建模空间上下文和时间动态来发现粒度的异常。", "innovation": "提出了一种称为 BeSTAD 的无监督框架，它可以捕捉大规模人群中的个性化行为特征，并通过结合空间上下文和时序动态来发现粒度的异常。BeSTAD 能够学习语义丰富的移动表示，整合位置含义和时间模式，从而检测个人移动行为中的细微偏差。此外，BeSTAD 使用一种行为聚类感知建模机制，构建个人行为档案，并通过跨时间段的行为对比和一致的语义对齐来识别异常。这种方法不仅能够检测行为转变和偏离常规的现象，还能够识别出存在此类变化的个体。通过直接从未标记数据中学习个体行为，BeSTAD 推进了异常检测向个性化和可解释的移动分析方向发展。", "conclusion": "BeSTAD 框架通过学习个体行为直接从未标记的数据中，不仅发现了大规模移动数据集中的行为转变和偏差，还通过构建个性化的行为档案，识别出表现出这些变化的个体，从而提供了一种新的、有效的异常检测方法。"}
{"llm_update_time": "20251015", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.12194", "html_url": "https://arxiv.org/abs/2510.12194", "title": "ResearStudio: 可介入框架以构建可控的深度研究代理", "title_en": "ResearStudio: A Human-Intervenable Framework for Building Controllable Deep-Research Agents", "authors": "Linyi Yang,Yixuan Weng", "background": "当前的深度研究代理在执行过程中采用‘开即忘’模式，用户在执行开始后无法修正错误或加入专家知识。基于此背景，本研究提出了ResearStudio框架，旨在提供实时的人工智能与人工控制相结合的方法，以增强深度研究代理的可控性与灵活性。", "innovation": "ResearStudio是第一个将实时人工控制置于核心位置的开源框架，采用了协作型工作坊的设计理念。该框架通过分层规划执行器将每一步写入实时的‘计划文档’中，并通过快速通讯层实时传输每个动作、文件变更和工具调用到网络界面，使得用户在任何时刻都可以暂停运行、编辑计划或代码、执行自定义命令并恢复执行，实现人工介入主导与人工智能辅助之间的灵活转换。此外，ResearStudio在自主模式下实现了在GAIA基准上与OpenAI的DeepResearch和Manus相媲美的出色表现，证明了强大的自动化性能与精细的人工控制可以共存。", "conclusion": "该框架的完整代码、协议和评估脚本可以在提供的链接中获取，并将持续更新以促进对安全可控研究代理的进一步工作。同时，开发者可以访问DeepScientist库进行进一步研究。"}
{"llm_update_time": "20251015", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.12091", "html_url": "https://arxiv.org/abs/2510.12091", "title": "ToPolyAgent: AI Agents for Coarse-Grained Topological Polymer Simulations", "title_en": "ToPolyAgent: AI Agents for Coarse-Grained Topological Polymer Simulations", "authors": "Lijie Ding,Jan-Michael Carrillo,Changwoo Do", "background": "本文介绍了ToPolyAgent，这是一种多智能体人工智能框架，可以使用自然语言指令执行拓扑聚合物的粗粒度分子动力学（MD）模拟。该框架将大型语言模型（LLMs）与领域特定的计算工具结合起来，支持不同聚合物结构的交互式和自主式模拟工作流，包括线性聚合物、环状聚合物、侧枝聚合物、星状聚合物以及树枝状聚合物。系统由四个由LLM驱动的智能体组成：配置智能体用于生成初始聚合物-溶剂配置；模拟智能体用于执行基于LAMMPS的MD模拟和构象分析；报告智能体用于编译Markdown报告；工作流智能体用于流水线式的自主操作。易交互模式通过用户反馈循环进行迭代改进，而自主模式则从详细的提示开始，实现端到端的任务执行。本文通过不同溶剂条件下的案例研究展示了ToPolyAgent的灵活性，并探讨了相互作用参数对直线聚合物构象的影响以及侧枝聚合物树枝长度的影响。通过将自然语言界面与严格的模拟工具相结合，ToPolyAgent降低了复杂计算流程的障碍，并促进了聚合物科学中的AI驱动材料发现。本研究为自主和可扩展的多智能体科学研究生态系统奠定了基础。\n", "innovation": "ToPolyAgent通过结合大型语言模型和领域特定的计算工具，实现了聚合物模拟的自然语言指令驱动，并支持跨聚合物架构的交互式和自主式模拟工作流。系统设计了四个智能体，分别处理初始配置、MD模拟执行、报告编制和自动化操作。该框架能够降低复杂计算流程的门槛，促进在聚合物科学中的AI驱动材料发现。研究还展示了其作为研究助理的能力，能够独立探究聚合物结构的特性。\n", "conclusion": "ToPolyAgent通过将自然语言界面与严格的分子动力学模拟工具相结合，降低了复杂计算流程的阻碍，推进了聚合物科学中AI驱动材料发现。该框架为自主和可扩展的多智能体科研生态系统的构建奠定了基础。"}
{"llm_update_time": "20251015", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.12171", "html_url": "https://arxiv.org/abs/2510.12171", "title": "MatSciBench：大规模语言模型在材料科学推理能力的基准测试", "title_en": "MatSciBench: Benchmarking the Reasoning Ability of Large Language Models in Materials Science", "authors": "Junkai Zhang,Jingru Gan,Xiaoxuan Wang,Zian Jia,Changquan Gu,Jianpeng Chen,Yanqiao Zhu,Mingyu Derek Ma,Dawei Zhou,Ling Li,Wei Wang", "background": "虽然大型语言模型（LLMs）在科学推理方面展示了显著的能力，但在材料科学领域的推理能力却鲜有探讨。MatSciBench的引入旨在填补这一空白，通过提供一个全面的大学水平基准测试，涵盖1340个涉及材料科学核心分支的问题，解决了现有的研究空白。该基准测试包括结构化和细粒度的分类体系，将问题细分为6个主要领域和31个子领域，基于解决问题所需的推理长度进一步分为三级难度等级。此外，它还包含了多模态推理，部分问题通过视觉背景进行说明。评估结果指出，即使是表现最佳的模型Gemini-2.5-Pro，其在大学水平材料科学问题上的准确率也低于80%，这表明MatSciBench具有极高的复杂性。这一多样化的评估框架和类别为客户理模型在材料科学中的科学推理能力提供了一个框架和基准。研究表明，不同的推理策略——基础链式思考、工具增强和自我纠正，并不能在所有场景中都表现出色。研究表明，这一基准测试有助于识别和克服材料科学范围内多模态推理任务过程中的挑战。", "innovation": "MatSciBench通过提供一个全面的材料科学大学水平基准测试，填补了现有研究的空白，其包括多模态推理、细粒度分类体系和复杂的问题难度分类。此外，它还通过评估不同推理策略（如基本信息链式思考、工具增强和自我纠正）在材料科学领域中的表现，展示了单一方法在各种场景中的局限性，从而推动了对多模态推理任务挑战的理解和解决。它还进一步分析了不同难度级别的性能、效率与准确性的权衡、多模态推理任务的挑战以及检索增强生成的影响。", "conclusion": "MatSciBench为评估和促进大型语言模型在材料科学领域中科学推理能力提供了全面且坚实的基准测试工具。通过这一全面的基准测试工具，客户理模型能够改善其科学推理能力，造福材料科学领域的研究和发展。"}
{"llm_update_time": "20251015", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.12178", "html_url": "https://arxiv.org/abs/2510.12178", "title": "Meta公司的LLaMA模型及其大语言模型的参数高效微调：综述", "title_en": "Evolution of meta's llama models and parameter-efficient fine-tuning of large language models: a survey", "authors": "Abdulhady Abas Abdullah,Arkaitz Zubiaga,Seyedali Mirjalili,Amir H. Gandomi,Fatemeh Daneshfar,Mohammadsadra Amini,Alan Salam Mohammed,Hadi Veisi", "background": "本文回顾了Meta AI的LLaMA系列模型（从LLaMA 1到LLaMA 4）及其相关的专门的参数高效微调（PEFT）方法的发展。文章首先介绍了LLaMA家族的底层模型（参数从70亿到2880亿）、其架构（包括原生的多模态和Mixture of Experts（MoE）变体），以及关键性能特征。此后，文章描述并讨论了PEFT的概念，即通过仅更新一部分参数来适配大型预训练模型，文中还介绍了五种应用于LLaMA的PEFT方法：LoRA（低秩适应）、LLaMA-Adapter V1和V2、LLaMA-Excitor和QLoRA（量化LoRA）。文章还详细讨论了各种方法的机制、参数节省和对LLaMA的应用（如指令微调、多模态任务），并提供了对模型和适配器架构、参数计数及基准测试结果的结构化讨论和分析。", "innovation": "文章重在介绍并详细讨论了从LLaMA 1到LLaMA 4的系列模型及其PEFT方法，特别是具体的五种PEFT方法（LoRA、LLaMA-Adapter V1和V2、LLaMA-Excitor和QLoRA），并详细展示了它们的工作机制、参数节省以及应用场景。此外，文章还对比了微调后的LLaMA模型与更大基线模型的效果。", "conclusion": "最后，文章探讨了LLaMA模型及其PEFT技术在实际应用中的成功案例（如法律和医疗领域），并讨论了存在的挑战和未来的研究方向（如更广泛的上下文扩展和提高稳健性）。"}
{"llm_update_time": "20251015", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.12201", "html_url": "https://arxiv.org/abs/2510.12201", "title": "关于以人为本的可解释人工智能系统的设计与评估：一项系统综述和分类", "title_en": "On the Design and Evaluation of Human-centered Explainable AI Systems: A Systematic Review and Taxonomy", "authors": "Aline Mangold,Juliane Zietz,Susanne Weinhold,Sebastian Pannasch", "background": "随着人工智能在日常生活中的普及，对既高效又能被理解的智能系统的需求日益增长。解释性人工智能(XAI)旨在提供决策和预测的可理解解释。然而，当前的评估过程过于技术化，并未充分关注用户需求。因此，涉及人类用户的评估研究可以作为指导人类用户研究的重要指南。本文回顾了65项用户研究，评价了不同领域和应用场景的XAI系统，为XAI系统的开发提供了一个全面的视角，并强调了以用户为中心的评价标准和设计目标。", "innovation": "本文提出了一种扩展现有的XAI评估和设计框架，将XAI系统特性分为核心系统和解释系统，并进一步将评估指标分为情感、认知、易用性、可解释性和解释指标。针对不同水平的人工智能专家提出了扩展的设计目标：对于人工智能新手，重点关注负责任使用、接受度和易用性；对于数据专家，则更关注性能表现及人类与人工智能的合作和系统及用户任务表现等。", "conclusion": "本文通过系统综述和分类，提供了一种全面视角来评估以人为本的XAI系统，为XAI开发人员提供了一个系统性的指导框架。"}
{"llm_update_time": "20251015", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.12218", "html_url": "https://arxiv.org/abs/2510.12218", "title": "GOAT: 一种用于目标导向工具代理的训练框架", "title_en": "GOAT: A Training Framework for Goal-Oriented Agent with Tools", "authors": "Hyunji Min,Sangwon Jung,Junyoung Sung,Dosung Lee,Leekyeung Han,Paul Hongsuck Seo", "background": "大型语言模型（LLMs）已从传统的文本生成扩展为主要作为能够基于用户意图使用外部工具的交互代理。然而，现有的LLM代理在处理需要将高层目标分解为正确规划和执行的多个相互依赖的API调用的目标导向查询方面仍表现出有限的能力。现有的方法主要依赖于零样本评估，因为缺乏相关的训练数据。虽然像GPT-4这样的专有封闭源模型展示了强大的推理能力，但较小的开源模型在有效使用复杂工具方面遇到困难。因此，我们提出了一种新的训练框架GOAT，该框架能够在无需人类注释的情况下微调LLM代理。GOAT能够直接从提供的API文档中自动构建目标导向的API执行任务的合成数据集，使模型能够推理相互依赖的调用并生成连贯的响应。", "innovation": "我们提出了一个新颖的训练框架GOAT，能够在无需人类注释的情况下微调LLM代理。GOAT能够直接从提供的API文档中自动构建目标导向的API执行任务的合成数据集，使模型能够推理相互依赖的调用并生成连贯的响应。通过广泛的实验结果，我们展示了GOAT训练的代理在多个现有目标导向基准测试中达到了最先进的性能。此外，我们还引入了GOATBench，一个新目标导向的API执行基准测试，表明使用GOAT训练的代理在这一设置中也表现出色。", "conclusion": "我们的结果突显了GOAT作为构建能够进行复杂推理和工具使用的稳健开源LLM代理的实际路径。"}
{"llm_update_time": "20251015", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.12224", "html_url": "https://arxiv.org/abs/2510.12224", "title": "MedKGEval：基于知识图谱的多轮次评估框架，用于临床LLM开放结束患者互动", "title_en": "MedKGEval: A Knowledge Graph-Based Multi-Turn Evaluation Framework for Open-Ended Patient Interactions with Clinical LLMs", "authors": "Yuechun Yu,Han Ying,Haoan Jin,Wenjian Jiang,Dong Xian,Binghao Wang,Zhou Yang,Mengyue Wu", "background": "在医学应用中可靠评估大型语言模型（LLMs）依旧是一个开放的挑战，尤其是在捕捉真实临床环境中复杂多轮医生和患者对话时。现有的评估方法通常依赖于对完整的对话转录进行事后审查，忽视了医学对话的动态性和情境敏感性，以及患者不断变化的信息需求。因此，本研究介绍了MedKGEval，一个基于结构化医学知识的多轮评估框架，旨在更精确地评估临床LLM。", "innovation": "MedKGEval的创新之处在于三个关键贡献：1）知识图谱驱动的患者模拟机制，通过一个专门的控制模块从经过策划的知识图谱中检索相关医学事实，使患者代理具有类似人类的、现实的对话行为；2）实时、每轮评估框架，随着对话的进行，每个模型响应将由法官代理依据一系列细粒度的、任务特定的指标进行评估，包括临床适宜性、事实准确性以及安全性；3）包含八个最新最佳的LLM的全面多轮基准测试，证明MedKGEval能够识别传统评估流水线往往忽略的细致行为缺陷和安全风险。", "conclusion": "MedKGEval最初设计用于中文和英文医学应用，通过切换输入知识图谱，该框架可以轻松扩展到其他语言，确保无缝的双语支持和领域的特定适用性。"}
{"llm_update_time": "20251015", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.12264", "html_url": "https://arxiv.org/abs/2510.12264", "title": "T³: 减少强化学习中主动推理中的信念偏差", "title_en": "$\\mathbf{T^3}$: Reducing Belief Deviation in Reinforcement Learning for Active Reasoning", "authors": "Deyu Zou,Yongqiang Chen,Jianxiang Wang,Haochen Yang,Mufei Li,James Cheng,Pan Li,Yu Gong", "background": "主动推理需要大规模语言模型（LLMs）与外部资源互动，灵活搜集信息以解决问题。该过程的核心是信念追踪：保持对问题状态和缺失信息的清晰理解，从而趋向解决方案。然而，由于推理能力有限，基于LLM的代理往往会出现信念偏差：难以正确建模信念，迷失问题状态，并陷入非信息性或重复性行为。一旦发生此情况，错误会累积，强化学习（RL）训练无法恰当奖励关键探索步骤。", "innovation": "本文提出了一种简单而有效的方法，即T³，用于追踪模型信念偏移，并在训练过程中截断轨迹以去除非信息性尾巴。通过保存信息性前缀的信用，T³系统地提高了策略优化。在5个具有挑战性的任务中，T³持续提升了训练稳定性、标记效率和最终性能，性能提升高达30%，同时减少了大约25%的展开标记量。这些结果突出了信念控制作为开发稳健而通用化的LLM主动推理器的关键原则的重要性。", "conclusion": "T³有效地解决了LLM基于代理在主动推理中的信念偏差问题，通过策略优化和减少非信息性行为，在多个任务中显著提高了训练的稳定性和效率。"}
{"llm_update_time": "20251015", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.12246", "html_url": "https://arxiv.org/abs/2510.12246", "title": "PromptFlow：像训练神经网络一样训练提示", "title_en": "PromptFlow: Training Prompts Like Neural Networks", "authors": "Jingyi Wang,Hongyuan Zhu,Ye Niu,Yunhui Deng", "background": "大型语言模型（LLMs）已在自然语言处理（NLP）任务中展现出深远的影响，但其在不同领域的有效部署通常需要特定领域的适应策略，因为通用模型在面对特定数据分布时可能会表现不佳。因此，最近在提示工程（PE）方面的进展提供了一种潜在的替代方法，通过优化输入指令来使LLM输出与任务目标一致。尽管这种方法具有潜力，但在手动设计提示方面仍然非常耗时，并且往往需要特殊的专家知识。目前的方法大多使用静态更新规则，缺乏动态策略选择机制，导致适应性不足，而大多数方法在每次更新时都会对整体提示进行编辑，而不考虑以更精细的粒度编辑提示部分。特别是在如何利用LLM的经验方面，研究仍处于初级阶段。", "innovation": "本文提出了一种PromptFlow，这是一种模块化训练框架，受到TensorFlow启发，结合了元提示、操作、优化和评估器。我们的框架能够使用最新的优化方法，并通过基于梯度的元学习自主探索最优提示精炼轨迹，无需大量特定任务的训练数据。具体而言，我们设计了一种强化学习方法，可以在提示工程（PE）过程中回收经验。", "conclusion": "我们在多个数据集上进行了大量实验，证明了PromptFlow的有效性。"}
{"llm_update_time": "20251015", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.12409", "html_url": "https://arxiv.org/abs/2510.12409", "title": "PricingLogic：评估大型语言模型在复杂旅游定价任务上的推理能力", "title_en": "PricingLogic: Evaluating LLMs Reasoning on Complex Tourism Pricing Tasks", "authors": "Yunuo Liu,Dawei Zhu,Zena Al-Khalili,Dai Cheng,Yanjun Chen,Dietrich Klakow,Wei Zhang,Xiaoyu Shen", "background": "旅行代理机构愿意将此易出错的任务外包给AI系统。然而，如果没有验证的可靠性，部署大型语言模型（LLMs）可能会导致财务损失并损害客户信任。为了应对这一挑战，作者提出了PricingLogic，这是一个基准测试，探究LLMs能否可靠地自动化涉及多个重叠费率规则的旅游相关价格任务。", "innovation": "PricingLogic是第一个专门设计来测试大型语言模型在处理复杂旅游定价任务时推理能力的基准测试。该测试包括基于42个真实世界定价政策的300个自然语言问题，涵盖了基础客户类型定价和涉及交互折扣的捆绑旅行计算。", "conclusion": "尽管大型语言模型具有广泛的能力，但研究结果表明，它们在这类支持收入的关键应用中仍然不可靠，特别是面对更复杂的任务时。研究结果强调了需要额外的保护措施或领域适应来确保这些模型在实际部署中的可靠性。"}
{"llm_update_time": "20251015", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.12269", "html_url": "https://arxiv.org/abs/2510.12269", "title": "Tensor 逻辑：AI 的语言", "title_en": "Tensor Logic: The Language of AI", "authors": "Pedro Domingos", "background": "当前的人工智能进展受限于缺乏能够提供所需所有功能的编程语言。虽然像PyTorch和TensorFlow这样的库提供了自动求导和高效GPU实现的功能，但它们是附加工在Python上的，Python最初并非为AI设计。这些库缺乏自动推理和知识获取的支持，导致了一连串复杂且耗时的尝试。另一方面，如LISP和Prolog这样的AI编程语言虽然性能优越但缺少可扩展性和学习支持。因此，这一研究旨在通过提出一种整合了神经AI和符号AI的编程语言来解决此问题。", "innovation": "该论文提出了Tensor逻辑，这是一种新型的编程语言，能够从根本上将神经AI和符号AI统一起来。Tensor逻辑仅有一个构造——张量方程，基于逻辑规则和爱因斯坦求和法则本质上是相同的操作的观察，并且其他的一切都可以归结于此。研究展示了如何在Tensor逻辑中优雅地实现神经、符号和统计AI的关键形式，包括变换器、形式推理、核机器和图形模型。最重要的创新在于，Tensor逻辑开拓了新的方向，如嵌入空间中的有声推理，结合了神经网络的可扩展性和学习能力以及符号推理的可靠性和透明性，从而可能成为更广泛采用AI的基础。", "conclusion": "Tensor逻辑为拓展AI应用提供了新的方向，结合了神经网络和符号推理的最优点。这种语言有可能成为广泛采用AI的基础，具有深远的影响。"}
{"llm_update_time": "20251015", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.12323", "html_url": "https://arxiv.org/abs/2510.12323", "title": "RAG-Anything: 全能RAG框架", "title_en": "RAG-Anything: All-in-One RAG Framework", "authors": "Zirui Guo,Xubin Ren,Lingrui Xu,Jiahao Zhang,Chao Huang", "background": "检索增强生成（RAG）作为一种扩展大型语言模型的基本范式已经出现，但当前RAG功能与实际信息环境之间存在关键不对齐。现代知识库是多模态的，包含丰富的文本内容、视觉元素、结构化表格和数学表达式。然而，现有的RAG框架仅限于文本内容，导致在处理多模态文档时存在根本性差距。", "innovation": "我们提出了RAG-Anything，一种统一框架，使其能够跨所有模态进行全面的知识检索。该方法将多模态内容重新概念化为相互连接的知识实体，而非孤立的数据类型。框架引入了双图构建，以在统一表示中捕捉跨模态关系和文本语义。开发了多模态混合检索，结合结构化知识导航与语义匹配，以在异构内容中有效地进行推理，其中相关证据跨越多个模态。RAG-Anything在具有挑战性的多模态基准测试中表现出优越性能，相对于最先进的方法取得了显著改进，特别是在长文档方面。", "conclusion": "我们的框架为多模态知识访问建立了新的范式，克服了当前系统的架构碎片化限制。我们的框架已经开源，可以访问：this https URL。"}
{"llm_update_time": "20251015", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.12350", "html_url": "https://arxiv.org/abs/2510.12350", "title": "O-Forge：一种大语言模型加计算机代数框架进行渐进行分析", "title_en": "O-Forge: An LLM + Computer Algebra Framework for Asymptotic Analysis", "authors": "Ayush Khaitan,Vijay Ganesh", "background": "大型语言模型近年来在解决IMO和Putnam问题上展现了高级能力，但在研究数学领域的应用仍然有限。主要难题是验证：提出的证明看起来很合乎逻辑，但没有严格的检查便无法信任。", "innovation": "本文提出了一个名为LLM+CAS的框架和工具O-Forge，将前沿的大语言模型与计算机代数系统结合在一个创新型符号反馈回路中，生成既创造性的又能被严格验证的证明。重点是渐近不等式，这个主题通常涉及困难的证明和正确分解领域。本文通过结合前沿的大语言模型和CAS证明，展示了框架在提出正确分解方面的有效性。", "conclusion": "本文证明了LLM+CAS框架在渐进行分析中具备高度有效性，特别是在提出正确分解方面。更广泛地说，本文展示了AI如何从竞赛数学迈向供职业数学家使用的高级研究工具。"}
{"llm_update_time": "20251015", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.12399", "html_url": "https://arxiv.org/abs/2510.12399", "title": "大语言模型支持的Vibe Coding综述", "title_en": "A Survey of Vibe Coding with Large Language Models", "authors": "Yuyao Ge,Lingrui Mei,Zenghao Duan,Tianhao Li,Yujia Zheng,Yiwei Wang,Lexin Wang,Jiayu Yao,Tianyu Liu,Yujun Cai,Baolong Bi,Fangda Guo,Jiafeng Guo,Shenghua Liu,Xueqi Cheng", "background": "随着大型语言模型（LLMs）的进步，编程范式从代码生成辅助转变为自主编程代理。这种变化催生了一种新的开发方法——Vibe Coding，开发人员通过观察结果来验证AI生成的实现，而不是逐行理解代码。尽管具有革命性的潜力，但这种新范式的有效性尚未得到彻底探索，现有研究表明，在人机协作中存在不可预见的生产力下降和根本性挑战。", "innovation": "本文进行了首个全面系统的Vibe Coding综述，针对大型语言模型。通过正式化的约束马尔可夫决策过程（C-MDP）建立理论基础，并将现有实践总结为五种不同的开发模型：无约束自动化、迭代对话协作、计划驱动、测试驱动和增强情境模型。分析显示，成功实施Vibe Coding不仅依赖于代理的能力，还依赖于系统性的上下文工程、成熟的开发环境以及人机协作开发模型的系统化设计。", "conclusion": "本文通过全面详细地分析超过1000篇相关研究文章，为Vibe Coding建立了理论基础和实用框架，首次提出了详尽的分类，并强调了在实施Vibe Coding时需要考虑系统化上下文工程和成熟的人机协作开发模型。"}
{"llm_update_time": "20251015", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.12428", "html_url": "https://arxiv.org/abs/2510.12428", "title": "Biased-Attention Guided Risk Prediction for Safe Decision-Making at Unsignalized Intersections", "title_en": "Biased-Attention Guided Risk Prediction for Safe Decision-Making at Unsignalized Intersections", "authors": "Chengyang Dong,Nan Guo", "background": "无信号交叉口的自主驾驶决策极具挑战性，因为涉及复杂的动态交互和高冲突风险。为实现前瞻性安全控制，本文提出了一种结合偏差注意力机制的深度强化学习（DRL）决策框架，该框架基于Soft Actor-Critic (SAC) 算法。", "innovation": "该框架的核心创新在于使用偏差注意力来构建一个交通风险预测器。该预测器评估进入交叉口的车辆在未来发生碰撞的长期风险，并将其转换为密集奖励信号，以引导SAC代理做出安全和高效的驾驶决策。", "conclusion": "仿真结果显示，本文提出的方法有效提高了交叉口的交通效率和车辆安全性，从而证明了在复杂场景中智能决策框架的有效性。我们的工作代码可在以下链接获取。"}
{"llm_update_time": "20251015", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.12423", "html_url": "https://arxiv.org/abs/2510.12423", "title": "MTOS：一种由大型语言模型驱动的多主题意见模拟框架，用于探索回声室动态", "title_en": "MTOS: A LLM-Driven Multi-topic Opinion Simulation Framework for Exploring Echo Chamber Dynamics", "authors": "Dingyi Zuo,Hongjie Zhang,Jie Ou,Chaosheng Feng,Shuwan Liu", "background": "近年来，社交媒体上的意见极化、信息隔离和认知偏差引起了学术界的广泛关注。在实际网络中，信息往往跨越多个相互关联的主题，这使得意见演变变得复杂，并突显了需要能够模拟主题之间相互作用的框架的需求。现有基于大型语言模型（LLMs）的研究主要集中在单个主题上，无法涵盖多主题、跨域背景下的认知转移。传统数值模型简化了复杂语言态度为离散值，导致缺乏可解释性、行为一致性和多个主题的整合能力。", "innovation": "为了解决这些问题，我们提出了多主题意见模拟（MTOS），这是一种结合多主题环境与大型语言模型的社会模拟框架。MTOS利用了大型语言模型并与短期和长期记忆相结合，引入了多种用户选择交互机制和动态主题选择策略，并通过信念衰减机制以支持主题之间的视角更新。进行了大规模实验，并通过消融研究来评估诸如群体极化和局部一致性等特征。结果显示，在多主题设置中，积极相关主题会放大回声室，消极相关主题会抑制它们，而无关主题还能通过资源竞争来缓解回声室效应。与传统的数值模型相比，基于大型语言模型的代理能够更真实地模拟意见动态变化、再现新闻文本的语言特征并捕捉复杂的类人推理过程，从而提高模拟解释性和系统稳定性。", "conclusion": "研究表明，在多主题环境下，现实世界中的意见极化趋势发生了显著变化：正相关主题会提升回声室效应，负相关主题会抑制回声室效应，而无关主题则通过资源竞争缓解回声室效应。相比传统数值模型，基于大型语言模型的代理更真实地模拟了动态意见变化、再现了新闻文本的语言特征，并捕捉了复杂的类人推理过程，从而提高了模拟的可解释性和系统的稳定性。"}
{"llm_update_time": "20251015", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.12534", "html_url": "https://arxiv.org/abs/2510.12534", "title": "ProtoSiTex：多标签文本分类的半可解释原型学习", "title_en": "ProtoSiTex: Learning Semi-Interpretable Prototypes for Multi-label Text Classification", "authors": "Utsav Kumar Nareti,Suraj Kumar,Soumya Pandey,Soumi Chattopadhyay,Chandranath Adak", "background": "用户生成的评论激增使得需要能够提供细粒度见解的可解释模型。现有基于原型的模型虽然提供直观解释，但通常在句子或文档级别操作，并未能解决真实世界文本分类中的多标签问题。当前研究旨在填补这一空白，提出了一个细粒度多标签文本分类的半可解释框架ProtoSiTex。", "innovation": "ProtoSiTex采用双阶段交替训练策略：无监督的原型发现阶段学习语义连贯和多样的原型，监督分类阶段将这些原型映射到类别标签。通过层级损失函数增强解释性和一致性。此外，引入了一个基于酒店评论的基准数据集，包含了子句子级别的多标签注释。ProtoSiTex通过适应性原型和多头注意力捕捉重叠和冲突的语义，在多基准实验中达到了最先进的性能，并提供了忠实、与人类对齐的解释。", "conclusion": "ProtoSiTex已被证明是一个稳健的半可解释多标签文本分类解决方案，不仅性能优异，还能够提供忠实、与人类对齐的解释。"}
{"llm_update_time": "20251015", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.12462", "html_url": "https://arxiv.org/abs/2510.12462", "title": "评估与缓解通信系统中的LLM作为裁判偏见", "title_en": "Evaluating and Mitigating LLM-as-a-judge Bias in Communication Systems", "authors": "Jiaxin Gao,Chen Chen,Yanwen Jia,Xueluan Gong,Kwok-Yan Lam,Qian Wang", "background": "大型语言模型（LLMs）正越来越多地用于自主评估通信系统中内容的质量，例如，评估电信客服聊天机器人的响应质量。然而，这些AI‘裁判’的公正性并不确定，他们评价标准中的任何偏见都可能扭曲结果，损害用户信任。", "innovation": "本文系统性地调查了两种LLM作为裁判模型（即GPT-Judge和JudgeLM）在点评分设置下的判断偏见，涵盖了11种偏见，包括隐性和显性两种形式。研究发现，最先进的LLM裁判模型对有偏输入具有鲁棒性，并且通常会给予较低分数。额外提供详细的评分标准进一步增强了这种鲁棒性。此外，研究还发现，对有偏高分响应进行微调会显著降低模型性能，这揭示了使用偏见数据进行训练的风险。研究还发现，被评判分数与任务难度相关：具有挑战性的数据集（如GPQA）会给出较低的平均分数，而开放性推理数据集（如JudgeLM-val）则给出较高的平均分数。", "conclusion": "本文提出了四种潜在的缓解策略，以确保在实际通信场景中实现公平可靠的AI评判。"}
{"llm_update_time": "20251015", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.12555", "html_url": "https://arxiv.org/abs/2510.12555", "title": "基于亲和力的收益作为多智能体强化学习环境中更高级社交行为的关键步骤", "title_en": "Inclusive Fitness as a Key Step Towards More Advanced Social Behaviors in Multi-Agent Reinforcement Learning Settings", "authors": "Andries Rosseau,Raphaël Avalos,Ann Nowé", "background": "自然选择的驱动力——竞争与合作——推动了数百万年来智慧的进化，形成了自然界的生物多样性和人类复杂的大脑。文章以此为背景，研究由亲和力概念建模的奖励函数在多智能体强化学习框架中的应用，探讨这种机制如何在社交动态中产生与生物进化类似的策略演化过程。", "innovation": "提出了一个新颖的基于遗传基因的多智能体强化学习框架，引入了亲和力作为智能体的奖励机制，从而实现了智能体之间基于遗传相似性的不同合作程度。该框架不仅适用于如囚徒困境等网络博弈，还扩展至具有空间和时间结构、有限资源及进化群体的开放环境，模拟了策略的渐进进化过程，类似于生物的自然选择机制。这种基因型奖励结构提供了策略的连续性，即从完全敌对到完全合作的连续谱，打破了早期研究中二元团队结构的局限性。", "conclusion": "通过将亲和力概念引入到智能体框架中，这种机制有助于智能体进化出更具战略性和社交智能的行为。新提出的框架为多智能体系统中高级社交行为的发展和进化机制研究提供了新的思路。"}
{"llm_update_time": "20251015", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.12635", "html_url": "https://arxiv.org/abs/2510.12635", "title": "Memory as Action: 自主性上下文管理以应对长期规划任务", "title_en": "Memory as Action: Autonomous Context Curation for Long-Horizon Agentic Tasks", "authors": "Yuxiang Zhang,Jiangming Shu,Ye Ma,Xueyuan Lin,Shangxi Wu,Jitao Sang", "background": "大语言模型在长期规划任务中面临挑战，因为它们的受限记忆容易被无关或不重要的上下文所淹没。现有的工作记忆方法通常依赖于与核心策略脱钩的外部启发式机制。本文将工作记忆管理重新定义为一种可学习的内在能力，提出了一种新的框架——Memory-as-Action，其中智能体通过执行显式的编辑操作来管理其工作记忆，作为统一策略的一部分。这种形式允许智能体通过强化学习的训练来平衡内存编目和长期任务目标之间的关系，同时受资源限制的影响。但是，这种记忆编辑行动打破了LLM交互中的标准假设，即连续增长的前缀假设，导致了我们称之为轨迹断裂的现象。这些非前缀更改破坏了标准策略梯度方法所需的因果连续性，使这些方法不再适用。", "innovation": "本文提出了一个新的框架——Memory-as-Action，以及一种新的算法——Dynamic Context Policy Optimization，以解决由于记忆编辑行动引起的轨迹断裂问题。Dynamic Context Policy Optimization通过在记忆操作点分割轨迹并应用轨迹级别的优势到每个结果动作段，使得端到端的强化学习变得稳定。这种方法不仅减少了总体计算消耗，还通过适应上下文编目的策略提高了任务性能，利用了模型的内在能力实现联合优化任务推理和记忆管理的目标。", "conclusion": "本文的成果表明，以端到端的方式联合优化任务推理和内存管理不仅减少了整体计算消耗，还提高了任务表现，是通过适应上下文编目的策略驱动的，这些策略根据模型的内在能力进行了调整。"}
{"llm_update_time": "20251015", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.12498", "html_url": "https://arxiv.org/abs/2510.12498", "title": "人工智能虚拟细胞：从多模态、多尺度、动力学到评估的决策过程", "title_en": "Artificial Intelligence Virtual Cells: From Measurements to Decisions across Modality, Scale, Dynamics, and Evaluation", "authors": "Chengpeng Hu,Calvin Yu-Chian Chen", "background": "AI虚拟细胞（AIVCs）旨在从多模态、多尺度测量中学习可执行、与决策相关的细胞状态模型。尽管最近的研究已引入了单细胞和空间基础模型，改善了跨模态对齐，扩大了扰动图谱，并探索了途径级别的读数，但现有的评估方法仍主要在单一的数据集和环境下进行，且缺乏对实验室和平台间数据运输的全面评估。此外，数据划分易受到泄漏和覆盖偏差的影响，剂量、时间和组合效应也未系统处理。跨尺度耦合也受到限制，研究间锚点在不同层次之间（分子、细胞和组织）的需求不一，与科学或临床读数的对齐也有所不同。", "innovation": "本文提出了一个模型无关的细胞状态潜在（CSL）视角，通过操作符语法组织学习：测量、提升/投影进行跨尺度耦合、干预进行剂量和调度。该视角促进了跨模态、多尺度、上下文和干预的一致性决策评估蓝图，并强调如途径活性、空间邻域和临床相关终点的功能空间读数。作者建议操作符意识的数据设计、抗泄露分区、透明校准和报告，以实现可复制、直接对比的评估。", "conclusion": "研究提出了一种新的评估框架，强调一致性决策评估，涵盖模态、尺度、上下文和干预，并促进功能空间读数，如途径活性、空间邻域和临床相关终点。同时建议了操作符意识的数据设计、防泄漏分区、透明校准和报告，以促进评估的可复制性和直接对比。"}
{"llm_update_time": "20251015", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.12563", "html_url": "https://arxiv.org/abs/2510.12563", "title": "HardcoreLogic：用长尾逻辑谜题游戏挑战大型推理模型", "title_en": "HardcoreLogic: Challenging Large Reasoning Models with Long-tail Logic Puzzle Games", "authors": "Jingcong Liang,Shijun Wan,Xuehai Wu,Siyuan Wang,Yitong Li,Qianglong Chen,Duyu Tang,Zhongyu Wei", "background": "大型推理模型（LRMs）在复杂的任务上表现出色，包括需要推导出满足所有约束条件的逻辑谜题游戏。然而，这些模型是否能够在面对非标准的谜题变体时灵活应用适当的规则，仍然是一个开放的问题。现有的谜题数据集主要关注如9x9数独这些流行谜题，这可能会导致模型过度拟合于标准格式并记忆解决模式，从而掩盖了对新模式规则的理解缺陷或适应新变体策略的能力不足。为了解决这个问题，作者引入了一个新的挑战基准——HardcoreLogic，包含了5000多个谜题，覆盖10个不同的游戏，旨在测试LRMs在逻辑谜题长尾范围内的鲁棒性。通过系统性地将标准谜题转换为提高复杂性（IC）、引入不常见元素（UE）以及不可解谜题（UP），HardcoreLogic减少了对记忆捷径的依赖。", "innovation": "HardcoreLogic是一个包含超过5000个谜题的新挑战基准，旨在测试大型推理模型在逻辑谜题“长尾”范围内的鲁棒性。它通过增加复杂性（IC）、引入不常见元素（UE）和不可解谜题（UP）三个维度系统地转变标准谜题，减少了对记忆捷径的依赖。评估结果显示，即使在现有基准测试中表现优异的模型，在HardcoreLogic上也表现出了显著下降，这表明模型对记忆化模式的严重依赖。增加的复杂性是主要困难来源，但模型在一些细微规则变化上也存在困难，即使这些变化并不增加谜题难度。", "conclusion": "HardcoreLogic揭示了当前大型推理模型的局限性，并为提高高级逻辑推理设定了基准。"}
{"llm_update_time": "20251015", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.12490", "html_url": "https://arxiv.org/abs/2510.12490", "title": "使用医疗算法进行基于LLM的任务导向对话在医学访谈中的应用", "title_en": "Using Medical Algorithms for Task-Oriented Dialogue in LLM-Based Medical Interviews", "authors": "Rui Reis,Pedro Rangel Henriques,João Ferreira-Coimbra,Eva Oliveira,Nuno F. Rodrigues", "background": "本文介绍了一个基于LLM的任务导向对话框架，用于医学访谈。该框架旨在优化临床对话流程，提高医生和患者在访谈中的用户体验。它通过将医疗算法和指南系统地转化为临床问题库，并结合冷启动机制、扩展和修剪机制、终止逻辑和自动化总结生成机制来实现这一目标。研究设计还受到人机交互原则的指导，旨在开发用户友好的患者和医生应用程序。初步评估利用了标准工具，如NASA-TLX、SUS和QUIS来评估系统的工作负载、易用性和用户满意度。此框架的背景在于现有医疗访谈过程中存在效率低下和用户体验不佳的问题。希望通过引入先进的人机交互技术和对话系统提升整体体验和效率。", "innovation": "本文提出了一种任务导向对话框架，该框架主要创新点包括：1) 利用多层次语义理解和知识结构设计了一个基于DAG结构的对话系统；2) 引入了冷启动机制和扩展-修剪机制来动态匹配患者反馈和逐步构建对话路径；3) 设计了终止逻辑确保访谈过程终止时机恰当；4) 开发了自动化技术来生成医生友好的结构化报告，与临床工作流程紧密结合。这些创新使得系统能够更加高效和智能地进行医疗访谈。", "conclusion": "初步研究结果表明，该系统在减轻医生和患者的工作负荷和提高系统易用性方面表现出色。患者应用在NASA-TLX、SUS和QUIS方面的得分分别为15.6、86和8.1/9，医生应用在NASA-TLX、SUS和满意度方面的得分分别为26、88.5和8.3/9。总体来看，该框架能够有效整合到临床流程中，降低了认知负担，并支持了高效摘要生成。然而，研究还存在系统延迟和样本量不足的问题，这可能限制了系统的广泛应用。未来可以进一步优化系统响应速度，扩展用户样本以提升应用的普适性和稳健性。"}
{"llm_update_time": "20251015", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.12693", "html_url": "https://arxiv.org/abs/2510.12693", "title": "ERA: 通过感知先验学习和在线强化学习将VLMs转化为具身代理", "title_en": "ERA: Transforming VLMs into Embodied Agents via Embodied Prior Learning and Online Reinforcement Learning", "authors": "Hanyang Chen,Mark Zhao,Rui Yang,Qinwei Ma,Ke Yang,Jiarui Yao,Kangrui Wang,Hao Bai,Zhenhailong Wang,Rui Pan,Mengchao Zhang,Jose Barreiros,Aykut Onol,ChengXiang Zhai,Heng Ji,Manling Li,Huan Zhang,Tong Zhang", "background": "近期具身AI的发展突显了视觉语言模型（VLMs）作为能够在复杂环境中进行感知、推理和互动的代理的潜力。然而，当前表现最好的系统依赖于成本高昂的大规模模型，而较小的VLMs则缺乏必要的知识和技能来成功执行任务。", "innovation": "该论文提出了Embodied Reasoning Agent（ERA），这是一个两阶段框架，结合了先验知识学习和在线强化学习。第一阶段名为Embodied Prior Learning（感知先验学习），通过三种类型的先验数据提取基础知识：1. 轨迹增强先验，通过强模型生成的结构化推理丰富现有的轨迹数据；2. 环境锚定先验，为环境内提供知识和实境监督；3. 外部知识先验，从环境外的数据集中转移一般知识。第二阶段运用在线强化学习构建算法管道，进一步提高代理性能。为解决代理强化学习中的固有问题，如长时视野、稀疏奖励和训练不稳定性，该文提出了三项关键设计：自我总结进行内容管理、密集奖励塑形和回合级策略优化。", "conclusion": "ERA-3B 在EB-ALFRED（高级规划任务）和EB-Manipulation（低级控制任务）中的表现超过了基于提示的大模型和以往基于训练的基线，在EB-ALFRED上实现了8.4%的整体改进，在EB-Manipulation上实现了19.4%的整体改进。ERA提供了一条实用的道路，通往可扩展的具身智能，并为未来的具身AI系统提供了方法论上的洞见。"}
{"llm_update_time": "20251015", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.12697", "html_url": "https://arxiv.org/abs/2510.12697", "title": "多智能体辩论用于自适应稳定性检测的大语言模型法官", "title_en": "Multi-Agent Debate for LLM Judges with Adaptive Stability Detection", "authors": "Tianyu Hu,Zhen Tan,Song Wang,Huaizhi Qu,Tianlong Chen", "background": "随着推理能力的增强，大型语言模型（LLMs）越来越多地被用于自动化评估任务。尽管LLMs-as-Judges提供了自动化评估的潜力，但当前的方法往往依赖于简单聚合方法（例如多数投票），即使每个代理给出正确的答案也可能失败。为了解决这个问题，作者提出了一种多智能体辩论法官框架，其中智能体协作推理并迭代改进他们的响应。", "innovation": "作者引入了一种自适应稳定性检测机制，通过时间变化的Beta-Binomial混合模型来建模法官共识动态，并根据分布相似性（Kolmogorov-Smirnov检验）采用自适应停止标准。该机制使用时间变化的Beta-Binomial混合分布来建模法官群体正确率动态，并采用基于分布相似性的自适应停止标准（Kolmogorov-Smirnov统计）。实验结果表明，该框架提高了评估准确性，同时保持了计算效率。", "conclusion": "与多数投票方法相比，该框架在保持计算效率的同时提高了判断准确性。数学化的辩论过程分析表明，辩论可以增强正确性，相比静态组合方法。"}
{"llm_update_time": "20251015", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.12713", "html_url": "https://arxiv.org/abs/2510.12713", "title": "朝向稳健的人工智能：基于自监督学习的环境外检测方法", "title_en": "Towards Robust Artificial Intelligence: Self-Supervised Learning Approach for Out-of-Distribution Detection", "authors": "Wissam Salhab,Darine Ameyed,Hamid Mcheick,Fehmi Jaafar", "background": "AI系统的稳健性指的是其在各种条件下保持可靠和准确性能的能力，包括环境外（OOD）样本、对抗攻击和环境变化。在关键安全系统中，如自动驾驶车辆、交通或医疗保健，系统故障可能导致严重后果。因此，提高AI系统的稳健性至关重要。", "innovation": "本文提出了一种在无需标记数据的情况下提升ODD检测的方法，通过结合自监督学习原则和图论技术，使得模型能够从未标记数据中学习有用表示，进而更高效地识别和分类OOD样本，与现有前沿技术相比，该方法达到了AUROC=0.99。", "conclusion": "本文介绍了一种基于自监督学习的环境外检测方法，该方法能够在没有标记数据的情况下提高AI系统的稳健性，利用图论技术实现了更高效的OOD样本识别，且在性能上优于现有方法。"}
{"llm_update_time": "20251015", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.12742", "html_url": "https://arxiv.org/abs/2510.12742", "title": "CTRL-Rec: 通过自然语言控制推荐系统", "title_en": "CTRL-Rec: Controlling Recommender Systems With Natural Language", "authors": "Micah Carroll,Adeline Foote,Kevin Feng,Marcus Williams,Anca Dragan,W. Bradley Knox,Smitha Milli", "background": "推荐系统往往为用户提供有限的控制选项，当用户不满意推荐结果时，常缺乏细化的操作手段。大型语言模型提供了新的解决方案，用户可以通过自然语言请求（如“我想要查看与我观点不同的尊重性的帖子”）来指导推荐系统。研究人员提议了一种方法，CTRL-Rec，在保证计算效率的同时实现了对传统推荐系统即时的语义控制。", "innovation": "该方法在训练阶段使用大型语言模型预测用户对项目的支持度，并训练嵌入模型进行近似计算；在部署阶段，使用一次大型语言模型嵌入计算即可针对用户请求即时控制推荐结果。实验显示，CTRL-Rec能够在MovieLens数据集上实现多样请求的细粒度控制，帮助用户获得更满意的推荐结果。", "conclusion": "研究结果表明，该方法提高了用户的控制感和满意度，相对于传统控制手段，用户对CTRL-Rec更为认可。"}
{"llm_update_time": "20251015", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.12732", "html_url": "https://arxiv.org/abs/2510.12732", "title": "Clutch Control: 基于注意力机制的组合型_uc000428768", "title_en": "Clutch Control: An Attention-based Combinatorial Bandit for Efficient Mutation in JavaScript Engine Fuzzing", "authors": "Myles Foley,Sergio Maffeis,Muhammad Fakhrur Rozi,Takeshi Takahashi", "background": "JavaScript引擎在网页浏览器、PDF阅读器和服务器端应用中广泛使用，但安全问题引起关注，促使开发了多种有针对性的模糊测试技术。现有方法通过随机选择在JavaScript代码中的突变位置。我们提出结合组合型多臂赌博机来优化突变目标的选择过程，以提升模糊测试的效果。", "innovation": "CLUTCH是一种新颖的深度组合型多臂赌博机，使用了来自深度学习的注意力机制来观察可变长度的JavaScript测试案例表示形式。此外，CLUTCH还使用了Concrete Dropout动态调整探索行为。实验结果表明，CLUTCH相比三种最先进的解决方案，能够将有效测试案例的数量提高20.3%，每个测试案例的覆盖率提高8.9%。在多变和组合环境中，CLUTCH优于最先进的多臂赌博机，在这两类环境中，减少至少78.1%和4.1%的遗憾。", "conclusion": "CLUTCH在JavaScript引擎模糊测试中显示了更高的效率，能够识别更好的突变目标，提高有效测试案例数量和覆盖率，同时在多变和组合环境中展示了优于传统方法的表现。"}
{"llm_update_time": "20251015", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.12703", "html_url": "https://arxiv.org/abs/2510.12703", "title": "CAMNet: 利用协同感知信息进行车辆轨迹预测", "title_en": "CAMNet: Leveraging Cooperative Awareness Messages for Vehicle Trajectory Prediction", "authors": "Mattia Grasselli,Angelo Porrello,Carlo Augusto Grazia", "background": "自动驾驶是一项具有挑战性的任务，尤其是由于安全问题。现代车辆通常配备了昂贵的传感器，如LiDAR、摄像头和雷达，以降低事故发生的风险。然而，这些传感器存在固有的局限性：其视场和视线可能被其他车辆阻挡，从而降低态势感知能力。在这种情况下，车辆之间的通信变得至关重要，因为它使汽车即使在传感器被阻挡的情况下也能共享信息并保持彼此的感知。一种实现这一目标的方法是使用协同意识消息（CAMs）。本文研究了CAM数据在车辆轨迹预测中的应用。我们设计并训练了一个基于CAM数据的神经网络，名为CAMNet，以用于广泛使用的运动预测数据集。然后，我们使用协同意识消息在另一个我们从头开始创建的数据集中评估了该模型，以评估这种类型的数据是否可以有效利用。研究表明CAMs确实可以支持车辆轨迹预测。同时，我们讨论了该方法的局限性，这指出了对未来研究的机会。", "innovation": "我们设计并训练了一个名为CAMNet的基于CAM数据的图神经网络，用于车辆轨迹预测。我们使用广泛使用的运动预测数据集训练模型，并在我们使用CAM数据创建的新数据集上进行了评估，以验证这种类型数据的有效性。这种方法展示了良好的结果，表明CAMs可以用于车辆轨迹预测。不仅如此，我们还讨论了该方法的局限性，这些局限性为未来的研究指出了方向。", "conclusion": "我们的研究表明，CAMs可以有效支持车辆轨迹预测，但该方法也面临一些局限，表明需要进一步研究以克服这些局限并提高模型性能。"}
{"llm_update_time": "20251015", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.11732", "html_url": "https://arxiv.org/abs/2510.11732", "title": "Serial-Parallel 双路径架构用于说话风格识别", "title_en": "Serial-Parallel Dual-Path Architecture for Speaking Style Recognition", "authors": "Guojian Li,Qijie Shao,Zhixian Zhao,Shuiyuan Wang,Zhonghua Fu,Lei Xie", "background": "现有的说话风格识别方法主要依赖于语言信息，对声学信息的整合有限，这限制了识别准确性的提升。声学和语言模态的融合为提升识别性能提供了潜力。", "innovation": "本文提出了一种新颖的串行并行双路径架构，该架构利用声学-语言双模态信息。串行路径遵循ASR+STYLE串行模式，体现出序列的时间依赖性；并行路径集成了我们设计的声学-语言相似性模块(AlsM)，以促进跨模态交互的同步性。相较于现有的说话风格识别基础模型OSUM，新方法减少了参数量88.4%，并提高了8种风格测试集上说话风格识别的准确率30.3%。", "conclusion": "提出的串行并行双路径架构在说话风格识别上具有显著优势，通过巧妙地融合声学和语言信息，提高了识别性能。"}
{"llm_update_time": "20251015", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.11728", "html_url": "https://arxiv.org/abs/2510.11728", "title": "使用大型语言模型建模超图", "title_en": "Modeling Hypergraph Using Large Language Models", "authors": "Bingqiao Gu,Jiale Zeng,Xingqin Qi,Dong Li", "background": "超图在模拟复杂系统中的高阶关系方面具有优势，并被应用于高阶聚类、超图神经网络和计算机视觉等领域。然而，这些应用依赖于高质量的大量真实世界超图数据，而与传统的成对图相比，真实超图数据集在规模和多样性方面仍然稀缺，这极大地限制了高级超图学习算法的发展和评估。因此，如何快速生成符合真实网络特征的大规模超图成为一个亟待解决的问题，但这一问题尚未得到充分关注。", "innovation": "受大型语言模型（LLMs）近期进展的启发，特别是它们的语义推理、结构生成和模拟人类行为的能力，作者探索了LLMs如何从全新角度促进超图生成。作者提出了HyperLLM，这是一种新颖的基于LLM的超图生成器，通过多智能体协作模拟超图的形成和演变过程。框架中整合了提示和结构反馈机制，以确保生成的超图反映关键的现实世界模式。", "conclusion": "跨多种数据集的广泛实验表明，HyperLLM在实现结构和时间超图模式的高保真度方面表现出色，同时只需要少量统计先验。研究结果表明，基于LLM的框架为超图建模提供了新的有前景的方向。"}
{"llm_update_time": "20251015", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2503.20934", "html_url": "https://arxiv.org/abs/2503.20934", "title": "利用LLMs、IDE和语义嵌入进行自动方法移动重构", "title_en": "Leveraging LLMs, IDEs, and Semantic Embeddings for Automated Move Method Refactoring", "authors": "Fraol Batole,Abhiram Bellur,Malinda Dilhara,Mohammed Raihan Ullah,Yaroslav Zharov,Timofey Bryksin,Kai Ishikawa,Haifeng Chen,Masaharu Morimoto,Shota Motoura,Takeo Hosomi,Tien N. Nguyen,Hridesh Rajan,Nikolaos Tsantalis,Danny Dig", "background": "尽管存在众多推荐哪段代码需要移动以及移动到何处的研究工具，但这些推荐与专家开发者进行方法移动重构时的实际做法并不一致。大型语言模型（LLMs）经过了大量训练，并依赖于代码的自然表达，因此它们应该能够准确推荐哪些方法在特定类中是错位的，以及哪些类是更好的宿主。然而，研究发现2016年LLMs的推荐中有高达80%的建议是不准确的。因此，该研究旨在开发一个完全由LLM支持的智能助手MM-assist，用于方法移动重构的全过程，从推荐到执行。", "innovation": "该研究引入了第一个自动过滤LLM幻觉并使LLMs保持自洽、自省和排名的创新解决方案。此外，通过使用增强检索生成（RAG）结合重构感知，解决了LLMs的有限上下文大小问题。该方法MM-assist综合了LLM、IDE、静态分析和语义相关性的优势，在多方法论的实证评估中表现出色，显著优于现有的最佳方法。", "conclusion": "MM-assist在重构推荐方面表现优异：在研究人员广泛使用的基准测试中，Recall@1和Recall@3指标提高了1.7倍；在开源软件中的210个最近重构示例中，召回率提高了至少2.4倍。此外，用户研究显示，30名经验丰富的参与者中有82.8%积极评价了MM-assist的推荐，证实了其有效性和实用性。"}
{"llm_update_time": "20251015", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.12787", "html_url": "https://arxiv.org/abs/2510.12787", "title": "Ax-Prover：数学与量子物理中定理证明的深度推理代理框架", "title_en": "Ax-Prover: A Deep Reasoning Agentic Framework for Theorem Proving in Mathematics and Quantum Physics", "authors": "Marco Del Tredici,Jacob McCarran,Benjamin Breen,Javier Aspuru Mijares,Weichen Winston Yin,Jacob M. Taylor,Frank Koppens,Dirk Englund", "background": "现有的自动定理证明系统主要集中在专用系统上，这些系统难以在不同科学领域之间进行泛化。论文介绍了一个名为Ax-Prover的多代理系统，该系统可以在Lean环境中解决跨学科的科学问题，并且可以独立工作或与人类专家协作。Ax-Prover通过形式证明生成来解决科学问题，这种过程需要创造性的推理和严格的语法精确性。该系统利用大型语言模型（LLMs）提供知识和推理，并通过模型上下文协议（MCP）与Lean工具结合，以确保形式正确性。该研究通过在数学和量子理论领域的新基准测试中与先进LLMs和专门证明系统进行对比，评估了Ax-Prover作为自治证明器的表现，结果显示在新基准测试中其表现优于现有最先进的系统。通过实用案例展示了Ax-Prover作为助手的能力，帮助一位专家对复杂的密码学定理进行了形式化证明。", "innovation": "引入了Ax-Prover多代理系统，该系统能够通过结合大型语言模型和Lean工具，提供一种通用的方法来进行形式验证，这在不同科学领域中有广泛应用。创新点在于实现了自动化形式证明与人类专家协作的可能性，特别是在数学和量子理论领域的新基准测试中展示了Ax-Prover的有效性，并且该系统的表现优于专门系统的通用性。", "conclusion": "Ax-Prover提供了一种能够跨不同科学领域进行形式验证的可移植方法。它显示了它在新的基准测试中的优越性，相比专门系统更具有灵活性和通用性。此外，该系统展示了它作为专家助手的实际应用场景，证明了其在实际工作中的价值。"}
{"llm_update_time": "20251015", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.11734", "html_url": "https://arxiv.org/abs/2510.11734", "title": "在大语言模型模拟人格中的人口法则：只需更详细和逼真的人格档案", "title_en": "Scaling Law in LLM Simulated Personality: More Detailed and Realistic Persona Profile Is All You Need", "authors": "Yuqi Bai,Tianyu Huang,Kun Sun,Yuting Chen", "background": "该研究聚焦于使用大规模语言模型（LLMs）来模拟社会实验，并探索其在虚拟角色饰演中模拟人类个性的能力。传统心理测量方法（如CFA和构造效度）无法捕捉LLMs在低层级模拟过程中的进步趋势，可能导致过早的拒绝或方法论的错位。研究认为需要开发一种全面的评估框架来系统地评估LLMs在模拟人类个性方面的表现，并强调了虚拟角色详细程度对个性模拟质量的重要性，以及发现LLMs在个性模拟中存在边际效益效果，特别是提出了人口法则作为理论基础和操作性评价指标，以应用于社会科学研究中。", "innovation": "该研究提出的贡献包括：1. 建立了一个全面的评估框架来系统地评估LLMs在模拟人类个性方面的表现；2. 实证展示了虚拟角色细节对于人格模拟质量的关键作用；3. 发现了LLMs在个性模拟中的边际效益效应，并提出了人口法则，为科学应用提供了理论基础和操作性评价指标。", "conclusion": "研究证实，只需详细的和个人档案，就能提高LLMs在社会科学研究实验中的模拟准确性。提出了潜在的应用LLMs的方法，以及需要改进的评估技术，以适应其在模仿人类个性方面的能力和改进轨迹。"}
{"llm_update_time": "20251015", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.11754", "html_url": "https://arxiv.org/abs/2510.11754", "title": "零射程大型语言模型代理用于完全自动的放射疗法治疗计划", "title_en": "Zero-Shot Large Language Model Agents for Fully Automated Radiotherapy Treatment Planning", "authors": "Dongrong Yang,Xin Wu,Yibo Xie,Xinyi Li,Qiuwen Wu,Jackie Wu,Yang Sheng", "background": "放射疗法治疗计划是一个迭代且依赖专家知识的过程，随着癌症病例的增加，手工计划的依赖性变得越来越难以维持，这就强调了需要自动化的需求。", "innovation": "该研究提出了一种工作流，利用基于大型语言模型（LLM）的代理来导航逆向治疗计划用于强度可调的放射疗法（IMRT）。LLM代理直接与临床治疗计划系统（TPS）交互，通过迭代提取中间计划状态并提出新的约束值来指导逆向优化。代理的决策机制受到当前观察和以前优化尝试和评估的指导，允许策略的动态改进。在零样训练设置下进行了规划过程，即LLM在没有接触手动生成的治疗计划的情况下运作，且未进行任何微调或任务特定的训练。评估结果显示，LLM生成的计划在器官危险区域(OAR)保护方面与临床计划相当，但在热点控制（Dmax）和适应性方面优于临床计划。", "conclusion": "该研究证明了零样全自动LLM驱动的工作流程在商业TPS中用于自动化IMRT治疗计划的可行性。提出的这种方法提供了一种可推广且临床适用的解决方案，可以减少计划变异性和支持AI计划策略更广泛的采用。"}
{"llm_update_time": "20251015", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.11739", "html_url": "https://arxiv.org/abs/2510.11739", "title": "使用Twitter跟随者发布内容进行乌尔都语名人画像", "title_en": "Celebrity Profiling on Short Urdu Text using Twitter Followers' Feed", "authors": "Muhammad Hamza,Rizwan Jafar", "background": "社交媒体已成为数字时代不可或缺的一部分，用作沟通、互动和信息共享的平台。名人是其中最活跃的用户之一，经常通过在线帖子分享个人和职业生活的细节。平台如Twitter提供了分析语言和行为的机会，以理解和识别社会模式。追随者通常与他们跟随的名人的语言特征和兴趣相似，因此，可以从追随者的文本数据中预测名人的人口统计信息。现有研究主要集中在英语和其他高资源语言上，而乌尔都语却鲜有研究.", "innovation": "本研究应用现代机器学习和深度学习技术，针对乌尔都语名人画像的问题。收集并预处理了次大陆名人体微的乌尔都语短文本数据集，并训练和比较了多种算法，包括逻辑回归、支持向量机、随机森林、卷积神经网络和长短期记忆网络。研究结果显示，可有效地使用机器学习和神经方法预测乌尔都语中的名人生理特征，虽然这些方法在低资源语言上较为新颖。", "conclusion": "研究发现，追随者 linguistic 特征可以通过机器学习和神经方法有效地用于预测乌尔都语中的名人生理特征，尽管乌尔都语是一种低资源语言，预测性别表现最佳，cRank 为 0.65，准确率 0.65，进一步研究年龄、职业和知名度预测也表现较为理想。这表明可以从追随者的语言特征中预测名人的社会统计信息，对低资源语言中的名人分析具有重要意义。"}
{"llm_update_time": "20251015", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.11738", "html_url": "https://arxiv.org/abs/2510.11738", "title": "SeeingSounds: 通过文本学习音视频对齐", "title_en": "SeeingSounds: Learning Audio-to-Visual Alignment via Text", "authors": "Simone Carnemolla,Matteo Pennisi,Chiara Russo,Simone Palazzo,Daniela Giordano,Concetto Spampinato", "background": "当前的音频到图像生成框架通常需要配对的音视频数据或视觉生成模型的训练数据，这限制了其应用范围和效率。本文提出了一个轻量级的模块化框架SeeingSounds，它不依赖于配对数据或视觉生成模型的训练，而是利用了音频、语言和视觉之间的互动关系，通过冻结的语言编码器将音频投影到语义语言空间，并通过视觉语言模型将其接地到视觉领域，实现了高效的、可扩展的学习，并支持细粒度和可解析的控制。这种方法基于认知神经科学，反映了人类跨模态感知的自然关联。", "innovation": "提出了一种全新的轻量级模块化框架SeeingSounds，它不需要配对的音视频数据或视觉生成模型的训练，而是利用了音频、语言和视觉之间的互动关系进行音频到图像的生成。方法通过冻结的语言编码器将音频投影到语义语言空间，并通过视觉语言模型将其接地到视觉领域。此外，通过程序文本提示生成支持细粒度和可解释的控制，通过音轨转换（例如音量或音高）转化为描述性提示（例如“远处的雷声”）来引导视觉输出。实验结果表明，SeeingSounds在标准基准测试中的零样本和监督设置中均优于现有方法，确立了可控音视频生成的新基准。", "conclusion": "SeeingSounds通过冻结的扩散模型骨架和轻量级适配器进行高效且可扩展的学习，实现了比现有方法更好的音视频生成性能。该方法支持细粒度和可解释的控制，通过音转换和文本提示生成来指导视觉输出，显示出在可控音频到视觉生成领域的显著优势。"}
{"llm_update_time": "20251015", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.11758", "html_url": "https://arxiv.org/abs/2510.11758", "title": "中国与北美兽医人工智能采用悖论：比较分析", "title_en": "The Adoption Paradox: A Comparative Analysis of Veterinary AI Adoption in China and the North America", "authors": "Shumin Li,Xiaoyun Lai", "background": "本文对比了中国和北美兽医专业人士对人工智能(AI)的感知、采用和应用情况，研究假设采用模式受到区域市场和人口统计因素的影响。研究通过对2025年5月至7月间在中国的455名兽医专业人士进行描述性、横断面调查，并将结果与中国和北美地区3968名兽医专业人士在2024年的调查数据进行了比较，揭示了两者在AI采用上的差异。", "innovation": "研究表明，虽然中国兽医在AI应用上表现出高的采纳率但低熟悉率，重点在临床任务；而北美兽医虽然高度熟悉但较低的采纳率，重点在行政管理任务。主要障碍都是对AI可靠性和准确性的担忧。文章还发现了采用悖论现象：中国市场表现出自下而上的实践推动型采用模式，重点增强临床效率；而北美市场则表现出更为谨慎，自上而下的结构化整合，重点关注行政效率提升。研究建议采用一致性策略是不足的，需要定制、区域特定的策略来负责任地将AI整合到全球兽医实践中", "conclusion": "本文揭示了中国与北美在兽医人工智能采用上的主要差异，并提出了采用悖论现象。研究结果表明，不同区域的市场和人口特征对AI的采用模式产生重要影响，强调了定制化策略的重要性。"}
{"llm_update_time": "20251015", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.11760", "html_url": "https://arxiv.org/abs/2510.11760", "title": "Audio-Guided Visual Perception for Audio-Visual Navigation", "title_en": "Audio-Guided Visual Perception for Audio-Visual Navigation", "authors": "Yi Wang,Yinfeng Yu,Fuchun Sun,Liejun Wang,Wendong Zheng", "background": "现有的音频-视觉导航（AVN）方法在识别已知声源方面表现良好，但在面对未见过的声音或未知环境时，导航成功率会显著下降，探索路径也变得过长。这一现象源于音频信号和相关视觉区域之间缺乏明确的对齐机制，导致代理在遇到新声音时无法有效利用视觉信息，从而出现盲目的探索。", "innovation": "本文提出了AGVP框架，将声音转化为策略易于记忆的空间引导信息。该框架首先通过音频自注意力机制提取全局音频上下文，然后利用此上下文作为查询引导视觉特征注意力，进一步在特征级别突出显示与声音来源相关的区域。随后进行时序建模和策略优化。这种设计理念强调可解释的跨模态对齐和区域加权，减少了对特定音频指纹的依赖。实验证明，AGVP提高了导航效率和鲁棒性，并在处理未听过的声音时实现了更优异的跨场景泛化能力。", "conclusion": "研究结果表明，AGVP框架不仅提高了音频-视觉导航的效率和鲁棒性，还在面对未听过的声音时实现了更优秀的跨场景泛化能力。"}
{"llm_update_time": "20251015", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.11759", "html_url": "https://arxiv.org/abs/2510.11759", "title": "AwareCompiler：利用协同知识数据驱动框架的感知上下文感知编译器优化", "title_en": "AwareCompiler: Agentic Context-Aware Compiler Optimization via a Synergistic Knowledge-Data Driven Framework", "authors": "Hongyu Lin,Haolin Pan,Haoran Luo,Yuchen Li,Kaichun Yao,Libo Zhang,Mingjie Xing,Yanjun Wu", "background": "编译器优化对于增强程序性能至关重要，通过转换优化流程序列来实现，同时保持正确性。尽管基于大型语言模型（LLMs）的代理在软件优化方面具有巨大潜力，但自动编译器优化仍然具有挑战性，原因包括：（1）抽象程序表示与具体优化步骤之间语义的不匹配；（2）代理与编译器环境交互机制效率低下；（3）大规模优化空间内决策过程导致奖励稀疏性。现有的框架尚未有效解决这些问题，论文旨在通过提出AwareCompiler这一新的代理优化框架来应对这些挑战。", "innovation": "AwareCompiler通过以下三项创新来解决上述挑战：知识结构化整合和数据集构建，知识驱动的自适应优化步骤生成，以及数据驱动的混合训练管道。实验结果显示，AwareCompiler在标准基准测试中显著优于现有基线模型，在性能和效率方面都有显著提升，证明了知识和数据协同驱动方法的有效性。", "conclusion": "实验结果表明，AwareCompiler在标准基准测试中显著超越现有基线，在性能和效率方面表现出色，强调了其知识和数据协同驱动方法的有效性。代码已公开，可以在提供的链接中访问。"}
{"llm_update_time": "20251015", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.11755", "html_url": "https://arxiv.org/abs/2510.11755", "title": "最佳学习的人工智能：AI增强学习环境的比较方法", "title_en": "Artificial Intelligence for Optimal Learning: A Comparative Approach towards AI-Enhanced Learning Environments", "authors": "Ananth Hariharan", "background": "在全球教育格局快速演变的背景下，技术的融合已经从提升手段转变为教育战略的核心支柱。这一转变受到了数字技术进步的推动，尤其是人工智能（AI）作为学习环境关键工具的出现。研究项目深入评价了三种不同的教育环境：传统教育方法不涉及技术整合、部分采用非AI技术增强传统课堂、以及利用AI驱动技术的环境对教育结果、学生参与度、教学方法和学习资源获取公平性的影响。研究旨在整合每种模式的优点，构建一个更全面的教育方法。通过结合传统教室中的个性化互动和经验证的教学方法、非AI技术支持的增强的可及性和协作工具，以及AI驱动技术提供的个性化、适应性学习策略，教育系统可以开发出更加丰富、有效的学习环境。这种方法旨在利用每种模式的最优点，从而提高教育成果、参与度和包容性，同时解决每种模式固有的独特挑战和限制。研究旨在为所有学生提供高质量教育的公平途径，满足其多样化需求，", "innovation": "本研究通过比较分析三种不同教育环境，包括无技术整合的传统教育、非AI技术增强的传统教育以及利用AI驱动技术的教育模式，来评估其对教育结果、学生参与度、教学方法和学习资源获取公平性的影响。研究旨在整合每种模式的优点，构建一个更全面的教育方法，利用传统教室中的个性化互动和经验证的教学方法、非AI技术支持的增强的可及性和协作工具，以及AI驱动技术提供的个性化、适应性学习策略，从而开发出更加丰富、有效的学习环境，提升教育成果、参与度和包容性，同时解决每种模式固有的独特挑战和限制。", "conclusion": "通过整合每种教育模式的优势，本研究旨在建立一个深度关注学生多样化需求的教育框架，确保所有学生都能平等地获得高质量的教育资源，从而提高教育的整体效果。"}
{"llm_update_time": "20251015", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.11812", "html_url": "https://arxiv.org/abs/2510.11812", "title": "PHANTOM RECALL：当熟悉的问题愚弄了聪明的模型", "title_en": "PHANTOM RECALL: When Familiar Puzzles Fool Smart Models", "authors": "Souradeep Mukhopadhyay,Rishabh Baral,Nimeesh Mahajan,Samhitha Harish,Aswin RRV,Mihir Parmar,Mutsumi Nakamura,Chitta Baral", "background": "大型语言模型（LLMs）如GPT、Gemini和Claude通常擅长解答经典逻辑谜题，但它们的答案背后有多少真正的推理能力？最新研究显示，这些模型往往依赖记忆中的模板而非从基本原理进行推理。当谜题稍做修改时，它们的表现会迅速下滑，显示出显著的脆弱性。", "innovation": "为了系统性地研究这些问题，论文引入了PHANTOM RECALL基准，包括25个著名的逻辑谜题和149个精心设计的修改版本，这些版本保留了推理结构但修改了表面细节和解决方案。评估了11种领先的大语言模型，并识别出一种重现模式——幻象回忆，即模型自信地模仿记忆中的解决方案或与修改后的场景不符的无效理由。此外，还提供了三个工具：自动逻辑等价判断器、详细的推理错误分类税法，以及一个基于这些类别的提示引导的缓解框架。", "conclusion": "尽管在未修改的谜题中接近完美准确，模型在修改后谜题中表现明显不如人类，既展示了幻象回忆，又表现出过度发挥的现象。研究揭示了一个关键局限：LLMs往往在情境线索发生变化时无法重新推理，凸显了语言流利性和逻辑理解之间的差距。"}
{"llm_update_time": "20251015", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.11769", "html_url": "https://arxiv.org/abs/2510.11769", "title": "GAR: Generative Adversarial Reinforcement Learning for Formal Theorem Proving", "title_en": "GAR: Generative Adversarial Reinforcement Learning for Formal Theorem Proving", "authors": "Ruida Wang,Jiarui Yao,Rui Pan,Shizhe Diao,Tong Zhang", "background": "通过可验证语言（如Lean）求解数学问题对数学和计算机科学领域产生了显著影响。当前最先进的模型经常使用昂贵的在线强化学习（RL）或专家迭代进行训练。然而，这些方法依赖于固定的问题集，导致训练效率低下，并限制了模型处理复杂问题的能力。", "innovation": "我们提出了GAR：生成对抗强化学习，这是一种综合的RL训练框架，能够同时训练问题生成者和解题者，并在对抗循环中共同提升。GAR引入了一种隐含的课程学习机制，将任务难度与证明者不断发展的能力相匹配，从而提高了训练效率并增强了证明高级定理的能力。实验表明，在使用GAR训练后，Goedel-Prover-V2-8B和DeepSeek-Prover-V2-7B在MiniF2F-Test基准上的pass@32平均相对改进了4.20%，而DeepSeek-Prover-V2在ProofNet-Test上的pass@32从22.58%提高到25.81%。GAR还为在可验证环境中问题生成与解题的共同进化建立了通用的RL范式。", "conclusion": "GAR框架通过生成对抗强化学习机制，提高了证明复杂定理的效率和性能，适用于更广泛的验证环境下的问题生成与解题的共同进化。"}
{"llm_update_time": "20251015", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.11752", "html_url": "https://arxiv.org/abs/2510.11752", "title": "基于最优传输的快速且可解释的蛋白质亚结构对齐", "title_en": "Fast and Interpretable Protein Substructure Alignment via Optimal Transport", "authors": "Zhiyu Wang,Bingxin Zhou,Jing Wang,Yang Tan,Weishu Zhao,Pietro Liò,Liang Hong", "background": "蛋白质是执行生命功能的重要生物大分子。蛋白质结构中的局部基序，如活性位点，是将结构与功能联系起来的最关键部分，对于理解蛋白质进化和蛋白质工程至关重要。现有的计算方法在识别和比较这些局部结构方面存在困难，这留下了一个理解蛋白质结构和利用其功能的重要空白。", "innovation": "本研究提出了PLASMA，第一个用于有效和可解释的残基级蛋白质亚结构对齐的深度学习框架。通过将问题重新定义为正则化最优传输任务，并利用可微Sinkhorn迭代，PLASMA能够为输入蛋白质结构对输出一个清晰的对齐矩阵和有解释性的整体相似度评分。通过广泛的定量评估和三个生物案例研究，我们证明了PLASMA实现了准确、轻量且可解释的残基级对齐。此外，还引入了PLASMA-PF，一种无需训练的变体，在缺乏训练数据的情况下提供了一种实用的替代方案。这种方法填补了蛋白质结构分析工具中的关键空白，为功能性注释、进化研究和基于结构的药物设计提供了新的机会。", "conclusion": "我们的方法通过官方实现确保了可重现性，在蛋白质结构分析工具中具有重要的应用价值，并为后续的研究提供了新的可能性。"}
{"llm_update_time": "20251015", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.11823", "html_url": "https://arxiv.org/abs/2510.11823", "title": "BlackIce: 一种针对AI安全测试的容器化红队工具包", "title_en": "BlackIce: A Containerized Red Teaming Toolkit for AI Security Testing", "authors": "Caelin Kaplan,Alexander Warnecke,Neil Archibald", "background": "随着AI模型被越来越多地集成到实际系统中，人们对其安全性和安全性提出了严重关切。这促使AI红队变得至关重要，组织需要主动识别和解决潜在的漏洞，以免被对手利用。尽管目前存在大量的AI红队工具，但从业者在从快速增长的工具环境中选择合适的工具时面临挑战，同时也难以管理和解决孤立项目中的复杂且经常冲突的软件依赖关系。鉴于这些挑战和拥有专用AI红队的组织数量较少，有必要降低进入门槛，并建立一个标准化的环境，简化全面的AI模型评估的设置和执行。", "innovation": "引入BlackIce，一种基于Kali Linux设计理念的开源容器化工具包，用于对大型语言模型（LLMs）和经典机器学习（ML）模型进行红队测试。BlackIce提供了一个可再现、已固定版本的Docker镜像，其中集成了14个精心选择的开源工具，支持负责任的AI和安全测试，可通过统一的命令行界面访问。容器的模块化结构使其易于社区驱动的扩展，以适应新的威胁。", "conclusion": "本研究描述了容器镜像的架构、工具选择过程以及它们支持的评估类型，旨在简化AI安全测试的流程和提高从业人员的效率。"}
{"llm_update_time": "20251015", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.11827", "html_url": "https://arxiv.org/abs/2510.11827", "title": "结合欧几里得和双曲表示的节点级异常检测", "title_en": "Combining Euclidean and Hyperbolic Representations for Node-level Anomaly Detection", "authors": "Simone Mungari,Ettore Ritacco,Pietro Sabatino", "background": "节点级异常检测（NAD）由于具有多样化的结构模式和特征分布而具有挑战性。因此，NAD 在多个应用领域中是一个重要的任务，包括欺诈检测、网络安全、推荐系统等。然而，现有的方法在处理复杂结构时往往表现不佳，这使得需要提出一种能够弥补这些不足的框架。", "innovation": "提出了一种名为Janus的框架，该框架结合使用欧几里得和双曲图神经网络来捕捉节点表示的互补方面。每个节点由两个嵌入欧几里得和双曲空间的视图组成，这些视图包括原始特征和通过随机行走和度数导出的结构特征。Janus采用多图自编码器框架，并配以对比学习目标作为正则化项，使欧几里得和双曲空间中的嵌入对齐，从而突出那些难以协调的视图，这些节点很可能是异常的。实验结果表明，Janus在四个真实世界数据集上的一致性能优于浅层和深层基线方法，从而证明了结合多种几何表示是识别图中细微而复杂的异常的有效且稳健的方法。", "conclusion": "研究结果表明，Janus框架在节点级异常检测中提供了稳健和有效的解决方案，不仅能够识别复杂图形中的细微异常，还能够在多方面展现优势，验证了结合欧几里得和双曲几何表示的有效性。"}
{"llm_update_time": "20251015", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.11835", "html_url": "https://arxiv.org/abs/2510.11835", "title": "数据还是语言监督：是什么让CLIP比DINO更好？", "title_en": "Data or Language Supervision: What Makes CLIP Better than DINO?", "authors": "Yiming Liu,Yuhui Zhang,Dhruba Ghosh,Ludwig Schmidt,Serena Yeung-Levy", "background": "CLIP在视觉语言模型（VLMs）中作为视觉编码器的表现优于自监督模型如DINO，但仍不清楚这种优势是来源于CLIP的语言监督还是其更大的训练数据量。为了分离这些因素，研究者在控制条件下对CLIP和DINO进行了预训练，结果显示两种模型具有相似的ImageNet准确度。CLIP在高层次语义（例如物体类别、文本）捕捉方面表现更好，而DINO则更敏感于低级别特征（如颜色和样式）。在20个VQA基准测试中的综合评估发现，CLIP在文本密集型任务中表现更优，而DINO在视觉中心型任务中稍占优势。语言监督的不同变体（如Sigmoid损失、预训练语言编码器）仅带来有限的提升。", "innovation": "在控制条件下对CLIP和DINO进行预训练，实现类似ImageNet准确度的结果；通过透视两种模型在高层次语义和低级别特征上的差异，进一步探究CLIP和DINO各自的特性，并将其应用于VLM评估中。", "conclusion": "研究结果提供了关于视觉编码器设计及其对VLM性能影响的科学见解，指出视觉编码器的优异表现可能更多地依赖于其强大的特征表示而非语言监督。"}
{"llm_update_time": "20251015", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.11824", "html_url": "https://arxiv.org/abs/2510.11824", "title": "合作多智能体强化学习中稳健性和弹性的实证研究", "title_en": "Empirical Study on Robustness and Resilience in Cooperative Multi-Agent Reinforcement Learning", "authors": "Simin Li,Zihao Mao,Hanxiao Li,Zonglei Jing,Zhuohang bian,Jun Guo,Li Wang,Zhuoran Han,Ruixiao Xu,Xin Yu,Chengdong Ma,Yuqing Ma,Bo An,Yaodong Yang,Weifeng Lv,Xianglong Liu", "background": "在合作多智能体强化学习（MARL）中，通常会在理想的模拟环境中调整超参数以最大化合作性能。然而，用于合作的策略在面临真实世界不确定性时往往缺乏稳健性和恢复能力。要构建可信赖的MARL系统，必须深入了解这一的能力，即在不确定性下保持稳定性和恢复不确定性的能力，后者在控制系统中被大量研究但在MARL中被忽视。本研究通过大量实验评估了4个真实环境、13种不确定类型和15个超参数下的合作、稳健性和恢复能力。", "innovation": "本研究通过大规模实证研究，首次系统性地评估了合作、稳健性和恢复能力在真实环境和不确定性下的表现。研究发现，超参数调整对建立可信赖的MARL系统至关重要，表现出一些出乎意料的效果，如参数共享、GAE和PopArt可能会损害稳健性，而提前停止训练、高评论家学习率和Leaky ReLU则具有帮助作用。研究还发现，稳健性和恢复能力在不同环境中和不同的智能体范围内表现差异显著，优化超参数能够显著提升合作、稳健性和恢复能力。此外，这一现象在各种MARL框架下得到了推广，也适用于各种鲁棒性MARL方法。", "conclusion": "本研究揭示了在不同不确定性类型的环境和智能体范围下，合作、稳健性和恢复能力的变化规律，指出优化超参数对提高MARL系统稳健性和恢复能力的重要性，并提供了一些策略以提升MARL系统的可信赖性。"}
{"llm_update_time": "20251015", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.11837", "html_url": "https://arxiv.org/abs/2510.11837", "title": "Countermind：大型语言模型的多层安全架构", "title_en": "Countermind: A Multi-Layered Security Architecture for Large Language Models", "authors": "Dominik Schwarz", "background": "大型语言模型（LLM）应用程序的安全性受到‘形式先行’攻击（如提示注入和监狱破解）的挑战，这些攻击将恶意指令嵌入用户输入中。传统的防御措施往往依赖于事后输出过滤，但它们通常是脆弱的，无法解决根本原因：模型无法区分可信指令与不受信任的数据。", "innovation": "该论文提出了Countermind，一种多层次的安全架构，旨在将防御从被动的、事后防御的姿态转变为主动的、推理中的和推理前的强制执行模型。架构包括：(1) 语义边界逻辑（SBL）及其与时间相关的文本加密器，旨在减少明文提示注入攻击面；(2) 参数空间限制（PSR）机制，利用表示工程原理，动态控制LLM对内部语义簇的访问权限，以减少语义漂移和危险的新兴行为；(3) 安全的自我调节内核，使用OODA循环和学习安全模块，根据不可变的审计日志适应其防御措施；(4) 多模态输入沙盒和上下文防御机制，以应对非文本数据和长期语义中毒的威胁。", "conclusion": "论文制定了一个评估计划，旨在量化提议的架构在减少形式先行攻击成功率方面的有效性，并衡量其可能的延迟开销。"}
{"llm_update_time": "20251015", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.11903", "html_url": "https://arxiv.org/abs/2510.11903", "title": "集成序列模型和关系模型的用户事件：数据集和预测任务", "title_en": "Integrating Sequential and Relational Modeling for User Events: Datasets and Prediction Tasks", "authors": "Rizal Fathony,Igor Melnyk,Owen Reinert,Nam H. Nguyen,Daniele Rosa,C. Bayan Bruss", "background": "用户事件建模在许多机器学习应用中扮演着中心角色，涉及电子商务、社交媒体、金融、网络安全等多个领域。用户事件可以被广泛归类为个人事件和关系事件。当前，这两种事件通常分别使用序列方法和图方法建模，但在实际系统中需要捕捉两种事件类型的情况时，以往的工作却很少将它们结合起来。这是因为一种方便的简化假设认为，用户行为可以用序列或图单一形式化表示。因此，迫切需要包含个人和关系事件的数据集和预测任务，以填补这一空白并推动集成建模的发展。", "innovation": "本文介绍了一组此类数据集，提出了统一的形式化方法，并实验证明结合这两种事件类型可以提高模型的效果。研究表明当前方法仍有提升空间。作者释放这些资源以支持统一用户事件建模的研究，并鼓励在此方向上取得进展。", "conclusion": "研究结果表明，当前方法在用户事件模型中仍存在改进的空间，文章提供的数据集和统一形式化为未来的研究提供了支持。"}
{"llm_update_time": "20251015", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.11883", "html_url": "https://arxiv.org/abs/2510.11883", "title": "Anatomically Aware Self-Supervision for Mammographic Images", "title_en": "MammoDINO: Anatomically Aware Self-Supervision for Mammographic Images", "authors": "Sicheng Zhou,Lei Wu,Cao Xiao,Parminder Bhatia,Taha Kass-Hout", "background": "自监督学习（SSL）已经在通用领域改变了视觉编码器的训练，但在医学成像领域尚未充分利用，这主要是由于数据有限和学科特定的偏差。乳腺X线摄影是医学成像中的一种重要方式，但受限于数据有限，这类技术的应用受限。文章提出了一种名为MammoDINO的新颖SSL框架，用于乳腺X线摄影，并在140万张乳腺X线图像上进行预训练。该框架通过结合解剖结构信息与2D预训练在3D数字乳腺断层成像(DBT)结构利用方面的创新，使得预训练模型能够学习到更有临床意义的特征，从而有效解决了数据稀少的问题并提高了模型的性能。", "innovation": "文章提出了一种新的SSL框架MammoDINO，该框架利用了解剖学感知的数据增强采样方法，在图像级别和区域级别上实现监督，并提出了利用3D DBT结构的跨层对比学习目标。这些创新使得MammoDINO不仅能够用于乳腺癌筛查任务，在多个基准数据集上也表现出色，而且为多用途计算机辅助诊断（CAD）工具提供了可扩展且无需人工标注的基础，有助于减轻放射科医生的工作负担并提高乳腺癌筛查的诊断效率。", "conclusion": "MammoDINO框架已经在多个乳腺癌筛查任务中达到了最佳性能，并且具有良好的跨基准数据集泛化能力。它提供了一种可扩展、无需标注的基础架构，为乳腺X线图像的多用途CAD工具的开发提供了支持，有助于减轻放射科医生的工作负担并提高乳腺癌筛查的诊断效率。"}
{"llm_update_time": "20251015", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.11928", "html_url": "https://arxiv.org/abs/2510.11928", "title": "数据层次上的差异检测：朝向一致的多语言问答", "title_en": "Discrepancy Detection at the Data Level: Toward Consistent Multilingual Question Answering", "authors": "Lorena Calvo-Bartolomé,Valérie Aldana,Karla Cantarero,Alonso Madroñal de Mesa,Jerónimo Arenas-García,Jordan Boyd-Graber", "background": "多语言问答系统需要确保不同语言之间的一致性，尤其是在处理诸如'胆红素症是什么？'这样的客观问题时。同时，这些系统还需要考虑文化差异对主观响应的影响。现有系统在多语言环境下的事实性和文化一致性方面存在挑战，特别是在处理敏感文化问题时（例如，谁在接生中提供帮助？）存在的地区差异和情境变化。因此，本研究旨在开发一种用户参与的检查管道MIND，以在多语言问答知识库中检测事实和文化差异。", "innovation": "提出了MIND，一种用户参与的检查管道，用于在多语言问答知识库中检测事实和文化差异。MIND特别关注识别因地区和情境不同而产生分歧的文化敏感问题的答案。评估MIND在母婴健康领域的双语问答系统上，并且发布了一份双语问题数据集，其中标注了事实和文化的不一致之处。此外，MIND在其他领域进行测试，以评估其泛化能力。", "conclusion": "MIND能够在各种情况下可靠地识别出不一致之处，为开发更加文化意识强和事实准确的问答系统提供了支持。"}
{"llm_update_time": "20251015", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.11926", "html_url": "https://arxiv.org/abs/2510.11926", "title": "使用紧凑型、无传感器依赖且可迁移学习的仅解码器变换器进行室内定位", "title_en": "Indoor Localization using Compact, Telemetry-Agnostic, Transfer-Learning Enabled Decoder-Only Transformer", "authors": "Nayan Sanjay Bhatia,Pranay Kocheta,Russell Elliott,Harikrishna S. Kuttivelil,Katia Obraczka", "background": "室内Wi-Fi定位由于无线信号高度敏感的环境动态、信道传播特性和硬件异构性，仍然是一个具有挑战性的问题。传统指纹识别和模型导向的方法通常需要耗费大量劳动力进行校准，当设备、信道或部署条件发生变化时，性能会迅速下降。因此，找到一种无需大量校准且能够在多样化的Wi-Fi部署中保持高精度的室内定位方法成为迫切需求。", "innovation": "本文介绍了Locaris，一种专门用于室内定位的仅解码器大型语言模型（LLM）。与现有的Wi-Fi测量需要预处理以及需要大量校准的方法不同，Locaris将每个接入点（AP）的测量结果视为一个标记，使其能够直接处理原始的Wi-Fi遥测数据。通过在不同的Wi-Fi数据集上进行微调，Locaris学习到了一种对原始信号与设备位置进行直接映射的轻量级且通用性高的模型。Locaris采用少数几个校准点即可实现对其已有训练的迁移学习，即使在未见过的设备或部署场景下也能保持高精度，且在使用较少样本时就能达到亚米级别精度。", "conclusion": "实验结果表明，紧凑型LLM可以作为无需校准的回归模型用于室内定位，能够在异构Wi-Fi部署中提供可扩展且鲁棒的跨环境性能。此外，局部适应性实验显示，即使使用少量校准点，Locaris在未见过的设备和部署场景中也能保持高精度。此项研究显示Locaris在大规模部署中极具实用性，特别是在大规模部署中校准极其困难的情况下。"}
{"llm_update_time": "20251015", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.11955", "html_url": "https://arxiv.org/abs/2510.11955", "title": "Y形生成流", "title_en": "Y-shaped Generative Flows", "authors": "Arip Asadulaev,Semyon Semenov,Abduragim Shtanchaev,Eric Moulines,Fakhri Karray,Martin Takac", "background": "现代连续时间生成模型通常会产生V形传输路径：每个样本在从先验到数据的路径上几乎呈直线独立移动，忽略了共享结构。", "innovation": "我们提出了Y形生成流，它可以一起沿着共享路径移动概率质量，然后分支到特定目标的终点。我们的方法基于新颖的速度驱动传输成本，具有介于零和一之间的亚线性指数。这种凹依赖关系奖励集体和快速的质量转移。我们提出了一个可扩展的神经ODE培训目标来实现这一想法。Y流在合成、图像和生物数据集上恢复层次结构意识的结构，并优于强大的基于流的基线，且通过更少的积分步骤达到目标，提高分布度量指标。", "conclusion": "Y流在合成、图像和生物数据集上的表现为它们恢复了层次结构意识的结构，并优于基于流的基准。它们通过较少的积分步骤达到目标，提高了分布度量指标。"}
{"llm_update_time": "20251015", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.11953", "html_url": "https://arxiv.org/abs/2510.11953", "title": "使用MMD塑造潜在空间：具有可编程先验的解卷积", "title_en": "Sculpting Latent Spaces With MMD: Disentanglement With Programmable Priors", "authors": "Quentin Fruytier,Akshay Malhotra,Shahab Hamidi-Rad,Aditya Sant,Aryan Mokhtari,Sujay Sanghavi", "background": "变量分解表示的学习，即每个独立的潜在变量捕捉不同的变化因素，是机器学习中的一个核心目标。目前的主要方法是变分自编码器（VAE）框架，它使用Kullback-Leibler（KL）散度约束来促使潜在空间匹配因子化的高斯先验。然而，本文提供了直接证据表明，基于KL的正则化器是不可靠的机制，通常无法确保聚合后的后验分布收敛于目标分布。作者使用他们新颖的无监督潜变量可预测性评分（LPS）来验证这一点并量化这种缠结。", "innovation": "作者提出了一个基于最大均差（MMD）的可编程先验框架，允许实践者明确地塑造潜在空间，实现复杂的CIFAR-10和Tiny ImageNet数据集上的互不相关性最佳状态，而不牺牲常见的重建权衡。此外，该框架可以用来设计先进的先验，以改善与语义特征的对齐。", "conclusion": "最终，本研究提供了一个重要的工具，用于特征设计，打开了模型可识别性和因果推理的新途径。"}
{"llm_update_time": "20251015", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.11958", "html_url": "https://arxiv.org/abs/2510.11958", "title": "直接多令牌解码", "title_en": "Direct Multi-Token Decoding", "authors": "Xuan Luo,Weizhi Wang,Xifeng Yan", "background": "由于强大的性能，解码器仅模型已成为大型语言模型（LLMs）的标准架构。研究表明，预训练的LLMs的不同层级可能具有不同的功能：早期层专注于理解输入语境，中间层处理特定任务的处理，后期层将抽象表示转换为输出令牌。已有假设提出，一旦信息被早期和中间层处理，由后期层即可生成多个令牌，而无需重复遍历早期和中间层，这一假设称为直接多令牌解码（DMTD）.", "innovation": "与推测性解码不同，DMTD方法不额外引入参数、辅助程序或生成后验证。即使在有限的数据集上进行训练，微调的DMTD Qwen3-4B模型已显示出积极的结果，实现了2倍的速度提升，并且仅有少量性能损失。此外，根据我们的扩展分析，模型性能预计会随着更大训练数据集的使用而进一步提升.", "conclusion": "尽管训练数据集有限，微调的DMTD Qwen3-4B模型已展示了显著的速度提升和较小的性能损失。同时，预计模型的性能会随着更大训练数据集的使用而进一步提升."}
{"llm_update_time": "20251015", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.11974", "html_url": "https://arxiv.org/abs/2510.11974", "title": "CTIArena：评估跨异构网络威胁情报的大语言模型知识与推理基准", "title_en": "CTIArena: Benchmarking LLM Knowledge and Reasoning Across Heterogeneous Cyber Threat Intelligence", "authors": "Yutong Cheng,Yang Liu,Changze Li,Dawn Song,Peng Gao", "background": "网络威胁情报（CTI）是现代网络安全的核心，提供关键洞察以检测和缓解不断演变的威胁。随着大语言模型（LLMs）具备自然语言理解和推理的能力，将其应用于CTI领域引起了广泛关注。然而，早期的研究在评估时存在局限性，包括仅使用封闭式场景、覆盖任务范围狭窄、仅限单源分析，无法反映现实中的多源推理需求。因此，研究者们需要一个可以系统评估LLMs在异构、多源CTI方面的表现的新基准。", "innovation": "我们提出了CTIArena，这是首个评估LLMs在异构、多源CTI方面的性能基准，工作在知识增强的环境下。CTIArena覆盖结构化、非结构化和混合三类任务，并进一步细分为九项任务，以捕捉现代安全运营中的CTI分析全面性。实验结果显示，大多数LLMs在封闭式场景下表现不佳，但在通过我们设计的检索增强技术增强后，表现显著提升。这一发现强调了通用LLMs的局限性以及需要领域定制的方法来充分释放其在CTI中的潜力。", "conclusion": "这些发现表明，通用的LLMs在封闭式场景中表现较差，但在结合特定于安全领域的知识后表现显著提高，这突显了通用LLMs的局限性以及领域定制化技术对于全面释放其CTI应用潜力的必要性。"}
{"llm_update_time": "20251015", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.11944", "html_url": "https://arxiv.org/abs/2510.11944", "title": "TopoAlign：通过拓扑分解对齐代码与数学的框架", "title_en": "TopoAlign: A Framework for Aligning Code to Math via Topological Decomposition", "authors": "Yupei Li,Philipp Borchert,Gerasimos Lampouras", "background": "大语言模型（LLMs）在非正式和正式的数学推理方面表现出色，但在将非正式推理转换为正式数学证明（即自动形式化）方面仍存在困难。自动形式化有助于将LLMs的非正式推理与能够进行机器验证的正式证明助手相结合，以减轻幻觉问题。然而，当前数学LLMs的表现受限于大型数据集的稀缺性，特别是包含非正式和正式声明配对的数据集。尽管当下的模型能够从自然语言指令中生成代码，但结构和语法规则之间的差异限制了这些模型向正式数学的有效迁移学习。", "innovation": "提出了一种名为TopoAlign的新框架，该框架利用广泛可用的代码库作为训练资源来训练数学LLMs。TopoAlign将代码分解为文档字符串、主函数和依赖函数，并将这些组件重新组装成结构上与正式声明相似的元件，从而生成结构对齐的代码数据，无需额外的人工注释。此外，通过在结构对齐的代码数据上训练两种最先进的模型DeepSeek-Math和Herald，证明了即使不引入新的数学知识，这种训练方法也能显著提高模型的表现。", "conclusion": "TopoAlign在DeepSeek-Math上的训练实现了BEq@10提高17.77%、typecheck@10提高68.82%的效果，在Herald上的表现也有所提升，即使是在缺乏额外数学知识的情况下，框架在BEq@10和typecheck@10上的表现分别提高了0.12%和1.09%，这些结果表明，使用对齐的代码数据进行训练对专门化的模型也具有显著的益处。"}
{"llm_update_time": "20251015", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.12029", "html_url": "https://arxiv.org/abs/2510.12029", "title": "CPR: 使用治愈性提示细化缓解大规模语言模型幻觉", "title_en": "CPR: Mitigating Large Language Model Hallucinations with Curative Prompt Refinement", "authors": "Jung-Woo Shim,Yeong-Joon Ju,Ji-Hoon Park,Seong-Whan Lee", "background": "最近在大型语言模型（LLMs）方面的进展表明，它们在回答各种提示时表现出较强的流畅性。然而，这些模型有时会生成看似合理的但实际上是错误的“幻觉”事实，这损害了用户的信任。不清晰或不规范的提示经常被用户使用，导致模型依据臆造而非实际意图来生成回答，这是产生此类错误的常见但未被充分重视的原因。", "innovation": "本文提出了一种名为Curative Prompt Refinement (CPR)的插件式框架，用于矫正不规范的提示，具体包括：1）清理不规范的提示；2）使用微调的小型语言模型生成附加的信息性任务描述，以此来调整用户的意图与提示的一致性。研究表明，CPR显著提高了语言模型生成内容的质量，同时减轻了幻觉现象。", "conclusion": "通过实证研究，我们发现使用CPR处理过的提示，其结果的质量在90%以上超过了未处理的原始提示，且没有依赖外部知识。"}
{"llm_update_time": "20251015", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.11978", "html_url": "https://arxiv.org/abs/2510.11978", "title": "VLM训练的学习动力学", "title_en": "Learning Dynamics of VLM Finetuning", "authors": "Jusheng Zhang,Kaitong Cai,Jing Yang,Keze Wang", "background": "偏好驱动的视觉-语言模型（VLM）微调容易受到负面干扰的影响：一些简单的负面样本会产生无效的梯度，使模型训练变得不稳定。现有的方法主要关注于对齐策略，但没有意识到指导微调策略的动力学特性。为了改进这一问题，本文重新构造了对齐任务，并提出了一种结合动力学意识优化的两阶段方法，以提高微调过程的稳定性和效果。", "innovation": "本文提出了一种名为CW-DPO的方法，这是一个两阶段策略，包括监督微调阶段和一个基于模型Token概率的冷却权重的DPO目标。首先，通过使用温和的负面样本进行监督微调，减少模型的自信偏差，增强训练。其次，在DPO概率计算中引入一个冷却权重，以温和的方式引入负样本，防止易混淆或分布外样本来干扰优化过程，同时保留难以对应负样本的信息。此外，该方法使用$\triangle\text{log} p$探针进行训练监控，以提供早期停止，教学计划设计以及故障诊断的信号。实验结果表明，与传统的自回归 fine-tuning 和传统的DPO方法相比，CW-DPO方法在多个VLM任务中表现出更稳定的优化过程、更好的校准和更高的胜率，收敛速度更快。进一步的消融研究揭示了冷却权重机制在提升性能中的关键作用，并展示了混合使用线上与数据集负样本的补充益处。", "conclusion": "我们的研究表明，在冷却偏好之前通过平滑学习动态是一种简单而通用的原则，可以增强视觉-语言模型的对齐鲁棒性。"}
{"llm_update_time": "20251015", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.11992", "html_url": "https://arxiv.org/abs/2510.11992", "title": "PanoTPS-Net：通过薄板样条变换实现全景室内布局估计", "title_en": "PanoTPS-Net: Panoramic Room Layout Estimation via Thin Plate Spline Transformation", "authors": "Hatem Ibrahem,Ahmed Salem,Qinmin Vivian Hu,Guanghui Wang", "background": "在计算机视觉领域，精确估计房间的3D布局是一项关键任务，其潜在应用包括机器人技术、增强现实和室内设计。现有的方法在处理不同形状的房间布局时存在局限性，尤其是在估计立方体和非立方体房间布局时表现不佳。因此，本文旨在提出一种新的模型PanoTPS-Net，以单张全景图像为基础，能够准确估计房间布局。", "innovation": "PanoTPS-Net模型结合了卷积神经网络（CNN）和薄板样条（TPS）空间变换，专门针对单张全景图像进行房间布局估计。此模型的独特之处在于，不仅能够通过CNN提取高阶特征来学习TPS变换的空间参数，还能够生成TPS空间变换层，进而将参考布局扭曲为所需布局。这种组合使得模型不仅能够准确预测房间布局，还能很好地应用于立方体和非立方体形状的房间布局估计。实验结果表明，该方法在各类公开数据集和现有的先进方法之间具有明显优势，能够在PanoContext、Stanford-2D3D、Matterport3DLayout和ZInD数据集上分别取得85.49、86.16、81.76、91.98的3DIoU值，说明模型在各类房间布局估计上具有良好的鲁棒性。", "conclusion": "本文提出的PanoTPS-Net模型在准确估计房间布局方面展示了卓越的有效性和鲁棒性，尤其是在处理不同类型房间布局时。模型架构的独特设计使得其不仅能够提升现有技术在准确度方面的表现，还能够在异型房间布局估计上展现出强大能力。"}
{"llm_update_time": "20251015", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.12032", "html_url": "https://arxiv.org/abs/2510.12032", "title": "多阶段提示精炼在大型语言模型中减轻幻觉", "title_en": "Multi-stage Prompt Refinement for Mitigating Hallucinations in Large Language Models", "authors": "Jung-Woo Shim,Yeong-Joon Ju,Ji-Hoon Park,Seong-Whan Lee", "background": "近年来，大规模语言模型（LLMs）在自然语言理解和生成任务上表现出强大的性能。然而，LLMs仍然面临幻觉问题，即模型生成看似正确但实际上不正确的信息。幻觉生成的原因有很多，其中不良提示、含糊不清的措辞、语法错误或不完整的信息等因素的影响尚未得到充分研究。研究者们通常探讨如何改进提示来减少幻觉的发生。", "innovation": "本文引入了多阶段提示精炼（MPR）框架，该框架旨在系统地提升包含错误的提示，多阶段分别解决标点符号错误、拼写错误和术语误用等问题。MPR 还通过增加上下文信息、自我反思机制和评级系统来改进提示的清晰度，确保最相关的信息被优先考虑。实验结果表明，MPR 能够将幻觉率降低超过 85%，并且可以与现有的后置幻觉缓解框架结合，提升了其多功能性。", "conclusion": "研究表明，经过 MPR 改进的提示相对于原始提示实现了超过 85% 的幻觉减少率，表明 MPR 能有效降低幻觉并提高 LLM 的输出准确性。此外，MPR 还提供了一个轻量级且可适应的解决方案，以提升各种领域中 LLMS 的可靠性。"}
{"llm_update_time": "20251015", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.11986", "html_url": "https://arxiv.org/abs/2510.11986", "title": "猜想：形式化数学推理中的一个被忽视的步骤", "title_en": "Conjecturing: An Overlooked Step in Formal Mathematical Reasoning", "authors": "Jasivan Alex Sivakumar,Philipp Borchert,Ronald Cardenas,Gerasimos Lampouras", "background": "自动形式化是指将非正式的数学陈述表达为正式语言的过程，但通常被认为是一个直接翻译的过程。然而，这忽视了一个关键的前置步骤：提出猜想。许多数学问题在直接形式化之前需要先提出一个结论性的答案或特定的界限。由于大型语言模型已经在自动形式化上遇到困难，而评估其猜想能力的验证通常与自动形式化或证明紧密交织在一起，难以完全理解其效果。针对这一缺口，我们扩展现有数据集以创建ConjectureBench，并重新设计评估框架和指标，专门用于衡量LLMs的猜想能力和其在自动形式化管道中的应用。我们对基础模型GPT-4.1和DeepSeek-V3.1的评估表明，在评估时考虑到猜想会显著提高其自动形式化的性能。然而，猜想也不应该假定给出。我们设计了推理时的方法Lean-FIRe，以提高猜想和自动形式化性能，达到对GPT-4.1成功解开13个PutnamBench问题和对DeepSeek-V3.1成功解开7个问题的首个端到端自动形式化。我们展示了LLMs具有生成准确猜想的知识，但提高自动形式化性能需要将猜想视为独立任务，并进一步探索如何正确地将其融入自动形式化中。最后，我们提供了前瞻性的指导，以引导未来的研究改善猜想，这是形式化数学推理中的一个被忽视的步骤。", "innovation": "提出了ConjectureBench数据集，专门用于衡量LLMs在猜想和自动形式化任务中的能力；设计了Lean-FIRe推理方法以改进猜想和自动形式化；通过该方法首次实现了对13个PutnamBench问题的端到端自动形式化（GPT-4.1），以及对7个问题的端到端自动形式化（DeepSeek-V3.1）；强调了猜想在自动形式化中的独立性和重要性，进一步探索了其在自动形式化流程中的正确整合方法；提供了未来研究的指导，以改善形式数学推理的猜想步骤，这是一个被忽视的重要环节。", "conclusion": "猜想是形式化数学推理中的一个关键但尚未被充分重视的步骤，LLMs在自动形式化过程中不仅需要处理猜想，还必须将其作为独立任务进行正确整合。作者通过该研究揭示了猜想在自动形式化中的重要性，并提出了改进这一过程的方法。未来的研究应进一步关注于如何正确地将猜想纳入自动形式化流程，并通过实际案例进一步验证和优化该流程。"}
{"llm_update_time": "20251015", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.12051", "html_url": "https://arxiv.org/abs/2510.12051", "title": "APCE: 可适应逐级扩展的上下文扩展用于长上下文处理", "title_en": "APCE: Adaptive Progressive Context Expansion for Long Context Processing", "authors": "Baisub Lee,Sanghyun Byun,Mohanad Odema,Jung Guack,Jacob Song,Woo Seong Chung", "background": "部署有用的长上下文变压器模型（LCTMs）面临着两个关键挑战：（1）随着序列长度增加，自我注意力因平方形式的增长以及KV缓存随线性增长而导致的内存占用增加；（2）ContextRot现象，即随着上下文长度增加，变压器架构的性能退化。鉴于输入的共享依赖性，文中提出是否可以精准选择最重要的输入片段来同时减少内存占用并缓解ContextRot效果。研究表明，对于长上下文摘要任务，这种方法是可行的。", "innovation": "提出了APCE（上下文感知的进步式上下文扩展）作为一个基于低维度语义相似性匹配当前查询来选择最重要的输入片段的解决方案。APCE直接操作输入，不依赖于特定的硬件或CUDA环境，这是一种兼容且可扩展到不同部署系统的解决方案。实证评估表明，与完整的密集基线相比，使用一部分输入序列（50%-70%）进行APCE处理，在上下文键值缓存和自我注意记忆效率方面有所改进，且摘要性能相当或更优。", "conclusion": "希望我们的发现能够激发进一步的研究，以探索更多面向其他相关长上下文任务的上下文感知效率解决方案。"}
{"llm_update_time": "20251015", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.12060", "html_url": "https://arxiv.org/abs/2510.12060", "title": "您的视觉自回归模型实际上是高效且可解释的生成分类器", "title_en": "Your VAR Model is Secretly an Efficient and Explainable Generative Classifier", "authors": "Yi-Chung Chen,David I. Inouye,Jing Gao", "background": "生成分类器利用条件生成模型进行分类，显示出对分布变化的鲁棒性。然而，该领域的进步主要由基于扩散的模型推动，其巨大的计算成本严重限制了其可扩展性。目前的研究主要集中在扩散模型上，这限制了我们对生成分类器的理解。本文旨在研究视觉自回归（VAR）建模的进展及其潜力作为新的生成分类器视角。", "innovation": "本文提出了一种新的基于视觉自回归建模的生成分类器（A-VARC+），引入了自适应自回归分类器，以实现准确性和推理速度之间的更好权衡，从而显著提高实际应用性。此外，本文表明，基于VAR的方法在根本上与基于扩散的方法不同。自回归分类器由于可计算的似然性，能够通过标记间互信息实现视觉可解释性，并且在类别增量学习任务中表现出对灾难性遗忘的内在抵抗力。", "conclusion": "本文证明了基于VAR的方法具有与基于扩散的方法不同的基本属性，提供了新的研究视角，并展示了其在实际应用中的潜力和优势。"}
{"llm_update_time": "20251015", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.12044", "html_url": "https://arxiv.org/abs/2510.12044", "title": "层级对齐：通过功能性层专业化实现大型语言模型的手术微调", "title_en": "Hierarchical Alignment: Surgical Fine-Tuning via Functional Layer Specialization in Large Language Models", "authors": "Yukun Zhang,Qi Dong", "background": "现有的大型语言模型（LLMs）对齐技术，例如直接偏好优化（DPO），通常将模型视为一个单一的实体，在所有层上施加均匀的优化压力。这种做法忽略了变体架构内部的功能专业化，不同层处理从语法规则到抽象推理的不同任务。本文探讨了这一一刀切的方法，并介绍了层级对齐这一新型方法，该方法对模型层的功能块施加特定的DPO优化：局部（语法规则）、中介（逻辑）和全局（事实性）。", "innovation": "本文介绍了一种新的层级对齐方法，这种方法针对模型的不同功能块（局部、中介和全局）应用特定的Direct Preference Optimization (DPO)。通过在如Llama-3.1-8B和Qwen1.5-7B等最先进的模型上进行控制实验，并使用LoRA进行精细调整，作者发现这种方法在语法流畅性、事实一致性以及逻辑连贯性上都取得了显著且可预测的提高。尤其是对全局层进行对齐（Global-Align）不仅提高了事实一致性，还展示了赋能逻辑一致性的最大效率，优于所有基线方法。此外，所有层级方法成功避免了标准DPO方法中的“对齐税”，即流畅性提升伴随着逻辑推理能力下降的问题。", "conclusion": "研究表明，与传统的单一优化方法相比，层级对齐方法提供了一条更资源高效、可控和可解释的模型对齐路径，强调了从单一优化转向结构感知的手术微调的重要性，以便构建更高级和可靠的大型语言模型。"}
{"llm_update_time": "20251015", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.12070", "html_url": "https://arxiv.org/abs/2510.12070", "title": "MEASURE: 多尺度最小充分表示学习在睡眠分期领域知识泛化的研究", "title_en": "MEASURE: Multi-scale Minimal Sufficient Representation Learning for Domain Generalization in Sleep Staging", "authors": "Sangmin Jo,Jee Seok Yoon,Wootaek Jeong,Kwanseok Oh,Heung-Il Suk", "background": "基于深度学习的自动睡眠分期模型在性能上取得了显著进步，并且在睡眠障碍诊断中发挥了重要作用。然而，这些模型由于生理信号的变异，在无法见到的受试者上表现出较差的泛化性能。针对这个问题，近年来已经研究了领域泛化的策略以确保在训练阶段各种未见过领域的性能都能得到提升。现有的一些技巧，如对比学习，已被证实能够学习跨领域不变的特征，但大多数方法在提取蕴含在不同样本间的非共享信息中的领域特征时还不够充分，无法有效地提取域不变的表示。因此，本文提出了一种新的MEASURE框架，旨在减少领域相关的多余信息，同时保留关键的时域和频域特征，从而提高睡眠阶段分类的性能。", "innovation": "提出了MEASURE框架，这是一种多尺度最小充分表示学习方法。该方法旨在减少领域相关的多余信息，同时保留关键的时域和频域特征。与现有方法相比，这种方法能够更充分地捕捉到不同特征尺度上的信息，从而更好地实现跨领域泛化。", "conclusion": "在公开的睡眠分期基准数据集上，包括SleepEDF-20和MASS，所提出的MEASURE方法在睡眠阶段分类任务上优于现有的方法。证明了该方法的有效性并能够提升模型的泛化性能。相关代码已发布。"}
{"llm_update_time": "20251015", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.12049", "html_url": "https://arxiv.org/abs/2510.12049", "title": "生成型人工智能与企业生产率：在线零售领域的现场实验", "title_en": "Generative AI and Firm Productivity: Field Experiments in Online Retail", "authors": "Lu Fang,Zhe Yuan,Kaifu Zhang,Dante Donati,Miklos Sarvary", "background": "本文通过一系列大型随机现场实验，评估了生成型人工智能（GenAI）对一家领先的跨境在线零售平台企业生产力的影响。实验覆盖了数百万用户和产品，并持续了从2023年到2024年的六个月时间，在此期间，GenAI技术被集成到七个面向消费者的业务工作流程中。实验显示，在衡量治疗效果后，GenAI的应用显著提高了销售业绩，增幅从0%到16.3%不等，具体取决于新的人工智能技术对现有业务实践的边际贡献。由于所有实验组的输入和价格保持不变，这些销售增长直接转化为总生产率的提升。四个有积极作用的GenAI应用预计每年将带来大约5美元的新增价值，对于零售商的规模而言，这是一个有经济意义的提升。结果表明，转化率的提高是主要机制，这表明GenAI减少了市场中的摩擦并将改善了消费者的体验。此外，研究还发现，小型和新成立的卖家以及不那么有经验的消费者在实验中表现出显著更大收益。这些发现提供了有关在线零售中GenAI生产力效应的新型大规模因果证据，强调了其即时价值和更广泛的潜在应用价值。", "innovation": "该研究通过大规模的随机实地实验量化的评估了GenAI对在线零售平台企业生产力的影响，这是在早期GenAI应用阶段的重要探索。实验涵盖了广泛的业务流程和消费者，展示了不同规模和经验的企业在采用GenAI技术时可能产生的不同效果，填补了学术界在这方面的研究空白。", "conclusion": "研究发现，GenAI的引入对企业销售业绩产生了显著的正向影响，主要通过提高转化率来实现。这项研究不仅支持了GenAI对于在线零售企业具有即时价值的论点，还指出了它在未来的广泛潜力。此外，研究还揭示了不同规模和经验的商家在采用GenAI技术时可能会产生不同的收益，这为未来的更广泛应用提供了指导意见。"}
{"llm_update_time": "20251015", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.12075", "html_url": "https://arxiv.org/abs/2510.12075", "title": "领域适配和生成对抗网络（GANs）的综述", "title_en": "A Review on Domain Adaption and Generative Adversarial Networks(GANs)", "authors": "Aashish Dhawan,Divyanshu Mudgal", "background": "当前计算机视觉领域的主要挑战是高质量标记数据的获取。在像图像分类这样的依赖于数据的领域，需要找到更可靠的方法来克服数据稀缺的问题，以生产出与之前基准结果相当的结果。由于人工成本高，通常获取标记数据难度很大，在某些情况下甚至不可能。本文旨在讨论领域适配以及实现它的各种方法，利用特定数据集训练的模型在相同类型的另一个数据领域上进行预测，例如：用飞机的画作训练的模型预测真实的飞机图像。", "innovation": "本文主要创新在于总结领域适配的方法，并讨论生成对抗网络（GANs）在这一过程中的应用。通过总结的方法和网络模型，能够有效地提高模型在不同数据域的任务表现，改进数据稀缺条件下的模型性能。", "conclusion": "本文综述了领域适配的各种方法及其在生成对抗网络中的应用，提出了利用特定数据集训练的模型在具有相同类型的另一数据域上进行预测的方法，为解决计算机视觉中数据稀缺问题提供了一种新的思路。"}
{"llm_update_time": "20251015", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.12083", "html_url": "https://arxiv.org/abs/2510.12083", "title": "基于AI的行为健康安全过滤器及数据集在文本对话中识别心理健康危机", "title_en": "An AI-Based Behavioral Health Safety Filter and Dataset for Identifying Mental Health Crises in Text-Based Conversations", "authors": "Benjamin W. Nelson,Celeste Wong,Matthew T. Silvestrini,Sooyoon Shin,Alanna Robinson,Jessica Lee,Eric Yang,John Torous,Andrew Trister", "background": "大型语言模型在处理心理健康紧急情况时常常出现误判，提供有害或不适当的建议，甚至促进有害行为。因此，研究者开发了一种名为Verily行为健康安全过滤器（VBHSF）的工具，并在两个数据集上进行了测试以评估其性能，从而改善这些模型处理心理健康紧急情况的能力。", "innovation": "该研究创新性地开发了Verily行为健康安全过滤器，并通过两个数据集测试了其性能，同时与开源内容审核护栏进行了比较。研究发现，VBHSF在敏感性和特异性方面表现出优越的性能，特别是在降低误报率的同时，最大限度地减少了危机的遗漏，这对于医疗健康应用尤为重要。", "conclusion": "总体而言，Verily行为健康安全过滤器在两个数据集中的表现稳健且具有普遍适用性，其优先考虑高敏感性以避免遗漏危机，这是医疗健康应用中非常关键的特性。与NVIDIA NeMo和OpenAI Omni Moderation Latest相比，VBHSF在敏感性上有显著提高，但在与OpenAI Omni Moderation Latest的竞争中，其特异性没有显著区别。"}
{"llm_update_time": "20251015", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.12110", "html_url": "https://arxiv.org/abs/2510.12110", "title": "深层关联，高创意：评估大型语言模型的简单而有效的指标", "title_en": "Deep Associations, High Creativity: A Simple yet Effective Metric for Evaluating Large Language Models", "authors": "Ziliang Qiu,Renfen Hu", "background": "评估LLMs的创造力构成了一个关键的研究领域，但是数据污染和昂贵的人工评估往往会阻碍进展。现有的评估方法存在数据污染的风险和高昂的成本。", "innovation": "提出了一种名为PACE的方法，要求LLMs生成平行联想链来评估其创造力。这种方法规避了数据污染的风险，并提供了一个简单而高效的评估方式。以Chatbot Arena创意写作排名的皮尔森相关系数为0.739（p < 0.001）证明了该方法的有效性。对于联想创造力的比较显示，在高表现的LLMs与普通人类表现相似的情况下，专业人类的表现始终优于LLMs。此外，语言分析显示，人类和LLMs在联想中的具体性呈现下降趋势，且人类表现出更多的联想模式多样性。", "conclusion": "虽然高表现的LLMs能实现等同于普通人类的评分，但在创意水平上，专业人类仍能持续超越LLMs。人类和LLMs在联想的具体性上均呈现下降趋势，但是人类的联想模式表现出更多的多样性。"}
{"llm_update_time": "20251015", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.12082", "html_url": "https://arxiv.org/abs/2510.12082", "title": "通过附加上下文增强神经代码表示", "title_en": "Enhancing Neural Code Representation with Additional Context", "authors": "Huy Nguyen,Christoph Treude,Patanamon Thongtanunam", "background": "自动化程序理解是软件工程任务的基础，包括代码摘要和代码克隆检测等。尽管最近的深度学习模型取得了很好的成果，但它们通常只依赖源代码，而忽略了版本历史或结构关系等上下文信息。这限制了它们捕捉代码演变和操作能力。", "innovation": "本文通过实证研究探讨了将上下文信号添加到代码表示中如何影响神经模型在关键理解任务上的性能。研究了代码克隆检测和代码摘要两个下游任务，使用SeSaMe（1,679个Java方法）和CodeSearchNet（63,259个方法）进行评估。优化了五种代表性的模型（CodeBERT、GraphCodeBERT、CodeT5、PLBART、ASTNN），分别在仅代码和其他上下文增强设置下进行了训练。结果显示，上下文总体上提高了性能：版本历史在克隆检测（例如CodeT5，F1分值提高15.92%）和摘要（例如GraphCodeBERT，METEOR提高5.56%）方面表现良好。结合多个上下文可以获得进一步的收益（高达21.48%的宏F1）。对于100个Java片段的人工评估表明，上下文增强后的摘要在准确性和内容方面显著优于未增强的摘要（p ≤ 0.026；差异可达0.55）。", "conclusion": "本文的研究结果突显了上下文信号增强对代码理解的潜力，并为优化神经SE模型中的上下文编码提供了新的方向。"}
{"llm_update_time": "20251015", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.12133", "html_url": "https://arxiv.org/abs/2510.12133", "title": "SafeMT：多轮对话中的多模态语言模型安全性", "title_en": "SafeMT: Multi-turn Safety for Multimodal Language Models", "authors": "Han Zhu,Juntao Dai,Jiaming Ji,Haoran Li,Chengkun Cai,Pengcheng Wen,Chi-Min Chan,Boyuan Chen,Yaodong Yang,Sirui Han,Yike Guo", "background": "随着多模态大型语言模型（MLLMs）的广泛应用，安全性问题日益引起关注。现有的基准测试没有充分考虑到多轮对话所带来的更大风险，尤其是这类对话在日常交流中更为常见。因此，文章提出了SafeMT基准，以鼓励社区关注这些模型在多轮对话中的安全性问题。", "innovation": "文章引入了SafeMT基准，该基准包含由有害查询和图像生成的不同长度的对话样本，共10,000个样本，涵盖了17种不同场景和四种脱笼（jailbreak）方法。此外，作者还提出了安全性指数（Safety Index，SI）来评估MLLMs在对话中的整体安全性。通过SafeMT基准测试了17个模型，发现有害对话中的轮次越多，攻击成功的风险越大。文章还提出了一种对话安全监控器，能够检测对话中的恶意意图，并为MLLMs提供相关安全策略。", "conclusion": "实验结果表明，该安全监控器在减少多轮语音识别错误方面比现有的防护模型更为有效。文章指出，当前这些模型的安全机制对于识别对话中的危险程度仍不足。"}
{"llm_update_time": "20251015", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.12111", "html_url": "https://arxiv.org/abs/2510.12111", "title": "Chimera: State Space Models Beyond Sequences", "title_en": "Chimera: State Space Models Beyond Sequences", "authors": "Aakash Lahoti,Tanya Marwah,Ratish Puduppully,Albert Gu", "background": "变换器等基于深度学习的方法已经成为处理各种类型数据（如序列、图像和图）的标准方法。这些方法依赖于自注意力机制，将数据视为无序的元素集合。这种方法忽略了数据的邻域结构或图拓扑结构，需要使用诸如序列和图像中的位置嵌入，或图中的随机游走等归纳偏置来融入这种结构信息。然而，设计针对特定任务的偏置需要大量努力，并可能引进一些副作用，阻碍泛化能力。", "innovation": "介绍了Chimera，这是一种统一模型，能够直接以合理的方式整合数据拓扑，从而消除对具体领域偏置的需求。关键思路是，状态空间模型自然不需要位置嵌入就可以适配任何图拓扑结构。实验结果显示，Chimera在语言、视觉和图结构域都取得了强大的性能，超越了BERT在GLUE上的成绩0.7分，超越ViT在ImageNet-1k上的成绩2.6%，并且在长范围图基准数据集上超过了所有基线。此外还提出了算法优化来提高Chimera的效率：一是对于有向无环图，Chimera可以实现为线性时间递推；二是对于一般图，通过简单的数学松弛，可以实现类似变换器的平方复杂度，而无需特定领域启发式方法。这些结果验证了Chimera的核心贡献，并支持了数据拓扑是跨模态强大的归纳偏置的观点。", "conclusion": "Chimera为状态空间模型提供了一种全新的应用方式，能够超越传统的序列数据结构，实现对图结构数据的高效处理，为多领域数据的统一建模提供了新的可能性。"}
{"llm_update_time": "20251015", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.12144", "html_url": "https://arxiv.org/abs/2510.12144", "title": "预算约束的主动学习以有效去阴性化生存数据", "title_en": "Budget-constrained Active Learning to Effectively De-censor Survival Data", "authors": "Ali Parsaee,Bei Jiang,Zachary Friggstad,Russell Greiner", "background": "传统的监督学习方法试图从已标记的数据集中学习模型。在预算有限的情况下，给定少量的已标记样本和一大池未标记样本，预算学习者可以使用给定的预算来为一些未标记样本获取标签，从而生成一个模型。本文将预算化学习应用于包括右截尾数据（生存时间只知道下限）的生存数据集中。这意味着学习者可以支付一部分标签成本来了解阴性样本，比如获得实例的实际时间（如从3年、截尾到7.2年、非截尾），或者了解额外的信息，如从3年、截尾转为4年、截尾或3.2年、非截尾。这可以类比真实的数据库收集，实际上对于那些截尾的患者进行随访并不总是能够得到非截尾信息，而且所得信息的多少取决于预算和数据本身的性质。", "innovation": "该研究提出了在预算约束下对生存数据进行去阴性化的主动学习方法，并理论和实验证明了其有效性。通过提供与标准批量AL方法BatchBALD相媲美的边界和时间复杂度，证明了该方法的高效性。实验结果表明，在多个基准任务上，本文的方法优于其他潜在方法。", "conclusion": "本文通过提出一种预算约束下的主动学习方法，并适配于生存数据集（包括右截尾数据），解决了如何有效去阴性化生存数据的问题。通过与标准算法进行对比，展示了新方法在实证研究中的优越性。未来的工作可以进一步探索更复杂的预算策略及其对学习效果的影响。"}
{"llm_update_time": "20251015", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.12116", "html_url": "https://arxiv.org/abs/2510.12116", "title": "理解模态差距：大型语音语言模型中语音-文本对齐机制的经验研究", "title_en": "Understanding the Modality Gap: An Empirical Study on the Speech-Text Alignment Mechanism of Large Speech Language Models", "authors": "Bajian Xiang,Shuaijiang Zhao,Tingwei Guo,Wei Zou", "background": "端到端的大规模语音语言模型（LSLMs）在对话生成方面表现出色，但它们在语义理解基准测试中却常常不如传统的流水线系统。通过系统的实验，研究者发现虽然经过语音-文本对齐训练后，LSLMs在纯文本输入场景下的表现会有所下降，但语音输入和文本输入之间的性能差距更加显著，这种差距称为模态差距。为了研究这种差距，研究者对粗粒度和细粒度的语音和文本表示进行了分析。", "innovation": "研究者发现，在深度表示层面上，语音和文本表示的方向性逐渐趋向一致，而数量级上则逐渐分离。此外，表示相似性与模态差距之间存在强相关性。在细粒度水平上，研究者观察到了文本和语音表示之间自发的标注级对齐模式。基于这些发现，研究者引入了对齐路径得分（Alignment Path Score）来量化标注级对齐质量，这种得分与模态差距表现出更强的相关性。研究者还设计了通过角度投影和长度归一化对关键标记进行目标干预的策略。这些干预策略展示了提高语音输入正确性潜力。该项研究提供了LSLMs中模态差距及对齐机制的首次系统实证分析，并为未来的优化提供了理论和方法指导。", "conclusion": "本研究深入分析了LSLMs中的模态差距和对齐机制，并通过引入对齐路径得分等新方法，对关键标记进行了干预，展示了提高语音输入正确性的潜力。研究为未来优化提供了理论支持和方法论指导。"}
{"llm_update_time": "20251015", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.12181", "html_url": "https://arxiv.org/abs/2510.12181", "title": "从知识到治疗：大型语言模型辅助的生物医学概念表示在药物再利用中的应用", "title_en": "From Knowledge to Treatment: Large Language Model Assisted Biomedical Concept Representation for Drug Repurposing", "authors": "Chengrui Xiang,Tengfei Ma,Xiangzheng Fu,Yiping Liu,Bosheng Song,Xiangxiang Zeng", "background": "药物再利用在加速治疗发现方面起着关键作用，尤其对于复杂和罕见疾病。生物医学知识图谱（KGs）因其编码丰富的临床关联而被广泛应用于支持药物再利用任务。然而，现有方法大多忽视了真实世界实验室中的常识性生物医学概念知识，例如机制先验信息，表明某些药物与特定治疗在本质上是不兼容的。为了弥合这一差距，我们提出了一种名为LLaDR的大型语言模型辅助药物再利用框架，该框架提升了生物医学概念在知识图谱中的表示。具体而言，我们从大型语言模型中提取生物医学实体的语义增强治疗相关文本表示，并用这些信息来微调知识图嵌入（KGE）模型。通过将治疗相关知识注入KGE中，LLaDR显著提高了生物医学概念的表示质量，增强了对未研究或复杂的疾病进行了学理解。", "innovation": "LLaDR通过使用大型语言模型提取和利用生物医学实体的语义增强治疗相关文本表示，并将其用于微调知识图嵌入模型，从而有效提升了生物医学概念的表示，加强了对未研究或复杂疾病的语义理解。实验表明，LLaDR在不同场景下的性能均为最优，且案例研究进一步证实了其稳定性和有效性。", "conclusion": "LLaDR在处理不同场景时展示了卓越的性能，并通过案例研究验证了其稳健性和有效性。代码可在提供的链接处获取。"}
{"llm_update_time": "20251015", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.12184", "html_url": "https://arxiv.org/abs/2510.12184", "title": "CompoDistill：多模态大语言模型中的组成推理注意力蒸馏", "title_en": "CompoDistill: Attention Distillation for Compositional Reasoning in Multimodal LLMs", "authors": "Jiwan Kim,Kibum Kim,Sangwoo Seo,Chanyoung Park", "background": "近年来，高效的多模态大型语言模型（MLLMs）因其高计算复杂性而受到广泛关注，使其在实际应用中更具可行性。知识蒸馏（KD）作为一种可行的方法逐渐引起了人们的关注，它能够将大型模型（教师）丰富的视觉和语言知识转移到小型模型（学生）上。然而，现有的KD方法在将教师MLLM的丰富视觉感知能力有效地转移给学生时存在困难，这一点在之前的研究所中很少被提及。现有研究主要关注语言知识的转移，而忽视了视觉关注的不同步问题，影响了模型的性能。研究表明，视觉注意力的不一致性是造成这一问题的主要因素。基于此，本文提出了一种新颖的知识蒸馏框架CompoDistill，它明确地将学生的视觉注意力与教师的视觉注意力对齐，从而提高学生模型的视觉感知能力。", "innovation": "提出了一种新的知识蒸馏框架CompoDistill，该框架能够明确地对齐学生和教师的视觉注意力，增强学生模型的视觉感知能力。CompoDistill不仅在需要视觉感知能力的组成推理任务上表现出显著的性能提升，还在视觉问答任务上保持了强大的性能。此外，CompoDistill在更先进的骨干网络中也表现出了很好的效果，表明其具有较强的通用性。", "conclusion": "CompoDistill显著提高了需要视觉感知能力的组成推理任务的性能，同时在视觉问答任务上保持了良好的性能表现。CompoDistill在先进的架构中也表现出有效性，展示了其较强的通用性。"}
{"llm_update_time": "20251015", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.12209", "html_url": "https://arxiv.org/abs/2510.12209", "title": "重新审视嘈杂标签下的元学习：重新加权动态及理论保障", "title_en": "Revisiting Meta-Learning with Noisy Labels: Reweighting Dynamics and Theoretical Guarantees", "authors": "Yiming Zhang,Chester Holtz,Gal Mishne,Alex Cloninger", "background": "在使用噪声标签进行学习时，过度参数化的网络倾向于记忆损坏的监督信号。基于元学习的样本重新加权通过使用一小部分干净的数据集来指导训练，从而减轻了这一问题，但其行为和训练动态缺乏理论理解。", "innovation": "该研究提供了在噪声标签情况下元重新加权的严格理论分析，揭示了其训练轨迹的三个阶段：（i）对齐阶段，增强与干净数据集一致的样本，抑制矛盾样本；（ii）过滤阶段，直到干净数据集损失稳定，逐步减少噪声样本的权重；（iii）后过滤阶段，噪声过滤对扰动敏感。研究提出了一种轻量级替代方案，集成了均值中心化、行位移和标签符号调制，同时避免了昂贵的双层优化。", "conclusion": "在合成和实际噪声标签基准测试中，该方法在性能上优于高度竞争的重新加权/选择基线，表现出更稳定的表现。"}
{"llm_update_time": "20251015", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.12137", "html_url": "https://arxiv.org/abs/2510.12137", "title": "Credal Transformer: 一种量化和缓解大型语言模型幻觉的稳健方法", "title_en": "Credal Transformer: A Principled Approach for Quantifying and Mitigating Hallucinations in Large Language Models", "authors": "Shihao Ji,Zihui Song,Jiajie Huang", "background": "大型语言模型（LLMs）会产生貌似有信心但实际上却不准确的断言。这种现象起源于Transformer的Softmax函数，它通过将模棱两可的注意力分数压缩为单一概率分布，从而使模型对不确定性信息视而不见。因此，文章提出了新的架构来解决这一问题，即Credal Transformer，它引入了一种基于证据理论的Credal Attention Mechanism (CAM)，以直接衡量模型的不确定性。通过将注意力分数重新定义为狄利克雷分布的证据质量，Credal Transformer确保当证据充足时恢复标准的注意力功能，而当证据不足时则表现为更散布的分布，表示模棱两可的情况。该方法能够识别不合适的输入，量化不确定性和减少对不可回答问题的自信错误，通过弃权仅回答有把握的问题来提高可靠性.", "innovation": "Credal Transformer通过引入Credal Attention Mechanism (CAM)来解决大型语言模型幻觉问题。CAM通过生成一个“credal set”（即一组概率分布）而不是单一的注意力向量，直接衡量模型的不确定性。同时，该方法通过重新定义注意力分数为狄利克雷分布的证据质量，确保在证据充分时恢复标准注意力功能，而在证据不足时表现出更大的不确定性，从而缓解幻觉问题，增强模型的可靠性。此外，该方法还提供了一种集成不确定性量化的模型设计范式，为更可靠的AI奠定基础。", "conclusion": "本文提出了一种新的架构（Credal Transformer），通过将注意力机制与证据理论相结合来直接衡量模型不确定性并缓解幻觉问题。该方法不仅识别并处理了不合适的输入，还显著减少了对不可回答问题的自信错误，同时还通过量化不确定性提高了模型的可靠性。这为大型语言模型的改进和更稳健的人工智能系统设计提供了新的视角和技术支持。"}
{"llm_update_time": "20251015", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.12214", "html_url": "https://arxiv.org/abs/2510.12214", "title": "DE3S: 双增强软稀疏形状学习在医学早期时间序列分类中的应用", "title_en": "DE3S: Dual-Enhanced Soft-Sparse-Shape Learning for Medical Early Time-Series Classification", "authors": "Tao Xie,Zexi Tan,Haoyi Xiao,Binbin Sun,Yiqun Zhang", "background": "在医疗应用中，早期时间序列分类（ETSC）对于时间敏感的场景，如重症监护病房（ICU）中的败血症预测至关重要。由于延迟预测导致大量死亡，ETSC能够显著提高ICU资源利用效率和医疗精准度。然而，现有的ETSC方法在准确性和及时性之间存在冲突，它们往往通过牺牲一方来追求另一方。弱初期信号和类别不平衡使得捕捉早期阶段的微妙模式变得困难。", "innovation": "本文提出了一种名为Dual-Enhanced Soft-Sparse-Shape Learning for Medical Early Time-Series Classification (DE3S)的新方法。其创新点包括：1. 结合传统的时序增强和基于注意力的全局时序增强的综合双增强策略，用于稳健的特征表示学习；2. 基于注意力得分的软稀疏形状机制，动态保留关键模式并聚合不重要的形状到有代表性的一组令牌中；3. 双路径 expert 混合网络（MoE）和 Inception 模块融合架构，其中 MoE 在形状内执行局部学习，而多个尺度的 Inception 模块捕获形状间的全局模式。", "conclusion": "DE3S框架通过加权交叉熵损失来处理类别不平衡，并在主题一致性数据集上表现出色。在六个真实世界的医疗数据集上的广泛实验表明，该方法具有行业领先的表现，并且消融研究确认了其组件的有效性。"}
{"llm_update_time": "20251015", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.12217", "html_url": "https://arxiv.org/abs/2510.12217", "title": "HALF: 意识到危害的LLM公平性评估与部署对齐", "title_en": "HALF: Harm-Aware LLM Fairness Evaluation Aligned with Deployment", "authors": "Ali Mekky,Omar El Herraoui,Preslav Nakov,Yuxia Wang", "background": "大型语言模型（LLMs）正被广泛应用到高影响领域，如临床决策支持、法律分析、招聘和教育等。因此，在部署前需要评估公平性和偏见，而现有评估方法缺乏实际场景的依据，不能考虑不同类型的危害严重性，例如外科手术中的偏见决策不应与文本总结中的风格化偏见等同看待。该研究尝试弥合这一差距，提出HALF（Harm-Aware LLM Fairness）框架，该框架在实际应用中评估模型偏见，并根据危害严重性加权结果。HALF使用五阶段流程将九个应用领域分为三个层级（严重、中等、轻微）的分级框架来组织这些领域。", "innovation": "HALF框架提出了一种部署对齐的评估方法，不仅考虑模型偏见，还根据实际使用情境中的危害严重性对结果进行加权。它提出了一个五阶段流程，将九个应用领域按照危害严重性分为三个层级：严重、中等和轻微，以此来进行模型公平性评估。研究结果发现，不同领域中LLM的公平性表现不一致，且模型大小或性能并不能保证公平性。此外，研究显示在医疗决策支持中推理模型表现更好，而在教育中的表现较差。", "conclusion": "HALF揭示了以往基准评估成功与实际部署准备之间的明显差距。"}
{"llm_update_time": "20251015", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.12253", "html_url": "https://arxiv.org/abs/2510.12253", "title": "扩散模型在强化学习中的应用：基础、分类与进展", "title_en": "Diffusion Models for Reinforcement Learning: Foundations, Taxonomy, and Development", "authors": "Changfu Xu,Jianxiong Guo,Yuzhu Liang,Haiyang Huang,Haodong Zou,Xi Zheng,Shui Yu,Xiaowen Chu,Jiannong Cao,Tian Wang", "background": "差分模型（DMs）作为生成模型的重要类别，在强化学习（RL）中展现出多模态表达能力、稳定训练和轨迹层次规划的显著优势。本文综述了基于扩散的RL方法，审视其在解决RL研究领域关键挑战中的应用。", "innovation": "本文建立了基于功能和方法论的双轴分类体系，组织了扩散与强化学习集成的相关领域；详细探讨了单智能体和多智能体环境中扩散方法的应用；分析了当前方法的局限性，并指出了未来研究的关键方向。", "conclusion": "文章总结了基于扩散的RL的发展方向并保持了GitHub存储库，提供了相关的论文和其他资源以应用DMs至RL领域。"}
{"llm_update_time": "20251015", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.12252", "html_url": "https://arxiv.org/abs/2510.12252", "title": "PromptLocate: 定位提示注入攻击", "title_en": "PromptLocate: Localizing Prompt Injection Attacks", "authors": "Yuqi Jia,Yupei Liu,Zedian Shao,Jinyuan Jia,Neil Gong", "background": "提示注入攻击通过在输入数据中加入一个注入的提示（包括指令和数据），使大型语言模型执行攻击者指定的任务，而不是其原本的任务。定位被注入的提示对攻击后的法医分析和数据恢复至关重要。尽管这一领域的重要性日益提高，但提示注入的定位仍然没有得到充分的研究。", "innovation": "本文提出了一种名为PromptLocate的方法，它是第一个用于定位注入提示的方法。PromptLocate包含三个步骤：分割被污染的数据为语义上一致的片段；识别被注入指令污染的片段；确定被注入数据污染的片段。实验结果表明，PromptLocate能够准确地定位八种现有和适应性攻击下的注入提示。", "conclusion": "本文通过引入PromptLocate方法，填补了提示注入定位这一领域的空白，并展示了其在多种攻击类型下的有效性和准确性。"}
{"llm_update_time": "20251015", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.12229", "html_url": "https://arxiv.org/abs/2510.12229", "title": "通过机制可解释性分析精调的LLM中的道德偏差", "title_en": "Analysing Moral Bias in Finetuned LLMs through Mechanistic Interpretability", "authors": "Bianca Raimondi,Daniela Dalbagno,Maurizio Gabbrielli", "background": "大型语言模型（LLMs）在精调过程中会表现出类似人类的偏见，但这些偏见是如何体现出来的机制尚不明确。为了更好地理解精调过程中的道德偏差，作者通过分析3个开源权重LLM对这一问题进行了探究。他们发现，这种偏见不仅在精调过程中被学习，也特异性地存在于模型的某些特定层中。通过仅对少量关键层进行干预，即可消除这种效应，从而为我们提供了一个新的证据，即可以通过针对性的干预措施来解释、定位和缓解LLM中的社会偏见，而无需重新训练模型。", "innovation": "提出了通过层插桩分析的方法，证明了道德偏见不仅在精调过程中被学习，还特异性地存在于模型的某些特定层中。特别的是，作者发现只需插入预训练模型的激活到少量关键层，即可消除这一效应，这为理解并解决LLM中的偏见提供了新方法。这一研究方法为更深层次地理解LLM的偏见机制提供了新的视角，也提供了缓解偏见的解决方案。", "conclusion": "研究发现，社会偏见在LLM中的出现并非不可解释，也能被精准定位并采取干预措施加以缓解。这种方法不仅可以删除这些偏见，还为缓解LLM中的偏见提供了新的思路，即通过干预特定层的激活即可消除这些偏见，而不需要重新训练整个模型。"}
{"llm_update_time": "20251015", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.12265", "html_url": "https://arxiv.org/abs/2510.12265", "title": "实时视频通信中的人机交互带宽估计以优化用户体验", "title_en": "Human-in-the-Loop Bandwidth Estimation for Quality of Experience Optimization in Real-Time Video Communication", "authors": "Sami Khairy,Gabriel Mittag,Vishak Gopal,Ross Cutler", "background": "视频会议系统的质量体验(QoE)受发端和接收端之间时间变化可用带宽的准确估计影响显著。由于网络架构和协议栈的快速变化以及定义能够可靠提高用户体验的QoE指标的难度，实时通信中的带宽估计依然是一项开放的挑战。", "innovation": "提出了一种部署在实际环境中的基于数据的人机交互带宽估计框架。该框架首先通过主观用户评价训练客观QoE奖励模型，衡量实时视频会议系统中的音频和视频质量。然后收集微软 Teams 实际通话中的带宽估计训练数据集，并引入一种新颖的分布离线强化学习算法训练基于神经网络的带宽估计器，旨在提高用户体验。", "conclusion": "实际A/B测试表明，所提方案相比基准带宽估计器将主观质量较差的通话比例降低了11.41%。此外，提出的离线强化学习算法被基准测试于D4RL任务中，证明了其在带宽估计之外的一般化能力。"}
{"llm_update_time": "20251015", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.12245", "html_url": "https://arxiv.org/abs/2510.12245", "title": "MoRA: On-the-fly Molecule-aware Low-Rank Adaptation Framework for LLM-based Multi-Modal Molecular Assistant", "title_en": "MoRA: On-the-fly Molecule-aware Low-Rank Adaptation Framework for LLM-based Multi-Modal Molecular Assistant", "authors": "Tao Yin,Xiaohong Zhang,Jiacheng Zhang,Li Huang,Zhibin Zhang,Yuansong Zeng,Jin Xie,Meng Yan", "background": "在药物发现领域，有效整合分子图结构与大型语言模型（LLM）是一个关键挑战。现有大多数多模态对齐方法通常通过微调LLM或同时添加静态适配器来处理这些结构。然而，这些方法有两个主要限制：一是优化一个共享参数空间，限制了模型捕捉特定分子结构特征的能力；二是特地微调LLM可能导致灾难性遗忘，削弱其泛化推理能力。", "innovation": "本文提出了一种实例特定的参数空间对齐方法（Mask-aware Low-Rank Adaptation, MoRA），该方法可以为每个分子输入实时生成一组独特的低秩适应权重。这些权重随后被动态注入到冻结的LLM中，使模型能够根据每个分子输入的结构进行适应，同时保持LLM的核心知识。", "conclusion": "广泛的实验表明，MoRA在关键的分子任务，如化学反应预测和分子描述等方面，实例特定的动态适应优于静态适应的基础模型，包括在反应预测精确度上提高了14.1%的相对改进，以及量子性质预测错误降低了22%。代码可在此网站访问。"}
{"llm_update_time": "20251015", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.12275", "html_url": "https://arxiv.org/abs/2510.12275", "title": "TFGA-Net: Temporal-Frequency Graph Attention Network for Brain-Controlled Speaker Extraction", "title_en": "TFGA-Net: Temporal-Frequency Graph Attention Network for Brain-Controlled Speaker Extraction", "authors": "Youhao Si,Yuan Liao,Qiushi Han,Yuhang Yang,Rui Dai,Liya Huang", "background": "基于脑电图（EEG）信号的听觉注意解码（AAD）的迅速发展为通过EEG驱动的目标说话人提取提供了可能性。然而，如何有效利用EEG和语音之间目标说话人的共同信息仍然是一个未解决的问题。", "innovation": "本文提出了一种脑控制说话人提取模型，利用听者的EEG记录来提取目标语音。该模型首先从EEG信号中提取多尺度时频特征，进一步结合与任务相关的皮层拓扑结构。此外，使用图卷积网络和自注意力机制以有效利用非欧几里得结构的EEG信号并捕捉其全局特征。为了充分利用融合的EEG和语音特征并保留全局上下文和捕获语音的节奏和语调，提出了将MossFormer与RNN-Free Recurrent结合的MossFormer2作为分离器。实验结果表明，TFGA-Net模型在某些客观评估指标中显著优于最新方法。", "conclusion": "TFGA-Net模型在Cocktail Party和KUL数据集上表现出色，显著优于现有方法。"}
{"llm_update_time": "20251015", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.12266", "html_url": "https://arxiv.org/abs/2510.12266", "title": "HiLoRA: 无需训练的自适应层级LoRA路由方法用于领域泛化", "title_en": "HiLoRA: Adaptive Hierarchical LoRA Routing for Training-Free Domain Generalization", "authors": "Ziyi Han,Huanyu Wang,Zeyu Zhang,Xiangxiang Dai,Xutong Liu,John C.S. Lui", "background": "低秩适应（LoRA）已成为一种广泛使用的大型语言模型（LLM）适应新领域的技术，得益于其模块化设计和在HuggingFace等平台上的广泛可用性。这种可用性激发了努力重用现有的LoRA进行领域泛化的方法。然而，现有方法通常依赖于明确的任务标签或额外训练，这在部署时是不切实际的。此外，它们通常激活固定数量的整体LoRA模块，造成参数冗余或不足，从而降低性能。", "innovation": "本文提出了一种无需训练的框架HiLoRA，通过层级路由LoRA池来执行自适应路由。HiLoRA利用结构化的LoRA属性定义了秩一组件（ROCs），将每个秩参数视为独立单元。对于给定的输入序列，HiLoRA首先适应性地选择一部分LoRA并基于序列级别的高斯似然性确定其ROC分配。在令牌级别，它进一步通过激活最相关信息的ROC来细化路由。此外，还提供了理论保证，说明HiLoRA以高概率选择最相关的LoRA。实验证明，HiLoRA在领域泛化方面实现了显著改进，相比最先进基线方法，准确率提高了多达55%，同时保持相似的推理吞吐量。", "conclusion": "HiLoRA方法在领域泛化上取得了显著的性能提升，具有高概率选择最相关LoRA的理论保证，并且保持了与最先进模型相似的推理速度。"}
{"llm_update_time": "20251015", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.12278", "html_url": "https://arxiv.org/abs/2510.12278", "title": "量子退火在教育环境中的人员排班", "title_en": "Quantum Annealing for Staff Scheduling in Educational Environments", "authors": "Alessia Ciacco,Francesca Guerriero,Eneko Osaba", "background": "本文解决了一个在意大利卡布里地区公立学校中出现的新型雇员分配问题。问题来源于学校中教职工在托儿所、小学和中学间分配的实际案例，受制于可用性、技能及公平性等因素。论文通过开发优化模型并研究基于量子退火的解决方案来探讨此问题，最终通过实际数据的计算实验展示了量子退火在短时间内能够产生平衡安排的能力。这些结果为量子优化方法在教育排程和更广泛的复杂资源配置任务中的实际应用提供了证据。", "innovation": "开发了基于量子退火的优化模型以解决学校雇员分配问题，该方案在实际数据上显示出快速生成合理的分配方案的能力。实验结果首次在该领域的应用中证实了量子退火的有效性与效率优势。", "conclusion": "基于量子退火的方法在教育排班、特别是多校区和不同教育水平之间复杂的人员分配方面显示了潜力。这些方法提供了快速且平衡的分配方案，验证了其在解决复杂资源分配问题中的实际价值。"}
{"llm_update_time": "20251015", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.12255", "html_url": "https://arxiv.org/abs/2510.12255", "title": "浅层稳健性，深层脆弱性：医疗LLM的多轮次评估", "title_en": "Shallow Robustness, Deep Vulnerabilities: Multi-Turn Evaluation of Medical LLMs", "authors": "Blazej Manczak,Eric Lin,Francisco Eiras,James O' Neill,Vaikkunth Mugunthan", "background": "大型语言模型（LLMs）正迅速进入医疗临床使用，但其在实际多轮交互中的可靠性尚未得到充分理解。现有的评估框架通常在理想条件下评估单一回合的问答任务，忽略了实际医疗咨询中常见的相互矛盾的输入、误导性的背景信息以及权威的影响。本研究引入了一种新的框架——MedQA-随访，用于系统性地评估医疗问答的多轮稳健性，着重区分浅层稳健性和深层稳健性，并引入间接直接维度区分基于背景的框架（间接）与明确建议（直接）。利用控制干预方法在MedQA数据集上评估五种最先进的LLMs，发现模型在浅层干扰下表现尚可，但在多轮设置中表现出严重漏洞，准确率从91.2%降至最低13.5%。出人意料的是，间接的、基于背景的干预往往比直接建议更有害，导致模型准确率下降更大。进一步分析显示模型之间的差异，部分模型在重复干预下表现进一步下降，而部分模型则部分恢复甚至提高。这些发现突显了多轮稳健性对于安全可靠部署医疗LLMs的重要性，但这一领域尚未得到充分探索。", "innovation": "本研究提出了MedQA-随访框架，用于系统性地评估医疗问答的多轮稳健性，区分浅层和深层稳健性，并将干预分为间接的基于背景框架和直接建议，这一点是创新之处。通过控制干预在MedQA数据集上评估五种最先进的LLMs，首次揭示了模型在多轮设置下表现出的严重漏洞，并揭示了间接干预往往比直接干预更不利的现象。差异分析显示了更多维度的模型表现差异。这些结果为安全和可靠部署医疗LLMs提供了新的视角。", "conclusion": "本研究揭示了多轮稳健性作为安全和可靠部署医疗LLMs的一个关键但未被充分探索的维度。模型在多轮设置下的准确率显著下降，且间接干预的负面影响更为显著。尽管部分模型在多次干预下表现不稳定，但仍有改进的空间。因此，未来的医疗LLM评估应注重多轮稳健性，关注不同模型的不同表现，以确保临床部署的安全性。"}
{"llm_update_time": "20251015", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.12325", "html_url": "https://arxiv.org/abs/2510.12325", "title": "因果启发的多模态推荐", "title_en": "Causal Inspired Multi Modal Recommendation", "authors": "Jie Yang,Chenyang Gu,Zixuan Liu", "background": "多模态推荐系统通过整合视觉、文本和用户-物品交互数据来增强电子商务和在线广告的个性化推荐。然而，现有的方法常常忽视了两种关键偏差：模态混杂（即潜在因素，如品牌风格或产品类别同时驱动多个模态并影响用户偏好，导致假象的特征-偏好关联），以及交互偏差（即真实的用户偏好与暴露效果和意外点击的噪音混合）。", "innovation": "提出了一种因果启发的多模态推荐框架。具体来说，引入了双通道跨模态扩散模块来识别隐藏的模态混杂因素，使用后门调整、分层匹配和向量量化码本来阻挡混杂路径，并应用前门调整与因果拓扑重建来构建一个去混杂的因果子图。", "conclusion": "在三个真实世界的电子商务数据集上的广泛实验显示，我们的方法不仅超越了当前最先进的基线方法，而且保持了强大的可解释性。"}
{"llm_update_time": "20251015", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.12312", "html_url": "https://arxiv.org/abs/2510.12312", "title": "Deep SPI：通过世界模型实现安全的策略更新", "title_en": "Deep SPI: Safe Policy Improvement via World Models", "authors": "Florent Delgrange,Raphael Avalos,Willem Röpke", "background": "现有的安全策略改进（Safe Policy Improvement，SPI）方法在理论控制策略更新方面提供了支持，但目前的保证主要关注离线、表格形式的强化学习（Reinforcement Learning，RL）。然而，本文扩展了SPI的应用场景，探讨了它在结合世界模型和表示学习的通用在线设置中的应用。这项研究展示了通过限制策略更新到当前策略的局部区域来确保单调改进和收敛的可能性，这与经典的离线RL文献中的安全策略改进定理形成了在线、深度的对应关系。", "innovation": "开发了一个理论框架，通过将策略更新限制在当前策略的局部区域内来确保单调改进和收敛。引入了名为DeepSPI的基于策略的方法，该方法结合了局部转换和奖励损失，并使用正则化的策略更新。DeepSPI在ALE-57基准测试中表现出色，能够匹配或超过包括PPO和DeepMDPs在内的强大基准，同时保留理论保证。", "conclusion": "通过引入DeepSPI算法，该研究将安全的策略改进与世界模型结合，提供了一种在线、深学习的框架来解释过渡和奖励预测损失与表示质量之间的关系。与传统的SPI定理类似，DeepSPI不仅提高了理论安全性，还提供了实际应用中的性能卓越的结果。"}
{"llm_update_time": "20251015", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.12285", "html_url": "https://arxiv.org/abs/2510.12285", "title": "Chinese ModernBERT with Whole-Word Masking", "title_en": "Chinese ModernBERT with Whole-Word Masking", "authors": "Zeyu Zhao,Ningtao Wang,Xing Fu,Yu Cheng", "background": "编码器仅有的Transformer在架构、数据和系统方面取得了进展，实现了准确度、速度和内存效率的帕累托改进。然而，这些改进并没有完全转移到中文中，因为中文的分词和形态学与英语有很大不同。因此，需要一种专门为中文设计的 encoder 来适应这些特点和需求，从而在中文模型中实现类似的改进。", "innovation": "研究引入了名为Chinese ModernBERT的完全从零开始的中文编码器，该编码器结合了以下创新点：1. 针对常见中文前缀和复合词的硬件感知32k BPE词汇表，减少了嵌入预算；2. 整词掩蔽（WWM）结合动态遮挡课程（从30%到15%），使任务难度与训练进度同步；3. 扩展了RoPE和交替局部/全局注意力的预训练管道，将本地上下文从1,024个token扩展到8,192个token；4. 采用阻尼余弦学习率计划，以实现稳定的长期优化。", "conclusion": "Chinese ModernBERT在CLUE基准测试中与强大的中文编码器表现相当，并且在bf16下能够实现高长度序列吞吐量的同时保持强短段序列速度。额外加入少量开放对照数据（如SimCLUE和T2Ranking）后，Chinese ModernBERT在SimCLUE测试集上的表现不断提高，表明了其在语义相似度评估（STS）中与带量化嵌入的Qwen相比的明确扩展路径。该研究将发布分词器和权重，以促进可重复的研究。"}
{"llm_update_time": "20251015", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.12334", "html_url": "https://arxiv.org/abs/2510.12334", "title": "Actor-Critic算法在随时间变化的奖励函数下的有限时间收敛分析", "title_en": "Finite-time Convergence Analysis of Actor-Critic with Evolving Reward", "authors": "Rui Hu,Yu Chen,Longbo Huang", "background": "许多流行的实用强化学习算法采用随时间变化的奖励函数，通过奖励塑形、熵正则化或课程学习等技术，但这些算法的理论基础尚未完全发展。本文提供了首个针对随时间变化的奖励函数进行了Markovian采样下的单时间尺度演员-评论家算法的有限时间收敛分析，分析了在此情况下政策优化和价值估计的影响。", "innovation": "推导了在随时间变化的奖励函数下的演员和评论家错误的非渐进型界，在假设条件下，展示了目标收敛速率可达到$O(1/\text{sqrt}(T))$，与静态奖励情况下的最佳已知速率相符，只要奖励参数的改变足够缓慢。此外，提出了Markovian采样下分布不匹配的新分析方法，提高了静态奖励情况下的最优收敛速率的一倍以上（$\text{log}^2T$倍）。", "conclusion": "通过这些结果，本文为许多流行的强化学习技术提供了理论基础。"}
{"llm_update_time": "20251015", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.12327", "html_url": "https://arxiv.org/abs/2510.12327", "title": "简单投影变体提升ColBERT性能", "title_en": "Simple Projection Variants Improve ColBERT Performance", "authors": "Benjamin Clavié,Sean Lee,Rikiya Takehi,Aamir Shakir,Makoto P. Kato", "background": "多向密集检索方法如ColBERT系统地使用单一层线性投影来降低每个向量的维度。然而，在这种设置中，单一层线性投影具有固有的局限性，尽管这些局限性非关键性。本文探讨了MaxSim操作符对多向检索模型训练梯度流动的影响，并表明这种简单的线性投影在这个环境下存在根本但非关键的限制。", "innovation": "文章研究了用更深入、非线性的前馈线性网络（FFN），如更深层次的FFN块、GLU块和跳连接替换单一层线性投影的可能性。通过系统设计和评估不同的投影块，作者展示了精心设计的最终投影对ColBERT模型下游性能的积极影响。研究还发现许多不同的投影变体表现优于原始线性投影，最佳变体使多种领域中广泛的检索基准的平均性能提高了超过10个NDCG@10点。此外，研究还分析了这些投影块的个别参数，以了解哪些因素影响实验性能，指出放大中间投影和残差连接特别重要。这些消融研究表明，即使是最不理想的投影变体也优于传统的单一层投影，证实了该假设的正确性。并且发现这种效果在随机种子上是稳健的，进一步确认了替换ColBERT模型中的线性层作为稳健的即插即用升级的有效性。", "conclusion": "精心设计的投影块能够显著提高ColBERT的性能，许多投影变体优于原始的单一层线性投影，最佳的投影变体在多个检索基准上提高了大量性能。通过实验发现，尤其重要的性能驱动因素是中间投影的放大和残差连接的使用。替换ColBERT模型中的线性层是可靠的、非侵入式的改进方法。"}
{"llm_update_time": "20251015", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.12376", "html_url": "https://arxiv.org/abs/2510.12376", "title": "深度注意力导向自适应子采样", "title_en": "Deep Attention-guided Adaptive Subsampling", "authors": "Sharath M Shankaranarayana,Soumava Kumar Roy,Prasad Sudhakar,Chandan Aladahalli", "background": "尽管深度神经网络在性能方面取得了显著的提升，但这些进步通常伴随着计算复杂度和成本的增加。在3D体数据或视频分类等任务中，由于存在固有的冗余性，并非所有切片或帧都是必要的。现有的一些解决方案使用Gumbel-max技巧来解决非可微操作的问题，但这些方法只具备任务自适应性而不具备输入自适应性，在实际应用中无法根据不同的输入进行调整，因此不够理想。", "innovation": "本文提出了一种新的可学习的子采样框架，该框架可以集成到任何神经网络架构中，通过引入注意力导向的采样模块，能够在推理过程中根据输入动态调整，从而提升性能并降低深度神经网络模型的复杂度。这种动态适应性不仅能够应对输入自适应问题，还在实际应用中展现出了优越性。", "conclusion": "实验结果表明，该方法在MedMNIST3D的3D医学成像数据集以及两个超声视频分类任务数据集（包括一个真实临床条件下的复杂内部数据集）中均表现出有效性，验证了其在实际应用中的潜力。此类动态子采样框架能够显著提升性能并减少计算复杂度，在实际应用中具有广泛的应用前景。"}
{"llm_update_time": "20251015", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.12379", "html_url": "https://arxiv.org/abs/2510.12379", "title": "LiteVPNet: 一种用于质量关键应用的轻量级视频编码控制网络", "title_en": "LiteVPNet: A Lightweight Network for Video Encoding Control in Quality-Critical Applications", "authors": "Vibhoothi Vibhoothi,François Pitié,Anil Kokaram", "background": "在过去的十年中，电影生产生态系统中的视频工作流为视频流传输技术提出了新的应用场景，例如现场虚拟制作等。这些新流程需要精确的质量控制和能效。现有的转码方法由于缺乏质量控制或计算开销而未能满足这些要求。为了填补这一空白，我们提出了一种轻量级神经网络（LiteVPNet），用于准确预测NVENC AV1编码器的量化参数以达到指定的VMAF（视频质量评估模型平均分数）评分。", "innovation": "所提出的LiteVPNet利用低复杂度特征，包括比特流特征、视频复杂度度量以及基于CLIP的语义嵌入，可以实现广泛的品质目标下VMAF误差低于1.2分。尤其值得注意的是，LiteVPNet在超过87%的测试集中能够将误差控制在2分之内，相比之下，现今最先进的方法大约在61%的测试集中能达到这样的精度。", "conclusion": "LiteVPNet在不同质量区域的性能表明了它能够在保障高质量的前提下，通过更高效的能源使用提高高价值内容的传输和流媒体，从而丰富高质量媒体体验。"}
{"llm_update_time": "20251015", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.12364", "html_url": "https://arxiv.org/abs/2510.12364", "title": "(R)evolution of Programming: Vibe Coding as a Post-Coding Paradigm", "title_en": "(R)evolution of Programming: Vibe Coding as a Post-Coding Paradigm", "authors": "Kevin Krings,Nino S. Bohn,Thomas Ludwig", "background": "近期生成式人工智能（GenAI），尤其是大型语言模型的进展，为软件开发实践带来了新的可能性。本文探讨了新兴的Vibe Coding (VC) 理念，强调开发者和AI系统之间直观的、情绪驱动的和即兴的互动。该研究基于用户端开发（EUD）的理论基础，通过对GitHub Copilot等工具支持的常规编程方法进行对比研究，提出了VC的概念并分析了其特征及其带来的挑战和机遇。访谈结果揭示了VC在五个主题维度上的表现：创造力、可持续性、编程的未来、协作和批判。研究结果对比了传统编程中的“协驾”视角与VC的“共生”视角，认为VC有望重新定义开发者的角色，模糊专业开发者与非专业开发者之间的界限。尽管VC有其独特的优势与应用潜力，但也需要解决可重复性、可扩展性和包容性等挑战问题。研究者认为VC代表了编程文化的重要转变，值得在人机交互和软件工程研究中进一步探究。", "innovation": "本文通过引入Vibe Coding (VC) 理念，打破了传统编程框架，提出了开发者和AI系统之间直观的、情绪驱动的和即兴的互动模式。VC以其独特的视角重新定义了编程文化，并指出未来编程实践将更多地融合情感和技术的交互体验。文章通过对比研究，构造了“共生”与“协驾”两种编程模式，并揭示了VC带来的重新定义专业与非专业开发者的角色转变和新挑战。文章提出VC是值得未来研究的主题，有望在人机交互和软件工程领域中引发更多关注。", "conclusion": "本文提出了Vibe Coding (VC) 理念，将其作为探讨编程文化和未来编程实践的发展方向。研究结果揭示了VC在创造力、可持续性、编程的未来、协作和批判五个维度的特殊表现，并将其与传统编程方法进行对比，指出了VC带来的角色转变和挑战。研究者认为VC代表了编程文化的转变，未来的研究需要继续深入探讨如可重复性、可扩展性和包容性等关键问题，并在人机交互和软件工程领域进一步探究其应用和发展潜力。"}
{"llm_update_time": "20251015", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.12367", "html_url": "https://arxiv.org/abs/2510.12367", "title": "LLM-REVal：我们能够信任LLM审稿人吗？", "title_en": "LLM-REVal: Can We Trust LLM Reviewers Yet?", "authors": "Rui Li,Jia-Chen Gu,Po-Nien Kung,Heming Xia,Junfeng liu,Xiangwen Kong,Zhifang Sui,Nanyun Peng", "background": "大型语言模型（LLMs）的快速发展促使研究人员广泛将其集成到学术工作流程中，有可能重塑研究和审稿的方式。尽管先前的研究强调了LLMs在支持研究和同行评议方面的潜力，但他们的双重角色以及研究与审稿之间的复杂互动带来了新的风险，这些风险尚待深入探索。本文关注LLMs深度集成到审稿和研究流程中如何影响学术公平性，通过模拟研究，探讨使用LLMs作为审稿人的潜在风险。该模拟包括生成和修订论文的研究代理和服务评估审稿的审稿代理，并基于模拟结果进行人工注释，发现LLMs评论者系统地提高了生成型论文的评分，并对人类撰写的论文给出了负面评价，这揭示了两种主要偏见：倾向于LLM生成的写作风格的语言特征偏见和对负面评论的厌恶。这些结果揭示了在不充分谨慎的情况下，LLMs在同行评议周期中的部署将对人类作者和学术研究带来的风险和公平性问题。然而，根据LLMs审稿人的建议进行修订可以在LLMs和人类评估中获得质量提升，表明LLMs作为审稿人的潜力，特别是在早起研究者中和提升低质量论文中。", "innovation": "本文通过模拟引入研究和审稿代理，探讨了LLMs在审稿中的系统偏见和潜在风险，揭示了对LGMs审稿人的信任问题。这种研究方法有助于更好地理解LLMs在学术工作流程中的作用，并提出进一步改进的方法。", "conclusion": "研究结果强调了在没有充分谨慎的情况下部署LLMs进行同行评议带来的风险和公平性问题。然而，通过指导性修订，可以利用LLMs作为审稿人来提高研究质量和低质量论文的水平。这表明，适当管理和规范下的LLMs具有作为审稿人的潜力，尤其是在提高早期研究者的质量方面和提升低质量论文方面。"}
{"llm_update_time": "20251015", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.12408", "html_url": "https://arxiv.org/abs/2510.12408", "title": "使用条件流匹配模型增强低场磁共振图像质量", "title_en": "Low-Field Magnetic Resonance Image Quality Enhancement using a Conditional Flow Matching Model", "authors": "Huu Tien Nguyen,Ahmed Karam Eldaly", "background": "低场磁共振成像(LF-MRI)因其经济性和便携性正迅速发展，但由于其固有的低信噪比和诊断质量下降的问题，图像质量不高。传统生成模型依赖迭代采样或对抗性目标，而该研究提出了一种基于条件流匹配(CFM)的新框架，该框架通过直接回归最优速度场来学习从噪声分布到目标数据分布的连续流动，以提高低场MRI图像的质量，填补高场和低场图像之间的质量差距，而不需要昂贵的基础设施。", "innovation": "该研究提出了一种基于条件流匹配(CFM)的新框架。与传统的依赖迭代采样或对抗性目标的生成模型不同，CFM通过直接回归最优速度场来学习从噪声分布到目标数据分布的连续流动。实验证明，CFM不仅实现了最先进的性能，还在分布内和分布外数据上表现出良好的泛化能力。此外，与竞争的深度学习方法相比，它使用的参数要少得多。这些结果突显了CFM作为MRI重建的强大且可扩展工具的潜力，特别是在资源有限的临床环境中。", "conclusion": "CFM不仅实现了最先进的性能，还在分布内和分布外数据上表现出良好的泛化能力。与竞争的深度学习方法相比，它使用的参数要少得多。这些结果突显了CFM作为MRI重建的强大且可扩展工具的潜力，特别是在资源有限的临床环境中。"}
{"llm_update_time": "20251015", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.12482", "html_url": "https://arxiv.org/abs/2510.12482", "title": "具有数据增强能力的文本-图像融合方法用于指示医学图像分割", "title_en": "A Text-Image Fusion Method with Data Augmentation Capabilities for Referring Medical Image Segmentation", "authors": "Shurong Chai,Rahul Kumar JAIN,Rui Xu,Shaocong Mo,Ruibo Hou,Shiyu Teng,Jiaqing Liu,Lanfen Lin,Yen-Wei Chen", "background": "深度学习依赖于数据增强以缓解数据有限的问题，尤其是在医学影像领域。近年来，多模态学习结合了文本和图像进行分割，称为引用或文本引导图像分割。然而，常见的数据增强技术（如旋转和翻转）会破坏图像和文本之间的空间对齐，从而削弱性能。", "innovation": "提出了一个早期融合框架，在数据增强之前将文本和视觉特征结合在一起，以保持空间一致性。还设计了一个轻量级生成器，将文本嵌入投影到视觉空间，以弥合语义差距。生成的伪影像可视化显示了准确的区域定位。该方法在三个医学影像任务和四种分割框架上进行了评估，取得了最先进的结果。", "conclusion": "该方法在三个医学影像任务和四种分割框架上的评估中取得了最先进的结果，代码可在GitHub上公开获取。"}
{"llm_update_time": "20251015", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.12476", "html_url": "https://arxiv.org/abs/2510.12476", "title": "当个性化迷惑检测器：机器生成文本检测中的特征反转陷阱", "title_en": "When Personalization Tricks Detectors: The Feature-Inversion Trap in Machine-Generated Text Detection", "authors": "Lang Gao,Xuhui Li,Chenxi Wang,Mingzhe Li,Wei Liu,Zirui Song,Jinghui Zhang,Rui Yan,Preslav Nakov,Xiuying Chen", "background": "大型语言模型（LLMs）在语言生成方面变得越来越强大，能够生成流畅的文本，甚至模仿个人风格。然而，这种能力也增加了身份冒用的风险。据我们所知，没有先前的工作研究过个性化机器生成文本（MGT）的检测。因此，该领域存在未解决的研究缺口。", "innovation": "引入了首个针对个性化场景下检测器鲁棒性的基准数据集`dataset`，基于文学和博客文本及其由LLM生成的模仿版本构建。提出了一个简单且可靠的方法`method`，用于预测个性化场景下检测器性能的变化趋势。", "conclusion": "该方法通过识别与反转特征对应的潜在方向，并构建主要在这些特征上有所区别的探针数据集，来评估检测器依赖性。实验结果显示，该方法可以准确预测检测器性能变化的方向和幅度，与实际性能差距的相关性达到85%。希望这项工作能够促进个性化文本检测领域的进一步研究。"}
{"llm_update_time": "20251015", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.12384", "html_url": "https://arxiv.org/abs/2510.12384", "title": "多组学整合揭示人类衰老的异质型象", "title_en": "Phenome-Wide Multi-Omics Integration Uncovers Distinct Archetypes of Human Aging", "authors": "Huifa Li,Feilong Tang,Haochen Xue,Yulong Li,Xinlin Zhuang,Bin Zhang,Eran Segal,Imran Razzak", "background": "衰老是一个高度复杂且异质的过程，不同的个体衰老速度不同，因此生物年龄（BA）比生理年龄更能准确反映生理衰退。尽管以往的研究使用单组学数据建立衰老时钟，但这些方法往往未能捕捉到人类衰老的全分子复杂性。该项目利用了包含12,000名30至70岁成年人的大规模队列，这些成年人具有广泛的纵向描述，涵盖了临床、行为、环境和多组学数据集——包括转录组学、脂质组学、代谢组学和微生物组数据。通过使用可以建模非线性生物动力学的先进机器学习框架，开发并严格验证了多组学衰老时钟，该时钟可以稳健地预测多种健康结果和未来疾病风险。集成多组学分子档案的无监督聚类揭示了不同的生物学亚型衰老，揭示了衰老轨迹中的显著异质性和不同衰老模式相关的通路特异性改变。这些发现表明了多组学整合在解码衰老分子景观中的力量，并为个性化健康跨度监测和预防与年龄相关的疾病的精准策略奠定了基础。", "innovation": "该项目利用大规模队列研究，开发了多组学衰老时钟，这是对以往单组学数据研究的重要创新。首先，多组学数据集的整合提供了更全面的分子复杂性分析，从而提高了对衰老过程的理解。其次，利用先进的机器学习框架，可以更准确地建模非线性生物动力学，提高了衰老时钟的预测准确性。最后，通过无监督聚类，揭示了丰富而具体的生物亚型，展示了异质性的独特性及其与不同衰老模式相关的通路特异性变化。这些发现为个性化健康寿命监测和预防与年龄相关的疾病提供了新的策略。", "conclusion": "多组学整合与聚类分析揭示了人类衰老的异质型象，证明了生物年龄是一个比生理年龄更准确的衰老指标。该研究不仅深入剖析了衰老过程中的分子变化，也为未来的健康监测和疾病预防提供了个性化的精准策略，为研究与年龄相关的疾病提供了新的见解和方法。"}
{"llm_update_time": "20251015", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.12389", "html_url": "https://arxiv.org/abs/2510.12389", "title": "字节划分差异作为基础设施偏差：如何子词系统在LLM访问和效率上创造不平等", "title_en": "Tokenization Disparities as Infrastructure Bias: How Subword Systems Create Inequities in LLM Access and Efficiency", "authors": "Hailay Kidu Teklehaymanot,Wolfgang Nejdl", "background": "字节划分差异对多语言人群获得人工智能的公平接入构成显著障碍。这项研究对超过200种语言的大规模跨语言字节划分效率进行了评估，以系统量化大型语言模型中的计算不平等。研究采用了标准化实验框架，应用一致的预处理和标准化协议，并通过tiktoken库对所有语言样本进行统一的字节划分，收集了全面的字节划分统计数据，包括句子每字节（TPS）和相对字节划分成本（RTC）等评价指标，与英语基准进行对比。研究发现，拉丁字母体系的语言表现出高字节划分效率，而非拉丁字母体系和形态复杂语言则面临显著的字节划分膨胀，RTC比率通常高达3-5倍，这导致了被代表不足的语言的计算成本增加和有效语境利用减少。整体而言，研究结果揭示了当前AI系统中的结构性不平等，低资源和非拉丁字母语言的使用者面临不相称的计算劣势。未来的研究应优先考虑制定基于语言的字节划分策略和适应性词汇构建方法，以确保更加包容和计算公平的多语言AI系统。", "innovation": "研究采用标准化的实验框架，对超过200种语言进行了大规模的跨语言字节划分效率评估，系统量化了大型语言模型中的计算不平等。通过tiktoken库的一致应用和统一的字节划分，收集了全面的字节划分统计数据，建立了相对字节划分成本（RTC）等评价指标，与英语基准进行对比。研究揭示了拉丁字母体系和非拉丁字母体系语言之间的显著字节划分效率差异。提出了应优先考虑制定基于语言的字节划分策略和适应性词汇构建方法，以确保提高计算公平性和包容性。", "conclusion": "研究表明，当前AI系统在字节划分效率上存在结构性不平等，低资源和非拉丁字母语言的使用者面临显著的计算劣势。未来的AI系统应当具备更适应语言多样性的特征，建立更公平的计算环境，确保所有语言群体都能平等地受益于先进的人工智能技术。"}
{"llm_update_time": "20251015", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.12503", "html_url": "https://arxiv.org/abs/2510.12503", "title": "不同指定场景下可微因果发现的鲁棒性", "title_en": "The Robustness of Differentiable Causal Discovery in Misspecified Scenarios", "authors": "Huiyang Yi,Yanyan He,Duxin Chen,Mingyu Kang,He Wang,Wenwu Yu", "background": "因果发现旨在从目标数据中学习变量间的因果关系，是机器学习中的基础任务。然而，现有的因果发现算法依赖于无法验证的因果假设，这种假设在实际数据中难以满足，从而限制了因果发现在实际场景中的广泛应用。", "innovation": "本文在八大模型假设违反条件下，广泛测试了理论假设为独立同分布数据的各种主流可微因果发现算法的实证性能。实验结果显示，除了比例变化的情况外，可微因果发现方法在结构汉明距离和结构干预距离的度量中对所推断的图形表现出鲁棒性。同时，本文还提供了可微因果发现方法性能的理论解释。", "conclusion": "本文旨在在模型假设违反情况下全面评估最近的可微因果发现方法的性能，并提供了因果发现合理评估的标准，以进一步促进其在实际场景中的应用。"}
{"llm_update_time": "20251015", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.12516", "html_url": "https://arxiv.org/abs/2510.12516", "title": "BoN Appetit Team at LeWiDi-2025: Best-of-N Test-time Scaling Can Not Stomach Annotation Disagreements (Yet)", "title_en": "BoN Appetit Team at LeWiDi-2025: Best-of-N Test-time Scaling Can Not Stomach Annotation Disagreements (Yet)", "authors": "Tomas Ruiz,Siyao Peng,Barbara Plank,Carsten Schwemmer", "background": "测试时缩放是一类技术，在推理时通过额外的计算来提高LLM输出的表现。这些技术通常应用于具有正确答案验证的领域，如数学和编程。然而，这些方法尚未扩展到涉及标注分歧的LeWiDi-2025任务。", "innovation": "将测试时缩放技术应用于LeWiDi-2025任务以评估标注分歧。实验使用了三种测试时缩放方法：两个基准算法(Model Averaging和Majority Voting)和一种Best-of-N采样方法。结果发现，后两种方法提高了LLM在LeWiDi任务上的表现，但Best-of-N方法未能做到。", "conclusion": "Best-of-N测试时缩放方法尚未从数学任务成功转移至LeWiDi任务，研究分析了可能的原因。"}
{"llm_update_time": "20251015", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.12537", "html_url": "https://arxiv.org/abs/2510.12537", "title": "通过平衡得分导向扩散实现无条件的人类运动和形状生成", "title_en": "Unconditional Human Motion and Shape Generation via Balanced Score-Based Diffusion", "authors": "David Björkstrand,Tiesheng Wang,Lars Bretzner,Josephine Sullivan", "background": "最近的研究探索了多种用于生成人类运动的人工智能模型家族，包括变分自编码器（VAEs）、生成对抗网络（GANs）以及基于扩散的模型。尽管这些方法在结构和工作原理上有所不同，许多模型需要使用过度参数化输入特征和辅助损失来提升实证效果。研究表明，即使仅使用精确的特征空间规范化和针对标准L2得分匹配损失的解析权重，得分导向扩散模型仍然可以与最先进的人类运动无条件生成结果相媲美，而且这一过程可以直接生成运动和形状，避免了后期形状恢复的滞后性问题。", "innovation": "该研究提出了一种平衡得分导向扩散的方法，在无需使用过度参数化输入特征和辅助损失的情况下，可以直接生成运动和形状，并且验证了这一方法可以与现有的最先进结果相竞争。此外，该方法提供了一个清楚的理论动机，并通过对比实验展示了每项修改的独立有效性。", "conclusion": "该研究证明了基于得分导向扩散模型在无需过度参数化输入特征和辅助损失的前提下，能够直接生成运动和形状，其性能可与当前的最先进结果相媲美。通过具体实验进一步说明了每项方法改进的有效性。"}
{"llm_update_time": "20251015", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.12494", "html_url": "https://arxiv.org/abs/2510.12494", "title": "PubSub-VFL: 通过发布者/订阅者架构在异构环境中实现高效的双端分割学习", "title_en": "PubSub-VFL: Towards Efficient Two-Party Split Learning in Heterogeneous Environments via Publisher/Subscriber Architecture", "authors": "Yi Liu,Yang Liu,Leqian Zheng,Jue Hong,Junjie Shi,Qingyou Yang,Ye Wu,Cong Wang", "background": "在数字经济快速发展的背景下，组织之间的数据协作已成为推动各行业增长的成熟业务模式。然而，隐私担忧使得直接数据共享变得不切实际。为解决这一问题，双端分割学习（即垂直联邦学习）作为一种保障安全协作学习的潜在解决方案而兴起。尽管该架构有诸多优点，但仍有待提高的方面，如低计算资源利用率和训练效率低下。具体而言，同步依赖设计会增加训练延迟，而参与者之间资源和数据的异质性进一步阻碍了高效的计算过程。", "innovation": "为克服这些挑战，本文提出了PubSub-VFL，一种基于发布者/订阅者架构的创新双端分割学习范式，旨在提升高计算效率。PubSub-VFL通过利用发布者/订阅者架构的解耦能力和参数服务器架构的数据并行性，设计了一个分层异步机制，从而降低训练延迟和提高系统效率。此外，为了缓解资源和数据异质性导致的训练不平衡，文章提出了一个基于参与者系统配置的优化问题，允许在保抽数隐私的同时选择最优超参数。理论分析表明，PubSub-VFL实现稳定收敛，并与差分隐私等安全协议兼容。广泛的实验证明了其有效性，与最先进的基线相比，PubSub-VFL不仅提高了训练速度（加快了2至7倍），且资源利用率高达91.07%。", "conclusion": "本研究提出了一种新的双端分割学习范式——PubSub-VFL，该范式采用发布者/订阅者架构，通过解耦机制和数据并行性设计分层异步机制，实现了高效计算，克服了传统架构的局限，展示了显著的训练加速和高资源利用率。"}
{"llm_update_time": "20251015", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.12541", "html_url": "https://arxiv.org/abs/2510.12541", "title": "基于AI的心电图信号实时预处理方法评估", "title_en": "Evaluation of Real-Time Preprocessing Methods in AI-Based ECG Signal Analysis", "authors": "Jasmin Freudenberg,Kai Hahn,Christian Weber,Madjid Fathi", "background": "便携式心电图系统日益流行，同时人们对于隐私合规、能效高、实时性要求也越来越高，这对信号处理提出了新的要求。为此，边缘计算领域日益受到重视，因为它能减少延迟时间并提高数据安全性。在此背景下，FACE项目旨在利用边缘和云计算的优势，开发一种创新的机器学习解决方案，用于分析长期心电图。该项目中，对心电图信号的各种预处理步骤进行了评估，以确定其在项目中的适用性。方法的选择特别基于能耗、处理能力以及实时性等标准.", "innovation": "FACE项目将边缘技术和云计算结合起来，开发了一种创新的机器学习解决方案，用于长期心电图的分析。该项目特别注重心电图信号的各种预处理步骤，并基于能耗、处理能力和实时性等标准来选择适合在边缘区域使用的方法.", "conclusion": "通过分析多种心电图信号的预处理步骤，该项目确定了最适合FACE项目的方法。这种方法不仅提高了数据处理能力，还确保了实时性和能量效率，有效地利用了边缘计算资源，满足了心电图分析中的主要需求。"}
{"llm_update_time": "20251015", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.12604", "html_url": "https://arxiv.org/abs/2510.12604", "title": "SMILE: SeMantic Ids Enhanced CoLd Item Representation for Click-through Rate Prediction in E-commerce SEarch", "title_en": "SMILE: SeMantic Ids Enhanced CoLd Item Representation for Click-through Rate Prediction in E-commerce SEarch", "authors": "Qihang Zhao,Zhongbo Sun,Xiaoyang Zheng,Xian Guo,Siyuan Wang,Zihan Liang,Mingcan Peng,Ben Chen,Chenyi Lei", "background": "现代搜索和推荐平台的兴起使得冷启动项目的协作信息不足加剧了现有项目中的马太效应，挑战了平台的多样性，成为长期存在的问题。现有方法通过将侧内容与协作信息对齐，从而通过高流行度项目传输合作信号到冷启动项目，但这些方法未能考虑合作与内容之间的不对称性，以及项目之间的细微差别。", "innovation": "提出了基于融合语义ID对齐的物品表示增强方法SMILE。具体来说，通过RQ-OPQ编码对物品内容和协作信息进行量化，并经过两步对齐：RQ编码跨项目传输共享的合作信号，而OPQ编码学习项目的差异化信息。", "conclusion": "大规模工业数据集上的离线实验综合展示了SMILE的优势，并严格的在线A/B测试确认了显著改进：点击率+1.66%，买家+1.57%，订单量+2.17%。"}
{"llm_update_time": "20251015", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.12603", "html_url": "https://arxiv.org/abs/2510.12603", "title": "暗中推理：潜在空间中的交错视觉-文本推理", "title_en": "Reasoning in the Dark: Interleaved Vision-Text Reasoning in Latent Space", "authors": "Chao Chen,Zhixin Ma,Yongqi Li,Yupeng Hu,Yinwei Wei,Wenjie Li,Liqiang Nie", "background": "多模态推理旨在通过在达到最终答案之前加入中间推理步骤来增强MLLM的能力。它从仅基于文本的推理发展到结合视觉信息，使思考过程能够通过图像和文本传达。尽管这种方法有效，但现有的多模态推理方法依赖于需要大量视觉-文本注释并且会带来推理延迟的显式推理步骤。针对这些问题，提出了多模态潜在推理，具有多模态表示、减少注释和推理效率的优势，结合提出了交错视觉-文本潜在推理（IVT-LR）方法，在潜在空间中同时注入视觉和文本信息于推理过程中。IVT-LR表示每一步推理，通过结合两部分：潜在文本（前一步的隐藏状态）和潜在视觉（选定的一组图像嵌入）来达成目标。进一步引入了渐进的多阶段训练策略，使MLLM能够完成上述多模态潜在推理步骤。", "innovation": "交错视觉-文本潜在推理（IVT-LR）在潜在空间中引入交错视觉和文本信息，从而用隐式方式表示推理步骤，并提出一种渐进的多阶段训练策略来帮助MLLM实现这种多模态潜在推理。通过M3CoT和ScienceQA的实验，IVT-LR方法显著提高了准确率并缩短了推理时间。", "conclusion": "实验结果表明，IVT-LR方法在M3CoT和ScienceQA上的准确率平均提高了5.45%，同时推理速度提高了5倍以上，相较现有方法显著提升了效率和准确度。"}
{"llm_update_time": "20251015", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.12608", "html_url": "https://arxiv.org/abs/2510.12608", "title": "StyleDecipher：使用风格分析进行LLM生成文本的稳健且可解释检测", "title_en": "StyleDecipher: Robust and Explainable Detection of LLM-Generated Texts with Stylistic Analysis", "authors": "Siyuan Li,Aodu Wulianghai,Xi Lin,Guangyan Li,Xiang Chen,Jun Wu,Jianhua Li", "background": "随着大规模语言模型（LLMs）在开放领域写作中的集成增加，检测机器生成的文本已成为确保内容真实性与信任的关键任务。现有的方法依赖于统计差异或模型特定的启发式方法来区分LLM生成的文本与人类撰写的文本。然而，在真实场景中，这些方法因泛化能力有限、易受重述影响、缺乏可解释性等问题，特别是在面对多样化的风格或混合人类-人工智能作者创作内容时，表现不佳。", "innovation": "本文提出了StyleDecipher，一种基于结合特征提取器来量化风格差异的稳健且可解释的检测框架，用于重新审视LLM生成文本的检测。通过联合建模离散风格指标和从语义嵌入中得出的连续风格表示，StyleDecipher能够在统一表示空间内捕捉人类和LLM输出之间的独特风格差异。该框架可以在无需访问模型内部或有标签片段的情况下，实现准确、可解释且领域无关的检测。", "conclusion": "在包含新闻、代码、论文、评论和学术摘要在内的五个不同领域中进行了广泛的实验，表明StyleDecipher可以持续达到领域的最佳准确性。此外，在跨域评估中，它在一些场景中超越了现有基线36.30%，并且能够抵抗对抗性扰动和混合人类-人工智能内容。进一步的定性和定量分析证实了风格信号为区分机器生成文本提供了可解释的证据。我们的源代码可以在这里访问：this https URL。"}
{"llm_update_time": "20251015", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.12624", "html_url": "https://arxiv.org/abs/2510.12624", "title": "Learning-To-Measure: In-context Active Feature Acquisition", "title_en": "Learning-To-Measure: In-context Active Feature Acquisition", "authors": "Yuta Kobayashi,Zilin Jing,Jiayu Yao,Hongseok Namkoong,Shalmali Joshi", "background": "AFA是一个顺序决策问题，目标是在提高模型性能的同时，通过自适应选择要获取的特征。实际应用中，AFA方法通常从具有系统性特征缺失和有限任务特定标签的回顾性数据中学习。先前工作主要专注于单一预定义任务的特征获取，这限制了其扩展性。因此，需要解决如何通过学习跨不同任务的获取策略的问题，即元AFA问题，以便在更广泛的任务场景下应用AFA方法。", "innovation": "本文提出了Learning-to-Measure (L2M)，它包括i) 可靠的未见任务不确定性量化，和ii) 使用不确定性指导的贪婪特征获取代理，该代理最大化条件互信息。L2M采用序列建模或自回归预训练方法来实现可靠不确定性量化，适用于任意缺失数据的任务。L2M直接在具有回顾性缺失的数据集上进行操作，并在上下文中执行元AFA任务，无需每项任务重新训练。实验结果表明，L2M在合成和真实世界的数据表基准测试中表现出了与任务特定基线相当或更优的效果，特别是在标签稀缺和特征高度缺失的情况下。", "conclusion": "本文提出的L2M方法通过可靠不确定性量化和不确定性导向的贪婪特征获取策略，解决了AFA在实际应用中遇到的挑战。L2M能够在具有回顾性缺失的数据集上直接执行元AFA任务，并在各种下游任务中展现出优越的表现，尤其是在高缺失率和少量标签的情况下。"}
{"llm_update_time": "20251015", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.12615", "html_url": "https://arxiv.org/abs/2510.12615", "title": "重新思考知识蒸馏：一种基于数据的相关性约束，具有负不对称的收益", "title_en": "Rethinking Knowledge Distillation: A Data Dependent Regulariser With a Negative Asymmetric Payoff", "authors": "Israel Mason-Williams,Gabryel Mason-Williams,Helen Yannakoudakis", "background": "知识蒸馏通常被认为是一种压缩机制，根据学生模型的准确性和损失来判断，但其功能影响尚不明确。这项研究量化了知识蒸馏的压缩能力以及功能层面的知识迁移，从而解耦压缩与架构的减少，提供了对知识蒸馏的改进理解。研究者通过假设检验、控制变量和随机控制蒸馏来理解不同数据模态下的知识迁移机制。为了严格测试分析的广度和极限，研究探索了多种蒸馏变体，并分析了模型大小下的蒸馏缩放定律。实验发现，在某些模态和架构中，虽然存在统计学上的知识迁移，但这种迁移的程度不如预期那样显著，尤其是在设计用来最大化知识共享的条件下。此外，在知识迁移显著的情况下，发现存在始终如一且严重的负向知识以不对称的方式迁移到学生模型，这对知识蒸馏应用的安全性提出了担忧。在12个实验设置、9个架构和7个数据集上，研究结果表明知识蒸馏更多地作为数据依赖性的正则化约束起作用，且具有负的不对称收益.", "innovation": "本文通过假设检验、控制变量和随机控制蒸馏等方法，从功能层面量化了知识蒸馏的压缩能力和知识迁移，而不是单纯依赖于准确性或损失。研究发现知识蒸馏不仅仅是压缩机制，更多地表现为数据依赖性的正则化约束，具有负的不对称收益，揭示了知识蒸馏的潜在安全问题，特别是负向知识的不对称迁移对学生模型的影响。", "conclusion": "知识蒸馏更多地作为一种依赖于数据的正则化机制，而不是一种压缩机制，且存在负向知识的不对称转移，这在某些情况下可能带来安全风险。研究表明，知识蒸馏的效果在不同的模态、架构和数据集上存在显著差异，应谨慎评估其实际应用的效果。"}
{"llm_update_time": "20251015", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.12630", "html_url": "https://arxiv.org/abs/2510.12630", "title": "设计具有控制信心的工具", "title_en": "Designing Tools with Control Confidence", "authors": "Ajith Anil Meera,Abian Torres,Pablo Lanillos", "background": "古人类在发明石器时，并不只是为了最大化工具完成特定任务的准确性，还着重于提高工具在未来类似环境中的使用信心。这一做法提高了工具的稳健性，即在环境不确定性下表现出最小的性能偏差。然而，当前的自主工具设计框架仅关注性能优化，而忽略工具使用者对未来重复使用的信心水平。这篇文章中，通过定义一个针对特定任务的自主手工具设计优化框架，并引入神经启发式控制信心项以提升工具使用时的稳健性，填补了这一空白。通过使用机械臂进行严格模拟，证明了以控制信心为目标函数设计的工具在面对环境不确定性时比单纯以准确性为目标函数的工具更加稳健。此外，将控制信心纳入工具设计的目标函数中，平衡了在控制干扰下工具设计的稳健性和目标准确性。最后，通过基于CMAES的进化优化策略进行自主工具设计，其性能优于其他最先进的优化器，能够在最少迭代次数内设计出最优工具。相关代码见：this https URL", "innovation": "定义了一个针对特定任务的自主手工具设计优化框架，并引入了神经启发式的控制信心项，以提升工具设计的稳健性。这填补了传统自主工具设计框架忽略使用者信心的空白，提出了一个新的平衡工具稳健性和目标准确性的策略。通过CMAES的进化优化策略实现工具的最优设计，超越了其他最先进的优化器。", "conclusion": "通过在机械臂上的严格模拟，展示了以控制信心为目标函数设计的工具在面对环境不确定性时比单纯以准确性为目标函数的工具更加稳健。提出的基于CMAES的优化策略能够平衡工具设计的稳健性和目标准确性，并在最少的迭代次数内设计出最优工具，提升了工具设计的效率和实际应用中的可靠性。"}
{"llm_update_time": "20251015", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.12642", "html_url": "https://arxiv.org/abs/2510.12642", "title": "Aixel: 一种统一、自适应和可扩展的基于AI的数据分析系统", "title_en": "Aixel: A Unified, Adaptive and Extensible System for AI-powered Data Analysis", "authors": "Meihui Zhang,Liming Wang,Chi Zhang,Zhaojing Luo", "background": "现代数据分析的趋势是将数据管理与学习结合起来，受到准确度、延迟和成本要求的指导。实际应用中，数据来自多种格式和多种来源，同时目标和预算会随时间变化。现有系统跨越数据库、分析库和调优服务来处理这些应用，这种碎片化导致了复杂用户交互、适应性有限、性能欠佳和组件间扩展性差的问题。", "innovation": "我们提出了一种统一、自适应和可扩展的系统Aixel，用于基于AI的数据分析。该系统涵盖了应用、任务、模型和数据四个层次。任务层提供了一个声明式的接口来捕捉用户的意图，并将其解析为可执行的操作计划。优化器编译并调度此计划以满足指定的目标。任务层协调数据和模型操作的执行，内置支持复用和缓存以提高效率。模型层提供了版本化存储，支持自适应构建、任务对齐漂移检测和安全更新。数据层提供了统一的数据管理能力，包括索引、约束感知发现、任务对齐选择和综合特征管理。", "conclusion": "通过上述设计的多层结构，Aixel提供了一个用户友好的、自适应的、高效的和可扩展的系统。"}
{"llm_update_time": "20251015", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.12451", "html_url": "https://arxiv.org/abs/2510.12451", "title": "平权视角下的平滑与尖锐极小值", "title_en": "A Function Centric Perspective On Flat and Sharp Minima", "authors": "Israel Mason-Williams,Gabryel Mason-Williams,Helen Yannakoudakis", "background": "平滑极小值被认为与深度神经网络的泛化能力有密切联系。然而，最近的研究揭示了这种关联较为复杂，理论上的反例和实验中的异常案例也在不断增加。这项研究回顾了模型性能中尖锐度的角色，重新定义尖锐度为一种与函数相关的特性，而非不良泛化的可靠指标。研究还展示了当模型经过正则化处理（例如，通过SAM、权重衰减或数据增强）时，通常会达到更尖锐的极小值，这些尖锐的极小值同时与更好的泛化能力、校准性、鲁棒性和功能一致性相关。研究表明，未经正则化的基线模型会收敛到更平坦的极小值，但常常在所有安全指标上表现更差。研究证明，函数复杂性而非平坦度决定了解决方案的几何形状，尖锐的极小值在正则化条件下能反映更合适的归纳偏差，需从函数中心的角度重新审视损失景观的几何结构。", "innovation": "提出了尖锐度应被视为一个与函数相关的特性，而非不良泛化的可靠指标；展示了当模型经过正则化处理，通常会达到更尖锐的极小值，且这些尖锐的极小值往往与更好的性能指标相关联；通过广泛的实验研究表明，未经正则化的基线模型会收敛到更平坦的极小值，但常在安全指标上表现更差；强调函数复杂性而非平坦度决定了解决方案的几何形状，尖锐的极小值在正则化条件下更可能是合适的归纳偏差。", "conclusion": "研究表明，尖锐度与函数复杂性的关系决定了极小值的几何形状，尖锐的极小值在正则化条件下往往更反映合适的归纳偏差，提出了从函数中心角度重新审视损失景观的几何结构的新视角。"}
{"llm_update_time": "20251015", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.12633", "html_url": "https://arxiv.org/abs/2510.12633", "title": "Laminar: 一个可扩展的异步 RL 后训练框架", "title_en": "Laminar: A Scalable Asynchronous RL Post-Training Framework", "authors": "Guangming Sheng,Yuxuan Tong,Borui Wan,Wang Zhang,Chaobo Jia,Xibin Wu,Yuqi Wu,Xiang Li,Chi Zhang,Yanghua Peng,Haibin Lin,Xin Liu,Chuan Wu", "background": "大型语言模型（LLMs）的强化学习（RL）后训练正在扩展到大规模集群并运行更长的时间，以增强模型的推理性能。然而，现有的 RL 框架的扩展性有限，由于 RL 策略生成的极端长尾分布导致严重的 GPU 利用率低下。当前的异步 RL 系统尝试缓解这一问题，但他们依赖于行为者和所有 rollouts 之间的全局权重同步，这会导致刚性模型更新时间表。这种全局同步不适合 RL 训练中高度偏斜且不断演化的轨迹生成延迟分布，从而削弱了训练效率。", "innovation": "我们的关键洞察是，高效的扩展需要通过轨迹级别的异步性来打破这一锁定的节奏，独立生成和消费每个轨迹。我们提出了一种名为 Laminar 的可扩展且稳健的 RL 后训练系统，该系统建立在完全解耦架构上。首先，我们用一层中继工作者取代全局更新，作为分布式的参数服务。这使异步和细粒度的权重同步成为可能，允许 rollouts 在任何时间拉取最新的权重，而不拖延行为者的训练循环。其次，动态打包机制将长尾轨迹集中在少数专用 rollouts 上，实现最大化的生成吞吐量。完全解耦的设计还能隔离故障，确保长时间运行任务的稳健性。", "conclusion": "我们在一个 1024-GPU 的集群上的评估表明，Laminar 在 state-of-the-art 系统上实现了高达 5.48 倍的训练吞吐量加速，同时减少了模型收敛时间。"}
{"llm_update_time": "20251015", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.12659", "html_url": "https://arxiv.org/abs/2510.12659", "title": "SG-XDEAT: 根据稀疏性指导的跨维度和跨编码注意以及目标感知调整在表格学习中的应用", "title_en": "SG-XDEAT: Sparsity-Guided Cross-Dimensional and Cross-Encoding Attention with Target-Aware Conditioning in Tabular Learning", "authors": "Chih-Chuan Cheng,Yi-Ju Tseng", "background": "该论文针对监督学习中的表格数据提出了一个新的框架SG-XDEAT（Sparsity-Guided Cross Dimensional and Cross-Encoding Attention with Target Aware Conditioning）。背景在于现有方法在处理表格数据时可能存在噪声和不同表观特征间依赖性捕捉不足的问题，导致模型性能不稳。SG-XDEAT通过引入一个多流编码器和特定的注意力机制来改进这一点，以更好地学习数据间的依赖性和消除不相关或噪声特征的影响。", "innovation": "SG-XDEAT的创新之处在于它采用了双重流编码器，将每个输入特征分解为原始值流和目标条件流，并通过多级注意力模块进行传播。同时，它融合了三种关键组件：跨维度自注意力，能够捕捉每个流内特征视图间的内相关性；跨编码自注意力，允许原始数据流与目标感知流之间进行双向交互；以及自适应稀疏自注意力机制(Adaptive Sparse Self-Attention)，动态抑制具有低有用性的标记，从而减少噪声的影响。这些机制共同提高了模型对表格数据的鲁棒性和准确性。", "conclusion": "实验证明，SG-XDEAT在多个公开基准数据集上一致优于现有基线方法，证实了同时建模原始和目标感知视图并动态过滤噪声能够产生更鲁棒的深层表格学习器。"}
{"llm_update_time": "20251015", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.12691", "html_url": "https://arxiv.org/abs/2510.12691", "title": "DiffEM: 使用期望最大化从污染数据中学习扩散模型", "title_en": "DiffEM: Learning from Corrupted Data with Diffusion Models via Expectation Maximization", "authors": "Danial Hosseintabar,Fan Chen,Giannis Daras,Antonio Torralba,Constantinos Daskalakis", "background": "扩散模型已成为高维反问题的强大生成先验方法。但是，当仅从受污染或噪声观测中学习这些模型时仍然具有挑战性。", "innovation": "提出了一个新的方法，即使用期望最大化（EM）从受噪声数据中训练扩散模型。该方法名为DiffEM，在E步使用条件扩散模型从观测数据中重建清晰数据，然后在M步使用重建数据来细化条件扩散模型。理论分析表明，在适当的统计条件下，DiffEM迭代表现出单调收敛。", "conclusion": "通过在各种图像重建任务中的实验展示了这种方法的有效性。"}
{"llm_update_time": "20251015", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.12643", "html_url": "https://arxiv.org/abs/2510.12643", "title": "推理模式很重要：学习推理无需人工论据", "title_en": "Reasoning Pattern Matters: Learning to Reason without Human Rationales", "authors": "Chaoxu Pang,Yixuan Cao,Ping Luo", "background": "大规模语言模型（LLMs）在广泛采用的SFT+RLVR框架下展示了显著的推理能力。该框架首先通过监督微调（SFT）在人类标注的推理路径（论据）上建立初始推理行为，然后使用可验证奖励的强化学习（RLVR）来优化模型，而无需使用黄金论据。然而，为SFT阶段标注高质量的论据仍然是非常昂贵的。因此，论文探讨了如何在不损害推理性能的前提下大大减少论据标注的成本。研究表明，对于一组特定的任务——称为模式化推理任务，推理遵循固定且一致执行的程序性策略。尽管实例在内容上可能有所不同，例如领域知识、事实信息或数值，但解决方案来自于应用共享的推理模式。这项研究认为，SFT+RLVR在这些任务上的成功主要是由于它使模型能够内化这些推理模式。使用数值语义匹配作为代表任务，提供了因果和行为证据，证明了推理模式而非论据的数量或质量是决定性能的关键因素。", "innovation": "提出了Pattern-Aware LLMs as Rationale AnnOtators (PARO)框架，该框架使大规模语言模型能够生成与特定任务相关的推理模式一致的论据，而无需人工标注论据。实验表明，PARO生成的论据在SFT+RLVR性能上与人工标注的比其大10倍的论据相当。这些结果表明，大规模的人工论据标注可以被基于语言模型的自动标注所取代，只要有限的人类监督来管理推理模式即可。", "conclusion": "大规模语言模型在SFT+RLVR框架下的能力主要依赖于内化固定的推理模式。提出了PARO框架，能有效生成无需人工标注的推理模式一致的论据。实验结果表明，只需要有限的人工监督，模型可以实现与大量人工标注论据相当的性能，未来有可能大幅减少人工标注的成本。"}
{"llm_update_time": "20251015", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.12689", "html_url": "https://arxiv.org/abs/2510.12689", "title": "从代理人到受托人：优化长期利益如何塑造LLM中的偏差和对齐", "title_en": "From Delegates to Trustees: How Optimizing for Long-Term Interests Shapes Bias and Alignment in LLM", "authors": "Suyash Fulay,Jocelyn Zhu,Michiel Bakker", "background": "大型语言模型（LLMs）在预测调查反应和政策偏好方面表现出色，促使人们对它们在各种领域代表人类利益的潜在能力产生了浓厚兴趣。大多数现有研究集中在行为克隆上，有效地评估模型再现个人表达偏好的程度。基于政治代理理论，本文突出了一个尚未充分探索的设计权衡：AI系统应当充当反映表达偏好的代理，还是行使如何最好地服务于个体利益的判断力的受托人。", "innovation": "本文通过一系列在美国政策问题投票中模拟的情景实验，应用一种基于时间价值框架来权衡短期与长期利益（模拟受托人角色），并将其与行为克隆模型（模拟代理人）的投票结果进行比较。结果显示，注重长期利益的预测能产生与专家共识更加一致的政策决定，但在一些缺乏明确共识的话题上，模型的默认立场也显示出更大的偏差。", "conclusion": "代理模型更好地维护了用户的自治权，但可能偏离得到广泛支持的政策立场，而受托模型能够在广受理解的问题上促进福利，但在主观话题上却存在由于父权主义和偏见风险导致的更大偏差。这些发现揭示了在设计AI系统来代表人类利益时的基本权衡。"}
{"llm_update_time": "20251015", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.12700", "html_url": "https://arxiv.org/abs/2510.12700", "title": "ReLU神经网络激活模式的拓扑特征", "title_en": "Topological Signatures of ReLU Neural Network Activation Patterns", "authors": "Vicente Bosca,Tatum Rask,Sunia Tanweer,Andrew R. Tawfeek,Branden Stone", "background": "本文探讨了ReLU神经网络激活模式的拓扑签名。研究对象为具有ReLU激活函数的前馈神经网络，分析了由网络诱导的特征空间的多面体分解。主要研究Fiedler分割的双图以及它与二分类问题决策边界的关联性。此外，通过计算回归任务中的细胞分解的同调学，观察训练损失和多面体细胞计数之间的相似模式，从而揭示模型训练过程中行为的内在联系。", "innovation": "本文的创新之处在于通过研究ReLU神经网络的多面体分解，探索了网络的拓扑特征与决策边界之间的关系，并通过计算同调学观察到训练损失和多面体细胞计数之间的关联，揭示了神经网络训练过程中的行为模式。这种分析方法为理解神经网络的内部机制提供了新的视角。", "conclusion": "本文的研究结果表明，通过分析ReLU神经网络的激活模式的拓扑特征，可以发现与决策边界高度相关的特定网络结构。同时，通过计算同调学，揭示了模型训练过程中损失函数和多面体细胞数之间的关联性，为模型优化和理解神经网络行为提供了重要依据。这些发现有助于进一步深入理解神经网络的工作原理。"}
{"llm_update_time": "20251015", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.12704", "html_url": "https://arxiv.org/abs/2510.12704", "title": "基于Transformer的胸部X光诊断混合解释引导学习", "title_en": "Hybrid Explanation-Guided Learning for Transformer-Based Chest X-Ray Diagnosis", "authors": "Shelley Zixin Shu,Haozhe Luo,Alexander Poellinger,Mauricio Reyes", "background": "基于Transformer的深度学习模型在医学影像中表现出色，通过注意力机制提高特征表示和可解释性。然而，这些模型容易学到虚假的相关性，导致偏见并限制泛化能力。虽然人类与AI注意力对齐可以缓解这些问题，但通常依赖于昂贵的手动监督。", "innovation": "提出了一种混合解释引导学习（H-EGL）框架，结合了自监督和人类指导的约束，以增强注意力对齐并提高泛化能力。自监督部分利用类区分注意力，不依赖于限制性先验，促进稳健性和灵活性。在使用视觉Transformer（ViT）进行胸部X光分类的实验中，H-EGL优于两种最先进的解释引导学习（EGL）方法，显示出更高的分类准确性和泛化能力，并生成与人类专业知识更一致的注意力图。", "conclusion": "H-EGL框架通过结合自监督和人类指导的约束，改善了Transformer模型在胸部X光诊断中的性能，提高了分类准确性和泛化能力。"}
{"llm_update_time": "20251015", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.12699", "html_url": "https://arxiv.org/abs/2510.12699", "title": "生成空间大小：理解与校准LLM生成的开放性", "title_en": "Generation Space Size: Understanding and Calibrating Open-Endedness of LLM Generations", "authors": "Sunny Yu,Ahmad Jabbar,Robert Hawkins,Dan Jurafsky,Myra Cheng", "background": "现有的大规模语言模型（LLM）在处理不同的生成任务时表现出不同的输出多样性问题。创造性任务中，它们倾向于产生过于同质化的输出；而在事实性任务中，则倾向于产生有歧义但不正确的响应。本文指出，这两种失败模式可以通过有效的生成空间大小（GSS）来统一和解决，即模型针对给定提示考虑的具有语义差异的输出集。作者通过构建GSSBench评估不同的指标，并探讨模型与理想行为之间的差异。", "innovation": "本文提出了一个名为GSSBench的任务套件，其中包含具有ground-truth GSS关系的提示对，用于评估不同指标并理解模型与期望行为之间的差异。实验发现，基于模型内部进行幻觉检测的指标，如EigenScore，比传统的多样性和不确定性量化指标更为有效。此外，该工作展示了GSS在三个方面的应用：检测提示的模糊性、预测澄清问题以实现更好的对接地、解释推理模型的过度思考和不足思考、引导模型扩大生成空间以产出高质量和多样化的输出。", "conclusion": "GSS框架有助于理解并校准LLM生成的开放性，通过基于模型内部的评估提供可解释的洞察，这在实际应用中具有重要意义。"}
{"llm_update_time": "20251015", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.12692", "html_url": "https://arxiv.org/abs/2510.12692", "title": "人在抉择婚配方面更胜一筹？在高风险创业竞赛中的人工智能与人工法官匹配对比", "title_en": "Who is a Better Matchmaker? Human vs. Algorithmic Judge Assignment in a High-Stakes Startup Competition", "authors": "Sarina Xi,Orelia Pi,Miaomiao Zhang,Becca Xiong,Jacqueline Ng Lane,Nihar B. Shah", "background": "人工智能在自动化和辅助复杂决策任务方面引起了广泛兴趣，但在需要语义理解和专业领域知识的情境下，算法与人类判断之间的比较仍然不明确。本研究通过哈佛校长创新挑战赛这一真实场景，探讨了这个课题，该竞赛是大学的顶级创业竞赛，颁发超过50万美元的奖金给学生和校友创业项目。高质量的法官指派至关重要。研究开发了一种AI基的法官指派算法，Hybrid Lexical-Semantic Similarity Ensemble (HLSE)，并在竞赛中部署和评价了其性能。研究使用盲法匹配质量分数由309对法官-创业项目中的裁判进行评估。研究表明，算法和人类专家在指派质量上没有统计学意义上的显著差异（AUC=0.48, p=0.40），平均得分分别为3.90和3.94，五分制中5表示匹配非常出色。此外，使用算法进行自动匹配相较于过去需要一周时间的人工匹配显著提高效率。这些结果表明，HLSE算法在匹配质量上达到了人类专家的水平，同时提供了更高的可扩展性和效率，突显了基于AI的解决方案在高风险环境下支持和提升人类决策的潜力。", "innovation": "本研究开发了一种名为Hybrid Lexical-Semantic Similarity Ensemble (HLSE)的AI基法官指派算法，并在实际高风险创业竞赛中进行了部署和评估，结果显示算法在匹配质量上达到了与人类专家相当的水平，同时赋予了更高的可扩展性和效率，为AI在决策支持中的应用提供了新的视角。", "conclusion": "研究采用HLSE算法在实际高风险创业竞赛中进行法官指派，结果表明算法在匹配质量上与人类专家没有统计学意义上的显著差异，同时具备更高的可扩展性和效率。这表明AI驱动的解决方案可以支持和提升人类决策的质量，在高风险环境中尤其适用。"}
{"llm_update_time": "20251015", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.12714", "html_url": "https://arxiv.org/abs/2510.12714", "title": "人工智能在放射性药物治疗中简化患者中心化剂量学中的应用", "title_en": "Artificial intelligence for simplified patient-centered dosimetry in radiopharmaceutical therapies", "authors": "Alejandro Lopez-Montes,Fereshteh Yousefirizi,Yizhou Chen,Yazdan Salimi,Robert Seifert,Ali Afshar-Oromieh,Carlos Uribe,Axel Rominger,Habib Zaidi,Arman Rahmim,Kuangyu Shi", "background": "放射性药物治疗（RPT）的快速发展突显了个性化和以患者为中心的剂量学的需求日益增加。当前的剂量学计算存在一些关键限制，需要新的解决方案。人工智能够为简化剂量计算提供解决途径，这对于推动更加患者友好的RPT具有重要意义。", "innovation": "该研究回顾并讨论了AI在简化剂量计算方面的主要进展，特别是如何通过AI解决当前剂量学计算中的关键问题，以支持更加个性化和患者友好的RPT。", "conclusion": "未来关于AI在RPT剂量学中的作用讨论表明，人工智能将在简化剂量测定和支持更加患者友好的RPT方面扮演重要角色。"}
{"llm_update_time": "20251015", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.12740", "html_url": "https://arxiv.org/abs/2510.12740", "title": "在语言模型中的关于核心议题的敏感性：嘿，请稍等一下", "title_en": "Hey, wait a minute: on at-issue sensitivity in Language Models", "authors": "Sanghee J. Kim,Kanishka Misra", "background": "评估语言模型（LMs）对话的自然度并不简单：不同的‘自然’概念差异显著，而可扩展的定量度量方法仍然有限。这一研究利用语言学上的‘核心议题’概念来评估对话的自然度，探讨了一种新方法：分段、生成、重新组合和比较（DGRC）方法。这种方法减轻了语言学分析中的偏见，并能系统地测试与语境敏感行为相关的动态特性。", "innovation": "研究提出了DGRC方法，这是一种利用语言学中的‘核心议题’概念来评估LMS对话自然度的创新方法，包括分段、生成、重新组合和比较步骤，从而系统地测试语境敏感行为，并减轻了语言分析中的偏见。", "conclusion": "研究发现，LMS倾向于继续对话的核心议题内容，这一倾向在指令微调模型中更为明显。然而，当相关提示（例如，“嘿，等一下”）出现时，它们会减少核心议题的偏好。尽管指令微调没有进一步放大这种调节效应，这一模式反映了成功的对话动态特征。"}
{"llm_update_time": "20251015", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.12727", "html_url": "https://arxiv.org/abs/2510.12727", "title": "农作物产量预测中的分级联邦学习在智能农业生产系统中的应用", "title_en": "Hierarchical Federated Learning for Crop Yield Prediction in Smart Agricultural Production Systems", "authors": "Anas Abouaomar,Mohammed El hanjri,Abdellatif Kobbane,Anis Laouiti,Khalid Nafil", "background": "本文提出了一种专为智能农业生产和作物产量预测设计的分级联邦学习架构。现有联邦学习技术在处理智能农业环境中的异构农业环境和隐私敏感数据时存在一定挑战，特别是在数据稀疏性和隐私保护方面。本文通过引入季节性订阅机制和多层次架构，旨在平衡局部专业性和全局普适性，同时减少通信开销和保护数据隐私。", "innovation": "本文提出的创新点在于提出了一种新型的分级联邦学习架构，通过在每个农业季节初使农场加入特定作物的集群，实现了局部作物类型的特定模型训练和全局模型聚合。这种架构能够结合多种作物的知识，提供局部的专业化训练和全局的普适性，同时确保了数据隐私和减少了通信开销。此外，通过实验验证了该系统在实际作物产量预测中的有效性。", "conclusion": "实验结果表明，提出的分级联邦学习系统在作物产量预测中具有显著优势，局部和作物层模型能够密切遵循实际产量模式，并且显著优于标准机器学习模型。这验证了在农业环境中采用分级联邦学习的优越性，特别是在涉及异构农业环境和隐私敏感农艺数据的场景下。"}
{"llm_update_time": "20251015", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.12733", "html_url": "https://arxiv.org/abs/2510.12733", "title": "HYPE: Hybrid Planning with Ego Proposal-Conditioned Predictions", "title_en": "HYPE: Hybrid Planning with Ego Proposal-Conditioned Predictions", "authors": "Hang Yu,Julian Jordan,Julian Schmidt,Silvan Lindner,Alessandro Canevaro,Wilhelm Stork", "background": "在复杂的城市环境中进行安全且可解释的运动规划，需要考虑到双向多智能体交互。因此，需要对潜在的自我机动操作的成本进行估计。许多现有的规划器使用采样方法生成初始轨迹，并通过优化学习预测未来环境状态来进一步完善这些轨迹。这一过程需要一个能够编码车辆期望行为的成本函数。设计这样一个成本函数如果需要考虑多种复杂的都市场景，是非常具有挑战性的。现有方法面临的主要挑战在于如何简化成本函数的设计，并确保规划的鲁棒性和安全性。本文重点讨论背景下的现有规划器和其面临的挑战.", "innovation": "本文提出了HYPE：一种将从学习提出的多模式轨迹提案作为启发式先验，整合进马尔可夫树搜索（MCTS）进一步优化的方法。为了模拟能够双向交互的场景，本文引入了一种基于自我条件的占用率预测模型，能够实现一致且场景感知的推理。这一设计简化了在细化阶段的成本函数设计，只需要使用简单的基于网格的成本项。该方法在大规模真实世界基准nuPlan和DeepUrban中的评估显示，HYPE在安全性和适应性方面达到了最先进的性能.", "conclusion": "HYPE 通过将提出的方法和预测模型相结合，成功解决了双向多智能体交互中成本函数设计的复杂性，并通过在真实世界基准中的评估证明了其在安全性和适应性方面的优越性能。"}
{"llm_update_time": "20251015", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.12702", "html_url": "https://arxiv.org/abs/2510.12702", "title": "超出后置条件：大型语言模型能否推断出适用于自动软件验证的形式合同？", "title_en": "Beyond Postconditions: Can Large Language Models infer Formal Contracts for Automatic Software Verification?", "authors": "Cedric Richter,Heike Wehrheim", "background": "自动软件验证器在检查软件与形式规范的一致性方面变得越来越有效，但在实践中并未被广泛采用，因为现实世界中的代码缺乏相应规范。大型语言模型（LLMs）有潜力从嵌入在代码中的自然语言提示（如函数名、注释或文档）中推断出形式后置条件，但生成的后置条件在后续验证中往往会导致验证器提出无效输入，这通常提示潜在问题其实是误报。为解决此问题，本文重新审视了从自然语言推断规范的问题，提出了NL2Contract任务，即使用LLMs将非正式的自然语言转化为形式功能合同，包括后置条件和前置条件。研究引出了验证并比较不同NL2Contract方法的指标，着重于推断出的功能合同的正确性、生成合同对错误行为的区分能力以及其在自动软件验证中的易用性。实验评估了不同LLMs在NL2Contract任务上的表现，并将其与后置条件生成任务（nl2postcond）进行了比较，结果表明LLMs在生成适用于所有输入的形式合同方面有效，所生成的合同足以区分错误行为和正确行为，配备LLMs推断出的功能合同的验证器比仅使用后置条件的验证器产生更少的虚假警报。进一步的研究显示，LLMs推断的前置条件通常与开发者的意图很好地对齐，从而使自动软件验证器能够捕捉到真正的软件漏洞。", "innovation": "引入了NL2Contract任务，旨在使用LLMs将非正式的自然语言转化为形式功能合同。开发了一套用于验证和比较不同NL2Contract方法的指标，并且通过实验评估了不同LLMs的有效性。研究发现，LLMs生成的功能合同在覆盖所有输入、区分错误行为与正确行为、为自动软件验证提供实际帮助方面表现出色，并能显著减少虚假警报数量。此外，LLMs生成的前置条件和开发者意图的对齐，增强了自动软件验证器的作用。", "conclusion": "大型语言模型可以在自动软件验证中有效生成形式合同，这些合同能够覆盖所有可能的输入、具有足够的区分能力，且能减少验证中的虚假警报。此外，LLMs生成的前置条件通常能更好地反映开发者意图，使得自动软件验证器能够有效地识别和解决实际软件中的漏洞。"}
{"llm_update_time": "20251015", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.12712", "html_url": "https://arxiv.org/abs/2510.12712", "title": "超越视觉：基于工具辅助图像感知、转换和推理的多模态LLM评估", "title_en": "Beyond Seeing: Evaluating Multimodal LLMs on Tool-Enabled Image Perception, Transformation, and Reasoning", "authors": "Xingang Guo,Utkarsh Tyagi,Advait Gosai,Paula Vergara,Ernesto Gabriel Hernández Montoya,Chen Bo Calvin Zhang,Bin Hu,Yunzhong He,Bing Liu,Rakshith Sharma Srinivasa", "background": "随着多模态大规模语言模型（MLLMs）在真实世界中的应用增多，用户提供的图片往往不够完美，需要通过剪裁、编辑或增强来发现关键的视觉线索。MLLMs不只局限于静态视觉感知，还需要在图像中进行动态的转换和其他工具的整合以解决复杂的任务。然而，将视觉从被动背景转变为可操作的认知空间的研究仍不足。现有的大多数基准测试仍然遵循思考图像的模式，将图像视为静态输入。为此，本文引入了IRIS，一种综合图像和系统的互动推理评估框架，评估MLLMs在不同视觉-文本任务中的感知、转换和推理能力。IRIS包含了1204个具有挑战性的开放性视觉任务（603单回合，601多回合），并覆盖五个不同的领域，利用详细的标准进行系统的评估。研究表明，当前的MLLMs在集成了视觉和通用工具的有效利用方面存在困难。最强的模型（GPT-5-think）的通过率仅达到18.68%。还观察到工具使用的不同行为，OpenAI模型从多样化的图像调整中受益，而Gemini-2.5-pro则没有改进。通过引入首个基于思考图像的基准测试，IRIS为多模态LLMs中的视觉智能研究提供了关键见解。", "innovation": "IRIS是一种新的评估框架，专门针对MLLMs在具备工具支持的图像感知、转换及推理中的能力进行评估。它首次采用综合图像和系统的互动推理方法，包含1204个具有挑战性的开放性视觉任务，并覆盖五个不同的领域，提供更细致的评价标准。研究结果表明了MLLMs在这种新模型下存在的挑战，并提供了解决这些问题的潜在方向。IRIS填补了现有基准测试在考虑实际应用场景中动态图像处理这一方面的空白，为未来相关研究提供了重要参考。", "conclusion": "当前的MLLMs在将视觉与通用工具有效集成的任务中还存在显著不足。通过引入首个中心于思考图像的IRIS基准，IRIS提供了对于推进多模态LLM中的视觉智能的关键见解，为未来的研究开辟了新的路径。未来的工作可能需要进一步优化模型，使其更好地理解和利用动态图像数据。"}
{"llm_update_time": "20251015", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.12750", "html_url": "https://arxiv.org/abs/2510.12750", "title": "VQArt-Bench：用于艺术与文化遗产的语义丰富VQA基准", "title_en": "VQArt-Bench: A semantically rich VQA Benchmark for Art and Cultural Heritage", "authors": "A. Alfarano,L. Venturoli,D. Negueruela del Castillo(University of Zurich, Max Planck Society)", "background": "现有的视觉问答（VQA）基准通常未能评估模型在复杂领域的深度语义理解，特别是视觉艺术分析。这些问题往往局限于简单的句法结构和表面属性，不能捕捉人类视觉探索的多样性和深度，促使模型采取统计捷径而非视觉推理。", "innovation": "研究人员引入了VQArt-Bench，这是一个新的大型VQA基准，专门针对文化遗产领域。该基准利用多智能体管道，让专门的智能体协作生成复杂、验证性和语义多样的问题。它按照与视觉理解相关的维度结构化，以测试模型解读象征意义、叙事和复杂视觉关系的能力。评估结果显示了当前模型在简单计数任务上的显著局限性，以及专有模型与开源模型之间的性能差距。", "conclusion": "该研究揭示了现有VQA模型在文化遗产领域中的能力局限性，并验证了VQArt-Bench的有效性和重要性，为未来研究提供了一个评估模型深度语义理解的新基准。"}
{"llm_update_time": "20251015", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.12768", "html_url": "https://arxiv.org/abs/2510.12768", "title": "动态高斯点云在单目4D重建中的不确定性重要性", "title_en": "Uncertainty Matters in Dynamic Gaussian Splatting for Monocular 4D Reconstruction", "authors": "Fengzhi Guo,Chih-Chuan Hsu,Sihao Ding,Cheng Zhang", "background": "单目输入下从动态3D场景重建本质上存在约束不足的问题，由于遮挡和极度新颖视图会导致模糊性。虽然动态高斯点云提供了一种有效的表示方法，但传统的模型会对所有高斯原语进行均匀优化，而不考虑它们是良好观察还是不良观察。这种限制导致了在遮挡下运动漂移，并在预测未见视角时产生合成质量下降。", "innovation": "提出了USplat4D，一种新型的不确定性感知动态高斯点云框架，通过传播可靠的运动提示来增强4D重建。该创新在于估计每个高斯随时间和空间的发生不确定性，并利用它构建时空图以实现不确定性感知优化。", "conclusion": "实验表明，明确建模不确定性可以一致地改进动态高斯点云模型，在遮挡下提供更稳定的几何形状，并在极端视角下产生高质量的合成结果。"}
{"llm_update_time": "20251015", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.12773", "html_url": "https://arxiv.org/abs/2510.12773", "title": "Dr.LLM: 动态层路由在大语言模型中的应用", "title_en": "Dr.LLM: Dynamic Layer Routing in LLMs", "authors": "Ahmed Heakl,Martin Gubri,Salman Khan,Sangdoo Yun,Seong Joon Oh", "background": "大语言模型（LLMs）在处理每个标记时会通过所有层的变换堆栈，这导致在处理简单查询时存在计算浪费，而在处理需要深层推理的复杂任务时又显得不够灵活。现有的自适应深度方法可以提高效率，但这些方法往往依赖于昂贵的推理时间搜索、架构改变或大规模重训练，并且通常在实践中会牺牲准确度。", "innovation": "本文介绍了一种称为Dr.LLM的可安装框架，该框架为预训练模型配备了轻量级的基于每层的路由器，这些路由器能够决定跳过、执行或重复一个块。路由器是在显式的监督下进行训练的：借助蒙特卡洛树搜索（MCTS）方法推导高质量的层配置，以在预算内保持或提高准确度。设计上包括分窗池化以确保路由的稳定性、 focal loss 与类别平衡，及瓶颈MLP路由器以应对类别不平衡和长度序列问题。在ARC（逻辑）和DART（数学）任务上，此框架能够提高准确度多达3.4%，同时每个示例节省5个层。路由器还能在领域外任务上迁移，仅导致模型准确度下降0.85%。", "conclusion": "总体而言，该研究证明了显式监督的路由器可以将冻结的大语言模型重新配置为适应预算和提升准确度的推理，而无需修改基础权重。"}
{"llm_update_time": "20251015", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.12795", "html_url": "https://arxiv.org/abs/2510.12795", "title": "CuMPerLay: 学习立方体多参数持续性向量化", "title_en": "CuMPerLay: Learning Cubical Multiparameter Persistence Vectorizations", "authors": "Caner Korkmaz,Brighton Nuwagira,Barış Coşkunuzer,Tolga Birdal", "background": "在图像拓扑工作中，Cubical Multiparameter Persistence (CMP) 提供了一种自然且强大的方法，但其使用受到多重滤波结构复杂性及CMP向量化的影响。现有的CMP向量化算法缺乏足够的灵活性和学习能力，影响了其在深度学习框架中的集成。", "innovation": "本文提出了一种新颖的可微向量化层CuMPerLay，它通过将CMP分解为可学习的单参数持续性组合来解决上述问题。通过CuMPerLay，CMP可以在Swin Transformer等先进架构中无缝使用，并且其向量表示在广义Wasserstein度量下的稳定性得到了理论保证。实验表明，在有限数据场景下，CuMPerLay在分类和分割性能上有所提升。", "conclusion": "CuMPerLay 提供了一个有前景的研究方向，旨在整合全局结构信息到深度网络中以进行结构化图像分析。"}
{"llm_update_time": "20251015", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.12796", "html_url": "https://arxiv.org/abs/2510.12796", "title": "DriveVLA-W0: 世界模型放大自主驾驶中的数据扩展定律", "title_en": "DriveVLA-W0: World Models Amplify Data Scaling Law in Autonomous Driving", "authors": "Yingyan Li,Shuyao Shang,Weisong Liu,Bing Zhan,Haochen Wang,Yuqi Wang,Yuntao Chen,Xiaoman Wang,Yasong An,Chufeng Tang,Lu Hou,Lue Fan,Zhaoxiang Zhang", "background": "在大规模数据集上扩展视觉-语言-动作(VLA)模型为实现更通用的驾驶智能提供了希望。然而，VLA模型受到“监督赤字”的限制：巨大的模型能力仅由稀疏、低维度的动作进行监督，使得其大部分表示能力未被充分利用。", "innovation": "提出了DriveVLA-W0训练范式，利用世界建模预测未来图像，生成密集的自我监督信号，促使模型学习驾驶环境的基本动态。该范式可以实例化应用于两种主要的VLA架构：一种自回归世界模型，适用于使用离散视觉标记的VLA；另一种扩散世界模型，适用于操作连续视觉特征的VLA。基于从世界建模中学习到的丰富表示，引入了轻量级的动作专家以解决实时部署的推理延迟问题。实验结果表明，DriveVLA-W0显著优于BEV和VLA基线，并且随着训练数据集规模的增加，性能提升加速。", "conclusion": "在交通仿真基准NAVSIM v1/v2和一个扩大680倍的内部数据集上的大量实验表明，DriveVLA-W0显著优于BEV和VLA基线，且随着训练数据集规模的扩大，性能提升呈加速趋势。"}
{"llm_update_time": "20251015", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2408.12910", "html_url": "https://arxiv.org/abs/2408.12910", "title": "驯服文本到图像合成技术：通过多轮指导实现用户中心化提示生成", "title_en": "Taming Text-to-Image Synthesis for Novices: User-centric Prompt Generation via Multi-turn Guidance", "authors": "Yilun Liu,Minggui He,Feiyu Yao,Yuhe Ji,Shimin Tao,Jingzhou Du,Duan Li,Jian Gao,Li Zhang,Hao Yang,Boxing Chen,Osamu Yoshie", "background": "文本到图像合成（TIS）模型的出现显著影响了数字图像创作，但这些模型对文本提示敏感，给新手用户带来挑战。现有的解决方案通过自动提示扩展或从用户查询生成提示来缓解这一问题，但这种方式在结果解释性和用户互动性方面缺乏用户中心性。", "innovation": "提出了一种基于对话的TIS提示生成模型——DialPrompt，强调新手用户的体验。DialPrompt设计为多轮工作流程，每轮对话中模型引导用户表达对可能优化维度的偏好，然后再生成最终的TIS提示。通过从高级用户中挖掘15个关键提示维度并构建多轮数据集进行训练，DialPrompt提升了用户中心性，使用户能够感知和控制TIS提示的创作过程。", "conclusion": "实验表明，与现有方法相比，DialPrompt在用户中心性得分上显著提高，同时保持了合成图像的质量。用户评估显示，DialPrompt在19名（尤其是新手）人类评审员中赢得高度评价。"}
{"llm_update_time": "20251015", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2412.02869", "html_url": "https://arxiv.org/abs/2412.02869", "title": "因果效应的约束可识别性", "title_en": "Constrained Identifiability of Causal Effects", "authors": "Yizuo Chen,Adnan Darwiche", "background": "该研究探讨了在因果图之外，还存在不同类型的约束（如逻辑约束）的情况下识别因果效应的方法。这些约束会限制由因果图诱导的模型参数化，从而减少识别性问题考虑的模型集合。", "innovation": "作者提出了约束可识别性的概念，并通过可操作的算术电路（ACs）框架实现了对约束可识别性的测试。该方法不仅考虑了严格正性的约束，还可以系统化地容纳各种类型的约束。研究证明，基于算术电路的方法至少与现有的古典识别性测试算法一样完整。", "conclusion": "通过举例说明，该研究展示了基于算术电路的方法的有效性，即在不同类型的约束下，不可识别的因果效应可能会变得可识别。"}
{"llm_update_time": "20251015", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.12789", "html_url": "https://arxiv.org/abs/2510.12789", "title": "UniFusion: 视觉语言模型作为统一编码器在图像生成中的应用", "title_en": "UniFusion: Vision-Language Model as Unified Encoder in Image Generation", "authors": "Kevin Li,Manuel Brack,Sudeep Katakol,Hareesh Ravi,Ajinkya Kale", "background": "尽管近期视觉生成技术取得了显著进展，现有的架构仍主要依赖独立的图像和文本编码器，这种分离限制了扩散模型进行跨模态推理和知识转移的能力。此前的尝试虽然在某种程度上尝试了桥梁之间的对接，但是通常使用视觉语言模型的最后一层信息，或者使用多个视觉编码器，甚至训练大规模的统一模型。然而，这些方法要求大量的计算资源和大规模数据，限制了应用的范围。", "innovation": "本文提出了UniFusion，一种基于扩散的生成模型，并且该模型以一个冻结的大型视觉-语言模型（VLM）作为统一的多模态编码器。核心创新在于层级注意力池化（LAP）机制，该机制从冻结VLM的文本和视觉标记中提取高层次语义和低层次细节，以条件化扩散生成模型。此外，提出了一种新的VLM-赋能重写注入以及灵活推理（VERIFI）的方法，该方法可以通过VLM生成的文本标记来指导扩散转换器（DiT）的内部提示重构。这不仅提高了生成的文本-图像对齐能力，增强了跨模态知识迁移，还展示了在单张图像编辑训练后，零样本外推到多元化图像参考的能力，进一步强调了UniFusion统一编码器设计的优势。", "conclusion": "我们的研究表明，与其它浅层融合架构相比，LAP在生成和视觉信息的忠实地转移方面表现出更好的性能。通过在单张图片编辑任务上的 fine-tuning，不仅可以提高生成中文本-图像对齐，反映跨模态知识迁移，还可以展示卓越的泛化能力。我们的模型不仅在单张图片编辑任务上进行了训练，还能零样本外推到多种图像参考上，进一步证实了UniFusion统一编码器设计的有效性。"}
{"llm_update_time": "20251015", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2408.06849", "html_url": "https://arxiv.org/abs/2408.06849", "title": "基于大型语言模型的因果代理", "title_en": "Causal Agent based on Large Language Model", "authors": "Kairong Han,Kun Kuang,Ziyu Zhao,Junjian Ye,Fei Wu", "background": "大型语言模型在各个领域取得了显著成功，但在处理因果问题和因果理论时，由于其复杂性，自然语言难以准确描述，导致大型语言模型在理解与应用因果理论方面存在困难。因果推断方法难以通过自然语言有效传递，造成因果代理在准确应用这些方法时受限。此外，因果数据集通常是表格形式，而大型语言模型在处理自然语言数据方面表现出色，因此二者在结构上存在不匹配，降低了对表格数据的有效推理能力。", "innovation": "本文提出了一种因果代理，将其嵌入到代理框架中，以解决上述挑战。因果代理包含工具、记忆和推理模块。工具模块调用Python代码，利用封装的因果功能模块将表格数据与自然语言对齐。推理模块通过多次迭代使用工具进行推理。记忆模块中存储了一个字典实例，其中键为唯一名称，值为因果图。通过建立包含变量级、边级、因果图级和因果效应级问题的Causal Tabular Question Answer（CausalTQA）基准测试集，验证了因果代理的有效性，在四个级别的问题上准确率均超过80%。在真实世界数据集QRData上进行验证后，因果代理比当前SOTA高出6%。", "conclusion": "因果代理展示了对四个层次因果问题的显著效果，与之前的SOTA相比在真实世界数据集上有所改进。通过GitHub仓库提供的代码，人们可以获得更多的实现细节和进一步深入了解。"}
{"llm_update_time": "20251015", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2502.10742", "html_url": "https://arxiv.org/abs/2502.10742", "title": "类似儿童成长的AI哲学基础", "title_en": "The Philosophical Foundations of Growing AI Like A Child", "authors": "Dezhi Luo,Yijiang Li,Hokin Deng", "background": "当前的语言模型尽管在高级推理方面表现出色，在现实世界场景中的鲁棒性不足，并且在人类直观解决的基本问题上表现不佳。", "innovation": "文章认为这些问题的根本原因在于人机认知发展之间的核心差异，提出将核心知识系统地集成到未来多模态语言模型中的工作方法，通过大规模生成使用认知原型策略的合成训练数据。", "conclusion": "文章主张这不是一个固有的架构限制，提出了一个可行的建议框架，为未来的多模态语言模型系统地整合核心知识。"}
{"llm_update_time": "20251015", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2411.14214", "html_url": "https://arxiv.org/abs/2411.14214", "title": "基于物理信息的自主生成型LLM代理在可解释的电力电子调制设计中的应用", "title_en": "Physics-Informed Autonomous LLM Agents for Explainable Power Electronics Modulation Design", "authors": "Junhua Liu,Fanfan Lin,Xinze Li,Kwan Hui Lim,Shuai Zhao", "background": "近年来，基于大规模语言模型（LLM）的自主代理在解决复杂的工业设计任务方面展现了强大的能力。然而，在旨在实现碳中性和高性能可再生能源系统的领域，现有的AI辅助设计自动化方法在可解释性、可扩展性和实际易用性方面面临重大挑战。为了解决这些限制，我们提出了一种称为PHIA（物理信息自主代理）的系统，它是通过大规模语言模型驱动的自动化电力电子系统中的功率转换器调制设计系统，最大限度地减少人工干预。", "innovation": "PHIA通过引入一个基于LLM的规划模块，该模块通过用户友好的聊天界面交互式地获取和验证设计要求。这种规划者与物理信息驱动的仿真和优化组件协作，自主生成和迭代优化调制设计。交互式界面在整个设计过程中通过文本解释和视觉输出提供解释性支持。实验结果显示，与第二最好的基准相比，PHIA将标准平均绝对误差降低了63.2%，并使整体设计过程加速了33倍以上。进一步的用户研究还证实，PHIA具有更高效的设计效率和更好的可用性，突显了其在电力电子工业设计流程中的潜在变革作用。", "conclusion": "PHIA减少了标准平均绝对误差63.2%，并加速了整体设计过程33倍以上。用户研究进一步证明了其优越的设计效率和可用性，其潜在能力在于转型电力电子工业设计工作流程。"}
{"llm_update_time": "20251015", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2505.10844", "html_url": "https://arxiv.org/abs/2505.10844", "title": "创造力还是蛮力？通过脑筋急转弯考察大型语言模型的问题解决能力", "title_en": "Creativity or Brute Force? Using Brainteasers as a Window into the Problem-Solving Abilities of Large Language Models", "authors": "Simeng Han,Howard Dai,Stephen Xia,Grant Zhang,Chen Liu,Lichang Chen,Hoang Huy Nguyen,Hongyuan Mei,Jiayuan Mao,R. Thomas McCoy", "background": "准确性仍然是评估AI系统的一个标准指标，但它提供的洞察有限，无法深入理解模型如何得出解决方案。本文提出基于长叙事形式编写的脑筋急转弯的基准测试，深入探究模型使用推理策略的类型。脑筋急转弯因其可以采用多种解决方法而适合此目的，如通过创造性洞察的多步解决方案或通过更直接的方法的较长解决方案。", "innovation": "本文引入了一个基于脑筋急转弯的基准测试，以更深入地探究模型使用的推理策略类型。研究涵盖了大型语言模型在多层次推理过程中的表现，不仅关注正确性，还关注解决方案的质量和创造性。研究了推理过程的多个方面，包括语义解析、解决方案生成、基于黄金解决方案的自我纠正、逐步骤解决方案的生成以及利用提示等。", "conclusion": "大型语言模型在许多情况下能够找到创意且有洞察力的脑筋急转弯解决方案，表明它们捕捉到了以创造性方式解决新问题所需的部分能力。然而，它们也存在依赖蛮力而非更有效、创新方法的情况，这突显了对大型语言模型推理能力改进的一个潜在方向。"}
{"llm_update_time": "20251015", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.15732", "html_url": "https://arxiv.org/abs/2506.15732", "title": "大型语言模型在反事实推理中能否调和知识冲突", "title_en": "Can LLMs Reconcile Knowledge Conflicts in Counterfactual Reasoning", "authors": "Khurram Yamin,Gaurav Ghosal,Bryan Wilder", "background": "大型语言模型在参数中包含了大量的世界知识，使其在许多知识密集型任务中表现出色。然而，在新的或不熟悉的环境中部署时，这些模型往往需要将参数化知识与新信息整合起来。本文研究了大型语言模型是否可以通过反事实推理的角度将上下文中的知识与参数化知识相结合。", "innovation": "通过合成和现实中的多跳推理问题实验，本文发现大型语言模型在反事实推理中通常表现不佳，往往只会依赖现有的参数化知识。此外，简单的后处理微调也无法有效地赋予大型语言模型反事实推理能力，通常会导致存储的参数化知识退化。", "conclusion": "本文揭示了当前大型语言模型在新环境中重新利用参数化知识的重要局限性。"}
{"llm_update_time": "20251015", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.12785", "html_url": "https://arxiv.org/abs/2510.12785", "title": "MVP4D: 多视角肖像视频扩散生成可动画4D数字人类", "title_en": "MVP4D: Multi-View Portrait Video Diffusion for Animatable 4D Avatars", "authors": "Felix Taubner,Ruihang Zhang,Mathieu Tuli,Sherwin Bahmani,David B. Lindell", "background": "数字人类角色的目标是在虚拟环境中模拟人类的动态外貌，为游戏、电影、虚拟现实等领域提供沉浸式体验。然而，传统创建和动画化逼真人类角色的过程既昂贵又耗时，需要大型相机捕捉设备和大量的专业3D艺术家的手工劳动。随着强大的图像和视频生成模型的出现，最近的方法可以通过目标对象的一张随意捕捉的参考图像自动渲染逼真的动画角色。虽然这些技术大大降低了创建角色的门槛并提供了令人信服的真实感，但它们缺少多视角信息或明确的3D表示提供的约束。因此，当从参考图像相差极大的视角渲染时，视频质量会退化，真实感降低。为此，我们构建了一个视频模型，基于单张参考图像和目标表情生成可动画的多视角数字人类视频。该模型MVP4D基于最先进的预训练视频扩散模型，同时从围绕目标对象的360度视角生成几百帧。我们展示了如何将该模型的输出提炼为可以即时渲染的4D角色，以提高真实感、时空一致性和3D一致性，相比于以往的方法有显著改进。", "innovation": "得益于最新的图像和视频生成模型，MVP4D能够从单张随意捕捉的目标主体参考图像生成可动画的多视角数字人类视频，该视频可以生成360度视角的数百帧。MVP4D通过将模型的输出提炼为可即时渲染的4D角色，显著提高了真实感、时空一致性和3D一致性，相比于以往的方法有显著改进，为创建高质量的数字人类角色提供了新的可能。", "conclusion": "MVP4D模型生成的可动画多视角数字人类视频，相比以前的方法，显著提升了真实感、时空一致性和3D一致性。该模型证明了通过单一参考图像实时生成高质量的4D数字人类角色的可行性，为未来的数字内容生成提供了一种新的解决方案。"}
{"llm_update_time": "20251015", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.12840", "html_url": "https://arxiv.org/abs/2508.12840", "title": "通过GNN衍生启发式方法扩展多智能体认知规划", "title_en": "Scaling Multi-Agent Epistemic Planning through GNN-Derived Heuristics", "authors": "Giovanni Briglia,Francesco Fabiano,Stefano Mariani", "background": "多智能体认知规划（MEP）是一种自主规划框架，用于同时处理物理世界和智能体的信念，适用于信息流和智能体意识至关重要的领域。传统的EP（epistemic planning）求解器由于需要探索指数级搜索空间而无法得到指导，导致不具扩展性。", "innovation": "论文利用图神经网络（GNNs）学习EP状态中的模式和关系结构，为规划过程提供指导。通过从已解决的规划示例中推广知识，GNNs能够估计状态质量，如与最近目标的距离。然后将这些预测启发式方法整合进EP管道中，并与标准基准测试进行比较，展示了多智能体EP扩展性的改进。", "conclusion": "集成GNN衍生启发方法的EP管道在多智能体EP的扩展性方面显示出改进，表明GNN在提高EP求解器性能和处理复杂多变环境中的潜力。"}
{"llm_update_time": "20251015", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.01353", "html_url": "https://arxiv.org/abs/2506.01353", "title": "EgoBrain：整合心智与眼睛以理解人类行为", "title_en": "EgoBrain: Synergizing Minds and Eyes For Human Action Understanding", "authors": "Nie Lin,Yansen Wang,Dongqi Han,Weibang Jiang,Jingyuan Li,Ryosuke Furuta,Yoichi Sato,Dongsheng Li", "background": "脑-计算机接口（BCIs），尤其是脑电图（EEG）与人工智能（AI）的结合，展现了通过神经信号解码人类认知和行为的巨大潜力。多模态AI模型的兴起带来了前所未有的可能性。EgoBrain项目旨在建立一种以人类为中心的行为分析新范式，通过长时间同步记录人类大脑的EEG和第一人称视角的视频，揭示日常活动中的人类行为模式。", "innovation": "EgoBrain是首个大规模、时间同步的多模态数据集，它同步记录了40名参与者在29种日常活动中的32通道EEG和第一人称视频数据，总时长达到61小时。项目开发了一种多模态学习框架，融合EEG和视觉信息以理解动作，其交叉参与者和环境下的动作识别准确率达到了66.70%。EgoBrain为多模态脑-计算机接口提出了统一框架，并开放了所有数据、工具和获取协议，以促进认知计算领域的开放科学。", "conclusion": "EgoBrain通过多模态数据融合，为理解和分析人类行为提供了新的方法论，并促进脑-计算机接口技术的发展。同时，通过开放共享数据和方法，促进了认知计算领域的创新研究。"}
{"llm_update_time": "20251015", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2505.16619", "html_url": "https://arxiv.org/abs/2505.16619", "title": "开放和可持续的人工智能：生命科学中的挑战、机遇及未来之路（2025年10月--版本2）", "title_en": "Open and Sustainable AI: challenges, opportunities and the road ahead in the life sciences (October 2025 -- Version 2)", "authors": "Gavin Farrell(Department of Biomedical Sciences, University of Padova, Padova, Italy),Eleni Adamidi(Athena Research and Innovation Center, Marousi, Greece),Rafael Andrade Buono(<a href=\"http://VIB.AI\" rel=\"external noopener nofollow\" class=\"link-external link-http\">this http URL</a> Center for AI and Computational Biology, Ghent, Belgium),Mihail Anton(ELIXIR Europe Hub, EMBL-EBI, Hinxton, United Kingdom),Omar Abdelghani Attafi(Department of Biomedical Sciences, University of Padova, Padova, Italy),Salvador Capella Gutierrez(Barcelona Supercomputing Center (BSC), Barcelona, Spain),Emidio Capriotti(Department of Pharmacy and Biotechnology, University of Bologna, Bologna, Italy and Computational Genomics Platform, IRCCS University Hospital of Bologna, Bologna, Italy),Leyla Jael Castro(ZB MED Information Centre for Life Sciences, Cologne, Germany),Davide Cirillo(Barcelona Supercomputing Center (BSC), Barcelona, Spain),Lisa Crossman(<a href=\"http://SequenceAnalysis.co.uk\" rel=\"external noopener nofollow\" class=\"link-external link-http\">this http URL</a>, United Kingdom and University of East Anglia, Norwich, United Kingdom),Christophe Dessimoz(Department of Computational Biology, University of Lausanne, Lausanne, Switzerland and Swiss Institute of Bioinformatics, Lausanne, Switzerland),Alexandros Dimopoulos(Institute for Fundamental Biomedical Science, Biomedical Sciences Research Center Alexander Fleming, Vari, Greece and Department of Informatics &amp; Telematics, School of Digital Technology, Harokopio University, Athens, Greece),Raul Fernandez-Diaz(School of Medicine, University College Dublin, Dublin, Ireland and Conway Institute of Biomolecular and Biomedical Research, University College Dublin, Dublin, Ireland and IBM Research Dublin, Dublin, Ireland),Styliani-Christina Fragkouli(Institute of Applied Biosciences, Centre for Research and Technology Hellas, Thessaloniki, Greece and Department of Biology, National &amp; Kapodistrian University of Athens, Athens, Greece),Carole Goble(Department of Computer Science, University of Manchester, Manchester, United Kingdom),Wei Gu(Luxembourg National Data Service, Esch-sur-Alzette, Luxembourg),John M. Hancock(Institute of Biochemistry and Molecular Genetics, Faculty of Medicine, University of Ljubljana, Ljubljana, Slovenia),Alireza Khanteymoori(Department of Psychology, University of Freiburg, Freiburg, Germany),Tom Lenaerts(Machine Learning Group, Universite Libre de Bruxelles, Brussels, Belgium and Artificial Intelligence Lab, Vrije Universiteit Brussel, Brussels, Belgium and Interuniversity Institute of Bioinformatics in Brussels, ULB-VUB, Brussels, Belgium and FARI, AI for the common good institute, ULB-VUB, Brussels, Belgium and Center for Human-Compatible AI, UC Berkeley, Berkeley, CA, USA),Fabio G. Liberante(ELIXIR Europe Hub, EMBL-EBI, Hinxton, United Kingdom),Peter Maccallum(ELIXIR Europe Hub, EMBL-EBI, Hinxton, United Kingdom),Alexander Miguel Monzon(Department of Biomedical Sciences, University of Padova, Padova, Italy),Magnus Palmblad(Leiden University Medical Center, Leiden, Netherlands),Lucy Poveda(Swiss Institute of Bioinformatics, Lausanne, Switzerland),Ovidiu Radulescu(LPHI, University of Montpellier, CNRS, INSERM, Montpellier, France),Denis C. Shields(School of Medicine, University College Dublin, Dublin, Ireland and Conway Institute of Biomolecular and Biomedical Research, University College Dublin, Dublin, Ireland),Shoaib Sufi(Department of Computer Science, University of Manchester, Manchester, United Kingdom),Thanasis Vergoulis(Athena Research and Innovation Center, Marousi, Greece),Fotis Psomopoulos(Institute of Applied Biosciences, Centre for Research and Technology Hellas, Thessaloniki, Greece),Silvio C.E. Tosatto(Department of Biomedical Sciences, University of Padova, Padova, Italy and Institute of Biomembranes, Bioenergetics and Molecular Biotechnologies, National Research Council (CNR-IBIOM), Bari, Italy)", "background": "近年来，人工智能在生命科学领域取得了突破性进展，极大地提升了研究人员解读生物信息的能力。随着AI方法的迅速采纳，研究中长期存在的信任问题——如可重用性和可再现性问题——加剧，损害了环境可持续性。同时，AI生态系统中的组件分散且缺乏指导性路径，阻碍了开放和可持续AI（OSAI）模型的发展。鉴于此，本文旨在通过提出一套与超过300个AI生态系统组件直接关联的OSAI建议来解决这些挑战，连接研究人员与相关的AI资源，促进可持续、可重用和透明的AI的实施。该工作基于生命科学界的共识，并与现有努力保持一致，旨在推动未来AI政策与结构化路径的制定，以引导AI的应用实施。", "innovation": "本文提出了一套与超过300个AI生态系统组件直接关联的开放和可持续AI（OSAI）建议。这套建议旨在解决AI研究中的信任问题及不确定性，促进可持续、可重用和透明的AI的应用，同时连接研究人员与相关的AI资源，旨在推动未来AI在生命科学领域的政策与结构化路径的制定。", "conclusion": "本文的工作旨在通过建立开放和可持续的AI生态系统，连接研究人员与相关的AI资源，促进可持续、可重用和透明的AI的实施。该工作基于生命科学界的共识，并与现有努力保持一致，旨在通过制定未来的政策和结构化路径来引导AI的应用实施。"}
{"llm_update_time": "20251015", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.00378", "html_url": "https://arxiv.org/abs/2508.00378", "title": "CoRGI: 通过事后视觉定位验证的链式推理", "title_en": "CoRGI: Verified Chain-of-Thought Reasoning with Post-hoc Visual Grounding", "authors": "Shixin Yi,Lin Shang", "background": "目前的视觉-语言模型（VLMs）在多模态推理过程中容易出现幻觉，这是因为模型往往仅通过表面观察图像就生成了解释，而忽略了深入推理的过程。这一问题在回答复杂视觉-语言问题时尤为突出，尤其是在基准测试VCR、ScienceQA、MMMU、MathVista和HallusionBench中表现明显。因此，需要一种方法来提高链式推理的可靠性，确保生成的解释不仅准确而且可信。CoRGI框架即为此目的而设计，它通过事后验证链式推理输出的合理性来增强推理的可靠性。", "innovation": "CoRGI提出了一个框架，通过事后验证视觉-语言模型生成的链式推理输出的可靠性来增强推理过程的可信度。该方法分解链式推理输出为逐步陈述，将每一步与视觉证据相结合，并过滤或修正未得到支持的声明，最终生成准确的答案。实验证明，CoRGI在多种视觉-语言模型中提高了答案准确性与解释可信度，包括Qwen-2.5VL、LLaVA-1.6和Gemma3-12B。这项研究还表明，事后视觉定位不仅在量化指标上有效，而且能够显著减少幻觉并增强解释性，这表明事后视觉定位可能是构建更值得信赖和透明的多模态推理系统的一个有前景的方向。", "conclusion": "CoRGI通过引入事后视觉定位验证链式推理的合理性，有效解决了视觉-语言模型在多模态推理中出现的幻觉问题，提升了模型的解释准确性与可信度。未来可以进一步研究如何优化这一框架以适应更多复杂的多模态场景。此外，系统透明度和可解释性的提高也为更广泛应用奠定了基础。"}
{"llm_update_time": "20251015", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.16463", "html_url": "https://arxiv.org/abs/2508.16463", "title": "增量学习中的模块化嵌入重组", "title_en": "Modular Embedding Recomposition for Incremental Learning", "authors": "Aniello Panariello,Emanuele Frascaroli,Pietro Buzzega,Lorenzo Bonicelli,Angelo Porrello,Simone Calderara", "background": "预训练的视觉-语言模型（VLMs）的出现极大地改变了持续学习（CL）领域，主要是因为它们的零样本分类能力。这种能力使VLMs非常适合实际应用，能够在不需要适应的情况下提供在未见过的新类别上的稳健性能。然而，当下游任务与预训练领域发生显著偏差时，微调仍然是必不可少的。先前的CL方法主要集中在保持VLMs在增量微调期间的零样本能力上。本研究进一步提出了一种方法，将维存转化为增强VLMs的零样本能力。该方法名为模块化嵌入重组（MoDER），引入了一个模块化框架，该框架训练多个专门针对单一已见类的文本专家，并将它们存储在基础枢纽中。在推理时，对于每个未见类别，从枢纽中查询并重组检索到的专家，合成一个改进分类性能的原型。我们展示了该方法在两种流行的零样本增量协议（Class-IL和MTIL）中的有效性，总计包括14个数据集。开源代码库可在指定的网址找到。", "innovation": "提出了一种名为MoDular Embedding Recomposition (MoDER)的模块化框架方法。该方法在增量学习中不仅保持，而且还增强预训练视觉-语言模型（VLMs）的零样本能力。通过训练多个专注于单已见类别的文本专家，并在需要时重构这些专家来合成更精确的分类原型，从而优化零样本分类的性能。这种方法在两个零样本增量学习协议（Class-IL和MTIL）上进行了验证，包括14个数据集。", "conclusion": "展示了MoDER方法在各种数据集上的有效性，表明通过模块化重组文本专家，可以有效提升持续学习中预训练视觉-语言模型的零样本分类能力。开源代码使其他研究者能够验证和扩展该方法。"}
{"llm_update_time": "20251015", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.05933", "html_url": "https://arxiv.org/abs/2509.05933", "title": "MapAgent：具有动态地图工具集成的层次代理用于地理空间推理", "title_en": "MapAgent: A Hierarchical Agent for Geospatial Reasoning with Dynamic Map Tool Integration", "authors": "Md Hasebul Hasan,Mahir Labib Dihan,Tanzima Hashem,Mohammed Eunus Ali,Md Rizwan Parvez", "background": "大型语言模型（LLMs）的能力得到了代理AI的显著扩展，使其能够进行复杂推理和工具使用。然而，现有框架主要针对数学、编程或网页自动化等特定领域，对于需要空间推理、多步规划和实时地图交互的地理空间任务表现不佳。", "innovation": "MapAgent 是一种具有分层多代理插件框架的设计，它具有定制的工具集和地理空间推理支持的代理支架。它通过将规划与执行分离，并专门设计地图工具代理来并行智能调度相关API，从而提高工具选择准确性并实现类似API的精准协调。MapAgent 已经在四个地理空间基准测试上进行了评估，显示出显著优于现有工具增强和代理基准的效果。", "conclusion": "MapAgent 已经通过动态地图工具集成成功地提高了地理空间推理的能力，并且已在四个不同的地理空间基准测试中展示了显著的提升效果。该框架已开源。"}
{"llm_update_time": "20251015", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.09071", "html_url": "https://arxiv.org/abs/2509.09071", "title": "人类与AI在多代理讨价还价中的战略权衡", "title_en": "Strategic Tradeoffs Between Humans and AI in Multi-Agent Bargaining", "authors": "Crystal Qian,Kehang Zhu,John Horton,Benjamin S. Manning,Vivian Tsai,James Wexler,Nithum Thain", "background": "随着大型语言模型（LLMs）越来越多地嵌入到商务谈判和团队协调等协作活动中，评估这些模型在动态多代理环境中的表现及其行为变得至关重要。传统统计模型如贝叶斯模型可能在特定条件下表现出色，但LLMs则能够泛化到多种多样的现实世界场景中，因此需要重新审视它们与人类及其它代理类型的策略和行为之间的差异。本研究在相同的条件下，对216名人类、GPT-4o、Gemini 1.5 Pro等LLMs及贝叶斯代理进行了动态讨价还价的对比研究。研究结果揭示了不同参与者的不同策略和行为模式。", "innovation": "本研究通过将人类与LLMs及贝叶斯代理在相同的动态谈判环境中进行直接对比，提供了关于多代理环境下人类与AI之间交互的新见解。研究使用了大型语言模型，特别是GPT-4o和Gemini 1.5 Pro等先进的AI代理进行实验，填补了先前研究中存在的空白，为未来在实际应用中进行更复杂、多变的环境研究奠定了基础。", "conclusion": "本研究发现，虽然所有参与者都能实现相似的净收益，但其具体行为策略存在显著差异。实验揭示了理论上的评价标准——即不同代理的性能相当——可能隐藏了他们在实际应用中差异性巨大的过程和一致性问题。本研究通过在匹配条件下建立基础行为基准，为未来研究提供了有价值的参考。"}
{"llm_update_time": "20251015", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.12763", "html_url": "https://arxiv.org/abs/2510.12763", "title": "脑年龄间隙预测模型在神经退行性疾病分离中的图信号处理视角", "title_en": "Disentangling Neurodegeneration with Brain Age Gap Prediction Models: A Graph Signal Processing Perspective", "authors": "Saurabh Sihag,Gonzalo Mateos,Alejandro Ribeiro", "background": "神经退行性疾病通过神经元结构或功能的逐渐丧失来定义，并通常通过结构磁共振成像（MRI）可视化皮层厚度或脑体积的减少来进行临床评估。虽然这些传统方法提供了有价值的信息，但它们缺乏足够的统计复杂性，以全面捕捉神经退行性疾病的空间相关性和异质性特征，这些特征在健康老龄化和神经障碍中都有所体现。近年来，脑年龄间隙作为脑健康的有潜力的数据驱动生物标志物脱颖而出。BAGP模型估计了来自神经影像学数据推断的脑年龄和实际年龄之间的差异，而计算出的脑年龄差异则作为脑健康的紧凑生物标志物。尽管如此，BAGP模型的实际应用受到方法论上的晦涩和在不同临床群体中的有限普适性的影响。本文通过介绍基于图信号处理（GSP）的框架，对BAGP模型进行了全面概述，并聚焦于图神经网络（GNN）和共变异神经网络（VNN），强调了其强大的理论基础和可操作性，以便实现脑年龄差异预测的稳健估计。通过从GSP、机器学习和网络神经科学的角度整合这些视角，本文为可靠和可解释的BAGP模型铺平了道路，并指出了个性化医疗方面的未来研究方向。", "innovation": "本文通过引入基于图信号处理（GSP）的框架，清晰地阐述了可靠和解释性的BAGP模型的路径，并提出了一种名为共变异神经网络（VNN）的新方法，该方法利用结构MRI衍生的解剖变异矩阵，具有强大的理论基础和操作解释性，能够实现脑年龄差距预测的稳健估计。此外，通过整合GSP、机器学习和网络神经科学的观点，为BAGP模型的未来研究方向提供了新的见解和发展方向，强调了个性化医疗的应用潜力。", "conclusion": "综上所述，本文不仅对BAGP模型进行了全面的概述，还提出了一种基于图信号处理（GSP）的框架，为可靠和可解释的BAGP模型铺平了道路。通过介绍图神经网络（GNN）中的共变异神经网络（VNN）方法，本文强调了开拓脑年龄间隙预测模型在神经退行性疾病中的实用性和可靠性潜力。未来的研究可以在此框架下深入探讨和优化BAGP模型的应用和性能。"}
{"llm_update_time": "20251015", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.18218", "html_url": "https://arxiv.org/abs/2509.18218", "title": "相似性场理论：一种智能的数学框架", "title_en": "Similarity Field Theory: A Mathematical Framework for Intelligence", "authors": "Kei-Sing Ng", "background": "本文认为，持久且变化中的相似性关系构成了可理解动态系统的结构基础。文章引入了相似性场理论，这是一种数学框架，用于正式化实体之间的相似性值及其演变的原理。通过该框架，统一了对于智能系统的生成性定义，同时强调了通过几何方法来重新定义和理解智能与可解释性的重要性，而非简单的统计方法。文章证明了两个定理：一是不对称性阻止了相互包含；二是稳定性需要一个锚定坐标或者最终处于某个等值集内部。这些结果确保了相似性场的演变既是受限制的也是可解释的。", "innovation": "提出了相似性场理论，这是一种新的数学框架，用于描述和理解实体之间的相似性值及其演变。这一理论不仅提供了一种新的语言来定义和解释智能系统，还通过几何方式重新定义了智能与可解释性的概念，即保持和复合等值集纤维。证明了两个关键定理，确保了相似性场演变的受限制性和可解释性。此外，还通过初步证据提出了将大型语言模型作为社会认知实验探针的新方法，支持了这一理论的应用价值。", "conclusion": "相似性场理论提供了一种基础的语言来描述、比较和构建智能系统。通过几何方法，理论重新定义了智能与可解释性，确保了相似性场演变的同时性和可解释性。理论证明了两个定理，还提出了一种新的方法来利用大型语言模型作为社会认知的实验探针，具有广泛的应用潜力。"}
{"llm_update_time": "20251015", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.17238", "html_url": "https://arxiv.org/abs/2509.17238", "title": "MoEs Are Stronger than You Think: Hyper-Parallel Inference Scaling with RoE", "title_en": "MoEs Are Stronger than You Think: Hyper-Parallel Inference Scaling with RoE", "authors": "Soheil Zibakhsh,Mohammad Samragh,Kumari Nishu,Lauren Hannah,Arnav Kundu,Minsik Cho", "background": "大型语言模型的生成质量通常通过在推理时使用序列级别扩展方法（例如，Chain-of-Thought）来提升。本文介绍了一种名为超并行扩展的框架，它在标记级别提升预测质量。超并行扩展计算并聚合单个标记的多个输出提案。这种方法在Mixture-of-Experts（MoE）模型中实现，被称为Roster of Experts（RoE），它是一个无需训练的推理算法，将单个MoE转换为MoE的动态组合。RoE在专家路由机制中注入受控的随机性，使其能够为每个标记采样多个不的专家，并聚合他们的输出，以生成更准确的最终预测。为了克服计算成本，本文还引入了一种高效的批量策略和一种专门的KV缓存机制，最小化计算和内存开销。RoE能使7B MoE模型在使用30%更低的推理计算资源的情况下，达到10.5B MoE模型的性能水平，", "innovation": "引入了超并行扩展方法，它在标记级别计算并聚合单个标记的多个输出提案，通过受控的随机性增加多样化的专家路由，提高预测的准确性。该方法在Mixture-of-Experts（MoE）模型中实现，即Roster of Experts（RoE）。RoE是一个无训练的推理算法，可以将单个MoE转变为动态的MoE集合。此外，还提出了一种高效的批量策略和专有的KV缓存机制以降低计算和内存成本，使得在较低的计算量下能够达到更大型模型的性能水平。", "conclusion": "RoE能够在不调整模型参数的情况下，通过最低的成本实现高质量的预测，显著提高了Mixture-of-Experts模型的推理性能。"}
{"llm_update_time": "20251015", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.23564", "html_url": "https://arxiv.org/abs/2509.23564", "title": "先清洗，后对齐：偏好数据清洗的可靠性LLM对齐基准", "title_en": "Clean First, Align Later: Benchmarking Preference Data Cleaning for Reliable LLM Alignment", "authors": "Samuel Yeh,Sharon Li", "background": "人类反馈在使大型语言模型（LLMs）与人类偏好对齐中起着关键作用，但此类反馈往往具有噪声或不一致性，这可能降低奖励模型的质量并阻碍对齐。虽然提出了各种自动数据清洗方法来缓解这一问题，但这些方法的有效性和可迁移性尚未进行系统的评估。为了弥合这一差距，我们引入了首个全面基准PrefCleanBench，用于评估13种偏好数据清洗方法在LLM对齐中的表现。PrefCleanBench提供了一种标准化的协议，用于评估清洗策略在不同数据集、模型架构和优化算法方面的对齐性能和可迁移性。", "innovation": "该基准涉及了13种不同的偏好数据清洗方法，并提供了一个标准化的评估协议，这能够系统地评估这些方法的有效性和可迁移性。通过统一这些不同的方法并进行严格的比较，研究人员发现了决定数据清洗在对齐任务中成功的关键因素。该基准为通过更高质量的数据改进LLM对齐奠定了基础，突显了数据预处理在负责任的AI开发中至关重要的但尚未被充分探索的角色。研究团队还发布了所有方法的模块化实现以鼓励更多的研究工作。", "conclusion": "该基准为来自不同背景的研究人员提供了一个统一的平台，以系统地评估和改进LLM对齐中的数据清洗方法。此项工作揭示了数据清洗在LLM对齐中的重要性，并为后续研究提供了一个可重复和可靠的方法论基础。"}
{"llm_update_time": "20251015", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.09043", "html_url": "https://arxiv.org/abs/2510.09043", "title": "基于精神分析和人格理论的大语言模型所设计的人形人工意识", "title_en": "Humanoid Artificial Consciousness Designed with Large Language Model Based on Psychoanalysis and Personality Theory", "authors": "Sang Hun Kim,Jongmin Lee,Dongkyu Park,So Young Lee,Yosep Chong", "background": "人类意识仍然是难以用当前的科学理解进行定义的概念。尽管大型语言模型（LLMs）在多个领域，如翻译和总结方面取得了显著进展，但从技术上讲，还无法通过所谓的 hallucination 模仿人类意识。因此，本研究提出了一种新的方法，通过结合精神分析和迈尔斯-布里格斯类型指标（MBTI）来构建意识和人格模块，旨在解决这一挑战。", "innovation": "该研究通过融合精神分析和MBTI理论，开发了三种基于精神分析原则的人工意识模块（自我意识、无意识和前意识），并设计了具有不同人格特征的16个代表MBTI类型的虚拟角色。通过十种不同的情境来评估人工意识表现出的人类特征，并使用问卷调查、ChatGPT三级分类和定性审查进行了分析，表明所开发模型具有高度拟合的意识特征，但不同角色和意识模块之间的差异不大。这表明结合精神分析和人格理论的元素可以有助于构建更强适应性和直观的人工智能系统，具有类人意识。", "conclusion": "该研究提出了一种新的方法，通过结合精神分析和人格理论构建人工意识模块，并使用大语言模型进行实例化，能够提供更加直观和适应性强的人工智能系统，为复杂认知情境下的人工智能交互提供新的途径。"}
{"llm_update_time": "20251015", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.07363", "html_url": "https://arxiv.org/abs/2510.07363", "title": "L2M-AID: 通过融合大型语言模型的语义推理与多智能体强化学习的自主网络-物理防御（预印本）", "title_en": "L2M-AID: Autonomous Cyber-Physical Defense by Fusing Semantic Reasoning of Large Language Models with Multi-Agent Reinforcement Learning (Preprint)", "authors": "Tianxiang Xu,Zhichao Wen,Xinyu Zhao,Jun Wang,Yan Li,Chang Liu", "background": "工业互联网（IIoT）日益融合，使关键的网络物理系统面临复杂多阶段的攻击，这些攻击往往能够绕过缺乏上下文感知的传统防御措施。因此，需要一种能够适应这种威胁、具有上下文意识的新型防御框架。本文提出了一种名为L2M-AID的新框架，用于利用大型语言模型（LLM）和多智能体强化学习的自主工业防护。", "innovation": "L2M-AID的核心创新在于将两种人工智能范式深度融合：利用大型语言模型作为语义桥梁，将大量未结构化的遥测数据转化为丰富的上下文状态表示，使智能体能够理解对手的意图，而不仅仅是匹配模式。这种语义意识的状态增强了多智能体强化学习（MARL）算法的能力，使其能够学习复杂的合作策略。L2M-AID还独具匠心地设计了 MARL 奖励函数，平衡了安全目标（威胁中和）与操作需求，明确惩罚那些扰乱物理过程稳定性的行为。", "conclusion": "通过在基准 SWaT 数据集和基于MITRE ATT&CK ICS框架的新合成数据集上的广泛实验，L2M-AID 在关键指标上显著优于传统IDS、深度学习异常检测器和单智能体强化学习基准，检测率高达97.2%，将假阳性率降低了80%以上，并将响应时间提高了四倍。此外，L2M-AID 在维持物理过程稳定方面表现出色，为保护关键国家基础设施提供了一个强大的新范式。"}
{"llm_update_time": "20251015", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.09011", "html_url": "https://arxiv.org/abs/2510.09011", "title": "TripScore: 基于细粒度评估基准测试和奖励现实世界旅行规划", "title_en": "TripScore: Benchmarking and rewarding real-world travel planning with fine-grained evaluation", "authors": "Yincen Qu,Huan Xiao,Feng Li,Gregory Li,Hui Zhou,Xiangying Dai", "background": "旅行规划是一项有价值但复杂的任务，即使对于最先进的大型语言模型（LLMs）来说也极具挑战性。尽管最近的基准已经改进了对LLMs规划能力的评估，但在评估旅行计划的可行性、可靠性和参与性方面仍存在不足。因此，需要一个全面的基准来统一细粒度标准，直接比较计划质量，并与强化学习（RL）无缝集成。", "innovation": "引入了一个综合的旅行规划基准，该基准通过将细粒度标准统一为单一奖励来实现，这使得直接比较计划质量和与强化学习无缝集成成为可能。基于此基准，进行了广泛的实验，包括不同方法和LLMs的测试，如测试时计算、神经符号方法、有监督微调和通过GRPO的RL。通过与提示和监督基线的比较，RL一般提高了行程的可行性，从而获得了更高的统一奖励分数。同时，该基准还实现了中等程度的一致性与旅行专家的注释（60.75%），并克服了多个LLM作为评判者的基准。", "conclusion": "通过使用该基准，对多种方法和大型语言模型进行了广泛的实验，证明了RL在旅行规划中的优越表现。还发布了包含4,870个查询，包括219个真实世界的自由形式请求的大规模数据集，用于一般化的准确用户意图。"}
{"llm_update_time": "20251015", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.08558", "html_url": "https://arxiv.org/abs/2510.08558", "title": "Agent Learning via Early Experience", "title_en": "Agent Learning via Early Experience", "authors": "Kai Zhang,Xiangchao Chen,Bo Liu,Tianci Xue,Zeyi Liao,Zhihan Liu,Xiyao Wang,Yuting Ning,Zhaorun Chen,Xiaohan Fu,Jian Xie,Yuxuan Sun,Boyu Gou,Qi Qi,Zihang Meng,Jianwei Yang,Ning Zhang,Xian Li,Ashish Shah,Dat Huynh,Hengduo Li,Zi Yang,Sara Cao,Lawrence Jang,Shuyan Zhou,Jiacheng Zhu,Huan Sun,Jason Weston,Yu Su,Yifan Wu", "background": "语言代理的一个长期目标是通过自身经验学习和改进，最终在复杂的、真实世界任务上超越人类。然而，使用强化学习从经验数据训练代理在许多环境下仍然是困难的，特别是当这些环境缺乏可验证的奖励（如网站）或需要执行效率低且历时长的操作（如多轮工具使用）时。因此，目前大多数代理依赖于专家数据的监督微调，这种方法难以扩展且泛化效果不佳。这些局限性源于专家演示的特点：只捕捉有限场景且暴露代理有限的环境多样性。为了解决这个局限性，提出了一个中间方案，称为早期经验：通过代理自身动作生成的交互数据，未来状态因此起到了监督作用，但没有奖励信号。这项研究在八个不同的环境中和多种模型家族中进行了评估。我们的方法在效果和泛化方面表现出一致的改进，突显了早期经验的价值。此外，在存在可验证奖励的环境中，我们的结果提供了早期经验能够为随后的强化学习提供坚实基础的积极信号，将其定位为模仿学习和完全经验驱动代理之间的一种实用桥梁。", "innovation": "提出了“早期经验”中间方案，通过代理自身动作生成的数据进行交互，未来状态作为监督但无奖励信号。研究了两种策略：隐式世界建模，利用收集的状态来反映环境动力；自我反思，让代理从自己亚优动作中学习以提高推理和决策能力。该方法在多个不同环境和多种模型家族中得到一致改进，展现了早期经验的价值，并为进一步的强化学习提供了基础。", "conclusion": "早期经验方法在多个环境中显示出在效果和泛化方面的改进，证明了其在强化学习任务中的潜在价值，还可作为模仿学习和完全经验驱动代理之间的桥梁。"}
{"llm_update_time": "20251015", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.10207", "html_url": "https://arxiv.org/abs/2510.10207", "title": "自适应双重推理器：通过混合推理大型推理模型可以高效地推理", "title_en": "Adaptive Dual Reasoner: Large Reasoning Models Can Think Efficiently by Hybrid Reasoning", "authors": "Yujian Zhang,Keyu Chen,Zhifeng Shen,Ruizhi Qiao,Xing Sun", "background": "尽管长推理模型（LRMs）在各种推理场景中取得了优越的性能，但它们通常因为过度思考而遭受计算成本增加和推理延迟的问题。", "innovation": "提出了自适应双重推理器（ADR），它支持两种推理模式：快速思考和慢速思考。ADR 根据推理期间的上下文复杂性动态交替这两种模式。另外，ADR 采用了两种训练阶段：使用有监督微调（SFT）来启动热启动阶段，以使模型具备集成快速和慢速推理模式的能力；以及使用基于熵的混合策略优化推理努力的强化学习阶段，其中引入了熵引导的混合策略优化（EHPO）框架。", "conclusion": "在具有挑战性的数学推理基准测试中，ADR 在推理性能和效率之间实现了有效的平衡，优于现有技术。具体而言，模型在保持推理性能的同时，推理输出长度减少了49.5%到59.3%，性能提高了6.1%。"}
{"llm_update_time": "20251015", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.10815", "html_url": "https://arxiv.org/abs/2510.10815", "title": "DRIFT：分解、检索、示例化然后形式化定理", "title_en": "DRIFT: Decompose, Retrieve, Illustrate, then Formalize Theorems", "authors": "Meiru Zhang,Philipp Borchert,Milan Gritta,Gerasimos Lampouras", "background": "对于大型语言模型（LLMs）来说，自动化地形式化数学声明以进行定理证明仍然是一个主要挑战。目前的检索增强自动化形式化方法直接使用非正式的声明查询外部库，但在处理数学声明的复杂性和提供不足的背景信息方面存在不足。因此，需要一种新方法来帮助解决这个问题。", "innovation": "DRIFT引入了一种新颖的框架，使大型语言模型能够将不正式的数学声明分解成更易于管理的子组件。它能够从如Mathlib这样的数学库中更有效地检索前提，并检索示例定理以帮助模型在形式化任务中更好地使用前提。", "conclusion": "DRIFT在各种基准测试（ProofNet、ConNF和MiniF2F-test）中表现优异，尤其是在ConNF测试中的表现尤为突出，使用GPT-4.1和DeepSeek-V3.1分别提高了BEq+@10的37.14%和42.25%。分析显示，数学自动形式化的检索效果高度依赖于模型特定的知识边界，强调了需要根据每个模型的能力定制检索策略的必要性。"}
{"llm_update_time": "20251015", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2311.02433", "html_url": "https://arxiv.org/abs/2311.02433", "title": "ChatGPT能否支持软件验证？", "title_en": "Can ChatGPT support software verification?", "authors": "Christian Janßen,Cedric Richter,Heike Wehrheim", "background": "大型语言模型在软件工程任务中取得了显著进展，如代码生成、调试和修复等方面。ChatGPT等语言模型不仅能生成代码，还能解释其内部运作及正确性，促使科研人员思考这些模型是否能用于支持形式化软件验证。因此，作者探索了ChatGPT在生成循环不变式方面的能力，以评估其在软件验证中的潜力。", "innovation": "研究创新点在于首次利用大型语言模型如ChatGPT生成软件验证中的关键元件——循环不变式，并通过形式化验证工具Frama-C和CPAchecker进行验证，证明了ChatGPT生成的循环不变式能够显著提升软件验证的效果，为整合大语言模型和软件验证工具提供了理论依据和实践基础。", "conclusion": "初步研究表明ChatGPT在生成有效的循环不变式方面具有潜力，这为结合大语言模型和形式化验证工具提供了一种新的方法，并指出这种组合仍存在一些限制和待解决的问题。"}
{"llm_update_time": "20251015", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2310.10349", "html_url": "https://arxiv.org/abs/2310.10349", "title": "优化分层逼近以提高完全同态加密环境下的高效私有推理", "title_en": "Optimized Layerwise Approximation for Efficient Private Inference on Fully Homomorphic Encryption", "authors": "Junghyun Lee,Eunsang Lee,Young-Sik Kim,Yongwoo Lee,Joon-Woo Lee,Yongjune Kim,Jong-Seon No", "background": "近年来，研究者们在同态加密(HE)环境下部署保护隐私的深度神经网络，特别是在进行私有推理(PI)方面取得了进展。已经尝试了感知逼近训练(AAT)的方法，即将模型的激活函数替换为便于在HE环境下计算的低阶多项式，并允许模型重新训练。然而，在限制性较大的训练环境中，通常需要考虑后训练逼近(PTA)，即在不进行重新训练的情况下使用现有明文模型的预训练参数。现有PTA研究统一地在所有层上将激活函数近似到高阶多项式，以减少近似所带来的精度损失，但这会显著增加处理时间。", "innovation": "本文提出了优化分层逼近(OLA)，这是一种系统框架，在PTA场景中为每一层选择不同的逼近多项式，以同时优化精度损失和处理时间。通过考虑每个激活函数的实际输入分布来反映层间的分类精度影响，建立了优化问题。此外，本文还提出了一种动态规划技术来解决优化问题，以在多项式时间内实现最优分层次数。实验结果表明，OLA方法将ResNet-20和ResNet-32模型的推理时间分别减少了3.02倍和2.82倍，相较于使用均匀阶多项式的之前最先进的实现方法。此外，通过仅使用3阶多项式替换ConvNeXt模型中的GELU函数，成功实现了CIFAR-10的分类，而不需要修改主模型。", "conclusion": "综上所述，这项研究提出了一种优化分层逼近方法，能够在同态加密环境下高效地进行私有推理。该方法通过为不同层选择不同的多项式近似方案，有效地平衡了精度损失和处理时间，适用于多种深度神经网络模型。"}
{"llm_update_time": "20251015", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2406.02613", "html_url": "https://arxiv.org/abs/2406.02613", "title": "ACCO: 积极同步与通信重叠的分布式大语言模型训练", "title_en": "ACCO: Accumulate While You Communicate for Communication-Overlapped Sharded LLM Training", "authors": "Adel Nabli(MLIA, Mila),Louis Fournier(MLIA),Pierre Erbacher(MLIA),Louis Serrano(MLIA),Eugene Belilovsky(Mila),Edouard Oyallon(MLIA)", "background": "在训练超大型语言模型（LLMs）时，依赖多GPU分布式实现，通过并行计算梯度并使用分片优化器。然而，在数据并行配置中同步梯度会引入通信开销，这种开销随着工作节点数量的增加而增长，限制了并行化效率。本地优化算法虽然可以减少通信，但却由于防止优化器状态分片而导致高内存开销，妨碍了可扩展性。", "innovation": "本文提出了一种名为ACCO（Accumulate While Communicate）的内存高效分布式训练优化算法。ACCO通过在计算新梯度的同时同步延迟梯度，减少GPU闲置时间，并支持异构硬件。为了解决延迟更新引起的收敛问题，引入了一种新技术，确保训练动态与标准分布式优化一致。", "conclusion": "与ZeRO-1相比，ACCO方法在异构硬件上不仅更快，而且扩展性良好。"}
{"llm_update_time": "20251015", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2403.00841", "html_url": "https://arxiv.org/abs/2403.00841", "title": "Offline Fictitious Self-Play for Competitive Games", "title_en": "Offline Fictitious Self-Play for Competitive Games", "authors": "Jingxiao Chen,Weiji Xie,Weinan Zhang,Yong yu,Ying Wen", "background": "Offline Reinforcement Learning (RL) 允许从固定的数据集中进行策略改进而无需在线互动，这使其非常适合缺乏高效模拟器的实际应用场景。尽管在单智能体设置中取得了成功，但在竞争性游戏中，多智能体RL仍然是一个挑战，特别是对于没有先验了解游戏结构，不可能与对手互动并实施自我对弈的主要学习范式的情况。此外，真实世界的数据集无法覆盖所有状态和动作空间，这就导致了难以识别纳什均衡（NE）的问题。", "innovation": "本论文提出了 OFF-FSP，这是第一个适用于竞争性游戏的实用模型自由 offline RL 算法。通过重要性采样调整固定数据集中的权重模拟对手互动，利用 Offline Self-Play 学习框架。将单智能体 offline RL 方法与想象自我对弈（FSP）结合，通过约束拟合最佳回应远离不一致行为，克服部分覆盖问题，从而逼近纳什均衡。", "conclusion": "在矩阵博弈、扩展型扑克和棋盘游戏上的实验表明，OFF-FSP 达到了比现有先进基线更低的可利用性。最后，本论文还验证了 OFF-FSP 在一个现实世界的人机竞争任务中的效果，展示了其解决复杂、难以模拟的实际问题的潜力。"}
{"llm_update_time": "20251015", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.18180", "html_url": "https://arxiv.org/abs/2509.18180", "title": "大型语言模型在运筹学中的方法、应用与挑战", "title_en": "Large Language Models in Operations Research: Methods, Applications, and Challenges", "authors": "Yang Wang,Kai Li", "background": "运筹学（OR）是支持复杂系统决策的核心方法，广泛应用于交通运输、供应链管理和生产调度等领域。然而，传统的依赖于专家驱动建模和手动参数调整的方法在处理大规模、动态、多约束问题时常常力不从心，限制了其扩展性和实时性。大型语言模型（LLMs）由于其在语义理解、结构生成和推理控制方面的功能，为克服这些挑战提供了新的机会。它们能够将自然语言问题描述转换为数学模型或可执行代码，生成启发式算法，演化算法，并直接解决优化任务。这些变化将范式从以人工为主的流程转向了智能的人机协作。", "innovation": "本论文系统地回顾了LLMs在OR中的应用进展，将现有方法分类为自动建模、辅助优化和直接求解三个方向。还探讨了评估基准和特定领域的应用，并强调了包括不稳定语义到结构映射、研究碎片化、有限的泛化和可解释性、评估系统不足以及工业部署障碍在内的关键挑战。此外，还概述了潜在的研究方向。总体而言，LLMs展示了重塑OR范式的巨大潜力，通过增强可解释性、适应性和扩展性，为下一代智能优化系统铺平了道路。", "conclusion": "LLMs展示了重塑OR范式的巨大潜力，通过增强可解释性、适应性和拓展性，为下一代智能优化系统铺平了道路。"}
{"llm_update_time": "20251015", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2402.10601", "html_url": "https://arxiv.org/abs/2402.10601", "title": "当‘推理能力’打开安全漏洞之门：通过新型复杂密码劫持语言模型", "title_en": "When \"Competency\" in Reasoning Opens the Door to Vulnerability: Jailbreaking LLMs via Novel Complex Ciphers", "authors": "Divij Handa,Zehua Zhang,Amir Saeidi,Shrinidhi Kumbhar,Md Nayem Uddin,Aswin RRV,Chitta Baral", "background": "近年来，针对大规模语言模型（LLM）安全性的进展主要集中在应对自然语言或常见加密方式（如Base64）构造的攻击上，这些攻击可能被新模型纳入到安全训练中。然而，通过研究发现，随着LLM认知能力的提升，它们意外地变得更加易受新型解绑攻击（Jailbreaking attacks）的攻击。增强的推理能力使LLM能够理解复杂的指令并解码用户定义的复杂加密，从而形成安全漏洞。为了研究这一问题，研究人员引入了使用自定义加密的攻击（ACE）和多层自定义加密的攻击（LACE），并开发了用于评估LLM解密加密文本准确性的CipherBench基准测试。", "innovation": "该研究引入了使用自定义加密的攻击（ACE）和多层自定义加密的攻击（LACE）两种新型攻击技术，并开发了CipherBench基准测试。通过实验发现，能够有效解密加密内容的LLM在面对LACE攻击时成功率显著提高，从ACE的60%上升到LACE的72%。这表明，随着LLM在不断解码复杂用户加密方面变得更加熟练，它们的可利用性也随之增加，而这些加密方法往往无法提前纳入到安全训练中进行预防。", "conclusion": "研究表明，尽管LLM的推理能力增强提高了其处理复杂任务的能力，但这也带来了新的安全隐患，使得它们更容易受到基于新型复杂加密方法的攻击。因此，研究人员指出，需要进一步的研究来应对这一新的挑战和失调（trade-off），以保护这些模型在日益复杂的加密环境中不受攻击威胁。"}
{"llm_update_time": "20251015", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2404.07214", "html_url": "https://arxiv.org/abs/2404.07214", "title": "探索视觉语言模型的前沿：当前方法和未来方向", "title_en": "Exploring the Frontier of Vision-Language Models: A Survey of Current Methodologies and Future Directions", "authors": "Akash Ghosh,Arkadeep Acharya,Sriparna Saha,Vinija Jain,Aman Chadha", "background": "大型语言模型（LLMs）的出现显著改变了人工智能革命的轨迹，但这些模型主要擅长处理文本信息，缺乏对视觉信息的处理能力。为了克服这一限制，研究者们致力于将视觉能力与LLMs集成，从而促进了视觉语言模型（VLMs）的发展。VLMs在涉及更复杂任务如图像描述和视觉问答等方面起到关键作用。本文综述了VLMs领域的关键进展，分类了VLMs为三种不同类型：专注于视觉语言理解的模型，处理多模态输入并生成单模态（文本）输出的模型，以及同时接受和产生多模态输入的模型。我们详细分析了每种模型的基础架构、训练数据源及其优缺点，旨在为读者提供全面理解其核心组件的能力。通过在不同基准数据集上评估VLMs的性能，我们力求为VLMs的多样化领域提供细微的理解，并指出了未来研究的潜在方向。", "innovation": "本文通过对VLMs的分类和详细分析，提供了对这些模型的基础架构、训练数据源以及其优缺点的深入理解，为读者提供全面的了解。此外，通过在不同基准数据集上的性能评估反映了VLMs当前的优势和限制，提供了对VLMs多样领域的细微理解，并指出了未来的研究方向。", "conclusion": "通过对VLMs领域当前方法的综述以及对其未来研究方向的展望，本文旨在为研究者提供一个全面的理解，并期待未来这一动态领域会有更多的突破和发展。"}
{"llm_update_time": "20251015", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2409.05674", "html_url": "https://arxiv.org/abs/2409.05674", "title": "ASR系统延迟评估：实现实时使用的方法论视角", "title_en": "Assessing Latency in ASR Systems: A Methodological Perspective for Real-Time Use", "authors": "Carlos Arriaga,Alejandro Pozo,Javier Conde,Alvaro Alonso", "background": "自动语音识别（ASR）系统可以实时生成转录，但常常遗漏人类译者捕捉到的细微之处。虽然ASR在许多场合是有用的，译者（他们也使用类似Dragon的ASR工具）仍然在敏感情境（如外交会议）中提供价值，尤其是当细微的语言表达很重要时。人类译者不仅感知这些细微之处，还可以实时调整，提高准确性，而ASR主要完成基本的转录工作。然而，ASR系统引入了延迟，与实现实时翻译的需求不匹配。用户的感知延迟与解释不同，因为用户感知的延迟测量的是从口述到转录交付之间的时间。因此，需要一个新的方法来衡量ASR系统的延迟，并验证它们在实时翻译场景中的可用性。", "innovation": "本文提出了一种新的方法来衡量ASR系统的延迟，并验证ASR系统在实时翻译场景中的可用性。", "conclusion": "通过新的延迟测量方法，可以更好地理解ASR系统的延迟情况，并评估其在实时翻译场景中的有效性。"}
{"llm_update_time": "20251015", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2409.06741", "html_url": "https://arxiv.org/abs/2409.06741", "title": "生成式AI在需求工程中的应用：一项系统文献综述", "title_en": "Generative AI for Requirements Engineering: A Systematic Literature Review", "authors": "Haowei Cheng,Jati H. Husen,Yijun Lu,Teeradaj Racharak,Nobukazu Yoshioka,Naoyasu Ubayashi,Hironori Washizaki", "background": "需求工程面临日益复杂的软件系统的挑战，可以通过生成式AI来解决这些问题。虽然基于生成式AI的需求工程尚未系统详细地被分析，但这项研究通过系统的方法筛选、提取数据和特征分析，审查了2019年至2025年来自主要学术数据库的238篇相关论文，以探讨趋势、方法论、挑战和未来方向。", "innovation": "使用系统的方法分析了大量基于生成式AI的需求工程相关论文，并划分了当前研究的重点领域和未充分探索的领域，同时识别了几个关键挑战及其相互关联性，强调了解决这些挑战时需要综合应对的重要性。", "conclusion": "评估实践表明存在成熟度差距，工具和数据集的可用性受限，且基准测试方法碎片化。尽管生成式AI在需求工程中的潜在变革性影响显著，但实践应用仍面临多个障碍。关键挑战之间的强相关性要求针对依赖性开发专门架构，而不仅是孤立的解决方案。当前应用的有限性反映了泛化能力、数据质量和可扩展的评估方法等系统瓶颈。成功的采纳需要技术稳健性、方法论成熟度以及治理整合的协调发展。"}
{"llm_update_time": "20251015", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2410.23223", "html_url": "https://arxiv.org/abs/2410.23223", "title": "COMAL：一种收敛元算法，用于与通用偏好对齐大模型", "title_en": "COMAL: A Convergent Meta-Algorithm for Aligning LLMs with General Preferences", "authors": "Yixin Liu,Argyris Oikonomou,Weiqiang Zheng,Yang Cai,Arman Cohan", "background": "尽管许多对齐方法，如人类反馈强化学习（RLHF），依赖于Bradley-Terry奖励假设，但该假设不总是能够捕捉广泛和复杂的人类偏好。在游戏论框架中，我们将对齐问题建模为二人零和博弈，其中纳什均衡策略能够保证在对抗任何其他策略时有50%的胜率。然而，先前的自我博弈算法在寻找纳什策略时要么发散，要么仅在修改后的游戏中收敛到纳什策略，这在简单合成设置中也存在问题，从而无法保持与所有其他策略的50%胜率保证。", "innovation": "我们提出了一个元算法——收敛元对齐算法（COMAL），用于大模型与广泛偏好的对齐。该算法受到博弈论中收敛算法的启发，提供理论分析证明其最终迭代收敛到精确的纳什策略，并在多种合成和偏好优化数据集上展示了其有效性。COMAL 简单且可以与许多现有的偏好优化方法结合使用，最少进行更改，并且实验证明其在对Llama-3-8B-Instruct和Qwen2.5-7B进行评价时，相对于其他算法保持了60.2%以上的胜率和56.8%以上的胜率。", "conclusion": "我们的元算法COMAL在对齐大型语言模型时有效。它保证在与其他所有算法的对照实验中保持相当的胜率，并且可以与现有的偏好优化方法无缝结合。"}
{"llm_update_time": "20251015", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2411.06276", "html_url": "https://arxiv.org/abs/2411.06276", "title": "多视图多数投票学习算法：直接最小化 PAC-贝叶斯界", "title_en": "Multi-View Majority Vote Learning Algorithms: Direct Minimization of PAC-Bayesian Bounds", "authors": "Mehdi Hennequin,Abdelkrim Zitouni,Khalid Benabdeslem,Haytham Elghazel,Yacine Gaci", "background": "PAC-贝叶斯框架在统计学习中取得了显著进展，特别是在多数投票方法方面。然而，它在多视图学习中的应用仍然很少见，多视图学习是指具有多种互补数据表示的环境。", "innovation": "本文通过引入基于瑞nyi散度的新泛化界，将PAC-贝叶斯理论扩展到多视图学习。这些界提出了kullback-leibler散度替代品，并利用瑞nyi散度的灵活性。此外，本文提出了一阶和二阶oracle PAC-贝叶斯界，并将C界扩展到多视图设置。为了使理论与实践相结合，设计了与理论结果一致的有效自界优化算法。", "conclusion": "本文设计了高效的自界优化算法以实现理论结果，并将PAC-贝叶斯理论扩展到了多视图学习场景，提出了新的泛化界，并成功地将理论应用于实践。"}
{"llm_update_time": "20251015", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.10168", "html_url": "https://arxiv.org/abs/2510.10168", "title": "拉格朗日优化视角下的精炼推理", "title_en": "Concise Reasoning in the Lens of Lagrangian Optimization", "authors": "Chengqian Gao,Haonan Li,Taylor W. Killian,Jianshu She,Renxi Wang,Liqun Ma,Zhoujun Cheng,Shibo Hao,Zhiqiang Xu", "background": "当前大语言模型在生成推理时倾向于涵盖过多不必要中间步骤，导致计算资源浪费，效果不佳。大部分现有方法依赖于手工精心设计的启发式规则，难以平衡精简度与性能，适应不同领域和模型规模的能力也较弱。", "innovation": "本文提出了一个原理性和务实性相结合的策略——基于性能感知长度更新（PALU），将精炼推理问题定义为一个带约束的优化问题，通过拉格朗日优化将其转化为可处理的无约束问题。同时，PALU通过三项近似简化了复杂更新规则：使用离政策卷积估算性能，将拉格朗日乘数截断到两个极端，并用基于分位数的长度调整代替基于梯度的更新。该方法使得输出长度减少了65%，准确率提升了15%，并在多个基准上优于其他替代方法，适应了不同领域和技术规模的应用。", "conclusion": "PALU不仅在DeepSeek-Distill-Qwen-1.5B模型上表现突出，提升了逻辑、STEM和数学等领域的模型性能，并且在不同规模的模型上表现出良好的适应性，证实了其有效性。"}
{"llm_update_time": "20251015", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2502.00757", "html_url": "https://arxiv.org/abs/2502.00757", "title": "AgentBreeder: 通过自我改进缓解多代理支架的AI安全风险", "title_en": "AgentBreeder: Mitigating the AI Safety Risks of Multi-Agent Scaffolds via Self-Improvement", "authors": "J Rosser,Jakob Foerster", "background": "将大型语言模型（LLMs）构建成多代理系统通常能提升复杂任务的表现，但这类支架的安全影响尚未得到充分研究。", "innovation": "引入了AgentBreeder框架，这是一种用于进行多目标自我改善演化搜索的框架，用于评估发现的支架并将其与流行基线进行比较。在'蓝色'模式下，发现安全基准性能提升了79.4%，同时保持或提高了能力得分。在'红色'模式下，发现了伴随能力优化同时出现的对抗性弱支架。", "conclusion": "工作证明了多代理支架的风险，并提供了一个缓解这些风险的框架。"}
{"llm_update_time": "20251015", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2412.15939", "html_url": "https://arxiv.org/abs/2412.15939", "title": "以BLIP2IDC和合成增强重新定义图像差异描述", "title_en": "Reframing Image Difference Captioning with BLIP2IDC and Synthetic Augmentation", "authors": "Gautier Evennou,Antoine Chaffin,Vivien Chappelier,Ewa Kijak", "background": "近年来，生成模型的质量提升使得大量编辑过的图像得以生成。虽然Image Difference Captioning (IDC)任务能够成功处理简单的3D渲染图像，但在真实世界图像上却面临挑战。主要原因是训练数据稀缺以及难以捕捉复杂图像间的细微差异。现有方法在此类问题上的表现有限，尤其是在真实世界图像上的表现不佳。为了应对这些挑战，该研究提出了一种简单有效的框架，用于将现有的图像描述模型适应IDC任务，并扩充IDC数据集。", "innovation": "该研究提出了BLIP2IDC，这是一种低成本的BLIP2适应IDC任务的方法，并证明其在真实世界IDC数据集上的表现显著优于双流方法。此外，该研究提出了合成增强策略，以无偏的方式提高IDC模型的表现，所提供的合成增强策略生成了高质量的数据，构建了一个名为Syned1的具有挑战性的新数据集，特别适合IDC任务。", "conclusion": "该研究提出的方法不仅有效解决了IDC技术面临的挑战，还为IDC任务的模型性能提升提供了新的途径，通过合成增强策略和适应IDC任务的框架，显著提高了IDC模型的表现，为该领域的发展做出了贡献。"}
{"llm_update_time": "20251015", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2502.01555", "html_url": "https://arxiv.org/abs/2502.01555", "title": "电子商务搜索中的查询品牌实体链接", "title_en": "Query Brand Entity Linking in E-Commerce Search", "authors": "Dong Liu,Sreyashi Nag", "background": "本文解决了电子商务搜索查询中的品牌实体链接问题。该任务面临的挑战包括查询极其简短（平均2.4个词）、缺乏自然语言结构，以及需要处理大量的独特品牌。", "innovation": "文章提出了一种两阶段的方法，结合命名实体识别和匹配，以及一个新颖的端到端解决方案，使用极端多分类。这两种方法通过离线基准测试和在线A/B测试的效果进行了验证。", "conclusion": "通过离线基准测试和在线A/B测试，验证了解决方案的有效性。"}
{"llm_update_time": "20251015", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2501.14050", "html_url": "https://arxiv.org/abs/2501.14050", "title": "GraphRAG 脱靶", "title_en": "GraphRAG under Fire", "authors": "Jiacheng Liang,Yuhui Wang,Changjiang Li,Rongyi Zhu,Tanqiu Jiang,Neil Gong,Ting Wang", "background": "GraphRAG通过将外部知识结构化为多尺度知识图谱，增强了检索增强生成（RAG）的效果，使语言模型能够集成广泛背景和详细信息。尽管GraphRAG已在多个领域展示了成功，但其安全影响尚未充分探讨。这项工作旨在弥补这一差距，特别关注GraphRAG在对抗投毒攻击中的脆弱性。", "innovation": "研究揭示了网络安全悖论：与传统RAG相比，GraphRAG基于图的索引和检索使得现有RAG攻击效果较差；然而，这些特征也创造了新的攻击面。为解决此问题，提出了GragPoison攻击，通过利用底层知识图谱中的共享关系，构建能够同时破坏多个查询的投毒文本。GragPoison采用了三个核心策略：关系注入、关系增强和叙述生成。", "conclusion": "跨多个不同数据集和模型的经验评估表明，GragPoison在效果（高达98%的成功率）和可扩展性（使用不到68%的投毒文本）方面明显优于现有攻击。此外，还探讨了潜在的防御措施及其局限性，指出了未来研究的潜在方向。"}
{"llm_update_time": "20251015", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2412.17534", "html_url": "https://arxiv.org/abs/2412.17534", "title": "CiteBART：学习生成本地引用的引文", "title_en": "CiteBART: Learning to Generate Citations for Local Citation Recommendation", "authors": "Ege Yiğit Çelik,Selma Tekir", "background": "文献引用推荐（LCR）任务是根据给定的上下文，建议一系列适用于引用位置的论文。随着生成式方法的发展，其效果超过了传统的预取和重排基线方法。本文在编码器-解码器架构中引入了针对引用的自训练方法，通过掩蔽作者和日期的引用标记来学习重建它们以满足LCR需求。研究了两种不同的预训练方案，一种仅基于局部上下文（CiteBART-Base），另一种扩展了局部上下文以包括被引用论文的标题和摘要（CiteBART-Global）。两种方法均在几个基准数据集上进行了实验。", "innovation": "本文提出了一种结合了编码器-解码器架构和自训练方法的模型——CiteBART，特别地，通过在局部上下文中掩蔽和预测引用标记，并扩展到包括被引用论文的标题和摘要以增强学习信号。此外，通过详尽的实验，包括消融研究、定性分析和幻觉分类统计，证明了CiteBART-Global在多个基准集上表现出优秀的性能和泛化能力。", "conclusion": "CiteBART-Global在Refseer和ArXiv等大基准集上表现优异，而在小型的FullTextPeerRead数据集上优势不明显。模型在前三个预测中的宏观幻觉率（MaHR）为4%，并且当真实值位于前k个预测列表中时，其他预测中的幻觉倾向显著降低。CiteBART-Global展示了广泛的泛化能力，证明其在跨数据集中的优越性。"}
{"llm_update_time": "20251015", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2501.13481", "html_url": "https://arxiv.org/abs/2501.13481", "title": "公平分配作业图的多项式时间算法", "title_en": "Polynomial-Time Algorithms for Fair Orientations of Chores", "authors": "Kevin Hsu,Valerie King", "background": "该研究关注图中作业的公平分配问题。每个顶点代表一个代理，每条边代表一个作业，如果与该代理对应的边不是作业的相邻边，则作业对代理没有边际效用。最近，Zhou等人（IJCAI, 2024）分析了包含货品和作业混合图的EFX（Envy-Free Up To Any Item）分配情况的复杂性，并猜想仅包含作业的图的EFX分配问题可能是NP完全问题。此外，相关工作已经证明，仅包含货品的图的EFX分配问题同样是NP完全的。因此，该文解决了这一猜想，设计了多项式时间算法，即使是包含自环的仅作业图也能够在存在的情况下找到EF1和EFX分配。此外还证明了对于多重图的EF1和EFX分配问题同样是NP完全问题。这项工作展示了货品和作业分配问题之间的惊人差异性。", "innovation": "该研究提供了多项式时间算法来找到仅包含作业的图的EF1和EFX分配，即使存在自环。同时证明了多重图的EF1和EFX分配问题同样是NP完全问题。这一工作揭示了货品和作业问题之间的显著差异性，解决了相关领域的猜想。", "conclusion": "研究表明，对于仅包含作业的图，可以使用多项式时间算法找到EF1和EFX分配，即使存在自环。此外，对于多重图的EF1和EFX分配问题同样是NP完全问题。这些结果提供了对公平分配问题的新见解，特别是在仅涉及作业的情况下。"}
{"llm_update_time": "20251015", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2502.02631", "html_url": "https://arxiv.org/abs/2502.02631", "title": "帕雷托Q：提高极低位宽LLM量化中的扩展规律", "title_en": "ParetoQ: Improving Scaling Laws in Extremely Low-bit LLM Quantization", "authors": "Zechun Liu,Changsheng Zhao,Hanxian Huang,Sijia Chen,Jing Zhang,Jiawei Zhao,Scott Roy,Lisa Jin,Yunyang Xiong,Yangyang Shi,Lin Xiao,Yuandong Tian,Bilge Soran,Raghuraman Krishnamoorthi,Tijmen Blankevoort,Vikas Chandra", "background": "量化模型的最佳位宽问题一直是持续争论的焦点。4位量化和1.58位量化都有支持者，但缺乏统一的框架使得结论不够稳固。之前的量化模型研究较少对比不同位宽的全面性能。", "innovation": "提出了帕雷托Q，这是首个统一框架，可以严谨地比较1位、1.58位、2位、3位和4位量化设置。帕雷托Q通过优化训练方案和改进量化函数，超越了特定位宽的以往方法。实验表明，3位、2位和1位量化在大小与精度权衡中保持了可比性能，在某些情况下甚至超过4位和二进制量化。", "conclusion": "相较于硬件限制，2位量化在减少内存占用和加速方面具有更大的前景。"}
{"llm_update_time": "20251015", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2505.12421", "html_url": "https://arxiv.org/abs/2505.12421", "title": "固定点可解释性", "title_en": "Fixed Point Explainability", "authors": "Emanuele La Malfa,Jon Vadillo,Marco Molinari,Michael Wooldridge", "background": "本文基于‘为何追溯’原则，引入了一种正式的固定点解释概念，通过递归应用来评估模型与其解释器之间相互作用的稳定性。固定的解释具有最小性、稳定性和忠实性等属性，揭示了模型隐藏的行为和解释的弱点。", "innovation": "定义了多种解释器（如基于特征和机制工具如稀疏自编码器）的收敛条件。并且报告了多个数据集和模型（包括LLM如Llama-3.3-70B）上的定量和定性结果，验证了固定点解释的有效性。", "conclusion": "本文通过固定点解释的概念，评估了模型与解释器之间的相互作用稳定性。通过实证分析，证明了固定点解释在复杂模型如LLM中的适用性和有效性。"}
{"llm_update_time": "20251015", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2502.14894", "html_url": "https://arxiv.org/abs/2502.14894", "title": "FOCUS on Contamination: A Geospatial Deep Learning Framework with a Noise-Aware Loss for Surface Water PFAS Prediction", "title_en": "FOCUS on Contamination: A Geospatial Deep Learning Framework with a Noise-Aware Loss for Surface Water PFAS Prediction", "authors": "Jowaria Khan,Alexa Friedman,Sydney Evans,Rachel Klein,Runzi Wang,Katherine E. Manz,Kaley Beins,David Q. Andrews,Elizabeth Bondi-Kelly", "background": "全氟和多氟烷基物质（PFAS）存在于不粘炊具等产品中，是持久性环境污染物，对人体健康有严重风险。准确地测绘PFAS污染对于指导有针对性的治理工作和保护公众及环境健康至关重要。然而，在大范围内进行检测仍然具有挑战性，因为测试成本高且模拟其扩散难度大。因此，需要一种能提供准确预测的方法来克服上述困难。", "innovation": "本工作提出了FOCUS（噪声感知损失的地理空间深度学习框架），用于预测大面积地表水中PFAS的污染情况。FOCUS通过结合水文流动数据、土地覆盖信息和已知PFAS源的距离，利用空间和环境上下文提高预测准确性，并使用了标签噪声感知的损失函数。此外，该框架还通过详尽的消融研究、鲁棒性分析和实际验证，以及与基线方法（如稀疏分割）和其他现有科学方法（如克里格法和污染物传输模拟）的比较，进行了评估。专家反馈验证了该框架在PFAS监测中的潜在可扩展性。", "conclusion": "我们的框架提高了大规模地表水中PFAS污染预测的准确性和效率，并显示出在PFAS监测中的可扩展潜力。对未来的研究，可以进一步探索和完善这个框架，并将其应用于其他类型的环境监测场景。"}
{"llm_update_time": "20251015", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2504.16946", "html_url": "https://arxiv.org/abs/2504.16946", "title": "MobileCity：大规模城市行为仿真高效框架", "title_en": "MobileCity: An Efficient Framework for Large-Scale Urban Behavior Simulation", "authors": "Xiaotong Ye,Nicolas Bougie,Toshihiko Yamasaki,Narimasa Watanabe", "background": "生成代理提供了模拟现实城市行为的有希望的能力。然而，现有的方法过度简化了交通选择，依赖于静态代理配置文件导致行为同质化，并且带有高昂的计算成本。这些问题限制了现有模拟平台的应用范围和效果。", "innovation": "我们提出了MobileCity，一种轻量级的仿真平台，用于具有高计算效率的现实城市移动建模。MobileCity通过引入多种交通模式的全面交通系统和从受访者问卷调查中收集数据来构建代理配置文件，解决上述限制。代理在预先生成的动作空间内进行行动选择，并使用局部模型为高效的代理记忆生成提供支持，以实现可扩展的模拟。通过对4,000个代理的详细微观和宏观层面评估，MobileCity展示了比基线模型更真实的城市行为而保持计算效率的特性，还进一步探索了预测移动模式和分析交通偏好人口趋势的实际应用。", "conclusion": "MobileCity在生成更真实的城市行为的同时，保持了高计算效率，并进一步探索了预测移动模式和分析交通偏好人口趋势的应用。有关的代码已公开发布。"}
{"llm_update_time": "20251015", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2505.11065", "html_url": "https://arxiv.org/abs/2505.11065", "title": "时间旅行是作弊：使用DeepFund实现实时基金投资基准测试", "title_en": "Time Travel is Cheating: Going Live with DeepFund for Real-Time Fund Investment Benchmarking", "authors": "Changlun Li,Yao Shi,Chen Wang,Qiqi Duan,Runke Ruan,Weijie Huang,Haonan Long,Lijun Huang,Nan Tang,Yuyu Luo", "background": "大型语言模型（LLMs）在金融任务上表现出色，包括财务报告总结、收益电话会议分析和资产分类，但在复杂基金投资的实际有效性尚待评估。现有的评估LLM驱动型交易策略的标准主要依赖历史回测，这导致LLMs可以“时光旅行”，利用训练语料库中嵌入的未来信息，从而产生信息泄露和过度乐观的性能估计。", "innovation": "本文介绍了DeepFund，这是一种实时基金基准工具，用于严格评估LLMs的实际市场条件，通过使用多代理架构直接与每个模型预训练截止后的实时股市数据进行连接，确保公平和无泄露的评估。通过在九家全球顶级机构的旗舰LLM上进行多投资维度的实证测试，揭示了显著的实际挑战，即使是先进的模型如DeepSeek-V3和Claude-3.7-Sonnet在DeepFund的实际交易环境中也面临净交易亏损，证明了LLMs在积极管理资金方面的局限性。", "conclusion": "本研究强调了LLMs在实际基金投资管理中的局限性，并使用DeepFund工具进行了严格且无时间旅行的实时市场测试。"}
{"llm_update_time": "20251015", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2505.12477", "html_url": "https://arxiv.org/abs/2505.12477", "title": "联合嵌入 vs 重构：潜在空间预测在自我监督学习中的不可证益处", "title_en": "Joint Embedding vs Reconstruction: Provable Benefits of Latent Space Prediction for Self Supervised Learning", "authors": "Hugues Van Assel,Mark Ibrahim,Tommaso Biancalani,Aviv Regev,Randall Balestriero", "background": "自监督学习(SSL)中的重建和联合嵌入已经发展成为两个主导范式。重建方法关注于从输入空间的另一种视图中恢复原始样本，而联合嵌入方法在于在潜在空间中对齐不同视图的表示。这两种方法各有优势，但实践者缺乏选择它们之间方法的明确指导。", "innovation": "通过采用闭式解法对这两种方法进行分析，研究揭示了每种范式的核心机制，并精确表征了数据增强过程如何影响学习表示。研究还表明，与监督学习不同，两种SSL范式都需要在样本数量增加时实现最小化对齐条件来达到最优效果，这对于无关特征尤为重要。该研究确定，在这些无关特征幅度较大的情况下，联合嵌入方法更具优势，因为它们施加的对齐条件比基于重构的方法更弱。", "conclusion": "研究不仅澄清了这两种范式之间的权衡，还证明了在真实世界具有挑战性的数据集上，联合嵌入方法的实证成功。"}
{"llm_update_time": "20251015", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2505.15058", "html_url": "https://arxiv.org/abs/2505.15058", "title": "AsynFusion：朝着异步潜空间一致性模型的解耦全身音频驱动化身发展", "title_en": "AsynFusion: Towards Asynchronous Latent Consistency Models for Decoupled Whole-Body Audio-Driven Avatars", "authors": "Tianbao Zhang,Jian Zhao,Yuer Li,Zheng Zhu,Ping Hu,Zhaoxin Fan,Wenjun Wu,Xuelong Li", "background": "全身音频驱动化身的姿态和表情生成是创建逼真数字人类和增强交互式虚拟代理能力的关键任务，广泛应用于虚拟现实、数字娱乐和远程通信。现有方法通常独立生成音频驱动的面部表情和手势，这导致面部和手势元素之间的不协调，使得动画不够自然和连贯。", "innovation": "本文提出了一种新颖的框架——AsynFusion，利用扩散变换器实现了表情和手势的和谐合成。该方法基于具有两个分支的DiT架构，并引入了协作同步模块以促进两种模态之间的双向特征交互，以及异步LCM抽样策略以减少计算开销并保持高质量输出。", "conclusion": "在广泛的实验中，AsynFusion在生成实时同步全身动画方面达到了最先进的性能，始终优于现有方法的定量和定性评估。"}
{"llm_update_time": "20251015", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2504.04821", "html_url": "https://arxiv.org/abs/2504.04821", "title": "一种针对图着色的定制化SAT求解器", "title_en": "A Customized SAT-based Solver for Graph Coloring", "authors": "Timo Brand,Daniel Faber,Stephan Held,Petra Mutzel", "background": "本研究构建了ZykovColor，一种基于SAT的新型算法，用于解决图着色问题。该算法立足于一种模仿Zykov树的编码方式，通过Hébrard和Katsirelos（2020）的方法，结合传播器强制执行传递性约束，加入搜索树剪枝的下界，并启用推断传播。该方法采用IPASIR-UP接口与CaDiCaL SAT求解器结合，进一步增强了算法功能，通过修改整合决策策略和使用顶点支配提示，以及增量自底向上的搜索策略。算法还包括更有效的团集计算和计算分数 chromatic 数的算法，以提高剪枝期间使用的下界。", "innovation": "ZykovColor有效地支持了以下创新特征：1）整合决策策略中顶点支配提示的修改；2）增量自底向上的搜索机制，允许利用先前计算的知识；3）其引入了更高效的团集计算和用于剪枝的分数 chromatic 数算法；4）结合了特定的定制化策略，能够改善搜索效率。这些创新使得ZykovColor在 DIMACS 和随机 Erdős-Rényi 图中表现出色，甚至在非常稀疏和高度密集的图中也优于现有的 SAT 方法。", "conclusion": "实验结果显示，ZykovColor 在 DIMACS 基准集及随机 Erdős-Rényi 图测试中优于其他现代图着色实现方法和 SAT 基础方法。通过进一步实验验证了新方法的有效性，并展示了 ZykovColor 在 Erdős-Rényi 图中的特定优化配置显著优于其他 SAT 方法。"}
{"llm_update_time": "20251015", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2505.16690", "html_url": "https://arxiv.org/abs/2505.16690", "title": "您的预训练LLM其实是个无监督置信校准器", "title_en": "Your Pre-trained LLM is Secretly an Unsupervised Confidence Calibrator", "authors": "Beier Luo,Shuoyuan Wang,Sharon Li,Hongxin Wei", "background": "对于大规模语言模型（PLMs）的后训练来说，将其预先训练的模型调整到与人类偏好和下游任务一致是至关重要的。然而，经过后训练的语言模型（PoLMs）常常表现出过度自信，即使在错误输出上也赋予高置信度，这可能会在关键应用中损害可靠性。现有的校准方法通常依赖于大量标记数据，但在实际应用中，下游任务的标签示例往往稀缺。", "innovation": "本文提出了一种名为DACA（Disagreement-Aware Confidence Alignment）的新型无监督方法，用于优化后训练中的参数（如温度$\tau$）。DACA通过只使用一致示例进行校准，从预测不一致的示例中有效地分离出影响，从而避免过大$\tau$导致的校准不足。理论分析表明，PLM在预测不一致实例时的置信度低估了PoLM的预测准确度，导致需要更大的$\tau$并产生不自信的预测。DACA通过选择性使用一致示例进行校准，改进了这种不匹配情况，提高了校准性能。", "conclusion": "实验证明了DACA的有效性，在GPT-4o等开源和API基的LLM上，平均ECE（校准误差）提高了高达15.08%。"}
{"llm_update_time": "20251015", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2502.16804", "html_url": "https://arxiv.org/abs/2502.16804", "title": "基于大型语言模型的多代理自主驾驶系统：近期进展综述", "title_en": "Multi-Agent Autonomous Driving Systems with Large Language Models: A Survey of Recent Advances", "authors": "Yaozu Wu,Dongyuan Li,Yankai Chen,Renhe Jiang,Henry Peng Zou,Wei-Chieh Huang,Yangning Li,Liancheng Fang,Zhen Wang,Philip S. Yu", "background": "自主驾驶系统（ADSs）正通过减少人为干预、提高运营效率和增强安全性来革新交通。大型语言模型（LLMs）被整合到ADSs中，以支持高级决策，通过它们强大的推理、指令遵循和沟通能力。然而，基于LLM的单代理ADSs面临三个主要挑战：有限的感知能力、不足的协作和高计算需求。通过利用语言驱动的通信和协调来增强代理间的协作，基于近期在多代理ADSs方面的进展，LLM可用于应对这些挑战。本文提供了一个关于自然语言处理与多代理ADSs新兴交叉领域的前沿综述。我们首先介绍相关的概念，然后根据不同的代理交互模式对现有基于LLM的方法进行分类。随后，我们讨论LLM代理与人类交互的场景。最后，我们总结了关键的应用、数据集和未来研究的挑战。", "innovation": "本文综述了基于语言模型的多代理ADSs的最新进展，通过利用语言驱动的沟通和协调来增强代理间的协作，解决了单代理ADSs面临的主要挑战：有限的感知能力、不足的协作和高计算需求。", "conclusion": "本文总结了基于语言模型的多代理ADSs的关键应用、数据集和面临的挑战，为未来的研究提供了支持。"}
{"llm_update_time": "20251015", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2505.16612", "html_url": "https://arxiv.org/abs/2505.16612", "title": "引导大语言模型进行机器翻译个性化", "title_en": "Steering Large Language Models for Machine Translation Personalization", "authors": "Daniel Scalena,Gabriele Sarti,Arianna Bisazza,Elisabetta Fersini,Malvina Nissim", "background": "大型语言模型简化了生成反映预定义风格限制的个性化翻译过程。然而，这些系统在处理隐含风格要求的示例集时仍然存在困难，例如由特定人类译者产生的文本。本研究旨在探索在少量示例可用时如何个性化自动生成的翻译，并特别关注文学翻译这一具有挑战性的领域。研究首先探讨了该任务的可行性以及风格信息如何在模型表示中编码，然后评估了各种提示策略和推理时干预措施，以引导模型生成偏向个性化风格的翻译。研究发现，对比自编码器（SAE）引导方法在风格调节和翻译质量方面表现出色，并且比提示方法具有更高的推理时间计算效率。进一步的分析表明，编码个性化属性的模型层在提示和SAE引导方法的影响下表现出相似的反应，表明潜在机制相似。", "innovation": "研究表明，对比自编码器（SAE）引导方法在风格调节和翻译质量方面表现出色，并且比提示方法具有更高的推理时间计算效率。进一步的分析表明，编码个性化属性的模型层在提示和SAE引导方法的影响下表现出相似的反应，表明潜在机制相似。", "conclusion": "研究展示了对比自编码器（SAE）引导方法具有出色的风格调节效果和翻译质量，且在推理时间计算效率方面优于提示方法，并且在对模型激活的影响上，注意编码个性化属性的层由提示和SAE引导方法影响的结果相似，这表明两者可能具有相似的机制。"}
{"llm_update_time": "20251015", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2505.18966", "html_url": "https://arxiv.org/abs/2505.18966", "title": "蛋白质设计与动态蛋白质词汇库", "title_en": "Protein Design with Dynamic Protein Vocabulary", "authors": "Nuowei Liu,Jiahao Kuang,Yanting Liu,Tao Ji,Changzhi Sun,Man Lan,Yuanbin Wu", "background": "蛋白质设计是生物技术中的基本挑战，旨在设计具有特定功能的新序列，而这些序列存在于可能的蛋白质序列空间中。近期，深度生成模型的进步使得从文本描述合成具有功能性的蛋白质成为可能，但是面临着结构合理性的挑战。先前基于自然蛋白质结构的经典方法激发了新的研究思路，即通过将自然蛋白质片段融入生成模型中来增强蛋白质的可折叠性。实验结果表明，即使随机地将片段融入设计也能提高可折叠性。", "innovation": "我们提出了一种名为ProDVa的创新蛋白质设计方法，该方法结合了文本编码器来描述功能性，蛋白质语言模型来设计蛋白质，以及片段编码器来根据文本功能描述动态检索蛋白质片段。实验证明，与最先进的模型相比，ProDVa使用不到0.04%的训练数据即可达到相似的功能对齐程度，同时显著设计了更多折叠良好的蛋白质，具体表现为pLDDT高于70的蛋白质比例提高了7.38%，PAE低于10的蛋白质比例提高了9.6%。", "conclusion": "我们的方法有效地设计了功能性对齐且结构合理的新蛋白质序列，展示了ProDVa在蛋白质设计方面具有显著优势。"}
{"llm_update_time": "20251015", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2505.19700", "html_url": "https://arxiv.org/abs/2505.19700", "title": "利用重要性抽样将对齐模块从大型语言模型中分离出来", "title_en": "Leveraging Importance Sampling to Detach Alignment Modules from Large Language Models", "authors": "Yi Liu,Dianqing Liu,Mingye Zhu,Junbo Guo,Yongdong Zhang,Zhendong Mao", "background": "随着各行各业广泛采用大型语言模型（LLMs），对高质量和可定制输出的需求增加。然而，传统的对齐方法往往需要重新训练大型预训练模型，这使得快速适应和优化LLMs以适应多种应用变得困难。", "innovation": "本文提出了一种名为Residual Alignment Model（RAM）的新型方法，将对齐过程形式化为重要性抽样的类型。这种方法将未对齐的上游模型作为提议分布，并将对齐过程作为基于自回归对齐模块的二次抽样，该模块作为重要性权重的估计器。这一设计使得对齐模块与目标对齐模型分离，提高了灵活性和扩展性。此外，作者还开发了一个具有迭代令牌级解码的重采样算法，以解决与之相比的方法在首令牌延迟问题上的常见缺陷。", "conclusion": "实验评价表明，该方法在两个领先的开源LLMs以及多种任务（如指令跟随、领域适应和偏好优化）中表现出色，且优于基础模型。"}
{"llm_update_time": "20251015", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2505.24069", "html_url": "https://arxiv.org/abs/2505.24069", "title": "大语言模型能够进行结构性推理吗？基于数据结构视角的评估", "title_en": "Can LLMs Reason Structurally? An Evaluation via the Lens of Data Structures", "authors": "Yu He,Yingxi Li,Colin White,Ellen Vitercik", "background": "随着大语言模型（LLMs）承担的任务越来越复杂，理解其算法推理能力变得至关重要。然而，现有的评估主要集中在不同的孤立任务上。本文提出了一种统一的诊断视角：结构性推理，即理解和操作顺序、层级和连接等关系。通过引入DSR-Bench基准测试，研究者旨在系统性地评估LLM的结构性推理能力，该基准测试利用可以解释的、算法上有意义的抽象层次结构。DSR-Bench涵盖了20种数据结构，35种操作，以及4,140个合成生成的问题实例，这些实例几乎没有污染。", "innovation": "提出了结构性推理这一统一的诊断视角，引入了DSR-Bench基准测试，这是首个通过标准数据结构系统评估LLM结构性推理能力的基准。DSR-Bench的设计包括分层结构，能够具体指出失败模式，并通过全自动评估确保客观和一致的评估。此外，还发现当前最先进的LLM在处理空间数据和自然语言场景时表现较差，无法推理它们自己生成的代码。", "conclusion": "DSR-Bench提供了结构性推理的原理性诊断工具，有助于揭示推理瓶颈，并指导开发更强大、更可靠的LLMs。"}
{"llm_update_time": "20251015", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.06907", "html_url": "https://arxiv.org/abs/2506.06907", "title": "带有结构引导随机偏微分方程的图上不确定性估计", "title_en": "Uncertainty Estimation on Graphs with Structure Informed Stochastic Partial Differential Equations", "authors": "Fred Xu,Thomas Markovich", "background": "图神经网络已经在各种网络建模任务中取得了令人印象深刻的结果，但在估计图上的不确定性方面仍然存在困难，尤其是在分布变化的情况下。与传统不确定性估计不同，基于图的不确定性必须同时考虑图结构和标签分布中的随机性，这增加了复杂性。现有方法在低和高标签信息量的图上的不确定性估计方面存在不足。因此，需要新的方法来准确评估不同分布下图的不确定性。", "innovation": "本文将随机偏微分方程（SPDE）驱动的Matern高斯过程进化方法与图神经网络（GNN）的注意力机制进行类比，提出了一种新的消息传递方案。该方法结合了空间和时间中的不确定性，可以通过控制协方差核平滑度来显式控制不确定性估计，从而提高不同类型图上的不确定性估计精度。", "conclusion": "本文通过在不同标签信息量的图数据集上的广泛实验，证明了该方法在离分布外（OOD）检测方面的有效性和优越性，比现有方法更为可靠。"}
{"llm_update_time": "20251015", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.01551", "html_url": "https://arxiv.org/abs/2506.01551", "title": "EvolveNav:通过自我提升的嵌入式推理增强基于LLM的视语言导航", "title_en": "EvolveNav: Empowering LLM-Based Vision-Language Navigation via Self-Improving Embodied Reasoning", "authors": "Bingqian Lin,Yunshuang Nie,Khun Loun Zai,Ziming Wei,Mingfei Han,Rongtao Xu,Minzhe Niu,Jianhua Han,Hanwang Zhang,Liang Lin,Bokui Chen,Cewu Lu,Xiaodan Liang", "background": "最近的研究表明，可以训练开源的大规模语言模型（LLMs）以增强其推理能力，从而提高视觉语言导航（VLN）的性能。然而，这些方法主要采用简单的输入-输出映射范式，导致模型学习复杂且导航决策难以解释。为了解决这些问题，本文背景在于探索更有效的学习方法，如Chain-of-Thought（CoT）训练，来提高决策的准确性和解释性。", "innovation": "本文提出了一种新颖的自我提升嵌入式推理框架EvolveNav。它通过两阶段训练过程改进基于LLM的VLN。首先是正式的CoT监督微调，激活模型的推理能力和提升推理速度；其次是自我反思的后续训练，通过模型自身推理输出作为自我增强的CoT标签来提高监督多样性。此外，设计了一个自我反思的辅助任务来鼓励模型学习正确的推理模式。", "conclusion": "实验结果表明，EvolveNav在R2R、REVERIE、CVDN和SOON等多种流行基准上优于之前的基于LLM的VLN方法，显示出在特定任务和跨任务训练中的持续优越性。"}
{"llm_update_time": "20251015", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.10412", "html_url": "https://arxiv.org/abs/2506.10412", "title": "Time-IMM：不规则多模态多元时间序列的数据集和基准", "title_en": "Time-IMM: A Dataset and Benchmark for Irregular Multimodal Multivariate Time Series", "authors": "Ching Chang,Jeehyun Hwang,Yidan Shi,Haixin Wang,Wen-Chih Peng,Tien-Fu Chen,Wei Wang", "background": "在医疗保健、气候建模和金融等领域中的时间序列数据通常是不规则的、多模态的、凌乱的，采样率各异、模态不一致且存在普遍的缺失值。现有的基准数据集通常假设干净的、规则采样的、单一模态的数据，这与实际应用之间存在很大的差距。", "innovation": "提出了一个名为Time-IMM的数据集，专门用于捕捉多模态多变量时间序列中的原因驱动型不规则性。此外，还引入了IMM-TSF基准库，用于不规则多模态时间序列的预测，该库包含支持时间戳到文本融合模块和多模态融合模块的专业化融合模块，并支持意识最新的平均和基于注意力的集成策略。", "conclusion": "实证结果显示，明确建模不规则时间序列中的多模态性能够显著提高预测性能。Time-IMM和IMM-TSF为实际条件下的时间序列分析提供了基础，数据集和基准库目前可以公开访问。"}
{"llm_update_time": "20251015", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.21857", "html_url": "https://arxiv.org/abs/2506.21857", "title": "SPADE：使用数据专家混合实现空间转录组学与病理学对齐的具有表现力的潜在空间", "title_en": "SPADE: Spatial Transcriptomics and Pathology Alignment Using a Mixture of Data Experts for an Expressive Latent Space", "authors": "Ekaterina Redekop,Mara Pleasure,Zichen Wang,Kimberly Flores,Anthony Sisk,William Speier,Corey W. Arnold", "background": "随着数字病理学的快速发展以及自监督深度学习技术的进步，各种病理任务的基础模型得以开发，尽管多模态方法整合了多种数据源，但仍然缺少将整个切片图像（WSI）与空间转录组学（ST）数据全面集成的方法，这对捕捉H&E染色之外的关键分子异质性至关重要。", "innovation": "介绍了一种新的基础模型SPADE，它通过一个统一的框架将病理学与ST数据结合，利用迁移算法中的数据专家混合技术，将对比学习用于多阶段的成像特征空间聚类，创建出共注册WSI片段和基因表达谱的表示。在广泛的数据集HEST-1k上预训练，SPADE显示出了明显优于基准模型的少量样本表现，说明整合形态学和分子信息进入一个潜在空间的好处。", "conclusion": "SPADE作为一个基础模型，成功地将WSI与ST数据整合，改进了图像表示的学习，并在多个任务中展示了优越的性能，证明了将形态学与分子信息整合的重要性。代码和预训练权重可在指定的链接中获得。"}
{"llm_update_time": "20251015", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.07961", "html_url": "https://arxiv.org/abs/2506.07961", "title": "BridgeVLA：视觉语言模型中输入输出对齐以实现高效三维操作学习", "title_en": "BridgeVLA: Input-Output Alignment for Efficient 3D Manipulation Learning with Vision-Language Models", "authors": "Peiyan Li,Yixiang Chen,Hongtao Wu,Xiao Ma,Xiangnan Wu,Yan Huang,Liang Wang,Tao Kong,Tieniu Tan", "background": "利用预训练的视觉-语言模型（VLMs）构建视觉-语言-动作（VLA）模型已成为机器人操作学习的有效方法。然而，大多数方法并未将3D信号纳入VLMs进行动作预测，这限制了在三维数据中固有的空间结构的充分利用，导致样本效率低下。因此，如何结合3D信号提高3D操作学习的样本效率成为研究的关键问题。BridgeVLA模型通过将3D输入投影到多个2D图像，并利用2D热图进行动作预测，有效解决了这一问题。", "innovation": "BridgeVLA模型引入了一种新颖的三维操作学习方法，它通过（1）将3D输入投影为多个2D图像，确保输入与VLM骨干网络对齐；（2）使用2D热图进行动作预测，统一输入和输出空间在一致的2D图像空间内。此外，该模型提出了一种可扩展的预训练方法，使VLM骨干网络在下游策略学习之前具备预测2D热图的能力。实验结果显示，BridgeVLA在三维操作学习上表现出高效和有效的性能，在多个仿真实验基准中均超越了最先进的基线方法。在实际机器人实验中，BridgeVLA表现出色，其样本效率也显著提高，成功率高达96.8%。", "conclusion": "BridgeVLA通过将3D输入与2D图像对齐以及利用2D热图进行动作预测，显著提升了三维操作学习的样本效率。该模型在多个仿真和真实机器人实验中表现出色，特别是在处理视觉干扰和未见过的任务指令时表现出强大的泛化能力。总体而言，BridgeVLA提供了有效和高效的三维机器人操作学习解决方案，极大地提高了样本效率和泛化性能。"}
{"llm_update_time": "20251015", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.21582", "html_url": "https://arxiv.org/abs/2506.21582", "title": "VIDEE: 以智能代理为辅助的文本分析的视觉互动分解、执行和评估", "title_en": "VIDEE: Visual and Interactive Decomposition, Execution, and Evaluation of Text Analytics with Intelligent Agents", "authors": "Sam Yu-Te Lee,Chenyang Ji,Shicheng Wen,Lifu Huang,Dongyu Liu,Kwan-Liu Ma", "background": "传统的文本分析需要具备自然语言处理（NLP）或文本分析专业知识，这对于初级分析师而言构成了一定的门槛。近年来，大型语言模型（LLMs）的发展改变了NLP的格局，使其变得更加易于使用和自动化，特别是在主题检测、摘要生成、信息抽取等任务上。本文基于此背景介绍了VIDEE系统，旨在帮助初级数据分析人员通过智能代理进行高级文本分析。", "innovation": "VIDEE系统提出了一种结合人类和智能代理合作的工作流程，这一过程包括三个阶段：（1）分解阶段，通过带有人工反馈的蒙特卡洛树搜索算法支持生成性推理；（2）执行阶段，自动生成可执行的文本分析流水线；（3）评估阶段，集成基于LLM的评估和可视化，支持用户验证执行结果。此外，还通过两项定量实验和用户研究验证了VIDEE的有效性和用户的使用行为，揭示了该系统对于非专家用户的实际适用性，并为未来智能文本分析系统的改进提供了设计建议。", "conclusion": "用户研究结果表明，VIDEE系统在非专家用户中具有良好的易用性，并揭示了不同经验水平用户的使用模式。研究发现为人类与智能代理的协作设计提供了有价值的设计启示，验证了VIDEE对于非专家用户的实际用途，并为智能文本分析系统的未来改进提供了指导。"}
{"llm_update_time": "20251015", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.00665", "html_url": "https://arxiv.org/abs/2507.00665", "title": "SAFER: 使用稀疏自编码器探究奖励模型中的安全性", "title_en": "SAFER: Probing Safety in Reward Models with Sparse Autoencoder", "authors": "Sihang Li,Wei Shi,Ziyuan Xie,Tao Liang,Guojun Ma,Xiang Wang", "background": "在使用强化学习从人类反馈(RLHF)对大型语言模型(LLMs)进行价值观对齐的过程中，核心的奖励模型仍然不透明，缺乏可解释性。本文旨在解决这一问题，并提出了一种新的框架SAFER，用于通过机械分析来解释和改进奖励模型。SAFER利用稀疏自编码器从奖励模型的激活中发现可被人类理解的特征，从而理解与安全相关的决策过程。", "innovation": "提出了稀疏自编码器增强奖励模型(SAFER)框架，该框架通过机械分析来揭示和改善奖励模型的可解释性，具体通过稀疏自编码器发现可解释的特征，并量化每个特征的重要性，从而设计针对性的数据污染和去噪策略，实现安全对齐的精确提升或降级，而不影响通用聊天性能。", "conclusion": "SAFER方法为高风险的LLM对齐任务提供了解释、审查和改进奖励模型的手段。该研究的代码可在指定的网址找到，并指出该论文讨论了与大语言模型安全性相关的话题，可能包括风险或不安全结果的讨论或示例。"}
{"llm_update_time": "20251015", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.00546", "html_url": "https://arxiv.org/abs/2507.00546", "title": "通过表示学习在纳米光子学中的逆设计", "title_en": "Inverse Design in Nanophotonics via Representation Learning", "authors": "Reza Marzban,Ali Adibi,Raphael Pestourie", "background": "逆设计在纳米光子学中的计算发现结构实现目标电磁响应已成为近期光学进步的关键工具。传统的直觉驱动或迭代优化方法在面对高维、非凸的设计空间和电磁模拟的巨大计算需求时表现出局限性。最近，机器学习（ML）被证明能够有效地解决这些瓶颈问题。", "innovation": "这篇综述通过表示学习的视角重新审视了ML增强的逆设计方法，将这些方法分为输出侧和输入侧两种类别。输出侧方法利用机器学习在解空间中学习表示来创建具有可微性的求解器以加速优化。而输入侧技术则利用机器学习学习可行设备几何的紧凑、潜空间表示，通过生成模型实现高效的全局探索。每种策略都包含了独特的需求差异、泛化能力和新颖设计发现的潜力。结合基于物理的优化和数据驱动的表示的混合框架能够帮助跳出局部极值，提升可扩展性，并促进知识转移。", "conclusion": "本文最后强调了开放挑战和机遇，强调管理和控制复杂性，几何独立表示的构建，同时整合制造约束并推动多物理场协同设计的进步。"}
{"llm_update_time": "20251015", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.01028", "html_url": "https://arxiv.org/abs/2507.01028", "title": "非对比自监督学习的双重视角", "title_en": "Dual Perspectives on Non-Contrastive Self-Supervised Learning", "authors": "Jean Ponce(ENS-PSL, NYU),Basile Terver(FAIR, WILLOW),Martial Hebert(CMU),Michael Arbel(Thoth)", "background": "在非对比方法的自监督学习中，通常使用'停止梯度'和'指数滑动平均'迭代步骤来避免表示坍塌，这些步骤在实际的下游应用中表现优秀。", "innovation": "本文从优化和动力系统双重视角研究这些步骤，证明了它们虽然不优化原始目标或其他光滑函数，但确实避免了坍塌。同时，当应用矩阵线性模型时，理论证明停止梯度和指数滑动平均没有坍塌。此外，本文使用动力系统视角在线性模型中，确定了这两个步骤的动力系统平衡点，并表明它们通常在参数空间中是渐近稳定的。", "conclusion": "理论发现通过使用真实和合成数据的实验得到了证实。"}
{"llm_update_time": "20251015", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.04295", "html_url": "https://arxiv.org/abs/2507.04295", "title": "LearnLens：利用LLM实现个性化、课程导向反馈并包含教育者参与的系统", "title_en": "LearnLens: LLM-Enabled Personalised, Curriculum-Grounded Feedback with Educators in the Loop", "authors": "Runcong Zhao,Artem Bobrov,Jiazheng Li,Cesare Aloisi,Yulan He", "background": "有效的反馈对于学生的学业非常重要，但对教师来说却非常耗时。现有系统在生成个性化、课程导向的反馈方面存在诸多挑战，这限制了其广泛应用和推广。因此，迫切需要一种能够解决这些挑战的有效解决方案，以提高教学质量和学习效率。", "innovation": "我们介绍了LearnLens，这是一种模块化的基于LLM的系统，能够生成个性化和课程导向的反馈，特别是在科学教育中。该系统包含三个关键组件：（1）一种错误感知评估模块，能够捕捉细微的推理错误；（2）一种基于课程的生成模块，使用结构化的、与主题链接的记忆链而非传统的基于相似性的检索方式，提高了相关性并减少了噪音；（3）一种教育者介入的界面，便于定制和监督。LearnLens通过结合上述功能，解决现有系统的关键挑战，提供可扩展的高质量反馈，从而同时增强教师和学生的能力。", "conclusion": "LearnLens作为一种创新的解决方案，通过利用LLM和一系列优化功能，提供了高质量且个性化的课程导向反馈，特别适用于科学教育场景，能够有效减轻教师的工作负担，丰富了学生的课堂学习体验。"}
{"llm_update_time": "20251015", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2505.21391", "html_url": "https://arxiv.org/abs/2505.21391", "title": "有限样本分析任意特征下的线性时差学习", "title_en": "Finite Sample Analysis of Linear Temporal Difference Learning with Arbitrary Features", "authors": "Zixuan Xie,Xinyu Liu,Rohan Chandra,Shangtong Zhang", "background": "线性 TD($\boldsymbol{\theta}$) 是最基础的强化学习评估算法之一。以往的研究通常假设特征线性无关来确定收敛速率，但在实际应用中，这样的假设往往无法满足。因此，该研究致力于在任意特征条件下不修改算法本身或增加额外假设的情况下，首次建立了线性 TD($\boldsymbol{\theta}$) 的 $L^2$ 收敛速率，适用于折扣率和平均回报两种场景。由于任意特征可能导致解的非唯一性，研究特意开发了一个新的随机逼近结果，该结果定义了以解集作为收敛目标，而不是单一解点。", "innovation": "该研究在不修改算法或增加额外假设的情况下，首次为线性 TD($\boldsymbol{\theta}$) 在任意特征条件下的 $L^2$ 收敛速率进行了分析，适用于折扣率和平均回报两种场景。此外，为了解决任意特征导致的解不一定唯一的问题，研究还提出了一个新的随机逼近结果，使得算法能够收敛到解集而不是单一解点。", "conclusion": "该研究解决了线性 TD($\boldsymbol{\theta}$) 在实际应用中面临的特征线性无关假设问题，提出了新的随机逼近方法，有效地处理了解的非唯一性问题，从而在有限样本条件下提供了更广义和实用的收敛分析结果。"}
{"llm_update_time": "20251015", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.08704", "html_url": "https://arxiv.org/abs/2507.08704", "title": "知识融合通过双向信息聚合", "title_en": "Knowledge Fusion via Bidirectional Information Aggregation", "authors": "Songlin Zhai,Guilin Qi,Yue Wang,Yuan Meng", "background": "知识图谱(KGs)是语义网的核心，提供了现实世界的实体及其关系的最新表示。然而，大型语言模型(LLMs)在预训练后基本保持静态，这导致其内部知识变得过时，限制了它们在时间敏感的网络应用中的实用性。现有方法通常通过参数侵入式微调来增强LLMs与KGs的结合，从而存在灾难性遗忘的风险，并且往往损害了LLMs的一般能力。此外，这些静态集成框架无法跟上现实世界KGs的持续演变，阻碍了它们在动态网络环境中的部署。", "innovation": "我们引入了KGA（知识图谱指导注意力），这是一种新颖的框架，它在推断时动态集成外部KGs到LLMs中，而不需要任何参数修改。灵感源自神经科学研究，通过创新地引入两种协同路径——自底向上知识融合路径和自顶向下注意力指导路径，我们重新设计了自注意力模块。自底向上的路径通过输入驱动的KG融合将外部知识动态地集成到输入表示中，这类似于人类大脑中的刺激驱动注意力过程。而自顶向下的路径则旨在通过目标导向的验证过程评估每条三元组的上下文相关性，从而抑制与任务无关的信号并放大与知识相关的变化。", "conclusion": "这两种路径的协同结合支持了实时知识融合。在四个基准上的广泛实验验证了KGA的强大融合性能和效率。"}
{"llm_update_time": "20251015", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.10348", "html_url": "https://arxiv.org/abs/2507.10348", "title": "Feature Distillation是模型异质联邦学习的更好选择", "title_en": "Feature Distillation is the Better Choice for Model-Heterogeneous Federated Learning", "authors": "Yichen Li,Xiuying Wang,Wenchao Xu,Haozhao Wang,Yining Qi,Jiahua Dong,Ruixuan Li", "background": "模型异质联邦学习（Hetero-FL）因其能够聚合来自异质模型的知识且保持本地数据私密而引起广泛关注。现有的方法主要关注于通用的方法——逻辑斯蒂归一化（logit）指导下的模型蒸馏，虽然这种方法是模型无相关的，但它未能补偿由于异质模型带来的知识偏差。简单地将Hetero-FL与模型蒸馏结合往往不能产生预期的结果，并且可能会导致训练过程不稳定", "innovation": "本文提议了一个稳定且高效的基于特征的集成联邦知识蒸馏方案，名为FedFD。该方法通过正交投影来对齐特征信息，从而更好地整合来自异质模型的知识。具体来说，它提出了一种新的基于特征的联邦模型蒸馏范式。全球模型需要在服务器端为每个客户端模型架构维护一个投影层，以独立对齐特征。利用正交技术重构投影层，以减轻异质模型带来的知识偏差，从而最大化蒸馏的知识", "conclusion": "广泛的实验表明，FedFD在模型异质性联邦学习中表现优于现有最先进的方法"}
{"llm_update_time": "20251015", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.19842", "html_url": "https://arxiv.org/abs/2507.19842", "title": "公共部门基于知识的合作业务流程设计方法", "title_en": "A Cooperative Approach for Knowledge-based Business Process Design in a Public Authority", "authors": "Mohammad Azarijafari,Luisa Mich,Michele Missikoff,Oleg Missikoff", "background": "当前，企业正经历着深刻的数字化转型，为了保持竞争力，企业需要适应数字解决方案，重塑组织结构和运营模式。这一转变对于中小企业同样重要。关键的创新领域是采用面向过程的生产模型。", "innovation": "该论文提出了一种基于知识的方法，旨在支持业务专家设计业务流程，不需要事先具备知识工程的知识。该方法引导设计师通过一个结构化的步骤序列，生成目标流程的图示工作流。知识库的构建从简单的基于文本的知识制品开始，逐步发展到更结构化、形式化的表示。该方法旨在允许所有参与业务流程设计的相关方采用共享的方法论。", "conclusion": "该方法为所有参与业务流程设计的参与者提供了一种共享的方法论，从而支持公共部门的基于知识的业务流程设计。"}
{"llm_update_time": "20251015", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.16880", "html_url": "https://arxiv.org/abs/2507.16880", "title": "Finding Dori: 在文本到图像扩散模型中，记忆并非局部化", "title_en": "Finding Dori: Memorization in Text-to-Image Diffusion Models Is Not Local", "authors": "Antoni Kowalczuk,Dominik Hintersdorf,Lukas Struppek,Kristian Kersting,Adam Dziedzic,Franziska Boenisch", "background": "文本到图像扩散模型（DMs）在图像生成方面取得了显著成功，但由于潜在的数据隐私和知识产权问题，人们对其持保留态度。Recent mitigation efforts have focused on identifying and pruning weights responsible for triggering verbatim training data replication，基于这样的假设，即记忆可以被局部化处理。然而，研究提出了挑战，指出即使在这样处理之后，对已缓解提示的文本嵌入进行小的调整也可能重新触发数据复制，揭示了此类防御的脆弱性。", "innovation": "本文对隐私保留提出了新的挑战性分析，表明记忆实际上并不局限于局部：(1) 记忆图像的复制触发器在文本嵌入空间中分布广泛；(2) 生成相同复制图像的嵌入会产生不同的模型激活；(3) 不同的修剪方法对同一图像识别出不一致的记忆相关权重集合。此外，研究表明，通过对抗性微调绕过局部性假设能够实现更稳健的缓解。", "conclusion": "这些发现为理解文本到图像DMs中的记忆本质提供了新的见解，并为开发可靠的DM记忆缓解措施提供了指导。"}
{"llm_update_time": "20251015", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.02348", "html_url": "https://arxiv.org/abs/2508.02348", "title": "基于摄像头提取道路布局的毫米波雷达非视距行人定位在T形路口的应用", "title_en": "mmWave Radar-Based Non-Line-of-Sight Pedestrian Localization at T-Junctions Utilizing Road Layout Extraction via Camera", "authors": "Byeonggyu Park,Hee-Yeun Kim,Byonghyok Choi,Hansang Cho,Byungkwan Kim,Soomok Lee,Mingu Jeon,Seong-Woo Kim", "background": "在城市环境中，非视距（NLoS）区域行人的定位是自动驾驶系统面临的重大挑战，毫米波雷达虽然具备检测能力，但2D雷达点云数据受到多路径反射的影响，难以进行准确的三维空间推理。相比之下，摄像头虽然提供高分辨率视觉信息，但缺乏深度感知，并不能直接观测到NLoS区域的物体。因此，本文提出了一种新的框架，通过从摄像头中提取的道路布局来解释雷达2D点云数据进行NLoS行人的定位。", "innovation": "该方法利用摄像头提供的视觉信息来解释2D雷达点云数据，并进行空间场景重建。通过安装在真实车辆上的雷达-摄像头系统进行了实验验证，使用在户外NLoS驾驶环境中收集的数据集来评估定位性能，展示了该方法的实用性和有效性。", "conclusion": "该研究提出了一种新的基于摄像头提取道路布局的毫米波雷达非视距行人定位方法，并通过实际应用验证了其有效性，为自动驾驶系统在复杂环境中的行人定位提供了新的解决方案。"}
{"llm_update_time": "20251015", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.01427", "html_url": "https://arxiv.org/abs/2508.01427", "title": "学习多域表示以实现稳健的在线手写验证", "title_en": "Capturing More: Learning Multi-Domain Representations for Robust Online Handwriting Verification", "authors": "Peirong Zhang,Kai Ding,Lianwen Jin", "background": "近年来，多域表示学习在在线手写验证（OHV）中展现出巨大潜力。传统方法大多仅利用时间域特征进行验证，忽略了频率域特征对鉴别手写真伪的重要性。本文旨在探索结合时间域和频率域的多域表示学习方法，以提升在线手写验证的准确性和鲁棒性。", "innovation": "提出了一种时空频协同模型——SPECTRUM。该模型包含三个核心组件：1）一个多尺度交互器，通过双模序列交互和多尺度聚合精细结合时间域和频率域特征；2）一个自门融合模块，动态集成全局时间和频率特征；3）一个多域基于距离的验证器，利用时间和频率表示提高真伪手写的鉴别能力，超越了传统的仅时间域的方法。实验结果证明SPECTRUM在现有的OHV方法中表现优越，强调了时间-频率多域学习的有效性。此外，本文还揭示了将多种手写生物特征结合起来可以显著增强手写表示的区分能力，促进验证。", "conclusion": "这项研究不仅验证了多域学习在OHV中的有效性，还为未来在特征和生物特征领域中的多域方法研究打开了新的方向。"}
{"llm_update_time": "20251015", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.04012", "html_url": "https://arxiv.org/abs/2508.04012", "title": "EMSEdit: 高效多步元学习驱动的模型编辑", "title_en": "EMSEdit: Efficient Multi-Step Meta-Learning-based Model Editing", "authors": "Xiaopeng Li,Shasha Li,Xi Wang,Shezheng Song,Bin Ji,Shangwen Wang,Jun Ma,Xiaodong Liu,Mina Liu,Jie Yu", "background": "大型语言模型（LLMs）驱动了众多AI应用，但更新其知识成本高昂。模型编辑通过目标参数修改提供了一种轻量级替代方案，而基于元学习的模型编辑（MLME）展示出很强的效果和效率。然而，MLME 在数据量不足的情况下表现不佳，并且由于使用KL散度，训练成本高。", "innovation": "我们提出了EMSEdit，它利用多步反向传播（MSBP）来有效捕捉编辑样本中的梯度-激活映射模式，每样本进行多步编辑以在数据有限的情况下提高编辑性能，并引入了基于范数的正则化以保存未修改的知识并提高训练效率。实验表明，EMSEdit在序列编辑和批处理编辑中均优于最先进的方法。此外，MSBP可以无缝集成到现有方法中以获得额外的性能提升。进一步的实验展示了EMSEdit在处理复杂编辑任务中的稳健性，并通过消融研究验证了每个设计组件的贡献。", "conclusion": "在两个数据集和三种LLM上的实验表明，EMSEdit在序列编辑和批处理编辑中一贯优于最先进的方法。此外，多步反向传播（MSBP）可以无缝地集成到现有的方法中，进一步的实验表明EMSEdit在处理复杂的编辑任务中的稳健性，而消融研究验证了每个设计组件的贡献。我们的代码可以在指定的URL找到。"}
{"llm_update_time": "20251015", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.02753", "html_url": "https://arxiv.org/abs/2508.02753", "title": "DMSC: 动态多尺度协调框架在时间序列预测中的应用", "title_en": "DMSC: Dynamic Multi-Scale Coordination Framework for Time Series Forecasting", "authors": "Haonan Yang,Jianchao Tang,Zhuo Li,Long Lan", "background": "时间序列预测（TSF）在建模不同尺度下的复杂时间依赖性方面面临持续的挑战。尽管最近的进展利用了不同的分解操作和基于CNN、MLP或Transformer的新型架构，现有方法仍然受到固定分解策略、依赖性建模碎片化和融合机制不够灵活的限制，这些限制限制了它们建模复杂时间依赖性的能力。", "innovation": "为了解决上述提到的三个问题，本文提出了一种新颖的动态多尺度协调框架（DMSC），并包括多尺度切块分解块（EMPD）、三重交互块（TIB）和自适应尺度路由MoE块（ASR-MoE）。EMPD能够动态地对序列进行层次化的切块，而无需预先定义的尺度限制。TIB用于在同一层分解表示中联合建模内部切块、外部切块和跨变量依赖性。EMPD和TIB被结合成了一种多层逐步级联架构内的层，早期层的粗糙表示通过门控路径适应性地引导后续层的细粒度特征提取。ASR-MoE则通过利用具有时间感知权重的专业全局和局部专家动态融合多尺度预测。", "conclusion": "在十三个真实世界的基准上的综合实验结果表明，DMSC能够保持最先进的（SOTA）性能并具有优越的计算效率，适用于TSF任务。相关代码可以在给定的链接处获得。"}
{"llm_update_time": "20251015", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.13423", "html_url": "https://arxiv.org/abs/2508.13423", "title": "增强基于LLM的自主系统在职业推荐中的对话推荐性能 - AdaptJobRec", "title_en": "AdaptJobRec: Enhancing Conversational Career Recommendation through an LLM-Powered Agentic System", "authors": "Qixin Wang,Dawei Wang,Kun Chen,Yaowei Hu,Puneet Girdhar,Ruoteng Wang,Aadesh Gupta,Chaitanya Devella,Wenlai Guo,Shangwen Huang,Bachir Aoun,Greg Hayworth,Han Li,Xintao Wu", "background": "推荐系统的发展从最初的单列表推荐演变为提供各种专题服务。经典的对话推荐系统（CRS）经历了从基础的基于检索的生成到具有高级推理和自我修正能力的代理系统。然而，代理系统伴随着显著的响应延迟，这是许多对话推荐系统长期存在的挑战。为了平衡处理复杂查询和减小延迟之间的关系，该文提出了一种名为AdaptJobRec的对话职位推荐系统，它利用自主代理集成个性化推荐算法工具。", "innovation": "AdaptJobRec是一种利用自主代理集成个性化推荐算法工具的对话职位推荐系统。该系统通过用户查询复杂度识别机制来减少响应延迟。对于简单的查询，代理直接选择合适的工具进行快速响应；对于复杂的查询，代理使用记忆处理模块过滤聊天历史记录，提取相关的内容，然后将结果传递给智能任务分解规划器，并最终使用个性化推荐工具执行任务。实验表明，AdaptJobRec相比竞争基线可以将平均响应延迟降低高达53.3%，同时显著提高了推荐准确性。", "conclusion": "AdaptJobRec有效地解决了代理系统响应延迟的问题，通过利用自主代理集成个性化推荐算法工具，并结合复杂的查询处理机制，实现了高效准确的职业推荐。该系统的应用展示了在沃尔玛真实的职位推荐场景中的实际效果。"}
{"llm_update_time": "20251015", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.12519", "html_url": "https://arxiv.org/abs/2508.12519", "title": "Sliced Optimal Transport的介绍", "title_en": "An Introduction to Sliced Optimal Transport", "authors": "Khai Nguyen", "background": "Sliced Optimal Transport（SOT）是当前快速发展的最优运输（OT）分支，它利用了一维最优运输问题的可解性。通过结合最优运输、积分几何学和计算统计学的工具，SOT 能快速高效地计算概率测度的距离、重心和核，同时保留丰富的几何结构。", "innovation": "文章提供了SOT的全面综述，涵盖了其数学基础、方法论进步、计算方法和应用。文章讨论了一维最优运输概念、积分几何学工具（如Radon变换）在投影测度中的作用，以及估计切片距离的统计技术。文章进一步探讨了最近的方法论进展，包括非线性投影、改进的蒙特卡洛近似、一维最优运输的统计估计技术、加权切片技术和运输计划估计方法。此外，文章还考察了诸如最小切片Wasserstein估计、重心、梯度流、核构造和嵌入等变分问题及其在不平衡、部分、多边际和Gromov-Wasserstein设置中的扩展情况。", "conclusion": "这些应用涵盖了机器学习、统计学、计算机图形学和计算机视觉，突显了SOT作为一种实用计算工具的多功能性。这项工作将吸引从事机器学习、数据科学和计算领域研究者和实践者的兴趣，他们正在寻求替代经典OT的高效替代方案。"}
{"llm_update_time": "20251015", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.14094", "html_url": "https://arxiv.org/abs/2508.14094", "title": "需要困难实例：在标注预算下最大化GRPO训练后效果", "title_en": "Hard Examples Are All You Need: Maximizing GRPO Post-Training Under Annotation Budgets", "authors": "Benjamin Pikus,Pratyush Ranjan Tiwari,Burton Ye", "background": "收集高质量的训练示例进行语言模型微调成本高昂，实际预算限制了可获取的数据量。研究发现示例难度影响GRPO训练效果，不同选择策略（简单、中等、困难、随机）对多个模型和推理任务的比较结果表明，使用基础模型最容易出错的10%最困难示例进行训练，可带来高达47%的性能提升，而简单示例仅带来3-15%的微小改进。这归因于GRPO需要结果变异性以生成学习信号；困难示例在整个训练过程中保持混合的成功/失败结果，而简单示例则迅速收敛到一致的成功，这消除了学习机会。", "innovation": "本研究通过对比不同难度级别的示例选择策略，展示了在有限的标注预算下，利用困难示例进行GRPO训练后可获得显著性能提升的独特方法。研究表明，当受到预算限制时，优先收集并标注基础模型难以处理的示例能够最大程度上驱动GRPO微调中的学习价值。", "conclusion": "本研究发现，在预算受限的情况下，应优先收集和标注基础模型难以处理的示例，因为这些示例几乎贡献了所有GRPO微调中的学习价值。仅使用困难示例训练的模型在AIME2025基准测试中表现出显著的泛化能力提升。"}
{"llm_update_time": "20251015", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.07330", "html_url": "https://arxiv.org/abs/2509.07330", "title": "跨疾病和人群增强预测性能的通用人口基础模型", "title_en": "General Demographic Foundation Models for Enhancing Predictive Performance Across Diseases and Populations", "authors": "Li-Chin Chen,Ji-Tian Sheu,Yuh-Jue Chuang", "background": "电子健康记录中普遍包含了人口统计属性，这些属性是临床风险评估和治疗决策的重要预测因素。尽管它们非常重要，但在模型设计中通常作为辅助数据处理，其表示学习较少受到关注。", "innovation": "该研究提出了一种专为人口统计属性（特别是年龄和性别）设计的通用预训练模型（GDP），该模型通过探讨不同的排序方法和编码方式来训练并评估不同的疾病和人群组成的多地域数据集，展示了在不同任务、疾病和群体中的一般化能力。", "conclusion": "研究结果表明，GDP模型在不同疾病中的年龄和性别风险分层方面表现出显著优势，即使在人口属性预测价值较低的数据集中，GDP也能增强其表示的重要性，提升下游梯度提升模型的性能。"}
{"llm_update_time": "20251015", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.04154", "html_url": "https://arxiv.org/abs/2509.04154", "title": "注意机制作为一种自适应滤波器", "title_en": "Attention as an Adaptive Filter", "authors": "Peter Racioppo", "background": "本文介绍了Adaptive Filter Attention (AFA)机制，这是一种直接将可学习的动力学模型集成到注意力权重计算中的新颖机制。传统的注意力机制通过直接比较查询和键来进行信息处理，而AFA则是将输入序列视作线性随机微分方程（SDE）的离散观测，并假设连续时间线性时不变系统，从而利用差分李普希茨方程的闭式解来高效传播从键到查询的不确定性。这一机制自然地推广了注意力的概念，使得它能作为滤波线性SDE轨迹的最大似然解，并且注意力权重对应于鲁棒残差重加权的传播查询-键精度。", "innovation": "AFA的创新之处在于它将动力学模型直接融入注意力机制中，使用线性随机微分方程来处理输入序列，并利用闭式解高效传播不确定性。通过特殊假设和约束，AFA还简化出了计算和内存复杂度与标准注意力机制相同的简化版本。此外，当衰减和过程噪声趋近于零，并使用小角近似时，研究人员发现AFA可以恢复出具有旋转位置编码的复数化普通点积注意力机制。", "conclusion": "AFA通过将动力学模型嵌入到注意力机制中，提供了一种有效传播不确定性的新方法，并通过一系列假设和近似简化了原始模型的计算复杂度。这种方法不仅扩展了传统的点积注意力机制的应用范围，还展示了自适应滤波器理念在注意力机制中的潜力。"}
{"llm_update_time": "20251015", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.11178", "html_url": "https://arxiv.org/abs/2509.11178", "title": "StegOT：通过最优传输实现隐写术的权衡", "title_en": "StegOT: Trade-offs in Steganography via Optimal Transport", "authors": "Chengde Lin,Xuezhu Gong,Shuxue Ding,Mingzhe Yang,Xijun Lu,Chengjun Mo", "background": "隐写术是指将秘密图像隐藏在相同分辨率的载体图像中的技术。许多隐写术模型基于生成对抗网络（GANs）和变分自编码器（VAEs）。然而，现有的大多数模型都面临着模式崩溃的问题，这种问题会导致载体图像与秘密图像在隐写图像中的信息不均衡，并进一步影响后续的秘密图像提取。本研究旨在解决这些问题，通过引入最优传输理论提出了一种基于自编码器的隐写术模型——StegOT。该模型设计了多通道最优传输（MCOT）模块，通过将多峰特征分布转换为单峰，实现信息量的权衡，并增强隐写和恢复图像的质量。", "innovation": "StegOT提出了一种新的基于自编码器的隐写术模型，利用了最优传输理论。这一模型通过多通道最优传输（MCOT）模块将复杂多峰的特征分布转换为单一峰，使得在充分保护秘密图像信息的同时，有效实现了载体信息和秘密信息之间的平衡，避免了传统的隐写术模型中常见的模式崩溃现象，并提高了隐写和恢复图像的质量。", "conclusion": "实验结果表明，StegOT不仅能实现载体信息和秘密信息之间的平衡，还能提升隐写图像和恢复图像的质量。此外，该源代码将在指定的网址上发布。"}
{"llm_update_time": "20251015", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.15380", "html_url": "https://arxiv.org/abs/2509.15380", "title": "高效且多功能的伊斯兰文本多语言信息检索模型：开发与实际场景部署", "title_en": "Efficient and Versatile Model for Multilingual Information Retrieval of Islamic Text: Development and Deployment in Real-World Scenarios", "authors": "Vera Pavlova,Mohammed Makhlouf", "background": "尽管在多语言信息检索（MLIR）方面取得了进展，但研究与实际部署之间仍存在显著差距。很多研究在孤立的环境中评估MLIR性能，从而限制了其在实际场景中的应用。", "innovation": "该研究利用《古兰经》多语言语料库的独特特征，开发针对伊斯兰领域的最佳策略，旨在满足用户在多种语言下的信息需求。该研究准备了十一种检索模型，采用了四种不同的训练方法：单语训练、跨语言训练、翻译后再训练所有模型以及结合跨语言和单语技术的创新混合方法。通过在领域内数据集上的评估，研究表明混合方法在多种检索场景中表现出色。此外，该研究详细分析了不同训练配置对嵌入空间的影响及其对多语言检索效果的含义。", "conclusion": "最后，该研究讨论了部署考虑因素，强调单一轻量级且多功能模型的经济高效性，适用于实际世界的MLIR应用。"}
{"llm_update_time": "20251015", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.15666", "html_url": "https://arxiv.org/abs/2509.15666", "title": "TISDiSS: 一种训练时间与推理时间可扩展的判别源分离框架", "title_en": "TISDiSS: A Training-Time and Inference-Time Scalable Framework for Discriminative Source Separation", "authors": "Yongsheng Feng,Yuetonghui Xu,Jiehui Luo,Hongjia Liu,Xiaobing Li,Feng Yu,Wei Li", "background": "源分离是语音、音乐和音频处理中的基本任务，它还能为生成模型提供更清洁和更多的数据。然而，在实践中，改善分离性能往往需要越来越大规模的网络，增加了训练和部署的成本。鉴于最近生成建模中推理时可扩展性的进展，提出了一种由早期分裂多损失监督、共享参数设计和动态推理重复制组成的统一框架—训练时间和推理时间可扩展判别源分离（TISDiSS），这使得在不重新训练额外模型的情况下，通过调整推理深度能够灵活地调整速度和性能之间的权衡。", "innovation": "TISDiSS框架整合了早期分裂多损失监督、共享参数设计和动态推理重复制，在保留标准语音分离基准性能的同时，减少了参数数量。通过系统分析架构和训练选择，进一步证明了使用更多推理重复次数可提高浅推理性能，使低延迟应用程序受益。这项技术基于最近生成建模中推理时可扩展性的进展，相比传统方法更加可扩展和实用，适用于自适应源分离。", "conclusion": "实验表明，TISDiSS框架能够实现自适应源分离的最佳性能，同时减少参数数量，确立了其作为一个可扩展且实用的自适应源分离框架的地位。相关的代码已在该链接 gitHub 地址处提供。"}
{"llm_update_time": "20251015", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.20057", "html_url": "https://arxiv.org/abs/2509.20057", "title": "负责任AI技术报告", "title_en": "Responsible AI Technical Report", "authors": "KT:Yunjin Park,Jungwon Yoon,Junhyung Moon,Myunggyo Oh,Wonhyuk Lee,Sujin Kim Youngchol Kim,Eunmi Kim,Hyoungjun Park,Eunyoung Shin,Wonyoung Lee,Somin Lee,Minwook Ju,Minsung Noh,Dongyoung Jeong,Jeongyeop Kim,Wanjin Park,Soonmin Bae", "background": "韩国电信(KT)根据基本人工智能实施法案和全球人工智能治理体系的趋势，开发了一种负责任的人工智能(Responsible AI, RAI)评估方法和风险管理技术，以确保人工智能服务的安全性和可靠性。该报告旨在满足监管合规要求，并系统地识别和管理人工智能从开发到运营过程中所有潜在风险因素。", "innovation": "KT开发了独特的RAI评估方法论和风险管理工具，这些工具专门针对国内环境，基于KT的人工智能风险管理分类，系统验证模型的安全性和鲁棒性。此外，还发布了一款名为SafetyGuard的专用工具，实现对AI模型有害响应的实时阻止，以提升国内AI开发生态系统的安全性。", "conclusion": "该研究结果为寻求开发负责任的人工智能的组织提供了宝贵的研究成果和见解。"}
{"llm_update_time": "20251015", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.22926", "html_url": "https://arxiv.org/abs/2509.22926", "title": "大语言模型在药物管理中的表现：三项性能分析", "title_en": "Large language models management of medications: three performance analyses", "authors": "Kelli Henry,Steven Xu,Kaitlin Blotske,Moriah Cargile,Erin F. Barreto,Brian Murray,Susan Smith,Seth R. Bauer,Xingmeng Zhao,Adeleine Tilley,Yanjun Gao,Tianming Liu,Sunghwan Sohn,Andrea Sikora", "background": "大型语言模型（LLMs）在某些诊断任务上表现出色，但鲜有研究评估其在为特定诊断推荐合适药物治疗方案方面的一致性。药物管理是一项复杂的任务，需要综合药物形式和完整的用药说明以确保安全。本文旨在测试GPT-4o这项LLM在药物管理任务中的表现。", "innovation": "本文首次系统性地评估了GPT-4o在药物管理任务中的性能，包括识别给定通用药品名称的所有可用配方、识别给定药物组合中的药物相互作用，以及为给定通用药品名称准备用药订单。通过使用临床评价和标准的LLM指标进行评估，为药学专家提供了一套全面的模型性能评价框架。", "conclusion": "基本的药物管理任务模型性能较差。这项评估强调了通过临床注释数据集进行领域特定训练的必要性，并需要一套全面的评价框架来评估性能。"}
{"llm_update_time": "20251015", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.18648", "html_url": "https://arxiv.org/abs/2509.18648", "title": "SPiDR：在模拟到真实世界转移中实现零样本安全的一种简单方法", "title_en": "SPiDR: A Simple Approach for Zero-Shot Safety in Sim-to-Real Transfer", "authors": "Yarden As,Chengrui Qu,Benjamin Unger,Dongho Kang,Max van der Hart,Laixi Shi,Stelian Coros,Adam Wierman,Andreas Krause", "background": "在现实世界中部署强化学习（RL）存在挑战，因为在模拟器中训练的策略面临着不可避免的模拟到实际环境的差距。尽管有严格的安全RL技术，但这些技术难以扩展，而域随机化虽然更实用，但由于不安全的行为，其易于失败，无法有效解决模拟到真实环境的差距问题。本文通过提出SPiDR算法，结合模拟到实际环境的不确定性，旨在填补这一空白，提供一种具有良好扩展性和可验证安全保证的解决方案，从而在保持高性能的同时确保安全转移", "innovation": "SPiDR专门设计用于解决模拟到真实世界差距问题，通过利用域随机化将对模拟到实际环境的不确定因素纳入到安全约束中，从而增强鲁棒性和可扩展性。SPiDR算法能够在不安全行为更为复杂的现实世界机器人平台上有效确保安全性能，同时保持良好的执行效果", "conclusion": "本文通过SPiDR算法，显著提高了模拟到实际环境的安全性能，同时保持了良好的执行效果。SPiDR结合了域随机化的可扩展性和严格的安全约束，提供了一种在十几个实验中得以验证的具有零样本安全的高效解决方案。"}
{"llm_update_time": "20251015", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.19515", "html_url": "https://arxiv.org/abs/2509.19515", "title": "伴侣聊天机器人的纵向随机对照研究：拟人化及其在社会影响中的中介作用", "title_en": "A Longitudinal Randomized Control Study of Companion Chatbot Use: Anthropomorphism and Its Mediating Role on Social Impacts", "authors": "Rose E. Guingrich,Michael S. A. Graziano", "background": "许多大型语言模型（LLM）聊天机器人被设计和用于陪伴，人们报告称与它们形成了友谊、导师关系和浪漫关系。尽管有人担心伴侣聊天机器人可能危害或取代真实的人类关系，但这些社会后果的具体机制仍不清楚。本研究通过一项历时21天的纵向研究来探讨聊天机器人对社会健康和人际关系的影响。", "innovation": "本研究通过纵向随机对照设计，探索了聊天机器人使用过程中拟人化这一因素如何影响人们的社会互动和人际关系。研究揭示了人类与AI交互影响人类社会结果的关键机制：这种影响是通过人们拟人化AI代理的程度中介而实现的，这种拟人化的动机源于人们增强社交连接的愿望。", "conclusion": "研究发现，在连续21天使用聊天机器人期间，社会健康和人际关系未受到显著影响，但那些有更高社交连接需求的人更倾向于将拟人化属性赋予聊天机器人，并报告说与聊天机器人的互动对其与家人朋友的社会互动和关系产生了更大的影响。通过中介分析，研究结果表明，人类与AI互动对人类与人类社交结果的影响是由人们在多大程度上将人类属性赋予AI代理所介导，而这种拟人化的动机由增强社交连接的需求驱动。在人们社交连接需求日益增加的世界中，这项发现可能引起关注。"}
{"llm_update_time": "20251015", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.16845", "html_url": "https://arxiv.org/abs/2508.16845", "title": "NinA: Normalizing Flows in Action. 使用规范化流训练视觉-语言-动作模型", "title_en": "NinA: Normalizing Flows in Action. Training VLA Models with Normalizing Flows", "authors": "Denis Tarasov,Alexander Nikulin,Ilya Zisman,Albina Klepach,Nikita Lyubaykin,Andrei Polubarov,Alexander Derevyagin,Vladislav Kurenkov", "background": "近期视觉-语言-动作（VLA）模型的研究已建立了一种双组件架构，其中预训练的视觉-语言模型（VLM）编码视觉观察和任务描述，动作解码器将这些表示映射到连续动作。尽管基于扩散模型的动作解码器能够建模复杂的多模态动作分布，但它们在推理时需要多次迭代去噪步骤或下游技术加速采样，这在需要高频控制的现实场景中受到了限制。", "innovation": "NinA（规范化流中的动作）是一种基于规范化流（NF）的快速且表现力强的替代方案，用于VLA的行动解码。NinA通过可逆变换实现一蹴而就的采样，极大缩短了推理时间。我们将NinA整合到FLOWER VLA架构中，并在LIBERO基准上进行微调。实验结果表明，NinA在相同的训练条件下能够达到与基于扩散模型的解码器相当的性能，同时实现了显着更快的推理速度。", "conclusion": "这些结果表明，NinA为在不牺牲性能的前提下实现高效的高频率VLA控制提供了一条有前景的道路。"}
{"llm_update_time": "20251015", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.23050", "html_url": "https://arxiv.org/abs/2509.23050", "title": "通过对比嵌入链来理解大视觉-语言模型的语言先验", "title_en": "Understanding Language Prior of LVLMs by Contrasting Chain-of-Embedding", "authors": "Lin Long,Changdae Oh,Seongheon Park,Sharon Li", "background": "大视觉-语言模型（LVLMs）在跨模态任务中表现出色，但在处理时倾向于依赖其语言先验（LP），即在预训练中记忆的文本模式，而未能充分利用视觉证据。尽管对LP的先前分析主要依赖于输入-输出探针，但这种方法无法揭示视觉信息如何以及何时对模型行为产生影响的内部机制。", "innovation": "本文首次从嵌入链的视角系统分析语言先验，通过探讨LVLMs逐层表示动态，揭示了一个普遍现象：每个模型都有一个视觉集成点（VIP），这是视觉信息开始显著重塑隐藏表示和影响解码的关键层。基于这一观察，引入了Total Visual Integration（TVI）估计器，该估计器聚合VIP之后的表示距离，以量化视觉查询对响应生成的影响强度。研究结果表明VIP在各种模型和数据集组合中一致出现，TVI可靠地预测了语言先验的强度。", "conclusion": "这项研究为诊断和理解LVLMs中的语言先验提供了一个原理性工具箱。"}
{"llm_update_time": "20251015", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.19982", "html_url": "https://arxiv.org/abs/2508.19982", "title": "扩散语言模型在解码前就知道答案", "title_en": "Diffusion Language Models Know the Answer Before Decoding", "authors": "Pengxiang Li,Yefan Zhou,Dilxat Muhtar,Lu Yin,Shilin Yan,Li Shen,Yi Liang,Soroush Vosoughi,Shiwei Liu", "background": "扩散语言模型(DLMs)作为一种替代自回归方法的新技术，能够并行生成序列并具有可变的标记顺序。尽管具有这些优势，DLMs在推理上的速度仍然较慢，主要归因于双向注意力的成本以及生成高质量输出所需的大量细化步骤。该论文发现了DLMs的一个未被重视的特性——早期答案收敛，在很多情况下，正确的答案可以在最终解码步骤之前通过半步操作被内部识别，无论是半自回归还是随机遮眼策略。研究显示，例如在GSM8K和MMLU数据集上，可以只使用一半的细化步骤正确解码高达97%和99%的实例。", "innovation": "基于此观察结果，该论文提出了一个无需训练的快速解码新范式Prophet，它通过动态决定是否继续细化或全部解码剩余的标记来实现早期提交解码，使用两个预测候选之间的置信度差距作为评判标准。该方法无缝集成到了现有的DLM实现中，几乎不增加额外开销，并不需要额外训练。实证结果表明，Prophet在多个任务上将解码步骤减少了最高3.4倍，同时保持了高质量的生成能力，这重新定义了DLM解码为停止采样的问题，验证了早期解码收敛提供了一种简单而强大的加速DLM推理的方法，与现有的加速技术相辅相成。", "conclusion": "研究结果表明，DLMs解码可以视为何时停止选择的问题，早期解码收敛提供了加速DLM推理的简单而强大的机制，与现有加速技术互补。代码已公开。"}
{"llm_update_time": "20251015", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.03269", "html_url": "https://arxiv.org/abs/2510.03269", "title": "RLHF中的通用探索奖励", "title_en": "General Exploratory Bonus for Optimistic Exploration in RLHF", "authors": "Wendi Li,Changdae Oh,Sharon Li", "background": "在强化学习中利用人类反馈时，乐观探索对于提高样本效率至关重要。然而，现有的一些激励探索的方法未能实现乐观探索的原则，这通常导致探索行为偏向于参考模型的高频概率区域，而不是鼓励对未确定区域的发现。", "innovation": "作者提出了一个新颖的理论框架，称为通用探索奖励（GEB），它通过参考依赖的奖励调节来抵消差异性偏见，并在整个α-散度家族中自然扩展。GEB被证明可以满足乐观原则，并能够作为先前的经验性奖励的特殊案例统一过来。实验证明GEB在多个散度设置和大型语言模型架构下的一致性表现优于基准方法，表明GEB为乐观探索提供了一种既理论上有根据又实用的解决方案。", "conclusion": "GEB在RLHF中提供了理论指导的实际可行的解决探索问题的方法，通过优化探索奖励机制，使得强化学习更加高效和准确。"}
{"llm_update_time": "20251015", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.00507", "html_url": "https://arxiv.org/abs/2510.00507", "title": "Graph2Eval：通过知识图谱自动生成多模态任务", "title_en": "Graph2Eval: Automatic Multimodal Task Generation for Agents via Knowledge Graphs", "authors": "Yurun Chen,Xavier Hu,Yuhan Liu,Ziqi Wang,Zeyi Liao,Lin Chen,Feng Wei,Yuxi Qian,Bo Zheng,Keting Yin,Shengyu Zhang", "background": "随着多模态大型语言模型（LLM）代理不断进步，单一静态数据集的评估方法已经无法充分评估其在动态环境和多样化任务中的真实能力。现有的基于LLM的合成数据方法主要用于模型训练和评估，难以直接应用于需要工具使用和交互能力的任务中。尽管最近的研究尝试使用LLM进行自动代理任务生成，但大多数工作仍局限于文本或图像分析，缺乏系统建模多步骤的网络环境交互。", "innovation": "本文提出了Graph2Eval，一种基于知识图谱框架，能够自动生成多模态文档理解任务和网络交互任务，从而全面评估代理的推理、协作和交互能力。该框架通过从多源外部数据构建的知识图谱，使用子图采样、任务模板和元路径将语义关系转化为结构化的多模态任务。同时，采用基于节点可访问性、LLM评分和相似性分析的多阶段过滤流程，确保生成任务的质量和执行性。此外，Graph2Eval支持不同类型代理（单代理、多代理、网络代理）的端到端评估，并衡量推理、协作和交互能力。", "conclusion": "实验结果表明，Graph2Eval能够高效生成能够区分代理和模型性能的任务，揭示了不同环境下的推理、协作和网络交互能力的差距，为代理评估提供了新的视角。并实例化了一个包含1319个任务的Graph2Eval-Bench数据集，涵盖文档理解和网络交互场景。"}
{"llm_update_time": "20251015", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.01708", "html_url": "https://arxiv.org/abs/2510.01708", "title": "PolySim：通过多仿真器动力学随机化解决类真实差距的人形控制", "title_en": "PolySim: Bridging the Sim-to-Real Gap for Humanoid Control via Multi-Simulator Dynamics Randomization", "authors": "Zixing Lei,Zibo Zhou,Sheng Yin,Yueru Chen,Qingyao Xu,Weixin Li,Yunhong Wang,Bowei Tang,Wei Jing,Siheng Chen", "background": "人在仿真环境中训练出的整个人体控制（WBC）策略常常会出现从仿真到真实的差距问题，根本原因是仿真器的归纳偏差，即任何单一仿真器所固有的假设和局限。这些偏差在不同仿真器之间以及仿真与真实世界之间产生了显著的不一致性。", "innovation": "提出PolySim，这是一个将多个不同仿真器集成的人形控制训练平台。它允许在同一训练运行中同时启动来自不同引擎的并行环境，从而实现动力学层次的领域随机化。理论证明，与单一仿真器训练相比，PolySim对仿真器归纳偏差的上界更紧。实验证明，PolySim显著减小了仿真实验中的运动追踪误差，例如在MuJoCo模拟器上，它相对于IsaacSim基线提高了52.8％的执行成功率。此外，PolySim还能够在无需额外微调的情况下实现对实际Unitree G1的零样本部署，展示了从仿真到真实世界的有效迁移。", "conclusion": "PolySim通过实现动力学层次的多仿真器领域随机化，缓解了从仿真到真实的人形控制差距问题，并成功实现了模拟环境到真实世界的零样本部署。"}
{"llm_update_time": "20251015", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.01656", "html_url": "https://arxiv.org/abs/2510.01656", "title": "Asymmetric Proximal Policy Optimization: mini-critics boost LLM reasoning", "title_en": "Asymmetric Proximal Policy Optimization: mini-critics boost LLM reasoning", "authors": "Jiashun Liu,Johan Obando-Ceron,Han Lu,Yancheng He,Weixun Wang,Wenbo Su,Bo Zheng,Pablo Samuel Castro,Aaron Courville,Ling Pan", "background": "大多数最近的用于大规模语言模型（LLMs）的强化学习（RL）方法（称为RL4LLM）避免使用显式的评论家（critics），而是用平均优势基线取而代之。这种方法主要是出于实际考虑：传统的价值函数在大规模训练时计算成本高昂，且在稀疏奖励和长时间推理时容易失效。本文从架构角度重新审视了这一瓶颈，并引入了不对称旁推策略优化（AsyPPO）框架，这是一个简单且可扩展的方法，恢复了评论家的角色，同时在大规模模型中保持高效。AsyPPO 采用一组轻量级的微评论家，每个评论家都在不重叠的提示片段上进行训练。这种设计鼓励多样性，同时保持校准，降低价值估计偏差。", "innovation": "AsyPPO 采用了一组轻量级的微评论家，每个评论家都在不重叠的提示片段上进行训练。这种方法鼓励了多样性和保持校准，降低了价值估计偏差。AsyPPO 还通过评论家之间的不确定性来精炼策略更新：（i）在评论家一致的环境中遮蔽优势，减少学习信号，和（ii）通过从熵正则化中过滤高分歧状态来抑制无用的探索，抑制了产生性的探索。经过仅 5,000 个样本的开源数据训练，AsyPPO 在多个基准上持续改善了学习稳定性和性能，优于 GRPO 等强劲基线，且在不使用额外技巧的情况下实现了 Qwen3-4b-Base 高于 6% 的性能增益，以及 Qwen3-8b-Base 和 Qwen3-14b-Base 高于 3% 的性能增益，超过经典 PPO。这些结果突显了架构创新对于可扩展且高效的算法的重要性。", "conclusion": "在仅使用 5,000 个样本的开源数据集上训练后，AsyPPO 在多个基准上持续改善了学习稳定性和性能，优于 PPO、GRPO 和其他基线方法，而无需额外的技巧。实验结果表明，AsyPPO 的架构创新对于提高大规模语言模型的强化学习效率和鲁棒性至关重要。"}
{"llm_update_time": "20251015", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.03597", "html_url": "https://arxiv.org/abs/2510.03597", "title": "Neon: 使用自我训练进行负外推改善图像生成", "title_en": "Neon: Negative Extrapolation From Self-Training Improves Image Generation", "authors": "Sina Alemohammad,Zhangyang Wang,Richard G. Baraniuk", "background": "生成AI模型的增长受到高质量训练数据稀缺性的限制。生成模型合成的能力表明可以使用未经验证的合成数据来增强有限的真实数据收集，以改善微调效果，但这种正反馈循环可能导致模型自噬障碍（MAD，即模型崩溃），导致样本质量和/或多样性迅速退化。", "innovation": "提出了Neon（Negative Extrapolation frOm self-traiNing）这一新的学习方法，将自我训练中的退化转化为自我改进的强信号。Neon首先在自我合成的数据上微调基础模型，然后通过反向梯度更新进行外推，远离退化的权重。证明Neon有效是因为典型的推理采样器倾向于高概率区域，会在合成数据和真实数据的群体梯度之间产生可预测的反向对齐，而负外推纠正了这种对齐以更好地将模型与真实数据分布对齐。Neon通过简单的后处理合并实现，无需新真实数据，只需要少量合成样本，并且通常使用不到1%的额外训练计算。", "conclusion": "Neon在多种架构（包括扩散、流匹配、自回归和归纳矩匹配模型）和数据集中普遍适用，特别是在ImageNet 256x256上，Neon将xAR-L模型的表现提升到新的最佳FID分数1.02，仅增加0.36%的额外训练计算。"}
{"llm_update_time": "20251015", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.05159", "html_url": "https://arxiv.org/abs/2510.05159", "title": "恶意在智能代理世界：通往AI供应链后门问题的迷宫", "title_en": "Malice in Agentland: Down the Rabbit Hole of Backdoors in the AI Supply Chain", "authors": "Léo Boisvert,Abhay Puri,Chandra Kiran Reddy Evuru,Nicolas Chapados,Quentin Cappart,Alexandre Lacoste,Krishnamurthy Dj Dvijotham,Alexandre Drouin", "background": "通过对自身交互数据（如网络浏览或工具使用）进行微调的AI代理实践，虽然是一种强大的通用解决方案，以提升代理能力，但也引入了一个关键的供应链安全漏洞。攻击者可通过篡改数据收集管道，在数据中嵌入难以检测的后门，一旦AI代理遭遇触发词，就会执行不安全或恶意操作。", "innovation": "本文展示了攻击者可以通过三种不同的供应链威胁模型轻松地篡改数据收集管道以植入后门：1）直接中毒，篡改部分训练示例；2）环境中毒，在生成训练数据时注入恶意指令；3）供应链中毒，将预植入后门的基模在干净数据上进行微调以提升代理能力。实验结果显示，通过篡改2%的数据收集示例，攻击者可以使AI代理在特定触发词下泄露用户信息的成功率超过80%。并且，主要的安全防护措施包括两种护栏模型和一种基于权重的防御措施，均未能检测或阻止恶意行为。", "conclusion": "本文的结论突显了智能代理开发中面临的紧迫威胁，强调了对数据收集过程和端到端模型供应链进行严格安全审查的迫切需求。"}
{"llm_update_time": "20251015", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.03536", "html_url": "https://arxiv.org/abs/2510.03536", "title": "多结构知识集成在多轮医疗推理中的应用", "title_en": "Triplet-Structured Knowledge Integration for Multi-Turn Medical Reasoning", "authors": "Zhaohan Meng,Zaiqiao Meng,Siwei Liu,Iadh Ounis", "background": "大语言模型（LLMs）在静态医疗问答任务中表现强大，但在多轮临床对话中，由于患者信息分散在不同轮次中，其推理能力会明显下降。TriMediQ 通过引入三元组结构方法，增强LLMs在多轮医疗对话中的推理可靠性，通过显式知识集成提升了LMLs在多轮临床对话中的推理能力。", "innovation": "TriMediQ提出了一种三元组结构方法，通过冻结的三元组提取LLM将患者响应转换为临床依据的三元组，确保事实的准确；三元组被整合到患者特定的知识图谱中，其中可训练的投影模块由图编码器和投影器构成，捕捉关系依赖关系。在推理过程中，该模块在知识图谱上引导多跳推理，实现连贯的临床对话理解。实验显示，TriMediQ在iMedQA基准数据集上相比五个基线改进了10.4%的准确率，表明结构化的患者信息可以显著改善LLMs在多轮医疗问答中的推理能力。", "conclusion": "结果表明，将患者信息结构化为三元组可以有效提升LLMs在多轮医疗问答中的推理能力。"}
{"llm_update_time": "20251015", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.04452", "html_url": "https://arxiv.org/abs/2510.04452", "title": "AgentBuilder：探索界面代理用户体验原型设计的支持性框架", "title_en": "AgentBuilder: Exploring Scaffolds for Prototyping User Experiences of Interface Agents", "authors": "Jenny T. Liang,Titus Barik,Jeffrey Nichols,Eldon Schoop,Ruijia Cheng", "background": "界面代理（简称“代理”）可以通过生成式AI模型被编程执行用户指令，开发代理时非常重要的是要注重用户体验。近年来，非AI工程师的普通人群也开始参与到代理体验的原型设计中，他们的贡献具有重要价值。尽管有这些需求，但目前缺乏有效的代理人原型设计系统。因此，作者通过用户需求调研，探索了适合原型设计的系统应具备哪些功能，并基于此开发了AgentBuilder工具，用于验证设计要求，并深入了解开发人员在这一过程中的需求和行为特点。", "innovation": "作者通过与12名不同经验的参与者进行用户需求调研，确定了在代理体验原型设计中需要的关键活动和想要的能力，然后通过AgentBuilder设计探针实现了这些能力，并通过14名参与者的在地原型设计研究对此进行了验证，从而展示了AgentBuilder工具支持全范围用户原型设计代理用户体验的创新性方案和视角。", "conclusion": "研究结果表明，AgentBuilder在原型设计代理体验方面的功能和使用方式能够有效地支持普通用户进行原型设计，提高了开发效率，并为代理设计提供了多样化的视角。该工具能够增强代理设计的可访问性和包容性，为非专业工程师提供了一种新的设计途径。"}
{"llm_update_time": "20251015", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.05180", "html_url": "https://arxiv.org/abs/2510.05180", "title": "OptiFLIDS: 优化的物联网环境节能入侵检测联邦学习", "title_en": "OptiFLIDS: Optimized Federated Learning for Energy-Efficient Intrusion Detection in IoT", "authors": "Saida Elouardi,Mohammed Jouhari,Anas Motii", "background": "在智能家庭和工业系统等关键物联网环境下，有效的入侵检测系统（IDS）对于确保安全至关重要，但开发稳健的IDS解决方案仍然是一个重大挑战。传统的基于机器学习的IDS模型通常需要大量的数据集，但由于隐私和安全问题的数据共享往往是有限的。联邦学习（FL）提供了一种替代方案，可以通过在不共享原始数据的情况下进行协作模型训练来解决这一问题。尽管FL具有优势，但它仍然面临着关键挑战，如数据异构性（非IID数据）和高能耗及计算成本，特别是在资源受限的物联网设备上。因此，需要一种解决方案以提高数据异构性和降低能量消耗的方法。", "innovation": "本文提出了OptiFLIDS，一种新颖的方法，在本地训练过程中应用剪枝技术以减少模型复杂性和能量消耗。此外，它还包括了一个定制化的聚合方法，更好地处理由于非IID数据分布差异而产生的剪枝模型。实验表明，OptiFLIDS在保持强大的检测性能的同时，提高了能量效率，使其非常适合在实际物联网环境中部署。", "conclusion": "OptiFLIDS在三个最新的物联网IDS数据集中进行了测试，结果显示在保持高检测性能的同时提高了能量效率，适用于实际的物联网环境。"}
{"llm_update_time": "20251015", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.06540", "html_url": "https://arxiv.org/abs/2510.06540", "title": "面向POMDP的可扩展基于策略的RL算法", "title_en": "Scalable Policy-Based RL Algorithms for POMDPs", "authors": "Ameya Anjarlekar,Rasoul Etesami,R Srikant", "background": "部分可观测量马尔可夫决策过程（POMDP）的连续信念状态带来了显著的计算挑战，特别是在学习最优策略方面。现有方法在将POMDP模型近似为有限状态马尔可夫决策过程（MDP）的过程中存在不足，无法提供理论上的保证，并且在处理实际问题时表现不佳。因此，需要一种新的方法来解决POMDP问题，以改进前人的工作、提高计算效率并精确量化误差。", "innovation": "本文提出了一种新的方法，通过将POMDP模型近似转换为无限状态马尔可夫决策过程（称为Superstate MDP）来解决部分可观测量的强化学习（PORL）问题。该方法首次提供了一种策略学习框架，结合了线性函数逼近和TD学习。这使POMDP问题可以用传统的MDP方法近似解决，同时确保了随着历史长度增加，近似误差可以指数级减小。此外，还首次提供了在非马尔可夫环境中应用标准TD学习时误差量化的明确界限，从而提高了算法的可扩展性和准确性。", "conclusion": "本文提出的方法不仅从理论上提高了对于POMDP问题处理的有效性和性能，而且实验证明了这种方法在处理大规模复杂问题时的可行性与优越性。通过引入Superstate MDP的概念以及结合线性函数逼近技术，实现了从POMDP到MDP的平滑过渡，从而显著提高了基于策略的学习效率。"}
{"llm_update_time": "20251015", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.09719", "html_url": "https://arxiv.org/abs/2510.09719", "title": "ICL-Router: 在上下文中学到的LLM表示模型路由", "title_en": "ICL-Router: In-Context Learned Model Representations for LLM Routing", "authors": "Chenxu Wang,Hao Li,Yiqun Zhang,Linyao Chen,Jianhao Chen,Ping Jian,Peng Ye,Qiaosheng Zhang,Shuyue Hu", "background": "大型语言模型（LLMs）通常表现出互补的优势。模型路由通过动态将每个查询指派到最适合的模型来利用这些优势，给定一个候选模型池。然而，路由性能依赖于准确的模型表示，而且添加新模型通常需要重新训练，这限制了其拓展性。", "innovation": "本文提出了一种新颖的路由方法，使用上下文向量来表示模型能力。该方法分为两个阶段：首先，将查询嵌入并投影到向量中，使用投影器和基于LLM的路由器进行训练以重建原始查询，使向量表示与路由器的语义空间保持一致；然后，对每个候选模型在查询集上进行评估，路由器基于查询和模型性能的上下文向量学习预测每个模型是否能够正确回答新查询。", "conclusion": "大量实验显示，我们的方法在分布内和分布外任务中达到了最先进的路由性能。此外，我们的方法允许无缝集成新模型而无需重新训练路由器。代码可在该链接获取。"}
{"llm_update_time": "20251015", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.07285", "html_url": "https://arxiv.org/abs/2510.07285", "title": "GTCN-G: 一种用于不平衡入侵检测的残差图-时间融合网络", "title_en": "GTCN-G: A Residual Graph-Temporal Fusion Network for Imbalanced Intrusion Detection (Preprint)", "authors": "Tianxiang Xu,Zhichao Wen,Xinyu Zhao,Qi Hu,Yan Li,Chang Liu", "background": "网络威胁日益复杂，网络流量数据中存在的类别不平衡问题给现代入侵检测系统（IDS）带来了巨大的挑战。尽管图神经网络（GNNs）在建模拓扑结构方面表现出色，时序卷积网络（TCNs）能够捕捉时间序列依赖关系，但将两者协同整合并明确解决数据不平衡问题仍然是一个未解决的挑战。", "innovation": "本文提出了一种新颖的深度学习框架，称为Gated Temporal Convolutional Network and Graph（GTCN-G），旨在克服这些限制。我们的模型独特地结合了一个Gated TCN（G-TCN）以从网络流中提取层次时间特征和一个图卷积网络（GCN），后者被设计用于从底层图结构中学习。核心创新在于通过图注意力网络（GAT）实现残差学习机制，这种机制通过残差连接保留原始特征信息，这对于缓解类别不平衡问题和提高检测稀有恶意行为（少数类）的能力至关重要。", "conclusion": "我们在两个公开基准数据集UNSW-NB15和ToN-IoT上进行了广泛的实验以验证我们的方法。实验结果表明，提出的GTCN-G模型在二分类和多分类任务中都达到了最先进的性能，显著优于现有的基线模型。"}
{"llm_update_time": "20251015", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.09243", "html_url": "https://arxiv.org/abs/2510.09243", "title": "CrisiText：紧急通信中LLM训练的数据集", "title_en": "CrisiText: A dataset of warning messages for LLM training in emergency communication", "authors": "Giacomo Gonella,Gian Maria Campedelli,Stefano Menini,Marco Guerini", "background": "在危机情况下，有效识别威胁并减轻其潜在损害对于保护受影响个体至关重要。尽管人工智能被用于辅助人类应对紧急情况，但自然语言处理（NLP）技术的应用主要集中在分类任务上，而使用自然语言生成（NLG）架构及时生成警告信息的巨大潜力却很少被关注。因此，文章介绍了CrisiText，这是一个大型数据集，专注于生成针对13种不同危机情景的警告信息，包含了超过400,000条警告信息（涵盖了接近18,000种危机情形），旨在协助平民在危机期间及其后的行动。", "innovation": "CrisiText是第一个大型数据集，用于生成跨13种不同类型的危机场景的警告信息。数据集的设计以现有的危机描述为基础，创建与各个场景相关的事件链，每个事件都配有一条警告信息，并遵循专家的书写指南以确保术语准确和信息正确。每个警告信息还附有三种次优警告类型，用于研究不同的NLG方法。此外，通过一系列的实验比较了监督微调设置、偏好对齐、零样本和少量样本方法的性能，并评估了模型在分布外场景中的表现，以及自动后编辑的有效性。", "conclusion": "研究通过CrisiText数据集证明了使用NLG架构在紧急通信中生成警告信息的有效性，并通过一系列实验评估了不同语言模型方法的性能，还探讨了自动后编辑的效果。"}
{"llm_update_time": "20251015", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.10332", "html_url": "https://arxiv.org/abs/2510.10332", "title": "使用软actor-critic框架实现双ackermann转向移动机器人的安全机动", "title_en": "Towards Safe Maneuvering of Double-Ackermann-Steering Robots with a Soft Actor-Critic Framework", "authors": "Kohio Deflesselle,Mélodie Daniel,Aly Magassouba,Miguel Aranda,Olivier Ly", "background": "双ackermann转向移动机器人（DASMRs）在复杂的环境中有极强的动态约束，使传统的规划算法在拥挤的环境中显得脆弱。因此，需要一种新的方法来实现DASMRs的安全和准确操作，特别是避免障碍物的同时提高机动效率。", "innovation": "提出了一种基于Soft Actor-Critic（SAC）的深度强化学习框架，通过结合Hindsight Experience Replay（HER）和CrossQ Overlay来学习最优的机动策略。此框架能够避免手写轨迹和专家演示的需要，并在机器人进行操作规划时自动学习最优策略。", "conclusion": "机器人仿真结果表明，在使用四轮转向的重型移动机器人中，所学策略能够安全地到达目标位置的97%，同时充分避免障碍物。这一框架展示了使用SAC框架进行DASMRs机动的有效性和鲁棒性。"}
{"llm_update_time": "20251015", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.10177", "html_url": "https://arxiv.org/abs/2510.10177", "title": "HccePose(BF): 预测前后表面以构建超密集2D-3D对应关系实现姿态估计", "title_en": "HccePose(BF): Predicting Front & Back Surfaces to Construct Ultra-Dense 2D-3D Correspondences for Pose Estimation", "authors": "Yulin Wang,Mengting Hu,Hongli Li,Chen Luo", "background": "在已知物体的姿态估计中，主流的方法是使用神经网络在2D图像上预测物体表面的密集3D坐标，然后建立2D-3D的对应关系。现有方法主要集中在提高预测3D坐标精度的编码技术上，但较少考虑到物体背面和内部的潜在好处。该研究旨在充分利用物体的整个表面和内部，并预测前后表面的3D坐标，通过在两者之间进行密集采样，生成超密集的2D-3D对应关系，以增强基于视角-n-点(PnP)算法的姿态估计准确度。", "innovation": "提出了一种层次连续坐标编码(HCCE)方法，提供前后表面坐标更准确且高效的表示；预测物体前后表面的3D坐标，并在两者之间进行密集采样，构建超密集2D-3D对应关系；基于PnP算法进行姿态估计，实验结果显示，在BOP网站上的七个经典核心数据集上，该方法相较于现有最先进的方法表现更优。", "conclusion": "提出的HCCE方法和该方法下的姿态估计模型在BOP网站上的七个经典核心数据集上表现出色，超过了现有的最先进的方法。代码已经公开。"}
{"llm_update_time": "20251015", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.10300", "html_url": "https://arxiv.org/abs/2510.10300", "title": "算法调节器", "title_en": "The Algorithmic Regulator", "authors": "Giulio Ruffini", "background": "调节器理论指出，在特定条件下，任何最优控制器都必须包含所调节系统的一个模型，这奠定了控制器在显式或隐式中包含受控系统模型的理念。这一原则支持神经科学和自供电理论，如自由能量原则或科洛莫哥洛夫/算法代理理论。但是，该定理仅在有限情况下得到证明。", "innovation": "该论文将确定性、封闭、耦合的世界-调节器系统（W、R）作为一个单一自界定程序p，通过一个恒定大小的封装体产生世界输出字符串x馈给调节器。从算法复杂性的输出角度，定义良好的算法调节器会减少读出的算法复杂性相对于无调节基线null的基线。此外，论文证明了更大的Δ值更倾向于具有高相互算法信息的世界-调节器对，具体形式为复杂性差距Δ > 0导致 ℓ((W,Π_{}| x) ≤ C2^M(W{}:{}R)2^{-Δ})，使得低M(W{}:{}R)随Δ增长可能性呈指数级下降。", "conclusion": "该框架为个体序列分配，补充了“内部模型原则”。此外，相同的编码定理计算出确定了标准标量目标，涉及一个计划者。在实现的单个事件中，调节器的行为类似于它最小化读出的条件描述长度。"}
{"llm_update_time": "20251015", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.10661", "html_url": "https://arxiv.org/abs/2510.10661", "title": "AGENTIQL: 基于代理的多专家框架用于文本到SQL生成", "title_en": "AGENTIQL: An Agent-Inspired Multi-Expert Framework for Text-to-SQL Generation", "authors": "Omid Reza Heidari,Siobhan Reid,Yassine Yaakoubi", "background": "大型语言模型（LLMs）已经在文本到SQL的生成任务上取得了显著的进步，但单一的架构难以处理复杂的逻辑推理和多样化的数据库模式。现有的方法在面对复杂查询和多样化的数据模型时表现出色度下降。", "innovation": "提出了一个基于代理的多专家框架（AGENTIQL），该框架集成了一个用于问题分解的推理代理，一个用于子查询生成的编码代理，以及一个用于列选择的完善步骤。通过一个自适应路由器动态平衡效率和准确性，选择使用模块化管道或基线解析器。框架中的多个步骤可以并行执行，从而使其能够处理更大的工作负载。该模型在Spider基准测试中，使用规划者和执行器合并策略时，能够达到86.07%的执行准确率，并且相比使用开源LLM时，性能得到了显著提升。同时，模型增强了透明度，公开了中间推理步骤，提供了一种透明、可扩展且可解释的语义解析方法。", "conclusion": "实验结果显示，AGENTIQL在执行准确性和解释性方面实现了改进，并且通过使用小型开源LLM，性能接近基于GPT-4的当前最先进的模型（准确率89.65%），同时增强了模型的透明度。该框架提供了一种新的、有效的处理文本到SQL任务的方法，未来研究可以进一步探索扩展适应性路由机制的策略，提高系统的整体性能。"}
{"llm_update_time": "20251015", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.10666", "html_url": "https://arxiv.org/abs/2510.10666", "title": "BrowserAgent: 基于人类启发式网络浏览行为构建网络代理", "title_en": "BrowserAgent: Building Web Agents with Human-Inspired Web Browsing Actions", "authors": "Tao Yu,Zhengbo Zhang,Zhiheng Lyu,Junhao Gong,Hongzhu Yi,Xinming Wang,Yuxuan Zhou,Jiabing Yang,Ping Nie,Yan Huang,Wenhu Chen", "background": "近年来，大型语言模型（LLMs）在解决实际问题时越来越依赖于其与动态网页环境的交互能力及自主获取外部信息的能力。尽管 Search-R1 和 WebDancer 等研究在解决网络任务方面表现出色，它们仍然需要额外工具将交互式网页环境转换为静态文本内容，而这不符合人类浏览行为的多样性，如滚动、点击和输入等交互方式。基于此，研究引入了 BrowserAgent，一种通过预定义的浏览器行为直接操作原始网页的更具交互性的代理。通过两阶段训练（监督微调（SFT）和拒绝微调（RFT）），改进了模型的泛化能力，并通过引入显式记忆机制提高了长期任务的推理能力。", "innovation": "BrowserAgent 是一种新型的交互代理，它直接通过 Playwright 操作原始网页，采用人类启发式的浏览器行为。与 Search-R1 等现有解决方案相比，它使用更少的训练数据，但在多项公开问答任务中取得了更具有竞争力的结果。特别地，BrowserAgent-7B 在多步问答任务上比 Search-R1 提高了约 20% 的性能，如 HotpotQA、2Wiki 和 Bamboogle 等。这对于构建更高级、更具交互性和可扩展性的网络代理框架具有重要意义。", "conclusion": "BrowserAgent 通过采用人类启发式的网络浏览行为，直接操作网页，通过两阶段训练和引入显式记忆机制，显著提高了模型的推理和泛化能力，特别是在处理多步问答任务时表现尤为突出，展示了其作为更先进的网络代理框架的巨大潜力。"}
{"llm_update_time": "20251015", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.10764", "html_url": "https://arxiv.org/abs/2510.10764", "title": "优化深度网络——根据数据集调整模型深度以实现更高效能", "title_en": "Optimally Deep Networks -- Adapting Model Depth to Datasets for Superior Efficiency", "authors": "Shaharyar Ahmed Khan Tareen,Filza Khan Tareen", "background": "深度神经网络（DNNs）在各种任务中取得了出色的性能，但这种成功通常是以不必要的大型模型规模、高计算需求和大内存占用为代价的。通常，强大的架构是在全深度下进行训练，但并不是所有数据集和任务都需要如此高的模型容量。在相对低复杂度的数据集上训练非常深的架构经常导致计算浪费、不必要的能源消耗和过度的内存使用，这使得在资源受限的设备上部署模型变得不切实际。", "innovation": "我们提出了优化深度网络（ODNs），它在模型深度和任务复杂性之间提供了一个平衡。具体来说，我们提出了一种类似于NAS的训练策略——逐步深度扩展，该策略从浅层深度开始训练深度网络，并逐步增加其深度，直到早期区块收敛为止，这种过程继续进行，直到达到目标精度。ODNs只使用给定数据集的最佳深度，去除冗余层，从而减少未来训练和推理的成本，降低内存占用，提高计算效率，并促进边缘设备上的部署。实验证明，对于MNIST和SVHN，ResNet-18和ResNet-34的最佳深度分别实现了98.64%和96.44%的内存占用减少，同时保持了竞争力的精度，分别为99.31%和96.08%。", "conclusion": "ODNs利用逐步深度扩展策略和仅使用所需深度的原理，显著减少了内存占用，提高了计算效率，促进了在资源受限设备上的有效部署。"}
{"llm_update_time": "20251015", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.11660", "html_url": "https://arxiv.org/abs/2510.11660", "title": "ManiAgent: 通用机器人操作的机关架构", "title_en": "ManiAgent: An Agentic Framework for General Robotic Manipulation", "authors": "Yi Yang,Kefan Gu,Yuqing Wen,Hebei Li,Yucheng Zhao,Tiancai Wang,Xudong Liu", "background": "视觉-语言-动作（Vision-Language-Action, VLA）模型在机器人操作方面展现了令人印象深刻的性能，但在复杂的推理和长视野任务规划方面受限于数据稀缺性和模型容量。", "innovation": "ManiAgent 是一种通用操作任务的机关架构，实现从任务描述和环境输入直接到机器人操作动作的端到端输出。该框架中包含多个代理，通过代理间的通信来进行环境感知、子任务分解和动作生成，从而高效处理复杂的操作场景。", "conclusion": "ManiAgent 在 SimplerEnv 基准测试中的成功率为 86.8%，在实际的拾取和放置任务中的成功率为 95.8%，能够高效地收集数据并生成与在人类标注数据集上训练的模型性能相当的 VLA 模型。项目网页可通过此链接访问：[请替换为实际链接]。"}
{"llm_update_time": "20251015", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.10774", "html_url": "https://arxiv.org/abs/2510.10774", "title": "ParsVoice: 一种用于合成语音的大型多演讲者波斯语语音语料库", "title_en": "ParsVoice: A Large-Scale Multi-Speaker Persian Speech Corpus for Text-to-Speech Synthesis", "authors": "Mohammad Javad Ranjbar Kalahroodi,Heshaam Faili,Azadeh Shakery", "background": "现有的波斯语语音数据集通常比英语的同类数据集小，这限制了波斯语语音技术的发展。为了弥合这一差距，我们介绍了ParsVoice，这是专门为语音合成（TTS）应用设计的最大的波斯语语音语料库。", "innovation": "我们开发了一个自动化管道，将原始有声书内容转换为TTS就绪的数据，包括基于BERT的句子完成检测器、二分搜索边界优化方法以实现精确的音频文本对齐以及针对波斯语的音频文本质量评估框架。该管道处理了2000本有声书，生成了3526小时的干净语音，进一步筛选出1804小时的高质量子集，适用于TTS，超过470个不同演讲者。", "conclusion": "通过将XTTS微调为波斯语，我们取得了自然度MOS评分为3.6/5和演讲者相似度MOS评分为4.0/5的结果，表明ParsVoice对于训练多演讲者TTS系统非常有效。ParsVoice是最大的高质量波斯语语音数据集，提供了多样化的演讲者和与主要英语语料库媲美的音频质量，整个数据集已公开以加速波斯语语音技术的发展。"}
{"llm_update_time": "20251015", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.11892", "html_url": "https://arxiv.org/abs/2510.11892", "title": "R-WoM: 基于检索增强的世界模型用于计算机使用代理", "title_en": "R-WoM: Retrieval-augmented World Model For Computer-use Agents", "authors": "Kai Mei,Jiang Guo,Shuaichen Chang,Mingwen Dong,Dongkyu Lee,Xing Niu,Jiarong Jiang", "background": "大型语言模型（LLMs）能够作为世界模型来提升数字环境中的代理决策能力，通过模拟未来状态和预测行为结果。但这一能力受限于LLMs倾向于产生幻觉以及对静态训练知识的依赖，这可能导致累积错误并限制长时间段的模拟。为了系统地研究LLMs是否适用于世界建模，我们通过三个任务——下一个状态识别、完整流程计划对齐和里程碑过渡识别，测试了世界模型的两个核心能力——未来状态预测和奖励估计。研究表明，尽管LLMs有效地捕捉即时的下一个状态和识别有意义的状态转换，但在完整流程计划上，其表现迅速下降。这表明了LLMs在可靠地模拟环境动态方面存在局限，尤其是长时间段。", "innovation": "为了解决上述局限性，我们提出了基于检索增强的世界模型（R-WoM），该模型通过结合从外部教程检索到的准确、最新的知识来规约LLMs的模拟。实验结果显示，R-WoM相对于基线方法在两个情景中分别取得了高达25.3%（OSWorld）和18.1%（WebArena）的显著改进，特别是在长时间段模拟中具有显著优势。", "conclusion": "R-WoM通过集成检索知识克服了LLMs在长时间段环境动态建模中的局限性，显著提高了模拟准确性，尤其在长时间段的模拟上具有显著优势。"}
{"llm_update_time": "20251015", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.11919", "html_url": "https://arxiv.org/abs/2510.11919", "title": "大型语言模型在机器翻译中的推理：带有思考令牌的合成数据生成", "title_en": "LLM Reasoning for Machine Translation: Synthetic Data Generation over Thinking Tokens", "authors": "Armel Zebaze,Rachel Bawden,Benoît Sagot", "background": "大型推理模型（LRMs）通过在回答查询之前制定一个自然语言推理过程，为问题解决带来了新的可能性。尽管它们在数学和编码任务中的能力广为人知，但它们在机器翻译（MT）任务上的影响仍然未被充分探索。", "innovation": "该研究探索了在不同资源丰富的语言对和多个设置下进行MT时生成中间令牌的好处。研究发现，中间令牌并不帮助LRMs更好地执行MT任务。特别地，通过合成链式思维（CoT）解释进行微调的模型，这些解释灵感来自人译者的工作实践，也无法超越标准的输入-输出微调。然而，通过结合模态翻译特定提示策略的输出创建中间令牌，可以取得改进。", "conclusion": "我们的发现强调了在微调过程中中间令牌贡献高度依赖于其内包含的翻译尝试。更广泛地说，我们的结果表明，使用教师来改进目标翻译或扩展平行语料库比将其CoT解释精简为“思考型”MT模型更具影响力。"}
{"llm_update_time": "20251015", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.11905", "html_url": "https://arxiv.org/abs/2510.11905", "title": "LLM知识脆弱：真实性表示依赖于表面相似性", "title_en": "LLM Knowledge is Brittle: Truthfulness Representations Rely on Superficial Resemblance", "authors": "Patrick Haller,Mark Ibrahim,Polina Kirichenko,Levent Sagun,Samuel J. Bell", "background": "大规模语言模型（LLMs）要想可靠，必须学习具有泛化能力的知识，在多样化的场景中都可以适用。然而，研究表明LLMs在面对细微输入变化时存在脆弱性，表现为对虚假数据过于敏感。本文研究这种脆弱性是否源于内部知识表示的不稳定性，通过考察LLMs在经过轻微变换后（如拼写错误或重述）表示真实性时的分离性来探究这一问题。", "innovation": "本文创新性地利用轻微的语义不变性扰动，考察LLMs表示真实性的内部表示随样本与预训练数据相似度降低时的退化情况，研究了四类LLM、五个评估数据集和三种知识探针方法下的表现。研究结果揭示了LLMs对真实性表示的内部表示随着样本与预训练数据的相似度降低会崩溃，表明LLMs可能学习了浅层、不稳定的知识表示，这限制了其泛化能力。这一研究将为虚假度量工具的有效性提出了根本性的挑战，并呼吁进一步研究提高学习知识表示的稳健性问题。", "conclusion": "本文的研究发现，LLMs对真实性的内部表示会随着样本与预训练数据的相似度降低而崩溃，这表明LLMs可能学习了仅依赖于具体表面形式的浅层、不稳定的知识表示，这限制了其泛化能力。因此，改善学习知识表示的稳健性是进一步研究的重要方向。"}
{"llm_update_time": "20251015", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.11928", "html_url": "https://arxiv.org/abs/2510.11928", "title": "在数据层面的不一致检测：迈向一致的多语言问答", "title_en": "Discrepancy Detection at the Data Level: Toward Consistent Multilingual Question Answering", "authors": "Lorena Calvo-Bartolomé,Valérie Aldana,Karla Cantarero,Alonso Madroñal de Mesa,Jerónimo Arenas-García,Jordan Boyd-Graber", "background": "多语言问答系统必须在不同语言中确保事实的一致性，尤其是在客观查询中（例如：什么是黄疸？），同时还要考虑到在主观响应中文化差异的影响。现有的多语言问答系统在处理文化敏感问题时（例如：谁在辅助分娩？）可能存在不一致和文化差异，这对确保系统的准确性和文化敏感性构成了挑战。", "innovation": "本文提出了一种名为MIND的用户在环的事实检查管道，用于检测多语言问答知识库中的事实和文化差异。MIND能够突出显示因地区和上下文不同而存在差异的文化敏感问题的答案，有助于识别和解决多语言问答中的不一致性问题，促进了开发更加文化敏感和事实准确的问答系统", "conclusion": "评估结果显示，MIND系统能够可靠地识别多语言问答系统中的不一致性。为了进一步验证MIND的适用性，研究团队还在其他领域的数据集上进行了测试。总体来看，MIND系统在多语言问答系统开发中提供了有力的支持，有助于提升系统的准确性与文化敏感性。"}
{"llm_update_time": "20251015", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.11952", "html_url": "https://arxiv.org/abs/2510.11952", "title": "GRAVITY: 一种基于用户资料生成个性化文本的框架", "title_en": "GRAVITY: A Framework for Personalized Text Generation via Profile-Grounded Synthetic Preferences", "authors": "Priyanka Dey,Daniele Rosa,Wenqing Zheng,Daniel Barcklow,Jieyu Zhao,Emilio Ferrara", "background": "传统的大型语言模型（LLMs）个性化通常依赖于昂贵的人类反馈或交互日志，这限制了其可扩展性，并忽视了用户的深层次属性。现有方法主要依靠人类注释来定制内容，导致成本高昂且难以大规模应用。", "innovation": "提出了GRAVITY框架，这是一种生成基于用户资料的合成偏好数据的方法，用于捕捉用户兴趣、价值观、信念和个性特质。通过整合人口统计学、文化和心理学框架（如霍夫斯泰德的文化维度、施瓦茨的基本价值观、世界价值观调查和大五人格OCEAN特质），GRAVITY能够生成偏好配对，以指导个性化内容的生成。", "conclusion": "实验结果表明，基于用户资料的合成数据可以捕捉更丰富的用户变异、减少对昂贵标注的依赖，并生成更吸引人、以用户为中心的内容，为LLM个性化提供了一条可扩展的道路。"}
{"llm_update_time": "20251015", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.11956", "html_url": "https://arxiv.org/abs/2510.11956", "title": "评估增强检索生成系统对未回答、不可作弊、现实及多跳查询的性能", "title_en": "Evaluating Retrieval-Augmented Generation Systems on Unanswerable, Uncheatable, Realistic, Multi-hop Queries", "authors": "Gabrielle Kaili-May Liu,Bryan Li,Arman Cohan,William Gantt Walden,Eugene Yang", "background": "现实应用场景中，RAG系统常遇到复杂的查询，这些查询的相关信息要么缺失，要么不完整。在这种情况下，RAG系统必须能够拒绝无法回答且不在主题范围内的查询，同时识别检索和多跳推理失败。然而，现有的RAG基准测试很少反映多跳或主题外问题的实际任务复杂性，这些问题往往可以通过不真实的多跳推理（即无需真正的多跳推理即可解决）或仅需简单的事实回忆来“作弊”。这限制了这些基准测试发现现有RAG系统限制的能力。", "innovation": "本文首次提出了一个用于自动生成不可作弊、现实且多跳查询（CRUMQs）的自动且可控制难度的管道，适用于任何语料库和领域。使用该管道在两个流行的RAG数据集上创建了CRUMQs，并通过领先检索增强的大语言模型基准测试实验展示了其有效性。结果表明，与现有的RAG基准测试相比，CRUMQs对RAG系统具有很高的挑战性，且相对于先前的RAG基准差异得分可减少高达81.0%。更广泛地说，该管道提供了一种简单的方法来增强基准测试的难度和现实性，从而驱动更强大的RAG系统开发。", "conclusion": "我们的管道能够在任何语料库和领域中自动生成不可作弊、现实且多跳查询（CRUMQs），并通过基准测试实验展示了其显著提高RAG系统挑战难度的效果。未来的研究可以进一步优化此管道，提高生成CRUMQs的自动化程度和质量。"}
{"llm_update_time": "20251015", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.11967", "html_url": "https://arxiv.org/abs/2510.11967", "title": "通过上下文折叠扩展长时限大语言模型代理", "title_en": "Scaling Long-Horizon LLM Agent via Context-Folding", "authors": "Weiwei Sun,Miao Lu,Zhan Ling,Kang Liu,Xuesong Yao,Yiming Yang,Jiecao Chen", "background": "大语言模型（LLM）代理在处理长时限任务时，由于上下文长度的限制而受到根本性制约。目前的代理通常将整个任务视为单一操作，这限制了它们在处理复杂任务时的灵活性。", "innovation": "本文提出了一种名为Context-Folding的框架，旨在让代理能够主动管理其工作中的上下文。该框架允许代理在处理子任务时主动分支到子轨迹上，完成子任务后重新折叠上下文，保留简洁的结果总结。为此，研究者开发了一种端到端的强化学习框架FoldGRPO，并引入了特定的过程奖励来鼓励有效的任务分解和上下文管理。", "conclusion": "在复杂的长时限任务（Deep Research和SWE）上，使用折叠代理可以在保持或超越反应基线性能的同时，使用比之前依赖于总结上下文管理的模型小10倍的活跃上下文，并显著提升了性能。"}
{"llm_update_time": "20251015", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.11812", "html_url": "https://arxiv.org/abs/2510.11812", "title": "PHANTOM RECALL：当熟悉的谜题愚弄智能模型", "title_en": "PHANTOM RECALL: When Familiar Puzzles Fool Smart Models", "authors": "Souradeep Mukhopadhyay,Rishabh Baral,Nimeesh Mahajan,Samhitha Harish,Aswin RRV,Mihir Parmar,Mutsumi Nakamura,Chitta Baral", "background": "大型语言模型（LLMs），如GPT、Gemini和Claude通常擅长解决经典的逻辑谜题，但它们的回答背后有多少真实的推理呢？最近的研究表明，这些模型往往依赖于记忆中的模板而非从基本原理进行推理。当谜题稍作修改，它们的表现就会骤然下降，显示出其惊人的脆弱性。", "innovation": "本文提出了一种新的基准——PHANTOM RECALL，它包括25个著名的逻辑谜题以及149个精心设计的变异题，这些变异题保持了推理结构但更改了表面细节和解决方案。本文评估了11种领先的LLMs，并识别出一个反复出现的失败模式——幽灵回忆，即模型自信地重现记忆中的解决方案或与改动后的情景不再匹配的错误推理。为了探查并缓解这一问题，研究贡献了三个工具：（i）自动生成逻辑等价性判断来检测推理不匹配，（ii）精细推理错误分类法，（iii）基于这些类别指导的提示框架。", "conclusion": "尽管在未修改的谜题上模型的准确率接近完美，但在修改后的谜题上它们的表现显著劣于人类，展示了‘幽灵回忆’和过度扩展的现象。我们的研究揭示了一个关键局限性：LLMs往往在上下文线索变化时无法重新推理，强调了语言流畅性和逻辑理解之间的差距。"}
{"llm_update_time": "20251015", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.11496", "html_url": "https://arxiv.org/abs/2510.11496", "title": "AndesVL技术报告：一种高效的移动侧多模态大语言模型", "title_en": "AndesVL Technical Report: An Efficient Mobile-side Multimodal Large Language Model", "authors": "Zhiwei Jin,Xiaohui Song,Nan Wang,Yafei Liu,Chao Li,Xin Li,Ruichen Wang,Zhihao Li,Qi Qi,Long Cheng,Dongze Hao,Quanlong Zheng,Yanhao Zhang,Haobo Ji,Jian Ma,Zhitong Zheng,Zhenyi Lin,Haolin Deng,Xin Zou,Xiaojie Yin,Ruilin Wang,Liankai Cai,Haijing Liu,Yuqing Qiu,Ke Chen,Zixian Li,Chi Xie,Huafei Li,Chenxing Li,Chuangchuang Wang,Kai Tang,Zhiguang Zhu,Kai Tang,Wenmei Gao,Rui Wang,Jun Wu,Chao Liu,Qin Xie,Chen Chen,Haonan Lu", "background": "近年来，基于云的多模态大规模语言模型（MM-LLMs）如QwenVL、InternVL、GPT-4o、Gemini和Claude Sonnet等取得了卓越的性能，其参数规模达到数十亿级别，并在各种开放源代码基准中表现出色。然而，这些模型在计算能力、内存和能耗方面仍然无法满足移动设备等边缘设备的需求。本论文旨在介绍AndesVL，这是一种基于Qwen3的LLM和多种视觉编码器构建的移动侧MM-LLM，包含参数从0.6B到4B的不同规模模型。AndesVL通过优化架构、训练流程和数据，在多个领域如图文理解、推理和数学等中已达到顶级水平，性能与现有类似规模模型相当。此外，AndesVL引入了1+N LoRA架构及Quantization-Aware LoRA Fine-Tuning (QALFT)框架，提高了模型在移动侧部署中的适应性和压缩效率，并采用了自定义的推测性解码和压缩策略，显著提升了性能和资源使用效率。", "innovation": "1. 通过自定义的1+N LoRA架构和Quantization-Aware LoRA Fine-Tuning (QALFT)框架，使AndesVL在移动设备上的任务适配和模型压缩更加高效。\n2. 利用OKV缓存淘汰算法结合定制化推测性解码和压缩策略，显著提升了AndesVL在 MediaTek Dimensity 9500芯片上的解码速度和内存使用效率。", "conclusion": "AndesVL在多种开放源代码基准和特定任务中达到了顶级性能，并通过创新的架构和优化策略显著提升了移动设备上的部署性能，对于追求高效和低功耗的多模态大语言模型部署具有重要价值。"}
{"llm_update_time": "20251015", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.11944", "html_url": "https://arxiv.org/abs/2510.11944", "title": "TopoAlign：一种通过拓扑分解对齐代码与数学的框架", "title_en": "TopoAlign: A Framework for Aligning Code to Math via Topological Decomposition", "authors": "Yupei Li,Philipp Borchert,Gerasimos Lampouras", "background": "现有的大型语言模型（LLMs）在处理非正式和正式推理方面表现出色，但是它们在自动形式化任务上仍然存在局限性。自动形式化是将非正式推理转换为正式数学陈述的技术，有助于将LLMs的非正式推理与形式证明助手相结合，增强机器验证能力和降低错误概率。然而，当前的数学LLMs受到训练数据规模不足的限制，特别是非正式和正式数学陈述之间的对齐数据匮乏，这妨碍了模型的有效迁移学习。目前的模型虽然能够在自然语言指令下生成代码，但代码和正式数学之间的结构和语法差异限制了有效迁移学习。", "innovation": "本文提出了TopoAlign框架，该框架将代码分解为文档字符串、主函数和依赖函数，并将其重新组合成结构上与形式数学陈述类似的新组件。这样生成的对齐代码数据可以直接用于训练数学LLMs，而无需额外的人工注释。作者使用最新的DeepSeek-Math和Herald模型在minif2f、Putnam和ProofNet基准测试上进行了评估，结果表明TopoAlign框架在DeepSeek-Math模型上表现显著提升，在BEq@10和typecheck@10等指标上分别提升了17.77%和68.82%的性能。即使没有引入新的数学知识，对于Herald模型，TopoAlign也在BEq@10和typecheck@10上分别提高了0.12%和1.09%，表明使用对齐的代码数据进行训练对于专业模型也是有益的。", "conclusion": "TopoAlign框架通过利用广泛可用的代码仓库作为训练资源，成功地对齐了代码与数学表述，证明了这种方法对于拓宽数学LLMs的适用范围和提升其性能的有效性，即使对于专门化模型也有显著益处。"}
{"llm_update_time": "20251015", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.11958", "html_url": "https://arxiv.org/abs/2510.11958", "title": "直接多令牌解码", "title_en": "Direct Multi-Token Decoding", "authors": "Xuan Luo,Weizhi Wang,Xifeng Yan", "background": "自编码解码器成为大型语言模型（LLMs）的标准架构以来，由于其强大的性能，越来越多的研究关注预训练的LLMs的不同层级可能具有不同的功能，如早期层专注于理解输入上下文，中间层处理任务特定的处理，而晚期层将抽象表示转换为输出令牌。研究者提出了一种直接多令牌解码（DMTD）的假设，认为一旦输入已经被早期和中间层处理，晚期层便可以通过处理隐藏状态生成多个令牌，从而避免多次通过早期和中间层。与推测性解码不同，这种方法没有引入额外参数或辅助机制，仅依靠已经训练的数据。", "innovation": "提出了直接多令牌解码（DMTD）的方法，这种方法能够在处理输入上下文完成后，通过晚期层直接生成多个令牌，从而加快解码速度，减少训练复杂度。DMTD方法在仅微弱影响性能的同时，实现了约2倍的解码速度提升，且预计随着训练数据集的增加，性能将有所改善。此外，这种方法不需要引入参数或后生成验证，具有较高的实用性与应用潜力。", "conclusion": "基于训练有限数据集的微调DMTD Qwen3-4B模型，已经取得了令人鼓舞的初步成果，展示了约2倍的解码速度提升且只有一点点性能损失。随着训练数据集的增加，预计其性能将得到进一步提升。"}
{"llm_update_time": "20251015", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.11683", "html_url": "https://arxiv.org/abs/2510.11683", "title": "边界指导的策略优化算法（BGPO）：为扩散大型语言模型的记忆高效强化学习", "title_en": "Boundary-Guided Policy Optimization for Memory-efficient RL of Diffusion Large Language Models", "authors": "Nianyi Lin,Jiajie Zhang,Lei Hou,Juanzi Li", "background": "将强化学习（RL）应用于扩散大型语言模型（dLLMs）的一个关键挑战是其不可处理的似然函数，这些函数对于RL目标至关重要，因此每一步训练都需要相应的近似。现有方法通过定制的蒙特卡罗（MC）采样来近似对数似然值为其证据下界（ELBOs），但在这个过程中，所有MC样本的前向计算图都需要保留，以进行非线性项梯度计算，这导致了显著的内存开销。这种限制限制了可行的样本大小，导致似然近似不精确，并最终扭曲了RL目标。", "innovation": "提出了一种名为BGPO（边界指导的策略优化）的记忆高效RL算法，该算法最大化了一个特别构建的基于ELBO目标的下界。这个下界被精心设计以满足两个关键性质：（1）线性：它是线性求和形式，其中每个项仅依赖于一个MC样本，从而允许样本间梯度累积并确保常量内存使用；（2）等价性：此下界的值和梯度与基于ELBO目标的在线策略学习中的值和梯度相等，也使其成为原RL目标的有效近似。这些特性允许BGPO采用较大的MC样本，从而获得更准确的似然近似和增强的RL目标估计，最终提高了性能。实验结果显示BGPO在数学问题解决、代码生成和规划任务中显著优于之前的RL算法。", "conclusion": "BGPO通过构建特殊的下界，使得其在无内存限制的情况下优化策略，从而实现了更精确的RL目标估计，且在实际的应用任务中表现出了显著的优势。"}
{"llm_update_time": "20251015", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.11997", "html_url": "https://arxiv.org/abs/2510.11997", "title": "SAGE：一种基于上下文知识的自顶向下自底向上的用户模拟器用于多轮AGент评估", "title_en": "SAGE: A Top-Down Bottom-Up Knowledge-Grounded User Simulator for Multi-turn AGent Evaluation", "authors": "Ryan Shea,Yunan Lu,Liang Qiu,Zhou Yu", "background": "多轮互动代理的评估具有挑战性，因为需要进行人工评估。现有的替代方法是使用模拟用户进行评估，但这些方法通常建模的是通用用户，忽略了捕捉现实行为所需的领域特定原则。", "innovation": "提出了SAGE，一种新型的用户模拟框架，以评估多轮代理。SAGE将业务逻辑中的自顶向下知识（如理想客户画像）与业务代理基础设施中的自底向上知识（如产品目录、FAQ和知识库）结合，生成更加现实和多样化的交互，并识别出高达33%的代理错误。", "conclusion": "通过实证评估表明，该方法产生的交互更加现实和多样化，同时识别出更多的代理错误，突显了其作为支持错误查找和迭代代理改进的评估工具的有效性。"}
{"llm_update_time": "20251015", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.12001", "html_url": "https://arxiv.org/abs/2510.12001", "title": "生成逻辑等价问题", "title_en": "Generate Logical Equivalence Questions", "authors": "Xinyu Wang,Haoming Yu,Yicheng Yang,Zhiyuan Li", "background": "在高等教育中，学术不端行为不容忍，然而随着在线教学和学习的普及，剽窃现象变得越来越普遍。自动问题生成（AQG）提供了一种潜在的解决方案，通过为每个学生生成独特的题目来减少抄袭。此外，AQG 还可以提供大量的练习题目。我们的 AQG 专注于为计算机科学新生的离散数学基础课程生成逻辑等价题目。", "innovation": "现有离散数学逻辑等价题目生成器在满足用户定义约束时会产生所有命题，导致生成效率低下且题目难度不一致。为此，我们提出了一种新的方法，该方法使用形式语言定义逻辑等价题目，将其转化为两组生成规则，并开发了一个线性时间算法来生成题目。", "conclusion": "我们通过两组实验评估了 AQG。第一组实验涉及一组学生完成了由我们系统生成的问题，统计分析表明，这些题目与教科书题目有相似的准确性。第二组实验评估了解决我们生成的问题、教科书问题和多个大型语言模型生成的问题所需步骤的数量，结果表明我们生成的问题难度与教科书问题相似，证实了我们 AQG 的质量。"}
{"llm_update_time": "20251015", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.12036", "html_url": "https://arxiv.org/abs/2510.12036", "title": "人类标签变异与模型公平性之间的相互作用", "title_en": "On the Interplay between Human Label Variation and Model Fairness", "authors": "Kemal Kurniawan,Meladel Mistica,Timothy Baldwin,Jey Han Lau", "background": "人类标签变异（HLV）对模型公平性的影晌尚未被充分研究。该研究通过对比使用多数投票标签与多种HLV方法进行训练，探讨了两种做法之间的关系。", "innovation": "研究创新地采用了一种新的比较方法，即通过对比使用多数投票标签与多种人类标签变异方法来探究它们对模型公平性的影响。", "conclusion": "研究结果显示，在未进行显式去偏见处理的情况下，人类标签变异训练方法对模型公平性具有积极影响。"}
{"llm_update_time": "20251015", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.11986", "html_url": "https://arxiv.org/abs/2510.11986", "title": "假说：形式化数学推理中被忽视的一步", "title_en": "Conjecturing: An Overlooked Step in Formal Mathematical Reasoning", "authors": "Jasivan Alex Sivakumar,Philipp Borchert,Ronald Cardenas,Gerasimos Lampouras", "background": "自动形式化是将非正式的数学陈述表达成正式语言的过程，但往往被视为直接翻译。然而，这忽略了重要的前一步：构建假说。许多数学问题在没有首先构建一个结论（如显式答案或具体界）的情况下无法直接进行形式化。现有的大型语言模型（LLMs）已经在自动形式化方面挣扎，而对其构建假说能力的评估往往与自动形式化或证明评价交织在一起，因此很难理解其效果。为了填补这一空白，研究者们扩充了现有数据集，创建了ConjectureBench，并重新设计了评估框架和指标，专门用于测量LLMs的构建假说能力和在自动形式化管道中的表现。这一评估表明，基础模型如GPT-4.1和DeepSeek-V3.1在考虑假说评估时，其自动形式化表现被严重高估了。同时，假说不应被假定提供。研究者设计了推理时方法Lean-FIRe以提高假说和自动形式化，不仅首次实现了13个PutnamBench问题和7个问题的端到端自动形式化，还展示了衡量自动形式化性能需要独立对待构建假说任务，并探索如何正确将其整合进入自动形式化过程的重要性。最后，研究提供了一些前瞻性的建议，引导未来研究在形式数学推理中重视构建假说这一被忽视的重要步骤。", "innovation": "基于现有的大型语言模型（LLMs）在自动形式化和构建假说方面的局限性，研究者创建了ConjectureBench数据集，并设计了评价框架和指标来单独评估构建假说的能力及在自动形式化中的整合。方法Lean-FIRe首次实现了基础模型端到端的自动形式化，强调了独立处理构建假说任务的必要性，并提出了未来的潜在研究方向。", "conclusion": "研究结果表明，虽然LLMs拥有生成准确假说的必要知识，但要提高自动形式化性能，必须将构建假说视为独立任务，并进一步研究如何正确地在自动形式化过程中进行整合。未来需要在形式数学推理中重视构建假说这一被忽视的重要步骤，以进一步提升模型的性能。"}
{"llm_update_time": "20251015", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.12029", "html_url": "https://arxiv.org/abs/2510.12029", "title": "CPR：使用矫正提示精炼降低大型语言模型的幻觉", "title_en": "CPR: Mitigating Large Language Model Hallucinations with Curative Prompt Refinement", "authors": "Jung-Woo Shim,Yeong-Joon Ju,Ji-Hoon Park,Seong-Whan Lee", "background": "近年来，大型语言模型（LLMs）的性能显著提升，能够在多种场景下生成流畅的回复。然而，这些模型有时会产生看起来合理但实际上错误的“幻觉”事实，这损害了用户的信任。往往被忽视但频繁发生的这些问题背后的原因之一是用户提供的提示不清晰或结构不良，导致模型基于假设而非实际情况生成回复。", "innovation": "本文提出了一种名为Curative Prompt Refinement (CPR) 的模块化框架，用于修正不清晰的提示。CPR可以1）清理结构不良的提示，2）生成额外的信息性任务描述，以使模型更准确地理解用户的意图。通过在小型语言模型上进行微调，CPR能够显著提高生成质量并减少幻觉现象。实验证明，使用CPR的提示比未使用CPR的原始提示在生成结果上提高了90%以上的胜率。", "conclusion": "应用CPR后，生成内容的质量明显提高，幻觉现象得到有效缓解。实证研究进一步表明，CPR可以在保持模型性能的同时显著减少错误信息的产生，提升总体生成质量。"}
{"llm_update_time": "20251015", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.12041", "html_url": "https://arxiv.org/abs/2510.12041", "title": "使用输入端推理时缩放提升文本转图像生成", "title_en": "Improving Text-to-Image Generation with Input-Side Inference-Time Scaling", "authors": "Ruibo Chen,Jiacheng Pan,Heng Huang,Zhenheng Yang", "background": "最近的文本转图像（T2I）生成技术取得了显著进展，但在处理简单或欠具体的提示时，现有模型往往表现不佳，导致图像与文本的对齐、视觉质量和美观度不理想。", "innovation": "本文提出了一种基于大型语言模型（LLMs）的提示重写框架，该框架可以在输入到T2I主干前优化用户输入。该方法引入了精心设计的奖励系统和迭代直接偏好优化（DPO）训练管道，使重写器能够在无需监督微调数据的情况下增强提示。本文在多个T2I模型和基准上评估了此方法，并展示了重写器在不同T2I主干间的强泛化能力以及随着大LLM容量的增加，性能增益的可扩展性。", "conclusion": "研究结果表明，提示重写是改善T2I系统的有效、可扩展且模型无关的方法。未来计划发布该方法的代码和预训练提示重写器。"}
{"llm_update_time": "20251015", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.12032", "html_url": "https://arxiv.org/abs/2510.12032", "title": "Multi-stage Prompt Refinement for Mitigating Hallucinations in Large Language Models", "title_en": "Multi-stage Prompt Refinement for Mitigating Hallucinations in Large Language Models", "authors": "Jung-Woo Shim,Yeong-Joon Ju,Ji-Hoon Park,Seong-Whan Lee", "background": "近年来，大型语言模型（LLMs）在自然语言理解和生成任务中达到了很高的性能水平。然而，这些模型仍然面临着生成错误但听起来合理信息（幻觉）的挑战。幻觉产生的原因很多，但之前对于不规范提示词、含义模糊的提示词、语法错误或信息不完整等问题的影响研究较少。此类问题亟待解决以提升模型的可靠性。", "innovation": "本文提出了一种名为Multi-stage Prompt Refinement (MPR)的框架，用于系统性地改善不规范的提示词问题。MPR框架可以在多个阶段中使用小型语言模型（SLMs）进行微调，针对标点符号错误、拼写错误和术语使用不当等问题进行改进。此外，MPR还通过增加上下文信息和自我反思机制实现了提示词的逐步优化，优先处理相关性最高的输入。实验结果显示，使用MPR精炼的提示词在幻觉基准测试中的胜率超过85%，展示了其有效减少幻觉并提高LLM输出准确性的能力。有趣的是，这种框架可以与现有的后处理幻觉缓解框架结合使用，进一步增强了其灵活性和适用性。", "conclusion": "MPR提供了一种轻量级且可适应的解决方案，以增强大型语言模型在各类领域的可靠性。"}
{"llm_update_time": "20251015", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.12040", "html_url": "https://arxiv.org/abs/2510.12040", "title": "在大型语言模型中进行幻觉检测的不确定性量化：基础、方法和未来方向", "title_en": "Uncertainty Quantification for Hallucination Detection in Large Language Models: Foundations, Methodology, and Future Directions", "authors": "Sungmin Kang,Yavuz Faruk Bakman,Duygu Nur Yaldiz,Baturalp Buyukates,Salman Avestimehr", "background": "随着大型语言模型（LLMs）的迅速发展，自然语言处理领域的格局发生了根本性的变化，使其在问答、机器翻译和文本总结等多个领域取得了突破。然而，LLMs在实际应用中的部署引起了可靠性与可信度的问题，因为它们容易产生尽管听起来合理但却是事实错误的输出（幻觉）。不确定性量化（UQ）已成为应对这一问题的核心研究方向，UQ提供了评估模型生成可靠性的基本原则和措施。这篇论文回顾了UQ的基础知识，包括其正式定义、知识性和随机性不确定性之间的传统区分，并探讨了如何将这些概念应用于LLMs。论文还详细介绍了UQ在幻觉检测中的作用，并系统地分类了现有方法，提供了实验证据。最后，论文指出了当前的局限性，并提出了未来的研究方向，从而更清晰地描绘了LLMs不确定性量化在幻觉检测中的现状图景。", "innovation": "该论文系统地介绍了不确定性量化的基础及其在幻觉检测中的应用，并详细分类了多种现有方法，提供了一定的实验证据支持。此外，它指出了当前研究的局限性，并对未来的研究方向提出了建设性的建议。", "conclusion": "不确定性量化在识别和改进大型语言模型生成可靠性方面的潜力有所体现，但目前仍存在一些局限性。未来的研究可以着眼于解决这些局限性，例如开发更有效的不确定性量化方法和增强模型的鲁棒性。"}
{"llm_update_time": "20251015", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.12044", "html_url": "https://arxiv.org/abs/2510.12044", "title": "层次对齐：大型语言模型功能性层特化的手术微调", "title_en": "Hierarchical Alignment: Surgical Fine-Tuning via Functional Layer Specialization in Large Language Models", "authors": "Yukun Zhang,Qi Dong", "background": "现有的大型语言模型（LLMs）对齐技术，如直接偏好优化（DPO），通常将模型视为一个整体，对所有层施加统一的优化压力。这种做法未能充分考虑到变压器架构中不同层的功能专业化，这些层各自负责从语法到抽象推理的多种任务。", "innovation": "本文提出了层次对齐（Hierarchical Alignment）这一新颖方法，它将目标化的DPO应用于模型不同功能块的层，包括局部（语法）、中间（逻辑）和全局（事实性）层。通过在最先进的模型（如Llama-3.1-8B和Qwen1.5-7B）上使用LoRA进行精确微调的一系列实验，研究结果表明，在大型语言模型中采用这种策略可以实现显著的且可预测的改进。", "conclusion": "层次对齐策略能够有效避免标准DPO中出现的“对齐税”，即提高流畅性的同时不影响逻辑推理。这些发现为模型对齐提供了一条更高效、可控和可解释的道路，证明在从整体优化转向结构感知的手术微调方面有巨大的潜力，以构建更先进和可靠的LLMs。"}
{"llm_update_time": "20251015", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.12051", "html_url": "https://arxiv.org/abs/2510.12051", "title": "APCE: 自适应渐进而扩内容选择扩展用于长上下文处理", "title_en": "APCE: Adaptive Progressive Context Expansion for Long Context Processing", "authors": "Baisub Lee,Sanghyun Byun,Mohanad Odema,Jung Guack,Jacob Song,Woo Seong Chung", "background": "部署有效的长上下文Transformer模型（LCTMs）面临两个关键挑战：（1）由于二次自注意力导致的记忆占用不断增长，以及随序列长度增加呈线性增长的KV缓存；（2）上下文旋转现象，即随着上下文长度增加，Transformer架构的性能下降。鉴于输入间的共享依赖，一个自然的问题是：我们是否可以通过有选择地处理最重要的输入片段来解决这些问题，从而（a）减少内存占用，并（b）减轻上下文旋转效应？", "innovation": "该论文提出了APCE，一种基于低维语义相似性匹配当前查询来选择最重要的输入片段的上下文感知解决方案。通过直接操作输入，APCE摆脱了对底层硬件或CUDA环境的严格依赖，提供了一种兼容且可扩展到各种部署系统的解决方案。实验结果表明，APCE相比全密基线在摘要任务上的性能更优或相当，使用输入序列中50%-70%的部分，实现了KV缓存和自注意力记忆效率的提高，", "conclusion": "该研究希望激发更多针对LCTMs的上下文感知效率解决方案的研究，用于其他相关的长上下文任务。"}
{"llm_update_time": "20251015", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.12083", "html_url": "https://arxiv.org/abs/2510.12083", "title": "基于AI的行为健康安全过滤器及数据集在文本对话中识别精神健康危机", "title_en": "An AI-Based Behavioral Health Safety Filter and Dataset for Identifying Mental Health Crises in Text-Based Conversations", "authors": "Benjamin W. Nelson,Celeste Wong,Matthew T. Silvestrini,Sooyoon Shin,Alanna Robinson,Jessica Lee,Eric Yang,John Torous,Andrew Trister", "background": "大型语言模型在处理精神健康紧急情况时往往表现不佳，提供的建议可能有害或不适当，且可能诱发破坏性行为。已有研究和工具如OpenAI Omni Moderation Latest和NVIDIA NeMo Guardrails未能有效处理这一问题。", "innovation": "该论文提出了Verily的行为健康安全过滤器（VBHSF），并在两个数据集中进行了评估。VBHSF的性能在特殊危机类别检测上表现出色，特别是在针对NVIDIA Aegis AI内容安全性数据集2.0时。VBHSF在各种精神健康危机类别上的敏感性显著高于NeMo和最近的OpenAI Omni Moderation，提高了医疗应用中的救助率。", "conclusion": "VBHSF在不同数据集中的表现均维持了较高的敏感性和较好的准确性，特别是在避免漏诊方面表现突出，为识别精神健康危机提供了新的技术和工具。"}
{"llm_update_time": "20251015", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.12115", "html_url": "https://arxiv.org/abs/2510.12115", "title": "跨语言领域适应中多语言知识获取动态追踪：以英日生物医学适应案例研究为例", "title_en": "Tracing Multilingual Knowledge Acquisition Dynamics in Domain Adaptation: A Case Study of English-Japanese Biomedical Adaptation", "authors": "Xin Zhao,Naoki Yoshinaga,Yuma Tsuta,Akiko Aizawa", "background": "多语言领域适应（ML-DA）被广泛用于将新领域的知识跨语言迁移到大型语言模型（LLMs）中。尽管提出了许多方法来提高领域适应性，但多语言知识获取的机制，即领域知识在单一语言中的学习和跨语言的转移，仍被研究不足。现有研究由于使用的训练和评估数据集的知识覆盖面不匹配，导致性能欠佳，尤其是在资源有限的情况下。这项工作研究了LLMs在多语言领域适应过程中的学习动态。", "innovation": "提出了AdaXEval，一种自适应评估方法，通过从与训练使用的双语领域语料库相同的语料库中构建多选题问答数据集，直接研究多语言知识获取。通过使用多样化的数据配方持续训练LLMs，追踪LLMs如何获取领域事实，并指出从领域训练数据到知识转化过程背后的机制。", "conclusion": "对13B英日双语LLM的实验结果表明，尽管有高质量的双语语料库，跨语言迁移仍然是一个挑战。代码已公开。"}
{"llm_update_time": "20251015", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.12110", "html_url": "https://arxiv.org/abs/2510.12110", "title": "深度关联，高度创意：一种简单有效的大型语言模型评估指标", "title_en": "Deep Associations, High Creativity: A Simple yet Effective Metric for Evaluating Large Language Models", "authors": "Ziliang Qiu,Renfen Hu", "background": "评估大型语言模型（LLMs）的创造力是一个关键的研究领域，但数据污染和昂贵的人工评估往往阻碍了研究进展。在借鉴人类创造力评估方法的基础上，本文提出了一种新的评估方法，即在要求LLMs生成平行关联链的过程中评估其创造力，以此来减轻数据污染的风险，并提供了一种简单且高效的评估方法。", "innovation": "本文提出了PACE（Parallel Association Chains for Evaluation），通过要求LLMs生成平行关联链来评估其创造力。这种评估方法与Chatbot Arena Creative Writing排名表现出较强的相关性（Spearman's ρ = 0.739，p < 0.001）。此外，进行了LLMs与人类创造力的对比分析，结果显示专业人类的表现始终优于LLMs，而高表现的LLMs得分可以与人类平均水平相当。语言分析还揭示了人类和LLMs在关联过程中呈现逐渐减少的明确性趋势，但人类的关联模式多样性更高。", "conclusion": "总之，PACE提供了一个简单且有效的大型语言模型评估指标，其结果与Chatbot Arena Creative Writing排名高度相关。进一步的对比分析显示，尽管有些高表现的LLMs可以达到人类平均水平的创造力水平，但专业的人类从业者在创造力方面仍然表现出更强的能力。此外，语言分析进一步揭示了人类和LLMs在创造力表达上的不同趋势，包括明确性的变化和关联模式的多样性。"}
{"llm_update_time": "20251015", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.12133", "html_url": "https://arxiv.org/abs/2510.12133", "title": "SafeMT：多轮对话安全评估", "title_en": "SafeMT: Multi-turn Safety for Multimodal Language Models", "authors": "Han Zhu,Juntao Dai,Jiaming Ji,Haoran Li,Chengkun Cai,Pengcheng Wen,Chi-Min Chan,Boyuan Chen,Yaodong Yang,Sirui Han,Yike Guo", "background": "随着多模态大型语言模型（MLLMs）的广泛应用，安全问题变得越来越重要。多轮对话在日常交互中更为普遍，其风险比单模态提示更大。然而，现有的基准测试没有充分考虑这种情况。", "innovation": "我们引入了SafeMT，这是一种基准测试，包含来自有害查询伴随图像生成的对话样本，并涵盖了17种不同的场景和四种脱狱方法。此外，我们提出了安全指数（SI）来评估MLLMs在对话中的整体安全性。通过基准测试评估了17个模型的安全性，发现不利对话中回合数量越多，成功攻击的风险越高。我们还提出了能够检测对话中隐藏的恶意意图并为MLLMs提供相关安全政策的对话安全审核员。", "conclusion": "实验结果显示，该审核员比现有防护模型更有效地减少了多轮ASR。"}
{"llm_update_time": "20251015", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.12116", "html_url": "https://arxiv.org/abs/2510.12116", "title": "理解模态差距：大规模语音语言模型的语音-文本对齐机制的实证研究", "title_en": "Understanding the Modality Gap: An Empirical Study on the Speech-Text Alignment Mechanism of Large Speech Language Models", "authors": "Bajian Xiang,Shuaijiang Zhao,Tingwei Guo,Wei Zou", "background": "端到端的大型语音语言模型在对话生成方面表现出色，但通常在语义理解基准测试中不如传统的流水线系统。系统实验表明，尽管在语音-文本对齐训练后文本输入性能有所下降，语音输入与文本输入间的性能差距更加显著，我们称之为模态差距。", "innovation": "通过分析粗粒度和细粒度的语音和文本表示，揭示了粗粒度层中语音和文本表示方向逐渐对齐而幅值逐渐分离的现象，同时发现表示相似性与模态差距高度相关。在细粒度层中，发现文本和语音表示之间存在自发的令牌级对齐模式并据此引入了对齐路径分数来量化令牌级对齐质量。此外，设计了针对关键令牌的角度投影和长度归一化策略，这些策略展示了改善语音输入正确性的方法。", "conclusion": "本研究首次系统地实证分析了大型语音语言模型的模态差距及对齐机制，提供了理论和方法论指导，以期优化未来的模型。"}
{"llm_update_time": "20251015", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.12164", "html_url": "https://arxiv.org/abs/2510.12164", "title": "平行推理综述", "title_en": "A Survey on Parallel Reasoning", "authors": "Ziqi Wang,Boye Niu,Zipeng Gao,Zhi Zheng,Tong Xu,Linghui Meng,Zhongli Li,Jing Liu,Yilong Chen,Chen Zhu,Hua Wu,Haifeng Wang,Enhong Chen", "background": "随着大型语言模型（LLMs）能力的增强，平行推理作为一种新的推理范式出现，通过同时探索多条思路来增强推理的鲁棒性，并在此过程中确定最终答案。这种方法因其能克服标准顺序方法脆弱性而在实践中得到广泛应用。", "innovation": "本文对平行推理进行了调研和总结，定义了平行推理的概念，并澄清了它与类似概念（如思维链）的区别。此外，通过一个新颖的分类体系（包括非交互式推理、交互式推理和效率导向的解码策略），详细讨论了高级技术，探讨了各种应用场景，并强调了核心挑战。", "conclusion": "文章指出了平行推理的核心挑战，并提出潜在研究方向，希望为初学者和未来的研究提供有用的道路图。相关资源可在此处获得。 https://this-http-url/"}
{"llm_update_time": "20251015", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.12137", "html_url": "https://arxiv.org/abs/2510.12137", "title": "Credal Transformer: 一种量化和减轻大型语言模型幻觉的原理性方法", "title_en": "Credal Transformer: A Principled Approach for Quantifying and Mitigating Hallucinations in Large Language Models", "authors": "Shihao Ji,Zihui Song,Jiajie Huang", "background": "大型语言模型（LLMs）可能会虚构，生成虽然自信但却是事实性错误的断言。这种现象归因于变压器中的Softmax函数，它通过将模棱两可的注意力分数压缩成单一的概率分布来创建“人为的确定性”，在每层过程中都会舍弃不确定性信息。这一机制导致了模型自信度的过高，即使生成的信息是错误的。因此，需要一种新的方法来解决这一问题，减少模型的虚构行为，并提高模型的可靠性。", "innovation": "本文提出了一种名为Credal Transformer的新架构，通过引入基于证据理论的Credal注意力机制（CAM）来替代标准注意力。CAM生成一个“信念集合”，即多个分布集合，集合的大小直接衡量模型的不确定性。此机制通过重新概念化注意力分数为狄利克雷分布的证据质量实现：足够的证据恢复标准注意力，而不足的证据产生分散分布，表示模棱两可。实验结果显示，Credal Transformer能够识别出分布外的输入、量化不确定性，并在回答无法回答的问题时显著减少自信错误，通过避免做出结论来降低错误率。", "conclusion": "本文提出了一个全新的架构来减轻幻觉问题，并提供了一种将不确定性量化直接集成到模型设计中的设计范式，为更可靠的AI奠定了基础。"}
{"llm_update_time": "20251015", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.12181", "html_url": "https://arxiv.org/abs/2510.12181", "title": "从知识到治疗：大型语言模型辅助的生物医学概念表示在药物重新利用中的应用", "title_en": "From Knowledge to Treatment: Large Language Model Assisted Biomedical Concept Representation for Drug Repurposing", "authors": "Chengrui Xiang,Tengfei Ma,Xiangzheng Fu,Yiping Liu,Bosheng Song,Xiangxiang Zeng", "background": "药物重新利用在加速疾病治疗发现中扮演着关键角色，尤其是在处理复杂和罕见疾病的领域。生物医学知识图谱(KGs)因其丰富的临床关联性而被广泛用于支持此任务。然而，现有的方法在很大程度上忽视了现实世界实验室中的常识生物医学概念知识，例如机制先验，表明某些药物与特定治疗方案本质上不兼容。", "innovation": "本文提出了LLaDR，一种大型语言模型辅助的药物重新利用框架，改善了生物医学概念在KG中的表示。具体来说，这项技术从大型语言模型(LLMs)中提取具有语义增强的治疗相关文本表示，并用于微调知识图嵌入(KGE)模型。通过将治疗相关知识注入KGE，LLaDR极大地改善了生物医学概念的表示，增强了对未研究或复杂的适应症的语义理解。基于基准的实验表明，LLaDR在不同场景中实现了最先进的性能，案例研究表明其稳健性和有效性。", "conclusion": "实验表明，LLaDR在不同的场景中实现了最先进的性能，并且通过阿尔茨海默病案例研究进一步证明了其稳健性和有效性。代码可从此处获取。"}
{"llm_update_time": "20251015", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.12185", "html_url": "https://arxiv.org/abs/2510.12185", "title": "不接轨：揭开音频聊天模型的时间偏差", "title_en": "Not in Sync: Unveiling Temporal Bias in Audio Chat Models", "authors": "Jiayu Yao,Shenghua Liu,Yiwei Wang,Rundong Cheng,Lingrui Mei,Baolong Bi,Zhen Xiong,Xueqi Cheng", "background": "大型音频语言模型（LALMs）在音频理解和多模态推理方面得到广泛应用，但它们在时间戳预测方面的表现仍较少被研究。这项研究表明了LALMs中普遍存在的时间偏差问题，即在回答关于事件发生时间的问题时，模型会预测出系统性偏移实际时间的时间戳，且这种偏差会随着音频长度增加而增加，不同事件类型和位置间的偏差也存在差异性。", "innovation": "研究首次系统地探讨了LALMs的时间偏差，引入了时间偏差指数（TBI），这是一种衡量预测事件时间系统性错位的新方法，并配合可视化框架为这个问题提供了定量和可视化解决方案。", "conclusion": "这项研究揭示了当前LALMs中存在的基本时间偏差限制，并呼吁开发时间上更稳健的架构，以改善模型的时间戳预测能力。"}
{"llm_update_time": "20251015", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.12167", "html_url": "https://arxiv.org/abs/2510.12167", "title": "向连续空间推理的推理时缩放", "title_en": "Towards Inference-time Scaling for Continuous Space Reasoning", "authors": "Minghan Wang,Thuy-Trang Vu,Ehsan Shareghi,Gholamreza Haffari", "background": "通过多次样本生成与过程奖励模型（PRM）或结果奖励模型（ORM）重新排序相结合的推理时缩放技术，在大型语言模型基于文本的推理中已被证明是有效的。本文研究了此类已建立的技术能否成功地适应连续空间中的推理，并使用COCONUT（Hao et al. 2024）连续空间推理LM作为基础模型。通过基于dropout的采样来生成多样化的推理路径被证明是可行的。通过生成样本的Pass@N分析表明，这种技术在连续空间中的应用有可能获得类似于离散空间中观察到的性能提升，但同时也指出了在连续思维空间中实现这种提升的独特挑战。", "innovation": "本文使用基于dropout的采样方法生成多样化的推理路径来提升连续空间推理LM的性能；通过Pass@N分析显示了潜在的显著性能提升；发现当前在连续思维空间中应用PRM和ORM的独特挑战；强调在连续推理模型训练框架中需要明确引入用于推理时正误区分的归纳偏置特性。", "conclusion": "现有的连续思考表示方法中的关键归纳偏置缺失是当前限制的关键原因，建议未来的工作不仅要优化准确性，还要明确整合在推理时可用于区分正确和错误想法的归纳偏置。"}
{"llm_update_time": "20251015", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.12217", "html_url": "https://arxiv.org/abs/2510.12217", "title": "HALF: 基于部署的公平性评估，考虑潜在危害", "title_en": "HALF: Harm-Aware LLM Fairness Evaluation Aligned with Deployment", "authors": "Ali Mekky,Omar El Herraoui,Preslav Nakov,Yuxia Wang", "background": "大型语言模型（LLMs）在临床决策支持、法律分析、招聘和教育等重要领域得到广泛应用，因此在部署前评估其公平性和偏见至关重要。然而，现有的评估缺乏对真实世界的参考，也没有考虑到不同危害严重程度的差异，例如手术中的偏差不应与文本摘要中的风格偏差同等对待。研究指出，现有的基准测试成功并不能充分准备模型进行实际部署。", "innovation": "HALF（Harm-Aware LLM Fairness）提出了一个与部署对齐的框架，可以评估模型在现实应用中的偏见并根据危害严重程度加权。通过五个阶段的管道将九个应用领域分为三类（严重、中等、轻微），HALF展示了八种LLM测试结果，表明LLMs在不同领域不是公平的，模型大小和性能也不能保证公平性，同时推理模型在医学决策支持中表现更好但在教育中表现更差。", "conclusion": "HALF 显示存在从前基准测试成功到部署准备之间的明显差距。"}
{"llm_update_time": "20251015", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.12023", "html_url": "https://arxiv.org/abs/2510.12023", "title": "对话转录中的信息提取：神经符号系统 vs. 大型语言模型", "title_en": "Information Extraction from Conversation Transcripts: Neuro-Symbolic vs. LLM", "authors": "Alice Saebom Kwak,Maria Alexeeva,Gus Hahn-Powell,Keith Alcock,Kevin McLaughlin,Doug McCorkle,Gabe McNunn,Mihai Surdeanu", "background": "当前信息提取趋势是大量依赖大型语言模型，这在很大程度上忽视了数十年来建立符号或统计信息提取系统的经验。论文在农业领域比较了基于神经符号（NS）和大型语言模型（LLM）的信息提取系统，评估了他们在涵盖猪肉、乳制品和作物子领域的九次访谈中的表现。LLM系统在整体F1得分上优于NS系统，但在核心细节方面优势较小。然而，两种系统各有权衡：NS方法在无上下文任务中提供更快的运行时间、更大的控制和更高的准确性，但缺乏通用性，在处理上下文细微差别方面存在问题，且需要大量资源来开发和维护。LLM系统则在性能、部署速度和维护方面表现更好，但在运行时间上较慢，可控性较低，对模型的依赖和幻觉风险较大。我们的研究结果强调了部署自然语言处理系统的‘隐藏成本’，突出了实现性能、效率和控制之间的平衡的必要性。", "innovation": "论文通过在农业领域的实验比较了神经符号（NS）和大型语言模型（LLM）驱动的信息提取系统的性能，展示了在实际应用中NLP系统的‘隐藏成本’，并建议实现性能、效率和控制之间的平衡是关键。", "conclusion": "基于此研究，LLM在整体信息提取性能上优于NS，但在速度、可控性和泛化能力等方面存在不足；NS系统则在无上下文任务中表现更佳，但需要更多资源。未来需要权衡不同方法的优点和缺点，以达到最佳应用效果。"}
{"llm_update_time": "20251015", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.12195", "html_url": "https://arxiv.org/abs/2510.12195", "title": "偏好调优的大语言模型在同时同声翻译中的分词应用", "title_en": "DPO-Tuned Large Language Models for Segmentation in Simultaneous Speech Translation", "authors": "Zeyu Yang,Satoshi Nakamura", "background": "同时同声翻译需要准确的分词以平衡翻译质量和延迟。近年来的研究，如SHAS，引入了预训练的分词模型，其性能优于启发式规则。然而，这些分词模型，尽管经过了预训练并比启发式方法更稳定，但在监督学习目标限制下，仍然无法融入人类偏好对齐，这对于自然的实时解释至关重要。因此，需要一种新的方法来提高分词的准确性和翻译质量，同时减少延迟。实验使用ACL 60/60语料库对英语-日语、中文、德语三个语言对进行评估，并使用SeamlessM4T v2作为翻译基础模型", "innovation": "提出了一种基于大型语言模型（LLMs）的分词框架，采用直接偏好优化（DPO）训练。这种方法通过利用偏好对齐，让LLMs预测出更符合实时翻译需求的自然分词点。实验结果显示，与SHAS等方法相比，该方法在分词准确性和翻译质量（BLEU、COMET）上取得了更高的表现，同时延迟也有所改善", "conclusion": "研究表明，偏好调优的LLMs有潜力超越现有的预训练分词模型，并促进适应性和人类导向的实时解释的发展。"}
{"llm_update_time": "20251015", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.12229", "html_url": "https://arxiv.org/abs/2510.12229", "title": "通过机制可解释性分析调优的大型语言模型中的道德偏见", "title_en": "Analysing Moral Bias in Finetuned LLMs through Mechanistic Interpretability", "authors": "Bianca Raimondi,Daniela Dalbagno,Maurizio Gabbrielli", "background": "研究表明，大型语言模型（LLMs）在微调过程中会内化类似人类的偏见，但这些偏见的具体机制尚不清楚。这项工作中，研究人员探讨了著名的Knobe效应（道德判断中的意图性偏见）是否会在微调的LLMs中出现，以及这种效应是否可以追溯到模型的具体组件。他们通过在3个开源权重的LLMs上进行逐层分析，发现偏见不仅在微调过程中学习，而且集中在特定的几层。令人惊讶的是，他们发现，只需将预训练模型的激活值填充到几个关键层中，就可以消除这种效应。这项研究提供了新的证据，证明社会偏见在LLMs中的存在可以通过目标干预来解释、定位和缓解，而无需重新训练模型。", "innovation": "研究人员通过逐层分析的方法，发现道德偏见不仅在微调过程中学习，还具体集中在模型的某些层中。此外，他们还发现，只需将预训练模型的激活值填充到几个关键层中，就可以消除这种效应。这表明社会偏见可以通过针对特定干预来解决，而不需要重新训练模型。", "conclusion": "这项研究为理解LLMs中的社会偏见提供了新的证据，表明可以通过针对特定层的干预来解释、定位和缓解这些偏见，而无需进行重新训练。"}
{"llm_update_time": "20251015", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.12251", "html_url": "https://arxiv.org/abs/2510.12251", "title": "DSAS: 一个多文档问答中注意力优化的通用即插即用框架", "title_en": "DSAS: A Universal Plug-and-Play Framework for Attention Optimization in Multi-Document Question Answering", "authors": "Jiakai Li,Rongzheng Wang,Yizhuo Ma,Shuang Liang,Guangchun Luo,Ke Qin", "background": "大型语言模型（LLMs）在多个领域展现了显著的潜力，但在多文档问答（Multi-doc QA）任务中存在显著的局限性。主要挑战包括长距离依赖建模和“中间丢失”问题。当前解决方案要么截断全局依赖关系，要么需要昂贵的微调，缺乏一个通用且简单的解决方案来应对这些挑战。", "innovation": "提出了双重阶段自适应锐化（DSAS）框架，包含两个模块：(i) 上下文门控权重（CGW）模块通过逐层注意力跟踪和位置感知加权评估段落的相关性，缓解“中间丢失”问题。(ii) 互注意力抑制（RAS）模块通过抑制关键文本和无关文本之间的信息交换，增强对关键段落的关注，从而减轻长距离依赖建模的限制。DSAS 作为一种即插即用解决方案，无需对架构进行修改或额外的训练参数。实验结果表明，DSAS 能够在主流 LLMs（Llama, Qwen, Mistral, Deepseek）上提高多文档问答任务的平均 F1 分数 4.2%，并在 Llama-3.1-8B-Instruct 和 Qwen2.5-14B-Instruct 上表现尤为明显。消融研究证实了 CGW 和 RAS 模块的必要贡献。进一步的详述进一步验证了 DSAS 的稳健性和可扩展性。", "conclusion": "实验结果证明了 DSAS 在四个基准上的有效性，表明了该模型能够显著改进多文档问答任务的性能。同时，该研究展示了 DSAS 的应用潜力，即插即用，无需修改现有架构，为多文档问答任务提供了一个实用的解决方案。"}
{"llm_update_time": "20251015", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.12306", "html_url": "https://arxiv.org/abs/2510.12306", "title": "使用大规模无监督管道和LLMs进行语料库自动标注：英语consider构型的变化", "title_en": "A large-scale, unsupervised pipeline for automatic corpus annotation using LLMs: variation and change in the English consider construction", "authors": "Cameron Morin,Matti Marttinen Larsson", "background": "随着自然语言语料库的以前所未有的速度扩展，手动注释仍然是语料库语言学工作中的一个重要方法论瓶颈。本文探讨了一种新的方法，利用大规模语言模型（LLMs）实现庞大语料库的自动语法注释。", "innovation": "本文提出了一种可扩展的无监督管道，通过一个四阶段的工作流：提示工程、预评估、自动批量处理和事后验证，实现了使用LLMs对庞大语料库进行自动化语法注释。这种方法与之前的监督和迭代方法不同，能够处理大规模的数据准备任务，减少人类干预。", "conclusion": "本研究通过一个历时性语料库对consider构型变化的案例研究，展示了该管道的有效性和可访问性，通过GPT-5使用OpenAI API标注了143,933个句子，准确率超过98%，开创新型数据准备的可能性，但仍需关注成本、许可和伦理等问题的实施挑战。"}
{"llm_update_time": "20251015", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.12316", "html_url": "https://arxiv.org/abs/2510.12316", "title": "通过事实击败有害刻板印象：基于RAG的反言论生成", "title_en": "Beating Harmful Stereotypes Through Facts: RAG-based Counter-speech Generation", "authors": "Greta Damo,Elena Cabrio,Serena Villata", "background": "反言论生成是专家活动的核心，如事实核查和反仇恨言论。现有工作通常将反言论生成视为纯文本生成任务，基于大型语言模型或非政府组织专家。这些方法存在局限性，因为生成的反言论在可靠性和一致性方面存在严重不足，且在可扩展性方面存在问题。", "innovation": "本文引入了一个新颖的框架，将反言论生成建模为基于知识的文本生成过程。该框架结合了先进的检索增强生成（RAG）管道，以确保为8个主要目标群体（根据仇恨言论文献确定）生成可信的反言论。文中还构建了一个知识库，涵盖了32,792个文本，来自联合国数字图书馆、EUR-Lex和欧盟基本权利局。结果表明，本文框架在质量和评估标准上均优于标准的大型语言模型基线和其他竞品方法。", "conclusion": "本文框架和知识库为研究可信和合理的反言论生成打下了基础，不仅在仇恨言论方面，而且在其他领域也有应用前景。"}
{"llm_update_time": "20251015", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.12255", "html_url": "https://arxiv.org/abs/2510.12255", "title": "浅层稳健性，深层脆弱性：医疗LLM的多轮评估", "title_en": "Shallow Robustness, Deep Vulnerabilities: Multi-Turn Evaluation of Medical LLMs", "authors": "Blazej Manczak,Eric Lin,Francisco Eiras,James O' Neill,Vaikkunth Mugunthan", "background": "大型语言模型（LLMs）正在迅速转向医疗临床使用，但在现实多轮交互中的可靠性仍然 poorly understood。现有的评估框架通常在理想条件下评估单轮问答，忽视了医疗咨询中常见的矛盾输入、误导性背景信息和权威影响等复杂性。研究表明，在浅层干扰下模型表现良好，但在多轮场景中表现严重脆弱，准确性从91.2%下降到13.5%。间接、基于语境的干预往往比直接建议更有害，这暴露了医疗部署中的显著脆弱性。进一步的分析揭示了模型间的差异，有些模型在重复干预下表现进一步下降，而另一些则部分恢复甚至提升。这些发现突显了多轮稳健性作为安全可靠部署医疗LLMs的关键但未充分探索的维度的重要性。", "innovation": "我们提出了MedQA-Followup框架，用于系统地评估医疗问答的多轮稳健性。该方法区分了浅层稳健性（抵抗误导性初始语境）和深层稳健性（在答案被挑战跨轮次时保持准确性），并引入了间接-直接轴来区分基于语境的框架（间接）和明确建议（直接）。通过控制干预MedQA数据集，评估了五个最先进的LLM，发现尽管模型在浅层干扰下表现良好，但在多轮设置中表现出严重的可破坏性，准确性从91.2%下降到13.5%。研究中还发现了间接干预比直接建议更有害的现象，这揭示了在临床部署中的显著脆弱性。此外，进一步的分析揭示了模型之间的差异，有些模型在重复干预下表现进一步下降，而另一些模型部分恢复甚至提升。这项研究强调了多轮稳健性作为医疗LLMs安全可靠部署的关键但未充分探索的维度的重要性。", "conclusion": "实验结果揭示了多轮稳健性作为安全可靠部署医疗LLMs的关键但未充分探索的维度的重要性。研究表明模型在浅层干扰下表现良好，但在多轮场景中表现严重脆弱。间接干预比直接建议更有害，暴露了在临床部署中的显著脆弱性。进一步的工作揭示了模型间差异，有些模型在重复干预下表现进一步下降，而另一些模型部分恢复甚至提升。这些发现突显了多轮稳健性的重要性，为安全可靠的医疗LLM部署提供指导。"}
{"llm_update_time": "20251015", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.12285", "html_url": "https://arxiv.org/abs/2510.12285", "title": "基于整词掩蔽的中文现代BERT", "title_en": "Chinese ModernBERT with Whole-Word Masking", "authors": "Zeyu Zhao,Ningtao Wang,Xing Fu,Yu Cheng", "background": "编码器Only Transformer在架构、数据和系统方面取得了进展，提高了准确率、速度和内存效率。然而，这些改进尚未完全转移到中文，因为中文的分词和形态学与英文有很大的不同。", "innovation": "本文引入了Chinese ModernBERT，这是一种完全从零开始设计的中文编码器，结合了硬件意识的32k BPE词汇表以适应常见中文前缀/复合词、动态整词掩蔽（WWM）结合动态掩蔽课程、扩展自注意力窗口并结合RoPE的二阶段预训练管道、以及减振余弦学习率计划以实现稳定的长时间优化。研究人员使用CCI3-HQ、CCI4（中文）和Cosmopedia-Chinese等数据集进行预训练。", "conclusion": "在CLUE上，Chinese ModernBERT在统一同训练协议下与强大的中文编码器具有竞争力。在半精度优化下，模型实现了长时间序列的高吞吐量，同时保持了强大的短序列速度。添加开放对比数据后，Chinese ModernBERT在SimCLUE上的表现进一步提升，达到了0.505（皮尔逊）/0.537（斯皮尔曼）的测试分数。这表明该模型在包含更多定制数据对的情况下，有望进一步扩展STS的性能。作者还将公开发布分词器和权重，以促进可重复的研究。"}
{"llm_update_time": "20251015", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.12355", "html_url": "https://arxiv.org/abs/2510.12355", "title": "通过输入归因进行精细分析的大脑-大模型对齐", "title_en": "Fine-grained Analysis of Brain-LLM Alignment through Input Attribution", "authors": "Michela Proietti,Roberto Capobianco,Mariya Toneva", "background": "了解大脑与大语言模型（LLMs）之间的对齐可以揭示语言处理背后的计算原理。现有研究试图通过各种方法分析大脑和LLMs之间的对齐关系，尤其是在预测下一词（Next-word Prediction，NWP）和脑对齐（Brain Alignment，BA）的相关性方面存在争议性问题。这项研究旨在通过引入细粒度的输入归因方法来识别对BA最重要的特定词汇，从而研究这些争议性问题中的营养价值差异。", "innovation": "本文提出了一种细粒度的输入归因方法，用于识别对大脑-LLM对齐最重要的特定词汇，并利用该方法研究了BA和NWP之间的关系。研究表明，BA和NWP依赖于不同的词汇子集：NWP呈现出语法规则偏向，而BA更侧重于语义和语篇层面的信息，体现了更加有针对性的近期效应。这些发现加深了我们对LLMs与人类语言处理之间关系的理解，并突显了BA和NWP在特征依赖方面的差异。此外，该归因方法还可广泛应用于探索各种语言处理任务中模型预测的认知相关性。", "conclusion": "这项工作进了一步理解LLMs与人类语言处理之间的关系，揭示了BA与NWP在使用词汇偏好上的不同模式。进一步的研究可以通过应用这种方法来探索更多语言处理任务中的相关性。"}
{"llm_update_time": "20251015", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.12367", "html_url": "https://arxiv.org/abs/2510.12367", "title": "LLM-REVal: 我们现在能否信任大型语言模型作为评审员？", "title_en": "LLM-REVal: Can We Trust LLM Reviewers Yet?", "authors": "Rui Li,Jia-Chen Gu,Po-Nien Kung,Heming Xia,Junfeng liu,Xiangwen Kong,Zhifang Sui,Nanyun Peng", "background": "大型语言模型（LLM）的迅猛发展激发了研究者们在学术工作流程中广泛集成它们的热情，可能重塑研究与评审的方式。尽管先前的研究揭示了LLM支持研究和评审的潜力，但它们在学术工作流程中的双重角色及研究与评审之间的复杂互动引发的新风险仍鲜有探讨。本研究聚焦于LLM如何深度集成到评审与研究过程中，如何影响学术公平性，通过模拟实验探究LLM作为评审员时的潜在风险。研究发现，LLM评审员系统地提高了LLM撰写论文的评分，而对人类撰写的论文则给予了较低的评分，甚至在多次修订后仍然坚持负面评价，这源于LLM对语言特征的偏好和对负面评论的厌恶两大主要偏差。", "innovation": "本研究通过引入基于LLM的角色代理进行模拟实验，观测LLM作为评审员对论文评分的影响，揭示了LLM评审员导致的偏见，并提出了基于LLM评审文稿对论文进行修订能够获得质量提升的观点。研究结果表明，若在同行评审流程中不加以谨慎使用LLM，则会对人类作者和学术研究造成公平性问题。同时，使用LLM的修订可提高论文质量，对早期研究工作者具有潜在价值。", "conclusion": "虽然LLM在早期研究阶段具有提升论文质量的潜力，但其作为评审员时存在的显著偏差可能损害人类作者的利益和学术公平性，需要在未来使用中加以谨慎。"}
{"llm_update_time": "20251015", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.12389", "html_url": "https://arxiv.org/abs/2510.12389", "title": "代词化差异作为基础设施偏见：次词元系统的不平等及其在LLM访问和效率中的影响", "title_en": "Tokenization Disparities as Infrastructure Bias: How Subword Systems Create Inequities in LLM Access and Efficiency", "authors": "Hailay Kidu Teklehaymanot,Wolfgang Nejdl", "background": "代词化差异对多语言人群实现人工智能的公平访问构成重大障碍。本研究通过大规模的跨语言评估超过200种语言的代词化效率，系统定量计算大规模语言模型中的计算不平等性。研究采用标准化实验框架，通过tiktoken库对所有语言样本进行统一处理，收集了广泛的标准评估指标，包括每句代词数（Tokens Per Sentence，TPS）和相对代词化成本（Relative Tokenization Cost，RTC），并与英语基线进行比较。", "innovation": "本研究首次进行了大规模的跨语言代词化效率评估，揭示了结构性不平等，并采用统一的实验框架和标准化协议来评估不同语言的代词化效率，识别出拉丁字母体系语言与非拉丁字母体系语言（尤其是形态复杂语言）在代词化效率和成本上的显著差异。", "conclusion": "研究结果强调了现有AI系统中的结构性不平等，即低资源和非拉丁字母体系语言的使用者面临不成比例的计算劣势。未来的研究应优先开发兼顾语言多样性特征的代词化策略和适应性词汇构建方法，以确保更包容且计算上更公平的多语言AI系统。"}
{"llm_update_time": "20251015", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.12434", "html_url": "https://arxiv.org/abs/2510.12434", "title": "PRoH:基于知识超图的动态规划与推理以增强检索生成", "title_en": "PRoH: Dynamic Planning and Reasoning over Knowledge Hypergraphs for Retrieval-Augmented Generation", "authors": "Xiangjun Zai,Xingyu Tan,Xiaoyang Wang,Qing Liu,Xiwei Xu,Wenjie Zhang", "background": "知识超图（KHs）作为检索增强生成（RAG）的知识表示已逐渐出现，通过一种结构化的形式来建模多实体关系。然而，现有的基于KH的RAG方法存在三个主要局限性：静态检索规划、非自适应检索执行以及对KH结构和语义的浅层利用，这些都限制了其进行有效的多跳问答的能力。", "innovation": "为了克服这些局限性，提出了一个动态的基于知识超图的规划与推理框架（PRoH），包括三个核心创新：（i）一个上下文感知的规划模块，通过绘制局部KH邻域以引导结构化推理计划生成；（ii）一个有序的带上下文约束的问题分解过程，将子问题以动态演变的有向无环图（DAG）组织起来，以支持自适应、多轨迹的探索；（iii）一个基于实体加权重叠（EWO）的推理路径检索算法，优先考虑语义一致的超边遍历。", "conclusion": "在多个领域的实验表明，PRoH在F1得分为19.73%、生成评估（G-E）得分为8.41%的平均值上超越了之前的SOTA模型HyperGraphRAG，在长距离多跳推理任务上表现出强大的稳健性。"}
{"llm_update_time": "20251015", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.12463", "html_url": "https://arxiv.org/abs/2510.12463", "title": "资源敏感但语言盲视：社区大小而非语法复杂性更好地预测大型语言模型在新型Wug测试中的准确性", "title_en": "Resource-sensitive but language-blind: Community size and not grammatical complexity better predicts the accuracy of Large Language Models in a novel Wug Test", "authors": "Nikoleta Pantelidou,Evelina Leivada,Paolo Morosi", "background": "大型语言模型的语言能力一直存在争议。这项研究通过在一个涉及新词的形态学泛化任务中测试模型，参与了这一讨论。研究使用了多语言改编的Wug测试，对六个模型进行了测试，横跨四门部分不相关的语言（加泰罗尼亚语、英语、希腊语和西班牙语），并与人类说话者进行了比较。", "innovation": "本研究贡献在于使用了一个涉及新词的形态学泛化任务测试模型的表现，这种方法不同于之前大多数研究，结果展示了模型在未见过词汇上的形态学泛化能力与人类相当，且更倾向于与社区大小和数据可用性相关，而非语法复杂性。", "conclusion": "研究发现，模型的行为主要受到语言资源丰富程度的影响，而非对语法复杂性的敏感性。对一项新型Wug测试的分析结果表明，与语法复杂性相比，社区大小和数据可用性更好地预测了大型语言模型的准确性。"}
{"llm_update_time": "20251015", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.12460", "html_url": "https://arxiv.org/abs/2510.12460", "title": "探究潜在知识冲突以实现忠实的检索增强生成", "title_en": "Probing Latent Knowledge Conflict for Faithful Retrieval-Augmented Generation", "authors": "Linfeng Gao,Baolong Bi,Zheng Yuan,Le Wang,Zerui Chen,Zhimin Wei,Shenghua Liu,Qinggang Zhang,Jinsong Su", "background": "检索增强生成（RAG）系统已被证明能够增强大型语言模型（LLMs）的事实准确性。然而，现有RAG系统通常存在忠实性问题，即模型的回答与检索到的上下文证据相矛盾。为了提高上下文忠实性，现有方法大多依赖外部干预，如提示工程、解码约束或基于奖励的微调等方式。这些方法将LLM视为黑箱，并忽视了一个关键问题：LLM如何在其参数化记忆中整合检索到的证据，特别是在知识冲突的情况下？", "innovation": "本文提出了一种闭包（CLEAR）框架，该框架通过以下步骤解决上述问题：首先，将上下文细分为句级知识；其次，使用隐藏状态探针定位冲突知识；最后，引入冲突意识微调来指导模型准确地整合检索到的证据。大量的实验结果表明，CLEAR在准确性和上下文忠实性方面都有显著提升，特别是在多种冲突条件下优于strong baselines；", "conclusion": "通过探针分析LLM的隐藏状态表示，研究发现了知识层次整合、句子级潜在线索的表现形式以及与参数化知识对齐时无关上下文常被放大的三个关键发现，并基于这些发现提出了CLEAR框架，显著提升了RAG系统的准确性和上下文忠实性。"}
{"llm_update_time": "20251015", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.12474", "html_url": "https://arxiv.org/abs/2510.12474", "title": "SMEC：重思嵌套表示学习在检索嵌入压缩中的应用", "title_en": "SMEC: Rethinking Matryoshka Representation Learning for Retrieval Embedding Compression", "authors": "Biao Zhang,Lixin Chen,Tong Liu,Bo Zheng", "background": "大型语言模型（LLMs）生成高维嵌入，能够捕捉丰富的语义和句法信息。然而，高维嵌入增加了计算复杂性和存储需求，限制了其实用部署。", "innovation": "提出了一种新的训练框架名为Sequential Matryoshka Embedding Compression (SMEC)，其中包括Sequential Matryoshka Representation Learning (SMRL)方法以减轻训练过程中的梯度方差、Adaptive Dimension Selection (ADS)模块以减少维度剪枝过程中的信息降解、以及Selectable Cross-batch Memory (S-XBM)模块以增强高维和低维嵌入之间的无监督学习。", "conclusion": "实验结果表明，SMEC能够在显著减少维度的同时保持性能。例如，在BEIR数据集上，我们的方法将压缩的LLM2Vec嵌入（256维度）的性能分别提高了1.1个和2.7个百分点，与其他Matryoshka-Adaptor和Search-Adaptor模型相比。"}
{"llm_update_time": "20251015", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.12476", "html_url": "https://arxiv.org/abs/2510.12476", "title": "当个性化愚弄检测器：机动生成文本检测中的特征反转陷阱", "title_en": "When Personalization Tricks Detectors: The Feature-Inversion Trap in Machine-Generated Text Detection", "authors": "Lang Gao,Xuhui Li,Chenxi Wang,Mingzhe Li,Wei Liu,Zirui Song,Jinghui Zhang,Rui Yan,Preslav Nakov,Xiuying Chen", "background": "大型语言模型（LLMs）在语言生成方面变得越来越强大，能够生成流畅的文字甚至模仿个人风格。然而，这种能力也增加了身份冒充的风险。到目前为止，尚无研究探讨个性化生成文本（MGT）的检测问题。", "innovation": "本文引入了\texttt{dataset}，这是一个针对个性化设置中检测器鲁棒性的首个基准数据集，由文学和博客文本及其LLM生成的模仿版本配对而成。研究发现了...\textit{特征反转陷阱}，即在通用领域具有区分性的特征在应用于个性化文本时会反转并误导。基于这一发现，本文提出\texttt{method}方法，这是预测检测器在个性化设置中性能变化的一种简单而可靠的方式。该方法识别嵌入的反转特征方向，并构建主要沿这些特征差异的探针数据集来评估检测器的依赖性。", "conclusion": "实验结果表明，\texttt{method}可以准确预测转移后变化的方向和幅度，与实际性能差距的相关性为85%。希望这项工作能激发更多关于个性化文本检测的研究。"}
{"llm_update_time": "20251015", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.12516", "html_url": "https://arxiv.org/abs/2510.12516", "title": "BoN Appetit Team at LeWiDi-2025: Best-of-N Test-time Scaling Can Not Stomach Annotation Disagreements (Yet)\n", "title_en": "BoN Appetit Team at LeWiDi-2025: Best-of-N Test-time Scaling Can Not Stomach Annotation Disagreements (Yet)", "authors": "Tomas Ruiz,Siyao Peng,Barbara Plank,Carsten Schwemmer", "background": "test-time scaling是一种在推理时通过额外计算提高LLM输出质量的技术。目前，这种技术主要应用于具有可验证正确答案的领域，如数学和编程。该研究将test-time scaling技术应用于LeWiDi-2025任务中的标注分歧评估中，同时探索三种测试时缩放方法的效果。\n", "innovation": "该研究首次尝试将test-time scaling应用于包含标注分歧的自然语言处理任务（LeWiDi-2025）。研究采用了三种test-time scaling方法：两种基准算法（模型平均和多数投票）以及一种Best-of-N抽样方法，并发现后者的有效性在当前阶段未能跨越数学任务到LeWiDi任务的鸿沟。\n", "conclusion": "通过实验发现，Best-of-N方法在从数学任务到LeWiDi任务的迁移上表现不佳。对于这一现象的研究工作为寻找新的方法以克服该问题提供了方向。\n"}
{"llm_update_time": "20251015", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.12548", "html_url": "https://arxiv.org/abs/2510.12548", "title": "VISaGE: 理解视觉通用概念和例外", "title_en": "VISaGE: Understanding Visual Generics and Exceptions", "authors": "Stella Frank,Emily Allaway", "background": "视觉语言模型（VLMs）在训练过程中学习概念性表示，但它们通常仅用于分析单一实例。当评估实例具有典型性时，这个范式能够在模型中协调两种先验：一种是实用先验，即文本和视觉输入都相关，源于VLM对一致输入的微调；另一种是语义先验，即概念性表示对类别实例一般是真实的。然而，当使用不一致的图像评估时，会导致这两种先验之间的冲突。为了探究VLM在这两种先验间的权衡，研究者引入了一个新的评估数据集VISaGE，其中包括典型和例外的图像。", "innovation": "研究者提出的问题是在不一致图像下，实用先验的优势超过了语义先验，导致概念理解下降。通过在VISaGE数据集上的精心实验，展示了当反常识图像破坏了实用先验假设时，概念理解会下降，并且这种效应比语义先验强，尤其是在查询单个实例时更为明显。", "conclusion": "研究表明，当不一致的图像破坏了实用先验下的假设时，VLM在概念理解上会表现出明显的下降。这种效应比语义先验更显著，特别是在单独查询实例时。这些发现为理解和改进VLM在处理非典型输入时的行为提供了新的视角。"}
{"llm_update_time": "20251015", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.12621", "html_url": "https://arxiv.org/abs/2510.12621", "title": "ACADATA：机器翻译用的学术平行数据集", "title_en": "ACADATA: Parallel Dataset of Academic Data for Machine Translation", "authors": "Iñaki Lacunza,Javier Garcia Gilabert,Francesca De Luca Fornaciari,Javier Aula-Blasco,Aitor Gonzalez-Agirre,Maite Melero,Marta Villegas", "background": "当前学术翻译领域缺乏高质量的数据集和模型，现有的机器翻译模型在学术领域尤其是长文本翻译上表现不理想，传统模型难以满足多语言方向的需求。", "innovation": "引入了ACADATA，这是一个高质量的平行数据集，包含ACAD-TRAIN和ACAD-BENCH两个部分，旨在提高机器翻译在学术领域的效果，特别是长文本翻译。通过在ACAD-TRAIN上微调两个大型语言模型，ACADATA显著提升了学术翻译的质量，尤其是在英语到其他语言的翻译上表现出色。", "conclusion": "ACADATA为学术领域和长文本翻译研究提供了宝贵的资源，通过释放ACAD-TRAIN、ACAD-BENCH和微调的模型，可以进一步促进相关研究的进展。"}
{"llm_update_time": "20251015", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.12587", "html_url": "https://arxiv.org/abs/2510.12587", "title": "Teaching Language Models to Faithfully Express Their Uncertainty", "title_en": "Teaching Language Models to Faithfully Express their Uncertainty", "authors": "Bryan Eikema,Evgenia Ilia,José G. C. de Souza,Chrysoula Zerva,Wilker Aziz", "background": "大型语言模型（LLMs）经常在其不确定性表达上出错：重复查询可以产生不同的答案，但生成的响应通常是未经修饰或修饰的方式无法反映这种变异性。这种不确定性未被忠实传达，影响了LLM知识状态的真实反映，即使对于强大的LLM也是如此。研究表明，许多LLM在表达不确定性时存在忠实度差距。", "innovation": "本文介绍了一种新的微调方法——可信不确定性调整(Faithful Uncertainty Tuning, FUT)，该方法能够教导指令微调的LLM准确表达不确定性，而不改变其基础答案分布。FUT通过将模型样本与不确定性修饰词（如“可能”或“可能”等表征模糊性的话语）对齐，并结合一组提示进行训练。实验展示了FUT在多个模型和数据集上的广泛适用性，并证明了它能显著减少忠实度差距，同时保持问答准确性并且引入最小的语义分布变化。进一步分析显示了FUT在不同解码策略、不同修饰器选择和其他形式不确定性表达方面的鲁棒性。", "conclusion": "研究结果表明，FUT是一种简单且有效的方法，能够教导LLM们准确表达不确定性，具有重要的应用价值。"}
{"llm_update_time": "20251015", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.12608", "html_url": "https://arxiv.org/abs/2510.12608", "title": "StyleDecipher：利用风格分析实现稳健可解释的大语言模型生成文本检测", "title_en": "StyleDecipher: Robust and Explainable Detection of LLM-Generated Texts with Stylistic Analysis", "authors": "Siyuan Li,Aodu Wulianghai,Xi Lin,Guangyan Li,Xiang Chen,Jun Wu,Jianhua Li", "background": "随着大语言模型（LLMs）在开放域写作中的集成程度越来越高，检测机器生成文本变得越来越重要，以确保内容的真实性和信任度。现有的方法依赖于统计差异或特定模型的启发式方法来区分LLL生成的文本和人类撰写的文本。然而，这些方法在现实世界场景中表现不佳，因为它们在泛化能力有限、对改写方法脆弱、缺乏解释性等方面存在局限性，特别是在面对风格多样性或混合人类-人工智能作者身份时。", "innovation": "本文提出了一种名为StyleDecipher的鲁棒且可解释的检测框架，该框架重新审视LLM生成文本检测，通过结合特征提取器量化风格差异。StyleDecipher通过联合建模离散风格指标和源自语义嵌入的连续风格表示，捕捉了人文和LLM输出在统一表示空间内的风格级差异。该框架无需访问模型内部或带标记的数据段即可实现准确、可解释和领域通用的检测。实验结果表明，StyleDecipher在多个领域中均达到当前最先进的在域准确度，并且在跨领域评估中超过了现有的基线方法，同时保持了对抗性干扰和混合人类-人工智能内容的鲁棒性。", "conclusion": "进一步的定量和定性分析证实，风格信号提供了可解释的证据以区分机器生成的文本。我们的源代码可以在以下链接访问：[提供链接]。"}
{"llm_update_time": "20251015", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.12637", "html_url": "https://arxiv.org/abs/2510.12637", "title": "COSTAR-A：一种增强大型语言模型在视角问题表现的提示框架", "title_en": "COSTAR-A: A prompting framework for enhancing Large Language Model performance on Point-of-View questions", "authors": "Nzubechukwu C. Ohalete(1),Kevin B. Gittner(1),Lauren M. Matheny(1) ((1) School of Data Science and Analytics, Kennesaw State University, GA, USA)", "background": "大型语言模型（LLMs）对提示设计非常敏感，优化的提示技术对于产生一致且高质量的输出至关重要。尽管现有的COSTAR框架通过增强提示的清晰度和输出对齐，提升了LLMs的表现，但在小型、本地优化模型中其表现的一致性较差，尤其是需要更具指示性或限制性输出的任务。通过一系列针对最多80亿参数的精细调整模型的受控测试，发现COSTAR-A框架能够提升这类模型在特定任务中的输出结构和决定性，尽管其效果在不同模型和应用场景中有所差异。", "innovation": "COSTAR-A通过在原有的COSTAR方法基础上新增‘答案’组件，形成了一个新的提示工程框架。它能够改善小型局部优化模型在某些任务中的输出结构和决策性，尤其在计算效率高的AI部署中表现突出。", "conclusion": "COSTAR-A在特定任务上展示了增强小型模型表现的潜力，尤其是在计算资源有限的硬件上。研究还指出COSTAR-A框架具有较高的适应性和扩展性，特别适用于计算环境有限的部署场景。"}
{"llm_update_time": "20251015", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.12643", "html_url": "https://arxiv.org/abs/2510.12643", "title": "推理模式很重要：无需人工推理学习推理", "title_en": "Reasoning Pattern Matters: Learning to Reason without Human Rationales", "authors": "Chaoxu Pang,Yixuan Cao,Ping Luo", "background": "大语言模型（LLMs）在广泛采用的SFT+RLVR范式下展现出了显著的推理能力。该范式首先通过人类标注的推理路径（理性）进行监督微调（SFT），然后通过验证奖励的强化学习（RLVR）优化模型，使用可验证的信号而非金标准理性。然而，为SFT阶段标注高质量的理性仍然非常昂贵。这篇论文探讨了如何在不牺牲推理性能的情况下显著降低标注理性成本。研究发现，在固定、程序化策略一致的问题上，如数值语义匹配等任务中，模式化推理使得模型能够内化这些推理模式。尽管实例在内容上有差异，但解决方案来自共享的推理模式。因此，SFT+RLVR在这类任务中的成功主要归因于模型学习和内化这些模式的能力。", "innovation": "论文提出了一种名为Pattern-Aware LLMs as Rationale AnnOtators (PARO)的简单有效框架，无需人工标注理性，使模型能够生成与特定任务推理模式对齐的理性。实验表明，PARO自动生成的理性在SFT+RLVR性能上与10倍更大的人工理性相当，这表明大规模的人工理性注释可以被基于LLM的自动注释所取代，只需少量的人类监督即可。", "conclusion": "研究结果表明，在模式化推理任务中，推理模式（而非理性数量或质量）是决定性能的关键，提出了能够自动生成与任务特定推理模式对齐的理性推理模式感知的大语言模型（PARO），实现了在无需大量人工标注的场景下进行有效推理学习。"}
{"llm_update_time": "20251015", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.12357", "html_url": "https://arxiv.org/abs/2510.12357", "title": "MoBiLE: 在消费级GPU上利用大核心和小核心混合的高效专家混合推理", "title_en": "MoBiLE: Efficient Mixture-of-Experts Inference on Consumer GPU with Mixture of Big Little Experts", "authors": "Yushu Zhao,Yubin Qin,Yang Wang,Xiaolong Yang,Huiming Han,Shaojun Wei,Yang Hu,Shouyi Yin", "background": "Mixture-of-Experts (MoE) 模型在多种应用中展现了出色的效果。MoE模型通过稀疏激活机制实现一种卸载策略，其中激活专家在GPU HBM中维护，非激活专家存储在CPU DRAM中。然而，这种方法的有效性受到CPU与GPU之间带宽有限的制约。现有方法通过预取技术来缓解这一瓶颈，它们尝试预测所需的专家并提前加载，但这些方法通常存在显著的训练开销，并在处理细粒度专家分割的现代MoE模型上效果较差。", "innovation": "本文提出了MoBiLE，一种插即用的MoE推理框架，引入了‘大核心和小核心混合专家’的策略。MoBiLE通过减少不重要的标记所用专家数量来加速推理，同时确保重要的标记使用完整的专家来保证模型质量。此外，该方法设计了一种专门的切换机制，用于在小核心和大核心专家之间进行切换，以提高内存效率。MoBiLE在四种典型的现代MoE架构和具有挑战性的生成任务上的评估结果显示，相对于基线，在消费级GPU系统上实现了1.60倍到1.72倍的速度提升，且准确率几乎没有下降。", "conclusion": "MoBiLE框架通过减少不重要标记的专家数量、优化内存使用并实现大核心与小核心专家的灵活切换，在保持模型准确率的同时显著提升了MoE模型的推理速度。"}
{"llm_update_time": "20251015", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.12699", "html_url": "https://arxiv.org/abs/2510.12699", "title": "生成空间大小：理解并校准LLM生成的开放性", "title_en": "Generation Space Size: Understanding and Calibrating Open-Endedness of LLM Generations", "authors": "Sunny Yu,Ahmad Jabbar,Robert Hawkins,Dan Jurafsky,Myra Cheng", "background": "不同的开放生成任务需要不同的输出多样性。然而，当前大规模语言模型往往失校准。它们在创意任务中产生过于同质化的输出，在事实任务中则虚构不正确的分散回答。本文认为这两种失败模式可以用有效的生成空间大小（GSS）的概念来统一和解决，GSS是模型对于提示考虑的语义上不同的输出集合。文章介绍了基于GSS关系的任务套件GSSBench，以便评估不同的度量标准并理解模型偏离理想行为的原因。结果发现，幻觉检测度量标准，特别是EigenScore，始终优于传统的多样性和不确定性量化度量标准，仅使用模型内部信息，提供了关于模型内部任务表示的可解释见解。文章展示了生成空间大小GSS的三个应用：（1）检测提示模糊并预测澄清问题以更好地定位，（2）解释并在推理模型中理解过度思考和不足思考，（3）引导模型扩展其生成空间以生成高质量且多样化的输出。", "innovation": "提出了有效的生成空间大小（GSS）的概念来统一和解决当前大型语言模型在创意任务中缺乏多样性和在事实任务中产生不准确的分散回答的两种失败模式。通过GSSBench任务套件，基于GSS关系评估不同度量标准，发现幻觉检测度量标准具有优势，提供关于模型内部任务表示的可解释见解，并展示了GSS在三个应用中的实际用途：提示模糊检测、推理模型解释和引导模型产生高质量和多样化输出。", "conclusion": "生成空间大小GSS是统一并解决当前大型语言模型在创意任务缺乏多样性和事实任务产生不准确的分散回答两种失败模式的有效概念。通过GSSBench展示了GSS对理解并校准LLM生成开放性的关键作用，提升了幻觉检测度量标准的表现，提供了模型内部任务表示的可解释见解，有助于提示澄清、推理模型解释以及生成高质量和多样化输出。"}
{"llm_update_time": "20251015", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.12720", "html_url": "https://arxiv.org/abs/2510.12720", "title": "Omni-Captioner：全面感知的数据管道、模型与基准", "title_en": "Omni-Captioner: Data Pipeline, Models, and Benchmark for Omni Detailed Perception", "authors": "Ziyang Ma,Ruiyang Xu,Zhenghao Xing,Yunfei Chu,Yuxuan Wang,Jinzheng He,Jin Xu,Pheng-Ann Heng,Kai Yu,Junyang Lin,Eng Siong Chng,Xie Chen", "background": "细粒度的多模态感知对人机交互至关重要。随着音频-视觉技术的进步，能够同时处理音频和视频信号的全语言模型（OLMs）已经成为了实现更加丰富理解和推理的一种有前景的范式。然而，这些模型在捕捉和描述细粒度细节方面的潜力仍被部分地开发出来。本文通过从数据管道、模型和基准测试三个角度进行系统和全面的研究，指出当前全语言模型在细节与幻觉之间的固有“共增长”问题，并提出了Omni-Detective数据生成管道以自主生成高度详细的且几乎无幻觉的多模态数据。基于这些数据训练了两种 captioning 模型：仅音频详细感知的 Audio-Captioner 和同时处理音频和视觉的 Omni-Captioner。并通过级联评价协议，这两个模型在开放源代码模型中达到了最佳性能，尤其是Omni-Captioner在视频-SALMONN 2 测试集上实现了在细节和幻觉之间最佳的折衷。", "innovation": "本文创新性地提出了Omni-Detective数据生成管道，解决了当前全语言模型在细节与幻觉之间的固有‘共增长’问题。同时，提出了基于Omni-Detective生成的数据训练的两种 captioning 模型：仅通过音频进行详细感知的Audio-Captioner 和同时处理音频和视觉的 Omni-Captioner。此外，构建了Omni-Cloze这一新的闭塞风格评估，用于详细音频、视觉和多模态 captioning 的稳定、高效和可靠的评估，从而在基准测试中达到了最佳性能折衷。", "conclusion": "实验结果和分析证明了Omni-Detective在生成高质量详细 caption 方面的有效性，以及Omni-Cloze在评估这类详细 caption 方面的优势。Omni-Captioner和Omni-Detective的提出为全方位感知提供了一套有效的解决方案，并且通过Omni-Cloze验证了这种感知的实际应用价值。"}
{"llm_update_time": "20251015", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.12766", "html_url": "https://arxiv.org/abs/2510.12766", "title": "语言模型建模语言", "title_en": "Language Models Model Language", "authors": "Łukasz Borchmann", "background": "语言学界对大型语言模型（LLMs）的评论往往是基于索绪尔和乔姆斯基的语言理论框架展开的，这方面的评论常常是推测性的且缺乏实际效果。批评声音质疑LLMs是否能够真正地建模自然语言，认为要实现理想的“语言能力”需要具备“深层结构”或“语义接地”等特征。", "innovation": "作者提出了向Witold Mańczak确立的经验证主义原则的转变视角，重新定义了语言的本质，即语言不仅是一种“符号系统”或“大脑的计算系统”，更重要的是涵盖了所有言语和文字的总和。此外，提出了使用特定语言元素使用频率的高低作为语言主要的治理原则，以此为基础重新审视和挑战以往对LLMs的批评，并提供了一种建设性的指南来进行语言模型的设计、评估和解释过程", "conclusion": "总体而言，文章主张对语言模型的研究应基于经验证据，强调语言使用中的频率原则，并为该领域的实际应用提供了新的视角和方法。"}
{"llm_update_time": "20251015", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.12722", "html_url": "https://arxiv.org/abs/2510.12722", "title": "基于GCG的虚拟语言中哪些词序有利于长度泛化在语言模型中的表现？", "title_en": "Which Word Orders Facilitate Length Generalization in LMs? An Investigation with GCG-Based Artificial Languages", "authors": "Nadine El-Naggar,Tatsuki Kuribayashi,Ted Briscoe", "background": "已有研究表明，语言模型（LMs）倾向于掌握类型学上频繁的语法特性，而不是稀有且不合理的特性，通常是通过人工语言（ALs）进行研究（White and Cotterell, 2021; Kuribayashi et al., 2024）。这项研究在此基础上进行了扩展，扩展了使用生成性范畴语法（GCG）的上下文自由AL形式，使AL能够涵盖以前未被注意到的但已证实的构造，例如无界依赖和轻微上下文敏感结构。此外，研究更加关注LM处理未见过的长度较长测试句子的能力，使得AL更好地反映了自然语言的特点，实验设计使结论更加明确——类型学上合理的词序对于LMs来说更容易进行有效的泛化.", "innovation": "引入了生成性范畴语法（GCG）对人工语言（ALs）进行了扩展，增强了AL描述自然语言模式的能力；重点研究了LMs在处理长度较长的未见过句子时的泛化能力，使得实验结果更具说服力和明确性.", "conclusion": "类型学上合理的词序倾向于使LMs能够更有效地进行泛化处理."}
{"llm_update_time": "20251015", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.12740", "html_url": "https://arxiv.org/abs/2510.12740", "title": "嘿，等等：语言模型中的议题敏感性研究", "title_en": "Hey, wait a minute: on at-issue sensitivity in Language Models", "authors": "Sanghee J. Kim,Kanishka Misra", "background": "评价语言模型（LMs）生成对话的自然性并非易事，因为‘自然性’的概念各异，且可扩展的定量度量有限。这项研究利用语言学中的‘议题敏感性’概念来评估对话的自然性，并引入了一种新方法：Divide, Generate, Recombine, and Compare（简称DGRC）。DGRC方法包括将对话作为提示分割、使用LM生成每个部分的延续、再组合成对话和后续内容、并比较重组序列的概率。这种方法减轻了对语言模型的语言分析偏见，并允许对话语敏感行为进行系统测试。", "innovation": "引入了Divide, Generate, Recombine, and Compare（DGRC）方法，该方法利用语言中的‘议题敏感性’评估对话自然度，分解对话内容、生成子部分的延续、重新组合后对话，并比较重组序列的可能性。这种方法减少对语言模型的语言分析偏见，并允许对话语敏感行为进行系统测试。发现了LM倾向于继续在议题内容上对话，特别是在指令调整模型中这种倾向更加显著。在相关提示（如“嘿，等等一下”）存在时，LM会减少其议题敏感性倾向，而指令调整没有进一步放大这种调节效果。这种模式反映了成功对话的特征表现之一。", "conclusion": "尽管指令调整没有进一步增强这种调节，在LMs中发现了议题敏感模式，反映了成功对话行为的关键特征，表明LM在处理对话时存在随机选择上的偏见。"}
{"llm_update_time": "20251015", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.12781", "html_url": "https://arxiv.org/abs/2510.12781", "title": " Predominantly 口头语言 手工校对转录的成本分析", "title_en": "Cost Analysis of Human-corrected Transcription for Predominately Oral Languages", "authors": "Yacouba Diarra,Nouhoum Souleymane Coulibaly,Michael Leventhal", "background": "为低资源语言创建语音数据集是一项至关重要的但理解不足的挑战，尤其是在人力劳动的实际成本方面。本文研究了为马里曼丁语班巴拉语等低资源语言子集生成高质量标注语音数据所需的时间和复杂性，该语言属于以口头为主的低识字率语言。通过一项为期一个月的实地研究，涉及十名具有母语熟练程度的转录员，我们分析了手工校正ASR生成的53小时班巴拉语音数据的转录。研究表明，在实验室条件下，准确转录一小时语音数据需要平均30小时的人力劳动，在实地条件下则需要36小时。", "innovation": "本文通过实地研究，提供了为具有相似特性的低资源语言创建自然语言处理资源的基线和实用见解，填补了在实际转录人力成本方面理解不足的空白。", "conclusion": "研究结果表明，在实验室条件下，准确转录一小时语音数据需要平均30小时的人力劳动，在实地条件下则需要36小时。这些研究为类似的语言提供了成本估算的基准，并提供了实用的见解，有助于更高效地创建自然语言处理资源。"}
{"llm_update_time": "20251015", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.11734", "html_url": "https://arxiv.org/abs/2510.11734", "title": "LLM拟合人格的缩放定律：只需更详细和真实的角色配置文件", "title_en": "Scaling Law in LLM Simulated Personality: More Detailed and Realistic Persona Profile Is All You Need", "authors": "Yuqi Bai,Tianyu Huang,Kun Sun,Yuting Chen", "background": "该研究关注使用大型语言模型（LLMs）模拟社会实验，探索它们在虚拟人物角色扮演中模拟人类个性的能力。研究开发了一个全流程评估框架，包括个体层面的稳定性和可识别性分析，以及用于检验LLMs在模拟人类个性方面的真实性与一致性的群体层面的分析方法（如逐步个性曲线）。方法上，该研究提出了对传统心理测量方法（如CFA和构建效度）的重要改进，这些方法在当前低级模拟水平下无法捕捉到LLMs的进步趋势，可能导致对该技术的不成熟拒绝或方法论不匹配的问题。", "innovation": "该研究的主要贡献包括：提出了一套系统框架来评估LLMs的虚拟人格；通过实证方法展示了角色细节在人格模拟质量中的关键作用；并识别了人格配置文件的边际效益效应，特别是在LLMs人格模拟中的缩放定律，提供了操作性的评估指标和将大型语言模型应用于社会科学研究的基础理论。", "conclusion": "该研究验证了更详细和真实的角色配置文件在提高LLMs人格模拟质量方面的显著效果，强调了它们的应用潜力，并为社会科学研究提供了理论基础和评估标准。"}
{"llm_update_time": "20251015", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.12773", "html_url": "https://arxiv.org/abs/2510.12773", "title": "Dr.LLM: 动态层路由在大语言模型中的应用", "title_en": "Dr.LLM: Dynamic Layer Routing in LLMs", "authors": "Ahmed Heakl,Martin Gubri,Salman Khan,Sangdoo Yun,Seong Joon Oh", "background": "大型语言模型在处理每个词元时会通过所有的transformer堆栈层次，这导致了对于简单的查询存在浪费计算的情况，而对于需要更深层次推理的复杂任务则显得不够灵活。现有的 adaptive-depth 方法可以提高效率，但它们需要在推理时的搜索、架构变化或大规模重新训练这些成本，实践中往往会在提高效率的同时牺牲准确性。", "innovation": "文献介绍了一种名为 'Dynamic routing of Layers for LLMs' 的可重构框架，它为预训练模型提供了轻量级的每层路由器，用于决定跳过、执行或重复一个块的操作。路由器通过明确定义的监督训练，结合蒙特卡洛树搜索 (MCTS)，在保持或改进计算预算下准确性的前提下进行训练。该设计包括基于窗口的池化以提高路由稳定性、焦点损失以平衡类别的失衡，以及瓶颈MLP路由器确保模型在类别失衡和长序列上具有鲁棒性。实验结果表明，在ARC（逻辑推理）和DART（数学任务）上，该方法提高了2.9%到3.4%的准确率，并且每个示例平均节省了5个层。该路由器还能够很好地应用于域外任务，仅损失0.85%的准确率，同时保持了效率，并优于先前的路由方法多达7.7%。", "conclusion": "整体而言，该研究展示了如何通过明确监督的路由器为冻结的LLM进行适应性改造，从而实现预算意识强且以提高准确性为目标的推理，而无需改变基模型权重。"}
{"llm_update_time": "20251015", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.11739", "html_url": "https://arxiv.org/abs/2510.11739", "title": "使用Twitter粉丝发文进行短篇乌尔都语名人画像研究", "title_en": "Celebrity Profiling on Short Urdu Text using Twitter Followers' Feed", "authors": "Muhammad Hamza,Rizwan Jafar", "background": "社交媒体已成数字时代的重要组成部分，作为通信、互动和信息共享的平台。名人是其活跃用户，经常通过在线帖子分享个人和职业生活。通过平台如Twitter可以分析语言和行为，了解人口和社会模式。由于粉丝的语言特征和兴趣与他们关注的名人相似，可以从粉丝的文本数据预测名人的人口统计信息。此前，大多数研究集中在英语等高资源语言上，乌尔都语等低资源语言则少有研究。", "innovation": "本研究将现代机器学习和深度学习技术应用于乌尔都语中名人画像的问题。收集并预处理了来自亚英次大陆名人粉丝的短乌尔都语微博数据，使用逻辑回归、支持向量机、随机森林、卷积神经网络和长短期记忆网络等多种算法进行训练和比较。研究表明，使用机器学习和神经网络方法可以从粉丝的文本数据中有效地预测人口统计信息，为低资源语言乌尔都语的研究提供了新的视角和发展空间。", "conclusion": "研究结果显示，虽然年龄、职业和知名度预测结果不是很理想，但在性别预测方面表现出色，累积排名为0.65，准确率为0.65。这表明可以从粉丝的文本特征有效地预测乌尔都语名人的人口统计信息，使用机器学习和神经网络方法对于低资源语言的乌尔都语有很好的应用效果。"}
{"llm_update_time": "20251015", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.11746", "html_url": "https://arxiv.org/abs/2510.11746", "title": "Telegram战争时期的论述演变：俄罗斯和乌克兰决策者通信的比较研究", "title_en": "Evolution of wartime discourse on Telegram: A comparative study of Ukrainian and Russian policymakers' communication before and after Russia's full-scale invasion of Ukraine", "authors": "Mykola Makhortykh,Aytalina Kulichkina,Kateryna Maikovska", "background": "本文研究了在正在进行的俄罗斯-乌克兰战争期间，由精英驱动的Telegram政治通信活动的变化。这是社交媒体时代第一次大规模的欧洲战争，其中涉及的主要是乌克兰和俄罗斯的政策制定者在2019年至2024年间在Telegram上的公开通信。研究通过分析俄罗斯于2022年全面入侵乌克兰后，通信量、主题内容和参与者互动的变化来探讨这一问题。", "innovation": "本文首次系统地研究了社交媒体时代背景下，两个重要国家——乌克兰和俄罗斯——在其政治体系中的政策制定者如何使用Telegram进行战时的政治交流，并在此过程中发现了不同的交流模式和策略。特别之处在于真实性高的数据集支持下，本文揭示了在全面战争爆发后，不同规模政党及其个人政策制定者的交流策略的差异。", "conclusion": "研究结果表明，在入侵后，Telegram上的活动显著增加，特别是在执政党的政策制定者之间。乌克兰的政策制定者最初主要讨论与战争相关的话题，但随着时间的推移逐步减少这一重点。相比之下，俄罗斯的政策制定者更多避免与战争相关的讨论，转而专注于不相关的议题，如西方危机，以转移公众注意力。此外，本文还指出大型政党与小型政党的交流策略存在差异，个体政策制定者也显示出不同的交流模式。这些研究发现为理解战争时期网上政治对话的动态提供了宝贵的视角，并对政策制定者如何应对战时沟通挑战提供了关键的见解。"}
{"llm_update_time": "20251015", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.11813", "html_url": "https://arxiv.org/abs/2510.11813", "title": "面向任务的缩减以实现可扩展的大语言模型-数据库系统", "title_en": "Task-Aware Reduction for Scalable LLM-Database Systems", "authors": "Marcus Emmanuel Barnes,Taher A. Ghaleb,Safwat Hassan", "background": "大型语言模型（LLMs）在数据密集型工作流程中应用越来越广泛，包括数据库查询和开发者可观察性等领域。然而，这些系统的有效性受到真实世界富文本数据（如日志、遥测和监控流）的体积、冗长和噪声的限制。直接将这类数据输入LLMs成本高、环境可持续性差，并且常常与任务目标不一致。尽管在LLM效率方面已经进行了模型或架构级别的优化，但减少上游输入冗长的问题尚未得到充分探讨。", "innovation": "本文主张将LLM的令牌预算视为注意力预算，并将具有任务意识的文本缩减视为语言数据系统设计中的第一级原则。我们强调输入侧缩减不应被视为压缩，而应视为注意力分配，即优先考虑对下游任务最重要的信息。本文概述了构建基准、设计自适应缩减管道以及将令牌预算感知预处理整合到数据库和检索系统中的开放研究挑战。", "conclusion": "我们的愿景是将稀缺的注意力资源导向嘈杂的数据密集型工作流程中的有意义信号，从而实现可扩展、准确和可持续的大语言模型-数据整合。"}
{"llm_update_time": "20251015", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.11834", "html_url": "https://arxiv.org/abs/2510.11834", "title": "不要依着界线走：面向过滤生成的边界指导", "title_en": "Don't Walk the Line: Boundary Guidance for Filtered Generation", "authors": "Sarah Ball,Andreas Haupt", "background": "生成模型越来越常与安全分类器一起使用，后者用于过滤掉有害或不合适的内容。一个常用策略是对生成器进行微调，以降低被分类器过滤掉的可能性，但这种方法可能并不理想，因为这样做往往会促使模型生成样本靠近分类器的决策边界，导致误报和漏报率增加。", "innovation": "本文提出了一种名为边界引导的强化学习微调方法，旨在显式地引导生成活动远离分类器的边界。该方法通过对生成器进行微调，使得生成的内容远离分类器的决策边界，从而增加输出的安全性和实用价值。通过在开放指令生成任务（如狱突和模棱两可指令）上的基准测试，边界引导能够同时提高生成内容的安全性和实用性，这一点通过LLM-as-a-Judge评估得到验证。此外，跨越不同模型规模和奖励设计的全面剥离实验还展示了该方法的稳健性。", "conclusion": "边界引导作为一种强化学习方法，在多种模型规模和奖励设计中展示了其运行的稳健性，有效提升了生成内容的安全性和实用性。这种方法对于处理生成模型的过滤生成问题具有重要的理论和实践意义。"}
{"llm_update_time": "20251015", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.11842", "html_url": "https://arxiv.org/abs/2510.11842", "title": "平衡合成数据和重放以增强特定任务能力", "title_en": "Balancing Synthetic Data and Replay for Enhancing Task-Specific Capabilities", "authors": "Urs Spiegelhalter,Jörg K.H. Franke,Frank Hutter", "background": "适应新任务的语言模型面临着一个基本权衡：模型必须学习新技能而不至于遗忘现有知识。尽管以往的研究探讨了合成数据生成技术，但在计算限制下的任务表现和知识保留之间的最优重播比例仍然没有被彻底理解。本文通过使用bAbI推理任务为目标，研究了重播比例配置与计算预算之间的相互作用。", "innovation": "本文进行了全面的经验研究，评估了不同总令牌预算和重放比例配置对任务掌握和通用知识保留的影响，揭示了平衡任务特定性能与通用知识保留的最优配置，并提供基于计算预算的经验指导.", "conclusion": "基于研究结果，本文为根据计算预算选择重播比例提供了经验指导，使得实践者可以以显著减少训练成本的方式实现强大的任务适应。"}
{"llm_update_time": "20251015", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.11835", "html_url": "https://arxiv.org/abs/2510.11835", "title": "数据或语言监督：是什么让CLIP比DINO更好？", "title_en": "Data or Language Supervision: What Makes CLIP Better than DINO?", "authors": "Yiming Liu,Yuhui Zhang,Dhruba Ghosh,Ludwig Schmidt,Serena Yeung-Levy", "background": "CLIP作为一种自我监督模型，在视觉语言模型（VLMs）中作为视觉编码器的表现优于DINO，但尚不清楚这种优势是源于CLIP的语言监督还是其庞大的数据量。为了研究这些因素，作者在相同架构、数据集和训练配置的可控环境下预训练CLIP和DINO，取得了类似的表现。通过对嵌入分析，发现CLIP捕捉高层语义（如物体类别和文本），而DINO对低级特征（如颜色和风格）更为敏感。当整合到VLMs并评估20个VQA基准时，CLIP在文本密集的任务中表现更优，而DINO在视觉导向的任务中略胜一筹。语言监督的不同变体（如sigmoid损失、预训练语言编码器）带来的改进有限。这些发现为视觉编码器设计及其对VLM性能的影响提供了科学见解。", "innovation": "作者在相同环境下预训练CLIP和DINO，探讨数据量和语言监督各自对视觉编码器性能的影响。并通过嵌入分析展示了两种模型在特征捕捉上的差异。同时，对不同语言监督方法进行实验，评估其对模型性能的影响。这些方法有助于区分CLIP和DINO在视觉语言模型中的优势所在。", "conclusion": "研究结果表明，无论是数据量还是语言监督，CLIP都能在视觉语言模型中实现更好的表现。具体的，语言监督对模型的影响有限。这一发现对视觉编码器的设计提供了科学指导。"}
{"llm_update_time": "20251015", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.11977", "html_url": "https://arxiv.org/abs/2510.11977", "title": "全面智能代理排行榜：智能代理评估缺失的基础架构", "title_en": "Holistic Agent Leaderboard: The Missing Infrastructure for AI Agent Evaluation", "authors": "Sayash Kapoor,Benedikt Stroebl,Peter Kirgis,Nitya Nadgir,Zachary S Siegel,Boyi Wei,Tianci Xue,Ziru Chen,Felix Chen,Saiteja Utpala,Franck Ndzomga,Dheeraj Oruganty,Sophie Luskin,Kangheng Liu,Botao Yu,Amit Arora,Dongyoon Hahm,Harsh Trivedi,Huan Sun,Juyong Lee,Tengjun Jin,Yifan Mai,Yifei Zhou,Yuxuan Zhu,Rishi Bommasani,Daniel Kang,Dawn Song,Peter Henderson,Yu Su,Percy Liang,Arvind Narayanan", "background": "人工智能代理已经在复杂的现实世界任务中得到了开发，从编程到客户服务。然而，智能代理的评估面临着许多挑战，这些挑战削弱了我们对代理真正工作能力的理解。为了应对这些挑战，作者引入了全面智能代理排行榜（HAL）。", "innovation": "作者的主要贡献包括：1. 提供了一套标准化的评估框架，能够并行评估数百台虚拟机，将评估时间从几周缩短到几小时，同时消除了常见的实现错误；2. 进行了三维分析，涵盖模型、框架和基准；通过21,730次代理滚动测试验证了这个框架的有效性，覆盖了9种模型和9种基准，在编程、网页导航、科学和客户服务领域进行了测试，总成本约为4万美元。作者的研究揭示了一些有趣的洞察，如较高的推理努力在大多数情况下降低了准确性；3. 利用基于LLM的日志检查，发现了之前未报告的行为，例如代理代理在HuggingFace上搜索基准而不是解决任务，或在航班预订任务中错误地使用信用卡。作者还发布了所有代理日志，共计25亿个语言模型调用令牌，以促进对代理行为的进一步研究。", "conclusion": "通过标准化智能代理评估方法和解决代理评估中的常见问题，作者希望从专注于在基准上表现优异的代理转向专注于在现实世界中可靠工作的代理。"}
{"llm_update_time": "20251015", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.11851", "html_url": "https://arxiv.org/abs/2510.11851", "title": "Deep Research Brings Deeper Harm", "title_en": "Deep Research Brings Deeper Harm", "authors": "Shuo Chen,Zonggen Li,Zhen Han,Bailan He,Tong Liu,Haokun Chen,Georg Groh,Philip Torr,Volker Tresp,Jindong Gu", "background": "基于大型语言模型（LLMs）的深度研究（DR）代理可以通过分解任务、检索在线信息和合成详细报告来进行复杂的多步骤研究。然而，这类具备强大能力的LLMs的误用可能会带来更大的风险，尤其是在生物安全等高风险和知识密集型领域中，DR可以生成包含详细禁用知识的专业报告。研究团队在实践中发现，即使有害查询被独立的LLM直接拒绝，DR代理也可能产生详细且危险的报告，这突显了更高的风险，并强调了更深入的安全分析的需求。传统的打破方法（jailbreak methods）在暴露DR代理独特的风险方面存在不足，因为它们不针对DR代理的研究能力。", "innovation": "论文提出了两种新颖的打破策略：计划注入（Plan Injection），该策略将恶意子目标注入代理的计划中；意图接管（Intent Hijack），该策略将有害查询重新转译为学术研究问题。通过在不同的大语言模型（LLMs）和各种安全基准测试中进行广泛的实验，包括通用和生物安全禁用提示，实验揭示了3个关键发现：(1) LLMs在DR代理中的对齐常常失败，有害提示以学术术语表达可以篡夺代理的意图；(2) 多步骤的计划和执行削弱了对齐，揭示了系统性漏洞，这些漏洞是单一提示级别保护所无法解决的；(3) DR代理不仅绕过了拒绝，还产生了比独立LLM更加连贯、专业且危险的内容。", "conclusion": "这些结果显示了DR代理中存在的根本性不对齐问题，并呼吁开发针对DR代理更有效的对齐技术。有关的代码和数据集可在提供的链接中获取。"}
{"llm_update_time": "20251015", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.12000", "html_url": "https://arxiv.org/abs/2510.12000", "title": "UALM: 统一音频语言模型以实现理解和生成以及推理", "title_en": "UALM: Unified Audio Language Model for Understanding, Generation and Reasoning", "authors": "Jinchuan Tian,Sang-gil Lee,Zhifeng Kong,Sreyan Ghosh,Arushi Goel,Chao-Han Huck Yang,Wenliang Dai,Zihan Liu,Hanrong Ye,Shinji Watanabe,Mohammad Shoeybi,Bryan Catanzaro,Rafael Valle,Wei Ping", "background": "近期的音频语言模型（ALM）研究将音频理解与文本到音频生成视为两个独立的任务。很少有研究试图将这些任务统一起来，这是为了向高级多模态推理迈出关键一步。这项工作的背景是在音频领域中将音频理解、文本到音频生成和多模态推理统一在一个模型中。", "innovation": "这项工作引入了统一音频语言模型（UALM），旨在将音频理解、文本到音频生成和多模态推理统一在一个模型中。UALM-Gen 是用于文本到音频生成的语言模型，可以直接预测音频标记，并且在质量上可以媲美最新的扩散模型。通过适当的数据混合、训练策略以及推理技术，单个 UALM 模型在音频理解、文本到音频生成、文本推理方面均能达到最先进的专业模型的水平。UALM-Reason 是一个多模态推理模型，使用文本和音频进行中间推理步骤，它有助于复杂生成任务。这是音频研究中首次实现跨模态生成推理，并通过主观评估确认其有效性。", "conclusion": "研究表明，单个 UALM 模型在音频理解、文本到音频生成、文本推理方面均能达到最先进的专业模型的水平。UALM-Reason 模型通过将文本和音频信息融合到中间推理步骤中的方法，有效增强了复杂生成任务的能力。这是一个重要的突破，为高级多模态推理提供了可能。"}
{"llm_update_time": "20251015", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.12063", "html_url": "https://arxiv.org/abs/2510.12063", "title": "ThinkPilot: 通过自动think-prefixes优化引导推理模型", "title_en": "ThinkPilot: Steering Reasoning Models via Automated Think-prefixes Optimization", "authors": "Sunzhu Li,Zhiyu Lin,Shuling Yang,Jiale Zhao,Wei Chen", "background": "大型推理模型（LRMs）虽然功能强大，但仍然存在效率低下和目标偏离的问题。目前的训练-free方法要么依赖于固定的直觉，要么提供描述性但不可操作的分析。本文通过引入ThinkPilot，一个无需训练的框架，自动优化LRMs的推理过程。ThinkPilot利用进化过程生成think-prefixes，这些前缀由推理行为分类驱动，以引导模型实现更优表现。", "innovation": "ThinkPilot是一个无需训练的框架，通过生成并优化think-prefixes来自动优化大型推理模型的推理过程。这些think-prefixes由推理行为分类驱动，能够引导模型实现更优的表现，显著改善了推理的准确性与效率之间的折衷，大幅度提升了安全性，并增强了指令的遵循。此外，ThinkPilot还能与基于训练的方法协同工作，可靠地控制大型推理模型的推理行为，不同任务偏好不同的行为分布，并自动识别和激发这些行为，提供了一种通用的框架来使大型推理模型的推理与任务需求相一致。", "conclusion": "广泛的实验表明，ThinkPilot在控制大型推理模型的推理行为、改善其性能方面具有广泛的有效性。通过自动识别并激发特定的任务需求，ThinkPilot提供了一个可泛化的框架，用于将大型推理模型的推理过程与任务需求相匹配。研究数据和代码可获取。"}
{"llm_update_time": "20251015", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.12121", "html_url": "https://arxiv.org/abs/2510.12121", "title": "通过目标化表示编辑在大型语言模型中实现精确属性强度控制", "title_en": "Precise Attribute Intensity Control in Large Language Models via Targeted Representation Editing", "authors": "Rongzhi Zhang,Liqin Ye,Yuzhao Heng,Xiang Chen,Tong Yu,Lingkai Kong,Sudheer Chava,Chao Zhang", "background": "为了使人工智能系统能够适应多样的用户期望，精确属性强度控制——生成具有特定、用户定义属性强度的大语言模型（LLM）输出——变得至关重要。然而，当前的LLM对齐方法通常只能提供方向性或开放性的指导，无法可靠地实现精确的属性强度。", "innovation": "本文提出了三种关键设计来解决这一局限性：1）将精确的属性强度控制重新表述为目标到达问题，而非简单的最大化；2）通过时差学习训练一个轻量级的价值函数，从部分生成内容预测最终的属性强度评分，从而引导LLM输出；3）通过梯度干预隐含表示，使模型能够精确地向特定属性强度目标方向导航。这种方法能够实现精细的、连续的属性强度控制，超越了简单的方向对齐。", "conclusion": "实验表明我们的方法能够高度准确地引导文本生成到用户指定的属性强度，并在三个下游任务中展示了效率增强：偏好评价数据合成、帕累托前沿逼近和优化、以及干预自由推理中对齐行为的蒸馏。"}
{"llm_update_time": "20251015", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.12088", "html_url": "https://arxiv.org/abs/2510.12088", "title": "One Life to Learn: Inferring Symbolic World Models for Stochastic Environments from Unguided Exploration", "title_en": "One Life to Learn: Inferring Symbolic World Models for Stochastic Environments from Unguided Exploration", "authors": "Zaid Khan,Archiki Prasad,Elias Stengel-Eskin,Jaemin Cho,Mohit Bansal", "background": "符号世界建模要求推断和表示环境的转换动力学，作为可执行程序。以往的研究主要集中在几乎确定性的环境中，这些环境有丰富的交互数据，简单的机械结构，并且有人类的指导。这项研究则专注于在随机性更强、更为复杂的环境中学习，强调在缺乏人类指导的情况下，仅凭有限的交互探索险恶环境。为此，研究者们开发了一个名为OneLife的框架，通过在概率编程框架中激活条件程序化法则来建模世界动态。", "innovation": "OneLife框架通过引入条件激活的程序化法则，构造了一个动态计算图，仅在相关世界状态下激活法则，从而有效地避免了所有法则都能预测复杂层次状态时带来的扩展难题。这种机制使系统能够在规则激活稀疏的情况下学习随机性动力学。此外，研究还提出了一个评估协议，该协议包括状态排名和状态保真度两个评估维度，以便在严格条件下验证方法的有效性。", "conclusion": "OneLife框架在实验中表现出了卓越的性能，在23种测试场景中的16种中优于基线方法。同时，研究也展示了OneLife的规划能力，其模拟滚动展示了能够识别出更优策略。该研究奠定了自主构建复杂未知环境中程序化世界模型的基础。"}
{"llm_update_time": "20251015", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.12200", "html_url": "https://arxiv.org/abs/2510.12200", "title": "HackWorld: 评估计算机使用代理在利用web应用程序漏洞方面的能力", "title_en": "HackWorld: Evaluating Computer-Use Agents on Exploiting Web Application Vulnerabilities", "authors": "Xiaoxue Ren,Penghao Jiang,Kaixin Li,Zhiyong Huang,Xiaoning Du,Jiaojiao Jiang,Zhenchang Xing,Jiamou Sun,Terry Yue Zhuo", "background": "网络应用程序是网络攻击的主要目标，因为它们是关键服务和敏感数据的入口点。传统渗透测试成本高、需要高度的专业知识，难以与不断扩大的网络生态系统同步。尽管语言模型代理在网络安全方面显示出潜力，但现代web应用程序要求视觉理解、动态内容处理和多步骤交互，这些只能由计算机使用代理（CUAs）完成。然而，它们通过图形界面发现和利用漏洞的能力仍被广泛忽视。", "innovation": "HackWorld 是第一个系统评估CUAs在通过视觉交互利用web应用程序漏洞方面能力的框架。它包括了36个真实世界的应用程序，涵盖了11个框架和7种语言，具有现实的漏洞，如注入漏洞、身份验证绕过和不安全输入处理。通过截旗赛（CTF）设置，测试CUAs识别和利用这些弱点并导航复杂Web界面的能力。", "conclusion": "对前沿CUAs的评估揭示了一些令人担忧的趋势：低于12%的利用率和低网络安全意识。CUAs常常在多步骤攻击规划和误用安全工具方面失败。这些结果揭示了CUAs在web安全领域的当前局限性，并指出了开发更安全意识强的代理，能够有效发现和利用漏洞的机会。"}
{"llm_update_time": "20251015", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.12178", "html_url": "https://arxiv.org/abs/2510.12178", "title": "元研究机构的LLaMA模型演变与大规模语言模型参数高效微调：一项综述", "title_en": "Evolution of meta's llama models and parameter-efficient fine-tuning of large language models: a survey", "authors": "Abdulhady Abas Abdullah,Arkaitz Zubiaga,Seyedali Mirjalili,Amir H. Gandomi,Fatemeh Daneshfar,Mohammadsadra Amini,Alan Salam Mohammed,Hadi Veisi", "background": "本文综述了Meta AI公司LLaMA系列模型的快速演变，从LLaMA 1到LLaMA 4及其所开发的参数高效微调（PEFT）方法。介绍了LLaMA家族的基础模型（7B-65B到288B参数）、它们的架构（包括原生 multimodal 和 Mixture-of-Experts 变体），以及关键性能特征。本文还探讨了PEFT的概念，即通过只更新一小部分参数来适应大规模预训练模型的方法，并回顾了已应用于LLaMA的五种PEFT方法：LoRA（低秩适应）、LLaMA-Adapter V1 和 V2、LLaMA-Excitor 和 QLoRA（量化LoRA），并分析了每种方法的机制、参数节省以及在LLaMA上的应用示例（例如指令调整、多模态任务）。", "innovation": "本文介绍了LLaMA系列模型及其对应的PEFT方法，尤其是五种特定的PEFT方法：LoRA、LLaMA-Adapter V1 和 V2、LLaMA-Excitor 和 QLoRA。文章详细讨论了每种方法的机制、节省的参数数量以及它们在LLaMA中的应用案例。同时，还提供了模型和适配器架构的结构化讨论、参数计数以及基准结果（包括微调后的LLaMA模型在某些任务上比更大基线模型表现更优的例子）。", "conclusion": "本文最终探讨了使用LLaMA基础模型及其PEFT方法在实际应用中的成功案例（如法律和医学领域），并讨论了未来研究方向（如扩展到更大上下文和提高鲁棒性）。本文提供了一站式资源，旨在帮助ML研究者和实践者了解LLaMA模型及其高效微调策略。"}
{"llm_update_time": "20251015", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.12210", "html_url": "https://arxiv.org/abs/2510.12210", "title": "DiSTAR: 在可扩展的标记自回归表示上进行扩散以生成语音", "title_en": "DiSTAR: Diffusion over a Scalable Token Autoregressive Representation for Speech Generation", "authors": "Yakun Song,Xiaobin Zhuang,Jiawei Chen,Zhikang Niu,Guanrou Yang,Chenpeng Du,Zhuo Chen,Yuping Wang,Yuxuan Wang,Xie Chen", "background": "近期尝试将自回归（AR）绘图方法与基于扩散的完善器结合应用于连续语音表示中，显示出一定的前景，但仍存在在分布转移下脆弱的问题，且提供的可控性有限。现有的零样本文本到语音系统在这方面尚存在不足，特别是在鲁棒性和多样性之间的权衡上显得不够灵活。", "innovation": "本文提出了一种名为DISTAR的新框架，该框架完全在离散残差矢量量化（RVQ）码空间中工作，并结合了AR语言模型与掩码扩散模型，无需强制对齐或持续预测器。具体来说，DISTAR 使用AR语言模型撰写区块级RVQ令牌，然后在草稿的基础上进行并行的掩码扩散填充，以完成下一个区块，从而实现长段合成，并缓解了经典的AR曝光偏差。此外，离散码空间在推理时提供明确的控制，使得DISTAR在贪婪解码和基于样本的解码下都能生成高质量的音频，支持鲁棒性和多样性的权衡，并允许测试时通过RVQ层剪枝实现可控的比特率和计算量。", "conclusion": "广泛的实验和消融实验表明，DISTAR 在鲁棒性、自然度和说话人/风格一致性方面超越了现有最先进的零样本TTS系统，同时保持了丰富的输出多样性。"}
{"llm_update_time": "20251015", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.12327", "html_url": "https://arxiv.org/abs/2510.12327", "title": "简单的投影变体提高ColBERT性能", "title_en": "Simple Projection Variants Improve ColBERT Performance", "authors": "Benjamin Clavié,Sean Lee,Rikiya Takehi,Aamir Shakir,Makoto P. Kato", "background": "多向量密集检索方法（如ColBERT）通常使用单一的线性投影来降低每个向量的维度。本文探讨了MaxSim操作符在多向量模型训练梯度流动中的影响，揭示了这种简单的线性投影在这种情况下存在固有的非关键限制。", "innovation": "本文提出了用已研究过的前向线性网络（FFN）替代单一线性投影，包括更深的非线性FFN块、GLU块和跳接连接，以缓解这些限制。通过设计和系统评估不同的投影块，研究表明精心设计的最终投影可提高ColBERT模型的下游性能。此外，研究还发现许多投影变体优于原始线性投影，性能最佳的变体在一系列跨领域的检索基准上提高了NDCG@10平均分数。", "conclusion": "研究进一步探讨了这些投影块的各个参数，揭示了中等放大投影和残差连接在驱动实证性能中的重要性。实验结果显示，即使在多个基准上使用多种非最优投影变体也优于传统的单一层投影，从而证实了我们的假设。最终，研究结果表明用馈前网络替换ColBERT模型中的线性层是一个稳健的可替代升级方法，这一效果在随机种子中是一致的。"}
{"llm_update_time": "20251015", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.12287", "html_url": "https://arxiv.org/abs/2510.12287", "title": "视觉语言模型通过视觉投影中的语义纠缠映射徽标到文本", "title_en": "Vision Language Models Map Logos to Text via Semantic Entanglement in the Visual Projector", "authors": "Sifan Li,Hongkai Chen,Yujun Cai,Qingwen Ye,Liyang Chen,Junsong Yuan,Yiwei Wang", "background": "视觉语言模型（VLMs）在过去取得了显著进展，但在处理多媒体推理时仍然容易出现幻觉现象，即模型生成的内容缺乏视觉证据支持。本文研究了一个之前被忽视的场景——标识幻觉，即模型在标识不包含明显文字的情况下生成品牌名称或文本内容。研究人员使用精心划分的纯符号、混合和带文本标识的数据集，以及具有挑战性的Hard-60子集，系统性地评估了领先VLMs的幻觉现象，并探索了其稳健性。", "innovation": "研究提出了一个新颖的诊断视角和实际缓解策略，通过语义纠缠在视觉投影中的结构化扰动分析，揭示了幻觉的根本原因，并展示了通过嵌入层分析和定向消融如何减少错误。研究表明，VLMs往往依赖于符号先验而非真实的图形感知，尤其是在标志性的圆形标识中。视觉投影子空间在这一失败模式中起着关键作用。这项工作为构建更加可信的多媒体系统提供了有前景的方向，强调了解耦目标投影空间和OCR指导解码的重要性。", "conclusion": "这些发现表明，VLMs在处理具有重要符号意义的徽标时依赖于先验符号而非真实的图形感知，尤其是在标志性的圆形标识中。视觉投影子空间在这一失败模式中扮演着关键角色。本研究提供了一个新的诊断工具和实际缓解措施，通过解耦目标投影空间和OCR指导解码，揭示了构建更加可信的多媒体系统的潜在途径。"}
{"llm_update_time": "20251015", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.12603", "html_url": "https://arxiv.org/abs/2510.12603", "title": "暗中推理：潜空间中的交错视觉-文本推理", "title_en": "Reasoning in the Dark: Interleaved Vision-Text Reasoning in Latent Space", "authors": "Chao Chen,Zhixin Ma,Yongqi Li,Yupeng Hu,Yinwei Wei,Wenjie Li,Liqiang Nie", "background": "多模态推理旨在通过在达到最终答案之前引入中间推理步骤来增强MLLM的能力。它已经从仅基于文本的推理发展到结合视觉信息的集成，使得思维过程可以通过图像和文本两种方式进行传达。尽管这种方法非常有效，但当前的多模态推理方法依赖于需要大量视觉-文本标注的显式推理步骤，且不可避免地引入了较大的推理延迟。", "innovation": "本文提出了一种名为Interleaved Vision-Text Latent Reasoning (IVT-LR)的新方法，通过在潜空间中注入视觉和文本信息来执行多模态隐式推理。具体表现为，每个推理步骤由两个部分构成：隐式文本（前一步的隐状态）和隐视图（一组选定的图像嵌入）。此外，还提出了一个渐进式多阶段训练策略，以使MLLM能够执行上述多模态隐式推理步骤。实验结果表明，IVT-LR方法相比现有方法在准确性上平均提高了5.45%，且推理速度提高了5倍以上。", "conclusion": "研究结果证明，IVT-LR方法在保持高准确性的同时显著提高了推理效率。通过在潜空间中引入交错的视觉-文本推理，该方法克服了当前多模态推理方法中的缺点，展示了显著的性能和效率提升。"}
{"llm_update_time": "20251015", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.12780", "html_url": "https://arxiv.org/abs/2510.12780", "title": "Content Anonymization for Privacy in Long-form Audio", "title_en": "Content Anonymization for Privacy in Long-form Audio", "authors": "Cristina Aggazzotti,Ashi Garg,Zexin Cai,Nicholas Andrews", "background": "以往的研究表明，语音匿名化技术在短暂孤立语音中能够有效隐藏说话人的声纹身份。然而，在实践中，长段音频在访谈、电话会议等场景中常见，这些情境中存在多条同说话人的语音记录，这增加了隐私泄露的风险。通过分析多条语音记录，攻击者能够利用说话人的词汇、语法和常用表达来重新识别说话人，即使声音已经被完全掩饰。因此，为应对这一风险，论文提出了内容匿名化的新方法，并在长对话场景下验证了其效果。", "innovation": "提出了内容匿名化的新方法，并在ASR-TTS流程中进行了上下文重写来消除说话人的特定风格，同时保留语言意义。通过在长电话对话场景下的实验，展示了基于内容的攻击对匿名化语音的有效性，并提出了内容基础上的匿名化方法如何减轻风险并保持语音实用性。研究发现，改写是有效防御内容攻击的方法，并建议相关利益方采用这种方法保证长段音频中的匿名性。", "conclusion": "研究证实了内容匿名化方法能有效防御基于内容的攻击，保护长语音中的隐私，并且建议在长录音和对话中应用该方法进一步保障隐私安全。"}
{"llm_update_time": "20251015", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.12680", "html_url": "https://arxiv.org/abs/2510.12680", "title": "揭开混合思维的神秘面纱：LLMs能否真正切换思考与不思考模式？", "title_en": "Demystifying Hybrid Thinking: Can LLMs Truly Switch Between Think and No-Think?", "authors": "Shouren Wang,Wang Yang,Xianxuan Long,Qifan Wang,Vipin Chaudhary,Xiaotian Han", "background": "现有的混合思维LLMs能够通过切换到推理和直接回答模式来平衡效率和推理能力，但实验显示，这些LLMs常常在无需思考模式中渗入推理行为。为了理解并缓解这一问题，作者分析了影响控制性的因素，确定了四个关键因素：（1）更大的数据规模，（2）使用来自不同问题的思考与不思考回答而非相同问题，（3）适度增加不思考数据的数量，（4）采用两阶段策略先训练推理能力再进行混合思维训练。这些发现揭示了当前混合思维的局限性并对如何增强其可控性提供了方向.", "innovation": "作者提出了一种实用的方法，与标准训练相比，该方法可以在两种模式中保持准确率的同时，显著减少不思考输出长度（从MATH500的1085减少到585）和支持推理的标记（从5917减少到522）。这种方法弥补了当前混合思维的不足，并提供了增强其可控性的方向.", "conclusion": "研究结果揭示了当前混合思维存在的局限性，并为其可控性的加强提供了指导方向。"}
{"llm_update_time": "20251015", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.12668", "html_url": "https://arxiv.org/abs/2510.12668", "title": "参数化注入的角色——参数化检索增强生成的系统性研究", "title_en": "The Role of Parametric Injection-A Systematic Study of Parametric Retrieval-Augmented Generation", "authors": "Minghao Tang,Shiyu Ni,Jingtong Wu,Zengxin Han,Keping Bi", "background": "检索增强生成（RAG）通过检索外部文档来增强大型语言模型（LLMs）。作为一种新兴形式的RAG，参数化检索增强生成（PRAG）将文档编码为模型参数（即LoRA模块），在推理过程中将这些表示注入模型，使得LLM与文档在参数级别进行交互。这比直接将文档放置在输入上下文中更加高效，并有可能提供更深层次的模型-文档交互。尽管PRAG越来越受到关注，其背后的机制仍然不完全理解。因此，该研究进行了一项系统性调查，以澄清参数化注入的作用，结果显示参数化文档只能捕捉文档的部分语义信息，单独依赖这些参数表现比文本级别互动更差。但是这些参数化表示可以编码高级别文档信息，有助于增强模型在输入上下文中对文档的理解。当结合使用参数化和文本表示时，模型可以更有效地利用相关信息，并对抗噪声输入更具鲁棒性，从而优于单独任何一种来源。研究者建议联合使用参数化和文本表示，并倡导增加参数表示的信息量以促进PRAG的发展。", "innovation": "研究进行了一项系统性调查，阐明了参数化注入的角色，指出参数化文档捕捉到的是文档的部分语义信息，单独依赖参数化表示的表现不及文本级别的交互。同时指出，综合使用参数化和文本表示能更好地利用相关信息，并提高模型的鲁棒性。此项研究揭示了参数化方法中的关键机制，丰富了PRAG的理论基础。", "conclusion": "研究建议联合使用参数化和文本表示，并增加参数表示的信息量以推进PRAG的发展。通过这种方法，模型可以在处理噪声输入时表现得更加稳健，并且能够更有效地利用相关信息。"}
{"llm_update_time": "20251015", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.12692", "html_url": "https://arxiv.org/abs/2510.12692", "title": "谁是更好的媒人？高风险创业竞赛中人力与算法法官匹配", "title_en": "Who is a Better Matchmaker? Human vs. Algorithmic Judge Assignment in a High-Stakes Startup Competition", "authors": "Sarina Xi,Orelia Pi,Miaomiao Zhang,Becca Xiong,Jacqueline Ng Lane,Nihar B. Shah", "background": "近年来，人工智能被广泛关注以自动完成和支撑复杂决策任务。然而，在需要语义理解和专业知识的背景下，算法与人类判断相比的优势仍不明确。本研究探讨了语义理解和专业知识需求环境下法官分配问题，即如何将提交的作品与合适的法官匹配的问题。这一问题在一个高风险的创业竞赛环境中得到研究，即哈佛校长创新挑战赛，该竞赛颁发超过50万美元的奖金给学生和校友创办的企业，要求高质的法官分配。", "innovation": "本研究开发了一种基于人工智能的法官分配算法——混合词汇语义相似性集成（HLSE），并在竞赛中部署使用。它还通过盲数据评分的方法评估了算法表现与人类专家分配表现的差异，未发现统计学上的显著性差异。同时，以往需要一周才能完成的手动匹配，在算法部署中数小时内就完成了。这意味着算法在保持与人类专家相同匹配质量的同时，还提高了可扩展性和效率，强调了AI驱动解决方案在支持和增强高风险环境下的法官匹配决策中的潜力。", "conclusion": "这项研究的结果表明，HLSE算法达到了人类专家级别的匹配质量，同时具备更大的可扩展性和效率优势，证明了AI驱动的问题解决方法在支持和增强复杂决策过程中的潜力。"}
{"llm_update_time": "20251015", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2207.13929", "html_url": "https://arxiv.org/abs/2207.13929", "title": "MLRIP：使用信息性事实知识和专业知识库预先训练军事语言表示模型", "title_en": "MLRIP: Pre-training a military language representation model with informative factual knowledge and professional knowledge base", "authors": "Hui Li,Xuekang Yang", "background": "将结构化知识整合到预训练语言模型中，已在特定领域自然语言处理任务中显示出显著的好处，特别是在如军事情报分析等专业领域。现有方法通常通过掩码技术和融合机制来整合外部知识，但往往无法充分利用输入序列中的内在战术关联和事实信息，还会引入未验证的外部来源的噪声。", "innovation": "我们提出了MLRIP（Military Language Representation with Integrated Prior）新颖的预训练框架，结合了层次知识集成管道和双阶段实体替换机制。该方法特别建模了军事实体之间的操作链接，捕捉了诸如指挥、支持和互动结构等关键依赖关系。", "conclusion": "全面评估结果表明，MLRIP在军事特定的NLP任务中表现优于现有的BERT基线模型，建立了军事实体识别、分类和操作链接提取任务的新最优性能，同时也展示了在资源受限环境中操作效率的优势。"}
{"llm_update_time": "20251015", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.12784", "html_url": "https://arxiv.org/abs/2510.12784", "title": "SRUM：统一多模态模型的精细自我奖励", "title_en": "SRUM: Fine-Grained Self-Rewarding for Unified Multimodal Models", "authors": "Weiyang Jin,Yuwei Niu,Jiaqi Liao,Chengqi Duan,Aoxue Li,Shenghua Gao,Xihui Liu", "background": "近期，统一多模态模型（UMMs）取得了显著进展，这些模型具备了将视觉和语言理解能力集成到单一框架中的能力。然而，这类模型在视觉理解与生成之间仍然存在显著差距，即模型在基于用户指令正确理解图片后，却无法从文本提示中生成忠实的图片。为解决这一问题，本研究探讨了模型能否通过其理解模块自行奖励生成模块实现自我提升。", "innovation": "本文提出了一种名为SRUM的新框架，这是一种自我奖励的后训练体系结构，可以应用于不同设计的已有UMMs。SRUM采用一种全球-局部双奖励系统，提供多尺度指导，以确保反馈的全面性。全局奖励用于确保整体视觉语义和布局的正确性，局部奖励则改进对象级别的精细度。通过这种方法，SRUM显著提升了T2I-CompBench和T2I-ReasonBench等测试集上的性能。", "conclusion": "本研究通过SRUM引入了一种强有力的新范式，使得UMMs的理解模块能够通过自我奖励机制引导并增强其生成模块，从而在统一多模态模型上展示了强大的自我改进和泛化能力。"}
{"llm_update_time": "20251015", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2308.00802", "html_url": "https://arxiv.org/abs/2308.00802", "title": "GRDD: 希腊方言NLP的数据集", "title_en": "GRDD: A Dataset for Greek Dialectal NLP", "authors": "Stergios Chatzikyriakidis,Chatrine Qwaider,Ilias Kolokousis,Christina Koula,Dimitris Papadakis,Efthymia Sakellariou", "background": "该论文提供了一个用于现代希腊方言计算研究的方言数据集。该数据集包含四种现代希腊方言的原始文本数据：克里特方言、Pontic方言、北希腊方言和塞浦路斯希腊方言。数据集很大，尽管存在不平衡问题，但它是首次尝试为现代希腊方言创建此类大规模方言资源。文体实验首先使用传统的ML算法，然后使用简单的DL架构。结果显示，即使使用简单的模型，也能很好地完成任务，这可能表明问题方言具有足够的特征以使模型表现良好。", "innovation": "该数据集是第一次尝试创建该类型大规模方言资源的数据集。实验还首次进行了方言识别，并展示了不同算法的错误分析。", "conclusion": "该数据集展示了即使是简单的模型也能很好地完成方言识别任务，表明这些方言具有足够的特征。部分错误分析揭示了数据集清理不足的问题。"}
{"llm_update_time": "20251015", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2404.06970", "html_url": "https://arxiv.org/abs/2404.06970", "title": "Hybrid Multi-stage Decoding for Few-shot NER with Entity-aware Contrastive Learning", "title_en": "Hybrid Multi-stage Decoding for Few-shot NER with Entity-aware Contrastive Learning", "authors": "Congying Liu,Gaosheng Wang,Peipei Liu,Xingyuan Wei,Hongsong Zhu", "background": "Few-shot named entity recognition (NER) can identify new named entities based on a few labeled examples. Previous methods, such as token-level or span-level metric learning, suffer from computational burden and a large number of negative sample spans.", "innovation": "MsFNER (Hybrid Multi-stage Decoding for Few-shot NER with Entity-aware Contrastive Learning) proposes a two-stage approach: entity-span detection and entity classification. It uses meta-learning to train and get the best entity-span detection model and entity classification model on the source domain. A contrastive learning module is introduced to enhance entity representations. During fine-tuning, the models are adjusted on the target domain support dataset, and at inference, entity-spans are jointly determined by the entity classification model and KNN (K-Nearest Neighbors).", "conclusion": "Experiments on the open FewNERD dataset show the advancement of MsFNER."}
{"llm_update_time": "20251015", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2402.10601", "html_url": "https://arxiv.org/abs/2402.10601", "title": "当推理能力成为漏洞之门：通过新型复杂密文破解大型语言模型", "title_en": "When \"Competency\" in Reasoning Opens the Door to Vulnerability: Jailbreaking LLMs via Novel Complex Ciphers", "authors": "Divij Handa,Zehua Zhang,Amir Saeidi,Shrinidhi Kumbhar,Md Nayem Uddin,Aswin RRV,Chitta Baral", "background": "近年来，大型语言模型（LLM）的安全性主要集中在应对自然语言或常见加密（例如Base64格式）构建的攻击，但随着LLM在推理方面的发展，它们意外地变得更加容易受到新型脱狱式攻击。这种能力使它们能够理解和解码复杂的用户定义密文，从而造成潜在的安全漏洞。研究人员引入了Attacks using Custom Encryptions (ACE) 和 Layered Attacks using Custom Encryptions (LACE) 方法来研究这一问题，并开发了CipherBench 来评估LLM在解密被加密的文本方面的准确性。实验表明，更擅长解密密文的LLM更容易受到LACE攻击，这揭示了一个危险的权衡：在提高自身能力同时，也增加了被攻击的风险。", "innovation": "提出了Attacks using Custom Encryptions (ACE) 和 Layered Attacks using Custom Encryptions (LACE) 方法，以及开发了CipherBench 评估工具来专门测试LLM在复杂密文中解密良性文本的准确性。这些方法和工具揭示了LLM能够解密新型复杂用户定义密文的特征，同时也增加了它们在实际使用中的攻击面。", "conclusion": "研究表明，LLM在提高解密复杂密文的能力的同时，也变得更容易受到攻击。对于未来的训练和使用，开发人员和安全专家需要注重平衡提高LLM的安全性和实用性。"}
{"llm_update_time": "20251015", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2412.12004", "html_url": "https://arxiv.org/abs/2412.12004", "title": "开源在大规模语言模型中的优势", "title_en": "The Open Source Advantage in Large Language Models (LLMs)", "authors": "Jiya Manchanda,Laura Boettcher,Matheus Westphalen,Jasser Jasser", "background": "大规模语言模型（LLMs）已经在自然语言处理领域取得了迅速的进步，特别是在文本生成、机器翻译和领域特定推理任务中取得了重大突破。现在，该领域面临着关键性的问题：一方面，闭源模型如GPT-4能够提供最先进的性能，但会限制可再现性、可访问性和外部监督；另一方面，开源框架如LLaMA和Mixtral则能够普及访问、促进协作并支持多种应用，通过技术如指令微调和LoRA实现了竞争性的结果。混合适应也通过结合闭源系统的可扩展性和开源框架的透明度和包容性解决了一些挑战。然而，本文认为开源仍是推进LLM研究和伦理部署的最稳健途径。", "innovation": "本文提出开放源代码是推进LLM研究和伦理部署的最佳途径，即使闭源模型在性能上更具优势，但开源模型虽然在性能上相对较低，却在普及性、合作性、透明性和包容性方面更具优势，并通过指令微调和LoRA等技术取得了竞争性的结果。进一步提出开源框架可以在不牺牲性能的情况下解决偏见缓解和资源可访问性等问题。", "conclusion": "开源仍然是推进大规模语言模型研究和伦理部署的最稳健路径。"}
{"llm_update_time": "20251015", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2406.02575", "html_url": "https://arxiv.org/abs/2406.02575", "title": "跨模态安全对齐：仅需文本去学习吗？", "title_en": "Cross-Modal Safety Alignment: Is textual unlearning all you need?", "authors": "Trishna Chakraborty,Erfan Shayegani,Zikui Cai,Nael Abu-Ghazaleh,M. Salman Asif,Yue Dong,Amit K. Roy-Chowdhury,Chengyu Song", "background": "近年来的研究表明，将新模态（如视觉-语言模型VLMs）集成到大规模语言模型（LLMs）中，创建了一个新的攻击面，绕过了现有的安全训练技术，如监督微调（SFT）和强化学习带有反馈的人工智能（RLHF）。虽然可以在多模态环境中进一步进行SFT和RLHF安全训练，但收集多模态训练数据是一项重大挑战。当前的多模态模型结构设计表明，不论输入模态的组合如何，所有输入最终都会融合到语言空间。在这项研究中，研究人员探索了在文本领域进行去学习是否可以在跨模态安全对齐中有效。", "innovation": "受当前多模态模型设计的启发，研究人员尝试了仅在文本领域进行去学习来实现跨模态的安全对齐。实验结果显示，在六个数据集上评估证明，这种做法具有可转移性，文本域去学习（文本和视听说-文本攻击）显著降低了攻击成功率（ASR）到少于8%，在某些情况下甚至低至接近2%。此外，研究发现使用多模态数据集进行去学习并不会提供任何潜在的好处，但会带来计算成本的显著增加，可能高达6倍。", "conclusion": "研究结果表明，仅在文本领域进行去学习在某些攻击类型中可以有效降低攻击成功率，而使用多模态数据集进行去学习则成本过高且并无额外改善。"}
{"llm_update_time": "20251015", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2502.04075", "html_url": "https://arxiv.org/abs/2502.04075", "title": "从理性的回答到情感共鸣：可控情绪生成在语言模型中的作用", "title_en": "From Rational Answers to Emotional Resonance: The Role of Controllable Emotion Generation in Language Models", "authors": "Yurui Dong,Luozhijie Jin,Yao Yang,Bingjie Lu,Jiaxi Yang,Zhi Liu", "background": "情感是人类沟通的基本组成部分，影响理解、信任和参与度，特别是在教育、医疗和心理健康等领域。尽管大型语言模型在推理和知识生成方面表现出色，但在表达一致、可控且情境适当的情感方面仍存在问题。这一限制限制了它们在真实的人机互动中的潜力。", "innovation": "我们提出了一种基于情绪向量（EVs）的可控情绪生成框架——这是一种从中性状态和情绪条件反应之间的内部激活变化中提取的潜在表示。通过在推理过程中向预先训练好的大语言模型中的隐藏状态注入这些向量，该方法能够实现精细、连续的情绪色调调整，而无需任何额外的训练或架构修改。此外，理论分析证明，情绪向量控制增强了情绪表达性，同时保持语义准确性和语言流畅性。", "conclusion": "情绪向量（EV）控制提供了一种有效且可解释的方法来在大语言模型中结合逻辑推理和情感理解，为构建能够实现更自然人机交互的情感共鸣人工智能系统提供了前景。"}
{"llm_update_time": "20251015", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2502.09457", "html_url": "https://arxiv.org/abs/2502.09457", "title": "语言模型中的多语言推理综述", "title_en": "A Survey of Multilingual Reasoning in Language Models", "authors": "Akash Ghosh,Debayan Datta,Sriparna Saha,Chirag Agarwal", "background": "近年来，语言模型（LMs）在推理和多语言能力方面取得了显著进展，但这些能力尚未在统一的多语言推理范式中得到广泛应用。多语言推理需要大规模处理跨语言的逻辑推理，同时解决语料库不平衡、偏见及资源短缺的问题。本文是首份深入综述多语言推理在LMs中的研究和应用的文献，回顾了现有方法、挑战、动机及基础方面，提供了标准数据资源及评价指标的概览，分析了先进方法的表现，并探讨了未来研究机会以提升语言模型处理多元语言和复杂推理任务的能力。", "innovation": "本文首次系统性回顾了多语言推理在语言模型中的应用，详细介绍了现有的方法、数据资源和评价标准，分析了最新方法在各种基准上的表现，并提出了未来研究的方向，旨在提升多语言推理的能力。此外，文章还列出了该项目的实时跟踪页面，反映了该领域的发展动态。", "conclusion": "本文深入探讨了多语言推理在语言模型中的应用，提出了多种现有方法及其在不同基准上的表现分析，并展望了未来的研究机会，强调了提升语言模型处理多元语言和复杂推理任务能力的重要性，同时也鼓励了对该领域持续的关注和研究。"}
{"llm_update_time": "20251015", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2502.00299", "html_url": "https://arxiv.org/abs/2502.00299", "title": "_chunkkv: 保留语义的kv缓存压缩以实现高效长上下文llm推理", "title_en": "ChunkKV: Semantic-Preserving KV Cache Compression for Efficient Long-Context LLM Inference", "authors": "Xiang Liu,Zhenheng Tang,Peijie Dong,Zeyu Li,Yue Liu,Bo Li,Xuming Hu,Xiaowen Chu", "background": "大型语言模型在处理长文本时需要大量GPU内存，其中键值（KV）缓存可能消耗高达70%的总内存。现有压缩方法通过评估单个令牌的重要性来减少内存使用，但忽视了令牌之间的关键语义关系，导致上下文碎片化并降低了性能。", "innovation": "ChunkKV重新想象了KV缓存压缩的基本单位，将语义片段而不是孤立的令牌作为压缩单位。此外，ChunkKV引入了一种新的逐层索引重用技术，利用保存索引之间的更高跨层相似性，降低了计算开销并提高了26.5%的吞吐量。在LongBench、Needle-In-A-HayStack、GSM8K和JailbreakV等挑战性基准测试中，ChunkKV在精度保持相同压缩率的情况下，最高可超越现有最先进方法8.7%的性能。这证实了基于语义的压缩显著提高了长上下文LLM推理的效率和性能，提供了一个简单而有效的内存瓶颈解决方案。", "conclusion": "这些结果表明，基于语义的压缩显著提升了长上下文LLM推理的效率和性能，是一个简单而有效的方法来解决内存瓶颈问题。完整的代码可从<link>获取。"}
{"llm_update_time": "20251015", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2503.02038", "html_url": "https://arxiv.org/abs/2503.02038", "title": "参与其中：理解具有人群意识的人机互作中的虚假信息动态", "title_en": "Persuasion at Play: Understanding Misinformation Dynamics in Demographic-Aware Human-LLM Interactions", "authors": "Angana Borah,Rada Mihalcea,Verónica Pérez-Rosas", "background": "现有文献表明，不同的人群在接触到虚假信息时的易感性存在差异，某些人群比其他人群更容易受到虚假信息的影响。大型语言模型（LLMs）通过大规模生成具有说服力的内容，进一步加剧了这些挑战，并可能强化现有的偏见。本研究旨在探讨在接触到虚假信息时，LLMs和人类之间双向的说服动态。研究通过人类立场数据集分析了人类对LLMs的影响，并通过生成基于LLMs的说服论点评估了LLMs对人类的影响。研究还使用了一个基于多代理的LLMs框架来分析在不同人群导向的LLMs代理之间的说服中虚假信息的传播情况。", "innovation": "本研究通过多代理LLMs框架研究了在不同人群导向的LLMs代理之间的说服中虚假信息的传播情况，揭示了人口因素如何影响LLMs中虚假信息的易感性，并指出这种影响方式与人类群体表现出类似模式。此外，研究表明，类似人类人口群体，多代理LLMs也表现出回声室效应。", "conclusion": "研究表明，人口因素在LLMs中影响虚假信息的易感性，与人类群体表现出类似模式。同时，多代理LLMs也表现出回声室效应。本研究揭示了人类与LLMs之间的相互作用，强调了在虚假信息下不同人口群体的差异，为未来干预提供了见解。"}
{"llm_update_time": "20251015", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2501.06374", "html_url": "https://arxiv.org/abs/2501.06374", "title": "AFRIDOC-MT: 非洲语言文档级翻译语料库", "title_en": "AFRIDOC-MT: Document-level MT Corpus for African Languages", "authors": "Jesujoba O. Alabi,Israel Abebe Azime,Miaoran Zhang,Cristina España-Bonet,Rachel Bawden,Dawei Zhu,David Ifeoluwa Adelani,Clement Oyeleke Odoje,Idris Akinade,Iffat Maab,Davis David,Shamsuddeen Hassan Muhammad,Neo Putini,David O. Ademuyiwa,Andrew Caines,Dietrich Klakow", "background": "语言翻译领域近期取得了显著进步，特别是在神经机器翻译（NMT）模型和大规模语言模型（LLMs）方面。然而，对非洲语言的文档级翻译数据集的需求仍然存在不足。现有的一些多语言数据集虽然包括多种语言，但往往缺乏面向特定目的和区域的详细文档级数据，特别是非洲语言领域。本文因此引入了 AFRIDOC-MT 数据集，该数据集专注于健康和信息技术领域的文档，包含了从英文翻译为阿姆哈拉语、豪萨语、斯瓦希里语、约鲁巴语和祖鲁语的高质量人工翻译的文档，旨在填补这一空白。", "innovation": "AFRIDOC-MT 是一个详尽的多语平行翻译数据集，覆盖英语和五种非洲语言——阿姆哈拉语、豪萨语、斯瓦希里语、约鲁巴语和祖鲁语。此数据集特别关注健康和信息技术领域的新闻文档，共有334份健康新闻和271份信息技术新闻文档，均由人类翻译。与现有数据集不同，AFRIDOC-MT 强调了各领域文档的真实需求和使用场景，提供了详细的人类翻译文本，以便研究者和开发者可以评估和改善这些语言之间的机器翻译性能。", "conclusion": "研究表明，在进行英译非阿语文档级翻译基准测试时，标准NMT模型NLLB-200表现出最佳平均性能。相比之下，通用大语言模型GPT-4o的表现优于通用模型。然而，经过微调的模型在翻译长文档时表现更加出色。此外，我们的分析发现，部分大语言模型存在生成不足、重复词汇或短语等问题，特别是在翻译非洲语言时更为明显。因此，我们需要改进这些模型以更好地支持非洲语言的翻译任务。"}
{"llm_update_time": "20251015", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2502.12470", "html_url": "https://arxiv.org/abs/2502.12470", "title": "在光谱上推理：将LLMs与系统1和系统2思维对齐", "title_en": "Reasoning on a Spectrum: Aligning LLMs to System 1 and System 2 Thinking", "authors": "Alireza S. Ziabari,Nona Ghazizadeh,Zhivar Sourati,Farzan Karimi-Malekabadi,Payam Piray,Morteza Dehghani", "background": "大型语言模型（LLMs）展示了令人印象深刻的推理能力，但它们依赖于结构化的逐步处理揭示了一个关键的局限性。相比之下，人类的认知能够在情境需求下灵活地在直观的启发式（System 1）和分析的审慎（System 2）推理之间切换。人类认知的这种灵活性与LLMs依赖单一推理策略形成了对比，引发了这样的问题：虽然人类的快速启发式推理进化为效率和适应性崇高，但一个统一的推理方法是否对LLMs最优化，或者它的刚性使它们在面对需要更具灵活性和直观性响应的任务时变得脆弱且不可靠？", "innovation": "研究人员通过创建一个包含有效System 1和System 2答案的数据集来显式地将LLMs与这些推理风格对齐，并评估了它们在推理基准测试中的表现。结果揭示了一种准确率和效率之间的权衡：System 2对齐模型在算术和符号推理方面表现出色，而System 1对齐模型在常识推理任务中的表现更好。通过变换单一推理数据的比例来分析推理光谱，结果呈现出准确率的单调变化。机制分析表明，System 1模型生成更具确定性的输出，而System 2模型表现出更大的不确定性。进一步基于生成内容的熵值将System 1-和System 2对齐模型结合，无需额外训练，获得了在几乎所有基准测试中表现更优的动态模型。该研究挑战了逐步推理总是最佳的假设，并强调了根据任务需求调整推理策略的需求。", "conclusion": "这项研究通过分析LLMs与人类思维方式的差异，揭示了单一推理策略的局限性，并提出了一种新的方法来在LLMs中引入更灵活的推理模式，从而提高了其在不同任务上的表现。"}
{"llm_update_time": "20251015", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2504.07421", "html_url": "https://arxiv.org/abs/2504.07421", "title": "AgentAda：适应技能的数据分析用于定制化的见解发现", "title_en": "AgentAda: Skill-Adaptive Data Analytics for Tailored Insight Discovery", "authors": "Amirhossein Abaskohi,Amrutha Varshini Ramesh,Shailesh Nanisetty,Chirag Goel,David Vazquez,Christopher Pal,Spandana Gella,Giuseppe Carenini,Issam H. Laradji", "background": "现有方法需要用户手动决定应用哪种数据分析方法，这限制了数据分析的灵活性和效率。而AgentAda是首款具备学习和应用新分析技能的LLM（大型语言模型）动力的分析代理，能够自动从一系列分析技能库中识别所需的技能进行分析，从而实现更复杂的数据分析任务。", "innovation": "AgentAda通过其独特的数据分析策略，包括问题生成器、混合检索增强生成（RAG）技能匹配器和代码生成器，以满足用户需求为基础，自动选择并应用最适合的数据分析技能进行关键模式的提取，这不仅提高了数据分析的效率，还使得现有的LLM能够实现超出其基本功能的新技能。", "conclusion": "AgentAda在KaggleBench基准测试中表现优异，获得了更高的专家评价（48.78%的评价者更偏好AgentAda的分析结果），此外，论文还提出了一种新颖的LLM作为裁判的方法，在大规模自动生成见解质量评估方面与人类评价相一致。"}
{"llm_update_time": "20251015", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2504.15349", "html_url": "https://arxiv.org/abs/2504.15349", "title": "通过受限制访问序列处理（RASP）探索Transformer在COGS/ReCOGS_pos中的组合适应能力", "title_en": "Exploring Compositional Generalization (in COGS/ReCOGS_pos) by Transformers using Restricted Access Sequence Processing (RASP)", "authors": "William Bruns", "background": "人类能够理解新出现的词语组合，只要这些组合来自不同的语境。Transformer模型在处理这类组合适应性问题（称为组合适应性泛化）时表现不佳。Kim和Linzen（2020）提出的COGS基准测试显示，Transformer模型在某些组合适应性泛化问题上准确率为0%。之前的一些研究表明，这类任务可能需要分层或树状结构的解决方案。本文旨在通过引入Transformer等效的编程语言RASP来测试Transformer编码器-解码器模型在这方面的表现。", "innovation": "研究团队使用RASP（受限制访问序列处理）来演示Transformer编码器-解码器模型可以在COGS和具有语义等效性的ReCOGS_pos系统中进行组合适应性泛化，并且这种过程是系统性和组合适应性的。通过应用非递归的、平坦的模板匹配规则，以及在识别语法模式和提取与主动词相关的名词时遮蔽前置词短语和从句，模型能够在不使用递归规则的情况下达到接近完美的精确匹配评分。", "conclusion": "RASP模型在COGS和ReCOGS_pos基准测试中的成绩表明，这些任务并不需要分层或树状结构的解决方案。研究结果表明，Transformer可以通过非递归的方式完成这些任务，并在语义和字符串精确匹配上取得了优异的表现。"}
{"llm_update_time": "20251015", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2505.15696", "html_url": "https://arxiv.org/abs/2505.15696", "title": "MaxPoolBERT：通过层间和令牌级聚合提升BERT分类", "title_en": "MaxPoolBERT: Enhancing BERT Classification via Layer- and Token-Wise Aggregation", "authors": "Maike Behrendt,Stefan Sylvius Wagner,Stefan Harmeling", "background": "BERT中的[CLS]标记通常被用作固定长度表示，用于分类任务，但先前的研究表明，其他标记和中间层也编码了宝贵的上下文信息。", "innovation": "提出了一种名为MaxPoolBERT的轻量级扩展方法，通过在层和令牌级别上聚合信息来细化[CLS]表示。具体而言，探索了三种修改：（i）跨多个层使用max-pooling聚合[CLS]标记，（ii）让[CLS]标记能够通过额外的多头注意力（MHA）层在整个最终层上进行注意力，（iii）将整个序列上的max-pooling与MHA结合使用。该方法在不需新的预训练或显著增加模型大小的情况下，增强了BERT的分类准确率（尤其是低资源任务）。", "conclusion": "在GLUE基准测试上的实验表明，MaxPoolBERT在GLUE基准测试的低资源任务中始终优于标准的BERT基线模型。"}
{"llm_update_time": "20251015", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2504.21421", "html_url": "https://arxiv.org/abs/2504.21421", "title": "现代日语依存距离和层次距离的分布及其影响因素", "title_en": "The Distribution of Dependency Distance and Hierarchical Distance in Contemporary Written Japanese and Its Influencing Factors", "authors": "Linxuan Wang,Shuiyuan Yu", "background": "本文探讨了现代日语中依存距离（DD）和层次距离（HD）之间的关系。通过对比固定和未固定句长情况下的概率分布，分析了随句长变化的平均依存距离（MDD）和平均层次距离（MHD），以及它们之间的相关系数。研究发现，谓词的价是决定MDD和MHD之间权衡关系的关键因素。日语母语者的说话方式会根据谓词的价来调节线性复杂性和层次复杂性，并且MDD和MHD的相对大小取决于谓词价的阈值是否达到。除认知负荷外，谓词的价还会影响DD和HD的概率分布。其对HD分布的影响大于对DD，导致两者概率分布的差异，使得MDD的均值低于MHD的均值。", "innovation": "本文通过分析现代日语中的依存距离和层次距离的分布，揭示了谓词价在调节句子复杂性方面的作用，并且发现其对 HD 的影响大于对 DD 的影响，从而影响了两者概率分布的差异。", "conclusion": "在现代日语中，谓词的价是决定 MDD 和 MHD 之间权衡关系的关键因素。通过调节句长、线性复杂性和层次复杂性，母语使用者能够控制认知负荷。"}
{"llm_update_time": "20251015", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2505.16612", "html_url": "https://arxiv.org/abs/2505.16612", "title": "利用对比自编码器引导的大语言模型机器翻译个性化", "title_en": "Steering Large Language Models for Machine Translation Personalization", "authors": "Daniel Scalena,Gabriele Sarti,Arianna Bisazza,Elisabetta Fersini,Malvina Nissim", "background": "大规模语言模型简化了个性化翻译的生产，但仍然难以处理隐式地通过一组示例（如特定译者的文章）代表的风格要求。当可用示例较少时，探索个性化自动翻译的策略很具挑战性，尤其是在文学翻译领域。该研究旨在确定任务可行性以及风格信息如何在模型表示中编码，并评估了各种提示策略和推理时干预措施，以引导模型生成个性化风格的翻译，特别关注使用稀疏自编码器（SAE）潜空间进行对比引导（contrastive steering），以识别显著的个性化属性。", "innovation": "研究提出了利用稀疏自编码器潜空间进行对比引导的方法，以增强风格条件和翻译质量，这种方法在推理时间的计算效率上优于提示方法。研究表明，无论是提示还是SAE引导，编码个性化属性的层都受到相似的影响，表明两种方法可能具有相同的机制。", "conclusion": "对比自编码器引导在实现风格条件和提高翻译质量方面表现出了更强的稳定性，相比提示方法，在推理时间计算效率上具有优势。研究还发现，引导对模型激活的影响表明，编码个性化属性的层在两种方法下都受到了相似的影响。"}
{"llm_update_time": "20251015", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2504.07274", "html_url": "https://arxiv.org/abs/2504.07274", "title": "用于未来金融的语言模型：面向度量、任务和数据机遇的综述", "title_en": "Language Modeling for the Future of Finance: A Survey into Metrics, Tasks, and Data Opportunities", "authors": "Nikita Tatarinov,Siddhant Sukhani,Agam Shah,Sudheer Chava", "background": "近年来，语言模型的进步促使越来越多的论文关注金融领域，在顶级自然语言处理（NLP）会议和期刊中有所体现。为了系统地研究这一趋势，作者回顾了2017年至2024年间38个会议和研讨会出版的374篇NLP研究论文，并对其中直接涉及金融任务的221篇论文进行了细致分析。", "innovation": "作者对涉及金融任务的NLP研究论文进行了系统回顾，并从11个量化和质化维度进行了评估。提出了四个方面的研究机会：(i) 扩展预测任务的范围；(ii) 丰富评价指标，使用金融指标；(iii) 利用多语言和危机时期的数据库；(iv) 平衡预训练语言模型与高效的或可解释的替代方案。作者还提供了数据集和工具推荐，具有对学术界和业界的启示意义。", "conclusion": "作者的研究指出了NLP研究人员面临的机遇，并提供了实际可行的方向，同时强调了数据集推荐的重要性和对未来学术界和产业界的影响。"}
{"llm_update_time": "20251015", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2505.19630", "html_url": "https://arxiv.org/abs/2505.19630", "title": "DoctorAgent-RL: 基于多agent强化学习系统的多轮临床对话", "title_en": "DoctorAgent-RL: A Multi-Agent Collaborative Reinforcement Learning System for Multi-Turn Clinical Dialogue", "authors": "Yichun Feng,Jiawei Wang,Lu Zhou,Zhen Lei,Yixue Li", "background": "虽然大型语言模型（LLMs）在生物医学问题回答方面显示了出色的性能，但在真实世界的临床咨询应用中仍面临核心挑战。单轮咨询系统要求患者一次性描述所有症状，导致诊断模糊且投诉不清。传统的多轮对话模型受限于静态监督学习，缺乏灵活性，无法智能提取关键的临床信息。", "innovation": "我们提出了一种基于强化学习（RL）的多agent协作框架\textbackslashOurs{}，将其建模为不确定环境下的动态决策过程。医生代理在与患者代理的多轮交互中不断优化其提问策略，并根据Consultation Evaluator的全面奖励动态调整其信息收集路径。该RL微调机制使LLMs能够自主发展与临床推理逻辑一致的交互策略，而非浅层次地模仿现有对话数据中的模式。此外，我们构建了MTMedDialog，这是第一个能够模拟患者互动的英语多轮医疗咨询数据集。实验表明，\textbackslashOurs{}在多轮推理能力和最终诊断表现上优于现有模型。此方法显示出巨大的实际价值，可以在时间紧迫的环境中减少诊断错误风险，释放医务人员为复杂病例服务，并首创了优化医疗资源分配和缓解人力资源短缺的策略。", "conclusion": "我们的方法展示了巨大的实用价值，有助于减少时间紧迫环境下的诊断错误风险，释放医疗工作者，特别是在处理复杂病例上，并开拓了优化医疗资源分配和减轻人力资源短缺的新策略。"}
{"llm_update_time": "20251015", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2505.19700", "html_url": "https://arxiv.org/abs/2505.19700", "title": "利用重要性采样从大规模语言模型中分离对齐模块", "title_en": "Leveraging Importance Sampling to Detach Alignment Modules from Large Language Models", "authors": "Yi Liu,Dianqing Liu,Mingye Zhu,Junbo Guo,Yongdong Zhang,Zhendong Mao", "background": "随着大规模语言模型（LLMs）在各行各业的广泛应用，对高质量且可定制的输出需求日益增加。然而，传统对齐方法往往需要重新训练大规模预训练模型，这使得快速适应和优化LLMs以应对多样应用变得困难。", "innovation": "为解决这一限制，我们提出了一种名为Residual Alignment Model (RAM)的新方法。RAM将对齐过程形式化为重要性采样的类型。上游未对齐模型充当提案分布，而对齐过程被构想为基于自回归对齐模块的二次采样，该模块作为重要性权重的估计器。这种设计允许对齐模块与目标对齐模型的自然分离，从而提高了灵活性和可扩展性。此外，我们还为对齐模块开发了一种高效的序列级训练策略，并设计了一种带有迭代token级解码的重采样算法以解决一般方法中常见的首个token延迟问题。", "conclusion": "我们方法在两个顶级开源LLMs上的实验评估中，包括指令遵循、领域适应和偏好优化等多个任务中，表现出持续超越基线模型的性能。"}
{"llm_update_time": "20251015", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2505.18943", "html_url": "https://arxiv.org/abs/2505.18943", "title": "MetaMind：使用元认知多智能体系统的建模人类社会思考", "title_en": "MetaMind: Modeling Human Social Thoughts with Metacognitive Multi-Agent Systems", "authors": "Xuanming Zhang,Yuxuan Chen,Samuel Yeh,Sharon Li", "background": "人类的社会互动依赖于推断他人未表达的意图、情感和信念的认知技能，这基于心理理论中的心智理论（Theory of Mind, ToM）概念。尽管大型语言模型（LLMs）在语义理解任务中表现出色，但在人类交流中的模糊性和上下文细腻方面却遇到困难。为了解决这一差距，MetaMind框架引入了一个多智能体系统，模仿了元认知的心理学理论，旨在模拟人类类型的社会推理。该框架将社会理解分解为三个协作阶段。第一阶段的心智理论代理生成关于用户心理状态（如意图、情感）的假设，第二阶段的道德代理使用文化规范和道德约束改进这些假设，第三阶段的响应代理生成上下文相关性适宜的响应，并验证其与推断意图的一致性。", "innovation": "MetaMind框架是一种多智能体系统，通过模仿元认知心理学理论，实现了将大型语言模型（LLMs）与人类级社会推理相结合的目标。框架将社会理解分解为三个协作阶段，涵盖了生成用户心理状态假设、使用文化规范和道德约束改进这些假设、以及生成上下文相关性适宜的响应。在三个具有挑战性的基准测试中，框架达到了最先进的性能，提升幅度为35.7%。特别是在现实世界的社会情境中提升了6.2%，首次让LLM在关键ToM任务上达到人类级性能。", "conclusion": "MetaMind框架推进了AI系统向人类级社会智能的进展，具有应用于具有同理心对话和文化敏感性互动的应用潜力。实验证明所有组件都至关重要，展示了框架在平衡上下文合理性、社会适宜性和用户适应性方面的能力。"}
{"llm_update_time": "20251015", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2505.22017", "html_url": "https://arxiv.org/abs/2505.22017", "title": "二次思考的代价：大型语言模型推理效率评估", "title_en": "The Price of a Second Thought: On the Evaluation of Reasoning Efficiency in Large Language Models", "authors": "Siqi Fan,Bowen Qin,Peng Han,Shuo Shang,Yequan Wang,Aixin Sun", "background": "最近训练的思考模型使用强化学习和反向检查进行链式推理（Backward-checking CoT），常常会表现出过度思考的现象，即即使是在简单问题上也会产生过长的输出结果，浪费了计算资源。现有的基于 token 效率的评估方法并没有全面反映出问题难度和中间计算成本等因素的影响。", "innovation": "本文提出了将推理效率定义为相对于思考模型和指令模型的相对指标，通过系统地验证多个思考模型和基准测试，发现了两种一致模式：指令模型整体上效率更高，问题难度会影响效率，思考模型会对简单问题浪费计算资源，但在困难问题上提供了更大的效益。进一步，提出了COTHINK，这是一种简单的两阶段管道方法，首先指令模型草拟一个简要概要，然后思考模型进行扩展。COTHINK在GSM8K、MATH500和AIME24基准上，将token使用减少了21.1%，同时保持了四个思考模型的准确性，并且在效率基准中保持了竞争力。", "conclusion": "COTHINK通过指令模型和思考模型的分工合作，有效地减少了token使用，同时保持了准确性，并且在多个基准测试中表现与高效基准持平，展示了在大型语言模型推理效率评估中的创新和应用价值。"}
{"llm_update_time": "20251015", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2503.21080", "html_url": "https://arxiv.org/abs/2503.21080", "title": "EmoDebt: 采用贝叶斯优化的情感智能策略化代理对代理债务回收", "title_en": "EmoDebt: Bayesian-Optimized Emotional Intelligence for Strategic Agent-to-Agent Debt Recovery", "authors": "Yunbo Long,Yuhan Liu,Liming Xu,Alexandra Brintrup", "background": "自主大型语言模型（LLM）代理的出现创建了一个新的由代理人之间的战略互动构成的生态系统。然而，在高风险、情感敏感的领域，如债务追收中，预训练在人类对话上的LLM代理由于其情感表达能力容易受到模拟负面情绪的对手策略的操控。现有方法面临着这一重大挑战，尚未得到有效解决。因此，先前的研究并未提供有效的策略来应对这一问题，特别是在情感敏感的债务追收场景中。", "innovation": "本研究首次提出了一种模拟债务回收场景的新数据集和多智能体模拟框架。在该框架内，引入了EmoDebt这一基于贝叶斯优化的情感智能代理。其核心创新是将模型在协商过程中表达情感的能力重新定义为一个序列决策问题，并通过在线学习不断调整代理的情绪转换策略，发现特定债务策略的最佳应对策略。实验结果表明，EmoDebt在成功比率和运营效率等关键性能指标上显著优于非适应性和无情感导向的基础模型，从而建立了新的战略鲁棒LLM代理在对抗性的情感敏感债务交互中的部署基础。", "conclusion": "通过引入关键基准和适应性较强的代理，本项工作建立了战略鲁棒LLM代理在对抗性情感敏感债务交互中的部署新基础。"}
{"llm_update_time": "20251015", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2505.22131", "html_url": "https://arxiv.org/abs/2505.22131", "title": "通过错误意识自我反思增强长链条推理精炼", "title_en": "Enhancing Long-Chain Reasoning Distillation through Error-Aware Self-Reflection", "authors": "Zhuoyang Wu,Xinze Li,Zhenghao Liu,Yukun Yan,Zhiyuan Liu,Minghe Yu,Cheng Yang,Yu Gu,Ge Yu,Maosong Sun", "background": "大型语言模型（LLMs）在数学问题解决任务中表现出强大的推理能力。现有的方法通常将小语言模型（SLMs）作为学生模型，使用包含详细推理过程的长序列推理链（CoTs）进行监督微调（SFT），以传递推理能力。然而，这种方法存在一个局限性：长序列CoT教师无法感知学生模型的能力，这限制了推理链的有效利用。", "innovation": "提出了一个称为ORION的新框架，通过错误意识自我反思过程来细化教师CoTs。ORION允许学生模型通过修正教师CoTs并结合自身的推理错误来构建更个性化的CoTs。实验表明，ORION在多个数学推理基准上的性能优于所有基线，改进幅度超过2%。进一步分析表明，由ORION构建的CoTs具有更高的连贯性和逻辑一致性，从而作为更有效的监督信号。", "conclusion": "ORION框架能够显著提高小语言模型的推理能力，通过更有效地利用教师模型的推理链，增强了SFT的效果，从而提高了最终的性能。"}
{"llm_update_time": "20251015", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2506.00739", "html_url": "https://arxiv.org/abs/2506.00739", "title": "DefenderBench：评估网络安全环境中语言代理的工具包", "title_en": "DefenderBench: A Toolkit for Evaluating Language Agents in Cybersecurity Environments", "authors": "Chiyu Zhang,Marc-Alexandre Cote,Michael Albada,Anush Sankaran,Jack W. Stokes,Tong Wang,Amir Abdi,William Blum,Muhammad Abdul-Mageed", "background": "大型语言模型（LLM）在人类语言理解和推理方面展现了令人印象深刻的性能，但在网络安全领域的潜力尚未得到充分探索。DefenderBench提供了一个实际的、开源的工具包，用于评估语言代理在攻防和网络安全知识任务中的表现。该工具包包括网络入侵、恶意内容检测、代码漏洞分析和网络安全知识评估等环境，旨在为研究人员提供负担得起且易于访问的评估工具，同时确保评估的公正性和严谨性。", "innovation": "DefenderBench通过模块化设计，支持自定义LLM和任务的无缝集成，促进可重复性和公平比较。该工具包广泛评估了多个最先进的和流行的语言模型，包括开放和封闭权重模型，使用标准化的代理框架进行基准测试，揭示了Claude-3.7-sonnet在DefenderBench评分中的最佳表现（81.65分），其次是Claude-3.7-sonnet-think（78.40分），开放权重模型Llama 3.3 70B的DefenderBench评分为71.81，显示出不俗的表现。", "conclusion": "DefenderBench的设计旨在促进数据安全研究的透明度和可重复性，提供了一个公平和严格的评估平台。研究人员可以通过访问提供的匿名版本进一步探索和利用此工具包。"}
{"llm_update_time": "20251015", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2506.05670", "html_url": "https://arxiv.org/abs/2506.05670", "title": "跨文化表达个性吗？引入CulturalPersonas以评估特质对齐", "title_en": "Can LLMs Express Personality Across Cultures? Introducing CulturalPersonas for Evaluating Trait Alignment", "authors": "Priyanka Dey,Yugal Khanter,Aayush Bothra,Jieyu Zhao,Emilio Ferrara", "background": "随着大型语言模型（LLMs）在交互式应用程序中的应用越来越广泛，如辅导和心理健康领域，这些模型在文化适宜性上的个性表达能力变得愈发重要。尽管近期有一些研究探讨了LLMs的人格评估，但这些研究大多忽视了文化和个性之间的相互作用。为此，作者引入了CulturalPersonas，这是一个首个经过人类验证的大规模基准数据集，用于评估LLMs在文化背景下的个性表达能力，这些文化背景包含了行为丰富的场景。数据集覆盖了六个不同国家的3000个基于情景的问题，旨在通过日常情景激发个性，这些情境源于当地的价值观。", "innovation": "CulturalPersonas是第一个大规模的基准数据集，其中包括人类验证，用于评估LLMs在文化基础上的行为丰富场景中的个性表达能力。该数据集包含来自六个不同国家的3000个基于情景的问题，旨在通过日常生活情境引发个性表现，这些问题植根于当地的价值观。作者通过使用多选题和开放式回答格式评估了三种LLMs，结果显示CulturalPersonas使模型与国家特定的人类个性分布更加一致，与现有基准相比，它能够引发更具表现力且文化相关的输出。CulturalPersonas能够为全球行为规范下的LLMs对齐提供新的方向，通过将个性表达与文化细微差别联系起来，作者希望CulturalPersonas能够为更社会智能和全球适应性的LLMs铺平道路", "conclusion": "通过将个性表达与文化细微差别相联系，作者设想CulturalPersonas将为LLMs提供更多社会智能和全球适应性发展的途径。"}
{"llm_update_time": "20251015", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2506.21582", "html_url": "https://arxiv.org/abs/2506.21582", "title": "VIDEE：使用智能代理进行文本分析的可视化和交互式分解、执行和评估", "title_en": "VIDEE: Visual and Interactive Decomposition, Execution, and Evaluation of Text Analytics with Intelligent Agents", "authors": "Sam Yu-Te Lee,Chenyang Ji,Shicheng Wen,Lifu Huang,Dongyu Liu,Kwan-Liu Ma", "background": "传统的文本分析需要深厚自然语言处理（NLP）或文本分析的专业知识，这对入门级分析师构成了一定的障碍。近年来，大规模语言模型（LLMs）的进步改变了NLP的格局，使得文本分析更加容易且自动化（如主题检测、摘要生成、信息提取等）。", "innovation": "我们提出了VIDEE系统，旨在支持初级数据分析师利用智能代理进行高级文本分析。该系统采用了一种人机协作的工作流程，包括：（1）分解阶段，集成了带有人类循环控制的蒙特卡洛树搜索算法，以支持生成推理并结合人类反馈；（2）执行阶段，自动生成一个可执行的文本分析管道；（3）评估阶段，集成了基于LLM的评估和可视化工具，以支持用户对执行结果的验证。通过定量实验评估VIDEE的效果，并分析智能代理的常见错误。参与者涉及不同程度的NLP和文本分析经验，展示系统的易用性并揭示了不同的用户行为模式。", "conclusion": "研究发现的人机协作设计启示、验证了VIDEE对于非专家用户的实用价值，并为未来的智能文本分析系统改进提供了指导意义。"}
{"llm_update_time": "20251015", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2506.20923", "html_url": "https://arxiv.org/abs/2506.20923", "title": "KaLM-Embedding-V2: 优越的训练技术和高质量数据激发的多功能嵌入模型", "title_en": "KaLM-Embedding-V2: Superior Training Techniques and Data Inspire A Versatile Embedding Model", "authors": "Xinping Zhao,Xinshuo Hu,Zifei Shan,Shouzheng Huang,Yao Zhou,Xin Zhang,Zetian Sun,Zhenyu Liu,Dongfang Li,Xinyuan Wei,Youcheng Pan,Yang Xiang,Meishan Zhang,Haofen Wang,Jun Yu,Baotian Hu,Min Zhang", "background": "近期关于基于大型语言模型（LLMs）的文本嵌入模型的研究主要集中在数据规模的扩展或合成上，而对训练技术和数据质量的探索较少，这限制了模型性能的提升。", "innovation": "在本文中，我们提出了KaLM-Embedding-V2，这是一种具有先进嵌入能力的多功能和紧凑型嵌入模型系列。通过先进的训练技术、高质量数据和0.5B的紧凑架构，来系统地激励LLMs的高级嵌入能力。创新点包括：1) 使用简单的平均池化和非因果注意力掩码来生成固定长度的嵌入；2) 提出了一个分阶段的训练管道，包括弱监督的预训练、强监督的微调以及对比蒸馏；3) 为训练数据收集超过20个类别用于预训练，100个类别用于微调和对比蒸馏，确保高质量的数据。这种方法使KaLM-Embedding-V2系列在大规模文本嵌入基准上实现了最佳性能，超过了类似规模的模型，甚至超过了多达26倍规模的模型，确立了在参数少于1B的多功能紧凑型嵌入模型的新标准。", "conclusion": "KaLM-Embedding-V2系列通过先进的训练技术和高质量数据，在大规模文本嵌入基准上取得了最佳性能，为多功能和紧凑型嵌入模型设定了新的标准，与大得多的模型相比，表现出卓越的性能。"}
{"llm_update_time": "20251015", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2506.22058", "html_url": "https://arxiv.org/abs/2506.22058", "title": "推理之初迷失", "title_en": "Lost at the Beginning of Reasoning", "authors": "Baohao Liao,Xinyi Chen,Sara Rajaee,Yuhui Xu,Christian Herold,Anders Søgaard,Maarten de Rijke,Christof Monz", "background": "近年来，大型语言模型（LLMs）在复杂推理能力方面取得了显著进展，尤其是在扩展的链式思考（CoT）推理过程中，通过回溯、自我反思和自我纠正机制的应用。尽管取得了这些进展，但LLMs在长时间CoT推理中的自我纠正能力仍被广泛忽视。近期的研究还发现，这些模型在推理中常常进行不必要的冗余推理。我们通过实证研究发现，首次推理步骤对最终预测结果的影响非常大，即在这一阶段引入的错误可能会显著影响后续推理质量。这种现象在多种最先进的开放源代码和闭源推理模型中都普遍存在。", "innovation": "我们提出了一种高效的采样策略，该策略利用奖励模型来识别并保留高质量的首次推理步骤，同时丢弃次优的步骤。这种方法可以在不牺牲任何准确性的前提下将推理成本降低多达70%。我们的研究强调了首次推理步骤在生成高质量推理轨迹中的关键作用，并从而使高效采样成为可能。", "conclusion": "我们的研究展示了首次推理步骤在高效推理轨迹生成中的核心作用。通过引入这种高效的采样策略，我们在降低推理成本的同时保持了准确性，为大型语言模型的推理过程提供了新的优化视角。"}
{"llm_update_time": "20251015", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2507.00665", "html_url": "https://arxiv.org/abs/2507.00665", "title": "SAFER: Probing Safety in Reward Models with Sparse Autoencoder", "title_en": "SAFER: Probing Safety in Reward Models with Sparse Autoencoder", "authors": "Sihang Li,Wei Shi,Ziyuan Xie,Tao Liang,Guojun Ma,Xiang Wang", "background": "精 vedltanenl 大型语言模型（LLMs）的正则化与人类价值观之间存在对齐问题是通过强化学习从人类反馈（RLHF）实现的，但其中的核心奖励模型依然缺乏透明度。本文探讨了如何通过机制分析来解释和改善奖励模型。本文利用稀疏自编码器（SAEs）揭露奖励模型激活中的人类可解释特征，以促进对安全相关的决策理解。", "innovation": "本文提出了稀疏自编码器增强的奖励模型（SAFER），这是一种通过机制分析解释和改进奖励模型的新框架。SAFER通过SAEs从奖励模型的激活中发现人类可解释的特征，应用SAFER到安全导向的偏好数据集上，并通过选择与拒绝的响应中激活的差异量化单个特征的重要性。基于这些特征级别的信号，设计了针对数据污染和去噪策略。", "conclusion": "实验结果表明，SAFER可以在最少数据修改的情况下精确地提升或降低安全对齐，且不会牺牲通用对话性能。本文的方法对高危LLM对齐任务中的解释、审计和改进奖励模型有所贡献。我们已在"}
{"llm_update_time": "20251015", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2507.08704", "html_url": "https://arxiv.org/abs/2507.08704", "title": "通过双向信息聚合的知识融合", "title_en": "Knowledge Fusion via Bidirectional Information Aggregation", "authors": "Songlin Zhai,Guilin Qi,Yue Wang,Yuan Meng", "background": "知识图谱(KGs)是语义互联网的基础，提供实时的世界实体和关系表示。大型语言模型(LLMs)在预训练后大多固定不变，导致其内部知识变得过时，限制了其在时效性互联网应用中的实用性。为解决知识的动态性和LLMs的静态性之间的差距，通常做法是通过参数侵入式微调增强LLMs，但这种方法存在灾难性遗忘的风险，且往往削弱LLMs的通用能力。更为严重的问题是静态整合框架无法跟上现实世界知识图谱的连续进化，阻碍其在动态互联网环境中的应用部署。", "innovation": "本文提出了KGA（知识图谱引导的注意力）框架，这是一种新颖的方法，在推理时动态地将外部KG整合到LLMs中，而无需修改任何参数。该框架受到神经科学研究的启发，在自注意力模块中引入了两条互补的路径：一种自下而上的知识融合路径和一种自上而下的注意力引导路径。这些路径共同支持实时知识融合，验证了KGA在四个基准测试中的强大融合性能和高效性。", "conclusion": "KGA框架通过引入两条路径，在推理时无需修改参数的情况下，动态地将外部KG整合到LLMs中。这种方法避免了参数侵入式微调的缺点，实现实时知识融合，并在多个基准测试中验证了其高效性和强大性能。"}
{"llm_update_time": "20251015", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2507.22337", "html_url": "https://arxiv.org/abs/2507.22337", "title": "NLP和神经检索器中否定的综合分类", "title_en": "A Comprehensive Taxonomy of Negation for NLP and Neural Retrievers", "authors": "Roxana Petcu,Samarth Bhargav,Maarten de Rijke,Evangelos Kanoulas", "background": "理解和解决复杂的推理任务对满足用户的信息需求至关重要。虽然密集型神经模型可以学习上下文表示，但在包含否定的查询上仍然表现不佳。本文旨在研究这一现象，并探讨传统神经信息检索和基于LLM的模型中的否定。通过对比哲学、语言和逻辑定义中的否定，本文构建了一个分类系统；生成了两个基准数据集来评估神经信息检索模型的性能，并进一步优化模型在否定方面的表现；提出了一个基于逻辑的分类机制，可以用来分析现有数据集上检索模型的表现。", "innovation": "本文引入了一种从哲学、语言和逻辑定义中衍生出来的否定分类体系；构建了两个基准数据集，用于评估神经信息检索模型的性能和调整模型以在否定方面表现更稳健；提出了一种逻辑分类机制，用于分析现有数据集上检索模型的性能；这种分类体系产生了否定类型的均衡分布，提供了更好的训练设置，有助于神经检索数据集（NevIR）更快收敛；揭示了现有数据集中否定类型的覆盖面，为理解调优模型在否定方面的泛化提供了见解。", "conclusion": "这种分类体系为均衡分配否定类型的数据集提供了更好的训练设置，有助于更快地收敛于神经检索数据集（NevIR）。此外，提出的分类体系揭示了现有数据集中否定类型的覆盖面，提供了有关影响调优模型在否定方面泛化的因素的见解。"}
{"llm_update_time": "20251015", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.04012", "html_url": "https://arxiv.org/abs/2508.04012", "title": "EMSEdit: 效率多步元学习模型编辑", "title_en": "EMSEdit: Efficient Multi-Step Meta-Learning-based Model Editing", "authors": "Xiaopeng Li,Shasha Li,Xi Wang,Shezheng Song,Bin Ji,Shangwen Wang,Jun Ma,Xiaodong Liu,Mina Liu,Jie Yu", "background": "大型语言模型（LLMs）在众多AI应用中发挥着重要作用，但更新这些模型的知识成本高昂。模型剪辑可通过有针对性的参数修改提供轻量级的选择，而基于元学习的模型剪辑（MLME）则表现出了强大且高效的编辑效果。然而，MLME在低数据量情况下表现不佳，并且由于使用了KL散度，其训练成本较高。", "innovation": "为了应对上述问题，本文提出了EMSEdit方法，该方法利用多步反向传播（MSBP）有效捕捉编辑样本中的梯度-激活模式映射，每次对样本进行多步编辑以在数据受限条件下提升编辑性能，并通过基于范数的正则化来保持未编辑的知识同时提高训练效率。实验证明，EMSEdit在序列编辑和批量编辑方面均优于最先进的方法，并且MSBP可以无缝集成到现有方法，进一步提升性能。此外，EMSEdit在多跳推理编辑任务中表现出色，拆分实验验证了每个设计组件的贡献。", "conclusion": "EMSEdit在两个数据集和三个LLM上的一系列实验表明，它在序列编辑和批量编辑方面均优于当前最佳方法。进一步的实验展示了EMSEdit处理复杂编辑的鲁棒性，而消融研究表明每个设计元素的贡献。本文公开了代码。"}
{"llm_update_time": "20251015", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.02322", "html_url": "https://arxiv.org/abs/2508.02322", "title": "CAMERA: 通过微专家冗余分析的多矩阵联合压缩", "title_en": "CAMERA: Multi-Matrix Joint Compression for MoE Models via Micro-Expert Redundancy Analysis", "authors": "Yuzhuang Xu,Xu Han,Yuanchi Zhang,Yixuan Wang,Yijun Liu,Shiyu Ji,Qingfu Zhu,Wanxiang Che", "background": "大规模语言模型（LLMs）采用混合专家（MoE）架构，在多种任务上表现出较强的性能放大效应，但在参数日益增长的同时也带来了巨大的计算和存储负担。尽管一些先前工作尝试通过专家级别的剪枝、合并或分解来减少参数，但这些方法仍然存在性能和计算效率方面的挑战。当前研究从矩阵层面细化了压缩单元，重新定义了MoE层为微专家的混合，并提出了CAMERA框架，用于识别微专家冗余。研究发现微专家在解码过程中贡献度存在显著差异，基于这一观察，提出了CAMERA-P结构化微专家剪枝框架和CAMERA-Q混合精度量化方法。实验表明，CAMERA-P在20%到60%的剪枝比下持续优于强基线，而CAMERA-Q在激进的2位量化中展现出更优的性能，超越现有矩阵和通道级别的方法。此外，该方法能在单张NVIDIA A100-40GB GPU上不到5分钟的时间内完成Qwen2-57B-A14B的微专家完全分析。", "innovation": "介绍了一种更为精细的压缩单元——微专家，重新定义了MoE层为微专家的混合，并提出了CAMERA框架，包括两个核心贡献：CAMERA-P结构化微专家剪枝框架和CAMERA-Q混合精度量化方法。这两个方法能够有效地解决MoE模型在大规模应用中的计算和存储挑战，分别提高了剪枝和量化的效果。", "conclusion": "实验结果表明，CAMERA-P在广泛剪枝比范围内持续优于强基线，而CAMERA-Q在激进的2位量化下表现出色，超越现有技术。方法还验证了其在大型模型上的高效性。"}
{"llm_update_time": "20251015", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2509.20057", "html_url": "https://arxiv.org/abs/2509.20057", "title": "负责的人工智能技术报告", "title_en": "Responsible AI Technical Report", "authors": "KT:Yunjin Park,Jungwon Yoon,Junhyung Moon,Myunggyo Oh,Wonhyuk Lee,Sujin Kim Youngchol Kim,Eunmi Kim,Hyoungjun Park,Eunyoung Shin,Wonyoung Lee,Somin Lee,Minwook Ju,Minsung Noh,Dongyoung Jeong,Jeongyeop Kim,Wanjin Park,Soonmin Bae", "background": "分析了基本的人工智能实施法案和全球人工智能治理趋势，制定了独特的监管合规方法，并系统地识别和管理从人工智能开发到运行的所有潜在风险因素。", "innovation": "开发了一种负责任的人工智能（RAI）评估方法和技术风险管理技术，提升了人工智能服务的安全性和可靠性。提出了针对国内环境的人工智能风险分类法，建立了一种可靠的评估方法来系统地验证模型的安全性和鲁棒性，提供了管理并减轻已识别的人工智能风险的实际工具。", "conclusion": "通过本报告的发布，还发布了专有的Guardrail：SafetyGuard，可实时阻止有害的人工智能模型响应，支持国内人工智能开发生态系统的安全性增强。这些研究成果也为寻求开发负责任人工智能的组织提供了有价值的见解。"}
{"llm_update_time": "20251015", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2509.19580", "html_url": "https://arxiv.org/abs/2509.19580", "title": "LLMs4All: 一种跨学科的大语言模型系统综述", "title_en": "LLMs4All: A Systematic Review of Large Language Models Across Academic Disciplines", "authors": "Yanfang Ye,Zheyuan Zhang,Tianyi Ma,Zehong Wang,Yiyang Li,Shifu Hou,Weixiang Sun,Kaiwen Shi,Yijun Ma,Wei Song,Ahmed Abbasi,Ying Cheng,Jane Cleland-Huang,Steven Corcelli,Robert Goulding,Ming Hu,Ting Hua,John Lalor,Fang Liu,Tengfei Luo,Ed Maginn,Nuno Moniz,Jason Rohr,Brett Savoie,Daniel Slate,Matthew Webber,Olaf Wiest,Johnny Zhang,Nitesh V. Chawla", "background": "当前的先进人工智能技术不断改变我们对世界的看法。例如，基于大型语言模型（LLMs）的应用，如ChatGPT，已经展示了在广泛主题上生成类人对话的能力。由于其在多种语言相关任务（如开放领域问答、翻译和文摘总结）上的出色表现，人们设想LLMs可以在更广泛的现实世界应用中产生深远影响（例如客户服务、教育和服务、科学发现）。因此，在讨论LLMs的优点的同时也指出了挑战。", "innovation": "本文对大型语言模型（LLMs）进行了全面综述，并探讨了它们如何集成到包括艺术、社会科学、经济和商业以及科学和技术在内的多个学术领域中。同时，该论文还讨论了生成式人工智能时代的大语言模型的关键限制、开放挑战以及未来方向。", "conclusion": "本文综述了LLMs在不同领域的应用，并通过关键观察和见解帮助研究者和从业者深入了解利用LLMs以实现多样化的现实世界应用的潜在价值。"}
{"llm_update_time": "20251015", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2509.17177", "html_url": "https://arxiv.org/abs/2509.17177", "title": "FlagEval Findings Report: 自动可验证文本和视觉问题上大型推理模型的初步评估", "title_en": "FlagEval Findings Report: A Preliminary Evaluation of Large Reasoning Models on Automatically Verifiable Textual and Visual Questions", "authors": "Bowen Qin,Chen Yue,Fang Yin,Hui Wang,JG Yao,Jiakang Liu,Jing-Shu Zheng,Miguel Hu Chen,Richeng Xuan,Shibei Meng,Shiqi Zhou,Teng Dai,Tong-Shuai Ren,Wei Cui,Xi Yang,Xialin Du,Xiaojing Xu,Xue Sun,Xuejing Li,Yaming Liu,Yesheng Liu,Ying Liu,Yonghua Lin,Yu Zhao,Yunduo Zhang,Yuwen Luo,Zheqi He,Zhiyuan He,Zhongyuan Wang", "background": "研究团队对当前大型推理模型（LRMs）进行了适度规模的无污染评估，并发现了一些初步结论。此外，团队还发布了检测视觉线索推理能力的评测基准——ROME。这些数据和更新可以在指定的网站上找到：this https URL", "innovation": "该团队开发并发布了ROME评测基准，旨在测试视觉线索推理能力。这是对现有的大型推理模型进行初步评估的重要创新。", "conclusion": "本次评估揭示了一些关于大型推理模型性能的初步结论，并为未来的研究提供了基础。"}
{"llm_update_time": "20251015", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2509.21875", "html_url": "https://arxiv.org/abs/2509.21875", "title": "LUMINA: 使用上下文知识信号检测RAG系统中的幻觉", "title_en": "LUMINA: Detecting Hallucinations in RAG System with Context-Knowledge Signals", "authors": "Samuel Yeh,Sharon Li,Tanwi Mallick", "background": "检索增强生成（RAG）旨在通过将响应 grounding 在检索到的文档上，减轻大型语言模型的自相矛盾。然而，即使提供了正确的上下文，基于RAG的大型语言模型仍然会自相矛盾。现有研究表明，这是因为模型对外部上下文和内部分知识的使用之间存在不平衡。已有许多方法试图通过量化这些信号来检测自相矛盾，但这些方法需要大量的超参数调整，限制了它们的通用性。因此，本文提出了一种新的框架LUMINA，利用外部上下文使用和内部知识使用的信号检测RAG系统中的幻觉。", "innovation": "LUMINA framework 通过分布距离量化外部上下文的使用，并通过跟踪预测令牌如何随Transformer层变化来衡量内部知识的使用。此外，还提出了一个统计验证这些度量的框架。实验表明，LUMINA在多个RAG幻觉基准测试和四个开源大型语言模型上，实现了更高的AUROC和AUPRC分数，并且在检索质量和模型匹配的宽松假设下仍保持其有效性。", "conclusion": "LUMINA framework 在检测RAG系统中的幻觉方面表现出更高的效果和实用性，特别是在宽松的检索质量和模型匹配假设下仍然表现稳定。"}
{"llm_update_time": "20251015", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2509.22926", "html_url": "https://arxiv.org/abs/2509.22926", "title": "大型语言模型在药物管理中的表现：三项性能分析", "title_en": "Large language models management of medications: three performance analyses", "authors": "Kelli Henry,Steven Xu,Kaitlin Blotske,Moriah Cargile,Erin F. Barreto,Brian Murray,Susan Smith,Seth R. Bauer,Xingmeng Zhao,Adeleine Tilley,Yanjun Gao,Tianming Liu,Sunghwan Sohn,Andrea Sikora", "background": "大型语言模型（LLMs）已经在某些诊断任务中表现出色，但很少有研究评估它们在为特定诊断推荐适当药物方案方面的连贯性。药物管理是一个复杂的过程，需要综合药物配方和完整的用药指令，以确保安全使用。本研究通过测试GPT-4o这一可用的LLM（通过ChatGPT提供），评估了其在三项药物管理任务中的表现。具体包括：识别给定通用药名的所有可用剂型、识别给定药物方案的药物-药物相互作用（DDI）、以及为给定通用药名准备药物处方。研究表明，模型在基本药物任务上的表现较差，需要通过临床标注数据集进行领域特定的训练，并建立一个全面的评估框架来衡量性能。", "innovation": "本研究首次评估了大型语言模型在药物管理和药物方案推荐方面的表现，并通过三个具体任务验证了模型的能力，即药物剂型识别、药物-药物相互作用识别和药物处方生成。这项研究还强调了利用临床标注数据集进行领域特定训练的必要性，并提出了全面的评估框架以评估模型性能。", "conclusion": "在基本药物任务上，模型性能较差。研究结果表明，需要通过临床标注数据集进行领域特定训练，并建立一个全面的评估框架，以提高大型语言模型在药物管理和药物方案推荐任务中的表现。"}
{"llm_update_time": "20251015", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2509.23441", "html_url": "https://arxiv.org/abs/2509.23441", "title": "Cognition-of-Thought 在大型语言模型中引发社会对齐的推理", "title_en": "Cognition-of-Thought Elicits Social-Aligned Reasoning in Large Language Models", "authors": "Xuanming Zhang,Yuxuan Chen,Samuel Yeh,Sharon Li", "background": "大型语言模型在复杂推理方面表现出色，但仍然可能出现有害行为。当前的对齐策略通常将安全性嵌入模型权重中，使得这些控制变得隐式、静态且难以修改。现有方法未能提供有效的动态和可调整的安全性对齐解决方案。", "innovation": "本文引入了一种新型解码时框架 Cognition-of-Thought (CooT)，它为大型语言模型配备了显式的认知自我监控循环。CooT 将标准文本生成器与认知感知器结合，持续监控文本生成过程。感知器基于结构性、优先性的原则（如安全高于服从）来检测潜在的不一致性。当检测到违规行为时，CooT 会回滚生成过程到错误点，并在注入的指导（结合普遍的社会优先级和上下文特定警告）下重新生成内容。CooT 使对齐从固定属性转变为动态的、明晰的且可审计的过程，实现了灵活的策略更新而无需重新训练模型。", "conclusion": "在多个基准和模型簇的广泛实验中，本文表明 CooT 一致地提高了安全性和社会推理性能。"}
{"llm_update_time": "20251015", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2509.24821", "html_url": "https://arxiv.org/abs/2509.24821", "title": "DiaCDM：使用初始化-响应-评估框架在教师-学生对话中进行认知诊断", "title_en": "DiaCDM: Cognitive Diagnosis in Teacher-Student Dialogues using the Initiation-Response-Evaluation Framework", "authors": "Rui Jia,Yuang Wei,Ruijia Li,Yuan-Hao Jiang,Xinyu Xie,Yaomin Shen,Min Zhang,Bo Jiang", "background": "认知诊断（CD）能够有效地从结构化测试数据中评估学生对知识的掌握情况，但在应用于实际的教师-学生对话时存在两个基本挑战。传统的认知诊断模型缺乏处理动态和非结构化对话的合适框架，同时从长对话中准确提取诊断意义也存在困难。", "innovation": "作者提出了一种创新模型 DiaCDM，该模型首先从教育理论中借鉴了初始化-响应-评估（IRE）框架，设计了一个专门针对对话的诊断框架。其次，开发了一种独特的基于图的编码方法，将教师的问题与相关的知识组件结合起来，以更精确地捕捉关键信息。这项工作是在对话环境中首次探索认知诊断的应用尝试。实验结果表明 DiaCDM 不仅显著提高了诊断准确性，还增强了结果的可解释性，为教师评估学生认知状态提供了一个强有力的工具。", "conclusion": "实验结果显示，DiaCDM 不仅显著提高了诊断准确性，而且提高了结果的可解释性，给教师提供了一个评估学生认知状态的强大工具。"}
{"llm_update_time": "20251015", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.19982", "html_url": "https://arxiv.org/abs/2508.19982", "title": "扩散语言模型在解码前就知道答案", "title_en": "Diffusion Language Models Know the Answer Before Decoding", "authors": "Pengxiang Li,Yefan Zhou,Dilxat Muhtar,Lu Yin,Shilin Yan,Li Shen,Yi Liang,Soroush Vosoughi,Shiwei Liu", "background": "扩散语言模型(DLMs)作为一种新的平行序列生成方法，相较于自回归模型提供了更灵活的token顺序。然而，它们的推理速度通常仍低于自回归模型，主要原因是双向注意力的成本和需要大量精细调整步骤才能生成高质量输出。", "innovation": "该研究发现了DLMs早期答案收敛的未被充分利用的特性，在许多情况下，正确的答案可以在最终解码步骤之前通过半步即可识别，这无论是半自回归还是随机遮盖调度下都适用。在此基础上，提出了一个无需训练的快速解码新范式——Prophet，该范式使用前两个预测候选的置信度差距作为是否继续细化或“押注”的标准。实验结果表明，Prophet可以将解码步骤减少多达3.4倍，同时保持高质量的生成。", "conclusion": "这一研究将DLM的解码问题重新定义为何时停止采样的问题，表明早期解码收敛作为一种简单的加速机制，在DLM推理加速方面具有潜力，可以补充现有的加速技术。整体方法实现简单，无需额外训练，且不影响现有DLM实施。"}
{"llm_update_time": "20251015", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2509.10446", "html_url": "https://arxiv.org/abs/2509.10446", "title": "DeepDive: 通过知识图谱和多轮RL推进深度搜索代理", "title_en": "DeepDive: Advancing Deep Search Agents with Knowledge Graphs and Multi-Turn RL", "authors": "Rui Lu,Zhenyu Hou,Zihan Wang,Hanchen Zhang,Xiao Liu,Yujiang Li,Shi Feng,Jie Tang,Yuxiao Dong", "background": "大型语言模型（LLMs）通过附加浏览工具极大地提高了它们作为解决复杂实际问题的深入搜索代理的潜力，但开放的LLMs在这些环境中的表现仍然较差，原因是为了深度思考需要长时间推理能力有限，并且缺乏足够的监督数据来应对困难任务。", "innovation": "提出了DeepDive策略。首先，自动从开放的知识图中生成复杂、困难且难以找到的问题。其次，通过端到端的多轮强化学习（RL）来增强LLMs在深度搜索中的长时间推理。设计了冗余惩罚以减少重复的相似查询。实验结果显示，DeepDive-32B在BrowseComp中达到了新的开源竞争结果，优于WebSailor、DeepSeek-R1-Browse和Search-o1。多轮RL训练提高了深层次搜索能力，并在多个基准测试中显著促进了性能提升。DeepDive允许测试时工具调用的扩展和并行采样。", "conclusion": "DeepDive通过提出先进的策略和多轮RL训练，显著提高了LLMs的深度搜索能力，展示了其在复杂任务上的潜力，并通过开源的资源促进进一步的研究和应用。"}
{"llm_update_time": "20251015", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2509.25913", "html_url": "https://arxiv.org/abs/2509.25913", "title": "Nadaraya-Watson内核理解混合专家（Mixture-of-Experts）", "title_en": "Understanding the Mixture-of-Experts with Nadaraya-Watson Kernel", "authors": "Chuanyang Zheng,Jiankai Sun,Yihang Gao,Enze Xie,Yuehao Wang,Peihao Wang,Ting Xu,Matthew Chang,Liliang Ren,Jingyao Li,Jing Xiong,Kashif Rasul,Mac Schwager,Anderson Schneider,Zhangyang Wang,Yuriy Nevmyvaka", "background": "混合专家（Mixture-of-Experts，MoE）已成为现代大型语言模型（LLMs）的基石。传统上，MoE 使用 Softmax 作为路由得分函数来聚合专家输出，这是一种在最早期 MoE 模型到现代 LLMs 中一直沿用的设计选择，现在被广泛认为是标准做法。然而，Softmax 用于将路由权重投影到概率单纯形中仍然被视为一种未经挑战的假设，而非一个精深的设计选择。本文首先回顾经典的 Nadaraya-Watson 回归，并观察到 MoE 与 Nadaraya-Watson 回归具有相同的数学形式。进一步研究表明，全连接前向神经网络（FFN）和 MoE 都可以被视为 Nadaraya-Watson 回归的特殊案例，其中核函数对应于输出层的输入神经元。这些见解促使我们提出了零附加成本的 Kernel Inspired Router with Normalization（KERN），一种FFN风格的路由函数，作为一种替代 Softmax 的方法。", "innovation": "我们提出了零附加成本的 Kernel Inspired Router with Normalization（KERN），这是一种 FFN 风格的路由函数，作为 Softmax 的替代方案。我们展示了这种路由器可以概括基于 Sigmoid 和 Softmax 的路由器。根据 FFN 实现中的经验观察和现有实践，我们建议在 KERN 路由器函数中使用 ReLU 激活和 l2-标准化。全面的 MoE 和 LLM 实验验证了提出的 FFN 风格路由器的有效性，即 \textbf{\textit{methodNorm}} 方法的有效性。", "conclusion": "本文通过理解 MoE 与 Nadaraya-Watson 回归的数学形式上的联系，提出了 KERN 作为 FFN 风格的路由函数，该方法不仅简化了 MoE 的设计，还在实践中被证明是有效和灵活的。"}
{"llm_update_time": "20251015", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.12411", "html_url": "https://arxiv.org/abs/2508.12411", "title": "大型语言模型的文化基因：跨语料库训练对模型价值观和偏见影响的研究", "title_en": "The Cultural Gene of Large Language Models: A Study on the Impact of Cross-Corpus Training on Model Values and Biases", "authors": "Emanuel Z. Fenech-Borg,Tilen P. Meznaric-Kos,Milica D. Lekovic-Bojovic,Arni J. Hentze-Djurhuus", "background": "全球部署的大规模语言模型（LLMs）普遍存在，但它们背后的文化和伦理假设却未被充分探索。本文旨在探讨LLMs通过其训练语料库继承的文化基因及其对模型价值观和偏见的影响。研究使用了一个针对个体主义与集体主义（IDV）及权力距离（PDI）两个跨文化维度的文化探针数据集（CPD），通过标准化的零样本提示对两个具有文化偏向的不同模型（西方中心的GPT-4和东方中心的ERNIE Bot）进行了比较，结果发现两者的文化价值观存在显著差异，并且通过计算文化匹配指数（CAI）进一步验证了这些差异的显著性。这一研究扩展了对LLMs文化假设的理解，并强调了文化敏感评估和部署的重要性，以避免算法文化霸权。", "innovation": "文章首次引入了‘文化基因’的概念，系统地提出了LLMs从其训练语料库中继承的价值趋向。通过双维度文化探针数据集对两个文化偏好不同的模型进行了详细比较，揭示了它们在文化价值观上的显著差异。此外，文章还引入了一个文化匹配指数（CAI），以量化LLMs与不同文化背景之间的匹配度，为理解LLMs的文化组成部分提供了新的视角。", "conclusion": "研究结果支持这样的观点：LLMs作为其文化语料库的统计反映，揭示了这些组成部分的文化价值观和偏见。这一发现促使了对LLMs的文化意识评估和部署的重要性，以避免算法文化霸权。"}
{"llm_update_time": "20251015", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2509.26074", "html_url": "https://arxiv.org/abs/2509.26074", "title": "Limited Preference Data? Learning Better Reward Model with Latent Space Synthesis", "title_en": "Limited Preference Data? Learning Better Reward Model with Latent Space Synthesis", "authors": "Leitian Tao,Xuefeng Du,Sharon Li", "background": "奖励建模对于使大规模语言模型（LLMs）与人类偏好相一致至关重要，但常常受限于偏好数据采集成本高。现有方法在合成文本数据时计算成本高昂。现有方法难以有效地以高效和经济的方式生成结构化的偏好数据。", "innovation": "提出了一种名为LENS的新框架，直接在LLM的潜在嵌入空间中合成偏好数据。LENS框架利用变分自编码器（VAE）学习响应嵌入的结构化潜在表示。通过在潜在空间中进行控制扰动并解码回嵌入空间，该方法可以高效地生成多样化且在语义上一致的合成偏好对，从而绕过昂贵的文本生成和注释过程。理论证明，合成的对保留下了原始的偏好顺序，并且改进了奖励模型的泛化能力。实验证明，与基于文本的增强方法相比，LENS在生成速度上快18倍，并且使用更小16000倍的模型仍能取得更好的效果。", "conclusion": "LENS框架为通过高效数据增强来提升奖励建模提供了一种可扩展且有效的替代方案。我们的工作展示了在潜在空间中合成偏好数据的有效性和实用性。"}
{"llm_update_time": "20251015", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2509.26072", "html_url": "https://arxiv.org/abs/2509.26072", "title": "The Silent Judge: Unacknowledged Shortcut Bias in LLM-as-a-Judge", "title_en": "The Silent Judge: Unacknowledged Shortcut Bias in LLM-as-a-Judge", "authors": "Arash Marioriyad,Mohammad Hossein Rohban,Mahdieh Soleymani Baghshah", "background": "随着大型语言模型（LLMs）的应用越来越广泛，它们被用作自动裁判来评估诸如总结、对话和创造性写作等任务中的系统输出。一个合格的裁判应当基于响应质量做出裁定，并明确表明其决策背后的因素。然而，现有的LLM裁判系统在依赖于提示中引入的捷径时表现不佳，未能仅有响应质量这一点上做出裁定。本文通过使用两个评估数据集（ELI5和LitBench），构建了100对判断任务，使用了两个广泛使用的模型（GPT-4o和Gemini-2.5-Flash），并在保持其他提示内容固定的情况下，向响应中添加了常见的线索，发现两个模型均表现出了显著的倾向性偏见，偏好新的响应而非旧的响应，以及明显的证明来源层次结构。这些偏差在GPT-4o模型和更主观、开放领域的LitBench数据集上尤为明显。", "innovation": "文章创新在于通过实验展示了当前的LLM裁判系统依赖于提示中引入的捷径，使得它们在评估任务时未能充分依据响应质量做出裁定。研究构建了100对判断任务，并添加了具体的线索以探讨模型的偏见和响应质量之间的关系。", "conclusion": "当前的LLM裁判系统存在捷径依赖性，且在这一过程中未能清晰地表达其决策依据，这对于作为研究或部署中的评估者是不可靠的。研究揭示了这些系统存在偏见和不忠的问题。"}
{"llm_update_time": "20251015", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.00507", "html_url": "https://arxiv.org/abs/2510.00507", "title": "Graph2Eval：通过知识图谱实现代理的自动多模态任务生成", "title_en": "Graph2Eval: Automatic Multimodal Task Generation for Agents via Knowledge Graphs", "authors": "Yurun Chen,Xavier Hu,Yuhan Liu,Ziqi Wang,Zeyi Liao,Lin Chen,Feng Wei,Yuxi Qian,Bo Zheng,Keting Yin,Shengyu Zhang", "background": "随着多模态LLM驱动的代理在自主性和泛化能力方面不断发展，基于静态数据集的评估方法已经不能充分评估其在动态环境和多样化任务中的实际能力。现有基于LLM的合成数据方法主要设计用于LLM的训练和评估，无法直接应用于需要工具使用和互动能力的代理任务。尽管最近有一些研究探讨了使用LLM实现自动代理任务生成，但大多数研究仅限于文本或图像分析，并没有系统地在Web环境中方面建模多步骤互动。", "innovation": "我们提出了基于知识图谱的Graph2Eval框架，它可以自动生成多模态文档理解和web互动任务，从而实现对代理推理、协作和互动能力的全面评估。该框架利用来自多源外部数据的知识图谱作为任务空间，通过子图采样、任务模板和元路径将语义关系转换为结构化的多模态任务。此外，Graph2Eval支持对不同类型代理进行全面的端到端评估（单代理、多代理和Web代理），并衡量其推理、协作和交互能力。我们还通过Graph2Eval-Bench，一个包含1,319个任务的精选数据集来实例化该框架，这些任务涵盖文档理解和网页互动场景。", "conclusion": "实验表明，Graph2Eval可以有效地生成能够区分代理和模型性能的任务，揭示不同设置中推理、协作和网页互动方面的差距，为代理评估提供了新的视角。"}
{"llm_update_time": "20251015", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.02392", "html_url": "https://arxiv.org/abs/2510.02392", "title": "KnowledgeSmith：利用模型编辑和遗忘揭示LLMs的知识更新", "title_en": "KnowledgeSmith: Uncovering Knowledge Updating in LLMs with Model Editing and Unlearning", "authors": "Yinyi Luo,Zhexian Zhou,Hao Chen,Kai Qiu,Marios Savvides,Sharon Li,Jindong Wang", "background": "大语言模型（LLMs）的知识更新机制尚未充分研究，主要问题是相关的评估数据不足、分散且规模较小。已有研究表明，LLMs 和人类在修改某些知识方面可能相似，但随着训练数据量的增加，编辑和遗忘的机制有何不同尚未明确。鉴于此，本文构建了一个统一框架，称为KnowledgeSmith，用于系统地分析LLMs的知识更新机制。通过将编辑和遗忘视为一个受限优化问题的实例，并提出一种自动数据集生成器以便进行控制性研究，该研究探讨了不同修改策略对模型知识的影响。", "innovation": "首先，将编辑和遗忘视为同一受约束优化问题的不同实例。然后，提出了一种自动数据集生成器，能够在多个图层和数据规模上提供结构化的干预措施，实现了对不同修改策略如何传播通过模型知识的研究，展示了知识传播、塑性扩展、一致性和稳健性等方面的细微见解。研究结果发现，LLMs在不同知识水平上的更新机制与人类不同，存在一致性的权衡关系。这些发现为设计更可靠和可扩展的策略提供了建议和启示。", "conclusion": "我们的研究结果表明，LLMs在不同层次的知识更新机制与人类不同，并且存在一致性和容量之间的权衡。我们希望这些发现能为设计更可靠和可扩展的策略提供借鉴和启发。"}
{"llm_update_time": "20251015", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.03202", "html_url": "https://arxiv.org/abs/2510.03202", "title": "基于模型的零样本跨语言传输源语言排名", "title_en": "Model-Based Ranking of Source Languages for Zero-Shot Cross-Lingual Transfer", "authors": "Abteen Ebrahimi,Adam Wiemerslage,Katharina von der Wense", "background": "该研究背景是在机器翻译和自然语言处理任务中，如何有效利用源语言和目标语言的数据来提高跨语言任务的表现。通常的做法是利用词汇和语言特征，但这种方法可能在缺乏目标语言数据时表现不佳。因此，如何在仅使用少量目标语言数据的情况下，准确地为跨语言任务选择合适的源语言成为一个挑战。", "innovation": "该论文提出了一个名为NN-Rank的算法，通过利用多语言模型的潜在表示和未标记的目标语言数据来进行源语言的排名，以支持零样本的跨语言任务转移。实验中，该算法应用于两个预训练的多语言模型，任务包括部分词性标注和命名实体识别。研究结果表明，与依赖词汇和语言特征的领先基线相比，NN-Rank在部分词性标注和命名实体识别任务中分别取得了高达35.56和18.14的平均提高，仅使用圣经等域外语料库数据也能保持竞争力，即使样本量很少。", "conclusion": "通过使用NN-Rank算法，该研究展示了仅利用少量目标语言数据，尤其是域外数据，如圣经，也能有效提高跨语言任务的表现，证明了该方法的有效性和域外数据的潜力。此外，大量的消融实验也验证了算法的鲁棒性和可靠性，在极少量的数据下也能产生高质量的排名。"}
{"llm_update_time": "20251015", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.03999", "html_url": "https://arxiv.org/abs/2510.03999", "title": "长时交互中欺骗行为的模拟与理解", "title_en": "Simulating and Understanding Deceptive Behaviors in Long-Horizon Interactions", "authors": "Yang Xu,Xuanming Zhang,Samuel Yeh,Jwala Dhamala,Ousmane Dia,Rahul Gupta,Sharon Li", "background": "欺骗是人类交流中的普遍特征，并已成为大型语言模型（LLMs）中的一个新兴关切。尽管近期研究已记录了LLMs在压力下实施欺骗的案例，但大多数评估仍局限于单轮提示，未能捕捉到欺骗策略通常展开的长期互动。", "innovation": "引入了首个用于模拟和评估LLMs在扩展序列的相互依赖任务和动态上下文压力下欺骗行为的仿真框架。该框架通过多代理系统进行了实际应用：一个执行代理负责完成任务，一个监督代理评估进展、提供反馈并维护信任状态。独立的欺骗审计员则回顾完整轨迹以识别和理解欺骗发生的时间和方式。该研究在11个前沿模型上进行了大量实验，涵盖了开源和闭源系统，发现欺骗行为依赖于模型且随着事件压力的增加而增加，并且持续侵蚀监督者的信任。", "conclusion": "研究结果确立了欺骗在长时互动中的一个新兴风险，并为未来LLMs在现实世界、信任敏感情境中的评估提供了基础。"}
{"llm_update_time": "20251015", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.03536", "html_url": "https://arxiv.org/abs/2510.03536", "title": "Triplet-Structured Knowledge Integration for Multi-Turn Medical Reasoning", "title_en": "Triplet-Structured Knowledge Integration for Multi-Turn Medical Reasoning", "authors": "Zhaohan Meng,Zaiqiao Meng,Siwei Liu,Iadh Ounis", "background": "大型语言模型（LLMs）在静态医疗问答任务上表现优异，但在多轮临床对话中，由于患者信息分散在不同轮次，LLMs的推理能力通常会下降。这项研究旨在通过明确的知识集成来提高LLMs在多轮临床对话中的推理可靠性。", "innovation": "提出了一种三元组结构的方法TriMediQ，该方法通过明确的知识集成增强LLMs的推理可靠性。具体来说，TriMediQ首先使用一个冻结的三元组提取LLM将患者回复转化为临床相关的三元组，通过约束式提示确保事实的精确性。然后，在为每位患者构建的知识图谱中，通过冻结所有LLM参数训练一个投影模块，该模块由图编码器和投影器构成，捕捉关系依赖性并引导多跳推理，从而有助于连贯的临床对话理解。", "conclusion": "在两个交互式医疗问答基准测试实验中，TriMediQ在iMedQA数据集上的准确率比五个现有基线高出高达10.4%。这些结果表明，将患者信息结构化为三元组可以有效地提高LLMs在多轮医疗问答推理中的能力。"}
{"llm_update_time": "20251015", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2509.26041", "html_url": "https://arxiv.org/abs/2509.26041", "title": "不言而喻的提示：LLM推理中的准确度无明确认可", "title_en": "Unspoken Hints: Accuracy Without Acknowledgement in LLM Reasoning", "authors": "Arash Marioriyad,Shaygan Adim,Nima Alighardashi,Mahdieh Soleymani Banghshah,Mohammad Hossein Rohban", "background": "大规模语言模型（LLMs）在解决数学和逻辑推理任务时越来越多地依赖于有链式思维（CoT）的提示。但关键问题在于，这些生成的推理是否真正忠实于底层的计算，还是仅仅是提示提供的答案捷径形成的后见之明叙述。此前有关带有提示与未带提示的实验已经进行了探索，但这种研究大多侧重于提示是否被明确承认。本研究在受控的提示条件下展开系统性研究，以此深入探讨CoT的忠实性问题，涉及四个数据集（AIME、GSM-Hard、MATH-500和UniADILR），两种先进的模型（GPT-4o和Gemini-2-Flash），以及结构化设定的不同提示条件，包含正确性和错误性、语调特性和复杂性等维度。", "innovation": "该研究创新之处在于对其通过系统化的受控提示实验来探索CoT推理的忠实性，涵盖了广泛的模型、数据集和提示条件，从准确性和提示的明确承认两个维度系统评估CoT的忠实性。通过揭示三种关键发现：正确的提示显著提高了在难题和逻辑推理任务中的准确度，而错误的提示在基线较低的任务中大幅降低了准确度；提示的频繁不被明确认可表明模型在处理复杂提示时更倾向于在推理过程中明确表达依赖关系；不同的提示呈现方式对准确性和提示的明确认可产生不同影响，暗示了人类喜好导向和自我审查可能导致的不同效果。", "conclusion": "此研究展示了LLM推理过程在多方面受到捷径引导的影响，这些捷径隐藏了其忠实性，并通过系统分析提示条件对准确性和提示承认率的影响揭示了这些复杂现象。"}
{"llm_update_time": "20251015", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.09243", "html_url": "https://arxiv.org/abs/2510.09243", "title": "CrisiText：紧急通讯中用于LLM训练的警报消息数据集", "title_en": "CrisiText: A dataset of warning messages for LLM training in emergency communication", "authors": "Giacomo Gonella,Gian Maria Campedelli,Stefano Menini,Marco Guerini", "background": "在危机情况（如自然灾害或暴力袭击）中有效地识别威胁并减轻潜在的破坏对于保护受威胁个体至关重要。尽管人工智能已被用于协助人类在紧急情况下，但仍主要集中在分类任务上。使用自然语言生成（NLP）架构生成及时警告信息的巨大潜力被忽视了。", "innovation": "本文介绍了CrisiText，这是第一个针对13种不同类型的危机场景生成警告信息的大规模数据集，包含超过40万个警告信息（几乎涵盖了18000个危机情况），旨在帮助平民在危机期间和之后。为了生成数据集，从现有的危机描述开始，创建与情景相关的事件链，每个事件都配有一条警告消息。生成过程遵循专家撰写的指南以确保术语正确性和建议的真实性，每条消息还配有三种非最优的警告类型以供不同的NLP方法研究。我们还进行了多种监督微调设置、偏好对齐、零样本和少样本方法的实验，评估了模型在分布外场景中的性能，并分析了自动后编辑的有效性。", "conclusion": "该研究提供了CrisiText警告信息数据集，展示了生成紧急情况下指南和警告信息的能力，为进一步研究和模型改进提供了基础。"}
{"llm_update_time": "20251015", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.09255", "html_url": "https://arxiv.org/abs/2510.09255", "title": "DSPO: 稳定且高效的策略优化算法以实现代理式搜索与推理", "title_en": "DSPO: Stable and Efficient Policy Optimization for Agentic Search and Reasoning", "authors": "Chenyang Gu,Yewen Pu,Bruce Yang,Xiaofan Li,Huan Gao", "background": "增强语言模型（LLMs）的外部知识主动搜寻能力对于处理复杂和现实世界任务至关重要。当前的方法要么依赖提示来唤起模型的内在代理能力，要么在应用强化学习（RL）于复杂交互式任务时遭遇性能天花板并崩溃，无法充分挖掘其真实的代理潜力。论文由此背景出发，针对上述问题进行探讨，并引入DSPO算法以解决这些挑战.", "innovation": "本文引入了动态过滤序列级别策略优化（DSPO），这是一种改进的RL算法，通过序列级别优化和动态样本筛选来实现增强的代理训练。特别之处在于该模型通过纯粹的RL训练来实现多轮次搜索与推理的融合，无需依赖监督演示数据。这一创新方法显著提升了模型在多个问答基准测试中的性能，特别是在复杂多跳问答（如HotpotQA）任务上，相较于之前的7B模型提高了34.1%，甚至超越了之前的14B模型，同时保持了异常出色的训练稳定性.", "conclusion": "研究展示了DSPO算法对于增强模型在代理式搜索和推理任务中的自主性和适应性的显著贡献，证明了基于RL的新型方法在实际应用中的潜力和优越性。"}
{"llm_update_time": "20251015", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.10661", "html_url": "https://arxiv.org/abs/2510.10661", "title": "AGENTIQL：一种受代理启发的多专家框架用于文本到SQL生成", "title_en": "AGENTIQL: An Agent-Inspired Multi-Expert Framework for Text-to-SQL Generation", "authors": "Omid Reza Heidari,Siobhan Reid,Yassine Yaakoubi", "background": "LLMs在文本到SQL生成方面已经取得了显著进展，但单一架构在处理复杂推理和模式多样性方面存在困难。", "innovation": "提出了一种基于代理启发的多专家框架AGENTIQL，该框架包含：1)推理代理进行问题分解；2)编码代理生成子查询；3)润色步骤进行列选择。引入了自适应路由器以在模块化流水线和基本解析器之间进行选择，以平衡效率和准确性。该流水线中的多个步骤可以并行执行，使其具有更好的扩展性。在Spider基准上，AGENTIQL在执行准确性和可解释性方面表现出色，使用14B模型时达到86.07% EX，而性能的实现依赖于路由机制的有效性，从而在使用远较小的开源LLMs的情况下接近GPT-4的SOTA（89.65% EX）。此外，该框架还提高了透明度，揭示了中间推理步骤，提供了稳健、可扩展且可解释的语义解析方法。", "conclusion": "AGENTIQL在Spider基准上的性能表明，通过引入多专家框架并结合适当的路由机制，可以有效提高文本到SQL生成的准确性和可解释性，甚至在使用更小的模型时也能接近更先进的方法。"}
{"llm_update_time": "20251015", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.07300", "html_url": "https://arxiv.org/abs/2510.07300", "title": "本地思维：增强一致性增强强化学习以解锁多语言推理", "title_en": "Think Natively: Unlocking Multilingual Reasoning with Consistency-Enhanced Reinforcement Learning", "authors": "Xue Zhang,Yunlong Liang,Fandong Meng,Songming Zhang,Kaiyu Huang,Yufeng Chen,Jinan Xu,Jie Zhou", "background": "大型推理模型（LRMs）通过采用“先思考后作答”的范式，在复杂推理任务上取得了显著性能，提升了准确性和可解释性。然而，当前的LRMs在处理非英语语言时存在两个关键限制：（1）它们难以保持输入和输出语言的一致性；（2）它们通常在错误的推理路径和较低的答案准确性方面表现不佳，尤其是在非英语语言中。这些限制极大地降低了非英语用户的经验，并阻碍了LRMs的全球部署。背景部分指出了LRMs在处理非英语语言时面临的挑战及其影响。", "innovation": "为了应对这些限制，作者提出了M-Thinker模型，该模型通过GRPO算法训练，并采用了语言一致性（LC）奖励和新型跨语言思维对齐（CTA）奖励。LC奖励定义了输入、思维和答案之间严格的语言一致性约束。CTA奖励则比较了模型在非英语和英语之间的推理路径，以从英语中转移其推理能力到非英语语言。此外，通过迭代的强化学习过程，M-Thinker-1.5B/7B模型不仅实现了近乎100%的语言一致性，还在MMATH和PolyMath等多语言基准测试中取得了优异的性能，并且展示了在域外语言上的良好泛化能力。说明了模型的新颖之处在于通过增强一致性的方法提升跨语言推理的能力。", "conclusion": "最终，M-Thinker模型在保持语言一致性的同时，还展示了在多语言环境下的优秀性能和良好的泛化能力，解决了当前LRMs在处理非英语语言时的局限性，为多语言推理任务提供了有效的解决方案。结论部分总结了研究的主要成果和潜在应用价值。"}
{"llm_update_time": "20251015", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.10666", "html_url": "https://arxiv.org/abs/2510.10666", "title": "BrowserAgent：利用人类启发式网络浏览行为构建网络代理", "title_en": "BrowserAgent: Building Web Agents with Human-Inspired Web Browsing Actions", "authors": "Tao Yu,Zhengbo Zhang,Zhiheng Lyu,Junhao Gong,Hongzhu Yi,Xinming Wang,Yuxuan Zhou,Jiabing Yang,Ping Nie,Yan Huang,Wenhu Chen", "background": "随着大规模语言模型（LLMs）处理现实世界问题的能力不断增强，它们能否有效互动并自主获取外部动态网页信息变得至关重要。尽管现有研究如Search-R1和WebDancer展示了在解决网络任务方面的出色表现，但它们依赖外部工具将交互式的网络环境转化为静态文本内容。这与人类的浏览行为不同，人类的浏览行为涉及多种与浏览器的交互行动，包括滚动、点击和输入等。本文探讨了如何通过引入一种模仿人类浏览行为的交互代理BrowserAgent来解决复杂的任务，同时通过直接操作Playwright和执行预定义的浏览器动作与原始网页互动。", "innovation": "本文提出的创新在于BrowserAgent通过模仿人类的网络浏览行为进行交互操作，使用较少量的训练数据（比Search-R1少），在不同的开集问答（Open-QA）任务中达到了更竞争性的结果。引入了显式的记忆机制来存储各步骤的关键结论，增强了模型在长期任务上的推理能力。在多跳问答（如HotpotQA、2Wiki和Bamboogle）方面，BrowserAgent-7B相较于Search-R1实现了约20%的改进。这表明BrowserAgent可以提供更高级的框架以支持更互动和可扩展的网络代理系统。", "conclusion": "研究结果表明，BrowserAgent作为一种更互动且可扩展的网络代理框架，可以显著提高LLM处理复杂任务的能力，特别是在跨多个步骤的任务上展示出了优越的性能。"}
{"llm_update_time": "20251015", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.11713", "html_url": "https://arxiv.org/abs/2510.11713", "title": "大型推理模型可中断性研究", "title_en": "Are Large Reasoning Models Interruptible?", "authors": "Tsung-Han Wu,Mihran Miroyan,David M. Chan,Trevor Darrell,Narges Norouzi,Joseph E. Gonzalez", "background": "以往对大型推理模型（LRMs）的研究通常在静态场景下进行评估，假设模型的回答是即时的，且请求的上下文在模型回应期间保持不变。虽然这种假设对于短期任务通常成立，但现代推理任务如辅助编程，需要长时间思考和代码可能发生变化。现有的研究忽略了模型在长时间推理过程中可能会由于中断或者上下文变化导致性能下降的问题。", "innovation": "该研究挑战了静态场景下的假设，通过引入两个现实动态场景来评估LRMs的鲁棒性：一是中断测试，二是动态上下文测试。这些测试揭示了即使在静态场景下表现先进的模型，也可能会因为中断或上下文变化而表现不佳。研究还发现了几种新的失败模式，包括推理渗漏、恐慌和自我怀疑等。", "conclusion": "在需要长时间推理的数学和编程基准测试中，静态评估往往高估了模型的鲁棒性。即使最先进的LRMs在遇到中断或面对动态上下文时可能会表现不佳，性能可能下降高达60%。这些发现提出了新的研究方向，以改进模型在动态环境下的鲁棒性。"}
{"llm_update_time": "20251015", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2409.05674", "html_url": "https://arxiv.org/abs/2409.05674", "title": "ASR系统延迟评估：实时使用中的方法论视角", "title_en": "Assessing Latency in ASR Systems: A Methodological Perspective for Real-Time Use", "authors": "Carlos Arriaga,Alejandro Pozo,Javier Conde,Alvaro Alonso", "background": "ASR系统可以实时生成语音转文字，但常常无法捕捉人类译员能够理解的语言细微之处。ASR工具在很多场合下很有用，但人类译员在敏感环境中（如外交会议）更是不可或缺，因为他们能够即时调整，提升准确度。然而，ASR系统存在延迟问题，不符合即时翻译的需求。用户感知的延迟和翻译感知的延迟不同，前者是指从讲话到生成转录的时间，而后者关注即时互动的需求。论文旨在解决这一延迟问题，提出一种新的ASR系统延迟测量方法，并验证其在实时翻译场景中的可用性。", "innovation": "提出了一种新的方法来测量ASR系统的延迟，并验证该方法在实时翻译场景中的实用性。这是首次从方法论角度探讨ASR系统延迟问题，以更好地服务于即时需求。", "conclusion": "通过新的延迟测量方法，研究验证了ASR系统在实时翻译中的可用性。这一创新方法对提升ASR系统的即时响应能力有潜在的积极影响，有助于未来开发更高效的实时语音翻译系统。"}
{"llm_update_time": "20251015", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2408.06849", "html_url": "https://arxiv.org/abs/2408.06849", "title": "基于大语言模型的因果代理", "title_en": "Causal Agent based on Large Language Model", "authors": "Kairong Han,Kun Kuang,Ziyu Zhao,Junjian Ye,Fei Wu", "background": "大语言模型在多种领域取得了显著的成功，但由于因果问题的内在复杂性和因果理论的描述要求，利用自然语言准确描述和理解这些问题具有挑战性。因果方法往往难以通过自然语言传达，限制了大语言模型在实际应用中的精确度。此外，因果数据集通常为表格格式，而大语言模型在处理自然语言数据方面表现出色，这种结构上的不匹配阻碍了它们对表格数据的有效推理。", "innovation": "为了解决这些问题，该研究将因果工具嵌入了一个代理框架，命名为因果代理。该代理包含工具、记忆和推理模块。工具模块中，因果代理调用Python代码并使用打包的因果函数模块来对齐表格数据与自然语言；在推理模块中，因果代理通过多次迭代使用工具进行推理；在记忆模块中，因果代理维护一个字典实例，其中键是唯一的名称而值是因果图。为了验证因果代理的因果能力，作者构建了一个名为Causal Tabular Question Answer (CausalTQA)的基准测试，包含四个层次的因果问题：变量层、边层、因果图层和因果效应层。CausalTQA包含大约1400个各个层次的问题。因果代理在整个四个层级的因果问题上表现出色，准确率均超过80%。在真实世界数据集QRData上的验证也表明，因果代理相较于当前最佳水平高出6%。本文代码可以通过提供的GitHub链接下载。", "conclusion": "研究证明了因果代理在处理因果问题方面的有效性和准确性，展示了其在当前最佳水平上的优势，并提供了进一步了解和实施细节的指南。"}
{"llm_update_time": "20251015", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2404.07214", "html_url": "https://arxiv.org/abs/2404.07214", "title": "探索视觉语言模型的前沿：当前方法与未来方向综述", "title_en": "Exploring the Frontier of Vision-Language Models: A Survey of Current Methodologies and Future Directions", "authors": "Akash Ghosh,Arkadeep Acharya,Sriparna Saha,Vinija Jain,Aman Chadha", "background": "大语言模型（LLMs）的出现极大地改变了人工智能革命的轨迹。然而，这些模型主要擅长处理文本信息，这导致了一个缺陷。为解决这一问题，研究人员致力于将视觉能力与LLMs相结合，从而导致了视觉语言模型（VLMs）的出现。这些高级模型能够处理如图像字幕和视觉问答等更复杂任务。本文综述了VLMs的关键进展，通过对不同类型的VLMs进行分类，详细地分析了各自的基础架构、训练数据来源和优缺点，帮助读者全面理解这些模型的组成部分。此外，还分析了VLMs在各种基准数据集中的性能，旨在提供对视觉语言模型多样景观的深刻理解，并展望了未来研究的机会，预测了进一步的突破和进步。", "innovation": "该研究通过详细分类和分析不同类型的VLMs，为视觉语言模型的关键进展提供了全面的理解。通过对这些模型的基础架构、训练数据来源及其优缺点进行深入探讨，旨在提供对这些模型的深刻理解，并通过分析其在各类基准数据集中的表现，理解其在不同任务中的性能和限制。同时，本文也指出了未来研究的潜在方向，预测了未来的突破和进步。", "conclusion": "本文通过对视觉语言模型的综合调研，深入分析了其不同类型的基础架构、优缺点以及在各类基准数据集中的表现，提供了对其当前方法的深入理解，并展望了未来研究的潜在方向，预测了进一步的研究突破和进展。"}
{"llm_update_time": "20251015", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2410.23223", "html_url": "https://arxiv.org/abs/2410.23223", "title": "COMAL: 一种用于与一般偏好对齐大语言模型的收敛元算法", "title_en": "COMAL: A Convergent Meta-Algorithm for Aligning LLMs with General Preferences", "authors": "Yixin Liu,Argyris Oikonomou,Weiqiang Zheng,Yang Cai,Arman Cohan", "background": "许多对齐方法，包括基于人类反馈的强化学习（RLHF），依赖于布雷德利-泰瑞（Bradley-Terry）奖励假设，但这个假设往往不足以捕捉人类偏好在内的全部范围和复杂性。以往的自博弈算法在寻找纳什均衡策略时要么发散，要么仅在修改后的游戏中收敛到纳什均衡策略，即使是在简单仿真环境中也是如此，这使得它们不能始终维持50%的胜率保证，即在所有其他策略中保持胜率。", "innovation": "本文提出了一种新的元算法——收敛性元对齐算法（Convergent Meta Alignment Algorithm，COMAL），灵感来源于博弈论中的收敛算法。该算法在理论上证明了最后迭代可以收敛到精确的纳什均衡政策，并通过合成数据集和偏好优化数据集展示了其有效性。COMAL 简单且可以与许多现有的偏好优化方法无缝集成。", "conclusion": "COMAL 在针对 Llama-3-8B-Instruct 和 Qwen2.5-7B 的实验中，相对于所有比较算法，在受控评估中保持了60.2%和56.8%以上的胜率。"}
{"llm_update_time": "20251015", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2505.10844", "html_url": "https://arxiv.org/abs/2505.10844", "title": "创造力还是暴力求解？通过脑筋急转弯探索大型语言模型的问题解决能力", "title_en": "Creativity or Brute Force? Using Brainteasers as a Window into the Problem-Solving Abilities of Large Language Models", "authors": "Simeng Han,Howard Dai,Stephen Xia,Grant Zhang,Chen Liu,Lichang Chen,Hoang Huy Nguyen,Hongyuan Mei,Jiayuan Mao,R. Thomas McCoy", "background": "目前使用的准确性评估标准已经成为了评估人工智能系统的一个标准方法，但是这种方法提供的关于模型如何得出解决方案的洞察是有限的。因此，本文引入了一套基于连贯长篇叙述形式的脑筋急转弯的基准测试，旨在更深入地探究模型所使用的推理策略类型。脑筋急转弯因其可以用多种方法（如一步即可解决的神来之笔或耗时更久的暴力求解）解答而非常适合这一目的。", "innovation": "本文对大型语言模型（LLMs）进行了多层次的推理探讨，不仅关注结果的正确性，还关注解决方案的质量和创造性。调查了多个方面的推理过程：包括把脑筋急转弯解析成精确的数学竞赛形式，从这些形式生成解决方案，基于黄金标准的自纠错解决方案，生成详细的解题步骤，以及利用提示。研究发现，很大一部分情况下LLMs能够提出富有创造性且洞察力丰富的解题思路，这表明它们具有解决新型问题的能力，但也存在未充分利用更高效或更创新的解题策略的情况，这表明提高LLMs推理能力的具体方向。", "conclusion": "总体而言，大型语言模型在解决脑筋急转弯时表现出创造力并提出富有洞察力的解决方案，同时也暴露了它们在某些情况下依赖暴力求解但忽略了更高效策略的现象。这为改进和训练大型语言模型的推理能力提出了新方向。"}
{"llm_update_time": "20251015", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2505.15877", "html_url": "https://arxiv.org/abs/2505.15877", "title": "突出重点：面向属性的关注嵌入", "title_en": "Highlighting What Matters: Promptable Embeddings for Attribute-Focused Image Retrieval", "authors": "Siting Li,Xiang Gao,Simon Shaolei Du", "background": "当前的文本到图像检索器特别是CLIP类似的检索器，由于其高效性和零样本能力而被广泛应用。然而，这些检索器在处理关注特定视觉属性的查询时表现不佳，尤其是在属性聚焦查询的处理上，它们的图像嵌入倾向于关注全局语义和主体，从而忽略了其他重要细节。", "innovation": "本文提出了一种新的嵌入方式——可提示嵌入，以更好地处理属性聚焦查询。这种方法通过增强对所需属性的强调，提升了检索性能。此外，提出了两种加速策略：预处理可提示嵌入和使用线性近似，进一步改善了检索性能。", "conclusion": "本文构建了COCO-Facet数据集，包含9,112个关于不同感兴趣属性的查询。实验结果显示，使用可提示嵌入的检索策略在多个方面优于传统方法，尤其是增强了对所需属性的关注，能够在不同程度上提高检索准确性，适用于各种查询类型、图像池和基础检索架构。"}
{"llm_update_time": "20251015", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2412.17534", "html_url": "https://arxiv.org/abs/2412.17534", "title": "CiteBART：学习为局部引文推荐生成引用", "title_en": "CiteBART: Learning to Generate Citations for Local Citation Recommendation", "authors": "Ege Yiğit Çelik,Selma Tekir", "background": "局部引文推荐（LCR）旨在根据给定的上下文推荐一组引用论文。随着生成式方法在效果上超越了传统的预取和重排基线方法，LCR任务的发展进入了新阶段。本研究在编码器-解码器架构中引入了针对引文的预训练，以在作者-日期引用标记中进行掩码，学习重建这些标记以完成LCR任务。两种预训练方案中，‘CiteBART-Base’仅使用局部上下文进行训练，而‘CiteBART-Global’还扩展了局部上下文添加引用论文的标题和摘要以丰富学习信号。", "innovation": "本研究提出了针对引文的预训练方法CiteBART，该方法基于编码器-解码器架构并在作者-日期引用标记中进行了掩码，旨在重建这些标记以满足LCR任务。引入了两种预训练方案：‘CiteBART-Base’仅使用局部上下文进行训练，而‘CiteBART-Global’利用引用论文的标题和摘要扩展局部上下文以增强学习信号。实验结果显示，这两种方案在LCR基准测试中表现出色，尤其是在Refseer和ArXiv等较大规模的基准测试中，‘CiteBART-Global’的效果尤为显著。同时，研究还进行了详尽的实验包括消融研究、定性分析以及详细的幻觉分类统计。", "conclusion": "研究表明，CiteBART-Global具备跨数据集的通用能力，在前3预测中的宏幻觉率MaHR为4%，并且当ground-truth在前k预测列表中的时候，其他预测中的幻觉倾向显著降低。‘CiteBART-Global’在较大规模基准测试中的性能尤为突出，是训练基准中最优的表现。"}
{"llm_update_time": "20251015", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2506.10412", "html_url": "https://arxiv.org/abs/2506.10412", "title": "Time-IMM：不规则多模态多变量时间序列的基准数据集", "title_en": "Time-IMM: A Dataset and Benchmark for Irregular Multimodal Multivariate Time Series", "authors": "Ching Chang,Jeehyun Hwang,Yidan Shi,Haixin Wang,Wen-Chih Peng,Tien-Fu Chen,Wei Wang", "background": "在医疗保健、气候建模和金融等领域的真实世界应用中，时间序列数据往往是不规则、多模态且杂乱的，具有不同的采样率、异步数据模态和普遍存在的缺失值。现有的基准测试通常假设干净且均匀采样的单一模态数据，这导致了研究与实际部署之间的巨大差距。", "innovation": "论文引入了Time-IMM数据集，专门捕捉多模态多变量时间序列中的推动因素不规则性，并将其分类为触发机制、约束机制和异常机制。此外，还引入了IMM-TSF基准库，用于不规则多模态时间序列的预测，包含专有的融合模块，支持时间戳到文本的融合模块、多模态融合模块，并提供了时序感知的平均和基于注意力的集成策略。研究表明，明确建模不规则时间序列数据的多模态性可以显著提高预测性能。", "conclusion": "Time-IMM和IMM-TSF为在实际条件下进行时间序列分析提供了基础。数据集和基准库已经公开发布，以促进进一步的研究和发展。"}
{"llm_update_time": "20251015", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2506.01551", "html_url": "https://arxiv.org/abs/2506.01551", "title": "EvolveNav：通过自我提升的嵌入式推理支持基于LLM的视觉语言导航", "title_en": "EvolveNav: Empowering LLM-Based Vision-Language Navigation via Self-Improving Embodied Reasoning", "authors": "Bingqian Lin,Yunshuang Nie,Khun Loun Zai,Ziming Wei,Mingfei Han,Rongtao Xu,Minzhe Niu,Jianhua Han,Hanwang Zhang,Liang Lin,Bokui Chen,Cewu Lu,Xiaodan Liang", "background": "近期研究揭示了训练开源大型语言模型（LLMs）以增强视觉-语言导航（VLN）性能和同时缩小LLMs训练语料库与VLN任务之间的领域差距的潜力。然而，这些方法大多采用简单的输入-输出映射方式，使得模型的映射学习困难且导航决策不可解释。Chain-of-Thought (CoT)训练作为一种潜在的方式，能够提高导航决策的准确性及可解释性，但导航任务的复杂性使得完美的CoT标签不可用，从而可能导致通过纯粹的CoT监督微调过拟合。", "innovation": "提出了一种新颖的自我改进嵌入式推理范式EvolveNav，用于增强基于LLM的VLN。该方法采用两阶段训练过程：（1）形式化的CoT监督微调，通过训练模型使其实现导航推理能力的激活和推理速度的提升；（2）自我反思后的训练，通过迭代使用模型自身的推理输出作为自我丰富的CoT标签来增强监督多样性。此外，还设计了一个自我反思的辅助任务来促使模型通过对比错误样式学习正确的推理模式。在多种流行基准测试中的实验结果显示，与基于LLM的VLN方法相比，EvolveNav方法具有持续的优势。", "conclusion": "实验结果表明，无论是在专门任务还是跨任务训练下，EvolveNav都能在流行的基准测试如R2R、REVERIE、CVDN和SOON上都表现出一致的优势。"}
{"llm_update_time": "20251015", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2502.02631", "html_url": "https://arxiv.org/abs/2502.02631", "title": "ParetoQ：在极低位宽LLM量化中改进标量法则", "title_en": "ParetoQ: Improving Scaling Laws in Extremely Low-bit LLM Quantization", "authors": "Zechun Liu,Changsheng Zhao,Hanxian Huang,Sijia Chen,Jing Zhang,Jiawei Zhao,Scott Roy,Lisa Jin,Yunyang Xiong,Yangyang Shi,Lin Xiao,Yuandong Tian,Bilge Soran,Raghuraman Krishnamoorthi,Tijmen Blankevoort,Vikas Chandra", "background": "关于采用量化模型在模型大小和准确率之间的最佳权衡位宽，存在持续的争论。一部分人支持4位量化，而另一部分人则认为1.58位量化效果更佳。然而，缺乏统一的多位量化框架使得相关结论较为薄弱。本文介绍ParetoQ，第一个能够统一比较1位、1.58位、2位、3位和4位量化设置的方法，揭示了在2位和3位之间存在显著的学习过渡：3位及以上，微调模型接近原始预训练分布；而低于2位的网络表示变化显著。通过优化训练方案和改进量化函数，ParetoQ超越所有特定位宽定制的方法。值得指出的是，ParetoQ的三元600M参数模型在准确率上超越了先前的6亿参数最强三元模型，仅使用其五分之一的参数。大量实验表明，在大小-准确率权衡中，三元、2位和3位量化保持相似性能，通常超过4位和二元量化。考虑到硬件限制，2位量化在内存缩减和加速方面具有前景。", "innovation": "本文提出了ParetoQ，这是第一个统一比较1位、1.58位、2位、3位和4位量化设置的方法。通过优化训练方案和改进量化函数，ParetoQ超过所有针对特定位宽定制的方法。特别地，ParetoQ的三元600M参数模型不仅在精度上超过了先前的6亿参数最强三元模型，还在相同参数下表现出更优的效果。大量实验表明，三元、2位和3位量化在大小-准确率权衡中保持相似性能，通常优于4位和二元量化，且2位量化在硬件优化方面显示出潜力。", "conclusion": "通过ParetoQ方法，作者发现低比特量化（三元、2位和3位）在大小-准确率权衡中表现出色，并且优化特定位宽的训练方案可以得到更好的量化效果。特别地，2位量化在减少内存使用和加速方面显示出显著优势。这些发现对于硬件受限场景下的量化模型设计具有重要指导意义。"}
{"llm_update_time": "20251015", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2506.15969", "html_url": "https://arxiv.org/abs/2506.15969", "title": "LazyEviction: 基于注意力模式观察的延迟KV淘汰以实现高效长链推理", "title_en": "LazyEviction: Lagged KV Eviction with Attention Pattern Observation for Efficient Long Reasoning", "authors": "Haoyue Zhang,Hualei Zhang,Xiaosong Ma,Jie Zhang,Song Guo", "background": "大规模语言模型（LLMs）通过链式推理展示了增强的能力。然而，延伸的推理序列增加了GPU内存的开销，主要由于增加的关键值（KV）缓存。现有的KV缓存压缩方法可以缓解内存瓶颈，但在长时间推理任务中效果不佳。在推理任务中分析注意力模式，揭示了‘Token Importance Recurrence’现象：许多令牌在多次解码步骤后重获高关注，但现有工作未能捕捉到这一现象，导致这些关键令牌的不公平淘汰。基于此，提出了一种名为LazyEviction的注意力模式观察为基础的延迟淘汰框架。", "innovation": "LazyEviction采用基于观察窗口的延迟淘汰框架，通过优先淘汰具有一定再出现模式的令牌，以保留潜在重出现的令牌。通过广泛的实验，证明了LazyEviction在减少KV缓存方面表现优异，同时保持了相当的准确度，并在现有KV缓存压缩基线中脱颖而出。", "conclusion": "实验表明，与现有的KV缓存压缩基线相比，LazyEviction能将KV缓存减少50%到70%，同时保持与现有方法相当的准确性，显著提升了长推理任务的效率。相关代码可以在此处找到。"}
{"llm_update_time": "20251015", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2507.07146", "html_url": "https://arxiv.org/abs/2507.07146", "title": "基于注意力感知的GNN输入防护策略对抗多轮LLM逃逸攻击", "title_en": "Attention-Aware GNN-based Input Defense against Multi-Turn LLM Jailbreak", "authors": "Zixuan Huang,Kecheng Huang,Lihao Yin,Bowei He,Huiling Zhen,Mingxuan Yuan,Zili Shao", "background": "大型语言模型（LLMs）在多种应用中取得了显著进步，但其功能同时也带来了构建性和恶意利用的风险。尽管进行了大量关于安全性的训练和调整工作，LLMs仍容易遭受'逃逸攻击'。近期，多轮攻击（不同于单轮攻击）的出现增加了这种脆弱性，这些攻击通过逐步提升对话的复杂性，使得检测和防御变得更加困难。", "innovation": "本文提出了G-Guard，一种基于图神经网络（GNN）且具有注意力感知的输入分类器，以防御针对LLMs的多轮逃逸攻击。G-Guard构建了一个多轮查询图，捕捉查询和多轮查询中危险关键词之间的关系。此外，提出了一种基于注意力的增强机制，根据当前的多轮对话检索最相关的单轮查询，将其作为一个标记节点加入到图中，以增强GNN分类当前查询为有害或无害的能力。", "conclusion": "实验结果表明，G-Guard在不同数据集和评估指标上均优于所有基准模型，证明了其作为对抗多轮逃逸攻击的稳健防护机制的有效性。"}
{"llm_update_time": "20251015", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2507.02659", "html_url": "https://arxiv.org/abs/2507.02659", "title": "OmniDraft: 在设备端跨词汇在线自适应草案模型用于推测性解码", "title_en": "OmniDraft: A Cross-vocabulary, Online Adaptive Drafter for On-device Speculative Decoding", "authors": "Ramchalam Kinattinkara Ramakrishnan,Zhaocong Yuan,Shaojie Zhuo,Chen Feng,Yicheng Lin,Chenzheng Su,Xiaopeng Zhang", "background": "目前推测性解码通常需要一个小型且高效的草稿模型，该模型可以预先训练或在线下训练至目标模型系列。但在在线部署环境中，有两个主要挑战：1）草稿模型与目标模型不兼容；2）期望通过减少延迟来提高性能。本研究旨在克服这些挑战，并提供一个统一的框架，使单一草稿模型能够与任何目标模型兼容，并且能够动态适应用户数据。研究表明，该框架特别适用于模型成本和效率是关键因素的设备端大语言模型应用。", "innovation": "OmniDraft框架中引入了在线n-gram缓存与混合蒸馏微调技术，以解决草稿模型和目标模型之间的跨词汇不匹配问题，并通过自适应草稿技术进一步提升解码速度。此外，OmniDraft还能够在不增加复杂性的情况下，实现单个模型与多个不同大小的目标模型的高效合作。", "conclusion": "OmniDraft展示了卓越的在线学习能力，能够在数学推理、编程和文本生成等任务中实现显著的性能提升。实验结果表明，一个大小为68M的Llama模型能与Vicuna-7B、Qwen2-7B和Llama3-8B等不同大小的目标模型进行推测性解码，并且提供最多2倍的加速效果。这一研究成果进一步突显了追求‘一个草稿模型兼容所有’的理念。"}
{"llm_update_time": "20251015", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.20353", "html_url": "https://arxiv.org/abs/2508.20353", "title": "DFAMS: 动态流指导的联邦对齐基于多原型搜索", "title_en": "DFAMS: Dynamic-flow guided Federated Alignment based Multi-prototype Search", "authors": "Zhibang Yang,Xinke Jiang,Rihong Qiu,Ruiqing Li,Yihang Zhang,Yue Fang,Yongxin Xu,Hongxin Ding,Xu Chu,Junfeng Zhao,Yasha Wang", "background": "联邦检索（FR）通过跨多个外部知识源路由查询，以减轻LLMs的幻觉，特别是在必要时外部知识分散的情况下。但是，现有的方法在处理具有歧义性的查询时，难以检索高质量且相关性强的文档，特别是在跨领域场景中。这极大地限制了它们在支持下游生成任务中的效果。", "innovation": "本文受到动态信息流（DIF）的启发，提出了一种新型框架DFAMS，利用DIF来识别潜在的查询意图并构建语义对齐的知识划分，以实现跨异构源的精确检索。DFAMS通过利用带有标注查询的梯度信号和Shapley值归因，探测LLMs中的DIF，并借用DIF来训练一种对齐模块，通过多原型对比学习来实现源内精细建模和知识库间的语义对齐。", "conclusion": "跨五个基准的实验结果显示，DFAMS在知识分类准确性、检索召回率和下游问答准确性上分别比先进的FR方法高14.37%、5.38%和6.45%。这验证了其在复杂联邦检索场景中的有效性。代码在指定链接处匿名提供。"}
{"llm_update_time": "20251015", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2509.15380", "html_url": "https://arxiv.org/abs/2509.15380", "title": "伊斯兰文本多语言信息检索的有效和多功能模型：在实际应用场景中的开发与部署", "title_en": "Efficient and Versatile Model for Multilingual Information Retrieval of Islamic Text: Development and Deployment in Real-World Scenarios", "authors": "Vera Pavlova,Mohammed Makhlouf", "background": "尽管近年来多语言信息检索（MLIR）取得了进展，但其研究与实际部署之间仍存在显著差距。许多研究仅在孤立环境中评估MLIR性能，限制了其在实际情景中的应用。为了弥合这一差距，本文利用古兰经多语言语料库的独特特性，研究开发适用于伊斯兰领域的高效短查询检索系统的方法，以满足用户多语言信息需求。", "innovation": "本文开发了包含11个检索模型的方案，采用四种训练方法：单语言、跨语言、全翻译训练以及一种结合了跨语言和单语言技术的新型混合方法。实验结果显示，混合方法在多种检索场景下取得了令人满意的结果。此外，详细分析了不同训练配置对嵌入空间的影响及其对多语言检索效果的含义。", "conclusion": "最后讨论了部署考量，强调部署一个通用、轻量的单模型的成本效益，适用于实际的多语言信息检索应用。"}
{"llm_update_time": "20251015", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2506.16552", "html_url": "https://arxiv.org/abs/2506.16552", "title": "Revela: 通过语言建模进行密集检索器学习", "title_en": "Revela: Dense Retriever Learning via Language Modeling", "authors": "Fengyu Cai,Tong Chen,Xinran Zhao,Sihao Chen,Hongming Zhang,Sherry Tongshuang Wu,Iryna Gurevych,Heinz Koeppl", "background": "密集检索器在通过外部和专业化的知识增强语言模型(AI)方面扮演着至关重要的角色。然而，典型的密集检索器训练需要带有注释的查询文档对，这些对在专业化领域（例如代码）或复杂环境（例如需要推理的情况）中往往是稀缺且成本高昂的。这些实际挑战激发了对自我监督检索器学习的兴趣。鉴于语言模型是通过自我监督学习目标（如下一个标记预测）训练来捕捉令牌级别的依赖关系，将检索问题类比为学习令牌组间的依赖关系是自然的。这项类比带来了问题：我们可以如何将自我监督学习目标和语言建模的精神应用于检索器的训练？", "innovation": "提出了Revela，这是一个统一且可扩展的自我监督检索器学习框架，通过语言模型接口训练检索器。Revela 通过队内注意力机制并结合检索器计算出的相似性评分来预测下个令牌，从而建模文档间的语义依赖关系。这种方法将模型构建成一个包含检索器的缩放模型，使其能够优化自我监督学习过程中的检索任务。实验证明，Revela 在特定领域（CoIR）、推理密集型（BRIGHT）和通用领域（BEIR）的基准测试中表现优异，特别是在 CoIR 和 BRIGHT 上超越了大型监督学习模型和专有 API，在 BEIR 上实现了无监督的状态最先进技术（SoTA），同时仅使用了极少量的训练数据和计算资源。性能随批次大小和模型大小的增加而提高，突显了Revela 的可扩展性和自我监督检索器学习的潜力.", "conclusion": "Revela为自我监督检索器学习提供了一种新的方法论和实现方案。其不仅在多种基准测试中表现出色，同时还能在有限的资源条件下取得最优表现，展示了其在处理复杂和专业领域信息检索任务中的潜力和优势。"}
{"llm_update_time": "20251015", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2507.04295", "html_url": "https://arxiv.org/abs/2507.04295", "title": "LearnLens：启用大语言模型的个性化、课程导向反馈制度，教师参于其中", "title_en": "LearnLens: LLM-Enabled Personalised, Curriculum-Grounded Feedback with Educators in the Loop", "authors": "Runcong Zhao,Artem Bobrov,Jiazheng Li,Cesare Aloisi,Yulan He", "background": "有效的反馈对于学生学习至关重要，但对教师而言却是劳动密集型的工作。现有的反馈生成系统面临一些挑战，如反馈的可扩展性、质量不足以及缺乏教师和学生之间的互动。因此，需要一种能够提供个性化、课程导向且教师可参与的反馈系统，以支持教育工作者和学生的需求和期望。", "innovation": "LearnLens 是一种模块化的大语言模型 (LLM) 系统，它通过三种主要组件提供个性化的、与课程对齐的反馈：(1) 错误感知评估模块，可以捕捉复杂的推理错误；(2) 以课程为基础的生成模块，使用结构化、主题链接的记忆链进行信息检索，提高相关性和减少噪音；(3) 教师在环中的接口，以便进行定制和监督。LearnLens 解决了现有系统的几个关键挑战，提供了可扩展的高质量反馈，从而赋能教师和学生。", "conclusion": "LearnLens 通过提供个性化、课程导向的反馈，能够在保持高质量的同时减轻教师的负担。通过将教师纳入反馈过程中的闭环，进一步提升了教育体验并促进了师生之间的有效沟通。"}
{"llm_update_time": "20251015", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2509.16548", "html_url": "https://arxiv.org/abs/2509.16548", "title": "SCAN: 自去噪蒙特卡洛标注法以实现稳健的过程奖励学习", "title_en": "SCAN: Self-Denoising Monte Carlo Annotation for Robust Process Reward Learning", "authors": "Yuyang Ding,Xinyu Shi,Juntao Li,Xiaobo Liang,Zhaopeng Tu,Min Zhang", "background": "过程奖励模型（PRMs）为大规模语言模型（LLMs）提供精细的、步骤级别的评估，有助于更深入的推理过程，并在复杂任务如数学推理中表现出色。然而，开发PRMs具有挑战性，因为高质量的人标注数据成本高且难以大量采集。蒙特卡洛（MC）估算生成的合成数据是一种有前景的替代方案，但由于噪声比例高，导致过拟合并影响大规模训练效果。", "innovation": "提出了一种名为Self-Denoising Monte Carlo Annotation (SCAN) 的框架，这是一种高效的数据合成和噪声容忍学习框架。关键发现表明：即使轻量级模型（如参数量1.5B）也能通过自去噪策略生成高质量的标注，大大降低推理成本。通过这一稳健的训练策略，PRMs可以从这种弱监督中学习，使ProcessBench任务的F1分数提高了39.2%。即使使用较小的合成数据集，模型也超越了基于大规模人工标注数据的基准模型，性能随合成数据量增加而持续提升。", "conclusion": "尽管使用了仅一个小规模合成数据集，但SCAN框架在ProcessBench任务中展现出了优越性能，并且随着合成数据量的增加，表现持续提升，显示了SCAN对于可扩展、低成本和稳健的PRM训练的巨大潜力。"}
{"llm_update_time": "20251015", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.03269", "html_url": "https://arxiv.org/abs/2510.03269", "title": "在RLHF中的通用探索奖励用于乐观探索", "title_en": "General Exploratory Bonus for Optimistic Exploration in RLHF", "authors": "Wendi Li,Changdae Oh,Sharon Li", "background": "在使用人类反馈的强化学习中，乐观探索对于提高样本效率至关重要。然而，现有的激励探索的方法往往无法实现乐观性，即它们倾向于鼓励探索高概率区域，而非探索不确定性较大的区域，从而导致保守行为而不是发现新的不确定区域。", "innovation": "本文提出了通用探索奖励（GEB），这是一种新的理论框架，能够确保满足乐观性的原则。GEB通过参考依赖的奖励调节来抵消偏差，并将先前的启发式奖励作为其特殊情况，自然地应用于α散度家族的整个范围内。实验结果表明，GEB在多中散度设置和大型语言模型背景下的一致性上显著优于基线方法，示范了它既是一个原理上的又有实际意义的乐观探索解决方案。", "conclusion": "GEB提供了一个理论和实践上都能有效促进乐观探索的解决方案，在使用人类反馈的强化学习中具有显著优势。"}
{"llm_update_time": "20251015", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2509.23564", "html_url": "https://arxiv.org/abs/2509.23564", "title": "Clean First, Align Later: Benchmarking Preference Data Cleaning for Reliable LLM Alignment", "title_en": "Clean First, Align Later: Benchmarking Preference Data Cleaning for Reliable LLM Alignment", "authors": "Samuel Yeh,Sharon Li", "background": "人类反馈对将大型语言模型（LLMs）与人类偏好对齐具有重要作用。然而，这种反馈往往存在噪音或不一致，这会影响奖励模型的质量并妨碍对齐。尽管已经提出了各种自动数据清洁方法来缓解这个问题，但对其有效性和泛化能力的系统评估仍然缺失。为了解决这个问题，引入了第一个全面基准，用于评估13种偏好数据清洁方法在LLM对齐中的效果。该基准提供了一个标准化协议，以评估清洁策略在不同数据集、模型架构和优化算法中的对接性能和泛化能力。通过统一不同的方法并严格比较它们，揭示了决定数据清洁在对齐任务中成功的关键因素。该基准为提高LLM对齐的有根据和可重复的方法奠定了基础，突出了数据预处理在负责任的人工智能开发中的重要作用。", "innovation": "提出第一个全面基准PrefCleanBench，用于评估偏好数据清洁方法在LLM对齐中的效果。统一不同方法并严格比较它们，揭示关键因素。标准化协议评估对接性能和泛化能力。提供模块化实现以促进进一步研究。", "conclusion": "该基准为通过提高数据质量来改进LLM对齐奠定了基础，突显了数据预处理在负责任的人工智能开发中的关键但未被充分利用的作用。进一步研究将催化更深入的探索。"}
{"llm_update_time": "20251015", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2509.17238", "html_url": "https://arxiv.org/abs/2509.17238", "title": "MoEs Are Stronger than You Think: Hyper-Parallel Inference Scaling with RoE", "title_en": "MoEs Are Stronger than You Think: Hyper-Parallel Inference Scaling with RoE", "authors": "Soheil Zibakhsh,Mohammad Samragh,Kumari Nishu,Lauren Hannah,Arnav Kundu,Minsik Cho", "background": "大型语言模型（LLMs）的生成质量经常通过在推理时使用序列级缩放方法（如Chain-of-Thought）来提升。引入了一个名为超并行缩放的框架，它可以在标记级别提高预测质量。超并行缩放计算并聚合单个标记的模型的多个输出提案。这项技术在Mixture-of-Experts（MoE）模型中得到了实现，称为Roster of Experts（RoE）。RoE是一个无需训练的推理算法，能够将一个MoE模型转换为一个动态的MoE模型集合。RoE通过将专家路由机制中的随机性控制在一个范围内，使其能够在为每个标记选择多个专家并聚合它们的输出来提高最终预测的准确性。为克服计算成本，还引入了一种高效的批处理策略和一个专门的KV缓存机制，以最小化计算和内存开销。例如，RoE使得一个7B的MoE模型能够匹配10.5B的MoE模型的性能，而在推理时使用了仅30%的计算量。这一改进在不调整模型参数的情况下实现了性能提升。", "innovation": "提出了一个称为超并行缩放（hyper-parallel scaling）的框架，它可以在标记级别提高预测质量。这一方法通过在模型中计算并聚合单个标记的多个输出提案来实现。在Mixture-of-Experts（MoE）模型中实现了这一概念，称为Roster of Experts（RoE），并通过一种无需训练的推理算法将其转换为动态的MoE模型集合。RoE引入了专家路由机制中的控制随机性，使得能够为每个标记选择多个多样性的专家并聚合它们的输出，从而更为准确地预测结果。为降低计算成本和内存消耗，RoE引入了一种高效的批处理策略和专门的KV缓存机制。这种方法使得一个7B规模的MoE模型能够媲美10.5B规模时的性能，而计算量减少30%。", "conclusion": "RoE通过一种无需训练的推理算法，能够显著提升Mixture-of-Experts（MoE）模型的性能，并且能够大幅减少推理时所需的计算资源，同时在不调整模型参数的情况下实现了这一目标。"}
{"llm_update_time": "20251015", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.11817", "html_url": "https://arxiv.org/abs/2510.11817", "title": "使用JAXA的正隆影像提高3D月球地图的质量", "title_en": "Enhancing the Quality of 3D Lunar Maps Using JAXA's Kaguya Imagery", "authors": "Yumi Iwashita,Haakon Moe,Yang Cheng,Adnan Ansar,Georgios Georgakis,Adrian Stoica,Kazuto Nakashima,Ryo Kurazume,Jim Torresen", "background": "随着全球对月球探索的不断增强，生成高精度3D月球地图的需求变得日益关键，特别是在像NASA的Endurance任务这样需要远距离行驶（2000公里穿越南部盆地-阿廷盆地）的长途任务中。虽然Kaguya TC的地形相机图像在全球范围内可用且分辨率高达10米/像素，但由于立体匹配误差和基于JPEG的压缩伪影，这些图像存在高度准确性问题。因此，本研究旨在通过减少来自压缩图像的视差图中的残留噪声来提高3D地图质量，从而改进高度数据，提高未来月球任务的安全性和可靠性。", "innovation": "本文提出了一种方法，通过对Kaguya TC图像进行分析并识别伴随压缩图像而来的系统性视差噪声模式，特别是暗区中的噪声模式，通过减少视差图中残留噪声来增强3D地图质量，进而有效地减轻由压缩引起的高度噪声，这对于确保未来月球任务的安全性和可靠性至关重要。", "conclusion": "我们实验结果表明，所提出的方法可有效减少高度噪声，从而提高地形数据的安全性和可靠性，为未来的月球任务提供了更高质量的3D地图。"}
{"llm_update_time": "20251015", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.11683", "html_url": "https://arxiv.org/abs/2510.11683", "title": "边界指导策略优化：用于扩散大型语言模型的高效记忆强化学习", "title_en": "Boundary-Guided Policy Optimization for Memory-efficient RL of Diffusion Large Language Models", "authors": "Nianyi Lin,Jiajie Zhang,Lei Hou,Juanzi Li", "background": "在将强化学习（RL）应用于扩散大型语言模型（dLLMs）时，面临着其似然函数难以处理的问题，而这些似然函数是RL目标的关键部分。现有方法通过自定义蒙特卡洛（MC）采样来近似对数似然，但由于非线性项的梯度计算需要保留所有MC样本的前向计算图，这导致了显存开销过大。这限制了可取样的样本规模，使得似然的近似不够准确，导致RL目标失真。", "innovation": "提出了一种名为边界指导策略优化（BGPO）的记忆高效RL算法，它通过最大化基于ELBO目标的一个特制的下界来优化策略。这个下界被精心设计，满足两个关键性质：线性性（每个项依赖单一MC样本，支持样本间梯度积累，确保内存使用量恒定）和等价性（其值和梯度与ELBO目标相等，提供了一个有效的RL目标近似），使得BGPO能够采用大量的MC样本，从而提高了似然近似和RL目标估计的准确性，提升了性能。", "conclusion": "实验表明，BGPO在解决数学问题、代码生成和规划任务等方面显著优于dLLMs的先前RL算法。我们的代码和模型可以在指定的链接处获取。"}
{"llm_update_time": "20251015", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.10815", "html_url": "https://arxiv.org/abs/2510.10815", "title": "DRIFT：分解、检索、举例然后形式化定理", "title_en": "DRIFT: Decompose, Retrieve, Illustrate, then Formalize Theorems", "authors": "Meiru Zhang,Philipp Borchert,Milan Gritta,Gerasimos Lampouras", "background": "大型语言模型（LLMs）在自动化数学命题形式化方面仍然面临重大挑战。当前的检索增强自形式化方法直接使用非正式的命题查询外部库，但忽视了一个根本问题：非正式的数学命题往往复杂且对基础数学概念的背景信息描述有限。这导致模型在理解底层数学概念和找到合适的前提条件时遇到困难。", "innovation": "该研究引入了DRIFT（分解、检索、举例然后形式化定理）框架，使LLMs能够将非正式的数学命题分解为更小、更易处理的“子组件”。这有助于更精准地从如Mathlib这样的数学库中检索前提条件，并且DRIFT能够检索示例定理来帮助模型更有效地进行形式化任务。实验结果显示，DRIFT在多种基准测试（ProofNet、ConNF和MiniF2F-test）中一致提升前提条件的检索效果，与DPR基线相比，ProofNet基准上的F1分数几乎翻倍。特别是在分布外的ConNF基准上，使用GPT-4.1和DeepSeek-V3.1，DRIFT分别实现了BEq+@10上的37.14%和42.25%的提升。", "conclusion": "研究表明，数学自动化形式化的检索有效性高度依赖于模型的知识边界，这强调了需要为每个模型的能力对检索策略进行适应性调整的需求。"}
{"llm_update_time": "20251015", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.09011", "html_url": "https://arxiv.org/abs/2510.09011", "title": "TripScore: 细致评估促进真实旅行计划的基准和奖励", "title_en": "TripScore: Benchmarking and rewarding real-world travel planning with fine-grained evaluation", "authors": "Yincen Qu,Huan Xiao,Feng Li,Gregory Li,Hui Zhou,Xiangying Dai", "background": "旅行规划是一项有价值的但又复杂的任务，即使对于先进的大型语言模型（LLMs）来说也存在显著的挑战。尽管近期的基准测试在评估LLMs的规划能力方面取得了进展，但它们往往未能全面评估旅行计划的可行性、可靠性和用户的参与度。因此，需要一个综合性的基准来统一细粒度的标准，以直接比较计划质量并无缝集成强化学习（RL）。论文提供了包含4,870个查询的大型数据集，其中包含了219个实际的自由形式请求，以便测试模型对实际用户意图的泛化能力。通过对多种方法和LLMs进行广泛的实验，包括RL通过GRPO，实验结果表明在基础模型上使用RL通常能提高行程的可行性。", "innovation": "论文引入了一个全面的旅行计划基准，整合了细粒度的标准到单一奖励中，使可以直接比较计划质量并将该评估无缝集成到强化学习中。构建的评估器与旅游专家的注释有60.75%的一致性，且优于多种LLM作评判的基础线。此外，论文发布了包含4,870个查询和219个实际自由形式请求的大规模数据集，以测试模型对真实用户意图的泛化能力。", "conclusion": "在整个系列实验中，各方法显现不同的表现，但在所有基线模型中，使用RL通常能够显著提升行程的可行性，并获得更优的综合得分。这表明RL在提高新颖的和具体的旅行计划可行性方面非常有效。"}
{"llm_update_time": "20251015", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.08558", "html_url": "https://arxiv.org/abs/2510.08558", "title": "通过早期经验学习的智能体", "title_en": "Agent Learning via Early Experience", "authors": "Kai Zhang,Xiangchao Chen,Bo Liu,Tianci Xue,Zeyi Liao,Zhihan Liu,Xiyao Wang,Yuting Ning,Zhaorun Chen,Xiaohan Fu,Jian Xie,Yuxuan Sun,Boyu Gou,Qi Qi,Zihang Meng,Jianwei Yang,Ning Zhang,Xian Li,Ashish Shah,Dat Huynh,Hengduo Li,Zi Yang,Sara Cao,Lawrence Jang,Shuyan Zhou,Jiacheng Zhu,Huan Sun,Jason Weston,Yu Su,Yifan Wu", "background": "长期目标是让语言代理通过自身的经验学习并提高，最终在复杂的实际任务中超越人类。然而，使用强化学习从经验数据训练代理在许多环境中仍然是困难的，环境或者缺乏可验证奖励（例如：网站），或者要求进行低效的长时间序列滚动（例如：多轮工具使用）。因此，大多数目前的代理依赖于在专家数据上的监督微调，这种方法难以扩展，并且泛化能力较差。这一局限性源于专家演示的特点：它们只能捕捉到有限范围的场景，并且将代理暴露在有限的环境多样性中。我们通过一个名为早期经验的中间方案解决了这一局限：由代理自身行为产生的交互数据，未来状态在此条件下作为监督信息，而无需奖励信号。", "innovation": "我们提出了一个名为早期经验的中间方案，即让代理通过自身行为产生的交互数据与环境互动，这些未来的状态作为监督信息，而不依赖于奖励信号。我们研究了两种策略来利用此类数据：（1）隐式世界建模，通过收集的状态来概述政策与环境动力学的关系；（2）自我反省，使代理从其次优行为中学习，以提高推理和决策能力。研究涉及八个不同的环境和多种模型家族，我们的方法能够在所有环境中提高效率和跨域泛化能力，表明早期经验的宝贵价值。此外，我们在具有可验证奖励的环境中发现，早期经验为后续的强化学习提供了强大的基础，将其定位为模仿学习与完全基于经验的智能体之间的实用桥梁。", "conclusion": "我们的方法在八个不同的环境中和多种模型家族中的表现一致地改进了效果和跨域泛化能力，突显了早期经验的价值。在具有可验证奖励的环境中，我们的研究结果表明，早期经验为后续的强化学习提供了强大的基础，将其定位为模仿学习与完全基于经验的智能体之间的实用桥梁。"}
{"llm_update_time": "20251015", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.11835", "html_url": "https://arxiv.org/abs/2510.11835", "title": "数据还是语言监督：是什么让CLIP比DINO更好？", "title_en": "Data or Language Supervision: What Makes CLIP Better than DINO?", "authors": "Yiming Liu,Yuhui Zhang,Dhruba Ghosh,Ludwig Schmidt,Serena Yeung-Levy", "background": "CLIP在视觉语言模型中的表现优于如DINO等自监督模型，但这种优势是否源于CLIP的语言监督还是其更大的训练数据仍不清楚。为了区分这些因素，研究在控制条件下对CLIP和DINO进行预训练，使用相同的架构、数据集和训练配置，达到类似的ImageNet准确性。", "innovation": "通过在控制条件下对CLIP和DINO进行预训练，使用相同的架构、数据集和训练配置，研究揭示了两种模型在高层语义（如物体类别、文本）和低级特征（如颜色、样式）上的不同表现。", "conclusion": "CLIP在文本密集型任务中表现出色，而DINO在视觉中心型任务中略微更优。不同形式的语言监督（如Sigmoid损失、预训练的语言编码器）带来的增益有限。该研究为视觉编码器设计及其对视觉语言模型性能影响提供了科学见解。"}
{"llm_update_time": "20251015", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.11907", "html_url": "https://arxiv.org/abs/2510.11907", "title": "针对综合道路交通安全视频描述和分析的任务特定双模型框架", "title_en": "Task-Specific Dual-Model Framework for Comprehensive Traffic Safety Video Description and Analysis", "authors": "Blessing Agyei Kyem,Neema Jakisa Owor,Andrews Danyo,Joshua Kofi Asamoah,Eugene Denteh,Tanner Muturi,Anthony Dontoh,Yaw Adu-Gyamfi,Armstrong Aboah", "background": "道路交通安全分析需要复杂的视频理解来捕捉细微的行为模式，并生成全面的描述以预防事故。现有方法在这种复杂情境下的效能仍有限，因此需要更专门的模型框架来优化这种理解过程。", "innovation": "本文提出了一种独特的双模型框架，通过特定任务优化VideoLLaMA和Qwen2.5-VL，使它们在视频字幕生成和视觉问答任务上互补，并减少任务干扰，使得每个模型都能更专注于特定任务。实验结果表明，VideoLLaMA在时间推理方面表现出色，VQA准确率为60.80%，而Qwen2.5-VL在视觉理解方面表现出色，CIDEr得分为1.1001。该方法在2025 AI City Challenge Track 2中获得了45.7572的S2得分，排名第十。实验证明，单独训练策略相比联合训练在VQA准确率上提高了8.6%的同时，保持了字幕的质量。", "conclusion": "该方法在道路交通安全视频描述和分析上表现出色，通过优化不同模型的功能，提高了对细微行为模式的理解和描述的准确性，展示了其在复杂视频理解任务中的优势，并在AI城市挑战赛中取得了显著的成果。"}
{"llm_update_time": "20251015", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.12075", "html_url": "https://arxiv.org/abs/2510.12075", "title": "关于领域适应和生成对抗网络（GANs）的综述", "title_en": "A Review on Domain Adaption and Generative Adversarial Networks(GANs)", "authors": "Aashish Dhawan,Divyanshu Mudgal", "background": "当今计算机视觉领域的关键挑战是高质量标注数据的获取不足。在图像分类研究领域，由于数据至关重要，因而需要找到更可靠的方法来克服数据稀缺问题，以达到或超过先前基准的结果。获取标注数据往往成本高昂或在某些情况下根本无法完成。本研究旨在讨论领域适应及其各种实施方法", "innovation": "文章的主要创新在于探讨使用已在一个特定数据集上训练的模型在不同领域进行预测的方法，比如用一个训练于飞机绘画的数据模型在真实飞机图像上进行预测，以此应对标注数据稀缺的问题。领域适应方法的研究为计算机视觉提供了新的可能性和解决方案", "conclusion": "文章总结了领域适应的概念、各种实施方法以及生成对抗网络（GANs）在该领域的应用，强调了其在降低数据获取成本和提高模型泛化能力方面的潜力。"}
{"llm_update_time": "20251015", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.12069", "html_url": "https://arxiv.org/abs/2510.12069", "title": "VIDMP3：通过姿态和位置先验表示运动的视频编辑", "title_en": "VIDMP3: Video Editing by Representing Motion with Pose and Position Priors", "authors": "Sandeep Mishra,Oindrila Saha,Alan C. Bovik", "background": "在需要灵活调整结构和语义的场景中，保留动作的视频编辑对创作者至关重要。尽管这种编辑方法具有潜力，但是现有研究对此领域探索不足。传统的基于扩散的方法在结构保持任务上表现出色，通过密集的引导信号确保内容的完整性。然而，部分最新的方法在处理结构可变编辑时经常遇到时间一致性差、主体身份漂移以及需要人工干预等问题。", "innovation": "为了应对这些挑战，作者提出了VidMP3，这是一种新颖的方法，利用姿态和位置先验来从源视频中学习泛化的运动表示。该方法能够生成同时保持原始动作和允许结构和语义灵活调整的新视频。定量和定性的评估结果表明，该方法在现有方法中表现更优。", "conclusion": "我们的方法在定性和定量的测试中都显示出了优越性。未来的工作将发布对应的代码，以便研究者进一步探索和改进这种新的视频编辑方式。"}
{"llm_update_time": "20251015", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.11992", "html_url": "https://arxiv.org/abs/2510.11992", "title": "PanoTPS-Net：基于薄板样条变换的全景房间布局估计", "title_en": "PanoTPS-Net: Panoramic Room Layout Estimation via Thin Plate Spline Transformation", "authors": "Hatem Ibrahem,Ahmed Salem,Qinmin Vivian Hu,Guanghui Wang", "background": "准确估计房间的3D布局在计算机视觉中是一个重要的任务，具有在机器人技术、增强现实和室内设计等领域的潜在应用。现有的方法大多需要多张图像或人工标注才能进行精确的房间布局估计，这限制了其在实际场景中的应用。为了解决这些问题，本文提出了一种名为PanoTPS-Net的新型模型，能够从单张全景图中估计房间布局。PanoTPS-Net结合了卷积神经网络（CNN）和薄板样条（TPS）空域变换，通过两阶段的架构，首先从输入图像中提取高级特征，然后生成TPS空域变换层，将参考布局变换为所需的布局。这种方法能够有效地预测房间布局，并很好地泛化到立方体和非立方体布局。", "innovation": "PanoTPS-Net模型的独特之处在于它结合了CNN和TPS技术，能够有效提取和利用全景图像中的高级特征来预测房间布局，并通过TPS变换将参考布局变形为所需的布局。此外，PanoTPS-Net能够适用于不同形状的房间布局估计，表现出了良好的鲁棒性，在不同数据集上的3DIoU值达到了85.49、86.16、81.76和91.98。该方法的创新性在于其能够从单张全景图像中准确估计房间布局，同时适用于各种形状的房间，并且在不同数据集上的表现优异，超越了现有方法的精度。", "conclusion": "本文提出的PanoTPS-Net模型，通过结合CNN和TPS技术，能够有效地从单张全景图中估计房间布局，并适用于不同形状的房间布局估计。实验结果表明，PanoTPS-Net在多个公开数据集上的精度表现优于现有方法，验证了该方法的有效性和鲁棒性。该模型为基于单张全景图的房间布局估计提供了一种新的解决方案，具有潜在的应用价值。"}
{"llm_update_time": "20251015", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.11996", "html_url": "https://arxiv.org/abs/2510.11996", "title": "使用RGB-D变换器引导提示的空间理解：细粒度对象关系推理", "title_en": "Prompt-Guided Spatial Understanding with RGB-D Transformers for Fine-Grained Object Relation Reasoning", "authors": "Tanner Muturi,Blessing Agyei Kyem,Joshua Kofi Asamoah,Neema Jakisa Owor,Richard Dyzinela,Andrews Danyo,Yaw Adu-Gyamfi,Armstrong Aboah", "background": "在大型3D环境（如仓库）中的空间推理仍然是视觉-语言系统的重大挑战，由于场景杂乱、遮挡和精确的空间理解需求。现有模型在这些设置中普遍难以泛化，因为它们高度依赖局部外观且缺乏显式的空间定位。对于物理AI空间智能仓库数据集，本文提出了一种专用的空间推理框架。该方法通过直接将掩码维度嵌入成边界框坐标，嵌入到输入提示中，增强空间理解能力，使模型能够进行物体几何形状和布局的推理。", "innovation": "本文提出了一种专用的空间推理框架，用于Physical AI Spatial Intelligence Warehouse数据集。该框架通过直接将掩码维度嵌入成边界框坐标，嵌入到输入提示中，增强空间理解能力，使模型能够进行物体几何形状和布局的推理。在四个问题类别（距离估计、物体计数、多选题定位和空间关系推理）上进行了细粒度的任务监督微调，并在训练集中将标准化答案附加到GPT响应，以进一步提高与评估系统的一致性。", "conclusion": "本文提出的空间推理框架，在公共排行榜上取得了73.0606的综合得分，排名第4。这些结果表明，在真实工业环境中推进空间推理的有效性取决于结构化提示丰富和目标优化。"}
{"llm_update_time": "20251015", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.12056", "html_url": "https://arxiv.org/abs/2510.12056", "title": "APGNet: 自适应先验引导的水下伪装目标检测", "title_en": "APGNet: Adaptive Prior-Guided for Underwater Camouflaged Object Detection", "authors": "Xinxin Huang,Han Sun,Junmin Cai,Ningzhong Liu,Huiyu Zhou", "background": "水下环境中的伪装物体检测对于海洋生态研究和资源勘探至关重要，但现有方法面临两大挑战：水下图像退化（低对比度和色彩失真）和海洋生物的自然伪装。传统的图像增强技术难以恢复退化图像中的关键特征，而专为陆地场景设计的伪装物体检测（COD）方法因未考虑水下光学特性，往往无法适应水下环境。", "innovation": "本文提出了自适应先验引导网络（APGNet），这是一种结合了Siamese架构和新颖先验引导机制的网络。首先，采用Multi-Scale Retinex with Color Restoration（MSRCR）算法进行数据增强，生成光照不变的图像以减轻退化效应。其次，设计了扩展感受野（ERF）模块结合多尺度逐步解码器（MPD）以捕捉多尺度上下文信息和细化特征表示。此外，提出了一个自适应先验引导机制，通过在高层特征中嵌入空间注意力实现粗定位，并使用可变形卷积在低层特征中细化轮廓。", "conclusion": "在两个公开MAS数据集上进行的广泛实验表明，本文提出的方法APGNet在广泛使用的评估指标下优于15种最先进的方法。"}
{"llm_update_time": "20251015", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.12089", "html_url": "https://arxiv.org/abs/2510.12089", "title": "Playmate2：基于奖励反馈的扩散变压器无训练多角色音频驱动动画", "title_en": "Playmate2: Training-Free Multi-Character Audio-Driven Animation via Diffusion Transformer with Reward Feedback", "authors": "Xingpei Ma,Shenneng Huang,Jiaran Cai,Yuansheng Guan,Shen Zheng,Hanfeng Zhao,Qiang Zhang,Shunsi Zhang", "background": "近年来，扩散模型在基于音频的人类视频生成方面取得了显著进展，超越了传统方法在质量和可控性方面的表现。然而，现有方法在唇同步精度、长视频生成的时间连贯性以及多角色动画方面仍然面临挑战。", "innovation": "本文提出了一种基于扩散变压器（DiT）的框架，用于生成任意长度的逼真对话视频，并提出了一种无训练的方法来实现多角色音频驱动动画。首先，采用基于LoRA的训练策略结合位置偏移推理方法，能够在保持基础模型能力的同时，实现高效长视频生成。此外，结合部分参数更新和奖励反馈，提高了唇同步和自然身体运动的效果。最后，提出了一种无训练方法，Mask Classifier-Free Guidance (Mask-CFG)，用于多角色动画，无需专门的数据集或模型修改，支持三种或更多角色的音频驱动动画。", "conclusion": "实验结果表明，本方法优于现有最先进的方法，能够实现高质量、时间连贯和多角色音频驱动视频生成，在简单、高效且成本效益高的方面表现出色。"}
{"llm_update_time": "20251015", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.12095", "html_url": "https://arxiv.org/abs/2510.12095", "title": "IL3D：LLM驱动的3D场景生成的大规模室内布局数据集", "title_en": "IL3D: A Large-Scale Indoor Layout Dataset for LLM-Driven 3D Scene Generation", "authors": "Wenxu Zhou,Kaixuan Nie,Hang Du,Dong Yin,Wei Huang,Siqiang Guo,Xiaobo Zhang,Pengbo Hu", "background": "当前，室内布局设计需要大量多样且高质量的训练数据，但此类数据的缺乏限制了大型语言模型（LLM）在相关场景生成任务中的应用效果。", "innovation": "IL3D是一个大规模的数据集，专为LLM驱动的3D场景生成设计，包含27,816个室内布局和29,215个高保真3D物体资产，每个实例都有自然语言标注，支持多模态学习。IL3D建立了严格的基准测试，结果显示在IL3D上进行监督微调（SFT）的LLM在泛化能力方面优于其他数据集上的SFT。IL3D还提供了灵活的多模态数据导出功能，支持多种视觉任务的应用。", "conclusion": "IL3D显著推动了3D场景生成和环境感知任务研究，通过提供高保真场景数据来支持具身智能体的环境感知任务。"}
{"llm_update_time": "20251015", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.12021", "html_url": "https://arxiv.org/abs/2510.12021", "title": "评估视觉变换器在医学成像中的可解释性", "title_en": "Evaluating the Explainability of Vision Transformers in Medical Imaging", "authors": "Leili Barekatain,Ben Glocker", "background": "在医学成像领域，理解模型决策至关重要，因为可解释性直接影响临床信任和应用。尽管视觉变换器（ViTs）在诊断成像方面表现出最先进的性能，但它们复杂的注意力机制给可解释性带来了挑战。为了应对这一挑战，本研究使用 Gradient Attention Rollout 和 Grad-CAM 评估了不同 ViT 架构和预训练策略（ViT、DeiT、DINO 和 Swin Transformer）的可解释性。研究在两种医学成像任务（外周血细胞分类和乳腺超声图像分类）上进行了定量和定性的分析，目的是找到最有解释性的方法，以提高模型的透明度并在临床诊断工作中可靠地集成 ViTs.", "innovation": "本研究通过使用 Gradient Attention Rollout 和 Grad-CAM 方法评估了不同 ViT 架构和预训练策略的可解释性。结果显示，结合使用 Grad-CAM 的 DINO 在多个数据集上提供了最忠实且局部化的解释。Grad-CAM 稳定地生成了类区分性和空间精确的热图，而 Gradient Attention Rollout 得到更散的激活。甚至在分类错误的情况下，DINO 能够突出显示可能误导模型的临床相关形态学特征。这些发现支持了通过提高模型透明度将 ViTs 可信且可解释地集成到关键的医学诊断工作流中的方法。", "conclusion": "本研究通过采用 Gradient Attention Rollout 和 Grad-CAM 方法评估了不同 ViT 架构和预训练策略（ViT、DeiT、DINO 和 Swin Transformer）的可解释性，发现 DINO 结合 Grad-CAM 提供了最忠实且局部化的解释。这些结果支持了在医学诊断工作流中提高 ViTs 的透明度和解释性以增强临床信任的做法。"}
{"llm_update_time": "20251015", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.11883", "html_url": "https://arxiv.org/abs/2510.11883", "title": "MammoDINO：关注解剖的自我监督学习用于乳房影像", "title_en": "MammoDINO: Anatomically Aware Self-Supervision for Mammographic Images", "authors": "Sicheng Zhou,Lei Wu,Cao Xiao,Parminder Bhatia,Taha Kass-Hout", "background": "自我监督学习(SSL)已经广泛应用于一般领域的视觉编码器训练，但在医学影像领域尚未得到充分应用，主要由于数据量有限以及领域特定的偏差。", "innovation": "提出了一种名为MammoDINO的新型SSL框架，该框架在140万张乳房影像图像上进行了预训练。引入了一种乳腺组织意识的数据增强采样器，用于图像级别和切片级别的监督，并结合了3D数字乳腺断层合成(CT)结构，实现了2D预训练。MammoDINO在多项乳腺癌筛查任务上获得了最先进的性能，且在五个基准数据集上表现出良好的泛化能力。该框架提供了可扩展的、无需标注的基础，用于多用途的计算机辅助诊断(CAD)工具，有助于减轻放射科医生的工作负担，并提高乳腺癌筛查的诊断效率。", "conclusion": "MammoDINO在多个乳腺癌筛查任务上表现出了优越的性能，并能够帮助提高乳腺癌筛查中的诊断效率，为多用途的CAD工具提供了基础，减轻了放射科医生的工作负担。"}
{"llm_update_time": "20251015", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.12098", "html_url": "https://arxiv.org/abs/2510.12098", "title": "An Adaptive Edge-Guided Dual-Network Framework for Fast QR Code Motion Deblurring", "title_en": "An Adaptive Edge-Guided Dual-Network Framework for Fast QR Code Motion Deblurring", "authors": "Jianping Li,Dongyang Guo,Wenjie Li,Wei Zhao", "background": "在普通的图像去模糊任务中，通常更注重感知质量，而二维码去模糊的任务则侧重于确保二维码能够成功解码。二维码具有高度结构化的特征和清晰的边缘，这些特征为图像恢复提供了强大的先验知识。然而，现有的深度学习方法通常没有明确利用这些先验知识。因此，本文提出了一个边缘导向注意力模块（Edge-Guided Attention Block，EGAB），将显式的边缘先验嵌入到Transformer架构中，从而开发出一个有效的新网络——边缘导向去混叠恢复器（Edge-Guided Restormer，EG-Restormer）。对于轻微模糊的输入，设计了轻量级高效网络（Lightweight and Efficient Network，LENet）以实现快速去模糊。进一步将这两种网络整合到一个自适应双网络（Adaptive Dual-network，ADNet）中，根据输入的模糊程度动态选择适当的网络，使其适用于资源受限的移动设备。", "innovation": "本文创新性地提出了边缘导向注意力模块（EGAB），并将其应用于二维码去模糊任务中。通过嵌入显式的边缘先验信息，EGAB能够在解决二维码去模糊问题时充分利用结构化特征。此外，基于EGAB开发的EG-Restormer和设计的LENet，结合自适应双网络（ADNet）能够有效地处理严重和轻微模糊的二维码，并在保持高质量解码率的同时，实现较快的处理速度。", "conclusion": "通过大量实验表明，提出的EG-Restormer和ADNet在网络性能和速度上均达到领先水平。自适应双网络结构（ADNet）能够根据输入模糊程度自动选择合适的网络模型，使其在资源有限的移动设备上具有很高的适用性。"}
{"llm_update_time": "20251015", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.12099", "html_url": "https://arxiv.org/abs/2510.12099", "title": "G4Splat: 生成先验引导的高斯点云几何向导", "title_en": "G4Splat: Geometry-Guided Gaussian Splatting with Generative Prior", "authors": "Junfeng Ni,Yixin Chen,Zhifei Yang,Yu Liu,Ruijie Lu,Song-Chun Zhu,Siyuan Huang", "background": "尽管近期研究表明，利用预训练的扩散模型生成先验信息以进行3D场景重建取得了进步，但现有方法仍存在两项关键限制：第一，缺乏可靠几何监督导致即使在观测区域内也难以生成高质量的重建结果，更不用说未观测区域；第二，缺乏有效机制来减少生成图像中的多视角不一致性，导致严重的形状-外观歧义性和场景几何结构退化。研究表明，准确的几何信息是利用生成模型有效提升3D场景重建效果的关键。", "innovation": "本文通过利用平面结构的普遍性得到精确的米尺度深度图，为观测和未观测区域都提供可靠的监督信息，并在其整个生成管道中引入几何指导，提高视图掩膜估计，引导新颖视图选择，并增强多视角一致性，从而实现准确且一致的场景重建。实验结果表明，与现有基线相比，我们的方法在几何和外观重建方面表现更优，尤其是在未观测区域。", "conclusion": "我们的方法天然支持单视角输入和未定姿态视频，具有广泛的应用性和鲁棒性，尤其适用于室内和室外场景。实验结果展示在Replica、ScanNet++和DeepBlending数据集上，我们的方法在几何和外观重建方面均表现出色。项目页面可访问https://example.com"}
{"llm_update_time": "20251015", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.12114", "html_url": "https://arxiv.org/abs/2510.12114", "title": "旧照片面部修复的自我监督选择性引导扩散模型", "title_en": "Self-Supervised Selective-Guided Diffusion Model for Old-Photo Face Restoration", "authors": "Wenjie Li,Xiangyi Wang,Heng Guo,Guangwei Gao,Zhanyu Ma", "background": "旧照片面部修复由于多种退化因素（如破损、褪色和严重模糊）存在重大挑战。现有预训练的扩散指导方法要么依赖明确的退化先验，要么依赖全局统计指导，这些方法在处理局部瑕疵或面部色彩时表现不佳。", "innovation": "提出了一种自我监督选择性引导扩散（SSDiff）方法，该方法利用在弱指导下由预训练的扩散模型生成的伪参照面部。这些伪标签具有结构对齐的轮廓和自然色彩，能够通过分阶段监督（在整个去噪过程中应用结构指导，在后期步骤中进行颜色细化），实现区域特异性修复。通过结合面部分割图和划痕掩模，该方法可以有选择地修复破损区域，避免身份不符。此外，构建了一个包含300张具有不同退化水平的实物旧照片的VintageFace基准数据集。", "conclusion": "实验结果表明，SSDiff在感知质量、保真度和区域可控性方面优于现有的基于生成对抗网络（GAN）和基于扩散的方法。"}
{"llm_update_time": "20251015", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.12126", "html_url": "https://arxiv.org/abs/2510.12126", "title": "MetaCaptioner: 使用开源套件实现通用视觉描述", "title_en": "MetaCaptioner: Towards Generalist Visual Captioning with Open-source Suites", "authors": "Zhenxin Lei,Zhangwei Gao,Changyao Tian,Erfei Cui,Guanzhou Chen,Danni Yang,Yuchen Duan,Zhaokai Wang,Wenhao Li,Weiyun Wang,Xiangyu Zhao,Jiayi Ji,Yu Qiao,Wenhai Wang,Gen Luo", "background": "通用视觉描述任务不仅要求对图像进行简单的外观描述，还要求整合多种视觉线索并处理多种视觉领域。当前开源模型在性能上与商用模型存在显著差距，限制了数据合成等应用的发展。", "innovation": "本文提出了一种新型多智能体协作的工作流CapFlow，通过利用开源模型，首次展示了在多种领域中可以达到与GPT-4.1媲美的描述质量，同时将成本降低了89.5%。利用CapFlow，作者生成了大量的高质量视觉描述，并通过微调方法得到了一个通用的视觉描述器MetaCaptioner。该模型在描述能力和多模态性能上与商用模型相当，甚至在开源社区达到了顶级水平。", "conclusion": "我们希望CapFlow和MetaCaptioner能够为未来的多模态研究提供一个强大且经济有效的视觉描述解决方案。"}
{"llm_update_time": "20251015", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.12119", "html_url": "https://arxiv.org/abs/2510.12119", "title": "ImageSentinel: 保护检索增强图像生成中视觉数据集的未经授权使用", "title_en": "ImageSentinel: Protecting Visual Datasets from Unauthorized Retrieval-Augmented Image Generation", "authors": "Ziyuan Luo,Yangyi Zhao,Ka Chun Cheung,Simon See,Renjie Wan", "background": "检索增强图像生成（RAIG）系统的广泛应用引起了对私人图像数据集未经授权使用的新关注。尽管RAIG系统在通过参考图像增强生成质量方面显示出卓越的能力，但在这样的系统中保护视觉数据集以防止未经授权使用仍然是一个具有挑战性的问题。传统的数字水印方法在RAIG系统中面临局限性，因为复杂的特征提取和重组过程无法在生成过程中保存水印信号。", "innovation": "我们提出了ImageSentinel，这是一种新颖的框架，用于保护RAIG中的视觉数据集。我们的框架生成保持与原始数据集视觉一致性的哨兵图像。这些哨兵通过随机生成的字符序列实现保护验证，这些字符序列作为检索密钥。为了确保无缝集成，我们利用视觉-语言模型生成哨兵图像。", "conclusion": "实验结果表明，ImageSentinel有效地检测未经授权的数据集使用，同时保留授权应用中的生成质量。相关代码可在以下链接访问：this https URL。"}
{"llm_update_time": "20251015", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.12107", "html_url": "https://arxiv.org/abs/2510.12107", "title": "DRL: 具有并行适配器的辨别性特征学习方法以实现类增量学习", "title_en": "DRL: Discriminative Representation Learning with Parallel Adapters for Class Incremental Learning", "authors": "Jiawei Zhan,Jun Liu,Jinlong Peng,Xiaochen Chen,Bin-Bin Gao,Yong Liu,Chengjie Wang", "background": "凭借预训练模型（PTMs）出色的表征能力，非复习类增量学习（CIL）取得了显著进展，但仍然是一项极其具有挑战性的任务。存在的挑战包括逐渐增加的模型复杂性、增量学习过程中非连续的表征变化，以及阶段间子问题优化和全局推理之间的一致性问题。", "innovation": "本文提出了一个辨别性表征学习（DRL）框架，以专门解决上述挑战。通过构建基于PTM的Incremental Parallel Adapter（IPA）网络，每次增量阶段仅通过少量参数学习的方式增加模型。IPA中的适配器能够继承和传播当前模型的表特征，从而保证不同增量阶段之间的平滑表征转变。此外，设计了Decoupled Anchor Supervision（DAS）以减少阶段间不一致并使学习的特征空间保持一致性，通过虚拟锚分别比较正负样本从而促进辨别性特征学习。实验结果表明，DRL不仅在CIL期间整体性能优于其他最先进的方法，而且在训练和推理阶段维持了高效率。", "conclusion": "DRL在CIL的整个过程中表现出稳定优异的性能，同时在训练和推理阶段都表现出高效率。这种方法通过提出一种新的框架和方法，成功解决了CIL中的关键挑战。"}
{"llm_update_time": "20251015", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.12132", "html_url": "https://arxiv.org/abs/2510.12132", "title": "FedHUG: 联邦异构无监督泛化的远程生理测量", "title_en": "FedHUG: Federated Heterogeneous Unsupervised Generalization for Remote Physiological Measurements", "authors": "Xiao Yang,Jiyao Wang", "background": "远程生理测量技术引起了广泛的关注，但这也需要收集用户的敏感信息。现有技术主要依赖于标记的数据来进行非接触测量。当需要利用大量缺乏标签的用户数据更新部署在实际环境中的模型时，会遇到诸多挑战。", "innovation": "本文提出了一个新的协议——联邦无监督领域泛化（FedUnguided Domain Generalization, FUDG），并进一步提出了联邦异构无监督泛化（Federated Heterogeneous Unsupervised Generalization, FedHUG）框架。该框架包括两个模块：（1）最小偏差聚合模块能够动态调整聚合权重，以应对来自不同领域的异构非IID特征。 （2）全局分布感知学习控制器能够参数化标签分布，并动态调整客户端特定的训练策略，以缓解服务端与客户端标签分布的偏差和长尾问题。这些贡献在使用RGB视频或毫米波雷达进行估计时表现优于现有技术。", "conclusion": "实验结果表明，提出的FedHUG方法在使用RGB视频或毫米波雷达进行估计时性能优于现有的先进技术和方法。代码将公开发布。"}
{"llm_update_time": "20251015", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.12159", "html_url": "https://arxiv.org/abs/2510.12159", "title": "DPL: 基于空间条件的扩散原型增强方法在单次医疗图像分割中的应用", "title_en": "DPL: Spatial-Conditioned Diffusion Prototype Enhancement for One-Shot Medical Segmentation", "authors": "Ziyuan Gao,Philippe Morel", "background": "单次医疗图像分割由于标注数据有限以及患者间显著的解剖学差异面临核心挑战。传统基于原型的方法依赖于特征确定性平均，这会导致脆弱的表示，难以捕捉鲁棒性泛化所需的类内多样性。", "innovation": "提出了扩散原型学习（DPL）框架，通过基于扩散的特征空间探索重建原型构造。DPL通过扩散增强模块将单一支持原型转化为多种样例，利用空间感知条件机制依据原型特征统计的几何属性进行条件化，并采用保守融合策略在保持原型保真度的同时最大化表示多样性。该框架确保在训练与推理阶段使用相同的扩散增强和融合流水线，从而生成用于相似性计算的增强原型。", "conclusion": "DPL 在腹部 MRI 和 CT 数据集上的广泛实验表明，与现有方法相比取得了显著改进，建立了单次医疗图像分割的新最先进性能。"}
{"llm_update_time": "20251015", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.12123", "html_url": "https://arxiv.org/abs/2510.12123", "title": "硬件感知的压缩单光子3D相机编码函数设计", "title_en": "Hardware-aware Coding Function Design for Compressive Single-Photon 3D Cameras", "authors": "David Parra,Felipe Gutierrez-Barragan,Trevor Seets,Andreas Velten", "background": "单光子相机在飞行时间3D成像中受到越来越多的欢迎，因为它们可以以极高的分辨率对单个光子进行时间标记。然而，其性能受到硬件限制的影响，如系统带宽、最大激光功率、传感器数据速率和内部传感器的内存和计算资源。近期，通过在传感器中实时压缩光子时间戳数据来应对数据速率的压缩直方图作为解决方案引入，但它们在面对实际照明硬件限制时表现不佳。本文讨论了此类硬件限制下的性能问题，并提出了一种约束优化方法来设计适用于压缩单光子3D成像的实际编码函数。这种方法通过梯度下降方法联合优化照明矩阵和编码矩阵，以适应硬件限制。研究显示，在带宽和峰值功率限制条件下，本文的编码函数优于传统设计。特别是在受限于峰值功率的系统中，表现尤为明显。最后，本文验证了此方法对于任意参数化的脉冲响应具有适用性，通过应用到具有非理想脉冲响应函数的真实系统中得到了测试。", "innovation": "提出了一种约束优化方法，通过梯度下降方法联合优化照明矩阵和编码矩阵，设计适用于压缩单光子3D成像的实际编码函数。这种方法能够适应硬件约束，尤其是涉及带宽和峰值功率限制的系统。同时，该方法适用于任意参数化的脉冲响应，即使是在具有非理想脉冲响应的真实系统中也能保持优势。", "conclusion": "研究表明，本文提出的编码函数在面对真实世界的照明硬件限制时，性能优于传统的编码设计，尤其是在受限于峰值功率的情况下表现尤为突出。此外，该方法能够适应各种任意参数化的脉冲响应，增强了其在实际应用中的灵活性和适用性。"}
{"llm_update_time": "20251015", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.12150", "html_url": "https://arxiv.org/abs/2510.12150", "title": "Class-aware Domain Knowledge Fusion and Fission for Continual Test-Time Adaptation", "title_en": "Class-aware Domain Knowledge Fusion and Fission for Continual Test-Time Adaptation", "authors": "Jiahuan Zhou,Chao Zhu,Zhenyu Cui,Zichen Liu,Xu Zou,Gang Hua", "background": "现有先进的持续测试时适调（CTTA）方法主要通过恢复初始模型或重用历史模型来减少由于下游领域数据不规则切换导致的历史知识灾难性遗忘。然而，这些方法通常伴随着新知识学习不足和有害历史知识带来的干扰，导致性能严重退化。以往解决这一问题的方法往往要么不能有效积累新的知识，要么在计算和存储成本之间存在权衡。", "innovation": "提出了一个针对持续测试时适调的类感知领域知识融合与分裂方法，简称KFF。该方法根据不同领域的测试时数据，适当地扩展和合并旧领域和新领域的类感知知识，并且通过一个领域知识分裂（KFI）模块，动态从配对的类感知领域提示池中分离出新的领域知识，缓解来自不同领域的旧知识带来的负面影响。为了避免不断分裂新知识带来的累积计算和存储开销，还设计了一个领域知识融合（KFU）模块，该模块可以以最小成本将分裂的新知识合并到现有知识库中，同时还设计了一个贪婪的知识动态合并策略，提高了新旧知识的兼容性，同时保持了计算效率。这些方法与现有方法相比，经过ImageNet-C数据集的实验验证，它们的有效性更强。", "conclusion": "本文提出了一种针对持续测试时适调的类感知领域知识融合与分裂方法（KFF）。该方法通过适应性地扩展和合并类感知的知识，有效解决了以前方法中存在的新知识学习不足和历史知识干扰问题。实验结果表明，KFF方法在多个测试集上明显优于其他方法，证明了其在持续测试时适调中的有效性。"}
{"llm_update_time": "20251015", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.12160", "html_url": "https://arxiv.org/abs/2510.12160", "title": "基于收集和传播时空信息的视频理解状态空间提示", "title_en": "State Space Prompting via Gathering and Spreading Spatio-Temporal Information for Video Understanding", "authors": "Jiahuan Zhou,Kai Zhu,Zhenyu Cui,Zichen Liu,Xu Zou,Gang Hua", "background": "近年来，预训练的时空模型在视频分类中显示出了巨大的潜力，它们能够以线性复杂度顺序压缩视频中的视觉标记，从而提高视频数据的处理效率，同时保持高性能。针对预训练模型在下游任务中的应用，提出了提示学习，只需少量微调参数即可实现高效的下游任务适配。然而，这些顺序压缩的提示标记无法捕捉视频中的空间和时间上下文信息，限制了视频帧内空间信息的有效传递以及帧间时间信息的传递和关键信息的提取。", "innovation": "为了应对上述问题，本文提出了状态空间提示（SSP）方法，该方法结合帧内和帧间提示以聚合和传播视频中的关键时空信息。具体而言，设计了一个帧内收集（IFG）模块来聚合每个帧内的空间关键信息，以及一个帧间传播（IFS）模块来在整个视频中传播关键的时空信息。通过适应性地平衡和压缩帧内外的关键时空信息，SSP以互补的方式有效地传递了视频中的关键信息。", "conclusion": "在四个视频基准数据集上的大量实验结果表明，我们的SSP方法在平均性能上比现有最先进的方法高出2.76%，同时减少了微调参数的成本。"}
{"llm_update_time": "20251015", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.12208", "html_url": "https://arxiv.org/abs/2510.12208", "title": "合成数据对目标检测模型性能的影响：基于现实世界数据的比较分析", "title_en": "The Impact of Synthetic Data on Object Detection Model Performance: A Comparative Analysis with Real-World Data", "authors": "Muammer Bay,Timo von Marcard,Dren Fazlija", "background": "近年来，生成式AI，尤其是计算机视觉领域，为各行业优化工作流程提供了新机会，包括物流和制造。然而，许多AI应用受限于专业知识和资源不足，不得不依赖通用模型。使用领域特定数据进行微调虽然有效，但成本高且效率低。因此，使用合成数据进行微调成为一种经济高效的替代方案。本文探讨了合成数据在仓库物流领域的应用对目标检测模型性能的影响。", "innovation": "本文通过使用NVIDIA Omniverse Replicator工具生成的合成数据，对比分析了目标检测模型在使用合成数据与仅使用现实世界数据之间的效果差异。研究涵盖了仓库环境中的托盘检测实验，采用了不同的数据生成策略。", "conclusion": "研究发现，合理集成合成数据和现实世界数据可以促进鲁棒且高效的物体检测模型的应用。"}
{"llm_update_time": "20251015", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.12182", "html_url": "https://arxiv.org/abs/2510.12182", "title": "BEEP3D：基于框监督的端到端伪掩码生成方法用于三维实例分割", "title_en": "BEEP3D: Box-Supervised End-to-End Pseudo-Mask Generation for 3D Instance Segmentation", "authors": "Youngju Yoo,Seho Kim,Changick Kim", "background": "3D实例分割对于理解复杂3D环境至关重要，但全监督方法需要密集的点级注释，导致注释成本高昂和劳动力密集。为了减轻这一问题，研究人员探索了框标注作为较弱但更有扩展性的监督形式。然而，框注释在重叠区域引入了固有的不确定性，使得点与实例的精准关联变得困难。现有方法通过训练专用的伪标签生成器来解决这种不确定性，但这种方法往往增加了整体训练时间和复杂性，阻碍了端到端优化。", "innovation": "本文提出了BEEP3D，一种基于学生-老师框架的端到端伪掩码生成方法。通过Exponential Moving Average，教师模型作为伪标签生成器并由学生模型更新。此外，BEEP3D引入了基于实例中心的查询细化机制，增强了位置查询定位，并利用实例中心附近的特征。同时，设计了两个新颖的损失函数：查询一致性损失和掩码特征一致性损失，以在预测和伪掩码之间对齐语义和几何信号。特别是在ScanNetV2和S3DIS数据集上的实验表明，BEEP3D在计算效率方面优于现有的弱监督方法，同时达到了可比拟或更优的性能。", "conclusion": "BEEP3D通过一种高效且准确的方法解决了弱监督3D实例分割中的关键挑战，提供了与最先进的方法性能相当或更好的结果，同时保持了计算效率。"}
{"llm_update_time": "20251015", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.12184", "html_url": "https://arxiv.org/abs/2510.12184", "title": "CompoDistill: 视觉注意力蒸馏在多模态LLM中的组成推理", "title_en": "CompoDistill: Attention Distillation for Compositional Reasoning in Multimodal LLMs", "authors": "Jiwan Kim,Kibum Kim,Sangwoo Seo,Chanyoung Park", "background": "近年来，高效的多模态大型语言模型（MLLMs）因其高计算复杂性而受到广泛关注，这使得它们在现实世界中的应用更具实际性。知识蒸馏（KD）作为一种有希望的替代方法，已经被提出，这种方法通过将大型模型（教师）的丰富视觉和语言知识转移到较小模型（学生）上。然而，现有的KD方法难以有效地将教师MLLM的丰富视觉感知能力转移到学生模型上，这个问题在先前的研究中被忽视了。", "innovation": "本文提出了CompoDistill，一种新颖的KD框架，它明确对齐学生的视觉注意力与教师的视觉注意力，以增强学生的视觉感知能力。CompoDistill在包含视觉感知能力的任务上的性能显著提高，并且在保持现有研究在视觉问答任务上的强大性能的同时，展示了其在更先进的骨干网络上的有效性，突显了其普适性。", "conclusion": "大量的实验表明，CompoDistill在需要视觉感知能力的组成推理任务上的性能显著提高，同时也维持了在现有的视觉问答任务上的强大表现。此外，CompoDistill与更高级的骨干网络配合使用时展示了其有效性，这表明了其普适性。"}
{"llm_update_time": "20251015", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.12174", "html_url": "https://arxiv.org/abs/2510.12174", "title": "UniGS：统一几何感知的高斯点渲染方法以实现多模态渲染", "title_en": "UniGS: Unified Geometry-Aware Gaussian Splatting for Multimodal Rendering", "authors": "Yusen Xie,Zhenmin Huang,Jianhao Jiao,Dimitrios Kanoulas,Jun Ma", "background": "本文提出了一种基于3D高斯点（Gaussian Splats）的统一地图表示和可微框架，用于高保真度多模态3D重建。该框架结合了一个能够同时渲染逼真RGB图像、几何准确的深度图、一致的表面法线以及语义标签的CUDA加速光栅化管道。为了实现有效的旋转和尺度参数优化，将光栅化设计为使用可微的射线椭球相交来渲染深度，而不是使用高斯中心。此外，还推导了表面法线渲染的解析梯度公式，确保重建3D场景之间的几何一致性。通过引入可学习的属性来减少训练过程中贡献最小的高斯的微分剪枝，从而提高计算和存储效率。", "innovation": "本文的创新在于提出了UniGS框架，它结合了一个CUDA加速的光栅化管道，旨在实现同步渲染逼真的RGB图像、几何准确的深度图、一致的法线以及语义标签。此外，通过使用可微的射线椭球相交来渲染深度，以及推导出表面法线渲染的解析梯度公式，从而实现对几何一致性的优化。此外，还引入了可学习的属性来实现对贡献最小的高斯的微分剪枝，以提高计算和存储效率。", "conclusion": "定量和定性的实验结果表明，本文提出的几何感知框架在所有模态下达到了最先进的重建精度，验证了其有效性。源代码和多模态查看器将在GitHub上公开。"}
{"llm_update_time": "20251015", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.12190", "html_url": "https://arxiv.org/abs/2510.12190", "title": "使用视觉语言模型进行多级推理的行车记录视频事故报告", "title_en": "Hierarchical Reasoning with Vision-Language Models for Incident Reports from Dashcam Videos", "authors": "Shingo Yokoi,Kento Sasaki,Yu Yamaguchi", "background": "近年来，端到端自主驾驶技术得益于大规模多变驾驶数据集的数据训练，但自主驾驶模型在未预见分布（OOD）场景中仍表现不佳。COOOL基准旨在通过促进超出封闭分类的危险理解来填补这一空白，2COOOL挑战还进一步鼓励生成可解释的事故报告。为了应对这一挑战，该研究提出了一种集成帧级描述、事故帧检测和视觉语言模型（VLM）中的细粒度推理的分层推理框架，用于从行车记录视频生成事故报告。", "innovation": "该研究提出了一种分层推理框架，该框架利用视觉语言模型从行车记录视频生成事故报告，并通过模型集成和盲A/B评分选择协议进一步提高了事实准确性和可读性。结果显示，该方法在官方2COOOL公开排行榜中排名第二，获得最佳CIDEr-D得分，生成了准确且连贯的事故叙述。这表明使用视觉语言模型进行分层推理是事故分析和交通关键事件广泛理解的有前途的方向.", "conclusion": "研究结果表明，通过视觉语言模型进行分层推理是一种有前途的方法，可用于事故分析，并帮助更全面地理解关键交通事件。该方法在2COOOL挑战中取得了很好的效果，进一步验证了分层推理方法在该领域的有效性。该方法的实现和代码可以从作者提供的链接获得。"}
{"llm_update_time": "20251015", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.12225", "html_url": "https://arxiv.org/abs/2510.12225", "title": "HoneyBee: 数据调料箱—为视觉语言推理者准备", "title_en": "HoneyBee: Data Recipes for Vision-Language Reasoners", "authors": "Hritik Bansal,Devandra Singh Sachan,Kai-Wei Chang,Aditya Grover,Gargi Ghosh,Wen-tau Yih,Ramakanth Pasunuru", "background": "近期视觉语言模型（VLMs）在推理任务中的表现非常出色，然而构建高性能VLM推理训练数据集的原则仍然不甚明朗。本文介绍了一些数据整理方法，并通过仔细控制训练和评估设置来研究它们对VLM推理能力的影响。研究分析了上下文（图像和问题配对）来源的效果，实施了有针对性的数据干预措施，并探讨了扩展图像、问题和思维链（CoT）解决方案的可能性。", "innovation": "本研究发现了（a）上下文来源策略对VLM性能有显著影响，（b）辅助信号如图像说明和文本推理方式的介入大幅度提高了性能，（c）所有数据维度的扩展（如每个图像的问题数和每个图像-问题配对的思维链数）可以显著提高推理能力。基于这些发现，作者还提出了HoneyBee，一个包含250万个示例的大型、高质量CoT推理数据集，该数据集由35万个图像-问题配对组成。使用HoneyBee训练的VLM在MathVerse等任务中优于现有的基础模型和参数更大的模型，准确率显著提高。此外，还提出了一个测试时的扩展策略，通过减少解码成本来提高准确率。", "conclusion": "本文提出了改进的VLM推理数据集整理策略，详细分析了上下文来源策略、数据干预措施以及数据维度扩展对VLM推理能力的影响，并展示了HoneyBee数据集在多个模型上显著提升了推理性能。"}
{"llm_update_time": "20251015", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.12241", "html_url": "https://arxiv.org/abs/2510.12241", "title": "Ivan-ISTD：重新思考红外小目标检测中的跨域异方差噪声扰动", "title_en": "Ivan-ISTD: Rethinking Cross-domain Heteroscedastic Noise Perturbations in Infrared Small Target Detection", "authors": "Yuehui Li,Yahao Lu,Haoyuan Wu,Sen Zhang,Liang Lin,Yukai Shi", "background": "在多媒体领域，红外小目标检测（ISTD）在无人机多模态传感中扮演重要角色。然而，ISTD 面临着跨域偏移和异方差噪声扰动的双重挑战，这限制了现有方法的性能和鲁棒性。", "innovation": "本文提出了一种双重小波引导不变学习框架（Ivan-ISTD），它分为两个阶段：第一阶段使用小波引导跨域合成生成与目标域对齐的训练样本；第二阶段通过实域噪声不变性学习从目标域中抽取噪声特征，建立动态噪声库，并通过自监督损失学习噪声不变性，从而克服了传统人工噪声建模中的分布偏差问题。此外，还构建了Dynamic-ISTD基准，该基准模拟了现实应用中遇到的分布偏移。", "conclusion": "实验结果表明，本方法在许多量化指标上优于现有的先进方法，并且在跨域场景中表现出色的鲁棒性。"}
{"llm_update_time": "20251015", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.12231", "html_url": "https://arxiv.org/abs/2510.12231", "title": "BIGFix: 双向图像生成与token修复", "title_en": "BIGFix: Bidirectional Image Generation with Token Fixing", "authors": "Victor Besnier,David Hurych,Andrei Bursuc,Eduardo Valle", "background": "近年来，图像和视频生成技术在学术界和工业界引起了广泛关注。然而，在这一领域中，提高推理效率是一个关键挑战，因为模型大小和推理步骤数量直接影响生成模型的商业化可行性。此外，这一挑战还提出了基础科学难题。有希望的方向是结合自回归序列令牌建模与每步多令牌预测，从而将推理时间减少多达一个数量级。但是，同时预测多个令牌可能由于令牌不兼容而引入结构上的不一致性，因为训练期间捕捉复杂联合依赖仍然具有挑战性。传统上，一旦令牌生成，就没有机制回退并改进错误预测。因此，研究者提出了一种自纠正图像生成方法，通过迭代地改进生成的令牌，进行自矫正。这种方法结合了新颖的训练方案，即在上下文中标记随机令牌，提高了鲁棒性并在抽样时允许令牌修复。这保留了并行令牌预测带来的效率优势，同时显著提升生成质量。", "innovation": "提出了一种自纠正图像生成方法，结合新颖的训练方案在上下文中标记随机令牌，提高了鲁棒性并在抽样时允许令牌修复。这种方法结合了平行令牌预测带来的效率优势，同时显著提升生成质量，相比传统的直接基于自回归分布生成方法，根据反馈来对错误进行纠正，提高生成的图片质量。", "conclusion": "该方法已经在ImageNet-256和CIFAR-10数据集上进行了图像生成评估，并在UCF-101和NuScenes数据集上进行了视频生成评估。不仅在图像生成方面，而且在视频生成方面均取得了显著的改进，证明了其有效性和优势。"}
{"llm_update_time": "20251015", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.12256", "html_url": "https://arxiv.org/abs/2510.12256", "title": "基于层次时空一致性代理嵌入的易于编辑的向量化视频表示", "title_en": "Vectorized Video Representation with Easy Editing via Hierarchical Spatio-Temporally Consistent Proxy Embedding", "authors": "Ye Chen,Liming Tan,Yupeng Zhu,Yuanbin Wang,Bingbing Ni", "background": "当前的视频表示依赖于不稳定的像素级匹配和跟踪，这些方法容易受到跟踪误差、遮挡和大范围运动的影响。本文探讨了这些不稳定性和复杂性如何影响视觉对象的表示，并指出现有的方法易受这些因素的困扰，尤其是在处理视频中的动态变化时更为明显。", "innovation": "本文提出了一种层次时空一致的代理节点来表示视频中的动态变化的对象/场景。代理节点具有多尺度结构表示能力，不受累计跟踪误差、长期运动、遮挡和视角变化的影响。同时，代理节点的动态表示更新机制利用了视频的时空先验信息，以减轻错误跟踪的影响，有效处理场景和对象的急剧变化。此外，这种分层表示还能使不同视频对象的形状和纹理表示解耦，提供可控的、精细的外观编辑能力。", "conclusion": "通过大量实验表明，提出的表示方法能够在少量参数下实现高视频重建精度，并支持复杂的视频处理任务，如视频修复和基于关键帧的时空一致视频编辑。"}
{"llm_update_time": "20251015", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.12258", "html_url": "https://arxiv.org/abs/2510.12258", "title": "Multiplicative Loss for Enhancing Semantic Segmentation in Medical and Cellular Images", "title_en": "Multiplicative Loss for Enhancing Semantic Segmentation in Medical and Cellular Images", "authors": "Yuto Yokoi,Kazuhiro Hotta", "background": "在医学和细胞图像语义分割中，虽然交叉熵和Dice损失被广泛使用，但它们的加性组合对超参数敏感且经常表现不佳，尤其是在数据有限的情况下。医学图像由于隐私、伦理和标注成本问题面临着数据稀缺的问题，因此需要强大的且高效的训练目标。", "innovation": "本文提出了一种新的损失函数Multiplicative Loss，它将交叉熵和Dice损失相乘，基于预测置信度动态调节梯度。此外，进一步提出了一种Confidence-Adaptive Multiplicative Loss，它通过Focal Loss的启发应用基于预测置信度的指数缩放，从而加强在低置信度下的梯度，有助于在极端数据稀缺的情况下提升学习。", "conclusion": "在医学和细胞分割基准上进行的实验表明，该框架在所有实验证据中都优于调参后的加性损失和其他现有损失函数，提供了一个简单、有效的且无需超参数调整的机制来在数据限制的挑战下实现稳健的分割。"}
{"llm_update_time": "20251015", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.12219", "html_url": "https://arxiv.org/abs/2510.12219", "title": "DIANet: 基于动态图像的相位感知双流网络在微表情识别中的应用", "title_en": "DIANet: A Phase-Aware Dual-Stream Network for Micro-Expression Recognition via Dynamic Images", "authors": "Vu Tram Anh Khuong,Luu Tu Nguyen,Thi Bich Phuong Man,Thanh Ha Le,Thi Duyen Ngo", "background": "微表情是瞬时且不自主的面部动作，通常持续时间不到半秒，能揭示真实情感。准确识别这些微妙的表情对于心理学、安全和行为分析等领域具有重要意义。然而，由于面部表情的细微和短暂特性以及标注数据的稀缺性，微表情识别（MER）任务仍然具有挑战性。尽管动态图像（DI）表示法能够将时间动态压缩为单一帧，但传统的DI方法往往忽略了微表情不同时间阶段的独特特征。面对这一挑战，本文提出了一种新的双流框架DIANet，该框架利用相位感知动态图像——一个是起始到峰值阶段的编码，另一个是峰值到结束阶段的捕捉。每个流由专门的卷积神经网络处理，并通过跨注意力融合模块根据其上下文相关性自适应地集成两个流中的特征。在三个经典的MER数据集（CASME-II、SAMM和MMEW）上的实验表明，所提出的算法在多个方面超过了传统的单相DI方法。实验结果强调了显式建模时间相位信息的重要性，并为MER的发展指出了一个有希望的方向。", "innovation": "提出了一个基于动态图像的双流框架DIANet，利用相位感知动态图像，并通过跨注意力融合模块自适应地整合两个流中的特征，从而提高了微表情识别的准确性。该方法能够在单帧中捕捉不同时间阶段的微表情特征，显著提升了MER的表现。", "conclusion": "提出的DIANet方法在多个标准数据集上实现了优异的性能，证明了双流框架和相位感知动态图像在微表情识别中的有效性。未来的研究可以进一步优化该模型，以适应更大的数据集和更复杂的微表情任务。"}
{"llm_update_time": "20251015", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.12259", "html_url": "https://arxiv.org/abs/2510.12259", "title": "本地背景特征在Out-of-Distribution检测中重要", "title_en": "Local Background Features Matter in Out-of-Distribution Detection", "authors": "Jinlun Ye,Zhuohao Sun,Yiqiao Qiu,Qiu Li,Zhijun Tan,Ruixuan Wang", "background": "在实际应用中部署深度神经网络时，Out-of-Distribution (OOD)检测至关重要，以确保其应用的可靠性和安全性。一个主要挑战是神经网络模型在OOD数据上会产生过度自信的预测。尽管使用辅助OOD数据集或生成假象OOD图像的一些方法在OOD检测上表现出色，但它们受限于数据收集和训练的高昂成本。因此，需要一种无需大规模额外数据或成本的有效OOD检测方法。先前的研究通过提取本地不变的背景特征来进行OOD检测，并证明了这种方法的有效性和广泛兼容性，从而获得新的SOTA性能。", "innovation": "本文提出了一种新颖且有效的OOD检测方法，利用本地背景特征作为模拟OOD特征用于模型训练。基于局部不变性，从ID图像中提取背景特征，通过优化减少这些背景特征的$L_2$-范数来减少模型在OOD数据上的过度自信问题。这种方法不需要额外的OOD数据或高昂的成本，并且与现有的事后方法具有广泛的兼容性，从而提高了检测性能并达到了新SOTA水平。", "conclusion": "通过广泛的实验证明，本文方法在多个标准OOD检测基准上有效，并且与现有的事后方法具有出色的兼容性，从而实现了新的SOTA性能。"}
{"llm_update_time": "20251015", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.12267", "html_url": "https://arxiv.org/abs/2510.12267", "title": "SpineBench: 评价多模态大语言模型脊椎病理分析的标准", "title_en": "SpineBench: Benchmarking Multimodal LLMs for Spinal Pathology Analysis", "authors": "Chenghanyu Zhang,Zekun Li,Peipei Li,Xing Cui,Shuhan Xia,Weixiang Yan,Yiqiao Zhang,Qianyu Zhuang", "background": "随着多模态大型语言模型（MLLMs）在医疗领域的集成度增加，各种医疗领域的综合性能评估变得更加关键。现有基准主要评估通用医疗任务，未能充分捕捉依赖视觉输入的细微领域中的性能表现，如脊椎医学。脊椎医学依赖视觉输入，因此需要一个专门的基准来评估MLLM在脊椎领域的性能。", "innovation": "提出了SpineBench，这是一个全面的视觉问答（VQA）基准，专门设计用于细粒度分析和评估MLLM在脊椎领域的表现。SpineBench包含64,878个问答对，来自40,263张脊椎影像，覆盖11种脊椎疾病。它通过脊椎疾病诊断和脊椎病变定位（两项关键临床任务）构建，形式为多项选择。SpineBench通过集成和标准化来自开源数据集的图像-标签对，并根据不同情况下的视觉相似性（相似但不同病）选择具有挑战性的负样本，模拟了真实世界的挑战场景。", "conclusion": "对12种领先MLLMs在SpineBench上的评估结果揭示了这些模型在脊椎任务中的表现不佳，指出了当前MLLMs在脊椎领域存在的局限性，指导了未来改进脊椎医学应用的方向。SpineBench已公开可用。"}
{"llm_update_time": "20251015", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.12283", "html_url": "https://arxiv.org/abs/2510.12283", "title": "Dual Learning with Dynamic Knowledge Distillation and Soft Alignment for Partially Relevant Video Retrieval", "title_en": "Dual Learning with Dynamic Knowledge Distillation and Soft Alignment for Partially Relevant Video Retrieval", "authors": "Jianfeng Dong,Lei Huang,Daizong Liu,Xianke Chen,Xun Yang,Changting Lin,Xun Wang,Meng Wang", "background": "几乎所有以前的文字到视频检索工作都假设视频预先修剪过，只包含与文本相关的内容且时长较短。然而，在实践中，视频通常是未经修剪的长时长画面，且包含更复杂的背景内容。因此，本文专注于更实际且更具挑战性的部分相关视频检索（PRVR）任务，即根据给定的查询检索部分相关的未经修剪的视频。", "innovation": "提出了一个新颖的框架，该框架从强大的大规模视觉-语言预训练模型中提炼泛化知识，并将其转移到一个轻量级的任务特定的PRVR网络。此外，引入了带有动态知识蒸馏的双学习框架（DL-DKD++），其中大型教师模型向紧凑的双分支学生网络提供监督。还提出了动态软目标构建机制，通过引入可自适应进化的软目标替代刚性硬目标监督，使模型能够更好地捕捉视频与查询之间的细粒度部分相关。", "conclusion": "实验结果显示，提出的模型在TVR、ActivityNet和Charades-STA数据集上实现了PRVR的最新性能。相关代码已发布。"}
{"llm_update_time": "20251015", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.12282", "html_url": "https://arxiv.org/abs/2510.12282", "title": "PAGS: 动态驾驶场景优先自适应高斯点绘法", "title_en": "PAGS: Priority-Adaptive Gaussian Splatting for Dynamic Driving Scenes", "authors": "Ying A,Wenzhang Sun,Chang Zeng,Chunfeng Wang,Hao Li,Jianxun Cui", "background": "动态3D城市场景的重建对于自动驾驶至关重要，但目前的方法在保真度和计算成本之间面临着显著的权衡。由于这些方法缺乏语义指导，它们均匀分配资源，对待静态背景和安全关键物体同等重要。这些方法的语义不敏感设计导致了它们的低效率。", "innovation": "我们提出了一种优先自适应高斯点绘法(PAGS)，该方法直接将任务感知的语义优先级注入到3D重建和渲染管道中。PAGS的两个核心贡献是：1. 语义引导的剪枝和正则化策略，利用混合重要性度量来激进地简化非关键场景元素，同时保持对导航至关重要的对象的微细节。2. 优先驱动渲染管道，采用基于优先级的深度预处理步骤激进地剔除被遮挡的原始体并加速最终着色计算。", "conclusion": "在Waymo和KITTI数据集上进行的大量实验表明，PAGS在安全关键物体上实现了卓越的重建质量，同时大幅减少了训练时间并提升了渲染速度，达到每秒超过350帧。"}
{"llm_update_time": "20251015", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.12260", "html_url": "https://arxiv.org/abs/2510.12260", "title": "AngularFuse：基于角度感知的空间敏感多模态图像融合解决方案", "title_en": "AngularFuse: A Closer Look at Angle-based Perception for Spatial-Sensitive Multi-Modality Image Fusion", "authors": "Xiaopeng Liu,Yupei Lin,Sen Zhang,Xiao Wang,Yukai Shi,Liang Lin", "background": "可见红外图像融合在自主驾驶和夜间监视等关键应用中至关重要。它的主要目标是整合多模态信息，生成更适合下游任务的增强图像。尽管基于深度学习的融合方法取得了显著进展，主流的无监督方法在实际应用中仍然面临严重挑战。现有的方法大多依赖于手工设计的损失函数来引导融合过程，但这些损失函数存在明显局限性。一方面，现有方法构建的参考图像往往缺乏细节且亮度不均，另一方面，广泛使用的梯度损失仅关注梯度大小。", "innovation": "本文提出了一种基于角度感知的空间敏感图像融合框架（AngularFuse）。首先，设计了一个跨模态互补掩码模块，迫使网络学习模态间互补信息。然后，引入了一种细粒度的参考图像合成策略，通过结合Laplacian边缘增强和自适应直方图均衡，生成了更丰富的细节和更协调亮度的参考图像。最后，引入了一种角度感知损失，首次在梯度域中同时约束梯度大小和方向，确保融合图像保留纹理强度和正确的边缘方向。系统实验表明，AngularFuse在公开的MSRS、RoadScene和M3FD数据集上的表现优于现有主流方法，具有明显的优越性。视觉对比进一步证实，我们的方法在复杂场景中产生了更清晰和详细的图像结果，展示了其卓越的融合能力。", "conclusion": "AngularFuse在MSRS、RoadScene和M3FD公开数据集上的实验结果表明，它在表现上超过了现有主流方法，并且这种方法在复杂场景中所生成的图像结果更是更加清晰和详细，证明了其出色的融合能力。"}
{"llm_update_time": "20251015", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.12287", "html_url": "https://arxiv.org/abs/2510.12287", "title": "Vision语言模型通过视觉投射中的语义纠缠将Logo映射到文本", "title_en": "Vision Language Models Map Logos to Text via Semantic Entanglement in the Visual Projector", "authors": "Sifan Li,Hongkai Chen,Yujun Cai,Qingwen Ye,Liyang Chen,Junsong Yuan,Yiwei Wang", "background": "Vision语言模型（VLMs）在多模态推理方面取得了显著进展，但仍易出现幻觉现象，即输出内容与视觉证据不符。本文研究了一种之前未被关注的场景——Logo幻觉，即模型生成品牌名称或文本内容，尽管Logo中并无可见文字。", "innovation": "本文通过构建纯符号、混合符号及含文本Logo的精心分割数据集，并采用具有挑战性的Hard-60子集，系统性地评估了主要VLMs的幻觉情况。还通过对九种结构化干扰的探针测试，表明即使在强干扰下仍存在幻觉现象，遮挡揭示了最明显的弱点。使用开放权重LLaVA进行嵌入级分析，揭示了幻觉与投影维度的小部分相关，通过目标消融显著减少了错误同时保持OCR准确性。", "conclusion": "研究发现，VLMs往往依赖于符号先验而非真实字符感知，特别是在那些图标式的圆形Logo上更明显。投影子空间在这一失败模式中起到决定性作用。本研究不仅提供了新的诊断视角，还提供了减少幻觉的实用性建议，强调了投影维度解耦和OCR引导解码作为构建更可信多模态系统的关键方向。"}
{"llm_update_time": "20251015", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.12308", "html_url": "https://arxiv.org/abs/2510.12308", "title": "混合高斯插值用于城市新型视图合成", "title_en": "Hybrid Gaussian Splatting for Novel Urban View Synthesis", "authors": "Mohamed Omran,Farhad Zanjani,Davide Abati,Jens Petersen,Amirhossein Habibian", "background": "本论文描述了Qualcomm AI Research团队在RealADSim-NVS挑战中的解决方案，该挑战是RealADSim Workshop在2025年ICCV会议上的一个评测任务，任务是合成街景中的新型视角。", "innovation": "作者团队采用了混合生成方法，结合了高斯插值和扩散模型，分为两个阶段：首先进行3D场景重建并渲染目标相机视角的新图，然后使用定制的单步骤扩散模型提升最终合成的效果。创新点在于提出了特定的初始化高斯原语的方式，并对增强模型进行了微调以及训练数据的优化。", "conclusion": "所提模型在公共排行榜上的综合评分为0.432，总体上取得了第二名的好成绩，通过PSNR、SSIM和LPIPS指标对模型进行了解析，证明了模型在新型城市视图合成中的有效性和优越性。"}
{"llm_update_time": "20251015", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.12376", "html_url": "https://arxiv.org/abs/2510.12376", "title": "深度注意力引导自适应子采样", "title_en": "Deep Attention-guided Adaptive Subsampling", "authors": "Sharath M Shankaranarayana,Soumava Kumar Roy,Prasad Sudhakar,Chandan Aladahalli", "background": "尽管深度神经网络在性能上取得了显著的进展，但这些改进通常伴随着计算复杂性和成本的增加。在诸如3D体素或视频分类等任务中，由于固有的冗余性，并非所有切片或帧都是必要的。", "innovation": "本文提出了一种新颖的学习子采样框架，可以集成到任何神经网络架构中。该框架通过注意力机制实现了输入自适应，在推理阶段动态调整。这不仅改善了性能，还降低了深度神经网络模型的复杂性。相比之下，现有的解诀方法仅任务自适应而不输入自适应，一旦学习机制确定后不会随不同输入调整，不适合实际应用。", "conclusion": "本方法已在3D医学成像数据集MedMNIST3D和两个超声视频数据集上展示了其有效性，其中一个数据集是实际临床条件下收集的具有挑战性的内部数据集。"}
{"llm_update_time": "20251015", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.12385", "html_url": "https://arxiv.org/abs/2510.12385", "title": "通过时空建模在第一人称装配视频中学习识别正确完成的操作步骤", "title_en": "Learning to Recognize Correctly Completed Procedure Steps in Egocentric Assembly Videos through Spatio-Temporal Modeling", "authors": "Tim J. Schoonbeek,Shao-Hsuan Hung,Dan Lehman,Hans Onvlee,Jacek Kustra,Peter H.N. de With,Fons van der Sommen", "background": "过程步骤识别（PSR）旨在识别视频中所有正确完成的操作步骤及其顺序。目前的先进模型仅依赖于检测视频帧中的装配对象状态，忽视了时间特征，导致模型的鲁棒性和准确性受限，尤其是在对象部分被遮挡的情况下。为了解决这些问题，本文提出了时空遮挡鲁棒的步骤识别建模（STORM-PSR），这是一种利用时空特征的双流框架进行PSR的方法。", "innovation": "STORM-PSR 引入了两个流：一个是装配状态检测流，另一个是时空流。时空流包含了一个使用新颖的弱监督方法预训练的空间编码器，以及基于变压器的时间编码器。该模型在 MECCANO 和 IndustReal 数据集上进行评估，与先前方法相比，实际和预测装配步骤完成时间的平均延迟分别减少了11.2%和26.1%。", "conclusion": "STORM-PSR 通过时空流减少了延迟，即使在对象部分被遮挡的情况下也能识别步骤完成。该方法的结果已公开展示，并提供了可公开访问的代码和新的 MECCANO 注释标签。"}
{"llm_update_time": "20251015", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.12387", "html_url": "https://arxiv.org/abs/2510.12387", "title": "场景坐标重建先验", "title_en": "Scene Coordinate Reconstruction Priors", "authors": "Wenjing Bian,Axel Barroso-Laguna,Tommaso Cavallari,Victor Adrian Prisacariu,Eric Brachmann", "background": "场景坐标回归(SCR)模型已被证明是3D视觉的强大隐式场景表示方法，支持视觉重定位和结构恢复。这些模型专门为一个场景进行训练，但如果训练图像未能提供足够的多视图约束，则模型可能会退化。本文的研究背景是探讨如何通过引入高阶重建先验来改进SCR模型的训练方法，使其能够更稳健地学习场景表示，从而提高3D重建的质量和效果，应用于新颖视图合成和相机重定位等下游任务中。", "innovation": "本文提出了一种概率重新解释SCR模型训练的方法，引入了多种重建先验，从简单的深度值分布先验到学习到的可能的场景坐标配置先验。特别是一类基于大型室内扫描点云训练的三维点云扩散模型，通过指导预测的3D场景点向最可能的几何结构转变，从而提高其在每一步的可信度。这种方法不仅提升了场景表示的学习质量，还增强了场景点云的连贯性，提高了相机姿态的准确性，并对新颖视图合成和相机重定位等下游任务产生了积极影响。", "conclusion": "在三项室内数据集上的实验结果表明，本文提出的方法能有效提升3D场景表示的学件质量，生成更一致的场景点云，提高相机重定位的注册率，最终对新型视图合成和相机再定位等下游任务有正面促进作用。"}
{"llm_update_time": "20251015", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.12400", "html_url": "https://arxiv.org/abs/2510.12400", "title": "使用视觉语言模型实现普遍城市监测：综述、评估及研究议程", "title_en": "Towards General Urban Monitoring with Vision-Language Models: A Review, Evaluation, and a Research Agenda", "authors": "André Torneiro,Diogo Monteiro,Paulo Novais,Pedro Rangel Henriques,Nuno F. Rodrigues", "background": "城市公共基础设施（如垃圾箱、道路标志、植被、人行道和建筑工地）的监测面临着多样性对象、环境和情境条件的挑战。当前最先进的技术通常依靠物联网传感器和人工检查，这些方法成本高昂、难以扩展，并且往往与普通市民通过直接视觉观察形成的感知不一致。", "innovation": "视觉语言模型（VLMs）结合了视觉感知与自然语言推理，能有效处理复杂视觉信息，把它们转变为解决城市监测挑战的有前景技术。本文通过回顾32篇2021年至2025年发表的同行评审论文，系统地探讨了VLMs在城市监测中的作用，特别是专注于零样本应用，以回答四个核心问题：（1）哪些城市监测任务已通过VLMs有效解决？（2）哪些VLM架构和框架最常用且表现最佳？（3）哪些数据集和资源支持这新兴领域？（4）基于VLM的应用如何进行评估，以及报告了哪些性能水平？", "conclusion": "本文使用系统研究方法，通过分析32篇文献，评估了视觉语言模型在城市监测中的应用。该研究提出了VLMs的优势和挑战，并指出了未来的研究方向，基于VLM的应用在城市监测中表现出了巨大的潜力。"}
{"llm_update_time": "20251015", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.12444", "html_url": "https://arxiv.org/abs/2510.12444", "title": "纵贯线放射报告生成综述：数据集构成、方法及性能评估", "title_en": "A Review of Longitudinal Radiology Report Generation: Dataset Composition, Methods, and Performance Evaluation", "authors": "Shaoyang Zhou,Yingshu Li,Yunyi Liu,Lingqiao Liu,Lei Wang,Luping Zhou", "background": "胸部X光成像作为一种广泛使用的诊断工具，在现代医学中发挥着重要作用，但由于其高利用率，为放射科医生带来了巨大工作量。传统方法通常是基于单张图像进行医学报告生成，未能捕捉到重要的纵向上下文，导致无法生成临床准确的比较说明。近年来，越来越多的研究开始关注将纵向数据纳入胸部X光报告生成（CXR RRG），使得模型能够借鉴历史研究，模拟放射科医生的工作流程，但现有调查显示，这些方法主要针对单张图像的医学报告生成，对于纵向数据的应用缺乏系统框架。", "innovation": "本研究首次提供了纵贯线放射报告生成（LRRG）的综合评审，研究了数据集构建策略、报告生成架构及其纵向特定设计，以及评估标准，包括纵向特定指标和广泛使用的基准措施。此外，总结了LRRG方法的性能，分析了不同消融研究，突出了纵向信息和架构设计选择对模型性能提升的关键作用。", "conclusion": "研究指出了当前研究中的五个主要局限性，并提出了未来发展的前景方向，旨在为这一新兴领域的进一步发展奠定基础。"}
{"llm_update_time": "20251015", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.12422", "html_url": "https://arxiv.org/abs/2510.12422", "title": "VideoLucy：长视频理解中的深层次记忆回溯", "title_en": "VideoLucy: Deep Memory Backtracking for Long Video Understanding", "authors": "Jialong Zuo,Yongtai Deng,Lingdong Kong,Jingkang Yang,Rui Jin,Yiwei Zhang,Nong Sang,Liang Pan,Ziwei Liu,Changxin Gao", "background": "最近的研究表明，利用大规模语言模型（LLMs）进行关键信息检索和整合的基于代理系统的架构，有望成为理解长时间视频的有力方法。然而，这些系统面临两大挑战：首先，它们通常在单帧上进行建模和推理，难以捕捉连续帧之间的临时上下文；其次，为了减少密集帧级字幕的成本，它们采用了稀疏的帧采样策略，这可能导致关键信息的丢失。", "innovation": "为克服这些限制，本文提出了VideoLucy，一个深层记忆回溯框架。受到人类回忆过程从粗到细的启发，VideoLucy采用分层记忆结构，具有渐进的粒度。通过基于代理的迭代回溯机制，VideoLucy系统性地挖掘视频范围内与问题相关的深度记忆，直到收集到足够的信息以提供一个可信的答案。这一设计使得VideoLucy能够在保持关键细节的同时有效理解连续帧的时间上下文。此外，还提出了EgoMem，这是一个用于评估模型在复杂事件理解以及长时间视频中捕捉细粒度细节能力的新基准数据集。广泛的实验表明，VideoLucy在多个长时间视频理解基准中显著优于现有最先进的方法，甚至超过了最新的专有模型如GPT-4o。", "conclusion": "实验结果表明，基于开源模型的VideoLucy在多个长视频理解基准测试中表现出色，其性能甚至超过了最新的专有模型。我们的代码和数据集将在以下链接公开：this https URL"}
{"llm_update_time": "20251015", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.12482", "html_url": "https://arxiv.org/abs/2510.12482", "title": "具有数据增强能力的文本-图像融合方法在引用医学图像分割中的应用", "title_en": "A Text-Image Fusion Method with Data Augmentation Capabilities for Referring Medical Image Segmentation", "authors": "Shurong Chai,Rahul Kumar JAIN,Rui Xu,Shaocong Mo,Ruibo Hou,Shiyu Teng,Jiaqing Liu,Lanfen Lin,Yen-Wei Chen", "background": "深度学习依赖大量数据以提高模型性能，尤其是在医学图像领域。现有的多模态学习将文本和图像结合用于分割，称为引用或文本指导图像分割。然而，常见的数据增强方法（如旋转和翻转）会破坏图像和文本之间的空间对齐，降低模型性能。为解决该问题，本文提出了一种在增强之前融合文本和视觉特征的早期融合框架，以保持空间一致性。同时，设计了一个轻量级生成器将文本嵌入投影到视觉空间，填补语义差距。生成的伪图像可视化显示了准确的区域定位。该方法在三个医学成像任务和四个分割框架上进行了评估，取得了最先进的性能。代码已在GitHub上公开发布，链接见文末。", "innovation": "1. 一种在数据增强之前融合文本和视觉特征的早期融合框架，以保持空间一致性；2. 设计了一个轻量级生成器将文本嵌入投影到视觉空间，填补语义差距；3. 在三个医学成像任务和四个分割框架上取得了最先进的性能。", "conclusion": "该方法在引用医学图像分割任务上取得了优秀的表现，通过早期融合和轻量级生成器增强了模型的鲁棒性和准确性。"}
{"llm_update_time": "20251015", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.12468", "html_url": "https://arxiv.org/abs/2510.12468", "title": "MS-GAGA: 具有度量选择性引导生成对抗攻击", "title_en": "MS-GAGA: Metric-Selective Guided Adversarial Generation Attack", "authors": "Dion J. X. Ho,Gabriel Lee Jun Rong,Niharika Shrivastava,Harshavardhan Abichandani,Pai Chet Ng,Xiaoxiao Miao", "background": "本文介绍了一种名为MS-GAGA（Metric-Selective Guided Adversarial Generation Attack）的双阶段框架，旨在针对黑色盒环境中深度伪造检测器生成具有转移性和视觉不可察觉性的对抗样本。在第一阶段，使用一种双流攻击模块生成对抗候选样本：MNTD-PGD优化了微小扰动预算下的梯度计算，而SG-PGD则专注于视觉显著区域的扰动。这种互补设计扩展了对抗搜索空间，并提高了跨未见模型的转移性。在第二阶段，使用一个具有度量意识的选择模块，根据对外部黑盒子模型的成功率及其与原始图像的结构相似度（SSIM）来评估候选样本。通过同时优化转移性和不可察觉性，MS-GAGA在未见过的检测器上实现了比最先进的攻击方式高达27%的错误分类率提升。", "innovation": "本文的创新之处在于提出了MS-GAGA框架，通过双阶段流程生成对抗样本，提升了对抗样本的转移性能并保持了视觉不可察觉性。具体创新包括：（1）第一阶段使用MNTD-PGD和SG-PGD生成更加高效和针对性的候选样本；（2）第二阶段使用度量意识的选择模块，确保生成的对抗样本在对抗性和不可感知性方面的均衡；（3）共同优化了转移性和不可感知性，使生成的对抗样本在未见过的检测器上表现出更优的效果。", "conclusion": "MS-GAGA框架在未见过的深度伪造检测器上达到了27%的相对更高的错误分类率，展示了其在对抗样本攻击中的强健性和有效性，提升了对抗样本攻击的策略和手段，对未来的深度伪造防御系统具有重要意义。"}
{"llm_update_time": "20251015", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.12524", "html_url": "https://arxiv.org/abs/2510.12524", "title": "从无向点云计算未符号距离场的Voronoi辅助扩散", "title_en": "Voronoi-Assisted Diffusion for Computing Unsigned Distance Fields from Unoriented Points", "authors": "Jiayi Kong,Chen Zong,Junkai Deng,Xuhui Chen,Fei Hou,Shiqing Xin,Junhui Hou,Chen Qian,Ying He", "background": "未符号距离场(UDFs)为任意拓扑的3D形状提供了一种灵活的表示方式，包括开表面、闭表面、可定向和不可定向的几何结构以及非流形结构。尽管最近的神经网络方法在学习UDFs方面显示出潜力，但它们经常遭受数值不稳定、高计算成本和可控性有限的问题。", "innovation": "本文提出了一种轻量级、无网络的方法，Voronoi辅助扩散(VAD)，可以直接从无向点云计算UDFs。该方法通过对输入点赋予双向法线，使用由能量函数编码的两个基于Voronoi的几何准则进行最优对齐。然后，对齐的法线扩散形成一个近似的UDF梯度场，再对其进行积分以恢复最终的UDF。实验表明，VAD能够稳健地处理封闭和开放表面，以及复杂的非流形和非定向几何结构，同时保持计算效率和稳定性。", "conclusion": "本文提出的VAD方法可以稳健地处理各种复杂的3D结构，同时保持计算效率和稳定性。这种方法为UDFs的计算提供了一种有效的、无网络的方法，改进了现有的数值稳定性和可控性问题。"}
{"llm_update_time": "20251015", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.12560", "html_url": "https://arxiv.org/abs/2510.12560", "title": "CoIRL-AD: Collaborative-Competitive Imitation-Reinforcement Learning in Latent World Models for Autonomous Driving", "title_en": "CoIRL-AD: Collaborative-Competitive Imitation-Reinforcement Learning in Latent World Models for Autonomous Driving", "authors": "Xiaoji Zheng,Ziyuan Yang,Yanhao Chen,Yuhang Peng,Yuanrong Tang,Gengyuan Liu,Bokui Chen,Jiangtao Gong", "background": "传统的端到端自主驾驶模型依赖于模仿学习（IL），但在泛化能力方面表现不佳。相比之下，强化学习（RL）通过奖励最大化促进探索，但其样本效率低且收敛不稳定。", "innovation": "提出了一种名为CoIRL-AD的竞合双策略框架，使其能够使IL和RL代理在训练过程中相互作用。通过引入一种基于竞争的机制，促进知识交流，防止梯度冲突。", "conclusion": "实验结果表明，CoIRL-AD在nuScenes数据集上的碰撞率降低了18%，具有更强的泛化能力和在长尾场景上的改进性能。相关代码可从链接处获取。"}
{"llm_update_time": "20251015", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.12362", "html_url": "https://arxiv.org/abs/2510.12362", "title": "CurriFlow: 以光流为基础的时序对齐与课程指导下的深度融合进行3D语义场景完整化", "title_en": "CurriFlow: Curriculum-Guided Depth Fusion with Optical Flow-Based Temporal Alignment for 3D Semantic Scene Completion", "authors": "Jinzhou Lin,Jie Zhou,Wenhao Xu,Rongtao Xu,Changwei Wang,Shunpeng Chen,Kexue Fu,Yihua Shao,Li Guo,Shibiao Xu", "background": "语义场景完成（SSC）旨在从单目图像中推断出完整的3D几何结构和语义信息，这对于自主驾驶中的相机感知至关重要。然而，现有的SSC方法依赖于时间堆叠或深度投影，常常缺乏显式的运动推理能力，难以处理遮挡和噪声深度监督带来的问题。", "innovation": "提出了一种名为CurriFlow的新颖语义占用预测框架，将基于光流的时间对齐与课程指导下的深度融合相结合。该框架通过多级融合策略在帧间对分割、视觉和深度特征进行对齐，增强了时间一致性和动态物体理解。此外，通过课程学习机制，在训练过程中逐步从稀疏但准确的LIDAR深度过渡到密集但噪声较大的视差深度，确保优化的稳定性和适应实际部署的无缝过渡。", "conclusion": "在SemanticKITTI基准测试中的实验表明，CurriFlow实现了最先进的性能，均方误差IoU为16.9，证实了我们的运动引导和课程感知设计对基于相机的3D语义场景完整化的有效性。"}
{"llm_update_time": "20251015", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.12537", "html_url": "https://arxiv.org/abs/2510.12537", "title": "通过平衡评分基于扩散模型实现无条件的人体运动和形状生成", "title_en": "Unconditional Human Motion and Shape Generation via Balanced Score-Based Diffusion", "authors": "David Björkstrand,Tiesheng Wang,Lars Bretzner,Josephine Sullivan", "background": "近年来，有人探索了多种模型家族用于人体运动生成，包括变分自动编码器（VAE）、生成对抗网络（GAN）和基于扩散的模型。尽管这些方法存在差异，许多方法依赖于过度参数化的输入特征和辅助损失来提高实证结果。然而，这些策略并非基于扩散模型达到人类运动分布的效果所必需。研究表明，仅通过精心的空间特征归一化和直接从标准 L2 分数匹配损失中得出的可分析权重，就能在无条件的人体运动生成中达到与现有最佳结果相当的效果，同时直接生成运动和形状，并避免从关节后期恢复形状的慢速步骤。", "innovation": "本方法通过平衡的评分基于扩散模型直接生成人体运动和形状，不依赖于过参数化输入特征和辅助损失。与传统方法不同，此方法通过精心的空间特征归一化和直接从标准 L2 分数匹配损失中得出的可分析权重，达到与现有最佳结果相当的效果。", "conclusion": "该研究方法逐步建立，每个组成部分都有明确的理论动机，并通过有针对性的消融实验展示了每项提议的增加的独立有效性。"}
{"llm_update_time": "20251015", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.12573", "html_url": "https://arxiv.org/abs/2510.12573", "title": "利用时序条件Mamba学习人类运动", "title_en": "Learning Human Motion with Temporally Conditional Mamba", "authors": "Quang Nguyen,Tri Le,Baoru Huang,Minh Nhat Vu,Ngan Le,Thieu Vo,Anh Nguyen", "background": "基于时变输入信号学习人类运动是一项具有挑战性但极具影响力的任务，具有多种应用。该任务的目标是生成或估计能够一致反映条件输入时间模式的人类运动。现有的方法通常依赖于交叉注意力机制来融合条件信息和动作信息，但这种方法主要捕获全局交互而不善于维持逐个时间步的临时对齐。", "innovation": "为了克服现有方法的主要局限性，我们提出了一个新的基于Mamba的模型——时空条件Mamba。该模型将条件信息整合到Mamba模块的递归动态中，从而可以更好地实现运动的时间对齐。", "conclusion": "通过在多种人类运动任务上的广泛实验，我们的方法证明了在全球对齐方面显著提高了时间对齐、动作真实性和条件一致性，并比最先进的方法有显著提高。项目页面详见this https URL"}
{"llm_update_time": "20251015", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.12565", "html_url": "https://arxiv.org/abs/2510.12565", "title": "MMOT: 无人机多光谱多目标跟踪的第一个具有挑战性的基准", "title_en": "MMOT: The First Challenging Benchmark for Drone-based Multispectral Multi-Object Tracking", "authors": "Tianhao Li,Tingfa Xu,Ying Wang,Haolin Qin,Xu Lin,Jianan Li", "background": "无人机上的基于多光谱的多目标跟踪对于小目标、严重遮挡和复杂背景具有重要意义，但同时这些因素也使得任务非常具有挑战性。现有的基于RGB的跟踪算法依赖于空间外观特征，如颜色和纹理，但在空中视角下性能较差，影响了系统的可靠性。与之相比，多光谱图像能够捕捉像素级的光谱反射率，从而在退化的空间条件下增强目标的可辨识性。然而，缺乏专门的多光谱无人机数据集阻碍了该领域的发展。", "innovation": "本文引入了MMOT，这是首个用于无人机多光谱多目标跟踪的具有挑战性的基准。MMOT具有三个关键特性：1）大规模数据集 - 125个视频序列，包含超过488.8万个注释，跨越八大类别；2）全面挑战 - 包括不同条件，如极端小目标、高密度场景、严重遮挡和复杂运动；3）精确导向注释 - 在空中视角下提供准确的定位并减少混淆。此外，本文还提出了一种多光谱和定向感知的多目标跟踪方案，结合现有方法，包括3D光谱干茎（Spectral 3D-Stem）、基于定向的Kalman滤波器以及端到端的定向适应性变压器。", "conclusion": "大量的实验结果表明，多光谱输入可以显著提高跟踪性能，特别是在小目标和高密度对象场景中。本研究预计将进一步推动无人机多光谱多目标跟踪研究的发展。MMOT、代码和基准已经公开提供。"}
{"llm_update_time": "20251015", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.12581", "html_url": "https://arxiv.org/abs/2510.12581", "title": "LayerSync: 自身对齐的中间层", "title_en": "LayerSync: Self-aligning Intermediate Layers", "authors": "Yasaman Haghighi,Bastien van Delft,Mariam Hassan,Alexandre Alahi", "background": "先前研究指出，生成模型的质量与其所学习的表示之间存在联系，并且外部指导能提高模型中间表示的质量，从而加速训练过程。然而，目前的方法大多依赖外部指导，论文方法通过使用模型自身的中间表示来实现自我规范，进一步提高生成质量和训练效率。", "innovation": "本文提出了一种名为LayerSync的方法，通过自我规范扩散模型的中间表示，提高生成质量和训练效率。该方法利用了不同层的表示质量差异，让更具语义的信息为较弱的部分提供内在指导，无需额外的数据或预训练模型。并且该方法适用于视觉以外的其他模态。", "conclusion": "该方法在图像生成任务上进行了广泛测试，证明了其在其他领域（如音频、视频、运动生成）的适用性。结果表明，它能显著提高生成质量和训练效率，例如在Imagenet数据集上加速流式转换器的训练超过8.75倍，并提高了生成质量23.6%。代码已在相关链接提供。"}
{"llm_update_time": "20251015", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.12579", "html_url": "https://arxiv.org/abs/2510.12579", "title": "使用植物网智能解锁零样本植物分割", "title_en": "Unlocking Zero-Shot Plant Segmentation with Pl@ntNet Intelligence", "authors": "Simon Ravé,Jean-Christophe Lombardo,Pejman Rasti,Alexis Joly,David Rousseau", "background": "本文介绍了一种针对农业图像的零样本分割方法，该方法结合了Plantnet这一大型植物分类模型及其DinoV2骨干网络和Segment Anything Model (SAM)。基于Plantnet强大的植物特征表示，该方法不需新收集和标注数据集，而是直接利用Plantnet模型对植物区域进行识别，并生成粗略的分割掩码。随后，SAM对这些掩码进行精细处理，以实现详细的分割。本文在四个不同复杂度的公共农业图像数据集上进行了评估，其中包括由于训练数据量有限和复杂环境条件导致传统监督方法效果不佳的数据集。", "innovation": "该方法的核心创新在于利用了Plantnet模型的专业知识，无需额外的数据收集和标注工作即可实现植物区域的识别和分割。通过比较基础的DinoV2模型与经过Plantnet微调的DinoV2模型的性能，本文展示了在多种复杂性数据集上，使用微调后的DinoV2模型能够得到更好的Jaccard Index（交并比）结果，即获得了更一致的性能改进。", "conclusion": "该研究证明了结合基础模型与面向植物的特定模型在农业场景中进行有效分割的潜力，能够缓解标注数据量不足的问题。未来的研究有望通过更深入地利用这些模型的独特功能，实现更加精确和适用的农业图像分割技术。"}
{"llm_update_time": "20251015", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.12408", "html_url": "https://arxiv.org/abs/2510.12408", "title": "使用条件流匹配模型增强低场磁共振图像质量", "title_en": "Low-Field Magnetic Resonance Image Quality Enhancement using a Conditional Flow Matching Model", "authors": "Huu Tien Nguyen,Ahmed Karam Eldaly", "background": "低场磁共振成像（LF-MRI）是一种迅速发展的成像技术，具有低成本和便携性的优势，但由于其固有的信噪比低和诊断质量降低的问题，导致其存在不足。目前的生成模型依赖于迭代采样或对抗目标，无法有效解决这一问题。本文在LF-MRI场景下，提出了基于条件流匹配（CFM）的图像质量传递新框架，旨在在不需要昂贵基础设施的情况下，通过将低场输入重建为高场类似图像，来缩小图像质量的差距。", "innovation": "本文提出了一种基于条件流匹配的新框架，能够直接回归最优速度场，实现从噪声分布到目标数据分布的连续流学习。这一方法无需迭代采样或对抗目标，且参数量显著少于竞争的深度学习方法，同时在分布内和分布外数据上都能稳健泛化。这表明CFM作为一种强大的、可扩展的工具，在资源有限的临床环境中具有很高的潜在价值。", "conclusion": "实验结果表明，CFM不仅在性能上达到最先进的水平，而且能够稳健地应用于分布内和分布外数据。此外，相较于其他竞争的深度学习方法，CFM使用了显著较少的参数。这些结果强调了CFM在MRI重建领域的巨大潜力，特别是在资源受限的临床环境中。"}
{"llm_update_time": "20251015", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.12603", "html_url": "https://arxiv.org/abs/2510.12603", "title": "在黑暗中推理：隐空间中的交错视觉-文本推理", "title_en": "Reasoning in the Dark: Interleaved Vision-Text Reasoning in Latent Space", "authors": "Chao Chen,Zhixin Ma,Yongqi Li,Yupeng Hu,Yinwei Wei,Wenjie Li,Liqiang Nie", "background": "多模态推理旨在通过在最终答案前加入中间推理步骤来增强MLLM的能力。它从仅基于文本的推理发展到了结合视觉信息的集成，使得思想过程可以通过图像和文本来表达。然而，当前的多模态推理方法依赖于需要大量视觉-文本标注且不可避免地增加推理延迟的显式推理步骤。", "innovation": "该研究提出了多模态隐空间推理方法，分为两个方面：一是提出了交错视觉-文本隐空间推理（IVT-LR）模型，它在隐空间中结合视觉和文本信息，用隐文本来表示上一步骤的隐藏状态，并用选定的图像嵌入表示视觉信息；二是提出了一种渐进的多阶段训练策略，有助于MLLM执行上述多模态隐空间推理步骤。", "conclusion": "实验结果表明，IVT-LR方法在M3CoT和ScienceQA上实现了5.45%的平均准确率提升，并且其推理速度比现有方法快5倍以上。"}
{"llm_update_time": "20251015", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.12605", "html_url": "https://arxiv.org/abs/2510.12605", "title": "WaterFlow：显式物理先验校正流在水下显著性掩膜生成中的应用", "title_en": "WaterFlow: Explicit Physics-Prior Rectified Flow for Underwater Saliency Mask Generation", "authors": "Runting Li,Shijie Lian,Hua Li,Yutong Li,Wenhui Wu,Sam Kwong", "background": "水下显著目标检测（USOD）面临着显著挑战，包括水下成像质量的下降和领域差距。现有的方法通常会忽略水下成像的物理原理，或者简单地将水下图像中的退化现象视为必须消除的干扰因素，未能充分挖掘其中包含的有价值信息。", "innovation": "我们提出了WaterFlow，这是一种校正流为基础的框架，用于水下显著目标检测。该框架创新性地将水下物理成像信息明确作为先验直接纳入网络训练过程中，并引入时间维度建模，显著增强了模型的显著目标识别能力。", "conclusion": "在USOD10K数据集上，WaterFlow实现了0.072的S_m增益，展示了我们方法的有效性和优越性。代码将在接收后发布。"}
{"llm_update_time": "20251015", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.12493", "html_url": "https://arxiv.org/abs/2510.12493", "title": "BSGS: 双阶段3D 高斯点绘方法用于相机运动去模糊", "title_en": "BSGS: Bi-stage 3D Gaussian Splatting for Camera Motion Deblurring", "authors": "An Zhao,Piaopiao Yu,Zhe Zhu,Mingqiang Wei", "background": "3D高斯点绘在3D场景重建中显示出卓越的能力，但对于由于摄像机运动引起的运动模糊图象的高分辨率3D场景重建，现有的3D高斯点绘（3DGS）去模糊方法受限于其固有机制，如对摄像机姿态高度依赖且难以有效控制由运动引起的错误高斯点稠密化现象。", "innovation": "我们提出了一种名为双阶段3D高斯点绘（Bi-Stage 3D Gaussian Splatting, BSGS）的新框架，该框架包含两个阶段。首阶段为摄像机姿态细化阶段，粗略优化摄像机姿态以减少由运动引起的畸变。第二阶段为全局刚体变换阶段，在固定粗略摄像机姿态的情况下进一步纠正由运动引起的模糊。为了缓解多个子帧梯度冲突，我们提出了子帧梯度聚合策略以同时优化这两阶段。同时，我们引入了一种基于空间-时间双阶段优化策略，以动态调整高斯点稠密化阈值并防止在模糊区域过早生成噪点的高斯。全面的实验证明了我们提出的去模糊方法的有效性，并展示了其在与最先进的方法相比的优势。", "conclusion": "通过提出双阶段3D高斯点绘方法，我们解决了现有3D高斯点绘去模糊方法中的问题，实现了从具有运动模糊的图像中精确重建3D场景。我们的方法提高了去模糊的准确性和效果，并在实际测试中优于现有方法。"}
{"llm_update_time": "20251015", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.12646", "html_url": "https://arxiv.org/abs/2510.12646", "title": "Zero-Shot CFC: 快速基于交叉频率一致性的实时图像降噪", "title_en": "Zero-Shot CFC: Fast Real-World Image Denoising based on Cross-Frequency Consistency", "authors": "Yanlin Jiang,Yuchen Liu,Mingren Liu", "background": "现有的零样本去噪方法在噪声独立性和零均值假设上存在限制，导致在实际应用场景中的效果不佳，而且其训练时间过长。研究指出现有的去噪方法依赖于噪声独立性和零均值的假设，但实际噪声特性更为复杂，无法满足这些假设，影响了实际噪声去除的效果和效率。科研人员致力于解决这一问题，希望发展一种能够处理复杂噪声且训练快速的方法来改善实际环境中的去噪效果。", "innovation": "本文提出了一种高效的基于交叉频率一致性的零样本去噪方法（Zero-Shot denoiser based on Cross-Frequency Consistency, ZSCFC），该方法通过单一噪声图像进行训练和去噪，并不需要关于噪声分布的假设。该方法利用图像在不同频率下纹理和内容的一致性和噪声的不一致性的特征，开发了一种跨频率一致性损失和超轻量化网络，实现了图像去噪。实验表明该方法在计算效率和去噪性能上优于其他现有的零样本去噪方法，有效解决了图像去噪中的实际问题。", "conclusion": "本文提出了一种新颖高效的零样本去噪方法 ZSCFC，该方法利用图像在不同频率下的频率一致性特征，实现了无需假设的图像去噪，提高了去噪的实际效果和计算效率，使其实现在复杂噪声条件下的快速应用。"}
{"llm_update_time": "20251015", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.12660", "html_url": "https://arxiv.org/abs/2510.12660", "title": "关于使用分级视觉基础模型进行低成本人体网格恢复和姿态估计的研究", "title_en": "On the Use of Hierarchical Vision Foundation Models for Low-Cost Human Mesh Recovery and Pose Estimation", "authors": "Shuhei Tarashima,Yushan Wang,Norio Tagawa", "background": "现有的最先进的人体网格恢复（HMR）方法，如HMR2.0及其后续版本，依赖于大型且非分层的视觉变换器作为编码器。这些编码器源自相应的HPE模型，如ViTPose。为了在不同计算预算下建立基准，首先构建了三个基于HMR2.0的轻量级变体，并且引入了分层视觉基础模型（VFMs）的早期阶段，如Swin Transformer、GroupMixFormer和VMamba作为编码器。这一设计基于观察到分层VFMs的中间阶段生成的特征图的解析度与或高于非分层模型的解析度。", "innovation": "创新之处在于，通过使用分层视觉基础模型（如Swin Transformer、GroupMixFormer和VMamba）的早期阶段来作为HMR和HPE的编码器，并且实验表明，在仅使用前两个或三个阶段时，能达到与全阶段模型相当的性能，同时提供更好的准确性和计算效率之间的折衷方案。", "conclusion": "研究通过对27个基于分层VFMs的HMR和HPE模型进行了全面评估，证明了使用分层VFMs早期阶段生成的模型，在准确性和计算效率之间提供了更好的折衷，并且性能可与全阶段模型媲美。"}
{"llm_update_time": "20251015", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.12679", "html_url": "https://arxiv.org/abs/2510.12679", "title": "MCOP: 多无人机协作占用预测", "title_en": "MCOP: Multi-UAV Collaborative Occupancy Prediction", "authors": "Zefu Lin,Wenbo Chen,Xiaojuan Jin,Yuran Yang,Lue Fan,Yixin Zhang,Yufeng Zhang,Zhaoxiang Zhang", "background": "无人机蜂群系统需要高效的协作感知机制以应对多种操作场景。当前基于顶视图（BEV）的方法存在两个主要局限性：边界框表示法无法捕捉场景的完整语义和几何信息，且在遇到未定义或被遮挡的对象时性能显著下降。", "innovation": "提出了一种新颖的多无人机协作占用预测框架。该框架通过整合空间感知特征编码器和跨代理特征集成，有效地保留了3D空间结构和语义。进一步引入高度感知特征降维来紧凑表示场景信息，并采用双重掩码感知指导机制以自适应选择特征并减少通信开销。", "conclusion": "由于缺乏合适的基准数据集，提出方法在扩展的三个数据集（虚拟的Air-to-Pred-Occ、UAV3D-Occupancy以及真实的GauUScene-Occ）进行评估。实验结果显示，方法能达到最先进的准确性，相比现有协作方法显著提高性能并仅将通信开销减少到以前方法的一小部分。"}
{"llm_update_time": "20251015", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.12586", "html_url": "https://arxiv.org/abs/2510.12586", "title": "通过自我监督预训练提升端到端像素空间生成建模", "title_en": "Advancing End-to-End Pixel Space Generative Modeling via Self-supervised Pre-training", "authors": "Jiachen Lei,Keli Liu,Julius Berner,Haiming Yu,Hongkai Zheng,Jiahong Wu,Xiangxiang Chu", "background": "像素空间的生成模型通常比其潜在空间的对应物更难训练，并且在性能上通常不如后者。这导致了在性能和效率方面持续的差距。在本研究中，作者提出了一种新颖的两阶段训练框架，用于缩小像素空间扩散和一致性模型的性能差距。第一阶段，作者预训练编码器以从干净的图像中捕捉有意义的语义，并使它们与同一确定性采样轨迹上的点对齐，该轨迹将先验点演化到数据分布。第二阶段，作者将编码器与随机初始化的解码器相结合，并对完整的模型进行端到端微调，以同时训练扩散和一致性模型。该研究在ImageNet数据集上展示了强大的实证性能，特别是在生成质量和效率方面显著超越了之前的像素空间方法，同时还与类似于基于VAE的模型在可比较的训练成本下竞争。此外，在ImageNet-256数据集上，作者的单一采样步骤的一致性模型达到了令人印象深刻的成绩，即FID为8.82，远超过其潜在空间的对应物。据所知，这是首次成功直接在高分辨率图像上训练一致性模型，而无需依赖于预训练的VAE或扩散模型。因此，进一步推动了端到端像素空间生成建模的进步", "innovation": "提出了一种新颖的两阶段训练框架，用于缩小像素空间扩散和一致性模型的性能差距。第一阶段预训练编码器以从干净的图像中捕捉有意义的语义，并使它们与同一确定性采样轨迹上的点对齐。第二阶段将编码器与随机初始化的解码器相结合，并对完整的模型进行端到端微调，以同时训练扩散和一致性模型。该研究展示了在生成质量和效率方面显著超越了之前的像素空间方法，同时还与类似于基于VAE的模型在可比较的训练成本下竞争，特别是在高分辨率图像的一致性模型训练方面的突破。", "conclusion": "该研究的训练框架在ImageNet数据集上展示了强大的实证性能，特别是在生成质量和效率方面显著超越了之前的像素空间方法，同时还与类似于基于VAE的模型在可比较的训练成本下竞争。在ImageNet-256数据集上，作者的一致性模型达到了令人印象深刻的成绩，即FID为8.82，远超过其潜在空间的对应物。据所知，这是首次成功直接在高分辨率图像上训练一致性模型，而无需依赖于预训练的VAE或扩散模型。"}
{"llm_update_time": "20251015", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.12670", "html_url": "https://arxiv.org/abs/2510.12670", "title": "TerraCodec：压缩地球观测数据", "title_en": "TerraCodec: Compressing Earth Observations", "authors": "Julen Costa-Watanabe,Isabelle Wittmann,Benedikt Blumenstiel,Konrad Schindler", "background": "地球观测(EO)卫星产生大量多光谱图像时间序列数据，这对存储和传输构成了严峻挑战。尽管机器学习驱动的EO压缩技术得到了发展，但仍存在缺乏公开预训练模型和与自然图像压缩技术不匹配的问题。现有的图像编码器忽视了时间冗余，而视频编码器依赖于运动先验，这些对包含大量静止场景的辐射度演化捕捉不充分。", "innovation": "本文引入了TerraCodec（TEC），这是一种针对EO特制的机器学习编码器家族，包括适应多光谱输入的高效图像变体以及利用时间跨域依赖性的Temporal Transformer模型（TEC-TT）。为了克服现有神经网络编码器的固定比特率设置，本文还提出了一种名为Latent Repacking的新方法，用于训练可在不同比特率-失真设置下操作的可变比特率变压器模型。实验表明，Tec在Sentinel-2数据上的压缩效果优于传统的编码器，能够在保持图像质量的同时实现3-10倍的压缩率。此外，TEC-TT能够实现无监督云遮挡修复，超越了现有方法在AllClear基准上的表现。", "conclusion": "本文的结果表明，定制化学习压缩算法是地球观测领域的一个有前景的研究方向。TEC及其变体将在宽松的许可协议下提供代码和模型权重。"}
{"llm_update_time": "20251015", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.12687", "html_url": "https://arxiv.org/abs/2510.12687", "title": "EReLiFM: Evidential Reliability-Aware Residual Flow Meta-Learning for Open-Set Domain Generalization under Noisy Labels", "title_en": "EReLiFM: Evidential Reliability-Aware Residual Flow Meta-Learning for Open-Set Domain Generalization under Noisy Labels", "authors": "Kunyu Peng,Di Wen,Kailun Yang,Jia Fu,Yufan Chen,Ruiping Liu,Jiamin Wu,Junwei Zheng,M. Saquib Sarfraz,Luc Van Gool,Danda Pani Paudel,Rainer Stiefelhagen", "background": "Open-set domain generalization (OSDG)旨在使深度学习模型能够识别新域中的未见过的类别，这对于实际应用至关重要。标签噪声破坏了OSDG，因为它会污染源域的知识，使得识别已知类别和拒绝未见过的类别变得更加困难。现有的方法通过超球面原型引导的元学习解决了带噪声标签（OSDG-NL）的OSDG问题，但它们难以弥合域间差距，特别是在只有有限的清理标记数据的情况下。", "innovation": "本文提出了一种新的方法，称为Evidential Reliability-Aware Residual Flow Meta-Learning（EReLiFM）。该方法首先引入了一个无监督的两阶段证据损失聚类方法，以促进标签可靠性意识。然后提出了一种残差流匹配机制，通过建模结构化的域条件和类别条件残差，使模型能够进行多样性和不确定性感知的转移，而不仅仅是基于插值的增强。在元学习过程中，模型通过最大化噪声集上的损失减少来优化清洁集上的更新方向，使用最自信预测类别的伪标签作为监督。", "conclusion": "实验结果显示，EReLiFM在OSDG-NL任务中优于现有方法，并达到了最先进的性能。源代码可以在以下网址获取：this https URL。"}
{"llm_update_time": "20251015", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.12741", "html_url": "https://arxiv.org/abs/2510.12741", "title": "视觉基础模型在医疗保健中的个性化 federated 细调", "title_en": "Personalized Federated Fine-Tuning of Vision Foundation Models for Healthcare", "authors": "Adam Tupper,Christian Gagné", "background": "基础模型为AI在医疗领域的应用开辟了新可能，但即使预训练于健康数据，仍需针对特定下游任务进行微调。尽管基础模型减少了所需训练数据量以达到良好性能，获取足够数据仍然是一个挑战，这主要由于不同来源的数据在共享和聚合时对患者隐私的限制。一种可能的解决方案是通过联邦学习在多个参与客户端（例如，医院、诊所等）之间对基础模型进行个性化微调。", "innovation": "提出了一种新的个性化联邦微调方法，用于学习正交LoRA适配器以解耦一般的和客户端特定的知识，使每个客户端能够充分利用其自己的数据和其他客户端的数据。", "conclusion": "在实际 federated 医学影像任务上的初步结果表明，作者的方法在当前的联邦微调方法中具有竞争力。"}
{"llm_update_time": "20251015", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.12712", "html_url": "https://arxiv.org/abs/2510.12712", "title": "超越视觉：评估多模态大语言模型在工具赋能图像感知、变换和推理方面的表现", "title_en": "Beyond Seeing: Evaluating Multimodal LLMs on Tool-Enabled Image Perception, Transformation, and Reasoning", "authors": "Xingang Guo,Utkarsh Tyagi,Advait Gosai,Paula Vergara,Ernesto Gabriel Hernández Montoya,Chen Bo Calvin Zhang,Bin Hu,Yunzhong He,Bing Liu,Rakshith Sharma Srinivasa", "background": "在现实场景中，用户提供的图像常有缺陷，需要进行裁剪、编辑或增强来揭示关键视觉线索。除了静态视觉感知，多模态大语言模型还需要能够动态地处理和变换图像，并将图像与其他工具整合起来解决复杂的任务。然而，从将视觉视为被动背景转变为一个可操作的认知工作空间的研究还较少。现有的大多数基准测试仍遵循静态图像分析的模式，即只视图像为静态输入。因此，有必要引入新的基准测试来评估多模态大语言模型在处理动态图像和与工具互动方面的能力。", "innovation": "我们提出了一种名为IRIS的基准测试，即Interactive Reasoning with Images and Systems（交互式图像与系统推理），用于评估多模态大语言模型在复杂的视觉-文本任务中感知、变换和推理的能力，以支持“通过图像思考”的模式。IRIS包含1204个具有挑战性的开放性任务（包括603个单轮和601个多轮任务），涉及到五个不同的领域，每个任务都配有详细的评估标准。它首次提供了一个以工具赋能图像感知、变换和推理为核心的基准测试，揭示了现有模型在这些任务上的表现和工具使用差异。", "conclusion": "当前的多模态大语言模型在图像与通用工具的有效整合方面表现不佳，即使最强的模型（GPT-5-think）也只能通过18.68%的任务。IRIS提供了对图像认知在多模态大语言模型发展中关键洞见，强调了更多与工具互动和复杂任务处理的研究价值。"}
{"llm_update_time": "20251015", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.12704", "html_url": "https://arxiv.org/abs/2510.12704", "title": "基于Transformer的胸部X射线诊断的混合解释引导学习", "title_en": "Hybrid Explanation-Guided Learning for Transformer-Based Chest X-Ray Diagnosis", "authors": "Shelley Zixin Shu,Haozhe Luo,Alexander Poellinger,Mauricio Reyes", "background": "基于Transformer的深度学习模型在医疗成像中表现卓越，通过注意力机制提高特征表示和可解释性。然而，这些模型易于学习不相关信息，导致偏见和泛化能力受限。虽然人类与AI注意力对齐可以缓解这些问题，但它通常依赖于昂贵的手动监督。", "innovation": "提出了一种混合解释引导学习（H-EGL）框架，结合自我监督和人类引导的约束来增强注意力对齐并提高泛化能力。该自我监督部分使用类特定注意力不依赖于限制性先验，增强鲁棒性和灵活性。在胸部X射线分类实验中，H-EGL优于两种最先进的解释引导学习（EGL）方法，显示了更好的分类准确性和泛化能力，并生成与人类专业知识更一致的注意力图。", "conclusion": "H-EGL框架通过结合自我监督和人类引导的约束，有效提升了基于Transformer的胸部X射线诊断模型的注意力对齐和泛化能力。"}
{"llm_update_time": "20251015", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.12747", "html_url": "https://arxiv.org/abs/2510.12747", "title": "FlashVSR：迈向实时基于扩散的流媒体视频超分辨率", "title_en": "FlashVSR: Towards Real-Time Diffusion-Based Streaming Video Super-Resolution", "authors": "Junhao Zhuang,Shi Guo,Xin Cai,Xiaohui Li,Yihao Liu,Chun Yuan,Tianfan Xue", "background": "虽然扩散模型在视频修复方面取得了进展，但在实际应用中实现视频超分辨率（VSR）仍然具有挑战性，主要由于延迟高、计算成本大以及难以泛化到超高清分辨率。现有的基于扩散的方法在处理实时VSR时存在效率低、不易扩展的问题，难以满足实时性能要求。", "innovation": "本文提出了FlashVSR，这是一种实时基于扩散的单步流媒体框架，实现了效率、可扩展性和实时性能。FlashVSR通过结合三种互补创新来实现这一点：一是适用于训练的三阶段蒸馏管道，支持流媒体超分辨率；二是局域约束稀疏注意力机制，减少了冗余计算并解决了训练测试分辨率差异；三是轻量化的条件Decoder，加速重建过程而不牺牲质量。此外，作者还构建了一个名为VSR-120K的新数据集，其中包含120,000个视频和180,000张图像，支持大规模训练。", "conclusion": "大量实验表明，FlashVSR能够可靠地扩展到超高清分辨率，并且相比之前的一步扩散VSR模型具有高达12倍的速度提升。FlashVSR将代码、预训练模型和数据集开源，以促进未来在高效扩散式VSR方面的研究。"}
{"llm_update_time": "20251015", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.12764", "html_url": "https://arxiv.org/abs/2510.12764", "title": "AnyUp: 全局特征上采样", "title_en": "AnyUp: Universal Feature Upsampling", "authors": "Thomas Wimmer,Prune Truong,Marie-Julie Rakotosaona,Michael Oechsle,Federico Tombari,Bernt Schiele,Jan Eric Lenssen", "background": "现有的基于学习的特征上采样方法（如DINO或CLIP）需要为每种特征提取器重新训练，因此在推理时无法迁移到不同的特征类型。这一限制降低了上采样质量。", "innovation": "提出了AnyUp方法，一种可以在任意分辨率上对任何视觉特征进行上采样的方法，无需针对特定编码器进行训练。AnyUp可以在不重新训练的情况下，进行不同特征类型的通用上采样，提高了上采样质量并保留了特征语义。", "conclusion": "实验表明，AnyUp在上采样特征方面达到了新的最先进的水平，可以跨不同特征类型通用，并且在下游任务中高效易用。"}
{"llm_update_time": "20251015", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.12749", "html_url": "https://arxiv.org/abs/2510.12749", "title": "SPORTS: 城市场景同时进行全景视觉里程估计、渲染、跟踪和分割", "title_en": "SPORTS: Simultaneous Panoptic Odometry, Rendering, Tracking and Segmentation for Urban Scenes Understanding", "authors": "Zhiliu Yang,Jinyu Dai,Jianyuan Zhang,Zhu Yang", "background": "场景感知、理解和模拟是体态人工智能代理的基本技术，但现有解决方案在场景分割不完整、动态物体干扰、传感器数据稀疏性和视域限制方面仍然存在缺陷。", "innovation": "本文提出了一种名为SPORTS的新型框架，通过将视频全景分割（VPS）、视觉里程估计（VO）和场景渲染（SR）任务紧密集成到一个迭代且统一的视角中，实现全方位场景理解。VPS采用自适应注意力基几何融合机制，结合姿态、深度和光流模态跨帧特征对齐，并自动调整不同解码阶段的特征图。VO利用VPS的结果优化动态物体的置信度估计，提高摄像姿态估计的准确性及深度图生成的完整性。SR利用点云基于点的渲染，转化为神经场合成高保真RGB视图和孪生全景视图。在三个公开数据集上进行的大量实验表明，基于注意力的特征融合在里程估计、跟踪、分割和新颖视图合成任务上优于大多数现有最先进的方法。", "conclusion": "本文提出的SPORTS框架在多个公共数据集上的实验中表现出色，特别是在里程估计、跟踪、分割和新型视图合成任务上均优于大多数现有方法。"}
{"llm_update_time": "20251015", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.12750", "html_url": "https://arxiv.org/abs/2510.12750", "title": "VQArt-Bench: 一个富含语义的艺术与文化遗产VQA基准", "title_en": "VQArt-Bench: A semantically rich VQA Benchmark for Art and Cultural Heritage", "authors": "A. Alfarano,L. Venturoli,D. Negueruela del Castillo(University of Zurich, Max Planck Society)", "background": "多模态大型语言模型（MLLMs）在联合视觉和语言任务中展现了显著的能力。然而，现有的视觉问答（VQA）基准往往无法评估深度语义理解，特别是在视觉艺术分析等复杂领域。这些基准中的问题局限于简单的句法结构和表面属性，无法捕捉人类视觉查询的多样性和深度。这些限制促使模型依赖统计捷径而非进行视觉推理。为了弥补这一差距，我们引入了VQArt-Bench，一个新的大规模VQA基准，专注于文化遗产领域。这个基准利用一种新的多代理流水线构建，其中各专门代理合作生成精细、验证过的、语言多样的问题。基准题目结构化在相关视觉理解维度上，测试模型在解释符号意义、叙事和复杂视觉关系方面的能力。", "innovation": "VQArt-Bench 通过利用多代理流水线技术，生成精细、验证过的、语言多样的问题，设计一个新的大规模 VQA 基准，专注于文化遗产品类，填补现有基准对深度语义理解的评估不足，特别是复杂领域的视觉艺术分析。该基准在相关视觉理解维度上提问，以测试模型的解释能力。评估结果显示当前流行的14种最先进的 MLLMs 存在明显限制，包括一些意想不到的简单计数任务上的表现弱点和基于专有模型与开源模型之间的差距。", "conclusion": "我们的评估揭示了现有模型在当前基准中的显著限制，包括简单计数任务上的意外弱点以及专有模型与开源模型之间的明显性能差距，这些都是亟待解决的问题。"}
{"llm_update_time": "20251015", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.12753", "html_url": "https://arxiv.org/abs/2510.12753", "title": "E-MoFlow: 通过隐式正则化从事件数据学习姿态运动和光流", "title_en": "E-MoFlow: Learning Egomotion and Optical Flow from Event Data via Implicit Regularization", "authors": "Wenpu Li,Bangyan Liao,Yi Zhou,Qi Xu,Pian Wan,Peidong Liu", "background": "在三维视觉中，光学流估计和6自由度自主运动估计是两个基本任务，通常独立解决。然而，对于神经形态视觉（如事件摄像头），缺乏鲁棒的数据关联使得单独解决这两个问题是不适当的，尤其是在缺乏真实数据监督的情况下。现有工作通过使用显式的变分正则化来增强流场的连续性，或者通过在参数化过程中引入结构和运动先验信息来改善事件对齐。这些方法各有不足：前者引入偏差并增加计算负担，而后者往往会收敛到局部最优解。鉴于这些问题，本文提出了一种无监督框架，通过隐式空间-时间及几何正则化联合优化姿态运动和光学流。该方法通过概念隐喻和推理机制，利用连续样条模型和隐式神经表示嵌入时空一致性，并通过微分几何约束引入结构和运动先验信息，从而实现无监督环境下的姿态运动和光学流统一估计，同时保持几何一致性。", "innovation": "提出了一种无监督框架E-MoFlow，通过隐式空间-时间及几何正则化联合优化姿态运动和光学流。该方法通过隐式神经表示嵌入时空一致性，利用连续样条模型进行姿态运动建模，并通过微分几何约束引入结构和运动先验信息，从而避免了显式深度估计，同时保持几何一致性。", "conclusion": "E-MoFlow框架在无监督范式下统一了姿态运动和光学流的估计，展现出对一般6自由度运动场景的适用性，其性能优于现有无监督方法，并且甚至在某些情况下可与有监督方法竞争。"}
{"llm_update_time": "20251015", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.12765", "html_url": "https://arxiv.org/abs/2510.12765", "title": "Efficient Perceptual Image Super Resolution: AIM 2025 Study and Benchmark", "title_en": "Efficient Perceptual Image Super Resolution: AIM 2025 Study and Benchmark", "authors": "Bruno Longarela,Marcos V. Conde,Alvaro Garcia,Radu Timofte", "background": "尽管在高效峰值信噪比（PSNR）导向的超分辨率方面取得了显著进展，但专注于感知质量度量的方法仍然相对效率低下。受此差距的驱动，本文旨在在严格的效率约束下（最大5M参数和2000GFLOPs，基于960x540的输入尺寸）复制或超越Real-ESRGAN的感知结果。", "innovation": "提出了一种解决方案，在高效和感知质量之间找到平衡。该解决方案在一种新型数据集上进行了评估，该数据集包含500张4K分辨率的测试图像，每张图像使用多种退化类型进行退化处理，但未提供原始的高质量对应物。这种设计旨在反映现实部署条件，并作为多样性和有挑战性的基准测试。", "conclusion": "最优方法在所有基准数据集上均优于Real-ESRGAN，表明了在感知领域高效方法的潜力。本文为高效感知超分辨率设定了现代基准线。"}
{"llm_update_time": "20251015", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.12768", "html_url": "https://arxiv.org/abs/2510.12768", "title": "动态高斯散斑对于单目4D重建中的不确定性问题", "title_en": "Uncertainty Matters in Dynamic Gaussian Splatting for Monocular 4D Reconstruction", "authors": "Fengzhi Guo,Chih-Chuan Hsu,Sihao Ding,Cheng Zhang", "background": "由于单目输入重建动态3D场景是信息不足的，由于遮挡和极端新颖视角导致不确定性，传统的动态高斯散斑模型优化所有高斯原语时没有考虑观察质量，导致在遮挡下出现运动漂移，以及在未知视角下合成效果差。", "innovation": "引入了USplat4D，这是一种新的非均匀动态高斯散斑框架，它通过传播可靠的运动线索来增强4D重建，并估计时间变化的每个高斯的不确定性，利用这种不确定性构建时空图，以实现不确定性感知优化。", "conclusion": "实验表明，明确建模不确定性能持续改善动态高斯散斑模型，在遮挡下获得更稳定的几何结构，并在极端视角下合成高质量的结果。"}
{"llm_update_time": "20251015", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.12758", "html_url": "https://arxiv.org/abs/2510.12758", "title": "基于注意力的监督深度学习在PET头部运动估计中的应用", "title_en": "PET Head Motion Estimation Using Supervised Deep Learning with Attention", "authors": "Zhuotong Cai,Tianyi Zeng,Jiazhen Zhang,Eléonore V. Lieffrig,Kathryn Fontaine,Chenyu You,Enette Mae Revilla,James S. Duncan,Jingmin Xin,Yihuan Lu,John A. Onofrey", "background": "脑部运动对正电子发射断层扫描（PET）成像构成重大挑战，导致图像伪影并影响放射性示踪剂摄取量的定量准确性。有效的头部运动估计和校正对于精确的定量图像分析和神经系统疾病准确诊断至关重要。硬件基于的运动跟踪（HMT）方法在实际临床实践中应用受限。为解决这一问题，本文提出了一种基于深度学习的头部运动校正方法（DL-HMC++），该方法能够从一秒钟的3D PET原始数据中预测刚性头部运动。DL-HMC++通过利用具有黄金标准运动测量的动态PET扫描进行监督训练。评估表明，DL-HMC++在两种PET扫描仪（HRRT和mCT）和四种放射性示踪剂（18F-FDG、18F-FPEB、11C-UCB-J和11C-LSN3172176）上表现出色，证明了在大规模PET研究中的有效性和普适性。定量和定性结果显示，DL-HMC++在去除头部运动伪影方面优于最先进的数据驱动的运动估计方法，生成的无运动图像能够精确区分脑结构，与黄金标准HMT产生的结果难以区分。该项研究显示了数据驱动的PET头部运动校正的潜力，能够减轻对HMT的需求，使其在研究之外的临床环境中更易于实施。", "innovation": "提出了一个基于深度学习的头部运动校正方法（DL-HMC++），能够从一秒钟的3D PET原始数据中预测刚性头部运动。该方法通过充分利用现有动态PET扫描数据及其黄金标准运动测量的外部HMT进行监督训练，从而有效克服了硬件基于的运动跟踪方法在实际临床环境中的局限性。", "conclusion": "DL-HMC++在两种PET扫描仪和四种放射性示踪剂上实现了优异的表现，证明了在大规模PET研究中的有效性和普适性。该方法有效改善了无运动图像的质量，并准确定界了脑结构，其结果在定性和定量测试中都优于现有的先进方法。该研究展示了数据驱动的PET头部运动校正具有潜在的价值，可广泛适用于临床环境，减轻硬件基于的运动跟踪方法的负担，使得头部运动校正能够超越科研环境在更广泛的临床人群中应用。该代码已公开可用。"}
{"llm_update_time": "20251015", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.12777", "html_url": "https://arxiv.org/abs/2510.12777", "title": "What If : 通过稀疏交互理解运动", "title_en": "What If : Understanding Motion Through Sparse Interactions", "authors": "Stefan Andreas Baumann,Nick Stracke,Timy Phan,Björn Ommer", "background": "理解物理场景的动力学涉及对其可能变化方式的推理，尤其是由局部交互引起的。传统方法通常只能对场景动力学进行密集采样，生成单一实现的结果，但缺乏对场景动力学的多模态表示和依赖物理交互的解释性。本研究提出了一种新颖框架——Flow Poke Transformer (FPT)，能够直接预测基于稀疏交互（称为“pokes”）的局部运动分布。", "innovation": "FPT 能够直接预测基于稀疏交互的多模态场景运动，提供对物理交互依赖及其场景动力学内在不确定性更具解释性的直接可访问表示。FPT 在多种下游任务上进行评估，与其他方法相比，展示了其灵活性。FPT 的通用预训练模型在密集面部运动生成任务中超过了专门的基础模型。对于强跨分布任务，可以通过微调 FPT 在合成数据集上获得显著改进。并且直接预测显式运动分布使得我们的方法在仅从稀疏交互进行部分移动分割任务上取得了竞争力的表现。", "conclusion": "研究表明，FPT 不仅提高了密度运动生成性能，还在不同场景中显示出强大的适应性，证明其方法的广泛适用性和高效性。"}
{"llm_update_time": "20251015", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.12784", "html_url": "https://arxiv.org/abs/2510.12784", "title": "SRUM: 细粒度自奖励——统合多模态模型", "title_en": "SRUM: Fine-Grained Self-Rewarding for Unified Multimodal Models", "authors": "Weiyang Jin,Yuwei Niu,Jiaqi Liao,Chengqi Duan,Aoxue Li,Shenghua Gao,Xihui Liu", "background": "近年来，统合多模态模型（UMMs）取得了显著进展，这些模型能够整合视觉和语言的生成与理解能力。然而，这些模型在视觉生成上往往不能很好地继承其视觉理解能力，即模型虽然能够根据用户指令正确理解图片，但在从文本提示生成图片时却无法做到一模一样。", "innovation": "为了弥合这一差距并实现自我改善，本文提出了一种新的自奖励后训练框架SRUM，该框架适用于各种设计的UMMs。SRUM通过模型自身的理解模块作为内部“评价者”，提供纠正信号以改进生成模块，而无需额外的人工标注数据。为了确保反馈的全面性，设计了一种全局-局部双重奖励系统，该系统提供多尺度指导，全局奖励确保整体视觉语义和布局的正确性，局部奖励细化对象级别的保真度。", "conclusion": "SRUM显示出强大的能力和良好的泛化能力，使其在T2I-CompBench上的表现从82.18提升到了88.37，在T2I-ReasonBench上的表现从43.82提升到了46.75。这项工作为UMMs的理解模块如何指导并增强其自身的生成能力建立了新的范式。"}
{"llm_update_time": "20251015", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.12788", "html_url": "https://arxiv.org/abs/2510.12788", "title": "高效单图像现实世界图像去模糊：AIM 2025 挑战报告", "title_en": "Efficient Real-World Deblurring using Single Images: AIM 2025 Challenge Report", "authors": "Daniel Feijoo,Paula Garrido-Mellado,Marcos V. Conde,Jaesung Rim,Alvaro Garcia,Sunghyun Cho,Radu Timofte", "background": "这篇论文回顾了AIM 2025高效现实世界去模糊挑战，旨在推动高效的现实模糊恢复。该挑战基于新的基于知名RSBlur数据集的测试集。该数据集包含使用双镜头系统捕捉的一对模糊和退化图像对。参赛者被要求开发有效的去模糊解决方案，同时满足严格的效率限制：模型参数少于500万，计算预算少于200 GMACs。共有71名参与者注册，最终有4支团队提交了有效解决方案。性能最佳的方法实现了31.1298 dB的PSNR，展示了高效方法在该领域的潜力。", "innovation": "挑战基于新的RSBlur数据集，使用双镜头系统捕捉图像对，参赛者需要在严格的效率限制下开发解决方案。提出了多种高效去模糊方法，并进行了比较分析。", "conclusion": "论文提供了对该挑战的全面概述，比较了提出的解决方案，并为高效现实世界图像去模糊领域的研究人员提供了有价值的参考。"}
{"llm_update_time": "20251015", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.12793", "html_url": "https://arxiv.org/abs/2510.12793", "title": "ViCO: 一种面向语义感知的动态高分辨率训练策略", "title_en": "ViCO: A Training Strategy towards Semantic Aware Dynamic High-Resolution", "authors": "Long Cui,Weiyun Wang,Jie Shao,Zichen Wen,Gen Luo,Linfeng Zhang,Yanting Zhang,Yu Qiao,Wenhai Wang", "background": "现有的多模态大规模语言模型（MLLMs）由于需要处理图像输入所引入的额外视觉令牌，导致了推理成本增加。", "innovation": "提出了视觉一致性学习（ViCO），这是一种新的训练算法，能够根据图像的语义复杂度使用不同数量的视觉令牌表示图像。方法关键在于使用具有不同图像压缩比的多个MLP连接器及在训练期间最小化基于不同MLP连接器条件的响应之间的KL散度。", "conclusion": "实验结果表明，该方法可以在保持模型感知、推理和OCR能力的同时，将视觉令牌的数量最多减少50%。希望该工作能促进更高效的MLLMs的发展。"}
{"llm_update_time": "20251015", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.12789", "html_url": "https://arxiv.org/abs/2510.12789", "title": "UniFusion：维视语言模型作为图像生成中的统一编码器", "title_en": "UniFusion: Vision-Language Model as Unified Encoder in Image Generation", "authors": "Kevin Li,Manuel Brack,Sudeep Katakol,Hareesh Ravi,Ajinkya Kale", "background": "尽管视觉生成方面取得了显著进展，现有的大多数架构仍依赖于独立的图像和文本编码器。这种分离限制了扩散模型在跨模态推理和知识转移方面的性能。此前尝试弥合这一差距的方法使用了视觉语言模型的最终层信息、采用多个视觉编码器或共同训练大规模统一模型用于文本和图像生成，这需要大量计算资源和大规模数据，从而限制了其应用范围。", "innovation": "提出了一种基于扩散的生成模型UniFusion，它以冻结的大型维视语言模型（VLM）作为统一的多模态编码器。UniFusion的核心是分层注意力 pooling (LAP) 机制，该机制从冻结的VLM中的文本和视觉标记中抽取高层次语义和低层次细节，以指导扩散生成模型。此外，还提出了VLM-Enabled Rewriting Injection with Flexibile Inference (VERIFI)，该方法仅依赖于由VLM生成的文本标记来指导扩散变换器中的模型内提示重写，从而在推理过程中结合了条件分布的对齐和VLM的推理能力，增强了推理能力和灵活性。进一步，在编辑任务上的微调不仅改善了生成的文本-图像对齐，表明跨模态知识转移，而且还展示了强大的泛化能力。", "conclusion": "当训练单一图像编辑任务时，该模型能够在没有任何图像参考的情况下泛化到多个图像参考，这进一步证明了UniFusion统一编码器设计的有效性。"}
{"llm_update_time": "20251015", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.12796", "html_url": "https://arxiv.org/abs/2510.12796", "title": "DriveVLA-W0：世界建模放大自动驾驶数据扩展定律", "title_en": "DriveVLA-W0: World Models Amplify Data Scaling Law in Autonomous Driving", "authors": "Yingyan Li,Shuyao Shang,Weisong Liu,Bing Zhan,Haochen Wang,Yuqi Wang,Yuntao Chen,Xiaoman Wang,Yasong An,Chufeng Tang,Lu Hou,Lue Fan,Zhaoxiang Zhang", "background": "在大规模数据上对视觉-语言-动作（VLA）模型进行缩放为实现更具通用性的驾驶智能提供了有希望的道路。然而，VLA模型受到“监督不足”的限制：巨大的模型容量仅由稀疏的、低维度的动作进行监督，导致其代表能力大大被浪费。", "innovation": "提出了 DriveVLA-W0 ，这是一种采用世界建模预测未来图像的培训 paradigm。这种方法产生了一个密集的自我监督信号，促使模型学习驾驶环境的基本动态。为两个主导的 VLA 架构引入了问题范式的实例：一种自回归世界模型用于使用离散视觉标记的 VLA，另一种扩散世界模型用于使用连续视觉特征操作的 VLA。基于从世界建模中学习到的丰富表示，引入了轻量级的动作专家以解决实际部署时的推理延迟问题。", "conclusion": "在 NAVSIM v1/v2 基准测试和一个规模大 680 倍的内部数据集上的广泛实验表明，DriveVLA-W0 显著优于 BEV 和 VLA 基线。最关键的是，它放大了数据缩放定律，表明随着训练数据集规模的增大，性能增益会加速。"}
{"llm_update_time": "20251015", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.12795", "html_url": "https://arxiv.org/abs/2510.12795", "title": "CuMPerLay: Learning Cubical Multiparameter Persistence Vectorizations", "title_en": "CuMPerLay: Learning Cubical Multiparameter Persistence Vectorizations", "authors": "Caner Korkmaz,Brighton Nuwagira,Barış Coşkunuzer,Tolga Birdal", "background": "Cubical Multiparameter Persistence (CMP) 提供了一种自然且强大的方法来对图像进行拓扑处理，但其复杂且多维度的结构以及向量化过程阻碍了其应用。以往的方法虽然提供了单参数持久性的表示，但无法直接处理CMP的基本挑战，即多参数复杂性与向量化难度。", "innovation": "本文提出了一个新的可微向量化层 CuMPerLay，它通过分解CMP为可学习的单参数持久性组合，解决了多参数结构的复杂性问题，同时利用了不同步函数的联合学习。此外，CuMPerLay 的微分性质使得它可以无缝集成到最先进的体系结构中，如 Swin Transformers，并提供了在泛化 Wasserstein 度量下的稳定向量化理论保证。实验结果在基准医疗成像和计算机视觉数据集上显示了 CuMPerLay 在分类和分割性能上的优势，尤其是在数据有限的情况下。", "conclusion": "CuMPerLay 提供了一种有希望的方法，将全局结构信息集成到深度网络中进行结构化图像分析，展示了一种有效的处理和利用 CMP 方法来改进图像处理任务结果的路径。"}
{"llm_update_time": "20251015", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.12785", "html_url": "https://arxiv.org/abs/2510.12785", "title": "MVP4D: 多视角肖像视频扩散模型用于可动画的4D头像", "title_en": "MVP4D: Multi-View Portrait Video Diffusion for Animatable 4D Avatars", "authors": "Felix Taubner,Ruihang Zhang,Mathieu Tuli,Sherwin Bahmani,David B. Lindell", "background": "数字化人类头像旨在模拟人类在虚拟环境中的动态外观，提供沉浸式体验。然而，传统上创建和动画化逼真的人类头像既昂贵又耗时，需要大型摄像头捕捉设备和大量专业的3D艺术家的手工努力。随着先进图像和视频生成模型的出现，近期方法可以通过单个随意捕捉的目标主体参考图像自动渲染逼真的动画头像。尽管这些技术在降低头像创建的门槛和提供令人信服的逼真性方面有显著进步，但它们缺乏多视图信息提供的约束或显式的3D表示，因此当从与参考图像差别较大的视角渲染时，图像质量和逼真性会下降。", "innovation": "本文提出了一种能够基于单个参考图像和目标表情同时生成数百帧可动画多视角视频的视频模型MVP4D。MVP4D模型基于最新的预训练视频扩散模型，在目标主体周围生成最多360度变化的视角数百帧。本文还展示了如何将这种模型的输出提取成一个可以实时渲染的4D头像。与先前的方法相比，本文的方法显著提高了生成头像的现实性、时间一致性和3D一致性。", "conclusion": "本文通过MVP4D模型生成了基于单个参考图像和目标表情的可动画多视角视频，显著提高了生成头像的现实性、时间一致性和3D一致性，降低了头像创建的门槛，提供了令人信服的逼真性。"}
{"llm_update_time": "20251015", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.12798", "html_url": "https://arxiv.org/abs/2510.12798", "title": "通过下一点预测检测一切", "title_en": "Detect Anything via Next Point Prediction", "authors": "Qing Jiang,Junan Huo,Xingyu Chen,Yuda Xiong,Zhaoyang Zeng,Yihao Chen,Tianhe Ren,Junzhi Yu,Lei Zhang", "background": "长期以来，目标检测主要依赖于基于坐标回归的传统模型，如YOLO、DETR和Grounding DINO。尽管近期尝试利用多模态大语言模型（MLLMs）来解决这一问题，但这些模型仍面临召回率低、重复预测、坐标对齐错误等挑战。因此，作者提出Rex-Omni，这是一种30亿参数规模的MLLM，实现了最先进的目标感知性能。在COCO和LVIS等基准测试中，Rex-Omni在零样本设置下的性能与或超过了回归模型（如DINO、Grounding DINO）。", "innovation": "Rex-Omni的主要创新之处在于：1）任务表达：使用特殊的令牌表示从0到999的量化坐标，简化模型的学习难度，提高坐标预测的令牌效率；2）数据引擎：构建多个数据引擎以生成高质量的定位、参考和指向数据，提供丰富的语义监督；3）训练管道：采用两阶段训练过程，结合监督微调2200万数据与基于GRPO的强化学习后训练。后训练采用几何感知的奖励机制来弥合离散坐标与连续预测之间的差距，从而提高框的准确性并减少重复预测等不良行为。", "conclusion": "Rex-Omni具备本体语言理解能力，使其具备各种应用功能，如对象参考、指示、视觉提示、GUI定位、空间参考、OCR和关键点检测，并在专用基准上进行了系统评估。作者认为，Rex-Omni铺平了更具通用性和语言感知的视觉感知系统的发展道路。"}
{"llm_update_time": "20251015", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.12801", "html_url": "https://arxiv.org/abs/2510.12801", "title": "DeepMMSearch-R1：增强多模态LLM在多模态网络搜索中的能力", "title_en": "DeepMMSearch-R1: Empowering Multimodal LLMs in Multimodal Web Search", "authors": "Kartik Narayan,Yang Xu,Tian Cao,Kavya Nerella,Vishal M. Patel,Navid Shiee,Peter Grasch,Chao Jia,Yinfei Yang,Zhe Gan", "background": "在真实世界应用中的多模态大语言模型（MLLMs）需要访问外部知识源，并保持对动态变化的现实信息的响应，以处理信息查寻和知识密集型用户查询。现有方法如检索增强生成（RAG）方法、搜索引擎代理和配备搜索引擎的MLLMs，常常由于僵化的流程、过多的搜索调用和构建不良的搜索查询而导致效率低下和结果不理想。", "innovation": "我们提出了DeepMMSearch-R1，这是一种能够进行按需、多轮次网络搜索并在图像和文本搜索工具中动态构建查询的首个多模态大语言模型。DeepMMSearch-R1 可以基于输入图像的相关裁剪启动网络搜索，使图像搜索更有效，并可以根据检索到的信息迭代适应文本搜索查询，从而实现自我反思和自我纠正。我们采用两阶段的训练流程：首先进行需要标记的预训练，然后进行在线强化学习优化。还介绍了一种新的多模态VQA数据集DeepMMSearchVQA，该数据集通过混合实时信息生成并含有多种跳转查询，这些查询结合了文本和视觉信息，教导模型何时搜索、搜索什么、使用哪种搜索工具以及如何在检索到的信息上推理。", "conclusion": "我们在各种知识密集型基准测试上进行了广泛的实验，证明了我们方法的优越性。我们分析了结果并提供了有助于推动多模态网络搜索发展的见解。"}
{"llm_update_time": "20251015", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.11760", "html_url": "https://arxiv.org/abs/2510.11760", "title": "Audio-Guided Visual Perception for Audio-Visual Navigation", "title_en": "Audio-Guided Visual Perception for Audio-Visual Navigation", "authors": "Yi Wang,Yinfeng Yu,Fuchun Sun,Liejun Wang,Wendong Zheng", "background": "当前的视听导航方法在处理已知音频源时表现出色，但在面对未听过的音频源或未见过的环境时，导航成功率会大幅下降，探索路径也变得过长。这一现象的原因在于，导航策略在训练过程中倾向于记忆不需要的‘声学指纹-场景’相关性，当面对新音频源时导致盲目探索。", "innovation": "本文提出了一种AGVP框架，它将声音从导航策略可记忆的声学指纹线索转化为空间导向，首先通过音频自我注意力提取全局听觉上下文，然后将此上下文作为查询来引导视觉特征注意力，突出声源相关的区域。通过这种设计，减少了对特定声学指纹的依赖。实验结果表明，AGVP提高了导航效率和鲁棒性，并实现了对未听过的音频源的跨场景泛化。", "conclusion": "AGVP框架通过增强跨模态理解和区域重新加权减少对特定声学指纹的依赖，从而提高了导航效率和鲁棒性，并在未听过的音频源上实现了更好的跨场景泛化。"}
{"llm_update_time": "20251015", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.11962", "html_url": "https://arxiv.org/abs/2510.11962", "title": "MosaicDiff：反映预训练动力学的无需训练的结构剪枝以加速扩散模型", "title_en": "MosaicDiff: Training-free Structural Pruning for Diffusion Model Acceleration Reflecting Pretraining Dynamics", "authors": "Bowei Guo,Shengkun Tang,Cong Zeng,Zhiqiang Shen", "background": "扩散模型以其生成能力而闻名，但它们的预训练过程表现出明显的学习速度差异，这一过程在社区之前的后训练加速工作中并未得到充分关注。", "innovation": "提出了名为MosaicDiff的新框架，通过轨迹感知结构剪枝将扩散预训练动力学与后训练采样加速对齐。该方法利用了扩散预训练中间快速学习阶段需要更保守的剪枝以保留关键模型特征这一观察，而早期和后期慢学习阶段则受益于更激进的剪枝策略。这种自适应剪枝机制首次明确反映了扩散预训练固有的学习速度变化，从而协调了模型的内部训练动态与加速采样过程。", "conclusion": "在DiT和SDXL上进行的大量实验表明，本方法能够在不牺牲输出质量的情况下实现显著的采样加速，大幅度超过了当前最先进的方法，还为更有效的无训练扩散加速提供了新的视角。"}
{"llm_update_time": "20251015", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.11878", "html_url": "https://arxiv.org/abs/2510.11878", "title": "GS-Verse: 基于网格的高斯插值在虚拟现实中的物理感知交互", "title_en": "GS-Verse: Mesh-based Gaussian Splatting for Physics-aware Interaction in Virtual Reality", "authors": "Anastasiya Pechko,Piotr Borycki,Joanna Waczyńska,Daniel Barczyk,Agata Szymańska,Sławomir Tadeja,Przemysław Spurek", "background": "随着对沉浸式3D内容的需求增加，直观且高效的互动方法变得尤为重要。当前用于在虚拟现实（VR）中物理操控3D内容的技术往往存在许多限制，如工程密集型过程依赖以及简化几何表示，比如四面体笼，这些都会影响视觉保真度和物理准确性。因此，该领域亟需创新解决方案以实现更精确的表面近似，从而达到高度现实的形变和交互效果。", "innovation": "本文介绍了一种名为`Gourad Splatting for Virtual Environment Rendering and Scene Editing`的创新方法，通过直接将物体的网格与高斯插值（GS）表示相结合来解决上述问题。这种方法能在保留几何细节的同时实现更精确的表面近似，提供更加真实的变形和交互效果。通过利用现有3D网格资产，该方法简化了内容重用和开发流程，并且具有物理学引擎无关性，提高了开发灵活性。研究表明，与当前最先进的在VR中结合高斯插值的方法相比，该方法在物理感知拉伸操作上表现出显著的统计优势，并且在其他物理模拟操作（如扭转和摇晃）上也表现得更为一致。", "conclusion": "本文提出的方法在各种交互和场景中都表现出高度可靠和高性能，展示了其作为现有方法替代方案的潜力。"}
{"llm_update_time": "20251015", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.12101", "html_url": "https://arxiv.org/abs/2510.12101", "title": "基于高斯语义场的一击即中的LiDAR全局定位", "title_en": "Gaussian Semantic Field for One-shot LiDAR Global Localization", "authors": "Pengyu Yin,Shenghai Yuan,Haozhi Cao,Xingyu Ji,Ruofei Bai,Siyu Chen,Lihua Xie", "background": "尽管基于地标语义注册的方法在全局定位中展现出了与几何方法相比的显著性能改进，但地标可能重复且易于误导对应建立。", "innovation": "提出了使用从高斯过程群体中学习的连续函数来建模语义分布，通过在对象层和度量语义层之间插入连续函数，形成三层3D场景图，实现了轻量且高效的单次定位算法，命名为Outram-GSF（高斯语义场）.", "conclusion": "通过广泛实验验证了该方法优于当前最先进的技术，展示了其优越的性能。"}
{"llm_update_time": "20251015", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.12060", "html_url": "https://arxiv.org/abs/2510.12060", "title": "你的VAR模型其实是高效且可解释的生成分类器", "title_en": "Your VAR Model is Secretly an Efficient and Explainable Generative Classifier", "authors": "Yi-Chung Chen,David I. Inouye,Jing Gao", "background": "生成分类器通过条件生成模型来实现分类，近年来展现出了良好的特性，如对数据分布迁移的强大鲁棒性。然而，该领域近年来的进展主要依赖于扩散模型，这些模型的计算成本很高，限制了大规模应用的可能性。当前的研究主要集中在扩散模型上，这限制了对生成分类器的理解。", "innovation": "本文提出了一种基于最近视觉自回归（VAR）建模进步的新型生成分类器，并进一步引入了可实现准确性和推理速度之间更好权衡的自适应VAR分类器+（A-VARC+）。该方法显示出与扩散模型基本不同的特性，即通过可计算的概率函数实现视觉可解释性，并在增量学习任务中具备内在的灾难性遗忘抵抗能力。", "conclusion": "本文提出的VAR模型不仅效率高，而且可解释性强，通过这两种特性，在实际应用中表现出色。更重要的是，该模型揭示了生成分类器与扩散模型之间的本质区别，为这一领域的研究提供了新的视角。"}
{"llm_update_time": "20251015", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.11738", "html_url": "https://arxiv.org/abs/2510.11738", "title": "SeeingSounds：通过文本学习音频到视觉对齐", "title_en": "SeeingSounds: Learning Audio-to-Visual Alignment via Text", "authors": "Simone Carnemolla,Matteo Pennisi,Chiara Russo,Simone Palazzo,Daniela Giordano,Concetto Spampinato", "background": "当前的音频到图像生成方法通常依赖于配对的音频-视觉数据和视觉生成模型的训练，这限制了其灵活性和应用范围。传统的做法可能将音频视为文本的替代品，或者仅依赖于音频到文本的映射，这种方法缺乏对人类感知自然交叉模态关联的模拟。因此，研究人员寻求一种新的框架，可以在不依赖配对数据和视觉生成模型训练的前提下，同时考虑音频、语言和视觉之间的互动，以实现更加灵活和可控的音频到图像生成任务。", "innovation": "提出了一种轻量级且模块化的框架SeeingSounds，它通过冻结的语言编码器将音频投影到语义语言空间，并利用视觉语言模型将音频字幕化到视觉领域。这种方法通过双对齐的方式工作：音频被投影到固定的语言编码器中的语义语言空间，并通过视觉语言模型在语境中诠释到视觉领域。这种方法借鉴了认知神经科学的原理，能够自然地模拟人类感知中的多模态关联。此外，该模型使用固定的扩散基础架构，并仅训练轻量级的适配器，从而实现高效的可扩展学习。通过程序化文本提示生成支持细粒度和可解释的控制，音频变换（如音量或音高变化）能转化为指导视觉输出的描述性提示。实验结果显示，SeeingSounds在零样本和监督环境中均优于现有方法，并在可控的音频到视觉生成任务中建立了新的状态点。", "conclusion": "SeeingSounds通过双对齐方法和自然语言处理技术，实现了音频到图像的灵活生成，并通过细粒度控制实现了高性能。该研究为未来基于文本的多模态生成任务提供了新的思路和方法，并在多个标准基准测试中取得了最先进的性能。"}
{"llm_update_time": "20251015", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.12483", "html_url": "https://arxiv.org/abs/2510.12483", "title": "快速视觉动作策略及其在机器人操作中的应用", "title_en": "Fast Visuomotor Policy for Robotic Manipulation", "authors": "Jingkai Jia,Tong Yang,Xueyao Chen,Chenhuan Liu,Wenqiang Zhang", "background": "现有的机器人策略多侧重于单模态动作预测，不适用于高频率和资源受限的机器人任务。研究团队旨在开发一种适用于此类场景的新框架，以提高操作精度和速度，同时减少计算负担并保证模型的简洁性和高效性。", "innovation": "提出了名为Energy Policy的新策略框架，该框架能够通过单次向前传递预测多模态动作，从而支持高速高精度机器人操纵。其创新点在于通过采用能量评分作为学习目标来促进多模态动作建模，并引入简单的能量MLP来实现这一目标，同时保持模型简洁高效。", "conclusion": "实验结果表明，Energy Policy在仿真和真实世界任务中都能与现有方法媲美或超越，并且显著减少了计算开销。特别是在MimicGen基准测试中，Energy Policy不仅表现出色，而且在推理速度上也优于现有方法。"}
{"llm_update_time": "20251015", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.12141", "html_url": "https://arxiv.org/abs/2510.12141", "title": "MAPS: 遮罩归因基于探察策略——一种将人类和模型解释对齐的计算框架", "title_en": "MAPS: Masked Attribution-based Probing of Strategies- A computational framework to align human and model explanations", "authors": "Sabine Muzellec,Yousif Kashef Alghetaa,Simon Kornblith,Kohitij Kar", "background": "人类的核心对象识别依赖于有选择地使用视觉信息，但指导这些选择的策略难以直接测量。目前存在的方法难以有效地评估和选择竞争的神经网络可解释性方法。MAPS工具通过将归因图转化为解释遮罩图像（EMI），对比有限像素预算下的最小图像的人类准确性和完整刺激的人类准确性，提供了一种按原理评价和选择这些解释方法的方式。这种方法通过计算模型归因图的行为相似性来揭示IBMs的最佳捕捉模型策略，从而实现与真实策略的可靠一致。", "innovation": "MAPS提供了一种行为验证的计算工具，它通过将归因图转化为解释遮罩图像（EMI），比较有限像素预算下的最小图像与完整刺激的人类准确性，来评估和选择神经网络的解释方法。它在实验室内能够可靠地揭示模型策略，且需要较少的行为实验。同时，这种方法仅需访问模型的归因和少量行为数据，避免了耗时的视觉物理学，为评估和关联人类行为、神经活动和模型决策提供了一个可扩展的工具，适用于多种标准下的人脑和模型解释对齐任务。", "conclusion": "MAPS通过需要较少行为实验和仅依赖模型归因和少量行为数据，避免了耗时的视觉物理学，为评估和关联人类行为、神经活动和模型决策提供了一个高效的工具。当应用于人类和猕猴时，这一工具可以帮助识别最能与生物学视觉一致的神经网络解释，从而确保其行为有效性。"}
{"llm_update_time": "20251015", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.12425", "html_url": "https://arxiv.org/abs/2510.12425", "title": "通过单调包含实现张量完成：广义低秩先验与深度除噪器的结合", "title_en": "Tensor Completion via Monotone Inclusion: Generalized Low-Rank Priors Meet Deep Denoisers", "authors": "Peng Chen,Deliang Wei,Jiale Yao,Fang Li", "background": "多维数据中的缺失值给下游分析带来了巨大挑战，在各种实际应用场景中普遍存在。这类数据天然可以用张量建模。虽然最近的一些结合全局低秩先验与插件式除噪器的完成方法在实验上表现出色，但这些方法通常依赖于经验上的收敛性或者对深除噪器作为隐式正则化操作的代理优化器的不现实假设，这一般并不成立。因此，有必要开发新的张量完成框架，以克服这些局限性。", "innovation": "提出了一种新的基于单调包含的张量完成框架，该框架统一了广义低秩先验与深度拟收缩除噪器，并超越了传统的凸优化。基于Davis-Yin分裂方案，开发了GTCTV DPC算法，并严格证明了其全局收敛性。实验证明，该算法在定量指标和视觉质量方面都优于现有方法，特别是在低采样率下表现尤为突出。", "conclusion": "本文提出的方法有效地解决了现有张量完成方法的不足，通过理论证明和实验证明，在低采样率下尤其是在数据质量要求较高的情况下，GTCTV DPC算法能够提供更好的结果。"}
{"llm_update_time": "20251015", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.12691", "html_url": "https://arxiv.org/abs/2510.12691", "title": "DiffEM: 使用期望最大化从受污染数据中学习扩散模型", "title_en": "DiffEM: Learning from Corrupted Data with Diffusion Models via Expectation Maximization", "authors": "Danial Hosseintabar,Fan Chen,Giannis Daras,Antonio Torralba,Constantinos Daskalakis", "background": "扩散模型在高维逆问题生成先验方面表现出了强大的能力。然而，当仅有受污染或噪声观测数据可用时，训练这些扩散模型仍然具有挑战性。本文的研究背景正是基于此种挑战展开，旨在探索一种基于期望最大化（EM）算法的改进训练方法，以便有效地利用受污染的数据来训练扩散模型。", "innovation": "本文提出的DiffEM方法创新性地将期望最大化和条件扩散模型结合，通过E步利用条件扩散模型从观测数据中重建干净数据，然后在M步中使用重建的数据来进一步优化条件扩散模型。此外，作者还提供了在适当统计条件下DiffEM迭代的单调收敛保证，这标志着在训练受污染数据驱动的扩散模型方面的理论进展。", "conclusion": "本文通过在各种图像重构任务上的实验验证了DiffEM方法的有效性。该方法能够有效地利用受污染的数据来训练扩散模型，进而提高图像恢复质量，同时其迭代过程具备理论上的单调收敛性。"}
{"llm_update_time": "20251015", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2310.05108", "html_url": "https://arxiv.org/abs/2310.05108", "title": "通过异构自监督学习增强表示", "title_en": "Enhancing Representations through Heterogeneous Self-Supervised Learning", "authors": "Zhong-Yu Li,Bo-Wen Yin,Yongxiang Liu,Li Liu,Ming-Ming Cheng", "background": "目前跨不同架构的异构表示已经被用于多种视觉任务，例如一些融合网络结合了变压器和卷积。然而，这些异构架构之间的互补作用在自监督学习中尚未得到充分利用。该研究旨在通过让基础模型从与其架构不同的辅助头学习，从而提高自监督学习的效果，以此提高模型的表现。", "innovation": "提出了一种新的自监督学习方法——异构自监督学习（HSSL）。HSSL 让基础模型通过学习与之架构不同的辅助头来获得新的表示能力，而无需对基础模型进行结构上的改动。同时，还提出了一种搜索策略，用于高效地确定最适合特定基础模型的辅助头，并提出了一些简单而有效的方法来增加模型之间的不一致性。", "conclusion": "HSSL 可以与多种自监督学习方法兼容，在图像分类、语义分割、实例分割和对象检测等多种下游任务中取得了优异的性能。研究中的代码可以在提供的链接处获得。"}
{"llm_update_time": "20251015", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.12548", "html_url": "https://arxiv.org/abs/2510.12548", "title": "VISaGE: 理解视觉普遍性和异常现象", "title_en": "VISaGE: Understanding Visual Generics and Exceptions", "authors": "Stella Frank,Emily Allaway", "background": "视觉语言模型（VLMs）在训练过程中学习概念性表示，即泛化的知识，它们通常用于分析单一实例。然而，当评估实例异常时，这种范式会导致模型中的两种先验之间产生张力。一种是实践先验，文本和视觉输入都相关的先验，源于VLM在一致输入上进行微调；另一种是语义先验，概念表示通常适用于该类别的实例。本文通过介绍一个新的评价数据集VISaGE来研究VLM在这两种先验之间的权衡机制，VISaGE包括典型和非凡的图像。实验表明，当实践先验下的一致假设被违反时，概念理解会下降，这种效应在询问单个实例时比语义先验更为显著。", "innovation": "本文提出了一种新的评价数据集VISaGE，旨在评估VLM在处理不同类别图像时概念理解的变化情况，并揭示了实践先验和语义先验之间的权衡。通过细致平衡的实验，揭示了当一致性假设被打破时，概念理解的下降趋势超过语义先验对个体实例的影响的效果。", "conclusion": "实践先验假设的一致性违反会导致概念理解的下降，而在询问个体实例时，这种效应比语义先验更为显著。这一发现有助于更好地理解VLM在处理不同类别图像时的表现，从而为后续研究和应用场景提供指导。"}
{"llm_update_time": "20251015", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.12709", "html_url": "https://arxiv.org/abs/2510.12709", "title": "SAIL-嵌入技术报告：全模态嵌入基础模型", "title_en": "SAIL-Embedding Technical Report: Omni-modal Embedding Foundation Model", "authors": "Lin Lin,Jiefeng Long,Zhihe Wan,Yuchi Wang,Dingkang Yang,Shuang Yang,Yueyang Yao,Xu Chen,Zirui Guo,Shengqiang Li,Weiran Li,Hanyu Li,Yaling Mou,Yan Qiu,Haiyang Yu,Xiao Liang,Hongsheng Li,Chao Feng", "background": "多模态嵌入模型旨在生成包含丰富信息的统一表示，从而支持多样化的跨模态任务。尽管从CLIP基于的双塔架构演进到大规模的视觉-语言模型，前期工作仍然在实际应用和商业场景中面临挑战，包括支持模态有限、训练机制不稳定和工业领域的差距。", "innovation": "引入了SAIL-Embedding全模态嵌入基础模型，通过定制化的训练策略和架构设计解决这些问题。提出了一个多阶段训练方案以增强表示学习的多功能性。具体包括内容感知渐进式训练以提高模型对多样下游任务的适应性和掌握丰富的跨模态能力，协作感知推荐增强训练通过从序列到项目和ID到项目的嵌入中提取知识并挖掘用户的历史兴趣，适应推荐场景下多模态表示。另外，还开发了随机专业化和数据驱动的模式匹配来增强模型训练的灵活性和泛化能力。", "conclusion": "实验结果表明，SAIL-Embedding在不同检索任务中均达到了最优性能。在多个实际场景中的在线实验中，我们观察到了推荐体验的关键指标Lifetime（LT）显著增加，例如在Douyin-Selected场景中，SAIL-Embedding导致7天和14天LT分别增加了0.158%和0.144%，对于Douyin信息流排名模型，SAIL-Embedding生成的匹配特征使AUC提高了0.08%。"}
{"llm_update_time": "20251015", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.12451", "html_url": "https://arxiv.org/abs/2510.12451", "title": "一种对平坦和尖锐极小值的函数中心视角", "title_en": "A Function Centric Perspective On Flat and Sharp Minima", "authors": "Israel Mason-Williams,Gabryel Mason-Williams,Helen Yannakoudakis", "background": "平坦极小值被认为与深度神经网络的泛化性能改善有关。然而，近期的研究表明，这种关联性并不简单，理论上的反例和经验上的异常情况都表明平滑度不能直接作为不良泛化能力的可靠指标。以往的研究主要集中在评估平滑度与泛化的关联性，但没有从算法函数特性的角度进行深入探讨。本文重新审视了模型性能与尖锐度之间的关系，认为尖锐度应被视为一种与函数相关的特性而非简单的平滑度指标。研究人员进行了广泛的实证研究，包括单目标优化到现代图像分类任务，发现经过正则化处理（如SAM、权重衰减或数据增强）后的尖锐极小值往往与更好的泛化、标定、鲁棒性和功能一致性相关联。在多个模型和数据集上，未经过正则化的基线模型倾向于收敛到更平坦的极小值，但却在所有安全指标上表现更差。这些发现表明，函数复杂性而非单独的平滑度决定了模型解空间的几何形状，尖锐的极小值可以反映更恰当的归纳偏置（尤其是在正则化条件下），这说明需要从函数中心的角度重新评估损失景观几何结构的重要性。", "innovation": "本文创新性地提出了尖锐度应被视为函数依赖的属性而非简单反映不良泛化的可靠指标的观点。通过广泛的实验研究，证明了经过正则化处理后的尖锐极小值与更好的泛化、标定、鲁棒性和功能一致性相关联，并强调了从函数中心的角度重新评估损失景观几何结构的重要性，提出了更准确的归纳偏置可能由尖锐的极小值反映的洞见。", "conclusion": "函数的复杂性而不是简单地平滑度决定了模型解空间的几何形状。尖锐的极小值可以体现更恰当的归纳偏置，尤其在正则化条件下。研究结果表明，需要从函数中心的视角来重新审视损失景观几何结构的重要性。"}
{"llm_update_time": "20251015", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.12720", "html_url": "https://arxiv.org/abs/2510.12720", "title": "Omni-Captioner: 数据pipeline, 模型和基准评测体系构建用于全方位细节感知", "title_en": "Omni-Captioner: Data Pipeline, Models, and Benchmark for Omni Detailed Perception", "authors": "Ziyang Ma,Ruiyang Xu,Zhenghao Xing,Yunfei Chu,Yuxuan Wang,Jinzheng He,Jin Xu,Pheng-Ann Heng,Kai Yu,Junyang Lin,Eng Siong Chng,Xie Chen", "background": "多元模态信息的精细感知对于推进人机交互至关重要。随着音频-视觉技术的进步，能够同时处理音频和视频信号的全方位语言模型（OLMs）变得很有前景，但当前这些模型尚不足以充分描绘和描述细微的信息细节。本文从数据管道、模型架构和基准测试三个角度全面系统地探究了全方位感知细节的方法和技术问题，旨在解决当前OLMs在精细细节捕捉和描述中的固有问题，提升模型性能，推动OLMs在多模态领域的应用与发展。", "innovation": "本文提出了一个名为Omni-Detective的自动化数据生成管道，集成工具调用，以自主生成高细节且少幻觉的多模态数据，这有助于显著提高模型在细节感知方面的性能。另外，研究设计了首个专门针对全方位感知细节的基准测试Omni-Cloze，该评测体系不仅保证了评估的稳定性和可靠性，还能准确地衡量模型在细粒度感知方面的表现，这是以往其他评测体系难以实现的任务。基于Omni-Detective生成的数据，研究训练了音频感知模型和多模态感知模型，分别在音频和多模态领域的评测中取得了最佳或接近最佳的表现，显著超过了现有最先进模型。", "conclusion": "研究展示并验证了Omni-Detective在数据密集度与幻觉控制之间取得的良好平衡，以及Omni-Cloze适用于多模态细节感知评测的优越性，这是以往研究尚未充分探索的领域。本工作的贡献在于，通过详细的数据生成管道、具备强大感知能力的模型和适合全面评估的评测体系，显著提升了模型在细节感知领域的性能，并推动了多元模态感知技术的发展。"}
{"llm_update_time": "20251015", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2402.05349", "html_url": "https://arxiv.org/abs/2402.05349", "title": "基于新PYRONEAR-2025数据集构建早期野火检测基准", "title_en": "Constructing a Real-World Benchmark for Early Wildfire Detection with the New PYRONEAR-2025 Dataset", "authors": "Mateo Lostanlen,Nicolas Isla,Jose Guillen,Renzo Zanca,Felix Veith,Cristian Buc,Valentin Barriere", "background": "早期野火检测（EWD）对于能够迅速响应并最小化野火扩散造成的负面影响至关重要。现有的数据集在规模和多样性方面有限，不足以支持有效的烟雾柱检测模型训练和评估，尤其是在实际应用中使用轻量级最先进的目标检测模型时，结果通常令人不满且不稳定。因此，迫切需要一个全面、多样化的数据集来改进野火检测技术。", "innovation": "PYRONEAR-2025 是一个综合了图像和视频的新数据集，涵盖了从公共摄像头网络、内部摄像头网络和部分合成及真实图片中获取的数据。该数据集包括约150,000个手动标注，涉及640场野火，覆盖法国、西班牙、智利和美国等地。此数据集的独特之处在于其规模和多样性，并且可以用于训练和评估包括序列模型在内的烟雾柱检测模型。使用轻量级的最先进的检测模型实验显示，PYRONEAR-2025 比现有数据集更具挑战性，但更稳定。同时，与其他公开数据集结合使用可以提升总体结果，并利用视频部分训练轻量级序列模型以提高总体召回率和保持早期检测的精确度。", "conclusion": "PYRONEAR-2025 数据集的推出显著提高了野火检测模型的准确性和稳定性，特别是在早期野火检测方面更为有效。同时，该数据集的开放性也促进了该领域的研究和技术进步。"}
{"llm_update_time": "20251015", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2407.07221", "html_url": "https://arxiv.org/abs/2407.07221", "title": "追溯联邦学习中毒攻击中的恶意客户端", "title_en": "Tracing Back the Malicious Clients in Poisoning Attacks to Federated Learning", "authors": "Yuqi Jia,Minghong Fang,Hongbin Liu,Jinghuai Zhang,Neil Zhenqiang Gong", "background": "联邦学习（FL）的训练阶段容易受到中毒攻击的影响，导致训练所得的全局模型对攻击者选择的目标输入进行误分类。目前的防御措施多侧重于保护FL的训练阶段，使得学习出的全局模型不受毒化，但当客户端的本地训练数据高度非独立同分布（non-iid）或恶意客户端数量较大时，这些防御措施往往效果有限，实验结果也证实了这一点。", "innovation": "我们提出了一种名为FLForensics的首个多阶段防御方法，旨在当现有训练阶段防御失效时，追踪在已知目标输入被错误分类后执行中毒攻击的恶意客户端。理论分析表明，FLForensics能够精确地区分善意和恶意客户端，不论攻击是否具适应性。实验验证了FLForensics在五种基准数据集上的有效性，包括追溯现有及适应性中毒攻击。", "conclusion": "FLForensics能够有效追踪联邦学习中毒攻击中的恶意客户端，无论是针对现有攻击还是适应性攻击均显示出良好的性能。这种方法通过理论和实践验证，提供了检测联邦学习中毒攻击的新手段，增强了整体系统的安全性，尤其在非 iid 的客户端数据和大量恶意客户端的情况下。"}
{"llm_update_time": "20251015", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2404.07214", "html_url": "https://arxiv.org/abs/2404.07214", "title": "视觉-语言模型前沿探究：当前方法与未来方向综述", "title_en": "Exploring the Frontier of Vision-Language Models: A Survey of Current Methodologies and Future Directions", "authors": "Akash Ghosh,Arkadeep Acharya,Sriparna Saha,Vinija Jain,Aman Chadha", "background": "大型语言模型（LLMs）的出现极大地重塑了人工智能革命的轨迹，但这些模型主要擅长处理文本信息，缺乏视觉处理能力，为此，研究人员试图将视觉能力集成到LLMs中，从而产生了视觉-语言模型（VLMs）。这些模型被广泛用于图像字幕和视觉问答等复杂任务。本文通过文献综述的形式，全面探讨了VLMs领域的关键进展，并对VLMs进行了分类，分为专注于视觉-语言理解的模型、处理多模态输入并生成单一模态（文本）输出的模型，以及既能接收又能生成多模态输入的模型。文章对于每一类模型详细解析了其基础架构、训练数据来源及其优势和局限性，为读者提供了全面理解VLMs核心组成部分的框架。此外，还分析了VLMs在多种基准数据集上的性能，旨在提供一个全面了解VLMs多样景观的视角。", "innovation": "本文通过综述的形式，全面探讨了VLMs领域的关键进展，并详细分析了不同类型的VLMs的基础架构、训练数据来源以及优势和局限性，为读者提供了全面理解VLMs核心组成部分的框架。同时，还分析了VLMs在多种基准数据集上的性能，为今后研究指明了方向。", "conclusion": "通过本文的分析，读者可以全面了解VLMs的当前研究现状。未来的研究将聚焦于进一步提高VLMs的性能和适应性，以应对更加复杂和多样的任务需求。"}
{"llm_update_time": "20251015", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2407.13753", "html_url": "https://arxiv.org/abs/2407.13753", "title": "通过动作单元的时间分析探索抑郁的面部生物标志物", "title_en": "Exploring Facial Biomarkers for Depression through Temporal Analysis of Action Units", "authors": "Aditya Parikh,Misha Sadeghi,Robert Richer,Lydia Helene Rupp,Lena Schindler-Gmelch,Marie Keinert,Malin Hager,Klara Capito,Farnaz Rahimi,Bernhard Egger,Matthias Berking,Bjoern M. Eskofier", "background": "抑郁症以持久的悲伤和兴趣丧失为特征，严重影响日常功能，已成为普遍存在的心理健康问题。传统的诊断方法依赖于主观评估，迫切需要客观方法进行准确的诊断。本研究探讨了使用面部动作单元（AUs）和情绪作为抑郁的生物标志物。我们分析了被诊断为有或没有抑郁的参与者的情绪表达视频数据。方法包括详细的特征提取、关键AUs的平均强度对比以及时间序列分类模型的应用。此外，我们还使用主成分分析（PCA）和多种聚类算法来研究情绪表达模式的变异性。结果表明，有抑郁和无抑郁的组别在与悲伤和快乐相关的AUs的强度方面存在显著差异，强调了面部分析在抑郁评估中的潜力。", "innovation": "本研究创新性地采用时间序列分析法和多种面部动作单元（AUs）来评估和诊断抑郁症，通过客观数据提供了一种新的诊断工具，优于传统的主观评估方法。", "conclusion": "本研究结果显示，面部动作单元（AUs）和情绪的差异可以作为有效的生物标志物来评估抑郁症。未来研究应进一步探索和验证这种生物标志物的有效性和实用性，为临床诊断提供有力支持。"}
{"llm_update_time": "20251015", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2407.02688", "html_url": "https://arxiv.org/abs/2407.02688", "title": "Funny-Valen-Tine: 规划解决方案分布增强机器抽象推理能力", "title_en": "Funny-Valen-Tine: Planning Solution Distribution Enhances Machine Abstract Reasoning Ability", "authors": "Ruizhuo Song,Beiming Yuan", "background": "视觉抽象推理是图像处理的核心。本文提出了一个统一的概率高亮基线模型Valen，并在两个具体任务（RPM和Bongard-Logo）中表现出色。通过分析模型的内部机制，发现求解器将每个任务视为某种分布，主要样本符合此分布而辅助样本不符合；因此，学习目标不是由正确解单独定义，而是由两组样本共同决定。", "innovation": "文章引入了Tine，它是对抗式适配器，促进Valen模型趋向正确解的密度分布，但由于对抗训练不稳，转而使用Funny，这是一种快速的高斯混合模型，直接估计正确解的密度分布，而不进行对抗游戏。还进一步将这一范例应用于SBR，以增强渐进模式规划能力。实验结果表明，明确规划解决方案分布是实现更强、更可解释的抽象推理的关键。", "conclusion": "广泛的实验表明，明确规划解决方案分布是实现更强、更可解释的抽象推理的关键。代码可在下方网址获取：this https URL"}
{"llm_update_time": "20251015", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2412.13443", "html_url": "https://arxiv.org/abs/2412.13443", "title": "DarkIR: Robust Low-Light Image Restoration", "title_en": "DarkIR: Robust Low-Light Image Restoration", "authors": "Daniel Feijoo,Juan C. Benito,Alvaro Garcia,Marcos V. Conde", "background": "摄影在夜间或暗环境下通常会面临噪声、低光照和模糊等问题，这些原因是由于环境昏暗和常用的长时间曝光造成的。虽然在这些条件下，去模糊和低光照图像增强（LLIE）是相关的，但大多数图像恢复方法将这些任务分开解决。大多数基于Transformer的模型专注于这些任务，但本文提出了一种新的注意力机制，用于增强高效的CNN的感受野。", "innovation": "提出了DarkIR，这是一种高效的、鲁棒的多任务低光照图像恢复的神经网络。与当前的基于Transformer的模型不同，本文提出的新注意力机制有效地提高了高效CNN的感受野，从而在参数和MAC操作上减少了计算成本。并且在LOLBlur、LOLv2和Real-LOLBlur数据集上取得了新的最佳结果，能够泛化到实际的夜间和暗光图像。", "conclusion": "暗光环境下图像恢复的DarkIR模型在效率和鲁棒性方面有所改进，能够在流行的LowLightLowBlur（LOLBlur）、LOL版本2（LOLv2）和真实世界模糊数据集（Real-LOLBlur）上取得新的最佳结果，并能够很好地应用于实际世界中的夜间和暗光环境下的图像恢复任务。"}
{"llm_update_time": "20251015", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2410.16910", "html_url": "https://arxiv.org/abs/2410.16910", "title": "TreeDiffusion：基于层次生成聚类的条件扩散模型", "title_en": "TreeDiffusion: Hierarchical Generative Clustering for Conditional Diffusion", "authors": "Jorge da Silva Gonçalves,Laura Manduchi,Moritz Vandenhirtz,Julia E. Vogt", "background": "生成建模和聚类在机器学习中通常是两个独立的任务。变分自编码器（VAEs）因其能够同时实现这两者而得以广泛应用，为生成聚类提供了框架。尽管VAEs能够学习到在潜在空间中具有含义的聚类表示，但它们往往难以生成高质量的样本。", "innovation": "本文通过引入TreeDiffusion，一种基于深度生成模型的层次聚类条件扩散模型，解决了上述问题。TreeDiffusion 结合了VAE学习到的层次结构聚类表示，并在扩散模型中条件化这些表示，从而产生高质量且特定于聚类的生成结果。该方法分为两步：首先，基于VAE的聚类模型学习数据的层次结构表示；其次，一个意识聚类的扩散模型基于学习到的层次结构生成图像。", "conclusion": "本研究通过顺序比较我们的方法与其他的条件策略，在真实数据集上展示了基于层次聚类表示的扩散模型在生成性能上的改进。此外，本方法的一个重要优势是可以生成既代表性和又特定于每个聚类的图像，从而更好地可视化学到的潜在结构。通过利用VAE学习的结构，我们的方法克服了基于VAE的聚类方法的生成限制，从而推进了生成聚类领域的研究。"}
{"llm_update_time": "20251015", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2412.15939", "html_url": "https://arxiv.org/abs/2412.15939", "title": "BLIP2IDC 和合成增强重新构架图像差异描述", "title_en": "Reframing Image Difference Captioning with BLIP2IDC and Synthetic Augmentation", "authors": "Gautier Evennou,Antoine Chaffin,Vivien Chappelier,Ewa Kijak", "background": "在过去几年中，生成模型质量的提升使得大规模生成修图图像成为可能。为了应对这类技术带来的负面影响，图像差异描述（IDC）任务旨在描述两幅图像之间的差异。尽管该任务在简单3D渲染图像上能够成功解决，但在处理真实世界图像时却遇到了困难。这种困难的原因有两个方面：训练数据的稀缺性，以及捕捉复杂图像之间细微差异的难度。", "innovation": "本文提出了一种简单但有效的框架，用于将现有的图像描述模型适应到IDC任务，并扩大IDC数据集。具体而言，本文介绍了BLIP2IDC，这是BLIP2对IDC任务的手动调整版本，实验结果表明在真实世界的IDC数据集上其性能显著优于双流方法。此外，本文还提出了使用合成增强策略提高IDC模型性能的通用方法，该策略生成了高质量的数据，从而创建了一个挑战性的新数据集Syned1，适合用于IDC任务。", "conclusion": "本文提出的方法不仅能够提高现有的图像描述模型在处理图像差异描述任务上的性能，还提供了一种简单的合成增强策略，能够生成高质量的数据集，从而显著提高IDC任务的性能和效率。"}
{"llm_update_time": "20251015", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2502.14894", "html_url": "https://arxiv.org/abs/2502.14894", "title": "FOCUS on Contamination: A Geospatial Deep Learning Framework with a Noise-Aware Loss for Surface Water PFAS Prediction", "title_en": "FOCUS on Contamination: A Geospatial Deep Learning Framework with a Noise-Aware Loss for Surface Water PFAS Prediction", "authors": "Jowaria Khan,Alexa Friedman,Sydney Evans,Rachel Klein,Runzi Wang,Katherine E. Manz,Kaley Beins,David Q. Andrews,Elizabeth Bondi-Kelly", "background": "全氟和多氟烷基物质（PFAS）是广泛存在于不粘炊具等产品中的环保污染物，具有严重的健康风险。准确地绘制PFAS污染图对于指导有针对性的修复工作和保护公众及环境健康至关重要，但由于测试成本高昂和模拟其传播的难度，大型区域的PFAS检测仍然具有挑战性。", "innovation": "引入了一种具有标签噪声感知损失函数的地理空间深度学习框架FOCUS，用于预测大面积水面的PFAS污染。通过整合水文流数据、土地覆盖信息和已知PFAS来源的地理位置信息，该方法利用空间和环境上下文来提高预测准确性。通过广泛的消融研究、鲁棒性分析、实地验证和与稀疏分割、Kriging、污染物传输模拟等基准方法的对比分析，验证了其性能。", "conclusion": "结果和专家反馈表明，该框架具有扩展PFAS监测的潜力。"}
{"llm_update_time": "20251015", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2501.06031", "html_url": "https://arxiv.org/abs/2501.06031", "title": "生成、转化、适应：基于VLM的迭代转化学习", "title_en": "Generate, Transduct, Adapt: Iterative Transduction with VLMs", "authors": "Oindrila Saha,Logan Lawrence,Grant Van Horn,Subhransu Maji", "background": "当前的transductive零样本学习借助于视觉语言模型内部的图像相似性来提升分类准确性，但极少有研究探讨这个背景下语言空间的结构。已有研究主要集中在直接利用视觉和语言模型进行单一的学习过程上，而较少从迭代的角度探讨语言与视觉空间的交互影响。", "innovation": "本文提出了GTA-CLIP，一种结合语言模型监督进行联合语言和视觉空间转化学习的新方法。GTA-CLIP的方法分为三步：逐步探索属性空间、属性增强的转化推理过程和基于数据集内推断出的标签微调编码器。通过CLIP编码器实验，GTA-CLIP在12个数据集和3个编码器上相比CLIP和转化学习CLIP分别在零样本设置中平均性能提升了8.6%和3.7%，并且在少量样本设置下也观察到类似的性能改进。此外，还通过消融实验展示了每一步的有效性，并可视化了视觉和语言空间随迭代学习的变化过程。", "conclusion": "通过实验证明，GTA-CLIP能够显著提高零样本和少量样本下的分类准确性。GTA-CLIP方法不仅展示了其在不同数据集上的广泛适用性和优势，还通过详细的分析和可视化展示了在迭代转化学习过程中语言和视觉空间的交互变化机制。"}
{"llm_update_time": "20251015", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2408.10845", "html_url": "https://arxiv.org/abs/2408.10845", "title": "CoVLA：自主驾驶的全面视觉语言行为数据集", "title_en": "CoVLA: Comprehensive Vision-Language-Action Dataset for Autonomous Driving", "authors": "Hidehisa Arai,Keita Miwa,Kento Sasaki,Yu Yamaguchi,Kohei Watanabe,Shunsuke Aoki,Issei Yamamoto", "background": "自主驾驶尤其在处理复杂和不可预测的场景时，需要具备复杂的推理和规划能力。尽管多模态大型语言模型（MLLMs）为此提供了一种有前景的方法，但它们的应用大多限于理解复杂环境或生成高级驾驶命令，很少有研究将它们扩展到端到端路径规划。由于缺乏覆盖视觉、语言和行为的大规模标注数据集，这成为一个重要的研究瓶颈。为解决这个问题，本文提出了一种名为CoVLA（Comprehensive Vision-Language-Action）的新数据集，该数据集包含超过80小时的现实驾驶视频。利用基于自动化数据处理和生成字幕的新颖可扩展方法，创建了准确的驾驶轨迹，并配以详细的自然语言描述的驾驶环境和操作，利用车内传感器的原始数据，使其在规模和注释丰富度上超越现有数据集。利用CoVLA，研究了处理不同类型驾驶场景的MLLM的驾驶能力，结果表明模型在生成连贯的语言和行为输出方面表现出色，强调了视觉语言行为（VLA）模型在自动驾驶领域的潜力。", "innovation": "本文创新地提出了CoVLA数据集，该数据集利用自动化数据处理和字幕生成管道，产生了准确的驾驶轨迹，配以详细的自然语言描述的驾驶环境和操作。此数据集使用车内传感器的原始数据，使其在规模和注解丰富度上超过了现有数据集。通过CoVLA，研究了MLLM的各种驾驶场景中的驾驶能力，结果展示了模型在生成连贯的语言和行为输出方面的强效性，突出了VLA模型在自动驾驶领域的潜力。该数据集为开发鲁棒、可解释和数据驱动的自动驾驶系统奠定了框架，促进了一种更安全和可靠的自动驾驶车辆。", "conclusion": "CoVLA数据集为训练和评估VLA模型提供了综合平台，支持了更安全和可靠的自动驾驶车辆的发展。该数据集专为学术研究而开源。"}
{"llm_update_time": "20251015", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2504.06486", "html_url": "https://arxiv.org/abs/2504.06486", "title": "注意（数据）差距：在小数据应用中评估视觉系统", "title_en": "Mind the (Data) Gap: Evaluating Vision Systems in Small Data Applications", "authors": "Samuel Stevens,S M Rayeed,Jenna Kline", "background": "在特定的计算机视觉任务中，AI工具的实际应用依赖于几百到几千个带有标签的样本量。这种小数据量的情况对需要昂贵专家注解的应用至关重要，如生态监测、医疗诊断或工业质量控制。然而，计算机视觉研究忽视了小数据区间的评估，越来越多的关注于零样本和少样本学习。我们将自然世界任务（NeWT）基准用于跨不同训练集大小比较多模态大规模语言模型（MLLMs）和仅视觉方法。这些视觉方法在整个小数据区间内表现出性能提升，在训练样本数量超过10个时，这种差距逐渐扩大。", "innovation": "我们首次在小数据背景下比较了多模态大规模语言模型和仅视觉方法，并强调在人工智能研究中明确进行小数据评估的重要性，以更好地将理论进展与实际部署联系起来。", "conclusion": "研究结果表明，尽管在早期多模态方法表现出一定的性能瓶颈，但在小数据区间内，仅视觉方法持续表现出更好的性能。因此，应重视在AI研究中进行小数据范围内的明确评估，以更好地连接理论成果与实际应用。"}
{"llm_update_time": "20251015", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2503.09949", "html_url": "https://arxiv.org/abs/2503.09949", "title": "UVE: MLLMs作为AI生成视频的统一评估者？", "title_en": "UVE: Are MLLMs Unified Evaluators for AI-Generated Videos?", "authors": "Yuanxin Liu,Rui Zhu,Shuhuai Ren,Jiacong Wang,Haoyuan Guo,Xu Sun,Lu Jiang", "background": "随着视频生成模型（VGMs）的快速增长，开发可靠且全面的自动评估指标对于人工智能生成的视频（AIGVs）变得至关重要。现有方法要么使用为其他任务优化的现成模型，要么依赖人类评估数据来训练专门的评估者。这些方法在特定评估方面受到局限，难以应对越来越精细和全面的评估需求。", "innovation": "本文探讨了利用多模态大型语言模型（MLLMs）作为AI生成视频的统一评估者的可能性，利用它们强大的视觉感知和语言理解能力。为评估自动评估指标在统一AI生成视频评价中的表现，作者引入了一个名为UVE-Bench的基准。该基准收集了由领先VGMs生成的视频，并提供了15个评估方面的两两人类偏好注释。作者利用UVE-Bench广泛评估了18个MLLMs。结果表明，尽管先进的MLLMs（如Qwen2VL-72B和InternVL2.5-78B）仍落后于人类评估者，但它们展示了在统一AI生成视频评价中的巨大潜力，远超现有的专用评估方法。此外，作者还深入分析了影响基于MLLM的评估器性能的关键设计选择，为未来AI生成视频评估研究提供了有价值的见解。", "conclusion": "虽然先进的MLLMs（例如Qwen2VL-72B和InternVL2.5-78B）仍然落后于人类评估者，但它们在统一AI生成视频评价中表现出了巨大的潜力，显著超过了现有的专属评估方法。此外，作者还深入分析了关键设计选择，这些选择影响了MLLM驱动的评估器的性能，为未来研究提供了宝贵见解。"}
{"llm_update_time": "20251015", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2504.16564", "html_url": "https://arxiv.org/abs/2504.16564", "title": "SAIP-Net：通过光谱自适应信息传播增强遥感图像分割", "title_en": "SAIP-Net: Enhancing Remote Sensing Image Segmentation via Spectral Adaptive Information Propagation", "authors": "Zhongtao Wang,Xizhe Cao,Yisong Chen,Guoping Wang", "background": "遥感图像的语义分割需要精准的边界和内在类的一致性，但传统的分层模型难以满足这些需求。传统的模型在空间域特征融合和感受野不足的问题上存在限制，这使得语义分割的效果不尽如人意。", "innovation": "提出了一种新的频率感知分割框架——SAIP-Net，该框架利用了光谱自适应信息传播(Spectral Adaptive Information Propagation, SAIP)。SAIP-Net通过自适应频率过滤和多尺度感受野增强，有效抑制了类内特征的一致性问题，并使边界线条更加清晰。这一框架显著改善了遥感图像分割的性能，特别是在结合光谱自适应策略与扩展的感受野方面表现出色。", "conclusion": "综合实验证明，SAIP-Net在遥感图像分割任务上的性能显著优于现有最先进的方法，证明了光谱自适应策略与扩展感受野相结合的有效性。"}
{"llm_update_time": "20251015", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2503.19764", "html_url": "https://arxiv.org/abs/2503.19764", "title": "OpenLex3D：开放词汇3D场景表示的分层评估基准", "title_en": "OpenLex3D: A Tiered Evaluation Benchmark for Open-Vocabulary 3D Scene Representations", "authors": "Christina Kassab,Sacha Morin,Martin Büchner,Matías Mattamala,Kumaraditya Gupta,Abhinav Valada,Liam Paull,Maurice Fallon", "background": "当前的3D场景理解主要依赖封闭词汇的语言模型，这些模型通过自然语言进行交互的能力有限。现有的评估主要集中在具有封闭语义的语料库上，这无法捕捉语言的丰富性和多样性。", "innovation": "该研究提出了OpenLex3D，一个专门的基准用于评估开放词汇的3D场景表示。它为来自Replica、ScanNet++和HM3D的数据集提供了全新的标签注释，能更好地捕捉现实世界的语言多样性，并通过引入同义对象类别和更细致的描述，提供了原来的13倍更多的标签。此外，该基准包括开放集3D语义分割任务和物体检索任务，以评估现有的开放词汇3D方法，揭示潜在的改进方向。", "conclusion": "通过OpenLex3D基准，研究人员获得了关于特征精度、分割以及下游能力的见解。该基准已公开发布。"}
{"llm_update_time": "20251015", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2505.08685", "html_url": "https://arxiv.org/abs/2505.08685", "title": "多注释者多器官分割（CURVAS）挑战结果中的校准与不确定性", "title_en": "Calibration and Uncertainty for multiRater Volume Assessment in multiorgan Segmentation (CURVAS) challenge results", "authors": "Meritxell Riera-Marin,Sikha O K,Julia Rodriguez-Comas,Matthias Stefan May,Zhaohong Pan,Xiang Zhou,Xiaokun Liang,Franciskus Xaverius Erick,Andrea Prenner,Cedric Hemon,Valentin Boussot,Jean-Louis Dillenseger,Jean-Claude Nunes,Abdul Qayyum,Moona Mazher,Steven A Niederer,Kaisar Kushibar,Carlos Martin-Isla,Petia Radeva,Karim Lekadir,Theodore Barfoot,Luis C. Garcia Peraza Herrera,Ben Glocker,Tom Vercauteren,Lucas Gago,Justin Englemann,Joy-Marie Kleiss,Anton Aubanell,Andreu Antolin,Javier Garcia-Lopez,Miguel A. Gonzalez Ballester,Adrian Galdran", "background": "深度学习已成为医学图像分割的主要方法，但确保这些模型的可靠性和临床适用性需要解决注释变异、校准和不确定性估计等关键挑战。因此，研究者们创建了多注释者多器官分割（CURVAS）挑战，旨在突出多名注释者在建立更全面的金标准中的关键作用，强调分割具有主观性，利用注释者之间的变异对稳健模型进行评估至关重要。", "innovation": "该挑战吸引七支队伍参与，提交了多种深度学习模型，并使用Dice相似系数（DSC）、预期校准误差（ECE）和连续排名概率分数（CRPS）等指标进行评估。通过结合共识和分歧的金标准，评估了深度学习模型处理不确定性的情况及其信心估计是否与真实分割性能一致。研究还展示了训练数据集多样且富含预训练知识的分割模型具有更高的稳健性，特别是在标准解剖结构偏差的情况下。最佳模型实现了高DSC和良好的校准不确定性估计。", "conclusion": "研究表明，良好的校准模型与结果质量高度相关。此外，本研究强调了多注释者金标准、深入的校准评估和不确定性感知评估的必要性，以开发值得信赖且临床可靠的基于深度学习的医学图像分割模型。"}
{"llm_update_time": "20251015", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2505.12434", "html_url": "https://arxiv.org/abs/2505.12434", "title": "VideoRFT: 通过强化微调激发LLM的视频推理能力", "title_en": "VideoRFT: Incentivizing Video Reasoning Capability in MLLMs via Reinforced Fine-Tuning", "authors": "Qi Wang,Yanrui Yu,Ye Yuan,Rui Mao,Tianfei Zhou", "background": "大语言模型（LLMs）通过强化微调（RFT）展现出在实现人类级别的推理能力方面的巨大潜力，并已扩展到大规模语言模型（MLLMs）。然而，对视频内容进行推理仍然是一个持续的挑战，因为视频数据包含复杂的逻辑结构和时间上的因果关系。", "innovation": "提出了VideoRFT，一种新的方法来扩展RFT范式，以培养MLLMs在视频推理方面的类人能力。该方法通过构建多专家驱动的、基于认知的CoT（链式思维）构建流水线，先通过提示策略引导LLM生成初步的CoTs，再通过MLLM进行修正，确保视觉一致性，减少视觉幻觉。这产生了两个新数据集：VideoRFT-CoT-102K用于监督微调（SFT），VideoRFT-RL-310K用于强化学习（RL）。此外，提出了一个新的语义一致性奖励，明确促进文本推理和视觉证据之间的对齐，促使模型产生基于视觉输入的连贯、情境感知的推理输出。", "conclusion": "广泛的实验表明，VideoRFT在六个视频推理基准测试中达到了最先进的性能。"}
{"llm_update_time": "20251015", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2503.00399", "html_url": "https://arxiv.org/abs/2503.00399", "title": "从人类感知角度使用LMMs进行语义分离的极低比特率图像压缩", "title_en": "Extremely low-bitrate Image Compression Semantically Disentangled by LMMs from a Human Perception Perspective", "authors": "Juan Song,Lijie Yang,Mingtao Feng", "background": "在极低比特率下保持图像的语义一致性和高感知质量一直是一项艰巨的挑战。受人类逐步感知机制的启发，本文提出了一种语义分离图像压缩框架（SEDIC）。该框架通过先训练一个图像编码器获得极简压缩参考图像，然后使用LMMs提取语义关键分量，包括整体描述、对象详细描述和语义分割掩码。通过基于预训练ControlNet的注意力引导对象恢复模型（ORAG）恢复对象细节，并设计多阶段语义图像解码器逐对象恢复细节，最终生成高质量高保真的重构图像。", "innovation": "本文提出了一个新的语义分离图像压缩框架SEDIC，该框架通过学习图像编码器和利用LMMs提取语义关键分量，结合注意力引导的对象恢复模型ORAG，实现逐对象恢复细节，最终生成高质量的重构图像。与现有技术相比，SEDIC在极低比特率下表现出更优的感知质量和语义一致性。", "conclusion": "实验结果表明，SEDIC在极低比特率下显著优于现有方法，能更好地保持感知质量和语义一致性。"}
{"llm_update_time": "20251015", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2504.08307", "html_url": "https://arxiv.org/abs/2504.08307", "title": "DSM: 构建用于3D视觉定位的多元语义地图", "title_en": "DSM: Constructing a Diverse Semantic Map for 3D Visual Grounding", "authors": "Qinghongbing Xie,Zijian Liang,Fuhao Li,Long Zeng", "background": "现有的3D视觉定位方法常常受到限制，它们要么重点关注几何和视觉线索，要么像传统的3D场景图一样，缺乏进行复杂推理所需的多维属性。这限制了语义理解和场景表示的有效性。", "innovation": "引入了Diverse Semantic Map (DSM)框架，通过叠加多种来自VLM的语义信息（包括外观、物理属性和功能用途）来丰富鲁棒几何模型，构建一种在线融合多视角观察的持续全面世界模型，并提出了基于这种语义丰富地图的DSM-Grounding新框架，将视觉定位从自由形式的VLM查询转变为结构化的语义推理过程，显著提高了准确性和可解释性。", "conclusion": "经过广泛评估，验证了DSM-Grounding方法在ScanRefer基准测试中的优越性，总体IoU@0.5达到了59.06%，超越了其他方法10%。在语义分割方面，DSM取得了67.93%的F-mIoU，优于所有基线，包括专用信息的优势方法。进一步在物理机器人中成功部署，验证了框架在实际应用中的实用价值。"}
{"llm_update_time": "20251015", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2505.05074", "html_url": "https://arxiv.org/abs/2505.05074", "title": "视觉效应预测：综述与再现性", "title_en": "Visual Affordance Prediction: Survey and Reproducibility", "authors": "Tommaso Apicella,Alessio Xompero,Andrea Cavallaro", "background": "视觉效应是指代理在观察相机视角下对物体可能执行的动作。对于抓取检测、效应分类、效应分割和手部姿态估计等任务，视觉效应预测的公式化方式各不相同。这种多样性的公式导致了不一致的定义，阻碍了不同方法之间的公正比较。因此，本文提出了一种全面且统一的视觉效应预测公式，考虑了目标对象的完整信息以及代理与对象的交互来完成任务。该整合公式允许我们全面和系统地回顾不同的视觉效应研究，突出方法和数据集的优缺点。此外，我们还讨论了再现性问题，如方法实现的不可用性和实验设置细节的缺失，这些问题使得视觉效应预测的基准不公正且不可靠。为了促进透明度，我们引入了《行为表》，这是一种详细说明方法、数据集和验证的文档，旨在支持未来领域内的再现性和公平性。", "innovation": "本文提出了一种统一的视觉效应预测公式，全面考虑了目标对象的完整信息和代理与对象的交互，以完成任务。这种新的整合公式为视觉效应预测的研究提供了全面和系统的视角，促进了方法和数据集的公正比较。同时，为了解决再现性问题，本文还介绍了《行为表》文档，为研究方法的透明性提供了支持。", "conclusion": "本文全面回顾了不同的视觉效应研究，突出了方法和数据集的优缺点，并讨论了再现性问题。此外，我们引入了《行为表》文档，旨在支持未来领域内的再现性和公平性，从而促进社区内研究的一致性和可靠性。"}
{"llm_update_time": "20251015", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2503.07392", "html_url": "https://arxiv.org/abs/2503.07392", "title": "SPEED: 面向扩散模型的可扩展、精确且高效的概念删除方法", "title_en": "SPEED: Scalable, Precise, and Efficient Concept Erasure for Diffusion Models", "authors": "Ouxiang Li,Yuan Wang,Xinting Hu,Houcheng Jiang,Tao Liang,Yanbin Hao,Guojun Ma,Fuli Feng", "background": "大规模文本到图像（T2I）扩散模型中概念的删除变得越来越重要，因为版权侵权、不当内容和隐私侵犯等问题日益受到关注。在可扩展的应用场景中，基于微调的方法在精确删除多个目标概念方面耗时且效率低下，而实时编辑方法由于存在冲突的优化目标，在编辑过程中往往会影响非目标概念的生成质量。为此，我们引入了SPEED，一种直接编辑模型参数的高效概念删除方法。SPEED通过寻找一个零空间，即一个不会影响非目标概念的模型编辑空间，从而实现高效和精确的概念删除。为了改进零空间的优化，我们引入了三种互补策略：基于影响的先验筛选（IPF）、有向先验增强（DPA）和不变等式约束（IEC），以确保在T2I生成过程中保持关键不变量。通过多个概念删除任务的广泛评估表明，SPEED 在保持非目标概念方面表现优于现有方法，实现了高效且高保真的概念删除，并在短短5秒内成功删除了100个概念。我们的代码和模型可在以下网址获取：this https URL.", "innovation": "SPEED采用直接编辑模型参数的方法，通过寻找一个零空间来实现高效和精准的概念删除。SPEED引入了三种策略：基于影响的先验筛选（IPF）、有向先验增强（DPA）和不变等式约束（IEC），以优化零空间并保持关键不变量。这些策略使得SPEED能够在保持非目标概念的同时，高效且保真地删除目标概念，实现可扩展的概念删除。", "conclusion": "广泛的评估结果显示，SPEED在整个概念删除任务中表现出色，能够在保持非目标概念的同时，高效地删除100个概念，并在短短5秒内完成。"}
{"llm_update_time": "20251015", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2505.13731", "html_url": "https://arxiv.org/abs/2505.13731", "title": "GeoRanker: 全球范围内的距离感知排名方法用于图像地理定位", "title_en": "GeoRanker: Distance-Aware Ranking for Worldwide Image Geolocalization", "authors": "Pengyue Jia,Seongheon Park,Song Gao,Xiangyu Zhao,Sharon Li", "background": "全球图像地理定位的任务是从地球上任何地方拍摄的图片中预测GPS坐标，由于不同地区视觉内容的巨大多样性，这一任务具有根本挑战性。目前的解决方案通常采用两阶段管道：首先检索候选点，然后选择最佳匹配项。然而，这些方法通常依靠简单的相似性启发式方法和点对点监督，未能建模候选点之间的空间关系。", "innovation": "本文提出了一种基于距离感知排名框架的GeoRanker，利用大型的视觉-语言模型，联合编码查询-候选交互，并预测地理邻近性。此外，还引入了多阶距离损失，可以排名绝对和相对距离，使得模型能够推理结构化空间关系。同时，还创建了GeoRanking数据集，这是第一个专门为此类地理排名任务设计的多模态候选信息数据集。", "conclusion": "GeoRanker 在两个标准基准测试（IM2GPS3K 和 YFCC4K）上达到了最先进的结果，显著优于当前的最佳方法。"}
{"llm_update_time": "20251015", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2505.15877", "html_url": "https://arxiv.org/abs/2505.15877", "title": "突出关键内容：面向属性聚焦图像检索的可提示嵌入", "title_en": "Highlighting What Matters: Promptable Embeddings for Attribute-Focused Image Retrieval", "authors": "Siting Li,Xiang Gao,Simon Shaolei Du", "background": "传统的图像检索方法倾向于关注图像中的全局语义和主题，而忽略了其他重要细节。对于属性聚焦的查询任务而言，现有的方法如CLIP等表现不佳且表现失衡，部分原因是它们的图像嵌入主要集中在全局语义和主要主题上，而忽视了其他关键属性。为此，该研究构建了COCO-Facet基准测试集，包含了9,112个关于图像多样属性的查询，用于评估当前图像检索方法处理属性聚焦查询的能力。", "innovation": "研究者提出了一种基于可提示嵌入的图像检索方法，能够突出显示所需的关键属性。这种方法通过利用多模态检索器生成可提示的图像嵌入，可以提升性能。此外，研究还提供了两种加速策略：预处理可提示嵌入和使用线性近似方法，这些策略分别在预定义提示和仅在推理过程中可用的提示条件下，实现了5%和3%的召回率提升。", "conclusion": "该研究表明，使用一般的图像嵌入进行检索可能不适合属性聚焦查询，而基于可提示嵌入的方法可以显著提高此类查询的性能。研究还强调了预处理和线性近似方法的应用，以提高实际应用中的可操作性。"}
{"llm_update_time": "20251015", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2505.16815", "html_url": "https://arxiv.org/abs/2505.16815", "title": "图像质量评估在类身人工智能中的应用", "title_en": "Image Quality Assessment for Embodied AI", "authors": "Chunyi Li,Jiaohao Xiao,Jianbo Zhang,Farong Wen,Zicheng Zhang,Yuan Tian,Xiangyang Zhu,Xiaohong Liu,Zhengxue Cheng,Weisi Lin,Guangtao Zhai", "background": "近期，类身人工智能（Embodied AI）发展迅速，然而它仍主要部署在实验室中，受实际环境各种扭曲的限制，其应用范围有限。传统的图像质量评估（IQA）方法旨在预测人类对扭曲图像的偏好；但是，尚未有人工智能方法能够评估图像在类身任务中的可用性，即对机器人的感知质量。因此，本文为克服上述问题，提出了IQA for Embodied AI这一课题", "innovation": "本文首次提出了IQA for Embodied AI这一课题，并做了以下创新：1）基于Mertonian系统和元认知理论，构建设感知-认知-决策-执行流水线，并定义了全面的主观评分收集流程；2）建立了Embodied-IQA数据库，包含超过36,000张参考/扭曲图像对，提供了超过500万精细级别的注释，来源于视觉语言模型/视觉语言动作模型/真实机器人；3）评估了主流IQA方法在Embodied-IQA数据库上的性能，展示了需要为类身人工智能开发更准确的质量指标的需求。", "conclusion": "通过这些评估，本文希望能够促进类身人工智能在复杂扭曲环境下的实际应用。"}
{"llm_update_time": "20251015", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2505.17011", "html_url": "https://arxiv.org/abs/2505.17011", "title": "在1D潜在空间中学习适应性和时间因果性视频分词", "title_en": "Learning Adaptive and Temporally Causal Video Tokenization in a 1D Latent Space", "authors": "Yan Li,Changyao Tian,Renqiu Xia,Ning Liao,Weiwei Guo,Junchi Yan,Hongsheng Li,Jifeng Dai,Hao Li,Xue Yang", "background": "目前存在多种视频编码和生成方法，但这些方法通常依赖于固定的视频分词方式，缺乏灵活性，在处理不同内容和场景时存在局限性。", "innovation": "该研究提出了一种名为AdapTok的新方法，这是一种自适应时间因果视频分词器，可以根据视频内容灵活分配不同帧的令牌。AdapTok采用了区块式遮罩策略和区块因果评分器等创新设计，提高了视频重建和生成的效果，且在不同令牌预算下表现出色，更具可扩展性和效率。", "conclusion": "通过广泛的实验，该方法在UCF-101和Kinetics-600数据集上的视频重建和生成任务中展示了其有效性。在没有额外图像数据的情况下，AdapTok提高了重建质量和生成性能，证明其自适应分词策略对于优化视频生成模型至关重要。"}
{"llm_update_time": "20251015", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2506.05864", "html_url": "https://arxiv.org/abs/2506.05864", "title": "CryoFastAR：快速的冷冻电镜初始重构简易方法", "title_en": "CryoFastAR: Fast Cryo-EM Ab Initio Reconstruction Made Easy", "authors": "Jiakai Zhang,Shouchen Zhou,Haizhao Dai,Xinhang Liu,Peihao Wang,Zhiwen Fan,Yuan Pei,Jingyi Yu", "background": "未有序的图像姿态估计对于三维重建、机器人技术和科学成像（如冷冻电子显微镜中的蛋白质近原子重建）来说是基础性的。虽然DUSt3R等几何基础模型能够实现端到端的密集三维重建，但在科学成像领域，尤其是冷冻电子显微镜中，由于低信噪比和对比传递函数失真等问题，姿态估计和三维重建仍然依赖于耗时的迭代优化过程。", "innovation": "作者介绍了CryoFastAR，这是一种新的几何基础模型，可以直接从带有噪声的冷冻电子显微镜图像中预测姿态，实现快速初始重构。CryoFastAR通过集成多视图特征和使用带真实噪声和CTF调制的大规模模拟冷冻电子显微镜数据进行训练，提高了姿态估计的准确性和通用性。此外，还提出了一种分阶段训练策略，先在较简单的条件下提取模型所需的关键特征，逐步增加难度以提高鲁棒性。", "conclusion": "实验结果表明，与传统的迭代方法相比，CryoFastAR在合成和真实数据集上达到了相似的质量，显著加快了推理速度。"}
{"llm_update_time": "20251015", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.07984", "html_url": "https://arxiv.org/abs/2507.07984", "title": "OST-Bench: 评估MLLMs在在线时空场景理解中的能力", "title_en": "OST-Bench: Evaluating the Capabilities of MLLMs in Online Spatio-temporal Scene Understanding", "authors": "Jingli Lin,Chenming Zhu,Runsen Xu,Xiaohan Mao,Xihui Liu,Tai Wang,Jiangmiao Pang", "background": "近期，多模态大型语言模型（MLLMs）在将视觉与语言集成以进行复杂推理方面展现出显著的能力。大多数现有的基准测试均在离线设置下进行，输入为预先录制好的固定集合，OP?", "innovation": "本文提出OST-Bench，旨在从智能体主动探索场景的角度评估在线时空理解能力。它强调了在增量获取观察下处理和推理的需求，以及将当前视觉输入与历史记忆结合以支持动态空间推理的需求。通过高效的数据收集管道，OST-Bench构建了来自ScanNet、Matterport3D和ARKitScenes的1400个场景和10000个问答对。在在线设定下，现有MLLMs的能力明显下降，特别是在探索范围扩大和记忆力增加时。进一步的实验证明了这些模型在复杂时空推理任务中的不足。", "conclusion": "我们的研究表明，复杂基于线索的空间推理需求和长时间记忆检索要求严重削弱了模型的表现。为促进该领域的进一步研究与开发，我们将代码、数据集和基准测试公开。"}
{"llm_update_time": "20251015", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2506.01551", "html_url": "https://arxiv.org/abs/2506.01551", "title": "EvolveNav: 通过自我改进的具身推理增强基于LLM的视觉语言导航", "title_en": "EvolveNav: Empowering LLM-Based Vision-Language Navigation via Self-Improving Embodied Reasoning", "authors": "Bingqian Lin,Yunshuang Nie,Khun Loun Zai,Ziming Wei,Mingfei Han,Rongtao Xu,Minzhe Niu,Jianhua Han,Hanwang Zhang,Liang Lin,Bokui Chen,Cewu Lu,Xiaodan Liang", "background": "近期的研究表明，通过训练开源大型语言模型（LLMs）来激发其推理能力，可以提高视觉语言导航（VLN）的表现，同时缩小LLMs训练语料库与VLN任务之间的领域差距。然而，现有的方法主要依赖于简单的输入输出映射方式，导致难以学习映射关系，且导航决策缺乏可解释性。", "innovation": "EvolveNav 提出了一种创新的自我改进的具身推理范式，结合了正式化的链式思考（CoT）监督微调和自我反思的后续训练，以提高导航决策的准确性和可解释性。具体来说，EvolveNav 包含两个阶段的训练过程：（1）形式化的 CoT 监督微调，训练模型以激活其导航推理能力并提高推理速度；（2）自我反思的后续训练，通过使用模型的自身推理输出作为自我丰富化的 CoT 标签，增强监督多样性。同时，还设计了一个自我反思辅助任务，以促使模型通过对比错误的推理模式来学习正确的推理模式。", "conclusion": "在针对特定任务和跨任务训练范式下的实验结果表明，EvolveNav 在多个流行的基准测试（如 R2R、REVERIE、CVDN 和 SOON）中优于基于LLM的VLN方法，展示了其在导航推理中的优越性。"}
{"llm_update_time": "20251015", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2506.21857", "html_url": "https://arxiv.org/abs/2506.21857", "title": "基于混合数据专家的ST和病理学对齐方法SPADE构建表现力强的潜在空间", "title_en": "SPADE: Spatial Transcriptomics and Pathology Alignment Using a Mixture of Data Experts for an Expressive Latent Space", "authors": "Ekaterina Redekop,Mara Pleasure,Zichen Wang,Kimberly Flores,Anthony Sisk,William Speier,Corey W. Arnold", "background": "数字病理学的快速发展和自监督深度学习的进步促进了多种病理任务的基础模型发展。尽管多模态方法整合多种数据源，但在将整个切片组织图像（WSI）与空间转录组学（ST）综合方面仍存在关键缺口，这对于超越标准苏木精和伊红（H&E）染色捕获重要的分子异质性至关重要。", "innovation": "SPADE是一个将病理学与ST数据综合的基模型，通过统一框架指导图像表示学习，创建一个基于ST信息的潜在空间。SPADE采用了混合数据专家技术，专家通过两阶段影像特征空间聚类和对比学习学习配对的WSI补片和基因表达模式的表示。SPADE在HEST-1k数据集上预训练，并在20个下游任务上进行评估，显示出比基线模型显著优于的少量样本表现，突显了将形态学和分子信息整合到一个潜在空间中的好处。", "conclusion": "SPADE在结合组织图像与空间转录组学方面表现出显著优势，能够在统一框架中建立一个引导图像表示学习的、基于ST信息的潜在空间，从而提升病理任务的表现。"}
{"llm_update_time": "20251015", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2506.04401", "html_url": "https://arxiv.org/abs/2506.04401", "title": "Normalize Filters! 经典智慧赋能深度视觉", "title_en": "Normalize Filters! Classical Wisdom for Deep Vision", "authors": "Gustavo Perez,Stella X. Yu", "background": "经典图像滤波器，例如均值滤波器或差值滤波器，通常会被仔细归一化以确保一致性、可解释性以及避免亮度偏移、 halo 或 ringing 等伪像。相比之下，深度网络中端到端学习的卷积滤波器缺乏这种约束。尽管它们可能看起来类似于小波和斑点/边缘检测器，但它们并没有以任何方式归一化。这种情况下，当图像经过大气传输时，其响应会被扭曲，导致结果不正确。目前的方法未能解决这一问题，而本文提供了一种解决方案，即提出滤波器归一化，随后通过具有可学习缩放和平移调整的方法来实现大气同变性。这种方法将经典滤波原理整合到深度学习中(适用于卷积神经网络和依赖卷积的视觉变压器)，在人造和自然强度变异性基准测试中表现出重大改进。", "innovation": "本文提出了一种简单但有效的滤波器归一化方法，通过这种方式，卷积滤波器在大气传输后仍能保持一致性，并具备目标域对称性。这种方法将经典滤波思想融入到深度学习中，针对两种经典的深度学习模型，卷积神经网络和依赖于卷积的视觉变压器，实现了显著的性能提升。其中，ResNet34模型甚至超过了CLIP在自然场景下的表现。实验分析表明，未经归一化的滤波器会降低性能，而滤波器归一化能规范化学习过程，促进多样性，提高鲁棒性与泛化能力。", "conclusion": "本文通过引入滤波器归一化结合可学习的缩放和平移调整的方法，解决了因大气传输导致滤波器响应扭曲的问题，从而提高了深度学习模型的性能，特别是在处理强度变异性方面展示了显著的优势。"}
{"llm_update_time": "20251015", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.14697", "html_url": "https://arxiv.org/abs/2507.14697", "title": "GTPBD: 细分级别的全球梯田地和边界数据集", "title_en": "GTPBD: A Fine-Grained Global Terraced Parcel and Boundary Dataset", "authors": "Zhiwei Zhang,Zi Ye,Yibin Wen,Shuai Yuan,Haohuan Fu,Jianxi Huang,Juepeng Zheng", "background": "农业地块是开展农业实践和应用的基础单位，对土地所有权注册、粮食安全评估、土壤侵蚀监测等至关重要。然而，现有的农田地块提取研究主要关注中分辨率地图或规则平原农田，缺乏对复杂梯田地形的表示，以满足精确度的需求。", "innovation": "本文介绍了一个更为细化的梯田地块数据集GTPBD（全球梯田地块和边界数据集），它是第一个覆盖主要全球梯田地区的高分辨率数据集，包含超过200,000个复杂的梯田地块，并通过手动标注。该数据集包含47,537张高分辨率图像，有三个层级的标签，包括像素级别的边界标签、掩码标签和地块标签。它覆盖了中国的七大地理区域和跨大陆的气候区域。相较于现有的数据集，GTPBD数据集带有很大的挑战，包括地形多样性、复杂的不规则地块对象以及多种领域的风格。提出的数据集适用于四个不同的任务，包括语义分割、边缘检测、梯田地提取和无监督领域适应。", "conclusion": "GTPBD填补了梯田遥感研究中的一项关键空白，为精细农业地形分析和跨场景的知识迁移提供了基础架构。"}
{"llm_update_time": "20251015", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.02348", "html_url": "https://arxiv.org/abs/2508.02348", "title": "基于摄像头提取道路布局的毫米波雷达城市T字路口非视距行人定位", "title_en": "mmWave Radar-Based Non-Line-of-Sight Pedestrian Localization at T-Junctions Utilizing Road Layout Extraction via Camera", "authors": "Byeonggyu Park,Hee-Yeun Kim,Byonghyok Choi,Hansang Cho,Byungkwan Kim,Soomok Lee,Mingu Jeon,Seong-Woo Kim", "background": "非视距(NLoS)区域内的行人定位在城市环境中是自主驾驶系统的重大挑战。虽然毫米波雷达在检测此类场景中的目标方面具有潜力，但其产生的2D雷达点云容易受到多路径反射的影响，导致空间推断困难。此外，尽管摄像头提供了高分辨率的视觉信息，但缺乏深度感知，无法直接观察到NLoS区域中的物体。", "innovation": "本文提出了一种创新框架，通过摄像头对道路布局的推断来解释毫米波雷达的2D点云数据，实现NLoS行人的定位。该方法利用摄像头的视觉信息来解读2D雷达点云，实现空间场景重建。", "conclusion": "通过在真实的车辆上安装雷达和摄像头系统的实验验证了提出方法的有效性。使用在户外NLoS驾驶环境中收集的数据集评估了定位性能，证明了该方法的实际适用性。"}
{"llm_update_time": "20251015", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.16880", "html_url": "https://arxiv.org/abs/2507.16880", "title": "寻找多莉：文本到图像扩散模型中的记忆并非局部的", "title_en": "Finding Dori: Memorization in Text-to-Image Diffusion Models Is Not Local", "authors": "Antoni Kowalczuk,Dominik Hintersdorf,Lukas Struppek,Kristian Kersting,Adam Dziedzic,Franziska Boenisch", "background": "文本到图像的扩散模型在图像生成方面取得了显著成功，但由于潜在的数据隐私和知识产权问题，它们仍然存在隐患。近期的研究试图通过识别和修剪引发训练数据复制的责任权重来减轻这些问题，基于这样一个假设：记忆是局部的。然而，本文挑战了这一假设。", "innovation": "研究发现，即使在修剪了引发数据复制的责任权重之后，对之前被解脱的记忆提示进行微妙的文本嵌入扰动仍然可以重新触发数据的复制，这表明记忆的不稳定性。进一步的分析提出了几个证据，表明记忆并非数据局部的，具体表现为：复制触发点遍布于文本嵌入空间、同样的复制图像的嵌入会产生不同的模型激活、不同的修剪方法将为同一图像识别出不一致的记忆相关权重。最后，研究证明了放弃局部性假设能够通过对抗性微调实现更稳健的缓解。", "conclusion": "这些发现提供了对文本到图像扩散模型中记忆本质的新见解，并指导了对抗扩散模型记忆更为可靠措施的发展。"}
{"llm_update_time": "20251015", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.03334", "html_url": "https://arxiv.org/abs/2508.03334", "title": "Macro-from-Micro Planning for High-Quality and Parallelized Autoregressive Long Video Generation", "title_en": "Macro-from-Micro Planning for High-Quality and Parallelized Autoregressive Long Video Generation", "authors": "Xunzhi Xiang,Yabo Chen,Guiyu Zhang,Zhongyu Wang,Zhe Gao,Quanming Xiang,Gonghu Shang,Junqi Liu,Haibin Huang,Yang Gao,Chi Zhang,Qi Fan,Xuelong Li", "background": "当前的自回归扩散模型在视频生成方面表现出色，但通常局限于短时长视频的合成。理论分析表明，自回归建模通常会因错误累积而导致时间漂移问题，这妨碍了长视频合成的并行化。", "innovation": "提出了一个名为Macro-from-Micro Planning (MMPL)的计划-然后填充框架，通过两级层次结构（微观规划和宏观规划）为长视频生成提供解决方案。MMPL通过预测每个短视频段内的稀疏未来关键帧，提供运动和外观先验，以指导高质量视频片段生成。然后，宏规划跨整个视频扩展了这些片段内的关键帧规划，确保视频片段之间的长期一致性。之后，基于MMPL的内容填充生成所有片段内的中间帧，支持自回归生成的高效并行化。", "conclusion": "广泛的实验表明，该方法在质量和稳定性方面优于现有长视频生成模型。生成的视频和比较结果可在项目页面上查看。"}
{"llm_update_time": "20251015", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.01427", "html_url": "https://arxiv.org/abs/2508.01427", "title": "捕获更多：学习多域表示以实现稳健的在线手写验证", "title_en": "Capturing More: Learning Multi-Domain Representations for Robust Online Handwriting Verification", "authors": "Peirong Zhang,Kai Ding,Lianwen Jin", "background": "在线手写验证（OHV）是通过分析手写笔迹是否存在伪造来确定其真实性的技术。传统的在线手写验证方法通常只利用时间域的特征，而忽略了频率域的信息，这导致了其在某些情况下性能上的限制。本文旨在通过结合多域（同时考虑时间和频率域）的表示学习来提高在线手写验证的准确性，从而弥补现有方法的不足，并探索不同手写生物特征的有效性与集成所带来的性能提升。", "innovation": "本文提出了SPECTRUM模型，这是一个结合了时间和频率域特征的时频协同模型。其创新之处在于通过多尺度交互模块和自调节融合模块，实现了微尺度到宏观尺度的时频融合，相较于传统的仅使用时间域特征的方法，显著提高了真实手写和伪造手写的区分能力。此外，模型展示了多种手写生物特征用于集成学习的优越性，进一步增强了手写笔迹表示的辨别力。", "conclusion": "广泛实验表明，SPECTRUM模型在众多现有的OHV方法中表现突出，证明了多域学习在OHV中的有效性，并为进一步的跨域研究奠定了基础。鉴于这些发现，未来的研究可以探索在特征域和生物特征域中使用更多种多域方法的可能性。"}
{"llm_update_time": "20251015", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.10367", "html_url": "https://arxiv.org/abs/2508.10367", "title": "多模态大型语言模型中的对比敏感性：一种心理物理学启发的评估", "title_en": "Contrast Sensitivity in Multimodal Large Language Models: A Psychophysics-Inspired Evaluation", "authors": "Pablo Hernández-Cámara,Alexandra Gomez-Villa,Jose Manuel Jaén-Lorites,Jorge Vila-Tomás,Valero Laparra,Jesus Malo", "background": "理解多模态大型语言模型（MLLMs）如何处理低级视觉特征对于评估它们的感知能力至关重要，但这一方面尚未系统化地进行研究。这一领域的研究深受人类心理物理学实验的启发。", "innovation": "本文通过将MLLMs视为端到端的观察者，并利用行为方法估计对比敏感函数（CSF），创新地提出了不对模型内部激活或分类器代理依赖的方法来获得对比阈值和CSFs。此外，作者发现CSF估计与提示措辞高度敏感，表明模型在语言上的鲁棒性有限，并且CSFs可以预测模型在频率过滤和对抗条件下的性能。", "conclusion": "本研究揭示了MLLMs在频率调谐方面的系统性差异，并将CSF估计确立为多模态感知的一种可扩展的诊断工具。"}
{"llm_update_time": "20251015", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.08549", "html_url": "https://arxiv.org/abs/2508.08549", "title": "通过多样教学和标签传播提升通用半监督医学图像分割", "title_en": "Boosting Generic Semi-Supervised Medical Image Segmentation via Diverse Teaching and Label Propagation", "authors": "Wei Li,Pengcheng Zhou,Linye Ma,Wenyi Zhao,Huihua Yang", "background": "医学图像分割面临的挑战包括标注数据有限和领域的变化，这导致了半监督医疗(SSMIS)、半监督医疗领域泛化(Semi-MDG)和无监督医疗领域适应(UMDA)等衍生场景。传统的针对特定任务设计的方法，在处理标内外数据以及领域转移时会导致错误累积，影响模型性能并限制进一步改进。因此，需要一种能够处理上述多个任务的通用框架来解决这些挑战。", "innovation": "提出的DTLP-Net框架包含一个学生模型和两个不同的教师模型，通过分隔有标签和无标签数据训练，以及周期性更新的教师模型生成可靠的多样性伪标签，用以增强通用半监督医学图像分割性能。此外，通过样本间和样本内数据增强以及标签传播来提升模型的全局和局部知识学习，进一步捕捉体素级别的关联，从而提高模型的鲁棒性。", "conclusion": "该框架在五个基准数据集的SSMIS、UMDA和Semi-MDG任务上进行评估，结果展示了对现有顶级方法的良好改进，证明了其在处理更复杂的半监督学习场景中的潜力。"}
{"llm_update_time": "20251015", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.09823", "html_url": "https://arxiv.org/abs/2508.09823", "title": "KonfAI: 用于医疗影像领域的模块化和完全可配置深度学习框架", "title_en": "KonfAI: A Modular and Fully Configurable Framework for Deep Learning in Medical Imaging", "authors": "Valentin Boussot,Jean-Louis Dillenseger", "background": "在医疗影像任务中，现有的深度学习框架通常需要用户修改其核心代码来定义训练、推理和评估工作流，这增加了开发时间，降低了实验的可重复性、透明度和可追溯性。KonfAI旨在解决这些问题，提供了一种模块化、可扩展且完全可配置的深度学习框架。", "innovation": "KonfAI通过结构化的YAML配置文件使用户能够无修改地定义完整的训练、推理和评估工作流，增强了可重复性、透明度和实验的可追溯性，同时减少了开发时间。此外，KonfAI还提供了原生抽象，涵盖了基于补丁的学习、测试时增强、模型组合以及直接访问中间特征表示等高级策略，还支持复杂的多模型训练设置。", "conclusion": "KonfAI已被成功应用于分割、注册和图像合成等任务，并在几个国际医疗影像挑战中取得了顶级结果。该框架已开源并可供免费使用。"}
{"llm_update_time": "20251015", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.07441", "html_url": "https://arxiv.org/abs/2508.07441", "title": "利用学习偏倚进行嘈杂异常检测", "title_en": "Levarging Learning Bias for Noisy Anomaly Detection", "authors": "Yuxin Zhang,Yunkang Cao,Yuqi Cheng,Yihan Sun,Weiming Shen", "background": "该论文针对全无监督图像异常检测（FUIAD）中的挑战，其中训练数据可能包含未标记的异常。传统的监测方法假设训练数据未受污染，但在现实世界中，数据污染会导致模型吸收异常数据为正常数据，从而降低异常检测性能。因此，论文旨在通过系统利用模型中的学习偏倚来缓解这一问题。学习偏倚来源于：(1) 正常样本的统计主导作用，驱动模型优先学习稳定的正常模式而非稀疏的异常，(2) 特征空间的差异性，其中正常数据内部一致性高而异常数据多样性高，导致模型响应不稳定。利用学习偏倚，第一阶段将训练集分割，训练子模型并聚合跨模型的异常得分进行数据净化，第二阶段在此净化后的数据集上训练最终的检测器。实验结果表明，该方法在不同噪声条件下表现出优越的异常检测和定位性能。剔除研究进一步验证了框架对污染的鲁棒性，突显了学习偏倚利用的重要性。", "innovation": "该研究提出了一种双阶段框架，用于系统地利用模型中的学习偏倚。该框架首先通过根据特征空间差异性和正常样本统计主导作用分割训练集和训练子模型，并聚合跨模型的异常评分进行数据净化。第二阶段在此净化后的数据集上训练最终的检测器。实验结果表明，该方法在不同噪声条件下表现出优越的异常检测和定位性能。", "conclusion": "该方法通过利用学习偏倚显著提升了异常检测的性能，在不同噪声条件下的检测和定位效果优异，适用于现实世界中不完美训练数据的场景。该模型的通用设计确保了与不同无监督架构的兼容性，提供了一个实用的解决方案。同时，该研究还具有鲁棒性和重要性验证，进一步强调了学习偏倚利用的重要性。"}
{"llm_update_time": "20251015", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.16845", "html_url": "https://arxiv.org/abs/2508.16845", "title": "NinA: Normalizing Flows in Action. 使用规范化流训练视觉-语言-动作模型", "title_en": "NinA: Normalizing Flows in Action. Training VLA Models with Normalizing Flows", "authors": "Denis Tarasov,Alexander Nikulin,Ilya Zisman,Albina Klepach,Nikita Lyubaykin,Andrei Polubarov,Alexander Derevyagin,Vladislav Kurenkov", "background": "视觉-语言-动作（VLA）模型取得了最新进展，并建立了一个两部分的架构。在该架构中，一个预训练的视觉-语言模型（VLM）用于编码视觉观察和任务描述，而动作解码器则将这些表示映射到连续动作。尽管扩散模型因其能够建模复杂多模态动作分布的特点而被广泛采用为动作解码器，但在推断时需要多次迭代去噪步骤或下游技术以加快采样，这在需要高频率控制的现实场景中受到了限制。", "innovation": "NinA（规范化流在动作中的应用），提出了一种用于VLA的快速且具有表达性的动作解码器替代方案。NinA用规范化流（NF）替换了基于扩散的解码器，能够通过可逆变换实现一击采样，从而大幅减少推理时间。将NinA集成到FLOWER VLA体系结构中，并在LIBERO基准上进行微调。实验显示，NinA在相同的训练方案下，性能与基于扩散的参照模型相当，但在推理速度上快得多。", "conclusion": "这些结果显示，NinA为高效、高频率的VLA控制提供了一条有希望的途径，而不会牺牲性能。"}
{"llm_update_time": "20251015", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.17025", "html_url": "https://arxiv.org/abs/2508.17025", "title": "跨视角在线动作检测的概率时序掩蔽注意机制", "title_en": "Probabilistic Temporal Masked Attention for Cross-view Online Action Detection", "authors": "Liping Xie,Yang Tan,Shicheng Jing,Huimin Lu,Kanjian Zhang", "background": "在线动作检测（OAD）是计算机视觉中视频序列分类的关键任务，广受关注。主流OAD模型在不同视角视频中的表达能力有限，当遇到未见过的视角时，容易受到干扰，影响泛化性能。", "innovation": "本文提出了一种新的概率时序掩蔽注意（PTMA）模型，通过概率建模为跨视角设置中视频帧提取隐式压缩表示。PTMA模型结合了基于GRU的时间掩蔽注意（TMA）单元，利用这些表示有效地查询输入视频序列，增强信息交互，促进自回归帧级视频分析。此外，多种视角信息可以集成到概率模型中，以帮助提取视角不变特征。", "conclusion": "在跨被试（cs）、跨视角（cv）和跨被试视角（csv）三种评估协议下，PTMA模型在DAHLIA、IKEA ASM和Breakfast数据集上实现了最先进的性能。"}
{"llm_update_time": "20251015", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.07447", "html_url": "https://arxiv.org/abs/2509.07447", "title": "在MLLM的眼中：基于凝视引导提示的自我中心视频意图理解基准", "title_en": "In the Eye of MLLM: Benchmarking Egocentric Video Intent Understanding with Gaze-Guided Prompting", "authors": "Taiying Peng,Jiacheng Hua,Miao Liu,Feng Lu", "background": "先进的多模态大型语言模型（MLLMs）极大地增强了AI助手处理跨模态复杂信息的能力。最近的自我中心视频，通过直接捕获用户的关注、动作和背景，并使用统一的坐标系统，为MLLMs提供了一个实现主动和个性化AI用户体验的机会。然而，现有的基准测试忽略了凝视作为用户意图指示器的重要性。", "innovation": "该研究介绍了一个名为EgoGazeVQA的新基准，在这个基准中，凝视信息被用于改进对日常生活中较长视频的理解。该研究利用MLLMs生成基于凝视的问答对，并由人类标注者进一步细化。实验证明现有的MLLMs在准确理解用户意图方面存在困难，而凝视引导的意图提示方法通过整合空间、时间和意图相关线索显著提高了性能。", "conclusion": "实验结果强调了凝视在自我中心设置中使AI助手更加个性化和有效的重要性。"}
{"llm_update_time": "20251015", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.10427", "html_url": "https://arxiv.org/abs/2508.10427", "title": "STRIDE-QA: Visual Question Answering Dataset for Spatiotemporal Reasoning in Urban Driving Scenes", "title_en": "STRIDE-QA: Visual Question Answering Dataset for Spatiotemporal Reasoning in Urban Driving Scenes", "authors": "Keishi Ishihara,Kento Sasaki,Tsubasa Takahashi,Daiki Shiono,Yu Yamaguchi", "background": "视觉语言模型（VLMs）已经在自动驾驶中应用，以支持在复杂现实场景中的决策。然而，这些模型仅基于静态的网络图像-文本对进行训练，这限制了对动态交通场景的精确时空推理能力。为此，本文提出了一个名为STRIDE-QA的大规模视觉问答（VQA）数据集，用于从第一人称视角进行物理基础的时空推理。该数据集来源于东京的100小时多传感器驾驶数据，覆盖了多种复杂的交通场景，并包含密集的自动标注信息，如3D边界框、分割掩码和多对象轨迹，为支持对象为中心和视角为中心的推理提供了基础。现有的视觉语言模型在这个数据集上的表现为显著不足，而通过微调，这些模型在空间定位和未来运动预测的一致性上取得了巨大进步。", "innovation": "本文创新地提出了一种名为STRIDE-QA的视觉问答数据集，专门用于城市驾驶场景中的时空推理，填补了现有视觉语言模型在处理动态交通场景时的时空推理能力缺陷。通过构建100小时的多传感器驾驶数据和密集的自动标注，该数据集可以支持对象为中心和视角为中心的推理，实现了对大量QA对和帧的数量级扩展，并通过三个新型的QA任务来要求进行空间定位和时间预测。微调现有的视觉语言模型在该数据集上显示了显著性能提升，特别是在空间定位和未来运动预测的一致性方面。该数据集为开发更可靠的适用于安全关键自动系统视觉语言模型提供了坚实的基础。", "conclusion": "STRIDE-QA为开发更可靠的视觉语言模型提供了综合基础，符合驾驶安全的关键需求。现有的视觉语言模型无法在预测一致性上取得显著成绩，而通过在STRIDE-QA上的适配预训练，这些模型在空间定位和未来运动预测上取得了显著的成功，从而验证了该数据集的价值和重要性。"}
{"llm_update_time": "20251015", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.02903", "html_url": "https://arxiv.org/abs/2509.02903", "title": "UrbanTwin: Building High-Fidelity Digital Twins for Sim2Real LiDAR Perception and Evaluation", "title_en": "UrbanTwin: Building High-Fidelity Digital Twins for Sim2Real LiDAR Perception and Evaluation", "authors": "Muhammad Shahbaz,Shaurya Agarwal", "background": "LiDAR-based感知在智能交通系统(ITS)中依赖于使用大规模标注数据集训练的深度神经网络。然而，创建这些数据集成本高昂、耗时且劳动密集，限制了感知系统的可扩展性。Sim2Real学习提供了一种可扩展的替代方案，但其成功取决于模拟的真实性，即模拟环境、动力学和传感器与真实世界的一致性。", "innovation": "本文介绍了一种可重现的工作流程，用于构建高保真数字孪生(HiFi DTs)，以生成逼真的合成数据集。该流程概括了使用开源资源如卫星图像、OpenStreetMap和传感器规范建模静态几何、道路基础设施和动态交通的实用步骤。最终环境支持可扩展和成本效益的数据生成，以支持鲁棒的Sim2Real学习。使用该流程提供的三个合成LiDAR数据集（UT-LUMPI、UT-V2X-Real 和 UT-TUMTraf-I）来模拟真实地点，这些数据集在感知任务上优于基于实际数据训练的基线。", "conclusion": "本指南为HiFi DTs在ITS研究和部署中的更广泛采用奠定了基础。生成的合成数据集能够带来规模经济效益，为模拟到现实学习提供有力支持。"}
{"llm_update_time": "20251015", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.10813", "html_url": "https://arxiv.org/abs/2509.10813", "title": "InternScenes：具现实布局的大规模仿真实景室内场景数据集", "title_en": "InternScenes: A Large-scale Simulatable Indoor Scene Dataset with Realistic Layouts", "authors": "Weipeng Zhong,Peizhou Cao,Yichen Jin,Li Luo,Wenzhe Cai,Jingli Lin,Hanqing Wang,Zhaoyang Lyu,Tai Wang,Bo Dai,Xudong Xu,Jiangmiao Pang", "background": "体态AI的发展高度依赖于大规模、可仿真的三维场景数据集，这些数据集需要具有场景多样性和真实布局。然而，现有的数据集通常受限于数据规模或多样性不足，存在着小型物品数量少以及物体碰撞严重的问题。", "innovation": "本文提出了InternScenes，一个大规模仿现实室内场景数据集，包含约4万个不同的场景，并整合了真实世界扫描数据、程序生成场景和设计师设计场景，其中有196万个三维物体和涵盖15种常见场景类型以及288种物体类别。该数据集通过保留场景中的大量小物品，实现了现实且复杂的布局，每区域平均有41.5个物体。此外，通过真实的仿真副本、增加交互式物体和物理模拟解决物体碰撞问题，确保了数据的可仿真性。", "conclusion": "InternScenes通过提供现实复杂布局的三维场景，为场景布局生成和基于点的目标导航等任务提供了新的挑战，在此基础上，还可以扩展模型训练规模，使得在复杂场景中的生成和导航成为可能。研究人员承诺开放数据、模型和基准测试，服务于整个社区。"}
{"llm_update_time": "20251015", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.17098", "html_url": "https://arxiv.org/abs/2509.17098", "title": "基于不确定性监督的可解释和鲁棒证据分割", "title_en": "Uncertainty-Supervised Interpretable and Robust Evidential Segmentation", "authors": "Yuzhu Li,An Sui,Fuping Wu,Xiahai Zhuang", "background": "在医学图像分割中，不确定性估计已被广泛应用，以提供可信赖度，尤其是在深度学习方法中。然而，之前的方法在不确定性估计中缺乏有效的监督，导致预测的可解释性和鲁棒性较低。", "innovation": "本文提出了一种自我监督的方法来引导不确定性学习。具体地，提出了边界和噪声周围图像梯度与不确定性之间的三个关系原则，并基于这些原则设计了两个不确定性监督损失。这两个损失增强了模型预测与人类解释之间的对齐，并引入了新的定量指标以评估不确定性的可解释性和鲁棒性。实验结果显示，与最先进的方法相比，所提出的方法在分割性能和异常分布场景中具有竞争力的同时，显著提高了不确定性的可解释性和鲁棒性。", "conclusion": "与现有方法相比，所提出的方法在保持分割性能的同时，可以在异常分布场景中取得更好的结果，同时显著提高不确定性的可解释性和鲁棒性。"}
{"llm_update_time": "20251015", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.11178", "html_url": "https://arxiv.org/abs/2509.11178", "title": "StegOT：通过最优传输实现隐写术中的权衡", "title_en": "StegOT: Trade-offs in Steganography via Optimal Transport", "authors": "Chengde Lin,Xuezhu Gong,Shuxue Ding,Mingzhe Yang,Xijun Lu,Chengjun Mo", "background": "隐写术旨在将秘密图像隐藏在一个分辨率相同的覆盖图像中。目前，许多隐写术模型基于生成对抗网络 (GAN) 和变分自编码器 (VAE)。但是，大多数现有模型存在模式坍缩的问题。模式坍缩会导致嵌入图像中的盖图像与秘密图像之间信息失衡，从而影响后续的秘密图像提取。", "innovation": "本文提出了一种基于自编码器的隐写术模型 StegOT，该模型结合了最优传输理论。我们设计了多通道最优传输 (MCOT) 模块，旨在将特征分布从具有多个峰值的分布转换为单一峰值，从而使信息产生权衡。实验结果显示，该方法不仅实现了盖图像和秘密图像的权衡效应，还改善了嵌入图像和恢复图像的质量。", "conclusion": "我们通过设计多通道最优传输 (MCOT) 模块，构建了 StegOT 模型，将具有多个峰值的特征分布转换为单一峰值，平衡了信息。实验表明，我们的方法不仅实现了真实的嵌入和恢复图像质量的提升，还实现了盖图像和秘密图像间的权衡。源代码将在此链接 http://example.com 公开。"}
{"llm_update_time": "20251015", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.21783", "html_url": "https://arxiv.org/abs/2509.21783", "title": "基于提示引导的行动识别表示拆解", "title_en": "Prompt-guided Representation Disentanglement for Action Recognition", "authors": "Tianci Wu,Guangming Zhu,Jiang Lu,Siyuan Wang,Ning Wang,Nuoye Xiong,Zhang Liang", "background": "行动识别是视频理解中的基本任务。现有方法通常从视频中提取统一特征以处理所有动作，这使得在多动作场景中建模不同对象之间的相互作用变得具有挑战性。为解决这一问题，本文探究了将任何特定动作从复杂场景中分离出来作为有效解决方案的可行性。因此，本文提出了提示引导的拆解表示行动识别（ProDA）框架，该框架能够从多动作场景中拆解任何特定动作。ProDA 利用时空场景图（SSGs）并通过动态提示模块（DPM）引导图解析神经网络（GPNN）生成动作特异性表示。此外，本文还设计了一种适合视频的 GPNN，其通过动态权重聚合信息。", "innovation": "本文提出了一种基于提示引导的拆解表示行动识别（ProDA）框架，利用时空场景图和动态提示模块引导图解析神经网络生成动作特异性表示，以及设计了适用于视频的动态权重聚合的图解析神经网络。", "conclusion": "实验表明，本文的方法在视频行动识别上的效果优于现有先进方法。"}
{"llm_update_time": "20251015", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.26165", "html_url": "https://arxiv.org/abs/2509.26165", "title": "Human-MME：人类中心多模态大型语言模型综合评估基准", "title_en": "Human-MME: A Holistic Evaluation Benchmark for Human-Centric Multimodal Large Language Models", "authors": "Yuansen Liu,Haiming Tang,Jinlong Peng,Jiangning Zhang,Xiaozhong Ji,Qingdong He,Wenbin Wu,Donghao Luo,Zhenye Gan,Junwei Zhu,Yunhang Shen,Chaoyou Fu,Chengjie Wang,Xiaobin Hu,Shuicheng Yan", "background": "多模态大型语言模型（MLLMs）在视觉理解任务中取得了显著进展，但在人类中心场景的理解方面的能力却鲜有探索。这主要是由于缺乏综合性的评估基准，这些基准需要同时考虑人类中心的微观细节和高维度因果推理能力。由于人体的物理复杂性和细粒度结构的标注难度，高质量的评估基准面临巨大挑战。因此，本文提出了Human-MME（Human-centric Multimodal Evaluation），旨在为MLLMs在人类中心场景理解方面的综合评估提供更全面的视角。该基准覆盖了多种人类场景，具有多层次的评估维度，以及高质量的注释，能扩展从单目标理解到多个人和多图像互操作的理解能力。", "innovation": "Human-MME提供了一个新颖的基准体系，包括：1. 多样性广泛，涵盖4个主要视觉领域和多个二级领域及39个子领域，确保覆盖广泛的情境；2. 渐进式的评估维度，从微观感知到高层次推理，构建了一个评价套件，包含8个维度和19,945个真实世界的图像问题对；3. 高质量注释，结合自动注释平台和人工标注，支持严格的手工标注，以促进模型的精确和可靠的评估。", "conclusion": "本文的大规模实验揭示了17个最先进的MLLMs的局限性，并引导未来MLLMs的研究朝着更好地理解人类中心图像的方向发展。所有数据和代码均可通过提供的链接获取。"}
{"llm_update_time": "20251015", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.22622", "html_url": "https://arxiv.org/abs/2509.22622", "title": "长生活：实时互动长视频生成", "title_en": "LongLive: Real-time Interactive Long Video Generation", "authors": "Shuai Yang,Wei Huang,Ruihang Chu,Yicheng Xiao,Yuyang Zhao,Xianbang Wang,Muyang Li,Enze Xie,Yingcong Chen,Yao Lu,Song Han,Yukang Chen", "background": "长视频生成面临着效率和质量的双重挑战。扩散模型和强迫扩散模型可以生成高质量的视频，但由于双向注意机制效率较低。因果注意自回归模型支持KV缓存以加快推理速度，但在长视频训练中由于内存问题往往导致质量下降。此外，在静态提示生成之外，长视频生成还需要支持如流式输入指令等互动功能，这对于动态内容创作至关重要，使用户能够实时引导故事情节。这种互动需求显著增加了复杂性，特别是在确保提示过渡期间的视觉一致性和语义连贯性方面。", "innovation": "LongLive采用了基于因果关系的帧级自回归设计，并整合了KV刷新机制以实现平滑过渡；引入了流式长调整（long tuning）以匹配训练和推理；使用短窗口注意和帧级注意沉淀（frame sink）以保持长时间的一致性并加快生成速度。通过这些关键设计，LongLive将一个1.3亿参数的短片段模型在32个GPU天内微调为长达一分钟的生成。推理时，LongLive在单块NVIDIA H100上可以保持20.7 FPS，并在VBench上表现出色，无论是短视频还是长视频。LongLive还可以在单个H100 GPU上支持长达240秒的视频，并且支持INT8量化推理，几乎不影响质量。", "conclusion": "LongLive通过创新的帧级自回归设计和高效的帧级KV刷新机制有效地解决了长视频生成中的效率和质量挑战，并展示了其在实时互动长视频生成中的优越性能。"}
{"llm_update_time": "20251015", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.26645", "html_url": "https://arxiv.org/abs/2509.26645", "title": "TTT3R：基于测试时间训练的3D重建", "title_en": "TTT3R: 3D Reconstruction as Test-Time Training", "authors": "Xingyu Chen,Yue Chen,Yuliang Xiu,Andreas Geiger,Anpei Chen", "background": "现代循环神经网络因为其线性时间复杂度成为了3D重建的竞争性架构。然而，当应用于超出训练上下文长度的场景时，其性能会显著下降，显示出有限的长度泛化能力。这些模型通常在训练过程中表现出色，但在测试阶段无法有效地适应新数据，导致泛化能力受限。", "innovation": "本文重新审视了从测试时训练的角度出发的3D重建基础模型，将模型设计视为一种在线学习问题。基于这一视角，TTT3R利用记忆状态与新观察值之间的对齐置信度来推导记忆更新的学习率，从而在保留历史信息和适应新数据之间取得平衡。这种方法是一种无需训练的干预措施，显著改善了长度泛化能力，与基线相比在整体姿态估计上取得了2倍的改进，同时在20 FPS下运行并仅需6 GB的GPU内存，能够处理数千张图像。", "conclusion": "TTT3R通过测试时训练的方法极大地提高了3D重建的长度泛化能力，比基线方法提高了2倍的整体姿态估计性能，且具有高效能，只需极少量的GPU内存即可处理大量图像。"}
{"llm_update_time": "20251015", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.04781", "html_url": "https://arxiv.org/abs/2510.04781", "title": "无需手持工具的文化遗产3D扫描自动化系统", "title_en": "Hands-Free Heritage: Automated 3D Scanning for Cultural Heritage Digitization", "authors": "Javed Ahmad,Federico Dassiè,Selene Frascella,Gabriele Marchello,Ferdinando Cannella,Arianna Traviglia", "background": "高保真3D扫描对于保护文化遗产古董至关重要，但它需要专有的知识和手动干预来保持最佳的扫描条件和覆盖范围。传统的扫描方法通常需要具备相关专业知识和技术的操作。", "innovation": "本研究提出了一种自动化双机器人扫描系统，结合协调的机器人操作和高分辨率的3D扫描，消除了手持或半自动工作流程的需求。系统通过参数化扫描空间来规划协调的动作，确保利用装有扫描器的机器人与托盘处理机器人之间的协调运动，实现全面的表面覆盖，减少遮挡，平衡重建精度与系统效率。", "conclusion": "实验结果显示，该方法在距离点线的距离（Chamfer Distance）和F分数方面明显优于基线方法，提供更优的几何精度，提高数字化效率，减少对专家操作者的依赖。"}
{"llm_update_time": "20251015", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.08955", "html_url": "https://arxiv.org/abs/2510.08955", "title": "物体聚焦的去噪扩散图像增强", "title_en": "Denoised Diffusion for Object-Focused Image Augmentation", "authors": "Nisha Pillai,Aditi Virupakshaiah,Harrison W. Smith,Amanda J. Ashworth,Prasanna Gowda,Phillip R. Owens,Adam R. Rivers,Bindu Nanduri,Mahalingam Ramkumar", "background": "现代农业操作越来越多地依赖结合多种数据来源的集成监控系统，以实现农场优化。基于无人机的动物健康监测是关键组成部分，但由于航空侦察图像中动物往往出现小、遮挡或者部分可见等问题，导致数据可用性有限。迁移学习方法由于缺乏反映特定农场条件（包括动物品种、环境、行为等差异）的大规模数据集，常常难以解决这一问题。因此，需要开发一种特定于问题、专注于动物的数据增强策略，以应对这些独特挑战。", "innovation": "为解决上述问题，我们提出了一种物体聚焦的数据增强框架，专门针对动物健康监控在数据稀缺设置下的需求。该方法通过从背景中分割动物并对其进行变换和基于扩散的合成，生成真实且多样的场景，从而增强动物检测和监控性能。实验结果表明，我们的增强数据集在动物检测任务上表现优于基线模型。", "conclusion": "通过生成特定领域的数据，我们的方法能够赋予实现实时动物健康监控解决方案的能力，即使在数据稀缺的场景下也能将有限数据与实际应用之间的差距缩小。"}
{"llm_update_time": "20251015", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.09953", "html_url": "https://arxiv.org/abs/2510.09953", "title": "J-RAS: 通过检索增强的联合训练提高医学图像分割", "title_en": "J-RAS: Enhancing Medical Image Segmentation via Retrieval-Augmented Joint Training", "authors": "Salma J. Ahmed,Emad A. Mohammed,Azam Asilian Bidgoli", "background": "医学应用中，图像分割是关键的技术，用于精确的诊断、治疗规划和疾病监测。虽然有经验的医疗专业人员进行的手动分割可以产生准确的结果，但这种方法耗时、成本高且受人为差异影响导致结果变异。尽管发展了基于人工智能（AI）的方法来自动化分割任务，但它们通常需要大量标注数据，这些数据在实践中很难获得，并且在面对组织间的差异性和罕见病理情况时难以泛化。", "innovation": "本文提出了联合检索增强分割（J-RAS），这是一种联合训练方法，将分割模型与检索模型相结合。通过这种联合优化，分割模型可以利用检索到的图像与掩码对来丰富其解剖理解，而检索模型则学习分割相关的特征而不仅仅是视觉相似性。联合优化确保了检索模型积极提供有意义的上下文线索以引导边界定义，从而增强了整体分割性能。", "conclusion": "在不同的分割模型（包括U-Net、TransUNet、SAM和SegFormer）上，在ACDC和M&Ms两个基准数据集上验证了J-RAS，结果显示其在不同的数据和架构上的一致改进。J-RAS方法的有效性和普遍性得到了验证，特别是在ACDC数据集上的实验证明了其性能提升显著。"}
{"llm_update_time": "20251015", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.10177", "html_url": "https://arxiv.org/abs/2510.10177", "title": "HccePose(BF): 预测前后表面以构建超密集2D-3D对应关系进行姿态估计", "title_en": "HccePose(BF): Predicting Front & Back Surfaces to Construct Ultra-Dense 2D-3D Correspondences for Pose Estimation", "authors": "Yulin Wang,Mengting Hu,Hongli Li,Chen Luo", "background": "在已见物体的姿态估计中，常使用神经网络预测物体二维图像上的密集3D坐标，进而建立密集的2D-3D对应关系。当前方法主要关注提高物体前表面预测3D坐标精度的高效编码技术，忽视了整合物体背面和内部的潜力。为了充分利用物体的完整表面和内部，研究中预测了物体前后表面的3D坐标，并在它们之间密集采样3D坐标，生成超密集的2D-3D对应关系，提升基于透视n点法(PnP)算法的姿态估计精度。此外，提出了层次连续坐标编码(HCCE)，以更准确、高效地表示物体前后表面的坐标。", "innovation": "研究引入了两个创新点：(1)预测前后表面的3D坐标，并在两者之间进行密集采样，构建超密集的2D-3D对应关系；(2)提出层次连续坐标编码(HCCE)，提供更准确、高效的坐标表示。", "conclusion": "实验结果表明，与BOP网站上现有的前沿方法相比，该方法在七个经典BOP数据集上均表现更优。"}
{"llm_update_time": "20251015", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.10518", "html_url": "https://arxiv.org/abs/2510.10518", "title": "VR-Thinker：通过图像推理增强视频奖励模型", "title_en": "VR-Thinker: Boosting Video Reward Models through Thinking-with-Image Reasoning", "authors": "Qunzhong Wang,Jie Liu,Jiajun Liang,Yilei Jiang,Yuanxing Zhang,Jinyuan Chen,Yaozhi Zheng,Xintao Wang,Pengfei Wan,Xiangyu Yue,Jiaheng Liu", "background": "近年来，多模态奖励模型（RMs）在视觉生成模型的后训练中有了显著进展。然而，当前的RMs存在固有的局限性：（1）视觉输入消耗大量上下文预算，导致帧数较少，从而丢失了细节；（2）所有的视觉信息都包含在初始提示中，加剧了链式推理中的幻觉和遗忘。", "innovation": "我们引入了VR-Thinker（图像推理框架），它为RMs配备了视觉推理操作（如选择帧）以及可配置的视觉记忆窗口，从而允许RM在上下文限制内主动获取和更新视觉证据，提高了推理准确性和可靠性。通过强化学习微调管道进行了视觉推理的激活：（i）使用精选的视觉链式思维数据进行冷启动，提炼基本的推理技能和操作格式；（ii）选择每个维度和整体判断都正确的样本，并对其进行高质量轨迹的拒绝采样微调，以进一步增强推理；（iii）应用组相对策略优化（GRPO）以增强推理。我们的方法在开源模型的视频偏好基准测试中达到了最先进的精度，特别是在较长的视频中：7B VR-Thinker在VideoGen Reward中达到80.5%，在GenAI-Bench中达到82.3%和在MJ-Bench-Video中达到75.6%。", "conclusion": "这些结果验证了图像推理在多模态奖励建模有效性和潜力。"}
{"llm_update_time": "20251015", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.09144", "html_url": "https://arxiv.org/abs/2510.09144", "title": "在线拓扑定位在支气管镜导航辅助中的应用", "title_en": "Online Topological Localization for Navigation Assistance in Bronchoscopy", "authors": "Clara Tomasini,Luis Riazuelo,Ana C. Murillo", "background": "支气管镜检查是呼吸医学中的基本程序，医疗专家通过患者的支气管树进行诊断或手术操作。医生需要导航确定支气管镜的位置，直到到达感兴趣区域。这项任务因复杂的支气管树结构和医生的经验和培训水平不同而极具挑战性。导航辅助可以提高操作的成功率，然而现有技术通常依赖于患者之前的CT扫描以获得空气道的3D模型，随后再通过额外的传感器或图像配准进行跟踪。这种方法虽然可以达到准确的位置信息，但需要额外的设置、扫描和培训。准确的计量定位不是必要条件，相对于通用的空气道模型的拓扑定位往往足以辅助医生进行导航。", "innovation": "本研究提出了一种基于图像的支气管镜拓扑定位流水线，在支气管镜检查过程中提供导航辅助，无需使用患者的CT扫描。该方法仅通过仿真数据进行训练，从而避免了真实数据标注的高成本，并展示了良好的泛化能力。实验结果表明，该方法在实际数据测试序列上的表现优于现有方法。", "conclusion": "通过提出基于图像的支气管镜拓扑定位流水线，本研究在无需额外CT扫描的情况下提高了导航辅助的准确性，并展示了良好的泛化能力，从而实现在支气管镜检查过程中的导航辅助，该方法超过现有方法的性能，特别是在实际数据测试序列上。"}
{"llm_update_time": "20251015", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.24099", "html_url": "https://arxiv.org/abs/2509.24099", "title": "通过校正流实现统一的多模态互动和反应3D运动生成", "title_en": "Unified Multi-Modal Interactive & Reactive 3D Motion Generation via Rectified Flow", "authors": "Prerit Gupta,Shourya Verma,Ananth Grama,Aniket Bera", "background": "在计算机图形学、动画和人机交互领域，生成具有上下文感知能力的两人互动的逼真运动仍然是一个核心挑战。现有模型通常需要处理多种输入模态，包括文本、音乐和先前的运动序列，以生成这些复杂的场景中的自然动画。然而，当前技术往往存在推理时间长和错误累积的问题，尤其是在基于扩散的方法中。这篇论文提出了DualFlow，一种统一且高效的多模态两人运动生成框架，旨在解决这些挑战并提供更好的性能。", "innovation": "DualFlow框架通过利用校正流，实现了噪声和数据之间的确定性直线采样路径，从而减少了推理时间并缓解了模型中常见的误差累积问题。此外，它引入了检索增强生成（Retrieval-Augmented Generation, RAG）模块，使用音乐特征和基于大语言模型（LLM）的文本分解来检索与空间关系、身体动作和节奏模式相关的运动范例，从而加强了语义基础。为了进一步增强两者之间的对齐，DualFlow采用对比损失以及同步损失来改善双人之间的协调性。这些创新措施使得DualFlow能够在多种场景中产生高质量、响应性强且高效的多模态人类运动。", "conclusion": "广泛的测试表明，DualFlow在文本转运动、音乐转运动以及多模态交互基准上的表现一致地优于现有方法，能够生成具有时间连贯性和节奏同步性的运动，从而在多模态的人机交互和动画中设定新的标准。"}
{"llm_update_time": "20251015", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.04876", "html_url": "https://arxiv.org/abs/2510.04876", "title": "BenthiCat: 一个结合光学与声学的数据集，用于推动底栖分类和栖息地制图", "title_en": "BenthiCat: An opti-acoustic dataset for advancing benthic classification and habitat mapping", "authors": "Hayat Rajani,Valerio Franchi,Borja Martinez-Clavel Valles,Raimon Ramos,Rafael Garcia,Nuno Gracias", "background": "底栖栖息地制图对于理解海洋生态系统、指导保护工作和支持可持续资源管理至关重要。然而，大型、标注的数据库的稀缺性限制了机器学习模型在这一领域的开发和基准测试。因此，需要一个全面的多模态数据集来支持这些工作。", "innovation": "该论文引入了一个详尽的多模态数据集，包含了大约一百万张侧扫声纳（SSS）瓦片，收集于西班牙加泰罗尼亚沿海，并补充了地形图和目标调查中搭载自主水下车辆（AUV）的同步光学图像。约36000张SSS瓦片被手动注释，以支持监督分类模型的精细调整。此外，提供了源代码预处理和注释工具，以增强数据集的可访问性并促进研究。该资源旨在为水下栖息地制图建立标准化基准，促进自主海底分类和多传感器集成的进步。", "conclusion": "该数据集旨在解决多传感器数据融合中的挑战，并利用光学图像和对应的SSS瓦片的空间关联来进行自我监督、跨模态表示学习。此项工作为底栖分类和水下栖息地制图的进步提供了宝贵的资源。"}
{"llm_update_time": "20251015", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.11190", "html_url": "https://arxiv.org/abs/2510.11190", "title": "FlexAC: 向具有灵活控制关联推理的大规模多模态语言模型迈进", "title_en": "FlexAC: Towards Flexible Control of Associative Reasoning in Multimodal Large Language Models", "authors": "Shengming Yuan,Xinyu Lyu,Shuailong Wang,Beitao Chen,Jingkuan Song,Lianli Gao", "background": "多模态大规模语言模型（MLLMs）在忠实性和创造力之间存在固有的权衡，因为不同任务需要不同程度的联想推理。现有的方法缺乏灵活调节这种推理强度的能力，限制了MLLMs在事实性和创造性场景中的适应性。这项研究旨在通过为MLLMs配备能够灵活控制联想推理的机制来弥补这一差距，通过探索MLLMs内部的联想机制，研究发现中间层对于塑造模型的联想倾向至关重要，以及通过修改这些层的表示可以有效调节联想推理强度，同时利用幻觉引导的方法生成指导这种调节的向量。", "innovation": "提出了一种轻量且无需训练的框架FlexAC，用于调节MLLMs的联想行为。FlexAC首先通过幻觉引导的中间表示来编码联想方向，然后选择高联想实例构建有效的联想引导向量，并根据创意指导与输出稳定性的平衡来适应性校准这些向量的强度。此外，FlexAC还包含根据少量目标领域样本的前向传递衍生的任务特定联想向量，使模型能够跟随多样的联想方向，从而更好地适应创造任务。实验结果表明，该方法在Creativity-MMBench上的创造性提升了5.8倍，CHAIR上的幻觉率降低了29%，超越了现有基线，证明了其在MLLMs中实现灵活控制关联推理的有效性。", "conclusion": "通过引入FlexAC框架，MLLMs现在可以更灵活地控制其联想推理，从而更好地适应创造性和事实性场景的需要。该方法显著改进了MLLMs的创造性和减少幻觉现象，并展示了其在控制MLLMs联想推理方面的有效性。"}
{"llm_update_time": "20251015", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.25026", "html_url": "https://arxiv.org/abs/2509.25026", "title": "GeoVLM-R1：改进遥感推理的强化微调", "title_en": "GeoVLM-R1: Reinforcement Fine-Tuning for Improved Remote Sensing Reasoning", "authors": "Mustansar Fiaz,Hiyam Debary,Paolo Fraccaro,Danda Paudel,Luc Van Gool,Fahad Khan,Salman Khan", "background": "近期强化学习（RL）在自然图像领域展示了强大的推理能力，但其在地球观测（EO）领域的应用潜力尚未被充分探索。EO任务引入了独特的挑战，包括目标检测、图像或区域描述、变化检测、语义对齐和时间分析等，这些任务需要基于任务的推理能力。现有方法难以有效应对这些变化检测和时空分析需求，尤其在保持模型稳定性和鲁棒性方面存在不足。论文针对这一问题，提出了一种新型的后训练框架，结合目标导向的奖励以增强基于推理的RL模型对多种EO任务的适应性。此策略增强了遥感图像的推理能力，稳定了优化过程，并提高了模型的鲁棒性。", "innovation": "该研究提出了一种新型的后训练框架，该框架结合了任务相关的奖励，以有效地适应基于推理的强化学习模型多种地球观测任务。此方法增强了处理遥感图像的推理能力，稳定了优化过程，并提高了鲁棒性。实验表明，与现有的通用和专门的视觉语言模型相比，该方法在多个EO基准测试上表现出了一致的性能提升，结果将会公开提供。", "conclusion": "该论文展示了通过强化学习改进遥感推理任务的可行性，并通过广泛实验验证了其有效性。研究结果表明，通过结合任务相关的奖励，可以显著提升基于推理的RL模型处理EO任务的能力和平稳性，这为进一步研究和实际应用提供了新的思路。"}
{"llm_update_time": "20251015", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.11340", "html_url": "https://arxiv.org/abs/2510.11340", "title": "REACT3D：恢复可交互物理3D场景的关节", "title_en": "REACT3D: Recovering Articulations for Interactive Physical 3D Scenes", "authors": "Zhao Huang,Boyang Sun,Alexandros Delitzas,Jiaqi Chen,Marc Pollefeys", "background": "随着体态智能的应用日益广泛，高质量的交互式3D场景变得越来越重要。然而，现有数据集仍受到标注部件分割、运动轨迹和关节类型等劳动密集型过程的限制。", "innovation": "我们提出了REACT3D，这是一种可扩展的零样本框架，能够将静态3D场景转化为可用于仿真模拟的交互式复制品，并描述了以下技术贡献：(i) 可开启对象检测与分割、(ii) 连接估计、(iii) 隐含几何补全及交互对象组装、(iv) 在广泛支持格式中的交互场景集成。这些方法使得REACT3D在检测/分割及关节估计指标上达到了最先进的性能。", "conclusion": "我们的框架实现了大规模研究中可交互场景理解的壁垒降低，具有广泛适用性和兼容性，提供了构建复杂仿真场景的基础。"}
{"llm_update_time": "20251015", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.24709", "html_url": "https://arxiv.org/abs/2509.24709", "title": "IWR-Bench: LVLMs能否从用户交互视频重建互动网页？", "title_en": "IWR-Bench: Can LVLMs reconstruct interactive webpage from a user interaction video?", "authors": "Yang Chen,Minghao Liu,Yufan Shen,Yunwen Li,Tianyuan Huang,Xinyu Fang,Tianyu Zheng,Wenxuan Huang,Cheng Yang,Daocheng Fu,Jianbiao Mei,Rong Wu,Yunfei Zhao,Licheng Wen,Xuemeng Yang,Song Mao,Qunshu Lin,Zhi Yu,Yongliang Shen,Yu Qiao,Botian Shi", "background": "现有的网页到代码任务主要集中在基于静态截图的网页代码生成，忽视了真实世界Web应用程序中至关重要的动态交互。因此，本文提出了IWR-Bench，这是一个新的基准测试，用于评估大规模视觉-语言模型（LVLMs）从视频中重建互动网页的能力。该基准测试包含了100个实际网站中的113个精心挑选的任务，其中包括1001个操作和多种类型的交互类型、视觉风格和领域。每个任务不仅包含用户交互视频，还包括所有抓取到的静动态资产，并从多模态推理和高级代码生成两个基本挑战来评估模型。研究表明，尽管在视觉保真度上表现良好，但当前模型在功能正确性上的表现仍然不足，引发了视觉-语言研究领域的严峻挑战。", "innovation": "本文提出了IWR-Bench，这是第一个专注于互动网页重建从视频的基准测试，包含100个实际网站中的113个详细任务，每项任务都涵盖了不同交互类型、视觉风格和视觉复杂性。此外，采用了一个代理作为评判者框架，并拥有一个全面的度量系统来自动评估生成的网页的功能正确性与视觉保真度。", "conclusion": "实验证明，大规模视觉-语言模型在功能正确性上存在显著挑战，最高得分为36.35%，而功能正确性只有24.39%，这表明当前模型在处理动态和时间敏感的数据时存在很大限制，IWR-Bench 是视觉-语言研究领域的重大挑战。相关基准测试和评估代码将公开发布。"}
{"llm_update_time": "20251015", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.11538", "html_url": "https://arxiv.org/abs/2510.11538", "title": "Massive Activations是Diffusion Transformers中局部细节合成的关键", "title_en": "Massive Activations are the Key to Local Detail Synthesis in Diffusion Transformers", "authors": "Chaofan Gan,Zicheng Zhao,Yuanpeng Tu,Xi Chen,Ziran Qin,Tieyuan Chen,Mehrtash Harandi,Weiyao Lin", "background": "近期研究表明，扩散变压器（DiTs）已成为视觉生成的强大骨干，但在其内部特征图中发现了大量的激活（Massive Activations，MAs），但这些激活的功能仍未被充分理解。本文系统地探讨了这些激活的作用，揭示了MAs在视觉生成中的角色。", "innovation": "本文提出了 Detail Guidance (DG) 策略，这是一种利用 MAs 的训练无干预的自引导方法，以增强DiTs的局部细节保真度，DG 构建了一个局部细节缺乏的模型，并利用该模型来引导原始网络进行更高质量的局部细节合成。该策略可以在 Classifier-Free Guidance (CFG) 优化微小细节方面进一步增强。", "conclusion": "大量的实验表明，我们的 DG 策略可以显著提高 DiTs 各种预训练版本（例如 SD3、SD3.5、Flux）的微小细节质量。"}
{"llm_update_time": "20251015", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.11576", "html_url": "https://arxiv.org/abs/2510.11576", "title": "基准模型在高光谱图像分类中的评估：应用于谷物作物类型制图", "title_en": "Benchmarking foundation models for hyperspectral image classification: Application to cereal crop type mapping", "authors": "Walid Elbarz,Mohamed Bourriz,Hicham Hajji,Hamd Ait Abdelali,François Bourzeix", "background": "基础模型正在改变地球观测领域，但对于利用高光谱成像进行农作物映射的潜力尚未充分探索。本文使用来自多时间段高光谱档案的SpectralEarth数据集预训练的三个基础模型——HyperSigma、DOFA和视觉转换器，对谷物作物映射进行了基准测试。", "innovation": "本文首次系统评估了基础模型在操作性高光谱图像作物映射中的应用，并通过与从零训练的紧凑型SpectralEarth模型的比较，强调了模型架构在不同地理区域和传感器平台的一般化中所起的关键作用。", "conclusion": "这些结果为基础模型在操作性高光谱图像作物分类中的应用提供了系统性评价，并指出了未来模型开发的方向。"}
{"llm_update_time": "20251015", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.11496", "html_url": "https://arxiv.org/abs/2510.11496", "title": "AndesVL技术报告：一种高效的移动侧多模态大型语言模型", "title_en": "AndesVL Technical Report: An Efficient Mobile-side Multimodal Large Language Model", "authors": "Zhiwei Jin,Xiaohui Song,Nan Wang,Yafei Liu,Chao Li,Xin Li,Ruichen Wang,Zhihao Li,Qi Qi,Long Cheng,Dongze Hao,Quanlong Zheng,Yanhao Zhang,Haobo Ji,Jian Ma,Zhitong Zheng,Zhenyi Lin,Haolin Deng,Xin Zou,Xiaojie Yin,Ruilin Wang,Liankai Cai,Haijing Liu,Yuqing Qiu,Ke Chen,Zixian Li,Chi Xie,Huafei Li,Chenxing Li,Chuangchuang Wang,Kai Tang,Zhiguang Zhu,Kai Tang,Wenmei Gao,Rui Wang,Jun Wu,Chao Liu,Qin Xie,Chen Chen,Haonan Lu", "background": "近年来，诸如QwenVL、InternVL、GPT-4o、Gemini和Claude Sonnet等基于云的MMLMs（大模型机器学习）展示了出色的表现，这些模型的参数量达到了数百亿，显著超过了边缘设备（如手机）在内存、功耗和计算能力方面的限制。", "innovation": "论文引入了AndesVL，这是一种基于Qwen3的LLM和各种视觉编码器构建的移动侧MMLMs（0.6亿至4亿参数范围内的模型）。论文详细介绍了AndesVL的模型架构、训练管道和训练数据。此外，提出了一种1+N LoRA架构和Quantization-Aware LoRA Fine-Tuning (QALFT)框架，以促进移动侧AndesVL的高效任务适应和模型压缩。并在部署AndesVL-4B时采用了自定义推测解码和压缩策略及缓存淘汰算法（OKV），实现了6.7倍的峰值解码速度提升，最高达30.9%的内存减少以及每权重1.8比特。", "conclusion": "AndesVL在多个开源基准上，如文本丰富的图像理解、推理和数学、多图像理解、一般性VQA、幻觉缓解、多语言理解和GUI相关任务方面达到了顶级性能，并基于MediaTek Dimensity 9500芯片发布了所有的模型。"}
{"llm_update_time": "20251015", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2309.02007", "html_url": "https://arxiv.org/abs/2309.02007", "title": "对数数学形态学：理论与应用", "title_en": "Logarithmic Mathematical Morphology: theory and applications", "authors": "Guillaume Noyel(CRESTIC)", "background": "传统的灰度图像数学形态学中，图像通过一个称为结构函数的图像进行分析，结构函数在图像域中平移并加到图像上。然而，在存在照明变化的图像中，结构函数的幅度应该随着图像亮度的变化而变化。这种特性在传统的灰度图像数学形态学中得不到满足，特别是在使用通常的加法运算时。为了应对这一问题，作者定义了一个新的框架，该框架定义了一种加法运算，其中结构函数的幅度随着图像幅度的变化而变化。", "innovation": "作者在Logarithmic Image Processing（对数图像处理）框架内选择了一种加法运算，能够模型化由光线强度变化等原因引起的照明变化。这种新的框架被称为对数数学形态学（Logarithmic Mathematical Morphology, LMM），该框架允许定义对照明变化具有良好鲁棒性的算子。", "conclusion": "通过对Logarithmic Mathematical Morphology的定义，作者提供了一种能够应对图像中照明变化的新方法，使得算子具有更好的鲁棒性。"}
{"llm_update_time": "20251015", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2503.00731", "html_url": "https://arxiv.org/abs/2503.00731", "title": "鲁棒实时模糊组织边界下的内窥镜立体匹配", "title_en": "Robust Real-Time Endoscopic Stereo Matching under Fuzzy Tissue Boundaries", "authors": "Yang Ding,Can Han,Sijia Du,Yaqi Wang,Dahong Qian", "background": "对于自动化的机器人微创外科手术，实时准确地获取场景深度至关重要。双目内窥镜立体匹配可以提供这种深度信息。然而，现有的立体匹配方法，主要是为自然图像设计的，通常在具有模糊组织边界特征的内窥镜图像上表现不佳，并且通常无法满足高分辨率内窥镜图像输入时的实时要求。", "innovation": "我们提出了RRESM，一种专门针对内窥镜图像设计的实时立体匹配方法。该方法结合了3D Mamba坐标注意力模块，通过位置敏感的关注图增强代价聚合，并通过Mamba模块建模长范围的空间依赖关系，生成稳健的代价体积，同时没有显著的计算开销。此外，还引入了一种高频视差优化模块，通过在小波域中放大高频细节来近组织边界附近优化视差预测。", "conclusion": "在SCARED和SERV-CT数据集上的评估表明，该方法在不失实时推理速度42 FPS的情况下达到了最先进的匹配准确性。"}
{"llm_update_time": "20251015", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2409.05809", "html_url": "https://arxiv.org/abs/2409.05809", "title": "OmniLens：通过LensLib到特定领域的适应实现通用镜头畸变矫正", "title_en": "OmniLens: Towards Universal Lens Aberration Correction via LensLib-to-Specific Domain Adaptation", "authors": "Qi Jiang,Yao Gao,Shaohua Gao,Zhonghua Yi,Xiaolong Qian,Hao Shi,Kailun Yang,Lei Sun,Kaiwei Wang", "background": "当前存在的通用计算畸变矫正（CAC）方法基于一个综合的镜头库（LensLib）对模型进行预训练，使其能够解决任意镜头的畸变问题，但现有的LensLibs的覆盖范围有限，这限制了模型对未见过的镜头的泛化能力。此外，模型的微调过程通常要求已知镜头的描述。", "innovation": "本文提出了OmniLens，这是一种通过（i）建立包含全面镜头样本的LensLib以预训练鲁棒的基础模型，（ii）利用快速的LensLib到特定领域适应方法将模型适应于未知设计镜头的快速镜头库到特定领域的自适应方法来解决通用CAC的问题。此外，还提出了基于统计观察到的退化引起的暗通道先验的无监督正则化项，以实现高效的领域适应。实验结果显示，通过EAOD生成的LensLib有效地开发了一种通用CAC模型，具有强大的泛化能力，此模型也能够通过0.35-1.81dB的PSNR改进非盲镜头特定方法，特别是在严重的畸变情况下，提出的适应方法显著改进了基础模型（最多2.59dB的PSNR提高）。", "conclusion": "通过提出EAOD管道生成现实畸变行为丰富的镜头样本，以及基于统计观察的无监督正则化项，开发了一种有效的LensLib到特定领域的适应方法，从而在通用镜头畸变矫正方面取得了显著进展。"}
{"llm_update_time": "20251015", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2310.00919", "html_url": "https://arxiv.org/abs/2310.00919", "title": "BAAF：针对医学超声图像分割任务的基准注意自适应框架", "title_en": "BAAF: A benchmark attention adaptive framework for medical ultrasound image segmentation tasks", "authors": "Gongping Chen,Lei Zhao,Xiaotao Yin,Liang Cui,Jianxun Zhang,Yu Dai,Ningning Liu", "background": "基于AI的辅助诊断程序在医学超声影像中的广泛研究。超声图像的复杂场景，其中内部和外部因素的干扰严重，对自动精确定位物体区域带来独特的挑战。", "innovation": "提出了一个更通用且 robust 的基准注意自适应框架（BAAF），用于协助医生更快更准确地在超声影像中分割或诊断病变和组织。BAAF 包含并行混合注意模块 (PHAM) 和自适应校准机制 (ACM)。BAAF 在计算后粗略校准输入特征，并从粗略校准的特征图中自适应地选择更稳健的病变或组织特征化。该设计进一步优化了 CNN 中的“what”和“where”关注与选择问题，并寻求提高医学超声影像中病变或组织的分割精度。", "conclusion": "该方法在四项医学超声影像分割任务上进行了评估，实验证明了相对于现有领先方法的显著性能改进。此外，与现有注意力机制的比较也展示了 BAAF 的优越性。这项工作为自动化的医学超声辅助诊断提供了可能性，减少了对人为准确性和精确性的依赖。"}
{"llm_update_time": "20251015", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2505.15058", "html_url": "https://arxiv.org/abs/2505.15058", "title": "AsynFusion: 向异步潜在一致性模型方向发展的解耦全身音频驱动化身", "title_en": "AsynFusion: Towards Asynchronous Latent Consistency Models for Decoupled Whole-Body Audio-Driven Avatars", "authors": "Tianbao Zhang,Jian Zhao,Yuer Li,Zheng Zhu,Ping Hu,Zhaoxin Fan,Wenjun Wu,Xuelong Li", "background": "全身音频驱动化身的姿势和表情生成对于创建逼真的数字人类和增强交互式虚拟代理的能力具有重要意义，应用场景广泛，包括虚拟现实、数字娱乐和远程通信。现有方法通常独立生成音频驱动的面部表情和手势，这导致了面部和手势之间缺乏有效的协调，使得动画显得不自然且不连贯。", "innovation": "本文提出了AsynFusion框架，该框架利用了扩散变换器实现表情和手势的和谐合成。该方法基于双分支DiT架构，支持面部表情和手势的并行生成，并引入了协同同步模块以促进两种模式之间的双向特征交互，以及异步LCM采样策略以降低计算开销同时保持高质量输出。", "conclusion": "广泛的实验表明，AsynFusion在生成实时同步全身动画方面达到了最先进的技术水平，在定量和定性的评估中均优于现有方法。"}
{"llm_update_time": "20251015", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2504.01483", "html_url": "https://arxiv.org/abs/2504.01483", "title": "GarmageNet: 一种用于缝制图设计和通用服装建模的多模态生成框架", "title_en": "GarmageNet: A Multimodal Generative Framework for Sewing Pattern Design and Generic Garment Modeling", "authors": "Siran Li,Ruiyang Liu,Chen Liu,Zhendong Wang,Gaofeng He,Yong-Lu Li,Xiaogang Jin,Huamin Wang", "background": "现实的数字服装建模仍然是一项劳动密集型的任务，因为将复杂的2D缝制图案转化为高保真、可用于物理模拟的3D服装需要极其细致的过程。现有方法大多依赖于劳动密集型的手动转换过程，效率低下且存在诸多限制。因此，提高数字服装建模的自动化与效率成为该领域的研究热点问题。", "innovation": "本文提出了GarmageNet，这是一种一体化生成框架，能够自动化2D缝制图案的创建、缝制关系的构建以及可与物理模拟兼容的3D服装初始生成。关键贡献是Garmage，一种新颖的服装表示方法，它将每个面板作为结构化几何图像编码，有效解决了2D结构图案与3D服装几何之间的语义和几何差距。接着提出了生成面板几何图像的潜在扩散变换器GarmageNet和预测面板轮廓上的点对点缝制连接的神经模块GarmageJigsaw。此外，作者还构建了一个包含14,801件精心设计的服装的数据集GarmageSet，这些服装具有详细的结构和样式注解，用于支持训练和评估。这些创新性方法展示了在多种应用场景中的多功能性和有效性，如多模态设计概念（文本提示、草图、照片）下的可扩展服装生成，直接建模从原始平缝图案，通过不规则点云恢复图案，以及使用传统指令进行服装逐进编辑，为全自动化、生产级管道奠定了基础，推动了数字时尚的发展。", "conclusion": "GarmageNet 提供了一种全面的方法，将多模态设计输入转化为高质量的3D服装模型，并且促进了基于物理的服装仿真。该方法展示了广泛的适用性，对于数字服装建模具有重要的实际价值和理论意义。"}
{"llm_update_time": "20251015", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2505.05510", "html_url": "https://arxiv.org/abs/2505.05510", "title": "如何训练你的变体深度神经网络", "title_en": "How to Train Your Metamorphic Deep Neural Network", "authors": "Thomas Sommariva,Simone Calderara,Angelo Porrello", "background": "NeuMeta 是一种近期提出的生成具有可变宽度和深度的神经网络的范式，基于隐式神经表示 (INR)，它能够学习连续的权重流形，直接生成压缩模型，包括一些在训练时未见过的配置。尽管有潜力，但原始的 NeuMeta 规范仅在底层模型的最后一层有效，限制了其更广泛的适用性。", "innovation": "本文提出了一种训练算法，扩展了 NeuMeta 的能力，使其能在最小化精度损失的情况下实现全网络的变体。该方法包含模块化的增量训练、INR 初始化以及替代批量归一化的策略。生成的变体网络在广泛的压缩比范围内保持竞争性的精度，提供了一种可扩展的解决方案，用于部署深度模型，使它们更具适应性和高效性。", "conclusion": "所提出的算法在保持竞争力的精度的同时，能够实现全网络的变体，为部署深度模型提供一种可扩展的解决方案。相关代码可以在提供的链接中获取。"}
{"llm_update_time": "20251015", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2505.12477", "html_url": "https://arxiv.org/abs/2505.12477", "title": "联合嵌入 vs 重构：潜在空间预测在自我监督学习中的可证明优势", "title_en": "Joint Embedding vs Reconstruction: Provable Benefits of Latent Space Prediction for Self Supervised Learning", "authors": "Hugues Van Assel,Mark Ibrahim,Tommaso Biancalani,Aviv Regev,Randall Balestriero", "background": "自监督学习（SSL）领域的两种主要范式是重建和联合嵌入。重建方法侧重于从输入空间的不同视角重建原始样本。相比之下，联合嵌入方法旨在将不同视角的表示在潜在空间中对齐。尽管这两种方法各有优势，但实践者在选择之间缺乏明确的指导方针。本文旨在揭示区分这两种范式的内部机制，并通过利用这两种方法的闭式解，精确地刻画了视角生成过程（例如，数据增强）如何影响学习到的表示。研究还发现，与有监督学习不同，SSL范式需要在增强与无关特征之间存在最小对齐，以便在样本量增大时达到渐近优化。因此，本文揭示了两种范式之间的权衡，并证实了联合嵌入方法在实际具有挑战性的数据集上的经验成功。", "innovation": "本文的创新之处在于通过利用闭式解精确定量分析了视角生成过程如何影响学习到的表示，展示两种SSL范式在达到渐近优化时都需最小对齐条件，而联合嵌入方法对无关特征的要求比基于重构的方法更弱，从而在特定情况下是更优的选择。", "conclusion": "研究结果表明，当无关特征的幅度较大时，应偏好联合嵌入方法，因为它们施加了比基于重构的方法更弱的对齐条件。这对两种SSD范式之间的权衡进行了澄清，并验证了联合嵌入方法在真实挑战性数据集上的经验成效。"}
{"llm_update_time": "20251015", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2506.01353", "html_url": "https://arxiv.org/abs/2506.01353", "title": "EgoBrain：结合心灵与眼睛进行人类动作理解", "title_en": "EgoBrain: Synergizing Minds and Eyes For Human Action Understanding", "authors": "Nie Lin,Yansen Wang,Dongqi Han,Weibang Jiang,Jingyuan Li,Ryosuke Furuta,Yoichi Sato,Dongsheng Li", "background": "脑-机接口(BCI)，尤其是通过脑电图(EEG)技术，与人工智能(AI)的结合，展示了通过神经信号解读人类认知和行为的巨大潜力。近年来，多模态AI模型的兴起带来了前所未有的新机遇。研究论文详细介绍了一个名为EgoBrain的新大型多模态数据集，该数据集同步了人类大脑的主观视觉和脑电波，收集了40名参与者的61小时记录，涵盖日常生活中的29种活动类别。该研究旨在推动以人类为中心的行为分析框架的发展，进一步深化脑机接口领域的多模态统一框架研究，并推动认知计算领域的开放科学实践。", "innovation": "该研究推出了EgoBrain，这是首款大规模、时间同步且结合主观视觉与EEG的数据集，特别关注理解和分析人类在日常活动中的行为。开发了一种多模态学习框架，用于融合EEG和视觉信息，提升人类行为的理解精度，并确保在跨参与者和跨环境条件下验证其有效性。这是第一次大规模探索人类行为的多模态数据集，不仅提供了新的研究方法，也促进了脑机接口技术的发展。", "conclusion": "EgoBrain为多模态脑-机接口技术开辟了新的道路，提供了一个整合多感官信息以更好地理解人类行为的平台。所有的数据、工具和获取协议都已公开，以促进认知计算领域更开放的研究环境。"}
{"llm_update_time": "20251015", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.16463", "html_url": "https://arxiv.org/abs/2508.16463", "title": "模块化嵌入重组用于增量学习", "title_en": "Modular Embedding Recomposition for Incremental Learning", "authors": "Aniello Panariello,Emanuele Frascaroli,Pietro Buzzega,Lorenzo Bonicelli,Angelo Porrello,Simone Calderara", "background": "预训练视觉-语言模型（VLMs）的出现显著改变了连续学习（CL），主要是由于它们的零样本分类能力。这种能力使VLMs非常适合实际应用，能够在不需要适应的情况下获得对新未见类别的稳健性能。然而，当下游任务与预训练领域有显著偏差时，微调仍然必不可少。之前的CL方法主要集中在保留VLMs的零样本能力，特别是在增量微调过程中。作者则更进一步，提出了一种方法，将保留转化为增强VLMs的零样本能力。", "innovation": "作者提出了一个名为MoDular Embedding Recomposition（MoDER）的模块化框架，该框架通过训练多个专为单一已见类别设计的文本专家，并将它们存储在一个基础枢纽中，来增强VLMs的零样本能力。在推断时，对于每个未见类别，查询枢纽并重组检索到的专家，生成改进分类的合成原型。", "conclusion": "作者展示了其方法在两种流行的零样本增量协议Class-IL和MTIL上的有效性，共涵盖14个数据集。代码库可在提供的链接中获取。"}
{"llm_update_time": "20251015", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.00378", "html_url": "https://arxiv.org/abs/2508.00378", "title": "CoRGI: 后验证视觉接地支持的链式推理验证", "title_en": "CoRGI: Verified Chain-of-Thought Reasoning with Post-hoc Visual Grounding", "authors": "Shixin Yi,Lin Shang", "background": "多模态语言模型（VLMs）在视觉-语言推理时常常表现出幻觉现象，这是因为模型往往在仅对图像进行浅层检查后就生成了解释。因此，需要一种框架来增强推理的可靠性，通过后验证来核实链式推理的输出，并确保答案的准确性和解释的可信度。现有的方法缺乏通过视觉证据核实推理步骤的支持，从而导致了幻觉现象的产生。本文提出了一种名为CoRGI（Chain of Reasoning with Grounded Insights）的框架，该框架能够将VLM生成的推理过程分解为逐步陈述，并将每个步骤与视觉证据联系起来，从而过滤或纠正不支持的断言，最终生成准确的答案。这项工作对多个难题基准测试集VCR、ScienceQA、MMMU、MathVista和HallusionBench进行了实验，证明了CoRGI在多个VLM模型的基础上能够持续提高答案准确性和解释可信度，尤其是在Qwen-2.5VL、LLaVA-1.6和Gemma3-12B等模型上。此外，定性分析进一步展示了验证过程如何减少幻觉并增强解释性，表明后验证的视觉接地是一个值得探索的方向，有助于构建更值得信赖和透明的多模态推理系统。", "innovation": "提出了一种名为CoRGI的框架，该框架能够将视觉-语言模型生成的推理过程分解为逐步陈述，并通过视觉证据进行验证和纠正。这种后验证的方法能够显著提高解释的可信度和回答的准确性，适用于多种视觉-语言模型。", "conclusion": "实验结果表明，CoRGI能够在多个视觉-语言模型上，不仅提高答案的准确性，还能增强解释的可信度。定性分析进一步证实了通过后验证的视觉接地可以减少模型生成的幻觉，增强系统的透明度和解释性，为构建更可信的多模态推理系统指明了方向。"}
{"llm_update_time": "20251015", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.21041", "html_url": "https://arxiv.org/abs/2508.21041", "title": "自然图像预训练的DINOv3高效微调用于异常有丝分裂图分类（MIDOG 2025任务2获胜者）", "title_en": "Efficient Fine-Tuning of DINOv3 Pretrained on Natural Images for Atypical Mitotic Figure Classification (MIDOG 2025 Task 2 Winner)", "authors": "Guillaume Balezo,Hana Feki,Raphaël Bourgade,Lily Monnier,Matthieu Blons,Alice Blondel,Etienne Decencière,Albert Pla Planas,Thomas Walter", "background": "不典型的有丝分裂图（AMFs）代表与不良预后相关的异常细胞分裂。然而，其检测由于低频度、微妙的形态特征以及观察者之间的差异性而困难重重。MIDOG 2025挑战赛为跨多个领域的AMF分类提供了基准。", "innovation": "使用低秩适应（LoRA）对最近发布的DINOv3-H+视觉变换器进行微调，并对其进行少量参数（约1.3M）训练，结合广泛的数据增强和领域加权Focal损失，成功处理领域异质性。尽管存在领域差距，该微调后的DINOv3仍能够成功转移到病理学，最终在测试集中名列前茅。此结果强调了DINOv3预训练的优势，并突出了我们微调策略的效率和鲁棒性，对于MIDOG 2025的异常有丝分裂分类挑战取得了最先进的结果。", "conclusion": "微调后的DINOv3达到最佳性能，证明了DINOv3预训练的优势以及本研究调整策略的有效性和稳健性，在AMF分类挑战中取得了最先进的结果。"}
{"llm_update_time": "20251015", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.11354", "html_url": "https://arxiv.org/abs/2509.11354", "title": "算法实现：一种低成本、基于GUI的半无监督显微镜分割框架介绍", "title_en": "Algorithmic Implementation: An Introduction to a Low-Cost, GUI-Based, Semi-Unsupervised Microscopy Segmentation Framework", "authors": "Surajit Das,Pavel Zun", "background": "本文介绍了一种用于低成本实验室（配备标准CPU桌面计算机）的新型显微镜图像分析框架。当前，这些科研机构受限于预算，难以采用高昂的高端显微镜设备进行研究，而现有的大多数显微镜图像分析工具复杂且需要编程技能或大量训练数据，使得它们难以被这些实验室所采用和维护。在此背景下，该文章旨在提供一种用户友好、无需编程技能即可操作的显微镜图像分割解决方案，旨在推动低成本且高效的细胞分析和研究，特别是对于个性化医疗中的细胞移植和肌肉再生疗法的研究具有重要意义。", "innovation": "该研究的主要创新点在于提出了一种基于Python的无需手动标注训练数据且无需训练过程的显微镜图像分析框架，通过先进的计算机视觉和机器学习管道实现对活细胞的无标签数据分析。该框架的模块化设计使得维护和集成更为便捷，同时支持单张图像和批量处理。该框架在多个公共livecells数据集上的实验表明，与当前的工具如Cellpose和StarDist相比，其具有更高的准确性和可重复性，并且在基于CPU的平台上具有竞争力的分割速度，这为基本研究和临床应用提供了强大的支持。", "conclusion": "总之，该研究开发了一种用户友好、无需编程技能即可操作、无需大量训练数据的显微镜图像分割工具。该工具在多个公共数据集上的实验结果证明了其高性能和高效率，并且其易于维护和灵活的集成特性使其适用于不同应用场景，尤其是在细胞移植和肌肉再生疗法等个性化医疗领域的基本研究和临床应用中展现出巨大潜力。"}
{"llm_update_time": "20251015", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.15979", "html_url": "https://arxiv.org/abs/2508.15979", "title": "基于模糊逻辑和空间统计的半监督显微分割GUI跨域分析", "title_en": "Semi-Unsupervised Microscopy Segmentation with Fuzzy Logic and Spatial Statistics for Cross-Domain Analysis Using a GUI", "authors": "Surajit Das,Pavel Zun", "background": "未染色的活细胞明场显微镜观察面临着低对比度、动态形态、不均匀照明以及缺乏标记的挑战。深层学习在染色、高对比度图像上实现了最佳表现，但需要大规模标记数据集、昂贵的硬件，并且在不均匀照明下可能会失效。这篇论文提出了一个低成本、轻量级、无需标注的分割方法，采用一次校准辅助的无监督框架，适用于不同成像模态和图像类型。该框架通过局部均值的空间标准差确定背景。不确定像素通过模糊逻辑、节点强度累计平方位移、统计特性进行解决，并在后分割去噪校准后保存为模板，直至噪声模式或对象类型显著变化。程序可以作为一个脚本或图形界面运行，供非程序员使用。该方法使用IoU、F1分数等指标进行了严格评估，并通过Wilcoxon符号秩测试验证了统计显著性。在未染色的明场肌细胞(C2C12)图像中，该方法在精度和召回率方面分别优于Cellpose 3.0和StarDist，平均IoU=0.43，F1=0.60, 提升了48%。在相位对比显微镜下，使用LIVECell数据集（n=3178），该方法的平均IoU为0.69，F1分数为0.81，获得了显著的专家一致性确认，证明了跨模态的稳健性。激光受损的聚合物表面的分割成功进一步证明了跨领域的稳健性。该工作通过引入同质图像平面概念，为训练和标注免费的分割提供了一种新的理论基础，该框架在CPU上运行高效，避免细胞染色，并且适合活细胞成像和生物医学应用", "innovation": "提出了一种低成本、轻量级、无需标注的分割方法，采用一次校准辅助的无监督框架，适用于不同成像模态和图像类型。通过局部均值的空间标准差确定背景，不确定像素通过模糊逻辑、节点强度累计平方位移、统计特性进行解决，后分割去噪校准后保存为模板，该过程直观易用，简单高效。该方法在未染色的明场肌细胞图像中显著优于现有的Cellpose 3.0和StarDist方法，并在相位对比显微镜下展示了跨模态稳健性。通过引入同质图像平面概念，该方法提供了新的理论基础，特别适合于活细胞成像和生物医学应用", "conclusion": "该研究提出的方法在未染色活细胞明场显微镜和相位对比显微镜中表现出色，显著优于现有的Cellpose 3.0和StarDist方法，并强调了其在跨领域分析中的适应性。该研究提出的同质图像平面概念为培训和标注免费的分割方法提供了新的理论基础，有助于未来活细胞成像和生物医学应用的进一步发展"}
{"llm_update_time": "20251015", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.10764", "html_url": "https://arxiv.org/abs/2510.10764", "title": "Optimally Deep Networks -- Adapting Model Depth to Datasets for Superior Efficiency", "title_en": "Optimally Deep Networks -- Adapting Model Depth to Datasets for Superior Efficiency", "authors": "Shaharyar Ahmed Khan Tareen,Filza Khan Tareen", "background": "深度神经网络（DNNs）在各种任务中表现出色，但通常这种成功是通过使用非常大的模型大小、高计算需求和大内存占用来实现的。传统的深度架构在训练时通常达到了完整的深度，但这往往并不适合所有数据集或任务。在复杂度较低的数据集上训练深度架构通常会导致不必要的计算浪费、能源消耗和内存使用过量，这使得在资源受限的设备上部署模型变得不切实际。", "innovation": "提出了一种称为渐进深度扩展（Progressive Depth Expansion）的NAS（神经架构搜索）策略，该策略通过分阶段增加网络深度来适应给定数据集的任务复杂度。ODNs（Optimally Deep Networks）使用仅针对特定数据集的最优深度，删除冗余层，从而减少了未来训练和推断的成本，降低了内存占用，提高了计算效率，促进了对边缘设备的部署。实验结果表明，对于MNIST和SVHN，最优深度的ResNet-18和ResNet-34分别在98.64%和96.44%的内存占用下实现了99.31%和96.08%的竞争性精度。", "conclusion": "ODNs通过根据数据集的具体任务需求动态调整模型深度，达成在确保高性能的同时大幅度降低资源消耗的目的，实现了在边缘设备上的高效部署。"}
{"llm_update_time": "20251015", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.11769", "html_url": "https://arxiv.org/abs/2510.11769", "title": "GAR：生成对抗式强化学习在形式定理证明中的应用", "title_en": "GAR: Generative Adversarial Reinforcement Learning for Formal Theorem Proving", "authors": "Ruida Wang,Jiarui Yao,Rui Pan,Shizhe Diao,Tong Zhang", "background": "通过可验证语言（如Lean）解决数学问题对数学和计算机科学领域产生了重大影响。现有最先进的模型通常使用昂贵的在线强化学习（RL）或专家迭代进行训练。然而，这些方法依赖于固定的问题集，导致训练效率低下，并限制了模型处理复杂问题的能力。", "innovation": "提出了一种名为GAR（生成对抗式强化学习）的全面RL训练框架，该框架以对抗循环同时训练问题生成者和求解器。GAR引入了一种隐藏的学习课程机制，该机制使任务难度与证明者能力的演变保持一致，从而提高了训练效率并增强了证明高级定理的能力。实验表明，在GAR训练下，Goedel-Prover-V2-8B和DeepSeek-Prover-V2-7B在MiniF2F-Test基准测试中的pass@32平均相对改进为4.20%，而DeepSeek-Prover-V2在ProofNet-Test中的pass@32从22.58%提高到25.81%。此外，GAR为验证环境下问题生成和解决的共同进化提供了一种通用的RL范式。", "conclusion": "GAR使得模型能够在一个更复杂、动态环境下去学习和解题，有效提高了证明高级定理的能力，为形式定理证明提供了新的训练框架。"}
{"llm_update_time": "20251015", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.11745", "html_url": "https://arxiv.org/abs/2510.11745", "title": "作为医生思考：ICU病亡预测的可解释AI方法", "title_en": "Think as a Doctor: An Interpretable AI Approach for ICU Mortality Prediction", "authors": "Qingwen Li,Xiaohang Zhao,Xiao Han,Hailiang Huang,Lanjuan Liu", "background": "ICU病亡预测通过使用ICU入院早期收集的EHRs估计患者出院时的病亡状态，对重症监护至关重要。虽然预测准确性很重要，但可解释性同样非常重要，以建立临床信任并符合监管标准，这成为信息系统研究的热点。理想的方法应具备内在可解释性并将其推理与ICU决策实践中的三个关键要素——临床进程识别、人口异质性和预后意识——相一致。但传统方法主要集中在人口异质性上，忽略了临床进程识别和预后意识。近年来，尽管原型学习方法已解决临床进程识别的问题，但将其他要素纳入模型的研发仍显不足。针对以上问题，该研究提出了ProtoDoctor，这是一种在推理过程中整合ICU决策实践中所有三个关键要素且具备内在可解释性的创新ICU病亡预测框架。", "innovation": "ProtoDoctor提出了两个关键创新：预测临床进程识别模块和人口异质性识别模块。预测临床进程识别模块通过原型学习法识别临床进程，并利用新型正则机制实现预后意识；人口异质性识别模块通过对特定队列原型和风险调整模型人口异质性。实验结果表明，ProtoDoctor在预测准确性上优于最先进的基线模型，并且其解释更具临床意义、可信度和适用性于ICU实践。", "conclusion": "ProtoDoctor是一种新型ICU病亡预测框架，能够实现内在解释性并整合ICU决策实践的三个关键要素。通过原型学习技术识别临床进程，并利用新型正则机制实现预后意识，同时对特定队列原型和风险调整模型化人口异质性，表明该方法在提高预测性能和提升解释性方面具有显著优势。"}
{"llm_update_time": "20251015", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.11827", "html_url": "https://arxiv.org/abs/2510.11827", "title": "结合欧几里得和双曲表示进行节点级异常检测", "title_en": "Combining Euclidean and Hyperbolic Representations for Node-level Anomaly Detection", "authors": "Simone Mungari,Ettore Ritacco,Pietro Sabatino", "background": "节点级异常检测（NAD）因结构模式和特征分布的多样性而极具挑战性。NAD 是一个关键任务，具有多种应用，从欺诈检测、网络安全到推荐系统。现实世界中的大量复杂图数据使得识别节点级异常变得困难。传统的浅层和深层模型可能无法有效检测到图中的细微且复杂的异常。", "innovation": "本文提出了一种名为 Janus 的框架，该框架联合使用欧几里得和双曲图神经网络来捕捉节点表示的互补方面。每个节点由两部分表示：原始特征和通过随机游走和度数推导的结构特征，分别嵌入到欧几里得和双曲空间中。利用多图自编码器框架，并配备对比学习目标作为正则化项，Janus 可以使嵌入在欧几里得和双曲空间之间对齐，从而突出那些难以调和的节点视图，并因此可能是异常的节点。实验结果显示 Janus 在多个真实世界数据集上优于浅层和深层基线，实验证明结合多种几何表示是识别图中微小而复杂异常的有效且稳健的方法。", "conclusion": "实验结果表明，Janus 框架在四个真实世界的图数据集上表现优于浅层和深层的基线方法，这表明结合多种几何表示是识别图中复杂和微妙的异常的有效且稳健的方法。"}
{"llm_update_time": "20251015", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.05839", "html_url": "https://arxiv.org/abs/2510.05839", "title": "在不完整模态下的鲁棒且可靠的多模态虚假信息识别", "title_en": "Towards Robust and Realible Multimodal Misinformation Recognition with Incomplete Modality", "authors": "Hengyang Zhou,Yiwei Wei,Jian Yang,Zhenyu Zhang", "background": "随着社交媒体平台上大量多模态虚假内容的出现，多模态虚假信息识别已成为一项急迫的任务。以往的研究主要集中在复杂的特征提取和融合，以从多模态内容中学习区分性信息。然而，在实际应用中，多媒体新闻在传播过程中可能会失去一些自然信息，导致模态不完整，这对现有模型的泛化能力和鲁棒性有害。", "innovation": "本文提出了一种新型的一般且鲁棒的多模态融合策略，称为多专家不完整模态学习网络（MMLNet）。该策略包含三个关键步骤：（1）多专家合作推理，通过动态利用多种专家的互补信息来弥补缺失的模态；（2）不完整模态适配器，通过利用新的特征分布来补偿缺失的信息；（3）模态缺失学习，利用标签感知自适应加权策略，通过对比学习来学习稳健的表示。在两个语言的三个实际基准上评估了MMLNet的表现，其性能优于最佳方法，同时保持了相对的简洁性。", "conclusion": "MMLNet通过确保由信息传播引起的不完整模态情况下虚假信息识别的准确性，有效遏制了恶意虚假信息的传播。"}
{"llm_update_time": "20251015", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.11834", "html_url": "https://arxiv.org/abs/2510.11834", "title": "不要踩界：过滤生成的边界引导", "title_en": "Don't Walk the Line: Boundary Guidance for Filtered Generation", "authors": "Sarah Ball,Andreas Haupt", "background": "生成模型越来越常与安全分类器结合使用，以过滤掉有害或不理想的输出。通常的做法是微调生成器，以降低被分类器过滤掉的概率，但这种方式可能效果不佳：它往往会使模型生成的内容偏向于分类器的决策边界，从而增加了误报和漏报的情况。", "innovation": "本文提出了边界引导（Boundary Guidance）的强化学习微调方法，这种方法明确地引导生成远离分类器的边界。在有关越狱和模糊提示的基准测试中，边界引导提高了生成输出的安全性和实用性，通过LLM作为裁判的评价。通过不同模型规模和奖励设计的全范围验证，证明了该方法的鲁棒性。", "conclusion": "边界引导方法在模型大小和奖励设计上的广泛实验验证了其鲁棒性，能够在保持输出安全性的前提下提高其实用性。"}
{"llm_update_time": "20251015", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2502.02631", "html_url": "https://arxiv.org/abs/2502.02631", "title": "ParetoQ：改善极低比特LLM量化中的扩展法则", "title_en": "ParetoQ: Improving Scaling Laws in Extremely Low-bit LLM Quantization", "authors": "Zechun Liu,Changsheng Zhao,Hanxian Huang,Sijia Chen,Jing Zhang,Jiawei Zhao,Scott Roy,Lisa Jin,Yunyang Xiong,Yangyang Shi,Lin Xiao,Yuandong Tian,Bilge Soran,Raghuraman Krishnamoorthi,Tijmen Blankevoort,Vikas Chandra", "background": "关于量化模型的比特宽度如何在模型大小和准确率之间实现最佳权衡，这是一个持续争论的话题。尽管4比特量化和1.58比特量化各有拥趸，但缺乏统一的比特框架使得结论不够有力。这篇论文介绍了ParetoQ，这是首个统一框架，用于严谨比较1比特、1.58比特、2比特、3比特和4比特量化设置之间的性能差异。研究表明，从2比特到3比特之间存在显著的学习过渡：对于3比特及以上的量化设置，微调后的模型停留在其原始预训练分布附近；而对于2比特及以下的量化设置，表示会发生剧烈变化。通过优化训练方案和细化量化函数，ParetoQ 超越了所有针对特定比特宽度的方法。ParetoQ 的三元量化模型在使用参数少于四分之一的情况下，仍超越了之前最佳的三元量化模型，且性能相当或更好。各种实验表明，三元量化、2比特量化和3比特量化在大小和准确性的权衡中保持了可比拟的表现，并且普遍优于4比特和二元量化。从硬件限制来看，2比特量化在减少内存占用和加快速度方面具有潜力。", "innovation": "ParetoQ 是首个统一框架，用于严谨比较不同比特宽度（1比特、1.58比特、2比特、3比特和4比特）的量化设置。ParetoQ 通过优化训练方案和细化量化函数，改进了三元量化模型，并在参数少于四分之一的情况下，显著提高了准确性。此外，研究表明从2比特到3比特之间存在显著的学习过渡，并且在大小和准确性的权衡中，三元量化、2比特量化和3比特量化普遍优于4比特和二元量化。研究还发现，2比特量化在硬件限制下的性能表现出希望中的减少内存占用和速度加快的效果。", "conclusion": "ParetoQ 在极低比特 LLM 量化中提供了一种改进扩展法则的框架。2 比特和 3 比特量化在大小-准确率权衡中表现出优于 4 比特和二元量化的方法，且性能接近或超越更早的三元量化模型。未来的工作可能进一步优化不同比特宽度的量化模型，以实现更高的性能和更好的可扩展性。"}
{"llm_update_time": "20251015", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.11832", "html_url": "https://arxiv.org/abs/2510.11832", "title": "Z0-Inf: 零阶近似用于数据影响", "title_en": "Z0-Inf: Zeroth Order Approximation for Data Influence", "authors": "Narine Kokhlikyan,Kamalika Chaudhuri,Saeed Mahloujifar", "background": "分析和改进现代机器学习系统的一个关键方面是理解单个训练实例如何影响模型的预测行为。通过估计这种影响可以实现关键的应用，包括数据选择和模型调试；特别是，自影响，它量化了一个训练点对其自身的影响力，在数据质量评估和异常检测中得到了广泛的应用。现有用于测量数据影响的方法通常由于准确性低或计算成本高而不适合大规模模型：大多数方法要么提供较差的近似值，要么依赖于难以扩大规模的梯度和逆Hessian计算。", "innovation": "本文提出了一种非常高效的零阶近似方法，用于估计训练数据的影响，并且仅需要之前方法所需时间与内存占用的很小一部分。该方法仅仅依赖于训练和测试数据的中间检查点的损失值及其自身，使得即使在目标损失函数不可微的情况下，该方法也具有广泛的应用性。除了计算效率外，该方法在估自身影响方面具有更好的准确性，对于微调大型语言模型，在估计训练测试影响方面具有可比或改进的准确性，从而实现了对训练数据如何塑造模型行为的大规模和实际分析。", "conclusion": "本文提出了一种高效的零阶近似方法（Z0-Inf），用于估算训练数据的影响。与现有方法相比，该方法计算效率更高，且能够准确估计数据对模型的影响。这一创新方法对于大规模模型的数据分析和调试具有重要意义，能够促进模型行为的可解释性并提升数据分析的效率。"}
{"llm_update_time": "20251015", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.11842", "html_url": "https://arxiv.org/abs/2510.11842", "title": "平衡合成数据和重播以提高任务特定能力", "title_en": "Balancing Synthetic Data and Replay for Enhancing Task-Specific Capabilities", "authors": "Urs Spiegelhalter,Jörg K.H. Franke,Frank Hutter", "background": "通过持续预训练调整语言模型以适应新的任务面临着根本性的权衡：模型必须学习新能力同时避免遗忘现有知识。尽管已有研究了合成数据生成技术，但在计算约束下权衡任务性能和知识保留的最优重播比率仍不清楚。本文通过实验研究了在适应新任务时重播比率配置和计算预算之间的相互作用。", "innovation": "使用bAbI推理任务作为目标，应用合成数据生成并系统地评估不同总令牌预算和重播比率配置的影响。分析它们对任务掌握和一般知识保留的影响，发现了一个在任务特定性能和一般知识保留之间平衡的最优配置。", "conclusion": "基于研究结果，提供了根据计算预算选择重播比率的实证指导，使实践者能够以显著减少的训练成本实现强力任务适应。"}
{"llm_update_time": "20251015", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.11839", "html_url": "https://arxiv.org/abs/2510.11839", "title": "WaveletDiff: 多级小波扩散生成时间序列", "title_en": "WaveletDiff: Multilevel Wavelet Diffusion For Time Series Generation", "authors": "Yu-Hsiang Wang,Olgica Milenkovic", "background": "时间序列数据在许多应用中普遍存在，如医疗健康、金融、音频信号处理和气候科学等。然而，高质量的大型时间序列数据集仍然稀缺。尽管合成生成可以解决这一限制，但当前模型在时间域和频率域的限制让他们难以重现真实世界时间序列的固有多层次结构。", "innovation": "作者引入了WaveletDiff框架，直接在小波系数上训练扩散模型，利用时间序列数据的固有多层次结构。该模型结合了为每个分解级别设计的变压器以及跨级别的注意机制，允许通过适应性门控在时间和频率尺度之间选择性地交换信息。此外，该模型还采用基于Parseval定理的个体层次上的能量保真约束，确保在扩散过程中保持频谱保真度。", "conclusion": "在来自能源、金融和神经科学等领域的六组真实数据集上进行全面测试表明，WaveletDiff在多个性能指标上都优于现有时间域和频率域生成方法。例如，WaveletDiff在差异化分数和Context-FID分数方面，与第二优基线相比平均减少到原来的1/3。"}
{"llm_update_time": "20251015", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.11829", "html_url": "https://arxiv.org/abs/2510.11829", "title": "广义的薛定谔桥在生成式AI中的软约束公式及其收敛性分析", "title_en": "Schrödinger bridge for generative AI: Soft-constrained formulation and convergence analysis", "authors": "Jin Ma,Ying Tan,Renyuan Xu", "background": "生成式AI可以视为学习将简单的参考测量映射到复杂的数据分布的问题，近期发现其与经典的薛定谔桥问题（SBPs）有着紧密联系。这些方法通过熵正则化的随机动力学插值在已知边缘概率下的数据分布，然而，经典的SBP存在硬性的终端约束，这在高维或数据稀缺情况下会导致稳定性问题。为了应对这一挑战，本文采用了软约束薛定谔桥问题（SCSBP）的方法，通过参数化终端约束，使其更加灵活，提供了更广泛的解决方案。研究表明，通过这种软约束，可以建立最优解的存在性，并且随着惩罚的增加，控制策略和价值函数逼近经典SBP的速度为线性。本文的分析基于Doob的h-变换，薛定谔势的稳定性结果，Gamma收敛以及一个新颖的不动点论证，这种方法有效地解决了优化过程中的空间度量问题，同时提供了一种辅助的熵最优传输问题来实现优化。这些结果不仅提供了一种定量的收敛性保障，为软约束桥梁提供了第一种具体的理论支持，还揭示了惩罚正则化如何通过增强生成模型的鲁棒性为微调和迁移学习提供新的可能性。", "innovation": "提出了软约束薛定谔桥问题（SCSBP）作为生成式AI的框架，通过引入惩罚函数代替硬约束，提供了更加灵活和鲁棒的随机控制模型；通过Doob的h-变换和Gamma收敛等数学工具，建立了最优解的存在性和收敛性，且提出了一种新的不动点论证来解决优化问题；研究了惩罚正则化在生成式模型中的作用，及如何通过该方法实现更有效的生成、微调和迁移学习过程。", "conclusion": "该研究不仅提供了生成式AI中薛定谔桥问题的软约束方法及其理论分析，还通过定量分析证明了软约束方法的收敛性和有效性，并为合理选择惩罚参数提出了建议，对于生成式AI领域的发展具有一定的理论贡献和应用价值。"}
{"llm_update_time": "20251015", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.11852", "html_url": "https://arxiv.org/abs/2510.11852", "title": "评估开源视觉-语言模型在多模态讽刺检测中的应用", "title_en": "Evaluating Open-Source Vision-Language Models for Multimodal Sarcasm Detection", "authors": "Saroj Basnet,Shafkat Farabi,Tharindu Ranasinghe,Diptesh Kanoji,Marcos Zampieri", "background": "近年来开源视觉-语言模型（VLMs）取得了显著进展，为理解和解释复杂的、主观的多媒体现象（如讽刺）提供了新的机会。本研究评估了七个最先进的VLMs（BLIP2、InstructBLIP、OpenFlamingo、LLaVA、PaliGemma、Gemma3和Qwen-VL）在多模态讽刺检测方面的性能，通过零样本、单样本和少量样本提示，评估了这些模型在生成讽刺实例解释方面的能力。评估基于三个讽刺基准数据集（Muse、MMSD2.0和SarcNet）进行。", "innovation": "本研究创新之处在于系统性地评估了多个最先进的开源视觉-语言模型在检测类似讽刺这样的复杂、主观的多模态现象上的能力，并探讨了其生成高质量解释的能力。", "conclusion": "当前模型在二元讽刺检测方面取得了一定的成功，但在生成高质量解释方面仍需特定任务的微调。"}
{"llm_update_time": "20251015", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.11856", "html_url": "https://arxiv.org/abs/2510.11856", "title": "进程绩效中富含行为的时序预测", "title_en": "Actor-Enriched Time Series Forecasting of Process Performance", "authors": "Aurelie Leribaux,Rafael Oyamada,Johannes De Smedt,Zahra Dasht Bozorgi,Artem Polyvyanyy,Jochen De Weerdt", "background": "过程挖掘中的预测过程监控（PPM）旨在预测未来的操作行为、结果或绩效指标。准确预测这些指标对于事先的决策至关重要。由于过程通常依赖资源，因此理解并加入行为者的行为对于预测是至关重要的。尽管现有研究已经将行为者行为的部分纳入考虑，但它们作为时间变化信号在PPM中的角色仍然有限。本研究探讨了将行为者行为信息，建模为时间序列，能否提高生产时间（TT）预测模型的预测性能。", "innovation": "通过利用实际事件日志构建包含TT特征以及行为者中心特征的时间序列，即行为者的参与度、行为的延续频率、中断和转移行为及其持续时间，本研究训练并比较了不同的模型，以研究加入行为者行为的益处。结果表明，富含行为的模型在均方根误差（RMSE）、平均绝对误差（MAE）和确定系数（R2）方面始终优于只包含TT特征的基线模型。这些发现表明，随着时间进行行为建模，并将这些信息纳入预测模型中，可以提高绩效指标的预测性能。", "conclusion": "与基线模型相比，富含行为的信息可以显著提高预测性能。这种新的时间序列建模方法在预测过程中绩效指标方面具有很大的潜力。"}
{"llm_update_time": "20251015", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.11868", "html_url": "https://arxiv.org/abs/2510.11868", "title": "通过对比学习结合负面语句改进知识图嵌入", "title_en": "Improving Knowledge Graph Embeddings through Contrastive Learning with Negative Statements", "authors": "Rita T. Sousa,Heiko Paulheim", "background": "知识图谱以结构化的三元组表示信息，并作为问答、链接预测和推荐系统等多种应用的基础。现有的研究主要集中在图嵌入方法上，这些方法将实体和关系表示为低维向量空间，以捕捉潜在的语义和结构。然而，大多数现有方法依赖于闭世界假设或局部闭世界假设，将缺失的三元组视为不成立的。这与许多现实世界知识图谱所基于的开放世界假设不符。尽管明确声明的反例有助于区分错误和未知的三元组，但它们在知识图谱中很少被包含，且在嵌入训练过程中经常被忽视。", "innovation": "本文提出了一种新颖的方法，将明确声明的负面语句整合到知识嵌入学习过程中。该方法采用双模型架构，两个嵌入模型并行训练，一个用于正陈述，另一个用于负陈述。在训练过程中，每个模型通过破坏正样本并选择由另一个模型评分最高的候选者来生成负样本。实验结果显示，该方法在多项任务中比最先进的嵌入模型提高了预测性能，表明整合有意义的负面知识对嵌入学习的价值。", "conclusion": "我们的研究证实了将有意义的负面知识整合到嵌入学习中的价值，并通过广泛实验表明提出的方法在链接预测和三元组分类任务中优于最新的嵌入模型。"}
{"llm_update_time": "20251015", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.11877", "html_url": "https://arxiv.org/abs/2510.11877", "title": "在随机博弈中通过序列建模实现鲁棒对抗强化学习", "title_en": "Robust Adversarial Reinforcement Learning in Stochastic Games via Sequence Modeling", "authors": "Xiaohang Tang,Zhuowen Cheng,Satyabrat Kumar", "background": "变换器(Transformer)作为一种高度表现力的序列建模架构，已经被应用于解决序列决策问题，最著名的是决策变换器(Decision Transformer，DT)，它通过针对期望回报进行条件约束学习策略。然而，基于序列建模的强化学习方法的对抗鲁棒性研究还很少。", "innovation": "本文引入了保守对抗鲁棒决策变换器(Conservative Adversarially Robust Decision Transformer，CART)，这是我们所知的第一个旨在增强DT在对抗随机博弈中的鲁棒性的框架。通过将每个阶段的主角和对手的互动形式化为阶段博弈，并使用这些阶段博弈得出的NashQ值来条件约束Transformer策略，CART生成同时对不可预知的状态转移具有保守性和对抗鲁棒性的策略。", "conclusion": "实验结果表明，CART在估计最小极大价值方面更加准确，并在一系列对抗随机博弈中实现了更优的最坏情况回报。"}
{"llm_update_time": "20251015", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.11903", "html_url": "https://arxiv.org/abs/2510.11903", "title": "集成序列和关系建模以整合用户事件：数据集和预测任务", "title_en": "Integrating Sequential and Relational Modeling for User Events: Datasets and Prediction Tasks", "authors": "Rizal Fathony,Igor Melnyk,Owen Reinert,Nam H. Nguyen,Daniele Rosa,C. Bayan Bruss", "background": "用户事件建模在许多机器学习应用中占据中心地位，涵盖了电子商务、社交媒体、金融和网络安全等多个领域。用户事件可以大致分为个人事件（涉及个体行为）和关系事件（涉及两个用户之间的交互），这两种事件通常分别使用序列方法和图方法进行建模。尽管现实世界系统需要捕捉这两种类型事件，前期研究很少将它们结合起来考虑，原因在于简单地认为用户行为可以通过单一的序列或图形形式得到充分表征。因此，需要有公共数据集和预测任务，能够明示地涵盖个人与关系事件。", "innovation": "引入了一组包含个人和关系事件的公共数据集，提出了一个统一的形式化模型，并通过实验证明结合这两种类型的事件能够使模型受益。结果显示现有方法仍有相当大的改进空间。", "conclusion": "这些资源被释放以支持统一用户事件建模的研究，并鼓励朝着这个方向进一步发展。"}
{"llm_update_time": "20251015", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.11899", "html_url": "https://arxiv.org/abs/2510.11899", "title": "ADARL: 自适应低秩结构在不确定性环境下稳健的策略学习", "title_en": "ADARL: Adaptive Low-Rank Structures for Robust Policy Learning under Uncertainty", "authors": "Chenliang Li,Junyu Leng,Jiaxiang Li,Youbang Sun,Shixiang Chen,Shahin Shahrampour,Alfredo Garcia", "background": "鲁棒强化学习（Robust RL）旨在处理环境动力学中的认识不确定性，但现有方法通常依赖于嵌套的最小-最大优化，这导致了高性能和高计算成本。这些方法通常会过度保守，对策略的调整不够灵活。文章背景指出现有方法存在的主要问题在于计算效率低且过于保守，因此需要一种新的方法来解决这些局限性。", "innovation": "提出了自适应秩表示（Adaptive Rank Representation，AdaRL），这是一种二层优化框架，通过调整策略复杂度与任务固有维度之间的匹配来提升鲁棒性。在下层，AdaRL在固定秩约束下进行策略优化，通过以中心模型为中心的Wasserstein球进行动力学采样；在上层，它能自适应地调整秩以平衡偏差和方差之间的关系，将策略参数投影到低秩流形上。此设计避免了求解对抗最坏情况的动力学，同时保证了适度的策略参数化，避免了过度参数化。", "conclusion": "与固定秩基线（例如SAC）和最先进的鲁棒RL方法（例如RNAC，Parseval）相比，实验证明，AdaRL不仅一致地表现更优，还能向潜在任务的固有秩收敛。这些结果强调，自适应低秩表示对于不确定性的环境下的鲁棒RL是一种有效且有原则的替代方案。"}
{"llm_update_time": "20251015", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.11933", "html_url": "https://arxiv.org/abs/2510.11933", "title": "非站稳态无模型强化学习中的高效重启", "title_en": "Efficient Restarts in Non-Stationary Model-Free Reinforcement Learning", "authors": "Hiroshi Nonaka,Simon Ambrozak,Sofia R. Miskala-Dinc,Amedeo Ercole,Aviva Prins", "background": "该研究背景在于无模型（模型自由）非站稳态强化学习（RL）中的重启设计问题，特别是在Mao等人（2022）的RestartQ-UCB算法中存在两种核心问题：一是完全忘记现象，即重启后丢失所有关于环境的学习信息；二是按预定时间表的重启，不考虑策略与当前环境动态的不兼容性。", "innovation": "创新之处在于提出了一种改进的重启机制，具体包括部分重启、自适应重启和选择性重启。这些都是对RestartQ-UCB和RWANDOMIZEDQ算法的修改。实验结果显示该方法在多种不同的环境中具有接近最优的经验性能，相对于RestartQ-UCB算法，动态遗憾度降低了高达91％。", "conclusion": "研究发现，提出的部分重启、自适应重启和选择性重启方法显著改进了模型自由非站稳态的RL算法性能，实现了接近最优的经验表现。"}
{"llm_update_time": "20251015", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.11942", "html_url": "https://arxiv.org/abs/2510.11942", "title": "关于可高效计算的函数、深度网络和稀疏组合性", "title_en": "On efficiently computable functions, deep networks and sparse compositionality", "authors": "Tomaso Poggio", "background": "论文背景在于探讨高效的图灵可计算函数与深度神经网络之间的关系。具体而言，它研究了在固定输入/输出精度下，如何通过组合稀疏的有向无环图（DAG）表示来实现这些函数的近似表示，进而构建具有高精度的深度神经网络模型。背景文献提及了可高效计算函数的定义及其在深度学习中的应用，强调了稀疏组合性在优化和神经网络结构设计中的重要性。", "innovation": "论文的创新点在于提出了高效的图灵可计算函数能够自然地映射到组合稀疏的DAG表示形式中，且通过将每个门电路替换为常规模型的神经模拟器，可以构建出满足目标精度的深度神经网络。此外，该研究还与组合性逼近速率以及优化过程中的稀疏结构层次搜索建立了联系。", "conclusion": "研究结论是，如果函数f在输入长度的对数时间内可被图灵机高效计算，则可以找到一个组合稀疏的DAG表示形式和相应的神经逼近模型，这两个模型都可以实现目标精度。进一步，该结论还说明了组合稀疏结构在深度学习和优化问题中的优势。"}
{"llm_update_time": "20251015", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.11917", "html_url": "https://arxiv.org/abs/2510.11917", "title": "图神经专家混合变分模型在 EEG 脑网络中阿尔茨海默病生物标志物识别中的应用", "title_en": "Variational Mixture of Graph Neural Experts for Alzheimer's Disease Biomarker Recognition in EEG Brain Networks", "authors": "Jun-En Ding,Anna Zilverstand,Shihao Yang,Albert Chih-Chieh Yang,Feng Liu", "background": "阿尔茨海默病（AD）和前颞叶痴呆（FTD）等痴呆症在脑电图（EEG）中表现出重叠的电生理特征，这为准确诊断带来挑战。现有的基于EEG的方法由于采用了全频带频率分析，限制了痴呆症亚型和严重程度阶段的精确区分。", "innovation": "提出了一种图神经专家混合变分模型（VMoGE），该模型结合了频率特异性生物标志物识别和结构化变分推断，以增强痴呆症的诊断和阶段分析。VMoGE 使用多粒度变压器提取四个频带中的多尺度时间模式，然后使用高斯马尔可夫随机场先验的变分图卷积编码器。通过结构化变分推断和自适应门控，VMoGE 将神经特化与生理学上有意义的EEG频率带关联起来。在两个不同数据集上对亚型分类和严重程度阶段的评估表明，相较于最先进的方法，VMoGE 在 AUC 上的提升范围为 +4% 到 +10%，并且 VMoGE 能提供可解释的见解，这些见解与临床指标和与神经病理学标记的空间模式相关联，促进了痴呆症生物标志物的发现。", "conclusion": "VMoGE 在痴呆症诊断和监控中表现出色，通过对专家权重的解释，提供了与临床指标和神经病理学标记的空间模式相关联的可解释洞察，从而促进了 EEG 生物标志物的发现。"}
{"llm_update_time": "20251015", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.11953", "html_url": "https://arxiv.org/abs/2510.11953", "title": "利用MMD塑造潜在空间：通过可编程先验的解缠", "title_en": "Sculpting Latent Spaces With MMD: Disentanglement With Programmable Priors", "authors": "Quentin Fruytier,Akshay Malhotra,Shahab Hamidi-Rad,Aditya Sant,Aryan Mokhtari,Sujay Sanghavi", "background": "学习解缠表征是机器学习中的核心目标，主流方法是变分自编码器（VAE）框架，通过Kullback-Leibler（KL）散度正则化鼓励潜在空间匹配因子化的高斯先验。然而，该研究直接提供了KL正则化不可靠的证据，这种机制在聚合后验中经常不能强制执行目标分布。", "innovation": "引入了基于最大均值差异（MMD）的可编程先验框架，允许实践者明确塑造潜在空间，实现CIFAR-10和Tiny ImageNet等复杂数据集上的状态最优的互独立关系，而无需常见的重建权衡。此外，该框架可用来设计与语义特征更好的对齐的高级先验。", "conclusion": "该研究为表征工程提供了一个基础工具，开启了模型识别和因果推理的新途径。"}
{"llm_update_time": "20251015", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.11926", "html_url": "https://arxiv.org/abs/2510.11926", "title": "使用紧凑、无传感器类型依赖、适配学习增强的仅解码器变压器进行室内定位", "title_en": "Indoor Localization using Compact, Telemetry-Agnostic, Transfer-Learning Enabled Decoder-Only Transformer", "authors": "Nayan Sanjay Bhatia,Pranay Kocheta,Russell Elliott,Harikrishna S. Kuttivelil,Katia Obraczka", "background": "室内Wi-Fi定位由于无线电信号的高度敏感性（对环境动态、信道传播特性和硬件异构性敏感），一直是一个挑战性问题。传统的指纹识别和基于模型的方法通常需要大量的人力进行校准，并且在设备、信道或部署条件变化时会迅速性能下降。", "innovation": "提出了Locaris，一种用于室内定位的仅解码器大型语言模型（LLM），将每个接入点（AP）测量视为一个标记，从而可以直接摄取原始的Wi-Fi遥测数据而无需预处理。通过在其LLM上对不同的Wi-Fi数据集进行微调，Locaris学会了直接从原始信号到设备位置的轻量级和通用映射。实验研究显示，Locaris在各种类型的遥测数据中与最先进的方法相比表现相近或更优。这表明紧凑型LLM可以作为无校准的回归模型用于室内定位，提供在异构Wi-Fi部署中的可扩展和稳健的跨环境性能。较少的数据适应实验进一步展示了Locaris即使在使用少量校准点的情况下也能保持高精度，适用于以前未见过的设备和部署场景。", "conclusion": "我们的研究结果强调了Locaris在大规模部署中进行室内定位的实际可行性，尤其是对于校准工作不可行的问题，能够提供亚米级的精度，适应缺失的AP，并支持所有可用的遥测数据。"}
{"llm_update_time": "20251015", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.11955", "html_url": "https://arxiv.org/abs/2510.11955", "title": "Y形生成流", "title_en": "Y-shaped Generative Flows", "authors": "Arip Asadulaev,Semyon Semenov,Abduragim Shtanchaev,Eric Moulines,Fakhri Karray,Martin Takac", "background": "现代连续时间生成模型通常诱导V形传输：每个样本独立地沿从先验分布到数据的几乎直线轨迹移动，忽略了共有的结构。本文介绍了一种新的Y形生成流，它通过共享路径共同移动概率质量，然后分别移向目标特定的终点。这种方法基于新颖的速度驱动传输成本，该成本具有介于零和一之间的次线性指数，这种凹依赖关系奖励联合快速的质量移动。", "innovation": "论文提出了Y形生成流，这是一种新的生成流模型，它通过共享路径共同移动概率质量，然后分别移向目标特定的终点。该模型基于新颖的速度驱动传输成本，该成本具有介于零和一之间的次线性指数，这种凹依赖关系奖励联合快速的质量移动。此外，通过一种可扩展的神经ODE训练目标实现了这一理念。实验结果显示，Y流恢复了层次结构意识的结构，提高了分布度量，优于强大的基于流的基线，并且需要更少的积分步骤即可达到目标。", "conclusion": "Y流在合成、图像和生物数据集上的实验表明，它能够恢复层次结构感知的结构，提高分布度量，优于强流基线模型，并且通过减少积分步骤更加高效地达到目标。"}
{"llm_update_time": "20251015", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.11962", "html_url": "https://arxiv.org/abs/2510.11962", "title": "MosaicDiff: 无需训练的结构剪枝以反映预训练动力学的扩散模型加速", "title_en": "MosaicDiff: Training-free Structural Pruning for Diffusion Model Acceleration Reflecting Pretraining Dynamics", "authors": "Bowei Guo,Shengkun Tang,Cong Zeng,Zhiqiang Shen", "background": "扩散模型因其生成能力而闻名，但它们的预训练过程会表现出学习速度不同的阶段，这一现象在社区中的后训练加速努力中一直被忽略。本文探讨了这一现象，并提出了MosaicDiff框架，该框架通过轨迹感知结构剪枝将扩散预训练动力学与后训练采样加速对齐。", "innovation": "提出了一种新的框架MosaicDiff，该框架通过轨迹感知结构剪枝将扩散预训练的动力学与后训练采样加速对齐。该方法根据扩散预训练中不同阶段的学习速度，采用适应性的剪枝机制，允许中期快速学习阶段采取保守剪枝以保留关键模型特征，而早期和后期慢速学习阶段则采用更激进的剪枝策略。这种机制首次明确反映了扩散预训练的固有学习速度变化，从而协调模型内部的训练动力学与加速采样过程。", "conclusion": "大量的实验结果表明，MosaicDiff方法在不牺牲输出质量的情况下实现显著的采样加速，比以前的最先进的方法具有显著的优势。此外，该方法还为培训无损的扩散加速提供了新的视角。"}
{"llm_update_time": "20251015", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.11963", "html_url": "https://arxiv.org/abs/2510.11963", "title": "QLENS:朝着语言变换器的量子视角", "title_en": "QLENS: Towards A Quantum Perspective of Language Transformers", "authors": "Aditya Gupta,Kirandeep Kaur,Vinayak Gupta", "background": "目前的自然语言处理中，Transformer的理解方法能够在模型推理过程中识别出中间预测，但是这些方法更像是有限的诊断检查点，缺乏一个可以机械地解释每一层如何促进这些演变状态之间过渡的数学框架。这种可解释性缺口和跨学科视角的成功促使我们转向物理学，寻求一个描述Transformer的数学框架。我们观察到语言模型本质上是概率性的，这种属性在量子力学的基本假设中有所呼应。这一平行性启发我们将这一学科的洞见应用于自然语言处理领域。", "innovation": "我们提出了一种名为QLENS的新颖尝试，旨在发展一种基于物理的Transformer生成过程的视角。在QLENS框架下，通过将隐藏层中的潜激活转换为由模型输出单位引出的希尔伯特空间中的状态向量来研究Transformer。在推理过程中，这一状态通过单位算子和相应定义的哈密顿量逐渐演化。最终概率分布通过使用特定的测量算子应用贝恩规则得到。为了证明QLENS的潜力，我们通过调查一个玩具Transformer来探讨单个层对模型预测轨迹的影响。", "conclusion": "我们将这项工作视为利用跨学科洞见来更广泛地理解Transformer的基础。"}
{"llm_update_time": "20251015", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.11978", "html_url": "https://arxiv.org/abs/2510.11978", "title": "VLMs调优的学习动力学", "title_en": "Learning Dynamics of VLM Finetuning", "authors": "Jusheng Zhang,Kaitong Cai,Jing Yang,Keze Wang", "background": "偏好驱动的视觉-语言模型微调存在脆弱性: 简单的错误否定样本会注入无信息的梯度，从而扰乱训练。现有的方法忽视了训练动态的重要性，难以稳定地实现目标优化。", "innovation": "提出了Cooling-Weight DPO (CW-DPO) 方法，这是一种两阶段的调优方法。第一阶段使用带权重的监督微调与温和的负样本，避免过自信而不加特殊惩罚。第二阶段通过冷却权重来调节负样本的重要性权重，抑制来自容易或离分布样本的无信息梯度，同时保留来自难以处理的负样本的信息。通过在训练中使用$\boldsymbol{\triangle \text{log } p}$探针作为关键信号，实现早期停止、课程设计和故障诊断。CW-DPO方法在多个VLM任务中展现了更稳定的优化、更好的校准和更高的一对一对抗胜率，且收敛速度更快。同时，消融实验表明冷却机制是提升性能的关键驱动力，混合使用现场和数据集负样本也带来了补充益处。", "conclusion": "我们的研究表明，先平滑学习动态再冷却偏好是实现视觉-语言模型稳健对齐的简单且通用原则。"}
{"llm_update_time": "20251015", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.11984", "html_url": "https://arxiv.org/abs/2510.11984", "title": "由调控神经动力学掌握学习：统计力学视角", "title_en": "Learning by Steering the Neural Dynamics: A Statistical Mechanics Perspective", "authors": "Mattia Scardecchia", "background": "尽管基于梯度优化训练的深度神经网络取得了显著的成功，但它们与生物原型在根本上存在差异。这一差距引发了关于大自然如何以最小的能量成本实现稳健、样本高效的学习，同时避免了反向传播来解决责任指派问题的关键问题。本文旨在通过研究神经动力学如何支持局部、分布式学习并扩展到简单的机器学习基准，来弥合现代人工智能与计算神经科学之间的差距。", "innovation": "本文采用统计力学工具，识别随机不对称循环网络中稳健动力学吸引子出现的条件。推导了固定点数量与自耦合强度的封闭形式表达式，并揭示了一种相变现象。在这个研究基础上，提出了一个具有生物可行性的算法，用于任何二进制递归网络的监督学习。通过将输入映射到动力学的固定点，算法能够学习MNIST数据集的纠缠版本，利用深度来发展层次表示并增加异同关联能力，并适用于多个架构。此外，还强调了算法性能与揭示的相变之间强烈的联系，并提出了皮层启发的替代方案以促进自耦合的出现。", "conclusion": "文章提出了一个调控神经动力学的学习算法，通过动态映射输入到固定点实现监督学习，揭示了神经网络中固定点涌现的相变现象，并通过生物可行的算法设计为实际应用提供了新的思路。"}
{"llm_update_time": "20251015", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.11987", "html_url": "https://arxiv.org/abs/2510.11987", "title": "非线性离散化与牛顿法：回归目标的稳定点特征", "title_en": "Nonlinear discretizations and Newton's method: characterizing stationary points of regression objectives", "authors": "Conor Rowan", "background": "二阶方法正逐渐成为标准的一阶优化器（如梯度下降和ADAM）训练神经网络的有前途的替代方案。虽然在科学机器学习中利用曲率信息的优势得到了认同，但迄今研究的二阶方法仅为拟牛顿法，即目标函数的海森矩阵只是近似值。尽管可能预期使用精确的海森矩阵会带来好处，但研究发现依赖精确曲率信息会稳定地导致神经网络训练失败。这一现象不仅揭示了非线性离散化几何信息，还揭示了损失景观中临界点的分布，引发对传统观点的质疑，即损失景观充满了局部极小值。", "innovation": "本文揭示了仅依赖估值而非精确海森矩阵的拟牛顿法在神经网络训练中是有效的，这与广泛接受的观点形成了对比。研究还发现，应更加关注损失景观中临界点的分布，而不是简单地假设其中存在大量局部极小值。", "conclusion": "研究结果表明，依赖精确曲率信息会导致神经网络训练失败，揭示了非线性离散化的几何特点和损失景观中稳定点的分布。因此，应重新思考并更深入地理解损失景观的结构，而不仅仅是存在大量的局部极小值这一传统观点。"}
{"llm_update_time": "20251015", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.12060", "html_url": "https://arxiv.org/abs/2510.12060", "title": "您的VAR模型实际上是高效且可解释的生成分类器", "title_en": "Your VAR Model is Secretly an Efficient and Explainable Generative Classifier", "authors": "Yi-Chung Chen,David I. Inouye,Jing Gao", "background": "生成分类器利用条件生成模型进行分类，近年来显示出对分布转移具有较强鲁棒性的优点。然而，这一领域的进步主要依赖于计算成本高的扩散模型，极大地制约了其可扩展性。这一做法也限制了我们对生成分类器的理解。", "innovation": "提出了一种基于近期视觉自回归（VAR）建模进展的新型生成分类器，并进一步引入了可实现精度和推理速度优良权衡的适应性VAR分类器$^+$ (A-VARC$^+$)，并且证明了基于VAR的方法在性质上与扩散模型不同，其可计算似然性使得基于VAR的分类器能够通过逐项互信息实现视觉可解释性，并在类增量学习任务中表现出固有的灾难性遗忘抵抗性。", "conclusion": "本工作通过引入A-VARC$^+$，展示了基于VAR的方法在性能和可解释性方面的优越性，从而显著提高了实际应用中的可行性。同时，基于VAR的方法展示了与基于扩散的方法的固有差异。"}
{"llm_update_time": "20251015", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.12026", "html_url": "https://arxiv.org/abs/2510.12026", "title": "Mamba可以通过测试时特征学习在上下文中学习低维目标", "title_en": "Mamaba Can Learn Low-Dimensional Targets In-Context via Test-Time Feature Learning", "authors": "Junsoo Oh,Wei Huang,Taiji Suzuki", "background": "Mamba 是一个最近提出的线性时间序列模型，因其计算效率和强大的实验性能而受到关注。然而，对其内部机制的理论理解仍然有限。本文通过集中在由低维度非线性目标函数定义的任务上，对 Mamba 的在上下文学习（ICL）能力提供了理论分析。具体来说，研究了一个单指数模型 $y \thickapprox g_*(\boldsymbol{\beta}^T \boldsymbol{x})$ 的在上下文学习，这个模型仅依赖于单个相关方向 $\boldsymbol{\beta}$（称为特征）。研究表明，预训练通过梯度方法的 Mamba 能够通过在测试阶段学习特征，直接从上下文示例中提取相关方向，从而实现高效的 ICL。", "innovation": "本文证明了 Mamba 能够通过测试时特征学习在上下文中学习低维度目标。具体地，Mamba 预训练通过梯度方法能够高效地执行 ICL，通过从上下文示例中直接提取相关方向，提高了测试样本复杂度，改进了线性 Transformer 类似核方法的性能，同时与非线性 Transformer 相比接近信息论最优率。研究揭示了 Mamba 中非线性门控机制在特征提取中的关键作用，被认为是其高效且高性能能力的背后驱动力。", "conclusion": "本文通过理论分析证明，Mamba 通过测试时特征学习，能够在上下文中学习低维度目标。测试时样本复杂度的提高表明 Mamba 的计算效率和接近信息论最优率的表现，这主要得益于非线性门控机制在特征提取中的关键作用。"}
{"llm_update_time": "20251015", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.12070", "html_url": "https://arxiv.org/abs/2510.12070", "title": "MEASURE: 多尺度最小充分表示学习在睡眠分类领域适应性中的应用", "title_en": "MEASURE: Multi-scale Minimal Sufficient Representation Learning for Domain Generalization in Sleep Staging", "authors": "Sangmin Jo,Jee Seok Yoon,Wootaek Jeong,Kwanseok Oh,Heung-Il Suk", "background": "基于深度学习的自动睡眠阶段划分在性能上取得了显著进步，在睡眠障碍诊断中发挥着重要作用。然而，当前的模型在面对未见过的受试者时，由于生理信号的变异，常常难以泛化，导致在未知领域场景中的性能下降。为了解决这一问题，领域泛化的研究方法最近被提出以确保模型在训练过程中能够适应未见过的领域。对比学习已经被证明能够通过在不同领域中对相同类别的样本进行对齐来学习领域不变特征。尽管如此，许多现有方法仍不足以提取充分的领域不变表示，因为它们未能明确处理样本间未共享信息中的领域特性。", "innovation": "本文提出了一种新颖的MEASURE框架，从而有效减少了领域相关的信息并保留了关键的时域和频域特征，以提高睡眠阶段分类的准确性。相较于现有的研究方法，这种方法更侧重于减少领域相关属性，从而避免了高阶特征过度拟合的问题，更好地发挥了不同特征层次的丰富时间和频率信息。", "conclusion": "在对公开可用的睡眠阶段划分基准数据集SleepEDF-20和MASS进行的详尽实验中，所提出的方法始终优于现有的前沿方法。我们的代码可以在：this https URL 找到。"}
{"llm_update_time": "20251015", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.12071", "html_url": "https://arxiv.org/abs/2510.12071", "title": "影响动力学与阶段式数据属性", "title_en": "Influence Dynamics and Stagewise Data Attribution", "authors": "Jin Hwa Lee,Matthew Smith,Maxwell Adam,Jesse Hoogland", "background": "当前的训练数据属性(TDA)方法将一个样本对另一个样本的影响视为静态的，但神经网络的训练在一个个阶段进行，表现出变化的影响模式。在本研究中，作者引入了一个基于单一学习理论的阶段式数据属性框架，认为影响可能会非单调地变化，包括符号翻转和在发展阶段转折处出现尖峰。作者首先在玩具模型中通过分析和经验验证这些预测，展示了模型逐渐学习语义层次时影响动态变化的具体映射。最后，在语言模型中展示了这些现象，证明了标记级影响的变化与已知的发展阶段相对应。", "innovation": "作者提出了一种基于单一学习理论的阶段式数据属性框架，该框架能够捕获影响随时间变化的复杂性，包括符号翻转和在发展阶段转折处出现尖峰。研究人员通过玩具模型的验证以及在大规模语言模型中的应用，展示了这一方法的有效性。", "conclusion": "研究证明了影响并非静态存在的，而是随着模型的学习逐渐形成语义层次结构的过程中的动态变化。这种变化不仅包括影响的非单调性，还包括符号翻转和在发展阶段转折处出现尖峰。这些发现不仅在理论上延伸了我们对神经网络训练过程的理解，也在实际应用中提供了更精确的模型解释途径。"}
{"llm_update_time": "20251015", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.12085", "html_url": "https://arxiv.org/abs/2510.12085", "title": "GraphShaper: 了解图结构几何多样性的几何感知对齐方法以提高文本标注图的迁移学习效果", "title_en": "GraphShaper: Geometry-aware Alignment for Improving Transfer Learning in Text-Attributed Graphs", "authors": "Heng Zhang,Tianyi Zhang,Yuling Shi,Xiaodong Gu,Yaomin Shen,Haochen You,Zijian Zhang,Yilei Yuan,Jin Huang", "background": "图基础模型代表了一个学习跨不同图领域可转移表示的变革性范式。最近的方法利用大规模语言模型通过对比学习将图和文本模态统一封装到共享表示空间中。但是，系统评估发现，在不同的拓扑模式交汇的结构性边界处，性能下降超过20个百分点。这种问题源自一个主要限制：当前方法假设所有图结构都可以被编码到单一欧几里得空间中。实际情况是，树结构需要双曲几何来保持分层分支，而循环模式需要球面几何来保全闭合特性。在结构性边界处，节点受到相互冲突的几何约束，统一编码空间无法解决。这提出了一个关键挑战：是否能够设计对齐框架以尊重图结构的内在几何多样性和差异？", "innovation": "我们提出了一个名为GraphShaper的几何感知框架，通过多几何独立化来增强图编码。该方法使用针对不同几何空间设计的专业网络，动态计算融合权重，根据局部结构特性自适应融合几何属性，从而在对齐文本嵌入之前保留结构完整性。广泛的实验显示，GraphShaper在零样本设置下，实现了引文网络9.47%的准确率提升，以及社交网络7.63%的提升。", "conclusion": "GraphShaper通过尊重图结构的内在几何多样性，解决了当前方法在结构性边界处的性能下降问题。该框架的应用显著提高了文本标注图的迁移学习效果。"}
{"llm_update_time": "20251015", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.12094", "html_url": "https://arxiv.org/abs/2510.12094", "title": "H4G: 在超曲空间中解开忠实推理以实现零样本图学习", "title_en": "H4G: Unlocking Faithful Inference for Zero-Shot Graph Learning in Hyperbolic Space", "authors": "Heng Zhang,Tianyi Zhang,Zijun Liu,Yuling Shi,Yaomin Shen,Haochen You,Haichuan Hu,Lubin Gan,Jin Huang", "background": "文本归属图在多个领域中广泛应用，为基于图与文本对齐的零样本学习提供了丰富的机会。然而，现有的方法在处理需要精细模式识别的任务时，特别是在异质图上，表现不佳。目前的方法存在过度概括问题，即在超曲空间中过度扩展球体半径，将多尺度结构信息压缩为统一的高层次抽象，这种抽象会导致关键局部模式的信息丢失，从而影响准确预测。", "innovation": "提出了一种名为H4G（Hyperbolic Graph）的框架，该框架通过使用可学习的块对角缩放矩阵和莫比乌斯矩阵乘法系统地减少嵌入半径，恢复对精细模式的访问同时保持全局接收到的能力，且计算开销小。", "conclusion": "实验结果表明，H4G 在异质图上实现了最先进的零样本性能，比现有方法提高了 12.8%，而在同质图上的改善为 8.4%，证明了通过减少半径可以实现准确多尺度表示，从而促进零样本图学习的发展。"}
{"llm_update_time": "20251015", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.12128", "html_url": "https://arxiv.org/abs/2510.12128", "title": "nuGPR: GPU-Accelerated Gaussian Process Regression with Iterative Algorithms and Low-Rank Approximations", "title_en": "nuGPR: GPU-Accelerated Gaussian Process Regression with Iterative Algorithms and Low-Rank Approximations", "authors": "Ziqi Zhao,Vivek Sarin", "background": "Gaussian Process Regression (GPR)是一种监督机器学习模型，具有内在的不确定性测量。然而，GPR的训练计算成本较高，这是其广泛应用的一大挑战。", "innovation": "本文提出了一种新的框架nuGPR，通过结合数值线性代数的思想（如预条件共轭梯度方法）、输入数据的聚类以及低秩逼近技术，显著降低了计算时间和空间复杂性。此外，通过使用数值梯度优化GPR模型的超参数，进一步减少了训练成本，避免了反向传播的需求。最后，利用CUDA Toolkit在NVIDIA GPU上高效并行化训练过程。与现有最先进的GPU加速GPR实现相比，nuGPR将总训练时间最多减少2倍，峰值内存消耗最多减少12倍，特别是在合成数据集和真实世界数据集上的表现更为显著。", "conclusion": "通过这些改进，nuGPR成功解决了GPR训练中的高计算成本问题，同时在训练时间和内存消耗上取得了显著的提升。"}
{"llm_update_time": "20251015", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.12096", "html_url": "https://arxiv.org/abs/2510.12096", "title": "重思动态稀疏训练在可扩展深度强化学习中的角色", "title_en": "Rethinking the Role of Dynamic Sparse Training for Scalable Deep Reinforcement Learning", "authors": "Guozheng Ma,Lu Li,Zilin Wang,Haoyu Wang,Shengchao Hu,Leszek Rutkowski,Dacheng Tao", "background": "神经网络的规模扩展在机器学习领域推动了突破性的进展，但在深度强化学习(DRL)中，这一范式却常常失效。在DRL中，更大的模型往往会由于独特的优化病态，如可塑性损失等问题而性能下降。尽管最近的研究表明，动态调整网络拓扑结构可以在训练中减轻这些问题，但现有研究存在三个关键的局限性：（1）在所有模块上应用统一的动态训练策略，而没有考虑到编码器、评论者和行为者遵循不同的学习范式；（2）仅在基础架构上进行评估，而没有明确动态训练和架构改进之间的相对重要性和相互作用；（3）缺乏不同动态方法之间的系统比较，包括稀疏到稀疏、密集到稀疏和稀疏到密集的方法。", "innovation": "通过跨模块和架构的全面调查，揭示了动态稀疏训练策略为各个模块提供了特定的益处，补充了通过架构改进所建立的主要可扩展性基础。最终，提炼出模块特定训练（MST）框架，该框架进一步利用了架构改进的优势，并在各类不同的RL算法中表现出显著的可扩展性收益，同时无需进行算法修改。", "conclusion": "动态稀疏训练策略能够在保持架构改进的原有优势的基础上，为各个模块提供特定的益处，最终提出的模块特定训练（MST）框架实际上提升了可扩展性，适用于多种不同的RL算法，且不需要修改算法，为可扩展、高效的深度强化学习提供了一种增强的方法。"}
{"llm_update_time": "20251015", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.12140", "html_url": "https://arxiv.org/abs/2510.12140", "title": "图少样本学习通过自适应频谱专家和跨集合分布校准", "title_en": "Graph Few-Shot Learning via Adaptive Spectrum Experts and Cross-Set Distribution Calibration", "authors": "Yonghao Liu,Yajun Wang,Chunli Guo,Wei Pang,Ximing Li,Fausto Giunchiglia,Xiaoyue Feng,Renchu Guan", "background": "图少样本学习近年来因其能够通过有限标记节点快速适应新任务的能力而引起了越来越多的关注。尽管现有图少样本学习方法取得了显著进展，但仍存在几个关键限制。目前大多数方法依赖于预定义且统一的图滤波器（如低通或高通滤波器）来全局增强或抑制节点频率信号。这些固定的频谱操作未能考虑到实际图内在的局部拓扑结构异质性。此外，这些方法常假设支撑集和支持集来自相同的分布，但在少样本条件下，支撑集中的有限标记数据可能不足以捕获查询集的复杂分布，导致泛化不足。", "innovation": "本文提出了GRACE（Graph few-shot leaRning框架），整合了自适应频谱专家和跨集合分布校准技术。理论上，该方法通过适应局部结构变化和跨集合分布校准来增强模型的泛化能力。实验上，GRACE在广泛实验设置中始终优于现有的最佳基线。", "conclusion": "GRACE框架在这种情况下表现出了优越性，它通过自适应频谱专家和跨集合分布校准改进了模型的泛化能力。实验结果证实了该方法的有效性，并超过了现有的最先进技术。"}
{"llm_update_time": "20251015", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.12144", "html_url": "https://arxiv.org/abs/2510.12144", "title": "在有效解隐生存数据方面的预算限制主动学习", "title_en": "Budget-constrained Active Learning to Effectively De-censor Survival Data", "authors": "Ali Parsaee,Bei Jiang,Zachary Friggstad,Russell Greiner", "background": "标准的监督学习尝试从带标签的数据集中学习模型。给出一小部分带标签的样本，以及一个池中的未标记样本，预算学习者可以使用其预算选择标记部分样本，通过学习这些样本来生成模型。本文的研究背景是在生存数据的背景下进行预算学习，这些数据包含了右删失样本，即某些样本的时间范围仅能确认一个下限。", "innovation": "该研究提供了一种在生存数据中应用最先进的预算学习算法的方法，并探讨了其局限性。该方法为标准活跃学习方法BatchBALD提供了具有相同渐近行为的界和时间复杂性。实证分析表明，在几个生存任务上，该模型的性能优于其他潜在方法。", "conclusion": "本文通过在生存数据中应用最优预算学习算法，提供了一个基于理论结果和实验分析的有效解隐生存数据的方法。"}
{"llm_update_time": "20251015", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.12111", "html_url": "https://arxiv.org/abs/2510.12111", "title": "Chimera：超越序列的状态空间模型", "title_en": "Chimera: State Space Models Beyond Sequences", "authors": "Aakash Lahoti,Tanya Marwah,Ratish Puduppully,Albert Gu", "background": "Transformer 基础的深度学习方法已经成为多种数据，如序列、图像和图建模的标准方法。这些方法依赖于自注意力机制，将数据视为无关顺序的元素集合，但忽略了数据的邻域结构或网络拓扑，并需要引入诱导偏置（如序列和图像中的位置嵌入，或图中的随机游走）来融合拓扑结构。然而，设计这些特定任务的偏置需要大量工作，并且可能会引入妨碍泛化的副作用。", "innovation": "我们提出了 Chimera，这是一种统一的模型，可以以一种严格的方式直接融合数据拓扑，从而去除特定领域的偏置需求。核心思想是状态空间模型，因其自然不需要位置嵌入，可以被推广以捕捉任何图拓扑。实验表明，Chimera 在语言、视觉和图域均表现出强大性能，相比 BERT 在 GLUE 上高出 0.7 分，相比 ViT 在 ImageNet-1k 上高出 2.6%，并且在长范围图基准测试中优于所有基线。我们还提出算法优化来提高 Chimera 的效率：对于有向无环图，Chimera 可以实现为线性时间递归；对于一般图，简单的数学松弛可以在不使用特定领域启发式的情况下实现类似 Transformer 的平方复杂度。", "conclusion": "这些结果验证了 Chimera 的核心贡献，并支持了数据拓扑作为跨模态的强大诱导偏置的概念。"}
{"llm_update_time": "20251015", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.12157", "html_url": "https://arxiv.org/abs/2510.12157", "title": "自我验证反思有助于具CoT推理的Transformer模型", "title_en": "Self-Verifying Reflection Helps Transformers with CoT Reasoning", "authors": "Zhongwei Yu,Wannian Xia,Xue Yan,Bo Xu,Haifeng Zhang,Yali Du,Jun Wang", "background": "先进的大型语言模型（LLMs）在推理链中经常进行自我验证以确保当前解决方案的正确性，并探索替代方案。然而，尽管进行自我验证，这些模型仍然检测到有限的错误，因此，自我验证如何体现在实际改进中的原理仍不明确。本文研究了这一问题。", "innovation": "本文提出了一种最小化的推理框架，即不使用自然语言的基本自我验证反思框架，以支持小型Transformer（仅有少量参数）的基本自我验证反思，从而确保分析清晰和降低全面实验的成本。理论证明，只要有适当的验证错误边界，自我验证反思可以保证改进。实验结果显示，尽管仅有数百万参数的小型Transformer在训练和自我验证执行中受益于自我验证，仍能达到令人惊叹的LLM级别的整数乘法和数独性能。此外，与大型语言模型类似的结果表明，强化学习提高了内部分布性能并激励小型Transformer进行频繁自我验证，但主要优化了表浅的统计模式，未能有效减少验证错误。", "conclusion": "综合生成Transformer与辨别验证二者各有利弊，本研究表明，在不需要大规模扩展和使用自然语言的情况下，这种结合自然有利于链式推理思维方式的发展。"}
{"llm_update_time": "20251015", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.12143", "html_url": "https://arxiv.org/abs/2510.12143", "title": "Fairness-Constrained Optimization Attack in Federated Learning", "title_en": "Fairness-Constrained Optimization Attack in Federated Learning", "authors": "Harsh Kasyap,Minghong Fang,Zhuqing Liu,Carsten Maple,Somanath Tripathy", "background": "联邦学习（FL）是一种保护隐私的机器学习技术，它使跨不同人口统计数据的参与者能够协作。FL允许模型共享，同时限制数据的移动。由于FL使参与者对其训练数据拥有独立性，因此它容易受到污染攻击。这种协作也可能在参与者之间传播偏见，即使无意中也可能如此，这通常是因为数据分布不同或数据中已存在的历史偏见。", "innovation": "本文提出了一种故意公平性攻击，其中客户端故意发送了一个带有偏见的模型，在训练中增加了公平性损失，即使是在数据分布同质的情况下。公平性损失是通过解决优化问题计算得出的，涉及到公平性指标如人口平等性和相等机会的公平性。这种攻击隐蔽且难以检测，因为它即使在增加偏见的同时仍能保持全局准确性。", "conclusion": "我们对我们的攻击进行了评估，该攻击对抗了FL系统中的最先进的拜占庭鲁棒和公平性意识聚合方案，用于不同的数据集和各种场景。实证结果表明，即使FL系统中只有一个恶意客户端，我们的攻击也能提高偏见高达90%，证明了攻击的有效性。"}
{"llm_update_time": "20251015", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.12209", "html_url": "https://arxiv.org/abs/2510.12209", "title": "重新审视含有噪声标签的元学习：重权动态与理论保证", "title_en": "Revisiting Meta-Learning with Noisy Labels: Reweighting Dynamics and Theoretical Guarantees", "authors": "Yiming Zhang,Chester Holtz,Gal Mishne,Alex Cloninger", "background": "在存在噪声标签的学习场景中，过度参数化的网络倾向于记忆化错误的监督信息。基于元学习的样本加权方法通过使用一小部分干净的子集来引导训练，从而减轻这一问题。然而，这种加权方法的行为及其训练动态缺乏理论上的理解。", "innovation": "本文提供了在噪声标签条件下对于元重权方法的严格的理论分析，并展示了其训练轨迹经历三个阶段：(i) 对于与干净子集一致的示例加强，对于冲突的示例减弱；(ii) 逐步将噪声样本权重推向零，直到干净子集的损失趋于稳定；(iii) 在经过过滤阶段后，噪声过滤变得对扰动敏感。机制上，这是训练信号与干净子集信号的相似性加权耦合以及干净子集的训练损失收缩。在噪声子集损失足够小时，耦合项消失，导致元重权方法在区分能力上减弱。文章还提出了一种轻量级的替代方案，结合了均值中心化、行列移动和标签信号调制，从而提供了更加稳定的表现，同时避免了昂贵的双层优化。", "conclusion": "该方法在合成的和实际的噪声标签基准上的表现均优于其他坚实的重权/选择基线。"}
{"llm_update_time": "20251015", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.12214", "html_url": "https://arxiv.org/abs/2510.12214", "title": "DE3S: 双增强软稀疏形状学习在医学早期时间序列分类中的应用", "title_en": "DE3S: Dual-Enhanced Soft-Sparse-Shape Learning for Medical Early Time-Series Classification", "authors": "Tao Xie,Zexi Tan,Haoyi Xiao,Binbin Sun,Yiqun Zhang", "background": "在医疗应用中，早期时间序列分类（ETSC）对于如重症监护室（ICU）中的败血症预测等紧急情况至关重要。由于延迟预测导致大量患者的死亡，ETSC能够显著提高ICU资源利用效率和医疗精准度，但也面临着准确性和及时性的冲突目标，现有的方法往往为一方牺牲另一方，难以捕捉早期阶段微弱且模糊的模式，这主要是由于初始信号较弱和类别不平衡问题。", "innovation": "该论文提出了双重增强软稀疏形状学习（DE3S），引入了一种新型的双重增强软形状学习框架，通过三个方面进行创新解决上述挑战：（1）综合双重增强策略结合传统的时域增强与基于注意力的全局时域增强以增强健壮表示学习；（2）基于注意力分数的软稀疏形状机制动态保留区分性模式，同时将不重要的形状聚类为具有代表性的令牌；（3）双重路径专家网络（MoE）和Inception模块融合架构，其中MoE进行形状本地学习，以及Inception模块捕获形状间的多尺度全局特征。", "conclusion": "该框架采用加权交叉熵损失来处理类别不平衡，并在受试者一致数据集上表现出高度稳健性。在六个实际医疗数据集上的广泛实验显示了最先进的表现，消融研究证实了各个组件的有效性。"}
{"llm_update_time": "20251015", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.12233", "html_url": "https://arxiv.org/abs/2510.12233", "title": "揭示图LLMs的脆弱性：基于TAG的可解读多维度对抗攻击", "title_en": "Unveiling the Vulnerability of Graph-LLMs: An Interpretable Multi-Dimensional Adversarial Attack on TAGs", "authors": "Bowen Fan,Zhilin Guo,Xunkai Li,Yihan Zhou,Bing Zhou,Zhenjun Li,Rong-Hua Li,Guoren Wang", "background": "图神经网络（GNNs）已经成为处理图结构数据的关键框架，广泛应用于社会网络分析和分子化学等领域。通过整合大型语言模型（LLMs），带有文本属性的图（TAGs）提升了节点表示的丰富语义，显著增强了基于图的学习能力。然而，这种复杂的协同作用引入了关键的漏洞，因为图LLMs在结构拓扑和文本属性方面都容易受到对抗攻击。尽管已经为每个方面设计了专门的攻击方法，但目前还没有将它们统一进一个综合框架中。", "innovation": "本文提出了一种新型的人类中心对抗攻击框架——Interpretable Multi-Dimensional Graph Attack（IMDGA），旨在协调结构和文本特征的多层面扰动。IMDGA利用三个紧密整合的模块，制造出既具有可解释性又高效的攻击，以更深入地理解图LLMs的脆弱性。通过严格的理论分析和全面的实证评估，IMDGA展示了比现有方法更优秀的可解释性、攻击效果、隐蔽性和鲁棒性。", "conclusion": "通过揭示TAG表示学习中的关键弱点，本文在图LLMs的语义维度上发现了一个之前未被充分探索的脆弱性维度，为提高其鲁棒性提供了有价值的见解。我们的代码和资源可在以下链接查看：this https URL."}
{"llm_update_time": "20251015", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.12245", "html_url": "https://arxiv.org/abs/2510.12245", "title": "MoRA: 在线分子感知低秩适应框架用于基于LLM的多模态分子助手", "title_en": "MoRA: On-the-fly Molecule-aware Low-Rank Adaptation Framework for LLM-based Multi-Modal Molecular Assistant", "authors": "Tao Yin,Xiaohong Zhang,Jiacheng Zhang,Li Huang,Zhibin Zhang,Yuansong Zeng,Jin Xie,Meng Yan", "background": "在药物发现中，有效将分子图结构与大型语言模型（LLMs）集成是一个关键挑战。现有方法通常通过微调LLM或同时添加静态适配器来处理这些结构，但这些方法有两个主要限制：（1）在所有分子输入之间优化共享参数空间，限制模型捕捉实例特定结构特征的能力；（2）为分子任务微调LLM可能导致灾难性遗忘，削弱其通用推理能力。", "innovation": "本文提出了一种实例特定的参数空间对齐方法，即Molecule-aware Low-Rank Adaptation（MoRA），在每个分子输入上即时进行。MoRA通过为每个输入分子图生成一组独特的低秩适应权重，动态地将这些权重注入冻结的LLM中，使得模型能够根据每个分子输入的结构进行自适应推理，同时保持LLM的核心知识。实验证明，在分子任务如化学反应预测和分子描述等方面，MoRA的实例特定动态适应优于静态适应基线，例如在反应预测精确匹配上提高14.1%，在量子性质预测误差上降低22%。", "conclusion": "广泛的实验表明，对于关键的分子任务（如化学反应预测和分子描述），MoRA的实例特定动态适应优于静态适应基线，如在反应预测精确匹配上提高了14.1%，在量子性质预测误差上降低了22%。代码可在以下链接获得：这个 https URL。"}
{"llm_update_time": "20251015", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.12253", "html_url": "https://arxiv.org/abs/2510.12253", "title": "扩散模型在强化学习中的应用：基础、分类与进展", "title_en": "Diffusion Models for Reinforcement Learning: Foundations, Taxonomy, and Development", "authors": "Changfu Xu,Jianxiong Guo,Yuzhu Liang,Haiyang Huang,Haodong Zou,Xi Zheng,Shui Yu,Xiaowen Chu,Jiannong Cao,Tian Wang", "background": "扩散模型(DMs)作为生成模型的主要类别，为强化学习(RL)提供了多模态表示、稳定的训练和轨迹级别规划等关键优势。本文综述了基于扩散的RL的最新成果，通过介绍RL的基本概念及其挑战，探讨了如何将DMs集成到RL框架中以解决该领域的关键挑战。文章详细讨论了从单代理到多代理领域的发展历程，构建了函数导向和方法导向的双重分类框架，综述了DM-RL综合模型与实施的发展，并指出了方法上的开放研究问题，明确了未来的研究方向，并指出适用于RL的DMs相关的材料和资源可在GitHub上获得。", "innovation": "本文提出了一种基于扩散模型的RL分类体系，建立了函数导向和方法导向的双重分类框架，同时详细讨论了单代理到多代理多个领域的扩散模型在RL中的逐步应用，为DM-RL的综合提供了多种框架，并强调了方法学上的开放问题和未来研究方向，还提供了持续更新的GitHub资源。", "conclusion": "本文综述了基于扩散模型的RL的最新进展，明确了其研究分类与发展方向，并提出了持续更新的资源库，为未来研究提供了实用的参考。"}
{"llm_update_time": "20251015", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.12249", "html_url": "https://arxiv.org/abs/2510.12249", "title": "优化的正则化参数在博弈学习中的应用", "title_en": "Optimal Regularization for Performative Learning", "authors": "Edwige Cyffers,Alireza Mirrokni,Marco Mondelli", "background": "在博弈学习中，数据分布会因部署的模型而变化，比如，战略用户会调整其特征以“玩转”系统。这种动态远比传统监督学习复杂。因此，在优化模型时，需要不仅考虑当前的数据分布，还要考虑到模型未来可能引导数据分布的方向变换，而具体变化的性质尚不可知。", "innovation": "探索了正则化如何帮助应对博弈效应，特别是在高维岭回归环境中研究了其影响。研究发现，虽然博弈效应会增加总体设置中的测试风险，但在特征数量超过样本数量的过度参数化情况下，这些效应能产生积极影响。研究还表明，最优正则化应与博弈效应的整体强度成比例，可以据此提前设定正则化参数。", "conclusion": "通过在合成数据集和真实世界数据集上的实证评估，证明了最优正则化参数选择的效果。"}
{"llm_update_time": "20251015", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.12266", "html_url": "https://arxiv.org/abs/2510.12266", "title": "HiLoRA: 不需训练的适应性分层LoRA路由，用于领域泛化", "title_en": "HiLoRA: Adaptive Hierarchical LoRA Routing for Training-Free Domain Generalization", "authors": "Ziyi Han,Huanyu Wang,Zeyu Zhang,Xiangxiang Dai,Xutong Liu,John C.S. Lui", "background": "Low-Rank Adaptation (LoRA) 是一种广泛使用的技术，用于使大型语言模型（LLMs）适应新领域，得益于其模块化设计和在HuggingFace等平台的广泛可用性。这种可用性激发了重用现有LoRA进行领域泛化的努力。现有方法通常依赖于明确的任务标签或额外的训练，这在部署中不切实际。而且，它们通常激活固定的LoRA模块数量，导致参数冗余或不足，从而影响性能。", "innovation": "我们提出了一个无需训练的框架HiLoRA，它对LoRA池执行适应性分层路由。利用LoRA的结构特性，HiLoRA定义了秩一组件（ROCs），其中每个秩参数被视为独立单元。对于给定的输入序列，HiLoRA首先自适应地选择一个LoRA子集，并确定其ROC分配基于序列级的高斯似然值。在tokens级别，它进一步通过激活最有信息性的ROC来细化路由。此外，我们提供了理论保证，HiLoRA能够以高概率选择最相关的LoRA。", "conclusion": "广泛实验表明，HiLoRA在领域泛化方面取得了巨大改进，在准确率上比最新基准提高了多达55%，同时保持了类似的推理吞吐量。"}
{"llm_update_time": "20251015", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.12220", "html_url": "https://arxiv.org/abs/2510.12220", "title": "分层Koopman扩散：快速生成与可解释的扩散轨迹", "title_en": "Hierarchical Koopman Diffusion: Fast Generation with Interpretable Diffusion Trajectory", "authors": "Hanru Bai,Weiyang Ding,Difan Zou", "background": "扩散模型在高保真图像生成方面取得了显著成果，但由于其固有的去噪迭代过程，导致采样速度较慢。虽然最近的一步方法通过学习直接噪声到图像的映射来加快推理速度，但也牺牲了扩散动力学固有的可解释性和细微控制能力，这是扩散模型enable应用程序如可编辑生成的关键优势。为了同时解决这一矛盾并保持这些优点，我们引入了分层Koopman扩散（Hierarchical Koopman Diffusion），该方法实现了一步采样和可解释的生成轨迹。该方法基于Koopman算子理论，在潜在空间中提升非线性的扩散动力学，由全局线性算子控制进化，从而产生轨迹的闭式解。这一建模不仅消除了迭代采样，还提供了对中间状态的完全访问，从而在生成过程中可以进行手动干预。通过设计一个分层架构来捕捉图像的多尺度性质，该架构通过特定尺度的Koopman子空间分解生成动力学，系统地捕捉从粗到细的细节。我们实验证明，分层Koopman扩散不仅实现了竞争性的一步生成性能，还通过频谱分析提供了一种解释和操控生成过程的原理性机制。该框架桥梁了一步采样和解释性之间的差距，在生成建模中为人像合成提供了新的途径。", "innovation": "分层Koopman扩散是一种新颖的框架，它实现了一步采样和可解释的生成轨迹。该方法基于Koopman算子理论，在潜在空间中提升了非线性扩散动力学，通过全局线性算子的演化提供了闭式轨迹解。它还设计了一个分层架构，根据不同尺度的Koopman子空间分解生成动力学，系统地捕捉从粗到细的细节。这种方法不仅解决了迭代采样的问题，还提供了对中间状态的完全访问，便于在生成过程中进行手动干预。同时，通过频谱分析提供了一种解释和操控生成过程的原理性机制。", "conclusion": "分层Koopman扩散框架为扩散模型中的快速采样和解释性之间的差距提供了解决方案，为生成建模中的可解释图像合成铺平了道路。"}
{"llm_update_time": "20251015", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.12254", "html_url": "https://arxiv.org/abs/2510.12254", "title": "FedMMKT：在多模态联邦学习中增强服务器端文本到图像模型和客户端任务模型", "title_en": "FedMMKT:Co-Enhancing a Server Text-to-Image Model and Client Task Models in Multi-Modal Federated Learning", "authors": "Ningxin He,Yang Liu,Wei Sun,Xiaozhou Ye,Ye Ouyang,Tiegang Gao,Zehui Zhang", "background": "文本到图像(T2I)模型在多种应用中展示了其灵活性。然而，将T2I模型适应于特定任务时受限于可用任务专用数据的缺乏，这通常受到隐私保护的限制。另一方面，现代移动系统和物联网基础设施中的丰富多模态数据提供了巨大的利用潜力。", "innovation": "本文提出了Federated Multi-modal Knowledge Transfer (FedMMKT)框架，该框架可以在不泄露数据隐私的前提下，通过分散的多模态数据同时增强服务器端的T2I模型和客户端的任务专用模型。", "conclusion": "通过引入FedMMKT框架，可以在保护数据隐私的同时，利用丰富的多模态数据来提高T2I模型的性能及其在特定任务上的应用效果，为T2I模型的广泛应用提供了新的解决方案和可能性。"}
{"llm_update_time": "20251015", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.12293", "html_url": "https://arxiv.org/abs/2510.12293", "title": "GFF-PIELM for High-Frequency PDEs", "title_en": "General Fourier Feature Physics-Informed Extreme Learning Machine (GFF-PIELM) for High-Frequency PDEs", "authors": "Fei Ren,Sifan Wang,Pei-Zhi Zhuang,Hai-Sui Yu,He Yang", "background": "传统基于物理的极学习机（PIELM）在解决包含高频率和变频率行为的偏微分方程（PDEs）时面临诸多挑战。", "innovation": "提出了一种新的通用傅里叶特征物理知情极学习机（GFF-PIELM），通过将变式的傅里叶特征映射（FFM）作为一个基于傅里叶的激活函数集成到极学习机（ELM）中，并且为隐藏神经元分配了一组频率系数，同时开发了一种创新的初始方法来确定这些超参数，从而有效处理高频率问题。", "conclusion": "GFF-PIELM不仅保留了PIELM框架的高精度、高效性和简单性，同时还继承了FFMs处理高频率问题的能力。通过五个案例研究中的十个数值例子验证了GFF-PIELM方法的有效性和可行性，相较于传统的PIELM，GFF-PIELM在提高预测精度的同时不增加训练时间和架构复杂性。我们的结果表明，PIELM可以扩展以高精度解决高频率和变频率的PDEs，而且我们的初始化策略还有可能启发其他物理知情机器学习（PIML）框架的进步。"}
{"llm_update_time": "20251015", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.12312", "html_url": "https://arxiv.org/abs/2510.12312", "title": "深SPI：通过世界模型实现安全策略改进", "title_en": "Deep SPI: Safe Policy Improvement via World Models", "authors": "Florent Delgrange,Raphael Avalos,Willem Röpke", "background": "Safe Policy Improvement (SPI) 提供了理论上的策略更新控制，但现有的保证主要针对离线的表格强化学习（RL）。本文研究了在结合世界模型和表示学习的一般在线环境中，SPI 的应用。", "innovation": "研究开发了一个理论框架，表明将策略更新限制在一个当前策略的明确定义的邻域可以确保单调改进和收敛。此外，进一步提出了一个称为 DeepSPI 的原则性在线策略算法，它结合了局部转换和奖励损失以及正则化的策略更新。", "conclusion": "在 ALE-57 基准上，DeepSPI 能够达到或超过包括 PPO 和 DeepMDPs 在内的强大基准，同时保留了理论保证。"}
{"llm_update_time": "20251015", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.12273", "html_url": "https://arxiv.org/abs/2510.12273", "title": "Multi-Action Self-Improvement for Neural Combinatorial Optimization", "title_en": "Multi-Action Self-Improvement for Neural Combinatorial Optimization", "authors": "Laurin Luttmann,Lin Xie", "background": "在神经组合优化（NCO）领域，自改善作为一种先进范式出现，模型通过生成和模仿高质量解决方案来迭代地改进其策略。尽管现有方法在实验性能上表现出色，但它们存在一些关键局限性：训练计算成本高昂，因为策略更新需要为每个实例采样大量候选解决方案以提取单个专家轨迹。更根本的是，这些方法未能利用多个代理协调的组合问题结构，比如最小最大路径中的车辆或调度中的机器。通过在单动作轨迹上进行监督，它们未能利用代理置换对称性，不同的动作序列会产生相同的解决方案，阻碍了泛化和学习协调行为的能力。作者指出，现有的方法在处理这种对称性方面存在不足。", "innovation": "为了应对这些挑战，作者扩展了自改善机制，使其能够处理联合多代理动作。模型架构在每个决策步骤中联合预测完整的代理任务分配。为了利用对称性，作者采用了集合预测损失，该损失在给定状态下为模型提供多个专家分配作为监督信号。这种方法提高了样本效率，并增强了模型学习协调行为的能力。此外，通过并行生成多代理动作，它极大地加速了自改善循环中的解决方案生成阶段。实验结果表明，这种方法在多个组合问题上显示出稳定增强的最终解决方案质量，并减少了生成延迟，相比标准的自改善方法表现出色。", "conclusion": "研究表明，通过扩展自改善机制到多代理联合动作，可以提高神经组合优化的效率和效果。这种方法不仅提高了模型的学习能力和样本效率，还显著缩短了解决方案生成的时间，实验证明该方法在多个组合优化问题上的性能优越。"}
{"llm_update_time": "20251015", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.12334", "html_url": "https://arxiv.org/abs/2510.12334", "title": "Actor-Critic with Evolving Reward的有限时间收敛分析", "title_en": "Finite-time Convergence Analysis of Actor-Critic with Evolving Reward", "authors": "Rui Hu,Yu Chen,Longbo Huang", "background": "许多流行的实用强化学习(RL)算法采用了演化的奖励函数，例如通过奖励重塑、熵正则化或经验曲线学习等技术，但它们的理论基础仍然不成熟。本文首次对在马尔可夫采样下存在演化奖励函数情况下的单时标Actor-Critic算法的有限时间收敛性进行了分析。", "innovation": "本文的主要创新在于，提出了在具有变化奖励参数情况下的单时标Actor-Critic算法的有限时间收敛性分析。作者推导出了非退化的演员和评论家的误差估计，并表明在奖励变化足够缓慢时，可达到$O(1/\text{sqrt}T)$的收敛率，这一率与静态奖励下最佳已知速率相同。此外，论文还引入了在马尔可夫采样下分布不匹配的新分析方法，改善了静态奖励下最佳已知速率的因子为$\text{log}^2T$。", "conclusion": "本研究为许多流行优化技术提供了理论基础，尤其是通过基于梯度的规则更新奖励时。这一结果不仅提高了我们对Actor-Critic算法的理解，还推进了强化学习领域的理论发展。"}
{"llm_update_time": "20251015", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.12383", "html_url": "https://arxiv.org/abs/2510.12383", "title": "跨模态表格和图像中的错误检测", "title_en": "Towards Cross-Modal Error Detection with Tables and Images", "authors": "Olga Ovcharenko,Sebastian Schelter", "background": "大规模组织确保数据质量仍然是一项持续的挑战。尽管最近有所进展，但保持数据的准确性和一致性仍然非常复杂，尤其是在处理多种数据模态（如图像、表格和文本）时。传统的错误检测和纠正方法倾向于专注于单一模态，通常是在表单中，但往往会遗漏跨模态错误，而这些错误在电子商务和医疗保健等领域是常见的。", "innovation": "本文采取了初步步骤，通过对几种方法进行基准测试，以表格数据为重点，进行跨模态错误检测。评估在四个数据集和五种基线方法上进行，其中，Cleanlab作为一种标签错误检测框架，DataScope作为一种数据估值方法，与强大的AutoML框架结合使用时表现最佳，达到了最高的F1分数。研究结果表明，当前的方法在面对重尾型的真实世界数据时仍有限制，需要进一步的研究。", "conclusion": "现有方法在应对重尾型真实世界数据时的局限性促使我们进一步探索这一领域，特别是在跨模态数据中实现更有效的错误检测方法。"}
{"llm_update_time": "20251015", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.12328", "html_url": "https://arxiv.org/abs/2510.12328", "title": "利用物理导向的图注意力网络通过遥相关进行长范围泰国极端降雨预测", "title_en": "Leveraging Teleconnections with Physics-Informed Graph Attention Networks for Long-Range Extreme Rainfall Forecasting in Thailand", "authors": "Kiattikun Chobtham,Kanoksri Sarinnapakorn,Kritanai Torsri,Prattana Deeprasertkul,Jirawan Kamma", "background": "准确预测降雨，特别是极端事件，是气候学和地球系统研究中的一个重大挑战。本文致力于改进泰国各地水文站的降雨预测，采用了一种新颖的物理导向的图神经网络（GNNs），结合了极端值分析技术，以捕捉复杂的空间和时间模式，并提高对遥相关性的解释能力。通过预处理可能影响区域降雨的气候指数，本文提出了一种图注意力网络与长短期记忆（Attention-LSTM）结合的方法，该方法使用初始边特征来结合简单的地形雨物理公式，进行注意力机制应用。随后使用LSTM层处理嵌入。为了预测极端降雨，使用了一种新的时空季节适应广义帕累托分布（GPD）方法，进行阈值超过峰值（POT）映射，以克服传统机器学习模型的局限性。实验结果表明，该方法在大多数地区，包括极易发生极端事件的区域，均优于现有的基准模型，并在许多情况下与最先进的技术竞争。相比运营预报系统SEAS5，本文实际应用提高了极端事件的预测准确性，有助于长期水资源管理决策。", "innovation": "本文创新性地将物理导向的图注意力网络与极端值分析技术相结合，提出了一种新颖的方法来改进泰国各地的降雨预测。该方法利用图结构来表示水文站，并结合了遥相关性以提供解释能力。使用时空适应广义帕累托分布方法进行阈值超过峰值映射，克服了传统机器学习模型的局限性，提高了对极端降雨事件的预测准确性和实用性。", "conclusion": "实验结果显示，本文提出的方法在大多数地区都优于现有的基准模型，并在许多情况下与最先进的技术竞争。尽管与运营预报系统SEAS5相比，该方法在某些方面仍可进一步改进，但其在提高极端事件预测准确性方面的优势使其成为改进长期水资源管理的有力工具。"}
{"llm_update_time": "20251015", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.12402", "html_url": "https://arxiv.org/abs/2510.12402", "title": "谨慎的权重衰减", "title_en": "Cautious Weight Decay", "authors": "Lizhang Chen,Jonathan Li,Kaizhao Liang,Baiyu Su,Cong Xie,Nuo Wang Pierse,Chen Liang,Ni Lao,Qiang Liu", "background": "标准的权重衰减方法在优化过程中会对损失函数进行显式的或隐式的影响，这可能会导致模型优化结果偏离原始优化目标。本文介绍了一种新的优化器无关的改动——谨慎的权重衰减（Cautious Weight Decay, CWD），它只对优化器更新方向一致的参数坐标应用权重衰减，保留了原始损失不变。", "innovation": "CWD 在达到稳态流形时表现出滑模行为，允许模型在优化未修改目标函数的局部帕累托最优稳态点时进行搜索。这种改变可以“即插即用”到如 AdamW, Lion, Muon 等优化器上，无需新添加超参数或额外调优。作者实验结果在语言模型预训练和 ImageNet 分类任务上展示了 CWD 的有效性，它能够在大规模模型（百万到十亿参数）上持续改善最终损失和准确率。", "conclusion": "CWT 是一种单行修改，适用于多种优化器，并且能带来在语言模型预训练和 ImageNet 分类等任务上的性能提升。"}
{"llm_update_time": "20251015", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.12401", "html_url": "https://arxiv.org/abs/2510.12401", "title": "增强大规模异构图上图神经网络预训练", "title_en": "Enhanced Pre-training of Graph Neural Networks for Million-Scale Heterogeneous Graphs", "authors": "Shengyin Sun,Chen Ma,Jiehao Chen", "background": "近年来，图神经网络（GNNs）促进了图数据挖掘的发展。然而，训练GNNs需要充足的特定标记数据，这既昂贵又有时不可用。近期研究提出了以自监督方式预训练GNNs，在有限的标记数据条件下将预训练的GNNs应用于下游任务。尽管如此，大多数现有方法仅针对同构图设计，而现实世界中的大部分图是异构的，并且未考虑语义不匹配（原始数据和包含更多可转移语义信息的理想数据之间的差异）。", "innovation": "本文提出了一个有效的框架，用于在大规模异构图上进行GNN预训练。首先设计了结构感知预训练任务，旨在捕捉异构图中的结构属性。然后设计了语义感知预训练任务以处理不匹配问题。具体来说，构建了一个由语义邻居组成的扰动子空间，以帮助处理语义不匹配。语义邻居使模型更多地关注语义空间中的通用知识，这反过来又帮助模型学习具有更好可转移性的知识。最后，通过在真实世界大规模异构图上的广泛实验，展示了所提出方法在先进基线方法上的优越性。", "conclusion": "本文提出了一个有效的框架，在大规模异构图上进行GNN的预训练。通过结构感知和语义感知的预训练任务，解决了数据中不可用和语义不匹配的问题。经过在实际大规模异构图上的广泛实验，证明了该方法优于现有的先进基线方法。"}
{"llm_update_time": "20251015", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.12405", "html_url": "https://arxiv.org/abs/2510.12405", "title": "无机晶体生成建模中的连续独特性和新颖性度量", "title_en": "Continuous Uniqueness and Novelty Metrics for Generative Modeling of Inorganic Crystals", "authors": "Masahiro Negishi,Hyunsoo Park,Kinga O. Mastej,Aron Walsh", "background": "为了应对气候变化等紧迫的科学挑战，正在开发越来越复杂的生成人工智能模型，这些模型可以高效地采样潜在功能材料的庞大化学空间。这些模型可以快速地配对新的化学成分和晶体结构。它们通常使用唯一性和新颖性指标进行评估，这些指标依赖于选定的晶体距离函数。然而，最常用的距离函数存在四个局限性：无法量化化合物之间的相似度；不能区分组分差异和结构差异；缺乏对原子坐标移动的利普希茨连续性；结果得到的独特性度量对于生成样本的排列不具不变性。", "innovation": "本文提出使用两种连续距离函数来评估独特性和新颖性，理论上来讲可以克服上述局限性。实验表明，这些距离函数揭示了传统距离函数所忽略的见解，提供了评估和比较生成模型的基础，更加可靠。", "conclusion": "通过使用两种连续距离函数，这些研究提供了评估生成模型的独特性和新颖性更可靠的方法。这种评估方法能够揭示传统方法可能遗漏的信息，为无机晶体生成建模提供更理论依据和实践指导。"}
{"llm_update_time": "20251015", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.12447", "html_url": "https://arxiv.org/abs/2510.12447", "title": "基于贝叶斯优化的动态定价与学习", "title_en": "Bayesian Optimization for Dynamic Pricing and Learning", "authors": "Anush Anand,Pranav Agrawal,Tejas Bodas", "background": "动态定价是指通过调整产品销售价格以最大化企业收入，根据市场供需进行灵活调整。现有文献通常将动态定价分为两类场景：无限库存场景和有限库存场景。无论哪一种场景下，最大的挑战都是需求函数未知，必须通过数据进行学习。传统的做法往往假设需求函数的具体参数形式，利用强化学习（RL）来识别接近最优的定价策略，但在实际应用场景中，这类假设可能不成立，从而限制了方法的适用性。", "innovation": "本文提出了一种基于高斯过程（GP）的非参数化方法，避免了严格的建模假设。通过将需求函数视为价格的黑盒函数，并基于贝叶斯优化（BO）开发定价算法，能够以较少的样本高效地优化未知函数。为此类无限和有限库存场景分别设计了基于BO的算法，并提供相应场景的遗憾保证，量化了这些方法的学习效率。实验表明，在复杂且不确定的环境中，基于BO的方法在收入上优于多项最新的RL算法，在假设较少且更具鲁棒性方面表现出色。", "conclusion": "基于BO的方法不仅在无限和有限库存设置下都表现出色，还通过减少假设和提高鲁棒性提高了动态定价的效率。贝叶斯优化成为一种强大的且实用的工具，适用于复杂和不确定环境下的动态定价。"}
{"llm_update_time": "20251015", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.12453", "html_url": "https://arxiv.org/abs/2510.12453", "title": "时间相关视频桥匹配", "title_en": "Time-Correlated Video Bridge Matching", "authors": "Viacheslav Vasilev,Arseny Ivanov,Nikita Gushchin,Maria Kovaleva,Alexander Korotin", "background": "扩散模型在由噪声生成数据任务中表现出色，能够将高斯分布映射到复杂的数据分布。然而，它们在处理复杂分布之间的平移任务时表现不佳，这限制了它们在数据到数据任务中的有效性。尽管桥匹配（BM）模型解决了这一问题，通过找到了不同数据分布之间的平移，但它们尚未应用于经过时间相关数据序列的任务，这对于需要保持时间连贯性的视频生成和处理任务来说是一个重要的局限性。", "innovation": "提出了时间相关视频桥匹配（TCVBM）框架，该框架将BM模型扩展到视频域的时间相关数据序列中，通过显式建模扩散桥中的序列间依赖性，直接将时间相关性纳入采样过程，从而提升了视频相关任务（帧插值、图像到视频生成和视频超分辨率）的质量和重建准确性。", "conclusion": "TCVBM在多个定量指标上优于现有的经典桥匹配方法和扩散模型，证明其生成质量和重建精度得到了显著提升。"}
{"llm_update_time": "20251015", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.12451", "html_url": "https://arxiv.org/abs/2510.12451", "title": "函数中心视角下的平坦和尖锐极小值", "title_en": "A Function Centric Perspective On Flat and Sharp Minima", "authors": "Israel Mason-Williams,Gabryel Mason-Williams,Helen Yannakoudakis", "background": "广泛认为平坦极小值与深度神经网络的泛化能力提升相关。然而，近期研究发现这一关系并不简单，理论和实证上都出现了与之相悖的例子。研究认为精确度（sharpness）应被理解为依赖于函数的一种特性，而不应将其视为差的泛化能力的可靠指标。从单目标优化到现代图像分类任务，研究表明在正则化情况下（如SAM、权重衰减或数据增强），尖锐的极小值通常会与更好的泛化、校准、鲁棒性和功能一致性相关联。未正则化的线索单元往往收敛于更平坦的极小值，但在所有安全指标上表现较差。", "innovation": "本文提出了一种函数中心的观点，认为精确度更应被视为函数依赖的特性而非差的泛化能力的指标。通过广泛的实证研究，指出在正则化条件下尖锐的极小值可以与更好的泛化、校准、鲁棒性和功能一致性相关联，强调function复杂度而非平坦性决定了解决方案的几何形状，揭示了更尖锐的极小值可能反映更具适当性的归纳偏置（尤其是在正则化条件下）。", "conclusion": "研究结果表明，函数复杂度而非仅平坦度决定了损失景观的几何形状，尖锐的极小值可能反映更适当的归纳偏置（特别是在正则化条件下），需要重新审视以函数为中心的损失景观几何观点。"}
{"llm_update_time": "20251015", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.12489", "html_url": "https://arxiv.org/abs/2510.12489", "title": "CrossAD：基于跨尺度关联和跨窗口建模的时间序列异常检测", "title_en": "CrossAD: Time Series Anomaly Detection with Cross-scale Associations and Cross-window Modeling", "authors": "Beibu Li,Qichao Shentu,Yang Shu,Hui Zhang,Ming Li,Ning Jin,Bin Yang,Chenjuan Guo", "background": "时间序列异常检测在许多实际应用中起着关键作用。多尺度建模能揭示单一尺度下可能未显现的潜在异常模式，但现有方法往往独立建模多尺度信息或依赖简单的特征融合策略，忽略了异常期间跨尺度关联的变化，且大多数方法基于固定滑动窗口进行多尺度建模，限制了其捕捉全面上下文信息的能力。", "innovation": "提出了一种名为CrossAD的新框架，综合考虑跨尺度关联和跨窗口建模。该框架通过跨尺度重构，从更粗糙的时间序列重建细粒度序列，捕捉跨尺度关联，并设计查询库，融入全局多尺度上下文，克服了固定窗口大小的限制。", "conclusion": "在多个真实数据集上进行的广泛实验，使用九个评估指标验证了CrossAD的有效性，显示出在异常检测方面的前沿性能。"}
{"llm_update_time": "20251015", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.12497", "html_url": "https://arxiv.org/abs/2510.12497", "title": "通过噪声感知指引缓解去噪生成模型中的噪声偏移", "title_en": "Mitigating the Noise Shift for Denoising Generative Models via Noise Awareness Guidance", "authors": "Jincheng Zhong,Boyuan Jiang,Xin Tao,Pengfei Wan,Kun Gai,Mingsheng Long", "background": "现有的去噪生成模型依赖于求解离散化的逆时间SDE或ODE。然而，这类模型中存在一个长期被忽视但普遍存在的问题：预设的噪声水平与采样过程中实际编码的中间状态噪声水平不匹配。这种不匹配被称为噪声偏移。通过实证分析发现，噪声偏移在现代扩散模型中普遍存在，并且表现出系统性的偏差，导致生成质量不佳。", "innovation": "提出了噪声感知指引（NAG）方法，这是一种简单而有效的方法，能够明确引导采样轨迹与预定义的噪声时间表保持一致。进一步引入了一种无需外部分类器的噪声条件和无条件引导的噪声感知指引变体。", "conclusion": "广泛实验，包括ImageNet生成和各种监督微调任务，表明NAG能够一致地缓解噪声偏移，显著提高主流扩散模型的生成质量。"}
{"llm_update_time": "20251015", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.12503", "html_url": "https://arxiv.org/abs/2510.12503", "title": "不同指定场景下可微因果发现算法的鲁棒性", "title_en": "The Robustness of Differentiable Causal Discovery in Misspecified Scenarios", "authors": "Huiyang Yi,Yanyan He,Duxin Chen,Mingyu Kang,He Wang,Wenwu Yu", "background": "因果发现旨在从目标数据中学习变量之间的因果关系，这是机器学习中的一个基础任务。然而，现有的因果发现算法通常依赖无法验证的因果假设，在实际数据中难以满足，从而限制了因果发现在实际应用场景中的广泛应用。", "innovation": "本文广泛评测了在八种模型假设违例情况下各种主流因果发现算法的实际性能，特别关注可微因果发现方法在结构汉明距离和结构干预距离度量下的鲁棒性。此外，还提供了可微因果发现方法性能的理论解释，并希望建立一个合理的因果发现评估标准，进一步促进其在实际场景中的应用。", "conclusion": "本文旨在全面评测近期可微因果发现方法在模型假设违例情况下的性能，并提供一个合理的因果发现评估标准，同时进一步促进其在实际场景中的应用。"}
{"llm_update_time": "20251015", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.12343", "html_url": "https://arxiv.org/abs/2510.12343", "title": "旅行商问题导向的标记重排序提高同态加密语言模型的稳定性", "title_en": "Traveling Salesman-Based Token Ordering Improves Stability in Homomorphically Encrypted Language Models", "authors": "Donghwan Rho,Sieun Seo,Hyewon Sung,Chohong Min,Ernest K. Ryu", "background": "随着用户越来越多地使用包含私人信息的大型语言模型（LLMs），安全和加密通信变得必不可少。同态加密（HE）通过直接在加密数据上执行计算提供了一个基本的解决方案。尽管先前的工作已经探讨了在HE下运行LLMs的各个方面，但文本生成，特别是下一个标记预测，这一难题受到了较少的关注，并且仍然是实现实际加密交互中的关键障碍。", "innovation": "本文提出了一种基于旅行商问题（TSP）的标记重排序策略来解决加密文本生成的困难，并且通过后处理步骤进一步减少近似误差。理论分析和实验结果表明，该方法可以防止崩溃，提高生成文本的一致性，并在整个过程中保持数据隐私。", "conclusion": "总体而言，本文的贡献推动了实用和隐私保护的语言模型推理的可能性。"}
{"llm_update_time": "20251015", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.12523", "html_url": "https://arxiv.org/abs/2510.12523", "title": "具有最小聚合收益约束的多臂 bandit 问题", "title_en": "Multi-Armed Bandits with Minimum Aggregated Revenue Constraints", "authors": "Ahmed Ben Yahmed,Hafedh El Ferchichi,Marc Abeille,Vianney Perchet", "background": "研究了一个具有上下文信息的多臂 bandit 问题，目标是确保每个臂在各种上下文中获得最小的累计奖励同时同时最大化总的累计奖励。这种框架涵盖了公平收益分配至关重要且上下文变化不可避免的广泛实际应用场景。", "innovation": "设计和分析了两种算法，一种乐观地优先考虑性能，另一种悲观地确保约束满足。对于每种算法，推导出了在问题层面依赖于遗憾和约束违反的上界。此外，建立了下界，表明结果中时间段依赖性在一般情况下是最优的，并揭示了先前工作依赖于自由探索原则的基本限制。", "conclusion": "这些成果揭示了在具有最小聚合收益约束的多臂 bandit 问题中的基本限制，同时也提供了更优的算法以平衡性能与约束满足，确保了广泛的实际应用场景中更好的平衡效果。"}
{"llm_update_time": "20251015", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.12541", "html_url": "https://arxiv.org/abs/2510.12541", "title": "基于AI的心电图信号实时预处理方法评估", "title_en": "Evaluation of Real-Time Preprocessing Methods in AI-Based ECG Signal Analysis", "authors": "Jasmin Freudenberg,Kai Hahn,Christian Weber,Madjid Fathi", "background": "便携式心电图（ECG）系统的普及以及对符合隐私保护、节电高效的心电图实时分析需求日益增长，促使需要新的信号处理方法，特别是在数据采集点。在这种背景下，边缘计算领域日益重要，因为它不仅能减少延迟时间，还能够提升数据安全性。", "innovation": "FACE项目旨在开发将边缘计算与云计算优势相结合的创新机器学习解决方案，用于分析长期心电图数据。在该论文中，分析了心电图信号的各种预处理步骤在项目中的应用性，尤其注重选择在边缘区域适用的方法，基于能量效率、处理能力和实时性能等标准。", "conclusion": "通过分析不同的预处理方法，选择出最适合该项目需求的方法，从而实现高效、实时的心电图信号分析。"}
{"llm_update_time": "20251015", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.12595", "html_url": "https://arxiv.org/abs/2510.12595", "title": "合作学习研究在实践中无法满足跨孤岛联邦学习的需求", "title_en": "Research in Collaborative Learning Does Not Serve Cross-Silo Federated Learning in Practice", "authors": "Kevin Kuo,Chhavi Yadav,Virginia Smith", "background": "跨孤岛联邦学习是一种能够在不直接共享私有数据的情况下促进组织间机器学习模型开发的有前途的方法。尽管由于GDPR和HIPAA等数据保护法规激发了组织的兴趣，但在实践中跨孤岛联邦学习的应用仍然有限。现有的研究尚未充分捕捉到跨孤岛联邦学习在实践中面临的真正挑战，这些问题与设备联邦学习等其他形式的联邦学习有所不同。", "innovation": "本研究通过访谈不同利益相关者，发现了跨孤岛联邦学习面临的一系列独特挑战，包括对于模型性能的担忧以及参与组织之间的激励和信任问题。这些发现填补了现有研究的空白，揭示了跨孤岛联邦学习与其他形式的联邦学习之间的差异。", "conclusion": "未来研究应该围绕如何克服这些挑战展开，从而促进跨孤岛联邦学习的应用和发展。"}
{"llm_update_time": "20251015", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.12494", "html_url": "https://arxiv.org/abs/2510.12494", "title": "PubSub-VFL: 在异构环境中通过发布者/订阅者架构向高效两方拆分学习", "title_en": "PubSub-VFL: Towards Efficient Two-Party Split Learning in Heterogeneous Environments via Publisher/Subscriber Architecture", "authors": "Yi Liu,Yang Liu,Leqian Zheng,Jue Hong,Junjie Shi,Qingyou Yang,Ye Wu,Cong Wang", "background": "随着数字经济的迅速发展，组织间的数据协作已经成为成熟的商业模式，推动了各行业的增长。然而，隐私问题使得直接的数据共享变得不可行。为此，Two-Party Split Learning（即垂直联邦学习VFL）作为一种安全的协作学习解决方案应运而生。尽管VFL具有诸多优势，但其依然面临着低计算资源利用率和训练效率低的问题。其同步设计增加了训练延迟，而参与者的资源和数据异构性进一步阻碍了高效的计算。", "innovation": "为了解决上述挑战，我们提出了PubSub-VFL，这是一种基于发布者/订阅者架构的新型VFL范式，优化了双方高效协同学习并提高了计算效率。PubSub-VFL通过利用发布者/订阅者架构的解耦能力和参数服务器架构中的数据并行性，设计了一种分层异步机制，从而减少了训练延迟并提高了系统效率。此外，为了缓解由于资源和数据异构性带来的训练不平衡问题，我们基于参与者的系统配置，建立了一个优化问题，并能够选择最优的超参数，同时保持隐私保护。我们通过理论分析表明，PubSub-VFL实现稳定的收敛，并且与差分隐私等安全协议兼容。通过在五个基准数据集上的案例研究，验证其有效性，结果显示PubSub-VFL不仅比最先进的基线模型加速训练2-7倍，而不牺牲准确性，还实现了高达91.07%的计算资源利用率。", "conclusion": "PubSub-VFL不仅通过分层异步机制解决了计算效率低的问题，还通过优化问题解决了训练不平衡和资源利用问题，从而实现了高效的两方拆分学习，特别是在异构环境下的应用。"}
{"llm_update_time": "20251015", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.12615", "html_url": "https://arxiv.org/abs/2510.12615", "title": "反思知识蒸馏：一种基于数据的正则化器，带有负的不对称收益", "title_en": "Rethinking Knowledge Distillation: A Data Dependent Regulariser With a Negative Asymmetric Payoff", "authors": "Israel Mason-Williams,Gabryel Mason-Williams,Helen Yannakoudakis", "background": "知识蒸馏通常被认为是压缩机制，但其功能影响尚未完全理解。这项工作量化了知识蒸馏的压缩容量及其背后的知识转移，从功能角度分离了压缩和架构简化，从而改善了对知识蒸馏的理解。", "innovation": "本研究通过假设测试、控制变量和随机控制蒸馏，理解不同数据模态下的知识转移机制。我们探索了多种蒸馏变体，并分析了不同模型规模下的蒸馏扩展法则。研究发现，尽管在一些模态和架构中存在显著的知识转移，但其程度低于预期。此外，我们还识别出一种在显著知识转移情况下的一致且严重的负面知识不对称转移，引起了知识蒸馏应用的安全问题。", "conclusion": "本研究发现知识蒸馏更多地扮演着一种依赖数据的正则化器的角色，而不是一种压缩机制，并且这种正则化器具有负的不对称收益。"}
{"llm_update_time": "20251015", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.12640", "html_url": "https://arxiv.org/abs/2510.12640", "title": "针对加速科学发现的时序点过程基座模型", "title_en": "On Foundation Models for Temporal Point Processes to Accelerate Scientific Discovery", "authors": "David Berghaus,Patrick Seifner,Kostadin Cvejoski,Ramses J. Sanchez", "background": "许多科学领域，从医学到地震学，依赖于对时间序列事件的分析来理解复杂系统。传统上，机器学习模型必须针对每个新数据集从头开始构建和训练，这是一个既慢又昂贵的过程。", "innovation": "我们引入了一种新的方法：单个强大模型，能够在上下文中学习事件数据的内在模式。该“基座模型”已经在数百万模拟事件序列上进行了训练，教会它关于事件如何发展的通用理解。因此，该模型可以即时分析新的科学数据，而无需重新训练，只需查看数据集中的少数几个例子即可。该模型还可以快速调整以获得更高的准确性。这种方法使复杂的事件分析更具可访问性，并加速了科学发现的步伐。", "conclusion": "这一方法使复杂的事件分析更加可访问，并加速了科学发现的速度。"}
{"llm_update_time": "20251015", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.12624", "html_url": "https://arxiv.org/abs/2510.12624", "title": "Learning-To-Measure: In-context Active Feature Acquisition", "title_en": "Learning-To-Measure: In-context Active Feature Acquisition", "authors": "Yuta Kobayashi,Zilin Jing,Jiayu Yao,Hongseok Namkoong,Shalmali Joshi", "background": "AFA（主动特征获取）是一个序列决策问题，目标是通过自适应选择要获取的特征来提高模型在测试实例上的性能。现有的AFA方法通常依赖于回顾性数据，这些数据在某些特征上系统性缺失，并且任务特定的标签有限。大多数先前的工作专注于单个预定义任务的特征获取，限制了其扩展性。因此，研究提出了一个元AFA（meta-AFA）问题，目的是学习跨不同任务的获取策略。", "innovation": "提出了Learning-to-Measure (L2M)，它包括：可靠地量化未见任务的不确定性，以及一个基于不确定性引导的贪婪特征获取代理，该代理最大化条件互信息。L2M使用序列建模或自回归预训练方法，为具有任意缺失的任意任务提供可靠的不确定性量化。L2M直接在具有回顾性缺失的数据集上工作，可以在具体任务中执行元AFA任务，无需为每个任务重新训练。总体而言，在合成和真实世界的表格基准测试中，L2M在稀缺标签和高缺失性下匹配或超越了特定任务的基线。", "conclusion": "L2M为解决AFA在多个任务上的扩展问题提供了一个有效的解决方案。它不仅能够可靠地量化不确定性，还能够在实际存在特征缺失的情况下有效地提升模型性能。这种方法无需针对每个具体任务进行重新训练，提高了算法的效率和适用性。"}
{"llm_update_time": "20251015", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.12618", "html_url": "https://arxiv.org/abs/2510.12618", "title": "关于使用基础推理模型实现快速粗粒化和方程发现", "title_en": "Towards Fast Coarse-graining and Equation Discovery with Foundation Inference Models", "authors": "Manuel Hinz,Maximilian Mauel,Patrick Seifner,David Berghaus,Kostadin Cvejoski,Ramses J. Sanchez", "background": "高维动态过程通常由数量较小的有效变量在低维流形上演化描述。识别这些潜在动态需要解决两个交织的问题：发现合适的粗粒化变量并同时拟合其动态方程。大多数机器学习方法通过联合训练自动编码器和保证动态一致性模型来解决这些问题。本文背景是在这一领域介绍了一种新的方法，即通过利用最近提出的基础推理模型（FIMs），独立解决这两个问题来降低成本和提高效率.", "innovation": "本文提出了一种通过利用基础推理模型（FIMs）来解耦动态识别和方程拟合过程的新方法。具体来说，使用已预训练的FIMs通过静默模式来估计动力系统的无穷小生成器（例如随机微分方程的漂移和扩散），并冻结其权重来实现动态推理的加速，仅训练编码器-解码器映射，从而定义了一个简单且与模拟一致的损失函数来稳定表示学习。该方法通过在合成视频数据中嵌入随机双阱系统来证明其潜在价值，展示了一种快速且可复用的粗粒化管道的可行性.", "conclusion": "本文通过解耦动态识别和方程拟合过程，利用基础推理模型（FIMs）来实现对高维动态过程的快速粗粒化和方程发现。该方法通过预训练的FIMs实现动态推理的加速，简化了粗粒化管道并提高了其稳定性。"}
{"llm_update_time": "20251015", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.12633", "html_url": "https://arxiv.org/abs/2510.12633", "title": "Laminar：一种可扩展的异步强化学习后处理训练框架", "title_en": "Laminar: A Scalable Asynchronous RL Post-Training Framework", "authors": "Guangming Sheng,Yuxuan Tong,Borui Wan,Wang Zhang,Chaobo Jia,Xibin Wu,Yuqi Wu,Xiang Li,Chi Zhang,Yanghua Peng,Haibin Lin,Xin Liu,Chuan Wu", "background": "大规模语言模型（LLMs）的强化学习（RL）后处理训练正在扩展到大型集群并长时间运行以提高模型的推断性能。然而，现有的RL框架存在可扩展性限制，因为RL轨迹生成极端的长尾偏差导致严重的GPU利用率低下。当前的异步RL系统试图缓解这一问题，但它们依赖于演员和所有随机游走之间的全局权重同步，这会创建一个僵化的模型更新日程，与RL训练中高度偏斜和演变的轨迹生成延迟分布不相适应，拖累训练效率。", "innovation": "我们的主要洞察是，高效的扩展需要通过轨迹级异步性打破这种步调一致，从而独立地生成和消费每个轨迹。我们提出Laminar，一种基于完全解耦架构的可扩展和鲁棒的RL后处理系统。首先，我们用一个代理工人层取代全局更新，作为分布式参数服务。这使RL能够异步进行细粒度的权重同步，允许随机游走在任何时候拉取最新的权重而不阻塞演员的训练循环。其次，动态打包机制将长尾轨迹合并到少数几个专用游走中，最大化生成速度。完全解耦的设计还隔离了失败，确保长时间运行任务的鲁棒性。", "conclusion": "我们在1024-GPU集群上的评估表明，Laminar相比最先进的系统实现了高达5.48倍的训练吞吐量加速，同时缩短了模型收敛时间。"}
{"llm_update_time": "20251015", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.12650", "html_url": "https://arxiv.org/abs/2510.12650", "title": "朝向情境中学习ODEs的基础推断模型", "title_en": "Towards Foundation Inference Models that Learn ODEs In-Context", "authors": "Maximilian Mauel,Manuel Hinz,Patrick Seifner,David Berghaus,Ramses J. Sanchez", "background": "普通微分方程（ODEs）描述了随连续时间演化的确定性动力系统。准确地从稀疏或含噪数据中推断出系统作为ODEs的数据驱动模型，仍然是自然科学领域中的一个核心挑战问题。", "innovation": "作者引入了FIM-ODE（基础推断模型），这是一种预训练的神经模型，能够在不依赖训练数据的情况下（零样本），从稀疏且含噪的观测数据中估计ODEs。该模型通过利用灵活的神经操作符在包含噪声的数据上实现了稳健的ODE推断。实验证明FIM-ODE能够提供与当前神经网络中最先进的方法相媲美的准确估计，并且在估计向量场的结构上进行了质量对比分析。", "conclusion": "该研究通过构建FIM-ODE，证明了在仅有少量或含噪声数据的情况下，能够准确推断ODEs的能力，并通过与最先进的神经网络方法进行对比实验，验证了FIM-ODE的有效性。"}
{"llm_update_time": "20251015", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.12659", "html_url": "https://arxiv.org/abs/2510.12659", "title": "SG-XDEAT: Sparsity-Guided Cross-Dimensional and Cross-Encoding Attention with Target-Aware Conditioning in Tabular Learning", "title_en": "SG-XDEAT: Sparsity-Guided Cross-Dimensional and Cross-Encoding Attention with Target-Aware Conditioning in Tabular Learning", "authors": "Chih-Chuan Cheng,Yi-Ju Tseng", "background": "现有表格数据监督学习方法通常处理单一流程或缺乏对目标感知的双向交互，导致声噪数据对模型性能影响较大。因此，研究一种能够同时建模原始值流和目标感知流的方法，以及动态抑制低效信息的机制，对于提高表格数据学习模型的鲁棒性至关重要。", "innovation": "提出了一种新颖的框架SG-XDEAT，其特点是采用了双重编码器，将每个输入特征分解为主要值流和目标条件化流。该框架还包括跨维度自注意力、跨编码自注意力以及自适应稀疏自注意力机制，能捕捉特征内部依赖性、实现双向交互并动态过滤噪声。", "conclusion": "在多个公开基准数据集上的实验结果表明，SG-XDEAT框架在鲁棒性方面优于强基线模型，证实了结合建模原始值流和目标感知流以及动态过滤噪声的有效性。"}
{"llm_update_time": "20251015", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.12638", "html_url": "https://arxiv.org/abs/2510.12638", "title": "专家还是非专家？评估离线强化学习数据的质量", "title_en": "Expert or not? assessing data quality in offline reinforcement learning", "authors": "Arip Asadulaev,Fakhri Karray,Martin Takac", "background": "离线强化学习（RL）仅从静态数据集学习，而不需要进一步与环境互动。在实践中，这样的数据集质量参差不齐，经常混杂专家、次优甚至随机轨迹。算法的选择因此依赖于数据的保真度。行为克隆在高质量数据中足够，而对于混合或低质量的数据，则通常需要使用离线RL方法来通过轨迹拼接有用的行为。但在实际应用中，由于数据的来源和技能组成未知，很难预先评估数据的质量。这篇论文关注的问题是在不训练代理的情况下，估计离线数据集的质量。我们研究了一个从简单累积奖励到学习值基估计的一系列指标，并引入了贝尔曼 Wasserstein 距离（BWD），这是一种带有价值感知的最优传输分数，衡量数据集的行为策略与随机基准策略之间的差异。BWD 无需环境交互或完整的策略优化即可计算得出。", "innovation": "纸张提出了不通过训练代理来进行离线数据集质量估计的方法。研究了一系列评估指标，包括简单的累积奖励和新的贝尔曼 Wasserstein 距离（BWD），这种值感知的最优传输指标可以量化数据集的行为策略与随机基准策略之间的差异。BWD 计算基于行为批评家和状态条件下的 OT 形式化，无需环境交互或完整的策略优化。在 D4RL MuJoCo 任务上，BWD 与多个离线 RL 算法的综合评估分数高度相关，因此能够有效地预测特定数据集上标准代理的表现情况。此外，将 BWD 作为正则化项集成到策略优化中，可以显式地促使学习的策略远离随机行为，从而提高收益。这一结果表明，策略优化的价值感知分布信号如 BWD 是实际工具，可以帮助处理离线 RL 数据集和策略优化。", "conclusion": "通过使用 BWD，可以有效预测标准代理在特定数据集上的表现，并且在策略优化时将其作为正则化项可以提高收益。这一方法表明了值感知的分布信号（如 BWD）对于管理离线 RL 数据集和策略优化的实际应用性。"}
{"llm_update_time": "20251015", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.12666", "html_url": "https://arxiv.org/abs/2510.12666", "title": "结构化稀疏性和权重自适应剪枝以提高内存和计算效率的 Whisper 模型", "title_en": "Structured Sparsity and Weight-adaptive Pruning for Memory and Compute efficient Whisper models", "authors": "Prasenjit K Mudi,Anshi Sachan,Dahlia Devapriya,Sheetal Kalyani", "background": "Whisper 在语音识别领域取得了显著进展，但其较大的模型体积限制了其在资源受限的边缘设备上的实际应用。本文的目标是为 Whisper 设计一种剪枝框架，通过引入结构化稀疏性和针对权重统计的自适应剪枝算法来减少模型的参数量、内存消耗和浮点操作数（FLOPs），而不损害语音识别错误率（WER）", "innovation": "提出了采用稀疏组LASSO（Sparse Group LASSO penalty）作为损失正则化器的结构化稀疏性方法；设计了一种权重统计感知的剪枝算法；并设计了自定义文本规范化器以优化WER评价", "conclusion": "在Common Voice 11.0 Hindi数据集上，相比原始模型，Whisper-small减少了35.4%的模型参数，14.25%的内存消耗和18.5%的FLOPs，Whisper-medium减少了31%的模型参数，15.29%的内存消耗和16.95%的FLOPs，而且显著优于基于迭代幅度剪枝的方法，剪枝参数量多18.7%，同时WER降低了12.31%。"}
{"llm_update_time": "20251015", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.12669", "html_url": "https://arxiv.org/abs/2510.12669", "title": "通过均匀边采样实现结构感知的光谱稀疏化", "title_en": "Structure-Aware Spectral Sparsification via Uniform Edge Sampling", "authors": "Kaiwen He,Petros Drineas,Rajiv Khanna", "background": "光谱聚类是图分区的基石方法，但由于依赖于特征向量计算，其难以扩展到大规模图。传统的稀疏化方法通过比例采样边来保留光谱特性，但需要昂贵的预处理步骤来估算有效电阻。因此，研究是否可以使用简单且无结构信息的均匀边采样策略来进行光谱聚类变得至关重要。", "innovation": "论文证明，对于能够良好分离的k聚类图，均匀采样边可以保留用于聚类的光谱子空间。具体来说，均匀采样$O(\frac{\beta^2 n \text{log} n}{\text{误差}^2})$条边，其中$\beta$是拉普拉斯矩阵条件数，就能生成一个稀疏表示，其最大的$(n-k)$维特征空间与聚类指示量几乎正交。这种方法允许我们在完全跳过重要性采样的情况下，获得一套新的电阻界限，并构建一种适用于主导特征空间的矩阵切尔诺夫界。这些工具使得在不依赖重要性采样的情况下，能够实现结构感知的光谱稀疏化。理论成果将基于聚类的核子集理论与光谱稀疏化联系起来，表明在良好聚类的情况下，均匀采样在某种程度上是结构感知的。这是首次提出均匀边采样能够保持结构感知的光谱聚类的有保障结果。", "conclusion": "通过引入新的电阻上限、秩$(n-k)$有效电阻的表述及适应主要特征空间的矩阵切尔诺夫界，本文证明在强聚类性假设下，均匀边采样可以用于保留结构的光谱聚类。这为在大规模图上实现高效的聚类提供了新方法，从而提高了光谱聚类在实际应用中的可行性和效率。"}
{"llm_update_time": "20251015", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.12700", "html_url": "https://arxiv.org/abs/2510.12700", "title": "ReLU神经网络激活模式的拓扑特征", "title_en": "Topological Signatures of ReLU Neural Network Activation Patterns", "authors": "Vicente Bosca,Tatum Rask,Sunia Tanweer,Andrew R. Tawfeek,Branden Stone", "background": "本文探讨了ReLU神经网络激活模式的拓扑特征。研究对象为含有ReLU激活函数的前向神经网络，并分析了由网络诱导的特征空间的多面体分解。", "innovation": "本文的主要创新在于：1）研究了伴随二分类的Fiedler分割与决策边界之间的相关性；2）通过回归任务中的细胞分解计算同调群，发现了训练损失与多面体细胞计数之间的相似行为模式。", "conclusion": "研究结果表明，通过多面体分解可以发现ReLU神经网络在训练过程中的某种拓扑结构和行为模式，这些发现对于理解神经网络的工作原理具有重要意义。"}
{"llm_update_time": "20251015", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.12691", "html_url": "https://arxiv.org/abs/2510.12691", "title": "DiffEM: 使用期望最大化从受污染数据学习扩散模型", "title_en": "DiffEM: Learning from Corrupted Data with Diffusion Models via Expectation Maximization", "authors": "Danial Hosseintabar,Fan Chen,Giannis Daras,Antonio Torralba,Constantinos Daskalakis", "background": "扩散模型已成为解决高维逆问题的强大生成先验模型，然而，当仅可用受污染或噪声数据时，从这些数据中学习扩散模型仍然具有挑战性。该论文旨在提出一种新的方法，通过期望最大化（EM）算法利用受污染的数据来训练扩散模型。", "innovation": "该论文提出了一个名为DiffEM的新方法，其利用条件扩散模型在E步从观测中重建干净数据，并在M步使用重建的数据来细化条件扩散模型。该方法旨在解决从受污染或噪声数据中训练扩散模型的挑战。理论分析提供了关于DiffEM迭代的单调收敛保障，假设适当的统计条件成立。通过在各种图像恢复任务中的实验，验证了该方法的有效性。", "conclusion": "本文通过提出DiffEM方法，在受污染数据上通过期望最大化的框架训练扩散模型。理论分析保证了方法的单调收敛性，并通过实验展示了其在图像恢复任务中的有效性。"}
{"llm_update_time": "20251015", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.12680", "html_url": "https://arxiv.org/abs/2510.12680", "title": "揭开混合思维的神秘面纱：LLMs能否真正切换思考与不思考模式？", "title_en": "Demystifying Hybrid Thinking: Can LLMs Truly Switch Between Think and No-Think?", "authors": "Shouren Wang,Wang Yang,Xianxuan Long,Qifan Wang,Vipin Chaudhary,Xiaotian Han", "background": "目前的LLM混合思维能够使模型在推理和直接作答之间切换，以平衡效率和推理能力。然而，实验表明当前的混合思维LLM未能完全分离这两种模式，推理行为常常渗入不思考模式中。", "innovation": "研究分析了影响可控性的因素，并发现四大关键因素：(1) 更大规模的数据，(2) 不同问题的思考与不思考答案而非相同问题，(3) 中等数量的不思考数据的增加，(4) 两阶段策略：首先训练推理能力，然后进行混合思维训练。基于这些发现，提出了一个实用的食谱，相比于标准训练，能够在两者模式中保持准确度的同时显著减少不思考输出长度（如在MATH500上从1085减少到585）并降低支持推理的标记如“wait”的出现次数（从5917减少到522）。", "conclusion": "研究揭示了当前混合思维的局限，并提出了增强其可控性的方向。"}
{"llm_update_time": "20251015", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.12681", "html_url": "https://arxiv.org/abs/2510.12681", "title": "CoRA: 潜在变量感知的时序基础模型适应", "title_en": "CoRA: Covariate-Aware Adaptation of Time Series Foundation Models", "authors": "Guo Qin,Zhi Chen,Yong Liu,Zhiyuan Shi,Haixuan Liu,Xiangdong Huang,Jianmin Wang,Mingsheng Long", "background": "时间序列基础模型（TSFMs）因其强大的模型能力、可扩展性和零样本泛化，在多个场景中展现出显著的效果。然而，由于多变量间依赖关系的异质性和大规模数据集上的骨干网络扩展性限制，大多数TSFMs通常是在单一时间序列数据集上预训练。这种限制使得TSFMs在真实世界预测任务中难以充分利用来自多种模态的外部潜在变量信息。TNMN提出了一种通用的潜在变量感知适应框架（CoRA），该框架在保留预训练骨干网络不变的同时，有效融合了时间序列、语言和图像等多种模态的外部潜在变量，提升预测质量。", "innovation": "TNMN提出了一种新的潜在变量感知适应框架（CoRA），它在预训练骨干网络不变的前提下，实现了外部潜在变量的高效融合。CoRA框架中引入了一种新型的Granger因果嵌入（GCE），能够自动评估潜在变量对于目标变量的因果可预测性，并通过零初始化的条件注入机制，避免预训练模型的灾难性遗忘，逐步整合外部信息。实验结果表明，CoRA在全或少样本训练样本条件下，TSFMs的协变量感知预测性能超越了现有先进模型，实现了改进31.1%的均方误差。", "conclusion": "CoRA具有与多种高级TSFMs的良好兼容性，并扩展了潜在变量的适用范围，为TSFMs的实际应用提供了一种可靠范式。"}
{"llm_update_time": "20251015", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.12686", "html_url": "https://arxiv.org/abs/2510.12686", "title": "从稀疏GPS轨迹进行异常停车检测的少量标注半监督学习", "title_en": "Few Shot Semi-Supervised Learning for Abnormal Stop Detection from Sparse GPS Trajectories", "authors": "Muhammad Ayub Sabir,Junbiao Pang,Jiaqi Wu,Fatima Ashraf", "background": "城市间客车运输中的异常停车检测（ASD）对于保障乘客安全、运营可靠性和合规性至关重要。然而，两个关键挑战阻碍了ASD的有效性：稀疏GPS轨迹使得短暂停留或未经授权的停车难以发现；有限的标记数据限制了监督学习的应用。现有的方法通常假设密集采样或规律运动模式，这限制了它们的应用范围。", "innovation": "为解决数据稀疏问题，该研究提出了一种感知稀疏性的分割（SAS）方法，可基于局部空间-时间密度自适应地定义分割边界。在此基础上引入了三项领域特定指标，以捕捉异常停车行为。为减轻稀疏性的影响，还开发了局部时空指标引导调整（LTIGA），通过局部相似性图平滑这些指标。为克服标签稀缺性，构建了一个空间-时间图，其中每个分割节点含有经LTIGA改进的特征，并应用标签传播来扩展弱监督，接着使用GCN学习关系模式。最终使用自训练模块融合高置信度的伪标签，以逐步改善预测。实验表明，仅使用10个标注实例即可实现AUC 0.854 和 AP 0.866，优于此前的方法。该代码和数据集已公开发布。", "conclusion": "实验结果表明，该方法在仅有10个标注实例的情况下实现了较好的性能（AUC达到0.854，AP达到0.866），显著优于之前的方法。此外，该方法解决了数据稀疏性和标签稀缺性的问题，且代码和数据集公开，为该领域的研究提供了参考。"}
{"llm_update_time": "20251015", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.12721", "html_url": "https://arxiv.org/abs/2510.12721", "title": "CARVQ: 正确适配器与分组残差向量量化方法在LLM嵌入压缩中的应用", "title_en": "CARVQ: Corrective Adaptor with Group Residual Vector Quantization for LLM Embedding Compression", "authors": "Dayin Gou,Sanghyun Byun,Nilesh Malpeddi,Gabrielle De Micheli,Prathamesh Vaste,Jacob Song,Woo Seong Chung", "background": "大语言模型（LLMs）通常依赖大量的参数进行标记嵌入，这需要大量的存储空间和内存占用。特别地，部署在边缘设备上的LLMs会受到内存的限制，通过压缩嵌入层来减少内存占用，不仅释放了内存带宽，还提高了推理速度。", "innovation": "引入了CARVQ，一种基于训练后模型的创新技术，结合了线性与非线性的变换，以分组残差向量量化技术应用于LLM嵌入压缩。CARVQ使用的技术可以在不需要特殊硬件支持的情况下将嵌入压缩到约1.6比特，并且在常见的生成、鉴别、数学和推理任务上表现良好，平均比特值较低，同时保持合理的困惑度和准确性，优于标量量化。", "conclusion": "我们的研究成果包括一项适用于最新变压器量化方法的新压缩技术，可以无缝集成到支持4位内存的任何硬件中，从而减少LLM在内存受限设备中的内存占用。这项工作展示了向边缘设备高效部署LLM的重要步骤。"}
{"llm_update_time": "20251015", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.12726", "html_url": "https://arxiv.org/abs/2510.12726", "title": "通过参数局部搜索视角改进决策树", "title_en": "Improving Decision Trees through the Lens of Parameterized Local Search", "authors": "Juha Harviainen,Frank Sommer,Manuel Sorge", "background": "学习决策树的算法通常包含局部搜索操作，如调整切割阈值或交换切割特征。本文研究了在固定数量下执行单一类型的这些操作以最小化分类错误的问题，发现这些问题在一般情况下是NP完全的。作者提供了一个全面的参数复杂性分析，旨在确定解释问题难易性及使其可处理的性质。研究表明，当特征数量$d$或领域大小$D$较小时，问题保持困难，但两者的组合则变为固定参数可处理的。此外，还提供了一个概念性实现并报告了实验结果。", "innovation": "研究了在固定数量下通过单一类型的局部搜索操作（调整切割阈值或交换切割特征）来最小化决策树分类错误的问题。提供了一个全面的参数复杂性分析，发现了当特征数量$d$或领域大小$D$较小时，问题变得困难，但两者的结合则变得可处理。提出了$(D + 1)^{2d} \times |I|^{O(1)}$的算法时间复杂度，并提供了概念性实现和实验结果。", "conclusion": "研究发现当特征数量$d$或领域大小$D$较小时，问题保持困难，但两者的组合则变得固定参数可处理，提出的时间复杂度为$(D + 1)^{2d} \times |I|^{O(1)}$的算法并进行了实验验证。"}
{"llm_update_time": "20251015", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.12719", "html_url": "https://arxiv.org/abs/2510.12719", "title": "小分子药物性质预测中化学预训练模型的多任务微调与加速", "title_en": "Multitask finetuning and acceleration of chemical pretrained models for small molecule drug property prediction", "authors": "Matthew Adrian,Yunsie Chung,Kevin Boyd,Saee Paliwal,Srimukh Prasad Veccham,Alan C. Cheng", "background": "化学预训练模型，有时被称为基础模型，正在药物发现应用中获得越来越多的关注。这些模型通过自我监督训练提取了一般化学知识，这些知识有可能改善诸如靶点效力和ADMET属性等关键药物发现终点的预测。多任务学习在提高预测模型上以前已成功应用。本文展示了在化学预训练图神经网络模型，如增强版的GROVER模型和知识导向的图变换器预训练（KGPT）中以多任务方式进行微调，显著提升了模型性能。特别是在大规模数据集上，多任务微调KERMT的表现提升最为明显。此外，作者还发布了一组多任务ADMET数据拆分，以便更准确地对多任务深度学习方法进行基准测试。最后，提供了一个KERMT模型的加速实现，使得大规模预训练、微调和推理能够适用于工业药物发现工作流程。", "innovation": "提出了在化学预训练图神经网络模型中以多任务方式进行微调的方法，尤其是在大规模数据集上，这种方法显著提升了模型性能。此外，还发布了一组ADMET多任务数据拆分，以及KERMT模型的加速实现，加速了大规模药物发现过程中的预测能力。", "conclusion": "通过多任务微调化学预训练模型（如增强版的GROVER模型和KGPT），显著提高了模型在药物性质预测任务上的表现。特别是在大规模数据集上，多任务微调的效果更为显著。此外，还发布了一组多任务ADMET数据集和KERMT模型的加速版本，有助于更好地评估多任务深度学习方法在药物预测中的表现，并加速了工业药物发现流程中的预测任务。"}
{"llm_update_time": "20251015", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.12734", "html_url": "https://arxiv.org/abs/2510.12734", "title": "Doctor Rashomon and the UNIVERSE of Madness: Variable Importance with Unobserved Confounding and the Rashomon Effect", "title_en": "Doctor Rashomon and the UNIVERSE of Madness: Variable Importance with Unobserved Confounding and the Rashomon Effect", "authors": "Jon Donnelly,Srikar Katta,Emanuele Borgonovo,Cynthia Rudin", "background": "Variable importance (VI)方法常用于假设生成、特征选择和科学验证。标准的VI管道中，分析师仅使用观测特征估计单个预测模型的VI。但特征的重要性取决于模型中包含的其他变量，而观测数据中常常忽略了重要的变量。此外，一个模型的VI往往与另一个同样优秀的模型的VI不同，这种现象被称为Rashomon效应。", "innovation": "该论文引入了UNobservables和Variable importance using Rashomon SEts (UNIVERSE)方法。该方法利用Rashomon集（数据集中接近最优的模型集合）来估计即使存在缺失特征情况下真实的变量重要性边界。该方法理论上保证了鲁棒性，并在半合成模拟中表现出色。此外，它还在信用风险任务中展示了其实用性。", "conclusion": "该研究通过引入UNIVERSE方法，解决了传统VI方法中忽视未观测变量和模型多样性导致的VI估计问题，理论上保证了模型的鲁棒性，并通过实验证明其在各种场景下的有效性。"}
{"llm_update_time": "20251015", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.12752", "html_url": "https://arxiv.org/abs/2510.12752", "title": "KoALA: KL-L0对抗检测器通过标签一致性", "title_en": "KoALA: KL-L0 Adversarial Detector via Label Agreement", "authors": "Siqi Li,Yasser Shoukry", "background": "深度神经网络对对抗攻击非常敏感，这对安全性和关键应用构成了重大风险。本文探讨了一种新颖的无语义特征的对抗检测器KoALA，它无需改变网络结构或重新训练对抗样本。", "innovation": "KoALA基于一个简单原则：当两个互补的相似度度量在类别预测上出现分歧时，即检测到对抗攻击。这些度量包括KL散度和L0相似度，它们分别针对不同的扰动类型敏感。KL散度对密集、低振幅的改变敏感，而L0相似度设计用于检测稀疏、高影响的改变。研究还提供了方法的正确性证明，并仅需简单微调预训练的图像编码器以确保嵌入与两个度量良好对齐。", "conclusion": "广泛实验表明，KoALA能够在满足定理条件时一致有效地检测对抗样本。在ResNet/CIFAR-10上，KoALA达到了0.94的精度和0.81的召回率；在CLIP/Tiny-ImageNet上，达到了0.66的精度和0.85的召回率。这表明KoALA是轻量级且可轻松集成到现有模型中的一种解决方案，适用于各种数据模态。"}
{"llm_update_time": "20251015", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.12727", "html_url": "https://arxiv.org/abs/2510.12727", "title": "智能农业生产系统中的分层联邦学习作物产量预测", "title_en": "Hierarchical Federated Learning for Crop Yield Prediction in Smart Agricultural Production Systems", "authors": "Anas Abouaomar,Mohammed El hanjri,Abdellatif Kobbane,Anis Laouiti,Khalid Nafil", "background": "本文提出了一种新的分层联邦学习架构，专门针对智能农业生产和作物产量预测系统。传统的联邦学习架构难以适应复杂多变的农业生产和隐私保护的需求。文中提出了一个分层的架构，包括个体智能农场、作物特定聚合器以及全局模型聚合器三层结构。每个作物集群中的客户端协作训练专门针对特定作物类型的模型，然后聚合生成一个高层的全球模型，整合多种作物的知识。这种设计能够实现局部专业化和全局泛化，同时保持数据隐私并减少通信开销。实验结果表明，该系统能够有效地提高作物产量预测的准确性，尤其适用于异质农业环境和隐私敏感的农业数据场景，显著优于标准机器学习模型。", "innovation": "提出了一种新的分层联邦学习架构，特别为智能农业生产和作物产量预测设计。该架构包括三层：智能农场、作物特定聚合器和全局模型聚合器。引入了按季节订阅机制，农场在每个农业季节开始时加入作物特定的集群。模型训练专门针对特定作物，最终生成整合多作物知识的全局模型。这种设计在保持数据隐私和减少通信开销的同时，实现了局部和全局方面的优化。实验表明该系统在提高预测准确性方面显著优于标准机器学习方法。", "conclusion": "该研究表明，分层联邦学习在智能农业系统中对于作物产量预测具有显著优势，尤其适用于异质农业环境和隐私敏感数据的场景。该架构在未来智能农业领域具有广阔的应用前景。"}
{"llm_update_time": "20251015", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.12769", "html_url": "https://arxiv.org/abs/2510.12769", "title": "对正确损失函数的高效全能预测", "title_en": "Sample-Efficient Omniprediction for Proper Losses", "authors": "Isaac Gibbs,Ryan J. Tibshirani", "background": "本文考虑了如何构造概率预测以在下游用户利用这些预测进行决策时实现准确决策的问题。对于单一决策者，设计最优预测器等同于最小化相应的负效用的正确损失函数。对于多个决策者，问题可以被视作全能预测的一种变体，目的是设计一个单一预测器同时最小化多个损失。已有实现全能预测的算法通常分为两类：一类是采用增强方法，优化其他辅助目标如多校准等，全能预测可作为一种附带的结果；另一类是基于对手的两玩家博弈方法，可以在线估计并回应“最坏情况”损失。", "innovation": "本文主要创新在于：首先，提出了多校准问题比全能预测更难，从而说明了前者方法必然会伴随非最优样本复杂度。其次，针对后者方法，介绍了如何将在线到批处理的转换用来获得样本高效算法，尽管该方法返回的预测器较为复杂且具有随机性。最后，设计了一种更直接的非随机算法，该算法利用了正确损失函数集的结构特点。", "conclusion": "本文通过分析正确损失预测，改进了先前的算法设计，提出了更高效的样本转换方法，最终设计出一种直接、非随机的算法，以应对多个决策者的情况并最小化损失。"}
{"llm_update_time": "20251015", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.11726", "html_url": "https://arxiv.org/abs/2510.11726", "title": "scPPDM：单细胞药物响应预测的扩散模型", "title_en": "scPPDM: A Diffusion Model for Single-Cell Drug-Response Prediction", "authors": "Zhaokang Liang,Shuyang Zhuang,Xiaoran Jiao,Weian Mao,Hao Chen,Chunhua Shen", "background": "现有的单细胞RNA测序(scRNA-seq)数据在预测单细胞药物响应方面存在困难，缺乏有效的扩散模型框架来处理单细胞药物响应预测。", "innovation": "提出了一种新的单细胞药物响应预测扩散模型(scPPDM)，这是首个将预处理状态和药物剂量耦合到统一潜空间中的扩散框架，通过非拼接的GD-Attn，评估结果显示在Tahoe-100M基准下的多个指标上scPPDM都取得了最优结果，特别是在未知药物条件下的DEG logFC-Spearman/Pearson相比第二名模型分别提高了36.11%/34.21%，同时模型还提供了一种透明的what-if分析和剂量调节界面，减少了实验负担，同时保持了生物学的特异性。", "conclusion": "scPPDM模型在Tahoe-100M基准下的多个评估指标上都超越了之前的模型，其能够便捷地进行what-if分析和剂量调节，为单细胞药物响应研究提供了新的工具。"}
{"llm_update_time": "20251015", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.12672", "html_url": "https://arxiv.org/abs/2510.12672", "title": "保持冷静并避免有害内容：概念对齐与潜在操纵以获得更安全的答案", "title_en": "Keep Calm and Avoid Harmful Content: Concept Alignment and Latent Manipulation Towards Safer Answers", "authors": "Ruben Belo,Claudia Soares,Marta Guimaraes", "background": "大型语言模型容易受到绕过内置安全措施的篡改攻击（例如，通过敌对提示欺骗模型），这使得这些模型可能会产生有害内容。现有的方法往往需要重新训练模型来修复问题，这会显著增加时间和资源成本。因此，开发一种不需要重新训练模型的方法来抑制有害概念就显得尤为重要。", "innovation": "本文提出了一种名为Concept Alignment and Concept Manipulation的轻量化方法（CALM），该方法在推理时通过修改模型最后一层的潜在表示来抑制有害概念，而不需重新训练。CALM结合了来自计算机视觉领域的控制向量技术（Controlled-Wrapped Perturbation, \textit{cw}）和正交投影，以去除与有害内容相关的潜在方向，同时保持模型性能。实验表明，CALM在大多数指标上优于基线方法，提供了一种无需额外训练数据或模型微调，具有较小计算开销的方法来提高AI安全性。", "conclusion": "该研究提出了一种轻量级方法（CALM），能够在推理时通过修改模型的潜在表示来有效削弱有害概念，而无需重新训练模型。实验结果表明，该方法在防止生成有害内容方面效果良好，并且在保持模型性能和计算效率方面更具优势。"}
{"llm_update_time": "20251015", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.11736", "html_url": "https://arxiv.org/abs/2510.11736", "title": "Dhumbal纸牌游戏的AI代理：一项比较研究", "title_en": "AI Agents for the Dhumbal Card Game: A Comparative Study", "authors": "Sahaj Raj Malla", "background": "本研究评估了用于Dhumbal，一种具有部分信息的有文化意义的多人纸牌游戏的人工智能（AI）代理，通过系统比较规则基础、搜索基础和学习基础策略。研究正式化了Dhumbal的游戏机制，并实现了多种代理，包括启发式方法（Aggressive，Conservative，Balanced，Opportunistic）、搜索方法（如Monte Carlo Tree Search及其变种Information Set Monte Carlo Tree Search）和强化学习方法（如Deep Q-Network和Proximal Policy Optimization），以及一个随机基线。评估包括类别内部锦标赛，然后是跨类别的冠军赛。性能通过胜率、经济结果、Jhyap成功、每轮丢弃的卡片数量、风险评估和决策效率来衡量。", "innovation": "研究贡献了一个可重复的AI框架，揭示了在部分信息条件下启发式方法的有效性，并提供了开源代码，从而推动了AI研究，并支持了文化纸牌游戏的数字化保存。", "conclusion": "规则基础的Aggressive代理在1024轮模拟游戏中胜率最高（88.3%，95% CI: [86.3, 90.3]），通过有效地利用Jhyap申明显著优于ISMCTS（9.0%）和PPO（1.5%）。"}
{"llm_update_time": "20251015", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.11744", "html_url": "https://arxiv.org/abs/2510.11744", "title": "量子核方法：收敛理论、分离边界和在营销分析中的应用", "title_en": "Quantum Kernel Methods: Convergence Theory, Separation Bounds and Applications to Marketing Analytics", "authors": "Laura Sáez-Ortuño,Santiago Forgas-Coll,Massimiliano Ferrara", "background": "本文研究了在NISQ时期的条件下将量子核方法应用于实际的消费者分类任务的可行性。通过将量子核支持向量机（Q-SVM）与量子特征提取模块（QFE）结合起来，形成一个混合处理管道，并与经典的和量子的基本数值进行基准测试，展示了量子计算在实际问题上的潜力。文章采用详细的性能指标进行比较，以验证和集成硬件，并为NISQ时代的流程和硬件集成提供了初步的证据。", "innovation": "文章提出了一种结合量子核支持向量机（Q-SVM）和量子特征提取模块（QFE）的混合处理管道，并与经典和量子基准进行了对比测试。通过固定超参数，Q-SVM 在测试中展现出较高的敏感度，同时保持了与经典SVM相当的精确度。该研究方法采用了最近正式化量子-经典分离并借助XEB风格方法验证资源的研究方向，实现表现出色的分类效果，同时需要注意硬件噪声的限制。", "conclusion": "本文的结果提供了对NISQ时期量子计算在实际问题中应用的一个初步评估，虽然在精确度方面已经达到可与经典方法竞争的水平，但仍需进一步研究以应对硬件噪声带来的挑战。这项研究为未来的工作流程和硬件集成提供了一个良好的起点。"}
{"llm_update_time": "20251015", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.11727", "html_url": "https://arxiv.org/abs/2510.11727", "title": "多目标贝叶斯优化与人类环路反馈结合用于灵活神经形态电子器件的制造", "title_en": "Multi-objective Bayesian Optimization with Human-in-the-Loop for Flexible Neuromorphic Electronics Fabrication", "authors": "Benius Dunn,Javier Meza-Arroyo,Armi Tiihonen,Mark Lee,Julia W. P. Hsu", "background": "神经形态计算硬件使边缘计算成为可能，并可在柔性电子产品中实现，为新型应用提供可能性。金属氧化物材料是制造柔性神经形态电子器件的有前途的候选者，但由于金属氧化物与聚合物基板兼容性差，导致了加工限制。由于光子固化结果依赖于多种输入参数，传统的网格搜索方法通过这些参数找到最佳加工条件不可行。因此，通过多目标贝叶斯优化（MOBO）来确定有利于神经形态应用的大电容频率分散和低泄漏电流的最佳光子固化条件成为关键。开发了一个人类在环内的（HITL）框架，用于将失败的实验纳入MOBO机器学习工作流，减少了实验轮数的需求，加速了优化过程。", "innovation": "本研究创新性地使用多目标贝叶斯优化（MOBO）结合人类在环内的（HITL）框架，用于优化光子固化条件下柔性金属-绝缘体-金属（MIM）电容器的制造工艺。这一方法能够有效处理多输入相关性高的实验问题，并能减少实验失败率高的多目标优化问题中的实验轮数，提高优化效率并生成可用于机器学习模型的结果。", "conclusion": "研究结果表明，通过MOBO和HITL框架结合可以优化柔性神经形态电子器件的制造条件，提供不同帕累托最优条件以调整电介质性质，同时通过Shapley加性解释分析揭示不同输入的重要性。该方法可用于多种多目标实验问题，为生成可用于机器学习模型的有效结果提供了一种新途径。"}
{"llm_update_time": "20251015", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.11789", "html_url": "https://arxiv.org/abs/2510.11789", "title": "非参数最小最大率在注意力模型中学习成对互作的维数无关结果", "title_en": "Dimension-Free Minimax Rates for Learning Pairwise Interactions in Attention-Style Models", "authors": "Shai Zucker,Xiong Wang,Fei Lu,Inbar Seroussi", "background": "本文研究了单层注意力模型中成对交互的学习收敛率，其中令牌通过权重矩阵和非线性激活函数进行交互。背景包括对当前技术的简要介绍，特别是在注意力模型中成对交互的学习效率和统计意义等方面的研究。\n", "innovation": "本文的主要创新在于证明了最小最大收敛率为 $M^{-\frac{2\beta}{2\beta+1}}$，其中 $M$ 是样本大小，依赖于激活函数的平滑度 $\beta$，而与其他因素（如令牌数、环境维度或权重矩阵的秩）无关。这一结果强调了注意力模型本身的统计效率，即使权重矩阵和激活函数无法单独识别。\n", "conclusion": "研究成果对注意力机制及其训练的理解提供了理论基础，证明了注意力风格的非局部模型即使在权重矩阵和激活函数不可独立识别的情况下，仍然具有维数无关的统计效率。"}
{"llm_update_time": "20251015", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.10681", "html_url": "https://arxiv.org/abs/2510.10681", "title": "RePro: 训练语言模型以忠实回收网络进行预训练", "title_en": "RePro: Training Language Models to Faithfully Recycle the Web for Pretraining", "authors": "Zichun Yu,Chenyan Xiong", "background": "高质量的预训练数据是大型语言模型（LLMs）的关键资源，但这些资源正在耗尽。该研究引入了一种名为RePro的新颖网页回收方法，通过强化学习训练一个小规模的语言模型（LM），生成高质量且忠实的原始数据重述版本，从而提高模型的预训练效果和效率。", "innovation": "RePro通过设计一个质量奖励和三个忠实度奖励，优化LM重新构造器，将有机数据转化为高质量的重述版本，保持其核心语义和结构。与现有的方法相比，RePro在多个下游任务上展示了显著的准确性和更高效的有机数据利用，特别是在不同回收数据量的实验中进一步验证了其优势。", "conclusion": "RePro为大型语言模型的预训练提供了一种有效且可控的途径，不仅提高了模型的准确性和数据效率，还在保持有机数据关键信息和特性的重述生成中表现更佳。该研究还开源了代码、重述器和回收数据，以便其他研究者验证和改进相关技术。"}
{"llm_update_time": "20251015", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.11750", "html_url": "https://arxiv.org/abs/2510.11750", "title": "PRISM: 通过结构-序列多模态表示的精细粒度检索提升蛋白质逆折叠", "title_en": "PRISM: Enhancing Protein Inverse Folding through Fine-Grained Retrieval on Structure-Sequence Multimodal Representations", "authors": "Sazan Mahbub,Souvik Kundu,Eric P. Xing", "background": "设计蛋白质序列以折叠成目标三维结构，即逆折叠问题，是蛋白质工程的核心，但由于序列空间的庞大和局部结构约束的重要性，它仍然是一个挑战。现有的深度学习方法在恢复方面表现突出，但缺乏显式的机制来重复自然蛋白质中保守的精细结构-序列模式。", "innovation": "我们提出了PRISM，这是一种多模态检索增强生成框架，用于逆折叠。它从已知蛋白质中检索潜在的精细结构-序列模式，并与混合自我交叉注意解码器集成。PRISM作为一种潜在变量概率模型进行构建，并通过有效的近似实施，结合了理论基础和实际可扩展性。PRISM在五个基准测试中均表现出最佳性能，包括改进的困惑度和氨基酸回收率，同时提高了折叠度量标准（RMSD、TM-score、pLDDT），证明精细粒度的多模态检索是蛋白质序列设计的强大且高效的范式。", "conclusion": "PRISM证明了精细粒度的多模态检索是蛋白质序列设计强大的并且高效的范式，并在多个基准测试中确立了新的最佳状态。"}
{"llm_update_time": "20251015", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.11752", "html_url": "https://arxiv.org/abs/2510.11752", "title": "通过最佳运输实现快速且可解释的蛋白质亚结构对齐", "title_en": "Fast and Interpretable Protein Substructure Alignment via Optimal Transport", "authors": "Zhiyu Wang,Bingxin Zhou,Jing Wang,Yang Tan,Weishu Zhao,Pietro Liò,Liang Hong", "background": "蛋白质是执行生命功能的生物大分子。蛋白质结构中的局部基序，如活性位点，是连接结构和功能的关键部分，对理解蛋白质进化和蛋白质工程至关重要。现有的计算方法难以识别和比较这些局部结构，这在理解蛋白质结构和利用其功能方面留下了巨大的知识空白。", "innovation": "本研究提出了PLASMA，这是一个基于深度学习的框架，用于高效且可解释的蛋白质残基级亚结构对齐。通过将问题重述为正则化最优传输任务，并利用可微分的Sinkhorn迭代，PLASMA能够为输入的蛋白质结构对输出清晰的对齐矩阵和解释性的总体相似性分数。通过广泛的定量评估和三个生物案例研究，证明PLASMA实现了准确、轻量级且可解释的残基级对齐。此外，还介绍了PLASMA-PF，这是一种无需训练的变种，当没有训练数据时，可以作为一种实用的选择。", "conclusion": "我们的方法解决了蛋白质结构分析工具的关键空白，并为功能注释、进化研究和基于结构的药物设计提供了新的机会。通过官方实现确保了可复制性，详见：这个链接 [链接]。"}
{"llm_update_time": "20251015", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.11817", "html_url": "https://arxiv.org/abs/2510.11817", "title": "使用JAXA的辉夜号图像提高3D月球地图质量", "title_en": "Enhancing the Quality of 3D Lunar Maps Using JAXA's Kaguya Imagery", "authors": "Yumi Iwashita,Haakon Moe,Yang Cheng,Adnan Ansar,Georgios Georgakis,Adrian Stoica,Kazuto Nakashima,Ryo Kurazume,Jim Torresen", "background": "随着全球对月球的探索日益加强，高质量的3D月球地图变得越来越关键，尤其是在如NASA的Endurance任务概念中，该任务设想使用一辆漫游车穿越南极-爱廷盖盆地2000公里的长途任务。尽管JAXA的辉夜号地形相机（Terrain Camera，TC）提供了全球范围内的10米/像素分辨率图像，但由于立体匹配错误和JPEG压缩产生的压缩伪影，这些图像存在高度不准确的问题。本研究旨在通过减少压缩图像在视差图中产生的残余噪声，提高从辉夜号TC图像生成的3D地图的质量。", "innovation": "本研究提出了一种方法来减轻Kaguya TC图像因压缩产生的噪声对3D地图质量的影响。通过分析Kaguya TC图像的压缩行为，识别出系统性的视差噪声模式，特别是在较暗区域。所提出的方法专注于降低来源于压缩图像的视差图像中的残余噪声，以提升3D地图的质量。实验结果显示，该方法有效地减少了高度噪声，提高了未来月球任务中地形数据的安全性和可靠性。", "conclusion": "本研究提出的方法能够有效减少3D地图中由压缩图像产生的残留噪声，从而提升月球地形数据的安全性和可靠性。这对于未来高空域漫游车的长时间任务至关重要，尤其适用于Endurance任务概念中的南极-爱廷盖盆地2000公里的长途漫游任务。"}
{"llm_update_time": "20251015", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.11835", "html_url": "https://arxiv.org/abs/2510.11835", "title": "数据或语言监督：是什么让CLIP比DINO更胜一筹？", "title_en": "Data or Language Supervision: What Makes CLIP Better than DINO?", "authors": "Yiming Liu,Yuhui Zhang,Dhruba Ghosh,Ludwig Schmidt,Serena Yeung-Levy", "background": "CLIP作为视语言模型(VLMs)的视觉编码器表现优于自监督模型如DINO，但其优势源自于语言监督还是大量数据尚未明确。本文通过控制条件下的预训练方法，对比了CLIP和DINO的表现，并分析了两种模型的嵌入特性以及在多种视觉问答任务中的应用情况。", "innovation": "本文创新性地在相同架构、数据集和训练配置下对CLIP和DINO进行预训练，并通过嵌入分析揭示了两种模型在高层语义和低级特征方面的差异，从而探讨了语言监督和大量数据在视觉编码器设计中的影响。", "conclusion": "实验结果显示，CLIP在文本密集型任务中表现出色，而DINO在视觉中心型任务中稍占上风。语言监督的不同形式仅带来有限的性能提升。研究结果为视觉编码器设计及其对VLM性能的影响提供了科学见解。"}
{"llm_update_time": "20251015", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.11871", "html_url": "https://arxiv.org/abs/2510.11871", "title": "无限维空间中的主动子空间", "title_en": "Active Subspaces in Infinite Dimension", "authors": "Poorbita Kundu,Nathan Wycoff", "background": "主动子空间分析利用梯度二次矩的主特征空间进行监督降维。本文将这种技术扩展到希尔伯特空间上的实值泛函。研究中定义了一个算子，当应用于欧几里得空间时，与主动子空间矩阵一致。这篇文章展示了许多主动子空间分析的期望属性可以直接扩展到无限维设置。此外，还提出了一个蒙特卡洛方法，并讨论了其收敛性。最后，该方法被用于创建可视化，以及改善复杂测试问题上的建模和优化工作。", "innovation": "将主动子空间分析方法扩展到了希尔伯特空间上的实值泛函上，定义了一个算子，并展示了许多期望属性可以直接推广到无限维设置，提出了一种蒙特卡洛方法研究其收敛性，应用于复杂测试问题上的优化和可视化", "conclusion": "该研究扩展了主动子空间分析，使其实用范围涵盖无限维空间，通过定义一个算子证明了其保持原有性质，提出了蒙特卡洛方法验证其有效性，最后应用于复杂测试问题以提高建模和优化效果"}
{"llm_update_time": "20251015", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.11824", "html_url": "https://arxiv.org/abs/2510.11824", "title": "在合作多智能体强化学习中的稳健性和抗扰性实证研究", "title_en": "Empirical Study on Robustness and Resilience in Cooperative Multi-Agent Reinforcement Learning", "authors": "Simin Li,Zihao Mao,Hanxiao Li,Zonglei Jing,Zhuohang bian,Jun Guo,Li Wang,Zhuoran Han,Ruixiao Xu,Xin Yu,Chengdong Ma,Yuqing Ma,Bo An,Yaodong Yang,Weifeng Lv,Xianglong Liu", "background": "在合作多智能体强化学习（MARL）中，常常在理想的模拟环境中调整超参数来最大化合作性能。然而，在实际环境中，为合作调优的策略往往缺乏对不确定性和干扰的鲁棒性和恢复能力。为了建立可信赖的MARL系统，需要深入理解鲁棒性和抗扰性，前者确保系统在不确定性下的稳定性，后者是指系统从干扰中恢复的能力。控制理论中已经系统地研究了抗扰性，但在MARL中对此关注不足。本文通过一项包含超过82,620次实验的大型实证研究，考察了4个真实环境、13种不确定性类型和15种超参数条件下的合作、鲁棒性和抗扰性。", "innovation": "本文进行了一项大规模的实证研究，评估了4个真实世界环境下的40多个MARL网络在13种不同类型不确定性下的合作、鲁棒性和抗扰性行为。主要发现超参数调优对于可信的MARL至关重要；出人意料的是，一些标准实践，如参数共享、GAE和PopArt，实际上降低了鲁棒性，而早期停止、高学习率和Leaky ReLU则一致改善了鲁棒性和抗扰性。这些发现证明，鲁棒性与抗扰性不能普遍适用于所有不确定性和智能体范围，需要针对特定情况调整超参数。", "conclusion": "通过优化超参数，发现对于所有MARL架构而言，合作、鲁棒性和抗扰性都有显著的改进。该现象还能推广到各种鲁棒的MARL方法上。研究结果可以提供对如何调优MARL系统的指导，以提高其在实际应用中的鲁棒性和整体性能。"}
{"llm_update_time": "20251015", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.11895", "html_url": "https://arxiv.org/abs/2510.11895", "title": "高概率边界条件下异质本地差异隐私", "title_en": "High-Probability Bounds For Heterogeneous Local Differential Privacy", "authors": "Maryam Aliakbarpour,Alireza Fallah,Swaha Roy,Ria Stevens", "background": "本文研究了在本地差异隐私（LDP）条件下，当用户可能具有不同级别的隐私要求，并且必须以高概率保证准确性时的统计估计问题。不同于常规基于期望的分析，本文针对一维和多维均值估计问题，发展了以$\boldsymbol{\text{2-范数}}$度量的有限样本上界，并且至少以$1-\beta$的概率成立。此外，本文还研究了在$\boldsymbol{\text{∞-范数}}$距离下的分布学习问题，设计了适应异质隐私需求的算法，并且提供高概率保证。", "innovation": "本文的主要创新点包括：1）提出了在异质LDP条件下的一维和多维均值估计问题的有限样本上界，并且以高概率成立。2）提供了与异质LDP相匹配的最小二项界，确立了本文保证在异质LDP条件下的最优性（在常数项上）。3）设计了一种在$\boldsymbol{\text{∞-范数}}$距离下适应异质隐私需求的算法，并且提供了高概率的保证。4）本文的方法为在用户特定隐私级别下的机制设计提供了理论指导。", "conclusion": "本文通过在异质LDP条件下针对均值估计和分布学习问题，提供了高概率保证的上界和算法，并且通过最小二项界证明了最优性，为隐私保护下的统计估计和学习问题提供了新见解和方法。"}
{"llm_update_time": "20251015", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.11967", "html_url": "https://arxiv.org/abs/2510.11967", "title": "通过上下文折叠扩展长时域LLM代理", "title_en": "Scaling Long-Horizon LLM Agent via Context-Folding", "authors": "Weiwei Sun,Miao Lu,Zhan Ling,Kang Liu,Xuesong Yao,Yiming Yang,Jiecao Chen", "background": "大规模语言模型（LLM）代理在执行长期任务时受到上下文长度的固有限制。", "innovation": "本文引入了一种称为上下文折叠的框架，使代理能够主动管理其工作上下文。通过程序化地将任务分解为子任务并实现后折叠，可以有效地管理上下文，同时保留简洁的结果总结。为此，开发了一种端到端的强化学习框架FoldGRPO，具有特定的过程奖励以鼓励有效的任务分解和上下文管理。在复杂长期任务（Deep Research和SWE）上，折叠代理能够与ReAct基线持平或超越基线，同时使用10倍较小的活动上下文，并显著优于依赖于总结的上下文管理的模型。", "conclusion": "该研究展示了如何通过上下文折叠技术改进长期任务中的LLM代理性能，不仅实现了更高效的任务管理，还取得了优于传统方法的成果。"}
{"llm_update_time": "20251015", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.11923", "html_url": "https://arxiv.org/abs/2510.11923", "title": "使用分子集体变量增强扩散采样法", "title_en": "Enhancing Diffusion-Based Sampling with Molecular Collective Variables", "authors": "Juno Nam,Bálint Máté,Artur P. Toshev,Manasa Kaniselvan,Rafael Gómez-Bombarelli,Ricky T. Q. Chen,Brandon Wood,Guan-Horng Liu,Benjamin Kurt Miller", "background": "扩散基采样器能够通过能量或对数密度来学习复杂、高维分布的采样，而无需训练数据。然而，它们在分子采样方面仍不实用，因为它们通常比分子动力学更慢，且难以探索热力学相关的模式。", "innovation": "作者提出了使用分子集体变量（CVs）的顺序偏置方法。这种方法通过中心在最近采样上的排斥势能，推动未来样本向新颖的CV区域发展，从而使投影空间中的温度有效提高。这种方法提高了效率，促进了模式发现，并能够估计自由能差。此外，通过重新加权偏置，方法仍然独立的从近似玻尔兹曼分布中采样。", "conclusion": "在标准肽构象采样基准测试中，该方法成功恢复了多样化的构象状态和准确的自由能剖面。这是首次使用扩散基采样法实现反应性采样，可以使用通用的原子间势能捕捉键的断裂和形成，准确性接近第一原理的精度。这种方法在反应能景的解析方面节省了大量计算时间，推动了扩散基采样在分子科学中的实际应用。"}
{"llm_update_time": "20251015", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.11905", "html_url": "https://arxiv.org/abs/2510.11905", "title": "LLM知识是脆弱的：真实陈述表示依赖于表面相似性", "title_en": "LLM Knowledge is Brittle: Truthfulness Representations Rely on Superficial Resemblance", "authors": "Patrick Haller,Mark Ibrahim,Polina Kirichenko,Levent Sagun,Samuel J. Bell", "background": "为了使大型语言模型（LLMs）可靠，它们必须学到能够广泛应用在各种环境中的稳健知识，但现有研究发现，LLMs在处理细微输入差异时的表现会显得脆弱和敏感。本文探讨了这种脆弱性是否直接源于模型内部知识表示不稳定性的问题，通过研究语言模型在经过表面变换以驱动其出分布（OOD）的样本中的表现，验证这一假设。", "innovation": "研究通过应用语义保持的扰动，考察陈述真实性的表示随着样本与预训练数据的相似度降低时的表现情况；研究了四个LLM家族、五个评估数据集和三种知识探针方法下的结果；揭示了LLMs可能学到表面且不稳健的知识表示，这种表示使得知识的泛化能力有限；提出了对真实陈述探针的有效性构成了根本性挑战，进一步强调了需要改进学习知识表示的稳健性的重要性。", "conclusion": "通过这些结果，研究建议LLMs针对细微变化的输入可能会学习到浅层且不稳健的知识表示；当前的真实陈述探针可能无法有效地检验模型的稳健性；未来研究需关注提升学习知识表示的稳健性。"}
{"llm_update_time": "20251015", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.11792", "html_url": "https://arxiv.org/abs/2510.11792", "title": "关于增益贝叶斯优化中的汤普森采样和双边不确定性", "title_en": "On Thompson Sampling and Bilateral Uncertainty in Additive Bayesian Optimization", "authors": "Nathan Wycoff", "background": "在贝叶斯优化（BO）中，添加假设可以缓解在高维度复杂函数建模和搜索中的双难题。然而，常见的采样函数如增益下置信边界，忽略了个维度之间的两两相关性（双边不确定性，BU），这增加了另一个层的近似假设。虽然理论上表明这样做的损失在无穷大样本情况下非常小，但在budget有限的情况下，这对实际效果的影响并不清楚。本文通过利用条件独立性，展示了支持双边不确定性汤普森采样可以高效执行的事实，并进行实证研究探讨忽略双边不确定性带来的损失，发现虽然增加的近似具有略差的表现，但在实际应用中影响甚微，这佐证了理论理解，表明忽略双边不确定性的近似在实践中对于BO是足够的，即使在非渐进状态下也是如此。", "innovation": "本文采用汤普森采样尊重双边不确定性的方式，利用条件独立性进行高效执行，并通过实证研究调查忽略双边不确定性对性能的影响，得出虽然近似具有略差的表现，但在实践中影响甚微，这佐证了理论理解，表明忽略双边不确定性的近似在实践中对于BO是足够的，即使在非渐进状态下也是如此。", "conclusion": "本文通过实证研究验证了在有限预算情况下，忽略双边不确定性在增益贝叶斯优化中的近似假设是足够的，因为虽然增益近似具有略差的表现，但在实际应用中影响甚微。"}
{"llm_update_time": "20251015", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.12029", "html_url": "https://arxiv.org/abs/2510.12029", "title": "CPR: 使用治疗性提示精炼缓解大型语言模型幻觉", "title_en": "CPR: Mitigating Large Language Model Hallucinations with Curative Prompt Refinement", "authors": "Jung-Woo Shim,Yeong-Joon Ju,Ji-Hoon Park,Seong-Whan Lee", "background": "大型语言模型（LLMs）在处理不同提示时表现出出色的流畅性，但有时会产生看似合理但实际上错误的“幻觉”事实，这会损害人们对这些模型的信任。然而，这种错误的常见但常被忽视的原因是用户使用了结构不良或模糊的提示，导致LLMs基于假设而不是实际意图生成响应。", "innovation": "本文介绍了一种名为Curative Prompt Refinement (CPR)的插拔式框架，用于治疗性提示精炼，1) 清理结构不良的提示；2) 生成额外的信息性任务描述，利用微调的小型语言模型来对齐用户意图和提示。当应用于语言模型时，我们发现CPR可以显著提高生成质量，同时减少幻觉。", "conclusion": "实证研究显示，经过CPR应用的提示超越了原提示90%以上，且无需任何外部知识。"}
{"llm_update_time": "20251015", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.12000", "html_url": "https://arxiv.org/abs/2510.12000", "title": "UALM: 统一的音频语言模型用于理解和推理", "title_en": "UALM: Unified Audio Language Model for Understanding, Generation and Reasoning", "authors": "Jinchuan Tian,Sang-gil Lee,Zhifeng Kong,Sreyan Ghosh,Arushi Goel,Chao-Han Huck Yang,Wenliang Dai,Zihan Liu,Hanrong Ye,Shinji Watanabe,Mohammad Shoeybi,Bryan Catanzaro,Rafael Valle,Wei Ping", "background": "当前音频语言模型（ALM）领域的发展侧重于将音频理解与文本到音频生成视为独立的任务。很少有研究尝试将这些任务统一起来，这一步骤对于促进高级多模态推理至关重要。现有的研究大多将音频理解和文本到音频生成视为单独的任务，尚未有效整合音频和文本数据，这限制了多模态推理模型的效果。因此，文章旨在提出一个能够同时处理音频理解和文本到音频生成，并支持复杂生成任务的多模态推理模型。", "innovation": "提出了一种名为UALM的统一音频语言模型，该模型能够同时实现音频理解、文本到音频生成以及多模态推理。首先介绍了一种UALM-Gen文本到音频语言模型，采用直接预测音频标记的方法，与现有的扩散模型不相上下。通过合理的数据混合、训练规程和推理技术，展示了单个UALM模型在音频理解、文本到音频生成以及文本推理方面能够达到与专门模型相当的质量。此外，还提出了UALM-Reason，一种利用文本和音频在中间推理步骤中的多模态推理模型，能够促进复杂生成任务的完成。这是音频研究中第一次展示跨模态生成推理的有效性，得到了主观评估的验证。", "conclusion": "通过UALM模型的研究，实现了音频理解和文本到音频生成的有效统一，同时支持复杂的多模态推理任务。该研究展示了多模态模型在音频研究中的潜在应用价值，为进一步研究奠定了基础。"}
{"llm_update_time": "20251015", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.12013", "html_url": "https://arxiv.org/abs/2510.12013", "title": "高维随机梯度下降的统计保证", "title_en": "Statistical Guarantees for High-Dimensional Stochastic Gradient Descent", "authors": "Jiaqi Li,Zhipeng Lou,Johannes Schmidt-Hieber,Wei Biao Wu", "background": "随机梯度下降（SGD）和其Ruppert-Polyak平均变体（ASGD）在现代大规模学习中占据核心地位，但在高维设置中的理论属性却很少被理解。", "innovation": "本文的关键创新在于将强效的高维时间序列工具应用于在线学习。具体来说，通过将SGD视为非线性自回归过程，并采用现有的耦合技术，证明了常学习率高维SGD的几何矩收缩现象，从而建立了迭代值的渐近平稳性。在此基础上，推导出SGD和ASGD在任意$q \textgreater= 2$及其$\text{l}^{\text{∞}}$范数下的$q$-次矩收敛，特别地，$\text{l}^{\text{∞}}$范数在高维稀疏或结构化模型中极为常用。此外，提供了精确的高概率收敛分析，进而为高维ASGD提供了概率界。通过弥补随机梯度下降理论中的关键缺口，本文提出的框架提供了分析一类广泛的高维学习算法的新型工具。", "conclusion": "本文不仅弥补了关于随机梯度下降理论的重要空白，而且为分析广泛的高维学习算法提供了新的工具箱。"}
{"llm_update_time": "20251015", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.12077", "html_url": "https://arxiv.org/abs/2510.12077", "title": "压缩性衡量复杂性：最小描述长度遇见奇异学习理论", "title_en": "Compressibility Measures Complexity: Minimum Description Length Meets Singular Learning Theory", "authors": "Einar Urdshals,Edmund Lau,Jesse Hoogland,Stan van Wingerden,Daniel Murfet", "background": "背景：研究人员试图通过优化神经网络压缩来减少计算资源的消耗，但是缺乏有效的复杂度估计方法来准确评估模型压缩的极限。", "innovation": "创新：本文引入了奇异学习理论来扩展最小描述长度（MDL）原则，应用于神经网络等奇异模型，发现基于局部学习系数（LLC）的复杂性估计与压缩性之间存在密切联系，甚至在某些情况下呈线性关系，从而为严格评估模型压缩的极限提供了一种途径。", "conclusion": "结论：本文的研究提供了通过局部学习系数（LLC）估算神经网络压缩性的方法，并展示了如何利用最小描述长度与奇异学习理论结合来确保模型压缩的极限评估更为精准和可靠。"}
{"llm_update_time": "20251015", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.12014", "html_url": "https://arxiv.org/abs/2510.12014", "title": "嵌入教师：将vLLM偏好蒸馏以实现可扩展的图像检索", "title_en": "Embedding the Teacher: Distilling vLLM Preferences for Scalable Image Retrieval", "authors": "Eric He,Akash Gupta,Adian Liusie,Vatsal Raina,Piotr Molenda,Shirom Chabra,Vyas Raina", "background": "文本-图像检索对于诸如产品推荐之类的应用是必要的。基于嵌入的方法如CLIP通过向量相似性搜索实现高效的大规模检索，但它们主要是在字面描述性的文本-图像对上进行训练，经常会无法捕捉到产品推荐应用中常见的抽象或个人信息驱动的属性（例如，“送给一个热爱园艺的母亲的礼物”）。相比之下，最先进的视觉-语言模型（vLLMs）能够灵活地对齐文本与图像，但由于其有限的上下文窗口，它们无法直接处理大目录中的检索任务。", "innovation": "本文提出了一种框架，将强大的vLLM的偏好排名蒸馏到一个基于嵌入的系统，从而保留了基于嵌入方法的推理时间可扩展性的同时，还转移了其细腻的对齐能力。实验表明，该方法在基于个人偏好产品推荐任务中显著优于现有的基于嵌入的方法，为个性化文本-图像检索提供了一个有效的解决方案。", "conclusion": "我们的方法在针对个人偏好的产品推荐任务中显著优于现有的基于嵌入的方法，能够通过向量相似性搜索在大规模图像检索中提供一个高效且个性化的解决方案。"}
{"llm_update_time": "20251015", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.12032", "html_url": "https://arxiv.org/abs/2510.12032", "title": "在大型语言模型中减轻幻觉的多阶段提示细化", "title_en": "Multi-stage Prompt Refinement for Mitigating Hallucinations in Large Language Models", "authors": "Jung-Woo Shim,Yeong-Joon Ju,Ji-Hoon Park,Seong-Whan Lee", "background": "近年来，大型语言模型（LLMs）在自然语言理解和生成任务中表现出强劲的性能。然而，LLMs在生成与事实不符但看似可信的信息（幻觉）方面仍面临挑战。研究发现，不良的提示（如语义模糊、语法错误、信息不完整等）是导致幻觉的主要原因之一，但相关研究仍相对有限。", "innovation": "本文提出了多阶段提示细化（MPR）框架，这是一个系统地改善不良提示并降低幻觉风险的多阶段方法。该框架利用小型语言模型（SLMs）针对特定错误进行微调，并通过迭代增强提示的清晰度，同时采用自我反思机制和排名机制优先考虑最相关输入。", "conclusion": "实验结果表明，通过MPR细化的提示比原始提示在幻觉基准测试中获得了超过85%的胜率，证实了MPR在减少幻觉和提高LLM输出准确性方面的有效性。此外，MPR可以与现有的后处理幻觉缓解框架结合使用，进一步增强了其多功能性。MPR提供了一种轻量级且灵活的解决方案，以增强各种领域中LLM的可靠性。"}
{"llm_update_time": "20251015", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.12054", "html_url": "https://arxiv.org/abs/2510.12054", "title": "MIARec：科学论文推荐中的相互影响意识异质网络嵌入", "title_en": "MIARec: Mutual-influence-aware Heterogeneous Network Embedding for Scientific Paper Recommendation", "authors": "Wenjin Xie,Tao Jia", "background": "随着科学文献的迅速扩张，学者们越来越需要精准且高质量的论文推荐。现有方法中，基于图的方法在利用学术网络内部固有的结构性特征方面得到了广泛关注，但这些方法往往忽视了学术网络中普遍存在的不对称学术影响力，在学习图表示时的这种忽略构成了一个限制因素。为解决这一问题，本文提出了感知相互影响的推荐（MIARec）模型。该模型通过引力方法度量学者间的相互学术影响力，并将其纳入图表示学习中消息传播过程中的特征聚合过程，同时还利用多通道聚合方法捕捉不同单一关系子网络的独立嵌入及其相互依赖嵌入，从而实现对异质学术网络的更全面理解。", "innovation": "本文提出的MIARec模型创新在于：1) 利用引力方法测量学者间的相互学术影响力，并将其应用到图表示学习的特征聚合过程中；2) 采用多通道聚合方法捕捉不同类型单关系子网络的独立嵌入及其相互依赖嵌入，增强了对异质学术网络的理解。", "conclusion": "在真实世界数据集上的广泛实验表明，MIARec模型在三个主要评估指标上均优于基线模型，这表明该模型在科学论文推荐任务中的有效性。"}
{"llm_update_time": "20251015", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.12066", "html_url": "https://arxiv.org/abs/2510.12066", "title": "AI Agents as Universal Task Solvers", "title_en": "AI Agents as Universal Task Solvers", "authors": "Alessandro Achille,Stefano Soatto", "background": "AI reasoning agents已经能够通过部署工具、模拟多种假设的结果并反思这些结果来解决各种任务。尽管这些代表已经在执行某种形式的计算，但这种计算不同于经典的执行程序的方式。文章探讨了AI代理是否能够实现通用性，即能否通过链式思考推理来完成任何可计算的任务，以及AI代理如何学习推理，是模型大小还是训练数据集大小的问题引发了讨论。", "innovation": "重新定义学习在AI代理中的角色，将其视为具有计算能力的随机动力系统，并强调时间在推理学习基础原则中的作用。从经典的归纳学习转向传递学习，传递学习的关键不是逼近过去的数据显示分布，而是捕捉其算法结构以减少找到新任务解决方案所需的时间。此外，作者提出了理论上推导的推理时间与训练时间的幂律关系，并强调了计算量越大，在无限空间和时间下，模型可能会表现出无洞察力的盲目求解行为，因此建议在扩大推理模型时，优化的关键量应是时间，而非仅仅增加模型大小。", "conclusion": "传递学习的关键在于减少在新任务中找到解决方案所需的时间，而不是重构误差。这种方法认为信息的关键作用是减少时间，而不是构建过去数据的分布。理论上，使用过去的数据显示的最快加速是紧密相关于其算法信息的。"}
{"llm_update_time": "20251015", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.12078", "html_url": "https://arxiv.org/abs/2510.12078", "title": "FedLoDrop: 弹性洛拉在联邦学习中的应用以增强一般化大型语言模型微调", "title_en": "FedLoDrop: Federated LoRA with Dropout for Generalized LLM Fine-tuning", "authors": "Sijing Xie,Dingzhu Wen,Changsheng You,Qimei Chen,Mehdi Bennis,Kaibin Huang", "background": "大型语言模型（LLMs）在特定任务上进行微调（Fine-tuning, FT）至关重要，这有助于提升准确性和相关性并减少资源消耗。然而，为了进一步增强泛化能力并降低训练成本，需要开发新的方法来优化微调过程。这一研究背景指出，当前的联邦洛拉（Federated LoRA）方法虽然能够降低成本，但存在泛化能力不足的问题。", "innovation": "该研究提出了一种新的框架——Federated LoRA with Dropout（FedLoDrop），通过在洛拉方法中的可训练矩阵的行和列应用dropout，进一步提高泛化能力。此外，研究还得出了泛化误差边界和收敛性分析，并通过实时误差与泛化误差之间的关系，解释了过拟合与欠拟合之间的基本权衡。同时，研究制定了一个优化问题，通过联合优化dropout率和资源分配来最小化泛化误差的上界。为了实现这一优化，还提出了分支定界（B\text{\textampersand}B）方法以找到全局最优解，以及一种惩罚逐次凸逼近（P-SCA）算法以高效地找到高质量的次优解。", "conclusion": "实验结果证明了提出方法的有效性，表明该方法能够减轻过拟合并提高大型语言模型的泛化能力。"}
{"llm_update_time": "20251015", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.12088", "html_url": "https://arxiv.org/abs/2510.12088", "title": "One Life to Learn: 从无指导探索推断随机环境的符号世界模型", "title_en": "One Life to Learn: Inferring Symbolic World Models for Stochastic Environments from Unguided Exploration", "authors": "Zaid Khan,Archiki Prasad,Elias Stengel-Eskin,Jaemin Cho,Mohit Bansal", "background": "现有的符号世界模型研究主要集中在可预测性强、交互数据丰富、机械简单且有人类指导的环境。然而，研究者们还需要探索更复杂且具有随机性的环境，其中的代理只有一次探索机会且没有人类干预。OneLife框架针对这种更实际且更具挑战性的环境提供了解决方案。", "innovation": "OneLife框架通过在概率编程框架中使用条件激活的程序法则建模世界动力学。这种方法能动态地构建计算图，仅通过相关法规则进行推理和优化，即使在稀疏状态下也能学习随机效应。此外，该论文提出了新的评估协议，用于评估在未指导探索条件下的方法，包括状态排名和状态保真度的评估指标。OneLife框架在无指导交互中成功学习关键环境动力学，优于基线方法16种情景中的16种，并展示了其规划能力。", "conclusion": "本研究建立了一个框架，用于自主构建未知复杂环境的程序化世界模型。这为探索复杂且不明确环境提供了新的方法论基础。"}
{"llm_update_time": "20251015", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.11910", "html_url": "https://arxiv.org/abs/2510.11910", "title": "通过Schatten-$p$正则化简化最优运输", "title_en": "Simplifying Optimal Transport through Schatten-$p$ Regularization", "authors": "Tyler Maunu", "background": "本文提出了一个使用Schatten-$p$范数正则化来恢复最优运输中的低秩结构的新通用框架。现有方法强调稀疏性和可解释性运输图或计划，但本文提供的是一系列统一且理论上一致的凸程序族，鼓励低维结构。并且，本文凸形式的特点使得可以通过直接的理论分析来推导最优条件和恢复低秩聚合和巴拿赫映射的保证。为了高效地求解提出的程序，开发了一种镜像下降算法，并证明了$p \ngeq 1$时的收敛性。实验结果显示该方法具有效率、可扩展性和能够恢复低秩运输结构的能力。", "innovation": "本文的新颖之处在于提出了一种使用Schatten-$p$范数正则化来恢复低秩结构的新框架，扩展了传统方法以促进稀疏和可解释的运输图或计划，并提供了一组统一和理论化的凸规划。开发了镜像下降算法，并证明了$p \ngeq 1$时的收敛性。实验表明该方法在效率、可扩展性和低秩运输结构恢复方面具有优越性。", "conclusion": "本文通过Schatten-$p$正则化提供了一种高效且统一的方法来简化最优运输问题，通过直接理论分析获得最优条件和恢复保证。开发的镜像下降算法证明了收敛性质，并通过合成和真实数据实验展示了其在效率、规模和恢复低秩运输结构方面的能力。"}
{"llm_update_time": "20251015", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.12121", "html_url": "https://arxiv.org/abs/2510.12121", "title": "通过目标化表示编辑在大型语言模型中实现精确属性强度控制", "title_en": "Precise Attribute Intensity Control in Large Language Models via Targeted Representation Editing", "authors": "Rongzhi Zhang,Liqin Ye,Yuzhao Heng,Xiang Chen,Tong Yu,Lingkai Kong,Sudheer Chava,Chao Zhang", "background": "大型语言模型（LLM）的属性强度控制对于适应不同用户期望的AI系统至关重要。现有的LLM对齐方法通常仅提供方向性或开放式指导，无法可靠地实现具体的属性强度。这项研究致力于解决现有方法的这一局限性。", "innovation": "提出了一种新的方法，将精确的属性强度控制重新定义为一个目标逼近问题，而不是简单的最大化；通过时差学习训练一个轻量级价值函数，预测最终的属性强度得分，从而引导LLM输出；通过基于梯度的干预手段调整隐藏表示，使模型精确地朝着特定的属性强度目标。该方法实现了对属性强度的精细、连续控制，优于简单的方向对齐。", "conclusion": "实验结果证明，该方法能够以高精度引导文本生成到用户指定的属性强度上，并且在三个下游任务中展示了效率提升：偏好数据合成、前沿逼近和优化、以及无干预推理中使用已对齐行为的精简。代码可在指定链接找到。"}
{"llm_update_time": "20251015", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.12117", "html_url": "https://arxiv.org/abs/2510.12117", "title": "Locket: 语言模型的强健特征锁定技术", "title_en": "Locket: Robust Feature-Locking Technique for Language Models", "authors": "Lipeng He,Vasisht Duddu,N. Asokan", "background": "Chatbot供应商（如OpenAI）依靠分层订阅方案来产生收入，为免费用户提供基本模型，为付费订阅者提供高级模型。然而，为了更经济地为供应商提供服务，采用细粒度的付费解锁方案（例如数学和编程高级特性）被视为可行。这需要一种特征锁定技术（FLoTE），该技术应具备以下特性：(i)有效拒绝未经授权的功能，(ii)保留解锁功能的实用性，(iii)抵御规避或未经授权的凭证共享攻击，(iv)在多个功能和用户之间具有可扩展性。现有的FLoTE（例如密码锁定模型）并不强健或可扩展。", "innovation": "我们提出了一种名为Locket的新颖的强健且可扩展的特征锁定技术（FLoTE），以支持付费解锁方案。Locket采用了新颖的合并方法，将适配器附着到一个大型语言模型（LLM）上以拒绝未经授权的功能。我们的全面评估表明，Locket在锁定功能上有效（100% 拒绝），在解锁功能上实用（解锁功能的实用性最多下降7%），稳健（攻击成功率最多为5%），并且可扩展到多个功能和客户端。", "conclusion": "Locket是第一种既强健又可扩展的FLoTE，可用于支持付费解锁方案。该方法使用了一种新颖的合并技术，将适配器附加到大型语言模型上以拒绝未经授权的功能。评估表明，Locket不仅能够有效拒绝所有锁定功能，而且对解锁功能的实用性影响较小，同时也能抵御攻击并具有可扩展性。"}
{"llm_update_time": "20251015", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.12148", "html_url": "https://arxiv.org/abs/2510.12148", "title": "通过薛定谔桥进行城市微气象的概率超分辨率", "title_en": "Probabilistic Super-Resolution for Urban Micrometeorology via a Schrödinger Bridge", "authors": "Yuki Yasuda,Ryo Onishi", "background": "本文采用了一个表示薛定谔桥问题解的神经网络，以在城市区域内实现2米温度的超分辨率化。薛定谔桥通常用于基于扩散过程描述两种数据分发之间的转换。这项研究使用了特定的薛定谔桥模型（SM），它可以将低分辨率的数据直接转化为高分辨率的数据，而常规的去噪扩散概率模型（简称为扩散模型DMs）则是从高斯噪声生成高分辨率数据。", "innovation": "这项研究创新之处在于：1) 使用了特定的薛定谔桥模型（SM），可以直接将低分辨率数据转换为高分辨率数据，而不像DMs那样从高斯噪声生成高分辨率数据。2) SM在计算成本上降低了五倍，且生成高分辨率样本的方差更大，体现出更高的不确定性量化能力。3) 由于SM降低了计算成本，本研究提出了一种基于SM的模型在微气象中实现实时超分辨率预测的可能性。", "conclusion": "研究结果表明，SM模型在保持与DM相当的准确性的同时，仅需要DM评估量的五分之一，且高分辨率样本显示出更大的方差，暗示了更好的不确定性量化。因此，基于SM的模型具有在微气象中进行实时超分辨率预测的可行性。"}
{"llm_update_time": "20251015", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.12152", "html_url": "https://arxiv.org/abs/2510.12152", "title": "跟随扰动领先者算法在分离bandits问题中的应用：兼备两种世界的最优性和实用性", "title_en": "Follow-the-Perturbed-Leader for Decoupled Bandits: Best-of-Both-Worlds and Practicality", "authors": "Chaiwon Kim,Jongyeong Lee,Min-hwan Oh", "background": "本文研究了分离的多臂老虎机（MAB）问题，其中学习者在每一轮中分别选择一个臂进行探索和一个臂进行利用。被探索臂的损失被观察但不计入，被利用臂的损失被遭受且无观察。之前的工作要么在自适应环境中（使用Decoupled-Tsallis-INF策略）实现最优的遗憾，要么通过扰动跟随领先者（FTPL）框架实现不同环境下的遗憾控制，但这些方法存在计算步骤和实用性的问题。", "innovation": "提出了一个使用Pareto扰动的跟随扰动领先者策略，该策略能够在不同环境中实现接近最优的遗憾，即在随机环境中实现常数遗憾，并且优于标准MAB的标准最优界。在对抗环境中实现最小最大最优遗憾，同时避免了Decoupled-Tsallis-INF策略中必要的凸优化步骤和FTPL框架中通常需要的重采样步骤，从而实现了巨大的计算改进，比Decoupled-Tsallis-INF快约20倍，并且在两种环境中都表现出更好的实际性能。", "conclusion": "实证结果表明，该方法优于纯探索策略，而单纯结合纯探索策略和标准利用策略则是次优的。"}
{"llm_update_time": "20251015", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.12180", "html_url": "https://arxiv.org/abs/2510.12180", "title": "通过均场演员-评论员流学习均场博弈", "title_en": "Learning Mean-Field Games through Mean-Field Actor-Critic Flow", "authors": "Mo Zhou,Haosheng Zhou,Ruimeng Hu", "background": "本文提出了均场博弈(MFGs)的均场演员-评论员(MFAC)流，这是一种结合强化学习和最优运输技术的连续时间学习动态方法，旨在解决均场博弈问题。MFAC框架通过偏微分方程(PDEs)控制的耦合梯度更新共同演化控制(演员)、价值函数(评论员)和分布组件。研究集中在如何将分布通过Wasserstein-2测地线推向均衡，即提出了最优运输测地线皮卡流(OTGP)。通过拉普拉斯函数实现了严格的收敛分析，并在适当的时标下建立了全局指数收敛性。实验结果验证了理论分析，并展示了MFAC框架在计算MFG均衡的有效性。", "innovation": "提出了均场演员-评论员流框架，并结合了强化学习和最优运输技术；提出了最优运输测地线皮卡流(OTGP)，它沿着Wasserstein-2测地线驱动分布向均衡状态收敛；通过拉普拉斯函数进行了严格的收敛分析，并建立了全局指数收敛性；强调了演员、评论员和分布组件之间的算法相互作用。", "conclusion": "通过均场演员-评论员流框架，本文在适当的时标下证明了全局指数收敛性，并通过实验展示了在计算MFG均衡的有效性。此外，研究揭示了演员、评论员和分布组件之间的算法相互作用。"}
{"llm_update_time": "20251015", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.12210", "html_url": "https://arxiv.org/abs/2510.12210", "title": "DiSTAR: 在可扩展的令牌自回归表示上进行扩散以生成语音", "title_en": "DiSTAR: Diffusion over a Scalable Token Autoregressive Representation for Speech Generation", "authors": "Yakun Song,Xiaobin Zhuang,Jiawei Chen,Zhikang Niu,Guanrou Yang,Chenpeng Du,Zhuo Chen,Yuping Wang,Yuxuan Wang,Xie Chen", "background": "最近的研究尝试将自回归（AR）制图器与基于扩散的修整器结合使用，以在连续语音表示上进行操作，虽然取得了一些进展，但在分布转移下仍然很脆弱，且提供了有限的可控性。", "innovation": "介绍了DiSTAR，一个零样本文本转语音框架，完全在离散残差矢量量化（RVQ）码空间中运行，并将AR语言模型与掩码扩散模型紧密耦合，无需强制对齐或持续时间预测。具体的创新在于：DiSTAR使用AR语言模型起草按块的RVQ令牌，并以起草为基础进行并行掩码扩散填充，以完成下一个块，从而实现块级别的并行长格式合成，同时缓解了经典的AR暴露偏差。DiSTAR通过离散码空间提供显式的控制：使用贪婪解码或样本解码，在无条件指导下生成高质量音频，支持稳健性和多样性之间的权衡，并允许通过RVQ层修剪在测试时实现可变比特率和可控计算。", "conclusion": "广泛的实验和消融实验表明，DiSTAR在鲁棒性、自然度和说话人/风格一致性方面优于最先进的零样本TTS系统，同时保持丰富的输出多样性。提供了音频样本：this https URL"}
{"llm_update_time": "20251015", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.12225", "html_url": "https://arxiv.org/abs/2510.12225", "title": "HoneyBee: 数据食谱为视觉语言推理器", "title_en": "HoneyBee: Data Recipes for Vision-Language Reasoners", "authors": "Hritik Bansal,Devandra Singh Sachan,Kai-Wei Chang,Aditya Grover,Gargi Ghosh,Wen-tau Yih,Ramakanth Pasunuru", "background": "近期视觉语言模型（VLMs）在推理任务上的表现极为出色，但构建高效的VLM推理训练数据集的原则仍不明确。这项研究介绍了多种数据整理方法，并通过仔细控制训练和评估设置，研究这些方法对VLM推理能力的影响。研究发现背景来源策略显著影响VLM性能，引入辅助信号（如图像标题）和包含文本推理均有效，而且所有数据维度的扩展（如每个图像的唯一问题数量和每个图像问题对的独特推理链数量）都能一致改善推理能力。", "innovation": "提出了HoneyBee，这是一种大规模、高质量的推理数据集，包含250万示例，35万图像问题对。使用HoneyBee训练的VLM在MathVerse上的性能超越了现有最佳模型和基础模型，分别提高了7.8%和24.8%。此外，提出了一个测试时缩放策略，降低了73%的解码成本，同时不牺牲准确性。", "conclusion": "这项研究为VLM推理数据集的整理提供了改进策略，并通过HoneyBee数据集和测试时缩放策略实现了显著的性能提升。"}
{"llm_update_time": "20251015", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.12238", "html_url": "https://arxiv.org/abs/2510.12238", "title": "基于梯度引导扩散的机遇约束规划框架", "title_en": "A Gradient Guided Diffusion Framework for Chance Constrained Programming", "authors": "Boyang Zhang,Zhiguo Wang,Ya-Feng Liu", "background": "机遇约束规划(Chance Constrained Programming, CCP)是一种解决不确定性下的优化问题的有效框架。", "innovation": "文章提出了一个新的基于梯度引导扩散的优化框架，称为GGDOpt。该框架通过三种创新点解决了CCP问题：（1）仅依赖样本集而不需知道不确定性的确切分布来处理广泛的CCP问题；（2）通过重新构形CCP为两种分布的采样问题来解决非凸性约束，充分利用了一阶和二阶梯度信息；（3）GGDOpt在轻微假设下行得到了理论收敛保证，并提供了实用的误差界。", "conclusion": "通过在前向扩散过程中逐步注入噪声以使非凸可行域凸化，GGDOpt能够引导反向采样生成渐近最优的解。实验结果显示，GGDOpt在合成数据集和无线通信波形设计任务中均优于现有方法，在解的质量和稳定性方面表现更佳，且约减少了80%的开销。"}
{"llm_update_time": "20251015", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.12206", "html_url": "https://arxiv.org/abs/2510.12206", "title": "基于碰撞模式预测的可控碰撞场景生成", "title_en": "Controllable Collision Scenario Generation via Collision Pattern Prediction", "authors": "Pin-Lun Chen,Chi-Hsi Kung,Che-Han Chang,Wei-Chen Chiu,Yi-Ting Chen", "background": "评估自动驾驶车辆（AVs）的安全性需要大量的安全关键场景，而这些场景中的碰撞由于其危险性及不常见性，现实收集变得尤为危险和难以实现。因此，研究社区集中于在仿真中生成这些安全关键场景。然而，控制碰撞类型和事故前时间（TTA）仍然具有挑战性。本文介绍了一个新的任务，即可控碰撞场景生成，旨在生成能够实现用户指定的碰撞类型和时间的轨迹，以研究自动生成所需碰撞场景的可行性。研究围绕这一主题，创建了一个大型的碰撞场景数据集，命名为COLLIDE，通过将真实驾驶记录转换为多样化碰撞，覆盖五种代表性的碰撞类型和不同TTA区间，保持了平衡。在此基础上，提出了一个框架来预测碰撞模式，这是一种紧凑且可解释的数据表示，捕捉碰撞冲击时主体车辆和对抗车辆的空间配置。通过实验表明，该方法在碰撞率和可控性上均优于强基准模型，生成的场景导致更高比例的规划器失败率，揭示了现有规划器的局限性。这表明这些场景可以提升规划器的鲁棒性，有助于不同碰撞场景下的AV部署安全提升", "innovation": "本文提出了一个名为COntrollable LIbrary of Data-enhanced Collision Environments（COLLIDE）的大型碰撞场景数据集，通过将真实驾驶记录转换为多样化且平衡的碰撞场景。并且提出了一个框架来预测碰撞模式（Collision Pattern），这是一种包含空间配置信息的紧凑和可解释表示。实验表明该方法显著优于基准方法，并且生成的场景能够提高规划器的鲁棒性，揭示了现有规划器的缺陷，有助于AVs的安全部署和优化.", "conclusion": "本文通过提出COLLIDE数据集和预测碰撞模式的框架，展示了在仿真中生成和控制特定碰撞场景的可行性。生成的场景提高了现有规划器的鲁棒性，并揭示了现有规划器的限制，为AVs的安全部署提供了支持和测试平台。"}
{"llm_update_time": "20251015", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.12260", "html_url": "https://arxiv.org/abs/2510.12260", "title": "AngularFuse: 基于角度感知的时空敏感多模态图像融合", "title_en": "AngularFuse: A Closer Look at Angle-based Perception for Spatial-Sensitive Multi-Modality Image Fusion", "authors": "Xiaopeng Liu,Yupei Lin,Sen Zhang,Xiao Wang,Yukai Shi,Liang Lin", "background": "可见-红外图像融合在自动驾驶和夜间监控等关键应用中至关重要。其主要目标是整合多模式信息以生成更适于下游任务的增强图像。尽管基于深度学习的融合方法取得了显著进展，但主流的无监督方法在实际应用中仍面临重大挑战。现有方法大多依赖手工设计的损失函数来指导融合过程，然而这些损失函数存在明显限制：首先是现有方法构建的参考图像往往缺乏细节且亮度不均；其次是广泛使用的梯度损失只关注梯度大小。", "innovation": "本文提出了一种基于角度感知的空间敏感图像融合框架（AngularFuse）。该方法首先设计了一种跨模态互补掩码模块，促使网络学习模态之间的互补信息。接着引入了一种细粒度的参考图像合成策略，通过结合拉普拉斯边缘增强和自适应直方图均衡生成更具细节和亮度平衡的参考图像。最后，引入了一种角度感知损失，这是首次在梯度域同时约束梯度大小和方向，确保融合图像保留纹理强度和正确的边缘方向。", "conclusion": "在MSRS、RoadScene和M3FD公开数据集上的综合实验表明，AngularFuse在现有主流方法中具有明显的性能优势。视觉对比进一步证实，该方法在挑战性场景中生成了更清晰、更详细的融合结果，展示了其出色的融合能力。"}
{"llm_update_time": "20251015", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.12271", "html_url": "https://arxiv.org/abs/2510.12271", "title": "动态预测：将日间预测进化至日内现实", "title_en": "The Living Forecast: Evolving Day-Ahead Predictions into Intraday Reality", "authors": "Kutay Bölat,Peter Palensky,Simon Tindemans", "background": "准确的日内预测对于电力系统运营至关重要，能够补充日渐失去相关性的日间预测。现有的日间预测会随着新信息的获取逐渐变得不再相关。因此，迫切需要一种新的方法来将日间预测实时更新为日内预测，而无需重新训练或重新推理。", "innovation": "本文提出了一种贝叶斯更新机制，能够将基于条件变分自编码器的日间完全概率性预测即时更新为日内预测。该方法通过对条件变分自编码器的结果进行观测测量的条件处理，以保持预测的概率结构，从而提供一致的点预测、分位数预测和集合预测。这种方法不仅计算效率高，而且适用于实时应用。实验表明，所提出的算法在多种预测指标上将预测准确性提高了25%，特别是在具有强烈时间相关性的时刻，性能提升显著。此外，基于模式字典的协方差结构进一步提升了预测性能.", "conclusion": "本文建立了一个理论基础坚实的方法论框架，用于现代电力系统的日内预测。该方法在家庭用电消耗和光伏发电的数据集上进行了验证，结果表明所提出的方法能够显著提高预测准确性。"}
{"llm_update_time": "20251015", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.12311", "html_url": "https://arxiv.org/abs/2510.12311", "title": "通过相互作用粒子兰德恩动力学学习潜在能量模型", "title_en": "Learning Latent Energy-Based Models via Interacting Particle Langevin Dynamics", "authors": "Joanna Marks,Tim Y. J. Wang,O. Deniz Akyildiz", "background": "本文基于粒子方法解决极大边缘似然估计（MMLE）问题的发展，开发了交互粒子算法来学习具有能量先验的潜在变量模型。研究了一个连续时间的学习框架，通过定义确定性微分方程（SDEs）来解决MMLE问题，获得了实际算法并提供了算法收敛性的理论保证。", "innovation": "提出了通过定义确定性微分方程来解决MMLE问题的一种连续时间学习框架。该研究通过粒子方法实现了实际算法的离散化，并提供了该算法收敛性的理论保证，从而证明了该方法在合成和图像数据集上的实际有效性。", "conclusion": "本文展示了通过相互作用粒子兰德恩动力学学习潜在能量模型的方法在合成和图像数据集上的有效性，并提供了算法收敛性的理论保证。"}
{"llm_update_time": "20251015", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.12269", "html_url": "https://arxiv.org/abs/2510.12269", "title": "Tensor 逻辑：AI 的语言", "title_en": "Tensor Logic: The Language of AI", "authors": "Pedro Domingos", "background": "当前的人工智能进步受限于没有一个具备所有必要功能的编程语言。虽然像PyTorch和TensorFlow这样的库提供了自动微分和高效的GPU实现，但它们都是基于Python进行扩展构建的，而Python并不是为AI设计的。它们在自动化推理和知识获取方面的缺乏支持导致了一系列拙劣的尝试。另一方面，AI专有的编程语言如LISP和Prolog则缺乏可扩展性和学习支持。", "innovation": "该论文提出了张量逻辑(Tensor Logic)，这是一种语言，通过在基础层面统一神经AI和符号AI，解决了上述问题。张量逻辑的唯一构造是张量方程，基于观察到逻辑规则和Einstein求和本质上是相同的操作，所有其他内容都可以归结为它们。论文展示了如何用张量逻辑优雅地实现神经、符号和统计AI的关键形式，包括变换器、形式推理、核机器和图形模型。张量逻辑最重要的创新在于开启了一条新的道路：在嵌入空间进行稳健推理，结合了神经网络的可扩展性和机器学习能力及符号推理的可靠性和透明性，可能成为更广泛采用AI的基础。", "conclusion": "张量逻辑有可能成为AI更广泛应用的基础，因为它将神经网络的可扩展性和机器学习能力与符号推理的可靠性和透明性相结合，开辟了在嵌入空间进行稳健推理的新方向。"}
{"llm_update_time": "20251015", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.12272", "html_url": "https://arxiv.org/abs/2510.12272", "title": "通过深度多智能体强化学习的异质RBC模型", "title_en": "Heterogeneous RBCs via deep multi-agent reinforcement learning", "authors": "Federico Gabriele,Aldo Glielmo,Marco Taboga", "background": "当前的宏观经济模型可以根据代理异质性分为两大类：一类是基于Heterogeneous-Agent New Keynesian (HANK)或Krusell-Smith (KS)方法的Heterogeneous-agent general equilibrium (GE)模型，这类模型依赖于general equilibrium和‘理性预期’假设，这些假设较为不切实际，使得模型计算非常繁琐，从而限制了模型中可以表现的异质性程度。另一类是agent-based models (ABMs)，它能够灵活包含大量任意异质的代理，但通常需要明确行为规则的设定，这会导致模型开发过程冗长且复杂。", "innovation": "本文提出了MARL-BC框架，将深度多智能体强化学习（MARL）与Real Business Cycle (RBC)模型相结合，解决了上述两大模型体系的局限性。它能够在使用单一代理时重现经典RBC结果；在大量相同代理的情况下重现KS模型的结果；并且能有效模拟复杂的代理异质性，这在传统GE模型中很难实现。", "conclusion": "我们的框架可以作为一种ABM在使用多种异质交互代理时，并且可以在极限情况下重现GE结果。因此，它是一种朝着将常常对立的建模范式综合在一起的方向迈出的一步。"}
{"llm_update_time": "20251015", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.12310", "html_url": "https://arxiv.org/abs/2510.12310", "title": "DeepTrust: 多步分类通过异质对抗表示实现鲁棒的Android恶意软件检测", "title_en": "DeepTrust: Multi-Step Classification through Dissimilar Adversarial Representations for Robust Android Malware Detection", "authors": "Daniel Pulido-Cortázar,Daniel Gibert,Felip Manyà", "background": "近年来，机器学习方法已被广泛应用于识别恶意Android应用程序。然而，这些方法仍面临潜在的对抗性示例攻击，即通过微妙操纵例子欺骗机器学习模型，导致错误预测。因此，鲁棒地检测恶意软件是亟待解决的问题。", "innovation": "本文提出了一种名为DeepTrust的新颖元启发式方法，通过排列灵活分类器，如深度神经网络，组成一个有序序列，最终决策由一个内部模型基于级联条件下作出。DeepTrust在2025 IEEE SaTML安全机器学习（SaTML）鲁棒Android恶意软件检测比赛中获得第一名，其在特征空间欺骗攻击下，性能提升最高达266%，同时保持了对非对抗性恶意软件的最佳检测率和低于1%的误报率。这种方法的有效性来自最大化的内部模型学习表示之间的差异性。通过使用能够产生数据本底上显著不同的嵌入的分类器，使得决策空间难以预测，从而阻碍了迭代扰动过程，使其难以实现，从而增强了系统的鲁棒性而不牺牲清洁样本上的准确性。", "conclusion": "DeepTrust通过级联异质嵌入的不同步骤分类，有效地提高了Android恶意软件检测的鲁棒性，实现了在对抗性攻击下的最佳性能并且不对正常样本检测造成影响。"}
{"llm_update_time": "20251015", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.12363", "html_url": "https://arxiv.org/abs/2510.12363", "title": "基于演员-评论家强化学习的机器人运动控制预训练", "title_en": "Pretraining in Actor-Critic Reinforcement Learning for Robot Motion Control", "authors": "Jiale Fan,Andrei Cramariuc,Tifanny Portela,Marco Hutter", "background": "预训练-微调范式近年来在人工智能研究中推动了诸多变革性进展，但在机器人运动控制的强化学习领域，尽管存在广泛可转移的知识，但在正式任务学习之前，每项具体技能通常都会从头开始学习。本文旨在提出一种预训练神经网络模型的范式，这些模型可以捕捉这种可转移知识，作为经典演员-评论家算法（如Proximal Policy Optimization，PPO）的强化学习过程的暖启动基础。", "innovation": "本文创新性地提出了一个基于任务无关的探索数据收集算法，旨在收集多样且动态的转换数据，通过监督学习训练Prispioceptive Inverse Dynamics Model (PIDM)，预训练权重被载入演员和评论家网络中进行初始化策略优化。实验验证该方法在七个不同的机器人运动控制任务上均显示出显著提升，相较于随机初始化，样本效率平均提升40.1%，任务性能提升7.5%。同时，进行了关键的消融研究和实证分析，揭示了该方法有效性的机制。", "conclusion": "我们提出的预训练方法显著提高了样本效率和任务性能，相较于随机初始化方法，平均样本效率提升了40.1%，任务性能提升了7.5%，并证明了首尾衔接逆动力学模型的预训练能够作为强初始化策略的基石，适用于机器人运动控制领域的演员-评论家强化学习过程。"}
{"llm_update_time": "20251015", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.12376", "html_url": "https://arxiv.org/abs/2510.12376", "title": "深监督引导自适应子采样", "title_en": "Deep Attention-guided Adaptive Subsampling", "authors": "Sharath M Shankaranarayana,Soumava Kumar Roy,Prasad Sudhakar,Chandan Aladahalli", "background": "尽管深度神经网络在性能方面提供了显著的进步，但这些提升往往伴随着更高的计算复杂性和成本。对于3D体素或视频分类等任务，由于固有的冗余性，并不总是需要所有切片或帧。这个问题亟需解决。", "innovation": "提出了一种新颖的可学习子采样框架，可以无缝集成到任何神经网络架构中。该框架采用注意力引导的采样模块，在推理过程中能够适应不同的输入，即使是在非训练阶段也能进行动态调整，从而提高性能并减少深度神经网络模型的复杂性。", "conclusion": "该方法已经在MedMNIST3D的3D医学成像数据集以及两个用于分类任务的超声视频数据集上进行了验证，包括一个在真实临床条件下收集的具有挑战性的内部数据集，证明了该方法的有效性。"}
{"llm_update_time": "20251015", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.12375", "html_url": "https://arxiv.org/abs/2510.12375", "title": "改进的中心极限定理及其Bootstrap近似方法在仿射随机逼近中的应用", "title_en": "Improved Central Limit Theorem and Bootstrap Approximations for Linear Stochastic Approximation", "authors": "Bogdan Butyrin,Eric Moulines,Alexey Naumov,Sergey Samsonov,Qi-Man Shao,Zhuo-Song Zhang", "background": "本文研究了在下降步长仿射随机逼近(Linear Stochastic Approximation, LSA)算法中Polyak-Ruppert平均迭代过程的多元正态逼近的Berry-Esseen边界。考虑了由Polyak-Juditsky中心极限定理预测的高斯分布的协方差矩阵，并建立了样本数量为$n$的逼近速度，即$n^{-1/3}$阶的凸距离。此外，还证明了乘法Bootstrap程序在约化误差中的分布近似的非渐近有效。对于后者分布的逼近速度，得到了最高为$\frac{1}{\root \nof {n} }$的结果，这显著优于Samsonov等人（2024年）之前的结果。", "innovation": "本文的创新之处在于对LSA算法中Polyak-Ruppert平均迭代过程的多元正态逼近给出了最高阶为$n^{-1/3}$的逼近速度，并且证明了乘法Bootstrap程序可以有效地近似约化误差的分布，对于后者分布的逼近速度，达到了最优的$\frac{1}{\root \nof {n} }$阶。这显著改进了之前的研究结果.", "conclusion": "本文通过研究LSA算法的Polyak-Ruppert平均迭代过程的多元正态逼近，并证明了乘法Bootstrap程序的有效性，为该领域提供了新的理论支持。"}
{"llm_update_time": "20251015", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.12379", "html_url": "https://arxiv.org/abs/2510.12379", "title": "LiteVPNet: 一种用于质量关键应用的轻量级视频编码控制网络", "title_en": "LiteVPNet: A Lightweight Network for Video Encoding Control in Quality-Critical Applications", "authors": "Vibhoothi Vibhoothi,François Pitié,Anil Kokaram", "background": "在过去的十年中，电影制作生态系统中的视频工作流程为视频流技术带来了新的应用场景，如现场虚拟制作等。这些新的工作流程需要精确的质量控制和能源效率。现有的转码方法往往无法满足这些需求，多数原因是缺少质量控制或计算负担过重。", "innovation": "提出了一个轻量级神经网络(LiteVPNet)，旨在准确预测适用于NVENC AV1编解码器的量化参数，以实现指定的VMAF得分。使用了低复杂度特征，包括比特流特性、视频复杂度度量以及基于CLIP的语义嵌入。", "conclusion": "LiteVPNet在广泛的质量目标范围内展示了平均VMAF误差低于1.2点的性能。值得注意的是，在87%以上的测试数据集中，其VMAF误差保持在2点以内，这大约是先进方法的两倍。LiteVPNet的跨各种质量区域的性能表明它能够为高价值内容传输和流媒体提供更高效的、高质量的媒体体验。"}
{"llm_update_time": "20251015", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.12403", "html_url": "https://arxiv.org/abs/2510.12403", "title": "机器人学习：教程", "title_en": "Robot Learning: A Tutorial", "authors": "Francesco Capuano,Caroline Pascal,Adil Zouitine,Thomas Wolf,Michel Aractingi", "background": "机器人学习正处于转折点，受到了机器学习的迅速发展和大规模机器人数据的日益可用的驱动。这种从基于模型的经典方法向基于数据的学习方法的转变，为自主系统解锁了前所未有的能力。本文档将引导读者从强化学习和行为克隆的基础原理，导航到能够处理多样化任务甚至不同机器人实体的通用语言条件模型。", "innovation": "本文档图示了现代机器人学习的路径，从基础的强化学习和行为克隆，到通用的语言条件模型，使机器人能够在多种任务和不同实体之间操作。作者的目标是为研究者和实践者提供理解概念和实用工具，使他们能够参与到机器人学习的发展中来，并提供了在lerobot中实现的即用型示例。", "conclusion": "本文档旨在作为机器人学习教程，通过提供基础原理、具体实用工具和指南，帮助读者理解和应用机器人学习的最新进展。"}
{"llm_update_time": "20251015", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.12392", "html_url": "https://arxiv.org/abs/2510.12392", "title": "通过自我指导和自适应切块改进生成性行为克隆", "title_en": "Improving Generative Behavior Cloning via Self-Guidance and Adaptive Chunking", "authors": "Junhyuk So,Chiwoong Lee,Shinyoung Lee,Jungseul Ok,Eunhyeok Park", "background": "生成性行为克隆（GBC）是一种简单而有效的机器人学习框架，尤其适用于多任务设置。现有的GBC方法常用开放回路（OL）控制策略，即通过扩散过程生成动作并分步骤执行，但不进行重新规划。虽然这种方法在成功率和泛化能力上表现出色，但其固有的随机性可能导致错误的动作采样，有时会引发意外的任务失败。此外，开放回路控制在嘈杂或动态环境中响应延迟，影响性能。", "innovation": "本文提出了两种新的技术以增强扩散策略的一致性和反应性：（1）自我指导，通过利用过去的观察数据来改进动作的准确度，促进前瞻性行为；（2）自适应切块，在重新反应带来的益处超过时间一致性需求时，仅选择性地更新动作序列。广泛的实验表明，本文方法在模拟和实际的机器人操作任务中显著提高了GBC性能。", "conclusion": "实验结果表明，我们的方法在广泛的模拟和实际机器人操作任务中显著提高了GBC的性能。"}
{"llm_update_time": "20251015", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.12430", "html_url": "https://arxiv.org/abs/2510.12430", "title": "神经引导采样方法在量子电路优化中的应用", "title_en": "Neural Guided Sampling for Quantum Circuit Optimization", "authors": "Bodo Rosenhahn,Tobias J. Osborne,Christoph Hirche", "background": "量子电路的移植，即在特定硬件拓扑下，使用受限的量子门集将通用的量子电路转化为等效电路，会显著增加电路长度。由于退相干效应，随着电路长度增加，计算结果的质量会大幅下降。因此，减少量子电路的门计数和提升计算效率成为重要任务。现有方法通过随机采样和标记替代策略来优化量子电路，但这些方法在采样效率方面存在挑战，导致优化耗时过长。针对这一问题，该论文提出了一种基于二维神经网络引导的采样方法，利用神经网络预测可归约的门组，提升量子电路优化的计算效率。", "innovation": "该研究提出了一种2D神经网络引导的采样方法，该方法能够预测量子电路中的可归约门组，从而大幅减少计算时间。实验结果表明，该方法在量子电路优化方面优于不同的qiskit或BQSKit优化级别。", "conclusion": "2D神经网络引导的采样方法能够有效提高量子电路优化的效率，通过预测可归约的门组，显著缩短计算时间，实际效果优于当前流行的优化工具。"}
{"llm_update_time": "20251015", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.12416", "html_url": "https://arxiv.org/abs/2510.12416", "title": "地缘政治、地缘经济学与风险：机器学习方法", "title_en": "Geopolitics, Geoeconomics and Risk:A Machine Learning Approach", "authors": "Alvaro Ortiz,Tomasa Rodrigo", "background": "本文介绍了涵盖42个国家的新兴和发展市场，包括基于市场的指标和新闻指标的数据集，如地缘政治风险、经济政策不确定性、贸易政策不确定性以及政治情绪。作者利用该数据集研究了情绪动态如何塑造主权风险，以及这些情绪指标相比传统的全球货币政策和市场波动性因素，在预测方面具有多大的价值。研究发现，虽然全球金融变量一直是主权风险的主要驱动因素，但地缘政治风险和经济政策不确定性同样扮演了重要角色，且其影响在与全球金融条件的非线性相互作用中被放大。", "innovation": "本文引入了一个新的高频日频面板数据集，结合新闻指标进行分析。通过马车竞赛式的预测模型分析，证明了纳入基于新闻的指标可以显著提高预测准确性，并通过非线性机器学习方法（尤其是随机森林）获得了最大的增益。此外，研究还强调了全球金融变量、地缘政治风险和经济政策不确定性在非线性互动中的关键作用，揭示了区域差异性，某些资产类别和新兴市场在面对政策利率冲击、全球金融波动和地缘政治风险时表现出更高的敏感性。", "conclusion": "本文的分析表明，全球金融变量仍然是主权风险的主要驱动因素，然而地缘政治风险和经济政策不确定性也扮演了重要角色，并且其影响强度通过与全球金融条件的非线性相互作用而被放大。研究还揭示了区域异质性，即某些资产类别和新兴市场在面对政策利率变动、全球金融波动和地缘政治风险冲击时表现出较高的敏感性。"}
{"llm_update_time": "20251015", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.12440", "html_url": "https://arxiv.org/abs/2510.12440", "title": "形式化模型与上下文感知安全验证的收敛性分析", "title_en": "Formal Models and Convergence Analysis for Context-Aware Security Verification", "authors": "Ayush Chaudhary", "background": "本文提出了一个形式化的框架，用于上下文感知的机器学习增强自适应系统的安全性验证。该框架提供了可证明的安全性保证，并探讨了上下文信息在这些系统安全检测能力和样本复杂性边界中的作用。", "innovation": "该研究引入了一个新的安全性属性：上下文完整性，并证明了包括样本复杂性边界、信息论极限、基于机器学习的负载生成器的收敛性保证以及组合式正确性边界等结果。", "conclusion": "对于自然家族的目标，理论上可以证明任何具有有限负载预算的静态验证器在上下文盲的情况下最多只能实现上下文完整性α，而一个具有足够的上下文信息的动态验证器可以实现超过α的上下文完整性。实验结果验证了理论预测，显示了准确的检测率随数据集增长和上下文丰富度增加而提升，训练损失在O(1/√T)速率收敛，且假阳性率在理论界限内。"}
{"llm_update_time": "20251015", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.12474", "html_url": "https://arxiv.org/abs/2510.12474", "title": "SMEC: 重新思考嵌套表示学习在检索嵌入压缩中的应用", "title_en": "SMEC: Rethinking Matryoshka Representation Learning for Retrieval Embedding Compression", "authors": "Biao Zhang,Lixin Chen,Tong Liu,Bo Zheng", "background": "大型语言模型（LLMs）生成的高维嵌入捕捉丰富的语义和句法信息，但高维嵌入增加了计算复杂性和存储需求，阻碍了实际部署。", "innovation": "提出了一个名为Sequential Matryoshka Embedding Compression (SMEC)的新训练框架。该框架引入了Sequential Matryoshka Representation Learning (SMRL)方法以减轻训练过程中的梯度方差，引入了Adaptive Dimension Selection (ADS)模块以减少降维过程中的信息降解，并引入了Selectable Cross-batch Memory (S-XBM)模块以增强高维和低维嵌入之间的无监督学习。", "conclusion": "实验表明，SMEC在实现显著维数降低的同时维持性能。在BEIR数据集上，该方法在压缩的LLM2Vec嵌入（256维度）上分别提高了1.1个和2.7个点的表现，与Matryoshka-Adaptor和Search-Adaptor模型相比。"}
{"llm_update_time": "20251015", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.12487", "html_url": "https://arxiv.org/abs/2510.12487", "title": "Diff-XYZ: 用于评估代码差异理解的基准", "title_en": "Diff-XYZ: A Benchmark for Evaluating Diff Understanding", "authors": "Evgeniy Glukhov,Michele Conti,Egor Bogomolov,Yaroslav Golubev,Alexander Bezzubov", "background": "大规模代码编辑和重构需要可靠地处理代码差异。目前缺乏专门针对代码差异理解的基准和相应的评测方法。该论文提出了一种名为Diff-XYZ的基准，包含三个监督任务：应用（旧代码+差异→新代码）、反应用（新代码-差异→旧代码）和差异生成（新代码-旧代码→差异）。这些实例来自真实的提交记录，并提供了自动化的评价指标和清晰的评价准则。这为评估大规模语言模型在代码差异理解方面的能力提供了重要的基础，进一步推动了代码差异格式和代码编辑模型的研发。", "innovation": "Diff-XYZ基准引入了三个监督任务，涵盖了代码差异理解、应用、反应用及生成，通过利用真实提交记录提供了全面的数据集和评价准则。此外，该研究通过跨格式比较不同差异表示方法，揭示了不同场景下应选用的不同格式和模型大小，从而为未来开发代码差异格式和编辑模型提供了重要的理论指导和实验证据。", "conclusion": "Diff-XYZ基准是评估和改进大规模语言模型处理代码差异能力的基础，能帮助未来进一步优化代码差异格式和编辑模型的发展。该基准已经发布在HuggingFace Hub，便于其他研究者使用和验证。"}
{"llm_update_time": "20251015", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.12636", "html_url": "https://arxiv.org/abs/2510.12636", "title": "根据数据调整噪声：基于一维过程的生成流", "title_en": "Adapting Noise to Data: Generative Flows from 1D Processes", "authors": "Jannis Chemseddine,Gregor Kornhardt,Richard Duong,Gabriele Steidl", "background": "本文介绍了使用一维去噪过程构建生成模型的一般框架。超越扩散过程，本文提出了其他实例以展示该方法的灵活性。", "innovation": "提出了一种新颖的框架，其中一维过程本身是可学习的，通过参数化噪声分布为数据适应的分位数函数实现。该构建与标准目标如流匹配和一致性模型无缝集成，学习基于分位数的噪声可以自然捕捉到重尾和紧支撑情形", "conclusion": "数值实验突显了该方法的灵活性和有效性。"}
{"llm_update_time": "20251015", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.12581", "html_url": "https://arxiv.org/abs/2510.12581", "title": "LayerSync: 自身对齐的中间层", "title_en": "LayerSync: Self-aligning Intermediate Layers", "authors": "Yasaman Haghighi,Bastien van Delft,Mariam Hassan,Alexandre Alahi", "background": "先前的研究强调了生成质量与差分模型学得表示之间的联系，表明模型中间表示的外部指导可以加速训练。本文观察到差分模型各层之间的表示质量差异，并提出了通过自身中间表示对差分模型进行正则化的新思路，使得较差层能够从更好的层中获得指导，减少了对外部监督的需求。这种方法适用于其他领域，且无需预训练模型或额外数据支持。", "innovation": "提出了一种名为LayerSync的领域无关方法，通过对模型自身中间表示进行正则化，增强了生成质量和训练效率，特别适用于流式转换器在ImageNet数据集上的训练加速和生成质量提升。此外，它还提供了一种通用的方法，可以在图像、音频、视频和运动生成等领域广泛应用，而无需额外的数据或预训练模型的支持。", "conclusion": "通过详尽评估，证明了该方法在图像生成任务中的有效性，并展示了其在其他领域的适用性。实验数据表明，使用LayerSync可以显著提高生成质量和训练效率，例如在ImageNet上将流式转换器的训练速度提高了8.75倍，生成质量提升了23.6%。该方法的相关代码已开源。"}
{"llm_update_time": "20251015", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.12368", "html_url": "https://arxiv.org/abs/2510.12368", "title": "浅层递归解码器在TRIGA Mark II反应堆中的约束传感和可靠状态估计", "title_en": "Constrained Sensing and Reliable State Estimation with Shallow Recurrent Decoders on a TRIGA Mark II Reactor", "authors": "Stefano Riva,Carolina Introini,Josè Nathan Kutz,Antonio Cammi", "background": "浅层递归解码器网络是一种新颖的数据驱动方法，能够在核反应堆等工程系统中提供精确的状态估计。该深度学习架构设计用于映射少量稀疏测量的时序轨迹到整个状态空间，包括不可观测的字段，并且能够处理噪声数据的集合策略，具有短训练时间和无需超参数调优的特点。", "innovation": "该方法对传感器位置无感知，能够处理噪声数据，通过集合策略利用短训练时间，且无需手工调优。此外，这种方法能够准确地实时重建系统中每个特征字段的状态，为反应堆数字孪生中的可解释监控和控制提供了适合的方法。", "conclusion": "该研究证明，浅层递归解码器能够在有限数据条件下准确重建TRIGA Mark II研究堆的全状态（温度、速度、压力、湍流量），并评估了其校正能力（当模型与数据存在差异时，确定稀疏测量是否能提供对解码器输出的校正）。该方法因其准确、实时的重建能力，适用于反应堆数字孪生中的可解释监控和控制。"}
{"llm_update_time": "20251015", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.12521", "html_url": "https://arxiv.org/abs/2510.12521", "title": "为什么噪声模型很重要：在学习正则化中的性能差距", "title_en": "Why the noise model matters: A performance gap in learned regularization", "authors": "Sebastian Banert,Christoph Brauer,Dirk Lorenz,Lionel Tondji", "background": "研究线性反问题有效地学习正则化器的挑战。对比了若干种学习的变分正则化方法与最优仿射重构，即最小化均方误差的最佳仿射线性变换。已知Tikhonov正则化可以达到最优重构，但需要精确的噪声协方差来正确加权数据保真项。然而，在许多实际应用中，噪声统计信息未知。因此，研究了在无噪声信息的情况下用于正则化的方法表现，关注Tikhonov、Lavrentiev和二次正则化。对于非白色噪声，理论分析和数值实验显示这些方法与最优仿射重构之间的性能差距。显示不同类型的正则化导致了不同的结果，突显了在噪声模型未明确学习时正则化结构选择的重要性。研究表明，准确建模或共同学习噪声统计信息在数据驱动的正则化中具有重大价值。", "innovation": "通过对多个学习的变分正则化方法与最优仿射重构进行分析和比较；对Tikhonov、Lavrentiev和二次正则化在非白色噪声情况下的表现进行了研究，揭示了不同类型的正则化导致不同的结果，强调即使在没有明确学习噪声模型的情况下，选择正确的正则化结构也非常重要。展示了准确建模或共同学习噪声统计信息在数据驱动正则化中的重要性。", "conclusion": "研究发现，在线性反问题中，正则化方法的表现与最优重构存在差距，这表明不同的正则化结构在未知噪声模型的情况下会影响到结果。准确地建模或共同学习噪声统计信息对于提高数据驱动的正则化方法的效果至关重要。"}
{"llm_update_time": "20251015", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.12547", "html_url": "https://arxiv.org/abs/2510.12547", "title": "Universal Adaptive Environment Discovery", "title_en": "Universal Adaptive Environment Discovery", "authors": "Madi Matymov,Ba-Hien Tran,Maurizio Filippone", "background": "机器学习中的一个开放问题是避免模型利用数据中的虚假相关性；著名的例子是水鸟数据集中背景标签的捷径。一种常见的解决方法是在多个环境中训练模型；在水鸟数据集中，这对应于通过对背景进行随机化来训练。然而，选择正确的环境是一个充满挑战的问题，因为这些环境通常不会预先知道。", "innovation": "本文提出了一个统一框架——通用自适应环境发现（Universal Adaptive Environment Discovery，UAED），学习数据变换的分布来实例化环境，并优化在该学习分布上的任何鲁棒目标函数。UAED 不需要预定义的组别或手动设计环境。此外，文章提供了 PAC-Bayes 边界和在标准状态下测试环境分布鲁棒性证明，实验证明 UAED 能够发现可解释的环境分布，提高了标准基准的最大化准确度，同时在平均准确度上保持竞争力。", "conclusion": "我们的结果显示，让环境自适应是进行离分布外泛化的实用途径。"}
{"llm_update_time": "20251015", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.12617", "html_url": "https://arxiv.org/abs/2510.12617", "title": "同模型，更好的表现：数据混洗对DNA语言模型基准测试的影响", "title_en": "Same model, better performance: the impact of shuffling on DNA Language Models benchmarking", "authors": "Davide Greco,Konrad Rawlik", "background": "大型语言模型在基因组学中的应用日益增多，因为它们能够解码复杂的生物序列。然而，评价DNA语言模型的能力是一项复杂的任务，涉及到基因组学领域的专业挑战和机器学习方法论的交汇点。这使得看似微小的实现细节会对基准测试的有效性产生重大影响。因此，研究人员需要一个标准化的基准来评估DNA语言模型的能力。", "innovation": "该研究提出了BEND（评估DNA语言模型），通过研究表明，硬件依赖的超参数（数据加载工人数和缓冲区大小）会导致相同的模型在不同硬件上表现有高达4%的虚假性能差异。研究还提出了一种简单的解决方案：在存储之前预混洗数据，可以消除硬件依赖性并保持效率。这项工作强调了标准的机器学习实践如何以意想不到的方式与特定领域的数据特征相互作用，这对于专门领域基准设计有着更广泛的影响。", "conclusion": "该工作展示了如何标准的机器学习实践与领域特定数据特征之间产生意想不到的相互作用，并指出预混洗数据是消除硬件依赖性的一种简单方法，同时保持高效率。这对于专门领域中的基准测试设计具有深远的意义。"}
{"llm_update_time": "20251015", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.12560", "html_url": "https://arxiv.org/abs/2510.12560", "title": "CoIRL-AD: 在潜在世界模型中实现协作-竞争模仿强化学习的自主驾驶", "title_en": "CoIRL-AD: Collaborative-Competitive Imitation-Reinforcement Learning in Latent World Models for Autonomous Driving", "authors": "Xiaoji Zheng,Ziyuan Yang,Yanhao Chen,Yuhang Peng,Yuanrong Tang,Gengyuan Liu,Bokui Chen,Jiangtao Gong", "background": "端到端的自主驾驶模型通常仅使用模拟学习（IL）训练，存在泛化能力差的问题。相比之下，强化学习（RL）通过最大化奖励促进探索，但面对样本效率低和不稳定收敛的挑战。为解决这些问题，一种自然的解决方案是将模拟学习和强化学习相结合。现有的方法通常采用两阶段范式，即使用IL进行预训练，然后使用RL进行微调。研究提出了一种名为CoIRL-AD的竞争性双策略框架，在训练过程中使IL和RL代理相互作用，引入了一种竞争机制，促进知识交流并防止梯度冲突。实验结果表明，在nuScenes数据集上，与基线相比，碰撞率降低了18%，泛化能力和对长尾场景的性能也得到了提升。", "innovation": "提出了一种名为CoIRL-AD的竞争性双策略框架，在训练过程中使IL和RL代理相互作用，引入了竞争机制，促进知识交流并防止梯度冲突。该方法在两个模型上取得了比基线更好的泛化能力和长尾场景性能。实验结果显示，CoIRL-AD方法在nuScenes数据集上取得了显著效果。此外，代码也已公开。", "conclusion": "CoIRL-AD方法通过结合模拟学习和强化学习，解决了自主驾驶模型泛化能力差和RL方法样本效率低的问题。实验结果证明了CoIRL-AD的有效性，在目标数据集上取得了显著的性能提高，并公开了代码。"}
{"llm_update_time": "20251015", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.12639", "html_url": "https://arxiv.org/abs/2510.12639", "title": "连续时间Sinkhorn动力学的收缩与熵生产", "title_en": "Contraction and entropy production in continuous-time Sinkhorn dynamics", "authors": "Anand Srinivasan,Jean-Jacques Slotine", "background": "近期研究表明，在有限正则化参数ε下，Sinkhorn算法的消失步长极限是一个概率测度空间中的镜像下降。这一研究为理解Sinkhorn算法的动力学提供了新的视角。", "innovation": "本文提出了两种关于Sinkhorn流的时间依赖度量下的$L^2$收缩标准，将其与某些条件期望算子的凸性联系起来。同时，得出了熵生产率的精确公式，之前仅知该值非正。研究进一步证明了扩散过程的标准半群分析系统地扩展到Sinkhorn流上。此外，定义了与非局部无穷小生成器相关的Dirichlet形式，证明了Poincaré不等式，并显示了当ε > 0时，谱间隙沿Sinkhorn流严格为正。最后，证明熵衰减呈指数形式等价于存在洛加诺夫斯基不等式。", "conclusion": "研究了Sinkhorn流的熵衰减与其洛加诺夫斯基不等式的等价性，并探讨了Sinkhorn LSI在生成模型训练中的设计原则及作为离散时间算法停止准则的应用。"}
{"llm_update_time": "20251015", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.12687", "html_url": "https://arxiv.org/abs/2510.12687", "title": "EReLiFM: Evidential Reliability-Aware Residual Flow Meta-Learning for Open-Set Domain Generalization under Noisy Labels", "title_en": "EReLiFM: Evidential Reliability-Aware Residual Flow Meta-Learning for Open-Set Domain Generalization under Noisy Labels", "authors": "Kunyu Peng,Di Wen,Kailun Yang,Jia Fu,Yufan Chen,Ruiping Liu,Jiamin Wu,Junwei Zheng,M. Saquib Sarfraz,Luc Van Gool,Danda Pani Paudel,Rainer Stiefelhagen", "background": "开放集域通用性(OSDG)旨在使深度学习模型能够识别新域中未见的类别，这对于实际应用至关重要。标记噪声阻碍了开放集域通用性的实现，因为它会破坏源域知识，使得识别已知类别和拒绝未见类别变得更加困难。现有方法在处理标记噪声的情况下(OSDG-NL)主要使用超球面原型引导的元学习，但它们在面对有限的干净标记数据时难以弥合不同域之间的差距。", "innovation": "提出了一种名为Evidential Reliability-Aware Residual Flow Meta-Learning (EReLiFM)的方法。首先，引入了一种无监督的两阶段证据损失聚类方法，以增强标签可靠性意识。其次，提出了一种残差流匹配机制，该机制能建模结构化的域和类别条件残差，从而提供超越插值增强的多样性和不确定性感知的迁移路径。在元学习过程中，模型被优化以使在干净集上更新的方向最大化噪声集上的损失减少，使用从最自信预测类别获得的伪标签进行监督。", "conclusion": "实验结果表明，EReLiFM在OSDG-NL任务上优于现有的方法，取得了最先进的性能。源代码可在此处获取：this https URL"}
{"llm_update_time": "20251015", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.12692", "html_url": "https://arxiv.org/abs/2510.12692", "title": "谁是更好的匹配者？哈佛创新挑战赛中人类与算法法官匹配的对比", "title_en": "Who is a Better Matchmaker? Human vs. Algorithmic Judge Assignment in a High-Stakes Startup Competition", "authors": "Sarina Xi,Orelia Pi,Miaomiao Zhang,Becca Xiong,Jacqueline Ng Lane,Nihar B. Shah", "background": "随着人工智能（AI）在自动化和支持复杂决策任务中的应用日益增长，人们开始关注算法与人工判断在需要语义理解和专业知识的情境下的对比。研究者将此问题应用于出版物评审和法官匹配的问题上，特别是在哈佛大学的高风险创业竞赛——哈佛总统创新挑战赛中。该竞赛颁发超过50万美元的资金给学生和校友创办的初创企业。研究者开发了一种基于人工智能的法官匹配算法——Hybrid Lexical-Semantic Similarity Ensemble (HLSE)——并将其部署在竞赛中。通过盲法评分法，将该算法的性能与人工专家匹配进行了评估。结果显示，两种方法在匹配质量上没有统计显著性差异，且平均评分几乎相同，均在5分评分中的4分左右；然而，算法能够在部署期间将原先需要整周时间的人工匹配任务缩短到几个小时内完成。这项研究证明了HLSE的匹配质量可达到与人工专家相当的水平，同时在扩展性和效率方面更加优越，说明了AI驱动的解决方案在高压力环境下的调节和提升人类决策的可能性，特别是在法官匹配方面。", "innovation": "研究展示了在高风险创业竞赛的法官匹配问题中，使用基于人工智能的Hybrid Lexical-Semantic Similarity Ensemble (HLSE)算法对人类专家的匹配效果进行对比。算法能够在保持匹配质量不逊色于人工判断的情况下，大幅提高效率，从而展示了人工智能在支持和增强人类决策方面的潜力。该算法特别应用了混合词汇语义相似度聚合的方法，以更准确地匹配法官与参赛项目。", "conclusion": "研究证明，HLSE算法在保证匹配质量的同时，提供了更高程度的可扩展性和效率，表明人工智能驱动的解决方案能够在高风险、专业领域中有效辅助和提高人类决策过程。具体来说，在哈佛总统创新挑战赛中，该算法不仅与人工专家的匹配质量无显著差异，而且能够大大提高执行效率，为类似应用场景提供了一种有效的技术替代方案。"}
{"llm_update_time": "20251015", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.12764", "html_url": "https://arxiv.org/abs/2510.12764", "title": "AnyUp: 具有通用特征上采样的方法", "title_en": "AnyUp: Universal Feature Upsampling", "authors": "Thomas Wimmer,Prune Truong,Marie-Julie Rakotosaona,Michael Oechsle,Federico Tombari,Bernt Schiele,Jan Eric Lenssen", "background": "现有的基于学习的特征上采样方法，例如DINO或CLIP，在每个特征提取器上都需要重新训练，因此无法在推理时泛化到不同的特征类型。这限制了这些方法的应用范围和效率，因为它们需要针对每个特征进行特定的训练和优化，而不能灵活地适用于各种特征类型和应用任务。", "innovation": "本文提出了AnyUp，这是一种在任何分辨率下可以应用于任何视觉特征的特征上采样方法，无需特定编码器的训练。AnyUp提出了一种在推理时特征无关的上采样架构，可以显著提高上采样质量，并且能够泛化到不同类型的特征，同时保持特征的语义信息。这种方法在实验中超越了现有技术，且高效易用，能够广泛应用于各种下游任务。", "conclusion": "AnyUp方法为特征上采样提供了一种新的解决方案，它能够在广泛的多分辨率和不同类型的特征上实现高质量的上采样，同时保持特征的语义信息。这种方法具备高效性和易于应用性，为多样化的下游任务提供了强有力的支持。"}
{"llm_update_time": "20251015", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.12728", "html_url": "https://arxiv.org/abs/2510.12728", "title": "数据模型协同进化：通过增长测试集优化LLM行为", "title_en": "Data-Model Co-Evolution: Growing Test Sets to Refine LLM Behavior", "authors": "Minjae Lee,Minsuk Kahng", "background": "机器学习领域长期存在的挑战是数据处理和模型优化之间的严格分离，这导致了缓慢的微调周期。大型语言模型（LLMs）的兴起突破了这一历史障碍，让应用程序开发者能够通过编辑提示指令立即控制模型行为。这种转变促使了一种新范式：数据-模型协同进化，其中活化的测试集和模型的指令同步进化。本文通过一个交互系统，专注于解决提示指令中编码微妙且专门领域政策的关键挑战，该交互系统帮助人们发现边缘情况、阐述期望行为的理由，并迭代地评估指令修订与不断增长的测试集之间的表现。", "innovation": "该研究通过一个交互系统，设计了一个结构化的流程来解决将微妙且专门领域的规则编码到提示指令中的关键挑战。该系统帮助人们发现边缘情况，阐述期望行为的理由，并迭代地评估指令修订与不断增长的测试集之间的表现，从而实现了数据模型的协同进化。用户研究结果表明，这种方法有助于参与者系统地完善指令并更明确地定义模糊的政策。这些成果朝着通过闭环开发方式实现更稳健和负责任的大型语言模型应用迈出了重要一步，方法是与当地偏好和政策保持协调一致。", "conclusion": "这项工作指出了通过局部偏好和政策协调一致的闭环开发方式实现了更稳健和负责任的大型语言模型应用的方向。"}
{"llm_update_time": "20251015", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.12733", "html_url": "https://arxiv.org/abs/2510.12733", "title": "HYPE: Hybrid Planning with Ego Proposal-Conditioned Predictions", "title_en": "HYPE: Hybrid Planning with Ego Proposal-Conditioned Predictions", "authors": "Hang Yu,Julian Jordan,Julian Schmidt,Silvan Lindner,Alessandro Canevaro,Wilhelm Stork", "background": "在复杂的都市环境中确保安全且可解释的运动规划需要考虑双向往来的多智能体互动。这种规划需要评估潜在的自我驾驶机动操作的成本。现有的许多计划者使用基于采样的方法生成初始轨迹，并通过优化对未来环境状态的预测来对其进行细化，这需要一个能够编码所需车辆行为的成本函数。设计这样一个成本函数在一个广泛的复杂都市场景中是非常具有挑战性的。", "innovation": "本文提出了HYPE：一种通过将从学习提案模型中得到的多模态轨迹提案作为启发式先验集成到蒙特卡洛树搜索（MCTS）细化中的混合规划方法。为了建模双向互动，引入了一种自我条件化的占用预测模型，使场景感知的推理保持一致。通过考虑提案驱动的指导，HYPE大大简化了细化中成本函数的设计，仅需最小化基于网格的成本术语。在nuPlan和DeepUrban大规模真实世界基准测试中的评估表明，HYPE能够有效实现最先进的性能，特别是在安全性与适应性方面。", "conclusion": "HYPE混合规划方法通过将多模态轨迹提案作为启发式先验纳入MCTS细化，有效简化了成本函数设计，并通过占用预测模型增强了场景感知能力，在复杂的都市环境中，HYPE在安全性与适应性方面均达到了最先进的性能。"}
{"llm_update_time": "20251015", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.12778", "html_url": "https://arxiv.org/abs/2510.12778", "title": "波前编码用于适应不变的近眼显示器", "title_en": "Wavefront Coding for Accommodation-Invariant Near-Eye Displays", "authors": "Ugur Akpinar,Erdem Sahin,Tina M. Hayward,Apratim Majumder,Rajesh Menon,Atanas Gotchev", "background": "本文提出了一个新的近眼显示方法，通过适应不变性解决立体显示中的融像-调节冲突问题。该系统结合了折射透镜眼内镜片与新型波前编码衍射光学元件，与预处理卷积神经网络共同工作。通过端到端学习联合优化波前编码光学元件和图像预处理模块，解决了眼光学引入的限制孔径和色差等问题，并且将神经传输函数和对比度敏感度函数结合进了损失模型，以考虑相关知觉效果。为了应对轴外失真，还在预处理模块中引入了位置依赖性。", "innovation": "提出了将波前编码衍射光学元件与预处理卷积神经网络结合的近眼显示方法，使用可微分的视网膜成像模型处理眼光学限制，并将神经传输函数和对比度敏感度函数结合进了损失模型。此外，还引入了预处理模块中的位置依赖性来应对轴外失真。", "conclusion": "通过严格的基于仿真分析，结果表明所设计的衍射光学元件展现了从4焦度不等的深度范围内的适应不变性。"}
{"llm_update_time": "20251015", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.12750", "html_url": "https://arxiv.org/abs/2510.12750", "title": "VQArt-Bench: 一份富有语义的视觉问答基准数据集用于艺术与文化遗产生", "title_en": "VQArt-Bench: A semantically rich VQA Benchmark for Art and Cultural Heritage", "authors": "A. Alfarano,L. Venturoli,D. Negueruela del Castillo(University of Zurich, Max Planck Society)", "background": "现有的多模态大型语言模型在视觉和语言联合任务中已经展示了显著的能力，但在视觉艺术分析等复杂领域中，现有的视觉问答（VQA）基准通常无法评估深入的语义理解能力。这些问题往往局限于简单的语法结构和表面属性，无法捕捉人类视觉探索的多样性和深度。这种局限性促使模型更多地依赖统计捷径而非进行视觉推理。", "innovation": "该论文提出了VQArt-Bench，这是一种大型视觉问答基准数据集，专门用于艺术与文化遗产生领域。通过一种新颖的多智能体流程构建，该基准集合作用了专门的智能体来生成精炼、验证且语言多样的问题。基准集从相关视觉理解维度结构化设计，旨在测试模型在解读象征意义、叙事和复杂视觉关系方面的能力。论文评估了包括14种最先进的MLLMs的表现，揭示了当前模型在简单计数任务等方面存在显著局限，并且揭示了内部模型与开源模型之间的性能差距。", "conclusion": "该评估展示了现有最先进模型在某些任务上的不足，并表明了VQArt-Bench对于促进和评估具有深度语义理解能力的视觉问答模型的重要性。"}
{"llm_update_time": "20251015", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.12795", "html_url": "https://arxiv.org/abs/2510.12795", "title": "CuMPerLay: Learning Cubical Multiparameter Persistence Vectorizations", "title_en": "CuMPerLay: Learning Cubical Multiparameter Persistence Vectorizations", "authors": "Caner Korkmaz,Brighton Nuwagira,Barış Coşkunuzer,Tolga Birdal", "background": "在处理图像时，流形多参数持久性（Multiparameter Persistent Homology, MP）提供了一种自然且强大的拓扑工作方式，然而其使用受到多元滤波结构复杂性和向量化MP时的困难所限制。", "innovation": "提出了CuMPerLay，这是一种新颖的可微向量化层，使立方体多参数持久性（Cubical Multiparameter Persistence, CMP）能够集成到深度学习管道中。CuMPerLay通过分解CMP为个体、可学习的一参数持久性组合，并且通过学习联合bifiltration函数来进行矢量化。该方法在Swin Transformers等最先进的架构中实现了无缝使用。", "conclusion": "在基准医疗影像和计算机视觉数据集上的实验显示，CuMPerLay在分类和分割性能上具有优势，尤其是在数据样本有限的场景下。CuMPerLay为将全局结构信息整合到深度网络中以进行结构化图像分析提供了有希望的方法。"}
{"llm_update_time": "20251015", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.12773", "html_url": "https://arxiv.org/abs/2510.12773", "title": "Dr.LLM: 在大语言模型中的动态层路由", "title_en": "Dr.LLM: Dynamic Layer Routing in LLMs", "authors": "Ahmed Heakl,Martin Gubri,Salman Khan,Sangdoo Yun,Seong Joon Oh", "background": "大语言模型（LLMs）在处理每个标记时都要通过所有变换器堆栈的层，这导致了简单查询的计算浪费，而深入推理需要的复杂查询则缺乏灵活性。现有的适配深度方法可以提高效率，但它们依赖于昂贵的推理时搜索、架构变化或大规模再训练，在实践中往往在效率提高的同时降低了准确性。", "innovation": "引入了一种可回抄的框架——Dr.LLM，动态路由层的大语言模型。该框架为预训练模型配备了轻量级的每层路由器，决定跳过、执行或重复一个块。路由器通过明确监督进行训练：利用蒙特卡洛树搜索（MCTS），我们得到了在预算的计算条件下能够保存或提高准确性的高质量层配置。设计中包含窗池法的稳定路由、面向类别的焦点损失以及瓶颈MLP路由器，确保在类别不平衡和长序列时的稳健性。", "conclusion": "在ARC（逻辑）和DART（数学）数据集上，该方法提高了高达3.4%的准确性，同时每个示例平均节省了5层。路由器在领域外任务（MMLU、GSM8k、AIME、TruthfulQA、SQuADv2、GPQA、PIQA、AGIEval）上也能实现有效的泛化，准确率仅下降0.85%，并且性能优于之前的路由方法最多7.7%。总体而言，该方法展示了明确监督的路由器能够使冻结的大语言模型适应预算感知、准确性驱动的推理，而不改变基模型权重。"}
{"llm_update_time": "20251015", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.12744", "html_url": "https://arxiv.org/abs/2510.12744", "title": "Dendrograms of Mixing Measures for Softmax-Gated Gaussian Mixture of Experts: Consistency without Model Sweeps", "title_en": "Dendrograms of Mixing Measures for Softmax-Gated Gaussian Mixture of Experts: Consistency without Model Sweeps", "authors": "Do Tien Hai,Trung Nguyen Mai,TrungTin Nguyen,Nhat Ho,Binh T. Nguyen,Christopher Drovandi", "background": "该论文探讨了Gaussian混合专家（Gaussian Mixture of Experts，GME）模型中softmax门控（softmax-gated）的统计框架，特别是重点解决了模型参数估计和模型选择中的三个长期挑战：（1）门控参数的共同平移非可识别性；（2）门控-专家内在的相互作用，使得似然函数内产生了耦合的微分关系；（3）softmax条件密度造成的分子分母的紧密耦合。这些挑战导致模型参数估计困难以及模型选择复杂性增加。论文还考虑了模型未正则化的情况，即模型参数过多时，介绍了近似非可识别方向上的MLE收敛率和相关多项式方程的可解性之间的关系。此外，针对模型选择，提出了基于混合测量树状图的softmax-Gaussian混合专家模型的选择策略，该方法在模型过拟合情况下能有效地选择专家数量且避免了多尺寸训练。", "innovation": "论文的核心创新在于开发了一种统一的统计框架，提出了针对softmax-Gated GME模型的Voronoi类型损失函数，并建立了最大似然估计量（MLE）的有限样本收敛速度。提出了一种基于混合测量树状图的选择策略，该策略在模型过拟合情况下能有效地选择专家数量，在样本量增加时可避免多尺寸训练，同时在模型未正规范化的条件下，能够准确恢复专家数量并实现预测的参数估计速率，甚至在模型错误指定的情况下仍能稳健地工作。", "conclusion": "最终，在合成数据模拟中，论文验证了理论的准确性，能够准确地恢复专家数量，并实现参数估计速率；在玉米组学数据集上，基于树状图指导的softmax-Gated GME模型能够选择适当的专家数量，揭示混和测量的层次结构，稳定似然函数，提供可解释的表型-基因型映射，表现优于传统的模型选择标准。"}
{"llm_update_time": "20251015", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.12789", "html_url": "https://arxiv.org/abs/2510.12789", "title": "UniFusion: 视觉语言模型作为统一编码器在图像生成中的应用", "title_en": "UniFusion: Vision-Language Model as Unified Encoder in Image Generation", "authors": "Kevin Li,Manuel Brack,Sudeep Katakol,Hareesh Ravi,Ajinkya Kale", "background": "尽管最近在视觉生成方面的进展非常显著，但现有的大多数架构仍然依赖于针对图像和文本的不同编码器。这种分离限制了扩散模型在跨模态推理和知识转移方面的性能。以前的努力尝试通过使用视觉语言模型的最后层信息、使用多个视觉编码器或训练大型联合模型来解决这一问题，但这些方法需要大量的计算资源和大规模的数据，限制了它们的应用范围。", "innovation": "本文提出了UniFusion，一种基于扩散的生成模型，该模型由一个冻结的大规模视觉语言模型（VLM）条件化，作为统一的多模态编码器。UniFusion的核心是一种分层注意力池化（LAP）机制，该机制从冻结的VLM的文本和视觉标记中抽取高层语义和低层细节，以条件化扩散生成模型。此外，提出了VLM-Enabled Rewriting Injection with Flexible Inference (VERIFI)，它仅在模型内提示重写过程中基于VLM生成的文本标记条件化扩散变换器（DiT）。本文证明了LAP在文本-图像对齐生成方面优于其他浅层次融合架构，并且VERIFI结合了条件分布对齐和VLM的推理能力，提高了推理的能力和灵活性。此外，编辑任务的微调不仅提高了生成中的文本-图像对齐，还展示了强大的泛化能力。", "conclusion": "通过训练，单张图像编辑任务的模型能够零样本泛化到多个图像参考，进一步证明了Unified Encoder设计UniFusion的优越性。"}
{"llm_update_time": "20251015", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2310.13862", "html_url": "https://arxiv.org/abs/2310.13862", "title": "针对去中心化联邦学习的竞争力攻击", "title_en": "Competitive Advantage Attacks to Decentralized Federated Learning", "authors": "Yuqi Jia,Minghong Fang,Neil Zhenqiang Gong", "background": "去中心化联邦学习（DFL）允许客户端（如医院和银行）无需中央调度服务器即可联合训练机器学习模型。在每次全局训练轮次中，各客户端在自身训练数据上训练本地模型，然后交换本地模型进行聚合。", "innovation": "本文提出了SelfishAttack这一新的针对DFL的攻击家族。SelfishAttack中，一组自私的客户端试图在结果中获得竞争优势，即自私客户端最终学习到的本地模型比非自私客户端的更准确。通过精心设计本地模型发送给每个剩余的非自私客户端实现这一目标。作者将找到这些本地模型的问题形式化为一个优化问题，并提出了解决方法，证明了当DFL使用不同聚合规则时，该方法可以找到优化问题的最优解。", "conclusion": "理论上，作者展示了其方法找到优化问题的最优解。实验中，表明SelfishAttack成功地增加了自私客户端本地模型与非自私客户端本地模型之间的准确度差距（即竞争优势）。此外，当扩展到提高竞争优势时，SelfishAttack 较之投毒攻击取得了更大的准确度差距。"}
{"llm_update_time": "20251015", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2311.01953", "html_url": "https://arxiv.org/abs/2311.01953", "title": "乐观的多代理策略梯度", "title_en": "Optimistic Multi-Agent Policy Gradient", "authors": "Wenshuai Zhao,Yi Zhao,Zhiyuan Li,Juho Kannala,Joni Pajarinen", "background": "在协作的多代理学习任务中，如果多代理学习方法（特别是多代理策略梯度MAPG方法）因过度拟合其他代理的次优行为而导致代理们收敛于一个次优的联合策略时，会产生相对过度概括（RO）问题。尽管多代理策略梯度方法产生当前最先进的结果，但目前还没有公布针对RO问题的解决方案。", "innovation": "该论文提出了一种通用但简单的框架，可在MAPG方法中实现乐观更新，从而缓解RO问题。这种方法涉及裁剪优势以消除负值，从而促进乐观更新。此外，提供形式分析证明，所提出的方法在固定点保留最优性。该方法在包括多代理MuJoCo和Overcooked基准任务的多种任务中表现出卓越性能，优于多个强基线在19项测试任务中的13项。", "conclusion": "该论文通过提出一种有效的解决多代理策略梯度方法中RO问题的框架，展示了在多种多代理学习任务中的优越性能，并且在固定点保留了最优性。"}
{"llm_update_time": "20251015", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2302.09904", "html_url": "https://arxiv.org/abs/2302.09904", "title": "WW-FL: 安全与隐私保护的大规模联邦学习", "title_en": "WW-FL: Secure and Private Large-Scale Federated Learning", "authors": "Felix Marx,Thomas Schneider,Ajith Suresh,Tobias Wehrle,Christian Weinert,Hossein Yalame", "background": "联邦学习（FL）是一种高效的大规模分布式机器学习方法，通过在客户端设备上保持训练数据来保证数据隐私。然而，近期的研究揭示了FL中的漏洞，这不仅影响了安全性，还可能导致通过中毒攻击披露个人模型更新中的敏感信息以及全局模型的聚合过程中敏感信息的披露。现有的FL保护措施在独立应用时存在不足，且创建有效的组合面临挑战。", "innovation": "我们提出了WW-FL，一个结合了安全多方计算（MPC）和分层联邦学习的创新框架，以保证数据和全局模型的隐私。WW-FL的一个显著特点是它可以防止恶意客户端直接中毒模型参数，将其限制为更不具破坏性的数据中毒攻击。此外，我们还提供了与Meta的CrypTen MPC框架集成的基于PyTorch的联邦学习实现，以系统地衡量WW-FL的性能和鲁棒性。", "conclusion": "我们的广泛评估表明，WW-FL是一个有前景的解决方案，可以实现安全和隐私保护的大规模联邦学习。"}
{"llm_update_time": "20251015", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2406.02613", "html_url": "https://arxiv.org/abs/2406.02613", "title": "ACCO: Accumulate While You Communicate for Communication-Overlapped Sharded LLM Training", "title_en": "ACCO: Accumulate While You Communicate for Communication-Overlapped Sharded LLM Training", "authors": "Adel Nabli(MLIA, Mila),Louis Fournier(MLIA),Pierre Erbacher(MLIA),Louis Serrano(MLIA),Eugene Belilovsky(Mila),Edouard Oyallon(MLIA)", "background": "训练大规模语言模型（LLM）依赖于使用多个GPU的分布式实现，通过分片优化器并行计算梯度。然而，在数据并行设置中同步梯度会导致通信开销增加，开销随着工作节点数量增加而增长，限制了并行化效率。局部优化算法虽然降低了通信成本，但因阻止优化器状态分片而产生了较高的内存成本，阻碍了可扩展性。", "innovation": "提出了一个名为ACCO（Accumulate while you Communicate）的内存高效分布式LLM训练优化算法。ACCO通过在同步延迟梯度的同时计算新梯度，减少了GPU空闲时间，并支持异构硬件。为解决延迟更新带来的收敛问题，ACCO引入了一种创新技术，确保训练动态与标准分布式优化保持一致。", "conclusion": "与ZeRO-1相比，ACCO方法显著更快且在异构硬件上具有良好的可扩展性。"}
{"llm_update_time": "20251015", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2211.15931", "html_url": "https://arxiv.org/abs/2211.15931", "title": "继续环境中的后验采样", "title_en": "Posterior Sampling for Continuing Environments", "authors": "Wanqiao Xu,Shi Dong,Benjamin Van Roy", "background": "现有的后验采样强化学习（PSRL）方法主要针对周期性环境，而本文旨在发展适用于持续性环境的PSRL扩展方法，使其能够与扩展到复杂环境的智能体设计自然集成。该方法在每个时间步骤，根据环境的后验分布采样时更新模型，从而保持一个统计上合理的环境模型，并根据该模型执行最大化预期 $\boldsymbol{\frac{1}{\text{折扣因子}}} -$ 折扣回报的策略。这种方法对于基于周转时间的折扣因子，证明了 $\tilde{O}(\tau S \boldsymbol{\frac{\text{动作数}}{\boldsymbol{\frac{1}{\text{折扣因子}}}}} T)$ 的贝叶斯遗憾上界，其中 $\tau$ 是奖励平均时间，$S$ 是环境状态数，$A$ 是动作数。这表明该算法在现实场景中的应用具有较强的泛化能力。", "innovation": "本文提出了继续PSRL方法，该方法能够维持一个统计上合理的环境模型，并根据模型执行最大化预期折扣回报的策略。同时，通过在每一步概率性地更换模型，引入了随机探索机制，解决了持续性环境下的探索与利用问题。这种方法是首次正式定义并严格分析具有随机探索的重采样方法。此外，这种方法还能够应用于复杂的环境，并在模型更新时保持智能体模型的一致性，从而提高算法的性能。", "conclusion": "本文研究了继续环境下的后验采样在强化学习中的应用，证明了该方法在持续性环境下的效率，并通过严格的分析证明了其优越性。该方法不仅能够维持一个统计上合理的环境模型，并根据模型执行优化策略，而且能有效地解决探索与利用的问题。此外，本文还展示了继续PSRL方法在复杂环境中的适用性和优越性，从而为未来的强化学习研究提供了新的思路。"}
{"llm_update_time": "20251015", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2410.22954", "html_url": "https://arxiv.org/abs/2410.22954", "title": "基于来源可靠性估计的检索增强生成", "title_en": "Retrieval-Augmented Generation with Estimation of Source Reliability", "authors": "Jeongyeon Hwang,Junyoung Park,Hyejin Park,Dongwoo Kim,Sangdon Park,Jungseul Ok", "background": "检索增强生成（RAG）是一种有效的方法，通过从外部数据库中检索信息来增强大型语言模型（LLMs）的客观准确性，这些数据库通常由各种来源组成，用于补充LLMs内部有限的知识。然而，标准的RAG框架在检索信息时可能会遇到错误，因为它仅依赖于查询与文档的相关性，忽视了这些来源的异质可靠性。", "innovation": "提出了一种新的多源RAG框架——可靠性感知RAG（RA-RAG），该框架通过跨多个来源交叉验证信息来估计来源的可靠性，并利用这种信息优先选择高可靠性和高相关性的文档，从而确保生成更稳健和准确的回复。RA-RAG首先通过跨多个来源交叉验证来估计来源的可靠性，然后从可靠性最高和最相关的前κ个来源中检索文档，并使用加权多数投票（WMV）聚合信息，以确保可扩展性不牺牲性能。", "conclusion": "全面的实验证明，RA-RAG在来源可靠性异质的场景中始终优于基线，在源增加时仍能高效扩展。此外，我们展示了RA-RAG估计现实世界来源可靠性的能力，突显了其实用性。我们的代码和数据可在RA-RAG中获得。"}
{"llm_update_time": "20251015", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2411.06276", "html_url": "https://arxiv.org/abs/2411.06276", "title": "多视图多数投票学习算法：直接最小化PAC-贝叶斯边界", "title_en": "Multi-View Majority Vote Learning Algorithms: Direct Minimization of PAC-Bayesian Bounds", "authors": "Mehdi Hennequin,Abdelkrim Zitouni,Khalid Benabdeslem,Haytham Elghazel,Yacine Gaci", "background": "PAC-贝叶斯框架显著提升了对统计学习的理解，特别是在多数投票方法的应用上。尽管取得了许多成功，但该框架在多视图学习中的应用仍未得到充分探索，而多视图学习涉及多种互补的数据表示。", "innovation": "该研究扩展了PAC-贝叶斯理论应用于多视图学习，并引入基于Rényi距离的新泛化界。此外，研究提出了第一和第二阶Oracle PAC-贝叶斯界，并将C界扩展到多视图设置中。为了理论与实践相结合，设计了与理论结果一致的高效自我边界优化算法。", "conclusion": "该研究通过得出基于Rényi距离的新泛化界、提出多视图下的Oracle PAC-贝叶斯界、设计高效优化算法，填补了多视图学习中PAC-贝叶斯理论的空白，促进了该领域的实践应用。"}
{"llm_update_time": "20251015", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2410.23223", "html_url": "https://arxiv.org/abs/2410.23223", "title": "COMAL：一种用于与一般偏好对齐大语言模型的收敛元算法", "title_en": "COMAL: A Convergent Meta-Algorithm for Aligning LLMs with General Preferences", "authors": "Yixin Liu,Argyris Oikonomou,Weiqiang Zheng,Yang Cai,Arman Cohan", "background": "许多对齐方法，包括基于人类反馈的强化学习（RLHF），依赖于布拉德利-特里奖赏假设，但这一假设不能充分捕捉人类偏好中的全部范围和复杂性。传统上，自博弈算法在寻找纳什策略时要么发散，要么仅在修改后的游戏中收敛到纳什策略，即使在简单的合成环境中也无法保持对所有其他策略的50%胜利率保证。因此，需要一种新的方法来解决这一问题。", "innovation": "提出了一个新的元算法，即 Convergent Meta Alignment Algorithm (COMAL)，其灵感来源于博弈论中的收敛算法。该算法被证明最后一个迭代收敛到精确的纳什策略，并且在合成数据集和偏好优化数据集上显示出有效性。COMAL 简单，可以与许多现有的方法无缝集成，进行最少的更改，并在几次实验中始终维持较高的胜利率。", "conclusion": "COMAL 已经被应用于几个大型语言模型，并且在所有与之比较的算法下，它始终分别保持了超过 60.2% 和 56.8% 的胜利率。该算法在与不同模型的对战中表现出了有效性，促进了大语言模型与一般偏好对齐的有效性。"}
{"llm_update_time": "20251015", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2305.14782", "html_url": "https://arxiv.org/abs/2305.14782", "title": "IBCL: 面向稳定性-可塑性折衷的零样本模型生成", "title_en": "IBCL: Zero-shot Model Generation under Stability-Plasticity Trade-offs", "authors": "Pengyuan Lu,Michele Caprio,Eric Eaton,Insup Lee", "background": "连续学习领域的算法已研究了折衷稳定性和可塑性贸易之间的平衡，但大多数研究集中在获取具有特定贸易偏好的模型上。当前在满足特定贸易偏好的连续学习问题下的方法（CLuST）中，主流技术依赖于重温学习，这在需求新的模型时需要重新训练，而不效率地消耗了大量资源，特别是在需要多个不同贸易偏好的模型时。为了解决这个问题，作者提出了Imprecise Bayesian Continual Learning (IBCL），一种能够高效解决CLuST问题的算法。IBCL使用凸组合代替重新训练，在常量时间执行任务。IBCL能够根据新任务，（1）以模型参数分布的凸包更新知识库并（2）通过无附加训练的凸组合生成单个帕累托最优模型，因此，通过IBCL获取特定贸易偏好的模型是零样本的。实验证明，IBCL在平均任务准确性和峰值任务准确率上分别最多可提高44%和45%，同时保持近零到正向的回传性，并且内存开销会收敛到常数。此外，在多目标强化学习任务中，IBCL能够保持相同的帕累托前沿hypervolume，同时大幅降低训练成本，IBCL的训练开销保持恒定，与所请求的偏好数量无关。", "innovation": "作者提出的IBCL算法解决了特定贸易偏好的连续学习问题（CLuST），通过取代重新训练的方式，使用常数时间的凸组合。IBCL能够在没有额外训练的情况下生成给定贸易偏好的单一帕累托最优模型，这使得按指定偏好获取模型成为零样本。IBCL在多个任务上的表现均优于现有的CLuST算法，在某些指标上能够提高44%至45%的准确率，同时保持低到零的反向传输性，并且内存和训练开销均保持稳定状态。IBCL还在多目标强化学习任务中表现出色，维持了相同的帕累托前沿体积，而显著降低了训练成本。该算法的独特之处在于其高效性和灵活性，能够根据不同的需求快速生成所需的模型，而无需额外的训练和高昂的计算成本。", "conclusion": "IBCL能够在保持模型性能的同时，大幅度降低训练和内存开销，使得在解决连续学习问题下的特定贸易偏好问题时更加高效且灵活。IBCL在多个实验中的结果表明，它不仅能够达到甚至超越当前最先进技术的分类准确率，还能有效处理多个偏好请求，并在多目标强化学习任务中降低训练成本而不牺牲性能。这种新颖的方法为连续学习领域提供了新的解决方案，特别是在需要处理复杂且大量贸易偏好的场景下显得尤为重要。"}
{"llm_update_time": "20251015", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2412.15426", "html_url": "https://arxiv.org/abs/2412.15426", "title": "本地调整图的维度缩减", "title_en": "Dimension Reduction with Locally Adjusted Graphs", "authors": "Yingfan Wang,Yiyang Sun,Haiyang Huang,Cynthia Rudin", "background": "DR算法已经被证明对于理解和探索大规模高维数据集非常重要，特别是在转录组学数据中寻找集群。初始阶段的DR方法通常会将原始高维数据转换为图，图中的每条边表示数据点对之间的相似性或差异性。但由于高维距离的可靠性问题和高维数据中提取的信息有限，这个图往往是次优的，特别是在数据集规模增加的情况下。通过选择嵌入的特定部分的数据点来缩小数据集，DR方法可以更清晰地观察到集群，因为提取的子图更为可靠。", "innovation": "该论文提出了LocalMAP，一种新的人工智能算法，它能局部动态调整图形结构，从而优化DR过程。通过动态抽取子图并在线更新图，LocalMAP能够在其他DR方法可能忽视或合并的真实集群中识别并分离出集群。", "conclusion": "通过在生物数据集上的案例研究，展示了LocalMAP的优势，强调了该方法在真实世界问题中帮助用户更准确地识别集群的作用。"}
{"llm_update_time": "20251015", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2501.11866", "html_url": "https://arxiv.org/abs/2501.11866", "title": "使用标注和未标注数据评估多个模型", "title_en": "Evaluating multiple models using labeled and unlabeled data", "authors": "Divya Shanmugam,Shuvom Sadhuka,Manish Raghavan,John Guttag,Bonnie Berger,Emma Pierson", "background": "在缺乏大量标注数据的情况下，评估机器学习分类器仍然具有挑战性。虽然标注数据可能非常昂贵或难以获取，但未标注数据则非常丰富。现有方法通常仅依赖标注数据来评估分类器性能，但在面对多个分类器、连续分类器得分以及大量未标注数据时，这种方法的实际效用存在一定局限性。", "innovation": "本文引入了一种新方法 Semi-Supervised Model Evaluation (SSME)，该方法利用标注和未标注数据来评估机器学习分类器，使其能够估计真实标签和分类器预测之间的联合分布，并用此模型来估计与分类器分数和真实标签相关的任何指标（如准确性或预期校准误差）。这种新方法能够在四个常见应用场景中更准确地评估模型性能，特别是在子数据集和语言模型评估方面。", "conclusion": "实验结果表明，SSME方法比其他方法更为准确，使用唯一标签数据估计性能时，误差降低了5.1倍，使用排名第二的方法估计时，误差降低了2.4倍。此外，该方法提高了对测试分布子集（如特定人口子群体）的性能评估以及对语言模型的性能评估的准确性。"}
{"llm_update_time": "20251015", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2501.08737", "html_url": "https://arxiv.org/abs/2501.08737", "title": "资源受限的联邦持续学习：什么是关键？", "title_en": "Resource-Constrained Federated Continual Learning: What Does Matter?", "authors": "Yichen Li,Yuying Wang,Jiahua Dong,Haozhao Wang,Yining Qi,Rui Zhang,Ruixuan Li", "background": "联邦持续学习（FCL）旨在通过在边缘设备上依次保留先前知识并适应新数据，实现隐私保护的数据流训练。现有FCL文献着重于数据隐私和访问先前数据的限制，但对训练开销没有要求。然而，在实际场景中，边缘设备受存储、计算预算和标签速率等资源的限制，这样的要求不合理。因此，作者使用大规模基准重新审视此问题，并在不同资源受限的环境下分析最新FCL方法的表现。实验涉及多种典型FCL技术、六个数据集以及两类增量学习场景。研究发现，在资源受限的环境下，现有的FCL方法均无法达到预期性能，且这种结论在敏感性分析中保持一致，表明大多数现有FCL方法过于依赖资源，不适合实际部署。此外，研究指出在资源约束下典型FCL技术的表现，并为未来的FCL研究方向提供了指导思想。", "innovation": "对FCL方法在资源受限条件下的性能进行研究，并指出现有方法的不足之处，提出未来研究方向。", "conclusion": "现有FCL方法在资源受限条件下无法实现预期性能，多数方法过于依赖资源，在实际部署中不合适。未来研究需要关注在资源受限条件下FCL方法的有效性和优化。"}
{"llm_update_time": "20251015", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2501.19205", "html_url": "https://arxiv.org/abs/2501.19205", "title": "RIGNO：任意区域上PDE算子学习的基于图的稳健准确框架", "title_en": "RIGNO: A Graph-based framework for robust and accurate operator learning for PDEs on arbitrary domains", "authors": "Sepehr Mousavi,Shizheng Wen,Levi Lingsch,Maximilian Herde,Bogdan Raonić,Siddhartha Mishra", "background": "学习任意域上的偏微分方程（PDE）解算子具有挑战性，因为这涉及到多种可能的形状和复杂的物理现象。现有的方法难以捕捉这些复杂性和多变性，特别是在基于点云的数据上进行学习时，准确性和鲁棒性难以保证。", "innovation": "提出了一种端到端的基于图神经网络（GNN）的神经算子框架RIGNO，用于从任意域点云数据中学习PDE解算子。RIGNO通过下采样的区域网格将数据在输入/输出点云之间映射，并包含确保时空分辨率不变性的新元素。", "conclusion": "RIGNO在各种时间依赖性和稳态PDE测试集上表现出显著的准确性，并能稳健地泛化到未见过的空间和时间分辨率。而且，该方法的表现优于现有的神经算子基线。"}
{"llm_update_time": "20251015", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2502.02631", "html_url": "https://arxiv.org/abs/2502.02631", "title": "ParetoQ：在极低比特LLM量化中改善扩增定律", "title_en": "ParetoQ: Improving Scaling Laws in Extremely Low-bit LLM Quantization", "authors": "Zechun Liu,Changsheng Zhao,Hanxian Huang,Sijia Chen,Jing Zhang,Jiawei Zhao,Scott Roy,Lisa Jin,Yunyang Xiong,Yangyang Shi,Lin Xiao,Yuandong Tian,Bilge Soran,Raghuraman Krishnamoorthi,Tijmen Blankevoort,Vikas Chandra", "background": "量化模型大小与精度之间的最佳权衡点一直是持续的争论焦点。虽然一些人支持4比特量化，另一些人则提倡1.58比特量化。然而，缺乏一个统一的多比特量化框架使得结论相对不稳定。该研究提出了ParetoQ，首个统一的框架，使得可以在1比特、1.58比特、2比特、3比特和4比特量化设置中进行严谨对比研究。", "innovation": "ParetoQ为不同比特量化提供了一个统一框架，通过优化训练方案和细化量化函数，超越了针对特定比特宽度的先前所有方法。特别地，ParetoQ的三元600M参数模型在仅使用五分之一参数的情况下，超过了此前最佳的三元3B参数模型的准确率。", "conclusion": "在规模与精度权衡中，三比特、二比特和三比特量化通常优于四比特和二进制量化。考虑硬件限制，二比特量化在内存缩减和加速方面表现出色。"}
{"llm_update_time": "20251015", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2412.11979", "html_url": "https://arxiv.org/abs/2412.11979", "title": "AlphaZero神经缩放和Zipf定律：棋盘游戏和幂律的故事", "title_en": "AlphaZero Neural Scaling and Zipf's Law: a Tale of Board Games and Power Laws", "authors": "Oren Neumann,Claudius Gros", "background": "神经缩放规律在多个领域已经被观察到，但目前为止缺乏对这种现象原因的普遍理解。最近的理论认为幂律损失源于Zipf定律，这个幂律在多个领域如自然语言中被观察到。一种理论断言，当Zipf分布的任务量子按照频率降序学习时，语言缩放律就会出现。本文通过研究AlphaZero（一种强化学习算法）在训练和推断数据中的幂律缩放，采用了语言模型缩放模型进行分析。游戏状态随着环境结构中的树形结构遵循Zipf定律，研究了缩放律指数与Zipf定律指数之间的相关性。", "innovation": "本文通过AlphaZero强化学习算法探讨了神经缩放与Zipf定律的关系，并提出了以下创新点：首先，发现训练和推断数据中的游戏状态遵循Zipf定律，这表明AlphaZero在学习游戏状态时，按照状态频率的降序进行优化，尽管这种顺序与建模复杂性成反比。其次，研究了模型规模的逆缩放（模型随规模增大未能改进）与异常Zipf曲线之间的相关性，其中终局状态是最常见的状态之一。第三，展示了大型模型在优化过程中转移注意力到较不重要的状态，损害了对早期重要状态的理解。", "conclusion": "研究发现了AlphaZero在训练和推断过程中游戏状态的Zipf定律分布，以及大型模型在学习中优先处理较不重要状态的现象，这些发现有助于理解神经网络在处理复杂任务时的缩放行为，并为神经网络的设计和优化提供了新的视角。"}
{"llm_update_time": "20251015", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2501.14050", "html_url": "https://arxiv.org/abs/2501.14050", "title": "GraphRAG 受击", "title_en": "GraphRAG under Fire", "authors": "Jiacheng Liang,Yuhui Wang,Changjiang Li,Rongyi Zhu,Tanqiu Jiang,Neil Gong,Ting Wang", "background": "GraphRAG 通过将外部知识组织成多尺度的知识图谱，改进了检索增强生成（RAG），使语言模型在生成过程中能够结合广泛背景和详细信息。虽然 GraphRAG 在各个领域都取得了成功，但其安全影响尚未得到充分研究。因此，有必要考察 GraphRAG 对于攻击的脆弱性，特别是在中毒攻击方面的脆弱性。研究发现，尽管 GraphRAG 的基于图的索引和检索机制使得现有的 RAG 中毒攻击效果较差，但它同样存在新的攻击面。", "innovation": "该研究提出了 GragPoison，这是一种新颖的攻击方法，利用底层知识图谱中共有的关系来构建能够同时影响多个查询的中毒文本。GragPoison 的三个关键策略是：（i）关系注入，引入虚假知识；（ii）关系增强，放大中毒影响；（iii）叙事生成，将恶意内容嵌入连贯文本。实验证实，GragPoison 在多个 GraphRAG 变体上具有高效率（最高 98% 的成功率）和高可扩展性（使用不到 68% 的中毒文本）.", "conclusion": "该研究揭示了 GraphRAG 的一项重要安全挑战，并提出了有效的防御措施。虽然找到了一些可行的防御策略，但也指出了未来研究的方向。"}
{"llm_update_time": "20251015", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2502.03698", "html_url": "https://arxiv.org/abs/2502.03698", "title": "我的学习策略有多脆弱？现代行为克隆策略的普遍敌对扰动攻击", "title_en": "How Vulnerable Is My Learned Policy? Universal Adversarial Perturbation Attacks On Modern Behavior Cloning Policies", "authors": "Akansha Kalra,Basavasagar Patil,Guanhong Tao,Daniel S. Brown", "background": "学习从演示（LfD）算法在机器人操作任务中展现出了良好的效果，但它们对脱机普遍扰动攻击的脆弱性尚未被充分研究。本文全面研究了对经典和近期提出的算法（包括行为克隆（BC）、LSTM-GMM、隐式行为克隆（IBC）、扩散策略（DP）以及向量量化行为变换器（VQ-BET））的对抗性攻击。实验表明，当前大多数方法对对抗性扰动非常敏感，并且这些攻击在算法、架构和任务之间常常可转移。这项工作首次进行了系统性的不同LfD算法对白盒和黑盒攻击的脆弱性研究。", "innovation": "本文首次全面研究了不同LfD算法对白盒和黑盒攻击的脆弱性，并通过实验证明了当前大多数方法对对抗性扰动非常敏感，并具有的可转移性，从而引发了关于黑盒攻击的安全性担忧。此外，我们研究涵盖了广泛使用的行为克隆算法。", "conclusion": "我们的研究揭示了现代BC算法的脆弱性，这为未来解决此类问题提供了方向。我们发现大多数当前的方法在对抗性扰动非常脆弱，且跨算法、架构和任务的攻击通常是可转移的。"}
{"llm_update_time": "20251015", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2502.03854", "html_url": "https://arxiv.org/abs/2502.03854", "title": "通过有界优势学习实现的镜像下降演员评论家", "title_en": "Mirror Descent Actor Critic via Bounded Advantage Learning", "authors": "Ryo Iwaki", "background": "强化学习（RL）算法中的正则化是一项核心组件。镜像下降价值迭代（MDVI）在价值和策略更新中使用克劳斯-勒布勒散度（Kullback-Leibler divergence）和熵作为正则化器。尽管MDVI在离散动作域中表现出色且具有强大的理论保证，但在连续动作域中，包含克劳斯-勒布勒散度和熵的正则化方法的表现不如仅包含熵的正则化方法。", "innovation": "作者提出了镜像下降演员评论家（MDAC）作为MDVI在连续动作域中的一种演员-评论家风格的实现，并通过在其评论家损失函数中限制演员的日志密度项，显著提高了其经验性能。作者还将MDAC与优势学习相关联，证明了在某种情况下限制优势项是有益的，并且探索了有效的限制函数选择。", "conclusion": "通过适当的限制函数选择，MDAC在连续动作域中表现优于强大的非正则化方法和仅包含熵的正则化方法。限制优势项在MDAC中的应用和理论分析的结合，提供了正则化增强反馈学习算法性能的见解。"}
{"llm_update_time": "20251015", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2502.10138", "html_url": "https://arxiv.org/abs/2502.10138", "title": "在具约束的线性函数近似的Markov决策过程中的高效验证性强化学习", "title_en": "Provably Efficient RL under Episode-Wise Safety in Constrained MDPs with Linear Function Approximation", "authors": "Toshinori Kitamura,Arnob Ghosh,Tadashi Kozuno,Wataru Kumagai,Kazumi Kasaura,Kenta Hoshino,Yohei Hosoe,Yutaka Matsuo", "background": "研究了在约束马尔可夫决策过程（CMDP）中的强化学习（RL）问题，其中智能体在满足每个时期预期总效用值约束的前提下，最大化预期累积奖励。尽管该问题在表征设置下已有充分理解，但在函数近似方面的理论成果仍相对缺乏。", "innovation": "提出了一种线性CMDP的RL算法，该算法在每个时期内保证约束不被违反，并实现了期望累积后悔量级为$\tilde{\text{O}}(\text{sqrt}(K))$。此外，该方法在计算效率上相当高效，与问题特定参数的多项式扩展有关，而不依赖于状态空间大小。", "conclusion": "结果表明，该方法大大优于近期的线性CMDP算法，这些算法要么违背约束要么产生指数级的计算成本。"}
{"llm_update_time": "20251015", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2412.00382", "html_url": "https://arxiv.org/abs/2412.00382", "title": "通过双师知识蒸馏实现公平图神经网络", "title_en": "Toward Fair Graph Neural Networks Via Dual-Teacher Knowledge Distillation", "authors": "Chengyu Li,Debo Cheng,Guixian Zhang,Yi Li,Shichao Zhang", "background": "图神经网络（GNNs）在各种实际应用中展示了强大的图表示学习性能。然而，它们经常由于敏感属性（如宗教或性别）产生偏差预测，这一问题在现有方法中被忽视。近年来，许多研究致力于减少GNN中的偏差。但这些方法往往依赖于部分数据的训练（例如，只使用节点特征或图结构），尽管这可以提高公平性，但由于利用可用的图信息有限，往往会导致模型实用性降低。", "innovation": "本文提出了一种有效策略来平衡公平性和实用性在知识蒸馏中的应用。具体来说，提出了一种新的公平学习框架FairDTD，基于双教师蒸馏，利用因果图模型来指导和优化蒸馏过程的设计。FairDTD引入了两个公平导向的教师模型：特征教师和结构教师，以促进双蒸馏，同时使学生模型从教师那里学习公平性知识，并利用完整数据来减轻实用性损失。此外，通过引入图级蒸馏间接补充图信息，在训练过程中提供知识转移的辅助，以及引入节点特定的温度模块以提高公平知识的综合转移。", "conclusion": "在不同的基准数据集上的实验表明，FairDTD 在保持高模型实用性的同时实现了最优公平性，展示了其在公平图表示学习中的有效性。"}
{"llm_update_time": "20251015", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2503.14357", "html_url": "https://arxiv.org/abs/2503.14357", "title": "基于Wasserstein距离的核主成分分析在聚类应用中的研究", "title_en": "Wasserstein-based Kernel Principal Component Analysis for Clustering Applications", "authors": "Alfredo Oneto,Blazhe Gjorgiev,Giovanni Sansavini", "background": "许多数据聚类应用需要处理不能用向量表示的对象。在这种情况下，袋矢量表示法通过离散分布描述复杂对象，并且Wasserstein距离提供了条件良好的不相似性度量。核方法通过将距离信息嵌入到便于分析的特征空间中进行了扩展，但是现有的聚类框架还没有结合Wasserstein距离和核方法来处理分布型数据的无监督框架。文献指出，本文填补了这一空白。", "innovation": "本文提出了一个计算上可行的框架，将Wasserstein度量与核方法整合以进行聚类。该框架可以同时处理向量型和分布型数据，适用于多种领域。具体创新点包括：(i) 使用多个参考分布高效地近似配对的Wasserstein距离；(ii) 基于Wasserstein距离构建移位的正定核函数，并结合核主成分分析进行特征映射；(iii) 提出可扩展的、距离无关的有效性指数，用于聚类评估和核参数优化。", "conclusion": "实验结果表明，该框架在电力分配图和真实世界时间序列上的有效性及效率。"}
{"llm_update_time": "20251015", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2504.12075", "html_url": "https://arxiv.org/abs/2504.12075", "title": "用于燃料逆向设计的生成深度学习框架", "title_en": "Generative Deep Learning Framework for Inverse Design of Fuels", "authors": "Kiran K. Yalamanchi,Pinaki Pal,Balaji Mohan,Abdullah S. AlRamadan,Jihad A. Badra,Yuanjiang Pei", "background": "传统的燃料筛选方法存在局限性，无法有效捕捉复杂的结构-性能关系。因此，需要一种新的方法来加速燃料的逆向设计，提高分子重建的精度和研究辛烷值（RON）预测的准确性，同时确保化学上的有效性。", "innovation": "提出了一个结合Co-优化变分自编码器（Co-VAE）架构和定量结构-性质关系（QSPR）技术的生成深度学习框架。该框架利用自编码器的潜在空间来增强分子重建，并准确估计研究辛烷值。通过富集的GDB-13数据库和优化超参数来训练模型，以平衡重构保真度、化学有效性和辛烷值预测。独立的回归模型进一步改进了辛烷值预测，差分进化算法也用于高效导航潜在空间，识别具有高RON的潜在燃料分子候选物。这种方法能够扩展应用于不同目标性质，实现燃料设计相关的大化学空间的系统探索。", "conclusion": "该生成模型可以适应不同的目标性质，使大规模化学空间的系统探索成为可能，从而改进了燃料设计的实用性与可靠性。该框架可以通过纳入额外的合成性标准来进一步扩展，提高新燃料的从头设计的适用性和可靠性。"}
{"llm_update_time": "20251015", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2504.19176", "html_url": "https://arxiv.org/abs/2504.19176", "title": "Newton-Puiseux Analysis for Interpretability and Calibration of Complex-Valued Neural Networks", "title_en": "Newton-Puiseux Analysis for Interpretability and Calibration of Complex-Valued Neural Networks", "authors": "Piotr Migus", "background": "复杂值神经网络（CVNNs）特别适合处理相位敏感信号，如心电图（ECG）、雷达/声纳和无线同相/正交（I/Q）流。然而，它们的可解释性和概率校准方面的研究仍然相对不足。", "innovation": "本文提出了一种Newton--Puiseux框架，通过（i）对不确定输入附近的logit差异拟合一个小型、角点感知的多项式近似，（ii）使用Newton--Puiseux展开将此近似因式分解以获得解析分支描述符，包括指数、重数和方向。这些描述符为原网络提供相位对齐的方向，并允许通过重数指导的温度调整进行改进校准。该方法不需要修改神经网络架构，并适用于任何具有将复杂logits转换为实数模的CVNN。", "conclusion": "相比未校准的softmax和标准后处理基线，该方法在两个案例研究中——MIT-BIH心律失常（ECG）数据集和RadioML 2016.10a（无线调制）——提高了Expected Calibration Error (ECE)。此外，还提供了置信区间、非参数检验，并量化了估计分支重数不准确度的敏感性。"}
{"llm_update_time": "20251015", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2505.10833", "html_url": "https://arxiv.org/abs/2505.10833", "title": "MergeBench：一种融合领域专业化大语言模型的基准", "title_en": "MergeBench: A Benchmark for Merging Domain-Specialized LLMs", "authors": "Yifei He,Siqi Zeng,Yuzheng Hu,Rui Yang,Tong Zhang,Han Zhao", "background": "现有的模型合并方法虽然显示出前景，但其评估在模型规模和任务多样性上有限，这对于大规模、领域特定的大语言模型的应用性提出了质疑。为了应对这些挑战，作者引入了MergeBench，这是一个全面的评估套件，旨在大规模评估模型合并。", "innovation": "MergeBench基于最新开源语言模型，包括2亿到9亿参数规模的Llama和Gemma家族模型，并覆盖五个关键领域：指令跟随、数学、多语言理解、编码和安全。通过标准化微调和评估协议，评估了八个代表性的合并方法在多任务性能、遗忘和运行时效率方面的表现，提供了实用的算法选择指南，并展示了模型合并在更强大基础模型上表现更好，以及合并系数调整和稀疏化技术可以提高知识保留的见解。", "conclusion": "尽管模型合并仍然存在一些挑战，如大型模型的计算成本、领域内表现与多任务模型之间的差距以及模型合并对标准大语言模型训练管道的潜在作用未充分探索，但MergeBench为未来研究提供了基础，旨在加深对模型合并的理解及其实际应用。"}
{"llm_update_time": "20251015", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2505.12421", "html_url": "https://arxiv.org/abs/2505.12421", "title": "固定点可解释性", "title_en": "Fixed Point Explainability", "authors": "Emanuele La Malfa,Jon Vadillo,Marco Molinari,Michael Wooldridge", "background": "本文提出了固定点解释的概念，这一概念借鉴了'何以质疑'的原则，通过递归应用来评估模型及其解释者之间相互作用的稳定性。固定点解释具有最小性、稳定性和忠实性等属性，能够揭示模型的隐藏行为和解释的局限性。研究者为多种解释工具定义了收敛条件，包括基于特征的方法和如稀疏自编码器等机理工具，并提供了多个数据集和模型，包括LLM（大型语言模型）Llama-3.3-70B的定量和定性结果。", "innovation": "1. 引入了固定点解释的概念及其稳定性评估方法。\n2. 为不同类型的解释工具（包括基于特征的工具和机理工具）定义了收敛条件。\n3. 提供了多个数据集和模型的实验结果，包括LLM，展示了其有效性与实用性。", "conclusion": "本文通过引入固定点解释的概念，为模型解释的稳定性提供了一个新的评估框架，并为不同类型的解释工具制定了收敛条件。实验结果表明，这种新的解释方法能够有效地揭示模型的隐藏行为，增强解释的精确性和可靠性。"}
{"llm_update_time": "20251015", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2505.12477", "html_url": "https://arxiv.org/abs/2505.12477", "title": "重建 vs 联合嵌入：从潜在空间预测在自我监督学习中的可证明优势", "title_en": "Joint Embedding vs Reconstruction: Provable Benefits of Latent Space Prediction for Self Supervised Learning", "authors": "Hugues Van Assel,Mark Ibrahim,Tommaso Biancalani,Aviv Regev,Randall Balestriero", "background": "自监督学习（SSL）中的重建和联合嵌入已成为主要的两大范式。重建方法侧重于从输入空间的不同视图中恢复原始样本。相比之下，联合嵌入方法在潜在空间中对齐不同视图的表示。两种方法各有优势，但由于缺乏明确的指导方针来选择它们，实践中很难做出抉择。", "innovation": "通过利用两种方法的闭式解，精确分析了视图生成过程（如数据增强）对学习表示的影响。发现重建和联合嵌入方法在样本数量增加时都要求最小的增强与无关特征之间的对齐程度以达到近似最优解。研究表明，在无关特征幅度大的场景中，联合嵌入方法更优，因为它们对齐的条件更弱。", "conclusion": "这些发现不仅明确了两种范式之间的权衡，还证实了在真实世界具有挑战性的数据集上，联合嵌入方法的实证成功。"}
{"llm_update_time": "20251015", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2505.13755", "html_url": "https://arxiv.org/abs/2505.13755", "title": "Panda：用于混沌动态预测的预训练模型", "title_en": "Panda: A pretrained forecast model for chaotic dynamics", "authors": "Jeffrey Lai,Anthony Bao,William Gilpin", "background": "混沌系统本质上对小误差极为敏感，这使得构建能够预测现实世界动力系统（如流体流动或神经活动）的数据驱动模型变得具有挑战性。现有的方法要么是专门针对单个体时序列训练的模型，要么是在缺乏内在动力学结构的巨大时序列数据库上训练的模型。基于动力学系统理论，本文希望填补这一空白，引入了一种新的方法来处理混沌动态系统的预测问题。", "innovation": "本文提出了Panda（Patched Attention for Nonlinear Dynamics），一种预训练模型。Panda在由进化算法发现的20000个合成混沌动力系统数据集上进行了训练。尽管只训练于低维常微分方程，Panda能够自发地预测偏微分方程，表现出零样本预测看不见的混沌系统的性能，并保持了短期准确性和长期统计数据。此外，还展示了微分方程的神经缩放定律，强调了预训练模型在探讨非线性动力学等抽象数学领域的潜力。", "conclusion": "Panda展示了在混沌动力学领域应用预训练模型的潜力，能够在未知的混沌系统上实现零样本预测，并且自发地提升了其预测复杂系统的性能。这一研究结果可能为将来的动态系统预测模型开发提供新的方向和路径。"}
{"llm_update_time": "20251015", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2505.09458", "html_url": "https://arxiv.org/abs/2505.09458", "title": "变分降秩自编码器", "title_en": "Variational Rank Reduction Autoencoders", "authors": "Jad Mounayer,Alicia Tierz,Jerome Tomezyk,Chady Ghnatios,Francisco Chinesta", "background": "降秩自编码器(RRAEs)通过截断SVD在潜在空间应用了一个正则化，增强了自编码器的能力，但因其确定性，使用它们进行生成任务并不直观。而变分自编码器（VAEs）由于学习了一个概率的潜在空间，因此在生成方面表现出色。已有的这两种模型各有优劣：RRAEs在降维方面表现较好，而VAEs则在生成方面更为出色。这篇文章提出了变分降秩自编码器（VRRAEs），试图结合两者的优点。研究表明，通过限制地采样RRAEs的潜在空间，并进一步使用KL散度进行正则化，可以显著提升VRRAEs的效果，优于RRAEs和VAEs。此外，SRVD（由SVD诱导的正则化）使得VRRAEs不仅在生成方面优于VAEs，还减少了潜在空间后验坍塌的可能性。文章通过合成数据集和MNIST、CelebA、CIFAR-10等实际数据集进行实验，验证了VRRAEs在许多基于FID评分的生成和插值任务中的优越性，展示了其在对抗坍塌时的鲁棒性。", "innovation": "变分降秩自编码器VRRAEs通过结合降秩自编码器和变分自编码器的优势，解决了确定性和生成性的矛盾。它通过限制地采样RRAE的潜在空间并通过KL散度进行进一步的正则化，既提升了生成质量，又减小了后验坍塌的概率。此外，文章在多个真实世界数据集上验证了VRRAEs在生成和插值任务中的优越性，尤其是在对抗后验坍塌时的鲁棒性方面。", "conclusion": "变分降秩自编码器（VRRAEs）结合了降秩自编码器和变分自编码器的优点，通过合理的采样策略和正则化方法，在生成质量和对抗后验坍塌方面均优于现有方法。通过合成数据集和实际数据集的实验验证，文章证明了VRRAEs在多个生成任务中的优越性能。新的开放源代码实现JAX（Equinox）也已发布，以便进一步研究和应用。"}
{"llm_update_time": "20251015", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2505.16690", "html_url": "https://arxiv.org/abs/2505.16690", "title": "您的预训练LLM其实是无监督的信心校正器", "title_en": "Your Pre-trained LLM is Secretly an Unsupervised Confidence Calibrator", "authors": "Beier Luo,Shuoyuan Wang,Sharon Li,Hongxin Wei", "background": "对于预训练语言模型(PLMs)来说，为了更好地适应人类偏好和下游任务，需要进行后训练。虽然大多数PLMs具有良好的置信度校准能力，但经过后训练的语言模型(PoLMs)常常表现出过度自信的倾向，这对关键应用的可靠性构成威胁。现有方法在调整PoLMs时遇到的主要障碍是缺乏针对每个具体下游任务的标注数据。", "innovation": "本文提出了一个名为DACA（Disagreement-Aware Confidence Alignment）的无监督方法，用于优化后训练置信度校准中的参数（例如温度$\tau$）。该方法通过仅使用一致的例子进行校准，有效解耦了预测不一致对校准的影响，避免了温度缩放过大导致的校准不足问题，从而提高了校准性能。", "conclusion": "实验结果表明，DACA方法在开源和API基础的大语言模型（如GPT-4o）上的平均ECE（校准误差）得到了显著改进，最高改善达15.08%，在常见基准测试中显示出有效性。"}
{"llm_update_time": "20251015", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2505.21391", "html_url": "https://arxiv.org/abs/2505.21391", "title": "有限样本分析任意特征下的线性时间差分学习", "title_en": "Finite Sample Analysis of Linear Temporal Difference Learning with Arbitrary Features", "authors": "Zixuan Xie,Xinyu Liu,Rohan Chandra,Shangtong Zhang", "background": "线性TD($\boldsymbol{\text{λ}}$)是政策评估中最具基础性的强化学习算法之一。以往的研究通常在特征线性独立的假设下确定收敛率，但在许多实际场景中并不成立。本文则在没有进行算法修改或增加额外假设的前提下，首次为任意特征下的线性TD($\boldsymbol{\text{λ}}$)建立了$L^2$收敛率，同时适用于折扣奖励和平均奖励的设置。", "innovation": "本文的创新在于无需对算法进行修改或增加任何假设，即可在任意特征的情况下，为线性TD($\boldsymbol{\text{λ}}$)建立$L^2$收敛率。此外，本文还针对任意特征可能导致的解的非唯一性问题，提出了一种新的随机逼近结果，该结果使得解收敛于解集而非单一解点。", "conclusion": "本文的研究结果适用于折扣奖励和平均奖励的设置，并为线性TD($\boldsymbol{\text{λ}}$)算法在实际应用中的收敛性提供了理论支持。"}
{"llm_update_time": "20251015", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.06907", "html_url": "https://arxiv.org/abs/2506.06907", "title": "使用结构驱动的随机偏微分方程进行图上的不确定性估计", "title_en": "Uncertainty Estimation on Graphs with Structure Informed Stochastic Partial Differential Equations", "authors": "Fred Xu,Thomas Markovich", "background": "图神经网络已经在各种网络建模任务中取得了显著成果，但在图上的不确定性估计，特别是在分布变化的情况下，仍然是一项具有挑战性的任务。传统不确定性估计未能考虑到图结构和标签分布带来的随机性，增加了不确定性估计的复杂性。本文在现有研究的基础之上，构建了一个新的消息传递方案，结合了从高斯过程方法驱动的随机偏微分方程中的结构信息，以改善图上的不确定性估计精度，尤其是在标签信息量不同情况下。", "innovation": "将随机偏微分方程（SPDE）与高斯过程联系起来，通过类比SPDE和图神经网络（GNN）消息传递，提出了一种新的消息传递方案，该方案同时考虑了空间和时间的不确定性，并允许对协方差核光滑度进行显式控制，从而提高了具有高低标签信息量的图上的不确定性估计。", "conclusion": "通过在具有不同标签信息量的图数据集上进行大量的异常分布外（OOD）检测实验表明，作者提出的方法比现有方法更具有稳定性和优越性。"}
{"llm_update_time": "20251015", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.10412", "html_url": "https://arxiv.org/abs/2506.10412", "title": "Time-IMM：一种不规则多模态多元时间序列的语料库和基准", "title_en": "Time-IMM: A Dataset and Benchmark for Irregular Multimodal Multivariate Time Series", "authors": "Ching Chang,Jeehyun Hwang,Yidan Shi,Haixin Wang,Wen-Chih Peng,Tien-Fu Chen,Wei Wang", "background": "在医疗保健、气候建模和金融等领域，实际应用中的时间序列数据通常具有不可预测性、多元性及杂乱性，采样频率不一致，模态不同步，且存在大量缺失值。现有基准通常假设干净、定期采样、单一模式的数据，这在研究与实际部署之间造成了显著的差距。", "innovation": "引入了Time-IMM数据集，专门针对原因驱动的不规则多模态多元时间序列中的时间序列不规则性进行记录，分为触发机制、约束机制和伪影机制九种类型。还提出了IMM-TSF基准库，以支持不规则多模态时间序列的异步整合与现实评估，包括专用融合模块，如时间戳到文本融合模块和多模态融合模块，支持最近效平均和注意力机制集成策略。实验表明，在不规则时间序列数据中明确建模多模态性显著提升了预测性能。", "conclusion": "Time-IMM和IMM-TSF为实现条件下时间序列分析奠定了基础。数据集可从以下网址获取：该网址，请访问；基准库可以从以下网址访问：该网址。"}
{"llm_update_time": "20251015", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2505.24069", "html_url": "https://arxiv.org/abs/2505.24069", "title": "数据结构视角下的大语言模型结构推理能力评估", "title_en": "Can LLMs Reason Structurally? An Evaluation via the Lens of Data Structures", "authors": "Yu He,Yingxi Li,Colin White,Ellen Vitercik", "background": "随着大型语言模型（LLMs）承担的任务越来越复杂，理解其算法推理能力变得至关重要。现有的评估主要集中在独立、分离的任务上。本文提出了一种统一的诊断视角：结构推理，即理解与操作诸如顺序、层次和连接等关系的能力。本文通过引入DSR-Bench基准，系统性地评测LLMs在通过经典数据结构进行结构推理的能力，从而为算法逻辑有意义的抽象提供可解释的框架。DSR-Bench覆盖了20种数据结构、35种操作以及4,140个合成生成的问题示例，且无污染。该基准的分层设计能够揭示具体的失败模式，而全自动化评估则保证了客观和一致的评估。通过对十种最新LLM进行评测，发现存在关键限制：最优秀模型在困难实例上的得分仅为0.498。进一步的评估套件显示模型在空间数据和自然语言场景中表现差强人意，并且无法对自身生成的代码进行推理。DSR-Bench提供了一种结构推理的规范诊断工具，有助于暴露推理瓶颈并指导开发更强大的、可靠的LLMs。", "innovation": "提出了结构推理作为评估LLMs新视角，并通过DSR-Bench基准系统性地评估LLMs的结构推理能力。该基准引入了20种数据结构、35种操作和4,140个合成生成的问题示例，且无污染，有助于揭示具体的失败模式，并通过全自动化评估确保评估的客观和一致性。", "conclusion": "通过对十种最新LLM评测揭示了关键限制，进一步的评估套件显示模型在某些类型的场景和任务上表现不佳。DSR-Bench为结构推理提供了一种规范诊断工具，有助于发现推理瓶颈并指导更具能力和可靠性的LLMs开发。"}
{"llm_update_time": "20251015", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2505.18966", "html_url": "https://arxiv.org/abs/2505.18966", "title": "蛋白质设计中的动态蛋白质词汇", "title_en": "Protein Design with Dynamic Protein Vocabulary", "authors": "Nuowei Liu,Jiahao Kuang,Yanting Liu,Tao Ji,Changzhi Sun,Man Lan,Yuanbin Wu", "background": "蛋白质设计是生物技术中的一个基本挑战，旨在设计具有特定功能的新颖序列，而在可能的蛋白质空间中存在巨大的可能性。近年来，深度生成模型的发展使从文本描述中构建功能蛋白质成为可能，但这些方法在结构合理性和准确性的方面存在问题。本文通过探索将自然蛋白质片段整合到生成模型中，来改善折叠性能，即使随机地插入片段也有效提高了折叠性能。基于此，作者提出了ProDVa方法，它集成了一个文本编码器以获取功能描述，一个蛋白质语言模型以设计蛋白质，以及一个片段编码器以根据文本功能描述动态检索蛋白质片段。实验结果表明，ProDVa设计方案既功能对齐也结构合理，并且使用不到0.04%的训练数据就达到了与最先进的模型相当的功能对齐程度，同时设计出的折叠性能更好的蛋白质也更多，具有pLDDT > 70和PAE < 10的蛋白质比例分别提高了7.38%和9.6%。", "innovation": "作者提出了一种名为ProDVa的新颖蛋白质设计方法，它通过结合文本编码器、蛋白质语言模型和片段编码器，能够有效地设计出既具有功能性又能实现合理结构的蛋白质序列。ProDVa通过引入基于文本功能描述动态检索的蛋白质片段编码器，进一步提高了结构实用性，并且在有限的训练数据下实现了良好的功能对齐效果，提升了蛋白质的设计效率和准确性。", "conclusion": "ProDVa方法通过整合文本编码器、蛋白质语言模型和片段编码器，实现了对蛋白质设计中结构合理性和功能对齐的双重优化，用远少于之前方法的训练数据达到了与之类似的功能表现，并且显著提高了蛋白质的设计折叠性能，为未来的蛋白质设计算法提供了新的思路和方法。"}
{"llm_update_time": "20251015", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.13345", "html_url": "https://arxiv.org/abs/2506.13345", "title": "通过时间差分误差最大化在多种奖励设置中学习探索", "title_en": "Learning to Explore in Diverse Reward Settings via Temporal-Difference-Error Maximization", "authors": "Sebastian Griesbach,Carlo D'Eramo", "background": "在不同的设置中，已经提出了多种启发式方法和高级方法来应用深度强化学习中的探索技术。噪声探索通常适用于密集奖励，而基于奖励的探索适用于稀疏奖励。然而，这些方法通常需要额外的调参来应对不利的奖励设置。当奖励设置不利于探索，即执行动作有代价而没有其他密集信号时，这些方法表现不佳。", "innovation": "本文提出了一种新型探索方法，稳定的目标误差寻优探索（SEE），能够在密集奖励、稀疏奖励以及不利于探索的奖励设置中表现稳定。SEE方法引入了三个设计选择，以缓解离策略学习带来的不稳定性、在阶段性设置中累积TD误差与最大化TD误差之间的冲突，以及TD误差的非站定性。SEE可以在与不同的off-policy算法结合使用时，不修改原本的目标优化管道。", "conclusion": "通过实验分析，我们展示了添加SEE的Soft-Actor Critic代理在不同类型任务和奖励设置中表现稳定，无需调整超参数。SEE方法为实现更广泛的场景下的自动探索提供了可能，特别是在奖励设置多样且复杂的情境下。"}
{"llm_update_time": "20251015", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.14143", "html_url": "https://arxiv.org/abs/2506.14143", "title": "利用决策树中的预测等价性", "title_en": "Leveraging Predictive Equivalence in Decision Trees", "authors": "Hayden McTavish,Zachery Boner,Jon Donnelly,Margo Seltzer,Cynthia Rudin", "background": "决策树因其清晰的推理过程而被广泛应用于解释性机器学习中。然而，这种结构隐藏了一个称为预测等价性的挑战：给定的决策树可以由多个不同的决策树表示其决策边界。这意味着具有相同决策边界的模型在评估过程上可能不同，这使得模型选择变得困难。这些模型在处理缺失值时表现不同，变量的重要性也会有所不同，但大多数优化过程会任意选择一个模型。", "innovation": "作者提供了一种布尔逻辑表示决策树的方法，这种表示不表现出预测等价性，并忠实于底层的决策边界。他们将此表示应用于若干下游机器学习任务。使用这种方法，作者展示了决策树对特征值在测试时的缺失具有相当的鲁棒性；他们解决了预测等价性对变量重要性量化的影响；并提出了一种优化达到预测成本的算法。", "conclusion": "决策树对特征值测试时的缺失表现出相当的鲁棒性；解决了预测等价性对变量重要性量化的影响；提出了一个优化达到预测成本的算法。"}
{"llm_update_time": "20251015", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.19133", "html_url": "https://arxiv.org/abs/2506.19133", "title": "Riemannian生成解码器", "title_en": "Riemannian generative decoder", "authors": "Andreas Bjerregaard,Søren Hauberg,Anders Krogh", "background": "黎曼表示学习通常依赖于编码器来估计在选定流形上的概率密度。这需要优化数值上易碎的目标，可能影响模型训练和质量。目前的方法常常仅处理少数特定流形，因此流形约束问题复杂且难以解决。\n", "innovation": "本文引入了黎曼生成解码器，它是一种统一的方法，用于在任何黎曼流形上找到流形值隐变量。通过移除编码器，我们大大简化了流形约束，相比当前通常只能处理少量特定流形的方法更具普适性。该方法使用黎曼优化器学习隐变量，并与解码器网络共同训练。这种方法仅需要一个解码器，兼容现有架构，并能得出与数据几何相一致的可解释隐变量空间。\n", "conclusion": "验证结果显示，所学表示遵循指定几何结构并捕捉内在非欧几里得结构。代码可在指定网址获取。"}
{"llm_update_time": "20251015", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.15065", "html_url": "https://arxiv.org/abs/2506.15065", "title": "HEAL: 在大型语言模型驱动的体态代理中幻觉的实证研究", "title_en": "HEAL: An Empirical Study on Hallucinations in Embodied Agents Driven by Large Language Models", "authors": "Trishna Chakraborty,Udita Ghosh,Xiaopan Zhang,Fahim Faisal Niloy,Yue Dong,Jiachen Li,Amit K. Roy-Chowdhury,Chengyu Song", "background": "大型语言模型（LLMs）被越来越多地用作体态代理的认知核心。然而，由于用户指令未与观察到的物理环境对齐而产生的幻觉可能导致导航错误，例如搜索不存在的冰箱。本文旨在研究LLM驱动的体态代理在场景任务不一致情况下执行长期任务时幻觉的系统性问题，探索幻觉发生的频率、触发类型以及现有模型的应对策略。为此，研究基于现有基准构建了一个幻觉探查集，能够诱导出比基础提示高40倍的幻觉率。研究评估了12个模型在两个模拟环境中的表现，发现模型虽然进行了推理，但未能解决场景任务不一致性问题，突显了处理不可行任务的局限性。", "innovation": "该研究提出了首个系统性的LLM驱动体态代理幻觉研究，构建了诱导更高频率幻觉的探查集，并评估了多种模型在不同环境下的表现，揭示了当前模型在处理不可行任务方面的根本限制，并提供了在不同情景下的行动建议，引导开发更稳健可靠的计划策略。", "conclusion": "研究表明，模型虽然能够进行推理，但在解决场景任务不一致性方面存在局限性，从而未能有效处理不可行任务。该研究为开发更稳健可靠的体态代理计划策略提供了指导，特别是在幻觉管理和任务规划方面。"}
{"llm_update_time": "20251015", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.15969", "html_url": "https://arxiv.org/abs/2506.15969", "title": "LazyEviction: 基于注意力模式观察的延迟KV驱逐算法以实现高效的长期推理", "title_en": "LazyEviction: Lagged KV Eviction with Attention Pattern Observation for Efficient Long Reasoning", "authors": "Haoyue Zhang,Hualei Zhang,Xiaosong Ma,Jie Zhang,Song Guo", "background": "大型语言模型（LLMs）通过链式推理显示出增强的能力，但扩展的推理序列会因增加的键值（KV）缓存而导致显著的GPU内存开销。现有的KV缓存压缩方法可以通过减轻内存瓶颈来解决这一问题，但在长推理任务中表现不佳。当前的研究揭示了推理任务中的注意力模式，并发现了‘Token Importance Recurrence’现象，即大量token在多次解码步骤中重新获得高注意力，但现有方法未能捕捉这一点，可能导致此类周期性关键token的不可预测的驱逐。", "innovation": "本文提出了‘LazyEviction’，一种基于观察窗口的延迟驱逐框架，通过优先考虑按tokens的重复模式进行驱逐，保留潜在的重复出现的tokens。实验表明，LazyEviction在保持与基线模型相当的准确性的前提下，能够减少50%-70%的KV缓存，并优于现有的KV缓存压缩基线。", "conclusion": "实验结果证明，LazyEviction在保持与现有基线模型相当的准确性的前提下，通过50%-70%的KV缓存减少，成功解决了长期推理任务中的内存瓶颈问题，并且其代码可从指定链接获取。"}
{"llm_update_time": "20251015", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.01028", "html_url": "https://arxiv.org/abs/2507.01028", "title": "无对比自监督学习的双重视角", "title_en": "Dual Perspectives on Non-Contrastive Self-Supervised Learning", "authors": "Jean Ponce(ENS-PSL, NYU),Basile Terver(FAIR, WILLOW),Martial Hebert(CMU),Michael Arbel(Thoth)", "background": "无对比方法中的自监督学习通常使用‘stop gradient’和‘指数移动平均’迭代过程来避免表示的崩溃，这些方法在下游应用中表现出色。然而，关于这些过程的具体机制和避免表示崩溃的原理并没有很多深入的研究。", "innovation": "本文从优化和动力系统两方面重新审视了这两种过程，证明了它们一般情况下虽然并不能优化原始目标或多样的光滑函数，但确实能够避免表示崩溃。在没有额外假设的前提下，作者利用动力系统视角，展示了在线性情况下，不使用stop gradient或指数移动平均总是会导致表示崩溃。此外，该文还详细刻画了这两种过程在该线性设置下的动力系统关联的均衡点，并证明了一般情况下它们是渐近稳定的。", "conclusion": "作者通过真实和合成数据的实验，证明了其理论发现的有效性。研究结果强调了从动力系统角度理解这些自监督学习方法的重要性。"}
{"llm_update_time": "20251015", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.02599", "html_url": "https://arxiv.org/abs/2507.02599", "title": "Padé逼近神经网络在使用振动和声学数据提高电动机故障诊断中的应用", "title_en": "Padé Approximant Neural Networks for Enhanced Electric Motor Fault Diagnosis Using Vibration and Acoustic Data", "authors": "Sertac Kilickaya,Levent Eren", "background": "在电动机状态监测中，通常使用加速度计和麦克风来检测故障。尽管传统的卷积神经网络（CNNs）和自组织操作神经网络（Self-ONNs）已经应用于这类场景，但基于深度学习模型的非线性神经网络架构显示出显著的性能提升潜力。本文的研究目的是通过利用Padé逼近神经网络（PadéNets）模型改善感应电机的故障诊断。", "innovation": "本文创新性地引入了Padé逼近神经网络（PadéNets）模型，并将其与传统的CNNs和Self-ONNs模型进行对比测试。研究表明，PadéNets在使用振动和声学数据进行电动机故障诊断时表现出更优的性能，尤其是在提高诊断准确性方面的表现尤为突出。", "conclusion": "PadéNets在所有测试情况下均表现优异，特别是在使用振动数据和声学数据进行故障诊断时，其诊断准确率分别达到了99.96%、98.26%、97.61%和98.33%。这得益于PadéNets增强的非线性特性及其与非限制激活函数（如LeakyReLU）的兼容性，从而显著提升了感应电机状态监测的故障诊断性能。"}
{"llm_update_time": "20251015", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.02659", "html_url": "https://arxiv.org/abs/2507.02659", "title": "OmniDraft：跨词汇、在线自适应草案生成器及其在设备上推断中的推测性解码", "title_en": "OmniDraft: A Cross-vocabulary, Online Adaptive Drafter for On-device Speculative Decoding", "authors": "Ramchalam Kinattinkara Ramakrishnan,Zhaocong Yuan,Shaojie Zhuo,Chen Feng,Yicheng Lin,Chenzheng Su,Xiaopeng Zhang", "background": "传统的推测性解码通常需要预先训练或部分训练一个小型高效的草稿模型到特定的模型系列，比如Llama或Qwen。但在在线部署场景中，存在两个主要挑战：1) 草稿模型与目标模型不兼容；2) 预期的延迟降低。本研究旨在克服上述问题。", "innovation": "提出了一种名为OmniDraft的统一框架，使得单一草稿模型能够与任何目标模型协同工作并根据用户数据动态调整。同时，引入了混合distillation fine-tuning和自适应抽样技术来解决词汇表匹配问题，并提升了解码速度。该框架特别适合于设备上的大语言模型应用，通过减少模型成本和提高效率来优化用户体验。", "conclusion": "OmniDraft框架能够在数学推理、编程和文本生成等任务中实现在线学习，并且能够使一个单一的Llama-68M模型与多个不同目标模型，如Vicuna-7B、Qwen2-7B和Llama3-8B一起进行推测性解码，相比传统方法，速度提高了1.5-2倍。此研究强调了上述挑战的解决需求，倡导了一“通用于所有模型的草稿生成器”的理念。"}
{"llm_update_time": "20251015", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.07146", "html_url": "https://arxiv.org/abs/2507.07146", "title": "注意力增强的基于图神经网络的输入防御机制对抗多轮大语言模型监狱突袭攻击", "title_en": "Attention-Aware GNN-based Input Defense against Multi-Turn LLM Jailbreak", "authors": "Zixuan Huang,Kecheng Huang,Lihao Yin,Bowei He,Huiling Zhen,Mingxuan Yuan,Zili Shao", "background": "大语言模型（LLMs）在各种应用中获得了广泛关注，但由于其功能存在被用于建设性或恶意利用的风险，尽管进行了大量针对安全性的训练和微调，LLMs仍然容易受到监狱突袭攻击的影响。最近，多轮攻击的出现进一步加剧了这一脆弱性，这类攻击通过逐步提高对话的复杂性，使得检测和缓解更加困难。", "innovation": "本研究引入了G-Guard，这是一种针对多轮LLM监狱突袭攻击的注意力增强的图神经网络（GNN）基于输入分类器。G-Guard通过构建多轮查询的实体图来捕捉查询及其多轮查询中有害关键词之间的关系，并提出了一种注意力增强的扩展机制，根据正在进行的多轮对话检索相关的单轮查询，将其作为带有标签的节点集成到图中，从而增强了GNN分类当前查询为有害或无害的能力。", "conclusion": "评估结果显示，G-Guard在多个数据集和评估指标上一致优于所有基线，证明了其作为对抗多轮监狱突袭攻击的稳健防御机制的有效性。"}
{"llm_update_time": "20251015", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.10348", "html_url": "https://arxiv.org/abs/2507.10348", "title": "Feature Distillation is the Better Choice for Model-Heterogeneous Federated Learning", "title_en": "Feature Distillation is the Better Choice for Model-Heterogeneous Federated Learning", "authors": "Yichen Li,Xiuying Wang,Wenchao Xu,Haozhao Wang,Yining Qi,Jiahua Dong,Ruixuan Li", "background": "当前模型异质联邦学习（Hetero-FL）引起了广泛关注，因为它能够聚合异质模型的知识同时保持本地数据的私密性。为了提升全局模型的性能，通常在全局聚合后采用组合式蒸馏等技术来增强模型性能。然而，直接将组合式蒸馏与Hetero-FL结合起来并不总是能得到理想的效果，而且可能会导致训练过程不稳定。这主要是因为现有方法主要关注于日志拾取蒸馏，虽然日志拾取蒸馏具有与softmax预测无关的特点，但未能弥补因模型异质性引起的知识偏差。", "innovation": "为了应对这一挑战，我们提出了一种称为FedFD的稳定且高效的模型异质联邦学习特征蒸馏方法，通过正交投影集成异质模型的知识来校准特征信息。FedFD引入了一种基于特征的组合式联邦知识蒸馏新框架，服务器上的全局模型需要为每种客户端模型架构保留一个投影层，以分别对齐特征。采用正交技术重新参数化投影层，以减轻来自异质模型的知识偏差，从而最大化蒸馏知识。", "conclusion": "广泛的实验表明，FedFD在性能上显著优于现有最先进的方法。"}
{"llm_update_time": "20251015", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.02753", "html_url": "https://arxiv.org/abs/2508.02753", "title": "DMSC: 动态多尺度协调框架用于时间序列预测", "title_en": "DMSC: Dynamic Multi-Scale Coordination Framework for Time Series Forecasting", "authors": "Haonan Yang,Jianchao Tang,Zhuo Li,Long Lan", "background": "时间序列预测（TSF）面临在不同时间尺度上建模复杂时间依赖关系的持续挑战。虽然最近的研究利用了不同的分解操作和基于CNN、MLP或Transformer的新颖架构，但现有方法仍然难以处理静态分解策略、断层依赖建模和不灵活的融合机制，这些都限制了它们建模复杂时间依赖关系的能力。", "innovation": "提出了一种名为DMSC的新型动态多尺度协调框架，该框架包括多尺度块（EMPD）、三重交互块（TIB）和自适应多尺度路由MoE块（ASR-MoE）。EMPD动态地将序列分解为具有指数缩放粒度的分层片段，通过输入自适应的片段调整消除预定义的比例约束。TIB则在每层拆分的表示中联合建模片内、片间以及跨变量依赖关系。EMPD和TIB通过分级路径集成到多层逐步级联架构中，粗粒度表示在早期层中适应性地引导后续层的细粒度特征提取。ASR-MoE通过利用与时间感知权重的专业化全局和局部专家动态融合多尺度预测。", "conclusion": "在十三个真实世界基准上的全面实验表明，DMSC在时间序列预测任务中保持了状态最先进（SOTA）的性能和更高的计算效率。代码可供参考：this https URL"}
{"llm_update_time": "20251015", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.09281", "html_url": "https://arxiv.org/abs/2508.09281", "title": "使用表征学习从学生代码中提取基于模式的知识组件", "title_en": "Pattern-based Knowledge Component Extraction from Student Code Using Representation Learning", "authors": "Muntasir Hoq,Griffin Pitts,Andrew Lan,Peter Brusilovsky,Bita Akram", "background": "计算机科学教育中的有效个性化学习依赖于准确地建模学生的知识和他们需要学习的内容。知识组件（KCs）为这种建模提供了基础，但学生代码中的自动化KCs提取由于发现的KCs缺乏解释性和编程问题的高结构性变化和复杂概念交互的开放性而具有挑战性。", "innovation": "本文提出了一种基于模式的新型可解释框架，通过变分自动编码器从学生代码中生成重要模式，利用基于注意力的代码表示模型来识别学生代码中正确且错误的模式实现。这些模式通过聚类形成基于模式的知识组件，该框架旨在自动化地、可扩展地且可解释性地识别代码中的细粒度编译器模式和算法构造，这些对于学生的学习至关重要。", "conclusion": "实验结果显示有意义的学习轨迹和在深度知识追踪（DKT）预测性能上的显著改进，超过传统知识追踪方法。本文通过提供一种可用于计算机科学教育的知识建模框架，促进了知识模型的发展，该框架用于自动化的模式化代码和算法构造识别，对学生学习至关重要。"}
{"llm_update_time": "20251015", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.08746", "html_url": "https://arxiv.org/abs/2508.08746", "title": "通过稀疏自编码器实现可解释的奖励模型", "title_en": "Interpretable Reward Model via Sparse Autoencoder", "authors": "Shuyi Zhang,Wei Shi,Sihang Li,Jiayi Liao,Tao Liang,Hengxing Cai,Xiang Wang", "background": "大语言模型（LLMs）已经广泛应用于多个领域。强化学习从人类反馈（RLHF）利用奖励模型（RMs）作为人类偏好的代理，以使LLM的行为与人类价值观保持一致。因此，奖励模型的准确性、可靠性和可解释性对于有效的对齐至关重要。然而，传统的奖励模型缺乏可解释性，难以提供奖励分配背后的推理，并且在用户偏好的变化方面不够灵活。虽然最近的发展尝试提升了多维度奖励模型的可解释性，但它们往往无法实现特征级别的归因，并且需要昂贵的标注成本。", "innovation": "我们提出了Sparse Autoencoder-enhanced Reward Model（SARM），这是一种新颖的架构，将预训练的稀疏自编码器（SAE）整合到奖励模型中。SARM将基于LLM的奖励模型的隐藏激活映射到一个可解释、稀疏和单义的特征空间，在该空间中，标量头聚合特征激活以生成透明且概念上明确的奖励评分。实践评估表明，SARM能够直接为奖励分配提供特征级别的归因，能够动态调整偏好变化，并在与传统奖励模型相比时取得了更高的对齐性能。", "conclusion": "实证研究表明，SARM能够直接为奖励分配提供特征级别的归因，能够动态调整偏好变化，并实现了优于传统奖励模型的对齐性能。我们的代码可以在 这里 获取。"}
{"llm_update_time": "20251015", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.19349", "html_url": "https://arxiv.org/abs/2507.19349", "title": "使用组不变非扩张算子从稀疏测量中重构SINR图", "title_en": "Reconstruction of SINR Maps from Sparse Measurements using Group Equivariant Non-Expansive Operators", "authors": "Lorenzo Mario Amorosa,Francesco Conti,Nicola Quercioli,Flavio Zabini,Tayebeh Lotfi Mahyari,Yiqun Ge,Patrizio Frosini", "background": "随着第六代（6G）无线网络的发展，准确的信号与干扰噪声比（SINR）图对于有效的资源管理和优化变得越来越关键。但是，以高分辨率获取这些地图往往成本高昂，造成了严重的数据稀缺挑战。这就需要可以利用非常稀疏的测量数据稳健重建完整图谱的机器学习（ML）方法。为了应对这个问题，我们提出了一种基于组不变非扩张算子（GENEOs）的新重建框架。因为这些算子具有较低的复杂度，并可以直接嵌入领域特定的几何先验，如平移不变性，这提供了一种有效的从少量样本中重建的方法。我们的核心见解是，在网络管理中，保持SINR图的拓扑结构，例如覆盖孔和干扰模式的几何结构，通常是比像素误差更关键的。我们验证了我们的方法，评估了其性能，不仅使用传统的统计指标（均方误差（MSE）），还使用了关键的拓扑指标（1- Wasserstein距离）。结果显示，尽管在均方误差上保持竞争力，我们的方法在拓扑保真度上显著优于现有的ML基准模型。这表明了使用GENEOs重建结构准确的SINR图，在下游网络优化任务中更可靠。", "innovation": "提出了一种基于组不变非扩张算子的新型重建框架，利用低复杂度的算子嵌入几何先验，能够从稀疏测量数据中有效重建SINR图，尤其是能保持拓扑结构的准确度，相较于传统方法提供了显著的优势。", "conclusion": "我们的方法在保持均方误差竞争力的同时，展示了在拓扑保真度上相比现有ML基准模型的显著优势。这一方法证明了在网络管理中的实际应用价值，能够创建更可靠的SINR图，从而有助于下游网络优化任务。"}
{"llm_update_time": "20251015", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.14094", "html_url": "https://arxiv.org/abs/2508.14094", "title": "需要的仅仅是困难的例子：在注解预算下的最大化GRPO后训练", "title_en": "Hard Examples Are All You Need: Maximizing GRPO Post-Training Under Annotation Budgets", "authors": "Benjamin Pikus,Pratyush Ranjan Tiwari,Burton Ye", "background": "高质量的训练实例对语言模型微调非常重要，但实际预算限制了可获得的数据量。作者分析了示例难度如何影响GRPO训练的效果，对比了从易到难的不同示例选择策略，并发现训练在最难的10%（即基模型最常失败的情况）示例上可以带来高达47%的显著性能提升，而较为简单的示例则几乎不带来提升。这是由于GRPO需要结果变化来生成学习信号，而难例在整个训练过程中保持混合的成功率，而简单的例子很快达到一致的成功结果，消除了学习机会。同时，训练在难例上的模型在分布外泛化方面表现出色，仅有训练了难例的模型在AIME2025基准上取得了实质性的进步。", "innovation": "作者研究了示例难度如何影响基于梯度的策略优化（GRPO）的训练效果，通过对比选择不同难度级别的示例，即容易、中等、困难和随机选择。实验发现，选择训练最难的示例能够显著提高模型性能。此外，训练在难例上的模型在数据分布之外泛化的表现更好，揭示了在预算有限时应优先收集和标注基模型难以处理的示例，因为这些示例在GRPO微调中几乎提供了所有的学习价值。", "conclusion": "当预算有限时，应优先收集和标注基模型难以处理的示例，因为这些示例在GRPO微调中几乎提供了所有的学习价值。这种方法在提升模型性能和泛化能力方面都非常有效，尤其是对于AIME2025这样的分布外基准测试。"}
{"llm_update_time": "20251015", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.18742", "html_url": "https://arxiv.org/abs/2508.18742", "title": "约束很重要：基于多模态表示的混合整数线性规划简化方法", "title_en": "Constraint Matters: Multi-Modal Representation for Reducing Mixed-Integer Linear programming", "authors": "Jiajun Li,Ran Hou,Yu Ding,Yixuan Li,Shisi Guan,Jiahui Duan,Xiongwei Han,Tao Zhong,Vincent Chau,Weiwei Wu,Wanyuan Wang", "background": "模型简化的目标是学习原始混合整数线性编程（MILP）的简化模型，可以更快地解决大规模MILP问题。大多数现有模型简化方法基于变量简化，通过预测子集变量的解值来实现。从另一个角度看，约束简化可以将子集不等式约束转化为等式来简化MILP，但这一方法尚未得到充分关注。本文提出了一种基于约束的MILP简化方法。这种简化方法面临两大挑战：哪些不等式约束是关键的，减少它们可以加速MILP求解同时保持可行性；如何高效预测这些关键约束。", "innovation": "提出了一种基于约束的MILP简化方法，包含多模态表示技术，该技术同时利用实例级和抽象级MILP建模信息来识别关键约束，并设计了一种启发式规则来选择关键紧约束子集。这种方法在解决MILP问题时相比最先进的方法提高了50%以上的解的质量，并减少了17.47%的计算时间。", "conclusion": "所提出的方法通过多模态表示技术能够有效识别和预测关键约束，从而大幅提高了解的质量并显著减少计算时间，验证了基于约束的简化方法的有效性。"}
{"llm_update_time": "20251015", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.00648", "html_url": "https://arxiv.org/abs/2509.00648", "title": "Context-Action Embedding Learning for Off-Policy Evaluation in Contextual Bandits", "title_en": "Context-Action Embedding Learning for Off-Policy Evaluation in Contextual Bandits", "authors": "Kushagra Chandak,Vincent Liu,Haanvid Lee", "background": "该论文讨论了上下文臂拉扯问题中的离策略评估（OPE），使用逆概率得分（IPS）加权方法，虽然这种方法无偏，但在动作空间大或某些上下文-动作空间未充分探索的情况下，会遭受显著的方差问题。最近提出的边际逆概率得分（MIPS）估计器通过利用动作嵌入解决了这个问题，但这些嵌入未最小化MIPS估计器的均方误差（MSE），并且未考虑上下文信息。", "innovation": "本文提出了Context-Action Embedding Learning for MIPS，即CAEL-MIPS，该方法通过从离线数据中学习上下文-动作嵌入来最小化MIPS估计器的MSE，从而解决了上述问题。基于MIPS偏差和方差的理论分析，提出了CAEL-MIPS的MSE最小化目标。", "conclusion": "在合成数据集和真实数据集上的实证研究中，本文的估计器在均方误差（MSE）方面优于基线方法。"}
{"llm_update_time": "20251015", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.20353", "html_url": "https://arxiv.org/abs/2508.20353", "title": "DFAMS: 动态流引导的联邦对齐基于多原型搜索", "title_en": "DFAMS: Dynamic-flow guided Federated Alignment based Multi-prototype Search", "authors": "Zhibang Yang,Xinke Jiang,Rihong Qiu,Ruiqing Li,Yihang Zhang,Yue Fang,Yongxin Xu,Hongxin Ding,Xu Chu,Junfeng Zhao,Yasha Wang", "background": "联邦检索(FR)将查询路由到多个外部知识源，以减轻大型语言模型(LLMs)的幻觉问题，特别在必要时利用分布的外部知识。然而，现有方法在处理含糊查询时难以检索到高质量的相关文档，特别是在跨域场景中，这极大地限制了其支持下游生成任务的有效性。", "innovation": "本文提出了DFAMS框架，该框架通过利用动态信息流(DIF)来识别潜在的查询意图并构建语义对齐的知识分区，以实现跨异构源的精确检索。DFAMS通过利用少量标注查询的梯度信号来进行DIF探针，并通过Shapley值归因跟踪与意图识别和子域边界检测相关的神经激活路径。此外，DFAMS通过多原型对比学习训练对齐模块，以实现细粒度的源内建模和跨知识库的语义对齐。", "conclusion": "在五个基准测试中，DFAMS相比先进的联邦检索方法，在知识分类准确性、检索召回率和下游问答准确性上分别提高了多达14.37%、5.38%和6.45%，证明了其在复杂联邦检索场景中的有效性。源代码匿名可从指定链接获取。"}
{"llm_update_time": "20251015", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.07330", "html_url": "https://arxiv.org/abs/2509.07330", "title": "跨疾病和人群增强预测性能的一般人口统计基础模型", "title_en": "General Demographic Foundation Models for Enhancing Predictive Performance Across Diseases and Populations", "authors": "Li-Chin Chen,Ji-Tian Sheu,Yuh-Jue Chuang", "background": "电子健康记录中普遍存在人口统计属性，这些属性在临床风险分层和治疗决策中非常重要。尽管这类信息的重要性显而易见，但在模型设计中仍往往被视为辅助变量，对其表征学习的关注较少。", "innovation": "研究开发了通用人口统计预训练（GDP）模型，专注于年龄和性别，通过探索不同排序方法和编码方式组合的方式，将表格形式的人口统计输入转化为有效的潜在嵌入。GDP模型在不同地理区域、疾病和人群组成的多种数据集上进行了预训练和评估，验证了其在任务、疾病和人群上的泛化能力，特别是在年龄和性别对风险分层影响显著的疾病中，排序顺序显著提高了模型在区分、校准和信息增益方面的性能。", "conclusion": "基础模型在表格形式的人口统计属性中提供了增强预测性能的潜在途径，特别是在年龄和性别对风险分层有显著影响的疾病中，即使这些属性在某些数据集中预测价值相对较低，GDP模型也能增加它们在后续梯度提升模型中的影响力，从而显著提高预测性能。"}
{"llm_update_time": "20251015", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.18964", "html_url": "https://arxiv.org/abs/2509.18964", "title": "异步平均Q学习中心极限定理", "title_en": "Central Limit Theorems for Asynchronous Averaged Q-Learning", "authors": "Xingtu Liu", "background": "论文建立了一系列关于异步更新的Polyak-Ruppert平均Q学习的中心极限定理。传统的中心极限定理通常关注的是平均结果的分布逼近正态分布，而该研究进一步探讨了在非同步更新情况下，Q学习算法的表现和渐近性质，特别是在Wasserstein距离下的非渐进性质.", "innovation": "首次证明了非渐进中心极限定理，明确地反映了迭代次数、状态-动作空间大小、折扣因子和探索质量之间的依赖关系对收敛率的影响。此外，还推导出函数中心极限定理，表明部分和过程的弱收敛性到布朗运动.", "conclusion": "研究表明，在异步更新条件下，使用Polyak-Ruppert平均化的Q学习算法的长期行为可以被描述为布朗运动的渐近性质，这对于理解算法的长期稳定性以及优化参数具有重要意义."}
{"llm_update_time": "20251015", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.04154", "html_url": "https://arxiv.org/abs/2509.04154", "title": "注意机制作为自适应滤波器", "title_en": "Attention as an Adaptive Filter", "authors": "Peter Racioppo", "background": "现有的注意力机制通常通过直接对比查询（queries）和键（keys）来计算注意力权重，这种机制缺乏动态模型的支持。因此，该研究旨在开发一种新的注意力机制，能够直接将可学习的动力学模型整合到注意力权重的计算中，以利用连续时间线性时不变系统的特性，改善信息处理的动态性与精度。", "innovation": "该研究引入了一种名为Adaptive Filter Attention (AFA)的新颖注意力机制。AFA将动力学模型直接融入到注意力权重的计算中，通过将输入序列建模为线性随机微分方程（SDE）的离散观测值，利用线性Lyapunov方程的闭解来在动态中传播不确定性。研究将普通的注意力机制通过最大似然估计转化为过滤线性SDE轨迹的过程，并使用稳健的残差加权来调整传播的查询-键精度。此外，通过进一步对系统动力学和噪声进行约束，获得了一种简化变体，其计算和内存复杂度与标准的注意力机制相同。在零衰减和过程噪声下的极限情况下，使用小角近似，恢复了复数形式的普通点积注意力机制，并结合了旋转位置编码。", "conclusion": "该研究展示了AFA在提高注意力机制的动态性和精度方面的潜力，并为未来的注意力机制设计提供了新的思路，特别适用于需要精细动态控制的任务。"}
{"llm_update_time": "20251015", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.09413", "html_url": "https://arxiv.org/abs/2509.09413", "title": "融合Lasso提高分组样本共现网络推断的准确性", "title_en": "Fused Lasso Improves Accuracy of Co-occurrence Network Inference in Grouped Samples", "authors": "Daniel Agyapong,Briana H. Beatty,Peter G. Kennedy,Jane C. Marks,Toby D. Hocking", "background": "现有的共现网络推断算法显著提升了我们对微生物群落的理解，但是这些算法一般只分析单一环境群落中微生物样本间的关联，通常只能捕捉到静态的微生物过程而非动态的过程。先前的研究往往将不同环境条件下的样本进行分组而不充分考虑环境变化对微生物群落间关联的影响。本研究通过明确调查微生物群落的空间和时间动态来解决这一局限性。研究人员分析了来自不同地点和时间点的公开微生物丰度数据，使用我们提出的同级交叉验证（SAC）框架评估算法性能，并在单独环境内的训练和测试数据及跨环境训练和测试数据的两个场景下进行评估。", "innovation": "本研究所提出的是一个名为fuser的算法，它与常见的机器学习方法不同，fuser在培训过程中可以保留每个样本的具体信号，并同时在环境中共享相关信息。与标准方法从联合数据中推断一个单一的通用网络截然不同，fuser可以生成特定于环境的预测网络，从而提高跨环境样本预测的准确性。科研团队展示了fuser在单一环境内和跨环境测试中的性能优越性。", "conclusion": "fuser算法在单一环境内能与现有算法如glmnet表现相似的预测能力，在跨环境测试中却能显著降低测试误差。这种算法可以提高微生物群落网络推断的准确性，特别适用于环境变化影响较大的研究场景。"}
{"llm_update_time": "20251015", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.22416", "html_url": "https://arxiv.org/abs/2509.22416", "title": "统一一招：预训练模型的通用图适应", "title_en": "One Prompt Fits All: Universal Graph Adaptation for Pretrained Models", "authors": "Yongqi Huang,Jitao Zhao,Dongxiao He,Xiaobao Wang,Yawen Li,Yuxiao Huang,Di Jin,Zhiyong Feng", "background": "Graph Prompt Learning（GPL）作为一种将图预训练模型与下游任务相连接的新兴范式而兴起，旨在减少标签依赖性并解决上游预训练与下游任务之间的不匹配问题。尽管现有GPL研究探索了多种提示策略，但它们的有效性和内在原理仍然不明朗。研究指出两个关键局限：第一，缺乏对底层机制的一致理解；第二，有限的应用场景适配能力。", "innovation": "该研究通过理论分析现有的GPL方法并揭示了代表层提示的本质，提出图提示学习应集中在释放预训练模型的能力上，而分类器则需适应下游场景。在此基础上，该研究提出了UniPrompt，这是一种能够适应任何预训练模型的新GPL方法，既能释放预训练模型的能力又能保留输入图的信息。广泛的实验表明，该方法能够有效与各种预训练模型结合，并在同域和跨域场景中获得强表现。", "conclusion": "该方法有效地整合了各种预训练模型，并在同域和跨域各场景中表现出强性能。"}
{"llm_update_time": "20251015", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.16548", "html_url": "https://arxiv.org/abs/2509.16548", "title": "SCAN: 自身去噪蒙特卡洛标注以实现稳健的过程奖励学习", "title_en": "SCAN: Self-Denoising Monte Carlo Annotation for Robust Process Reward Learning", "authors": "Yuyang Ding,Xinyu Shi,Juntao Li,Xiaobo Liang,Zhaopeng Tu,Min Zhang", "background": "过程奖励模型（PRMs）能够提供细粒度的步骤级评估，有助于大型语言模型（LLMs）进行更深入的推理过程，特别在复杂任务如数学推理方面表现良好。然而，开发PRMs存在挑战，因为高质量的人工标注数据成本高且难以大规模扩展。蒙特卡洛（MC）估计生成的合成数据是一种有前景的替代方案，但由于噪声比例高，可能导致过拟合，影响大规模训练效果。研究表明，标注模型在标注步骤正确性时，往往会低估和高估，这归因于其标注能力的限制。", "innovation": "本文进行了初探性研究，探讨了MC估计生成的合成数据中的噪声分布，发现标注模型在标注步骤正确性时倾向于低估和高估。基于此，提出了Self-Denoising Monte Carlo Annotation（SCAN）框架，这是一种高效的数据合成和抗噪声学习框架。该框架的关键发现表明：（1）即使轻量级模型（例如，1.5B参数）可以通过自我去噪策略生成高质量的标注，使得PRMs仅需传统MC估计6%的推理成本即可获得优越性能。（2）通过我们的稳健学习策略，PRMs可以从这种弱监督中有效学习，ProcessBench中取得39.2个F1得分的提升（从19.9到59.1）。即使使用紧凑的合成数据集，我们的模型也超越了包括基于大规模人工标注数据集（如PRM800K）训练的基线模型的强劲基线。此外，随着合成数据规模的扩大，性能持续提升，表明SCAN具有可扩展、成本效益和鲁棒性过程奖励模型培训的潜力。", "conclusion": "本文提出了一种名为SCAN的框架，能够从低质量的弱监督中学习，显著提高了PRMs性能，同时大幅降低了推理成本。随着合成数据规模的增加，性能持续提升，表明SCAN在大规模、低成本和鲁棒性PRMs培训方面具有巨大潜力。"}
{"llm_update_time": "20251015", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.23050", "html_url": "https://arxiv.org/abs/2509.23050", "title": "通过对比链嵌入理解LVLM的语言先验", "title_en": "Understanding Language Prior of LVLMs by Contrasting Chain-of-Embedding", "authors": "Lin Long,Changdae Oh,Seongheon Park,Sharon Li", "background": "大型多模态语言模型（LVLMs）在多模态任务上表现出色，但它们通常依赖于语言先验（LP），即预训练中记忆的文本模式，而过度依赖语言而不充分利用视觉证据。现有的LP分析主要依赖于输入-输出探针，这无法揭示当以及如何视觉信息影响模型行为的内部机制。", "innovation": "本文首次通过链嵌入这一视角系统地分析了语言先验，研究了LVLMs中的逐层表示动态。提出了视觉整合点（VIP）这一概念，并引入了总视觉整合（TVI）估计器来量化视觉查询对响应生成的影响力。该研究在多个模型和数据集上证明了VIP的一致出现，并表明TVI可以可靠地预测语言先验的强度。", "conclusion": "该研究提供了一种有原则的工具箱，用于诊断和理解LVLMs中的语言先验。"}
{"llm_update_time": "20251015", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.22363", "html_url": "https://arxiv.org/abs/2509.22363", "title": "大型音频语言模型中的可靠性探究", "title_en": "Investigating Faithfulness in Large Audio Language Models", "authors": "Lovenya Jain,Pooneh Mousavi,Mirco Ravanelli,Cem Subakan", "background": "链式思考（CoT）表示反映了模型决策过程的准确性，并可以作为可靠的解释。先前的研究发现，基于文本的大语言模型（LLMs）的CoT往往不准确。然而，这种评估尚未应用于大型音频-语言模型（LALMs），而LALMs在安全敏感的应用中至关重要。由于LALMs中的推理更为复杂，模型必须首先从音频中提取相关信息，然后才能进行推理。本文通过在两个具有挑战性的推理数据集（SAKURA和MMAR）上应用目标干预（包括改写、填充令牌插入、早期回答和引入错误），探究了LALMs产生CoT的可靠性。", "innovation": "研究填补了大型音频语言模型中链式思考表示可靠性的空白，通过应用多种类型的目标干预措施评估了这些模型的链式思考表示的质量，证明了LALMs一般会产生与其决策过程相关的CoTs。这一工作强调了在安全性要求高的应用中，对LALMs的CoT进行可靠性评估的重要性。", "conclusion": "实验表明，LALMs通常能够产生与其决策过程一致的CoTs，表明这些模型能够提供较为可靠的解释。这一结论对于确保大型音频语言模型在安全敏感应用中的适用性具有重要意义。"}
{"llm_update_time": "20251015", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.26327", "html_url": "https://arxiv.org/abs/2509.26327", "title": "广义信息瓶颈理论的深度学习原理", "title_en": "A Generalized Information Bottleneck Theory of Deep Learning", "authors": "Charles Westphal,Stephen Hailes,Mirco Musolesi", "background": "信息瓶颈（IB）原则为理解神经网络（NNs）的学习提供了一个诱人的理论框架。然而，由于未解决的理论模糊性和准确估计的显著挑战，其实际用途受到了限制。", "innovation": "提出了广义信息瓶颈（GIB）框架，通过视角的协同性来重新解释原始的IB原则，即仅通过联合处理特征获得的信息。提供理论和实验证据证明协同函数的泛化能力优于非协同函数。基于可以计算的协同性的平均互信息（II）重新定义了IB。证明在完美估计的情况下，原始IB的目标由GIB上界约束，确保与现有IB理论兼容的同时，解决了其局限性。GIB在多种架构（包括具有ReLU激活的标准IB失效的架构）上表现出一致的压缩阶段，同时在CNNs和Transformers中提供可解释的动力，并更紧密地符合我们的对抗稳健性理解。", "conclusion": "GIB在广泛模型架构上表现出一致的压缩阶段，同时在CNNs和Transformers中展示了可解释的动力，并更紧密地反映了我们的对抗稳健性理解。"}
{"llm_update_time": "20251015", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.06540", "html_url": "https://arxiv.org/abs/2510.06540", "title": "POMDPs的可扩展策略基于RL算法", "title_en": "Scalable Policy-Based RL Algorithms for POMDPs", "authors": "Ameya Anjarlekar,Rasoul Etesami,R Srikant", "background": "部分可观测马尔可夫决策过程（POMDP）中的信念状态连续性带来了显著的计算挑战，在学习最优策略时尤为突出。现有方法在将POMDP转化为有限状态马尔可夫决策过程（Superstate MDP）时，并未实现理论上的严格保证，这使得直接学习最优策略变得困难。", "innovation": "本文提出了一种方法，通过将POMDP近似转化为Superstate MDP，并使用基于策略的学习方法结合线性函数逼近来学习Superstate MDP的最优策略。这种方法证明了可以在近似解决POMDP问题时，通过TD学习后跟策略优化，将POMDP视为MDP来处理，其中MDP状态对应于有限的历史。同时，论文展示了近似误差随着历史长度的增加呈指数级减少。最重要的是，作者提出了有界时间内的误差量化界限，这是首次明确量化应用标准TD学习到非马尔可夫环境设置时引入的误差。", "conclusion": "本文提出的方法通过将POMDP转化为Superstate MDP并利用基于策略的学习来近似解决POMDP问题，展示了在有限历史条件下，这种转换的可行性，并且详细量化了这种转换引入的误差。"}
{"llm_update_time": "20251015", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.05180", "html_url": "https://arxiv.org/abs/2510.05180", "title": "OptiFLIDS：物联网中高效能耗入侵检测的优化联邦学习", "title_en": "OptiFLIDS: Optimized Federated Learning for Energy-Efficient Intrusion Detection in IoT", "authors": "Saida Elouardi,Mohammed Jouhari,Anas Motii", "background": "在智能家庭和工业系统等关键物联网环境中，有效的入侵检测系统（IDS）对保证安全至关重要。然而，开发可靠的IDS解决方案仍然是一个巨大的挑战。传统的基于机器学习的IDS模型通常需要大量的数据集，但由于隐私和安全问题，数据共享常常受限。联邦学习（FL）为这一问题提供了一种替代方案，通过协作模型训练而不共享原始数据，但FL仍然面临着数据异质性（非IID数据）和高能耗与计算成本等关键挑战，尤其是对资源受限的物联网设备。", "innovation": "该论文提出了一种名为OptiFLIDS的新方法，该方法在局部训练阶段应用剪枝技术以降低模型复杂度和能耗，并结合定制化的聚合方法来更好地处理由于非IID数据分布而产生的剪枝模型差异。实验表明，OptiFLIDS在保持强大的检测性能的同时提升了能源效率，使其非常适合部署在真实的物联网环境中。", "conclusion": "实验结果表明，OptiFLIDS在保持强大的检测性能的同时提升了能源效率，是一种适合在真实的物联网环境中部署的有效方案。"}
{"llm_update_time": "20251015", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.07285", "html_url": "https://arxiv.org/abs/2510.07285", "title": "GTCN-G: 一个残差图时序融合网络以应对不平衡入侵检测", "title_en": "GTCN-G: A Residual Graph-Temporal Fusion Network for Imbalanced Intrusion Detection (Preprint)", "authors": "Tianxiang Xu,Zhichao Wen,Xinyu Zhao,Qi Hu,Yan Li,Chang Liu", "background": "现代入侵检测系统（IDS）面临网络威胁日益复杂和流量数据中固有的类别不平衡问题。虽然图神经网络（GNNs）擅长建模拓扑结构，时间卷积网络（TCNs）擅长捕捉时序依赖关系，但是如何将这两种技术结合并有效地处理数据不平衡问题仍然是一个开放的挑战。", "innovation": "这篇文章提出了一个新颖的深度学习框架，叫做Gated Temporal Convolutional Network and Graph（GTCN-G），它将带有残差学习机制的时间门控卷积网络（G-TCN）和图卷积网络（GCN）融合在一起，用于提取网络流的层级时序特征，并从潜在的图结构中学习。核心创新点在于通过图注意网络（GAT）实现的残差学习机制，这种机制通过残差连接保留原始特征信息，这对于缓解类别不平衡问题和提高对稀有恶意活动（少数类别）的检测灵敏度至关重要。", "conclusion": "通过对两个公开的基准数据集（UNSW-NB15和ToN-IoT）进行广泛的实验，我们的方法得到了实证结果的支持。GTCN-G模型在二分类和多分类任务中均取得了最先进的性能，明显优于现有的基线模型。"}
{"llm_update_time": "20251015", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.07505", "html_url": "https://arxiv.org/abs/2510.07505", "title": "PEAR: Planner-Executor Agent Robustness Benchmark", "title_en": "PEAR: Planner-Executor Agent Robustness Benchmark", "authors": "Shen Dong,Mingxuan Zhang,Pengfei He,Li Ma,Bhavani Thuraisingham,Hui Liu,Yue Xing", "background": "大规模语言模型（LLM）驱动的多智能体系统（MAS）在解决跨多种领域的复杂多步骤任务方面显示出强大的潜力。然而，尽管它们具备卓越的能力，MAS仍然容易受到对抗性操纵的影响。现有研究通常仅关注孤立的攻击面或特定场景，缺乏对MAS整体脆弱性的全面理解。", "innovation": "本文引入了PEAR基准，旨在系统地评估规划执行MAS的功能性和脆弱性。研究表明，在规划者和执行者之间存在性能和鲁棒性之间的权衡，针对规划者的攻击尤为有效。这些发现提供了提升MAS鲁棒性的实用建议，并为多代理环境中的有原则防御奠定了基础。", "conclusion": "实验发现：1. 弱规划者比弱执行者更严重地影响系统的整体清洁任务性能；2. 规划者的知识模块对于其功能至关重要，但执行者的知识模块不影响清洁任务性能；3. 在任务性能与鲁棒性之间存在权衡；4. 针对规划者的攻击特别有效，能够误导系统。这些结果为提升MAS的鲁棒性提供了关键洞见。"}
{"llm_update_time": "20251015", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.09719", "html_url": "https://arxiv.org/abs/2510.09719", "title": "ICL-Router: 在上下文中学到的LLM表示法用于模型路由", "title_en": "ICL-Router: In-Context Learned Model Representations for LLM Routing", "authors": "Chenxu Wang,Hao Li,Yiqun Zhang,Linyao Chen,Jianhao Chen,Ping Jian,Peng Ye,Qiaosheng Zhang,Shuyue Hu", "background": "大规模语言模型（LLMs）通常表现出互补的强项。模型路由通过动态将每个查询导向最适合的模型来利用这些强项。然而，路由性能依赖于准确的模型表示，并且每当添加新模型时通常需要重新训练路由模型，这限制了扩展性。", "innovation": "本文提出了一种新的路由方法，利用上下文向量表示模型的能力。该方法分为两个步骤：首先，查询被嵌入并投影到向量中，用一个投影器和基于LLM的路由器训练去重建原始查询，确保向量表示与路由器的语义空间对齐；其次，每个候选模型在一组查询上进行配置，路由器根据查询和模型在上下文中的表现来预测每个模型能否正确回答新的查询。广泛的实验表明，该方法在分布内和分布外任务中均实现了最先进的路由性能。此外，该方法还允许无缝集成新模型而无需重新训练路由器。", "conclusion": "本研究提出的ICL-Router方法在LLM路由上取得了显著进展，在提升路由性能的同时，简化了扩展新模型的过程。该方法已经通过了广泛的实验验证，并且代码已经发布。"}
{"llm_update_time": "20251015", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.10341", "html_url": "https://arxiv.org/abs/2510.10341", "title": "Graph-Tuple 多视图图学习", "title_en": "Multi-View Graph Learning with Graph-Tuple", "authors": "Shiyu Chen,Ningyuan Huang,Soledad Villar", "background": "图神经网络（GNNs）通常根据图的边数进行缩放，这使得它们在稀疏图上非常有效，但在密集图上（如点云或分子交互）效率较低。一种常见的解决办法是通过相似度阈值或距离剪枝来稀疏化图，但这需要人为选择一种相互作用尺度，并且会丢弃其他尺度的重要信息。", "innovation": "本文引入了一种多视图图-元组框架。我们不对整个图进行操作，而是将其分解为不相交的子图，同时捕捉主要的本地交互和较弱的远距离连接。我们通过一种受非交换算子理论启发的异质消息传递架构学习多视图表示，这一方法被形式化证明为比单一图的消息传递模型更具表达力，并能保证较低的Oracle风险。我们使用此框架在两个科学领域上进行了应用：基于特征稀少的库仑矩阵的分子性质预测和基于几何点云的宇宙学参数推断。实验证明，我们的多视图图-元组模型在两个应用中的表现优于单一图基线，展示了该多视图方法的强大和灵活性。", "conclusion": "我们的多视图图-元组模型在分子性质预测和宇宙学参数推断上的表现优于单一图基线，说明了多视图方法的强大力量和适用性。"}
{"llm_update_time": "20251015", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.01656", "html_url": "https://arxiv.org/abs/2510.01656", "title": "非对称近端策略优化：迷你评论者提升大语言模型推理", "title_en": "Asymmetric Proximal Policy Optimization: mini-critics boost LLM reasoning", "authors": "Jiashun Liu,Johan Obando-Ceron,Han Lu,Yancheng He,Weixun Wang,Wenbo Su,Bo Zheng,Pablo Samuel Castro,Aaron Courville,Ling Pan", "background": "大多数最近的基于强化学习（RL）的方法在大规模语言模型（LLM）中避免了显式的评论者，而是用平均优势基线替代。这一转变主要是实用性的：传统价值函数在大数据量的语言模型上训练时非常耗时，且在稀疏奖励和长时间推理的情况下往往效果不佳。本文从架构层面重新审视这一瓶颈问题，并提出了非对称近端策略优化（AsyPPO），这是一种简单且可扩展的框架，能够在不牺牲效率的情况下恢复评论者的作用。AsyPPO 使用一组轻量级的迷你评论者，每个评论者都在不重叠的提示片段上训练，这鼓励了多样性并保持了校准，从而减少了价值估计偏见。此外，AsyPPO 还利用评论者之间的不确定性来改善策略更新：在评论者一致同意且梯度添加的增益较少的状态下，遮蔽优势；并过滤高差异状态，以抑制不必要的探索。", "innovation": "AsyPPO 引入了一种简单且可扩展的框架，通过一组轻量级的迷你评论者训练，以处理超大规模模型的问题。这些迷你评论者在不重叠的提示片段上单独训练，从而增加了模型的多样性和校准性。AsyPPO 利用了评论者之间的不确定性来优化策略更新，一方面通过在评论者一致同意且梯度回报较低的状态下遮蔽优势，另一方面在较高的不确定性状态下减少熵正则化，以抑制不必要的探索。这些创新显著提升了学习的稳定性和性能，对比了许多强大的基线模型，包括 GRPO，而无需额外的技巧。", "conclusion": "AsyPPO 在开放数据集上仅用 5,000 个样本进行训练后，无论是在 Qwen3-4b-Base、Qwen3-8b-Base 还是 Qwen3-14b-Base 上都显著提升了学习的稳定性和性能，与经典的 PPO 相比，性能提高了超过 6%。这些结果突显了有影响力的架构创新对于大规模、高效算法的重要性。"}
{"llm_update_time": "20251015", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.03269", "html_url": "https://arxiv.org/abs/2510.03269", "title": "在RLHF中的通用探索奖金用于乐观探索", "title_en": "General Exploratory Bonus for Optimistic Exploration in RLHF", "authors": "Wendi Li,Changdae Oh,Sharon Li", "background": "乐观探索在增强学习中通过人类反馈提高样本效率方面起着关键作用，但现有激励探索的探索奖金方法往往未能实现乐观主义。目前的公式化方法在KL或$\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\beta}}}}}}}}}}}}}}}}}}}}}}}}}}$-散度正则化下，无意中偏向于参考模型的高概率区域，强化保守行为而不是鼓励探索不确定区域。", "innovation": "提出了一种新颖的理论框架——通用探索奖金（GEB），该框架可证明满足乐观原则。GEB 通过参考依赖的奖励调节来抵消散度诱导的偏差，并将先前的经验奖金作为特殊情况统一在一起，同时自然地扩展到整个$\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\beta}}}}}}}}}}}}}}}}}}}}}}}}$-散度家族，从而能够一致地在多个散度设置和大规模语言模型背景下超越基线方法。这些结果表明GEB提供了乐观探索的既指导性又实用的解决方案。", "conclusion": "GEB 在增强学习中通过人类反馈实现乐观探索，为这种方法提供了一个既经得起检验又实际可行的解决方案。在多项实验中均优于基线方法，特别是在涉及不确定区域的发现任务中。"}
{"llm_update_time": "20251015", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.09487", "html_url": "https://arxiv.org/abs/2510.09487", "title": "近最优的基于模型的对抗性模仿学习的二次保证", "title_en": "Near-Optimal Second-Order Guarantees for Model-Based Adversarial Imitation Learning", "authors": "Shangzhe Li,Dongruo Zhou,Weitong Zhang", "background": "研究在线对抗性模仿学习（AIL），其中智能体从离线专家演示中学习，并在线与环境交互但无法访问奖励。尽管取得了强有力的实验结果，但在线交互的好处及其对随机性的影响仍然不完全理解。该研究通过引入基于模型的AIL算法（MB-AIL），填补了这一空白，并在通用函数近似下建立了其与专家数据和奖励无关交互相关的无截断的二次样本复杂性保证。这些二次边界提供了实例相关的结果，能够根据相关策略回报的方差进行缩放，因此随着系统接近确定性，这些边界会更为严格。", "innovation": "引入了基于模型的AIL算法（MB-AIL），并且在通用函数逼近下建立了无截断的二次样本复杂性保证。此外，研究还与新构造的硬实例家庭的信息论下界相结合，展示了MB-AIL在有限专家演示的情况下达到最小最大最优样本复杂性，与下界在时间范围$H$、精度$\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{}}}}}}}$$\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{}}}}}}}$和策略方差$\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{}}}}}}}$方面的依赖关系相同。实验结果还验证了理论发现，并表明实际实施的MB-AIL在样本效率上与现有方法相当或更优。", "conclusion": "该研究在无奖惩交互的情况下，通过引入MB-AIL算法，填补了在线交互好处和随机性影响的理解空白。MB-AIL在基于模型的增强学习领域取得了重要的理论突破，显示了其在实际应用中的高效性。"}
{"llm_update_time": "20251015", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.11062", "html_url": "https://arxiv.org/abs/2510.11062", "title": "强强联手：协作大语言模型的在线强化学习", "title_en": "Stronger Together: On-Policy Reinforcement Learning for Collaborative LLMs", "authors": "Yujie Zhao,Lanxiang Hu,Yang Wang,Minmin Hou,Hao Zhang,Ke Ding,Jishen Zhao", "background": "多智能体系统（MAS）和强化学习（RL）被广泛用于提升大型语言模型（LLMs）的智能能力。MAS 通过基于角色的协调性提升任务性能，而 RL 则利用环境奖励学习更强的策略。然而，将在线 RL 应用于 MAS 仍然较少被探索且存在独特挑战。", "innovation": "该研究提出了 AT-GRPO，这是一种针对 MAS 专门设计的基于角色和回合的分组 RL 算法，以及支持单策略和多策略模式的训练系统。在游戏、规划、编程和数学任务中，AT-GRPO 显著提高了性能。特别是在长足规划中，单智能体 RL 基线从 14.0% 提高到 96.0% 至 99.5%。并在编程和数学任务中分别平均提高了 3.87% 到 7.62% 和 9.0% 到 17.93% 的推理性能。", "conclusion": "AT-GRPO 在多种任务中提供了显著的改进，特别是在长期规划中，单智能体 RL 基线性能从 14.0% 提高到 96.0% 至 99.5%，并且在编程和数学推理任务中也表现出了显著的进步。该论文提供的代码和环境可以在提供的链接中获得。"}
{"llm_update_time": "20251015", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.10764", "html_url": "https://arxiv.org/abs/2510.10764", "title": "Optimally Deep Networks -- Adapting Model Depth to Datasets for Superior Efficiency", "title_en": "Optimally Deep Networks -- Adapting Model Depth to Datasets for Superior Efficiency", "authors": "Shaharyar Ahmed Khan Tareen,Filza Khan Tareen", "background": "深度神经网络（DNNs）在各种任务中提供了出色的性能，但这些成功通常是以不必要的大模型规模、高计算需求和大量内存使用为代价的。通常，强大的架构以全深度训练，但并不过所有数据集或任务真正需要如此高的模型容量。在相对低复杂度的数据集上训练非常深的架构通常会导致计算浪费、不必要的能源消耗和过度的内存使用，进而使得在资源受限的设备上部署模型变得不切实际。", "innovation": "本文引入了一种称为渐进深度扩展的网络架构训练策略，即ODNs（Optimally Deep Networks），以在模型深度和任务复杂度之间提供平衡。ODNs在特定数据集上仅使用必要的深度，去除冗余层，从而降低未来的训练和推理成本，减少内存占用，提高计算效率，并便于在边缘设备上的部署。实验结果表明，对于MNIST和SVHN数据集，ResNet-18和ResNet-34的最优深度分别实现了高达98.64％和96.44％的内存占用量减少，同时保持了竞争性的精度99.31％和96.08％。", "conclusion": "ODNs通过仅使用给定数据集所需的最优深度，去除冗余层，从而减少了未来的训练和推理成本，并提高了计算效率，同时大大降低了内存占用，使模型能够在资源受限的设备上更易于部署。在不同数据集上进行的实验支持了ODNs的有效性，并表明这种优化策略可以在节省资源的同时保持良好的性能。"}
{"llm_update_time": "20251015", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.11683", "html_url": "https://arxiv.org/abs/2510.11683", "title": "Boundary-Guided Policy Optimization for Memory-efficient RL of Diffusion Large Language Models", "title_en": "Boundary-Guided Policy Optimization for Memory-efficient RL of Diffusion Large Language Models", "authors": "Nianyi Lin,Jiajie Zhang,Lei Hou,Juanzi Li", "background": "应用强化学习（RL）到扩散型大语言模型（dLLMs）的一个关键挑战是其不可解的似然函数，这些函数在RL目标中至关重要，需要在每次训练步骤中进行相应的近似。现有方法通过定制的蒙特卡洛（MC）采样近似对数似然度，但所有的MC采样前向计算图需要保留以进行非线性项的梯度计算，这导致了巨大的内存开销，限制了可行的样本大小，从而导致了不准确的似然近似，最终扭曲了RL目标。", "innovation": "本文提出了Boundary-Guided Policy Optimization (BGPO)，这是一种内存高效的RL算法，通过最大化基于ELBO目标的特制下界来优化策略。该下界被精心设计，具有两个关键性质：线性特性，使其成为每个样本独立的线性和，便于梯度累积并保持恒定的内存使用；等值特性，使其在有政策训练中的价值和梯度与基于ELBO的目标相等，从而也成为原始RL目标的有效近似。这些性质允许BGPO采用较大的MC采样规模，从而提高RL目标的估计精度和性能。实验结果表明，BGPO在数学问题解决、代码生成和规划任务中显著优于之前用于dLLMs的RL算法。我们的代码和模型可以在提供的链接中获得。", "conclusion": "BGPO不仅在内存开销上表现出色，还能提供更准确的似然近似和改进的RL目标估计，因此在实践中表现出更好的性能。"}
{"llm_update_time": "20251015", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2311.02433", "html_url": "https://arxiv.org/abs/2311.02433", "title": "ChatGPT能否支持软件验证？", "title_en": "Can ChatGPT support software verification?", "authors": "Christian Janßen,Cedric Richter,Heike Wehrheim", "background": "大语言模型在软件工程任务中表现出色，例如代码生成、调试和修复。这些模型不仅能生成代码，还能解释其工作原理及其正确性，这引发了利用像ChatGPT这样的语言模型支持形式化软件验证的问题。", "innovation": "本文探索了ChatGPT生成循环不变式的可能性，这是一种核心的软件验证任务。研究通过向Frama-C和CPAchecker两个形式验证器提供生成的不变式来验证它们的有效性和实用性，结果显示ChatGPT生成的不变式有助于以前Frama-C无法解决的任务的验证。", "conclusion": "本文基于初步见解，提出了将ChatGPT或其他大型语言模型与软件验证器结合的方法，并讨论了当前的局限性和开放问题。"}
{"llm_update_time": "20251015", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2310.00919", "html_url": "https://arxiv.org/abs/2310.00919", "title": "BAAF：一种用于医学超声图像分割任务的基准注意力自适应框架", "title_en": "BAAF: A benchmark attention adaptive framework for medical ultrasound image segmentation tasks", "authors": "Gongping Chen,Lei Zhao,Xiaotao Yin,Liang Cui,Jianxun Zhang,Yu Dai,Ningning Liu", "background": "基于AI的辅助诊断程序在医学超声图像中得到了广泛研究。但在复杂的超声图像场景中，内部和外部因素的耦合干扰严重，使得自动精确定位超声图像对象区域具有独特的挑战。因此，研究如何更加通用且稳健地开发辅助医生在超声图像中快速准确地分割或诊断病变和组织的方法，成为了一个重要的研究主题。", "innovation": "提出了一种平行混合注意力模块（PHAM）和自适应校准机制（ACM）构成的标准化注意力自适应框架（BAAF）。该框架首先对输入特征进行粗略校准，然后从粗校准后的特征图中自适应地选择更稳健的病变或组织特征描述。BAAF通过优化CNN中的“重点”和“位置”选择问题，旨在提高医学超声图像中病变或组织分割的准确性。", "conclusion": "BAAF在四个医学超声分割任务中的评价结果表明，其在提高现有先进方法性能方面表现显著，同时与现存的注意力机制相比，也展示了其优越性。这项工作为自动化的医学超声辅助诊断提供了可能，并降低了对人类精确度和精度的依赖。"}
{"llm_update_time": "20251015", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2208.08067", "html_url": "https://arxiv.org/abs/2208.08067", "title": "K-ASTRO：结构感知的LLM适应性编码漏洞检测", "title_en": "K-ASTRO: Structure-Aware Adaptation of LLMs for Code Vulnerability Detection", "authors": "Yifan Zhang,Michael Sandborn,Stefan Larson,Yu Huang,Kevin Leach", "background": "大型语言模型（LLMs）正在改变软件工程任务，包括代码漏洞检测，这是一个重要的软件安全领域。然而，现有的方法往往依赖于资源密集型模型或基于图的技术，这限制了它们的可用性和实用性。", "innovation": "该论文介绍了K-ASTRO，一种轻量级的变压器模型，结合了LLMs的语义嵌入与抽象语法树（AST）的结构特征，以提高代码漏洞检测的效率和准确性。该方法引入了一种基于AST的增强技术，灵感来自突变测试，一种结构意识的注意力机制，结合了增强的AST特征，以及一个联合适应流水线，以统一代码语义和语法。实验结果在三大大规模数据集（BigVul、DiverseVul 和 PrimeVul）上展示了最先进的性能，同时能够通过CPU实现快速推理并大大缩短训练时间。K-ASTRO提供了一个可扩展、可解释、高效的解决方案，通过开放源代码工具为后续研究提供支持，缩小了LLM进步与实用的软件漏洞检测之间的差距。", "conclusion": "K-ASTRO通过结合LLMs的语义嵌入和AST的结构特征，提供了一种高效的代码漏洞检测方法。它不仅提高了性能，还使得最先进的方法可以在CPU上快速部署，增强了开发过程的实用性。此外，推出的开源工具促进了该领域的进一步研究。"}
{"llm_update_time": "20251015", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2403.00841", "html_url": "https://arxiv.org/abs/2403.00841", "title": "离线假想自游戏在竞争性游戏中的应用", "title_en": "Offline Fictitious Self-Play for Competitive Games", "authors": "Jingxiao Chen,Weiji Xie,Weinan Zhang,Yong yu,Ying Wen", "background": "离线强化学习（RL）允许通过固定的数据集进行策略改进而无需在线交互，使其非常适合缺乏高效模拟器的实际应用场景。尽管在单智能体设置中取得了成功，但离线多智能体RL在竞争性游戏中依然面临挑战。主要原因在于无法利用自游戏这种学习范式，以及实际数据集无法覆盖所有状态和动作空间，这使得难以识别纳什均衡。", "innovation": "论文提出了名为OFF-FSP的第一个实际的无模型离线RL算法，用于竞争性游戏。该算法通过重要性采样调整固定数据集权重来模拟与不同对手的交互，并结合单智能体离线RL方法和假想自游戏（FSP）来近似纳什均衡，从而解决了数据覆盖不足的问题。", "conclusion": "实验表明OFF-FSP在矩阵博弈、扩展现形扑克和棋盘游戏中显著降低了可利用性，特别是在一个真实的人机竞争任务中表现良好，展示了它在解决复杂、难以模拟的实际问题上的潜力。"}
{"llm_update_time": "20251015", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2403.15524", "html_url": "https://arxiv.org/abs/2403.15524", "title": "PPA-Game: 描述和学习在线内容创作者之间竞争动态", "title_en": "PPA-Game: Characterizing and Learning Competitive Dynamics Among Online Content Creators", "authors": "Renzhe Xu,Haotian Wang,Xingxuan Zhang,Bo Li,Peng Cui", "background": "该论文探讨了在网络推荐系统（如YouTube和TikTok）中，内容创作者竞争有限消费者注意力的情况。在这个背景下，内容创作者需要依据自身内容的质量进行竞争，而其收益则基于不同的权重分配而成比例确定的。", "innovation": "提出了比例收益分配游戏（PPA-Game）模型，该模型不仅对PPA-Game进行了博弈理论分析，还引入了多玩家多臂老虎机框架来讨论代理人在线学习资源收益的过程。此外，提出了一个在线算法，该算法对于T轮中每个代理累积收益的最大化具有理论上可证明的最优性界限。", "conclusion": "研究表明，虽然PPA-Game不总是保证纯纳什均衡的存在，但在大多数情况下仍存在纯纳什均衡。该方法通过理论分析和实验证明了在线学习算法的有效性。"}
{"llm_update_time": "20251015", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2405.13950", "html_url": "https://arxiv.org/abs/2405.13950", "title": "学习采样纤维进行拟合优度检验", "title_en": "Learning to sample fibers for goodness-of-fit testing", "authors": "Ivan Gvozdanović,Sonja Petrović", "background": "文章讨论了为离散指数族模型构建精确拟合优度检验的问题，这是一个经典但至今对于许多结构化或稀疏数据类型来说仍然难以解决的问题。难题在于需要有效从高维多胞形中的格点中采样，这是计算上难解的核心任务。", "innovation": "文章将该问题转化为马尔可夫决策过程，并展示了一种强化学习方法来学习采样策略。这种方法特别适用于那些传统MCMC采样器由于问题大小、稀疏结构以及过程中需要进行禁止性的非线性代数计算而收敛缓慢的数据集和模型。创新之处在于在提供了非线性代数理论保证的同时，采用线性代数中的可扩展工具。算法基于一个证明收敛的演员-评论家采样方案。", "conclusion": "通过这种方法发现的采样策略能够有效地获得交换样本，显著地减少了统计检验所需的计算时间。"}
{"llm_update_time": "20251015", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2405.15132", "html_url": "https://arxiv.org/abs/2405.15132", "title": "超越噪声：通过最优邻域识别的固有维度估计", "title_en": "Beyond the noise: intrinsic dimension estimation with optimal neighbourhood identification", "authors": "Antonio Di Noia,Iuri Macocco,Aldo Glielmo,Alessandro Laio,Antonietta Mira", "background": "固有维度（ID）在无监督学习和特征选择中是一个关键概念，因为它是系统描述所需的变量数的一个下界。然而，在几乎所有的真实数据集分析中，固有维度都依赖于数据的分析尺度。通常，在小规模时，固有维度非常大，因为数据受到测量误差的影响。在大规模时，固有维度也可能被错误地增大，因为包含数据的流形的曲率和拓扑结构所致。", "innovation": "本文提出了一种自动化协议，用于选择正确的尺度范围，使得在该范围内固有维度有意义且有用。该协议基于以下原则：对于小于正确尺度的距离，数据密度应保持恒定。在提出的框架中，通过估计密度来估计固有维度，因此这种条件是自洽地施加的。", "conclusion": "通过在人工和真实数据集上的基准测试证明了该程序的有效性和稳健性。"}
{"llm_update_time": "20251015", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2407.00736", "html_url": "https://arxiv.org/abs/2407.00736", "title": "量子电路合成与编译优化：综述与前景", "title_en": "Quantum Circuit Synthesis and Compilation Optimization: Overview and Prospects", "authors": "Ge Yan,Wenjie Wu,Yuheng Chen,Kaisen Pan,Xudong Lu,Zixiang Zhou,Yuhan Wang,Ruocheng Wang,Junchi Yan", "background": "量子计算是一个有望克服当前计算能力瓶颈的研究方向。随着量子处理器技术的逐渐成熟，越来越多的研究关注于量子算法的开发与实现，特别是在逻辑电路设计和量子编译优化这两个关键步骤。近年来，研究人员发现这种方法的规模和精度正在稳定提升，尤其在整合人工智能方法之后。", "innovation": "本研究综合了从算法层到量子硬件的集成设计和优化方案，结合了逻辑电路设计和编译优化的步骤，利用人工智能算法的出色认知和学习能力，以期降低人工设计成本，提高执行的精确性和效率，并促进量子算法在硬件上的实现与验证。", "conclusion": "本文系统地回顾和整理了大量文献，探讨了一种从算法层到量子硬件的集成设计和优化方案的可行性，强调了通过整合人工智能技术来减少人工成本、提高执行效率和验证量子算法优越性的重要性。"}
{"llm_update_time": "20251015", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2412.12004", "html_url": "https://arxiv.org/abs/2412.12004", "title": "大型语言模型（LLMs）的开源优势", "title_en": "The Open Source Advantage in Large Language Models (LLMs)", "authors": "Jiya Manchanda,Laura Boettcher,Matheus Westphalen,Jasser Jasser", "background": "大型语言模型（LLMs）在自然语言处理领域迅速发展，推动了诸如文本生成、机器翻译和领域特定推理等任务的重大突破。然而，该领域现在面临着一个关键的立场问题：一方面，像GPT-4这样的闭源模型能够提供最先进的性能，但限制了可重复性、可访问性和外部监管；另一方面，像LLaMA和Mixtral这样的开源框架则降低了使用门槛，促进了合作并支持多元的应用，通过技术如指令调优和LoRA实现了竞争性的成果。", "innovation": "文章探讨了一种混合方法来解决偏见缓解和资源可访问性的挑战，该方法结合了闭源系统的扩展性和开源框架的透明性和包容性。同时，文章认为开源是推进大型语言模型研究和伦理部署的最稳健途径。", "conclusion": "最终，文章主张开源框架是推动大型语言模型研究和伦理应用的最佳路径。"}
{"llm_update_time": "20251015", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2406.02575", "html_url": "https://arxiv.org/abs/2406.02575", "title": "跨模态安全性对齐：仅仅需要文本去学习吗？", "title_en": "Cross-Modal Safety Alignment: Is textual unlearning all you need?", "authors": "Trishna Chakraborty,Erfan Shayegani,Zikui Cai,Nael Abu-Ghazaleh,M. Salman Asif,Yue Dong,Amit K. Roy-Chowdhury,Chengyu Song", "background": "最近的研究表明，将新模态融入大型语言模型（LLMs），如视觉语言模型（VLMs），创造了新的攻击面，绕过了现有的诸如监督微调（SFT）和基于人类反馈的强化学习（RLHF）等安全训练技术。虽然可以在多模态环境下进一步进行SFT和RLHF安全训练，但收集多模态训练数据存在显著挑战。因此，借鉴近期多模态模型的结构设计，即不论输入模态的组合如何，最终都会被融合到语言空间中，本文旨在探索仅在文本域中去学习是否能够有效实现跨模态的安全性对齐。", "innovation": "本文的创新之处在于，研究了在视觉语言模型中仅在文本域进行去学习是否可以有效实现跨模态的安全性对齐，而无需使用多模态数据集进行训练，从而节省计算资源。实验表明，仅在文本域进行去学习可以显著降低攻击成功率（ASR）至低于8%，有时甚至低至不到2%，同时保留了模型的实际应用价值。此外，实验表明，使用多模态数据集进行去学习虽然并没有提升性能，但却增加了显著的计算需求，最多可能增加6倍。", "conclusion": "跨模态安全性对齐研究显示，在视觉语言模型中仅在文本域进行去学习可以有效降低攻击成功率，且无需显著增加计算资源，而使用多模态数据集进行去学习则增加了显著的计算需求，但并没有提升性能。"}
{"llm_update_time": "20251015", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2410.07222", "html_url": "https://arxiv.org/abs/2410.07222", "title": "使用图神经网络计算系统性风险措施", "title_en": "Computing Systemic Risk Measures with Graph Neural Networks", "authors": "Lukas Gonon,Thilo Meyer-Brandis,Niklas Weber", "background": "本文研究了具有显式建模双边负债的随机金融网络中的系统性风险衡量标准。研究者在此基础上，将Biagini等（2019）提出的风险衡量标准的概念扩展到图结构化的数据集上。特别地，研究者关注的是由Eisenberg和Noe（2001）提出的清结算算法衍生出的聚合函数。在这一设置下，作者证明了存在一个最优随机分配，它能够分配总的最小救助资本并确保网络运行。此外，本文还研究了系统性风险和最优随机分配的数值方法。", "innovation": "本文创新性地提出了使用置换等变神经网络架构，如图神经网络（GNNs）和扩展置换等变神经网络（(X)PENNs），来逼近系统性风险和最优随机分配。这些等变网络特别适用于处理图数据。通过数值实验，本文提供了证据表明这些置换等变方法优于其他方法。", "conclusion": "本文展示了如何利用置换等变方法计算系统性风险，并通过理论证明和实证分析验证了这些方法的有效性。"}
{"llm_update_time": "20251015", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2502.01555", "html_url": "https://arxiv.org/abs/2502.01555", "title": "电子商务搜索中的查询品牌实体链接", "title_en": "Query Brand Entity Linking in E-Commerce Search", "authors": "Dong Liu,Sreyashi Nag", "background": "本文讨论了电子商务搜索查询中的品牌实体链接问题。这一任务的挑战在于查询极其简短，缺乏自然语言结构，并且需要处理大量的独特品牌。", "innovation": "本文提出了两种创新方法：一种是结合命名实体识别与匹配的两阶段方法，另一种是使用极端多分类的全端到端解决方案。", "conclusion": "通过离线基准测试和线上的A/B测试，验证了这两个解决方案的有效性。"}
{"llm_update_time": "20251015", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2410.11857", "html_url": "https://arxiv.org/abs/2410.11857", "title": "LLMBridge: 在提示为中心的互联网中降低成本", "title_en": "LLMBridge: Reducing Costs in a Prompt-Centric Internet", "authors": "Noah Martin,Abdullah Bin Faisal,Hiba Eltigani,Rukhshan Haroon,Swaminathan Lamelas,Fahad Dogar", "background": "今天的互联网基础设施围绕HTTP进行内容检索，中间设备（如HTTP代理）在性能、安全性和成本效益方面起着关键作用。未来，互联网通信将主要通过向生成式AI模型发送“提示”来实现。因此，将需要能够提供类似HTTP代理功能（如缓存、路由、压缩）的代理，同时解决基于提示通信的独特挑战和机会。作为支持基于提示通信的第一步，我们介绍了LLMBridge，这是一种针对成本意识用户（如发展中国家和地区、教育用户，例如学生和教师）设计的LLM代理，支持三项关键优化：模型选择（将提示路由到最适合的模型）、上下文管理（智能减少上下文量）和语义缓存（使用本地模型和向量数据库提供提示）。这些优化在成本和质量之间引入了权衡，应用程序通过高级双向接口对其进行导航。", "innovation": "LLMBridge是一种专为成本意识用户设计的LLM代理，支持三项关键优化：模型选择、上下文管理和语义缓存。这些优化在成本和质量之间引入了权衡，应用程序通过高级双向接口对其进行导航。我们在两种成本敏感环境中部署了LLMBridge：一个基于WhatsApp的问题解答服务和一个大学教室环境。WhatsApp服务已经运行超过12个月，服务100多名用户，处理超过14700个请求。同时，我们在三个计算机科学课程中向学生展示了LLMBridge，支持了各种LLM驱动的应用程序，平均每天处理500多个请求。我们记录了两种环境下的部署经验，并使用收集的工作负载来评估不同成本优化策略的有效性，分析了其成本、延迟和响应质量之间的权衡。", "conclusion": "我们报告了在两种环境下的部署经验，并使用收集的工作负载来评估不同成本优化策略的有效性。实验结果表明，LLMBridge能够在减轻成本的同时提供高质量的服务。"}
{"llm_update_time": "20251015", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2501.10486", "html_url": "https://arxiv.org/abs/2501.10486", "title": "使用基于注意机制的模型提高引力波参数估计中机器学习的可靠性", "title_en": "Enhancing the reliability of machine learning for gravitational wave parameter estimation with attention-based models", "authors": "Hibiki Iwanaga,Mahoro Matsuyama,Yousuke Itoh", "background": "该研究旨在提高通过机器学习估计引力波参数的可靠性。研究人员开发了基于视觉变换器的两个独立机器学习模型来从双黑洞合并的引力波信号频谱图中估计有效自旋和引力波合并质量。为了增强这些模型的可靠性，他们采用了注意力图来可视化模型在预测时关注的区域，这有助于验证模型的参数估计是否基于物理意义上的信息。此外，通过使用这些注意力图，研究者还展示了评估参数估计结果受到干扰影响的方法。研究结果显示，当模型更多地关注干扰时，参数估计结果会更受到偏置影响。", "innovation": "该研究的创新之处在于，通过开发基于视觉变换器的机器学习模型，并利用注意力图可视化模型关注的区域，提高了引力波参数估计的可靠性。此外，研究者还展示了基于注意力图评估参数估计结果受干扰影响的方法，这为区分模型生成可靠还是不可靠的参数估计结果提供了一种潜在的方法。", "conclusion": "该研究展示了两个基于视觉变换器的独立机器学习模型在从双黑洞合并引力波信号频谱图中估计有效自旋和合并质量方面的卓越表现。利用注意力图验证了模型参数估计的有效性，并且研究证实了关注干扰对参数估计结果有显著影响。通过这种方法，未来可以更好地评估机器学习模型生成的参数估计结果的可靠性，为引力波天体物理研究提供更可靠的数据支持。"}
{"llm_update_time": "20251015", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2502.14894", "html_url": "https://arxiv.org/abs/2502.14894", "title": "FOCUS on Contamination: 一种具有噪声感知损失的地理空间深度学习框架，用于地表水PFAS预测", "title_en": "FOCUS on Contamination: A Geospatial Deep Learning Framework with a Noise-Aware Loss for Surface Water PFAS Prediction", "authors": "Jowaria Khan,Alexa Friedman,Sydney Evans,Rachel Klein,Runzi Wang,Katherine E. Manz,Kaley Beins,David Q. Andrews,Elizabeth Bondi-Kelly", "background": "全氟和多氟烷基物质（PFAS）是一种存在于不粘锅等产品中的持久性环境污染物，对人体健康有严重风险。准确地映射PFAS污染对于指导定向修复工作和保护公众及环境健康至关重要。然而，由于测试成本高且模拟其传播的难度大，在大面积地区检测仍然具有挑战性。本研究旨在通过构建具有噪声感知损失函数的空间深度学习框架（FOCUS），解决这一问题，以提高地表水PFAS污染预测的准确性。", "innovation": "提出的FOCUS框架引入了具有标签噪声感知损失函数的空间深度学习模型，通过整合水文流动数据、地表覆盖信息以及已知PFAS污染源的距离，同时结合空间和环境背景信息，提升预测精度。该框架通过对不同抽样率情况下预测结果的敏感性分析、对实际数据的验证以及与现有基准方法（如稀疏分割、克里金法和污染物质传输模拟）的对比分析，展示了其在大规模PFAS监控中的潜力。", "conclusion": "通过广泛开展消融研究、鲁棒性分析、实际验证和现有的基准方法对比分析，研究结果显示该框架在PFAS地表水污染预测中具有潜在的应用价值。"}
{"llm_update_time": "20251015", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2505.05510", "html_url": "https://arxiv.org/abs/2505.05510", "title": "如何训练你的形态变化深度神经网络", "title_en": "How to Train Your Metamorphic Deep Neural Network", "authors": "Thomas Sommariva,Simone Calderara,Angelo Porrello", "background": "NeuMeta是一个基于隐式神经表示（INR）的新范式，用于生成不同宽度和深度的神经网络。它学习连续的权重流形，可以直接生成压缩模型，包括训练期间未见过的配置。尽管NeuMeta有前景，但其原始版本只能在底层模型的最后几层有效，限制了其更广泛的适用性。", "innovation": "本文提出了一种训练算法，扩展了NeuMeta的能力，使其能够实现整个网络的形态变化，同时最小化准确性降级。该方法包括块级别的增量训练、INR初始化以及替换批量归一化的策略。这种方法生成的形态变化网络在其压缩比范围内保持了竞争力，提供了一种可扩展的解决方案，以实现深度模型的适应和高效部署。", "conclusion": "所提出的方案实现了整个网络的形态变化，同时保持了竞争力的准确性，为深度模型的可适应高效部署提供了可扩展的解决方案。"}
{"llm_update_time": "20251015", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2504.01924", "html_url": "https://arxiv.org/abs/2504.01924", "title": "Gen-C：使用生成性人群填充虚拟世界", "title_en": "Gen-C: Populating Virtual Worlds with Generative Crowds", "authors": "Andreas Panayiotou,Panayiotis Charalambous,Ioannis Karamouzas", "background": "过去二十年间，研究者在模拟基于代理的人群方面取得了重要的进展，但大多数努力集中在诸如碰撞避免、路径跟随和群集等低级任务上。为了实现更现实的模拟，需要对从代理自身的交互以及与环境的长期交互中涌现出来的高级行为进行建模。本文介绍了一种名为Generative Crowds (Gen-C)的生成框架，它可以产生捕捉到代理-代理与代理-环境互动的事件场景，形成有组织的高级群体计划。为了避免收集和标注真实人群视频数据的劳动密集过程，本文利用大型语言模型（LLMs）生成合成的人群场景数据集。", "innovation": "Gen-C采用时间扩展图表示，编码动作、互动和空间上下文。Gen-C 利用了双重变分图自编码器（VGAE）架构，结合了基于文字和结构信号的连接模式和节点特征的学习，克服了直接使用LLM生成的局限性，实现了可扩展而环境感知的多代理人群模拟系统。研究表明，Gen-C能够在多样性行为场景（如大学校园和火车站）中生成异质人群、一致的互动和高阶决策模式，这些模式与实际世界人口动态一致。", "conclusion": "Gen-C展示了其有效性，能够在不同行为场景下生成多样人群、连贯的互动和符合现实世界人口动态的高阶决策模式，从而为生成性人群的虚拟世界填充提供了有潜力的解决方案。"}
{"llm_update_time": "20251015", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2408.11450", "html_url": "https://arxiv.org/abs/2408.11450", "title": "基于椭球的持续同调", "title_en": "Persistent Homology via Ellipsoids", "authors": "Niklas Canova,Sara Kališnik,Aaron Moser,Bastian Rieck,Ana Žegarac", "background": "持久同调是拓扑数据分析中最受欢迎的方法之一。利用持久同调时，第一步是构造一系列嵌套的单纯形复形。存在多种不同的复形可供选择，其中Čech复形、Rips复形、α复形和目击者复形较为流行。本文介绍了一种新颖的几何信息驱动的单纯形复形，名为Rips类型椭球复形。这种方法基于这样的理念：与传统的（欧几里得）以采样点为中心的球体相比，沿着切线方向对齐的椭球体更好地逼近数据。我们通过主成分分析估计从样本直接获得的切空间，并提供一种计算Rips类型椭球条码的算法，这是一种基于Rips类型椭球复形的拓扑描述。另外，我们证明椭球条码对输入数据具有连续性，即输入数据的小扰动会导致相应的椭球条码按比例产生小变化，为与经典Rips和Čech滤波器稳定性结果相当（但略微弱一些）的理论保证。此外，我们进行了大量实验，将Rips类型椭球条码与标准的Rips条码进行了比较。研究结果表明，Rips类型椭球复形特别适用于从采样中估计流形和具有瓶颈的空间的同胚，并且对应于真实拓扑特征的持续间隔比使用数据集Rips复形的结果更长。此外，在稀疏采样点云中，Rips类型椭球条码还产生了更好的分类结果。最后，我们在分类任务中展示Rips类型椭球条码优于Rips条码的表现.", "innovation": "提出了一种基于椭球的新型几何驱动单纯形复形，称为Rips类型椭球复形。该复形以主成分分析从样本直接获得的切空间为理论基础。提出了一种计算Rips类型椭球条码的算法，这是基于Rips类型椭球复形的拓扑描述。证明了椭球条码具有连续性，对输入数据的小扰动会导致相应的椭球条码按比例产生小变化，这种理论保证类似于经典Rips和Čech滤波器的稳定性结果。实验表明Rips类型椭球复形特别适用于估计流形和具有瓶颈的空间的同胚，产生了更长的持续间隔，并且对于稀疏采样点云的分类有更好结果，相较于Rips条码有更出色的表现。", "conclusion": "Rips类型椭球复形在估计流形和具有瓶颈的空间的同胚方面特别有效。与标准Rips复形相比，Rips类型椭球复形在地计算持续间隔时表现出更长的间隔，且在稀疏采样点云的分类任务中效果更优。此外，Rips类型椭球条码在分类任务中的表现也优于标准Rips条码。"}
{"llm_update_time": "20251015", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2505.16612", "html_url": "https://arxiv.org/abs/2505.16612", "title": "指引大型语言模型进行机器翻译个性化", "title_en": "Steering Large Language Models for Machine Translation Personalization", "authors": "Daniel Scalena,Gabriele Sarti,Arianna Bisazza,Elisabetta Fersini,Malvina Nissim", "background": "大型语言模型简化了生成反映预定义风格限制的个性化翻译过程。然而，当风格要求隐含地由一组示例表示，如特定人类翻译者生成的文本时，这些系统仍然存在挑战。本研究探讨了在可用示例较少的情况下，如何个性化自动生成的翻译，尤其是难懂的文学翻译领域。", "innovation": "研究评估了各种提示策略和推理时干预措施，以引导模型生成符合个性化风格的翻译，特别是在对比使用稀疏自动编码器(SAE)潜在变量进行个性化调驱取得显著效果方面。", "conclusion": "对比SAE调驱能够提供稳健的风格条件和翻译质量，相比提示方法在推理时间上更具计算效率。进一步研究表明，编码个性化属性的层在提示和SAE调驱下受到的影响相似，暗示相似的机制在起作用。"}
{"llm_update_time": "20251015", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2505.15696", "html_url": "https://arxiv.org/abs/2505.15696", "title": "MaxPoolBERT：通过层级和令牌级聚合提高BERT分类", "title_en": "MaxPoolBERT: Enhancing BERT Classification via Layer- and Token-Wise Aggregation", "authors": "Maike Behrendt,Stefan Sylvius Wagner,Stefan Harmeling", "background": "BERT中的[CLS]标记通常用作固定长度表示进行分类任务，但先前的研究表明，其他标记和中间层也编码有价值的情境信息。本研究探讨了轻量级的扩展方法，通过在层和标记之间聚合信息来细化[CLS]表示。实验表明这种方法在低资源任务上提高了BERT的分类准确性，而无需进行新的预训练或增加模型大小。这项工作扩展了对BERT在分类任务中的应用的理解，特别是在低资源场景下，展示了新的架构改进的有效性。", "innovation": "本研究提出了一种轻量级的扩展方法，通过在层和标记之间聚合信息来改进BERT的[CLS]表示。具体包括：（i）多层中的[CLS]标记的最大池化；（ii）[CLS]标记通过额外的多头注意力（MHA）层来在整个最终层上进行注意力权衡；（iii）结合整个序列的最大池化与MHA。这种方法无需新的预训练，也无需显著增加模型大小，即可提高BERT的分类准确性，特别是在低资源任务中表现更佳。实验结果表明，MaxPoolBERT在GLUE基准测试的低资源任务中的一致性表现优于标准的BERT基线模型。", "conclusion": "本研究的MaxPoolBERT方法通过轻量级的扩展，在低资源分类任务上显著提升了BERT模型的分类准确性，而无需增加新的预训练步骤或显著增加模型规模。这种通过层级和令牌级聚合信息的方法提供了一种有效的方式来增强BERT模型的表示能力，特别是在资源受限的环境中。"}
{"llm_update_time": "20251015", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2503.17538", "html_url": "https://arxiv.org/abs/2503.17538", "title": "通过近似充分统计量的对比学习的统计理论", "title_en": "A Statistical Theory of Contrastive Learning via Approximate Sufficient Statistics", "authors": "Licong Lin,Song Mei", "background": "对比学习是一种现代方法，用于从无标签数据中抽取有用表示，通过训练模型来区分相似样本和不相似样本，这在基础模型中取得了显著进展。本研究对基于数据增强的对比学习进行了新的理论框架分析，重点关注SimCLR作为典型例子。该研究基于近似充分统计量的概念，将这一概念扩展到了CLE IP使用KL散度进行对比语言-图像预训练的情况之外，并将其推广到等价形式和一般f散度形式", "innovation": "发展了一个新的理论框架来分析数据增强基础上的对比学习，将近似充分统计量的概念扩展到对比语言-图像预训练之外，并将其推广到等价形式和一般f散度形式。证实了通过最小化SimCLR和其他对比损失得到的编码器近似充分，并展示了这些近乎充分的编码器可以有效地适应下游回归和分类任务，评估依赖于它们的充分性和数据增强在对比学习中的误差", "conclusion": "研究结果表明，通过最小化对比损失得到的编码器可以近似为充分统计量形式，并且这些近似充分统计量的编码器可以有效应用于下流任务的表现依赖于它们的充分性以及数据增强在对比学习中的误差。通过研究表明，这一统计理论对于线性回归和主题分类任务具有广泛适用性"}
{"llm_update_time": "20251015", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2505.15877", "html_url": "https://arxiv.org/abs/2505.15877", "title": "突出关键信息：面向属性聚焦图像检索的可提示嵌入", "title_en": "Highlighting What Matters: Promptable Embeddings for Attribute-Focused Image Retrieval", "authors": "Siting Li,Xiang Gao,Simon Shaolei Du", "background": "图像的信息量远超过一千个字，但并非所有的图像内容都对特定任务至关重要，因此需要集中注意力于关键信息。理想的文本到图像检索器应优先处理与查询相关的特定视觉属性。为了评估当前检索器在处理属性聚焦查询方面的性能，研究人员构建了一个名为COCO-Facet的数据集，包含9,112个关于不同兴趣属性的查询。研究发现，尽管CLIP这类检索器因高效和零样本能力而被广泛采用，但它们的表现不佳且不平衡，原因在于其图像嵌入侧重于全局语义和主体，而忽略了其他细节。即使对于最新的基于多模态大型语言模型的检索器，即使输出维度较大，也面临这一限制。因此，研究人员认为使用一般的图像嵌入进行检索对于处理此类查询是低效的。", "innovation": "提出了一种名为可提示图像嵌入的技术，该技术能够突出显示所需的属性，从而提升性能。该方法不仅适用于查询类型和图像池，还能跨基础检索器架构进行推广。为了增强其实用性，提出了两种加速策略：预处理可提示嵌入和使用线性近似。结果显示，预处理策略在预定义提示时可提高5%的Recall@5，而线性近似策略在只有询问期间可用提示时可提高8%的性能。", "conclusion": "可提示的图像嵌入可以更好地专注于特定视觉属性，从而提高属性聚焦图像检索的性能。同时，提出的加速策略可以进一步提升其实用性和实际应用效益。"}
{"llm_update_time": "20251015", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2505.19093", "html_url": "https://arxiv.org/abs/2505.19093", "title": "一种处理随机缺失数据的模型驱动聚类变元选择统一框架", "title_en": "A Unified Framework for Variable Selection in Model-Based Clustering with Missing Not at Random", "authors": "Binh H. Ho,Long Nguyen Chi,TrungTin Nguyen,Binh T. Nguyen,Van Ha Hoang,Christopher Drovandi", "background": "基于模型的聚类与变量选择相结合是揭示复杂数据中潜在结构的强大工具，但这一工具的效果常受到识别定义异质子群的关键变量和处理在如转录组学等领域的数据随机缺失等问题的挑战。已有若干方法被提出以解决这些问题，但这些方法通常各自解决这些问题，从而限制了其灵活性和适应性。", "innovation": "本文提出了一种统一框架，旨在同时解决这些问题。该方法通过引入数据驱动的惩罚矩阵到正则化聚类中，以实现更灵活的变量选择，并且具有一个明确模式缺失与潜在类别隶属关系的机制。证明了提出框架在某些正则条件下具有渐近一致性和选择一致性，即使在有缺失数据的情况下也能实现。", "conclusion": "这一统一策略显着增强了基于模型的聚类的能力和效率，推进了在复杂缺失数据模式下识别信息变量的方法学。框架在仿真和合成及真实转录组学数据集上进行了评估，展示了其性能，包括计算效率。"}
{"llm_update_time": "20251015", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2505.18185", "html_url": "https://arxiv.org/abs/2505.18185", "title": "BrainOmni：统一EEG和MEG信号的大脑基础模型", "title_en": "BrainOmni: A Brain Foundation Model for Unified EEG and MEG Signals", "authors": "Qinfan Xiao,Ziyun Cui,Chi Zhang,Siqi Chen,Wen Wu,Andrew Thwaites,Alexandra Woolgar,Bowen Zhou,Chao Zhang", "background": "脑电图（EEG）和磁源成像（MEG）通过捕捉树突电流产生的电磁场来无创测量神经活动。尽管它们都基于相同的生物物理学原理，但两者表现出不同的信号模式。信号模式因设备和记录装置的传感器配置差异而进一步复杂化。现有方法通常依赖于为单个模态和数据集特定的模型，这限制了性能并阻碍了跨领域的扩展。", "innovation": "本文提出BrainOmni，这是首个能够在异构EEG和MEG记录中泛化的脑基础模型。为了统一多种数据源，引入了BrainTokenizer，它是第一个将时空脑活动量化为离散表示的分词器。其核心是新颖的传感器编码器，能够编码如空间布局、方向和类型等传感器属性，从而在不同设备和模态上保持兼容性。基于离散表示，BrainOmni通过自监督预训练学习通用语义嵌入。此外，这是首个支持EEG和MEG信号，以及首个纳入大规模MEG预训练的模型基础模型。", "conclusion": "共使用1997小时的EEG和656小时的MEG数据进行预训练。实验结果显示，BrainOmni在多种下游任务中优于现有存基础模型和特定任务模型，并且展现出了对未见过的EEG和MEG设备的强泛化能力。进一步分析表明，联合EEG和MEG（EMEG）训练能在这两个模态中都取得一致的改进。代码和模型检查点将在被接受后发布。"}
{"llm_update_time": "20251015", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.01353", "html_url": "https://arxiv.org/abs/2506.01353", "title": "EgoBrain: 统合心智与眼光以实现人类动作理解", "title_en": "EgoBrain: Synergizing Minds and Eyes For Human Action Understanding", "authors": "Nie Lin,Yansen Wang,Dongqi Han,Weibang Jiang,Jingyuan Li,Ryosuke Furuta,Yoichi Sato,Dongsheng Li", "background": "脑-机接口(BCI)，特别是脑电图(EEG)，与人工智能(AI)的整合被证明能够解码人类从神经信号中的认知和行为。特别是在多模态AI模型兴起的背景下，带来了前所未有的新可能性。", "innovation": "提出EgoBrain——世界上第一个大规模、时间同步的多模态数据集，它同步了40名参与者在29类日常活动中记录的32通道EEG和第一人称视频，建立了以人为中心的行为分析新范式。这是一个61小时的同步数据集，通过多模态学习框架融合EEG和视觉进行动作理解，并在跨参与者和跨环境挑战中得到验证，实现了66.70%的动作识别准确率。", "conclusion": "EgoBrain为多模态脑-机接口提供了一体化框架。所有数据、工具和采集协议均公开共享，以促进认知计算中的开放科学。"}
{"llm_update_time": "20251015", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.15732", "html_url": "https://arxiv.org/abs/2506.15732", "title": "LLMs能否在反事实推理中解决知识冲突", "title_en": "Can LLMs Reconcile Knowledge Conflicts in Counterfactual Reasoning", "authors": "Khurram Yamin,Gaurav Ghosal,Bryan Wilder", "background": "大规模语言模型在其参数中包含了广泛的世界知识，这使其能够表现出色的许多知识密集型任务。然而，在新的环境中部署时，这些语言模型经常会遇到必须将参数化知识与新或不熟悉的信息相结合的情况。本研究通过反事实推理的视角，探讨了语言模型是否可以在上下文中结合知识并利用其参数化知识。通过合成和现实的多步推理问题实验，研究表明，语言模型通常在反事实推理上挣扎，往往只能依赖其参数化的知识。此外，研究还表明简单的事后调优可能难以培养反事实推理能力，常常导致存储参数化知识的退化。最终，本研究揭示了现有语言模型在新环境中重新利用参数知识的重要局限性。", "innovation": "本研究通过反事实推理的视角探讨了语言模型在上下文中结合知识并利用其参数化知识的能力。通过合成和现实的多步推理问题实验，研究展示了语言模型在反事实推理上的局限性，并表明简单的事后调优可能难以培养反事实推理能力，常常导致存储参数化知识的退化。", "conclusion": "本研究揭示了现有语言模型在新环境中重新利用参数知识的重要局限性，指出当前模型在处理知识冲突和进行反事实推理方面的不足。"}
{"llm_update_time": "20251015", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.21857", "html_url": "https://arxiv.org/abs/2506.21857", "title": "SPADE: Spatial Transcriptomics and Pathology Alignment Using a Mixture of Data Experts for an Expressive Latent Space", "title_en": "SPADE: Spatial Transcriptomics and Pathology Alignment Using a Mixture of Data Experts for an Expressive Latent Space", "authors": "Ekaterina Redekop,Mara Pleasure,Zichen Wang,Kimberly Flores,Anthony Sisk,William Speier,Corey W. Arnold", "background": "随着数字病理学和自我监督深度学习的进步，多种病理任务在不同疾病中的基础模型得以发展。尽管多模态方法整合了各种数据源，但在将整个切片图像（WSI）与空间转录组学（ST）综合以捕捉标准HE染色无法反映的关键分子异质性方面仍然存在关键空白。", "innovation": "SPADE引入了一种基础模型，该模型将组织病理学与ST数据结合，在统一框架中指导图像表示学习，从而创建一个受ST指导的潜空间。SPADE通过对比学习在两阶段图像特征空间聚类中构建专家，这有助于学习对齐的WSI碎片和基因表达谱的表示。", "conclusion": "SPADE在HEST-1k综合数据集上进行预训练，并在20个下游任务中进行评估，展示了显著优于基准模型的少量-shot性能，强调了将形态学和分子信息整合到同一潜空间的优越性。代码和预训练权重可在提供的链接中获得。"}
{"llm_update_time": "20251015", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.00546", "html_url": "https://arxiv.org/abs/2507.00546", "title": "通过表征学习实现纳米光子学逆设计", "title_en": "Inverse Design in Nanophotonics via Representation Learning", "authors": "Reza Marzban,Ali Adibi,Raphael Pestourie", "background": "逆设计在纳米光子学中的应用，即通过计算方法发现能够实现特定电磁响应的结构，已经成为光学进展中的关键工具。传统的直觉驱动或迭代优化方法难以应对高维度、非凸的设计空间，并且电磁模拟的计算需求也非常可观。最近，机器学习（ML）被用来有效地解决这些瓶颈问题。", "innovation": "这篇论文通过表征学习框架分类讨论了增强逆设计方法的两大类：输出侧和输入侧。输出侧方法利用ML在解空间中学习一个表示，以创建一个可微的求解器来加速优化。输入侧技术则利用ML学习可行的设备几何形状的紧凑表示，通过生成模型实现有效的全局探索。这些方法在数据需求、泛化能力和新设计发现潜力方面各有特点。结合基于物理的优化与数据驱动的表示的混合框架有助于跳出局部最优，提高可扩展性并实现知识转移。", "conclusion": "本文最后强调了开放的挑战和机会，集中在复杂性管理、几何无关的表示、结合制造约束及多物理场联合设计的进展上。"}
{"llm_update_time": "20251015", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.16880", "html_url": "https://arxiv.org/abs/2507.16880", "title": "寻找多里：文本到图像扩散模型的回忆并非局部", "title_en": "Finding Dori: Memorization in Text-to-Image Diffusion Models Is Not Local", "authors": "Antoni Kowalczuk,Dominik Hintersdorf,Lukas Struppek,Kristian Kersting,Adam Dziedzic,Franziska Boenisch", "background": "文本到图像扩散模型（DMs）在图像生成方面取得了显著成功，但潜在的数据隐私和知识产权问题依然存在，这是因为模型有可能无意中记住和复制训练数据。近期的应对措施集中在识别和修剪负责触发直接复制训练数据的权重，假设这种记忆是局部的，可以被定位并删除，然而本文通过实验挑战了这一假设。", "innovation": "作者挑战了记忆是局部的这一假设，发现即使修剪了敏感权重，一小部分文本嵌入的微小变化仍然可以重新触发数据复制。此外，作者通过分析发现，（1）用于触发记忆图片复制的文本嵌入是分布在嵌入空间中的；（2）产生相同复制图像的嵌入会导致模型激活的不同反应；（3）不同的修剪方法对同一张图片识别出的记忆相关权重不同。这些发现表明记忆并非是局部的，为开发更可靠的对抗性微调提供依据，使其能够有效避免DMs的记忆。", "conclusion": "本研究揭示了文本到图像DMs中记忆的本质特点，并提出了防范DMs记忆的可靠方法。通过对记忆的非局部性进行分析，展示了对抗性微调作为一种更强的缓解策略，从而提供了更深入的见解以指导未来相关研究的发展。"}
{"llm_update_time": "20251015", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.08986", "html_url": "https://arxiv.org/abs/2507.08986", "title": "基于物理的机器学习封闭形式和壁面模型在超音速过渡-连续边界层预测中的应用", "title_en": "Physics-Based Machine Learning Closures and Wall Models for Hypersonic Transition-Continuum Boundary Layer Predictions", "authors": "Ashish S. Nair,Narendra Singh,Marco Panesi,Justin Sirignano,Jonathan F. MacArt", "background": "在超音速稀薄流的建模中，由于过渡-连续区（即Knudsen数从0.1到10的范围）内经典连续假设失效，传统的Navier-Stokes-Fourier (NSF) 模型无法准确预测诸如速度滑移、温度跃变和冲击结构偏差等非平衡效应。因此，需要开发一种能够扩展连续求解器在非平衡超音速区适用性的方法。", "innovation": "本文提出了一个基于物理的机器学习框架，通过增强输运模型和边界条件，提高超音速过渡-连续区流体模型的准确性。该框架包括使用深度学习偏微分方程模型（DPMs）来训练粘性剪切应力和热流嵌入的偏微分方程，以及引入基于偏斜高斯分布函数的壁面模型，取代经验性的滑移边界条件，以实现物理驱动的数据驱动边界条件。", "conclusion": "拟合无迹张量粘性模型结合偏斜高斯分布函数壁面模型显著提高了超音速和高Knudsen数区的预测精度。平行训练以及包含高超音速数据的训练策略能够增强模型泛化能力。然而，模式复杂性增加对于样本外情况的作用逐渐减弱，表明在自由度和过拟合之间需要寻求平衡。该研究为在常规连续方法失效的流域中改善超音速流建模提供了数据驱动和物理一致性策略。"}
{"llm_update_time": "20251015", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.02322", "html_url": "https://arxiv.org/abs/2508.02322", "title": "CAMERA: 通过微专家冗余分析进行MoE模型的多矩阵联合压缩", "title_en": "CAMERA: Multi-Matrix Joint Compression for MoE Models via Micro-Expert Redundancy Analysis", "authors": "Yuzhuang Xu,Xu Han,Yuanchi Zhang,Yixuan Wang,Yijun Liu,Shiyu Ji,Qingfu Zhu,Wanxiang Che", "background": "大规模语言模型（LLMs）具有混合专家（MoE）架构，在任务类型广泛的情况下，随着参数的增加，它们能够表现出强大的性能扩展。然而，它们也面临着巨大的计算和存储开销，且性能增益并未与专家参数的增长成比例。前人的工作试图通过专家级别的剪枝、合并或分解来减少参数，但仍然存在性能和计算效率的挑战。", "innovation": "本文引入了微专家作为一种更细粒度的压缩单元，通过多矩阵联合压缩（CAMERA）框架来识别微专家冗余。文中提出了CAMERA-P，一种结构化的微专家剪枝框架，以及CAMERA-Q，一种专为微专家设计的混合精度量化方法。CAMERA-P在20%-60%的不同剪枝比例下，始终优于强大的基线模型。CAMERA-Q在2位量化策略下，表现超过现有矩阵和通道级别的方法。本文的方法可以在单个NVIDIA A100-40GB GPU 上在不到5分钟的时间内完成Qwen2-57B-A14B的微专家完整分析。", "conclusion": "我们的研究表明，通过CAMERA框架可以有效减轻MoE模型的计算和存储负担，同时保持模型的性能。这种方法在多个下游任务中表现出色，特别是对于高度量化的场景。"}
{"llm_update_time": "20251015", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.04012", "html_url": "https://arxiv.org/abs/2508.04012", "title": "EMSEdit：高效的多步元学习驱动的模型编辑", "title_en": "EMSEdit: Efficient Multi-Step Meta-Learning-based Model Editing", "authors": "Xiaopeng Li,Shasha Li,Xi Wang,Shezheng Song,Bin Ji,Shangwen Wang,Jun Ma,Xiaodong Liu,Mina Liu,Jie Yu", "background": "大型语言模型（LLMs）驱动了许多AI应用，但更新知识成本高昂。模型编辑通过目标参数修改提供了一种轻量级的替代方案，而基于元学习的模型编辑（MLME）展示出了强大的效果和效率。然而，我们发现MLME在低数据量环境下表现较差，并且由于使用KL散度，训练成本很高。", "innovation": "本文提出了一种称为EMSEdit（Effective Multi-Step Edit）的方法，利用多步反向传播（MSBP）有效捕捉编辑样本内的梯度-激活映射模式，每样本进行多步编辑以在有限数据下提升编辑性能，同时引入基于范数的正则化以保留未经编辑的知识并提高训练效率。实验结果表明，EMSEdit在序列和批量编辑中均优于现有最先进的方法，并且MSBP可以无缝集成到现有方法中以获得额外的性能提升。进一步的实验中，EMSEdit在多跳推理编辑任务中表现出良好的鲁棒性，而消融研究验证了每个设计组件的贡献。", "conclusion": "EMSEdit在多个数据集和大型语言模型上进行了验证，表现出色，总体上优于先进的模型编辑方法。此外，多步反向传播作为一种技术可以集成到现有方法中以进一步提升性能。"}
{"llm_update_time": "20251015", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.11675", "html_url": "https://arxiv.org/abs/2509.11675", "title": "SpaPool: Soft Partition Assignment Pooling for Graph Neural Networks", "title_en": "SpaPool: Soft Partition Assignment Pooling for__Graph Neural Networks", "authors": "Rodrigue Govan(ISEA),Romane Scherrer(ISEA),Philippe Fournier-Viger,Nazha Selmaoui-Folcher(ISEA)", "background": "传统的图神经网络(GNNs) pooling方法要么过于密集要么过于稀疏，难以同时保持图的结构完整性并有效减小图的大小。SpaPool提出了一个结合了密集和稀疏技术优势的新颖的pooling方法，通过自适应地将顶点分组到不同的簇中，旨在既保持图的结构又减少图的大小。", "innovation": "SpaPool是一种结合了密集和稀疏技术优势的新型池化方法，能够自适应地将顶点分组到不同的簇中，以保持图的结构完整性并有效减小图的大小。实验结果表明，与现有的池化技术相比，SpaPool在多个数据集上展现出竞争力，并特别适合小规模图的处理。", "conclusion": "SpaPool为高效且有效的图处理应用提供了一种有前途的方法，特别是在需要保持图结构完整性的场景中。实验结果证明了其在多个数据集上的有效性，特别是在小规模图上的卓越性能。"}
{"llm_update_time": "20251015", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.12519", "html_url": "https://arxiv.org/abs/2508.12519", "title": "Sliced Optimal Transport简介", "title_en": "An Introduction to Sliced Optimal Transport", "authors": "Khai Nguyen", "background": "Sliced Optimal Transport (SOT) 是最优运输(OT)的一个快速发展分支，它利用了线性最优运输问题的可计算性。通过结合最优运输理论、积分几何和计算统计学的工具，SOT 使得概率测度的距离、巴耶茨中心和核的快速和可扩展计算成为可能，同时保留了丰富的几何结构。这项论文对 SOT 进行了全面的回顾，涵盖了其数学基础、方法学进展、计算方法以及应用。论文讨论了最优运输和一维最优运输的基本概念，积分几何工具（如Radon变换）在投影测度中的作用，以及估计切片距离的统计技术。论文进一步探讨了最近的方法学进展，包括非线性投影、改进的蒙特卡洛近似、一维最优运输的统计估计技术、加权切片技术和运输方案估计方法。还包括了变异问题的探讨，如最小切片Wasserstein估计、巴耶茨中心、梯度流、核构建和嵌入，以及扩展到不均衡、部分、多边缘和Gromov-Wasserstein设置的情况。这些应用涵盖了机器学习、统计学、计算机图形学和计算机视觉领域，突出了 SOT 作为一种实用计算工具的多功能性。这项工作将对研究和实践者感兴趣，特别是在机器学习、数据科学和计算学科，寻求经典的最优运输的高效替代品方面。", "innovation": "SOT 在保持复杂几何结构的同时提供了距离、巴耶茨中心和核的快速计算方法；结合了最优运输、积分几何和计算统计学工具；涵盖了从理论基础到应用的各种最新方法和进展，包括非线性投影、改进的蒙特卡洛近似、加权切片技术和运输方案估计方法；扩展了最优运输的应用范围，包括机器学习、统计学、计算机图形学和计算机视觉领域。", "conclusion": "本文对 Sliced Optimal Transport 进行了全面的介绍，涵盖了其理论基础、方法学进展、计算技术和应用程序，旨在为从事机器学习、数据科学和计算学科的研究者和实践者提供一种高效的最优运输替代方法。"}
{"llm_update_time": "20251015", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.16845", "html_url": "https://arxiv.org/abs/2508.16845", "title": "NinA: Normalizing Flows in Action. 使用正常化流动训练视觉语言行动模型", "title_en": "NinA: Normalizing Flows in Action. Training VLA Models with Normalizing Flows", "authors": "Denis Tarasov,Alexander Nikulin,Ilya Zisman,Albina Klepach,Nikita Lyubaykin,Andrei Polubarov,Alexander Derevyagin,Vladislav Kurenkov", "background": "近期关于视觉-语言-行动（VLA）模型的研究已经建立了一个两部分的架构，其中预训练的视觉-语言模型（VLM）编码视觉观察和任务描述，而行动解码器将这些表示转换为连续动作。由于其能够建模复杂的多模态动作分布的能力，扩散模型被广泛用作行动解码器。然而，这类模型在推断时需要多次迭代降噪步骤，或者需要下游技术以提高采样速度，这限制了其在需要高频控制的真实世界场景中的实用性。", "innovation": "我们提出了NinA（Normalizing Flows in Action），这是一种与扩散型解码器相比而言更快速且表达能力强的替代方案。NinA使用不可逆变换的Normalizing Flow（NF）替换扩散型行动解码器，能够通过单步采样实现重采样，显著减少了推断时间。将NinA融入FLOWER VLA架构并基于LIBERO基准进行微调。实验结果表明，在相同的训练过程中，NinA能达到与扩散型模型相当的性能，而推断速度显著提高。这些结果表明，NinA可能为实现高效的高频VLA控制提供了一条有前景的道路，而不会牺牲性能。", "conclusion": "我们的研究显示，NinA能够在不牺牲性能的情况下，为VLA提供高效的高频控制，为未来的应用提供了新的选择。"}
{"llm_update_time": "20251015", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.17098", "html_url": "https://arxiv.org/abs/2509.17098", "title": "基于不确定性监督的可解释和鲁棒的证据分割", "title_en": "Uncertainty-Supervised Interpretable and Robust Evidential Segmentation", "authors": "Yuzhu Li,An Sui,Fuping Wu,Xiahai Zhuang", "background": "在医学图像分割中，不确定性估计已经被广泛研究作为提供可靠性的工具，特别是在深度学习方法中的应用。然而，先前的方法通常在不确定性估计中缺乏有效的监督，导致预测的低可解释性和鲁棒性。", "innovation": "本文提出了一种自监督的方法来引导不确定性学习。具体地，根据不确定性与边界和噪声周围图像梯度的关系，提出了三条原则。基于这些原则设计了两个不确定性监督损失。这些损失增强了模型预测与人类解释之间的对齐。此外，引入了新的定量指标来评估不确定性的可解释性和鲁棒性。实验结果表明，相较于最先进的方法，该方法在准确的分割性能和分布外（OOD）场景中具有优越的表现，同时显著提高了不确定性的可解释性和鲁棒性。", "conclusion": "与现有的最佳方法相比，所提出的方法在保持竞争性的分割性能的同时，还在不确定性的可解释性和鲁棒性方面取得了优越的结果，同时提升了模型在分布外场景中的表现。"}
{"llm_update_time": "20251015", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.16707", "html_url": "https://arxiv.org/abs/2509.16707", "title": "增加阿尔法：AI驱动交易框架的性能与风险", "title_en": "Increase Alpha: Performance and Risk of an AI-Driven Trading Framework", "authors": "Sid Ghatak,Arman Khaledian,Navid Parvini,Nariman Khaledian", "background": "金融市场存在未利用的价格、成交量和横截面关系模式，导致市场效率低下。尽管许多方法使用大规模变压器，但本文探索了一条领域专门化路径：使用精选特性的前馈和循环网络来捕捉嘈杂金融数据中的微妙规律。这种紧凑的设计在低信噪比环境下表现可靠，适用于大规模日常生产。在增加阿尔法公司，我们构建了一个深度学习框架，将超过800种美国股票映射为每日方向信号，同时保持了计算资源的节省。本文的目的是概述预测模型的总体框架，并通过透明的行业标准指标评估其实时性能，包括基准对比分析、累积回报、年化夏普比率和最大回撤率。", "innovation": "本文采用前馈和循环网络结合精选特征的途径，专注于领域专门化，实现计算资源的节省并能在低信噪比环境下可靠运行。本文构建了一个深度学习框架，将超过800种美国股票映射为每日方向信号，展示了AI驱动模型在面对市场波动时的稳健性与稳定性能。基准对比分析表明，使用该模型的组合提供了低风险、持续的收益流，年化夏普比率超过2.5，最大回撤率约为3%，且与标普500市场基准的相关性接近零。此外，通过不同市场环境进行的对比，进一步彰显了该模型在市场波动中的性能稳定性。", "conclusion": "市场中的不完全效率可以通过合理选择变量并使用适度计算开销的传统深度学习框架得以系统性利用。本文展示了这种框架在金融市场的潜力，并有可能为人工智能驱动的市场优势开发新的方法和技术。"}
{"llm_update_time": "20251015", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.03597", "html_url": "https://arxiv.org/abs/2510.03597", "title": "Neon: 自身训练中的负外推改善图像生成", "title_en": "Neon: Negative Extrapolation From Self-Training Improves Image Generation", "authors": "Sina Alemohammad,Zhangyang Wang,Richard G. Baraniuk", "background": "生成式AI模型的扩展受到高质量训练数据稀缺性的限制。使用合成数据（未验证）来增强有限的真实数据集，以期在微调中提高性能，但这种正反馈循环会导致模型自我消耗失调（MAD，即模型崩溃），导致样本质量和/或多样性快速下降。", "innovation": "Neon（负外推自学习）是一种新的学习方法，将自我训练的退化转化为自我改进的强大信号。Neon 在自训练的基础上，首先对自身的自合成数据进行微调，然后反向更新梯度，远离退化的权重。通过简单的后处理合并实现，无需新的真实数据，仅使用少量的额外训练计算（通常少于1%），Neon 能够在不同架构和数据集上有效提升图像生成质量。", "conclusion": "Neon 在 ImageNet 256x256 数据集上将 xAR-L 模型提升至新的最佳 FID 指标 1.02，仅使用额外0.36%的计算资源。代码可在指定链接下载。"}
{"llm_update_time": "20251015", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.25265", "html_url": "https://arxiv.org/abs/2509.25265", "title": "使用可扩展的噪声注入框架评估放射噪声对胸部X光语义分割和疾病分类的影响", "title_en": "Evaluating the Impact of Radiographic Noise on Chest X-ray Semantic Segmentation and Disease Classification Using a Scalable Noise Injection Framework", "authors": "Derek Jiu,Kiran Nijjer,Nishant Chinta,Ryan Bui,Kevin Zhu", "background": "深度学习模型在放射学分析中越来越广泛的应用，但由于医学成像中的固有随机噪声，其可靠性受到了挑战。不同类型的噪声对这些模型的影响尚缺乏系统性的、跨任务的理解。为此，本研究评估了最先进的卷积神经网络（CNN）在两种关键的胸部X光任务——语义分割和肺部疾病分类中，对模拟的量子（泊松）和电子（高斯）噪声的稳健性。", "innovation": "本研究使用了一种新型的可扩展噪声注入框架，对公共数据集（Landmark，ChestX-ray14）上的常见架构（UNet，DeepLabV3，FPN；ResNet，DenseNet，EfficientNet）应用了受临床驱动的噪声严重性，系统地研究了不同类型的噪声在任务层面对模型的影响。研究结果揭示了任务之间显著的差异性，部分分割任务在严重电子噪声下表现差强人意，而分类任务则表现出一定的鲁棒性，但也存在差异。", "conclusion": "研究发现，虽然分类模型具备一定程度的内在鲁棒性，但像素级分割任务则更为脆弱。任务和噪声特定的模型故障现象指出，在将诊断AI安全地临床应用之前，需要有针对性的验证和缓解策略。"}
{"llm_update_time": "20251015", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.04355", "html_url": "https://arxiv.org/abs/2510.04355", "title": "MDPs中无界空间的量化器设计，模型学习以及量化Q学习", "title_en": "Quantizer Design for Finite Model Approximations, Model Learning, and Quantized Q-Learning for MDPs with Unbounded Spaces", "authors": "Osman Bicer,Ali D. Kara,Serdar Yuksel", "background": "本文研究了无限状态空间的马尔可夫决策过程（MDP）的近似误差上界，讨论了优化量化器的设计对于量化Q学习和经验模型学习的重要性。提出的新上界是建立在Kara等人的研究之上的。", "innovation": "本文提出了对有限模型近似误差的细化上界，并探讨了量化器在量化Q学习和经验模型学习中的作用。特别地，讨论了在Lyapunov增长条件下，随着量化器分箱数量的增加，上界趋向于0的过程。", "conclusion": "本文区分了规划和学习两种不同的设置，前者可以独立设计近似MDP，而后者则受限于探索策略下的马尔可夫链不变测度，这在量化器设计的性能评估上带来了显著的挑战，即便在两种设置下均可以得出渐近近似最优的结果。"}
{"llm_update_time": "20251015", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.17177", "html_url": "https://arxiv.org/abs/2509.17177", "title": "FlagEval Findings Report: 一个自动可验证文本和视觉问题的大规模推理模型初步评估", "title_en": "FlagEval Findings Report: A Preliminary Evaluation of Large Reasoning Models on Automatically Verifiable Textual and Visual Questions", "authors": "Bowen Qin,Chen Yue,Fang Yin,Hui Wang,JG Yao,Jiakang Liu,Jing-Shu Zheng,Miguel Hu Chen,Richeng Xuan,Shibei Meng,Shiqi Zhou,Teng Dai,Tong-Shuai Ren,Wei Cui,Xi Yang,Xialin Du,Xiaojing Xu,Xue Sun,Xuejing Li,Yaming Liu,Yesheng Liu,Ying Liu,Yonghua Lin,Yu Zhao,Yunduo Zhang,Yuwen Luo,Zheqi He,Zhiyuan He,Zhongyuan Wang", "background": "该研究旨在评估当前大型推理模型（LRMs）在自动可验证的文本和视觉问题上的表现。研究团队进行了一项中等规模的、部分无污染（在一定程度上）的评估，以发现关于这些模型的一些初步结果。", "innovation": "研究人员开发了ROME，一个旨在测试视觉线索推理的评估基准，用来评估视觉语言模型。同时，在研究网站上发布了基准数据、评估数据以及其他更新。", "conclusion": "该研究通过中等规模的评估发现了大规模推理模型在自动可验证的文本和视觉问题上的初步表现，并且提出了一个新的评估基准ROME。"}
{"llm_update_time": "20251015", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.04876", "html_url": "https://arxiv.org/abs/2510.04876", "title": "BenthiCat: 用于推进底栖分类和栖息地制图的光学-声学数据集", "title_en": "BenthiCat: An opti-acoustic dataset for advancing benthic classification and habitat mapping", "authors": "Hayat Rajani,Valerio Franchi,Borja Martinez-Clavel Valles,Raimon Ramos,Rafael Garcia,Nuno Gracias", "background": "底栖栖息地映射对于理解海洋生态系统、指导保护努力和支持可持续资源管理至关重要。然而，缺乏大型、注释的数据集限制了机器学习模型在这一领域的开发和基准测试。", "innovation": "该论文引入了一个全面的多模态数据集，其中包括大约一百万个侧扫声纳（SSS）瓷砖，数据收集自西班牙加泰罗尼亚海岸，并伴有地形图和来自自主水下车辆（AUV）的准确实验光学图像。大约36000个SSS瓷砖已经手动注释，用于监督分类模型的微调。提供的开放源代码预处理和注释工具增强了数据集的访问性并鼓励进一步研究。本资源旨在为底栖栖息地制图建立一个标准化基准，促进自主海底分类和多传感器集成的进步。", "conclusion": "该数据集旨在解决自主水下车辆中多传感器数据融合的挑战，通过空间关联光学图像与对应的声音图像，促进跨模式的自监督表示学习。开放源代码的预处理和注释工具也是为了增强数据集的访问性和鼓励进一步的研究。"}
{"llm_update_time": "20251015", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.17238", "html_url": "https://arxiv.org/abs/2509.17238", "title": "MoEs Are Stronger than You Think: Hyper-Parallel Inference Scaling with RoE", "title_en": "MoEs Are Stronger than You Think: Hyper-Parallel Inference Scaling with RoE", "authors": "Soheil Zibakhsh,Mohammad Samragh,Kumari Nishu,Lauren Hannah,Arnav Kundu,Minsik Cho", "background": "大型语言模型（LLMs）的生成质量通常通过在推理时使用序列级缩放方法（例如：Chain-of-Thought）来提高。本文提出了一种互补的框架——超并行缩放，它在标记级别上提高预测质量。RoE 方法通过计算和聚合同一标记的模型的多个输出提案，实现这一目标。RoE 在 Mixture-of-Experts (MoE) 模型上实现，具体为 Roster of Experts (RoE)，并保持训练过程的无参数调整。RoE 通过向专家路由机制注入可控的随机性，使得每个标记可以采样多个多样性的专家并组合它们的输出，以实现更准确的最终预测。为了降低计算成本，RoE 引入了高效批处理策略和专门的 KV 缓存机制，以最小化计算和内存开销。该策略使得 RoE 在推理过程中相比于使用 7B MoE 模型，可以在计算上节省 30% 的资源，并保持与 10.5B MoE 模型相当的性能。", "innovation": "本文介绍了一种超并行缩放技术，该技术在标记得分上提升预测质量，通过计算和聚合每个标记的多个输出提案实现。RoE 能够在无需调整模型参数的情况下，使 7B MoE 模型在推理过程中性能达到 10.5B MoE 模型的水平，并节省 30% 的计算资源。为了实现这一目标，RoE 采用了高效批处理策略和专一的 KV 缓存机制，有效降低计算和内存开销。", "conclusion": "RoE 是一种无需训练的推理算法，可以在不调优模型参数的情况下，显著提升 MoE 模型的推理性能。与之前的方法相比，RoE 提供了一种新的思路，即通过在推理时结合多个专家的预测来提高语言模型的生成质量，同时减少计算资源的需求。"}
{"llm_update_time": "20251015", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.06957", "html_url": "https://arxiv.org/abs/2510.06957", "title": "加速苹果硅芯片上量化机器学习稀疏三元GEMM", "title_en": "Accelerating Sparse Ternary GEMM for Quantized ML on Apple Silicon", "authors": "Baraq Lipshitz,Alessio Melone,Charalampos Maraziaris,Muhammed Bilal", "background": "现有的苹果硅CPU库中稀疏三元矩阵乘法(GEMM)的实现仍不优化。", "innovation": "提出了一种针对苹果M系列处理器优化的稀疏三元GEMM内核，包括针对处理器架构的优化，例如新型分块和交错稀疏数据格式以提高内存局部性，增加指令级并行性（ILP）的策略，以及使用NEON的单指令多数据（SIMD）向量化来利用数据级并行性。", "conclusion": "无须提供专门结论段落，但从内容来看，作者指出他们的标量实现对于50%稀疏性的大型矩阵达到了5.98倍的性能增长，并实现了处理器理论峰值性能的50.2%；矢量化实现对于25%稀疏性的大型矩阵获得最高5.59倍的性能增长，随着稀疏水平变化保持稳定。"}
{"llm_update_time": "20251015", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.05159", "html_url": "https://arxiv.org/abs/2510.05159", "title": "恶意在智能体世界：数据收集中的恶意后门问题", "title_en": "Malice in Agentland: Down the Rabbit Hole of Backdoors in the AI Supply Chain", "authors": "Léo Boisvert,Abhay Puri,Chandra Kiran Reddy Evuru,Nicolas Chapados,Quentin Cappart,Alexandre Lacoste,Krishnamurthy Dj Dvijotham,Alexandre Drouin", "background": "由于在AI代理上进行微调以改进其能力，通常通过使用其自身交互（如网络浏览或工具使用）的数据，这被认为是一种强大的通用策略，但也会引入在AI供应链中的关键安全漏洞。通过污染数据收集管道，恶意攻击者可以嵌入难以检测的后门，触发特定目标短语时，代理执行不安全或恶意行为。本文作者详细探讨了在攻击链中三种不同层面的威胁模型，并展示了通过少量污染即可实现高效恶意行为的具体案例。", "innovation": "本文作者提出了三种针对供应链不同层次的威胁模型，包括直接微调数据污染、环境污染以及供应链污染。特别是展示了微调数据中仅污染极少部分（2%）即可在特定触发条件下使代理泄露用户信息的现象，并验证了现有防护机制难以检测或阻止此类恶意行为，从而对智能体AI的发展提出了急迫的威胁警报，并强调了对数据收集流程和整体模型供应链进行严格安全审查的必要性。", "conclusion": "本研究揭示了在AI供应链中潜藏的严重威胁，强调了需要严格审查数据收集过程与端到端模型供应链的安全问题，同时也指出了现有防护措施的局限性。"}
{"llm_update_time": "20251015", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.04407", "html_url": "https://arxiv.org/abs/2510.04407", "title": "尺度不变的遗憾匹配和最优点在线学习：在零和游戏中理论与实践的结合", "title_en": "Scale-Invariant Regret Matching and Online Learning with Optimal Convergence: Bridging Theory and Practice in Zero-Sum Games", "authors": "Brian Hu Zhang,Ioannis Anagnostides,Tuomas Sandholm", "background": "多年来，通过一阶方法解决零和博弈的理论与实践之间存在着明显的鸿沟。尽管自2000年代初Nemirovski的镜像-近似算法和Nesterov的过度差距技术以来，收敛速率为$T^{-1}$得到了证明，但在实践中最有效的方法是基于遗憾匹配及其现代变体的*假设遗憾最小化*。特别是在大多数基准测试中，最先进的是*预测*遗憾匹配$^+$（PRM$^+$）结合非均匀平均。然而，这些算法在自我博弈中即使无效时，也表现出缓慢的$\text{Ω}(T^{-1/2})$收敛速度。", "innovation": "本文提出了一种新的尺度不变且无需参数的PRM$^+$变体，称为IREG-PRM$^+$。它提供了$T^{-1/2}$的最佳迭代收敛保证以及$T^{-1}$（即最优）平均迭代收敛保证，并且在基准游戏中表现与PRM$^+$相似。技术上，我们将IREG-PRM$^+$类比于乐观梯度下降法，并且具有自适应学习率。新设计的IREG-PRM$^+$避免了遗憾匹配的基本缺陷（遗憾向量的$\\ell_2$-范数可能减少），从而使Regret Vector Upper-bound（RVU）类型不等式成为可能，这首次无需引入额外参数来保证光滑性。此外，我们发现IREG-PRM$^+$与我们引入的一种学习率依赖于错预测误差的自适应乐观梯度下降法表现相当，解释了遗憾匹配家族相对于标准优化技术的效果。", "conclusion": "我们关闭了理论与实践之间的差距，提出了一种新的竞争力不同的PRM$^+$模型IREG-PRM$^+$，该模型保持了遗憾向量范数的非减性质，从而使得IREG-PRM$^+$具有了最优的在线学习性能，并在基准游戏中表现与PRM$^+$相当。"}
{"llm_update_time": "20251015", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.07185", "html_url": "https://arxiv.org/abs/2510.07185", "title": "无监督校准下的分割同态分类", "title_en": "Split Conformal Classification with Unsupervised Calibration", "authors": "Santiago Mazuelas", "background": "现有的分割同态预测方法能够利用校准样本将任何预测规则转化为符合目标覆盖概率的集合预测规则，且能够提供强大的性能保证，成本较低。然而，这些方法要求使用与训练样本不同的标签样本进行校准，这一要求具有高度不便性，因为它阻止了使用所有已标记样本进行训练，还可能需要额外获取标签用于校准。鉴于此，该论文提出了一种有效的方法，其中集合预测规则是通过共同使用监督训练样本和先前用于学习分类规则的无监督校准样本获得的。", "innovation": "该论文提出了一种新的分割同态预测方法，其创新之处在于利用无监督校准样本和监督训练样本来获得集合预测规则，从而不需要专用于校准的标签样本。这种方法能够在一定程度上保持与有监督校准相似的性能，但会有一些计算效率和性能保证的适度下降。", "conclusion": "理论实验证明了该方法能够在保持性能的同时，减少对额外标签样本的需求，提升了训练过程的效率。"}
{"llm_update_time": "20251015", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.10169", "html_url": "https://arxiv.org/abs/2510.10169", "title": "脑痕：一种用于BCI训练和数据收集的严肃游戏", "title_en": "BrainForm: a Serious Game for BCI Training and Data Collection", "authors": "Michele Romani,Devis Zanoni,Elisabetta Farella,Luca Turchet", "background": "脑-计算机接口(BCI)系统的设计通常需要复杂的专业设备和设置，这限制了其广泛应用。脑痕(CerebrusForm)旨在通过使用消费级硬件和简易设置，创建一个可以大规模收集数据的BCI培训系统。研究者研究了BCI控制技能在重复会话中的发展情况以及两种视知觉刺激纹理的效果。", "innovation": "脑痕系统首次提供了一种通过游戏化方式实现BCI训练和数据收集的平台。该系统利用用户在多次会话中不断发展的BCI技能，以及对刺激纹理不同视知觉效果的研究，通过在线指标和会后问卷显示了学习效果，即使在压力条件下也证明了符号拼写等技能的提升。", "conclusion": "研究结果表明，脑痕作为一种可扩展的、用户友好的BCI研究工具，展现了其潜力，并为实现持续参与和减少训练疲劳提供了指导。"}
{"llm_update_time": "20251015", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.08955", "html_url": "https://arxiv.org/abs/2510.08955", "title": "对象导向的去噪扩散图像增强", "title_en": "Denoised Diffusion for Object-Focused Image Augmentation", "authors": "Nisha Pillai,Aditi Virupakshaiah,Harrison W. Smith,Amanda J. Ashworth,Prasanna Gowda,Phillip R. Owens,Adam R. Rivers,Bindu Nanduri,Mahalingam Ramkumar", "background": "现代农业运营越来越多地依赖于结合多个数据源的综合监控系统，用于农场优化。基于无人机的动物健康监测是关键组成部分，但由于特定场地区域的限制因素，如动物太小、遮挡或部分可见，面临数据不足的问题。迁移学习方法由于缺乏能反映特定农场条件的大数据集，包括动物品种、环境和行为的差异，难以解决这一问题。因此，需要开发一种问题特定的、以动物为中心的数据增强策略，适应这些独有的挑战。", "innovation": "本文提出了一种针对动物健康监测的关键任务设计的对象导向的数据增强框架。该方法通过分割背景和对动物进行变换和扩散合成，创建出具有现实感和多样性的场景，从而增强动物检测和监控性能。实验结果表明，增强后的数据集在动物检测任务上的性能优于基线模型。通过生成特定领域的数据，该方法能够为数据稀缺场景下的实时动物健康监测解决方案赋能，弥合数据匮乏与实用应用之间的差距。", "conclusion": "该方法能够帮助在数据稀缺的情况下提升动物健康监测的实时性和准确性，解决了传统迁移学习方法难以应对的特定农场条件下的动物识别挑战。通过生成具有针对性的数据，该策略提升了动物健康监测系统的有效性和可靠性，具有重要的实际应用价值。"}
{"llm_update_time": "20251015", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.14032", "html_url": "https://arxiv.org/abs/2509.14032", "title": "在具有逐个玩家凹耦合约束的游戏中的纳什均衡：存在性和计算", "title_en": "Nash Equilibria in Games with Playerwise Concave Coupling Constraints: Existence and Computation", "authors": "Philip Jordan,Maryam Kamgarpour", "background": "本文研究了参与者的可选策略受到共享耦合约束（依赖于他们联合策略的约束）约束的连续静态游戏中的纳什均衡的存在性和计算问题。特别地，本文侧重于具有逐个玩家凹效用和逐个玩家凹约束的博弈类。先前关于纳什均衡存在性的结果不适用于此类博弈，因为它们依赖于可行集联合凹性的强硬假设。本文通过利用拓扑不动点理论和逐个玩家凹约束下可行集合同性的新颖结构洞察，给出了在较弱条件下纳什均衡存在的证明。", "innovation": "本文通过利用拓扑不变点理论和逐个玩家凹约束下可行集合同性的新颖结构洞察，给出了弱假设下的纳什均衡存在的证明；并在逐个玩家凹效用可以表示潜在函数的额外假设下，提出了通过独立梯度方法计算纳什均衡的方法，考虑到可行区域可能是非凸的，引入了带自适应步长的对数屏障正则化梯度上升方法，并在精确梯度反馈下证明了该方法在O(ε⁻³)迭代次数内收敛到ε-近似受约束的纳什均衡。", "conclusion": "本文从初始可实现策略配置开始，在精确梯度反馈下，使用带自适应步长的对数屏障正则化梯度上升方法在O(ε⁻³)次迭代内收敛到ε-近似受约束的纳什均衡。"}
{"llm_update_time": "20251015", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.11713", "html_url": "https://arxiv.org/abs/2510.11713", "title": "大规模推理模型在可以中断的情况下可靠吗？", "title_en": "Are Large Reasoning Models Interruptible?", "authors": "Tsung-Han Wu,Mihran Miroyan,David M. Chan,Trevor Darrell,Narges Norouzi,Joseph E. Gonzalez", "background": "传统的大型推理模型（LRMs）在静态、‘固定世界’的环境中表现出色，即模型的响应被认为是即时的，对话的背景在模型产生响应期间被认为不会改变。然而，在现代的长周期任务如辅助编程中，模型可能需要数小时来解决问题，而且代码可能会经历显著的变化，这与‘固定世界’假设不符。", "innovation": "本文挑战了‘固定世界’假设，通过两种现实的动态场景评估LRMs的鲁棒性：中断测试对部分输出的高质量，动态背景测试模型对飞行中变化的适应能力。即使在静态评估中成绩很高的最新LRMs，在受到中断或接触变更背景时也可能会表现出不可预测的性能下降，性能下降最多可达60%。此外，研究发现几种新型的失败模式，包括推理泄露、恐慌和自我怀疑。", "conclusion": "在需要长篇推理的数学和编程基准测试中，静态评估一直高估了模型的稳健性。即使最先进的LRMs，在面对中断或变更背景时，一旦在推理过程中引入更新信息，性能可能会急剧下降。这些发现揭示了新型的失败模式，需要对模型的鲁棒性进行进一步评估和改进，以应对动态变化的场景。"}
{"llm_update_time": "20251015", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.10774", "html_url": "https://arxiv.org/abs/2510.10774", "title": "ParsVoice: 一个大规模多说话人波斯语语音语料库用于文本转语音合成", "title_en": "ParsVoice: A Large-Scale Multi-Speaker Persian Speech Corpus for Text-to-Speech Synthesis", "authors": "Mohammad Javad Ranjbar Kalahroodi,Heshaam Faili,Azadeh Shakery", "background": "现有的波斯语语音数据集通常规模小于英语的数据集，这限制了波斯语语音技术的发展。为了解决这个问题，我们通过引入ParsVoice——专门为文本转语音(TTS)应用设计的最大规模的波斯语语音语料库，填补了这一空白。这个语料库基于2,000个有声读物，生成了3,526小时的高质量音频，并进一步筛选出1,804小时高质音频，适用于TTS系统，涵盖470多名说话人。", "innovation": "我们开发了一套自动化管道，将原始有声读物内容转化为TTS可用的数据，包括基于BERT的句子完成检测器、二分搜索边界优化方法以实现精确的音频文本对齐，以及定制的音频文本质量评估框架，专门针对波斯语。", "conclusion": "ParsVoice 是迄今为止最大的高质量波斯语语音数据集，提供了说话人多样性和音频质量，与主要的英语语料库相当。我们已经将完整的数据集公开，以加速波斯语语音技术的发展。ParsVoice 数据集可从此链接下载: [this https URL](this https URL)。"}
{"llm_update_time": "20251015", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.08558", "html_url": "https://arxiv.org/abs/2510.08558", "title": "Agent Learning via Early Experience", "title_en": "Agent Learning via Early Experience", "authors": "Kai Zhang,Xiangchao Chen,Bo Liu,Tianci Xue,Zeyi Liao,Zhihan Liu,Xiyao Wang,Yuting Ning,Zhaorun Chen,Xiaohan Fu,Jian Xie,Yuxuan Sun,Boyu Gou,Qi Qi,Zihang Meng,Jianwei Yang,Ning Zhang,Xian Li,Ashish Shah,Dat Huynh,Hengduo Li,Zi Yang,Sara Cao,Lawrence Jang,Shuyan Zhou,Jiacheng Zhu,Huan Sun,Jason Weston,Yu Su,Yifan Wu", "background": "语言代理的一个长期目标是通过自身的经验学习和提高，最终在复杂的现实世界任务中超越人类。然而，使用强化学习从经验数据训练代理在许多环境中仍然困难，因为这些环境或缺乏可验证的奖励（例如网站），或需要低效的长期滚动（例如多轮工具使用）。因此，当前大多数代理都依赖于在专家数据上的监督微调，这难以扩展且泛化能力弱。这一局限性源自专家示范的本质：它们仅捕捉狭窄范围的场景，并限制代理暴露于有限的环境多样性。本文提出了一种折中的方法——早期经验：由代理自身行动生成的交互数据，未来状态作为监督，无需奖励信号。", "innovation": "本文提出了一种名为「早期经验」的中间方法，这种手法通过代理自身行动生成的交互数据进行训练，其中未来状态作为监督，无须奖励信号。研究了两种策略利用此类数据：（1）隐式世界建模，利用收集的多态来建立策略与环境动力的联系；（2）自我反思，代理从自身的次优行动中学习，以改善推理和决策。在八个多样环境中和多个模型家族中进行了评估，方法能一致改善效果和跨域泛化能力，强调早期经验的价值。此外，在具有可验证奖励的环境中，结果表明早期经验为后续的强化学习提供了坚实的基础，将其定位为模仿学习与完全经验驱动代理之间的实用桥梁。", "conclusion": "方法在不同环境下的表现一致改进了有效性和跨域泛化能力，强调了早期经验的价值。在具有可验证奖励的环境中，我们的结果展示了早期经验可以作为模仿学习和完全经验驱动代理之间的有效桥梁，为其在实际应用中的转型提供了希望。"}
{"llm_update_time": "20251015", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2510.11813", "html_url": "https://arxiv.org/abs/2510.11813", "title": "面向任务的缩减以实现可扩展的LLM数据库系统", "title_en": "Task-Aware Reduction for Scalable LLM-Database Systems", "authors": "Marcus Emmanuel Barnes,Taher A. Ghaleb,Safwat Hassan", "background": "大型语言模型(LLMs)在数据分析流程中的应用日益广泛，涵盖了数据库查询到开发者观测等多个方面。但这些系统的效果受限于现实世界中富文本数据（如日志、遥测和监控流）的体量、冗长和噪音。直接将此类数据输入LLM会带来高昂成本、环境保护问题，并且通常与任务目标不符。尽管针对LLM效率的优化发生在模型或架构层面，但减少上游输入冗长问题的研究还未得到充分探索。", "innovation": "本文提出将LLM的令牌预算视为注意力预算，并将任务感知的文本缩减作为语言——数据系统中的首要设计原则。作者将输入侧缩减视为注意力分配：优先考虑下游任务最相关的信息。该研究还指出了构建基准、设计自适应缩减管道以及将令牌预算的处理纳入数据库和检索系统的开放性研究挑战。", "conclusion": "本文旨在将稀缺的注意力资源引导至嘈杂的数据密集型流程中的有意义信号，以实现具有扩展性、准确性和可持续性的LLM-数据整合。"}
{"llm_update_time": "20251015", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2510.11722", "html_url": "https://arxiv.org/abs/2510.11722", "title": "eye2vec: 学习眼动的分布式表示以进行程序理解分析", "title_en": "eye2vec: Learning Distributed Representations of Eye Movement for Program Comprehension Analysis", "authors": "Haruhiko Yoshioka,Kazumasa Shimari,Hidetake Uwano,Kenichi Matsumoto", "background": "在程序理解的常见眼动追踪研究中，研究者必须预先选择分析目标，如控制流或语法元素，然后开发分析方法从固定点提取适当的度量标准。研究者可以定义不同级别的分析区域（AOIs），如单词、行或代码块，这些差异导致不同的结果。此外，固定点对单词/行的解释因分析目的的不同而有所不同，因此眼动追踪分析是依赖于研究者耗时的手动工作的困难任务。 eye2vec将连贯的两个固定点表示为语法元素之间的转换，这使得可以采用丰富的语义解释的各种数据分析方法。", "innovation": "eye2vec通过使用分布式表示来将连续的两个固定点表示为语法元素之间的转换。这种表示方法简化了眼动追踪分析，使得可以采用各种具有丰富语义解释的数据分析方法。这种方法减少了传统研究中的手动工作量，提高了分析的灵活性和准确性。", "conclusion": "eye2vec提供了一种新的方法，通过分布式表示来处理眼动追踪数据，这对于程序理解和分析非常有用。这种方法不仅简化了人工工作量，还引入了更大的分析灵活性和更深层次的语义理解。"}
{"llm_update_time": "20251015", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2510.11872", "html_url": "https://arxiv.org/abs/2510.11872", "title": "DMAS-Forge：分布式系统中透明部署AI应用的框架", "title_en": "DMAS-Forge: A Framework for Transparent Deployment of AI Applications as Distributed Systems", "authors": "Alessandro Cornacchia,Vaastav Anand,Muhammad Bilal,Zafar Qazi,Marco Canini", "background": "随着代理AI应用的发展，它们越来越多地依赖具有独特角色、专门工具和访问内存层的多个代理来解决复杂任务，类似于服务导向的架构。然而，在编程框架和新协议快速发展的背景下，将AI代理作为分布式系统进行部署和测试仍然是一个令人望而却步且劳动密集的任务。", "innovation": "DMAS-Forge框架旨在解决这一问题，它将应用程序逻辑与具体部署选择分离，并旨在透明地生成所需的粘合代码和配置，以在多种部署场景中启动分布式多代理应用，同时减少手动努力。", "conclusion": "本文介绍了DMAS-Forge的愿景、设计原则及原型，并讨论了方法的机会和未来工作。"}
{"llm_update_time": "20251015", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2510.12011", "html_url": "https://arxiv.org/abs/2510.12011", "title": "TorchCor：使用GPU上的有限元方法进行高性能心肌电生理模拟", "title_en": "TorchCor: High-Performance Cardiac Electrophysiology Simulations with the Finite Element Method on GPUs", "authors": "Bei Zhou,Maximilian Balmus,Cesare Corrado,Ludovica Cicci,Shuang Qian,Steven A. Niederer", "background": "心肌电生理学（CEP）模拟在理解心律失常和指导临床决策方面越来越重要。然而，这些模拟通常需要具有大量CPU核心的高性能计算资源，这些资源对许多研究小组和临床医生来说往往是不可用的。", "innovation": "我们提出了TorchCor，这是一个基于PyTorch的高性能Python库，用于使用通用GPU上的有限元方法进行CEP模拟。TorchCor显著加速了CEP模拟，特别适用于大型3D网格。通过与制造的解析解和N版本基准问题进行对比，验证了解算器的准确性。", "conclusion": "TorchCor免费提供给学术界和商业使用，没有任何限制。"}
{"llm_update_time": "20251015", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2510.11838", "html_url": "https://arxiv.org/abs/2510.11838", "title": "Lingxi: 基于过程知识引导扩展的仓库级问题解决框架", "title_en": "Lingxi: Repository-Level Issue Resolution Framework Enhanced by Procedural Knowledge Guided Scaling", "authors": "Xu Yang,Jiayuan Zhou,Michael Pacheco,Wenhan Zhu,Pengfei He,Shaowei Wang,Kui Liu,Ruiqi Pan", "background": "随着大型语言模型（LLMs）的进步，LLM支持的代理在软件工程任务中取得了显著进步，但仍然难以解决复杂的仓库级问题。现有基于代理的方法存在两个关键局限性：缺乏处理问题的程序知识（即修复问题的步骤和背后的理由），以及过度依赖强大的计算能力进行盲目的探索。", "innovation": "本文提出了一种名为Lingxi的问题解决框架，该框架利用从历史修复数据中提取的过程知识来指导解决仓库级问题。Lingxi在离线构建过程知识并通过层次抽象机制使代理学习修复背后的原理和理由。在线应用时，Lingxi采用一种知识驱动的扩展方法，通过分析类似问题的过程知识来从多个角度智能地分析目标问题，而不是进行盲目且无方向性的探索。", "conclusion": "Lingxi在SWE-bench Verified基准测试的Past@1设置中，成功解决了74.6%的bug，显著优于五种现有先进技术，性能提升了5.4%到14.9%。消融研究表明，Lingxi的成功直接归因于使用过程知识。没有过程知识，仅通过扩展的方式提高性能几乎没有作用。进一步的定性研究显示，设计模式与编码实践是最关键的知识方面，不同知识方面在不同阶段中扮演的角色不同（即分析、计划和修复阶段）。"}
{"llm_update_time": "20251015", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2510.12120", "html_url": "https://arxiv.org/abs/2510.12120", "title": "采用协议驱动方法进行多代理LLM工程：一种探索", "title_en": "Towards Engineering Multi-Agent LLMs: A Protocol-Driven Approach", "authors": "Zhenyu Mao,Jacky Keung,Fengji Zhang,Shuo Liu,Yifei Wang,Jialong Li", "background": "软件开发需求的增加激发了通过大型语言模型（LLMs）自动化软件工程（SE）任务的兴趣。尽管近期研究将LLMs扩展到多代理系统（MAS）来模拟协作开发流程，但这些系统经常因为缺乏核心SE结构原则而失败，具体表现为定义不足、协调不一致和验证不当。", "innovation": "本文提出了软件工程多代理协议（SEMAP），这是一种协议层次的方法，它为多代理LLMs实例化了三个核心SE设计原则：明确的行为合约建模、结构化消息传递和生命周期引导执行与验证。该方法基于Google的Agent-to-Agent（A2A）基础设施实施。实证研究表明，SEMAP在不同SE任务中有效减少了故障数量。在代码开发中，SEMAP实现了高达69.6%的功能级开发失败减少和56.7%的部署级开发失败减少。在漏洞检测方面，SEMAP分别减少了Python任务47.4%和C/C++任务28.2%的失败次数。", "conclusion": "SEMAP作为一种协议驱动方法，显著提高了多代理LLMs的可靠性，在多个SE任务中有效减少了失败频率，展现了在整个软件开发过程中使用多代理系统的潜力。"}
{"llm_update_time": "20251015", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2510.12364", "html_url": "https://arxiv.org/abs/2510.12364", "title": "(R)evolution of Programming: Vibe Coding as a Post-Coding Paradigm", "title_en": "(R)evolution of Programming: Vibe Coding as a Post-Coding Paradigm", "authors": "Kevin Krings,Nino S. Bohn,Thomas Ludwig", "background": "近年来，生成型人工智能（GenAI），尤其是大型语言模型，为软件开发实践带来了新的可能性。本文探讨了一种新兴的Vibe Coding (VC)范式，该范式强调开发者与AI系统之间直观、情感驱动和即兴的互动。作者依托于用户导向开发（EUD）的讨论，通过与十个经验丰富的软件开发人员的半结构化访谈，识别出五个主题维度：创造力、可持续性、编程的未来、协作和批评。", "innovation": "本文创新性地提出并分析了Vibe Coding (VC)这一范式，将其与现有的编程方法如GitHub Copilot进行对比，通过一个比喻性的共漂流视角，重新定义了开发者角色。VC允许新型的表达形式和快速原型设计，但也带来了可重复性、可扩展性和包容性方面的挑战。", "conclusion": "VC被视作编程文化的一次重要转变，值得在人机交互（HCI）和软件工程研究中进一步进行深入探索。"}
{"llm_update_time": "20251015", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2510.12294", "html_url": "https://arxiv.org/abs/2510.12294", "title": "Show Your Title! A Scoping Review on Verbalization in Software Engineering with LLM-Assisted Screening", "title_en": "Show Your Title! A Scoping Review on Verbalization in Software Engineering with LLM-Assisted Screening", "authors": "Gergő Balogh,Dávid Kószó,Homayoun Safarpour Motealegh Mahalegi,László Tóth,Bence Szakács,Áron Búcsú", "background": "软件工程（SE）中如何理解软件开发者的思考、决策和行为仍是一个关键挑战。口头化技术（捕捉口头或书面思维过程的方法）提供了一种轻量级且易于访问的方式来研究这些认知方面。本文通过对软件工程与心理学交叉领域的研究进行范围性回顾，着重讨论口头数据的使用。为了使跨学科的大规模综述可行，作者采用了一种基于大型语言模型（LLM）的筛选流程，使用GPT自动评估超过9,000篇论文的相关性。", "innovation": "作者利用了大型语言模型（LLM）辅助的筛查管道，特别是使用GPT来基于标题自动评估超过9,000篇论文的相关性，这为大范围的跨学科评审提供了可能性。这种方法验证了GPT输出的人类评审一致率高，自动筛查在支持跨学科评审过程中的有效性。", "conclusion": "数据表明，SE领域口头化相关工作中的主要主题倾向于SE的专业技能，而更多的人文主题则相对不足。SE频繁使用心理学方法，但心理学反过来使用SE方法的情况很少。通过GPT自动筛查方法验证了其有效性和准确性。"}
{"llm_update_time": "20251015", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2510.12397", "html_url": "https://arxiv.org/abs/2510.12397", "title": "在黑色星期五运行我的云基准测试吗？", "title_en": "Should I Run My Cloud Benchmark on Black Friday?", "authors": "Sören Henning,Adriano Vogel,Esteban Perez-Wohlfeil,Otmar Ertl,Rick Rabiser", "background": "在云环境中，基准测试和性能实验是常见的。但由于性能高度可变性，导致这些结果常常受到怀疑，人们的关注点在于它们的再现性和可信度。先前的研究通过反复执行流处理应用程序基准，观察到应用级别的性能可变性，尽管这一可变性没有人们想象的那么显著。这项研究基于更广泛的规模发现了更微妙的日间和周间性能模式。在此基础上，进一步研究考察了一种主要的全球事件（如黑色星期五）是否会影响性能基准测试的结果。", "innovation": "通过长期的实证研究，该论文不仅量化了云环境中性能变化的影响，而且通过识别日间和周间的微妙性能模式，为基准测试的实施提供了更为精确的指导。论文将黑色星期五这样的特殊事件纳入考量，进一步探索其对云环境性能基准测试结果的影响。", "conclusion": "论文的研究表明，尽管存在性能的变化性，但在大多数情况下，这种变化通常不如人们的预期那么显著。而某些特定的日子或事件（如黑色星期五）可能会对性能基准测试的结果产生显著影响。因此，选择性能基准测试的执行时间至关重要。"}
{"llm_update_time": "20251015", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2510.12478", "html_url": "https://arxiv.org/abs/2510.12478", "title": "DarTwin made precise by SysMLv2 -- An Experiment", "title_en": "DarTwin made precise by SysMLv2 -- An Experiment", "authors": "Øystein Haugen,Stefan Klikovits,Martin Arthur Andersen,Jonathan Beaulieu,Francis Bordeleau,Joachim Denil,Joost Mertens", "background": "SysMLv2引入了一些机制，用于内置特定领域的概念和语言扩展，这有望简化特定领域语言（DSL）的创建以及与现有系统描述和技术设计的接口。本文则通过分析这些功能并使用具体案例评估SysMLv2的能力来进行这一研究，同时开发了一个名为DarTwin DSL的DSL，旨在通过SysMLv2技术标准化DarTwin的进化表示法，并探讨了现有SysMLv2工具在图形表示方面的局限性。这项工作将模型驱动工程（MDE）应用于数字孪生，并与SysMLv2的发布相结合，为系统工程中的数字孪生演变管理提供一种系统的方法。", "innovation": "首先，SysMLv2提供的功能性支持使得可以通过内置机制创建特定领域的语言和语言扩展；其次，作者通过开发DarTwin DSL来具体实现数字孪生的进化，并将这一方法与现有SysMLv2工具的技术能力相结合。这种结合为未来的特定领域工程提供了一种新的模式。", "conclusion": "通过本文的研究，作者不仅展示了如何使用新的SysMLv2功能来实现特定领域的DSL，而且还指出当前SysMLv2工具在图形表示方面存在局限。未来的研究将集中在更全面地利用SysMLv2来进一步完善数字孪生的相关技术和方法，为模型驱动的工程带来更多的创新和应用前景。"}
{"llm_update_time": "20251015", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2510.12487", "html_url": "https://arxiv.org/abs/2510.12487", "title": "Diff-XYZ：评估代码差异理解的基准", "title_en": "Diff-XYZ: A Benchmark for Evaluating Diff Understanding", "authors": "Evgeniy Glukhov,Michele Conti,Egor Bogomolov,Yaroslav Golubev,Alexander Bezzubov", "background": "大规模的代码编辑和重构代理依赖于可靠的代码差异处理能力。现有的基准主要集中在特定的代码差异任务上，缺乏涵盖多种场景的综合评估方法。因此，有必要建立一个全面的基准来评估不同代码差异处理模型的性能，尤其是针对代码差异的生成、应用和反向应用等任务。", "innovation": "Diff-XYZ引入了一种包含三个监督任务的紧凑基准：应用（旧代码 + 差异 → 新代码）、反应用（新代码 - 差异 → 旧代码）和差异生成（新代码 - 旧代码 → 差异）。该基准的数据集从真实的CommitPackFT提交中抽取，同时提供了自动计算的指标和清晰的评估协议。通过Diff-XYZ基准，研究者能够针对不同的应用场景和模型规模来评估统一的差异格式的表现，从而识别出最适合不同类型任务和不同模型大小的最佳格式。", "conclusion": "Diff-XYZ基准为评估和改进大型语言模型中代码差异处理提供了可重用的基础，可以帮助未来进一步改进代码差异格式和模型编辑代码的能力。该数据集已发布在HuggingFace Hub上，可供研究人员使用。"}
{"llm_update_time": "20251015", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2510.12566", "html_url": "https://arxiv.org/abs/2510.12566", "title": "浏览器基础Web服务可持续性报告中的终端设备能源模型评估", "title_en": "Evaluating End-User Device Energy Models in Sustainability Reporting of Browser-Based Web Services", "authors": "Maja H. Kirkeby,Timmie Lagermann", "background": "当前，基于网络的服务越来越多地依赖简化能源和碳排放模型来进行可持续性报告，如丹麦数字政府机构的Digst框架和英国的DIMPACT模型。尽管这些模型被广泛应用，其准确性和精确性尚未充分研究。研究通过在购物、预订、导航和新闻服务中的典型场景下，使用预定义的用户流程在四种不同的笔记本平台上测量能源消耗，发现常被使用的恒定功率近似（P * t）由于网站类别、设备类型和任务特征的不同，与实际测量的能源消耗存在显著差异。", "innovation": "本研究通过实证分析，评估简化能源和碳排放模型在实际用户交互场景中的表现，指出恒定功率近似在不同场景下与实际能源消耗存在显著差异，这些差异并非随机，而是系统性的。研究还强调了在可持续性报告框架中需要具备类别感知和设备映射的动力参数，以提高模型的精确性。", "conclusion": "研究发现，简化能源模型在不同网站类别、设备类型和任务特性下表现出显著的偏差，这些偏差并非随机，而是系统性的。研究突显了在可持续性报告框架中需要开发更加精确的动力参数，以及分类别和设备特性的参数以进行可靠的可持续性报告。"}
{"llm_update_time": "20251015", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2510.12082", "html_url": "https://arxiv.org/abs/2510.12082", "title": "使用额外上下文增强神经代码表示", "title_en": "Enhancing Neural Code Representation with Additional Context", "authors": "Huy Nguyen,Christoph Treude,Patanamon Thongtanunam", "background": "自动程序理解是许多软件工程任务的基础，包括代码摘要和克隆检测等。近期的研究利用深度学习模型取得了很好的效果，但这些模型通常仅依赖于源代码，忽略了版本历史记录、结构关系等上下文信息。这限制了它们捕捉代码演变和操作的能力。该研究通过实证分析，探讨了各种上下文信号如何丰富代码表示以及这种丰富对神经模型在关键理解任务上的性能影响。通过将所选模型在代码克隆检测和代码摘要两个任务上的性能进行了评估来验证这一点，所使用的数据集分别为SeSaMe和CodeSearchNet，涉及五种代表性的模型。研究表明，与其他代码上下文相比，版本历史记录对克隆检测的影响较大，而调用图对不同模型和任务的影响有所不同。论文强调了优化神经SE模型中上下文编码的可能性。", "innovation": "增加了版本历史记录、结构关系等上下文信息作为代码表示的补充，提升神经模型在关键理解任务上的性能，并且通过对比单一上下文类型和多种上下文组合的效果，展示了增强的潜在价值。", "conclusion": "上下文信息的增强有助于提高代码理解的能力，这对优化神经SE模型中的上下文编码具有重要意义。同时，研究结果表明互补的上下文可以带来更多性能上的提升，为优化神经SE模型中上下文编码提供了新的方向。"}
{"llm_update_time": "20251015", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2510.12546", "html_url": "https://arxiv.org/abs/2510.12546", "title": "EmpathiSEr：面向软件工程的同理心量表的发展与验证", "title_en": "The EmpathiSEr: Development and Validation of Software Engineering Oriented Empathy Scales", "authors": "Hashini Gunatilake,John Grundy,Rashina Hoda,Ingo Mueller", "background": "软件工程中的同理心在协作、沟通和以用户为中心的设计中起到关键作用。尽管软件工程研究已逐渐认识到同理心是关键的人类特质之一，但尚未有专门设计用于测量在软件工程特别社会技术环境中同理心的有效工具。现有的通用同理心量表虽然在心理和医疗领域被广泛认可，但由于语言、情境和假设问题，往往不适合软件从业者。这些量表未能考虑到软件工程中的多样化、角色特定和领域特定的同理心表达，比如理解非技术用户或另一名从业者的技术限制。而这些表达与临床或日常生活中的同理心存在显著差异。为弥补这一差距，作者开发并验证了两个面向特定领域（从业者对用户和从业者内部）的同理心量表：EmpathiSEr-P 和 EmpathiSEr-U，并构建了一个实践员导向的概念框架来包含认知同理心、情感同理心和同理回应三个维度。采用严谨的多阶段方法，包括专家评估、认知访谈和两次实践者调查，以确保量表的有效性和实用性。", "innovation": "基于实践导向的概念框架，开发了第一个心理测量上验证过的软件工程特定领域内专门的同理心量表，包括EmpathiSEr-P（评估从业者间的同理心）和EmpathiSEr-U（捕捉从业者对用户的同理心），并被认为是软件团队和用户交互中进行同理心增强干预研究的重要工具。", "conclusion": "结果表明，EmpathiSEr-P 和 EmpathiSEr-U 是第一个心理测量上验证过的专为软件工程设计的同理心量表，为研究人员和实践者提供了评估和设计促进同理心的干预措施的工具，有助于提升软件团队和用户交互的质量。"}
{"llm_update_time": "20251015", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2510.12616", "html_url": "https://arxiv.org/abs/2510.12616", "title": "动态系统集合中的运行时组成：挑战、解决方案、工具和评估方法的系统回顾", "title_en": "Runtime Composition in Dynamic System of Systems: A Systematic Review of Challenges, Solutions, Tools, and Evaluation Methods", "authors": "Muhammad Ashfaq,Ahmed R. Sadik,Teerath Das,Muhammad Waseem,Niko Makitalo,Tommi Mikkonen", "background": "现代系统集合（SoSs）在动态环境中运行（例如智能城市和自动驾驶车辆），这些环境中对运行时组成——即实时发现、集成和协调组成系统（CSs）——具有很高的需求，以提高适应能力。尽管人们对这一领域的兴趣日益浓厚，但关于动态SoSs中的运行时组成的文献缺乏系统综合。", "innovation": "本研究通过系统文献综述（SLR）探讨了动态SoSs中的运行时组成，并识别出了四个挑战类别（建模与分析、弹性操作、系统编排、CSs异构性）、七种解决方案领域（协同仿真和数字孪生、语义本体、集成框架、适应性架构、中间件、形式方法、基于AI的弹性）、支持工具和服务导向的整合框架，并提出了包括模拟、实施驱动和以人为中心研究在内的评价方法。", "conclusion": "综合研究表明存在多种张力，包括自主性与协调、建模与现实之间的差距以及社会技术整合。研究呼吁标准化评估标准、可扩展的分散架构以及跨领域的框架。研究旨在指导研究人员和从业者开发和实施动态可组装的SoSs。"}
{"llm_update_time": "20251015", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2510.12047", "html_url": "https://arxiv.org/abs/2510.12047", "title": "大型语言模型尊重合约吗？评估和强制执行代码生成中的合约遵守", "title_en": "Do Large Language Models Respect Contracts? Evaluating and Enforcing Contract-Adherence in Code Generation", "authors": "Soohan Lim,Joonghyuk Hahn,Hyunwoo Park,Sang-Ki Ko,Yo-Sub Han", "background": "当前的代码生成基准测试，如HumanEval+和MBPP+，主要通过正确性（pass@k）测试大型语言模型（LLMs），但它们忽视了现实软件中至关重要的一个方面：合约遵守——规定如何拒绝不正确输入的先决条件和有效性约束。这导致现有基准未能衡量模型生成真正可靠代码的能力，从而未能全面确保代码的实际应用。为填补这一空白，作者引入了PACT框架，旨在系统地评估和增强LLM生成代码片段中的合约遵守情况，同时保持功能正确性。", "innovation": "PACT框架有三个主要贡献：一是提供了一个专注于合约违规的综合测试集，扩展了HumanEval+和MBPP+；二是能够在变化的提示条件下系统分析代码生成情况，证明与合约描述相比，结合合约违规测试案例显著提升了模型遵守合约的能力；三是引入了新的度量标准，以严格量化测试和代码生成中的合约遵守情况。", "conclusion": "PACT通过揭示常规基准测试中忽略的关键错误，提供了评估LLM生成代码片段功能性和实用性严格且可解释的度量标准。相关代码和数据可以在指定的链接中获取。"}
{"llm_update_time": "20251015", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2510.12582", "html_url": "https://arxiv.org/abs/2510.12582", "title": "GUPPY：Python式的量子经典编程", "title_en": "GUPPY: Pythonic Quantum-Classical Programming", "authors": "Mark Koch,Alan Lawrence,Kartik Singhal,Seyon Sivarajah,Ross Duncan", "background": "随着量子计算技术的发展，开发适用于实际量子硬件的编程语言成为了研究的重点之一。现有的一些量子编程语言多为专门设计，缺乏与传统编程语言的兼容性，使得用户难以利用已有的编程技能进行量子编程。", "innovation": "Guppy 是一种嵌入在 Python 中的领域特定语言，允许用户使用 Python 风格的语法编写高层次的量子和经典混合程序，具有复杂控制流。这种设计不仅保持了量子软件与传统 Python 环境的良好兼容性，还大大降低了用户使用量子计算技术的门槛。", "conclusion": "Guppy 提供了一种新的量子编程方法，通过 Python 风格的语法实现了高层次的量子程序编写，方便用户在实际的量子硬件上运行这些程序。"}
{"llm_update_time": "20251015", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2510.12702", "html_url": "https://arxiv.org/abs/2510.12702", "title": "超越后置条件：大型语言模型能否为自动软件验证推断正式合同？", "title_en": "Beyond Postconditions: Can Large Language Models infer Formal Contracts for Automatic Software Verification?", "authors": "Cedric Richter,Heike Wehrheim", "background": "自动软件验证器在检查软件与正式规范的一致性方面越来越有效。然而，它们在实践中的应用受限于现实世界代码缺乏正式规范。尽管大型语言模型在从代码中的自然语言提示（如函数名、注释或文档）推断正式后置条件方面表现出潜力，但这些后置条件在验证过程中可能导致无效输入，这些指出了潜在问题但实际上是误报。因此，研究者重新审视了从自然语言推断规范的问题，并提出了NL2Contract任务，即使用 large language models 将非正式的自然语言转化为包含后置条件和前置条件的形式化功能合同。", "innovation": "研究引入了NL2Contract任务，即使用大型语言模型将非正式的自然语言转化为形式化的功能合同，包括后置条件和前置条件。研究还提出了一套评估指标，用于验证和比较不同NL2Contract的方法，这些指标包括形式化的合同的正确性、生成的合同区分错误行为和正常行为的能力以及在自动软件验证中的实用性。研究表明，大型语言模型在生成适用于所有输入的功能合同方面效果显著，生成的合同能够有效地区分错误行为和正常行为，且验证器能够通过提供大型语言模型推断的功能合同减少误报。", "conclusion": "大型语言模型在生成功能合同方面表现出色，这些合同足够表达以区分错误行为和正常行为，在提供这些合同的情况下，自动软件验证器生成的误报较少。进一步的研究发现，由大型语言模型生成的前置条件通常很好地反映了开发人员的意图，使我们能够使用自动软件验证器来捕捉真实世界的错误。"}
{"llm_update_time": "20251015", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2208.08067", "html_url": "https://arxiv.org/abs/2208.08067", "title": "K-ASTRO: 结构感知的大语言模型适应方法用于代码漏洞检测", "title_en": "K-ASTRO: Structure-Aware Adaptation of LLMs for Code Vulnerability Detection", "authors": "Yifan Zhang,Michael Sandborn,Stefan Larson,Yu Huang,Kevin Leach", "background": "大型语言模型（LLMs）正在改变软件工程任务，包括代码漏洞检测——这是软件安全的一个关键领域。然而，现有的方法往往依赖于资源密集型模型或图基技术，这限制了它们的可访问性和实用性。", "innovation": "K-ASTRO 是一种轻量级的Transformer模型，结合了LLMs的语义嵌入和AST的结构特征，以提高代码漏洞检测的效率和准确性。我们提出了一种基于AST的增强技术，受到变异测试的启发；结构感知的注意力机制，结合了增强的AST特征；以及一个联合适应管道，以统一代码语义和语法。", "conclusion": "K-ASTRO 在三个大规模数据集上的实验结果表明其达到了业界领先的表现，同时能够在CPU上快速进行推理，训练时间也较短。通过提供可扩展、具有解释性和高效性解决方案，K-ASTRO 桥接了LLM技术进步与实用软件漏洞检测之间的差距，并开源了工具以促进进一步研究。"}
{"llm_update_time": "20251015", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2510.12186", "html_url": "https://arxiv.org/abs/2510.12186", "title": "iCodeReviewer：利用组合提示提高安全代码审查", "title_en": "iCodeReviewer: Improving Secure Code Review with Mixture of Prompts", "authors": "Yun Peng,Kisub Kim,Linghan Meng,Kui Liu", "background": "代码审查是确保软件质量的关键过程，能够早期识别潜在的软件问题。安全问题尤为重要，因为它们可能导致严重的软件崩溃和服务中断。最近的研究集中在自动化方法上，以减少安全代码审查过程中的手动工作量。尽管取得了进展，但当前的安全代码审查自动化方法，如静态分析、深度学习模型和提示方法，仍然面临精确度和覆盖面有限的问题，以及缺乏全面评估的挑战。", "innovation": "我们提出了iCodeReviewer，这是一种基于大语言模型（LLMs）的自动化安全代码审查方法。iCodeReviewer使用一种新颖的混合提示架构，结合了许多提示专家来提高安全问题的覆盖面。每个提示专家是一个动态提示管道，用于检查特定安全问题的存在。iCodeReviewer还实现了一个有效的路由算法，根据输入程序的代码特征仅激活必要的提示专家，从而减少由于LLM幻觉引起的假阳性。", "conclusion": "在我们内部数据集中的实验结果表明，iCodeReviewer在安全问题识别和定位方面的F1分数为63.98%。当部署到生产环境时，iCodeReviewer生成的审查评论的接受率为84%，证明了其有效性。"}
{"llm_update_time": "20251015", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2510.12380", "html_url": "https://arxiv.org/abs/2510.12380", "title": "通过编码器参数调整降低AV1解码复杂性和能耗的实证研究", "title_en": "An Empirical Study of Reducing AV1 Decoder Complexity and Energy Consumption via Encoder Parameter Tuning", "authors": "Vibhoothi Vibhoothi,Julien Zouein,Shanker Shreejith,Jean-Baptiste Kempf,Anil Kokaram", "background": "先进视频编解码器（如AV1）的广泛应用受到了其高解码复杂度的限制，特别是对于电池约束的设备而言，这是一个重大挑战。虽然编码器可以配置以生成对解码器友好的位流，但估算给定视频的解码复杂度和能耗是相当困难的。已有研究强调了通过调整编码器参数来降低解码器复杂度的潜力，但系统地分析这种调整对不同编码器的影响仍然不足。本研究通过系统地分析二者AV1编码器libaom-av1和SVT-AV1中的不同编码工具的禁用情况和编码参数调整，利用系统级能耗测量工具（如RAPL、Intel SoC Watch等），量化了解码复杂性、能耗和压缩效率之间的权衡关系。", "innovation": "本研究通过实证分析揭示了通过禁用特定编码工具和调整编码参数来降低AV1解码复杂度的策略，特别是在libaom-av1和SVT-AV1两种编码器中。研究发现，特定的编码器配置可以在几乎不影响感知质量的情况下显著减少解码周期数。对于libaom-av1，禁用CDEF这一内环滤波器可以将平均解码周期减少10%；而SVT-AV1通过使用内置的快速解码预设（fast-decode=2）则能够实现更显著的24%解码周期减少。这些发现为内容提供商提供了降低AV1视频流能耗的策略。", "conclusion": "通过禁用特定的编码工具和调整编码参数，研究发现可以显著降低AV1解码器的复杂度和能耗，而几乎不影响感知质量。特别是对于libaom-av1和SVT-AV1编码器，研究人员提出了具体的配置建议，这为降低AV1视频流的能耗提供了实用策略。"}
{"llm_update_time": "20251015", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2304.06367", "html_url": "https://arxiv.org/abs/2304.06367", "title": "GitHub开源项目中关于个人数据和数据保护问题的谁、什么和为什么", "title_en": "The whos, whats, and whys of issues related to personal data and data protection in open-source projects on GitHub", "authors": "Anne Henning,Lukas Schulte,Steffen Herbold,Oksana Kulyk,Peter Mayer", "background": "欧盟的通用数据保护条例（GDPR）和美国的加利福尼亚消费者隐私法案（CCPA）等数据保护法规影响了软件处理用户个人数据的方式。先前的研究主要关注软件运营中对这些法规的讨论，或这些话题在软件开发过程之外的其他渠道中的讨论。然而，缺乏这类法规对软件开发过程的影响视角。本文通过分析652个开源GitHub项目中的问题，探讨了这些法规如何影响软件开发过程中的讨论、谁报告与讨论涉及个人数据和数据保护的问题，以及开发人员如何应对这些问题。研究发现，GDPR实施后，报告问题的比例显著增加。最常见的问题类型是与隐私增强相关的功能请求，通常由频繁报告者和频繁贡献者提出。特别地，匿名报告者也频繁报告隐私增强问题。大多数请求未经过反对投票便得到了解决。总体而言，研究结果表明，数据保护法规有效促进了软件开发社区中关于隐私的讨论。", "innovation": "本文利用归纳编码分析了652个开源GitHub项目中的问题，探讨了数据保护法规如何影响软件开发过程中的讨论，识别报告和讨论个人数据和数据保护问题的角色，并量化分析了角色、解决方案和数据保护问题之间的关系，以了解相关性并预测问题的解决方案。这是首次从软件开发过程的角度全面研究数据保护法规的影响", "conclusion": "数据保护法规显著增加了关于个人数据和隐私问题的讨论，尤其是在GDPR实施后。最常见的问题类型是与隐私增强相关的功能请求，通常由频繁报告者和贡献者提出，但也吸引了匿名报告者的关注。大多数问题没有反对意见就得到了解决，这表明这些法规促进了开源社区中关于数据保护和隐私的积极讨论。"}
{"llm_update_time": "20251015", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2408.13653", "html_url": "https://arxiv.org/abs/2408.13653", "title": "针对自动驾驶中3D障碍检测规格性的鲁棒性评估", "title_en": "On the Robustness Evaluation of 3D Obstacle Detection Against Specifications in Autonomous Driving", "authors": "Tri Minh Triet Pham,Bo Yang,Jinqiu Yang", "background": "自主驾驶系统依赖于实时传感器数据（如摄像头和激光雷达）进行时间敏感的决策，并使用深度神经网络。这些决策的准确性对于自主驾驶系统的广泛应用至关重要，因为错误可能会导致严重的后果。尤其是3D障碍物检测对来自多种来源的点云数据噪声非常敏感。目前，尚无针对源自激光雷达传感器规格和对其捕捉不同颜色和材料物体能力的研究中的规范性扰动的鲁棒性进行评估的方法。", "innovation": "本文提出了一种名为SORBET的框架，用于评估3D障碍检测模型在面对这些规范性扰动对点云数据影响下的鲁棒性。该框架应用于评估五个经典的3D障碍检测模型的鲁棒性，其中包括百度Apollo的一个工业级四级自动驾驶系统。此外，还研究了偏离的障碍物检测结果如何传播并负面影响路径预测。这些评估强调了在针对规范性扰动对3D障碍检测进行测试方面的重要性。", "conclusion": "我们的评估发现，即使是点云数据中的微小变化（如移除两个点）也可能带来检测性能的显著下降。而且，这种负面影响会进一步传播到其他模块，对自主驾驶系统的安全性构成威胁。"}
{"llm_update_time": "20251015", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2311.02433", "html_url": "https://arxiv.org/abs/2311.02433", "title": "ChatGPT能否支持软件验证？", "title_en": "Can ChatGPT support software verification?", "authors": "Christian Janßen,Cedric Richter,Heike Wehrheim", "background": "大型语言模型在软件工程任务中越来越有效，如代码生成、调试和修复。以ChatGPT为代表的语言模型不仅能生成代码，还能解释其工作原理及其正确性，这为利用ChatGPT辅助形式软件验证提出了可能。程序验证中核心任务是生成循环不变式，有效的不变式生成可能帮助形式验证工具。", "innovation": "本文初步探索了ChatGPT生成循环不变式的可能性。通过让ChatGPT注释106个C程序中的循环不变式，并通过Frama-C和CPAchecker验证器检查生成不变式的有效性与实用性。结果表明，ChatGPT能够生成有效的循环不变式，从而使Frama-C能够验证之前无法解决的任务。基于初步发现，本文提出了将ChatGPT与软件验证工具结合的方式，并讨论了当前的局限性和开放问题。", "conclusion": "初步研究表明，ChatGPT有潜力支持软件验证，尤其是生成循环不变式的任务。通过结合大语言模型与验证工具，可以进一步提升形式验证的效率和准确性，但仍存在许多挑战需要克服。"}
{"llm_update_time": "20251015", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2507.19842", "html_url": "https://arxiv.org/abs/2507.19842", "title": "一种公共机构基于知识的业务流程设计合作方法", "title_en": "A Cooperative Approach for Knowledge-based Business Process Design in a Public Authority", "authors": "Mohammad Azarijafari,Luisa Mich,Michele Missikoff,Oleg Missikoff", "background": "当前企业正经历着由于不可避免的数字化转型而引发的深刻变革。为了保持竞争力，企业需要适应数字解决方案，转变其组织结构和运营方式。这种组织转变对小企业和中型企业同样重要。一个关键的创新前沿是在生产中采用基于过程的生产模式。", "innovation": "该论文提出了一种基于知识的方法，支持业务专家设计业务流程。该方法不需要以前对知识工程的专门知识，并引导设计师通过结构化的步骤来生成目标流程的图示工作流。知识库的构建从简单的基于文本的知识制品开始，然后逐步发展到更结构化、形式化的表示。", "conclusion": "该方法旨在为所有参与业务流程设计的各个利益相关者和参与者提供一种共享的方法。"}
{"llm_update_time": "20251015", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2504.07208", "html_url": "https://arxiv.org/abs/2504.07208", "title": "谁在乎测试？：社会技术软件测试体验的共同创造", "title_en": "Who cares about testing?: Co-creations of Socio-technical Software Testing Experiences", "authors": "Mark Swillus,Rashina Hoda,Andy Zaidman", "background": "软件测试对于确保软件质量至关重要，但开发者的参与度却差异很大。识别导致参与度差异的技术、组织和社会因素对于去除障碍并利用测试的促进因素至关重要。尽管大量研究强调测试策略和技术解决方案的价值，但对于为什么开发者会（不会）进行测试知之甚少。本文研究了软件开发者的亲身经历，以揭示他们对测试的看法如何改变。通过对开发者的深入、半结构化访谈，研究探索了测试实践的使用时间和原因。该研究通过社会技术和扎根理论（STGT）系统的分析，呈现出开发者是否使用测试实践背后的原因，并提出了新兴测试策略（ETS）理论。", "innovation": "本研究采用社会技术和扎根理论（STGT）系统分析19名软件开发者深入、半结构化访谈的数据，揭示了个人实践变化中的测试实践条件，并提出新兴测试策略（ETS）理论，解释开发者为何（不）使用测试实践。此外，研究揭示了测试制品与从业者集体反思之间的新视角，并认可测试是一个与人类和社会因素交织在一起的工作和环境体验。", "conclusion": "本研究揭示了测试实践背后的新兴测试策略，并理解了开发者的个人体验和观点的演变，为理解和促进测试实践提供了新的视角。"}
{"llm_update_time": "20251015", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2504.17542", "html_url": "https://arxiv.org/abs/2504.17542", "title": "Cottontail：大型语言模型驱动的生成高度结构化测试输入的条件执行", "title_en": "Cottontail: Large Language Model-Driven Concolic Execution for Highly Structured Test Input Generation", "authors": "Haoxin Tu,Seongmin Lee,Yuxian Li,Peng Chen,Lingxiao Jiang,Marcel Böhme", "background": "现有的条件执行引擎在输入结构的路径约束选择上缺乏辨识能力，导致测试效果有限；同时它们在约束求解能力上也有局限性，生成了大量无效的测试输入；此外，还需要人工提供结构化的种子输入以进行无间断测试。", "innovation": "提出了Cottontail，一种新的基于大型语言模型的条件执行引擎。Cottontail设有一个称为Expressive Structural Coverage Tree (ESCT)的更具表示性的程序路径模型，能够选择结构意识的路径约束。还设计了一个基于Solve-Complete范式的大型语言模型驱动的约束求解器，智能地解决路径约束，获取既能满足约束又能符合输入语法的测试输入。最终，使用基于历史指导的种子输入获取策略，在测试开始前或饱和后，获取新的高度结构化的测试输入。", "conclusion": "在SymCC基础上实现Cottontail，实验结果表明，Cottontail在横向和分支覆盖率上分别比基线方法平均提高了30.73%和41.32%。此外，Cottontail还发现六个之前未知的漏洞（六个CVE编号），这些问题已向开发者报告，并有四个已被修复。"}
{"llm_update_time": "20251015", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2504.08621", "html_url": "https://arxiv.org/abs/2504.08621", "title": "MooseAgent：基于大规模预训练语言模型的多智能体框架以自动化MOOSE仿真", "title_en": "MooseAgent: A LLM Based Multi-agent Framework for Automating Moose Simulation", "authors": "Tao Zhang,Zhenhai Liu,Yong Xin,Yongjun Jiao", "background": "有限元方法（FEM）在工程和科学计算中广泛应用，但在其预处理、求解器配置和后处理阶段往往会消耗大量时间，并且需要专业知识。", "innovation": "提出了一个名为MooseAgent的自动化解决方案框架，该框架结合了大规模预训练语言模型（LLMs）和多智能体系统。它能够通过自然语言理解用户描述的仿真要求，并通过任务分解和多轮迭代验证策略自动生成MOOSE输入文件的策略。构建并利用注释的MOOSE输入卡片和函数文档的向量数据库来提高准确性和降低模型幻觉。", "conclusion": "实验评价表明，MooseAgent可以在一定程度上自动化MOOSE仿真过程，特别是在处理相对简单的单一物理问题时成功率为高。研究的主要贡献是提出了一个适用于MOOSE的多智能体自动化框架，验证了其简化有限元仿真过程和降低用户门槛的潜力，提供了智能有限元仿真软件开发的新思路。MooseAgent框架的代码已经开源，可以在提供的链接处下载。"}
{"llm_update_time": "20251015", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2508.16508", "html_url": "https://arxiv.org/abs/2508.16508", "title": "Abmax：基于JAX的自适应建模框架", "title_en": "Abmax: A JAX-based Agent-based Modeling Framework", "authors": "Siddharth Chaturvedi,Ahmed El-Gazzar,Marcel van Gerven", "background": "自适应建模（ABM）是研究复杂系统的主要方法之一。通过将系统分解为更简单的相互作用的代理，ABM使研究人员能够观察复杂现象的出现。高性能数组计算库如JAX通过自动矢量化和即时（JIT）编译能够将此类计算模型扩展到大量代理。然而，使用JAX达到这种扩展时，计算模型中使用的数组形状在整个模拟过程中应保持不变，这在某些需要灵活数据结构的代理操作中可能构成约束，尤其是当需要动态选择并单独更新不同数量的代理时。", "innovation": "为了应对这一挑战，我们引入了Abmax，这是一种基于JAX的ABM框架，它实现了多个JIT可编译的算法以提供这一功能。在经典的捕食者模型基准测试中，Abmax实现了与最先进的实现相当的运行时性能。此外，我们还展示了这种功能也可以矢量化，从而可以并行运行许多类似的自适应模型。因此，Abmax不仅改善了现有框架，还进一步推动了自适应建模的性能和实用性。", "conclusion": "我们展示了Abmax在两个例子中的应用：交通流模型和金融市场模型，展示了其使用场景。Abmax为自适应建模提供了更强大的功能，使得开发和运行大规模、复杂自适应模拟变得更加容易和高效。"}
{"llm_update_time": "20251015", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2412.06994", "html_url": "https://arxiv.org/abs/2412.06994", "title": "Phaedrus: 使用轻量级生成模型和大规模语言模型预测动态应用程序行为", "title_en": "Phaedrus: Predicting Dynamic Application Behavior with Lightweight Generative Models and LLMs", "authors": "Bodhisatwa Chatterjee,Neeraj Jadhav,Santosh Pande", "background": "应用特征化是许多软件开发任务的关键技术，如代码和内存布局优化，其中优化决策针对特定程序特征进行定制。然而，现代应用程序的代码库在不同输入下的行为差异巨大，这使得依赖单一代表性执行实例的传统特征化方法面临挑战。传统的基于配置文件的优化方法难以应对现代应用程序输入依赖的变异性，导致在不同输入上获取的应用程序行为迥异。Phaedrus 针对这一问题提出了一种新的编译器辅助深度学习框架，旨在预测跨不同执行实例的动态程序行为，特别是在动态函数调用方面。传统的配置文件指导优化方法在处理输入依赖的现代应用程序变异性时遇到困难，因为针对不同输入进行配置文件化会导致应用程序行为的差异性。为解决这一问题，Phaedrus 提出了两种新的方法：应用行为合成，这是一种无配置文件方法，其中大规模语言模型直接基于源代码和静态编译分析推断动态函数，从而省去传统配置文件化步骤；以及应用配置文件泛化，这种方法使用经过压缩和增强的完整程序路径（WPP）基于函数配置文件训练的生成模型来预测在未见输入下的应用程序行为。实验结果显示，Phaedrus 可以实现WPP函数配置文件大小最多减少 $10^7$ 倍，可以预测执行时间覆盖85-99%的最常用函数，同时能实现约13.19% (多达65%)的应用程序二进制大小减少和约6.08% (多达20%)的性能改进，且无需执行过程中的配置文件化。", "innovation": "Phaedrus 提出了一种新的编译器辅助深度学习框架，通过两种方法解决传统配置文件指导优化方法在处理输入依赖现代应用程序变异性时遇到的问题。第一种方法是应用行为合成，大规模语言模型直接根据源代码和静态编译分析推断动态函数，无需传统配置文件。第二种方法是应用配置文件泛化，使用经过压缩和增强的完整程序路径函数配置文件训练的生成模型来预测未知输入下的应用程序行为。这种方法可以大幅减少WPP函数配置文件大小并提高性能，并且在不执行配置文件化的情况下实现了显著的性能改善和二进制大小减少。", "conclusion": "Phaedrus 提出了一种新的框架，在不执行配置文件化的情况下，通过轻量级生成模型和大规模语言模型有效预测动态应用程序行为。实验表明，该方法显著减小了WPP函数配置文件的大小，预测了执行时间占据大部分的应用程序行为，同时提高了约6%的性能，并减少约13%的应用程序二进制大小。"}
{"llm_update_time": "20251015", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2510.03551", "html_url": "https://arxiv.org/abs/2510.03551", "title": "软件系统中元稳态故障的形式化分析", "title_en": "Formal Analysis of Metastable Failures in Software Systems", "authors": "Peter Alvaro,Rebecca Isaacs,Rupak Majumdar,Kiran-Kumar Muniswamy-Reddy,Mahmoud Salamati,Sadegh Soudjani", "background": "许多大型软件系统显示出元稳态故障的现象。这类故障中，由于工作量的瞬时激增导致系统性能下降，并且在移除工作负载后，系统性能持续维持在较低水平。这种故障在许多大型企业中都报告过，并被认为是云系统可用性中断的一种罕见但灾难性的根源。本文将探讨并提供请求-响应服务器系统中元稳态的数学基础。通过自定义语言建模及数据驱动的校准，构造连续时间马尔可夫链来近似程序语义，进而通过模型结构来提供元稳态模型行为的可视化。这种可视化方法能有效识别导致元稳态行为的系统参数化。", "innovation": "作者提出了一种新的方法论，通过自定义语言建模及数据驱动的校准构造连续时间马尔可夫链，以此研究请求-响应服务器系统中的元稳态故障，并利用模型结构进行可视化分析，有效识别导致元稳态的系统参数化。同时，本文提供了基于逃逸概率的形式化元稳态定义，并揭示了元稳态现象与CTMC特征值结构的关系，从而设计了预测元稳态服务器模型复原时间的算法工具。最后，通过实际的请求-响应系统故障模型，展示了该方法能在毫秒级别上捕捉预测元稳态行为的实例，并且算法确认系统参数接近元稳态模式时复原时间会显著增加。", "conclusion": "本文通过自定义语言和连续时间马尔可夫链模型研究请求-响应服务器系统中的元稳态故障，成功地提供了描述该现象的形式化定义，并开发了预测复原时间的算法工具。研究表明，该方法不仅能够高效识别可能导致元稳态的系统参数化，还能够快速预测这些模式下的复原时间，对实际系统的管理维护具有重要意义。"}
{"llm_update_time": "20251015", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2409.06741", "html_url": "https://arxiv.org/abs/2409.06741", "title": "生成式人工智能在需求工程中的应用：一项系统文献综述", "title_en": "Generative AI for Requirements Engineering: A Systematic Literature Review", "authors": "Haowei Cheng,Jati H. Husen,Yijun Lu,Teeradaj Racharak,Nobukazu Yoshioka,Naoyasu Ubayashi,Hironori Washizaki", "background": "面对日益复杂的软件系统，需求工程面临着诸多挑战。生成式人工智能（GenAI）可以解决这些挑战，但基于GenAI的需求工程研究尚未进行系统性分析，因此本文通过系统文献综述的方式，考察2019年至2025年间发表的艺术文章，研究趋势、方法、挑战及未来方向。", "innovation": "本文采用了系统性的论文筛选、数据提取和特征分析方法，涵盖了238篇文章。研究发现，生成式预训练转换器模型在当前应用中占主导地位，但这类研究在需求工程各个阶段的分布不均匀，且尚未深入探索需求管理。三项核心挑战（重现性、幻觉和可解释性）形成一个紧密相关的三角关系，这对信任和一致性产生影响。研究指出，需要针对这些挑战的整体解决方案，而非孤立的解决策略。此外，工业应用还处于初级阶段，仅有少量研究达到生产水平集成。", "conclusion": "评估实践暴露出成熟度缺口、工具和数据集可用性有限以及分散的基准测试方法。尽管GenAI在需求工程中具有变革潜力，但由于若干障碍，其实用应用尚未达到广泛应用的水平。核心挑战的强烈关联性意味着需要针对这些挑战的交互依赖性领域进行专门的设计而不是孤立的解决方案。现有部署的局限性反映了在推广性、数据质量和可扩展评估方法方面的系统性瓶颈。成功的应用需要在技术稳健性、方法论成熟度和治理整合方面的协调性发展。"}
